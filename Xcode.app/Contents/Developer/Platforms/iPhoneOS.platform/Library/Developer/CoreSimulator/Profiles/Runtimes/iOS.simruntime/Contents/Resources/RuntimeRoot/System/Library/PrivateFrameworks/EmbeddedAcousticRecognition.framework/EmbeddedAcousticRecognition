&n
&n
=K
Configuration file %@ does not exist
EndpointerThreshold does not exist for clientModelVersion %u
EndpointerExtraDelayFrequency does not exist for task %@ and there is no default value returning nil
Texture coordinates (
) out of range
Bitmap coordinates (
) out of bounds
Computing pdf-priors from : 
 out of 
 classes have counts
 lower than 
--class-frame-counts is empty: Cannot initialize priors 
without the counts.
Dimensionality mismatch,
 class_frame_counts 
 pdf_output_llk 
Invalid pdf (
): log-prior dimension = 
<InputData>
<InputDataDim>
<InputDataShape>
<OutputData>
<OutputDataDim>
<OutputDataShape>
<InputExtraList>
<OutputExtraList>
<InputPenultimate>
<OutputPenultimate>
<OutputPenultimateDim>
<InputRequestedUnit>
<GraphReset>
<IsRNN>
<IsFOFE>
<Engine>
</Engine>
Unknown token 
, a typo in config file?
row_index >= 0 && col_index >= 0
!shape.empty()
.config
in != nullptr
out_vec.Dim() % row_num == 0
out_vec.Dim() == out_numrows * out_numcols
!out_node.empty()
Unimplemented TODO
the number of input tensors 
 != 
 , the list of input tensor names
you requested additional outputs, but haven't defined any tensors for that
ReadBasicType: encountered end of stream.
ReadBasicType: did not get expected integer type, 
 vs. 
.  You can change this code to successfully
 read it later, if needed.
Read failure in ReadBasicType, file position is 
, next char is 
Undefined filter document type: 
RECEIVED 
Reject due to sentence length
Reject due to token length
Reject due to document type
Reject due to document length
Reject due to sentences per document
lm-personalize.data
dictated
typed
unknown
QSR_CRASH_ON_WARN
wstring_convert: from_bytes error
expanded
mutable
error
acceptor
not acceptor
input deterministic
non input deterministic
output deterministic
non output deterministic
input/output epsilons
no input/output epsilons
input epsilons
no input epsilons
output epsilons
no output epsilons
input label sorted
not input label sorted
output label sorted
not output label sorted
weighted
unweighted
cyclic
acyclic
cyclic at initial state
acyclic at initial state
top sorted
not top sorted
accessible
not accessible
coaccessible
not coaccessible
string
not string
 -> 
Phone changed before final transition-id found [broken lattice or mismatched model or wrong --reorder option?]
FATAL
ERROR
ImplToFst: Assignment operator disallowed
Fst::Write: No write stream method for 
 Fst type
Fst::Write: No write filename method for 
vector
null
TestProperties: stored Fst properties incorrect
 (stored: props1, computed: props2)
CompatProperties: mismatch: 
: props1 = 
false
, props2 = 
VectorFst::Write: write failed: 
Inconsistent number of states observed during write
tropical
standard
compact
lattice4
Fst::UpdateFstHeader: write failed: 
Fst::Write: Can't open file: 
standard output
Trying to word-align empty lattice.
INFO
AutoQueue: using state-order discipline
AutoQueue: using top-order discipline
AutoQueue: using LIFO discipline
AutoQueue: using SCC meta-discipline
AutoQueue: SCC #
: using trivial discipline
: using shortest-first discipline
: using LIFO disciplle
: using FIFO disciplle
TopOrderQueue: fst is not acyclic.
RmEpsilon: inconsistent acyclic property bit
Prune: Weight needs to have the path property and
 be commutative: 
uapd
LME STREAM DUMP [Header]
LME STREAM DUMP 
: qsrHeader = 
Incorrect quasar blob header
: metaVersion = 
Incorrect quasar blob version
: dataTypeStr = 
Incorrect data type for Lme
Incorrect data type for UserAcusticProfileData
Incorrect data type for UserAcousticProfileData
: dataVersion = 
Was looking for B, but got 
Write failure in WriteBasicType.
loglikes
att_probs
beam 
 of 
, head 
: alignment too low: 
: head 
: location was 
Beam 
 has failed decoder checks 
 times; could num-forbidden-frames[-silence] be too low?
EncodingFinished()
Function is not implemented for this class
No frames output in pitch extraction
Pitch-tracking Viterbi cost is 
 per frame, over 
 frames.
Forward-cost per frame changed from 
 to 
Latency is 
Could not align output
Write failure in WriteIntegerType.
ReadIntegerVector: expected to see type of size 
, saw instead 
, at file position 
ReadIntegerVector: expected to see [, saw 
ReadIntegerVector: read failure at file position 
Silence label is set to 
 but does not match the auto-determined silence label 
. Will use latter.
Word alignment for MBR decoding failed.
Empty aligned lattice. MBR decoding failed.
Best-path failed
Lattice word alignment time: 
word-boundary-int-file
Word boundary file with format <integer-phone-id> [begin|end|singleton|internal|nonword]
unpronounced-word-file
File containing newline-separated list of words with no pronunciation.
max-expand
If >0, the max amount by which lattices will be expanded.
Could not read clock 
silence-label
Numeric id of word symbol that is to be used for silence arcs in the word-aligned lattice (zero is OK)
partial-word-label
Numeric id of word symbol that is to be used for arcs in the word-aligned lattice corresponding to partial words at the end of "forced-out" utterances (zero is OK)
reorder
True if the lattices were generated from graphs that had the --reorder option true, relating to reordering self-loops (typically true)
GCCacheStore: Enter GC: object = 
), free recently cached = 
, cache size = 
, cache frac = 
, cache limit = 
(size) <= (cache_size_)
../libquasar/libkaldi/tools/openfst/src/include/fst/cache.h
GCCacheStore:GC: Unable to free all cached states
GCCacheStore: Exit GC: object = 
Check failed: "
" file: 
 line: 
 000000000000
Could not convert
albums
artists
audiobooks
composers
genres
playlists
podcasts
songs
songs_artists
albums_artists
radiostations
movie_titles
tvshow_titles
phonetic-match-building
on-device-data-sources
ranking-method
most-recently-played
play-count
lg-fst-name
l-fst-name
g-osyms-name
%@.G.fst
%@.LG.fst
com.apple.siri
quasar.pm
SymbolTable::WriteText: Can't open file 
SymbolTable::Write: Can't open file 
<unspecified>
<RecurrentComponentType>
</Component>
, a typo in config?
 (RecurrentComponentType)
you defined two different recurrent component types 
 vs 
<InputDim>
<OutputDim>
this is not a recurrent component, initialization failed, you used 
Unrecognized token 
forward component is not an RNN
backward component is not an RNN
## Forward RNN: input-dim 
, output-dim 
## Backward RNN: input-dim 
Running forward propagation for batch size = 
, which contains 
 frames each from 
 utterances.
Running backward propagation for batch size = 
no recursive recurrent definition
the forward RNN's input dimension does not match the component's input dimension 
the backward RNN's input dimension does not match the component's input dimension 
the component has output dimension 
 , doesn't equal the sum of individual RNN 
 and 
This function is probably not meaningful for bidirectional RNNs.
need RecurrentNnetTrainOptions in recurrent style component, ignoring SetTrainOptions
Inconsistent return type: RecurrentBaseComponent::GetTrainOptions() can not be cast to RecurrentNnetTrainOptions
VectorizeWeightsCorrs
 is not implemented for 
 component.
Function not implemented for this class
GetUnitOutputFnc
GetNormalizedLearningRate
PerturbParams
GetGradient
Running on single input doesn't make sense for bidirectional RNNs, since history state is not saved.
Forward RNN is not quantizable
Backward RNN is not quantizable
create
/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/libquasar/liblm/src/fst_builder.cpp
Not implemented (
Unknown FstBuilder implementation: 
addState
build
Expected 
 states, but only observed 
 state(s).
 arcs, but only observed 
 arc(s).
FstBuilder
MutableFstBuilder
A mutable FST should be supplied when using 
addStateImpl
SqueezedFstBuilder
A stream should be supplied when using 
writeHeader
Aligned file format is currently not supported.
writeState
writeArc
Options(
implementation=
explicitStartEndMarkers=
keepDisambiguationSymbols=
removeRedundantStates=
attachSymbolTables=
mutableFst=
squeezedFst=
SqueezedOptions(
acceptor=
quantized=
stream=
MutableOptions(
fst=
squeezed
_acceptor
_transducer
AudioAdded
AudioEndPointedClient
AudioEndPointedServer
AudioMaxBufferLengthReached
decoders.
.lattice-biglm-lme-faster.supported-lme-template-list
Couldn't get supported LME list
oov-replacement value 
 is not a supported LME for specified decoder chain
slot-to-lme-map
Map from developer slots to LMEs
max-lme-per-utterance
The number of the max lme per utterance. Utterances containing more LME's will be dropped
Empty LME template for slot 
Utterance skipped as number of LMEs in utterance exceed threshold
Tokenizer failed to tokenize '
Failed to tokenize sentence
Can't add pronunciation for 
 (word is not OOV)
Pronunciation mapping failed
orthography=
 pronSize=
|\(|\)|"|\[|\]|\{|\}|
|,|;|\?|\!|\\
lmeDataFactory initialization with 
 failed
G2P initialization with 
No pronunciation for word 
. Falling back to G2P
No OOVs to add
Could not get LME data
Can't open 
 for writing
prons
frequency
app-lm.data
Error reading JSON config file: 
VoiceTrigger
WatermarkDetector not run on input origin 
WatermarkDetector: not enough audio cached.
Failed to compute spectrogram.
WatermarkPeakAvg
WatermarkPeakMax
WatermarkDetected
WatermarkDetector peakMax=
, peakAvg=
, detected=
watermark-detector
above-hi
Frequency (in Hz) of top of upper band
above-lo
Frequency (in Hz) of bottom of upper band
notch-hi
Frequency (in Hz) of top of notch
notch-lo
Frequency (in Hz) of bottom of notch
below-hi
Frequency (in Hz) of top of lower band
below-lo
Frequency (in Hz) of bottom of lower band
supported-input-origins-list
The input origins that are supported (should be comma separated)
watermark-threshold
Average notch threshold value to detect a watermark
povey
mincount %s
maxcount %s
discount %u %lf
mincount %99s
maxcount %99s
maxcount value out of range
discount %u %lf
warning: count value out of range
unrecognized parameter
warning: discount coefficient 
 = 0.0
Good-Turing discounting 
-grams
GT-count [
] = 
warning: no singleton counts
warning: count of count 
 is zero 
-- lowering maxcount
GT discounting disabled
 is zero
warning: discount coeff 
 is out of range: 
discount1 %lf
discount1 %lf
Kneser-Ney smoothing 
n1 = 
n2 = 
one of required KneserNey count-of-counts is zero
D = 
modifying 
-gram counts for Kneser-Ney smoothing
discount2 %lf
discount3+ %lf
discount2 %lf
discount3+ %lf
n3 = 
n4 = 
one of required modified KneserNey count-of-counts is zero
D1 = 
D2 = 
D3+ = 
one of modified KneserNey discounts is negative
discounting method does not support float counts
: Expected token 
, got 
Got EOF while reading matrix data
After end of matrix data, read error.
Stream failure/EOF while reading matrix data.
infinity
Reading negative infinite value into matrix.
Reading negative NaN value into matrix.
Expecting numeric matrix data, got 
Reading infinite value into matrix.
Reading NaN value into matrix.
 File position at start is 
, currently 
Failed to write vector to stream: stream not good
Processed 
s/(.*)/(.*)/(g|gI);
\\([1-9])
Invalid number of groups observed in regex
$$$1
Invalid regular expression: '
 in '
Loaded 
 rules.
Unable to open the file to read: '
max-radius-km
ContextDependency
ToPdf
EndContextDependency
ToLength
Got unexpected token 
 reading context-dependency object.
ContextDependency::GetPdfInfo, no pdfs returned for position 
 of phone 
.   Continuing but this is a serious error.
samplingRateFilter
taskTypeFilter
deviceIdFilter
farFieldFilter
bluetoothDeviceIdFilter
aneContextFilter
cpuContextFilter
gpuContextFilter
 = {
.bz2
warning: '-' used multiple times for input
warning: '-' used multiple times for output
exec compress -c
exec uncompress -c
exec gzip -c
exec gzip -dcf
exec bzip2
exec bzip2 -dcf
exec 7z a -si
exec 7z e -so
exec xz
exec xz -dcf
%s;%s %s
%s;%s >%s
Decoding ready artifact not compatible with speech model (datapack) version
Artifact in 
 stage will be transformed to 
 stage
transformedArtifact != nullptr && transformedArtifact->getLifeCycleStage() == AppLmArtifactLifeCycleStages::get().DECODING_READY
Artifact transformed to decoding readiness not compatible with speech model (datapack) version
language-model-weight
orth
freq
app-lm.data.oov-replacement
\unknown-first
app-lm.NGRAM
phrase-count
custom-prons
Artifact is in incorrect life cycle stage (
Target life cycle stage is invalid (
Unable to revert during the life cycle (from 
Unable to transform artifact beyond 
ngram-count
asr-datapack-version
language-model-fst
Something went wrong while serializing the FST model.
language-model-arpa
Something went wrong while serializing the ARPA model.
Unable to transform artifact to 
 stage.
tokenizer-datapack-version
Artifact transitioned into invalid life cycle stage (
ptree contains data that cannot be represented in JSON format
void boost::property_tree::json_parser::write_json_internal(std::basic_ostream<typename Ptree::key_type::value_type> &, const Ptree &, const std::string &, bool) [Ptree = boost::property_tree::basic_ptree<std::string, std::string>]
/AppleInternal/Library/BuildRoots/b958ad6d-2c13-11ed-a8d5-b25c5e9b9057/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator16.1.Internal.sdk/usr/local/include/boost/property_tree/json_parser/detail/write.hpp
write error
<unspecified file>
0123456789ABCDEF
<Epsilon>
<UnbiasedVar>
<Gamma>
<Beta>
Reading LayerNorm component
 ( min 
, max 
, mean 
, variance 
, skewness 
, kurtosis 
Invalid silence-phones string 
This doesn't work when utt detect is enabled. Doing nothing.
Lattice is null. Doing nothing
Lattice is empty. Doing nothing
~w00
Best conf result sessionId: 
 result: 
WORD_EMBED
IS_LME
LME_ID
IS_SIL
NUM_PHONES
AC_COST_UNPUSHED
IN_BEST_PATH
AC_COST
GRAPH_COST
NUM_FRAMES
LOG_POSTERIOR
LIN_POSTERIOR
Unknown feature type: 
model-feature-list
Comma-separated list of arc features. Example: "BAG_OF_PHONES,KEYWORD:hey,KEYWORD:Siri,LM_SCORE,AC_SCORE,NUM_FRAMES,LOG_POSTERIOR,LIN_POSTERIOR"
sil-phone-csl-file
File containing colon-separated list of silence phones.
node-merge-tol-ms
Node merging tolerance in ms
word-emb-marisa-file
MARISA trie file for word embedding lookup
word-emb-mat-flt32-file
Kaldi binary matrix file (float32) that stores word embeddings
transform-file
See LatticeRnn in nnet/lattice-rnn.h
forward-model-file
backward-model-file
arc-output-model-file
numUnderslashes <= 1
Obtained HWCN in 
StopWatch is still running.
StopWatch is already running.
model-file
Endpoint model file
sequence of features for endpoint model
enable-memory-map
model is memory mapped
endpoint-threshold
Threshold for final endpoint detection
trailing-silence-limit
An upper limit for trailing silence duration (miliseconds) after which recognizer should be forced to endpoint
extra-delay-ms
delaying the endpointer trigger decision by th given amount of time (in msec), when specified.
silence-posterior-nfhat-limit
An upper limit for silence posterior NFHat estimate (miliseconds) after which recognizer should be forced to endpoint
server-features-latency-clamp-begin
Starting point (in miliseconds)for ServerFeaturesLatency Clamp. ServerFeaturesLatency will be clamped at this value for the duration of clamp i.e [serverFeaturesLatencyClampBeginMs, serverFeaturesLatencyClampEndMs]
server-features-latency-clamp-end
Ending point (in miliseconds)for ServerFeaturesLatency Clamp. ServerFeaturesLatency will be allowed to update after this point i.e it will not be clamped anymore
endpoint-threshold needs to be configured to a value between 0-1
num-of-words default
trailing-silence-duration default
eos-likelihood default
silence-posterior default
Hybrid endpointer created with incorrect version
hybrid-endpoint
hybrid-endpoint.
Missing hybrid endpointer config
eager-result-acceptance
eager-result-acceptance.
Missing eager-result-acceptance config
default-server-ep-features
default-server-ep-features.
No available endpointer for samplingRate = 
Feature dim=
 does not match model dim=
Nnet output for endpointing is incorrect
, ep-nnet-value=
EagerResultAccept not configured
Nnet output for recognitionResult validation is incorrect
, nnet-output=
misc-shared.
misc-shared
endpoint.
endpoint
eager.
eager
geo-config-file
The 
 field available since version 
. Please upgrade config.
feature-read.
feature-read
No recognizer component for certain combinations.
Unsupported config file version
voice-trigger-phrase
VoiceTrigger phrase as space separated list of tokens as recognized by the decoder
voice-trigger-phrases
VoiceTrigger phrases as comma/space separated list of tokens as recognized by the decoder
lead-buffer-leeway
Number of samples the primary buffer is allowed to fall behind secondary buffers
trigger phrase: 
num of trigger phrases: 
Endpointing model file
feature-list
List of features
batch-size
Number of feature vectors processed w/o interruption
\NT-inline
SortedMatcher: bad match type
compose
ComposeFst: output symbol table of 1st argument 
does not match input symbol table of 2nd argument
WARNING
CompatSymbols: Symbol table check sums do not match. 
Table sizes are 
ComposeFst: 1st argument requires matching but cannot.
ComposeFst: 2nd argument requires matching but cannot.
ComposeFst: 1st argument cannot match on output labels 
and 2nd argument cannot match on input labels (sort?).
ComposeFst: both sides can't require match
ComposeFstMatcher: safe copy not supported
LookAheadComposeFilter: 1st argument cannot 
match/look-ahead on output labels and 2nd argument 
cannot match/look-ahead on input labels.
LookAheadMatcher: No look-ahead matcher defined
MultiEpsMatcher: Bad multi-eps label: 0
SingleShortestPath: for nshortest > 1, use ShortestPath
 instead
SingleShortestPath: weight and state thresholds not applicable
reverse_
NShortestPath: FST has a cycle and include_final_ties was set to true. This is not currently supported.
DeterminizeFst:
 distance to final states computed for acceptors only
DeterminizeFst: argument not an acceptor
determinize
DeterminizeFsaImpl: cannot copy with out_dist vector
<ShortlistTable>
<PivotShortlist>
<ShortlistLangPairs>
Shortlist target symbol id 
 not in shortlist!
Has shortlist, but dissabled due to shortlist-lang-pair = 
, lp = 
, shortlist-cond-n = 
, shortlist-freq-n = 
Using shortlist, reducing Voc size to 
ConstrainSoftmax
  linearity is quantized
  bias
BackpropagateFnc
 Not implemented!
linearity_
bias_
data
language
Can't init factory :(
v32@?0@"NSString"8@"NSString"16^B24
Can't init LmeDataFactory: (unexpected exception)
Can't init LmeDataFactory: %s
lme-create
jit-use-tokenizer
Getting LME data: outPronCacheHits 
 outPronCacheMisses 
 wordsRejected 
 wordsAccepted 
.tmp
v8@?0
v16@?0@"NSURL"8
Failed to read quasar pronunciation cache from profile blob with error : 
EARUserProfileBuilder.mm
Tokenizer is invoked after explicit release!
Config file version is not supported.
Quasar internal unknown exception
Quasar internal C++ exception: %s
\contact-first
\contact-middle
\contact-last
\contact-nickname
\company-first
\app-first
\jit
v32@?0@8@16^B24
none
ERROR 
ar_AE
bg_BG
zh_CN
zh_TW
hr_HR
cs_CZ
da_DK
nl_NL
nl_BE
en_AE
en_AU
en_GB
en_ID
en_IE
en_IN
en_MY
en_PH
en_SA
en_SG
en_US
en_ZA
fi_FI
fr_BE
fr_CA
fr_FR
de_AT
de_CH
de_DE
el_GR
he_IL
hi_IN
hu_HU
is_IS
it_IT
ja_JP
ko_KR
mr_IN
nb_NO
pl_PL
pt_BR
pt_PT
ro_RO
ru_RU
sk_SK
es_CL
es_CO
es_ES
es_US
sv_SE
th_TH
tr_TR
uk_UA
ur_PK
hy_AM
bn_IN
pa_IN
gu_IN
or_IN
ta_IN
ta_LK
te_IN
kn_IN
ml_IN
si_LK
lo_LA
bo_CN
bo_IN
my_MM
ka_GE
am_ET
chr_US
iu_CA
km_KH
mn_CN
Unknown locale specified in configuration: 
notchWidth %d, antiNotch %d, mR %d, mK %d, mN %d 
notchVec[%d]=%d 
notch-detector.psd.txt
notch-detector.fft.txt
notch-detector.feats.txt
online-las-lm-rescoring-beam-search
LAS model (TF/Espresso/CoreML graph)
encoder-model-file
LAS encoder split model (TF/Espresso/CoreML graph)
decoder-model-file
LAS decoder split model (TF/Espresso/CoreML graph)
batch size
substring-delimiter
Substring delimiter
token-delimiter
Token delimiter
token-delimiters
List of token delimiters
split-tokens-by-character
split tokens by character
lexicon-fst-file
Lexicon FST (to be used for re-tokenization)
subword-sym-table-file
Subword symbol table
lm-fst-file
LM FST (to be used for re-tokenization)
lm-scale
Scaling factor to use for LM weights
subword-oov-symbol
The subword OOV token symbol
word-oov-symbol
The word-level OOV token symbol
word-boundary-symbol
The word boundary subword token symbol
mapping-cache-size
Cache size to use for lazy FST mapping operations
decoderOpts.beam == dynamic_cast<kaldi::quasar::CEEncoderDecoderNet *>(inferenceNet.get())->Beam()
Either `model-file` or both `encoder-model-file` and `decoder-model-file` must be specified
Batch size is not an integer multiple of the frame subsampling factor. 
Encoder might drop frames.
Both token-delimiter and token-delimiters were provided. 
token-delimiter is deprecated, use token-delimiters instead.
Input FST 
 is not ilabel sorted
Subword symbol table must be provided
Invalid path FST. State 
 has 
 arcs
Decoder did not reach end-state, outputting partial traceback.
Failed to get raw recognition lattice.
remove-eos
remove EOS labels from output
remove-sil
remove silence labels from output
max-steps
maximum number of decoder steps
beam
beam width (must match the model)
length-penalty
length penalty
coverage-penalty
coverage penalty
SymbolTable::ReadText: Can't open file 
LatticeWeightTpl::Divide, NaN or invalid number produced. 
[dividing by zero?]  Returning zero.
Union: input/output symbol tables of 1st argument 
do not match input/output symbol tables of 2nd argument
StateSort: bad order vector size: 
there are 
<VocabSize>
<UnknownWord>
<BeginOfSentenceWord>
<EndOfSentenceWord>
the vector cannot be represented as a matrix with rows 
 , while it has dimension 
{ wordCount: %ld, trailingSilenceDuration: %ld, endOfSentenceLikelihood: %f, pauseCounts: ( %@ ), silencePosterior: %f, clientSilenceFramesCountMs: %f, clientSilenceProbability: %f, silencePosteriorNF: %f, serverFeaturesLatency: %f, eagerResultEndTime: %ld }
filter-devices cannot be empty
filter-input-origins cannot be empty
An earlier LatticeRnn in the decoder chain already ran. Doing nothing.
Request does not match filter. Doing nothing.
LatticeRnn output is incorrect 
latnnMitigatorScore
version
Model version
output-model-file
phone-pd2pi-file
bag-of-phones-model-file
Map model into memory (requires aligned models)
threshold
0 = not trigger, 1 = trigger
filter-devices
FORMAT: Pipe-separated list of devices with support for wildcards. Wildcards must come at the end of each device in the list. Example 1: "filter-devices": "*" - matches any device. Example 2: "filter-devices": "iPhone7|Watch*|AudioAccessory1" - matches iPhone7, AudioAccessory1, and devices starting with "Watch". USAGE: One decoder chain can have multiple LatticeRnnMitigators, which are specified using colon notation to create unique names. Example decoder chain: lattice-biglm-lme-faster, ..., lattice-rnn-mitigator:X, lattice-rnn-mitigator:Y, lattice-rnn-mitigator:Z. The LatticeRnnMitigators are checked one-by-one in order. The first one that matches a request will 'claim' the request, run, and prevent the rest from running. All the filter-* conditions are AND'ed together, so a request must match all of them for the corresponding LatticeRnnMitigator to run.
filter-input-origins
List of input origins with the same format as filter-devices.
calibration-scale
Calibration Scale
calibration-offset
Calibration Offset
AC_SCORE
BAG_OF_PHONES
KEYWORD
Cannot find symbol ID for 
LM_SCORE
the input grammar data is empty
the input symbol table is empty
<eps>
LME: no user data available for creating a grammar FST
word <
> not in the input symbol table
/WORD-DIS-
Illegal word: 
Invalid phone in pron for word: 
Word 
Word does not exist in lexicon: 
Phone 
) does not exist in the lexicon
Illegal phone: 
For a lexicon using pos-dep phones, cannot view disambig IDs with pos-indep phones
For a lexicon using pos-indep phones, cannot view disambig IDs with pos-dep phones
Invalid phone 
 not found in lexicon.
Removing a pron for word: 
the base lexicon is not at base phone set mode
the preferred lexicon is not at base phone set mode
the base lexicon and preferred lexicon have different phone set
the guessed lexicon is not at base phone set mode
the base lexicon and guessed lexicon have different phone set
the preferred lexicon and guessed lexicon has different phone set
all input lexicons (base, preferred, guessed) are empty
input user data is empty
AlternativesProcessorBlock
 Config:
tag [
] is not recognized; panicking, cannot produce metaValue
Failed adding meta info, original metaInfo 
Mapping file '
' is not found
<default>
RecogCpuTimeMs
AverageActiveTokensPerFrame
EARErrorDomain
speakingRate
averagePauseDuration
jitter
shimmer
pitch
voicing
 tokenName=%@, start=%f, silenceStart=%f, end=%f, confidence=%f, hasSpaceAfter=%d, hasSpaceBefore=%d, phoneSeq=%@, ipaPhoneSeq=%@, appendedAutoPunctuation=%d, prependedAutoPunctuation=%d, isModifiedByAutoPunctuation=%d
(ver=%@, score=%f, threshold=%f)
<tokenSausage = %@, interpretationIndices = %@>
[TTAW] Final Result Empty.
[TTAW] oneBestFinalResult: 
,correctIndexList: [
 tokens=%@, preITNTokens=%@
[TTAW] partialResult: 
anyResults=%@, countOfIsFinalFalseAlreadyWritten=%@, prevBestRecogText=%s
Requested index %zu out of bounds %zu
%d.%d
com.apple._EARSpeechRecognizer.recognition
com.apple._EARSpeechRecognizer.formatter
com.apple._EARSpeechRecognizer.training
v32@?0@"NSString"8Q16^B24
EARSpeechRecognizer.mm
enableParallelLoading
keepANEModelLoaded
taskForMemoryLock
Could not build recognizer: %d
DUMMYTOKEN
Dictation
textfield-editing-suite
plist
com.apple._EARSpeechRecognizer.recognition.workloop
Size mismatch
Continuous Listening should not be used with Mux
Array sizes are not the same
.mlmodelc
.espresso.net
Tokenized text: "
" to "
", "
Tokenization duration:
partial
final
itnDurationInNs
isEmojiPersonalizationUsed
isEmojiDisambiguationUsed
isEmojiExpectedButNotRecognized
[TTAW] partialIndex: 
, subFinalResult: 
, partialResult: 
[TTAW] exact match, index = 
Should never get here
static _EARSpeechRecognitionResultPackage *ResultStreamWrapper::resultPackageWithResultChoices(const std::vector<std::vector<Token>> &, bool, _EARFormatter *__strong, const quasar::AudioAnalytics &, const quasar::LatnnMitigatorResult &, const double, NSString *__strong, const unsigned int, NSString *__strong, bool, const std::vector<Token> &, _EARSpeechRecognitionResult *__autoreleasing *, bool, std::shared_ptr<ContinuousListeningConfig>, bool, bool, const std::vector<Token> &, std::vector<std::vector<Token>> &, const std::vector<quasar::ItnOverride> &, quasar::ItnEnablingFlags::Flags, bool, bool, _EARSpeechRecognitionResultPackage *__autoreleasing *, const std::vector<std::set<std::string>> &, NSDictionary<NSString *,_EARSpeechRecognitionResultPackage *> *__autoreleasing *, BOOL, BOOL, const std::vector<quasar::Token> &, BOOL, const std::shared_ptr<const VoiceCommandActiveSetCompilation> &, BOOL, NSDictionary<NSString *,NSNumber *> *__autoreleasing *, NSArray<NSString *> *__autoreleasing *)
Results are not properly labeled
v24@?0@"NSDictionary"8@"NSArray"16
v32@?0@"NSArray"8Q16^B24
Quasar PostITN Result. isFinal=
PostITN 1-Best: 
PostITN Choice: 
PostITN Token[
Quasar internal C++ exception:
Quasar executor unknown exception
Quasar executor ObjC exception: %@
Quasar executor C++ exception: %s
Could not report recognition error: %@
DefaultCompactStore::Write: Alignment failed: 
DefaultCompactStore::Write: Write failed: 
v32@?0@"NSString"8@16^B24
Recognition was unsuccessful
Configuration needs either 'romanizer' or 'pron-guide-model-file'
romanization
Failed to create ICU Transilerator for scripts : 
Failed to create unicode string for "
wstring_convert: to_bytes error
 not contained in BPE encoder 
 mapping to 
no symbol 
Decoder hit max sentence length : 
Failed to create UTF-8 string: 
RomanizerBlock
<space>
</w>
failed to unmap region: 
Memory unlock of file failed: 
Failed to hint VM for 
mmap'ed region of 
 at offset 
 from 
 to addr 
Mapping of file failed: 
File mapping at offset 
 of size 
 of file 
 could not be honored, reading instead.
Failed to read 
 bytes at offset 
from "
Read 
 bytes. 
 remaining.
EARSdapiHelper.mm
Failed to initialize SDAPI
src-locale not present in the config
tgt-locale not present in the config
QE handler contains 
 features
quality_features
Raw hypothesis : 
Tokenized hypothesis : 
Meta info 
Confidence 
LowConfidence 
empty source input received
empty nbest input received
Raw source : 
Tokenized source : 
Input'
' has no value set!
QualityEstimatorBlock
class definition has too many fields
VectorFst::Read: read failed: 
VectorFst::Read: unexpected end of file: 
FstImpl::ReadHeader: source: 
, fst_type: 
, arc_type: 
, version: 
, flags: 
FstImpl::ReadHeader: Fst not of type "
FstImpl::ReadHeader: Arc not of type "
FstImpl::ReadHeader: Obsolete 
 Fst version: 
ExpandedFst::Read: Can't open file: 
standard input
 millions
, input-dim 
Non-matching output dims, component:
 data:
Backpropagate() attempted while disabled
Non-matching dims! 
 input-dim : 
 data : 
'inf' in component parameters (weight explosion, try lower learning rate?)
'nan' in component parameters (try lower learning rate?)
maxent model estimation not supported (requires liblbfgs)
nnet-file
The model is not of type kaldi::InferenceNetItf.
action-fst-directory
label-tsv-file
convert-to-plain-text-after-label
default-fst-do-nothing
spaceApplyDefault.fst
spaceApplyRemoveBefore.fst
rewriteApplyCapitalize.fst
rewriteApplyDefault.fst
default-backoff-label
apply-label-threshold-length
label-threshold-tsv-file
joint-model
tasks
Missing supported tasks.
shared-num-nn-components
For non-Kaldi models, shared neural network components is not supported. 'shared-num-nn-components' in config json should not be set.
source-vocab-file
cluster-id-file
excluded-postitn-tokens
informal-text-length
special-formal-puncs
end-of-sentence-puncs
do-not-cap-feature-name
InverseTextNormalizer already initialized.
max-num-feats
chunk-length
punctuation
.punctuation
For non-Kaldi models, 'chunk-length' in config json needs to be set to [1, model input length - 2]. The itn model input length is 
For non-Kaldi models, 'chunk-length' in config json needs to be set to [1, model input length - 2]. The punctuation model input length is 
For non-Kaldi models, <PAD> is required in source-vocab-file
Initialized ITN
Invalid line in compound word list file
chunk overlap is bigger than chunk length.
File containing cluster Ids.
compound-word-file
Maximum number of feats
no-title-casing-file
File with list of words that should not be title-cased
Source vocabulary file
token-boundary-id
Token boundary symbol ID
word-sense-file
File containing list of word senses.
align-right-preitn-tokens-file
File storing list of pre-ITN tokens that should map to next post-ITN token.
regex-feat-file
TSV file storing regex-to-feature map.
double-regex-feat-file
guard-markers-file
TSV file storing guard markers that prevent ITN.
supplement-config-file
supplemental json file which may contain punctuation and other frequently updated paramters such as max-num-feats
Number of tokens in each chunk
chunk-overlap
the number of overlap tokens between two chunks
entity-tsv-file
Duplicate occurrence of entity "
Unknown start entity "
Unknown end entity "
Initialized EntityTransformer.
inputToken=
 label=
outputToken=
Sublabel application 
 failed for token 
Applying 
 overrides
start entity <
end entity <
Encountered orphan start entity 
This cannot happen
inputToken="
" label=
label (
) output score is under threshold (
). Skip applying the label
 concateFst="
ITN failed.
Missing TokenBoundary label
Something that should never happen, just happened. Debug me please...
Regex match for 
) with label 
Preprocessed token: 
tokenNum=
 tokenId=
 word=
 tag=
 tagIsSense=
index=
 token=
 commandId=
French
dictionary
eats
five
hotdogs
Tantor
mighty
fine
elephant.
" ~ 
" -> 
Merging pre-token 
 to next post token
 to previous post token
ITN failed
Tantor-ITN numInputTokens=
 numOutputTokens=
 numOverrides=
 input="
 output="
 overrides=
 preToPostTokMap=
WARNING: No concatenation point found
Detected size mismatch between resultPostItn=
 and resultAlignment=
chunk_tokens_str: 
chunk_post_itn: 
chunk_alignment: 
result_post_itn: 
result_alignment: 
token sequence time is not monotonic increasing.
reset token timing.
emoji-keyword-remove-fst-1
post-itn-hammer
<PAD>
StopWatch is not running.
Process CPU time was not enabled
unordered_map::at: key not found
Emoji
emoji
Emojis
emojis
Emoji's
emoji's
map::at:  key not found
column == arcFeatDims
Cannot phone pd2pi file 
Malformed phone pd2pi file line=
Coding error. norm_word not found for arc
Coding error. wordEmbMat not loaded.
SymbolTable::ReadText: Bad number of columns (
file = 
, line = 
SymbolTable::ReadText: Bad non-negative integer "
SymbolTable::AddSymbol: symbol = 
 already in symbol_map_ with key = 
 but supplied new key = 
 (ignoring new key)
SymbolTable::Read: read failed
SymbolTable::Write: write failed
Missing required field separator
Negative symbol table entry when not allowed
operator()
/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/libquasar/liblm/src/impl/weights.cpp
NULL
EventMap::read, was not expecting character 
Input shape template [
] must include the R and C tokens.
] includes multiple R tokens.
] includes multiple C tokens.
] includes tokens other than R, C and 1.
] must include the R token.
] must include the C token.
Both num_rows and num_cols is 0. At least one dimension should be provided.
num_cols > 0
num_elements % num_cols == 0
num_rows > 0
num_elements % num_rows == 0
num_rows * num_cols == num_elements
UTF8StringToLabels: continuation byte as lead byte
UTF8StringToLabels: truncated utf-8 byte sequence
UTF8StringToLabels: missing/invalid continuation byte
UTF8StringToLabels: Invalid character found: 
StringCompiler::ConvertSymbolToLabel: Symbol "
" is not mapped to any integer label, symbol table = 
StringCompiler::ConvertSymbolToLabel: Bad label integer 
arg0
arg0/adpos
arg1
arg1/adpos
arg2
arg2/adpos
arg0/lacuna
arg1/lacuna
arg2/lacuna
Key = 
%s/1gms/vocab%s
%s/1gms/vocab
reading 
%s/%dgms/%dgm.idx
malformed index entry
%s/%dgms/%s
binary format not yet support in readMinCounts
maxorder %u
malformed N-gram count or more than 
 words per line
undefined word index 
ngram [
] exceeds write buffer
bad binary format
maxorder %u
could not read ngram order
word index 
 out of range
data misaligned
increasing offset bytes from 
 (order 
 level 
SRILM_BINARY_COUNTS_001
neglogprob
logprob
log10prob
Unknown LM score type "
NegLogProb
LogProb
Log10Prob
Coding error
scoreType
tokens
wrong dimensionality of logScores vector
utterance doesn't end with sentence-end symbol(
Ngram orders from previous utterances inconsistent with ones from current utterance
Unexpected number of backoffs: 
utterances
words
OOVs
invalidTokens
invalidUtterances
logProb
perplexity calculation failed, words 
 logprob = 
PPL1
ngramHits
Computed perplexity for 
 sentences, 
 words, 
 OOVs, 
 invalid tokens, 
 invalid utterances
logprob = 
perplexity calculation failed
 ppl = 
 ppl1 = 
Score types do not match
Number of utterances don't match
Number of tokens don't match
aligning scores of utterance 
Utterance 
 doesn't match 
 doesn't match isValidScore
 has non-matching token ids
 has non-matching number of token scores
dimensionality of logScores was chosen too big: 
number of collected tokens and utterances inconsistent
unsupported LmScoreType
number of CorpusStats and interpolation weights don't match
could not retrieve scores from CorpusStats
iterative process to obtain optimal interpolation weights failed
something went wrong with log-score interpolation
number of collected log-scores doesn't match CorpusStats
Input scores are not logProb format, logScores are not comparable
failed to estimate the interpolation weights
Num new Lms = 
 but num interp weights = 
LM component 
 weight: 
Rescoring failed
LM score (type=
) = 
lmScore=
 doesn't match expected score=
Failed to find lattice-biglm-lme-faster decoder
enableLme=false, but LME data was provided. 
Option 1: Set enableLme=true to use the LME data for scoring text with LME tokens. 
Option 2: Set enableLme=false, remove the LME data, and provide text with non-terminals instead of LME tokens.
Could not find OOV word "
" in symbol table(s)
Could not compute LM score due to empty tokenIds and empty tokens.
Could not find "
" in symbol table(s), ignoring token
" in symbol table(s), replacing with "
You chose to use the LM rescoring decoder, but it was not found.
Extra LM weight exceeds max-total-extra-weight, rescaling with 
Extra LM weight must be positive (i.e. not in log scale)
Extra LM weight too small, not using extra LM(s)
Extra LM weight must sum to less than 1.0, using only Extra LM(s)
Mismatch in tokenLmInfos and filteredIds sizes
Mismatch in token IDs
the base LM is NULL or empty
replace
ReplaceFstImpl: input symbols of Fst 
 does not match input symbols of base Fst (0'th fst)
ReplaceFstImpl: output symbols of Fst 
 does not match output symbols of base Fst 
(0'th fst)
ReplaceFstImpl: no Fst corresponding to root label '
' in the input tuple vector
ReplaceFstImpl::ReplaceFstImpl: always_cache = 
ReplaceFst: inconsistent arc iterator flags
Not using replace matcher
CacheDeterministicOnDemandFst cache hit rate = 
, size = 
uninitialized model component
 for location-specific placeholder 
the provided NnlmEvaluator is neither DNN nor RNN
The LME class 
 is not modeled by the NNLM
multiple LME FSTs are mapped into the same non-terminals classes, wrong config?
the individual DeterministicOnDemandFst is NULL or empty
you are requesting linear interpolation, but the total weight is not 1: 
Invalid word symbol, clipping left context: 
Decoder chain was not lazily initialized
No regional model map from 1st pass GeoContext available
placeholder 
 not found in model-map for region 
Using location-specific bigG for 
 from region 
mixture_origin[
masterlm
Empty token received
Invalid code point, 
Invalid UTF-8, 
Not enough space, 
input contains | which is the separator for g2p model.
[a-zA-Z]\.[a-zA-Z]
[a-zA-Z]-[a-zA-Z]
Locale-aware upper/lowercasing failed, falling back to locale-insensitive versions.
^[a-zA-Z]+[0-9]+$
([0-9])
Phone changed unexpectedly in lattice [broken lattice or mismatched model?]
Unexpected phone 
 found inside a word.
Phone changed while following final self-loop [broken lattice or mismatched model or wrong --reorder option?]
Invalid word at end of lattice [partial lattice, forced out?]
Discarding word-ids at the end of a sentence, that don't have alignments.
Broken silence arc at end of utterance (the phone changed); code error
Broken silence arc at end of utterance (does not reach end of silence)
Partial word detected at end of utterance
Not expecting binary unpronounced words file.
Invalid line in unpronounced words file: 
Invalid line in word-boundary file: 
nonword
begin
singleton
internal
Empty word-boundary file
 was not specified in word-boundary file (or options)
[Lattice has input epsilons and/or is not input-deterministic 
(in Mohri sense)]-- i.e. lattice is not deterministic.  
Word-alignment may be slow and-or blow up in memory.
Number of states in lattice exceeded max-states of 
, original lattice had 
 states.  Returning what we have.
ArcMap: non-zero arc labels for superfinal arc
strlen(FLAGS_fst_weight_separator) == 1
../libquasar/libkaldi/src/fstext/lattice-weight.h
Infinity
-Infinity
BadNumber
randgen
RandGenVisitor: cyclic input
ComposeFst: Weights must be a commutative semiring: 
Failed to create a 
 by 
 matrix with only 
 bytes available in the workspace
Failed to create a vector of 
 elements with only 
size >= 0
mem_size_bytes >= 0
Can't create a child workspace of 
. Only have 
 bytes
Feature type unknown. Ignoring feature ..
Initialized nnet with Model file =
Endpoint model file cannot be empty
Feature unknown, 
features allowed are ("num-of-words","num-trailing-sil", "num-frames","end-of-sentence","pause-counts","num-input-label-words","stream-conf","silence-posterior","client-silence-frames-count-ms","client-silence-probability","silence-posterior-nf","server-features-latency", "eager-result-end-time")
endpoint-feature-list cannot be empty
com.apple.siri.languagemodeltraining
com.apple.speech.languagemodeltraining
_EARLMTKaldiVocab
Incorrect format of vocab file for line=%@
VocabSize in the file %lu does not match total vocabulary in file %lu
One of <UnknownWord>, <BeginOfSentenceWord> or <EndOfSentenceWord> symbols are missing from file:%@
token_post_in_cnet_slot
max_post_in_cnet_slot
secondmax_post_in_cnet_slot
num_arcs_in_cnet_slot
logpost
avg_loglike
hyp_len
token_pos_in_hyp
token_freq
token_logfreq
num_frames
spk_rate
(num_hyps_out > 0) && (num_hyps_out <= num_hyps_in_)
std::find(feature_list_.begin(), feature_list_.end(), feature_list[i]) != feature_list_.end() && "Unknown feature provided in the feature list"
token_unigram_frequencies_.size() > 0
nbest_hyps.size() == num_hyps_in_
nbest_loglikes.size() == num_hyps_in_
num_frames > 0
Hypothesis token (
) does not match any arc in the confusion network slot
!binary_in && "Not expecting a binary file."
ss.good()
!binary_in && "Not expecting binary confidence file."
intercept
(atof(feat_std_str.c_str()) > 0) && "Obtained a zero/negative value for standard deviation"
feature_list_.size() == weights_.size()
feature_list_.size() == feature_mean_.size()
feature_list_.size() == feature_std_.size()
feature_list == feature_list_
feats.Dim() == weights_.size()
decoder
overallScore
input
rawOutput
output
numInputPhones
isScoreHigh
isPartial
decoderName
results
com.apple.siri._EARSpeechRecognitionAudioBuffer
Ending current audio stream.
    
Multiple connections to receiving block input name: 
output port not connected: 
Missing input(s) for 
Block '
' - required input not connected: '
' - nonexistent input connected: '
graph-ouput input name specifier not used
Multiple values received in graph-output!
No value received in graph-output!
Unsuported merge-style: 
Input '
' set multiple times!
ProcessingSource
ProcessingSink
MergerBlock
NullBlock
DumpBlock
\data\
ngram
Reading 
\end\
line 
1.#INF
batchSize > 0 && updateInterval > 0 && learningRate > 0 && initializeOption > 0 && initializeOption < 3 && recognitionInterval > 0 && "Bad configuration"
updateInterval % batchSize == 0 && "Bad configuration"
Training network path must be specified.
Training model loading done.
initializeOption > 0 && initializeOption < 3 && "Unrecognized initialize option"
Initial size must be set if initialize option is 2(aka. all-zeros)
Training variables are initialized, training speaker code: 
, inference speaker code: 
, accumulated gradient: 
, processed samples: 
, training offset: 
, recognition offset: 
Training is continuous, speaker code: 
Training speaker code is reset, speaker code: 
gradBuffer && updatedSpeakerCode && "Speaker code container or gradient container does not exist"
Iteration:[
] done, calculated gradient: 
Speaker code is updated: 
Reaches recognition interval, going to reset training and inference speaker code, processed samples: 
, speaker code: 
Training is still running, going to set end to true and end training
Training is ended, going to set end to false and resume training.
refMat.NumRows() == 1
Invalid frame range. Coding error.
signal energy (dB) = 
 noise energy (dB) = 
mt-decoders.
engine-type
CORRECT
SEARCH_ERROR
HOMOPHONE
LM_OVER
GRAPH_OVER
AM_OVER
REF_TOO_SHORT
HYPO_TOO_SHORT
Invalid Category given 
TRANS_ID
PHONE
WORD
Invalid level given 
GENERAL
SCHEMA
CONTEXT
MIN_DURATION
PATTERN
LENGTH
AC-MATCH
AC-MISMATCH
WORD-CONFUSION
Invalid info given 
HYPO
AMONLY
Invalid source given 
Clipping left context because of unknown or rejected word: "
Parameters for 
 have already been registered.
Decoder: 
 inputArcs=
 maxArcs=
Must call init() for 
 before calling run().
Skipping Decoder: 
Running Decoder: 
Decoder 
 failed.
Time
FirstPassCpuMs
stabilizer-averaging-period-ms
Duration in milliseconds over which to stabilize partial results
stabilizer-minimum-word-seen-ms
Minimum duration in milliseconds that word must be recognized before it is considered stable
dfst-cache-size
The maximum number of items cached by each deterministic FST. Has no effect if the decoder doesn't use deterministic FST.
max-arcs
If > 0, decoder does nothing and returns Decoder::Success if the number of input lattice arcs exceeds this value. Decoders can customize behavior related to max-arcs. For example, rescoring decoder scales the lattice before checking max-arcs and keeps checks max-arcs while it runs.
max-arcs-fail-decoder
If true, return Decoder::Failed instead of Decoder::Success when exceeding max-arcs. This stops execution of subsequent decoders in the decoder chain but does not stop or fail the request. Decoders can customize behavior related to max-arcs-fail-decoder
double-partial-silence-interval-ms
if > 0, write a second partial result with a delay of trailing silence duration milliseconds
Linear Output Failed
Skipping calculateNBest since we already did it (eager)
nbest size=
symTableId=
, but decoderChainOutput->lmeInfos.size()=
No HWCN computed, so skipping nbestV2
empty partial results!
empty or mismatched number of timestamps for final result
partial result: 
, partial result timestamp: 
, partial reference: 
partial_results_toggle_count=
partial_results_average_feedback_lag=
faster_partial_results_toggle_count=
faster_partial_results_average_feedback_lag=
Building Decoder 
lattice-biglm-faster
lattice-biglm-lme-faster
lattice-scale-rescore
lattice-word-aligner
lattice-lm-rescore
lattice-realigner
error-blamer
lattice-confidence
lattice-faster
keyword-spotting-decoder
seeva-decoder
seeva-step-decoder
seeva-step-biglm-decoder
seeva-greedy-decoder
seeva-batch-decoder
las-beam-search-decoder
las-speculative-beam-search-decoder
las-lm-rescoring-beam-search-decoder
las-lm-rescoring-speculative-beam-search-decoder
transducer-beam-search-decoder
system-combination-decoder
confusion-network-combiner
phonetic-match
fingerprint-detector
audio-analytics-decoder
audio-analytics-only
lattice-rnn-mitigator
lattice-confidence2
e2e-asr-confidence
watermark-detector2
lattice-biglm-lme-ftm-faster
Unknown decoder type "
" in "
No word boundary info found. Cannot give proper phone sequence.
Phone sequencing failed; ran out of words for unknown reasons. 
Lattice word alignment and confidence computation will also fail. 
PLEASE FILE A RADAR
Phone sequencing failed; Ran out of phones, probably because 
the last word got clipped in the audio. 
Lattice word alignment and confidence computation will also fail.
error-blaming-report
failure-reason
CONFIDENCE
FRAME_LENGTH
Blaming 
Cannot blame given reference and hypothesis, one of them is empty.
Schematics have to be registered first before usage, call RegisterSchematics first
Size of registered schematics is 
 does not match with supplied schematics for utterance, which are 
Unexpected number of confidenceScores
Unexpected number of confidenceScores got 
 words in lattice and got 
 confidence scores
tag-start
tag-end
parameter-prefix
command-phrase-prefix
Error with configuration for CommandTagger
command-tagger
text-proc
start
alignment-queries
No mismatch found - this should never happen)
original upcase region start: 
original upcase region end: 
projections
Adjusting alignment queries
Adjusting alignment projections
Unsupported mapping operation
Unicode error (ICU): 
CaseMapBlock
Non-finite energy found for frame 
. Waveform is: 
SRILM_BINARY_NGRAM_001
SRILM_BINARY_NGRAM_002
gram]
[OOV]
 in binary format
 in old binary format
\%d-grams
invalid ngram order 
skipping 
ngram %u=%lld
ngram order 
ngram number 
unexpected input
discarded 
 OOV 
warning: 
-grams read, expected 
ngram line has 
 fields (
 expected)
invalid codebook index "
bad prob "
warning: questionable prob "
ignoring non-zero bow "
" for maximal ngram
bad bow "
warning: questionable bow "
warning: no bow for prefix of ngram "
warning: non-zero probability for 
 in closed-vocabulary LM
reached EOF before \end\
\data\
ngram %d=%lld
\%d-grams:
writing 
%.*lg
%s%s
%.*lg
\end\
index: %1023s
data: %1023s
invalid binary LM format!
%.1023s
incompatible binary format
failed to read from data file
index (
skipToNextTrie failed for order 
failed to estimate GT discount for order 
Good Turing parameters for 
-grams:
BOW denominator for context "
" is zero; scaling probabilities to sum to 1
BOW numerator for context "
" is 
 < 0
 <= 0,
numerator is 
CONTEXT 
 numerator 
 denominator 
 BOW 
warning: the size of this n-gram exceeds 
 characters (increasing buffer size...): 
 WORD 
 CONTEXTPROB 
 OLDPROB 
 NEWPROB 
 DELTA-H 
 DELTA-LOGP 
 PPL-CHANGE 
 PRUNED 
pruned 
 PRUNED 1
 LPROB 
 BACKOFF-LPROB 
 PRUNED
faking probability for context 
inserted 
 redundant 
-gram probs
warning: distributing 
 left-over probability mass over 
 zeroton words
 left-over probability mass over all 
 words
 NUMER 
 DENOM 
 DISCOUNT 
 LOW 
 LOLPROB 
 backoff probability mass left for "
" -- 
disabling interpolation
incrementing denominator
-gram contexts containing pseudo-events
-gram probs predicting pseudo-events
-gram probs discounted to zero
long-name
Long-name field not allowed
, geoRegion=
Bitmap region not allowed
Circle info required
Both circle and bitmap info used in region 
, which is prohibited
Default region is not part of geo-config file in older versions 
(bitmapRegion->getBitmapColor()) == (geoconfig::NULL_REFERENCE_BITMAP_COLOR)
Neither bitmap nor circle info found in region 
model-map
 not supported
classLM-template-to-fst-map
Neither 
 nor 
 found for region 
 in geo-config
Empty model file for placeholder 
GeoLM: Model cannot be loaded since it does not exist: 
.fst
FST: input label is not sorted!
loading NNLM from 
 not implemented
contextual-data
contextual-data.
sanitizer-special-chars-pattern
Override pattern for TextSanitizer mSpecialChars.
score-threshold
Score threshold for Portrait named entity.
supported-categories
Supported categories for Portrait named entity, delimited by comma
contextual-data.source-map
framework
Contextual data: empty framework is configured in source-map
Portrait
PeopleSuggester
Contextual data: undefined framework is configured: 
max-limit
from-date-in-sec
to-date-in-sec
contact-only
Contextual data: invalid configuration for supported-categories, configured value: 
Contextual data: supported categories: 
, number: 
contextual-data.category-map
contextual-data.name-average-cost-map
contextual-data.name-deviation-cost-map
Contextual data: sanitizer special character patter is set to empty.
preprocessingCategoryCounts
postprocessingCategoryCounts
Contextual data: failed to add words, status: 
1,2,3,4,5,6,7,8,12,13,14,15,16,17,18,20,21
\NT-contact
Config Version is not high enough for personalization
personalization-recipe.personalization-version
Personalization not configured
personalization-recipe.
personalization-recipe
personalization-recipe.categories
Personalization version: 
personalization-version
The version of the categories data
chars-to-trim
The characters to be trimmed from the edges of the raw entity string
chars-to-split
The characters used to split the raw entity string
The relative frequency of the data
template-name
The template name for LME
tag-name
The tag name for LME (also important for enumerations)
Category 
Ignoring entry with orthography 
CoreMLInferenceNet: On-Device ASR: (ANE) Eager Loading and keepANEModelLoaded: 
Could not load 
input1
output1
in_extras.size() == 1
input2
could not make features: 
CoreML prediction failed, falling back to CPU inference
could not predict: 
No output from CoreML: 
v16@?0^v8
Could not make multiarray from matrix 
Unexpected output shape from CoreML: 
Unexpected output from CoreML: 
Could not make multiarray from vector 
Non-vector shape output from CoreML: 
fst-file
LM FST file for dummy experiments
filename
weight
<SourceStateDimension>
<MaxAttentions>
 (SourceStateDimension|MaxAttentions)
Initializing component of type 
this is a non-recurrent version, cannot have a recurrent internal component
no recursive inclusion
component is not initialized, max attention is 
, source state dimension is 
component has input dim 
, attentions 
, source state dimension 
, however, the internal training component has input dim 
the output dim of attention component is 
 , however, the internal training component has output dim 
State 
NumFramesReady() not implemented for this decodable type.
model-override-json
Not applying override because model-override-json is empty or does not exist
Not applying override because override configuration's version is unsupported
Not applying override because the override language: 
 is different from the datapack's language: 
Not applying override because the override phoneset: 
 is different from the datapack's phoneset: 
Not applying override because the override config version: 
 is greater than the datapack's config version: 
phonetic-match-building.
LG FST name
L FST name
G output symbol name
.lg-fst-file
Overriding 
.lg-fst-file to 
.word-syms-map-file
.word-syms-map-file to 
.l-fst-file
.l-fst-file to 
Internal C++ exception: 
output-symtab-file
Output symbol table file
lg-fst-file
LG FST file
phonomap-file
Phonomap file
sys-select-bias
System selection bias
sys-select-lm-scale
System selection LM scale
regex-list-file
List of regular expressions that will be used to catch inputs for phonetic match.
regex-whitelist-file
Regex whitelist
regex-blacklist-file
Regex blacklist
lm-logprob-threshold
Only do PM if LVCSR's LM logprob is less than this.
entity-tags-tsv-file
File containing start and end entity tags
sys-select-score-scale
Scale factor for PM-overallScore for addition to confidences
sys-select-score-min
Minimum PM-overallScore at which to discard the PM result
sys-select-length-norm
Divide PM-overallScore by phone sequence length
do-use-confmodel
Flag for whether or not to use a confidence model, if true confidence-model-file must also be set
confidence-model-file
Filename for confidence model file, format <FEATURE> <WEIGHT> (one per line)
l-fst-file
L FST file (if specified per-word segmentation will be output)
max-align-total-tokens
Maximum number of tokens used just for alignment pass
protect-lme-tags
Comma separated list of trailing strings which can be used identify tokens to be protected from replacement by phonetic match
wildcard-symbol
The wildcard symbol is used to specify a partial match. It will always align with a single phone. Normally set to ~ if you wish to allow phonetic match to do a partial match (filling in the words recognised pre-PM where the wildcard occurs)
wildcard-scale
The wildcard scale is a multiplier applied to the negative log likelihoods in the phonomap corresponding to the wildcard-symbol
placeholders-file
Each line in the file contains a regexes which to match a token in PM-input. The regex should be followed by <TAB> and then a new token which used to get a pron for the replacement. The original token will be switched back when added to the choice list (after PM-output). e.g. (.*)\artist-first<TAB>any_artist. l-fst-file must be specified and contain a prob forthe word given
The JSON config file that stores Phonetic-Match model overrides
Config version < 158 so using FST compatibility mode so subroutine states with no outgoing arcs denotes an exit state
Config version >= 158 so exit states in subroutines are expected to be proper final states - phonetic match will fail otherwise
Phonetic match decoder is using subroutine feature but config version < 111
Must specify an l-fst-file in order to lookup prons for placeholders
Placeholders not formatted correctly in 
Expected each line contain a regex to match followed by a placeholder word, e.g. (.*)\room-first<TAB>kitchen
Replacement word '
' in placeholder regex '
' is not present in '
Found pron="
" for word=
 in placeholder regex=
constant
Setting constant term/intercept to 
Setting 
Feature 
 is not in the model definition.
Read in Confidence Model 
 added 
numWildcardWordMatches=
Matched placeholder for word=
 replacing with pron="
phone=
 start=
 end=
 confidence=
Phone '
' is not a valid phone symbol
Number of phones is 0
PM Failed.
PM ELAPSED: 
 num_phones=
PM Alignment failed - no results
Mismatched number of non-aligned and aligned phonetic match result 
PM ALIGN ELAPSED: 
PM Alignment failed
PM Failed to get any results from lattice
No LM cost found. Skipping PM. Hint: Did you include lattice-lm-rescore?
LVCSR LM logprob=
 is greater than threshold 
. Skipping PM.
pmInput="
Not a match with the regex whitelist. Skipping PM.
Matches the regex blacklist. Skipping PM.
**PM JSON RESULT:
No good phonetic match results
pmOutput="
Score low. Discarding PM result.
Switching to phonetic match decoder output
PM-input
PM-output
PM-used
PM-partial
PM-decoder
Symbol decoder beam
max-active
Symbol decoder max active states
beam-delta
Symbol decoder beam delta
hash-ratio
Symbol decoder hash ratio
ac-scale
Symbol decoder acoustic scale
max-total-tokens
Max total allocated tokens at any time.
pm_overall_score
slm_mean_confidence
trans_slm_mean_confidence
m.size() == PhoneticMatchConfFeatures::kFeatureCount
<n/a>
Greated than 256 rec symbols (phones) in phonomap 
 can't be supported
Cannot perform phonetic match since LG FST is empty
Phone features size of 
 != wildcard LM costs size of 
Frame 
Max tokens 
 exceeded - 
Allocated max tokens 
 prev_id=
 nextstate=
 weight=
 ilabel=
 olabel=
 phone=
Ran out of token storage
Process non-emitting with cutoff=
Exit subroutine state=
subroutine=
 prevnextstate=
Cannot enter subroutine=
 ret_state=
 (nesting not allowed)
Process emitting isym=
Failed to reach final state
Subroutine index 
 already defined
 not used - subroutines indexes must be consecutive
Found 
 phonetic match subroutines 
Possible memory leak: 
: you might have forgotten to call Delete on 
some Elems
\s{2,}
Ignoring silence phone "sil"
ASR prons are empty
Language not provided
Unsupported language: "
Unknown phone: "
Language = 
, IPA prons=
, ASR prons=
, NvASR prons=
, XSAMPA prons=
ja-JP
zh_HK
aai1
aai2
aai3
aai4
aai5
aai6
aau1
aau2
aau3
aau4
aau5
aau6
eoi1
eoi2
eoi3
eoi4
eoi5
eoi6
d.ge
t.sh
a . a
a! . a
i . i
i! . i
M . M
M! . M
e . e
e! . e
o . o
o! . o
p . p
p . p_j
b . b
p\ . p\
t . t
t . ts
t . ts\
d . d
z . z
d . dz
k . k
k . k_j
g . g
s . s
s\ . s\
h . h
4 . 4
A_1_N
A_2_N
A_3_N
A_4_N
A_5_N
A_6_N
aI_1
aI_2
aI_3
aI_4
aI_5
aI_6
a_1_n
a_2_n
a_3_n
a_4_n
a_5_n
a_6_n
aU_1
aU_2
aU_3
aU_4
aU_5
aU_6
p_j_1
p_j_2
p_j_3
p_j_4
p_j_5
p_j_6
p O_1
BU.O1
p O_2
BU.O2
p O_3
BU.O3
p O_4
BU.O4
p O_5
BU.O5
p O_6
p u_1
BU.U1
p u_2
BU.U2
p u_3
BU.U3
p u_4
BU.U4
p u_5
BU.U5
p u_6
p i_1
BI.I1
p i_2
BI.I2
p i_3
BI.I3
p i_4
BI.I4
p i_5
BI.I5
p i_6
p i_1_n
BI.IN1
p i_2_n
BI.IN2
p i_3_n
BI.IN3
p i_4_n
BI.IN4
p i_5_n
BI.IN5
p i_6_n
p i_1_N
BI.IG1
p i_2_N
BI.IG2
p i_3_N
BI.IG3
p i_4_N
BI.IG4
p i_5_N
BI.IG5
p i_6_N
p_j_1 a_1_n
BI.AN1
p_j_2 a_2_n
BI.AN2
p_j_3 a_3_n
BI.AN3
p_j_4 a_4_n
BI.AN4
p_j_5 a_5_n
BI.AN5
p_j_6 a_6_n
p_j_1 aU_1
BI.AO1
p_j_2 aU_2
BI.AO2
p_j_3 aU_3
BI.AO3
p_j_4 aU_4
BI.AO4
p_j_5 aU_5
BI.AO5
p_j_6 aU_6
p_j_1 E_1
BI.IE1
p_j_2 E_2
BI.IE2
p_j_3 E_3
BI.IE3
p_j_4 E_4
BI.IE4
p_j_5 E_5
BI.IE5
p_j_6 E_6
ts_h
ts`_h
ts`_h_w
ts`_h o_1_N
CHU.OG1
ts`_h o_2_N
CHU.OG2
ts`_h o_3_N
CHU.OG3
ts`_h o_4_N
CHU.OG4
ts`_h o_5_N
CHU.OG5
ts`_h o_6_N
ts`_h u_1
CHU.U1
ts`_h u_2
CHU.U2
ts`_h u_3
CHU.U3
ts`_h u_4
CHU.U4
ts`_h u_5
CHU.U5
ts`_h u_6
ts`_h_w @_1_n
CHU.UN1
ts`_h_w @_2_n
CHU.UN2
ts`_h_w @_3_n
CHU.UN3
ts`_h_w @_4_n
CHU.UN4
ts`_h_w @_5_n
CHU.UN5
ts`_h_w @_6_n
ts_h_w
ts_h o_1_N
CU.OG1
ts_h o_2_N
CU.OG2
ts_h o_3_N
CU.OG3
ts_h o_4_N
CU.OG4
ts_h o_5_N
CU.OG5
ts_h o_6_N
ts_h u_1
CU.U1
ts_h u_2
CU.U2
ts_h u_3
CU.U3
ts_h u_4
CU.U4
ts_h u_5
CU.U5
ts_h u_6
ts_h_w @_1_n
CU.UN1
ts_h_w @_2_n
CU.UN2
ts_h_w @_3_n
CU.UN3
ts_h_w @_4_n
CU.UN4
ts_h_w @_5_n
CU.UN5
ts_h_w @_6_n
t_j_1
t_j_2
t_j_3
t_j_4
t_j_5
t_j_6
t i_1
DI.I1
t i_2
DI.I2
t i_3
DI.I3
t i_4
DI.I4
t i_5
DI.I5
t i_6
t i_1_N
DI.IG1
t i_2_N
DI.IG2
t i_3_N
DI.IG3
t i_4_N
DI.IG4
t i_5_N
DI.IG5
t i_6_N
t_j_1 a_1_n
DI.AN1
t_j_2 a_2_n
DI.AN2
t_j_3 a_3_n
DI.AN3
t_j_4 a_4_n
DI.AN4
t_j_5 a_5_n
DI.AN5
t_j_6 a_6_n
t_j_1 aU_1
DI.AO1
t_j_2 aU_2
DI.AO2
t_j_3 aU_3
DI.AO3
t_j_4 aU_4
DI.AO4
t_j_5 aU_5
DI.AO5
t_j_6 aU_6
t_j_1 E_1
DI.IE1
t_j_2 E_2
DI.IE2
t_j_3 E_3
DI.IE3
t_j_4 E_4
DI.IE4
t_j_5 E_5
DI.IE5
t_j_6 E_6
t_j_1 oU_1
DI.OU1
t_j_2 oU_2
DI.OU2
t_j_3 oU_3
DI.OU3
t_j_4 oU_4
DI.OU4
t_j_5 oU_5
DI.OU5
t_j_6 oU_6
t o_1_N
DU.OG1
t o_2_N
DU.OG2
t o_3_N
DU.OG3
t o_4_N
DU.OG4
t o_5_N
DU.OG5
t o_6_N
t u_1
DU.U1
t u_2
DU.U2
t u_3
DU.U3
t u_4
DU.U4
t u_5
DU.U5
t u_6
t_w @_1_n
DU.UN1
t_w @_2_n
DU.UN2
t_w @_3_n
DU.UN3
t_w @_4_n
DU.UN4
t_w @_5_n
DU.UN5
t_w @_6_n
@_1_N
@_2_N
@_3_N
@_4_N
@_5_N
@_6_N
eI_1
eI_2
eI_3
eI_4
eI_5
eI_6
@_1_n
@_2_n
@_3_n
@_4_n
@_5_n
@_6_n
@`_1
@`_2
@`_3
@`_4
@`_5
@`_6
k o_1_N
GU.OG1
k o_2_N
GU.OG2
k o_3_N
GU.OG3
k o_4_N
GU.OG4
k o_5_N
GU.OG5
k o_6_N
k u_1
GU.U1
k u_2
GU.U2
k u_3
GU.U3
k u_4
GU.U4
k u_5
GU.U5
k u_6
k_w @_1_n
GU.UN1
k_w @_2_n
GU.UN2
k_w @_3_n
GU.UN3
k_w @_4_n
GU.UN4
k_w @_5_n
GU.UN5
k_w @_6_n
x o_1_N
HU.OG1
x o_2_N
HU.OG2
x o_3_N
HU.OG3
x o_4_N
HU.OG4
x o_5_N
HU.OG5
x o_6_N
x u_1
HU.U1
x u_2
HU.U2
x u_3
HU.U3
x u_4
HU.U4
x u_5
HU.U5
x u_6
x_w @_1_n
HU.UN1
x_w @_2_n
HU.UN2
x_w @_3_n
HU.UN3
x_w @_4_n
HU.UN4
x_w @_5_n
HU.UN5
x_w @_6_n
i_1_N
i_2_N
i_3_N
i_4_N
i_5_N
i_6_N
i_1_n
i_2_n
i_3_n
i_4_n
i_5_n
i_6_n
ts\_j_1
ts\_j_2
ts\_j_3
ts\_j_4
ts\_j_5
ts\_j_6
ts\ i_1
JI.I1
ts\ i_2
JI.I2
ts\ i_3
JI.I3
ts\ i_4
JI.I4
ts\ i_5
JI.I5
ts\ i_6
ts\ i_1_n
JI.IN1
ts\ i_2_n
JI.IN2
ts\ i_3_n
JI.IN3
ts\ i_4_n
JI.IN4
ts\ i_5_n
JI.IN5
ts\ i_6_n
ts\ i_1_N
JI.IG1
ts\ i_2_N
JI.IG2
ts\ i_3_N
JI.IG3
ts\ i_4_N
JI.IG4
ts\ i_5_N
JI.IG5
ts\ i_6_N
ts\_j_1 a_1_n
JI.AN1
ts\_j_2 a_2_n
JI.AN2
ts\_j_3 a_3_n
JI.AN3
ts\_j_4 a_4_n
JI.AN4
ts\_j_5 a_5_n
JI.AN5
ts\_j_6 a_6_n
ts\_j_1 a_1
JI.A1
ts\_j_2 a_2
JI.A2
ts\_j_3 a_3
JI.A3
ts\_j_4 a_4
JI.A4
ts\_j_5 a_5
JI.A5
ts\_j_6 a_6
ts\_j_1 aU_1
JI.AO1
ts\_j_2 aU_2
JI.AO2
ts\_j_3 aU_3
JI.AO3
ts\_j_4 aU_4
JI.AO4
ts\_j_5 aU_5
JI.AO5
ts\_j_6 aU_6
ts\_j_1 E_1
JI.IE1
ts\_j_2 E_2
JI.IE2
ts\_j_3 E_3
JI.IE3
ts\_j_4 E_4
JI.IE4
ts\_j_5 E_5
JI.IE5
ts\_j_6 E_6
ts\_j_1 oU_1
JI.OU1
ts\_j_2 oU_2
JI.OU2
ts\_j_3 oU_3
JI.OU3
ts\_j_4 oU_4
JI.OU4
ts\_j_5 oU_5
JI.OU5
ts\_j_6 oU_6
ts\_j_1 A_1_N
JI.AG1
ts\_j_2 A_2_N
JI.AG2
ts\_j_3 A_3_N
JI.AG3
ts\_j_4 A_4_N
JI.AG4
ts\_j_5 A_5_N
JI.AG5
ts\_j_6 A_6_N
ts\_j_1 o_1_N
JI.OG1
ts\_j_2 o_2_N
JI.OG2
ts\_j_3 o_3_N
JI.OG3
ts\_j_4 o_4_N
JI.OG4
ts\_j_5 o_5_N
JI.OG5
ts\_j_6 o_6_N
ts\ y_1
JU.YU1
ts\ y_2
JU.YU2
ts\ y_3
JU.YU3
ts\ y_4
JU.YU4
ts\ y_5
JU.YU5
ts\ y_6
ts\_H_1
ts\_H_2
ts\_H_3
ts\_H_4
ts\_H_5
ts\_H_6
ts\_H_1 a_1_n
JU.AN1
ts\_H_2 a_2_n
JU.AN2
ts\_H_3 a_3_n
JU.AN3
ts\_H_4 a_4_n
JU.AN4
ts\_H_5 a_5_n
JU.AN5
ts\_H_6 a_6_n
ts\_H_1 E_1
JU.IE1
ts\_H_2 E_2
JU.IE2
ts\_H_3 E_3
JU.IE3
ts\_H_4 E_4
JU.IE4
ts\_H_5 E_5
JU.IE5
ts\_H_6 E_6
ts\_H_1 i_1_n
JU.IN1
ts\_H_2 i_2_n
JU.IN2
ts\_H_3 i_3_n
JU.IN3
ts\_H_4 i_4_n
JU.IN4
ts\_H_5 i_5_n
JU.IN5
ts\_H_6 i_6_n
k_h_w
k_h o_1_N
KU.OG1
k_h o_2_N
KU.OG2
k_h o_3_N
KU.OG3
k_h o_4_N
KU.OG4
k_h o_5_N
KU.OG5
k_h o_6_N
k_h u_1
KU.U1
k_h u_2
KU.U2
k_h u_3
KU.U3
k_h u_4
KU.U4
k_h u_5
KU.U5
k_h u_6
k_h_w @_1_n
KU.UN1
k_h_w @_2_n
KU.UN2
k_h_w @_3_n
KU.UN3
k_h_w @_4_n
KU.UN4
k_h_w @_5_n
KU.UN5
k_h_w @_6_n
l_j_1
l_j_2
l_j_3
l_j_4
l_j_5
l_j_6
l i_1
LI.I1
l i_2
LI.I2
l i_3
LI.I3
l i_4
LI.I4
l i_5
LI.I5
l i_6
l i_1_n
LI.IN1
l i_2_n
LI.IN2
l i_3_n
LI.IN3
l i_4_n
LI.IN4
l i_5_n
LI.IN5
l i_6_n
l i_1_N
LI.IG1
l i_2_N
LI.IG2
l i_3_N
LI.IG3
l i_4_N
LI.IG4
l i_5_N
LI.IG5
l i_6_N
l_j_1 a_1_n
LI.AN1
l_j_2 a_2_n
LI.AN2
l_j_3 a_3_n
LI.AN3
l_j_4 a_4_n
LI.AN4
l_j_5 a_5_n
LI.AN5
l_j_6 a_6_n
l_j_1 a_1
LI.A1
l_j_2 a_2
LI.A2
l_j_3 a_3
LI.A3
l_j_4 a_4
LI.A4
l_j_5 a_5
LI.A5
l_j_6 a_6
l_j_1 aU_1
LI.AO1
l_j_2 aU_2
LI.AO2
l_j_3 aU_3
LI.AO3
l_j_4 aU_4
LI.AO4
l_j_5 aU_5
LI.AO5
l_j_6 aU_6
l_j_1 E_1
LI.IE1
l_j_2 E_2
LI.IE2
l_j_3 E_3
LI.IE3
l_j_4 E_4
LI.IE4
l_j_5 E_5
LI.IE5
l_j_6 E_6
l_j_1 oU_1
LI.OU1
l_j_2 oU_2
LI.OU2
l_j_3 oU_3
LI.OU3
l_j_4 oU_4
LI.OU4
l_j_5 oU_5
LI.OU5
l_j_6 oU_6
l_j_1 A_1_N
LI.AG1
l_j_2 A_2_N
LI.AG2
l_j_3 A_3_N
LI.AG3
l_j_4 A_4_N
LI.AG4
l_j_5 A_5_N
LI.AG5
l_j_6 A_6_N
l o_1_N
LU.OG1
l o_2_N
LU.OG2
l o_3_N
LU.OG3
l o_4_N
LU.OG4
l o_5_N
LU.OG5
l o_6_N
l u_1
LU.U1
l u_2
LU.U2
l u_3
LU.U3
l u_4
LU.U4
l u_5
LU.U5
l u_6
l_w @_1_n
LU.UN1
l_w @_2_n
LU.UN2
l_w @_3_n
LU.UN3
l_w @_4_n
LU.UN4
l_w @_5_n
LU.UN5
l_w @_6_n
l_H_1
l_H_2
l_H_3
l_H_4
l_H_5
l_H_6
l_H_1 E_1
LYU.IE1
l_H_2 E_2
LYU.IE2
l_H_3 E_3
LYU.IE3
l_H_4 E_4
LYU.IE4
l_H_5 E_5
LYU.IE5
l_H_6 E_6
l y_1
LYU.YU1
l y_2
LYU.YU2
l y_3
LYU.YU3
l y_4
LYU.YU4
l y_5
LYU.YU5
l y_6
m_j_1
m_j_2
m_j_3
m_j_4
m_j_5
m_j_6
m u_1
MU.U1
m u_2
MU.U2
m u_3
MU.U3
m u_4
MU.U4
m u_5
MU.U5
m u_6
m i_1
MI.I1
m i_2
MI.I2
m i_3
MI.I3
m i_4
MI.I4
m i_5
MI.I5
m i_6
m i_1_n
MI.IN1
m i_2_n
MI.IN2
m i_3_n
MI.IN3
m i_4_n
MI.IN4
m i_5_n
MI.IN5
m i_6_n
m i_1_N
MI.IG1
m i_2_N
MI.IG2
m i_3_N
MI.IG3
m i_4_N
MI.IG4
m i_5_N
MI.IG5
m i_6_N
m_j_1 a_1_n
MI.AN1
m_j_2 a_2_n
MI.AN2
m_j_3 a_3_n
MI.AN3
m_j_4 a_4_n
MI.AN4
m_j_5 a_5_n
MI.AN5
m_j_6 a_6_n
m_j_1 aU_1
MI.AO1
m_j_2 aU_2
MI.AO2
m_j_3 aU_3
MI.AO3
m_j_4 aU_4
MI.AO4
m_j_5 aU_5
MI.AO5
m_j_6 aU_6
m_j_1 E_1
MI.IE1
m_j_2 E_2
MI.IE2
m_j_3 E_3
MI.IE3
m_j_4 E_4
MI.IE4
m_j_5 E_5
MI.IE5
m_j_6 E_6
m_j_1 oU_1
MI.OU1
m_j_2 oU_2
MI.OU2
m_j_3 oU_3
MI.OU3
m_j_4 oU_4
MI.OU4
m_j_5 oU_5
MI.OU5
m_j_6 oU_6
n_j_1
n_j_2
n_j_3
n_j_4
n_j_5
n_j_6
n i_1
NI.I1
n i_2
NI.I2
n i_3
NI.I3
n i_4
NI.I4
n i_5
NI.I5
n i_6
n i_1_n
NI.IN1
n i_2_n
NI.IN2
n i_3_n
NI.IN3
n i_4_n
NI.IN4
n i_5_n
NI.IN5
n i_6_n
n i_1_N
NI.IG1
n i_2_N
NI.IG2
n i_3_N
NI.IG3
n i_4_N
NI.IG4
n i_5_N
NI.IG5
n i_6_N
n_j_1 a_1_n
NI.AN1
n_j_2 a_2_n
NI.AN2
n_j_3 a_3_n
NI.AN3
n_j_4 a_4_n
NI.AN4
n_j_5 a_5_n
NI.AN5
n_j_6 a_6_n
n_j_1 aU_1
NI.AO1
n_j_2 aU_2
NI.AO2
n_j_3 aU_3
NI.AO3
n_j_4 aU_4
NI.AO4
n_j_5 aU_5
NI.AO5
n_j_6 aU_6
n_j_1 E_1
NI.IE1
n_j_2 E_2
NI.IE2
n_j_3 E_3
NI.IE3
n_j_4 E_4
NI.IE4
n_j_5 E_5
NI.IE5
n_j_6 E_6
n_j_1 oU_1
NI.OU1
n_j_2 oU_2
NI.OU2
n_j_3 oU_3
NI.OU3
n_j_4 oU_4
NI.OU4
n_j_5 oU_5
NI.OU5
n_j_6 oU_6
n_j_1 A_1_N
NI.AG1
n_j_2 A_2_N
NI.AG2
n_j_3 A_3_N
NI.AG3
n_j_4 A_4_N
NI.AG4
n_j_5 A_5_N
NI.AG5
n_j_6 A_6_N
n o_1_N
NU.OG1
n o_2_N
NU.OG2
n o_3_N
NU.OG3
n o_4_N
NU.OG4
n o_5_N
NU.OG5
n o_6_N
n u_1
NU.U1
n u_2
NU.U2
n u_3
NU.U3
n u_4
NU.U4
n u_5
NU.U5
n u_6
n_H_1
n_H_2
n_H_3
n_H_4
n_H_5
n_H_6
n_H_1 E_1
NYU.IE1
n_H_2 E_2
NYU.IE2
n_H_3 E_3
NYU.IE3
n_H_4 E_4
NYU.IE4
n_H_5 E_5
NYU.IE5
n_H_6 E_6
n y_1
NYU.YU1
n y_2
NYU.YU2
n y_3
NYU.YU3
n y_4
NYU.YU4
n y_5
NYU.YU5
n y_6
o_1_N
o_2_N
o_3_N
o_4_N
o_5_N
o_6_N
oU_1
oU_2
oU_3
oU_4
oU_5
oU_6
p_h_j_1
p_h_j_2
p_h_j_3
p_h_j_4
p_h_j_5
p_h_j_6
p_h i_1
PI.I1
p_h i_2
PI.I2
p_h i_3
PI.I3
p_h i_4
PI.I4
p_h i_5
PI.I5
p_h i_6
p_h i_1_n
PI.IN1
p_h i_2_n
PI.IN2
p_h i_3_n
PI.IN3
p_h i_4_n
PI.IN4
p_h i_5_n
PI.IN5
p_h i_6_n
p_h i_1_N
PI.IG1
p_h i_2_N
PI.IG2
p_h i_3_N
PI.IG3
p_h i_4_N
PI.IG4
p_h i_5_N
PI.IG5
p_h i_6_N
p_h_j_1 a_1_n
PI.AN1
p_h_j_2 a_2_n
PI.AN2
p_h_j_3 a_3_n
PI.AN3
p_h_j_4 a_4_n
PI.AN4
p_h_j_5 a_5_n
PI.AN5
p_h_j_6 a_6_n
p_h_j_1 aU_1
PI.AO1
p_h_j_2 aU_2
PI.AO2
p_h_j_3 aU_3
PI.AO3
p_h_j_4 aU_4
PI.AO4
p_h_j_5 aU_5
PI.AO5
p_h_j_6 aU_6
p_h_j_1 E_1
PI.IE1
p_h_j_2 E_2
PI.IE2
p_h_j_3 E_3
PI.IE3
p_h_j_4 E_4
PI.IE4
p_h_j_5 E_5
PI.IE5
p_h_j_6 E_6
ts\_h_j_1
ts\_h_j_2
ts\_h_j_3
ts\_h_j_4
ts\_h_j_5
ts\_h_j_6
ts\_h i_1
QI.I1
ts\_h i_2
QI.I2
ts\_h i_3
QI.I3
ts\_h i_4
QI.I4
ts\_h i_5
QI.I5
ts\_h i_6
ts\_h i_1_n
QI.IN1
ts\_h i_2_n
QI.IN2
ts\_h i_3_n
QI.IN3
ts\_h i_4_n
QI.IN4
ts\_h i_5_n
QI.IN5
ts\_h i_6_n
ts\_h i_1_N
QI.IG1
ts\_h i_2_N
QI.IG2
ts\_h i_3_N
QI.IG3
ts\_h i_4_N
QI.IG4
ts\_h i_5_N
QI.IG5
ts\_h i_6_N
ts\_h_j_1 a_1_n
QI.AN1
ts\_h_j_2 a_2_n
QI.AN2
ts\_h_j_3 a_3_n
QI.AN3
ts\_h_j_4 a_4_n
QI.AN4
ts\_h_j_5 a_5_n
QI.AN5
ts\_h_j_6 a_6_n
ts\_h_j_1 a_1
QI.A1
ts\_h_j_2 a_2
QI.A2
ts\_h_j_3 a_3
QI.A3
ts\_h_j_4 a_4
QI.A4
ts\_h_j_5 a_5
QI.A5
ts\_h_j_6 a_6
ts\_h_j_1 aU_1
QI.AO1
ts\_h_j_2 aU_2
QI.AO2
ts\_h_j_3 aU_3
QI.AO3
ts\_h_j_4 aU_4
QI.AO4
ts\_h_j_5 aU_5
QI.AO5
ts\_h_j_6 aU_6
ts\_h_j_1 E_1
QI.IE1
ts\_h_j_2 E_2
QI.IE2
ts\_h_j_3 E_3
QI.IE3
ts\_h_j_4 E_4
QI.IE4
ts\_h_j_5 E_5
QI.IE5
ts\_h_j_6 E_6
ts\_h_j_1 oU_1
QI.OU1
ts\_h_j_2 oU_2
QI.OU2
ts\_h_j_3 oU_3
QI.OU3
ts\_h_j_4 oU_4
QI.OU4
ts\_h_j_5 oU_5
QI.OU5
ts\_h_j_6 oU_6
ts\_h_j_1 A_1_N
QI.AG1
ts\_h_j_2 A_2_N
QI.AG2
ts\_h_j_3 A_3_N
QI.AG3
ts\_h_j_4 A_4_N
QI.AG4
ts\_h_j_5 A_5_N
QI.AG5
ts\_h_j_6 A_6_N
ts\_h_j_1 o_1_N
QI.OG1
ts\_h_j_2 o_2_N
QI.OG2
ts\_h_j_3 o_3_N
QI.OG3
ts\_h_j_4 o_4_N
QI.OG4
ts\_h_j_5 o_5_N
QI.OG5
ts\_h_j_6 o_6_N
ts\_h y_1
QU.YU1
ts\_h y_2
QU.YU2
ts\_h y_3
QU.YU3
ts\_h y_4
QU.YU4
ts\_h y_5
QU.YU5
ts\_h y_6
ts\_h_H_1
ts\_h_H_2
ts\_h_H_3
ts\_h_H_4
ts\_h_H_5
ts\_h_H_6
ts\_h_H_1 a_1_n
QU.AN1
ts\_h_H_2 a_2_n
QU.AN2
ts\_h_H_3 a_3_n
QU.AN3
ts\_h_H_4 a_4_n
QU.AN4
ts\_h_H_5 a_5_n
QU.AN5
ts\_h_H_6 a_6_n
ts\_h_H_1 i_1_n
QU.IN1
ts\_h_H_2 i_2_n
QU.IN2
ts\_h_H_3 i_3_n
QU.IN3
ts\_h_H_4 i_4_n
QU.IN4
ts\_h_H_5 i_5_n
QU.IN5
ts\_h_H_6 i_6_n
ts\_h_H_1 E_1
QU.IE1
ts\_h_H_2 E_2
QU.IE2
ts\_h_H_3 E_3
QU.IE3
ts\_h_H_4 E_4
QU.IE4
ts\_h_H_5 E_5
QU.IE5
ts\_h_H_6 E_6
z`_w
z` u_1
RU.U1
z` u_2
RU.U2
z` u_3
RU.U3
z` u_4
RU.U4
z` u_6
z`_w @_1_n
RU.UN1
z`_w @_2_n
RU.UN2
z`_w @_3_n
RU.UN3
z`_w @_4_n
RU.UN4
z`_w @_5_n
RU.UN5
z`_w @_6_n
s`_w
s` u_1
SHU.U1
s` u_2
SHU.U2
s` u_3
SHU.U3
s` u_4
SHU.U4
s` u_5
SHU.U5
s` u_6
s`_w @_1_n
SHU.UN1
s`_w @_2_n
SHU.UN2
s`_w @_3_n
SHU.UN3
s`_w @_4_n
SHU.UN4
s`_w @_5_n
SHU.UN5
s`_w @_6_n
s o_1_N
SU.OG1
s o_2_N
SU.OG2
s o_3_N
SU.OG3
s o_4_N
SU.OG4
s o_5_N
SU.OG5
s o_6_N
s u_1
SU.U1
s u_2
SU.U2
s u_3
SU.U3
s u_4
SU.U4
s u_5
SU.U5
s u_6
s_w @_1_n
SU.UN1
s_w @_2_n
SU.UN2
s_w @_3_n
SU.UN3
s_w @_4_n
SU.UN4
s_w @_5_n
SU.UN5
s_w @_6_n
t_h_j_1
t_h_j_2
t_h_j_3
t_h_j_4
t_h_j_5
t_h_j_6
t_h i_1
TI.I1
t_h i_2
TI.I2
t_h i_3
TI.I3
t_h i_4
TI.I4
t_h i_5
TI.I5
t_h i_6
t_h i_1_N
TI.IG1
t_h i_2_N
TI.IG2
t_h i_3_N
TI.IG3
t_h i_4_N
TI.IG4
t_h i_5_N
TI.IG5
t_h i_6_N
t_h_j_1 a_1_n
TI.AN1
t_h_j_2 a_2_n
TI.AN2
t_h_j_3 a_3_n
TI.AN3
t_h_j_4 a_4_n
TI.AN4
t_h_j_5 a_5_n
TI.AN5
t_h_j_6 a_6_n
TI.AN6
t_h_j_1 aU_1
TI.AO1
t_h_j_2 aU_2
TI.AO2
t_h_j_3 aU_3
TI.AO3
t_h_j_4 aU_4
TI.AO4
t_h_j_5 aU_5
TI.AO5
t_h_j_6 aU_6
t_h_j_1 E_1
TI.IE1
t_h_j_2 E_2
TI.IE2
t_h_j_3 E_3
TI.IE3
t_h_j_4 E_4
TI.IE4
t_h_j_5 E_5
TI.IE5
t_h_j_6 E_6
t_h o_1_N
TU.OG1
t_h o_2_N
TU.OG2
t_h o_3_N
TU.OG3
t_h o_4_N
TU.OG4
t_h o_5_N
TU.OG5
t_h o_6_N
t_h_w
t_h u_1
TU.U1
t_h u_2
TU.U2
t_h u_3
TU.U3
t_h u_4
TU.U4
t_h u_5
TU.U5
t_h u_6
t_h_w @_1_n
TU.UN1
t_h_w @_2_n
TU.UN2
t_h_w @_3_n
TU.UN3
t_h_w @_4_n
TU.UN4
t_h_w @_5_n
TU.UN5
t_h_w @_6_n
u_1_n
u_2_n
u_3_n
u_4_n
u_5_n
u_6_n
s\_j_1
s\_j_2
s\_j_3
s\_j_4
s\_j_5
s\_j_6
s\ i_1
XI.I1
s\ i_2
XI.I2
s\ i_3
XI.I3
s\ i_4
XI.I4
s\ i_5
XI.I5
s\ i_6
s\ i_1_n
XI.IN1
s\ i_2_n
XI.IN2
s\ i_3_n
XI.IN3
s\ i_4_n
XI.IN4
s\ i_5_n
XI.IN5
s\ i_6_n
s\ i_1_N
XI.IG1
s\ i_2_N
XI.IG2
s\ i_3_N
XI.IG3
s\ i_4_N
XI.IG4
s\ i_5_N
XI.IG5
s\ i_6_N
s\_j_1 a_1_n
XI.AN1
s\_j_2 a_2_n
XI.AN2
s\_j_3 a_3_n
XI.AN3
s\_j_4 a_4_n
XI.AN4
s\_j_5 a_5_n
XI.AN5
s\_j_6 a_6_n
s\_j_1 a_1
XI.A1
s\_j_2 a_2
XI.A2
s\_j_3 a_3
XI.A3
s\_j_4 a_4
XI.A4
s\_j_5 a_5
XI.A5
s\_j_6 a_6
s\_j_1 aU_1
XI.AO1
s\_j_2 aU_2
XI.AO2
s\_j_3 aU_3
XI.AO3
s\_j_4 aU_4
XI.AO4
s\_j_5 aU_5
XI.AO5
s\_j_6 aU_6
s\_j_1 E_1
XI.IE1
s\_j_2 E_2
XI.IE2
s\_j_3 E_3
XI.IE3
s\_j_4 E_4
XI.IE4
s\_j_5 E_5
XI.IE5
s\_j_6 E_6
s\_j_1 oU_1
XI.OU1
s\_j_2 oU_2
XI.OU2
s\_j_3 oU_3
XI.OU3
s\_j_4 oU_4
XI.OU4
s\_j_5 oU_5
XI.OU5
s\_j_6 oU_6
s\_j_1 A_1_N
XI.AG1
s\_j_2 A_2_N
XI.AG2
s\_j_3 A_3_N
XI.AG3
s\_j_4 A_4_N
XI.AG4
s\_j_5 A_5_N
XI.AG5
s\_j_6 A_6_N
s\_j_1 o_1_N
XI.OG1
s\_j_2 o_2_N
XI.OG2
s\_j_3 o_3_N
XI.OG3
s\_j_4 o_4_N
XI.OG4
s\_j_5 o_5_N
XI.OG5
s\_j_6 o_6_N
s\ y_1
XU.YU1
s\ y_2
XU.YU2
s\ y_3
XU.YU3
s\ y_4
XU.YU4
s\ y_5
XU.YU5
s\ y_6
s\_H_1
s\_H_2
s\_H_3
s\_H_4
s\_H_5
s\_H_6
s\_H_1 a_1_n
XU.AN1
s\_H_2 a_2_n
XU.AN2
s\_H_3 a_3_n
XU.AN3
s\_H_4 a_4_n
XU.AN4
s\_H_5 a_5_n
XU.AN5
s\_H_6 a_6_n
s\_H_1 i_1_n
XU.IN1
s\_H_2 i_2_n
XU.IN2
s\_H_3 i_3_n
XU.IN3
s\_H_4 i_4_n
XU.IN4
s\_H_5 i_5_n
XU.IN5
s\_H_6 i_6_n
s\_H_1 E_1
XU.IE1
s\_H_2 E_2
XU.IE2
s\_H_3 E_3
XU.IE3
s\_H_4 E_4
XU.IE4
s\_H_5 E_5
XU.IE5
s\_H_6 E_6
j_1 i_1
Y.I1
j_2 i_2
Y.I2
j_3 i_3
Y.I3
j_4 i_4
Y.I4
j_5 i_5
Y.I5
j_6 i_6
j_1 a_1
Y.A1
j_2 a_2
Y.A2
j_3 a_3
Y.A3
j_4 a_4
Y.A4
j_5 a_5
Y.A5
j_6 a_6
j_1 aU_1
Y.AO1
j_2 aU_2
Y.AO2
j_3 aU_3
Y.AO3
j_4 aU_4
Y.AO4
j_5 aU_5
Y.AO5
j_6 aU_6
j_1 E_1
Y.IE1
j_2 E_2
Y.IE2
j_3 E_3
Y.IE3
j_4 E_4
Y.IE4
j_5 E_5
Y.IE5
j_6 E_6
j_1 oU_1
Y.OU1
j_2 oU_2
Y.OU2
j_3 oU_3
Y.OU3
j_4 oU_4
Y.OU4
j_5 oU_5
Y.OU5
j_6 oU_6
j_1 i_1_n
Y.IN1
j_2 i_2_n
Y.IN2
j_3 i_3_n
Y.IN3
j_4 i_4_n
Y.IN4
j_5 i_5_n
Y.IN5
j_6 i_6_n
j_1 A_1_N
Y.AG1
j_2 A_2_N
Y.AG2
j_3 A_3_N
Y.AG3
j_4 A_4_N
Y.AG4
j_5 A_5_N
Y.AG5
j_6 A_6_N
j_1 i_1_N
Y.IG1
j_2 i_2_N
Y.IG2
j_3 i_3_N
Y.IG3
j_4 i_4_N
Y.IG4
j_5 i_5_N
Y.IG5
j_6 i_6_N
j_1 o_1_N
Y.OG1
j_2 o_2_N
Y.OG2
j_3 o_3_N
Y.OG3
j_4 o_4_N
Y.OG4
j_5 o_5_N
Y.OG5
j_6 o_6_N
j_1 a_1_n
Y.AN1
j_2 a_2_n
Y.AN2
j_3 a_3_n
Y.AN3
j_4 a_4_n
Y.AN4
j_5 a_5_n
Y.AN5
j_6 a_6_n
j_1 y_1
YU.YU1
j_2 y_2
YU.YU2
j_3 y_3
YU.YU3
j_4 y_4
YU.YU4
j_5 y_5
YU.YU5
j_6 y_6
j_H_1
j_H_2
j_H_3
j_H_4
j_H_5
j_H_6
j_H_1 a_1_n
YU.AN1
j_H_2 a_2_n
YU.AN2
j_H_3 a_3_n
YU.AN3
j_H_4 a_4_n
YU.AN4
j_H_5 a_5_n
YU.AN5
j_H_6 a_6_n
j_H_1 i_1_n
YU.IN1
j_H_2 i_2_n
YU.IN2
j_H_3 i_3_n
YU.IN3
j_H_4 i_4_n
YU.IN4
j_H_5 i_5_n
YU.IN5
j_H_6 i_6_n
j_H_1 E_1
YU.IE1
j_H_2 E_2
YU.IE2
j_H_3 E_3
YU.IE3
j_H_4 E_4
YU.IE4
j_H_5 E_5
YU.IE5
j_H_6 E_6
ts`_w
ts` o_1_N
ZHU.OG1
ts` o_2_N
ZHU.OG2
ts` o_3_N
ZHU.OG3
ts` o_4_N
ZHU.OG4
ts` o_5_N
ZHU.OG5
ts` o_6_N
ts` u_1
ZHU.U1
ts` u_2
ZHU.U2
ts` u_3
ZHU.U3
ts` u_4
ZHU.U4
ts` u_5
ZHU.U5
ts` u_6
ts`_w @_1_n
ZHU.UN1
ts`_w @_2_n
ZHU.UN2
ts`_w @_3_n
ZHU.UN3
ts`_w @_4_n
ZHU.UN4
ts`_w @_5_n
ZHU.UN5
ts`_w @_6_n
ts_w
ts o_1_N
ZU.OG1
ts o_2_N
ZU.OG2
ts o_3_N
ZU.OG3
ts o_4_N
ZU.OG4
ts o_5_N
ZU.OG5
ts o_6_N
ts u_1
ZU.U1
ts u_2
ZU.U2
ts u_3
ZU.U3
ts u_4
ZU.U4
ts u_5
ZU.U5
ts u_6
ts_w @_1_n
ZU.UN1
ts_w @_2_n
ZU.UN2
ts_w @_3_n
ZU.UN3
ts_w @_4_n
ZU.UN4
ts_w @_5_n
ZU.UN5
ts_w @_6_n
a_1_n r\
AN1.R
aI_1 r\
AI1.R
p_j_1 a_1_n r\
BI.AN1.R
p_h_j_1 a_1_n r\
PI.AN1.R
t_j_1 a_1_n r\
DI.AN1.R
t_h_j_1 a_1_n r\
TI.AN1.R
l_j_1 a_1_n r\
LI.AN1.R
m_j_1 a_1_n r\
MI.AN1.R
n_j_1 a_1_n r\
NI.AN1.R
ts\_j_1 a_1_n r\
JI.AN1.R
ts\_H_1 a_1_n r\
JU.AN1.R
ts\_h_j_1 a_1_n r\
QI.AN1.R
ts\_h_H_1 a_1_n r\
QU.AN1.R
s\_j_1 a_1_n r\
XI.AN1.R
s\_H_1 a_1_n r\
XU.AN1.R
j_1 a_1_n r\
Y.AN1.R
j_H_1 a_1_n r\
YU.AN1.R
a_2_n r\
AN2.R
aI_2 r\
AI2.R
p_j_2 a_2_n r\
BI.AN2.R
p_h_j_2 a_2_n r\
PI.AN2.R
t_j_2 a_2_n r\
DI.AN2.R
t_h_j_2 a_2_n r\
TI.AN2.R
l_j_2 a_2_n r\
LI.AN2.R
m_j_2 a_2_n r\
MI.AN2.R
n_j_2 a_2_n r\
NI.AN2.R
ts\_j_2 a_2_n r\
JI.AN2.R
ts\_H_2 a_2_n r\
JU.AN2.R
ts\_h_j_2 a_2_n r\
QI.AN2.R
ts\_h_H_2 a_2_n r\
QU.AN2.R
s\_j_2 a_2_n r\
XI.AN2.R
s\_H_2 a_2_n r\
XU.AN2.R
j_2 a_2_n r\
Y.AN2.R
j_H_2 a_2_n r\
YU.AN2.R
a_3_n r\
AN3.R
aI_3 r\
AI3.R
p_j_3 a_3_n r\
BI.AN3.R
p_h_j_3 a_3_n r\
PI.AN3.R
t_j_3 a_3_n r\
DI.AN3.R
t_h_j_3 a_3_n r\
TI.AN3.R
l_j_3 a_3_n r\
LI.AN3.R
m_j_3 a_3_n r\
MI.AN3.R
n_j_3 a_3_n r\
NI.AN3.R
ts\_j_3 a_3_n r\
JI.AN3.R
ts\_H_3 a_3_n r\
JU.AN3.R
ts\_h_j_3 a_3_n r\
QI.AN3.R
ts\_h_H_3 a_3_n r\
QU.AN3.R
s\_j_3 a_3_n r\
XI.AN3.R
s\_H_3 a_3_n r\
XU.AN3.R
j_3 a_3_n r\
Y.AN3.R
j_H_3 a_3_n r\
YU.AN3.R
a_4_n r\
AN4.R
aI_4 r\
AI4.R
p_j_4 a_4_n r\
BI.AN4.R
p_h_j_4 a_4_n r\
PI.AN4.R
t_j_4 a_4_n r\
DI.AN4.R
t_h_j_4 a_4_n r\
TI.AN4.R
l_j_4 a_4_n r\
LI.AN4.R
m_j_4 a_4_n r\
MI.AN4.R
n_j_4 a_4_n r\
NI.AN4.R
ts\_j_4 a_4_n r\
JI.AN4.R
ts\_H_4 a_4_n r\
JU.AN4.R
ts\_h_j_4 a_4_n r\
QI.AN4.R
ts\_h_H_4 a_4_n r\
QU.AN4.R
s\_j_4 a_4_n r\
XI.AN4.R
s\_H_4 a_4_n r\
XU.AN4.R
j_4 a_4_n r\
Y.AN4.R
j_H_4 a_4_n r\
YU.AN4.R
a_5_n r\
AN5.R
aI_5 r\
AI5.R
p_j_5 a_5_n r\
BI.AN5.R
p_h_j_5 a_5_n r\
PI.AN5.R
t_j_5 a_5_n r\
DI.AN5.R
t_h_j_5 a_5_n r\
TI.AN5.R
l_j_5 a_5_n r\
LI.AN5.R
m_j_5 a_5_n r\
MI.AN5.R
n_j_5 a_5_n r\
NI.AN5.R
ts\_j_5 a_5_n r\
JI.AN5.R
ts\_H_5 a_5_n r\
JU.AN5.R
ts\_h_j_5 a_5_n r\
QI.AN5.R
ts\_h_H_5 a_5_n r\
QU.AN5.R
s\_j_5 a_5_n r\
XI.AN5.R
s\_H_5 a_5_n r\
XU.AN5.R
j_5 a_5_n r\
Y.AN5.R
j_H_5 a_5_n r\
YU.AN5.R
a_6_n r\
aI_6 r\
p_j_6 a_6_n r\
p_h_j_6 a_6_n r\
t_j_6 a_6_n r\
t_h_j_6 a_6_n r\
l_j_6 a_6_n r\
m_j_6 a_6_n r\
n_j_6 a_6_n r\
ts\_j_6 a_6_n r\
ts\_H_6 a_6_n r\
ts\_h_j_6 a_6_n r\
ts\_h_H_6 a_6_n r\
s\_j_6 a_6_n r\
s\_H_6 a_6_n r\
j_6 a_6_n r\
j_H_6 a_6_n r\
a_1 r\
A1.R
a_2 r\
A2.R
a_3 r\
A3.R
a_4 r\
A4.R
a_5 r\
A5.R
a_6 r\
j_1 a_1 r\
Y.A1.R
j_2 a_2 r\
Y.A2.R
j_3 a_3 r\
Y.A3.R
j_4 a_4 r\
Y.A4.R
j_5 a_5 r\
Y.A5.R
j_6 a_6 r\
l_j_1 a_1 r\
LI.A1.R
l_j_2 a_2 r\
LI.A2.R
l_j_3 a_3 r\
LI.A3.R
l_j_4 a_4 r\
LI.A4.R
l_j_5 a_5 r\
LI.A5.R
l_j_6 a_6 r\
ts\_j_1 a_1 r\
JI.A1.R
ts\_j_2 a_2 r\
JI.A2.R
ts\_j_3 a_3 r\
JI.A3.R
ts\_j_4 a_4 r\
JI.A4.R
ts\_j_5 a_5 r\
JI.A5.R
ts\_j_6 a_6 r\
ts\_h_j_1 a_1 r\
QI.A1.R
ts\_h_j_2 a_2 r\
QI.A2.R
ts\_h_j_3 a_3 r\
QI.A3.R
ts\_h_j_4 a_4 r\
QI.A4.R
ts\_h_j_5 a_5 r\
QI.A5.R
ts\_h_j_6 a_6 r\
s\_j_1 a_1 r\
XI.A1.R
s\_j_2 a_2 r\
XI.A2.R
s\_j_3 a_3 r\
XI.A3.R
s\_j_4 a_4 r\
XI.A4.R
s\_j_5 a_5 r\
XI.A5.R
s\_j_6 a_6 r\
aU_1 r\
AO1.R
aU_2 r\
AO2.R
aU_3 r\
AO3.R
aU_4 r\
AO4.R
aU_5 r\
AO5.R
aU_6 r\
p_j_1 aU_1 r\
BI.AO1.R
p_j_2 aU_2 r\
BI.AO2.R
p_j_3 aU_3 r\
BI.AO3.R
p_j_4 aU_4 r\
BI.AO4.R
p_j_5 aU_5 r\
BI.AO5.R
p_j_6 aU_6 r\
p_h_j_1 aU_1 r\
PI.AO1.R
p_h_j_2 aU_2 r\
PI.AO2.R
p_h_j_3 aU_3 r\
PI.AO3.R
p_h_j_4 aU_4 r\
PI.AO4.R
p_h_j_5 aU_5 r\
PI.AO5.R
p_h_j_6 aU_6 r\
t_j_1 aU_1 r\
DI.AO1.R
t_j_2 aU_2 r\
DI.AO2.R
t_j_3 aU_3 r\
DI.AO3.R
t_j_4 aU_4 r\
DI.AO4.R
t_j_5 aU_5 r\
DI.AO5.R
t_j_6 aU_6 r\
t_h_j_1 aU_1 r\
TI.AO1.R
t_h_j_2 aU_2 r\
TI.AO2.R
t_h_j_3 aU_3 r\
TI.AO3.R
t_h_j_4 aU_4 r\
TI.AO4.R
t_h_j_5 aU_5 r\
TI.AO5.R
t_h_j_6 aU_6 r\
l_j_1 aU_1 r\
LI.AO1.R
l_j_2 aU_2 r\
LI.AO2.R
l_j_3 aU_3 r\
LI.AO3.R
l_j_4 aU_4 r\
LI.AO4.R
l_j_5 aU_5 r\
LI.AO5.R
l_j_6 aU_6 r\
m_j_1 aU_1 r\
MI.AO1.R
m_j_2 aU_2 r\
MI.AO2.R
m_j_3 aU_3 r\
MI.AO3.R
m_j_4 aU_4 r\
MI.AO4.R
m_j_5 aU_5 r\
MI.AO5.R
m_j_6 aU_6 r\
n_j_1 aU_1 r\
NI.AO1.R
n_j_2 aU_2 r\
NI.AO2.R
n_j_3 aU_3 r\
NI.AO3.R
n_j_4 aU_4 r\
NI.AO4.R
n_j_5 aU_5 r\
NI.AO5.R
n_j_6 aU_6 r\
ts\_j_1 aU_1 r\
JI.AO1.R
ts\_j_2 aU_2 r\
JI.AO2.R
ts\_j_3 aU_3 r\
JI.AO3.R
ts\_j_4 aU_4 r\
JI.AO4.R
ts\_j_5 aU_5 r\
JI.AO5.R
ts\_j_6 aU_6 r\
ts\_h_j_1 aU_1 r\
QI.AO1.R
ts\_h_j_2 aU_2 r\
QI.AO2.R
ts\_h_j_3 aU_3 r\
QI.AO3.R
ts\_h_j_4 aU_4 r\
QI.AO4.R
ts\_h_j_5 aU_5 r\
QI.AO5.R
ts\_h_j_6 aU_6 r\
s\_j_1 aU_1 r\
XI.AO1.R
s\_j_2 aU_2 r\
XI.AO2.R
s\_j_3 aU_3 r\
XI.AO3.R
s\_j_4 aU_4 r\
XI.AO4.R
s\_j_5 aU_5 r\
XI.AO5.R
s\_j_6 aU_6 r\
j_1 aU_1 r\
Y.AO1.R
j_2 aU_2 r\
Y.AO2.R
j_3 aU_3 r\
Y.AO3.R
j_4 aU_4 r\
Y.AO4.R
j_5 aU_5 r\
Y.AO5.R
j_6 aU_6 r\
@_1_n r\
EN1.R
1_1 r\
IH1.R
M_1 r\
eI_1 r\
EI1.R
y_1 r\
YU1.R
n y_1 r\
NYU.YU1.R
l y_1 r\
LYU.YU1.R
ts\ y_1 r\
JU.YU1.R
ts\_h y_1 r\
QU.YU1.R
s\ y_1 r\
XU.YU1.R
j_1 y_1 r\
YU.YU1.R
i_1_n r\
IN1.R
i_1 r\
I1.R
p i_1_n r\
BI.IN1.R
p_h i_1_n r\
PI.IN1.R
m i_1_n r\
MI.IN1.R
n i_1_n r\
NI.IN1.R
l i_1_n r\
LI.IN1.R
ts\ i_1_n r\
JI.IN1.R
ts\_h i_1_n r\
QI.IN1.R
s\ i_1_n r\
XI.IN1.R
j_1 i_1_n r\
Y.IN1.R
t_w @_1_n r\
DU.UN1.R
t_h_w @_1_n r\
TU.UN1.R
l_w @_1_n r\
LU.UN1.R
k_w @_1_n r\
GU.UN1.R
k_h_w @_1_n r\
KU.UN1.R
x_w @_1_n r\
HU.UN1.R
ts_w @_1_n r\
ZU.UN1.R
ts`_w @_1_n r\
ZHU.UN1.R
ts_h_w @_1_n r\
CU.UN1.R
ts`_h_w @_1_n r\
CHU.UN1.R
s_w @_1_n r\
SU.UN1.R
s`_w @_1_n r\
SHU.UN1.R
z`_w @_1_n r\
RU.UN1.R
p i_1 r\
BI.I1.R
p_h i_1 r\
PI.I1.R
t i_1 r\
DI.I1.R
t_h i_1 r\
TI.I1.R
l i_1 r\
LI.I1.R
m i_1 r\
MI.I1.R
n i_1 r\
NI.I1.R
ts\ i_1 r\
JI.I1.R
ts\_h i_1 r\
QI.I1.R
s\ i_1 r\
XI.I1.R
j_1 i_1 r\
Y.I1.R
@_2_n r\
EN2.R
1_2 r\
IH2.R
M_2 r\
eI_2 r\
EI2.R
y_2 r\
YU2.R
n y_2 r\
NYU.YU2.R
l y_2 r\
LYU.YU2.R
ts\ y_2 r\
JU.YU2.R
ts\_h y_2 r\
QU.YU2.R
s\ y_2 r\
XU.YU2.R
j_2 y_2 r\
YU.YU2.R
i_2_n r\
IN2.R
i_2 r\
I2.R
p i_2_n r\
BI.IN2.R
p_h i_2_n r\
PI.IN2.R
m i_2_n r\
MI.IN2.R
n i_2_n r\
NI.IN2.R
l i_2_n r\
LI.IN2.R
ts\ i_2_n r\
JI.IN2.R
ts\_h i_2_n r\
QI.IN2.R
s\ i_2_n r\
XI.IN2.R
j_2 i_2_n r\
Y.IN2.R
t_w @_2_n r\
DU.UN2.R
t_h_w @_2_n r\
TU.UN2.R
l_w @_2_n r\
LU.UN2.R
k_w @_2_n r\
GU.UN2.R
k_h_w @_2_n r\
KU.UN2.R
x_w @_2_n r\
HU.UN2.R
ts_w @_2_n r\
ZU.UN2.R
ts`_w @_2_n r\
ZHU.UN2.R
ts_h_w @_2_n r\
CU.UN2.R
ts`_h_w @_2_n r\
CHU.UN2.R
s_w @_2_n r\
SU.UN2.R
s`_w @_2_n r\
SHU.UN2.R
z`_w @_2_n r\
RU.UN2.R
p i_2 r\
BI.I2.R
p_h i_2 r\
PI.I2.R
t i_2 r\
DI.I2.R
t_h i_2 r\
TI.I2.R
l i_2 r\
LI.I2.R
m i_2 r\
MI.I2.R
n i_2 r\
NI.I2.R
ts\ i_2 r\
JI.I2.R
ts\_h i_2 r\
QI.I2.R
s\ i_2 r\
XI.I2.R
j_2 i_2 r\
Y.I2.R
@_3_n r\
EN3.R
1_3 r\
IH3.R
M_3 r\
eI_3 r\
EI3.R
y_3 r\
YU3.R
n y_3 r\
NYU.YU3.R
l y_3 r\
LYU.YU3.R
ts\ y_3 r\
JU.YU3.R
ts\_h y_3 r\
QU.YU3.R
s\ y_3 r\
XU.YU3.R
j_3 y_3 r\
YU.YU3.R
i_3_n r\
IN3.R
i_3 r\
I3.R
p i_3_n r\
BI.IN3.R
p_h i_3_n r\
PI.IN3.R
m i_3_n r\
MI.IN3.R
n i_3_n r\
NI.IN3.R
l i_3_n r\
LI.IN3.R
ts\ i_3_n r\
JI.IN3.R
ts\_h i_3_n r\
QI.IN3.R
s\ i_3_n r\
XI.IN3.R
j_3 i_3_n r\
Y.IN3.R
t_w @_3_n r\
DU.UN3.R
t_h_w @_3_n r\
TU.UN3.R
l_w @_3_n r\
LU.UN3.R
k_w @_3_n r\
GU.UN3.R
k_h_w @_3_n r\
KU.UN3.R
x_w @_3_n r\
HU.UN3.R
ts_w @_3_n r\
ZU.UN3.R
ts`_w @_3_n r\
ZHU.UN3.R
ts_h_w @_3_n r\
CU.UN3.R
ts`_h_w @_3_n r\
CHU.UN3.R
s_w @_3_n r\
SU.UN3.R
s`_w @_3_n r\
SHU.UN3.R
z`_w @_3_n r\
RU.UN3.R
p i_3 r\
BI.I3.R
p_h i_3 r\
PI.I3.R
t i_3 r\
DI.I3.R
t_h i_3 r\
TI.I3.R
l i_3 r\
LI.I3.R
m i_3 r\
MI.I3.R
n i_3 r\
NI.I3.R
ts\ i_3 r\
JI.I3.R
ts\_h i_3 r\
QI.I3.R
s\ i_3 r\
XI.I3.R
j_3 i_3 r\
Y.I3.R
@_4_n r\
EN4.R
1_4 r\
IH4.R
M_4 r\
eI_4 r\
EI4.R
y_4 r\
YU4.R
n y_4 r\
NYU.YU4.R
l y_4 r\
LYU.YU4.R
ts\ y_4 r\
JU.YU4.R
ts\_h y_4 r\
QU.YU4.R
s\ y_4 r\
XU.YU4.R
j_4 y_4 r\
YU.YU4.R
i_4_n r\
IN4.R
i_4 r\
I4.R
p i_4_n r\
BI.IN4.R
p_h i_4_n r\
PI.IN4.R
m i_4_n r\
MI.IN4.R
n i_4_n r\
NI.IN4.R
l i_4_n r\
LI.IN4.R
ts\ i_4_n r\
JI.IN4.R
ts\_h i_4_n r\
QI.IN4.R
s\ i_4_n r\
XI.IN4.R
j_4 i_4_n r\
Y.IN4.R
t_w @_4_n r\
DU.UN4.R
t_h_w @_4_n r\
TU.UN4.R
l_w @_4_n r\
LU.UN4.R
k_w @_4_n r\
GU.UN4.R
k_h_w @_4_n r\
KU.UN4.R
x_w @_4_n r\
HU.UN4.R
ts_w @_4_n r\
ZU.UN4.R
ts`_w @_4_n r\
ZHU.UN4.R
ts_h_w @_4_n r\
CU.UN4.R
ts`_h_w @_4_n r\
CHU.UN4.R
s_w @_4_n r\
SU.UN4.R
s`_w @_4_n r\
SHU.UN4.R
z`_w @_4_n r\
RU.UN4.R
p i_4 r\
BI.I4.R
p_h i_4 r\
PI.I4.R
t i_4 r\
DI.I4.R
t_h i_4 r\
TI.I4.R
l i_4 r\
LI.I4.R
m i_4 r\
MI.I4.R
n i_4 r\
NI.I4.R
ts\ i_4 r\
JI.I4.R
ts\_h i_4 r\
QI.I4.R
s\ i_4 r\
XI.I4.R
j_4 i_4 r\
Y.I4.R
@_5_n r\
EN5.R
1_5 r\
IH5.R
M_5 r\
eI_5 r\
EI5.R
y_5 r\
YU5.R
n y_5 r\
NYU.YU5.R
l y_5 r\
LYU.YU5.R
ts\ y_5 r\
JU.YU5.R
ts\_h y_5 r\
QU.YU5.R
s\ y_5 r\
XU.YU5.R
j_5 y_5 r\
YU.YU5.R
i_5_n r\
IN5.R
i_5 r\
I5.R
p i_5_n r\
BI.IN5.R
p_h i_5_n r\
PI.IN5.R
m i_5_n r\
MI.IN5.R
n i_5_n r\
NI.IN5.R
l i_5_n r\
LI.IN5.R
ts\ i_5_n r\
JI.IN5.R
ts\_h i_5_n r\
QI.IN5.R
s\ i_5_n r\
XI.IN5.R
j_5 i_5_n r\
Y.IN5.R
t_w @_5_n r\
DU.UN5.R
t_h_w @_5_n r\
TU.UN5.R
l_w @_5_n r\
LU.UN5.R
k_w @_5_n r\
GU.UN5.R
k_h_w @_5_n r\
KU.UN5.R
x_w @_5_n r\
HU.UN5.R
ts_w @_5_n r\
ZU.UN5.R
ts`_w @_5_n r\
ZHU.UN5.R
ts_h_w @_5_n r\
CU.UN5.R
ts`_h_w @_5_n r\
CHU.UN5.R
s_w @_5_n r\
SU.UN5.R
s`_w @_5_n r\
SHU.UN5.R
z`_w @_5_n r\
RU.UN5.R
p i_5 r\
BI.I5.R
p_h i_5 r\
PI.I5.R
t i_5 r\
DI.I5.R
t_h i_5 r\
TI.I5.R
l i_5 r\
LI.I5.R
m i_5 r\
MI.I5.R
n i_5 r\
NI.I5.R
ts\ i_5 r\
JI.I5.R
ts\_h i_5 r\
QI.I5.R
s\ i_5 r\
XI.I5.R
j_5 i_5 r\
Y.I5.R
@_6_n r\
1_6 r\
M_6 r\
eI_6 r\
y_6 r\
n y_6 r\
l y_6 r\
ts\ y_6 r\
ts\_h y_6 r\
s\ y_6 r\
j_6 y_6 r\
i_6_n r\
i_6 r\
p i_6_n r\
p_h i_6_n r\
m i_6_n r\
n i_6_n r\
l i_6_n r\
ts\ i_6_n r\
ts\_h i_6_n r\
s\ i_6_n r\
j_6 i_6_n r\
t_w @_6_n r\
t_h_w @_6_n r\
l_w @_6_n r\
k_w @_6_n r\
k_h_w @_6_n r\
x_w @_6_n r\
ts_w @_6_n r\
ts`_w @_6_n r\
ts_h_w @_6_n r\
ts`_h_w @_6_n r\
s_w @_6_n r\
s`_w @_6_n r\
z`_w @_6_n r\
p i_6 r\
p_h i_6 r\
t i_6 r\
t_h i_6 r\
l i_6 r\
m i_6 r\
n i_6 r\
ts\ i_6 r\
ts\_h i_6 r\
s\ i_6 r\
j_6 i_6 r\
O_1 r\
O1.R
O_2 r\
O2.R
O_3 r\
O3.R
O_4 r\
O4.R
O_5 r\
O5.R
O_6 r\
p O_1 r\
BU.O1.R
p O_2 r\
BU.O2.R
p O_3 r\
BU.O3.R
p O_4 r\
BU.O4.R
p O_5 r\
BU.O5.R
p O_6 r\
oU_1 r\
OU1.R
oU_2 r\
OU2.R
oU_3 r\
OU3.R
oU_4 r\
OU4.R
oU_5 r\
OU5.R
oU_6 r\
t_j_1 oU_1 r\
DI.OU1.R
t_j_2 oU_2 r\
DI.OU2.R
t_j_3 oU_3 r\
DI.OU3.R
t_j_4 oU_4 r\
DI.OU4.R
t_j_5 oU_5 r\
DI.OU5.R
t_j_6 oU_6 r\
l_j_1 oU_1 r\
LI.OU1.R
l_j_2 oU_2 r\
LI.OU2.R
l_j_3 oU_3 r\
LI.OU3.R
l_j_4 oU_4 r\
LI.OU4.R
l_j_5 oU_5 r\
LI.OU5.R
l_j_6 oU_6 r\
m_j_1 oU_1 r\
MI.OU1.R
m_j_2 oU_2 r\
MI.OU2.R
m_j_3 oU_3 r\
MI.OU3.R
m_j_4 oU_4 r\
MI.OU4.R
m_j_5 oU_5 r\
MI.OU5.R
m_j_6 oU_6 r\
n_j_1 oU_1 r\
NI.OU1.R
n_j_2 oU_2 r\
NI.OU2.R
n_j_3 oU_3 r\
NI.OU3.R
n_j_4 oU_4 r\
NI.OU4.R
n_j_5 oU_5 r\
NI.OU5.R
n_j_6 oU_6 r\
ts\_j_1 oU_1 r\
JI.OU1.R
ts\_j_2 oU_2 r\
JI.OU2.R
ts\_j_3 oU_3 r\
JI.OU3.R
ts\_j_4 oU_4 r\
JI.OU4.R
ts\_j_5 oU_5 r\
JI.OU5.R
ts\_j_6 oU_6 r\
ts\_h_j_1 oU_1 r\
QI.OU1.R
ts\_h_j_2 oU_2 r\
QI.OU2.R
ts\_h_j_3 oU_3 r\
QI.OU3.R
ts\_h_j_4 oU_4 r\
QI.OU4.R
ts\_h_j_5 oU_5 r\
QI.OU5.R
ts\_h_j_6 oU_6 r\
s\_j_1 oU_1 r\
XI.OU1.R
s\_j_2 oU_2 r\
XI.OU2.R
s\_j_3 oU_3 r\
XI.OU3.R
s\_j_4 oU_4 r\
XI.OU4.R
s\_j_5 oU_5 r\
XI.OU5.R
s\_j_6 oU_6 r\
j_1 oU_1 r\
Y.OU1.R
j_2 oU_2 r\
Y.OU2.R
j_3 oU_3 r\
Y.OU3.R
j_4 oU_4 r\
Y.OU4.R
j_5 oU_5 r\
Y.OU5.R
j_6 oU_6 r\
i_1_N r\
IG1.R
i_2_N r\
IG2.R
i_3_N r\
IG3.R
i_4_N r\
IG4.R
i_5_N r\
IG5.R
i_6_N r\
p i_1_N r\
BI.IG1.R
p i_2_N r\
BI.IG2.R
p i_3_N r\
BI.IG3.R
p i_4_N r\
BI.IG4.R
p i_5_N r\
BI.IG5.R
p i_6_N r\
p_h i_1_N r\
PI.IG1.R
p_h i_2_N r\
PI.IG2.R
p_h i_3_N r\
PI.IG3.R
p_h i_4_N r\
PI.IG4.R
p_h i_5_N r\
PI.IG5.R
p_h i_6_N r\
t i_1_N r\
DI.IG1.R
t i_2_N r\
DI.IG2.R
t i_3_N r\
DI.IG3.R
t i_4_N r\
DI.IG4.R
t i_5_N r\
DI.IG5.R
t i_6_N r\
t_h i_1_N r\
TI.IG1.R
t_h i_2_N r\
TI.IG2.R
t_h i_3_N r\
TI.IG3.R
t_h i_4_N r\
TI.IG4.R
t_h i_5_N r\
TI.IG5.R
t_h i_6_N r\
l i_1_N r\
LI.IG1.R
l i_2_N r\
LI.IG2.R
l i_3_N r\
LI.IG3.R
l i_4_N r\
LI.IG4.R
l i_5_N r\
LI.IG5.R
l i_6_N r\
m i_1_N r\
MI.IG1.R
m i_2_N r\
MI.IG2.R
m i_3_N r\
MI.IG3.R
m i_4_N r\
MI.IG4.R
m i_5_N r\
MI.IG5.R
m i_6_N r\
n i_1_N r\
NI.IG1.R
n i_2_N r\
NI.IG2.R
n i_3_N r\
NI.IG3.R
n i_4_N r\
NI.IG4.R
n i_5_N r\
NI.IG5.R
n i_6_N r\
ts\ i_1_N r\
JI.IG1.R
ts\ i_2_N r\
JI.IG2.R
ts\ i_3_N r\
JI.IG3.R
ts\ i_4_N r\
JI.IG4.R
ts\ i_5_N r\
JI.IG5.R
ts\ i_6_N r\
ts\_h i_1_N r\
QI.IG1.R
ts\_h i_2_N r\
QI.IG2.R
ts\_h i_3_N r\
QI.IG3.R
ts\_h i_4_N r\
QI.IG4.R
ts\_h i_5_N r\
QI.IG5.R
ts\_h i_6_N r\
s\ i_1_N r\
XI.IG1.R
s\ i_2_N r\
XI.IG2.R
s\ i_3_N r\
XI.IG3.R
s\ i_4_N r\
XI.IG4.R
s\ i_5_N r\
XI.IG5.R
s\ i_6_N r\
j_1 i_1_N r\
Y.IG1.R
j_2 i_2_N r\
Y.IG2.R
j_3 i_3_N r\
Y.IG3.R
j_4 i_4_N r\
Y.IG4.R
j_5 i_5_N r\
Y.IG5.R
j_6 i_6_N r\
@_1_N r\
EG1.R
@_2_N r\
EG2.R
@_3_N r\
EG3.R
@_4_N r\
EG4.R
@_5_N r\
EG5.R
@_6_N r\
u_1 r\
U1.R
u_2 r\
U2.R
u_3 r\
U3.R
u_4 r\
U4.R
u_5 r\
U5.R
u_6 r\
p u_1 r\
BU.U1.R
p u_2 r\
BU.U2.R
p u_3 r\
BU.U3.R
p u_4 r\
BU.U4.R
p u_5 r\
BU.U5.R
p u_6 r\
t u_1 r\
DU.U1.R
t u_2 r\
DU.U2.R
t u_3 r\
DU.U3.R
t u_4 r\
DU.U4.R
t u_5 r\
DU.U5.R
t u_6 r\
t_h u_1 r\
TU.U1.R
t_h u_2 r\
TU.U2.R
t_h u_3 r\
TU.U3.R
t_h u_4 r\
TU.U4.R
t_h u_5 r\
TU.U5.R
t_h u_6 r\
l u_1 r\
LU.U1.R
l u_2 r\
LU.U2.R
l u_3 r\
LU.U3.R
l u_4 r\
LU.U4.R
l u_5 r\
LU.U5.R
l u_6 r\
m u_1 r\
MU.U1.R
m u_2 r\
MU.U2.R
m u_3 r\
MU.U3.R
m u_4 r\
MU.U4.R
m u_5 r\
MU.U5.R
m u_6 r\
n u_1 r\
NU.U1.R
n u_2 r\
NU.U2.R
n u_3 r\
NU.U3.R
n u_4 r\
NU.U4.R
n u_5 r\
NU.U5.R
n u_6 r\
k u_1 r\
GU.U1.R
k u_2 r\
GU.U2.R
k u_3 r\
GU.U3.R
k u_4 r\
GU.U4.R
k u_5 r\
GU.U5.R
k u_6 r\
k_h u_1 r\
KU.U1.R
k_h u_2 r\
KU.U2.R
k_h u_3 r\
KU.U3.R
k_h u_4 r\
KU.U4.R
k_h u_5 r\
KU.U5.R
k_h u_6 r\
x u_1 r\
HU.U1.R
x u_2 r\
HU.U2.R
x u_3 r\
HU.U3.R
x u_4 r\
HU.U4.R
x u_5 r\
HU.U5.R
x u_6 r\
ts u_1 r\
ZU.U1.R
ts u_2 r\
ZU.U2.R
ts u_3 r\
ZU.U3.R
ts u_4 r\
ZU.U4.R
ts u_5 r\
ZU.U5.R
ts u_6 r\
ts_h u_1 r\
CU.U1.R
ts_h u_2 r\
CU.U2.R
ts_h u_3 r\
CU.U3.R
ts_h u_4 r\
CU.U4.R
ts_h u_5 r\
CU.U5.R
ts_h u_6 r\
s u_1 r\
SU.U1.R
s u_2 r\
SU.U2.R
s u_3 r\
SU.U3.R
s u_4 r\
SU.U4.R
s u_5 r\
SU.U5.R
s u_6 r\
ts` u_1 r\
ZHU.U1.R
ts` u_2 r\
ZHU.U2.R
ts` u_3 r\
ZHU.U3.R
ts` u_4 r\
ZHU.U4.R
ts` u_5 r\
ZHU.U5.R
ts` u_6 r\
ts`_h u_1 r\
CHU.U1.R
ts`_h u_2 r\
CHU.U2.R
ts`_h u_3 r\
CHU.U3.R
ts`_h u_4 r\
CHU.U4.R
ts`_h u_5 r\
CHU.U5.R
ts`_h u_6 r\
s` u_1 r\
SHU.U1.R
s` u_2 r\
SHU.U2.R
s` u_3 r\
SHU.U3.R
s` u_4 r\
SHU.U4.R
s` u_5 r\
SHU.U5.R
s` u_6 r\
z` u_1 r\
RU.U1.R
z` u_2 r\
RU.U2.R
z` u_3 r\
RU.U3.R
z` u_4 r\
RU.U4.R
z` u_5 r\
RU.U5.R
z` u_6 r\
7_1 r\
E1.R
7_2 r\
E2.R
7_3 r\
E3.R
7_4 r\
E4.R
7_5 r\
E5.R
7_6 r\
A_1_N r\
AG1.R
A_2_N r\
AG2.R
A_3_N r\
AG3.R
A_4_N r\
AG4.R
A_5_N r\
AG5.R
A_6_N r\
ts\_j_1 A_1_N r\
JI.AG1.R
ts\_j_2 A_2_N r\
JI.AG2.R
ts\_j_3 A_3_N r\
JI.AG3.R
ts\_j_4 A_4_N r\
JI.AG4.R
ts\_j_5 A_5_N r\
JI.AG5.R
ts\_j_6 A_6_N r\
l_j_1 A_1_N r\
LI.AG1.R
l_j_2 A_2_N r\
LI.AG2.R
l_j_3 A_3_N r\
LI.AG3.R
l_j_4 A_4_N r\
LI.AG4.R
l_j_5 A_5_N r\
LI.AG5.R
l_j_6 A_6_N r\
n_j_1 A_1_N r\
NI.AG1.R
n_j_2 A_2_N r\
NI.AG2.R
n_j_3 A_3_N r\
NI.AG3.R
n_j_4 A_4_N r\
NI.AG4.R
n_j_5 A_5_N r\
NI.AG5.R
n_j_6 A_6_N r\
ts\_h_j_1 A_1_N r\
QI.AG1.R
ts\_h_j_2 A_2_N r\
QI.AG2.R
ts\_h_j_3 A_3_N r\
QI.AG3.R
ts\_h_j_4 A_4_N r\
QI.AG4.R
ts\_h_j_5 A_5_N r\
QI.AG5.R
ts\_h_j_6 A_6_N r\
s\_j_1 A_1_N r\
XI.AG1.R
s\_j_2 A_2_N r\
XI.AG2.R
s\_j_3 A_3_N r\
XI.AG3.R
s\_j_4 A_4_N r\
XI.AG4.R
s\_j_5 A_5_N r\
XI.AG5.R
s\_j_6 A_6_N r\
j_1 A_1_N r\
Y.AG1.R
j_2 A_2_N r\
Y.AG2.R
j_3 A_3_N r\
Y.AG3.R
j_4 A_4_N r\
Y.AG4.R
j_5 A_5_N r\
Y.AG5.R
j_6 A_6_N r\
o_1_N r\
OG1.R
o_2_N r\
OG2.R
o_3_N r\
OG3.R
o_4_N r\
OG4.R
o_5_N r\
OG5.R
o_6_N r\
ts`_h o_1_N r\
CHU.OG1.R
ts`_h o_2_N r\
CHU.OG2.R
ts`_h o_3_N r\
CHU.OG3.R
ts`_h o_4_N r\
CHU.OG4.R
ts`_h o_5_N r\
CHU.OG5.R
ts`_h o_6_N r\
ts_h o_1_N r\
CU.OG1.R
ts_h o_2_N r\
CU.OG2.R
ts_h o_3_N r\
CU.OG3.R
ts_h o_4_N r\
CU.OG4.R
ts_h o_5_N r\
CU.OG5.R
ts_h o_6_N r\
t o_1_N r\
DU.OG1.R
t o_2_N r\
DU.OG2.R
t o_3_N r\
DU.OG3.R
t o_4_N r\
DU.OG4.R
t o_5_N r\
DU.OG5.R
t o_6_N r\
k o_1_N r\
GU.OG1.R
k o_2_N r\
GU.OG2.R
k o_3_N r\
GU.OG3.R
k o_4_N r\
GU.OG4.R
k o_5_N r\
GU.OG5.R
k o_6_N r\
x o_1_N r\
HU.OG1.R
x o_2_N r\
HU.OG2.R
x o_3_N r\
HU.OG3.R
x o_4_N r\
HU.OG4.R
x o_5_N r\
HU.OG5.R
x o_6_N r\
ts\_j_1 o_1_N r\
JI.OG1.R
ts\_j_2 o_2_N r\
JI.OG2.R
ts\_j_3 o_3_N r\
JI.OG3.R
ts\_j_4 o_4_N r\
JI.OG4.R
ts\_j_5 o_5_N r\
JI.OG5.R
ts\_j_6 o_6_N r\
k_h o_1_N r\
KU.OG1.R
k_h o_2_N r\
KU.OG2.R
k_h o_3_N r\
KU.OG3.R
k_h o_4_N r\
KU.OG4.R
k_h o_5_N r\
KU.OG5.R
k_h o_6_N r\
l o_1_N r\
LU.OG1.R
l o_2_N r\
LU.OG2.R
l o_3_N r\
LU.OG3.R
l o_4_N r\
LU.OG4.R
l o_5_N r\
LU.OG5.R
l o_6_N r\
n o_1_N r\
NU.OG1.R
n o_2_N r\
NU.OG2.R
n o_3_N r\
NU.OG3.R
n o_4_N r\
NU.OG4.R
n o_5_N r\
NU.OG5.R
n o_6_N r\
ts\_h_j_1 o_1_N r\
QI.OG1.R
ts\_h_j_2 o_2_N r\
QI.OG2.R
ts\_h_j_3 o_3_N r\
QI.OG3.R
ts\_h_j_4 o_4_N r\
QI.OG4.R
ts\_h_j_5 o_5_N r\
QI.OG5.R
ts\_h_j_6 o_6_N r\
s o_1_N r\
SU.OG1.R
s o_2_N r\
SU.OG2.R
s o_3_N r\
SU.OG3.R
s o_4_N r\
SU.OG4.R
s o_5_N r\
SU.OG5.R
s o_6_N r\
t_h o_1_N r\
TU.OG1.R
t_h o_2_N r\
TU.OG2.R
t_h o_3_N r\
TU.OG3.R
t_h o_4_N r\
TU.OG4.R
t_h o_5_N r\
TU.OG5.R
t_h o_6_N r\
s\_j_1 o_1_N r\
XI.OG1.R
s\_j_2 o_2_N r\
XI.OG2.R
s\_j_3 o_3_N r\
XI.OG3.R
s\_j_4 o_4_N r\
XI.OG4.R
s\_j_5 o_5_N r\
XI.OG5.R
s\_j_6 o_6_N r\
j_1 o_1_N r\
Y.OG1.R
j_2 o_2_N r\
Y.OG2.R
j_3 o_3_N r\
Y.OG3.R
j_4 o_4_N r\
Y.OG4.R
j_5 o_5_N r\
Y.OG5.R
j_6 o_6_N r\
ts` o_1_N r\
ZHU.OG1.R
ts` o_2_N r\
ZHU.OG2.R
ts` o_3_N r\
ZHU.OG3.R
ts` o_4_N r\
ZHU.OG4.R
ts` o_5_N r\
ZHU.OG5.R
ts` o_6_N r\
ts o_1_N r\
ZU.OG1.R
ts o_2_N r\
ZU.OG2.R
ts o_3_N r\
ZU.OG3.R
ts o_4_N r\
ZU.OG4.R
ts o_5_N r\
ZU.OG5.R
ts o_6_N r\
E_1 r\
IE1.R
E_2 r\
IE2.R
E_3 r\
IE3.R
E_4 r\
IE4.R
E_5 r\
IE5.R
E_6 r\
p_j_1 E_1 r\
BI.IE1.R
p_j_2 E_2 r\
BI.IE2.R
p_j_3 E_3 r\
BI.IE3.R
p_j_4 E_4 r\
BI.IE4.R
p_j_5 E_5 r\
BI.IE5.R
p_j_6 E_6 r\
t_j_1 E_1 r\
DI.IE1.R
t_j_2 E_2 r\
DI.IE2.R
t_j_3 E_3 r\
DI.IE3.R
t_j_4 E_4 r\
DI.IE4.R
t_j_5 E_5 r\
DI.IE5.R
t_j_6 E_6 r\
ts\_j_1 E_1 r\
JI.IE1.R
ts\_j_2 E_2 r\
JI.IE2.R
ts\_j_3 E_3 r\
JI.IE3.R
ts\_j_4 E_4 r\
JI.IE4.R
ts\_j_5 E_5 r\
JI.IE5.R
ts\_j_6 E_6 r\
ts\_H_1 E_1 r\
JU.IE1.R
ts\_H_2 E_2 r\
JU.IE2.R
ts\_H_3 E_3 r\
JU.IE3.R
ts\_H_4 E_4 r\
JU.IE4.R
ts\_H_5 E_5 r\
JU.IE5.R
ts\_H_6 E_6 r\
l_j_1 E_1 r\
LI.IE1.R
l_j_2 E_2 r\
LI.IE2.R
l_j_3 E_3 r\
LI.IE3.R
l_j_4 E_4 r\
LI.IE4.R
l_j_5 E_5 r\
LI.IE5.R
l_j_6 E_6 r\
l_H_1 E_1 r\
LYU.IE1.R
l_H_2 E_2 r\
LYU.IE2.R
l_H_3 E_3 r\
LYU.IE3.R
l_H_4 E_4 r\
LYU.IE4.R
l_H_5 E_5 r\
LYU.IE5.R
l_H_6 E_6 r\
m_j_1 E_1 r\
MI.IE1.R
m_j_2 E_2 r\
MI.IE2.R
m_j_3 E_3 r\
MI.IE3.R
m_j_4 E_4 r\
MI.IE4.R
m_j_5 E_5 r\
MI.IE5.R
m_j_6 E_6 r\
n_j_1 E_1 r\
NI.IE1.R
n_j_2 E_2 r\
NI.IE2.R
n_j_3 E_3 r\
NI.IE3.R
n_j_4 E_4 r\
NI.IE4.R
n_j_5 E_5 r\
NI.IE5.R
n_j_6 E_6 r\
n_H_1 E_1 r\
NYU.IE1.R
n_H_2 E_2 r\
NYU.IE2.R
n_H_3 E_3 r\
NYU.IE3.R
n_H_4 E_4 r\
NYU.IE4.R
n_H_5 E_5 r\
NYU.IE5.R
n_H_6 E_6 r\
p_h_j_1 E_1 r\
PI.IE1.R
p_h_j_2 E_2 r\
PI.IE2.R
p_h_j_3 E_3 r\
PI.IE3.R
p_h_j_4 E_4 r\
PI.IE4.R
p_h_j_5 E_5 r\
PI.IE5.R
p_h_j_6 E_6 r\
ts\_h_j_1 E_1 r\
QI.IE1.R
ts\_h_j_2 E_2 r\
QI.IE2.R
ts\_h_j_3 E_3 r\
QI.IE3.R
ts\_h_j_4 E_4 r\
QI.IE4.R
ts\_h_j_5 E_5 r\
QI.IE5.R
ts\_h_j_6 E_6 r\
ts\_h_H_1 E_1 r\
QU.IE1.R
ts\_h_H_2 E_2 r\
QU.IE2.R
ts\_h_H_3 E_3 r\
QU.IE3.R
ts\_h_H_4 E_4 r\
QU.IE4.R
ts\_h_H_5 E_5 r\
QU.IE5.R
ts\_h_H_6 E_6 r\
t_h_j_1 E_1 r\
TI.IE1.R
t_h_j_2 E_2 r\
TI.IE2.R
t_h_j_3 E_3 r\
TI.IE3.R
t_h_j_4 E_4 r\
TI.IE4.R
t_h_j_5 E_5 r\
TI.IE5.R
t_h_j_6 E_6 r\
s\_j_1 E_1 r\
XI.IE1.R
s\_j_2 E_2 r\
XI.IE2.R
s\_j_3 E_3 r\
XI.IE3.R
s\_j_4 E_4 r\
XI.IE4.R
s\_j_5 E_5 r\
XI.IE5.R
s\_j_6 E_6 r\
s\_H_1 E_1 r\
XU.IE1.R
s\_H_2 E_2 r\
XU.IE2.R
s\_H_3 E_3 r\
XU.IE3.R
s\_H_4 E_4 r\
XU.IE4.R
s\_H_5 E_5 r\
XU.IE5.R
s\_H_6 E_6 r\
j_1 E_1 r\
Y.IE1.R
j_2 E_2 r\
Y.IE2.R
j_3 E_3 r\
Y.IE3.R
j_4 E_4 r\
Y.IE4.R
j_5 E_5 r\
Y.IE5.R
j_6 E_6 r\
j_H_1 E_1 r\
YU.IE1.R
j_H_2 E_2 r\
YU.IE2.R
j_H_3 E_3 r\
YU.IE3.R
j_H_4 E_4 r\
YU.IE4.R
j_H_5 E_5 r\
YU.IE5.R
j_H_6 E_6 r\
n a_1
N.A1
n a_2
N.A2
n a_3
N.A3
n a_4
N.A4
n a_5
N.A5
n a_6
n 7_1
N.E1
n 7_2
N.E2
n 7_3
N.E3
n 7_4
N.E4
n 7_5
N.E5
n 7_6
n aI_1
N.AI1
n aI_2
N.AI2
n aI_3
N.AI3
n aI_4
N.AI4
n aI_5
N.AI5
n aI_6
n eI_1
N.EI1
n eI_2
N.EI2
n eI_3
N.EI3
n eI_4
N.EI4
n eI_5
N.EI5
n eI_6
n aU_1
N.AO1
n aU_2
N.AO2
n aU_3
N.AO3
n aU_4
N.AO4
n aU_5
N.AO5
n aU_6
n oU_1
N.OU1
n oU_2
N.OU2
n oU_3
N.OU3
n oU_4
N.OU4
n oU_5
N.OU5
n oU_6
n a_1_n
N.AN1
n a_2_n
N.AN2
n a_3_n
N.AN3
n a_4_n
N.AN4
n a_5_n
N.AN5
n a_6_n
n @_1_n
N.EN1
n @_2_n
N.EN2
n @_3_n
N.EN3
n @_4_n
N.EN4
n @_5_n
N.EN5
n @_6_n
n A_1_N
N.AG1
n A_2_N
N.AG2
n A_3_N
N.AG3
n A_4_N
N.AG4
n A_5_N
N.AG5
n A_6_N
n @_1_N
N.EG1
n @_2_N
N.EG2
n @_3_N
N.EG3
n @_4_N
N.EG4
n @_5_N
N.EG5
n @_6_N
n_w O_1
NU.O1
n_w O_2
NU.O2
n_w O_3
NU.O3
n_w O_4
NU.O4
n_w O_5
NU.O5
n_w O_6
n_w a_1_n
NU.AN1
n_w a_2_n
NU.AN2
n_w a_3_n
NU.AN3
n_w a_4_n
NU.AN4
n_w a_5_n
NU.AN5
n_w a_6_n
n a_1 r\
N.A1.R
n a_2 r\
N.A2.R
n a_3 r\
N.A3.R
n a_4 r\
N.A4.R
n a_5 r\
N.A5.R
n a_6 r\
n 7_1 r\
N.E1.R
n 7_2 r\
N.E2.R
n 7_3 r\
N.E3.R
n 7_4 r\
N.E4.R
n 7_5 r\
N.E5.R
n 7_6 r\
n aI_1 r\
N.AI1.R
n aI_2 r\
N.AI2.R
n aI_3 r\
N.AI3.R
n aI_4 r\
N.AI4.R
n aI_5 r\
N.AI5.R
n aI_6 r\
n eI_1 r\
N.EI1.R
n eI_2 r\
N.EI2.R
n eI_3 r\
N.EI3.R
n eI_4 r\
N.EI4.R
n eI_5 r\
N.EI5.R
n eI_6 r\
n aU_1 r\
N.AO1.R
n aU_2 r\
N.AO2.R
n aU_3 r\
N.AO3.R
n aU_4 r\
N.AO4.R
n aU_5 r\
N.AO5.R
n aU_6 r\
n oU_1 r\
N.OU1.R
n oU_2 r\
N.OU2.R
n oU_3 r\
N.OU3.R
n oU_4 r\
N.OU4.R
n oU_5 r\
N.OU5.R
n oU_6 r\
n a_1_n r\
N.AN1.R
n a_2_n r\
N.AN2.R
n a_3_n r\
N.AN3.R
n a_4_n r\
N.AN4.R
n a_5_n r\
N.AN5.R
n a_6_n r\
n @_1_n r\
N.EN1.R
n @_2_n r\
N.EN2.R
n @_3_n r\
N.EN3.R
n @_4_n r\
N.EN4.R
n @_5_n r\
N.EN5.R
n @_6_n r\
n A_1_N r\
N.AG1.R
n A_2_N r\
N.AG2.R
n A_3_N r\
N.AG3.R
n A_4_N r\
N.AG4.R
n A_5_N r\
N.AG5.R
n A_6_N r\
n @_1_N r\
N.EG1.R
n @_2_N r\
N.EG2.R
n @_3_N r\
N.EG3.R
n @_4_N r\
N.EG4.R
n @_5_N r\
N.EG5.R
n @_6_N r\
n_w O_1 r\
NU.O1.R
n_w O_2 r\
NU.O2.R
n_w O_3 r\
NU.O3.R
n_w O_4 r\
NU.O4.R
n_w O_5 r\
NU.O5.R
n_w O_6 r\
n_w a_1_n r\
NU.AN1.R
n_w a_2_n r\
NU.AN2.R
n_w a_3_n r\
NU.AN3.R
n_w a_4_n r\
NU.AN4.R
n_w a_5_n r\
NU.AN5.R
n_w a_6_n r\
ProcessingGraph: Unknown blocktype '
', did you forget to call 'registerBlockType'?
graph-output
graph-input
Block ID allready exist: 
Missing (or empty) block-type for block ID: 
Creating graph connection: 
Unknown block identifier in 'receives-from': 
No config block allowed for '
updateConfiguration called for nonexisting block id: 
receive-from
Invalid connection syntax in: 
Block has no outgoing connections: 
' can have no outgoing connections
Block has no incomming connections: 
' can have no incomming connections
 graph connectivity error(s)
Block name lookup not supported for this graph type!
Multiple inputs not supported for (legacy) block config format
Invalid block index: 
merge-style
type of merge performed
PDecTranslatorBlock
mt model file name
maximum number of active beams in pruning
as-beam
as_beam pruning value
rs-beam
rs_beam pruning value
confidence-threshold
confidence threshold
lm-model-file
path to language model file
lm-weight
language model weight
veto-factor
MT defcoding veto factor
veto-factor-exclude-input-tags
MT decoding, exclude input tags in  veto factor computation
veto-factor-num-external-input-tags
MT decoding, num externally provided tags to exclude for veto factor
norm-costs
normalize costs in mt decoding? (backward compatible version)
norm-mode
normalize costs in mt decoding? (off|length|gnmt)
norm-alpha
normalization alpha parameter
norm-sigma
normalization sigma parameter
unk-replace
max-seq-length
maximum decoding sequence length
max-seq-length-relative
maximum decoding sequence length as factor of input length
max-seq-length-floor
maximum decoding sequence length floor (used with input length factor)
lm-mode
lm mode
confidence model file
stop-mode
stop mode in mt decoding (nbeam|best|finished_score)
block-control
flow control for block sequence (<empty>|optional|optional_stop_on_success)
shortlist-lang-pair
language pair used for shortlist
shortlist-cond-n
top n in condition table used for shortlist
shortlist-freq-n
top n in freq words used for shortlist
nbest
maximum entries in nbest list to produce (default to same as 'beam'}
stop-mode-finished-score-beam
number of finished hypotheses considered for finished score stop mode (default: 1)
stream-buffer-n
stream decoding initial read length (effective read buffer)
stream-block-m
stream decoding read/write length (block size for looped read/write calls)
stream-stabilize
stabilize partial stream decoding results after each read/write block
partial-input-override
optional override parameter block to change parameter settings for partial-input processing
timing-meta-info
include decoder timing information in meta info json
model-type
kaldi
translation model type (kaldi/espresso)
use memory map
phrase-book-mode
phrase book mode
pron-guide-model-file
pron guide model file
pron-guide-preprocessing
pron guide preprocessing (splitting into characters and <space> insertion)
romanizer
phrasebook-case-sensitve
case sensitive phrase book?
filter-list-file
filter list file
pb-file-list
phrase book file list
maximum entries in nbest list to produce
reset-meta-info
reset metaInfo json
source-locale
source locale
target-locale
target locale
source-token
source tag for multilingual model
target-token
target tag for multilingual model
share-translation-model
share translation model
use-sentencepiece-ids
use sentencepiece ids directly, drop dictionaries
PDecPhraseBookBlock
filter-redundant-tags
flag on whether to filter out or keep hypotheses with redundant tags
tag-to-meta-json-file
a json file that contains a mapping between tags and their corresponding string in the meta info 
AlignmentProcessorBlock
source
segmentor-encode
pdec-decode
segmentor-decode
tokenized
word-level-alignments
If set to true, then the BPE level alignments are merged into word level alignments
avoid-crossing-words
If set to True, then the Alignment Processor Block expects the tokenized translations and the alignment ranges do not cross the tokenized words
use-stripped-token-text
If set to true, the whitespace stripped surface token representation is used instead of the internal representation.
DoNotTranslateBlock
target
AmbiguityAnnotatorBlock
disambiguation-dictionary-file
disambiguation dictionary file
max-match-length
maximum token sequence length in matching
prefer-position
prefer early match position over multiword matches
prefer-multiword
prefer longer multiword matches to shorter ones
multisense-keep
number of senses to keep when several senses match a word in a hypotheses
strip-gender
keep 'gender' in the metainfo (false), or remove it (true)
case-sensitive
used to disable phrase book block
filter-entries
filter to make translations unique
normalization-pattern-file
apply regular expressions from file for normalized lookup
normalize-on-load
apply normalization (lowercaseing/regex) to phrasebook keys on load
SimpleTokenizerBlock
tokenizer-file
tokenizer regular expression replacement (sed / perl -p style)
PhraseBookBlock
InputHammerBlock
strip-token
strip tokenizer artefacts on romanizer input
memory map pronounciator model
share-pron-guide-model
share model instance with other identical blocks
SentencePieceBlock
sentence-piece-file
sentence piece model file
action
encode
action to perform (encode/decode/decode-api)
src-locale
the source locale
tgt-locale
the target locale
features
list of features
src-ovs-file
the source OVS file
tgt-ovs-file
the target OVS file
fertility-file
the fertility file
min-trans-len-percent
the minimum translation length (in percent of expected length)
max-trans-len-percent
the maximum translation length (in percent of expected length)
regex-file
the regular expression file
PDecForceAlignBlock
maximum entries in target nbest list to process
include-eos
include the score for the EOS symbol
score-only
force decode only, without alignment
FilterBlock
locale-validation
check source locale is compatible with metainfo locale
maximum nbest list size (default: don't limit nbest size)
annotation-based-filtering
filter based on annotation in the metainfo
SelectBlock
control
value
match-key
metadata key to match on
match-pattern
metadata value match pattern
match-wildcard
wildcard string for match-pattern, that can match any subtree
locale
locale for case mapping (if not set use locale independent mapping)
capitalize-camel-case
Capitalize camel-case first tokens
exception-file
Path to file with additional exceptions that should not be capitalized
GenderVerifierBlock
inflections-file
inflection list for gendered words.
locale to use for tokenization.
PlaceholderBlock
enable
output placeholders in the target
placeholder-tag
<-->
placeholder tag
placeholder-size
placeholder size in the UI
max-placeholders
limit on the number of placeholders
separator
string for separating nbest entries
use-meta-info
should meta info be dumped
meta-separator
string for separating output string from meta data
limit dumping to this many entries from nbest list (0 = do not limit)
TokenizerBlock
output-tokens
control if tokenization affects the translation tokens or just meta info.
locale for tokenization (if not set use locale independent mapping)
.dict
Phrasebook file type unknown
DatabasePhraseBook
disable
cost
norm_cost
status
phrasebook_exact
1000
 1000
word confidences
sentence confidence
low confidence
deep copy constructor not implemented in the case of vectorized_weights.
<ParamStddev>
<LearnRateCoef>
<RandomSeed>
<InitTransformType>
<GradientNormType>
<MaxGrad>
 (ParamStddev|LearnRateCoef|InitTransformType|RandomSeed|GradientNormType|MaxGrad)
Linearity().NumRows() == mat.NumRows() && Linearity().NumCols() == mat.NumCols()
unrecognized config token 
 linearity
  linearity_grad
, lr-coef 
Unexpected mismatch in indexes: 
Unimplemented except for BaseFloat weights
Weights are already vectorized
Performing  vectorization of linear component
veccorrs->size() == linearity_corr_.size()
LinearityCorr(ic).NumRows() * LinearityCorr(ic).NumCols() == NumParams()
Done  vectorization of linear component
the multi batch gradient quantization does not work yet
Wrong quantizer type (neither 
 ): 
Insufficient storage area: 
 needed: 
(end) <= (Bits())
/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/libquasar/libkaldi/tools/openfst/src/extensions/ngram/bitmap-index.cc
You cannot call FinalizeDecoding() and then call 
GetRawLattice() with use_final_probs == false
GetRawLattice: no tokens active on frame 
: not producing lattice.
init:
 buckets:
 load:
 max:
No tokens alive [doing pruning].. warning first time only for each utterance
Negative extra_cost: 
No tokens alive at end of file
No tokens alive [doing pruning]
PruneActiveTokens: pruned tokens from 
pruned tokens from 
Error, no surviving tokens: frame is 
using RNN style LM in the decoder
v != nullptr
capacity_ > 0
am-scale
Scaling factor for acoustic likelihoods
nbest-size
number of NBest from 1st pass used for interpolation weight estimation
nnlm-nce-norm-factor-list
the normalization factor for NCE trained NNLMs, use comma to separate multiple ones
rnnlm-max-context-size
maximal context for RNN style LM, no-op for other style of LMs
big-g-fst-file-list
list of BigGrammar FST filename, use comma to separate multiple ones
big-g-nnet-file-list
list of BigGrammar NNLM filename, use comma to separate multiple ones
nnet-map-file-ext
the file extension name of the corresponding NNLM word map file
Map FST/NNLM models into memory (requires aligned models)
lattice-beam
the lattice beam for the rescored lattice
wordmap
Could not read the NNLM normalization factor info
the number of NNLM files and the number of NNLM norm factors do not match
rescoreScaled
Skip rescoring: inputArcs=
Rescoring ok=
 outputArcs=
The rescoring LM interpolation weights:
rescored
Rescoring with 
 symbol(s) for left context from 
 word(s)
Total LM cost after rescoring = 
Placeholder 
 not in geo-config 
region-dependent-variable-list
 for template 
'%c'
[character %d]
dynamic_cast<CEInferenceNet* const>(extra_nnet_) != nullptr
Backed by either TensorFlow or Espresso.
the NCE normalization factor is 
HIT vs MISS: 
lm-score 
, penultimate cache 
Compile with USE_TENSORFLOW=ON to use TensorFlow models
Compile with USE_TORCH=ON to use Torch models
No ComputeEngineConfigItf for model file: 
.espresso/code.nitroir
.pt|.zip
recognizers
Found missing recognizer request handlers.
Initialized SyncSpeechRecognizer with config 
decodables.
frontends.
SyncSpeechRecognizer not initialized
opts_.max_steps > 0
bos_index_ >= 0 && eos_index_ >= 0
Decoding output contains BOS label (
). Mapping it to label 0.
Decoding output contains label 0. Mapping it to BOS label (
fst-phonomap-file
Phonomap file as an fst. This must be input-arc sorted
phonetic-syms-file
Symbol table file representing the phone set.
corrections.
Invalid format for boolean argument [expected true or false]: 
Use add() to append array elements
Leaves can't have children
Can't add a value dictionary-like to a tree that is already array-like
Can't add a value array-like to a tree that is already dictionary-like
nested erase() not implemented
strtoul: out of range
expected value
expected key string
expected ':'
expected '}' or ','
void boost::property_tree::json_parser::detail::source<boost::property_tree::json_parser::detail::encoding<char>, std::istreambuf_iterator<char>, std::istreambuf_iterator<char>>::parse_error(const char *) [Encoding = boost::property_tree::json_parser::detail::encoding<char>, Iterator = std::istreambuf_iterator<char>, Sentinel = std::istreambuf_iterator<char>]
/AppleInternal/Library/BuildRoots/b958ad6d-2c13-11ed-a8d5-b25c5e9b9057/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator16.1.Internal.sdk/usr/local/include/boost/property_tree/json_parser/detail/parser.hpp
expected ']' or ','
unterminated string
invalid code sequence
invalid escape sequence
invalid codepoint, stray low surrogate
invalid codepoint, stray high surrogate
expected codepoint reference after high surrogate
expected low surrogate after high surrogate
expected 'true'
expected 'false'
expected 'null'
expected digits after -
need at least one digit after '.'
need at least one digit in exponent
garbage after data
cannot open file
void boost::property_tree::json_parser::read_json(const std::string &, Ptree &, const std::locale &) [Ptree = boost::property_tree::basic_ptree<std::string, std::string>]
/AppleInternal/Library/BuildRoots/b958ad6d-2c13-11ed-a8d5-b25c5e9b9057/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator16.1.Internal.sdk/usr/local/include/boost/property_tree/json_parser.hpp
void boost::property_tree::json_parser::write_json(const std::string &, const Ptree &, const std::locale &, bool) [Ptree = boost::property_tree::basic_ptree<std::string, std::string>]
hanning
hamming
rectangular
Invalid window type 
Inconsistent setting: center=true but lookahead is set to 
Flooring variance When normalizing variance, floored 
 elements; num-frames was 
total rollbacked steps are 
On beam 
 peak attention at 
 which is too close to 
Not enough steps to rollback, need wait for more audio and reinitialization
bluetoothDeviceId
utteranceDetection
EagerUsed
Detected latency overflow, change to int_max.
dup stat: token=
, source=
Empty tokenStrings received
Empty tokenStrings[0] received
Token=
 found in Lexicon, prons=
Skipping invalid token=
 found in PronCache
Failed to generated pronunciations for word=
in backoff window, skip updating pron cache for token 
Byte-range queried for number of codepoints seems to intersect a codepoint
Config:
Token: 
 not found in raw string input: 
Char ranges in the word char map exceeds total number of characters
Mismatch in sizes of alignment queries and projections from the first leg don't match.
Json corresponding to alignment-queries cannot be parsed.
AlignmentProcessorBlock::handleSourceInput() called called with empty input
AlignmentProcessorBlock::handleSourceInput() called called with multiple inputs
alignment-span-info
For alignment mapping to work properly, ensure whole string provided as first token.
Query range [
] is out of bounds.
] is illegal.
AlignmentProcessorBlock::handleSegmentEncInput() called called with empty input
AlignmentProcessorBlock::handleSegmentEncInput() called called with multiple inputs
AlignmentProcessorBlock::handlePDecInput() called with empty input
AlignmentProcessorBlock::handleSegmentDecInput() called with empty input
AlignmentProcessorBlock::handleTokenizedInput() called with empty input
size of n-best list from segment-decoder and PDec-translator are different
Tokenizer did not return same number of phrases as the Translator.
resetting original query ranges from alignment-span-info
Disambiguation symbol 
 is also a phone.
Determinization aborted since passed 
 states.
max-states reached in determinization
Determinization terminated since passed 
 states, partial results will be generated.
Determinization aborted since looped more than 
 times during epsilon closure.
looped more than max-states times in determinization
DeterminizerStar: FST was not functional -> not determinizable
First string: 
Second string: 
Non-functional FST: cannot determinize.
Debug function called (probably SIGUSR1 caught).
Nothing to trace back
Traceback did not reach start state (possibly debug-code error)
Traceback below (or on standard error) in format ilabel (olabel olabel) ilabel (olabel) ...
EncodeMapper: Label-encoded arc has different input and output labels
EncodeMapper: Weight-encoded arc has non-trivial weight
EncodeMapper: decode failed
EncodeTable::Decode: unknown decode key: 
FST is not an unweighted acceptor
Acyclic Minimization
Cyclic Minimization
Weight::Properties() & kIdempotent
../libquasar/libkaldi/tools/openfst/src/include/fst/minimize.h
PrePartition
Initial Partition: 
Context FST created but there are no phone symbols: probably input FST was empty.
context
ContextFst: CreateArc, invalid olabel supplied [confusion about phone list or disambig symbols?]: 
ContextFst copying not yet supported [not hard, but would have to test.]
ContextMatcher: bad match type
TableMatcher: bad match type
final_weight.String().empty()
final_weight.Weight().Value1() == 0.0
final_weight.Weight().Value2() == 0.0
Total forward probability over lattice = 
, while total backward probability = 
Non-finite total probability in lattice (
). Numeric problems with model?
best cost = 
path len=
 mean conf=
[stack trace: ]
nnlm-trainer-config
nnlm trainer config path no default value
nnlm-loading-files
nnlm espresso inference network used for evaluation
wordmap-file-extension
The file extension that is used for workmap file.
enable-wordmap
The indicator on whether enable wordmap at inference time.
norm-factor
norm factor used at inference time
max-context-size
maximum context size used by nnlm at inference time
num-epochs
number of epochs that training pipeline goes over the given data
evaluate-after-each-epoch
the flag that indicates whether enable evaluation after each epochs
nnlm-trainer-overwrite-config
optional field that can overwrite existing default trainer config
The nnet loading path contains dangerous components.
Malformed LM neural network file name, fileBasename=
Other data type is not supported for NNLM trainer.
Unsupported NNLM training Config
.shape
ComputeAheadFeatInput
ivector file 
 cannot be opened
Landmark hash ark file 
imposterMean=
imposterStd=
Name of nnet file
Threshold to apply to ivector score
ivector-fingerprint-ark-file
ark file with ivectors for fingerprints
ivector-imposter-ark-file
ark file with ivectors with imposters
trigger-preceding-max-ms
Maximum amount of audio used before trigger phrase
trigger-trailing-min-ms
Minimum amount of audio used after trigger phrase
trigger-trailing-max-ms
Maximum amount of audio used after trigger phrase
trigger-num-tokens
The number of tokens in the trigger phrase (two for hey siri)
ivector-threshold
ivector-score-bias
Bias to apply to ivector score when combining with lmark
lmark-hash-strategy
Hashing strategy (e.g. 3x3)
lmark-hash-start-idx
Feature start idx for hashing
lmark-hash-end-idx
Feature end idx for hashing
lmark-hash-fingerprint-ark-file
ark file with landmark hash vectors for fingerprints
lmark-hash-imposter-ark-file
ark file with landmark hash vectors for imposters
lmark-min-len
Min num frames for computing similarity between landmark hash vectors
lmark-max-len
Max num frames for computing similarity between landmark hash vectors
lmark-threshold
Threshold to apply to landmark similarity
imposter ivector file 
 is empty
fp-ivectors=enabled
Unrecognized hash strategy string 
Landmark params not properly set
fp-landmark=enabled
Invalid fbank dims. 
Expected: 
 Got: 
Encountered zero iVector
Speaker embedding=
Index=
 similarity=
 exceeded threshold=
Did not match any known fingerprints
Trigger phrase not detected
Not enough audio to make a decision.
Hash strategy 
 is not implemented
Landmark hash=
] Unnormalized landmark hash score: 
] T-normalized landmark hash score: 
FingerprintDetector not run on input origin 
Error: Utterance features were improperly cached.
Zero-length utterance. Rejecting utterance.
Error: getAudioProcessingWindow failed
Processed Frames: 
Best i-vector match score=
 index=
Adjusted i-vector score=
 thres=
FingerprintAlgo
FingerprintIndex
FingerprintScore
FingerprintDetected
FingerprintDetected=
 MatchingIndex=
 matchingScore=
num-ceps
Number of cepstra in MFCC computation (including C0)
use-energy
Use energy (not C0) in MFCC computation
energy-floor
Floor on energy (absolute, not relative) in MFCC computation
raw-energy
If true, compute energy before preemphasis and windowing
cepstral-lifter
Constant that controls scaling of MFCCs
htk-compat
If true, put energy or C0 last and use a factor of sqrt(2) on C0.  Warning: not sufficient to get HTK compatible features (need to change other parameters).
sample-frequency
Waveform data sample frequency (must match the waveform file, if specified there)
frame-length
Frame length in milliseconds
frame-shift
Frame shift in milliseconds
preemphasis-coefficient
Coefficient for use in signal preemphasis
remove-dc-offset
Subtract mean from waveform on each frame
dither
Dithering constant (0.0 means no dither)
window-type
Type of window ("hamming"|"hanning"|"povey"|"rectangular")
round-to-power-of-two
If true, round window size to power of two.
snip-edges
If true, end effects will be handled by outputting only frames that completely fit in the file, and the number of frames depends on the frame-length.  If false, the number of frames depends only on the frame-shift, and we reflect the data at the ends.
num-mel-bins
Number of triangular mel-frequency bins
low-freq
Low cutoff frequency for mel bins
high-freq
High cutoff frequency for mel bins (if < 0, offset from Nyquist)
vtln-low
Low inflection point in piecewise linear VTLN warping function
vtln-high
High inflection point in piecewise linear VTLN warping function (if negative, offset from high-mel-freq
debug-mel
Print out debugging information for mel bin computation
cmn-window
Window in frames for running average CMN computation
min-cmn-window
Minimum CMN window used at start of decoding (adds latency only at start). Only applicable if center == false, ignored otherwise.
norm-vars
If true, normalize variance to one.
center
If true, use a window centered on the current frame (to the extent possible, modulo end effects). If false, window is set based on "cmn-window" and "lookahead".
lookahead
Number of frames to look ahead for online CMN. Ignored if center==true.
SequentialTableReader<Holder>::Open(), could not close previously open object.
Invalid rspecifier 
Trying to use empty SequentialTableReader (perhaps you 
passed the empty string as an argument to a program?)
TableReader::Open, error closing previous input (only warning, since permissive mode).
TableReader::Open, error closing previous input.
TableReader: failed to open stream 
TableReader: error beginning to read table (wrong filename?): 
Done() called on TableReader object at the wrong time.
IsOpen() called on invalid object.
Key() called on TableReader object at the wrong time.
Value() called on TableReader object at the wrong time.
KaldiObjectHolder::Value() called wrongly.
TableReader: FreeCurernt called at the wrong time.
TableReader: Next() called wrongly.
Error reading archive 
Invalid archive file format: expected space after key 
, got character 
, reading 
Object read failed, reading archive 
Reading Table object, failed reading binary header
Exception caught reading Table object 
Close() called on TableReader twice or otherwise wrongly.
Error detected closing TableReader for archive 
 but ignoring 
it as permissive mode specified.
TableReader: reading archive failed: 
TableReader::Open, error closing previous input 
Failed to open script file 
TableReader: failed to load object from 
 (to suppress this error, add the permissive 
(p, ) option to the rspecifier.
TableReader: you called Value() after FreeCurrent().
TableReader: Value() called at the wrong time.
TableReader: LoadCurrent() called at the wrong time.
TableReader: failed to open file 
TableReader: FreeCurrent called at the wrong time.
SequentialTableReader, reading script file: Next called wrongly.
Close() called on input that was not open.
Close() called on scp file with read error, ignoring the error because permissive mode specified.
TableReader: reading script file failed: from scp 
empty CTC keyword
<EncoderInput>
<DecoderParentIds>
<DecoderInput>
<DecoderCheck>
<DecoderSuccess>
<DecoderOutput>
<DecoderAttention>
<Encode>
<Reset>
<InputShapeTemplate>
<FrameSubsamplingFactor>
<BOSIndex>
<EOSIndex>
<SilIndex>
<Beam>
in->GetNumDims() == cfg_.input_shape_template.ndim
in->GetDimSize(cfg_.input_shape_template.col_index) == InputDim()
<Inputs>
<Outputs>
<InputStates>
<OutputStates>
<InitialStates>
<Feats>
<Parents>
<Check>
<Attentions>
<Success>
<InputFeats>
<FinishEncoding>
<OutputFeats>
input_states.size() == cfg_.input_states.size()
input_feats->GetNumDims() == cfg_.input_shape_template.ndim
input_feats->GetDimSize(cfg_.input_shape_template.col_index) == InputDim()
<InputParents>
<InputLabels>
<OutputLoglikes>
<OutputAlignments>
<InputAttentionStates>
<ComputeCellOutputs>
<InputCellOutputs>
input_states.size() == cfg_.output_states.size()
input_feats != nullptr
input_feats->GetDimSize(cfg_.input_shape_template.row_index) > 0
src_states.size() == cfg_.input_states.size()
src_states.size() == cfg_.output_states.size()
src_states.size() == dst_states.size()
encoder_input
decoder_parent_ids
decoder_input
decoder_output
decoder_attention
reset
inputs
outputs
input_states
output_states
initial_states
feats
parents
attentions
input_feats
output_feats
input_parents
input_labels
output_loglikes
output_alignments
Attempt to write into immutable matrix
Too many rows*cols for 8-bit Matrix
Quantized matrix improperly serialized
unimplemented
New stride (
) must not be smaller than
 the current stride (
) must be a multiple of 
current stride (
Non matching dimensions: Rows:
 VectorDim:
Non matching dimensions: Cols:
matrix A and B can not be transposed at the same time, not implemented yet
Memory allocation failed when initializing CuVector 
with dimension 
 object size in bytes: 
word-syms-file
word symbol table text format filename
HCLG FST filename
Could not read symbol table from text file 
/sil_S/
/sil_B/
/sil_I/
/sil_E/
Problem decoding utterance.
FINAL RESULT:
Result Choice[
Pronounciation Choice[
update-interval
Beam update interval in frames
beam-update
Beam update rate
max-beam-update
Max beam update rate
inter-utt-sil
Maximum # of silence frames to trigger new utterance
max-utt-sil
Maximum # of silence frames to trigger end of speech while no speech presented
max-utt-length
If the utterance becomes longer than this number of frames, shorter silence is acceptable as an utterance separator
det-max-mem
Maximum approximate memory usage in determinization (real usage might be many times this)
det-max-loop
Option used to detect a particular type of determinization failure, typically due to invalid input (e.g., negative-cost loops)
Decoding beam.
Decoder max active states.
min-active
Decoder minimum #active states.
Lattice generation beam
prune-interval
Interval (in frames) at which to prune tokens
determinize-lattice
If true, determinize the lattice (in a special sense, keeping only best pdf-sequence for each word-sequence).
Increment used in decoding-- this parameter is obscure and relates to a speedup in the way the max-active constraint is applied.  Larger is more accurate.
Setting used in decoder to control hash behavior
word-ins-penalty
Word insertion penalty applied to each word
delta
Tolerance used in determinization
max-mem
Maximum approximate memory usage in determinization (real usage might be many times this).
phone-determinize
If true, do an initial pass of determinization on both phones and words (see also --word-determinize)
word-determinize
If true, do a second pass of determinization on words only (see also --phone-determinize)
minimize
If true, push and minimize after determinization.
Could not topologically sort lattice: this probably means it has bad properties e.g. epsilon cycles.  Your LM or lexicon might be broken, e.g. LM with epsilon cycles or lexicon with empty words.
determinization did not succeed(partial output will be pruned tighter than the specified beam.)
Beam: 
; Speed: 
 xRT
Changed confidence for slot=
1best: 
phrase=
 orig: 
 new: 
Unsupported n-best index configuration
n-best output size is wrong
am-file
Acoustic model (transition model) filename
Decoding beam
first-pass-lattice-beam
First pass lattice beam
Decoding lattice beam
retry-beam
Fall-back decoding beam
HCP FST filename
tree-file
Tree file
phone-map-file
Phone mappings file
Conversion of alignments in lattice is only supported for models with context width = 1, other models will result in alignments which do not properly consider cross-word contexts
Problem decoding utterance for re-alignment.
Determinization finished earlier than the beam
kaldi::OnlineDecodableNnet1Lazy is required at this point in the first pass with configured realign-model parameter.
opts_.beam > 0
Not implemented
prior=(-?\d+\.?\d*)$
RegexParseError: expected [ or ( at 
 but found 
Unexpected regex found: '
' in '
Unbalanced parenthesis or brackets found in grammar
prior=
 config:
empty nbest (token) input received
size
text
positions
placeholders
Input dimension of parallel component and input dimensions of nested networks do not match.
Output dimension of parallel component and output dimensions of nested networks do not match.
no limiting of nbest output size
invalid value for nbest option!
limiting n-best size to 
using metainfo annotation to filter nbest
simple nbest size limiting
validating source locale against metainfo locale
locale validation disabled
senses
source-locale not set
defLocale
defLocale: <
 incompatible with srcLocale: <
> deleting alternatives and stripping nbest annotation from metainfo
> deleting alternatives and stripping disambig annotation from metainfo
sending 
 alternatives without limiting
 alternatives, too few to limit (limit=
 alternatives, limiting from 
no hypotheses, sending empty list of hypotheses
only one hypothesis, sending it
1-best hypothesis is low confidence, sending only this hypothesis
1-best hypothesis has no ambiguity annotation, sending only this hypothesis
no ambiguity found: 
 alternative(s)
ambiguity found: 
unconstrained
reduced
avoid
The number of recognition request parameters is 
 (requirement is 3)
 (requirement is 5 or 8 for config file ver 15.0+)
Illegal char '*' found in task type 
Illegal char '*' found in device type 
farField type must be '*', 'true', or 'false': 
Illegal char '*' found in bluetooth device id 
aneContext type must be '*', 'unconstrained', 'reduced', or 'avoid': 
cpuContext type must be '*', 'unconstrained', 'reduced', or 'avoid': 
gpuContext type must be '*', 'unconstrained', 'reduced', or 'avoid': 
Could not find the recognizer components for the params samplingRate=
 task=
 device=
 farField=
 bluetoothDeviceId=
 aneContext=
 cpuContext=
 gpuContext=
associated-task-mapping
Recognizer string malformed
 :: 
Could not make Unicode regex: 
Could not open BreakIterator: 
<NumCells>
<BiasMean>
<BiasRange>
<ForgetGateBiasMean>
<ForgetGateBiasRange>
<ProjectionLearnRateCoef>
<MaxNorm>
<MaxCell>
<NoPeep>
<OutputCellValues>
Invalid token 
. Allowed tokens: 
(NumCells|BiasMean|BiasRange|ForgetGateBiasMean|ForgetGateBiasRange|ParamStddev|LearnRateCoef|ProjectionLearnRateCoef|MaxNorm|
MaxGrad|MaxCell|NoPeep|InitTransformType|GradientNormType|RandomSeed)
bias_ thought to be initialized here
# LSTM cells (
) should not be less than output dim (
input_weights_ thougth to be un-initialized here
recurrent_weights_ thougth to be un-initialized here
peephole_weights_ thougth to be un-initialized here
bias_ thougth to be un-initialized here
projection_weights_ thougth to be un-initialized here
 Input weights:
 Recurrent weights:
 Bias:
 Forget gate bias:
 Peephole weights:
 Projection weights:
  Gradients are uninitialized
 For batch 
  Number of cells : 
  Input weights gradient: 
  Recurrent weights gradient: 
  Bias gradient: 
  Peephole weights gradient: 
  Projection weights gradient: 
  Gates values: 
  Cell values: 
  Cell outputs: 
  Cell outputs gated: 
  Output values: 
  Gates diff: 
  Cell diff: 
  Cell out gated diff: 
  Output diff: 
Accumulating gradients for batch id = 
Reset previous states for utts 
input_weights_
recurrent_weights_
peephole_weights_
projection_weights_
input_weights_gradient_.size() > ib
input_weights_gradient_[ib]
recurrent_weights_gradient_.size() > ib
recurrent_weights_gradient_[ib]
bias_gradient_.size() > ib
bias_gradient_[ib]
has_peepholes_
peephole_weights_gradient_.size() > ib
peephole_weights_gradient_[ib]
has_projection_layer_
projection_weights_gradient_.size() > ib
projection_weights_gradient_[ib]
input_weights_ thought to be un-initialized here
recurrent_weights_ thought to be un-initialized here
bias_ thought to be un-initialized here
peephole_weights_ thought to be un-initialized here
projection_weights_ thought to be un-initialized here
Allocated memory for the parameters: 
Allocating forward buffers for batch 
; batch size = 
Allocating backward buffers for batch 
input_weights_gradient_.size() == 0
recurrent_weights_gradient_.size() == 0
bias_gradient_.size() == 0
peephole_weights_gradient_.size() == 0
projection_weights_gradient_.size() == 0
Allocated memory for the gradients: 
Saving last output and cell state for batch 
Input weights #rows = 
; expecting 
; #cells = 
Input weights #columns = 
 (same as input dim)
Recurrent weights #rows = 
Recurrent weights #columns = 
 (same as output dim)
Peephole weights #rows = 
Peephole weights #columns = 
 (same as #cells)
Bias dim = 
Projection weights #rows = 
Projection weights #columns = 
learn_rate_coeff_ must not be negative; found: 
projection_learn_rate_coeff_ must not be negative; found: 
max_norm_ must not be negative; found: 
max_grad_ must not be negative; found: 
max_cell_values_ must not be negative; found: 
Performing  vectorization of lstm component
gradients_valid_ is thought to be false here
input_weights_gradient_[ic]->NumRows() == InputWeights().NumRows() && input_weights_gradient_[ic]->NumCols() == InputWeights().NumCols()
recurrent_weights_gradient_[ic]->NumRows() == RecurrentWeights().NumRows() && recurrent_weights_gradient_[ic]->NumCols() == RecurrentWeights().NumCols()
bias_gradient_[ic]->Dim() == Bias().Dim()
peephole_weights_gradient_[ic]->NumRows() == PeepholeWeights().NumRows() && peephole_weights_gradient_[ic]->NumCols() == PeepholeWeights().NumCols()
projection_weights_gradient_[ic]->NumRows() == ProjectionWeights().NumRows() && projection_weights_gradient_[ic]->NumCols() == ProjectionWeights().NumCols()
Done vectorization of lstm component
Must first call init() for 
 before calling createDecodable().
Building Decodable 
Unknown decodable type "
matrix-scaled
matrix-scaled-mapped
matrix-scaled-mapped-tm
ctc-online-kwd
dummy
nnet1-lazy
Acoustic model (transition model) filename (only used for lattice stuff)
tid2pdf-file
Text file of ints representing PDF IDs for transition IDs 0, 1, 2, ... 
Read transModel
Using TID2PDF file
Created OnlineDecodableMatrixScaled decodable
decodable type "
Created OnlineDecodableMatrixScaledMapped decodable
OnlineDecodableMatrixScaledMapped: mismatch, matrix has 
 rows but transition-model has 
 pdf-ids.
tm-weight
Weight factor for tm likelihoods
Created OnlineDecodableMatrixScaledMappedTm decodable
Created OnlineDecodableIdenticalMatrix decodable
class-frame-counts-file
File containing vector with frame-counts of pdfs to compute log-priors. This is the same as class-frame-counts, but allows paths that are relative to the json config file (class-frame-counts requires absolute paths). If class-frame-counts is also specified, this param will override it.
Name of nnet model file
File for feature transform in front of nnet's main network (in nnet format)
skip-frames
Number of frames to be skipped in nnet computation.
use-gpu-id
Unused, kaldi is compiled w/o CUDA
silence-model-file
Name of nnet model file for computing silence posteriors
compute-sil-model-posteriors-from-realign-model
True if penultimate activations from realign model are the input to the silence model, otherwise use the penultimate activations from the main acoustic model
workspace-size-kb
Workspace size in Kilo Bytes
realign-model-file
Name of nnet model file for computing posteriors for later realignment of 1st/2nd pass lattices
realign-class-frame-counts-file
File containing vector with frame counts of pdfs to compute log-priors. This is the same as class-frame-counts, but allows paths that are relative to the json config file (class-frame-counts requires absolute paths). If class-frame-counts is also specified, this param will override it.
compute-realign-model-posteriors-from-penultimate
True if penultimate activations from main acoustic model are the input to the realignment model, otherwise use the same features as the main acoustic model as input
skip-blanks-threshold
Threshold for skipping frames with a CTC trained acoustic model, applied to posterior probability of the blank symbol
blank-pdf-id
Pdf-id of blank symbol of CTC trained acoustic model, used in combination with skip-blanks-threshold
skip-across-batch
Make skip-frames deterministic by skipping across batches instead of within batches (default: false).
blank-penalty
Penalty for blanks with a CTC trained acoustic model when silence posterior is higher than a threshold
blank-penalty-silence-threshold
Threshold of silence posterior when the blank penalty is appled to blanks
class-frame-counts
Vector with frame-counts of pdfs to compute log-priors. (priors are typically subtracted from log-posteriors or pre-softmax activations)
prior-scale
Scaling factor to be applied on pdf-log-priors
prior-cutoff
Classes with priors lower than cutoff will have 0 likelihood
Read mapped nnetTransf
Read nnetTransf
Read pdfPrior
Read model file for computing silence posteriors=
Read model file for computing realignment posteriors=
Created OnlineDecodableNnet1LazyDecodable decodable
Skipping 
 frames may not give you good results.
Parameters realign_model_input_is_penultimate_ and sil_model_input_is_realign_penultimate_ cannot both be true at the same time.
Realignment model (nnet_realign) must be set in order to pass its penultimate activations to the silence model.
skip_across_batch cannot be set if you aren't frame skipping
skip_across_batch does not work with skip_blanks_threshold or nnet_realign
nnet transformation contains splicing, which is not 
supported by OnlineDecodableNnet1Lazy. Use a separate splice 
operation to perform splicing.
nnet contains splicing, which is not supported by 
OnlineDecodableNnet1Lazy. Use a separate splice operation to 
perform splicing.
Given task and language pair combination is not supported
Failed to compile unicode outliers regex
sanitized string is empty
Pruned state-level lattice with beam 
 and retrying determinization with that beam.
Effective beam 
 was less than beam 
 * cutoff 
, pruning raw 
lattice with new beam 
 and retrying.
Both --phone-determinize and --word-determinize are set to 
false, copying lattice without determinization.
Doing first pass of determinization on phone + word 
lattices.
Doing second pass of determinization on word lattices.
Pushing and minimizing on word lattices.
Topological sorting of state-level lattice failed (probably
 your lexicon has empty words or your LM has epsilon cycles
Lattice determinization terminated but not 
 because of lattice-beam.  (#states, #arcs) is ( 
 ), versus limits ( 
 ) (else, may be memory limit).
Total weight of input lattice is zero.
Lattice determinization aborted since looped more than 
Cost below best cost was encountered:
Rebuilt repository in determinize-lattice: repository shrank from 
 bytes (approximately)
Did not reach requested beam in determinize-lattice: 
size exceeds maximum 
 bytes; (repo,arcs,elems) = (
), after rebuilding, repo size was 
, effective beam was 
 vs. requested beam 
Rebuilding repository.
empty subset
Zero weight!
New cost is less (check the difference is small) 
Invalid or out-of-range hex value
Found token separator char in token: "
Found unassigned code point 
 in string "
Unicode normalization failed for:
Input string is not Unicode normalized:
Found illegal char with value 
~U is not followed by 8 hex digits
~U is not followed by a valid unloggly code point
~w is not followed by 2 hex digits
~w followed by hexValue=
Encountered invalid tilde char: 
Unicode normalization failed for :
Illegal occurrence of ^ in HatText token 
Illegal use of ^ followed by value 
 in HatText token 
Conversion failed for qsr token 
Illegal occurrence of ~U in QsrText token 
Illegal occurrence of ~w in QsrText token 
Unsupported occurrence of ~w in QsrText token 
Illegal use of ~ in QsrText token 
Illegal occurrence of ~U in QsrText string 
Illegal occurrence of ~w in QsrText string 
Unsupported occurrence of ~w in QsrText string 
Illegal use of ~ in QsrText string 
) -> 
Failed to encode srcToken="
" dstToken="
u_strFromUTF8() failed with error=
Unicode NFC normalization failed.
u_strToUTF8() failed with error=
pre = "
post = "
map = 
<InFeatureMaps>
<OutFeatureMaps>
<PatchStep>
<SectionStep>
<SectionSize>
<FilterSize>
<InSharedBands>
<PoolSize>
<PoolStep>
<BiasLearnRateCoef>
 (ParamStddev|BiasMean|BiasRange|InFeatureMaps|OutFeatureMaps|PatchStep|SectionStep|SectionSize|FilterSize|LearnRateCoef|BiasLearnRateCoef|MaxNorm|RandomSeed)
ConvolutionalMaxPoolingComponent: Invalid max pooling size
ConvolutionalMaxPoolingComponent: Max pooling step must be >= 1
ConvolutionalMaxPoolingComponent: output dim mismatch
ConvolutionalMaxPoolingComponent: input dim mismatch
ConvolutionalMaxPoolingComponent: too few input bands to compute the output
pointer is thought to be un-initialized here
<Filters>
<Bias>
  filters
  filters_grad
, max-norm 
  bias_grad
 , # of sections: 
, section size after pooling: 
Backpropagation of CNN ConvolutionalMaxPoolingComponent is not supported for quantized weights
Not supported for quantized weights
Unimplemented
Backpropagation of CNN ConvolutionalMaxPoolingComponent is not supported on CPU
ConvolutionalMaxPoolingComponent::AccumGradients can't be called before ConvolutionalMaxPoolingComponent::Backpropagate
Performing vectorization of convolutional maxpooling component
(nlinparams + Bias().Dim()) == NumParams()
veccorrs->size() == filters_grad_.size() && veccorrs->size() == bias_grad_.size()
(filters_grad_[ic]->NumRows() * filters_grad_[ic]->NumCols() + bias_grad_[ic]->Dim()) == NumParams()
Done  vectorization of convolutional maxpooling component
<NumBands>
 (NumBands)
NumBands should be > 0
Invalid NumBands value
 CnnRearrange 
<PrePadding>
<PostPadding>
<Postamble>
<PadValue>
Invalid pre and post padding sizes
Invalid postamble size
 PaddingComponent 
<FmapXLen>
<FmapYLen>
<PadTop>
<PadBottom>
<PadLeft>
<PadRight>
h > 0 && w > 0
num_to_trim_h < h
num_to_trim_w < w
input_dim_ % (h * w) == 0
output_dim_ % (out_h * out_w) == 0
c == out_c
Config file must be loaded before calling this method.
Config path is empty. Config file must be loaded before calling this method.
File 
 not found.
remove child: 
The existing value of the key: 
 is a list. New value will be appended to the list.
 will be appended with new value.
Appending of new value is supported only for value types - list, string. Please cross check value for key: 
The override key: 
 starts with 
, however no existing key/value was found to be appended. New value will be added for the keyPath: 
override config version << 
 is incompatible with main config version: 
override config type << 
 is not the same as main config type: 
model-info.version
override config language [
] is not the same as main config langauge [
We only support override of speech model.
Failed to load override config with error = 
This method can be called only once throughout the lifetime of this object.
Using cache for json file 
Reading json file 
Config override: 
Set json config file path to 
failed to parse json file 
, error: 
version-major
version-minor
Config file version is missing. 
Reading version 
 as 15.0
Version of currently loaded config file: 
 Supported config file version: 
 (minimum supported version: 
Config file version 
 is lower than the minimum supported version 
 is higher than the supported version 
Config file does not have speech model-info node.
Config file does not have mt-model-info node.
Config file does not have model-info node.
model-info
mt-model-info
Only one of model-info and mt-model-info can exist in the config
model-info.language
model-info.os-types
Empty model-info.os-types
model-info.sampling-rates
Empty model-info.sampling-rates
model-info.tasks
Empty model-info.tasks
model-info.phoneset-version
model-info.acoustic-profile-version
lme-create.template-map
ACE category name 
 occurs twice in lme-create.template-map
lme-create.name-enumerator-map
Quasar template name 
 occurs twice in lme-create.name-enumerator-map
type
g2p.model-version
model-info.hybrid-endpointer-version
Error parsing model-info 
mt-model-info.version
mt-model-info.source-language
mt-model-info.target-language
mt-model-info.language-pairs
invalid language pair: 
mt-model-info.tasks
'mt-model-info.tasks' must be dictionary of task specific language pair lists, when no global language pair(s) provided
task specific language pair lists require minimum config version 
language-pairs
no 'language-pairs' section in task section '
Non source and target language pair.
Empty mt-model-info.tasks
mt-model-info.task-alias
missing decoder config for task 
 (expected config in 
language-pair-specific-settings
invalid language pair name: 
missing specific setting, this should not happen.
source language 
 using 
' tokenizer.
target language 
Error parsing mt-model-info 
hybrid-client-configs
hybrid-client-configs.hybrid-ep-thresholds
hybrid-client-configs.hybrid-ep-extra-delay-frequency
%s : %s
%s : %d
%s : %f
parameter [
] was not verified of its presence in the original config. Adding/Replacing it.
] is not in original config.
] is not a leaf node.
-file
nt-fsts.\NT-bizname
g2p-blacklist
-directory
geo-config
-ark-file
ark:
-file-list
rule-fst
Could not find required name "
Parameter "
" requires minimum version 
 but config version is 
" requires maximum version 
Ignoring unrecognized option 
Required parameter "
" not found
Prefix must end with '.' : 
Incompatible system config version. Needs to be >= 
 to use 
Incompatible system config version. Needs to be <= 
Invalid integer option "
Invalid floating-point option "
Parameter name 
 already registered
append:
boost::bad_format_string: format-string is ill-formed
boost::too_many_args: format-string referred to fewer arguments than were passed
boost::too_few_args: format-string referred to more arguments than were passed
VersionUnsupported: 
result-combiner
result-combiner.
1.0,1.0
compute-conf
Whether to use existing confidence or re-compute a score from the tokens, default = true.
nbest-depth
The maximum number of alternatives to allow in the combined output, default = 10.
system-weights
A comma-separated list of weights to apply to each system, in the same order as the provided system input, default is 1.0,1.0.
contact-first@contact-middle@contact-last@appname-first@appname-last,contact-first@contact-middle@contact-last@appname-first@appname-last
backbone-system
The index of the system to use as the reference/backbone system. This is the default system, and the one which is used for alignment.
eps-backbone
The epsilon confidence score for epsilons inserted into the backbone.
eps-alternative
The epsilon confidence score for epsilons inserted into the alternative systems.
do-selection
Switch to control whether to do system selection or combination, default is 'true' (i.e. do selection only).
combine-any-region
Switch to control whether, if regions are specified, to do region combination within the entire utterance, if the region exists at all in the two CNs.
combine-in-region-only
Switch to control whether, if regions are specified, to do region combination only in slots where the region exists.
confidence-delta
The delta by which the competing systems must be better than the backbone in order to be considered better.
region-list
List of regional terminals to mach for use for system combination (works with region-combine options). Comma-separated for each system, and @-separated for each region within a system (e.g. contact-first@appname-first,contact-last).
do-flatten
Switch to control whether to flatten the confusion network such that only a 1-best combination/selection is performed.
do-partial-merge
Switch to control whether to allow merging a partial hypothesis with a longer one before doign selection.
max-partial-shift
The amount of jitter or shift to allow when deciding whether to merge a longer hypothesis with a partial one.
truncation-delta-milliseconds
Skip system combination if (backbone speech end - competing speech end) >= this value. Value can be positive or negative. This prevents truncation if the CN being combined with is too short. By default, we don't enable this check, value = huge number.
Could not read system weight info
Number of systems is 
System 
 Number of alternatives is 
Alternative = 
Final alternatives list:
DECODER OPTION in slot 
 word 
 score = 
 phoneSeq 
CONSENSUS in slot 
 selected word 
End time of competing confusion network is 
ConfusionNetworkMerge: Backbone word starts at the same time as the end of the competing CN. Merge starting at 
ConfusionNetworkMerge: Exceeded the maximum allowable shift amount (
) with 
 won't try to merge anymore.
ConfusionNetworkMerge: Backbone word starts before the end of the competing CN, ends after and covers more audio. Merge starting at 
ConfusionNetworkMerge: We have exceeded the maximum allowable shift amount (
 we won't try to merge anymore.
ConfusionNetworkMerge: Backbone word starts after end of the competing CN, and haven't started merging yet, and the word doesn't start too long after. Merge starting at 
Merging the word/words in slot 
 onto the end of the competing confusion network
Found a region of interest in the confusion network
Could not find a region of interest in the confusion network
BestConfidence is 
Competing Confidence for system 
 is 
Best system End Time is 
End time for competing system 
Competing system does not cover enough speech (max truncation is 
 ,current truncation is 
Exiting selection logic
Proceeding with selection logic using merged partial confusion network
Switching selected system from 
 new score = 
 old score = 
Selected system is 
FINAL HYPOTHESIS IS  : 
text=
 tokens=[
DecodableMatrixScaledMapped: mismatch, matrix has 
if >= 0, use this value as length penalty weight. Default means using the default in the graph
pad-size
if the whole audio is too short, pad to this length
mmapped-graph
is it a memory mapped graph?
num-inter-op-threads
The maximum number of threads for inter ops in TF graph
num-intra-op-threads
The maximum number of threads for intra ops in TF graph
default-device
TF default device
catf-input
the catf input, a list of comma delimited values
allow-soft-placement
TF allow soft placement
log-device-placement
TF log device placement
profiling-granularity
Level of profiling (higher means more precise breakdown per operation)
model-config-file
The config file for the model
model-config-binary
is the config file binary?
model-config-end-token
The config file's end token
number of frames in each batch
model-beam
the beam size used in the model
time-reduction-factor
source sequence length reduction factor in the model
max-decode-length
the maximum number of decoding steps
if > 0, use this value as the coverage penalty.
utt-end-beam
if > 0, use this beam at the utterance end.
safe-align-thresh
number of steps for alignment wiggle room
init-wait-time
number of frames before running the first generation step
cont-wait-time
number of frames before running the continuous generation step
rb-steps-fail
for early termination (failed), rollback this number of steps
rb-steps-boundary
for hitting boundary, rollback this number of steps
encoder-only
only streaming the encoder part
min-attn-weight
the minimum attention weight for a valid generation step
split
 tokens active.
VoiceCommandsBasicEndPointer inter-utt-sil=
, max-utt-length=
, max-utt-sil=
call to empty boost::function
illegal count weight or 
line too long?
SymbolTableData
/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/libquasar/liblm/src/symbol_tables.cpp
</s>
<unk>
-pau-
Null symbol table passed to constructor
Could not find symbol: 
/WORD-DIS-1/
observeTrainingSymbol
unmapped FST symbol
trainVocab not set
lookupTrainId
trying to look-up unmapped FST symbol: 
training token 
 not present in training map
 not present in training or ARPA vocabulary
observeSymbol
Unknown symbol source 
symbolMask and numSymbols should be non-null
Label out of bounds: 
observeBigGSymbols
observeSrilmVocabulary
ARPA vocabulary contains data pack OOV: 
generateTrainToBigGIdRemapping
 observed in ARPA but not present in SRILM Vocab
IterateSRILMVocabTokens
ComputeSRILMVocabToOpenFSTSymbolTableRemapping
FST SymbolTable should contain <s>.
FST SymbolTable should contain </s>.
InsertOrDie
../libquasar/liblm/include/lm/stl_utils.h
duplicate key 
FST SymbolTable does not contain token 
 (id 
duplicate element 
phrase-length-limit
max-num-enumerations
tag-sequences
we should have allocated enough space, instead we get in 
this expensive copy/resize on GPU. buffer size 
 , current end 
 , incoming data size 
read
AlignInput: can't determine stream position
AlignOutput: can't determine stream position
FstHeader::Read: Bad FST header: 
FstHeader::Read: read failed: 
Unknown file read mode 
Invalid UTF8 string:
Could not extract UTF8 length: 
Could not extract UTF8 chars: 
Regex compilation failed for:
Failed to initialize regex: 
Could not set regext text: 
Could not create space text: 
Error getting capacity for splitting text: 
Could not set regex text: 
Could not set region: 
Could not trim: 
Could not create input text: 
Could not create to text: 
Could not replace text with regex: 
Could not get utf-8 string: 
) Could not decode UTF8: 
) Could not set regex input: 
) Failed to apply regex: 
Could not extract UTF16 length: 
Could not extract UTF16 chars: 
BreakIterator construction failed: 
speculative-steps
steps to decode beyond attention checks
rollback-steps
steps to rollback before each speculative decoder
speculative-catchup
Catch up at the end of utterance by returning speculative predictions
unchecked-attention-heads
Do not perform checks for attention heads at these indexes
Error writing compressed matrix to stream.
Reading aligned matrix as a stream
Expected token 
. This could mean that you're trying to memory map an unaligned file.
Seeking for aligned data failed
Failed to read header
Failed to read data.
TranslationModel/__QNNO__initial_state:0
TranslationModel/__QNNO__encoder_values:0
TranslationModel/__QNNO__output_state:0
TranslationModel/__QNNO__softmax:0
TranslationModel/__QNNO__top_k_scores:0
TranslationModel/__QNNO__top_k_indices:0
TranslationModel/__QNNO__attention:0
TranslationModel/__QNNI__source_input:0
TranslationModel/__QNNI__target_input:0
TranslationModel/__QNNI__input_state:0
TranslationModel/__QNNI__top_k:0
input_mask
position
embedding
Nnet already mapped from a file
InputSymbolTableFile
Input symbol table size 
OutputSymbolTableFile
Output symbol table size 
<InputSymbolTable>
InputSymbolTable
<OutputSymbolTable>
OutputSymbolTable
InputVocab
Input vocab size 
OutputVocab
Output vocab size 
EspressoEngine
EncoderEspressoEngine
DecoderEspressoEngine
Graph
EmbeddingGraph
EncoderGraph
DecoderGraph
DecoderLangGraph
HandoverLangGraph
Mmap
AddSrcBos
AddSrcEos
PadSrc
PadSrcConfigs
MaxSrcTokens
Reverse
IsRNN
UseAttention
UseTopK
TopKCount
ModelBatchSize
BPEEncoder
Failed to read BPE model from : 
<BPE>
Failed to read embedded BPE model
BPE read - entries: 
AddTag
TagFormat
IsEspresso
SourceInputStr
TargetInputStr
EncoderValuesStr
ScoresStr
ShortlistStr
ShortlistFile
Loading Shortlist file...
<Shortlist>
Reading Shortlist...
ReadoutNnetFile
Loading readout Nnet file...
<ReadoutNnet>
Reading readout Nnet...
AlignmentLayerStr
AlignmentHeads
ShiftedAlignments
TransposeSourceInput
TwoDimSourceInput
HandoverStrings
StateStrings
StateWidth
StateLayoutND
NeedsPosition
NeedsEncoderPositions
NeedsEncoderOut
PositionZeroBased
ApplyLog
PositionScaleStr
NoSymbolTables
Either Graph or both EncoderGraph and DecoderGraph (or at least one DecoderLangGraph) must be specified in model file
Input symbol table must be specified
Output symbol table must be specified
Mmap must be set in model config file
IsRNN must be set in model config file
AddSrcBos must be set in model config file
Reverse must be set in model config file
Model is an RNN
UseTopK is set, Only 
 best outputs will be used
.next
f_encoder_
f_decoder_
Loading ENCODER...
Loading EMBEDDING...
Loading DECODER...
TensorFlow support not compiled
Handover plan required but not loaded!
Loading DECODER for '
'...
Loading HANDOVER for '
Unknown label not described in the model
Model does not support n-best inputs
Unexpected tensor rank 
 for encoder output
Espresso shortlist models require active shortlist!
 for handover 
Model does not support stream-decoding
Position input: 
readout layer size: 
Batched decoding not implemented for transformers with state handling
<UnkMode>
<UnkToken>
<Version>
<NumBpe>
Expected to read number of BPE units now, but got 
BPE model version: 
# of BPE model entries : 
 # of chars 
BPE model unk mode = 
, unk token = 
Wrong number of fields, ignoring : 
keep
char2unk
word2unk
dropword
dropchar
Unknown BPE unknown mode
Unknown unk mode : 
 diff 
Memory mapping failed. Not a valid Kaldi binary file: 
Memory mapping failed. mapped_file_ is NULL
memory mapped file 
opts_.eos_probability_threshold >= 0.0 && opts_.eos_probability_threshold <= 1.0
NoGradNorm
 correctedUtterances=%@
Input symbol id 
 missing from target vocabulary
Output symbol id 
 id=
lmScorer failed
lmScorer wrong number of results
lmScorer wrong result token
lmScorer wrong last result token
graphCost
acousticCost
choices
aligned
Word alignment failed: 
startMillis
endMillis
Multiple primary buffers are not allowed! 
Hint: Only one decoder chain can do system combination.
Cannot remove the primary buffer
Secondary chain rejected audio, probably waiting for primary: 
Invalid line in lexicon: '
Unable to load additional lexicon from: 
\PM-
<eps>
Unsupported phoneme '
' observed, skipping the pron 
Building NameEnumerator 
simple
raw-copy
exhaustive
regex
derived
Unknown NameEnumerator "
GetNumDims() == 2
prefilter input
<DNFList>
Skipping tag 
Input hammer has 
 known entries it will remove
Add tag 
 to pass lists
Not configured for locale : 
 on line 
Input hammer has DNF 
 known entries across 
 locales it will leave in place
RemoveUnderScores = 
, StripTokenLocales = 
, # of entries 
</DNFList>
<RemoveUnderScores>
<StripTokenLocales>
Locale not in pass list 
Input hammer did not change anything 
Input hammer removed tags 
Lattice word alignment failed. Cannot obtain word hyp lattice.
Empty word-aligned lattice. Cannot obtain word hyp lattice.
Could not load general voc
Sdapi has errored. Dying.
Could not tokenize
Could not get info from tokenized result
Failed TPToken_GetResultData with error code : 
Failed TPToken_DeleteResult with error code : 
No starting states!
Unsupported storage type 
Must have at least 3 mel bins
Bad values in options: low-freq 
 and high-freq 
 vs. nyquist 
Bad values in options: vtln-low 
 and vtln-high 
, versus 
low-freq 
Invalid indexing. You may have set --num-mel-bins too large.
bin 
, offset = 
, vec = 
MEL BANKS:
disambig_sym_start_ > 0 && disambig_sym_end_ > 0 && disambig_sym_start_ <= disambig_sym_end_
!fsts.empty()
FstNonNullAndHasArcs(fst)
MergeTrieFst[
 fsts_datas_size 
 unigram_fst_size 
 num_states 
 num_states_expanded 
 num_arcs 
sub_arc.ilabel != 0
!prev_arc || (current_arc->ilabel > prev_arc->ilabel) || (current_arc->ilabel == prev_arc->ilabel && current_arc->weight.Value() >= prev_arc->weight.Value())
group_size > 0
!IsDisambigSym(first_sub_arc.ilabel) || (group_size == 1)
first_sub_arc.ilabel > prev_group_ilabel
sub_arc.ilabel == first_sub_arc.ilabel
sub_arc_nextstate_final == Weight::One()
!safe
error: %s
memory error: %s
Initialized profile service failed 
Initialization of profile service succeeded 
Initialization of textproc failed 
Initialization of textproc succeeded 
Loading of general voc failed for voc=
, svc=
 with value=
Loading succeeded for voc=
 and svc=
Loaded CP1252 voc
Loaded UTF8 voc
locale: 
modelVersion: 
languageId: 
emptyDeltaVoc: 
pgVoc: 
generalVoc: 
paramsetHolder: 
generalVocTP: 
generalSvcTP: 
lexiconTP: 
staticTokenTP: 
staticItnTP: 
NcsDatapackManager loaded locale 
Error: Voc does not contain the tokencoll collation table
oh no:
 gave us 
Could not open lexicon
Could not open ITN
Could not do TPToken_Open
sdapi
SDhAdapter
SDAdaptAlignment
SDAdaptMethod
SDAdaptResultCode
SDhAdaptAccumResult
SDhAdaptApplyResult
SDAdapterInfo
SDAdaptConfigAndStatsItem
SDAdaptAccumResultInfo
SDAdaptApplyResultInfo
SDhChannel
SDChannelType
SDChannelResultCode
SDChannelFileFormat
SDExtChanDataType
SDWaveEncodingType
SDSignalFormat
SDChannelInfo
SDExtChanServerEventResult
SDExtChanServerEventType
SDExtChanServerEventSink
SDExtChanClientEventType
SDExtChanClientEventSource
SDExternalChannel
SDhColl
SDhCorpus
SDhCorpusWord
SDCorpusDocumentInfo
SDCorpusInfo
SDFPExceptionType
SDMemStats
SDEnvContainerType
SDEnvSpec
SDhEnvHolder
SDEnvHolderSource
SDEnvHolderInfo
SDInteger
SDUnsigned
SDUnsigned16
SDArraySize
SDByte
SDBool
SDChar
SDWideChar
SDFileSpec
SDInteger64
SDUnsigned64
SDDuration
SDUttFrameDuration
SDRecogFrameDuration
SDMicrosecTime
SDCycleTime
SDUserData
SDUniqueId
SDMemoryErrorUserData
SDErrorUserData
SDLogUserData
SDSnapTime
SDPlatformInfo
SDInitializeResultCode
SDFinalizeResultCode
SDProgressCallback
SDReallocateArrayCallback
SDMemoryErrorHandler
SDErrorHandler
SDLogHandler
SDAccumCallback
SDApplyCallback
SDFileFormat
SDFileSupportType
SDFileCompatibility
SDSaveResultCode
SDhGlobalParam
SDParamType
SDParamQueryMode
SDhLattice
SDTokenType
SDRuleParseTokenType
SDConfidence
SDLatticeInfo
SDChoiceConfidencePredictors
SDChoiceInfo
SDTokenConfidencePredictors
SDToken
SDPartialToken
SDRuleParseToken
SDLatticeLink
SDChoiceTokenConfidencePredictors
SDChoiceToken
SDLmAdaptMode
SDLmClearLoadedType
SDhWeights
SDhTopicLmSlot
SDhFactoryCorrectiveLm
SDTopicWeight
SDWeightsInfo
SDLmScoreComponentType
SDDetailedLmScore
SDInitCheckRecord
SDInitTypeSize
SDhAdapterParamSet
SDhChannelParamSet
SDhConfidenceParamSet
SDhLatticeNBestParamSet
SDhLatticePostProbParamSet
SDhPrefiltererBuildParamSet
SDhPrefiltererSearchParamSet
SDhPronGuessParamSet
SDhSausageParamSet
SDhSearchParamSet
SDhSearchCrossLayerParamSet
SDhUserDeltaParamSet
SDParamSetContainerType
SDParamSetSpec
SDParamSetInfo
SDhParamSetHolder
SDParamSetHolderInfo
SDhParamSetParam
SDPrefiltererInfo
SDhPrefilterer
SDhPrefilterResult
SDProfileStyle
SDFunctionDemangleStyle
SDhRecognizer
SDPronGuessResultCode
SDRecognizerInfo
SDWordAlignInfo
SDhSegmentResult
SDSegmentationScores
SDPartialResultScore
SDhRepro
SDReproType
SDReproInfo
SDhRule
SDRuleItemType
SDRuleOperType
SDRuleInfo
SDRuleItem
SDRuleSpec
SDhSausage
SDSausageTokenType
SDSausageInfo
SDSausageToken
SDSausageChoiceToken
SDhSigProc
SDSigProcAdaptationDataType
SDSigProcInfo
SDhState
SDStateInfo
SDStateSpec
SDStateWordSpec
SDhTransducer
SDStateTransducerSpec
SDhUser
SDUserCovarianceType
SDUserInfo
SDhUtt
SDUttType
SDEnergyStatus
SDPitchStatus
SDFrameType
SDUttTimeStamp
SDUttInfo
SDUttFrameInfo
SDhUttFile
SDUttFileFormat
SDhVoc
SDCharType
SDVocTagSetType
SDVocInfo
SDhWord
SDWordSourceType
SDWordInfo
SDWordSpec
datapackDir
locales
name
modelVersion
languageId
language_model_set
acoustic_model_set
empty_delta_voc
pg_voc
general_voc
paramset_holder
textproc_model_set.model_voc
textproc_model_set.model_svc
textproc_model_set.lexicon
textproc_model_set.static_token
textproc_model_set.static_itn
EARAudioReader.m
Could not make Opus decoder: %d
Only expecting to get 1 Opus packet at a time, not %lu
i32@?0^I8^{AudioBufferList=I[1{AudioBuffer=II^v}]}16^^{AudioStreamPacketDescription}24
Opus ecoder gave us %d bytes bytes but we really only expected %d
Could not finish Opus decoding for offline only mode: %d
v24@?0@"NSData"8^B16
<LMstate>
 ...
warning: word probs for this context sum to 
 != 1 : 
too many words per sentence
bad n-best hyp format
%g %g %lu
could not create socket: 
could not bind socket: 
could not accept connection: 
fork failed: 
client 
: connection accepted
probserver ready
: send: 
_R_E_M_O_T_E_L_M_V=2
%s %g
%s %llu %u
%s command unknown
 probabilities served
nonword 
 has nonzero probability 
read() method not implemented
write() method not implemented
Failed to allocate memory
 at time 
Repetition
Length
The feature type '
' is not supported
src-ovs-file not present in the config
tgt-ovs-file not present in the config
Registered OVS Feature
OVS file '
' has 
regex-file not present in the config
Registered Repetition Feature
Regular expression file for repetition error detection'
Language '
' not supported for regular experssion in repetition feature
Repetition feature has read the regular expressions from file 
min-trans-len-percent not present in the config
max-trans-len-percent not present in the config
fertility-file not present in the config
Registered Length Feature
Fertility file '
The fertility file is should contain exactly two fields <word  fertility>
WRITE 
EMPTY 
CANCEL 
firstPassScaled
FST File empty
Write accessed states for 
utt-detect.
utt-detect
g-fst-file
Grammar FST filename
inv-g-fst-file
Inverted Grammar FST filename (overrides uninverted)
dynamic-class-lm-emission
If true, enable dynamic classLm emission
dynamic-class-lm-tag-list
THe dynamic class tags list seperated by comma
dynamic-class-lm-smallG-file
The prior for correspoding classLm tags. Each line should contain two columns, tag and log prob
static-class-lm-tag-list
The static tags lit seperated by comma. Add this will improve dynamic emission's latency
big-g-fst-weight-list
the interpolation weights for the FST LMs, use comma to separate multiple ones
max-total-extra-weight
Max first pass weight for limiting total weight of all extra LMs in the first pass - all-app LM and possibly one more app specific LM
big-g-nnet-weight-list
the interpolation weights for the NNLMs, use comma to separate multiple ones
silence-phone-list
List of silence phones.
phone-syms-file
Phone symbol table (text format) filename
enable-state-access-recording
Record which states in each FST are accessed, to allow for efficient reordering
recog-progress-freq
Frequency(in milliseconds) of reporting recognition progress
enable-endpointing
Enable server endpointing
streaming-conf-model-file
Filename for streaming confidence model file, format <WEIGHT> <FEATURE> (one per line)
streaming-conf-normstats-file
Filename for normalization statistics file for streaming confidence, format <FEATURES-LIST>
 <MEANS-LIST>
 <Standard-Deviations-LIST>
 (each line has a comma separated value for all features)
use-endpoint-for-utt-detect
Use endpoint configuration for doing utterance detection
autocomplete-partial-result
Allow partial result to hallucinate word even if speaker hasn't finished saying it yet. For example, Pneumonoultramicroscopicsilicovolcanoconiosis is recognized after a few syllables.
compute-trailing-silence-from-lattice
True if trailing silence should be computed from the lattice, otherwise use a separate two-state machine to compute trailing silence separately (set this parameter to false if a CTC trained acoustic model is being used).
enable-eager
Enable eager
use-partial-traceback-with-final-cost
For partial results, use traceback which taking final cost into account.
If non-empty: This is a key into the top-level 'spg' dictionary of the config file, and this decoder will run a SilencePosteriorGenerator configured from the corresponding dictionary value. If empty: This decoder will not run a SilencePosteriorGenerator.
run-system-combination-after-recognition
Run system combination at the end of recognition
rejected-left-context-tokens
List of tokens that don't work with left context. The decoder will reset the left context when it encounters one of these tokens.
inter-utterance-left-context-max-size
Maximum size for inter-utterance left context
Using pre-inverted grammar: 
Using regular grammar, need to negate in memory: 
gInvFst: input label is not sorted!
State access recording is enabled. This will slow decoding, so disregard performance.
No BigG FST or NNLM specified. Hint: This is a BigLm decoder.
Could not read FST LM interpolation weight info
The number of big FST LMs and the number of weights mismatch
Could not read NN LM interpolation weight info
The number of big NN LMs and the number of weights mismatch
Language model weight must be 1 when using a single LM
 but does not match 
the auto-determined silence label 
Failed to read phone symbol table file: 
No silence phones given!
ERROR 1: Cannot compute pause counts - word boundary info is missing
ERROR 2: autocomplete-partial-result is false (default), but word-boundary-int-file is missing.
Option 1: Set autocomplete-partial-result=true. This is *usually* done only for 'srch' and 'srch'-variant (WebSearch) decoder chains. This is required if the model doesn't have word-boundary-int-file.
Option 2: Keep using autocomplete-partial-result=false, but add a word-boundary-int-file. This is *usually* done for all other tasks.
needPauseCounts=true and autocomplete-partial-result=true is not supported yet.
Eager disabled because word-boundary-int-file is missing.
VoiceTrigger phrase word "
" not found in symbol table.
VoiceTriggerPhrase not set. This could lead to wrong endpointing that clips any payload after "Hey Siri"
Decoding beam: 
Finished initializing OnlineLatticeBiglmFasterDecoder.
.recorded_state_accesses
State access file [
] exists
State access file exists - not overwriting
location-specific component not supported in OnlineLatticeBiglmFasterDecoder
some FST/NN LMs failed to load
Using 
Created new decoder
uttDetector: 
endPointer: 
Feature extraction misconfigured
RaiseToSpeak
The dyanamic classlm tag prior file name is empty
SymbolTable::ReadText: Can't open dyanamic classlm tag file 
" in base symbol table
-start
-end
Failed to create FST from partial traceback
Failed to get traceback for utterance 
Time Taken to add timestamps for first pass results: 
eagerDecisionLog
MATCH
NOMATCH
eagerOutputLog
Failed to get recognition lattice
Average number of active tokens: 
Last frame processed 
EstimatedEpTruncation
EstimatedEndPointerTrailingSilence
Server side end pointer first triggered frame 
ProcessEmittingWallMs
ProcessEmittingCpuMs
ProcessNonemittingWallMs
ProcessNonemittingCpuMs
PruneActiveTokensWallMs
PruneActiveTokensCpuMs
Recognition cancelled
Ending audio for secondary audio buffers at utterance boundary
Recognition Paused
spg batch size > 1 unexpected because spg->config.frameByFrame should be set
spgSilenceFramesCount=
 spgSilencePosterior=
 spgSilenceProbabilityRaw=
Raw pauses = [
], words = [
Server side end pointer triggered frame 
ep-features
Reporting end point status=
Since endpointer is not enabled ignoring utterance 
Utterance detector triggered 
Utterance detector force triggered because current utterance has too many frames: 
Sending recognition progress report for frameCount=
 processedAudioDurationMs=
This should only be called if endPointer exists
rt-min
Approximate minimum decoding run time factor
rt-max
Approximate maximum decoding run time factor
max-total-forward-links
Max total allocated forward links at any time.
small-lm-prune-beam-diff
Pruning threshold for small LM before checking with big LM; smaller prunes more aggresively
early-endpoint-threshold
Threshold for early endpoint detection
pause-threshold-list
Comma-separated list for pause-threshold vector, which is used for determining the pause-counts vector that is an endpointer feature. pause-counts[n] is the number of interword pauses >= pause-threshold[n]. For example, pause-threshold=[3,30,100] and pauses of 90 frames and 100 frames will result in pause-counts=[2,2,1].
pauses-as-bool
Needs pause-threshold-list. If true, then pause-threshold vector is used to create a pause-counts vector,where pause-counts[n] is a boolean for asserting interword pauses >= pause-threshold[n]. For example, pause-threshold=[3,30,100] and pause of 90 frames will result in pause-counts=[1,1,0].
Delaying the endpointer trigger decision by the given amount of time (in msec), when specified in recog request.
use-nnet
Use nnet for utterance detection if true
left-context
Use left context for utterance detection if true
hard-max-utt-length-ms
If the utterance exceeds this length, force trigger the utterance detector. Ignored if <= 0. It is named 'hard' because there is a softer 'max-utt-length' config that does not trigger right away when exceeded.
same-state-transition-probability
Same state transition probablity
acoustic-evidence-deweighting-power
Acoustic evidence deweighting power
bigGFst: input label is not sorted!
count > 0
: Could not vm_allocate 
: Could not vm_deallocate 
 bytes of 
Error in ProcessNonemitting: no surviving tokens: frame is 
Ran out of forward links in storage
PruneActiveTokensFinal: pruned tokens from 
 links from 
 pruned_tok_frames_ 
 pruned_link_toks_ 
No tokens alive at end of file
No tokens alive [doing pruning].. warning first time only for each utterance
link_extra_cost is NAN
No tokens alive [doing pruning]
: not producing lattice.
GetRawLattice: NumStates 
 NumArcs 
 NumFinal 
Cannot undo PruneActiveTokensFinal(undoable=false)
UndoPruneActiveTokensFinal: restored tokens from 
Skipping compaction final pruning because has been done
Compacted in 
 ms 
tokens 
 and forward links 
Move the partial traceback to the end of word phone
Pause error - Consecutive word-end
Pause error - Word with missing startframe or endframe
Pause error - Word-end before word-begin
Pause error - Word spans into next word
Pause error - Found more word times than words
SplitRadixComplexFft called with invalid number of points 
Error: logn is out of bounds in SRFFT
State access recording requires ExpandedFST
gender
tokenizer output
an input to the AmbiguityAnnotatorBlock has not come from a TokenizerBlock
length
received 
-token source: ["
in hypothesis 
 is translated as "
 in sense 
limiting senses to 
 before limit
 after limit
found the sense "
" in 1-best
" in hypothesis 
tokenizer input
source span: 
 alternatives
no alternatives
source match
source index
source length
target match
target index
target length
formality
explicit
lexid
these source spans: 
 are ambiguous
no source spans are ambiguous
max_label_fraction > 0
chunk_size >= 0
Acoustic encoder has fixed input size which mismatches decoder; set chunk-size to 
states.size() == 1 && states[0] == 0
No frames to decode. Force decoding EOS.
blank_states.size() == nonblank_states.size()
labels.size() == 0
nonblank_state.size() == labels.size()
blank_state.size() == labels.size()
blank_state.size() + nonblank_state.size() == labels.size()
nonblank_outputs.front()->GetNumDims() == 2
nonblank_outputs.size() == labels.size()
blank_outputs.front()->GetNumDims() == 2
blank_outputs.size() == labels.size()
blank_outputs.front()->GetDimSize(1) == nonblank_outputs.front()->GetDimSize(1)
blank_outputs.size() + nonblank_outputs.size() == labels.size()
FindOrDie
missing key 
sourceApplication
requestApplication
category
score
sourceFramework
Contextual data: configuration file does not exist
Contextual data: Unknown exception
Contextual data: quasar exception: 
Contextual data: invalid contextual named entity data
Contextual data: missing category or language for Portrait named entity
Internal unknown exception
Internal C++ exception: %s
TransitionModel::TupleToTransitionState, tuple not found.
 (incompatible tree and model?)
ComputeDerivedOfProbs(): non-self-loop prob is 
<TransitionModel>
<Tuples>
<Triples>
</Triples>
</Tuples>
<LogProbs>
</LogProbs>
</TransitionModel>
Unknown component type: 
Unknown gradient normalizaiton type: 
Unknown matrix initialization type: 
please update to formatted name 
 ASAP, you used 
Unknown component type marker: 
Unknown gradient normalization marker: 
Unknown matrix initialization marker: 
Missing type: 
<Nnet>
</Nnet>
the L2 Norm clipping value must be greater than 0, you set 
either the gradient or the gradient norm data is not initialized
the gradient clipping value must be greater than 0, you set 
the gradient data is not initialized
the factor in RMSPROP must be [0, 1], you set 
The input dimension is not divisible by the output dimension
Not implmented! Should not be called!!!
Non-matching dims! Input batch size: 
 output dim : 
Requested output for invalid unit: 
; total units = 
Relaxation factor must be positive; found: 
<RelaxFactor>
<BlockDims>
 (BlockDims)
Total block dimensions and output dimension mismatch
<DropoutRetention>
 (DropoutRetention)
<Alpha>
  frame_offsets 
<ReadVector>
<BuildVector>
</BuildVector>
 (ReadVector|BuildVector)
Error parsing <BuildVector>
Not implemented!
Unity component doesn't expect any tokens
<DuplicateStart>
<DuplicateSize>
<NumDuplicates>
 (DuplicateStart|DuplicateSize|NumDuplicates)
Requested duplication doesn't match the output and input sizes
Duplication parameters out of range
 shift_data
  shift_data_grad
<InitParam>
 (InitParam|LearnRateCoef|GradientNormType|MaxGrad)
 scale_data
  scale_data_grad
 (InitParam)
<VisibleType>
<HiddenType>
<VisibleBiasMean>
<VisibleBiasRange>
<HiddenBiasMean>
<HiddenBiasRange>
<VisibleBiasCmvnFilename>
 Typo in config?
 (VisibleType|HiddenType|VisibleBiasMean|VisibleBiasRange|HiddenBiasMean|HiddenBiasRange|ParamStddev|VisibleBiasCmvnFilename|RandomSeed)
bern
Bernoulli
gauss
Gaussian
Wrong <VisibleType>
Wrong <HiddenType>
Initializing from <VisibleBiasCmvnFilename> 
Unknown type 
Nonmatching dims, component:
pos_vis
pos_hid
neg_vis
Mismatch between pos_vis and neg_vis variances, 
danger of weight explosion. a) Reducing weights with scale 
 b) Lowering learning rate to 
 [pos_vis_std:
,neg_vis_std:
'inf' in 
'nan' in 
Forcing the variance to be non-negative! 
->0.0
<MSDims>
 (MSDims)
this implementation only models the strict recurrent component, i.e, it requests the input 
and output dimensions be the same,  you set input/out dimension to 
<Nonlinearity>
 (Nonlinearity|ParamStddev|BiasMean|BiasRange|LearnRateCoef|BiasLearnRateCoef|MaxNorm|RandomSeed|MaxGrad|InitTransformType|GradientNormType)
 bias
  linearity_grad is uninitialized
  bias_grad is uninitialized
Unknown nonlinearity type: 
 filters: 
 bias: 
<PatchDim>
<PatchStride>
 (ParamStddev|BiasMean|BiasRange|PatchDim|PatchStep|PatchStride|MaxNorm|GradientNormType|MaxGrad|RandomSeed)
num_splice 
num_patches 
filter_dim 
num_filters 
<PoolStride>
<Scale>
 (PoolSize|PoolStep|PoolStride|Scale)
 (PoolSize|PoolStep|PoolStride)
<PoolXLen>
<PoolYLen>
<PoolXStep>
<PoolYStep>
 (FmapXLen|FmapYLen|PoolXLen|PoolYLen|PoolXStep|PoolYStep)
num_fmaps 
Invalid component parameters
<SpliceLength>
<RowStride>
<TimeLength>
nested_network {
nested_gradient {
<NestedNnetFilename>
<NestedNnetProto>
<LearnRateFactor>
  (offset,weights) : 
  lr-coef 
  (offset,weights_grad) : 
<FeatureDim>
<CentralOffset>
<PoolWeight>
<Normalize>
 (FeatureDim|CentralOffset <vec>|PoolSize <vec>|LearnRateCoef|Normalize)
Initializing from pool-weight vector
<FrameOffset>
<FrameWeight>
the multi subbatch version for this class is not implemented yet
the ParallelComponent has history size 
 , but the input history data has dimension 
the network has history size 
</NestedNnetFilename>
</NestedNnetProto>
, typo in config?
 (NestedNnetFilename|NestedNnetProto)
<NestedNnetCount>
<NestedNnet>
</ParallelComponent>
Two different learning rates: 
nested_network #
nested_gradient #
nested_propagate #
nested_backpropagate #
<NumComponents>
The input dimension is not divisible by the number of components
The output dimension does not match the dimension of individual component
<ComponentWeight>
</InterpolationComponent>
 CompressedWordVec table
 WordVec table
 we don't save intermediate gradient
<FillerSymbolId>
 (ParamStddev|LearnRateCoef|VocabSize|RandomSeed|InitTransformType|GradientNormType|MaxGrad)
invalid vocabulary size 
it doesn't make sense to initialize the word vec as an identify matrix
RMSPROP is not implemented in word embedding yet
not implemented
, bias-lr-coef 
 (ParamStddev|BiasMean|BiasRange|LearnRateCoef|BiasLearnRateCoef|InitTransformType|RandomSeed|GradientNormType|MaxGrad)
it does not make sense to do RMSPROP in this component
 CompressedWordTrans table
<AffineTransform>
<LinearTransform>
<Quantized8BitLinearTransform>
<Quantized16BitLinearTransform>
<SharedNceComponent>
<ConvolutionalComponent>
<ConvolutionalMaxPoolingComponent>
<Quantized8BitConvolutionalMaxPoolingComponent>
<Quantized16BitConvolutionalMaxPoolingComponent>
<Convolutional2DComponent>
<Quantized8BitConvolutional2DComponent>
<Quantized16BitConvolutional2DComponent>
<LstmComponent>
<Quantized8BitLstmComponent>
<Quantized16BitLstmComponent>
<GatedRecurrentUnit>
<SimplerSimpleRecurrentUnit>
<Recurrent>
<BidirectionalRecurrentComponent>
<WordVecComponent>
<FofeWordVecComponent>
<WordMultiVecComponent>
<CompressedWordMultiVecComponent>
<CompressedWordVecComponent>
<FixedAttentionComponent>
<MovingAttentionComponent>
<GlobalAttentionComponent>
<GlobalRecurrentAttention>
<ScaledDotAttention>
<MultiHeadAttention>
<SupervisedMultiHeadAttention>
<SelfAttention>
<AverageAttention>
<LayerNorm>
<Softmax>
<LogSoftmax>
<BlockSoftmax>
<MultiSoftmax>
<RelaxedSoftmax>
<Sigmoid>
<Tanh>
<Dropout>
<Maxout>
<Rectified>
<ExponentialLinear>
<ScaledExponentialLinear>
<PNorm>
<Rbm>
<Splice>
<Desplice>
<Copy>
<CnnRearrangeComponent>
<PaddingComponent>
<Padding2DComponent>
<AddShift>
<Rescale>
<QuantizedAffineTransform>
<Quantized16BitAffineTransform>
<NormalizeComponent>
<KlHmm>
<AveragePoolingComponent>
<AveragePooling2DComponent>
<MaxPoolingComponent>
<MaxPooling2DComponent>
<SentenceAveragingComponent>
<FramePoolingComponent>
<ParallelComponent>
<Duplicate>
<Identity>
<TemporalMaxPooling>
<InterpolationComponent>
<CompressedWordTransComponent>
<VectorwiseQuantized8BitAffineTransform>
<VectorwiseQuantized16BitAffineTransform>
ClipValue
ClipL2Norm
Rmsprop
Identity
Uniform
Gauss
  linearity is vectorwise quantized
sentencepiece encoder input
sentencepiece encoder output
sentencepiece decoder input
sentencepiece decoder output
subword confidences
decode
decode-api
decode-space
Unknown sentence piece action: 
SentencePiece error while loading file '
Dropping confidence scores in sentence piece encoding
firstleg 
Inconsistent sentencepiece decoding length, expected 
 got 
Inconsistent token sequence: previous end = 
, current start = 
Config Version is not high enough for index rule denumeration
Enumeration rules not configured
The default tag for denumeration
Config Version is not high enough for denumeration
LmeWordTagger not used
Unsupported number of lme-word-taggers
Unsupported lme-word-tagger
lme-word-tagger
index-rule-tagger
rules
index
default-tag
Invalid string: %@
Failed to perform UTF-8 encoding on string: 
Topological sorting of state-level lattice failed (probably your lexicon has empty words or your LM has epsilon cycles; this  is a bad idea.)
Minimizing lattice with self-loops (lattices should not have self-loops)
Largest equivalence group (using hash) is 
, minimization might be slow.
Removing 
 states.
warning: maximum tagged index lowered to 
maximum number of tagged words (
) exceeded
maximum number of tags (
%s%c%s
%c%s
QuasarC
[QSR] FATAL %s
[QSR] ERROR %s
[QSR] WARN %s
[QSR] PRODINFO %s
[QSR] INFO %s
[QSR] DEBUG %s
[QSR] TRACE %s
Token(
en-like
zh-like
algorithm
Algorithm name. Possible values: en-like, zh-like
Invalid algorithm
Index error: [
-derived
Tag with multiple words: "
" for "
\contact-first-phonetic
\contact-last-phonetic
\contact-first-derived
\contact-last-derived
syms
<sigma>
<rho>
<phi>
lattice-
wmapper-
rpathcounter-
mapper-cd-
 symbol '
' missing from target symbol table.
Target symbol table missing: 
 input symbols.
 output symbols.
Push: pushing type is set to 0: 
pushing neither labels nor weights.
ShortestDistance: Weight needs to be right distributive: 
ShortestDistance: first_path option disallowed when 
Weight does not have the path property: 
Reweight: Reweighting to the final states requires 
Weight to be right distributive: 
Reweight: Reweighting to the initial state requires 
Weight to be left distributive: 
right_gallic_
right_gallic
left_gallic
ArcMapFst: non-zero arc labels for superfinal arc
StringWeight::Divide: only right division is defined 
for the right string semiring
factor_weight
FactorWeightFst: factor mode is set to 0: 
factoring neither arc weights nor final weights.
FromGallicMapper: unrepresentable weight: 
 for arc with ilabel = 
, olabel = 
, nextstate = 
CompositeWeightWriter: 
FLAGS_fst_weight_separator.size() is not equal to 1
FLAGS_fst_weight_parentheses.size() is not equal to 2
Epsilon
BadString
SigmaMatcher: bad match type
SigmaMatcher: 0 cannot be used as sigma_label
SigmaMatcher:: bad match type: 
SigmaMatcher::Find: bad label (sigma)
RhoMatcher: bad match type
RhoMatcher: 0 cannot be used as rho_label
RhoMatcher:: bad match type: 
RhoMatcher::Find: bad label (rho)
resize overflow
sparsehash: FATAL ERROR: failed to reallocate %lu elements for ptr %p
insert overflow
DeterminizeFst: 
a state table can not be passed with transducer input
StringWeight::Divide: 
only explicit left or right division is defined 
for the 
 semiring
restricted_string
StringWeight::Plus: unequal arguments 
(non-functional FST?)
 w1 = 
 w2 = 
EmptySet
BadSet
gallic_
StringWeight::Divide: only left division is defined 
for the left string semiring
_from_gallic
GallicToNewSymbolMapper: unrepresentable weight: 
UNKNOWN
INVALID
RAW_PHRASE_COUNTS
PROCESSED_PHRASE_COUNTS
PROCESSED_NGRAM_COUNTS
DECODING_READY
number of start/end LME class tags doesn't match: 
cannot find 
 in the vocab file
 LME classes, their IDs are not contiguous
seeva-step
seeva inference encoder graph file
seeva inference decoder graph file
num-encoder-states
number of encoder states
num-decoder-states
number of decoder states
align-state-list
alignment state indices in the decoder states
vocab-file
the vocab file for the model output token
vocab-is-binary
vocab file is binary
model-format-version
model format version
feature transform file
lme-start-tag-list
a list of LME start tag
lme-end-tag-list
a list of LME end tag
speller-fst-file
the speller FST file
Inverted small grammar FST filename
lm-unknown-word
the unknown word (OOV) in the LM
the lm beam should be no less than the model beam, 
loaded an inverted G, make sure the speller FST is weighted
do not have an inverted G, make sure the speller FST is unweighted
spellerFst: input label is not sorted
cannot find the OOV word 
 in the symbol table
Finished initializing OnlineSeevaStepBigLmDecoder
/cpu:0
lme-score-scale
scale the LME FST score when LME is active
nonlme-score-scale
scale the nonLME arc score when LME is active.
lm-score-scale
scale external LM score when available
lm-miss-penalty
penalty for missing LM arc
lm-miss-final-penalty
penalty for missing LM arc in final
lm-beam
use this beam value for the external LM
lme-beam
use this beam value for the LME arcs
length-penalty-lm
the length penalty value when using external LM
Custom pronunciation file is malformed: 
lexicon
Custom pronunciation file contained no lexicon field
lexeme
grapheme
phoneme
alias
Custom pronunciation file was missing fields
 (contains no phonemes)
 (contains no graphemes)
read error
void boost::property_tree::xml_parser::read_xml_internal(std::basic_istream<typename Ptree::key_type::value_type> &, Ptree &, int, const std::string &) [Ptree = boost::property_tree::basic_ptree<std::string, std::string>]
/AppleInternal/Library/BuildRoots/b958ad6d-2c13-11ed-a8d5-b25c5e9b9057/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator16.1.Internal.sdk/usr/local/include/boost/property_tree/detail/xml_parser_read_rapidxml.hpp
expected <
unexpected end of data
expected element name
expected >
expected attribute name
expected =
expected ' or "
expected ;
invalid numeric character entity
<xmlattr>
<xmltext>
<xmlcomment>
online-las-beam-search
0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!"#$%&'()*+,-./:;<=>?@[\]^_`{|}~
dictation-languages
current-dictation-language
was-language-toggled
multilingual-keyboard-languages
keyboard-convo-language-priors
keyboard-global-language-priors
previous-message-language
global-last-keyboard-used
dictation-language-priors
bitmap-color
The value of the 
 in region 
 has to be 
 but is 
 has to be a positive integer but is 
do-not-translate
Metainfo does not contain any alignment spans
error parsing Json >
Metainfo does not contain any alignment projections
 ||| 
error parsing Json <
Not caching word with too many prons: "
" has 
 prons
Skipping illegal word: "
Encoding should be either QsrText or NotEncoded
Skipping illegal word.
: nWords = 
: orthography = 
: nProns = 
: pron = 
Ignoring corrupted prons: orthography = 
, nProns = 
Duplicate key is being added to enumerationTypeMap with key=
Invalid write version choice: 
, it is now set to: 
LME STREAM WRITE 
: About to write FSTs
: templateName = 
: <FST>
: done.
formatVersion=
Failed to read LmeData stream. Incorrect version: 
Error reading LmeData stream: 
LME STREAM DUMP [Body]
: g2pModelVersion = 
: symTableFirstKey = 
: symTableLastKey = 
: fstSize = 
: phoneSetVersion = 
Expected asset path does not match LME Data's asset path. LME Data should be regenerated. Quitting deserialization early.
expected assetPath=
deserialized assetPath=
LME STREAM DUMP [Pron Cache]
: About to read FSTs
Failed to deserialize symbol table from LME data stream. Quitting deserialization early.
: <symTable:
 symbols>
LME memory_overhead 
 fsts 
LME STREAM DUMP DONE 
LME data stream successfully read with 
 symbols; 
) ~ "
LME STREAM DUMP         
LME data stream version is old, but still supported. Current write version is 
 and stream version is 
tokenMapToStream dump, key=
 value=
: nMapSize = 
: key = 
 value = 
basicTypeMapToStream dump, key=
Matrix::Read, size mismatch 
Can not map into the wrong matrix data type
: Seeking failed
: Reading whole matrix failed
: Reading a matrix row failed
: Seek for padding 
: Expected "[", got EOF
: Expected "[", got "
Matrix has inconsistent #cols: 
 vs.
 (processing row
Failed to read matrix from stream.  
Wrong sized arguments
Wrong size of arguments.
index item is bigger than the voc size 
index 
 is too big for matrix that has rows = 
Failed to write matrix to stream: stream not good
Failed to write matrix to stream
 [ ]
AddConfigOverride() can only be called before init()
speaker-code-training
speaker-code-training.
mux.
embedded-mlock
Initialized SpeechRecognizer with config 
getActiveConfiguration called before init.
setActiveConfiguration called before init.
Cannot call setActiveConfiguration while recognition is running.
SpeechRecognizer must be in initialized state before you call runAsync(). 
Hint: Make sure you call waitForAsyncRecogToFinish() before calling runAsync() again.
Utterance concatenation should only be used with utterance detection
No primary buffer was set! 
Hint: If multiple decoder chains are active, one of them should do system combination.
Running runSyncAndMarkEndOfRun() in separate thread
Cancelling recognition
This function can only be called in Recognizing or Cancelling state
finalResultTokens
finalResultTokensV2
sessionId
userId
isFinal
cache
geoLocationStatusUponRunAsync
Symbol table list passed to runSync() must start empty
Invalid recognition request parameters
Speaker code training is enabled, going to cache features and labels as training data
Created OnlineFeatInputItf chain
Frontend and SPG frame durations differ: 
End of recognition.
Pause/Resume: processedUtteranceEndedAfterPause: 
Pause/Resume: Utterance generated after pause call
Pause/Resume: Utterance generated after resume call
Start recognition of a new utterance...
Ran out of forward link storage during decode: 
Ran out of token storage during decode: 
Reporting empty result due to thrown exception during decode
far_field
SpeechRecognizer must be initialized before calling runSync()
Symbol table list passed to runSyncUtterance() must start empty
uttNum
jsonConfigFilePath
taskType
deviceId
recognizerComponents
farField
enableWhisperDetection
numLmeDataStreams
utteranceConcatenation
epExtraDelay
InputOrigin
highPriority
LME DataStreams=
 samplingRate=
 taskType=
 deviceId=
 enableWhisperDetection=
 endpointerExtraDelay=
 inputOrigin=
 highPriority=
You have provided a reference transcript, which will trigger error-blaming (if specified in 
the config file). This is an EXPERIMENTAL feature that uses lots of memory and incurs lots of 
latency!
runSync:initTime
There is no decoder which affects recognition, this must be a configuration error.
eagerRequested
Eager disabled: not supported by first-pass decoder: 
Eager disabled: silence posterior required but not available: 
Eager disabled: not supported by second-pass decoder: 
eagerUsed
Waiting for first valid feature frame of first utterance...
uttDetectAbort
Rejected
Pause/Resume: Ignoring any further processing of the utterance with uttStartFrame=
Recognition is final and successful, trigger training
Recognition is final but not successful, skip training
geoLocationStatusUponRequestComplete
recognitionStatus
Training is not enabled, skip training
Result stream does not exist, skip training.
Average confidence: 
 is below threshold: 
, skip training
Feature buffer is null or reversed pdf is empty, skip training.
Populating training data, original feature size: 
, alignment size: 
Reaches the end of labels
Training data is populated and shuffled, aligned data size: 
, silence frame count: 
Training is not enabled, not concatenating labels.
Recognition is not final, concatenating alignments, feature buffer size: 
, label buffer size: 
, pdfs size: 
, num frames: 
Label concatenation is completed, label buffer size: 
audioReadTime
featureComputeTime
whisperScore
whisperDetected
utteranceLength
audioEndTime
utteranceEndTime
timeElapsedSinceRunAsyncCall
timeElapsedSinceRunSyncCall
recognizer-components
DidConfNetCombination
ConfNetWaitTimeMs
ConfNetworkCombinedNbestSourceID
ConfNetworkCombinerStartTimeMs
LastWordClipped
WordAligned
Write results got a NULL lattice
NullLattice
Recognition is going to fail because of NULL lattice. Padding labels to align with features
PartialResultsAvgLagMs
PartialResultsToggleCount
FasterPartialResultsAvgLagMs
FasterPartialResultsToggleCount
Shortest path cost: 
lmeStatus
jitLmeUsed
aotLmeUsed
Matched trigger phrase: 
, with index: 
Lattice was not NULL, but failed to generate any choices
NoChoices
RecogThreadCpuTimeMs
EosToPreItnMs
lm_interp_weights
Pause called but recognizer in state:
, do nothing..
Pause: utterance detection is disabled or utterance concatenation is enabled, do nothing.. 
Pause: pausing the recognizer.
Resume: The recognizer was not paused, so nothing to resume, ignoring the call.
Resume: utterance detection is disabled or utterance concatenation is enabled, do nothing.. 
Resume: resuming the recognizer.
Unable to json at path lme-create from json
word-syms-map-file
Unable to read symbol table from json at path lme-create.word-syms-map-file
Initialized symbol table
training-nnet-file
Training neural network path
max-feature-cache-size
Max feature cache size for training
learning-rate
Learning rate of the training
training-nnet-version
Training neural network version
generic-speaker-code
Generic speaker code
initialize-option
Options to initialize training speaker code, 1 is generic speaker code, 2 is all-zeros
recognition-interval
The threshold to apply trained speaker code in recognition
supported-tasks
Supported tasks for training. Only the configured tasks will run training at the end of recognition
The interval which will be used for updating the speaker code for training, default is 64
Training mini batch size, default is 1
enable-continuous-training
The flag to enable continuous training, default is false
initial-size
Speaker code dimension. As speaker code is one-dimentional vector, it's also the number of rows
If average confidence of all tokens is below the threshold, the utterance will be dropped, default is 0
silence-frame-ratio
The ratio of silence frames, num(silence_frame) = min(ratio * num(valid_speech_frame), num(silence_frame)), default is 0
update-inference
If it is true, the inference speaker code used in recognition will be updated in training, otherwise inference speaker code is always the generic one, default is false
shared-tags
sharedTags: 
Text sanitizer initialization failed 
\room-first
\room-middle
\room-last
\house-first
\house-middle
\house-last
\zone-first
\zone-middle
\zone-last
\group-first
\group-middle
\group-last
\device-first
\device-middle
\device-last
\scene-first
\scene-middle
\scene-last
\deviceNames-first
\accessory-first
\artist-first
\appMusicArtistName-first
\custom_words-first
\playlist-first
\podcastTitle-first
\appPlaylistTitle-first
\appAudiobookTitle-first
\appShowTitle-first
thread constructor failed
unique_lock::unlock: not locked
unique_lock::lock: references null mutex
unique_lock::lock: already locked
LibLM encountered a fatal error.
TRACE
tmpdir.XXXXXX
Bad path
Bad stream
openProtected() failed: 
fsync() failed: 
close() failed: 
rename() failed: 
FTM second pass decoder chain failed
FTM chain must have at least two elements
FTM Decoder must be derived from OnlineLatticeBiglmFasterDecoder
Second pass decoders must support eager
ftm-combination
ftm-chain
Decoder chain to select for LRNN FTM computation.
overwrite
Overwrite the main FTM score with the FTM score from the subchain
Invalid SilencePosteriorGeneratorConfig name "
Invalid recognizer specifier "
", must have 3 components
Parallel loading is enabled
SpeechRecognizerModelLoader: (ANE) Model will not be unloaded
spg.
 references spg that does not exist: 
setActiveConfiguration(
), loaded: 
 frontends, 
 decodables, 
 decoder chains, 
 SPG configs.
Value 
 not found in active configuration.
rule-config-file
rule-type
Rule config file does not exist or it is a directory. File path = 
Read rule config file = 
Failed to parse config file = 
rule: 
 is not valid in file with locale: 
clone-from field is invalid. Rule config file path=
clone-from
pre-alt-gen
post-alt-gen
post-combine
alt-gen
whole-string-rules
We do not support step = 
Please check config file for regex rule, step name = 
Skip empty input text = 
Failed to generate enumeration in step = 
Enumeration is calculated already.
more than 
 fields per line
 words in hyp
(%lf)
bad Decipher score: 
badly formatted hyp
 tokens in hyp
bad acoustic score: 
bad LM score: 
bad word count: 
warning: hyp contains zero prob words: 
warning: hyp contains OOV words: 
failed to open database file
connected to database
SELECT column, dictionary, max_length FROM decompress
No decompression info found for phrasebook 
 error: 
SELECT output, length(output), metadata, length(metadata) FROM phrasebook WHERE input=? ORDER BY rowid LIMIT ?
SQLITE Querying error: 
Could not prepare SQLite Statement
1.2.11
SQLite Binding error: 
metadata
Unknown column provided for decompression.
Could not open decoding-graph FST 
Reading FST: error reading FST header.
FST with arc type 
 not supported.
const
Reading FST: unsupported hammer FST type: 
Error reading FST (after reading header).
Hammer didn't change any text. Therefore returning the original input.
Number of outputs (n) cannot be less than 1.
, start silence: 
Empty tokenName
Pre-text-proc Choice[
Post-text-proc Choice[
Pre-sanitization: 
Post-sanitization Choice[
modelFile doesn't exist, or it's a directory: 
Key not found: 
 configured key='
' prefix=
Empty post-itn-hammer rule
, jsonConfigPath=
 configured
itn2 configured key='
ignogre itn2 config of 
, what we are looking for is 
Failed to configure itn2
Ignore unknown node text-proc.
Key does not match 'locale' or 'locale::keyboard': 
Locale cannot include leading/trailing whitespace: 
Keyboard cannot include leading/trailing whitespace: 
Locale with separator '
' not supported: 
Keyboard with separator '
Locale=
 should only be used with keyboard=*
Keyboard=* is reserved for internal use
There are itn2 models, but cannot find one for locale=
empty ITN input tokens
empty sanitizer input tokens
empty postItnHammer input tokens
locale=
 keyboard="
 postItnHammer="
 emojiHammer="
emoji-hammer
default
sanitizer
itn2
lattice-proc
spokenemoji|
ConstFst::Read: Alignment failed: 
ConstFst::Read: Read failed: 
Could not align file during write after header
Could not align file during write after writing states
ConstFst Write write failed: 
Inconsistent number of arcs observed during write
help
[]~#^_-+=:.,/
'\''
"`$\
Invalid parameters supplied to OnlineLdaInput
Invalid parameters supplied to OnlineTransformInput
end_pad_ > 0
input.NumRows() <= strict_batch_size + total_batch_context_
NaN in features
inf in features
Batch 
Must use penultimate-compatible AM with silence nnet
Frames consumed by model (
) does not match frames added by batchwise splicing (
). Hint: Are batch-left-context and batch-right-context correct for this model?
orig_input_size + frames_padded - total_batch_context_ == output->NumRows()
output->NumRows() == sil_post->NumRows()
NaN in NNet output
inf in NNet output
input.NumRows() <= strict_batch_size_
There is extra input, rows=
, cols=
extra_input_.NumRows() == 1 && feats.NumRows() >= 1
orig_input_size + frames_padded == output->NumRows()
(!has_sil_post_ && next_sil_post.NumRows() == 0) || (has_sil_post_ && next_features.NumRows() == next_sil_post.NumRows())
Unexpected point reached in code: 
possibly you are skipping frames?
Attempting to get a discarded frame.
Attempt get frame without check its validity.
<blk>
keyword-spotting
The threshold for the keyword score
frame-offset
frame offset
do-viterbi
apply viterbi for keyword detection
tokens-file
symbole table file
keyword-list-file
list of keywords and their corresponding tokens sequence
Number of frames that get decoded in one go
do-batch-reset
Reset scores after each batch result
do-top-result-only
Only return the best keyword score
do-moving-avg
Performs a moving average of the scores
moving-avg-window-size
Set the window size for the moving average
Number of labels: 
Blank label "
Blank label index: 
Invalid keyword-phrase line
Adding keyword: 
Symbol "
Number of keywords: 
Error: Both, Viterbi and moving average decoding enabled, select only one
Moving average window size: 
keyword mismatch 
Error: no utterance features were provided
No keywords found.
Start of batches
unmatched  posterior matrix dimension and number of symbols
empty posterior matrix
About to process 
 frames in batch
KWD 
End of batch
End of batches
keyword detected
no keywords detected
keyword search finished with 
 detected hypothesis.
Missing voicing regions in audio analytics
Voiced region start: 
 end:
Voicing threshold=
 mean=
 stddev=
the base lexicon is empty
the base symbol table is empty
the number of templates in the user data is zero
insufficient number of word disambiguation symbols in the graph, 
 . deleting offending pronunciations.
number of word symbols before LME: 
User-provided LME symbol table clashes with base symbol table.
number of word symbols after LME: 
LME: number of disambiguation symbols is 
the optional silence 
 is not defined in the symbol table
the word boundary string can only have non-space characters, you set it (
number of prons, pre/post-compound:
 #comp_words:
can not find symbol 
 in the input symbol table
LME: no available user data for 
-th template
LME: detected a zero frequency - ignoring this word
not in the compound mode, and the number of words in this entry is more than 1, use CreateFst() instead
remove excessive homophone prons without removing words, rebuild the FST now
has to remove 
 words, rebuild the FST now
LME: spent 
 seconds on creating the compound lexicon for 
 items
the output symtable is not empty
 before calling createOnlineFeInput().
subsample
stride
Take every n'th feature, for this value of stride(with negative value, repeats each feature n times)
' cannot occur at the first stage of feature-extract
Building FeatureExtractor 
cmvn
fbank
fbankwithpitch
mfcc
nnet-forward
nnet-forward-skip
splice
transform
cache-input
compute-ahead-input
fbank-with-audio-analytics
append
Unknown feature-extract type "
Finished reading matrix file 
Minumum CMN window used at start of decoding (adds latency only at start). 
init-cmvn-stats-file
Stats File for warm-start online CMVN
prior-count
number of frames used from prior CMVN stats file
buffer-output
Use OnlineBufferingInput
cmvn-window
Window in frames for running average CMVN computation
min-cmvn-window
Minumum CMVN window used at start of decoding (adds latency only at start). 
low-watermark
Low watermark (in number of frames) for audio buffer read. Ignored if <= 0.
resample-freq
The frequency to resample to.
resample-cutoff-hz
The cutoff for the filter for resampling the audio
resample-num-zeros
Controls sharpness of filter.
' can only occur at the first stage of feature-extract
analytics-sample-frequency
analytics-frame-length
analytics-frame-shift
analytics-preemphasis-coefficient
Coefficient for use in signal preemphasis (deprecated)
min-f0
min. F0 to search for (Hz)
max-f0
max. F0 to search for (Hz)
soft-min-f0
Minimum f0, applied in soft way, must not exceed min-f0
penalty-factor
cost factor for FO change.
lowpass-cutoff
cutoff frequency for LowPass filter (Hz) 
resample-frequency
Frequency that we down-sample the signal to. Must be more than twice lowpass-cutoff
delta-pitch
Smallest relative change in pitch that our algorithm measures
nccf-ballast
Increasing this factor reduces NCCF for quiet frames
nccf-ballast-online
This is useful mainly for debug; it affects how the NCCF ballast is computed.
lowpass-filter-width
Integer that determines filter width of lowpass filter, more gives sharper filter
upsample-filter-width
Integer that determines filter width when upsampling NCCF
frames-per-chunk
Only relevant for offline pitch extraction (e.g. compute-kaldi-pitch-feats), you can set it to a small nonzero value, such as 10, for better feature compatibility with online decoding (affects energy normalization in the algorithm)
simulate-first-pass-online
If true, compute-kaldi-pitch-feats will output features that correspond to what an online decoder would see in the first pass of decoding-- not the final version of the features, which is the default.  Relevant if --frames-per-chunk > 0
recompute-frame
Only relevant for online pitch extraction, or for compatibility with online pitch extraction.  A non-critical parameter; the frame at which we recompute some of the forward pointers, after revising our estimate of the signal energy.  Relevant if--frames-per-chunk > 0
max-frames-latency
Maximum number of frames of latency that we allow pitch tracking to introduce into the feature processing (affects output only if --frames-per-chunk > 0 and --simulate-first-pass-online=true
analytics-snip-edges
If this is set to false, the incomplete frames near the ending edge won't be snipped, so that the number of frames is the file size divided by the frame-shift. This makes different types of features give the same number of frames.
pitch-viterbi-window
Number of frames over which we want to run viterbi for computing pitch.
lda-matrix-file
LDA matrix filename
Number of frames of left context
right-context
Number of frames of right context
no-softmax
No softmax on MLP output (or remove it if found), the pre-softmax activations will be used as log-likelihoods, log-priors will be subtracted
apply-log
Transform MLP output to logscale
batch-left-context
Number of frames of left context to prepend to the batch as extra rows
batch-right-context
Number of frames of right context to append to the batch as extra rows
strict-batch-size
Batch size applied just for this extractor. Ignored if <= 0. Unlike feature-read.batch-size, which is just a hint, this batch size is so strict that even the last batch will be padded to exactly this size with copies of the last frame if the last batch is too small. (The padding is removed from the output). Excludes context frames (actual batch size is strict-batch-size + batch-left-context + batch-right-context).
zero-pad
Zero pad the features, instead of last frame padding, to reach the strict-batch-size requirementvalid only when strict-batch-size is also specified
append-pad-info
Append the pad info as an additional row in the input matrixThe first element of the appended row is the number of padded rows, which excludes this extra appended rowvalid only when strict-batch-size is also specified
append-context-size
Append the context matrix along with the input. Ignored if <= 0Add the specified amount of rows as context to the input features and one additional row which has the batch number. The context is obtained from last N rows of output of the previous inference.Context is ignored by the model for the first inference i.e. batch num is 0valid only when strict-batch-size is also specified
strict-batch-sizes
Defines an array of 3 sizes - [ModelInterfaceSize, FirstBatchSize, SubsequentBatchSize]ModelInterfaceSize: defines the size of input expected by the modelFirstBatchSize: defines the batch size used for 1st inference, will be padded with zeros                 if less than than ModelInterfaceSizeSubsequentBatchSize: defines the batch size used for the rest of the inferenences, will be                     padded with zeros if less than than ModelInterfaceSize(The padding is removed from the output)This feature is added support streaming Acoustic FTM and Hey Siri checker using the same model
cannot set both strict-batch-size & strict-batch-sizes
strict-batch-sizes needs 3 sizes
Model input size must be greater than batch sizes
Nonsense option combination : --apply-log=true and --no-softmax=true
Option --class-frame-counts has to be used together with 
--no-softmax or --apply-log
Used --apply-log=true, but nnet 
 does not have <softmax> as last component!
Batch size applied just for this extractor. Ignored if <= 0. Unlike feature-read.batch-size, which is just a hint, this batch size is so strict that even the last batch will be padded to exactly this size with copies of the last frame if the last batch is too small. (The padding is removed from the output). Includes skipped frames (neural network sees `ceil(strict-batch-size / (1 + skip-frames))` frames at a time.
default-speaker-code
If the nnet requires speaker code as input and speaker code is not set by request data, the default one will be used as a backup
Set inference speaker code to: 
Set inference speaker code to be default: 
File for any linear (or affine) feature transformation
cache-data
If true, cache all data (e.g. fbank feats)
cache-analytics
If true, cache all analytics data
max-queued-frames
Max number of frames to compute ahead. Use this to limit memory. Note this is not a strict limit: If we are at or above the limit, we will wait to fetch the next batch. If we are under the limit, we will fetch the next batch, which may cause us to exceed the limit. Values <= 0: no limit Value = 1 (default): compute ahead only 1 batch
Creating ComputeAheadFeatInput with maxQueuedFrames=
delta-order
Order of delta computation
delta-window
Parameter controlling window for delta computation (actual window size for each delta order is 1 + 2*delta-window-size)
Add an extra dimension with energy to the FBANK output.
Floor on energy (absolute, not relative) in FBANK computation
If true, put energy last.  Warning: not sufficient to get HTK compatible features (need to change other parameters).
use-log-fbank
If true, produce log-filterbank, else produce linear.
cache-energy
If true, cache energy values.
Frequency that we down-sample the signal to.  Must be more than twice lowpass-cutoff
pitch-scale
Scaling factor for the final normalized log-pitch value
pov-scale
Scaling factor for final POV (probability of voicing) feature
pov-offset
This can be used to add an offset to the POV feature. Intended for use in online decoding as a substitute for  CMN.
delta-pitch-scale
Term to scale the final delta log-pitch feature
delta2-pitch-scale
Term to scale the final 2nd-order log-pitch feature
delta-pitch-noise-stddev
Standard deviation for noise we add to the delta log-pitch (before scaling); should be about the same as delta-pitch option to pitch creation.  The purpose is to get rid of peaks in the delta-pitch caused by discretization of pitch values.
normalization-left-context
Left-context (in frames) for moving window normalization
normalization-right-context
Right-context (in frames) for moving window normalization
Number of frames on each side of central frame, to use for delta window.
delay
Number of frames by which the pitch information is delayed.
add-pov-feature
If true, the warped NCCF is added to output features
add-normalized-log-pitch
If true, the log-pitch with POV-weighted mean subtraction over 1.5 second window is added to output features
add-delta-pitch
If true, time derivative of log-pitch is added to output features
add-delta2-pitch
If true, 2nd order time derivative of log-pitch is added to output features
add-raw-log-pitch
If true, log(pitch) is added to output features
use-pitch
Add extra dimensions for pitch to the FBANK output.
add-pitch-period
If true, pitch period is added to output features
add-pov
If true, probability of voicing is added to output features
add-max-amplitude
If true, max amplitude is added to output features
No feature vectors requested?!
strict-batch-sizes supports only 3 sizes
Model input size must be greater than other batch sizes in strict-batch-sizes
append-pad-info cannot be set if strict-batch-size is <= 0
zero-pad cannot be set if strict-batch-size is <= 0
append-context-size cannot be set if strict-batch-size is <= 0
supported by OnlineNnetForwardInput. Use a separate splice 
OnlineNnetForwardInput. Use a separate splice operation to 
Invalid partition id 
 has to be in range [0,
Requested word position is out of bounds 
Supplied word position index 
, is out of bounds in ErrorRegion, should be in range [0,
Algorithmic error, do not know what to do with level 
Supplied region_id is out of bound, have only 
 regions, asked for 
--------------------------------------------
From frame 
LM scores:
Hyp 
AM scores: 
Ref: 
Hyp: 
Ref Models:
Hyp Models:
Ref Phones:
Hyp Phones:
Ref Scores:
Hyp Scores:
           
Supplied frame is not part of given transition ids
fst-type
fst format (default: squeezed_acceptor)
lm-personalize.model
fst-basename
basename of FST file (default: bigG)
Unsupported FST type: 
ngram-count-flags
SRILM ngram-count flags
arpa-lm-output-file-name
output arpa language model (relative) file name (default: "")
ngram-counts-output-file-name
output ngram counts file name (default: "")
-text
-vocab
ngram-count-flags is not allowed to contain 
write
ngram-count-flags is not allowed to write flag: 
weight-optimization-strategy
Weight optimization strategy
ngram-order
N-gram order for interpolation
uniform
Unknown weight optimization strategy 
ngram-adapt-flags
SRILM flags for adaptation
arpa-lm-input-file
arpa language model to be adapted - (relative) file name (default: "")
-read-text
-read-counts
-read-dev
-write-lm
ngram-adapt-flags is not allowed to contain 
ngram-adapt-flags is not allowed to write flag: 
There are no unseen words in vocab
Encountered more than 1 arc with <unseen>
No arc with <unseen>
numArcsAdded 
 numArcsToAdd 
Incorrect number of arcs added. This is a bug.
Unsupported LmBuildConfig type
arpa
ngramCountCtx is null
ARPA LM write error
/lm.arpa
Config not set to write ARPA file
other input types not yet implemented
ngram-count failed with status: 
ngram-count failed to generate lm
Built ngram with order 
ARPA vocabulary file not set. Hint: check lm-personalize.data.train-arpa-lm-file
Input ARPA file doesn't match LmData. Hint: check lm-personalize.data.train-arpa-lm-file
residual-adapt
residual-adapt failed with status: 
residual-adapt failed to generate lm
residual-adapt failed to determine eta
residual-adapt: eta: 
Ngram counts can only be generated from plain text or phrase counts
Arpa2Fst
free
MinimizeEncoded
ArcSort1
addUnseenWords
Add unseen words failed
ArcSort2
Convert
FstConvert
Verify
FST verification failed
FST properties incorrect
-unk
OOV replacement set, but ngram-count flags don't contain -unk. ngrams will be ignored
order
numStates
numArcs
decoder-chain-name
Name of the decoder for the given task from which to take the bigG FST, e.g., msg
task-name
Name of the task to lookup, e.g., Dictation
.lattice-biglm-lme-faster
Unsupported config: first decoder must have only one big G FST
bigG
squeezed_acceptor
app-lm.interpolation
/current
conversion
optimization
training
residualAdaptationWeight
(current_idx_) >= (0)
../libquasar/liblm/include/lm/streams_liblm.h
NGramFst only accepts OpenGRM langauge models as input
Could not identify unigram state.
Unigram state 
 has no arcs.
Number of contexts arcs != number of states - 1
Number of contexts != number of states
Input fst is not structured properly
Structure problems detected during construction
Not enough bits for quantization: 
Malformed file
_quantized
Too much data for reduced file format: 
 missing in new FST!
Too much data for squeezed file format: 
Could not align file during write after states
Could not align file during write after arcs
Verify: Fst start state ID unset
Verify: Fst start state ID exceeds number of states 
Verify: Fst input label ID of arc at position 
 of state 
 is negative
Verify: Fst input label ID 
 of arc at position 
 is missing from input symbol table "
Verify: Fst output label ID of arc at position 
Verify: Fst output label ID 
 is missing from output symbol table "
Verify: Fst weight of arc at position 
 is invalid
Verify: Fst destination state ID of arc at position 
 exceeds number of states
Verify: Fst final weight of state 
Verify: Fst error property is set
Verify: stored Fst properties incorrect 
(props1 = stored props, props2 = tested)
/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/libquasar/liblm/src/impl/srilm.cpp
Interpolate
initializeBasicNgramLM
format error in mix-lm file 
num-of-words
num-trailing-sil
end-of-sentence
pause-counts
silence-posterior
client-silence-frames-count-ms
client-silence-probability
silence-posterior-nf
server-features-latency
eager-result-end-time
spg-silence-frames-count
spg-silence-posterior
spg-silence-probability-raw
Read endpoint model file =
Writing to json string failed. 
BasicEndPointer inter-utt-sil=
Feature unknown, features allowed are: 
NNet model file for endpointing cannot be empty when use-nnet-endpointer is set
Empty feature list (endpoint.feature-list). Specify features from: 
Invalid pause-threshold-list string 
pause-threshold-list should not be empty if pauses-as-bool is set
NnetEndPointer endpoint-threshold=
num-frames
sequence-of-words
num-input-label-words
stream-conf
com.apple.sequoia.tokenizer
mini.json
ncs/dispatch.voc
ncs/lexicon.enh
ncs/itn_s.enh
GeoLM: Unknown exception while reading geo-config.json
GeoLM: Error while loading geo-config.json file: 
Geo config file loaded but some parts of config JSON have never been used
Dumping unused parts of geo config JSON ...
Finished loading geography from 
geo-config-version
Unsupported geo config version 
cache-region-id-enabled
 field not allowed
regions
 not in 
Loaded circle geoRegion="
Multiple default region 
Loaded default geoRegion="
Same 
Loaded bitmap geoRegion="
Internal error. At this point geoRegion=
 must have either bitmap or circle info
Default region 
 missing in geo-config.
Default region is not part of geo-config but given in main-config file.
Loaded geoCircleRegions=
 geoBitmapRegions=
regions-bitmap
The regions-bitmap section is not available
GeoLM: Unknown exception while reading regions-bitmap
GeoLM: Error while loading regions-bitmap file: 
The config file contains some bitmap regions but the 
 field is missing
Geo ClassLM template=
 assigned to FST from geoRegion=
 based on regions bitmap
Using regionId 
 instead of location
 based on known region id
 based on default region
Internal error, known location expected but got 
Computing geo context for 
Internal error, unknown location expected but got 
Access to geo location denied
 based on cached region id
Cannot resolve regionId=
Location is within max radius of geoRegion=
 based on circle regions
 is waiting for followers so letting them proceed
 is exhausted even though follower buffer is ahead of 
leadBuffer must not be changed to another buffer after audio is started
No audio left, and endOfAudio set. Returning false.
Waiting for more audio or endOfAudio
Copied 
 samples (
) into data
returning code: 
Maximum buffer length 
 has been reached. All additional audio will be dropped.
Maximum ring size 
Clipped audio length 
Added 
 samples: 
Clipping audio buffer like other at 
Clipping audio buffer like other from 
; it was 
Cannot synchronize when lead buffer has been deallocated
Signalling end of audio...
PacketsReceived="
Server endpoint triggered so moving buffer marker to end of buffer.
emptyAudioBuffer: ring=
 bufferPos=
 bufferLen=
It does not make sense for maxRingSizeSeconds (limit on the amount of unread audio queued in the buffer) to be greater than maxBufferLenReached (limit on the total amount of audio written to the buffer)
Leader is waiting for follower, not waiting
circular_buffer
Clipped too big left context: 
 words; limit is 
Word(
lmeType: 
 is not listed in lmeTypeInOffsetOrder.
Unchecked
Detected
Not Detected
freezing component 
 (1-based) in this Update
Components to propagate (startCompIdx=
, num_comps=
) must not be greater than 
#components in the network (
Components to propagate to (
Freezing specified components (1-based):
<NnetProto>
Missing </NnetProto> at the end.
</NnetProto>
The network '
' is empty.
Dimensionality mismatch!
 Previous layer output:
 Current layer input:
Could not read any components
The mapped network '
num-components 
input-dim 
output-dim 
number-of-parameters 
component 
### No gradient info
### Gradient stats :
Component 
### Forward propagation buffers not initialized
### Forward propagation buffer content, note in the parallel GPU training, this only includes the first subbatch content :
[0] output of <Input> 
] output of 
### Backward propagation buffers not initialized
### Backward propagation buffer content, Note in multi subbatch case, only the first subbatch is reported :
[0] diff of <Input> 
] diff-output of 
Dimension mismatch between output/input of components 
 <--> 
The word vec component can only be the first component
The word multivec component can only be the first component
The compressed word vec component can only be the first component
a recurrent trainer option. 
a regular trainer option. 
workspace_size_bytes >= 0
Set workspace of 
 bytes for 
 sub-batches
xent
Invalid set to freeze ( non-unique components ): --freeze-components 
Using workspace of size: 
 KBs
Unknown objective function code : 
At iteration 
linearity_corr_.size() > batch_idx
linearity_corr_[batch_idx]
bias_corr_.size() > batch_idx
bias_corr_[batch_idx]
, and Recurrent style components have additional configurations 
bptt_steps 
num_sequences 
NnetTrainOptions : 
learn_rate 
momentum 
l2_penalty 
l1_penalty 
qtype_compact_grad 
step_compact_grad 
num_subbatches 
average_gradients 
vectorize_weights 
The GPU ID for the matrix randomizer is 
Removing softmax from the nnet 
last_component_idx_ >= 0
Performing vectorization of affine transform component
(nlinparams + bias_->Dim()) == NumParams()
veccorrs->size() == linearity_corr_.size() && veccorrs->size() == bias_corr_.size()
(LinearityCorr(ic).NumRows() * LinearityCorr(ic).NumCols() + bias_corr_[ic]->Dim()) == NumParams()
Done  vectorization of affine transform component
 (ParamStddev|BiasMean|BiasRange|LearnRateCoef|BiasLearnRateCoef|MaxNorm|InitTransformType|GradientNormType|MaxGrad|RandomSeed)
Bias().Dim() == vec.Dim()
assetVersion
modelTrainingData
dataHash
oovs
quasar.lm
there are different number of items in the weights list
there are different number of items in each vector
weights should sum to one (i.e. not in log scale)
linear weights converged after 
 iterations
Last state of linear clat is not a final state (perhaps text contains \CS-xx-start without \CS-xx-end?) LM score will not be accurate.
fail to top-sort the rescored lattice
no old LM defined
total number of old LMs is 
 , but the number of interpolation weights is 
no new LM defined
Failed to limit interp_weights2
total number of new LMs is 
can not perform LM rescoring on the lattice
Failed to get a best path in the lattice
Failed to get new total LM score
max_weights: 
Initial weights 
Total number of weights is 
 , but the number of max weights is 
LM should not have been added to DeterministicOnDemandFstCreator. max_weight <= 0: 
Unimplemented. num_effective_max_weights > 1: 
Final weights: 
Division by zero [0/0] in CompactLatticeWeightTpl
Error: division by zero in CompactLatticeWeightTpl::Divide()
Error in Divide (CompactLatticeWeightTpl): cannot divide, length mismatch.
Error in Divide (CompactLatticeWeighTpl): cannot divide, data mismatch.
Cannot divide CompactLatticeWeightTpl with DIVIDE_ANY.
invalid deterministic on-demand FST
can not find label 
 from state 
 . Wrong LM intput?
only linear weight estimation has been implemented now
Caught exception doing lattice determinization
Memory allocation error doing lattice determinization; using 
 bytes (max = 
 (repo,arcs,elems) = (
[empty subset]
Failure in determinize-lattice: size exceeds maximum 
warning: mixture prior out of range: 
too many words in line
ARPA
lm ngram order
lm prior weight
lm type
classes
class definitions
simple-classes
use unique class model
cache-served-ngrams
enable client side caching
allowed options for mixture LM 
 are
error in ngram lm
error in class defintions lm
COUNTLM
error in count-lm 
MAXENT
error in maxent lm 
LMCLIENT
 is not a valid LM type
[post=
[probs=
 in geo config version 
, upgrade to latest version (or version 
dispatch.voc
lexicon.enh
token_s.enh
EAR Initialization failed for custom-lm, error:
CustomLMBuilderErrorDomain
%@/oovProfile.txt
com.apple.ear
EARPSRAudioProcessor
word-syms-marisa-file
Base word symbol table in MARISA trie format (overrides other format files)
Base word symbol table mappable format filename (overrides text and binary format file)
word-syms-binary-file
Base word symbol table binary format filename (overrides text format file)
Base word symbol table text format filename
Model loader is deallocated
No word symbol table file specified.
Failed to convert HatText token to QsrText token:
Failed to convert QsrText token to HatText token:
Calling Write() when offset is nonzero is unsupported
Programming error: Invalid output encoding
<SourceDotTransform>
this is not an updatable component, you used 
<TargetDotTransform>
<SourceAddTransform>
<TargetAddTransform>
Reading attention model
read source dot transform failed
read target dot transform failed
read source add transform failed
## Source Dot Transform: input-dim 
## Target Dot Transform: input-dim 
## Source Add Transform: input-dim 
## Target Add Transform: input-dim 
source state dimension is 
 , but the source dot transform has input dim 
 , but the source add transform has input dim 
the component has input dim 
 , but the target dot transform has input dim 
 , but the target add transform has input dim 
the source and target dot transform has different output dim 
the source and target add transform has different output dim 
the source/target add transform has output dim 
 , but the component has output dim 
it doesn't make sense to use a non-reccurent network here
cannot initialize source dot transform from 
cannot initialize target dot transform from 
it doesn't make sense to use a non-recurrent network here
## Internal recurrent network info 
not implemented yet
the internal recurrent network has output dim 
the internal network takes input dimension 
 , that is not equal the sum of 
source vector dimension 
target input network dim 
the internal network has output dim 
ara-XWW
cmn-CHN
cmn-TWN
nor-NOR
yue-HKG
zh_MO
yue-MAC
ms_MY
zlm-MYS
Unable to resolve 3-letter locale for 
Identifier '
' does not parse into two elements.
Could not read magic header
Magic header was wrong
Could not read number of words
Could not read mapped file
SymbolTable::Read: Can't open file 
Slow symbol table initialization and sorting! This should NEVER be called for perf or memory critical workloads
 are padded words
Slow linear search called! This is OK if called during recognition initialization, but should 
NEVER be called during online recognition.
Logic error (this should not happen).
pass
match
.frontend
.nfhat
Silence posterior generator created with incorrect version
frameByFrame requires output batch size of 1
Siri
zero
one\number
one\pronoun
three
four
seven
eight
nine
eleven
twelve
thirteen
fourteen
fifteen
sixteen
seventeen
eighteen
nineteen
twenty
thirty
forty
fifty
sixty
seventy
eighty
ninety
hundred
thousand
million
billion
trillion
\inverted-question-mark
\inverted-exclamation-mark
continuous-listening.
continuous-listening
\caps-on
\no-caps-on
\no-space-on
\all-caps-on
\caps-off
\no-caps-off
\no-space-off
\all-caps-off
left context: 
; commands: 
CommandStartIndex
Partials: currentTokens should be empty when client left context is provided
Final: currentTokens should be empty when client left context is provided
\letter
\uppercase-letter
\lowercase-letter
Separate post-ITN output: 
Separate post-ITN punctuation: 
preITN leftContext: 
preITN currentContext: 
strip before milliseconds: 
prependedOutputs: 
output: 
delay-finalization-tokens
Interesting tokens that will delay the finalization
fallback-itn-left-context
The fallback left context for across-utterances ITN
itn-left-context-max-length
The maximum token number of left context
delay-finalization-max-length
The maximum token number for the delayed finalization buffer
delay-finalization-length
Finalization would be delayed if token number is no larger than this length
Using previous utterance as left context
leading-inter-utterance-space-tokens
Tokens may add leading inter-utterance space based on itn left context
tokenScore: tokenIndex argument is out of range
tokenString: tokenIndex argument is out of range
Input lattice must be topologically sorted.
_LT_
Cannot read munge file: 
Number of munge rules: 
This should not be called with empty tokens
Munge line with non-space whitespace: 
Munge line missing probability: 
Probabilistic munge rules not implemented (probability must be 1.0): 
Munge line with more than 1 '<-'
/REJECT/
Munge line with empty rhs: 
Munge line with invalid lhs: 
Munge line with invalid rhs: 
MergedMungeRule: 
 {rhs=
 lhs=
 reject=
BasicMungeRule: {rhs=
 startAnchor=
 endAnchor=
Unable to intern metatag due to const.
%s%u
warning: failed to add 
 to vocabulary
warning: line contains only one token
warning: failed to add alias 
 for word 
%u %s
malformed vocab index line
Vector<Real>::Read, adding but dimensions mismatch 
Error reading vector data (binary mode); truncated stream? (size = 
EOF while trying to read vector.
Expected "[" but got 
Failed to read number.
Expected whitespace after number.
Reading negative infinite value into vector.
Reading negative NaN value into vector.
Expecting numeric vector data, got 
After end of vector data, read error.
EOF while reading vector data.
Newline found while reading vector (maybe it's a matrix?)
Reading infinite value into vector.
Reading NaN value into vector.
Failed to read vector from stream.  
SoftMax produced NaN on vector
Empty vector
Failed to write vector to stream
UTF-8
UTF-16LE
UTF-16BE
conversion from UTF-16
 not supported
iconv
offset 
offset unknown 
In class File, failed writing to buffer
/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/libquasar/liblm/src/impl/arpa2fst-kaldi.cpp
<s> is missing from FST symbol table. 
Note that this is a requirement of the Kaldi implementation even when the explicitStartEndMarkers option is set to false.
</s> is missing from FST symbol table. 
<s> and </s> should be different symbols.
 is missing from FST symbol table.
Symbol 
 in ARPA model has no remapping.
Non-event symbol 
 occurs as a probabilistic event. 
Is <unk> modeled as a word?
 n-grams, but only found 
Non-finite loss (
) in cross-entropy calculation
Non-finite entropy (
Posterior pdf-id out of NN-output dimension, please check number of pdfs by 'hmm-info'.
 nn-outputs : 
, posterior pdf-id : 
ProgressLoss[
h]: 
 (Xent)
Can't collect performance from non Xent object
AvgLoss: 
 (Xent), 
[AvgXent: 
, AvgTargetEnt: 
progress: [
FRAME_ACCURACY >> 
% <<
Loss
Entropy
Correct
Frames
) in MSE calculation
 (Mse)
Can't collect performance from non Mse object
 (Mse), 
[RMS 
 states and 
 arcs.
Not Implemented
error writing 
print version information
max ngram order
debug
tagged
skip
stop-words
stop-word vocabulary for stop-Ngram LM
map-unk
word to map unknown words to
tolower
map vocabulary to lowercase
float-counts
vocab
vocab file
vocab-aliases
vocab alias file
nonevents
non-event vocabulary
limit-vocab
maxent
maxent-convert-to-arpa
count-lm
reverse
no-sos
don't insert start-of-sentence tokens
no-eos
don't insert end-of-sentence tokens
write-lm
write-vocab
prune
prune redundant probs
minprune
prune only ngrams at least this long
memuse
show memory usage
min-alignment-value
minimum total alignment weight that must be assigned to the attention window
num-forbidden-frames
min number of frames that must be in the encoder output buffer after the right attention boundary
num-forbidden-frames-silence
min number of buffer frames after the right attention boundary when top prediction is silence
chunk-size
chunk size used in estimating attention window location
Coding error: the number of arcs has changed after node-merging
Malformed phrasebook line:
failed to open phrasebook file 
Loading phrasebook: 
# of keys: 
Expecting 
invalid model type specifier: 
Interpolation weight
max-rescore-weight
Max rescoring weight: 0 = exclude from rescoring, 1 = use in rescoring as usual, betw 0 and 1 = limit rescoring weight chosen by EM algorithm
deserialize-test
Test if the new model can be read before it is installed
Type of model. Examples: 'dummy' or 'ngram'
Unknown model type: 
Reading LmModel currentDir=
maxRescoreWeight
Unknown exception
C++ exception: 
Reserved metadata key: 
Model is only for inference and cannot be written
Destination is empty
totalTime
times
Not enough data. Skip training
Reading LmModel dir=
Coordinated rename failed. This should never happen and is a bug!
lm.json
/garbage
Testing deserialization
Deserialization test failed.
/next
WatermarkDetector2 not run on input origin 
WatermarkDetector2 not supported for sampling rate=
WatermarkDetector2: missing trigger phrase endTime.
WatermarkDetector2: not enough audio cached.
WatermarkDetector2: Trigger phrase not detected
WatermarkDetector2: score=
 detected=
Watermark2Score
Watermark2Detected
Watermark2StartTimeSecs
Threshold value to detect a watermark
anti-notch-offset
Frequency (in Hz) of anti notch offset
notch-width
Frequency (in Hz) of width of notch
notch-freq
comma separated list of notch frequencies
classifier
comma separated list of classifier values
unknown keyword
#remaining_frames for fbank 
 and energy 
 don't match!
mismatch between finished pitch frames and remaining frames+new wav frames: 
 v.s. 
ConvertToFST
/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/libquasar/liblm/src/impl/arpa2fst-inhouse.cpp
Unable to resolve silence token 
SilenceOptions: {
Creating silence state.
FST will have 
StateInstantiator
Artifact in life cycle stage 
incorrect text normalization meta-data.
Artifact in invalid life cycle stage.
Unable to transform artifact from 
A Tokenizer instance was provided when the input data is processed.
A Tokenizer instance was not provided when the input data is unprocessed.
Unable to determine whether model is adaptable to 
 life cycle stage.
No such node
basic_ptree<K, D, C> &boost::property_tree::basic_ptree<std::string, std::string>::get_child(const boost::property_tree::basic_ptree::path_type &) [Key = std::string, Data = std::string, KeyCompare = std::less<std::string>]
/AppleInternal/Library/BuildRoots/b958ad6d-2c13-11ed-a8d5-b25c5e9b9057/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator16.1.Internal.sdk/usr/local/include/boost/property_tree/detail/ptree_implementation.hpp
gtmin
gtmax
cdiscount
ndiscount
wbdiscount
kndiscount
ukndiscount
kn-counts-modified
interpolate
mean
Mismatch in number of key and value pairs in ScaledDotAttention, got 
 keys and 
 values
Mismatch of key matrix input in ScaledDotAttention, expected 
, but got 
Mismatch of value matrix input in ScaledDotAttention, expected 
SetKeyValueStores needs to be called in ScaledDotAttention for attention to work
<AddQuery>
<QueryTransform>
<KeyTransform>
<ValueTransform>
<OutputTransform>
Reading ScaledDotAttention component
reading query transform failed
reading key transform failed
reading value transform failed
reading output transform failed
<NumberHeads>
Reading MultiHeadAttention component
<SupervisedHeads>
Reading SupervisedMultiHeadAttention component
Reading SelfAttention component
<Attention>
failed to read attention component in SelfAttention
ResetHistoryState for SelfAttention makes only sense if all utterances get reset at the same time
<AverageFfn>
<Gate>
Reading AverageAttention component
reading average feed-forward network failed
done
reading input gate network failed
</AverageAttention>
Recurrent neural networks are not supported inside the average attention component.
ResetHistoryState for AverageAttention makes only sense if all utterances get reset at the same time
Error: computeEta2: couldn't find dev n-gram in ARPA, 
hint: add to Vocab iterator and re-normalize Ngram.
process-feeds-config-file
Configuration file for feed processing rules
spoken-forms-file
Spokenforms file
regex-rules-file
Post-tokenization regex rule file
additional-lexicon-file
Additional lexicon file
FST type
Wildcard symbol for partial match
squeezed_transducer
QSR_SYM_V000
~w01
Error opening 
root
[root] grammar is not present.
Generating grammar FST for 
 ... 
.txt
Building L FST ... 
/pmlexicon.txt
Building Aligned-L FST ... 
Composing LG FST for [
] ... 
Stripping out all the grammar symbols on the output side for [root] ... 
Moving the grammar symbols from input side to output side for [root] ... 
<-2, root>
Not combining $
 with root because it contains subgrammars
$root
Unable to find symbol $
 in the symbol table.
lmeDataFactory initialization failed!
G2P model does not exist
state: 
 # of intervals: 
# of states: 
# of intervals: 
# of intervals/state: 
# of non-interval states: 
IntervalReachVisitor: state2index map must be empty 
for this FST
IntervalReachVisitor: state2index map incomplete
IntervalReachVisitor: cyclic input
StateReachable: final state contained in a cycle
LabelReachableData: no relabeling data
LabelReachable::ReachInit: fst is not sorted
FastLogAccumulator: initialization error.
FastLogAccumulator::SetState: invalid state id.
WriteIntPairs: Can't open file: 
WriteIntPairs: Write failed: 
# of calls: 
# of intervals/call: 
Failed TPLexicon_GetInfo()
could not format word sequence: 
could not get text of word sequence
could not get result
could not get result Alignment 
result could not be deleted
quasar.artifact
Input not monotonic
Adjacent 'ID'
Adjacent 'DI'
Unexpected character
Invalid alignment string
String is all I's, all D's, or empty
Output not monotonic
Coding error. addAudio() called after endAudio()
(BiasMean|BiasRange|ParamStddev|LearnRateCoef|MaxNorm|MaxGrad|InitTransformType
|GradientNormType|RandomSeed)
 Gate recurrent weights:
 Activation recurrent weights:
  Gate recurrent weights gradient: 
  Activation recurrent weights gradient: 
  Candidate activations: 
  Activations: 
  Candidate activation diff: 
  Activation diff: 
; output dim = 
Gate recurrent weights #rows = 
Gate recurrent weights #columns = 
Activation recurrent weights #rows = 
Activation recurrent weights #columns = 
Saving last activation batch 
mapping [
] -> [
Tokens:
Logic error! newTokens should not be empty here.
       shrinking token before replacement
   DNT copy: '
   step backward to: '
' / 
   discarding: '
       setting hasSpaceAfter of DNT token
       allready hasSpaceAfter of DNT token
       removing hasSpaceAfter of DNT token
   partial:  '
       tokenStartPos: '
finnished mapping [
], actual source length: 
Adjusting projections
Adjusted range start is out of bounds: 
Adjusted range end is out of bounds: 
    Changing target 
`source` input empty!
Span information differs between source and target - skipping!
do-not-translate only support one-to-one span alignments
    not mapping [
    original: '
Unknown protection class: 
Failed to set protection class for path: 
en-US
Did not get correct batch [
) for frame 
Request for expired frame (
): current frame offset is 
Request for invalid frame (
): you need to check
 IsLastFrame, or, for frame zero, check that the input is valid.
Could not calculate silence posterior for frame=
, current frame offset is=
Silence posterior cache incorrectly calculated rows=
Requested posteriors for realignment do no longer exist.
Realignment model posterior cache is empty, make sure that acoustic model for realignment is configured correctly
Request for invalid frame (you need to check IsLastFrame,
 or, for frame zero, check that the input is valid.
LogLikelihood() must be called before this method as silence posteriors are pre-computed there
EARAudioResultsGenerator
This class is internal to Quasar, and this function is never called
recogResult.params is null. Should NEVER happen
Decoding for only the last utterance failed. Updating recogStatus to success
Quasar PreITN Result. isFinal=
PreITN 1-Best: 
PreITN Choice: 
 muxIds: 
PreITN Token[
Sanitization returned empty string
Tokenizer returned empty tokens
Pronguesser returned empty prons for orthography 
profile
people-suggester-contacts-count
best-people-suggester-contacts-count
best-people-suggester-contacts-bonus
best-people-suggester-contacts-bonus is 0, ignoring.
LmeDataFactory already initialized.
lme-create.
Failed to find 
 in template-map, skipped.
params
lme-create.name-enumerator-map.
.params.
name-scale-map
name-average-cost-map
name-deviation-cost-map
max-entity-count-map
max-orthography-length-map
max-pronunciation-length-map
read mmaped lexicon from 
Could not read lexicon data from mmaped source 
can not open 
Cannot open g2p rewrite file 
G2P blacklist does not support rewrite rules
Malformed g2p rewrite file line=
g2p rewrite file contains whitespace line=
Failed to encode g2p rewrite entry in QsrText: 
G2P rewrite rule 
G2P rewrite size=
LmeDataFactory initialized.
LmeDataFactory not initialized.
Checking category "
": Not supported
": Supported
Starting LME for new speaker.
AOT LME data has already been provided.
LME data has phone set version 
 which is different from model phone set version 
Adding AOT LME for speaker. lmeDataStatus=
, nextLmeStartSymbolKey[AotLme]=
Multipe LmeType in single user data is not supported.
is UserData empty? not able to tell which lmeType from userData which has size: 
generate Lme Data for lmeType: 
Serializing.
Deserialization test failed. Cannot properly serialize this data.
Deserialization test passed.
User data is empty
Lme enumerating return NothingToDo, errorCode=
Lme enumerating failed, errorCode=
Expected symbol table from previous LME data but none was found. 
lmeData.symTableFirstKey = 
, lmeData.symTableLastKey = 
Failed to build the LME fst using the direct method
_num_word_homophones=
_num_fst_paths=
_num_word_homophones
_num_fst_paths
Failed to build the LME fst
LmeEnumeratingTimeMs=
, lmeFstCreatingTimeMs=
, maxPronsPerWordSeen=
LmeEnumeratingTimeMs
LmeFstCreatingTimeMs
Created lmeData.symTable
Original lmeData.symTableFirstKey = 
, Original lmeData.symTableLastKey = 
New lmeData.symTableFirstKey = 
, New lmeData.symTableLastKey = 
Ignoring user data key 
Getting LME data for userDataKey = 
 quasarTemplateName = 
No supported templates were found in userData. Only the templates specified under 
"supported-lme-template-list" in the json config file are supported.
Skipping name containing bad word:
Skipping name containing bad word
Could not find enumerator for quasar template 
Enumeration type:
Word has empty orthography
Word with hex sequence 
has frequency 
Word has no prons, orthography=
Word has pron with 
 phones, exceeds maxPronLen=
, orthography=
Rewriting from=
 to=
Could not read magic header from 
Magic header was wrong in 
Could not read the number of words from the mapped file 
Could not read the offset region in the mapped file 
base-dict-file
Base lexicon file
base-dict-mapped-file
Base lexicon file, mmap-able (overrides text lexicon file)
lme-scale
Scaling factor for the LME FST
lme-average-cost
the cost of entering an LME FST
lme-deviation-cost
the cost of deviating from an average size LME class
supported-lme-template-plist
Comma-delimited LME template names, ordered by enrollment priority
supported-lme-template-list
Comma-delimited LME template names
contacts-template-name
Quasar template name for user's contact names
appcontacts-template-name
Quasar template name for 3rd-party app contact names
max-num-enumerated-contacts
Maximum number of contacts (e.g. in NT-contact and NT-appcontact) to allow in a user's profile
just-in-time-template-name
Just in time LME template name
template-map
Mapping from ACE category names to Quasar template names
name-enumerator-map
Mapping from Quasar template names to enumerator names
max-prons-compound-word
Maximum number of pronunciations for compound words
During G2P, empty prons will be returned for tokens listed in this file. File format: same as a lexicon text file (not hat encoded) with the prons removed so that only one column remains per line. Order does not matter.
g2p-rewrite-file
File format: If a rule is in the form of 'A -> B' (whitespace optional), then rewrite token A to token B before doing G2P. If a rule is in the form of 'A', then rewrite A to an empty string. This 2nd rule has the same format and effect as g2p-blacklist entries and therefore makes g2p-rewrite-file a superset of g2p-blacklist.
LME scale for specific Quasar template names
the cost of entering an LME FST for a specific template
the cost of deviating from an average size LME class for a specific template
Per-template map: If >= 0, maximum number of entities allowed. Additional entities are rejected.
Per-template map: If >= 0, maximum orthography length. Entries with any words that have longer orthography lengths are rejected.
Per-template map: If >= 0, maximum pronunciation length (# phonemes). Entries with longer pronunciations are rejected.
Exceeded enumeration limit. Stopped enumerating.
\NT-buzz
\NT-appcontact
fallback
both
phrase_book_only
unknown phrase-book-mode: 
integrated
rescore_bpe
rescore_word
partial_bias
unknown lm-mode: 
gnmt
unknown 'norm-mode': 
specifying both 'norm-cost' (old parameter name) and 'norm-mode' (new name) at the same time is not allowed.
nbeam
best
finished_score
unknown stop-mode: 
espresso
Unknown 'model-type': 
degenerate_translation
Degenerate translation <
> from <
>. Copying the input sequence to the output.
Decoding require valid SentencePiece IDs in input
Streaming decoding not compatible with 'use-sentencepiece-ids'
stream-decoding unexpectly ended, as no futher hyps remain
stream-decoding was closed, but decoder did not clear active hyps
Using meta data from phrasebook loaded inside of PDec - deprecated in MT production!
use shared phrasebook: 
load phrasebook: 
Cache phrasebook: 
failed loading phrasebook: 
<constructor argument>
Model file name not supplied (configuration value 'model-file' is empty)
Model for final- and partial-inputs has to be the same for now.
Phrasebooks are not yet supported for partial-input
Failed to read lm fst from: 
vetoed
stopped
phrasebook_fuzzy
subword string
Invalid entry terminating ReadRaw : 
 phrasebook entries
Apply BPE source : 
Apply BPE target : 
Failed to read model from 
Already mapped from a file
Using the special symbols ids <unk>=
, <s> = 
, </s> = 
Applying log to output probs 
Has BPE Model
No embedded BPE Model
Configuring multilang decorator
<HasPhraseBook>
# PhraseBook entries 
No phrasebook in the model
Getting model for: 
 (sharing disabled)
Getting existing model for: 
Getting new model for: 
Reading phrasebook
<PhraseBook>
num_entries 
</PhraseBook>
# of keys 
Reading tag filters from : 
Select decoder for 
Selected 
Decoder for 
 not found
Try to find decoder for 
 not found!
No tar tag specified but required by model!
entered Init with #ActiveHyps: 
 at decoding-position: 
Initializing NbestCompare. alpha: 
, sigma: 
entered StaticReadWrite final: 
 with #ActiveHyps: 
Input stream did not grow. Previously processed: 
 provided: 
partial_input_addition:
src_input_host_[0].NumRows(): 
partial_output: 
BPE input 
Couldn't find symbol 
 or <unk> UNK symbol
entered Read to process #tokens: 
A Both type TagFormat requires non-empty source and target tags
SrcTag cannot be empty for TagFormat::Src
TarTag cannot be empty for TagFormat::Tar
<src-
> <tar-
entered Write with #ActiveHyps: 
input_batch_idx: 
hyp_idx: 
Final word in hyp list
Skipping target eos symbol
Nothing left in heap
Beam decoder hit maximum sequence length
Pruned all hyps, nothing left to expand
dropping worse identical hyp; score-diff: 
using lattice state:
Adding invalid arc 
At output position 
, # surviving hypotheses: 
No hyps finished, setting 
 partial hyps to final
Setting longest vetoted translation as best 
# of cached states 
For 'partial_bias' lm-mode, storing token: 
Didn't extract any paths from the lattice
Unknown replacement disabled for: 
Error converting BPE to word list 
Not applying BPE to target
Nbestlist cannot be null
Decoder not configured for SentencePiece ID decoding.
Model not configured for SentencePiece ID decoding.
Input Hammer not supported for sentencepiece id decoding.
Phrasebook (kaldi level) not supported for sentencepiece id decoding.
Decoder beam (
) should not be negative.
Decoder confidence threshold (
) should be in the range [0, 1000].
Decoder maximum nbest list size (
model does not require the use of src/tar tags
Apply tags to ID sequence require a tag symbol table in MultiLangDecorator!
Source locale 
, Target locale 
 source tag 
 target locale 
, # of phrasebooks 
Re-decode without LM 
time
Input : 
Greedy decoding
Beam decoding
Word level LM re-scoring
Applying confidence scores to n-best list
Looking for UNK symbol 
UNK label : 
No UNK symbol in translation model vocabulary
Language model does not have output symbol table
LM UNK ID 
Language model does not have OOV symbol : 
 in LM
Word lookup failure : 
 (label=
Old Cost = 
, New cost = 
, Hyp = 
 finalcost=
Alignment cost 
time total
time start feedforward
time start ff graph
time start ff handover graph
time get history state
time set history state
time feed forward
time ff graph
time ff readout
Decoder not configured for string decoding (use SentencePiece ID decoding).
Model lacks full symbol tables (use SentencePiece ID decoding).
Total # of phrasebook matches : 
FindInPhraseBooks # 
Phrasebook fallback match
Phrasebook locale match
, phrasebook idx=
should_be_hyp == "hyp"
(first_underscore_index != std::string::npos) && (first_underscore_index > 3)
0 && "Invalid feature name"
(hyp_id >= 1) && (hyp_id <= num_hyps_)
std::find(feature_list_without_hyp_ids_.begin(), feature_list_without_hyp_ids_.end(), should_be_in_feature_list_without_hyp_ids) != feature_list_without_hyp_ids_.end()
hyp_confidence_values.size() == num_hyps_
count
25pct
50pct
75pct
TextSanitizer is already initialized
[^\u0000-\uFFEF]
Failed to compile special characters regex
(\s)+
Failed to compile duplicate spaces regex
[\p{C}]+
Failed to compile control characters regex
TextSanitizer is not initialized
Empty string received.
wstring_convert failed for text: 
Failed to normalize 
Could not open UTF8: : 
Failed to replace unicode characters in range [\u0000-\uFFEF]: 
Failed to remove some special characters: 
Failed to remove redundant space characters: 
Failed to remove control characters: 
Intermediate basic sanitization result=
If silence posteriors are available, trigger only when the average silence posterior is >= this value. Otherwise, ignore this value.
silence-window
Sliding window size (in frames) for silence posterior average. Silence posterior is ignored if this value is <= 0.
stable-partials
Trigger only after the number of stable partial results (one per frame) exceeds this value. (Eager's stabilization is unrelated to ResultStreamStabilizer stabilization). Regardless of this value, the trigger always looks for at least 1 stable partial result.
early
backoff
max-triggers
Ignored if <= 0: Maximum number of eager result triggers. Once exceeded, no more eager results are created.
require-silence-posterior
If true, disable eager for requests that don't have silence posteriors. Defaults to true since 'false eager results' increase without silence posteriors. Set this to false for experimentation or if the number of 'false eager results' is acceptable.
Debug mode: require-silence-posterior=false and trigger every frame without affecting state machine
{silencePosterior=
 silenceWindow=
 stablePartials=
{early=
 backoff=
 maxTriggers=
 requireSilencePosterior=
 debug=
{frame=
 finalActive=
 words=[
 ids=[
 trailingSilence=
 silencePosterior=
 allowTrigger=
n must be positive
init() was not called
Cannot compute average of 0 items
ENABLED 
 hasSilencePosterior=
trigger=
 numTriggers=
 thisFrame=
 avgSilPost={
 numStable=
INVALID 
INVALIDATED 
TRIGGER 
TRIGGERED 
Invalidate and trigger shouldn't happen on the same frame
Bad state transition: triggered 
silence phone probability must be [0,1) 
invalid silence phone value <
the input lexicon is empty
Cannot dereference iterator that is already at the end
Cannot increment iterator that is already at the end
[OOV context]
H-MAXENT 0.1
# %ld %ld %ld %ld
 contexts...
<word> <weight> expected
format error in H-MAXENT file
H-MAXENT 0.1
# %ld %ld %ld %ld
%s %f
Counting counts of order 1 
Counting counts of order 
Contexts:
Creating feature contexts...
Indexing contexts of order 
Creating reverse context index...
WARNING: Data contains n-grams that cannot be properly mapped the nodes of the Maximum Entropy model structure;
         If you are adapting a prior model, use also adaptation data (with weight 0) for creating the prior model
Creating count contexts...
Coding error: SyncDecoder 
 has already been initialized.
Ignoring unknown SyncDecoder type "
Recognition will crash if you try to use it
suites
resourceBaseURL
v24@?0@"EARVoiceCommandSuite"8^B16
EARVoiceCommandActiveSet.mm
Missing key "%@" of type NSNumber
Wrong value type for key "%@"; expecting NSNumber
Missing key "%@" of type NSArray
Wrong value type for key "%@"; expecting NSArray
Missing key "%@" of type NSString
Wrong value type for key "%@"; expecting NSString
v32@?0@8Q16^B24
identifier
commandSpecs
v24@?0@"EARVoiceCommandSpec"8^B16
valence
FSTRelativePaths
FSTSymbol
B32@?0@8Q16^B24
Wrong value type in array for key "%@"; expecting NSString
mt-decoders
blocks
graph
block-definitions
block
block-type
limit-input-data-length
PDEC
Logic error: truncateUtf8 called with negative lenght (should not happen)
missing source or target locale, skipping parsing language-pair-specific-settings
block definition '
' (referenced in '
]') not found
<overlay-settings>
Changing phrase book mode using command line overlay causes use of previously ignored translation model file: 
.graph
missing source or target locale!
Unknown block definition name: 
Machine translation configuration for task '
' not found!
Assuming legacy (non-graph) config format, deprecated for production MT configurations!
missing source or target locale, skipping parsing 
No language pair specific settings found (this might be a configuration error).
Config file does not support language pair: 
 for task: 
input_truncated
__NONE__
mt-quasar-config.json
siri
EMTTranslator.mm
Task string cannot be nil
com.apple.sequoia
Failed to parse mt-quasar-config.json
v32@?0@"SFTranscriptionSegment"8Q16^B24
<OutputEmbeddings>
<OutputPhoneLoglikes>
<OutputEOSProbabilities>
<InputFrameCount>
<OutputPhoneDim>
<SilPhoneIndex>
<FrameOverlap>
<NumSpeculativeOutputs>
(InputFrameCount - FrameOverlap) must be a multiple of FrameSubsamplingFactor
<BlankIndex>
<ContextSize>
input_labels->GetNumDims() == 1
Mismatch at [
<InputAcousticEmbeddings>
<InputLabelEmbeddings>
input_acoustic_embeddings->GetNumDims() == cfg_.input_shape_template.ndim
input_acoustic_embeddings->GetDimSize(cfg_.input_shape_template.col_index) == InputDim()
input_label_embeddings->GetNumDims() == cfg_.input_shape_template.ndim
input_label_embeddings->GetDimSize(cfg_.input_shape_template.col_index) == InputDim()
input_acoustic_embeddings->GetDimSize(cfg_.input_shape_template.row_index) == input_label_embeddings->GetDimSize(cfg_.input_shape_template.row_index)
input_acoustic_embeddings.NumRows() == input_label_embeddings.NumRows()
input_acoustic_embeddings.NumCols() == input_label_embeddings.NumCols()
output_embeddings
input_acoustic_embeddings
input_label_embeddings
quasar.geolm.helper
<unspecifed>
<unknown>
Stream failure detected.
state ID
FstPrinter: Integer 
 is not mapped to any textual symbol
, symbol table = 
, destination = 
arc input label
arc output label
acoustic-encoder-model-file
Acoustic encoder model (TF/Espresso/CoreML graph)
label-encoder-model-file
Label encoder model (TF/Espresso/CoreML graph)
joint-predictor-model-file
Joint predictor model (TF/Espresso/CoreML graph)
max-label-fraction
#decoded-nonblank-labels / #acoustic-encoder-output-frames <= max-label-fraction. Must be positive. Active only if max-steps < 0.
Number of acoustic encoder output frames to compute per chunk.
Remove EOS labels from output.
Remove silence labels from output.
remove-blank
Remove blank labels from output.
merge-hyps
Merge equivalent hypotheses.
merge-max
Assign max score to merged hypotheses, otherwise total score (default).
label-context-size
Context size to merge hypotheses by label context. Inactive if negative (default).
keep-merged-hyps-active
Keep hypotheses active when merged by label context.
Maximum number of decoder steps. Inactive if negative (default).
At least min-active best hypotheses are retained after pruning.
At most max-active best hypotheses are retained after pruning.
Beam width. pruning-cutoff = best-hypothesis-score - beam.
Score penalty added for each non-blank label.
Enable endpointing.
max-frames
Maximum number of frames allowed. Hard limit. We will endpoint when this many frames are decoded.
max-trailing-sil-frames
Maximum number of trailing silence frames allowed. Active only if some speech frames have already been decoded.
eos-probability-threshold
Endpointing threshold. Endpoints if P(EOS) > eos-probability-threshold. Active only if some speech frames have already been decoded.
enable-utterance-detection
Enable utterance detection.
max-utt-frames
Maximum number of frames allowed in an utterance if num-utt-speech-frames == 0. Otherwise, it is used to determine the maximum number of trailing silence frames allowed.
max-utt-trailing-sil-frames
Maximum number of trailing silence frames allowed in an utterance if num-utt-frames <= max-utt-frames. Otherwise, we use the formula max-utt-trailing-sil-frames * max-utt-frames / num-utt-frames.
Concat: input/output symbol tables of 1st argument 
ConstantEventMap::Write(), could not write to stream.
Could not map value 
 for key 
Multiple values map to the same point: this code cannot 
handle this case.
TableEventMap::Write(), could not write to stream.
, for key 
, cannot be mapped.
SplitEventMap::Write(), could not write to stream.
SplitEventMap::Read, NULL pointers.
EventMap::MaxResult(), empty result
Empty phone in phonetic sequence: 
Could not interpret 
 as a phone. Found in phonetic sequence: 
weight must be between 0 and 1 inclusive (weight=%f)
total weight must be between 0 and 1 inclusive (weight=%f, current total weight=%f)
word 
 has multiple class memberships
class 
 expands to string of more than one word
opts_.min_active > 0
opts_.max_active >= opts_.min_active
decodable->BOSIndex() >= 0 && decodable->EOSIndex() >= 0
Decoding output contains label 0. Replacing it with BOS label (
creating PDecTranslatorFactory
HeaderAvailable
/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/libquasar/liblm/src/impl/arpa2fst-kaldi/arpa-lm-compiler.cpp
Reverting to slower state tracking because model is large: 
-gram with symbols up to 
ConsumeNGram
 skipped: n-gram has invalid BOS/EOS placement
RemoveRedundantStates
Reduced num-states from 
Check
Arpa file did not contain the beginning-of-sentence symbol 
 skipped: no parent (n-1)-gram exists
 <eps> or disambiguation symbol 
found in the ARPA file. 
asset_info.json
Not able to set metadata. Unsupported key "
Not able to set info. Unsupported key "
Artifact file was changed before being loaded
Invalid artifact
Invalid artifact - empty metadata
Failed to write metadata
Error while writing 
 to archive
Required key "
" not found in artifact
Supported locale "
" not present
Required dependent key "
" missing from artifact
supported_locales
content-list
Error while trying to open archive at 
 for reading: 
Failed to find archive entry named 
Error while trying to read data from open archive: 
Unable to configure archive as ZIP: 
compression-level=0
Unable to configure archive options: 
Unable to open archive: 
Failed to write header for 
 to archive: 
Unable to write 
Error while trying to read next entry from open archive: 
Failed to write 
Something went wrong while writing content.
Unable to read command FST 
Unable to read one or more command FSTs
DefaultCompactStore::Read: Alignment failed: 
DefaultCompactStore::Read: Read failed: 
GenericRegister::GetEntry : 
lookup failed in shared object: 
-fst.so
Fst::Read: Can't open file: 
Fst::Read: Unknown FST type "
" (arc type = "
"): 
CompactFstImpl: input fst incompatible with compactor
DefaultCompactStore: compactor incompatible with fst
min-voicing-duration
Minimum duration of voicing
acoustic-feature-window-width
Minimum width of the normalization window for acoustic audio analytics features
Utterance feature cache is disabled. Skipping audio analytics.
No audio features generated. Rejecting utterance.
Audio analytics finished..
 score= 
Cycles detected in lattice.
Invalid list of region specifiers provided 
Using non-terminal regions for combination from 
Splitting into labels : 
 Check start 
 end 
 against start 
 lab in lat 
 lab in check 
Found state 
 id 
 start 
 For MBR start 
 distance is 
Match 
not_in_static_vocab
 Find Overlapping With 
Word with ID = 
 does not exist in word map. Is a dynamic vocabulary being used?
No arc to continue with
Recomputing TBP on Ref Interval 
 for arc on 
Recomputed TBP is 
 post score avg is 
Compact Lattice Current state=
 ARC ilabel: 
 olabel: 
 weight1: 
 weight2: 
Next State=
 duration = 
 word is 
Original Duration Was 
 without silence it is 
Warning - state Time Mismatch - 
Time = 
 not in state posterior map...
Couldn't find state 
 defaulting posterior to 0, w1=
 w2=
No states in the word posterior computation - this may be because the word has 0 duration (could happen for class LM)
Utterance ID is 
Needed to find 
 actually only found 
Couldn't find arc
Warning: MISMATCH BETWEEN LENGTH OF 1-BEST and LENGTH OF CONFIDENCE VECTOR
Finished generating 1-best word-level confidence features for 
 words in utterance 
Add Candidate: 
 to candidate/confusion set
Candidate Update: 
Confidence score @ word 
 MBR SCORE IS 
Confidence score @ alt word 
Using special symbol for silence = 
Adding hypothesis number 
 additional cost for non 1-best 
Adding 1-best [
] pen= 0.0 score= 
Add 1-Best word 
 confidence 
Adding alternative [
] pen= 
Was not able to topologically sort lattice (cycles found?)
INIT
MODEL
No Confidence Model Supplied.
Read in Confidence Model , added 
Scaling feature 
 with value of 
 by weight = 
Warning - confidence is NaN or inf, or will be inf in log - confidence model could be bad/compromised. Defaulting to 1.0
Confidence score is 
Rank in list = 
 Orig = 
 sc= 
 HIGH 
p_avg
p_max
p_min
p_geo
comb_score
lm_post
am_post
n_match
n_intersect
p_wcr
p_uni_lm
p_avg_low
p_avg_high
p_avg_diffhigh
p_avg_difflow
rank_score
low_rank_score
high_rank_score
delta_low
delta_high
p_mbr
p_fan_out
n_fan_out
p_fan_in
n_fan_in
n_wrd_inutt
avg_depth
avg_post
avg_ac
avg_lm
avg_conf
avg_like
avg_likelow
avg_likehigh
avg_ac_like
avg_ac_likelow
avg_ac_likehigh
ob_start
ob_dur
ob_p_avg
ob_p_max
ob_p_min
ob_p_geo
ob_comb_score
ob_lm_post
ob_am_post
ob_n_match
ob_n_intersect
ob_p_wcr
ob_p_uni_lm
ob_p_avg_low
ob_p_avg_high
ob_p_avg_diffhigh
ob_p_avg_difflow
ob_rank_score
ob_low_rank_score
ob_high_rank_score
ob_delta_low
ob_delta_high
ob_p_mbr
ob_p_fan_out
ob_n_fan_out
ob_p_fan_in
ob_n_fan_in
cand_p_avg
cand_p_min
cand_p_max
is_eps
alt_hyp_overlap
hyp_sub_alt_prev
hyp_sub_alt
hyp_sub_alt_next
alt_sub_hyp_prev
alt_sub_hyp
alt_sub_hyp_next
alt_lthalf_hyp
hyp_lthalf_alt
alt_in_prev
alt_prev_score
alt_in_next
alt_next_score
alt_tbp
ob_tbp
num_in_confset
prev_in_ob
next_in_ob
prev_best_score
next_best_score
cand_avg_p_avg
cand_avg_tbp
cand_avg_p_max
cand_avg_p_min
cand_wrd_len
sub_compound_left
sub_compound_right
is_lme_word
ob_is_lme_word
alt_has_lme_word
is_one_best
phonetic_dist_to_ob
min_phonetic_dist_confset
m.size() == Features::kFeatureCount
Too many states on the stack. There may be a cycle.
LabelsToUTF8String: Bad code point: 
LabelsToUTF8String: Invalid character found: 
Context size mismatch, ilabel-info [from context FST is 
, context-dependency object expects 
phone == 0.  Possibly you are trying to get a reversed FST with a non-central "central position" P (i.e. asymmetric context), but forgot to initialize the ContextFst object with P as N-1-P (or it could be a simpler problem)
phone == 0.  Some mismatch happened, or there is a code error.
GetHmmAsFst: context-dependency object could not produce 
an answer: pdf-class = 
 ctx-window = 
.  This probably points to either a coding error in some graph-building process, a mismatch of topology with context-dependency object, the wrong FST being passed on a command-line, or something of  that general nature.
tree did not succeed in converting phone window 
AddTransitionProbs: invalid symbol 
 on graph input side.
 on lattice input side.
Error generating random alignment (wrong length?): 
requested length is 
 versus min-length 
AddSelfLoops: graph already has self-loops.
Label 
 neither 0, nor a disambiguation symbol 
(#transition id = 
ConvertAlignment: could not map phone 
Failed to produce suitable phone lengths
ConvertAlignment: error converting alingment, possibly different topologies?
enabled 
 modelLanguage 
 requestLanguage 
Have result
Result is model
Model is compatible with recognizer. Returning it. Elapsed 
Returning nullptr. Elapsed 
task=
 appName=
com.apple.MobileSMS
Not loading custom-lm because task or app doesn't support it.
cache-size
Cache size for lazy replace operation
enable-lme
Enable LME
lme-sym-start-key
Starting key value for LME symbols
classLM-fst-file-list
list of classLM FST filenames, use comma to separate multiple ones
classLM-template-list
list of classLM templates, in the same order as the classLM-fst-file-list
classLM-nnlm-file-list
list of class Nnlm filenames, use comma to separate multiple ones
classLM-nnlm-template-list
list of classNNLM templates
classLM-nnlm-scale-list
list of classNNLM scales
classLM-start-name-list
list of classLM start names, in the same order as the classLM-fst-file-list
classLM-end-name-list
list of classLM end names, in the same order as the classLM-fst-file-list
Cached template ID 
 for 
The number of classLM templates = 
, which does not match the number of classLM Fst files = 
ClassNNLM doesn't have either tag or model provided.
classnnlm file list can only support one neural net 
Expected range start to be symbol id 
 and a phone word: 
Expected range end to be a disambiguation symbol: 
Disabling small LM pruning for symbols [
lmePhoneWordSymStart 
 lmePhoneWordSymEnd 
 lmeDisambigSymStart 
 lmeDisambigSymEnd 
Could not match classLM scale number
 Expected number of classLM symbols for base/start/end match: 
:lmeLoadingTime
LME container 
: offset 
 firstKey 
 lastKey 
Ignoring unsupported template 
 in stream # 
Ignoring null or arc-less FST for template 
lmeDataStreams and lmeInfos size mismatch. Should NEVER happen
lmeMergeInitTime 
 is null.
Reading LME container 
 for user 
LME container data 
LME data stream 
 has phone set version 
. This data stream will not be used.
Bad LME data (empty): stream=
, symTableFirstKey=
, symTableLastKey=
Bad LME data (invalid last key): stream=
, symTable->AvailableKey()=
 in blob is not supported by datapack.
 in blob uses different enumeration type (
) in datapack.
G2P model version 
 in blob is older than datapack's version 
geoLocationStatus
ClassLM template 
 assigned to FST from 
classlm_origin[
 assigned to NNLM from 
geoContextFound
geoLastRegionIdWasCached
geoLastRegionIdCacheMiss
Using location-specific classLM slot for template=
: placeholder 
 not found in regional map
, using placeholder 
 from regional map
Using decoder-specific classLM slot for template=
, location-specific slot not available
Filtering out unsupported / unused placeholder 
Japanese derived
Unable to get character type for some characters in the orthography
Tag with multiple words: 
Lattice score cache indices = 
 vals = 
Supplied frame 
 is out of range of cache which is in [0,
Pdf 
 is not in cache for frame 
Scaling factor for LM probabilities. Note: the ratio acoustic-scale/lm-scale is all that matters.
More than one lists detected in 
, only first list [
] will be used.
\EOS
Failed to tokenize 
Unable to open the file to read.
 frames
forced alignment source
forced alignment target
PDecForceAlignBlock 'source' input must not be empty
Option 'use-sentencepiece-ids' require vocabulary IDs set in 'input phrase'.
Ignoring shortlisting configuration for kaldi models, running with full readout layer
Inconsistent alignment dimension 
 expecting 
Inconsistent alignment dimension!
Model not conmpatible with `use-sentencepiece-ids`
Model lacks full symbol table, and require `use-sentencepiece-ids`
Source symbol sequence : 
 (length: 
Target symbol sequence : 
 excluding </s> symbol: 
model trained with supervised alignment required for alignment
invalid evaluation task specification 
invalid data specifier: 
invalid metric specifier: 
invalid optimization specifier: 
select-based-on
optimization-method
best-weight
weight list contains invalid range specification (should be e.g."0.0:0.2:10.0")
weight list range specification exceeds maximum number of weights: 
weight list should be comma-separated list of maximum size 
latitude
Latitude used in evaluation
longitude
Longitude used in evaluation
evaluation-metrics
List of metrics calculated during evaluation (e.g. dev-ppl, test-wer)
select-model-based-on
Metric based on which the best model is selected (i.e. usually dev-ppl)
Method to find the best model: "interpolation"(default) or "sweep-weights"
sweep-weights
Range of interpolation weights tested with optimization "sweep-weights"
min-audio
Required number of audio files
max-audio
Maximum number of audio files
remove-unk
If true simply removes all OOVs from input
min-weight
If final weight <= this value, model will not be used
max-weight
Weight will get clipped to this value when saving model
min-pass-rate
If >= 0: Fail the evaluation if ANY computeTextStats() call (1) returns failure OR (2) returns success but doesn't process enough utterances correctly to meet this threshold
min-unadapted-dev-ppl
If >= 0: Model will not be used if this condition is not met
max-unadapted-dev-ppl
min-best-weight-dev-ppl
max-best-weight-dev-ppl
min-dev-ppl-abs-improvement
min-dev-ppl-rel-improvement
dev-ppl
Model selection can only be done on a single metric (select-model-based-on)
invalid choice of min-audio and max-audio
sweep-weights specified in wrong format
Adding 0.0 to sweep-weight list for optimization method "
Adding 1.0 to sweep-weight list for optimization method "
std::is_sorted(evalWeightsList.begin(), evalWeightsList.end())
minWeight >= 0.0 && minWeight <= 1.0 && maxWeight >= 0.0 && maxWeight <= 1.0
First task should be on tuning on dev set
For interpolated models, we should evaluate weights 0 and 1
Task failed
model-selection
bestWeight (
) exceeds maxWeight (
). Clipping to maxWeight
) is below minWeight (
). Model will not be used
PPL checks failed
Running evaluation task 
 with 
 utterances
no text data available for 
computeTextStats failed
Pass rate: 
 passes: 
 total: 
Pass rate too low
perplexity interpolation failed for weight 
no audio data available for 
invalid evaluation metric
computing text stats for weight 
 FAILED
perplexity calculation failed, numTokens is 
bestWeights should be empty
best weight estimation for perplexity interpolation failed
best weights have wrong size or don't sum up to one
invalid optimization method
model selection returned an invalid weight
best weight: 
 PPL: 
checkPPL 
: No CorpusStat
: ppl 
 minPpl 
 maxPpl 
checkPPL: absImprovement 
 relImprovement 
lm-personalize.evaluator
en_US_napg.json
vocdelta.voc
pg.voc
mrec.psh
num-input-hyps must be provided for using model-based confidence
No result choices available. Skipping confidence estimation
Only one result in resultChoices and its empty. Skipping confidence estimation
Subword token index exceeds the number of subwords in the token
Filename for confidence model file. Each line must have the format: intercept <value> OR, <FEATURE> <WEIGHT> [ <FEATURE-MEAN> [ <FEATURE-STD> ] ](feature mean and std values are both optional, could be provided for feature normalization)
token-unigram-freqs
Name of the file with token unigram frequencies
num-input-hyps
number of hypotheses to expect as input to the confidence feature extractor
num-output-hyps
number of hypotheses to produce confidence values for
extract-features
Extract confidence features (even if model is not provided)
Unknown option "-%s";
  type "%s -help" for information
Warning: %s option "-%s" needs an argument
Warning: option "-%s" got a non-numeric argument "%s".  Using default: %d
Warning: option "-%s" got a negative argument "%s".  Using default: %u.
Warning: option "-%s" got non-floating-point argument "%s".  Using default: %lg.
Usage of command "%s"
 -%s%-*s %s
Default value: %d
Default value: %u
Default value: %lg
Default value: "%s"
 -help%-*s Print this message
%s: can't represent the time "%s".
%s: can't parse "%s" as a time.
total memory 
, used 
, wasted 
allocations of size 
allocations of size >= 
<NullWord>
<SymbolToWord>
<WordToSymbol>
<PhoneWordSymbol>
Tried to add overlapping and/or out-of-order symbol table to symbol table list: 
symTableFirstKey=
, previous symbol table's last key=
Word ID 
 not in symbol table 
 with start key 
Got word: 
) from symbol table 
 is already in the symbol list - indices in different symbol tables are not distinct
Found an empty LME word, which should not happen
seeva-greedy
model file
list of vocab
transform file
SeevaModel/__QNNI__source_input
SeevaModel/__QNNO__prediction
<spc>
@[^#]*#|#[^@]*@
EARSyncPSRAudioProcessor
<LeftContext>
<RightContext>
<SourceReversed>
<NoTargetConcat>
<ReattachTarget>
<DotProductRelation>
 (SourceStateDimension|MaxAttentions|LeftContext|RightContext)
component is not initialized, left and right context is 
The target input is concatenated. component has input dim 
The target input is not concatenated. component has input dim 
 , and output dim 
, and you requested to reattch the target, however, 
the internal component has output dim 
component has output dim 
 does not match the internal component's output dim 
the maximum attention is 
 , that does not match the left_context + 1 + right_context, you defined left/right context as 
the source state must have the same dimension as the input dimension of the component if want to take the dot product between them
if not taking the dot production relation from the source and target, you must at least concatenate or reattach the target
Internal error, unexpected pixel size 
Cannot open bitmap file 
Unexpected magic 
Bitmap width must be positive but was 
Bitmap height must be positive but was 
Whitespace expected before binary data
PGM header suggests different file size than actual size, expected=
 actual=
Could not map file 
 into memory
Mapped a PGM bitmap fileName=
 width=
 height=
 maxGreyValue=
latency
numFramesProcessed
totalWallTime
acousticLatency
contextModelLatency
localeSpecificMetrics
languageCode
posterior
confidence
messageLanguageTaggingLatency
isConfident
detectedLocale
conversationMessagePriors
lastMessageLanguage
numAcousticRuns
acousticScores
Invalid locale string given 
Logging LDContext
priors=
dictation_locales=[
current_dictaion_locale=
was_language_toggled=
multilingual_keyboard_locales=[
keyboard_convo_locale_priors=
keyboard_global_locale_priors=
previous_message_locale=
global_last_keyboard_used=
dictation_locale_priors=
window-size
The number of frames to be considered per decision. In flexible input size, this is the minimum window size for creating the 1st LID result. When prediction-interval is used, -1 will deactivate the minimum size.
feature-dim
The dimension size of the features.
languages-list
Comma separated list of languages
compiled-model-file
The name of the compiled model file
model-input-name
The name of the key for the model input
model-output-name
The name of the key for the model output
use-flexible-model
Whether or not the model accepts flexible (variable) input size.
max-window-size
The maximum size window for processing. Only works with flexible input size enabled.
use-cpu-only
Only use the CPU for inference
send-only-final-result
Do not send incremental results, send only the final result. Fixed input will always only send the final result.
minimum-confidence
For flexible input size, the minimum confidence for sending early results back. Only works with flexible input size enabled.
prediction-interval
The interval which we should make decisions (-1 is only once). Only works with flexible input size enabled.
ui-minimum-confidence
Determines whether or no the UI should consider the result non-confident. Should be greater than or equal to minimum-confidence.
input-tensor-shape
The shape of the input tensor specified by (dims, row index, col index).
Only use prediction interval with variable size input.
A negative window-size deactivates an initial minimum window size and requires a positive prediction-interval setting.
Max window size much be configured for flexible model
Must unable useFlexibleModel to have variable input size.
Maximum window size configured to be less than window size
Shape of the input tensor must be specified through (dims, row index, col index).
Input tensor row index must be non-negative and less than input tensor dims.
Input tensor col index must be non-negative less than input tensor dims.
Context provided no locale priors.
No acoustic posteriors.
Using dummy context model. Since acoustic posteriors are equal, defaulting to dictationLocales and currentDictationLocale from the context.
core-ml
acousticLanguagePosteriors
dictationLocales
currentDictationLocale
wasLocaleToggled
multilingualKeyboardLocales
keyboardConvoLocalePriors
keyboardGlobalLocalePriors
previousMessageLocale
globalLastKeyboardUsed
dictationLocalePriors
path to the model file
supported-locales
the locales understood by the model
supported-languages
the languages understood by the model
model-file-format
the format of the model file, must be "core-ml"
model-input-names
the input features expected by the model
the output feature that contains the locale posteriors
Invalid model file format "
Model input names contains duplicates
Invalid context-aware input feature name "
language-detectors
Configuration is incorrect. Only two components are supported.
ld-frontends.
ld-inference-model.
Something went wrong initializing the model.
override-locale-language-map
ld-context-aware-model
 found in config file, but no ContextAwareLDModelFactory was provided.
Something went wrong initializing the ContextAwareLDModelConfig.
Invalid sampling rate 
given.
Resetting for new request.
Version 118 or greater is required.
Unable to reset model.
 frames of audio.
Data is empty
Reached maximum window size. Treating this as the end of audio.
Not enough features yet to meet minimum window size.
Waiting until the next predictionInterval to run.
Running LanguageDetector with 
Something went wrong in LD inference.
Error in processing acoustic result.
Error running acoustic model.
No valid window found. Running contextual model based on equal acoustic priors.
Contextual model failed to run properly.
Language detector max confidence: 
Metrics for locale not in input: 
No context.
Empty priors.
If dictation priors are defined, then dictation locales must be.
4, 1, 2
Symbol: '
' not found in input symbols table.
 Mapping to null...
Not enough space
Invalid UTF-8
Invalid code point
bitset set argument out of range
LmeDataNotChecked
LmeDataOK
LmeDataNull
LmeDataOKButVersionOutdated
LmeDataVersionUnsupported
LmeDataPhoneSetMismatch
LmeDataCorrupt
Unknown
LmeNotUsed
LmeUsedNotRecognized
LmeUsedAndRecognized
, phoneSeq: 
, startSil: 
, confidence: 
, ipaPhoneSeq: 
OriginalToken: 
CandidateToken: 
There should be one cost for each result choice
concatNbest aChoices=
 bChoicesOrig=
 bChoices=
concatNbest[
 cost=(
 aIndex=
 bIndex=
tokenName
startMilliseconds
endMilliseconds
silStartMilliSeconds
hasSpaceAfter
hasSpaceBefore
phoneSeq
ipaPhoneSeq
Inconsistent number of columns. Expected 
Failed to open file: 
max-slot-depth
If >0, the max number of words to allow in each slot of the confusion network.
alt-confidence-model-file
eps-confidence-model-file
Filename for epsilon confidence model file, format <FEATURE> <WEIGHT> (one per line)
scale-low
Acoustic scaling factor (divisor) for low-end, eg, 2 (for a standard divisor of 12 = 0.08333)
scale-high
Acoustic scaling factor (divisor) for high-end, eg, 20 (for a standard divisor of 12 = 0.08333)
acoustic-scale
Scaling factor for acoustic likelihoods, default 0.08333
do-acoustic-stability
Turn computation of acoustic stability features (at multiple acoustic scales) on/off with true(default)/false.
do-process-alternatives
Control whether or not to process alternatives in the sausage network, or run in 1-Best mode, using true(default)/false.
do-process-sausage
Turn computation of features derived from the structure of the sausage network on/off with true(default)/false.
do-process-rank
Turn computation of rank-based features (at multiple acoustic scales) on/off with true(default)/false.
do-process-faninout
Turn computation of contextual posterior features related to fan-in and fan-out context on/off with true(default)/false.
do-process-post
Turn computation of lattice state posteriors (used for time-based-posterior and other measures) on/off with true(default)/false.
Turn computation of confidence score from the model off, effectively generating the time-based posterior as the confidence score,turn on/off with true(default)/false.
do-add-epsilon
Turn computation of epsilon confidence score on, this will use the supplied epsilon confidence model parameters score,turn on/off with true(default)/false.
decode-mbr
If true, do Minimum Bayes Risk decoding (else, Maximum a Posteriori)
number of NBest hypotheses to produce hypotheses (with confidence) for.
Prune incoming lattice to this beam
Finished initializing OnlineLatticeConfidenceDecoder.
sausage-labels
symList.size() != symListWords.size()
Note: Have trimmed confusion network slot depth from 
tokenDur: 
speechDur: 
%u blocks of %u-word chunks
ngram_quantized
reduced_transducer
reduced_acceptor
reduced_quantized_transducer
reduced_quantized_acceptor
squeezed_quantized_transducer
squeezed_quantized_acceptor
Reading FST: unsupported FST type: 
leftNnetWordmapExist || rightNnetWordmapExist
Malformed wordmap files. fileBasename=
, fileExtension=
Could not read the NNLM word map file 
found object in map for fst 
Writing FST: unable to open file to write: 
Writing FST: unsupported FST type: 
found object in map for symbol table 
Could not read symbol table from file: 
, type: 
Model is not in espresso format: 
Compiling espresso model: 
Skipping already compiled ANE model: 
Error happens in compiling network: 
, reason: 
Successfully compiled model in ANE cache: 
Purging espresso model: 
Failed to check ANE cache existence, network: 
, status: 
Skipping network which does not exist in ANE cache: 
Failed to purge model from ANE cache, network: 
Successfully purged model from ANE cache: 
backgroundLoading
fraction
ModelLoader embedded mlock overrides: 
could not sysconf(_SC_PAGESIZE): 
total 
 pages loaded of 
NGramFst::Read: Alignment failed: 
NGramFst::Read: Read failed: 
ReducedFst::Read: Alignment failed: 
ReducedFst::Read: Read failed: 
SqueezedFst::Read: Alignment failed before aligning states region: 
SqueezedFst::Read: Alignment failed before aligning arcs region: 
SqueezedFst::Read: Read failed after reading states and arcs: 
SqueezedFst::Read: Alignment failed before aligning final states region: 
Falling back to slow loading for 
SqueezedFst::Read: Read failed after reading final states: 
/*.weights
could not find weights for: 
could not open: 
could not lseek: 
could not mmap: 
loaded 
 pages of 
EARSPG: SilencePosteriorGenerator Config file does not exist at %@
resetForNewRequest
 or 
<Function>
<OutputTensor>
<AllowNonCPU>
src->GetNumDims() == 2
converted_data
Can't deal with this yet
Got nothing for needed output 
 in [
No input in model for 
CoreML feature provider creation failed: 
Could not make temporary MultiArray: 
unsupported MLFeatureValue type
t_ != nil
t_ == nil
Unsupported CoreML input type 
Unsupported CoreML required non-MultiArray input: 
Could not build blank array: 
v32@?0@"NSString"8@"MLFeatureDescription"16^B24
 => 
CoreML evaluation failed: 
data_batch.size() == batch_count
CoreML batch evaluation failed: 
CoreMLTensorData copy failed: 
Copy failed: 
could not make temporary array: 
vectorizeIntoMultiArray: failed: 
Asked for float32 of a non-float32 buffer
t_ || fv_
CoreMLTensorData create failed: 
Unsupported feature type: 
Could not make MLMultiArray: 
not supported MLMultiArray data type: 
<FiltXLen>
<FiltYLen>
<FiltXStep>
<FiltYStep>
<PadX>
<PadY>
 (ParamStddev|BiasMean|BiasRange|FmapXLen|FmapYLen|FiltXLen|FiltYLen|FiltXStep|FiltYStep|ConnectFmap|LearnRateCoef|BiasLearnRateCoef|RandomSeed|GradientNormType|MaxGrad)
input_dim_ % (fmap_x_len_ * fmap_y_len_) == 0
output_dim_ % (out_fmap_x_len * out_fmap_y_len) == 0
filters_->NumRows() == num_output_fmaps && filters_->NumCols() == num_input_fmaps * filt_x_len_ * filt_y_len_
wei_src.Dim() == NumParams()
 OutSizeX:
 OutSizeY:
 InFmaps:
 OutFmaps:
Performing vectorization of convolutional 2d component
Done  vectorization of convolutional 2D component
Convolutional2DComponent needs workspace set to perform back-propagation
Unsupported BNNS filter weight arrangement
It did not work
Unsupported
After assign, Convolution filter has padding? 
Reading Whe_
Whe_.Dims() 
Reading Whd_
Whd_.Dims() 
Reading Whc_
Whc_.Dims() 
Handover is not supported for stream input.
Model type requires full handover.
BidirectionalEncoder is not supported for stream input.
Un-supported model type : 
time decoder
time attention
time readout
time output embedding
Left symbol sequence : 
 (# 
Right symbol sequence : 
 including </s>) 
Constrained Softmax with force alignment decoding is not Supported!
<SymbolTable>
</SymbolTable>
<ModelType>
Full ModelType 
Undefined Torch model type
ModelType 
TorchN
TorchM
TorchT
TorchF
Unsupported Torch model type : 
Processing token 
Found BPE token
SHORTLIST
Found SHORTLIST token
TMPATT
Found TMPATT token
CHILD
Found CHILD token
PyTorch
Found PyTorch token
DotT
Found DotT token
AddTag:
Extracted add tag : 
AddTag value 
TagFormat:
Extracted tag format : 
TagFormat value 
ShareEmbed
Found shared embeddings token
EncPos
Found encoder position embedding token
DecPos
Found decoder position embedding token
Found add beginning of sentence tag
Found add end of sentence tag
AlignModel
MultipleDecoders
Found multiple decoders token
Found 'NoSymbolTables' token
Unknown model sub tag 
dot attention 
<NumDecoders>
<DecoderLanguage>
<HandoverCellStateOnly>
<HasHandoverLayer>
Handover layer not supported with PyTorch models 
 Cell handover 
 Has handover layer 
<HasInputSymbolTable>
Has input symbol table 
isyms
Embedded input symbols could not read
PyTorch require symbol table
Special input symbol(s) not defined <s> </s> <unk> 
Overridding default input symbols <<unk> = 
, </s> =  
<HasOutputSymbolTable>
Has output symbol table 
osyms
Embedded output symbols could not read
PyTorch requires symbol table
Special output symbol(s) not defined <s> </s> <unk> 
Overridding default output symbols <<unk> = 
Trying to read embedded BPE model 
Number of BPE entries : 
Trying to read Shortlist
Searching for SupervisedMultiHeadAttention component
Done reading model 
use coverage penalty 
number of frames in each batch, if <0 will feed whole speech in one batch
only streaming the encoder, no partial results
length-penalty-stream
if >= 0, use this value as length penalty during streaming. Otherwise use the value in the graph
if > 0, use this value as the coverage penalty. Otherwise use the value in the graph
cover-pen-ceil
the maximum coverage penalty
cover-pen-step-size
dynamically adjusting coverage penalty with this step size
silence-thresh
if > 0, turn on dynamic coverage penalty when encounter this amount of silence
min-input-count
if > 0, set the minimum number of frames to start streaming. Otherwise use the value in the graph
min-input-left
if > 0, set the minimum number of frames for leftover during streaming. Otherwise use the value in the graph
min-aln-weight
if > 0, set the minimum alignment weight during streaming. Otherwise use the value in the graph
min-init-aln
if > 0, set the minimum initial peak alignment value for the streaming. Otherwise use the value in the graph
min-cont-aln
if > 0, set the minimum continuous peak alignment value for the streaming. Otherwise use the value in the graph
aln-step-size
reduce the min-aln value by this size to increase streaming
min-aln-floor
the aln-value floor when reduction happens
max-input-count
if > 0 && < received_frames, reduce min-aln value to generate partial result if not already so
count-step-size
adjust the min-aln value according to this frequency
init-stable-tokens
number of tokens needed for stablizing the streaming inference at the initial stage
cont-stable-tokens
number of tokens needed for stablizing the streaming inference
dynamic-stable-tokens
turn on dynamic stable tokens to encourage streaming
min-token-floor
the stable token floor when reduction happens
if > 0, use this beam at the utterance end. Otherwise use the value in the graph
if > 0, scale the LME FST score. Otherwise use the value in the graph
if > 0, scale the nonLME arc score when LME is active. Otherwise use the value in the graph
<Topology>
</Topology>
<TopologyEntry>
Reading HmmTopology object, expected </Topology> or <TopologyEntry>, got 
<ForPhones>
Reading HmmTopology object, unexpected end of file while expecting phones.
</ForPhones>
Reading HmmTopology object, expected integer, got instead 
</TopologyEntry>
<State>
Expected </TopologyEntry> or <State>, got instead 
States are expected to be in order from zero, expected 
<PdfClass>
<SelfLoopPdfClass>
pdf classes should be defined using <PdfClass> 
or <ForwardPdfClass>/<SelfLoopPdfClass> pair
<ForwardPdfClass>
<Transition>
<Final>
You are trying to read old-format topology with new Kaldi.
</State>
Reading HmmTopology,  unexpected token 
Phone with index 
 appears in multiple topology entries.
HmmTopology::Check(), empty object.
HmmTopology::Check(), phone has no valid index.
HmmTopoloy::Check(), entry with no corresponding phones.
HmmTopology::Check(), cannot only have one state (i.e., must have at least one emitting state).
HmmTopology::Check(), last state must have no transitions.
HmmTopology::Check(), last state must not be emitting.
HmmTopology::Check(), negative or zero transition prob.
We do not allow any state to be nonemitting and have a transition to the final-state (this would stop the SplitToPhones function from identifying the last state of a phone.
HmmTopology::Check(), invalid dest state 
HmmTopology::Check(), duplicate transition found.
Total probability for state 
 in topology entry is 
HmmTopology::Check, state 
 has no input transitions.
HmmTopology::Check(), pdf_classes are expected to be contiguous and start from zero.
TopologyForPhone(), phone 
 not covered.
' with 
feature index=
 is in models file but missing in normstats file.
 is in normstats file but missing in model file.
Invalid line in file=
 line=
Did not find feature=
Atleast one feature weight and Intercept is needed in model file=
Successfully loaded streaming confidence model file=
Confidence model file connot be empty. Missing configuration parameter confidence-model-file
Normalization statistics is not in the correct format
Number of features does not match with model file, 
Incorrect number of feature means, 
Incorrect number of feature stddevs, 
Standard deviation is 0 for feature=
Unknown feature=
 in normalization statistics file
Successfully loaded streaming confidence normalization stats file=
Confidence normalization stats file cannot be empty. Missing configuration parameter norm-stats-file
Missing feature index=
 in input features
 feature[
 in means or stddev stats
Evaluated features=
, confidence=
INTERCEPT
isfirst
isinside
avg_active
avg_bestcost
avg_epsilenceframes
found invalid synset name '
' in phrasebook
wordnet
found entry without 'syn' field in wordnet phrasebook for '
string_view::substr
No frames fit in file (#samples is 
Non-finite log energy found for frame 
PTree::Error, Error reading JSON config file: 
PTree::JsonParseError, Error reading JSON config file: 
creating PhonetisaurusG2P object
creating PDecG2P object 
Unknown quasar G2P engine type: 
PNSR
/Assistant/SpeakerCode
trainingSpeakerCode
inferenceSpeakerCode
accumulatedGradient
numTrainedFrames
trainingNnetVersion
trainingOffset
recognitionOffset
Coordinates out of bounds latitude=
 longitude=
This or other location undefined, can't computer distance
lat=DENIED lon=DENIED
lat=UNDEFINED lon=UNDEFINED
lat=
 lon=
DENIED
UNDEFINED
KNOWN
num-best
PhonetisaurusG2P Config: model=
, nBest=
g2p model file doesn't exist, or it's a directory: 
Phonetisaurus failed to load model!
Increase nbest, and try again. nbest=
+Tgram]
 <= 0
max-seq-length-veto-factor
PDecG2P Config: model=
, beam=
, lmWeight=
, maxSeqLength=
, vetoFactor=
, lmModelFile=
, maxLengthVetoFactor=
Reducing maximum sequence length from 
 because of max-seq-length-veto-factor
-grams
Found protected token "
" is phonetically matched to "
Bad LME placeholder replacement pmOutput="
" with pmInput="
LME placeholder replacement pmOutput="
Mixture of wildcards and non-wildcards in replacement of input='
' with rawOutput='
' is invalid
Wildcards/placeholders found not replacing input='
No wildcards/placeholders found replacing input='
matchCost
isValid
spans
ITN Override: 
Moving token '
' to following span
' to preceeding span
Undefined GCD since m = 0, n = 0.
Changing word 
Iter = 
, delta-Q = 
Iterating too many times in MbrDecode; stopping.
Edit distance increased: 
L = 
Invalid b_arc value
sum of gamma[
,s] is 
Times out of order
MBR Sausage Alignment Epsilon Symbol is 
Invalid path found.
#Corrections: QsrText-encoded keyword: 
default-n-best-size
The default value for n-best size.
corrections.keyword-finder
keyword-finder.
corrections.sanitization
#Corrections: No sanitization model is provided.
#Corrections: Keyword Finder returning due to null input (not necessarily an error).
#Corrections: Keyword Finder original input utterance: 
#Corrections: Keyword: 
#Corrections: Keyword pronunciation: 
#Corrections: Keyword location: 
#Corrections: Edit distance: 
#Corrections: 
 KWF results from 
-best list
#Corrections: Pre-itn stitched result 
<NumGroups>
<NumTables>
<VocabSizes>
<MaxItems>
<EmbedDimensions>
<AssignedTable>
<InitializeToConcat>
<UseTransform>
, a typo in config? 
(NumGroups|VocabSizes|MaxDimensions|EmbedDimensions|LearnRateCoef|ParamStddev|RandomSeed|InitTransformType|GradientNormType|MaxGrad)
<FeatureTransform>
require an updatable component, you used 
dimension mismatch, cannot initialize to concatenation, expected dim is 
 actual dim is 
cannot initialize to concatenation for this transform
initialized the transform for concatenation
it doesn't make sense to initialize the embedding table as an identify matrix
, a typo in config? (NumGroups|VocabSizes|MaxDimensions|EmbedDimensions|LearnRateCoef)
failed to read feature transform
## Embedding Table: 
## Feature Transform: input-dim 
No intermediate gradients for embedding tables, here is the gradient info for the transforms: 
RMSPROP is not implemented in word multi embedding yet
must have at least one group, you used 
must have at least one embedding table, you used 
there are only 
 groups, but you set 
 embedding tables
 groups, but the number vocab list size is 
 groups, but the max item list size is 
 groups, but the embedding dim list size is 
 groups, but 
 groups have assigned tables
the actual number of embedding tables is 
 and different than 
 groups, but the number of feature transforms is 
the 
-th group has assigned table index 
 , the number of tables is 
-th group has invalid vocab size 
-th group has invalid max item value 
-th group has invalid embedding dimension value 
-th group has mismatched embedding table and vocab size 
-th group has mismatched embedding table and embedding dim 
-th group has mismatched embedding table and feature transform 
-th group has feature transform output dim 
 does not match component output dim 
input dim of the component is 
 , while the input dim defined in max items is 
Total embedding size of 
 doesn't match the component output size of 
 when transforms are not used
Not implemented yet when transforms are used
WordMultiVecComponent doesn't support multi-batches yet
Using transform with gradient compression is not supported yet
Performing vectorization of WordMultiVecComponent
veccorrs->size() == 1
Done  vectorization of WordMultiVecComponent
Write failure in WriteBasicType<bool>
Read failure in ReadBasicType<bool>, file position is 
ReadBasicType: expected float, saw 
ReadBasicType: failed to read, at file position 
Reading arbitrary strings in text mode is unimplemented
ReadString, failed to read string at file position 
ReadString, saw eof while looking for null terminator, at file position 
Writing arbitrary strings in text mode is unimplemented
Write failure in WriteString.
Write failure in WriteToken.
ReadToken, failed to read token at file position 
ReadToken, expected space after token, saw instead 
Error ungetting '<' in PeekToken
Failed to read token [started at file position 
], expected 
Expected token "
", got instead "
<ComputePlatform>
<CheckpointName>
ret == ESPRESSO_STATUS_SUCCESS
CPU_ALT
.net
.weights
espresso_plan_start_profiling_with_options(plan_, profilingOptions) == ESPRESSO_STATUS_SUCCESS
plan_ != nullptr
espresso_plan_build(plan_) == ESPRESSO_STATUS_SUCCESS
plan_ == network_.plan
es_data != nullptr
rank > 0
rank == result_shape.size()
result_shape[i] == shape[i]
buf_data != nullptr
Unsupported concat axis: 
src_buf != nullptr
src->GetNumDims() >= 1
0 <= start
start <= end
end <= num_split
Set function name for checkpoint failed, error=
Espresso failed query blob info 
Espresso failed to reset plan with 
Espresso failed to declare input `
Espresso failed to declare output `
configuration name not supported: 
Espresso failed to unpack shape for input `
Espresso failed to change input blob shapes with 
Espresso failed to build plan with 
kv.second->storage_type == ESPRESSO_STORAGE_TYPE_FLOAT32
espresso_network_bind_buffer failed: 
espresso_plan_execute_sync() failed: 
Failed to bind buffer for input=
, error=
Failed to run checkpoint network, error=
Failed to set function to main, error=
Failed to run main network, error=
Unsupported input dimensions
ANE_RUNTIME
ANE_RUNTIME_DIRECT
METAL
Using The Metal GPU backend (legacy, deprecated) 
METAL_MPS_GRAPH
Unknown platform: 
Set compute platform to 
batch_config_
width_config_
t_.buffer.storage_type == ESPRESSO_STORAGE_TYPE_FLOAT32
Tensor rank is greater than 2: 
srcESBuffer != nullptr
srcend - srcstart >= 0
length >= 0
unsupported storage type.
bitmap-file
lon-left
lon-right
The value of 
 is not greater than 
lat-bottom
lat-top
Bitmap file name cannot be empty!
.pgm
The bitmap file 
 has unexpected suffix, should be 
Loaded regions bitmap width=
Cannot use degenerate regions bitmap width=
Internal error, expecting a real location at this point
The value 
 is not a valid longitude
 is not a valid latitude
This is a FOFE model
penultimate 
Illegal value for 'phrase-book-mode' in 'PDecPhraseBookBlock': 
Failed to allocate array
Failed to create feature provider
Error during prediction
EARLanguageDetector
_EARLanguageDetector init failed
The configuration file or models for _EARLanguageDetector are incorrect.
NSString *localAFDictationLanguageForKeyboardLanguage(NSString *__strong)
EARLanguageDetector.mm
AFDictationLanguageForKeyboardLanguage
void *AssistantServicesLibrary()
arc_output_model_file.empty()
output_model_file.empty()
writeBinaryCount: count 
 is too large
readBinaryCount: incomplete long count
readBinaryCount: incomplete long long count
notch-detector.hfpower.txt
notch-detector.wt.txt
notch-detector.weighted.spectrum.txt
avlo = 
  avhi = 
bands_below.lo = 
, bands_below.hi = 
bands_notch.lo = 
, bands_notch.hi = 
bands_above.lo = 
, bands_above.hi = 
bands_across.lo = 
, bands_across.hi = 
notch-detector.peak.txt
quasar
wait-milliseconds
The number of milliseconds to wait for a confusion network to become available in the cache
No confusion network cache found.
No confusion network found in decodeChainOutput. Doing nothing.
This doesn't work when utt detect/concatenation is enabled. Doing nothing.
No confusion network found in cache. Doing nothing.
Detected phrases in confusion network - backing off to flattened 1-best (this is OK)
Combined sausage is empty. Doing nothing.
Tokens not monotonic and have been corrected.
mismatch between finished audio analytics frames and remaining frames+new wav frames: 
symbol table file
Reset scores after each result
num-discriminative-branches
Number of discriminative branch outputs to be decoded
discriminative-config-file
Config to map the keywords to the discriminative branch numbersAlso specifies the weights to be used for combining the phonetic and discriminative scoresExpected format: <kwdToken> <discBranchId> <phoneticScoreScaleFactor> <discScoreScaleFactor>
num-frames-to-use
Num of frames to use for decodingThis is specifically required when using discriminative branch as we need to use thediscriminative output coming out of the first block
No keywords configured, ignore discriminative config
invalid mapping, expected format <kwd> <discBranchId> <phoneticScaleFactor> <discScaleFactor>
Invalid discriminative branch ID
Kwd: 
 DiscriminativeBranch: 
Weights: 
Mismatch in num keywords specified in discriminative config
DP contains no keywords for detection
Coding error. Keyword 
KWD: 
 CTC Score: 
 Disc Score: 
Dimension mismatch. Code or DP error
Frames seen so far: 
Error reading phone map from 
 (bad line 
Read empty phone map from 
illegal skip prob line
bad skip prob value 
%s %lg
iteration 
log likelihood = 
cannot write data to zero size vector
invalid input data type specifier: 
inputDataType 
 numDocumentsRejected 
 numSentencesRejected 
 numSentencesMungeRejected 
 numDocuments 
 numUniqSentences 
 numSentences 
 numSentencesMungeChanged 
 numTokens 
 numTokensOOV 
numDocumentsRejected
numSentencesRejected
numDocuments
numSentences
numTokens
numTokensOOV
numDocumentsDictated
numDocumentsTyped
numTokensDictated
numTokensTyped
numTokensEstimatedExamined
numSentencesMungeRejected
numSentencesMungeChanged
Unsupported config: first decoder is not lattice-biglm-lme-faster
Unsupported config: first decoder lacks word-syms-map-file
min-words should be a single int or a comma-separated list of size 1..
minWords.size() == NumDataSetTypes
train-dev-test-split should be comma-separated list of size 
splitOffsets: 
train-dev-test-split values should sum to 1
external-train-dev-test-split should be comma-separated list of size 
externalSplitOffsets: 
external-train-dev-test-split values should sum to 1
symbolTable init 
Observing symbols from 
 symbols in bigG 
symbol=
Could not find OOV symbol: 
Symbol out of range: 
Symbol has wrong value in symbolInBigG: 
OOV replacement 
 identical with unseenId
OOV replacement not in symbol table or out of range: 
train ARPA LM file doesn't exist: 
 didn't observe OOV symbol 
 in 
Filtering by languages 
Creating lmScorer. minSentencePpl=
 maxSentencePpl=
external
Train data: 
Dev data: 
Test data: 
External test data: 
train-dev-test-split
Comma-separated list of 3 positive numbers that should sum to 1. Example: 0.7:0.2:0.1 means data will be split as follows: 70%% train, 20%% dev, and 10%% test
sources
Comma-separated list of sources. They can be anything since the caller is responsible for interpreting them.
query-limit
Query limit. The caller is responsible for interpreting this.
max-age-days
Maximum age of data. The caller is responsible for interpreting this.
min-age-days
Minimum age of data. The caller is responsible for interpreting this.
min-words
Minimum number of total words for training to proceed.
max-words
Maximum number of total words to use.
oov-replacement
Replace OOVs with this token
filter-language
If true, filter text by Language ID
external-data-file
Optionally provide an external data file as general test set to evaluate over-adaptation
external-train-dev-test-split
Will split into common train & dev sets, but keeping an extra external test set.Comma-separated list of 3 positive numbers that should sum to 1. Example: 0.1:0.2:0.7 means external data will be split as follows: 10%% train, 20%% dev, and 70%% external
munge-file
Munge file. See documentation in Munger.hpp
min-sentence-ppl
If >= 0: sentences with background LM PPL < this value are rejected.
max-sentence-ppl
If >= 0: sentences with background LM PPL > this value are rejected.
max-sentence-oov-ratio
If >= 0: sentences with OOV ratio > this value are rejected.
max-sentence-oov-count
If >= 0: sentences with OOV count > this value are rejected.
max-document-length
If > 0: documents with length (UTF8 bytes) > this value are rejected.
max-sentences-per-document
If > 0: documents with number of sentences > this value are rejected.
max-sentence-length
If > 0: sentences with length (UTF8 bytes) > this value are rejected.
max-token-length
If > 0: sentences with token length (UTF8 bytes) > this value are rejected.
filter-language-list
Comma-separated list of languages to keep using Language ID. Default: model-info.language.split('_')[0]. Example default: 'en' for 'en_US'
input-type
Format of input data (e.g. ngram-counts). Default: plain-text
rdar-69947462
Requires approval of <rdar://problem/69947462> [AzulC] New fields in Dictation Personalization dodML
filter-document-types
A list of document types which will be excluded from training corpus, e.g. typed, dictated
train-arpa-lm-file
ARPA LM file estimated from training data
max-examined-words
Maximum number of words that can be investigated or preprocessed
max-estimated-examined-words
Maximum number of estimated words that can be investigated or preprocessed
cjk-characters-per-word
Number of average characters per word in CJK locales
externalSplitOffsets.size() == NumPartitions
splitOffsets.size() == NumPartitions
external data file doesn't exist: 
Reading external data file 
addNgramCounts only support training data currently!
Unable to split line "
" into n-gram and count.
Unable to parse count of line "
OOV token encountered in ngram counts. Skipping...
ADDED 
 : number of tokens and symbolIds don't match
Reject due to empty
oovRatio=
 numTokensOOV=
Reject due to high oov ratio
Reject due to high oov count
Reject due to no ppl
ppl=
Reject due to low ppl
Reject due to high ppl
Unsupported input type 
invalid input sentence: 
 for reading
numSymbolsInTrainSet 
Unable to serialize record.
data metrics 
Cannot have leading or trailing space in filename "
Found ~ at the beginning of filename "
". Shell like path expansions not supported.
Found what looks like an rspecifier instead of a filename "
Trying to classify rxfilename with pipe symbol in the wrong place (pipe without | at the end?): 
Error opening input stream 
Invalid input filename format 
Input::Stream(), not open.
open called on already open file.
, errno is 
Pipe 
 had nonzero return status 
FileInputImpl::Open(), 
FileInputImpl::Stream(), file is not open.
FileInputImpl::Close(), file is not open.
StandardInputImpl::Open(), open called on already open file.
StandardInputImpl::Stream(), object not initialized.
StandardInputImpl::Close(), file is not open.
Failed opening pipe for reading, command is: 
Pipe opened with command 
 is empty.
PipeInputImpl::Stream(), object not initialized.
PipeInputImpl::Close(), file is not open.
Cannot get offset from filename 
 (possibly you compiled in 32-bit and have a >32-bit
 byte offset into a file; you'll have to compile 64-bit.
system-combination
selected-chain
Decoder chain to select for output.
selection-model-file
Filename for selection model. Each line must have the format: intercept <value> OR, <FEATURE> <WEIGHT> [ <FEATURE-MEAN> [ <FEATURE-STD> ] ](feature mean and std values are both optional, could be provided for feature normalization)
num-hyps-primary
Number of primary chain hypotheses to consider for selection.
num-hyps-secondary
Number of secondary chain hypotheses to consider for selection.
selection-threshold
Threshold value for system selection
uncombinable-word-tags
Force primary selection if recognition has any of these suffixes
disable-pron-transfer
Do not copy word pronunciations from the primary chain
disable-after-first-utterance
Do not run system combination for second-and-later utterances
No selection model supplied. The output of the primary chain will be selected.
 before calling runAsyncTasks().
Running async tasks of Decoder: 
Not running async tasks for post-first utterances of Decoder: 
Synchronous decoding failed: 
All secondary chain decoders should affect recognition.
Skipping run for post-first utterances of Decoder: 
Last frame of utterance has not been processed, returning success without running system selection
Eager not enabled, running system selection
Last frame of utterance has been processed, running system selection
Secondary decoder chains threw an exception. Skipping system combination.
Done with workerthreads
Output of the secondary decoder chain (
) was selected.
Could not find frame duration of selected secondary decoder chain.
decoderChainOutput->uttNumFrames * decoderPassData.featureMatrix->FrameDurationMs() >= selectedDecoderChainOutput->uttNumFrames * selectedFrameDuration->second
decoderChainOutput->processedLastFrame == selectedDecoderChainOutput->processedLastFrame
Output of the primary decoder chain was selected.
Both the primary and secondary result choices are empty
No result choices were available for the secondary chain. Selecting the primary chain
Result choices for the primary chain:
Result choices for the secondary chain 
Number of primary chain alternatives was less than the number of hypotheses requested for selection. The last choice will be repeated
Number of secondary chain alternatives was less than the number of hypotheses requested for selection. The last choice will be repeated
Output of primary decoder chain was selected because it contains uncombinable word tags
Feature extraction for system selection failed. Selecting the primary chain.
No selection model was provided, output of primary decoder chain was selected.
Output of the secondary decoder chain 
 was selected.
primary (
) != secondary (
Result choice 
 was empty
 (size = 
Received 
hypotheses for feature extraction, expected 
 OOVs
 zeroprobs, 
logprob= 
 ppl= 
 ppl= undefined
 ppl1= 
 ppl1= undefined
 words,
 rank1= 
 rank5= 
 rank10= 
 words+sents,
 rank1wSent= 
 rank5wSent= 
 rank10wSent= 
 qloss= 
 absloss= 
"). 
Trailing whitespace not allowd in rspecifier (found "
Will treat this as kNoRspecifier.
SRILM release %s
1.7.1
 (with third-party contributions)
Program version %s
This software is subject to the SRILM Community Research License Version
1.0 (the "License"); you may not use this software except in compliance
with the License.  A copy of the License is included in the SRILM root
directory in the "License" file.  Software distributed under the License
is distributed on an "AS IS" basis, WITHOUT WARRANTY OF ANY KIND, either
express or implied.  See the License for the specific language governing
rights and limitations under the License.
This software is Copyright (c) 1995-2014 SRI International.  All rights
reserved.
Portions of this software are
Copyright (c) 2002-2005 Jeff Bilmes
Copyright (c) 2009-2013 Tanel Alumae
Copyright (c) 2012-2013 Microsoft Corp.
SRILM also includes open-source software as listed in the
ACKNOWLEDGEMENTS file in the SRILM root directory.
If this software was obtained under a commercial license agreement with
SRI then the provisions therein govern the use of the software and the
above notice does not apply.
Support for compressed files is included.
%u@%255s
%64s
server host 
 not found
socket: server 
connect: server 
server 
: could not read banner
send: server 
: protocol version 2 not supported
recv: server 
: unexpected return: 
%lu %u
: send 
text mapper entries must be unique
Overriding parameter: 
Overrides JSON does not contain section for '
'.  Skipping.
Json config filename=
Overrides JSON does not exist in datapack; falling back to default overrides.
non_acoustic_default
dictation_cs50
dictation
Failed to load paramset holder
Loaded paramset holder file:  
Could not find file 
Could not laod Empty voc
Could not load PG voc
Mandatory config field missing
Pronguess paramset value is not valid.
Search paramset value is not valid.
Lattice-nbest paramset value is not valid.
FragmentWordsState
OptionalPronWordsState
Generating pronunciations for orthography=
, spoken-form=
Orthography=
, Prons=
pronguess_paramset_name
search_paramset_name
lattice_nbest_paramset_name
napg_params
overrides
title_format
pronguess_overrides
search_overrides
lattice_nbest_overrides
Unknown PDec model type: 
.0 to use PDec model type: 
Compatible system config version (
.0) for PDec model type 
.0 required)
Unknown PDec feature flag: 
.0 to use PDec feature flag: 
.0) for PDec feature flag 
seeva-batch
seeva inference graph file
the vocab file that describes model output token
lm-rescore-chain
the LM rescore decoder chain
use-second-rescore
use the LM rescoring decoder
remove the unknown word during rescoring
unk-word
map the OOV word to this word
e2e-word-map-file
map the E2E word to Quasar
lm weight for LM rescoring
LM-SCORE-DEBUG: select beam 
SeevaModel/__QNNI__source_catf_input
SeevaModel/__QNNI__length_penalty_weight
SeevaModel/__QNNO__nbest_list
SeevaModel/__QNNO__nbest_score
source-input-str
source input tensor name
source-catf-input-str
source catf input tensor name
length-pen-wt-str
length penalty weight tensor name
nbest-list-str
nbest list tensor name
nbest-score-str
nbest score tensor name
/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/libquasar/liblm/src/impl/arpa2fst.cpp
Arc sorting not supported when using 
Explicit modeling of <s> and </s> is not supported when using 
Retention of disambiguation symbols is not supported when using 
Retention of redundant states is not supported when using 
Attaching symbol table is not supported when using 
Unknown ConvertToFST implementation: 
The symbol with key 0 should be 
phonetic-match-building.on-device-data-sources.
limit
Limit on the number of items, default=
prior-exp-decay-factor
Exponential decay factor, default=
prior-power-scale
Prior scale of the priors, default=
Regex
RegexEnumerator not available for 
Enumerator is not available for field [
Prior
Unable to open the file to write: '
Could not find prior field '
' in the header
Could not find field '
 fields, but found 
 at '
Prior field out of bound: 
Invalid prior: 
artists_songs
artists_albums
artist_name
song_name
album_name
playlist_name
radiostation_name
composer_name
genre_name
podcast_name
audiobook_name
movie_name
show_name
An error occurred when reading TSV from: 
An error occurred when reading NT from: 
Invalid DataFeed type 
Field '
' does not exist in data feed, skipping.
Data feed [
] is not supplied, skipping the spoken form '
prior
Found feed: 
min_popularity
power_scale
prior_field
text_fields
date_field
Loading from 
Number of output lattice states is getting out of hand, aborting conversion
Could not find arc for input_state 
 olabel 
 in LM. Failed to reconstruct lattice (incompatible LM?).
Acoustic model file
Phone table file
optional-silence
Optional silence phone
silence-prob
Silence probability (0.0 to 1.0)
Word boundary file
align-lattice-expand-limit
Lattice expansion limit when doing word alignment(0 for none)
reconstruct-lattice-expand-limit
Lattice expansion limit when doing lattice reconstruction(0 for none)
big-g-fst-file
Negative SmallG FST filename
raw-smallg-fst-file
SmallG FST (with no phone or word loops for nonterminals) filename
extended-report
Set to false if only the concise error-report should be generated.
lm-context-length
Language model context length (e.g. 4-gram has length 3)
overlap-percentage
Required overlap in percent of two regions in reference and hypothesis to be viewed as the same region.
json-output-format
True if error reports should be formatted as JSON file.
You have not specified unpronounced-word-file. This will prevent you from using class LM tags 
like \CS-GeoBizName-start and \CS-GeoBizName-end in the ref transcription for error blamer. 
Created lexicon FST
WORD-DIS-
 phone words (including word disambig symbols) in base word table
inv-g-fst-file is now ignored because it does not work with class LMs. 
Please use raw-smallg-fst-file.
The number of big FST LMs + NN LMs doesn't match the number of weights (FST LMs + NN LMs)
Word alignment failed.
Word alignment lattice empty.
Lattice reconstruction failed.
 not found in symbol table(s).
 has word ID 0.
Ref transcription word: 
, ID: 
HypoStartFrame
HypoEndFrame
RefStartFrame
RefEndFrame
RefLmCost
HypoLmCost
RefAmCost
HypoAmCost
RefWords
HypoWords
Confusions
RefModel
HypoModel
RefPhone
HypoPhone
Word
StartFrame
EndFrame
LmCost
AmCost
RefTotalCost
HypoTotalCost
RefGraphCost
HypoGraphCost
Attributes
ErrorRegions
PresentInLattice
RankInLattice
Recoverable
AmScaleFactorToRecover
ReferenceInfo
No reference transcription provided.
no first pass LM defined
total number of LMs is 
, but the number of interpolation weights is 
Left context labels not yet implemented.
Failed to map compound LME words. LME data is probably corrupt.
Could not map all words to symbol ids.
failed-words
Failed to create decoding graph.
 Hint: Are all the ref words in the pron lexicon?
Encountered problem while creating decoding graph for reference.
Retrying utterance with beam 
Problem decoding utterance for forced alignment.
Encountered problem while force aligning the reference.
Word alignment failed for reference lattice. Aborting error-blaming.
Encountered problem while word-aligning the reference lattice.
Reference lattice reconstruction failed. Aborting error-blaming.
Encountered problem while reconstructing the reference lattice.
Word alignment failed for hypothesis lattice. Aborting error-blaming.
Encountered problem while word-aligning the hypothesis lattice.
Hypothesis lattice reconstruction failed.
Encountered problem while reconstructing the hypothesis lattice.
LM rescoring in error-blamer was not successful.
LM rescoring was not successful.
Lattice reconstruction with smallG failed.
Encountered problem while trying to reconstruct lattices with smallG.
smallG
transition-scale
Scale of transition probabilities (excluding self-loops)
self-loop-scale
Scale of self-loop vs. non-self-loop probability mass 
Reorder transition ids for greater decoding efficiency.
rm-eps
Remove [most] epsilons before minimization (only applicable if disambig symbols present)
Unable to parse input string.
Pre-alignment tokens not monotonic.
Aligner failed. There is a BUG. FIX THIS!!!
 alignment=
 src=[
] dest=[
Hammer rewrite failed.
@[a-z]*#|#[a-z]*@
Unsupported model format version.
LM-SCORE-DEBUG: beam 
 E2E 
 LM 
0-th beam failed
seeva
SeevaModel/__QNNI__coverage_penalty_weight
SeevaModel/__QNNI__minimum_input_count
SeevaModel/__QNNI__minimum_input_left
SeevaModel/__QNNI__minimum_alignment_weight
SeevaModel/__QNNI__minimum_peak_alignment
SeevaModel/__QNNI__stable_tokens
SeevaModel/__QNNI__utt_end_beam
SeevaModel/__QNNI__trace_back
SeevaModel/decoder/__QNNO__nbest_list
SeevaModel/decoder/__QNNO__nbest_score
SeevaModel/decoder/__QNNO__graph_reset
SeevaModel/decoder/__QNNO__partial_result
SeevaModel/decoder/__QNNO__encoder_only
SeevaModel/__QNNI__lme_fst_header
SeevaModel/__QNNI__lme_fst_states
SeevaModel/__QNNI__lme_fst_arcs
SeevaModel/__QNNI__lme_score_scale
SeevaModel/__QNNI__nonlme_score_scale
Version mismatch for PronChoice
Unknown format for pronunciation string
Empty pronunciations for one of the tokens. Exiting with 0 pron combinations.
pron combination = 
, logWeight = 
Cycles detected in lattice
Invalid lattice: different paths have a different number of frames
Utterance does not seem to have a consistent length.
Utterance does not have a final-state.
Invalid lattice: final state before max_time
Topological sorting failed
Done Topo Sort
Failure in best-path algorithm for lattice (infinite costs?)
Add 
 ilabel 
 usedarcind 
 weight 
Rescoring empty lattice
the DeterministicOnDemandFst is invalid
invalid arc.olabel 
cannot find arc with label 
 on state 
 in the LM FST, wrong input?
POSITION = 
 FROM: 
 TO: 
 WORD = 
 PROB = 
 EXPANDPROB = 
class expansion contains no words
%s %lf
varprune
pruning threshold for variable order ngrams
debugging level for LM
recompute
recompute lower-order counts by summation
sort
sort ngrams output
write-order
output ngram counts order
file tag to use in messages
text file to read
text-has-weights
text file contains count weights
counts file to read
intersect
intersect counts with this file
read-with-mincounts
apply minimum counts when reading counts file
read-google
Google counts directory to read
counts file to write
write1
1gram counts file to write
write2
2gram counts file to write
write3
3gram counts file to write
write4
4gram counts file to write
write5
5gram counts file to write
write6
6gram counts file to write
write7
7gram counts file to write
write8
8gram counts file to write
write9
9gram counts file to write
write-binary
binary counts file to write
lower GT discounting cutoff
upper GT discounting cutoff
gt1min
lower 1gram discounting cutoff
gt1max
upper 1gram discounting cutoff
gt2min
lower 2gram discounting cutoff
gt2max
upper 2gram discounting cutoff
gt3min
lower 3gram discounting cutoff
gt3max
upper 3gram discounting cutoff
gt4min
lower 4gram discounting cutoff
gt4max
upper 4gram discounting cutoff
gt5min
lower 5gram discounting cutoff
gt5max
upper 5gram discounting cutoff
gt6min
lower 6gram discounting cutoff
gt6max
upper 6gram discounting cutoff
gt7min
lower 7gram discounting cutoff
gt7max
upper 7gram discounting cutoff
gt8min
lower 8gram discounting cutoff
gt8max
upper 8gram discounting cutoff
gt9min
lower 9gram discounting cutoff
gt9max
upper 9gram discounting cutoff
Good-Turing discount parameter file
Good-Turing 1gram discounts
Good-Turing 2gram discounts
Good-Turing 3gram discounts
Good-Turing 4gram discounts
Good-Turing 5gram discounts
Good-Turing 6gram discounts
Good-Turing 7gram discounts
Good-Turing 8gram discounts
Good-Turing 9gram discounts
discounting constant
cdiscount1
1gram discounting constant
cdiscount2
2gram discounting constant
cdiscount3
3gram discounting constant
cdiscount4
4gram discounting constant
cdiscount5
5gram discounting constant
cdiscount6
6gram discounting constant
cdiscount7
7gram discounting constant
cdiscount8
8gram discounting constant
cdiscount9
9gram discounting constant
use natural discounting
ndiscount1
1gram natural discounting
ndiscount2
2gram natural discounting
ndiscount3
3gram natural discounting
ndiscount4
4gram natural discounting
ndiscount5
5gram natural discounting
ndiscount6
6gram natural discounting
ndiscount7
7gram natural discounting
ndiscount8
8gram natural discounting
ndiscount9
9gram natural discounting
addsmooth
additive smoothing constant
addsmooth1
1gram additive smoothing constant
addsmooth2
2gram additive smoothing constant
addsmooth3
3gram additive smoothing constant
addsmooth4
4gram additive smoothing constant
addsmooth5
5gram additive smoothing constant
addsmooth6
6gram additive smoothing constant
addsmooth7
7gram additive smoothing constant
addsmooth8
8gram additive smoothing constant
addsmooth9
9gram additive smoothing constant
use Witten-Bell discounting
wbdiscount1
1gram Witten-Bell discounting
wbdiscount2
2gram Witten-Bell discounting
wbdiscount3
3gram Witten-Bell discounting
wbdiscount4
4gram Witten-Bell discounting
wbdiscount5
5gram Witten-Bell discounting
wbdiscount6
6gram Witten-Bell discounting
wbdiscount7
7gram Witten-Bell discounting
wbdiscount8
8gram Witten-Bell discounting
wbdiscount9
9gram Witten-Bell discounting
use modified Kneser-Ney discounting
kndiscount1
1gram modified Kneser-Ney discounting
kndiscount2
2gram modified Kneser-Ney discounting
kndiscount3
3gram modified Kneser-Ney discounting
kndiscount4
4gram modified Kneser-Ney discounting
kndiscount5
5gram modified Kneser-Ney discounting
kndiscount6
6gram modified Kneser-Ney discounting
kndiscount7
7gram modified Kneser-Ney discounting
kndiscount8
8gram modified Kneser-Ney discounting
kndiscount9
9gram modified Kneser-Ney discounting
use original Kneser-Ney discounting
ukndiscount1
1gram original Kneser-Ney discounting
ukndiscount2
2gram original Kneser-Ney discounting
ukndiscount3
3gram original Kneser-Ney discounting
ukndiscount4
4gram original Kneser-Ney discounting
ukndiscount5
5gram original Kneser-Ney discounting
ukndiscount6
6gram original Kneser-Ney discounting
ukndiscount7
7gram original Kneser-Ney discounting
ukndiscount8
8gram original Kneser-Ney discounting
ukndiscount9
9gram original Kneser-Ney discounting
Kneser-Ney discount parameter file
Kneser-Ney 1gram discounts
Kneser-Ney 2gram discounts
Kneser-Ney 3gram discounts
Kneser-Ney 4gram discounts
Kneser-Ney 5gram discounts
Kneser-Ney 6gram discounts
Kneser-Ney 7gram discounts
Kneser-Ney 8gram discounts
Kneser-Ney 9gram discounts
input counts already modified for KN smoothing
kn-modify-counts-at-end
modify counts after discount estimation rather than before
use interpolated estimates
interpolate1
use interpolated 1gram estimates
interpolate2
use interpolated 2gram estimates
interpolate3
use interpolated 3gram estimates
interpolate4
use interpolated 4gram estimates
interpolate5
use interpolated 5gram estimates
interpolate6
use interpolated 6gram estimates
interpolate7
use interpolated 7gram estimates
interpolate8
use interpolated 8gram estimates
interpolate9
use interpolated 9gram estimates
LM to estimate
write-binary-lm
output LM in binary format
init-lm
initial LM for EM estimation
keep <unk> in LM
meta-tag
meta tag used to input count-of-count information
use fractional counts
closed-form-doug-paul-hack
use a closed-form formula for the Doug Paul Hack
build a tagged LM
train a count-based LM
build a skip N-gram LM
skip-init
default initial skip probability
em-iters
max number of EM iterations
em-delta
min log likelihood delta for EM
Estimate maximum entropy model
maxent-alpha
The L1 regularisation constant for max-ent estimation
maxent-sigma2
The L2 regularisation constant for max-ent estimation (default: 6 for estimation, 0.5 for adaptation)
Save estimated max-ent model as a regular ARPA backoff model
trust-totals
trust lower-order counts for estimation
limit count reading to specified vocabulary
write vocab to file
write-vocab-index
write vocab index map to file
the default action is to write counts to stdout
fractional counts, variable, tagged, stop-word Ngram and skip N-gram models are mutually exclusive
conflicting default discounting options
option tagged not yet supported when providing external Vocab
error reading Google counts from 
LM order must be positive -- set to 1
conflicting discounting options for order 
using NaturalDiscount for 
using WittenBell for 
using ConstDiscount for 
using AddSmooth for 
using KneserNey for 
using ModKneserNey for 
using GoodTuring for 
error in reading discount parameter file 
error in discount estimator for order 
Closed-form Doug Paul Hack is not supported in combination with a count-based LM.
format error in init-lm file
count-lm estimation needs initial model
cannot use -float-counts with count-lm
LM estimation failed
Closed-form Doug Paul Hack is not supported in combination with a maximum-entropy LM.
format error in maxent prior (-init-lm) file
Maxent LM estimation failed
opts_.max_utt_trailing_sil_frames >= 0
opts_.max_utt_frames >= opts_.max_utt_trailing_sil_frames
values
Map of <int, float>. Example: {"8000": 1, "16000": 0}
: Cannot find key: 
Unknown location
Building appendable feature 
sampling-rate
location
Unknown appendable feature: 
Rejected client conf network due to invalid HatText encoding
Stored conf network!
regular expression replacer in: 
regular expression replacer out: 
Only (global) replacement operations are supported, got 
 with specifier 
read expression: "
", mapping to "
RegularExpressionReplacer read in 
 regular expressions
Begin
Both
None
Unknown AddTag format
bothAsOne
bothasone
bothSeparate
bothseparate
Unknown tag format 
Pushing weights of empty compact lattice
Lattice has non-coaccessible states.
Encountered unexpected number of enumerations: 
Sanitizer already initialized.
Initialized Sanitizer
The model is not of type nnet1::Nnet1InferenceNet.
Neural net file
!\exclamation-mark
,\comma
.\period
;\semicolon
:\colon
?\question-mark
I\pronoun
v40@?0@"NSString"8{_NSRange=QQ}16^B32
order %u
mixweights %u
 %lg
countmodulus %s
vocabsize %s
totalcount %s
counts -
google-counts %s
counts %s
order %u
vocabsize %99s
totalcount %99s
countmodulus %99s
mixweights %u
premature end to mixture weights
%lg%n
incomplete mixture weight vector
counts %1023s
google-counts %1023s
warning: zero denominator count for ngram 
posterior counts 
warning: no data to estimate mixture weight 
for count 
, order 
Supplied utterance id is out of bounds
RefDurations
HypoDurations
Reference
Hypothesis
RefTotalScore
HypoTotalScore
RefAmScore
HypoAmScore
Reference is not in hypo lattice
Reference is in hypo lattice (Rank: 
) and 
cannot be recovered
can be recovered by multiplying the current acoustic-scale with 
Not able to convert given phone_id 
, check if given phone symbol table is the correct one.
HOTFIX
fst_custom.fst
decoders
lattice-biglm-lme-faster.big-g-fst-file-list
big-g-fst-file-list not found for decoder 
 skipping..
lattice-biglm-lme-faster.word-syms-map-file
Symbol-table file not found in json file 
1shot_new.json
{{TEMPLATE}}
\NT-unknown
Failed to tokenize
Tokenizer could not tokenize
template list not found for used template 
template list not found for used template: 
template names should be enclosed in {} and contain only one word (lowercase)
Number of OOVs = 
No OOVs
could not get LME data
Template names should be enclosed in {} and contain only one word (in lowercase)
No templates provided
Template names should be enclosed in {} and contain only one word
Template list found more than once for : 
Input FST is cyclic
Could not write fst to file path 
Could not write fst to file
print version information and exit
adapt-order
maximum n-gram order for which adaptation is to be performed [default is 3]
lm-order
n-gram order of the LM to be adapted (passed via -read-lm option) [default is 3]
read-text
text file of adaptation data. Only n-gram counts up to the order passed via -adapt-order will be generated from this file
indicates that text file passed via -read-text or -read-dev contains count weights
read-counts
counts file of adaptation data. Only n-gram counts up to the order passed via -adapt-order will be read from this file
adaptation weight. It will be used for all n-gram orders for which no -eta(n) is provided
eta1
adaptation weight for 1-grams
eta2
adaptation weight for 2-grams
eta3
adaptation weight for 3-grams
eta4
adaptation weight for 4-grams
eta5
adaptation weight for 5-grams
eta6
adaptation weight for 6-grams
eta7
adaptation weight for 7-grams
eta8
adaptation weight for 8-grams
eta9
adaptation weight for 9-grams
read-lm
LM file to be adapted. This is an LM file in ARPA text or binary format
output adapted LM file. This is an ARPA LM in text or binary format, see -write-binary-lm [default is text format]
indicates that the output adapted LM file passed via -write-lm will be written in binary format
dont-trust-totals
do not trust lower-order counts for adaptation, recompute from the higher-order counts [default is to trust lower-order counts]
read-dev
text file of dev data used to optimize eta. If provided, the optimized eta will be used for all orders and thus override all -eta or -eta(n) options
max-eta
maximum possible value of eta. It's only used when -read-dev is provided to set the maximum value of optimized eta
adaptation order must be >= 1 and <= 
, use -adapt-order with a relevant value
no adaptation text or counts are provided, use -read-text and/or -read-counts option
-textFileHasWeights option will be ignored as no input text option is provided (use -read-text)
no input lm file is provided, use -read-lm option
command-line (read-lm) and custom-lm config options cannot be mixed.
command-line (write-lm) and custom-lm config options cannot be mixed.
Vocab file (option -vocab) not provided, reading vocabulary from ARPA
format error in lm file
Ignoring Vocab file (option -vocab) when taking Vocab from LmData
Warning: Provided a ctx.vocabIter (ignored) when taking Vocab from LmData
text file 
 looks empty or has only invalid lines
only plain text or phrase counts supported for dev data
Eta optimization failed
optimized eta = 
, used for orders 1 to 
-gram adaptation weight must be >= 0.0 and < 1.0, use -eta option with a relevant value
or -read-dev option to provide dev data for optimizing eta
LM adaptation failed
adapted LM written to 
Unable to instantiate a translator factory
Unable to instantiate translator factory
No translation configurations given, cannot instantiate translator
Unable to instantiate translator
Step name must be 
mutually-exclusive-group
from
validate-brackets
validate-brackets will be overwritten by validate-brackets = 
(?i)
Rule file supplied is invalid: 
file
Read sub-rule config file = 
Failed to load sub-rule file = 
split-case-sensitive
max-alt
max-alt will be overwritten by max-alt = 
split-case-sensitive will be overwritten by split-case-sensitive = 
\g<0>
Gender
inflections
multiword-inflections
Error parsing multiword inflections: expected list of words.
Error parsing multiword inflection, too many inflection alternatives.
Invalid inflection: 
Unmatched words in one of the alternatives
Expected female sentence, got: '
Expected male sentence, got: '
No hypotheses, sending empty list.
Already found higher scoring gender alternatives, ignoring new alternatives.
Last sentence in NBest list is an unpaired gender alternative, ignoring.
Expected gendered sentence, got: '
Found valid gender alternatives.
Non matching gender alternatives, ignoring the second alternative.
Non-gendered sentence, keeping.
WARNING: asking to round a value to 0 significant figures makes no sense 
 answer is 0.
total
Task 
 not found in config
Multiple decoder chains for task 
Decoder chain 
 not found in config for task 
.ptoks
read in partial tokens  
finished 
 beam search steps at frame 
finished the last 
 beam search steps
SeevaModel/encoder/__QNNO__encoder_output
SeevaModel/encoder/__QNNI__encoder_state_
SeevaModel/encoder/__QNNO__encoder_state_
SeevaModel/__QNNI__target_input
SeevaModel/__QNNI__encoder_output
SeevaModel/decoder/__QNNO__decoder_full_score
SeevaModel/decoder/__QNNI__decoder_state_
SeevaModel/decoder/__QNNO__decoder_state_
Empty silence phones
NaturalLess: Weight type is not idempotent: 
DeterminizeFst: Weight needs to have the 
path property to disambiguate output: 
Unrecognized commandId=
\all-caps
\cap
\spelling-cap
\no-caps
\no-space
\new-line
\new-paragraph
.\period-paragraph
\tab-key
\no-break-space
\spelling-no-break-space
\space-bar
\backslash
\spelling-backslash
ucasemap_utf8ToUpper failed
ucasemap_utf8ToTitle failed
Reading SimplerSimpleRecurrentUnit component
<InputTransform>
reading input transform network failed
<c_0>
</SimplerSimpleRecurrentUnit>
Another recurrent neural networks are not supported inside SSRU component.
ResetHistoryState for SimplerSimpleRecurrentUnit makes only sense if all utterances get reset at the same time
./background_power_%ld.log
./runtime_power_%ld.log
Sampling background power consumption for %d seconds 
%@ -fi 1 -G PMP > %@
(turning off PMP because it's unavailable, power measurements might be less accurate) 
%@ -fi 1 > %@
%@ -ft -G PMP > %@
%@ -ft > %@
killall %@
jetsam max
jetsam average
max rss
units
memory
CPU time
ANE time
perf
total energy
ANE energy
GPU energy
DRAM energy
ECPU energy
PCPU energy
other energy
energy
mean background power
std background power
total power
ANE power
GPU power
DRAM power
ECPU power
PCPU power
other power
power
================ Profiler Summary ===============
|             |  Jetsam  |    Peak   |  Average |
|             |          |  %7.2f  | %7.2f  |
| Memory (MB) -----------------------------------
|             |  MAX_RSS |    Peak   |     -    |
|             |          |  %7.2f  |          |
=================================================
| Time (s)    |    CPU   |    GPU    |    ANE*  |
|             | %7.2f  |      -    | %7.2f  |
=================================================
| * ANE time unavailable for CoreML networks.   |
=================================================
| Background  |   Idle   |  Average  |   std    |
| Power* (mW) |          |   %5.1f   |  %5.1f   |
| %s     -----------------------------------
|             |  Total  |  ANE  |  GPU  |  DRAM |
|             |  %6.2f | %5.1f | %5.1f | %5.1f |
| Energy (J)  -----------------------------------
| %s     |         |  ECPU |  PCPU | OTHER |
|             |         | %5.1f | %5.1f | %5.1f |
|             -----------------------------------
|             |  Total  |  ANE  |  GPU  |  DRAM |
|             |   %5d |  %4d |  %4d |  %4d |
| Power (mW)  -----------------------------------
| %s     |         |  ECPU |  PCPU | OTHER |
| ^           |         |  %4d |  %4d |  %4d |
=================================================
| * If Idle power consumption is significant,   |
|   try enabling one of the power settings      |
|   recommended  above and kill any daemon(s)   |
|   that are not needed by transcribe.          |
| ^ Power measurements can be inaccurate on     |
|   short audios and/or new hardwares.          |
=================================================
via PMP
non-PMP
rm %@ %@
---> 
---> Energy Counters
=> Energy Model
ECPU
ECORE
PCPU
PCORE
DRAM
Warning: failed to parse log file %s
/dev/null
/bin/bash
/usr/bin/sudo
Warning: Could not get ledger info for pid.
Warning: Could not get ledger info for pid
phys_footprint
Warning: Could not get ledger entry info for pid
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/agent.cc
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/agent.cc:13: MARISA_NULL_ERROR: str == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/agent.cc:36: MARISA_STATE_ERROR: state_.get() != NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/agent.cc:38: MARISA_MEMORY_ERROR: state_.get() == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/include/marisa/scoped-ptr.h
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/include/marisa/scoped-ptr.h:19: MARISA_RESET_ERROR: (ptr != NULL) && (ptr == ptr_)
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/io/mapper.cc
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/io/mapper.cc:63: MARISA_NULL_ERROR: (ptr == NULL) && (size != 0)
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/io/mapper.cc:71: MARISA_STATE_ERROR: !is_open()
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/io/mapper.cc:72: MARISA_IO_ERROR: size > avail_
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/io/mapper.cc:99: MARISA_STATE_ERROR: !is_open()
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/io/mapper.cc:100: MARISA_IO_ERROR: size > avail_
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/trie/louds-trie.cc
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/trie/louds-trie.cc:73: MARISA_BOUND_ERROR: agent.query().id() >= size()
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/trie/louds-trie.cc:451: MARISA_MEMORY_ERROR: next_trie_.get() == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/trie/louds-trie.cc:468: MARISA_MEMORY_ERROR: next_trie_.get() == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/trie/louds-trie.cc:542: MARISA_MEMORY_ERROR: next_trie_.get() == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/trie/config.h
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/trie/config.h:59: MARISA_CODE_ERROR: (config_flags & ~MARISA_CONFIG_MASK) != 0
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/trie/config.h:101: MARISA_CODE_ERROR: undefined cache level
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/trie/config.h:121: MARISA_CODE_ERROR: undefined tail mode
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/trie/config.h:141: MARISA_CODE_ERROR: undefined node order
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/trie/header.h
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/trie/header.h:21: MARISA_FORMAT_ERROR: !test_header(ptr)
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/trie/../io/mapper.h
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/trie/../io/mapper.h:28: MARISA_NULL_ERROR: (objs == NULL) && (num_objs != 0)
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/trie/../io/mapper.h:30: MARISA_SIZE_ERROR: num_objs > (MARISA_SIZE_MAX / sizeof(T))
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/trie/../vector/bit-vector.h
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/trie/../vector/bit-vector.h:52: MARISA_SIZE_ERROR: size_ == MARISA_UINT32_MAX
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/trie/../vector/vector.h
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/trie/../vector/vector.h:100: MARISA_STATE_ERROR: fixed_
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/trie/../vector/bit-vector.h:135: MARISA_FORMAT_ERROR: temp_num_1s > size_
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/trie/../vector/vector.h:202: MARISA_FORMAT_ERROR: (total_size % sizeof(T)) != 0
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/trie/../vector/vector.h:107: MARISA_STATE_ERROR: fixed_
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/trie/../vector/flat-vector.h
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/trie/../vector/flat-vector.h:134: MARISA_FORMAT_ERROR: temp_value_size > 32
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/trie/louds-trie.cc:428: MARISA_MEMORY_ERROR: std::bad_alloc
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/trie/tail.cc
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/trie/tail.cc:13: MARISA_NULL_ERROR: offsets == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/trie/tail.cc:36: MARISA_CODE_ERROR: undefined tail mode
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/trie/tail.cc:170: MARISA_RANGE_ERROR: current.length() == 0
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/trie/tail.cc:192: MARISA_SIZE_ERROR: buf_.size() > MARISA_UINT32_MAX
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/vector/vector.h
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/vector/vector.h:100: MARISA_STATE_ERROR: fixed_
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/keyset.cc
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/keyset.cc:50: MARISA_NULL_ERROR: str == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/keyset.cc:61: MARISA_NULL_ERROR: (ptr == NULL) && (length != 0)
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/keyset.cc:62: MARISA_SIZE_ERROR: length > MARISA_UINT32_MAX
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/keyset.cc:129: MARISA_MEMORY_ERROR: new_blocks.get() == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/keyset.cc:138: MARISA_MEMORY_ERROR: new_block.get() == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/keyset.cc:151: MARISA_MEMORY_ERROR: new_blocks.get() == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/keyset.cc:159: MARISA_MEMORY_ERROR: new_block.get() == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/keyset.cc:169: MARISA_MEMORY_ERROR: new_blocks.get() == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/keyset.cc:177: MARISA_MEMORY_ERROR: new_block.get() == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/trie.cc
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/trie.cc:14: MARISA_MEMORY_ERROR: temp.get() == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/trie.cc:33: MARISA_NULL_ERROR: (ptr == NULL) && (size != 0)
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/trie.cc:36: MARISA_MEMORY_ERROR: temp.get() == NULL
/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/libquasar/libsentencepiece/src/bpe_model.cc
(index) >= (0)
(index) < (static_cast<int>(symbols.size()))
/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/libquasar/libsentencepiece/src/builtin_pb/sentencepiece.pb.cc
sentencepiece.SentencePieceText.SentencePiece
sentencepiece.SentencePieceText
sentencepiece.NBestSentencePieceText
<pad>
/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/libquasar/libsentencepiece/src/builtin_pb/sentencepiece_model.pb.cc
sentencepiece.TrainerSpec
sentencepiece.NormalizerSpec
sentencepiece.SelfTestData.Sample
sentencepiece.SelfTestData
sentencepiece.ModelProto.SentencePiece
sentencepiece.ModelProto
Program terminated with an unrecoverable error.
Cancelled
Invalid argument
Deadline exceeded
Not found
Already exists
Permission denied
Unauthenticated
Failed precondition
Aborted
Out of range
Internal
Unavailable
Data loss
/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/libquasar/libsentencepiece/src/filesystem.cc
ReadAll is not supported for stdin.
/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/libquasar/libsentencepiece/src/model_factory.cc
Unknown model_type: 
piece must not be empty.
 is already defined.
unk is already defined.
byte piece 
 is found although `byte_fallback` is false.
 is invalid.
unk is not defined.
there are not 256 byte pieces although `byte_fallback` is true.
<0x%02X>
src/model_interface.h
Not implemented.
/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/libquasar/libsentencepiece/src/normalizer.cc
precompiled_charsmap is empty. use identity normalization.
(length) >= (0)
(norm_to_orig->size()) == (normalized->size() + 1)
Blob for normalization rule is broken.
Trie data size exceeds the input blob size.
(0) == (trie_->build(key.size(), const_cast<char **>(&key[0]), nullptr, nullptr))
src/util.h
'result' Must be non NULL
../libsentencepiece/third_party/darts_clone/darts.h:703: exception: failed to resize pool: std::bad_alloc
../libsentencepiece/third_party/darts_clone/darts.h:1141: exception: failed to insert key: negative value
../libsentencepiece/third_party/darts_clone/darts.h:1143: exception: failed to insert key: zero-length key
../libsentencepiece/third_party/darts_clone/darts.h:1157: exception: failed to insert key: invalid null character
../libsentencepiece/third_party/darts_clone/darts.h:1162: exception: failed to insert key: wrong key order
../libsentencepiece/third_party/darts_clone/darts.h:842: exception: failed to build rank index: std::bad_alloc
../libsentencepiece/third_party/darts_clone/darts.h:1380: exception: failed to modify unit: too large offset
../libsentencepiece/third_party/darts_clone/darts.h:1726: exception: failed to build double-array: invalid null character
../libsentencepiece/third_party/darts_clone/darts.h:1728: exception: failed to build double-array: negative value
../libsentencepiece/third_party/darts_clone/darts.h:1743: exception: failed to build double-array: wrong key order
/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/libquasar/libsentencepiece/src/sentencepiece_processor.cc
_status.ok()
model_proto->ParseFromArray(serialized.data(), serialized.size())
LOG(
 samples did not pass the test.
Self-test failures. See LOG(INFO).
model_
Model is not initialized.
normalizer_
Normalizer is not initialized.
type == TrainerSpec::UNIGRAM || type == TrainerSpec::BPE
Vocabulary constraint is only enabled in subword units.
(v.size()) >= (1)
!v[0].empty()
absl::SimpleAtoi(v[1], &freq)
Could not parse the frequency
pieces
output container is null
detokenized
!w.empty()
Empty piece is not allowed.
(begin) < (norm_to_orig.size())
(end) < (norm_to_orig.size())
(orig_begin) <= (input.size())
(orig_end) <= (input.size())
(orig_begin) <= (orig_end)
(consumed) == (normalized.size())
all normalized characters are not consumed.
output proto is null
nbest_spt
model_->IsNBestEncodeAvailable()
NBestEncode is not available for the current model.
!nbests.empty()
NBestEncode returns empty result.
(nbest_size) <= (512)
nbest_size must be nbest_size <= 512
model_->IsSampleEncodeAvailable()
SampleEncode is not available for the current model.
model_->IsSampleEncodeAndScoreAvailable()
SampleEncodeAndScore is not available for the current model.
!results.empty()
SampleEncodeAndScore returns empty result.
model_->IsCalculateEntropyAvailable()
CalculateEntropy is not available for the current model.
Invalid id: 
Returns default value 
unknown extra_option type.
it != extra_option_map.end()
option "
" is not available.
!IsUnknown(PieceToId(absl::string_view(model_->bos_piece().data())))
id for `
` is not defined.
!IsUnknown(PieceToId(absl::string_view(model_->eos_piece().data())))
model file path should not be empty.
input->ReadAll(&serialized)
(0) <= (byte)
(consumed) == (1)
(token_index_begin + offset) == (token_index_end)
/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/libquasar/libsentencepiece/src/unigram_model.cc
Failed to find the best path in Viterbi.
nbest_size >= 1. Returns empty result.
Too big agenda. shrinking
(num_nodes) < (trie_results.size())
no pieces are loaded.
cannot build double-array.
no entry is found in the trie.
include_best not supported for wor false
removing best path from samples
Two sentence piece sequences are not equivalent! Left: 
, Score: 
. Right: 
 Error #
third_party/protobuf-lite/google/protobuf/parse_context.h
Can't happen
/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/libquasar/libsentencepiece/third_party/protobuf-lite/arena.cc
CHECK failed: (min_bytes) <= (std::numeric_limits<size_t>::max() - kBlockHeaderSize): 
/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/libquasar/libsentencepiece/third_party/protobuf-lite/common.cc
This program requires version 
 of the Protocol Buffer runtime library, but the installed version is 
.  Please update your library.  If you compiled the program yourself, make sure that your headers are from the same version of Protocol Buffers as your link-time library.  (Version verification failed in "
This program was compiled against version 
 of the Protocol Buffer runtime library, which is not compatible with the installed version (
).  Contact the program author for an update.  If you compiled the program yourself, make sure that your headers are from the same version of Protocol Buffers as your link-time library.  (Version verification failed in "
%d.%d.%d
[libprotobuf %s %s:%d] %s
/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/libquasar/libsentencepiece/third_party/protobuf-lite/extension_set.cc
Non-primitive types can't be packed.
can't reach here.
third_party/protobuf-lite/google/protobuf/extension_set_inl.h
/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/libquasar/libsentencepiece/third_party/protobuf-lite/generated_message_util.cc
CHECK failed: (scc->visit_status.load(std::memory_order_relaxed)) == (SCCInfoBase::kRunning): 
(cannot determine missing fields for lite message)
/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/libquasar/libsentencepiece/third_party/protobuf-lite/message_lite.cc
parse
 exceeded maximum protobuf size of 2GB: 
Can't 
 message of type "
" because it is missing required fields: 
true
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
?N6quasar6Bitmap21CoordinatesOutOfRangeE
N6quasar6BitmapE
N6quasar12BitmapLoaderE
N5kaldi6quasar14CEInferenceNetE
_N6quasar18PersonalizedLmDataE
NSt3__112codecvt_utf8IDiLm1114111ELNS_12codecvt_modeE0EEE
P?N3fst9VectorFstINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEENS_11VectorStateIS6_NSt3__19allocatorIS6_EEEEEE
N3fst8SccQueueIiNS_9QueueBaseIiEEEE
N5kaldi6quasar18OnlineLASDecodableE
N5kaldi6quasar29OnlineLASSpeculativeDecodableE
MbP?
N5kaldi18OnlinePitchFeatureE
N3fst15MemoryArenaBaseE
N3fst14MemoryPoolBaseE
AN6quasar33OnlineLatticeWordAlignmentDecoderE
~*?N3fst9ImplToFstINS_14CompactFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_19UnweightedCompactorIS5_EEjNS_19DefaultCompactStoreINSt3__14pairINSA_IiiEEiEEjEEEENS_11ExpandedFstIS5_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar8DataFeedENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_pointerIPN6quasar13TextTokenizerENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN6quasar13TextTokenizerEEE
NSt3__120__shared_ptr_emplaceIN6quasar9PMBuilderENS_9allocatorIS2_EEEE
N5kaldi5nnet131BidirectionalRecurrentComponentE
N6quasar2lm11fst_builder10FstBuilderIN3fst6ArcTplINS3_17TropicalWeightTplIfEEEEEE
N6quasar2lm11fst_builder17MutableFstBuilderIN3fst6ArcTplINS3_17TropicalWeightTplIfEEEEEE
N6quasar2lm11fst_builder18SqueezedFstBuilderIN3fst6ArcTplINS3_17TropicalWeightTplIfEEEELb1ELb0EEE
N6quasar2lm11fst_builder18SqueezedFstBuilderIN3fst6ArcTplINS3_17TropicalWeightTplIfEEEELb0ELb0EEE
?333333
333333
N6quasar20RecogAudioBufferBaseE
N6quasar9AppLmDataE
NSt3__120__shared_ptr_emplaceIN6quasar14GlobalLRUCacheINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_6vectorIS8_NS6_IS8_EEEEEENS6_ISC_EEEE
N6quasar14GlobalLRUCacheINSt3__112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEENS1_6vectorIS7_NS5_IS7_EEEEEE
@N6quasar17WatermarkDetectorE
15NaturalDiscount
9KneserNey
12ModKneserNey
10GoodTuring
NSt3__111__end_stateIcEE
NSt3__120__shared_ptr_pointerIPNS_13__empty_stateIcEENS_10shared_ptrIS2_E27__shared_ptr_default_deleteIS2_S2_EENS_9allocatorIS2_EEEE
NSt3__116__owns_one_stateIcEE
NSt3__115__has_one_stateIcEE
NSt3__118__match_char_icaseIcNS_12regex_traitsIcEEEE
NSt3__112__match_charIcEE
NSt3__116__back_ref_icaseIcNS_12regex_traitsIcEEEE
NSt3__110__back_refIcEE
NSt3__120__bracket_expressionIcNS_12regex_traitsIcEEEE
NSt3__117__owns_two_statesIcEE
NSt3__111__alternateIcEE
NSt3__111__match_anyIcEE
BN5kaldi17ContextDependencyE
NSt3__120__shared_ptr_emplaceIKN5kaldi5TimerENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar21NgramSrilmCountConfigENS_9allocatorIS2_EEEE
?N5kaldi5nnet19LayerNormE
N6quasar14HwcnConfidenceE
NSt3__120__shared_ptr_emplaceIN6marisa4TrieENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi6MatrixIfEENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar22WlatArcFeWordEmbeddingENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar14WlatArcFeIsLmeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar14WlatArcFeLmeIdENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar14WlatArcFeIsSilENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar18WlatArcFeNumPhonesENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar29WlatArcFeAcousticCostUnpushedENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar19WlatArcFeInBestPathENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar21WlatArcFeAcousticCostENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar18WlatArcFeGraphCostENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar18WlatArcFeNumFramesENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar21WlatArcFeLogPosteriorENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar21WlatArcFeLinPosteriorENS_9allocatorIS2_EEEE
fff?
NSt3__120__shared_ptr_emplaceIN5kaldi5nnet14NnetENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar16MiscSharedConfigENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar19EndPointModelConfigENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar11EagerConfigENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar9GeographyENS_9allocatorIS2_EEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_17TropicalWeightTplIfEEEENSt3__19allocatorIS6_EEEEEENS_10MutableFstIS6_EEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_11ArcIteratorINS_3FstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEEE4LinkEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_21SequenceComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_23PushLabelsComposeFilterINS_24PushWeightsComposeFilterINS_22LookAheadComposeFilterINS_24AltSequenceComposeFilterINS_16LookAheadMatcherINS_3FstIS5_EEEESE_EESE_SE_LNS_9MatchTypeE2EEESE_SE_LSG_2EEESE_SE_LSG_2EEENS_24GenericComposeStateTableIS5_NS_15PairFilterStateINSL_INS_18IntegerFilterStateIaEENS_17WeightFilterStateIS4_EEEENSM_IiEEEENS_24DefaultComposeStateTupleIiSS_EENS_21CompactHashStateTableISU_NS_11ComposeHashISU_EEEEEEEE
N3fst13StateIteratorINS_10ComposeFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_17DefaultCacheStoreIS5_EEEEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_11VectorStateIS7_NSt3__19allocatorIS7_EEEEEEEE
N3fst14DeterminizeFstINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEE
N3fst18DeterminizeFsaImplINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_20DefaultCommonDivisorIS4_EENS_24DefaultDeterminizeFilterIS6_EENS_28DefaultDeterminizeStateTableIS6_NS_18IntegerFilterStateIaEEEEEE
N3fst22DeterminizeFstImplBaseINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEE
N3fst9CacheImplINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEE
N3fst13CacheBaseImplINS_10CacheStateINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENSt3__19allocatorIS7_EEEENS_17DefaultCacheStoreIS7_EEEE
N3fst13StateIteratorINS_14DeterminizeFstINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEEEE
N3fst18CacheStateIteratorINS_14DeterminizeFstINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEEEE
N3fst17StateIteratorBaseINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEE
N5kaldi5nnet124QuantizedAffineTransformIaEE
N5kaldi5nnet124QuantizedAffineTransformIsEE
N5kaldi5nnet115LinearTransformINS_15QuantizedMatrixIaEEEE
N5kaldi5nnet115LinearTransformINS_15QuantizedMatrixIsEEEE
N5kaldi5nnet115LinearTransformINS_12CuMatrixBaseIfEEEE
NSt3__120__shared_ptr_pointerIPN6quasar14LmeDataFactoryENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN6quasar14LmeDataFactoryEEE
NSt3__120__shared_ptr_pointerIPN6quasar14GlobalLRUCacheINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_6vectorIS8_NS6_IS8_EEEEEENS_14default_deleteISC_EENS6_ISC_EEEE
NSt3__114default_deleteIN6quasar14GlobalLRUCacheINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_6vectorIS8_NS6_IS8_EEEEEEEE
NSt3__120__shared_ptr_emplaceIN6quasar7LmeDataENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN3fst11SymbolTableENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceINS_14basic_ifstreamIcNS_11char_traitsIcEEEENS_9allocatorIS4_EEEE
NSt3__120__shared_ptr_emplaceINS_18basic_stringstreamIcNS_11char_traitsIcEENS_9allocatorIcEEEENS4_IS6_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar12LmeContainerENS_9allocatorIS2_EEEE
N6quasar37OnlineLASLmRescoringBeamSearchDecoderE
N3fst10MemoryPoolINS_8DfsStateINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEE
NSt3__120__shared_ptr_emplaceIN3fst18StdToLatticeMapperIfEENS_9allocatorIS3_EEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEENS2_INS_16LatticeWeightTplIfEEEENS_18StdToLatticeMapperIfEEEENS_3FstIS8_EEEE
N3fst13StateIteratorINS_9ArcMapFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS2_INS_16LatticeWeightTplIfEEEENS_18StdToLatticeMapperIfEEEEEE
NSt3__120__shared_ptr_pointerIPN3fst11SymbolTableENS_10shared_ptrIS2_E27__shared_ptr_default_deleteIS2_S2_EENS_9allocatorIS2_EEEE
N3fst9ArcMapFstINS_6ArcTplINS_17TropicalWeightTplIfEEEES4_NS_14ArcScaleMapperEEE
N3fst13ArcMapFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEES4_NS_14ArcScaleMapperEEE
N3fst9CacheImplINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N3fst13StateIteratorINS_9ArcMapFstINS_6ArcTplINS_17TropicalWeightTplIfEEEES5_NS_14ArcScaleMapperEEEEE
N3fst17StateIteratorBaseINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N3fst15ArcIteratorBaseINS_6ArcTplINS_16LatticeWeightTplIfEEEEEE
N3fst13VectorFstImplINS_11VectorStateINS_6ArcTplINS_16LatticeWeightTplIfEEEENSt3__19allocatorIS5_EEEEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_6ArcTplINS_16LatticeWeightTplIfEEEENSt3__19allocatorIS5_EEEEEE
N3fst9VectorFstINS_6ArcTplINS_16LatticeWeightTplIfEEEENS_11VectorStateIS4_NSt3__19allocatorIS4_EEEEEE
N3fst10MemoryPoolINS_11ArcIteratorINS_3FstINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_11ArcIteratorINS_3FstINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEEE4LinkEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENS_21SequenceComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENS_21SequenceComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENS_22LookAheadComposeFilterINS_24AltSequenceComposeFilterINS_16LookAheadMatcherINS_3FstIS5_EEEESC_EESC_SC_LNS_9MatchTypeE2EEENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSI_EENS_21CompactHashStateTableISK_NS_11ComposeHashISK_EEEEEEEE
N3fst13StateIteratorINS_10ComposeFstINS_6ArcTplINS_16LatticeWeightTplIfEEEENS_17DefaultCacheStoreIS5_EEEEEE
N3fst18CacheStateIteratorINS_10ComposeFstINS_6ArcTplINS_16LatticeWeightTplIfEEEENS_17DefaultCacheStoreIS5_EEEEEE
N3fst14DeterminizeFstINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEE
N3fst22DeterminizeFstImplBaseINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEE
N3fst13StateIteratorINS_14DeterminizeFstINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEEEE
N3fst18CacheStateIteratorINS_14DeterminizeFstINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEEEE
N3fst17StateIteratorBaseINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEE
NSt3__120__shared_ptr_emplaceINS_6vectorINS1_IN6quasar5TokenENS_9allocatorIS3_EEEENS4_IS6_EEEENS4_IS8_EEEE
N6quasar19LatticeRnnMitigatorE
NSt3__120__shared_ptr_emplaceIN6quasar20WlatArcFeBagOfPhonesENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar16WlatArcFeKeywordENS_9allocatorIS2_EEEE
N5kaldi6quasar10LexiconItfE
N5kaldi6quasar7LexiconE
N5kaldi6quasar12ConstLexiconE
N6quasar28AlternativesProcessorOptionsE
N6quasar25ConfiguredProcessingBlockINS_28AlternativesProcessorOptionsEEE
N6quasar26AlternativesProcessorBlockE
v@34EARContinuousListeningResultHelper
NSt3__120__shared_ptr_emplaceI25EARModelInitializeContextNS_9allocatorIS1_EEEE
25EARModelInitializeContext
NSt3__120__shared_ptr_emplaceINS_19basic_istringstreamIcNS_11char_traitsIcEENS_9allocatorIcEEEENS4_IS6_EEEE
NSt3__120__shared_ptr_emplaceIKN6quasar32VoiceCommandActiveSetCompilationENS_9allocatorIS3_EEEE
N3fst10CompactFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_19UnweightedCompactorIS4_EEjNS_19DefaultCompactStoreINSt3__14pairINS9_IiiEEiEEjEEEE
N3fst17ImplToExpandedFstINS_14CompactFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_19UnweightedCompactorIS5_EEjNS_19DefaultCompactStoreINSt3__14pairINSA_IiiEEiEEjEEEENS_11ExpandedFstIS5_EEEE
N3fst14CompactFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_19UnweightedCompactorIS4_EEjNS_19DefaultCompactStoreINSt3__14pairINS9_IiiEEiEEjEEEE
N3fst13SortedMatcherINS_10CompactFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_19UnweightedCompactorIS5_EEjNS_19DefaultCompactStoreINSt3__14pairINSA_IiiEEiEEjEEEEEE
N3fst10MemoryPoolINS_11ArcIteratorINS_10CompactFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_19UnweightedCompactorIS6_EEjNS_19DefaultCompactStoreINSt3__14pairINSB_IiiEEiEEjEEEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_11ArcIteratorINS_10CompactFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_19UnweightedCompactorIS7_EEjNS_19DefaultCompactStoreINSt3__14pairINSC_IiiEEiEEjEEEEEEE4LinkEEE
NSt3__120__shared_ptr_emplaceI19ResultStreamWrapperNS_9allocatorIS1_EEEE
19ResultStreamWrapper
NSt3__120__shared_ptr_emplaceIbNS_9allocatorIbEEEE
NSt3__120__shared_ptr_emplaceI34EARContinuousListeningResultHelperNS_9allocatorIS1_EEEE
NSt3__113__assoc_stateIN6quasar8LocationEEE
NSt3__120__shared_ptr_emplaceIN6quasar14RunAsyncParamsENS_9allocatorIS2_EEEE
NSt3__110__function6__funcIZ23getModelFilesWithSuffixRKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEES9_E3$_6NS5_ISA_EEFbS7_EEE
NSt3__110__function6__baseIFbNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEEEE
Z23getModelFilesWithSuffixRKNSt3__112basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEES7_E3$_6
N6quasar16RomanizerOptionsE
N6quasar25ConfiguredProcessingBlockINS_16RomanizerOptionsEEE
N6quasar14RomanizerBlockE
NSt3__112codecvt_utf8IwLm1114111ELNS_12codecvt_modeE0EEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS7_9allocatorIfEEEEEEEENS9_ISD_EEEEEENS_10MutableFstISD_EEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS7_9allocatorIfEEEEEEEENS9_ISD_EEEEEENS_10MutableFstISD_EEEE
N3fst10MutableFstINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS5_9allocatorIfEEEEEEEEEE
N3fst11ExpandedFstINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS5_9allocatorIfEEEEEEEEEE
N3fst3FstINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS5_9allocatorIfEEEEEEEEEE
N3fst13VectorFstImplINS_11VectorStateINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS6_9allocatorIfEEEEEEEENS8_ISC_EEEEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS6_9allocatorIfEEEEEEEENS8_ISC_EEEEEE
N3fst10MemoryPoolINS_8DfsStateINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS6_9allocatorIfEEEEEEEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS7_9allocatorIfEEEEEEEEEEE4LinkEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS6_9allocatorIfEEEEEEEENS_11VectorStateISC_NS8_ISC_EEEEEEEE
N3fst22MutableArcIteratorBaseINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS5_9allocatorIfEEEEEEEEEE
N3fst15ArcIteratorBaseINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS5_9allocatorIfEEEEEEEEEE
N6quasar11OptionValueINSt3__112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEEEE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar18NNMTTransliteratorENS_9allocatorIS3_EEEE
N3fst10MappedFileE
N6quasar23QualityEstimatorOptionsE
N6quasar25ConfiguredProcessingBlockINS_23QualityEstimatorOptionsEEE
N6quasar21QualityEstimatorBlockE
L?N3fst9VectorFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_11VectorStateIS4_NSt3__19allocatorIS4_EEEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_17TropicalWeightTplIfEEEENSt3__19allocatorIS6_EEEEEENS_10MutableFstIS6_EEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_17TropicalWeightTplIfEEEENSt3__19allocatorIS6_EEEEEENS_10MutableFstIS6_EEEE
N3fst9VectorFstINS_6ArcTplINS_12LogWeightTplIfEEEENS_11VectorStateIS4_NSt3__19allocatorIS4_EEEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_12LogWeightTplIfEEEENSt3__19allocatorIS6_EEEEEENS_10MutableFstIS6_EEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_12LogWeightTplIfEEEENSt3__19allocatorIS6_EEEEEENS_10MutableFstIS6_EEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_11VectorStateIS5_NSt3__19allocatorIS5_EEEEEEEE
N3fst22MutableArcIteratorBaseINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_6ArcTplINS_12LogWeightTplIfEEEENS_11VectorStateIS5_NSt3__19allocatorIS5_EEEEEEEE
N6quasar21InverseTextNormalizerE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar5VocabENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_pointerIPN6quasar34SpaceApplyDefaultFstTokenTransformENS_10shared_ptrINS1_17FstTokenTransformEE27__shared_ptr_default_deleteIS5_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrIN6quasar17FstTokenTransformEE27__shared_ptr_default_deleteIS2_NS1_34SpaceApplyDefaultFstTokenTransformEEE
NSt3__120__shared_ptr_pointerIPN6quasar39RewriteApplyCapitalizeFstTokenTransformENS_10shared_ptrINS1_17FstTokenTransformEE27__shared_ptr_default_deleteIS5_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrIN6quasar17FstTokenTransformEE27__shared_ptr_default_deleteIS2_NS1_39RewriteApplyCapitalizeFstTokenTransformEEE
NSt3__120__shared_ptr_pointerIPN6quasar36RewriteApplyDefaultFstTokenTransformENS_10shared_ptrINS1_17FstTokenTransformEE27__shared_ptr_default_deleteIS5_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrIN6quasar17FstTokenTransformEE27__shared_ptr_default_deleteIS2_NS1_36RewriteApplyDefaultFstTokenTransformEEE
NSt3__120__shared_ptr_pointerIPN6quasar24ComposeFstTokenTransformENS_10shared_ptrINS1_17FstTokenTransformEE27__shared_ptr_default_deleteIS5_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrIN6quasar17FstTokenTransformEE27__shared_ptr_default_deleteIS2_NS1_24ComposeFstTokenTransformEEE
NSt3__120__shared_ptr_emplaceINS_3mapINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_6vectorIiNS5_IiEEEENS_4lessIS7_EENS5_INS_4pairIKS7_SA_EEEEEENS5_ISH_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar18QuasarTextProcImplENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar10PrefixTreeINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEES9_EENS7_ISA_EEEE
N3fst13SortedMatcherINS_3FstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_21SequenceComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_17NullComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_17NullComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_24AltSequenceComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_18MatchComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
NSt3__120__shared_ptr_emplaceINS_6vectorIN6quasar25PreTokenToPostTokenItnMapENS_9allocatorIS3_EEEENS4_IS6_EEEE
N5kaldi8CuMatrixIdEE
N5kaldi12CuMatrixBaseIdEE
N5kaldi11CuSubMatrixIdEE
N6quasar16WlatArcFeKeywordE
N6quasar23WlatArcFeatureExtractorE
N6quasar14WlatArcFeIsLmeE
N6quasar14WlatArcFeLmeIdE
N6quasar14WlatArcFeIsSilE
N6quasar18WlatArcFeNumPhonesE
N6quasar29WlatArcFeAcousticCostUnpushedE
N6quasar19WlatArcFeInBestPathE
N6quasar21WlatArcFeAcousticCostE
N6quasar18WlatArcFeGraphCostE
N6quasar18WlatArcFeNumFramesE
N6quasar21WlatArcFeLogPosteriorE
N6quasar21WlatArcFeLinPosteriorE
N6quasar20WlatArcFeBagOfPhonesE
N6quasar22WlatArcFeWordEmbeddingE
N3fst11SymbolTableE
N3fst7ArcInfoE
N3fst14BackoffArcInfoE
N3fst13InterpArcInfoE
N3fst11MatcherBaseINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N6quasar11FstLmScorerE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEE4LinkEEE
NSt3__120__shared_ptr_emplaceIN6quasar15SymbolTableListENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar22SpeechRecognizerConfigENS_9allocatorIS2_EEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEE4LinkEEE
N3fst14ReplaceFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_24DefaultReplaceStateTableIS4_lEENS_17DefaultCacheStoreIS4_EEEE
N3fst13CacheBaseImplINS_10CacheStateINS_6ArcTplINS_17TropicalWeightTplIfEEEENSt3__19allocatorIS5_EEEENS_17DefaultCacheStoreIS5_EEEE
N3fst13StateIteratorINS_10ReplaceFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_24DefaultReplaceStateTableIS5_lEENS_17DefaultCacheStoreIS5_EEEEEE
N3fst17ReplaceFstMatcherINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_24DefaultReplaceStateTableIS4_lEENS_17DefaultCacheStoreIS4_EEEE
N3fst10MemoryPoolINS_11ArcIteratorINS_10ReplaceFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_24DefaultReplaceStateTableIS6_lEENS_17DefaultCacheStoreIS6_EEEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_11ArcIteratorINS_10ReplaceFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_24DefaultReplaceStateTableIS7_lEENS_17DefaultCacheStoreIS7_EEEEEEE4LinkEEE
N5kaldi6quasar31RecurrentNeuralDeterministicFstIN3fst6ArcTplINS2_17TropicalWeightTplIfEEEEEE
NSt3__120__shared_ptr_emplaceIN3fst7ArcInfoENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceINS_6vectorINS_10shared_ptrIN3fst7ArcInfoEEENS_9allocatorIS5_EEEENS6_IS8_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar23SpeechRequestResultDataENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar18DecoderChainOutputENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi5TimerENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar17SpeechRequestDataENS_9allocatorIS2_EEEE
NSt3__110__function6__funcIZN6quasar11FstLmScorer14computeLmScoreERKNS_6vectorINS_10shared_ptrINS2_12LmeContainerEEENS_9allocatorIS7_EEEERKNS2_8LocationERKNS_12basic_stringIcNS_11char_traitsIcEENS8_IcEEEERKNS4_ISK_NS8_ISK_EEEEbRNS2_6LmInfoERKNS4_INS5_IN5kaldi6quasar8LmHandleEEENS8_ISW_EEEEbSM_RKNS4_IiNS8_IiEEEEbbbiSQ_E3$_2NS8_IS15_EEFNS5_IN3fst3FstINS17_6ArcTplINS17_17TropicalWeightTplIfEEEEEEEERKS1E_EEE
ZN6quasar11FstLmScorer14computeLmScoreERKNSt3__16vectorINS1_10shared_ptrINS_12LmeContainerEEENS1_9allocatorIS5_EEEERKNS_8LocationERKNS1_12basic_stringIcNS1_11char_traitsIcEENS6_IcEEEERKNS2_ISI_NS6_ISI_EEEEbRNS_6LmInfoERKNS2_INS3_IN5kaldi6quasar8LmHandleEEENS6_ISU_EEEEbSK_RKNS2_IiNS6_IiEEEEbbbiSO_E3$_2
NSt3__110__function6__funcIZN6quasar11FstLmScorer14computeLmScoreERKNS_6vectorINS_10shared_ptrINS2_12LmeContainerEEENS_9allocatorIS7_EEEERKNS2_8LocationERKNS_12basic_stringIcNS_11char_traitsIcEENS8_IcEEEERKNS4_ISK_NS8_ISK_EEEEbRNS2_6LmInfoERKNS4_INS5_IN5kaldi6quasar8LmHandleEEENS8_ISW_EEEEbSM_RKNS4_IiNS8_IiEEEEbbbiSQ_E3$_3NS8_IS15_EEFNS5_INSU_17NnlmEvaluatorBaseEEERKS18_EEE
ZN6quasar11FstLmScorer14computeLmScoreERKNSt3__16vectorINS1_10shared_ptrINS_12LmeContainerEEENS1_9allocatorIS5_EEEERKNS_8LocationERKNS1_12basic_stringIcNS1_11char_traitsIcEENS6_IcEEEERKNS2_ISI_NS6_ISI_EEEEbRNS_6LmInfoERKNS2_INS3_IN5kaldi6quasar8LmHandleEEENS6_ISU_EEEEbSK_RKNS2_IiNS6_IiEEEEbbbiSO_E3$_3
N4utf815not_enough_roomE
N4utf89exceptionE
N4utf812invalid_utf8E
N4utf818invalid_code_pointE
N6quasar13QuasarG2PBaseE
N5kaldi12CuVectorBaseIdEE
NSt3__110__function6__funcIZN5kaldi6quasar26ConfidenceFeatureExtractorINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEE30GetConfidenceFeaturesFromNBestERKNS_6vectorINSC_ISA_NS8_ISA_EEEENS8_ISE_EEEERKNSC_IfNS8_IfEEEEiPNSC_INS2_6MatrixIfEENS8_ISO_EEEEEUliiE_NS8_ISS_EEFfiiEEE
NSt3__110__function6__baseIFfiiEEE
ZN5kaldi6quasar26ConfidenceFeatureExtractorINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEE30GetConfidenceFeaturesFromNBestERKNS2_6vectorINSA_IS8_NS6_IS8_EEEENS6_ISC_EEEERKNSA_IfNS6_IfEEEEiPNSA_INS_6MatrixIfEENS6_ISM_EEEEEUliiE_
NSt3__110__function6__funcIZN5kaldi6quasar26ConfidenceFeatureExtractorINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEE30GetConfidenceFeaturesFromNBestERKNS_6vectorINSC_ISA_NS8_ISA_EEEENS8_ISE_EEEERKNSC_IfNS8_IfEEEEiPNSC_INS2_6MatrixIfEENS8_ISO_EEEEEUliiE0_NS8_ISS_EEFfiiEEE
ZN5kaldi6quasar26ConfidenceFeatureExtractorINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEE30GetConfidenceFeaturesFromNBestERKNS2_6vectorINSA_IS8_NS6_IS8_EEEENS6_ISC_EEEERKNSA_IfNS6_IfEEEEiPNSA_INS_6MatrixIfEENS6_ISM_EEEEEUliiE0_
NSt3__110__function6__funcIZN5kaldi6quasar26ConfidenceFeatureExtractorINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEE30GetConfidenceFeaturesFromNBestERKNS_6vectorINSC_ISA_NS8_ISA_EEEENS8_ISE_EEEERKNSC_IfNS8_IfEEEEiPNSC_INS2_6MatrixIfEENS8_ISO_EEEEEUliiE1_NS8_ISS_EEFfiiEEE
ZN5kaldi6quasar26ConfidenceFeatureExtractorINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEE30GetConfidenceFeaturesFromNBestERKNS2_6vectorINSA_IS8_NS6_IS8_EEEENS6_ISC_EEEERKNSA_IfNS6_IfEEEEiPNSA_INS_6MatrixIfEENS6_ISM_EEEEEUliiE1_
NSt3__110__function6__funcIZN5kaldi6quasar26ConfidenceFeatureExtractorINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEE30GetConfidenceFeaturesFromNBestERKNS_6vectorINSC_ISA_NS8_ISA_EEEENS8_ISE_EEEERKNSC_IfNS8_IfEEEEiPNSC_INS2_6MatrixIfEENS8_ISO_EEEEEUliiE2_NS8_ISS_EEFfiiEEE
ZN5kaldi6quasar26ConfidenceFeatureExtractorINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEE30GetConfidenceFeaturesFromNBestERKNS2_6vectorINSA_IS8_NS6_IS8_EEEENS6_ISC_EEEERKNSA_IfNS6_IfEEEEiPNSA_INS_6MatrixIfEENS6_ISM_EEEEEUliiE2_
NSt3__110__function6__funcIZN5kaldi6quasar26ConfidenceFeatureExtractorINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEE30GetConfidenceFeaturesFromNBestERKNS_6vectorINSC_ISA_NS8_ISA_EEEENS8_ISE_EEEERKNSC_IfNS8_IfEEEEiPNSC_INS2_6MatrixIfEENS8_ISO_EEEEEUliiE3_NS8_ISS_EEFfiiEEE
ZN5kaldi6quasar26ConfidenceFeatureExtractorINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEE30GetConfidenceFeaturesFromNBestERKNS2_6vectorINSA_IS8_NS6_IS8_EEEENS6_ISC_EEEERKNSA_IfNS6_IfEEEEiPNSA_INS_6MatrixIfEENS6_ISM_EEEEEUliiE3_
NSt3__110__function6__funcIZN5kaldi6quasar26ConfidenceFeatureExtractorINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEE30GetConfidenceFeaturesFromNBestERKNS_6vectorINSC_ISA_NS8_ISA_EEEENS8_ISE_EEEERKNSC_IfNS8_IfEEEEiPNSC_INS2_6MatrixIfEENS8_ISO_EEEEEUliiE4_NS8_ISS_EEFfiiEEE
ZN5kaldi6quasar26ConfidenceFeatureExtractorINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEE30GetConfidenceFeaturesFromNBestERKNS2_6vectorINSA_IS8_NS6_IS8_EEEENS6_ISC_EEEERKNSA_IfNS6_IfEEEEiPNSA_INS_6MatrixIfEENS6_ISM_EEEEEUliiE4_
NSt3__110__function6__funcIZN5kaldi6quasar26ConfidenceFeatureExtractorINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEE30GetConfidenceFeaturesFromNBestERKNS_6vectorINSC_ISA_NS8_ISA_EEEENS8_ISE_EEEERKNSC_IfNS8_IfEEEEiPNSC_INS2_6MatrixIfEENS8_ISO_EEEEEUliiE5_NS8_ISS_EEFfiiEEE
ZN5kaldi6quasar26ConfidenceFeatureExtractorINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEE30GetConfidenceFeaturesFromNBestERKNS2_6vectorINSA_IS8_NS6_IS8_EEEENS6_ISC_EEEERKNSA_IfNS6_IfEEEEiPNSA_INS_6MatrixIfEENS6_ISM_EEEEEUliiE5_
NSt3__110__function6__funcIZN5kaldi6quasar26ConfidenceFeatureExtractorINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEE30GetConfidenceFeaturesFromNBestERKNS_6vectorINSC_ISA_NS8_ISA_EEEENS8_ISE_EEEERKNSC_IfNS8_IfEEEEiPNSC_INS2_6MatrixIfEENS8_ISO_EEEEEUliiE6_NS8_ISS_EEFfiiEEE
ZN5kaldi6quasar26ConfidenceFeatureExtractorINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEE30GetConfidenceFeaturesFromNBestERKNS2_6vectorINSA_IS8_NS6_IS8_EEEENS6_ISC_EEEERKNSA_IfNS6_IfEEEEiPNSA_INS_6MatrixIfEENS6_ISM_EEEEEUliiE6_
NSt3__110__function6__funcIZN5kaldi6quasar16ConfusionNetworkINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEEC1ERKNS_6vectorINSC_ISA_NS8_ISA_EEEENS8_ISE_EEEERKNSC_IfNS8_IfEEEENS_8functionIFSE_SE_EEENSN_IFSA_SA_EEEEd0_UlSE_E_NS8_ISS_EESO_EE
NSt3__110__function6__baseIFNS_6vectorINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS6_IS8_EEEESA_EEE
ZN5kaldi6quasar16ConfusionNetworkINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEEC1ERKNS2_6vectorINSA_IS8_NS6_IS8_EEEENS6_ISC_EEEERKNSA_IfNS6_IfEEEENS2_8functionIFSC_SC_EEENSL_IFS8_S8_EEEEd0_UlSC_E_
NSt3__110__function6__funcIZN5kaldi6quasar16ConfusionNetworkINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEEC1ERKNS_6vectorINSC_ISA_NS8_ISA_EEEENS8_ISE_EEEERKNSC_IfNS8_IfEEEENS_8functionIFSE_SE_EEENSN_IFSA_SA_EEEEd_UlSA_E_NS8_ISS_EESQ_EE
NSt3__110__function6__baseIFNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEES7_EEE
ZN5kaldi6quasar16ConfusionNetworkINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEEC1ERKNS2_6vectorINSA_IS8_NS6_IS8_EEEENS6_ISC_EEEERKNSA_IfNS6_IfEEEENS2_8functionIFSC_SC_EEENSL_IFS8_S8_EEEEd_UlS8_E_
NSt3__120__shared_ptr_pointerIPN6quasar20SyncSpeechRecognizerENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN6quasar20SyncSpeechRecognizerEEE
N6quasar15OptionValueBaseE
N6quasar11OptionsBaseE
N6quasar15ProcessingBlockE
N6quasar25MultiInputProcessingBlockE
N6quasar16ProcessingSourceE
N6quasar14ProcessingSinkE
N6quasar13MergerOptionsE
N6quasar25ConfiguredProcessingBlockINS_13MergerOptionsEEE
N6quasar11MergerBlockE
N6quasar9NullBlockE
N6quasar16DumpBlockOptionsE
N6quasar25ConfiguredProcessingBlockINS_16DumpBlockOptionsEEE
N6quasar9DumpBlockE
N6quasar2lm8arpa2fst10kaldi_fork14ArpaFileParserE
NSt3__120__shared_ptr_emplaceIN5kaldi8CuMatrixIfEENS_9allocatorIS3_EEEE
$@N6quasar10TranslatorE
NSt3__120__shared_ptr_emplaceIN6quasar14PDecTranslatorENS_9allocatorIS2_EEEE
N5kaldi6quasar17AbstractAttributeE
N5kaldi6quasar10MajorErrorE
N5kaldi6quasar15SchemaAttributeE
N5kaldi6quasar15StringAttributeE
N5kaldi6quasar14FloatAttributeE
N5kaldi6quasar13BaseAttributeE
N5kaldi6quasar16AttributeWrapperE
N5kaldi6quasar16ContextAttributeE
N5kaldi6quasar13WordConfusionE
N5kaldi6quasar16AttributeFactoryE
9SpeechITN
13QuasarITNImpl
@N6quasar7DecoderE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_16LatticeWeightTplIfEEEENSt3__19allocatorIS6_EEEEEENS_10MutableFstIS6_EEEE
N3fst11ExpandedFstINS_6ArcTplINS_16LatticeWeightTplIfEEEEEE
N3fst3FstINS_6ArcTplINS_16LatticeWeightTplIfEEEEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_6ArcTplINS_16LatticeWeightTplIfEEEENS_11VectorStateIS5_NSt3__19allocatorIS5_EEEEEEEE
N3fst22MutableArcIteratorBaseINS_6ArcTplINS_16LatticeWeightTplIfEEEEEE
N3fst9FifoQueueIiEE
N3fst9VectorFstINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENS_11VectorStateIS6_NSt3__19allocatorIS6_EEEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENSt3__19allocatorIS8_EEEEEENS_10MutableFstIS8_EEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENSt3__19allocatorIS7_EEEEEE
N3fst13CacheBaseImplINS_10CacheStateINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENSt3__19allocatorIS7_EEEENS_17DefaultCacheStoreIS7_EEEE
NSt3__120__shared_ptr_emplaceINS_6vectorIdNS_9allocatorIdEEEENS2_IS4_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar5TokenENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar31OnlineLatticeBiglmFasterDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar34OnlineLatticeBiglmLmeFasterDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar34OnlineLatticeBiglmLmeFasterDecoder23LmeCreationDependenciesENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar29OnlineLatticeRescalingDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar33OnlineLatticeWordAlignmentDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar24OnlineLmRescoringDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar31OnlineLatticeRealignmentDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar19ErrorBlamingDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar30OnlineLatticeConfidenceDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar20LatticeFasterDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar28OnlineKeywordSpottingDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar18OnlineSeevaDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar22OnlineSeevaStepDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar27OnlineSeevaStepBigLmDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar18SeevaGreedyDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar17SeevaBatchDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar26OnlineLASBeamSearchDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar37OnlineLASSpeculativeBeamSearchDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar37OnlineLASLmRescoringBeamSearchDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar48OnlineLASLmRescoringSpeculativeBeamSearchDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar33OnlineTransducerBeamSearchDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar24SystemCombinationDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar31ConfusionNetworkCombinerDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar20PhoneticMatchDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar19FingerprintDetectorENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar27OnlineAudioAnalyticsDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar17WatermarkDetectorENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar21AudioAnalyticsDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar19LatticeRnnMitigatorENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar14HwcnConfidenceENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar16E2EAsrConfidenceENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar18WatermarkDetector2ENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar20LatticeLmeFtmDecoderENS_9allocatorIS2_EEEE
N5kaldi6quasar11ErrorBlamerE
N3fst3FstINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEE
N3fst7FstImplINS_6ArcTplINS_16LatticeWeightTplIfEEEEEE
N3fst18ComposeFstImplBaseINS_6ArcTplINS_16LatticeWeightTplIfEEEENS_17DefaultCacheStoreIS4_EEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENS_17NullComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENS_24AltSequenceComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N6quasar13CommandTaggerE
N6quasar14CaseMapOptionsE
N6quasar25ConfiguredProcessingBlockINS_14CaseMapOptionsEEE
N6quasar12CaseMapBlockE
Q5Ngram
13NgramBayesMix
N6quasar9GeoRegionE
NSt3__120__shared_ptr_emplaceIN6quasar12BitmapRegionENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar12CircleRegionENS_9allocatorIS2_EEEE
NSt3__110__function6__funcIZN6quasar9GeoRegion10loadModelsERNS2_11ModelLoaderERNS2_10filesystem4PathEE3$_0NS_9allocatorIS9_EEFNS_10shared_ptrIN3fst3FstINSD_6ArcTplINSD_17TropicalWeightTplIfEEEEEEEERKNS_12basic_stringIcNS_11char_traitsIcEENSA_IcEEEEEEE
ZN6quasar9GeoRegion10loadModelsERNS_11ModelLoaderERNS_10filesystem4PathEE3$_0
NSt3__110__function6__funcIZN6quasar9GeoRegion10loadModelsERNS2_11ModelLoaderERNS2_10filesystem4PathEE3$_1NS_9allocatorIS9_EEFNS_10shared_ptrIN5kaldi6quasar17NnlmEvaluatorBaseEEERKNS_12basic_stringIcNS_11char_traitsIcEENSA_IcEEEEEEE
ZN6quasar9GeoRegion10loadModelsERNS_11ModelLoaderERNS_10filesystem4PathEE3$_1
N5kaldi18CoreMLInferenceNetE
NSt3__120__shared_ptr_emplaceIN5kaldi18CoreMLInferenceNetENS_9allocatorIS2_EEEE
N6quasar11DummyConfigE
N6quasar12DummyLmModelE
NSt3__120__shared_ptr_pointerIPN6quasar11FstLmHandleENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN6quasar11FstLmHandleEEE
NSt3__120__shared_ptr_pointerIPN6quasar12DummyLmModelENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN6quasar12DummyLmModelEEE
N5kaldi5nnet123FixedAttentionComponentE
N6quasar20PhoneticMatchDecoderE
NSt3__120__shared_ptr_emplaceIN6quasar25URegularExpressionWrapperENS_9allocatorIS2_EEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_6ArcTplINS_17TropicalWeightTplIfEEEENSt3__19allocatorIS5_EEEEEE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar13SymbolDecoderINS2_8PhonomapEEENS_9allocatorIS5_EEEE
>N6quasar15ProcessingGraphE
N6quasar21LinearProcessingGraphE
N6quasar23DirectedProcessingGraphE
NSt3__120__shared_ptr_emplaceIN6quasar14ProcessingSinkENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar16ProcessingSourceENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_pointerIPN6quasar15ProcessingBlockENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN6quasar15ProcessingBlockEEE
N6quasar17PhraseBookOptionsE
N6quasar25ConfiguredProcessingBlockINS_17PhraseBookOptionsEEE
N6quasar15PhraseBookBlockE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENS_24AltSequenceComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N5kaldi6quasar14RnnlmEvaluatorE
N6quasar24OnlineLmRescoringDecoderE
NSt3__110__function6__funcIZN6quasar24OnlineLmRescoringDecoder10finishInitEvE3$_0NS_9allocatorIS4_EEFNS_10shared_ptrIN3fst3FstINS8_6ArcTplINS8_17TropicalWeightTplIfEEEEEEEERKNS_12basic_stringIcNS_11char_traitsIcEENS5_IcEEEEEEE
ZN6quasar24OnlineLmRescoringDecoder10finishInitEvE3$_0
NSt3__110__function6__funcIZN6quasar24OnlineLmRescoringDecoder10finishInitEvE3$_1NS_9allocatorIS4_EEFNS_10shared_ptrIN5kaldi6quasar17NnlmEvaluatorBaseEEERKNS_12basic_stringIcNS_11char_traitsIcEENS5_IcEEEEEEE
ZN6quasar24OnlineLmRescoringDecoder10finishInitEvE3$_1
NSt3__110__function6__funcIZN6quasar24OnlineLmRescoringDecoder7runImplERNS2_15DecoderPassDataERKNS_10shared_ptrINS2_18DecoderChainOutputEEERKNS6_INS2_17SpeechRequestDataEEERKNS_8functionIFbvEEEbE3$_2NS_9allocatorISK_EEFNS6_IN3fst3FstINSN_6ArcTplINSN_17TropicalWeightTplIfEEEEEEEERKSU_EEE
ZN6quasar24OnlineLmRescoringDecoder7runImplERNS_15DecoderPassDataERKNSt3__110shared_ptrINS_18DecoderChainOutputEEERKNS4_INS_17SpeechRequestDataEEERKNS3_8functionIFbvEEEbE3$_2
NSt3__110__function6__funcIZN6quasar24OnlineLmRescoringDecoder7runImplERNS2_15DecoderPassDataERKNS_10shared_ptrINS2_18DecoderChainOutputEEERKNS6_INS2_17SpeechRequestDataEEERKNS_8functionIFbvEEEbE3$_3NS_9allocatorISK_EEFNS6_IN5kaldi6quasar17NnlmEvaluatorBaseEEERKSQ_EEE
ZN6quasar24OnlineLmRescoringDecoder7runImplERNS_15DecoderPassDataERKNSt3__110shared_ptrINS_18DecoderChainOutputEEERKNS4_INS_17SpeechRequestDataEEERKNS3_8functionIFbvEEEbE3$_3
N5kaldi6quasar14DnnlmEvaluatorE
N6quasar20SyncSpeechRecognizerE
NSt3__120__shared_ptr_emplaceIN6quasar20RecognizerComponentsINS1_11SyncDecoderEEENS_9allocatorIS4_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar18RecogRequestFilterENS_9allocatorIS2_EEEE
N5boost13property_tree11json_parser17json_parser_errorE
N5boost13property_tree17file_parser_errorE
N6quasar5PTree14JsonParseErrorE
N6quasar5PTree5ErrorE
N6quasar5PTree7BadPathE
N5boost16exception_detail10clone_implINS0_19error_info_injectorINS_13property_tree11json_parser17json_parser_errorEEEEE
N5boost16exception_detail19error_info_injectorINS_13property_tree11json_parser17json_parser_errorEEE
N5boost16exception_detail10clone_baseE
333333
@(kn
N5kaldi6quasar19SeevaBeamSearchBaseE
N6quasar3G2PE
N6quasar25AlignmentProcessorOptionsE
N6quasar25ConfiguredProcessingBlockINS_25AlignmentProcessorOptionsEEE
N6quasar23AlignmentProcessorBlockE
N3fst13StateIteratorINS_12ArcPosingFstINS_6ArcTplINS_12LogWeightTplIfEEEENS2_INS_17TropicalWeightTplIfEEEEEEEE
N3fst15ArcIteratorBaseINS_6ArcTplINS_12LogWeightTplIfEEEEEE
N3fst19MutableArcPosingFstINS_6ArcTplINS_12LogWeightTplIfEEEENS1_INS_17TropicalWeightTplIfEEEEEE
N3fst11ArcIteratorINS_19MutableArcPosingFstINS_6ArcTplINS_12LogWeightTplIfEEEENS2_INS_17TropicalWeightTplIfEEEEEEEE
N3fst18MutableArcIteratorINS_19MutableArcPosingFstINS_6ArcTplINS_12LogWeightTplIfEEEENS2_INS_17TropicalWeightTplIfEEEEEEEE
N3fst13StateIteratorINS_12ArcPosingFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS2_INS_12LogWeightTplIfEEEEEEEE
N3fst9LifoQueueIiEE
NSt3__15dequeIiNS_9allocatorIiEEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENSt3__19allocatorIS8_EEEEEENS_10MutableFstIS8_EEEE
N3fst10MutableFstINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEEE4LinkEEE
N3fst22MutableArcIteratorBaseINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEE
N3fst10ContextFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEiEE
N3fst14ContextFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEEiEE
N3fst13StateIteratorINS_10ContextFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEiEEEE
N3fst18CacheStateIteratorINS_10ContextFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEiEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_21SequenceComposeFilterINS_14ContextMatcherIS5_iEES9_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSD_EENS_21CompactHashStateTableISF_NS_11ComposeHashISF_EEEEEEEE
N3fst14ContextMatcherINS_6ArcTplINS_17TropicalWeightTplIfEEEEiEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_21SequenceComposeFilterINS_14ContextMatcherIS5_iEES9_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSD_EENS_21CompactHashStateTableISF_NS_11ComposeHashISF_EEEEEEEE
N3fst12TableMatcherINS_3FstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_13SortedMatcherIS6_EEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_21SequenceComposeFilterINS_12TableMatcherINS_3FstIS5_EENS_13SortedMatcherISA_EEEESC_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSH_EENS_21CompactHashStateTableISJ_NS_11ComposeHashISJ_EEEEEEEE
N6quasar11FstLmHandleE
N3fst31BackoffDeterministicOnDemandFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_3FstIS4_EEEE
N3fst7FstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N3fst3FstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N5kaldi8CuVectorIfEE
NSt3__120__shared_ptr_emplaceIN5kaldi14WordHypLatticeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIZN5kaldi14WordHypLattice20GetNBestMeanConfPathERNS_6vectorINS3_IPNS2_3ArcENS_9allocatorIS5_EEEENS6_IS8_EEEEiE14BackTraceTokenNS6_ISC_EEEE
N6quasar10NNLmConfigE
N6quasar9NNLmModelE
NSt3__120__shared_ptr_emplaceIN6quasar10NNLmConfig20NNLmConfigParametersENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar14RegionalLmPlugINS_10shared_ptrIN5kaldi6quasar17NnlmEvaluatorBaseEEEEENS_9allocatorIS8_EEEE
NSt3__110__function6__funcIZN6quasar9NNLmModelC1ERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEESB_SB_RKNS_10shared_ptrIKNS2_10NNLmConfigEEEE3$_0NS7_ISI_EEFNSC_IN5kaldi6quasar17NnlmEvaluatorBaseEEESB_EEE
NSt3__110__function6__baseIFNS_10shared_ptrIN5kaldi6quasar17NnlmEvaluatorBaseEEERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEEEE
ZN6quasar9NNLmModelC1ERKNSt3__112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEES9_S9_RKNS1_10shared_ptrIKNS_10NNLmConfigEEEE3$_0
NSt3__110__function6__funcIZN6quasar9NNLmModelC1ERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEffSB_bfiE3$_1NS7_ISC_EEFNS_10shared_ptrIN5kaldi6quasar17NnlmEvaluatorBaseEEESB_EEE
ZN6quasar9NNLmModelC1ERKNSt3__112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEEffS9_bfiE3$_1
N3fst24DeterministicOnDemandFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N3fst10ReplaceFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_24DefaultReplaceStateTableIS4_lEENS_17DefaultCacheStoreIS4_EEEE
N3fst29CacheDeterministicOnDemandFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_24DeterministicOnDemandFstIS4_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar9NNLmModelENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_pointerIPN6quasar9NNLmModelENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN6quasar9NNLmModelEEE
N6quasar21ComputeAheadFeatInputE
NSt3__120__shared_ptr_emplaceIN6quasar21ComputeAheadFeatInput5BatchENS_9allocatorIS3_EEEE
N6quasar19FingerprintDetectorE
N5kaldi32SequentialTableReaderArchiveImplINS_17KaldiObjectHolderINS_6VectorIfEEEEEE
N5kaldi29SequentialTableReaderImplBaseINS_17KaldiObjectHolderINS_6VectorIfEEEEEE
N5kaldi31SequentialTableReaderScriptImplINS_17KaldiObjectHolderINS_6VectorIfEEEEEE
N6quasar18AMKeywordDetectionE
N5kaldi6quasar19CEEncoderDecoderNetE
N5kaldi6quasar24CESplitEncoderDecoderNetE
N5kaldi8CuVectorIdEE
N6quasar20LatticeFasterDecoderE
NSt3__120__shared_ptr_emplaceIN3fst9VectorFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEENS1_11VectorStateIS6_NS_9allocatorIS6_EEEEEENS8_ISB_EEEE
N3fst10MutableFstINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEE
N3fst13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENSt3__19allocatorIS7_EEEEEE
N3fst7FstImplINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEE
N3fst15ArcIteratorBaseINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEE
N6quasar8TextProcE
N6quasar31OnlineLatticeRealignmentDecoderE
NSt3__119__deque_base_commonILb1EEE
NSt3__120__shared_ptr_emplaceIN5kaldi16WordBoundaryInfoENS_9allocatorIS2_EEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENSt3__19allocatorIS8_EEEEEENS_10MutableFstIS8_EEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENSt3__19allocatorIS8_EEEEEENS_10MutableFstIS8_EEEE
N3fst11ExpandedFstINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEE
N3fst3FstINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEE
N3fst10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEEE4LinkEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENS_11VectorStateIS7_NSt3__19allocatorIS7_EEEEEEEE
N3fst22MutableArcIteratorBaseINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEE
N3fst13CacheBaseImplINS_10CacheStateINS_6ArcTplINS_16LatticeWeightTplIfEEEENSt3__19allocatorIS5_EEEENS_17DefaultCacheStoreIS5_EEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENS_22LookAheadComposeFilterINS_24AltSequenceComposeFilterINS_16LookAheadMatcherINS_3FstIS5_EEEESC_EESC_SC_LNS_9MatchTypeE2EEENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSI_EENS_21CompactHashStateTableISK_NS_11ComposeHashISK_EEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENS_22LookAheadComposeFilterINS_21SequenceComposeFilterINS_16LookAheadMatcherINS_3FstIS5_EEEESC_EESC_SC_LNS_9MatchTypeE2EEENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSI_EENS_21CompactHashStateTableISK_NS_11ComposeHashISK_EEEEEEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENS_22LookAheadComposeFilterINS_21SequenceComposeFilterINS_16LookAheadMatcherINS_3FstIS5_EEEESC_EESC_SC_LNS_9MatchTypeE2EEENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSI_EENS_21CompactHashStateTableISK_NS_11ComposeHashISK_EEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENS_17NullComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENS_18MatchComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENS_18MatchComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N6quasar18PlaceholderOptionsE
N6quasar25ConfiguredProcessingBlockINS_18PlaceholderOptionsEEE
N6quasar16PlaceholderBlockE
N6quasar18FilterBlockOptionsE
N6quasar25ConfiguredProcessingBlockINS_18FilterBlockOptionsEEE
N6quasar11FilterBlockE
N5kaldi5nnet113LstmComponentINS_12CuMatrixBaseIfEEEE
N5kaldi5nnet113LstmComponentINS_15QuantizedMatrixIaEEEE
N5kaldi5nnet113LstmComponentINS_15QuantizedMatrixIsEEEE
N6quasar9DecodableE
NSt3__120__shared_ptr_emplaceIN6quasar36OnlineDecodableMatrixScaledDecodableENS_9allocatorIS2_EEEE
N6quasar36OnlineDecodableMatrixScaledDecodableE
NSt3__120__shared_ptr_pointerIPN5kaldi27OnlineDecodableMatrixScaledENS_10shared_ptrINS1_18DecodableInterfaceEE27__shared_ptr_default_deleteIS5_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrIN5kaldi18DecodableInterfaceEE27__shared_ptr_default_deleteIS2_NS1_27OnlineDecodableMatrixScaledEEE
NSt3__120__shared_ptr_emplaceIN6quasar42OnlineDecodableMatrixScaledMappedDecodableENS_9allocatorIS2_EEEE
N6quasar42OnlineDecodableMatrixScaledMappedDecodableE
NSt3__120__shared_ptr_emplaceIN5kaldi33OnlineDecodableMatrixScaledMappedENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar44OnlineDecodableMatrixScaledMappedTmDecodableENS_9allocatorIS2_EEEE
N6quasar44OnlineDecodableMatrixScaledMappedTmDecodableE
NSt3__120__shared_ptr_emplaceIN5kaldi35OnlineDecodableMatrixScaledMappedTmENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar39OnlineDecodableIdenticalMatrixDecodableENS_9allocatorIS2_EEEE
N6quasar39OnlineDecodableIdenticalMatrixDecodableE
NSt3__120__shared_ptr_pointerIPN5kaldi30OnlineDecodableIdenticalMatrixENS_10shared_ptrINS1_18DecodableInterfaceEE27__shared_ptr_default_deleteIS5_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrIN5kaldi18DecodableInterfaceEE27__shared_ptr_default_deleteIS2_NS1_30OnlineDecodableIdenticalMatrixEEE
NSt3__120__shared_ptr_emplaceIN6quasar33OnlineDecodableNnet1LazyDecodableENS_9allocatorIS2_EEEE
N6quasar33OnlineDecodableNnet1LazyDecodableE
NSt3__120__shared_ptr_emplaceIN5kaldi5nnet18PdfPriorENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi24OnlineDecodableNnet1LazyENS_9allocatorIS2_EEEE
N6quasar27GlobalPDecTranslatorFactoryE
N3fst10MemoryPoolINS_8DfsStateINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEE
14StopNgramStats
N5kaldi5nnet121CnnRearrangeComponentE
N5kaldi5nnet116PaddingComponentE
N5kaldi5nnet118Padding2DComponentE
N5kaldi5nnet132ConvolutionalMaxPoolingComponentINS_12CuMatrixBaseIfEEEE
N5kaldi5nnet132ConvolutionalMaxPoolingComponentINS_15QuantizedMatrixIaEEEE
N5kaldi5nnet132ConvolutionalMaxPoolingComponentINS_15QuantizedMatrixIsEEEE
N6quasar12SystemConfigE
N5boost2io18basic_altstringbufIcNSt3__111char_traitsIcEENS2_9allocatorIcEEEE
N5boost16exception_detail10clone_implINS0_19error_info_injectorINS_2io17bad_format_stringEEEEE
N5boost16exception_detail19error_info_injectorINS_2io17bad_format_stringEEE
N5boost2io17bad_format_stringE
N5boost2io12format_errorE
N5boost16exception_detail10clone_implINS0_19error_info_injectorINS_2io13too_many_argsEEEEE
N5boost16exception_detail19error_info_injectorINS_2io13too_many_argsEEE
N5boost2io13too_many_argsE
N5boost2io22basic_oaltstringstreamIcNSt3__111char_traitsIcEENS2_9allocatorIcEEEE
N5boost16base_from_memberINS_10shared_ptrINS_2io18basic_altstringbufIcNSt3__111char_traitsIcEENS4_9allocatorIcEEEEEELi0EEE
N5boost6detail18sp_counted_impl_pdIPNS_2io18basic_altstringbufIcNSt3__111char_traitsIcEENS4_9allocatorIcEEEENS2_22basic_oaltstringstreamIcS6_S8_E5No_OpEEE
N5boost6detail15sp_counted_baseE
N5boost2io22basic_oaltstringstreamIcNSt3__111char_traitsIcEENS2_9allocatorIcEEE5No_OpE
N5boost16exception_detail10clone_implINS0_19error_info_injectorINS_2io12too_few_argsEEEEE
N5boost16exception_detail19error_info_injectorINS_2io12too_few_argsEEE
N5boost2io12too_few_argsE
N6quasar24ConfusionNetworkCombinerE
N6quasar14ResultCombinerE
N6quasar21RankingResultCombinerE
N6quasar13TextTokenizerE
N6quasar14BasicTokenizerE
N5kaldi27DecodableMatrixScaledMappedE
N5kaldi6quasar18SeevaStepInferenceE
N5kaldi6quasar24SeevaStepInferenceConfigE
N5kaldi6quasar20SeevaInferenceConfigE
N6quasar28VoiceCommandsBasicEndPointerE
N5boost9algorithm6detail13token_finderFINS1_10is_any_ofFIcEEEE
N5boost16exception_detail10clone_implINS0_19error_info_injectorINS_17bad_function_callEEEEE
N5boost16exception_detail19error_info_injectorINS_17bad_function_callEEE
N5boost17bad_function_callE
7LMStats
NSt3__120__shared_ptr_emplaceI5VocabNS_9allocatorIS1_EEEE
NSt3__120__shared_ptr_emplaceINS_13unordered_mapIjiNS_4hashIjEENS_8equal_toIjEENS_9allocatorINS_4pairIKjiEEEEEENS6_ISB_EEEE
NSt3__110__function6__funcIZN6quasar2lm46ComputeSRILMVocabToOpenFSTSymbolTableRemappingERK5VocabRKN3fst11SymbolTableEPNS_13unordered_mapIjiNS_4hashIjEENS_8equal_toIjEENS_9allocatorINS_4pairIKjiEEEEEEbE3$_0NSG_ISN_EEFvPKcjEEE
NSt3__110__function6__baseIFvPKcjEEE
ZN6quasar2lm46ComputeSRILMVocabToOpenFSTSymbolTableRemappingERK5VocabRKN3fst11SymbolTableEPNSt3__113unordered_mapIjiNS8_4hashIjEENS8_8equal_toIjEENS8_9allocatorINS8_4pairIKjiEEEEEEbE3$_0
N6quasar20ExhaustiveEnumeratorE
N6quasar48OnlineLASLmRescoringSpeculativeBeamSearchDecoderE
N3fst9ImplToFstINS_18ComposeFstImplBaseINS_6ArcTplINS_16LatticeWeightTplIfEEEENS_17DefaultCacheStoreIS5_EEEENS_3FstIS5_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar18QsrTextSymbolTableENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN3fst9ArcMapFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEENS3_INS1_16LatticeWeightTplIfEEEENS1_18StdToLatticeMapperIfEEEENS_9allocatorISC_EEEE
N3fst9ArcMapFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS1_INS_16LatticeWeightTplIfEEEENS_18StdToLatticeMapperIfEEEE
N3fst13ArcMapFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEENS1_INS_16LatticeWeightTplIfEEEENS_18StdToLatticeMapperIfEEEE
N3fst9CacheImplINS_6ArcTplINS_16LatticeWeightTplIfEEEEEE
NSt3__120__shared_ptr_emplaceIN3fst14ArcScaleMapperENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN3fst9ArcMapFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEES6_NS1_14ArcScaleMapperEEENS_9allocatorIS8_EEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEES5_NS_14ArcScaleMapperEEENS_3FstIS5_EEEE
N3fst10ComposeFstINS_6ArcTplINS_16LatticeWeightTplIfEEEENS_17DefaultCacheStoreIS4_EEEE
NSt3__120__shared_ptr_pointerIPN5kaldi6quasar13ESNetworkPlanENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIN5kaldi6quasar13ESNetworkPlanEEE
NSt3__120__shared_ptr_pointerIPN5kaldi6quasar22ComputeEngineBufferItfENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIN5kaldi6quasar22ComputeEngineBufferItfEEE
N3fst12ArcPosingFstINS_6ArcTplINS_12LogWeightTplIfEEEENS1_INS_17TropicalWeightTplIfEEEEEE
N3fst3FstINS_6ArcTplINS_12LogWeightTplIfEEEEEE
N3fst17StateIteratorBaseINS_6ArcTplINS_12LogWeightTplIfEEEEEE
N3fst11ArcIteratorINS_12ArcPosingFstINS_6ArcTplINS_12LogWeightTplIfEEEENS2_INS_17TropicalWeightTplIfEEEEEEEE
N3fst10MutableFstINS_6ArcTplINS_12LogWeightTplIfEEEEEE
N3fst22MutableArcIteratorBaseINS_6ArcTplINS_12LogWeightTplIfEEEEEE
N3fst13VectorFstImplINS_11VectorStateINS_6ArcTplINS_17TropicalWeightTplIfEEEENSt3__19allocatorIS5_EEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_24AltSequenceComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst9AutoQueueIiEE
N3fst15StateOrderQueueIiEE
N3fst18ShortestFirstQueueIiNS_18StateWeightCompareIiNS_11NaturalLessINS_17TropicalWeightTplIfEEEEEELb0EEE
N3fst9ImplToFstINS_22DeterminizeFstImplBaseINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEENS_3FstIS7_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar10ResultInfoENS_9allocatorIS2_EEEE
N6quasar16MultiAudioBufferE
N6quasar26MultiChainMultiAudioBufferE
N6quasar14NameEnumeratorE
N6quasar17RawCopyEnumeratorE
NSt3__120__shared_ptr_emplaceIN6quasar20SimpleNameEnumeratorENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar17RawCopyEnumeratorENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar20ExhaustiveEnumeratorENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar15RegexEnumeratorENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar25JapaneseDerivedEnumeratorENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar17DerivedEnumeratorENS_9allocatorIS2_EEEE
N5kaldi6quasar22ComputeEngineBufferItfE
N5kaldi6quasar16ComputeEngineItfE
N5kaldi6quasar22ComputeEngineConfigItfE
NSt3__110__function6__baseIFfNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEEEE
NSt3__110__function6__funcIZN5kaldi6quasar7AlignerINS3_20ConfusionNetworkSlotINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEEESB_EC1ENS_8functionIFfSC_SB_EEEEUlSC_E_NS9_ISH_EEFfSC_EEE
NSt3__110__function6__baseIFfN5kaldi6quasar20ConfusionNetworkSlotINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEEEEEE
ZN5kaldi6quasar7AlignerINS0_20ConfusionNetworkSlotINSt3__112basic_stringIcNS3_11char_traitsIcEENS3_9allocatorIcEEEEEES9_EC1ENS3_8functionIFfSA_S9_EEEEUlSA_E_
NSt3__110__function6__funcIZN5kaldi6quasar7AlignerINS3_20ConfusionNetworkSlotINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEEESB_EC1ENS_8functionIFfSC_SB_EEEEUlSB_E_NS9_ISH_EEFfSB_EEE
ZN5kaldi6quasar7AlignerINS0_20ConfusionNetworkSlotINSt3__112basic_stringIcNS3_11char_traitsIcEENS3_9allocatorIcEEEEEES9_EC1ENS3_8functionIFfSA_S9_EEEEUlS9_E_
N6quasar18InputHammerOptionsE
N6quasar25ConfiguredProcessingBlockINS_18InputHammerOptionsEEE
N6quasar16InputHammerBlockE
NSt3__120__shared_ptr_emplaceIN5kaldi17LatticeScoreCacheENS_9allocatorIS2_EEEE
N5sdapi14SdapiTokenizerE
@N3fst6quasar16MergeTrieFstImplE
N3fst6quasar12MergeTrieFstE
NSt3__120__shared_ptr_emplaceIN3fst6quasar16MergeTrieFstImplENS_9allocatorIS3_EEEE
supo
mcpl
N5kaldi26ContextDependencyInterfaceE
N5kaldi18DecodableInterfaceE
N5kaldi21E2EDecodableInterfaceE
N5kaldi32AutoRegressiveDecodableInterfaceE
N5kaldi10OptionsItfE
N5kaldi17FeedForwardNetItfE
N5kaldi22ModelInitializeContextE
N5kaldi15InferenceNetItfE
N5kaldi20EncoderDecoderNetItfE
N6quasar16BitmapLoaderImplE
14_LM_FollowIter
NSt3__120__shared_ptr_emplaceI8WordInfoNS_9allocatorIS1_EEEE
N6quasar10OVSFeatureE
N6quasar23QualityEstimatorFeatureE
N6quasar17RepetitionFeatureE
N6quasar13LengthFeatureE
NSt3__120__shared_ptr_emplaceIN6quasar10OVSFeatureENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar17RepetitionFeatureENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar13LengthFeatureENS_9allocatorIS2_EEEE
N6quasar31OnlineLatticeBiglmFasterDecoderE
N3fst10MutableFstINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_16LatticeWeightTplIfEEEENSt3__19allocatorIS6_EEEEEENS_10MutableFstIS6_EEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEENS_11VectorStateIS7_NSt3__19allocatorIS7_EEEEEEEE
N3fst22MutableArcIteratorBaseINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEE
NSt3__120__shared_ptr_emplaceIN6quasar7UttInfoENS_9allocatorIS2_EEEE
NSt3__110__function6__funcIZN6quasar31OnlineLatticeBiglmFasterDecoder26doEverythingWithRawLatticeERNS2_15DecoderPassDataERKNS_10shared_ptrINS2_18DecoderChainOutputEEERKNS6_INS2_17SpeechRequestDataEEERKN5kaldi6quasar37OnlineLatticeBiglmFasterDecoderConfigERKNS_6atomicIbEEE3$_0NS_9allocatorISO_EEFbvEEE
ZN6quasar31OnlineLatticeBiglmFasterDecoder26doEverythingWithRawLatticeERNS_15DecoderPassDataERKNSt3__110shared_ptrINS_18DecoderChainOutputEEERKNS4_INS_17SpeechRequestDataEEERKN5kaldi6quasar37OnlineLatticeBiglmFasterDecoderConfigERKNS3_6atomicIbEEE3$_0
NSt3__120__shared_ptr_pointerIPN3fst9VectorFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEENS1_11VectorStateIS6_NS_9allocatorIS6_EEEEEENS_10shared_ptrINS1_3FstIS6_EEE27__shared_ptr_default_deleteISF_SB_EENS8_ISB_EEEE
NSt3__110shared_ptrIN3fst3FstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEEEEE27__shared_ptr_default_deleteIS7_NS1_9VectorFstIS6_NS1_11VectorStateIS6_NS_9allocatorIS6_EEEEEEEE
NSt3__120__shared_ptr_emplaceIN6quasar23StateAccessRecordingFstENS_9allocatorIS2_EEEE
NSt3__110__function6__funcIZN6quasar31OnlineLatticeBiglmFasterDecoder10finishInitEvE3$_1NS_9allocatorIS4_EEFNS_10shared_ptrIN3fst3FstINS8_6ArcTplINS8_17TropicalWeightTplIfEEEEEEEERKNS_12basic_stringIcNS_11char_traitsIcEENS5_IcEEEEEEE
NSt3__110__function6__baseIFNS_10shared_ptrIN3fst3FstINS3_6ArcTplINS3_17TropicalWeightTplIfEEEEEEEERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEEEE
ZN6quasar31OnlineLatticeBiglmFasterDecoder10finishInitEvE3$_1
NSt3__110__function6__funcIZN6quasar31OnlineLatticeBiglmFasterDecoder10finishInitEvE3$_2NS_9allocatorIS4_EEFNS_10shared_ptrIN5kaldi6quasar17NnlmEvaluatorBaseEEERKNS_12basic_stringIcNS_11char_traitsIcEENS5_IcEEEEEEE
ZN6quasar31OnlineLatticeBiglmFasterDecoder10finishInitEvE3$_2
NSt3__120__shared_ptr_emplaceIN6quasar21LRStreamingConfidenceENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar13EagerDecisionENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar23LatticeGenerationOutputENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN3fst31BackoffDeterministicOnDemandFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEENS1_3FstIS6_EEEENS_9allocatorIS9_EEEE
NSt3__120__shared_ptr_emplaceINS_6vectorINS_4pairIPN3fst24DeterministicOnDemandFstINS3_6ArcTplINS3_17TropicalWeightTplIfEEEEEEfEENS_9allocatorISB_EEEENSC_ISE_EEEE
NSt3__120__shared_ptr_emplaceIN3fst35LeftContextDeterministicOnDemandFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEEEENS_9allocatorIS7_EEEE
NSt3__120__shared_ptr_emplaceIN3fst31ComposeDeterministicOnDemandFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEENS1_24DeterministicOnDemandFstIS6_EES8_EENS_9allocatorIS9_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar31OnlineLatticeBiglmFasterDecoderIN3fst3FstINS4_6ArcTplINS4_17TropicalWeightTplIfEEEEEENS4_29CacheDeterministicOnDemandFstIS9_NS4_24DeterministicOnDemandFstIS9_EEEEEENS_9allocatorISF_EEEE
N5kaldi6quasar31OnlineLatticeBiglmFasterDecoderIN3fst3FstINS2_6ArcTplINS2_17TropicalWeightTplIfEEEEEENS2_29CacheDeterministicOnDemandFstIS7_NS2_24DeterministicOnDemandFstIS7_EEEEEE
N5kaldi6quasar34LatticeBiglmFasterTraceBackDecoderIN3fst3FstINS2_6ArcTplINS2_17TropicalWeightTplIfEEEEEENS2_29CacheDeterministicOnDemandFstIS7_NS2_24DeterministicOnDemandFstIS7_EEEEEE
N5kaldi6quasar9TokenHeap5TokenE
N5kaldi6quasar9TokenHeap11ForwardLinkE
NSt3__120__shared_ptr_emplaceIN3fst9VectorFstINS1_6ArcTplINS1_16LatticeWeightTplIfEEEENS1_11VectorStateIS6_NS_9allocatorIS6_EEEEEENS8_ISB_EEEE
NSt3__110__function6__funcIZN6quasar31OnlineLatticeBiglmFasterDecoder14finishDecodingERNS2_15DecoderPassDataERKNS_10shared_ptrINS2_18DecoderChainOutputEEERKNS6_INS2_17SpeechRequestDataEEEE3$_3NS_9allocatorISF_EEFbvEEE
ZN6quasar31OnlineLatticeBiglmFasterDecoder14finishDecodingERNS_15DecoderPassDataERKNSt3__110shared_ptrINS_18DecoderChainOutputEEERKNS4_INS_17SpeechRequestDataEEEE3$_3
NSt3__120__shared_ptr_emplaceIN6quasar24LatticeGenerationContextENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar15DecoderPassDataENS_9allocatorIS2_EEEE
N6quasar23StateAccessRecordingFstE
N6quasar34StateAccessRecordingFstArcIteratorE
NSt3__120__shared_ptr_emplaceIN6quasar23StateAccessRecordingFst4DataENS_9allocatorIS3_EEEE
N6quasar25AmbiguityAnnotatorOptionsE
N6quasar25ConfiguredProcessingBlockINS_25AmbiguityAnnotatorOptionsEEE
N6quasar23AmbiguityAnnotatorBlockE
NSt3__110__function6__funcIZN6quasar23AmbiguityAnnotatorBlock16MatchSpanCompareEbbE3$_0NS_9allocatorIS4_EEFbRKNS3_9MatchSpanES9_EEE
NSt3__110__function6__baseIFbRKN6quasar23AmbiguityAnnotatorBlock9MatchSpanES6_EEE
ZN6quasar23AmbiguityAnnotatorBlock16MatchSpanCompareEbbE3$_0
NSt3__110__function6__funcIZN6quasar23AmbiguityAnnotatorBlock16MatchSpanCompareEbbE3$_1NS_9allocatorIS4_EEFbRKNS3_9MatchSpanES9_EEE
ZN6quasar23AmbiguityAnnotatorBlock16MatchSpanCompareEbbE3$_1
NSt3__110__function6__funcIZN6quasar23AmbiguityAnnotatorBlock16MatchSpanCompareEbbE3$_2NS_9allocatorIS4_EEFbRKNS3_9MatchSpanES9_EEE
ZN6quasar23AmbiguityAnnotatorBlock16MatchSpanCompareEbbE3$_2
NSt3__110__function6__funcIZN6quasar23AmbiguityAnnotatorBlock16MatchSpanCompareEbbE3$_3NS_9allocatorIS4_EEFbRKNS3_9MatchSpanES9_EEE
ZN6quasar23AmbiguityAnnotatorBlock16MatchSpanCompareEbbE3$_3
N5kaldi6quasar33TransducerAutoRegressiveDecodableE
NSt3__110__function6__baseIFvPK4TrieIj6BOnodeEjRKNS_6vectorIjNS_9allocatorIjEEEES6_EEE
NSt3__110__function6__funcIZN6quasar2lm9srilm_ext11IterateTrieERK4TrieIj6BOnodeEiNS_8functionIFvPS8_jRKNS_6vectorIjNS_9allocatorIjEEEESB_EEEE3$_4NSD_ISK_EEFvSB_jjSB_EEE
NSt3__110__function6__baseIFvPK4TrieIj6BOnodeEjjS6_EEE
ZN6quasar2lm9srilm_ext11IterateTrieERK4TrieIj6BOnodeEiNSt3__18functionIFvPS5_jRKNS7_6vectorIjNS7_9allocatorIjEEEES9_EEEE3$_4
NSt3__120__shared_ptr_pointerIPN6quasar14ContextualDataENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN6quasar14ContextualDataEEE
.N5kaldi6quasar18TooManyTokensErrorE
N5kaldi6quasar24TooManyForwardLinksErrorE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEENSt3__19allocatorIS8_EEEEEENS_10MutableFstIS8_EEEE
?fff?(
?N5kaldi5nnet19ComponentE
N5kaldi5nnet118UpdatableComponentE
N5kaldi5nnet127Quantizable8BitComponentItfE
N5kaldi5nnet128Quantizable16BitComponentItfE
N5kaldi5nnet122ConvolutionalComponentE
N5kaldi5nnet124Convolutional2DComponentINS_15QuantizedMatrixIsEEEE
N5kaldi5nnet122RecurrentBaseComponentE
N5kaldi5nnet119HistoricalComponentE
N5kaldi5nnet116WordVecComponentE
N5kaldi5nnet124CompressibleComponentItfE
N5kaldi5nnet120FofeWordVecComponentE
N5kaldi5nnet121WordMultiVecComponentINS_12CuMatrixBaseIfEEEE
N5kaldi5nnet121WordMultiVecComponentINS_16CompressedMatrixEEE
N5kaldi5nnet126CompressedWordVecComponentE
N5kaldi5nnet17SoftmaxE
N5kaldi5nnet110LogSoftmaxE
N5kaldi5nnet112BlockSoftmaxE
N5kaldi5nnet114RelaxedSoftmaxE
N5kaldi5nnet17SigmoidE
N5kaldi5nnet14TanhE
N5kaldi5nnet17DropoutE
N5kaldi5nnet115MaxoutComponentE
N5kaldi5nnet114PNormComponentE
N5kaldi5nnet124RectifiedLinearComponentE
N5kaldi5nnet126ExponentialLinearComponentE
N5kaldi5nnet132ScaledExponentialLinearComponentE
N5kaldi5nnet13RbmE
N5kaldi5nnet17RbmBaseE
N5kaldi5nnet16SpliceE
N5kaldi5nnet113CopyComponentE
N5kaldi5nnet18AddShiftE
N5kaldi5nnet17RescaleE
N5kaldi5nnet15KlHmmE
N5kaldi5nnet126SentenceAveragingComponentE
N5kaldi5nnet123AveragePoolingComponentE
N5kaldi5nnet125AveragePooling2DComponentE
N5kaldi5nnet119MaxPoolingComponentE
N5kaldi5nnet121MaxPooling2DComponentE
N5kaldi5nnet121FramePoolingComponentE
N5kaldi5nnet117ParallelComponentE
N5kaldi5nnet112MultiSoftmaxE
N5kaldi5nnet19RecurrentE
N5kaldi5nnet118DuplicateComponentE
N5kaldi5nnet117IdentityComponentE
N5kaldi5nnet18DespliceE
N5kaldi5nnet118SharedNceComponentE
N5kaldi5nnet127TemporalMaxPoolingComponentE
N5kaldi5nnet122InterpolationComponentE
N5kaldi5nnet128CompressedWordTransComponentE
N5kaldi5nnet134VectorwiseQuantizedAffineTransformIaEE
N5kaldi5nnet134VectorwiseQuantizedAffineTransformIsEE
N5kaldi5nnet122AttentionBaseComponentE
N5kaldi5nnet131RecurrentAttentionBaseComponentE
N5kaldi5nnet131AttentionBaseInferenceComponentE
N5kaldi5nnet117Nnet1InferenceNetE
N5kaldi5nnet137VectorwiseQuantizable8BitComponentItfE
N6quasar20SentencePieceOptionsE
N6quasar25ConfiguredProcessingBlockINS_20SentencePieceOptionsEEE
N6quasar18SentencePieceBlockE
NSt3__120__shared_ptr_pointerIPN13sentencepiece22SentencePieceProcessorENS_10shared_ptrIS2_E27__shared_ptr_default_deleteIS2_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrIN13sentencepiece22SentencePieceProcessorEE27__shared_ptr_default_deleteIS2_S2_EE
14NgramEvalStats
N6quasar17LmeWordTaggerBaseE
N6quasar22IndexRuleLmeWordTaggerE
11TaggedVocab
p}?N6quasar17DerivedEnumeratorE
N6quasar17DerivedEnumerator9AlgorithmE
N6quasar15EnLikeAlgorithmE
N6quasar15ZhLikeAlgorithmE
N3fst9ImplToFstINS_18ComposeFstImplBaseINS_6ArcTplINS_12LogWeightTplIfEEEENS_17DefaultCacheStoreIS5_EEEENS_3FstIS5_EEEE
N3fst10MemoryPoolINS_8DfsStateINS_6ArcTplINS_12LogWeightTplIfEEEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_6ArcTplINS_12LogWeightTplIfEEEEEEE4LinkEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_12LogWeightTplIfEEEENSt3__19allocatorIS6_EEEEEENS_10MutableFstIS6_EEEE
N3fst11ExpandedFstINS_6ArcTplINS_12LogWeightTplIfEEEEEE
N3fst9ImplToFstINS_22DeterminizeFstImplBaseINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_3FstIS5_EEEE
N3fst10ComposeFstINS_6ArcTplINS_12LogWeightTplIfEEEENS_17DefaultCacheStoreIS4_EEEE
N3fst13SortedMatcherINS_3FstINS_6ArcTplINS_12LogWeightTplIfEEEEEEEE
N3fst11MatcherBaseINS_6ArcTplINS_12LogWeightTplIfEEEEEE
N3fst10MemoryPoolINS_11ArcIteratorINS_3FstINS_6ArcTplINS_12LogWeightTplIfEEEEEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_11ArcIteratorINS_3FstINS_6ArcTplINS_12LogWeightTplIfEEEEEEEEE4LinkEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_12LogWeightTplIfEEEEEENS_21SequenceComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst18ComposeFstImplBaseINS_6ArcTplINS_12LogWeightTplIfEEEENS_17DefaultCacheStoreIS4_EEEE
N3fst13CacheBaseImplINS_10CacheStateINS_6ArcTplINS_12LogWeightTplIfEEEENSt3__19allocatorIS5_EEEENS_17DefaultCacheStoreIS5_EEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_12LogWeightTplIfEEEEEENS_21SequenceComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_12LogWeightTplIfEEEEEENS_23PushLabelsComposeFilterINS_24PushWeightsComposeFilterINS_22LookAheadComposeFilterINS_24AltSequenceComposeFilterINS_16LookAheadMatcherINS_3FstIS5_EEEESE_EESE_SE_LNS_9MatchTypeE2EEESE_SE_LSG_2EEESE_SE_LSG_2EEENS_24GenericComposeStateTableIS5_NS_15PairFilterStateINSL_INS_18IntegerFilterStateIaEENS_17WeightFilterStateIS4_EEEENSM_IiEEEENS_24DefaultComposeStateTupleIiSS_EENS_21CompactHashStateTableISU_NS_11ComposeHashISU_EEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_12LogWeightTplIfEEEEEENS_23PushLabelsComposeFilterINS_24PushWeightsComposeFilterINS_22LookAheadComposeFilterINS_21SequenceComposeFilterINS_16LookAheadMatcherINS_3FstIS5_EEEESE_EESE_SE_LNS_9MatchTypeE2EEESE_SE_LSG_2EEESE_SE_LSG_2EEENS_24GenericComposeStateTableIS5_NS_15PairFilterStateINSL_INS_18IntegerFilterStateIaEENS_17WeightFilterStateIS4_EEEENSM_IiEEEENS_24DefaultComposeStateTupleIiSS_EENS_21CompactHashStateTableISU_NS_11ComposeHashISU_EEEEEEEE
N3fst13StateIteratorINS_10ComposeFstINS_6ArcTplINS_12LogWeightTplIfEEEENS_17DefaultCacheStoreIS5_EEEEEE
N3fst18CacheStateIteratorINS_10ComposeFstINS_6ArcTplINS_12LogWeightTplIfEEEENS_17DefaultCacheStoreIS5_EEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_12LogWeightTplIfEEEEEENS_17NullComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_12LogWeightTplIfEEEEEENS_17NullComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_12LogWeightTplIfEEEEEENS_24AltSequenceComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_12LogWeightTplIfEEEEEENS_24AltSequenceComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_12LogWeightTplIfEEEEEENS_18MatchComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_12LogWeightTplIfEEEEEENS_18MatchComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst9VectorFstINS_10ReverseArcINS_6ArcTplINS_12LogWeightTplIfEEEEEENS_11VectorStateIS6_NSt3__19allocatorIS6_EEEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_12LogWeightTplIfEEEEEENSt3__19allocatorIS8_EEEEEENS_10MutableFstIS8_EEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_12LogWeightTplIfEEEEEENSt3__19allocatorIS8_EEEEEENS_10MutableFstIS8_EEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_12LogWeightTplIfEEEEEENSt3__19allocatorIS8_EEEEEENS_10MutableFstIS8_EEEE
N3fst10MutableFstINS_10ReverseArcINS_6ArcTplINS_12LogWeightTplIfEEEEEEEE
N3fst11ExpandedFstINS_10ReverseArcINS_6ArcTplINS_12LogWeightTplIfEEEEEEEE
N3fst3FstINS_10ReverseArcINS_6ArcTplINS_12LogWeightTplIfEEEEEEEE
N3fst13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_12LogWeightTplIfEEEEEENSt3__19allocatorIS7_EEEEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_12LogWeightTplIfEEEEEENSt3__19allocatorIS7_EEEEEE
N3fst7FstImplINS_10ReverseArcINS_6ArcTplINS_12LogWeightTplIfEEEEEEEE
N3fst10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_6ArcTplINS_12LogWeightTplIfEEEEEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_6ArcTplINS_12LogWeightTplIfEEEEEEEEE4LinkEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_10ReverseArcINS_6ArcTplINS_12LogWeightTplIfEEEEEENS_11VectorStateIS7_NSt3__19allocatorIS7_EEEEEEEE
N3fst22MutableArcIteratorBaseINS_10ReverseArcINS_6ArcTplINS_12LogWeightTplIfEEEEEEEE
N3fst15ArcIteratorBaseINS_10ReverseArcINS_6ArcTplINS_12LogWeightTplIfEEEEEEEE
N3fst9VectorFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEENS_11VectorStateIS7_NSt3__19allocatorIS7_EEEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEENSt3__19allocatorIS9_EEEEEENS_10MutableFstIS9_EEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEENSt3__19allocatorIS9_EEEEEENS_10MutableFstIS9_EEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEENSt3__19allocatorIS9_EEEEEENS_10MutableFstIS9_EEEE
N3fst10MutableFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEE
N3fst11ExpandedFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEE
N3fst3FstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEE
N3fst13VectorFstImplINS_11VectorStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEENSt3__19allocatorIS8_EEEEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEENSt3__19allocatorIS8_EEEEEE
N3fst7FstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEE
N3fst10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEEE4LinkEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEENS_11VectorStateIS8_NSt3__19allocatorIS8_EEEEEEEE
N3fst22MutableArcIteratorBaseINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEE
N3fst15ArcIteratorBaseINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEE
N3fst9VectorFstINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEENS_11VectorStateIS9_NSt3__19allocatorIS9_EEEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEENSt3__19allocatorISB_EEEEEENS_10MutableFstISB_EEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEENSt3__19allocatorISB_EEEEEENS_10MutableFstISB_EEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEENSt3__19allocatorISB_EEEEEENS_10MutableFstISB_EEEE
N3fst10MutableFstINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEEEE
N3fst11ExpandedFstINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEEEE
N3fst3FstINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEEEE
N3fst13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEENSt3__19allocatorISA_EEEEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEENSt3__19allocatorISA_EEEEEE
N3fst7FstImplINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEEEE
N3fst10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEEEEE4LinkEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEENS_11VectorStateISA_NSt3__19allocatorISA_EEEEEEEE
N3fst22MutableArcIteratorBaseINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEEEE
N3fst15ArcIteratorBaseINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEEEE
N3fst9ArcMapFstINS_6ArcTplINS_12LogWeightTplIfEEEES4_NS_14RmWeightMapperIS4_S4_EEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_6ArcTplINS_12LogWeightTplIfEEEES5_NS_14RmWeightMapperIS5_S5_EEEENS_3FstIS5_EEEE
N3fst13ArcMapFstImplINS_6ArcTplINS_12LogWeightTplIfEEEES4_NS_14RmWeightMapperIS4_S4_EEEE
N3fst13StateIteratorINS_9ArcMapFstINS_6ArcTplINS_12LogWeightTplIfEEEES5_NS_14RmWeightMapperIS5_S5_EEEEEE
N3fst9ArcMapFstINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE1EEENS_14ToGallicMapperIS4_LS6_1EEEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE1EEENS_14ToGallicMapperIS5_LS7_1EEEEENS_3FstIS8_EEEE
N3fst13ArcMapFstImplINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE1EEENS_14ToGallicMapperIS4_LS6_1EEEEE
N3fst9CacheImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEE
N3fst13CacheBaseImplINS_10CacheStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEENSt3__19allocatorIS8_EEEENS_17DefaultCacheStoreIS8_EEEE
N3fst13StateIteratorINS_9ArcMapFstINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE1EEENS_14ToGallicMapperIS5_LS7_1EEEEEEE
N3fst17StateIteratorBaseINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEE
N3fst15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEENS_12GallicFactorIiS4_LS6_1EEEEE
N3fst9ImplToFstINS_19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEENS_12GallicFactorIiS5_LS7_1EEEEENS_3FstIS8_EEEE
N3fst19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEENS_12GallicFactorIiS4_LS6_1EEEEE
N3fst13StateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEENS_12GallicFactorIiS5_LS7_1EEEEEEE
N3fst18CacheStateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEENS_12GallicFactorIiS5_LS7_1EEEEEEE
N3fst12SigmaMatcherINS_13SortedMatcherINS_3FstINS_6ArcTplINS_12LogWeightTplIfEEEEEEEEEE
N3fst10RhoMatcherINS_12SigmaMatcherINS_13SortedMatcherINS_3FstINS_6ArcTplINS_12LogWeightTplIfEEEEEEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_12LogWeightTplIfEEEEEENS_21SequenceComposeFilterINS_10RhoMatcherINS_12SigmaMatcherINS_13SortedMatcherINS_3FstIS5_EEEEEEEESF_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSJ_EENS_21CompactHashStateTableISL_NS_11ComposeHashISL_EEEEEEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_12LogWeightTplIfEEEEEENS_21SequenceComposeFilterINS_10RhoMatcherINS_12SigmaMatcherINS_13SortedMatcherINS_3FstIS5_EEEEEEEESF_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSJ_EENS_21CompactHashStateTableISL_NS_11ComposeHashISL_EEEEEEEE
N3fst12SigmaMatcherINS_13SortedMatcherINS_3FstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEEEE
N3fst10MemoryPoolINS_11ArcIteratorINS_3FstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_21SequenceComposeFilterINS_12SigmaMatcherINS_13SortedMatcherINS_3FstIS5_EEEEEESD_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSH_EENS_21CompactHashStateTableISJ_NS_11ComposeHashISJ_EEEEEEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_21SequenceComposeFilterINS_12SigmaMatcherINS_13SortedMatcherINS_3FstIS5_EEEEEESD_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSH_EENS_21CompactHashStateTableISJ_NS_11ComposeHashISJ_EEEEEEEE
N3fst18CacheStateIteratorINS_10ComposeFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_17DefaultCacheStoreIS5_EEEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENSt3__19allocatorIS8_EEEEEENS_10MutableFstIS8_EEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENSt3__19allocatorIS8_EEEEEENS_10MutableFstIS8_EEEE
N3fst13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENSt3__19allocatorIS7_EEEEEE
N3fst10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEEEE
N3fst18DeterminizeFsaImplINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_20DefaultCommonDivisorIS3_EENS_24DefaultDeterminizeFilterIS4_EENS_28DefaultDeterminizeStateTableIS4_NS_18IntegerFilterStateIaEEEEEE
N3fst22DeterminizeFstImplBaseINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N3fst18DeterminizeFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3ENS_20DefaultCommonDivisorIS3_EENS_24DefaultDeterminizeFilterIS4_EENS_28DefaultDeterminizeStateTableIS4_NS_18IntegerFilterStateIaEEEEEE
N3fst13StateIteratorINS_14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEEEEEE
N3fst18CacheStateIteratorINS_14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEEEEEE
N3fst15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEENS_12GallicFactorIiS4_LS6_3EEEEE
N3fst9ImplToFstINS_19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEENS_12GallicFactorIiS5_LS7_3EEEEENS_3FstIS8_EEEE
N3fst19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEENS_12GallicFactorIiS4_LS6_3EEEEE
N3fst13StateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEENS_12GallicFactorIiS5_LS7_3EEEEEEE
N3fst18CacheStateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEENS_12GallicFactorIiS5_LS7_3EEEEEEE
N3fst9ArcMapFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEES5_NS_16FromGallicMapperIS5_LS6_3EEEEE
N3fst13ArcMapFstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEES5_NS_16FromGallicMapperIS5_LS6_3EEEEE
N3fst13StateIteratorINS_9ArcMapFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEES6_NS_16FromGallicMapperIS6_LS7_3EEEEEEE
N3fst18DeterminizeFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2ENS_20DefaultCommonDivisorIS3_EENS_24DefaultDeterminizeFilterIS4_EENS_28DefaultDeterminizeStateTableIS4_NS_18IntegerFilterStateIaEEEEEE
N3fst9ArcMapFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE2EEENS_14ToGallicMapperIS4_LS6_2EEEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE2EEENS_14ToGallicMapperIS5_LS7_2EEEEENS_3FstIS8_EEEE
N3fst3FstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEEEE
N3fst13ArcMapFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE2EEENS_14ToGallicMapperIS4_LS6_2EEEEE
N3fst9CacheImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEEEE
N3fst13CacheBaseImplINS_10CacheStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEENSt3__19allocatorIS8_EEEENS_17DefaultCacheStoreIS8_EEEE
N3fst7FstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEEEE
N3fst10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEEEEE4LinkEEE
N3fst17StateIteratorBaseINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEEEE
N3fst14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEEEE
N3fst9ImplToFstINS_22DeterminizeFstImplBaseINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEEEENS_3FstIS8_EEEE
N3fst18DeterminizeFsaImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEENS_19GallicCommonDivisorIiS4_LS6_2ENS_20DefaultCommonDivisorIS4_EEEENS_24DefaultDeterminizeFilterIS7_EENS_28DefaultDeterminizeStateTableIS7_NS_18IntegerFilterStateIaEEEEEE
N3fst22DeterminizeFstImplBaseINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEEEE
N3fst13StateIteratorINS_14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEEEEEE
N3fst18CacheStateIteratorINS_14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEEEEEE
N3fst15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEENS_12GallicFactorIiS4_LS6_2EEEEE
N3fst9ImplToFstINS_19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEENS_12GallicFactorIiS5_LS7_2EEEEENS_3FstIS8_EEEE
N3fst19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEENS_12GallicFactorIiS4_LS6_2EEEEE
N3fst13StateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEENS_12GallicFactorIiS5_LS7_2EEEEEEE
N3fst18CacheStateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEENS_12GallicFactorIiS5_LS7_2EEEEEEE
N3fst9ArcMapFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEES5_NS_16FromGallicMapperIS5_LS6_2EEEEE
N3fst13ArcMapFstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEES5_NS_16FromGallicMapperIS5_LS6_2EEEEE
N3fst13StateIteratorINS_9ArcMapFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEES6_NS_16FromGallicMapperIS6_LS7_2EEEEEEE
N3fst18DeterminizeFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4ENS_20DefaultCommonDivisorIS3_EENS_24DefaultDeterminizeFilterIS4_EENS_28DefaultDeterminizeStateTableIS4_NS_18IntegerFilterStateIaEEEEEE
N3fst9ArcMapFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE4EEENS_14ToGallicMapperIS4_LS6_4EEEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE4EEENS_14ToGallicMapperIS5_LS7_4EEEEENS_3FstIS8_EEEE
N3fst3FstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEEEE
N3fst13ArcMapFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE4EEENS_14ToGallicMapperIS4_LS6_4EEEEE
N3fst9CacheImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEEEE
N3fst13CacheBaseImplINS_10CacheStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEENSt3__19allocatorIS8_EEEENS_17DefaultCacheStoreIS8_EEEE
N3fst7FstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEEEE
N3fst10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEEEEE4LinkEEE
N3fst17StateIteratorBaseINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEEEE
N3fst14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEEEE
N3fst9ImplToFstINS_22DeterminizeFstImplBaseINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEEEENS_3FstIS8_EEEE
N3fst18DeterminizeFsaImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEENS_19GallicCommonDivisorIiS4_LS6_4ENS_20DefaultCommonDivisorIS4_EEEENS_24DefaultDeterminizeFilterIS7_EENS_28DefaultDeterminizeStateTableIS7_NS_18IntegerFilterStateIaEEEEEE
N3fst22DeterminizeFstImplBaseINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEEEE
N3fst13StateIteratorINS_14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEEEEEE
N3fst18CacheStateIteratorINS_14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEEEEEE
N3fst15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEENS_12GallicFactorIiS4_LS6_4EEEEE
N3fst9ImplToFstINS_19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEENS_12GallicFactorIiS5_LS7_4EEEEENS_3FstIS8_EEEE
N3fst19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEENS_12GallicFactorIiS4_LS6_4EEEEE
N3fst13StateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEENS_12GallicFactorIiS5_LS7_4EEEEEEE
N3fst18CacheStateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEENS_12GallicFactorIiS5_LS7_4EEEEEEE
N3fst9ArcMapFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEES5_NS_16FromGallicMapperIS5_LS6_4EEEEE
N3fst13ArcMapFstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEES5_NS_16FromGallicMapperIS5_LS6_4EEEEE
N3fst13StateIteratorINS_9ArcMapFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEES6_NS_16FromGallicMapperIS6_LS7_4EEEEEEE
N3fst18CacheStateIteratorINS_14DeterminizeFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEE
N3fst9VectorFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEENS_11VectorStateIS7_NSt3__19allocatorIS7_EEEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEENSt3__19allocatorIS9_EEEEEENS_10MutableFstIS9_EEEE
N3fst10MutableFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N3fst13VectorFstImplINS_11VectorStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEENSt3__19allocatorIS8_EEEEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEENSt3__19allocatorIS8_EEEEEE
N3fst7FstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N3fst15ArcIteratorBaseINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N3fst9VectorFstINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEENS_11VectorStateIS9_NSt3__19allocatorIS9_EEEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEENSt3__19allocatorISB_EEEEEENS_10MutableFstISB_EEEE
N3fst10MutableFstINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEEEE
N3fst13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEENSt3__19allocatorISA_EEEEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEENSt3__19allocatorISA_EEEEEE
N3fst7FstImplINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEEEE
N3fst15ArcIteratorBaseINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEEEE
N3fst15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEENS_12GallicFactorIiS4_LS6_0EEEEE
N3fst9ImplToFstINS_19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEENS_12GallicFactorIiS5_LS7_0EEEEENS_3FstIS8_EEEE
N3fst13CacheBaseImplINS_10CacheStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEENSt3__19allocatorIS8_EEEENS_17DefaultCacheStoreIS8_EEEE
N3fst18CacheStateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEENS_12GallicFactorIiS5_LS7_0EEEEEEE
N3fst17StateIteratorBaseINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N6quasar8artifact27AppLmArtifactLifeCycleStageE
AN6quasar27OnlineSeevaStepBigLmDecoderE
N5kaldi6quasar26SeevaStepLmInferenceConfigE
N5kaldi12CuMatrixBaseIfEE
NSt3__120__shared_ptr_emplaceIN3fst14BackoffArcInfoENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar31DeterministicOnDemandFstCreatorIN3fst6ArcTplINS4_17TropicalWeightTplIfEEEEEENS_9allocatorIS9_EEEE
N3fst18CacheStateIteratorINS_10ReplaceFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_24DefaultReplaceStateTableIS5_lEENS_17DefaultCacheStoreIS5_EEEEEE
N3fst13SortedMatcherINS_10ReplaceFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_24DefaultReplaceStateTableIS5_lEENS_17DefaultCacheStoreIS5_EEEEEE
N5kaldi6quasar27NeuralNgramDeterministicFstIN3fst6ArcTplINS2_17TropicalWeightTplIfEEEEEE
NSt3__120__shared_ptr_emplaceIN3fst35InterpolateDeterministicOnDemandFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEEEENS_9allocatorIS7_EEEE
N3fst35InterpolateDeterministicOnDemandFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
NSt3__120__shared_ptr_emplaceIN3fst29CacheDeterministicOnDemandFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEENS1_24DeterministicOnDemandFstIS6_EEEENS_9allocatorIS9_EEEE
N5boost13property_tree10xml_parser16xml_parser_errorE
N5boost13property_tree6detail8rapidxml11parse_errorE
N5boost16exception_detail10clone_implINS0_19error_info_injectorINS_13property_tree10xml_parser16xml_parser_errorEEEEE
N5boost16exception_detail19error_info_injectorINS_13property_tree10xml_parser16xml_parser_errorEEE
N5boost9exceptionE
N6quasar26OnlineLASBeamSearchDecoderE
N3fst18ShortestFirstQueueIiNS_18StateWeightCompareIiNS_11NaturalLessINS_16LatticeWeightTplIfEEEEEELb0EEE
N3fst9ImplToFstINS_22DeterminizeFstImplBaseINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEENS_3FstIS7_EEEE
N3fst18DeterminizeFsaImplINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENS_20DefaultCommonDivisorIS4_EENS_24DefaultDeterminizeFilterIS6_EENS_28DefaultDeterminizeStateTableIS6_NS_18IntegerFilterStateIaEEEEEE
N3fst9CacheImplINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEE
NSt3__120__shared_ptr_emplaceIN6quasar25ConcreteSpeechRequestDataENS_9allocatorIS2_EEEE
N6quasar13WordPronCacheE
N6quasar7LmeDataE
?N6quasar22SpeechRecognizerConfig23UnsupportedVersionErrorE
N6quasar16SpeechRecognizerE
NSt3__123enable_shared_from_thisIN6quasar16SpeechRecognizerEEE
NSt3__120__shared_ptr_emplaceINS_5mutexENS_9allocatorIS1_EEEE
N6quasar16SpeechRecognizer25ModelLoaderFactoryAdapterE
N6quasar27SpeechRecognizerModelLoader7FactoryE
NSt3__120__shared_ptr_emplaceIN6quasar19SpeakerCodeTrainingENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar16RecogAudioBufferENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_pointerIPN6quasar26DecoderChainPersistentDataENS_10shared_ptrIS2_E27__shared_ptr_default_deleteIS2_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrIN6quasar26DecoderChainPersistentDataEE27__shared_ptr_default_deleteIS2_S2_EE
N5kaldi8CuMatrixIfEE
NSt3__120__shared_ptr_pointerIPN6quasar16SpeechRecognizerENS_10shared_ptrIS2_E27__shared_ptr_default_deleteIS2_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrIN6quasar16SpeechRecognizerEE27__shared_ptr_default_deleteIS2_S2_EE
NSt3__110__function6__funcINS_6__bindIMN6quasar16SpeechRecognizerEFbvEJPS4_EEENS_9allocatorIS8_EEFbvEEE
NSt3__110__function6__baseIFbvEEE
NSt3__16__bindIMN6quasar16SpeechRecognizerEFbvEJPS2_EEE
NSt3__118__weak_result_typeIMN6quasar16SpeechRecognizerEFbvEEE
NSt3__114unary_functionIPN6quasar16SpeechRecognizerEbEE
NSt3__120__shared_ptr_emplaceIN6quasar21ConfusionNetworkCacheENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar27SpeechRecognizerModelLoaderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar25SpeakerCodeTrainingConfigENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar9MuxHelperENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar26MultiChainMultiAudioBufferENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar16MultiAudioBufferENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi20OnlineBufferingInputENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar18OnlineCacheInputFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceINS_5queueIN5kaldi8CuMatrixIfEENS_5dequeIS4_NS_9allocatorIS4_EEEEEENS6_IS9_EEEE
NSt3__120__shared_ptr_emplaceIjNS_9allocatorIjEEEE
NSt3__120__shared_ptr_emplaceIN5kaldi19OnlineFeatureMatrixENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar25SilencePosteriorGeneratorENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar22ResultStreamStabilizerENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar5PTreeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar15SyncRecogResultENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar20SyncRecogAudioBufferENS_9allocatorIS2_EEEE
NSt3__110__function6__baseIFfffEEE
NSt3__110__function6__funcIN5kaldi6quasar19ConfusionNetworkArcINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEEUlffE_ENS8_ISC_EEFfffEEE
N5kaldi6quasar19ConfusionNetworkArcINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEEUlffE_E
NSt3__110__function6__funcIZN5kaldi6quasar16ConfusionNetworkINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEE9ConstructEvEUlNS3_20ConfusionNetworkSlotISA_EESA_E_NS8_ISE_EEFfSD_SA_EEE
NSt3__110__function6__baseIFfN5kaldi6quasar20ConfusionNetworkSlotINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEEESA_EEE
ZN5kaldi6quasar16ConfusionNetworkINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEE9ConstructEvEUlNS0_20ConfusionNetworkSlotIS8_EES8_E_
N6quasar10filesystem22TemporaryDirectoryPathE
N6quasar20LatticeLmeFtmDecoderE
N6quasar27SpeechRecognizerModelLoader14DefaultFactoryE
NSt3__120__shared_ptr_emplaceIN6quasar20RecognizerComponentsINS1_7DecoderEEENS_9allocatorIS4_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar31SilencePosteriorGeneratorConfigENS_9allocatorIS2_EEEE
N6quasar15RegexEnumeratorE
NSt3__120__shared_ptr_emplaceIN6quasar11ReplaceStepENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar9SplitStepENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar15WholeStringStepENS_9allocatorIS2_EEEE
?NSt3__121__basic_string_commonILb1EEE
N6quasar18DatabasePhraseBookE
N6quasar17GenericPhraseBookE
NSt3__120__shared_ptr_pointerIPN6quasar18DatabasePhraseBookENS_10shared_ptrIS2_E27__shared_ptr_default_deleteIS2_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrIN6quasar18DatabasePhraseBookEE27__shared_ptr_default_deleteIS2_S2_EE
N6quasar14QuasarTextProcE
NSt3__120__shared_ptr_pointerIPN3fst8ConstFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEEjEENS_10shared_ptrINS1_3FstIS6_EEE27__shared_ptr_default_deleteISB_S7_EENS_9allocatorIS7_EEEE
NSt3__110shared_ptrIN3fst3FstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEEEEE27__shared_ptr_default_deleteIS7_NS1_8ConstFstIS6_jEEEE
NSt3__120__shared_ptr_emplaceIN6quasar21InverseTextNormalizerENS_9allocatorIS2_EEEE
N5kaldi18OnlineFeatInputItfE
N5kaldi15OnlineCmvnInputE
N5kaldi14OnlineCmnInputE
N5kaldi16OnlineCacheInputE
N5kaldi19OnlineRecordedInputE
N5kaldi17OnlineSpliceInputE
N5kaldi22OnlineSpliceBatchInputE
N5kaldi22OnlineNnetForwardInputE
N5kaldi29OnlineNnetForwardSkippedInputE
N5kaldi17OnlineAppendInputE
N5kaldi17OnlineSubsampleFeE
N5kaldi14OnlineLdaInputE
N5kaldi20OnlineTransformInputE
N5kaldi20OnlineBufferingInputE
N5kaldi14OnlinePadInputE
N5kaldi16OnlineDeltaInputE
N6quasar28OnlineKeywordSpottingDecoderE
9StopNgram
N@N3fst12ArcPosingFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS1_INS_12LogWeightTplIfEEEEEE
N3fst11ArcIteratorINS_12ArcPosingFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS2_INS_12LogWeightTplIfEEEEEEEE
N3fst16TableMatcherImplINS_3FstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_13SortedMatcherIS6_EEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_21SequenceComposeFilterINS_12TableMatcherINS_3FstIS5_EENS_13SortedMatcherISA_EEEESC_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSH_EENS_21CompactHashStateTableISJ_NS_11ComposeHashISJ_EEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_21SequenceComposeFilterINS_13SortedMatcherINS_3FstIS5_EEEENS_12TableMatcherISA_SB_EEEENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSH_EENS_21CompactHashStateTableISJ_NS_11ComposeHashISJ_EEEEEEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_21SequenceComposeFilterINS_13SortedMatcherINS_3FstIS5_EEEENS_12TableMatcherISA_SB_EEEENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSH_EENS_21CompactHashStateTableISJ_NS_11ComposeHashISJ_EEEEEEEE
N6quasar16FeatureExtractorE
N6quasar11OnlineCmnFeE
N6quasar12OnlineCmvnFeE
N6quasar13OnlineDeltaFeE
N6quasar13OnlineFbankFeE
N6quasar22OnlineFbankWithPitchFeE
N6quasar31OnlineFbankWithAudioAnalyticsFeE
N6quasar11OnlineLdaFeE
N6quasar12OnlineMfccFeE
N6quasar19OnlineNnetForwardFeE
N6quasar23OnlineNnetForwardSkipFeE
N6quasar14OnlineSpliceFeE
N6quasar23OnlineStaticTransformFeE
N6quasar18OnlineCacheInputFeE
N6quasar25OnlineComputeAheadInputFeE
N6quasar17OnlineSubsampleFeE
NSt3__120__shared_ptr_emplaceIN5kaldi17OnlineSubsampleFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar11OnlineCmnFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar12OnlineCmvnFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar13OnlineDeltaFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar13OnlineFbankFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar22OnlineFbankWithPitchFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar11OnlineLdaFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar12OnlineMfccFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar19OnlineNnetForwardFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar23OnlineNnetForwardSkipFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar14OnlineSpliceFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar17OnlineSubsampleFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar23OnlineStaticTransformFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar25OnlineComputeAheadInputFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar31OnlineFbankWithAudioAnalyticsFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar14OnlineAppendFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi14OnlineCmnInputENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi15OnlineCmvnInputENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi16OnlineDeltaInputENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi5FbankENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi13OnlineFeInputINS1_5FbankEEENS_9allocatorIS4_EEEE
N5kaldi13OnlineFeInputINS_5FbankEEE
NSt3__120__shared_ptr_emplaceIN5kaldi14FbankWithPitchENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi13OnlineFeInputINS1_14FbankWithPitchEEENS_9allocatorIS4_EEEE
N5kaldi13OnlineFeInputINS_14FbankWithPitchEEE
NSt3__120__shared_ptr_emplaceIN5kaldi23FbankWithAudioAnalyticsENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi13OnlineFeInputINS1_23FbankWithAudioAnalyticsEEENS_9allocatorIS4_EEEE
N5kaldi13OnlineFeInputINS_23FbankWithAudioAnalyticsEEE
NSt3__120__shared_ptr_emplaceIN5kaldi14OnlineLdaInputENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi4MfccENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi13OnlineFeInputINS1_4MfccEEENS_9allocatorIS4_EEEE
N5kaldi13OnlineFeInputINS_4MfccEEE
NSt3__120__shared_ptr_emplaceIN5kaldi22OnlineNnetForwardInputENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi29OnlineNnetForwardSkippedInputENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi17OnlineSpliceInputENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi20OnlineTransformInputENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi16OnlineCacheInputENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar21ComputeAheadFeatInputENS_9allocatorIS2_EEEE
N5kaldi6quasar11ErrorRegionE
N3fst11ExpandedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N6quasar14NgramFstConfigE
N6quasar21NgramSrilmCountConfigE
N6quasar29NgramSrilmInterpolationConfigE
N6quasar26NgramSrilmAdaptationConfigE
N6quasar13NgramLmModel2E
vector
const
ngram
ngram_quantized
reduced_transducer
reduced_acceptor
reduced_quantized_transducer
reduced_quantized_acceptor
squeezed_transducer
squeezed_acceptor
squeezed_quantized_transducer
squeezed_quantized_acceptor
N5kaldi6quasar8LmHandleE
N6quasar2lm26WeightOptimizationStrategyE
N3fst10MemoryPoolINS_8DfsStateINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEE
N3fst9VectorFstINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_11VectorStateIS6_NSt3__19allocatorIS6_EEEEEE
N3fst11ExpandedFstINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENSt3__19allocatorIS7_EEEEEE
N3fst15ArcIteratorBaseINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEE
NSt3__110__function6__funcIZN6quasar26_populateNgramCountContextERNS_10unique_ptrIN5srilm17NgramCountContextENS_14default_deleteIS5_EEEERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEESH_RNS2_6LmDataEbE3$_0NSD_ISK_EEFPNS2_2lm19TokenStringAndCountExEEE
NSt3__110__function6__baseIFPN6quasar2lm19TokenStringAndCountExEEE
ZN6quasar26_populateNgramCountContextERNSt3__110unique_ptrIN5srilm17NgramCountContextENS0_14default_deleteIS3_EEEERKNS0_12basic_stringIcNS0_11char_traitsIcEENS0_9allocatorIcEEEESF_RNS_6LmDataEbE3$_0
NSt3__110__function6__funcIZN6quasar26_populateNgramCountContextERNS_10unique_ptrIN5srilm17NgramCountContextENS_14default_deleteIS5_EEEERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEESH_RNS2_6LmDataEbE3$_1NSD_ISK_EEFbxEEE
NSt3__110__function6__baseIFbxEEE
ZN6quasar26_populateNgramCountContextERNSt3__110unique_ptrIN5srilm17NgramCountContextENS0_14default_deleteIS3_EEEERKNS0_12basic_stringIcNS0_11char_traitsIcEENS0_9allocatorIcEEEESF_RNS_6LmDataEbE3$_1
NSt3__110__function6__funcIZN6quasar26_populateNgramCountContextERNS_10unique_ptrIN5srilm17NgramCountContextENS_14default_deleteIS5_EEEERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEESH_RNS2_6LmDataEbE3$_2NSD_ISK_EEFvvEEE
NSt3__110__function6__baseIFvvEEE
ZN6quasar26_populateNgramCountContextERNSt3__110unique_ptrIN5srilm17NgramCountContextENS0_14default_deleteIS3_EEEERKNS0_12basic_stringIcNS0_11char_traitsIcEENS0_9allocatorIcEEEESF_RNS_6LmDataEbE3$_2
N6quasar2lm9GeneratorINS0_19TokenStringAndCountEEE
NSt3__117bad_function_callE
NSt3__110__function6__funcIZN6quasar26_populateNgramCountContextERNS_10unique_ptrIN5srilm17NgramCountContextENS_14default_deleteIS5_EEEERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEESH_RNS2_6LmDataEbE3$_3NSD_ISK_EEFPNS2_2lm19TokenStringAndCountExEEE
ZN6quasar26_populateNgramCountContextERNSt3__110unique_ptrIN5srilm17NgramCountContextENS0_14default_deleteIS3_EEEERKNS0_12basic_stringIcNS0_11char_traitsIcEENS0_9allocatorIcEEEESF_RNS_6LmDataEbE3$_3
NSt3__110__function6__funcIZN6quasar26_populateNgramCountContextERNS_10unique_ptrIN5srilm17NgramCountContextENS_14default_deleteIS5_EEEERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEESH_RNS2_6LmDataEbE3$_4NSD_ISK_EEFbxEEE
ZN6quasar26_populateNgramCountContextERNSt3__110unique_ptrIN5srilm17NgramCountContextENS0_14default_deleteIS3_EEEERKNS0_12basic_stringIcNS0_11char_traitsIcEENS0_9allocatorIcEEEESF_RNS_6LmDataEbE3$_4
NSt3__110__function6__funcIZN6quasar26_populateNgramCountContextERNS_10unique_ptrIN5srilm17NgramCountContextENS_14default_deleteIS5_EEEERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEESH_RNS2_6LmDataEbE3$_5NSD_ISK_EEFvvEEE
ZN6quasar26_populateNgramCountContextERNSt3__110unique_ptrIN5srilm17NgramCountContextENS0_14default_deleteIS3_EEEERKNS0_12basic_stringIcNS0_11char_traitsIcEENS0_9allocatorIcEEEESF_RNS_6LmDataEbE3$_5
NSt3__120__shared_ptr_emplaceIN3fst8ConstFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEEjEENS_9allocatorIS7_EEEE
N3fst8ConstFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEjEE
N3fst17ImplToExpandedFstINS_12ConstFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEEjEENS_11ExpandedFstIS5_EEEE
N3fst9ImplToFstINS_12ConstFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEEjEENS_11ExpandedFstIS5_EEEE
NSt3__120__shared_ptr_emplaceIN3fst8NGramFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb0EEENS_9allocatorIS7_EEEE
N3fst8NGramFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0EEE
N3fst17ImplToExpandedFstINS_12NGramFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0EEENS_11ExpandedFstIS5_EEEE
N3fst9ImplToFstINS_12NGramFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0EEENS_11ExpandedFstIS5_EEEE
N3fst12NGramFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0EEE
N3fst12NGramFstDataINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0EEE
N3fst11ArcIteratorINS_8NGramFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0EEEEE
N3fst15NGramFstMatcherINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0EEE
NSt3__120__shared_ptr_emplaceIN3fst8NGramFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb1EEENS_9allocatorIS7_EEEE
N3fst8NGramFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1EEE
N3fst17ImplToExpandedFstINS_12NGramFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1EEENS_11ExpandedFstIS5_EEEE
N3fst9ImplToFstINS_12NGramFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1EEENS_11ExpandedFstIS5_EEEE
N3fst12NGramFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1EEE
N3fst12NGramFstDataINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1EEE
N3fst11ArcIteratorINS_8NGramFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1EEEEE
N3fst15NGramFstMatcherINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1EEE
NSt3__120__shared_ptr_emplaceIN3fst10ReducedFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb0ELb0EEENS_9allocatorIS7_EEEE
N3fst10ReducedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb0EEE
N3fst17ImplToExpandedFstINS_14ReducedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb0EEENS_11ExpandedFstIS5_EEEE
N3fst9ImplToFstINS_14ReducedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb0EEENS_11ExpandedFstIS5_EEEE
N3fst14ReducedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb0EEE
N3fst13StateIteratorINS_10ReducedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb0EEEEE
NSt3__120__shared_ptr_emplaceIN3fst10ReducedFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb1ELb0EEENS_9allocatorIS7_EEEE
N3fst10ReducedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb0EEE
N3fst17ImplToExpandedFstINS_14ReducedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb0EEENS_11ExpandedFstIS5_EEEE
N3fst9ImplToFstINS_14ReducedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb0EEENS_11ExpandedFstIS5_EEEE
N3fst14ReducedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb0EEE
N3fst13StateIteratorINS_10ReducedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb0EEEEE
N3fst11ArcIteratorINS_10ReducedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb0EEEEE
NSt3__120__shared_ptr_emplaceIN3fst10ReducedFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb0ELb1EEENS_9allocatorIS7_EEEE
N3fst10ReducedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb1EEE
N3fst17ImplToExpandedFstINS_14ReducedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb1EEENS_11ExpandedFstIS5_EEEE
N3fst9ImplToFstINS_14ReducedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb1EEENS_11ExpandedFstIS5_EEEE
N3fst14ReducedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb1EEE
N3fst13StateIteratorINS_10ReducedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb1EEEEE
N3fst11ArcIteratorINS_10ReducedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb1EEEEE
NSt3__120__shared_ptr_emplaceIN3fst10ReducedFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb1ELb1EEENS_9allocatorIS7_EEEE
N3fst10ReducedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb1EEE
N3fst17ImplToExpandedFstINS_14ReducedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb1EEENS_11ExpandedFstIS5_EEEE
N3fst9ImplToFstINS_14ReducedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb1EEENS_11ExpandedFstIS5_EEEE
N3fst14ReducedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb1EEE
N3fst13StateIteratorINS_10ReducedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb1EEEEE
N3fst11ArcIteratorINS_10ReducedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb1EEEEE
NSt3__120__shared_ptr_emplaceIN3fst11SqueezedFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb0ELb0EEENS_9allocatorIS7_EEEE
N3fst11SqueezedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb0EEE
N3fst17ImplToExpandedFstINS_15SqueezedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb0EEENS_11ExpandedFstIS5_EEEE
N3fst9ImplToFstINS_15SqueezedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb0EEENS_11ExpandedFstIS5_EEEE
N3fst15SqueezedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb0EEE
NSt3__120__shared_ptr_emplaceIN3fst11SqueezedFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb1ELb0EEENS_9allocatorIS7_EEEE
N3fst11SqueezedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb0EEE
N3fst17ImplToExpandedFstINS_15SqueezedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb0EEENS_11ExpandedFstIS5_EEEE
N3fst9ImplToFstINS_15SqueezedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb0EEENS_11ExpandedFstIS5_EEEE
N3fst15SqueezedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb0EEE
N3fst11ArcIteratorINS_11SqueezedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb0EEEEE
NSt3__120__shared_ptr_emplaceIN3fst11SqueezedFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb0ELb1EEENS_9allocatorIS7_EEEE
N3fst11SqueezedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb1EEE
N3fst17ImplToExpandedFstINS_15SqueezedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb1EEENS_11ExpandedFstIS5_EEEE
N3fst9ImplToFstINS_15SqueezedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb1EEENS_11ExpandedFstIS5_EEEE
N3fst15SqueezedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb1EEE
N3fst11ArcIteratorINS_11SqueezedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb1EEEEE
NSt3__120__shared_ptr_emplaceIN3fst11SqueezedFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb1ELb1EEENS_9allocatorIS7_EEEE
N3fst11SqueezedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb1EEE
N3fst17ImplToExpandedFstINS_15SqueezedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb1EEENS_11ExpandedFstIS5_EEEE
N3fst9ImplToFstINS_15SqueezedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb1EEENS_11ExpandedFstIS5_EEEE
N3fst15SqueezedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb1EEE
N3fst11ArcIteratorINS_11SqueezedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb1EEEEE
NSt3__120__shared_ptr_emplaceIN6quasar13NgramLmModel2ENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_pointerIPN6quasar13NgramLmModel2ENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN6quasar13NgramLmModel2EEE
NSt3__120__shared_ptr_pointerIP5NgramNS_10shared_ptrIS1_E27__shared_ptr_default_deleteIS1_S1_EENS_9allocatorIS1_EEEE
NSt3__110shared_ptrI5NgramE27__shared_ptr_default_deleteIS1_S1_EE
N6quasar2lm5srilm13VocabIteratorE
N6quasar2lm5srilm11InterpolateE
N6quasar2lm11InterpolateI5NgramS2_EE
NSt3__110__function6__funcIZN6quasar2lm29referenceVectorToObjectStreamINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEE5NgramEEPNS3_9GeneratorIT0_EERKNS_6vectorIT_NS8_ISH_EEEENS_8functionIFPSD_xEEEEUlxE_NS8_ISQ_EEFbxEEE
ZN6quasar2lm29referenceVectorToObjectStreamINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEE5NgramEEPNS0_9GeneratorIT0_EERKNS2_6vectorIT_NS6_ISF_EEEENS2_8functionIFPSB_xEEEEUlxE_
NSt3__110__function6__funcIZN6quasar2lm29referenceVectorToObjectStreamINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEE5NgramEEPNS3_9GeneratorIT0_EERKNS_6vectorIT_NS8_ISH_EEEENS_8functionIFPSD_xEEEEUlvE_NS8_ISQ_EEFvvEEE
ZN6quasar2lm29referenceVectorToObjectStreamINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEE5NgramEEPNS0_9GeneratorIT0_EERKNS2_6vectorIT_NS6_ISF_EEEENS2_8functionIFPSB_xEEEEUlvE_
N6quasar2lm9GeneratorI5NgramEE
N6quasar2lm6StreamIP5NgramEE
NSt3__110__function6__funcIZN6quasar2lm5srilm32CreateLazyLoadedNgramModelStreamERKNS_6vectorINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS9_ISB_EEEEP5VocabiE3$_0NS9_ISI_EEFP5NgramxEEE
NSt3__110__function6__baseIFP5NgramxEEE
ZN6quasar2lm5srilm32CreateLazyLoadedNgramModelStreamERKNSt3__16vectorINS2_12basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEENS7_IS9_EEEEP5VocabiE3$_0
N6quasar10EndPointerE
N6quasar15BasicEndPointerE
N6quasar14NnetEndPointerE
NSt3__120__shared_ptr_emplaceIN6quasar9GeoRegionENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar17RegionsBitmapDataENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar9Geography10GeoContextENS_9allocatorIS3_EEEE
@N6quasar16RecogAudioBufferE
N5boost16exception_detail10clone_implINS0_19error_info_injectorISt12length_errorEEEE
N5boost16exception_detail19error_info_injectorISt12length_errorEE
N6quasar20SpeechRecognizerBaseE
N6quasar18LmeDataFactoryBaseE
N5kaldi5nnet116NnetTrainOptionsE
N5kaldi5nnet114HistoryOptionsE
N5kaldi5nnet125RecurrentNnetTrainOptionsE
NSt3__120__shared_ptr_emplaceIN5kaldi5nnet117Nnet1InferenceNetENS_9allocatorIS3_EEEE
N5kaldi5nnet115AffineTransformE
NSt3__120__shared_ptr_emplaceIN6quasar18PersonalizedLmDataENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar29NgramSrilmInterpolationConfigENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar11LmEvaluatorENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar9LmLoader2ENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar9AppLmDataENS_9allocatorIS2_EEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEENSt3__19allocatorIS8_EEEEEENS_10MutableFstIS8_EEEE
N3fst11ExpandedFstINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEE
N3fst10MutableFstINS_6ArcTplINS_16LatticeWeightTplIfEEEEEE
N3fst31ComposeDeterministicOnDemandFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_24DeterministicOnDemandFstIS4_EES6_EE
N3fst7FstImplINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEE
N3fst9VectorFstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEENS_11VectorStateIS8_NSt3__19allocatorIS8_EEEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEENSt3__19allocatorISA_EEEEEENS_10MutableFstISA_EEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEENSt3__19allocatorIS9_EEEEEE
N3fst14DeterminizeFstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEE
N3fst9ImplToFstINS_22DeterminizeFstImplBaseINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEENS_3FstIS9_EEEE
N3fst18DeterminizeFsaImplINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEENS_20DefaultCommonDivisorIS6_EENS_24DefaultDeterminizeFilterIS8_EENS_28DefaultDeterminizeStateTableIS8_NS_18IntegerFilterStateIaEEEEEE
N3fst22DeterminizeFstImplBaseINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEE
N3fst9CacheImplINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEE
N3fst13CacheBaseImplINS_10CacheStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEENSt3__19allocatorIS9_EEEENS_17DefaultCacheStoreIS9_EEEE
N3fst13StateIteratorINS_14DeterminizeFstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEEEE
N3fst18CacheStateIteratorINS_14DeterminizeFstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEEEE
N3fst17StateIteratorBaseINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_16LatticeWeightTplIfEEEENSt3__19allocatorIS6_EEEEEENS_10MutableFstIS6_EEEE
N3fst35LeftContextDeterministicOnDemandFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
8BayesMix
18NgramProbArrayTrie
8SubVocab
?NSt3__120__shared_ptr_emplaceIN6quasar17PSRAudioProcessorENS_9allocatorIS2_EEEE
N5kaldi5nnet124GlobalAttentionComponentE
N5kaldi5nnet124GlobalRecurrentAttentionE
11NgramCountsIdE
N5kaldi27OnlineAudioAnalyticsFeatureE
N6quasar27PrefixSearchableSymbolTableE
N6quasar9SymbolMap25SortedSymbolMapQuasarImplE
N6quasar9SymbolMap19SymbolMapQuasarImplE
N6quasar9SymbolMap19SymbolMapMarisaImplE
NSt3__120__shared_ptr_pointerIPN3fst10MappedFileENS_10shared_ptrIS2_E27__shared_ptr_default_deleteIS2_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrIN3fst10MappedFileEE27__shared_ptr_default_deleteIS2_S2_EE
NSt3__120__shared_ptr_pointerIPN6quasar9SymbolMap25SortedSymbolMapQuasarImplENS_10shared_ptrIN3fst11SymbolTableEE27__shared_ptr_default_deleteIS7_S3_EENS_9allocatorIS3_EEEE
NSt3__110shared_ptrIN3fst11SymbolTableEE27__shared_ptr_default_deleteIS2_N6quasar9SymbolMap25SortedSymbolMapQuasarImplEEE
NSt3__120__shared_ptr_pointerIPN6quasar9SymbolMap19SymbolMapQuasarImplENS_10shared_ptrIN3fst11SymbolTableEE27__shared_ptr_default_deleteIS7_S3_EENS_9allocatorIS3_EEEE
NSt3__110shared_ptrIN3fst11SymbolTableEE27__shared_ptr_default_deleteIS2_N6quasar9SymbolMap19SymbolMapQuasarImplEEE
NSt3__120__shared_ptr_pointerIPN6quasar9SymbolMap19SymbolMapMarisaImplENS_10shared_ptrIN3fst11SymbolTableEE27__shared_ptr_default_deleteIS7_S3_EENS_9allocatorIS3_EEEE
NSt3__110shared_ptrIN3fst11SymbolTableEE27__shared_ptr_default_deleteIS2_N6quasar9SymbolMap19SymbolMapMarisaImplEEE
N6quasar18SelectBlockOptionsE
N6quasar25ConfiguredProcessingBlockINS_18SelectBlockOptionsEEE
N6quasar11SelectBlockE
N6quasar31ContinuousListeningResultHelperE
NSt3__120__shared_ptr_emplaceIN6quasar25ContinuousListeningConfigENS_9allocatorIS2_EEEE
N3fst15ArcIteratorBaseINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEE
N3fst13VectorFstImplINS_11VectorStateINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEENSt3__19allocatorIS7_EEEEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEENSt3__19allocatorIS7_EEEEEE
N6quasar9MungeRuleE
N6quasar15MergedMungeRuleE
N6quasar14BasicMungeRuleE
5Vocab
N6quasar2lm8arpa2fst10kaldi_impl12ConvertToFSTE
NSt3__110shared_ptrINS_13unordered_mapIjiNS_4hashIjEENS_8equal_toIjEENS_9allocatorINS_4pairIKjiEEEEEEE27__shared_ptr_default_deleteISB_SB_EE
N5kaldi5nnet116LossEvaluatorItfE
N5kaldi5nnet14XentE
N5kaldi5nnet13MseE
N5kaldi11CuSubVectorIfEE
N6quasar37OnlineLASSpeculativeBeamSearchDecoderE
N6quasar16SharedPhraseBookE
NSt3__120__shared_ptr_pointerIPN6quasar16SharedPhraseBookENS_10shared_ptrIS2_E27__shared_ptr_default_deleteIS2_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrIN6quasar16SharedPhraseBookEE27__shared_ptr_default_deleteIS2_S2_EE
N6quasar13LmBuildConfigE
N6quasar8LmModel2E
dummy
ngram
ngram-adaptation
nnlm
NSt3__120__shared_ptr_emplaceIN6quasar11ModelLoaderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_pointerIPN6quasar21NgramSrilmCountConfigENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN6quasar21NgramSrilmCountConfigEEE
NSt3__120__shared_ptr_pointerIPN6quasar11DummyConfigENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN6quasar11DummyConfigEEE
NSt3__120__shared_ptr_pointerIPN6quasar26NgramSrilmAdaptationConfigENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN6quasar26NgramSrilmAdaptationConfigEEE
NSt3__120__shared_ptr_pointerIPN6quasar10NNLmConfigENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN6quasar10NNLmConfigEEE
NSt3__110__function6__funcIZN6quasar8LmModel25writeERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEE3$_0NS7_ISC_EEFvSB_EEE
NSt3__110__function6__baseIFvRKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEEEE
ZN6quasar8LmModel25writeERKNSt3__112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEEE3$_0
NSt3__110__function6__funcIZN6quasar19loadLmFromDirectoryERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEESA_RS8_RNS_8optionalINS_10shared_ptrINS2_8LmModel2EEEEEE3$_1NS6_ISI_EEFvSA_EEE
ZN6quasar19loadLmFromDirectoryERKNSt3__112basic_stringIcNS0_11char_traitsIcEENS0_9allocatorIcEEEES8_RS6_RNS0_8optionalINS0_10shared_ptrINS_8LmModel2EEEEEE3$_1
NSt3__110__function6__funcIZN6quasar8removeLmERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEE3$_2NS6_ISB_EEFvSA_EEE
ZN6quasar8removeLmERKNSt3__112basic_stringIcNS0_11char_traitsIcEENS0_9allocatorIcEEEEE3$_2
N6quasar18WatermarkDetector2E
NSt3__120__shared_ptr_emplaceIN5kaldi10SnrTrackerENS_9allocatorIS2_EEEE
N6quasar2lm8arpa2fst7inhouse16mutable_fst_impl12ConvertToFSTE
N6quasar2lm8arpa2fst7inhouse12ConvertToFSTE
N6quasar2lm8arpa2fst12ConvertToFSTE
N6quasar2lm7ConvertI5NgramN3fst11ExpandedFstINS3_6ArcTplINS3_17TropicalWeightTplIfEEEEEEEE
N6quasar2lm8arpa2fst7inhouse16fst_builder_impl12ConvertToFSTE
NSt3__120__shared_ptr_pointerIPNS_13unordered_mapIjiNS_4hashIjEENS_8equal_toIjEENS_9allocatorINS_4pairIKjiEEEEEENS_10shared_ptrISB_E27__shared_ptr_default_deleteISB_SB_EENS6_ISB_EEEE
NSt3__110__function6__funcIZNK6quasar2lm8arpa2fst7inhouse16mutable_fst_impl12ConvertToFSTclERK5NgramE3$_0NS_9allocatorISB_EEFmPK6BOnodeEEE
NSt3__110__function6__baseIFmPK6BOnodeEEE
ZNK6quasar2lm8arpa2fst7inhouse16mutable_fst_impl12ConvertToFSTclERK5NgramE3$_0
NSt3__110__function6__funcIZNK6quasar2lm8arpa2fst7inhouse16mutable_fst_impl12ConvertToFSTclERK5NgramE3$_1NS_9allocatorISB_EEFviRKN3fst17TropicalWeightTplIfEEEEE
NSt3__110__function6__baseIFviRKN3fst17TropicalWeightTplIfEEEEE
ZNK6quasar2lm8arpa2fst7inhouse16mutable_fst_impl12ConvertToFSTclERK5NgramE3$_1
NSt3__110__function6__funcIZNK6quasar2lm8arpa2fst7inhouse16mutable_fst_impl12ConvertToFSTclERK5NgramE3$_2NS_9allocatorISB_EEFviEEE
NSt3__110__function6__baseIFviEEE
ZNK6quasar2lm8arpa2fst7inhouse16mutable_fst_impl12ConvertToFSTclERK5NgramE3$_2
NSt3__110__function6__funcIZNK6quasar2lm8arpa2fst7inhouse16mutable_fst_impl12ConvertToFSTclERK5NgramE3$_3NS_9allocatorISB_EEFviRKN3fst6ArcTplINSE_17TropicalWeightTplIfEEEEEEE
NSt3__110__function6__baseIFviRKN3fst6ArcTplINS2_17TropicalWeightTplIfEEEEEEE
ZNK6quasar2lm8arpa2fst7inhouse16mutable_fst_impl12ConvertToFSTclERK5NgramE3$_3
NSt3__110__function6__funcIZNK6quasar2lm8arpa2fst7inhouse16mutable_fst_impl12ConvertToFSTclERK5NgramE3$_4NS_9allocatorISB_EEFviEEE
ZNK6quasar2lm8arpa2fst7inhouse16mutable_fst_impl12ConvertToFSTclERK5NgramE3$_4
NSt3__110__function6__funcIZNK6quasar2lm8arpa2fst7inhouse16mutable_fst_impl12ConvertToFSTclERK5NgramE3$_5NS_9allocatorISB_EEFviEEE
ZNK6quasar2lm8arpa2fst7inhouse16mutable_fst_impl12ConvertToFSTclERK5NgramE3$_5
NSt3__110__function6__funcIZNK6quasar2lm8arpa2fst7inhouse16mutable_fst_impl12ConvertToFSTclERK5NgramE3$_6NS_9allocatorISB_EEFviRKN3fst6ArcTplINSE_17TropicalWeightTplIfEEEEEEE
ZNK6quasar2lm8arpa2fst7inhouse16mutable_fst_impl12ConvertToFSTclERK5NgramE3$_6
NSt3__110__function6__funcIZNK6quasar2lm8arpa2fst7inhouse16mutable_fst_impl12ConvertToFSTclERK5NgramE3$_7NS_9allocatorISB_EEFviEEE
ZNK6quasar2lm8arpa2fst7inhouse16mutable_fst_impl12ConvertToFSTclERK5NgramE3$_7
NSt3__110__function6__funcIZNK6quasar2lm8arpa2fst7inhouse16mutable_fst_impl12ConvertToFSTclERK5NgramE3$_8NS_9allocatorISB_EEFvPK4TrieIj6BOnodeEjRKNS_6vectorIjNSC_IjEEEESI_EEE
ZNK6quasar2lm8arpa2fst7inhouse16mutable_fst_impl12ConvertToFSTclERK5NgramE3$_8
NSt3__110__function6__funcIZNK6quasar2lm8arpa2fst7inhouse16fst_builder_impl12ConvertToFSTclERK5NgramE4$_11NS_9allocatorISB_EEFvPK4TrieIj6BOnodeEjRKNS_6vectorIjNSC_IjEEEESI_EEE
ZNK6quasar2lm8arpa2fst7inhouse16fst_builder_impl12ConvertToFSTclERK5NgramE4$_11
NSt3__110__function6__funcIZNK6quasar2lm8arpa2fst7inhouse16fst_builder_impl12ConvertToFSTclERK5NgramE3$_9NS_9allocatorISB_EEFmPK6BOnodeEEE
ZNK6quasar2lm8arpa2fst7inhouse16fst_builder_impl12ConvertToFSTclERK5NgramE3$_9
NSt3__110__function6__funcIZNK6quasar2lm8arpa2fst7inhouse16fst_builder_impl12ConvertToFSTclERK5NgramE4$_12NS_9allocatorISB_EEFviEEE
ZNK6quasar2lm8arpa2fst7inhouse16fst_builder_impl12ConvertToFSTclERK5NgramE4$_12
NSt3__110__function6__funcIZNK6quasar2lm8arpa2fst7inhouse16fst_builder_impl12ConvertToFSTclERK5NgramE4$_13NS_9allocatorISB_EEFvPK4TrieIj6BOnodeEjRKNS_6vectorIjNSC_IjEEEESI_EEE
NSt3__110__function6__funcIZZNK6quasar2lm8arpa2fst7inhouse16fst_builder_impl12ConvertToFSTclERK5NgramENK4$_13clEPK4TrieIj6BOnodeEjRKNS_6vectorIjNS_9allocatorIjEEEESG_EUliE_NSI_ISN_EEFviEEE
ZZNK6quasar2lm8arpa2fst7inhouse16fst_builder_impl12ConvertToFSTclERK5NgramENK4$_13clEPK4TrieIj6BOnodeEjRKNSt3__16vectorIjNSE_9allocatorIjEEEESD_EUliE_
NSt3__110__function6__funcIZZNK6quasar2lm8arpa2fst7inhouse16fst_builder_impl12ConvertToFSTclERK5NgramENK4$_13clEPK4TrieIj6BOnodeEjRKNS_6vectorIjNS_9allocatorIjEEEESG_EUliRKN3fst17TropicalWeightTplIfEEE_NSI_ISS_EEFviSR_EEE
ZZNK6quasar2lm8arpa2fst7inhouse16fst_builder_impl12ConvertToFSTclERK5NgramENK4$_13clEPK4TrieIj6BOnodeEjRKNSt3__16vectorIjNSE_9allocatorIjEEEESD_EUliRKN3fst17TropicalWeightTplIfEEE_
NSt3__110__function6__funcIZZNK6quasar2lm8arpa2fst7inhouse16fst_builder_impl12ConvertToFSTclERK5NgramENK4$_13clEPK4TrieIj6BOnodeEjRKNS_6vectorIjNS_9allocatorIjEEEESG_EUliRKN3fst6ArcTplINSN_17TropicalWeightTplIfEEEEE_NSI_ISU_EEFviST_EEE
ZZNK6quasar2lm8arpa2fst7inhouse16fst_builder_impl12ConvertToFSTclERK5NgramENK4$_13clEPK4TrieIj6BOnodeEjRKNSt3__16vectorIjNSE_9allocatorIjEEEESD_EUliRKN3fst6ArcTplINSL_17TropicalWeightTplIfEEEEE_
ZNK6quasar2lm8arpa2fst7inhouse16fst_builder_impl12ConvertToFSTclERK5NgramE4$_13
N5boost13property_tree11ptree_errorE
N5boost13property_tree14ptree_bad_pathE
N6quasar8artifact13AppLmArtifactE
N5boost16exception_detail10clone_implINS0_19error_info_injectorINS_13property_tree14ptree_bad_pathEEEEE
N5boost16exception_detail19error_info_injectorINS_13property_tree14ptree_bad_pathEEE
N5boost3any6holderINS_13property_tree11string_pathINSt3__112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEENS2_13id_translatorISA_EEEEEE
N5boost3any11placeholderE
N5boost13property_tree11string_pathINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEENS0_13id_translatorIS8_EEEE
NSt3__120__shared_ptr_pointerIPN3fst3FstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEEEENS_14default_deleteIS7_EENS_9allocatorIS7_EEEE
NSt3__114default_deleteIN3fst3FstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEEEEEE
10WittenBell
N5kaldi5nnet118ScaledDotAttentionE
N5kaldi5nnet118MultiHeadAttentionE
N5kaldi5nnet128SupervisedMultiHeadAttentionE
N5kaldi5nnet113SelfAttentionE
N5kaldi5nnet116AverageAttentionE
21ResidualAdaptiveNgram
@olabel_lookahead
N3fst10MutableFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N6quasar9PronCacheINSt3__112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEENS1_6vectorIS7_NS5_IS7_EEEEEE
NSt3__120__shared_ptr_emplaceIN6quasar14LmeDataFactoryENS_9allocatorIS2_EEEE
N3fst9ImplToFstINS_9AddOnImplINS_8ConstFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEjEENS_9AddOnPairINS_18LabelReachableDataIiEESA_EEEENS_11ExpandedFstIS6_EEEE
NSt3__16__nodeIcEE
NSt3__110shared_ptrINS_13__empty_stateIcEEE27__shared_ptr_default_deleteIS2_S2_EE
NSt3__113__empty_stateIcEE
NSt3__120__l_anchor_multilineIcEE
NSt3__120__r_anchor_multilineIcEE
NSt3__115__word_boundaryIcNS_12regex_traitsIcEEEE
NSt3__111__lookaheadIcNS_12regex_traitsIcEEEE
NSt3__123__match_any_but_newlineIcEE
NSt3__120__match_char_collateIcNS_12regex_traitsIcEEEE
NSt3__118__back_ref_collateIcNS_12regex_traitsIcEEEE
NSt3__128__begin_marked_subexpressionIcEE
NSt3__126__end_marked_subexpressionIcEE
NSt3__16__loopIcEE
NSt3__117__repeat_one_loopIcEE
NSt3__121__empty_non_own_stateIcEE
N3fst13TopOrderQueueIiEE
NSt3__112__deque_baseIiNS_9allocatorIiEEEE
N3fst3FstINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEE
N3fst7FstImplINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEE
N3fst14DeterminizeFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N3fst13StateIteratorINS_14DeterminizeFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE3EEENS_14ToGallicMapperIS5_LS7_3EEEEENS_3FstIS8_EEEE
N3fst13ArcMapFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE3EEENS_14ToGallicMapperIS4_LS6_3EEEEE
N3fst9CacheImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEEEE
N3fst7FstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEEEE
N3fst9ImplToFstINS_22DeterminizeFstImplBaseINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEEEENS_3FstIS8_EEEE
N3fst18DeterminizeFsaImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEENS_19GallicCommonDivisorIiS4_LS6_3ENS_20DefaultCommonDivisorIS4_EEEENS_24DefaultDeterminizeFilterIS7_EENS_28DefaultDeterminizeStateTableIS7_NS_18IntegerFilterStateIaEEEEEE
N3fst22DeterminizeFstImplBaseINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEES6_NS_16FromGallicMapperIS6_LS7_3EEEEENS_3FstIS6_EEEE
N3fst13StateIteratorINS_9ArcMapFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE2EEENS_14ToGallicMapperIS5_LS7_2EEEEEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEES6_NS_16FromGallicMapperIS6_LS7_2EEEEENS_3FstIS6_EEEE
N3fst13StateIteratorINS_9ArcMapFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE4EEENS_14ToGallicMapperIS5_LS7_4EEEEEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEES6_NS_16FromGallicMapperIS6_LS7_4EEEEENS_3FstIS6_EEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEENSt3__19allocatorIS9_EEEEEENS_10MutableFstIS9_EEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEENSt3__19allocatorIS9_EEEEEENS_10MutableFstIS9_EEEE
N3fst11ExpandedFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N3fst3FstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N3fst10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEEE4LinkEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEENS_11VectorStateIS8_NSt3__19allocatorIS8_EEEEEEEE
N3fst22MutableArcIteratorBaseINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEENSt3__19allocatorISB_EEEEEENS_10MutableFstISB_EEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEENSt3__19allocatorISB_EEEEEENS_10MutableFstISB_EEEE
N3fst11ExpandedFstINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEEEE
N3fst3FstINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEEEE
N3fst10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEEEEE4LinkEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEENS_11VectorStateISA_NSt3__19allocatorISA_EEEEEEEE
N3fst22MutableArcIteratorBaseINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEEEE
N3fst19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEENS_12GallicFactorIiS4_LS6_0EEEEE
N3fst9CacheImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N3fst13StateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEENS_12GallicFactorIiS5_LS7_0EEEEEEE
N3fst10MatcherFstINS_8ConstFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEjEENS_21LabelLookAheadMatcherINS_13SortedMatcherIS6_EELj1760ENS_18FastLogAccumulatorIS5_EENS_14LabelReachableIS5_SB_NS_18LabelReachableDataIiEEEEEEXadL_ZN6quasar25olabel_lookahead_fst_typeEEENS_23LabelLookAheadRelabelerIS5_SE_EENS_9AddOnPairISE_SE_EEEE
N3fst17ImplToExpandedFstINS_9AddOnImplINS_8ConstFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEjEENS_9AddOnPairINS_18LabelReachableDataIiEESA_EEEENS_11ExpandedFstIS6_EEEE
N3fst12ConstFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEEjEE
N3fst21LabelLookAheadMatcherINS_13SortedMatcherINS_8ConstFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEjEEEELj1760ENS_18FastLogAccumulatorIS6_EENS_14LabelReachableIS6_SA_NS_18LabelReachableDataIiEEEEEE
N3fst20LookAheadMatcherBaseINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N3fst13SortedMatcherINS_8ConstFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEjEEEE
N3fst10MemoryPoolINS_11ArcIteratorINS_8ConstFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEjEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_11ArcIteratorINS_8ConstFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEjEEEEE4LinkEEE
N3fst9AddOnImplINS_8ConstFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEjEENS_9AddOnPairINS_18LabelReachableDataIiEES9_EEEE
N3fst10ComposeFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_17DefaultCacheStoreIS4_EEEE
N3fst9ImplToFstINS_18ComposeFstImplBaseINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_17DefaultCacheStoreIS5_EEEENS_3FstIS5_EEEE
N3fst18ComposeFstImplBaseINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_17DefaultCacheStoreIS4_EEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_23PushLabelsComposeFilterINS_24PushWeightsComposeFilterINS_22LookAheadComposeFilterINS_21SequenceComposeFilterINS_16LookAheadMatcherINS_3FstIS5_EEEESE_EESE_SE_LNS_9MatchTypeE2EEESE_SE_LSG_2EEESE_SE_LSG_2EEENS_24GenericComposeStateTableIS5_NS_15PairFilterStateINSL_INS_18IntegerFilterStateIaEENS_17WeightFilterStateIS4_EEEENSM_IiEEEENS_24DefaultComposeStateTupleIiSS_EENS_21CompactHashStateTableISU_NS_11ComposeHashISU_EEEEEEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_18MatchComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst9ImplToFstINS_14ReplaceFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_24DefaultReplaceStateTableIS5_lEENS_17DefaultCacheStoreIS5_EEEENS_3FstIS5_EEEE
N5sdapi12SdapiITNImplE
NSt3__120__shared_ptr_emplaceIN6quasar8artifact8ArtifactENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar8artifact13AppLmArtifactENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_pointerIPN6quasar9AppLmDataENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN6quasar9AppLmDataEEE
NSt3__120__shared_ptr_pointerIPN6quasar14CustomPronDataENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN6quasar14CustomPronDataEEE
NSt3__120__shared_ptr_pointerIPN6quasar8artifact13AppLmArtifactENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIN6quasar8artifact13AppLmArtifactEEE
NSt3__120__shared_ptr_pointerIPN5kaldi6quasar8LmHandleENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIN5kaldi6quasar8LmHandleEEE
N6quasar20SyncRecogAudioBufferE
N5kaldi5nnet118GatedRecurrentUnitE
N6quasar19DoNotTranslateBlockE
N6quasar20AppleFileCoordinatorE
N6quasar23AppleLanguageRecognizerE
N5kaldi27OnlineDecodableMatrixScaledE
N5kaldi30OnlineDecodableIdenticalMatrixE
N5kaldi33OnlineDecodableMatrixScaledMappedE
N5kaldi35OnlineDecodableMatrixScaledMappedTmE
N5kaldi24OnlineDecodableNnet1LazyE
NSt3__120__shared_ptr_emplaceIN6quasar21SyncPSRAudioProcessorENS_9allocatorIS2_EEEE
N6quasar22ResultStreamStabilizerE
N6quasar14LmeDataFactoryE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar7LexiconENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar6LmeFstENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar12ConstLexiconENS_9allocatorIS3_EEEE
NSt3__110__function6__funcINS_6__bindIRFbRKN6quasar18LmeDataFactoryBase4WordEiEJRKNS_12placeholders4__phILi1EEERiEEENS_9allocatorISG_EEFbS7_EEE
NSt3__110__function6__baseIFbRKN6quasar18LmeDataFactoryBase4WordEEEE
NSt3__16__bindIRFbRKN6quasar18LmeDataFactoryBase4WordEiEJRKNS_12placeholders4__phILi1EEERiEEE
NSt3__118__weak_result_typeIPFbRKN6quasar18LmeDataFactoryBase4WordEiEEE
NSt3__115binary_functionIRKN6quasar18LmeDataFactoryBase4WordEibEE
N6quasar11PDecOptionsE
N6quasar17TranslatorOptionsE
N6quasar25ConfiguredProcessingBlockINS_17TranslatorOptionsEEE
N6quasar19PDecTranslatorBlockE
N6quasar20PDecEngineBlockMixinE
N6quasar11OptionValueINS_5PTreeEEE
N6quasar11OptionValueIbEE
N6quasar11OptionValueIiEE
N6quasar11OptionValueIdEE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar17TranslationEngineIJNS2_21TranslationBeamSearchINS2_19TorchEncoderDecoderEEENS4_INS2_6EncdecEEEEEENS_9allocatorIS9_EEEE
N5kaldi6quasar21TranslationBeamSearchINS0_6EncdecEEE
NSt3__110shared_ptrIN5kaldi6quasar19TorchEncoderDecoderEE27__shared_ptr_default_deleteIS3_S3_EE
NSt3__120__shared_ptr_pointerIPN5kaldi6quasar6EncdecENS_10shared_ptrIS3_E27__shared_ptr_default_deleteIS3_S3_EENS_9allocatorIS3_EEEE
NSt3__110shared_ptrIN5kaldi6quasar6EncdecEE27__shared_ptr_default_deleteIS3_S3_EE
NSt3__120__shared_ptr_emplaceINS_4pairINS_10shared_ptrIN5kaldi6quasar16ComputeEngineItfEEES6_EENS_9allocatorIS7_EEEE
N3fst9VectorFstINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS5_9allocatorIfEEEEEEEENS_11VectorStateISB_NS7_ISB_EEEEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS7_9allocatorIfEEEEEEEENS9_ISD_EEEEEENS_10MutableFstISD_EEEE
N3fst7FstImplINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS5_9allocatorIfEEEEEEEEEE
N3fst9QueueBaseIiEE
N3fst18ShortestFirstQueueIiNS_18StateWeightCompareIiNS_11NaturalLessINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS6_9allocatorIfEEEEEEEEEELb0EEE
N3fst9VectorFstINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS6_9allocatorIfEEEEEEEEEENS_11VectorStateISD_NS8_ISD_EEEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS8_9allocatorIfEEEEEEEEEENSA_ISF_EEEEEENS_10MutableFstISF_EEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS8_9allocatorIfEEEEEEEEEENSA_ISF_EEEEEENS_10MutableFstISF_EEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS8_9allocatorIfEEEEEEEEEENSA_ISF_EEEEEENS_10MutableFstISF_EEEE
N3fst10MutableFstINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS6_9allocatorIfEEEEEEEEEEEE
N3fst11ExpandedFstINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS6_9allocatorIfEEEEEEEEEEEE
N3fst3FstINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS6_9allocatorIfEEEEEEEEEEEE
N3fst13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS7_9allocatorIfEEEEEEEEEENS9_ISE_EEEEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS7_9allocatorIfEEEEEEEEEENS9_ISE_EEEEEE
N3fst7FstImplINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS6_9allocatorIfEEEEEEEEEEEE
N3fst10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS7_9allocatorIfEEEEEEEEEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS8_9allocatorIfEEEEEEEEEEEEE4LinkEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS7_9allocatorIfEEEEEEEEEENS_11VectorStateISE_NS9_ISE_EEEEEEEE
N3fst22MutableArcIteratorBaseINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS6_9allocatorIfEEEEEEEEEEEE
N3fst15ArcIteratorBaseINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS6_9allocatorIfEEEEEEEEEEEE
N3fst14DeterminizeFstINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS6_9allocatorIfEEEEEEEEEEEE
N3fst9ImplToFstINS_22DeterminizeFstImplBaseINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS7_9allocatorIfEEEEEEEEEEEENS_3FstISE_EEEE
N3fst18DeterminizeFsaImplINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS6_9allocatorIfEEEEEEEEEENS_20DefaultCommonDivisorISB_EENS_24DefaultDeterminizeFilterISD_EENS_28DefaultDeterminizeStateTableISD_NS_18IntegerFilterStateIaEEEEEE
N3fst22DeterminizeFstImplBaseINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS6_9allocatorIfEEEEEEEEEEEE
N3fst9CacheImplINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS6_9allocatorIfEEEEEEEEEEEE
N3fst13CacheBaseImplINS_10CacheStateINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS7_9allocatorIfEEEEEEEEEENS9_ISE_EEEENS_17DefaultCacheStoreISE_EEEE
N3fst13StateIteratorINS_14DeterminizeFstINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS7_9allocatorIfEEEEEEEEEEEEEE
N3fst18CacheStateIteratorINS_14DeterminizeFstINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS7_9allocatorIfEEEEEEEEEEEEEE
N3fst17StateIteratorBaseINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS6_9allocatorIfEEEEEEEEEEEE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar10PhraseBookENS_9allocatorIS3_EEEE
>NSt3__110__function6__funcIZN5kaldi6quasar31SystemSelectionFeatureExtractor15ExtractFeaturesERKNS_6vectorINS5_IfNS_9allocatorIfEEEENS6_IS8_EEEEPS8_E3$_1NS6_ISE_EEFfiEEE
NSt3__110__function6__baseIFfiEEE
ZN5kaldi6quasar31SystemSelectionFeatureExtractor15ExtractFeaturesERKNSt3__16vectorINS3_IfNS2_9allocatorIfEEEENS4_IS6_EEEEPS6_E3$_1
NSt3__110__function6__funcIZN5kaldi6quasar31SystemSelectionFeatureExtractor15ExtractFeaturesERKNS_6vectorINS5_IfNS_9allocatorIfEEEENS6_IS8_EEEEPS8_E3$_2NS6_ISE_EEFfiEEE
ZN5kaldi6quasar31SystemSelectionFeatureExtractor15ExtractFeaturesERKNSt3__16vectorINS3_IfNS2_9allocatorIfEEEENS4_IS6_EEEEPS6_E3$_2
NSt3__110__function6__funcIZN5kaldi6quasar31SystemSelectionFeatureExtractor15ExtractFeaturesERKNS_6vectorINS5_IfNS_9allocatorIfEEEENS6_IS8_EEEEPS8_E3$_3NS6_ISE_EEFfiEEE
ZN5kaldi6quasar31SystemSelectionFeatureExtractor15ExtractFeaturesERKNSt3__16vectorINS3_IfNS2_9allocatorIfEEEENS4_IS6_EEEEPS6_E3$_3
NSt3__110__function6__funcIZN5kaldi6quasar31SystemSelectionFeatureExtractor15ExtractFeaturesERKNS_6vectorINS5_IfNS_9allocatorIfEEEENS6_IS8_EEEEPS8_E3$_4NS6_ISE_EEFfiEEE
ZN5kaldi6quasar31SystemSelectionFeatureExtractor15ExtractFeaturesERKNSt3__16vectorINS3_IfNS2_9allocatorIfEEEENS4_IS6_EEEEPS6_E3$_4
NSt3__110__function6__funcIZN5kaldi6quasar31SystemSelectionFeatureExtractor15ExtractFeaturesERKNS_6vectorINS5_IfNS_9allocatorIfEEEENS6_IS8_EEEEPS8_E3$_5NS6_ISE_EEFfiEEE
ZN5kaldi6quasar31SystemSelectionFeatureExtractor15ExtractFeaturesERKNSt3__16vectorINS3_IfNS2_9allocatorIfEEEENS4_IS6_EEEEPS6_E3$_5
NSt3__110__function6__funcIZN5kaldi6quasar31SystemSelectionFeatureExtractor15ExtractFeaturesERKNS_6vectorINS5_IfNS_9allocatorIfEEEENS6_IS8_EEEEPS8_E3$_6NS6_ISE_EEFfiEEE
ZN5kaldi6quasar31SystemSelectionFeatureExtractor15ExtractFeaturesERKNSt3__16vectorINS3_IfNS2_9allocatorIfEEEENS4_IS6_EEEEPS6_E3$_6
NSt3__110__function6__funcIZN5kaldi6quasar31SystemSelectionFeatureExtractor15ExtractFeaturesERKNS_6vectorINS5_IfNS_9allocatorIfEEEENS6_IS8_EEEEPS8_E3$_7NS6_ISE_EEFfiEEE
ZN5kaldi6quasar31SystemSelectionFeatureExtractor15ExtractFeaturesERKNSt3__16vectorINS3_IfNS2_9allocatorIfEEEENS4_IS6_EEEEPS6_E3$_7
NSt3__110__function6__funcIZN5kaldi6quasar31SystemSelectionFeatureExtractor15ExtractFeaturesERKNS_6vectorINS5_IfNS_9allocatorIfEEEENS6_IS8_EEEEPS8_E3$_8NS6_ISE_EEFfiEEE
ZN5kaldi6quasar31SystemSelectionFeatureExtractor15ExtractFeaturesERKNSt3__16vectorINS3_IfNS2_9allocatorIfEEEENS4_IS6_EEEEPS6_E3$_8
N6quasar18BasicTextSanitizerE
N6quasar13TextSanitizerE
7MEModel
11NgramCountsImE
N6quasar11SyncDecoderE
NSt3__120__shared_ptr_emplaceIN6quasar26KeywordSpottingSyncDecoderENS_9allocatorIS2_EEEE
N6quasar14PDecTranslatorE
8VarNgram
N6quasar33OnlineTransducerBeamSearchDecoderE
N5kaldi8EventMapE
N5kaldi16ConstantEventMapE
N5kaldi13TableEventMapE
N5kaldi13SplitEventMapE
NSt3__120__shared_ptr_emplaceIN13sentencepiece22SentencePieceProcessorENS_9allocatorIS2_EEEE
16SimpleClassNgram
N6quasar23GlobalTranslatorFactoryE
NSt3__120__shared_ptr_emplaceIN6quasar27GlobalPDecTranslatorFactoryENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar29GlobalHotfixTranslatorFactoryENS_9allocatorIS2_EEEE
N6quasar2lm8arpa2fst10kaldi_fork14ArpaLmCompilerE
N6quasar2lm8arpa2fst10kaldi_fork18ArpaLmCompilerImplINS2_12_GLOBAL__N_116OptimizedHistKeyEEE
N6quasar2lm8arpa2fst10kaldi_fork27ArpaLmCompilerImplInterfaceE
N6quasar2lm8arpa2fst10kaldi_fork18ArpaLmCompilerImplINS2_12_GLOBAL__N_114GeneralHistKeyEEE
N6quasar20SimpleNameEnumeratorE
N6quasar8artifact8ArtifactE
N6quasar8artifact13ArchiveReaderE
N6quasar8artifact13ArchiveWriterE
NSt3__110__function6__funcIZN6quasar8artifact8Artifact21openContentForWritingERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEbE3$_0NS8_ISD_EEFbSC_EEE
NSt3__110__function6__baseIFbRKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEEEE
ZN6quasar8artifact8Artifact21openContentForWritingERKNSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEbE3$_0
N6quasar8artifact20ArtifactOutputStreamE
NSt3__120__shared_ptr_emplaceIN6quasar8artifact13ArchiveReaderENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar8artifact25ArtifactInputStreamBufferENS_9allocatorIS3_EEEE
N6quasar8artifact25ArtifactInputStreamBufferE
N6quasar8artifact19ArtifactInputStreamE
NSt3__120__shared_ptr_emplaceIN6quasar8artifact19ArtifactInputStreamENS_9allocatorIS3_EEEE
N3fst11FstRegisterINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N3fst15GenericRegisterINSt3__112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEENS_16FstRegisterEntryINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_11FstRegisterISC_EEEE
NSt3__110__function6__funcIZ420-[_EARFormatter formatWords:unrepairedWordsOut:task:language:preItnLeftContext:separateAutoEndPunctuation:partialResults:timestampOffset:zeroTimestamp:continuousListeningConfig:postItnLeftContext:itnResult:itnOverrides:itnEnablingFlags:recognizeEmoji:leftContextProvidedByClient:preItnRightContext:emojiTokenIndices:persistEmoji:shouldHideTrailingPunctuation:isTrailingPunctuationHidden:isFinal:choiceIdx:itnCompletion:]E3$_0NS_9allocatorIS2_EEFNS_6vectorIN6quasar5TokenENS3_IS7_EEEERKS9_EEE
NSt3__110__function6__baseIFNS_6vectorIN6quasar5TokenENS_9allocatorIS4_EEEERKS7_EEE
Z420-[_EARFormatter formatWords:unrepairedWordsOut:task:language:preItnLeftContext:separateAutoEndPunctuation:partialResults:timestampOffset:zeroTimestamp:continuousListeningConfig:postItnLeftContext:itnResult:itnOverrides:itnEnablingFlags:recognizeEmoji:leftContextProvidedByClient:preItnRightContext:emojiTokenIndices:persistEmoji:shouldHideTrailingPunctuation:isTrailingPunctuationHidden:isFinal:choiceIdx:itnCompletion:]E3$_0
N6quasar21AudioAnalyticsDecoderE
N3fst13SortedMatcherINS_3FstINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEE
N3fst11MatcherBaseINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEE
N3fst10MemoryPoolINS_11ArcIteratorINS_3FstINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_11ArcIteratorINS_3FstINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEEE4LinkEEE
N3fst10ComposeFstINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEENS_17DefaultCacheStoreISA_EEEE
N3fst9ImplToFstINS_18ComposeFstImplBaseINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEENS_17DefaultCacheStoreISB_EEEENS_3FstISB_EEEE
N3fst3FstINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEENS_21SequenceComposeFilterINS_13SortedMatcherINS_3FstISB_EEEESH_EENS_24GenericComposeStateTableISB_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSL_EENS_21CompactHashStateTableISN_NS_11ComposeHashISN_EEEEEEEE
N3fst18ComposeFstImplBaseINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEENS_17DefaultCacheStoreISA_EEEE
N3fst13CacheBaseImplINS_10CacheStateINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEENSt3__19allocatorISB_EEEENS_17DefaultCacheStoreISB_EEEE
N3fst7FstImplINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEENS_21SequenceComposeFilterINS_13SortedMatcherINS_3FstISB_EEEESH_EENS_24GenericComposeStateTableISB_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSL_EENS_21CompactHashStateTableISN_NS_11ComposeHashISN_EEEEEEEE
N3fst10MemoryPoolINS_8DfsStateINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEE4LinkEEE
N3fst13StateIteratorINS_10ComposeFstINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEENS_17DefaultCacheStoreISB_EEEEEE
N3fst18CacheStateIteratorINS_10ComposeFstINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEENS_17DefaultCacheStoreISB_EEEEEE
N3fst17StateIteratorBaseINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEENSt3__19allocatorISC_EEEEEENS_10MutableFstISC_EEEE
N3fst10MutableFstINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEE
N3fst11ExpandedFstINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEE
N3fst10MutableFstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEE
N3fst13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEENSt3__19allocatorIS9_EEEEEE
N3fst7FstImplINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEE
N3fst15ArcIteratorBaseINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEE
N3fst9VectorFstINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEENS_11VectorStateISA_NSt3__19allocatorISA_EEEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEENSt3__19allocatorISC_EEEEEENS_10MutableFstISC_EEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEENSt3__19allocatorISC_EEEEEENS_10MutableFstISC_EEEE
N3fst13VectorFstImplINS_11VectorStateINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEENSt3__19allocatorISB_EEEEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEENSt3__19allocatorISB_EEEEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEENS_11VectorStateISB_NSt3__19allocatorISB_EEEEEEEE
N3fst22MutableArcIteratorBaseINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEE
N3fst15ArcIteratorBaseINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEE
N3fst18ShortestFirstQueueIiNS_18StateWeightCompareIiNS_11NaturalLessINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEELb0EEE
N3fst9VectorFstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEENS_11VectorStateISC_NSt3__19allocatorISC_EEEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEENSt3__19allocatorISE_EEEEEENS_10MutableFstISE_EEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEENSt3__19allocatorISE_EEEEEENS_10MutableFstISE_EEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEENSt3__19allocatorISE_EEEEEENS_10MutableFstISE_EEEE
N3fst10MutableFstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEE
N3fst11ExpandedFstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEE
N3fst3FstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEE
N3fst13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEENSt3__19allocatorISD_EEEEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEENSt3__19allocatorISD_EEEEEE
N3fst7FstImplINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEE
N3fst10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEEE4LinkEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEENS_11VectorStateISD_NSt3__19allocatorISD_EEEEEEEE
N3fst22MutableArcIteratorBaseINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEE
N3fst15ArcIteratorBaseINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEE
N3fst14DeterminizeFstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEE
N3fst9ImplToFstINS_22DeterminizeFstImplBaseINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEENS_3FstISD_EEEE
N3fst18DeterminizeFsaImplINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEENS_20DefaultCommonDivisorISA_EENS_24DefaultDeterminizeFilterISC_EENS_28DefaultDeterminizeStateTableISC_NS_18IntegerFilterStateIaEEEEEE
N3fst22DeterminizeFstImplBaseINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEE
N3fst9CacheImplINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEE
N3fst13CacheBaseImplINS_10CacheStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEENSt3__19allocatorISD_EEEENS_17DefaultCacheStoreISD_EEEE
N3fst13StateIteratorINS_14DeterminizeFstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEEEE
N3fst18CacheStateIteratorINS_14DeterminizeFstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEEEE
N3fst17StateIteratorBaseINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEE
N3fst15ArcIteratorBaseINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEENSt3__19allocatorIS9_EEEEEENS_10MutableFstIS9_EEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEENSt3__19allocatorIS9_EEEEEENS_10MutableFstIS9_EEEE
N3fst3FstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N3fst13VectorFstImplINS_11VectorStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEENSt3__19allocatorIS8_EEEEEE
N3fst7FstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N3fst10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEENS_11VectorStateIS8_NSt3__19allocatorIS8_EEEEEEEE
N3fst9VectorFstINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEENS_11VectorStateIS9_NSt3__19allocatorIS9_EEEEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEENSt3__19allocatorISB_EEEEEENS_10MutableFstISB_EEEE
N3fst10MutableFstINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEEEE
N3fst11ExpandedFstINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEENSt3__19allocatorISA_EEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEEEEE4LinkEEE
N3fst22MutableArcIteratorBaseINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEEEE
N3fst15ArcIteratorBaseINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEEEE
N3fst9ArcMapFstINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE0EEENS_14ToGallicMapperIS4_LS6_0EEEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE0EEENS_14ToGallicMapperIS5_LS7_0EEEEENS_3FstIS8_EEEE
N3fst13ArcMapFstImplINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE0EEENS_14ToGallicMapperIS4_LS6_0EEEEE
N3fst13StateIteratorINS_9ArcMapFstINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE0EEENS_14ToGallicMapperIS5_LS7_0EEEEEEE
N3fst17StateIteratorBaseINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N3fst9ImplToFstINS_19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEENS_12GallicFactorIiS5_LS7_0EEEEENS_3FstIS8_EEEE
N3fst19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEENS_12GallicFactorIiS4_LS6_0EEEEE
N3fst10RandGenFstINS_6ArcTplINS_17TropicalWeightTplIfEEEES4_NS_10ArcSamplerIS4_NS_18UniformArcSelectorIS4_EEEEEE
N3fst9ImplToFstINS_14RandGenFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEES5_NS_10ArcSamplerIS5_NS_18UniformArcSelectorIS5_EEEEEENS_3FstIS5_EEEE
N3fst14RandGenFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEES4_NS_10ArcSamplerIS4_NS_18UniformArcSelectorIS4_EEEEEE
N3fst13StateIteratorINS_10RandGenFstINS_6ArcTplINS_17TropicalWeightTplIfEEEES5_NS_10ArcSamplerIS5_NS_18UniformArcSelectorIS5_EEEEEEEE
N3fst18CacheStateIteratorINS_10RandGenFstINS_6ArcTplINS_17TropicalWeightTplIfEEEES5_NS_10ArcSamplerIS5_NS_18UniformArcSelectorIS5_EEEEEEEE
N6quasar34OnlineLatticeBiglmLmeFasterDecoderE
NSt3__110__function6__funcIZN6quasar34OnlineLatticeBiglmLmeFasterDecoder10finishInitEvE3$_0NS_9allocatorIS4_EEFNS_10shared_ptrIN3fst3FstINS8_6ArcTplINS8_17TropicalWeightTplIfEEEEEEEERKNS_12basic_stringIcNS_11char_traitsIcEENS5_IcEEEEEEE
ZN6quasar34OnlineLatticeBiglmLmeFasterDecoder10finishInitEvE3$_0
NSt3__110__function6__funcIZN6quasar34OnlineLatticeBiglmLmeFasterDecoder10finishInitEvE3$_1NS_9allocatorIS4_EEFNS_10shared_ptrIN5kaldi6quasar17NnlmEvaluatorBaseEEERKNS_12basic_stringIcNS_11char_traitsIcEENS5_IcEEEEEEE
ZN6quasar34OnlineLatticeBiglmLmeFasterDecoder10finishInitEvE3$_1
NSt3__120__shared_ptr_emplaceIN3fst9ArcMapFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEES6_NS1_6quasar23OffsetOutputLabelMapperEEENS_9allocatorIS9_EEEE
N3fst9ArcMapFstINS_6ArcTplINS_17TropicalWeightTplIfEEEES4_NS_6quasar23OffsetOutputLabelMapperEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEES5_NS_6quasar23OffsetOutputLabelMapperEEENS_3FstIS5_EEEE
N3fst13ArcMapFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEES4_NS_6quasar23OffsetOutputLabelMapperEEE
N3fst13StateIteratorINS_9ArcMapFstINS_6ArcTplINS_17TropicalWeightTplIfEEEES5_NS_6quasar23OffsetOutputLabelMapperEEEEE
NSt3__120__shared_ptr_emplaceIN3fst6quasar12MergeTrieFstENS_9allocatorIS3_EEEE
NSt3__110__function6__funcIZN6quasar34OnlineLatticeBiglmLmeFasterDecoder28insertLocationSpecificModelsERKNS_10shared_ptrINS2_18DecoderChainOutputEEERKNS4_INS2_17SpeechRequestDataEEERNS_6vectorIN3fst12FstWithLabelINSE_6ArcTplINSE_17TropicalWeightTplIfEEEEEENS_9allocatorISK_EEEERNSD_IiNSL_IiEEEERNS2_8LocationEE3$_2NSL_ISU_EEFNS4_INSE_3FstISJ_EEEERKSY_EEE
NSt3__110__function6__baseIFNS_10shared_ptrIN3fst3FstINS3_6ArcTplINS3_17TropicalWeightTplIfEEEEEEEERKSA_EEE
ZN6quasar34OnlineLatticeBiglmLmeFasterDecoder28insertLocationSpecificModelsERKNSt3__110shared_ptrINS_18DecoderChainOutputEEERKNS2_INS_17SpeechRequestDataEEERNS1_6vectorIN3fst12FstWithLabelINSC_6ArcTplINSC_17TropicalWeightTplIfEEEEEENS1_9allocatorISI_EEEERNSB_IiNSJ_IiEEEERNS_8LocationEE3$_2
NSt3__110__function6__funcIZN6quasar34OnlineLatticeBiglmLmeFasterDecoder28insertLocationSpecificModelsERKNS_10shared_ptrINS2_18DecoderChainOutputEEERKNS4_INS2_17SpeechRequestDataEEERNS_6vectorIN3fst12FstWithLabelINSE_6ArcTplINSE_17TropicalWeightTplIfEEEEEENS_9allocatorISK_EEEERNSD_IiNSL_IiEEEERNS2_8LocationEE3$_3NSL_ISU_EEFNS4_IN5kaldi6quasar17NnlmEvaluatorBaseEEERKSZ_EEE
NSt3__110__function6__baseIFNS_10shared_ptrIN5kaldi6quasar17NnlmEvaluatorBaseEEERKS6_EEE
ZN6quasar34OnlineLatticeBiglmLmeFasterDecoder28insertLocationSpecificModelsERKNSt3__110shared_ptrINS_18DecoderChainOutputEEERKNS2_INS_17SpeechRequestDataEEERNS1_6vectorIN3fst12FstWithLabelINSC_6ArcTplINSC_17TropicalWeightTplIfEEEEEENS1_9allocatorISI_EEEERNSB_IiNSJ_IiEEEERNS_8LocationEE3$_3
NSt3__110__function6__funcIZN6quasar34OnlineLatticeBiglmLmeFasterDecoder28insertLocationSpecificModelsERKNS_10shared_ptrINS2_18DecoderChainOutputEEERKNS4_INS2_17SpeechRequestDataEEERNS_6vectorIN3fst12FstWithLabelINSE_6ArcTplINSE_17TropicalWeightTplIfEEEEEENS_9allocatorISK_EEEERNSD_IiNSL_IiEEEERNS2_8LocationEE3$_4NSL_ISU_EEFNS4_IN5kaldi6quasar17NnlmEvaluatorBaseEEERKSZ_EEE
ZN6quasar34OnlineLatticeBiglmLmeFasterDecoder28insertLocationSpecificModelsERKNSt3__110shared_ptrINS_18DecoderChainOutputEEERKNS2_INS_17SpeechRequestDataEEERNS1_6vectorIN3fst12FstWithLabelINSC_6ArcTplINSC_17TropicalWeightTplIfEEEEEENS1_9allocatorISI_EEEERNSB_IiNSJ_IiEEEERNS_8LocationEE3$_4
N6quasar25JapaneseDerivedEnumeratorE
N6quasar29OnlineLatticeRescalingDecoderE
N6quasar21PDecForceAlignOptionsE
N6quasar25ConfiguredProcessingBlockINS_21PDecForceAlignOptionsEEE
N6quasar19PDecForceAlignBlockE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar19TorchEncoderDecoderENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar6EncdecENS_9allocatorIS3_EEEE
train
test
external
none
sweep-weights
interpolation
N6quasar16E2EAsrConfidenceE
NSt3__120__shared_ptr_emplaceINS_6vectorINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS5_IS7_EEEENS5_IS9_EEEE
NSt3__120__shared_ptr_emplaceINS_6vectorIN5kaldi6MatrixIfEENS_9allocatorIS4_EEEENS5_IS7_EEEE
NSt3__120__shared_ptr_emplaceINS_6vectorINS1_IfNS_9allocatorIfEEEENS2_IS4_EEEENS2_IS6_EEEE
5N5kaldi6quasar17NnlmEvaluatorBaseE
N6quasar18SeevaGreedyDecoderE
N5kaldi5nnet124MovingAttentionComponentE
N6quasar15MappedPgmBitmapE
NSt3__120__shared_ptr_pointerIPN6quasar15MappedPgmBitmapENS_10shared_ptrIS2_E27__shared_ptr_default_deleteIS2_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrIN6quasar15MappedPgmBitmapEE27__shared_ptr_default_deleteIS2_S2_EE
N6quasar15AcousticLDModelE
N6quasar22AcousticLDModelFactoryE
N6quasar14LDResultStreamE
N6quasar19ContextAwareLDModelE
N6quasar24DummyContextAwareLDModelE
N6quasar26ContextAwareLDModelFactoryE
NSt3__120__shared_ptr_emplaceIKN6quasar10LDFrontendENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar8LDConfigENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIKN6quasar25ContextAwareLDModelConfigENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar14LDRequestStateENS_9allocatorIS2_EEEE
NSt3__110__function6__funcIZNK6quasar16LanguageDetector21processAcousticResultERNS2_14LDRequestStateERNS3_23WrappedLDAcousticResultEE3$_2NS_9allocatorIS8_EEFNS_12basic_stringIcNS_11char_traitsIcEENS9_IcEEEERKNS2_17language_detector6LocaleEEEE
NSt3__110__function6__baseIFNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEERKN6quasar17language_detector6LocaleEEEE
ZNK6quasar16LanguageDetector21processAcousticResultERNS_14LDRequestStateERNS0_23WrappedLDAcousticResultEE3$_2
N6quasar30OnlineLatticeConfidenceDecoderE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar8WordConfENS_9allocatorIS3_EEEE
N6quasar12IModelLoaderE
N6quasar11ModelLoaderE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar15NnlmDecoderWordENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar14CEInferenceNetENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar15FofeLmEvaluatorENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar14RnnlmEvaluatorENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar14DnnlmEvaluatorENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi15TransitionModelENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar11ModelLoader20EmbeddedMlockContextENS_9allocatorIS3_EEEE
N5kaldi6quasar20SeevaBeamSearchBigLmE
N5kaldi6quasar16CoreMLTensorDataE
N5kaldi6quasar19CoreMLNetworkConfigE
N5kaldi6quasar17CoreMLNetworkPlanE
N5kaldi5nnet124Convolutional2DComponentINS_12CuMatrixBaseIfEEEE
N5kaldi5nnet124Convolutional2DComponentINS_15QuantizedMatrixIaEEEE
N5kaldi11CuSubMatrixIfEE
N5kaldi6quasar19TorchEncoderDecoder14AttentionModelE
N5kaldi6quasar19TorchEncoderDecoderE
NSt3__120__shared_ptr_pointerIPN5kaldi5nnet14NnetENS_10shared_ptrIS3_E27__shared_ptr_default_deleteIS3_S3_EENS_9allocatorIS3_EEEE
NSt3__110shared_ptrIN5kaldi5nnet14NnetEE27__shared_ptr_default_deleteIS3_S3_EE
N5kaldi6quasar20SeevaStreamInferenceE
N5kaldi6quasar26SeevaStreamInferenceConfigE
16TaggedNgramStats
N6quasar19StreamingConfidenceE
N6quasar21LRStreamingConfidenceE
@N6quasar16PhonetisaurusG2PE
NSt3__120__shared_ptr_emplaceI13PhonetisaurusNS_9allocatorIS1_EEEE
11TaggedNgram
@@N5kaldi5nnet118NormalizeComponentE
N6quasar7PDecG2PE
N5kaldi6quasar21TranslationBeamSearchINS0_19TorchEncoderDecoderEEE
N5kaldi12CuVectorBaseIfEE
NSt3__120__shared_ptr_pointerIPN5kaldi6quasar19TorchEncoderDecoderENS_10shared_ptrIS3_E27__shared_ptr_default_deleteIS3_S3_EENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar15PhonesetMappingENS_9allocatorIS2_EEEE
N5kaldi6quasar12ESTensorDataE
N5kaldi6quasar15ESNetworkConfigE
N5kaldi6quasar13ESNetworkPlanE
N5kaldi6quasar15FofeLmEvaluatorE
N6quasar21PdecPhraseBookOptionsE
N6quasar25ConfiguredProcessingBlockINS_21PdecPhraseBookOptionsEEE
N6quasar19PDecPhraseBookBlockE
22EARContextAwareLDModel
29EARContextAwareLDModelFactory
25EARAcousticLDModelFactory
NSt3__120__shared_ptr_emplaceI21CoreMLAcousticLDModelNS_9allocatorIS1_EEEE
21CoreMLAcousticLDModel
NSt3__120__shared_ptr_emplaceIN6quasar9LDContextENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceI17EARLDResultStreamNS_9allocatorIS1_EEEE
17EARLDResultStream
NSt3__120__shared_ptr_emplaceIKN6quasar9LDContextENS_9allocatorIS3_EEEE
N6quasar25ConfiguredProcessingBlockINS_16TokenizerOptionsEEE
N6quasar14TokenizerBlockE
N6quasar16TokenizerOptionsE
N6quasar31ConfusionNetworkCombinerDecoderE
NSt3__120__shared_ptr_emplaceINS_6vectorINS1_INS1_IN6quasar5TokenENS_9allocatorIS3_EEEENS4_IS6_EEEENS4_IS8_EEEENS4_ISA_EEEE
N6quasar26KeywordSpottingSyncDecoderE
NSt3__113basic_fstreamIcNS_11char_traitsIcEEEE
NSt3__110shared_ptrIN3fst11SymbolTableEE27__shared_ptr_default_deleteIS2_S2_EE
?9SkipNgram
8@N6quasar6LmDataE
N6quasar2lm6StreamIPNS0_19TokenStringAndCountEEE
plain-text
ngram-counts
phrase-counts
template-grammar
N6quasar10filesystem4PathE
NSt3__110__function6__funcIZNK6quasar6LmData9serializeENS3_11DataSetTypeENS_10unique_ptrINS_13basic_ostreamIcNS_11char_traitsIcEEEENS_14default_deleteIS9_EEEEE3$_1NS_9allocatorISD_EEFvRKNS2_2lm19TokenStringAndCountEEEE
NSt3__110__function6__baseIFvRKN6quasar2lm19TokenStringAndCountEEEE
ZNK6quasar6LmData9serializeENS0_11DataSetTypeENSt3__110unique_ptrINS2_13basic_ostreamIcNS2_11char_traitsIcEEEENS2_14default_deleteIS7_EEEEE3$_1
NSt3__110__function6__funcIZNK6quasar6LmData9serializeENS3_11DataSetTypeENS_10unique_ptrINS_13basic_ostreamIcNS_11char_traitsIcEEEENS_14default_deleteIS9_EEEEE3$_2NS_9allocatorISD_EEFvRKNS2_2lm19TokenStringAndCountEEEE
ZNK6quasar6LmData9serializeENS0_11DataSetTypeENSt3__110unique_ptrINS2_13basic_ostreamIcNS2_11char_traitsIcEEEENS2_14default_deleteIS7_EEEEE3$_2
NSt3__110__function6__funcIZNK6quasar6LmData9serializeENS3_11DataSetTypeENS_10unique_ptrINS_13basic_ostreamIcNS_11char_traitsIcEEEENS_14default_deleteIS9_EEEEE3$_3NS_9allocatorISD_EEFvRKNS2_2lm19TokenStringAndCountEEEE
ZNK6quasar6LmData9serializeENS0_11DataSetTypeENSt3__110unique_ptrINS2_13basic_ostreamIcNS2_11char_traitsIcEEEENS2_14default_deleteIS7_EEEEE3$_3
N5kaldi13InputImplBaseE
N5kaldi13FileInputImplE
N5kaldi17StandardInputImplE
N5kaldi13PipeInputImplE
N5kaldi19OffsetFileInputImplE
N5kaldi13basic_pipebufIcEE
N6quasar24SystemCombinationDecoderE
NSt3__123enable_shared_from_thisIN6quasar24SystemCombinationDecoderEEE
NSt3__120__shared_ptr_emplaceINS_6vectorIfNS_9allocatorIfEEEENS2_IS4_EEEE
N6quasar24OfflineRecogResultStreamE
8LMClient
N5sdapi8SdapiG2PE
NSt3__120__shared_ptr_emplaceIN5sdapi18SimpleStringMapperENS_9allocatorIS2_EEEE
N3fst18ShortestFirstQueueIiNS_18StateWeightCompareIiNS_11NaturalLessINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEELb0EEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEENSt3__19allocatorISA_EEEEEENS_10MutableFstISA_EEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEENSt3__19allocatorISA_EEEEEENS_10MutableFstISA_EEEE
N3fst11ExpandedFstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEE
N3fst3FstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEE
N3fst10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEEE4LinkEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEENS_11VectorStateIS9_NSt3__19allocatorIS9_EEEEEEEE
N3fst22MutableArcIteratorBaseINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEE
N6quasar17SeevaBatchDecoderE
N5kaldi6quasar25SeevaInferenceTensorNamesE
NSt3__120__shared_ptr_emplaceIN6quasar17PMRegexEnumeratorENS_9allocatorIS2_EEEE
N6quasar19ErrorBlamingDecoderE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar10LexiconFstENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar14RegionalLmPlugINS_10shared_ptrIN3fst3FstINS4_6ArcTplINS4_17TropicalWeightTplIfEEEEEEEEEENS_9allocatorISC_EEEE
NSt3__110__function6__funcIZN6quasar19ErrorBlamingDecoder10finishInitEvE3$_0NS_9allocatorIS4_EEFNS_10shared_ptrIN3fst3FstINS8_6ArcTplINS8_17TropicalWeightTplIfEEEEEEEERKNS_12basic_stringIcNS_11char_traitsIcEENS5_IcEEEEEEE
ZN6quasar19ErrorBlamingDecoder10finishInitEvE3$_0
NSt3__110__function6__funcIZN6quasar19ErrorBlamingDecoder10finishInitEvE3$_1NS_9allocatorIS4_EEFNS_10shared_ptrIN5kaldi6quasar17NnlmEvaluatorBaseEEERKNS_12basic_stringIcNS_11char_traitsIcEENS5_IcEEEEEEE
ZN6quasar19ErrorBlamingDecoder10finishInitEvE3$_1
NSt3__110__function6__funcIZN6quasar19ErrorBlamingDecoder7runImplERNS2_15DecoderPassDataERKNS_10shared_ptrINS2_18DecoderChainOutputEEERKNS6_INS2_17SpeechRequestDataEEERKNS_8functionIFbvEEEbE3$_2NS_9allocatorISK_EEFNS6_IN3fst3FstINSN_6ArcTplINSN_17TropicalWeightTplIfEEEEEEEERKSU_EEE
ZN6quasar19ErrorBlamingDecoder7runImplERNS_15DecoderPassDataERKNSt3__110shared_ptrINS_18DecoderChainOutputEEERKNS4_INS_17SpeechRequestDataEEERKNS3_8functionIFbvEEEbE3$_2
NSt3__110__function6__funcIZN6quasar19ErrorBlamingDecoder7runImplERNS2_15DecoderPassDataERKNS_10shared_ptrINS2_18DecoderChainOutputEEERKNS6_INS2_17SpeechRequestDataEEERKNS_8functionIFbvEEEbE3$_3NS_9allocatorISK_EEFNS6_IN5kaldi6quasar17NnlmEvaluatorBaseEEERKSQ_EEE
ZN6quasar19ErrorBlamingDecoder7runImplERNS_15DecoderPassDataERKNSt3__110shared_ptrINS_18DecoderChainOutputEEERKNS4_INS_17SpeechRequestDataEEERKNS3_8functionIFbvEEEbE3$_3
NSt3__120__shared_ptr_emplaceIN3fst13InterpArcInfoENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi21TrainingGraphCompilerENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN3fst9VectorFstINS1_6ArcTplINS1_23CompactLatticeWeightTplINS1_16LatticeWeightTplIfEEiEEEENS1_11VectorStateIS8_NS_9allocatorIS8_EEEEEENSA_ISD_EEEE
N6quasar17FstTokenTransformE
N6quasar14TokenTransformIN3fst9VectorFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEENS1_11VectorStateIS6_NSt3__19allocatorIS6_EEEEEEEE
N6quasar24ComposeFstTokenTransformE
N6quasar34SpaceApplyDefaultFstTokenTransformE
N6quasar39RewriteApplyCapitalizeFstTokenTransformE
N6quasar36RewriteApplyDefaultFstTokenTransformE
NSt3__120__shared_ptr_emplaceIN3fst14StringCompilerINS1_6ArcTplINS1_17TropicalWeightTplIfEEEEEENS_9allocatorIS7_EEEE
N3fst9ArcMapFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE3EEENS_14ToGallicMapperIS4_LS6_3EEEEE
N3fst3FstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEEEE
N3fst13CacheBaseImplINS_10CacheStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEENSt3__19allocatorIS8_EEEENS_17DefaultCacheStoreIS8_EEEE
N3fst10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEEEEE4LinkEEE
N3fst13StateIteratorINS_9ArcMapFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE3EEENS_14ToGallicMapperIS5_LS7_3EEEEEEE
N3fst17StateIteratorBaseINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEEEE
N3fst14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEEEE
N6quasar18OnlineSeevaDecoderE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEE4LinkEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEENSt3__19allocatorIS8_EEEEEENS_10MutableFstIS8_EEEE
N3fst17StateIteratorBaseINS_6ArcTplINS_16LatticeWeightTplIfEEEEEE
N3fst13SortedMatcherINS_3FstINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEE
N3fst11MatcherBaseINS_6ArcTplINS_16LatticeWeightTplIfEEEEEE
10ClassNgram
N5srilm10StringIterE
10NgramStats
8Discount
5Debug
13ConstDiscount
9AddSmooth
N6quasar7FeatureE
N6quasar17IntToFloatFeatureE
N6quasar19SamplingRateFeatureE
N6quasar15LocationFeatureE
N6quasar14OnlineAppendFeE
NSt3__120__shared_ptr_emplaceIN6quasar19SamplingRateFeatureENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar15LocationFeatureENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi17OnlineAppendInputENS_9allocatorIS2_EEEE
N6quasar22SimpleTokenizerOptionsE
N6quasar25ConfiguredProcessingBlockINS_22SimpleTokenizerOptionsEEE
N6quasar20SimpleTokenizerBlockE
NSt3__118codecvt_utf8_utf16IwLm1114111ELNS_12codecvt_modeE0EEE
NSt3__111__end_stateIwEE
NSt3__16__nodeIwEE
NSt3__120__shared_ptr_pointerIPNS_13__empty_stateIwEENS_10shared_ptrIS2_E27__shared_ptr_default_deleteIS2_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrINS_13__empty_stateIwEEE27__shared_ptr_default_deleteIS2_S2_EE
NSt3__113__empty_stateIwEE
NSt3__116__owns_one_stateIwEE
NSt3__115__has_one_stateIwEE
NSt3__120__l_anchor_multilineIwEE
NSt3__120__r_anchor_multilineIwEE
NSt3__115__word_boundaryIwNS_12regex_traitsIwEEEE
NSt3__111__lookaheadIwNS_12regex_traitsIwEEEE
NSt3__123__match_any_but_newlineIwEE
NSt3__118__match_char_icaseIwNS_12regex_traitsIwEEEE
NSt3__120__match_char_collateIwNS_12regex_traitsIwEEEE
NSt3__112__match_charIwEE
NSt3__116__back_ref_icaseIwNS_12regex_traitsIwEEEE
NSt3__118__back_ref_collateIwNS_12regex_traitsIwEEEE
NSt3__110__back_refIwEE
NSt3__120__bracket_expressionIwNS_12regex_traitsIwEEEE
NSt3__128__begin_marked_subexpressionIwEE
NSt3__126__end_marked_subexpressionIwEE
NSt3__16__loopIwEE
NSt3__117__owns_two_statesIwEE
NSt3__117__repeat_one_loopIwEE
NSt3__111__alternateIwEE
NSt3__121__empty_non_own_stateIwEE
NSt3__111__match_anyIwEE
N6quasar11RecogResultE
N6quasar21RecogResultStreamBaseE
N6quasar17PMRegexEnumeratorE
N6quasar9SanitizerE
N6quasar27OnlineAudioAnalyticsDecoderE
12NgramCountLM
N5kaldi20OnlineAudioSourceItfE
N5kaldi6quasar12ErrorProfileE
N6quasar16HotfixTranslatorE
NSt3__120__shared_ptr_pointerIP5VocabNS_14default_deleteIS1_EENS_9allocatorIS1_EEEE
NSt3__114default_deleteI5VocabEE
N6quasar29GlobalHotfixTranslatorFactoryE
NSt3__120__shared_ptr_emplaceIN6quasar16HotfixTranslatorENS_9allocatorIS2_EEEE
N6quasar9RegexStepE
N6quasar11ReplaceStepE
N6quasar15WholeStringStepE
N6quasar9SplitStepE
NSt3__120__shared_ptr_emplaceIN6quasar11ReplaceStep9RegexRuleENS_9allocatorIS3_EEEE
N6quasar21GenderVerifierOptionsE
N6quasar25ConfiguredProcessingBlockINS_21GenderVerifierOptionsEEE
N6quasar19GenderVerifierBlockE
N6quasar15FileCoordinatorE
N6quasar18LanguageRecognizerE
N6quasar22OnlineSeevaStepDecoderE
N6quasar17TranslatorFactoryE
NSt3__120__shared_ptr_emplaceIN6quasar17TranslatorFactoryENS_9allocatorIS2_EEEE
N3fst13VectorFstImplINS_11VectorStateINS_6ArcTplINS_12LogWeightTplIfEEEENSt3__19allocatorIS5_EEEEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_6ArcTplINS_12LogWeightTplIfEEEENSt3__19allocatorIS5_EEEEEE
N3fst7FstImplINS_6ArcTplINS_12LogWeightTplIfEEEEEE
N3fst14DeterminizeFstINS_6ArcTplINS_12LogWeightTplIfEEEEEE
N3fst9ImplToFstINS_22DeterminizeFstImplBaseINS_6ArcTplINS_12LogWeightTplIfEEEEEENS_3FstIS5_EEEE
N3fst18DeterminizeFsaImplINS_6ArcTplINS_12LogWeightTplIfEEEENS_20DefaultCommonDivisorIS3_EENS_24DefaultDeterminizeFilterIS4_EENS_28DefaultDeterminizeStateTableIS4_NS_18IntegerFilterStateIaEEEEEE
N3fst22DeterminizeFstImplBaseINS_6ArcTplINS_12LogWeightTplIfEEEEEE
N3fst9CacheImplINS_6ArcTplINS_12LogWeightTplIfEEEEEE
N3fst13StateIteratorINS_14DeterminizeFstINS_6ArcTplINS_12LogWeightTplIfEEEEEEEE
N3fst18CacheStateIteratorINS_14DeterminizeFstINS_6ArcTplINS_12LogWeightTplIfEEEEEEEE
N3fst18DeterminizeFstImplINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3ENS_20DefaultCommonDivisorIS3_EENS_24DefaultDeterminizeFilterIS4_EENS_28DefaultDeterminizeStateTableIS4_NS_18IntegerFilterStateIaEEEEEE
N3fst9ArcMapFstINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE3EEENS_14ToGallicMapperIS4_LS6_3EEEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE3EEENS_14ToGallicMapperIS5_LS7_3EEEEENS_3FstIS8_EEEE
N3fst3FstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEEEE
N3fst13ArcMapFstImplINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE3EEENS_14ToGallicMapperIS4_LS6_3EEEEE
N3fst9CacheImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEEEE
N3fst13CacheBaseImplINS_10CacheStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEENSt3__19allocatorIS8_EEEENS_17DefaultCacheStoreIS8_EEEE
N3fst7FstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEEEE
N3fst10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEEEEE4LinkEEE
N3fst13StateIteratorINS_9ArcMapFstINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE3EEENS_14ToGallicMapperIS5_LS7_3EEEEEEE
N3fst17StateIteratorBaseINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEEEE
N3fst14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEEEE
N3fst9ImplToFstINS_22DeterminizeFstImplBaseINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEEEENS_3FstIS8_EEEE
N3fst18DeterminizeFsaImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEENS_19GallicCommonDivisorIiS4_LS6_3ENS_20DefaultCommonDivisorIS4_EEEENS_24DefaultDeterminizeFilterIS7_EENS_28DefaultDeterminizeStateTableIS7_NS_18IntegerFilterStateIaEEEEEE
N3fst22DeterminizeFstImplBaseINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEEEE
N3fst13StateIteratorINS_14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEEEEEE
N3fst18CacheStateIteratorINS_14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEEEEEE
N3fst15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEENS_12GallicFactorIiS4_LS6_3EEEEE
N3fst9ImplToFstINS_19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEENS_12GallicFactorIiS5_LS7_3EEEEENS_3FstIS8_EEEE
N3fst19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEENS_12GallicFactorIiS4_LS6_3EEEEE
N3fst13StateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEENS_12GallicFactorIiS5_LS7_3EEEEEEE
N3fst18CacheStateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEENS_12GallicFactorIiS5_LS7_3EEEEEEE
N3fst9ArcMapFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEES5_NS_16FromGallicMapperIS5_LS6_3EEEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEES6_NS_16FromGallicMapperIS6_LS7_3EEEEENS_3FstIS6_EEEE
N3fst13ArcMapFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEES5_NS_16FromGallicMapperIS5_LS6_3EEEEE
N3fst13StateIteratorINS_9ArcMapFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEES6_NS_16FromGallicMapperIS6_LS7_3EEEEEEE
N3fst18DeterminizeFstImplINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2ENS_20DefaultCommonDivisorIS3_EENS_24DefaultDeterminizeFilterIS4_EENS_28DefaultDeterminizeStateTableIS4_NS_18IntegerFilterStateIaEEEEEE
N3fst9ArcMapFstINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE2EEENS_14ToGallicMapperIS4_LS6_2EEEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE2EEENS_14ToGallicMapperIS5_LS7_2EEEEENS_3FstIS8_EEEE
N3fst3FstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEEEE
N3fst13ArcMapFstImplINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE2EEENS_14ToGallicMapperIS4_LS6_2EEEEE
N3fst9CacheImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEEEE
N3fst13CacheBaseImplINS_10CacheStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEENSt3__19allocatorIS8_EEEENS_17DefaultCacheStoreIS8_EEEE
N3fst7FstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEEEE
N3fst10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEEEEE4LinkEEE
N3fst13StateIteratorINS_9ArcMapFstINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE2EEENS_14ToGallicMapperIS5_LS7_2EEEEEEE
N3fst17StateIteratorBaseINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEEEE
N3fst14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEEEE
N3fst9ImplToFstINS_22DeterminizeFstImplBaseINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEEEENS_3FstIS8_EEEE
N3fst18DeterminizeFsaImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEENS_19GallicCommonDivisorIiS4_LS6_2ENS_20DefaultCommonDivisorIS4_EEEENS_24DefaultDeterminizeFilterIS7_EENS_28DefaultDeterminizeStateTableIS7_NS_18IntegerFilterStateIaEEEEEE
N3fst22DeterminizeFstImplBaseINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEEEE
N3fst13StateIteratorINS_14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEEEEEE
N3fst18CacheStateIteratorINS_14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEEEEEE
N3fst15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEENS_12GallicFactorIiS4_LS6_2EEEEE
N3fst9ImplToFstINS_19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEENS_12GallicFactorIiS5_LS7_2EEEEENS_3FstIS8_EEEE
N3fst19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEENS_12GallicFactorIiS4_LS6_2EEEEE
N3fst13StateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEENS_12GallicFactorIiS5_LS7_2EEEEEEE
N3fst18CacheStateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEENS_12GallicFactorIiS5_LS7_2EEEEEEE
N3fst9ArcMapFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEES5_NS_16FromGallicMapperIS5_LS6_2EEEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEES6_NS_16FromGallicMapperIS6_LS7_2EEEEENS_3FstIS6_EEEE
N3fst13ArcMapFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEES5_NS_16FromGallicMapperIS5_LS6_2EEEEE
N3fst13StateIteratorINS_9ArcMapFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEES6_NS_16FromGallicMapperIS6_LS7_2EEEEEEE
N3fst18DeterminizeFstImplINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4ENS_20DefaultCommonDivisorIS3_EENS_24DefaultDeterminizeFilterIS4_EENS_28DefaultDeterminizeStateTableIS4_NS_18IntegerFilterStateIaEEEEEE
N3fst9ArcMapFstINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE4EEENS_14ToGallicMapperIS4_LS6_4EEEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE4EEENS_14ToGallicMapperIS5_LS7_4EEEEENS_3FstIS8_EEEE
N3fst3FstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEEEE
N3fst13ArcMapFstImplINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE4EEENS_14ToGallicMapperIS4_LS6_4EEEEE
N3fst9CacheImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEEEE
N3fst13CacheBaseImplINS_10CacheStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEENSt3__19allocatorIS8_EEEENS_17DefaultCacheStoreIS8_EEEE
N3fst7FstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEEEE
N3fst10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEEEEE4LinkEEE
N3fst13StateIteratorINS_9ArcMapFstINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE4EEENS_14ToGallicMapperIS5_LS7_4EEEEEEE
N3fst17StateIteratorBaseINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEEEE
N3fst14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEEEE
N3fst9ImplToFstINS_22DeterminizeFstImplBaseINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEEEENS_3FstIS8_EEEE
N3fst18DeterminizeFsaImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEENS_19GallicCommonDivisorIiS4_LS6_4ENS_20DefaultCommonDivisorIS4_EEEENS_24DefaultDeterminizeFilterIS7_EENS_28DefaultDeterminizeStateTableIS7_NS_18IntegerFilterStateIaEEEEEE
N3fst22DeterminizeFstImplBaseINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEEEE
N3fst13StateIteratorINS_14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEEEEEE
N3fst18CacheStateIteratorINS_14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEEEEEE
N3fst15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEENS_12GallicFactorIiS4_LS6_4EEEEE
N3fst9ImplToFstINS_19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEENS_12GallicFactorIiS5_LS7_4EEEEENS_3FstIS8_EEEE
N3fst19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEENS_12GallicFactorIiS4_LS6_4EEEEE
N3fst13StateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEENS_12GallicFactorIiS5_LS7_4EEEEEEE
N3fst18CacheStateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEENS_12GallicFactorIiS5_LS7_4EEEEEEE
N3fst9ArcMapFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEES5_NS_16FromGallicMapperIS5_LS6_4EEEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEES6_NS_16FromGallicMapperIS6_LS7_4EEEEENS_3FstIS6_EEEE
N3fst13ArcMapFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEES5_NS_16FromGallicMapperIS5_LS6_4EEEEE
N3fst13StateIteratorINS_9ArcMapFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEES6_NS_16FromGallicMapperIS6_LS7_4EEEEEEE
N3fst9VectorFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEENS_11VectorStateIS7_NSt3__19allocatorIS7_EEEEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEENSt3__19allocatorIS9_EEEEEENS_10MutableFstIS9_EEEE
N3fst10MutableFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N3fst11ExpandedFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEENSt3__19allocatorIS8_EEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEEE4LinkEEE
N3fst22MutableArcIteratorBaseINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N3fst15ArcIteratorBaseINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEENSt3__19allocatorISB_EEEEEENS_10MutableFstISB_EEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEENSt3__19allocatorISB_EEEEEENS_10MutableFstISB_EEEE
N3fst3FstINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEEEE
N3fst13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEENSt3__19allocatorISA_EEEEEE
N3fst7FstImplINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEEEE
N3fst10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEEEEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEENS_11VectorStateISA_NSt3__19allocatorISA_EEEEEEEE
N3fst15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEENS_12GallicFactorIiS4_LS6_0EEEEE
N3fst9CacheImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N3fst13CacheBaseImplINS_10CacheStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEENSt3__19allocatorIS8_EEEENS_17DefaultCacheStoreIS8_EEEE
N3fst13StateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEENS_12GallicFactorIiS5_LS7_0EEEEEEE
N3fst18CacheStateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEENS_12GallicFactorIiS5_LS7_0EEEEEEE
N6quasar16CommandTransformE
N6quasar23AllCapsCommandTransformE
N6quasar25AllCapsOnCommandTransformE
N6quasar19CapCommandTransformE
N6quasar22CapsOnCommandTransformE
N6quasar23CapsOffCommandTransformE
N6quasar22NoCapsCommandTransformE
N6quasar24NoCapsOnCommandTransformE
N6quasar23NoSpaceCommandTransformE
N6quasar25NoSpaceOnCommandTransformE
N6quasar26NoSpaceOffCommandTransformE
N6quasar23NewLineCommandTransformE
N6quasar28NewParagraphCommandTransformE
N6quasar31PeriodParagraphCommandTransformE
N6quasar22TabKeyCommandTransformE
N6quasar28NoBreakSpaceCommandTransformE
N6quasar24SpaceBarCommandTransformE
N6quasar25BackslashCommandTransformE
N6quasar26AllCapsOffCommandTransformE
N6quasar25NoCapsOffCommandTransformE
NSt3__120__shared_ptr_emplaceIN6quasar23AllCapsCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar25AllCapsOnCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar26AllCapsOffCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar19CapCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar22CapsOnCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar23CapsOffCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar22NoCapsCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar24NoCapsOnCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar25NoCapsOffCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar23NoSpaceCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar25NoSpaceOnCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar26NoSpaceOffCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar23NewLineCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar28NewParagraphCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar31PeriodParagraphCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar22TabKeyCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar28NoBreakSpaceCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar24SpaceBarCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar25BackslashCommandTransformENS_9allocatorIS2_EEEE
N5kaldi5nnet126SimplerSimpleRecurrentUnitE
N6marisa9ExceptionE
We love Marisa.
N13sentencepiece3bpe5ModelE
N13sentencepiece5model8FreeListIZNKS_3bpe5Model12SampleEncodeEN4absl11string_viewEfE10SymbolPairEE
NSt3__110__function6__funcIZNK13sentencepiece3bpe5Model12SampleEncodeEN4absl11string_viewEfE3$_2NS_9allocatorIS7_EEFvS6_PNS_6vectorINS_4pairIS6_iEENS8_ISC_EEEEEEE
NSt3__110__function6__baseIFvN4absl11string_viewEPNS_6vectorINS_4pairIS3_iEENS_9allocatorIS6_EEEEEEE
ZNK13sentencepiece3bpe5Model12SampleEncodeEN4absl11string_viewEfE3$_2
N13sentencepiece31SentencePieceText_SentencePieceE
N13sentencepiece17SentencePieceTextE
N13sentencepiece22NBestSentencePieceTextE
N6google8protobuf8internal16InternalMetadata9ContainerINSt3__112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEEEE
N6google8protobuf8internal16InternalMetadata13ContainerBaseE
N13sentencepiece11TrainerSpecE
N13sentencepiece14NormalizerSpecE
N13sentencepiece19SelfTestData_SampleE
N13sentencepiece12SelfTestDataE
N13sentencepiece24ModelProto_SentencePieceE
N13sentencepiece10ModelProtoE
N13sentencepiece9character5ModelE
N13sentencepiece10filesystem17PosixReadableFileE
N13sentencepiece10filesystem12ReadableFileE
N13sentencepiece14ModelInterfaceE
N13sentencepiece10normalizer10NormalizerE
N5Darts15DoubleArrayImplIvvivEE
N5Darts7Details9ExceptionE
N13sentencepiece22SentencePieceProcessorE
@N13sentencepiece7unigram5ModelE
N13sentencepiece7unigram7LatticeE
N13sentencepiece5model8FreeListINS_7unigram7Lattice4NodeEEE
N13sentencepiece5model8FreeListIZNS_7unigram7Lattice5NBestEmbfE10HypothesisEE
N13sentencepiece4word5ModelE
N6google8protobuf14FatalExceptionE
N6google8protobuf8internal15ExtensionFinderE
N6google8protobuf8internal24GeneratedExtensionFinderE
N6google8protobuf8internal12ExtensionSet8KeyValueE
N6google8protobuf13RepeatedFieldIiEE
N6google8protobuf13RepeatedFieldIxEE
N6google8protobuf13RepeatedFieldIjEE
N6google8protobuf13RepeatedFieldIyEE
N6google8protobuf13RepeatedFieldIfEE
N6google8protobuf13RepeatedFieldIdEE
N6google8protobuf13RepeatedFieldIbEE
N6google8protobuf16RepeatedPtrFieldINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEEE
N6google8protobuf8internal20RepeatedPtrFieldBaseE
N6google8protobuf16RepeatedPtrFieldINS0_11MessageLiteEEE
NSt3__13mapIiN6google8protobuf8internal12ExtensionSet9ExtensionENS_4lessIiEENS_9allocatorINS_4pairIKiS5_EEEEEE
N6google8protobuf11MessageLiteE
NSt3__112basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEE
Loading configuration from: %@
Phonetic-match building is not supported
Internal unknown exception
Internal C++ exception: %s
Cannot write profile: path is empty
Cannot write profile: path points to a directory
Persisting speech profile to path=%{private}@ failed with error=%{public}@ protectionClass=%ld coordinated=%d
Persisted speech profile to path=%{private}@ protectionClass=%ld coordinated=%d
Reading user profile: path %{private}@
Failed to read profile: stream failure
Successfully read Quasar blob profile
Failed to read Quasar blob profile: corrupt data or plist profile
Failed to read plist profile: nil data
Failed to read plist profile: nil or bad dict dict
Failed to read plist profile: nil profile
Read stream of %lu bytes
Successfully read plist profile
Failed to read plist profile: corrupt data
Failed to read profile: Internal unknown exception
Failed to read profile: Internal C++ exception: %s
Size mismatch. concatNbest would throw. Logging data loss.
Voice commands enabled without active set; using bundled assets.
Audio buffer has been deallocated; not restarting recognition
Result stream wrapper has been deallocated; not restarting recognition
Result stream wrapper has been deallocated
Error file sent for compilation does not exist. Not compiling.
Error determining compilation status: %@
Attempting to compile ANE model: %@
Found an error: %@
Compilation completed.
Skipping model that's already compiled: %@
Unexpected exception while compiling recognizer models with configuration path: %@
Exception (...): %s
Error file sent for purge does not exist. Not purging.
Attempting to purge ANE model: %@
Purge completed.
Unexpected exception while purging compiled recognizer models with configuration path: %@
Got interrupt signal, going to interrupt training if training is enabled and still running.
Unexpected exception while initializing EARSpeechModelInfo from configuration file at %@
Recognition failure in execution %{public}@
Starting to initialize model, fileName=%@
Finished initializing model, fileName=%@
detectUtterances %d concatenateUtterances %d allowUtteranceDelay %d formatAcrossUtterances %d
Recognizer has been deallocated; not writing partial results
Recognizer has been deallocated; not writing final choices
Result stream has been deallocated; not writing final choices
recogResult.params is null. Should NEVER happen
Recognizer has been deallocated; not reporting result progress
Result stream has been deallocated; not reporting result progress
Recognizer has been deallocated; not writing end point data
Result stream has been deallocated; not writing end point data
Recognizer has been deallocated; not training speaker code.
Training instance has been deallocated; not training speaker code.
Speaker code writer has been deallocated; not training speaker code.
Features or labels are invalid, not feeding data for training, feature size: %zu, label size: %zu
Training starts, total samples: %zu
Training finishes, writing updated speaker code out, processed samples: %zu, training offset: %zu, recognition offset: %zu
mlock source %s size %lu mlock_fraction %f mlock_size %lu locked_ %d ret %d errno %d strerror %s
munlock source %s size %lu mlock_fraction %f mlock_size %lu locked_ %d ret %d errno %d strerror %s
%{public}s
Input type not recognized
Initializing %@
File does not exist %@
Unsupported input data type
Document type is not set properly
Input data to serialization is nil
Serialization process failed with error: %@
Deserialization process failed with error: %@
Unknown protection class: %@
Cannot cast to NgramFstConfig
Cannot cast to NgramLmModel
Model building failed
Interpolation failed
PSR: EARAudioProcessor Config file does not exist at %@
PSR: ERR: AudioProcessorPipeline created with incorrect version
endAudio
resetForNewRequest
ComputeTask done
dealloc
Failed to dynamic cast Artifact to AppLmArtifact
Failed to load app lm data object for use parsing custom prons
Interpolating app-lm with a weight of %f
Interpolating app-lm with default weight
Transitioned artifact
Transitioning artifact at %@ failed
No custom prons or OOVs present in artifact
LME template for adding artifact custom prons not present in %@ or is empty
LME tag empty
Cannot find emoji recognition candidate from emoji hammer
Cannot create EMFEmojiToken; Unable to connect to Emoji Foundation framework
Config file does not exist at %{public}@
ARG: ERR: AudioProcessorPipeline created with incorrect version
Resetting audio result generator
Got valid result mat in sync fashion with numRows:%lu and numCols:%lu
Got valid result row in sync fashion with numCols:%lu
Ending audio
Unknown EARVoiceCommandActiveSet serialized version
Unknown EARVoiceCommandSuite serialized version
Unknown EARVoiceCommandSpec serialized version
GeoLM: geo config path: %@
GeoLM: Internal unknown exception
GeoLM: Internal C++ exception: %s
GeoLM: selected regionId: %@
Cannot create SPM model
_EARFormatter initialization failed: %s
Quasar Itn missing in configuration
Quasar Itn is nil
Emoji service is not available; Emoji Recognition is turned off
PSR: EARSyncAudioProcessor Config file does not exist at %@
Added %d samples, processed %d ms of audio so far
End audio: Processed %d ms of audio so far
Failed to read speaker code file, language is null or empty
Failed to read speaker code file, path is null or empty
Reading speaker code file from disk, full path: %@
Failed to read speaker code file, error: %@
Failed to deserialize speaker code file, error: %@
Failed to write speaker code file, training speaker code is null or empty
Failed to write speaker code file, inference speaker code is null or empty
Failed to write speaker code file, accumulated gradient is null or empty
Failed to write speaker code file, language is null or empty
Failed to write speaker code file, path is null or empty
Saving speaker code file on disk, full path: %@, num trained frames: %zu, training offset: %zu, recognition offset: %zu, training speaker code: %@, inference speaker code: %@, accumulated gradient: %@
Failed to serialize speaker code data, error: %@
Speaker code data is serialized, writing to file: %@
Failed to write speaker code data, error: %@
Error loading context-aware model: %@
%s, error %@
No supported languages found in acousticPosteriors
context.currentDictationLanguage is empty, setting currentDictationLocale to zeroes.
context.wasLanguageToggled not set, defaulting to false.
context.multilingualKeyboardLanguages not set, setting multilingualKeyboardLocales to zeroes.
context.keyboardConvoLanguagePriors not set, setting keyboardConvoLocalePriors to uniform probability.
context.keyboardGlobalLanguagePriors not set, setting keyboardGlobalLocalePriors to uniform probability.
context.previousMessageLanguage not set, setting previousMessageLocale to zeroes.
context.globalLastKeyboardUsed not set, setting globalLastKeyboardUsed to zeroes.
context.dictationLanguagePriors not set, setting dictationLocalePriors to uniform probability.
Exception in EARContextAwareLDModelFactory::createModel: %s
Unsupported model file format "%s"
Identified languages of messages = %@
%@ maps to %@
There is no keyboard language for %@
Starting new request
previousMessageLanguage and keyboardConvoLanguagePriors are both set, so recentMessages will be ignored.
Unsupported locales (%s) found in context, will be ignored
Error initializing model.
Attempting to load model file: %@
Failed to reload CoreML model with error: %@
Failed to create feature multiarray with error %@
Failed to create feature provider with error %@
Error during prediction: %@
LanguageDetector: EARLanguageDetector model file does not exist at %@
Received didFinishProcessingFrames
Got an error when trying to print logging info
Logging Data: %@
Sending logging info to delegate
Received didComputeResult
Sending language detector result to delegate
Sending language detector confidences to delegate
Failed to initialize XML parser for custom prons file at %@
softlink:o:path:/System/Library/PrivateFrameworks/AssistantServices.framework/AssistantServices
_EAROnDeviceEndpointerInfo
_EARPhoneticMatchData
_EARPhoneticMatchBuilder
EMTSpan
NSCopying
NoiseSampler
_EARWordPart
_EARPeopleSuggesterConfig
_EARUserProfileBuilder
_EARUserProfile
_EARUserProfileConfig
_EARUserProfileContainer
_EAREndpointFeatures
_EARDefaultServerEndpointFeatures
_EAREndpointer
_EARSpeechRecognitionToken
_EARAcousticFeature
_EARAudioAnalytics
_EARLatticeMitigatorResult
_EARSpeechRecognition
_EARSpeechRecognitionResultPackage
_EARSpeechRecognitionResult
_EARResultContext
_EARLazyDoubleArray
_EARSpeechRecognizer
Q$+*
_EARSpeechModelInfo
_EARSpeakerCodeInfo
_EARSyncResultStreamHelper
_EARSpeechRecognitionResultStream
NSObject
_EARSpeechRecognitionActiveConfiguration
_EARRecognitionMetrics
EARSdapiHelper
TextSequenceInference
TextSequence
TextSequenceTrain
_EARTransformUtil
_EARLMTKaldiVocab
_EARSpeechRecognitionAudioBuffer
_EARSyncSpeechRecognizer
_EARSystemResult
_EARCombinedResult
_EARResultCombiner
TextProcessorInference
TextProcessor
TextProcessorTrain
_EARLanguageDetectorRequestContext
_EARTextNormalization
_EARNnetUtil
EARTokenPronounciations
EARKeywordFinderResult
EARKeywordFinder
EARAudioReader
_EARHash
_EARContextualData
EARStringView
EMTTokenizer
_EARLmData
_EARLmModel
_EARLmModel2
_EARNgramLmModel
_EARNgramLmModel2
_EARLmBuilder
_EARInterpolator
_EARLmInterpolator
_EARLmEvaluator
_EARLmLoader
_EARLmLoader2
_EAROovToken
_EARAppLmData
_EARCustomLMBuilder
EARPSRAudioProcessor
EARCSpeechRecognitionResultStreamGlue
_EARLanguageDetectorAudioBuffer
EMTToken
_EARArtifact
_EARAppLmArtifact
_EARAppLmArtifactUtils
_EAREmojiRecognition
EARAudioResult
EARAudioResultsGenerator
EARVoiceCommandActiveSet
NSSecureCoding
NSCoding
EARVoiceCommandSuite
EARVoiceCommandSpec
EMTTranslator
_EARGeoLMHelper
EARVoiceCommandInterpretation
EARVoiceCommandArgument
_EARLanguageModel
EARSentencePieceModule
_EARFormatter
EMTResult
_EARJitProfile
_EARCustomPronData
EARSyncPSRAudioProcessor
_EARLmHandle
EARClientSilenceFeatures
EARCaesuraSilencePosteriorGenerator
_EARSpeakerCodeReader
_EARSpeakerCodeWriter
_EARSpeakerCodeWriterInterface
_EARPhonesetMapping
_EARLanguageDetectorLoggingInfo
_EARLanguageDetectorResult
_EARLanguageDetector
_EARCommandTagging
_EARCommandTaggingResult
_EARCommandTagger
_EARPlsParser
NSXMLParserDelegate
_EARTokenizer
_EARSdapiTokenizer
_EARNLTokenizer
_EARLMTGlobalNNLM
_EARProfiler
init
defaultManager
fileExistsAtPath:
ear_toString
numberWithDouble:
numberWithInt:
initWithConfig:
getEndpointerThresholdForClientModelVersion:task:
getEndpointerExtraDelayFrequencyForTask:
.cxx_destruct
.cxx_construct
_hybridClientConfigs
UTF8String
stringWithUTF8String:
stringByStandardizingPath
fileSystemRepresentation
fileURLWithFileSystemRepresentation:isDirectory:relativeToURL:
numberWithBool:
setValue:forKey:
setValue:forKeyPath:
addObject:
length
firstObject
stringByAppendingPathComponent:
createDirectoryAtPath:withIntermediateDirectories:attributes:error:
numberWithFloat:
componentsJoinedByString:
_initWithCommandTaggings:
countByEnumeratingWithState:objects:count:
objectForKey:
initWithCapacity:
initWithPresence:indexes:adpositionIndexes:
initWithCommandIdentifier:suiteIdentifiers:verbIndexes:arguments:
mutableCopy
count
exchangeObjectAtIndex:withObjectAtIndex:
copy
addIndex:
array
_initWithQuasarToken:
quasarToken
quasarTokens
quasarPreItnTokens
_initWithQuasarCommandTagging:
setWithCapacity:
convertFeedType:
objectAtIndexedSubscript:
initWithFeedType:jsonConfigFile:
writeTsv:
sortItemsByPriorDesc
sortItemsByPriorAsc
normalizePriors
expDecayPriors
powerScalePriors
applyRegexEnumerations
addOsym
appendData:prior:
roomForMoreData
getLimit
dataFeed
_dataFeed
T{shared_ptr<quasar::DataFeed>=^{DataFeed}^{__shared_weak_count}},R,N,V_dataFeed
tokenizerWithNcsRoot:
stringWithFormat:
writePlaceholderFstToPath:
writePlaceholderSymbolsToPath:
initWithNcsRoot:jsonConfigFile:dataFeeds:
initWithNcsRoot:jsonConfigFile:dataFeedsFile:
supportPhoneticMatchBuilding
buildGFsts
buildLFst
buildAlignedLFst
composeLGFsts
combineFsts
reset
writeAlignedLFstToPath:
writeLGFstToPath:
writeOSymsToPath:asText:quasarise:
writeISymsToPath:asText:
writeGFstsToDirectory:
writeLFstToPath:
writeIndividualLGFstsToDirectory:
writeMetadataToPath:
lgFstName
lFstName
osymsName
tokenizer
pmBuilder
_tokenizer
_pmBuilder
T{shared_ptr<quasar::TextTokenizer>=^{TextTokenizer}^{__shared_weak_count}},R,N,V_tokenizer
T{shared_ptr<quasar::PMBuilder>=^{PMBuilder}^{__shared_weak_count}},R,N,V_pmBuilder
copyWithZone:
initWithIdentifier:range:doNotTranslate:
identifier
range
doNotTranslate
_doNotTranslate
_identifier
_range
T@"NSString",R,N,V_identifier
T{_NSRange=QQ},R,N,V_range
TB,R,N,V_doNotTranslate
initWithUnigram:ofSize:
initWithZipfOfSize:
drawNoise
_alias
_unigram
_generator
initWithOrthography:pronunciations:tag:
initWithOrthography:pronunciations:tagName:frequency:
tagName
orthography
frequency
pronunciations
_tagName
_orthography
_tag
_frequency
_pronunciations
T@"NSString",R,N,V_orthography
Tq,R,N,V_tag
T@"NSString",R,N
TQ,R,N,V_frequency
T@"NSSet",R,N,V_pronunciations
initWithContactsCount:bestContactsCount:bestContactsBonus:
contactsCount
bestContactsCount
bestContactsBonus
_contactsCount
_bestContactsCount
_bestContactsBonus
TI,R,N,V_contactsCount
TI,R,N,V_bestContactsCount
TI,R,N,V_bestContactsBonus
EnsureSDAPIInitialized
localeIdentifier
initWithConfiguration:language:overrides:sdapiOverrides:generalVoc:emptyVoc:pgVoc:lexiconEnh:tokenEnh:paramsetHolder:
initWithConfiguration:language:overrides:sdapiOverrides:generalVoc:emptyVoc:pgVoc:lexiconEnh:tokenEnh:paramsetHolder:isJit:
enumerateKeysAndObjectsUsingBlock:
pronunciationsForOrthography:
numberWithLongLong:
objectForKeyedSubscript:
longLongValue
_writeProfileToStream:
dataWithBytes:length:
writeProfileToFile:protectionClass:coordinated:length:error:
stringByDeletingLastPathComponent
initWithFilePresenter:
fileURLWithPath:isDirectory:relativeToURL:
coordinateWritingItemAtURL:options:error:byAccessor:
readUserProfile:
bytes
readUserProfileWithPath:
currentHandler
handleFailureInMethod:object:file:lineNumber:description:
removeAllWords
arrayWithObjects:count:
stringWithCString:encoding:
addWordWithParts:templateName:
getWords
getTemplateToAverageCost
getTemplateToDeviationCost
initialize
isEasyToRecognizeWord:forLocale:
initWithConfiguration:withLanguage:withSdapiOverrides:withSdapiConfig:
initWithConfiguration:language:sdapiOverrides:generalVoc:emptyVoc:pgVoc:lexiconEnh:tokenEnh:paramsetHolder:
removeLmeDataForTemplateName:
userId
setUserId:
templateToVersion
setTemplateToVersion:
dataProfile
writeProfileToFile:protectionClass:length:error:
readUserProfile:reuseProfile:
readUserProfileWithPath:reuseProfile:
addPersonalizationData:
addPersonalizationJsonData:
writeOutUserDataToJson:withConfig:
sanitizedStringWithString:
signalEndOfUserData
createInlineLmeUserDataForContextStrings:
createInlineLmeUserDataForContextData:speechProfile:
peopleSuggesterConfig
_userData
_dataFactory
_g2p
_pronCache
_sanitizer
_personalizationRecipe
_quasarLmeData
_reuseProfile
_outPronCache
_outPronCacheHits
_outPronCacheMisses
_wordsRejected
_wordsAccepted
_quasarTemplate2Count
_unmaskedUserId
_templateToVersion
T@"_EARPeopleSuggesterConfig",R,N
T@"NSString",C,N
T@"NSDictionary",C,N
raise:format:
initWithConfiguration:overrides:
lmeConfig
initWithContentsOfFile:options:error:
propertyListWithData:options:format:error:
valueForKey:
dataWithBytesNoCopy:length:
initWithPath:userId:recognitionOnly:error:
initWithPath:error:
lmeData
maskedUserIdWithMask:
quasarContainerWithUserIdMask:
data
_fstream
_mutex
_lmeData
T@"NSData",R,C,N
T@"NSString",R,C,N
initWithWordCount:trailingSilenceDuration:endOfSentenceLikelihood:pauseCounts:silencePosterior:clientSilenceFramesCountMs:clientSilenceProbability:silencePosteriorNF:serverFeaturesLatency:eagerResultEndTime:
initWithWordCount:trailingSilenceDuration:endOfSentenceLikelihood:pauseCounts:silencePosterior:clientSilenceFramesCountMs:clientSilenceProbability:silencePosteriorNF:serverFeaturesLatency:
description
wordCount
setWordCount:
trailingSilenceDuration
setTrailingSilenceDuration:
endOfSentenceLikelihood
setEndOfSentenceLikelihood:
pauseCounts
setPauseCounts:
silencePosterior
setSilencePosterior:
clientSilenceFramesCountMs
setClientSilenceFramesCountMs:
clientSilenceProbability
setClientSilenceProbability:
silencePosteriorNF
setSilencePosteriorNF:
serverFeaturesLatency
setServerFeaturesLatency:
eagerResultEndTime
setEagerResultEndTime:
_silencePosteriorNF
_serverFeaturesLatency
_wordCount
_trailingSilenceDuration
_endOfSentenceLikelihood
_pauseCounts
_silencePosterior
_clientSilenceFramesCountMs
_clientSilenceProbability
_eagerResultEndTime
Tq,N,V_wordCount
Tq,N,V_trailingSilenceDuration
Td,N,V_endOfSentenceLikelihood
T@"NSArray",C,N,V_pauseCounts
Td,N,V_silencePosterior
Td,N,V_clientSilenceFramesCountMs
Td,N,V_clientSilenceProbability
Tf,N,V_silencePosteriorNF
Tf,N,V_serverFeaturesLatency
Tq,N,V_eagerResultEndTime
initWithWordCount:trailingSilenceDuration:endOfSentenceLikelihood:silencePosterior:
Tf,N,V_endOfSentenceLikelihood
Tf,N,V_silencePosterior
initWithConfiguration:modelVersion:
initWithConfiguration:
initWithConfiguration:delaysTrigger:modelVersion:
requestSupportedWithSamplingRate:
updateEndpointerThresholdWithValue:
updateEndpointerDelayedTriggerSwitch:
didEndpointWithFeatures:audioTimestamp:featuresToLog:endpointPosterior:extraDelayMs:
defaultServerEndpointFeatures
acceptEagerResultWithFeatures:featuresToLog:
_endpointer
unsignedIntValue
tokenName
hash
initWithTokenName:start:end:silenceStart:confidence:hasSpaceAfter:hasSpaceBefore:phoneSequence:ipaPhoneSequence:appendedAutoPunctuation:
start
silenceStart
confidence
hasSpaceAfter
hasSpaceBefore
phoneSequence
ipaPhoneSequence
appendedAutoPunctuation
prependedAutoPunctuation
isModifiedByAutoPunctuation
stringByAppendingFormat:
isEqual:
initWithTokenName:start:end:silenceStart:confidence:hasSpaceAfter:hasSpaceBefore:phoneSequence:ipaPhoneSequence:
_quasarToken
T{Token={basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}IIIfBB{basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}{basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}{vector<std::pair<std::string, float>, std::allocator<std::pair<std::string, float>>>=^v^v{__compressed_pair<std::pair<std::string, float> *, std::allocator<std::pair<std::string, float>>>=^v}}{basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}BB{basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}B},R,N,V_quasarToken
Td,R,N
TB,R,N
_initWithAcousticFeatureValues:frameDuration:
acousticFeatureValuePerFrame
frameDuration
_acousticFeatureValuePerFrame
_frameDuration
T@"NSArray",R,C,N,V_acousticFeatureValuePerFrame
Td,R,N,V_frameDuration
_initWithSpeechRecognitionFeatures:acousticFeatures:snr:
speechRecognitionFeatures
acousticFeatures
_speechRecognitionFeatures
_acousticFeatures
_snr
T@"NSDictionary",R,C,N,V_speechRecognitionFeatures
T@"NSDictionary",R,C,N,V_acousticFeatures
Td,R,N,V_snr
initWithVersion:score:threshold:
version
score
threshold
_score
_threshold
_version
T@"NSString",R,C,N,V_version
Tf,R,N,V_score
Tf,R,N,V_threshold
_initWithTokenPhraseChoiceList:
numberWithUnsignedInt:
_initWithTokenSausage:interpretationIndices:
tokenSausage
interpretationIndices
objectAtIndex:
intValue
addObjectsFromArray:
_tokenPhraseChoiceList
_initWithNBestList:useHatText:
nBest
oneBest
granularizedRecognition
setTokenSausage:
_tokenSausage
_interpretationIndices
T@"NSArray",C,N,V_tokenSausage
T@"NSArray",R,C,N,V_interpretationIndices
_initWithRecognition:preITNRecognition:unrepairedRecognition:recognitionIsFormatted:isFinal:audioAnalytics:utteranceStart:
_initWithRecognition:preITNRecognition:unrepairedRecognition:recognitionIsFormatted:isFinal:audioAnalytics:utteranceStart:latticeMitigatorResult:
_initWithRecognition:preITNRecognition:unrepairedRecognition:recognitionIsFormatted:isFinal:audioAnalytics:utteranceStart:latticeMitigatorResult:nBestVoiceCommandInterpretations:preITNNBestVoiceCommandInterpretations:recognitionPaused:
_initWithRecognition:preITNRecognition:unrepairedRecognition:recognitionIsFormatted:isFinal:audioAnalytics:utteranceStart:latticeMitigatorResult:nBestVoiceCommandInterpretations:preITNNBestVoiceCommandInterpretations:recognitionPaused:firstResultAfterResume:
recognition
preITNRecognition
unrepairedRecognition
recognitionIsFormatted
isFinal
audioAnalytics
utteranceStart
latticeMitigatorResult
nBestVoiceCommandInterpretations
preITNNBestVoiceCommandInterpretations
recognitionPaused
firstResultAfterResume
_initWithTokens:preITNTokens:
_initWithRecognition:preITNRecognition:unrepairedRecognition:recognitionIsFormatted:isFinal:
_initWithRecognition:preITNRecognition:unrepairedRecognition:recognitionIsFormatted:isFinal:audioAnalytics:
nBestResults
setCorrectPartialResultIndexList:oneBestFinalResult:partialResultIndexOffset:
hasNonEmptyToken
setFirstResultAfterResume:
setIsFinal:
correctPartialResultIndexList
_recognitionIsFormatted
_isFinal
_recognitionPaused
_firstResultAfterResume
_recognition
_preITNRecognition
_unrepairedRecognition
_audioAnalytics
_utteranceStart
_latticeMitigatorResult
_correctPartialResultIndexList
_nBestVoiceCommandInterpretations
_preITNNBestVoiceCommandInterpretations
TB,N,V_isFinal
TB,N,V_firstResultAfterResume
T@"_EARSpeechRecognition",R,C,N,V_recognition
T@"_EARSpeechRecognition",R,C,N,V_preITNRecognition
T@"_EARSpeechRecognition",R,C,N,V_unrepairedRecognition
TB,R,N,V_recognitionIsFormatted
T@"_EARAudioAnalytics",R,C,N,V_audioAnalytics
Td,R,N,V_utteranceStart
T@"_EARLatticeMitigatorResult",R,C,N,V_latticeMitigatorResult
T@"NSArray",R,C,N,V_correctPartialResultIndexList
T@"NSArray",R,C,N,V_nBestVoiceCommandInterpretations
T@"NSArray",R,C,N,V_preITNNBestVoiceCommandInterpretations
TB,R,N,V_recognitionPaused
_initWithTokens:preITNTokens:confidence:
_initWithTokens:preITNTokens:confidence:voiceCommandInterpretations:preITNVoiceCommandInterpretations:
tokens
preITNTokens
voiceCommandInterpretations
preITNVoiceCommandInterpretations
_confidence
_voiceCommandInterpretations
_preITNVoiceCommandInterpretations
_quasarTokens
_quasarPreItnTokens
T{vector<quasar::Token, std::allocator<quasar::Token>>=^{Token}^{Token}{__compressed_pair<quasar::Token *, std::allocator<quasar::Token>>=^{Token}}},R,N,V_quasarTokens
T{vector<quasar::Token, std::allocator<quasar::Token>>=^{Token}^{Token}{__compressed_pair<quasar::Token *, std::allocator<quasar::Token>>=^{Token}}},R,N,V_quasarPreItnTokens
T@"NSArray",R,C,N
Td,R,N,V_confidence
T@"NSArray",R,C,N,V_voiceCommandInterpretations
T@"NSArray",R,C,N,V_preITNVoiceCommandInterpretations
itnEnablingFlags
recognizeEmoji
formatWords:unrepairedWordsOut:task:language:preItnLeftContext:separateAutoEndPunctuation:partialResults:timestampOffset:zeroTimestamp:continuousListeningConfig:postItnLeftContext:itnResult:itnOverrides:itnEnablingFlags:recognizeEmoji:leftContextProvidedByClient:preItnRightContext:emojiTokenIndices:persistEmoji:shouldHideTrailingPunctuation:isTrailingPunctuationHidden:isFinal:choiceIdx:itnCompletion:
numberWithUnsignedInteger:
incrementCountOfIsFinalFalseAlreadyWritten
addPartialResultToContext:
resetPartialResultContext
updateLoggableResultWithCurrentResult:currentCosts:startMilliseconds:
prevBestRecogText
setPrevBestRecogText:
countOfIsFinalFalseAlreadyWritten
setCountOfIsFinalFalseAlreadyWritten:
prevPackage
setPrevPackage:
prevMuxPackages
setPrevMuxPackages:
prevPackageWithoutPersonalization
setPrevPackageWithoutPersonalization:
anyResults
setAnyResults:
continuousListeningResultHelper
setContinuousListeningResultHelper:
partialResults
partialResultIndexOffset
loggableConcatResult
setLoggableConcatResult:
loggableConcatCosts
setLoggableConcatCosts:
_anyResults
_countOfIsFinalFalseAlreadyWritten
_prevPackage
_prevMuxPackages
_prevPackageWithoutPersonalization
_partialResultIndexOffset
_continuousListeningResultHelper
_prevBestRecogText
_partialResults
_loggableConcatResult
_loggableConcatCosts
T{basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}},N,V_prevBestRecogText
TQ,N,V_countOfIsFinalFalseAlreadyWritten
T@"_EARSpeechRecognitionResultPackage",&,N,V_prevPackage
T@"NSDictionary",&,N,V_prevMuxPackages
T@"_EARSpeechRecognitionResultPackage",&,N,V_prevPackageWithoutPersonalization
TB,N,V_anyResults
T{shared_ptr<EARContinuousListeningResultHelper>=^{EARContinuousListeningResultHelper}^{__shared_weak_count}},N,V_continuousListeningResultHelper
T{vector<std::vector<quasar::Token>, std::allocator<std::vector<quasar::Token>>>=^v^v{__compressed_pair<std::vector<quasar::Token> *, std::allocator<std::vector<quasar::Token>>>=^v}},R,N,V_partialResults
TQ,R,N,V_partialResultIndexOffset
T{vector<std::vector<quasar::Token>, std::allocator<std::vector<quasar::Token>>>=^v^v{__compressed_pair<std::vector<quasar::Token> *, std::allocator<std::vector<quasar::Token>>>=^v}},N,V_loggableConcatResult
T{vector<double, std::allocator<double>>=^d^d{__compressed_pair<double *, std::allocator<double>>=^d}},N,V_loggableConcatCosts
_initWithDoubleVector:
_vec
initWithConfiguration:overrides:overrideConfigFiles:
activeConfigurationForEverything
initWithConfiguration:overrides:overrideConfigFiles:language:activeConfiguration:
initWithConfiguration:overrides:overrideConfigFiles:language:activeConfiguration:enableSpeakerCodeTraining:
initWithConfiguration:overrides:overrideConfigFiles:language:activeConfiguration:modelLoadingOptions:enableSpeakerCodeTraining:
initWithConfiguration:overrides:overrideConfigFiles:language:activeConfiguration:modelLoadingOptions:enableSpeakerCodeTraining:supportEmojiRecognition:
initWithConfiguration:overrides:overrideConfigFiles:language:activeConfiguration:modelLoadingOptions:enableSpeakerCodeTraining:supportEmojiRecognition:voiceCommandActiveSet:
initWithConfiguration:overrides:overrideConfigFiles:language:activeConfiguration:modelLoadingOptions:enableSpeakerCodeTraining:supportEmojiRecognition:voiceCommandActiveSet:modelContextDelegate:
enumerateObjectsUsingBlock:
speechRecognizerActiveConfiguration
boolValue
_initWithSpeechModelInfo:
initWithLanguage:
trainingSpeakerCode
inferenceSpeakerCode
accumulatedGradient
nnetVersion
numFrames
unsignedLongValue
trainingOffset
recognitionOffset
initWithLanguage:withSdapiConfig:quasarConfig:
initWithConfiguration:overrides:overrideConfigFiles:generalVoc:lexiconEnh:itnEnh:
initWithConfiguration:overrides:overrideConfigFiles:generalVoc:lexiconEnh:itnEnh:language:
initWithConfiguration:overrides:overrideConfigFiles:generalVoc:lexiconEnh:itnEnh:language:activeConfiguration:
initWithConfiguration:overrides:overrideConfigFiles:generalVoc:lexiconEnh:itnEnh:language:activeConfiguration:enableSpeakerCodeTraining:
initWithConfiguration:overrides:overrideConfigFiles:generalVoc:lexiconEnh:itnEnh:language:activeConfiguration:modelLoadingOptions:enableSpeakerCodeTraining:
initWithConfiguration:overrides:overrideConfigFiles:generalVoc:lexiconEnh:itnEnh:language:activeConfiguration:modelLoadingOptions:enableSpeakerCodeTraining:supportEmojiRecognition:
initWithConfiguration:overrides:overrideConfigFiles:generalVoc:lexiconEnh:itnEnh:language:activeConfiguration:modelLoadingOptions:enableSpeakerCodeTraining:supportEmojiRecognition:voiceCommandActiveSet:
initWithConfiguration:overrides:overrideConfigFiles:generalVoc:lexiconEnh:itnEnh:language:activeConfiguration:modelLoadingOptions:enableSpeakerCodeTraining:supportEmojiRecognition:voiceCommandActiveSet:modelContextDelegate:
supportedByQuasarSystemConfig:
initWithQuasarConfig:overrideConfigFiles:supportEmojiRecognition:language:skipPathsExistCheck:
formatWords:unrepairedWordsOut:task:
initWithGeneralVoc:withLexiconEnh:withItnEnh:
initWithConfiguration:useQuasarFormatter:activeConfiguration:
supportedByQuasarConfig:
initWithQuasarConfig:
bundleForClass:
resourceURL
URLForResource:withExtension:
dictionaryWithContentsOfURL:
initWithPlistJSONDictionary:
setWithObject:
initWithSuites:resourceBaseURL:
ear_toStringOrNothing
newlineCharacterSet
componentsSeparatedByCharactersInSet:
lastObject
tokenizeTextFromEnd:withLimit:outTokensInVocab:
setLeftContext:
_restartActiveRecognition
splitWithTokenizer:isLeftContext:shouldTruncate:outTokensInVocab:
allObjects
stringValue
setObject:forKeyedSubscript:
arrayByAddingObjectsFromArray:
_setProfileContainers:muxIds:
runRecognitionWithResultStream:language:task:samplingRate:
runRecognitionWithResultStream:language:task:samplingRate:userProfileData:speakerCodeWriter:
_detachFromRecognizer
_audioBufferWithLangauge:task:samplingRate:userProfileData:resultStream:
_initWithAudioBuffer:speechRecognizer:
stringByReplacingOccurrencesOfString:withString:
isContinuousListening
enableVoiceCommands
setInferenceSpeakerCode:
numberWithUnsignedLong:
setNumFrames:
setIsSpeakerCodeUsed:
_setUnderlyingBuffer:
addAudioSampleData:
endAudio
waitForCompletion
error
results
recognitionResultsWithAudioData:userProfileData:language:task:samplingRate:
initWithTagResults:
subarrayWithRange:
taggedResults
needsANECompilationForModelAtURL:result:error:
modelWithContentsOfURL:error:
purgeANEIRForModelAtURL:error:
_initWithActiveConfiguration:
resumeRecognitionWithLeftContext:rightContext:selectedText:
refreshEmojiRecognizer
processInfo
systemUptime
tokenize:limit:
reverseObjectEnumerator
insertObject:atIndex:
splitWithTokenizer:outTokensInVocab:
minimumSupportedConfigurationVersion
maximumSupportedConfigurationVersion
rawTokenResultsFromRecognitionResults:
compileRecognizerModelsWithConfiguration:
purgeCompiledRecognizerModelsWithConfiguration:
initWithConfiguration:overrideConfigFiles:
initWithConfiguration:overrides:overrideConfigFiles:language:
initWithConfiguration:withLanguage:withSdapiConfig:
initWithConfiguration:withGeneralVoc:withLexiconEnh:withItnEnh:
initWithConfiguration:overrides:generalVoc:lexiconEnh:itnEnh:
initWithConfiguration:overrideConfigFiles:generalVoc:lexiconEnh:itnEnh:
initWithConfiguration:useQuasarFormatter:
setEnableVoiceCommands:
setHighPriority:
setLeftContextText:
setRightContext:
setUserProfileData:
setJitProfileData:
setUserProfile:
_unmaskMuxPackages:
runRecognitionWithResultStream:
updateUserProfileData:
updateJitProfileData:
runRecognitionWithResultStream:speakerCodeWriter:language:task:samplingRate:
canCloneIsFinalAsLastNonFinal
writeRecordedStateAccesses
recognitionResultsWithAudioData:userProfileData:language:task:samplingRate:extraLanguageModel:
testFormattingWithOneBestResults:uttMillis:
cancelRecognition
_waitForAsyncRecogToFinish
interruptTraining
recognitionStatistics
recognitionUtterenceStatistics
recognitionUtteranceInfos
getFormatterWithBlock:
_waitForInitialization
dumpModelVirtualMemoryInfo
setActiveConfiguration:
isSpeakerCodeTrainingSupported:
activeConfiguration
setAlternateRawRecognitionTokenSausage:
getRecognizer
pauseRecognition
userProfileData
jitProfileData
modelInfo
speakerCodeInfo
detectUtterances
setDetectUtterances:
concatenateUtterances
setConcatenateUtterances:
allowUtteranceDelay
setAllowUtteranceDelay:
formatAcrossUtterances
setFormatAcrossUtterances:
endpointStart
setEndpointStart:
recognizeEagerCandidates
setRecognizeEagerCandidates:
farField
setFarField:
highPriority
enableSpeakerCodeTraining
setEnableSpeakerCodeTraining:
maximumRecognitionDuration
setMaximumRecognitionDuration:
recognitionReplacements
setRecognitionReplacements:
recognitionConfidenceSubtraction
setRecognitionConfidenceSubtraction:
leftContext
inputOrigin
setInputOrigin:
deviceId
setDeviceId:
refTranscriptForErrorBlaming
setRefTranscriptForErrorBlaming:
bluetoothDeviceId
setBluetoothDeviceId:
sessionId
setSessionId:
extraLmList
setExtraLmList:
scoreNbestExtraLmList
setScoreNbestExtraLmList:
scoreNbest
setScoreNbest:
latitude
setLatitude:
longitude
setLongitude:
disableAutoPunctuation
setDisableAutoPunctuation:
disablePartialResults
setDisablePartialResults:
voiceCommandActiveSet
setRecognizeEmoji:
rightContext
selectedText
setSelectedText:
aneContext
setAneContext:
cpuContext
setCpuContext:
gpuContext
setGpuContext:
recognitionMetrics
setRecognitionMetrics:
leftContextForItn
setLeftContextForItn:
configPath
overrideDoServerSideEndpointing
setOverrideDoServerSideEndpointing:
_formatterQueue
_formatter
_trainingQueue
_training
_voiceCommandCompilation
_enableVoiceCommands
_recognizer
_currentAudioBuffer
_currentResultStreamWrapper
_currentLanguage
_currentTask
_currentSamplingRate
_recognitionQueue
_muxIdMask
_muxIdReverseMask
_muxIds
_userProfiles
_rightContextTokens
_modelInitializeContext
_detectUtterances
_concatenateUtterances
_allowUtteranceDelay
_formatAcrossUtterances
_recognizeEagerCandidates
_farField
_highPriority
_enableSpeakerCodeTraining
_scoreNbest
_disableAutoPunctuation
_disablePartialResults
_recognizeEmoji
_userProfileData
_jitProfileData
_modelInfo
_speakerCodeInfo
_endpointStart
_maximumRecognitionDuration
_recognitionReplacements
_recognitionConfidenceSubtraction
_leftContext
_inputOrigin
_deviceId
_refTranscriptForErrorBlaming
_bluetoothDeviceId
_userId
_sessionId
_extraLmList
_scoreNbestExtraLmList
_latitude
_longitude
_voiceCommandActiveSet
_rightContext
_selectedText
_aneContext
_cpuContext
_gpuContext
_recognitionMetrics
_leftContextForItn
_configPath
_overrideDoServerSideEndpointing
T@"NSString",R,N,V_configPath
TS,R,N
T@"NSNumber",&,N,V_overrideDoServerSideEndpointing
T@"NSData",C,N,V_userProfileData
T@"NSData",C,N,V_jitProfileData
T@"_EARSpeechModelInfo",R,N,V_modelInfo
T@"_EARSpeakerCodeInfo",R,N,V_speakerCodeInfo
TB,N,V_detectUtterances
TB,N,V_concatenateUtterances
TB,N,V_allowUtteranceDelay
TB,N,V_formatAcrossUtterances
Td,N,V_endpointStart
TB,N,V_recognizeEagerCandidates
TB,N,V_farField
TB,N,V_highPriority
TB,N,V_enableSpeakerCodeTraining
Td,N,V_maximumRecognitionDuration
T@"NSDictionary",C,N,V_recognitionReplacements
T@"NSDictionary",C,N,V_recognitionConfidenceSubtraction
T@"NSArray",C,N,V_leftContext
T@"NSString",C,N,V_inputOrigin
T@"NSString",C,N,V_deviceId
T@"NSString",C,N,V_refTranscriptForErrorBlaming
T@"NSString",C,N,V_bluetoothDeviceId
T@"NSString",C,N,V_userId
T@"NSString",C,N,V_sessionId
T@"NSArray",C,N,V_extraLmList
T@"NSArray",C,N,V_scoreNbestExtraLmList
TB,N,V_scoreNbest
Td,N,V_latitude
Td,N,V_longitude
TB,N,V_disableAutoPunctuation
TB,N,V_disablePartialResults
TB,N,V_enableVoiceCommands
T@"EARVoiceCommandActiveSet",R,N,V_voiceCommandActiveSet
TB,N,V_recognizeEmoji
T@"NSString",C,N,V_rightContext
T@"NSString",C,N,V_selectedText
T@"NSString",C,N,V_aneContext
T@"NSString",C,N,V_cpuContext
T@"NSString",C,N,V_gpuContext
T@"_EARRecognitionMetrics",C,N,V_recognitionMetrics
T@"NSArray",C,N,V_leftContextForItn
initWithInt:
samplingRates
tasks
language
phoneSetVersion
acousticProfileVersion
_speechModelInfo
T@"NSSet",R,N
initWithUnsignedInt:
initWithUnsignedLong:
getTrainingSpeakerCode:inferenceSpeakerCode:accumulatedGradient:nnetVersion:numFrames:trainingOffset:recognitionOffset:language:
isSpeakerCodeUsed
_isSpeakerCodeUsed
_trainingSpeakerCode
_inferenceSpeakerCode
_accumulatedGradient
_numFrames
_nnetVersion
_trainingOffset
_recognitionOffset
T@"NSString",R,N,V_trainingSpeakerCode
T@"NSString",C,N,V_inferenceSpeakerCode
T@"NSString",R,N,V_accumulatedGradient
T@"NSNumber",C,N,V_numFrames
T@"NSNumber",R,N,V_nnetVersion
T@"NSNumber",R,N,V_trainingOffset
T@"NSNumber",R,N,V_recognitionOffset
TB,N,V_isSpeakerCodeUsed
addPartialFinalTag:result:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
superclass
debugDescription
TQ,R
T#,R
T@"NSString",R,C
speechRecognizer:didRecognizePartialResult:
speechRecognizer:didFinishRecognitionWithError:
speechRecognizer:didRecognizeFinalResults:
speechRecognizer:didRecognizeFinalResults:tokenSausage:nBestChoices:
speechRecognizer:didRecognizeFinalResultPackage:
speechRecognizer:didProcessAudioDuration:
speechRecognizer:didRecognizeRawEagerRecognitionCandidate:
speechRecognizer:didProduceEndpointFeaturesWithWordCount:trailingSilenceDuration:eosLikelihood:pauseCounts:silencePosterior:processedAudioDurationInMilliseconds:
speechRecognizer:didRecognizePartialResultNbest:
speechRecognizer:didProduceLoggablePackage:
speechRecognizer:didRecognizeFinalResultCandidatePackage:
_finishSemaphore
_error
_results
_taggedResults
T@"NSMutableArray",R,N,V_taggedResults
T@"NSError",R,N,V_error
T@"NSArray",R,N,V_results
setSamplingRateFilter:
setTaskTypeFilter:
setFarFieldFilter:
setDeviceIdFilter:
setBluetoothDeviceIdFilter:
setAneContextFilter:
setCpuContextFilter:
setGpuContextFilter:
samplingRateFilter
taskTypeFilter
farFieldFilter
deviceIdFilter
bluetoothDeviceIdFilter
aneContextFilter
cpuContextFilter
gpuContextFilter
ear_stringWithStringView:
activeConfigurationForNothing
_samplingRateFilter
_taskTypeFilter
_farFieldFilter
_deviceIdFilter
_bluetoothDeviceIdFilter
_aneContextFilter
_cpuContextFilter
_gpuContextFilter
T@"NSSet",C,N,V_samplingRateFilter
T@"NSSet",C,N,V_taskTypeFilter
T@"NSSet",C,N,V_farFieldFilter
T@"NSSet",C,N,V_deviceIdFilter
T@"NSSet",C,N,V_bluetoothDeviceIdFilter
T@"NSSet",C,N,V_aneContextFilter
T@"NSSet",C,N,V_cpuContextFilter
T@"NSSet",C,N,V_gpuContextFilter
initWithRecognizer:
addPauseDurationMetric
addEmojiRecognitionMetrics:recognizedEmojis:
pauseDurations
itnDurationInNs
isEmojiPersonalizationUsed
isEmojiDisambiguationUsed
isEmojiExpectedButNotRecognized
recognizedEmojis
_isEmojiPersonalizationUsed
_isEmojiDisambiguationUsed
_isEmojiExpectedButNotRecognized
_pauseDurations
_itnDurationInNs
_recognizedEmojis
T@"NSArray",R,C,N,V_pauseDurations
T@"NSNumber",R,N,V_itnDurationInNs
TB,R,N,V_isEmojiPersonalizationUsed
TB,R,N,V_isEmojiDisambiguationUsed
TB,R,N,V_isEmojiExpectedButNotRecognized
T@"NSArray",R,C,N,V_recognizedEmojis
initWithArray:copyItems:
replaceObjectAtIndex:withObject:
handleFailureInFunction:file:lineNumber:description:
initWithDictionary:
initWithArray:
formattedTokensWithoutEmojiModifier:emojiTokenIndices:recognizeEmoji:
appendNbestListWithEmojiAlternativesForFormattedTokens:formattedTokensWithoutEmojiModifier:formattedNBestList:formattedNBestListWithoutEmojiModifier:emojiTokenIndices:recognizeEmoji:
appendString:
dictionaryWithObjects:forKeys:count:
errorWithDomain:code:userInfo:
didStartModelInitializing:
didFinishModelInitializing:
lowercaseString
setObject:forKey:
isEnableAutoPunctuation:task:itnEnablingFlags:
floatValue
setTrainingSpeakerCode:inferenceSpeakerCode:accumulatedGradient:nnetVersion:numFrames:trainingOffset:recognitionOffset:language:
handle
unsignedIntegerValue
initWithLength:
setObject:atIndexedSubscript:
removeObjectAtIndex:
addWordWithInputId:
sequence
initWithLength:BOS:
resetWithBOS:
target
_sequence
_target
addWordWithInputId:target:mask:
mask
_mask
hatToQsrString:
hatToQsrStrings:
stringWithContentsOfURL:encoding:error:
isEqualToString:
whitespaceCharacterSet
initWithContentsOfUrl:outError:
indexForWord:
vocabSize
endOfSentenceIndex
beginOfSentenceIndex
unknownWordIndex
endOfSentenceToken
_bosIndex
_eosIndex
_unkIndex
_eosToken
_w2i
addAudioSamples:count:
triggerServerSideEndPointer
bufferedAudioDuration
packetArrivalTimestampFromAudioTime:
_buffer
_queue
_speechRecognizer
_cancelled
_ended
initWithConfiguration:memoryLock:
getSpeechRecognitionResultFromTokens:taskName:
resetWithSamplingRate:language:taskType:userId:sessionId:deviceId:farField:audioSource:maxAudioBufferSizeSeconds:
resultsWithAddedAudio:numberOfSamples:taskName:
resultsWithAddedFloatAudio:numberOfSamples:taskName:
resultsWithEndedAudio
_syncRecognizer
sausage
setSausage:
nBestIndexes
setNBestIndexes:
confidences
setConfidences:
_sausage
_nBestIndexes
_confidences
T@"NSArray",C,N,V_sausage
T@"NSArray",C,N,V_nBestIndexes
T@"NSArray",C,N,V_confidences
nBestStrings
setNBestStrings:
nBestSourceIndexes
setNBestSourceIndexes:
originalRanks
setOriginalRanks:
_nBestStrings
_nBestSourceIndexes
_originalRanks
T@"NSArray",C,N,V_nBestStrings
T@"NSArray",C,N,V_nBestSourceIndexes
T@"NSArray",C,N,V_originalRanks
combinedResultWithSystemResults:
_combiner
modelDescription
inputDescriptionsByName
multiArrayConstraint
shape
outputDescriptionsByName
initWithDictionary:error:
predictionFromFeatures:options:error:
setUsesCPUOnly:
featureValueForName:
multiArrayValue
featureNames
initWithDataPointer:shape:dataType:strides:deallocator:error:
strides
longValue
dataType
dataPointer
initWithVocab:
addText:
textSequence
initWithLength:vocab:BOS:
_text
_vocab
addText:length:
addTokenizedText:length:
shuffleSamples
numberSamples
numberTokens
_numValidTokens
languagePriors
dictationLanguages
currentDictationLanguage
wasLanguageToggled
multilingualKeyboardLanguages
keyboardConvoLanguagePriors
keyboardGlobalLanguagePriors
previousMessageLanguage
globalLastKeyboardUsed
dictationLanguagePriors
setLanguagePriors:
setDictationLanguages:
setCurrentDictationLanguage:
setWasLanguageToggled:
setMultilingualKeyboardLanguages:
setKeyboardConvoLanguagePriors:
setKeyboardGlobalLanguagePriors:
setPreviousMessageLanguage:
setGlobalLastKeyboardUsed:
setDictationLanguagePriors:
recentMessages
setRecentMessages:
contextFromLDContext:
LDContext
_languagePriors
_dictationLanguages
_currentDictationLanguage
_wasLanguageToggled
_multilingualKeyboardLanguages
_keyboardConvoLanguagePriors
_keyboardGlobalLanguagePriors
_previousMessageLanguage
_globalLastKeyboardUsed
_dictationLanguagePriors
_recentMessages
T{LDContext={map<quasar::language_detector::Locale, double, std::less<quasar::language_detector::Locale>, std::allocator<std::pair<const quasar::language_detector::Locale, double>>>={__tree<std::__value_type<quasar::language_detector::Locale, double>, std::__map_value_compare<quasar::language_detector::Locale, std::__value_type<quasar::language_detector::Locale, double>, std::less<quasar::language_detector::Locale>, true>, std::allocator<std::__value_type<quasar::language_detector::Locale, double>>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<quasar::language_detector::Locale, double>, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::__map_value_compare<quasar::language_detector::Locale, std::__value_type<quasar::language_detector::Locale, double>, std::less<quasar::language_detector::Locale>, true>>=Q}}}{optional<std::set<quasar::language_detector::Locale>>=(?=c{set<quasar::language_detector::Locale, std::less<quasar::language_detector::Locale>, std::allocator<quasar::language_detector::Locale>>={__tree<quasar::language_detector::Locale, std::less<quasar::language_detector::Locale>, std::allocator<quasar::language_detector::Locale>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<quasar::language_detector::Locale, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::less<quasar::language_detector::Locale>>=Q}}})B}{optional<quasar::language_detector::Locale>=(?=c{Locale={basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}{basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}})B}{optional<bool>=(?=cB)B}{optional<std::vector<quasar::language_detector::Locale>>=(?=c{vector<quasar::language_detector::Locale, std::allocator<quasar::language_detector::Locale>>=^{Locale}^{Locale}{__compressed_pair<quasar::language_detector::Locale *, std::allocator<quasar::language_detector::Locale>>=^{Locale}}})B}{optional<std::map<quasar::language_detector::Locale, double>>=(?=c{map<quasar::language_detector::Locale, double, std::less<quasar::language_detector::Locale>, std::allocator<std::pair<const quasar::language_detector::Locale, double>>>={__tree<std::__value_type<quasar::language_detector::Locale, double>, std::__map_value_compare<quasar::language_detector::Locale, std::__value_type<quasar::language_detector::Locale, double>, std::less<quasar::language_detector::Locale>, true>, std::allocator<std::__value_type<quasar::language_detector::Locale, double>>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<quasar::language_detector::Locale, double>, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::__map_value_compare<quasar::language_detector::Locale, std::__value_type<quasar::language_detector::Locale, double>, std::less<quasar::language_detector::Locale>, true>>=Q}}})B}{optional<std::map<quasar::language_detector::Locale, double>>=(?=c{map<quasar::language_detector::Locale, double, std::less<quasar::language_detector::Locale>, std::allocator<std::pair<const quasar::language_detector::Locale, double>>>={__tree<std::__value_type<quasar::language_detector::Locale, double>, std::__map_value_compare<quasar::language_detector::Locale, std::__value_type<quasar::language_detector::Locale, double>, std::less<quasar::language_detector::Locale>, true>, std::allocator<std::__value_type<quasar::language_detector::Locale, double>>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<quasar::language_detector::Locale, double>, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::__map_value_compare<quasar::language_detector::Locale, std::__value_type<quasar::language_detector::Locale, double>, std::less<quasar::language_detector::Locale>, true>>=Q}}})B}{optional<quasar::language_detector::Locale>=(?=c{Locale={basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}{basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}})B}{optional<quasar::language_detector::Locale>=(?=c{Locale={basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}{basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}})B}{optional<std::map<quasar::language_detector::Locale, double>>=(?=c{map<quasar::language_detector::Locale, double, std::less<quasar::language_detector::Locale>, std::allocator<std::pair<const quasar::language_detector::Locale, double>>>={__tree<std::__value_type<quasar::language_detector::Locale, double>, std::__map_value_compare<quasar::language_detector::Locale, std::__value_type<quasar::language_detector::Locale, double>, std::less<quasar::language_detector::Locale>, true>, std::allocator<std::__value_type<quasar::language_detector::Locale, double>>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<quasar::language_detector::Locale, double>, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::__map_value_compare<quasar::language_detector::Locale, std::__value_type<quasar::language_detector::Locale, double>, std::less<quasar::language_detector::Locale>, true>>=Q}}})B}},R
T@"NSDictionary",C,N,V_languagePriors
T@"NSSet",C,N,V_dictationLanguages
T@"NSString",C,N,V_currentDictationLanguage
T@"NSNumber",C,N,V_wasLanguageToggled
T@"NSArray",C,N,V_multilingualKeyboardLanguages
T@"NSDictionary",C,N,V_keyboardConvoLanguagePriors
T@"NSDictionary",C,N,V_keyboardGlobalLanguagePriors
T@"NSString",C,N,V_previousMessageLanguage
T@"NSString",C,N,V_globalLastKeyboardUsed
T@"NSDictionary",C,N,V_dictationLanguagePriors
T@"NSArray",C,N,V_recentMessages
doubleValue
initWithNcsRoot:
tokenize:
munge:
initWithNcsRoot:mungeRuleFile:
initWithNcsRoot:mungeRules:
initWithMungeRules:
normalize:
_munger
doBackPropWithNnetModelFile:inputFeatureVector:inputTargetVector:inputLearningRate:inputFreezeComponents:inputNumLocalIterations:inputGradNormFactor:inputGradNormType:inputBatchSize:inputObjectiveFunction:outTrainingLosses:outModelLayersUpdated:
doBackPropWithNnetModelFile:inputFeatureVector:inputTargetVector:inputLearningRate:inputFreezeComponents:inputNumLocalIterations:inputGradNormFactor:inputGradNormType:inputBatchSize:inputObjectiveFunction:outTrainingLoss:outModelLayersUpdated:
initWithToken:pronunciations:
_quasarProns
token
setToken:
setPronunciations:
_token
T@"NSString",C,N,V_token
T@"NSArray",C,N,V_pronunciations
_initWithCorrectedUtterances:
correctedUtterances
_correctedUtterances
T@"NSArray",R,C,N,V_correctedUtterances
correctedResultWithKeyword:tokenizedKeyword:preItnSausage:preItnOneBest:preItnOneBestIndices:nbestSize:
_kwf
pathExtension
_opx_enumerateAudioBuffersWithBlock:
_avf_enumerateAudioBuffersWithBlock:
assetWithURL:
assetReaderWithAsset:error:
tracksWithMediaType:
assetReaderAudioMixOutputWithAudioTracks:audioSettings:
canAddOutput:
addOutput:
startReading
copyNextSampleBuffer
mutableBytes
_opx_enumeratePacketsWithBlock:
fileHandleForReadingFromURL:error:
readDataUpToLength:error:
getBytes:length:
initWithFileURL:sampleRate:
enumerateAudioBuffersWithBlock:
_fileURL
_sampleRate
dataUsingEncoding:
_ear_sha256
raise:format:arguments:
addNamedEntity:metadata:
dateWithTimeIntervalSinceNow:
addNamedEntity2:metadata:
iterNamedEntitySourceWithApplication:block:
iterNamedEntitySourceWithApplication:task:block:
iterRankedContactSourceWithApplication:block:
iterRankedContactSourceWithApplication:task:block:
metrics
containsEntity
_contextualData
initWithBytes:length:encoding:
lengthOfBytesUsingEncoding:
getCString:maxLength:encoding:
URLByAppendingPathComponent:
path
text
formattedStringWithStrings:preToPostItnArray:
formattedStringWithStrings:
initWithModelURL:
format:preToPostItnMap:
format:
outputLocale
_outputLocale
T@"NSLocale",R,N,V_outputLocale
suites
resourceBaseURL
commandSpecs
fstRelativePaths
valence
fstSymbol
addSentenceWithType:uuid:content:hasWeights:
initWithConfiguration:ncsRoot:recognizerConfiguration:
addDocumentWithUUID:content:
addDocumentWithUUID:content:metadata:
addLineWithType:uuid:content:
addSentenceWithType:uuid:content:
addNgramCountWithType:content:
setInputFormat:
enumerateSentencesOfType:block:
sources
queryLimit
maxAge
minAge
wordFrequency
roundingEnabled
setRoundingEnabled:
inputType
_roundingEnabled
_inputType
_data
T{shared_ptr<quasar::PersonalizedLmData>=^{PersonalizedLmData}^{__shared_weak_count}},R,N,V_data
TB,N,V_roundingEnabled
Tq,R,N,V_inputType
initWithConfiguration:root:
_initWithHandle:
trainWithData:
dataWithPropertyList:format:options:error:
removeWithDirectory:
_initWithModel:
initFromDirectory:
trainWithData:shouldStop:
setWeight:
writeToDirectory:
weight
serializedModelWithLanguage:modelData:oovs:
deserializeModelData:
model
buildConfig
_model
_buildConfig
T{shared_ptr<quasar::LmModel2>=^{LmModel2}^{__shared_weak_count}},R,N,V_model
T{shared_ptr<quasar::LmBuildConfig>=^{LmBuildConfig}^{__shared_weak_count}},R,N,V_buildConfig
setProtectionClass:
_initWithModel:config:
generateNgramCounts:
arpaFileName
ngramModel
ngramBuildConfig
_ngramModel
_ngramBuildConfig
T{shared_ptr<quasar::NgramLmModel2>=^{NgramLmModel2}^{__shared_weak_count}},R,N,V_ngramModel
T{shared_ptr<quasar::NgramFstConfig>=^{NgramFstConfig}^{__shared_weak_count}},R,N,V_ngramBuildConfig
buildLmWithConfig:root:data:dir:shouldStop:
loadLmFromDir:
removeLmDir:
generateNgramCountsWithConfig:root:data:
interpolate:configPath:dataRoot:modelRoot:
interpolateArpaFilePaths:configPath:dataRoot:modelRoot:
initWithConfiguration:root:recognizerConfiguration:
runEvaluationWithData:handle:result:bestWeight:
initWithConfiguration:recognizerConfiguration:
runEvaluationWithData:handle:result:
runEvaluationWithData:handle:shouldStop:result:bestWeight:
_evaluator
fetchOrLoadModelWithDirectory:recognizer:
loadForRecognitionWithDirectory:recognizer:task:applicationName:
invalidate
_loader
initWithRoot:
initWithOrthography:prons:frequency:
prons
_prons
T@"NSSet",R,N,V_prons
Tq,R,N,V_frequency
setProns:forWord:pronIsXsampa:
canAddProns:forWord:pronIsXsampa:
initWithAppLmData:
orderedOovs
initWithConfiguration:ncsRoot:recognizerConfigPath:
addOovTokensFromSentence:
setXsampaProns:forWord:
setAsrProns:forWord:
canAddXsampaProns:forWord:
canAddAsrProns:forWord:
generateLmeData:
lmeThreshold
supportedSlots
T{shared_ptr<quasar::AppLmData>=^{AppLmData}^{__shared_weak_count}},R,N,Vdata
T@"NSArray",R,N
defaultCStringEncoding
writeToFile:options:error:
getFstGrammar:overrideFolder:weight:errorOut:
_customLMBuilder
initWithConfigFile:configRoot:sampleRate:delegate:queue:
_startComputeTask
delegate
psrAudioProcessor:hasSpeakerVector:speakerVectorSize:processedAudioDurationMs:
psrAudioProcessor:hasResult:numElements:
psrAudioProcessor:finishedWithFinalSpeakerVector:speakerVectorSize:processedAudioDurationMs:
dealloc
initWithConfigFile:configRoot:sampleRate:delegate:
addAudio:
resetForNewRequest
configRoot
setConfigRoot:
setDelegate:
queue
setQueue:
batchSize
setBatchSize:
_audioProcessor
_sysConfig
_configRoot
_delegate
_batchSize
T@"<EARPSRAudioProcessorDelegate>",W,N,V_delegate
T@"NSString",&,N,V_configRoot
T@"NSObject<OS_dispatch_queue>",&,N,V_queue
TQ,N,V_batchSize
initWithStream:
_stream
initWithConfiguration:usage:
commandId
tagSequence
tokensForTag:
commandTaggings
commandTaggingFromRecognitionResult:activeCommands:
parameterTagForIndex:
commandPhraseTagForIndex:
isParameterTag:
isCommandPhraseTag:
_initWithAudioBuffer:
initWithText:confidence:score:precededBySpace:followedBySpace:
precededBySpace
followedBySpace
initWithText:confidence:precededBySpace:followedBySpace:
_precededBySpace
_followedBySpace
T@"NSString",R,N,V_text
Tf,R,N,V_confidence
TB,R,N,V_precededBySpace
TB,R,N,V_followedBySpace
isValid:
initWithAcceptedContent:acceptedInfo:dependent:
getVersion
getLocale
supportsInfo:
hasInfo:
getInfo:
supportsContent:
hasContent:
getContent:
isMinimalistic
minimize
write:
isEquivalentTo:
_artifact
_tryToLoadCachedLmData:ncsRoot:dataRoot:
_cacheLmData:configFilepath:ncsRoot:dataRoot:
_loadRawAppLmData:ncsRoot:dataRoot:
initWithCustomPronData:
initWithAppLmArtifact:
transitionArtifactAt:toStage:configPath:ncsRoot:dataRoot:estimationRoot:minimize:
createEmptyArtifact:version:locale:saveTo:
createPhraseCountsArtifact:version:locale:rawPhraseCountsPath:customPronunciationsPath:saveTo:
transitionArtifactAt:toStage:configPath:ncsRoot:dataRoot:estimationRoot:minimize:saveTo:
loadLmHandleFromArtifactAt:configPath:ncsRoot:
initWithVersion:andLocale:
initWithPath:
loadAppLmData:ncsRoot:dataRoot:
loadCustomPronData:ncsRoot:dataRoot:
loadOovs
loadLmHandle
isAdaptableToSpeechModelVersion:locale:
getLifeCycleStage
_cachedLmData
_cachedConfigFilepath
_cachedNcsRoot
_cachedDataRoot
getProns
addCustomPronsToUserProfile:artifact:configPath:
fileURLWithPath:
coordinateReadingItemAtURL:options:error:byAccessor:
processString:
dominantLanguage
createDirectoryAtURL:withIntermediateDirectories:attributes:error:
emojiLocaleDataWithLocaleIdentifier:
_frequentEmojiBaseStrings
isEmojiRecognitionCapable
formatEmojiStrings:isLogging:
isValidEmoji:
emojiTokenWithString:localeData:
supportsSkinToneVariants
lastUsedVariantEmojiForEmoji:
hasLastUsedVariantForEmoji:
string
_initWithoutConnection
readEmojiDefaults
recentEmojis
copyWithoutModifiers
containsObject:
didUseEmoji:
_disconnect
_isSingleEmoji
stringByTrimmingCharactersInSet:
baseStringForEmojiString:
emojiTokensForText:phoneticReading:options:searchType:includePrefixMatches:
formatEmojiStrings:
resetEmojiPreferences
resetEmojiMetrics
searchEmojiAlternativesForSpokenEmoji:count:emojiCharacter:
_preferences
_localeData
_frequentEmojis
_cemlocaleRef
initWithAudioResultMat:vectorSize:numVectors:
audioResultMat
setAudioResultMat:
audioResultsNumVectors
setAudioResultsNumVectors:
audioResultsVectorSize
setAudioResultsVectorSize:
_audioResultMat
_audioResultsNumVectors
_audioResultsVectorSize
T@"NSData",&,N,V_audioResultMat
TQ,N,V_audioResultsNumVectors
TQ,N,V_audioResultsVectorSize
setLength:
appendData:
hasEARAudioResultMatrix:
hasEARAudioResultLastVector:
audioResultMatrix
audioResultLastVector
_isAudioSessionLive
_entireResultMatrix
_globalNumVectors
_vectorSize
_sessionFrameCount
T@"<EARAudioResultsGeneratorDelegate>",W,N,V_delegate
dataWithCapacity:
appendBytes:length:
isEqualToSet:
encodeInteger:forKey:
encodeObject:forKey:
decodeIntegerForKey:
decodeObjectOfClass:forKey:
arrayWithCapacity:
plistJSONDictionary
absoluteString
integerValue
URLWithString:
supportsSecureCoding
encodeWithCoder:
initWithCoder:
TB,R
_suites
_resourceBaseURL
T@"NSSet",R,C,N,V_suites
T@"NSURL",R,C,N,V_resourceBaseURL
initWithIdentifier:commands:
_commandSpecs
T@"NSString",R,C,N,V_identifier
T@"NSSet",R,C,N,V_commandSpecs
numberWithChar:
indexOfObjectPassingTest:
setWithArray:
initWithIdentifier:valence:fstRelativePaths:fstSymbol:
_valence
_fstRelativePaths
_fstSymbol
Tc,R,N,V_valence
T@"NSSet",R,C,N,V_fstRelativePaths
T@"NSString",R,N,V_fstSymbol
initWithModelURL:task:
initWithModelURLs:task:skipNonFinalToCatchup:translatorCacheSize:
setMaxConcurrentOperationCount:
progress
setTotalUnitCount:
translateSpeech:from:to:completion:
rawTranscription
segments
substring
translateTokens:from:to:spans:completion:
translateString:from:to:completion:
_tokenizeString:
_prepareFor:to:
_dispatchTranslationRequest:isFinal:spans:completion:
translateTokens:isFinal:spans:completion:
componentsSeparatedByString:
totalUnitCount
blockOperationWithBlock:
setQueuePriority:
addOperation:
completedUnitCount
initWithLocale:tokens:confidence:lowConfidence:metaInfo:
initWithModelURL:task:skipNonFinalToCatchup:
initWithModelURL:task:skipNonFinalToCatchup:translatorCacheSize:
initWithModelURLs:task:
initWithModelURLs:task:skipNonFinalToCatchup:
loadTranslatorFrom:to:
translateSpeech:completion:
translateString:completion:
translateTokens:from:to:completion:
translateTokens:isFinal:completion:
prepareFor:to:
getTranslatorWithCompletion:
callbackQueue
setCallbackQueue:
_translatorFactory
_translator
_sourceLocale
_targetLocale
_configs
_skipNonFinalToCatchup
_translationRequestsQueue
_translationQueue
_callbackQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_callbackQueue
regionIdForLatitude:longitude:
_geography
verbIndexes
arguments
indexes
addIndexes:
adpositionIndexes
firstIndex
lastIndex
commandIdentifier
suiteIdentifiers
isEqualToIndexSet:
isEqualToArray:
_commandIdentifier
_suiteIdentifiers
_verbIndexes
_arguments
T@"NSString",R,C,N,V_commandIdentifier
T@"NSSet",R,C,N,V_suiteIdentifiers
T{_NSRange=QQ},R,N
T@"NSIndexSet",R,C,N,V_verbIndexes
T@"NSArray",R,C,N,V_arguments
presence
_presence
_indexes
_adpositionIndexes
Tc,R,N,V_presence
T@"NSIndexSet",R,C,N,V_indexes
T@"NSIndexSet",R,C,N,V_adpositionIndexes
addDataSource:weight:
enumerateDataSourcesAndWeightsUsingBlock:
totalWeight
_dataSources
_totalWeight
Tf,R,N,V_totalWeight
initWithModelPath:
encodeUtterance:
_processor
initWithQuasarConfig:overrideConfigFiles:
initWithQuasarConfig:overrideConfigFiles:supportEmojiRecognition:language:
initializeItnMetrics
recognizeEmojiForTokens:recognizeEmoji:emojiTokenIndices:persistEmoji:choiceIdx:
convertStringsToQuasarTokens:offset:
getOrthography:
formatWords:task:autoPunctuate:recognizeEmoji:
formattedStringWithStrings:task:
convertStringsToQuasarTokens:
formattedStringWithStrings:preToPostItnArray:task:
formatWords:unrepairedWordsOut:
_formattedStringWithStrings:task:leftContext:recognizeEmoji:
_formattedStringWithStrings:task:leftContext:recognizeEmoji:rightContext:
initWithQuasarConfig:language:
formatWords:task:autoPunctuate:
formattedRecognitionWithNBestList:
_formattedStringWithStrings:task:leftContext:
_formattedStringWithoutEmojiModifier:
emojiPhraseRemoveKeyword:
emojiAlternativesForFormattedTokens:stringsWithoutEmojiModifier:alternateNameForTokens:
setLanguage:
_itn
_emojiFormatter
_itnDurationSum
_itnCount
_emojiMetrics
_language
T@"NSString",C,N,V_language
removeLastObject
locale
lowConfidence
metaInfo
_lowConfidence
_locale
_tokens
_metaInfo
T@"NSLocale",R,N,V_locale
T@"NSArray",R,N,V_tokens
TB,R,N,V_lowConfidence
T@"NSString",R,N,V_metaInfo
initWithConfiguration:ncsRoot:language:
jitProfileFromContextualStrings:
_profileBuilder
isValid
validationError
getRejectedProns
setData:
T{shared_ptr<quasar::CustomPronData>=^{CustomPronData}^{__shared_weak_count}},N,V_data
initWithConfigFile:configRoot:sampleRate:delegate:queue:maxBufferSizeSeconds:
initWithConfigFile:configRoot:sampleRate:delegate:queue:maxBufferSizeSeconds:memoryLock:
getLatestSuperVector
getProcessedAudioDurationMs
_scoreReportTimestamp
_maxBufferSizeSeconds
T@"<EARSyncPSRAudioProcessorDelegate>",W,N,V_delegate
_handle
T{shared_ptr<kaldi::quasar::LmHandle>=^{LmHandle}^{__shared_weak_count}},R,N,V_handle
initWithSilenceFramesCountMs:silenceProbability:silenceDurationMs:silencePosterior:processedAudioMs:
silenceFramesCountMs
setSilenceFramesCountMs:
silenceProbability
setSilenceProbability:
silenceDurationMs
setSilenceDurationMs:
processedAudioMs
setProcessedAudioMs:
_silenceFramesCountMs
_silenceProbability
_silenceDurationMs
_processedAudioMs
Td,N,V_silenceFramesCountMs
Td,N,V_silenceProbability
Td,N,V_silenceDurationMs
Td,N,V_processedAudioMs
initWithConfigFile:samplingRate:
initWithConfigFile:samplingRate:queue:
clientSilenceFeaturesAvailable:
silenceDurationEstimateAvailable:numEstimates:clientProcessedAudioMs:
initWithConfigFile:
addAudio:numSamples:
getFrameDurationMs
_silenceGenerator
_configFile
_samplingRate
_spgQueue
T@"<EARCaesuraSilencePosteriorGeneratorDelegate>",W,N,V_delegate
setComputeUnits:
modelWithContentsOfURL:configuration:error:
multiArrayByConcatenatingMultiArrays:alongAxis:dataType:
featureValueWithMultiArray:
featuresAtIndex:
predictionsFromBatch:options:error:
type
initWithShape:dataType:error:
int64Value
fillWithNumber:
isOptional
initWithFeatureProviderArray:
copyIntoMultiArray:error:
vectorizeIntoMultiArray:storageOrder:error:
featureValueWithInt64:
featureValueWithDouble:
dataWithContentsOfFile:options:error:
dictionary
substringToIndex:
ipaPhoneSequenceForAsrProns:
nvAsrPhoneSequenceForXsampaProns:
_phoneset
sharedProfiler
_perfProfiler
addProfilingNetwork:
loggingDict
setLoggingDict:
context
setContext:
_loggingDict
_context
T@"NSDictionary",C,N,V_loggingDict
T@"_EARLanguageDetectorRequestContext",C,N,V_context
isConfident
setIsConfident:
_isConfident
T@"NSDictionary",C,N,V_confidences
TB,N,V_isConfident
fileURLWithPath:isDirectory:
localizedDescription
dictionaryWithCapacity:
dictionaryValue
initWithConfigFile:overrides:
quasarLocalesOfMessages:
null
dominantLanguageForString:
updateContext:withMessageLocales:
localesOfMessages:
startRequestWith:context:delegate:
featureQueuePriority
setFeatureQueuePriority:
languageDetector
_featureQueuePriority
TI,N,V_featureQueuePriority
arrayWithObjects:
dictionaryWithObject:forKey:
dictionaryWithObjects:forKeys:
languageDetectorDidCompleteProcessing:loggingInfo:
languageDetector:result:
languageDetector:confidences:
fileExistsAtPath:isDirectory:
_tagging
_commandId
_tagSequence
T@"NSString",R,C,N,V_commandId
T@"NSArray",R,C,N,V_tagSequence
_commandTaggings
T@"NSArray",R,C,N,V_commandTaggings
_tagger
initWithData:
parse
dataWithContentsOfFile:
setWithSet:
parserDidStartDocument:
parserDidEndDocument:
parser:foundNotationDeclarationWithName:publicID:systemID:
parser:foundUnparsedEntityDeclarationWithName:publicID:systemID:notationName:
parser:foundAttributeDeclarationWithName:forElement:type:defaultValue:
parser:foundElementDeclarationWithName:model:
parser:foundInternalEntityDeclarationWithName:value:
parser:foundExternalEntityDeclarationWithName:publicID:systemID:
parser:didStartElement:namespaceURI:qualifiedName:attributes:
parser:didEndElement:namespaceURI:qualifiedName:
parser:didStartMappingPrefix:toURI:
parser:didEndMappingPrefix:
parser:foundCharacters:
parser:foundIgnorableWhitespace:
parser:foundProcessingInstructionWithTarget:data:
parser:foundComment:
parser:foundCDATA:
parser:resolveExternalEntityName:systemID:
parser:parseErrorOccurred:
parser:validationErrorOccurred:
initWithFilePath:
lexemes
_currentGrapheme
_currentPhonemes
_parser
_elementValue
_lexemes
T@"NSMutableDictionary",R,N,V_lexemes
initWithTagSchemes:
setString:
substringWithRange:
enumerateTagsInRange:unit:scheme:options:usingBlock:
_nlTagger
set_memoryProfiler:
set_perfProfiler:
set_powerProfiler:
set_hasPMP:
set_keepLogFiles:
_powerProfiler
_hasPMP
parsePowerSummary:writeTo:
_memoryProfiler
ane_performance_info
total_ane_time_ns
sample
finishProfilingNetworks
_keepLogFiles
stringWithContentsOfFile:encoding:error:
containsString:
stringByReplacingOccurrencesOfString:withString:options:range:
setMemoryProfiler:
setPerfProfiler:
setPowerProfiler:powerProfilerName:
KeepLogFiles:
finishProfiling
reportProfilingAsDictionary
reportProfiling
cleanupLogfiles
_n_samples
_max_rss
_jetsam_max
_jetsam_tot
_background_power
_networks
_power_summary
_start_time
_end_time
_ane_time
_power_profiler_name
_background_power_logfile_name
_runtime_power_logfile_name
__memoryProfiler
__perfProfiler
__powerProfiler
__hasPMP
__keepLogFiles
TB,V__memoryProfiler
TB,V__perfProfiler
TB,V__powerProfiler
TB,V__hasPMP
TB,V__keepLogFiles
@24@0:8@16
@28@0:8I16@20
v16@0:8
@16@0:8
{HybridClientConfigs="hybridEndpointerThresholds"{map<int, std::map<std::string, double>, std::less<int>, std::allocator<std::pair<const int, std::map<std::string, double>>>>="__tree_"{__tree<std::__value_type<int, std::map<std::string, double>>, std::__map_value_compare<int, std::__value_type<int, std::map<std::string, double>>, std::less<int>, true>, std::allocator<std::__value_type<int, std::map<std::string, double>>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<int, std::map<std::string, double>>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<int, std::__value_type<int, std::map<std::string, double>>, std::less<int>, true>>="__value_"Q}}}"hybridEndpointerExtraDelayFrequency"{map<std::string, int, std::less<std::string>, std::allocator<std::pair<const std::string, int>>>="__tree_"{__tree<std::__value_type<std::string, int>, std::__map_value_compare<std::string, std::__value_type<std::string, int>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, int>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, int>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, int>, std::less<std::string>, true>>="__value_"Q}}}}
i24@0:8q16
@32@0:8q16@24
v24@0:8@16
B28@0:8@16f24
B16@0:8
i16@0:8
{shared_ptr<quasar::DataFeed>=^{DataFeed}^{__shared_weak_count}}16@0:8
{shared_ptr<quasar::DataFeed>="__ptr_"^{DataFeed}"__cntrl_"^{__shared_weak_count}}
B24@0:8@16
@40@0:8@16@24@32
B32@0:8@16B24B28
B28@0:8@16B24
{shared_ptr<quasar::TextTokenizer>=^{TextTokenizer}^{__shared_weak_count}}16@0:8
{shared_ptr<quasar::PMBuilder>=^{PMBuilder}^{__shared_weak_count}}16@0:8
{shared_ptr<quasar::TextTokenizer>="__ptr_"^{TextTokenizer}"__cntrl_"^{__shared_weak_count}}
{shared_ptr<quasar::PMBuilder>="__ptr_"^{PMBuilder}"__cntrl_"^{__shared_weak_count}}
@24@0:8^{_NSZone=}16
@44@0:8@16{_NSRange=QQ}24B40
{_NSRange=QQ}16@0:8
@"NSString"
{_NSRange="location"Q"length"Q}
@24@0:8Q16
@32@0:8^f16Q24
Q16@0:8
{vector<unsigned long, std::allocator<unsigned long>>="__begin_"^Q"__end_"^Q"__end_cap_"{__compressed_pair<unsigned long *, std::allocator<unsigned long>>="__value_"^Q}}
{vector<float, std::allocator<float>>="__begin_"^f"__end_"^f"__end_cap_"{__compressed_pair<float *, std::allocator<float>>="__value_"^f}}
{mersenne_twister_engine<unsigned int, 32UL, 624UL, 397UL, 31UL, 2567483615U, 11UL, 4294967295U, 7UL, 2636928640U, 15UL, 4022730752U, 18UL, 1812433253U>="__x_"[624I]"__i_"Q}
@40@0:8@16@24q32
@48@0:8@16@24@32Q40
q16@0:8
@"NSSet"
@28@0:8I16I20I24
I16@0:8
B32@0:8@16@24
@48@0:8@16@24@32@40
@88@0:8@16@24@32@40@48@56@64@72@80
@96@0:8@16@24@32@40@48@56@64@72@80@88
@100@0:8@16@24@32@40@48@56@64@72@80@88B96
v32@0:8@16@24
B24@0:8^v16
B48@0:8@16q24^Q32^@40
B52@0:8@16q24B32^Q36^@44
v28@0:8@16B24
@32@0:8@16@24
{map<std::string, std::vector<std::vector<quasar::LmeDataFactoryBase::Word>>, std::less<std::string>, std::allocator<std::pair<const std::string, std::vector<std::vector<quasar::LmeDataFactoryBase::Word>>>>>="__tree_"{__tree<std::__value_type<std::string, std::vector<std::vector<quasar::LmeDataFactoryBase::Word>>>, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<std::vector<quasar::LmeDataFactoryBase::Word>>>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::vector<std::vector<quasar::LmeDataFactoryBase::Word>>>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::vector<std::vector<quasar::LmeDataFactoryBase::Word>>>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<std::vector<quasar::LmeDataFactoryBase::Word>>>, std::less<std::string>, true>>="__value_"Q}}}
{shared_ptr<quasar::LmeDataFactory>="__ptr_"^{LmeDataFactory}"__cntrl_"^{__shared_weak_count}}
{unique_ptr<quasar::TextTokenizer, std::default_delete<quasar::TextTokenizer>>="__ptr_"{__compressed_pair<quasar::TextTokenizer *, std::default_delete<quasar::TextTokenizer>>="__value_"^{TextTokenizer}}}
{unique_ptr<quasar::G2P, std::default_delete<quasar::G2P>>="__ptr_"{__compressed_pair<quasar::G2P *, std::default_delete<quasar::G2P>>="__value_"^{G2P}}}
{shared_ptr<quasar::PronCache<std::string, std::vector<std::string>>>="__ptr_"^v"__cntrl_"^{__shared_weak_count}}
{BasicTextSanitizer="_vptr$TextSanitizer"^^?"mUnicodeOutliers"{shared_ptr<quasar::URegularExpressionWrapper>="__ptr_"^{URegularExpressionWrapper}"__cntrl_"^{__shared_weak_count}}"mSpecialChars"{shared_ptr<quasar::URegularExpressionWrapper>="__ptr_"^{URegularExpressionWrapper}"__cntrl_"^{__shared_weak_count}}"mDupSpacePattern"{shared_ptr<quasar::URegularExpressionWrapper>="__ptr_"^{URegularExpressionWrapper}"__cntrl_"^{__shared_weak_count}}"mCtrlCharsPattern"{shared_ptr<quasar::URegularExpressionWrapper>="__ptr_"^{URegularExpressionWrapper}"__cntrl_"^{__shared_weak_count}}"state"i"UTF8_MAP"{unordered_map<std::string, std::string, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<const std::string, std::string>>>="__table_"{__hash_table<std::__hash_value_type<std::string, std::string>, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, std::string>, std::hash<std::string>, std::equal_to<std::string>, true>, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, std::string>, std::equal_to<std::string>, std::hash<std::string>, true>, std::allocator<std::__hash_value_type<std::string, std::string>>>="__bucket_list_"{unique_ptr<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *> *> *[], std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *> *> *>>>="__ptr_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *> *> **, std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *> *> *>>>="__value_"^^v"__value_"{__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *> *> *>>="__data_"{__compressed_pair<unsigned long, std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *> *> *>>="__value_"Q}}}}"__p1_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *> *>, std::allocator<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *>>>="__value_"{__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *> *>="__next_"^v}}"__p2_"{__compressed_pair<unsigned long, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, std::string>, std::hash<std::string>, std::equal_to<std::string>, true>>="__value_"Q}"__p3_"{__compressed_pair<float, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, std::string>, std::equal_to<std::string>, std::hash<std::string>, true>>="__value_"f}}}"unicode_map"{unordered_map<char32_t, char32_t, std::hash<char32_t>, std::equal_to<char32_t>, std::allocator<std::pair<const char32_t, char32_t>>>="__table_"{__hash_table<std::__hash_value_type<char32_t, char32_t>, std::__unordered_map_hasher<char32_t, std::__hash_value_type<char32_t, char32_t>, std::hash<char32_t>, std::equal_to<char32_t>, true>, std::__unordered_map_equal<char32_t, std::__hash_value_type<char32_t, char32_t>, std::equal_to<char32_t>, std::hash<char32_t>, true>, std::allocator<std::__hash_value_type<char32_t, char32_t>>>="__bucket_list_"{unique_ptr<std::__hash_node_base<std::__hash_node<std::__hash_value_type<char32_t, char32_t>, void *> *> *[], std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<char32_t, char32_t>, void *> *> *>>>="__ptr_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<char32_t, char32_t>, void *> *> **, std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<char32_t, char32_t>, void *> *> *>>>="__value_"^^v"__value_"{__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<char32_t, char32_t>, void *> *> *>>="__data_"{__compressed_pair<unsigned long, std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<char32_t, char32_t>, void *> *> *>>="__value_"Q}}}}"__p1_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<char32_t, char32_t>, void *> *>, std::allocator<std::__hash_node<std::__hash_value_type<char32_t, char32_t>, void *>>>="__value_"{__hash_node_base<std::__hash_node<std::__hash_value_type<char32_t, char32_t>, void *> *>="__next_"^v}}"__p2_"{__compressed_pair<unsigned long, std::__unordered_map_hasher<char32_t, std::__hash_value_type<char32_t, char32_t>, std::hash<char32_t>, std::equal_to<char32_t>, true>>="__value_"Q}"__p3_"{__compressed_pair<float, std::__unordered_map_equal<char32_t, std::__hash_value_type<char32_t, char32_t>, std::equal_to<char32_t>, std::hash<char32_t>, true>>="__value_"f}}}}
{unique_ptr<quasar::PersonalizationRecipe, std::default_delete<quasar::PersonalizationRecipe>>="__ptr_"{__compressed_pair<quasar::PersonalizationRecipe *, std::default_delete<quasar::PersonalizationRecipe>>="__value_"^{PersonalizationRecipe}}}
{shared_ptr<quasar::LmeData>="__ptr_"^{LmeData}"__cntrl_"^{__shared_weak_count}}
{unique_ptr<quasar::WordPronCache, std::default_delete<quasar::WordPronCache>>="__ptr_"{__compressed_pair<quasar::WordPronCache *, std::default_delete<quasar::WordPronCache>>="__value_"^{WordPronCache}}}
{unordered_map<std::string, int, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<const std::string, int>>>="__table_"{__hash_table<std::__hash_value_type<std::string, int>, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, int>, std::hash<std::string>, std::equal_to<std::string>, true>, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, int>, std::equal_to<std::string>, std::hash<std::string>, true>, std::allocator<std::__hash_value_type<std::string, int>>>="__bucket_list_"{unique_ptr<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, int>, void *> *> *[], std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, int>, void *> *> *>>>="__ptr_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, int>, void *> *> **, std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, int>, void *> *> *>>>="__value_"^^v"__value_"{__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, int>, void *> *> *>>="__data_"{__compressed_pair<unsigned long, std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, int>, void *> *> *>>="__value_"Q}}}}"__p1_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, int>, void *> *>, std::allocator<std::__hash_node<std::__hash_value_type<std::string, int>, void *>>>="__value_"{__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, int>, void *> *>="__next_"^v}}"__p2_"{__compressed_pair<unsigned long, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, int>, std::hash<std::string>, std::equal_to<std::string>, true>>="__value_"Q}"__p3_"{__compressed_pair<float, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, int>, std::equal_to<std::string>, std::hash<std::string>, true>>="__value_"f}}}
{map<std::string, long long, std::less<std::string>, std::allocator<std::pair<const std::string, long long>>>="__tree_"{__tree<std::__value_type<std::string, long long>, std::__map_value_compare<std::string, std::__value_type<std::string, long long>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, long long>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, long long>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, long long>, std::less<std::string>, true>>="__value_"Q}}}
{unique_ptr<quasar::LmeConfig, std::default_delete<quasar::LmeConfig>>="__ptr_"{__compressed_pair<quasar::LmeConfig *, std::default_delete<quasar::LmeConfig>>="__value_"^{LmeConfig}}}
@44@0:8@16@24B32^@36
@32@0:8@16^@24
{shared_ptr<const quasar::LmeData>=^{LmeData}^{__shared_weak_count}}16@0:8
{shared_ptr<quasar::LmeContainer>=^{LmeContainer}^{__shared_weak_count}}24@0:8@16
{shared_ptr<std::ifstream>="__ptr_"^v"__cntrl_"^{__shared_weak_count}}
{mutex="__m_"{_opaque_pthread_mutex_t="__sig"q"__opaque"[56c]}}
@80@0:8q16q24d32@40d48d56d64f72f76
@88@0:8q16q24d32@40d48d56d64f72f76q80
v24@0:8q16
d16@0:8
v24@0:8d16
f16@0:8
v20@0:8f16
@"NSArray"
@40@0:8q16q24f32f36
@36@0:8@16B24^@28
B24@0:8Q16
v20@0:8B16
B56@0:8@16d24^@32^f40^i48
B32@0:8@16^@24
{unique_ptr<quasar::HybridEndpointer, std::default_delete<quasar::HybridEndpointer>>="__ptr_"{__compressed_pair<quasar::HybridEndpointer *, std::default_delete<quasar::HybridEndpointer>>="__value_"^{HybridEndpointer}}}
@80@0:8@16d24d32d40d48B56B60@64@72
@84@0:8@16d24d32d40d48B56B60@64@72B80
@24@0:8r^v16
{Token={basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}IIIfBB{basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}{basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}{vector<std::pair<std::string, float>, std::allocator<std::pair<std::string, float>>>=^v^v{__compressed_pair<std::pair<std::string, float> *, std::allocator<std::pair<std::string, float>>>=^v}}{basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}BB{basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}B}16@0:8
{Token="tokenName"{basic_string<char, std::char_traits<char>, std::allocator<char>>="__r_"{__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>="__value_"{__rep=""(?="__l"{__long="__cap_"Q"__size_"Q"__data_"*}"__s"{__short=""(?="__size_"C"__lx"c)"__data_"[23c]}"__r"{__raw="__words"[3Q]})}}}"startMilliseconds"I"endMilliseconds"I"silStartMilliSeconds"I"confidence"f"hasSpaceAfter"B"hasSpaceBefore"B"phoneSeq"{basic_string<char, std::char_traits<char>, std::allocator<char>>="__r_"{__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>="__value_"{__rep=""(?="__l"{__long="__cap_"Q"__size_"Q"__data_"*}"__s"{__short=""(?="__size_"C"__lx"c)"__data_"[23c]}"__r"{__raw="__words"[3Q]})}}}"ipaPhoneSeq"{basic_string<char, std::char_traits<char>, std::allocator<char>>="__r_"{__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>="__value_"{__rep=""(?="__l"{__long="__cap_"Q"__size_"Q"__data_"*}"__s"{__short=""(?="__size_"C"__lx"c)"__data_"[23c]}"__r"{__raw="__words"[3Q]})}}}"subwordConfidence"{vector<std::pair<std::string, float>, std::allocator<std::pair<std::string, float>>>="__begin_"^v"__end_"^v"__end_cap_"{__compressed_pair<std::pair<std::string, float> *, std::allocator<std::pair<std::string, float>>>="__value_"^v}}"muxId"{basic_string<char, std::char_traits<char>, std::allocator<char>>="__r_"{__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>="__value_"{__rep=""(?="__l"{__long="__cap_"Q"__size_"Q"__data_"*}"__s"{__short=""(?="__size_"C"__lx"c)"__data_"[23c]}"__r"{__raw="__words"[3Q]})}}}"appendedAutoPunctuation"B"prependedAutoPunctuation"B"alternateTokenName"{basic_string<char, std::char_traits<char>, std::allocator<char>>="__r_"{__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>="__value_"{__rep=""(?="__l"{__long="__cap_"Q"__size_"Q"__data_"*}"__s"{__short=""(?="__size_"C"__lx"c)"__data_"[23c]}"__r"{__raw="__words"[3Q]})}}}"isModifiedByAutoPunctuation"B}
@28@0:8@16f24
@40@0:8@16@24d32
@"NSDictionary"
@32@0:8@16f24f28
@28@0:8r^v16B24
{pair<std::vector<std::vector<unsigned int>>, std::vector<std::vector<std::vector<quasar::Token>>>>={vector<std::vector<unsigned int>, std::allocator<std::vector<unsigned int>>>=^v^v{__compressed_pair<std::vector<unsigned int> *, std::allocator<std::vector<unsigned int>>>=^v}}{vector<std::vector<std::vector<quasar::Token>>, std::allocator<std::vector<std::vector<quasar::Token>>>>=^v^v{__compressed_pair<std::vector<std::vector<quasar::Token>> *, std::allocator<std::vector<std::vector<quasar::Token>>>>=^v}}}16@0:8
@48@0:8@16@24@32B40B44
@56@0:8@16@24@32B40B44@48
@64@0:8@16@24@32B40B44@48d56
@72@0:8@16@24@32B40B44@48d56@64
@92@0:8@16@24@32B40B44@48d56@64@72@80B88
@96@0:8@16@24@32B40B44@48d56@64@72@80B88B92
v36@0:8r^v16r^v24i32
@"_EARSpeechRecognition"
@"_EARAudioAnalytics"
@"_EARLatticeMitigatorResult"
@64@0:8{vector<quasar::Token, std::allocator<quasar::Token>>=^{Token}^{Token}{__compressed_pair<quasar::Token *, std::allocator<quasar::Token>>=^{Token}}}16{vector<quasar::Token, std::allocator<quasar::Token>>=^{Token}^{Token}{__compressed_pair<quasar::Token *, std::allocator<quasar::Token>>=^{Token}}}40
@72@0:8{vector<quasar::Token, std::allocator<quasar::Token>>=^{Token}^{Token}{__compressed_pair<quasar::Token *, std::allocator<quasar::Token>>=^{Token}}}16{vector<quasar::Token, std::allocator<quasar::Token>>=^{Token}^{Token}{__compressed_pair<quasar::Token *, std::allocator<quasar::Token>>=^{Token}}}40d64
@88@0:8{vector<quasar::Token, std::allocator<quasar::Token>>=^{Token}^{Token}{__compressed_pair<quasar::Token *, std::allocator<quasar::Token>>=^{Token}}}16{vector<quasar::Token, std::allocator<quasar::Token>>=^{Token}^{Token}{__compressed_pair<quasar::Token *, std::allocator<quasar::Token>>=^{Token}}}40d64@72@80
{vector<quasar::Token, std::allocator<quasar::Token>>=^{Token}^{Token}{__compressed_pair<quasar::Token *, std::allocator<quasar::Token>>=^{Token}}}16@0:8
{vector<quasar::Token, std::allocator<quasar::Token>>="__begin_"^{Token}"__end_"^{Token}"__end_cap_"{__compressed_pair<quasar::Token *, std::allocator<quasar::Token>>="__value_"^{Token}}}
v24@0:8r^v16
v36@0:8r^v16r^v24I32
{basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}16@0:8
v40@0:8{basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}16
v24@0:8Q16
{shared_ptr<EARContinuousListeningResultHelper>=^{EARContinuousListeningResultHelper}^{__shared_weak_count}}16@0:8
v32@0:8{shared_ptr<EARContinuousListeningResultHelper>=^{EARContinuousListeningResultHelper}^{__shared_weak_count}}16
{vector<std::vector<quasar::Token>, std::allocator<std::vector<quasar::Token>>>=^v^v{__compressed_pair<std::vector<quasar::Token> *, std::allocator<std::vector<quasar::Token>>>=^v}}16@0:8
v40@0:8{vector<std::vector<quasar::Token>, std::allocator<std::vector<quasar::Token>>>=^v^v{__compressed_pair<std::vector<quasar::Token> *, std::allocator<std::vector<quasar::Token>>>=^v}}16
{vector<double, std::allocator<double>>=^d^d{__compressed_pair<double *, std::allocator<double>>=^d}}16@0:8
v40@0:8{vector<double, std::allocator<double>>=^d^d{__compressed_pair<double *, std::allocator<double>>=^d}}16
@"_EARSpeechRecognitionResultPackage"
{shared_ptr<EARContinuousListeningResultHelper>="__ptr_"^{EARContinuousListeningResultHelper}"__cntrl_"^{__shared_weak_count}}
{basic_string<char, std::char_traits<char>, std::allocator<char>>="__r_"{__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>="__value_"{__rep=""(?="__l"{__long="__cap_"Q"__size_"Q"__data_"*}"__s"{__short=""(?="__size_"C"__lx"c)"__data_"[23c]}"__r"{__raw="__words"[3Q]})}}}
{vector<std::vector<quasar::Token>, std::allocator<std::vector<quasar::Token>>>="__begin_"^v"__end_"^v"__end_cap_"{__compressed_pair<std::vector<quasar::Token> *, std::allocator<std::vector<quasar::Token>>>="__value_"^v}}
{vector<double, std::allocator<double>>="__begin_"^d"__end_"^d"__end_cap_"{__compressed_pair<double *, std::allocator<double>>="__value_"^d}}
@56@0:8@16@24@32@40@48
@60@0:8@16@24@32@40@48B56
@68@0:8@16@24@32@40@48@56B64
@72@0:8@16@24@32@40@48@56B64B68
@80@0:8@16@24@32@40@48@56B64B68@72
@88@0:8@16@24@32@40@48@56B64B68@72@80
@64@0:8@16@24@32@40@48@56
@72@0:8@16@24@32@40@48@56@64
@80@0:8@16@24@32@40@48@56@64@72
@84@0:8@16@24@32@40@48@56@64@72B80
@92@0:8@16@24@32@40@48@56@64@72@80B88
@96@0:8@16@24@32@40@48@56@64@72@80B88B92
@104@0:8@16@24@32@40@48@56@64@72@80B88B92@96
@112@0:8@16@24@32@40@48@56@64@72@80B88B92@96@104
@28@0:8@16B24
@36@0:8@16B24@28
@56@0:8@16@24@32@40Q48
@64@0:8@16@24@32Q40@48@56
{shared_ptr<quasar::RecogAudioBufferBase>=^{RecogAudioBufferBase}^{__shared_weak_count}}64@0:8@16@24Q32@40{shared_ptr<quasar::RecogResultStreamBase>=^{RecogResultStreamBase}^{__shared_weak_count}}48
@64@0:8@16@24@32@40Q48@56
S16@0:8
v24@0:8@?16
{shared_ptr<quasar::SpeechRecognizer>=^{SpeechRecognizer}^{__shared_weak_count}}16@0:8
v40@0:8@16@24@32
@40@0:8@16Q24^@32
{vector<std::string, std::allocator<std::string>>=^v^v{__compressed_pair<std::string *, std::allocator<std::string>>=^v}}32@0:8@16^@24
{vector<std::string, std::allocator<std::string>>=^v^v{__compressed_pair<std::string *, std::allocator<std::string>>=^v}}40@0:8@16B24B28^@32
@"NSObject<OS_dispatch_queue>"
@"_EARFormatter"
{shared_ptr<quasar::SpeakerCodeTraining>="__ptr_"^{SpeakerCodeTraining}"__cntrl_"^{__shared_weak_count}}
{shared_ptr<const quasar::VoiceCommandActiveSetCompilation>="__ptr_"^{VoiceCommandActiveSetCompilation}"__cntrl_"^{__shared_weak_count}}
{shared_ptr<quasar::SpeechRecognizer>="__ptr_"^{SpeechRecognizer}"__cntrl_"^{__shared_weak_count}}
@"_EARSpeechRecognitionAudioBuffer"
{weak_ptr<ResultStreamWrapper>="__ptr_"^{ResultStreamWrapper}"__cntrl_"^{__shared_weak_count}}
{vector<std::string, std::allocator<std::string>>="__begin_"^v"__end_"^v"__end_cap_"{__compressed_pair<std::string *, std::allocator<std::string>>="__value_"^v}}
{shared_ptr<EARModelInitializeContext>="__ptr_"^{EARModelInitializeContext}"__cntrl_"^{__shared_weak_count}}
@"_EARTokenizer"
@"NSData"
@"_EARSpeechModelInfo"
@"_EARSpeakerCodeInfo"
@"EARVoiceCommandActiveSet"
@"_EARRecognitionMetrics"
@"NSNumber"
{SpeechModelInfo="version"{basic_string<char, std::char_traits<char>, std::allocator<char>>="__r_"{__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>="__value_"{__rep=""(?="__l"{__long="__cap_"Q"__size_"Q"__data_"*}"__s"{__short=""(?="__size_"C"__lx"c)"__data_"[23c]}"__r"{__raw="__words"[3Q]})}}}"samplingRates"{set<int, std::less<int>, std::allocator<int>>="__tree_"{__tree<int, std::less<int>, std::allocator<int>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<int, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::less<int>>="__value_"Q}}}"tasks"{set<std::string, std::less<std::string>, std::allocator<std::string>>="__tree_"{__tree<std::string, std::less<std::string>, std::allocator<std::string>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::string, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::less<std::string>>="__value_"Q}}}"osTypes"{set<std::string, std::less<std::string>, std::allocator<std::string>>="__tree_"{__tree<std::string, std::less<std::string>, std::allocator<std::string>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::string, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::less<std::string>>="__value_"Q}}}"language"{basic_string<char, std::char_traits<char>, std::allocator<char>>="__r_"{__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>="__value_"{__rep=""(?="__l"{__long="__cap_"Q"__size_"Q"__data_"*}"__s"{__short=""(?="__size_"C"__lx"c)"__data_"[23c]}"__r"{__raw="__words"[3Q]})}}}"phoneSetVersion"{basic_string<char, std::char_traits<char>, std::allocator<char>>="__r_"{__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>="__value_"{__rep=""(?="__l"{__long="__cap_"Q"__size_"Q"__data_"*}"__s"{__short=""(?="__size_"C"__lx"c)"__data_"[23c]}"__r"{__raw="__words"[3Q]})}}}"acousticProfileVersion"{basic_string<char, std::char_traits<char>, std::allocator<char>>="__r_"{__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>="__value_"{__rep=""(?="__l"{__long="__cap_"Q"__size_"Q"__data_"*}"__s"{__short=""(?="__size_"C"__lx"c)"__data_"[23c]}"__r"{__raw="__words"[3Q]})}}}"aceToQuasarTemplate"{map<std::string, std::string, std::less<std::string>, std::allocator<std::pair<const std::string, std::string>>>="__tree_"{__tree<std::__value_type<std::string, std::string>, std::__map_value_compare<std::string, std::__value_type<std::string, std::string>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::string>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::string>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::string>, std::less<std::string>, true>>="__value_"Q}}}"quasarTemplateToAce"{map<std::string, std::vector<std::string>, std::less<std::string>, std::allocator<std::pair<const std::string, std::vector<std::string>>>>="__tree_"{__tree<std::__value_type<std::string, std::vector<std::string>>, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<std::string>>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::vector<std::string>>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::vector<std::string>>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<std::string>>, std::less<std::string>, true>>="__value_"Q}}}"quasarTemplateToEnumerationType"{map<std::string, std::string, std::less<std::string>, std::allocator<std::pair<const std::string, std::string>>>="__tree_"{__tree<std::__value_type<std::string, std::string>, std::__map_value_compare<std::string, std::__value_type<std::string, std::string>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::string>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::string>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::string>, std::less<std::string>, true>>="__value_"Q}}}"g2pModelVersion"i"hybridEndpointerVersion"i}
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
v48@0:8@16@24@32@40
v32@0:8@16d24
v72@0:8@16q24q32d40@48d56q64
v32@0:8@"_EARSpeechRecognizer"16@"_EARSpeechRecognitionResult"24
v32@0:8@"_EARSpeechRecognizer"16@"NSError"24
v32@0:8@"_EARSpeechRecognizer"16@"NSArray"24
v48@0:8@"_EARSpeechRecognizer"16@"NSArray"24@"NSArray"32@"NSArray"40
v32@0:8@"_EARSpeechRecognizer"16@"_EARSpeechRecognitionResultPackage"24
v32@0:8@"_EARSpeechRecognizer"16d24
v32@0:8@"_EARSpeechRecognizer"16@"_EARSpeechRecognition"24
v72@0:8@"_EARSpeechRecognizer"16q24q32d40@"NSArray"48d56q64
@20@0:8B16
@48@0:8{basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}16@40
@"NSObject<OS_dispatch_semaphore>"
@"NSError"
@"NSMutableArray"
{SpeechRecognizerActiveConfiguration={optional<std::set<unsigned int>>=(?=c{set<unsigned int, std::less<unsigned int>, std::allocator<unsigned int>>={__tree<unsigned int, std::less<unsigned int>, std::allocator<unsigned int>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<unsigned int, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::less<unsigned int>>=Q}}})B}{optional<std::set<std::string>>=(?=c{set<std::string, std::less<std::string>, std::allocator<std::string>>={__tree<std::string, std::less<std::string>, std::allocator<std::string>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::string, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::less<std::string>>=Q}}})B}{optional<std::set<std::string>>=(?=c{set<std::string, std::less<std::string>, std::allocator<std::string>>={__tree<std::string, std::less<std::string>, std::allocator<std::string>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::string, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::less<std::string>>=Q}}})B}{optional<std::set<bool>>=(?=c{set<bool, std::less<bool>, std::allocator<bool>>={__tree<bool, std::less<bool>, std::allocator<bool>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<bool, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::less<bool>>=Q}}})B}{optional<std::set<std::string>>=(?=c{set<std::string, std::less<std::string>, std::allocator<std::string>>={__tree<std::string, std::less<std::string>, std::allocator<std::string>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::string, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::less<std::string>>=Q}}})B}{optional<std::set<std::string>>=(?=c{set<std::string, std::less<std::string>, std::allocator<std::string>>={__tree<std::string, std::less<std::string>, std::allocator<std::string>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::string, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::less<std::string>>=Q}}})B}{optional<std::set<std::string>>=(?=c{set<std::string, std::less<std::string>, std::allocator<std::string>>={__tree<std::string, std::less<std::string>, std::allocator<std::string>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::string, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::less<std::string>>=Q}}})B}{optional<std::set<std::string>>=(?=c{set<std::string, std::less<std::string>, std::allocator<std::string>>={__tree<std::string, std::less<std::string>, std::allocator<std::string>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::string, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::less<std::string>>=Q}}})B}}16@0:8
@32@0:8{shared_ptr<quasar::SpeechRecognizer>=^{SpeechRecognizer}^{__shared_weak_count}}16
{weak_ptr<quasar::SpeechRecognizer>="__ptr_"^{SpeechRecognizer}"__cntrl_"^{__shared_weak_count}}
@"NSArray"16@0:8
@32@0:8Q16Q24
v40@0:8Q16Q24Q32
Q24@0:8@16
{unordered_map<std::string, unsigned long, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<const std::string, unsigned long>>>="__table_"{__hash_table<std::__hash_value_type<std::string, unsigned long>, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, unsigned long>, std::hash<std::string>, std::equal_to<std::string>, true>, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, unsigned long>, std::equal_to<std::string>, std::hash<std::string>, true>, std::allocator<std::__hash_value_type<std::string, unsigned long>>>="__bucket_list_"{unique_ptr<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, unsigned long>, void *> *> *[], std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, unsigned long>, void *> *> *>>>="__ptr_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, unsigned long>, void *> *> **, std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, unsigned long>, void *> *> *>>>="__value_"^^v"__value_"{__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, unsigned long>, void *> *> *>>="__data_"{__compressed_pair<unsigned long, std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, unsigned long>, void *> *> *>>="__value_"Q}}}}"__p1_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, unsigned long>, void *> *>, std::allocator<std::__hash_node<std::__hash_value_type<std::string, unsigned long>, void *>>>="__value_"{__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, unsigned long>, void *> *>="__next_"^v}}"__p2_"{__compressed_pair<unsigned long, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, unsigned long>, std::hash<std::string>, std::equal_to<std::string>, true>>="__value_"Q}"__p3_"{__compressed_pair<float, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, unsigned long>, std::equal_to<std::string>, std::hash<std::string>, true>>="__value_"f}}}
@40@0:8{shared_ptr<quasar::RecogAudioBufferBase>=^{RecogAudioBufferBase}^{__shared_weak_count}}16@32
v32@0:8r^s16Q24
v32@0:8{shared_ptr<quasar::RecogAudioBufferBase>=^{RecogAudioBufferBase}^{__shared_weak_count}}16
Q20@0:8f16
{shared_ptr<quasar::RecogAudioBufferBase>="__ptr_"^{RecogAudioBufferBase}"__cntrl_"^{__shared_weak_count}}
@"_EARSpeechRecognizer"
v76@0:8I16@20@28@36@44@52B60@64I72
@48@0:8{vector<std::vector<quasar::Token>, std::allocator<std::vector<quasar::Token>>>=^v^v{__compressed_pair<std::vector<quasar::Token> *, std::allocator<std::vector<quasar::Token>>>=^v}}16@40
@40@0:8@16Q24@32
{shared_ptr<quasar::SyncSpeechRecognizer>="__ptr_"^{SyncSpeechRecognizer}"__cntrl_"^{__shared_weak_count}}
{unique_ptr<quasar::ResultCombiner, std::default_delete<quasar::ResultCombiner>>="__ptr_"{__compressed_pair<quasar::ResultCombiner *, std::default_delete<quasar::ResultCombiner>>="__value_"^{ResultCombiner}}}
@24@0:8@"_EARLMTKaldiVocab"16
v24@0:8@"NSString"16
@40@0:8Q16@24Q32
@"_EARLMTKaldiVocab"
v32@0:8@16Q24
{LDContext={map<quasar::language_detector::Locale, double, std::less<quasar::language_detector::Locale>, std::allocator<std::pair<const quasar::language_detector::Locale, double>>>={__tree<std::__value_type<quasar::language_detector::Locale, double>, std::__map_value_compare<quasar::language_detector::Locale, std::__value_type<quasar::language_detector::Locale, double>, std::less<quasar::language_detector::Locale>, true>, std::allocator<std::__value_type<quasar::language_detector::Locale, double>>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<quasar::language_detector::Locale, double>, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::__map_value_compare<quasar::language_detector::Locale, std::__value_type<quasar::language_detector::Locale, double>, std::less<quasar::language_detector::Locale>, true>>=Q}}}{optional<std::set<quasar::language_detector::Locale>>=(?=c{set<quasar::language_detector::Locale, std::less<quasar::language_detector::Locale>, std::allocator<quasar::language_detector::Locale>>={__tree<quasar::language_detector::Locale, std::less<quasar::language_detector::Locale>, std::allocator<quasar::language_detector::Locale>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<quasar::language_detector::Locale, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::less<quasar::language_detector::Locale>>=Q}}})B}{optional<quasar::language_detector::Locale>=(?=c{Locale={basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}{basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}})B}{optional<bool>=(?=cB)B}{optional<std::vector<quasar::language_detector::Locale>>=(?=c{vector<quasar::language_detector::Locale, std::allocator<quasar::language_detector::Locale>>=^{Locale}^{Locale}{__compressed_pair<quasar::language_detector::Locale *, std::allocator<quasar::language_detector::Locale>>=^{Locale}}})B}{optional<std::map<quasar::language_detector::Locale, double>>=(?=c{map<quasar::language_detector::Locale, double, std::less<quasar::language_detector::Locale>, std::allocator<std::pair<const quasar::language_detector::Locale, double>>>={__tree<std::__value_type<quasar::language_detector::Locale, double>, std::__map_value_compare<quasar::language_detector::Locale, std::__value_type<quasar::language_detector::Locale, double>, std::less<quasar::language_detector::Locale>, true>, std::allocator<std::__value_type<quasar::language_detector::Locale, double>>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<quasar::language_detector::Locale, double>, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::__map_value_compare<quasar::language_detector::Locale, std::__value_type<quasar::language_detector::Locale, double>, std::less<quasar::language_detector::Locale>, true>>=Q}}})B}{optional<std::map<quasar::language_detector::Locale, double>>=(?=c{map<quasar::language_detector::Locale, double, std::less<quasar::language_detector::Locale>, std::allocator<std::pair<const quasar::language_detector::Locale, double>>>={__tree<std::__value_type<quasar::language_detector::Locale, double>, std::__map_value_compare<quasar::language_detector::Locale, std::__value_type<quasar::language_detector::Locale, double>, std::less<quasar::language_detector::Locale>, true>, std::allocator<std::__value_type<quasar::language_detector::Locale, double>>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<quasar::language_detector::Locale, double>, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::__map_value_compare<quasar::language_detector::Locale, std::__value_type<quasar::language_detector::Locale, double>, std::less<quasar::language_detector::Locale>, true>>=Q}}})B}{optional<quasar::language_detector::Locale>=(?=c{Locale={basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}{basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}})B}{optional<quasar::language_detector::Locale>=(?=c{Locale={basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}{basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}})B}{optional<std::map<quasar::language_detector::Locale, double>>=(?=c{map<quasar::language_detector::Locale, double, std::less<quasar::language_detector::Locale>, std::allocator<std::pair<const quasar::language_detector::Locale, double>>>={__tree<std::__value_type<quasar::language_detector::Locale, double>, std::__map_value_compare<quasar::language_detector::Locale, std::__value_type<quasar::language_detector::Locale, double>, std::less<quasar::language_detector::Locale>, true>, std::allocator<std::__value_type<quasar::language_detector::Locale, double>>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<quasar::language_detector::Locale, double>, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::__map_value_compare<quasar::language_detector::Locale, std::__value_type<quasar::language_detector::Locale, double>, std::less<quasar::language_detector::Locale>, true>>=Q}}})B}}16@0:8
{unique_ptr<quasar::Munger, std::default_delete<quasar::Munger>>="__ptr_"{__compressed_pair<quasar::Munger *, std::default_delete<quasar::Munger>>="__value_"^{Munger}}}
@96@0:8@16@24@32f40@44i52f56@60f68@72^f80^@88
@96@0:8@16@24@32f40@44i52f56@60f68@72^@80^@88
{TokenProns={basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}{vector<quasar::PronChoice, std::allocator<quasar::PronChoice>>=^{PronChoice}^{PronChoice}{__compressed_pair<quasar::PronChoice *, std::allocator<quasar::PronChoice>>=^{PronChoice}}}{vector<quasar::PronChoice, std::allocator<quasar::PronChoice>>=^{PronChoice}^{PronChoice}{__compressed_pair<quasar::PronChoice *, std::allocator<quasar::PronChoice>>=^{PronChoice}}}}16@0:8
@64@0:8@16@24@32@40@48q56
{unique_ptr<quasar::KeywordFinder, std::default_delete<quasar::KeywordFinder>>="__ptr_"{__compressed_pair<quasar::KeywordFinder *, std::default_delete<quasar::KeywordFinder>>="__value_"^{KeywordFinder}}}
@32@0:8@16Q24
@24@0:8@?16
@"NSURL"
v32@0:8@16@?24
v40@0:8@16@24@?32
{map<std::string, std::vector<std::vector<quasar::LmeDataFactoryBase::Word>>, std::less<std::string>, std::allocator<std::pair<const std::string, std::vector<std::vector<quasar::LmeDataFactoryBase::Word>>>>>={__tree<std::__value_type<std::string, std::vector<std::vector<quasar::LmeDataFactoryBase::Word>>>, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<std::vector<quasar::LmeDataFactoryBase::Word>>>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::vector<std::vector<quasar::LmeDataFactoryBase::Word>>>>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::vector<std::vector<quasar::LmeDataFactoryBase::Word>>>, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<std::vector<quasar::LmeDataFactoryBase::Word>>>, std::less<std::string>, true>>=Q}}}16@0:8
{unordered_map<std::string, double, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<const std::string, double>>>={__hash_table<std::__hash_value_type<std::string, double>, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, double>, std::hash<std::string>, std::equal_to<std::string>, true>, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, double>, std::equal_to<std::string>, std::hash<std::string>, true>, std::allocator<std::__hash_value_type<std::string, double>>>={unique_ptr<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, double>, void *> *> *[], std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, double>, void *> *> *>>>={__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, double>, void *> *> **, std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, double>, void *> *> *>>>=^^v{__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, double>, void *> *> *>>={__compressed_pair<unsigned long, std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, double>, void *> *> *>>=Q}}}}{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, double>, void *> *>, std::allocator<std::__hash_node<std::__hash_value_type<std::string, double>, void *>>>={__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, double>, void *> *>=^v}}{__compressed_pair<unsigned long, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, double>, std::hash<std::string>, std::equal_to<std::string>, true>>=Q}{__compressed_pair<float, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, double>, std::equal_to<std::string>, std::hash<std::string>, true>>=f}}}16@0:8
{shared_ptr<quasar::ContextualData>="__ptr_"^{ContextualData}"__cntrl_"^{__shared_weak_count}}
{optional<std::string>=(?=c{basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}})B}16@0:8
@32@0:8{basic_string_view<char, std::char_traits<char>>=*Q}16
@"NSLocale"
v40@0:8Q16@24@32
v44@0:8Q16@24@32B40
v32@0:8Q16@24
v32@0:8Q16@?24
{shared_ptr<quasar::PersonalizedLmData>=^{PersonalizedLmData}^{__shared_weak_count}}16@0:8
{shared_ptr<quasar::PersonalizedLmData>="__ptr_"^{PersonalizedLmData}"__cntrl_"^{__shared_weak_count}}
@32@0:8{shared_ptr<quasar::LmModel2>=^{LmModel2}^{__shared_weak_count}}16
B32@0:8@16@?24
{shared_ptr<quasar::LmModel2>=^{LmModel2}^{__shared_weak_count}}16@0:8
{shared_ptr<quasar::LmBuildConfig>=^{LmBuildConfig}^{__shared_weak_count}}16@0:8
{shared_ptr<quasar::LmModel2>="__ptr_"^{LmModel2}"__cntrl_"^{__shared_weak_count}}
{shared_ptr<quasar::LmBuildConfig>="__ptr_"^{LmBuildConfig}"__cntrl_"^{__shared_weak_count}}
@48@0:8{shared_ptr<quasar::NgramLmModel2>=^{NgramLmModel2}^{__shared_weak_count}}16{shared_ptr<quasar::NgramFstConfig>=^{NgramFstConfig}^{__shared_weak_count}}32
{shared_ptr<quasar::NgramLmModel2>=^{NgramLmModel2}^{__shared_weak_count}}16@0:8
{shared_ptr<quasar::NgramFstConfig>=^{NgramFstConfig}^{__shared_weak_count}}16@0:8
{shared_ptr<quasar::NgramLmModel2>="__ptr_"^{NgramLmModel2}"__cntrl_"^{__shared_weak_count}}
{shared_ptr<quasar::NgramFstConfig>="__ptr_"^{NgramFstConfig}"__cntrl_"^{__shared_weak_count}}
@32@0:8{shared_ptr<quasar::NgramLmModel2>=^{NgramLmModel2}^{__shared_weak_count}}16
@56@0:8@16@24@32@40@?48
B40@0:8@16@24^@32
B48@0:8@16@24^@32^f40
B56@0:8@16@24@?32^@40^f48
{shared_ptr<quasar::LmEvaluator>="__ptr_"^{LmEvaluator}"__cntrl_"^{__shared_weak_count}}
{shared_ptr<quasar::LmLoader2>="__ptr_"^{LmLoader2}"__cntrl_"^{__shared_weak_count}}
@32@0:8{shared_ptr<quasar::AppLmData>=^{AppLmData}^{__shared_weak_count}}16
B36@0:8@16@24B32
q36@0:8@16@24B32
q32@0:8@16@24
{shared_ptr<quasar::AppLmData>=^{AppLmData}^{__shared_weak_count}}16@0:8
{shared_ptr<quasar::AppLmData>="__ptr_"^{AppLmData}"__cntrl_"^{__shared_weak_count}}
B44@0:8@16@24f32^@36
{unique_ptr<quasar::CustomLMBuilder, std::default_delete<quasar::CustomLMBuilder>>="__ptr_"{__compressed_pair<quasar::CustomLMBuilder *, std::default_delete<quasar::CustomLMBuilder>>="__value_"^{CustomLMBuilder}}}
{unique_ptr<sdapi::SdapiTokenizer, std::default_delete<sdapi::SdapiTokenizer>>="__ptr_"{__compressed_pair<sdapi::SdapiTokenizer *, std::default_delete<sdapi::SdapiTokenizer>>="__value_"^{SdapiTokenizer}}}
@48@0:8@16@24Q32@40
@56@0:8@16@24Q32@40@48
{shared_ptr<quasar::PSRAudioProcessor>="__ptr_"^{PSRAudioProcessor}"__cntrl_"^{__shared_weak_count}}
{SystemConfig="_vptr$OptionsItf"^^?"info"{SystemConfigInfo="jsonConfigFilePath"{basic_string<char, std::char_traits<char>, std::allocator<char>>="__r_"{__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>="__value_"{__rep=""(?="__l"{__long="__cap_"Q"__size_"Q"__data_"*}"__s"{__short=""(?="__size_"C"__lx"c)"__data_"[23c]}"__r"{__raw="__words"[3Q]})}}}"configFileVersion"{Version="versionMajor"i"versionMinor"i}"configPath"{Path="_vptr$Path"^^?"str"{basic_string<char, std::char_traits<char>, std::allocator<char>>="__r_"{__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>="__value_"{__rep=""(?="__l"{__long="__cap_"Q"__size_"Q"__data_"*}"__s"{__short=""(?="__size_"C"__lx"c)"__data_"[23c]}"__r"{__raw="__words"[3Q]})}}}}"pTree"{PTree="dataType"i"dataValue"{basic_string<char, std::char_traits<char>, std::allocator<char>>="__r_"{__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>="__value_"{__rep=""(?="__l"{__long="__cap_"Q"__size_"Q"__data_"*}"__s"{__short=""(?="__size_"C"__lx"c)"__data_"[23c]}"__r"{__raw="__words"[3Q]})}}}"map"{vector<std::pair<std::string, quasar::PTree>, std::allocator<std::pair<std::string, quasar::PTree>>>="__begin_"^v"__end_"^v"__end_cap_"{__compressed_pair<std::pair<std::string, quasar::PTree> *, std::allocator<std::pair<std::string, quasar::PTree>>>="__value_"^v}}"isALeaf"B}"speechModelInfo"{SpeechModelInfo="version"{basic_string<char, std::char_traits<char>, std::allocator<char>>="__r_"{__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>="__value_"{__rep=""(?="__l"{__long="__cap_"Q"__size_"Q"__data_"*}"__s"{__short=""(?="__size_"C"__lx"c)"__data_"[23c]}"__r"{__raw="__words"[3Q]})}}}"samplingRates"{set<int, std::less<int>, std::allocator<int>>="__tree_"{__tree<int, std::less<int>, std::allocator<int>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<int, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::less<int>>="__value_"Q}}}"tasks"{set<std::string, std::less<std::string>, std::allocator<std::string>>="__tree_"{__tree<std::string, std::less<std::string>, std::allocator<std::string>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::string, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::less<std::string>>="__value_"Q}}}"osTypes"{set<std::string, std::less<std::string>, std::allocator<std::string>>="__tree_"{__tree<std::string, std::less<std::string>, std::allocator<std::string>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::string, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::less<std::string>>="__value_"Q}}}"language"{basic_string<char, std::char_traits<char>, std::allocator<char>>="__r_"{__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>="__value_"{__rep=""(?="__l"{__long="__cap_"Q"__size_"Q"__data_"*}"__s"{__short=""(?="__size_"C"__lx"c)"__data_"[23c]}"__r"{__raw="__words"[3Q]})}}}"phoneSetVersion"{basic_string<char, std::char_traits<char>, std::allocator<char>>="__r_"{__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>="__value_"{__rep=""(?="__l"{__long="__cap_"Q"__size_"Q"__data_"*}"__s"{__short=""(?="__size_"C"__lx"c)"__data_"[23c]}"__r"{__raw="__words"[3Q]})}}}"acousticProfileVersion"{basic_string<char, std::char_traits<char>, std::allocator<char>>="__r_"{__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>="__value_"{__rep=""(?="__l"{__long="__cap_"Q"__size_"Q"__data_"*}"__s"{__short=""(?="__size_"C"__lx"c)"__data_"[23c]}"__r"{__raw="__words"[3Q]})}}}"aceToQuasarTemplate"{map<std::string, std::string, std::less<std::string>, std::allocator<std::pair<const std::string, std::string>>>="__tree_"{__tree<std::__value_type<std::string, std::string>, std::__map_value_compare<std::string, std::__value_type<std::string, std::string>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::string>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::string>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::string>, std::less<std::string>, true>>="__value_"Q}}}"quasarTemplateToAce"{map<std::string, std::vector<std::string>, std::less<std::string>, std::allocator<std::pair<const std::string, std::vector<std::string>>>>="__tree_"{__tree<std::__value_type<std::string, std::vector<std::string>>, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<std::string>>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::vector<std::string>>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::vector<std::string>>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<std::string>>, std::less<std::string>, true>>="__value_"Q}}}"quasarTemplateToEnumerationType"{map<std::string, std::string, std::less<std::string>, std::allocator<std::pair<const std::string, std::string>>>="__tree_"{__tree<std::__value_type<std::string, std::string>, std::__map_value_compare<std::string, std::__value_type<std::string, std::string>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::string>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::string>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::string>, std::less<std::string>, true>>="__value_"Q}}}"g2pModelVersion"i"hybridEndpointerVersion"i}"translationModelInfo"{TranslationModelInfo="version"{basic_string<char, std::char_traits<char>, std::allocator<char>>="__r_"{__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>="__value_"{__rep=""(?="__l"{__long="__cap_"Q"__size_"Q"__data_"*}"__s"{__short=""(?="__size_"C"__lx"c)"__data_"[23c]}"__r"{__raw="__words"[3Q]})}}}"tasks"{set<std::string, std::less<std::string>, std::allocator<std::string>>="__tree_"{__tree<std::string, std::less<std::string>, std::allocator<std::string>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::string, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::less<std::string>>="__value_"Q}}}"languagePairs"{vector<std::pair<std::string, std::string>, std::allocator<std::pair<std::string, std::string>>>="__begin_"^v"__end_"^v"__end_cap_"{__compressed_pair<std::pair<std::string, std::string> *, std::allocator<std::pair<std::string, std::string>>>="__value_"^v}}"taskSpecificLanguagePairs"{unordered_map<std::string, std::vector<std::pair<std::string, std::string>>, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<const std::string, std::vector<std::pair<std::string, std::string>>>>>="__table_"{__hash_table<std::__hash_value_type<std::string, std::vector<std::pair<std::string, std::string>>>, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, std::vector<std::pair<std::string, std::string>>>, std::hash<std::string>, std::equal_to<std::string>, true>, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, std::vector<std::pair<std::string, std::string>>>, std::equal_to<std::string>, std::hash<std::string>, true>, std::allocator<std::__hash_value_type<std::string, std::vector<std::pair<std::string, std::string>>>>>="__bucket_list_"{unique_ptr<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::vector<std::pair<std::string, std::string>>>, void *> *> *[], std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::vector<std::pair<std::string, std::string>>>, void *> *> *>>>="__ptr_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::vector<std::pair<std::string, std::string>>>, void *> *> **, std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::vector<std::pair<std::string, std::string>>>, void *> *> *>>>="__value_"^^v"__value_"{__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::vector<std::pair<std::string, std::string>>>, void *> *> *>>="__data_"{__compressed_pair<unsigned long, std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::vector<std::pair<std::string, std::string>>>, void *> *> *>>="__value_"Q}}}}"__p1_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::vector<std::pair<std::string, std::string>>>, void *> *>, std::allocator<std::__hash_node<std::__hash_value_type<std::string, std::vector<std::pair<std::string, std::string>>>, void *>>>="__value_"{__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::vector<std::pair<std::string, std::string>>>, void *> *>="__next_"^v}}"__p2_"{__compressed_pair<unsigned long, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, std::vector<std::pair<std::string, std::string>>>, std::hash<std::string>, std::equal_to<std::string>, true>>="__value_"Q}"__p3_"{__compressed_pair<float, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, std::vector<std::pair<std::string, std::string>>>, std::equal_to<std::string>, std::hash<std::string>, true>>="__value_"f}}}"pairSpecificSettings"{unordered_map<std::string, quasar::TranslationPairSetting, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<const std::string, quasar::TranslationPairSetting>>>="__table_"{__hash_table<std::__hash_value_type<std::string, quasar::TranslationPairSetting>, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, quasar::TranslationPairSetting>, std::hash<std::string>, std::equal_to<std::string>, true>, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, quasar::TranslationPairSetting>, std::equal_to<std::string>, std::hash<std::string>, true>, std::allocator<std::__hash_value_type<std::string, quasar::TranslationPairSetting>>>="__bucket_list_"{unique_ptr<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, quasar::TranslationPairSetting>, void *> *> *[], std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, quasar::TranslationPairSetting>, void *> *> *>>>="__ptr_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, quasar::TranslationPairSetting>, void *> *> **, std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, quasar::TranslationPairSetting>, void *> *> *>>>="__value_"^^v"__value_"{__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, quasar::TranslationPairSetting>, void *> *> *>>="__data_"{__compressed_pair<unsigned long, std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, quasar::TranslationPairSetting>, void *> *> *>>="__value_"Q}}}}"__p1_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, quasar::TranslationPairSetting>, void *> *>, std::allocator<std::__hash_node<std::__hash_value_type<std::string, quasar::TranslationPairSetting>, void *>>>="__value_"{__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, quasar::TranslationPairSetting>, void *> *>="__next_"^v}}"__p2_"{__compressed_pair<unsigned long, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, quasar::TranslationPairSetting>, std::hash<std::string>, std::equal_to<std::string>, true>>="__value_"Q}"__p3_"{__compressed_pair<float, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, quasar::TranslationPairSetting>, std::equal_to<std::string>, std::hash<std::string>, true>>="__value_"f}}}"taskLangPairSpecificSettings"{unordered_map<std::string, std::unordered_map<std::string, quasar::TranslationPairSetting>, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<const std::string, std::unordered_map<std::string, quasar::TranslationPairSetting>>>>="__table_"{__hash_table<std::__hash_value_type<std::string, std::unordered_map<std::string, quasar::TranslationPairSetting>>, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, std::unordered_map<std::string, quasar::TranslationPairSetting>>, std::hash<std::string>, std::equal_to<std::string>, true>, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, std::unordered_map<std::string, quasar::TranslationPairSetting>>, std::equal_to<std::string>, std::hash<std::string>, true>, std::allocator<std::__hash_value_type<std::string, std::unordered_map<std::string, quasar::TranslationPairSetting>>>>="__bucket_list_"{unique_ptr<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::unordered_map<std::string, quasar::TranslationPairSetting>>, void *> *> *[], std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::unordered_map<std::string, quasar::TranslationPairSetting>>, void *> *> *>>>="__ptr_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::unordered_map<std::string, quasar::TranslationPairSetting>>, void *> *> **, std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::unordered_map<std::string, quasar::TranslationPairSetting>>, void *> *> *>>>="__value_"^^v"__value_"{__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::unordered_map<std::string, quasar::TranslationPairSetting>>, void *> *> *>>="__data_"{__compressed_pair<unsigned long, std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::unordered_map<std::string, quasar::TranslationPairSetting>>, void *> *> *>>="__value_"Q}}}}"__p1_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::unordered_map<std::string, quasar::TranslationPairSetting>>, void *> *>, std::allocator<std::__hash_node<std::__hash_value_type<std::string, std::unordered_map<std::string, quasar::TranslationPairSetting>>, void *>>>="__value_"{__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::unordered_map<std::string, quasar::TranslationPairSetting>>, void *> *>="__next_"^v}}"__p2_"{__compressed_pair<unsigned long, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, std::unordered_map<std::string, quasar::TranslationPairSetting>>, std::hash<std::string>, std::equal_to<std::string>, true>>="__value_"Q}"__p3_"{__compressed_pair<float, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, std::unordered_map<std::string, quasar::TranslationPairSetting>>, std::equal_to<std::string>, std::hash<std::string>, true>>="__value_"f}}}"taskAlias"{unordered_map<std::string, std::string, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<const std::string, std::string>>>="__table_"{__hash_table<std::__hash_value_type<std::string, std::string>, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, std::string>, std::hash<std::string>, std::equal_to<std::string>, true>, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, std::string>, std::equal_to<std::string>, std::hash<std::string>, true>, std::allocator<std::__hash_value_type<std::string, std::string>>>="__bucket_list_"{unique_ptr<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *> *> *[], std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *> *> *>>>="__ptr_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *> *> **, std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *> *> *>>>="__value_"^^v"__value_"{__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *> *> *>>="__data_"{__compressed_pair<unsigned long, std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *> *> *>>="__value_"Q}}}}"__p1_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *> *>, std::allocator<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *>>>="__value_"{__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *> *>="__next_"^v}}"__p2_"{__compressed_pair<unsigned long, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, std::string>, std::hash<std::string>, std::equal_to<std::string>, true>>="__value_"Q}"__p3_"{__compressed_pair<float, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, std::string>, std::equal_to<std::string>, std::hash<std::string>, true>>="__value_"f}}}}"hybridClientConfigs"{HybridClientConfigs="hybridEndpointerThresholds"{map<int, std::map<std::string, double>, std::less<int>, std::allocator<std::pair<const int, std::map<std::string, double>>>>="__tree_"{__tree<std::__value_type<int, std::map<std::string, double>>, std::__map_value_compare<int, std::__value_type<int, std::map<std::string, double>>, std::less<int>, true>, std::allocator<std::__value_type<int, std::map<std::string, double>>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<int, std::map<std::string, double>>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<int, std::__value_type<int, std::map<std::string, double>>, std::less<int>, true>>="__value_"Q}}}"hybridEndpointerExtraDelayFrequency"{map<std::string, int, std::less<std::string>, std::allocator<std::pair<const std::string, int>>>="__tree_"{__tree<std::__value_type<std::string, int>, std::__map_value_compare<std::string, std::__value_type<std::string, int>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, int>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, int>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, int>, std::less<std::string>, true>>="__value_"Q}}}}"configType"i"requiredAbsolutePaths"{unordered_set<std::string, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::string>>="__table_"{__hash_table<std::string, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::string>>="__bucket_list_"{unique_ptr<std::__hash_node_base<std::__hash_node<std::string, void *> *> *[], std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::string, void *> *> *>>>="__ptr_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::string, void *> *> **, std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::string, void *> *> *>>>="__value_"^^v"__value_"{__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::string, void *> *> *>>="__data_"{__compressed_pair<unsigned long, std::allocator<std::__hash_node_base<std::__hash_node<std::string, void *> *> *>>="__value_"Q}}}}"__p1_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::string, void *> *>, std::allocator<std::__hash_node<std::string, void *>>>="__value_"{__hash_node_base<std::__hash_node<std::string, void *> *>="__next_"^v}}"__p2_"{__compressed_pair<unsigned long, std::hash<std::string>>="__value_"Q}"__p3_"{__compressed_pair<float, std::equal_to<std::string>>="__value_"f}}}"optionalAbsolutePaths"{unordered_set<std::string, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::string>>="__table_"{__hash_table<std::string, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::string>>="__bucket_list_"{unique_ptr<std::__hash_node_base<std::__hash_node<std::string, void *> *> *[], std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::string, void *> *> *>>>="__ptr_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::string, void *> *> **, std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::string, void *> *> *>>>="__value_"^^v"__value_"{__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::string, void *> *> *>>="__data_"{__compressed_pair<unsigned long, std::allocator<std::__hash_node_base<std::__hash_node<std::string, void *> *> *>>="__value_"Q}}}}"__p1_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::string, void *> *>, std::allocator<std::__hash_node<std::string, void *>>>="__value_"{__hash_node_base<std::__hash_node<std::string, void *> *>="__next_"^v}}"__p2_"{__compressed_pair<unsigned long, std::hash<std::string>>="__value_"Q}"__p3_"{__compressed_pair<float, std::equal_to<std::string>>="__value_"f}}}}"prefix"{basic_string<char, std::char_traits<char>, std::allocator<char>>="__r_"{__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>="__value_"{__rep=""(?="__l"{__long="__cap_"Q"__size_"Q"__data_"*}"__s"{__short=""(?="__size_"C"__lx"c)"__data_"[23c]}"__r"{__raw="__words"[3Q]})}}}"modelLoader"{shared_ptr<quasar::ModelLoader>="__ptr_"^{ModelLoader}"__cntrl_"^{__shared_weak_count}}"mainModelVersion"{basic_string<char, std::char_traits<char>, std::allocator<char>>="__r_"{__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>="__value_"{__rep=""(?="__l"{__long="__cap_"Q"__size_"Q"__data_"*}"__s"{__short=""(?="__size_"C"__lx"c)"__data_"[23c]}"__r"{__raw="__words"[3Q]})}}}"mainSpeechModelInfo"{SpeechModelInfo="version"{basic_string<char, std::char_traits<char>, std::allocator<char>>="__r_"{__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>="__value_"{__rep=""(?="__l"{__long="__cap_"Q"__size_"Q"__data_"*}"__s"{__short=""(?="__size_"C"__lx"c)"__data_"[23c]}"__r"{__raw="__words"[3Q]})}}}"samplingRates"{set<int, std::less<int>, std::allocator<int>>="__tree_"{__tree<int, std::less<int>, std::allocator<int>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<int, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::less<int>>="__value_"Q}}}"tasks"{set<std::string, std::less<std::string>, std::allocator<std::string>>="__tree_"{__tree<std::string, std::less<std::string>, std::allocator<std::string>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::string, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::less<std::string>>="__value_"Q}}}"osTypes"{set<std::string, std::less<std::string>, std::allocator<std::string>>="__tree_"{__tree<std::string, std::less<std::string>, std::allocator<std::string>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::string, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::less<std::string>>="__value_"Q}}}"language"{basic_string<char, std::char_traits<char>, std::allocator<char>>="__r_"{__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>="__value_"{__rep=""(?="__l"{__long="__cap_"Q"__size_"Q"__data_"*}"__s"{__short=""(?="__size_"C"__lx"c)"__data_"[23c]}"__r"{__raw="__words"[3Q]})}}}"phoneSetVersion"{basic_string<char, std::char_traits<char>, std::allocator<char>>="__r_"{__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>="__value_"{__rep=""(?="__l"{__long="__cap_"Q"__size_"Q"__data_"*}"__s"{__short=""(?="__size_"C"__lx"c)"__data_"[23c]}"__r"{__raw="__words"[3Q]})}}}"acousticProfileVersion"{basic_string<char, std::char_traits<char>, std::allocator<char>>="__r_"{__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>="__value_"{__rep=""(?="__l"{__long="__cap_"Q"__size_"Q"__data_"*}"__s"{__short=""(?="__size_"C"__lx"c)"__data_"[23c]}"__r"{__raw="__words"[3Q]})}}}"aceToQuasarTemplate"{map<std::string, std::string, std::less<std::string>, std::allocator<std::pair<const std::string, std::string>>>="__tree_"{__tree<std::__value_type<std::string, std::string>, std::__map_value_compare<std::string, std::__value_type<std::string, std::string>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::string>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::string>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::string>, std::less<std::string>, true>>="__value_"Q}}}"quasarTemplateToAce"{map<std::string, std::vector<std::string>, std::less<std::string>, std::allocator<std::pair<const std::string, std::vector<std::string>>>>="__tree_"{__tree<std::__value_type<std::string, std::vector<std::string>>, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<std::string>>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::vector<std::string>>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::vector<std::string>>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<std::string>>, std::less<std::string>, true>>="__value_"Q}}}"quasarTemplateToEnumerationType"{map<std::string, std::string, std::less<std::string>, std::allocator<std::pair<const std::string, std::string>>>="__tree_"{__tree<std::__value_type<std::string, std::string>, std::__map_value_compare<std::string, std::__value_type<std::string, std::string>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::string>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::string>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::string>, std::less<std::string>, true>>="__value_"Q}}}"g2pModelVersion"i"hybridEndpointerVersion"i}"boolMap"{map<std::string, bool *, std::less<std::string>, std::allocator<std::pair<const std::string, bool *>>>="__tree_"{__tree<std::__value_type<std::string, bool *>, std::__map_value_compare<std::string, std::__value_type<std::string, bool *>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, bool *>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, bool *>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, bool *>, std::less<std::string>, true>>="__value_"Q}}}"intMap"{map<std::string, int *, std::less<std::string>, std::allocator<std::pair<const std::string, int *>>>="__tree_"{__tree<std::__value_type<std::string, int *>, std::__map_value_compare<std::string, std::__value_type<std::string, int *>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, int *>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, int *>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, int *>, std::less<std::string>, true>>="__value_"Q}}}"uintMap"{map<std::string, unsigned int *, std::less<std::string>, std::allocator<std::pair<const std::string, unsigned int *>>>="__tree_"{__tree<std::__value_type<std::string, unsigned int *>, std::__map_value_compare<std::string, std::__value_type<std::string, unsigned int *>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, unsigned int *>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, unsigned int *>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, unsigned int *>, std::less<std::string>, true>>="__value_"Q}}}"int64Map"{map<std::string, long long *, std::less<std::string>, std::allocator<std::pair<const std::string, long long *>>>="__tree_"{__tree<std::__value_type<std::string, long long *>, std::__map_value_compare<std::string, std::__value_type<std::string, long long *>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, long long *>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, long long *>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, long long *>, std::less<std::string>, true>>="__value_"Q}}}"floatMap"{map<std::string, float *, std::less<std::string>, std::allocator<std::pair<const std::string, float *>>>="__tree_"{__tree<std::__value_type<std::string, float *>, std::__map_value_compare<std::string, std::__value_type<std::string, float *>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, float *>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, float *>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, float *>, std::less<std::string>, true>>="__value_"Q}}}"doubleMap"{map<std::string, double *, std::less<std::string>, std::allocator<std::pair<const std::string, double *>>>="__tree_"{__tree<std::__value_type<std::string, double *>, std::__map_value_compare<std::string, std::__value_type<std::string, double *>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, double *>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, double *>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, double *>, std::less<std::string>, true>>="__value_"Q}}}"stringMap"{map<std::string, std::string *, std::less<std::string>, std::allocator<std::pair<const std::string, std::string *>>>="__tree_"{__tree<std::__value_type<std::string, std::string *>, std::__map_value_compare<std::string, std::__value_type<std::string, std::string *>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::string *>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::string *>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::string *>, std::less<std::string>, true>>="__value_"Q}}}"stringVecMap"{map<std::string, std::vector<std::string> *, std::less<std::string>, std::allocator<std::pair<const std::string, std::vector<std::string> *>>>="__tree_"{__tree<std::__value_type<std::string, std::vector<std::string> *>, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<std::string> *>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::vector<std::string> *>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::vector<std::string> *>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<std::string> *>, std::less<std::string>, true>>="__value_"Q}}}"stringPairVecMap"{map<std::string, std::vector<std::pair<std::string, std::string>> *, std::less<std::string>, std::allocator<std::pair<const std::string, std::vector<std::pair<std::string, std::string>> *>>>="__tree_"{__tree<std::__value_type<std::string, std::vector<std::pair<std::string, std::string>> *>, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<std::pair<std::string, std::string>> *>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::vector<std::pair<std::string, std::string>> *>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::vector<std::pair<std::string, std::string>> *>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<std::pair<std::string, std::string>> *>, std::less<std::string>, true>>="__value_"Q}}}"stringUnorderedSetMap"{map<std::string, std::unordered_set<std::string> *, std::less<std::string>, std::allocator<std::pair<const std::string, std::unordered_set<std::string> *>>>="__tree_"{__tree<std::__value_type<std::string, std::unordered_set<std::string> *>, std::__map_value_compare<std::string, std::__value_type<std::string, std::unordered_set<std::string> *>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::unordered_set<std::string> *>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::unordered_set<std::string> *>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::unordered_set<std::string> *>, std::less<std::string>, true>>="__value_"Q}}}"paramMinVersionMap"{map<std::string, quasar::SystemConfig::Version, std::less<std::string>, std::allocator<std::pair<const std::string, quasar::SystemConfig::Version>>>="__tree_"{__tree<std::__value_type<std::string, quasar::SystemConfig::Version>, std::__map_value_compare<std::string, std::__value_type<std::string, quasar::SystemConfig::Version>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, quasar::SystemConfig::Version>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, quasar::SystemConfig::Version>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, quasar::SystemConfig::Version>, std::less<std::string>, true>>="__value_"Q}}}"paramMaxVersionMap"{map<std::string, quasar::SystemConfig::Version, std::less<std::string>, std::allocator<std::pair<const std::string, quasar::SystemConfig::Version>>>="__tree_"{__tree<std::__value_type<std::string, quasar::SystemConfig::Version>, std::__map_value_compare<std::string, std::__value_type<std::string, quasar::SystemConfig::Version>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, quasar::SystemConfig::Version>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, quasar::SystemConfig::Version>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, quasar::SystemConfig::Version>, std::less<std::string>, true>>="__value_"Q}}}"requiredParams"{map<std::string, std::set<std::string>, std::less<std::string>, std::allocator<std::pair<const std::string, std::set<std::string>>>>="__tree_"{__tree<std::__value_type<std::string, std::set<std::string>>, std::__map_value_compare<std::string, std::__value_type<std::string, std::set<std::string>>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::set<std::string>>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::set<std::string>>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::set<std::string>>, std::less<std::string>, true>>="__value_"Q}}}"state"i}
@"<EARPSRAudioProcessorDelegate>"
@24@0:8^{EARCSpeechRecognitionResultStream=^v^?^?^?^?^?}16
{EARCSpeechRecognitionResultStream="ctx"^v"DisposeContext"^?"DidRecognizePartialResultTokens"^?"DidFinishRecognitionWithError"^?"DidRecognizeFinalResults"^?"DidProcessAudioDuration"^?}
{shared_ptr<quasar::RecogAudioBuffer>="__ptr_"^{RecogAudioBuffer}"__cntrl_"^{__shared_weak_count}}
@36@0:8@16f24B28B32
@40@0:8@16f24f28B32B36
{shared_ptr<quasar::artifact::Artifact>="__ptr_"^{Artifact}"__cntrl_"^{__shared_weak_count}}
B48@0:8@16@24@32@40
B64@0:8@16@24@32@40@48@56
@68@0:8@16Q24@32@40@48@56B64
B76@0:8@16Q24@32@40@48@56B64@68
@32@0:8{shared_ptr<quasar::artifact::AppLmArtifact>=^{AppLmArtifact}^{__shared_weak_count}}16
{shared_ptr<quasar::AppLmData>=^{AppLmData}^{__shared_weak_count}}40@0:8@16@24@32
v56@0:8{shared_ptr<quasar::AppLmData>=^{AppLmData}^{__shared_weak_count}}16@32@40@48
B40@0:8@16@24@32
@40@0:8@16q24@32
@"EMFEmojiPreferencesClient"
@"EMFEmojiLocaleData"
^{__EmojiLocaleDataWrapper=}
@40@0:8@16Q24Q32
{shared_ptr<quasar::SyncPSRAudioProcessor>="__ptr_"^{SyncPSRAudioProcessor}"__cntrl_"^{__shared_weak_count}}
@"NSMutableData"
@"<EARAudioResultsGeneratorDelegate>"
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
@44@0:8@16c24@28@36
c16@0:8
@36@0:8@16@24B32
@44@0:8@16@24B32q36
v48@0:8@16@24@32@?40
v56@0:8@16@24@32@40@?48
v36@0:8@16B24@?28
v44@0:8@16B24@28@?36
{vector<std::string, std::allocator<std::string>>=^v^v{__compressed_pair<std::string *, std::allocator<std::string>>=^v}}24@0:8@16
v60@0:8{vector<std::string, std::allocator<std::string>>=^v^v{__compressed_pair<std::string *, std::allocator<std::string>>=^v}}16B40@44@?52
{shared_ptr<quasar::TranslatorFactory>="__ptr_"^{TranslatorFactory}"__cntrl_"^{__shared_weak_count}}
{shared_ptr<quasar::Translator>="__ptr_"^{Translator}"__cntrl_"^{__shared_weak_count}}
{vector<quasar::SystemConfig, std::allocator<quasar::SystemConfig>>="__begin_"^{SystemConfig}"__end_"^{SystemConfig}"__end_cap_"{__compressed_pair<quasar::SystemConfig *, std::allocator<quasar::SystemConfig>>="__value_"^{SystemConfig}}}
@"NSOperationQueue"
@32@0:8d16d24
{unique_ptr<quasar::Geography, std::default_delete<quasar::Geography>>="__ptr_"{__compressed_pair<quasar::Geography *, std::default_delete<quasar::Geography>>="__value_"^{Geography}}}
@"NSIndexSet"
@36@0:8c16@20@28
v28@0:8@16f24
{vector<std::pair<id<_EARLanguageModelDataSource>, float>, std::allocator<std::pair<id<_EARLanguageModelDataSource>, float>>>="__begin_"^v"__end_"^v"__end_cap_"{__compressed_pair<std::pair<id<_EARLanguageModelDataSource>, float> *, std::allocator<std::pair<id<_EARLanguageModelDataSource>, float>>>="__value_"^v}}
{shared_ptr<sentencepiece::SentencePieceProcessor>="__ptr_"^{SentencePieceProcessor}"__cntrl_"^{__shared_weak_count}}
B24@0:8r^v16
{vector<quasar::Token, std::allocator<quasar::Token>>=^{Token}^{Token}{__compressed_pair<quasar::Token *, std::allocator<quasar::Token>>=^{Token}}}24@0:8@16
{vector<quasar::Token, std::allocator<quasar::Token>>=^{Token}^{Token}{__compressed_pair<quasar::Token *, std::allocator<quasar::Token>>=^{Token}}}28@0:8@16I24
@44@0:8@16@24B32@36
@48@0:8@16@24B32@36B44
B36@0:8r^v16r^v24S32
{vector<quasar::Token, std::allocator<quasar::Token>>=^{Token}^{Token}{__compressed_pair<quasar::Token *, std::allocator<quasar::Token>>=^{Token}}}32@0:8r^v16^v24
{vector<quasar::Token, std::allocator<quasar::Token>>=^{Token}^{Token}{__compressed_pair<quasar::Token *, std::allocator<quasar::Token>>=^{Token}}}40@0:8r^v16^v24@32
{vector<quasar::Token, std::allocator<quasar::Token>>=^{Token}^{Token}{__compressed_pair<quasar::Token *, std::allocator<quasar::Token>>=^{Token}}}184@0:8r^v16^v24@32@40r^v48B56^v60I68B72{shared_ptr<quasar::ContinuousListeningConfig>=^{ContinuousListeningConfig}^{__shared_weak_count}}76r^v92^v100r^v108S116B120B124r^v128^v136B144B148{shared_ptr<bool>=^B^{__shared_weak_count}}152B168i172@?176
v44@0:8^v16B24^v28B36i40
{vector<quasar::Token, std::allocator<quasar::Token>>=^{Token}^{Token}{__compressed_pair<quasar::Token *, std::allocator<quasar::Token>>=^{Token}}}36@0:8r^v16r^v24B32
v60@0:8r^v16r^v24^v32^v40r^v48B56
@40@0:8@16@24B32B36
{basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}24@0:8r^v16
@44@0:8@16@24@32B40
@52@0:8@16@24@32B40@44
{unique_ptr<SpeechITN, std::default_delete<SpeechITN>>="__ptr_"{__compressed_pair<SpeechITN *, std::default_delete<SpeechITN>>="__value_"^{SpeechITN}}}
@"_EAREmojiRecognition"
@"NSMutableDictionary"
@48@0:8@16@24f32B36@40
@"_EARUserProfileBuilder"
@32@0:8{shared_ptr<quasar::CustomPronData>=^{CustomPronData}^{__shared_weak_count}}16
{shared_ptr<quasar::CustomPronData>=^{CustomPronData}^{__shared_weak_count}}16@0:8
v32@0:8{shared_ptr<quasar::CustomPronData>=^{CustomPronData}^{__shared_weak_count}}16
{shared_ptr<quasar::CustomPronData>="__ptr_"^{CustomPronData}"__cntrl_"^{__shared_weak_count}}
@64@0:8@16@24Q32@40@48q56
@68@0:8@16@24Q32@40@48q56B64
@"<EARSyncPSRAudioProcessorDelegate>"
@32@0:8{shared_ptr<kaldi::quasar::LmHandle>=^{LmHandle}^{__shared_weak_count}}16
{shared_ptr<kaldi::quasar::LmHandle>=^{LmHandle}^{__shared_weak_count}}16@0:8
{shared_ptr<kaldi::quasar::LmHandle>="__ptr_"^{LmHandle}"__cntrl_"^{__shared_weak_count}}
@56@0:8d16d24d32d40d48
{shared_ptr<quasar::SilencePosteriorGenerator>="__ptr_"^{SilencePosteriorGenerator}"__cntrl_"^{__shared_weak_count}}
@"<EARCaesuraSilencePosteriorGeneratorDelegate>"
v80@0:8^@16^@24^@32^@40^@48^@56^@64@72
v80@0:8@16@24@32Q40Q48Q56Q64@72
v80@0:8@"NSString"16@"NSString"24@"NSString"32Q40Q48Q56Q64@"NSString"72
{shared_ptr<quasar::PhonesetMapping>="__ptr_"^{PhonesetMapping}"__cntrl_"^{__shared_weak_count}}
@"_EARLanguageDetectorRequestContext"
{vector<std::optional<quasar::language_detector::Locale>, std::allocator<std::optional<quasar::language_detector::Locale>>>=^v^v{__compressed_pair<std::optional<quasar::language_detector::Locale> *, std::allocator<std::optional<quasar::language_detector::Locale>>>=^v}}24@0:8@16
{shared_ptr<const quasar::LDContext>=^{LDContext}^{__shared_weak_count}}32@0:8r^v16r^v24
@40@0:8Q16@24@32
v20@0:8I16
{unique_ptr<quasar::LanguageDetector, std::default_delete<quasar::LanguageDetector>>="__ptr_"{__compressed_pair<quasar::LanguageDetector *, std::default_delete<quasar::LanguageDetector>>="__value_"^{LanguageDetector}}}
{unique_ptr<quasar::CommandTagging, std::default_delete<quasar::CommandTagging>>="__ptr_"{__compressed_pair<quasar::CommandTagging *, std::default_delete<quasar::CommandTagging>>="__value_"^{CommandTagging}}}
@32@0:8@16q24
@24@0:8q16
{unique_ptr<quasar::CommandTagger, std::default_delete<quasar::CommandTagger>>="__ptr_"{__compressed_pair<quasar::CommandTagger *, std::default_delete<quasar::CommandTagger>>="__value_"^{CommandTagger}}}
v56@0:8@16@24@32@40@48
v24@0:8@"NSXMLParser"16
v48@0:8@"NSXMLParser"16@"NSString"24@"NSString"32@"NSString"40
v56@0:8@"NSXMLParser"16@"NSString"24@"NSString"32@"NSString"40@"NSString"48
v40@0:8@"NSXMLParser"16@"NSString"24@"NSString"32
v56@0:8@"NSXMLParser"16@"NSString"24@"NSString"32@"NSString"40@"NSDictionary"48
v32@0:8@"NSXMLParser"16@"NSString"24
v32@0:8@"NSXMLParser"16@"NSData"24
@"NSData"40@0:8@"NSXMLParser"16@"NSString"24@"NSString"32
v32@0:8@"NSXMLParser"16@"NSError"24
@"NSMutableSet"
@"NSXMLParser"
@"NSMutableString"
{unique_ptr<quasar::TextTokenizer, std::default_delete<quasar::TextTokenizer>>={__compressed_pair<quasar::TextTokenizer *, std::default_delete<quasar::TextTokenizer>>=^{TextTokenizer}}}24@0:8@16
@"NLTagger"
v28@0:8B16@20
v24@0:8^v16
v32@0:8@16^{powerSummary=dddddddddddddd}24
{vector<void *, std::allocator<void *>>="__begin_"^^v"__end_"^^v"__end_cap_"{__compressed_pair<void **, std::allocator<void *>>="__value_"^^v}}
{powerSummary="total_energy"d"ane_energy"d"gpu_energy"d"ecpu_energy"d"pcpu_energy"d"dram_energy"d"other_energy"d"total_power"d"ane_power"d"gpu_power"d"ecpu_power"d"pcpu_power"d"dram_power"d"other_power"d}
mcpl
@(#)$Id: ngram-count.cc,v 1.78 2013/09/16 06:50:23 stolcke Exp $
@(#)$Id: residual-adapt.cc,v 1.78 2020/11/25 14:30:00 Amr Mousa Exp $
(|
L\
$`
$`
$`
$`
$`
$`
$`
$`
Configuration file %@ does not exist
EndpointerThreshold does not exist for clientModelVersion %u
EndpointerExtraDelayFrequency does not exist for task %@ and there is no default value returning nil
Texture coordinates (
) out of range
Bitmap coordinates (
) out of bounds
Computing pdf-priors from : 
 out of 
 classes have counts
 lower than 
--class-frame-counts is empty: Cannot initialize priors 
without the counts.
Dimensionality mismatch,
 class_frame_counts 
 pdf_output_llk 
Invalid pdf (
): log-prior dimension = 
<InputData>
<InputDataDim>
<InputDataShape>
<OutputData>
<OutputDataDim>
<OutputDataShape>
<InputExtraList>
<OutputExtraList>
<InputPenultimate>
<OutputPenultimate>
<OutputPenultimateDim>
<InputRequestedUnit>
<GraphReset>
<IsRNN>
<IsFOFE>
<Engine>
</Engine>
Unknown token 
, a typo in config file?
row_index >= 0 && col_index >= 0
!shape.empty()
.config
in != nullptr
out_vec.Dim() % row_num == 0
out_vec.Dim() == out_numrows * out_numcols
!out_node.empty()
Unimplemented TODO
the number of input tensors 
 != 
 , the list of input tensor names
you requested additional outputs, but haven't defined any tensors for that
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
ReadBasicType: encountered end of stream.
ReadBasicType: did not get expected integer type, 
 vs. 
.  You can change this code to successfully
 read it later, if needed.
Read failure in ReadBasicType, file position is 
, next char is 
Undefined filter document type: 
RECEIVED 
Reject due to sentence length
Reject due to token length
Reject due to document type
Reject due to document length
Reject due to sentences per document
lm-personalize.data
dictated
typed
unknown
QSR_CRASH_ON_WARN
wstring_convert: from_bytes error
expanded
mutable
error
acceptor
not acceptor
input deterministic
non input deterministic
output deterministic
non output deterministic
input/output epsilons
no input/output epsilons
input epsilons
no input epsilons
output epsilons
no output epsilons
input label sorted
not input label sorted
output label sorted
not output label sorted
weighted
unweighted
cyclic
acyclic
cyclic at initial state
acyclic at initial state
top sorted
not top sorted
accessible
not accessible
coaccessible
not coaccessible
string
not string
 -> 
Phone changed before final transition-id found [broken lattice or mismatched model or wrong --reorder option?]
FATAL
ERROR
ImplToFst: Assignment operator disallowed
Fst::Write: No write stream method for 
 Fst type
Fst::Write: No write filename method for 
vector
null
TestProperties: stored Fst properties incorrect
 (stored: props1, computed: props2)
CompatProperties: mismatch: 
: props1 = 
true
false
, props2 = 
VectorFst::Write: write failed: 
Inconsistent number of states observed during write
tropical
standard
compact
lattice4
Fst::UpdateFstHeader: write failed: 
Fst::Write: Can't open file: 
standard output
Trying to word-align empty lattice.
INFO
AutoQueue: using state-order discipline
AutoQueue: using top-order discipline
AutoQueue: using LIFO discipline
AutoQueue: using SCC meta-discipline
AutoQueue: SCC #
: using trivial discipline
: using shortest-first discipline
: using LIFO disciplle
: using FIFO disciplle
TopOrderQueue: fst is not acyclic.
RmEpsilon: inconsistent acyclic property bit
Prune: Weight needs to have the path property and
 be commutative: 
uapd
LME STREAM DUMP [Header]
LME STREAM DUMP 
: qsrHeader = 
Incorrect quasar blob header
: metaVersion = 
Incorrect quasar blob version
: dataTypeStr = 
Incorrect data type for Lme
Incorrect data type for UserAcusticProfileData
Incorrect data type for UserAcousticProfileData
: dataVersion = 
Was looking for B, but got 
Write failure in WriteBasicType.
loglikes
att_probs
beam 
 of 
, head 
: alignment too low: 
: head 
: location was 
Beam 
 has failed decoder checks 
 times; could num-forbidden-frames[-silence] be too low?
EncodingFinished()
Function is not implemented for this class
No frames output in pitch extraction
Pitch-tracking Viterbi cost is 
 per frame, over 
 frames.
Forward-cost per frame changed from 
 to 
Latency is 
Could not align output
Write failure in WriteIntegerType.
ReadIntegerVector: expected to see type of size 
, saw instead 
, at file position 
ReadIntegerVector: expected to see [, saw 
ReadIntegerVector: read failure at file position 
Silence label is set to 
 but does not match the auto-determined silence label 
. Will use latter.
Word alignment for MBR decoding failed.
Empty aligned lattice. MBR decoding failed.
Best-path failed
Lattice word alignment time: 
word-boundary-int-file
Word boundary file with format <integer-phone-id> [begin|end|singleton|internal|nonword]
unpronounced-word-file
File containing newline-separated list of words with no pronunciation.
max-expand
If >0, the max amount by which lattices will be expanded.
Could not read clock 
silence-label
Numeric id of word symbol that is to be used for silence arcs in the word-aligned lattice (zero is OK)
partial-word-label
Numeric id of word symbol that is to be used for arcs in the word-aligned lattice corresponding to partial words at the end of "forced-out" utterances (zero is OK)
reorder
True if the lattices were generated from graphs that had the --reorder option true, relating to reordering self-loops (typically true)
GCCacheStore: Enter GC: object = 
), free recently cached = 
, cache size = 
, cache frac = 
, cache limit = 
(size) <= (cache_size_)
../libquasar/libkaldi/tools/openfst/src/include/fst/cache.h
GCCacheStore:GC: Unable to free all cached states
GCCacheStore: Exit GC: object = 
Check failed: "
" file: 
 line: 
 000000000000
Could not convert
albums
artists
audiobooks
composers
genres
playlists
podcasts
songs
songs_artists
albums_artists
radiostations
movie_titles
tvshow_titles
phonetic-match-building
on-device-data-sources
ranking-method
most-recently-played
play-count
lg-fst-name
l-fst-name
g-osyms-name
%@.G.fst
%@.LG.fst
com.apple.siri
quasar.pm
SymbolTable::WriteText: Can't open file 
SymbolTable::Write: Can't open file 
<unspecified>
<RecurrentComponentType>
</Component>
, a typo in config?
 (RecurrentComponentType)
you defined two different recurrent component types 
 vs 
<InputDim>
<OutputDim>
this is not a recurrent component, initialization failed, you used 
Unrecognized token 
forward component is not an RNN
backward component is not an RNN
## Forward RNN: input-dim 
, output-dim 
## Backward RNN: input-dim 
Running forward propagation for batch size = 
, which contains 
 frames each from 
 utterances.
Running backward propagation for batch size = 
no recursive recurrent definition
the forward RNN's input dimension does not match the component's input dimension 
the backward RNN's input dimension does not match the component's input dimension 
the component has output dimension 
 , doesn't equal the sum of individual RNN 
 and 
This function is probably not meaningful for bidirectional RNNs.
need RecurrentNnetTrainOptions in recurrent style component, ignoring SetTrainOptions
Inconsistent return type: RecurrentBaseComponent::GetTrainOptions() can not be cast to RecurrentNnetTrainOptions
VectorizeWeightsCorrs
 is not implemented for 
 component.
Function not implemented for this class
GetUnitOutputFnc
GetNormalizedLearningRate
PerturbParams
GetGradient
Running on single input doesn't make sense for bidirectional RNNs, since history state is not saved.
Forward RNN is not quantizable
Backward RNN is not quantizable
create
/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/libquasar/liblm/src/fst_builder.cpp
Not implemented (
Unknown FstBuilder implementation: 
addState
build
Expected 
 states, but only observed 
 state(s).
 arcs, but only observed 
 arc(s).
FstBuilder
MutableFstBuilder
A mutable FST should be supplied when using 
addStateImpl
SqueezedFstBuilder
A stream should be supplied when using 
writeHeader
Aligned file format is currently not supported.
writeState
writeArc
Options(
implementation=
explicitStartEndMarkers=
keepDisambiguationSymbols=
removeRedundantStates=
attachSymbolTables=
mutableFst=
squeezedFst=
SqueezedOptions(
acceptor=
quantized=
stream=
MutableOptions(
fst=
squeezed
_acceptor
_transducer
AudioAdded
AudioEndPointedClient
AudioEndPointedServer
AudioMaxBufferLengthReached
decoders.
.lattice-biglm-lme-faster.supported-lme-template-list
Couldn't get supported LME list
oov-replacement value 
 is not a supported LME for specified decoder chain
slot-to-lme-map
Map from developer slots to LMEs
max-lme-per-utterance
The number of the max lme per utterance. Utterances containing more LME's will be dropped
Empty LME template for slot 
Utterance skipped as number of LMEs in utterance exceed threshold
Tokenizer failed to tokenize '
Failed to tokenize sentence
Can't add pronunciation for 
 (word is not OOV)
Pronunciation mapping failed
orthography=
 pronSize=
|\(|\)|"|\[|\]|\{|\}|
|,|;|\?|\!|\\
lmeDataFactory initialization with 
 failed
G2P initialization with 
No pronunciation for word 
. Falling back to G2P
No OOVs to add
Could not get LME data
Can't open 
 for writing
prons
frequency
app-lm.data
Error reading JSON config file: 
VoiceTrigger
WatermarkDetector not run on input origin 
WatermarkDetector: not enough audio cached.
Failed to compute spectrogram.
WatermarkPeakAvg
WatermarkPeakMax
WatermarkDetected
WatermarkDetector peakMax=
, peakAvg=
, detected=
watermark-detector
above-hi
Frequency (in Hz) of top of upper band
above-lo
Frequency (in Hz) of bottom of upper band
notch-hi
Frequency (in Hz) of top of notch
notch-lo
Frequency (in Hz) of bottom of notch
below-hi
Frequency (in Hz) of top of lower band
below-lo
Frequency (in Hz) of bottom of lower band
supported-input-origins-list
The input origins that are supported (should be comma separated)
watermark-threshold
Average notch threshold value to detect a watermark
povey
mincount %s
maxcount %s
discount %u %lf
mincount %99s
maxcount %99s
maxcount value out of range
discount %u %lf
warning: count value out of range
unrecognized parameter
warning: discount coefficient 
 = 0.0
Good-Turing discounting 
-grams
GT-count [
] = 
warning: no singleton counts
warning: count of count 
 is zero 
-- lowering maxcount
GT discounting disabled
 is zero
warning: discount coeff 
 is out of range: 
discount1 %lf
discount1 %lf
Kneser-Ney smoothing 
n1 = 
n2 = 
one of required KneserNey count-of-counts is zero
D = 
modifying 
-gram counts for Kneser-Ney smoothing
discount2 %lf
discount3+ %lf
discount2 %lf
discount3+ %lf
n3 = 
n4 = 
one of required modified KneserNey count-of-counts is zero
D1 = 
D2 = 
D3+ = 
one of modified KneserNey discounts is negative
discounting method does not support float counts
: Expected token 
, got 
Got EOF while reading matrix data
After end of matrix data, read error.
Stream failure/EOF while reading matrix data.
infinity
Reading negative infinite value into matrix.
Reading negative NaN value into matrix.
Expecting numeric matrix data, got 
Reading infinite value into matrix.
Reading NaN value into matrix.
 File position at start is 
, currently 
Failed to write vector to stream: stream not good
Processed 
s/(.*)/(.*)/(g|gI);
\\([1-9])
Invalid number of groups observed in regex
$$$1
Invalid regular expression: '
 in '
Loaded 
 rules.
Unable to open the file to read: '
max-radius-km
ContextDependency
ToPdf
EndContextDependency
ToLength
Got unexpected token 
 reading context-dependency object.
ContextDependency::GetPdfInfo, no pdfs returned for position 
 of phone 
.   Continuing but this is a serious error.
samplingRateFilter
taskTypeFilter
deviceIdFilter
farFieldFilter
bluetoothDeviceIdFilter
aneContextFilter
cpuContextFilter
gpuContextFilter
 = {
.bz2
warning: '-' used multiple times for input
warning: '-' used multiple times for output
exec compress -c
exec uncompress -c
exec gzip -c
exec gzip -dcf
exec bzip2
exec bzip2 -dcf
exec 7z a -si
exec 7z e -so
exec xz
exec xz -dcf
%s;%s %s
%s;%s >%s
Decoding ready artifact not compatible with speech model (datapack) version
Artifact in 
 stage will be transformed to 
 stage
transformedArtifact != nullptr && transformedArtifact->getLifeCycleStage() == AppLmArtifactLifeCycleStages::get().DECODING_READY
Artifact transformed to decoding readiness not compatible with speech model (datapack) version
language-model-weight
orth
freq
app-lm.data.oov-replacement
\unknown-first
app-lm.NGRAM
phrase-count
custom-prons
Artifact is in incorrect life cycle stage (
Target life cycle stage is invalid (
Unable to revert during the life cycle (from 
Unable to transform artifact beyond 
ngram-count
asr-datapack-version
language-model-fst
Something went wrong while serializing the FST model.
language-model-arpa
Something went wrong while serializing the ARPA model.
Unable to transform artifact to 
 stage.
tokenizer-datapack-version
Artifact transitioned into invalid life cycle stage (
ptree contains data that cannot be represented in JSON format
void boost::property_tree::json_parser::write_json_internal(std::basic_ostream<typename Ptree::key_type::value_type> &, const Ptree &, const std::string &, bool) [Ptree = boost::property_tree::basic_ptree<std::string, std::string>]
/AppleInternal/Library/BuildRoots/b958ad6d-2c13-11ed-a8d5-b25c5e9b9057/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator16.1.Internal.sdk/usr/local/include/boost/property_tree/json_parser/detail/write.hpp
write error
<unspecified file>
0123456789ABCDEF
<Epsilon>
<UnbiasedVar>
<Gamma>
<Beta>
Reading LayerNorm component
 ( min 
, max 
, mean 
, variance 
, skewness 
, kurtosis 
Invalid silence-phones string 
This doesn't work when utt detect is enabled. Doing nothing.
Lattice is null. Doing nothing
Lattice is empty. Doing nothing
~w00
Best conf result sessionId: 
 result: 
WORD_EMBED
IS_LME
LME_ID
IS_SIL
NUM_PHONES
AC_COST_UNPUSHED
IN_BEST_PATH
AC_COST
GRAPH_COST
NUM_FRAMES
LOG_POSTERIOR
LIN_POSTERIOR
Unknown feature type: 
model-feature-list
Comma-separated list of arc features. Example: "BAG_OF_PHONES,KEYWORD:hey,KEYWORD:Siri,LM_SCORE,AC_SCORE,NUM_FRAMES,LOG_POSTERIOR,LIN_POSTERIOR"
sil-phone-csl-file
File containing colon-separated list of silence phones.
node-merge-tol-ms
Node merging tolerance in ms
word-emb-marisa-file
MARISA trie file for word embedding lookup
word-emb-mat-flt32-file
Kaldi binary matrix file (float32) that stores word embeddings
transform-file
See LatticeRnn in nnet/lattice-rnn.h
forward-model-file
backward-model-file
arc-output-model-file
numUnderslashes <= 1
Obtained HWCN in 
StopWatch is still running.
StopWatch is already running.
/dev/urandom
model-file
Endpoint model file
sequence of features for endpoint model
enable-memory-map
model is memory mapped
endpoint-threshold
Threshold for final endpoint detection
trailing-silence-limit
An upper limit for trailing silence duration (miliseconds) after which recognizer should be forced to endpoint
extra-delay-ms
delaying the endpointer trigger decision by th given amount of time (in msec), when specified.
silence-posterior-nfhat-limit
An upper limit for silence posterior NFHat estimate (miliseconds) after which recognizer should be forced to endpoint
server-features-latency-clamp-begin
Starting point (in miliseconds)for ServerFeaturesLatency Clamp. ServerFeaturesLatency will be clamped at this value for the duration of clamp i.e [serverFeaturesLatencyClampBeginMs, serverFeaturesLatencyClampEndMs]
server-features-latency-clamp-end
Ending point (in miliseconds)for ServerFeaturesLatency Clamp. ServerFeaturesLatency will be allowed to update after this point i.e it will not be clamped anymore
endpoint-threshold needs to be configured to a value between 0-1
num-of-words default
trailing-silence-duration default
eos-likelihood default
silence-posterior default
Hybrid endpointer created with incorrect version
hybrid-endpoint
hybrid-endpoint.
Missing hybrid endpointer config
eager-result-acceptance
eager-result-acceptance.
Missing eager-result-acceptance config
default-server-ep-features
default-server-ep-features.
No available endpointer for samplingRate = 
Feature dim=
 does not match model dim=
Nnet output for endpointing is incorrect
, ep-nnet-value=
EagerResultAccept not configured
Nnet output for recognitionResult validation is incorrect
, nnet-output=
misc-shared.
misc-shared
endpoint.
endpoint
eager.
eager
geo-config-file
The 
 field available since version 
. Please upgrade config.
feature-read.
feature-read
No recognizer component for certain combinations.
Unsupported config file version
voice-trigger-phrase
VoiceTrigger phrase as space separated list of tokens as recognized by the decoder
voice-trigger-phrases
VoiceTrigger phrases as comma/space separated list of tokens as recognized by the decoder
lead-buffer-leeway
Number of samples the primary buffer is allowed to fall behind secondary buffers
trigger phrase: 
num of trigger phrases: 
Endpointing model file
feature-list
List of features
batch-size
Number of feature vectors processed w/o interruption
\NT-inline
SortedMatcher: bad match type
compose
ComposeFst: output symbol table of 1st argument 
does not match input symbol table of 2nd argument
WARNING
CompatSymbols: Symbol table check sums do not match. 
Table sizes are 
ComposeFst: 1st argument requires matching but cannot.
ComposeFst: 2nd argument requires matching but cannot.
ComposeFst: 1st argument cannot match on output labels 
and 2nd argument cannot match on input labels (sort?).
ComposeFst: both sides can't require match
ComposeFstMatcher: safe copy not supported
LookAheadComposeFilter: 1st argument cannot 
match/look-ahead on output labels and 2nd argument 
cannot match/look-ahead on input labels.
LookAheadMatcher: No look-ahead matcher defined
MultiEpsMatcher: Bad multi-eps label: 0
SingleShortestPath: for nshortest > 1, use ShortestPath
 instead
SingleShortestPath: weight and state thresholds not applicable
reverse_
NShortestPath: FST has a cycle and include_final_ties was set to true. This is not currently supported.
DeterminizeFst:
 distance to final states computed for acceptors only
DeterminizeFst: argument not an acceptor
determinize
DeterminizeFsaImpl: cannot copy with out_dist vector
<ShortlistTable>
<PivotShortlist>
<ShortlistLangPairs>
Shortlist target symbol id 
 not in shortlist!
Has shortlist, but dissabled due to shortlist-lang-pair = 
, lp = 
, shortlist-cond-n = 
, shortlist-freq-n = 
Using shortlist, reducing Voc size to 
ConstrainSoftmax
  linearity is quantized
  bias
BackpropagateFnc
 Not implemented!
linearity_
bias_
data
language
Can't init factory :(
v32@?0@"NSString"8@"NSString"16^B24
Can't init LmeDataFactory: (unexpected exception)
Can't init LmeDataFactory: %s
lme-create
jit-use-tokenizer
Getting LME data: outPronCacheHits 
 outPronCacheMisses 
 wordsRejected 
 wordsAccepted 
.tmp
v8@?0
v16@?0@"NSURL"8
Failed to read quasar pronunciation cache from profile blob with error : 
EARUserProfileBuilder.mm
Tokenizer is invoked after explicit release!
Config file version is not supported.
Quasar internal unknown exception
Quasar internal C++ exception: %s
\contact-first
\contact-middle
\contact-last
\contact-nickname
\company-first
\app-first
\jit
v32@?0@8@16^B24
none
ERROR 
ar_AE
bg_BG
zh_CN
zh_TW
hr_HR
cs_CZ
da_DK
nl_NL
nl_BE
en_AE
en_AU
en_GB
en_ID
en_IE
en_IN
en_MY
en_PH
en_SA
en_SG
en_US
en_ZA
fi_FI
fr_BE
fr_CA
fr_FR
de_AT
de_CH
de_DE
el_GR
he_IL
hi_IN
hu_HU
is_IS
it_IT
ja_JP
ko_KR
mr_IN
nb_NO
pl_PL
pt_BR
pt_PT
ro_RO
ru_RU
sk_SK
es_CL
es_CO
es_ES
es_US
sv_SE
th_TH
tr_TR
uk_UA
ur_PK
hy_AM
bn_IN
pa_IN
gu_IN
or_IN
ta_IN
ta_LK
te_IN
kn_IN
ml_IN
si_LK
lo_LA
bo_CN
bo_IN
my_MM
ka_GE
am_ET
chr_US
iu_CA
km_KH
mn_CN
Unknown locale specified in configuration: 
notchWidth %d, antiNotch %d, mR %d, mK %d, mN %d 
notchVec[%d]=%d 
notch-detector.psd.txt
notch-detector.fft.txt
notch-detector.feats.txt
online-las-lm-rescoring-beam-search
LAS model (TF/Espresso/CoreML graph)
encoder-model-file
LAS encoder split model (TF/Espresso/CoreML graph)
decoder-model-file
LAS decoder split model (TF/Espresso/CoreML graph)
batch size
substring-delimiter
Substring delimiter
token-delimiter
Token delimiter
token-delimiters
List of token delimiters
split-tokens-by-character
split tokens by character
lexicon-fst-file
Lexicon FST (to be used for re-tokenization)
subword-sym-table-file
Subword symbol table
lm-fst-file
LM FST (to be used for re-tokenization)
lm-scale
Scaling factor to use for LM weights
subword-oov-symbol
The subword OOV token symbol
word-oov-symbol
The word-level OOV token symbol
word-boundary-symbol
The word boundary subword token symbol
mapping-cache-size
Cache size to use for lazy FST mapping operations
decoderOpts.beam == dynamic_cast<kaldi::quasar::CEEncoderDecoderNet *>(inferenceNet.get())->Beam()
Either `model-file` or both `encoder-model-file` and `decoder-model-file` must be specified
Batch size is not an integer multiple of the frame subsampling factor. 
Encoder might drop frames.
Both token-delimiter and token-delimiters were provided. 
token-delimiter is deprecated, use token-delimiters instead.
Input FST 
 is not ilabel sorted
Subword symbol table must be provided
Invalid path FST. State 
 has 
 arcs
Decoder did not reach end-state, outputting partial traceback.
Failed to get raw recognition lattice.
remove-eos
remove EOS labels from output
remove-sil
remove silence labels from output
max-steps
maximum number of decoder steps
beam
beam width (must match the model)
length-penalty
length penalty
coverage-penalty
coverage penalty
SymbolTable::ReadText: Can't open file 
LatticeWeightTpl::Divide, NaN or invalid number produced. 
[dividing by zero?]  Returning zero.
Union: input/output symbol tables of 1st argument 
do not match input/output symbol tables of 2nd argument
StateSort: bad order vector size: 
there are 
<VocabSize>
<UnknownWord>
<BeginOfSentenceWord>
<EndOfSentenceWord>
the vector cannot be represented as a matrix with rows 
 , while it has dimension 
{ wordCount: %ld, trailingSilenceDuration: %ld, endOfSentenceLikelihood: %f, pauseCounts: ( %@ ), silencePosterior: %f, clientSilenceFramesCountMs: %f, clientSilenceProbability: %f, silencePosteriorNF: %f, serverFeaturesLatency: %f, eagerResultEndTime: %ld }
filter-devices cannot be empty
filter-input-origins cannot be empty
An earlier LatticeRnn in the decoder chain already ran. Doing nothing.
Request does not match filter. Doing nothing.
LatticeRnn output is incorrect 
latnnMitigatorScore
version
Model version
output-model-file
phone-pd2pi-file
bag-of-phones-model-file
Map model into memory (requires aligned models)
threshold
0 = not trigger, 1 = trigger
filter-devices
FORMAT: Pipe-separated list of devices with support for wildcards. Wildcards must come at the end of each device in the list. Example 1: "filter-devices": "*" - matches any device. Example 2: "filter-devices": "iPhone7|Watch*|AudioAccessory1" - matches iPhone7, AudioAccessory1, and devices starting with "Watch". USAGE: One decoder chain can have multiple LatticeRnnMitigators, which are specified using colon notation to create unique names. Example decoder chain: lattice-biglm-lme-faster, ..., lattice-rnn-mitigator:X, lattice-rnn-mitigator:Y, lattice-rnn-mitigator:Z. The LatticeRnnMitigators are checked one-by-one in order. The first one that matches a request will 'claim' the request, run, and prevent the rest from running. All the filter-* conditions are AND'ed together, so a request must match all of them for the corresponding LatticeRnnMitigator to run.
filter-input-origins
List of input origins with the same format as filter-devices.
calibration-scale
Calibration Scale
calibration-offset
Calibration Offset
AC_SCORE
BAG_OF_PHONES
KEYWORD
Cannot find symbol ID for 
LM_SCORE
the input grammar data is empty
the input symbol table is empty
<eps>
LME: no user data available for creating a grammar FST
word <
> not in the input symbol table
/WORD-DIS-
Illegal word: 
Invalid phone in pron for word: 
Word 
Word does not exist in lexicon: 
Phone 
) does not exist in the lexicon
Illegal phone: 
For a lexicon using pos-dep phones, cannot view disambig IDs with pos-indep phones
For a lexicon using pos-indep phones, cannot view disambig IDs with pos-dep phones
Invalid phone 
 not found in lexicon.
Removing a pron for word: 
the base lexicon is not at base phone set mode
the preferred lexicon is not at base phone set mode
the base lexicon and preferred lexicon have different phone set
the guessed lexicon is not at base phone set mode
the base lexicon and guessed lexicon have different phone set
the preferred lexicon and guessed lexicon has different phone set
all input lexicons (base, preferred, guessed) are empty
input user data is empty
AlternativesProcessorBlock
 Config:
tag [
] is not recognized; panicking, cannot produce metaValue
Failed adding meta info, original metaInfo 
Mapping file '
' is not found
<default>
RecogCpuTimeMs
AverageActiveTokensPerFrame
EARErrorDomain
speakingRate
averagePauseDuration
jitter
shimmer
pitch
voicing
 tokenName=%@, start=%f, silenceStart=%f, end=%f, confidence=%f, hasSpaceAfter=%d, hasSpaceBefore=%d, phoneSeq=%@, ipaPhoneSeq=%@, appendedAutoPunctuation=%d, prependedAutoPunctuation=%d, isModifiedByAutoPunctuation=%d
(ver=%@, score=%f, threshold=%f)
<tokenSausage = %@, interpretationIndices = %@>
[TTAW] Final Result Empty.
[TTAW] oneBestFinalResult: 
,correctIndexList: [
 tokens=%@, preITNTokens=%@
[TTAW] partialResult: 
anyResults=%@, countOfIsFinalFalseAlreadyWritten=%@, prevBestRecogText=%s
Requested index %zu out of bounds %zu
%d.%d
com.apple._EARSpeechRecognizer.recognition
com.apple._EARSpeechRecognizer.formatter
com.apple._EARSpeechRecognizer.training
v32@?0@"NSString"8Q16^B24
EARSpeechRecognizer.mm
enableParallelLoading
keepANEModelLoaded
taskForMemoryLock
Could not build recognizer: %d
DUMMYTOKEN
Dictation
textfield-editing-suite
plist
com.apple._EARSpeechRecognizer.recognition.workloop
Size mismatch
Continuous Listening should not be used with Mux
Array sizes are not the same
.mlmodelc
.espresso.net
Tokenized text: "
" to "
", "
Tokenization duration:
partial
final
itnDurationInNs
isEmojiPersonalizationUsed
isEmojiDisambiguationUsed
isEmojiExpectedButNotRecognized
[TTAW] partialIndex: 
, subFinalResult: 
, partialResult: 
[TTAW] exact match, index = 
Should never get here
static _EARSpeechRecognitionResultPackage *ResultStreamWrapper::resultPackageWithResultChoices(const std::vector<std::vector<Token>> &, bool, _EARFormatter *__strong, const quasar::AudioAnalytics &, const quasar::LatnnMitigatorResult &, const double, NSString *__strong, const unsigned int, NSString *__strong, bool, const std::vector<Token> &, _EARSpeechRecognitionResult *__autoreleasing *, bool, std::shared_ptr<ContinuousListeningConfig>, bool, bool, const std::vector<Token> &, std::vector<std::vector<Token>> &, const std::vector<quasar::ItnOverride> &, quasar::ItnEnablingFlags::Flags, bool, bool, _EARSpeechRecognitionResultPackage *__autoreleasing *, const std::vector<std::set<std::string>> &, NSDictionary<NSString *,_EARSpeechRecognitionResultPackage *> *__autoreleasing *, BOOL, BOOL, const std::vector<quasar::Token> &, BOOL, const std::shared_ptr<const VoiceCommandActiveSetCompilation> &, BOOL, NSDictionary<NSString *,NSNumber *> *__autoreleasing *, NSArray<NSString *> *__autoreleasing *)
Results are not properly labeled
v24@?0@"NSDictionary"8@"NSArray"16
v32@?0@"NSArray"8Q16^B24
Quasar PostITN Result. isFinal=
PostITN 1-Best: 
PostITN Choice: 
PostITN Token[
Quasar internal C++ exception:
Quasar executor unknown exception
Quasar executor ObjC exception: %@
Quasar executor C++ exception: %s
Could not report recognition error: %@
DefaultCompactStore::Write: Alignment failed: 
DefaultCompactStore::Write: Write failed: 
v32@?0@"NSString"8@16^B24
Recognition was unsuccessful
Configuration needs either 'romanizer' or 'pron-guide-model-file'
romanization
Failed to create ICU Transilerator for scripts : 
Failed to create unicode string for "
wstring_convert: to_bytes error
 not contained in BPE encoder 
 mapping to 
no symbol 
Decoder hit max sentence length : 
Failed to create UTF-8 string: 
RomanizerBlock
<space>
</w>
failed to unmap region: 
Memory unlock of file failed: 
Failed to hint VM for 
mmap'ed region of 
 at offset 
 from 
 to addr 
Mapping of file failed: 
File mapping at offset 
 of size 
 of file 
 could not be honored, reading instead.
Failed to read 
 bytes at offset 
from "
Read 
 bytes. 
 remaining.
EARSdapiHelper.mm
Failed to initialize SDAPI
src-locale not present in the config
tgt-locale not present in the config
QE handler contains 
 features
quality_features
Raw hypothesis : 
Tokenized hypothesis : 
Meta info 
Confidence 
LowConfidence 
empty source input received
empty nbest input received
Raw source : 
Tokenized source : 
Input'
' has no value set!
QualityEstimatorBlock
class definition has too many fields
VectorFst::Read: read failed: 
VectorFst::Read: unexpected end of file: 
FstImpl::ReadHeader: source: 
, fst_type: 
, arc_type: 
, version: 
, flags: 
FstImpl::ReadHeader: Fst not of type "
FstImpl::ReadHeader: Arc not of type "
FstImpl::ReadHeader: Obsolete 
 Fst version: 
ExpandedFst::Read: Can't open file: 
standard input
 millions
, input-dim 
Non-matching output dims, component:
 data:
Backpropagate() attempted while disabled
Non-matching dims! 
 input-dim : 
 data : 
'inf' in component parameters (weight explosion, try lower learning rate?)
'nan' in component parameters (try lower learning rate?)
maxent model estimation not supported (requires liblbfgs)
nnet-file
The model is not of type kaldi::InferenceNetItf.
action-fst-directory
label-tsv-file
convert-to-plain-text-after-label
default-fst-do-nothing
spaceApplyDefault.fst
spaceApplyRemoveBefore.fst
rewriteApplyCapitalize.fst
rewriteApplyDefault.fst
default-backoff-label
apply-label-threshold-length
label-threshold-tsv-file
joint-model
tasks
Missing supported tasks.
shared-num-nn-components
For non-Kaldi models, shared neural network components is not supported. 'shared-num-nn-components' in config json should not be set.
source-vocab-file
cluster-id-file
excluded-postitn-tokens
informal-text-length
special-formal-puncs
end-of-sentence-puncs
do-not-cap-feature-name
InverseTextNormalizer already initialized.
max-num-feats
chunk-length
punctuation
.punctuation
For non-Kaldi models, 'chunk-length' in config json needs to be set to [1, model input length - 2]. The itn model input length is 
For non-Kaldi models, 'chunk-length' in config json needs to be set to [1, model input length - 2]. The punctuation model input length is 
For non-Kaldi models, <PAD> is required in source-vocab-file
Initialized ITN
Invalid line in compound word list file
chunk overlap is bigger than chunk length.
File containing cluster Ids.
compound-word-file
Maximum number of feats
no-title-casing-file
File with list of words that should not be title-cased
Source vocabulary file
token-boundary-id
Token boundary symbol ID
word-sense-file
File containing list of word senses.
align-right-preitn-tokens-file
File storing list of pre-ITN tokens that should map to next post-ITN token.
regex-feat-file
TSV file storing regex-to-feature map.
double-regex-feat-file
guard-markers-file
TSV file storing guard markers that prevent ITN.
supplement-config-file
supplemental json file which may contain punctuation and other frequently updated paramters such as max-num-feats
Number of tokens in each chunk
chunk-overlap
the number of overlap tokens between two chunks
entity-tsv-file
Duplicate occurrence of entity "
Unknown start entity "
Unknown end entity "
Initialized EntityTransformer.
inputToken=
 label=
outputToken=
Sublabel application 
 failed for token 
Applying 
 overrides
start entity <
end entity <
Encountered orphan start entity 
This cannot happen
inputToken="
" label=
label (
) output score is under threshold (
). Skip applying the label
 concateFst="
ITN failed.
Missing TokenBoundary label
Something that should never happen, just happened. Debug me please...
Regex match for 
) with label 
Preprocessed token: 
tokenNum=
 tokenId=
 word=
 tag=
 tagIsSense=
index=
 token=
 commandId=
French
dictionary
eats
five
hotdogs
Tantor
mighty
fine
elephant.
" ~ 
" -> 
Merging pre-token 
 to next post token
 to previous post token
ITN failed
Tantor-ITN numInputTokens=
 numOutputTokens=
 numOverrides=
 input="
 output="
 overrides=
 preToPostTokMap=
WARNING: No concatenation point found
Detected size mismatch between resultPostItn=
 and resultAlignment=
chunk_tokens_str: 
chunk_post_itn: 
chunk_alignment: 
result_post_itn: 
result_alignment: 
token sequence time is not monotonic increasing.
reset token timing.
emoji-keyword-remove-fst-1
post-itn-hammer
<PAD>
StopWatch is not running.
Process CPU time was not enabled
unordered_map::at: key not found
Emoji
emoji
Emojis
emojis
Emoji's
emoji's
map::at:  key not found
column == arcFeatDims
Cannot phone pd2pi file 
Malformed phone pd2pi file line=
Coding error. norm_word not found for arc
Coding error. wordEmbMat not loaded.
SymbolTable::ReadText: Bad number of columns (
file = 
, line = 
SymbolTable::ReadText: Bad non-negative integer "
SymbolTable::AddSymbol: symbol = 
 already in symbol_map_ with key = 
 but supplied new key = 
 (ignoring new key)
SymbolTable::Read: read failed
SymbolTable::Write: write failed
Missing required field separator
Negative symbol table entry when not allowed
operator()
/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/libquasar/liblm/src/impl/weights.cpp
NULL
EventMap::read, was not expecting character 
Input shape template [
] must include the R and C tokens.
] includes multiple R tokens.
] includes multiple C tokens.
] includes tokens other than R, C and 1.
] must include the R token.
] must include the C token.
Both num_rows and num_cols is 0. At least one dimension should be provided.
num_cols > 0
num_elements % num_cols == 0
num_rows > 0
num_elements % num_rows == 0
num_rows * num_cols == num_elements
UTF8StringToLabels: continuation byte as lead byte
UTF8StringToLabels: truncated utf-8 byte sequence
UTF8StringToLabels: missing/invalid continuation byte
UTF8StringToLabels: Invalid character found: 
StringCompiler::ConvertSymbolToLabel: Symbol "
" is not mapped to any integer label, symbol table = 
StringCompiler::ConvertSymbolToLabel: Bad label integer 
arg0
arg0/adpos
arg1
arg1/adpos
arg2
arg2/adpos
arg0/lacuna
arg1/lacuna
arg2/lacuna
Key = 
%s/1gms/vocab%s
%s/1gms/vocab
reading 
%s/%dgms/%dgm.idx
malformed index entry
%s/%dgms/%s
binary format not yet support in readMinCounts
maxorder %u
malformed N-gram count or more than 
 words per line
undefined word index 
ngram [
] exceeds write buffer
bad binary format
maxorder %u
could not read ngram order
word index 
 out of range
data misaligned
increasing offset bytes from 
 (order 
 level 
SRILM_BINARY_COUNTS_001
neglogprob
logprob
log10prob
Unknown LM score type "
NegLogProb
LogProb
Log10Prob
Coding error
scoreType
tokens
wrong dimensionality of logScores vector
utterance doesn't end with sentence-end symbol(
Ngram orders from previous utterances inconsistent with ones from current utterance
Unexpected number of backoffs: 
utterances
words
OOVs
invalidTokens
invalidUtterances
logProb
perplexity calculation failed, words 
 logprob = 
PPL1
ngramHits
Computed perplexity for 
 sentences, 
 words, 
 OOVs, 
 invalid tokens, 
 invalid utterances
logprob = 
perplexity calculation failed
 ppl = 
 ppl1 = 
Score types do not match
Number of utterances don't match
Number of tokens don't match
aligning scores of utterance 
Utterance 
 doesn't match 
 doesn't match isValidScore
 has non-matching token ids
 has non-matching number of token scores
dimensionality of logScores was chosen too big: 
number of collected tokens and utterances inconsistent
unsupported LmScoreType
number of CorpusStats and interpolation weights don't match
could not retrieve scores from CorpusStats
iterative process to obtain optimal interpolation weights failed
something went wrong with log-score interpolation
number of collected log-scores doesn't match CorpusStats
Input scores are not logProb format, logScores are not comparable
failed to estimate the interpolation weights
Num new Lms = 
 but num interp weights = 
LM component 
 weight: 
Rescoring failed
LM score (type=
) = 
lmScore=
 doesn't match expected score=
Failed to find lattice-biglm-lme-faster decoder
enableLme=false, but LME data was provided. 
Option 1: Set enableLme=true to use the LME data for scoring text with LME tokens. 
Option 2: Set enableLme=false, remove the LME data, and provide text with non-terminals instead of LME tokens.
Could not find OOV word "
" in symbol table(s)
Could not compute LM score due to empty tokenIds and empty tokens.
Could not find "
" in symbol table(s), ignoring token
" in symbol table(s), replacing with "
You chose to use the LM rescoring decoder, but it was not found.
Extra LM weight exceeds max-total-extra-weight, rescaling with 
Extra LM weight must be positive (i.e. not in log scale)
Extra LM weight too small, not using extra LM(s)
Extra LM weight must sum to less than 1.0, using only Extra LM(s)
Mismatch in tokenLmInfos and filteredIds sizes
Mismatch in token IDs
the base LM is NULL or empty
replace
ReplaceFstImpl: input symbols of Fst 
 does not match input symbols of base Fst (0'th fst)
ReplaceFstImpl: output symbols of Fst 
 does not match output symbols of base Fst 
(0'th fst)
ReplaceFstImpl: no Fst corresponding to root label '
' in the input tuple vector
ReplaceFstImpl::ReplaceFstImpl: always_cache = 
ReplaceFst: inconsistent arc iterator flags
Not using replace matcher
CacheDeterministicOnDemandFst cache hit rate = 
, size = 
uninitialized model component
 for location-specific placeholder 
the provided NnlmEvaluator is neither DNN nor RNN
The LME class 
 is not modeled by the NNLM
multiple LME FSTs are mapped into the same non-terminals classes, wrong config?
the individual DeterministicOnDemandFst is NULL or empty
you are requesting linear interpolation, but the total weight is not 1: 
Invalid word symbol, clipping left context: 
Decoder chain was not lazily initialized
No regional model map from 1st pass GeoContext available
placeholder 
 not found in model-map for region 
Using location-specific bigG for 
 from region 
mixture_origin[
masterlm
Empty token received
Invalid code point, 
Invalid UTF-8, 
Not enough space, 
input contains | which is the separator for g2p model.
[a-zA-Z]\.[a-zA-Z]
[a-zA-Z]-[a-zA-Z]
Locale-aware upper/lowercasing failed, falling back to locale-insensitive versions.
^[a-zA-Z]+[0-9]+$
([0-9])
Phone changed unexpectedly in lattice [broken lattice or mismatched model?]
Unexpected phone 
 found inside a word.
Phone changed while following final self-loop [broken lattice or mismatched model or wrong --reorder option?]
Invalid word at end of lattice [partial lattice, forced out?]
Discarding word-ids at the end of a sentence, that don't have alignments.
Broken silence arc at end of utterance (the phone changed); code error
Broken silence arc at end of utterance (does not reach end of silence)
Partial word detected at end of utterance
Not expecting binary unpronounced words file.
Invalid line in unpronounced words file: 
Invalid line in word-boundary file: 
nonword
begin
singleton
internal
Empty word-boundary file
 was not specified in word-boundary file (or options)
[Lattice has input epsilons and/or is not input-deterministic 
(in Mohri sense)]-- i.e. lattice is not deterministic.  
Word-alignment may be slow and-or blow up in memory.
Number of states in lattice exceeded max-states of 
, original lattice had 
 states.  Returning what we have.
ArcMap: non-zero arc labels for superfinal arc
strlen(FLAGS_fst_weight_separator) == 1
../libquasar/libkaldi/src/fstext/lattice-weight.h
Infinity
-Infinity
BadNumber
randgen
RandGenVisitor: cyclic input
ComposeFst: Weights must be a commutative semiring: 
Failed to create a 
 by 
 matrix with only 
 bytes available in the workspace
Failed to create a vector of 
 elements with only 
size >= 0
mem_size_bytes >= 0
Can't create a child workspace of 
. Only have 
 bytes
Feature type unknown. Ignoring feature ..
Initialized nnet with Model file =
Endpoint model file cannot be empty
Feature unknown, 
features allowed are ("num-of-words","num-trailing-sil", "num-frames","end-of-sentence","pause-counts","num-input-label-words","stream-conf","silence-posterior","client-silence-frames-count-ms","client-silence-probability","silence-posterior-nf","server-features-latency", "eager-result-end-time")
endpoint-feature-list cannot be empty
com.apple.siri.languagemodeltraining
com.apple.speech.languagemodeltraining
_EARLMTKaldiVocab
Incorrect format of vocab file for line=%@
VocabSize in the file %lu does not match total vocabulary in file %lu
One of <UnknownWord>, <BeginOfSentenceWord> or <EndOfSentenceWord> symbols are missing from file:%@
token_post_in_cnet_slot
max_post_in_cnet_slot
secondmax_post_in_cnet_slot
num_arcs_in_cnet_slot
logpost
avg_loglike
hyp_len
token_pos_in_hyp
token_freq
token_logfreq
num_frames
spk_rate
(num_hyps_out > 0) && (num_hyps_out <= num_hyps_in_)
std::find(feature_list_.begin(), feature_list_.end(), feature_list[i]) != feature_list_.end() && "Unknown feature provided in the feature list"
token_unigram_frequencies_.size() > 0
nbest_hyps.size() == num_hyps_in_
nbest_loglikes.size() == num_hyps_in_
num_frames > 0
Hypothesis token (
) does not match any arc in the confusion network slot
!binary_in && "Not expecting a binary file."
ss.good()
!binary_in && "Not expecting binary confidence file."
intercept
(atof(feat_std_str.c_str()) > 0) && "Obtained a zero/negative value for standard deviation"
feature_list_.size() == weights_.size()
feature_list_.size() == feature_mean_.size()
feature_list_.size() == feature_std_.size()
feature_list == feature_list_
feats.Dim() == weights_.size()
decoder
overallScore
input
rawOutput
output
numInputPhones
isScoreHigh
isPartial
decoderName
results
com.apple.siri._EARSpeechRecognitionAudioBuffer
Ending current audio stream.
    
Multiple connections to receiving block input name: 
output port not connected: 
Missing input(s) for 
Block '
' - required input not connected: '
' - nonexistent input connected: '
graph-ouput input name specifier not used
Multiple values received in graph-output!
No value received in graph-output!
Unsuported merge-style: 
Input '
' set multiple times!
ProcessingSource
ProcessingSink
MergerBlock
NullBlock
DumpBlock
\data\
ngram
Reading 
\end\
line 
1.#INF
batchSize > 0 && updateInterval > 0 && learningRate > 0 && initializeOption > 0 && initializeOption < 3 && recognitionInterval > 0 && "Bad configuration"
updateInterval % batchSize == 0 && "Bad configuration"
Training network path must be specified.
Training model loading done.
initializeOption > 0 && initializeOption < 3 && "Unrecognized initialize option"
Initial size must be set if initialize option is 2(aka. all-zeros)
Training variables are initialized, training speaker code: 
, inference speaker code: 
, accumulated gradient: 
, processed samples: 
, training offset: 
, recognition offset: 
Training is continuous, speaker code: 
Training speaker code is reset, speaker code: 
gradBuffer && updatedSpeakerCode && "Speaker code container or gradient container does not exist"
Iteration:[
] done, calculated gradient: 
Speaker code is updated: 
Reaches recognition interval, going to reset training and inference speaker code, processed samples: 
, speaker code: 
Training is still running, going to set end to true and end training
Training is ended, going to set end to false and resume training.
refMat.NumRows() == 1
Invalid frame range. Coding error.
signal energy (dB) = 
 noise energy (dB) = 
mt-decoders.
engine-type
CORRECT
SEARCH_ERROR
HOMOPHONE
LM_OVER
GRAPH_OVER
AM_OVER
REF_TOO_SHORT
HYPO_TOO_SHORT
Invalid Category given 
TRANS_ID
PHONE
WORD
Invalid level given 
GENERAL
SCHEMA
CONTEXT
MIN_DURATION
PATTERN
LENGTH
AC-MATCH
AC-MISMATCH
WORD-CONFUSION
Invalid info given 
HYPO
AMONLY
Invalid source given 
Clipping left context because of unknown or rejected word: "
Parameters for 
 have already been registered.
Decoder: 
 inputArcs=
 maxArcs=
Must call init() for 
 before calling run().
Skipping Decoder: 
Running Decoder: 
Decoder 
 failed.
Time
FirstPassCpuMs
stabilizer-averaging-period-ms
Duration in milliseconds over which to stabilize partial results
stabilizer-minimum-word-seen-ms
Minimum duration in milliseconds that word must be recognized before it is considered stable
dfst-cache-size
The maximum number of items cached by each deterministic FST. Has no effect if the decoder doesn't use deterministic FST.
max-arcs
If > 0, decoder does nothing and returns Decoder::Success if the number of input lattice arcs exceeds this value. Decoders can customize behavior related to max-arcs. For example, rescoring decoder scales the lattice before checking max-arcs and keeps checks max-arcs while it runs.
max-arcs-fail-decoder
If true, return Decoder::Failed instead of Decoder::Success when exceeding max-arcs. This stops execution of subsequent decoders in the decoder chain but does not stop or fail the request. Decoders can customize behavior related to max-arcs-fail-decoder
double-partial-silence-interval-ms
if > 0, write a second partial result with a delay of trailing silence duration milliseconds
Linear Output Failed
Skipping calculateNBest since we already did it (eager)
nbest size=
symTableId=
, but decoderChainOutput->lmeInfos.size()=
No HWCN computed, so skipping nbestV2
empty partial results!
empty or mismatched number of timestamps for final result
partial result: 
, partial result timestamp: 
, partial reference: 
partial_results_toggle_count=
partial_results_average_feedback_lag=
faster_partial_results_toggle_count=
faster_partial_results_average_feedback_lag=
Building Decoder 
lattice-biglm-faster
lattice-biglm-lme-faster
lattice-scale-rescore
lattice-word-aligner
lattice-lm-rescore
lattice-realigner
error-blamer
lattice-confidence
lattice-faster
keyword-spotting-decoder
seeva-decoder
seeva-step-decoder
seeva-step-biglm-decoder
seeva-greedy-decoder
seeva-batch-decoder
las-beam-search-decoder
las-speculative-beam-search-decoder
las-lm-rescoring-beam-search-decoder
las-lm-rescoring-speculative-beam-search-decoder
transducer-beam-search-decoder
system-combination-decoder
confusion-network-combiner
phonetic-match
fingerprint-detector
audio-analytics-decoder
audio-analytics-only
lattice-rnn-mitigator
lattice-confidence2
e2e-asr-confidence
watermark-detector2
lattice-biglm-lme-ftm-faster
Unknown decoder type "
" in "
No word boundary info found. Cannot give proper phone sequence.
Phone sequencing failed; ran out of words for unknown reasons. 
Lattice word alignment and confidence computation will also fail. 
PLEASE FILE A RADAR
Phone sequencing failed; Ran out of phones, probably because 
the last word got clipped in the audio. 
Lattice word alignment and confidence computation will also fail.
error-blaming-report
failure-reason
CONFIDENCE
FRAME_LENGTH
Blaming 
Cannot blame given reference and hypothesis, one of them is empty.
Schematics have to be registered first before usage, call RegisterSchematics first
Size of registered schematics is 
 does not match with supplied schematics for utterance, which are 
Unexpected number of confidenceScores
Unexpected number of confidenceScores got 
 words in lattice and got 
 confidence scores
tag-start
tag-end
parameter-prefix
command-phrase-prefix
Error with configuration for CommandTagger
command-tagger
text-proc
start
alignment-queries
No mismatch found - this should never happen)
original upcase region start: 
original upcase region end: 
projections
Adjusting alignment queries
Adjusting alignment projections
Unsupported mapping operation
Unicode error (ICU): 
CaseMapBlock
Non-finite energy found for frame 
. Waveform is: 
SRILM_BINARY_NGRAM_001
SRILM_BINARY_NGRAM_002
gram]
[OOV]
 in binary format
 in old binary format
\%d-grams
invalid ngram order 
skipping 
ngram %u=%lld
ngram order 
ngram number 
unexpected input
discarded 
 OOV 
warning: 
-grams read, expected 
ngram line has 
 fields (
 expected)
invalid codebook index "
bad prob "
warning: questionable prob "
ignoring non-zero bow "
" for maximal ngram
bad bow "
warning: questionable bow "
warning: no bow for prefix of ngram "
warning: non-zero probability for 
 in closed-vocabulary LM
reached EOF before \end\
\data\
ngram %d=%lld
\%d-grams:
writing 
%.*lg
%s%s
%.*lg
\end\
index: %1023s
data: %1023s
invalid binary LM format!
%.1023s
incompatible binary format
failed to read from data file
index (
skipToNextTrie failed for order 
failed to estimate GT discount for order 
Good Turing parameters for 
-grams:
BOW denominator for context "
" is zero; scaling probabilities to sum to 1
BOW numerator for context "
" is 
 < 0
 <= 0,
numerator is 
CONTEXT 
 numerator 
 denominator 
 BOW 
warning: the size of this n-gram exceeds 
 characters (increasing buffer size...): 
 WORD 
 CONTEXTPROB 
 OLDPROB 
 NEWPROB 
 DELTA-H 
 DELTA-LOGP 
 PPL-CHANGE 
 PRUNED 
pruned 
 PRUNED 1
 LPROB 
 BACKOFF-LPROB 
 PRUNED
faking probability for context 
inserted 
 redundant 
-gram probs
warning: distributing 
 left-over probability mass over 
 zeroton words
 left-over probability mass over all 
 words
 NUMER 
 DENOM 
 DISCOUNT 
 LOW 
 LOLPROB 
 backoff probability mass left for "
" -- 
disabling interpolation
incrementing denominator
-gram contexts containing pseudo-events
-gram probs predicting pseudo-events
-gram probs discounted to zero
long-name
Long-name field not allowed
, geoRegion=
Bitmap region not allowed
Circle info required
Both circle and bitmap info used in region 
, which is prohibited
Default region is not part of geo-config file in older versions 
(bitmapRegion->getBitmapColor()) == (geoconfig::NULL_REFERENCE_BITMAP_COLOR)
Neither bitmap nor circle info found in region 
model-map
 not supported
classLM-template-to-fst-map
Neither 
 nor 
 found for region 
 in geo-config
Empty model file for placeholder 
GeoLM: Model cannot be loaded since it does not exist: 
.fst
FST: input label is not sorted!
loading NNLM from 
 not implemented
contextual-data
contextual-data.
sanitizer-special-chars-pattern
Override pattern for TextSanitizer mSpecialChars.
score-threshold
Score threshold for Portrait named entity.
supported-categories
Supported categories for Portrait named entity, delimited by comma
contextual-data.source-map
framework
Contextual data: empty framework is configured in source-map
Portrait
PeopleSuggester
Contextual data: undefined framework is configured: 
max-limit
from-date-in-sec
to-date-in-sec
contact-only
Contextual data: invalid configuration for supported-categories, configured value: 
Contextual data: supported categories: 
, number: 
contextual-data.category-map
contextual-data.name-average-cost-map
contextual-data.name-deviation-cost-map
Contextual data: sanitizer special character patter is set to empty.
preprocessingCategoryCounts
postprocessingCategoryCounts
Contextual data: failed to add words, status: 
1,2,3,4,5,6,7,8,12,13,14,15,16,17,18,20,21
\NT-contact
Config Version is not high enough for personalization
personalization-recipe.personalization-version
Personalization not configured
personalization-recipe.
personalization-recipe
personalization-recipe.categories
Personalization version: 
personalization-version
The version of the categories data
chars-to-trim
The characters to be trimmed from the edges of the raw entity string
chars-to-split
The characters used to split the raw entity string
The relative frequency of the data
template-name
The template name for LME
tag-name
The tag name for LME (also important for enumerations)
Category 
Ignoring entry with orthography 
CoreMLInferenceNet: On-Device ASR: (ANE) Eager Loading and keepANEModelLoaded: 
Could not load 
input1
output1
in_extras.size() == 1
input2
could not make features: 
CoreML prediction failed, falling back to CPU inference
could not predict: 
No output from CoreML: 
v16@?0^v8
Could not make multiarray from matrix 
Unexpected output shape from CoreML: 
Unexpected output from CoreML: 
Could not make multiarray from vector 
Non-vector shape output from CoreML: 
fst-file
LM FST file for dummy experiments
filename
weight
<SourceStateDimension>
<MaxAttentions>
 (SourceStateDimension|MaxAttentions)
Initializing component of type 
this is a non-recurrent version, cannot have a recurrent internal component
no recursive inclusion
component is not initialized, max attention is 
, source state dimension is 
component has input dim 
, attentions 
, source state dimension 
, however, the internal training component has input dim 
the output dim of attention component is 
 , however, the internal training component has output dim 
State 
NumFramesReady() not implemented for this decodable type.
model-override-json
Not applying override because model-override-json is empty or does not exist
Not applying override because override configuration's version is unsupported
Not applying override because the override language: 
 is different from the datapack's language: 
Not applying override because the override phoneset: 
 is different from the datapack's phoneset: 
Not applying override because the override config version: 
 is greater than the datapack's config version: 
phonetic-match-building.
LG FST name
L FST name
G output symbol name
.lg-fst-file
Overriding 
.lg-fst-file to 
.word-syms-map-file
.word-syms-map-file to 
.l-fst-file
.l-fst-file to 
Internal C++ exception: 
output-symtab-file
Output symbol table file
lg-fst-file
LG FST file
phonomap-file
Phonomap file
sys-select-bias
System selection bias
sys-select-lm-scale
System selection LM scale
regex-list-file
List of regular expressions that will be used to catch inputs for phonetic match.
regex-whitelist-file
Regex whitelist
regex-blacklist-file
Regex blacklist
lm-logprob-threshold
Only do PM if LVCSR's LM logprob is less than this.
entity-tags-tsv-file
File containing start and end entity tags
sys-select-score-scale
Scale factor for PM-overallScore for addition to confidences
sys-select-score-min
Minimum PM-overallScore at which to discard the PM result
sys-select-length-norm
Divide PM-overallScore by phone sequence length
do-use-confmodel
Flag for whether or not to use a confidence model, if true confidence-model-file must also be set
confidence-model-file
Filename for confidence model file, format <FEATURE> <WEIGHT> (one per line)
l-fst-file
L FST file (if specified per-word segmentation will be output)
max-align-total-tokens
Maximum number of tokens used just for alignment pass
protect-lme-tags
Comma separated list of trailing strings which can be used identify tokens to be protected from replacement by phonetic match
wildcard-symbol
The wildcard symbol is used to specify a partial match. It will always align with a single phone. Normally set to ~ if you wish to allow phonetic match to do a partial match (filling in the words recognised pre-PM where the wildcard occurs)
wildcard-scale
The wildcard scale is a multiplier applied to the negative log likelihoods in the phonomap corresponding to the wildcard-symbol
placeholders-file
Each line in the file contains a regexes which to match a token in PM-input. The regex should be followed by <TAB> and then a new token which used to get a pron for the replacement. The original token will be switched back when added to the choice list (after PM-output). e.g. (.*)\artist-first<TAB>any_artist. l-fst-file must be specified and contain a prob forthe word given
The JSON config file that stores Phonetic-Match model overrides
Config version < 158 so using FST compatibility mode so subroutine states with no outgoing arcs denotes an exit state
Config version >= 158 so exit states in subroutines are expected to be proper final states - phonetic match will fail otherwise
Phonetic match decoder is using subroutine feature but config version < 111
Must specify an l-fst-file in order to lookup prons for placeholders
Placeholders not formatted correctly in 
Expected each line contain a regex to match followed by a placeholder word, e.g. (.*)\room-first<TAB>kitchen
Replacement word '
' in placeholder regex '
' is not present in '
Found pron="
" for word=
 in placeholder regex=
constant
Setting constant term/intercept to 
Setting 
Feature 
 is not in the model definition.
Read in Confidence Model 
 added 
numWildcardWordMatches=
Matched placeholder for word=
 replacing with pron="
phone=
 start=
 end=
 confidence=
Phone '
' is not a valid phone symbol
Number of phones is 0
PM Failed.
PM ELAPSED: 
 num_phones=
PM Alignment failed - no results
Mismatched number of non-aligned and aligned phonetic match result 
PM ALIGN ELAPSED: 
PM Alignment failed
PM Failed to get any results from lattice
No LM cost found. Skipping PM. Hint: Did you include lattice-lm-rescore?
LVCSR LM logprob=
 is greater than threshold 
. Skipping PM.
pmInput="
Not a match with the regex whitelist. Skipping PM.
Matches the regex blacklist. Skipping PM.
**PM JSON RESULT:
No good phonetic match results
pmOutput="
Score low. Discarding PM result.
Switching to phonetic match decoder output
PM-input
PM-output
PM-used
PM-partial
PM-decoder
Symbol decoder beam
max-active
Symbol decoder max active states
beam-delta
Symbol decoder beam delta
hash-ratio
Symbol decoder hash ratio
ac-scale
Symbol decoder acoustic scale
max-total-tokens
Max total allocated tokens at any time.
pm_overall_score
slm_mean_confidence
trans_slm_mean_confidence
m.size() == PhoneticMatchConfFeatures::kFeatureCount
<n/a>
Greated than 256 rec symbols (phones) in phonomap 
 can't be supported
Cannot perform phonetic match since LG FST is empty
Phone features size of 
 != wildcard LM costs size of 
Frame 
Max tokens 
 exceeded - 
Allocated max tokens 
 prev_id=
 nextstate=
 weight=
 ilabel=
 olabel=
 phone=
Ran out of token storage
Process non-emitting with cutoff=
Exit subroutine state=
subroutine=
 prevnextstate=
Cannot enter subroutine=
 ret_state=
 (nesting not allowed)
Process emitting isym=
Failed to reach final state
Subroutine index 
 already defined
 not used - subroutines indexes must be consecutive
Found 
 phonetic match subroutines 
Possible memory leak: 
: you might have forgotten to call Delete on 
some Elems
\s{2,}
Ignoring silence phone "sil"
ASR prons are empty
Language not provided
Unsupported language: "
Unknown phone: "
Language = 
, IPA prons=
, ASR prons=
, NvASR prons=
, XSAMPA prons=
ja-JP
zh_HK
aai1
aai2
aai3
aai4
aai5
aai6
aau1
aau2
aau3
aau4
aau5
aau6
eoi1
eoi2
eoi3
eoi4
eoi5
eoi6
d.ge
t.sh
a . a
a! . a
i . i
i! . i
M . M
M! . M
e . e
e! . e
o . o
o! . o
p . p
p . p_j
b . b
p\ . p\
t . t
t . ts
t . ts\
d . d
z . z
d . dz
k . k
k . k_j
g . g
s . s
s\ . s\
h . h
4 . 4
A_1_N
A_2_N
A_3_N
A_4_N
A_5_N
A_6_N
aI_1
aI_2
aI_3
aI_4
aI_5
aI_6
a_1_n
a_2_n
a_3_n
a_4_n
a_5_n
a_6_n
aU_1
aU_2
aU_3
aU_4
aU_5
aU_6
p_j_1
p_j_2
p_j_3
p_j_4
p_j_5
p_j_6
p O_1
BU.O1
p O_2
BU.O2
p O_3
BU.O3
p O_4
BU.O4
p O_5
BU.O5
p O_6
p u_1
BU.U1
p u_2
BU.U2
p u_3
BU.U3
p u_4
BU.U4
p u_5
BU.U5
p u_6
p i_1
BI.I1
p i_2
BI.I2
p i_3
BI.I3
p i_4
BI.I4
p i_5
BI.I5
p i_6
p i_1_n
BI.IN1
p i_2_n
BI.IN2
p i_3_n
BI.IN3
p i_4_n
BI.IN4
p i_5_n
BI.IN5
p i_6_n
p i_1_N
BI.IG1
p i_2_N
BI.IG2
p i_3_N
BI.IG3
p i_4_N
BI.IG4
p i_5_N
BI.IG5
p i_6_N
p_j_1 a_1_n
BI.AN1
p_j_2 a_2_n
BI.AN2
p_j_3 a_3_n
BI.AN3
p_j_4 a_4_n
BI.AN4
p_j_5 a_5_n
BI.AN5
p_j_6 a_6_n
p_j_1 aU_1
BI.AO1
p_j_2 aU_2
BI.AO2
p_j_3 aU_3
BI.AO3
p_j_4 aU_4
BI.AO4
p_j_5 aU_5
BI.AO5
p_j_6 aU_6
p_j_1 E_1
BI.IE1
p_j_2 E_2
BI.IE2
p_j_3 E_3
BI.IE3
p_j_4 E_4
BI.IE4
p_j_5 E_5
BI.IE5
p_j_6 E_6
ts_h
ts`_h
ts`_h_w
ts`_h o_1_N
CHU.OG1
ts`_h o_2_N
CHU.OG2
ts`_h o_3_N
CHU.OG3
ts`_h o_4_N
CHU.OG4
ts`_h o_5_N
CHU.OG5
ts`_h o_6_N
ts`_h u_1
CHU.U1
ts`_h u_2
CHU.U2
ts`_h u_3
CHU.U3
ts`_h u_4
CHU.U4
ts`_h u_5
CHU.U5
ts`_h u_6
ts`_h_w @_1_n
CHU.UN1
ts`_h_w @_2_n
CHU.UN2
ts`_h_w @_3_n
CHU.UN3
ts`_h_w @_4_n
CHU.UN4
ts`_h_w @_5_n
CHU.UN5
ts`_h_w @_6_n
ts_h_w
ts_h o_1_N
CU.OG1
ts_h o_2_N
CU.OG2
ts_h o_3_N
CU.OG3
ts_h o_4_N
CU.OG4
ts_h o_5_N
CU.OG5
ts_h o_6_N
ts_h u_1
CU.U1
ts_h u_2
CU.U2
ts_h u_3
CU.U3
ts_h u_4
CU.U4
ts_h u_5
CU.U5
ts_h u_6
ts_h_w @_1_n
CU.UN1
ts_h_w @_2_n
CU.UN2
ts_h_w @_3_n
CU.UN3
ts_h_w @_4_n
CU.UN4
ts_h_w @_5_n
CU.UN5
ts_h_w @_6_n
t_j_1
t_j_2
t_j_3
t_j_4
t_j_5
t_j_6
t i_1
DI.I1
t i_2
DI.I2
t i_3
DI.I3
t i_4
DI.I4
t i_5
DI.I5
t i_6
t i_1_N
DI.IG1
t i_2_N
DI.IG2
t i_3_N
DI.IG3
t i_4_N
DI.IG4
t i_5_N
DI.IG5
t i_6_N
t_j_1 a_1_n
DI.AN1
t_j_2 a_2_n
DI.AN2
t_j_3 a_3_n
DI.AN3
t_j_4 a_4_n
DI.AN4
t_j_5 a_5_n
DI.AN5
t_j_6 a_6_n
t_j_1 aU_1
DI.AO1
t_j_2 aU_2
DI.AO2
t_j_3 aU_3
DI.AO3
t_j_4 aU_4
DI.AO4
t_j_5 aU_5
DI.AO5
t_j_6 aU_6
t_j_1 E_1
DI.IE1
t_j_2 E_2
DI.IE2
t_j_3 E_3
DI.IE3
t_j_4 E_4
DI.IE4
t_j_5 E_5
DI.IE5
t_j_6 E_6
t_j_1 oU_1
DI.OU1
t_j_2 oU_2
DI.OU2
t_j_3 oU_3
DI.OU3
t_j_4 oU_4
DI.OU4
t_j_5 oU_5
DI.OU5
t_j_6 oU_6
t o_1_N
DU.OG1
t o_2_N
DU.OG2
t o_3_N
DU.OG3
t o_4_N
DU.OG4
t o_5_N
DU.OG5
t o_6_N
t u_1
DU.U1
t u_2
DU.U2
t u_3
DU.U3
t u_4
DU.U4
t u_5
DU.U5
t u_6
t_w @_1_n
DU.UN1
t_w @_2_n
DU.UN2
t_w @_3_n
DU.UN3
t_w @_4_n
DU.UN4
t_w @_5_n
DU.UN5
t_w @_6_n
@_1_N
@_2_N
@_3_N
@_4_N
@_5_N
@_6_N
eI_1
eI_2
eI_3
eI_4
eI_5
eI_6
@_1_n
@_2_n
@_3_n
@_4_n
@_5_n
@_6_n
@`_1
@`_2
@`_3
@`_4
@`_5
@`_6
k o_1_N
GU.OG1
k o_2_N
GU.OG2
k o_3_N
GU.OG3
k o_4_N
GU.OG4
k o_5_N
GU.OG5
k o_6_N
k u_1
GU.U1
k u_2
GU.U2
k u_3
GU.U3
k u_4
GU.U4
k u_5
GU.U5
k u_6
k_w @_1_n
GU.UN1
k_w @_2_n
GU.UN2
k_w @_3_n
GU.UN3
k_w @_4_n
GU.UN4
k_w @_5_n
GU.UN5
k_w @_6_n
x o_1_N
HU.OG1
x o_2_N
HU.OG2
x o_3_N
HU.OG3
x o_4_N
HU.OG4
x o_5_N
HU.OG5
x o_6_N
x u_1
HU.U1
x u_2
HU.U2
x u_3
HU.U3
x u_4
HU.U4
x u_5
HU.U5
x u_6
x_w @_1_n
HU.UN1
x_w @_2_n
HU.UN2
x_w @_3_n
HU.UN3
x_w @_4_n
HU.UN4
x_w @_5_n
HU.UN5
x_w @_6_n
i_1_N
i_2_N
i_3_N
i_4_N
i_5_N
i_6_N
i_1_n
i_2_n
i_3_n
i_4_n
i_5_n
i_6_n
ts\_j_1
ts\_j_2
ts\_j_3
ts\_j_4
ts\_j_5
ts\_j_6
ts\ i_1
JI.I1
ts\ i_2
JI.I2
ts\ i_3
JI.I3
ts\ i_4
JI.I4
ts\ i_5
JI.I5
ts\ i_6
ts\ i_1_n
JI.IN1
ts\ i_2_n
JI.IN2
ts\ i_3_n
JI.IN3
ts\ i_4_n
JI.IN4
ts\ i_5_n
JI.IN5
ts\ i_6_n
ts\ i_1_N
JI.IG1
ts\ i_2_N
JI.IG2
ts\ i_3_N
JI.IG3
ts\ i_4_N
JI.IG4
ts\ i_5_N
JI.IG5
ts\ i_6_N
ts\_j_1 a_1_n
JI.AN1
ts\_j_2 a_2_n
JI.AN2
ts\_j_3 a_3_n
JI.AN3
ts\_j_4 a_4_n
JI.AN4
ts\_j_5 a_5_n
JI.AN5
ts\_j_6 a_6_n
ts\_j_1 a_1
JI.A1
ts\_j_2 a_2
JI.A2
ts\_j_3 a_3
JI.A3
ts\_j_4 a_4
JI.A4
ts\_j_5 a_5
JI.A5
ts\_j_6 a_6
ts\_j_1 aU_1
JI.AO1
ts\_j_2 aU_2
JI.AO2
ts\_j_3 aU_3
JI.AO3
ts\_j_4 aU_4
JI.AO4
ts\_j_5 aU_5
JI.AO5
ts\_j_6 aU_6
ts\_j_1 E_1
JI.IE1
ts\_j_2 E_2
JI.IE2
ts\_j_3 E_3
JI.IE3
ts\_j_4 E_4
JI.IE4
ts\_j_5 E_5
JI.IE5
ts\_j_6 E_6
ts\_j_1 oU_1
JI.OU1
ts\_j_2 oU_2
JI.OU2
ts\_j_3 oU_3
JI.OU3
ts\_j_4 oU_4
JI.OU4
ts\_j_5 oU_5
JI.OU5
ts\_j_6 oU_6
ts\_j_1 A_1_N
JI.AG1
ts\_j_2 A_2_N
JI.AG2
ts\_j_3 A_3_N
JI.AG3
ts\_j_4 A_4_N
JI.AG4
ts\_j_5 A_5_N
JI.AG5
ts\_j_6 A_6_N
ts\_j_1 o_1_N
JI.OG1
ts\_j_2 o_2_N
JI.OG2
ts\_j_3 o_3_N
JI.OG3
ts\_j_4 o_4_N
JI.OG4
ts\_j_5 o_5_N
JI.OG5
ts\_j_6 o_6_N
ts\ y_1
JU.YU1
ts\ y_2
JU.YU2
ts\ y_3
JU.YU3
ts\ y_4
JU.YU4
ts\ y_5
JU.YU5
ts\ y_6
ts\_H_1
ts\_H_2
ts\_H_3
ts\_H_4
ts\_H_5
ts\_H_6
ts\_H_1 a_1_n
JU.AN1
ts\_H_2 a_2_n
JU.AN2
ts\_H_3 a_3_n
JU.AN3
ts\_H_4 a_4_n
JU.AN4
ts\_H_5 a_5_n
JU.AN5
ts\_H_6 a_6_n
ts\_H_1 E_1
JU.IE1
ts\_H_2 E_2
JU.IE2
ts\_H_3 E_3
JU.IE3
ts\_H_4 E_4
JU.IE4
ts\_H_5 E_5
JU.IE5
ts\_H_6 E_6
ts\_H_1 i_1_n
JU.IN1
ts\_H_2 i_2_n
JU.IN2
ts\_H_3 i_3_n
JU.IN3
ts\_H_4 i_4_n
JU.IN4
ts\_H_5 i_5_n
JU.IN5
ts\_H_6 i_6_n
k_h_w
k_h o_1_N
KU.OG1
k_h o_2_N
KU.OG2
k_h o_3_N
KU.OG3
k_h o_4_N
KU.OG4
k_h o_5_N
KU.OG5
k_h o_6_N
k_h u_1
KU.U1
k_h u_2
KU.U2
k_h u_3
KU.U3
k_h u_4
KU.U4
k_h u_5
KU.U5
k_h u_6
k_h_w @_1_n
KU.UN1
k_h_w @_2_n
KU.UN2
k_h_w @_3_n
KU.UN3
k_h_w @_4_n
KU.UN4
k_h_w @_5_n
KU.UN5
k_h_w @_6_n
l_j_1
l_j_2
l_j_3
l_j_4
l_j_5
l_j_6
l i_1
LI.I1
l i_2
LI.I2
l i_3
LI.I3
l i_4
LI.I4
l i_5
LI.I5
l i_6
l i_1_n
LI.IN1
l i_2_n
LI.IN2
l i_3_n
LI.IN3
l i_4_n
LI.IN4
l i_5_n
LI.IN5
l i_6_n
l i_1_N
LI.IG1
l i_2_N
LI.IG2
l i_3_N
LI.IG3
l i_4_N
LI.IG4
l i_5_N
LI.IG5
l i_6_N
l_j_1 a_1_n
LI.AN1
l_j_2 a_2_n
LI.AN2
l_j_3 a_3_n
LI.AN3
l_j_4 a_4_n
LI.AN4
l_j_5 a_5_n
LI.AN5
l_j_6 a_6_n
l_j_1 a_1
LI.A1
l_j_2 a_2
LI.A2
l_j_3 a_3
LI.A3
l_j_4 a_4
LI.A4
l_j_5 a_5
LI.A5
l_j_6 a_6
l_j_1 aU_1
LI.AO1
l_j_2 aU_2
LI.AO2
l_j_3 aU_3
LI.AO3
l_j_4 aU_4
LI.AO4
l_j_5 aU_5
LI.AO5
l_j_6 aU_6
l_j_1 E_1
LI.IE1
l_j_2 E_2
LI.IE2
l_j_3 E_3
LI.IE3
l_j_4 E_4
LI.IE4
l_j_5 E_5
LI.IE5
l_j_6 E_6
l_j_1 oU_1
LI.OU1
l_j_2 oU_2
LI.OU2
l_j_3 oU_3
LI.OU3
l_j_4 oU_4
LI.OU4
l_j_5 oU_5
LI.OU5
l_j_6 oU_6
l_j_1 A_1_N
LI.AG1
l_j_2 A_2_N
LI.AG2
l_j_3 A_3_N
LI.AG3
l_j_4 A_4_N
LI.AG4
l_j_5 A_5_N
LI.AG5
l_j_6 A_6_N
l o_1_N
LU.OG1
l o_2_N
LU.OG2
l o_3_N
LU.OG3
l o_4_N
LU.OG4
l o_5_N
LU.OG5
l o_6_N
l u_1
LU.U1
l u_2
LU.U2
l u_3
LU.U3
l u_4
LU.U4
l u_5
LU.U5
l u_6
l_w @_1_n
LU.UN1
l_w @_2_n
LU.UN2
l_w @_3_n
LU.UN3
l_w @_4_n
LU.UN4
l_w @_5_n
LU.UN5
l_w @_6_n
l_H_1
l_H_2
l_H_3
l_H_4
l_H_5
l_H_6
l_H_1 E_1
LYU.IE1
l_H_2 E_2
LYU.IE2
l_H_3 E_3
LYU.IE3
l_H_4 E_4
LYU.IE4
l_H_5 E_5
LYU.IE5
l_H_6 E_6
l y_1
LYU.YU1
l y_2
LYU.YU2
l y_3
LYU.YU3
l y_4
LYU.YU4
l y_5
LYU.YU5
l y_6
m_j_1
m_j_2
m_j_3
m_j_4
m_j_5
m_j_6
m u_1
MU.U1
m u_2
MU.U2
m u_3
MU.U3
m u_4
MU.U4
m u_5
MU.U5
m u_6
m i_1
MI.I1
m i_2
MI.I2
m i_3
MI.I3
m i_4
MI.I4
m i_5
MI.I5
m i_6
m i_1_n
MI.IN1
m i_2_n
MI.IN2
m i_3_n
MI.IN3
m i_4_n
MI.IN4
m i_5_n
MI.IN5
m i_6_n
m i_1_N
MI.IG1
m i_2_N
MI.IG2
m i_3_N
MI.IG3
m i_4_N
MI.IG4
m i_5_N
MI.IG5
m i_6_N
m_j_1 a_1_n
MI.AN1
m_j_2 a_2_n
MI.AN2
m_j_3 a_3_n
MI.AN3
m_j_4 a_4_n
MI.AN4
m_j_5 a_5_n
MI.AN5
m_j_6 a_6_n
m_j_1 aU_1
MI.AO1
m_j_2 aU_2
MI.AO2
m_j_3 aU_3
MI.AO3
m_j_4 aU_4
MI.AO4
m_j_5 aU_5
MI.AO5
m_j_6 aU_6
m_j_1 E_1
MI.IE1
m_j_2 E_2
MI.IE2
m_j_3 E_3
MI.IE3
m_j_4 E_4
MI.IE4
m_j_5 E_5
MI.IE5
m_j_6 E_6
m_j_1 oU_1
MI.OU1
m_j_2 oU_2
MI.OU2
m_j_3 oU_3
MI.OU3
m_j_4 oU_4
MI.OU4
m_j_5 oU_5
MI.OU5
m_j_6 oU_6
n_j_1
n_j_2
n_j_3
n_j_4
n_j_5
n_j_6
n i_1
NI.I1
n i_2
NI.I2
n i_3
NI.I3
n i_4
NI.I4
n i_5
NI.I5
n i_6
n i_1_n
NI.IN1
n i_2_n
NI.IN2
n i_3_n
NI.IN3
n i_4_n
NI.IN4
n i_5_n
NI.IN5
n i_6_n
n i_1_N
NI.IG1
n i_2_N
NI.IG2
n i_3_N
NI.IG3
n i_4_N
NI.IG4
n i_5_N
NI.IG5
n i_6_N
n_j_1 a_1_n
NI.AN1
n_j_2 a_2_n
NI.AN2
n_j_3 a_3_n
NI.AN3
n_j_4 a_4_n
NI.AN4
n_j_5 a_5_n
NI.AN5
n_j_6 a_6_n
n_j_1 aU_1
NI.AO1
n_j_2 aU_2
NI.AO2
n_j_3 aU_3
NI.AO3
n_j_4 aU_4
NI.AO4
n_j_5 aU_5
NI.AO5
n_j_6 aU_6
n_j_1 E_1
NI.IE1
n_j_2 E_2
NI.IE2
n_j_3 E_3
NI.IE3
n_j_4 E_4
NI.IE4
n_j_5 E_5
NI.IE5
n_j_6 E_6
n_j_1 oU_1
NI.OU1
n_j_2 oU_2
NI.OU2
n_j_3 oU_3
NI.OU3
n_j_4 oU_4
NI.OU4
n_j_5 oU_5
NI.OU5
n_j_6 oU_6
n_j_1 A_1_N
NI.AG1
n_j_2 A_2_N
NI.AG2
n_j_3 A_3_N
NI.AG3
n_j_4 A_4_N
NI.AG4
n_j_5 A_5_N
NI.AG5
n_j_6 A_6_N
n o_1_N
NU.OG1
n o_2_N
NU.OG2
n o_3_N
NU.OG3
n o_4_N
NU.OG4
n o_5_N
NU.OG5
n o_6_N
n u_1
NU.U1
n u_2
NU.U2
n u_3
NU.U3
n u_4
NU.U4
n u_5
NU.U5
n u_6
n_H_1
n_H_2
n_H_3
n_H_4
n_H_5
n_H_6
n_H_1 E_1
NYU.IE1
n_H_2 E_2
NYU.IE2
n_H_3 E_3
NYU.IE3
n_H_4 E_4
NYU.IE4
n_H_5 E_5
NYU.IE5
n_H_6 E_6
n y_1
NYU.YU1
n y_2
NYU.YU2
n y_3
NYU.YU3
n y_4
NYU.YU4
n y_5
NYU.YU5
n y_6
o_1_N
o_2_N
o_3_N
o_4_N
o_5_N
o_6_N
oU_1
oU_2
oU_3
oU_4
oU_5
oU_6
p_h_j_1
p_h_j_2
p_h_j_3
p_h_j_4
p_h_j_5
p_h_j_6
p_h i_1
PI.I1
p_h i_2
PI.I2
p_h i_3
PI.I3
p_h i_4
PI.I4
p_h i_5
PI.I5
p_h i_6
p_h i_1_n
PI.IN1
p_h i_2_n
PI.IN2
p_h i_3_n
PI.IN3
p_h i_4_n
PI.IN4
p_h i_5_n
PI.IN5
p_h i_6_n
p_h i_1_N
PI.IG1
p_h i_2_N
PI.IG2
p_h i_3_N
PI.IG3
p_h i_4_N
PI.IG4
p_h i_5_N
PI.IG5
p_h i_6_N
p_h_j_1 a_1_n
PI.AN1
p_h_j_2 a_2_n
PI.AN2
p_h_j_3 a_3_n
PI.AN3
p_h_j_4 a_4_n
PI.AN4
p_h_j_5 a_5_n
PI.AN5
p_h_j_6 a_6_n
p_h_j_1 aU_1
PI.AO1
p_h_j_2 aU_2
PI.AO2
p_h_j_3 aU_3
PI.AO3
p_h_j_4 aU_4
PI.AO4
p_h_j_5 aU_5
PI.AO5
p_h_j_6 aU_6
p_h_j_1 E_1
PI.IE1
p_h_j_2 E_2
PI.IE2
p_h_j_3 E_3
PI.IE3
p_h_j_4 E_4
PI.IE4
p_h_j_5 E_5
PI.IE5
p_h_j_6 E_6
ts\_h_j_1
ts\_h_j_2
ts\_h_j_3
ts\_h_j_4
ts\_h_j_5
ts\_h_j_6
ts\_h i_1
QI.I1
ts\_h i_2
QI.I2
ts\_h i_3
QI.I3
ts\_h i_4
QI.I4
ts\_h i_5
QI.I5
ts\_h i_6
ts\_h i_1_n
QI.IN1
ts\_h i_2_n
QI.IN2
ts\_h i_3_n
QI.IN3
ts\_h i_4_n
QI.IN4
ts\_h i_5_n
QI.IN5
ts\_h i_6_n
ts\_h i_1_N
QI.IG1
ts\_h i_2_N
QI.IG2
ts\_h i_3_N
QI.IG3
ts\_h i_4_N
QI.IG4
ts\_h i_5_N
QI.IG5
ts\_h i_6_N
ts\_h_j_1 a_1_n
QI.AN1
ts\_h_j_2 a_2_n
QI.AN2
ts\_h_j_3 a_3_n
QI.AN3
ts\_h_j_4 a_4_n
QI.AN4
ts\_h_j_5 a_5_n
QI.AN5
ts\_h_j_6 a_6_n
ts\_h_j_1 a_1
QI.A1
ts\_h_j_2 a_2
QI.A2
ts\_h_j_3 a_3
QI.A3
ts\_h_j_4 a_4
QI.A4
ts\_h_j_5 a_5
QI.A5
ts\_h_j_6 a_6
ts\_h_j_1 aU_1
QI.AO1
ts\_h_j_2 aU_2
QI.AO2
ts\_h_j_3 aU_3
QI.AO3
ts\_h_j_4 aU_4
QI.AO4
ts\_h_j_5 aU_5
QI.AO5
ts\_h_j_6 aU_6
ts\_h_j_1 E_1
QI.IE1
ts\_h_j_2 E_2
QI.IE2
ts\_h_j_3 E_3
QI.IE3
ts\_h_j_4 E_4
QI.IE4
ts\_h_j_5 E_5
QI.IE5
ts\_h_j_6 E_6
ts\_h_j_1 oU_1
QI.OU1
ts\_h_j_2 oU_2
QI.OU2
ts\_h_j_3 oU_3
QI.OU3
ts\_h_j_4 oU_4
QI.OU4
ts\_h_j_5 oU_5
QI.OU5
ts\_h_j_6 oU_6
ts\_h_j_1 A_1_N
QI.AG1
ts\_h_j_2 A_2_N
QI.AG2
ts\_h_j_3 A_3_N
QI.AG3
ts\_h_j_4 A_4_N
QI.AG4
ts\_h_j_5 A_5_N
QI.AG5
ts\_h_j_6 A_6_N
ts\_h_j_1 o_1_N
QI.OG1
ts\_h_j_2 o_2_N
QI.OG2
ts\_h_j_3 o_3_N
QI.OG3
ts\_h_j_4 o_4_N
QI.OG4
ts\_h_j_5 o_5_N
QI.OG5
ts\_h_j_6 o_6_N
ts\_h y_1
QU.YU1
ts\_h y_2
QU.YU2
ts\_h y_3
QU.YU3
ts\_h y_4
QU.YU4
ts\_h y_5
QU.YU5
ts\_h y_6
ts\_h_H_1
ts\_h_H_2
ts\_h_H_3
ts\_h_H_4
ts\_h_H_5
ts\_h_H_6
ts\_h_H_1 a_1_n
QU.AN1
ts\_h_H_2 a_2_n
QU.AN2
ts\_h_H_3 a_3_n
QU.AN3
ts\_h_H_4 a_4_n
QU.AN4
ts\_h_H_5 a_5_n
QU.AN5
ts\_h_H_6 a_6_n
ts\_h_H_1 i_1_n
QU.IN1
ts\_h_H_2 i_2_n
QU.IN2
ts\_h_H_3 i_3_n
QU.IN3
ts\_h_H_4 i_4_n
QU.IN4
ts\_h_H_5 i_5_n
QU.IN5
ts\_h_H_6 i_6_n
ts\_h_H_1 E_1
QU.IE1
ts\_h_H_2 E_2
QU.IE2
ts\_h_H_3 E_3
QU.IE3
ts\_h_H_4 E_4
QU.IE4
ts\_h_H_5 E_5
QU.IE5
ts\_h_H_6 E_6
z`_w
z` u_1
RU.U1
z` u_2
RU.U2
z` u_3
RU.U3
z` u_4
RU.U4
z` u_6
z`_w @_1_n
RU.UN1
z`_w @_2_n
RU.UN2
z`_w @_3_n
RU.UN3
z`_w @_4_n
RU.UN4
z`_w @_5_n
RU.UN5
z`_w @_6_n
s`_w
s` u_1
SHU.U1
s` u_2
SHU.U2
s` u_3
SHU.U3
s` u_4
SHU.U4
s` u_5
SHU.U5
s` u_6
s`_w @_1_n
SHU.UN1
s`_w @_2_n
SHU.UN2
s`_w @_3_n
SHU.UN3
s`_w @_4_n
SHU.UN4
s`_w @_5_n
SHU.UN5
s`_w @_6_n
s o_1_N
SU.OG1
s o_2_N
SU.OG2
s o_3_N
SU.OG3
s o_4_N
SU.OG4
s o_5_N
SU.OG5
s o_6_N
s u_1
SU.U1
s u_2
SU.U2
s u_3
SU.U3
s u_4
SU.U4
s u_5
SU.U5
s u_6
s_w @_1_n
SU.UN1
s_w @_2_n
SU.UN2
s_w @_3_n
SU.UN3
s_w @_4_n
SU.UN4
s_w @_5_n
SU.UN5
s_w @_6_n
t_h_j_1
t_h_j_2
t_h_j_3
t_h_j_4
t_h_j_5
t_h_j_6
t_h i_1
TI.I1
t_h i_2
TI.I2
t_h i_3
TI.I3
t_h i_4
TI.I4
t_h i_5
TI.I5
t_h i_6
t_h i_1_N
TI.IG1
t_h i_2_N
TI.IG2
t_h i_3_N
TI.IG3
t_h i_4_N
TI.IG4
t_h i_5_N
TI.IG5
t_h i_6_N
t_h_j_1 a_1_n
TI.AN1
t_h_j_2 a_2_n
TI.AN2
t_h_j_3 a_3_n
TI.AN3
t_h_j_4 a_4_n
TI.AN4
t_h_j_5 a_5_n
TI.AN5
t_h_j_6 a_6_n
TI.AN6
t_h_j_1 aU_1
TI.AO1
t_h_j_2 aU_2
TI.AO2
t_h_j_3 aU_3
TI.AO3
t_h_j_4 aU_4
TI.AO4
t_h_j_5 aU_5
TI.AO5
t_h_j_6 aU_6
t_h_j_1 E_1
TI.IE1
t_h_j_2 E_2
TI.IE2
t_h_j_3 E_3
TI.IE3
t_h_j_4 E_4
TI.IE4
t_h_j_5 E_5
TI.IE5
t_h_j_6 E_6
t_h o_1_N
TU.OG1
t_h o_2_N
TU.OG2
t_h o_3_N
TU.OG3
t_h o_4_N
TU.OG4
t_h o_5_N
TU.OG5
t_h o_6_N
t_h_w
t_h u_1
TU.U1
t_h u_2
TU.U2
t_h u_3
TU.U3
t_h u_4
TU.U4
t_h u_5
TU.U5
t_h u_6
t_h_w @_1_n
TU.UN1
t_h_w @_2_n
TU.UN2
t_h_w @_3_n
TU.UN3
t_h_w @_4_n
TU.UN4
t_h_w @_5_n
TU.UN5
t_h_w @_6_n
u_1_n
u_2_n
u_3_n
u_4_n
u_5_n
u_6_n
s\_j_1
s\_j_2
s\_j_3
s\_j_4
s\_j_5
s\_j_6
s\ i_1
XI.I1
s\ i_2
XI.I2
s\ i_3
XI.I3
s\ i_4
XI.I4
s\ i_5
XI.I5
s\ i_6
s\ i_1_n
XI.IN1
s\ i_2_n
XI.IN2
s\ i_3_n
XI.IN3
s\ i_4_n
XI.IN4
s\ i_5_n
XI.IN5
s\ i_6_n
s\ i_1_N
XI.IG1
s\ i_2_N
XI.IG2
s\ i_3_N
XI.IG3
s\ i_4_N
XI.IG4
s\ i_5_N
XI.IG5
s\ i_6_N
s\_j_1 a_1_n
XI.AN1
s\_j_2 a_2_n
XI.AN2
s\_j_3 a_3_n
XI.AN3
s\_j_4 a_4_n
XI.AN4
s\_j_5 a_5_n
XI.AN5
s\_j_6 a_6_n
s\_j_1 a_1
XI.A1
s\_j_2 a_2
XI.A2
s\_j_3 a_3
XI.A3
s\_j_4 a_4
XI.A4
s\_j_5 a_5
XI.A5
s\_j_6 a_6
s\_j_1 aU_1
XI.AO1
s\_j_2 aU_2
XI.AO2
s\_j_3 aU_3
XI.AO3
s\_j_4 aU_4
XI.AO4
s\_j_5 aU_5
XI.AO5
s\_j_6 aU_6
s\_j_1 E_1
XI.IE1
s\_j_2 E_2
XI.IE2
s\_j_3 E_3
XI.IE3
s\_j_4 E_4
XI.IE4
s\_j_5 E_5
XI.IE5
s\_j_6 E_6
s\_j_1 oU_1
XI.OU1
s\_j_2 oU_2
XI.OU2
s\_j_3 oU_3
XI.OU3
s\_j_4 oU_4
XI.OU4
s\_j_5 oU_5
XI.OU5
s\_j_6 oU_6
s\_j_1 A_1_N
XI.AG1
s\_j_2 A_2_N
XI.AG2
s\_j_3 A_3_N
XI.AG3
s\_j_4 A_4_N
XI.AG4
s\_j_5 A_5_N
XI.AG5
s\_j_6 A_6_N
s\_j_1 o_1_N
XI.OG1
s\_j_2 o_2_N
XI.OG2
s\_j_3 o_3_N
XI.OG3
s\_j_4 o_4_N
XI.OG4
s\_j_5 o_5_N
XI.OG5
s\_j_6 o_6_N
s\ y_1
XU.YU1
s\ y_2
XU.YU2
s\ y_3
XU.YU3
s\ y_4
XU.YU4
s\ y_5
XU.YU5
s\ y_6
s\_H_1
s\_H_2
s\_H_3
s\_H_4
s\_H_5
s\_H_6
s\_H_1 a_1_n
XU.AN1
s\_H_2 a_2_n
XU.AN2
s\_H_3 a_3_n
XU.AN3
s\_H_4 a_4_n
XU.AN4
s\_H_5 a_5_n
XU.AN5
s\_H_6 a_6_n
s\_H_1 i_1_n
XU.IN1
s\_H_2 i_2_n
XU.IN2
s\_H_3 i_3_n
XU.IN3
s\_H_4 i_4_n
XU.IN4
s\_H_5 i_5_n
XU.IN5
s\_H_6 i_6_n
s\_H_1 E_1
XU.IE1
s\_H_2 E_2
XU.IE2
s\_H_3 E_3
XU.IE3
s\_H_4 E_4
XU.IE4
s\_H_5 E_5
XU.IE5
s\_H_6 E_6
j_1 i_1
Y.I1
j_2 i_2
Y.I2
j_3 i_3
Y.I3
j_4 i_4
Y.I4
j_5 i_5
Y.I5
j_6 i_6
j_1 a_1
Y.A1
j_2 a_2
Y.A2
j_3 a_3
Y.A3
j_4 a_4
Y.A4
j_5 a_5
Y.A5
j_6 a_6
j_1 aU_1
Y.AO1
j_2 aU_2
Y.AO2
j_3 aU_3
Y.AO3
j_4 aU_4
Y.AO4
j_5 aU_5
Y.AO5
j_6 aU_6
j_1 E_1
Y.IE1
j_2 E_2
Y.IE2
j_3 E_3
Y.IE3
j_4 E_4
Y.IE4
j_5 E_5
Y.IE5
j_6 E_6
j_1 oU_1
Y.OU1
j_2 oU_2
Y.OU2
j_3 oU_3
Y.OU3
j_4 oU_4
Y.OU4
j_5 oU_5
Y.OU5
j_6 oU_6
j_1 i_1_n
Y.IN1
j_2 i_2_n
Y.IN2
j_3 i_3_n
Y.IN3
j_4 i_4_n
Y.IN4
j_5 i_5_n
Y.IN5
j_6 i_6_n
j_1 A_1_N
Y.AG1
j_2 A_2_N
Y.AG2
j_3 A_3_N
Y.AG3
j_4 A_4_N
Y.AG4
j_5 A_5_N
Y.AG5
j_6 A_6_N
j_1 i_1_N
Y.IG1
j_2 i_2_N
Y.IG2
j_3 i_3_N
Y.IG3
j_4 i_4_N
Y.IG4
j_5 i_5_N
Y.IG5
j_6 i_6_N
j_1 o_1_N
Y.OG1
j_2 o_2_N
Y.OG2
j_3 o_3_N
Y.OG3
j_4 o_4_N
Y.OG4
j_5 o_5_N
Y.OG5
j_6 o_6_N
j_1 a_1_n
Y.AN1
j_2 a_2_n
Y.AN2
j_3 a_3_n
Y.AN3
j_4 a_4_n
Y.AN4
j_5 a_5_n
Y.AN5
j_6 a_6_n
j_1 y_1
YU.YU1
j_2 y_2
YU.YU2
j_3 y_3
YU.YU3
j_4 y_4
YU.YU4
j_5 y_5
YU.YU5
j_6 y_6
j_H_1
j_H_2
j_H_3
j_H_4
j_H_5
j_H_6
j_H_1 a_1_n
YU.AN1
j_H_2 a_2_n
YU.AN2
j_H_3 a_3_n
YU.AN3
j_H_4 a_4_n
YU.AN4
j_H_5 a_5_n
YU.AN5
j_H_6 a_6_n
j_H_1 i_1_n
YU.IN1
j_H_2 i_2_n
YU.IN2
j_H_3 i_3_n
YU.IN3
j_H_4 i_4_n
YU.IN4
j_H_5 i_5_n
YU.IN5
j_H_6 i_6_n
j_H_1 E_1
YU.IE1
j_H_2 E_2
YU.IE2
j_H_3 E_3
YU.IE3
j_H_4 E_4
YU.IE4
j_H_5 E_5
YU.IE5
j_H_6 E_6
ts`_w
ts` o_1_N
ZHU.OG1
ts` o_2_N
ZHU.OG2
ts` o_3_N
ZHU.OG3
ts` o_4_N
ZHU.OG4
ts` o_5_N
ZHU.OG5
ts` o_6_N
ts` u_1
ZHU.U1
ts` u_2
ZHU.U2
ts` u_3
ZHU.U3
ts` u_4
ZHU.U4
ts` u_5
ZHU.U5
ts` u_6
ts`_w @_1_n
ZHU.UN1
ts`_w @_2_n
ZHU.UN2
ts`_w @_3_n
ZHU.UN3
ts`_w @_4_n
ZHU.UN4
ts`_w @_5_n
ZHU.UN5
ts`_w @_6_n
ts_w
ts o_1_N
ZU.OG1
ts o_2_N
ZU.OG2
ts o_3_N
ZU.OG3
ts o_4_N
ZU.OG4
ts o_5_N
ZU.OG5
ts o_6_N
ts u_1
ZU.U1
ts u_2
ZU.U2
ts u_3
ZU.U3
ts u_4
ZU.U4
ts u_5
ZU.U5
ts u_6
ts_w @_1_n
ZU.UN1
ts_w @_2_n
ZU.UN2
ts_w @_3_n
ZU.UN3
ts_w @_4_n
ZU.UN4
ts_w @_5_n
ZU.UN5
ts_w @_6_n
a_1_n r\
AN1.R
aI_1 r\
AI1.R
p_j_1 a_1_n r\
BI.AN1.R
p_h_j_1 a_1_n r\
PI.AN1.R
t_j_1 a_1_n r\
DI.AN1.R
t_h_j_1 a_1_n r\
TI.AN1.R
l_j_1 a_1_n r\
LI.AN1.R
m_j_1 a_1_n r\
MI.AN1.R
n_j_1 a_1_n r\
NI.AN1.R
ts\_j_1 a_1_n r\
JI.AN1.R
ts\_H_1 a_1_n r\
JU.AN1.R
ts\_h_j_1 a_1_n r\
QI.AN1.R
ts\_h_H_1 a_1_n r\
QU.AN1.R
s\_j_1 a_1_n r\
XI.AN1.R
s\_H_1 a_1_n r\
XU.AN1.R
j_1 a_1_n r\
Y.AN1.R
j_H_1 a_1_n r\
YU.AN1.R
a_2_n r\
AN2.R
aI_2 r\
AI2.R
p_j_2 a_2_n r\
BI.AN2.R
p_h_j_2 a_2_n r\
PI.AN2.R
t_j_2 a_2_n r\
DI.AN2.R
t_h_j_2 a_2_n r\
TI.AN2.R
l_j_2 a_2_n r\
LI.AN2.R
m_j_2 a_2_n r\
MI.AN2.R
n_j_2 a_2_n r\
NI.AN2.R
ts\_j_2 a_2_n r\
JI.AN2.R
ts\_H_2 a_2_n r\
JU.AN2.R
ts\_h_j_2 a_2_n r\
QI.AN2.R
ts\_h_H_2 a_2_n r\
QU.AN2.R
s\_j_2 a_2_n r\
XI.AN2.R
s\_H_2 a_2_n r\
XU.AN2.R
j_2 a_2_n r\
Y.AN2.R
j_H_2 a_2_n r\
YU.AN2.R
a_3_n r\
AN3.R
aI_3 r\
AI3.R
p_j_3 a_3_n r\
BI.AN3.R
p_h_j_3 a_3_n r\
PI.AN3.R
t_j_3 a_3_n r\
DI.AN3.R
t_h_j_3 a_3_n r\
TI.AN3.R
l_j_3 a_3_n r\
LI.AN3.R
m_j_3 a_3_n r\
MI.AN3.R
n_j_3 a_3_n r\
NI.AN3.R
ts\_j_3 a_3_n r\
JI.AN3.R
ts\_H_3 a_3_n r\
JU.AN3.R
ts\_h_j_3 a_3_n r\
QI.AN3.R
ts\_h_H_3 a_3_n r\
QU.AN3.R
s\_j_3 a_3_n r\
XI.AN3.R
s\_H_3 a_3_n r\
XU.AN3.R
j_3 a_3_n r\
Y.AN3.R
j_H_3 a_3_n r\
YU.AN3.R
a_4_n r\
AN4.R
aI_4 r\
AI4.R
p_j_4 a_4_n r\
BI.AN4.R
p_h_j_4 a_4_n r\
PI.AN4.R
t_j_4 a_4_n r\
DI.AN4.R
t_h_j_4 a_4_n r\
TI.AN4.R
l_j_4 a_4_n r\
LI.AN4.R
m_j_4 a_4_n r\
MI.AN4.R
n_j_4 a_4_n r\
NI.AN4.R
ts\_j_4 a_4_n r\
JI.AN4.R
ts\_H_4 a_4_n r\
JU.AN4.R
ts\_h_j_4 a_4_n r\
QI.AN4.R
ts\_h_H_4 a_4_n r\
QU.AN4.R
s\_j_4 a_4_n r\
XI.AN4.R
s\_H_4 a_4_n r\
XU.AN4.R
j_4 a_4_n r\
Y.AN4.R
j_H_4 a_4_n r\
YU.AN4.R
a_5_n r\
AN5.R
aI_5 r\
AI5.R
p_j_5 a_5_n r\
BI.AN5.R
p_h_j_5 a_5_n r\
PI.AN5.R
t_j_5 a_5_n r\
DI.AN5.R
t_h_j_5 a_5_n r\
TI.AN5.R
l_j_5 a_5_n r\
LI.AN5.R
m_j_5 a_5_n r\
MI.AN5.R
n_j_5 a_5_n r\
NI.AN5.R
ts\_j_5 a_5_n r\
JI.AN5.R
ts\_H_5 a_5_n r\
JU.AN5.R
ts\_h_j_5 a_5_n r\
QI.AN5.R
ts\_h_H_5 a_5_n r\
QU.AN5.R
s\_j_5 a_5_n r\
XI.AN5.R
s\_H_5 a_5_n r\
XU.AN5.R
j_5 a_5_n r\
Y.AN5.R
j_H_5 a_5_n r\
YU.AN5.R
a_6_n r\
aI_6 r\
p_j_6 a_6_n r\
p_h_j_6 a_6_n r\
t_j_6 a_6_n r\
t_h_j_6 a_6_n r\
l_j_6 a_6_n r\
m_j_6 a_6_n r\
n_j_6 a_6_n r\
ts\_j_6 a_6_n r\
ts\_H_6 a_6_n r\
ts\_h_j_6 a_6_n r\
ts\_h_H_6 a_6_n r\
s\_j_6 a_6_n r\
s\_H_6 a_6_n r\
j_6 a_6_n r\
j_H_6 a_6_n r\
a_1 r\
A1.R
a_2 r\
A2.R
a_3 r\
A3.R
a_4 r\
A4.R
a_5 r\
A5.R
a_6 r\
j_1 a_1 r\
Y.A1.R
j_2 a_2 r\
Y.A2.R
j_3 a_3 r\
Y.A3.R
j_4 a_4 r\
Y.A4.R
j_5 a_5 r\
Y.A5.R
j_6 a_6 r\
l_j_1 a_1 r\
LI.A1.R
l_j_2 a_2 r\
LI.A2.R
l_j_3 a_3 r\
LI.A3.R
l_j_4 a_4 r\
LI.A4.R
l_j_5 a_5 r\
LI.A5.R
l_j_6 a_6 r\
ts\_j_1 a_1 r\
JI.A1.R
ts\_j_2 a_2 r\
JI.A2.R
ts\_j_3 a_3 r\
JI.A3.R
ts\_j_4 a_4 r\
JI.A4.R
ts\_j_5 a_5 r\
JI.A5.R
ts\_j_6 a_6 r\
ts\_h_j_1 a_1 r\
QI.A1.R
ts\_h_j_2 a_2 r\
QI.A2.R
ts\_h_j_3 a_3 r\
QI.A3.R
ts\_h_j_4 a_4 r\
QI.A4.R
ts\_h_j_5 a_5 r\
QI.A5.R
ts\_h_j_6 a_6 r\
s\_j_1 a_1 r\
XI.A1.R
s\_j_2 a_2 r\
XI.A2.R
s\_j_3 a_3 r\
XI.A3.R
s\_j_4 a_4 r\
XI.A4.R
s\_j_5 a_5 r\
XI.A5.R
s\_j_6 a_6 r\
aU_1 r\
AO1.R
aU_2 r\
AO2.R
aU_3 r\
AO3.R
aU_4 r\
AO4.R
aU_5 r\
AO5.R
aU_6 r\
p_j_1 aU_1 r\
BI.AO1.R
p_j_2 aU_2 r\
BI.AO2.R
p_j_3 aU_3 r\
BI.AO3.R
p_j_4 aU_4 r\
BI.AO4.R
p_j_5 aU_5 r\
BI.AO5.R
p_j_6 aU_6 r\
p_h_j_1 aU_1 r\
PI.AO1.R
p_h_j_2 aU_2 r\
PI.AO2.R
p_h_j_3 aU_3 r\
PI.AO3.R
p_h_j_4 aU_4 r\
PI.AO4.R
p_h_j_5 aU_5 r\
PI.AO5.R
p_h_j_6 aU_6 r\
t_j_1 aU_1 r\
DI.AO1.R
t_j_2 aU_2 r\
DI.AO2.R
t_j_3 aU_3 r\
DI.AO3.R
t_j_4 aU_4 r\
DI.AO4.R
t_j_5 aU_5 r\
DI.AO5.R
t_j_6 aU_6 r\
t_h_j_1 aU_1 r\
TI.AO1.R
t_h_j_2 aU_2 r\
TI.AO2.R
t_h_j_3 aU_3 r\
TI.AO3.R
t_h_j_4 aU_4 r\
TI.AO4.R
t_h_j_5 aU_5 r\
TI.AO5.R
t_h_j_6 aU_6 r\
l_j_1 aU_1 r\
LI.AO1.R
l_j_2 aU_2 r\
LI.AO2.R
l_j_3 aU_3 r\
LI.AO3.R
l_j_4 aU_4 r\
LI.AO4.R
l_j_5 aU_5 r\
LI.AO5.R
l_j_6 aU_6 r\
m_j_1 aU_1 r\
MI.AO1.R
m_j_2 aU_2 r\
MI.AO2.R
m_j_3 aU_3 r\
MI.AO3.R
m_j_4 aU_4 r\
MI.AO4.R
m_j_5 aU_5 r\
MI.AO5.R
m_j_6 aU_6 r\
n_j_1 aU_1 r\
NI.AO1.R
n_j_2 aU_2 r\
NI.AO2.R
n_j_3 aU_3 r\
NI.AO3.R
n_j_4 aU_4 r\
NI.AO4.R
n_j_5 aU_5 r\
NI.AO5.R
n_j_6 aU_6 r\
ts\_j_1 aU_1 r\
JI.AO1.R
ts\_j_2 aU_2 r\
JI.AO2.R
ts\_j_3 aU_3 r\
JI.AO3.R
ts\_j_4 aU_4 r\
JI.AO4.R
ts\_j_5 aU_5 r\
JI.AO5.R
ts\_j_6 aU_6 r\
ts\_h_j_1 aU_1 r\
QI.AO1.R
ts\_h_j_2 aU_2 r\
QI.AO2.R
ts\_h_j_3 aU_3 r\
QI.AO3.R
ts\_h_j_4 aU_4 r\
QI.AO4.R
ts\_h_j_5 aU_5 r\
QI.AO5.R
ts\_h_j_6 aU_6 r\
s\_j_1 aU_1 r\
XI.AO1.R
s\_j_2 aU_2 r\
XI.AO2.R
s\_j_3 aU_3 r\
XI.AO3.R
s\_j_4 aU_4 r\
XI.AO4.R
s\_j_5 aU_5 r\
XI.AO5.R
s\_j_6 aU_6 r\
j_1 aU_1 r\
Y.AO1.R
j_2 aU_2 r\
Y.AO2.R
j_3 aU_3 r\
Y.AO3.R
j_4 aU_4 r\
Y.AO4.R
j_5 aU_5 r\
Y.AO5.R
j_6 aU_6 r\
@_1_n r\
EN1.R
1_1 r\
IH1.R
M_1 r\
eI_1 r\
EI1.R
y_1 r\
YU1.R
n y_1 r\
NYU.YU1.R
l y_1 r\
LYU.YU1.R
ts\ y_1 r\
JU.YU1.R
ts\_h y_1 r\
QU.YU1.R
s\ y_1 r\
XU.YU1.R
j_1 y_1 r\
YU.YU1.R
i_1_n r\
IN1.R
i_1 r\
I1.R
p i_1_n r\
BI.IN1.R
p_h i_1_n r\
PI.IN1.R
m i_1_n r\
MI.IN1.R
n i_1_n r\
NI.IN1.R
l i_1_n r\
LI.IN1.R
ts\ i_1_n r\
JI.IN1.R
ts\_h i_1_n r\
QI.IN1.R
s\ i_1_n r\
XI.IN1.R
j_1 i_1_n r\
Y.IN1.R
t_w @_1_n r\
DU.UN1.R
t_h_w @_1_n r\
TU.UN1.R
l_w @_1_n r\
LU.UN1.R
k_w @_1_n r\
GU.UN1.R
k_h_w @_1_n r\
KU.UN1.R
x_w @_1_n r\
HU.UN1.R
ts_w @_1_n r\
ZU.UN1.R
ts`_w @_1_n r\
ZHU.UN1.R
ts_h_w @_1_n r\
CU.UN1.R
ts`_h_w @_1_n r\
CHU.UN1.R
s_w @_1_n r\
SU.UN1.R
s`_w @_1_n r\
SHU.UN1.R
z`_w @_1_n r\
RU.UN1.R
p i_1 r\
BI.I1.R
p_h i_1 r\
PI.I1.R
t i_1 r\
DI.I1.R
t_h i_1 r\
TI.I1.R
l i_1 r\
LI.I1.R
m i_1 r\
MI.I1.R
n i_1 r\
NI.I1.R
ts\ i_1 r\
JI.I1.R
ts\_h i_1 r\
QI.I1.R
s\ i_1 r\
XI.I1.R
j_1 i_1 r\
Y.I1.R
@_2_n r\
EN2.R
1_2 r\
IH2.R
M_2 r\
eI_2 r\
EI2.R
y_2 r\
YU2.R
n y_2 r\
NYU.YU2.R
l y_2 r\
LYU.YU2.R
ts\ y_2 r\
JU.YU2.R
ts\_h y_2 r\
QU.YU2.R
s\ y_2 r\
XU.YU2.R
j_2 y_2 r\
YU.YU2.R
i_2_n r\
IN2.R
i_2 r\
I2.R
p i_2_n r\
BI.IN2.R
p_h i_2_n r\
PI.IN2.R
m i_2_n r\
MI.IN2.R
n i_2_n r\
NI.IN2.R
l i_2_n r\
LI.IN2.R
ts\ i_2_n r\
JI.IN2.R
ts\_h i_2_n r\
QI.IN2.R
s\ i_2_n r\
XI.IN2.R
j_2 i_2_n r\
Y.IN2.R
t_w @_2_n r\
DU.UN2.R
t_h_w @_2_n r\
TU.UN2.R
l_w @_2_n r\
LU.UN2.R
k_w @_2_n r\
GU.UN2.R
k_h_w @_2_n r\
KU.UN2.R
x_w @_2_n r\
HU.UN2.R
ts_w @_2_n r\
ZU.UN2.R
ts`_w @_2_n r\
ZHU.UN2.R
ts_h_w @_2_n r\
CU.UN2.R
ts`_h_w @_2_n r\
CHU.UN2.R
s_w @_2_n r\
SU.UN2.R
s`_w @_2_n r\
SHU.UN2.R
z`_w @_2_n r\
RU.UN2.R
p i_2 r\
BI.I2.R
p_h i_2 r\
PI.I2.R
t i_2 r\
DI.I2.R
t_h i_2 r\
TI.I2.R
l i_2 r\
LI.I2.R
m i_2 r\
MI.I2.R
n i_2 r\
NI.I2.R
ts\ i_2 r\
JI.I2.R
ts\_h i_2 r\
QI.I2.R
s\ i_2 r\
XI.I2.R
j_2 i_2 r\
Y.I2.R
@_3_n r\
EN3.R
1_3 r\
IH3.R
M_3 r\
eI_3 r\
EI3.R
y_3 r\
YU3.R
n y_3 r\
NYU.YU3.R
l y_3 r\
LYU.YU3.R
ts\ y_3 r\
JU.YU3.R
ts\_h y_3 r\
QU.YU3.R
s\ y_3 r\
XU.YU3.R
j_3 y_3 r\
YU.YU3.R
i_3_n r\
IN3.R
i_3 r\
I3.R
p i_3_n r\
BI.IN3.R
p_h i_3_n r\
PI.IN3.R
m i_3_n r\
MI.IN3.R
n i_3_n r\
NI.IN3.R
l i_3_n r\
LI.IN3.R
ts\ i_3_n r\
JI.IN3.R
ts\_h i_3_n r\
QI.IN3.R
s\ i_3_n r\
XI.IN3.R
j_3 i_3_n r\
Y.IN3.R
t_w @_3_n r\
DU.UN3.R
t_h_w @_3_n r\
TU.UN3.R
l_w @_3_n r\
LU.UN3.R
k_w @_3_n r\
GU.UN3.R
k_h_w @_3_n r\
KU.UN3.R
x_w @_3_n r\
HU.UN3.R
ts_w @_3_n r\
ZU.UN3.R
ts`_w @_3_n r\
ZHU.UN3.R
ts_h_w @_3_n r\
CU.UN3.R
ts`_h_w @_3_n r\
CHU.UN3.R
s_w @_3_n r\
SU.UN3.R
s`_w @_3_n r\
SHU.UN3.R
z`_w @_3_n r\
RU.UN3.R
p i_3 r\
BI.I3.R
p_h i_3 r\
PI.I3.R
t i_3 r\
DI.I3.R
t_h i_3 r\
TI.I3.R
l i_3 r\
LI.I3.R
m i_3 r\
MI.I3.R
n i_3 r\
NI.I3.R
ts\ i_3 r\
JI.I3.R
ts\_h i_3 r\
QI.I3.R
s\ i_3 r\
XI.I3.R
j_3 i_3 r\
Y.I3.R
@_4_n r\
EN4.R
1_4 r\
IH4.R
M_4 r\
eI_4 r\
EI4.R
y_4 r\
YU4.R
n y_4 r\
NYU.YU4.R
l y_4 r\
LYU.YU4.R
ts\ y_4 r\
JU.YU4.R
ts\_h y_4 r\
QU.YU4.R
s\ y_4 r\
XU.YU4.R
j_4 y_4 r\
YU.YU4.R
i_4_n r\
IN4.R
i_4 r\
I4.R
p i_4_n r\
BI.IN4.R
p_h i_4_n r\
PI.IN4.R
m i_4_n r\
MI.IN4.R
n i_4_n r\
NI.IN4.R
l i_4_n r\
LI.IN4.R
ts\ i_4_n r\
JI.IN4.R
ts\_h i_4_n r\
QI.IN4.R
s\ i_4_n r\
XI.IN4.R
j_4 i_4_n r\
Y.IN4.R
t_w @_4_n r\
DU.UN4.R
t_h_w @_4_n r\
TU.UN4.R
l_w @_4_n r\
LU.UN4.R
k_w @_4_n r\
GU.UN4.R
k_h_w @_4_n r\
KU.UN4.R
x_w @_4_n r\
HU.UN4.R
ts_w @_4_n r\
ZU.UN4.R
ts`_w @_4_n r\
ZHU.UN4.R
ts_h_w @_4_n r\
CU.UN4.R
ts`_h_w @_4_n r\
CHU.UN4.R
s_w @_4_n r\
SU.UN4.R
s`_w @_4_n r\
SHU.UN4.R
z`_w @_4_n r\
RU.UN4.R
p i_4 r\
BI.I4.R
p_h i_4 r\
PI.I4.R
t i_4 r\
DI.I4.R
t_h i_4 r\
TI.I4.R
l i_4 r\
LI.I4.R
m i_4 r\
MI.I4.R
n i_4 r\
NI.I4.R
ts\ i_4 r\
JI.I4.R
ts\_h i_4 r\
QI.I4.R
s\ i_4 r\
XI.I4.R
j_4 i_4 r\
Y.I4.R
@_5_n r\
EN5.R
1_5 r\
IH5.R
M_5 r\
eI_5 r\
EI5.R
y_5 r\
YU5.R
n y_5 r\
NYU.YU5.R
l y_5 r\
LYU.YU5.R
ts\ y_5 r\
JU.YU5.R
ts\_h y_5 r\
QU.YU5.R
s\ y_5 r\
XU.YU5.R
j_5 y_5 r\
YU.YU5.R
i_5_n r\
IN5.R
i_5 r\
I5.R
p i_5_n r\
BI.IN5.R
p_h i_5_n r\
PI.IN5.R
m i_5_n r\
MI.IN5.R
n i_5_n r\
NI.IN5.R
l i_5_n r\
LI.IN5.R
ts\ i_5_n r\
JI.IN5.R
ts\_h i_5_n r\
QI.IN5.R
s\ i_5_n r\
XI.IN5.R
j_5 i_5_n r\
Y.IN5.R
t_w @_5_n r\
DU.UN5.R
t_h_w @_5_n r\
TU.UN5.R
l_w @_5_n r\
LU.UN5.R
k_w @_5_n r\
GU.UN5.R
k_h_w @_5_n r\
KU.UN5.R
x_w @_5_n r\
HU.UN5.R
ts_w @_5_n r\
ZU.UN5.R
ts`_w @_5_n r\
ZHU.UN5.R
ts_h_w @_5_n r\
CU.UN5.R
ts`_h_w @_5_n r\
CHU.UN5.R
s_w @_5_n r\
SU.UN5.R
s`_w @_5_n r\
SHU.UN5.R
z`_w @_5_n r\
RU.UN5.R
p i_5 r\
BI.I5.R
p_h i_5 r\
PI.I5.R
t i_5 r\
DI.I5.R
t_h i_5 r\
TI.I5.R
l i_5 r\
LI.I5.R
m i_5 r\
MI.I5.R
n i_5 r\
NI.I5.R
ts\ i_5 r\
JI.I5.R
ts\_h i_5 r\
QI.I5.R
s\ i_5 r\
XI.I5.R
j_5 i_5 r\
Y.I5.R
@_6_n r\
1_6 r\
M_6 r\
eI_6 r\
y_6 r\
n y_6 r\
l y_6 r\
ts\ y_6 r\
ts\_h y_6 r\
s\ y_6 r\
j_6 y_6 r\
i_6_n r\
i_6 r\
p i_6_n r\
p_h i_6_n r\
m i_6_n r\
n i_6_n r\
l i_6_n r\
ts\ i_6_n r\
ts\_h i_6_n r\
s\ i_6_n r\
j_6 i_6_n r\
t_w @_6_n r\
t_h_w @_6_n r\
l_w @_6_n r\
k_w @_6_n r\
k_h_w @_6_n r\
x_w @_6_n r\
ts_w @_6_n r\
ts`_w @_6_n r\
ts_h_w @_6_n r\
ts`_h_w @_6_n r\
s_w @_6_n r\
s`_w @_6_n r\
z`_w @_6_n r\
p i_6 r\
p_h i_6 r\
t i_6 r\
t_h i_6 r\
l i_6 r\
m i_6 r\
n i_6 r\
ts\ i_6 r\
ts\_h i_6 r\
s\ i_6 r\
j_6 i_6 r\
O_1 r\
O1.R
O_2 r\
O2.R
O_3 r\
O3.R
O_4 r\
O4.R
O_5 r\
O5.R
O_6 r\
p O_1 r\
BU.O1.R
p O_2 r\
BU.O2.R
p O_3 r\
BU.O3.R
p O_4 r\
BU.O4.R
p O_5 r\
BU.O5.R
p O_6 r\
oU_1 r\
OU1.R
oU_2 r\
OU2.R
oU_3 r\
OU3.R
oU_4 r\
OU4.R
oU_5 r\
OU5.R
oU_6 r\
t_j_1 oU_1 r\
DI.OU1.R
t_j_2 oU_2 r\
DI.OU2.R
t_j_3 oU_3 r\
DI.OU3.R
t_j_4 oU_4 r\
DI.OU4.R
t_j_5 oU_5 r\
DI.OU5.R
t_j_6 oU_6 r\
l_j_1 oU_1 r\
LI.OU1.R
l_j_2 oU_2 r\
LI.OU2.R
l_j_3 oU_3 r\
LI.OU3.R
l_j_4 oU_4 r\
LI.OU4.R
l_j_5 oU_5 r\
LI.OU5.R
l_j_6 oU_6 r\
m_j_1 oU_1 r\
MI.OU1.R
m_j_2 oU_2 r\
MI.OU2.R
m_j_3 oU_3 r\
MI.OU3.R
m_j_4 oU_4 r\
MI.OU4.R
m_j_5 oU_5 r\
MI.OU5.R
m_j_6 oU_6 r\
n_j_1 oU_1 r\
NI.OU1.R
n_j_2 oU_2 r\
NI.OU2.R
n_j_3 oU_3 r\
NI.OU3.R
n_j_4 oU_4 r\
NI.OU4.R
n_j_5 oU_5 r\
NI.OU5.R
n_j_6 oU_6 r\
ts\_j_1 oU_1 r\
JI.OU1.R
ts\_j_2 oU_2 r\
JI.OU2.R
ts\_j_3 oU_3 r\
JI.OU3.R
ts\_j_4 oU_4 r\
JI.OU4.R
ts\_j_5 oU_5 r\
JI.OU5.R
ts\_j_6 oU_6 r\
ts\_h_j_1 oU_1 r\
QI.OU1.R
ts\_h_j_2 oU_2 r\
QI.OU2.R
ts\_h_j_3 oU_3 r\
QI.OU3.R
ts\_h_j_4 oU_4 r\
QI.OU4.R
ts\_h_j_5 oU_5 r\
QI.OU5.R
ts\_h_j_6 oU_6 r\
s\_j_1 oU_1 r\
XI.OU1.R
s\_j_2 oU_2 r\
XI.OU2.R
s\_j_3 oU_3 r\
XI.OU3.R
s\_j_4 oU_4 r\
XI.OU4.R
s\_j_5 oU_5 r\
XI.OU5.R
s\_j_6 oU_6 r\
j_1 oU_1 r\
Y.OU1.R
j_2 oU_2 r\
Y.OU2.R
j_3 oU_3 r\
Y.OU3.R
j_4 oU_4 r\
Y.OU4.R
j_5 oU_5 r\
Y.OU5.R
j_6 oU_6 r\
i_1_N r\
IG1.R
i_2_N r\
IG2.R
i_3_N r\
IG3.R
i_4_N r\
IG4.R
i_5_N r\
IG5.R
i_6_N r\
p i_1_N r\
BI.IG1.R
p i_2_N r\
BI.IG2.R
p i_3_N r\
BI.IG3.R
p i_4_N r\
BI.IG4.R
p i_5_N r\
BI.IG5.R
p i_6_N r\
p_h i_1_N r\
PI.IG1.R
p_h i_2_N r\
PI.IG2.R
p_h i_3_N r\
PI.IG3.R
p_h i_4_N r\
PI.IG4.R
p_h i_5_N r\
PI.IG5.R
p_h i_6_N r\
t i_1_N r\
DI.IG1.R
t i_2_N r\
DI.IG2.R
t i_3_N r\
DI.IG3.R
t i_4_N r\
DI.IG4.R
t i_5_N r\
DI.IG5.R
t i_6_N r\
t_h i_1_N r\
TI.IG1.R
t_h i_2_N r\
TI.IG2.R
t_h i_3_N r\
TI.IG3.R
t_h i_4_N r\
TI.IG4.R
t_h i_5_N r\
TI.IG5.R
t_h i_6_N r\
l i_1_N r\
LI.IG1.R
l i_2_N r\
LI.IG2.R
l i_3_N r\
LI.IG3.R
l i_4_N r\
LI.IG4.R
l i_5_N r\
LI.IG5.R
l i_6_N r\
m i_1_N r\
MI.IG1.R
m i_2_N r\
MI.IG2.R
m i_3_N r\
MI.IG3.R
m i_4_N r\
MI.IG4.R
m i_5_N r\
MI.IG5.R
m i_6_N r\
n i_1_N r\
NI.IG1.R
n i_2_N r\
NI.IG2.R
n i_3_N r\
NI.IG3.R
n i_4_N r\
NI.IG4.R
n i_5_N r\
NI.IG5.R
n i_6_N r\
ts\ i_1_N r\
JI.IG1.R
ts\ i_2_N r\
JI.IG2.R
ts\ i_3_N r\
JI.IG3.R
ts\ i_4_N r\
JI.IG4.R
ts\ i_5_N r\
JI.IG5.R
ts\ i_6_N r\
ts\_h i_1_N r\
QI.IG1.R
ts\_h i_2_N r\
QI.IG2.R
ts\_h i_3_N r\
QI.IG3.R
ts\_h i_4_N r\
QI.IG4.R
ts\_h i_5_N r\
QI.IG5.R
ts\_h i_6_N r\
s\ i_1_N r\
XI.IG1.R
s\ i_2_N r\
XI.IG2.R
s\ i_3_N r\
XI.IG3.R
s\ i_4_N r\
XI.IG4.R
s\ i_5_N r\
XI.IG5.R
s\ i_6_N r\
j_1 i_1_N r\
Y.IG1.R
j_2 i_2_N r\
Y.IG2.R
j_3 i_3_N r\
Y.IG3.R
j_4 i_4_N r\
Y.IG4.R
j_5 i_5_N r\
Y.IG5.R
j_6 i_6_N r\
@_1_N r\
EG1.R
@_2_N r\
EG2.R
@_3_N r\
EG3.R
@_4_N r\
EG4.R
@_5_N r\
EG5.R
@_6_N r\
u_1 r\
U1.R
u_2 r\
U2.R
u_3 r\
U3.R
u_4 r\
U4.R
u_5 r\
U5.R
u_6 r\
p u_1 r\
BU.U1.R
p u_2 r\
BU.U2.R
p u_3 r\
BU.U3.R
p u_4 r\
BU.U4.R
p u_5 r\
BU.U5.R
p u_6 r\
t u_1 r\
DU.U1.R
t u_2 r\
DU.U2.R
t u_3 r\
DU.U3.R
t u_4 r\
DU.U4.R
t u_5 r\
DU.U5.R
t u_6 r\
t_h u_1 r\
TU.U1.R
t_h u_2 r\
TU.U2.R
t_h u_3 r\
TU.U3.R
t_h u_4 r\
TU.U4.R
t_h u_5 r\
TU.U5.R
t_h u_6 r\
l u_1 r\
LU.U1.R
l u_2 r\
LU.U2.R
l u_3 r\
LU.U3.R
l u_4 r\
LU.U4.R
l u_5 r\
LU.U5.R
l u_6 r\
m u_1 r\
MU.U1.R
m u_2 r\
MU.U2.R
m u_3 r\
MU.U3.R
m u_4 r\
MU.U4.R
m u_5 r\
MU.U5.R
m u_6 r\
n u_1 r\
NU.U1.R
n u_2 r\
NU.U2.R
n u_3 r\
NU.U3.R
n u_4 r\
NU.U4.R
n u_5 r\
NU.U5.R
n u_6 r\
k u_1 r\
GU.U1.R
k u_2 r\
GU.U2.R
k u_3 r\
GU.U3.R
k u_4 r\
GU.U4.R
k u_5 r\
GU.U5.R
k u_6 r\
k_h u_1 r\
KU.U1.R
k_h u_2 r\
KU.U2.R
k_h u_3 r\
KU.U3.R
k_h u_4 r\
KU.U4.R
k_h u_5 r\
KU.U5.R
k_h u_6 r\
x u_1 r\
HU.U1.R
x u_2 r\
HU.U2.R
x u_3 r\
HU.U3.R
x u_4 r\
HU.U4.R
x u_5 r\
HU.U5.R
x u_6 r\
ts u_1 r\
ZU.U1.R
ts u_2 r\
ZU.U2.R
ts u_3 r\
ZU.U3.R
ts u_4 r\
ZU.U4.R
ts u_5 r\
ZU.U5.R
ts u_6 r\
ts_h u_1 r\
CU.U1.R
ts_h u_2 r\
CU.U2.R
ts_h u_3 r\
CU.U3.R
ts_h u_4 r\
CU.U4.R
ts_h u_5 r\
CU.U5.R
ts_h u_6 r\
s u_1 r\
SU.U1.R
s u_2 r\
SU.U2.R
s u_3 r\
SU.U3.R
s u_4 r\
SU.U4.R
s u_5 r\
SU.U5.R
s u_6 r\
ts` u_1 r\
ZHU.U1.R
ts` u_2 r\
ZHU.U2.R
ts` u_3 r\
ZHU.U3.R
ts` u_4 r\
ZHU.U4.R
ts` u_5 r\
ZHU.U5.R
ts` u_6 r\
ts`_h u_1 r\
CHU.U1.R
ts`_h u_2 r\
CHU.U2.R
ts`_h u_3 r\
CHU.U3.R
ts`_h u_4 r\
CHU.U4.R
ts`_h u_5 r\
CHU.U5.R
ts`_h u_6 r\
s` u_1 r\
SHU.U1.R
s` u_2 r\
SHU.U2.R
s` u_3 r\
SHU.U3.R
s` u_4 r\
SHU.U4.R
s` u_5 r\
SHU.U5.R
s` u_6 r\
z` u_1 r\
RU.U1.R
z` u_2 r\
RU.U2.R
z` u_3 r\
RU.U3.R
z` u_4 r\
RU.U4.R
z` u_5 r\
RU.U5.R
z` u_6 r\
7_1 r\
E1.R
7_2 r\
E2.R
7_3 r\
E3.R
7_4 r\
E4.R
7_5 r\
E5.R
7_6 r\
A_1_N r\
AG1.R
A_2_N r\
AG2.R
A_3_N r\
AG3.R
A_4_N r\
AG4.R
A_5_N r\
AG5.R
A_6_N r\
ts\_j_1 A_1_N r\
JI.AG1.R
ts\_j_2 A_2_N r\
JI.AG2.R
ts\_j_3 A_3_N r\
JI.AG3.R
ts\_j_4 A_4_N r\
JI.AG4.R
ts\_j_5 A_5_N r\
JI.AG5.R
ts\_j_6 A_6_N r\
l_j_1 A_1_N r\
LI.AG1.R
l_j_2 A_2_N r\
LI.AG2.R
l_j_3 A_3_N r\
LI.AG3.R
l_j_4 A_4_N r\
LI.AG4.R
l_j_5 A_5_N r\
LI.AG5.R
l_j_6 A_6_N r\
n_j_1 A_1_N r\
NI.AG1.R
n_j_2 A_2_N r\
NI.AG2.R
n_j_3 A_3_N r\
NI.AG3.R
n_j_4 A_4_N r\
NI.AG4.R
n_j_5 A_5_N r\
NI.AG5.R
n_j_6 A_6_N r\
ts\_h_j_1 A_1_N r\
QI.AG1.R
ts\_h_j_2 A_2_N r\
QI.AG2.R
ts\_h_j_3 A_3_N r\
QI.AG3.R
ts\_h_j_4 A_4_N r\
QI.AG4.R
ts\_h_j_5 A_5_N r\
QI.AG5.R
ts\_h_j_6 A_6_N r\
s\_j_1 A_1_N r\
XI.AG1.R
s\_j_2 A_2_N r\
XI.AG2.R
s\_j_3 A_3_N r\
XI.AG3.R
s\_j_4 A_4_N r\
XI.AG4.R
s\_j_5 A_5_N r\
XI.AG5.R
s\_j_6 A_6_N r\
j_1 A_1_N r\
Y.AG1.R
j_2 A_2_N r\
Y.AG2.R
j_3 A_3_N r\
Y.AG3.R
j_4 A_4_N r\
Y.AG4.R
j_5 A_5_N r\
Y.AG5.R
j_6 A_6_N r\
o_1_N r\
OG1.R
o_2_N r\
OG2.R
o_3_N r\
OG3.R
o_4_N r\
OG4.R
o_5_N r\
OG5.R
o_6_N r\
ts`_h o_1_N r\
CHU.OG1.R
ts`_h o_2_N r\
CHU.OG2.R
ts`_h o_3_N r\
CHU.OG3.R
ts`_h o_4_N r\
CHU.OG4.R
ts`_h o_5_N r\
CHU.OG5.R
ts`_h o_6_N r\
ts_h o_1_N r\
CU.OG1.R
ts_h o_2_N r\
CU.OG2.R
ts_h o_3_N r\
CU.OG3.R
ts_h o_4_N r\
CU.OG4.R
ts_h o_5_N r\
CU.OG5.R
ts_h o_6_N r\
t o_1_N r\
DU.OG1.R
t o_2_N r\
DU.OG2.R
t o_3_N r\
DU.OG3.R
t o_4_N r\
DU.OG4.R
t o_5_N r\
DU.OG5.R
t o_6_N r\
k o_1_N r\
GU.OG1.R
k o_2_N r\
GU.OG2.R
k o_3_N r\
GU.OG3.R
k o_4_N r\
GU.OG4.R
k o_5_N r\
GU.OG5.R
k o_6_N r\
x o_1_N r\
HU.OG1.R
x o_2_N r\
HU.OG2.R
x o_3_N r\
HU.OG3.R
x o_4_N r\
HU.OG4.R
x o_5_N r\
HU.OG5.R
x o_6_N r\
ts\_j_1 o_1_N r\
JI.OG1.R
ts\_j_2 o_2_N r\
JI.OG2.R
ts\_j_3 o_3_N r\
JI.OG3.R
ts\_j_4 o_4_N r\
JI.OG4.R
ts\_j_5 o_5_N r\
JI.OG5.R
ts\_j_6 o_6_N r\
k_h o_1_N r\
KU.OG1.R
k_h o_2_N r\
KU.OG2.R
k_h o_3_N r\
KU.OG3.R
k_h o_4_N r\
KU.OG4.R
k_h o_5_N r\
KU.OG5.R
k_h o_6_N r\
l o_1_N r\
LU.OG1.R
l o_2_N r\
LU.OG2.R
l o_3_N r\
LU.OG3.R
l o_4_N r\
LU.OG4.R
l o_5_N r\
LU.OG5.R
l o_6_N r\
n o_1_N r\
NU.OG1.R
n o_2_N r\
NU.OG2.R
n o_3_N r\
NU.OG3.R
n o_4_N r\
NU.OG4.R
n o_5_N r\
NU.OG5.R
n o_6_N r\
ts\_h_j_1 o_1_N r\
QI.OG1.R
ts\_h_j_2 o_2_N r\
QI.OG2.R
ts\_h_j_3 o_3_N r\
QI.OG3.R
ts\_h_j_4 o_4_N r\
QI.OG4.R
ts\_h_j_5 o_5_N r\
QI.OG5.R
ts\_h_j_6 o_6_N r\
s o_1_N r\
SU.OG1.R
s o_2_N r\
SU.OG2.R
s o_3_N r\
SU.OG3.R
s o_4_N r\
SU.OG4.R
s o_5_N r\
SU.OG5.R
s o_6_N r\
t_h o_1_N r\
TU.OG1.R
t_h o_2_N r\
TU.OG2.R
t_h o_3_N r\
TU.OG3.R
t_h o_4_N r\
TU.OG4.R
t_h o_5_N r\
TU.OG5.R
t_h o_6_N r\
s\_j_1 o_1_N r\
XI.OG1.R
s\_j_2 o_2_N r\
XI.OG2.R
s\_j_3 o_3_N r\
XI.OG3.R
s\_j_4 o_4_N r\
XI.OG4.R
s\_j_5 o_5_N r\
XI.OG5.R
s\_j_6 o_6_N r\
j_1 o_1_N r\
Y.OG1.R
j_2 o_2_N r\
Y.OG2.R
j_3 o_3_N r\
Y.OG3.R
j_4 o_4_N r\
Y.OG4.R
j_5 o_5_N r\
Y.OG5.R
j_6 o_6_N r\
ts` o_1_N r\
ZHU.OG1.R
ts` o_2_N r\
ZHU.OG2.R
ts` o_3_N r\
ZHU.OG3.R
ts` o_4_N r\
ZHU.OG4.R
ts` o_5_N r\
ZHU.OG5.R
ts` o_6_N r\
ts o_1_N r\
ZU.OG1.R
ts o_2_N r\
ZU.OG2.R
ts o_3_N r\
ZU.OG3.R
ts o_4_N r\
ZU.OG4.R
ts o_5_N r\
ZU.OG5.R
ts o_6_N r\
E_1 r\
IE1.R
E_2 r\
IE2.R
E_3 r\
IE3.R
E_4 r\
IE4.R
E_5 r\
IE5.R
E_6 r\
p_j_1 E_1 r\
BI.IE1.R
p_j_2 E_2 r\
BI.IE2.R
p_j_3 E_3 r\
BI.IE3.R
p_j_4 E_4 r\
BI.IE4.R
p_j_5 E_5 r\
BI.IE5.R
p_j_6 E_6 r\
t_j_1 E_1 r\
DI.IE1.R
t_j_2 E_2 r\
DI.IE2.R
t_j_3 E_3 r\
DI.IE3.R
t_j_4 E_4 r\
DI.IE4.R
t_j_5 E_5 r\
DI.IE5.R
t_j_6 E_6 r\
ts\_j_1 E_1 r\
JI.IE1.R
ts\_j_2 E_2 r\
JI.IE2.R
ts\_j_3 E_3 r\
JI.IE3.R
ts\_j_4 E_4 r\
JI.IE4.R
ts\_j_5 E_5 r\
JI.IE5.R
ts\_j_6 E_6 r\
ts\_H_1 E_1 r\
JU.IE1.R
ts\_H_2 E_2 r\
JU.IE2.R
ts\_H_3 E_3 r\
JU.IE3.R
ts\_H_4 E_4 r\
JU.IE4.R
ts\_H_5 E_5 r\
JU.IE5.R
ts\_H_6 E_6 r\
l_j_1 E_1 r\
LI.IE1.R
l_j_2 E_2 r\
LI.IE2.R
l_j_3 E_3 r\
LI.IE3.R
l_j_4 E_4 r\
LI.IE4.R
l_j_5 E_5 r\
LI.IE5.R
l_j_6 E_6 r\
l_H_1 E_1 r\
LYU.IE1.R
l_H_2 E_2 r\
LYU.IE2.R
l_H_3 E_3 r\
LYU.IE3.R
l_H_4 E_4 r\
LYU.IE4.R
l_H_5 E_5 r\
LYU.IE5.R
l_H_6 E_6 r\
m_j_1 E_1 r\
MI.IE1.R
m_j_2 E_2 r\
MI.IE2.R
m_j_3 E_3 r\
MI.IE3.R
m_j_4 E_4 r\
MI.IE4.R
m_j_5 E_5 r\
MI.IE5.R
m_j_6 E_6 r\
n_j_1 E_1 r\
NI.IE1.R
n_j_2 E_2 r\
NI.IE2.R
n_j_3 E_3 r\
NI.IE3.R
n_j_4 E_4 r\
NI.IE4.R
n_j_5 E_5 r\
NI.IE5.R
n_j_6 E_6 r\
n_H_1 E_1 r\
NYU.IE1.R
n_H_2 E_2 r\
NYU.IE2.R
n_H_3 E_3 r\
NYU.IE3.R
n_H_4 E_4 r\
NYU.IE4.R
n_H_5 E_5 r\
NYU.IE5.R
n_H_6 E_6 r\
p_h_j_1 E_1 r\
PI.IE1.R
p_h_j_2 E_2 r\
PI.IE2.R
p_h_j_3 E_3 r\
PI.IE3.R
p_h_j_4 E_4 r\
PI.IE4.R
p_h_j_5 E_5 r\
PI.IE5.R
p_h_j_6 E_6 r\
ts\_h_j_1 E_1 r\
QI.IE1.R
ts\_h_j_2 E_2 r\
QI.IE2.R
ts\_h_j_3 E_3 r\
QI.IE3.R
ts\_h_j_4 E_4 r\
QI.IE4.R
ts\_h_j_5 E_5 r\
QI.IE5.R
ts\_h_j_6 E_6 r\
ts\_h_H_1 E_1 r\
QU.IE1.R
ts\_h_H_2 E_2 r\
QU.IE2.R
ts\_h_H_3 E_3 r\
QU.IE3.R
ts\_h_H_4 E_4 r\
QU.IE4.R
ts\_h_H_5 E_5 r\
QU.IE5.R
ts\_h_H_6 E_6 r\
t_h_j_1 E_1 r\
TI.IE1.R
t_h_j_2 E_2 r\
TI.IE2.R
t_h_j_3 E_3 r\
TI.IE3.R
t_h_j_4 E_4 r\
TI.IE4.R
t_h_j_5 E_5 r\
TI.IE5.R
t_h_j_6 E_6 r\
s\_j_1 E_1 r\
XI.IE1.R
s\_j_2 E_2 r\
XI.IE2.R
s\_j_3 E_3 r\
XI.IE3.R
s\_j_4 E_4 r\
XI.IE4.R
s\_j_5 E_5 r\
XI.IE5.R
s\_j_6 E_6 r\
s\_H_1 E_1 r\
XU.IE1.R
s\_H_2 E_2 r\
XU.IE2.R
s\_H_3 E_3 r\
XU.IE3.R
s\_H_4 E_4 r\
XU.IE4.R
s\_H_5 E_5 r\
XU.IE5.R
s\_H_6 E_6 r\
j_1 E_1 r\
Y.IE1.R
j_2 E_2 r\
Y.IE2.R
j_3 E_3 r\
Y.IE3.R
j_4 E_4 r\
Y.IE4.R
j_5 E_5 r\
Y.IE5.R
j_6 E_6 r\
j_H_1 E_1 r\
YU.IE1.R
j_H_2 E_2 r\
YU.IE2.R
j_H_3 E_3 r\
YU.IE3.R
j_H_4 E_4 r\
YU.IE4.R
j_H_5 E_5 r\
YU.IE5.R
j_H_6 E_6 r\
n a_1
N.A1
n a_2
N.A2
n a_3
N.A3
n a_4
N.A4
n a_5
N.A5
n a_6
n 7_1
N.E1
n 7_2
N.E2
n 7_3
N.E3
n 7_4
N.E4
n 7_5
N.E5
n 7_6
n aI_1
N.AI1
n aI_2
N.AI2
n aI_3
N.AI3
n aI_4
N.AI4
n aI_5
N.AI5
n aI_6
n eI_1
N.EI1
n eI_2
N.EI2
n eI_3
N.EI3
n eI_4
N.EI4
n eI_5
N.EI5
n eI_6
n aU_1
N.AO1
n aU_2
N.AO2
n aU_3
N.AO3
n aU_4
N.AO4
n aU_5
N.AO5
n aU_6
n oU_1
N.OU1
n oU_2
N.OU2
n oU_3
N.OU3
n oU_4
N.OU4
n oU_5
N.OU5
n oU_6
n a_1_n
N.AN1
n a_2_n
N.AN2
n a_3_n
N.AN3
n a_4_n
N.AN4
n a_5_n
N.AN5
n a_6_n
n @_1_n
N.EN1
n @_2_n
N.EN2
n @_3_n
N.EN3
n @_4_n
N.EN4
n @_5_n
N.EN5
n @_6_n
n A_1_N
N.AG1
n A_2_N
N.AG2
n A_3_N
N.AG3
n A_4_N
N.AG4
n A_5_N
N.AG5
n A_6_N
n @_1_N
N.EG1
n @_2_N
N.EG2
n @_3_N
N.EG3
n @_4_N
N.EG4
n @_5_N
N.EG5
n @_6_N
n_w O_1
NU.O1
n_w O_2
NU.O2
n_w O_3
NU.O3
n_w O_4
NU.O4
n_w O_5
NU.O5
n_w O_6
n_w a_1_n
NU.AN1
n_w a_2_n
NU.AN2
n_w a_3_n
NU.AN3
n_w a_4_n
NU.AN4
n_w a_5_n
NU.AN5
n_w a_6_n
n a_1 r\
N.A1.R
n a_2 r\
N.A2.R
n a_3 r\
N.A3.R
n a_4 r\
N.A4.R
n a_5 r\
N.A5.R
n a_6 r\
n 7_1 r\
N.E1.R
n 7_2 r\
N.E2.R
n 7_3 r\
N.E3.R
n 7_4 r\
N.E4.R
n 7_5 r\
N.E5.R
n 7_6 r\
n aI_1 r\
N.AI1.R
n aI_2 r\
N.AI2.R
n aI_3 r\
N.AI3.R
n aI_4 r\
N.AI4.R
n aI_5 r\
N.AI5.R
n aI_6 r\
n eI_1 r\
N.EI1.R
n eI_2 r\
N.EI2.R
n eI_3 r\
N.EI3.R
n eI_4 r\
N.EI4.R
n eI_5 r\
N.EI5.R
n eI_6 r\
n aU_1 r\
N.AO1.R
n aU_2 r\
N.AO2.R
n aU_3 r\
N.AO3.R
n aU_4 r\
N.AO4.R
n aU_5 r\
N.AO5.R
n aU_6 r\
n oU_1 r\
N.OU1.R
n oU_2 r\
N.OU2.R
n oU_3 r\
N.OU3.R
n oU_4 r\
N.OU4.R
n oU_5 r\
N.OU5.R
n oU_6 r\
n a_1_n r\
N.AN1.R
n a_2_n r\
N.AN2.R
n a_3_n r\
N.AN3.R
n a_4_n r\
N.AN4.R
n a_5_n r\
N.AN5.R
n a_6_n r\
n @_1_n r\
N.EN1.R
n @_2_n r\
N.EN2.R
n @_3_n r\
N.EN3.R
n @_4_n r\
N.EN4.R
n @_5_n r\
N.EN5.R
n @_6_n r\
n A_1_N r\
N.AG1.R
n A_2_N r\
N.AG2.R
n A_3_N r\
N.AG3.R
n A_4_N r\
N.AG4.R
n A_5_N r\
N.AG5.R
n A_6_N r\
n @_1_N r\
N.EG1.R
n @_2_N r\
N.EG2.R
n @_3_N r\
N.EG3.R
n @_4_N r\
N.EG4.R
n @_5_N r\
N.EG5.R
n @_6_N r\
n_w O_1 r\
NU.O1.R
n_w O_2 r\
NU.O2.R
n_w O_3 r\
NU.O3.R
n_w O_4 r\
NU.O4.R
n_w O_5 r\
NU.O5.R
n_w O_6 r\
n_w a_1_n r\
NU.AN1.R
n_w a_2_n r\
NU.AN2.R
n_w a_3_n r\
NU.AN3.R
n_w a_4_n r\
NU.AN4.R
n_w a_5_n r\
NU.AN5.R
n_w a_6_n r\
ProcessingGraph: Unknown blocktype '
', did you forget to call 'registerBlockType'?
graph-output
graph-input
Block ID allready exist: 
Missing (or empty) block-type for block ID: 
Creating graph connection: 
Unknown block identifier in 'receives-from': 
No config block allowed for '
updateConfiguration called for nonexisting block id: 
receive-from
Invalid connection syntax in: 
Block has no outgoing connections: 
' can have no outgoing connections
Block has no incomming connections: 
' can have no incomming connections
 graph connectivity error(s)
Block name lookup not supported for this graph type!
Multiple inputs not supported for (legacy) block config format
Invalid block index: 
merge-style
type of merge performed
PDecTranslatorBlock
mt model file name
maximum number of active beams in pruning
as-beam
as_beam pruning value
rs-beam
rs_beam pruning value
confidence-threshold
confidence threshold
lm-model-file
path to language model file
lm-weight
language model weight
veto-factor
MT defcoding veto factor
veto-factor-exclude-input-tags
MT decoding, exclude input tags in  veto factor computation
veto-factor-num-external-input-tags
MT decoding, num externally provided tags to exclude for veto factor
norm-costs
normalize costs in mt decoding? (backward compatible version)
norm-mode
normalize costs in mt decoding? (off|length|gnmt)
norm-alpha
normalization alpha parameter
norm-sigma
normalization sigma parameter
unk-replace
max-seq-length
maximum decoding sequence length
max-seq-length-relative
maximum decoding sequence length as factor of input length
max-seq-length-floor
maximum decoding sequence length floor (used with input length factor)
lm-mode
lm mode
confidence model file
stop-mode
stop mode in mt decoding (nbeam|best|finished_score)
block-control
flow control for block sequence (<empty>|optional|optional_stop_on_success)
shortlist-lang-pair
language pair used for shortlist
shortlist-cond-n
top n in condition table used for shortlist
shortlist-freq-n
top n in freq words used for shortlist
nbest
maximum entries in nbest list to produce (default to same as 'beam'}
stop-mode-finished-score-beam
number of finished hypotheses considered for finished score stop mode (default: 1)
stream-buffer-n
stream decoding initial read length (effective read buffer)
stream-block-m
stream decoding read/write length (block size for looped read/write calls)
stream-stabilize
stabilize partial stream decoding results after each read/write block
partial-input-override
optional override parameter block to change parameter settings for partial-input processing
timing-meta-info
include decoder timing information in meta info json
model-type
kaldi
translation model type (kaldi/espresso)
use memory map
phrase-book-mode
phrase book mode
pron-guide-model-file
pron guide model file
pron-guide-preprocessing
pron guide preprocessing (splitting into characters and <space> insertion)
romanizer
phrasebook-case-sensitve
case sensitive phrase book?
filter-list-file
filter list file
pb-file-list
phrase book file list
maximum entries in nbest list to produce
reset-meta-info
reset metaInfo json
source-locale
source locale
target-locale
target locale
source-token
source tag for multilingual model
target-token
target tag for multilingual model
share-translation-model
share translation model
use-sentencepiece-ids
use sentencepiece ids directly, drop dictionaries
PDecPhraseBookBlock
filter-redundant-tags
flag on whether to filter out or keep hypotheses with redundant tags
tag-to-meta-json-file
a json file that contains a mapping between tags and their corresponding string in the meta info 
AlignmentProcessorBlock
source
segmentor-encode
pdec-decode
segmentor-decode
tokenized
word-level-alignments
If set to true, then the BPE level alignments are merged into word level alignments
avoid-crossing-words
If set to True, then the Alignment Processor Block expects the tokenized translations and the alignment ranges do not cross the tokenized words
use-stripped-token-text
If set to true, the whitespace stripped surface token representation is used instead of the internal representation.
DoNotTranslateBlock
target
AmbiguityAnnotatorBlock
disambiguation-dictionary-file
disambiguation dictionary file
max-match-length
maximum token sequence length in matching
prefer-position
prefer early match position over multiword matches
prefer-multiword
prefer longer multiword matches to shorter ones
multisense-keep
number of senses to keep when several senses match a word in a hypotheses
strip-gender
keep 'gender' in the metainfo (false), or remove it (true)
case-sensitive
used to disable phrase book block
filter-entries
filter to make translations unique
normalization-pattern-file
apply regular expressions from file for normalized lookup
normalize-on-load
apply normalization (lowercaseing/regex) to phrasebook keys on load
SimpleTokenizerBlock
tokenizer-file
tokenizer regular expression replacement (sed / perl -p style)
PhraseBookBlock
InputHammerBlock
strip-token
strip tokenizer artefacts on romanizer input
memory map pronounciator model
share-pron-guide-model
share model instance with other identical blocks
SentencePieceBlock
sentence-piece-file
sentence piece model file
action
encode
action to perform (encode/decode/decode-api)
src-locale
the source locale
tgt-locale
the target locale
features
list of features
src-ovs-file
the source OVS file
tgt-ovs-file
the target OVS file
fertility-file
the fertility file
min-trans-len-percent
the minimum translation length (in percent of expected length)
max-trans-len-percent
the maximum translation length (in percent of expected length)
regex-file
the regular expression file
PDecForceAlignBlock
maximum entries in target nbest list to process
include-eos
include the score for the EOS symbol
score-only
force decode only, without alignment
FilterBlock
locale-validation
check source locale is compatible with metainfo locale
maximum nbest list size (default: don't limit nbest size)
annotation-based-filtering
filter based on annotation in the metainfo
SelectBlock
control
value
match-key
metadata key to match on
match-pattern
metadata value match pattern
match-wildcard
wildcard string for match-pattern, that can match any subtree
locale
locale for case mapping (if not set use locale independent mapping)
capitalize-camel-case
Capitalize camel-case first tokens
exception-file
Path to file with additional exceptions that should not be capitalized
GenderVerifierBlock
inflections-file
inflection list for gendered words.
locale to use for tokenization.
PlaceholderBlock
enable
output placeholders in the target
placeholder-tag
<-->
placeholder tag
placeholder-size
placeholder size in the UI
max-placeholders
limit on the number of placeholders
separator
string for separating nbest entries
use-meta-info
should meta info be dumped
meta-separator
string for separating output string from meta data
limit dumping to this many entries from nbest list (0 = do not limit)
TokenizerBlock
output-tokens
control if tokenization affects the translation tokens or just meta info.
locale for tokenization (if not set use locale independent mapping)
.dict
Phrasebook file type unknown
DatabasePhraseBook
disable
cost
norm_cost
status
phrasebook_exact
1000
 1000
word confidences
sentence confidence
low confidence
deep copy constructor not implemented in the case of vectorized_weights.
<ParamStddev>
<LearnRateCoef>
<RandomSeed>
<InitTransformType>
<GradientNormType>
<MaxGrad>
 (ParamStddev|LearnRateCoef|InitTransformType|RandomSeed|GradientNormType|MaxGrad)
Linearity().NumRows() == mat.NumRows() && Linearity().NumCols() == mat.NumCols()
unrecognized config token 
 linearity
  linearity_grad
, lr-coef 
Unexpected mismatch in indexes: 
Unimplemented except for BaseFloat weights
Weights are already vectorized
Performing  vectorization of linear component
veccorrs->size() == linearity_corr_.size()
LinearityCorr(ic).NumRows() * LinearityCorr(ic).NumCols() == NumParams()
Done  vectorization of linear component
the multi batch gradient quantization does not work yet
Wrong quantizer type (neither 
 ): 
Insufficient storage area: 
 needed: 
(end) <= (Bits())
/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/libquasar/libkaldi/tools/openfst/src/extensions/ngram/bitmap-index.cc
You cannot call FinalizeDecoding() and then call 
GetRawLattice() with use_final_probs == false
GetRawLattice: no tokens active on frame 
: not producing lattice.
init:
 buckets:
 load:
 max:
No tokens alive [doing pruning].. warning first time only for each utterance
Negative extra_cost: 
No tokens alive at end of file
No tokens alive [doing pruning]
PruneActiveTokens: pruned tokens from 
pruned tokens from 
Error, no surviving tokens: frame is 
using RNN style LM in the decoder
v != nullptr
capacity_ > 0
am-scale
Scaling factor for acoustic likelihoods
nbest-size
number of NBest from 1st pass used for interpolation weight estimation
nnlm-nce-norm-factor-list
the normalization factor for NCE trained NNLMs, use comma to separate multiple ones
rnnlm-max-context-size
maximal context for RNN style LM, no-op for other style of LMs
big-g-fst-file-list
list of BigGrammar FST filename, use comma to separate multiple ones
big-g-nnet-file-list
list of BigGrammar NNLM filename, use comma to separate multiple ones
nnet-map-file-ext
the file extension name of the corresponding NNLM word map file
Map FST/NNLM models into memory (requires aligned models)
lattice-beam
the lattice beam for the rescored lattice
wordmap
Could not read the NNLM normalization factor info
the number of NNLM files and the number of NNLM norm factors do not match
rescoreScaled
Skip rescoring: inputArcs=
Rescoring ok=
 outputArcs=
The rescoring LM interpolation weights:
rescored
Rescoring with 
 symbol(s) for left context from 
 word(s)
Total LM cost after rescoring = 
Placeholder 
 not in geo-config 
region-dependent-variable-list
 for template 
'%c'
[character %d]
dynamic_cast<CEInferenceNet* const>(extra_nnet_) != nullptr
Backed by either TensorFlow or Espresso.
the NCE normalization factor is 
HIT vs MISS: 
lm-score 
, penultimate cache 
Compile with USE_TENSORFLOW=ON to use TensorFlow models
Compile with USE_TORCH=ON to use Torch models
No ComputeEngineConfigItf for model file: 
.espresso/code.nitroir
.pt|.zip
recognizers
Found missing recognizer request handlers.
Initialized SyncSpeechRecognizer with config 
decodables.
frontends.
SyncSpeechRecognizer not initialized
opts_.max_steps > 0
bos_index_ >= 0 && eos_index_ >= 0
Decoding output contains BOS label (
). Mapping it to label 0.
Decoding output contains label 0. Mapping it to BOS label (
fst-phonomap-file
Phonomap file as an fst. This must be input-arc sorted
phonetic-syms-file
Symbol table file representing the phone set.
corrections.
Invalid format for boolean argument [expected true or false]: 
Use add() to append array elements
Leaves can't have children
Can't add a value dictionary-like to a tree that is already array-like
Can't add a value array-like to a tree that is already dictionary-like
nested erase() not implemented
strtoul: out of range
expected value
expected key string
expected ':'
expected '}' or ','
void boost::property_tree::json_parser::detail::source<boost::property_tree::json_parser::detail::encoding<char>, std::istreambuf_iterator<char>, std::istreambuf_iterator<char>>::parse_error(const char *) [Encoding = boost::property_tree::json_parser::detail::encoding<char>, Iterator = std::istreambuf_iterator<char>, Sentinel = std::istreambuf_iterator<char>]
/AppleInternal/Library/BuildRoots/b958ad6d-2c13-11ed-a8d5-b25c5e9b9057/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator16.1.Internal.sdk/usr/local/include/boost/property_tree/json_parser/detail/parser.hpp
expected ']' or ','
unterminated string
invalid code sequence
invalid escape sequence
invalid codepoint, stray low surrogate
invalid codepoint, stray high surrogate
expected codepoint reference after high surrogate
expected low surrogate after high surrogate
expected 'true'
expected 'false'
expected 'null'
expected digits after -
need at least one digit after '.'
need at least one digit in exponent
garbage after data
cannot open file
void boost::property_tree::json_parser::read_json(const std::string &, Ptree &, const std::locale &) [Ptree = boost::property_tree::basic_ptree<std::string, std::string>]
/AppleInternal/Library/BuildRoots/b958ad6d-2c13-11ed-a8d5-b25c5e9b9057/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator16.1.Internal.sdk/usr/local/include/boost/property_tree/json_parser.hpp
void boost::property_tree::json_parser::write_json(const std::string &, const Ptree &, const std::locale &, bool) [Ptree = boost::property_tree::basic_ptree<std::string, std::string>]
hanning
hamming
rectangular
Invalid window type 
Inconsistent setting: center=true but lookahead is set to 
Flooring variance When normalizing variance, floored 
 elements; num-frames was 
total rollbacked steps are 
On beam 
 peak attention at 
 which is too close to 
Not enough steps to rollback, need wait for more audio and reinitialization
bluetoothDeviceId
utteranceDetection
EagerUsed
Detected latency overflow, change to int_max.
dup stat: token=
, source=
Empty tokenStrings received
Empty tokenStrings[0] received
Token=
 found in Lexicon, prons=
Skipping invalid token=
 found in PronCache
Failed to generated pronunciations for word=
in backoff window, skip updating pron cache for token 
Byte-range queried for number of codepoints seems to intersect a codepoint
Config:
Token: 
 not found in raw string input: 
Char ranges in the word char map exceeds total number of characters
Mismatch in sizes of alignment queries and projections from the first leg don't match.
Json corresponding to alignment-queries cannot be parsed.
AlignmentProcessorBlock::handleSourceInput() called called with empty input
AlignmentProcessorBlock::handleSourceInput() called called with multiple inputs
alignment-span-info
For alignment mapping to work properly, ensure whole string provided as first token.
Query range [
] is out of bounds.
] is illegal.
AlignmentProcessorBlock::handleSegmentEncInput() called called with empty input
AlignmentProcessorBlock::handleSegmentEncInput() called called with multiple inputs
AlignmentProcessorBlock::handlePDecInput() called with empty input
AlignmentProcessorBlock::handleSegmentDecInput() called with empty input
AlignmentProcessorBlock::handleTokenizedInput() called with empty input
size of n-best list from segment-decoder and PDec-translator are different
Tokenizer did not return same number of phrases as the Translator.
resetting original query ranges from alignment-span-info
Disambiguation symbol 
 is also a phone.
Determinization aborted since passed 
 states.
max-states reached in determinization
Determinization terminated since passed 
 states, partial results will be generated.
Determinization aborted since looped more than 
 times during epsilon closure.
looped more than max-states times in determinization
DeterminizerStar: FST was not functional -> not determinizable
First string: 
Second string: 
Non-functional FST: cannot determinize.
Debug function called (probably SIGUSR1 caught).
Nothing to trace back
Traceback did not reach start state (possibly debug-code error)
Traceback below (or on standard error) in format ilabel (olabel olabel) ilabel (olabel) ...
EncodeMapper: Label-encoded arc has different input and output labels
EncodeMapper: Weight-encoded arc has non-trivial weight
EncodeMapper: decode failed
EncodeTable::Decode: unknown decode key: 
FST is not an unweighted acceptor
Acyclic Minimization
Cyclic Minimization
Weight::Properties() & kIdempotent
../libquasar/libkaldi/tools/openfst/src/include/fst/minimize.h
PrePartition
Initial Partition: 
Context FST created but there are no phone symbols: probably input FST was empty.
context
ContextFst: CreateArc, invalid olabel supplied [confusion about phone list or disambig symbols?]: 
ContextFst copying not yet supported [not hard, but would have to test.]
ContextMatcher: bad match type
TableMatcher: bad match type
final_weight.String().empty()
final_weight.Weight().Value1() == 0.0
final_weight.Weight().Value2() == 0.0
Total forward probability over lattice = 
, while total backward probability = 
Non-finite total probability in lattice (
). Numeric problems with model?
best cost = 
path len=
 mean conf=
[stack trace: ]
nnlm-trainer-config
nnlm trainer config path no default value
nnlm-loading-files
nnlm espresso inference network used for evaluation
wordmap-file-extension
The file extension that is used for workmap file.
enable-wordmap
The indicator on whether enable wordmap at inference time.
norm-factor
norm factor used at inference time
max-context-size
maximum context size used by nnlm at inference time
num-epochs
number of epochs that training pipeline goes over the given data
evaluate-after-each-epoch
the flag that indicates whether enable evaluation after each epochs
nnlm-trainer-overwrite-config
optional field that can overwrite existing default trainer config
The nnet loading path contains dangerous components.
Malformed LM neural network file name, fileBasename=
Other data type is not supported for NNLM trainer.
Unsupported NNLM training Config
.shape
ComputeAheadFeatInput
ivector file 
 cannot be opened
Landmark hash ark file 
imposterMean=
imposterStd=
Name of nnet file
Threshold to apply to ivector score
ivector-fingerprint-ark-file
ark file with ivectors for fingerprints
ivector-imposter-ark-file
ark file with ivectors with imposters
trigger-preceding-max-ms
Maximum amount of audio used before trigger phrase
trigger-trailing-min-ms
Minimum amount of audio used after trigger phrase
trigger-trailing-max-ms
Maximum amount of audio used after trigger phrase
trigger-num-tokens
The number of tokens in the trigger phrase (two for hey siri)
ivector-threshold
ivector-score-bias
Bias to apply to ivector score when combining with lmark
lmark-hash-strategy
Hashing strategy (e.g. 3x3)
lmark-hash-start-idx
Feature start idx for hashing
lmark-hash-end-idx
Feature end idx for hashing
lmark-hash-fingerprint-ark-file
ark file with landmark hash vectors for fingerprints
lmark-hash-imposter-ark-file
ark file with landmark hash vectors for imposters
lmark-min-len
Min num frames for computing similarity between landmark hash vectors
lmark-max-len
Max num frames for computing similarity between landmark hash vectors
lmark-threshold
Threshold to apply to landmark similarity
imposter ivector file 
 is empty
fp-ivectors=enabled
Unrecognized hash strategy string 
Landmark params not properly set
fp-landmark=enabled
Invalid fbank dims. 
Expected: 
 Got: 
Encountered zero iVector
Speaker embedding=
Index=
 similarity=
 exceeded threshold=
Did not match any known fingerprints
Trigger phrase not detected
Not enough audio to make a decision.
Hash strategy 
 is not implemented
Landmark hash=
] Unnormalized landmark hash score: 
] T-normalized landmark hash score: 
FingerprintDetector not run on input origin 
Error: Utterance features were improperly cached.
Zero-length utterance. Rejecting utterance.
Error: getAudioProcessingWindow failed
Processed Frames: 
Best i-vector match score=
 index=
Adjusted i-vector score=
 thres=
FingerprintAlgo
FingerprintIndex
FingerprintScore
FingerprintDetected
FingerprintDetected=
 MatchingIndex=
 matchingScore=
num-ceps
Number of cepstra in MFCC computation (including C0)
use-energy
Use energy (not C0) in MFCC computation
energy-floor
Floor on energy (absolute, not relative) in MFCC computation
raw-energy
If true, compute energy before preemphasis and windowing
cepstral-lifter
Constant that controls scaling of MFCCs
htk-compat
If true, put energy or C0 last and use a factor of sqrt(2) on C0.  Warning: not sufficient to get HTK compatible features (need to change other parameters).
sample-frequency
Waveform data sample frequency (must match the waveform file, if specified there)
frame-length
Frame length in milliseconds
frame-shift
Frame shift in milliseconds
preemphasis-coefficient
Coefficient for use in signal preemphasis
remove-dc-offset
Subtract mean from waveform on each frame
dither
Dithering constant (0.0 means no dither)
window-type
Type of window ("hamming"|"hanning"|"povey"|"rectangular")
round-to-power-of-two
If true, round window size to power of two.
snip-edges
If true, end effects will be handled by outputting only frames that completely fit in the file, and the number of frames depends on the frame-length.  If false, the number of frames depends only on the frame-shift, and we reflect the data at the ends.
num-mel-bins
Number of triangular mel-frequency bins
low-freq
Low cutoff frequency for mel bins
high-freq
High cutoff frequency for mel bins (if < 0, offset from Nyquist)
vtln-low
Low inflection point in piecewise linear VTLN warping function
vtln-high
High inflection point in piecewise linear VTLN warping function (if negative, offset from high-mel-freq
debug-mel
Print out debugging information for mel bin computation
cmn-window
Window in frames for running average CMN computation
min-cmn-window
Minimum CMN window used at start of decoding (adds latency only at start). Only applicable if center == false, ignored otherwise.
norm-vars
If true, normalize variance to one.
center
If true, use a window centered on the current frame (to the extent possible, modulo end effects). If false, window is set based on "cmn-window" and "lookahead".
lookahead
Number of frames to look ahead for online CMN. Ignored if center==true.
SequentialTableReader<Holder>::Open(), could not close previously open object.
Invalid rspecifier 
Trying to use empty SequentialTableReader (perhaps you 
passed the empty string as an argument to a program?)
TableReader::Open, error closing previous input (only warning, since permissive mode).
TableReader::Open, error closing previous input.
TableReader: failed to open stream 
TableReader: error beginning to read table (wrong filename?): 
Done() called on TableReader object at the wrong time.
IsOpen() called on invalid object.
Key() called on TableReader object at the wrong time.
Value() called on TableReader object at the wrong time.
KaldiObjectHolder::Value() called wrongly.
TableReader: FreeCurernt called at the wrong time.
TableReader: Next() called wrongly.
Error reading archive 
Invalid archive file format: expected space after key 
, got character 
, reading 
Object read failed, reading archive 
Reading Table object, failed reading binary header
Exception caught reading Table object 
Close() called on TableReader twice or otherwise wrongly.
Error detected closing TableReader for archive 
 but ignoring 
it as permissive mode specified.
TableReader: reading archive failed: 
TableReader::Open, error closing previous input 
Failed to open script file 
TableReader: failed to load object from 
 (to suppress this error, add the permissive 
(p, ) option to the rspecifier.
TableReader: you called Value() after FreeCurrent().
TableReader: Value() called at the wrong time.
TableReader: LoadCurrent() called at the wrong time.
TableReader: failed to open file 
TableReader: FreeCurrent called at the wrong time.
SequentialTableReader, reading script file: Next called wrongly.
Close() called on input that was not open.
Close() called on scp file with read error, ignoring the error because permissive mode specified.
TableReader: reading script file failed: from scp 
empty CTC keyword
<EncoderInput>
<DecoderParentIds>
<DecoderInput>
<DecoderCheck>
<DecoderSuccess>
<DecoderOutput>
<DecoderAttention>
<Encode>
<Reset>
<InputShapeTemplate>
<FrameSubsamplingFactor>
<BOSIndex>
<EOSIndex>
<SilIndex>
<Beam>
in->GetNumDims() == cfg_.input_shape_template.ndim
in->GetDimSize(cfg_.input_shape_template.col_index) == InputDim()
<Inputs>
<Outputs>
<InputStates>
<OutputStates>
<InitialStates>
<Feats>
<Parents>
<Check>
<Attentions>
<Success>
<InputFeats>
<FinishEncoding>
<OutputFeats>
input_states.size() == cfg_.input_states.size()
input_feats->GetNumDims() == cfg_.input_shape_template.ndim
input_feats->GetDimSize(cfg_.input_shape_template.col_index) == InputDim()
<InputParents>
<InputLabels>
<OutputLoglikes>
<OutputAlignments>
<InputAttentionStates>
<ComputeCellOutputs>
<InputCellOutputs>
input_states.size() == cfg_.output_states.size()
input_feats != nullptr
input_feats->GetDimSize(cfg_.input_shape_template.row_index) > 0
src_states.size() == cfg_.input_states.size()
src_states.size() == cfg_.output_states.size()
src_states.size() == dst_states.size()
encoder_input
decoder_parent_ids
decoder_input
decoder_output
decoder_attention
reset
inputs
outputs
input_states
output_states
initial_states
feats
parents
attentions
input_feats
output_feats
input_parents
input_labels
output_loglikes
output_alignments
Attempt to write into immutable matrix
Too many rows*cols for 8-bit Matrix
Quantized matrix improperly serialized
unimplemented
New stride (
) must not be smaller than
 the current stride (
) must be a multiple of 
current stride (
Non matching dimensions: Rows:
 VectorDim:
Non matching dimensions: Cols:
matrix A and B can not be transposed at the same time, not implemented yet
Memory allocation failed when initializing CuVector 
with dimension 
 object size in bytes: 
word-syms-file
word symbol table text format filename
HCLG FST filename
Could not read symbol table from text file 
/sil_S/
/sil_B/
/sil_I/
/sil_E/
Problem decoding utterance.
FINAL RESULT:
Result Choice[
Pronounciation Choice[
update-interval
Beam update interval in frames
beam-update
Beam update rate
max-beam-update
Max beam update rate
inter-utt-sil
Maximum # of silence frames to trigger new utterance
max-utt-sil
Maximum # of silence frames to trigger end of speech while no speech presented
max-utt-length
If the utterance becomes longer than this number of frames, shorter silence is acceptable as an utterance separator
det-max-mem
Maximum approximate memory usage in determinization (real usage might be many times this)
det-max-loop
Option used to detect a particular type of determinization failure, typically due to invalid input (e.g., negative-cost loops)
Decoding beam.
Decoder max active states.
min-active
Decoder minimum #active states.
Lattice generation beam
prune-interval
Interval (in frames) at which to prune tokens
determinize-lattice
If true, determinize the lattice (in a special sense, keeping only best pdf-sequence for each word-sequence).
Increment used in decoding-- this parameter is obscure and relates to a speedup in the way the max-active constraint is applied.  Larger is more accurate.
Setting used in decoder to control hash behavior
word-ins-penalty
Word insertion penalty applied to each word
delta
Tolerance used in determinization
max-mem
Maximum approximate memory usage in determinization (real usage might be many times this).
phone-determinize
If true, do an initial pass of determinization on both phones and words (see also --word-determinize)
word-determinize
If true, do a second pass of determinization on words only (see also --phone-determinize)
minimize
If true, push and minimize after determinization.
Could not topologically sort lattice: this probably means it has bad properties e.g. epsilon cycles.  Your LM or lexicon might be broken, e.g. LM with epsilon cycles or lexicon with empty words.
determinization did not succeed(partial output will be pruned tighter than the specified beam.)
Beam: 
; Speed: 
 xRT
Changed confidence for slot=
1best: 
phrase=
 orig: 
 new: 
Unsupported n-best index configuration
n-best output size is wrong
am-file
Acoustic model (transition model) filename
Decoding beam
first-pass-lattice-beam
First pass lattice beam
Decoding lattice beam
retry-beam
Fall-back decoding beam
HCP FST filename
tree-file
Tree file
phone-map-file
Phone mappings file
Conversion of alignments in lattice is only supported for models with context width = 1, other models will result in alignments which do not properly consider cross-word contexts
Problem decoding utterance for re-alignment.
Determinization finished earlier than the beam
kaldi::OnlineDecodableNnet1Lazy is required at this point in the first pass with configured realign-model parameter.
opts_.beam > 0
Not implemented
prior=(-?\d+\.?\d*)$
RegexParseError: expected [ or ( at 
 but found 
Unexpected regex found: '
' in '
Unbalanced parenthesis or brackets found in grammar
prior=
 config:
empty nbest (token) input received
size
text
positions
placeholders
Input dimension of parallel component and input dimensions of nested networks do not match.
Output dimension of parallel component and output dimensions of nested networks do not match.
no limiting of nbest output size
invalid value for nbest option!
limiting n-best size to 
using metainfo annotation to filter nbest
simple nbest size limiting
validating source locale against metainfo locale
locale validation disabled
senses
source-locale not set
defLocale
defLocale: <
 incompatible with srcLocale: <
> deleting alternatives and stripping nbest annotation from metainfo
> deleting alternatives and stripping disambig annotation from metainfo
sending 
 alternatives without limiting
 alternatives, too few to limit (limit=
 alternatives, limiting from 
no hypotheses, sending empty list of hypotheses
only one hypothesis, sending it
1-best hypothesis is low confidence, sending only this hypothesis
1-best hypothesis has no ambiguity annotation, sending only this hypothesis
no ambiguity found: 
 alternative(s)
ambiguity found: 
unconstrained
reduced
avoid
The number of recognition request parameters is 
 (requirement is 3)
 (requirement is 5 or 8 for config file ver 15.0+)
Illegal char '*' found in task type 
Illegal char '*' found in device type 
farField type must be '*', 'true', or 'false': 
Illegal char '*' found in bluetooth device id 
aneContext type must be '*', 'unconstrained', 'reduced', or 'avoid': 
cpuContext type must be '*', 'unconstrained', 'reduced', or 'avoid': 
gpuContext type must be '*', 'unconstrained', 'reduced', or 'avoid': 
Could not find the recognizer components for the params samplingRate=
 task=
 device=
 farField=
 bluetoothDeviceId=
 aneContext=
 cpuContext=
 gpuContext=
associated-task-mapping
Recognizer string malformed
 :: 
Could not make Unicode regex: 
Could not open BreakIterator: 
<NumCells>
<BiasMean>
<BiasRange>
<ForgetGateBiasMean>
<ForgetGateBiasRange>
<ProjectionLearnRateCoef>
<MaxNorm>
<MaxCell>
<NoPeep>
<OutputCellValues>
Invalid token 
. Allowed tokens: 
(NumCells|BiasMean|BiasRange|ForgetGateBiasMean|ForgetGateBiasRange|ParamStddev|LearnRateCoef|ProjectionLearnRateCoef|MaxNorm|
MaxGrad|MaxCell|NoPeep|InitTransformType|GradientNormType|RandomSeed)
bias_ thought to be initialized here
# LSTM cells (
) should not be less than output dim (
input_weights_ thougth to be un-initialized here
recurrent_weights_ thougth to be un-initialized here
peephole_weights_ thougth to be un-initialized here
bias_ thougth to be un-initialized here
projection_weights_ thougth to be un-initialized here
 Input weights:
 Recurrent weights:
 Bias:
 Forget gate bias:
 Peephole weights:
 Projection weights:
  Gradients are uninitialized
 For batch 
  Number of cells : 
  Input weights gradient: 
  Recurrent weights gradient: 
  Bias gradient: 
  Peephole weights gradient: 
  Projection weights gradient: 
  Gates values: 
  Cell values: 
  Cell outputs: 
  Cell outputs gated: 
  Output values: 
  Gates diff: 
  Cell diff: 
  Cell out gated diff: 
  Output diff: 
Accumulating gradients for batch id = 
Reset previous states for utts 
input_weights_
recurrent_weights_
peephole_weights_
projection_weights_
input_weights_gradient_.size() > ib
input_weights_gradient_[ib]
recurrent_weights_gradient_.size() > ib
recurrent_weights_gradient_[ib]
bias_gradient_.size() > ib
bias_gradient_[ib]
has_peepholes_
peephole_weights_gradient_.size() > ib
peephole_weights_gradient_[ib]
has_projection_layer_
projection_weights_gradient_.size() > ib
projection_weights_gradient_[ib]
input_weights_ thought to be un-initialized here
recurrent_weights_ thought to be un-initialized here
bias_ thought to be un-initialized here
peephole_weights_ thought to be un-initialized here
projection_weights_ thought to be un-initialized here
Allocated memory for the parameters: 
Allocating forward buffers for batch 
; batch size = 
Allocating backward buffers for batch 
input_weights_gradient_.size() == 0
recurrent_weights_gradient_.size() == 0
bias_gradient_.size() == 0
peephole_weights_gradient_.size() == 0
projection_weights_gradient_.size() == 0
Allocated memory for the gradients: 
Saving last output and cell state for batch 
Input weights #rows = 
; expecting 
; #cells = 
Input weights #columns = 
 (same as input dim)
Recurrent weights #rows = 
Recurrent weights #columns = 
 (same as output dim)
Peephole weights #rows = 
Peephole weights #columns = 
 (same as #cells)
Bias dim = 
Projection weights #rows = 
Projection weights #columns = 
learn_rate_coeff_ must not be negative; found: 
projection_learn_rate_coeff_ must not be negative; found: 
max_norm_ must not be negative; found: 
max_grad_ must not be negative; found: 
max_cell_values_ must not be negative; found: 
Performing  vectorization of lstm component
gradients_valid_ is thought to be false here
input_weights_gradient_[ic]->NumRows() == InputWeights().NumRows() && input_weights_gradient_[ic]->NumCols() == InputWeights().NumCols()
recurrent_weights_gradient_[ic]->NumRows() == RecurrentWeights().NumRows() && recurrent_weights_gradient_[ic]->NumCols() == RecurrentWeights().NumCols()
bias_gradient_[ic]->Dim() == Bias().Dim()
peephole_weights_gradient_[ic]->NumRows() == PeepholeWeights().NumRows() && peephole_weights_gradient_[ic]->NumCols() == PeepholeWeights().NumCols()
projection_weights_gradient_[ic]->NumRows() == ProjectionWeights().NumRows() && projection_weights_gradient_[ic]->NumCols() == ProjectionWeights().NumCols()
Done vectorization of lstm component
Must first call init() for 
 before calling createDecodable().
Building Decodable 
Unknown decodable type "
matrix-scaled
matrix-scaled-mapped
matrix-scaled-mapped-tm
ctc-online-kwd
dummy
nnet1-lazy
Acoustic model (transition model) filename (only used for lattice stuff)
tid2pdf-file
Text file of ints representing PDF IDs for transition IDs 0, 1, 2, ... 
Read transModel
Using TID2PDF file
Created OnlineDecodableMatrixScaled decodable
decodable type "
Created OnlineDecodableMatrixScaledMapped decodable
OnlineDecodableMatrixScaledMapped: mismatch, matrix has 
 rows but transition-model has 
 pdf-ids.
tm-weight
Weight factor for tm likelihoods
Created OnlineDecodableMatrixScaledMappedTm decodable
Created OnlineDecodableIdenticalMatrix decodable
class-frame-counts-file
File containing vector with frame-counts of pdfs to compute log-priors. This is the same as class-frame-counts, but allows paths that are relative to the json config file (class-frame-counts requires absolute paths). If class-frame-counts is also specified, this param will override it.
Name of nnet model file
File for feature transform in front of nnet's main network (in nnet format)
skip-frames
Number of frames to be skipped in nnet computation.
use-gpu-id
Unused, kaldi is compiled w/o CUDA
silence-model-file
Name of nnet model file for computing silence posteriors
compute-sil-model-posteriors-from-realign-model
True if penultimate activations from realign model are the input to the silence model, otherwise use the penultimate activations from the main acoustic model
workspace-size-kb
Workspace size in Kilo Bytes
realign-model-file
Name of nnet model file for computing posteriors for later realignment of 1st/2nd pass lattices
realign-class-frame-counts-file
File containing vector with frame counts of pdfs to compute log-priors. This is the same as class-frame-counts, but allows paths that are relative to the json config file (class-frame-counts requires absolute paths). If class-frame-counts is also specified, this param will override it.
compute-realign-model-posteriors-from-penultimate
True if penultimate activations from main acoustic model are the input to the realignment model, otherwise use the same features as the main acoustic model as input
skip-blanks-threshold
Threshold for skipping frames with a CTC trained acoustic model, applied to posterior probability of the blank symbol
blank-pdf-id
Pdf-id of blank symbol of CTC trained acoustic model, used in combination with skip-blanks-threshold
skip-across-batch
Make skip-frames deterministic by skipping across batches instead of within batches (default: false).
blank-penalty
Penalty for blanks with a CTC trained acoustic model when silence posterior is higher than a threshold
blank-penalty-silence-threshold
Threshold of silence posterior when the blank penalty is appled to blanks
class-frame-counts
Vector with frame-counts of pdfs to compute log-priors. (priors are typically subtracted from log-posteriors or pre-softmax activations)
prior-scale
Scaling factor to be applied on pdf-log-priors
prior-cutoff
Classes with priors lower than cutoff will have 0 likelihood
Read mapped nnetTransf
Read nnetTransf
Read pdfPrior
Read model file for computing silence posteriors=
Read model file for computing realignment posteriors=
Created OnlineDecodableNnet1LazyDecodable decodable
Skipping 
 frames may not give you good results.
Parameters realign_model_input_is_penultimate_ and sil_model_input_is_realign_penultimate_ cannot both be true at the same time.
Realignment model (nnet_realign) must be set in order to pass its penultimate activations to the silence model.
skip_across_batch cannot be set if you aren't frame skipping
skip_across_batch does not work with skip_blanks_threshold or nnet_realign
nnet transformation contains splicing, which is not 
supported by OnlineDecodableNnet1Lazy. Use a separate splice 
operation to perform splicing.
nnet contains splicing, which is not supported by 
OnlineDecodableNnet1Lazy. Use a separate splice operation to 
perform splicing.
Given task and language pair combination is not supported
Failed to compile unicode outliers regex
sanitized string is empty
Pruned state-level lattice with beam 
 and retrying determinization with that beam.
Effective beam 
 was less than beam 
 * cutoff 
, pruning raw 
lattice with new beam 
 and retrying.
Both --phone-determinize and --word-determinize are set to 
false, copying lattice without determinization.
Doing first pass of determinization on phone + word 
lattices.
Doing second pass of determinization on word lattices.
Pushing and minimizing on word lattices.
Topological sorting of state-level lattice failed (probably
 your lexicon has empty words or your LM has epsilon cycles
Lattice determinization terminated but not 
 because of lattice-beam.  (#states, #arcs) is ( 
 ), versus limits ( 
 ) (else, may be memory limit).
Total weight of input lattice is zero.
Lattice determinization aborted since looped more than 
Cost below best cost was encountered:
Rebuilt repository in determinize-lattice: repository shrank from 
 bytes (approximately)
Did not reach requested beam in determinize-lattice: 
size exceeds maximum 
 bytes; (repo,arcs,elems) = (
), after rebuilding, repo size was 
, effective beam was 
 vs. requested beam 
Rebuilding repository.
empty subset
Zero weight!
New cost is less (check the difference is small) 
Invalid or out-of-range hex value
Found token separator char in token: "
Found unassigned code point 
 in string "
Unicode normalization failed for:
Input string is not Unicode normalized:
Found illegal char with value 
~U is not followed by 8 hex digits
~U is not followed by a valid unloggly code point
~w is not followed by 2 hex digits
~w followed by hexValue=
Encountered invalid tilde char: 
Unicode normalization failed for :
Illegal occurrence of ^ in HatText token 
Illegal use of ^ followed by value 
 in HatText token 
Conversion failed for qsr token 
Illegal occurrence of ~U in QsrText token 
Illegal occurrence of ~w in QsrText token 
Unsupported occurrence of ~w in QsrText token 
Illegal use of ~ in QsrText token 
Illegal occurrence of ~U in QsrText string 
Illegal occurrence of ~w in QsrText string 
Unsupported occurrence of ~w in QsrText string 
Illegal use of ~ in QsrText string 
) -> 
Failed to encode srcToken="
" dstToken="
u_strFromUTF8() failed with error=
Unicode NFC normalization failed.
u_strToUTF8() failed with error=
pre = "
post = "
map = 
<InFeatureMaps>
<OutFeatureMaps>
<PatchStep>
<SectionStep>
<SectionSize>
<FilterSize>
<InSharedBands>
<PoolSize>
<PoolStep>
<BiasLearnRateCoef>
 (ParamStddev|BiasMean|BiasRange|InFeatureMaps|OutFeatureMaps|PatchStep|SectionStep|SectionSize|FilterSize|LearnRateCoef|BiasLearnRateCoef|MaxNorm|RandomSeed)
ConvolutionalMaxPoolingComponent: Invalid max pooling size
ConvolutionalMaxPoolingComponent: Max pooling step must be >= 1
ConvolutionalMaxPoolingComponent: output dim mismatch
ConvolutionalMaxPoolingComponent: input dim mismatch
ConvolutionalMaxPoolingComponent: too few input bands to compute the output
pointer is thought to be un-initialized here
<Filters>
<Bias>
  filters
  filters_grad
, max-norm 
  bias_grad
 , # of sections: 
, section size after pooling: 
Backpropagation of CNN ConvolutionalMaxPoolingComponent is not supported for quantized weights
Not supported for quantized weights
Unimplemented
Backpropagation of CNN ConvolutionalMaxPoolingComponent is not supported on CPU
ConvolutionalMaxPoolingComponent::AccumGradients can't be called before ConvolutionalMaxPoolingComponent::Backpropagate
Performing vectorization of convolutional maxpooling component
(nlinparams + Bias().Dim()) == NumParams()
veccorrs->size() == filters_grad_.size() && veccorrs->size() == bias_grad_.size()
(filters_grad_[ic]->NumRows() * filters_grad_[ic]->NumCols() + bias_grad_[ic]->Dim()) == NumParams()
Done  vectorization of convolutional maxpooling component
<NumBands>
 (NumBands)
NumBands should be > 0
Invalid NumBands value
 CnnRearrange 
<PrePadding>
<PostPadding>
<Postamble>
<PadValue>
Invalid pre and post padding sizes
Invalid postamble size
 PaddingComponent 
<FmapXLen>
<FmapYLen>
<PadTop>
<PadBottom>
<PadLeft>
<PadRight>
h > 0 && w > 0
num_to_trim_h < h
num_to_trim_w < w
input_dim_ % (h * w) == 0
output_dim_ % (out_h * out_w) == 0
c == out_c
Config file must be loaded before calling this method.
Config path is empty. Config file must be loaded before calling this method.
File 
 not found.
remove child: 
The existing value of the key: 
 is a list. New value will be appended to the list.
 will be appended with new value.
Appending of new value is supported only for value types - list, string. Please cross check value for key: 
The override key: 
 starts with 
, however no existing key/value was found to be appended. New value will be added for the keyPath: 
override config version << 
 is incompatible with main config version: 
override config type << 
 is not the same as main config type: 
model-info.version
override config language [
] is not the same as main config langauge [
We only support override of speech model.
Failed to load override config with error = 
This method can be called only once throughout the lifetime of this object.
Using cache for json file 
Reading json file 
Config override: 
Set json config file path to 
failed to parse json file 
, error: 
version-major
version-minor
Config file version is missing. 
Reading version 
 as 15.0
Version of currently loaded config file: 
 Supported config file version: 
 (minimum supported version: 
Config file version 
 is lower than the minimum supported version 
 is higher than the supported version 
Config file does not have speech model-info node.
Config file does not have mt-model-info node.
Config file does not have model-info node.
model-info
mt-model-info
Only one of model-info and mt-model-info can exist in the config
model-info.language
model-info.os-types
Empty model-info.os-types
model-info.sampling-rates
Empty model-info.sampling-rates
model-info.tasks
Empty model-info.tasks
model-info.phoneset-version
model-info.acoustic-profile-version
lme-create.template-map
ACE category name 
 occurs twice in lme-create.template-map
lme-create.name-enumerator-map
Quasar template name 
 occurs twice in lme-create.name-enumerator-map
type
g2p.model-version
model-info.hybrid-endpointer-version
Error parsing model-info 
mt-model-info.version
mt-model-info.source-language
mt-model-info.target-language
mt-model-info.language-pairs
invalid language pair: 
mt-model-info.tasks
'mt-model-info.tasks' must be dictionary of task specific language pair lists, when no global language pair(s) provided
task specific language pair lists require minimum config version 
language-pairs
no 'language-pairs' section in task section '
Non source and target language pair.
Empty mt-model-info.tasks
mt-model-info.task-alias
missing decoder config for task 
 (expected config in 
language-pair-specific-settings
invalid language pair name: 
missing specific setting, this should not happen.
source language 
 using 
' tokenizer.
target language 
Error parsing mt-model-info 
hybrid-client-configs
hybrid-client-configs.hybrid-ep-thresholds
hybrid-client-configs.hybrid-ep-extra-delay-frequency
%s : %s
%s : %d
%s : %f
parameter [
] was not verified of its presence in the original config. Adding/Replacing it.
] is not in original config.
] is not a leaf node.
-file
nt-fsts.\NT-bizname
g2p-blacklist
-directory
geo-config
-ark-file
ark:
-file-list
rule-fst
Could not find required name "
Parameter "
" requires minimum version 
 but config version is 
" requires maximum version 
Ignoring unrecognized option 
Required parameter "
" not found
Prefix must end with '.' : 
Incompatible system config version. Needs to be >= 
 to use 
Incompatible system config version. Needs to be <= 
Invalid integer option "
Invalid floating-point option "
Parameter name 
 already registered
append:
boost::bad_format_string: format-string is ill-formed
boost::too_many_args: format-string referred to fewer arguments than were passed
boost::too_few_args: format-string referred to more arguments than were passed
VersionUnsupported: 
result-combiner
result-combiner.
1.0,1.0
compute-conf
Whether to use existing confidence or re-compute a score from the tokens, default = true.
nbest-depth
The maximum number of alternatives to allow in the combined output, default = 10.
system-weights
A comma-separated list of weights to apply to each system, in the same order as the provided system input, default is 1.0,1.0.
contact-first@contact-middle@contact-last@appname-first@appname-last,contact-first@contact-middle@contact-last@appname-first@appname-last
backbone-system
The index of the system to use as the reference/backbone system. This is the default system, and the one which is used for alignment.
eps-backbone
The epsilon confidence score for epsilons inserted into the backbone.
eps-alternative
The epsilon confidence score for epsilons inserted into the alternative systems.
do-selection
Switch to control whether to do system selection or combination, default is 'true' (i.e. do selection only).
combine-any-region
Switch to control whether, if regions are specified, to do region combination within the entire utterance, if the region exists at all in the two CNs.
combine-in-region-only
Switch to control whether, if regions are specified, to do region combination only in slots where the region exists.
confidence-delta
The delta by which the competing systems must be better than the backbone in order to be considered better.
region-list
List of regional terminals to mach for use for system combination (works with region-combine options). Comma-separated for each system, and @-separated for each region within a system (e.g. contact-first@appname-first,contact-last).
do-flatten
Switch to control whether to flatten the confusion network such that only a 1-best combination/selection is performed.
do-partial-merge
Switch to control whether to allow merging a partial hypothesis with a longer one before doign selection.
max-partial-shift
The amount of jitter or shift to allow when deciding whether to merge a longer hypothesis with a partial one.
truncation-delta-milliseconds
Skip system combination if (backbone speech end - competing speech end) >= this value. Value can be positive or negative. This prevents truncation if the CN being combined with is too short. By default, we don't enable this check, value = huge number.
Could not read system weight info
Number of systems is 
System 
 Number of alternatives is 
Alternative = 
Final alternatives list:
DECODER OPTION in slot 
 word 
 score = 
 phoneSeq 
CONSENSUS in slot 
 selected word 
End time of competing confusion network is 
ConfusionNetworkMerge: Backbone word starts at the same time as the end of the competing CN. Merge starting at 
ConfusionNetworkMerge: Exceeded the maximum allowable shift amount (
) with 
 won't try to merge anymore.
ConfusionNetworkMerge: Backbone word starts before the end of the competing CN, ends after and covers more audio. Merge starting at 
ConfusionNetworkMerge: We have exceeded the maximum allowable shift amount (
 we won't try to merge anymore.
ConfusionNetworkMerge: Backbone word starts after end of the competing CN, and haven't started merging yet, and the word doesn't start too long after. Merge starting at 
Merging the word/words in slot 
 onto the end of the competing confusion network
Found a region of interest in the confusion network
Could not find a region of interest in the confusion network
BestConfidence is 
Competing Confidence for system 
 is 
Best system End Time is 
End time for competing system 
Competing system does not cover enough speech (max truncation is 
 ,current truncation is 
Exiting selection logic
Proceeding with selection logic using merged partial confusion network
Switching selected system from 
 new score = 
 old score = 
Selected system is 
FINAL HYPOTHESIS IS  : 
text=
 tokens=[
DecodableMatrixScaledMapped: mismatch, matrix has 
if >= 0, use this value as length penalty weight. Default means using the default in the graph
pad-size
if the whole audio is too short, pad to this length
mmapped-graph
is it a memory mapped graph?
num-inter-op-threads
The maximum number of threads for inter ops in TF graph
num-intra-op-threads
The maximum number of threads for intra ops in TF graph
default-device
TF default device
catf-input
the catf input, a list of comma delimited values
allow-soft-placement
TF allow soft placement
log-device-placement
TF log device placement
profiling-granularity
Level of profiling (higher means more precise breakdown per operation)
model-config-file
The config file for the model
model-config-binary
is the config file binary?
model-config-end-token
The config file's end token
number of frames in each batch
model-beam
the beam size used in the model
time-reduction-factor
source sequence length reduction factor in the model
max-decode-length
the maximum number of decoding steps
if > 0, use this value as the coverage penalty.
utt-end-beam
if > 0, use this beam at the utterance end.
safe-align-thresh
number of steps for alignment wiggle room
init-wait-time
number of frames before running the first generation step
cont-wait-time
number of frames before running the continuous generation step
rb-steps-fail
for early termination (failed), rollback this number of steps
rb-steps-boundary
for hitting boundary, rollback this number of steps
encoder-only
only streaming the encoder part
min-attn-weight
the minimum attention weight for a valid generation step
split
 tokens active.
VoiceCommandsBasicEndPointer inter-utt-sil=
, max-utt-length=
, max-utt-sil=
call to empty boost::function
illegal count weight or 
line too long?
SymbolTableData
/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/libquasar/liblm/src/symbol_tables.cpp
</s>
<unk>
-pau-
Null symbol table passed to constructor
Could not find symbol: 
/WORD-DIS-1/
observeTrainingSymbol
unmapped FST symbol
trainVocab not set
lookupTrainId
trying to look-up unmapped FST symbol: 
training token 
 not present in training map
 not present in training or ARPA vocabulary
observeSymbol
Unknown symbol source 
symbolMask and numSymbols should be non-null
Label out of bounds: 
observeBigGSymbols
observeSrilmVocabulary
ARPA vocabulary contains data pack OOV: 
generateTrainToBigGIdRemapping
 observed in ARPA but not present in SRILM Vocab
IterateSRILMVocabTokens
ComputeSRILMVocabToOpenFSTSymbolTableRemapping
FST SymbolTable should contain <s>.
FST SymbolTable should contain </s>.
InsertOrDie
../libquasar/liblm/include/lm/stl_utils.h
duplicate key 
FST SymbolTable does not contain token 
 (id 
duplicate element 
phrase-length-limit
max-num-enumerations
tag-sequences
we should have allocated enough space, instead we get in 
this expensive copy/resize on GPU. buffer size 
 , current end 
 , incoming data size 
read
AlignInput: can't determine stream position
AlignOutput: can't determine stream position
FstHeader::Read: Bad FST header: 
FstHeader::Read: read failed: 
Unknown file read mode 
Invalid UTF8 string:
Could not extract UTF8 length: 
Could not extract UTF8 chars: 
Regex compilation failed for:
Failed to initialize regex: 
Could not set regext text: 
Could not create space text: 
Error getting capacity for splitting text: 
Could not set regex text: 
Could not set region: 
Could not trim: 
Could not create input text: 
Could not create to text: 
Could not replace text with regex: 
Could not get utf-8 string: 
) Could not decode UTF8: 
) Could not set regex input: 
) Failed to apply regex: 
Could not extract UTF16 length: 
Could not extract UTF16 chars: 
BreakIterator construction failed: 
speculative-steps
steps to decode beyond attention checks
rollback-steps
steps to rollback before each speculative decoder
speculative-catchup
Catch up at the end of utterance by returning speculative predictions
unchecked-attention-heads
Do not perform checks for attention heads at these indexes
Error writing compressed matrix to stream.
Reading aligned matrix as a stream
Expected token 
. This could mean that you're trying to memory map an unaligned file.
Seeking for aligned data failed
Failed to read header
Failed to read data.
TranslationModel/__QNNO__initial_state:0
TranslationModel/__QNNO__encoder_values:0
TranslationModel/__QNNO__output_state:0
TranslationModel/__QNNO__softmax:0
TranslationModel/__QNNO__top_k_scores:0
TranslationModel/__QNNO__top_k_indices:0
TranslationModel/__QNNO__attention:0
TranslationModel/__QNNI__source_input:0
TranslationModel/__QNNI__target_input:0
TranslationModel/__QNNI__input_state:0
TranslationModel/__QNNI__top_k:0
input_mask
position
embedding
Nnet already mapped from a file
InputSymbolTableFile
Input symbol table size 
OutputSymbolTableFile
Output symbol table size 
<InputSymbolTable>
InputSymbolTable
<OutputSymbolTable>
OutputSymbolTable
InputVocab
Input vocab size 
OutputVocab
Output vocab size 
EspressoEngine
EncoderEspressoEngine
DecoderEspressoEngine
Graph
EmbeddingGraph
EncoderGraph
DecoderGraph
DecoderLangGraph
HandoverLangGraph
Mmap
AddSrcBos
AddSrcEos
PadSrc
PadSrcConfigs
MaxSrcTokens
Reverse
IsRNN
UseAttention
UseTopK
TopKCount
ModelBatchSize
BPEEncoder
Failed to read BPE model from : 
<BPE>
Failed to read embedded BPE model
BPE read - entries: 
AddTag
TagFormat
IsEspresso
SourceInputStr
TargetInputStr
EncoderValuesStr
ScoresStr
ShortlistStr
ShortlistFile
Loading Shortlist file...
<Shortlist>
Reading Shortlist...
ReadoutNnetFile
Loading readout Nnet file...
<ReadoutNnet>
Reading readout Nnet...
AlignmentLayerStr
AlignmentHeads
ShiftedAlignments
TransposeSourceInput
TwoDimSourceInput
HandoverStrings
StateStrings
StateWidth
StateLayoutND
NeedsPosition
NeedsEncoderPositions
NeedsEncoderOut
PositionZeroBased
ApplyLog
PositionScaleStr
NoSymbolTables
Either Graph or both EncoderGraph and DecoderGraph (or at least one DecoderLangGraph) must be specified in model file
Input symbol table must be specified
Output symbol table must be specified
Mmap must be set in model config file
IsRNN must be set in model config file
AddSrcBos must be set in model config file
Reverse must be set in model config file
Model is an RNN
UseTopK is set, Only 
 best outputs will be used
.next
f_encoder_
f_decoder_
Loading ENCODER...
Loading EMBEDDING...
Loading DECODER...
TensorFlow support not compiled
Handover plan required but not loaded!
Loading DECODER for '
'...
Loading HANDOVER for '
Unknown label not described in the model
Model does not support n-best inputs
Unexpected tensor rank 
 for encoder output
Espresso shortlist models require active shortlist!
 for handover 
Model does not support stream-decoding
Position input: 
readout layer size: 
Batched decoding not implemented for transformers with state handling
<UnkMode>
<UnkToken>
<Version>
<NumBpe>
Expected to read number of BPE units now, but got 
BPE model version: 
# of BPE model entries : 
 # of chars 
BPE model unk mode = 
, unk token = 
Wrong number of fields, ignoring : 
keep
char2unk
word2unk
dropword
dropchar
Unknown BPE unknown mode
Unknown unk mode : 
 diff 
Memory mapping failed. Not a valid Kaldi binary file: 
Memory mapping failed. mapped_file_ is NULL
memory mapped file 
opts_.eos_probability_threshold >= 0.0 && opts_.eos_probability_threshold <= 1.0
NoGradNorm
 correctedUtterances=%@
Input symbol id 
 missing from target vocabulary
Output symbol id 
 id=
lmScorer failed
lmScorer wrong number of results
lmScorer wrong result token
lmScorer wrong last result token
graphCost
acousticCost
choices
aligned
Word alignment failed: 
startMillis
endMillis
Multiple primary buffers are not allowed! 
Hint: Only one decoder chain can do system combination.
Cannot remove the primary buffer
Secondary chain rejected audio, probably waiting for primary: 
Invalid line in lexicon: '
Unable to load additional lexicon from: 
\PM-
<eps>
Unsupported phoneme '
' observed, skipping the pron 
Building NameEnumerator 
simple
raw-copy
exhaustive
regex
derived
Unknown NameEnumerator "
GetNumDims() == 2
prefilter input
<DNFList>
Skipping tag 
Input hammer has 
 known entries it will remove
Add tag 
 to pass lists
Not configured for locale : 
 on line 
Input hammer has DNF 
 known entries across 
 locales it will leave in place
RemoveUnderScores = 
, StripTokenLocales = 
, # of entries 
</DNFList>
<RemoveUnderScores>
<StripTokenLocales>
Locale not in pass list 
Input hammer did not change anything 
Input hammer removed tags 
Lattice word alignment failed. Cannot obtain word hyp lattice.
Empty word-aligned lattice. Cannot obtain word hyp lattice.
Could not load general voc
Sdapi has errored. Dying.
Could not tokenize
Could not get info from tokenized result
Failed TPToken_GetResultData with error code : 
Failed TPToken_DeleteResult with error code : 
No starting states!
Unsupported storage type 
Must have at least 3 mel bins
Bad values in options: low-freq 
 and high-freq 
 vs. nyquist 
Bad values in options: vtln-low 
 and vtln-high 
, versus 
low-freq 
Invalid indexing. You may have set --num-mel-bins too large.
bin 
, offset = 
, vec = 
MEL BANKS:
disambig_sym_start_ > 0 && disambig_sym_end_ > 0 && disambig_sym_start_ <= disambig_sym_end_
!fsts.empty()
FstNonNullAndHasArcs(fst)
MergeTrieFst[
 fsts_datas_size 
 unigram_fst_size 
 num_states 
 num_states_expanded 
 num_arcs 
sub_arc.ilabel != 0
!prev_arc || (current_arc->ilabel > prev_arc->ilabel) || (current_arc->ilabel == prev_arc->ilabel && current_arc->weight.Value() >= prev_arc->weight.Value())
group_size > 0
!IsDisambigSym(first_sub_arc.ilabel) || (group_size == 1)
first_sub_arc.ilabel > prev_group_ilabel
sub_arc.ilabel == first_sub_arc.ilabel
sub_arc_nextstate_final == Weight::One()
!safe
error: %s
memory error: %s
Initialized profile service failed 
Initialization of profile service succeeded 
Initialization of textproc failed 
Initialization of textproc succeeded 
Loading of general voc failed for voc=
, svc=
 with value=
Loading succeeded for voc=
 and svc=
Loaded CP1252 voc
Loaded UTF8 voc
locale: 
modelVersion: 
languageId: 
emptyDeltaVoc: 
pgVoc: 
generalVoc: 
paramsetHolder: 
generalVocTP: 
generalSvcTP: 
lexiconTP: 
staticTokenTP: 
staticItnTP: 
NcsDatapackManager loaded locale 
Error: Voc does not contain the tokencoll collation table
oh no:
 gave us 
Could not open lexicon
Could not open ITN
Could not do TPToken_Open
sdapi
SDhAdapter
SDAdaptAlignment
SDAdaptMethod
SDAdaptResultCode
SDhAdaptAccumResult
SDhAdaptApplyResult
SDAdapterInfo
SDAdaptConfigAndStatsItem
SDAdaptAccumResultInfo
SDAdaptApplyResultInfo
SDhChannel
SDChannelType
SDChannelResultCode
SDChannelFileFormat
SDExtChanDataType
SDWaveEncodingType
SDSignalFormat
SDChannelInfo
SDExtChanServerEventResult
SDExtChanServerEventType
SDExtChanServerEventSink
SDExtChanClientEventType
SDExtChanClientEventSource
SDExternalChannel
SDhColl
SDhCorpus
SDhCorpusWord
SDCorpusDocumentInfo
SDCorpusInfo
SDFPExceptionType
SDMemStats
SDEnvContainerType
SDEnvSpec
SDhEnvHolder
SDEnvHolderSource
SDEnvHolderInfo
SDInteger
SDUnsigned
SDUnsigned16
SDArraySize
SDByte
SDBool
SDChar
SDWideChar
SDFileSpec
SDInteger64
SDUnsigned64
SDDuration
SDUttFrameDuration
SDRecogFrameDuration
SDMicrosecTime
SDCycleTime
SDUserData
SDUniqueId
SDMemoryErrorUserData
SDErrorUserData
SDLogUserData
SDSnapTime
SDPlatformInfo
SDInitializeResultCode
SDFinalizeResultCode
SDProgressCallback
SDReallocateArrayCallback
SDMemoryErrorHandler
SDErrorHandler
SDLogHandler
SDAccumCallback
SDApplyCallback
SDFileFormat
SDFileSupportType
SDFileCompatibility
SDSaveResultCode
SDhGlobalParam
SDParamType
SDParamQueryMode
SDhLattice
SDTokenType
SDRuleParseTokenType
SDConfidence
SDLatticeInfo
SDChoiceConfidencePredictors
SDChoiceInfo
SDTokenConfidencePredictors
SDToken
SDPartialToken
SDRuleParseToken
SDLatticeLink
SDChoiceTokenConfidencePredictors
SDChoiceToken
SDLmAdaptMode
SDLmClearLoadedType
SDhWeights
SDhTopicLmSlot
SDhFactoryCorrectiveLm
SDTopicWeight
SDWeightsInfo
SDLmScoreComponentType
SDDetailedLmScore
SDInitCheckRecord
SDInitTypeSize
SDhAdapterParamSet
SDhChannelParamSet
SDhConfidenceParamSet
SDhLatticeNBestParamSet
SDhLatticePostProbParamSet
SDhPrefiltererBuildParamSet
SDhPrefiltererSearchParamSet
SDhPronGuessParamSet
SDhSausageParamSet
SDhSearchParamSet
SDhSearchCrossLayerParamSet
SDhUserDeltaParamSet
SDParamSetContainerType
SDParamSetSpec
SDParamSetInfo
SDhParamSetHolder
SDParamSetHolderInfo
SDhParamSetParam
SDPrefiltererInfo
SDhPrefilterer
SDhPrefilterResult
SDProfileStyle
SDFunctionDemangleStyle
SDhRecognizer
SDPronGuessResultCode
SDRecognizerInfo
SDWordAlignInfo
SDhSegmentResult
SDSegmentationScores
SDPartialResultScore
SDhRepro
SDReproType
SDReproInfo
SDhRule
SDRuleItemType
SDRuleOperType
SDRuleInfo
SDRuleItem
SDRuleSpec
SDhSausage
SDSausageTokenType
SDSausageInfo
SDSausageToken
SDSausageChoiceToken
SDhSigProc
SDSigProcAdaptationDataType
SDSigProcInfo
SDhState
SDStateInfo
SDStateSpec
SDStateWordSpec
SDhTransducer
SDStateTransducerSpec
SDhUser
SDUserCovarianceType
SDUserInfo
SDhUtt
SDUttType
SDEnergyStatus
SDPitchStatus
SDFrameType
SDUttTimeStamp
SDUttInfo
SDUttFrameInfo
SDhUttFile
SDUttFileFormat
SDhVoc
SDCharType
SDVocTagSetType
SDVocInfo
SDhWord
SDWordSourceType
SDWordInfo
SDWordSpec
datapackDir
locales
name
modelVersion
languageId
language_model_set
acoustic_model_set
empty_delta_voc
pg_voc
general_voc
paramset_holder
textproc_model_set.model_voc
textproc_model_set.model_svc
textproc_model_set.lexicon
textproc_model_set.static_token
textproc_model_set.static_itn
EARAudioReader.m
Could not make Opus decoder: %d
Only expecting to get 1 Opus packet at a time, not %lu
i32@?0^I8^{AudioBufferList=I[1{AudioBuffer=II^v}]}16^^{AudioStreamPacketDescription}24
Opus ecoder gave us %d bytes bytes but we really only expected %d
Could not finish Opus decoding for offline only mode: %d
v24@?0@"NSData"8^B16
<LMstate>
 ...
warning: word probs for this context sum to 
 != 1 : 
too many words per sentence
bad n-best hyp format
%g %g %lu
could not create socket: 
could not bind socket: 
could not accept connection: 
fork failed: 
client 
: connection accepted
probserver ready
: send: 
_R_E_M_O_T_E_L_M_V=2
%s %g
%s %llu %u
%s command unknown
 probabilities served
nonword 
 has nonzero probability 
read() method not implemented
write() method not implemented
Failed to allocate memory
 at time 
Repetition
Length
The feature type '
' is not supported
src-ovs-file not present in the config
tgt-ovs-file not present in the config
Registered OVS Feature
OVS file '
' has 
regex-file not present in the config
Registered Repetition Feature
Regular expression file for repetition error detection'
Language '
' not supported for regular experssion in repetition feature
Repetition feature has read the regular expressions from file 
min-trans-len-percent not present in the config
max-trans-len-percent not present in the config
fertility-file not present in the config
Registered Length Feature
Fertility file '
The fertility file is should contain exactly two fields <word  fertility>
WRITE 
EMPTY 
CANCEL 
firstPassScaled
FST File empty
Write accessed states for 
utt-detect.
utt-detect
g-fst-file
Grammar FST filename
inv-g-fst-file
Inverted Grammar FST filename (overrides uninverted)
dynamic-class-lm-emission
If true, enable dynamic classLm emission
dynamic-class-lm-tag-list
THe dynamic class tags list seperated by comma
dynamic-class-lm-smallG-file
The prior for correspoding classLm tags. Each line should contain two columns, tag and log prob
static-class-lm-tag-list
The static tags lit seperated by comma. Add this will improve dynamic emission's latency
big-g-fst-weight-list
the interpolation weights for the FST LMs, use comma to separate multiple ones
max-total-extra-weight
Max first pass weight for limiting total weight of all extra LMs in the first pass - all-app LM and possibly one more app specific LM
big-g-nnet-weight-list
the interpolation weights for the NNLMs, use comma to separate multiple ones
silence-phone-list
List of silence phones.
phone-syms-file
Phone symbol table (text format) filename
enable-state-access-recording
Record which states in each FST are accessed, to allow for efficient reordering
recog-progress-freq
Frequency(in milliseconds) of reporting recognition progress
enable-endpointing
Enable server endpointing
streaming-conf-model-file
Filename for streaming confidence model file, format <WEIGHT> <FEATURE> (one per line)
streaming-conf-normstats-file
Filename for normalization statistics file for streaming confidence, format <FEATURES-LIST>
 <MEANS-LIST>
 <Standard-Deviations-LIST>
 (each line has a comma separated value for all features)
use-endpoint-for-utt-detect
Use endpoint configuration for doing utterance detection
autocomplete-partial-result
Allow partial result to hallucinate word even if speaker hasn't finished saying it yet. For example, Pneumonoultramicroscopicsilicovolcanoconiosis is recognized after a few syllables.
compute-trailing-silence-from-lattice
True if trailing silence should be computed from the lattice, otherwise use a separate two-state machine to compute trailing silence separately (set this parameter to false if a CTC trained acoustic model is being used).
enable-eager
Enable eager
use-partial-traceback-with-final-cost
For partial results, use traceback which taking final cost into account.
If non-empty: This is a key into the top-level 'spg' dictionary of the config file, and this decoder will run a SilencePosteriorGenerator configured from the corresponding dictionary value. If empty: This decoder will not run a SilencePosteriorGenerator.
run-system-combination-after-recognition
Run system combination at the end of recognition
rejected-left-context-tokens
List of tokens that don't work with left context. The decoder will reset the left context when it encounters one of these tokens.
inter-utterance-left-context-max-size
Maximum size for inter-utterance left context
Using pre-inverted grammar: 
Using regular grammar, need to negate in memory: 
gInvFst: input label is not sorted!
State access recording is enabled. This will slow decoding, so disregard performance.
No BigG FST or NNLM specified. Hint: This is a BigLm decoder.
Could not read FST LM interpolation weight info
The number of big FST LMs and the number of weights mismatch
Could not read NN LM interpolation weight info
The number of big NN LMs and the number of weights mismatch
Language model weight must be 1 when using a single LM
 but does not match 
the auto-determined silence label 
Failed to read phone symbol table file: 
No silence phones given!
ERROR 1: Cannot compute pause counts - word boundary info is missing
ERROR 2: autocomplete-partial-result is false (default), but word-boundary-int-file is missing.
Option 1: Set autocomplete-partial-result=true. This is *usually* done only for 'srch' and 'srch'-variant (WebSearch) decoder chains. This is required if the model doesn't have word-boundary-int-file.
Option 2: Keep using autocomplete-partial-result=false, but add a word-boundary-int-file. This is *usually* done for all other tasks.
needPauseCounts=true and autocomplete-partial-result=true is not supported yet.
Eager disabled because word-boundary-int-file is missing.
VoiceTrigger phrase word "
" not found in symbol table.
VoiceTriggerPhrase not set. This could lead to wrong endpointing that clips any payload after "Hey Siri"
Decoding beam: 
Finished initializing OnlineLatticeBiglmFasterDecoder.
.recorded_state_accesses
State access file [
] exists
State access file exists - not overwriting
location-specific component not supported in OnlineLatticeBiglmFasterDecoder
some FST/NN LMs failed to load
Using 
Created new decoder
uttDetector: 
endPointer: 
Feature extraction misconfigured
RaiseToSpeak
The dyanamic classlm tag prior file name is empty
SymbolTable::ReadText: Can't open dyanamic classlm tag file 
" in base symbol table
-start
-end
Failed to create FST from partial traceback
Failed to get traceback for utterance 
Time Taken to add timestamps for first pass results: 
eagerDecisionLog
MATCH
NOMATCH
eagerOutputLog
Failed to get recognition lattice
Average number of active tokens: 
Last frame processed 
EstimatedEpTruncation
EstimatedEndPointerTrailingSilence
Server side end pointer first triggered frame 
ProcessEmittingWallMs
ProcessEmittingCpuMs
ProcessNonemittingWallMs
ProcessNonemittingCpuMs
PruneActiveTokensWallMs
PruneActiveTokensCpuMs
Recognition cancelled
Ending audio for secondary audio buffers at utterance boundary
Recognition Paused
spg batch size > 1 unexpected because spg->config.frameByFrame should be set
spgSilenceFramesCount=
 spgSilencePosterior=
 spgSilenceProbabilityRaw=
Raw pauses = [
], words = [
Server side end pointer triggered frame 
ep-features
Reporting end point status=
Since endpointer is not enabled ignoring utterance 
Utterance detector triggered 
Utterance detector force triggered because current utterance has too many frames: 
Sending recognition progress report for frameCount=
 processedAudioDurationMs=
This should only be called if endPointer exists
rt-min
Approximate minimum decoding run time factor
rt-max
Approximate maximum decoding run time factor
max-total-forward-links
Max total allocated forward links at any time.
small-lm-prune-beam-diff
Pruning threshold for small LM before checking with big LM; smaller prunes more aggresively
early-endpoint-threshold
Threshold for early endpoint detection
pause-threshold-list
Comma-separated list for pause-threshold vector, which is used for determining the pause-counts vector that is an endpointer feature. pause-counts[n] is the number of interword pauses >= pause-threshold[n]. For example, pause-threshold=[3,30,100] and pauses of 90 frames and 100 frames will result in pause-counts=[2,2,1].
pauses-as-bool
Needs pause-threshold-list. If true, then pause-threshold vector is used to create a pause-counts vector,where pause-counts[n] is a boolean for asserting interword pauses >= pause-threshold[n]. For example, pause-threshold=[3,30,100] and pause of 90 frames will result in pause-counts=[1,1,0].
Delaying the endpointer trigger decision by the given amount of time (in msec), when specified in recog request.
use-nnet
Use nnet for utterance detection if true
left-context
Use left context for utterance detection if true
hard-max-utt-length-ms
If the utterance exceeds this length, force trigger the utterance detector. Ignored if <= 0. It is named 'hard' because there is a softer 'max-utt-length' config that does not trigger right away when exceeded.
same-state-transition-probability
Same state transition probablity
acoustic-evidence-deweighting-power
Acoustic evidence deweighting power
bigGFst: input label is not sorted!
count > 0
: Could not vm_allocate 
: Could not vm_deallocate 
 bytes of 
Error in ProcessNonemitting: no surviving tokens: frame is 
Ran out of forward links in storage
PruneActiveTokensFinal: pruned tokens from 
 links from 
 pruned_tok_frames_ 
 pruned_link_toks_ 
No tokens alive at end of file
No tokens alive [doing pruning].. warning first time only for each utterance
link_extra_cost is NAN
No tokens alive [doing pruning]
: not producing lattice.
GetRawLattice: NumStates 
 NumArcs 
 NumFinal 
Cannot undo PruneActiveTokensFinal(undoable=false)
UndoPruneActiveTokensFinal: restored tokens from 
Skipping compaction final pruning because has been done
Compacted in 
 ms 
tokens 
 and forward links 
Move the partial traceback to the end of word phone
Pause error - Consecutive word-end
Pause error - Word with missing startframe or endframe
Pause error - Word-end before word-begin
Pause error - Word spans into next word
Pause error - Found more word times than words
SplitRadixComplexFft called with invalid number of points 
Error: logn is out of bounds in SRFFT
State access recording requires ExpandedFST
gender
tokenizer output
an input to the AmbiguityAnnotatorBlock has not come from a TokenizerBlock
length
received 
-token source: ["
in hypothesis 
 is translated as "
 in sense 
limiting senses to 
 before limit
 after limit
found the sense "
" in 1-best
" in hypothesis 
tokenizer input
source span: 
 alternatives
no alternatives
source match
source index
source length
target match
target index
target length
formality
explicit
lexid
these source spans: 
 are ambiguous
no source spans are ambiguous
max_label_fraction > 0
chunk_size >= 0
Acoustic encoder has fixed input size which mismatches decoder; set chunk-size to 
states.size() == 1 && states[0] == 0
No frames to decode. Force decoding EOS.
blank_states.size() == nonblank_states.size()
labels.size() == 0
nonblank_state.size() == labels.size()
blank_state.size() == labels.size()
blank_state.size() + nonblank_state.size() == labels.size()
nonblank_outputs.front()->GetNumDims() == 2
nonblank_outputs.size() == labels.size()
blank_outputs.front()->GetNumDims() == 2
blank_outputs.size() == labels.size()
blank_outputs.front()->GetDimSize(1) == nonblank_outputs.front()->GetDimSize(1)
blank_outputs.size() + nonblank_outputs.size() == labels.size()
FindOrDie
missing key 
sourceApplication
requestApplication
category
score
sourceFramework
Contextual data: configuration file does not exist
Contextual data: Unknown exception
Contextual data: quasar exception: 
Contextual data: invalid contextual named entity data
Contextual data: missing category or language for Portrait named entity
Internal unknown exception
Internal C++ exception: %s
TransitionModel::TupleToTransitionState, tuple not found.
 (incompatible tree and model?)
ComputeDerivedOfProbs(): non-self-loop prob is 
<TransitionModel>
<Tuples>
<Triples>
</Triples>
</Tuples>
<LogProbs>
</LogProbs>
</TransitionModel>
Unknown component type: 
Unknown gradient normalizaiton type: 
Unknown matrix initialization type: 
please update to formatted name 
 ASAP, you used 
Unknown component type marker: 
Unknown gradient normalization marker: 
Unknown matrix initialization marker: 
Missing type: 
<Nnet>
</Nnet>
the L2 Norm clipping value must be greater than 0, you set 
either the gradient or the gradient norm data is not initialized
the gradient clipping value must be greater than 0, you set 
the gradient data is not initialized
the factor in RMSPROP must be [0, 1], you set 
The input dimension is not divisible by the output dimension
Not implmented! Should not be called!!!
Non-matching dims! Input batch size: 
 output dim : 
Requested output for invalid unit: 
; total units = 
Relaxation factor must be positive; found: 
<RelaxFactor>
<BlockDims>
 (BlockDims)
Total block dimensions and output dimension mismatch
<DropoutRetention>
 (DropoutRetention)
<Alpha>
  frame_offsets 
<ReadVector>
<BuildVector>
</BuildVector>
 (ReadVector|BuildVector)
Error parsing <BuildVector>
Not implemented!
Unity component doesn't expect any tokens
<DuplicateStart>
<DuplicateSize>
<NumDuplicates>
 (DuplicateStart|DuplicateSize|NumDuplicates)
Requested duplication doesn't match the output and input sizes
Duplication parameters out of range
 shift_data
  shift_data_grad
<InitParam>
 (InitParam|LearnRateCoef|GradientNormType|MaxGrad)
 scale_data
  scale_data_grad
 (InitParam)
<VisibleType>
<HiddenType>
<VisibleBiasMean>
<VisibleBiasRange>
<HiddenBiasMean>
<HiddenBiasRange>
<VisibleBiasCmvnFilename>
 Typo in config?
 (VisibleType|HiddenType|VisibleBiasMean|VisibleBiasRange|HiddenBiasMean|HiddenBiasRange|ParamStddev|VisibleBiasCmvnFilename|RandomSeed)
bern
Bernoulli
gauss
Gaussian
Wrong <VisibleType>
Wrong <HiddenType>
Initializing from <VisibleBiasCmvnFilename> 
Unknown type 
Nonmatching dims, component:
pos_vis
pos_hid
neg_vis
Mismatch between pos_vis and neg_vis variances, 
danger of weight explosion. a) Reducing weights with scale 
 b) Lowering learning rate to 
 [pos_vis_std:
,neg_vis_std:
'inf' in 
'nan' in 
Forcing the variance to be non-negative! 
->0.0
<MSDims>
 (MSDims)
this implementation only models the strict recurrent component, i.e, it requests the input 
and output dimensions be the same,  you set input/out dimension to 
<Nonlinearity>
 (Nonlinearity|ParamStddev|BiasMean|BiasRange|LearnRateCoef|BiasLearnRateCoef|MaxNorm|RandomSeed|MaxGrad|InitTransformType|GradientNormType)
 bias
  linearity_grad is uninitialized
  bias_grad is uninitialized
Unknown nonlinearity type: 
 filters: 
 bias: 
<PatchDim>
<PatchStride>
 (ParamStddev|BiasMean|BiasRange|PatchDim|PatchStep|PatchStride|MaxNorm|GradientNormType|MaxGrad|RandomSeed)
num_splice 
num_patches 
filter_dim 
num_filters 
<PoolStride>
<Scale>
 (PoolSize|PoolStep|PoolStride|Scale)
 (PoolSize|PoolStep|PoolStride)
<PoolXLen>
<PoolYLen>
<PoolXStep>
<PoolYStep>
 (FmapXLen|FmapYLen|PoolXLen|PoolYLen|PoolXStep|PoolYStep)
num_fmaps 
Invalid component parameters
<SpliceLength>
<RowStride>
<TimeLength>
nested_network {
nested_gradient {
<NestedNnetFilename>
<NestedNnetProto>
<LearnRateFactor>
  (offset,weights) : 
  lr-coef 
  (offset,weights_grad) : 
<FeatureDim>
<CentralOffset>
<PoolWeight>
<Normalize>
 (FeatureDim|CentralOffset <vec>|PoolSize <vec>|LearnRateCoef|Normalize)
Initializing from pool-weight vector
<FrameOffset>
<FrameWeight>
the multi subbatch version for this class is not implemented yet
the ParallelComponent has history size 
 , but the input history data has dimension 
the network has history size 
</NestedNnetFilename>
</NestedNnetProto>
, typo in config?
 (NestedNnetFilename|NestedNnetProto)
<NestedNnetCount>
<NestedNnet>
</ParallelComponent>
Two different learning rates: 
nested_network #
nested_gradient #
nested_propagate #
nested_backpropagate #
<NumComponents>
The input dimension is not divisible by the number of components
The output dimension does not match the dimension of individual component
<ComponentWeight>
</InterpolationComponent>
 CompressedWordVec table
 WordVec table
 we don't save intermediate gradient
<FillerSymbolId>
 (ParamStddev|LearnRateCoef|VocabSize|RandomSeed|InitTransformType|GradientNormType|MaxGrad)
invalid vocabulary size 
it doesn't make sense to initialize the word vec as an identify matrix
RMSPROP is not implemented in word embedding yet
not implemented
, bias-lr-coef 
 (ParamStddev|BiasMean|BiasRange|LearnRateCoef|BiasLearnRateCoef|InitTransformType|RandomSeed|GradientNormType|MaxGrad)
it does not make sense to do RMSPROP in this component
 CompressedWordTrans table
<AffineTransform>
<LinearTransform>
<Quantized8BitLinearTransform>
<Quantized16BitLinearTransform>
<SharedNceComponent>
<ConvolutionalComponent>
<ConvolutionalMaxPoolingComponent>
<Quantized8BitConvolutionalMaxPoolingComponent>
<Quantized16BitConvolutionalMaxPoolingComponent>
<Convolutional2DComponent>
<Quantized8BitConvolutional2DComponent>
<Quantized16BitConvolutional2DComponent>
<LstmComponent>
<Quantized8BitLstmComponent>
<Quantized16BitLstmComponent>
<GatedRecurrentUnit>
<SimplerSimpleRecurrentUnit>
<Recurrent>
<BidirectionalRecurrentComponent>
<WordVecComponent>
<FofeWordVecComponent>
<WordMultiVecComponent>
<CompressedWordMultiVecComponent>
<CompressedWordVecComponent>
<FixedAttentionComponent>
<MovingAttentionComponent>
<GlobalAttentionComponent>
<GlobalRecurrentAttention>
<ScaledDotAttention>
<MultiHeadAttention>
<SupervisedMultiHeadAttention>
<SelfAttention>
<AverageAttention>
<LayerNorm>
<Softmax>
<LogSoftmax>
<BlockSoftmax>
<MultiSoftmax>
<RelaxedSoftmax>
<Sigmoid>
<Tanh>
<Dropout>
<Maxout>
<Rectified>
<ExponentialLinear>
<ScaledExponentialLinear>
<PNorm>
<Rbm>
<Splice>
<Desplice>
<Copy>
<CnnRearrangeComponent>
<PaddingComponent>
<Padding2DComponent>
<AddShift>
<Rescale>
<QuantizedAffineTransform>
<Quantized16BitAffineTransform>
<NormalizeComponent>
<KlHmm>
<AveragePoolingComponent>
<AveragePooling2DComponent>
<MaxPoolingComponent>
<MaxPooling2DComponent>
<SentenceAveragingComponent>
<FramePoolingComponent>
<ParallelComponent>
<Duplicate>
<Identity>
<TemporalMaxPooling>
<InterpolationComponent>
<CompressedWordTransComponent>
<VectorwiseQuantized8BitAffineTransform>
<VectorwiseQuantized16BitAffineTransform>
ClipValue
ClipL2Norm
Rmsprop
Identity
Uniform
Gauss
  linearity is vectorwise quantized
sentencepiece encoder input
sentencepiece encoder output
sentencepiece decoder input
sentencepiece decoder output
subword confidences
decode
decode-api
decode-space
Unknown sentence piece action: 
SentencePiece error while loading file '
Dropping confidence scores in sentence piece encoding
firstleg 
Inconsistent sentencepiece decoding length, expected 
 got 
Inconsistent token sequence: previous end = 
, current start = 
Config Version is not high enough for index rule denumeration
Enumeration rules not configured
The default tag for denumeration
Config Version is not high enough for denumeration
LmeWordTagger not used
Unsupported number of lme-word-taggers
Unsupported lme-word-tagger
lme-word-tagger
index-rule-tagger
rules
index
default-tag
Invalid string: %@
Failed to perform UTF-8 encoding on string: 
Topological sorting of state-level lattice failed (probably your lexicon has empty words or your LM has epsilon cycles; this  is a bad idea.)
Minimizing lattice with self-loops (lattices should not have self-loops)
Largest equivalence group (using hash) is 
, minimization might be slow.
Removing 
 states.
warning: maximum tagged index lowered to 
maximum number of tagged words (
) exceeded
maximum number of tags (
%s%c%s
%c%s
QuasarC
[QSR] FATAL %s
[QSR] ERROR %s
[QSR] WARN %s
[QSR] PRODINFO %s
[QSR] INFO %s
[QSR] DEBUG %s
[QSR] TRACE %s
Token(
en-like
zh-like
algorithm
Algorithm name. Possible values: en-like, zh-like
Invalid algorithm
Index error: [
-derived
Tag with multiple words: "
" for "
\contact-first-phonetic
\contact-last-phonetic
\contact-first-derived
\contact-last-derived
syms
<sigma>
<rho>
<phi>
lattice-
wmapper-
rpathcounter-
mapper-cd-
 symbol '
' missing from target symbol table.
Target symbol table missing: 
 input symbols.
 output symbols.
Push: pushing type is set to 0: 
pushing neither labels nor weights.
ShortestDistance: Weight needs to be right distributive: 
ShortestDistance: first_path option disallowed when 
Weight does not have the path property: 
Reweight: Reweighting to the final states requires 
Weight to be right distributive: 
Reweight: Reweighting to the initial state requires 
Weight to be left distributive: 
right_gallic_
right_gallic
left_gallic
ArcMapFst: non-zero arc labels for superfinal arc
StringWeight::Divide: only right division is defined 
for the right string semiring
factor_weight
FactorWeightFst: factor mode is set to 0: 
factoring neither arc weights nor final weights.
FromGallicMapper: unrepresentable weight: 
 for arc with ilabel = 
, olabel = 
, nextstate = 
CompositeWeightWriter: 
FLAGS_fst_weight_separator.size() is not equal to 1
FLAGS_fst_weight_parentheses.size() is not equal to 2
Epsilon
BadString
SigmaMatcher: bad match type
SigmaMatcher: 0 cannot be used as sigma_label
SigmaMatcher:: bad match type: 
SigmaMatcher::Find: bad label (sigma)
RhoMatcher: bad match type
RhoMatcher: 0 cannot be used as rho_label
RhoMatcher:: bad match type: 
RhoMatcher::Find: bad label (rho)
resize overflow
sparsehash: FATAL ERROR: failed to reallocate %lu elements for ptr %p
insert overflow
DeterminizeFst: 
a state table can not be passed with transducer input
StringWeight::Divide: 
only explicit left or right division is defined 
for the 
 semiring
restricted_string
StringWeight::Plus: unequal arguments 
(non-functional FST?)
 w1 = 
 w2 = 
EmptySet
BadSet
gallic_
StringWeight::Divide: only left division is defined 
for the left string semiring
_from_gallic
GallicToNewSymbolMapper: unrepresentable weight: 
UNKNOWN
INVALID
RAW_PHRASE_COUNTS
PROCESSED_PHRASE_COUNTS
PROCESSED_NGRAM_COUNTS
DECODING_READY
number of start/end LME class tags doesn't match: 
cannot find 
 in the vocab file
 LME classes, their IDs are not contiguous
seeva-step
seeva inference encoder graph file
seeva inference decoder graph file
num-encoder-states
number of encoder states
num-decoder-states
number of decoder states
align-state-list
alignment state indices in the decoder states
vocab-file
the vocab file for the model output token
vocab-is-binary
vocab file is binary
model-format-version
model format version
feature transform file
lme-start-tag-list
a list of LME start tag
lme-end-tag-list
a list of LME end tag
speller-fst-file
the speller FST file
Inverted small grammar FST filename
lm-unknown-word
the unknown word (OOV) in the LM
the lm beam should be no less than the model beam, 
loaded an inverted G, make sure the speller FST is weighted
do not have an inverted G, make sure the speller FST is unweighted
spellerFst: input label is not sorted
cannot find the OOV word 
 in the symbol table
Finished initializing OnlineSeevaStepBigLmDecoder
/cpu:0
lme-score-scale
scale the LME FST score when LME is active
nonlme-score-scale
scale the nonLME arc score when LME is active.
lm-score-scale
scale external LM score when available
lm-miss-penalty
penalty for missing LM arc
lm-miss-final-penalty
penalty for missing LM arc in final
lm-beam
use this beam value for the external LM
lme-beam
use this beam value for the LME arcs
length-penalty-lm
the length penalty value when using external LM
Custom pronunciation file is malformed: 
lexicon
Custom pronunciation file contained no lexicon field
lexeme
grapheme
phoneme
alias
Custom pronunciation file was missing fields
 (contains no phonemes)
 (contains no graphemes)
read error
void boost::property_tree::xml_parser::read_xml_internal(std::basic_istream<typename Ptree::key_type::value_type> &, Ptree &, int, const std::string &) [Ptree = boost::property_tree::basic_ptree<std::string, std::string>]
/AppleInternal/Library/BuildRoots/b958ad6d-2c13-11ed-a8d5-b25c5e9b9057/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator16.1.Internal.sdk/usr/local/include/boost/property_tree/detail/xml_parser_read_rapidxml.hpp
expected <
unexpected end of data
expected element name
expected >
expected attribute name
expected =
expected ' or "
expected ;
invalid numeric character entity
<xmlattr>
<xmltext>
<xmlcomment>
online-las-beam-search
0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!"#$%&'()*+,-./:;<=>?@[\]^_`{|}~
dictation-languages
current-dictation-language
was-language-toggled
multilingual-keyboard-languages
keyboard-convo-language-priors
keyboard-global-language-priors
previous-message-language
global-last-keyboard-used
dictation-language-priors
bitmap-color
The value of the 
 in region 
 has to be 
 but is 
 has to be a positive integer but is 
do-not-translate
Metainfo does not contain any alignment spans
error parsing Json >
Metainfo does not contain any alignment projections
 ||| 
error parsing Json <
Not caching word with too many prons: "
" has 
 prons
Skipping illegal word: "
Encoding should be either QsrText or NotEncoded
Skipping illegal word.
: nWords = 
: orthography = 
: nProns = 
: pron = 
Ignoring corrupted prons: orthography = 
, nProns = 
Duplicate key is being added to enumerationTypeMap with key=
Invalid write version choice: 
, it is now set to: 
LME STREAM WRITE 
: About to write FSTs
: templateName = 
: <FST>
: done.
formatVersion=
Failed to read LmeData stream. Incorrect version: 
Error reading LmeData stream: 
LME STREAM DUMP [Body]
: g2pModelVersion = 
: symTableFirstKey = 
: symTableLastKey = 
: fstSize = 
: phoneSetVersion = 
Expected asset path does not match LME Data's asset path. LME Data should be regenerated. Quitting deserialization early.
expected assetPath=
deserialized assetPath=
LME STREAM DUMP [Pron Cache]
: About to read FSTs
Failed to deserialize symbol table from LME data stream. Quitting deserialization early.
: <symTable:
 symbols>
LME memory_overhead 
 fsts 
LME STREAM DUMP DONE 
LME data stream successfully read with 
 symbols; 
) ~ "
LME STREAM DUMP         
LME data stream version is old, but still supported. Current write version is 
 and stream version is 
tokenMapToStream dump, key=
 value=
: nMapSize = 
: key = 
 value = 
basicTypeMapToStream dump, key=
Matrix::Read, size mismatch 
Can not map into the wrong matrix data type
: Seeking failed
: Reading whole matrix failed
: Reading a matrix row failed
: Seek for padding 
: Expected "[", got EOF
: Expected "[", got "
Matrix has inconsistent #cols: 
 vs.
 (processing row
Failed to read matrix from stream.  
Wrong sized arguments
Wrong size of arguments.
index item is bigger than the voc size 
index 
 is too big for matrix that has rows = 
Failed to write matrix to stream: stream not good
Failed to write matrix to stream
 [ ]
AddConfigOverride() can only be called before init()
speaker-code-training
speaker-code-training.
mux.
embedded-mlock
Initialized SpeechRecognizer with config 
getActiveConfiguration called before init.
setActiveConfiguration called before init.
Cannot call setActiveConfiguration while recognition is running.
SpeechRecognizer must be in initialized state before you call runAsync(). 
Hint: Make sure you call waitForAsyncRecogToFinish() before calling runAsync() again.
Utterance concatenation should only be used with utterance detection
No primary buffer was set! 
Hint: If multiple decoder chains are active, one of them should do system combination.
Running runSyncAndMarkEndOfRun() in separate thread
Cancelling recognition
This function can only be called in Recognizing or Cancelling state
finalResultTokens
finalResultTokensV2
sessionId
userId
isFinal
cache
geoLocationStatusUponRunAsync
Symbol table list passed to runSync() must start empty
Invalid recognition request parameters
Speaker code training is enabled, going to cache features and labels as training data
Created OnlineFeatInputItf chain
Frontend and SPG frame durations differ: 
End of recognition.
Pause/Resume: processedUtteranceEndedAfterPause: 
Pause/Resume: Utterance generated after pause call
Pause/Resume: Utterance generated after resume call
Start recognition of a new utterance...
Ran out of forward link storage during decode: 
Ran out of token storage during decode: 
Reporting empty result due to thrown exception during decode
far_field
SpeechRecognizer must be initialized before calling runSync()
Symbol table list passed to runSyncUtterance() must start empty
uttNum
jsonConfigFilePath
taskType
deviceId
recognizerComponents
farField
enableWhisperDetection
numLmeDataStreams
utteranceConcatenation
epExtraDelay
InputOrigin
highPriority
LME DataStreams=
 samplingRate=
 taskType=
 deviceId=
 enableWhisperDetection=
 endpointerExtraDelay=
 inputOrigin=
 highPriority=
You have provided a reference transcript, which will trigger error-blaming (if specified in 
the config file). This is an EXPERIMENTAL feature that uses lots of memory and incurs lots of 
latency!
runSync:initTime
There is no decoder which affects recognition, this must be a configuration error.
eagerRequested
Eager disabled: not supported by first-pass decoder: 
Eager disabled: silence posterior required but not available: 
Eager disabled: not supported by second-pass decoder: 
eagerUsed
Waiting for first valid feature frame of first utterance...
uttDetectAbort
Rejected
Pause/Resume: Ignoring any further processing of the utterance with uttStartFrame=
Recognition is final and successful, trigger training
Recognition is final but not successful, skip training
geoLocationStatusUponRequestComplete
recognitionStatus
Training is not enabled, skip training
Result stream does not exist, skip training.
Average confidence: 
 is below threshold: 
, skip training
Feature buffer is null or reversed pdf is empty, skip training.
Populating training data, original feature size: 
, alignment size: 
Reaches the end of labels
Training data is populated and shuffled, aligned data size: 
, silence frame count: 
Training is not enabled, not concatenating labels.
Recognition is not final, concatenating alignments, feature buffer size: 
, label buffer size: 
, pdfs size: 
, num frames: 
Label concatenation is completed, label buffer size: 
audioReadTime
featureComputeTime
whisperScore
whisperDetected
utteranceLength
audioEndTime
utteranceEndTime
timeElapsedSinceRunAsyncCall
timeElapsedSinceRunSyncCall
recognizer-components
DidConfNetCombination
ConfNetWaitTimeMs
ConfNetworkCombinedNbestSourceID
ConfNetworkCombinerStartTimeMs
LastWordClipped
WordAligned
Write results got a NULL lattice
NullLattice
Recognition is going to fail because of NULL lattice. Padding labels to align with features
PartialResultsAvgLagMs
PartialResultsToggleCount
FasterPartialResultsAvgLagMs
FasterPartialResultsToggleCount
Shortest path cost: 
lmeStatus
jitLmeUsed
aotLmeUsed
Matched trigger phrase: 
, with index: 
Lattice was not NULL, but failed to generate any choices
NoChoices
RecogThreadCpuTimeMs
EosToPreItnMs
lm_interp_weights
Pause called but recognizer in state:
, do nothing..
Pause: utterance detection is disabled or utterance concatenation is enabled, do nothing.. 
Pause: pausing the recognizer.
Resume: The recognizer was not paused, so nothing to resume, ignoring the call.
Resume: utterance detection is disabled or utterance concatenation is enabled, do nothing.. 
Resume: resuming the recognizer.
Unable to json at path lme-create from json
word-syms-map-file
Unable to read symbol table from json at path lme-create.word-syms-map-file
Initialized symbol table
training-nnet-file
Training neural network path
max-feature-cache-size
Max feature cache size for training
learning-rate
Learning rate of the training
training-nnet-version
Training neural network version
generic-speaker-code
Generic speaker code
initialize-option
Options to initialize training speaker code, 1 is generic speaker code, 2 is all-zeros
recognition-interval
The threshold to apply trained speaker code in recognition
supported-tasks
Supported tasks for training. Only the configured tasks will run training at the end of recognition
The interval which will be used for updating the speaker code for training, default is 64
Training mini batch size, default is 1
enable-continuous-training
The flag to enable continuous training, default is false
initial-size
Speaker code dimension. As speaker code is one-dimentional vector, it's also the number of rows
If average confidence of all tokens is below the threshold, the utterance will be dropped, default is 0
silence-frame-ratio
The ratio of silence frames, num(silence_frame) = min(ratio * num(valid_speech_frame), num(silence_frame)), default is 0
update-inference
If it is true, the inference speaker code used in recognition will be updated in training, otherwise inference speaker code is always the generic one, default is false
shared-tags
sharedTags: 
Text sanitizer initialization failed 
\room-first
\room-middle
\room-last
\house-first
\house-middle
\house-last
\zone-first
\zone-middle
\zone-last
\group-first
\group-middle
\group-last
\device-first
\device-middle
\device-last
\scene-first
\scene-middle
\scene-last
\deviceNames-first
\accessory-first
\artist-first
\appMusicArtistName-first
\custom_words-first
\playlist-first
\podcastTitle-first
\appPlaylistTitle-first
\appAudiobookTitle-first
\appShowTitle-first
thread constructor failed
unique_lock::unlock: not locked
unique_lock::lock: references null mutex
unique_lock::lock: already locked
LibLM encountered a fatal error.
TRACE
tmpdir.XXXXXX
Bad path
Bad stream
openProtected() failed: 
fsync() failed: 
close() failed: 
rename() failed: 
FTM second pass decoder chain failed
FTM chain must have at least two elements
FTM Decoder must be derived from OnlineLatticeBiglmFasterDecoder
Second pass decoders must support eager
ftm-combination
ftm-chain
Decoder chain to select for LRNN FTM computation.
overwrite
Overwrite the main FTM score with the FTM score from the subchain
Invalid SilencePosteriorGeneratorConfig name "
Invalid recognizer specifier "
", must have 3 components
Parallel loading is enabled
SpeechRecognizerModelLoader: (ANE) Model will not be unloaded
spg.
 references spg that does not exist: 
setActiveConfiguration(
), loaded: 
 frontends, 
 decodables, 
 decoder chains, 
 SPG configs.
Value 
 not found in active configuration.
rule-config-file
rule-type
Rule config file does not exist or it is a directory. File path = 
Read rule config file = 
Failed to parse config file = 
rule: 
 is not valid in file with locale: 
clone-from field is invalid. Rule config file path=
clone-from
pre-alt-gen
post-alt-gen
post-combine
alt-gen
whole-string-rules
We do not support step = 
Please check config file for regex rule, step name = 
Skip empty input text = 
Failed to generate enumeration in step = 
Enumeration is calculated already.
more than 
 fields per line
 words in hyp
(%lf)
bad Decipher score: 
badly formatted hyp
 tokens in hyp
bad acoustic score: 
bad LM score: 
bad word count: 
warning: hyp contains zero prob words: 
warning: hyp contains OOV words: 
failed to open database file
connected to database
SELECT column, dictionary, max_length FROM decompress
No decompression info found for phrasebook 
 error: 
SELECT output, length(output), metadata, length(metadata) FROM phrasebook WHERE input=? ORDER BY rowid LIMIT ?
SQLITE Querying error: 
Could not prepare SQLite Statement
1.2.11
SQLite Binding error: 
metadata
Unknown column provided for decompression.
Could not open decoding-graph FST 
Reading FST: error reading FST header.
FST with arc type 
 not supported.
const
Reading FST: unsupported hammer FST type: 
Error reading FST (after reading header).
Hammer didn't change any text. Therefore returning the original input.
Number of outputs (n) cannot be less than 1.
, start silence: 
Empty tokenName
Pre-text-proc Choice[
Post-text-proc Choice[
Pre-sanitization: 
Post-sanitization Choice[
modelFile doesn't exist, or it's a directory: 
Key not found: 
 configured key='
' prefix=
Empty post-itn-hammer rule
, jsonConfigPath=
 configured
itn2 configured key='
ignogre itn2 config of 
, what we are looking for is 
Failed to configure itn2
Ignore unknown node text-proc.
Key does not match 'locale' or 'locale::keyboard': 
Locale cannot include leading/trailing whitespace: 
Keyboard cannot include leading/trailing whitespace: 
Locale with separator '
' not supported: 
Keyboard with separator '
Locale=
 should only be used with keyboard=*
Keyboard=* is reserved for internal use
There are itn2 models, but cannot find one for locale=
empty ITN input tokens
empty sanitizer input tokens
empty postItnHammer input tokens
locale=
 keyboard="
 postItnHammer="
 emojiHammer="
emoji-hammer
default
sanitizer
itn2
lattice-proc
spokenemoji|
ConstFst::Read: Alignment failed: 
ConstFst::Read: Read failed: 
Could not align file during write after header
Could not align file during write after writing states
ConstFst Write write failed: 
Inconsistent number of arcs observed during write
help
[]~#^_-+=:.,/
'\''
"`$\
Invalid parameters supplied to OnlineLdaInput
Invalid parameters supplied to OnlineTransformInput
end_pad_ > 0
input.NumRows() <= strict_batch_size + total_batch_context_
NaN in features
inf in features
Batch 
Must use penultimate-compatible AM with silence nnet
Frames consumed by model (
) does not match frames added by batchwise splicing (
). Hint: Are batch-left-context and batch-right-context correct for this model?
orig_input_size + frames_padded - total_batch_context_ == output->NumRows()
output->NumRows() == sil_post->NumRows()
NaN in NNet output
inf in NNet output
input.NumRows() <= strict_batch_size_
There is extra input, rows=
, cols=
extra_input_.NumRows() == 1 && feats.NumRows() >= 1
orig_input_size + frames_padded == output->NumRows()
(!has_sil_post_ && next_sil_post.NumRows() == 0) || (has_sil_post_ && next_features.NumRows() == next_sil_post.NumRows())
Unexpected point reached in code: 
possibly you are skipping frames?
Attempting to get a discarded frame.
Attempt get frame without check its validity.
<blk>
keyword-spotting
The threshold for the keyword score
frame-offset
frame offset
do-viterbi
apply viterbi for keyword detection
tokens-file
symbole table file
keyword-list-file
list of keywords and their corresponding tokens sequence
Number of frames that get decoded in one go
do-batch-reset
Reset scores after each batch result
do-top-result-only
Only return the best keyword score
do-moving-avg
Performs a moving average of the scores
moving-avg-window-size
Set the window size for the moving average
Number of labels: 
Blank label "
Blank label index: 
Invalid keyword-phrase line
Adding keyword: 
Symbol "
Number of keywords: 
Error: Both, Viterbi and moving average decoding enabled, select only one
Moving average window size: 
keyword mismatch 
Error: no utterance features were provided
No keywords found.
Start of batches
unmatched  posterior matrix dimension and number of symbols
empty posterior matrix
About to process 
 frames in batch
KWD 
End of batch
End of batches
keyword detected
no keywords detected
keyword search finished with 
 detected hypothesis.
Missing voicing regions in audio analytics
Voiced region start: 
 end:
Voicing threshold=
 mean=
 stddev=
the base lexicon is empty
the base symbol table is empty
the number of templates in the user data is zero
insufficient number of word disambiguation symbols in the graph, 
 . deleting offending pronunciations.
number of word symbols before LME: 
User-provided LME symbol table clashes with base symbol table.
number of word symbols after LME: 
LME: number of disambiguation symbols is 
the optional silence 
 is not defined in the symbol table
the word boundary string can only have non-space characters, you set it (
number of prons, pre/post-compound:
 #comp_words:
can not find symbol 
 in the input symbol table
LME: no available user data for 
-th template
LME: detected a zero frequency - ignoring this word
not in the compound mode, and the number of words in this entry is more than 1, use CreateFst() instead
remove excessive homophone prons without removing words, rebuild the FST now
has to remove 
 words, rebuild the FST now
LME: spent 
 seconds on creating the compound lexicon for 
 items
the output symtable is not empty
 before calling createOnlineFeInput().
subsample
stride
Take every n'th feature, for this value of stride(with negative value, repeats each feature n times)
' cannot occur at the first stage of feature-extract
Building FeatureExtractor 
cmvn
fbank
fbankwithpitch
mfcc
nnet-forward
nnet-forward-skip
splice
transform
cache-input
compute-ahead-input
fbank-with-audio-analytics
append
Unknown feature-extract type "
Finished reading matrix file 
Minumum CMN window used at start of decoding (adds latency only at start). 
init-cmvn-stats-file
Stats File for warm-start online CMVN
prior-count
number of frames used from prior CMVN stats file
buffer-output
Use OnlineBufferingInput
cmvn-window
Window in frames for running average CMVN computation
min-cmvn-window
Minumum CMVN window used at start of decoding (adds latency only at start). 
low-watermark
Low watermark (in number of frames) for audio buffer read. Ignored if <= 0.
resample-freq
The frequency to resample to.
resample-cutoff-hz
The cutoff for the filter for resampling the audio
resample-num-zeros
Controls sharpness of filter.
' can only occur at the first stage of feature-extract
analytics-sample-frequency
analytics-frame-length
analytics-frame-shift
analytics-preemphasis-coefficient
Coefficient for use in signal preemphasis (deprecated)
min-f0
min. F0 to search for (Hz)
max-f0
max. F0 to search for (Hz)
soft-min-f0
Minimum f0, applied in soft way, must not exceed min-f0
penalty-factor
cost factor for FO change.
lowpass-cutoff
cutoff frequency for LowPass filter (Hz) 
resample-frequency
Frequency that we down-sample the signal to. Must be more than twice lowpass-cutoff
delta-pitch
Smallest relative change in pitch that our algorithm measures
nccf-ballast
Increasing this factor reduces NCCF for quiet frames
nccf-ballast-online
This is useful mainly for debug; it affects how the NCCF ballast is computed.
lowpass-filter-width
Integer that determines filter width of lowpass filter, more gives sharper filter
upsample-filter-width
Integer that determines filter width when upsampling NCCF
frames-per-chunk
Only relevant for offline pitch extraction (e.g. compute-kaldi-pitch-feats), you can set it to a small nonzero value, such as 10, for better feature compatibility with online decoding (affects energy normalization in the algorithm)
simulate-first-pass-online
If true, compute-kaldi-pitch-feats will output features that correspond to what an online decoder would see in the first pass of decoding-- not the final version of the features, which is the default.  Relevant if --frames-per-chunk > 0
recompute-frame
Only relevant for online pitch extraction, or for compatibility with online pitch extraction.  A non-critical parameter; the frame at which we recompute some of the forward pointers, after revising our estimate of the signal energy.  Relevant if--frames-per-chunk > 0
max-frames-latency
Maximum number of frames of latency that we allow pitch tracking to introduce into the feature processing (affects output only if --frames-per-chunk > 0 and --simulate-first-pass-online=true
analytics-snip-edges
If this is set to false, the incomplete frames near the ending edge won't be snipped, so that the number of frames is the file size divided by the frame-shift. This makes different types of features give the same number of frames.
pitch-viterbi-window
Number of frames over which we want to run viterbi for computing pitch.
lda-matrix-file
LDA matrix filename
Number of frames of left context
right-context
Number of frames of right context
no-softmax
No softmax on MLP output (or remove it if found), the pre-softmax activations will be used as log-likelihoods, log-priors will be subtracted
apply-log
Transform MLP output to logscale
batch-left-context
Number of frames of left context to prepend to the batch as extra rows
batch-right-context
Number of frames of right context to append to the batch as extra rows
strict-batch-size
Batch size applied just for this extractor. Ignored if <= 0. Unlike feature-read.batch-size, which is just a hint, this batch size is so strict that even the last batch will be padded to exactly this size with copies of the last frame if the last batch is too small. (The padding is removed from the output). Excludes context frames (actual batch size is strict-batch-size + batch-left-context + batch-right-context).
zero-pad
Zero pad the features, instead of last frame padding, to reach the strict-batch-size requirementvalid only when strict-batch-size is also specified
append-pad-info
Append the pad info as an additional row in the input matrixThe first element of the appended row is the number of padded rows, which excludes this extra appended rowvalid only when strict-batch-size is also specified
append-context-size
Append the context matrix along with the input. Ignored if <= 0Add the specified amount of rows as context to the input features and one additional row which has the batch number. The context is obtained from last N rows of output of the previous inference.Context is ignored by the model for the first inference i.e. batch num is 0valid only when strict-batch-size is also specified
strict-batch-sizes
Defines an array of 3 sizes - [ModelInterfaceSize, FirstBatchSize, SubsequentBatchSize]ModelInterfaceSize: defines the size of input expected by the modelFirstBatchSize: defines the batch size used for 1st inference, will be padded with zeros                 if less than than ModelInterfaceSizeSubsequentBatchSize: defines the batch size used for the rest of the inferenences, will be                     padded with zeros if less than than ModelInterfaceSize(The padding is removed from the output)This feature is added support streaming Acoustic FTM and Hey Siri checker using the same model
cannot set both strict-batch-size & strict-batch-sizes
strict-batch-sizes needs 3 sizes
Model input size must be greater than batch sizes
Nonsense option combination : --apply-log=true and --no-softmax=true
Option --class-frame-counts has to be used together with 
--no-softmax or --apply-log
Used --apply-log=true, but nnet 
 does not have <softmax> as last component!
Batch size applied just for this extractor. Ignored if <= 0. Unlike feature-read.batch-size, which is just a hint, this batch size is so strict that even the last batch will be padded to exactly this size with copies of the last frame if the last batch is too small. (The padding is removed from the output). Includes skipped frames (neural network sees `ceil(strict-batch-size / (1 + skip-frames))` frames at a time.
default-speaker-code
If the nnet requires speaker code as input and speaker code is not set by request data, the default one will be used as a backup
Set inference speaker code to: 
Set inference speaker code to be default: 
File for any linear (or affine) feature transformation
cache-data
If true, cache all data (e.g. fbank feats)
cache-analytics
If true, cache all analytics data
max-queued-frames
Max number of frames to compute ahead. Use this to limit memory. Note this is not a strict limit: If we are at or above the limit, we will wait to fetch the next batch. If we are under the limit, we will fetch the next batch, which may cause us to exceed the limit. Values <= 0: no limit Value = 1 (default): compute ahead only 1 batch
Creating ComputeAheadFeatInput with maxQueuedFrames=
delta-order
Order of delta computation
delta-window
Parameter controlling window for delta computation (actual window size for each delta order is 1 + 2*delta-window-size)
Add an extra dimension with energy to the FBANK output.
Floor on energy (absolute, not relative) in FBANK computation
If true, put energy last.  Warning: not sufficient to get HTK compatible features (need to change other parameters).
use-log-fbank
If true, produce log-filterbank, else produce linear.
cache-energy
If true, cache energy values.
Frequency that we down-sample the signal to.  Must be more than twice lowpass-cutoff
pitch-scale
Scaling factor for the final normalized log-pitch value
pov-scale
Scaling factor for final POV (probability of voicing) feature
pov-offset
This can be used to add an offset to the POV feature. Intended for use in online decoding as a substitute for  CMN.
delta-pitch-scale
Term to scale the final delta log-pitch feature
delta2-pitch-scale
Term to scale the final 2nd-order log-pitch feature
delta-pitch-noise-stddev
Standard deviation for noise we add to the delta log-pitch (before scaling); should be about the same as delta-pitch option to pitch creation.  The purpose is to get rid of peaks in the delta-pitch caused by discretization of pitch values.
normalization-left-context
Left-context (in frames) for moving window normalization
normalization-right-context
Right-context (in frames) for moving window normalization
Number of frames on each side of central frame, to use for delta window.
delay
Number of frames by which the pitch information is delayed.
add-pov-feature
If true, the warped NCCF is added to output features
add-normalized-log-pitch
If true, the log-pitch with POV-weighted mean subtraction over 1.5 second window is added to output features
add-delta-pitch
If true, time derivative of log-pitch is added to output features
add-delta2-pitch
If true, 2nd order time derivative of log-pitch is added to output features
add-raw-log-pitch
If true, log(pitch) is added to output features
use-pitch
Add extra dimensions for pitch to the FBANK output.
add-pitch-period
If true, pitch period is added to output features
add-pov
If true, probability of voicing is added to output features
add-max-amplitude
If true, max amplitude is added to output features
No feature vectors requested?!
strict-batch-sizes supports only 3 sizes
Model input size must be greater than other batch sizes in strict-batch-sizes
append-pad-info cannot be set if strict-batch-size is <= 0
zero-pad cannot be set if strict-batch-size is <= 0
append-context-size cannot be set if strict-batch-size is <= 0
supported by OnlineNnetForwardInput. Use a separate splice 
OnlineNnetForwardInput. Use a separate splice operation to 
Invalid partition id 
 has to be in range [0,
Requested word position is out of bounds 
Supplied word position index 
, is out of bounds in ErrorRegion, should be in range [0,
Algorithmic error, do not know what to do with level 
Supplied region_id is out of bound, have only 
 regions, asked for 
--------------------------------------------
From frame 
LM scores:
Hyp 
AM scores: 
Ref: 
Hyp: 
Ref Models:
Hyp Models:
Ref Phones:
Hyp Phones:
Ref Scores:
Hyp Scores:
           
Supplied frame is not part of given transition ids
fst-type
fst format (default: squeezed_acceptor)
lm-personalize.model
fst-basename
basename of FST file (default: bigG)
Unsupported FST type: 
ngram-count-flags
SRILM ngram-count flags
arpa-lm-output-file-name
output arpa language model (relative) file name (default: "")
ngram-counts-output-file-name
output ngram counts file name (default: "")
-text
-vocab
ngram-count-flags is not allowed to contain 
write
ngram-count-flags is not allowed to write flag: 
weight-optimization-strategy
Weight optimization strategy
ngram-order
N-gram order for interpolation
uniform
Unknown weight optimization strategy 
ngram-adapt-flags
SRILM flags for adaptation
arpa-lm-input-file
arpa language model to be adapted - (relative) file name (default: "")
-read-text
-read-counts
-read-dev
-write-lm
ngram-adapt-flags is not allowed to contain 
ngram-adapt-flags is not allowed to write flag: 
There are no unseen words in vocab
Encountered more than 1 arc with <unseen>
No arc with <unseen>
numArcsAdded 
 numArcsToAdd 
Incorrect number of arcs added. This is a bug.
Unsupported LmBuildConfig type
arpa
ngramCountCtx is null
ARPA LM write error
/lm.arpa
Config not set to write ARPA file
other input types not yet implemented
ngram-count failed with status: 
ngram-count failed to generate lm
Built ngram with order 
ARPA vocabulary file not set. Hint: check lm-personalize.data.train-arpa-lm-file
Input ARPA file doesn't match LmData. Hint: check lm-personalize.data.train-arpa-lm-file
residual-adapt
residual-adapt failed with status: 
residual-adapt failed to generate lm
residual-adapt failed to determine eta
residual-adapt: eta: 
Ngram counts can only be generated from plain text or phrase counts
Arpa2Fst
free
MinimizeEncoded
ArcSort1
addUnseenWords
Add unseen words failed
ArcSort2
Convert
FstConvert
Verify
FST verification failed
FST properties incorrect
-unk
OOV replacement set, but ngram-count flags don't contain -unk. ngrams will be ignored
order
numStates
numArcs
decoder-chain-name
Name of the decoder for the given task from which to take the bigG FST, e.g., msg
task-name
Name of the task to lookup, e.g., Dictation
.lattice-biglm-lme-faster
Unsupported config: first decoder must have only one big G FST
bigG
squeezed_acceptor
app-lm.interpolation
/current
conversion
optimization
training
residualAdaptationWeight
(current_idx_) >= (0)
../libquasar/liblm/include/lm/streams_liblm.h
NGramFst only accepts OpenGRM langauge models as input
Could not identify unigram state.
Unigram state 
 has no arcs.
Number of contexts arcs != number of states - 1
Number of contexts != number of states
Input fst is not structured properly
Structure problems detected during construction
Not enough bits for quantization: 
Malformed file
_quantized
Too much data for reduced file format: 
 missing in new FST!
Too much data for squeezed file format: 
Could not align file during write after states
Could not align file during write after arcs
Verify: Fst start state ID unset
Verify: Fst start state ID exceeds number of states 
Verify: Fst input label ID of arc at position 
 of state 
 is negative
Verify: Fst input label ID 
 of arc at position 
 is missing from input symbol table "
Verify: Fst output label ID of arc at position 
Verify: Fst output label ID 
 is missing from output symbol table "
Verify: Fst weight of arc at position 
 is invalid
Verify: Fst destination state ID of arc at position 
 exceeds number of states
Verify: Fst final weight of state 
Verify: Fst error property is set
Verify: stored Fst properties incorrect 
(props1 = stored props, props2 = tested)
/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/libquasar/liblm/src/impl/srilm.cpp
Interpolate
initializeBasicNgramLM
format error in mix-lm file 
num-of-words
num-trailing-sil
end-of-sentence
pause-counts
silence-posterior
client-silence-frames-count-ms
client-silence-probability
silence-posterior-nf
server-features-latency
eager-result-end-time
spg-silence-frames-count
spg-silence-posterior
spg-silence-probability-raw
Read endpoint model file =
Writing to json string failed. 
BasicEndPointer inter-utt-sil=
Feature unknown, features allowed are: 
NNet model file for endpointing cannot be empty when use-nnet-endpointer is set
Empty feature list (endpoint.feature-list). Specify features from: 
Invalid pause-threshold-list string 
pause-threshold-list should not be empty if pauses-as-bool is set
NnetEndPointer endpoint-threshold=
num-frames
sequence-of-words
num-input-label-words
stream-conf
com.apple.sequoia.tokenizer
mini.json
ncs/dispatch.voc
ncs/lexicon.enh
ncs/itn_s.enh
GeoLM: Unknown exception while reading geo-config.json
GeoLM: Error while loading geo-config.json file: 
Geo config file loaded but some parts of config JSON have never been used
Dumping unused parts of geo config JSON ...
Finished loading geography from 
geo-config-version
Unsupported geo config version 
cache-region-id-enabled
 field not allowed
regions
 not in 
Loaded circle geoRegion="
Multiple default region 
Loaded default geoRegion="
Same 
Loaded bitmap geoRegion="
Internal error. At this point geoRegion=
 must have either bitmap or circle info
Default region 
 missing in geo-config.
Default region is not part of geo-config but given in main-config file.
Loaded geoCircleRegions=
 geoBitmapRegions=
regions-bitmap
The regions-bitmap section is not available
GeoLM: Unknown exception while reading regions-bitmap
GeoLM: Error while loading regions-bitmap file: 
The config file contains some bitmap regions but the 
 field is missing
Geo ClassLM template=
 assigned to FST from geoRegion=
 based on regions bitmap
Using regionId 
 instead of location
 based on known region id
 based on default region
Internal error, known location expected but got 
Computing geo context for 
Internal error, unknown location expected but got 
Access to geo location denied
 based on cached region id
Cannot resolve regionId=
Location is within max radius of geoRegion=
 based on circle regions
 is waiting for followers so letting them proceed
 is exhausted even though follower buffer is ahead of 
leadBuffer must not be changed to another buffer after audio is started
No audio left, and endOfAudio set. Returning false.
Waiting for more audio or endOfAudio
Copied 
 samples (
) into data
returning code: 
Maximum buffer length 
 has been reached. All additional audio will be dropped.
Maximum ring size 
Clipped audio length 
Added 
 samples: 
Clipping audio buffer like other at 
Clipping audio buffer like other from 
; it was 
Cannot synchronize when lead buffer has been deallocated
Signalling end of audio...
PacketsReceived="
Server endpoint triggered so moving buffer marker to end of buffer.
emptyAudioBuffer: ring=
 bufferPos=
 bufferLen=
It does not make sense for maxRingSizeSeconds (limit on the amount of unread audio queued in the buffer) to be greater than maxBufferLenReached (limit on the total amount of audio written to the buffer)
Leader is waiting for follower, not waiting
circular_buffer
Clipped too big left context: 
 words; limit is 
Word(
lmeType: 
 is not listed in lmeTypeInOffsetOrder.
Unchecked
Detected
Not Detected
freezing component 
 (1-based) in this Update
Components to propagate (startCompIdx=
, num_comps=
) must not be greater than 
#components in the network (
Components to propagate to (
Freezing specified components (1-based):
<NnetProto>
Missing </NnetProto> at the end.
</NnetProto>
The network '
' is empty.
Dimensionality mismatch!
 Previous layer output:
 Current layer input:
Could not read any components
The mapped network '
num-components 
input-dim 
output-dim 
number-of-parameters 
component 
### No gradient info
### Gradient stats :
Component 
### Forward propagation buffers not initialized
### Forward propagation buffer content, note in the parallel GPU training, this only includes the first subbatch content :
[0] output of <Input> 
] output of 
### Backward propagation buffers not initialized
### Backward propagation buffer content, Note in multi subbatch case, only the first subbatch is reported :
[0] diff of <Input> 
] diff-output of 
Dimension mismatch between output/input of components 
 <--> 
The word vec component can only be the first component
The word multivec component can only be the first component
The compressed word vec component can only be the first component
a recurrent trainer option. 
a regular trainer option. 
workspace_size_bytes >= 0
Set workspace of 
 bytes for 
 sub-batches
xent
Invalid set to freeze ( non-unique components ): --freeze-components 
Using workspace of size: 
 KBs
Unknown objective function code : 
At iteration 
linearity_corr_.size() > batch_idx
linearity_corr_[batch_idx]
bias_corr_.size() > batch_idx
bias_corr_[batch_idx]
, and Recurrent style components have additional configurations 
bptt_steps 
num_sequences 
NnetTrainOptions : 
learn_rate 
momentum 
l2_penalty 
l1_penalty 
qtype_compact_grad 
step_compact_grad 
num_subbatches 
average_gradients 
vectorize_weights 
The GPU ID for the matrix randomizer is 
Removing softmax from the nnet 
last_component_idx_ >= 0
Performing vectorization of affine transform component
(nlinparams + bias_->Dim()) == NumParams()
veccorrs->size() == linearity_corr_.size() && veccorrs->size() == bias_corr_.size()
(LinearityCorr(ic).NumRows() * LinearityCorr(ic).NumCols() + bias_corr_[ic]->Dim()) == NumParams()
Done  vectorization of affine transform component
 (ParamStddev|BiasMean|BiasRange|LearnRateCoef|BiasLearnRateCoef|MaxNorm|InitTransformType|GradientNormType|MaxGrad|RandomSeed)
Bias().Dim() == vec.Dim()
assetVersion
modelTrainingData
dataHash
oovs
quasar.lm
there are different number of items in the weights list
there are different number of items in each vector
weights should sum to one (i.e. not in log scale)
linear weights converged after 
 iterations
Last state of linear clat is not a final state (perhaps text contains \CS-xx-start without \CS-xx-end?) LM score will not be accurate.
fail to top-sort the rescored lattice
no old LM defined
total number of old LMs is 
 , but the number of interpolation weights is 
no new LM defined
Failed to limit interp_weights2
total number of new LMs is 
can not perform LM rescoring on the lattice
Failed to get a best path in the lattice
Failed to get new total LM score
max_weights: 
Initial weights 
Total number of weights is 
 , but the number of max weights is 
LM should not have been added to DeterministicOnDemandFstCreator. max_weight <= 0: 
Unimplemented. num_effective_max_weights > 1: 
Final weights: 
Division by zero [0/0] in CompactLatticeWeightTpl
Error: division by zero in CompactLatticeWeightTpl::Divide()
Error in Divide (CompactLatticeWeightTpl): cannot divide, length mismatch.
Error in Divide (CompactLatticeWeighTpl): cannot divide, data mismatch.
Cannot divide CompactLatticeWeightTpl with DIVIDE_ANY.
invalid deterministic on-demand FST
can not find label 
 from state 
 . Wrong LM intput?
only linear weight estimation has been implemented now
Caught exception doing lattice determinization
Memory allocation error doing lattice determinization; using 
 bytes (max = 
 (repo,arcs,elems) = (
[empty subset]
Failure in determinize-lattice: size exceeds maximum 
warning: mixture prior out of range: 
too many words in line
ARPA
lm ngram order
lm prior weight
lm type
classes
class definitions
simple-classes
use unique class model
cache-served-ngrams
enable client side caching
allowed options for mixture LM 
 are
error in ngram lm
error in class defintions lm
COUNTLM
error in count-lm 
MAXENT
error in maxent lm 
LMCLIENT
 is not a valid LM type
[post=
[probs=
 in geo config version 
, upgrade to latest version (or version 
dispatch.voc
lexicon.enh
token_s.enh
EAR Initialization failed for custom-lm, error:
CustomLMBuilderErrorDomain
%@/oovProfile.txt
com.apple.ear
EARPSRAudioProcessor
word-syms-marisa-file
Base word symbol table in MARISA trie format (overrides other format files)
Base word symbol table mappable format filename (overrides text and binary format file)
word-syms-binary-file
Base word symbol table binary format filename (overrides text format file)
Base word symbol table text format filename
Model loader is deallocated
No word symbol table file specified.
Failed to convert HatText token to QsrText token:
Failed to convert QsrText token to HatText token:
Calling Write() when offset is nonzero is unsupported
Programming error: Invalid output encoding
<SourceDotTransform>
this is not an updatable component, you used 
<TargetDotTransform>
<SourceAddTransform>
<TargetAddTransform>
Reading attention model
read source dot transform failed
read target dot transform failed
read source add transform failed
## Source Dot Transform: input-dim 
## Target Dot Transform: input-dim 
## Source Add Transform: input-dim 
## Target Add Transform: input-dim 
source state dimension is 
 , but the source dot transform has input dim 
 , but the source add transform has input dim 
the component has input dim 
 , but the target dot transform has input dim 
 , but the target add transform has input dim 
the source and target dot transform has different output dim 
the source and target add transform has different output dim 
the source/target add transform has output dim 
 , but the component has output dim 
it doesn't make sense to use a non-reccurent network here
cannot initialize source dot transform from 
cannot initialize target dot transform from 
it doesn't make sense to use a non-recurrent network here
## Internal recurrent network info 
not implemented yet
the internal recurrent network has output dim 
the internal network takes input dimension 
 , that is not equal the sum of 
source vector dimension 
target input network dim 
the internal network has output dim 
ara-XWW
cmn-CHN
cmn-TWN
nor-NOR
yue-HKG
zh_MO
yue-MAC
ms_MY
zlm-MYS
Unable to resolve 3-letter locale for 
Identifier '
' does not parse into two elements.
Could not read magic header
Magic header was wrong
Could not read number of words
Could not read mapped file
SymbolTable::Read: Can't open file 
Slow symbol table initialization and sorting! This should NEVER be called for perf or memory critical workloads
 are padded words
Slow linear search called! This is OK if called during recognition initialization, but should 
NEVER be called during online recognition.
Logic error (this should not happen).
pass
match
.frontend
.nfhat
Silence posterior generator created with incorrect version
frameByFrame requires output batch size of 1
Siri
zero
one\number
one\pronoun
three
four
seven
eight
nine
eleven
twelve
thirteen
fourteen
fifteen
sixteen
seventeen
eighteen
nineteen
twenty
thirty
forty
fifty
sixty
seventy
eighty
ninety
hundred
thousand
million
billion
trillion
\inverted-question-mark
\inverted-exclamation-mark
continuous-listening.
continuous-listening
\caps-on
\no-caps-on
\no-space-on
\all-caps-on
\caps-off
\no-caps-off
\no-space-off
\all-caps-off
left context: 
; commands: 
CommandStartIndex
Partials: currentTokens should be empty when client left context is provided
Final: currentTokens should be empty when client left context is provided
\letter
\uppercase-letter
\lowercase-letter
Separate post-ITN output: 
Separate post-ITN punctuation: 
preITN leftContext: 
preITN currentContext: 
strip before milliseconds: 
prependedOutputs: 
output: 
delay-finalization-tokens
Interesting tokens that will delay the finalization
fallback-itn-left-context
The fallback left context for across-utterances ITN
itn-left-context-max-length
The maximum token number of left context
delay-finalization-max-length
The maximum token number for the delayed finalization buffer
delay-finalization-length
Finalization would be delayed if token number is no larger than this length
Using previous utterance as left context
leading-inter-utterance-space-tokens
Tokens may add leading inter-utterance space based on itn left context
tokenScore: tokenIndex argument is out of range
tokenString: tokenIndex argument is out of range
Input lattice must be topologically sorted.
_LT_
Cannot read munge file: 
Number of munge rules: 
This should not be called with empty tokens
Munge line with non-space whitespace: 
Munge line missing probability: 
Probabilistic munge rules not implemented (probability must be 1.0): 
Munge line with more than 1 '<-'
/REJECT/
Munge line with empty rhs: 
Munge line with invalid lhs: 
Munge line with invalid rhs: 
MergedMungeRule: 
 {rhs=
 lhs=
 reject=
BasicMungeRule: {rhs=
 startAnchor=
 endAnchor=
Unable to intern metatag due to const.
%s%u
warning: failed to add 
 to vocabulary
warning: line contains only one token
warning: failed to add alias 
 for word 
%u %s
malformed vocab index line
Vector<Real>::Read, adding but dimensions mismatch 
Error reading vector data (binary mode); truncated stream? (size = 
EOF while trying to read vector.
Expected "[" but got 
Failed to read number.
Expected whitespace after number.
Reading negative infinite value into vector.
Reading negative NaN value into vector.
Expecting numeric vector data, got 
After end of vector data, read error.
EOF while reading vector data.
Newline found while reading vector (maybe it's a matrix?)
Reading infinite value into vector.
Reading NaN value into vector.
Failed to read vector from stream.  
SoftMax produced NaN on vector
Empty vector
Failed to write vector to stream
UTF-8
UTF-16LE
UTF-16BE
conversion from UTF-16
 not supported
iconv
offset 
offset unknown 
In class File, failed writing to buffer
/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/libquasar/liblm/src/impl/arpa2fst-kaldi.cpp
<s> is missing from FST symbol table. 
Note that this is a requirement of the Kaldi implementation even when the explicitStartEndMarkers option is set to false.
</s> is missing from FST symbol table. 
<s> and </s> should be different symbols.
 is missing from FST symbol table.
Symbol 
 in ARPA model has no remapping.
Non-event symbol 
 occurs as a probabilistic event. 
Is <unk> modeled as a word?
 n-grams, but only found 
Non-finite loss (
) in cross-entropy calculation
Non-finite entropy (
Posterior pdf-id out of NN-output dimension, please check number of pdfs by 'hmm-info'.
 nn-outputs : 
, posterior pdf-id : 
ProgressLoss[
h]: 
 (Xent)
Can't collect performance from non Xent object
AvgLoss: 
 (Xent), 
[AvgXent: 
, AvgTargetEnt: 
progress: [
FRAME_ACCURACY >> 
% <<
Loss
Entropy
Correct
Frames
) in MSE calculation
 (Mse)
Can't collect performance from non Mse object
 (Mse), 
[RMS 
 states and 
 arcs.
Not Implemented
error writing 
print version information
max ngram order
debug
tagged
skip
stop-words
stop-word vocabulary for stop-Ngram LM
map-unk
word to map unknown words to
tolower
map vocabulary to lowercase
float-counts
vocab
vocab file
vocab-aliases
vocab alias file
nonevents
non-event vocabulary
limit-vocab
maxent
maxent-convert-to-arpa
count-lm
reverse
no-sos
don't insert start-of-sentence tokens
no-eos
don't insert end-of-sentence tokens
write-lm
write-vocab
prune
prune redundant probs
minprune
prune only ngrams at least this long
memuse
show memory usage
min-alignment-value
minimum total alignment weight that must be assigned to the attention window
num-forbidden-frames
min number of frames that must be in the encoder output buffer after the right attention boundary
num-forbidden-frames-silence
min number of buffer frames after the right attention boundary when top prediction is silence
chunk-size
chunk size used in estimating attention window location
Coding error: the number of arcs has changed after node-merging
Malformed phrasebook line:
failed to open phrasebook file 
Loading phrasebook: 
# of keys: 
Expecting 
invalid model type specifier: 
Interpolation weight
max-rescore-weight
Max rescoring weight: 0 = exclude from rescoring, 1 = use in rescoring as usual, betw 0 and 1 = limit rescoring weight chosen by EM algorithm
deserialize-test
Test if the new model can be read before it is installed
Type of model. Examples: 'dummy' or 'ngram'
Unknown model type: 
Reading LmModel currentDir=
maxRescoreWeight
Unknown exception
C++ exception: 
Reserved metadata key: 
Model is only for inference and cannot be written
Destination is empty
totalTime
times
Not enough data. Skip training
Reading LmModel dir=
Coordinated rename failed. This should never happen and is a bug!
lm.json
/garbage
Testing deserialization
Deserialization test failed.
/next
WatermarkDetector2 not run on input origin 
WatermarkDetector2 not supported for sampling rate=
WatermarkDetector2: missing trigger phrase endTime.
WatermarkDetector2: not enough audio cached.
WatermarkDetector2: Trigger phrase not detected
WatermarkDetector2: score=
 detected=
Watermark2Score
Watermark2Detected
Watermark2StartTimeSecs
Threshold value to detect a watermark
anti-notch-offset
Frequency (in Hz) of anti notch offset
notch-width
Frequency (in Hz) of width of notch
notch-freq
comma separated list of notch frequencies
classifier
comma separated list of classifier values
unknown keyword
#remaining_frames for fbank 
 and energy 
 don't match!
mismatch between finished pitch frames and remaining frames+new wav frames: 
 v.s. 
ConvertToFST
/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/libquasar/liblm/src/impl/arpa2fst-inhouse.cpp
Unable to resolve silence token 
SilenceOptions: {
Creating silence state.
FST will have 
StateInstantiator
Artifact in life cycle stage 
incorrect text normalization meta-data.
Artifact in invalid life cycle stage.
Unable to transform artifact from 
A Tokenizer instance was provided when the input data is processed.
A Tokenizer instance was not provided when the input data is unprocessed.
Unable to determine whether model is adaptable to 
 life cycle stage.
No such node
basic_ptree<K, D, C> &boost::property_tree::basic_ptree<std::string, std::string>::get_child(const boost::property_tree::basic_ptree::path_type &) [Key = std::string, Data = std::string, KeyCompare = std::less<std::string>]
/AppleInternal/Library/BuildRoots/b958ad6d-2c13-11ed-a8d5-b25c5e9b9057/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator16.1.Internal.sdk/usr/local/include/boost/property_tree/detail/ptree_implementation.hpp
gtmin
gtmax
cdiscount
ndiscount
wbdiscount
kndiscount
ukndiscount
kn-counts-modified
interpolate
mean
Mismatch in number of key and value pairs in ScaledDotAttention, got 
 keys and 
 values
Mismatch of key matrix input in ScaledDotAttention, expected 
, but got 
Mismatch of value matrix input in ScaledDotAttention, expected 
SetKeyValueStores needs to be called in ScaledDotAttention for attention to work
<AddQuery>
<QueryTransform>
<KeyTransform>
<ValueTransform>
<OutputTransform>
Reading ScaledDotAttention component
reading query transform failed
reading key transform failed
reading value transform failed
reading output transform failed
<NumberHeads>
Reading MultiHeadAttention component
<SupervisedHeads>
Reading SupervisedMultiHeadAttention component
Reading SelfAttention component
<Attention>
failed to read attention component in SelfAttention
ResetHistoryState for SelfAttention makes only sense if all utterances get reset at the same time
<AverageFfn>
<Gate>
Reading AverageAttention component
reading average feed-forward network failed
done
reading input gate network failed
</AverageAttention>
Recurrent neural networks are not supported inside the average attention component.
ResetHistoryState for AverageAttention makes only sense if all utterances get reset at the same time
Error: computeEta2: couldn't find dev n-gram in ARPA, 
hint: add to Vocab iterator and re-normalize Ngram.
process-feeds-config-file
Configuration file for feed processing rules
spoken-forms-file
Spokenforms file
regex-rules-file
Post-tokenization regex rule file
additional-lexicon-file
Additional lexicon file
FST type
Wildcard symbol for partial match
squeezed_transducer
QSR_SYM_V000
~w01
Error opening 
root
[root] grammar is not present.
Generating grammar FST for 
 ... 
.txt
Building L FST ... 
/pmlexicon.txt
Building Aligned-L FST ... 
Composing LG FST for [
] ... 
Stripping out all the grammar symbols on the output side for [root] ... 
Moving the grammar symbols from input side to output side for [root] ... 
<-2, root>
Not combining $
 with root because it contains subgrammars
$root
Unable to find symbol $
 in the symbol table.
lmeDataFactory initialization failed!
G2P model does not exist
state: 
 # of intervals: 
# of states: 
# of intervals: 
# of intervals/state: 
# of non-interval states: 
IntervalReachVisitor: state2index map must be empty 
for this FST
IntervalReachVisitor: state2index map incomplete
IntervalReachVisitor: cyclic input
StateReachable: final state contained in a cycle
LabelReachableData: no relabeling data
LabelReachable::ReachInit: fst is not sorted
FastLogAccumulator: initialization error.
FastLogAccumulator::SetState: invalid state id.
WriteIntPairs: Can't open file: 
WriteIntPairs: Write failed: 
# of calls: 
# of intervals/call: 
Failed TPLexicon_GetInfo()
could not format word sequence: 
could not get text of word sequence
could not get result
could not get result Alignment 
result could not be deleted
quasar.artifact
Input not monotonic
Adjacent 'ID'
Adjacent 'DI'
Unexpected character
Invalid alignment string
String is all I's, all D's, or empty
Output not monotonic
Coding error. addAudio() called after endAudio()
(BiasMean|BiasRange|ParamStddev|LearnRateCoef|MaxNorm|MaxGrad|InitTransformType
|GradientNormType|RandomSeed)
 Gate recurrent weights:
 Activation recurrent weights:
  Gate recurrent weights gradient: 
  Activation recurrent weights gradient: 
  Candidate activations: 
  Activations: 
  Candidate activation diff: 
  Activation diff: 
; output dim = 
Gate recurrent weights #rows = 
Gate recurrent weights #columns = 
Activation recurrent weights #rows = 
Activation recurrent weights #columns = 
Saving last activation batch 
mapping [
] -> [
Tokens:
Logic error! newTokens should not be empty here.
       shrinking token before replacement
   DNT copy: '
   step backward to: '
' / 
   discarding: '
       setting hasSpaceAfter of DNT token
       allready hasSpaceAfter of DNT token
       removing hasSpaceAfter of DNT token
   partial:  '
       tokenStartPos: '
finnished mapping [
], actual source length: 
Adjusting projections
Adjusted range start is out of bounds: 
Adjusted range end is out of bounds: 
    Changing target 
`source` input empty!
Span information differs between source and target - skipping!
do-not-translate only support one-to-one span alignments
    not mapping [
    original: '
Unknown protection class: 
Failed to set protection class for path: 
en-US
Did not get correct batch [
) for frame 
Request for expired frame (
): current frame offset is 
Request for invalid frame (
): you need to check
 IsLastFrame, or, for frame zero, check that the input is valid.
Could not calculate silence posterior for frame=
, current frame offset is=
Silence posterior cache incorrectly calculated rows=
Requested posteriors for realignment do no longer exist.
Realignment model posterior cache is empty, make sure that acoustic model for realignment is configured correctly
Request for invalid frame (you need to check IsLastFrame,
 or, for frame zero, check that the input is valid.
LogLikelihood() must be called before this method as silence posteriors are pre-computed there
EARAudioResultsGenerator
This class is internal to Quasar, and this function is never called
recogResult.params is null. Should NEVER happen
Decoding for only the last utterance failed. Updating recogStatus to success
Quasar PreITN Result. isFinal=
PreITN 1-Best: 
PreITN Choice: 
 muxIds: 
PreITN Token[
Sanitization returned empty string
Tokenizer returned empty tokens
Pronguesser returned empty prons for orthography 
profile
people-suggester-contacts-count
best-people-suggester-contacts-count
best-people-suggester-contacts-bonus
best-people-suggester-contacts-bonus is 0, ignoring.
LmeDataFactory already initialized.
lme-create.
Failed to find 
 in template-map, skipped.
params
lme-create.name-enumerator-map.
.params.
name-scale-map
name-average-cost-map
name-deviation-cost-map
max-entity-count-map
max-orthography-length-map
max-pronunciation-length-map
read mmaped lexicon from 
Could not read lexicon data from mmaped source 
can not open 
Cannot open g2p rewrite file 
G2P blacklist does not support rewrite rules
Malformed g2p rewrite file line=
g2p rewrite file contains whitespace line=
Failed to encode g2p rewrite entry in QsrText: 
G2P rewrite rule 
G2P rewrite size=
LmeDataFactory initialized.
LmeDataFactory not initialized.
Checking category "
": Not supported
": Supported
Starting LME for new speaker.
AOT LME data has already been provided.
LME data has phone set version 
 which is different from model phone set version 
Adding AOT LME for speaker. lmeDataStatus=
, nextLmeStartSymbolKey[AotLme]=
Multipe LmeType in single user data is not supported.
is UserData empty? not able to tell which lmeType from userData which has size: 
generate Lme Data for lmeType: 
Serializing.
Deserialization test failed. Cannot properly serialize this data.
Deserialization test passed.
User data is empty
Lme enumerating return NothingToDo, errorCode=
Lme enumerating failed, errorCode=
Expected symbol table from previous LME data but none was found. 
lmeData.symTableFirstKey = 
, lmeData.symTableLastKey = 
Failed to build the LME fst using the direct method
_num_word_homophones=
_num_fst_paths=
_num_word_homophones
_num_fst_paths
Failed to build the LME fst
LmeEnumeratingTimeMs=
, lmeFstCreatingTimeMs=
, maxPronsPerWordSeen=
LmeEnumeratingTimeMs
LmeFstCreatingTimeMs
Created lmeData.symTable
Original lmeData.symTableFirstKey = 
, Original lmeData.symTableLastKey = 
New lmeData.symTableFirstKey = 
, New lmeData.symTableLastKey = 
Ignoring user data key 
Getting LME data for userDataKey = 
 quasarTemplateName = 
No supported templates were found in userData. Only the templates specified under 
"supported-lme-template-list" in the json config file are supported.
Skipping name containing bad word:
Skipping name containing bad word
Could not find enumerator for quasar template 
Enumeration type:
Word has empty orthography
Word with hex sequence 
has frequency 
Word has no prons, orthography=
Word has pron with 
 phones, exceeds maxPronLen=
, orthography=
Rewriting from=
 to=
Could not read magic header from 
Magic header was wrong in 
Could not read the number of words from the mapped file 
Could not read the offset region in the mapped file 
base-dict-file
Base lexicon file
base-dict-mapped-file
Base lexicon file, mmap-able (overrides text lexicon file)
lme-scale
Scaling factor for the LME FST
lme-average-cost
the cost of entering an LME FST
lme-deviation-cost
the cost of deviating from an average size LME class
supported-lme-template-plist
Comma-delimited LME template names, ordered by enrollment priority
supported-lme-template-list
Comma-delimited LME template names
contacts-template-name
Quasar template name for user's contact names
appcontacts-template-name
Quasar template name for 3rd-party app contact names
max-num-enumerated-contacts
Maximum number of contacts (e.g. in NT-contact and NT-appcontact) to allow in a user's profile
just-in-time-template-name
Just in time LME template name
template-map
Mapping from ACE category names to Quasar template names
name-enumerator-map
Mapping from Quasar template names to enumerator names
max-prons-compound-word
Maximum number of pronunciations for compound words
During G2P, empty prons will be returned for tokens listed in this file. File format: same as a lexicon text file (not hat encoded) with the prons removed so that only one column remains per line. Order does not matter.
g2p-rewrite-file
File format: If a rule is in the form of 'A -> B' (whitespace optional), then rewrite token A to token B before doing G2P. If a rule is in the form of 'A', then rewrite A to an empty string. This 2nd rule has the same format and effect as g2p-blacklist entries and therefore makes g2p-rewrite-file a superset of g2p-blacklist.
LME scale for specific Quasar template names
the cost of entering an LME FST for a specific template
the cost of deviating from an average size LME class for a specific template
Per-template map: If >= 0, maximum number of entities allowed. Additional entities are rejected.
Per-template map: If >= 0, maximum orthography length. Entries with any words that have longer orthography lengths are rejected.
Per-template map: If >= 0, maximum pronunciation length (# phonemes). Entries with longer pronunciations are rejected.
Exceeded enumeration limit. Stopped enumerating.
\NT-buzz
\NT-appcontact
fallback
both
phrase_book_only
unknown phrase-book-mode: 
integrated
rescore_bpe
rescore_word
partial_bias
unknown lm-mode: 
gnmt
unknown 'norm-mode': 
specifying both 'norm-cost' (old parameter name) and 'norm-mode' (new name) at the same time is not allowed.
nbeam
best
finished_score
unknown stop-mode: 
espresso
Unknown 'model-type': 
degenerate_translation
Degenerate translation <
> from <
>. Copying the input sequence to the output.
Decoding require valid SentencePiece IDs in input
Streaming decoding not compatible with 'use-sentencepiece-ids'
stream-decoding unexpectly ended, as no futher hyps remain
stream-decoding was closed, but decoder did not clear active hyps
Using meta data from phrasebook loaded inside of PDec - deprecated in MT production!
use shared phrasebook: 
load phrasebook: 
Cache phrasebook: 
failed loading phrasebook: 
<constructor argument>
Model file name not supplied (configuration value 'model-file' is empty)
Model for final- and partial-inputs has to be the same for now.
Phrasebooks are not yet supported for partial-input
Failed to read lm fst from: 
vetoed
stopped
phrasebook_fuzzy
subword string
Invalid entry terminating ReadRaw : 
 phrasebook entries
Apply BPE source : 
Apply BPE target : 
Failed to read model from 
Already mapped from a file
Using the special symbols ids <unk>=
, <s> = 
, </s> = 
Applying log to output probs 
Has BPE Model
No embedded BPE Model
Configuring multilang decorator
<HasPhraseBook>
# PhraseBook entries 
No phrasebook in the model
Getting model for: 
 (sharing disabled)
Getting existing model for: 
Getting new model for: 
Reading phrasebook
<PhraseBook>
num_entries 
</PhraseBook>
# of keys 
Reading tag filters from : 
Select decoder for 
Selected 
Decoder for 
 not found
Try to find decoder for 
 not found!
No tar tag specified but required by model!
entered Init with #ActiveHyps: 
 at decoding-position: 
Initializing NbestCompare. alpha: 
, sigma: 
entered StaticReadWrite final: 
 with #ActiveHyps: 
Input stream did not grow. Previously processed: 
 provided: 
partial_input_addition:
src_input_host_[0].NumRows(): 
partial_output: 
BPE input 
Couldn't find symbol 
 or <unk> UNK symbol
entered Read to process #tokens: 
A Both type TagFormat requires non-empty source and target tags
SrcTag cannot be empty for TagFormat::Src
TarTag cannot be empty for TagFormat::Tar
<src-
> <tar-
entered Write with #ActiveHyps: 
input_batch_idx: 
hyp_idx: 
Final word in hyp list
Skipping target eos symbol
Nothing left in heap
Beam decoder hit maximum sequence length
Pruned all hyps, nothing left to expand
dropping worse identical hyp; score-diff: 
using lattice state:
Adding invalid arc 
At output position 
, # surviving hypotheses: 
No hyps finished, setting 
 partial hyps to final
Setting longest vetoted translation as best 
# of cached states 
For 'partial_bias' lm-mode, storing token: 
Didn't extract any paths from the lattice
Unknown replacement disabled for: 
Error converting BPE to word list 
Not applying BPE to target
Nbestlist cannot be null
Decoder not configured for SentencePiece ID decoding.
Model not configured for SentencePiece ID decoding.
Input Hammer not supported for sentencepiece id decoding.
Phrasebook (kaldi level) not supported for sentencepiece id decoding.
Decoder beam (
) should not be negative.
Decoder confidence threshold (
) should be in the range [0, 1000].
Decoder maximum nbest list size (
model does not require the use of src/tar tags
Apply tags to ID sequence require a tag symbol table in MultiLangDecorator!
Source locale 
, Target locale 
 source tag 
 target locale 
, # of phrasebooks 
Re-decode without LM 
time
Input : 
Greedy decoding
Beam decoding
Word level LM re-scoring
Applying confidence scores to n-best list
Looking for UNK symbol 
UNK label : 
No UNK symbol in translation model vocabulary
Language model does not have output symbol table
LM UNK ID 
Language model does not have OOV symbol : 
 in LM
Word lookup failure : 
 (label=
Old Cost = 
, New cost = 
, Hyp = 
 finalcost=
Alignment cost 
time total
time start feedforward
time start ff graph
time start ff handover graph
time get history state
time set history state
time feed forward
time ff graph
time ff readout
Decoder not configured for string decoding (use SentencePiece ID decoding).
Model lacks full symbol tables (use SentencePiece ID decoding).
Total # of phrasebook matches : 
FindInPhraseBooks # 
Phrasebook fallback match
Phrasebook locale match
, phrasebook idx=
should_be_hyp == "hyp"
(first_underscore_index != std::string::npos) && (first_underscore_index > 3)
0 && "Invalid feature name"
(hyp_id >= 1) && (hyp_id <= num_hyps_)
std::find(feature_list_without_hyp_ids_.begin(), feature_list_without_hyp_ids_.end(), should_be_in_feature_list_without_hyp_ids) != feature_list_without_hyp_ids_.end()
hyp_confidence_values.size() == num_hyps_
count
25pct
50pct
75pct
TextSanitizer is already initialized
[^\u0000-\uFFEF]
Failed to compile special characters regex
(\s)+
Failed to compile duplicate spaces regex
[\p{C}]+
Failed to compile control characters regex
TextSanitizer is not initialized
Empty string received.
wstring_convert failed for text: 
Failed to normalize 
Could not open UTF8: : 
Failed to replace unicode characters in range [\u0000-\uFFEF]: 
Failed to remove some special characters: 
Failed to remove redundant space characters: 
Failed to remove control characters: 
Intermediate basic sanitization result=
If silence posteriors are available, trigger only when the average silence posterior is >= this value. Otherwise, ignore this value.
silence-window
Sliding window size (in frames) for silence posterior average. Silence posterior is ignored if this value is <= 0.
stable-partials
Trigger only after the number of stable partial results (one per frame) exceeds this value. (Eager's stabilization is unrelated to ResultStreamStabilizer stabilization). Regardless of this value, the trigger always looks for at least 1 stable partial result.
early
backoff
max-triggers
Ignored if <= 0: Maximum number of eager result triggers. Once exceeded, no more eager results are created.
require-silence-posterior
If true, disable eager for requests that don't have silence posteriors. Defaults to true since 'false eager results' increase without silence posteriors. Set this to false for experimentation or if the number of 'false eager results' is acceptable.
Debug mode: require-silence-posterior=false and trigger every frame without affecting state machine
{silencePosterior=
 silenceWindow=
 stablePartials=
{early=
 backoff=
 maxTriggers=
 requireSilencePosterior=
 debug=
{frame=
 finalActive=
 words=[
 ids=[
 trailingSilence=
 silencePosterior=
 allowTrigger=
n must be positive
init() was not called
Cannot compute average of 0 items
ENABLED 
 hasSilencePosterior=
trigger=
 numTriggers=
 thisFrame=
 avgSilPost={
 numStable=
INVALID 
INVALIDATED 
TRIGGER 
TRIGGERED 
Invalidate and trigger shouldn't happen on the same frame
Bad state transition: triggered 
silence phone probability must be [0,1) 
invalid silence phone value <
the input lexicon is empty
Cannot dereference iterator that is already at the end
Cannot increment iterator that is already at the end
[OOV context]
H-MAXENT 0.1
# %ld %ld %ld %ld
 contexts...
<word> <weight> expected
format error in H-MAXENT file
H-MAXENT 0.1
# %ld %ld %ld %ld
%s %f
Counting counts of order 1 
Counting counts of order 
Contexts:
Creating feature contexts...
Indexing contexts of order 
Creating reverse context index...
WARNING: Data contains n-grams that cannot be properly mapped the nodes of the Maximum Entropy model structure;
         If you are adapting a prior model, use also adaptation data (with weight 0) for creating the prior model
Creating count contexts...
Coding error: SyncDecoder 
 has already been initialized.
Ignoring unknown SyncDecoder type "
Recognition will crash if you try to use it
suites
resourceBaseURL
v24@?0@"EARVoiceCommandSuite"8^B16
EARVoiceCommandActiveSet.mm
Missing key "%@" of type NSNumber
Wrong value type for key "%@"; expecting NSNumber
Missing key "%@" of type NSArray
Wrong value type for key "%@"; expecting NSArray
Missing key "%@" of type NSString
Wrong value type for key "%@"; expecting NSString
v32@?0@8Q16^B24
identifier
commandSpecs
v24@?0@"EARVoiceCommandSpec"8^B16
valence
FSTRelativePaths
FSTSymbol
B32@?0@8Q16^B24
Wrong value type in array for key "%@"; expecting NSString
mt-decoders
blocks
graph
block-definitions
block
block-type
limit-input-data-length
PDEC
Logic error: truncateUtf8 called with negative lenght (should not happen)
missing source or target locale, skipping parsing language-pair-specific-settings
block definition '
' (referenced in '
]') not found
<overlay-settings>
Changing phrase book mode using command line overlay causes use of previously ignored translation model file: 
.graph
missing source or target locale!
Unknown block definition name: 
Machine translation configuration for task '
' not found!
Assuming legacy (non-graph) config format, deprecated for production MT configurations!
missing source or target locale, skipping parsing 
No language pair specific settings found (this might be a configuration error).
Config file does not support language pair: 
 for task: 
input_truncated
__NONE__
mt-quasar-config.json
siri
EMTTranslator.mm
Task string cannot be nil
com.apple.sequoia
Failed to parse mt-quasar-config.json
v32@?0@"SFTranscriptionSegment"8Q16^B24
<OutputEmbeddings>
<OutputPhoneLoglikes>
<OutputEOSProbabilities>
<InputFrameCount>
<OutputPhoneDim>
<SilPhoneIndex>
<FrameOverlap>
<NumSpeculativeOutputs>
(InputFrameCount - FrameOverlap) must be a multiple of FrameSubsamplingFactor
<BlankIndex>
<ContextSize>
input_labels->GetNumDims() == 1
Mismatch at [
<InputAcousticEmbeddings>
<InputLabelEmbeddings>
input_acoustic_embeddings->GetNumDims() == cfg_.input_shape_template.ndim
input_acoustic_embeddings->GetDimSize(cfg_.input_shape_template.col_index) == InputDim()
input_label_embeddings->GetNumDims() == cfg_.input_shape_template.ndim
input_label_embeddings->GetDimSize(cfg_.input_shape_template.col_index) == InputDim()
input_acoustic_embeddings->GetDimSize(cfg_.input_shape_template.row_index) == input_label_embeddings->GetDimSize(cfg_.input_shape_template.row_index)
input_acoustic_embeddings.NumRows() == input_label_embeddings.NumRows()
input_acoustic_embeddings.NumCols() == input_label_embeddings.NumCols()
output_embeddings
input_acoustic_embeddings
input_label_embeddings
quasar.geolm.helper
<unspecifed>
<unknown>
Stream failure detected.
state ID
FstPrinter: Integer 
 is not mapped to any textual symbol
, symbol table = 
, destination = 
arc input label
arc output label
acoustic-encoder-model-file
Acoustic encoder model (TF/Espresso/CoreML graph)
label-encoder-model-file
Label encoder model (TF/Espresso/CoreML graph)
joint-predictor-model-file
Joint predictor model (TF/Espresso/CoreML graph)
max-label-fraction
#decoded-nonblank-labels / #acoustic-encoder-output-frames <= max-label-fraction. Must be positive. Active only if max-steps < 0.
Number of acoustic encoder output frames to compute per chunk.
Remove EOS labels from output.
Remove silence labels from output.
remove-blank
Remove blank labels from output.
merge-hyps
Merge equivalent hypotheses.
merge-max
Assign max score to merged hypotheses, otherwise total score (default).
label-context-size
Context size to merge hypotheses by label context. Inactive if negative (default).
keep-merged-hyps-active
Keep hypotheses active when merged by label context.
Maximum number of decoder steps. Inactive if negative (default).
At least min-active best hypotheses are retained after pruning.
At most max-active best hypotheses are retained after pruning.
Beam width. pruning-cutoff = best-hypothesis-score - beam.
Score penalty added for each non-blank label.
Enable endpointing.
max-frames
Maximum number of frames allowed. Hard limit. We will endpoint when this many frames are decoded.
max-trailing-sil-frames
Maximum number of trailing silence frames allowed. Active only if some speech frames have already been decoded.
eos-probability-threshold
Endpointing threshold. Endpoints if P(EOS) > eos-probability-threshold. Active only if some speech frames have already been decoded.
enable-utterance-detection
Enable utterance detection.
max-utt-frames
Maximum number of frames allowed in an utterance if num-utt-speech-frames == 0. Otherwise, it is used to determine the maximum number of trailing silence frames allowed.
max-utt-trailing-sil-frames
Maximum number of trailing silence frames allowed in an utterance if num-utt-frames <= max-utt-frames. Otherwise, we use the formula max-utt-trailing-sil-frames * max-utt-frames / num-utt-frames.
Concat: input/output symbol tables of 1st argument 
ConstantEventMap::Write(), could not write to stream.
Could not map value 
 for key 
Multiple values map to the same point: this code cannot 
handle this case.
TableEventMap::Write(), could not write to stream.
, for key 
, cannot be mapped.
SplitEventMap::Write(), could not write to stream.
SplitEventMap::Read, NULL pointers.
EventMap::MaxResult(), empty result
Empty phone in phonetic sequence: 
Could not interpret 
 as a phone. Found in phonetic sequence: 
weight must be between 0 and 1 inclusive (weight=%f)
total weight must be between 0 and 1 inclusive (weight=%f, current total weight=%f)
word 
 has multiple class memberships
class 
 expands to string of more than one word
opts_.min_active > 0
opts_.max_active >= opts_.min_active
decodable->BOSIndex() >= 0 && decodable->EOSIndex() >= 0
Decoding output contains label 0. Replacing it with BOS label (
creating PDecTranslatorFactory
HeaderAvailable
/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/libquasar/liblm/src/impl/arpa2fst-kaldi/arpa-lm-compiler.cpp
Reverting to slower state tracking because model is large: 
-gram with symbols up to 
ConsumeNGram
 skipped: n-gram has invalid BOS/EOS placement
RemoveRedundantStates
Reduced num-states from 
Check
Arpa file did not contain the beginning-of-sentence symbol 
 skipped: no parent (n-1)-gram exists
 <eps> or disambiguation symbol 
found in the ARPA file. 
asset_info.json
Not able to set metadata. Unsupported key "
Not able to set info. Unsupported key "
Artifact file was changed before being loaded
Invalid artifact
Invalid artifact - empty metadata
Failed to write metadata
Error while writing 
 to archive
Required key "
" not found in artifact
Supported locale "
" not present
Required dependent key "
" missing from artifact
supported_locales
content-list
Error while trying to open archive at 
 for reading: 
Failed to find archive entry named 
Error while trying to read data from open archive: 
Unable to configure archive as ZIP: 
compression-level=0
Unable to configure archive options: 
Unable to open archive: 
Failed to write header for 
 to archive: 
Unable to write 
Error while trying to read next entry from open archive: 
Failed to write 
Something went wrong while writing content.
Unable to read command FST 
Unable to read one or more command FSTs
DefaultCompactStore::Read: Alignment failed: 
DefaultCompactStore::Read: Read failed: 
GenericRegister::GetEntry : 
lookup failed in shared object: 
-fst.so
Fst::Read: Can't open file: 
Fst::Read: Unknown FST type "
" (arc type = "
"): 
CompactFstImpl: input fst incompatible with compactor
DefaultCompactStore: compactor incompatible with fst
min-voicing-duration
Minimum duration of voicing
acoustic-feature-window-width
Minimum width of the normalization window for acoustic audio analytics features
Utterance feature cache is disabled. Skipping audio analytics.
No audio features generated. Rejecting utterance.
Audio analytics finished..
 score= 
Cycles detected in lattice.
Invalid list of region specifiers provided 
Using non-terminal regions for combination from 
Splitting into labels : 
 Check start 
 end 
 against start 
 lab in lat 
 lab in check 
Found state 
 id 
 start 
 For MBR start 
 distance is 
Match 
not_in_static_vocab
 Find Overlapping With 
Word with ID = 
 does not exist in word map. Is a dynamic vocabulary being used?
No arc to continue with
Recomputing TBP on Ref Interval 
 for arc on 
Recomputed TBP is 
 post score avg is 
Compact Lattice Current state=
 ARC ilabel: 
 olabel: 
 weight1: 
 weight2: 
Next State=
 duration = 
 word is 
Original Duration Was 
 without silence it is 
Warning - state Time Mismatch - 
Time = 
 not in state posterior map...
Couldn't find state 
 defaulting posterior to 0, w1=
 w2=
No states in the word posterior computation - this may be because the word has 0 duration (could happen for class LM)
Utterance ID is 
Needed to find 
 actually only found 
Couldn't find arc
Warning: MISMATCH BETWEEN LENGTH OF 1-BEST and LENGTH OF CONFIDENCE VECTOR
Finished generating 1-best word-level confidence features for 
 words in utterance 
Add Candidate: 
 to candidate/confusion set
Candidate Update: 
Confidence score @ word 
 MBR SCORE IS 
Confidence score @ alt word 
Using special symbol for silence = 
Adding hypothesis number 
 additional cost for non 1-best 
Adding 1-best [
] pen= 0.0 score= 
Add 1-Best word 
 confidence 
Adding alternative [
] pen= 
Was not able to topologically sort lattice (cycles found?)
INIT
MODEL
No Confidence Model Supplied.
Read in Confidence Model , added 
Scaling feature 
 with value of 
 by weight = 
Warning - confidence is NaN or inf, or will be inf in log - confidence model could be bad/compromised. Defaulting to 1.0
Confidence score is 
Rank in list = 
 Orig = 
 sc= 
 HIGH 
p_avg
p_max
p_min
p_geo
comb_score
lm_post
am_post
n_match
n_intersect
p_wcr
p_uni_lm
p_avg_low
p_avg_high
p_avg_diffhigh
p_avg_difflow
rank_score
low_rank_score
high_rank_score
delta_low
delta_high
p_mbr
p_fan_out
n_fan_out
p_fan_in
n_fan_in
n_wrd_inutt
avg_depth
avg_post
avg_ac
avg_lm
avg_conf
avg_like
avg_likelow
avg_likehigh
avg_ac_like
avg_ac_likelow
avg_ac_likehigh
ob_start
ob_dur
ob_p_avg
ob_p_max
ob_p_min
ob_p_geo
ob_comb_score
ob_lm_post
ob_am_post
ob_n_match
ob_n_intersect
ob_p_wcr
ob_p_uni_lm
ob_p_avg_low
ob_p_avg_high
ob_p_avg_diffhigh
ob_p_avg_difflow
ob_rank_score
ob_low_rank_score
ob_high_rank_score
ob_delta_low
ob_delta_high
ob_p_mbr
ob_p_fan_out
ob_n_fan_out
ob_p_fan_in
ob_n_fan_in
cand_p_avg
cand_p_min
cand_p_max
is_eps
alt_hyp_overlap
hyp_sub_alt_prev
hyp_sub_alt
hyp_sub_alt_next
alt_sub_hyp_prev
alt_sub_hyp
alt_sub_hyp_next
alt_lthalf_hyp
hyp_lthalf_alt
alt_in_prev
alt_prev_score
alt_in_next
alt_next_score
alt_tbp
ob_tbp
num_in_confset
prev_in_ob
next_in_ob
prev_best_score
next_best_score
cand_avg_p_avg
cand_avg_tbp
cand_avg_p_max
cand_avg_p_min
cand_wrd_len
sub_compound_left
sub_compound_right
is_lme_word
ob_is_lme_word
alt_has_lme_word
is_one_best
phonetic_dist_to_ob
min_phonetic_dist_confset
m.size() == Features::kFeatureCount
Too many states on the stack. There may be a cycle.
LabelsToUTF8String: Bad code point: 
LabelsToUTF8String: Invalid character found: 
Context size mismatch, ilabel-info [from context FST is 
, context-dependency object expects 
phone == 0.  Possibly you are trying to get a reversed FST with a non-central "central position" P (i.e. asymmetric context), but forgot to initialize the ContextFst object with P as N-1-P (or it could be a simpler problem)
phone == 0.  Some mismatch happened, or there is a code error.
GetHmmAsFst: context-dependency object could not produce 
an answer: pdf-class = 
 ctx-window = 
.  This probably points to either a coding error in some graph-building process, a mismatch of topology with context-dependency object, the wrong FST being passed on a command-line, or something of  that general nature.
tree did not succeed in converting phone window 
AddTransitionProbs: invalid symbol 
 on graph input side.
 on lattice input side.
Error generating random alignment (wrong length?): 
requested length is 
 versus min-length 
AddSelfLoops: graph already has self-loops.
Label 
 neither 0, nor a disambiguation symbol 
(#transition id = 
ConvertAlignment: could not map phone 
Failed to produce suitable phone lengths
ConvertAlignment: error converting alingment, possibly different topologies?
enabled 
 modelLanguage 
 requestLanguage 
Have result
Result is model
Model is compatible with recognizer. Returning it. Elapsed 
Returning nullptr. Elapsed 
task=
 appName=
com.apple.MobileSMS
Not loading custom-lm because task or app doesn't support it.
lm-personalize
cache-size
Cache size for lazy replace operation
enable-lme
Enable LME
lme-sym-start-key
Starting key value for LME symbols
classLM-fst-file-list
list of classLM FST filenames, use comma to separate multiple ones
classLM-template-list
list of classLM templates, in the same order as the classLM-fst-file-list
classLM-nnlm-file-list
list of class Nnlm filenames, use comma to separate multiple ones
classLM-nnlm-template-list
list of classNNLM templates
classLM-nnlm-scale-list
list of classNNLM scales
classLM-start-name-list
list of classLM start names, in the same order as the classLM-fst-file-list
classLM-end-name-list
list of classLM end names, in the same order as the classLM-fst-file-list
Cached template ID 
 for 
The number of classLM templates = 
, which does not match the number of classLM Fst files = 
ClassNNLM doesn't have either tag or model provided.
classnnlm file list can only support one neural net 
Expected range start to be symbol id 
 and a phone word: 
Expected range end to be a disambiguation symbol: 
Disabling small LM pruning for symbols [
lmePhoneWordSymStart 
 lmePhoneWordSymEnd 
 lmeDisambigSymStart 
 lmeDisambigSymEnd 
Could not match classLM scale number
 Expected number of classLM symbols for base/start/end match: 
:lmeLoadingTime
LME container 
: offset 
 firstKey 
 lastKey 
Ignoring unsupported template 
 in stream # 
Ignoring null or arc-less FST for template 
lmeDataStreams and lmeInfos size mismatch. Should NEVER happen
lmeMergeInitTime 
 is null.
Reading LME container 
 for user 
LME container data 
LME data stream 
 has phone set version 
. This data stream will not be used.
Bad LME data (empty): stream=
, symTableFirstKey=
, symTableLastKey=
Bad LME data (invalid last key): stream=
, symTable->AvailableKey()=
 in blob is not supported by datapack.
 in blob uses different enumeration type (
) in datapack.
G2P model version 
 in blob is older than datapack's version 
geoLocationStatus
ClassLM template 
 assigned to FST from 
classlm_origin[
 assigned to NNLM from 
geoContextFound
geoLastRegionIdWasCached
geoLastRegionIdCacheMiss
Using location-specific classLM slot for template=
: placeholder 
 not found in regional map
, using placeholder 
 from regional map
Using decoder-specific classLM slot for template=
, location-specific slot not available
Filtering out unsupported / unused placeholder 
Japanese derived
Unable to get character type for some characters in the orthography
Tag with multiple words: 
Lattice score cache indices = 
 vals = 
Supplied frame 
 is out of range of cache which is in [0,
Pdf 
 is not in cache for frame 
Scaling factor for LM probabilities. Note: the ratio acoustic-scale/lm-scale is all that matters.
More than one lists detected in 
, only first list [
] will be used.
\EOS
Failed to tokenize 
Unable to open the file to read.
 frames
forced alignment source
forced alignment target
PDecForceAlignBlock 'source' input must not be empty
Option 'use-sentencepiece-ids' require vocabulary IDs set in 'input phrase'.
Ignoring shortlisting configuration for kaldi models, running with full readout layer
Inconsistent alignment dimension 
 expecting 
Inconsistent alignment dimension!
Model not conmpatible with `use-sentencepiece-ids`
Model lacks full symbol table, and require `use-sentencepiece-ids`
Source symbol sequence : 
 (length: 
Target symbol sequence : 
 excluding </s> symbol: 
model trained with supervised alignment required for alignment
invalid evaluation task specification 
invalid data specifier: 
invalid metric specifier: 
invalid optimization specifier: 
select-based-on
optimization-method
best-weight
weight list contains invalid range specification (should be e.g."0.0:0.2:10.0")
weight list range specification exceeds maximum number of weights: 
weight list should be comma-separated list of maximum size 
latitude
Latitude used in evaluation
longitude
Longitude used in evaluation
evaluation-metrics
List of metrics calculated during evaluation (e.g. dev-ppl, test-wer)
select-model-based-on
Metric based on which the best model is selected (i.e. usually dev-ppl)
Method to find the best model: "interpolation"(default) or "sweep-weights"
sweep-weights
Range of interpolation weights tested with optimization "sweep-weights"
min-audio
Required number of audio files
max-audio
Maximum number of audio files
remove-unk
If true simply removes all OOVs from input
min-weight
If final weight <= this value, model will not be used
max-weight
Weight will get clipped to this value when saving model
min-pass-rate
If >= 0: Fail the evaluation if ANY computeTextStats() call (1) returns failure OR (2) returns success but doesn't process enough utterances correctly to meet this threshold
min-unadapted-dev-ppl
If >= 0: Model will not be used if this condition is not met
max-unadapted-dev-ppl
min-best-weight-dev-ppl
max-best-weight-dev-ppl
min-dev-ppl-abs-improvement
min-dev-ppl-rel-improvement
dev-ppl
Model selection can only be done on a single metric (select-model-based-on)
invalid choice of min-audio and max-audio
sweep-weights specified in wrong format
Adding 0.0 to sweep-weight list for optimization method "
Adding 1.0 to sweep-weight list for optimization method "
std::is_sorted(evalWeightsList.begin(), evalWeightsList.end())
minWeight >= 0.0 && minWeight <= 1.0 && maxWeight >= 0.0 && maxWeight <= 1.0
First task should be on tuning on dev set
For interpolated models, we should evaluate weights 0 and 1
Task failed
model-selection
bestWeight (
) exceeds maxWeight (
). Clipping to maxWeight
) is below minWeight (
). Model will not be used
PPL checks failed
Running evaluation task 
 with 
 utterances
no text data available for 
computeTextStats failed
Pass rate: 
 passes: 
 total: 
Pass rate too low
perplexity interpolation failed for weight 
no audio data available for 
invalid evaluation metric
computing text stats for weight 
 FAILED
perplexity calculation failed, numTokens is 
bestWeights should be empty
best weight estimation for perplexity interpolation failed
best weights have wrong size or don't sum up to one
invalid optimization method
model selection returned an invalid weight
best weight: 
 PPL: 
checkPPL 
: No CorpusStat
: ppl 
 minPpl 
 maxPpl 
checkPPL: absImprovement 
 relImprovement 
lm-personalize.evaluator
en_US_napg.json
vocdelta.voc
pg.voc
mrec.psh
num-input-hyps must be provided for using model-based confidence
No result choices available. Skipping confidence estimation
Only one result in resultChoices and its empty. Skipping confidence estimation
Subword token index exceeds the number of subwords in the token
Filename for confidence model file. Each line must have the format: intercept <value> OR, <FEATURE> <WEIGHT> [ <FEATURE-MEAN> [ <FEATURE-STD> ] ](feature mean and std values are both optional, could be provided for feature normalization)
token-unigram-freqs
Name of the file with token unigram frequencies
num-input-hyps
number of hypotheses to expect as input to the confidence feature extractor
num-output-hyps
number of hypotheses to produce confidence values for
extract-features
Extract confidence features (even if model is not provided)
Unknown option "-%s";
  type "%s -help" for information
Warning: %s option "-%s" needs an argument
Warning: option "-%s" got a non-numeric argument "%s".  Using default: %d
Warning: option "-%s" got a negative argument "%s".  Using default: %u.
Warning: option "-%s" got non-floating-point argument "%s".  Using default: %lg.
Usage of command "%s"
 -%s%-*s %s
Default value: %d
Default value: %u
Default value: %lg
Default value: "%s"
 -help%-*s Print this message
%s: can't represent the time "%s".
%s: can't parse "%s" as a time.
total memory 
, used 
, wasted 
allocations of size 
allocations of size >= 
<NullWord>
<SymbolToWord>
<WordToSymbol>
<PhoneWordSymbol>
Tried to add overlapping and/or out-of-order symbol table to symbol table list: 
symTableFirstKey=
, previous symbol table's last key=
Word ID 
 not in symbol table 
 with start key 
Got word: 
) from symbol table 
 is already in the symbol list - indices in different symbol tables are not distinct
Found an empty LME word, which should not happen
seeva-greedy
model file
list of vocab
transform file
SeevaModel/__QNNI__source_input
SeevaModel/__QNNO__prediction
<spc>
@[^#]*#|#[^@]*@
EARSyncPSRAudioProcessor
<LeftContext>
<RightContext>
<SourceReversed>
<NoTargetConcat>
<ReattachTarget>
<DotProductRelation>
 (SourceStateDimension|MaxAttentions|LeftContext|RightContext)
component is not initialized, left and right context is 
The target input is concatenated. component has input dim 
The target input is not concatenated. component has input dim 
 , and output dim 
, and you requested to reattch the target, however, 
the internal component has output dim 
component has output dim 
 does not match the internal component's output dim 
the maximum attention is 
 , that does not match the left_context + 1 + right_context, you defined left/right context as 
the source state must have the same dimension as the input dimension of the component if want to take the dot product between them
if not taking the dot production relation from the source and target, you must at least concatenate or reattach the target
Internal error, unexpected pixel size 
Cannot open bitmap file 
Unexpected magic 
Bitmap width must be positive but was 
Bitmap height must be positive but was 
Whitespace expected before binary data
PGM header suggests different file size than actual size, expected=
 actual=
Could not map file 
 into memory
Mapped a PGM bitmap fileName=
 width=
 height=
 maxGreyValue=
latency
numFramesProcessed
totalWallTime
acousticLatency
contextModelLatency
localeSpecificMetrics
languageCode
posterior
confidence
messageLanguageTaggingLatency
isConfident
detectedLocale
conversationMessagePriors
lastMessageLanguage
numAcousticRuns
acousticScores
Invalid locale string given 
Logging LDContext
priors=
dictation_locales=[
current_dictaion_locale=
was_language_toggled=
multilingual_keyboard_locales=[
keyboard_convo_locale_priors=
keyboard_global_locale_priors=
previous_message_locale=
global_last_keyboard_used=
dictation_locale_priors=
window-size
The number of frames to be considered per decision. In flexible input size, this is the minimum window size for creating the 1st LID result. When prediction-interval is used, -1 will deactivate the minimum size.
feature-dim
The dimension size of the features.
languages-list
Comma separated list of languages
compiled-model-file
The name of the compiled model file
model-input-name
The name of the key for the model input
model-output-name
The name of the key for the model output
use-flexible-model
Whether or not the model accepts flexible (variable) input size.
max-window-size
The maximum size window for processing. Only works with flexible input size enabled.
use-cpu-only
Only use the CPU for inference
send-only-final-result
Do not send incremental results, send only the final result. Fixed input will always only send the final result.
minimum-confidence
For flexible input size, the minimum confidence for sending early results back. Only works with flexible input size enabled.
prediction-interval
The interval which we should make decisions (-1 is only once). Only works with flexible input size enabled.
ui-minimum-confidence
Determines whether or no the UI should consider the result non-confident. Should be greater than or equal to minimum-confidence.
input-tensor-shape
The shape of the input tensor specified by (dims, row index, col index).
Only use prediction interval with variable size input.
A negative window-size deactivates an initial minimum window size and requires a positive prediction-interval setting.
Max window size much be configured for flexible model
Must unable useFlexibleModel to have variable input size.
Maximum window size configured to be less than window size
Shape of the input tensor must be specified through (dims, row index, col index).
Input tensor row index must be non-negative and less than input tensor dims.
Input tensor col index must be non-negative less than input tensor dims.
Context provided no locale priors.
No acoustic posteriors.
Using dummy context model. Since acoustic posteriors are equal, defaulting to dictationLocales and currentDictationLocale from the context.
core-ml
acousticLanguagePosteriors
dictationLocales
currentDictationLocale
wasLocaleToggled
multilingualKeyboardLocales
keyboardConvoLocalePriors
keyboardGlobalLocalePriors
previousMessageLocale
globalLastKeyboardUsed
dictationLocalePriors
path to the model file
supported-locales
the locales understood by the model
supported-languages
the languages understood by the model
model-file-format
the format of the model file, must be "core-ml"
model-input-names
the input features expected by the model
the output feature that contains the locale posteriors
Invalid model file format "
Model input names contains duplicates
Invalid context-aware input feature name "
language-detectors
Configuration is incorrect. Only two components are supported.
ld-frontends.
ld-inference-model.
Something went wrong initializing the model.
override-locale-language-map
ld-context-aware-model
 found in config file, but no ContextAwareLDModelFactory was provided.
Something went wrong initializing the ContextAwareLDModelConfig.
Invalid sampling rate 
given.
Resetting for new request.
Version 118 or greater is required.
Unable to reset model.
 frames of audio.
Data is empty
Reached maximum window size. Treating this as the end of audio.
Not enough features yet to meet minimum window size.
Waiting until the next predictionInterval to run.
Running LanguageDetector with 
Something went wrong in LD inference.
Error in processing acoustic result.
Error running acoustic model.
No valid window found. Running contextual model based on equal acoustic priors.
Contextual model failed to run properly.
Language detector max confidence: 
Metrics for locale not in input: 
No context.
Empty priors.
If dictation priors are defined, then dictation locales must be.
4, 1, 2
Symbol: '
' not found in input symbols table.
 Mapping to null...
Not enough space
Invalid UTF-8
Invalid code point
bitset set argument out of range
LmeDataNotChecked
LmeDataOK
LmeDataNull
LmeDataOKButVersionOutdated
LmeDataVersionUnsupported
LmeDataPhoneSetMismatch
LmeDataCorrupt
Unknown
LmeNotUsed
LmeUsedNotRecognized
LmeUsedAndRecognized
, phoneSeq: 
, startSil: 
, confidence: 
, ipaPhoneSeq: 
OriginalToken: 
CandidateToken: 
There should be one cost for each result choice
concatNbest aChoices=
 bChoicesOrig=
 bChoices=
concatNbest[
 cost=(
 aIndex=
 bIndex=
tokenName
startMilliseconds
endMilliseconds
silStartMilliSeconds
hasSpaceAfter
hasSpaceBefore
phoneSeq
ipaPhoneSeq
Inconsistent number of columns. Expected 
Failed to open file: 
max-slot-depth
If >0, the max number of words to allow in each slot of the confusion network.
alt-confidence-model-file
eps-confidence-model-file
Filename for epsilon confidence model file, format <FEATURE> <WEIGHT> (one per line)
scale-low
Acoustic scaling factor (divisor) for low-end, eg, 2 (for a standard divisor of 12 = 0.08333)
scale-high
Acoustic scaling factor (divisor) for high-end, eg, 20 (for a standard divisor of 12 = 0.08333)
acoustic-scale
Scaling factor for acoustic likelihoods, default 0.08333
do-acoustic-stability
Turn computation of acoustic stability features (at multiple acoustic scales) on/off with true(default)/false.
do-process-alternatives
Control whether or not to process alternatives in the sausage network, or run in 1-Best mode, using true(default)/false.
do-process-sausage
Turn computation of features derived from the structure of the sausage network on/off with true(default)/false.
do-process-rank
Turn computation of rank-based features (at multiple acoustic scales) on/off with true(default)/false.
do-process-faninout
Turn computation of contextual posterior features related to fan-in and fan-out context on/off with true(default)/false.
do-process-post
Turn computation of lattice state posteriors (used for time-based-posterior and other measures) on/off with true(default)/false.
Turn computation of confidence score from the model off, effectively generating the time-based posterior as the confidence score,turn on/off with true(default)/false.
do-add-epsilon
Turn computation of epsilon confidence score on, this will use the supplied epsilon confidence model parameters score,turn on/off with true(default)/false.
decode-mbr
If true, do Minimum Bayes Risk decoding (else, Maximum a Posteriori)
number of NBest hypotheses to produce hypotheses (with confidence) for.
Prune incoming lattice to this beam
Finished initializing OnlineLatticeConfidenceDecoder.
sausage-labels
symList.size() != symListWords.size()
Note: Have trimmed confusion network slot depth from 
tokenDur: 
speechDur: 
%u blocks of %u-word chunks
ngram_quantized
reduced_transducer
reduced_acceptor
reduced_quantized_transducer
reduced_quantized_acceptor
squeezed_quantized_transducer
squeezed_quantized_acceptor
Reading FST: unsupported FST type: 
leftNnetWordmapExist || rightNnetWordmapExist
Malformed wordmap files. fileBasename=
, fileExtension=
Could not read the NNLM word map file 
found object in map for fst 
Writing FST: unable to open file to write: 
Writing FST: unsupported FST type: 
found object in map for symbol table 
Could not read symbol table from file: 
, type: 
Model is not in espresso format: 
Compiling espresso model: 
Skipping already compiled ANE model: 
Error happens in compiling network: 
, reason: 
Successfully compiled model in ANE cache: 
Purging espresso model: 
Failed to check ANE cache existence, network: 
, status: 
Skipping network which does not exist in ANE cache: 
Failed to purge model from ANE cache, network: 
Successfully purged model from ANE cache: 
backgroundLoading
fraction
ModelLoader embedded mlock overrides: 
could not sysconf(_SC_PAGESIZE): 
total 
 pages loaded of 
NGramFst::Read: Alignment failed: 
NGramFst::Read: Read failed: 
ReducedFst::Read: Alignment failed: 
ReducedFst::Read: Read failed: 
SqueezedFst::Read: Alignment failed before aligning states region: 
SqueezedFst::Read: Alignment failed before aligning arcs region: 
SqueezedFst::Read: Read failed after reading states and arcs: 
SqueezedFst::Read: Alignment failed before aligning final states region: 
Falling back to slow loading for 
SqueezedFst::Read: Read failed after reading final states: 
/*.weights
could not find weights for: 
could not open: 
could not lseek: 
could not mmap: 
loaded 
 pages of 
EARSPG: SilencePosteriorGenerator Config file does not exist at %@
resetForNewRequest
 or 
<Function>
<OutputTensor>
<AllowNonCPU>
src->GetNumDims() == 2
converted_data
Can't deal with this yet
Got nothing for needed output 
 in [
No input in model for 
CoreML feature provider creation failed: 
Could not make temporary MultiArray: 
unsupported MLFeatureValue type
t_ != nil
t_ == nil
Unsupported CoreML input type 
Unsupported CoreML required non-MultiArray input: 
Could not build blank array: 
v32@?0@"NSString"8@"MLFeatureDescription"16^B24
 => 
CoreML evaluation failed: 
data_batch.size() == batch_count
CoreML batch evaluation failed: 
CoreMLTensorData copy failed: 
Copy failed: 
could not make temporary array: 
vectorizeIntoMultiArray: failed: 
Asked for float32 of a non-float32 buffer
t_ || fv_
CoreMLTensorData create failed: 
Unsupported feature type: 
Could not make MLMultiArray: 
not supported MLMultiArray data type: 
<FiltXLen>
<FiltYLen>
<FiltXStep>
<FiltYStep>
<PadX>
<PadY>
 (ParamStddev|BiasMean|BiasRange|FmapXLen|FmapYLen|FiltXLen|FiltYLen|FiltXStep|FiltYStep|ConnectFmap|LearnRateCoef|BiasLearnRateCoef|RandomSeed|GradientNormType|MaxGrad)
input_dim_ % (fmap_x_len_ * fmap_y_len_) == 0
output_dim_ % (out_fmap_x_len * out_fmap_y_len) == 0
filters_->NumRows() == num_output_fmaps && filters_->NumCols() == num_input_fmaps * filt_x_len_ * filt_y_len_
wei_src.Dim() == NumParams()
 OutSizeX:
 OutSizeY:
 InFmaps:
 OutFmaps:
Performing vectorization of convolutional 2d component
Done  vectorization of convolutional 2D component
Convolutional2DComponent needs workspace set to perform back-propagation
Unsupported BNNS filter weight arrangement
It did not work
Unsupported
After assign, Convolution filter has padding? 
Reading Whe_
Whe_.Dims() 
Reading Whd_
Whd_.Dims() 
Reading Whc_
Whc_.Dims() 
Handover is not supported for stream input.
Model type requires full handover.
BidirectionalEncoder is not supported for stream input.
Un-supported model type : 
time decoder
time attention
time readout
time output embedding
Left symbol sequence : 
 (# 
Right symbol sequence : 
 including </s>) 
Constrained Softmax with force alignment decoding is not Supported!
<SymbolTable>
</SymbolTable>
<ModelType>
Full ModelType 
Undefined Torch model type
ModelType 
TorchN
TorchM
TorchT
TorchF
Unsupported Torch model type : 
Processing token 
Found BPE token
SHORTLIST
Found SHORTLIST token
TMPATT
Found TMPATT token
CHILD
Found CHILD token
PyTorch
Found PyTorch token
DotT
Found DotT token
AddTag:
Extracted add tag : 
AddTag value 
TagFormat:
Extracted tag format : 
TagFormat value 
ShareEmbed
Found shared embeddings token
EncPos
Found encoder position embedding token
DecPos
Found decoder position embedding token
Found add beginning of sentence tag
Found add end of sentence tag
AlignModel
MultipleDecoders
Found multiple decoders token
Found 'NoSymbolTables' token
Unknown model sub tag 
dot attention 
<NumDecoders>
<DecoderLanguage>
<HandoverCellStateOnly>
<HasHandoverLayer>
Handover layer not supported with PyTorch models 
 Cell handover 
 Has handover layer 
<HasInputSymbolTable>
Has input symbol table 
isyms
Embedded input symbols could not read
PyTorch require symbol table
Special input symbol(s) not defined <s> </s> <unk> 
Overridding default input symbols <<unk> = 
, </s> =  
<HasOutputSymbolTable>
Has output symbol table 
osyms
Embedded output symbols could not read
PyTorch requires symbol table
Special output symbol(s) not defined <s> </s> <unk> 
Overridding default output symbols <<unk> = 
Trying to read embedded BPE model 
Number of BPE entries : 
Trying to read Shortlist
Searching for SupervisedMultiHeadAttention component
Done reading model 
use coverage penalty 
number of frames in each batch, if <0 will feed whole speech in one batch
only streaming the encoder, no partial results
length-penalty-stream
if >= 0, use this value as length penalty during streaming. Otherwise use the value in the graph
if > 0, use this value as the coverage penalty. Otherwise use the value in the graph
cover-pen-ceil
the maximum coverage penalty
cover-pen-step-size
dynamically adjusting coverage penalty with this step size
silence-thresh
if > 0, turn on dynamic coverage penalty when encounter this amount of silence
min-input-count
if > 0, set the minimum number of frames to start streaming. Otherwise use the value in the graph
min-input-left
if > 0, set the minimum number of frames for leftover during streaming. Otherwise use the value in the graph
min-aln-weight
if > 0, set the minimum alignment weight during streaming. Otherwise use the value in the graph
min-init-aln
if > 0, set the minimum initial peak alignment value for the streaming. Otherwise use the value in the graph
min-cont-aln
if > 0, set the minimum continuous peak alignment value for the streaming. Otherwise use the value in the graph
aln-step-size
reduce the min-aln value by this size to increase streaming
min-aln-floor
the aln-value floor when reduction happens
max-input-count
if > 0 && < received_frames, reduce min-aln value to generate partial result if not already so
count-step-size
adjust the min-aln value according to this frequency
init-stable-tokens
number of tokens needed for stablizing the streaming inference at the initial stage
cont-stable-tokens
number of tokens needed for stablizing the streaming inference
dynamic-stable-tokens
turn on dynamic stable tokens to encourage streaming
min-token-floor
the stable token floor when reduction happens
if > 0, use this beam at the utterance end. Otherwise use the value in the graph
if > 0, scale the LME FST score. Otherwise use the value in the graph
if > 0, scale the nonLME arc score when LME is active. Otherwise use the value in the graph
<Topology>
</Topology>
<TopologyEntry>
Reading HmmTopology object, expected </Topology> or <TopologyEntry>, got 
<ForPhones>
Reading HmmTopology object, unexpected end of file while expecting phones.
</ForPhones>
Reading HmmTopology object, expected integer, got instead 
</TopologyEntry>
<State>
Expected </TopologyEntry> or <State>, got instead 
States are expected to be in order from zero, expected 
<PdfClass>
<SelfLoopPdfClass>
pdf classes should be defined using <PdfClass> 
or <ForwardPdfClass>/<SelfLoopPdfClass> pair
<ForwardPdfClass>
<Transition>
<Final>
You are trying to read old-format topology with new Kaldi.
</State>
Reading HmmTopology,  unexpected token 
Phone with index 
 appears in multiple topology entries.
HmmTopology::Check(), empty object.
HmmTopology::Check(), phone has no valid index.
HmmTopoloy::Check(), entry with no corresponding phones.
HmmTopology::Check(), cannot only have one state (i.e., must have at least one emitting state).
HmmTopology::Check(), last state must have no transitions.
HmmTopology::Check(), last state must not be emitting.
HmmTopology::Check(), negative or zero transition prob.
We do not allow any state to be nonemitting and have a transition to the final-state (this would stop the SplitToPhones function from identifying the last state of a phone.
HmmTopology::Check(), invalid dest state 
HmmTopology::Check(), duplicate transition found.
Total probability for state 
 in topology entry is 
HmmTopology::Check, state 
 has no input transitions.
HmmTopology::Check(), pdf_classes are expected to be contiguous and start from zero.
TopologyForPhone(), phone 
 not covered.
' with 
feature index=
 is in models file but missing in normstats file.
 is in normstats file but missing in model file.
Invalid line in file=
 line=
Did not find feature=
Atleast one feature weight and Intercept is needed in model file=
Successfully loaded streaming confidence model file=
Confidence model file connot be empty. Missing configuration parameter confidence-model-file
Normalization statistics is not in the correct format
Number of features does not match with model file, 
Incorrect number of feature means, 
Incorrect number of feature stddevs, 
Standard deviation is 0 for feature=
Unknown feature=
 in normalization statistics file
Successfully loaded streaming confidence normalization stats file=
Confidence normalization stats file cannot be empty. Missing configuration parameter norm-stats-file
Missing feature index=
 in input features
 feature[
 in means or stddev stats
Evaluated features=
, confidence=
INTERCEPT
isfirst
isinside
avg_active
avg_bestcost
avg_epsilenceframes
found invalid synset name '
' in phrasebook
wordnet
found entry without 'syn' field in wordnet phrasebook for '
string_view::substr
No frames fit in file (#samples is 
Non-finite log energy found for frame 
PTree::Error, Error reading JSON config file: 
PTree::JsonParseError, Error reading JSON config file: 
creating PhonetisaurusG2P object
creating PDecG2P object 
Unknown quasar G2P engine type: 
PNSR
/Assistant/SpeakerCode
trainingSpeakerCode
inferenceSpeakerCode
accumulatedGradient
numTrainedFrames
trainingNnetVersion
trainingOffset
recognitionOffset
Coordinates out of bounds latitude=
 longitude=
This or other location undefined, can't computer distance
lat=DENIED lon=DENIED
lat=UNDEFINED lon=UNDEFINED
lat=
 lon=
DENIED
UNDEFINED
KNOWN
num-best
PhonetisaurusG2P Config: model=
, nBest=
g2p model file doesn't exist, or it's a directory: 
Phonetisaurus failed to load model!
Increase nbest, and try again. nbest=
+Tgram]
 <= 0
max-seq-length-veto-factor
PDecG2P Config: model=
, beam=
, lmWeight=
, maxSeqLength=
, vetoFactor=
, lmModelFile=
, maxLengthVetoFactor=
Reducing maximum sequence length from 
 because of max-seq-length-veto-factor
-grams
Found protected token "
" is phonetically matched to "
Bad LME placeholder replacement pmOutput="
" with pmInput="
LME placeholder replacement pmOutput="
Mixture of wildcards and non-wildcards in replacement of input='
' with rawOutput='
' is invalid
Wildcards/placeholders found not replacing input='
No wildcards/placeholders found replacing input='
matchCost
isValid
spans
ITN Override: 
Moving token '
' to following span
' to preceeding span
Undefined GCD since m = 0, n = 0.
Changing word 
Iter = 
, delta-Q = 
Iterating too many times in MbrDecode; stopping.
Edit distance increased: 
L = 
Invalid b_arc value
sum of gamma[
,s] is 
Times out of order
MBR Sausage Alignment Epsilon Symbol is 
Invalid path found.
#Corrections: QsrText-encoded keyword: 
default-n-best-size
The default value for n-best size.
corrections.keyword-finder
keyword-finder.
corrections.sanitization
#Corrections: No sanitization model is provided.
#Corrections: Keyword Finder returning due to null input (not necessarily an error).
#Corrections: Keyword Finder original input utterance: 
#Corrections: Keyword: 
#Corrections: Keyword pronunciation: 
#Corrections: Keyword location: 
#Corrections: Edit distance: 
#Corrections: 
 KWF results from 
-best list
#Corrections: Pre-itn stitched result 
<NumGroups>
<NumTables>
<VocabSizes>
<MaxItems>
<EmbedDimensions>
<AssignedTable>
<InitializeToConcat>
<UseTransform>
, a typo in config? 
(NumGroups|VocabSizes|MaxDimensions|EmbedDimensions|LearnRateCoef|ParamStddev|RandomSeed|InitTransformType|GradientNormType|MaxGrad)
<FeatureTransform>
require an updatable component, you used 
dimension mismatch, cannot initialize to concatenation, expected dim is 
 actual dim is 
cannot initialize to concatenation for this transform
initialized the transform for concatenation
it doesn't make sense to initialize the embedding table as an identify matrix
, a typo in config? (NumGroups|VocabSizes|MaxDimensions|EmbedDimensions|LearnRateCoef)
failed to read feature transform
## Embedding Table: 
## Feature Transform: input-dim 
No intermediate gradients for embedding tables, here is the gradient info for the transforms: 
RMSPROP is not implemented in word multi embedding yet
must have at least one group, you used 
must have at least one embedding table, you used 
there are only 
 groups, but you set 
 embedding tables
 groups, but the number vocab list size is 
 groups, but the max item list size is 
 groups, but the embedding dim list size is 
 groups, but 
 groups have assigned tables
the actual number of embedding tables is 
 and different than 
 groups, but the number of feature transforms is 
the 
-th group has assigned table index 
 , the number of tables is 
-th group has invalid vocab size 
-th group has invalid max item value 
-th group has invalid embedding dimension value 
-th group has mismatched embedding table and vocab size 
-th group has mismatched embedding table and embedding dim 
-th group has mismatched embedding table and feature transform 
-th group has feature transform output dim 
 does not match component output dim 
input dim of the component is 
 , while the input dim defined in max items is 
Total embedding size of 
 doesn't match the component output size of 
 when transforms are not used
Not implemented yet when transforms are used
WordMultiVecComponent doesn't support multi-batches yet
Using transform with gradient compression is not supported yet
Performing vectorization of WordMultiVecComponent
veccorrs->size() == 1
Done  vectorization of WordMultiVecComponent
Write failure in WriteBasicType<bool>
Read failure in ReadBasicType<bool>, file position is 
ReadBasicType: expected float, saw 
ReadBasicType: failed to read, at file position 
Reading arbitrary strings in text mode is unimplemented
ReadString, failed to read string at file position 
ReadString, saw eof while looking for null terminator, at file position 
Writing arbitrary strings in text mode is unimplemented
Write failure in WriteString.
Write failure in WriteToken.
ReadToken, failed to read token at file position 
ReadToken, expected space after token, saw instead 
Error ungetting '<' in PeekToken
Failed to read token [started at file position 
], expected 
Expected token "
", got instead "
<ComputePlatform>
<CheckpointName>
ret == ESPRESSO_STATUS_SUCCESS
CPU_ALT
.net
.weights
espresso_plan_start_profiling_with_options(plan_, profilingOptions) == ESPRESSO_STATUS_SUCCESS
plan_ != nullptr
espresso_plan_build(plan_) == ESPRESSO_STATUS_SUCCESS
plan_ == network_.plan
es_data != nullptr
rank > 0
rank == result_shape.size()
result_shape[i] == shape[i]
buf_data != nullptr
Unsupported concat axis: 
src_buf != nullptr
src->GetNumDims() >= 1
0 <= start
start <= end
end <= num_split
Set function name for checkpoint failed, error=
Espresso failed query blob info 
Espresso failed to reset plan with 
Espresso failed to declare input `
Espresso failed to declare output `
configuration name not supported: 
Espresso failed to unpack shape for input `
Espresso failed to change input blob shapes with 
Espresso failed to build plan with 
kv.second->storage_type == ESPRESSO_STORAGE_TYPE_FLOAT32
espresso_network_bind_buffer failed: 
espresso_plan_execute_sync() failed: 
Failed to bind buffer for input=
, error=
Failed to run checkpoint network, error=
Failed to set function to main, error=
Failed to run main network, error=
Unsupported input dimensions
ANE_RUNTIME
ANE_RUNTIME_DIRECT
METAL
Using The Metal GPU backend (legacy, deprecated) 
METAL_MPS_GRAPH
Unknown platform: 
Set compute platform to 
batch_config_
width_config_
t_.buffer.storage_type == ESPRESSO_STORAGE_TYPE_FLOAT32
Tensor rank is greater than 2: 
srcESBuffer != nullptr
srcend - srcstart >= 0
length >= 0
unsupported storage type.
bitmap-file
lon-left
lon-right
The value of 
 is not greater than 
lat-bottom
lat-top
Bitmap file name cannot be empty!
.pgm
The bitmap file 
 has unexpected suffix, should be 
Loaded regions bitmap width=
Cannot use degenerate regions bitmap width=
Internal error, expecting a real location at this point
The value 
 is not a valid longitude
 is not a valid latitude
This is a FOFE model
penultimate 
Illegal value for 'phrase-book-mode' in 'PDecPhraseBookBlock': 
Failed to allocate array
Failed to create feature provider
Error during prediction
EARLanguageDetector
_EARLanguageDetector init failed
The configuration file or models for _EARLanguageDetector are incorrect.
NSString *localAFDictationLanguageForKeyboardLanguage(NSString *__strong)
EARLanguageDetector.mm
AFDictationLanguageForKeyboardLanguage
void *AssistantServicesLibrary()
arc_output_model_file.empty()
output_model_file.empty()
writeBinaryCount: count 
 is too large
readBinaryCount: incomplete long count
readBinaryCount: incomplete long long count
notch-detector.hfpower.txt
notch-detector.wt.txt
notch-detector.weighted.spectrum.txt
avlo = 
  avhi = 
bands_below.lo = 
, bands_below.hi = 
bands_notch.lo = 
, bands_notch.hi = 
bands_above.lo = 
, bands_above.hi = 
bands_across.lo = 
, bands_across.hi = 
notch-detector.peak.txt
quasar
wait-milliseconds
The number of milliseconds to wait for a confusion network to become available in the cache
No confusion network cache found.
No confusion network found in decodeChainOutput. Doing nothing.
This doesn't work when utt detect/concatenation is enabled. Doing nothing.
No confusion network found in cache. Doing nothing.
Detected phrases in confusion network - backing off to flattened 1-best (this is OK)
Combined sausage is empty. Doing nothing.
Tokens not monotonic and have been corrected.
mismatch between finished audio analytics frames and remaining frames+new wav frames: 
symbol table file
Reset scores after each result
num-discriminative-branches
Number of discriminative branch outputs to be decoded
discriminative-config-file
Config to map the keywords to the discriminative branch numbersAlso specifies the weights to be used for combining the phonetic and discriminative scoresExpected format: <kwdToken> <discBranchId> <phoneticScoreScaleFactor> <discScoreScaleFactor>
num-frames-to-use
Num of frames to use for decodingThis is specifically required when using discriminative branch as we need to use thediscriminative output coming out of the first block
No keywords configured, ignore discriminative config
invalid mapping, expected format <kwd> <discBranchId> <phoneticScaleFactor> <discScaleFactor>
Invalid discriminative branch ID
Kwd: 
 DiscriminativeBranch: 
Weights: 
Mismatch in num keywords specified in discriminative config
DP contains no keywords for detection
Coding error. Keyword 
KWD: 
 CTC Score: 
 Disc Score: 
Dimension mismatch. Code or DP error
Frames seen so far: 
Error reading phone map from 
 (bad line 
Read empty phone map from 
illegal skip prob line
bad skip prob value 
%s %lg
iteration 
log likelihood = 
cannot write data to zero size vector
invalid input data type specifier: 
inputDataType 
 numDocumentsRejected 
 numSentencesRejected 
 numSentencesMungeRejected 
 numDocuments 
 numUniqSentences 
 numSentences 
 numSentencesMungeChanged 
 numTokens 
 numTokensOOV 
numDocumentsRejected
numSentencesRejected
numDocuments
numSentences
numTokens
numTokensOOV
numDocumentsDictated
numDocumentsTyped
numTokensDictated
numTokensTyped
numTokensEstimatedExamined
numSentencesMungeRejected
numSentencesMungeChanged
Unsupported config: first decoder is not lattice-biglm-lme-faster
Unsupported config: first decoder lacks word-syms-map-file
min-words should be a single int or a comma-separated list of size 1..
minWords.size() == NumDataSetTypes
train-dev-test-split should be comma-separated list of size 
splitOffsets: 
train-dev-test-split values should sum to 1
external-train-dev-test-split should be comma-separated list of size 
externalSplitOffsets: 
external-train-dev-test-split values should sum to 1
symbolTable init 
Observing symbols from 
 symbols in bigG 
symbol=
Could not find OOV symbol: 
Symbol out of range: 
Symbol has wrong value in symbolInBigG: 
OOV replacement 
 identical with unseenId
OOV replacement not in symbol table or out of range: 
train ARPA LM file doesn't exist: 
 didn't observe OOV symbol 
 in 
Filtering by languages 
Creating lmScorer. minSentencePpl=
 maxSentencePpl=
external
Train data: 
Dev data: 
Test data: 
External test data: 
train-dev-test-split
Comma-separated list of 3 positive numbers that should sum to 1. Example: 0.7:0.2:0.1 means data will be split as follows: 70%% train, 20%% dev, and 10%% test
sources
Comma-separated list of sources. They can be anything since the caller is responsible for interpreting them.
query-limit
Query limit. The caller is responsible for interpreting this.
max-age-days
Maximum age of data. The caller is responsible for interpreting this.
min-age-days
Minimum age of data. The caller is responsible for interpreting this.
min-words
Minimum number of total words for training to proceed.
max-words
Maximum number of total words to use.
oov-replacement
Replace OOVs with this token
filter-language
If true, filter text by Language ID
external-data-file
Optionally provide an external data file as general test set to evaluate over-adaptation
external-train-dev-test-split
Will split into common train & dev sets, but keeping an extra external test set.Comma-separated list of 3 positive numbers that should sum to 1. Example: 0.1:0.2:0.7 means external data will be split as follows: 10%% train, 20%% dev, and 70%% external
munge-file
Munge file. See documentation in Munger.hpp
min-sentence-ppl
If >= 0: sentences with background LM PPL < this value are rejected.
max-sentence-ppl
If >= 0: sentences with background LM PPL > this value are rejected.
max-sentence-oov-ratio
If >= 0: sentences with OOV ratio > this value are rejected.
max-sentence-oov-count
If >= 0: sentences with OOV count > this value are rejected.
max-document-length
If > 0: documents with length (UTF8 bytes) > this value are rejected.
max-sentences-per-document
If > 0: documents with number of sentences > this value are rejected.
max-sentence-length
If > 0: sentences with length (UTF8 bytes) > this value are rejected.
max-token-length
If > 0: sentences with token length (UTF8 bytes) > this value are rejected.
filter-language-list
Comma-separated list of languages to keep using Language ID. Default: model-info.language.split('_')[0]. Example default: 'en' for 'en_US'
input-type
Format of input data (e.g. ngram-counts). Default: plain-text
rdar-69947462
Requires approval of <rdar://problem/69947462> [AzulC] New fields in Dictation Personalization dodML
filter-document-types
A list of document types which will be excluded from training corpus, e.g. typed, dictated
train-arpa-lm-file
ARPA LM file estimated from training data
max-examined-words
Maximum number of words that can be investigated or preprocessed
max-estimated-examined-words
Maximum number of estimated words that can be investigated or preprocessed
cjk-characters-per-word
Number of average characters per word in CJK locales
externalSplitOffsets.size() == NumPartitions
splitOffsets.size() == NumPartitions
external data file doesn't exist: 
Reading external data file 
addNgramCounts only support training data currently!
Unable to split line "
" into n-gram and count.
Unable to parse count of line "
OOV token encountered in ngram counts. Skipping...
ADDED 
 : number of tokens and symbolIds don't match
Reject due to empty
oovRatio=
 numTokensOOV=
Reject due to high oov ratio
Reject due to high oov count
Reject due to no ppl
ppl=
Reject due to low ppl
Reject due to high ppl
Unsupported input type 
invalid input sentence: 
 for reading
numSymbolsInTrainSet 
Unable to serialize record.
data metrics 
Cannot have leading or trailing space in filename "
Found ~ at the beginning of filename "
". Shell like path expansions not supported.
Found what looks like an rspecifier instead of a filename "
Trying to classify rxfilename with pipe symbol in the wrong place (pipe without | at the end?): 
Error opening input stream 
Invalid input filename format 
Input::Stream(), not open.
open called on already open file.
, errno is 
Pipe 
 had nonzero return status 
FileInputImpl::Open(), 
FileInputImpl::Stream(), file is not open.
FileInputImpl::Close(), file is not open.
StandardInputImpl::Open(), open called on already open file.
StandardInputImpl::Stream(), object not initialized.
StandardInputImpl::Close(), file is not open.
Failed opening pipe for reading, command is: 
Pipe opened with command 
 is empty.
PipeInputImpl::Stream(), object not initialized.
PipeInputImpl::Close(), file is not open.
Cannot get offset from filename 
 (possibly you compiled in 32-bit and have a >32-bit
 byte offset into a file; you'll have to compile 64-bit.
system-combination
selected-chain
Decoder chain to select for output.
selection-model-file
Filename for selection model. Each line must have the format: intercept <value> OR, <FEATURE> <WEIGHT> [ <FEATURE-MEAN> [ <FEATURE-STD> ] ](feature mean and std values are both optional, could be provided for feature normalization)
num-hyps-primary
Number of primary chain hypotheses to consider for selection.
num-hyps-secondary
Number of secondary chain hypotheses to consider for selection.
selection-threshold
Threshold value for system selection
uncombinable-word-tags
Force primary selection if recognition has any of these suffixes
disable-pron-transfer
Do not copy word pronunciations from the primary chain
disable-after-first-utterance
Do not run system combination for second-and-later utterances
No selection model supplied. The output of the primary chain will be selected.
 before calling runAsyncTasks().
Running async tasks of Decoder: 
Not running async tasks for post-first utterances of Decoder: 
Synchronous decoding failed: 
All secondary chain decoders should affect recognition.
Skipping run for post-first utterances of Decoder: 
Last frame of utterance has not been processed, returning success without running system selection
Eager not enabled, running system selection
Last frame of utterance has been processed, running system selection
Secondary decoder chains threw an exception. Skipping system combination.
Done with workerthreads
Output of the secondary decoder chain (
) was selected.
Could not find frame duration of selected secondary decoder chain.
decoderChainOutput->uttNumFrames * decoderPassData.featureMatrix->FrameDurationMs() >= selectedDecoderChainOutput->uttNumFrames * selectedFrameDuration->second
decoderChainOutput->processedLastFrame == selectedDecoderChainOutput->processedLastFrame
Output of the primary decoder chain was selected.
Both the primary and secondary result choices are empty
No result choices were available for the secondary chain. Selecting the primary chain
Result choices for the primary chain:
Result choices for the secondary chain 
Number of primary chain alternatives was less than the number of hypotheses requested for selection. The last choice will be repeated
Number of secondary chain alternatives was less than the number of hypotheses requested for selection. The last choice will be repeated
Output of primary decoder chain was selected because it contains uncombinable word tags
Feature extraction for system selection failed. Selecting the primary chain.
No selection model was provided, output of primary decoder chain was selected.
Output of the secondary decoder chain 
 was selected.
primary (
) != secondary (
Result choice 
 was empty
 (size = 
Received 
hypotheses for feature extraction, expected 
 OOVs
 zeroprobs, 
logprob= 
 ppl= 
 ppl= undefined
 ppl1= 
 ppl1= undefined
 words,
 rank1= 
 rank5= 
 rank10= 
 words+sents,
 rank1wSent= 
 rank5wSent= 
 rank10wSent= 
 qloss= 
 absloss= 
"). 
Trailing whitespace not allowd in rspecifier (found "
Will treat this as kNoRspecifier.
SRILM release %s
1.7.1
 (with third-party contributions)
Program version %s
This software is subject to the SRILM Community Research License Version
1.0 (the "License"); you may not use this software except in compliance
with the License.  A copy of the License is included in the SRILM root
directory in the "License" file.  Software distributed under the License
is distributed on an "AS IS" basis, WITHOUT WARRANTY OF ANY KIND, either
express or implied.  See the License for the specific language governing
rights and limitations under the License.
This software is Copyright (c) 1995-2014 SRI International.  All rights
reserved.
Portions of this software are
Copyright (c) 2002-2005 Jeff Bilmes
Copyright (c) 2009-2013 Tanel Alumae
Copyright (c) 2012-2013 Microsoft Corp.
SRILM also includes open-source software as listed in the
ACKNOWLEDGEMENTS file in the SRILM root directory.
If this software was obtained under a commercial license agreement with
SRI then the provisions therein govern the use of the software and the
above notice does not apply.
Support for compressed files is included.
localhost
%u@%255s
%64s
server host 
 not found
socket: server 
connect: server 
server 
: could not read banner
send: server 
: protocol version 2 not supported
recv: server 
: unexpected return: 
%lu %u
: send 
text mapper entries must be unique
Overriding parameter: 
Overrides JSON does not contain section for '
'.  Skipping.
Json config filename=
Overrides JSON does not exist in datapack; falling back to default overrides.
non_acoustic_default
dictation_cs50
dictation
Failed to load paramset holder
Loaded paramset holder file:  
Could not find file 
Could not laod Empty voc
Could not load PG voc
Mandatory config field missing
Pronguess paramset value is not valid.
Search paramset value is not valid.
Lattice-nbest paramset value is not valid.
FragmentWordsState
OptionalPronWordsState
Generating pronunciations for orthography=
, spoken-form=
Orthography=
, Prons=
pronguess_paramset_name
search_paramset_name
lattice_nbest_paramset_name
napg_params
overrides
title_format
pronguess_overrides
search_overrides
lattice_nbest_overrides
Unknown PDec model type: 
.0 to use PDec model type: 
Compatible system config version (
.0) for PDec model type 
.0 required)
Unknown PDec feature flag: 
.0 to use PDec feature flag: 
.0) for PDec feature flag 
seeva-batch
seeva inference graph file
the vocab file that describes model output token
lm-rescore-chain
the LM rescore decoder chain
use-second-rescore
use the LM rescoring decoder
remove the unknown word during rescoring
unk-word
map the OOV word to this word
e2e-word-map-file
map the E2E word to Quasar
lm weight for LM rescoring
LM-SCORE-DEBUG: select beam 
SeevaModel/__QNNI__source_catf_input
SeevaModel/__QNNI__length_penalty_weight
SeevaModel/__QNNO__nbest_list
SeevaModel/__QNNO__nbest_score
source-input-str
source input tensor name
source-catf-input-str
source catf input tensor name
length-pen-wt-str
length penalty weight tensor name
nbest-list-str
nbest list tensor name
nbest-score-str
nbest score tensor name
/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/libquasar/liblm/src/impl/arpa2fst.cpp
Arc sorting not supported when using 
Explicit modeling of <s> and </s> is not supported when using 
Retention of disambiguation symbols is not supported when using 
Retention of redundant states is not supported when using 
Attaching symbol table is not supported when using 
Unknown ConvertToFST implementation: 
The symbol with key 0 should be 
phonetic-match-building.on-device-data-sources.
limit
Limit on the number of items, default=
prior-exp-decay-factor
Exponential decay factor, default=
prior-power-scale
Prior scale of the priors, default=
Regex
RegexEnumerator not available for 
Enumerator is not available for field [
Prior
Unable to open the file to write: '
Could not find prior field '
' in the header
Could not find field '
 fields, but found 
 at '
Prior field out of bound: 
Invalid prior: 
artists_songs
artists_albums
artist_name
song_name
album_name
playlist_name
radiostation_name
composer_name
genre_name
podcast_name
audiobook_name
movie_name
show_name
An error occurred when reading TSV from: 
An error occurred when reading NT from: 
Invalid DataFeed type 
Field '
' does not exist in data feed, skipping.
Data feed [
] is not supplied, skipping the spoken form '
prior
Found feed: 
min_popularity
power_scale
prior_field
text_fields
date_field
Loading from 
Number of output lattice states is getting out of hand, aborting conversion
Could not find arc for input_state 
 olabel 
 in LM. Failed to reconstruct lattice (incompatible LM?).
Acoustic model file
Phone table file
optional-silence
Optional silence phone
silence-prob
Silence probability (0.0 to 1.0)
Word boundary file
align-lattice-expand-limit
Lattice expansion limit when doing word alignment(0 for none)
reconstruct-lattice-expand-limit
Lattice expansion limit when doing lattice reconstruction(0 for none)
big-g-fst-file
Negative SmallG FST filename
raw-smallg-fst-file
SmallG FST (with no phone or word loops for nonterminals) filename
extended-report
Set to false if only the concise error-report should be generated.
lm-context-length
Language model context length (e.g. 4-gram has length 3)
overlap-percentage
Required overlap in percent of two regions in reference and hypothesis to be viewed as the same region.
json-output-format
True if error reports should be formatted as JSON file.
You have not specified unpronounced-word-file. This will prevent you from using class LM tags 
like \CS-GeoBizName-start and \CS-GeoBizName-end in the ref transcription for error blamer. 
Created lexicon FST
WORD-DIS-
 phone words (including word disambig symbols) in base word table
inv-g-fst-file is now ignored because it does not work with class LMs. 
Please use raw-smallg-fst-file.
The number of big FST LMs + NN LMs doesn't match the number of weights (FST LMs + NN LMs)
Word alignment failed.
Word alignment lattice empty.
Lattice reconstruction failed.
 not found in symbol table(s).
 has word ID 0.
Ref transcription word: 
, ID: 
HypoStartFrame
HypoEndFrame
RefStartFrame
RefEndFrame
RefLmCost
HypoLmCost
RefAmCost
HypoAmCost
RefWords
HypoWords
Confusions
RefModel
HypoModel
RefPhone
HypoPhone
Word
StartFrame
EndFrame
LmCost
AmCost
RefTotalCost
HypoTotalCost
RefGraphCost
HypoGraphCost
Attributes
ErrorRegions
PresentInLattice
RankInLattice
Recoverable
AmScaleFactorToRecover
ReferenceInfo
No reference transcription provided.
no first pass LM defined
total number of LMs is 
, but the number of interpolation weights is 
Left context labels not yet implemented.
Failed to map compound LME words. LME data is probably corrupt.
Could not map all words to symbol ids.
failed-words
Failed to create decoding graph.
 Hint: Are all the ref words in the pron lexicon?
Encountered problem while creating decoding graph for reference.
Retrying utterance with beam 
Problem decoding utterance for forced alignment.
Encountered problem while force aligning the reference.
Word alignment failed for reference lattice. Aborting error-blaming.
Encountered problem while word-aligning the reference lattice.
Reference lattice reconstruction failed. Aborting error-blaming.
Encountered problem while reconstructing the reference lattice.
Word alignment failed for hypothesis lattice. Aborting error-blaming.
Encountered problem while word-aligning the hypothesis lattice.
Hypothesis lattice reconstruction failed.
Encountered problem while reconstructing the hypothesis lattice.
LM rescoring in error-blamer was not successful.
LM rescoring was not successful.
Lattice reconstruction with smallG failed.
Encountered problem while trying to reconstruct lattices with smallG.
smallG
transition-scale
Scale of transition probabilities (excluding self-loops)
self-loop-scale
Scale of self-loop vs. non-self-loop probability mass 
Reorder transition ids for greater decoding efficiency.
rm-eps
Remove [most] epsilons before minimization (only applicable if disambig symbols present)
Unable to parse input string.
Pre-alignment tokens not monotonic.
Aligner failed. There is a BUG. FIX THIS!!!
 alignment=
 src=[
] dest=[
Hammer rewrite failed.
@[a-z]*#|#[a-z]*@
Unsupported model format version.
LM-SCORE-DEBUG: beam 
 E2E 
 LM 
0-th beam failed
seeva
SeevaModel/__QNNI__coverage_penalty_weight
SeevaModel/__QNNI__minimum_input_count
SeevaModel/__QNNI__minimum_input_left
SeevaModel/__QNNI__minimum_alignment_weight
SeevaModel/__QNNI__minimum_peak_alignment
SeevaModel/__QNNI__stable_tokens
SeevaModel/__QNNI__utt_end_beam
SeevaModel/__QNNI__trace_back
SeevaModel/decoder/__QNNO__nbest_list
SeevaModel/decoder/__QNNO__nbest_score
SeevaModel/decoder/__QNNO__graph_reset
SeevaModel/decoder/__QNNO__partial_result
SeevaModel/decoder/__QNNO__encoder_only
SeevaModel/__QNNI__lme_fst_header
SeevaModel/__QNNI__lme_fst_states
SeevaModel/__QNNI__lme_fst_arcs
SeevaModel/__QNNI__lme_score_scale
SeevaModel/__QNNI__nonlme_score_scale
Version mismatch for PronChoice
Unknown format for pronunciation string
Empty pronunciations for one of the tokens. Exiting with 0 pron combinations.
pron combination = 
, logWeight = 
Cycles detected in lattice
Invalid lattice: different paths have a different number of frames
Utterance does not seem to have a consistent length.
Utterance does not have a final-state.
Invalid lattice: final state before max_time
Topological sorting failed
Done Topo Sort
Failure in best-path algorithm for lattice (infinite costs?)
Add 
 ilabel 
 usedarcind 
 weight 
Rescoring empty lattice
the DeterministicOnDemandFst is invalid
invalid arc.olabel 
cannot find arc with label 
 on state 
 in the LM FST, wrong input?
POSITION = 
 FROM: 
 TO: 
 WORD = 
 PROB = 
 EXPANDPROB = 
class expansion contains no words
%s %lf
varprune
pruning threshold for variable order ngrams
debugging level for LM
recompute
recompute lower-order counts by summation
sort
sort ngrams output
write-order
output ngram counts order
file tag to use in messages
text file to read
text-has-weights
text file contains count weights
counts file to read
intersect
intersect counts with this file
read-with-mincounts
apply minimum counts when reading counts file
read-google
Google counts directory to read
counts file to write
write1
1gram counts file to write
write2
2gram counts file to write
write3
3gram counts file to write
write4
4gram counts file to write
write5
5gram counts file to write
write6
6gram counts file to write
write7
7gram counts file to write
write8
8gram counts file to write
write9
9gram counts file to write
write-binary
binary counts file to write
lower GT discounting cutoff
upper GT discounting cutoff
gt1min
lower 1gram discounting cutoff
gt1max
upper 1gram discounting cutoff
gt2min
lower 2gram discounting cutoff
gt2max
upper 2gram discounting cutoff
gt3min
lower 3gram discounting cutoff
gt3max
upper 3gram discounting cutoff
gt4min
lower 4gram discounting cutoff
gt4max
upper 4gram discounting cutoff
gt5min
lower 5gram discounting cutoff
gt5max
upper 5gram discounting cutoff
gt6min
lower 6gram discounting cutoff
gt6max
upper 6gram discounting cutoff
gt7min
lower 7gram discounting cutoff
gt7max
upper 7gram discounting cutoff
gt8min
lower 8gram discounting cutoff
gt8max
upper 8gram discounting cutoff
gt9min
lower 9gram discounting cutoff
gt9max
upper 9gram discounting cutoff
Good-Turing discount parameter file
Good-Turing 1gram discounts
Good-Turing 2gram discounts
Good-Turing 3gram discounts
Good-Turing 4gram discounts
Good-Turing 5gram discounts
Good-Turing 6gram discounts
Good-Turing 7gram discounts
Good-Turing 8gram discounts
Good-Turing 9gram discounts
discounting constant
cdiscount1
1gram discounting constant
cdiscount2
2gram discounting constant
cdiscount3
3gram discounting constant
cdiscount4
4gram discounting constant
cdiscount5
5gram discounting constant
cdiscount6
6gram discounting constant
cdiscount7
7gram discounting constant
cdiscount8
8gram discounting constant
cdiscount9
9gram discounting constant
use natural discounting
ndiscount1
1gram natural discounting
ndiscount2
2gram natural discounting
ndiscount3
3gram natural discounting
ndiscount4
4gram natural discounting
ndiscount5
5gram natural discounting
ndiscount6
6gram natural discounting
ndiscount7
7gram natural discounting
ndiscount8
8gram natural discounting
ndiscount9
9gram natural discounting
addsmooth
additive smoothing constant
addsmooth1
1gram additive smoothing constant
addsmooth2
2gram additive smoothing constant
addsmooth3
3gram additive smoothing constant
addsmooth4
4gram additive smoothing constant
addsmooth5
5gram additive smoothing constant
addsmooth6
6gram additive smoothing constant
addsmooth7
7gram additive smoothing constant
addsmooth8
8gram additive smoothing constant
addsmooth9
9gram additive smoothing constant
use Witten-Bell discounting
wbdiscount1
1gram Witten-Bell discounting
wbdiscount2
2gram Witten-Bell discounting
wbdiscount3
3gram Witten-Bell discounting
wbdiscount4
4gram Witten-Bell discounting
wbdiscount5
5gram Witten-Bell discounting
wbdiscount6
6gram Witten-Bell discounting
wbdiscount7
7gram Witten-Bell discounting
wbdiscount8
8gram Witten-Bell discounting
wbdiscount9
9gram Witten-Bell discounting
use modified Kneser-Ney discounting
kndiscount1
1gram modified Kneser-Ney discounting
kndiscount2
2gram modified Kneser-Ney discounting
kndiscount3
3gram modified Kneser-Ney discounting
kndiscount4
4gram modified Kneser-Ney discounting
kndiscount5
5gram modified Kneser-Ney discounting
kndiscount6
6gram modified Kneser-Ney discounting
kndiscount7
7gram modified Kneser-Ney discounting
kndiscount8
8gram modified Kneser-Ney discounting
kndiscount9
9gram modified Kneser-Ney discounting
use original Kneser-Ney discounting
ukndiscount1
1gram original Kneser-Ney discounting
ukndiscount2
2gram original Kneser-Ney discounting
ukndiscount3
3gram original Kneser-Ney discounting
ukndiscount4
4gram original Kneser-Ney discounting
ukndiscount5
5gram original Kneser-Ney discounting
ukndiscount6
6gram original Kneser-Ney discounting
ukndiscount7
7gram original Kneser-Ney discounting
ukndiscount8
8gram original Kneser-Ney discounting
ukndiscount9
9gram original Kneser-Ney discounting
Kneser-Ney discount parameter file
Kneser-Ney 1gram discounts
Kneser-Ney 2gram discounts
Kneser-Ney 3gram discounts
Kneser-Ney 4gram discounts
Kneser-Ney 5gram discounts
Kneser-Ney 6gram discounts
Kneser-Ney 7gram discounts
Kneser-Ney 8gram discounts
Kneser-Ney 9gram discounts
input counts already modified for KN smoothing
kn-modify-counts-at-end
modify counts after discount estimation rather than before
use interpolated estimates
interpolate1
use interpolated 1gram estimates
interpolate2
use interpolated 2gram estimates
interpolate3
use interpolated 3gram estimates
interpolate4
use interpolated 4gram estimates
interpolate5
use interpolated 5gram estimates
interpolate6
use interpolated 6gram estimates
interpolate7
use interpolated 7gram estimates
interpolate8
use interpolated 8gram estimates
interpolate9
use interpolated 9gram estimates
LM to estimate
write-binary-lm
output LM in binary format
init-lm
initial LM for EM estimation
keep <unk> in LM
meta-tag
meta tag used to input count-of-count information
use fractional counts
closed-form-doug-paul-hack
use a closed-form formula for the Doug Paul Hack
build a tagged LM
train a count-based LM
build a skip N-gram LM
skip-init
default initial skip probability
em-iters
max number of EM iterations
em-delta
min log likelihood delta for EM
Estimate maximum entropy model
maxent-alpha
The L1 regularisation constant for max-ent estimation
maxent-sigma2
The L2 regularisation constant for max-ent estimation (default: 6 for estimation, 0.5 for adaptation)
Save estimated max-ent model as a regular ARPA backoff model
trust-totals
trust lower-order counts for estimation
limit count reading to specified vocabulary
write vocab to file
write-vocab-index
write vocab index map to file
the default action is to write counts to stdout
fractional counts, variable, tagged, stop-word Ngram and skip N-gram models are mutually exclusive
conflicting default discounting options
option tagged not yet supported when providing external Vocab
error reading Google counts from 
LM order must be positive -- set to 1
conflicting discounting options for order 
using NaturalDiscount for 
using WittenBell for 
using ConstDiscount for 
using AddSmooth for 
using KneserNey for 
using ModKneserNey for 
using GoodTuring for 
error in reading discount parameter file 
error in discount estimator for order 
Closed-form Doug Paul Hack is not supported in combination with a count-based LM.
format error in init-lm file
count-lm estimation needs initial model
cannot use -float-counts with count-lm
LM estimation failed
Closed-form Doug Paul Hack is not supported in combination with a maximum-entropy LM.
format error in maxent prior (-init-lm) file
Maxent LM estimation failed
opts_.max_utt_trailing_sil_frames >= 0
opts_.max_utt_frames >= opts_.max_utt_trailing_sil_frames
values
Map of <int, float>. Example: {"8000": 1, "16000": 0}
: Cannot find key: 
Unknown location
Building appendable feature 
sampling-rate
location
Unknown appendable feature: 
Rejected client conf network due to invalid HatText encoding
Stored conf network!
regular expression replacer in: 
regular expression replacer out: 
Only (global) replacement operations are supported, got 
 with specifier 
read expression: "
", mapping to "
RegularExpressionReplacer read in 
 regular expressions
Begin
Both
None
Unknown AddTag format
bothAsOne
bothasone
bothSeparate
bothseparate
Unknown tag format 
Pushing weights of empty compact lattice
Lattice has non-coaccessible states.
Encountered unexpected number of enumerations: 
Sanitizer already initialized.
Initialized Sanitizer
The model is not of type nnet1::Nnet1InferenceNet.
Neural net file
!\exclamation-mark
,\comma
.\period
;\semicolon
:\colon
?\question-mark
I\pronoun
v40@?0@"NSString"8{_NSRange=QQ}16^B32
order %u
mixweights %u
 %lg
countmodulus %s
vocabsize %s
totalcount %s
counts -
google-counts %s
counts %s
order %u
vocabsize %99s
totalcount %99s
countmodulus %99s
mixweights %u
premature end to mixture weights
%lg%n
incomplete mixture weight vector
counts %1023s
google-counts %1023s
warning: zero denominator count for ngram 
posterior counts 
warning: no data to estimate mixture weight 
for count 
, order 
Supplied utterance id is out of bounds
RefDurations
HypoDurations
Reference
Hypothesis
RefTotalScore
HypoTotalScore
RefAmScore
HypoAmScore
Reference is not in hypo lattice
Reference is in hypo lattice (Rank: 
) and 
cannot be recovered
can be recovered by multiplying the current acoustic-scale with 
Not able to convert given phone_id 
, check if given phone symbol table is the correct one.
HOTFIX
fst_custom.fst
decoders
lattice-biglm-lme-faster.big-g-fst-file-list
big-g-fst-file-list not found for decoder 
 skipping..
lattice-biglm-lme-faster.word-syms-map-file
Symbol-table file not found in json file 
1shot_new.json
{{TEMPLATE}}
\NT-unknown
Failed to tokenize
Tokenizer could not tokenize
template list not found for used template 
template list not found for used template: 
template names should be enclosed in {} and contain only one word (lowercase)
Number of OOVs = 
No OOVs
could not get LME data
Template names should be enclosed in {} and contain only one word (in lowercase)
No templates provided
Template names should be enclosed in {} and contain only one word
Template list found more than once for : 
Input FST is cyclic
Could not write fst to file path 
Could not write fst to file
print version information and exit
adapt-order
maximum n-gram order for which adaptation is to be performed [default is 3]
lm-order
n-gram order of the LM to be adapted (passed via -read-lm option) [default is 3]
read-text
text file of adaptation data. Only n-gram counts up to the order passed via -adapt-order will be generated from this file
indicates that text file passed via -read-text or -read-dev contains count weights
read-counts
counts file of adaptation data. Only n-gram counts up to the order passed via -adapt-order will be read from this file
adaptation weight. It will be used for all n-gram orders for which no -eta(n) is provided
eta1
adaptation weight for 1-grams
eta2
adaptation weight for 2-grams
eta3
adaptation weight for 3-grams
eta4
adaptation weight for 4-grams
eta5
adaptation weight for 5-grams
eta6
adaptation weight for 6-grams
eta7
adaptation weight for 7-grams
eta8
adaptation weight for 8-grams
eta9
adaptation weight for 9-grams
read-lm
LM file to be adapted. This is an LM file in ARPA text or binary format
output adapted LM file. This is an ARPA LM in text or binary format, see -write-binary-lm [default is text format]
indicates that the output adapted LM file passed via -write-lm will be written in binary format
dont-trust-totals
do not trust lower-order counts for adaptation, recompute from the higher-order counts [default is to trust lower-order counts]
read-dev
text file of dev data used to optimize eta. If provided, the optimized eta will be used for all orders and thus override all -eta or -eta(n) options
max-eta
maximum possible value of eta. It's only used when -read-dev is provided to set the maximum value of optimized eta
adaptation order must be >= 1 and <= 
, use -adapt-order with a relevant value
no adaptation text or counts are provided, use -read-text and/or -read-counts option
-textFileHasWeights option will be ignored as no input text option is provided (use -read-text)
no input lm file is provided, use -read-lm option
command-line (read-lm) and custom-lm config options cannot be mixed.
command-line (write-lm) and custom-lm config options cannot be mixed.
Vocab file (option -vocab) not provided, reading vocabulary from ARPA
format error in lm file
Ignoring Vocab file (option -vocab) when taking Vocab from LmData
Warning: Provided a ctx.vocabIter (ignored) when taking Vocab from LmData
text file 
 looks empty or has only invalid lines
only plain text or phrase counts supported for dev data
Eta optimization failed
optimized eta = 
, used for orders 1 to 
-gram adaptation weight must be >= 0.0 and < 1.0, use -eta option with a relevant value
or -read-dev option to provide dev data for optimizing eta
LM adaptation failed
adapted LM written to 
Unable to instantiate a translator factory
Unable to instantiate translator factory
No translation configurations given, cannot instantiate translator
Unable to instantiate translator
Step name must be 
mutually-exclusive-group
from
validate-brackets
validate-brackets will be overwritten by validate-brackets = 
(?i)
Rule file supplied is invalid: 
file
Read sub-rule config file = 
Failed to load sub-rule file = 
split-case-sensitive
max-alt
max-alt will be overwritten by max-alt = 
split-case-sensitive will be overwritten by split-case-sensitive = 
\g<0>
Gender
inflections
multiword-inflections
Error parsing multiword inflections: expected list of words.
Error parsing multiword inflection, too many inflection alternatives.
Invalid inflection: 
Unmatched words in one of the alternatives
Expected female sentence, got: '
Expected male sentence, got: '
No hypotheses, sending empty list.
Already found higher scoring gender alternatives, ignoring new alternatives.
Last sentence in NBest list is an unpaired gender alternative, ignoring.
Expected gendered sentence, got: '
Found valid gender alternatives.
Non matching gender alternatives, ignoring the second alternative.
Non-gendered sentence, keeping.
WARNING: asking to round a value to 0 significant figures makes no sense 
 answer is 0.
total
Task 
 not found in config
Multiple decoder chains for task 
Decoder chain 
 not found in config for task 
.ptoks
read in partial tokens  
finished 
 beam search steps at frame 
finished the last 
 beam search steps
SeevaModel/encoder/__QNNO__encoder_output
SeevaModel/encoder/__QNNI__encoder_state_
SeevaModel/encoder/__QNNO__encoder_state_
SeevaModel/__QNNI__target_input
SeevaModel/__QNNI__encoder_output
SeevaModel/decoder/__QNNO__decoder_full_score
SeevaModel/decoder/__QNNI__decoder_state_
SeevaModel/decoder/__QNNO__decoder_state_
Empty silence phones
NaturalLess: Weight type is not idempotent: 
DeterminizeFst: Weight needs to have the 
path property to disambiguate output: 
Unrecognized commandId=
\all-caps
\cap
\spelling-cap
\no-caps
\no-space
\new-line
\new-paragraph
.\period-paragraph
\tab-key
\no-break-space
\spelling-no-break-space
\space-bar
\backslash
\spelling-backslash
ucasemap_utf8ToUpper failed
ucasemap_utf8ToTitle failed
Reading SimplerSimpleRecurrentUnit component
<InputTransform>
reading input transform network failed
<c_0>
</SimplerSimpleRecurrentUnit>
Another recurrent neural networks are not supported inside SSRU component.
ResetHistoryState for SimplerSimpleRecurrentUnit makes only sense if all utterances get reset at the same time
./background_power_%ld.log
./runtime_power_%ld.log
Sampling background power consumption for %d seconds 
%@ -fi 1 -G PMP > %@
(turning off PMP because it's unavailable, power measurements might be less accurate) 
%@ -fi 1 > %@
%@ -ft -G PMP > %@
%@ -ft > %@
killall %@
jetsam max
jetsam average
max rss
units
memory
CPU time
ANE time
perf
total energy
ANE energy
GPU energy
DRAM energy
ECPU energy
PCPU energy
other energy
energy
mean background power
std background power
total power
ANE power
GPU power
DRAM power
ECPU power
PCPU power
other power
power
================ Profiler Summary ===============
|             |  Jetsam  |    Peak   |  Average |
|             |          |  %7.2f  | %7.2f  |
| Memory (MB) -----------------------------------
|             |  MAX_RSS |    Peak   |     -    |
|             |          |  %7.2f  |          |
=================================================
| Time (s)    |    CPU   |    GPU    |    ANE*  |
|             | %7.2f  |      -    | %7.2f  |
=================================================
| * ANE time unavailable for CoreML networks.   |
=================================================
| Background  |   Idle   |  Average  |   std    |
| Power* (mW) |          |   %5.1f   |  %5.1f   |
| %s     -----------------------------------
|             |  Total  |  ANE  |  GPU  |  DRAM |
|             |  %6.2f | %5.1f | %5.1f | %5.1f |
| Energy (J)  -----------------------------------
| %s     |         |  ECPU |  PCPU | OTHER |
|             |         | %5.1f | %5.1f | %5.1f |
|             -----------------------------------
|             |  Total  |  ANE  |  GPU  |  DRAM |
|             |   %5d |  %4d |  %4d |  %4d |
| Power (mW)  -----------------------------------
| %s     |         |  ECPU |  PCPU | OTHER |
| ^           |         |  %4d |  %4d |  %4d |
=================================================
| * If Idle power consumption is significant,   |
|   try enabling one of the power settings      |
|   recommended  above and kill any daemon(s)   |
|   that are not needed by transcribe.          |
| ^ Power measurements can be inaccurate on     |
|   short audios and/or new hardwares.          |
=================================================
via PMP
non-PMP
rm %@ %@
---> 
---> Energy Counters
=> Energy Model
ECPU
ECORE
PCPU
PCORE
DRAM
Warning: failed to parse log file %s
/dev/null
/bin/bash
/usr/bin/sudo
Warning: Could not get ledger info for pid.
Warning: Could not get ledger info for pid
phys_footprint
Warning: Could not get ledger entry info for pid
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/agent.cc
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/agent.cc:13: MARISA_NULL_ERROR: str == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/agent.cc:36: MARISA_STATE_ERROR: state_.get() != NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/agent.cc:38: MARISA_MEMORY_ERROR: state_.get() == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/include/marisa/scoped-ptr.h
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/include/marisa/scoped-ptr.h:19: MARISA_RESET_ERROR: (ptr != NULL) && (ptr == ptr_)
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/io/mapper.cc
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/io/mapper.cc:63: MARISA_NULL_ERROR: (ptr == NULL) && (size != 0)
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/io/mapper.cc:71: MARISA_STATE_ERROR: !is_open()
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/io/mapper.cc:72: MARISA_IO_ERROR: size > avail_
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/io/mapper.cc:99: MARISA_STATE_ERROR: !is_open()
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/io/mapper.cc:100: MARISA_IO_ERROR: size > avail_
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/trie/louds-trie.cc
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/trie/louds-trie.cc:73: MARISA_BOUND_ERROR: agent.query().id() >= size()
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/trie/louds-trie.cc:451: MARISA_MEMORY_ERROR: next_trie_.get() == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/trie/louds-trie.cc:468: MARISA_MEMORY_ERROR: next_trie_.get() == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/trie/louds-trie.cc:542: MARISA_MEMORY_ERROR: next_trie_.get() == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/trie/config.h
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/trie/config.h:59: MARISA_CODE_ERROR: (config_flags & ~MARISA_CONFIG_MASK) != 0
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/trie/config.h:101: MARISA_CODE_ERROR: undefined cache level
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/trie/config.h:121: MARISA_CODE_ERROR: undefined tail mode
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/trie/config.h:141: MARISA_CODE_ERROR: undefined node order
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/trie/header.h
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/trie/header.h:21: MARISA_FORMAT_ERROR: !test_header(ptr)
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/trie/../io/mapper.h
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/trie/../io/mapper.h:28: MARISA_NULL_ERROR: (objs == NULL) && (num_objs != 0)
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/trie/../io/mapper.h:30: MARISA_SIZE_ERROR: num_objs > (MARISA_SIZE_MAX / sizeof(T))
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/trie/../vector/bit-vector.h
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/trie/../vector/bit-vector.h:52: MARISA_SIZE_ERROR: size_ == MARISA_UINT32_MAX
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/trie/../vector/vector.h
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/trie/../vector/vector.h:100: MARISA_STATE_ERROR: fixed_
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/trie/../vector/bit-vector.h:135: MARISA_FORMAT_ERROR: temp_num_1s > size_
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/trie/../vector/vector.h:202: MARISA_FORMAT_ERROR: (total_size % sizeof(T)) != 0
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/trie/../vector/vector.h:107: MARISA_STATE_ERROR: fixed_
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/trie/../vector/flat-vector.h
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/trie/../vector/flat-vector.h:134: MARISA_FORMAT_ERROR: temp_value_size > 32
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/trie/louds-trie.cc:428: MARISA_MEMORY_ERROR: std::bad_alloc
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/trie/tail.cc
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/trie/tail.cc:13: MARISA_NULL_ERROR: offsets == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/trie/tail.cc:36: MARISA_CODE_ERROR: undefined tail mode
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/trie/tail.cc:170: MARISA_RANGE_ERROR: current.length() == 0
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/trie/tail.cc:192: MARISA_SIZE_ERROR: buf_.size() > MARISA_UINT32_MAX
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/vector/vector.h
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/grimoire/vector/vector.h:100: MARISA_STATE_ERROR: fixed_
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/keyset.cc
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/keyset.cc:50: MARISA_NULL_ERROR: str == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/keyset.cc:61: MARISA_NULL_ERROR: (ptr == NULL) && (length != 0)
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/keyset.cc:62: MARISA_SIZE_ERROR: length > MARISA_UINT32_MAX
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/keyset.cc:129: MARISA_MEMORY_ERROR: new_blocks.get() == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/keyset.cc:138: MARISA_MEMORY_ERROR: new_block.get() == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/keyset.cc:151: MARISA_MEMORY_ERROR: new_blocks.get() == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/keyset.cc:159: MARISA_MEMORY_ERROR: new_block.get() == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/keyset.cc:169: MARISA_MEMORY_ERROR: new_blocks.get() == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/keyset.cc:177: MARISA_MEMORY_ERROR: new_block.get() == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/trie.cc
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/trie.cc:14: MARISA_MEMORY_ERROR: temp.get() == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/trie.cc:33: MARISA_NULL_ERROR: (ptr == NULL) && (size != 0)
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/lib/marisa/trie.cc:36: MARISA_MEMORY_ERROR: temp.get() == NULL
/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/libquasar/libsentencepiece/src/bpe_model.cc
(index) >= (0)
(index) < (static_cast<int>(symbols.size()))
/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/libquasar/libsentencepiece/src/builtin_pb/sentencepiece.pb.cc
sentencepiece.SentencePieceText.SentencePiece
sentencepiece.SentencePieceText
sentencepiece.NBestSentencePieceText
<pad>
/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/libquasar/libsentencepiece/src/builtin_pb/sentencepiece_model.pb.cc
sentencepiece.TrainerSpec
sentencepiece.NormalizerSpec
sentencepiece.SelfTestData.Sample
sentencepiece.SelfTestData
sentencepiece.ModelProto.SentencePiece
sentencepiece.ModelProto
Program terminated with an unrecoverable error.
Cancelled
Invalid argument
Deadline exceeded
Not found
Already exists
Permission denied
Unauthenticated
Failed precondition
Aborted
Out of range
Internal
Unavailable
Data loss
/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/libquasar/libsentencepiece/src/filesystem.cc
ReadAll is not supported for stdin.
/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/libquasar/libsentencepiece/src/model_factory.cc
Unknown model_type: 
piece must not be empty.
 is already defined.
unk is already defined.
byte piece 
 is found although `byte_fallback` is false.
 is invalid.
unk is not defined.
there are not 256 byte pieces although `byte_fallback` is true.
<0x%02X>
src/model_interface.h
Not implemented.
/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/libquasar/libsentencepiece/src/normalizer.cc
precompiled_charsmap is empty. use identity normalization.
(length) >= (0)
(norm_to_orig->size()) == (normalized->size() + 1)
Blob for normalization rule is broken.
Trie data size exceeds the input blob size.
(0) == (trie_->build(key.size(), const_cast<char **>(&key[0]), nullptr, nullptr))
src/util.h
'result' Must be non NULL
../libsentencepiece/third_party/darts_clone/darts.h:703: exception: failed to resize pool: std::bad_alloc
../libsentencepiece/third_party/darts_clone/darts.h:1141: exception: failed to insert key: negative value
../libsentencepiece/third_party/darts_clone/darts.h:1143: exception: failed to insert key: zero-length key
../libsentencepiece/third_party/darts_clone/darts.h:1157: exception: failed to insert key: invalid null character
../libsentencepiece/third_party/darts_clone/darts.h:1162: exception: failed to insert key: wrong key order
../libsentencepiece/third_party/darts_clone/darts.h:842: exception: failed to build rank index: std::bad_alloc
../libsentencepiece/third_party/darts_clone/darts.h:1380: exception: failed to modify unit: too large offset
../libsentencepiece/third_party/darts_clone/darts.h:1726: exception: failed to build double-array: invalid null character
../libsentencepiece/third_party/darts_clone/darts.h:1728: exception: failed to build double-array: negative value
../libsentencepiece/third_party/darts_clone/darts.h:1743: exception: failed to build double-array: wrong key order
/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/libquasar/libsentencepiece/src/sentencepiece_processor.cc
_status.ok()
model_proto->ParseFromArray(serialized.data(), serialized.size())
LOG(
 samples did not pass the test.
Self-test failures. See LOG(INFO).
model_
Model is not initialized.
normalizer_
Normalizer is not initialized.
type == TrainerSpec::UNIGRAM || type == TrainerSpec::BPE
Vocabulary constraint is only enabled in subword units.
(v.size()) >= (1)
!v[0].empty()
absl::SimpleAtoi(v[1], &freq)
Could not parse the frequency
pieces
output container is null
detokenized
!w.empty()
Empty piece is not allowed.
(begin) < (norm_to_orig.size())
(end) < (norm_to_orig.size())
(orig_begin) <= (input.size())
(orig_end) <= (input.size())
(orig_begin) <= (orig_end)
(consumed) == (normalized.size())
all normalized characters are not consumed.
output proto is null
nbest_spt
model_->IsNBestEncodeAvailable()
NBestEncode is not available for the current model.
!nbests.empty()
NBestEncode returns empty result.
(nbest_size) <= (512)
nbest_size must be nbest_size <= 512
model_->IsSampleEncodeAvailable()
SampleEncode is not available for the current model.
model_->IsSampleEncodeAndScoreAvailable()
SampleEncodeAndScore is not available for the current model.
!results.empty()
SampleEncodeAndScore returns empty result.
model_->IsCalculateEntropyAvailable()
CalculateEntropy is not available for the current model.
Invalid id: 
Returns default value 
unknown extra_option type.
it != extra_option_map.end()
option "
" is not available.
!IsUnknown(PieceToId(absl::string_view(model_->bos_piece().data())))
id for `
` is not defined.
!IsUnknown(PieceToId(absl::string_view(model_->eos_piece().data())))
model file path should not be empty.
input->ReadAll(&serialized)
(0) <= (byte)
(consumed) == (1)
(token_index_begin + offset) == (token_index_end)
/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/libquasar/libsentencepiece/src/unigram_model.cc
Failed to find the best path in Viterbi.
nbest_size >= 1. Returns empty result.
Too big agenda. shrinking
(num_nodes) < (trie_results.size())
no pieces are loaded.
cannot build double-array.
no entry is found in the trie.
include_best not supported for wor false
removing best path from samples
Two sentence piece sequences are not equivalent! Left: 
, Score: 
. Right: 
 Error #
third_party/protobuf-lite/google/protobuf/parse_context.h
Can't happen
/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/libquasar/libsentencepiece/third_party/protobuf-lite/arena.cc
CHECK failed: (min_bytes) <= (std::numeric_limits<size_t>::max() - kBlockHeaderSize): 
/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/libquasar/libsentencepiece/third_party/protobuf-lite/common.cc
This program requires version 
 of the Protocol Buffer runtime library, but the installed version is 
.  Please update your library.  If you compiled the program yourself, make sure that your headers are from the same version of Protocol Buffers as your link-time library.  (Version verification failed in "
This program was compiled against version 
 of the Protocol Buffer runtime library, which is not compatible with the installed version (
).  Contact the program author for an update.  If you compiled the program yourself, make sure that your headers are from the same version of Protocol Buffers as your link-time library.  (Version verification failed in "
%d.%d.%d
[libprotobuf %s %s:%d] %s
/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/libquasar/libsentencepiece/third_party/protobuf-lite/extension_set.cc
Non-primitive types can't be packed.
can't reach here.
third_party/protobuf-lite/google/protobuf/extension_set_inl.h
/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/libquasar/libsentencepiece/third_party/protobuf-lite/generated_message_util.cc
CHECK failed: (scc->visit_status.load(std::memory_order_relaxed)) == (SCCInfoBase::kRunning): 
(cannot determine missing fields for lite message)
/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/libquasar/libsentencepiece/third_party/protobuf-lite/message_lite.cc
parse
 exceeded maximum protobuf size of 2GB: 
Can't 
 message of type "
" because it is missing required fields: 
N6quasar6Bitmap21CoordinatesOutOfRangeE
N6quasar6BitmapE
N6quasar12BitmapLoaderE
N5kaldi6quasar14CEInferenceNetE
N6quasar18PersonalizedLmDataE
N3fst8SccQueueIiNS_9QueueBaseIiEEEE
N5kaldi6quasar18OnlineLASDecodableE
N5kaldi6quasar29OnlineLASSpeculativeDecodableE
MbP?
N5kaldi18OnlinePitchFeatureE
N3fst15MemoryArenaBaseE
N3fst14MemoryPoolBaseE
AN6quasar33OnlineLatticeWordAlignmentDecoderE
~*?N3fst9ImplToFstINS_14CompactFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_19UnweightedCompactorIS5_EEjNS_19DefaultCompactStoreINSt3__14pairINSA_IiiEEiEEjEEEENS_11ExpandedFstIS5_EEEE
"(9DJPV^djq
NSt3__120__shared_ptr_emplaceIN6quasar8DataFeedENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_pointerIPN6quasar13TextTokenizerENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN6quasar13TextTokenizerEEE
NSt3__120__shared_ptr_emplaceIN6quasar9PMBuilderENS_9allocatorIS2_EEEE
N5kaldi5nnet131BidirectionalRecurrentComponentE
N6quasar2lm11fst_builder10FstBuilderIN3fst6ArcTplINS3_17TropicalWeightTplIfEEEEEE
N6quasar2lm11fst_builder17MutableFstBuilderIN3fst6ArcTplINS3_17TropicalWeightTplIfEEEEEE
N6quasar2lm11fst_builder18SqueezedFstBuilderIN3fst6ArcTplINS3_17TropicalWeightTplIfEEEELb1ELb0EEE
N6quasar2lm11fst_builder18SqueezedFstBuilderIN3fst6ArcTplINS3_17TropicalWeightTplIfEEEELb0ELb0EEE
?333333
333333
N6quasar20RecogAudioBufferBaseE
N6quasar9AppLmDataE
NSt3__120__shared_ptr_emplaceIN6quasar14LmeDataFactoryENS_9allocatorIS2_EEEE
N6quasar17WatermarkDetectorE
15NaturalDiscount
9KneserNey
12ModKneserNey
10GoodTuring
Yuuu4Y
9NSt3__16__nodeIcEE
NSt3__110shared_ptrINS_13__empty_stateIcEEE27__shared_ptr_default_deleteIS2_S2_EE
NSt3__114default_deleteINS_13__empty_stateIcEEEE
NSt3__116__owns_one_stateIcEE
NSt3__115__has_one_stateIcEE
NSt3__118__match_char_icaseIcNS_12regex_traitsIcEEEE
NSt3__112__match_charIcEE
NSt3__116__back_ref_icaseIcNS_12regex_traitsIcEEEE
NSt3__110__back_refIcEE
NSt3__120__bracket_expressionIcNS_12regex_traitsIcEEEE
NSt3__117__owns_two_statesIcEE
NSt3__111__alternateIcEE
NSt3__111__match_anyIcEE
".cc
OU\N5kaldi17ContextDependencyE
NSt3__120__shared_ptr_emplaceIKN5kaldi5TimerENS_9allocatorIS3_EEEE
"E)0NSt3__120__shared_ptr_emplaceIN6quasar21NgramSrilmCountConfigENS_9allocatorIS2_EEEE
N5boost13property_tree11ptree_errorE
N5boost16exception_detail10clone_baseE
N5boost16exception_detail10clone_implINS0_19error_info_injectorINS_13property_tree11json_parser17json_parser_errorEEEEE
N5boost16exception_detail19error_info_injectorINS_13property_tree11json_parser17json_parser_errorEEE
N5boost13property_tree11json_parser17json_parser_errorE
N5boost13property_tree17file_parser_errorE
N5kaldi5nnet19LayerNormE
N6quasar14HwcnConfidenceE
NSt3__120__shared_ptr_emplaceIN6marisa4TrieENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi6MatrixIfEENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar22WlatArcFeWordEmbeddingENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar14WlatArcFeIsLmeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar14WlatArcFeLmeIdENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar14WlatArcFeIsSilENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar18WlatArcFeNumPhonesENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar29WlatArcFeAcousticCostUnpushedENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar19WlatArcFeInBestPathENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar21WlatArcFeAcousticCostENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar18WlatArcFeGraphCostENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar18WlatArcFeNumFramesENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar21WlatArcFeLogPosteriorENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar21WlatArcFeLinPosteriorENS_9allocatorIS2_EEEE
 +7zz
NSt3__120__shared_ptr_emplaceIN5kaldi5nnet14NnetENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar16MiscSharedConfigENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar19EndPointModelConfigENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar11EagerConfigENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar9GeographyENS_9allocatorIS2_EEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_17TropicalWeightTplIfEEEENSt3__19allocatorIS6_EEEEEENS_10MutableFstIS6_EEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_11ArcIteratorINS_3FstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEEE4LinkEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_21SequenceComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_23PushLabelsComposeFilterINS_24PushWeightsComposeFilterINS_22LookAheadComposeFilterINS_24AltSequenceComposeFilterINS_16LookAheadMatcherINS_3FstIS5_EEEESE_EESE_SE_LNS_9MatchTypeE2EEESE_SE_LSG_2EEESE_SE_LSG_2EEENS_24GenericComposeStateTableIS5_NS_15PairFilterStateINSL_INS_18IntegerFilterStateIaEENS_17WeightFilterStateIS4_EEEENSM_IiEEEENS_24DefaultComposeStateTupleIiSS_EENS_21CompactHashStateTableISU_NS_11ComposeHashISU_EEEEEEEE
N3fst13StateIteratorINS_10ComposeFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_17DefaultCacheStoreIS5_EEEEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_11VectorStateIS7_NSt3__19allocatorIS7_EEEEEEEE
N3fst14DeterminizeFstINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEE
N3fst18DeterminizeFsaImplINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_20DefaultCommonDivisorIS4_EENS_24DefaultDeterminizeFilterIS6_EENS_28DefaultDeterminizeStateTableIS6_NS_18IntegerFilterStateIaEEEEEE
N3fst22DeterminizeFstImplBaseINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEE
N3fst9CacheImplINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEE
N3fst13CacheBaseImplINS_10CacheStateINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENSt3__19allocatorIS7_EEEENS_17DefaultCacheStoreIS7_EEEE
N3fst13StateIteratorINS_14DeterminizeFstINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEEEE
N3fst18CacheStateIteratorINS_14DeterminizeFstINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEEEE
N3fst17StateIteratorBaseINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEE
N5kaldi5nnet124QuantizedAffineTransformIaEE
N5kaldi5nnet124QuantizedAffineTransformIsEE
N5kaldi5nnet115LinearTransformINS_12CuMatrixBaseIfEEEE
NSt3__120__shared_ptr_pointerIPN6quasar14LmeDataFactoryENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN6quasar14LmeDataFactoryEEE
NSt3__120__shared_ptr_pointerIPN6quasar14GlobalLRUCacheINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_6vectorIS8_NS6_IS8_EEEEEENS_14default_deleteISC_EENS6_ISC_EEEE
NSt3__114default_deleteIN6quasar14GlobalLRUCacheINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_6vectorIS8_NS6_IS8_EEEEEEEE
NSt3__120__shared_ptr_emplaceIN6quasar7LmeDataENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN3fst11SymbolTableENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceINS_14basic_ifstreamIcNS_11char_traitsIcEEEENS_9allocatorIS4_EEEE
NSt3__120__shared_ptr_emplaceINS_18basic_stringstreamIcNS_11char_traitsIcEENS_9allocatorIcEEEENS4_IS6_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar12LmeContainerENS_9allocatorIS2_EEEE
#/VV
BOHN6quasar37OnlineLASLmRescoringBeamSearchDecoderE
N3fst10MemoryPoolINS_8DfsStateINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEE
NSt3__120__shared_ptr_emplaceIN3fst18StdToLatticeMapperIfEENS_9allocatorIS3_EEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEENS2_INS_16LatticeWeightTplIfEEEENS_18StdToLatticeMapperIfEEEENS_3FstIS8_EEEE
N3fst13StateIteratorINS_9ArcMapFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS2_INS_16LatticeWeightTplIfEEEENS_18StdToLatticeMapperIfEEEEEE
NSt3__120__shared_ptr_pointerIPN3fst11SymbolTableENS_10shared_ptrIS2_E27__shared_ptr_default_deleteIS2_S2_EENS_9allocatorIS2_EEEE
N3fst9ArcMapFstINS_6ArcTplINS_17TropicalWeightTplIfEEEES4_NS_14ArcScaleMapperEEE
N3fst13ArcMapFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEES4_NS_14ArcScaleMapperEEE
N3fst13StateIteratorINS_9ArcMapFstINS_6ArcTplINS_17TropicalWeightTplIfEEEES5_NS_14ArcScaleMapperEEEEE
N3fst17StateIteratorBaseINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_16LatticeWeightTplIfEEEENSt3__19allocatorIS6_EEEEEENS_10MutableFstIS6_EEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENS_21SequenceComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENS_22LookAheadComposeFilterINS_24AltSequenceComposeFilterINS_16LookAheadMatcherINS_3FstIS5_EEEESC_EESC_SC_LNS_9MatchTypeE2EEENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSI_EENS_21CompactHashStateTableISK_NS_11ComposeHashISK_EEEEEEEE
N3fst13StateIteratorINS_10ComposeFstINS_6ArcTplINS_16LatticeWeightTplIfEEEENS_17DefaultCacheStoreIS5_EEEEEE
N3fst18CacheStateIteratorINS_10ComposeFstINS_6ArcTplINS_16LatticeWeightTplIfEEEENS_17DefaultCacheStoreIS5_EEEEEE
N3fst14DeterminizeFstINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEE
N3fst22DeterminizeFstImplBaseINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEE
N3fst13StateIteratorINS_14DeterminizeFstINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEEEE
N3fst18CacheStateIteratorINS_14DeterminizeFstINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEEEE
N3fst17StateIteratorBaseINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEE
N6quasar19LatticeRnnMitigatorE
NSt3__120__shared_ptr_emplaceIN6quasar20WlatArcFeBagOfPhonesENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar16WlatArcFeKeywordENS_9allocatorIS2_EEEE
6C<N5kaldi6quasar10LexiconItfE
N5kaldi6quasar7LexiconE
N5kaldi6quasar12ConstLexiconE
N6quasar28AlternativesProcessorOptionsE
N6quasar25ConfiguredProcessingBlockINS_28AlternativesProcessorOptionsEEE
N6quasar26AlternativesProcessorBlockE
34EARContinuousListeningResultHelper
NSt3__120__shared_ptr_emplaceI25EARModelInitializeContextNS_9allocatorIS1_EEEE
25EARModelInitializeContext
NSt3__120__shared_ptr_emplaceINS_19basic_istringstreamIcNS_11char_traitsIcEENS_9allocatorIcEEEENS4_IS6_EEEE
NSt3__120__shared_ptr_emplaceIKN6quasar32VoiceCommandActiveSetCompilationENS_9allocatorIS3_EEEE
N3fst10CompactFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_19UnweightedCompactorIS4_EEjNS_19DefaultCompactStoreINSt3__14pairINS9_IiiEEiEEjEEEE
N3fst17ImplToExpandedFstINS_14CompactFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_19UnweightedCompactorIS5_EEjNS_19DefaultCompactStoreINSt3__14pairINSA_IiiEEiEEjEEEENS_11ExpandedFstIS5_EEEE
N3fst14CompactFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_19UnweightedCompactorIS4_EEjNS_19DefaultCompactStoreINSt3__14pairINS9_IiiEEiEEjEEEE
N3fst13SortedMatcherINS_10CompactFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_19UnweightedCompactorIS5_EEjNS_19DefaultCompactStoreINSt3__14pairINSA_IiiEEiEEjEEEEEE
N3fst10MemoryPoolINS_11ArcIteratorINS_10CompactFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_19UnweightedCompactorIS6_EEjNS_19DefaultCompactStoreINSt3__14pairINSB_IiiEEiEEjEEEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_11ArcIteratorINS_10CompactFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_19UnweightedCompactorIS7_EEjNS_19DefaultCompactStoreINSt3__14pairINSC_IiiEEiEEjEEEEEEE4LinkEEE
NSt3__120__shared_ptr_emplaceI19ResultStreamWrapperNS_9allocatorIS1_EEEE
19ResultStreamWrapper
NSt3__120__shared_ptr_emplaceIbNS_9allocatorIbEEEE
NSt3__120__shared_ptr_emplaceI34EARContinuousListeningResultHelperNS_9allocatorIS1_EEEE
NSt3__113__assoc_stateIN6quasar8LocationEEE
NSt3__120__shared_ptr_emplaceIN6quasar14RunAsyncParamsENS_9allocatorIS2_EEEE
NSt3__110__function6__funcIZ23getModelFilesWithSuffixRKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEES9_E3$_6NS5_ISA_EEFbS7_EEE
NSt3__110__function6__baseIFbNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEEEE
Z23getModelFilesWithSuffixRKNSt3__112basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEES7_E3$_6
N6quasar16RomanizerOptionsE
N6quasar25ConfiguredProcessingBlockINS_16RomanizerOptionsEEE
N6quasar14RomanizerBlockE
NSt3__112codecvt_utf8IwLm1114111ELNS_12codecvt_modeE0EEE
N3fst10MutableFstINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS5_9allocatorIfEEEEEEEEEE
N3fst13VectorFstImplINS_11VectorStateINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS6_9allocatorIfEEEEEEEENS8_ISC_EEEEEE
N3fst22MutableArcIteratorBaseINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS5_9allocatorIfEEEEEEEEEE
N6quasar11OptionValueINSt3__112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEEEE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar18NNMTTransliteratorENS_9allocatorIS3_EEEE
N3fst10MappedFileE
+2#B
;N6quasar23QualityEstimatorOptionsE
N6quasar25ConfiguredProcessingBlockINS_23QualityEstimatorOptionsEEE
N6quasar21QualityEstimatorBlockE
!-[[
FLSN3fst9VectorFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_11VectorStateIS4_NSt3__19allocatorIS4_EEEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_17TropicalWeightTplIfEEEENSt3__19allocatorIS6_EEEEEENS_10MutableFstIS6_EEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_17TropicalWeightTplIfEEEENSt3__19allocatorIS6_EEEEEENS_10MutableFstIS6_EEEE
N3fst9VectorFstINS_6ArcTplINS_12LogWeightTplIfEEEENS_11VectorStateIS4_NSt3__19allocatorIS4_EEEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_12LogWeightTplIfEEEENSt3__19allocatorIS6_EEEEEENS_10MutableFstIS6_EEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_12LogWeightTplIfEEEENSt3__19allocatorIS6_EEEEEENS_10MutableFstIS6_EEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_11VectorStateIS5_NSt3__19allocatorIS5_EEEEEEEE
N3fst22MutableArcIteratorBaseINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_6ArcTplINS_12LogWeightTplIfEEEENS_11VectorStateIS5_NSt3__19allocatorIS5_EEEEEEEE
N3fst22MutableArcIteratorBaseINS_6ArcTplINS_12LogWeightTplIfEEEEEE
N3fst10MemoryPoolINS_8DfsStateINS_6ArcTplINS_12LogWeightTplIfEEEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_6ArcTplINS_12LogWeightTplIfEEEEEEE4LinkEEE
&;PN6quasar21InverseTextNormalizerE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar5VocabENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar25URegularExpressionWrapperENS_9allocatorIS2_EEEE
NSt3__112codecvt_utf8IDiLm1114111ELNS_12codecvt_modeE0EEE
NSt3__120__shared_ptr_pointerIPN6quasar34SpaceApplyDefaultFstTokenTransformENS_10shared_ptrINS1_17FstTokenTransformEE27__shared_ptr_default_deleteIS5_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrIN6quasar17FstTokenTransformEE27__shared_ptr_default_deleteIS2_NS1_34SpaceApplyDefaultFstTokenTransformEEE
NSt3__114default_deleteIN6quasar34SpaceApplyDefaultFstTokenTransformEEE
NSt3__120__shared_ptr_pointerIPN6quasar39RewriteApplyCapitalizeFstTokenTransformENS_10shared_ptrINS1_17FstTokenTransformEE27__shared_ptr_default_deleteIS5_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrIN6quasar17FstTokenTransformEE27__shared_ptr_default_deleteIS2_NS1_39RewriteApplyCapitalizeFstTokenTransformEEE
NSt3__114default_deleteIN6quasar39RewriteApplyCapitalizeFstTokenTransformEEE
NSt3__120__shared_ptr_pointerIPN6quasar36RewriteApplyDefaultFstTokenTransformENS_10shared_ptrINS1_17FstTokenTransformEE27__shared_ptr_default_deleteIS5_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrIN6quasar17FstTokenTransformEE27__shared_ptr_default_deleteIS2_NS1_36RewriteApplyDefaultFstTokenTransformEEE
NSt3__114default_deleteIN6quasar36RewriteApplyDefaultFstTokenTransformEEE
NSt3__120__shared_ptr_pointerIPN6quasar24ComposeFstTokenTransformENS_10shared_ptrINS1_17FstTokenTransformEE27__shared_ptr_default_deleteIS5_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrIN6quasar17FstTokenTransformEE27__shared_ptr_default_deleteIS2_NS1_24ComposeFstTokenTransformEEE
NSt3__114default_deleteIN6quasar24ComposeFstTokenTransformEEE
NSt3__120__shared_ptr_emplaceINS_3mapINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_6vectorIiNS5_IiEEEENS_4lessIS7_EENS5_INS_4pairIKS7_SA_EEEEEENS5_ISH_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar18QuasarTextProcImplENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar10PrefixTreeINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEES9_EENS7_ISA_EEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_6ArcTplINS_17TropicalWeightTplIfEEEENSt3__19allocatorIS5_EEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_17NullComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_17NullComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_24AltSequenceComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_18MatchComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
NSt3__120__shared_ptr_emplaceINS_6vectorIN6quasar25PreTokenToPostTokenItnMapENS_9allocatorIS3_EEEENS4_IS6_EEEE
N5kaldi8CuMatrixIdEE
N5kaldi12CuMatrixBaseIdEE
N5kaldi11CuSubMatrixIdEE
N6quasar16WlatArcFeKeywordE
N6quasar23WlatArcFeatureExtractorE
N6quasar14WlatArcFeIsLmeE
N6quasar14WlatArcFeLmeIdE
N6quasar14WlatArcFeIsSilE
N6quasar18WlatArcFeNumPhonesE
N6quasar29WlatArcFeAcousticCostUnpushedE
N6quasar19WlatArcFeInBestPathE
N6quasar21WlatArcFeAcousticCostE
N6quasar18WlatArcFeGraphCostE
N6quasar18WlatArcFeNumFramesE
N6quasar21WlatArcFeLogPosteriorE
N6quasar21WlatArcFeLinPosteriorE
N6quasar20WlatArcFeBagOfPhonesE
N6quasar22WlatArcFeWordEmbeddingE
N3fst11SymbolTableE
N3fst7ArcInfoE
N3fst14BackoffArcInfoE
N3fst13InterpArcInfoE
N3fst11MatcherBaseINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
".]]
N6quasar11FstLmScorerE
N3fst10MutableFstINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEE4LinkEEE
NSt3__120__shared_ptr_emplaceIN6quasar15SymbolTableListENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar22SpeechRecognizerConfigENS_9allocatorIS2_EEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEE4LinkEEE
N3fst14ReplaceFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_24DefaultReplaceStateTableIS4_lEENS_17DefaultCacheStoreIS4_EEEE
N3fst13CacheBaseImplINS_10CacheStateINS_6ArcTplINS_17TropicalWeightTplIfEEEENSt3__19allocatorIS5_EEEENS_17DefaultCacheStoreIS5_EEEE
N3fst13StateIteratorINS_10ReplaceFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_24DefaultReplaceStateTableIS5_lEENS_17DefaultCacheStoreIS5_EEEEEE
N3fst17ReplaceFstMatcherINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_24DefaultReplaceStateTableIS4_lEENS_17DefaultCacheStoreIS4_EEEE
N3fst10MemoryPoolINS_11ArcIteratorINS_10ReplaceFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_24DefaultReplaceStateTableIS6_lEENS_17DefaultCacheStoreIS6_EEEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_11ArcIteratorINS_10ReplaceFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_24DefaultReplaceStateTableIS7_lEENS_17DefaultCacheStoreIS7_EEEEEEE4LinkEEE
N5kaldi6quasar31RecurrentNeuralDeterministicFstIN3fst6ArcTplINS2_17TropicalWeightTplIfEEEEEE
NSt3__120__shared_ptr_emplaceIN3fst7ArcInfoENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceINS_6vectorINS_10shared_ptrIN3fst7ArcInfoEEENS_9allocatorIS5_EEEENS6_IS8_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar23SpeechRequestResultDataENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar18DecoderChainOutputENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi5TimerENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar17SpeechRequestDataENS_9allocatorIS2_EEEE
NSt3__110__function6__funcIZN6quasar11FstLmScorer14computeLmScoreERKNS_6vectorINS_10shared_ptrINS2_12LmeContainerEEENS_9allocatorIS7_EEEERKNS2_8LocationERKNS_12basic_stringIcNS_11char_traitsIcEENS8_IcEEEERKNS4_ISK_NS8_ISK_EEEEbRNS2_6LmInfoERKNS4_INS5_IN5kaldi6quasar8LmHandleEEENS8_ISW_EEEEbSM_RKNS4_IiNS8_IiEEEEbbbiSQ_E3$_2NS8_IS15_EEFNS5_IN3fst3FstINS17_6ArcTplINS17_17TropicalWeightTplIfEEEEEEEERKS1E_EEE
ZN6quasar11FstLmScorer14computeLmScoreERKNSt3__16vectorINS1_10shared_ptrINS_12LmeContainerEEENS1_9allocatorIS5_EEEERKNS_8LocationERKNS1_12basic_stringIcNS1_11char_traitsIcEENS6_IcEEEERKNS2_ISI_NS6_ISI_EEEEbRNS_6LmInfoERKNS2_INS3_IN5kaldi6quasar8LmHandleEEENS6_ISU_EEEEbSK_RKNS2_IiNS6_IiEEEEbbbiSO_E3$_2
NSt3__110__function6__funcIZN6quasar11FstLmScorer14computeLmScoreERKNS_6vectorINS_10shared_ptrINS2_12LmeContainerEEENS_9allocatorIS7_EEEERKNS2_8LocationERKNS_12basic_stringIcNS_11char_traitsIcEENS8_IcEEEERKNS4_ISK_NS8_ISK_EEEEbRNS2_6LmInfoERKNS4_INS5_IN5kaldi6quasar8LmHandleEEENS8_ISW_EEEEbSM_RKNS4_IiNS8_IiEEEEbbbiSQ_E3$_3NS8_IS15_EEFNS5_INSU_17NnlmEvaluatorBaseEEERKS18_EEE
ZN6quasar11FstLmScorer14computeLmScoreERKNSt3__16vectorINS1_10shared_ptrINS_12LmeContainerEEENS1_9allocatorIS5_EEEERKNS_8LocationERKNS1_12basic_stringIcNS1_11char_traitsIcEENS6_IcEEEERKNS2_ISI_NS6_ISI_EEEEbRNS_6LmInfoERKNS2_INS3_IN5kaldi6quasar8LmHandleEEENS6_ISU_EEEEbSK_RKNS2_IiNS6_IiEEEEbbbiSO_E3$_3
N4utf815not_enough_roomE
N4utf89exceptionE
N4utf812invalid_utf8E
N4utf818invalid_code_pointE
N6quasar13QuasarG2PBaseE
PN3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEENSt3__19allocatorIS8_EEEEEENS_10MutableFstIS8_EEEE
N3fst9AutoQueueIiEE
N3fst15StateOrderQueueIiEE
N5kaldi12CuVectorBaseIdEE
QVGt
NSt3__110__function6__funcIZN5kaldi6quasar26ConfidenceFeatureExtractorINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEE30GetConfidenceFeaturesFromNBestERKNS_6vectorINSC_ISA_NS8_ISA_EEEENS8_ISE_EEEERKNSC_IfNS8_IfEEEEiPNSC_INS2_6MatrixIfEENS8_ISO_EEEEEUliiE_NS8_ISS_EEFfiiEEE
NSt3__110__function6__baseIFfiiEEE
ZN5kaldi6quasar26ConfidenceFeatureExtractorINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEE30GetConfidenceFeaturesFromNBestERKNS2_6vectorINSA_IS8_NS6_IS8_EEEENS6_ISC_EEEERKNSA_IfNS6_IfEEEEiPNSA_INS_6MatrixIfEENS6_ISM_EEEEEUliiE_
NSt3__110__function6__funcIZN5kaldi6quasar26ConfidenceFeatureExtractorINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEE30GetConfidenceFeaturesFromNBestERKNS_6vectorINSC_ISA_NS8_ISA_EEEENS8_ISE_EEEERKNSC_IfNS8_IfEEEEiPNSC_INS2_6MatrixIfEENS8_ISO_EEEEEUliiE0_NS8_ISS_EEFfiiEEE
ZN5kaldi6quasar26ConfidenceFeatureExtractorINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEE30GetConfidenceFeaturesFromNBestERKNS2_6vectorINSA_IS8_NS6_IS8_EEEENS6_ISC_EEEERKNSA_IfNS6_IfEEEEiPNSA_INS_6MatrixIfEENS6_ISM_EEEEEUliiE0_
NSt3__110__function6__funcIZN5kaldi6quasar26ConfidenceFeatureExtractorINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEE30GetConfidenceFeaturesFromNBestERKNS_6vectorINSC_ISA_NS8_ISA_EEEENS8_ISE_EEEERKNSC_IfNS8_IfEEEEiPNSC_INS2_6MatrixIfEENS8_ISO_EEEEEUliiE1_NS8_ISS_EEFfiiEEE
ZN5kaldi6quasar26ConfidenceFeatureExtractorINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEE30GetConfidenceFeaturesFromNBestERKNS2_6vectorINSA_IS8_NS6_IS8_EEEENS6_ISC_EEEERKNSA_IfNS6_IfEEEEiPNSA_INS_6MatrixIfEENS6_ISM_EEEEEUliiE1_
NSt3__110__function6__funcIZN5kaldi6quasar26ConfidenceFeatureExtractorINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEE30GetConfidenceFeaturesFromNBestERKNS_6vectorINSC_ISA_NS8_ISA_EEEENS8_ISE_EEEERKNSC_IfNS8_IfEEEEiPNSC_INS2_6MatrixIfEENS8_ISO_EEEEEUliiE2_NS8_ISS_EEFfiiEEE
ZN5kaldi6quasar26ConfidenceFeatureExtractorINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEE30GetConfidenceFeaturesFromNBestERKNS2_6vectorINSA_IS8_NS6_IS8_EEEENS6_ISC_EEEERKNSA_IfNS6_IfEEEEiPNSA_INS_6MatrixIfEENS6_ISM_EEEEEUliiE2_
NSt3__110__function6__funcIZN5kaldi6quasar26ConfidenceFeatureExtractorINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEE30GetConfidenceFeaturesFromNBestERKNS_6vectorINSC_ISA_NS8_ISA_EEEENS8_ISE_EEEERKNSC_IfNS8_IfEEEEiPNSC_INS2_6MatrixIfEENS8_ISO_EEEEEUliiE3_NS8_ISS_EEFfiiEEE
ZN5kaldi6quasar26ConfidenceFeatureExtractorINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEE30GetConfidenceFeaturesFromNBestERKNS2_6vectorINSA_IS8_NS6_IS8_EEEENS6_ISC_EEEERKNSA_IfNS6_IfEEEEiPNSA_INS_6MatrixIfEENS6_ISM_EEEEEUliiE3_
NSt3__110__function6__funcIZN5kaldi6quasar26ConfidenceFeatureExtractorINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEE30GetConfidenceFeaturesFromNBestERKNS_6vectorINSC_ISA_NS8_ISA_EEEENS8_ISE_EEEERKNSC_IfNS8_IfEEEEiPNSC_INS2_6MatrixIfEENS8_ISO_EEEEEUliiE4_NS8_ISS_EEFfiiEEE
ZN5kaldi6quasar26ConfidenceFeatureExtractorINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEE30GetConfidenceFeaturesFromNBestERKNS2_6vectorINSA_IS8_NS6_IS8_EEEENS6_ISC_EEEERKNSA_IfNS6_IfEEEEiPNSA_INS_6MatrixIfEENS6_ISM_EEEEEUliiE4_
NSt3__110__function6__funcIZN5kaldi6quasar26ConfidenceFeatureExtractorINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEE30GetConfidenceFeaturesFromNBestERKNS_6vectorINSC_ISA_NS8_ISA_EEEENS8_ISE_EEEERKNSC_IfNS8_IfEEEEiPNSC_INS2_6MatrixIfEENS8_ISO_EEEEEUliiE5_NS8_ISS_EEFfiiEEE
ZN5kaldi6quasar26ConfidenceFeatureExtractorINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEE30GetConfidenceFeaturesFromNBestERKNS2_6vectorINSA_IS8_NS6_IS8_EEEENS6_ISC_EEEERKNSA_IfNS6_IfEEEEiPNSA_INS_6MatrixIfEENS6_ISM_EEEEEUliiE5_
NSt3__110__function6__funcIZN5kaldi6quasar26ConfidenceFeatureExtractorINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEE30GetConfidenceFeaturesFromNBestERKNS_6vectorINSC_ISA_NS8_ISA_EEEENS8_ISE_EEEERKNSC_IfNS8_IfEEEEiPNSC_INS2_6MatrixIfEENS8_ISO_EEEEEUliiE6_NS8_ISS_EEFfiiEEE
ZN5kaldi6quasar26ConfidenceFeatureExtractorINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEE30GetConfidenceFeaturesFromNBestERKNS2_6vectorINSA_IS8_NS6_IS8_EEEENS6_ISC_EEEERKNSA_IfNS6_IfEEEEiPNSA_INS_6MatrixIfEENS6_ISM_EEEEEUliiE6_
NSt3__110__function6__funcIZN5kaldi6quasar16ConfusionNetworkINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEEC1ERKNS_6vectorINSC_ISA_NS8_ISA_EEEENS8_ISE_EEEERKNSC_IfNS8_IfEEEENS_8functionIFSE_SE_EEENSN_IFSA_SA_EEEEd0_UlSE_E_NS8_ISS_EESO_EE
NSt3__110__function6__baseIFNS_6vectorINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS6_IS8_EEEESA_EEE
ZN5kaldi6quasar16ConfusionNetworkINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEEC1ERKNS2_6vectorINSA_IS8_NS6_IS8_EEEENS6_ISC_EEEERKNSA_IfNS6_IfEEEENS2_8functionIFSC_SC_EEENSL_IFS8_S8_EEEEd0_UlSC_E_
NSt3__110__function6__funcIZN5kaldi6quasar16ConfusionNetworkINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEEC1ERKNS_6vectorINSC_ISA_NS8_ISA_EEEENS8_ISE_EEEERKNSC_IfNS8_IfEEEENS_8functionIFSE_SE_EEENSN_IFSA_SA_EEEEd_UlSA_E_NS8_ISS_EESQ_EE
NSt3__110__function6__baseIFNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEES7_EEE
ZN5kaldi6quasar16ConfusionNetworkINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEEC1ERKNS2_6vectorINSA_IS8_NS6_IS8_EEEENS6_ISC_EEEERKNSA_IfNS6_IfEEEENS2_8functionIFSC_SC_EEENSL_IFS8_S8_EEEEd_UlS8_E_
NSt3__120__shared_ptr_pointerIPN6quasar20SyncSpeechRecognizerENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN6quasar20SyncSpeechRecognizerEEE
N6quasar15OptionValueBaseE
N6quasar11OptionsBaseE
N6quasar15ProcessingBlockE
N6quasar25MultiInputProcessingBlockE
N6quasar16ProcessingSourceE
N6quasar14ProcessingSinkE
N6quasar13MergerOptionsE
N6quasar25ConfiguredProcessingBlockINS_13MergerOptionsEEE
N6quasar11MergerBlockE
N6quasar9NullBlockE
N6quasar16DumpBlockOptionsE
N6quasar25ConfiguredProcessingBlockINS_16DumpBlockOptionsEEE
N6quasar9DumpBlockE
N6quasar2lm8arpa2fst10kaldi_fork14ArpaFileParserE
NSt3__120__shared_ptr_emplaceIN5kaldi8CuMatrixIfEENS_9allocatorIS3_EEEE
".]]
HNUN6quasar10TranslatorE
NSt3__120__shared_ptr_emplaceIN6quasar14PDecTranslatorENS_9allocatorIS2_EEEE
N5kaldi6quasar17AbstractAttributeE
N5kaldi6quasar10MajorErrorE
N5kaldi6quasar15SchemaAttributeE
N5kaldi6quasar15StringAttributeE
N5kaldi6quasar14FloatAttributeE
N5kaldi6quasar13BaseAttributeE
N5kaldi6quasar16AttributeWrapperE
N5kaldi6quasar16ContextAttributeE
N5kaldi6quasar13WordConfusionE
N5kaldi6quasar16AttributeFactoryE
9SpeechITN
13QuasarITNImpl
333?
N6quasar7DecoderE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_16LatticeWeightTplIfEEEENSt3__19allocatorIS6_EEEEEENS_10MutableFstIS6_EEEE
N3fst11ExpandedFstINS_6ArcTplINS_16LatticeWeightTplIfEEEEEE
N3fst9VectorFstINS_6ArcTplINS_16LatticeWeightTplIfEEEENS_11VectorStateIS4_NSt3__19allocatorIS4_EEEEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_6ArcTplINS_16LatticeWeightTplIfEEEENS_11VectorStateIS5_NSt3__19allocatorIS5_EEEEEEEE
N3fst22MutableArcIteratorBaseINS_6ArcTplINS_16LatticeWeightTplIfEEEEEE
N3fst13TopOrderQueueIiEE
NSt3__112__deque_baseIiNS_9allocatorIiEEEE
N3fst9FifoQueueIiEE
N3fst9VectorFstINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENS_11VectorStateIS6_NSt3__19allocatorIS6_EEEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENSt3__19allocatorIS8_EEEEEENS_10MutableFstIS8_EEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENSt3__19allocatorIS7_EEEEEE
N3fst13CacheBaseImplINS_10CacheStateINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENSt3__19allocatorIS7_EEEENS_17DefaultCacheStoreIS7_EEEE
NSt3__120__shared_ptr_emplaceINS_6vectorIdNS_9allocatorIdEEEENS2_IS4_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar5TokenENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar31OnlineLatticeBiglmFasterDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar34OnlineLatticeBiglmLmeFasterDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar34OnlineLatticeBiglmLmeFasterDecoder23LmeCreationDependenciesENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar29OnlineLatticeRescalingDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar33OnlineLatticeWordAlignmentDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar24OnlineLmRescoringDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar31OnlineLatticeRealignmentDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar19ErrorBlamingDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar30OnlineLatticeConfidenceDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar20LatticeFasterDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar28OnlineKeywordSpottingDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar18OnlineSeevaDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar22OnlineSeevaStepDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar27OnlineSeevaStepBigLmDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar18SeevaGreedyDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar17SeevaBatchDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar26OnlineLASBeamSearchDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar37OnlineLASSpeculativeBeamSearchDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar37OnlineLASLmRescoringBeamSearchDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar48OnlineLASLmRescoringSpeculativeBeamSearchDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar33OnlineTransducerBeamSearchDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar24SystemCombinationDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar31ConfusionNetworkCombinerDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar20PhoneticMatchDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar19FingerprintDetectorENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar27OnlineAudioAnalyticsDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar17WatermarkDetectorENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar21AudioAnalyticsDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar19LatticeRnnMitigatorENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar14HwcnConfidenceENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar16E2EAsrConfidenceENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar18WatermarkDetector2ENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar20LatticeLmeFtmDecoderENS_9allocatorIS2_EEEE
!-QQ
N5kaldi6quasar11ErrorBlamerE
N3fst3FstINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEE
N3fst13VectorFstImplINS_11VectorStateINS_6ArcTplINS_16LatticeWeightTplIfEEEENSt3__19allocatorIS5_EEEEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_6ArcTplINS_16LatticeWeightTplIfEEEENSt3__19allocatorIS5_EEEEEE
N3fst7FstImplINS_6ArcTplINS_16LatticeWeightTplIfEEEEEE
N3fst10ComposeFstINS_6ArcTplINS_16LatticeWeightTplIfEEEENS_17DefaultCacheStoreIS4_EEEE
N3fst18ComposeFstImplBaseINS_6ArcTplINS_16LatticeWeightTplIfEEEENS_17DefaultCacheStoreIS4_EEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENS_17NullComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENS_24AltSequenceComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N6quasar13CommandTaggerE
N6quasar14CaseMapOptionsE
N6quasar25ConfiguredProcessingBlockINS_14CaseMapOptionsEEE
N6quasar12CaseMapBlockE
!-[[
!-[[
".]]
5Ngram
13NgramBayesMix
N6quasar9GeoRegionE
NSt3__120__shared_ptr_emplaceIN6quasar12BitmapRegionENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar12CircleRegionENS_9allocatorIS2_EEEE
NSt3__110__function6__funcIZN6quasar9GeoRegion10loadModelsERNS2_11ModelLoaderERNS2_10filesystem4PathEE3$_0NS_9allocatorIS9_EEFNS_10shared_ptrIN3fst3FstINSD_6ArcTplINSD_17TropicalWeightTplIfEEEEEEEERKNS_12basic_stringIcNS_11char_traitsIcEENSA_IcEEEEEEE
ZN6quasar9GeoRegion10loadModelsERNS_11ModelLoaderERNS_10filesystem4PathEE3$_0
NSt3__110__function6__funcIZN6quasar9GeoRegion10loadModelsERNS2_11ModelLoaderERNS2_10filesystem4PathEE3$_1NS_9allocatorIS9_EEFNS_10shared_ptrIN5kaldi6quasar17NnlmEvaluatorBaseEEERKNS_12basic_stringIcNS_11char_traitsIcEENSA_IcEEEEEEE
ZN6quasar9GeoRegion10loadModelsERNS_11ModelLoaderERNS_10filesystem4PathEE3$_1
N5kaldi18CoreMLInferenceNetE
NSt3__120__shared_ptr_emplaceIN5kaldi18CoreMLInferenceNetENS_9allocatorIS2_EEEE
?N6quasar11DummyConfigE
N6quasar12DummyLmModelE
NSt3__120__shared_ptr_pointerIPN6quasar11FstLmHandleENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN6quasar11FstLmHandleEEE
NSt3__120__shared_ptr_pointerIPN6quasar12DummyLmModelENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN6quasar12DummyLmModelEEE
N5kaldi5nnet123FixedAttentionComponentE
N6quasar20PhoneticMatchDecoderE
N6quasar10filesystem4PathE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar13SymbolDecoderINS2_8PhonomapEEENS_9allocatorIS5_EEEE
N3fst13SortedMatcherINS_3FstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_21SequenceComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N6quasar15ProcessingGraphE
N6quasar21LinearProcessingGraphE
N6quasar23DirectedProcessingGraphE
N6quasar11OptionValueIiEE
N6quasar11OptionValueIdEE
N6quasar11OptionValueIbEE
N6quasar11OptionValueINS_5PTreeEEE
NSt3__120__shared_ptr_emplaceIN6quasar14ProcessingSinkENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar16ProcessingSourceENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_pointerIPN6quasar15ProcessingBlockENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN6quasar15ProcessingBlockEEE
zDN6quasar17PhraseBookOptionsE
N6quasar25ConfiguredProcessingBlockINS_17PhraseBookOptionsEEE
N6quasar15PhraseBookBlockE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENS_24AltSequenceComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N5kaldi6quasar14RnnlmEvaluatorE
N6quasar24OnlineLmRescoringDecoderE
NSt3__110__function6__funcIZN6quasar24OnlineLmRescoringDecoder10finishInitEvE3$_0NS_9allocatorIS4_EEFNS_10shared_ptrIN3fst3FstINS8_6ArcTplINS8_17TropicalWeightTplIfEEEEEEEERKNS_12basic_stringIcNS_11char_traitsIcEENS5_IcEEEEEEE
ZN6quasar24OnlineLmRescoringDecoder10finishInitEvE3$_0
NSt3__110__function6__funcIZN6quasar24OnlineLmRescoringDecoder10finishInitEvE3$_1NS_9allocatorIS4_EEFNS_10shared_ptrIN5kaldi6quasar17NnlmEvaluatorBaseEEERKNS_12basic_stringIcNS_11char_traitsIcEENS5_IcEEEEEEE
ZN6quasar24OnlineLmRescoringDecoder10finishInitEvE3$_1
NSt3__110__function6__funcIZN6quasar24OnlineLmRescoringDecoder7runImplERNS2_15DecoderPassDataERKNS_10shared_ptrINS2_18DecoderChainOutputEEERKNS6_INS2_17SpeechRequestDataEEERKNS_8functionIFbvEEEbE3$_2NS_9allocatorISK_EEFNS6_IN3fst3FstINSN_6ArcTplINSN_17TropicalWeightTplIfEEEEEEEERKSU_EEE
ZN6quasar24OnlineLmRescoringDecoder7runImplERNS_15DecoderPassDataERKNSt3__110shared_ptrINS_18DecoderChainOutputEEERKNS4_INS_17SpeechRequestDataEEERKNS3_8functionIFbvEEEbE3$_2
NSt3__110__function6__funcIZN6quasar24OnlineLmRescoringDecoder7runImplERNS2_15DecoderPassDataERKNS_10shared_ptrINS2_18DecoderChainOutputEEERKNS6_INS2_17SpeechRequestDataEEERKNS_8functionIFbvEEEbE3$_3NS_9allocatorISK_EEFNS6_IN5kaldi6quasar17NnlmEvaluatorBaseEEERKSQ_EEE
ZN6quasar24OnlineLmRescoringDecoder7runImplERNS_15DecoderPassDataERKNSt3__110shared_ptrINS_18DecoderChainOutputEEERKNS4_INS_17SpeechRequestDataEEERKNS3_8functionIFbvEEEbE3$_3
N5kaldi6quasar14DnnlmEvaluatorE
N6quasar20SyncSpeechRecognizerE
NSt3__120__shared_ptr_emplaceIN6quasar20RecognizerComponentsINS1_11SyncDecoderEEENS_9allocatorIS4_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar18RecogRequestFilterENS_9allocatorIS2_EEEE
N6quasar5PTree14JsonParseErrorE
N6quasar5PTree5ErrorE
N6quasar5PTree7BadPathE
333333
=(kn
N5kaldi6quasar19SeevaBeamSearchBaseE
ZaN6quasar3G2PE
N6quasar25AlignmentProcessorOptionsE
N6quasar25ConfiguredProcessingBlockINS_25AlignmentProcessorOptionsEEE
N6quasar23AlignmentProcessorBlockE
+8nn
2?8GG
N3fst13StateIteratorINS_12ArcPosingFstINS_6ArcTplINS_12LogWeightTplIfEEEENS2_INS_17TropicalWeightTplIfEEEEEEEE
N3fst15ArcIteratorBaseINS_6ArcTplINS_12LogWeightTplIfEEEEEE
N3fst19MutableArcPosingFstINS_6ArcTplINS_12LogWeightTplIfEEEENS1_INS_17TropicalWeightTplIfEEEEEE
N3fst11ArcIteratorINS_19MutableArcPosingFstINS_6ArcTplINS_12LogWeightTplIfEEEENS2_INS_17TropicalWeightTplIfEEEEEEEE
N3fst18MutableArcIteratorINS_19MutableArcPosingFstINS_6ArcTplINS_12LogWeightTplIfEEEENS2_INS_17TropicalWeightTplIfEEEEEEEE
N3fst13StateIteratorINS_12ArcPosingFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS2_INS_12LogWeightTplIfEEEEEEEE
N3fst9LifoQueueIiEE
NSt3__15dequeIiNS_9allocatorIiEEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENSt3__19allocatorIS8_EEEEEENS_10MutableFstIS8_EEEE
N3fst10MutableFstINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEEE4LinkEEE
N3fst22MutableArcIteratorBaseINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEE
N3fst10ContextFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEiEE
N3fst14ContextFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEEiEE
N3fst13StateIteratorINS_10ContextFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEiEEEE
N3fst18CacheStateIteratorINS_10ContextFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEiEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_21SequenceComposeFilterINS_14ContextMatcherIS5_iEES9_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSD_EENS_21CompactHashStateTableISF_NS_11ComposeHashISF_EEEEEEEE
N3fst14ContextMatcherINS_6ArcTplINS_17TropicalWeightTplIfEEEEiEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_21SequenceComposeFilterINS_14ContextMatcherIS5_iEES9_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSD_EENS_21CompactHashStateTableISF_NS_11ComposeHashISF_EEEEEEEE
N3fst12TableMatcherINS_3FstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_13SortedMatcherIS6_EEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_21SequenceComposeFilterINS_12TableMatcherINS_3FstIS5_EENS_13SortedMatcherISA_EEEESC_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSH_EENS_21CompactHashStateTableISJ_NS_11ComposeHashISJ_EEEEEEEE
?N6quasar11FstLmHandleE
N3fst31BackoffDeterministicOnDemandFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_3FstIS4_EEEE
N3fst7FstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N3fst3FstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N5kaldi8CuVectorIfEE
NSt3__120__shared_ptr_emplaceIN5kaldi14WordHypLatticeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIZN5kaldi14WordHypLattice20GetNBestMeanConfPathERNS_6vectorINS3_IPNS2_3ArcENS_9allocatorIS5_EEEENS6_IS8_EEEEiE14BackTraceTokenNS6_ISC_EEEE
N6quasar10NNLmConfigE
N6quasar9NNLmModelE
N5kaldi6quasar8LmHandleE
NSt3__120__shared_ptr_emplaceIN6quasar10NNLmConfig20NNLmConfigParametersENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar14RegionalLmPlugINS_10shared_ptrIN5kaldi6quasar17NnlmEvaluatorBaseEEEEENS_9allocatorIS8_EEEE
NSt3__110__function6__funcIZN6quasar9NNLmModelC1ERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEESB_SB_RKNS_10shared_ptrIKNS2_10NNLmConfigEEEE3$_0NS7_ISI_EEFNSC_IN5kaldi6quasar17NnlmEvaluatorBaseEEESB_EEE
NSt3__110__function6__baseIFNS_10shared_ptrIN5kaldi6quasar17NnlmEvaluatorBaseEEERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEEEE
ZN6quasar9NNLmModelC1ERKNSt3__112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEES9_S9_RKNS1_10shared_ptrIKNS_10NNLmConfigEEEE3$_0
NSt3__110__function6__funcIZN6quasar9NNLmModelC1ERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEffSB_bfiE3$_1NS7_ISC_EEFNS_10shared_ptrIN5kaldi6quasar17NnlmEvaluatorBaseEEESB_EEE
ZN6quasar9NNLmModelC1ERKNSt3__112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEEffS9_bfiE3$_1
N3fst10ReplaceFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_24DefaultReplaceStateTableIS4_lEENS_17DefaultCacheStoreIS4_EEEE
N3fst29CacheDeterministicOnDemandFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_24DeterministicOnDemandFstIS4_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar9NNLmModelENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_pointerIPN6quasar9NNLmModelENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN6quasar9NNLmModelEEE
N6quasar21ComputeAheadFeatInputE
NSt3__120__shared_ptr_emplaceIN6quasar21ComputeAheadFeatInput5BatchENS_9allocatorIS3_EEEE
N6quasar19FingerprintDetectorE
N5kaldi32SequentialTableReaderArchiveImplINS_17KaldiObjectHolderINS_6VectorIfEEEEEE
N5kaldi29SequentialTableReaderImplBaseINS_17KaldiObjectHolderINS_6VectorIfEEEEEE
N5kaldi31SequentialTableReaderScriptImplINS_17KaldiObjectHolderINS_6VectorIfEEEEEE
N6quasar18AMKeywordDetectionE
N5kaldi6quasar19CEEncoderDecoderNetE
N5kaldi6quasar24CESplitEncoderDecoderNetE
N5kaldi8CuVectorIdEE
N6quasar20LatticeFasterDecoderE
NSt3__120__shared_ptr_emplaceIN3fst9VectorFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEENS1_11VectorStateIS6_NS_9allocatorIS6_EEEEEENS8_ISB_EEEE
N3fst10MutableFstINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEE
N3fst13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENSt3__19allocatorIS7_EEEEEE
N3fst7FstImplINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEE
N3fst15ArcIteratorBaseINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEE
N6quasar8TextProcE
!-QQ
=JCII
ipN6quasar31OnlineLatticeRealignmentDecoderE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_16LatticeWeightTplIfEEEENSt3__19allocatorIS6_EEEEEENS_10MutableFstIS6_EEEE
N3fst15ArcIteratorBaseINS_6ArcTplINS_16LatticeWeightTplIfEEEEEE
NSt3__120__shared_ptr_emplaceIN5kaldi16WordBoundaryInfoENS_9allocatorIS2_EEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENSt3__19allocatorIS8_EEEEEENS_10MutableFstIS8_EEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENSt3__19allocatorIS8_EEEEEENS_10MutableFstIS8_EEEE
N3fst11ExpandedFstINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEE
N3fst3FstINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEE
N3fst10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEEE4LinkEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENS_11VectorStateIS7_NSt3__19allocatorIS7_EEEEEEEE
N3fst22MutableArcIteratorBaseINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEE
N3fst13CacheBaseImplINS_10CacheStateINS_6ArcTplINS_16LatticeWeightTplIfEEEENSt3__19allocatorIS5_EEEENS_17DefaultCacheStoreIS5_EEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENS_22LookAheadComposeFilterINS_24AltSequenceComposeFilterINS_16LookAheadMatcherINS_3FstIS5_EEEESC_EESC_SC_LNS_9MatchTypeE2EEENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSI_EENS_21CompactHashStateTableISK_NS_11ComposeHashISK_EEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENS_22LookAheadComposeFilterINS_21SequenceComposeFilterINS_16LookAheadMatcherINS_3FstIS5_EEEESC_EESC_SC_LNS_9MatchTypeE2EEENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSI_EENS_21CompactHashStateTableISK_NS_11ComposeHashISK_EEEEEEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENS_22LookAheadComposeFilterINS_21SequenceComposeFilterINS_16LookAheadMatcherINS_3FstIS5_EEEESC_EESC_SC_LNS_9MatchTypeE2EEENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSI_EENS_21CompactHashStateTableISK_NS_11ComposeHashISK_EEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENS_17NullComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENS_18MatchComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENS_18MatchComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N6quasar2lm6StreamIPNS0_19TokenStringAndCountEEE
N6quasar18PlaceholderOptionsE
N6quasar25ConfiguredProcessingBlockINS_18PlaceholderOptionsEEE
N6quasar16PlaceholderBlockE
N6quasar18FilterBlockOptionsE
N6quasar25ConfiguredProcessingBlockINS_18FilterBlockOptionsEEE
N6quasar11FilterBlockE
=N5kaldi5nnet113LstmComponentINS_12CuMatrixBaseIfEEEE
N5kaldi5nnet113LstmComponentINS_15QuantizedMatrixIaEEEE
N5kaldi5nnet113LstmComponentINS_15QuantizedMatrixIsEEEE
.N6quasar9DecodableE
NSt3__120__shared_ptr_emplaceIN6quasar36OnlineDecodableMatrixScaledDecodableENS_9allocatorIS2_EEEE
N6quasar36OnlineDecodableMatrixScaledDecodableE
NSt3__120__shared_ptr_pointerIPN5kaldi27OnlineDecodableMatrixScaledENS_10shared_ptrINS1_18DecodableInterfaceEE27__shared_ptr_default_deleteIS5_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrIN5kaldi18DecodableInterfaceEE27__shared_ptr_default_deleteIS2_NS1_27OnlineDecodableMatrixScaledEEE
NSt3__114default_deleteIN5kaldi27OnlineDecodableMatrixScaledEEE
NSt3__120__shared_ptr_emplaceIN6quasar42OnlineDecodableMatrixScaledMappedDecodableENS_9allocatorIS2_EEEE
N6quasar42OnlineDecodableMatrixScaledMappedDecodableE
NSt3__120__shared_ptr_emplaceIN5kaldi33OnlineDecodableMatrixScaledMappedENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar44OnlineDecodableMatrixScaledMappedTmDecodableENS_9allocatorIS2_EEEE
N6quasar44OnlineDecodableMatrixScaledMappedTmDecodableE
NSt3__120__shared_ptr_emplaceIN5kaldi35OnlineDecodableMatrixScaledMappedTmENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar39OnlineDecodableIdenticalMatrixDecodableENS_9allocatorIS2_EEEE
N6quasar39OnlineDecodableIdenticalMatrixDecodableE
NSt3__120__shared_ptr_pointerIPN5kaldi30OnlineDecodableIdenticalMatrixENS_10shared_ptrINS1_18DecodableInterfaceEE27__shared_ptr_default_deleteIS5_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrIN5kaldi18DecodableInterfaceEE27__shared_ptr_default_deleteIS2_NS1_30OnlineDecodableIdenticalMatrixEEE
NSt3__114default_deleteIN5kaldi30OnlineDecodableIdenticalMatrixEEE
NSt3__120__shared_ptr_emplaceIN6quasar33OnlineDecodableNnet1LazyDecodableENS_9allocatorIS2_EEEE
N6quasar33OnlineDecodableNnet1LazyDecodableE
NSt3__120__shared_ptr_emplaceIN5kaldi5nnet18PdfPriorENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi24OnlineDecodableNnet1LazyENS_9allocatorIS2_EEEE
N6quasar27GlobalPDecTranslatorFactoryE
)6vv
\biN3fst10MemoryPoolINS_8DfsStateINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEE
14StopNgramStats
abfnrtv_
N5kaldi5nnet121CnnRearrangeComponentE
N5kaldi5nnet116PaddingComponentE
N5kaldi5nnet118Padding2DComponentE
N5kaldi5nnet132ConvolutionalMaxPoolingComponentINS_15QuantizedMatrixIsEEEE
%www
/HHH HHHHHHHHHH
HHHH=8#HH
&3dd
O]UN6quasar12SystemConfigE
N5boost2io18basic_altstringbufIcNSt3__111char_traitsIcEENS2_9allocatorIcEEEE
N5boost16exception_detail10clone_implINS0_19error_info_injectorINS_2io17bad_format_stringEEEEE
N5boost16exception_detail19error_info_injectorINS_2io17bad_format_stringEEE
N5boost2io17bad_format_stringE
N5boost2io12format_errorE
N5boost16exception_detail10clone_implINS0_19error_info_injectorINS_2io13too_many_argsEEEEE
N5boost16exception_detail19error_info_injectorINS_2io13too_many_argsEEE
N5boost2io13too_many_argsE
N5boost2io22basic_oaltstringstreamIcNSt3__111char_traitsIcEENS2_9allocatorIcEEEE
N5boost16base_from_memberINS_10shared_ptrINS_2io18basic_altstringbufIcNSt3__111char_traitsIcEENS4_9allocatorIcEEEEEELi0EEE
N5boost6detail18sp_counted_impl_pdIPNS_2io18basic_altstringbufIcNSt3__111char_traitsIcEENS4_9allocatorIcEEEENS2_22basic_oaltstringstreamIcS6_S8_E5No_OpEEE
N5boost6detail15sp_counted_baseE
N5boost2io22basic_oaltstringstreamIcNSt3__111char_traitsIcEENS2_9allocatorIcEEE5No_OpE
N5boost16exception_detail10clone_implINS0_19error_info_injectorINS_2io12too_few_argsEEEEE
N5boost16exception_detail19error_info_injectorINS_2io12too_few_argsEEE
N5boost2io12too_few_argsE
~N6quasar24ConfusionNetworkCombinerE
N6quasar14ResultCombinerE
N6quasar21RankingResultCombinerE
N6quasar13TextTokenizerE
N6quasar14BasicTokenizerE
N5kaldi27DecodableMatrixScaledMappedE
N5kaldi6quasar18SeevaStepInferenceE
N5kaldi6quasar24SeevaStepInferenceConfigE
N5kaldi6quasar20SeevaInferenceConfigE
N6quasar28VoiceCommandsBasicEndPointerE
N5boost9algorithm6detail13token_finderFINS1_10is_any_ofFIcEEEE
N5boost16exception_detail10clone_implINS0_19error_info_injectorINS_17bad_function_callEEEEE
N5boost16exception_detail19error_info_injectorINS_17bad_function_callEEE
N5boost17bad_function_callE
7LMStats
NSt3__120__shared_ptr_emplaceI5VocabNS_9allocatorIS1_EEEE
NSt3__120__shared_ptr_emplaceINS_13unordered_mapIjiNS_4hashIjEENS_8equal_toIjEENS_9allocatorINS_4pairIKjiEEEEEENS6_ISB_EEEE
NSt3__110__function6__funcIZN6quasar2lm46ComputeSRILMVocabToOpenFSTSymbolTableRemappingERK5VocabRKN3fst11SymbolTableEPNS_13unordered_mapIjiNS_4hashIjEENS_8equal_toIjEENS_9allocatorINS_4pairIKjiEEEEEEbE3$_0NSG_ISN_EEFvPKcjEEE
NSt3__110__function6__baseIFvPKcjEEE
ZN6quasar2lm46ComputeSRILMVocabToOpenFSTSymbolTableRemappingERK5VocabRKN3fst11SymbolTableEPNSt3__113unordered_mapIjiNS8_4hashIjEENS8_8equal_toIjEENS8_9allocatorINS8_4pairIKjiEEEEEEbE3$_0
!-[[
N6quasar20ExhaustiveEnumeratorE
!-[[
N6quasar48OnlineLASLmRescoringSpeculativeBeamSearchDecoderE
N3fst9ImplToFstINS_18ComposeFstImplBaseINS_6ArcTplINS_16LatticeWeightTplIfEEEENS_17DefaultCacheStoreIS5_EEEENS_3FstIS5_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar18QsrTextSymbolTableENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN3fst9ArcMapFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEENS3_INS1_16LatticeWeightTplIfEEEENS1_18StdToLatticeMapperIfEEEENS_9allocatorISC_EEEE
N3fst9ArcMapFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS1_INS_16LatticeWeightTplIfEEEENS_18StdToLatticeMapperIfEEEE
N3fst13ArcMapFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEENS1_INS_16LatticeWeightTplIfEEEENS_18StdToLatticeMapperIfEEEE
N3fst9CacheImplINS_6ArcTplINS_16LatticeWeightTplIfEEEEEE
NSt3__114default_deleteIN3fst11SymbolTableEEE
NSt3__120__shared_ptr_emplaceIN3fst14ArcScaleMapperENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN3fst9ArcMapFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEES6_NS1_14ArcScaleMapperEEENS_9allocatorIS8_EEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEES5_NS_14ArcScaleMapperEEENS_3FstIS5_EEEE
NSt3__120__shared_ptr_pointerIPN5kaldi6quasar13ESNetworkPlanENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIN5kaldi6quasar13ESNetworkPlanEEE
NSt3__120__shared_ptr_pointerIPN5kaldi6quasar22ComputeEngineBufferItfENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIN5kaldi6quasar22ComputeEngineBufferItfEEE
N3fst11ExpandedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N3fst15ArcIteratorBaseINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N3fst13VectorFstImplINS_11VectorStateINS_6ArcTplINS_17TropicalWeightTplIfEEEENSt3__19allocatorIS5_EEEEEE
NSt3__119__deque_base_commonILb1EEE
N3fst9VectorFstINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_11VectorStateIS6_NSt3__19allocatorIS6_EEEEEE
N3fst11ExpandedFstINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENSt3__19allocatorIS7_EEEEEE
N3fst15ArcIteratorBaseINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_24AltSequenceComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst18ShortestFirstQueueIiNS_18StateWeightCompareIiNS_11NaturalLessINS_17TropicalWeightTplIfEEEEEELb0EEE
N3fst9ImplToFstINS_22DeterminizeFstImplBaseINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEENS_3FstIS7_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar10ResultInfoENS_9allocatorIS2_EEEE
N6quasar16MultiAudioBufferE
N6quasar26MultiChainMultiAudioBufferE
N6quasar14NameEnumeratorE
N6quasar17RawCopyEnumeratorE
NSt3__120__shared_ptr_emplaceIN6quasar20SimpleNameEnumeratorENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar17RawCopyEnumeratorENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar20ExhaustiveEnumeratorENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar15RegexEnumeratorENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar25JapaneseDerivedEnumeratorENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar17DerivedEnumeratorENS_9allocatorIS2_EEEE
N5kaldi6quasar22ComputeEngineBufferItfE
N5kaldi6quasar16ComputeEngineItfE
N5kaldi6quasar22ComputeEngineConfigItfE
NSt3__110__function6__baseIFfNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEEEE
NSt3__110__function6__funcIZN5kaldi6quasar7AlignerINS3_20ConfusionNetworkSlotINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEEESB_EC1ENS_8functionIFfSC_SB_EEEEUlSC_E_NS9_ISH_EEFfSC_EEE
NSt3__110__function6__baseIFfN5kaldi6quasar20ConfusionNetworkSlotINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEEEEEE
ZN5kaldi6quasar7AlignerINS0_20ConfusionNetworkSlotINSt3__112basic_stringIcNS3_11char_traitsIcEENS3_9allocatorIcEEEEEES9_EC1ENS3_8functionIFfSA_S9_EEEEUlSA_E_
NSt3__110__function6__funcIZN5kaldi6quasar7AlignerINS3_20ConfusionNetworkSlotINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEEESB_EC1ENS_8functionIFfSC_SB_EEEEUlSB_E_NS9_ISH_EEFfSB_EEE
ZN5kaldi6quasar7AlignerINS0_20ConfusionNetworkSlotINSt3__112basic_stringIcNS3_11char_traitsIcEENS3_9allocatorIcEEEEEES9_EC1ENS3_8functionIFfSA_S9_EEEEUlS9_E_
N6quasar18InputHammerOptionsE
N6quasar25ConfiguredProcessingBlockINS_18InputHammerOptionsEEE
N6quasar16InputHammerBlockE
NSt3__120__shared_ptr_emplaceIN5kaldi17LatticeScoreCacheENS_9allocatorIS2_EEEE
N5sdapi14SdapiTokenizerE
!-``
NZSN3fst6quasar16MergeTrieFstImplE
N3fst6quasar12MergeTrieFstE
NSt3__120__shared_ptr_emplaceIN3fst6quasar16MergeTrieFstImplENS_9allocatorIS3_EEEE
supo
mcpl
N5kaldi26ContextDependencyInterfaceE
N5kaldi18DecodableInterfaceE
N5kaldi21E2EDecodableInterfaceE
N5kaldi32AutoRegressiveDecodableInterfaceE
N5kaldi10OptionsItfE
N5kaldi17FeedForwardNetItfE
N5kaldi22ModelInitializeContextE
N5kaldi15InferenceNetItfE
N5kaldi20EncoderDecoderNetItfE
N6quasar16BitmapLoaderImplE
?14_LM_FollowIter
NSt3__120__shared_ptr_emplaceI8WordInfoNS_9allocatorIS1_EEEE
N6quasar10OVSFeatureE
N6quasar23QualityEstimatorFeatureE
N6quasar17RepetitionFeatureE
N6quasar13LengthFeatureE
NSt3__120__shared_ptr_emplaceIN6quasar10OVSFeatureENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar17RepetitionFeatureENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar13LengthFeatureENS_9allocatorIS2_EEEE
N6quasar31OnlineLatticeBiglmFasterDecoderE
N3fst9VectorFstINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEENS_11VectorStateIS6_NSt3__19allocatorIS6_EEEEEE
NSt3__120__shared_ptr_emplaceIN6quasar7UttInfoENS_9allocatorIS2_EEEE
NSt3__110__function6__funcIZN6quasar31OnlineLatticeBiglmFasterDecoder26doEverythingWithRawLatticeERNS2_15DecoderPassDataERKNS_10shared_ptrINS2_18DecoderChainOutputEEERKNS6_INS2_17SpeechRequestDataEEERKN5kaldi6quasar37OnlineLatticeBiglmFasterDecoderConfigERKNS_6atomicIbEEE3$_0NS_9allocatorISO_EEFbvEEE
NSt3__110__function6__baseIFbvEEE
ZN6quasar31OnlineLatticeBiglmFasterDecoder26doEverythingWithRawLatticeERNS_15DecoderPassDataERKNSt3__110shared_ptrINS_18DecoderChainOutputEEERKNS4_INS_17SpeechRequestDataEEERKN5kaldi6quasar37OnlineLatticeBiglmFasterDecoderConfigERKNS3_6atomicIbEEE3$_0
N3fst10MemoryPoolINS_8DfsStateINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEE
NSt3__110shared_ptrIN3fst3FstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEEEEE27__shared_ptr_default_deleteIS7_NS1_9VectorFstIS6_NS1_11VectorStateIS6_NS_9allocatorIS6_EEEEEEEE
NSt3__114default_deleteIN3fst9VectorFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEENS1_11VectorStateIS6_NS_9allocatorIS6_EEEEEEEE
NSt3__120__shared_ptr_emplaceIN6quasar23StateAccessRecordingFstENS_9allocatorIS2_EEEE
NSt3__110__function6__funcIZN6quasar31OnlineLatticeBiglmFasterDecoder10finishInitEvE3$_1NS_9allocatorIS4_EEFNS_10shared_ptrIN3fst3FstINS8_6ArcTplINS8_17TropicalWeightTplIfEEEEEEEERKNS_12basic_stringIcNS_11char_traitsIcEENS5_IcEEEEEEE
NSt3__110__function6__baseIFNS_10shared_ptrIN3fst3FstINS3_6ArcTplINS3_17TropicalWeightTplIfEEEEEEEERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEEEE
ZN6quasar31OnlineLatticeBiglmFasterDecoder10finishInitEvE3$_1
NSt3__110__function6__funcIZN6quasar31OnlineLatticeBiglmFasterDecoder10finishInitEvE3$_2NS_9allocatorIS4_EEFNS_10shared_ptrIN5kaldi6quasar17NnlmEvaluatorBaseEEERKNS_12basic_stringIcNS_11char_traitsIcEENS5_IcEEEEEEE
ZN6quasar31OnlineLatticeBiglmFasterDecoder10finishInitEvE3$_2
NSt3__120__shared_ptr_emplaceIN6quasar21LRStreamingConfidenceENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar13EagerDecisionENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar23LatticeGenerationOutputENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN3fst31BackoffDeterministicOnDemandFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEENS1_3FstIS6_EEEENS_9allocatorIS9_EEEE
NSt3__120__shared_ptr_emplaceINS_6vectorINS_4pairIPN3fst24DeterministicOnDemandFstINS3_6ArcTplINS3_17TropicalWeightTplIfEEEEEEfEENS_9allocatorISB_EEEENSC_ISE_EEEE
NSt3__120__shared_ptr_emplaceIN3fst35LeftContextDeterministicOnDemandFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEEEENS_9allocatorIS7_EEEE
NSt3__120__shared_ptr_emplaceIN3fst31ComposeDeterministicOnDemandFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEENS1_24DeterministicOnDemandFstIS6_EES8_EENS_9allocatorIS9_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar31OnlineLatticeBiglmFasterDecoderIN3fst3FstINS4_6ArcTplINS4_17TropicalWeightTplIfEEEEEENS4_29CacheDeterministicOnDemandFstIS9_NS4_24DeterministicOnDemandFstIS9_EEEEEENS_9allocatorISF_EEEE
N5kaldi6quasar31OnlineLatticeBiglmFasterDecoderIN3fst3FstINS2_6ArcTplINS2_17TropicalWeightTplIfEEEEEENS2_29CacheDeterministicOnDemandFstIS7_NS2_24DeterministicOnDemandFstIS7_EEEEEE
N5kaldi6quasar34LatticeBiglmFasterTraceBackDecoderIN3fst3FstINS2_6ArcTplINS2_17TropicalWeightTplIfEEEEEENS2_29CacheDeterministicOnDemandFstIS7_NS2_24DeterministicOnDemandFstIS7_EEEEEE
N5kaldi6quasar9TokenHeap5TokenE
N5kaldi6quasar9TokenHeap11ForwardLinkE
NSt3__120__shared_ptr_emplaceIN3fst9VectorFstINS1_6ArcTplINS1_16LatticeWeightTplIfEEEENS1_11VectorStateIS6_NS_9allocatorIS6_EEEEEENS8_ISB_EEEE
NSt3__110__function6__funcIZN6quasar31OnlineLatticeBiglmFasterDecoder14finishDecodingERNS2_15DecoderPassDataERKNS_10shared_ptrINS2_18DecoderChainOutputEEERKNS6_INS2_17SpeechRequestDataEEEE3$_3NS_9allocatorISF_EEFbvEEE
ZN6quasar31OnlineLatticeBiglmFasterDecoder14finishDecodingERNS_15DecoderPassDataERKNSt3__110shared_ptrINS_18DecoderChainOutputEEERKNS4_INS_17SpeechRequestDataEEEE3$_3
NSt3__120__shared_ptr_emplaceIN6quasar24LatticeGenerationContextENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar15DecoderPassDataENS_9allocatorIS2_EEEE
N6quasar23StateAccessRecordingFstE
N6quasar34StateAccessRecordingFstArcIteratorE
NSt3__120__shared_ptr_emplaceIN6quasar23StateAccessRecordingFst4DataENS_9allocatorIS3_EEEE
N6quasar25AmbiguityAnnotatorOptionsE
N6quasar25ConfiguredProcessingBlockINS_25AmbiguityAnnotatorOptionsEEE
N6quasar23AmbiguityAnnotatorBlockE
NSt3__110__function6__funcIZN6quasar23AmbiguityAnnotatorBlock16MatchSpanCompareEbbE3$_0NS_9allocatorIS4_EEFbRKNS3_9MatchSpanES9_EEE
NSt3__110__function6__baseIFbRKN6quasar23AmbiguityAnnotatorBlock9MatchSpanES6_EEE
ZN6quasar23AmbiguityAnnotatorBlock16MatchSpanCompareEbbE3$_0
NSt3__110__function6__funcIZN6quasar23AmbiguityAnnotatorBlock16MatchSpanCompareEbbE3$_1NS_9allocatorIS4_EEFbRKNS3_9MatchSpanES9_EEE
ZN6quasar23AmbiguityAnnotatorBlock16MatchSpanCompareEbbE3$_1
NSt3__110__function6__funcIZN6quasar23AmbiguityAnnotatorBlock16MatchSpanCompareEbbE3$_2NS_9allocatorIS4_EEFbRKNS3_9MatchSpanES9_EEE
ZN6quasar23AmbiguityAnnotatorBlock16MatchSpanCompareEbbE3$_2
NSt3__110__function6__funcIZN6quasar23AmbiguityAnnotatorBlock16MatchSpanCompareEbbE3$_3NS_9allocatorIS4_EEFbRKNS3_9MatchSpanES9_EEE
ZN6quasar23AmbiguityAnnotatorBlock16MatchSpanCompareEbbE3$_3
N5kaldi6quasar33TransducerAutoRegressiveDecodableE
NSt3__110__function6__baseIFvPK4TrieIj6BOnodeEjRKNS_6vectorIjNS_9allocatorIjEEEES6_EEE
NSt3__110__function6__funcIZN6quasar2lm9srilm_ext11IterateTrieERK4TrieIj6BOnodeEiNS_8functionIFvPS8_jRKNS_6vectorIjNS_9allocatorIjEEEESB_EEEE3$_4NSD_ISK_EEFvSB_jjSB_EEE
NSt3__110__function6__baseIFvPK4TrieIj6BOnodeEjjS6_EEE
ZN6quasar2lm9srilm_ext11IterateTrieERK4TrieIj6BOnodeEiNSt3__18functionIFvPS5_jRKNS7_6vectorIjNS7_9allocatorIjEEEES9_EEEE3$_4
NSt3__120__shared_ptr_pointerIPN6quasar14ContextualDataENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN6quasar14ContextualDataEEE
.N5kaldi6quasar18TooManyTokensErrorE
N5kaldi6quasar24TooManyForwardLinksErrorE
B=GL8t`V~[yo
N5kaldi5nnet19ComponentE
N5kaldi5nnet118UpdatableComponentE
N5kaldi5nnet127Quantizable8BitComponentItfE
N5kaldi5nnet128Quantizable16BitComponentItfE
N5kaldi5nnet115LinearTransformINS_15QuantizedMatrixIaEEEE
N5kaldi5nnet115LinearTransformINS_15QuantizedMatrixIsEEEE
N5kaldi5nnet132ConvolutionalMaxPoolingComponentINS_12CuMatrixBaseIfEEEE
N5kaldi5nnet132ConvolutionalMaxPoolingComponentINS_15QuantizedMatrixIaEEEE
N5kaldi5nnet122ConvolutionalComponentE
N5kaldi5nnet124Convolutional2DComponentINS_15QuantizedMatrixIsEEEE
N5kaldi5nnet122RecurrentBaseComponentE
N5kaldi5nnet119HistoricalComponentE
N5kaldi5nnet116WordVecComponentE
N5kaldi5nnet124CompressibleComponentItfE
N5kaldi5nnet120FofeWordVecComponentE
N5kaldi5nnet121WordMultiVecComponentINS_12CuMatrixBaseIfEEEE
N5kaldi5nnet121WordMultiVecComponentINS_16CompressedMatrixEEE
N5kaldi5nnet126CompressedWordVecComponentE
N5kaldi5nnet17SoftmaxE
N5kaldi5nnet110LogSoftmaxE
N5kaldi5nnet112BlockSoftmaxE
N5kaldi5nnet114RelaxedSoftmaxE
N5kaldi5nnet17SigmoidE
N5kaldi5nnet14TanhE
N5kaldi5nnet17DropoutE
N5kaldi5nnet115MaxoutComponentE
N5kaldi5nnet114PNormComponentE
N5kaldi5nnet124RectifiedLinearComponentE
N5kaldi5nnet126ExponentialLinearComponentE
N5kaldi5nnet132ScaledExponentialLinearComponentE
N5kaldi5nnet13RbmE
N5kaldi5nnet17RbmBaseE
N5kaldi5nnet16SpliceE
N5kaldi5nnet113CopyComponentE
N5kaldi5nnet18AddShiftE
N5kaldi5nnet17RescaleE
N5kaldi5nnet15KlHmmE
N5kaldi5nnet126SentenceAveragingComponentE
N5kaldi5nnet123AveragePoolingComponentE
N5kaldi5nnet125AveragePooling2DComponentE
N5kaldi5nnet119MaxPoolingComponentE
N5kaldi5nnet121MaxPooling2DComponentE
N5kaldi5nnet121FramePoolingComponentE
N5kaldi5nnet117ParallelComponentE
N5kaldi5nnet112MultiSoftmaxE
N5kaldi5nnet19RecurrentE
N5kaldi5nnet118DuplicateComponentE
N5kaldi5nnet117IdentityComponentE
N5kaldi5nnet18DespliceE
N5kaldi5nnet118SharedNceComponentE
N5kaldi5nnet127TemporalMaxPoolingComponentE
N5kaldi5nnet122InterpolationComponentE
N5kaldi5nnet128CompressedWordTransComponentE
N5kaldi5nnet134VectorwiseQuantizedAffineTransformIaEE
N5kaldi5nnet134VectorwiseQuantizedAffineTransformIsEE
N5kaldi5nnet122AttentionBaseComponentE
N5kaldi5nnet131RecurrentAttentionBaseComponentE
N5kaldi5nnet131AttentionBaseInferenceComponentE
N5kaldi5nnet117Nnet1InferenceNetE
N5kaldi5nnet137VectorwiseQuantizable8BitComponentItfE
N5kaldi11CuSubMatrixIfEE
N6quasar20SentencePieceOptionsE
N6quasar25ConfiguredProcessingBlockINS_20SentencePieceOptionsEEE
N6quasar18SentencePieceBlockE
NSt3__120__shared_ptr_pointerIPN13sentencepiece22SentencePieceProcessorENS_10shared_ptrIS2_E27__shared_ptr_default_deleteIS2_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrIN13sentencepiece22SentencePieceProcessorEE27__shared_ptr_default_deleteIS2_S2_EE
NSt3__114default_deleteIN13sentencepiece22SentencePieceProcessorEEE
14NgramEvalStats
N6quasar17LmeWordTaggerBaseE
N6quasar22IndexRuleLmeWordTaggerE
$0rr
!-[[
FLS11TaggedVocab
p}?N6quasar17DerivedEnumeratorE
N6quasar17DerivedEnumerator9AlgorithmE
N6quasar15EnLikeAlgorithmE
N6quasar15ZhLikeAlgorithmE
L>~A
2?8==
N3fst9ImplToFstINS_18ComposeFstImplBaseINS_6ArcTplINS_12LogWeightTplIfEEEENS_17DefaultCacheStoreIS5_EEEENS_3FstIS5_EEEE
N3fst3FstINS_6ArcTplINS_12LogWeightTplIfEEEEEE
N3fst10MutableFstINS_6ArcTplINS_12LogWeightTplIfEEEEEE
N3fst13VectorFstImplINS_11VectorStateINS_6ArcTplINS_12LogWeightTplIfEEEENSt3__19allocatorIS5_EEEEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_6ArcTplINS_12LogWeightTplIfEEEENSt3__19allocatorIS5_EEEEEE
N3fst7FstImplINS_6ArcTplINS_12LogWeightTplIfEEEEEE
N3fst10ComposeFstINS_6ArcTplINS_12LogWeightTplIfEEEENS_17DefaultCacheStoreIS4_EEEE
N3fst13SortedMatcherINS_3FstINS_6ArcTplINS_12LogWeightTplIfEEEEEEEE
N3fst11MatcherBaseINS_6ArcTplINS_12LogWeightTplIfEEEEEE
N3fst10MemoryPoolINS_11ArcIteratorINS_3FstINS_6ArcTplINS_12LogWeightTplIfEEEEEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_11ArcIteratorINS_3FstINS_6ArcTplINS_12LogWeightTplIfEEEEEEEEE4LinkEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_12LogWeightTplIfEEEEEENS_21SequenceComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst18ComposeFstImplBaseINS_6ArcTplINS_12LogWeightTplIfEEEENS_17DefaultCacheStoreIS4_EEEE
N3fst13CacheBaseImplINS_10CacheStateINS_6ArcTplINS_12LogWeightTplIfEEEENSt3__19allocatorIS5_EEEENS_17DefaultCacheStoreIS5_EEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_12LogWeightTplIfEEEEEENS_21SequenceComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_12LogWeightTplIfEEEEEENS_23PushLabelsComposeFilterINS_24PushWeightsComposeFilterINS_22LookAheadComposeFilterINS_24AltSequenceComposeFilterINS_16LookAheadMatcherINS_3FstIS5_EEEESE_EESE_SE_LNS_9MatchTypeE2EEESE_SE_LSG_2EEESE_SE_LSG_2EEENS_24GenericComposeStateTableIS5_NS_15PairFilterStateINSL_INS_18IntegerFilterStateIaEENS_17WeightFilterStateIS4_EEEENSM_IiEEEENS_24DefaultComposeStateTupleIiSS_EENS_21CompactHashStateTableISU_NS_11ComposeHashISU_EEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_12LogWeightTplIfEEEEEENS_23PushLabelsComposeFilterINS_24PushWeightsComposeFilterINS_22LookAheadComposeFilterINS_21SequenceComposeFilterINS_16LookAheadMatcherINS_3FstIS5_EEEESE_EESE_SE_LNS_9MatchTypeE2EEESE_SE_LSG_2EEESE_SE_LSG_2EEENS_24GenericComposeStateTableIS5_NS_15PairFilterStateINSL_INS_18IntegerFilterStateIaEENS_17WeightFilterStateIS4_EEEENSM_IiEEEENS_24DefaultComposeStateTupleIiSS_EENS_21CompactHashStateTableISU_NS_11ComposeHashISU_EEEEEEEE
N3fst13StateIteratorINS_10ComposeFstINS_6ArcTplINS_12LogWeightTplIfEEEENS_17DefaultCacheStoreIS5_EEEEEE
N3fst18CacheStateIteratorINS_10ComposeFstINS_6ArcTplINS_12LogWeightTplIfEEEENS_17DefaultCacheStoreIS5_EEEEEE
N3fst17StateIteratorBaseINS_6ArcTplINS_12LogWeightTplIfEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_12LogWeightTplIfEEEEEENS_17NullComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_12LogWeightTplIfEEEEEENS_17NullComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_12LogWeightTplIfEEEEEENS_24AltSequenceComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_12LogWeightTplIfEEEEEENS_24AltSequenceComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_12LogWeightTplIfEEEEEENS_18MatchComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_12LogWeightTplIfEEEEEENS_18MatchComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst9VectorFstINS_10ReverseArcINS_6ArcTplINS_12LogWeightTplIfEEEEEENS_11VectorStateIS6_NSt3__19allocatorIS6_EEEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_12LogWeightTplIfEEEEEENSt3__19allocatorIS8_EEEEEENS_10MutableFstIS8_EEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_12LogWeightTplIfEEEEEENSt3__19allocatorIS8_EEEEEENS_10MutableFstIS8_EEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_12LogWeightTplIfEEEEEENSt3__19allocatorIS8_EEEEEENS_10MutableFstIS8_EEEE
N3fst10MutableFstINS_10ReverseArcINS_6ArcTplINS_12LogWeightTplIfEEEEEEEE
N3fst11ExpandedFstINS_10ReverseArcINS_6ArcTplINS_12LogWeightTplIfEEEEEEEE
N3fst3FstINS_10ReverseArcINS_6ArcTplINS_12LogWeightTplIfEEEEEEEE
N3fst13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_12LogWeightTplIfEEEEEENSt3__19allocatorIS7_EEEEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_12LogWeightTplIfEEEEEENSt3__19allocatorIS7_EEEEEE
N3fst7FstImplINS_10ReverseArcINS_6ArcTplINS_12LogWeightTplIfEEEEEEEE
N3fst10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_6ArcTplINS_12LogWeightTplIfEEEEEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_6ArcTplINS_12LogWeightTplIfEEEEEEEEE4LinkEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_10ReverseArcINS_6ArcTplINS_12LogWeightTplIfEEEEEENS_11VectorStateIS7_NSt3__19allocatorIS7_EEEEEEEE
N3fst22MutableArcIteratorBaseINS_10ReverseArcINS_6ArcTplINS_12LogWeightTplIfEEEEEEEE
N3fst15ArcIteratorBaseINS_10ReverseArcINS_6ArcTplINS_12LogWeightTplIfEEEEEEEE
N3fst9VectorFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEENS_11VectorStateIS7_NSt3__19allocatorIS7_EEEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEENSt3__19allocatorIS9_EEEEEENS_10MutableFstIS9_EEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEENSt3__19allocatorIS9_EEEEEENS_10MutableFstIS9_EEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEENSt3__19allocatorIS9_EEEEEENS_10MutableFstIS9_EEEE
N3fst10MutableFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEE
N3fst11ExpandedFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEE
N3fst3FstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEE
N3fst13VectorFstImplINS_11VectorStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEENSt3__19allocatorIS8_EEEEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEENSt3__19allocatorIS8_EEEEEE
N3fst7FstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEE
N3fst10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEEE4LinkEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEENS_11VectorStateIS8_NSt3__19allocatorIS8_EEEEEEEE
N3fst22MutableArcIteratorBaseINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEE
N3fst15ArcIteratorBaseINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEE
N3fst9VectorFstINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEENS_11VectorStateIS9_NSt3__19allocatorIS9_EEEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEENSt3__19allocatorISB_EEEEEENS_10MutableFstISB_EEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEENSt3__19allocatorISB_EEEEEENS_10MutableFstISB_EEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEENSt3__19allocatorISB_EEEEEENS_10MutableFstISB_EEEE
N3fst10MutableFstINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEEEE
N3fst11ExpandedFstINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEEEE
N3fst3FstINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEEEE
N3fst13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEENSt3__19allocatorISA_EEEEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEENSt3__19allocatorISA_EEEEEE
N3fst7FstImplINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEEEE
N3fst10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEEEEE4LinkEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEENS_11VectorStateISA_NSt3__19allocatorISA_EEEEEEEE
N3fst22MutableArcIteratorBaseINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEEEE
N3fst15ArcIteratorBaseINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEEEE
N3fst9ArcMapFstINS_6ArcTplINS_12LogWeightTplIfEEEES4_NS_14RmWeightMapperIS4_S4_EEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_6ArcTplINS_12LogWeightTplIfEEEES5_NS_14RmWeightMapperIS5_S5_EEEENS_3FstIS5_EEEE
N3fst13ArcMapFstImplINS_6ArcTplINS_12LogWeightTplIfEEEES4_NS_14RmWeightMapperIS4_S4_EEEE
N3fst13StateIteratorINS_9ArcMapFstINS_6ArcTplINS_12LogWeightTplIfEEEES5_NS_14RmWeightMapperIS5_S5_EEEEEE
N3fst9ArcMapFstINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE1EEENS_14ToGallicMapperIS4_LS6_1EEEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE1EEENS_14ToGallicMapperIS5_LS7_1EEEEENS_3FstIS8_EEEE
N3fst13ArcMapFstImplINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE1EEENS_14ToGallicMapperIS4_LS6_1EEEEE
N3fst9CacheImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEE
N3fst13CacheBaseImplINS_10CacheStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEENSt3__19allocatorIS8_EEEENS_17DefaultCacheStoreIS8_EEEE
N3fst13StateIteratorINS_9ArcMapFstINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE1EEENS_14ToGallicMapperIS5_LS7_1EEEEEEE
N3fst17StateIteratorBaseINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEE
N3fst15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEENS_12GallicFactorIiS4_LS6_1EEEEE
N3fst9ImplToFstINS_19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEENS_12GallicFactorIiS5_LS7_1EEEEENS_3FstIS8_EEEE
N3fst19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEENS_12GallicFactorIiS4_LS6_1EEEEE
N3fst13StateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEENS_12GallicFactorIiS5_LS7_1EEEEEEE
N3fst18CacheStateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEENS_12GallicFactorIiS5_LS7_1EEEEEEE
N3fst12SigmaMatcherINS_13SortedMatcherINS_3FstINS_6ArcTplINS_12LogWeightTplIfEEEEEEEEEE
N3fst10RhoMatcherINS_12SigmaMatcherINS_13SortedMatcherINS_3FstINS_6ArcTplINS_12LogWeightTplIfEEEEEEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_12LogWeightTplIfEEEEEENS_21SequenceComposeFilterINS_10RhoMatcherINS_12SigmaMatcherINS_13SortedMatcherINS_3FstIS5_EEEEEEEESF_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSJ_EENS_21CompactHashStateTableISL_NS_11ComposeHashISL_EEEEEEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_12LogWeightTplIfEEEEEENS_21SequenceComposeFilterINS_10RhoMatcherINS_12SigmaMatcherINS_13SortedMatcherINS_3FstIS5_EEEEEEEESF_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSJ_EENS_21CompactHashStateTableISL_NS_11ComposeHashISL_EEEEEEEE
N3fst12SigmaMatcherINS_13SortedMatcherINS_3FstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_21SequenceComposeFilterINS_12SigmaMatcherINS_13SortedMatcherINS_3FstIS5_EEEEEESD_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSH_EENS_21CompactHashStateTableISJ_NS_11ComposeHashISJ_EEEEEEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_21SequenceComposeFilterINS_12SigmaMatcherINS_13SortedMatcherINS_3FstIS5_EEEEEESD_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSH_EENS_21CompactHashStateTableISJ_NS_11ComposeHashISJ_EEEEEEEE
N3fst18CacheStateIteratorINS_10ComposeFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_17DefaultCacheStoreIS5_EEEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENSt3__19allocatorIS8_EEEEEENS_10MutableFstIS8_EEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENSt3__19allocatorIS8_EEEEEENS_10MutableFstIS8_EEEE
N3fst13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENSt3__19allocatorIS7_EEEEEE
N3fst10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEEEE
N3fst18DeterminizeFsaImplINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_20DefaultCommonDivisorIS3_EENS_24DefaultDeterminizeFilterIS4_EENS_28DefaultDeterminizeStateTableIS4_NS_18IntegerFilterStateIaEEEEEE
N3fst22DeterminizeFstImplBaseINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N3fst18DeterminizeFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3ENS_20DefaultCommonDivisorIS3_EENS_24DefaultDeterminizeFilterIS4_EENS_28DefaultDeterminizeStateTableIS4_NS_18IntegerFilterStateIaEEEEEE
N3fst13StateIteratorINS_14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEEEEEE
N3fst18CacheStateIteratorINS_14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEEEEEE
N3fst15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEENS_12GallicFactorIiS4_LS6_3EEEEE
N3fst9ImplToFstINS_19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEENS_12GallicFactorIiS5_LS7_3EEEEENS_3FstIS8_EEEE
N3fst19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEENS_12GallicFactorIiS4_LS6_3EEEEE
N3fst13StateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEENS_12GallicFactorIiS5_LS7_3EEEEEEE
N3fst18CacheStateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEENS_12GallicFactorIiS5_LS7_3EEEEEEE
N3fst9ArcMapFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEES5_NS_16FromGallicMapperIS5_LS6_3EEEEE
N3fst13ArcMapFstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEES5_NS_16FromGallicMapperIS5_LS6_3EEEEE
N3fst13StateIteratorINS_9ArcMapFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEES6_NS_16FromGallicMapperIS6_LS7_3EEEEEEE
N3fst18DeterminizeFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2ENS_20DefaultCommonDivisorIS3_EENS_24DefaultDeterminizeFilterIS4_EENS_28DefaultDeterminizeStateTableIS4_NS_18IntegerFilterStateIaEEEEEE
N3fst9ArcMapFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE2EEENS_14ToGallicMapperIS4_LS6_2EEEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE2EEENS_14ToGallicMapperIS5_LS7_2EEEEENS_3FstIS8_EEEE
N3fst3FstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEEEE
N3fst13ArcMapFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE2EEENS_14ToGallicMapperIS4_LS6_2EEEEE
N3fst9CacheImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEEEE
N3fst13CacheBaseImplINS_10CacheStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEENSt3__19allocatorIS8_EEEENS_17DefaultCacheStoreIS8_EEEE
N3fst7FstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEEEE
N3fst10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEEEEE4LinkEEE
N3fst17StateIteratorBaseINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEEEE
N3fst14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEEEE
N3fst9ImplToFstINS_22DeterminizeFstImplBaseINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEEEENS_3FstIS8_EEEE
N3fst18DeterminizeFsaImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEENS_19GallicCommonDivisorIiS4_LS6_2ENS_20DefaultCommonDivisorIS4_EEEENS_24DefaultDeterminizeFilterIS7_EENS_28DefaultDeterminizeStateTableIS7_NS_18IntegerFilterStateIaEEEEEE
N3fst22DeterminizeFstImplBaseINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEEEE
N3fst13StateIteratorINS_14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEEEEEE
N3fst18CacheStateIteratorINS_14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEEEEEE
N3fst15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEENS_12GallicFactorIiS4_LS6_2EEEEE
N3fst9ImplToFstINS_19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEENS_12GallicFactorIiS5_LS7_2EEEEENS_3FstIS8_EEEE
N3fst19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEENS_12GallicFactorIiS4_LS6_2EEEEE
N3fst13StateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEENS_12GallicFactorIiS5_LS7_2EEEEEEE
N3fst18CacheStateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEENS_12GallicFactorIiS5_LS7_2EEEEEEE
N3fst9ArcMapFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEES5_NS_16FromGallicMapperIS5_LS6_2EEEEE
N3fst13ArcMapFstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEES5_NS_16FromGallicMapperIS5_LS6_2EEEEE
N3fst13StateIteratorINS_9ArcMapFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEES6_NS_16FromGallicMapperIS6_LS7_2EEEEEEE
N3fst18DeterminizeFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4ENS_20DefaultCommonDivisorIS3_EENS_24DefaultDeterminizeFilterIS4_EENS_28DefaultDeterminizeStateTableIS4_NS_18IntegerFilterStateIaEEEEEE
N3fst9ArcMapFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE4EEENS_14ToGallicMapperIS4_LS6_4EEEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE4EEENS_14ToGallicMapperIS5_LS7_4EEEEENS_3FstIS8_EEEE
N3fst3FstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEEEE
N3fst13ArcMapFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE4EEENS_14ToGallicMapperIS4_LS6_4EEEEE
N3fst9CacheImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEEEE
N3fst13CacheBaseImplINS_10CacheStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEENSt3__19allocatorIS8_EEEENS_17DefaultCacheStoreIS8_EEEE
N3fst7FstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEEEE
N3fst10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEEEEE4LinkEEE
N3fst17StateIteratorBaseINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEEEE
N3fst14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEEEE
N3fst9ImplToFstINS_22DeterminizeFstImplBaseINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEEEENS_3FstIS8_EEEE
N3fst18DeterminizeFsaImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEENS_19GallicCommonDivisorIiS4_LS6_4ENS_20DefaultCommonDivisorIS4_EEEENS_24DefaultDeterminizeFilterIS7_EENS_28DefaultDeterminizeStateTableIS7_NS_18IntegerFilterStateIaEEEEEE
N3fst22DeterminizeFstImplBaseINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEEEE
N3fst13StateIteratorINS_14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEEEEEE
N3fst18CacheStateIteratorINS_14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEEEEEE
N3fst15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEENS_12GallicFactorIiS4_LS6_4EEEEE
N3fst9ImplToFstINS_19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEENS_12GallicFactorIiS5_LS7_4EEEEENS_3FstIS8_EEEE
N3fst19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEENS_12GallicFactorIiS4_LS6_4EEEEE
N3fst13StateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEENS_12GallicFactorIiS5_LS7_4EEEEEEE
N3fst18CacheStateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEENS_12GallicFactorIiS5_LS7_4EEEEEEE
N3fst9ArcMapFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEES5_NS_16FromGallicMapperIS5_LS6_4EEEEE
N3fst13ArcMapFstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEES5_NS_16FromGallicMapperIS5_LS6_4EEEEE
N3fst13StateIteratorINS_9ArcMapFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEES6_NS_16FromGallicMapperIS6_LS7_4EEEEEEE
N3fst18CacheStateIteratorINS_14DeterminizeFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEE
N3fst9VectorFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEENS_11VectorStateIS7_NSt3__19allocatorIS7_EEEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEENSt3__19allocatorIS9_EEEEEENS_10MutableFstIS9_EEEE
N3fst10MutableFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N3fst13VectorFstImplINS_11VectorStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEENSt3__19allocatorIS8_EEEEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEENSt3__19allocatorIS8_EEEEEE
N3fst7FstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N3fst15ArcIteratorBaseINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N3fst9VectorFstINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEENS_11VectorStateIS9_NSt3__19allocatorIS9_EEEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEENSt3__19allocatorISB_EEEEEENS_10MutableFstISB_EEEE
N3fst10MutableFstINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEEEE
N3fst13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEENSt3__19allocatorISA_EEEEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEENSt3__19allocatorISA_EEEEEE
N3fst7FstImplINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEEEE
N3fst15ArcIteratorBaseINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEEEE
N3fst15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEENS_12GallicFactorIiS4_LS6_0EEEEE
N3fst9ImplToFstINS_19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEENS_12GallicFactorIiS5_LS7_0EEEEENS_3FstIS8_EEEE
N3fst13CacheBaseImplINS_10CacheStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEENSt3__19allocatorIS8_EEEENS_17DefaultCacheStoreIS8_EEEE
N3fst18CacheStateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEENS_12GallicFactorIiS5_LS7_0EEEEEEE
N3fst17StateIteratorBaseINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N6quasar8artifact27AppLmArtifactLifeCycleStageE
AN6quasar27OnlineSeevaStepBigLmDecoderE
N5kaldi6quasar26SeevaStepLmInferenceConfigE
N5kaldi12CuMatrixBaseIfEE
NSt3__120__shared_ptr_emplaceIN3fst14BackoffArcInfoENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar31DeterministicOnDemandFstCreatorIN3fst6ArcTplINS4_17TropicalWeightTplIfEEEEEENS_9allocatorIS9_EEEE
N3fst18CacheStateIteratorINS_10ReplaceFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_24DefaultReplaceStateTableIS5_lEENS_17DefaultCacheStoreIS5_EEEEEE
N3fst13SortedMatcherINS_10ReplaceFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_24DefaultReplaceStateTableIS5_lEENS_17DefaultCacheStoreIS5_EEEEEE
N5kaldi6quasar27NeuralNgramDeterministicFstIN3fst6ArcTplINS2_17TropicalWeightTplIfEEEEEE
NSt3__120__shared_ptr_emplaceIN3fst35InterpolateDeterministicOnDemandFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEEEENS_9allocatorIS7_EEEE
N3fst35InterpolateDeterministicOnDemandFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
NSt3__120__shared_ptr_emplaceIN3fst29CacheDeterministicOnDemandFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEENS1_24DeterministicOnDemandFstIS6_EEEENS_9allocatorIS9_EEEE
N5boost13property_tree10xml_parser16xml_parser_errorE
N5boost13property_tree6detail8rapidxml11parse_errorE
N5boost16exception_detail10clone_implINS0_19error_info_injectorINS_13property_tree10xml_parser16xml_parser_errorEEEEE
N5boost16exception_detail19error_info_injectorINS_13property_tree10xml_parser16xml_parser_errorEEE
N6quasar26OnlineLASBeamSearchDecoderE
N3fst18ShortestFirstQueueIiNS_18StateWeightCompareIiNS_11NaturalLessINS_16LatticeWeightTplIfEEEEEELb0EEE
N3fst9ImplToFstINS_22DeterminizeFstImplBaseINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEENS_3FstIS7_EEEE
N3fst18DeterminizeFsaImplINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENS_20DefaultCommonDivisorIS4_EENS_24DefaultDeterminizeFilterIS6_EENS_28DefaultDeterminizeStateTableIS6_NS_18IntegerFilterStateIaEEEEEE
N3fst9CacheImplINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEE
NSt3__120__shared_ptr_emplaceIN6quasar25ConcreteSpeechRequestDataENS_9allocatorIS2_EEEE
N6quasar13WordPronCacheE
N6quasar7LmeDataE
IOV@
N6quasar22SpeechRecognizerConfig23UnsupportedVersionErrorE
N6quasar16SpeechRecognizerE
NSt3__123enable_shared_from_thisIN6quasar16SpeechRecognizerEEE
NSt3__120__shared_ptr_emplaceINS_5mutexENS_9allocatorIS1_EEEE
N6quasar16SpeechRecognizer25ModelLoaderFactoryAdapterE
N6quasar27SpeechRecognizerModelLoader7FactoryE
NSt3__120__shared_ptr_emplaceIN6quasar19SpeakerCodeTrainingENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar16RecogAudioBufferENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_pointerIPN6quasar26DecoderChainPersistentDataENS_10shared_ptrIS2_E27__shared_ptr_default_deleteIS2_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrIN6quasar26DecoderChainPersistentDataEE27__shared_ptr_default_deleteIS2_S2_EE
NSt3__114default_deleteIN6quasar26DecoderChainPersistentDataEEE
N5kaldi8CuMatrixIfEE
NSt3__120__shared_ptr_pointerIPN6quasar16SpeechRecognizerENS_10shared_ptrIS2_E27__shared_ptr_default_deleteIS2_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrIN6quasar16SpeechRecognizerEE27__shared_ptr_default_deleteIS2_S2_EE
NSt3__114default_deleteIN6quasar16SpeechRecognizerEEE
NSt3__110__function6__funcINS_6__bindIMN6quasar16SpeechRecognizerEFbvEJPS4_EEENS_9allocatorIS8_EEFbvEEE
NSt3__16__bindIMN6quasar16SpeechRecognizerEFbvEJPS2_EEE
NSt3__118__weak_result_typeIMN6quasar16SpeechRecognizerEFbvEEE
NSt3__114unary_functionIPN6quasar16SpeechRecognizerEbEE
NSt3__120__shared_ptr_emplaceIN6quasar21ConfusionNetworkCacheENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar27SpeechRecognizerModelLoaderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar25SpeakerCodeTrainingConfigENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar9MuxHelperENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar26MultiChainMultiAudioBufferENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar16MultiAudioBufferENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi20OnlineBufferingInputENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar18OnlineCacheInputFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceINS_5queueIN5kaldi8CuMatrixIfEENS_5dequeIS4_NS_9allocatorIS4_EEEEEENS6_IS9_EEEE
NSt3__120__shared_ptr_emplaceIjNS_9allocatorIjEEEE
NSt3__120__shared_ptr_emplaceIN5kaldi19OnlineFeatureMatrixENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar25SilencePosteriorGeneratorENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar22ResultStreamStabilizerENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar5PTreeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceINS_6vectorINS1_IN6quasar5TokenENS_9allocatorIS3_EEEENS4_IS6_EEEENS4_IS8_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar15SyncRecogResultENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar20SyncRecogAudioBufferENS_9allocatorIS2_EEEE
NSt3__110__function6__baseIFfffEEE
NSt3__110__function6__funcIN5kaldi6quasar19ConfusionNetworkArcINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEEUlffE_ENS8_ISC_EEFfffEEE
N5kaldi6quasar19ConfusionNetworkArcINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEEUlffE_E
NSt3__110__function6__funcIZN5kaldi6quasar16ConfusionNetworkINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEE9ConstructEvEUlNS3_20ConfusionNetworkSlotISA_EESA_E_NS8_ISE_EEFfSD_SA_EEE
NSt3__110__function6__baseIFfN5kaldi6quasar20ConfusionNetworkSlotINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEEESA_EEE
ZN5kaldi6quasar16ConfusionNetworkINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEE9ConstructEvEUlNS0_20ConfusionNetworkSlotIS8_EES8_E_
N6quasar10filesystem22TemporaryDirectoryPathE
N5boost9exceptionE
N6quasar20LatticeLmeFtmDecoderE
N6quasar27SpeechRecognizerModelLoader14DefaultFactoryE
NSt3__120__shared_ptr_emplaceIN6quasar20RecognizerComponentsINS1_7DecoderEEENS_9allocatorIS4_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar31SilencePosteriorGeneratorConfigENS_9allocatorIS2_EEEE
N6quasar15RegexEnumeratorE
NSt3__120__shared_ptr_emplaceIN6quasar11ReplaceStepENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar9SplitStepENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar15WholeStringStepENS_9allocatorIS2_EEEE
?NSt3__121__basic_string_commonILb1EEE
N6quasar18DatabasePhraseBookE
N6quasar17GenericPhraseBookE
NSt3__120__shared_ptr_pointerIPN6quasar18DatabasePhraseBookENS_10shared_ptrIS2_E27__shared_ptr_default_deleteIS2_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrIN6quasar18DatabasePhraseBookEE27__shared_ptr_default_deleteIS2_S2_EE
NSt3__114default_deleteIN6quasar18DatabasePhraseBookEEE
N6quasar14QuasarTextProcE
N3fst8ConstFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEjEE
N3fst17ImplToExpandedFstINS_12ConstFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEEjEENS_11ExpandedFstIS5_EEEE
N3fst9ImplToFstINS_12ConstFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEEjEENS_11ExpandedFstIS5_EEEE
NSt3__120__shared_ptr_pointerIPN3fst8ConstFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEEjEENS_10shared_ptrINS1_3FstIS6_EEE27__shared_ptr_default_deleteISB_S7_EENS_9allocatorIS7_EEEE
NSt3__110shared_ptrIN3fst3FstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEEEEE27__shared_ptr_default_deleteIS7_NS1_8ConstFstIS6_jEEEE
NSt3__114default_deleteIN3fst8ConstFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEEjEEEE
NSt3__120__shared_ptr_emplaceIN6quasar21InverseTextNormalizerENS_9allocatorIS2_EEEE
N5kaldi18OnlineFeatInputItfE
N5kaldi15OnlineCmvnInputE
N5kaldi14OnlineCmnInputE
N5kaldi16OnlineCacheInputE
N5kaldi19OnlineRecordedInputE
N5kaldi17OnlineSpliceInputE
N5kaldi22OnlineSpliceBatchInputE
N5kaldi22OnlineNnetForwardInputE
N5kaldi29OnlineNnetForwardSkippedInputE
N5kaldi17OnlineAppendInputE
N5kaldi17OnlineSubsampleFeE
N5kaldi14OnlineLdaInputE
N5kaldi20OnlineTransformInputE
N5kaldi20OnlineBufferingInputE
N5kaldi14OnlinePadInputE
N5kaldi16OnlineDeltaInputE
&2?nn
Y_fN6quasar28OnlineKeywordSpottingDecoderE
9StopNgram
N3fst12ArcPosingFstINS_6ArcTplINS_12LogWeightTplIfEEEENS1_INS_17TropicalWeightTplIfEEEEEE
N3fst11ExpandedFstINS_6ArcTplINS_12LogWeightTplIfEEEEEE
N3fst11ArcIteratorINS_12ArcPosingFstINS_6ArcTplINS_12LogWeightTplIfEEEENS2_INS_17TropicalWeightTplIfEEEEEEEE
N3fst12ArcPosingFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS1_INS_12LogWeightTplIfEEEEEE
N3fst11ArcIteratorINS_12ArcPosingFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS2_INS_12LogWeightTplIfEEEEEEEE
N3fst16TableMatcherImplINS_3FstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_13SortedMatcherIS6_EEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_21SequenceComposeFilterINS_12TableMatcherINS_3FstIS5_EENS_13SortedMatcherISA_EEEESC_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSH_EENS_21CompactHashStateTableISJ_NS_11ComposeHashISJ_EEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_21SequenceComposeFilterINS_13SortedMatcherINS_3FstIS5_EEEENS_12TableMatcherISA_SB_EEEENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSH_EENS_21CompactHashStateTableISJ_NS_11ComposeHashISJ_EEEEEEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_21SequenceComposeFilterINS_13SortedMatcherINS_3FstIS5_EEEENS_12TableMatcherISA_SB_EEEENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSH_EENS_21CompactHashStateTableISJ_NS_11ComposeHashISJ_EEEEEEEE
N6quasar16FeatureExtractorE
N6quasar11OnlineCmnFeE
N6quasar12OnlineCmvnFeE
N6quasar13OnlineDeltaFeE
N6quasar13OnlineFbankFeE
N6quasar22OnlineFbankWithPitchFeE
N6quasar31OnlineFbankWithAudioAnalyticsFeE
N6quasar11OnlineLdaFeE
N6quasar12OnlineMfccFeE
N6quasar19OnlineNnetForwardFeE
N6quasar23OnlineNnetForwardSkipFeE
N6quasar14OnlineSpliceFeE
N6quasar23OnlineStaticTransformFeE
N6quasar18OnlineCacheInputFeE
N6quasar25OnlineComputeAheadInputFeE
N6quasar17OnlineSubsampleFeE
NSt3__120__shared_ptr_emplaceIN5kaldi17OnlineSubsampleFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar11OnlineCmnFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar12OnlineCmvnFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar13OnlineDeltaFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar13OnlineFbankFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar22OnlineFbankWithPitchFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar11OnlineLdaFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar12OnlineMfccFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar19OnlineNnetForwardFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar23OnlineNnetForwardSkipFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar14OnlineSpliceFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar17OnlineSubsampleFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar23OnlineStaticTransformFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar25OnlineComputeAheadInputFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar31OnlineFbankWithAudioAnalyticsFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar14OnlineAppendFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi14OnlineCmnInputENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi15OnlineCmvnInputENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi16OnlineDeltaInputENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi5FbankENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi13OnlineFeInputINS1_5FbankEEENS_9allocatorIS4_EEEE
N5kaldi13OnlineFeInputINS_5FbankEEE
NSt3__120__shared_ptr_emplaceIN5kaldi14FbankWithPitchENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi13OnlineFeInputINS1_14FbankWithPitchEEENS_9allocatorIS4_EEEE
N5kaldi13OnlineFeInputINS_14FbankWithPitchEEE
NSt3__120__shared_ptr_emplaceIN5kaldi23FbankWithAudioAnalyticsENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi13OnlineFeInputINS1_23FbankWithAudioAnalyticsEEENS_9allocatorIS4_EEEE
N5kaldi13OnlineFeInputINS_23FbankWithAudioAnalyticsEEE
NSt3__120__shared_ptr_emplaceIN5kaldi14OnlineLdaInputENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi4MfccENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi13OnlineFeInputINS1_4MfccEEENS_9allocatorIS4_EEEE
N5kaldi13OnlineFeInputINS_4MfccEEE
NSt3__120__shared_ptr_emplaceIN5kaldi22OnlineNnetForwardInputENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi29OnlineNnetForwardSkippedInputENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi17OnlineSpliceInputENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi20OnlineTransformInputENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi16OnlineCacheInputENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar21ComputeAheadFeatInputENS_9allocatorIS2_EEEE
N5kaldi6quasar11ErrorRegionE
!N6quasar14NgramFstConfigE
N6quasar21NgramSrilmCountConfigE
N6quasar29NgramSrilmInterpolationConfigE
N6quasar26NgramSrilmAdaptationConfigE
N6quasar13NgramLmModel2E
vector
const
ngram
ngram_quantized
reduced_transducer
reduced_acceptor
reduced_quantized_transducer
reduced_quantized_acceptor
squeezed_transducer
squeezed_acceptor
squeezed_quantized_transducer
squeezed_quantized_acceptor
N6quasar2lm26WeightOptimizationStrategyE
NSt3__110__function6__funcIZN6quasar26_populateNgramCountContextERNS_10unique_ptrIN5srilm17NgramCountContextENS_14default_deleteIS5_EEEERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEESH_RNS2_6LmDataEbE3$_0NSD_ISK_EEFPNS2_2lm19TokenStringAndCountExEEE
NSt3__110__function6__baseIFPN6quasar2lm19TokenStringAndCountExEEE
ZN6quasar26_populateNgramCountContextERNSt3__110unique_ptrIN5srilm17NgramCountContextENS0_14default_deleteIS3_EEEERKNS0_12basic_stringIcNS0_11char_traitsIcEENS0_9allocatorIcEEEESF_RNS_6LmDataEbE3$_0
NSt3__110__function6__funcIZN6quasar26_populateNgramCountContextERNS_10unique_ptrIN5srilm17NgramCountContextENS_14default_deleteIS5_EEEERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEESH_RNS2_6LmDataEbE3$_1NSD_ISK_EEFbxEEE
NSt3__110__function6__baseIFbxEEE
ZN6quasar26_populateNgramCountContextERNSt3__110unique_ptrIN5srilm17NgramCountContextENS0_14default_deleteIS3_EEEERKNS0_12basic_stringIcNS0_11char_traitsIcEENS0_9allocatorIcEEEESF_RNS_6LmDataEbE3$_1
NSt3__110__function6__funcIZN6quasar26_populateNgramCountContextERNS_10unique_ptrIN5srilm17NgramCountContextENS_14default_deleteIS5_EEEERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEESH_RNS2_6LmDataEbE3$_2NSD_ISK_EEFvvEEE
NSt3__110__function6__baseIFvvEEE
ZN6quasar26_populateNgramCountContextERNSt3__110unique_ptrIN5srilm17NgramCountContextENS0_14default_deleteIS3_EEEERKNS0_12basic_stringIcNS0_11char_traitsIcEENS0_9allocatorIcEEEESF_RNS_6LmDataEbE3$_2
N6quasar2lm9GeneratorINS0_19TokenStringAndCountEEE
NSt3__110__function6__funcIZN6quasar26_populateNgramCountContextERNS_10unique_ptrIN5srilm17NgramCountContextENS_14default_deleteIS5_EEEERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEESH_RNS2_6LmDataEbE3$_3NSD_ISK_EEFPNS2_2lm19TokenStringAndCountExEEE
ZN6quasar26_populateNgramCountContextERNSt3__110unique_ptrIN5srilm17NgramCountContextENS0_14default_deleteIS3_EEEERKNS0_12basic_stringIcNS0_11char_traitsIcEENS0_9allocatorIcEEEESF_RNS_6LmDataEbE3$_3
NSt3__110__function6__funcIZN6quasar26_populateNgramCountContextERNS_10unique_ptrIN5srilm17NgramCountContextENS_14default_deleteIS5_EEEERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEESH_RNS2_6LmDataEbE3$_4NSD_ISK_EEFbxEEE
ZN6quasar26_populateNgramCountContextERNSt3__110unique_ptrIN5srilm17NgramCountContextENS0_14default_deleteIS3_EEEERKNS0_12basic_stringIcNS0_11char_traitsIcEENS0_9allocatorIcEEEESF_RNS_6LmDataEbE3$_4
NSt3__110__function6__funcIZN6quasar26_populateNgramCountContextERNS_10unique_ptrIN5srilm17NgramCountContextENS_14default_deleteIS5_EEEERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEESH_RNS2_6LmDataEbE3$_5NSD_ISK_EEFvvEEE
ZN6quasar26_populateNgramCountContextERNSt3__110unique_ptrIN5srilm17NgramCountContextENS0_14default_deleteIS3_EEEERKNS0_12basic_stringIcNS0_11char_traitsIcEENS0_9allocatorIcEEEESF_RNS_6LmDataEbE3$_5
NSt3__120__shared_ptr_emplaceIN3fst8ConstFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEEjEENS_9allocatorIS7_EEEE
NSt3__120__shared_ptr_emplaceIN3fst8NGramFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb0EEENS_9allocatorIS7_EEEE
N3fst8NGramFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0EEE
N3fst17ImplToExpandedFstINS_12NGramFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0EEENS_11ExpandedFstIS5_EEEE
N3fst9ImplToFstINS_12NGramFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0EEENS_11ExpandedFstIS5_EEEE
N3fst12NGramFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0EEE
N3fst12NGramFstDataINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0EEE
N3fst11ArcIteratorINS_8NGramFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0EEEEE
N3fst15NGramFstMatcherINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0EEE
NSt3__120__shared_ptr_emplaceIN3fst8NGramFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb1EEENS_9allocatorIS7_EEEE
N3fst8NGramFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1EEE
N3fst17ImplToExpandedFstINS_12NGramFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1EEENS_11ExpandedFstIS5_EEEE
N3fst9ImplToFstINS_12NGramFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1EEENS_11ExpandedFstIS5_EEEE
N3fst12NGramFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1EEE
N3fst12NGramFstDataINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1EEE
N3fst11ArcIteratorINS_8NGramFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1EEEEE
N3fst15NGramFstMatcherINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1EEE
NSt3__120__shared_ptr_emplaceIN3fst10ReducedFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb0ELb0EEENS_9allocatorIS7_EEEE
N3fst10ReducedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb0EEE
N3fst17ImplToExpandedFstINS_14ReducedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb0EEENS_11ExpandedFstIS5_EEEE
N3fst9ImplToFstINS_14ReducedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb0EEENS_11ExpandedFstIS5_EEEE
N3fst14ReducedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb0EEE
N3fst13StateIteratorINS_10ReducedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb0EEEEE
NSt3__120__shared_ptr_emplaceIN3fst10ReducedFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb1ELb0EEENS_9allocatorIS7_EEEE
N3fst10ReducedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb0EEE
N3fst17ImplToExpandedFstINS_14ReducedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb0EEENS_11ExpandedFstIS5_EEEE
N3fst9ImplToFstINS_14ReducedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb0EEENS_11ExpandedFstIS5_EEEE
N3fst14ReducedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb0EEE
N3fst13StateIteratorINS_10ReducedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb0EEEEE
N3fst11ArcIteratorINS_10ReducedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb0EEEEE
NSt3__120__shared_ptr_emplaceIN3fst10ReducedFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb0ELb1EEENS_9allocatorIS7_EEEE
N3fst10ReducedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb1EEE
N3fst17ImplToExpandedFstINS_14ReducedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb1EEENS_11ExpandedFstIS5_EEEE
N3fst9ImplToFstINS_14ReducedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb1EEENS_11ExpandedFstIS5_EEEE
N3fst14ReducedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb1EEE
N3fst13StateIteratorINS_10ReducedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb1EEEEE
N3fst11ArcIteratorINS_10ReducedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb1EEEEE
NSt3__120__shared_ptr_emplaceIN3fst10ReducedFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb1ELb1EEENS_9allocatorIS7_EEEE
N3fst10ReducedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb1EEE
N3fst17ImplToExpandedFstINS_14ReducedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb1EEENS_11ExpandedFstIS5_EEEE
N3fst9ImplToFstINS_14ReducedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb1EEENS_11ExpandedFstIS5_EEEE
N3fst14ReducedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb1EEE
N3fst13StateIteratorINS_10ReducedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb1EEEEE
N3fst11ArcIteratorINS_10ReducedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb1EEEEE
NSt3__120__shared_ptr_emplaceIN3fst11SqueezedFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb0ELb0EEENS_9allocatorIS7_EEEE
N3fst11SqueezedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb0EEE
N3fst17ImplToExpandedFstINS_15SqueezedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb0EEENS_11ExpandedFstIS5_EEEE
N3fst9ImplToFstINS_15SqueezedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb0EEENS_11ExpandedFstIS5_EEEE
N3fst15SqueezedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb0EEE
NSt3__120__shared_ptr_emplaceIN3fst11SqueezedFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb1ELb0EEENS_9allocatorIS7_EEEE
N3fst11SqueezedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb0EEE
N3fst17ImplToExpandedFstINS_15SqueezedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb0EEENS_11ExpandedFstIS5_EEEE
N3fst9ImplToFstINS_15SqueezedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb0EEENS_11ExpandedFstIS5_EEEE
N3fst15SqueezedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb0EEE
N3fst11ArcIteratorINS_11SqueezedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb0EEEEE
NSt3__120__shared_ptr_emplaceIN3fst11SqueezedFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb0ELb1EEENS_9allocatorIS7_EEEE
N3fst11SqueezedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb1EEE
N3fst17ImplToExpandedFstINS_15SqueezedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb1EEENS_11ExpandedFstIS5_EEEE
N3fst9ImplToFstINS_15SqueezedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb1EEENS_11ExpandedFstIS5_EEEE
N3fst15SqueezedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb1EEE
N3fst11ArcIteratorINS_11SqueezedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb1EEEEE
NSt3__120__shared_ptr_emplaceIN3fst11SqueezedFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb1ELb1EEENS_9allocatorIS7_EEEE
N3fst11SqueezedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb1EEE
N3fst17ImplToExpandedFstINS_15SqueezedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb1EEENS_11ExpandedFstIS5_EEEE
N3fst9ImplToFstINS_15SqueezedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb1EEENS_11ExpandedFstIS5_EEEE
N3fst15SqueezedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb1EEE
N3fst11ArcIteratorINS_11SqueezedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb1EEEEE
NSt3__120__shared_ptr_emplaceIN6quasar13NgramLmModel2ENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_pointerIPN6quasar13NgramLmModel2ENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN6quasar13NgramLmModel2EEE
NSt3__120__shared_ptr_pointerIP5NgramNS_10shared_ptrIS1_E27__shared_ptr_default_deleteIS1_S1_EENS_9allocatorIS1_EEEE
NSt3__110shared_ptrI5NgramE27__shared_ptr_default_deleteIS1_S1_EE
NSt3__114default_deleteI5NgramEE
N6quasar2lm5srilm13VocabIteratorE
N6quasar2lm5srilm11InterpolateE
N6quasar2lm11InterpolateI5NgramS2_EE
NSt3__110__function6__funcIZN6quasar2lm29referenceVectorToObjectStreamINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEE5NgramEEPNS3_9GeneratorIT0_EERKNS_6vectorIT_NS8_ISH_EEEENS_8functionIFPSD_xEEEEUlxE_NS8_ISQ_EEFbxEEE
ZN6quasar2lm29referenceVectorToObjectStreamINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEE5NgramEEPNS0_9GeneratorIT0_EERKNS2_6vectorIT_NS6_ISF_EEEENS2_8functionIFPSB_xEEEEUlxE_
NSt3__110__function6__funcIZN6quasar2lm29referenceVectorToObjectStreamINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEE5NgramEEPNS3_9GeneratorIT0_EERKNS_6vectorIT_NS8_ISH_EEEENS_8functionIFPSD_xEEEEUlvE_NS8_ISQ_EEFvvEEE
ZN6quasar2lm29referenceVectorToObjectStreamINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEE5NgramEEPNS0_9GeneratorIT0_EERKNS2_6vectorIT_NS6_ISF_EEEENS2_8functionIFPSB_xEEEEUlvE_
N6quasar2lm9GeneratorI5NgramEE
N6quasar2lm6StreamIP5NgramEE
NSt3__110__function6__funcIZN6quasar2lm5srilm32CreateLazyLoadedNgramModelStreamERKNS_6vectorINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS9_ISB_EEEEP5VocabiE3$_0NS9_ISI_EEFP5NgramxEEE
NSt3__110__function6__baseIFP5NgramxEEE
ZN6quasar2lm5srilm32CreateLazyLoadedNgramModelStreamERKNSt3__16vectorINS2_12basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEENS7_IS9_EEEEP5VocabiE3$_0
QVG`7[
,92N6quasar10EndPointerE
N6quasar15BasicEndPointerE
N6quasar14NnetEndPointerE
NSt3__120__shared_ptr_emplaceIN6quasar9GeoRegionENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar17RegionsBitmapDataENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar9Geography10GeoContextENS_9allocatorIS3_EEEE
N6quasar16RecogAudioBufferE
N5boost16exception_detail10clone_implINS0_19error_info_injectorISt12length_errorEEEE
N5boost16exception_detail19error_info_injectorISt12length_errorEE
N6quasar20SpeechRecognizerBaseE
N6quasar18LmeDataFactoryBaseE
N5kaldi5nnet116NnetTrainOptionsE
N5kaldi5nnet114HistoryOptionsE
N5kaldi5nnet125RecurrentNnetTrainOptionsE
NSt3__120__shared_ptr_emplaceIN5kaldi5nnet117Nnet1InferenceNetENS_9allocatorIS3_EEEE
N5kaldi5nnet115AffineTransformE
NSt3__120__shared_ptr_emplaceIN6quasar18PersonalizedLmDataENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar29NgramSrilmInterpolationConfigENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar11LmEvaluatorENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar9LmLoader2ENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar9AppLmDataENS_9allocatorIS2_EEEE
)6vv
\biN3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEENSt3__19allocatorIS8_EEEEEENS_10MutableFstIS8_EEEE
N3fst11ExpandedFstINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEE
N3fst10MutableFstINS_6ArcTplINS_16LatticeWeightTplIfEEEEEE
N3fst31ComposeDeterministicOnDemandFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_24DeterministicOnDemandFstIS4_EES6_EE
N3fst7FstImplINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEE
N3fst9VectorFstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEENS_11VectorStateIS8_NSt3__19allocatorIS8_EEEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEENSt3__19allocatorISA_EEEEEENS_10MutableFstISA_EEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEENSt3__19allocatorIS9_EEEEEE
N3fst14DeterminizeFstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEE
N3fst9ImplToFstINS_22DeterminizeFstImplBaseINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEENS_3FstIS9_EEEE
N3fst18DeterminizeFsaImplINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEENS_20DefaultCommonDivisorIS6_EENS_24DefaultDeterminizeFilterIS8_EENS_28DefaultDeterminizeStateTableIS8_NS_18IntegerFilterStateIaEEEEEE
N3fst22DeterminizeFstImplBaseINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEE
N3fst9CacheImplINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEE
N3fst13CacheBaseImplINS_10CacheStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEENSt3__19allocatorIS9_EEEENS_17DefaultCacheStoreIS9_EEEE
N3fst13StateIteratorINS_14DeterminizeFstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEEEE
N3fst18CacheStateIteratorINS_14DeterminizeFstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEEEE
N3fst17StateIteratorBaseINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEE
N3fst35LeftContextDeterministicOnDemandFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
8BayesMix
18NgramProbArrayTrie
8SubVocab
?NSt3__120__shared_ptr_emplaceIN6quasar17PSRAudioProcessorENS_9allocatorIS2_EEEE
N5kaldi5nnet124GlobalAttentionComponentE
N5kaldi5nnet124GlobalRecurrentAttentionE
11NgramCountsIdE
N5kaldi27OnlineAudioAnalyticsFeatureE
!.OO
;HAN6quasar27PrefixSearchableSymbolTableE
N6quasar9SymbolMap25SortedSymbolMapQuasarImplE
N6quasar9SymbolMap19SymbolMapQuasarImplE
N6quasar9SymbolMap19SymbolMapMarisaImplE
NSt3__120__shared_ptr_pointerIPN3fst10MappedFileENS_10shared_ptrIS2_E27__shared_ptr_default_deleteIS2_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrIN3fst10MappedFileEE27__shared_ptr_default_deleteIS2_S2_EE
NSt3__114default_deleteIN3fst10MappedFileEEE
NSt3__120__shared_ptr_pointerIPN6quasar9SymbolMap25SortedSymbolMapQuasarImplENS_10shared_ptrIN3fst11SymbolTableEE27__shared_ptr_default_deleteIS7_S3_EENS_9allocatorIS3_EEEE
NSt3__110shared_ptrIN3fst11SymbolTableEE27__shared_ptr_default_deleteIS2_N6quasar9SymbolMap25SortedSymbolMapQuasarImplEEE
NSt3__114default_deleteIN6quasar9SymbolMap25SortedSymbolMapQuasarImplEEE
NSt3__120__shared_ptr_pointerIPN6quasar9SymbolMap19SymbolMapQuasarImplENS_10shared_ptrIN3fst11SymbolTableEE27__shared_ptr_default_deleteIS7_S3_EENS_9allocatorIS3_EEEE
NSt3__110shared_ptrIN3fst11SymbolTableEE27__shared_ptr_default_deleteIS2_N6quasar9SymbolMap19SymbolMapQuasarImplEEE
NSt3__114default_deleteIN6quasar9SymbolMap19SymbolMapQuasarImplEEE
NSt3__120__shared_ptr_pointerIPN6quasar9SymbolMap19SymbolMapMarisaImplENS_10shared_ptrIN3fst11SymbolTableEE27__shared_ptr_default_deleteIS7_S3_EENS_9allocatorIS3_EEEE
NSt3__110shared_ptrIN3fst11SymbolTableEE27__shared_ptr_default_deleteIS2_N6quasar9SymbolMap19SymbolMapMarisaImplEEE
NSt3__114default_deleteIN6quasar9SymbolMap19SymbolMapMarisaImplEEE
IPX`N6quasar18SelectBlockOptionsE
N6quasar25ConfiguredProcessingBlockINS_18SelectBlockOptionsEEE
N6quasar11SelectBlockE
N6quasar31ContinuousListeningResultHelperE
NSt3__120__shared_ptr_emplaceIN6quasar25ContinuousListeningConfigENS_9allocatorIS2_EEEE
N3fst15ArcIteratorBaseINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEE
N3fst13VectorFstImplINS_11VectorStateINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEENSt3__19allocatorIS7_EEEEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEENSt3__19allocatorIS7_EEEEEE
N6quasar9MungeRuleE
N6quasar15MergedMungeRuleE
N6quasar14BasicMungeRuleE
5Vocab
N6quasar2lm8arpa2fst10kaldi_impl12ConvertToFSTE
NSt3__110shared_ptrINS_13unordered_mapIjiNS_4hashIjEENS_8equal_toIjEENS_9allocatorINS_4pairIKjiEEEEEEE27__shared_ptr_default_deleteISB_SB_EE
N5kaldi5nnet116LossEvaluatorItfE
N5kaldi5nnet14XentE
N5kaldi5nnet13MseE
N5kaldi11CuSubVectorIfEE
N6quasar37OnlineLASSpeculativeBeamSearchDecoderE
N6quasar16SharedPhraseBookE
NSt3__120__shared_ptr_pointerIPN6quasar16SharedPhraseBookENS_10shared_ptrIS2_E27__shared_ptr_default_deleteIS2_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrIN6quasar16SharedPhraseBookEE27__shared_ptr_default_deleteIS2_S2_EE
NSt3__114default_deleteIN6quasar16SharedPhraseBookEEE
!N6quasar13LmBuildConfigE
N6quasar8LmModel2E
dummy
ngram
ngram-adaptation
nnlm
NSt3__120__shared_ptr_pointerIPN6quasar21NgramSrilmCountConfigENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN6quasar21NgramSrilmCountConfigEEE
NSt3__120__shared_ptr_pointerIPN6quasar11DummyConfigENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN6quasar11DummyConfigEEE
NSt3__120__shared_ptr_pointerIPN6quasar26NgramSrilmAdaptationConfigENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN6quasar26NgramSrilmAdaptationConfigEEE
NSt3__120__shared_ptr_pointerIPN6quasar10NNLmConfigENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN6quasar10NNLmConfigEEE
NSt3__110__function6__funcIZN6quasar8LmModel25writeERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEE3$_0NS7_ISC_EEFvSB_EEE
NSt3__110__function6__baseIFvRKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEEEE
ZN6quasar8LmModel25writeERKNSt3__112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEEE3$_0
NSt3__110__function6__funcIZN6quasar19loadLmFromDirectoryERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEESA_RS8_RNS_8optionalINS_10shared_ptrINS2_8LmModel2EEEEEE3$_1NS6_ISI_EEFvSA_EEE
ZN6quasar19loadLmFromDirectoryERKNSt3__112basic_stringIcNS0_11char_traitsIcEENS0_9allocatorIcEEEES8_RS6_RNS0_8optionalINS0_10shared_ptrINS_8LmModel2EEEEEE3$_1
NSt3__110__function6__funcIZN6quasar8removeLmERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEE3$_2NS6_ISB_EEFvSA_EEE
ZN6quasar8removeLmERKNSt3__112basic_stringIcNS0_11char_traitsIcEENS0_9allocatorIcEEEEE3$_2
N6quasar18WatermarkDetector2E
NSt3__120__shared_ptr_emplaceIN5kaldi10SnrTrackerENS_9allocatorIS2_EEEE
N6quasar2lm8arpa2fst7inhouse16mutable_fst_impl12ConvertToFSTE
N6quasar2lm8arpa2fst7inhouse12ConvertToFSTE
N6quasar2lm8arpa2fst12ConvertToFSTE
N6quasar2lm7ConvertI5NgramN3fst11ExpandedFstINS3_6ArcTplINS3_17TropicalWeightTplIfEEEEEEEE
N6quasar2lm8arpa2fst7inhouse16fst_builder_impl12ConvertToFSTE
NSt3__120__shared_ptr_pointerIPNS_13unordered_mapIjiNS_4hashIjEENS_8equal_toIjEENS_9allocatorINS_4pairIKjiEEEEEENS_10shared_ptrISB_E27__shared_ptr_default_deleteISB_SB_EENS6_ISB_EEEE
NSt3__114default_deleteINS_13unordered_mapIjiNS_4hashIjEENS_8equal_toIjEENS_9allocatorINS_4pairIKjiEEEEEEEE
NSt3__110__function6__funcIZNK6quasar2lm8arpa2fst7inhouse16mutable_fst_impl12ConvertToFSTclERK5NgramE3$_0NS_9allocatorISB_EEFmPK6BOnodeEEE
NSt3__110__function6__baseIFmPK6BOnodeEEE
ZNK6quasar2lm8arpa2fst7inhouse16mutable_fst_impl12ConvertToFSTclERK5NgramE3$_0
NSt3__110__function6__funcIZNK6quasar2lm8arpa2fst7inhouse16mutable_fst_impl12ConvertToFSTclERK5NgramE3$_1NS_9allocatorISB_EEFviRKN3fst17TropicalWeightTplIfEEEEE
NSt3__110__function6__baseIFviRKN3fst17TropicalWeightTplIfEEEEE
ZNK6quasar2lm8arpa2fst7inhouse16mutable_fst_impl12ConvertToFSTclERK5NgramE3$_1
NSt3__110__function6__funcIZNK6quasar2lm8arpa2fst7inhouse16mutable_fst_impl12ConvertToFSTclERK5NgramE3$_2NS_9allocatorISB_EEFviEEE
NSt3__110__function6__baseIFviEEE
ZNK6quasar2lm8arpa2fst7inhouse16mutable_fst_impl12ConvertToFSTclERK5NgramE3$_2
NSt3__110__function6__funcIZNK6quasar2lm8arpa2fst7inhouse16mutable_fst_impl12ConvertToFSTclERK5NgramE3$_3NS_9allocatorISB_EEFviRKN3fst6ArcTplINSE_17TropicalWeightTplIfEEEEEEE
NSt3__110__function6__baseIFviRKN3fst6ArcTplINS2_17TropicalWeightTplIfEEEEEEE
ZNK6quasar2lm8arpa2fst7inhouse16mutable_fst_impl12ConvertToFSTclERK5NgramE3$_3
NSt3__110__function6__funcIZNK6quasar2lm8arpa2fst7inhouse16mutable_fst_impl12ConvertToFSTclERK5NgramE3$_4NS_9allocatorISB_EEFviEEE
ZNK6quasar2lm8arpa2fst7inhouse16mutable_fst_impl12ConvertToFSTclERK5NgramE3$_4
NSt3__110__function6__funcIZNK6quasar2lm8arpa2fst7inhouse16mutable_fst_impl12ConvertToFSTclERK5NgramE3$_5NS_9allocatorISB_EEFviEEE
ZNK6quasar2lm8arpa2fst7inhouse16mutable_fst_impl12ConvertToFSTclERK5NgramE3$_5
NSt3__110__function6__funcIZNK6quasar2lm8arpa2fst7inhouse16mutable_fst_impl12ConvertToFSTclERK5NgramE3$_6NS_9allocatorISB_EEFviRKN3fst6ArcTplINSE_17TropicalWeightTplIfEEEEEEE
ZNK6quasar2lm8arpa2fst7inhouse16mutable_fst_impl12ConvertToFSTclERK5NgramE3$_6
NSt3__110__function6__funcIZNK6quasar2lm8arpa2fst7inhouse16mutable_fst_impl12ConvertToFSTclERK5NgramE3$_7NS_9allocatorISB_EEFviEEE
ZNK6quasar2lm8arpa2fst7inhouse16mutable_fst_impl12ConvertToFSTclERK5NgramE3$_7
NSt3__110__function6__funcIZNK6quasar2lm8arpa2fst7inhouse16mutable_fst_impl12ConvertToFSTclERK5NgramE3$_8NS_9allocatorISB_EEFvPK4TrieIj6BOnodeEjRKNS_6vectorIjNSC_IjEEEESI_EEE
ZNK6quasar2lm8arpa2fst7inhouse16mutable_fst_impl12ConvertToFSTclERK5NgramE3$_8
NSt3__110__function6__funcIZNK6quasar2lm8arpa2fst7inhouse16fst_builder_impl12ConvertToFSTclERK5NgramE4$_11NS_9allocatorISB_EEFvPK4TrieIj6BOnodeEjRKNS_6vectorIjNSC_IjEEEESI_EEE
ZNK6quasar2lm8arpa2fst7inhouse16fst_builder_impl12ConvertToFSTclERK5NgramE4$_11
NSt3__110__function6__funcIZNK6quasar2lm8arpa2fst7inhouse16fst_builder_impl12ConvertToFSTclERK5NgramE3$_9NS_9allocatorISB_EEFmPK6BOnodeEEE
ZNK6quasar2lm8arpa2fst7inhouse16fst_builder_impl12ConvertToFSTclERK5NgramE3$_9
NSt3__110__function6__funcIZNK6quasar2lm8arpa2fst7inhouse16fst_builder_impl12ConvertToFSTclERK5NgramE4$_12NS_9allocatorISB_EEFviEEE
ZNK6quasar2lm8arpa2fst7inhouse16fst_builder_impl12ConvertToFSTclERK5NgramE4$_12
NSt3__110__function6__funcIZNK6quasar2lm8arpa2fst7inhouse16fst_builder_impl12ConvertToFSTclERK5NgramE4$_13NS_9allocatorISB_EEFvPK4TrieIj6BOnodeEjRKNS_6vectorIjNSC_IjEEEESI_EEE
NSt3__110__function6__funcIZZNK6quasar2lm8arpa2fst7inhouse16fst_builder_impl12ConvertToFSTclERK5NgramENK4$_13clEPK4TrieIj6BOnodeEjRKNS_6vectorIjNS_9allocatorIjEEEESG_EUliE_NSI_ISN_EEFviEEE
ZZNK6quasar2lm8arpa2fst7inhouse16fst_builder_impl12ConvertToFSTclERK5NgramENK4$_13clEPK4TrieIj6BOnodeEjRKNSt3__16vectorIjNSE_9allocatorIjEEEESD_EUliE_
NSt3__110__function6__funcIZZNK6quasar2lm8arpa2fst7inhouse16fst_builder_impl12ConvertToFSTclERK5NgramENK4$_13clEPK4TrieIj6BOnodeEjRKNS_6vectorIjNS_9allocatorIjEEEESG_EUliRKN3fst17TropicalWeightTplIfEEE_NSI_ISS_EEFviSR_EEE
ZZNK6quasar2lm8arpa2fst7inhouse16fst_builder_impl12ConvertToFSTclERK5NgramENK4$_13clEPK4TrieIj6BOnodeEjRKNSt3__16vectorIjNSE_9allocatorIjEEEESD_EUliRKN3fst17TropicalWeightTplIfEEE_
NSt3__110__function6__funcIZZNK6quasar2lm8arpa2fst7inhouse16fst_builder_impl12ConvertToFSTclERK5NgramENK4$_13clEPK4TrieIj6BOnodeEjRKNS_6vectorIjNS_9allocatorIjEEEESG_EUliRKN3fst6ArcTplINSN_17TropicalWeightTplIfEEEEE_NSI_ISU_EEFviST_EEE
ZZNK6quasar2lm8arpa2fst7inhouse16fst_builder_impl12ConvertToFSTclERK5NgramENK4$_13clEPK4TrieIj6BOnodeEjRKNSt3__16vectorIjNSE_9allocatorIjEEEESD_EUliRKN3fst6ArcTplINSL_17TropicalWeightTplIfEEEEE_
ZNK6quasar2lm8arpa2fst7inhouse16fst_builder_impl12ConvertToFSTclERK5NgramE4$_13
N6quasar8artifact13AppLmArtifactE
N5boost16exception_detail10clone_implINS0_19error_info_injectorINS_13property_tree14ptree_bad_pathEEEEE
N5boost16exception_detail19error_info_injectorINS_13property_tree14ptree_bad_pathEEE
N5boost13property_tree14ptree_bad_pathE
N5boost3any6holderINS_13property_tree11string_pathINSt3__112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEENS2_13id_translatorISA_EEEEEE
N5boost3any11placeholderE
N5boost13property_tree11string_pathINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEENS0_13id_translatorIS8_EEEE
NSt3__120__shared_ptr_pointerIPN3fst3FstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEEEENS_14default_deleteIS7_EENS_9allocatorIS7_EEEE
NSt3__114default_deleteIN3fst3FstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEEEEEE
10WittenBell
N5kaldi5nnet118ScaledDotAttentionE
N5kaldi5nnet118MultiHeadAttentionE
N5kaldi5nnet128SupervisedMultiHeadAttentionE
N5kaldi5nnet113SelfAttentionE
N5kaldi5nnet116AverageAttentionE
21ResidualAdaptiveNgram
IOVolabel_lookahead
NSt3__120__shared_ptr_emplaceIN6quasar14GlobalLRUCacheINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_6vectorIS8_NS6_IS8_EEEEEENS6_ISC_EEEE
N6quasar14GlobalLRUCacheINSt3__112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEENS1_6vectorIS7_NS5_IS7_EEEEEE
N3fst9ImplToFstINS_9AddOnImplINS_8ConstFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEjEENS_9AddOnPairINS_18LabelReachableDataIiEESA_EEEENS_11ExpandedFstIS6_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar11ModelLoaderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_pointerIPN3fst9VectorFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEENS1_11VectorStateIS6_NS_9allocatorIS6_EEEEEENS_10shared_ptrINS1_3FstIS6_EEE27__shared_ptr_default_deleteISF_SB_EENS8_ISB_EEEE
NSt3__111__end_stateIcEE
NSt3__120__shared_ptr_pointerIPNS_13__empty_stateIcEENS_10shared_ptrIS2_E27__shared_ptr_default_deleteIS2_S2_EENS_9allocatorIS2_EEEE
NSt3__113__empty_stateIcEE
NSt3__120__l_anchor_multilineIcEE
NSt3__120__r_anchor_multilineIcEE
NSt3__115__word_boundaryIcNS_12regex_traitsIcEEEE
NSt3__111__lookaheadIcNS_12regex_traitsIcEEEE
NSt3__123__match_any_but_newlineIcEE
NSt3__120__match_char_collateIcNS_12regex_traitsIcEEEE
NSt3__118__back_ref_collateIcNS_12regex_traitsIcEEEE
NSt3__128__begin_marked_subexpressionIcEE
NSt3__126__end_marked_subexpressionIcEE
NSt3__16__loopIcEE
NSt3__117__repeat_one_loopIcEE
NSt3__121__empty_non_own_stateIcEE
N3fst3FstINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEE
N3fst7FstImplINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEE
N3fst14DeterminizeFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N3fst9ImplToFstINS_22DeterminizeFstImplBaseINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_3FstIS5_EEEE
N3fst13StateIteratorINS_14DeterminizeFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE3EEENS_14ToGallicMapperIS5_LS7_3EEEEENS_3FstIS8_EEEE
N3fst13ArcMapFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE3EEENS_14ToGallicMapperIS4_LS6_3EEEEE
N3fst9CacheImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEEEE
N3fst7FstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEEEE
N3fst9ImplToFstINS_22DeterminizeFstImplBaseINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEEEENS_3FstIS8_EEEE
N3fst18DeterminizeFsaImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEENS_19GallicCommonDivisorIiS4_LS6_3ENS_20DefaultCommonDivisorIS4_EEEENS_24DefaultDeterminizeFilterIS7_EENS_28DefaultDeterminizeStateTableIS7_NS_18IntegerFilterStateIaEEEEEE
N3fst22DeterminizeFstImplBaseINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEES6_NS_16FromGallicMapperIS6_LS7_3EEEEENS_3FstIS6_EEEE
N3fst13StateIteratorINS_9ArcMapFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE2EEENS_14ToGallicMapperIS5_LS7_2EEEEEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEES6_NS_16FromGallicMapperIS6_LS7_2EEEEENS_3FstIS6_EEEE
N3fst13StateIteratorINS_9ArcMapFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE4EEENS_14ToGallicMapperIS5_LS7_4EEEEEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEES6_NS_16FromGallicMapperIS6_LS7_4EEEEENS_3FstIS6_EEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEENSt3__19allocatorIS9_EEEEEENS_10MutableFstIS9_EEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEENSt3__19allocatorIS9_EEEEEENS_10MutableFstIS9_EEEE
N3fst11ExpandedFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N3fst3FstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N3fst10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEEE4LinkEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEENS_11VectorStateIS8_NSt3__19allocatorIS8_EEEEEEEE
N3fst22MutableArcIteratorBaseINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEENSt3__19allocatorISB_EEEEEENS_10MutableFstISB_EEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEENSt3__19allocatorISB_EEEEEENS_10MutableFstISB_EEEE
N3fst11ExpandedFstINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEEEE
N3fst3FstINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEEEE
N3fst10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEEEEE4LinkEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEENS_11VectorStateISA_NSt3__19allocatorISA_EEEEEEEE
N3fst22MutableArcIteratorBaseINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEEEE
N3fst19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEENS_12GallicFactorIiS4_LS6_0EEEEE
N3fst9CacheImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N3fst13StateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEENS_12GallicFactorIiS5_LS7_0EEEEEEE
N3fst10MatcherFstINS_8ConstFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEjEENS_21LabelLookAheadMatcherINS_13SortedMatcherIS6_EELj1760ENS_18FastLogAccumulatorIS5_EENS_14LabelReachableIS5_SB_NS_18LabelReachableDataIiEEEEEEXadL_ZN6quasar25olabel_lookahead_fst_typeEEENS_23LabelLookAheadRelabelerIS5_SE_EENS_9AddOnPairISE_SE_EEEE
N3fst17ImplToExpandedFstINS_9AddOnImplINS_8ConstFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEjEENS_9AddOnPairINS_18LabelReachableDataIiEESA_EEEENS_11ExpandedFstIS6_EEEE
N3fst12ConstFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEEjEE
N3fst21LabelLookAheadMatcherINS_13SortedMatcherINS_8ConstFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEjEEEELj1760ENS_18FastLogAccumulatorIS6_EENS_14LabelReachableIS6_SA_NS_18LabelReachableDataIiEEEEEE
N3fst20LookAheadMatcherBaseINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N3fst13SortedMatcherINS_8ConstFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEjEEEE
N3fst10MemoryPoolINS_11ArcIteratorINS_8ConstFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEjEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_11ArcIteratorINS_8ConstFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEjEEEEE4LinkEEE
N3fst9AddOnImplINS_8ConstFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEjEENS_9AddOnPairINS_18LabelReachableDataIiEES9_EEEE
N3fst10ComposeFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_17DefaultCacheStoreIS4_EEEE
N3fst9ImplToFstINS_18ComposeFstImplBaseINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_17DefaultCacheStoreIS5_EEEENS_3FstIS5_EEEE
N3fst18ComposeFstImplBaseINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_17DefaultCacheStoreIS4_EEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_23PushLabelsComposeFilterINS_24PushWeightsComposeFilterINS_22LookAheadComposeFilterINS_21SequenceComposeFilterINS_16LookAheadMatcherINS_3FstIS5_EEEESE_EESE_SE_LNS_9MatchTypeE2EEESE_SE_LSG_2EEESE_SE_LSG_2EEENS_24GenericComposeStateTableIS5_NS_15PairFilterStateINSL_INS_18IntegerFilterStateIaEENS_17WeightFilterStateIS4_EEEENSM_IiEEEENS_24DefaultComposeStateTupleIiSS_EENS_21CompactHashStateTableISU_NS_11ComposeHashISU_EEEEEEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_18MatchComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst9ImplToFstINS_14ReplaceFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_24DefaultReplaceStateTableIS5_lEENS_17DefaultCacheStoreIS5_EEEENS_3FstIS5_EEEE
N5sdapi12SdapiITNImplE
NSt3__120__shared_ptr_emplaceIN6quasar8artifact8ArtifactENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar8artifact13AppLmArtifactENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_pointerIPN6quasar9AppLmDataENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN6quasar9AppLmDataEEE
NSt3__120__shared_ptr_pointerIPN6quasar14CustomPronDataENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN6quasar14CustomPronDataEEE
NSt3__120__shared_ptr_pointerIPN6quasar8artifact13AppLmArtifactENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIN6quasar8artifact13AppLmArtifactEEE
NSt3__120__shared_ptr_pointerIPN5kaldi6quasar8LmHandleENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIN5kaldi6quasar8LmHandleEEE
N6quasar20SyncRecogAudioBufferE
N5kaldi5nnet118GatedRecurrentUnitE
N6quasar19DoNotTranslateBlockE
N6quasar20AppleFileCoordinatorE
N6quasar23AppleLanguageRecognizerE
N5kaldi27OnlineDecodableMatrixScaledE
N5kaldi30OnlineDecodableIdenticalMatrixE
N5kaldi33OnlineDecodableMatrixScaledMappedE
N5kaldi35OnlineDecodableMatrixScaledMappedTmE
N5kaldi24OnlineDecodableNnet1LazyE
NSt3__120__shared_ptr_emplaceIN6quasar21SyncPSRAudioProcessorENS_9allocatorIS2_EEEE
N6quasar22ResultStreamStabilizerE
N6quasar14LmeDataFactoryE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar7LexiconENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar6LmeFstENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar12ConstLexiconENS_9allocatorIS3_EEEE
NSt3__110__function6__funcINS_6__bindIRFbRKN6quasar18LmeDataFactoryBase4WordEiEJRKNS_12placeholders4__phILi1EEERiEEENS_9allocatorISG_EEFbS7_EEE
NSt3__110__function6__baseIFbRKN6quasar18LmeDataFactoryBase4WordEEEE
NSt3__16__bindIRFbRKN6quasar18LmeDataFactoryBase4WordEiEJRKNS_12placeholders4__phILi1EEERiEEE
NSt3__118__weak_result_typeIPFbRKN6quasar18LmeDataFactoryBase4WordEiEEE
NSt3__115binary_functionIRKN6quasar18LmeDataFactoryBase4WordEibEE
kxq&&
N6quasar11PDecOptionsE
N6quasar17TranslatorOptionsE
N6quasar25ConfiguredProcessingBlockINS_17TranslatorOptionsEEE
N6quasar19PDecTranslatorBlockE
N6quasar20PDecEngineBlockMixinE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar17TranslationEngineIJNS2_21TranslationBeamSearchINS2_19TorchEncoderDecoderEEENS4_INS2_6EncdecEEEEEENS_9allocatorIS9_EEEE
N5kaldi6quasar21TranslationBeamSearchINS0_19TorchEncoderDecoderEEE
N5kaldi6quasar21TranslationBeamSearchINS0_6EncdecEEE
NSt3__120__shared_ptr_pointerIPN5kaldi6quasar19TorchEncoderDecoderENS_10shared_ptrIS3_E27__shared_ptr_default_deleteIS3_S3_EENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_pointerIPN5kaldi6quasar6EncdecENS_10shared_ptrIS3_E27__shared_ptr_default_deleteIS3_S3_EENS_9allocatorIS3_EEEE
NSt3__110shared_ptrIN5kaldi6quasar6EncdecEE27__shared_ptr_default_deleteIS3_S3_EE
NSt3__114default_deleteIN5kaldi6quasar6EncdecEEE
NSt3__120__shared_ptr_emplaceINS_4pairINS_10shared_ptrIN5kaldi6quasar16ComputeEngineItfEEES6_EENS_9allocatorIS7_EEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS7_9allocatorIfEEEEEEEENS9_ISD_EEEEEENS_10MutableFstISD_EEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS7_9allocatorIfEEEEEEEENS9_ISD_EEEEEENS_10MutableFstISD_EEEE
N3fst11ExpandedFstINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS5_9allocatorIfEEEEEEEEEE
N3fst3FstINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS5_9allocatorIfEEEEEEEEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS6_9allocatorIfEEEEEEEENS8_ISC_EEEEEE
N3fst10MemoryPoolINS_8DfsStateINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS6_9allocatorIfEEEEEEEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS7_9allocatorIfEEEEEEEEEEE4LinkEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS6_9allocatorIfEEEEEEEENS_11VectorStateISC_NS8_ISC_EEEEEEEE
N3fst15ArcIteratorBaseINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS5_9allocatorIfEEEEEEEEEE
N3fst9QueueBaseIiEE
N3fst18ShortestFirstQueueIiNS_18StateWeightCompareIiNS_11NaturalLessINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS6_9allocatorIfEEEEEEEEEELb0EEE
N3fst9VectorFstINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS6_9allocatorIfEEEEEEEEEENS_11VectorStateISD_NS8_ISD_EEEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS8_9allocatorIfEEEEEEEEEENSA_ISF_EEEEEENS_10MutableFstISF_EEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS8_9allocatorIfEEEEEEEEEENSA_ISF_EEEEEENS_10MutableFstISF_EEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS8_9allocatorIfEEEEEEEEEENSA_ISF_EEEEEENS_10MutableFstISF_EEEE
N3fst10MutableFstINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS6_9allocatorIfEEEEEEEEEEEE
N3fst11ExpandedFstINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS6_9allocatorIfEEEEEEEEEEEE
N3fst3FstINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS6_9allocatorIfEEEEEEEEEEEE
N3fst13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS7_9allocatorIfEEEEEEEEEENS9_ISE_EEEEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS7_9allocatorIfEEEEEEEEEENS9_ISE_EEEEEE
N3fst7FstImplINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS6_9allocatorIfEEEEEEEEEEEE
N3fst10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS7_9allocatorIfEEEEEEEEEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS8_9allocatorIfEEEEEEEEEEEEE4LinkEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS7_9allocatorIfEEEEEEEEEENS_11VectorStateISE_NS9_ISE_EEEEEEEE
N3fst22MutableArcIteratorBaseINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS6_9allocatorIfEEEEEEEEEEEE
N3fst15ArcIteratorBaseINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS6_9allocatorIfEEEEEEEEEEEE
N3fst14DeterminizeFstINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS6_9allocatorIfEEEEEEEEEEEE
N3fst9ImplToFstINS_22DeterminizeFstImplBaseINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS7_9allocatorIfEEEEEEEEEEEENS_3FstISE_EEEE
N3fst18DeterminizeFsaImplINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS6_9allocatorIfEEEEEEEEEENS_20DefaultCommonDivisorISB_EENS_24DefaultDeterminizeFilterISD_EENS_28DefaultDeterminizeStateTableISD_NS_18IntegerFilterStateIaEEEEEE
N3fst22DeterminizeFstImplBaseINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS6_9allocatorIfEEEEEEEEEEEE
N3fst9CacheImplINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS6_9allocatorIfEEEEEEEEEEEE
N3fst13CacheBaseImplINS_10CacheStateINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS7_9allocatorIfEEEEEEEEEENS9_ISE_EEEENS_17DefaultCacheStoreISE_EEEE
N3fst13StateIteratorINS_14DeterminizeFstINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS7_9allocatorIfEEEEEEEEEEEEEE
N3fst18CacheStateIteratorINS_14DeterminizeFstINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS7_9allocatorIfEEEEEEEEEEEEEE
N3fst17StateIteratorBaseINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS6_9allocatorIfEEEEEEEEEEEE
NSt3__110__function6__funcIZN5kaldi6quasar31SystemSelectionFeatureExtractor15ExtractFeaturesERKNS_6vectorINS5_IfNS_9allocatorIfEEEENS6_IS8_EEEEPS8_E3$_1NS6_ISE_EEFfiEEE
NSt3__110__function6__baseIFfiEEE
ZN5kaldi6quasar31SystemSelectionFeatureExtractor15ExtractFeaturesERKNSt3__16vectorINS3_IfNS2_9allocatorIfEEEENS4_IS6_EEEEPS6_E3$_1
NSt3__110__function6__funcIZN5kaldi6quasar31SystemSelectionFeatureExtractor15ExtractFeaturesERKNS_6vectorINS5_IfNS_9allocatorIfEEEENS6_IS8_EEEEPS8_E3$_2NS6_ISE_EEFfiEEE
ZN5kaldi6quasar31SystemSelectionFeatureExtractor15ExtractFeaturesERKNSt3__16vectorINS3_IfNS2_9allocatorIfEEEENS4_IS6_EEEEPS6_E3$_2
NSt3__110__function6__funcIZN5kaldi6quasar31SystemSelectionFeatureExtractor15ExtractFeaturesERKNS_6vectorINS5_IfNS_9allocatorIfEEEENS6_IS8_EEEEPS8_E3$_3NS6_ISE_EEFfiEEE
ZN5kaldi6quasar31SystemSelectionFeatureExtractor15ExtractFeaturesERKNSt3__16vectorINS3_IfNS2_9allocatorIfEEEENS4_IS6_EEEEPS6_E3$_3
NSt3__110__function6__funcIZN5kaldi6quasar31SystemSelectionFeatureExtractor15ExtractFeaturesERKNS_6vectorINS5_IfNS_9allocatorIfEEEENS6_IS8_EEEEPS8_E3$_4NS6_ISE_EEFfiEEE
ZN5kaldi6quasar31SystemSelectionFeatureExtractor15ExtractFeaturesERKNSt3__16vectorINS3_IfNS2_9allocatorIfEEEENS4_IS6_EEEEPS6_E3$_4
NSt3__110__function6__funcIZN5kaldi6quasar31SystemSelectionFeatureExtractor15ExtractFeaturesERKNS_6vectorINS5_IfNS_9allocatorIfEEEENS6_IS8_EEEEPS8_E3$_5NS6_ISE_EEFfiEEE
ZN5kaldi6quasar31SystemSelectionFeatureExtractor15ExtractFeaturesERKNSt3__16vectorINS3_IfNS2_9allocatorIfEEEENS4_IS6_EEEEPS6_E3$_5
NSt3__110__function6__funcIZN5kaldi6quasar31SystemSelectionFeatureExtractor15ExtractFeaturesERKNS_6vectorINS5_IfNS_9allocatorIfEEEENS6_IS8_EEEEPS8_E3$_6NS6_ISE_EEFfiEEE
ZN5kaldi6quasar31SystemSelectionFeatureExtractor15ExtractFeaturesERKNSt3__16vectorINS3_IfNS2_9allocatorIfEEEENS4_IS6_EEEEPS6_E3$_6
NSt3__110__function6__funcIZN5kaldi6quasar31SystemSelectionFeatureExtractor15ExtractFeaturesERKNS_6vectorINS5_IfNS_9allocatorIfEEEENS6_IS8_EEEEPS8_E3$_7NS6_ISE_EEFfiEEE
ZN5kaldi6quasar31SystemSelectionFeatureExtractor15ExtractFeaturesERKNSt3__16vectorINS3_IfNS2_9allocatorIfEEEENS4_IS6_EEEEPS6_E3$_7
NSt3__110__function6__funcIZN5kaldi6quasar31SystemSelectionFeatureExtractor15ExtractFeaturesERKNS_6vectorINS5_IfNS_9allocatorIfEEEENS6_IS8_EEEEPS8_E3$_8NS6_ISE_EEFfiEEE
ZN5kaldi6quasar31SystemSelectionFeatureExtractor15ExtractFeaturesERKNSt3__16vectorINS3_IfNS2_9allocatorIfEEEENS4_IS6_EEEEPS6_E3$_8
N6quasar18BasicTextSanitizerE
N6quasar13TextSanitizerE
7MEModel
11NgramCountsImE
N6quasar11SyncDecoderE
NSt3__120__shared_ptr_emplaceIN6quasar26KeywordSpottingSyncDecoderENS_9allocatorIS2_EEEE
N6quasar14PDecTranslatorE
8VarNgram
N6quasar33OnlineTransducerBeamSearchDecoderE
N5kaldi8EventMapE
N5kaldi16ConstantEventMapE
N5kaldi13TableEventMapE
N5kaldi13SplitEventMapE
NSt3__120__shared_ptr_emplaceIN13sentencepiece22SentencePieceProcessorENS_9allocatorIS2_EEEE
!-[[
!-[[
16SimpleClassNgram
N6quasar23GlobalTranslatorFactoryE
NSt3__120__shared_ptr_emplaceIN6quasar27GlobalPDecTranslatorFactoryENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar29GlobalHotfixTranslatorFactoryENS_9allocatorIS2_EEEE
N6quasar2lm8arpa2fst10kaldi_fork14ArpaLmCompilerE
N6quasar2lm8arpa2fst10kaldi_fork18ArpaLmCompilerImplINS2_12_GLOBAL__N_116OptimizedHistKeyEEE
N6quasar2lm8arpa2fst10kaldi_fork27ArpaLmCompilerImplInterfaceE
N6quasar2lm8arpa2fst10kaldi_fork18ArpaLmCompilerImplINS2_12_GLOBAL__N_114GeneralHistKeyEEE
N6quasar20SimpleNameEnumeratorE
N6quasar8artifact8ArtifactE
N6quasar8artifact13ArchiveReaderE
N6quasar8artifact13ArchiveWriterE
NSt3__110__function6__funcIZN6quasar8artifact8Artifact21openContentForWritingERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEbE3$_0NS8_ISD_EEFbSC_EEE
NSt3__110__function6__baseIFbRKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEEEE
ZN6quasar8artifact8Artifact21openContentForWritingERKNSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEbE3$_0
N6quasar8artifact20ArtifactOutputStreamE
NSt3__120__shared_ptr_emplaceIN6quasar8artifact13ArchiveReaderENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar8artifact25ArtifactInputStreamBufferENS_9allocatorIS3_EEEE
N6quasar8artifact25ArtifactInputStreamBufferE
N6quasar8artifact19ArtifactInputStreamE
NSt3__120__shared_ptr_emplaceIN6quasar8artifact19ArtifactInputStreamENS_9allocatorIS3_EEEE
N3fst11FstRegisterINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N3fst15GenericRegisterINSt3__112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEENS_16FstRegisterEntryINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_11FstRegisterISC_EEEE
NSt3__110__function6__funcIZ420-[_EARFormatter formatWords:unrepairedWordsOut:task:language:preItnLeftContext:separateAutoEndPunctuation:partialResults:timestampOffset:zeroTimestamp:continuousListeningConfig:postItnLeftContext:itnResult:itnOverrides:itnEnablingFlags:recognizeEmoji:leftContextProvidedByClient:preItnRightContext:emojiTokenIndices:persistEmoji:shouldHideTrailingPunctuation:isTrailingPunctuationHidden:isFinal:choiceIdx:itnCompletion:]E3$_0NS_9allocatorIS2_EEFNS_6vectorIN6quasar5TokenENS3_IS7_EEEERKS9_EEE
NSt3__110__function6__baseIFNS_6vectorIN6quasar5TokenENS_9allocatorIS4_EEEERKS7_EEE
Z420-[_EARFormatter formatWords:unrepairedWordsOut:task:language:preItnLeftContext:separateAutoEndPunctuation:partialResults:timestampOffset:zeroTimestamp:continuousListeningConfig:postItnLeftContext:itnResult:itnOverrides:itnEnablingFlags:recognizeEmoji:leftContextProvidedByClient:preItnRightContext:emojiTokenIndices:persistEmoji:shouldHideTrailingPunctuation:isTrailingPunctuationHidden:isFinal:choiceIdx:itnCompletion:]E3$_0
N6quasar21AudioAnalyticsDecoderE
;HABB
N3fst13SortedMatcherINS_3FstINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEE
N3fst11MatcherBaseINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEE
N3fst10MemoryPoolINS_11ArcIteratorINS_3FstINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_11ArcIteratorINS_3FstINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEEE4LinkEEE
N3fst10ComposeFstINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEENS_17DefaultCacheStoreISA_EEEE
N3fst9ImplToFstINS_18ComposeFstImplBaseINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEENS_17DefaultCacheStoreISB_EEEENS_3FstISB_EEEE
N3fst3FstINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEENS_21SequenceComposeFilterINS_13SortedMatcherINS_3FstISB_EEEESH_EENS_24GenericComposeStateTableISB_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSL_EENS_21CompactHashStateTableISN_NS_11ComposeHashISN_EEEEEEEE
N3fst18ComposeFstImplBaseINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEENS_17DefaultCacheStoreISA_EEEE
N3fst13CacheBaseImplINS_10CacheStateINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEENSt3__19allocatorISB_EEEENS_17DefaultCacheStoreISB_EEEE
N3fst7FstImplINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEENS_21SequenceComposeFilterINS_13SortedMatcherINS_3FstISB_EEEESH_EENS_24GenericComposeStateTableISB_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSL_EENS_21CompactHashStateTableISN_NS_11ComposeHashISN_EEEEEEEE
N3fst10MemoryPoolINS_8DfsStateINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEE4LinkEEE
N3fst13StateIteratorINS_10ComposeFstINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEENS_17DefaultCacheStoreISB_EEEEEE
N3fst18CacheStateIteratorINS_10ComposeFstINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEENS_17DefaultCacheStoreISB_EEEEEE
N3fst17StateIteratorBaseINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEENSt3__19allocatorISC_EEEEEENS_10MutableFstISC_EEEE
N3fst10MutableFstINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEE
N3fst11ExpandedFstINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEE
N3fst10MutableFstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEE
N3fst13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEENSt3__19allocatorIS9_EEEEEE
N3fst7FstImplINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEE
N3fst15ArcIteratorBaseINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEE
N3fst9VectorFstINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEENS_11VectorStateISA_NSt3__19allocatorISA_EEEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEENSt3__19allocatorISC_EEEEEENS_10MutableFstISC_EEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEENSt3__19allocatorISC_EEEEEENS_10MutableFstISC_EEEE
N3fst13VectorFstImplINS_11VectorStateINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEENSt3__19allocatorISB_EEEEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEENSt3__19allocatorISB_EEEEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEENS_11VectorStateISB_NSt3__19allocatorISB_EEEEEEEE
N3fst22MutableArcIteratorBaseINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEE
N3fst15ArcIteratorBaseINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEE
N3fst18ShortestFirstQueueIiNS_18StateWeightCompareIiNS_11NaturalLessINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEELb0EEE
N3fst9VectorFstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEENS_11VectorStateISC_NSt3__19allocatorISC_EEEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEENSt3__19allocatorISE_EEEEEENS_10MutableFstISE_EEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEENSt3__19allocatorISE_EEEEEENS_10MutableFstISE_EEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEENSt3__19allocatorISE_EEEEEENS_10MutableFstISE_EEEE
N3fst10MutableFstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEE
N3fst11ExpandedFstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEE
N3fst3FstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEE
N3fst13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEENSt3__19allocatorISD_EEEEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEENSt3__19allocatorISD_EEEEEE
N3fst7FstImplINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEE
N3fst10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEEE4LinkEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEENS_11VectorStateISD_NSt3__19allocatorISD_EEEEEEEE
N3fst22MutableArcIteratorBaseINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEE
N3fst15ArcIteratorBaseINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEE
N3fst14DeterminizeFstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEE
N3fst9ImplToFstINS_22DeterminizeFstImplBaseINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEENS_3FstISD_EEEE
N3fst18DeterminizeFsaImplINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEENS_20DefaultCommonDivisorISA_EENS_24DefaultDeterminizeFilterISC_EENS_28DefaultDeterminizeStateTableISC_NS_18IntegerFilterStateIaEEEEEE
N3fst22DeterminizeFstImplBaseINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEE
N3fst9CacheImplINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEE
N3fst13CacheBaseImplINS_10CacheStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEENSt3__19allocatorISD_EEEENS_17DefaultCacheStoreISD_EEEE
N3fst13StateIteratorINS_14DeterminizeFstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEEEE
N3fst18CacheStateIteratorINS_14DeterminizeFstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEEEE
N3fst17StateIteratorBaseINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEE
N3fst10MutableFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEENSt3__19allocatorIS9_EEEEEENS_10MutableFstIS9_EEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEENSt3__19allocatorIS9_EEEEEENS_10MutableFstIS9_EEEE
N3fst3FstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N3fst13VectorFstImplINS_11VectorStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEENSt3__19allocatorIS8_EEEEEE
N3fst7FstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N3fst10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEENS_11VectorStateIS8_NSt3__19allocatorIS8_EEEEEEEE
N3fst9VectorFstINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEENS_11VectorStateIS9_NSt3__19allocatorIS9_EEEEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEENSt3__19allocatorISB_EEEEEENS_10MutableFstISB_EEEE
N3fst10MutableFstINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEEEE
N3fst11ExpandedFstINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEENSt3__19allocatorISA_EEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEEEEE4LinkEEE
N3fst22MutableArcIteratorBaseINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEEEE
N3fst15ArcIteratorBaseINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEEEE
N3fst9ArcMapFstINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE0EEENS_14ToGallicMapperIS4_LS6_0EEEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE0EEENS_14ToGallicMapperIS5_LS7_0EEEEENS_3FstIS8_EEEE
N3fst13ArcMapFstImplINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE0EEENS_14ToGallicMapperIS4_LS6_0EEEEE
N3fst13StateIteratorINS_9ArcMapFstINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE0EEENS_14ToGallicMapperIS5_LS7_0EEEEEEE
N3fst17StateIteratorBaseINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N3fst9ImplToFstINS_19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEENS_12GallicFactorIiS5_LS7_0EEEEENS_3FstIS8_EEEE
N3fst19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEENS_12GallicFactorIiS4_LS6_0EEEEE
N3fst10RandGenFstINS_6ArcTplINS_17TropicalWeightTplIfEEEES4_NS_10ArcSamplerIS4_NS_18UniformArcSelectorIS4_EEEEEE
N3fst9ImplToFstINS_14RandGenFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEES5_NS_10ArcSamplerIS5_NS_18UniformArcSelectorIS5_EEEEEENS_3FstIS5_EEEE
N3fst14RandGenFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEES4_NS_10ArcSamplerIS4_NS_18UniformArcSelectorIS4_EEEEEE
N3fst9CacheImplINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N3fst13StateIteratorINS_10RandGenFstINS_6ArcTplINS_17TropicalWeightTplIfEEEES5_NS_10ArcSamplerIS5_NS_18UniformArcSelectorIS5_EEEEEEEE
N3fst18CacheStateIteratorINS_10RandGenFstINS_6ArcTplINS_17TropicalWeightTplIfEEEES5_NS_10ArcSamplerIS5_NS_18UniformArcSelectorIS5_EEEEEEEE
N6quasar34OnlineLatticeBiglmLmeFasterDecoderE
NSt3__110__function6__funcIZN6quasar34OnlineLatticeBiglmLmeFasterDecoder10finishInitEvE3$_0NS_9allocatorIS4_EEFNS_10shared_ptrIN3fst3FstINS8_6ArcTplINS8_17TropicalWeightTplIfEEEEEEEERKNS_12basic_stringIcNS_11char_traitsIcEENS5_IcEEEEEEE
ZN6quasar34OnlineLatticeBiglmLmeFasterDecoder10finishInitEvE3$_0
NSt3__110__function6__funcIZN6quasar34OnlineLatticeBiglmLmeFasterDecoder10finishInitEvE3$_1NS_9allocatorIS4_EEFNS_10shared_ptrIN5kaldi6quasar17NnlmEvaluatorBaseEEERKNS_12basic_stringIcNS_11char_traitsIcEENS5_IcEEEEEEE
ZN6quasar34OnlineLatticeBiglmLmeFasterDecoder10finishInitEvE3$_1
NSt3__120__shared_ptr_emplaceIN3fst9ArcMapFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEES6_NS1_6quasar23OffsetOutputLabelMapperEEENS_9allocatorIS9_EEEE
N3fst9ArcMapFstINS_6ArcTplINS_17TropicalWeightTplIfEEEES4_NS_6quasar23OffsetOutputLabelMapperEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEES5_NS_6quasar23OffsetOutputLabelMapperEEENS_3FstIS5_EEEE
N3fst13ArcMapFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEES4_NS_6quasar23OffsetOutputLabelMapperEEE
N3fst13StateIteratorINS_9ArcMapFstINS_6ArcTplINS_17TropicalWeightTplIfEEEES5_NS_6quasar23OffsetOutputLabelMapperEEEEE
NSt3__120__shared_ptr_emplaceIN3fst6quasar12MergeTrieFstENS_9allocatorIS3_EEEE
NSt3__110__function6__funcIZN6quasar34OnlineLatticeBiglmLmeFasterDecoder28insertLocationSpecificModelsERKNS_10shared_ptrINS2_18DecoderChainOutputEEERKNS4_INS2_17SpeechRequestDataEEERNS_6vectorIN3fst12FstWithLabelINSE_6ArcTplINSE_17TropicalWeightTplIfEEEEEENS_9allocatorISK_EEEERNSD_IiNSL_IiEEEERNS2_8LocationEE3$_2NSL_ISU_EEFNS4_INSE_3FstISJ_EEEERKSY_EEE
NSt3__110__function6__baseIFNS_10shared_ptrIN3fst3FstINS3_6ArcTplINS3_17TropicalWeightTplIfEEEEEEEERKSA_EEE
ZN6quasar34OnlineLatticeBiglmLmeFasterDecoder28insertLocationSpecificModelsERKNSt3__110shared_ptrINS_18DecoderChainOutputEEERKNS2_INS_17SpeechRequestDataEEERNS1_6vectorIN3fst12FstWithLabelINSC_6ArcTplINSC_17TropicalWeightTplIfEEEEEENS1_9allocatorISI_EEEERNSB_IiNSJ_IiEEEERNS_8LocationEE3$_2
NSt3__110__function6__funcIZN6quasar34OnlineLatticeBiglmLmeFasterDecoder28insertLocationSpecificModelsERKNS_10shared_ptrINS2_18DecoderChainOutputEEERKNS4_INS2_17SpeechRequestDataEEERNS_6vectorIN3fst12FstWithLabelINSE_6ArcTplINSE_17TropicalWeightTplIfEEEEEENS_9allocatorISK_EEEERNSD_IiNSL_IiEEEERNS2_8LocationEE3$_3NSL_ISU_EEFNS4_IN5kaldi6quasar17NnlmEvaluatorBaseEEERKSZ_EEE
NSt3__110__function6__baseIFNS_10shared_ptrIN5kaldi6quasar17NnlmEvaluatorBaseEEERKS6_EEE
ZN6quasar34OnlineLatticeBiglmLmeFasterDecoder28insertLocationSpecificModelsERKNSt3__110shared_ptrINS_18DecoderChainOutputEEERKNS2_INS_17SpeechRequestDataEEERNS1_6vectorIN3fst12FstWithLabelINSC_6ArcTplINSC_17TropicalWeightTplIfEEEEEENS1_9allocatorISI_EEEERNSB_IiNSJ_IiEEEERNS_8LocationEE3$_3
NSt3__110__function6__funcIZN6quasar34OnlineLatticeBiglmLmeFasterDecoder28insertLocationSpecificModelsERKNS_10shared_ptrINS2_18DecoderChainOutputEEERKNS4_INS2_17SpeechRequestDataEEERNS_6vectorIN3fst12FstWithLabelINSE_6ArcTplINSE_17TropicalWeightTplIfEEEEEENS_9allocatorISK_EEEERNSD_IiNSL_IiEEEERNS2_8LocationEE3$_4NSL_ISU_EEFNS4_IN5kaldi6quasar17NnlmEvaluatorBaseEEERKSZ_EEE
ZN6quasar34OnlineLatticeBiglmLmeFasterDecoder28insertLocationSpecificModelsERKNSt3__110shared_ptrINS_18DecoderChainOutputEEERKNS2_INS_17SpeechRequestDataEEERNS1_6vectorIN3fst12FstWithLabelINSC_6ArcTplINSC_17TropicalWeightTplIfEEEEEENS1_9allocatorISI_EEEERNSB_IiNSJ_IiEEEERNS_8LocationEE3$_4
N6quasar25JapaneseDerivedEnumeratorE
N6quasar29OnlineLatticeRescalingDecoderE
N6quasar21PDecForceAlignOptionsE
N6quasar25ConfiguredProcessingBlockINS_21PDecForceAlignOptionsEEE
N6quasar19PDecForceAlignBlockE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar19TorchEncoderDecoderENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar6EncdecENS_9allocatorIS3_EEEE
train
test
external
none
sweep-weights
interpolation
N6quasar16E2EAsrConfidenceE
NSt3__120__shared_ptr_emplaceINS_6vectorINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS5_IS7_EEEENS5_IS9_EEEE
NSt3__120__shared_ptr_emplaceINS_6vectorIN5kaldi6MatrixIfEENS_9allocatorIS4_EEEENS5_IS7_EEEE
NSt3__120__shared_ptr_emplaceINS_6vectorINS1_IfNS_9allocatorIfEEEENS2_IS4_EEEENS2_IS6_EEEE
'.N5kaldi6quasar17NnlmEvaluatorBaseE
N6quasar18SeevaGreedyDecoderE
N5kaldi5nnet124MovingAttentionComponentE
N6quasar15MappedPgmBitmapE
NSt3__120__shared_ptr_pointerIPN6quasar15MappedPgmBitmapENS_10shared_ptrIS2_E27__shared_ptr_default_deleteIS2_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrIN6quasar15MappedPgmBitmapEE27__shared_ptr_default_deleteIS2_S2_EE
NSt3__114default_deleteIN6quasar15MappedPgmBitmapEEE
N6quasar15AcousticLDModelE
N6quasar22AcousticLDModelFactoryE
N6quasar14LDResultStreamE
N6quasar19ContextAwareLDModelE
N6quasar24DummyContextAwareLDModelE
N6quasar26ContextAwareLDModelFactoryE
NSt3__120__shared_ptr_emplaceIKN6quasar10LDFrontendENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar8LDConfigENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIKN6quasar25ContextAwareLDModelConfigENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar14LDRequestStateENS_9allocatorIS2_EEEE
NSt3__110__function6__funcIZNK6quasar16LanguageDetector21processAcousticResultERNS2_14LDRequestStateERNS3_23WrappedLDAcousticResultEE3$_2NS_9allocatorIS8_EEFNS_12basic_stringIcNS_11char_traitsIcEENS9_IcEEEERKNS2_17language_detector6LocaleEEEE
NSt3__110__function6__baseIFNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEERKN6quasar17language_detector6LocaleEEEE
ZNK6quasar16LanguageDetector21processAcousticResultERNS_14LDRequestStateERNS0_23WrappedLDAcousticResultEE3$_2
IOVN6quasar30OnlineLatticeConfidenceDecoderE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar8WordConfENS_9allocatorIS3_EEEE
N6quasar12IModelLoaderE
N6quasar11ModelLoaderE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar15NnlmDecoderWordENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar14CEInferenceNetENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar15FofeLmEvaluatorENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar14RnnlmEvaluatorENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar14DnnlmEvaluatorENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi15TransitionModelENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar11ModelLoader20EmbeddedMlockContextENS_9allocatorIS3_EEEE
NN5kaldi6quasar20SeevaBeamSearchBigLmE
N5kaldi6quasar16CoreMLTensorDataE
N5kaldi6quasar19CoreMLNetworkConfigE
N5kaldi6quasar17CoreMLNetworkPlanE
N5kaldi5nnet124Convolutional2DComponentINS_12CuMatrixBaseIfEEEE
N5kaldi5nnet124Convolutional2DComponentINS_15QuantizedMatrixIaEEEE
N5kaldi6quasar19TorchEncoderDecoder14AttentionModelE
N5kaldi6quasar19TorchEncoderDecoderE
NSt3__120__shared_ptr_pointerIPN5kaldi5nnet14NnetENS_10shared_ptrIS3_E27__shared_ptr_default_deleteIS3_S3_EENS_9allocatorIS3_EEEE
NSt3__110shared_ptrIN5kaldi5nnet14NnetEE27__shared_ptr_default_deleteIS3_S3_EE
NSt3__114default_deleteIN5kaldi5nnet14NnetEEE
N5kaldi6quasar20SeevaStreamInferenceE
N5kaldi6quasar26SeevaStreamInferenceConfigE
16TaggedNgramStats
N6quasar19StreamingConfidenceE
N6quasar21LRStreamingConfidenceE
N6quasar16PhonetisaurusG2PE
NSt3__120__shared_ptr_emplaceI13PhonetisaurusNS_9allocatorIS1_EEEE
11TaggedNgram
N5kaldi5nnet118NormalizeComponentE
N5kaldi12CuVectorBaseIfEE
N6quasar7PDecG2PE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar10PhraseBookENS_9allocatorIS3_EEEE
NSt3__110shared_ptrIN5kaldi6quasar19TorchEncoderDecoderEE27__shared_ptr_default_deleteIS3_S3_EE
NSt3__114default_deleteIN5kaldi6quasar19TorchEncoderDecoderEEE
N3fst24DeterministicOnDemandFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N3fst10MemoryPoolINS_11ArcIteratorINS_3FstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEEEE
N3fst9VectorFstINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS5_9allocatorIfEEEEEEEENS_11VectorStateISB_NS7_ISB_EEEEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS7_9allocatorIfEEEEEEEENS9_ISD_EEEEEENS_10MutableFstISD_EEEE
N3fst7FstImplINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS5_9allocatorIfEEEEEEEEEE
ONSt3__120__shared_ptr_emplaceIN6quasar15PhonesetMappingENS_9allocatorIS2_EEEE
&8dd
N5kaldi6quasar12ESTensorDataE
N5kaldi6quasar15ESNetworkConfigE
N5kaldi6quasar13ESNetworkPlanE
N5kaldi6quasar15FofeLmEvaluatorE
N6quasar21PdecPhraseBookOptionsE
N6quasar25ConfiguredProcessingBlockINS_21PdecPhraseBookOptionsEEE
N6quasar19PDecPhraseBookBlockE
22EARContextAwareLDModel
29EARContextAwareLDModelFactory
25EARAcousticLDModelFactory
NSt3__120__shared_ptr_emplaceI21CoreMLAcousticLDModelNS_9allocatorIS1_EEEE
21CoreMLAcousticLDModel
NSt3__120__shared_ptr_emplaceIN6quasar9LDContextENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceI17EARLDResultStreamNS_9allocatorIS1_EEEE
17EARLDResultStream
NSt3__120__shared_ptr_emplaceIKN6quasar9LDContextENS_9allocatorIS3_EEEE
N6quasar25ConfiguredProcessingBlockINS_16TokenizerOptionsEEE
N6quasar14TokenizerBlockE
N6quasar16TokenizerOptionsE
N6quasar31ConfusionNetworkCombinerDecoderE
NSt3__120__shared_ptr_emplaceINS_6vectorINS1_INS1_IN6quasar5TokenENS_9allocatorIS3_EEEENS4_IS6_EEEENS4_IS8_EEEENS4_ISA_EEEE
N6quasar26KeywordSpottingSyncDecoderE
NSt3__113basic_fstreamIcNS_11char_traitsIcEEEE
NSt3__110shared_ptrIN3fst11SymbolTableEE27__shared_ptr_default_deleteIS2_S2_EE
?9SkipNgram
N6quasar6LmDataE
plain-text
ngram-counts
phrase-counts
template-grammar
NSt3__110__function6__funcIZNK6quasar6LmData9serializeENS3_11DataSetTypeENS_10unique_ptrINS_13basic_ostreamIcNS_11char_traitsIcEEEENS_14default_deleteIS9_EEEEE3$_1NS_9allocatorISD_EEFvRKNS2_2lm19TokenStringAndCountEEEE
NSt3__110__function6__baseIFvRKN6quasar2lm19TokenStringAndCountEEEE
ZNK6quasar6LmData9serializeENS0_11DataSetTypeENSt3__110unique_ptrINS2_13basic_ostreamIcNS2_11char_traitsIcEEEENS2_14default_deleteIS7_EEEEE3$_1
NSt3__110__function6__funcIZNK6quasar6LmData9serializeENS3_11DataSetTypeENS_10unique_ptrINS_13basic_ostreamIcNS_11char_traitsIcEEEENS_14default_deleteIS9_EEEEE3$_2NS_9allocatorISD_EEFvRKNS2_2lm19TokenStringAndCountEEEE
ZNK6quasar6LmData9serializeENS0_11DataSetTypeENSt3__110unique_ptrINS2_13basic_ostreamIcNS2_11char_traitsIcEEEENS2_14default_deleteIS7_EEEEE3$_2
NSt3__110__function6__funcIZNK6quasar6LmData9serializeENS3_11DataSetTypeENS_10unique_ptrINS_13basic_ostreamIcNS_11char_traitsIcEEEENS_14default_deleteIS9_EEEEE3$_3NS_9allocatorISD_EEFvRKNS2_2lm19TokenStringAndCountEEEE
ZNK6quasar6LmData9serializeENS0_11DataSetTypeENSt3__110unique_ptrINS2_13basic_ostreamIcNS2_11char_traitsIcEEEENS2_14default_deleteIS7_EEEEE3$_3
N5kaldi13InputImplBaseE
N5kaldi13FileInputImplE
N5kaldi17StandardInputImplE
N5kaldi13PipeInputImplE
N5kaldi19OffsetFileInputImplE
N5kaldi13basic_pipebufIcEE
N6quasar24SystemCombinationDecoderE
NSt3__123enable_shared_from_thisIN6quasar24SystemCombinationDecoderEEE
NSt3__120__shared_ptr_emplaceINS_6vectorIfNS_9allocatorIfEEEENS2_IS4_EEEE
".]]
HNUN6quasar24OfflineRecogResultStreamE
8LMClient
N5sdapi8SdapiG2PE
NSt3__120__shared_ptr_emplaceIN5sdapi18SimpleStringMapperENS_9allocatorIS2_EEEE
N3fst18ShortestFirstQueueIiNS_18StateWeightCompareIiNS_11NaturalLessINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEELb0EEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEENSt3__19allocatorISA_EEEEEENS_10MutableFstISA_EEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEENSt3__19allocatorISA_EEEEEENS_10MutableFstISA_EEEE
N3fst11ExpandedFstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEE
N3fst3FstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEE
N3fst10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEEE4LinkEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEENS_11VectorStateIS9_NSt3__19allocatorIS9_EEEEEEEE
N3fst22MutableArcIteratorBaseINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEE
N6quasar17SeevaBatchDecoderE
N5kaldi6quasar25SeevaInferenceTensorNamesE
!0W~
ekrNN
NSt3__120__shared_ptr_emplaceIN6quasar17PMRegexEnumeratorENS_9allocatorIS2_EEEE
N6quasar19ErrorBlamingDecoderE
N3fst3FstINS_6ArcTplINS_16LatticeWeightTplIfEEEEEE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar10LexiconFstENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar14RegionalLmPlugINS_10shared_ptrIN3fst3FstINS4_6ArcTplINS4_17TropicalWeightTplIfEEEEEEEEEENS_9allocatorISC_EEEE
NSt3__117bad_function_callE
NSt3__110__function6__funcIZN6quasar19ErrorBlamingDecoder10finishInitEvE3$_0NS_9allocatorIS4_EEFNS_10shared_ptrIN3fst3FstINS8_6ArcTplINS8_17TropicalWeightTplIfEEEEEEEERKNS_12basic_stringIcNS_11char_traitsIcEENS5_IcEEEEEEE
ZN6quasar19ErrorBlamingDecoder10finishInitEvE3$_0
NSt3__110__function6__funcIZN6quasar19ErrorBlamingDecoder10finishInitEvE3$_1NS_9allocatorIS4_EEFNS_10shared_ptrIN5kaldi6quasar17NnlmEvaluatorBaseEEERKNS_12basic_stringIcNS_11char_traitsIcEENS5_IcEEEEEEE
ZN6quasar19ErrorBlamingDecoder10finishInitEvE3$_1
NSt3__110__function6__funcIZN6quasar19ErrorBlamingDecoder7runImplERNS2_15DecoderPassDataERKNS_10shared_ptrINS2_18DecoderChainOutputEEERKNS6_INS2_17SpeechRequestDataEEERKNS_8functionIFbvEEEbE3$_2NS_9allocatorISK_EEFNS6_IN3fst3FstINSN_6ArcTplINSN_17TropicalWeightTplIfEEEEEEEERKSU_EEE
ZN6quasar19ErrorBlamingDecoder7runImplERNS_15DecoderPassDataERKNSt3__110shared_ptrINS_18DecoderChainOutputEEERKNS4_INS_17SpeechRequestDataEEERKNS3_8functionIFbvEEEbE3$_2
NSt3__110__function6__funcIZN6quasar19ErrorBlamingDecoder7runImplERNS2_15DecoderPassDataERKNS_10shared_ptrINS2_18DecoderChainOutputEEERKNS6_INS2_17SpeechRequestDataEEERKNS_8functionIFbvEEEbE3$_3NS_9allocatorISK_EEFNS6_IN5kaldi6quasar17NnlmEvaluatorBaseEEERKSQ_EEE
ZN6quasar19ErrorBlamingDecoder7runImplERNS_15DecoderPassDataERKNSt3__110shared_ptrINS_18DecoderChainOutputEEERKNS4_INS_17SpeechRequestDataEEERKNS3_8functionIFbvEEEbE3$_3
NSt3__120__shared_ptr_emplaceIN3fst13InterpArcInfoENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi21TrainingGraphCompilerENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN3fst9VectorFstINS1_6ArcTplINS1_23CompactLatticeWeightTplINS1_16LatticeWeightTplIfEEiEEEENS1_11VectorStateIS8_NS_9allocatorIS8_EEEEEENSA_ISD_EEEE
N6quasar17FstTokenTransformE
N6quasar14TokenTransformIN3fst9VectorFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEENS1_11VectorStateIS6_NSt3__19allocatorIS6_EEEEEEEE
N6quasar24ComposeFstTokenTransformE
N6quasar34SpaceApplyDefaultFstTokenTransformE
N6quasar39RewriteApplyCapitalizeFstTokenTransformE
N6quasar36RewriteApplyDefaultFstTokenTransformE
NSt3__120__shared_ptr_emplaceIN3fst14StringCompilerINS1_6ArcTplINS1_17TropicalWeightTplIfEEEEEENS_9allocatorIS7_EEEE
N3fst9ArcMapFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE3EEENS_14ToGallicMapperIS4_LS6_3EEEEE
N3fst3FstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEEEE
N3fst13CacheBaseImplINS_10CacheStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEENSt3__19allocatorIS8_EEEENS_17DefaultCacheStoreIS8_EEEE
N3fst10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEEEEE4LinkEEE
N3fst13StateIteratorINS_9ArcMapFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE3EEENS_14ToGallicMapperIS5_LS7_3EEEEEEE
N3fst17StateIteratorBaseINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEEEE
N3fst14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEEEE
4@9MM
4@9N6quasar18OnlineSeevaDecoderE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEE4LinkEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEENS_11VectorStateIS7_NSt3__19allocatorIS7_EEEEEEEE
N3fst22MutableArcIteratorBaseINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEENSt3__19allocatorIS8_EEEEEENS_10MutableFstIS8_EEEE
N3fst17StateIteratorBaseINS_6ArcTplINS_16LatticeWeightTplIfEEEEEE
N3fst13SortedMatcherINS_3FstINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEE
N3fst11MatcherBaseINS_6ArcTplINS_16LatticeWeightTplIfEEEEEE
N3fst10MemoryPoolINS_11ArcIteratorINS_3FstINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_11ArcIteratorINS_3FstINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEEE4LinkEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENS_21SequenceComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
".]]
HNU10ClassNgram
N5srilm10StringIterE
10NgramStats
8Discount
5Debug
13ConstDiscount
9AddSmooth
N6quasar7FeatureE
N6quasar17IntToFloatFeatureE
N6quasar19SamplingRateFeatureE
N6quasar15LocationFeatureE
N6quasar14OnlineAppendFeE
NSt3__120__shared_ptr_emplaceIN6quasar19SamplingRateFeatureENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar15LocationFeatureENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi17OnlineAppendInputENS_9allocatorIS2_EEEE
[www4[
?#'9?
BBB"B&*<B
N6quasar22SimpleTokenizerOptionsE
N6quasar25ConfiguredProcessingBlockINS_22SimpleTokenizerOptionsEEE
N6quasar20SimpleTokenizerBlockE
NSt3__118codecvt_utf8_utf16IwLm1114111ELNS_12codecvt_modeE0EEE
NSt3__111__end_stateIwEE
NSt3__16__nodeIwEE
NSt3__120__shared_ptr_pointerIPNS_13__empty_stateIwEENS_10shared_ptrIS2_E27__shared_ptr_default_deleteIS2_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrINS_13__empty_stateIwEEE27__shared_ptr_default_deleteIS2_S2_EE
NSt3__114default_deleteINS_13__empty_stateIwEEEE
NSt3__113__empty_stateIwEE
NSt3__116__owns_one_stateIwEE
NSt3__115__has_one_stateIwEE
NSt3__120__l_anchor_multilineIwEE
NSt3__120__r_anchor_multilineIwEE
NSt3__115__word_boundaryIwNS_12regex_traitsIwEEEE
NSt3__111__lookaheadIwNS_12regex_traitsIwEEEE
NSt3__123__match_any_but_newlineIwEE
NSt3__118__match_char_icaseIwNS_12regex_traitsIwEEEE
NSt3__120__match_char_collateIwNS_12regex_traitsIwEEEE
NSt3__112__match_charIwEE
NSt3__116__back_ref_icaseIwNS_12regex_traitsIwEEEE
NSt3__118__back_ref_collateIwNS_12regex_traitsIwEEEE
NSt3__110__back_refIwEE
NSt3__120__bracket_expressionIwNS_12regex_traitsIwEEEE
NSt3__128__begin_marked_subexpressionIwEE
NSt3__126__end_marked_subexpressionIwEE
NSt3__16__loopIwEE
NSt3__117__owns_two_statesIwEE
NSt3__117__repeat_one_loopIwEE
NSt3__111__alternateIwEE
NSt3__121__empty_non_own_stateIwEE
NSt3__111__match_anyIwEE
N6quasar11RecogResultE
N6quasar21RecogResultStreamBaseE
N6quasar17PMRegexEnumeratorE
N6quasar9SanitizerE
N6quasar27OnlineAudioAnalyticsDecoderE
12NgramCountLM
N5kaldi20OnlineAudioSourceItfE
N5kaldi6quasar12ErrorProfileE
N6quasar16HotfixTranslatorE
N6quasar9PronCacheINSt3__112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEENS1_6vectorIS7_NS5_IS7_EEEEEE
NSt3__120__shared_ptr_pointerIP5VocabNS_14default_deleteIS1_EENS_9allocatorIS1_EEEE
NSt3__114default_deleteI5VocabEE
N6quasar29GlobalHotfixTranslatorFactoryE
NSt3__120__shared_ptr_emplaceIN6quasar16HotfixTranslatorENS_9allocatorIS2_EEEE
N6quasar9RegexStepE
N6quasar11ReplaceStepE
N6quasar15WholeStringStepE
N6quasar9SplitStepE
NSt3__120__shared_ptr_emplaceIN6quasar11ReplaceStep9RegexRuleENS_9allocatorIS3_EEEE
N6quasar21GenderVerifierOptionsE
N6quasar25ConfiguredProcessingBlockINS_21GenderVerifierOptionsEEE
N6quasar19GenderVerifierBlockE
N6quasar15FileCoordinatorE
N6quasar18LanguageRecognizerE
N6quasar22OnlineSeevaStepDecoderE
N6quasar17TranslatorFactoryE
NSt3__120__shared_ptr_emplaceIN6quasar17TranslatorFactoryENS_9allocatorIS2_EEEE
2?8GG
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_12LogWeightTplIfEEEENSt3__19allocatorIS6_EEEEEENS_10MutableFstIS6_EEEE
N3fst14DeterminizeFstINS_6ArcTplINS_12LogWeightTplIfEEEEEE
N3fst9ImplToFstINS_22DeterminizeFstImplBaseINS_6ArcTplINS_12LogWeightTplIfEEEEEENS_3FstIS5_EEEE
N3fst18DeterminizeFsaImplINS_6ArcTplINS_12LogWeightTplIfEEEENS_20DefaultCommonDivisorIS3_EENS_24DefaultDeterminizeFilterIS4_EENS_28DefaultDeterminizeStateTableIS4_NS_18IntegerFilterStateIaEEEEEE
N3fst22DeterminizeFstImplBaseINS_6ArcTplINS_12LogWeightTplIfEEEEEE
N3fst9CacheImplINS_6ArcTplINS_12LogWeightTplIfEEEEEE
N3fst13StateIteratorINS_14DeterminizeFstINS_6ArcTplINS_12LogWeightTplIfEEEEEEEE
N3fst18CacheStateIteratorINS_14DeterminizeFstINS_6ArcTplINS_12LogWeightTplIfEEEEEEEE
N3fst18DeterminizeFstImplINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3ENS_20DefaultCommonDivisorIS3_EENS_24DefaultDeterminizeFilterIS4_EENS_28DefaultDeterminizeStateTableIS4_NS_18IntegerFilterStateIaEEEEEE
N3fst9ArcMapFstINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE3EEENS_14ToGallicMapperIS4_LS6_3EEEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE3EEENS_14ToGallicMapperIS5_LS7_3EEEEENS_3FstIS8_EEEE
N3fst3FstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEEEE
N3fst13ArcMapFstImplINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE3EEENS_14ToGallicMapperIS4_LS6_3EEEEE
N3fst9CacheImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEEEE
N3fst13CacheBaseImplINS_10CacheStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEENSt3__19allocatorIS8_EEEENS_17DefaultCacheStoreIS8_EEEE
N3fst7FstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEEEE
N3fst10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEEEEE4LinkEEE
N3fst13StateIteratorINS_9ArcMapFstINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE3EEENS_14ToGallicMapperIS5_LS7_3EEEEEEE
N3fst17StateIteratorBaseINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEEEE
N3fst14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEEEE
N3fst9ImplToFstINS_22DeterminizeFstImplBaseINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEEEENS_3FstIS8_EEEE
N3fst18DeterminizeFsaImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEENS_19GallicCommonDivisorIiS4_LS6_3ENS_20DefaultCommonDivisorIS4_EEEENS_24DefaultDeterminizeFilterIS7_EENS_28DefaultDeterminizeStateTableIS7_NS_18IntegerFilterStateIaEEEEEE
N3fst22DeterminizeFstImplBaseINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEEEE
N3fst13StateIteratorINS_14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEEEEEE
N3fst18CacheStateIteratorINS_14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEEEEEE
N3fst15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEENS_12GallicFactorIiS4_LS6_3EEEEE
N3fst9ImplToFstINS_19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEENS_12GallicFactorIiS5_LS7_3EEEEENS_3FstIS8_EEEE
N3fst19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEENS_12GallicFactorIiS4_LS6_3EEEEE
N3fst13StateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEENS_12GallicFactorIiS5_LS7_3EEEEEEE
N3fst18CacheStateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEENS_12GallicFactorIiS5_LS7_3EEEEEEE
N3fst9ArcMapFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEES5_NS_16FromGallicMapperIS5_LS6_3EEEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEES6_NS_16FromGallicMapperIS6_LS7_3EEEEENS_3FstIS6_EEEE
N3fst13ArcMapFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEES5_NS_16FromGallicMapperIS5_LS6_3EEEEE
N3fst13StateIteratorINS_9ArcMapFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEES6_NS_16FromGallicMapperIS6_LS7_3EEEEEEE
N3fst18DeterminizeFstImplINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2ENS_20DefaultCommonDivisorIS3_EENS_24DefaultDeterminizeFilterIS4_EENS_28DefaultDeterminizeStateTableIS4_NS_18IntegerFilterStateIaEEEEEE
N3fst9ArcMapFstINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE2EEENS_14ToGallicMapperIS4_LS6_2EEEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE2EEENS_14ToGallicMapperIS5_LS7_2EEEEENS_3FstIS8_EEEE
N3fst3FstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEEEE
N3fst13ArcMapFstImplINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE2EEENS_14ToGallicMapperIS4_LS6_2EEEEE
N3fst9CacheImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEEEE
N3fst13CacheBaseImplINS_10CacheStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEENSt3__19allocatorIS8_EEEENS_17DefaultCacheStoreIS8_EEEE
N3fst7FstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEEEE
N3fst10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEEEEE4LinkEEE
N3fst13StateIteratorINS_9ArcMapFstINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE2EEENS_14ToGallicMapperIS5_LS7_2EEEEEEE
N3fst17StateIteratorBaseINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEEEE
N3fst14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEEEE
N3fst9ImplToFstINS_22DeterminizeFstImplBaseINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEEEENS_3FstIS8_EEEE
N3fst18DeterminizeFsaImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEENS_19GallicCommonDivisorIiS4_LS6_2ENS_20DefaultCommonDivisorIS4_EEEENS_24DefaultDeterminizeFilterIS7_EENS_28DefaultDeterminizeStateTableIS7_NS_18IntegerFilterStateIaEEEEEE
N3fst22DeterminizeFstImplBaseINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEEEE
N3fst13StateIteratorINS_14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEEEEEE
N3fst18CacheStateIteratorINS_14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEEEEEE
N3fst15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEENS_12GallicFactorIiS4_LS6_2EEEEE
N3fst9ImplToFstINS_19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEENS_12GallicFactorIiS5_LS7_2EEEEENS_3FstIS8_EEEE
N3fst19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEENS_12GallicFactorIiS4_LS6_2EEEEE
N3fst13StateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEENS_12GallicFactorIiS5_LS7_2EEEEEEE
N3fst18CacheStateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEENS_12GallicFactorIiS5_LS7_2EEEEEEE
N3fst9ArcMapFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEES5_NS_16FromGallicMapperIS5_LS6_2EEEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEES6_NS_16FromGallicMapperIS6_LS7_2EEEEENS_3FstIS6_EEEE
N3fst13ArcMapFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEES5_NS_16FromGallicMapperIS5_LS6_2EEEEE
N3fst13StateIteratorINS_9ArcMapFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEES6_NS_16FromGallicMapperIS6_LS7_2EEEEEEE
N3fst18DeterminizeFstImplINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4ENS_20DefaultCommonDivisorIS3_EENS_24DefaultDeterminizeFilterIS4_EENS_28DefaultDeterminizeStateTableIS4_NS_18IntegerFilterStateIaEEEEEE
N3fst9ArcMapFstINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE4EEENS_14ToGallicMapperIS4_LS6_4EEEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE4EEENS_14ToGallicMapperIS5_LS7_4EEEEENS_3FstIS8_EEEE
N3fst3FstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEEEE
N3fst13ArcMapFstImplINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE4EEENS_14ToGallicMapperIS4_LS6_4EEEEE
N3fst9CacheImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEEEE
N3fst13CacheBaseImplINS_10CacheStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEENSt3__19allocatorIS8_EEEENS_17DefaultCacheStoreIS8_EEEE
N3fst7FstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEEEE
N3fst10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEEEEE4LinkEEE
N3fst13StateIteratorINS_9ArcMapFstINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE4EEENS_14ToGallicMapperIS5_LS7_4EEEEEEE
N3fst17StateIteratorBaseINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEEEE
N3fst14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEEEE
N3fst9ImplToFstINS_22DeterminizeFstImplBaseINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEEEENS_3FstIS8_EEEE
N3fst18DeterminizeFsaImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEENS_19GallicCommonDivisorIiS4_LS6_4ENS_20DefaultCommonDivisorIS4_EEEENS_24DefaultDeterminizeFilterIS7_EENS_28DefaultDeterminizeStateTableIS7_NS_18IntegerFilterStateIaEEEEEE
N3fst22DeterminizeFstImplBaseINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEEEE
N3fst13StateIteratorINS_14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEEEEEE
N3fst18CacheStateIteratorINS_14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEEEEEE
N3fst15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEENS_12GallicFactorIiS4_LS6_4EEEEE
N3fst9ImplToFstINS_19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEENS_12GallicFactorIiS5_LS7_4EEEEENS_3FstIS8_EEEE
N3fst19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEENS_12GallicFactorIiS4_LS6_4EEEEE
N3fst13StateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEENS_12GallicFactorIiS5_LS7_4EEEEEEE
N3fst18CacheStateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEENS_12GallicFactorIiS5_LS7_4EEEEEEE
N3fst9ArcMapFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEES5_NS_16FromGallicMapperIS5_LS6_4EEEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEES6_NS_16FromGallicMapperIS6_LS7_4EEEEENS_3FstIS6_EEEE
N3fst13ArcMapFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEES5_NS_16FromGallicMapperIS5_LS6_4EEEEE
N3fst13StateIteratorINS_9ArcMapFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEES6_NS_16FromGallicMapperIS6_LS7_4EEEEEEE
N3fst9VectorFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEENS_11VectorStateIS7_NSt3__19allocatorIS7_EEEEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEENSt3__19allocatorIS9_EEEEEENS_10MutableFstIS9_EEEE
N3fst10MutableFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N3fst11ExpandedFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEENSt3__19allocatorIS8_EEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEEE4LinkEEE
N3fst22MutableArcIteratorBaseINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N3fst15ArcIteratorBaseINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEENSt3__19allocatorISB_EEEEEENS_10MutableFstISB_EEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEENSt3__19allocatorISB_EEEEEENS_10MutableFstISB_EEEE
N3fst3FstINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEEEE
N3fst13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEENSt3__19allocatorISA_EEEEEE
N3fst7FstImplINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEEEE
N3fst10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEEEEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEENS_11VectorStateISA_NSt3__19allocatorISA_EEEEEEEE
N3fst15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEENS_12GallicFactorIiS4_LS6_0EEEEE
N3fst9CacheImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N3fst13CacheBaseImplINS_10CacheStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEENSt3__19allocatorIS8_EEEENS_17DefaultCacheStoreIS8_EEEE
N3fst13StateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEENS_12GallicFactorIiS5_LS7_0EEEEEEE
N3fst18CacheStateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEENS_12GallicFactorIiS5_LS7_0EEEEEEE
N6quasar16CommandTransformE
N6quasar23AllCapsCommandTransformE
N6quasar25AllCapsOnCommandTransformE
N6quasar19CapCommandTransformE
N6quasar22CapsOnCommandTransformE
N6quasar23CapsOffCommandTransformE
N6quasar22NoCapsCommandTransformE
N6quasar24NoCapsOnCommandTransformE
N6quasar23NoSpaceCommandTransformE
N6quasar25NoSpaceOnCommandTransformE
N6quasar26NoSpaceOffCommandTransformE
N6quasar23NewLineCommandTransformE
N6quasar28NewParagraphCommandTransformE
N6quasar31PeriodParagraphCommandTransformE
N6quasar22TabKeyCommandTransformE
N6quasar28NoBreakSpaceCommandTransformE
N6quasar24SpaceBarCommandTransformE
N6quasar25BackslashCommandTransformE
N6quasar26AllCapsOffCommandTransformE
N6quasar25NoCapsOffCommandTransformE
NSt3__120__shared_ptr_emplaceIN6quasar23AllCapsCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar25AllCapsOnCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar26AllCapsOffCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar19CapCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar22CapsOnCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar23CapsOffCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar22NoCapsCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar24NoCapsOnCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar25NoCapsOffCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar23NoSpaceCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar25NoSpaceOnCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar26NoSpaceOffCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar23NewLineCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar28NewParagraphCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar31PeriodParagraphCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar22TabKeyCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar28NoBreakSpaceCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar24SpaceBarCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar25BackslashCommandTransformENS_9allocatorIS2_EEEE
N5kaldi5nnet126SimplerSimpleRecurrentUnitE
".cc
OU\We love Marisa.
N6marisa9ExceptionE
N13sentencepiece3bpe5ModelE
N13sentencepiece5model8FreeListIZNKS_3bpe5Model12SampleEncodeEN4absl11string_viewEfE10SymbolPairEE
NSt3__110__function6__funcIZNK13sentencepiece3bpe5Model12SampleEncodeEN4absl11string_viewEfE3$_2NS_9allocatorIS7_EEFvS6_PNS_6vectorINS_4pairIS6_iEENS8_ISC_EEEEEEE
NSt3__110__function6__baseIFvN4absl11string_viewEPNS_6vectorINS_4pairIS3_iEENS_9allocatorIS6_EEEEEEE
ZNK13sentencepiece3bpe5Model12SampleEncodeEN4absl11string_viewEfE3$_2
)6N13sentencepiece31SentencePieceText_SentencePieceE
N13sentencepiece17SentencePieceTextE
N13sentencepiece22NBestSentencePieceTextE
N6google8protobuf8internal16InternalMetadata9ContainerINSt3__112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEEEE
N6google8protobuf8internal16InternalMetadata13ContainerBaseE
2DSe
N13sentencepiece11TrainerSpecE
N13sentencepiece14NormalizerSpecE
N13sentencepiece19SelfTestData_SampleE
N13sentencepiece12SelfTestDataE
N13sentencepiece24ModelProto_SentencePieceE
N13sentencepiece10ModelProtoE
N13sentencepiece9character5ModelE
$).38=BGLQN13sentencepiece10filesystem17PosixReadableFileE
N13sentencepiece10filesystem12ReadableFileE
-03N13sentencepiece14ModelInterfaceE
N13sentencepiece10normalizer10NormalizerE
N5Darts15DoubleArrayImplIvvivEE
N5Darts7Details9ExceptionE
N13sentencepiece22SentencePieceProcessorE
$1WW
BPHN13sentencepiece7unigram5ModelE
N13sentencepiece7unigram7LatticeE
N13sentencepiece5model8FreeListINS_7unigram7Lattice4NodeEEE
N13sentencepiece5model8FreeListIZNS_7unigram7Lattice5NBestEmbfE10HypothesisEE
N13sentencepiece4word5ModelE
N6google8protobuf14FatalExceptionE
+8ER_l
/3N6google8protobuf8internal15ExtensionFinderE
N6google8protobuf8internal24GeneratedExtensionFinderE
N6google8protobuf8internal12ExtensionSet8KeyValueE
N6google8protobuf13RepeatedFieldIiEE
N6google8protobuf13RepeatedFieldIxEE
N6google8protobuf13RepeatedFieldIjEE
N6google8protobuf13RepeatedFieldIyEE
N6google8protobuf13RepeatedFieldIfEE
N6google8protobuf13RepeatedFieldIdEE
N6google8protobuf13RepeatedFieldIbEE
N6google8protobuf16RepeatedPtrFieldINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEEE
N6google8protobuf8internal20RepeatedPtrFieldBaseE
N6google8protobuf16RepeatedPtrFieldINS0_11MessageLiteEEE
NSt3__13mapIiN6google8protobuf8internal12ExtensionSet9ExtensionENS_4lessIiEENS_9allocatorINS_4pairIKiS5_EEEEEE
N6google8protobuf11MessageLiteE
NSt3__112basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEE
Loading configuration from: %@
Phonetic-match building is not supported
Internal unknown exception
Internal C++ exception: %s
Cannot write profile: path is empty
Cannot write profile: path points to a directory
Persisting speech profile to path=%{private}@ failed with error=%{public}@ protectionClass=%ld coordinated=%d
Persisted speech profile to path=%{private}@ protectionClass=%ld coordinated=%d
Reading user profile: path %{private}@
Failed to read profile: stream failure
Successfully read Quasar blob profile
Failed to read Quasar blob profile: corrupt data or plist profile
Failed to read plist profile: nil data
Failed to read plist profile: nil or bad dict dict
Failed to read plist profile: nil profile
Read stream of %lu bytes
Successfully read plist profile
Failed to read plist profile: corrupt data
Failed to read profile: Internal unknown exception
Failed to read profile: Internal C++ exception: %s
Size mismatch. concatNbest would throw. Logging data loss.
Voice commands enabled without active set; using bundled assets.
Audio buffer has been deallocated; not restarting recognition
Result stream wrapper has been deallocated; not restarting recognition
Result stream wrapper has been deallocated
Error file sent for compilation does not exist. Not compiling.
Error determining compilation status: %@
Attempting to compile ANE model: %@
Found an error: %@
Compilation completed.
Skipping model that's already compiled: %@
Unexpected exception while compiling recognizer models with configuration path: %@
Exception (...): %s
Error file sent for purge does not exist. Not purging.
Attempting to purge ANE model: %@
Purge completed.
Unexpected exception while purging compiled recognizer models with configuration path: %@
Got interrupt signal, going to interrupt training if training is enabled and still running.
Unexpected exception while initializing EARSpeechModelInfo from configuration file at %@
Recognition failure in execution %{public}@
Starting to initialize model, fileName=%@
Finished initializing model, fileName=%@
detectUtterances %d concatenateUtterances %d allowUtteranceDelay %d formatAcrossUtterances %d
Recognizer has been deallocated; not writing partial results
Recognizer has been deallocated; not writing final choices
Result stream has been deallocated; not writing final choices
recogResult.params is null. Should NEVER happen
Recognizer has been deallocated; not reporting result progress
Result stream has been deallocated; not reporting result progress
Recognizer has been deallocated; not writing end point data
Result stream has been deallocated; not writing end point data
Recognizer has been deallocated; not training speaker code.
Training instance has been deallocated; not training speaker code.
Speaker code writer has been deallocated; not training speaker code.
Features or labels are invalid, not feeding data for training, feature size: %zu, label size: %zu
Training starts, total samples: %zu
Training finishes, writing updated speaker code out, processed samples: %zu, training offset: %zu, recognition offset: %zu
mlock source %s size %lu mlock_fraction %f mlock_size %lu locked_ %d ret %d errno %d strerror %s
munlock source %s size %lu mlock_fraction %f mlock_size %lu locked_ %d ret %d errno %d strerror %s
%{public}s
Input type not recognized
Initializing %@
File does not exist %@
Unsupported input data type
Document type is not set properly
Input data to serialization is nil
Serialization process failed with error: %@
Deserialization process failed with error: %@
Unknown protection class: %@
Cannot cast to NgramFstConfig
Cannot cast to NgramLmModel
Model building failed
Interpolation failed
PSR: EARAudioProcessor Config file does not exist at %@
PSR: ERR: AudioProcessorPipeline created with incorrect version
endAudio
resetForNewRequest
ComputeTask done
dealloc
Failed to dynamic cast Artifact to AppLmArtifact
Failed to load app lm data object for use parsing custom prons
Interpolating app-lm with a weight of %f
Interpolating app-lm with default weight
Transitioned artifact
Transitioning artifact at %@ failed
No custom prons or OOVs present in artifact
LME template for adding artifact custom prons not present in %@ or is empty
LME tag empty
Cannot find emoji recognition candidate from emoji hammer
Cannot create EMFEmojiToken; Unable to connect to Emoji Foundation framework
Config file does not exist at %{public}@
ARG: ERR: AudioProcessorPipeline created with incorrect version
Resetting audio result generator
Got valid result mat in sync fashion with numRows:%lu and numCols:%lu
Got valid result row in sync fashion with numCols:%lu
Ending audio
Unknown EARVoiceCommandActiveSet serialized version
Unknown EARVoiceCommandSuite serialized version
Unknown EARVoiceCommandSpec serialized version
GeoLM: geo config path: %@
GeoLM: Internal unknown exception
GeoLM: Internal C++ exception: %s
GeoLM: selected regionId: %@
Cannot create SPM model
_EARFormatter initialization failed: %s
Quasar Itn missing in configuration
Quasar Itn is nil
Emoji service is not available; Emoji Recognition is turned off
PSR: EARSyncAudioProcessor Config file does not exist at %@
Added %d samples, processed %d ms of audio so far
End audio: Processed %d ms of audio so far
Failed to read speaker code file, language is null or empty
Failed to read speaker code file, path is null or empty
Reading speaker code file from disk, full path: %@
Failed to read speaker code file, error: %@
Failed to deserialize speaker code file, error: %@
Failed to write speaker code file, training speaker code is null or empty
Failed to write speaker code file, inference speaker code is null or empty
Failed to write speaker code file, accumulated gradient is null or empty
Failed to write speaker code file, language is null or empty
Failed to write speaker code file, path is null or empty
Saving speaker code file on disk, full path: %@, num trained frames: %zu, training offset: %zu, recognition offset: %zu, training speaker code: %@, inference speaker code: %@, accumulated gradient: %@
Failed to serialize speaker code data, error: %@
Speaker code data is serialized, writing to file: %@
Failed to write speaker code data, error: %@
Error loading context-aware model: %@
No supported languages found in acousticPosteriors
context.currentDictationLanguage is empty, setting currentDictationLocale to zeroes.
context.wasLanguageToggled not set, defaulting to false.
context.multilingualKeyboardLanguages not set, setting multilingualKeyboardLocales to zeroes.
context.keyboardConvoLanguagePriors not set, setting keyboardConvoLocalePriors to uniform probability.
context.keyboardGlobalLanguagePriors not set, setting keyboardGlobalLocalePriors to uniform probability.
context.previousMessageLanguage not set, setting previousMessageLocale to zeroes.
context.globalLastKeyboardUsed not set, setting globalLastKeyboardUsed to zeroes.
context.dictationLanguagePriors not set, setting dictationLocalePriors to uniform probability.
%s, error %@
Exception in EARContextAwareLDModelFactory::createModel: %s
Unsupported model file format "%s"
Identified languages of messages = %@
%@ maps to %@
There is no keyboard language for %@
Starting new request
previousMessageLanguage and keyboardConvoLanguagePriors are both set, so recentMessages will be ignored.
Unsupported locales (%s) found in context, will be ignored
Error initializing model.
Attempting to load model file: %@
Failed to reload CoreML model with error: %@
Failed to create feature multiarray with error %@
Failed to create feature provider with error %@
Error during prediction: %@
LanguageDetector: EARLanguageDetector model file does not exist at %@
Received didFinishProcessingFrames
Got an error when trying to print logging info
Logging Data: %@
Sending logging info to delegate
Received didComputeResult
Sending language detector result to delegate
Sending language detector confidences to delegate
Failed to initialize XML parser for custom prons file at %@
softlink:o:path:/System/Library/PrivateFrameworks/AssistantServices.framework/AssistantServices
_EAROnDeviceEndpointerInfo
_EARPhoneticMatchData
_EARPhoneticMatchBuilder
EMTSpan
NSCopying
NoiseSampler
_EARWordPart
_EARPeopleSuggesterConfig
_EARUserProfileBuilder
_EARUserProfile
_EARUserProfileConfig
_EARUserProfileContainer
_EAREndpointFeatures
_EARDefaultServerEndpointFeatures
_EAREndpointer
_EARSpeechRecognitionToken
_EARAcousticFeature
_EARAudioAnalytics
_EARLatticeMitigatorResult
_EARSpeechRecognition
_EARSpeechRecognitionResultPackage
_EARSpeechRecognitionResult
_EARResultContext
_EARLazyDoubleArray
_EARSpeechRecognizer
Q$+*
_EARSpeechModelInfo
_EARSpeakerCodeInfo
_EARSyncResultStreamHelper
_EARSpeechRecognitionResultStream
NSObject
_EARSpeechRecognitionActiveConfiguration
_EARRecognitionMetrics
EARSdapiHelper
TextSequenceInference
TextSequence
TextSequenceTrain
_EARTransformUtil
_EARLMTKaldiVocab
_EARSpeechRecognitionAudioBuffer
_EARSyncSpeechRecognizer
_EARSystemResult
_EARCombinedResult
_EARResultCombiner
TextProcessorInference
TextProcessor
TextProcessorTrain
_EARLanguageDetectorRequestContext
_EARTextNormalization
_EARNnetUtil
EARTokenPronounciations
EARKeywordFinderResult
EARKeywordFinder
EARAudioReader
_EARHash
_EARContextualData
EARStringView
EMTTokenizer
_EARLmData
_EARLmModel
_EARLmModel2
_EARNgramLmModel
_EARNgramLmModel2
_EARLmBuilder
_EARInterpolator
_EARLmInterpolator
_EARLmEvaluator
_EARLmLoader
_EARLmLoader2
_EAROovToken
_EARAppLmData
_EARCustomLMBuilder
EARPSRAudioProcessor
EARCSpeechRecognitionResultStreamGlue
_EARLanguageDetectorAudioBuffer
EMTToken
_EARArtifact
_EARAppLmArtifact
_EARAppLmArtifactUtils
_EAREmojiRecognition
EARAudioResult
EARAudioResultsGenerator
EARVoiceCommandActiveSet
NSSecureCoding
NSCoding
EARVoiceCommandSuite
EARVoiceCommandSpec
EMTTranslator
_EARGeoLMHelper
EARVoiceCommandInterpretation
EARVoiceCommandArgument
_EARLanguageModel
EARSentencePieceModule
_EARFormatter
EMTResult
_EARJitProfile
_EARCustomPronData
EARSyncPSRAudioProcessor
_EARLmHandle
EARClientSilenceFeatures
EARCaesuraSilencePosteriorGenerator
_EARSpeakerCodeReader
_EARSpeakerCodeWriter
_EARSpeakerCodeWriterInterface
_EARPhonesetMapping
_EARLanguageDetectorLoggingInfo
_EARLanguageDetectorResult
_EARLanguageDetector
_EARCommandTagging
_EARCommandTaggingResult
_EARCommandTagger
_EARPlsParser
NSXMLParserDelegate
_EARTokenizer
_EARSdapiTokenizer
_EARNLTokenizer
_EARLMTGlobalNNLM
_EARProfiler
initWithTagSchemes:
predictionsFromBatch:options:error:
dataWithPropertyList:format:options:error:
substringToIndex:
enumerateKeysAndObjectsUsingBlock:
fillWithNumber:
objectAtIndexedSubscript:
valueForKey:
replaceObjectAtIndex:withObject:
lastUsedVariantEmojiForEmoji:
total_ane_time_ns
raise:format:
copyWithoutModifiers
getBytes:length:
tracksWithMediaType:
mutableBytes
dateWithTimeIntervalSinceNow:
substringWithRange:
enumerateObjectsUsingBlock:
objectForKey:
mutableCopy
getCString:maxLength:encoding:
length
countByEnumeratingWithState:objects:count:
raise:format:arguments:
completedUnitCount
componentsJoinedByString:
objectForKeyedSubscript:
firstIndex
vectorizeIntoMultiArray:storageOrder:error:
startReading
firstObject
absoluteString
enumerateTagsInRange:unit:scheme:options:usingBlock:
allObjects
componentsSeparatedByCharactersInSet:
decodeIntegerForKey:
strides
initWithUnsignedInt:
lengthOfBytesUsingEncoding:
shape
isEqualToArray:
_initWithoutConnection
decodeObjectOfClass:forKey:
errorWithDomain:code:userInfo:
outputDescriptionsByName
rawTranscription
initWithUnsignedLong:
blockOperationWithBlock:
dominantLanguage
floatValue
exchangeObjectAtIndex:withObjectAtIndex:
createDirectoryAtPath:withIntermediateDirectories:attributes:error:
string
readDataUpToLength:error:
defaultCStringEncoding
componentsSeparatedByString:
stringByAppendingFormat:
isEqualToIndexSet:
setObject:atIndexedSubscript:
_isSingleEmoji
whitespaceCharacterSet
defaultManager
boolValue
supportsSkinToneVariants
systemUptime
setString:
isEqualToSet:
stringByAppendingPathComponent:
dominantLanguageForString:
setObject:forKey:
createDirectoryAtURL:withIntermediateDirectories:attributes:error:
readEmojiDefaults
isEqualToString:
indexOfObjectPassingTest:
needsANECompilationForModelAtURL:result:error:
doubleValue
setComputeUnits:
localeIdentifier
ane_performance_info
processInfo
initWithContentsOfFile:options:error:
featureNames
stringByDeletingLastPathComponent
parse
setObject:forKeyedSubscript:
bundleForClass:
resourceURL
newlineCharacterSet
featureValueForName:
addIndex:
processString:
stringByReplacingOccurrencesOfString:withString:
bytes
appendBytes:length:
setTotalUnitCount:
currentHandler
localizedDescription
UTF8String
recentEmojis
appendData:
URLWithString:
progress
writeToFile:options:error:
containsObject:
featureValueWithDouble:
canAddOutput:
addIndexes:
longLongValue
isOptional
stringByStandardizingPath
reverseObjectEnumerator
stringByReplacingOccurrencesOfString:withString:options:range:
initWithDataPointer:shape:dataType:strides:deallocator:error:
null
inputDescriptionsByName
path
featureValueWithInt64:
initWithArray:
appendString:
addObject:
initWithDictionary:
longValue
containsString:
type
pathExtension
numberWithBool:
emojiLocaleDataWithLocaleIdentifier:
insertObject:atIndex:
featureValueWithMultiArray:
stringByTrimmingCharactersInSet:
addObjectsFromArray:
initWithArray:copyItems:
stringValue
lowercaseString
unsignedIntValue
setUsesCPUOnly:
dataPointer
fileExistsAtPath:
setValue:forKey:
propertyListWithData:options:format:error:
initWithDictionary:error:
featuresAtIndex:
numberWithChar:
URLByAppendingPathComponent:
stringWithCString:encoding:
int64Value
numberWithDouble:
intValue
emojiTokenWithString:localeData:
dictionary
unsignedIntegerValue
array
setValue:forKeyPath:
emojiTokensForText:phoneticReading:options:searchType:includePrefixMatches:
modelDescription
dataType
addOperation:
initWithFilePresenter:
handleFailureInFunction:file:lineNumber:description:
initWithBytes:length:encoding:
initWithFeatureProviderArray:
addOutput:
clientSilenceFeaturesAvailable:
numberWithFloat:
_disconnect
unsignedLongValue
dictionaryValue
initWithCapacity:
arrayByAddingObjectsFromArray:
fileHandleForReadingFromURL:error:
handleFailureInMethod:object:file:lineNumber:description:
dataUsingEncoding:
stringWithContentsOfFile:encoding:error:
integerValue
stringWithContentsOfURL:encoding:error:
numberWithInt:
encodeInteger:forKey:
dictionaryWithCapacity:
modelWithContentsOfURL:configuration:error:
fileSystemRepresentation
dataWithBytes:length:
setQueuePriority:
dictionaryWithContentsOfURL:
initWithShape:dataType:error:
URLForResource:withExtension:
stringWithFormat:
modelWithContentsOfURL:error:
initWithInt:
numberWithLongLong:
arrayWithCapacity:
dataWithBytesNoCopy:length:
fileURLWithFileSystemRepresentation:isDirectory:relativeToURL:
coordinateReadingItemAtURL:options:error:byAccessor:
setWithArray:
setWithCapacity:
encodeObject:forKey:
coordinateWritingItemAtURL:options:error:byAccessor:
stringWithUTF8String:
purgeANEIRForModelAtURL:error:
numberWithUnsignedInt:
arrayWithObjects:count:
dictionaryWithObject:forKey:
multiArrayByConcatenatingMultiArrays:alongAxis:dataType:
setWithObject:
multiArrayConstraint
copy
arrayWithObjects:
setLength:
languageDetectorDidCompleteProcessing:loggingInfo:
subarrayWithRange:
fileURLWithPath:
dataWithCapacity:
numberWithUnsignedInteger:
dictionaryWithObjects:forKeys:
multiArrayValue
dictionaryWithObjects:forKeys:count:
assetReaderAudioMixOutputWithAudioTracks:audioSettings:
predictionFromFeatures:options:error:
fileURLWithPath:isDirectory:
hasLastUsedVariantForEmoji:
numberWithUnsignedLong:
didFinishModelInitializing:
substring
dataWithContentsOfFile:
fileURLWithPath:isDirectory:relativeToURL:
lastIndex
setWithSet:
assetReaderWithAsset:error:
setMaxConcurrentOperationCount:
totalUnitCount
lastObject
copyIntoMultiArray:error:
dataWithContentsOfFile:options:error:
copyNextSampleBuffer
didStartModelInitializing:
removeObjectAtIndex:
removeLastObject
segments
assetWithURL:
init
initWithConfig:
getEndpointerThresholdForClientModelVersion:task:
getEndpointerExtraDelayFrequencyForTask:
.cxx_destruct
.cxx_construct
_hybridClientConfigs
convertFeedType:
initWithFeedType:jsonConfigFile:
writeTsv:
sortItemsByPriorDesc
sortItemsByPriorAsc
normalizePriors
expDecayPriors
powerScalePriors
applyRegexEnumerations
addOsym
appendData:prior:
roomForMoreData
getLimit
dataFeed
_dataFeed
T{shared_ptr<quasar::DataFeed>=^{DataFeed}^{__shared_weak_count}},R,N,V_dataFeed
writePlaceholderFstToPath:
writePlaceholderSymbolsToPath:
initWithNcsRoot:jsonConfigFile:dataFeeds:
initWithNcsRoot:jsonConfigFile:dataFeedsFile:
supportPhoneticMatchBuilding
buildGFsts
buildLFst
buildAlignedLFst
composeLGFsts
combineFsts
reset
writeAlignedLFstToPath:
writeLGFstToPath:
writeOSymsToPath:asText:quasarise:
writeISymsToPath:asText:
writeGFstsToDirectory:
writeLFstToPath:
writeIndividualLGFstsToDirectory:
writeMetadataToPath:
lgFstName
lFstName
osymsName
tokenizer
pmBuilder
_tokenizer
_pmBuilder
T{shared_ptr<quasar::TextTokenizer>=^{TextTokenizer}^{__shared_weak_count}},R,N,V_tokenizer
T{shared_ptr<quasar::PMBuilder>=^{PMBuilder}^{__shared_weak_count}},R,N,V_pmBuilder
copyWithZone:
initWithIdentifier:range:doNotTranslate:
identifier
range
doNotTranslate
_doNotTranslate
_identifier
_range
T@"NSString",R,N,V_identifier
T{_NSRange=QQ},R,N,V_range
TB,R,N,V_doNotTranslate
initWithZipfOfSize:
initWithUnigram:ofSize:
drawNoise
_alias
_unigram
_generator
initWithOrthography:pronunciations:tag:
initWithOrthography:pronunciations:tagName:frequency:
tagName
orthography
frequency
pronunciations
_tagName
_orthography
_tag
_frequency
_pronunciations
T@"NSString",R,N,V_orthography
Tq,R,N,V_tag
T@"NSString",R,N
TQ,R,N,V_frequency
T@"NSSet",R,N,V_pronunciations
initWithContactsCount:bestContactsCount:bestContactsBonus:
contactsCount
bestContactsCount
bestContactsBonus
_contactsCount
_bestContactsCount
_bestContactsBonus
TI,R,N,V_contactsCount
TI,R,N,V_bestContactsCount
TI,R,N,V_bestContactsBonus
initialize
isEasyToRecognizeWord:forLocale:
initWithConfiguration:withLanguage:withSdapiOverrides:withSdapiConfig:
initWithConfiguration:language:sdapiOverrides:generalVoc:emptyVoc:pgVoc:lexiconEnh:tokenEnh:paramsetHolder:
initWithConfiguration:language:overrides:sdapiOverrides:generalVoc:emptyVoc:pgVoc:lexiconEnh:tokenEnh:paramsetHolder:
initWithConfiguration:language:overrides:sdapiOverrides:generalVoc:emptyVoc:pgVoc:lexiconEnh:tokenEnh:paramsetHolder:isJit:
addWordWithParts:templateName:
removeAllWords
removeLmeDataForTemplateName:
userId
setUserId:
templateToVersion
setTemplateToVersion:
_writeProfileToStream:
dataProfile
writeProfileToFile:protectionClass:length:error:
writeProfileToFile:protectionClass:coordinated:length:error:
readUserProfile:reuseProfile:
readUserProfile:
readUserProfileWithPath:reuseProfile:
readUserProfileWithPath:
addPersonalizationData:
addPersonalizationJsonData:
writeOutUserDataToJson:withConfig:
pronunciationsForOrthography:
sanitizedStringWithString:
signalEndOfUserData
createInlineLmeUserDataForContextStrings:
createInlineLmeUserDataForContextData:speechProfile:
peopleSuggesterConfig
_userData
_dataFactory
_g2p
_pronCache
_sanitizer
_personalizationRecipe
_quasarLmeData
_reuseProfile
_outPronCache
_outPronCacheHits
_outPronCacheMisses
_wordsRejected
_wordsAccepted
_quasarTemplate2Count
_unmaskedUserId
_templateToVersion
T@"_EARPeopleSuggesterConfig",R,N
T@"NSString",C,N
T@"NSDictionary",C,N
initWithConfiguration:overrides:
lmeConfig
initWithPath:userId:recognitionOnly:error:
initWithPath:error:
lmeData
maskedUserIdWithMask:
quasarContainerWithUserIdMask:
data
_fstream
_mutex
_lmeData
T@"NSData",R,C,N
T@"NSString",R,C,N
initWithWordCount:trailingSilenceDuration:endOfSentenceLikelihood:pauseCounts:silencePosterior:clientSilenceFramesCountMs:clientSilenceProbability:silencePosteriorNF:serverFeaturesLatency:
initWithWordCount:trailingSilenceDuration:endOfSentenceLikelihood:pauseCounts:silencePosterior:clientSilenceFramesCountMs:clientSilenceProbability:silencePosteriorNF:serverFeaturesLatency:eagerResultEndTime:
description
wordCount
setWordCount:
trailingSilenceDuration
setTrailingSilenceDuration:
endOfSentenceLikelihood
setEndOfSentenceLikelihood:
pauseCounts
setPauseCounts:
silencePosterior
setSilencePosterior:
clientSilenceFramesCountMs
setClientSilenceFramesCountMs:
clientSilenceProbability
setClientSilenceProbability:
silencePosteriorNF
setSilencePosteriorNF:
serverFeaturesLatency
setServerFeaturesLatency:
eagerResultEndTime
setEagerResultEndTime:
_silencePosteriorNF
_serverFeaturesLatency
_wordCount
_trailingSilenceDuration
_endOfSentenceLikelihood
_pauseCounts
_silencePosterior
_clientSilenceFramesCountMs
_clientSilenceProbability
_eagerResultEndTime
Tq,N,V_wordCount
Tq,N,V_trailingSilenceDuration
Td,N,V_endOfSentenceLikelihood
T@"NSArray",C,N,V_pauseCounts
Td,N,V_silencePosterior
Td,N,V_clientSilenceFramesCountMs
Td,N,V_clientSilenceProbability
Tf,N,V_silencePosteriorNF
Tf,N,V_serverFeaturesLatency
Tq,N,V_eagerResultEndTime
initWithWordCount:trailingSilenceDuration:endOfSentenceLikelihood:silencePosterior:
Tf,N,V_endOfSentenceLikelihood
Tf,N,V_silencePosterior
initWithConfiguration:
initWithConfiguration:modelVersion:
initWithConfiguration:delaysTrigger:modelVersion:
requestSupportedWithSamplingRate:
updateEndpointerThresholdWithValue:
updateEndpointerDelayedTriggerSwitch:
didEndpointWithFeatures:audioTimestamp:featuresToLog:endpointPosterior:extraDelayMs:
defaultServerEndpointFeatures
acceptEagerResultWithFeatures:featuresToLog:
_endpointer
hash
isEqual:
initWithTokenName:start:end:silenceStart:confidence:hasSpaceAfter:hasSpaceBefore:phoneSequence:ipaPhoneSequence:
initWithTokenName:start:end:silenceStart:confidence:hasSpaceAfter:hasSpaceBefore:phoneSequence:ipaPhoneSequence:appendedAutoPunctuation:
_initWithQuasarToken:
tokenName
start
silenceStart
confidence
hasSpaceAfter
hasSpaceBefore
phoneSequence
ipaPhoneSequence
appendedAutoPunctuation
prependedAutoPunctuation
isModifiedByAutoPunctuation
quasarToken
_quasarToken
T{Token={basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=*QQ}{__short=[23c]{?=C}}{__raw=[3Q]})}}}IIIfBB{basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=*QQ}{__short=[23c]{?=C}}{__raw=[3Q]})}}}{basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=*QQ}{__short=[23c]{?=C}}{__raw=[3Q]})}}}{vector<std::pair<std::string, float>, std::allocator<std::pair<std::string, float>>>=^v^v{__compressed_pair<std::pair<std::string, float> *, std::allocator<std::pair<std::string, float>>>=^v}}{basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=*QQ}{__short=[23c]{?=C}}{__raw=[3Q]})}}}BB{basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=*QQ}{__short=[23c]{?=C}}{__raw=[3Q]})}}}B},R,N,V_quasarToken
Td,R,N
TB,R,N
_initWithAcousticFeatureValues:frameDuration:
acousticFeatureValuePerFrame
frameDuration
_acousticFeatureValuePerFrame
_frameDuration
T@"NSArray",R,C,N,V_acousticFeatureValuePerFrame
Td,R,N,V_frameDuration
_initWithSpeechRecognitionFeatures:acousticFeatures:snr:
speechRecognitionFeatures
acousticFeatures
_speechRecognitionFeatures
_acousticFeatures
_snr
T@"NSDictionary",R,C,N,V_speechRecognitionFeatures
T@"NSDictionary",R,C,N,V_acousticFeatures
Td,R,N,V_snr
initWithVersion:score:threshold:
version
score
threshold
_score
_threshold
_version
T@"NSString",R,C,N,V_version
Tf,R,N,V_score
Tf,R,N,V_threshold
_initWithTokenSausage:interpretationIndices:
_initWithNBestList:useHatText:
_initWithTokenPhraseChoiceList:
nBest
oneBest
_tokenPhraseChoiceList
granularizedRecognition
tokenSausage
setTokenSausage:
interpretationIndices
_tokenSausage
_interpretationIndices
T@"NSArray",C,N,V_tokenSausage
T@"NSArray",R,C,N,V_interpretationIndices
_initWithRecognition:preITNRecognition:unrepairedRecognition:recognitionIsFormatted:isFinal:
_initWithRecognition:preITNRecognition:unrepairedRecognition:recognitionIsFormatted:isFinal:audioAnalytics:
_initWithRecognition:preITNRecognition:unrepairedRecognition:recognitionIsFormatted:isFinal:audioAnalytics:utteranceStart:
_initWithRecognition:preITNRecognition:unrepairedRecognition:recognitionIsFormatted:isFinal:audioAnalytics:utteranceStart:latticeMitigatorResult:
_initWithRecognition:preITNRecognition:unrepairedRecognition:recognitionIsFormatted:isFinal:audioAnalytics:utteranceStart:latticeMitigatorResult:nBestVoiceCommandInterpretations:preITNNBestVoiceCommandInterpretations:recognitionPaused:
_initWithRecognition:preITNRecognition:unrepairedRecognition:recognitionIsFormatted:isFinal:audioAnalytics:utteranceStart:latticeMitigatorResult:nBestVoiceCommandInterpretations:preITNNBestVoiceCommandInterpretations:recognitionPaused:firstResultAfterResume:
nBestResults
setCorrectPartialResultIndexList:oneBestFinalResult:partialResultIndexOffset:
hasNonEmptyToken
setFirstResultAfterResume:
recognition
preITNRecognition
unrepairedRecognition
recognitionIsFormatted
isFinal
setIsFinal:
audioAnalytics
utteranceStart
latticeMitigatorResult
correctPartialResultIndexList
nBestVoiceCommandInterpretations
preITNNBestVoiceCommandInterpretations
recognitionPaused
firstResultAfterResume
_recognitionIsFormatted
_isFinal
_recognitionPaused
_firstResultAfterResume
_recognition
_preITNRecognition
_unrepairedRecognition
_audioAnalytics
_utteranceStart
_latticeMitigatorResult
_correctPartialResultIndexList
_nBestVoiceCommandInterpretations
_preITNNBestVoiceCommandInterpretations
TB,N,V_isFinal
TB,N,V_firstResultAfterResume
T@"_EARSpeechRecognition",R,C,N,V_recognition
T@"_EARSpeechRecognition",R,C,N,V_preITNRecognition
T@"_EARSpeechRecognition",R,C,N,V_unrepairedRecognition
TB,R,N,V_recognitionIsFormatted
T@"_EARAudioAnalytics",R,C,N,V_audioAnalytics
Td,R,N,V_utteranceStart
T@"_EARLatticeMitigatorResult",R,C,N,V_latticeMitigatorResult
T@"NSArray",R,C,N,V_correctPartialResultIndexList
T@"NSArray",R,C,N,V_nBestVoiceCommandInterpretations
T@"NSArray",R,C,N,V_preITNNBestVoiceCommandInterpretations
TB,R,N,V_recognitionPaused
_initWithTokens:preITNTokens:
_initWithTokens:preITNTokens:confidence:
_initWithTokens:preITNTokens:confidence:voiceCommandInterpretations:preITNVoiceCommandInterpretations:
tokens
preITNTokens
voiceCommandInterpretations
preITNVoiceCommandInterpretations
quasarTokens
quasarPreItnTokens
_confidence
_voiceCommandInterpretations
_preITNVoiceCommandInterpretations
_quasarTokens
_quasarPreItnTokens
T{vector<quasar::Token, std::allocator<quasar::Token>>=^{Token}^{Token}{__compressed_pair<quasar::Token *, std::allocator<quasar::Token>>=^{Token}}},R,N,V_quasarTokens
T{vector<quasar::Token, std::allocator<quasar::Token>>=^{Token}^{Token}{__compressed_pair<quasar::Token *, std::allocator<quasar::Token>>=^{Token}}},R,N,V_quasarPreItnTokens
T@"NSArray",R,C,N
Td,R,N,V_confidence
T@"NSArray",R,C,N,V_voiceCommandInterpretations
T@"NSArray",R,C,N,V_preITNVoiceCommandInterpretations
incrementCountOfIsFinalFalseAlreadyWritten
addPartialResultToContext:
resetPartialResultContext
updateLoggableResultWithCurrentResult:currentCosts:startMilliseconds:
prevBestRecogText
setPrevBestRecogText:
countOfIsFinalFalseAlreadyWritten
setCountOfIsFinalFalseAlreadyWritten:
prevPackage
setPrevPackage:
prevMuxPackages
setPrevMuxPackages:
prevPackageWithoutPersonalization
setPrevPackageWithoutPersonalization:
anyResults
setAnyResults:
continuousListeningResultHelper
setContinuousListeningResultHelper:
partialResults
partialResultIndexOffset
loggableConcatResult
setLoggableConcatResult:
loggableConcatCosts
setLoggableConcatCosts:
_anyResults
_countOfIsFinalFalseAlreadyWritten
_prevPackage
_prevMuxPackages
_prevPackageWithoutPersonalization
_partialResultIndexOffset
_continuousListeningResultHelper
_prevBestRecogText
_partialResults
_loggableConcatResult
_loggableConcatCosts
T{basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=*QQ}{__short=[23c]{?=C}}{__raw=[3Q]})}}},N,V_prevBestRecogText
TQ,N,V_countOfIsFinalFalseAlreadyWritten
T@"_EARSpeechRecognitionResultPackage",&,N,V_prevPackage
T@"NSDictionary",&,N,V_prevMuxPackages
T@"_EARSpeechRecognitionResultPackage",&,N,V_prevPackageWithoutPersonalization
TB,N,V_anyResults
T{shared_ptr<EARContinuousListeningResultHelper>=^{EARContinuousListeningResultHelper}^{__shared_weak_count}},N,V_continuousListeningResultHelper
T{vector<std::vector<quasar::Token>, std::allocator<std::vector<quasar::Token>>>=^v^v{__compressed_pair<std::vector<quasar::Token> *, std::allocator<std::vector<quasar::Token>>>=^v}},R,N,V_partialResults
TQ,R,N,V_partialResultIndexOffset
T{vector<std::vector<quasar::Token>, std::allocator<std::vector<quasar::Token>>>=^v^v{__compressed_pair<std::vector<quasar::Token> *, std::allocator<std::vector<quasar::Token>>>=^v}},N,V_loggableConcatResult
T{vector<double, std::allocator<double>>=^d^d{__compressed_pair<double *, std::allocator<double>>=^d}},N,V_loggableConcatCosts
_initWithDoubleVector:
count
objectAtIndex:
_vec
minimumSupportedConfigurationVersion
maximumSupportedConfigurationVersion
rawTokenResultsFromRecognitionResults:
compileRecognizerModelsWithConfiguration:
purgeCompiledRecognizerModelsWithConfiguration:
initWithConfiguration:overrideConfigFiles:
initWithConfiguration:overrides:overrideConfigFiles:
initWithConfiguration:overrides:overrideConfigFiles:language:
initWithConfiguration:overrides:overrideConfigFiles:language:activeConfiguration:
initWithConfiguration:overrides:overrideConfigFiles:language:activeConfiguration:enableSpeakerCodeTraining:
initWithConfiguration:overrides:overrideConfigFiles:language:activeConfiguration:modelLoadingOptions:enableSpeakerCodeTraining:
initWithConfiguration:overrides:overrideConfigFiles:language:activeConfiguration:modelLoadingOptions:enableSpeakerCodeTraining:supportEmojiRecognition:
initWithConfiguration:overrides:overrideConfigFiles:language:activeConfiguration:modelLoadingOptions:enableSpeakerCodeTraining:supportEmojiRecognition:voiceCommandActiveSet:
initWithConfiguration:overrides:overrideConfigFiles:language:activeConfiguration:modelLoadingOptions:enableSpeakerCodeTraining:supportEmojiRecognition:voiceCommandActiveSet:modelContextDelegate:
initWithConfiguration:withLanguage:withSdapiConfig:
initWithConfiguration:withGeneralVoc:withLexiconEnh:withItnEnh:
initWithConfiguration:overrides:overrideConfigFiles:generalVoc:lexiconEnh:itnEnh:
initWithConfiguration:overrides:generalVoc:lexiconEnh:itnEnh:
initWithConfiguration:overrideConfigFiles:generalVoc:lexiconEnh:itnEnh:
initWithConfiguration:overrides:overrideConfigFiles:generalVoc:lexiconEnh:itnEnh:language:
initWithConfiguration:overrides:overrideConfigFiles:generalVoc:lexiconEnh:itnEnh:language:activeConfiguration:
initWithConfiguration:overrides:overrideConfigFiles:generalVoc:lexiconEnh:itnEnh:language:activeConfiguration:enableSpeakerCodeTraining:
initWithConfiguration:overrides:overrideConfigFiles:generalVoc:lexiconEnh:itnEnh:language:activeConfiguration:modelLoadingOptions:enableSpeakerCodeTraining:
initWithConfiguration:overrides:overrideConfigFiles:generalVoc:lexiconEnh:itnEnh:language:activeConfiguration:modelLoadingOptions:enableSpeakerCodeTraining:supportEmojiRecognition:
initWithConfiguration:overrides:overrideConfigFiles:generalVoc:lexiconEnh:itnEnh:language:activeConfiguration:modelLoadingOptions:enableSpeakerCodeTraining:supportEmojiRecognition:voiceCommandActiveSet:
initWithConfiguration:overrides:overrideConfigFiles:generalVoc:lexiconEnh:itnEnh:language:activeConfiguration:modelLoadingOptions:enableSpeakerCodeTraining:supportEmojiRecognition:voiceCommandActiveSet:modelContextDelegate:
initWithConfiguration:useQuasarFormatter:
initWithConfiguration:useQuasarFormatter:activeConfiguration:
setEnableVoiceCommands:
setHighPriority:
setLeftContextText:
setLeftContext:
setRightContext:
setUserProfileData:
setJitProfileData:
_setProfileContainers:muxIds:
setUserProfile:
_unmaskMuxPackages:
runRecognitionWithResultStream:
updateUserProfileData:
updateJitProfileData:
runRecognitionWithResultStream:language:task:samplingRate:
runRecognitionWithResultStream:speakerCodeWriter:language:task:samplingRate:
runRecognitionWithResultStream:language:task:samplingRate:userProfileData:speakerCodeWriter:
canCloneIsFinalAsLastNonFinal
writeRecordedStateAccesses
_audioBufferWithLangauge:task:samplingRate:userProfileData:resultStream:
_restartActiveRecognition
recognitionResultsWithAudioData:userProfileData:language:task:samplingRate:
recognitionResultsWithAudioData:userProfileData:language:task:samplingRate:extraLanguageModel:
testFormattingWithOneBestResults:uttMillis:
isContinuousListening
itnEnablingFlags
cancelRecognition
_waitForAsyncRecogToFinish
interruptTraining
recognitionStatistics
recognitionUtterenceStatistics
recognitionUtteranceInfos
getFormatterWithBlock:
_waitForInitialization
dumpModelVirtualMemoryInfo
setActiveConfiguration:
isSpeakerCodeTrainingSupported:
activeConfiguration
setAlternateRawRecognitionTokenSausage:
getRecognizer
pauseRecognition
resumeRecognitionWithLeftContext:rightContext:selectedText:
tokenizeTextFromEnd:withLimit:outTokensInVocab:
splitWithTokenizer:outTokensInVocab:
splitWithTokenizer:isLeftContext:shouldTruncate:outTokensInVocab:
userProfileData
jitProfileData
modelInfo
speakerCodeInfo
detectUtterances
setDetectUtterances:
concatenateUtterances
setConcatenateUtterances:
allowUtteranceDelay
setAllowUtteranceDelay:
formatAcrossUtterances
setFormatAcrossUtterances:
endpointStart
setEndpointStart:
recognizeEagerCandidates
setRecognizeEagerCandidates:
farField
setFarField:
highPriority
enableSpeakerCodeTraining
setEnableSpeakerCodeTraining:
maximumRecognitionDuration
setMaximumRecognitionDuration:
recognitionReplacements
setRecognitionReplacements:
recognitionConfidenceSubtraction
setRecognitionConfidenceSubtraction:
leftContext
inputOrigin
setInputOrigin:
deviceId
setDeviceId:
refTranscriptForErrorBlaming
setRefTranscriptForErrorBlaming:
bluetoothDeviceId
setBluetoothDeviceId:
sessionId
setSessionId:
extraLmList
setExtraLmList:
scoreNbestExtraLmList
setScoreNbestExtraLmList:
scoreNbest
setScoreNbest:
latitude
setLatitude:
longitude
setLongitude:
disableAutoPunctuation
setDisableAutoPunctuation:
disablePartialResults
setDisablePartialResults:
enableVoiceCommands
voiceCommandActiveSet
recognizeEmoji
setRecognizeEmoji:
rightContext
selectedText
setSelectedText:
aneContext
setAneContext:
cpuContext
setCpuContext:
gpuContext
setGpuContext:
recognitionMetrics
setRecognitionMetrics:
leftContextForItn
setLeftContextForItn:
configPath
overrideDoServerSideEndpointing
setOverrideDoServerSideEndpointing:
_formatterQueue
_formatter
_trainingQueue
_training
_voiceCommandCompilation
_enableVoiceCommands
_recognizer
_currentAudioBuffer
_currentResultStreamWrapper
_currentLanguage
_currentTask
_currentSamplingRate
_recognitionQueue
_muxIdMask
_muxIdReverseMask
_muxIds
_userProfiles
_rightContextTokens
_modelInitializeContext
_detectUtterances
_concatenateUtterances
_allowUtteranceDelay
_formatAcrossUtterances
_recognizeEagerCandidates
_farField
_highPriority
_enableSpeakerCodeTraining
_scoreNbest
_disableAutoPunctuation
_disablePartialResults
_recognizeEmoji
_userProfileData
_jitProfileData
_modelInfo
_speakerCodeInfo
_endpointStart
_maximumRecognitionDuration
_recognitionReplacements
_recognitionConfidenceSubtraction
_leftContext
_inputOrigin
_deviceId
_refTranscriptForErrorBlaming
_bluetoothDeviceId
_userId
_sessionId
_extraLmList
_scoreNbestExtraLmList
_latitude
_longitude
_voiceCommandActiveSet
_rightContext
_selectedText
_aneContext
_cpuContext
_gpuContext
_recognitionMetrics
_leftContextForItn
_configPath
_overrideDoServerSideEndpointing
T@"NSString",R,N,V_configPath
TS,R,N
T@"NSNumber",&,N,V_overrideDoServerSideEndpointing
T@"NSData",C,N,V_userProfileData
T@"NSData",C,N,V_jitProfileData
T@"_EARSpeechModelInfo",R,N,V_modelInfo
T@"_EARSpeakerCodeInfo",R,N,V_speakerCodeInfo
TB,N,V_detectUtterances
TB,N,V_concatenateUtterances
TB,N,V_allowUtteranceDelay
TB,N,V_formatAcrossUtterances
Td,N,V_endpointStart
TB,N,V_recognizeEagerCandidates
TB,N,V_farField
TB,N,V_highPriority
TB,N,V_enableSpeakerCodeTraining
Td,N,V_maximumRecognitionDuration
T@"NSDictionary",C,N,V_recognitionReplacements
T@"NSDictionary",C,N,V_recognitionConfidenceSubtraction
T@"NSArray",C,N,V_leftContext
T@"NSString",C,N,V_inputOrigin
T@"NSString",C,N,V_deviceId
T@"NSString",C,N,V_refTranscriptForErrorBlaming
T@"NSString",C,N,V_bluetoothDeviceId
T@"NSString",C,N,V_userId
T@"NSString",C,N,V_sessionId
T@"NSArray",C,N,V_extraLmList
T@"NSArray",C,N,V_scoreNbestExtraLmList
TB,N,V_scoreNbest
Td,N,V_latitude
Td,N,V_longitude
TB,N,V_disableAutoPunctuation
TB,N,V_disablePartialResults
TB,N,V_enableVoiceCommands
T@"EARVoiceCommandActiveSet",R,N,V_voiceCommandActiveSet
TB,N,V_recognizeEmoji
T@"NSString",C,N,V_rightContext
T@"NSString",C,N,V_selectedText
T@"NSString",C,N,V_aneContext
T@"NSString",C,N,V_cpuContext
T@"NSString",C,N,V_gpuContext
T@"_EARRecognitionMetrics",C,N,V_recognitionMetrics
T@"NSArray",C,N,V_leftContextForItn
_initWithSpeechModelInfo:
samplingRates
tasks
language
phoneSetVersion
acousticProfileVersion
_speechModelInfo
T@"NSSet",R,N
initWithLanguage:
trainingSpeakerCode
inferenceSpeakerCode
setInferenceSpeakerCode:
accumulatedGradient
numFrames
setNumFrames:
nnetVersion
trainingOffset
recognitionOffset
isSpeakerCodeUsed
setIsSpeakerCodeUsed:
_isSpeakerCodeUsed
_trainingSpeakerCode
_inferenceSpeakerCode
_accumulatedGradient
_numFrames
_nnetVersion
_trainingOffset
_recognitionOffset
T@"NSString",R,N,V_trainingSpeakerCode
T@"NSString",C,N,V_inferenceSpeakerCode
T@"NSString",R,N,V_accumulatedGradient
T@"NSNumber",C,N,V_numFrames
T@"NSNumber",R,N,V_nnetVersion
T@"NSNumber",R,N,V_trainingOffset
T@"NSNumber",R,N,V_recognitionOffset
TB,N,V_isSpeakerCodeUsed
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
superclass
debugDescription
TQ,R
T#,R
T@"NSString",R,C
speechRecognizer:didRecognizePartialResult:
speechRecognizer:didFinishRecognitionWithError:
speechRecognizer:didRecognizeFinalResults:
speechRecognizer:didRecognizeFinalResults:tokenSausage:nBestChoices:
speechRecognizer:didRecognizeFinalResultPackage:
speechRecognizer:didProcessAudioDuration:
speechRecognizer:didRecognizeRawEagerRecognitionCandidate:
speechRecognizer:didProduceEndpointFeaturesWithWordCount:trailingSilenceDuration:eosLikelihood:pauseCounts:silencePosterior:processedAudioDurationInMilliseconds:
speechRecognizer:didRecognizePartialResultNbest:
speechRecognizer:didProduceLoggablePackage:
speechRecognizer:didRecognizeFinalResultCandidatePackage:
initWithTagResults:
waitForCompletion
addPartialFinalTag:result:
error
results
taggedResults
_finishSemaphore
_error
_results
_taggedResults
T@"NSMutableArray",R,N,V_taggedResults
T@"NSError",R,N,V_error
T@"NSArray",R,N,V_results
activeConfigurationForEverything
activeConfigurationForNothing
_initWithActiveConfiguration:
speechRecognizerActiveConfiguration
samplingRateFilter
setSamplingRateFilter:
taskTypeFilter
setTaskTypeFilter:
farFieldFilter
setFarFieldFilter:
deviceIdFilter
setDeviceIdFilter:
bluetoothDeviceIdFilter
setBluetoothDeviceIdFilter:
aneContextFilter
setAneContextFilter:
cpuContextFilter
setCpuContextFilter:
gpuContextFilter
setGpuContextFilter:
_samplingRateFilter
_taskTypeFilter
_farFieldFilter
_deviceIdFilter
_bluetoothDeviceIdFilter
_aneContextFilter
_cpuContextFilter
_gpuContextFilter
T@"NSSet",C,N,V_samplingRateFilter
T@"NSSet",C,N,V_taskTypeFilter
T@"NSSet",C,N,V_farFieldFilter
T@"NSSet",C,N,V_deviceIdFilter
T@"NSSet",C,N,V_bluetoothDeviceIdFilter
T@"NSSet",C,N,V_aneContextFilter
T@"NSSet",C,N,V_cpuContextFilter
T@"NSSet",C,N,V_gpuContextFilter
initWithRecognizer:
addPauseDurationMetric
addEmojiRecognitionMetrics:recognizedEmojis:
pauseDurations
itnDurationInNs
isEmojiPersonalizationUsed
isEmojiDisambiguationUsed
isEmojiExpectedButNotRecognized
recognizedEmojis
_isEmojiPersonalizationUsed
_isEmojiDisambiguationUsed
_isEmojiExpectedButNotRecognized
_pauseDurations
_itnDurationInNs
_recognizedEmojis
T@"NSArray",R,C,N,V_pauseDurations
T@"NSNumber",R,N,V_itnDurationInNs
TB,R,N,V_isEmojiPersonalizationUsed
TB,R,N,V_isEmojiDisambiguationUsed
TB,R,N,V_isEmojiExpectedButNotRecognized
T@"NSArray",R,C,N,V_recognizedEmojis
EnsureSDAPIInitialized
initWithLength:
addWordWithInputId:
sequence
initWithLength:BOS:
resetWithBOS:
target
_sequence
_target
addWordWithInputId:target:mask:
mask
_mask
hatToQsrString:
hatToQsrStrings:
initWithContentsOfUrl:outError:
indexForWord:
vocabSize
endOfSentenceIndex
beginOfSentenceIndex
unknownWordIndex
endOfSentenceToken
_bosIndex
_eosIndex
_unkIndex
_eosToken
_w2i
_initWithAudioBuffer:speechRecognizer:
addAudioSamples:count:
addAudioSampleData:
endAudio
triggerServerSideEndPointer
_setUnderlyingBuffer:
_detachFromRecognizer
bufferedAudioDuration
packetArrivalTimestampFromAudioTime:
_buffer
_queue
_speechRecognizer
_cancelled
_ended
initWithConfiguration:memoryLock:
resetWithSamplingRate:language:taskType:userId:sessionId:deviceId:farField:audioSource:maxAudioBufferSizeSeconds:
getSpeechRecognitionResultFromTokens:taskName:
resultsWithAddedAudio:numberOfSamples:taskName:
resultsWithAddedFloatAudio:numberOfSamples:taskName:
resultsWithEndedAudio
_syncRecognizer
sausage
setSausage:
nBestIndexes
setNBestIndexes:
confidences
setConfidences:
_sausage
_nBestIndexes
_confidences
T@"NSArray",C,N,V_sausage
T@"NSArray",C,N,V_nBestIndexes
T@"NSArray",C,N,V_confidences
nBestStrings
setNBestStrings:
nBestSourceIndexes
setNBestSourceIndexes:
originalRanks
setOriginalRanks:
_nBestStrings
_nBestSourceIndexes
_originalRanks
T@"NSArray",C,N,V_nBestStrings
T@"NSArray",C,N,V_nBestSourceIndexes
T@"NSArray",C,N,V_originalRanks
combinedResultWithSystemResults:
_combiner
initWithVocab:
addText:
textSequence
initWithLength:vocab:BOS:
_text
_vocab
addText:length:
addTokenizedText:length:
shuffleSamples
numberSamples
numberTokens
_numValidTokens
contextFromLDContext:
LDContext
languagePriors
setLanguagePriors:
dictationLanguages
setDictationLanguages:
currentDictationLanguage
setCurrentDictationLanguage:
wasLanguageToggled
setWasLanguageToggled:
multilingualKeyboardLanguages
setMultilingualKeyboardLanguages:
keyboardConvoLanguagePriors
setKeyboardConvoLanguagePriors:
keyboardGlobalLanguagePriors
setKeyboardGlobalLanguagePriors:
previousMessageLanguage
setPreviousMessageLanguage:
globalLastKeyboardUsed
setGlobalLastKeyboardUsed:
dictationLanguagePriors
setDictationLanguagePriors:
recentMessages
setRecentMessages:
_languagePriors
_dictationLanguages
_currentDictationLanguage
_wasLanguageToggled
_multilingualKeyboardLanguages
_keyboardConvoLanguagePriors
_keyboardGlobalLanguagePriors
_previousMessageLanguage
_globalLastKeyboardUsed
_dictationLanguagePriors
_recentMessages
T{LDContext={map<quasar::language_detector::Locale, double, std::less<quasar::language_detector::Locale>, std::allocator<std::pair<const quasar::language_detector::Locale, double>>>={__tree<std::__value_type<quasar::language_detector::Locale, double>, std::__map_value_compare<quasar::language_detector::Locale, std::__value_type<quasar::language_detector::Locale, double>, std::less<quasar::language_detector::Locale>, true>, std::allocator<std::__value_type<quasar::language_detector::Locale, double>>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<quasar::language_detector::Locale, double>, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::__map_value_compare<quasar::language_detector::Locale, std::__value_type<quasar::language_detector::Locale, double>, std::less<quasar::language_detector::Locale>, true>>=Q}}}{optional<std::set<quasar::language_detector::Locale>>=(?=c{set<quasar::language_detector::Locale, std::less<quasar::language_detector::Locale>, std::allocator<quasar::language_detector::Locale>>={__tree<quasar::language_detector::Locale, std::less<quasar::language_detector::Locale>, std::allocator<quasar::language_detector::Locale>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<quasar::language_detector::Locale, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::less<quasar::language_detector::Locale>>=Q}}})B}{optional<quasar::language_detector::Locale>=(?=c{Locale={basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=*QQ}{__short=[23c]{?=C}}{__raw=[3Q]})}}}{basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=*QQ}{__short=[23c]{?=C}}{__raw=[3Q]})}}}})B}{optional<bool>=(?=cB)B}{optional<std::vector<quasar::language_detector::Locale>>=(?=c{vector<quasar::language_detector::Locale, std::allocator<quasar::language_detector::Locale>>=^{Locale}^{Locale}{__compressed_pair<quasar::language_detector::Locale *, std::allocator<quasar::language_detector::Locale>>=^{Locale}}})B}{optional<std::map<quasar::language_detector::Locale, double>>=(?=c{map<quasar::language_detector::Locale, double, std::less<quasar::language_detector::Locale>, std::allocator<std::pair<const quasar::language_detector::Locale, double>>>={__tree<std::__value_type<quasar::language_detector::Locale, double>, std::__map_value_compare<quasar::language_detector::Locale, std::__value_type<quasar::language_detector::Locale, double>, std::less<quasar::language_detector::Locale>, true>, std::allocator<std::__value_type<quasar::language_detector::Locale, double>>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<quasar::language_detector::Locale, double>, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::__map_value_compare<quasar::language_detector::Locale, std::__value_type<quasar::language_detector::Locale, double>, std::less<quasar::language_detector::Locale>, true>>=Q}}})B}{optional<std::map<quasar::language_detector::Locale, double>>=(?=c{map<quasar::language_detector::Locale, double, std::less<quasar::language_detector::Locale>, std::allocator<std::pair<const quasar::language_detector::Locale, double>>>={__tree<std::__value_type<quasar::language_detector::Locale, double>, std::__map_value_compare<quasar::language_detector::Locale, std::__value_type<quasar::language_detector::Locale, double>, std::less<quasar::language_detector::Locale>, true>, std::allocator<std::__value_type<quasar::language_detector::Locale, double>>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<quasar::language_detector::Locale, double>, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::__map_value_compare<quasar::language_detector::Locale, std::__value_type<quasar::language_detector::Locale, double>, std::less<quasar::language_detector::Locale>, true>>=Q}}})B}{optional<quasar::language_detector::Locale>=(?=c{Locale={basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=*QQ}{__short=[23c]{?=C}}{__raw=[3Q]})}}}{basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=*QQ}{__short=[23c]{?=C}}{__raw=[3Q]})}}}})B}{optional<quasar::language_detector::Locale>=(?=c{Locale={basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=*QQ}{__short=[23c]{?=C}}{__raw=[3Q]})}}}{basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=*QQ}{__short=[23c]{?=C}}{__raw=[3Q]})}}}})B}{optional<std::map<quasar::language_detector::Locale, double>>=(?=c{map<quasar::language_detector::Locale, double, std::less<quasar::language_detector::Locale>, std::allocator<std::pair<const quasar::language_detector::Locale, double>>>={__tree<std::__value_type<quasar::language_detector::Locale, double>, std::__map_value_compare<quasar::language_detector::Locale, std::__value_type<quasar::language_detector::Locale, double>, std::less<quasar::language_detector::Locale>, true>, std::allocator<std::__value_type<quasar::language_detector::Locale, double>>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<quasar::language_detector::Locale, double>, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::__map_value_compare<quasar::language_detector::Locale, std::__value_type<quasar::language_detector::Locale, double>, std::less<quasar::language_detector::Locale>, true>>=Q}}})B}},R
T@"NSDictionary",C,N,V_languagePriors
T@"NSSet",C,N,V_dictationLanguages
T@"NSString",C,N,V_currentDictationLanguage
T@"NSNumber",C,N,V_wasLanguageToggled
T@"NSArray",C,N,V_multilingualKeyboardLanguages
T@"NSDictionary",C,N,V_keyboardConvoLanguagePriors
T@"NSDictionary",C,N,V_keyboardGlobalLanguagePriors
T@"NSString",C,N,V_previousMessageLanguage
T@"NSString",C,N,V_globalLastKeyboardUsed
T@"NSDictionary",C,N,V_dictationLanguagePriors
T@"NSArray",C,N,V_recentMessages
initWithNcsRoot:mungeRuleFile:
initWithNcsRoot:mungeRules:
initWithNcsRoot:
initWithMungeRules:
normalize:
tokenize:
munge:
_munger
doBackPropWithNnetModelFile:inputFeatureVector:inputTargetVector:inputLearningRate:inputFreezeComponents:inputNumLocalIterations:inputGradNormFactor:inputGradNormType:inputBatchSize:inputObjectiveFunction:outTrainingLoss:outModelLayersUpdated:
doBackPropWithNnetModelFile:inputFeatureVector:inputTargetVector:inputLearningRate:inputFreezeComponents:inputNumLocalIterations:inputGradNormFactor:inputGradNormType:inputBatchSize:inputObjectiveFunction:outTrainingLosses:outModelLayersUpdated:
initWithToken:pronunciations:
_quasarProns
token
setToken:
setPronunciations:
_token
T@"NSString",C,N,V_token
T@"NSArray",C,N,V_pronunciations
_initWithCorrectedUtterances:
correctedUtterances
_correctedUtterances
T@"NSArray",R,C,N,V_correctedUtterances
correctedResultWithKeyword:tokenizedKeyword:preItnSausage:preItnOneBest:preItnOneBestIndices:nbestSize:
_kwf
initWithFileURL:sampleRate:
enumerateAudioBuffersWithBlock:
_avf_enumerateAudioBuffersWithBlock:
_opx_enumerateAudioBuffersWithBlock:
_opx_enumeratePacketsWithBlock:
_fileURL
_sampleRate
_ear_sha256
addNamedEntity:metadata:
addNamedEntity2:metadata:
iterNamedEntitySourceWithApplication:block:
iterNamedEntitySourceWithApplication:task:block:
iterRankedContactSourceWithApplication:block:
iterRankedContactSourceWithApplication:task:block:
metrics
containsEntity
getWords
getTemplateToAverageCost
getTemplateToDeviationCost
_contextualData
ear_toString
ear_toStringOrNothing
ear_stringWithStringView:
initWithModelURL:
format:preToPostItnMap:
format:
outputLocale
_outputLocale
T@"NSLocale",R,N,V_outputLocale
initWithConfiguration:ncsRoot:recognizerConfiguration:
addDocumentWithUUID:content:
addDocumentWithUUID:content:metadata:
addLineWithType:uuid:content:
addSentenceWithType:uuid:content:hasWeights:
addSentenceWithType:uuid:content:
addNgramCountWithType:content:
setInputFormat:
enumerateSentencesOfType:block:
sources
queryLimit
maxAge
minAge
wordFrequency
roundingEnabled
setRoundingEnabled:
inputType
_roundingEnabled
_inputType
_data
T{shared_ptr<quasar::PersonalizedLmData>=^{PersonalizedLmData}^{__shared_weak_count}},R,N,V_data
TB,N,V_roundingEnabled
Tq,R,N,V_inputType
removeWithDirectory:
_initWithModel:
initWithConfiguration:root:
initFromDirectory:
handle
trainWithData:
trainWithData:shouldStop:
setWeight:
writeToDirectory:
weight
serializedModelWithLanguage:modelData:oovs:
deserializeModelData:
model
buildConfig
_model
_buildConfig
T{shared_ptr<quasar::LmModel2>=^{LmModel2}^{__shared_weak_count}},R,N,V_model
T{shared_ptr<quasar::LmBuildConfig>=^{LmBuildConfig}^{__shared_weak_count}},R,N,V_buildConfig
_initWithHandle:
setProtectionClass:
_initWithModel:config:
generateNgramCounts:
arpaFileName
ngramModel
ngramBuildConfig
_ngramModel
_ngramBuildConfig
T{shared_ptr<quasar::NgramLmModel2>=^{NgramLmModel2}^{__shared_weak_count}},R,N,V_ngramModel
T{shared_ptr<quasar::NgramFstConfig>=^{NgramFstConfig}^{__shared_weak_count}},R,N,V_ngramBuildConfig
buildLmWithConfig:root:data:dir:shouldStop:
loadLmFromDir:
removeLmDir:
generateNgramCountsWithConfig:root:data:
interpolate:configPath:dataRoot:modelRoot:
interpolateArpaFilePaths:configPath:dataRoot:modelRoot:
initWithConfiguration:root:recognizerConfiguration:
initWithConfiguration:recognizerConfiguration:
runEvaluationWithData:handle:result:
runEvaluationWithData:handle:result:bestWeight:
runEvaluationWithData:handle:shouldStop:result:bestWeight:
_evaluator
fetchOrLoadModelWithDirectory:recognizer:
loadForRecognitionWithDirectory:recognizer:task:applicationName:
invalidate
_loader
initWithRoot:
initWithOrthography:prons:frequency:
prons
_prons
T@"NSSet",R,N,V_prons
Tq,R,N,V_frequency
initWithAppLmData:
orderedOovs
initWithConfiguration:ncsRoot:recognizerConfigPath:
addOovTokensFromSentence:
setProns:forWord:pronIsXsampa:
setXsampaProns:forWord:
setAsrProns:forWord:
canAddProns:forWord:pronIsXsampa:
canAddXsampaProns:forWord:
canAddAsrProns:forWord:
generateLmeData:
lmeThreshold
supportedSlots
T{shared_ptr<quasar::AppLmData>=^{AppLmData}^{__shared_weak_count}},R,N,Vdata
T@"NSArray",R,N
getFstGrammar:overrideFolder:weight:errorOut:
_customLMBuilder
psrAudioProcessor:hasSpeakerVector:speakerVectorSize:processedAudioDurationMs:
psrAudioProcessor:hasResult:numElements:
psrAudioProcessor:finishedWithFinalSpeakerVector:speakerVectorSize:processedAudioDurationMs:
dealloc
initWithConfigFile:configRoot:sampleRate:delegate:
initWithConfigFile:configRoot:sampleRate:delegate:queue:
addAudio:
resetForNewRequest
_startComputeTask
configRoot
setConfigRoot:
delegate
setDelegate:
queue
setQueue:
batchSize
setBatchSize:
_audioProcessor
_sysConfig
_configRoot
_delegate
_batchSize
T@"<EARPSRAudioProcessorDelegate>",W,N,V_delegate
T@"NSString",&,N,V_configRoot
T@"NSObject<OS_dispatch_queue>",&,N,V_queue
TQ,N,V_batchSize
initWithStream:
_stream
_initWithAudioBuffer:
initWithText:confidence:precededBySpace:followedBySpace:
initWithText:confidence:score:precededBySpace:followedBySpace:
text
precededBySpace
followedBySpace
_precededBySpace
_followedBySpace
T@"NSString",R,N,V_text
Tf,R,N,V_confidence
TB,R,N,V_precededBySpace
TB,R,N,V_followedBySpace
isValid:
initWithAcceptedContent:acceptedInfo:dependent:
getVersion
getLocale
supportsInfo:
hasInfo:
getInfo:
supportsContent:
hasContent:
getContent:
isMinimalistic
minimize
write:
isEquivalentTo:
_artifact
createEmptyArtifact:version:locale:saveTo:
createPhraseCountsArtifact:version:locale:rawPhraseCountsPath:customPronunciationsPath:saveTo:
transitionArtifactAt:toStage:configPath:ncsRoot:dataRoot:estimationRoot:minimize:
transitionArtifactAt:toStage:configPath:ncsRoot:dataRoot:estimationRoot:minimize:saveTo:
loadLmHandleFromArtifactAt:configPath:ncsRoot:
initWithVersion:andLocale:
initWithPath:
initWithAppLmArtifact:
_tryToLoadCachedLmData:ncsRoot:dataRoot:
_cacheLmData:configFilepath:ncsRoot:dataRoot:
_loadRawAppLmData:ncsRoot:dataRoot:
loadAppLmData:ncsRoot:dataRoot:
loadCustomPronData:ncsRoot:dataRoot:
loadOovs
loadLmHandle
isAdaptableToSpeechModelVersion:locale:
getLifeCycleStage
_cachedLmData
_cachedConfigFilepath
_cachedNcsRoot
_cachedDataRoot
addCustomPronsToUserProfile:artifact:configPath:
formatEmojiStrings:
formatEmojiStrings:isLogging:
_frequentEmojiBaseStrings
didUseEmoji:
resetEmojiPreferences
resetEmojiMetrics
baseStringForEmojiString:
isEmojiRecognitionCapable
isValidEmoji:
searchEmojiAlternativesForSpokenEmoji:count:emojiCharacter:
_preferences
_localeData
_frequentEmojis
_cemlocaleRef
initWithAudioResultMat:vectorSize:numVectors:
audioResultMat
setAudioResultMat:
audioResultsNumVectors
setAudioResultsNumVectors:
audioResultsVectorSize
setAudioResultsVectorSize:
_audioResultMat
_audioResultsNumVectors
_audioResultsVectorSize
T@"NSData",&,N,V_audioResultMat
TQ,N,V_audioResultsNumVectors
TQ,N,V_audioResultsVectorSize
hasEARAudioResultMatrix:
hasEARAudioResultLastVector:
audioResultMatrix
audioResultLastVector
_isAudioSessionLive
_entireResultMatrix
_globalNumVectors
_vectorSize
_sessionFrameCount
T@"<EARAudioResultsGeneratorDelegate>",W,N,V_delegate
supportsSecureCoding
encodeWithCoder:
initWithCoder:
TB,R
initWithSuites:resourceBaseURL:
plistJSONDictionary
initWithPlistJSONDictionary:
suites
resourceBaseURL
_suites
_resourceBaseURL
T@"NSSet",R,C,N,V_suites
T@"NSURL",R,C,N,V_resourceBaseURL
initWithIdentifier:commands:
commandSpecs
_commandSpecs
T@"NSString",R,C,N,V_identifier
T@"NSSet",R,C,N,V_commandSpecs
initWithIdentifier:valence:fstRelativePaths:fstSymbol:
valence
fstRelativePaths
fstSymbol
_valence
_fstRelativePaths
_fstSymbol
Tc,R,N,V_valence
T@"NSSet",R,C,N,V_fstRelativePaths
T@"NSString",R,N,V_fstSymbol
initWithModelURL:task:
initWithModelURL:task:skipNonFinalToCatchup:
initWithModelURL:task:skipNonFinalToCatchup:translatorCacheSize:
initWithModelURLs:task:
initWithModelURLs:task:skipNonFinalToCatchup:
initWithModelURLs:task:skipNonFinalToCatchup:translatorCacheSize:
loadTranslatorFrom:to:
translateSpeech:completion:
translateSpeech:from:to:completion:
translateString:completion:
translateString:from:to:completion:
translateTokens:from:to:completion:
translateTokens:from:to:spans:completion:
translateTokens:isFinal:completion:
translateTokens:isFinal:spans:completion:
prepareFor:to:
_tokenizeString:
_prepareFor:to:
_dispatchTranslationRequest:isFinal:spans:completion:
getTranslatorWithCompletion:
callbackQueue
setCallbackQueue:
_translatorFactory
_translator
_sourceLocale
_targetLocale
_configs
_skipNonFinalToCatchup
_translationRequestsQueue
_translationQueue
_callbackQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_callbackQueue
regionIdForLatitude:longitude:
_geography
initWithCommandIdentifier:suiteIdentifiers:verbIndexes:arguments:
commandIdentifier
suiteIdentifiers
verbIndexes
arguments
_commandIdentifier
_suiteIdentifiers
_verbIndexes
_arguments
T@"NSString",R,C,N,V_commandIdentifier
T@"NSSet",R,C,N,V_suiteIdentifiers
T{_NSRange=QQ},R,N
T@"NSIndexSet",R,C,N,V_verbIndexes
T@"NSArray",R,C,N,V_arguments
initWithPresence:indexes:adpositionIndexes:
presence
indexes
adpositionIndexes
_presence
_indexes
_adpositionIndexes
Tc,R,N,V_presence
T@"NSIndexSet",R,C,N,V_indexes
T@"NSIndexSet",R,C,N,V_adpositionIndexes
addDataSource:weight:
enumerateDataSourcesAndWeightsUsingBlock:
totalWeight
_dataSources
_totalWeight
Tf,R,N,V_totalWeight
initWithModelPath:
encodeUtterance:
_processor
supportedByQuasarConfig:
supportedByQuasarSystemConfig:
convertStringsToQuasarTokens:
convertStringsToQuasarTokens:offset:
initWithLanguage:withSdapiConfig:quasarConfig:
initWithQuasarConfig:
initWithQuasarConfig:overrideConfigFiles:
initWithQuasarConfig:overrideConfigFiles:supportEmojiRecognition:language:
initWithQuasarConfig:overrideConfigFiles:supportEmojiRecognition:language:skipPathsExistCheck:
initWithQuasarConfig:language:
isEnableAutoPunctuation:task:itnEnablingFlags:
initWithGeneralVoc:withLexiconEnh:withItnEnh:
formatWords:unrepairedWordsOut:
formatWords:unrepairedWordsOut:task:
formatWords:unrepairedWordsOut:task:language:preItnLeftContext:separateAutoEndPunctuation:partialResults:timestampOffset:zeroTimestamp:continuousListeningConfig:postItnLeftContext:itnResult:itnOverrides:itnEnablingFlags:recognizeEmoji:leftContextProvidedByClient:preItnRightContext:emojiTokenIndices:persistEmoji:shouldHideTrailingPunctuation:isTrailingPunctuationHidden:isFinal:choiceIdx:itnCompletion:
recognizeEmojiForTokens:recognizeEmoji:emojiTokenIndices:persistEmoji:choiceIdx:
formattedTokensWithoutEmojiModifier:emojiTokenIndices:recognizeEmoji:
appendNbestListWithEmojiAlternativesForFormattedTokens:formattedTokensWithoutEmojiModifier:formattedNBestList:formattedNBestListWithoutEmojiModifier:emojiTokenIndices:recognizeEmoji:
formatWords:task:autoPunctuate:
formatWords:task:autoPunctuate:recognizeEmoji:
refreshEmojiRecognizer
initializeItnMetrics
getOrthography:
formattedStringWithStrings:
formattedStringWithStrings:task:
formattedStringWithStrings:preToPostItnArray:
formattedStringWithStrings:preToPostItnArray:task:
formattedRecognitionWithNBestList:
_formattedStringWithStrings:task:leftContext:
_formattedStringWithStrings:task:leftContext:recognizeEmoji:
_formattedStringWithStrings:task:leftContext:recognizeEmoji:rightContext:
_formattedStringWithoutEmojiModifier:
emojiPhraseRemoveKeyword:
emojiAlternativesForFormattedTokens:stringsWithoutEmojiModifier:alternateNameForTokens:
setLanguage:
_itn
_emojiFormatter
_itnDurationSum
_itnCount
_emojiMetrics
_language
T@"NSString",C,N,V_language
initWithLocale:tokens:confidence:lowConfidence:metaInfo:
locale
lowConfidence
metaInfo
_lowConfidence
_locale
_tokens
_metaInfo
T@"NSLocale",R,N,V_locale
T@"NSArray",R,N,V_tokens
TB,R,N,V_lowConfidence
T@"NSString",R,N,V_metaInfo
initWithConfiguration:ncsRoot:language:
jitProfileFromContextualStrings:
_profileBuilder
initWithCustomPronData:
isValid
validationError
getProns
getRejectedProns
setData:
T{shared_ptr<quasar::CustomPronData>=^{CustomPronData}^{__shared_weak_count}},N,V_data
initWithConfigFile:configRoot:sampleRate:delegate:queue:maxBufferSizeSeconds:
initWithConfigFile:configRoot:sampleRate:delegate:queue:maxBufferSizeSeconds:memoryLock:
getLatestSuperVector
getProcessedAudioDurationMs
_scoreReportTimestamp
_maxBufferSizeSeconds
T@"<EARSyncPSRAudioProcessorDelegate>",W,N,V_delegate
_handle
T{shared_ptr<kaldi::quasar::LmHandle>=^{LmHandle}^{__shared_weak_count}},R,N,V_handle
initWithSilenceFramesCountMs:silenceProbability:silenceDurationMs:silencePosterior:processedAudioMs:
silenceFramesCountMs
setSilenceFramesCountMs:
silenceProbability
setSilenceProbability:
silenceDurationMs
setSilenceDurationMs:
processedAudioMs
setProcessedAudioMs:
_silenceFramesCountMs
_silenceProbability
_silenceDurationMs
_processedAudioMs
Td,N,V_silenceFramesCountMs
Td,N,V_silenceProbability
Td,N,V_silenceDurationMs
Td,N,V_processedAudioMs
silenceDurationEstimateAvailable:numEstimates:clientProcessedAudioMs:
initWithConfigFile:
initWithConfigFile:samplingRate:
initWithConfigFile:samplingRate:queue:
addAudio:numSamples:
getFrameDurationMs
_silenceGenerator
_configFile
_samplingRate
_spgQueue
T@"<EARCaesuraSilencePosteriorGeneratorDelegate>",W,N,V_delegate
getTrainingSpeakerCode:inferenceSpeakerCode:accumulatedGradient:nnetVersion:numFrames:trainingOffset:recognitionOffset:language:
setTrainingSpeakerCode:inferenceSpeakerCode:accumulatedGradient:nnetVersion:numFrames:trainingOffset:recognitionOffset:language:
ipaPhoneSequenceForAsrProns:
nvAsrPhoneSequenceForXsampaProns:
_phoneset
loggingDict
setLoggingDict:
context
setContext:
_loggingDict
_context
T@"NSDictionary",C,N,V_loggingDict
T@"_EARLanguageDetectorRequestContext",C,N,V_context
isConfident
setIsConfident:
_isConfident
T@"NSDictionary",C,N,V_confidences
TB,N,V_isConfident
localesOfMessages:
quasarLocalesOfMessages:
updateContext:withMessageLocales:
initWithConfigFile:overrides:
startRequestWith:context:delegate:
featureQueuePriority
setFeatureQueuePriority:
languageDetector
_featureQueuePriority
TI,N,V_featureQueuePriority
languageDetector:result:
languageDetector:confidences:
_initWithQuasarCommandTagging:
tokensForTag:
commandId
tagSequence
_tagging
_commandId
_tagSequence
T@"NSString",R,C,N,V_commandId
T@"NSArray",R,C,N,V_tagSequence
_initWithCommandTaggings:
commandTaggings
_commandTaggings
T@"NSArray",R,C,N,V_commandTaggings
initWithConfiguration:usage:
commandTaggingFromRecognitionResult:activeCommands:
parameterTagForIndex:
commandPhraseTagForIndex:
isParameterTag:
isCommandPhraseTag:
_tagger
parserDidStartDocument:
parserDidEndDocument:
parser:foundNotationDeclarationWithName:publicID:systemID:
parser:foundUnparsedEntityDeclarationWithName:publicID:systemID:notationName:
parser:foundAttributeDeclarationWithName:forElement:type:defaultValue:
parser:foundElementDeclarationWithName:model:
parser:foundInternalEntityDeclarationWithName:value:
parser:foundExternalEntityDeclarationWithName:publicID:systemID:
parser:didStartElement:namespaceURI:qualifiedName:attributes:
parser:didEndElement:namespaceURI:qualifiedName:
parser:didStartMappingPrefix:toURI:
parser:didEndMappingPrefix:
parser:foundCharacters:
parser:foundIgnorableWhitespace:
parser:foundProcessingInstructionWithTarget:data:
parser:foundComment:
parser:foundCDATA:
parser:resolveExternalEntityName:systemID:
parser:parseErrorOccurred:
parser:validationErrorOccurred:
initWithData:
initWithFilePath:
lexemes
_currentGrapheme
_currentPhonemes
_parser
_elementValue
_lexemes
T@"NSMutableDictionary",R,N,V_lexemes
tokenize:limit:
tokenizerWithNcsRoot:
_nlTagger
sharedProfiler
setMemoryProfiler:
setPerfProfiler:
setPowerProfiler:powerProfilerName:
KeepLogFiles:
addProfilingNetwork:
sample
finishProfilingNetworks
finishProfiling
reportProfilingAsDictionary
reportProfiling
cleanupLogfiles
parsePowerSummary:writeTo:
_memoryProfiler
set_memoryProfiler:
_perfProfiler
set_perfProfiler:
_powerProfiler
set_powerProfiler:
_hasPMP
set_hasPMP:
_keepLogFiles
set_keepLogFiles:
_n_samples
_max_rss
_jetsam_max
_jetsam_tot
_background_power
_networks
_power_summary
_start_time
_end_time
_ane_time
_power_profiler_name
_background_power_logfile_name
_runtime_power_logfile_name
__memoryProfiler
__perfProfiler
__powerProfiler
__hasPMP
__keepLogFiles
TB,V__memoryProfiler
TB,V__perfProfiler
TB,V__powerProfiler
TB,V__hasPMP
TB,V__keepLogFiles
@24@0:8@16
@28@0:8I16@20
v16@0:8
@16@0:8
{HybridClientConfigs="hybridEndpointerThresholds"{map<int, std::map<std::string, double>, std::less<int>, std::allocator<std::pair<const int, std::map<std::string, double>>>>="__tree_"{__tree<std::__value_type<int, std::map<std::string, double>>, std::__map_value_compare<int, std::__value_type<int, std::map<std::string, double>>, std::less<int>, true>, std::allocator<std::__value_type<int, std::map<std::string, double>>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<int, std::map<std::string, double>>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<int, std::__value_type<int, std::map<std::string, double>>, std::less<int>, true>>="__value_"Q}}}"hybridEndpointerExtraDelayFrequency"{map<std::string, int, std::less<std::string>, std::allocator<std::pair<const std::string, int>>>="__tree_"{__tree<std::__value_type<std::string, int>, std::__map_value_compare<std::string, std::__value_type<std::string, int>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, int>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, int>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, int>, std::less<std::string>, true>>="__value_"Q}}}}
i24@0:8q16
@32@0:8q16@24
v24@0:8@16
B28@0:8@16f24
B16@0:8
i16@0:8
{shared_ptr<quasar::DataFeed>=^{DataFeed}^{__shared_weak_count}}16@0:8
{shared_ptr<quasar::DataFeed>="__ptr_"^{DataFeed}"__cntrl_"^{__shared_weak_count}}
B24@0:8@16
@40@0:8@16@24@32
B32@0:8@16B24B28
B28@0:8@16B24
{shared_ptr<quasar::TextTokenizer>=^{TextTokenizer}^{__shared_weak_count}}16@0:8
{shared_ptr<quasar::PMBuilder>=^{PMBuilder}^{__shared_weak_count}}16@0:8
{shared_ptr<quasar::TextTokenizer>="__ptr_"^{TextTokenizer}"__cntrl_"^{__shared_weak_count}}
{shared_ptr<quasar::PMBuilder>="__ptr_"^{PMBuilder}"__cntrl_"^{__shared_weak_count}}
@24@0:8^{_NSZone=}16
@44@0:8@16{_NSRange=QQ}24B40
{_NSRange=QQ}16@0:8
@"NSString"
{_NSRange="location"Q"length"Q}
@24@0:8Q16
@32@0:8^f16Q24
Q16@0:8
{vector<unsigned long, std::allocator<unsigned long>>="__begin_"^Q"__end_"^Q"__end_cap_"{__compressed_pair<unsigned long *, std::allocator<unsigned long>>="__value_"^Q}}
{vector<float, std::allocator<float>>="__begin_"^f"__end_"^f"__end_cap_"{__compressed_pair<float *, std::allocator<float>>="__value_"^f}}
{mersenne_twister_engine<unsigned int, 32UL, 624UL, 397UL, 31UL, 2567483615U, 11UL, 4294967295U, 7UL, 2636928640U, 15UL, 4022730752U, 18UL, 1812433253U>="__x_"[624I]"__i_"Q}
@40@0:8@16@24q32
@48@0:8@16@24@32Q40
q16@0:8
@"NSSet"
@28@0:8I16I20I24
I16@0:8
B32@0:8@16@24
@48@0:8@16@24@32@40
@88@0:8@16@24@32@40@48@56@64@72@80
@96@0:8@16@24@32@40@48@56@64@72@80@88
@100@0:8@16@24@32@40@48@56@64@72@80@88B96
v32@0:8@16@24
B24@0:8^v16
B48@0:8@16q24^Q32^@40
B52@0:8@16q24B32^Q36^@44
v28@0:8@16B24
@32@0:8@16@24
{map<std::string, std::vector<std::vector<quasar::LmeDataFactoryBase::Word>>, std::less<std::string>, std::allocator<std::pair<const std::string, std::vector<std::vector<quasar::LmeDataFactoryBase::Word>>>>>="__tree_"{__tree<std::__value_type<std::string, std::vector<std::vector<quasar::LmeDataFactoryBase::Word>>>, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<std::vector<quasar::LmeDataFactoryBase::Word>>>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::vector<std::vector<quasar::LmeDataFactoryBase::Word>>>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::vector<std::vector<quasar::LmeDataFactoryBase::Word>>>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<std::vector<quasar::LmeDataFactoryBase::Word>>>, std::less<std::string>, true>>="__value_"Q}}}
{shared_ptr<quasar::LmeDataFactory>="__ptr_"^{LmeDataFactory}"__cntrl_"^{__shared_weak_count}}
{unique_ptr<quasar::TextTokenizer, std::default_delete<quasar::TextTokenizer>>="__ptr_"{__compressed_pair<quasar::TextTokenizer *, std::default_delete<quasar::TextTokenizer>>="__value_"^{TextTokenizer}}}
{unique_ptr<quasar::G2P, std::default_delete<quasar::G2P>>="__ptr_"{__compressed_pair<quasar::G2P *, std::default_delete<quasar::G2P>>="__value_"^{G2P}}}
{shared_ptr<quasar::PronCache<std::string, std::vector<std::string>>>="__ptr_"^v"__cntrl_"^{__shared_weak_count}}
{BasicTextSanitizer="_vptr$TextSanitizer"^^?"mUnicodeOutliers"{shared_ptr<quasar::URegularExpressionWrapper>="__ptr_"^{URegularExpressionWrapper}"__cntrl_"^{__shared_weak_count}}"mSpecialChars"{shared_ptr<quasar::URegularExpressionWrapper>="__ptr_"^{URegularExpressionWrapper}"__cntrl_"^{__shared_weak_count}}"mDupSpacePattern"{shared_ptr<quasar::URegularExpressionWrapper>="__ptr_"^{URegularExpressionWrapper}"__cntrl_"^{__shared_weak_count}}"mCtrlCharsPattern"{shared_ptr<quasar::URegularExpressionWrapper>="__ptr_"^{URegularExpressionWrapper}"__cntrl_"^{__shared_weak_count}}"state"i"UTF8_MAP"{unordered_map<std::string, std::string, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<const std::string, std::string>>>="__table_"{__hash_table<std::__hash_value_type<std::string, std::string>, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, std::string>, std::hash<std::string>, std::equal_to<std::string>, true>, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, std::string>, std::equal_to<std::string>, std::hash<std::string>, true>, std::allocator<std::__hash_value_type<std::string, std::string>>>="__bucket_list_"{unique_ptr<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *> *> *[], std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *> *> *>>>="__ptr_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *> *> **, std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *> *> *>>>="__value_"^^v"__value_"{__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *> *> *>>="__data_"{__compressed_pair<unsigned long, std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *> *> *>>="__value_"Q}}}}"__p1_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *> *>, std::allocator<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *>>>="__value_"{__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *> *>="__next_"^v}}"__p2_"{__compressed_pair<unsigned long, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, std::string>, std::hash<std::string>, std::equal_to<std::string>, true>>="__value_"Q}"__p3_"{__compressed_pair<float, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, std::string>, std::equal_to<std::string>, std::hash<std::string>, true>>="__value_"f}}}"unicode_map"{unordered_map<char32_t, char32_t, std::hash<char32_t>, std::equal_to<char32_t>, std::allocator<std::pair<const char32_t, char32_t>>>="__table_"{__hash_table<std::__hash_value_type<char32_t, char32_t>, std::__unordered_map_hasher<char32_t, std::__hash_value_type<char32_t, char32_t>, std::hash<char32_t>, std::equal_to<char32_t>, true>, std::__unordered_map_equal<char32_t, std::__hash_value_type<char32_t, char32_t>, std::equal_to<char32_t>, std::hash<char32_t>, true>, std::allocator<std::__hash_value_type<char32_t, char32_t>>>="__bucket_list_"{unique_ptr<std::__hash_node_base<std::__hash_node<std::__hash_value_type<char32_t, char32_t>, void *> *> *[], std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<char32_t, char32_t>, void *> *> *>>>="__ptr_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<char32_t, char32_t>, void *> *> **, std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<char32_t, char32_t>, void *> *> *>>>="__value_"^^v"__value_"{__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<char32_t, char32_t>, void *> *> *>>="__data_"{__compressed_pair<unsigned long, std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<char32_t, char32_t>, void *> *> *>>="__value_"Q}}}}"__p1_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<char32_t, char32_t>, void *> *>, std::allocator<std::__hash_node<std::__hash_value_type<char32_t, char32_t>, void *>>>="__value_"{__hash_node_base<std::__hash_node<std::__hash_value_type<char32_t, char32_t>, void *> *>="__next_"^v}}"__p2_"{__compressed_pair<unsigned long, std::__unordered_map_hasher<char32_t, std::__hash_value_type<char32_t, char32_t>, std::hash<char32_t>, std::equal_to<char32_t>, true>>="__value_"Q}"__p3_"{__compressed_pair<float, std::__unordered_map_equal<char32_t, std::__hash_value_type<char32_t, char32_t>, std::equal_to<char32_t>, std::hash<char32_t>, true>>="__value_"f}}}}
{unique_ptr<quasar::PersonalizationRecipe, std::default_delete<quasar::PersonalizationRecipe>>="__ptr_"{__compressed_pair<quasar::PersonalizationRecipe *, std::default_delete<quasar::PersonalizationRecipe>>="__value_"^{PersonalizationRecipe}}}
{shared_ptr<quasar::LmeData>="__ptr_"^{LmeData}"__cntrl_"^{__shared_weak_count}}
{unique_ptr<quasar::WordPronCache, std::default_delete<quasar::WordPronCache>>="__ptr_"{__compressed_pair<quasar::WordPronCache *, std::default_delete<quasar::WordPronCache>>="__value_"^{WordPronCache}}}
{unordered_map<std::string, int, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<const std::string, int>>>="__table_"{__hash_table<std::__hash_value_type<std::string, int>, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, int>, std::hash<std::string>, std::equal_to<std::string>, true>, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, int>, std::equal_to<std::string>, std::hash<std::string>, true>, std::allocator<std::__hash_value_type<std::string, int>>>="__bucket_list_"{unique_ptr<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, int>, void *> *> *[], std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, int>, void *> *> *>>>="__ptr_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, int>, void *> *> **, std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, int>, void *> *> *>>>="__value_"^^v"__value_"{__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, int>, void *> *> *>>="__data_"{__compressed_pair<unsigned long, std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, int>, void *> *> *>>="__value_"Q}}}}"__p1_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, int>, void *> *>, std::allocator<std::__hash_node<std::__hash_value_type<std::string, int>, void *>>>="__value_"{__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, int>, void *> *>="__next_"^v}}"__p2_"{__compressed_pair<unsigned long, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, int>, std::hash<std::string>, std::equal_to<std::string>, true>>="__value_"Q}"__p3_"{__compressed_pair<float, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, int>, std::equal_to<std::string>, std::hash<std::string>, true>>="__value_"f}}}
{map<std::string, long long, std::less<std::string>, std::allocator<std::pair<const std::string, long long>>>="__tree_"{__tree<std::__value_type<std::string, long long>, std::__map_value_compare<std::string, std::__value_type<std::string, long long>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, long long>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, long long>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, long long>, std::less<std::string>, true>>="__value_"Q}}}
{unique_ptr<quasar::LmeConfig, std::default_delete<quasar::LmeConfig>>="__ptr_"{__compressed_pair<quasar::LmeConfig *, std::default_delete<quasar::LmeConfig>>="__value_"^{LmeConfig}}}
@44@0:8@16@24B32^@36
@32@0:8@16^@24
{shared_ptr<const quasar::LmeData>=^{LmeData}^{__shared_weak_count}}16@0:8
{shared_ptr<quasar::LmeContainer>=^{LmeContainer}^{__shared_weak_count}}24@0:8@16
{shared_ptr<std::ifstream>="__ptr_"^v"__cntrl_"^{__shared_weak_count}}
{mutex="__m_"{_opaque_pthread_mutex_t="__sig"q"__opaque"[56c]}}
@80@0:8q16q24d32@40d48d56d64f72f76
@88@0:8q16q24d32@40d48d56d64f72f76q80
v24@0:8q16
d16@0:8
v24@0:8d16
f16@0:8
v20@0:8f16
@"NSArray"
@40@0:8q16q24f32f36
@36@0:8@16B24^@28
B24@0:8Q16
v20@0:8B16
B56@0:8@16d24^@32^f40^i48
B32@0:8@16^@24
{unique_ptr<quasar::HybridEndpointer, std::default_delete<quasar::HybridEndpointer>>="__ptr_"{__compressed_pair<quasar::HybridEndpointer *, std::default_delete<quasar::HybridEndpointer>>="__value_"^{HybridEndpointer}}}
@80@0:8@16d24d32d40d48B56B60@64@72
@84@0:8@16d24d32d40d48B56B60@64@72B80
@24@0:8r^v16
{Token={basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=*QQ}{__short=[23c]{?=C}}{__raw=[3Q]})}}}IIIfBB{basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=*QQ}{__short=[23c]{?=C}}{__raw=[3Q]})}}}{basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=*QQ}{__short=[23c]{?=C}}{__raw=[3Q]})}}}{vector<std::pair<std::string, float>, std::allocator<std::pair<std::string, float>>>=^v^v{__compressed_pair<std::pair<std::string, float> *, std::allocator<std::pair<std::string, float>>>=^v}}{basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=*QQ}{__short=[23c]{?=C}}{__raw=[3Q]})}}}BB{basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=*QQ}{__short=[23c]{?=C}}{__raw=[3Q]})}}}B}16@0:8
{Token="tokenName"{basic_string<char, std::char_traits<char>, std::allocator<char>>="__r_"{__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>="__value_"{__rep=""(?="__l"{__long="__data_"*"__size_"Q"__cap_"Q}"__s"{__short="__data_"[23c]""{?="__size_"C}}"__r"{__raw="__words"[3Q]})}}}"startMilliseconds"I"endMilliseconds"I"silStartMilliSeconds"I"confidence"f"hasSpaceAfter"B"hasSpaceBefore"B"phoneSeq"{basic_string<char, std::char_traits<char>, std::allocator<char>>="__r_"{__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>="__value_"{__rep=""(?="__l"{__long="__data_"*"__size_"Q"__cap_"Q}"__s"{__short="__data_"[23c]""{?="__size_"C}}"__r"{__raw="__words"[3Q]})}}}"ipaPhoneSeq"{basic_string<char, std::char_traits<char>, std::allocator<char>>="__r_"{__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>="__value_"{__rep=""(?="__l"{__long="__data_"*"__size_"Q"__cap_"Q}"__s"{__short="__data_"[23c]""{?="__size_"C}}"__r"{__raw="__words"[3Q]})}}}"subwordConfidence"{vector<std::pair<std::string, float>, std::allocator<std::pair<std::string, float>>>="__begin_"^v"__end_"^v"__end_cap_"{__compressed_pair<std::pair<std::string, float> *, std::allocator<std::pair<std::string, float>>>="__value_"^v}}"muxId"{basic_string<char, std::char_traits<char>, std::allocator<char>>="__r_"{__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>="__value_"{__rep=""(?="__l"{__long="__data_"*"__size_"Q"__cap_"Q}"__s"{__short="__data_"[23c]""{?="__size_"C}}"__r"{__raw="__words"[3Q]})}}}"appendedAutoPunctuation"B"prependedAutoPunctuation"B"alternateTokenName"{basic_string<char, std::char_traits<char>, std::allocator<char>>="__r_"{__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>="__value_"{__rep=""(?="__l"{__long="__data_"*"__size_"Q"__cap_"Q}"__s"{__short="__data_"[23c]""{?="__size_"C}}"__r"{__raw="__words"[3Q]})}}}"isModifiedByAutoPunctuation"B}
@28@0:8@16f24
@40@0:8@16@24d32
@"NSDictionary"
@32@0:8@16f24f28
@28@0:8r^v16B24
{pair<std::vector<std::vector<unsigned int>>, std::vector<std::vector<std::vector<quasar::Token>>>>={vector<std::vector<unsigned int>, std::allocator<std::vector<unsigned int>>>=^v^v{__compressed_pair<std::vector<unsigned int> *, std::allocator<std::vector<unsigned int>>>=^v}}{vector<std::vector<std::vector<quasar::Token>>, std::allocator<std::vector<std::vector<quasar::Token>>>>=^v^v{__compressed_pair<std::vector<std::vector<quasar::Token>> *, std::allocator<std::vector<std::vector<quasar::Token>>>>=^v}}}16@0:8
@48@0:8@16@24@32B40B44
@56@0:8@16@24@32B40B44@48
@64@0:8@16@24@32B40B44@48d56
@72@0:8@16@24@32B40B44@48d56@64
@92@0:8@16@24@32B40B44@48d56@64@72@80B88
@96@0:8@16@24@32B40B44@48d56@64@72@80B88B92
v36@0:8r^v16r^v24i32
@"_EARSpeechRecognition"
@"_EARAudioAnalytics"
@"_EARLatticeMitigatorResult"
@64@0:8{vector<quasar::Token, std::allocator<quasar::Token>>=^{Token}^{Token}{__compressed_pair<quasar::Token *, std::allocator<quasar::Token>>=^{Token}}}16{vector<quasar::Token, std::allocator<quasar::Token>>=^{Token}^{Token}{__compressed_pair<quasar::Token *, std::allocator<quasar::Token>>=^{Token}}}40
@72@0:8{vector<quasar::Token, std::allocator<quasar::Token>>=^{Token}^{Token}{__compressed_pair<quasar::Token *, std::allocator<quasar::Token>>=^{Token}}}16{vector<quasar::Token, std::allocator<quasar::Token>>=^{Token}^{Token}{__compressed_pair<quasar::Token *, std::allocator<quasar::Token>>=^{Token}}}40d64
@88@0:8{vector<quasar::Token, std::allocator<quasar::Token>>=^{Token}^{Token}{__compressed_pair<quasar::Token *, std::allocator<quasar::Token>>=^{Token}}}16{vector<quasar::Token, std::allocator<quasar::Token>>=^{Token}^{Token}{__compressed_pair<quasar::Token *, std::allocator<quasar::Token>>=^{Token}}}40d64@72@80
{vector<quasar::Token, std::allocator<quasar::Token>>=^{Token}^{Token}{__compressed_pair<quasar::Token *, std::allocator<quasar::Token>>=^{Token}}}16@0:8
{vector<quasar::Token, std::allocator<quasar::Token>>="__begin_"^{Token}"__end_"^{Token}"__end_cap_"{__compressed_pair<quasar::Token *, std::allocator<quasar::Token>>="__value_"^{Token}}}
v24@0:8r^v16
v36@0:8r^v16r^v24I32
{basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=*QQ}{__short=[23c]{?=C}}{__raw=[3Q]})}}}16@0:8
v40@0:8{basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=*QQ}{__short=[23c]{?=C}}{__raw=[3Q]})}}}16
v24@0:8Q16
{shared_ptr<EARContinuousListeningResultHelper>=^{EARContinuousListeningResultHelper}^{__shared_weak_count}}16@0:8
v32@0:8{shared_ptr<EARContinuousListeningResultHelper>=^{EARContinuousListeningResultHelper}^{__shared_weak_count}}16
{vector<std::vector<quasar::Token>, std::allocator<std::vector<quasar::Token>>>=^v^v{__compressed_pair<std::vector<quasar::Token> *, std::allocator<std::vector<quasar::Token>>>=^v}}16@0:8
v40@0:8{vector<std::vector<quasar::Token>, std::allocator<std::vector<quasar::Token>>>=^v^v{__compressed_pair<std::vector<quasar::Token> *, std::allocator<std::vector<quasar::Token>>>=^v}}16
{vector<double, std::allocator<double>>=^d^d{__compressed_pair<double *, std::allocator<double>>=^d}}16@0:8
v40@0:8{vector<double, std::allocator<double>>=^d^d{__compressed_pair<double *, std::allocator<double>>=^d}}16
@"_EARSpeechRecognitionResultPackage"
{shared_ptr<EARContinuousListeningResultHelper>="__ptr_"^{EARContinuousListeningResultHelper}"__cntrl_"^{__shared_weak_count}}
{basic_string<char, std::char_traits<char>, std::allocator<char>>="__r_"{__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>="__value_"{__rep=""(?="__l"{__long="__data_"*"__size_"Q"__cap_"Q}"__s"{__short="__data_"[23c]""{?="__size_"C}}"__r"{__raw="__words"[3Q]})}}}
{vector<std::vector<quasar::Token>, std::allocator<std::vector<quasar::Token>>>="__begin_"^v"__end_"^v"__end_cap_"{__compressed_pair<std::vector<quasar::Token> *, std::allocator<std::vector<quasar::Token>>>="__value_"^v}}
{vector<double, std::allocator<double>>="__begin_"^d"__end_"^d"__end_cap_"{__compressed_pair<double *, std::allocator<double>>="__value_"^d}}
@56@0:8@16@24@32@40@48
@60@0:8@16@24@32@40@48B56
@68@0:8@16@24@32@40@48@56B64
@72@0:8@16@24@32@40@48@56B64B68
@80@0:8@16@24@32@40@48@56B64B68@72
@88@0:8@16@24@32@40@48@56B64B68@72@80
@64@0:8@16@24@32@40@48@56
@72@0:8@16@24@32@40@48@56@64
@80@0:8@16@24@32@40@48@56@64@72
@84@0:8@16@24@32@40@48@56@64@72B80
@92@0:8@16@24@32@40@48@56@64@72@80B88
@96@0:8@16@24@32@40@48@56@64@72@80B88B92
@104@0:8@16@24@32@40@48@56@64@72@80B88B92@96
@112@0:8@16@24@32@40@48@56@64@72@80B88B92@96@104
@28@0:8@16B24
@36@0:8@16B24@28
@56@0:8@16@24@32@40Q48
@64@0:8@16@24@32Q40@48@56
{shared_ptr<quasar::RecogAudioBufferBase>=^{RecogAudioBufferBase}^{__shared_weak_count}}64@0:8@16@24Q32@40{shared_ptr<quasar::RecogResultStreamBase>=^{RecogResultStreamBase}^{__shared_weak_count}}48
@64@0:8@16@24@32@40Q48@56
S16@0:8
v24@0:8@?16
{shared_ptr<quasar::SpeechRecognizer>=^{SpeechRecognizer}^{__shared_weak_count}}16@0:8
v40@0:8@16@24@32
@40@0:8@16Q24^@32
{vector<std::string, std::allocator<std::string>>=^v^v{__compressed_pair<std::string *, std::allocator<std::string>>=^v}}32@0:8@16^@24
{vector<std::string, std::allocator<std::string>>=^v^v{__compressed_pair<std::string *, std::allocator<std::string>>=^v}}40@0:8@16B24B28^@32
@"NSObject<OS_dispatch_queue>"
@"_EARFormatter"
{shared_ptr<quasar::SpeakerCodeTraining>="__ptr_"^{SpeakerCodeTraining}"__cntrl_"^{__shared_weak_count}}
{shared_ptr<const quasar::VoiceCommandActiveSetCompilation>="__ptr_"^{VoiceCommandActiveSetCompilation}"__cntrl_"^{__shared_weak_count}}
{shared_ptr<quasar::SpeechRecognizer>="__ptr_"^{SpeechRecognizer}"__cntrl_"^{__shared_weak_count}}
@"_EARSpeechRecognitionAudioBuffer"
{weak_ptr<ResultStreamWrapper>="__ptr_"^{ResultStreamWrapper}"__cntrl_"^{__shared_weak_count}}
{vector<std::string, std::allocator<std::string>>="__begin_"^v"__end_"^v"__end_cap_"{__compressed_pair<std::string *, std::allocator<std::string>>="__value_"^v}}
{shared_ptr<EARModelInitializeContext>="__ptr_"^{EARModelInitializeContext}"__cntrl_"^{__shared_weak_count}}
@"_EARTokenizer"
@"NSData"
@"_EARSpeechModelInfo"
@"_EARSpeakerCodeInfo"
@"EARVoiceCommandActiveSet"
@"_EARRecognitionMetrics"
@"NSNumber"
{SpeechModelInfo="version"{basic_string<char, std::char_traits<char>, std::allocator<char>>="__r_"{__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>="__value_"{__rep=""(?="__l"{__long="__data_"*"__size_"Q"__cap_"Q}"__s"{__short="__data_"[23c]""{?="__size_"C}}"__r"{__raw="__words"[3Q]})}}}"samplingRates"{set<int, std::less<int>, std::allocator<int>>="__tree_"{__tree<int, std::less<int>, std::allocator<int>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<int, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::less<int>>="__value_"Q}}}"tasks"{set<std::string, std::less<std::string>, std::allocator<std::string>>="__tree_"{__tree<std::string, std::less<std::string>, std::allocator<std::string>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::string, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::less<std::string>>="__value_"Q}}}"osTypes"{set<std::string, std::less<std::string>, std::allocator<std::string>>="__tree_"{__tree<std::string, std::less<std::string>, std::allocator<std::string>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::string, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::less<std::string>>="__value_"Q}}}"language"{basic_string<char, std::char_traits<char>, std::allocator<char>>="__r_"{__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>="__value_"{__rep=""(?="__l"{__long="__data_"*"__size_"Q"__cap_"Q}"__s"{__short="__data_"[23c]""{?="__size_"C}}"__r"{__raw="__words"[3Q]})}}}"phoneSetVersion"{basic_string<char, std::char_traits<char>, std::allocator<char>>="__r_"{__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>="__value_"{__rep=""(?="__l"{__long="__data_"*"__size_"Q"__cap_"Q}"__s"{__short="__data_"[23c]""{?="__size_"C}}"__r"{__raw="__words"[3Q]})}}}"acousticProfileVersion"{basic_string<char, std::char_traits<char>, std::allocator<char>>="__r_"{__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>="__value_"{__rep=""(?="__l"{__long="__data_"*"__size_"Q"__cap_"Q}"__s"{__short="__data_"[23c]""{?="__size_"C}}"__r"{__raw="__words"[3Q]})}}}"aceToQuasarTemplate"{map<std::string, std::string, std::less<std::string>, std::allocator<std::pair<const std::string, std::string>>>="__tree_"{__tree<std::__value_type<std::string, std::string>, std::__map_value_compare<std::string, std::__value_type<std::string, std::string>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::string>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::string>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::string>, std::less<std::string>, true>>="__value_"Q}}}"quasarTemplateToAce"{map<std::string, std::vector<std::string>, std::less<std::string>, std::allocator<std::pair<const std::string, std::vector<std::string>>>>="__tree_"{__tree<std::__value_type<std::string, std::vector<std::string>>, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<std::string>>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::vector<std::string>>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::vector<std::string>>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<std::string>>, std::less<std::string>, true>>="__value_"Q}}}"quasarTemplateToEnumerationType"{map<std::string, std::string, std::less<std::string>, std::allocator<std::pair<const std::string, std::string>>>="__tree_"{__tree<std::__value_type<std::string, std::string>, std::__map_value_compare<std::string, std::__value_type<std::string, std::string>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::string>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::string>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::string>, std::less<std::string>, true>>="__value_"Q}}}"g2pModelVersion"i"hybridEndpointerVersion"i}
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
v48@0:8@16@24@32@40
v32@0:8@16d24
v72@0:8@16q24q32d40@48d56q64
v32@0:8@"_EARSpeechRecognizer"16@"_EARSpeechRecognitionResult"24
v32@0:8@"_EARSpeechRecognizer"16@"NSError"24
v32@0:8@"_EARSpeechRecognizer"16@"NSArray"24
v48@0:8@"_EARSpeechRecognizer"16@"NSArray"24@"NSArray"32@"NSArray"40
v32@0:8@"_EARSpeechRecognizer"16@"_EARSpeechRecognitionResultPackage"24
v32@0:8@"_EARSpeechRecognizer"16d24
v32@0:8@"_EARSpeechRecognizer"16@"_EARSpeechRecognition"24
v72@0:8@"_EARSpeechRecognizer"16q24q32d40@"NSArray"48d56q64
@20@0:8B16
@48@0:8{basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=*QQ}{__short=[23c]{?=C}}{__raw=[3Q]})}}}16@40
@"NSObject<OS_dispatch_semaphore>"
@"NSError"
@"NSMutableArray"
{SpeechRecognizerActiveConfiguration={optional<std::set<unsigned int>>=(?=c{set<unsigned int, std::less<unsigned int>, std::allocator<unsigned int>>={__tree<unsigned int, std::less<unsigned int>, std::allocator<unsigned int>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<unsigned int, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::less<unsigned int>>=Q}}})B}{optional<std::set<std::string>>=(?=c{set<std::string, std::less<std::string>, std::allocator<std::string>>={__tree<std::string, std::less<std::string>, std::allocator<std::string>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::string, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::less<std::string>>=Q}}})B}{optional<std::set<std::string>>=(?=c{set<std::string, std::less<std::string>, std::allocator<std::string>>={__tree<std::string, std::less<std::string>, std::allocator<std::string>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::string, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::less<std::string>>=Q}}})B}{optional<std::set<bool>>=(?=c{set<bool, std::less<bool>, std::allocator<bool>>={__tree<bool, std::less<bool>, std::allocator<bool>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<bool, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::less<bool>>=Q}}})B}{optional<std::set<std::string>>=(?=c{set<std::string, std::less<std::string>, std::allocator<std::string>>={__tree<std::string, std::less<std::string>, std::allocator<std::string>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::string, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::less<std::string>>=Q}}})B}{optional<std::set<std::string>>=(?=c{set<std::string, std::less<std::string>, std::allocator<std::string>>={__tree<std::string, std::less<std::string>, std::allocator<std::string>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::string, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::less<std::string>>=Q}}})B}{optional<std::set<std::string>>=(?=c{set<std::string, std::less<std::string>, std::allocator<std::string>>={__tree<std::string, std::less<std::string>, std::allocator<std::string>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::string, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::less<std::string>>=Q}}})B}{optional<std::set<std::string>>=(?=c{set<std::string, std::less<std::string>, std::allocator<std::string>>={__tree<std::string, std::less<std::string>, std::allocator<std::string>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::string, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::less<std::string>>=Q}}})B}}16@0:8
@32@0:8{shared_ptr<quasar::SpeechRecognizer>=^{SpeechRecognizer}^{__shared_weak_count}}16
{weak_ptr<quasar::SpeechRecognizer>="__ptr_"^{SpeechRecognizer}"__cntrl_"^{__shared_weak_count}}
@"NSArray"16@0:8
@32@0:8Q16Q24
v40@0:8Q16Q24Q32
Q24@0:8@16
{unordered_map<std::string, unsigned long, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<const std::string, unsigned long>>>="__table_"{__hash_table<std::__hash_value_type<std::string, unsigned long>, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, unsigned long>, std::hash<std::string>, std::equal_to<std::string>, true>, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, unsigned long>, std::equal_to<std::string>, std::hash<std::string>, true>, std::allocator<std::__hash_value_type<std::string, unsigned long>>>="__bucket_list_"{unique_ptr<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, unsigned long>, void *> *> *[], std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, unsigned long>, void *> *> *>>>="__ptr_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, unsigned long>, void *> *> **, std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, unsigned long>, void *> *> *>>>="__value_"^^v"__value_"{__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, unsigned long>, void *> *> *>>="__data_"{__compressed_pair<unsigned long, std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, unsigned long>, void *> *> *>>="__value_"Q}}}}"__p1_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, unsigned long>, void *> *>, std::allocator<std::__hash_node<std::__hash_value_type<std::string, unsigned long>, void *>>>="__value_"{__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, unsigned long>, void *> *>="__next_"^v}}"__p2_"{__compressed_pair<unsigned long, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, unsigned long>, std::hash<std::string>, std::equal_to<std::string>, true>>="__value_"Q}"__p3_"{__compressed_pair<float, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, unsigned long>, std::equal_to<std::string>, std::hash<std::string>, true>>="__value_"f}}}
@40@0:8{shared_ptr<quasar::RecogAudioBufferBase>=^{RecogAudioBufferBase}^{__shared_weak_count}}16@32
v32@0:8r^s16Q24
v32@0:8{shared_ptr<quasar::RecogAudioBufferBase>=^{RecogAudioBufferBase}^{__shared_weak_count}}16
Q20@0:8f16
{shared_ptr<quasar::RecogAudioBufferBase>="__ptr_"^{RecogAudioBufferBase}"__cntrl_"^{__shared_weak_count}}
@"_EARSpeechRecognizer"
v76@0:8I16@20@28@36@44@52B60@64I72
@48@0:8{vector<std::vector<quasar::Token>, std::allocator<std::vector<quasar::Token>>>=^v^v{__compressed_pair<std::vector<quasar::Token> *, std::allocator<std::vector<quasar::Token>>>=^v}}16@40
@40@0:8@16Q24@32
{shared_ptr<quasar::SyncSpeechRecognizer>="__ptr_"^{SyncSpeechRecognizer}"__cntrl_"^{__shared_weak_count}}
{unique_ptr<quasar::ResultCombiner, std::default_delete<quasar::ResultCombiner>>="__ptr_"{__compressed_pair<quasar::ResultCombiner *, std::default_delete<quasar::ResultCombiner>>="__value_"^{ResultCombiner}}}
@24@0:8@"_EARLMTKaldiVocab"16
v24@0:8@"NSString"16
@40@0:8Q16@24Q32
@"_EARLMTKaldiVocab"
v32@0:8@16Q24
{LDContext={map<quasar::language_detector::Locale, double, std::less<quasar::language_detector::Locale>, std::allocator<std::pair<const quasar::language_detector::Locale, double>>>={__tree<std::__value_type<quasar::language_detector::Locale, double>, std::__map_value_compare<quasar::language_detector::Locale, std::__value_type<quasar::language_detector::Locale, double>, std::less<quasar::language_detector::Locale>, true>, std::allocator<std::__value_type<quasar::language_detector::Locale, double>>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<quasar::language_detector::Locale, double>, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::__map_value_compare<quasar::language_detector::Locale, std::__value_type<quasar::language_detector::Locale, double>, std::less<quasar::language_detector::Locale>, true>>=Q}}}{optional<std::set<quasar::language_detector::Locale>>=(?=c{set<quasar::language_detector::Locale, std::less<quasar::language_detector::Locale>, std::allocator<quasar::language_detector::Locale>>={__tree<quasar::language_detector::Locale, std::less<quasar::language_detector::Locale>, std::allocator<quasar::language_detector::Locale>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<quasar::language_detector::Locale, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::less<quasar::language_detector::Locale>>=Q}}})B}{optional<quasar::language_detector::Locale>=(?=c{Locale={basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=*QQ}{__short=[23c]{?=C}}{__raw=[3Q]})}}}{basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=*QQ}{__short=[23c]{?=C}}{__raw=[3Q]})}}}})B}{optional<bool>=(?=cB)B}{optional<std::vector<quasar::language_detector::Locale>>=(?=c{vector<quasar::language_detector::Locale, std::allocator<quasar::language_detector::Locale>>=^{Locale}^{Locale}{__compressed_pair<quasar::language_detector::Locale *, std::allocator<quasar::language_detector::Locale>>=^{Locale}}})B}{optional<std::map<quasar::language_detector::Locale, double>>=(?=c{map<quasar::language_detector::Locale, double, std::less<quasar::language_detector::Locale>, std::allocator<std::pair<const quasar::language_detector::Locale, double>>>={__tree<std::__value_type<quasar::language_detector::Locale, double>, std::__map_value_compare<quasar::language_detector::Locale, std::__value_type<quasar::language_detector::Locale, double>, std::less<quasar::language_detector::Locale>, true>, std::allocator<std::__value_type<quasar::language_detector::Locale, double>>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<quasar::language_detector::Locale, double>, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::__map_value_compare<quasar::language_detector::Locale, std::__value_type<quasar::language_detector::Locale, double>, std::less<quasar::language_detector::Locale>, true>>=Q}}})B}{optional<std::map<quasar::language_detector::Locale, double>>=(?=c{map<quasar::language_detector::Locale, double, std::less<quasar::language_detector::Locale>, std::allocator<std::pair<const quasar::language_detector::Locale, double>>>={__tree<std::__value_type<quasar::language_detector::Locale, double>, std::__map_value_compare<quasar::language_detector::Locale, std::__value_type<quasar::language_detector::Locale, double>, std::less<quasar::language_detector::Locale>, true>, std::allocator<std::__value_type<quasar::language_detector::Locale, double>>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<quasar::language_detector::Locale, double>, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::__map_value_compare<quasar::language_detector::Locale, std::__value_type<quasar::language_detector::Locale, double>, std::less<quasar::language_detector::Locale>, true>>=Q}}})B}{optional<quasar::language_detector::Locale>=(?=c{Locale={basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=*QQ}{__short=[23c]{?=C}}{__raw=[3Q]})}}}{basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=*QQ}{__short=[23c]{?=C}}{__raw=[3Q]})}}}})B}{optional<quasar::language_detector::Locale>=(?=c{Locale={basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=*QQ}{__short=[23c]{?=C}}{__raw=[3Q]})}}}{basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=*QQ}{__short=[23c]{?=C}}{__raw=[3Q]})}}}})B}{optional<std::map<quasar::language_detector::Locale, double>>=(?=c{map<quasar::language_detector::Locale, double, std::less<quasar::language_detector::Locale>, std::allocator<std::pair<const quasar::language_detector::Locale, double>>>={__tree<std::__value_type<quasar::language_detector::Locale, double>, std::__map_value_compare<quasar::language_detector::Locale, std::__value_type<quasar::language_detector::Locale, double>, std::less<quasar::language_detector::Locale>, true>, std::allocator<std::__value_type<quasar::language_detector::Locale, double>>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<quasar::language_detector::Locale, double>, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::__map_value_compare<quasar::language_detector::Locale, std::__value_type<quasar::language_detector::Locale, double>, std::less<quasar::language_detector::Locale>, true>>=Q}}})B}}16@0:8
{unique_ptr<quasar::Munger, std::default_delete<quasar::Munger>>="__ptr_"{__compressed_pair<quasar::Munger *, std::default_delete<quasar::Munger>>="__value_"^{Munger}}}
@96@0:8@16@24@32f40@44i52f56@60f68@72^f80^@88
@96@0:8@16@24@32f40@44i52f56@60f68@72^@80^@88
{TokenProns={basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=*QQ}{__short=[23c]{?=C}}{__raw=[3Q]})}}}{vector<quasar::PronChoice, std::allocator<quasar::PronChoice>>=^{PronChoice}^{PronChoice}{__compressed_pair<quasar::PronChoice *, std::allocator<quasar::PronChoice>>=^{PronChoice}}}{vector<quasar::PronChoice, std::allocator<quasar::PronChoice>>=^{PronChoice}^{PronChoice}{__compressed_pair<quasar::PronChoice *, std::allocator<quasar::PronChoice>>=^{PronChoice}}}}16@0:8
@64@0:8@16@24@32@40@48q56
{unique_ptr<quasar::KeywordFinder, std::default_delete<quasar::KeywordFinder>>="__ptr_"{__compressed_pair<quasar::KeywordFinder *, std::default_delete<quasar::KeywordFinder>>="__value_"^{KeywordFinder}}}
@32@0:8@16Q24
@24@0:8@?16
@"NSURL"
v32@0:8@16@?24
v40@0:8@16@24@?32
{map<std::string, std::vector<std::vector<quasar::LmeDataFactoryBase::Word>>, std::less<std::string>, std::allocator<std::pair<const std::string, std::vector<std::vector<quasar::LmeDataFactoryBase::Word>>>>>={__tree<std::__value_type<std::string, std::vector<std::vector<quasar::LmeDataFactoryBase::Word>>>, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<std::vector<quasar::LmeDataFactoryBase::Word>>>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::vector<std::vector<quasar::LmeDataFactoryBase::Word>>>>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::vector<std::vector<quasar::LmeDataFactoryBase::Word>>>, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<std::vector<quasar::LmeDataFactoryBase::Word>>>, std::less<std::string>, true>>=Q}}}16@0:8
{unordered_map<std::string, double, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<const std::string, double>>>={__hash_table<std::__hash_value_type<std::string, double>, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, double>, std::hash<std::string>, std::equal_to<std::string>, true>, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, double>, std::equal_to<std::string>, std::hash<std::string>, true>, std::allocator<std::__hash_value_type<std::string, double>>>={unique_ptr<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, double>, void *> *> *[], std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, double>, void *> *> *>>>={__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, double>, void *> *> **, std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, double>, void *> *> *>>>=^^v{__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, double>, void *> *> *>>={__compressed_pair<unsigned long, std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, double>, void *> *> *>>=Q}}}}{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, double>, void *> *>, std::allocator<std::__hash_node<std::__hash_value_type<std::string, double>, void *>>>={__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, double>, void *> *>=^v}}{__compressed_pair<unsigned long, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, double>, std::hash<std::string>, std::equal_to<std::string>, true>>=Q}{__compressed_pair<float, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, double>, std::equal_to<std::string>, std::hash<std::string>, true>>=f}}}16@0:8
{shared_ptr<quasar::ContextualData>="__ptr_"^{ContextualData}"__cntrl_"^{__shared_weak_count}}
{optional<std::string>=(?=c{basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=*QQ}{__short=[23c]{?=C}}{__raw=[3Q]})}}})B}16@0:8
@32@0:8{basic_string_view<char, std::char_traits<char>>=*Q}16
@"NSLocale"
v40@0:8Q16@24@32
v44@0:8Q16@24@32B40
v32@0:8Q16@24
v32@0:8Q16@?24
{shared_ptr<quasar::PersonalizedLmData>=^{PersonalizedLmData}^{__shared_weak_count}}16@0:8
{shared_ptr<quasar::PersonalizedLmData>="__ptr_"^{PersonalizedLmData}"__cntrl_"^{__shared_weak_count}}
@32@0:8{shared_ptr<quasar::LmModel2>=^{LmModel2}^{__shared_weak_count}}16
B32@0:8@16@?24
{shared_ptr<quasar::LmModel2>=^{LmModel2}^{__shared_weak_count}}16@0:8
{shared_ptr<quasar::LmBuildConfig>=^{LmBuildConfig}^{__shared_weak_count}}16@0:8
{shared_ptr<quasar::LmModel2>="__ptr_"^{LmModel2}"__cntrl_"^{__shared_weak_count}}
{shared_ptr<quasar::LmBuildConfig>="__ptr_"^{LmBuildConfig}"__cntrl_"^{__shared_weak_count}}
@48@0:8{shared_ptr<quasar::NgramLmModel2>=^{NgramLmModel2}^{__shared_weak_count}}16{shared_ptr<quasar::NgramFstConfig>=^{NgramFstConfig}^{__shared_weak_count}}32
{shared_ptr<quasar::NgramLmModel2>=^{NgramLmModel2}^{__shared_weak_count}}16@0:8
{shared_ptr<quasar::NgramFstConfig>=^{NgramFstConfig}^{__shared_weak_count}}16@0:8
{shared_ptr<quasar::NgramLmModel2>="__ptr_"^{NgramLmModel2}"__cntrl_"^{__shared_weak_count}}
{shared_ptr<quasar::NgramFstConfig>="__ptr_"^{NgramFstConfig}"__cntrl_"^{__shared_weak_count}}
@32@0:8{shared_ptr<quasar::NgramLmModel2>=^{NgramLmModel2}^{__shared_weak_count}}16
@56@0:8@16@24@32@40@?48
B40@0:8@16@24^@32
B48@0:8@16@24^@32^f40
B56@0:8@16@24@?32^@40^f48
{shared_ptr<quasar::LmEvaluator>="__ptr_"^{LmEvaluator}"__cntrl_"^{__shared_weak_count}}
{shared_ptr<quasar::LmLoader2>="__ptr_"^{LmLoader2}"__cntrl_"^{__shared_weak_count}}
@32@0:8{shared_ptr<quasar::AppLmData>=^{AppLmData}^{__shared_weak_count}}16
B36@0:8@16@24B32
q36@0:8@16@24B32
q32@0:8@16@24
{shared_ptr<quasar::AppLmData>=^{AppLmData}^{__shared_weak_count}}16@0:8
{shared_ptr<quasar::AppLmData>="__ptr_"^{AppLmData}"__cntrl_"^{__shared_weak_count}}
B44@0:8@16@24f32^@36
{unique_ptr<quasar::CustomLMBuilder, std::default_delete<quasar::CustomLMBuilder>>="__ptr_"{__compressed_pair<quasar::CustomLMBuilder *, std::default_delete<quasar::CustomLMBuilder>>="__value_"^{CustomLMBuilder}}}
{unique_ptr<sdapi::SdapiTokenizer, std::default_delete<sdapi::SdapiTokenizer>>="__ptr_"{__compressed_pair<sdapi::SdapiTokenizer *, std::default_delete<sdapi::SdapiTokenizer>>="__value_"^{SdapiTokenizer}}}
@48@0:8@16@24Q32@40
@56@0:8@16@24Q32@40@48
{shared_ptr<quasar::PSRAudioProcessor>="__ptr_"^{PSRAudioProcessor}"__cntrl_"^{__shared_weak_count}}
{SystemConfig="_vptr$OptionsItf"^^?"info"{SystemConfigInfo="jsonConfigFilePath"{basic_string<char, std::char_traits<char>, std::allocator<char>>="__r_"{__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>="__value_"{__rep=""(?="__l"{__long="__data_"*"__size_"Q"__cap_"Q}"__s"{__short="__data_"[23c]""{?="__size_"C}}"__r"{__raw="__words"[3Q]})}}}"configFileVersion"{Version="versionMajor"i"versionMinor"i}"configPath"{Path="_vptr$Path"^^?"str"{basic_string<char, std::char_traits<char>, std::allocator<char>>="__r_"{__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>="__value_"{__rep=""(?="__l"{__long="__data_"*"__size_"Q"__cap_"Q}"__s"{__short="__data_"[23c]""{?="__size_"C}}"__r"{__raw="__words"[3Q]})}}}}"pTree"{PTree="dataType"i"dataValue"{basic_string<char, std::char_traits<char>, std::allocator<char>>="__r_"{__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>="__value_"{__rep=""(?="__l"{__long="__data_"*"__size_"Q"__cap_"Q}"__s"{__short="__data_"[23c]""{?="__size_"C}}"__r"{__raw="__words"[3Q]})}}}"map"{vector<std::pair<std::string, quasar::PTree>, std::allocator<std::pair<std::string, quasar::PTree>>>="__begin_"^v"__end_"^v"__end_cap_"{__compressed_pair<std::pair<std::string, quasar::PTree> *, std::allocator<std::pair<std::string, quasar::PTree>>>="__value_"^v}}"isALeaf"B}"speechModelInfo"{SpeechModelInfo="version"{basic_string<char, std::char_traits<char>, std::allocator<char>>="__r_"{__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>="__value_"{__rep=""(?="__l"{__long="__data_"*"__size_"Q"__cap_"Q}"__s"{__short="__data_"[23c]""{?="__size_"C}}"__r"{__raw="__words"[3Q]})}}}"samplingRates"{set<int, std::less<int>, std::allocator<int>>="__tree_"{__tree<int, std::less<int>, std::allocator<int>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<int, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::less<int>>="__value_"Q}}}"tasks"{set<std::string, std::less<std::string>, std::allocator<std::string>>="__tree_"{__tree<std::string, std::less<std::string>, std::allocator<std::string>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::string, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::less<std::string>>="__value_"Q}}}"osTypes"{set<std::string, std::less<std::string>, std::allocator<std::string>>="__tree_"{__tree<std::string, std::less<std::string>, std::allocator<std::string>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::string, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::less<std::string>>="__value_"Q}}}"language"{basic_string<char, std::char_traits<char>, std::allocator<char>>="__r_"{__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>="__value_"{__rep=""(?="__l"{__long="__data_"*"__size_"Q"__cap_"Q}"__s"{__short="__data_"[23c]""{?="__size_"C}}"__r"{__raw="__words"[3Q]})}}}"phoneSetVersion"{basic_string<char, std::char_traits<char>, std::allocator<char>>="__r_"{__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>="__value_"{__rep=""(?="__l"{__long="__data_"*"__size_"Q"__cap_"Q}"__s"{__short="__data_"[23c]""{?="__size_"C}}"__r"{__raw="__words"[3Q]})}}}"acousticProfileVersion"{basic_string<char, std::char_traits<char>, std::allocator<char>>="__r_"{__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>="__value_"{__rep=""(?="__l"{__long="__data_"*"__size_"Q"__cap_"Q}"__s"{__short="__data_"[23c]""{?="__size_"C}}"__r"{__raw="__words"[3Q]})}}}"aceToQuasarTemplate"{map<std::string, std::string, std::less<std::string>, std::allocator<std::pair<const std::string, std::string>>>="__tree_"{__tree<std::__value_type<std::string, std::string>, std::__map_value_compare<std::string, std::__value_type<std::string, std::string>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::string>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::string>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::string>, std::less<std::string>, true>>="__value_"Q}}}"quasarTemplateToAce"{map<std::string, std::vector<std::string>, std::less<std::string>, std::allocator<std::pair<const std::string, std::vector<std::string>>>>="__tree_"{__tree<std::__value_type<std::string, std::vector<std::string>>, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<std::string>>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::vector<std::string>>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::vector<std::string>>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<std::string>>, std::less<std::string>, true>>="__value_"Q}}}"quasarTemplateToEnumerationType"{map<std::string, std::string, std::less<std::string>, std::allocator<std::pair<const std::string, std::string>>>="__tree_"{__tree<std::__value_type<std::string, std::string>, std::__map_value_compare<std::string, std::__value_type<std::string, std::string>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::string>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::string>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::string>, std::less<std::string>, true>>="__value_"Q}}}"g2pModelVersion"i"hybridEndpointerVersion"i}"translationModelInfo"{TranslationModelInfo="version"{basic_string<char, std::char_traits<char>, std::allocator<char>>="__r_"{__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>="__value_"{__rep=""(?="__l"{__long="__data_"*"__size_"Q"__cap_"Q}"__s"{__short="__data_"[23c]""{?="__size_"C}}"__r"{__raw="__words"[3Q]})}}}"tasks"{set<std::string, std::less<std::string>, std::allocator<std::string>>="__tree_"{__tree<std::string, std::less<std::string>, std::allocator<std::string>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::string, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::less<std::string>>="__value_"Q}}}"languagePairs"{vector<std::pair<std::string, std::string>, std::allocator<std::pair<std::string, std::string>>>="__begin_"^v"__end_"^v"__end_cap_"{__compressed_pair<std::pair<std::string, std::string> *, std::allocator<std::pair<std::string, std::string>>>="__value_"^v}}"taskSpecificLanguagePairs"{unordered_map<std::string, std::vector<std::pair<std::string, std::string>>, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<const std::string, std::vector<std::pair<std::string, std::string>>>>>="__table_"{__hash_table<std::__hash_value_type<std::string, std::vector<std::pair<std::string, std::string>>>, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, std::vector<std::pair<std::string, std::string>>>, std::hash<std::string>, std::equal_to<std::string>, true>, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, std::vector<std::pair<std::string, std::string>>>, std::equal_to<std::string>, std::hash<std::string>, true>, std::allocator<std::__hash_value_type<std::string, std::vector<std::pair<std::string, std::string>>>>>="__bucket_list_"{unique_ptr<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::vector<std::pair<std::string, std::string>>>, void *> *> *[], std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::vector<std::pair<std::string, std::string>>>, void *> *> *>>>="__ptr_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::vector<std::pair<std::string, std::string>>>, void *> *> **, std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::vector<std::pair<std::string, std::string>>>, void *> *> *>>>="__value_"^^v"__value_"{__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::vector<std::pair<std::string, std::string>>>, void *> *> *>>="__data_"{__compressed_pair<unsigned long, std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::vector<std::pair<std::string, std::string>>>, void *> *> *>>="__value_"Q}}}}"__p1_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::vector<std::pair<std::string, std::string>>>, void *> *>, std::allocator<std::__hash_node<std::__hash_value_type<std::string, std::vector<std::pair<std::string, std::string>>>, void *>>>="__value_"{__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::vector<std::pair<std::string, std::string>>>, void *> *>="__next_"^v}}"__p2_"{__compressed_pair<unsigned long, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, std::vector<std::pair<std::string, std::string>>>, std::hash<std::string>, std::equal_to<std::string>, true>>="__value_"Q}"__p3_"{__compressed_pair<float, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, std::vector<std::pair<std::string, std::string>>>, std::equal_to<std::string>, std::hash<std::string>, true>>="__value_"f}}}"pairSpecificSettings"{unordered_map<std::string, quasar::TranslationPairSetting, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<const std::string, quasar::TranslationPairSetting>>>="__table_"{__hash_table<std::__hash_value_type<std::string, quasar::TranslationPairSetting>, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, quasar::TranslationPairSetting>, std::hash<std::string>, std::equal_to<std::string>, true>, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, quasar::TranslationPairSetting>, std::equal_to<std::string>, std::hash<std::string>, true>, std::allocator<std::__hash_value_type<std::string, quasar::TranslationPairSetting>>>="__bucket_list_"{unique_ptr<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, quasar::TranslationPairSetting>, void *> *> *[], std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, quasar::TranslationPairSetting>, void *> *> *>>>="__ptr_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, quasar::TranslationPairSetting>, void *> *> **, std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, quasar::TranslationPairSetting>, void *> *> *>>>="__value_"^^v"__value_"{__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, quasar::TranslationPairSetting>, void *> *> *>>="__data_"{__compressed_pair<unsigned long, std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, quasar::TranslationPairSetting>, void *> *> *>>="__value_"Q}}}}"__p1_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, quasar::TranslationPairSetting>, void *> *>, std::allocator<std::__hash_node<std::__hash_value_type<std::string, quasar::TranslationPairSetting>, void *>>>="__value_"{__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, quasar::TranslationPairSetting>, void *> *>="__next_"^v}}"__p2_"{__compressed_pair<unsigned long, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, quasar::TranslationPairSetting>, std::hash<std::string>, std::equal_to<std::string>, true>>="__value_"Q}"__p3_"{__compressed_pair<float, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, quasar::TranslationPairSetting>, std::equal_to<std::string>, std::hash<std::string>, true>>="__value_"f}}}"taskLangPairSpecificSettings"{unordered_map<std::string, std::unordered_map<std::string, quasar::TranslationPairSetting>, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<const std::string, std::unordered_map<std::string, quasar::TranslationPairSetting>>>>="__table_"{__hash_table<std::__hash_value_type<std::string, std::unordered_map<std::string, quasar::TranslationPairSetting>>, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, std::unordered_map<std::string, quasar::TranslationPairSetting>>, std::hash<std::string>, std::equal_to<std::string>, true>, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, std::unordered_map<std::string, quasar::TranslationPairSetting>>, std::equal_to<std::string>, std::hash<std::string>, true>, std::allocator<std::__hash_value_type<std::string, std::unordered_map<std::string, quasar::TranslationPairSetting>>>>="__bucket_list_"{unique_ptr<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::unordered_map<std::string, quasar::TranslationPairSetting>>, void *> *> *[], std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::unordered_map<std::string, quasar::TranslationPairSetting>>, void *> *> *>>>="__ptr_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::unordered_map<std::string, quasar::TranslationPairSetting>>, void *> *> **, std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::unordered_map<std::string, quasar::TranslationPairSetting>>, void *> *> *>>>="__value_"^^v"__value_"{__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::unordered_map<std::string, quasar::TranslationPairSetting>>, void *> *> *>>="__data_"{__compressed_pair<unsigned long, std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::unordered_map<std::string, quasar::TranslationPairSetting>>, void *> *> *>>="__value_"Q}}}}"__p1_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::unordered_map<std::string, quasar::TranslationPairSetting>>, void *> *>, std::allocator<std::__hash_node<std::__hash_value_type<std::string, std::unordered_map<std::string, quasar::TranslationPairSetting>>, void *>>>="__value_"{__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::unordered_map<std::string, quasar::TranslationPairSetting>>, void *> *>="__next_"^v}}"__p2_"{__compressed_pair<unsigned long, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, std::unordered_map<std::string, quasar::TranslationPairSetting>>, std::hash<std::string>, std::equal_to<std::string>, true>>="__value_"Q}"__p3_"{__compressed_pair<float, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, std::unordered_map<std::string, quasar::TranslationPairSetting>>, std::equal_to<std::string>, std::hash<std::string>, true>>="__value_"f}}}"taskAlias"{unordered_map<std::string, std::string, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<const std::string, std::string>>>="__table_"{__hash_table<std::__hash_value_type<std::string, std::string>, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, std::string>, std::hash<std::string>, std::equal_to<std::string>, true>, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, std::string>, std::equal_to<std::string>, std::hash<std::string>, true>, std::allocator<std::__hash_value_type<std::string, std::string>>>="__bucket_list_"{unique_ptr<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *> *> *[], std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *> *> *>>>="__ptr_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *> *> **, std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *> *> *>>>="__value_"^^v"__value_"{__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *> *> *>>="__data_"{__compressed_pair<unsigned long, std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *> *> *>>="__value_"Q}}}}"__p1_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *> *>, std::allocator<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *>>>="__value_"{__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *> *>="__next_"^v}}"__p2_"{__compressed_pair<unsigned long, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, std::string>, std::hash<std::string>, std::equal_to<std::string>, true>>="__value_"Q}"__p3_"{__compressed_pair<float, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, std::string>, std::equal_to<std::string>, std::hash<std::string>, true>>="__value_"f}}}}"hybridClientConfigs"{HybridClientConfigs="hybridEndpointerThresholds"{map<int, std::map<std::string, double>, std::less<int>, std::allocator<std::pair<const int, std::map<std::string, double>>>>="__tree_"{__tree<std::__value_type<int, std::map<std::string, double>>, std::__map_value_compare<int, std::__value_type<int, std::map<std::string, double>>, std::less<int>, true>, std::allocator<std::__value_type<int, std::map<std::string, double>>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<int, std::map<std::string, double>>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<int, std::__value_type<int, std::map<std::string, double>>, std::less<int>, true>>="__value_"Q}}}"hybridEndpointerExtraDelayFrequency"{map<std::string, int, std::less<std::string>, std::allocator<std::pair<const std::string, int>>>="__tree_"{__tree<std::__value_type<std::string, int>, std::__map_value_compare<std::string, std::__value_type<std::string, int>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, int>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, int>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, int>, std::less<std::string>, true>>="__value_"Q}}}}"configType"i"requiredAbsolutePaths"{unordered_set<std::string, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::string>>="__table_"{__hash_table<std::string, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::string>>="__bucket_list_"{unique_ptr<std::__hash_node_base<std::__hash_node<std::string, void *> *> *[], std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::string, void *> *> *>>>="__ptr_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::string, void *> *> **, std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::string, void *> *> *>>>="__value_"^^v"__value_"{__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::string, void *> *> *>>="__data_"{__compressed_pair<unsigned long, std::allocator<std::__hash_node_base<std::__hash_node<std::string, void *> *> *>>="__value_"Q}}}}"__p1_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::string, void *> *>, std::allocator<std::__hash_node<std::string, void *>>>="__value_"{__hash_node_base<std::__hash_node<std::string, void *> *>="__next_"^v}}"__p2_"{__compressed_pair<unsigned long, std::hash<std::string>>="__value_"Q}"__p3_"{__compressed_pair<float, std::equal_to<std::string>>="__value_"f}}}"optionalAbsolutePaths"{unordered_set<std::string, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::string>>="__table_"{__hash_table<std::string, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::string>>="__bucket_list_"{unique_ptr<std::__hash_node_base<std::__hash_node<std::string, void *> *> *[], std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::string, void *> *> *>>>="__ptr_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::string, void *> *> **, std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::string, void *> *> *>>>="__value_"^^v"__value_"{__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::string, void *> *> *>>="__data_"{__compressed_pair<unsigned long, std::allocator<std::__hash_node_base<std::__hash_node<std::string, void *> *> *>>="__value_"Q}}}}"__p1_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::string, void *> *>, std::allocator<std::__hash_node<std::string, void *>>>="__value_"{__hash_node_base<std::__hash_node<std::string, void *> *>="__next_"^v}}"__p2_"{__compressed_pair<unsigned long, std::hash<std::string>>="__value_"Q}"__p3_"{__compressed_pair<float, std::equal_to<std::string>>="__value_"f}}}}"prefix"{basic_string<char, std::char_traits<char>, std::allocator<char>>="__r_"{__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>="__value_"{__rep=""(?="__l"{__long="__data_"*"__size_"Q"__cap_"Q}"__s"{__short="__data_"[23c]""{?="__size_"C}}"__r"{__raw="__words"[3Q]})}}}"modelLoader"{shared_ptr<quasar::ModelLoader>="__ptr_"^{ModelLoader}"__cntrl_"^{__shared_weak_count}}"mainModelVersion"{basic_string<char, std::char_traits<char>, std::allocator<char>>="__r_"{__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>="__value_"{__rep=""(?="__l"{__long="__data_"*"__size_"Q"__cap_"Q}"__s"{__short="__data_"[23c]""{?="__size_"C}}"__r"{__raw="__words"[3Q]})}}}"mainSpeechModelInfo"{SpeechModelInfo="version"{basic_string<char, std::char_traits<char>, std::allocator<char>>="__r_"{__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>="__value_"{__rep=""(?="__l"{__long="__data_"*"__size_"Q"__cap_"Q}"__s"{__short="__data_"[23c]""{?="__size_"C}}"__r"{__raw="__words"[3Q]})}}}"samplingRates"{set<int, std::less<int>, std::allocator<int>>="__tree_"{__tree<int, std::less<int>, std::allocator<int>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<int, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::less<int>>="__value_"Q}}}"tasks"{set<std::string, std::less<std::string>, std::allocator<std::string>>="__tree_"{__tree<std::string, std::less<std::string>, std::allocator<std::string>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::string, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::less<std::string>>="__value_"Q}}}"osTypes"{set<std::string, std::less<std::string>, std::allocator<std::string>>="__tree_"{__tree<std::string, std::less<std::string>, std::allocator<std::string>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::string, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::less<std::string>>="__value_"Q}}}"language"{basic_string<char, std::char_traits<char>, std::allocator<char>>="__r_"{__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>="__value_"{__rep=""(?="__l"{__long="__data_"*"__size_"Q"__cap_"Q}"__s"{__short="__data_"[23c]""{?="__size_"C}}"__r"{__raw="__words"[3Q]})}}}"phoneSetVersion"{basic_string<char, std::char_traits<char>, std::allocator<char>>="__r_"{__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>="__value_"{__rep=""(?="__l"{__long="__data_"*"__size_"Q"__cap_"Q}"__s"{__short="__data_"[23c]""{?="__size_"C}}"__r"{__raw="__words"[3Q]})}}}"acousticProfileVersion"{basic_string<char, std::char_traits<char>, std::allocator<char>>="__r_"{__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>="__value_"{__rep=""(?="__l"{__long="__data_"*"__size_"Q"__cap_"Q}"__s"{__short="__data_"[23c]""{?="__size_"C}}"__r"{__raw="__words"[3Q]})}}}"aceToQuasarTemplate"{map<std::string, std::string, std::less<std::string>, std::allocator<std::pair<const std::string, std::string>>>="__tree_"{__tree<std::__value_type<std::string, std::string>, std::__map_value_compare<std::string, std::__value_type<std::string, std::string>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::string>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::string>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::string>, std::less<std::string>, true>>="__value_"Q}}}"quasarTemplateToAce"{map<std::string, std::vector<std::string>, std::less<std::string>, std::allocator<std::pair<const std::string, std::vector<std::string>>>>="__tree_"{__tree<std::__value_type<std::string, std::vector<std::string>>, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<std::string>>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::vector<std::string>>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::vector<std::string>>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<std::string>>, std::less<std::string>, true>>="__value_"Q}}}"quasarTemplateToEnumerationType"{map<std::string, std::string, std::less<std::string>, std::allocator<std::pair<const std::string, std::string>>>="__tree_"{__tree<std::__value_type<std::string, std::string>, std::__map_value_compare<std::string, std::__value_type<std::string, std::string>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::string>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::string>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::string>, std::less<std::string>, true>>="__value_"Q}}}"g2pModelVersion"i"hybridEndpointerVersion"i}"boolMap"{map<std::string, bool *, std::less<std::string>, std::allocator<std::pair<const std::string, bool *>>>="__tree_"{__tree<std::__value_type<std::string, bool *>, std::__map_value_compare<std::string, std::__value_type<std::string, bool *>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, bool *>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, bool *>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, bool *>, std::less<std::string>, true>>="__value_"Q}}}"intMap"{map<std::string, int *, std::less<std::string>, std::allocator<std::pair<const std::string, int *>>>="__tree_"{__tree<std::__value_type<std::string, int *>, std::__map_value_compare<std::string, std::__value_type<std::string, int *>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, int *>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, int *>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, int *>, std::less<std::string>, true>>="__value_"Q}}}"uintMap"{map<std::string, unsigned int *, std::less<std::string>, std::allocator<std::pair<const std::string, unsigned int *>>>="__tree_"{__tree<std::__value_type<std::string, unsigned int *>, std::__map_value_compare<std::string, std::__value_type<std::string, unsigned int *>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, unsigned int *>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, unsigned int *>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, unsigned int *>, std::less<std::string>, true>>="__value_"Q}}}"int64Map"{map<std::string, long long *, std::less<std::string>, std::allocator<std::pair<const std::string, long long *>>>="__tree_"{__tree<std::__value_type<std::string, long long *>, std::__map_value_compare<std::string, std::__value_type<std::string, long long *>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, long long *>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, long long *>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, long long *>, std::less<std::string>, true>>="__value_"Q}}}"floatMap"{map<std::string, float *, std::less<std::string>, std::allocator<std::pair<const std::string, float *>>>="__tree_"{__tree<std::__value_type<std::string, float *>, std::__map_value_compare<std::string, std::__value_type<std::string, float *>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, float *>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, float *>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, float *>, std::less<std::string>, true>>="__value_"Q}}}"doubleMap"{map<std::string, double *, std::less<std::string>, std::allocator<std::pair<const std::string, double *>>>="__tree_"{__tree<std::__value_type<std::string, double *>, std::__map_value_compare<std::string, std::__value_type<std::string, double *>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, double *>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, double *>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, double *>, std::less<std::string>, true>>="__value_"Q}}}"stringMap"{map<std::string, std::string *, std::less<std::string>, std::allocator<std::pair<const std::string, std::string *>>>="__tree_"{__tree<std::__value_type<std::string, std::string *>, std::__map_value_compare<std::string, std::__value_type<std::string, std::string *>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::string *>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::string *>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::string *>, std::less<std::string>, true>>="__value_"Q}}}"stringVecMap"{map<std::string, std::vector<std::string> *, std::less<std::string>, std::allocator<std::pair<const std::string, std::vector<std::string> *>>>="__tree_"{__tree<std::__value_type<std::string, std::vector<std::string> *>, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<std::string> *>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::vector<std::string> *>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::vector<std::string> *>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<std::string> *>, std::less<std::string>, true>>="__value_"Q}}}"stringPairVecMap"{map<std::string, std::vector<std::pair<std::string, std::string>> *, std::less<std::string>, std::allocator<std::pair<const std::string, std::vector<std::pair<std::string, std::string>> *>>>="__tree_"{__tree<std::__value_type<std::string, std::vector<std::pair<std::string, std::string>> *>, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<std::pair<std::string, std::string>> *>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::vector<std::pair<std::string, std::string>> *>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::vector<std::pair<std::string, std::string>> *>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<std::pair<std::string, std::string>> *>, std::less<std::string>, true>>="__value_"Q}}}"stringUnorderedSetMap"{map<std::string, std::unordered_set<std::string> *, std::less<std::string>, std::allocator<std::pair<const std::string, std::unordered_set<std::string> *>>>="__tree_"{__tree<std::__value_type<std::string, std::unordered_set<std::string> *>, std::__map_value_compare<std::string, std::__value_type<std::string, std::unordered_set<std::string> *>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::unordered_set<std::string> *>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::unordered_set<std::string> *>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::unordered_set<std::string> *>, std::less<std::string>, true>>="__value_"Q}}}"paramMinVersionMap"{map<std::string, quasar::SystemConfig::Version, std::less<std::string>, std::allocator<std::pair<const std::string, quasar::SystemConfig::Version>>>="__tree_"{__tree<std::__value_type<std::string, quasar::SystemConfig::Version>, std::__map_value_compare<std::string, std::__value_type<std::string, quasar::SystemConfig::Version>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, quasar::SystemConfig::Version>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, quasar::SystemConfig::Version>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, quasar::SystemConfig::Version>, std::less<std::string>, true>>="__value_"Q}}}"paramMaxVersionMap"{map<std::string, quasar::SystemConfig::Version, std::less<std::string>, std::allocator<std::pair<const std::string, quasar::SystemConfig::Version>>>="__tree_"{__tree<std::__value_type<std::string, quasar::SystemConfig::Version>, std::__map_value_compare<std::string, std::__value_type<std::string, quasar::SystemConfig::Version>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, quasar::SystemConfig::Version>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, quasar::SystemConfig::Version>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, quasar::SystemConfig::Version>, std::less<std::string>, true>>="__value_"Q}}}"requiredParams"{map<std::string, std::set<std::string>, std::less<std::string>, std::allocator<std::pair<const std::string, std::set<std::string>>>>="__tree_"{__tree<std::__value_type<std::string, std::set<std::string>>, std::__map_value_compare<std::string, std::__value_type<std::string, std::set<std::string>>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::set<std::string>>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::set<std::string>>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::set<std::string>>, std::less<std::string>, true>>="__value_"Q}}}"state"i}
@"<EARPSRAudioProcessorDelegate>"
@24@0:8^{EARCSpeechRecognitionResultStream=^v^?^?^?^?^?}16
{EARCSpeechRecognitionResultStream="ctx"^v"DisposeContext"^?"DidRecognizePartialResultTokens"^?"DidFinishRecognitionWithError"^?"DidRecognizeFinalResults"^?"DidProcessAudioDuration"^?}
{shared_ptr<quasar::RecogAudioBuffer>="__ptr_"^{RecogAudioBuffer}"__cntrl_"^{__shared_weak_count}}
@36@0:8@16f24B28B32
@40@0:8@16f24f28B32B36
{shared_ptr<quasar::artifact::Artifact>="__ptr_"^{Artifact}"__cntrl_"^{__shared_weak_count}}
B48@0:8@16@24@32@40
B64@0:8@16@24@32@40@48@56
@68@0:8@16Q24@32@40@48@56B64
B76@0:8@16Q24@32@40@48@56B64@68
@32@0:8{shared_ptr<quasar::artifact::AppLmArtifact>=^{AppLmArtifact}^{__shared_weak_count}}16
{shared_ptr<quasar::AppLmData>=^{AppLmData}^{__shared_weak_count}}40@0:8@16@24@32
v56@0:8{shared_ptr<quasar::AppLmData>=^{AppLmData}^{__shared_weak_count}}16@32@40@48
B40@0:8@16@24@32
@40@0:8@16q24@32
@"EMFEmojiPreferencesClient"
@"EMFEmojiLocaleData"
^{__EmojiLocaleDataWrapper=}
@40@0:8@16Q24Q32
{shared_ptr<quasar::SyncPSRAudioProcessor>="__ptr_"^{SyncPSRAudioProcessor}"__cntrl_"^{__shared_weak_count}}
@"NSMutableData"
@"<EARAudioResultsGeneratorDelegate>"
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
@44@0:8@16c24@28@36
c16@0:8
@36@0:8@16@24B32
@44@0:8@16@24B32q36
v48@0:8@16@24@32@?40
v56@0:8@16@24@32@40@?48
v36@0:8@16B24@?28
v44@0:8@16B24@28@?36
{vector<std::string, std::allocator<std::string>>=^v^v{__compressed_pair<std::string *, std::allocator<std::string>>=^v}}24@0:8@16
v60@0:8{vector<std::string, std::allocator<std::string>>=^v^v{__compressed_pair<std::string *, std::allocator<std::string>>=^v}}16B40@44@?52
{shared_ptr<quasar::TranslatorFactory>="__ptr_"^{TranslatorFactory}"__cntrl_"^{__shared_weak_count}}
{shared_ptr<quasar::Translator>="__ptr_"^{Translator}"__cntrl_"^{__shared_weak_count}}
{vector<quasar::SystemConfig, std::allocator<quasar::SystemConfig>>="__begin_"^{SystemConfig}"__end_"^{SystemConfig}"__end_cap_"{__compressed_pair<quasar::SystemConfig *, std::allocator<quasar::SystemConfig>>="__value_"^{SystemConfig}}}
@"NSOperationQueue"
@32@0:8d16d24
{unique_ptr<quasar::Geography, std::default_delete<quasar::Geography>>="__ptr_"{__compressed_pair<quasar::Geography *, std::default_delete<quasar::Geography>>="__value_"^{Geography}}}
@"NSIndexSet"
@36@0:8c16@20@28
v28@0:8@16f24
{vector<std::pair<id<_EARLanguageModelDataSource>, float>, std::allocator<std::pair<id<_EARLanguageModelDataSource>, float>>>="__begin_"^v"__end_"^v"__end_cap_"{__compressed_pair<std::pair<id<_EARLanguageModelDataSource>, float> *, std::allocator<std::pair<id<_EARLanguageModelDataSource>, float>>>="__value_"^v}}
{shared_ptr<sentencepiece::SentencePieceProcessor>="__ptr_"^{SentencePieceProcessor}"__cntrl_"^{__shared_weak_count}}
B24@0:8r^v16
{vector<quasar::Token, std::allocator<quasar::Token>>=^{Token}^{Token}{__compressed_pair<quasar::Token *, std::allocator<quasar::Token>>=^{Token}}}24@0:8@16
{vector<quasar::Token, std::allocator<quasar::Token>>=^{Token}^{Token}{__compressed_pair<quasar::Token *, std::allocator<quasar::Token>>=^{Token}}}28@0:8@16I24
@44@0:8@16@24B32@36
@48@0:8@16@24B32@36B44
B36@0:8r^v16r^v24S32
{vector<quasar::Token, std::allocator<quasar::Token>>=^{Token}^{Token}{__compressed_pair<quasar::Token *, std::allocator<quasar::Token>>=^{Token}}}32@0:8r^v16^v24
{vector<quasar::Token, std::allocator<quasar::Token>>=^{Token}^{Token}{__compressed_pair<quasar::Token *, std::allocator<quasar::Token>>=^{Token}}}40@0:8r^v16^v24@32
{vector<quasar::Token, std::allocator<quasar::Token>>=^{Token}^{Token}{__compressed_pair<quasar::Token *, std::allocator<quasar::Token>>=^{Token}}}184@0:8r^v16^v24@32@40r^v48B56^v60I68B72{shared_ptr<quasar::ContinuousListeningConfig>=^{ContinuousListeningConfig}^{__shared_weak_count}}76r^v92^v100r^v108S116B120B124r^v128^v136B144B148{shared_ptr<bool>=^B^{__shared_weak_count}}152B168i172@?176
v44@0:8^v16B24^v28B36i40
{vector<quasar::Token, std::allocator<quasar::Token>>=^{Token}^{Token}{__compressed_pair<quasar::Token *, std::allocator<quasar::Token>>=^{Token}}}36@0:8r^v16r^v24B32
v60@0:8r^v16r^v24^v32^v40r^v48B56
@40@0:8@16@24B32B36
{basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=*QQ}{__short=[23c]{?=C}}{__raw=[3Q]})}}}24@0:8r^v16
@44@0:8@16@24@32B40
@52@0:8@16@24@32B40@44
{unique_ptr<SpeechITN, std::default_delete<SpeechITN>>="__ptr_"{__compressed_pair<SpeechITN *, std::default_delete<SpeechITN>>="__value_"^{SpeechITN}}}
@"_EAREmojiRecognition"
@"NSMutableDictionary"
@48@0:8@16@24f32B36@40
@"_EARUserProfileBuilder"
@32@0:8{shared_ptr<quasar::CustomPronData>=^{CustomPronData}^{__shared_weak_count}}16
{shared_ptr<quasar::CustomPronData>=^{CustomPronData}^{__shared_weak_count}}16@0:8
v32@0:8{shared_ptr<quasar::CustomPronData>=^{CustomPronData}^{__shared_weak_count}}16
{shared_ptr<quasar::CustomPronData>="__ptr_"^{CustomPronData}"__cntrl_"^{__shared_weak_count}}
@64@0:8@16@24Q32@40@48q56
@68@0:8@16@24Q32@40@48q56B64
@"<EARSyncPSRAudioProcessorDelegate>"
@32@0:8{shared_ptr<kaldi::quasar::LmHandle>=^{LmHandle}^{__shared_weak_count}}16
{shared_ptr<kaldi::quasar::LmHandle>=^{LmHandle}^{__shared_weak_count}}16@0:8
{shared_ptr<kaldi::quasar::LmHandle>="__ptr_"^{LmHandle}"__cntrl_"^{__shared_weak_count}}
@56@0:8d16d24d32d40d48
{shared_ptr<quasar::SilencePosteriorGenerator>="__ptr_"^{SilencePosteriorGenerator}"__cntrl_"^{__shared_weak_count}}
@"<EARCaesuraSilencePosteriorGeneratorDelegate>"
v80@0:8^@16^@24^@32^@40^@48^@56^@64@72
v80@0:8@16@24@32Q40Q48Q56Q64@72
v80@0:8@"NSString"16@"NSString"24@"NSString"32Q40Q48Q56Q64@"NSString"72
{shared_ptr<quasar::PhonesetMapping>="__ptr_"^{PhonesetMapping}"__cntrl_"^{__shared_weak_count}}
@"_EARLanguageDetectorRequestContext"
{vector<std::optional<quasar::language_detector::Locale>, std::allocator<std::optional<quasar::language_detector::Locale>>>=^v^v{__compressed_pair<std::optional<quasar::language_detector::Locale> *, std::allocator<std::optional<quasar::language_detector::Locale>>>=^v}}24@0:8@16
{shared_ptr<const quasar::LDContext>=^{LDContext}^{__shared_weak_count}}32@0:8r^v16r^v24
@40@0:8Q16@24@32
v20@0:8I16
{unique_ptr<quasar::LanguageDetector, std::default_delete<quasar::LanguageDetector>>="__ptr_"{__compressed_pair<quasar::LanguageDetector *, std::default_delete<quasar::LanguageDetector>>="__value_"^{LanguageDetector}}}
{unique_ptr<quasar::CommandTagging, std::default_delete<quasar::CommandTagging>>="__ptr_"{__compressed_pair<quasar::CommandTagging *, std::default_delete<quasar::CommandTagging>>="__value_"^{CommandTagging}}}
@32@0:8@16q24
@24@0:8q16
{unique_ptr<quasar::CommandTagger, std::default_delete<quasar::CommandTagger>>="__ptr_"{__compressed_pair<quasar::CommandTagger *, std::default_delete<quasar::CommandTagger>>="__value_"^{CommandTagger}}}
v56@0:8@16@24@32@40@48
v24@0:8@"NSXMLParser"16
v48@0:8@"NSXMLParser"16@"NSString"24@"NSString"32@"NSString"40
v56@0:8@"NSXMLParser"16@"NSString"24@"NSString"32@"NSString"40@"NSString"48
v40@0:8@"NSXMLParser"16@"NSString"24@"NSString"32
v56@0:8@"NSXMLParser"16@"NSString"24@"NSString"32@"NSString"40@"NSDictionary"48
v32@0:8@"NSXMLParser"16@"NSString"24
v32@0:8@"NSXMLParser"16@"NSData"24
@"NSData"40@0:8@"NSXMLParser"16@"NSString"24@"NSString"32
v32@0:8@"NSXMLParser"16@"NSError"24
@"NSMutableSet"
@"NSXMLParser"
@"NSMutableString"
{unique_ptr<quasar::TextTokenizer, std::default_delete<quasar::TextTokenizer>>={__compressed_pair<quasar::TextTokenizer *, std::default_delete<quasar::TextTokenizer>>=^{TextTokenizer}}}24@0:8@16
@"NLTagger"
v28@0:8B16@20
v24@0:8^v16
v32@0:8@16^{powerSummary=dddddddddddddd}24
{vector<void *, std::allocator<void *>>="__begin_"^^v"__end_"^^v"__end_cap_"{__compressed_pair<void **, std::allocator<void *>>="__value_"^^v}}
{powerSummary="total_energy"d"ane_energy"d"gpu_energy"d"ecpu_energy"d"pcpu_energy"d"dram_energy"d"other_energy"d"total_power"d"ane_power"d"gpu_power"d"ecpu_power"d"pcpu_power"d"dram_power"d"other_power"d}
mcpl
@(#)$Id: ngram-count.cc,v 1.78 2013/09/16 06:50:23 stolcke Exp $
@(#)$Id: residual-adapt.cc,v 1.78 2020/11/25 14:30:00 Amr Mousa Exp $
