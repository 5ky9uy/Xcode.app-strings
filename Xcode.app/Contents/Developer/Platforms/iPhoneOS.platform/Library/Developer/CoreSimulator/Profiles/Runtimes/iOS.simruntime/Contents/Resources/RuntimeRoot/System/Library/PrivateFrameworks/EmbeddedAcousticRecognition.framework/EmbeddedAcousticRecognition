FT
NSt3__120__shared_ptr_emplaceIN6quasar14LmeDataFactoryENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar14GlobalLRUCacheINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_6vectorIS8_NS6_IS8_EEEEEENS6_ISC_EEEE
N6quasar14GlobalLRUCacheINSt3__112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEENS1_6vectorIS7_NS5_IS7_EEEEEE
?N6quasar6Bitmap21CoordinatesOutOfRangeE
N6quasar6BitmapE
N6quasar12BitmapLoaderE
N5kaldi6quasar14CEInferenceNetE
P?N3fst9VectorFstINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEENS_11VectorStateIS6_NSt3__19allocatorIS6_EEEEEE
N3fst9FifoQueueIiEE
N5kaldi6quasar18OnlineLASDecodableE
MbP?
N5kaldi18OnlinePitchFeatureE
N3fst15MemoryArenaBaseE
N3fst14MemoryPoolBaseE
AN6quasar33OnlineLatticeWordAlignmentDecoderE
<N5kaldi5nnet131BidirectionalRecurrentComponentE
?333333
333333
?N6quasar17WatermarkDetectorE
@15NaturalDiscount
8Discount
5Debug
9KneserNey
12ModKneserNey
10GoodTuring
ffffff
BN5kaldi17ContextDependencyE
NSt3__120__shared_ptr_emplaceIN6quasar16RecogAudioBufferENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIKN5kaldi5TimerENS_9allocatorIS3_EEEE
?N5kaldi5nnet19LayerNormE
N6quasar14HwcnConfidenceE
NSt3__120__shared_ptr_emplaceIN6marisa4TrieENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi6MatrixIfEENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar22WlatArcFeWordEmbeddingENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar14WlatArcFeIsLmeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar14WlatArcFeLmeIdENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar14WlatArcFeIsSilENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar18WlatArcFeNumPhonesENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar29WlatArcFeAcousticCostUnpushedENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar19WlatArcFeInBestPathENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar21WlatArcFeAcousticCostENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar18WlatArcFeGraphCostENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar18WlatArcFeNumFramesENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar21WlatArcFeLogPosteriorENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar21WlatArcFeLinPosteriorENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi5nnet14NnetENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar16MiscSharedConfigENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar19EndPointModelConfigENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar11EagerConfigENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar9GeographyENS_9allocatorIS2_EEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_17TropicalWeightTplIfEEEENSt3__19allocatorIS6_EEEEEENS_10MutableFstIS6_EEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_11ArcIteratorINS_3FstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEEE4LinkEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_21SequenceComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_23PushLabelsComposeFilterINS_24PushWeightsComposeFilterINS_22LookAheadComposeFilterINS_24AltSequenceComposeFilterINS_16LookAheadMatcherINS_3FstIS5_EEEESE_EESE_SE_LNS_9MatchTypeE2EEESE_SE_LSG_2EEESE_SE_LSG_2EEENS_24GenericComposeStateTableIS5_NS_15PairFilterStateINSL_INS_18IntegerFilterStateIaEENS_17WeightFilterStateIS4_EEEENSM_IiEEEENS_24DefaultComposeStateTupleIiSS_EENS_21CompactHashStateTableISU_NS_11ComposeHashISU_EEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_23PushLabelsComposeFilterINS_24PushWeightsComposeFilterINS_22LookAheadComposeFilterINS_21SequenceComposeFilterINS_16LookAheadMatcherINS_3FstIS5_EEEESE_EESE_SE_LNS_9MatchTypeE2EEESE_SE_LSG_2EEESE_SE_LSG_2EEENS_24GenericComposeStateTableIS5_NS_15PairFilterStateINSL_INS_18IntegerFilterStateIaEENS_17WeightFilterStateIS4_EEEENSM_IiEEEENS_24DefaultComposeStateTupleIiSS_EENS_21CompactHashStateTableISU_NS_11ComposeHashISU_EEEEEEEE
N3fst13StateIteratorINS_10ComposeFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_17DefaultCacheStoreIS5_EEEEEE
N3fst3FstINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEE
N3fst7FstImplINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEE
NSt3__114basic_ofstreamIcNS_11char_traitsIcEEEE
N3fst15ArcIteratorBaseINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEE
N3fst18DeterminizeFsaImplINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_20DefaultCommonDivisorIS4_EENS_24DefaultDeterminizeFilterIS6_EENS_28DefaultDeterminizeStateTableIS6_NS_18IntegerFilterStateIaEEEEEE
N3fst22DeterminizeFstImplBaseINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEE
N3fst9CacheImplINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEE
N3fst13CacheBaseImplINS_10CacheStateINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENSt3__19allocatorIS7_EEEENS_17DefaultCacheStoreIS7_EEEE
N3fst13StateIteratorINS_14DeterminizeFstINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEEEE
N3fst18CacheStateIteratorINS_14DeterminizeFstINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEEEE
N3fst17StateIteratorBaseINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEE
N5kaldi5nnet124QuantizedAffineTransformIaEE
N5kaldi5nnet124QuantizedAffineTransformIsEE
N5kaldi5nnet115LinearTransformINS_15QuantizedMatrixIaEEEE
N5kaldi5nnet115LinearTransformINS_15QuantizedMatrixIsEEEE
N5kaldi5nnet115LinearTransformINS_12CuMatrixBaseIfEEEE
NSt3__120__shared_ptr_pointerIPN6quasar14LmeDataFactoryENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN6quasar14LmeDataFactoryEEE
NSt3__120__shared_ptr_pointerIPN6quasar14GlobalLRUCacheINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_6vectorIS8_NS6_IS8_EEEEEENS_14default_deleteISC_EENS6_ISC_EEEE
NSt3__114default_deleteIN6quasar14GlobalLRUCacheINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_6vectorIS8_NS6_IS8_EEEEEEEE
NSt3__119basic_istringstreamIcNS_11char_traitsIcEENS_9allocatorIcEEEE
N6quasar19LatticeRnnMitigatorE
NSt3__120__shared_ptr_emplaceIN6quasar20WlatArcFeBagOfPhonesENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar16WlatArcFeKeywordENS_9allocatorIS2_EEEE
N5kaldi6quasar10LexiconItfE
N5kaldi6quasar7LexiconE
N5kaldi6quasar12ConstLexiconE
N6quasar28AlternativesProcessorOptionsE
N6quasar25ConfiguredProcessingBlockINS_28AlternativesProcessorOptionsEEE
N6quasar26AlternativesProcessorBlockE
N6quasar11OptionValueINSt3__112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEEEE
v@12LmFstWrapper
NSt3__120__shared_ptr_emplaceINS_19basic_istringstreamIcNS_11char_traitsIcEENS_9allocatorIcEEEENS4_IS6_EEEE
NSt3__120__shared_ptr_pointerIPN5kaldi5TimerENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN5kaldi5TimerEEE
NSt3__120__shared_ptr_pointerIP12LmFstWrapperNS_14default_deleteIS1_EENS_9allocatorIS1_EEEE
NSt3__114default_deleteI12LmFstWrapperEE
NSt3__120__shared_ptr_emplaceIN6quasar12DfstLmHandleENS_9allocatorIS2_EEEE
NSt3__113__assoc_stateIN6quasar8LocationEEE
NSt3__120__shared_ptr_emplaceIN6quasar14RunAsyncParamsENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceI19ResultStreamWrapperNS_9allocatorIS1_EEEE
19ResultStreamWrapper
NSt3__110__function6__funcIZ19getCoreMLModelFilesRKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEE3$_5NS5_ISA_EEFbS7_EEE
NSt3__110__function6__baseIFbNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEEEE
Z19getCoreMLModelFilesRKNSt3__112basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEE3$_5
N6quasar16RomanizerOptionsE
N6quasar25ConfiguredProcessingBlockINS_16RomanizerOptionsEEE
N6quasar14RomanizerBlockE
NSt3__112codecvt_utf8IwLm1114111ELNS_12codecvt_modeE0EEE
N3fst10MappedFileE
N6quasar23QualityEstimatorOptionsE
N6quasar25ConfiguredProcessingBlockINS_23QualityEstimatorOptionsEEE
N6quasar21QualityEstimatorBlockE
NSt3__111__end_stateIcEE
NSt3__16__nodeIcEE
NSt3__120__shared_ptr_pointerIPNS_13__empty_stateIcEENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteINS_13__empty_stateIcEEEE
NSt3__113__empty_stateIcEE
NSt3__116__owns_one_stateIcEE
NSt3__115__has_one_stateIcEE
NSt3__110__l_anchorIcEE
NSt3__110__r_anchorIcEE
NSt3__115__word_boundaryIcNS_12regex_traitsIcEEEE
NSt3__111__lookaheadIcNS_12regex_traitsIcEEEE
NSt3__123__match_any_but_newlineIcEE
NSt3__118__match_char_icaseIcNS_12regex_traitsIcEEEE
NSt3__120__match_char_collateIcNS_12regex_traitsIcEEEE
NSt3__112__match_charIcEE
NSt3__116__back_ref_icaseIcNS_12regex_traitsIcEEEE
NSt3__118__back_ref_collateIcNS_12regex_traitsIcEEEE
NSt3__110__back_refIcEE
NSt3__120__bracket_expressionIcNS_12regex_traitsIcEEEE
NSt3__128__begin_marked_subexpressionIcEE
NSt3__126__end_marked_subexpressionIcEE
NSt3__16__loopIcEE
NSt3__117__owns_two_statesIcEE
NSt3__117__repeat_one_loopIcEE
NSt3__111__alternateIcEE
NSt3__121__empty_non_own_stateIcEE
NSt3__111__match_anyIcEE
N3fst9VectorFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_11VectorStateIS4_NSt3__19allocatorIS4_EEEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_17TropicalWeightTplIfEEEENSt3__19allocatorIS6_EEEEEENS_10MutableFstIS6_EEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_17TropicalWeightTplIfEEEENSt3__19allocatorIS6_EEEEEENS_10MutableFstIS6_EEEE
N3fst9VectorFstINS_6ArcTplINS_12LogWeightTplIfEEEENS_11VectorStateIS4_NSt3__19allocatorIS4_EEEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_12LogWeightTplIfEEEENSt3__19allocatorIS6_EEEEEENS_10MutableFstIS6_EEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_12LogWeightTplIfEEEENSt3__19allocatorIS6_EEEEEENS_10MutableFstIS6_EEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_11VectorStateIS5_NSt3__19allocatorIS5_EEEEEEEE
N3fst22MutableArcIteratorBaseINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_6ArcTplINS_12LogWeightTplIfEEEENS_11VectorStateIS5_NSt3__19allocatorIS5_EEEEEEEE
N6quasar21InverseTextNormalizerE
NSt3__120__shared_ptr_emplaceIN6quasar25URegularExpressionWrapperENS_9allocatorIS2_EEEE
NSt3__112codecvt_utf8IDiLm1114111ELNS_12codecvt_modeE0EEE
NSt3__120__shared_ptr_pointerIPN6quasar34SpaceApplyDefaultFstTokenTransformENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN6quasar34SpaceApplyDefaultFstTokenTransformEEE
NSt3__120__shared_ptr_pointerIPN6quasar39RewriteApplyCapitalizeFstTokenTransformENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN6quasar39RewriteApplyCapitalizeFstTokenTransformEEE
NSt3__120__shared_ptr_pointerIPN6quasar36RewriteApplyDefaultFstTokenTransformENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN6quasar36RewriteApplyDefaultFstTokenTransformEEE
NSt3__120__shared_ptr_pointerIPN6quasar24ComposeFstTokenTransformENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN6quasar24ComposeFstTokenTransformEEE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar10PrefixTreeINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEES9_EENS7_ISA_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar5VocabENS_9allocatorIS3_EEEE
N3fst9ImplToFstINS_18ComposeFstImplBaseINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_17DefaultCacheStoreIS5_EEEENS_3FstIS5_EEEE
N3fst11MatcherBaseINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_17NullComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_17NullComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_24AltSequenceComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_18MatchComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N5kaldi8CuMatrixIdEE
N5kaldi12CuMatrixBaseIdEE
N5kaldi11CuSubMatrixIdEE
N6quasar16WlatArcFeKeywordE
N6quasar23WlatArcFeatureExtractorE
N6quasar14WlatArcFeIsLmeE
N6quasar14WlatArcFeLmeIdE
N6quasar14WlatArcFeIsSilE
N6quasar18WlatArcFeNumPhonesE
N6quasar29WlatArcFeAcousticCostUnpushedE
N6quasar19WlatArcFeInBestPathE
N6quasar21WlatArcFeAcousticCostE
N6quasar18WlatArcFeGraphCostE
N6quasar18WlatArcFeNumFramesE
N6quasar21WlatArcFeLogPosteriorE
N6quasar21WlatArcFeLinPosteriorE
N6quasar20WlatArcFeBagOfPhonesE
N6quasar22WlatArcFeWordEmbeddingE
N3fst11SymbolTableE
N3fst7ArcInfoE
N3fst14BackoffArcInfoE
N3fst13InterpArcInfoE
N6quasar11FstLmScorerE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEE4LinkEEE
NSt3__120__shared_ptr_emplaceIN6quasar22SpeechRecognizerConfigENS_9allocatorIS2_EEEE
N3fst10ReplaceFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_24DefaultReplaceStateTableIS4_lEENS_17DefaultCacheStoreIS4_EEEE
N3fst9ImplToFstINS_14ReplaceFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_24DefaultReplaceStateTableIS5_lEENS_17DefaultCacheStoreIS5_EEEENS_3FstIS5_EEEE
N3fst13StateIteratorINS_10ReplaceFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_24DefaultReplaceStateTableIS5_lEENS_17DefaultCacheStoreIS5_EEEEEE
N3fst17ReplaceFstMatcherINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_24DefaultReplaceStateTableIS4_lEENS_17DefaultCacheStoreIS4_EEEE
N3fst10MemoryPoolINS_11ArcIteratorINS_10ReplaceFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_24DefaultReplaceStateTableIS6_lEENS_17DefaultCacheStoreIS6_EEEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_11ArcIteratorINS_10ReplaceFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_24DefaultReplaceStateTableIS7_lEENS_17DefaultCacheStoreIS7_EEEEEEE4LinkEEE
N3fst29CacheDeterministicOnDemandFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_24DeterministicOnDemandFstIS4_EEEE
N5kaldi6quasar31RecurrentNeuralDeterministicFstIN3fst6ArcTplINS2_17TropicalWeightTplIfEEEEEE
NSt3__120__shared_ptr_emplaceIN3fst13InterpArcInfoENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceINS_6vectorINS_10shared_ptrIN3fst7ArcInfoEEENS_9allocatorIS5_EEEENS6_IS8_EEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEENSt3__19allocatorIS8_EEEEEENS_10MutableFstIS8_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi5TimerENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar17SpeechRequestDataENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar23SpeechRequestResultDataENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar18DecoderChainOutputENS_9allocatorIS2_EEEE
N5kaldi6quasar8LmHandleE
N4utf815not_enough_roomE
N4utf89exceptionE
N4utf812invalid_utf8E
N4utf818invalid_code_pointE
N6quasar13QuasarG2PBaseE
N3fst9VectorFstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEENS_11VectorStateIS8_NSt3__19allocatorIS8_EEEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEENSt3__19allocatorISA_EEEEEENS_10MutableFstISA_EEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEENSt3__19allocatorIS9_EEEEEE
N5kaldi12CuVectorBaseIdEE
NSt3__110__function6__funcIZN5kaldi6quasar26ConfidenceFeatureExtractorINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEE30GetConfidenceFeaturesFromNBestERKNS_6vectorINSC_ISA_NS8_ISA_EEEENS8_ISE_EEEERKNSC_IfNS8_IfEEEEiPNSC_INS2_6MatrixIfEENS8_ISO_EEEEEUliiE_NS8_ISS_EEFfiiEEE
NSt3__110__function6__baseIFfiiEEE
ZN5kaldi6quasar26ConfidenceFeatureExtractorINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEE30GetConfidenceFeaturesFromNBestERKNS2_6vectorINSA_IS8_NS6_IS8_EEEENS6_ISC_EEEERKNSA_IfNS6_IfEEEEiPNSA_INS_6MatrixIfEENS6_ISM_EEEEEUliiE_
NSt3__110__function6__funcIZN5kaldi6quasar26ConfidenceFeatureExtractorINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEE30GetConfidenceFeaturesFromNBestERKNS_6vectorINSC_ISA_NS8_ISA_EEEENS8_ISE_EEEERKNSC_IfNS8_IfEEEEiPNSC_INS2_6MatrixIfEENS8_ISO_EEEEEUliiE0_NS8_ISS_EEFfiiEEE
ZN5kaldi6quasar26ConfidenceFeatureExtractorINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEE30GetConfidenceFeaturesFromNBestERKNS2_6vectorINSA_IS8_NS6_IS8_EEEENS6_ISC_EEEERKNSA_IfNS6_IfEEEEiPNSA_INS_6MatrixIfEENS6_ISM_EEEEEUliiE0_
NSt3__110__function6__funcIZN5kaldi6quasar26ConfidenceFeatureExtractorINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEE30GetConfidenceFeaturesFromNBestERKNS_6vectorINSC_ISA_NS8_ISA_EEEENS8_ISE_EEEERKNSC_IfNS8_IfEEEEiPNSC_INS2_6MatrixIfEENS8_ISO_EEEEEUliiE1_NS8_ISS_EEFfiiEEE
ZN5kaldi6quasar26ConfidenceFeatureExtractorINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEE30GetConfidenceFeaturesFromNBestERKNS2_6vectorINSA_IS8_NS6_IS8_EEEENS6_ISC_EEEERKNSA_IfNS6_IfEEEEiPNSA_INS_6MatrixIfEENS6_ISM_EEEEEUliiE1_
NSt3__110__function6__funcIZN5kaldi6quasar26ConfidenceFeatureExtractorINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEE30GetConfidenceFeaturesFromNBestERKNS_6vectorINSC_ISA_NS8_ISA_EEEENS8_ISE_EEEERKNSC_IfNS8_IfEEEEiPNSC_INS2_6MatrixIfEENS8_ISO_EEEEEUliiE2_NS8_ISS_EEFfiiEEE
ZN5kaldi6quasar26ConfidenceFeatureExtractorINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEE30GetConfidenceFeaturesFromNBestERKNS2_6vectorINSA_IS8_NS6_IS8_EEEENS6_ISC_EEEERKNSA_IfNS6_IfEEEEiPNSA_INS_6MatrixIfEENS6_ISM_EEEEEUliiE2_
NSt3__110__function6__funcIZN5kaldi6quasar26ConfidenceFeatureExtractorINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEE30GetConfidenceFeaturesFromNBestERKNS_6vectorINSC_ISA_NS8_ISA_EEEENS8_ISE_EEEERKNSC_IfNS8_IfEEEEiPNSC_INS2_6MatrixIfEENS8_ISO_EEEEEUliiE3_NS8_ISS_EEFfiiEEE
ZN5kaldi6quasar26ConfidenceFeatureExtractorINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEE30GetConfidenceFeaturesFromNBestERKNS2_6vectorINSA_IS8_NS6_IS8_EEEENS6_ISC_EEEERKNSA_IfNS6_IfEEEEiPNSA_INS_6MatrixIfEENS6_ISM_EEEEEUliiE3_
NSt3__110__function6__funcIZN5kaldi6quasar26ConfidenceFeatureExtractorINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEE30GetConfidenceFeaturesFromNBestERKNS_6vectorINSC_ISA_NS8_ISA_EEEENS8_ISE_EEEERKNSC_IfNS8_IfEEEEiPNSC_INS2_6MatrixIfEENS8_ISO_EEEEEUliiE4_NS8_ISS_EEFfiiEEE
ZN5kaldi6quasar26ConfidenceFeatureExtractorINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEE30GetConfidenceFeaturesFromNBestERKNS2_6vectorINSA_IS8_NS6_IS8_EEEENS6_ISC_EEEERKNSA_IfNS6_IfEEEEiPNSA_INS_6MatrixIfEENS6_ISM_EEEEEUliiE4_
NSt3__110__function6__funcIZN5kaldi6quasar26ConfidenceFeatureExtractorINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEE30GetConfidenceFeaturesFromNBestERKNS_6vectorINSC_ISA_NS8_ISA_EEEENS8_ISE_EEEERKNSC_IfNS8_IfEEEEiPNSC_INS2_6MatrixIfEENS8_ISO_EEEEEUliiE5_NS8_ISS_EEFfiiEEE
ZN5kaldi6quasar26ConfidenceFeatureExtractorINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEE30GetConfidenceFeaturesFromNBestERKNS2_6vectorINSA_IS8_NS6_IS8_EEEENS6_ISC_EEEERKNSA_IfNS6_IfEEEEiPNSA_INS_6MatrixIfEENS6_ISM_EEEEEUliiE5_
NSt3__110__function6__funcIZN5kaldi6quasar26ConfidenceFeatureExtractorINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEE30GetConfidenceFeaturesFromNBestERKNS_6vectorINSC_ISA_NS8_ISA_EEEENS8_ISE_EEEERKNSC_IfNS8_IfEEEEiPNSC_INS2_6MatrixIfEENS8_ISO_EEEEEUliiE6_NS8_ISS_EEFfiiEEE
ZN5kaldi6quasar26ConfidenceFeatureExtractorINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEE30GetConfidenceFeaturesFromNBestERKNS2_6vectorINSA_IS8_NS6_IS8_EEEENS6_ISC_EEEERKNSA_IfNS6_IfEEEEiPNSA_INS_6MatrixIfEENS6_ISM_EEEEEUliiE6_
NSt3__110__function6__funcIZN5kaldi6quasar16ConfusionNetworkINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEEC1ERKNS_6vectorINSC_ISA_NS8_ISA_EEEENS8_ISE_EEEERKNSC_IfNS8_IfEEEENS_8functionIFSE_SE_EEENSN_IFSA_SA_EEEEd0_UlSE_E_NS8_ISS_EESO_EE
NSt3__110__function6__baseIFNS_6vectorINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS6_IS8_EEEESA_EEE
ZN5kaldi6quasar16ConfusionNetworkINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEEC1ERKNS2_6vectorINSA_IS8_NS6_IS8_EEEENS6_ISC_EEEERKNSA_IfNS6_IfEEEENS2_8functionIFSC_SC_EEENSL_IFS8_S8_EEEEd0_UlSC_E_
NSt3__110__function6__funcIZN5kaldi6quasar16ConfusionNetworkINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEEC1ERKNS_6vectorINSC_ISA_NS8_ISA_EEEENS8_ISE_EEEERKNSC_IfNS8_IfEEEENS_8functionIFSE_SE_EEENSN_IFSA_SA_EEEEd_UlSA_E_NS8_ISS_EESQ_EE
NSt3__110__function6__baseIFNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEES7_EEE
ZN5kaldi6quasar16ConfusionNetworkINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEEC1ERKNS2_6vectorINSA_IS8_NS6_IS8_EEEENS6_ISC_EEEERKNSA_IfNS6_IfEEEENS2_8functionIFSC_SC_EEENSL_IFS8_S8_EEEEd_UlS8_E_
NSt3__120__shared_ptr_pointerIPN6quasar20SyncSpeechRecognizerENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN6quasar20SyncSpeechRecognizerEEE
N6quasar15OptionValueBaseE
N6quasar11OptionsBaseE
N6quasar15ProcessingBlockE
N6quasar25MultiInputProcessingBlockE
N6quasar16ProcessingSourceE
N6quasar14ProcessingSinkE
N6quasar13MergerOptionsE
N6quasar25ConfiguredProcessingBlockINS_13MergerOptionsEEE
N6quasar11MergerBlockE
N6quasar9NullBlockE
NSt3__120__shared_ptr_emplaceIN5kaldi8CuMatrixIfEENS_9allocatorIS3_EEEE
$@N6quasar10TranslatorE
NSt3__120__shared_ptr_emplaceIN6quasar14PDecTranslatorENS_9allocatorIS2_EEEE
N5kaldi6quasar17AbstractAttributeE
N5kaldi6quasar10MajorErrorE
N5kaldi6quasar15SchemaAttributeE
N5kaldi6quasar15StringAttributeE
N5kaldi6quasar14FloatAttributeE
N5kaldi6quasar13BaseAttributeE
N5kaldi6quasar16AttributeWrapperE
N5kaldi6quasar16ContextAttributeE
N5kaldi6quasar13WordConfusionE
N5kaldi6quasar16AttributeFactoryE
9SpeechITN
13QuasarITNImpl
N6quasar7DecoderE
N3fst18MutableArcIteratorINS_9VectorFstINS_6ArcTplINS_16LatticeWeightTplIfEEEENS_11VectorStateIS5_NSt3__19allocatorIS5_EEEEEEEE
N3fst22MutableArcIteratorBaseINS_6ArcTplINS_16LatticeWeightTplIfEEEEEE
N3fst9VectorFstINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENS_11VectorStateIS6_NSt3__19allocatorIS6_EEEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENSt3__19allocatorIS8_EEEEEENS_10MutableFstIS8_EEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENSt3__19allocatorIS7_EEEEEE
N3fst14DeterminizeFstINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEE
N3fst22DeterminizeFstImplBaseINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEE
N3fst13CacheBaseImplINS_10CacheStateINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENSt3__19allocatorIS7_EEEENS_17DefaultCacheStoreIS7_EEEE
N3fst13StateIteratorINS_14DeterminizeFstINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEEEE
N3fst18CacheStateIteratorINS_14DeterminizeFstINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEEEE
N3fst17StateIteratorBaseINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEE
NSt3__120__shared_ptr_emplaceINS_6vectorINS1_IN6quasar5TokenENS_9allocatorIS3_EEEENS4_IS6_EEEENS4_IS8_EEEE
NSt3__120__shared_ptr_emplaceINS_6vectorIdNS_9allocatorIdEEEENS2_IS4_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar31OnlineLatticeBiglmFasterDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN3fst11SymbolTableENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar18QsrTextSymbolTableENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar34OnlineLatticeBiglmLmeFasterDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar34OnlineLatticeBiglmLmeFasterDecoder23LmeCreationDependenciesENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar15SymbolTableListENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar29OnlineLatticeRescalingDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar33OnlineLatticeWordAlignmentDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar24OnlineLmRescoringDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar31OnlineLatticeRealignmentDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar19ErrorBlamingDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar30OnlineLatticeConfidenceDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar20LatticeFasterDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar28OnlineKeywordSpottingDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar18OnlineSeevaDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar22OnlineSeevaStepDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar27OnlineSeevaStepBigLmDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar18SeevaGreedyDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar26OnlineLASBeamSearchDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar31ConfusionNetworkCombinerDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar20PhoneticMatchDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar19FingerprintDetectorENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar27OnlineAudioAnalyticsDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar17WatermarkDetectorENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar21AudioAnalyticsDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar19LatticeRnnMitigatorENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar14HwcnConfidenceENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar16E2EAsrConfidenceENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar18WatermarkDetector2ENS_9allocatorIS2_EEEE
N5kaldi6quasar11ErrorBlamerE
N3fst10MemoryPoolINS_8DfsStateINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEE
N3fst10MemoryPoolINS_8DfsStateINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEE
N3fst9VectorFstINS_6ArcTplINS_16LatticeWeightTplIfEEEENS_11VectorStateIS4_NSt3__19allocatorIS4_EEEEEE
N3fst18ComposeFstImplBaseINS_6ArcTplINS_16LatticeWeightTplIfEEEENS_17DefaultCacheStoreIS4_EEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENS_21SequenceComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENS_22LookAheadComposeFilterINS_24AltSequenceComposeFilterINS_16LookAheadMatcherINS_3FstIS5_EEEESC_EESC_SC_LNS_9MatchTypeE2EEENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSI_EENS_21CompactHashStateTableISK_NS_11ComposeHashISK_EEEEEEEE
N3fst13StateIteratorINS_10ComposeFstINS_6ArcTplINS_16LatticeWeightTplIfEEEENS_17DefaultCacheStoreIS5_EEEEEE
N3fst18CacheStateIteratorINS_10ComposeFstINS_6ArcTplINS_16LatticeWeightTplIfEEEENS_17DefaultCacheStoreIS5_EEEEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENS_17NullComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENS_24AltSequenceComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N6quasar13CommandTaggerE
NSt3__120__shared_ptr_emplaceIN6quasar18QuasarTextProcImplENS_9allocatorIS2_EEEE
N6quasar14CaseMapOptionsE
N6quasar25ConfiguredProcessingBlockINS_14CaseMapOptionsEEE
N6quasar12CaseMapBlockE
Q5Ngram
12NgramVisitor
13NgramBayesMix
N6quasar9GeoRegionE
NSt3__120__shared_ptr_emplaceIN6quasar12BitmapRegionENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar12CircleRegionENS_9allocatorIS2_EEEE
N5kaldi18CoreMLInferenceNetE
NSt3__120__shared_ptr_emplaceIN5kaldi18CoreMLInferenceNetENS_9allocatorIS2_EEEE
N6quasar12DummyLmModelE
N5kaldi5nnet123FixedAttentionComponentE
N6quasar20PhoneticMatchDecoderE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_16LatticeWeightTplIfEEEENSt3__19allocatorIS6_EEEEEENS_10MutableFstIS6_EEEE
N3fst11ExpandedFstINS_6ArcTplINS_16LatticeWeightTplIfEEEEEE
N3fst13VectorFstImplINS_11VectorStateINS_6ArcTplINS_17TropicalWeightTplIfEEEENSt3__19allocatorIS5_EEEEEE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar13SymbolDecoderINS2_8PhonomapEEENS_9allocatorIS5_EEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_16LatticeWeightTplIfEEEENSt3__19allocatorIS6_EEEEEENS_10MutableFstIS6_EEEE
N3fst10MemoryPoolINS_11ArcIteratorINS_3FstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_21SequenceComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst18ComposeFstImplBaseINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_17DefaultCacheStoreIS4_EEEE
>N6quasar15ProcessingGraphE
N6quasar21LinearProcessingGraphE
N6quasar23DirectedProcessingGraphE
N6quasar11OptionValueIiEE
N6quasar11OptionValueIdEE
N6quasar11OptionValueIbEE
N6quasar11OptionValueINS_5PTreeEEE
NSt3__120__shared_ptr_emplaceIN6quasar14ProcessingSinkENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar16ProcessingSourceENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_pointerIPN6quasar15ProcessingBlockENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN6quasar15ProcessingBlockEEE
N6quasar21PDecTranslatorFactoryE
N3fst13VectorFstImplINS_11VectorStateINS_6ArcTplINS_16LatticeWeightTplIfEEEENSt3__19allocatorIS5_EEEEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_6ArcTplINS_16LatticeWeightTplIfEEEENSt3__19allocatorIS5_EEEEEE
N3fst7FstImplINS_6ArcTplINS_16LatticeWeightTplIfEEEEEE
N3fst9ImplToFstINS_18ComposeFstImplBaseINS_6ArcTplINS_16LatticeWeightTplIfEEEENS_17DefaultCacheStoreIS5_EEEENS_3FstIS5_EEEE
N3fst13SortedMatcherINS_3FstINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEE
N3fst11MatcherBaseINS_6ArcTplINS_16LatticeWeightTplIfEEEEEE
N3fst10MemoryPoolINS_11ArcIteratorINS_3FstINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_11ArcIteratorINS_3FstINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEEE4LinkEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENS_21SequenceComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENS_24AltSequenceComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N5kaldi6quasar14RnnlmEvaluatorE
N6quasar24OnlineLmRescoringDecoderE
N5kaldi6quasar14DnnlmEvaluatorE
N6quasar20SyncSpeechRecognizerE
NSt3__120__shared_ptr_emplaceIN6quasar20RecognizerComponentsINS1_11SyncDecoderEEENS_9allocatorIS4_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar18RecogRequestFilterENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar11SessionDataENS_9allocatorIS2_EEEE
N5boost13property_tree11json_parser17json_parser_errorE
N5boost13property_tree17file_parser_errorE
N5boost13property_tree11ptree_errorE
N6quasar5PTree14JsonParseErrorE
N6quasar5PTree5ErrorE
N6quasar5PTree7BadPathE
N5boost16exception_detail10clone_implINS0_19error_info_injectorINS_13property_tree11json_parser17json_parser_errorEEEEE
N5boost16exception_detail19error_info_injectorINS_13property_tree11json_parser17json_parser_errorEEE
N5boost9exceptionE
N5boost16exception_detail10clone_baseE
NSt3__114basic_ifstreamIcNS_11char_traitsIcEEEE
NSt3__113basic_filebufIcNS_11char_traitsIcEEEE
333333
@(kn
N5kaldi6quasar19SeevaBeamSearchBaseE
N6quasar3G2PE
N6quasar25AlignmentProcessorOptionsE
N6quasar25ConfiguredProcessingBlockINS_25AlignmentProcessorOptionsEEE
N6quasar23AlignmentProcessorBlockE
N3fst13StateIteratorINS_12ArcPosingFstINS_6ArcTplINS_12LogWeightTplIfEEEENS2_INS_17TropicalWeightTplIfEEEEEEEE
N3fst15ArcIteratorBaseINS_6ArcTplINS_12LogWeightTplIfEEEEEE
N3fst19MutableArcPosingFstINS_6ArcTplINS_12LogWeightTplIfEEEENS1_INS_17TropicalWeightTplIfEEEEEE
N3fst11ArcIteratorINS_19MutableArcPosingFstINS_6ArcTplINS_12LogWeightTplIfEEEENS2_INS_17TropicalWeightTplIfEEEEEEEE
N3fst18MutableArcIteratorINS_19MutableArcPosingFstINS_6ArcTplINS_12LogWeightTplIfEEEENS2_INS_17TropicalWeightTplIfEEEEEEEE
N3fst12ArcPosingFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS1_INS_12LogWeightTplIfEEEEEE
N3fst13StateIteratorINS_12ArcPosingFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS2_INS_12LogWeightTplIfEEEEEEEE
N3fst11ArcIteratorINS_12ArcPosingFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS2_INS_12LogWeightTplIfEEEEEEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENSt3__19allocatorIS8_EEEEEENS_10MutableFstIS8_EEEE
N3fst10MutableFstINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_11VectorStateIS7_NSt3__19allocatorIS7_EEEEEEEE
N3fst10ContextFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEiEE
N3fst14ContextFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEEiEE
N3fst13StateIteratorINS_10ContextFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEiEEEE
N3fst18CacheStateIteratorINS_10ContextFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEiEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_21SequenceComposeFilterINS_14ContextMatcherIS5_iEES9_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSD_EENS_21CompactHashStateTableISF_NS_11ComposeHashISF_EEEEEEEE
N3fst14ContextMatcherINS_6ArcTplINS_17TropicalWeightTplIfEEEEiEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_21SequenceComposeFilterINS_14ContextMatcherIS5_iEES9_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSD_EENS_21CompactHashStateTableISF_NS_11ComposeHashISF_EEEEEEEE
N3fst12TableMatcherINS_3FstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_13SortedMatcherIS6_EEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_21SequenceComposeFilterINS_12TableMatcherINS_3FstIS5_EENS_13SortedMatcherISA_EEEESC_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSH_EENS_21CompactHashStateTableISJ_NS_11ComposeHashISJ_EEEEEEEE
N6quasar11FstLmHandleE
N6quasar12DfstLmHandleE
N3fst31BackoffDeterministicOnDemandFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_3FstIS4_EEEE
N3fst7FstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N3fst3FstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N3fst10MemoryPoolINS_8DfsStateINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEE
N5kaldi8CuVectorIfEE
NSt3__120__shared_ptr_emplaceIN5kaldi14WordHypLatticeENS_9allocatorIS2_EEEE
N6quasar19FingerprintDetectorE
N5kaldi32SequentialTableReaderArchiveImplINS_17KaldiObjectHolderINS_6VectorIfEEEEEE
N5kaldi29SequentialTableReaderImplBaseINS_17KaldiObjectHolderINS_6VectorIfEEEEEE
N5kaldi31SequentialTableReaderScriptImplINS_17KaldiObjectHolderINS_6VectorIfEEEEEE
N6quasar18AMKeywordDetectionE
N5kaldi6quasar19CEEncoderDecoderNetE
N5kaldi8CuVectorIdEE
N6quasar20LatticeFasterDecoderE
N3fst10MutableFstINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEE
N3fst13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENSt3__19allocatorIS7_EEEEEE
N3fst7FstImplINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEE
N3fst15ArcIteratorBaseINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEE
N6quasar8TextProcE
N6quasar31OnlineLatticeRealignmentDecoderE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENSt3__19allocatorIS8_EEEEEENS_10MutableFstIS8_EEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENSt3__19allocatorIS8_EEEEEENS_10MutableFstIS8_EEEE
N3fst11ExpandedFstINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEE
N3fst3FstINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEE
N3fst10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEEE4LinkEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENS_11VectorStateIS7_NSt3__19allocatorIS7_EEEEEEEE
N3fst22MutableArcIteratorBaseINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEE
N3fst13CacheBaseImplINS_10CacheStateINS_6ArcTplINS_16LatticeWeightTplIfEEEENSt3__19allocatorIS5_EEEENS_17DefaultCacheStoreIS5_EEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENS_22LookAheadComposeFilterINS_24AltSequenceComposeFilterINS_16LookAheadMatcherINS_3FstIS5_EEEESC_EESC_SC_LNS_9MatchTypeE2EEENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSI_EENS_21CompactHashStateTableISK_NS_11ComposeHashISK_EEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENS_22LookAheadComposeFilterINS_21SequenceComposeFilterINS_16LookAheadMatcherINS_3FstIS5_EEEESC_EESC_SC_LNS_9MatchTypeE2EEENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSI_EENS_21CompactHashStateTableISK_NS_11ComposeHashISK_EEEEEEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENS_22LookAheadComposeFilterINS_21SequenceComposeFilterINS_16LookAheadMatcherINS_3FstIS5_EEEESC_EESC_SC_LNS_9MatchTypeE2EEENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSI_EENS_21CompactHashStateTableISK_NS_11ComposeHashISK_EEEEEEEE
N3fst17StateIteratorBaseINS_6ArcTplINS_16LatticeWeightTplIfEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENS_17NullComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENS_18MatchComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENS_18MatchComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N6quasar18FilterBlockOptionsE
N6quasar25ConfiguredProcessingBlockINS_18FilterBlockOptionsEEE
N6quasar11FilterBlockE
N5kaldi5nnet113LstmComponentINS_12CuMatrixBaseIfEEEE
N5kaldi5nnet113LstmComponentINS_15QuantizedMatrixIaEEEE
N5kaldi5nnet113LstmComponentINS_15QuantizedMatrixIsEEEE
N6quasar9DecodableE
NSt3__120__shared_ptr_emplaceIN6quasar36OnlineDecodableMatrixScaledDecodableENS_9allocatorIS2_EEEE
N6quasar36OnlineDecodableMatrixScaledDecodableE
NSt3__120__shared_ptr_pointerIPN5kaldi27OnlineDecodableMatrixScaledENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN5kaldi27OnlineDecodableMatrixScaledEEE
NSt3__120__shared_ptr_emplaceIN6quasar42OnlineDecodableMatrixScaledMappedDecodableENS_9allocatorIS2_EEEE
N6quasar42OnlineDecodableMatrixScaledMappedDecodableE
NSt3__120__shared_ptr_emplaceIN5kaldi33OnlineDecodableMatrixScaledMappedENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar44OnlineDecodableMatrixScaledMappedTmDecodableENS_9allocatorIS2_EEEE
N6quasar44OnlineDecodableMatrixScaledMappedTmDecodableE
NSt3__120__shared_ptr_emplaceIN5kaldi35OnlineDecodableMatrixScaledMappedTmENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar39OnlineDecodableIdenticalMatrixDecodableENS_9allocatorIS2_EEEE
N6quasar39OnlineDecodableIdenticalMatrixDecodableE
NSt3__120__shared_ptr_pointerIPN5kaldi30OnlineDecodableIdenticalMatrixENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN5kaldi30OnlineDecodableIdenticalMatrixEEE
NSt3__120__shared_ptr_emplaceIN6quasar33OnlineDecodableNnet1LazyDecodableENS_9allocatorIS2_EEEE
N6quasar33OnlineDecodableNnet1LazyDecodableE
NSt3__120__shared_ptr_emplaceIN5kaldi5nnet18PdfPriorENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi24OnlineDecodableNnet1LazyENS_9allocatorIS2_EEEE
14StopNgramStats
10NgramStats
NSt3__118basic_stringstreamIcNS_11char_traitsIcEENS_9allocatorIcEEEE
N5kaldi5nnet121CnnRearrangeComponentE
N5kaldi5nnet116PaddingComponentE
N5kaldi5nnet118Padding2DComponentE
N5kaldi5nnet132ConvolutionalMaxPoolingComponentINS_12CuMatrixBaseIfEEEE
N5kaldi5nnet132ConvolutionalMaxPoolingComponentINS_15QuantizedMatrixIaEEEE
N5kaldi5nnet132ConvolutionalMaxPoolingComponentINS_15QuantizedMatrixIsEEEE
N6quasar12SystemConfigE
N5boost2io18basic_altstringbufIcNSt3__111char_traitsIcEENS2_9allocatorIcEEEE
N5boost16exception_detail10clone_implINS0_19error_info_injectorINS_2io17bad_format_stringEEEEE
N5boost16exception_detail19error_info_injectorINS_2io17bad_format_stringEEE
N5boost2io17bad_format_stringE
N5boost2io12format_errorE
N5boost16exception_detail10clone_implINS0_19error_info_injectorINS_2io13too_many_argsEEEEE
N5boost16exception_detail19error_info_injectorINS_2io13too_many_argsEEE
N5boost2io13too_many_argsE
N5boost2io22basic_oaltstringstreamIcNSt3__111char_traitsIcEENS2_9allocatorIcEEEE
N5boost16base_from_memberINS_10shared_ptrINS_2io18basic_altstringbufIcNSt3__111char_traitsIcEENS4_9allocatorIcEEEEEELi0EEE
N5boost6detail18sp_counted_impl_pdIPNS_2io18basic_altstringbufIcNSt3__111char_traitsIcEENS4_9allocatorIcEEEENS2_22basic_oaltstringstreamIcS6_S8_E5No_OpEEE
N5boost6detail15sp_counted_baseE
N5boost2io22basic_oaltstringstreamIcNSt3__111char_traitsIcEENS2_9allocatorIcEEE5No_OpE
N5boost16exception_detail10clone_implINS0_19error_info_injectorINS_2io12too_few_argsEEEEE
N5boost16exception_detail19error_info_injectorINS_2io12too_few_argsEEE
N5boost2io12too_few_argsE
N6quasar24ConfusionNetworkCombinerE
N6quasar14ResultCombinerE
N6quasar21RankingResultCombinerE
N6quasar13TextTokenizerE
N6quasar14BasicTokenizerE
N5kaldi27DecodableMatrixScaledMappedE
N5kaldi6quasar18SeevaStepInferenceE
N5kaldi6quasar24SeevaStepInferenceConfigE
N5kaldi6quasar20SeevaInferenceConfigE
N5boost9algorithm6detail13token_finderFINS1_10is_any_ofFIcEEEE
N5boost16exception_detail10clone_implINS0_19error_info_injectorINS_17bad_function_callEEEEE
N5boost16exception_detail19error_info_injectorINS_17bad_function_callEEE
N5boost17bad_function_callE
7LMStats
N6quasar20ExhaustiveEnumeratorE
?NSt3__119basic_ostringstreamIcNS_11char_traitsIcEENS_9allocatorIcEEEE
N3fst11ExpandedFstINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS5_9allocatorIfEEEEEEEEEE
N3fst3FstINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS5_9allocatorIfEEEEEEEEEE
N3fst10MemoryPoolINS_8DfsStateINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS6_9allocatorIfEEEEEEEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS7_9allocatorIfEEEEEEEEEEE4LinkEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS7_9allocatorIfEEEEEEEENS9_ISD_EEEEEENS_10MutableFstISD_EEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS7_9allocatorIfEEEEEEEENS9_ISD_EEEEEENS_10MutableFstISD_EEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS6_9allocatorIfEEEEEEEENS8_ISC_EEEEEE
N3fst12ArcPosingFstINS_6ArcTplINS_12LogWeightTplIfEEEENS1_INS_17TropicalWeightTplIfEEEEEE
N3fst3FstINS_6ArcTplINS_12LogWeightTplIfEEEEEE
N3fst17StateIteratorBaseINS_6ArcTplINS_12LogWeightTplIfEEEEEE
N3fst11ArcIteratorINS_12ArcPosingFstINS_6ArcTplINS_12LogWeightTplIfEEEENS2_INS_17TropicalWeightTplIfEEEEEEEE
N3fst10MutableFstINS_6ArcTplINS_12LogWeightTplIfEEEEEE
N3fst22MutableArcIteratorBaseINS_6ArcTplINS_12LogWeightTplIfEEEEEE
NSt3__119__deque_base_commonILb1EEE
N3fst9VectorFstINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_11VectorStateIS6_NSt3__19allocatorIS6_EEEEEE
N3fst11ExpandedFstINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENSt3__19allocatorIS7_EEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_24AltSequenceComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_18MatchComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst18ShortestFirstQueueIiNS_18StateWeightCompareIiNS_11NaturalLessINS_17TropicalWeightTplIfEEEEEELb0EEE
N3fst9ImplToFstINS_22DeterminizeFstImplBaseINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEENS_3FstIS7_EEEE
N6quasar16MultiAudioBufferE
N6quasar14NameEnumeratorE
N6quasar17RawCopyEnumeratorE
NSt3__120__shared_ptr_emplaceIN6quasar20SimpleNameEnumeratorENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar17RawCopyEnumeratorENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar20ExhaustiveEnumeratorENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar15RegexEnumeratorENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar25JapaneseDerivedEnumeratorENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar17DerivedEnumeratorENS_9allocatorIS2_EEEE
N5kaldi6quasar22ComputeEngineBufferItfE
N5kaldi6quasar16ComputeEngineItfE
N5kaldi6quasar22ComputeEngineConfigItfE
NSt3__110__function6__baseIFfNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEEEE
NSt3__110__function6__funcIZN5kaldi6quasar7AlignerINS3_20ConfusionNetworkSlotINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEEESB_EC1ENS_8functionIFfSC_SB_EEEEUlSC_E_NS9_ISH_EEFfSC_EEE
NSt3__110__function6__baseIFfN5kaldi6quasar20ConfusionNetworkSlotINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEEEEEE
ZN5kaldi6quasar7AlignerINS0_20ConfusionNetworkSlotINSt3__112basic_stringIcNS3_11char_traitsIcEENS3_9allocatorIcEEEEEES9_EC1ENS3_8functionIFfSA_S9_EEEEUlSA_E_
NSt3__110__function6__funcIZN5kaldi6quasar7AlignerINS3_20ConfusionNetworkSlotINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEEESB_EC1ENS_8functionIFfSC_SB_EEEEUlSB_E_NS9_ISH_EEFfSB_EEE
ZN5kaldi6quasar7AlignerINS0_20ConfusionNetworkSlotINSt3__112basic_stringIcNS3_11char_traitsIcEENS3_9allocatorIcEEEEEES9_EC1ENS3_8functionIFfSA_S9_EEEEUlS9_E_
N6quasar18InputHammerOptionsE
N6quasar25ConfiguredProcessingBlockINS_18InputHammerOptionsEEE
N6quasar16InputHammerBlockE
NSt3__120__shared_ptr_emplaceIN5kaldi17LatticeScoreCacheENS_9allocatorIS2_EEEE
N5sdapi14SdapiTokenizerE
N5kaldi26ContextDependencyInterfaceE
N5kaldi18DecodableInterfaceE
N5kaldi21E2EDecodableInterfaceE
N5kaldi10OptionsItfE
N5kaldi17FeedForwardNetItfE
N5kaldi15InferenceNetItfE
N5kaldi20EncoderDecoderNetItfE
N6quasar16BitmapLoaderImplE
14_LM_FollowIter
NSt3__120__shared_ptr_emplaceI8WordInfoNS_9allocatorIS1_EEEE
N6quasar10OVSFeatureE
N6quasar23QualityEstimatorFeatureE
N6quasar17RepetitionFeatureE
N6quasar13LengthFeatureE
NSt3__120__shared_ptr_emplaceIN6quasar10OVSFeatureENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar17RepetitionFeatureENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar13LengthFeatureENS_9allocatorIS2_EEEE
N6quasar31OnlineLatticeBiglmFasterDecoderE
N3fst10MutableFstINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEE
NSt3__120__shared_ptr_emplaceIN3fst9VectorFstINS1_6ArcTplINS1_23CompactLatticeWeightTplINS1_16LatticeWeightTplIfEEiEEEENS1_11VectorStateIS8_NS_9allocatorIS8_EEEEEENSA_ISD_EEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEENS_11VectorStateIS7_NSt3__19allocatorIS7_EEEEEEEE
N3fst22MutableArcIteratorBaseINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEE
NSt3__110__function6__funcIZN6quasar31OnlineLatticeBiglmFasterDecoder26doEverythingWithRawLatticeERNS2_15DecoderPassDataERKNS_10shared_ptrINS2_18DecoderChainOutputEEERKNS6_INS2_17SpeechRequestDataEEERKN5kaldi6quasar37OnlineLatticeBiglmFasterDecoderConfigERKNS_6atomicIbEEE3$_0NS_9allocatorISO_EEFbvEEE
ZN6quasar31OnlineLatticeBiglmFasterDecoder26doEverythingWithRawLatticeERNS_15DecoderPassDataERKNSt3__110shared_ptrINS_18DecoderChainOutputEEERKNS4_INS_17SpeechRequestDataEEERKN5kaldi6quasar37OnlineLatticeBiglmFasterDecoderConfigERKNS3_6atomicIbEEE3$_0
NSt3__120__shared_ptr_pointerIPN3fst9VectorFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEENS1_11VectorStateIS6_NS_9allocatorIS6_EEEEEENS_14default_deleteISB_EENS8_ISB_EEEE
NSt3__114default_deleteIN3fst9VectorFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEENS1_11VectorStateIS6_NS_9allocatorIS6_EEEEEEEE
NSt3__120__shared_ptr_emplaceIN6quasar23StateAccessRecordingFstENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar21LRStreamingConfidenceENS_9allocatorIS2_EEEE
N3fst14ReplaceFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_24DefaultReplaceStateTableIS4_lEENS_17DefaultCacheStoreIS4_EEEE
N3fst13CacheBaseImplINS_10CacheStateINS_6ArcTplINS_17TropicalWeightTplIfEEEENSt3__19allocatorIS5_EEEENS_17DefaultCacheStoreIS5_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar13EagerDecisionENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar31OnlineLatticeBiglmFasterDecoder23LatticeGenerationOutputENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceINS_6vectorINS_4pairIPN3fst24DeterministicOnDemandFstINS3_6ArcTplINS3_17TropicalWeightTplIfEEEEEEfEENS_9allocatorISB_EEEENSC_ISE_EEEE
NSt3__120__shared_ptr_emplaceIN3fst35InterpolateDeterministicOnDemandFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEEEENS_9allocatorIS7_EEEE
NSt3__120__shared_ptr_emplaceIN3fst7ArcInfoENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN3fst35LeftContextDeterministicOnDemandFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEEEENS_9allocatorIS7_EEEE
N3fst35LeftContextDeterministicOnDemandFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N3fst31ComposeDeterministicOnDemandFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_24DeterministicOnDemandFstIS4_EES6_EE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar31OnlineLatticeBiglmFasterDecoderIN3fst3FstINS4_6ArcTplINS4_17TropicalWeightTplIfEEEEEENS4_29CacheDeterministicOnDemandFstIS9_NS4_24DeterministicOnDemandFstIS9_EEEEEENS_9allocatorISF_EEEE
N5kaldi6quasar31OnlineLatticeBiglmFasterDecoderIN3fst3FstINS2_6ArcTplINS2_17TropicalWeightTplIfEEEEEENS2_29CacheDeterministicOnDemandFstIS7_NS2_24DeterministicOnDemandFstIS7_EEEEEE
N5kaldi6quasar34LatticeBiglmFasterTraceBackDecoderIN3fst3FstINS2_6ArcTplINS2_17TropicalWeightTplIfEEEEEENS2_29CacheDeterministicOnDemandFstIS7_NS2_24DeterministicOnDemandFstIS7_EEEEEE
N5kaldi6quasar9TokenHeap5TokenE
N5kaldi6quasar9TokenHeap11ForwardLinkE
NSt3__117bad_function_callE
NSt3__120__shared_ptr_emplaceIN6quasar31OnlineLatticeBiglmFasterDecoder24LatticeGenerationContextENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar15DecoderPassDataENS_9allocatorIS2_EEEE
N6quasar23StateAccessRecordingFstE
N6quasar34StateAccessRecordingFstArcIteratorE
N6quasar25AmbiguityAnnotatorOptionsE
N6quasar25ConfiguredProcessingBlockINS_25AmbiguityAnnotatorOptionsEEE
N6quasar23AmbiguityAnnotatorBlockE
NSt3__110__function6__funcIZN6quasar23AmbiguityAnnotatorBlock16MatchSpanCompareEbbE3$_0NS_9allocatorIS4_EEFbRKNS3_9MatchSpanES9_EEE
NSt3__110__function6__baseIFbRKN6quasar23AmbiguityAnnotatorBlock9MatchSpanES6_EEE
ZN6quasar23AmbiguityAnnotatorBlock16MatchSpanCompareEbbE3$_0
NSt3__110__function6__funcIZN6quasar23AmbiguityAnnotatorBlock16MatchSpanCompareEbbE3$_1NS_9allocatorIS4_EEFbRKNS3_9MatchSpanES9_EEE
ZN6quasar23AmbiguityAnnotatorBlock16MatchSpanCompareEbbE3$_1
NSt3__110__function6__funcIZN6quasar23AmbiguityAnnotatorBlock16MatchSpanCompareEbbE3$_2NS_9allocatorIS4_EEFbRKNS3_9MatchSpanES9_EEE
ZN6quasar23AmbiguityAnnotatorBlock16MatchSpanCompareEbbE3$_2
NSt3__110__function6__funcIZN6quasar23AmbiguityAnnotatorBlock16MatchSpanCompareEbbE3$_3NS_9allocatorIS4_EEFbRKNS3_9MatchSpanES9_EEE
ZN6quasar23AmbiguityAnnotatorBlock16MatchSpanCompareEbbE3$_3
.N5kaldi6quasar18TooManyTokensErrorE
N5kaldi6quasar24TooManyForwardLinksErrorE
NSt3__120__shared_ptr_emplaceIN6quasar11ClassLmPlugENS_9allocatorIS2_EEEE
?N5kaldi5nnet19ComponentE
N5kaldi5nnet118UpdatableComponentE
N5kaldi5nnet119HistoricalComponentE
N5kaldi5nnet122RecurrentBaseComponentE
N5kaldi5nnet122AttentionBaseComponentE
N5kaldi5nnet131RecurrentAttentionBaseComponentE
N5kaldi5nnet131AttentionBaseInferenceComponentE
N5kaldi5nnet127Quantizable8BitComponentItfE
N5kaldi5nnet128Quantizable16BitComponentItfE
N5kaldi5nnet117Nnet1InferenceNetE
N5kaldi5nnet114RelaxedSoftmaxE
N5kaldi5nnet110LogSoftmaxE
N5kaldi5nnet17SoftmaxE
N5kaldi5nnet112BlockSoftmaxE
N5kaldi5nnet17SigmoidE
N5kaldi5nnet14TanhE
N5kaldi5nnet17DropoutE
N5kaldi5nnet115MaxoutComponentE
N5kaldi5nnet114PNormComponentE
N5kaldi5nnet124RectifiedLinearComponentE
N5kaldi5nnet126ExponentialLinearComponentE
N5kaldi5nnet132ScaledExponentialLinearComponentE
N5kaldi5nnet15KlHmmE
N5kaldi5nnet16SpliceE
N5kaldi5nnet113CopyComponentE
N5kaldi5nnet117IdentityComponentE
N5kaldi5nnet118DuplicateComponentE
N5kaldi5nnet18AddShiftE
N5kaldi5nnet17RescaleE
N5kaldi5nnet137VectorwiseQuantizable8BitComponentItfE
N5kaldi5nnet17RbmBaseE
N5kaldi5nnet13RbmE
N5kaldi5nnet112MultiSoftmaxE
N5kaldi5nnet19RecurrentE
N5kaldi5nnet122ConvolutionalComponentE
N5kaldi5nnet123AveragePoolingComponentE
N5kaldi5nnet119MaxPoolingComponentE
N5kaldi5nnet127TemporalMaxPoolingComponentE
N5kaldi5nnet125AveragePooling2DComponentE
N5kaldi5nnet121MaxPooling2DComponentE
N5kaldi5nnet18DespliceE
N5kaldi5nnet126SentenceAveragingComponentE
N5kaldi5nnet121FramePoolingComponentE
N5kaldi5nnet117ParallelComponentE
N5kaldi5nnet122InterpolationComponentE
N5kaldi5nnet126CompressedWordVecComponentE
N5kaldi5nnet124CompressibleComponentItfE
N5kaldi5nnet116WordVecComponentE
N5kaldi5nnet120FofeWordVecComponentE
N5kaldi5nnet118SharedNceComponentE
N5kaldi5nnet128CompressedWordTransComponentE
N5kaldi5nnet134VectorwiseQuantizedAffineTransformIaEE
N5kaldi5nnet134VectorwiseQuantizedAffineTransformIsEE
N6quasar20SentencePieceOptionsE
N6quasar25ConfiguredProcessingBlockINS_20SentencePieceOptionsEEE
N6quasar18SentencePieceBlockE
NSt3__120__shared_ptr_pointerIPN13sentencepiece22SentencePieceProcessorENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN13sentencepiece22SentencePieceProcessorEEE
N6quasar17LmeWordTaggerBaseE
N6quasar22IndexRuleLmeWordTaggerE
11TaggedVocab
p}?N6quasar17DerivedEnumeratorE
N6quasar17DerivedEnumerator9AlgorithmE
N6quasar15EnLikeAlgorithmE
N6quasar15ZhLikeAlgorithmE
N3fst9ImplToFstINS_18ComposeFstImplBaseINS_6ArcTplINS_12LogWeightTplIfEEEENS_17DefaultCacheStoreIS5_EEEENS_3FstIS5_EEEE
N3fst10MemoryPoolINS_8DfsStateINS_6ArcTplINS_12LogWeightTplIfEEEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_6ArcTplINS_12LogWeightTplIfEEEEEEE4LinkEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_12LogWeightTplIfEEEENSt3__19allocatorIS6_EEEEEENS_10MutableFstIS6_EEEE
N3fst11ExpandedFstINS_6ArcTplINS_12LogWeightTplIfEEEEEE
N3fst9ImplToFstINS_22DeterminizeFstImplBaseINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_3FstIS5_EEEE
N3fst10ComposeFstINS_6ArcTplINS_12LogWeightTplIfEEEENS_17DefaultCacheStoreIS4_EEEE
N3fst13SortedMatcherINS_3FstINS_6ArcTplINS_12LogWeightTplIfEEEEEEEE
N3fst11MatcherBaseINS_6ArcTplINS_12LogWeightTplIfEEEEEE
N3fst10MemoryPoolINS_11ArcIteratorINS_3FstINS_6ArcTplINS_12LogWeightTplIfEEEEEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_11ArcIteratorINS_3FstINS_6ArcTplINS_12LogWeightTplIfEEEEEEEEE4LinkEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_12LogWeightTplIfEEEEEENS_21SequenceComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst18ComposeFstImplBaseINS_6ArcTplINS_12LogWeightTplIfEEEENS_17DefaultCacheStoreIS4_EEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_12LogWeightTplIfEEEEEENS_21SequenceComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_12LogWeightTplIfEEEEEENS_23PushLabelsComposeFilterINS_24PushWeightsComposeFilterINS_22LookAheadComposeFilterINS_24AltSequenceComposeFilterINS_16LookAheadMatcherINS_3FstIS5_EEEESE_EESE_SE_LNS_9MatchTypeE2EEESE_SE_LSG_2EEESE_SE_LSG_2EEENS_24GenericComposeStateTableIS5_NS_15PairFilterStateINSL_INS_18IntegerFilterStateIaEENS_17WeightFilterStateIS4_EEEENSM_IiEEEENS_24DefaultComposeStateTupleIiSS_EENS_21CompactHashStateTableISU_NS_11ComposeHashISU_EEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_12LogWeightTplIfEEEEEENS_23PushLabelsComposeFilterINS_24PushWeightsComposeFilterINS_22LookAheadComposeFilterINS_21SequenceComposeFilterINS_16LookAheadMatcherINS_3FstIS5_EEEESE_EESE_SE_LNS_9MatchTypeE2EEESE_SE_LSG_2EEESE_SE_LSG_2EEENS_24GenericComposeStateTableIS5_NS_15PairFilterStateINSL_INS_18IntegerFilterStateIaEENS_17WeightFilterStateIS4_EEEENSM_IiEEEENS_24DefaultComposeStateTupleIiSS_EENS_21CompactHashStateTableISU_NS_11ComposeHashISU_EEEEEEEE
N3fst13StateIteratorINS_10ComposeFstINS_6ArcTplINS_12LogWeightTplIfEEEENS_17DefaultCacheStoreIS5_EEEEEE
N3fst18CacheStateIteratorINS_10ComposeFstINS_6ArcTplINS_12LogWeightTplIfEEEENS_17DefaultCacheStoreIS5_EEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_12LogWeightTplIfEEEEEENS_17NullComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_12LogWeightTplIfEEEEEENS_17NullComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_12LogWeightTplIfEEEEEENS_24AltSequenceComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_12LogWeightTplIfEEEEEENS_24AltSequenceComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_12LogWeightTplIfEEEEEENS_18MatchComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_12LogWeightTplIfEEEEEENS_18MatchComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_12LogWeightTplIfEEEEEENSt3__19allocatorIS8_EEEEEENS_10MutableFstIS8_EEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_12LogWeightTplIfEEEEEENSt3__19allocatorIS8_EEEEEENS_10MutableFstIS8_EEEE
N3fst11ExpandedFstINS_10ReverseArcINS_6ArcTplINS_12LogWeightTplIfEEEEEEEE
N3fst3FstINS_10ReverseArcINS_6ArcTplINS_12LogWeightTplIfEEEEEEEE
N3fst10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_6ArcTplINS_12LogWeightTplIfEEEEEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_6ArcTplINS_12LogWeightTplIfEEEEEEEEE4LinkEEE
N3fst15ArcIteratorBaseINS_10ReverseArcINS_6ArcTplINS_12LogWeightTplIfEEEEEEEE
N3fst9VectorFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEENS_11VectorStateIS7_NSt3__19allocatorIS7_EEEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEENSt3__19allocatorIS9_EEEEEENS_10MutableFstIS9_EEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEENSt3__19allocatorIS9_EEEEEENS_10MutableFstIS9_EEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEENSt3__19allocatorIS9_EEEEEENS_10MutableFstIS9_EEEE
N3fst10MutableFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEE
N3fst11ExpandedFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEE
N3fst3FstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEE
N3fst13VectorFstImplINS_11VectorStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEENSt3__19allocatorIS8_EEEEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEENSt3__19allocatorIS8_EEEEEE
N3fst7FstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEE
N3fst10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEEE4LinkEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEENS_11VectorStateIS8_NSt3__19allocatorIS8_EEEEEEEE
N3fst22MutableArcIteratorBaseINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEE
N3fst15ArcIteratorBaseINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEE
N3fst9VectorFstINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEENS_11VectorStateIS9_NSt3__19allocatorIS9_EEEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEENSt3__19allocatorISB_EEEEEENS_10MutableFstISB_EEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEENSt3__19allocatorISB_EEEEEENS_10MutableFstISB_EEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEENSt3__19allocatorISB_EEEEEENS_10MutableFstISB_EEEE
N3fst10MutableFstINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEEEE
N3fst11ExpandedFstINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEEEE
N3fst3FstINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEEEE
N3fst13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEENSt3__19allocatorISA_EEEEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEENSt3__19allocatorISA_EEEEEE
N3fst7FstImplINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEEEE
N3fst10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEEEEE4LinkEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEENS_11VectorStateISA_NSt3__19allocatorISA_EEEEEEEE
N3fst22MutableArcIteratorBaseINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEEEE
N3fst15ArcIteratorBaseINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEEEE
N3fst9ArcMapFstINS_6ArcTplINS_12LogWeightTplIfEEEES4_NS_14RmWeightMapperIS4_S4_EEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_6ArcTplINS_12LogWeightTplIfEEEES5_NS_14RmWeightMapperIS5_S5_EEEENS_3FstIS5_EEEE
N3fst13ArcMapFstImplINS_6ArcTplINS_12LogWeightTplIfEEEES4_NS_14RmWeightMapperIS4_S4_EEEE
N3fst9ArcMapFstINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE1EEENS_14ToGallicMapperIS4_LS6_1EEEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE1EEENS_14ToGallicMapperIS5_LS7_1EEEEENS_3FstIS8_EEEE
N3fst13ArcMapFstImplINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE1EEENS_14ToGallicMapperIS4_LS6_1EEEEE
N3fst9CacheImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEE
N3fst13CacheBaseImplINS_10CacheStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEENSt3__19allocatorIS8_EEEENS_17DefaultCacheStoreIS8_EEEE
N3fst13StateIteratorINS_9ArcMapFstINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE1EEENS_14ToGallicMapperIS5_LS7_1EEEEEEE
N3fst17StateIteratorBaseINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEE
N3fst15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEENS_12GallicFactorIiS4_LS6_1EEEEE
N3fst9ImplToFstINS_19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEENS_12GallicFactorIiS5_LS7_1EEEEENS_3FstIS8_EEEE
N3fst19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEENS_12GallicFactorIiS4_LS6_1EEEEE
N3fst13StateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEENS_12GallicFactorIiS5_LS7_1EEEEEEE
N3fst18CacheStateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEENS_12GallicFactorIiS5_LS7_1EEEEEEE
N3fst12SigmaMatcherINS_13SortedMatcherINS_3FstINS_6ArcTplINS_12LogWeightTplIfEEEEEEEEEE
N3fst10RhoMatcherINS_12SigmaMatcherINS_13SortedMatcherINS_3FstINS_6ArcTplINS_12LogWeightTplIfEEEEEEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_12LogWeightTplIfEEEEEENS_21SequenceComposeFilterINS_10RhoMatcherINS_12SigmaMatcherINS_13SortedMatcherINS_3FstIS5_EEEEEEEESF_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSJ_EENS_21CompactHashStateTableISL_NS_11ComposeHashISL_EEEEEEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_12LogWeightTplIfEEEEEENS_21SequenceComposeFilterINS_10RhoMatcherINS_12SigmaMatcherINS_13SortedMatcherINS_3FstIS5_EEEEEEEESF_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSJ_EENS_21CompactHashStateTableISL_NS_11ComposeHashISL_EEEEEEEE
N3fst12SigmaMatcherINS_13SortedMatcherINS_3FstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEEEE
N3fst10ComposeFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_17DefaultCacheStoreIS4_EEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_21SequenceComposeFilterINS_12SigmaMatcherINS_13SortedMatcherINS_3FstIS5_EEEEEESD_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSH_EENS_21CompactHashStateTableISJ_NS_11ComposeHashISJ_EEEEEEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_21SequenceComposeFilterINS_12SigmaMatcherINS_13SortedMatcherINS_3FstIS5_EEEEEESD_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSH_EENS_21CompactHashStateTableISJ_NS_11ComposeHashISJ_EEEEEEEE
N3fst18CacheStateIteratorINS_10ComposeFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_17DefaultCacheStoreIS5_EEEEEE
N3fst14DeterminizeFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N3fst18DeterminizeFsaImplINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_20DefaultCommonDivisorIS3_EENS_24DefaultDeterminizeFilterIS4_EENS_28DefaultDeterminizeStateTableIS4_NS_18IntegerFilterStateIaEEEEEE
N3fst22DeterminizeFstImplBaseINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N3fst9CacheImplINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N3fst18DeterminizeFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3ENS_20DefaultCommonDivisorIS3_EENS_24DefaultDeterminizeFilterIS4_EENS_28DefaultDeterminizeStateTableIS4_NS_18IntegerFilterStateIaEEEEEE
N3fst13StateIteratorINS_14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEEEEEE
N3fst18CacheStateIteratorINS_14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEEEEEE
N3fst15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEENS_12GallicFactorIiS4_LS6_3EEEEE
N3fst9ImplToFstINS_19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEENS_12GallicFactorIiS5_LS7_3EEEEENS_3FstIS8_EEEE
N3fst19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEENS_12GallicFactorIiS4_LS6_3EEEEE
N3fst13StateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEENS_12GallicFactorIiS5_LS7_3EEEEEEE
N3fst18CacheStateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEENS_12GallicFactorIiS5_LS7_3EEEEEEE
N3fst9ArcMapFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEES5_NS_16FromGallicMapperIS5_LS6_3EEEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEES6_NS_16FromGallicMapperIS6_LS7_3EEEEENS_3FstIS6_EEEE
N3fst13ArcMapFstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEES5_NS_16FromGallicMapperIS5_LS6_3EEEEE
N3fst13StateIteratorINS_9ArcMapFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEES6_NS_16FromGallicMapperIS6_LS7_3EEEEEEE
N3fst18DeterminizeFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2ENS_20DefaultCommonDivisorIS3_EENS_24DefaultDeterminizeFilterIS4_EENS_28DefaultDeterminizeStateTableIS4_NS_18IntegerFilterStateIaEEEEEE
N3fst9ArcMapFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE2EEENS_14ToGallicMapperIS4_LS6_2EEEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE2EEENS_14ToGallicMapperIS5_LS7_2EEEEENS_3FstIS8_EEEE
N3fst3FstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEEEE
N3fst13ArcMapFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE2EEENS_14ToGallicMapperIS4_LS6_2EEEEE
N3fst9CacheImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEEEE
N3fst13CacheBaseImplINS_10CacheStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEENSt3__19allocatorIS8_EEEENS_17DefaultCacheStoreIS8_EEEE
N3fst7FstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEEEE
N3fst10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEEEEE4LinkEEE
N3fst13StateIteratorINS_9ArcMapFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE2EEENS_14ToGallicMapperIS5_LS7_2EEEEEEE
N3fst17StateIteratorBaseINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEEEE
N3fst14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEEEE
N3fst9ImplToFstINS_22DeterminizeFstImplBaseINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEEEENS_3FstIS8_EEEE
N3fst18DeterminizeFsaImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEENS_19GallicCommonDivisorIiS4_LS6_2ENS_20DefaultCommonDivisorIS4_EEEENS_24DefaultDeterminizeFilterIS7_EENS_28DefaultDeterminizeStateTableIS7_NS_18IntegerFilterStateIaEEEEEE
N3fst22DeterminizeFstImplBaseINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEEEE
N3fst13StateIteratorINS_14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEEEEEE
N3fst18CacheStateIteratorINS_14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEEEEEE
N3fst15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEENS_12GallicFactorIiS4_LS6_2EEEEE
N3fst9ImplToFstINS_19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEENS_12GallicFactorIiS5_LS7_2EEEEENS_3FstIS8_EEEE
N3fst19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEENS_12GallicFactorIiS4_LS6_2EEEEE
N3fst13StateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEENS_12GallicFactorIiS5_LS7_2EEEEEEE
N3fst18CacheStateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEENS_12GallicFactorIiS5_LS7_2EEEEEEE
N3fst9ArcMapFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEES5_NS_16FromGallicMapperIS5_LS6_2EEEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEES6_NS_16FromGallicMapperIS6_LS7_2EEEEENS_3FstIS6_EEEE
N3fst13ArcMapFstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEES5_NS_16FromGallicMapperIS5_LS6_2EEEEE
N3fst13StateIteratorINS_9ArcMapFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEES6_NS_16FromGallicMapperIS6_LS7_2EEEEEEE
N3fst18DeterminizeFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4ENS_20DefaultCommonDivisorIS3_EENS_24DefaultDeterminizeFilterIS4_EENS_28DefaultDeterminizeStateTableIS4_NS_18IntegerFilterStateIaEEEEEE
N3fst9ArcMapFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE4EEENS_14ToGallicMapperIS4_LS6_4EEEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE4EEENS_14ToGallicMapperIS5_LS7_4EEEEENS_3FstIS8_EEEE
N3fst3FstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEEEE
N3fst13ArcMapFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE4EEENS_14ToGallicMapperIS4_LS6_4EEEEE
N3fst9CacheImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEEEE
N3fst13CacheBaseImplINS_10CacheStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEENSt3__19allocatorIS8_EEEENS_17DefaultCacheStoreIS8_EEEE
N3fst7FstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEEEE
N3fst10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEEEEE4LinkEEE
N3fst13StateIteratorINS_9ArcMapFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE4EEENS_14ToGallicMapperIS5_LS7_4EEEEEEE
N3fst17StateIteratorBaseINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEEEE
N3fst14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEEEE
N3fst9ImplToFstINS_22DeterminizeFstImplBaseINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEEEENS_3FstIS8_EEEE
N3fst18DeterminizeFsaImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEENS_19GallicCommonDivisorIiS4_LS6_4ENS_20DefaultCommonDivisorIS4_EEEENS_24DefaultDeterminizeFilterIS7_EENS_28DefaultDeterminizeStateTableIS7_NS_18IntegerFilterStateIaEEEEEE
N3fst22DeterminizeFstImplBaseINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEEEE
N3fst13StateIteratorINS_14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEEEEEE
N3fst18CacheStateIteratorINS_14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEEEEEE
N3fst15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEENS_12GallicFactorIiS4_LS6_4EEEEE
N3fst9ImplToFstINS_19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEENS_12GallicFactorIiS5_LS7_4EEEEENS_3FstIS8_EEEE
N3fst19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEENS_12GallicFactorIiS4_LS6_4EEEEE
N3fst13StateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEENS_12GallicFactorIiS5_LS7_4EEEEEEE
N3fst18CacheStateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEENS_12GallicFactorIiS5_LS7_4EEEEEEE
N3fst9ArcMapFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEES5_NS_16FromGallicMapperIS5_LS6_4EEEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEES6_NS_16FromGallicMapperIS6_LS7_4EEEEENS_3FstIS6_EEEE
N3fst13ArcMapFstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEES5_NS_16FromGallicMapperIS5_LS6_4EEEEE
N3fst13StateIteratorINS_9ArcMapFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEES6_NS_16FromGallicMapperIS6_LS7_4EEEEEEE
N3fst18CacheStateIteratorINS_14DeterminizeFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEE
N3fst9VectorFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEENS_11VectorStateIS7_NSt3__19allocatorIS7_EEEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEENSt3__19allocatorIS9_EEEEEENS_10MutableFstIS9_EEEE
N3fst10MutableFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N3fst13VectorFstImplINS_11VectorStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEENSt3__19allocatorIS8_EEEEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEENSt3__19allocatorIS8_EEEEEE
N3fst7FstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N3fst15ArcIteratorBaseINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N3fst9VectorFstINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEENS_11VectorStateIS9_NSt3__19allocatorIS9_EEEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEENSt3__19allocatorISB_EEEEEENS_10MutableFstISB_EEEE
N3fst10MutableFstINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEEEE
N3fst13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEENSt3__19allocatorISA_EEEEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEENSt3__19allocatorISA_EEEEEE
N3fst7FstImplINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEEEE
N3fst15ArcIteratorBaseINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEEEE
N3fst15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEENS_12GallicFactorIiS4_LS6_0EEEEE
N3fst9ImplToFstINS_19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEENS_12GallicFactorIiS5_LS7_0EEEEENS_3FstIS8_EEEE
N3fst13CacheBaseImplINS_10CacheStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEENSt3__19allocatorIS8_EEEENS_17DefaultCacheStoreIS8_EEEE
N3fst18CacheStateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEENS_12GallicFactorIiS5_LS7_0EEEEEEE
N3fst17StateIteratorBaseINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N6quasar27OnlineSeevaStepBigLmDecoderE
N5kaldi6quasar26SeevaStepLmInferenceConfigE
N5kaldi12CuMatrixBaseIfEE
NSt3__120__shared_ptr_emplaceIN3fst31BackoffDeterministicOnDemandFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEENS1_3FstIS6_EEEENS_9allocatorIS9_EEEE
NSt3__120__shared_ptr_emplaceIN3fst14BackoffArcInfoENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar31DeterministicOnDemandFstCreatorIN3fst6ArcTplINS4_17TropicalWeightTplIfEEEEEENS_9allocatorIS9_EEEE
N3fst18CacheStateIteratorINS_10ReplaceFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_24DefaultReplaceStateTableIS5_lEENS_17DefaultCacheStoreIS5_EEEEEE
N3fst13SortedMatcherINS_10ReplaceFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_24DefaultReplaceStateTableIS5_lEENS_17DefaultCacheStoreIS5_EEEEEE
N5kaldi6quasar27NeuralNgramDeterministicFstIN3fst6ArcTplINS2_17TropicalWeightTplIfEEEEEE
N3fst35InterpolateDeterministicOnDemandFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
NSt3__120__shared_ptr_emplaceIN3fst31ComposeDeterministicOnDemandFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEENS1_24DeterministicOnDemandFstIS6_EES8_EENS_9allocatorIS9_EEEE
NSt3__120__shared_ptr_emplaceIN3fst29CacheDeterministicOnDemandFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEENS1_24DeterministicOnDemandFstIS6_EEEENS_9allocatorIS9_EEEE
N6quasar26OnlineLASBeamSearchDecoderE
NSt3__120__shared_ptr_emplaceIN3fst9VectorFstINS1_6ArcTplINS1_16LatticeWeightTplIfEEEENS1_11VectorStateIS6_NS_9allocatorIS6_EEEEEENS8_ISB_EEEE
N3fst18ShortestFirstQueueIiNS_18StateWeightCompareIiNS_11NaturalLessINS_16LatticeWeightTplIfEEEEEELb0EEE
N3fst9ImplToFstINS_22DeterminizeFstImplBaseINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEENS_3FstIS7_EEEE
N3fst18DeterminizeFsaImplINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENS_20DefaultCommonDivisorIS4_EENS_24DefaultDeterminizeFilterIS6_EENS_28DefaultDeterminizeStateTableIS6_NS_18IntegerFilterStateIaEEEEEE
N3fst9CacheImplINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEE
NSt3__120__shared_ptr_emplaceIN6quasar25ConcreteSpeechRequestDataENS_9allocatorIS2_EEEE
N6quasar13WordPronCacheE
N6quasar7LmeDataE
NSt3__120__shared_ptr_pointerIPN3fst11SymbolTableENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
N6quasar22SpeechRecognizerConfig23UnsupportedVersionErrorE
N6quasar16SpeechRecognizerE
NSt3__123enable_shared_from_thisIN6quasar16SpeechRecognizerEEE
NSt3__120__shared_ptr_emplaceINS_5mutexENS_9allocatorIS1_EEEE
N6quasar16SpeechRecognizer25ModelLoaderFactoryAdapterE
N6quasar27SpeechRecognizerModelLoader7FactoryE
NSt3__120__shared_ptr_emplaceIN6quasar19SpeakerCodeTrainingENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_pointerIPN6quasar26DecoderChainPersistentDataENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN6quasar26DecoderChainPersistentDataEEE
N5kaldi8CuMatrixIfEE
NSt3__120__shared_ptr_pointerIPN6quasar16SpeechRecognizerENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN6quasar16SpeechRecognizerEEE
NSt3__110__function6__funcINS_6__bindIMN6quasar16SpeechRecognizerEFbvEJPS4_EEENS_9allocatorIS8_EEFbvEEE
NSt3__110__function6__baseIFbvEEE
NSt3__16__bindIMN6quasar16SpeechRecognizerEFbvEJPS2_EEE
NSt3__118__weak_result_typeIMN6quasar16SpeechRecognizerEFbvEEE
NSt3__114unary_functionIPN6quasar16SpeechRecognizerEbEE
NSt3__120__shared_ptr_emplaceIN6quasar21ConfusionNetworkCacheENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar25SpeakerCodeTrainingConfigENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar16MultiAudioBufferENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi20OnlineBufferingInputENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar18OnlineCacheInputFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceINS_5queueIN5kaldi8CuMatrixIfEENS_5dequeIS4_NS_9allocatorIS4_EEEEEENS6_IS9_EEEE
NSt3__120__shared_ptr_emplaceIjNS_9allocatorIjEEEE
NSt3__120__shared_ptr_emplaceIN5kaldi19OnlineFeatureMatrixENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar25SilencePosteriorGeneratorENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar22ResultStreamStabilizerENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar5PTreeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar15SyncRecogResultENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar20SyncRecogAudioBufferENS_9allocatorIS2_EEEE
NSt3__110__function6__baseIFfffEEE
NSt3__110__function6__funcIN5kaldi6quasar19ConfusionNetworkArcINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEEUlffE_ENS8_ISC_EEFfffEEE
N5kaldi6quasar19ConfusionNetworkArcINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEEUlffE_E
NSt3__110__function6__funcIZN5kaldi6quasar16ConfusionNetworkINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEE9ConstructEvEUlNS3_20ConfusionNetworkSlotISA_EESA_E_NS8_ISE_EEFfSD_SA_EEE
NSt3__110__function6__baseIFfN5kaldi6quasar20ConfusionNetworkSlotINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEEESA_EEE
ZN5kaldi6quasar16ConfusionNetworkINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEE9ConstructEvEUlNS0_20ConfusionNetworkSlotIS8_EES8_E_
N6quasar27SpeechRecognizerModelLoader14DefaultFactoryE
NSt3__120__shared_ptr_emplaceIN6quasar20RecognizerComponentsINS1_7DecoderEEENS_9allocatorIS4_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar31SilencePosteriorGeneratorConfigENS_9allocatorIS2_EEEE
N6quasar15RegexEnumeratorE
NSt3__120__shared_ptr_emplaceIN6quasar11ReplaceStepENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar9SplitStepENS_9allocatorIS2_EEEE
?N6quasar14QuasarTextProcE
N3fst12ConstFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEEjEE
NSt3__120__shared_ptr_pointerIPN3fst8ConstFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEEjEENS_14default_deleteIS7_EENS_9allocatorIS7_EEEE
NSt3__114default_deleteIN3fst8ConstFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEEjEEEE
NSt3__120__shared_ptr_emplaceIN6quasar21InverseTextNormalizerENS_9allocatorIS2_EEEE
N5kaldi18OnlineFeatInputItfE
N5kaldi15OnlineCmvnInputE
N5kaldi14OnlineCmnInputE
N5kaldi16OnlineCacheInputE
N5kaldi19OnlineRecordedInputE
N5kaldi17OnlineSpliceInputE
N5kaldi22OnlineSpliceBatchInputE
N5kaldi22OnlineNnetForwardInputE
N5kaldi29OnlineNnetForwardSkippedInputE
N5kaldi17OnlineAppendInputE
N5kaldi17OnlineSubsampleFeE
N5kaldi14OnlineLdaInputE
N5kaldi20OnlineTransformInputE
N5kaldi20OnlineBufferingInputE
N5kaldi14OnlinePadInputE
N5kaldi16OnlineDeltaInputE
N6quasar28OnlineKeywordSpottingDecoderE
NSt3__113basic_fstreamIcNS_11char_traitsIcEEEE
9StopNgram
N3fst9VectorFstINS_10ReverseArcINS_6ArcTplINS_12LogWeightTplIfEEEEEENS_11VectorStateIS6_NSt3__19allocatorIS6_EEEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_12LogWeightTplIfEEEEEENSt3__19allocatorIS8_EEEEEENS_10MutableFstIS8_EEEE
N3fst10MutableFstINS_10ReverseArcINS_6ArcTplINS_12LogWeightTplIfEEEEEEEE
N3fst13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_12LogWeightTplIfEEEEEENSt3__19allocatorIS7_EEEEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_12LogWeightTplIfEEEEEENSt3__19allocatorIS7_EEEEEE
N3fst7FstImplINS_10ReverseArcINS_6ArcTplINS_12LogWeightTplIfEEEEEEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_10ReverseArcINS_6ArcTplINS_12LogWeightTplIfEEEEEENS_11VectorStateIS7_NSt3__19allocatorIS7_EEEEEEEE
N3fst14DeterminizeFstINS_6ArcTplINS_12LogWeightTplIfEEEEEE
N3fst9ImplToFstINS_22DeterminizeFstImplBaseINS_6ArcTplINS_12LogWeightTplIfEEEEEENS_3FstIS5_EEEE
N3fst18DeterminizeFsaImplINS_6ArcTplINS_12LogWeightTplIfEEEENS_20DefaultCommonDivisorIS3_EENS_24DefaultDeterminizeFilterIS4_EENS_28DefaultDeterminizeStateTableIS4_NS_18IntegerFilterStateIaEEEEEE
N3fst22DeterminizeFstImplBaseINS_6ArcTplINS_12LogWeightTplIfEEEEEE
N3fst13StateIteratorINS_14DeterminizeFstINS_6ArcTplINS_12LogWeightTplIfEEEEEEEE
N3fst18CacheStateIteratorINS_14DeterminizeFstINS_6ArcTplINS_12LogWeightTplIfEEEEEEEE
N3fst18DeterminizeFstImplINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3ENS_20DefaultCommonDivisorIS3_EENS_24DefaultDeterminizeFilterIS4_EENS_28DefaultDeterminizeStateTableIS4_NS_18IntegerFilterStateIaEEEEEE
N3fst9ArcMapFstINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE3EEENS_14ToGallicMapperIS4_LS6_3EEEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE3EEENS_14ToGallicMapperIS5_LS7_3EEEEENS_3FstIS8_EEEE
N3fst3FstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEEEE
N3fst13ArcMapFstImplINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE3EEENS_14ToGallicMapperIS4_LS6_3EEEEE
N3fst7FstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEEEEE4LinkEEE
N3fst13StateIteratorINS_9ArcMapFstINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE3EEENS_14ToGallicMapperIS5_LS7_3EEEEEEE
N3fst17StateIteratorBaseINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEEEE
N3fst14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEEEE
N3fst18DeterminizeFsaImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEENS_19GallicCommonDivisorIiS4_LS6_3ENS_20DefaultCommonDivisorIS4_EEEENS_24DefaultDeterminizeFilterIS7_EENS_28DefaultDeterminizeStateTableIS7_NS_18IntegerFilterStateIaEEEEEE
N3fst22DeterminizeFstImplBaseINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEEEE
N3fst13StateIteratorINS_14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEEEEEE
N3fst18CacheStateIteratorINS_14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEEEEEE
N3fst15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEENS_12GallicFactorIiS4_LS6_3EEEEE
N3fst9ImplToFstINS_19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEENS_12GallicFactorIiS5_LS7_3EEEEENS_3FstIS8_EEEE
N3fst19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEENS_12GallicFactorIiS4_LS6_3EEEEE
N3fst13StateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEENS_12GallicFactorIiS5_LS7_3EEEEEEE
N3fst18CacheStateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEENS_12GallicFactorIiS5_LS7_3EEEEEEE
N3fst9ArcMapFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEES5_NS_16FromGallicMapperIS5_LS6_3EEEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEES6_NS_16FromGallicMapperIS6_LS7_3EEEEENS_3FstIS6_EEEE
N3fst13ArcMapFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEES5_NS_16FromGallicMapperIS5_LS6_3EEEEE
N3fst13StateIteratorINS_9ArcMapFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEES6_NS_16FromGallicMapperIS6_LS7_3EEEEEEE
N3fst18DeterminizeFstImplINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2ENS_20DefaultCommonDivisorIS3_EENS_24DefaultDeterminizeFilterIS4_EENS_28DefaultDeterminizeStateTableIS4_NS_18IntegerFilterStateIaEEEEEE
N3fst9ArcMapFstINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE2EEENS_14ToGallicMapperIS4_LS6_2EEEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE2EEENS_14ToGallicMapperIS5_LS7_2EEEEENS_3FstIS8_EEEE
N3fst3FstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEEEE
N3fst13ArcMapFstImplINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE2EEENS_14ToGallicMapperIS4_LS6_2EEEEE
N3fst9CacheImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEEEE
N3fst13CacheBaseImplINS_10CacheStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEENSt3__19allocatorIS8_EEEENS_17DefaultCacheStoreIS8_EEEE
N3fst7FstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEEEE
N3fst10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEEEEE4LinkEEE
N3fst13StateIteratorINS_9ArcMapFstINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE2EEENS_14ToGallicMapperIS5_LS7_2EEEEEEE
N3fst17StateIteratorBaseINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEEEE
N3fst14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEEEE
N3fst9ImplToFstINS_22DeterminizeFstImplBaseINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEEEENS_3FstIS8_EEEE
N3fst18DeterminizeFsaImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEENS_19GallicCommonDivisorIiS4_LS6_2ENS_20DefaultCommonDivisorIS4_EEEENS_24DefaultDeterminizeFilterIS7_EENS_28DefaultDeterminizeStateTableIS7_NS_18IntegerFilterStateIaEEEEEE
N3fst22DeterminizeFstImplBaseINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEEEE
N3fst13StateIteratorINS_14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEEEEEE
N3fst18CacheStateIteratorINS_14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEEEEEE
N3fst15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEENS_12GallicFactorIiS4_LS6_2EEEEE
N3fst9ImplToFstINS_19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEENS_12GallicFactorIiS5_LS7_2EEEEENS_3FstIS8_EEEE
N3fst19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEENS_12GallicFactorIiS4_LS6_2EEEEE
N3fst13StateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEENS_12GallicFactorIiS5_LS7_2EEEEEEE
N3fst18CacheStateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEENS_12GallicFactorIiS5_LS7_2EEEEEEE
N3fst9ArcMapFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEES5_NS_16FromGallicMapperIS5_LS6_2EEEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEES6_NS_16FromGallicMapperIS6_LS7_2EEEEENS_3FstIS6_EEEE
N3fst13ArcMapFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEES5_NS_16FromGallicMapperIS5_LS6_2EEEEE
N3fst13StateIteratorINS_9ArcMapFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEES6_NS_16FromGallicMapperIS6_LS7_2EEEEEEE
N3fst18DeterminizeFstImplINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4ENS_20DefaultCommonDivisorIS3_EENS_24DefaultDeterminizeFilterIS4_EENS_28DefaultDeterminizeStateTableIS4_NS_18IntegerFilterStateIaEEEEEE
N3fst9ArcMapFstINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE4EEENS_14ToGallicMapperIS4_LS6_4EEEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE4EEENS_14ToGallicMapperIS5_LS7_4EEEEENS_3FstIS8_EEEE
N3fst3FstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEEEE
N3fst13ArcMapFstImplINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE4EEENS_14ToGallicMapperIS4_LS6_4EEEEE
N3fst9CacheImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEEEE
N3fst13CacheBaseImplINS_10CacheStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEENSt3__19allocatorIS8_EEEENS_17DefaultCacheStoreIS8_EEEE
N3fst7FstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEEEE
N3fst10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEEEEE4LinkEEE
N3fst13StateIteratorINS_9ArcMapFstINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE4EEENS_14ToGallicMapperIS5_LS7_4EEEEEEE
N3fst17StateIteratorBaseINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEEEE
N3fst14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEEEE
N3fst9ImplToFstINS_22DeterminizeFstImplBaseINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEEEENS_3FstIS8_EEEE
N3fst18DeterminizeFsaImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEENS_19GallicCommonDivisorIiS4_LS6_4ENS_20DefaultCommonDivisorIS4_EEEENS_24DefaultDeterminizeFilterIS7_EENS_28DefaultDeterminizeStateTableIS7_NS_18IntegerFilterStateIaEEEEEE
N3fst22DeterminizeFstImplBaseINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEEEE
N3fst13StateIteratorINS_14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEEEEEE
N3fst18CacheStateIteratorINS_14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEEEEEE
N3fst15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEENS_12GallicFactorIiS4_LS6_4EEEEE
N3fst9ImplToFstINS_19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEENS_12GallicFactorIiS5_LS7_4EEEEENS_3FstIS8_EEEE
N3fst19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEENS_12GallicFactorIiS4_LS6_4EEEEE
N3fst13StateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEENS_12GallicFactorIiS5_LS7_4EEEEEEE
N3fst18CacheStateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEENS_12GallicFactorIiS5_LS7_4EEEEEEE
N3fst9ArcMapFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEES5_NS_16FromGallicMapperIS5_LS6_4EEEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEES6_NS_16FromGallicMapperIS6_LS7_4EEEEENS_3FstIS6_EEEE
N3fst13ArcMapFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEES5_NS_16FromGallicMapperIS5_LS6_4EEEEE
N3fst13StateIteratorINS_9ArcMapFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEES6_NS_16FromGallicMapperIS6_LS7_4EEEEEEE
N3fst16TableMatcherImplINS_3FstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_13SortedMatcherIS6_EEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_21SequenceComposeFilterINS_12TableMatcherINS_3FstIS5_EENS_13SortedMatcherISA_EEEESC_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSH_EENS_21CompactHashStateTableISJ_NS_11ComposeHashISJ_EEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_21SequenceComposeFilterINS_13SortedMatcherINS_3FstIS5_EEEENS_12TableMatcherISA_SB_EEEENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSH_EENS_21CompactHashStateTableISJ_NS_11ComposeHashISJ_EEEEEEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_21SequenceComposeFilterINS_13SortedMatcherINS_3FstIS5_EEEENS_12TableMatcherISA_SB_EEEENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSH_EENS_21CompactHashStateTableISJ_NS_11ComposeHashISJ_EEEEEEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEENSt3__19allocatorIS9_EEEEEENS_10MutableFstIS9_EEEE
N3fst10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEENS_11VectorStateIS8_NSt3__19allocatorIS8_EEEEEEEE
N3fst22MutableArcIteratorBaseINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N3fst3FstINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEEEE
N3fst22MutableArcIteratorBaseINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEEEE
N3fst19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEENS_12GallicFactorIiS4_LS6_0EEEEE
N6quasar16FeatureExtractorE
N6quasar11OnlineCmnFeE
N6quasar12OnlineCmvnFeE
N6quasar13OnlineDeltaFeE
N6quasar13OnlineFbankFeE
N6quasar22OnlineFbankWithPitchFeE
N6quasar31OnlineFbankWithAudioAnalyticsFeE
N6quasar11OnlineLdaFeE
N6quasar12OnlineMfccFeE
N6quasar19OnlineNnetForwardFeE
N6quasar23OnlineNnetForwardSkipFeE
N6quasar14OnlineSpliceFeE
N6quasar23OnlineStaticTransformFeE
N6quasar18OnlineCacheInputFeE
N6quasar25OnlineComputeAheadInputFeE
N6quasar17OnlineSubsampleFeE
NSt3__120__shared_ptr_emplaceIN5kaldi17OnlineSubsampleFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar11OnlineCmnFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar12OnlineCmvnFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar13OnlineDeltaFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar13OnlineFbankFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar22OnlineFbankWithPitchFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar11OnlineLdaFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar12OnlineMfccFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar19OnlineNnetForwardFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar23OnlineNnetForwardSkipFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar14OnlineSpliceFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar17OnlineSubsampleFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar23OnlineStaticTransformFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar25OnlineComputeAheadInputFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar31OnlineFbankWithAudioAnalyticsFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar14OnlineAppendFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi14OnlineCmnInputENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi15OnlineCmvnInputENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi16OnlineDeltaInputENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi5FbankENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi13OnlineFeInputINS1_5FbankEEENS_9allocatorIS4_EEEE
N5kaldi13OnlineFeInputINS_5FbankEEE
NSt3__120__shared_ptr_emplaceIN5kaldi14FbankWithPitchENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi13OnlineFeInputINS1_14FbankWithPitchEEENS_9allocatorIS4_EEEE
N5kaldi13OnlineFeInputINS_14FbankWithPitchEEE
NSt3__120__shared_ptr_emplaceIN5kaldi23FbankWithAudioAnalyticsENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi13OnlineFeInputINS1_23FbankWithAudioAnalyticsEEENS_9allocatorIS4_EEEE
N5kaldi13OnlineFeInputINS_23FbankWithAudioAnalyticsEEE
NSt3__120__shared_ptr_emplaceIN5kaldi14OnlineLdaInputENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi4MfccENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi13OnlineFeInputINS1_4MfccEEENS_9allocatorIS4_EEEE
N5kaldi13OnlineFeInputINS_4MfccEEE
NSt3__120__shared_ptr_emplaceIN5kaldi22OnlineNnetForwardInputENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi29OnlineNnetForwardSkippedInputENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi17OnlineSpliceInputENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi20OnlineTransformInputENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi16OnlineCacheInputENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar21ComputeAheadFeatInputENS_9allocatorIS2_EEEE
N6quasar21ComputeAheadFeatInputE
N5kaldi6quasar11ErrorRegionE
N6quasar10EndPointerE
N6quasar15BasicEndPointerE
N6quasar14NnetEndPointerE
NSt3__120__shared_ptr_emplaceIN6quasar9GeoRegionENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar17RegionsBitmapDataENS_9allocatorIS2_EEEE
@N6quasar16RecogAudioBufferE
N5boost16exception_detail10clone_implINS0_19error_info_injectorISt12length_errorEEEE
N5boost16exception_detail19error_info_injectorISt12length_errorEE
N6quasar20RecogAudioBufferBaseE
N6quasar20SpeechRecognizerBaseE
N6quasar18LmeDataFactoryBaseE
N5kaldi5nnet116NnetTrainOptionsE
N5kaldi5nnet114HistoryOptionsE
N5kaldi5nnet125RecurrentNnetTrainOptionsE
NSt3__120__shared_ptr_emplaceIN5kaldi5nnet117Nnet1InferenceNetENS_9allocatorIS3_EEEE
N5kaldi5nnet115AffineTransformE
NSt3__120__shared_ptr_emplaceIN6quasar6LmDataENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar11LmEvaluatorENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar8LmLoaderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar9AppLmDataENS_9allocatorIS2_EEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEENSt3__19allocatorIS8_EEEEEENS_10MutableFstIS8_EEEE
N3fst11ExpandedFstINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEE
N3fst3FstINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEE
N3fst10MutableFstINS_6ArcTplINS_16LatticeWeightTplIfEEEEEE
N3fst24DeterministicOnDemandFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
NSt3__120__shared_ptr_emplaceIN3fst9VectorFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEENS1_11VectorStateIS6_NS_9allocatorIS6_EEEEEENS8_ISB_EEEE
N3fst10MutableFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N3fst11ExpandedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEE4LinkEEE
N3fst7FstImplINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEE
N3fst8SccQueueIiNS_9QueueBaseIiEEEE
N3fst14DeterminizeFstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEE
N3fst9ImplToFstINS_22DeterminizeFstImplBaseINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEENS_3FstIS9_EEEE
N3fst18DeterminizeFsaImplINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEENS_20DefaultCommonDivisorIS6_EENS_24DefaultDeterminizeFilterIS8_EENS_28DefaultDeterminizeStateTableIS8_NS_18IntegerFilterStateIaEEEEEE
N3fst22DeterminizeFstImplBaseINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEE
N3fst9CacheImplINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEE
N3fst13CacheBaseImplINS_10CacheStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEENSt3__19allocatorIS9_EEEENS_17DefaultCacheStoreIS9_EEEE
N3fst13StateIteratorINS_14DeterminizeFstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEEEE
N3fst18CacheStateIteratorINS_14DeterminizeFstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEEEE
N3fst17StateIteratorBaseINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_16LatticeWeightTplIfEEEENSt3__19allocatorIS6_EEEEEENS_10MutableFstIS6_EEEE
N3fst15ArcIteratorBaseINS_6ArcTplINS_16LatticeWeightTplIfEEEEEE
8BayesMix
18NgramProbArrayTrie
8SubVocab
?NSt3__120__shared_ptr_emplaceIN6quasar17PSRAudioProcessorENS_9allocatorIS2_EEEE
N5kaldi5nnet124GlobalAttentionComponentE
N5kaldi5nnet124GlobalRecurrentAttentionE
11NgramCountsIdE
N5kaldi27OnlineAudioAnalyticsFeatureE
N6quasar27PrefixSearchableSymbolTableE
NSt3__120__shared_ptr_emplaceIN6quasar9SymbolMap25SortedSymbolMapQuasarImplENS_9allocatorIS3_EEEE
N6quasar9SymbolMap25SortedSymbolMapQuasarImplE
N6quasar9SymbolMap19SymbolMapQuasarImplE
NSt3__120__shared_ptr_emplaceIN6quasar9SymbolMap19SymbolMapQuasarImplENS_9allocatorIS3_EEEE
N6quasar9SymbolMap19SymbolMapMarisaImplE
NSt3__120__shared_ptr_pointerIPN3fst10MappedFileENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN3fst10MappedFileEEE
NSt3__120__shared_ptr_pointerIPN6quasar9SymbolMap19SymbolMapMarisaImplENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIN6quasar9SymbolMap19SymbolMapMarisaImplEEE
N6quasar18SelectBlockOptionsE
N6quasar25ConfiguredProcessingBlockINS_18SelectBlockOptionsEEE
N6quasar11SelectBlockE
N3fst15ArcIteratorBaseINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEE
N3fst13VectorFstImplINS_11VectorStateINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEENSt3__19allocatorIS7_EEEEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEENSt3__19allocatorIS7_EEEEEE
N6quasar9MungeRuleE
N6quasar15MergedMungeRuleE
N6quasar14BasicMungeRuleE
5Vocab
N6quasar7LmModelE
NSt3__110__function6__funcIZN6quasar7LmModel17readFromDirectoryERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEESB_RS9_RNS_8optionalINS_10shared_ptrIS3_EEEEE3$_0NS7_ISI_EEFvSB_EEE
NSt3__110__function6__baseIFvRKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEEEE
ZN6quasar7LmModel17readFromDirectoryERKNSt3__112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEES9_RS7_RNS1_8optionalINS1_10shared_ptrIS0_EEEEE3$_0
NSt3__120__shared_ptr_pointerIPN6quasar7LmModelENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN6quasar7LmModelEEE
NSt3__110__function6__funcIZN6quasar7LmModel5writeERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEE3$_1NS7_ISC_EEFvSB_EEE
ZN6quasar7LmModel5writeERKNSt3__112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEEE3$_1
NSt3__110__function6__funcIZN6quasar7LmModel6removeERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEE3$_2NS7_ISC_EEFvSB_EEE
ZN6quasar7LmModel6removeERKNSt3__112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEEE3$_2
N5kaldi5nnet116LossEvaluatorItfE
N5kaldi5nnet14XentE
N5kaldi5nnet13MseE
N5kaldi11CuSubMatrixIfEE
N6quasar23SharedPhraseBookOptionsE
N6quasar25ConfiguredProcessingBlockINS_23SharedPhraseBookOptionsEEE
N6quasar15PhraseBookBlockE
NSt3__120__shared_ptr_pointerIPN6quasar16SharedPhraseBookENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN6quasar16SharedPhraseBookEEE
EN6quasar18WatermarkDetector2E
NSt3__120__shared_ptr_emplaceIN5kaldi10SnrTrackerENS_9allocatorIS2_EEEE
13ConstDiscount
N5kaldi5nnet118ScaledDotAttentionE
N5kaldi5nnet118MultiHeadAttentionE
N5kaldi5nnet128SupervisedMultiHeadAttentionE
N5kaldi5nnet113SelfAttentionE
N5kaldi5nnet116AverageAttentionE
N6quasar12NgramLmModelE
vector
const
ngram
ngram_quantized
reduced_transducer
reduced_acceptor
reduced_quantized_transducer
reduced_quantized_acceptor
squeezed_transducer
squeezed_acceptor
squeezed_quantized_transducer
squeezed_quantized_acceptor
N6quasar22ConvertingNgramVisitorE
N3fst9LifoQueueIiEE
NSt3__15dequeIiNS_9allocatorIiEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEEE4LinkEEE
N3fst22MutableArcIteratorBaseINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEE
NSt3__120__shared_ptr_pointerIPN6quasar11FstLmHandleENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN6quasar11FstLmHandleEEE
N6quasar13VocabIteratorE
N3fst13TopOrderQueueIiEE
NSt3__120__shared_ptr_emplaceIN3fst8ConstFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEEjEENS_9allocatorIS7_EEEE
N3fst8ConstFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEjEE
N3fst17ImplToExpandedFstINS_12ConstFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEEjEENS_11ExpandedFstIS5_EEEE
N3fst9ImplToFstINS_12ConstFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEEjEENS_11ExpandedFstIS5_EEEE
NSt3__120__shared_ptr_emplaceIN3fst8NGramFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb0EEENS_9allocatorIS7_EEEE
N3fst8NGramFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0EEE
N3fst17ImplToExpandedFstINS_12NGramFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0EEENS_11ExpandedFstIS5_EEEE
N3fst9ImplToFstINS_12NGramFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0EEENS_11ExpandedFstIS5_EEEE
N3fst12NGramFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0EEE
N3fst12NGramFstDataINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0EEE
N3fst11ArcIteratorINS_8NGramFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0EEEEE
N3fst15NGramFstMatcherINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0EEE
NSt3__120__shared_ptr_emplaceIN3fst8NGramFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb1EEENS_9allocatorIS7_EEEE
N3fst8NGramFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1EEE
N3fst17ImplToExpandedFstINS_12NGramFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1EEENS_11ExpandedFstIS5_EEEE
N3fst9ImplToFstINS_12NGramFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1EEENS_11ExpandedFstIS5_EEEE
N3fst12NGramFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1EEE
N3fst12NGramFstDataINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1EEE
N3fst11ArcIteratorINS_8NGramFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1EEEEE
N3fst15NGramFstMatcherINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1EEE
NSt3__120__shared_ptr_emplaceIN3fst10ReducedFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb0ELb0EEENS_9allocatorIS7_EEEE
N3fst10ReducedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb0EEE
N3fst17ImplToExpandedFstINS_14ReducedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb0EEENS_11ExpandedFstIS5_EEEE
N3fst9ImplToFstINS_14ReducedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb0EEENS_11ExpandedFstIS5_EEEE
N3fst14ReducedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb0EEE
N3fst13StateIteratorINS_10ReducedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb0EEEEE
N3fst17StateIteratorBaseINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
NSt3__120__shared_ptr_emplaceIN3fst10ReducedFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb1ELb0EEENS_9allocatorIS7_EEEE
N3fst10ReducedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb0EEE
N3fst17ImplToExpandedFstINS_14ReducedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb0EEENS_11ExpandedFstIS5_EEEE
N3fst9ImplToFstINS_14ReducedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb0EEENS_11ExpandedFstIS5_EEEE
N3fst14ReducedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb0EEE
N3fst13StateIteratorINS_10ReducedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb0EEEEE
N3fst11ArcIteratorINS_10ReducedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb0EEEEE
NSt3__120__shared_ptr_emplaceIN3fst10ReducedFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb0ELb1EEENS_9allocatorIS7_EEEE
N3fst10ReducedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb1EEE
N3fst17ImplToExpandedFstINS_14ReducedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb1EEENS_11ExpandedFstIS5_EEEE
N3fst9ImplToFstINS_14ReducedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb1EEENS_11ExpandedFstIS5_EEEE
N3fst14ReducedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb1EEE
N3fst13StateIteratorINS_10ReducedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb1EEEEE
N3fst11ArcIteratorINS_10ReducedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb1EEEEE
NSt3__120__shared_ptr_emplaceIN3fst10ReducedFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb1ELb1EEENS_9allocatorIS7_EEEE
N3fst10ReducedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb1EEE
N3fst17ImplToExpandedFstINS_14ReducedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb1EEENS_11ExpandedFstIS5_EEEE
N3fst9ImplToFstINS_14ReducedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb1EEENS_11ExpandedFstIS5_EEEE
N3fst14ReducedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb1EEE
N3fst13StateIteratorINS_10ReducedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb1EEEEE
N3fst11ArcIteratorINS_10ReducedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb1EEEEE
NSt3__120__shared_ptr_emplaceIN3fst11SqueezedFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb0ELb0EEENS_9allocatorIS7_EEEE
N3fst11SqueezedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb0EEE
N3fst17ImplToExpandedFstINS_15SqueezedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb0EEENS_11ExpandedFstIS5_EEEE
N3fst9ImplToFstINS_15SqueezedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb0EEENS_11ExpandedFstIS5_EEEE
N3fst15SqueezedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb0EEE
NSt3__120__shared_ptr_emplaceIN3fst11SqueezedFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb1ELb0EEENS_9allocatorIS7_EEEE
N3fst11SqueezedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb0EEE
N3fst17ImplToExpandedFstINS_15SqueezedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb0EEENS_11ExpandedFstIS5_EEEE
N3fst9ImplToFstINS_15SqueezedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb0EEENS_11ExpandedFstIS5_EEEE
N3fst15SqueezedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb0EEE
N3fst11ArcIteratorINS_11SqueezedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb0EEEEE
NSt3__120__shared_ptr_emplaceIN3fst11SqueezedFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb0ELb1EEENS_9allocatorIS7_EEEE
N3fst11SqueezedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb1EEE
N3fst17ImplToExpandedFstINS_15SqueezedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb1EEENS_11ExpandedFstIS5_EEEE
N3fst9ImplToFstINS_15SqueezedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb1EEENS_11ExpandedFstIS5_EEEE
N3fst15SqueezedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb1EEE
N3fst11ArcIteratorINS_11SqueezedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb1EEEEE
NSt3__120__shared_ptr_emplaceIN3fst11SqueezedFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb1ELb1EEENS_9allocatorIS7_EEEE
N3fst11SqueezedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb1EEE
N3fst17ImplToExpandedFstINS_15SqueezedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb1EEENS_11ExpandedFstIS5_EEEE
N3fst9ImplToFstINS_15SqueezedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb1EEENS_11ExpandedFstIS5_EEEE
N3fst15SqueezedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb1EEE
N3fst11ArcIteratorINS_11SqueezedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb1EEEEE
N5sdapi12SdapiITNImplE
N6quasar20SyncRecogAudioBufferE
N5kaldi5nnet118GatedRecurrentUnitE
N6quasar20AppleFileCoordinatorE
N6quasar23AppleLanguageRecognizerE
N5kaldi27OnlineDecodableMatrixScaledE
N5kaldi30OnlineDecodableIdenticalMatrixE
N5kaldi33OnlineDecodableMatrixScaledMappedE
N5kaldi35OnlineDecodableMatrixScaledMappedTmE
N5kaldi24OnlineDecodableNnet1LazyE
NSt3__120__shared_ptr_emplaceIN6quasar21SyncPSRAudioProcessorENS_9allocatorIS2_EEEE
N6quasar22ResultStreamStabilizerE
N6quasar14LmeDataFactoryE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar7LexiconENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar6LmeFstENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar12ConstLexiconENS_9allocatorIS3_EEEE
NSt3__110__function6__funcINS_6__bindIRFbRKN6quasar18LmeDataFactoryBase4WordEiEJRKNS_12placeholders4__phILi1EEERiEEENS_9allocatorISG_EEFbS7_EEE
NSt3__110__function6__baseIFbRKN6quasar18LmeDataFactoryBase4WordEEEE
NSt3__16__bindIRFbRKN6quasar18LmeDataFactoryBase4WordEiEJRKNS_12placeholders4__phILi1EEERiEEE
NSt3__118__weak_result_typeIPFbRKN6quasar18LmeDataFactoryBase4WordEiEEE
NSt3__115binary_functionIRKN6quasar18LmeDataFactoryBase4WordEibEE
@N6quasar11PDecOptionsE
N6quasar17TranslatorOptionsE
N6quasar25ConfiguredProcessingBlockINS_17TranslatorOptionsEEE
N6quasar19PDecTranslatorBlockE
N6quasar20PDecEngineBlockMixinE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar21TranslationBeamSearchINS2_19TorchEncoderDecoderEEENS_9allocatorIS5_EEEE
N5kaldi6quasar21TranslationBeamSearchINS0_19TorchEncoderDecoderEEE
N5kaldi12CuVectorBaseIfEE
N3fst10MutableFstINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS5_9allocatorIfEEEEEEEEEE
N3fst13VectorFstImplINS_11VectorStateINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS6_9allocatorIfEEEEEEEENS8_ISC_EEEEEE
N3fst22MutableArcIteratorBaseINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS5_9allocatorIfEEEEEEEEEE
N3fst9QueueBaseIiEE
N3fst18ShortestFirstQueueIiNS_18StateWeightCompareIiNS_11NaturalLessINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS6_9allocatorIfEEEEEEEEEELb0EEE
N3fst9VectorFstINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS6_9allocatorIfEEEEEEEEEENS_11VectorStateISD_NS8_ISD_EEEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS8_9allocatorIfEEEEEEEEEENSA_ISF_EEEEEENS_10MutableFstISF_EEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS8_9allocatorIfEEEEEEEEEENSA_ISF_EEEEEENS_10MutableFstISF_EEEE
N3fst11ExpandedFstINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS6_9allocatorIfEEEEEEEEEEEE
N3fst3FstINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS6_9allocatorIfEEEEEEEEEEEE
N3fst13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS7_9allocatorIfEEEEEEEEEENS9_ISE_EEEEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS7_9allocatorIfEEEEEEEEEENS9_ISE_EEEEEE
N3fst7FstImplINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS6_9allocatorIfEEEEEEEEEEEE
N3fst10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS7_9allocatorIfEEEEEEEEEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS8_9allocatorIfEEEEEEEEEEEEE4LinkEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS7_9allocatorIfEEEEEEEEEENS_11VectorStateISE_NS9_ISE_EEEEEEEE
N3fst22MutableArcIteratorBaseINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS6_9allocatorIfEEEEEEEEEEEE
N3fst15ArcIteratorBaseINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS6_9allocatorIfEEEEEEEEEEEE
N3fst14DeterminizeFstINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS6_9allocatorIfEEEEEEEEEEEE
N3fst18DeterminizeFsaImplINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS6_9allocatorIfEEEEEEEEEENS_20DefaultCommonDivisorISB_EENS_24DefaultDeterminizeFilterISD_EENS_28DefaultDeterminizeStateTableISD_NS_18IntegerFilterStateIaEEEEEE
N3fst22DeterminizeFstImplBaseINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS6_9allocatorIfEEEEEEEEEEEE
N3fst9CacheImplINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS6_9allocatorIfEEEEEEEEEEEE
N3fst13CacheBaseImplINS_10CacheStateINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS7_9allocatorIfEEEEEEEEEENS9_ISE_EEEENS_17DefaultCacheStoreISE_EEEE
N3fst18CacheStateIteratorINS_14DeterminizeFstINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS7_9allocatorIfEEEEEEEEEEEEEE
N3fst17StateIteratorBaseINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS6_9allocatorIfEEEEEEEEEEEE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar10PhraseBookENS_9allocatorIS3_EEEE
N6quasar18BasicTextSanitizerE
N6quasar13TextSanitizerE
7MEModel
11NgramCountsImE
N6quasar11SyncDecoderE
NSt3__120__shared_ptr_emplaceIN6quasar26KeywordSpottingSyncDecoderENS_9allocatorIS2_EEEE
N6quasar14PDecTranslatorE
8VarNgram
N5kaldi8EventMapE
N5kaldi16ConstantEventMapE
N5kaldi13TableEventMapE
N5kaldi13SplitEventMapE
16SimpleClassNgram
N6quasar20SimpleNameEnumeratorE
N6quasar21AudioAnalyticsDecoderE
N3fst9ImplToFstINS_18ComposeFstImplBaseINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEENS_17DefaultCacheStoreISB_EEEENS_3FstISB_EEEE
N3fst3FstINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEE
N3fst10MemoryPoolINS_8DfsStateINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEE4LinkEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEENSt3__19allocatorISC_EEEEEENS_10MutableFstISC_EEEE
N3fst10MutableFstINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEE
N3fst11ExpandedFstINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEE
N3fst10MutableFstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEE
N3fst13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEENSt3__19allocatorIS9_EEEEEE
N3fst7FstImplINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEE
N3fst15ArcIteratorBaseINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEE
N3fst9VectorFstINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEENS_11VectorStateISA_NSt3__19allocatorISA_EEEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEENSt3__19allocatorISC_EEEEEENS_10MutableFstISC_EEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEENSt3__19allocatorISC_EEEEEENS_10MutableFstISC_EEEE
N3fst13VectorFstImplINS_11VectorStateINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEENSt3__19allocatorISB_EEEEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEENSt3__19allocatorISB_EEEEEE
N3fst7FstImplINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEENS_11VectorStateISB_NSt3__19allocatorISB_EEEEEEEE
N3fst22MutableArcIteratorBaseINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEE
N3fst15ArcIteratorBaseINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEE
N3fst13SortedMatcherINS_3FstINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEE
N3fst11MatcherBaseINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEE
N3fst10MemoryPoolINS_11ArcIteratorINS_3FstINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_11ArcIteratorINS_3FstINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEEE4LinkEEE
N3fst10ComposeFstINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEENS_17DefaultCacheStoreISA_EEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEENS_21SequenceComposeFilterINS_13SortedMatcherINS_3FstISB_EEEESH_EENS_24GenericComposeStateTableISB_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSL_EENS_21CompactHashStateTableISN_NS_11ComposeHashISN_EEEEEEEE
N3fst18ComposeFstImplBaseINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEENS_17DefaultCacheStoreISA_EEEE
N3fst13CacheBaseImplINS_10CacheStateINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEENSt3__19allocatorISB_EEEENS_17DefaultCacheStoreISB_EEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEENS_21SequenceComposeFilterINS_13SortedMatcherINS_3FstISB_EEEESH_EENS_24GenericComposeStateTableISB_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSL_EENS_21CompactHashStateTableISN_NS_11ComposeHashISN_EEEEEEEE
N3fst13StateIteratorINS_10ComposeFstINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEENS_17DefaultCacheStoreISB_EEEEEE
N3fst18CacheStateIteratorINS_10ComposeFstINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEENS_17DefaultCacheStoreISB_EEEEEE
N3fst17StateIteratorBaseINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEE
N3fst18ShortestFirstQueueIiNS_18StateWeightCompareIiNS_11NaturalLessINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEELb0EEE
N3fst9VectorFstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEENS_11VectorStateISC_NSt3__19allocatorISC_EEEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEENSt3__19allocatorISE_EEEEEENS_10MutableFstISE_EEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEENSt3__19allocatorISE_EEEEEENS_10MutableFstISE_EEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEENSt3__19allocatorISE_EEEEEENS_10MutableFstISE_EEEE
N3fst10MutableFstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEE
N3fst11ExpandedFstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEE
N3fst3FstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEE
N3fst13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEENSt3__19allocatorISD_EEEEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEENSt3__19allocatorISD_EEEEEE
N3fst7FstImplINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEE
N3fst10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEEE4LinkEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEENS_11VectorStateISD_NSt3__19allocatorISD_EEEEEEEE
N3fst22MutableArcIteratorBaseINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEE
N3fst15ArcIteratorBaseINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEE
N3fst14DeterminizeFstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEE
N3fst9ImplToFstINS_22DeterminizeFstImplBaseINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEENS_3FstISD_EEEE
N3fst18DeterminizeFsaImplINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEENS_20DefaultCommonDivisorISA_EENS_24DefaultDeterminizeFilterISC_EENS_28DefaultDeterminizeStateTableISC_NS_18IntegerFilterStateIaEEEEEE
N3fst22DeterminizeFstImplBaseINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEE
N3fst9CacheImplINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEE
N3fst13CacheBaseImplINS_10CacheStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEENSt3__19allocatorISD_EEEENS_17DefaultCacheStoreISD_EEEE
N3fst13StateIteratorINS_14DeterminizeFstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEEEE
N3fst18CacheStateIteratorINS_14DeterminizeFstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEEEE
N3fst17StateIteratorBaseINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_6ArcTplINS_17TropicalWeightTplIfEEEENSt3__19allocatorIS5_EEEEEE
N3fst15ArcIteratorBaseINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEENSt3__19allocatorIS9_EEEEEENS_10MutableFstIS9_EEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEENSt3__19allocatorIS9_EEEEEENS_10MutableFstIS9_EEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEENSt3__19allocatorIS9_EEEEEENS_10MutableFstIS9_EEEE
N3fst10MutableFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N3fst3FstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N3fst13VectorFstImplINS_11VectorStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEENSt3__19allocatorIS8_EEEEEE
N3fst7FstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N3fst10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEEE4LinkEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEENS_11VectorStateIS8_NSt3__19allocatorIS8_EEEEEEEE
N3fst22MutableArcIteratorBaseINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N3fst9VectorFstINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEENS_11VectorStateIS9_NSt3__19allocatorIS9_EEEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEENSt3__19allocatorISB_EEEEEENS_10MutableFstISB_EEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEENSt3__19allocatorISB_EEEEEENS_10MutableFstISB_EEEE
N3fst10MutableFstINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEEEE
N3fst11ExpandedFstINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEEEE
N3fst3FstINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEEEE
N3fst13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEENSt3__19allocatorISA_EEEEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEENSt3__19allocatorISA_EEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEEEEE4LinkEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEENS_11VectorStateISA_NSt3__19allocatorISA_EEEEEEEE
N3fst22MutableArcIteratorBaseINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEEEE
N3fst15ArcIteratorBaseINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEEEE
N3fst13CacheBaseImplINS_10CacheStateINS_6ArcTplINS_12LogWeightTplIfEEEENSt3__19allocatorIS5_EEEENS_17DefaultCacheStoreIS5_EEEE
N3fst13StateIteratorINS_9ArcMapFstINS_6ArcTplINS_12LogWeightTplIfEEEES5_NS_14RmWeightMapperIS5_S5_EEEEEE
N3fst9ArcMapFstINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE0EEENS_14ToGallicMapperIS4_LS6_0EEEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE0EEENS_14ToGallicMapperIS5_LS7_0EEEEENS_3FstIS8_EEEE
N3fst13ArcMapFstImplINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE0EEENS_14ToGallicMapperIS4_LS6_0EEEEE
N3fst13StateIteratorINS_9ArcMapFstINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE0EEENS_14ToGallicMapperIS5_LS7_0EEEEEEE
N3fst17StateIteratorBaseINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N3fst15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEENS_12GallicFactorIiS4_LS6_0EEEEE
N3fst9ImplToFstINS_19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEENS_12GallicFactorIiS5_LS7_0EEEEENS_3FstIS8_EEEE
N3fst19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEENS_12GallicFactorIiS4_LS6_0EEEEE
N3fst13StateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEENS_12GallicFactorIiS5_LS7_0EEEEEEE
N6quasar34OnlineLatticeBiglmLmeFasterDecoderE
NSt3__120__shared_ptr_emplaceIN6quasar7LmeDataENS_9allocatorIS2_EEEE
N6quasar25JapaneseDerivedEnumeratorE
N6quasar29OnlineLatticeRescalingDecoderE
N6quasar21PDecForceAlignOptionsE
N6quasar25ConfiguredProcessingBlockINS_21PDecForceAlignOptionsEEE
N6quasar19PDecForceAlignBlockE
train
test
external
none
sweep-weights
interpolation
N6quasar16E2EAsrConfidenceE
5N5kaldi6quasar17NnlmEvaluatorBaseE
N6quasar18SeevaGreedyDecoderE
N5kaldi5nnet124MovingAttentionComponentE
N6quasar15MappedPgmBitmapE
NSt3__120__shared_ptr_pointerIPN6quasar15MappedPgmBitmapENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN6quasar15MappedPgmBitmapEEE
N6quasar15AcousticLDModelE
N6quasar22AcousticLDModelFactoryE
N6quasar14LDResultStreamE
N6quasar19ContextAwareLDModelE
N6quasar24DummyContextAwareLDModelE
N6quasar26ContextAwareLDModelFactoryE
NSt3__120__shared_ptr_emplaceIKN6quasar10LDFrontendENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar8LDConfigENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIKN6quasar25ContextAwareLDModelConfigENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar14LDRequestStateENS_9allocatorIS2_EEEE
NSt3__110__function6__funcIZNK6quasar16LanguageDetector21processAcousticResultERNS2_14LDRequestStateERNS3_23WrappedLDAcousticResultEE3$_2NS_9allocatorIS8_EEFNS_12basic_stringIcNS_11char_traitsIcEENS9_IcEEEERKNS2_6LocaleEEEE
NSt3__110__function6__baseIFNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEERKN6quasar6LocaleEEEE
ZNK6quasar16LanguageDetector21processAcousticResultERNS_14LDRequestStateERNS0_23WrappedLDAcousticResultEE3$_2
N6quasar30OnlineLatticeConfidenceDecoderE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar8WordConfENS_9allocatorIS3_EEEE
N6quasar12IModelLoaderE
N6quasar11ModelLoaderE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar15NnlmDecoderWordENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar14CEInferenceNetENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar15FofeLmEvaluatorENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar14RnnlmEvaluatorENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar14DnnlmEvaluatorENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_pointerIPN3fst8NGramFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb0EEENS_14default_deleteIS7_EENS_9allocatorIS7_EEEE
NSt3__114default_deleteIN3fst8NGramFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb0EEEEE
NSt3__120__shared_ptr_pointerIPN3fst8NGramFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb1EEENS_14default_deleteIS7_EENS_9allocatorIS7_EEEE
NSt3__114default_deleteIN3fst8NGramFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb1EEEEE
NSt3__120__shared_ptr_pointerIPN3fst10ReducedFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb0ELb0EEENS_14default_deleteIS7_EENS_9allocatorIS7_EEEE
NSt3__114default_deleteIN3fst10ReducedFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb0ELb0EEEEE
NSt3__120__shared_ptr_pointerIPN3fst10ReducedFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb1ELb0EEENS_14default_deleteIS7_EENS_9allocatorIS7_EEEE
NSt3__114default_deleteIN3fst10ReducedFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb1ELb0EEEEE
NSt3__120__shared_ptr_pointerIPN3fst10ReducedFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb0ELb1EEENS_14default_deleteIS7_EENS_9allocatorIS7_EEEE
NSt3__114default_deleteIN3fst10ReducedFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb0ELb1EEEEE
NSt3__120__shared_ptr_pointerIPN3fst10ReducedFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb1ELb1EEENS_14default_deleteIS7_EENS_9allocatorIS7_EEEE
NSt3__114default_deleteIN3fst10ReducedFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb1ELb1EEEEE
NSt3__120__shared_ptr_pointerIPN3fst11SqueezedFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb0ELb0EEENS_14default_deleteIS7_EENS_9allocatorIS7_EEEE
NSt3__114default_deleteIN3fst11SqueezedFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb0ELb0EEEEE
NSt3__120__shared_ptr_pointerIPN3fst11SqueezedFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb1ELb0EEENS_14default_deleteIS7_EENS_9allocatorIS7_EEEE
NSt3__114default_deleteIN3fst11SqueezedFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb1ELb0EEEEE
NSt3__120__shared_ptr_pointerIPN3fst11SqueezedFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb0ELb1EEENS_14default_deleteIS7_EENS_9allocatorIS7_EEEE
NSt3__114default_deleteIN3fst11SqueezedFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb0ELb1EEEEE
NSt3__120__shared_ptr_pointerIPN3fst11SqueezedFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb1ELb1EEENS_14default_deleteIS7_EENS_9allocatorIS7_EEEE
NSt3__114default_deleteIN3fst11SqueezedFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb1ELb1EEEEE
NSt3__120__shared_ptr_emplaceIN5kaldi15TransitionModelENS_9allocatorIS2_EEEE
N5kaldi6quasar20SeevaBeamSearchBigLmE
N5kaldi6quasar16CoreMLTensorDataE
N5kaldi6quasar19CoreMLNetworkConfigE
N5kaldi6quasar17CoreMLNetworkPlanE
N5kaldi5nnet124Convolutional2DComponentINS_12CuMatrixBaseIfEEEE
N5kaldi5nnet124Convolutional2DComponentINS_15QuantizedMatrixIaEEEE
N5kaldi5nnet124Convolutional2DComponentINS_15QuantizedMatrixIsEEEE
BN5kaldi6quasar19TorchEncoderDecoder14AttentionModelE
N5kaldi6quasar19TorchEncoderDecoderE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar19TorchEncoderDecoderENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_pointerIPN5kaldi6quasar19TorchEncoderDecoderENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIN5kaldi6quasar19TorchEncoderDecoderEEE
NSt3__120__shared_ptr_pointerIPN5kaldi5nnet14NnetENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIN5kaldi5nnet14NnetEEE
N5kaldi6quasar20SeevaStreamInferenceE
N5kaldi6quasar26SeevaStreamInferenceConfigE
16TaggedNgramStats
N6quasar19StreamingConfidenceE
N6quasar21LRStreamingConfidenceE
@N6quasar16PhonetisaurusG2PE
NSt3__120__shared_ptr_emplaceI13PhonetisaurusNS_9allocatorIS1_EEEE
11TaggedNgram
PN5kaldi5nnet118NormalizeComponentE
N5kaldi11CuSubVectorIfEE
N6quasar7PDecG2PE
N3fst13SortedMatcherINS_3FstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEE
N3fst9VectorFstINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS5_9allocatorIfEEEEEEEENS_11VectorStateISB_NS7_ISB_EEEEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS7_9allocatorIfEEEEEEEENS9_ISD_EEEEEENS_10MutableFstISD_EEEE
N3fst7FstImplINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS5_9allocatorIfEEEEEEEEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS6_9allocatorIfEEEEEEEENS_11VectorStateISC_NS8_ISC_EEEEEEEE
N3fst15ArcIteratorBaseINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS5_9allocatorIfEEEEEEEEEE
ON3fst9AutoQueueIiEE
N3fst15StateOrderQueueIiEE
NSt3__112__deque_baseIiNS_9allocatorIiEEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS8_9allocatorIfEEEEEEEEEENSA_ISF_EEEEEENS_10MutableFstISF_EEEE
N3fst10MutableFstINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS6_9allocatorIfEEEEEEEEEEEE
N3fst9ImplToFstINS_22DeterminizeFstImplBaseINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS7_9allocatorIfEEEEEEEEEEEENS_3FstISE_EEEE
N3fst13StateIteratorINS_14DeterminizeFstINS_10ReverseArcINS_6ArcTplINS_25LatticeWeightWithStateTplINS_16LatticeWeightTplIfEEfNSt3__16vectorIfNS7_9allocatorIfEEEEEEEEEEEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENSt3__19allocatorIS8_EEEEEENS_10MutableFstIS8_EEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENSt3__19allocatorIS8_EEEEEENS_10MutableFstIS8_EEEE
N3fst13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENSt3__19allocatorIS7_EEEEEE
N3fst10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEEEE
N5kaldi5nnet121WordMultiVecComponentINS_12CuMatrixBaseIfEEEE
N5kaldi5nnet121WordMultiVecComponentINS_16CompressedMatrixEEE
N5kaldi6quasar12ESTensorDataE
N5kaldi6quasar15ESNetworkConfigE
N5kaldi6quasar13ESNetworkPlanE
N5kaldi6quasar15FofeLmEvaluatorE
N6quasar17PhraseBookOptionsE
N6quasar25ConfiguredProcessingBlockINS_17PhraseBookOptionsEEE
N6quasar19PDecPhraseBookBlockE
22EARContextAwareLDModel
29EARContextAwareLDModelFactory
25EARAcousticLDModelFactory
NSt3__120__shared_ptr_emplaceI21CoreMLAcousticLDModelNS_9allocatorIS1_EEEE
21CoreMLAcousticLDModel
NSt3__120__shared_ptr_emplaceIN6quasar9LDContextENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceI17EARLDResultStreamNS_9allocatorIS1_EEEE
17EARLDResultStream
NSt3__120__shared_ptr_emplaceIKN6quasar9LDContextENS_9allocatorIS3_EEEE
N6quasar25ConfiguredProcessingBlockINS_16TokenizerOptionsEEE
N6quasar14TokenizerBlockE
N6quasar16TokenizerOptionsE
N6quasar31ConfusionNetworkCombinerDecoderE
NSt3__120__shared_ptr_emplaceINS_6vectorINS1_INS1_IN6quasar5TokenENS_9allocatorIS3_EEEENS4_IS6_EEEENS4_IS8_EEEENS4_ISA_EEEE
N6quasar26KeywordSpottingSyncDecoderE
NSt3__114default_deleteIN3fst11SymbolTableEEE
?9SkipNgram
8@plain-text
ngram-counts
phrase-counts
template-grammar
NSt3__120__shared_ptr_emplaceIN6quasar11ModelLoaderENS_9allocatorIS2_EEEE
NSt3__115basic_stringbufIcNS_11char_traitsIcEENS_9allocatorIcEEEE
N5kaldi13InputImplBaseE
N5kaldi13FileInputImplE
N5kaldi17StandardInputImplE
N5kaldi13PipeInputImplE
N5kaldi19OffsetFileInputImplE
N5kaldi13basic_pipebufIcEE
N6quasar24OfflineRecogResultStreamE
8LMClient
N5sdapi8SdapiG2PE
NSt3__120__shared_ptr_emplaceIN5sdapi18SimpleStringMapperENS_9allocatorIS2_EEEE
N3fst18ShortestFirstQueueIiNS_18StateWeightCompareIiNS_11NaturalLessINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEELb0EEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEENSt3__19allocatorISA_EEEEEENS_10MutableFstISA_EEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEENSt3__19allocatorISA_EEEEEENS_10MutableFstISA_EEEE
N3fst11ExpandedFstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEE
N3fst3FstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEE
N3fst10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEEE4LinkEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEENS_11VectorStateIS9_NSt3__19allocatorIS9_EEEEEEEE
N3fst22MutableArcIteratorBaseINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEE
N6quasar19ErrorBlamingDecoderE
N3fst3FstINS_6ArcTplINS_16LatticeWeightTplIfEEEEEE
NSt3__120__shared_ptr_emplaceIN5kaldi16WordBoundaryInfoENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar10LexiconFstENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi21TrainingGraphCompilerENS_9allocatorIS2_EEEE
N6quasar17FstTokenTransformE
N6quasar14TokenTransformIN3fst9VectorFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEENS1_11VectorStateIS6_NSt3__19allocatorIS6_EEEEEEEE
N6quasar24ComposeFstTokenTransformE
N6quasar34SpaceApplyDefaultFstTokenTransformE
N6quasar39RewriteApplyCapitalizeFstTokenTransformE
N6quasar36RewriteApplyDefaultFstTokenTransformE
NSt3__120__shared_ptr_emplaceIN3fst14StringCompilerINS1_6ArcTplINS1_17TropicalWeightTplIfEEEEEENS_9allocatorIS7_EEEE
N3fst13StateIteratorINS_14DeterminizeFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEE
N3fst9ArcMapFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE3EEENS_14ToGallicMapperIS4_LS6_3EEEEE
N3fst3FstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEEEE
N3fst13CacheBaseImplINS_10CacheStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEENSt3__19allocatorIS8_EEEENS_17DefaultCacheStoreIS8_EEEE
N3fst10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEEEEE4LinkEEE
N3fst13StateIteratorINS_9ArcMapFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE3EEENS_14ToGallicMapperIS5_LS7_3EEEEEEE
N3fst17StateIteratorBaseINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEEEE
N3fst14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEENSt3__19allocatorIS9_EEEEEENS_10MutableFstIS9_EEEE
N3fst11ExpandedFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N3fst3FstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEEE4LinkEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEENSt3__19allocatorISB_EEEEEENS_10MutableFstISB_EEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEENSt3__19allocatorISB_EEEEEENS_10MutableFstISB_EEEE
N3fst11ExpandedFstINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEEEE
N3fst10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEEEEE4LinkEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEENS_11VectorStateISA_NSt3__19allocatorISA_EEEEEEEE
N3fst9CacheImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N3fst13StateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEENS_12GallicFactorIiS5_LS7_0EEEEEEE
N6quasar18OnlineSeevaDecoderE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEE4LinkEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEENSt3__19allocatorIS8_EEEEEENS_10MutableFstIS8_EEEE
N3fst10ComposeFstINS_6ArcTplINS_16LatticeWeightTplIfEEEENS_17DefaultCacheStoreIS4_EEEE
10ClassNgram
N5srilm10StringIterE
10WittenBell
9AddSmooth
N6quasar7FeatureE
N6quasar17IntToFloatFeatureE
N6quasar19SamplingRateFeatureE
N6quasar15LocationFeatureE
N6quasar14OnlineAppendFeE
NSt3__120__shared_ptr_emplaceIN6quasar19SamplingRateFeatureENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar15LocationFeatureENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi17OnlineAppendInputENS_9allocatorIS2_EEEE
N6quasar22SimpleTokenizerOptionsE
N6quasar25ConfiguredProcessingBlockINS_22SimpleTokenizerOptionsEEE
N6quasar20SimpleTokenizerBlockE
NSt3__118codecvt_utf8_utf16IwLm1114111ELNS_12codecvt_modeE0EEE
NSt3__111__end_stateIwEE
NSt3__16__nodeIwEE
NSt3__120__shared_ptr_pointerIPNS_13__empty_stateIwEENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteINS_13__empty_stateIwEEEE
NSt3__113__empty_stateIwEE
NSt3__116__owns_one_stateIwEE
NSt3__115__has_one_stateIwEE
NSt3__110__l_anchorIwEE
NSt3__110__r_anchorIwEE
NSt3__115__word_boundaryIwNS_12regex_traitsIwEEEE
NSt3__111__lookaheadIwNS_12regex_traitsIwEEEE
NSt3__123__match_any_but_newlineIwEE
NSt3__118__match_char_icaseIwNS_12regex_traitsIwEEEE
NSt3__120__match_char_collateIwNS_12regex_traitsIwEEEE
NSt3__112__match_charIwEE
NSt3__116__back_ref_icaseIwNS_12regex_traitsIwEEEE
NSt3__118__back_ref_collateIwNS_12regex_traitsIwEEEE
NSt3__110__back_refIwEE
NSt3__120__bracket_expressionIwNS_12regex_traitsIwEEEE
NSt3__128__begin_marked_subexpressionIwEE
NSt3__126__end_marked_subexpressionIwEE
NSt3__16__loopIwEE
NSt3__117__owns_two_statesIwEE
NSt3__117__repeat_one_loopIwEE
NSt3__111__alternateIwEE
NSt3__121__empty_non_own_stateIwEE
NSt3__111__match_anyIwEE
N6quasar11RecogResultE
N6quasar21RecogResultStreamBaseE
N6quasar9SanitizerE
N6quasar27OnlineAudioAnalyticsDecoderE
NSt3__120__shared_ptr_pointerIPN6quasar13TextTokenizerENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN6quasar13TextTokenizerEEE
12NgramCountLM
N5kaldi20OnlineAudioSourceItfE
N5kaldi6quasar12ErrorProfileE
N6quasar9PronCacheINSt3__112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEENS1_6vectorIS7_NS5_IS7_EEEEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE3EEENS_14ToGallicMapperIS5_LS7_3EEEEENS_3FstIS8_EEEE
N3fst13ArcMapFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE3EEENS_14ToGallicMapperIS4_LS6_3EEEEE
N3fst9CacheImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEEEE
N3fst7FstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEEEE
N3fst9ImplToFstINS_22DeterminizeFstImplBaseINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEEEENS_3FstIS8_EEEE
N3fst18DeterminizeFsaImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEENS_19GallicCommonDivisorIiS4_LS6_3ENS_20DefaultCommonDivisorIS4_EEEENS_24DefaultDeterminizeFilterIS7_EENS_28DefaultDeterminizeStateTableIS7_NS_18IntegerFilterStateIaEEEEEE
N3fst22DeterminizeFstImplBaseINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEEEE
N6quasar9RegexStepE
N6quasar11ReplaceStepE
N6quasar9SplitStepE
NSt3__120__shared_ptr_emplaceIN6quasar11ReplaceStep9RegexRuleENS_9allocatorIS3_EEEE
N6quasar15FileCoordinatorE
N6quasar18LanguageRecognizerE
N6quasar22OnlineSeevaStepDecoderE
N6quasar17TranslatorFactoryE
NSt3__120__shared_ptr_emplaceIN6quasar21PDecTranslatorFactoryENS_9allocatorIS2_EEEE
N3fst14DeterminizeFstINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEE
N3fst13VectorFstImplINS_11VectorStateINS_6ArcTplINS_12LogWeightTplIfEEEENSt3__19allocatorIS5_EEEEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_6ArcTplINS_12LogWeightTplIfEEEENSt3__19allocatorIS5_EEEEEE
N3fst7FstImplINS_6ArcTplINS_12LogWeightTplIfEEEEEE
N3fst22MutableArcIteratorBaseINS_10ReverseArcINS_6ArcTplINS_12LogWeightTplIfEEEEEEEE
N3fst9CacheImplINS_6ArcTplINS_12LogWeightTplIfEEEEEE
N3fst9CacheImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEEEE
N3fst13CacheBaseImplINS_10CacheStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEENSt3__19allocatorIS8_EEEENS_17DefaultCacheStoreIS8_EEEE
N3fst10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEEEEEE
N3fst9ImplToFstINS_22DeterminizeFstImplBaseINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEEEENS_3FstIS8_EEEE
N3fst9VectorFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEENS_11VectorStateIS7_NSt3__19allocatorIS7_EEEEEE
N3fst11ExpandedFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEENSt3__19allocatorIS8_EEEEEE
N3fst15ArcIteratorBaseINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEENSt3__19allocatorISB_EEEEEENS_10MutableFstISB_EEEE
N3fst7FstImplINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEEEE
N3fst10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEEEEEE
N3fst9CacheImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N3fst13CacheBaseImplINS_10CacheStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEENSt3__19allocatorIS8_EEEENS_17DefaultCacheStoreIS8_EEEE
N3fst18CacheStateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEENS_12GallicFactorIiS5_LS7_0EEEEEEE
N6quasar16CommandTransformE
N6quasar23AllCapsCommandTransformE
N6quasar25AllCapsOnCommandTransformE
N6quasar19CapCommandTransformE
N6quasar22CapsOnCommandTransformE
N6quasar23CapsOffCommandTransformE
N6quasar22NoCapsCommandTransformE
N6quasar24NoCapsOnCommandTransformE
N6quasar23NoSpaceCommandTransformE
N6quasar25NoSpaceOnCommandTransformE
N6quasar26NoSpaceOffCommandTransformE
N6quasar23NewLineCommandTransformE
N6quasar28NewParagraphCommandTransformE
N6quasar31PeriodParagraphCommandTransformE
N6quasar22TabKeyCommandTransformE
N6quasar28NoBreakSpaceCommandTransformE
N6quasar24SpaceBarCommandTransformE
N6quasar25BackslashCommandTransformE
N6quasar26AllCapsOffCommandTransformE
N6quasar25NoCapsOffCommandTransformE
NSt3__120__shared_ptr_emplaceIN6quasar23AllCapsCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar25AllCapsOnCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar26AllCapsOffCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar19CapCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar22CapsOnCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar23CapsOffCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar22NoCapsCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar24NoCapsOnCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar25NoCapsOffCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar23NoSpaceCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar25NoSpaceOnCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar26NoSpaceOffCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar23NewLineCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar28NewParagraphCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar31PeriodParagraphCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar22TabKeyCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar28NoBreakSpaceCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar24SpaceBarCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar25BackslashCommandTransformENS_9allocatorIS2_EEEE
N5boost6system14error_category12std_categoryE
N5boost6system12_GLOBAL__N_121system_error_categoryE
N5boost6system14error_categoryE
N5boost12noncopyable_11noncopyableE
N5boost6system12_GLOBAL__N_122generic_error_categoryE
N5boost10filesystem16filesystem_errorE
N5boost6system12system_errorE
N5boost6detail17sp_counted_impl_pINS_10filesystem16filesystem_error5m_impEEE
N5boost6detail17sp_counted_impl_pINS_10filesystem6detail11dir_itr_impEEE
N6marisa9ExceptionE
We love Marisa.
N13sentencepiece3bpe5ModelE
N13sentencepiece5model8FreeListIZNKS_3bpe5Model6EncodeEN4absl11string_viewEE10SymbolPairEE
NSt3__110__function6__funcIZNK13sentencepiece3bpe5Model6EncodeEN4absl11string_viewEE3$_1NS_9allocatorIS7_EEFvS6_PNS_6vectorINS_4pairIS6_iEENS8_ISC_EEEEEEE
NSt3__110__function6__baseIFvN4absl11string_viewEPNS_6vectorINS_4pairIS3_iEENS_9allocatorIS6_EEEEEEE
ZNK13sentencepiece3bpe5Model6EncodeEN4absl11string_viewEE3$_1
N13sentencepiece31SentencePieceText_SentencePieceE
N13sentencepiece17SentencePieceTextE
N13sentencepiece22NBestSentencePieceTextE
N13sentencepiece11TrainerSpecE
N13sentencepiece14NormalizerSpecE
N13sentencepiece19SelfTestData_SampleE
N13sentencepiece12SelfTestDataE
N13sentencepiece24ModelProto_SentencePieceE
N13sentencepiece10ModelProtoE
N6google8protobuf8internal29InternalMetadataWithArenaBaseINSt3__112basic_stringIcNS3_11char_traitsIcEENS3_9allocatorIcEEEENS1_29InternalMetadataWithArenaLiteEE9ContainerE
NSt3__112basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEE
NSt3__121__basic_string_commonILb1EEE
N13sentencepiece9character5ModelE
N13sentencepiece10filesystem17PosixReadableFileE
N13sentencepiece10filesystem12ReadableFileE
N13sentencepiece14ModelInterfaceE
N13sentencepiece10normalizer10NormalizerE
N5Darts15DoubleArrayImplIvvivEE
N5Darts7Details9ExceptionE
N13sentencepiece22SentencePieceProcessorE
N13sentencepiece7unigram5ModelE
N13sentencepiece7unigram7LatticeE
N13sentencepiece5model8FreeListINS_7unigram7Lattice4NodeEEE
N13sentencepiece5model8FreeListIZNS_7unigram7Lattice5NBestEmE10HypothesisEE
N13sentencepiece4word5ModelE
N6google8protobuf14FatalExceptionE
N6google8protobuf8internal15ExtensionFinderE
N6google8protobuf8internal24GeneratedExtensionFinderE
N6google8protobuf8internal12ExtensionSet8KeyValueE
N6google8protobuf13RepeatedFieldIiEE
N6google8protobuf13RepeatedFieldIxEE
N6google8protobuf13RepeatedFieldIjEE
N6google8protobuf13RepeatedFieldIyEE
N6google8protobuf13RepeatedFieldIfEE
N6google8protobuf13RepeatedFieldIdEE
N6google8protobuf13RepeatedFieldIbEE
N6google8protobuf16RepeatedPtrFieldINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEEE
N6google8protobuf8internal20RepeatedPtrFieldBaseE
N6google8protobuf16RepeatedPtrFieldINS0_11MessageLiteEEE
NSt3__13mapIiN6google8protobuf8internal12ExtensionSet9ExtensionENS_4lessIiEENS_9allocatorINS_4pairIKiS5_EEEEEE
N6google8protobuf11MessageLiteE
N6google8protobuf8internal12FieldSkipperE
N6google8protobuf8internal29CodedOutputStreamFieldSkipperE
N6google8protobuf2io20ZeroCopyOutputStreamE
N6google8protobuf2io17ArrayOutputStreamE
N6google8protobuf2io18StringOutputStreamE
decoders.
.lattice-biglm-lme-faster.supported-lme-template-list
Couldn't get supported LME list
oov-replacement value 
 is not a supported LME for specified decoder chain
slot-to-lme-map
Map from developer slots to LMEs
Empty LME template for slot 
lmeDataFactory initialization with 
 failed
G2P initialization with 
Tokenizer failed to tokenize '
|\(|\)|"|\[|\]|\{|\}|
|,|;|\?|\!|\\
Can't add pronunciation for 
 (word is not OOV)
No OOVs to add
Could not get LME data
Can't open 
 for writing
app-lm.data
Error reading JSON config file: 
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
QSR_CRASH_ON_WARN
Texture coordinates (
) out of range
Bitmap coordinates (
) out of bounds
Computing pdf-priors from : 
 out of 
 classes have counts
 lower than 
--class-frame-counts is empty: Cannot initialize priors 
without the counts.
Dimensionality mismatch,
 class_frame_counts 
 pdf_output_llk 
Invalid pdf (
): log-prior dimension = 
<InputData>
<InputDataDim>
<InputDataShape>
<OutputData>
<OutputDataDim>
<OutputDataShape>
<InputExtraList>
<OutputExtraList>
<InputPenultimate>
<OutputPenultimate>
<OutputPenultimateDim>
<InputRequestedUnit>
<GraphReset>
<IsRNN>
<IsFOFE>
<Engine>
</Engine>
Unknown token 
, a typo in config file?
row_index >= 0 && col_index >= 0
!shape.empty()
.config
in != nullptr
out_vec.Dim() % row_num == 0
out_vec.Dim() == out_numrows * out_numcols
!out_node.empty()
Unimplemented TODO
the number of input tensors 
 != 
 , the list of input tensor names
you requested additional outputs, but haven't defined any tensors for that
ReadBasicType: encountered end of stream.
ReadBasicType: did not get expected integer type, 
 vs. 
.  You can change this code to successfully
 read it later, if needed.
Read failure in ReadBasicType, file position is 
, next char is 
expanded
mutable
error
acceptor
not acceptor
input deterministic
non input deterministic
output deterministic
non output deterministic
input/output epsilons
no input/output epsilons
input epsilons
no input epsilons
output epsilons
no output epsilons
input label sorted
not input label sorted
output label sorted
not output label sorted
weighted
unweighted
cyclic
acyclic
cyclic at initial state
acyclic at initial state
top sorted
not top sorted
accessible
not accessible
coaccessible
not coaccessible
string
not string
 -> 
Phone changed before final transition-id found [broken lattice or mismatched model or wrong --reorder option?]
FATAL
ERROR
ImplToFst: Assignment operator disallowed
Fst::Write: No write stream method for 
 Fst type
Fst::Write: No write filename method for 
vector
null
TestProperties: stored Fst properties incorrect
 (stored: props1, computed: props2)
CompatProperties: mismatch: 
: props1 = 
true
false
, props2 = 
VectorFst::Write: write failed: 
Inconsistent number of states observed during write
tropical
standard
compact
lattice4
Fst::UpdateFstHeader: write failed: 
Fst::Write: Can't open file: 
standard output
Trying to word-align empty lattice.
INFO
AutoQueue: using state-order discipline
AutoQueue: using top-order discipline
AutoQueue: using LIFO discipline
AutoQueue: using SCC meta-discipline
AutoQueue: SCC #
: using trivial discipline
: using shortest-first discipline
: using LIFO disciplle
: using FIFO disciplle
TopOrderQueue: fst is not acyclic.
RmEpsilon: inconsistent acyclic property bit
Prune: Weight needs to have the path property and
 be commutative: 
uapd
LME STREAM DUMP [Header]
LME STREAM DUMP 
: qsrHeader = 
Incorrect quasar blob header
: metaVersion = 
Incorrect quasar blob version
: dataTypeStr = 
Incorrect data type for Lme
Incorrect data type for UserAcusticProfileData
Incorrect data type for UserAcousticProfileData
: dataVersion = 
Was looking for B, but got 
Write failure in WriteBasicType.
loglikes
att_probs
Function is not implemented for this class
No frames output in pitch extraction
Pitch-tracking Viterbi cost is 
 per frame, over 
 frames.
Forward-cost per frame changed from 
 to 
Latency is 
Could not align output
Write failure in WriteIntegerType.
ReadIntegerVector: expected to see type of size 
, saw instead 
, at file position 
ReadIntegerVector: expected to see [, saw 
ReadIntegerVector: read failure at file position 
Silence label is set to 
 but does not match the auto-determined silence label 
. Will use latter.
Word alignment for MBR decoding failed.
Empty aligned lattice. MBR decoding failed.
Best-path failed
Lattice word alignment time: 
word-boundary-int-file
Word boundary file with format <integer-phone-id> [begin|end|singleton|internal|nonword]
unpronounced-word-file
File containing newline-separated list of words with no pronunciation.
max-expand
If >0, the max amount by which lattices will be expanded.
Could not read clock 
silence-label
Numeric id of word symbol that is to be used for silence arcs in the word-aligned lattice (zero is OK)
partial-word-label
Numeric id of word symbol that is to be used for arcs in the word-aligned lattice corresponding to partial words at the end of "forced-out" utterances (zero is OK)
reorder
True if the lattices were generated from graphs that had the --reorder option true, relating to reordering self-loops (typically true)
Could not convert
<RecurrentComponentType>
</Component>
, a typo in config?
 (RecurrentComponentType)
you defined two different recurrent component types 
 vs 
<InputDim>
<OutputDim>
this is not a recurrent component, initialization failed, you used 
Unrecognized token 
forward component is not an RNN
backward component is not an RNN
## Forward RNN: input-dim 
, output-dim 
## Backward RNN: input-dim 
Running forward propagation for batch size = 
, which contains 
 frames each from 
 utterances.
Running backward propagation for batch size = 
no recursive recurrent definition
the forward RNN's input dimension does not match the component's input dimension 
the backward RNN's input dimension does not match the component's input dimension 
the component has output dimension 
 , doesn't equal the sum of individual RNN 
 and 
This function is probably not meaningful for bidirectional RNNs.
need RecurrentNnetTrainOptions in recurrent style component, ignoring SetTrainOptions
Inconsistent return type: RecurrentBaseComponent::GetTrainOptions() can not be cast to RecurrentNnetTrainOptions
VectorizeWeightsCorrs
 is not implemented for 
 component.
Function not implemented for this class
GetUnitOutputFnc
GetNormalizedLearningRate
PerturbParams
GetGradient
Running on single input doesn't make sense for bidirectional RNNs, since history state is not saved.
Forward RNN is not quantizable
Backward RNN is not quantizable
VoiceTrigger
WatermarkDetector not run on input origin 
WatermarkDetector: not enough audio cached.
Failed to compute spectrogram.
WatermarkPeakAvg
WatermarkPeakMax
WatermarkDetected
WatermarkDetector peakMax=
, peakAvg=
, detected=
watermark-detector
above-hi
Frequency (in Hz) of top of upper band
above-lo
Frequency (in Hz) of bottom of upper band
notch-hi
Frequency (in Hz) of top of notch
notch-lo
Frequency (in Hz) of bottom of notch
below-hi
Frequency (in Hz) of top of lower band
below-lo
Frequency (in Hz) of bottom of lower band
supported-input-origins-list
The input origins that are supported (should be comma separated)
watermark-threshold
Average notch threshold value to detect a watermark
povey
mincount %s
maxcount %s
discount %u %lf
mincount %99s
maxcount %99s
maxcount value out of range
discount %u %lf
warning: count value out of range
unrecognized parameter
warning: discount coefficient 
 = 0.0
Good-Turing discounting 
-grams
GT-count [
] = 
warning: no singleton counts
warning: count of count 
 is zero 
-- lowering maxcount
GT discounting disabled
 is zero
warning: discount coeff 
 is out of range: 
discount1 %lf
discount1 %lf
Kneser-Ney smoothing 
n1 = 
n2 = 
one of required KneserNey count-of-counts is zero
D = 
modifying 
-gram counts for Kneser-Ney smoothing
discount2 %lf
discount3+ %lf
discount2 %lf
discount3+ %lf
n3 = 
n4 = 
one of required modified KneserNey count-of-counts is zero
D1 = 
D2 = 
D3+ = 
one of modified KneserNey discounts is negative
discounting method does not support float counts
: Expected token 
, got 
Got EOF while reading matrix data
After end of matrix data, read error.
Stream failure/EOF while reading matrix data.
infinity
Reading negative infinite value into matrix.
Reading negative NaN value into matrix.
Expecting numeric matrix data, got 
Reading infinite value into matrix.
Reading NaN value into matrix.
 File position at start is 
, currently 
Failed to write vector to stream: stream not good
Processed 
 of 
max-radius-km
ContextDependency
ToPdf
EndContextDependency
ToLength
Got unexpected token 
 reading context-dependency object.
.bz2
warning: '-' used multiple times for input
warning: '-' used multiple times for output
exec compress -c
exec uncompress -c
exec gzip -c
exec gzip -dcf
exec bzip2
exec bzip2 -dcf
exec 7z a -si
exec 7z e -so
exec xz
exec xz -dcf
%s;%s %s
%s;%s >%s
<Epsilon>
<Gamma>
<Beta>
Reading LayerNorm component
 ( min 
, max 
, mean 
, variance 
, skewness 
, kurtosis 
Invalid silence-phones string 
This doesn't work when utt detect is enabled. Doing nothing.
Lattice is null. Doing nothing
Lattice is empty. Doing nothing
~w00
Best conf result sessionId: 
 result: 
WORD_EMBED
IS_LME
LME_ID
IS_SIL
NUM_PHONES
AC_COST_UNPUSHED
IN_BEST_PATH
AC_COST
GRAPH_COST
NUM_FRAMES
LOG_POSTERIOR
LIN_POSTERIOR
Unknown feature type: 
model-feature-list
Comma-separated list of arc features. Example: "BAG_OF_PHONES,KEYWORD:hey,KEYWORD:Siri,LM_SCORE,AC_SCORE,NUM_FRAMES,LOG_POSTERIOR,LIN_POSTERIOR"
sil-phone-csl-file
File containing colon-separated list of silence phones.
node-merge-tol-ms
Node merging tolerance in ms
word-emb-marisa-file
MARISA trie file for word embedding lookup
word-emb-mat-flt32-file
Kaldi binary matrix file (float32) that stores word embeddings
transform-file
See LatticeRnn in nnet/lattice-rnn.h
forward-model-file
backward-model-file
arc-output-model-file
Obtained HWCN in 
StopWatch is still running.
StopWatch is already running.
warning: 
<unk>
</s>
-pau-
error writing 
version
print version information
order
max ngram order
debug
tagged
skip
classes
class definitions
simple-classes
use unique class model
stop-words
stop-word vocabulary for stop-Ngram LM
map-unk
word to map unknown words to
tolower
map vocabulary to lowercase
float-counts
cache-served-ngrams
enable client side caching
vocab
vocab file
vocab-aliases
vocab alias file
nonevents
non-event vocabulary
limit-vocab
maxent
maxent-convert-to-arpa
cache
count-lm
reverse
no-sos
don't insert start-of-sentence tokens
no-eos
don't insert end-of-sentence tokens
write-vocab
prune
prune redundant probs
minprune
prune only ngrams at least this long
memuse
show memory usage
nbest
model-file
Endpoint model file
sequence of features for endpoint model
enable-memory-map
model is memory mapped
endpoint-threshold
Threshold for final endpoint detection
trailing-silence-limit
An upper limit for trailing silence duration (miliseconds) after which recognizer should be forced to endpoint
extra-delay-ms
delaying the endpointer trigger decision by th given amount of time (in msec), when specified.
silence-posterior-nfhat-limit
An upper limit for silence posterior NFHat estimate (miliseconds) after which recognizer should be forced to endpoint
server-features-latency-clamp-begin
Starting point (in miliseconds)for ServerFeaturesLatency Clamp. ServerFeaturesLatency will be clamped at this value for the duration of clamp i.e [serverFeaturesLatencyClampBeginMs, serverFeaturesLatencyClampEndMs]
server-features-latency-clamp-end
Ending point (in miliseconds)for ServerFeaturesLatency Clamp. ServerFeaturesLatency will be allowed to update after this point i.e it will not be clamped anymore
endpoint-threshold needs to be configured to a value between 0-1
num-of-words default
trailing-silence-duration default
eos-likelihood default
silence-posterior default
Hybrid endpointer created with incorrect version
hybrid-endpoint
hybrid-endpoint.
Missing hybrid endpointer config
eager-result-acceptance
eager-result-acceptance.
Missing eager-result-acceptance config
default-server-ep-features
default-server-ep-features.
No available endpointer for samplingRate = 
Feature dim=
 does not match model dim=
Nnet output for endpointing is incorrect
, ep-nnet-value=
EagerResultAccept not configured
Nnet output for recognitionResult validation is incorrect
, nnet-output=
misc-shared.
misc-shared
endpoint.
endpoint
eager.
eager
geo-config-file
The 
 field available since version 
. Please upgrade config.
feature-read.
feature-read
recognizers
No recognizer component for certain combinations.
Unsupported config file version
voice-trigger-phrase
VoiceTrigger phrase as space separated list of tokens as recognized by the decoder
Endpointing model file
feature-list
List of features
batch-size
Number of feature vectors processed w/o interruption
\NT-inline
GCCacheStore: Enter GC: object = 
), free recently cached = 
, cache size = 
, cache frac = 
, cache limit = 
(size) <= (cache_size_)
../libquasar/libkaldi/tools/openfst/src/include/fst/cache.h
GCCacheStore:GC: Unable to free all cached states
GCCacheStore: Exit GC: object = 
Check failed: "
" file: 
 line: 
SortedMatcher: bad match type
compose
ComposeFst: output symbol table of 1st argument 
does not match input symbol table of 2nd argument
WARNING
CompatSymbols: Symbol table check sums do not match. 
Table sizes are 
ComposeFst: 1st argument requires matching but cannot.
ComposeFst: 2nd argument requires matching but cannot.
ComposeFst: 1st argument cannot match on output labels 
and 2nd argument cannot match on input labels (sort?).
ComposeFst: both sides can't require match
ComposeFstMatcher: safe copy not supported
LookAheadComposeFilter: 1st argument cannot 
match/look-ahead on output labels and 2nd argument 
cannot match/look-ahead on input labels.
LookAheadMatcher: No look-ahead matcher defined
MultiEpsMatcher: Bad multi-eps label: 0
SingleShortestPath: for nshortest > 1, use ShortestPath
 instead
SingleShortestPath: weight and state thresholds not applicable
reverse_
NShortestPath: FST has a cycle and include_final_ties was set to true. This is not currently supported.
DeterminizeFst:
 distance to final states computed for acceptors only
DeterminizeFst: argument not an acceptor
determinize
DeterminizeFsaImpl: cannot copy with out_dist vector
<ShortlistTable>
<ShortlistLangPairs>
Has shortlist, but dissabled due to shortlist-lang-pair = 
, lp = 
, shortlist-cond-n = 
, shortlist-freq-n = 
Using shortlist, reducing Voc size to 
ConstrainSoftmax
  linearity is quantized
  bias
BackpropagateFnc
 Not implemented!
linearity_
bias_
orthography
T@"NSString",R,N,V_orthography
Tq,R,N,V_tag
tagName
T@"NSString",R,N
frequency
TQ,R,N,V_frequency
pronunciations
T@"NSSet",R,N,V_pronunciations
Can't init factory :(
v32@?0@"NSString"8@"NSString"16^B24
Can't init LmeDataFactory: (unexpected exception)
Can't init LmeDataFactory: %s
could not get LME data :( %d
Failed to read quasar pronunciation cache from profile blob with error : 
EARUserProfileBuilder.mm
Tokenizer is invoked after explicit release!
\contact-first
\contact-middle
\contact-last
\contact-nickname
\company-first
\app-first
\jit
none
ERROR 
ar_AE
bg_BG
zh_CN
zh_TW
hr_HR
cs_CZ
da_DK
nl_NL
nl_BE
en_AE
en_AU
en_GB
en_ID
en_IE
en_IN
en_MY
en_PH
en_SA
en_SG
en_US
en_ZA
fi_FI
fr_BE
fr_CA
fr_FR
de_AT
de_CH
de_DE
el_GR
he_IL
hi_IN
hu_HU
is_IS
it_IT
ja_JP
ko_KR
mr_IN
nb_NO
pl_PL
pt_BR
pt_PT
ro_RO
ru_RU
sk_SK
es_CL
es_CO
es_ES
es_US
sv_SE
th_TH
tr_TR
uk_UA
ur_PK
hy_AM
bn_IN
pa_IN
gu_IN
or_IN
ta_IN
ta_LK
te_IN
kn_IN
ml_IN
si_LK
lo_LA
bo_CN
bo_IN
my_MM
ka_GE
am_ET
iu_CA
km_KH
mn_CN
Unknown locale specified in configuration: 
notchWidth %d, antiNotch %d, mR %d, mK %d, mN %d 
notchVec[%d]=%d 
notch-detector.psd.txt
notch-detector.fft.txt
notch-detector.feats.txt
there are 
<VocabSize>
<UnknownWord>
<BeginOfSentenceWord>
<EndOfSentenceWord>
the vector cannot be represented as a matrix with rows 
 , while it has dimension 
{ wordCount: %ld, trailingSilenceDuration: %ld, endOfSentenceLikelihood: %f, pauseCounts: ( %@ ), silencePosterior: %f, clientSilenceFramesCountMs: %f, clientSilenceProbability: %f, silencePosteriorNF: %f, serverFeaturesLatency: %f, eagerResultEndTime: %ld }
wordCount
Tq,N,V_wordCount
trailingSilenceDuration
Tq,N,V_trailingSilenceDuration
endOfSentenceLikelihood
Td,N,V_endOfSentenceLikelihood
pauseCounts
T@"NSArray",C,N,V_pauseCounts
silencePosterior
Td,N,V_silencePosterior
clientSilenceFramesCountMs
Td,N,V_clientSilenceFramesCountMs
clientSilenceProbability
Td,N,V_clientSilenceProbability
silencePosteriorNF
Tf,N,V_silencePosteriorNF
serverFeaturesLatency
Tf,N,V_serverFeaturesLatency
eagerResultEndTime
Tq,N,V_eagerResultEndTime
Tf,N,V_endOfSentenceLikelihood
Tf,N,V_silencePosterior
Configuration file %@ does not exist
filter-devices cannot be empty
filter-input-origins cannot be empty
An earlier LatticeRnn in the decoder chain already ran. Doing nothing.
Request does not match filter. Doing nothing.
LatticeRnn output is incorrect 
latnnMitigatorScore
Model version
output-model-file
phone-pd2pi-file
bag-of-phones-model-file
Map model into memory (requires aligned models)
threshold
0 = not trigger, 1 = trigger
filter-devices
FORMAT: Pipe-separated list of devices with support for wildcards. Wildcards must come at the end of each device in the list. Example 1: "filter-devices": "*" - matches any device. Example 2: "filter-devices": "iPhone7|Watch*|AudioAccessory1" - matches iPhone7, AudioAccessory1, and devices starting with "Watch". USAGE: One decoder chain can have multiple LatticeRnnMitigators, which are specified using colon notation to create unique names. Example decoder chain: lattice-biglm-lme-faster, ..., lattice-rnn-mitigator:X, lattice-rnn-mitigator:Y, lattice-rnn-mitigator:Z. The LatticeRnnMitigators are checked one-by-one in order. The first one that matches a request will 'claim' the request, run, and prevent the rest from running. All the filter-* conditions are AND'ed together, so a request must match all of them for the corresponding LatticeRnnMitigator to run.
filter-input-origins
List of input origins with the same format as filter-devices.
AC_SCORE
BAG_OF_PHONES
KEYWORD
Cannot find symbol ID for 
LM_SCORE
the input grammar data is empty
the input symbol table is empty
<eps>
LME: no user data available for creating a grammar FST
word <
> not in the input symbol table
/WORD-DIS-
Illegal word: 
Invalid phone in pron for word: 
Word 
Word does not exist in lexicon: 
Phone 
) does not exist in the lexicon
Illegal phone: 
For a lexicon using pos-dep phones, cannot view disambig IDs with pos-indep phones
For a lexicon using pos-indep phones, cannot view disambig IDs with pos-dep phones
Invalid phone 
 not found in lexicon.
Removing a pron for word: 
the base lexicon is not at base phone set mode
the preferred lexicon is not at base phone set mode
the base lexicon and preferred lexicon have different phone set
the guessed lexicon is not at base phone set mode
the base lexicon and guessed lexicon have different phone set
the preferred lexicon and guessed lexicon has different phone set
all input lexicons (base, preferred, guessed) are empty
input user data is empty
AlternativesProcessorBlock
 Config:
tag [
] is not recognized; panicking, cannot produce metaValue
Failed adding meta info, original metaInfo 
Mapping file '
' is not found
<default>
RecogCpuTimeMs
AverageActiveTokensPerFrame
EARErrorDomain
speakingRate
averagePauseDuration
jitter
shimmer
pitch
voicing
 tokenName=%@, start=%f, silenceStart=%f, end=%f, confidence=%f, hasSpaceAfter=%d, hasSpaceBefore=%d, phoneSeq=%@, ipaPhoneSeq=%@
quasarToken
T{Token={basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}IIIfBB{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}},R,N,V_quasarToken
tokenName
T@"NSString",R,C,N
start
Td,R,N
silenceStart
confidence
hasSpaceAfter
TB,R,N
hasSpaceBefore
phoneSequence
ipaPhoneSequence
acousticFeatureValuePerFrame
T@"NSArray",R,C,N,V_acousticFeatureValuePerFrame
frameDuration
Td,R,N,V_frameDuration
speechRecognitionFeatures
T@"NSDictionary",R,C,N,V_speechRecognitionFeatures
acousticFeatures
T@"NSDictionary",R,C,N,V_acousticFeatures
(ver=%@, score=%f, threshold=%f)
T@"NSString",R,C,N,V_version
score
Tf,R,N,V_score
Tf,R,N,V_threshold
<tokenSausage = %@, interpretationIndices = %@>
tokenSausage
T@"NSArray",R,C,N,V_tokenSausage
interpretationIndices
T@"NSArray",R,C,N,V_interpretationIndices
recognition
T@"_EARSpeechRecognition",R,C,N,V_recognition
preITNRecognition
T@"_EARSpeechRecognition",R,C,N,V_preITNRecognition
recognitionIsFormatted
TB,R,N,V_recognitionIsFormatted
isFinal
TB,R,N,V_isFinal
audioAnalytics
T@"_EARAudioAnalytics",R,C,N,V_audioAnalytics
utteranceStart
Td,R,N,V_utteranceStart
latticeMitigatorResult
T@"_EARLatticeMitigatorResult",R,C,N,V_latticeMitigatorResult
quasarTokens
T{vector<quasar::Token, std::__1::allocator<quasar::Token> >=^{Token}^{Token}{__compressed_pair<quasar::Token *, std::__1::allocator<quasar::Token> >=^{Token}}},R,N,V_quasarTokens
quasarPreItnTokens
T{vector<quasar::Token, std::__1::allocator<quasar::Token> >=^{Token}^{Token}{__compressed_pair<quasar::Token *, std::__1::allocator<quasar::Token> >=^{Token}}},R,N,V_quasarPreItnTokens
tokens
T@"NSArray",R,C,N
preITNTokens
%d.%d
com.apple._EARSpeechRecognizer.recognition
com.apple._EARSpeechRecognizer.formatter
com.apple._EARSpeechRecognizer.training
v32@?0@"NSString"8Q16^B24
EARSpeechRecognizer.mm
v8@?0
Could not build recognizer: %d
[ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ]
dispatch.voc
lexicon.enh
token_s.enh
com.apple._EARSpeechRecognizer.recognition.workloop
Tokenized "
" to "
", "
Dictation
@"NSString"12@?0i8
v28@?0@"<_EARLanguageModelDataSource>"8f16^B20
Disabling eager to maintain compatibility with utterance detection
userProfileData
T@"NSData",C,N,V_userProfileData
jitProfileData
T@"NSData",C,N,V_jitProfileData
modelInfo
T@"_EARSpeechModelInfo",R,N
detectUtterances
TB,N,V_detectUtterances
concatenateUtterances
TB,N,V_concatenateUtterances
endpointStart
Td,N,V_endpointStart
recognizeEagerCandidates
TB,N,V_recognizeEagerCandidates
farField
TB,N,V_farField
highPriority
TB,N,V_highPriority
maximumRecognitionDuration
Td,N,V_maximumRecognitionDuration
recognitionReplacements
T@"NSDictionary",C,N,V_recognitionReplacements
recognitionConfidenceSubtraction
T@"NSDictionary",C,N,V_recognitionConfidenceSubtraction
leftContext
T@"NSArray",C,N,V_leftContext
inputOrigin
T@"NSString",C,N,V_inputOrigin
deviceId
T@"NSString",C,N,V_deviceId
refTranscriptForErrorBlaming
T@"NSString",C,N,V_refTranscriptForErrorBlaming
bluetoothDeviceId
T@"NSString",C,N,V_bluetoothDeviceId
userId
T@"NSString",C,N,V_userId
sessionId
T@"NSString",C,N,V_sessionId
extraLmList
T@"NSArray",C,N,V_extraLmList
speakerCode
T@"NSString",C,N,V_speakerCode
samplingRates
T@"NSSet",R,N
tasks
language
phoneSetVersion
acousticProfileVersion
hash
TQ,R
superclass
T#,R
description
T@"NSString",R,C
debugDescription
T@"NSError",R,N,V_error
results
T@"NSArray",R,N,V_results
Quasar internal unknown exception
Quasar internal C++ exception: %s
Quasar executor unknown exception
Quasar executor C++ exception: %s
Could not report recognition error: %@
v32@?0@"NSString"8@16^B24
Recognition was unsucessful
.mlmodelc
Configuration needs either 'romanizer' or 'pron-guide-model-file'
romanization
Failed to create ICU Transilerator for scripts : 
Failed to create unicode string for "
wstring_convert: from_bytes error
wstring_convert: to_bytes error
 not contained in BPE encoder 
 mapping to 
Failed to create UTF-8 string: 
RomanizerBlock
<space>
</w>
failed to unmap region: 
Failed to hint VM for 
mmap'ed region of 
 at offset 
 from 
 to addr 
Mapping of file failed: 
File mapping at offset 
 of size 
 of file 
 could not be honored, reading instead.
Failed to read 
 bytes at offset 
from "
Read 
 bytes. 
 remaining.
EARSdapiHelper.mm
Failed to initialize SDAPI
src-locale not present in the config
tgt-locale not present in the config
QE handler contains 
 features
Raw hypothesis : 
Tokenized hypothesis : 
Meta info 
Confidence 
LowConfidence 
empty source input received
empty nbest input received
Raw source : 
Tokenized source : 
Input'
' has no value set!
QualityEstimatorBlock
class definition has too many fields
VectorFst::Read: read failed: 
VectorFst::Read: unexpected end of file: 
FstImpl::ReadHeader: source: 
, fst_type: 
, arc_type: 
, version: 
, flags: 
FstImpl::ReadHeader: Fst not of type "
FstImpl::ReadHeader: Arc not of type "
FstImpl::ReadHeader: Obsolete 
 Fst version: 
ExpandedFst::Read: Can't open file: 
standard input
 millions
, input-dim 
Non-matching output dims, component:
 data:
Backpropagate() attempted while disabled
Non-matching dims! 
 input-dim : 
 data : 
'inf' in component parameters (weight explosion, try lower learning rate?)
'nan' in component parameters (try lower learning rate?)
maxent model estimation not supported (requires liblbfgs)
nnet-file
The model is not of type nnet1::Nnet1InferenceNet.
action-fst-directory
label-tsv-file
convert-to-plain-text-after-label
spaceApplyDefault.fst
spaceApplyRemoveBefore.fst
rewriteApplyCapitalize.fst
rewriteApplyDefault.fst
default-backoff-label
Missing supported tasks.
shared-num-nn-components
InverseTextNormalizer already initialized.
max-num-feats
punctuation
.punctuation
Initialized ITN
Invalid line in compound word list file
chunk overlap is bigger than chunk length.
cluster-id-file
File containing cluster Ids.
compound-word-file
Maximum number of feats
no-title-casing-file
File with list of words that should not be title-cased
source-vocab-file
Source vocabulary file
token-boundary-id
Token boundary symbol ID
word-sense-file
File containing list of word senses.
align-right-preitn-tokens-file
File storing list of pre-ITN tokens that should map to next post-ITN token.
regex-feat-file
TSV file storing regex-to-feature map.
double-regex-feat-file
guard-markers-file
TSV file storing guard markers that prevent ITN.
supplement-config-file
supplemental json file which may contain punctuation and other frequently updated paramters such as max-num-feats
chunk-length
Number of tokens in each chunk
chunk-overlap
the number of overlap tokens between two chunks
entity-tsv-file
Duplicate occurrence of entity "
Unknown start entity "
Unknown end entity "
Initialized EntityTransformer.
inputToken=
 label=
outputToken=
Sublabel application 
 failed for token 
Applying 
 overrides
start entity <
end entity <
Encountered orphan start entity 
This cannot happen
inputToken="
" label=
 concateFst="
ITN failed.
Missing TokenBoundary label
Something that should never happen, just happened. Debug me please...
Regex match for 
) with label 
Preprocessed token: 
tokenNum=
 tokenId=
 word=
 tag=
 tagIsSense=
index=
 token=
 commandId=
French
dictionary
eats
five
hotdogs
Tantor
mighty
fine
elephant.
" ~ 
" -> 
Merging pre-token 
 to next post token
 to previous post token
Tantor-ITN numInputTokens=
 numOutputTokens=
 numOverrides=
 input="
 output="
 overrides=
 preToPostTokMap=
ITN failed
WARNING: No concatenation point found
Detected size mismatch between chunkAlignment=
 and currentPostItnChunk=
chunk_tokens_str: 
chunk_post_itn: 
chunk_alignment: 
result_post_itn: 
result_alignment: 
token sequence time is not monotonic increasing.
reset token timing.
StopWatch is not running.
Process CPU time was not enabled
unordered_map::at: key not found
map::at:  key not found
column == arcFeatDims
Cannot phone pd2pi file 
Malformed phone pd2pi file line=
Coding error. norm_word not found for arc
Coding error. wordEmbMat not loaded.
SymbolTable::ReadText: Bad number of columns (
file = 
, line = 
SymbolTable::ReadText: Bad non-negative integer "
SymbolTable::AddSymbol: symbol = 
 already in symbol_map_ with key = 
 but supplied new key = 
 (ignoring new key)
SymbolTable::Read: read failed
SymbolTable::Write: write failed
Missing required field separator
Negative symbol table entry when not allowed
NULL
EventMap::read, was not expecting character 
Key = 
%s/1gms/vocab%s
%s/1gms/vocab
reading 
%s/%dgms/%dgm.idx
malformed index entry
%s/%dgms/%s
binary format not yet support in readMinCounts
maxorder %u
malformed N-gram count or more than 
 words per line
undefined word index 
ngram [
] exceeds write buffer
bad binary format
maxorder %u
could not read ngram order
word index 
 out of range
data misaligned
increasing offset bytes from 
 (order 
 level 
SRILM_BINARY_COUNTS_001
NegLogProb
LogProb
Log10Prob
Coding error
scoreType
wrong dimensionality of logScores vector
utterance doesn't end with sentence-end symbol(
Ngram orders from previous utterances inconsistent with ones from current utterance
Unexpected number of backoffs: 
utterances
words
OOVs
invalidTokens
invalidUtterances
logProb
perplexity calculation failed, words 
 logprob = 
PPL1
ngramHits
Computed perplexity for 
 sentences, 
 words, 
 OOVs, 
 invalid tokens, 
 invalid utterances
logprob = 
perplexity calculation failed
 ppl = 
 ppl1 = 
Score types do not match
Number of utterances don't match
Number of tokens don't match
aligning scores of utterance 
Utterance 
 doesn't match 
 doesn't match isValidScore
 has non-matching token ids
 has non-matching number of token scores
dimensionality of logScores was chosen too big: 
number of collected tokens and utterances inconsistent
unsupported LmScoreType
number of CorpusStats and interpolation weights don't match
could not retrieve scores from CorpusStats
iterative process to obtain optimal interpolation weights failed
something went wrong with log-score interpolation
number of collected log-scores doesn't match CorpusStats
Input scores are not logProb format, logScores are not comparable
failed to estimate the interpolation weights
Num new Lms = 
 but num interp weights = 
LM component 
 weight: 
Rescoring failed
LM score (type=
) = 
lmScore=
 doesn't match expected score=
Failed to find lattice-biglm-lme-faster decoder
enableLme=false, but LME data was provided. 
Option 1: Set enableLme=true to use the LME data for scoring text with LME tokens. 
Option 2: Set enableLme=false, remove the LME data, and provide text with non-terminals instead of LME tokens.
Could not find OOV word "
" in symbol table(s)
Could not find "
" in symbol table(s), ignoring token
" in symbol table(s), replacing with "
You chose to use the LM rescoring decoder, but it was not found.
Extra LM weight exceeds max-total-extra-weight, rescaling with 
Extra LM weight must be positive (i.e. not in log scale)
Extra LM weight too small, not using extra LM(s)
Extra LM weight must sum to less than 1.0, using only Extra LM(s)
Mismatch in tokenLmInfos and filteredIds sizes
Mismatch in token IDs
the base LM is NULL or empty
replace
ReplaceFstImpl: input symbols of Fst 
 does not match input symbols of base Fst (0'th fst)
ReplaceFstImpl: output symbols of Fst 
 does not match output symbols of base Fst 
(0'th fst)
ReplaceFstImpl: no Fst corresponding to root label '
' in the input tuple vector
ReplaceFstImpl::ReplaceFstImpl: always_cache = 
ReplaceFst: inconsistent arc iterator flags
Not using replace matcher
the provided NnlmEvaluator is neither DNN nor RNN
The LME class 
 is not modeled by the NNLM
multiple LME FSTs are mapped into the same non-terminals classes, wrong config?
the individual DeterministicOnDemandFst is NULL or empty
you are requesting linear interpolation, but the total weight is not 1: 
Decoder chain was not lazily initialized
Empty token received
Invalid code point, 
Invalid UTF-8, 
Not enough space, 
input contains | which is the separator for g2p model.
[a-zA-Z]\.[a-zA-Z]
[a-zA-Z]-[a-zA-Z]
Locale-aware upper/lowercasing failed, falling back to locale-insensitive versions.
^[a-zA-Z]+[0-9]+$
([0-9])
Phone changed unexpectedly in lattice [broken lattice or mismatched model?]
Unexpected phone 
 found inside a word.
Phone changed while following final self-loop [broken lattice or mismatched model or wrong --reorder option?]
Invalid word at end of lattice [partial lattice, forced out?]
Discarding word-ids at the end of a sentence, that don't have alignments.
Broken silence arc at end of utterance (the phone changed); code error
Broken silence arc at end of utterance (does not reach end of silence)
Partial word detected at end of utterance
Code error, word-aligning lattice
Not expecting binary unpronounced words file.
Invalid line in unpronounced words file: 
Invalid line in word-boundary file: 
nonword
begin
singleton
internal
Empty word-boundary file
 was not specified in word-boundary file (or options)
[Lattice has input epsilons and/or is not input-deterministic 
(in Mohri sense)]-- i.e. lattice is not deterministic.  
Word-alignment may be slow and-or blow up in memory.
Number of states in lattice exceeded max-states of 
, original lattice had 
 states.  Returning what we have.
ArcMap: non-zero arc labels for superfinal arc
strlen(FLAGS_fst_weight_separator) == 1
../libquasar/libkaldi/src/fstext/lattice-weight.h
Infinity
-Infinity
BadNumber
ComposeFst: Weights must be a commutative semiring: 
Failed to create a 
 by 
 matrix with only 
 bytes available in the workspace
Failed to create a vector of 
 elements with only 
size >= 0
mem_size_bytes >= 0
Can't create a child workspace of 
. Only have 
 bytes
Feature type unknown. Ignoring feature ..
Initialized nnet with Model file =
Endpoint model file cannot be empty
Feature unknown, 
features allowed are ("num-of-words","num-trailing-sil", "num-frames","end-of-sentence","pause-counts","num-input-label-words","stream-conf","silence-posterior","client-silence-frames-count-ms","client-silence-probability","silence-posterior-nf","server-features-latency", "eager-result-end-time")
endpoint-feature-list cannot be empty
token_post_in_cnet_slot
max_post_in_cnet_slot
secondmax_post_in_cnet_slot
num_arcs_in_cnet_slot
logpost
avg_loglike
hyp_len
token_pos_in_hyp
token_freq
token_logfreq
num_frames
spk_rate
(num_hyps_out > 0) && (num_hyps_out <= num_hyps_in_)
std::find(feature_list_.begin(), feature_list_.end(), feature_list[i]) != feature_list_.end() && "Unknown feature provided in the feature list"
token_unigram_frequencies_.size() > 0
nbest_hyps.size() == num_hyps_in_
nbest_loglikes.size() == num_hyps_in_
num_frames > 0
Hypothesis token (
) does not match any arc in the confusion network slot
!binary_in && "Not expecting a binary file."
ss.good()
!binary_in && "Not expecting binary confidence file."
intercept
(atof(feat_std_str.c_str()) > 0) && "Obtained a negative value for standard deviation"
feature_list_.size() == weights_.size()
feature_list_.size() == feature_mean_.size()
feature_list_.size() == feature_std_.size()
feature_list == feature_list_
feats.Dim() == weights_.size()
LatticeWeightTpl::Divide, NaN or invalid number produced. 
[dividing by zero?]  Returning zero.
com.apple.siri._EARSpeechRecognitionAudioBuffer
bufferedAudioDuration
Ending current audio stream.
    
Multiple connections to receiving block input name: 
output port not connected: 
Missing input(s) for 
Block '
' - required input not connected: '
' - nonexistent input connected: '
Multiple values received in graph-output!
No value received in graph-output!
Unsuported merge-style: 
Input '
' set multiple times!
ProcessingSource
ProcessingSink
MergerBlock
NullBlock
sausage
T@"NSArray",C,N,V_sausage
nBestIndexes
T@"NSArray",C,N,V_nBestIndexes
confidences
T@"NSArray",C,N,V_confidences
nBestStrings
T@"NSArray",C,N,V_nBestStrings
nBestSourceIndexes
T@"NSArray",C,N,V_nBestSourceIndexes
originalRanks
T@"NSArray",C,N,V_originalRanks
updateInterval % batchSize == 0 && "Bad configuration"
batchSize > 0 && updateInterval > 0 && learningRate > 0 && "Bad configuration"
Training neural network is already initialized.
Training network path must be specified.
Training model loading done.
trainingNnet && "Training nnet does not exist"
gradBuffer && updatedSpeakerCode && "Speaker code container or gradient container does not exist"
Iteration:[
] done, calculated gradient: 
Speaker code is updated: 
, processed samples: 
, accumulated gradient: 
Training is still running, going to set end to true and end training
Training is ended, going to set end to false and resume training.
refMat.NumRows() == 1
Invalid frame range. Coding error.
signal energy (dB) = 
 noise energy (dB) = 
mt-decoders.
engine-type
Unknown mt engine type: 
CORRECT
SEARCH_ERROR
HOMOPHONE
LM_OVER
GRAPH_OVER
AM_OVER
REF_TOO_SHORT
HYPO_TOO_SHORT
Invalid Category given 
TRANS_ID
PHONE
WORD
Invalid level given 
GENERAL
SCHEMA
CONTEXT
MIN_DURATION
PATTERN
LENGTH
AC-MATCH
AC-MISMATCH
WORD-CONFUSION
Invalid info given 
HYPO
AMONLY
Invalid source given 
Parameters for 
 have already been registered.
Must call init() for 
 before calling run().
Running Decoder: 
Decoder 
 failed.
Time
FirstPassCpuMs
stabilizer-averaging-period-ms
Duration in milliseconds over which to stabilize partial results
stabilizer-minimum-word-seen-ms
Minimum duration in milliseconds that word must be recognized before it is considered stable
dfst-cache-size
The maximum number of items cached by each deterministic FST. Has no effect if the decoder doesn't use deterministic FST.
Linear Output Failed
Skipping calculateNBest since we already did it (eager)
nbest size=
symTableId=
, but decoderChainOutput->lmeStatus.size()=
empty partial results!
empty or mismatched number of timestamps for final result
partial result: 
, partial result timestamp: 
, partial reference: 
partial_results_toggle_count=
partial_results_average_feedback_lag=
faster_partial_results_toggle_count=
faster_partial_results_average_feedback_lag=
Building Decoder 
lattice-biglm-faster
lattice-biglm-lme-faster
lattice-scale-rescore
lattice-word-aligner
lattice-lm-rescore
lattice-realigner
error-blamer
lattice-confidence
lattice-faster
keyword-spotting-decoder
seeva-decoder
seeva-step-decoder
seeva-step-biglm-decoder
seeva-greedy-decoder
las-beam-search-decoder
confusion-network-combiner
phonetic-match
fingerprint-detector
audio-analytics-decoder
audio-analytics-only
lattice-rnn-mitigator
lattice-confidence2
e2e-asr-confidence
watermark-detector2
Unknown decoder type "
" in "
No word boundary info found. Cannot give proper phone sequence.
Phone sequencing failed; ran out of words for unknown reasons. 
Lattice word alignment and confidence computation will also fail. 
PLEASE FILE A RADAR
Phone sequencing failed; Ran out of phones, probably because 
the last word got clipped in the audio. 
Lattice word alignment and confidence computation will also fail.
<unspecified>
error-blaming-report
failure-reason
CONFIDENCE
FRAME_LENGTH
Blaming 
Cannot blame given reference and hypothesis, one of them is empty.
Schematics have to be registered first before usage, call RegisterSchematics first
Size of registered schematics is 
 does not match with supplied schematics for utterance, which are 
Unexpected number of confidenceScores
Unexpected number of confidenceScores got 
 words in lattice and got 
 confidence scores
StateSort: bad order vector size: 
tag-start
tag-end
parameter-prefix
command-phrase-prefix
Error with configuration for CommandTagger
command-tagger
text-proc
Unsupported mapping operation
Unicode error (ICU): 
CaseMapBlock
Non-finite energy found for frame 
. Waveform is: 
SRILM_BINARY_NGRAM_001
SRILM_BINARY_NGRAM_002
gram]
[OOV]
 in binary format
 in old binary format
\data\
\%d-grams
invalid ngram order 
skipping 
ngram %u=%lld
ngram order 
ngram number 
unexpected input
discarded 
 OOV 
\end\
-grams read, expected 
ngram line has 
 fields (
 expected)
invalid codebook index "
bad prob "
warning: questionable prob "
ignoring non-zero bow "
" for maximal ngram
bad bow "
warning: questionable bow "
warning: no bow for prefix of ngram "
warning: non-zero probability for 
 in closed-vocabulary LM
reached EOF before \end\
\data\
ngram %d=%lld
\%d-grams:
writing 
%.*lg
%s%s
%.*lg
\end\
index: %1023s
data: %1023s
invalid binary LM format!
%.1023s
incompatible binary format
failed to read from data file
index (
skipToNextTrie failed for order 
failed to estimate GT discount for order 
Good Turing parameters for 
-grams:
BOW denominator for context "
" is zero; scaling probabilities to sum to 1
BOW numerator for context "
" is 
 < 0
 <= 0,
numerator is 
CONTEXT 
 numerator 
 denominator 
 BOW 
warning: the size of this n-gram exceeds 
 characters (increasing buffer size...): 
 WORD 
 CONTEXTPROB 
 OLDPROB 
 NEWPROB 
 DELTA-H 
 DELTA-LOGP 
 PPL-CHANGE 
 PRUNED 
pruned 
 PRUNED 1
 LPROB 
 BACKOFF-LPROB 
 PRUNED
faking probability for context 
inserted 
 redundant 
-gram probs
warning: distributing 
 left-over probability mass over 
 zeroton words
 left-over probability mass over all 
 words
 NUMER 
 DENOM 
 DISCOUNT 
 LOW 
 LOLPROB 
 backoff probability mass left for "
" -- 
disabling interpolation
incrementing denominator
-gram contexts containing pseudo-events
-gram probs predicting pseudo-events
-gram probs discounted to zero
long-name
Long-name field not allowed
, geoRegion=
Bitmap region not allowed
Circle info required
Both circle and bitmap info used in region 
, which is prohibited
Neither bitmap nor circle info found in region 
classLM-template-to-fst-map
Empty FST file name for template 
ClassLM template map required
Config Version is not high enough for personalization
personalization-recipe.personalization-version
Personalization not configured
personalization-recipe.
personalization-recipe
personalization-recipe.categories
Personalization version: 
personalization-version
The version of the categories data
chars-to-trim
The characters to be trimmed from the edges of the raw entity string
chars-to-split
The characters used to split the raw entity string
The relative frequency of the data
template-name
The template name for LME
tag-name
The tag name for LME (also important for enumerations)
Category 
 not supported
Ignoring entry with orthography 
Could not load 
input1
output1
in_extras.size() == 1
input2
could not make features: 
CoreML prediction failed, falling back to CPU inference
could not predict: 
No output from CoreML: 
v16@?0^v8
Could not make multiarray from matrix 
Unexpected output shape from CoreML: 
Unexpected output from CoreML: 
Could not make multiarray from vector 
Non-vector shape output from CoreML: 
fst-file
LM FST file for dummy experiments
filename
<SourceStateDimension>
<MaxAttentions>
 (SourceStateDimension|MaxAttentions)
Initializing component of type 
this is a non-recurrent version, cannot have a recurrent internal component
no recursive inclusion
component is not initialized, max attention is 
, source state dimension is 
component has input dim 
, attentions 
, source state dimension 
, however, the internal training component has input dim 
the output dim of attention component is 
 , however, the internal training component has output dim 
State 
NumFramesReady() not implemented for this decodable type.
output-symtab-file
Output symbol table file
lg-fst-file
LG FST file
phonomap-file
Phonomap file
sys-select-bias
System selection bias
sys-select-lm-scale
System selection LM scale
regex-list-file
List of regular expressions that will be used to catch inputs for phonetic match.
regex-whitelist-file
Regex whitelist
regex-blacklist-file
Regex blacklist
lm-logprob-threshold
Only do PM if LVCSR's LM logprob is less than this.
entity-tags-tsv-file
File containing start and end entity tags
sys-select-score-scale
Scale factor for PM-overallScore for addition to confidences
sys-select-score-min
Minimum PM-overallScore at which to discard the PM result
sys-select-length-norm
Divide PM-overallScore by phone sequence length
do-use-confmodel
Flag for whether or not to use a confidence model, if true confidence-model-file must also be set
confidence-model-file
Filename for confidence model file, format <FEATURE> <WEIGHT> (one per line)
l-fst-file
L FST file (if specified per-word segmentation will be output)
max-align-total-tokens
Maximum number of tokens used just for alignment pass
protect-lme-tags
Comma separated list of trailing strings which can be used identify tokens to be protected from replacement by phonetic match
wildcard-symbol
The wildcard symbol is used to specify a partial match. It will always align with a single phone. Normally set to ~ if you wish to allow phonetic match to do a partial match (filling in the words recognised pre-PM where the wildcard occurs)
wildcard-scale
The wildcard scale is a multiplier applied to the negative log likelihoods in the phonomap corresponding to the wildcard-symbol
Config version < 158 so using FST compatibility mode so subroutine states with no outgoing arcs denotes an exit state
Config version >= 158 so exit states in subroutines are expected to be proper final states - phonetic match will fail otherwise
Phonetic match decoder is using subroutine feature but config version < 111
constant
Setting constant term/intercept to 
Setting 
Feature 
 is not in the model definition.
Read in Confidence Model 
 added 
~w01
wildcard="
" replacement="
" goodMatch=0
" goodMatch=1
pmPartialInput="
pmPartialOutput="
pmCompleteOutput="
FetchResultsImpl(sausage.size()=
 phoneIndex=
 state=
phone=
 start=
 end=
 confidence=
Found protected token "
" is phonetically matched to "
Phone '
' is not a valid phone symbol
Number of phones is 0
PM Failed.
PM ELAPSED: 
 num_phones=
PM Alignment failed - due to wildcard match with partial word
graphCost[
 pmOutput[
PM ALIGN ELAPSED: 
PM Alignment failed
PM Failed to get any results from alignment lattice
PM Failed to get any results from lattice
NBest list of PM results > 1 - LM score adjustment only works for a single theory
graphCost=
 numStates=
 decodeScore=
 overallScore=
 partialMatch=
No LM cost found. Skipping PM. Hint: Did you include lattice-lm-rescore?
LVCSR LM logprob=
 is greater than threshold 
. Skipping PM.
pmInput="
Not a match with the regex whitelist. Skipping PM.
Matches the regex blacklist. Skipping PM.
pmOutput="
Score low. Discarding PM result.
Protecting LME replacement. Skipping PM.
Switching to phonetic match decoder output
PM-lvcsrLmLogProb
PM-isWhiteListMatch
PM-isBlackListMatch
PM-graphCost
PM-decodeScore
PM-overallScore
PM-confidence
PM-result
PM-input
PM-output
PM-used
PM-partial
PM-decoder
beam
Symbol decoder beam
max-active
Symbol decoder max active states
beam-delta
Symbol decoder beam delta
hash-ratio
Symbol decoder hash ratio
ac-scale
Symbol decoder acoustic scale
max-total-tokens
Max total allocated tokens at any time.
pm_overall_score
slm_mean_confidence
trans_slm_mean_confidence
m.size() == Features::kFeatureCount
<n/a>
Greated than 256 rec symbols (phones) in phonomap 
 can't be supported
Frame 
Max tokens 
 exceeded - 
Allocated max tokens 
 prev_id=
 nextstate=
 weight=
 ilabel=
 olabel=
 phone=
Ran out of token storage
Process non-emitting with cutoff=
Exit subroutine state=
subroutine=
 prevnextstate=
Cannot enter subroutine=
 ret_state=
 (nesting not allowed)
Process emitting isym=
Failed to reach final state
Subroutine index 
 already defined
 not used - subroutines indexes must be consecutive
Found 
 phonetic match subroutines 
Possible memory leak: 
: you might have forgotten to call Delete on 
some Elems
\s{2,}
Ignoring silence phone "sil"
ASR prons are empty
Language not provided
Unsupported language: "
Unknown phone: "
Language = 
, IPA prons=
, ASR prons=
, NvASR prons=
, XSAMPA prons=
ja-JP
zh_HK
aai1
aai2
aai3
aai4
aai5
aai6
aau1
aau2
aau3
aau4
aau5
aau6
eoi1
eoi2
eoi3
eoi4
eoi5
eoi6
d.ge
t.sh
a . a
a! . a
i . i
i! . i
M . M
M! . M
e . e
e! . e
o . o
o! . o
p . p
p . p_j
b . b
p\ . p\
t . t
t . ts
t . ts\
d . d
z . z
d . dz
k . k
k . k_j
g . g
s . s
s\ . s\
h . h
4 . 4
A_1_N
A_2_N
A_3_N
A_4_N
A_5_N
A_6_N
aI_1
aI_2
aI_3
aI_4
aI_5
aI_6
a_1_n
a_2_n
a_3_n
a_4_n
a_5_n
a_6_n
aU_1
aU_2
aU_3
aU_4
aU_5
aU_6
p_j_1
p_j_2
p_j_3
p_j_4
p_j_5
p_j_6
p O_1
BU.O1
p O_2
BU.O2
p O_3
BU.O3
p O_4
BU.O4
p O_5
BU.O5
p O_6
p u_1
BU.U1
p u_2
BU.U2
p u_3
BU.U3
p u_4
BU.U4
p u_5
BU.U5
p u_6
p i_1
BI.I1
p i_2
BI.I2
p i_3
BI.I3
p i_4
BI.I4
p i_5
BI.I5
p i_6
p i_1_n
BI.IN1
p i_2_n
BI.IN2
p i_3_n
BI.IN3
p i_4_n
BI.IN4
p i_5_n
BI.IN5
p i_6_n
p i_1_N
BI.IG1
p i_2_N
BI.IG2
p i_3_N
BI.IG3
p i_4_N
BI.IG4
p i_5_N
BI.IG5
p i_6_N
p_j_1 a_1_n
BI.AN1
p_j_2 a_2_n
BI.AN2
p_j_3 a_3_n
BI.AN3
p_j_4 a_4_n
BI.AN4
p_j_5 a_5_n
BI.AN5
p_j_6 a_6_n
p_j_1 aU_1
BI.AO1
p_j_2 aU_2
BI.AO2
p_j_3 aU_3
BI.AO3
p_j_4 aU_4
BI.AO4
p_j_5 aU_5
BI.AO5
p_j_6 aU_6
p_j_1 E_1
BI.IE1
p_j_2 E_2
BI.IE2
p_j_3 E_3
BI.IE3
p_j_4 E_4
BI.IE4
p_j_5 E_5
BI.IE5
p_j_6 E_6
ts_h
ts`_h
ts`_h_w
ts`_h o_1_N
CHU.OG1
ts`_h o_2_N
CHU.OG2
ts`_h o_3_N
CHU.OG3
ts`_h o_4_N
CHU.OG4
ts`_h o_5_N
CHU.OG5
ts`_h o_6_N
ts`_h u_1
CHU.U1
ts`_h u_2
CHU.U2
ts`_h u_3
CHU.U3
ts`_h u_4
CHU.U4
ts`_h u_5
CHU.U5
ts`_h u_6
ts`_h_w @_1_n
CHU.UN1
ts`_h_w @_2_n
CHU.UN2
ts`_h_w @_3_n
CHU.UN3
ts`_h_w @_4_n
CHU.UN4
ts`_h_w @_5_n
CHU.UN5
ts`_h_w @_6_n
ts_h_w
ts_h o_1_N
CU.OG1
ts_h o_2_N
CU.OG2
ts_h o_3_N
CU.OG3
ts_h o_4_N
CU.OG4
ts_h o_5_N
CU.OG5
ts_h o_6_N
ts_h u_1
CU.U1
ts_h u_2
CU.U2
ts_h u_3
CU.U3
ts_h u_4
CU.U4
ts_h u_5
CU.U5
ts_h u_6
ts_h_w @_1_n
CU.UN1
ts_h_w @_2_n
CU.UN2
ts_h_w @_3_n
CU.UN3
ts_h_w @_4_n
CU.UN4
ts_h_w @_5_n
CU.UN5
ts_h_w @_6_n
t_j_1
t_j_2
t_j_3
t_j_4
t_j_5
t_j_6
t i_1
DI.I1
t i_2
DI.I2
t i_3
DI.I3
t i_4
DI.I4
t i_5
DI.I5
t i_6
t i_1_N
DI.IG1
t i_2_N
DI.IG2
t i_3_N
DI.IG3
t i_4_N
DI.IG4
t i_5_N
DI.IG5
t i_6_N
t_j_1 a_1_n
DI.AN1
t_j_2 a_2_n
DI.AN2
t_j_3 a_3_n
DI.AN3
t_j_4 a_4_n
DI.AN4
t_j_5 a_5_n
DI.AN5
t_j_6 a_6_n
t_j_1 aU_1
DI.AO1
t_j_2 aU_2
DI.AO2
t_j_3 aU_3
DI.AO3
t_j_4 aU_4
DI.AO4
t_j_5 aU_5
DI.AO5
t_j_6 aU_6
t_j_1 E_1
DI.IE1
t_j_2 E_2
DI.IE2
t_j_3 E_3
DI.IE3
t_j_4 E_4
DI.IE4
t_j_5 E_5
DI.IE5
t_j_6 E_6
t_j_1 oU_1
DI.OU1
t_j_2 oU_2
DI.OU2
t_j_3 oU_3
DI.OU3
t_j_4 oU_4
DI.OU4
t_j_5 oU_5
DI.OU5
t_j_6 oU_6
t o_1_N
DU.OG1
t o_2_N
DU.OG2
t o_3_N
DU.OG3
t o_4_N
DU.OG4
t o_5_N
DU.OG5
t o_6_N
t u_1
DU.U1
t u_2
DU.U2
t u_3
DU.U3
t u_4
DU.U4
t u_5
DU.U5
t u_6
t_w @_1_n
DU.UN1
t_w @_2_n
DU.UN2
t_w @_3_n
DU.UN3
t_w @_4_n
DU.UN4
t_w @_5_n
DU.UN5
t_w @_6_n
@_1_N
@_2_N
@_3_N
@_4_N
@_5_N
@_6_N
eI_1
eI_2
eI_3
eI_4
eI_5
eI_6
@_1_n
@_2_n
@_3_n
@_4_n
@_5_n
@_6_n
@`_1
@`_2
@`_3
@`_4
@`_5
@`_6
k o_1_N
GU.OG1
k o_2_N
GU.OG2
k o_3_N
GU.OG3
k o_4_N
GU.OG4
k o_5_N
GU.OG5
k o_6_N
k u_1
GU.U1
k u_2
GU.U2
k u_3
GU.U3
k u_4
GU.U4
k u_5
GU.U5
k u_6
k_w @_1_n
GU.UN1
k_w @_2_n
GU.UN2
k_w @_3_n
GU.UN3
k_w @_4_n
GU.UN4
k_w @_5_n
GU.UN5
k_w @_6_n
x o_1_N
HU.OG1
x o_2_N
HU.OG2
x o_3_N
HU.OG3
x o_4_N
HU.OG4
x o_5_N
HU.OG5
x o_6_N
x u_1
HU.U1
x u_2
HU.U2
x u_3
HU.U3
x u_4
HU.U4
x u_5
HU.U5
x u_6
x_w @_1_n
HU.UN1
x_w @_2_n
HU.UN2
x_w @_3_n
HU.UN3
x_w @_4_n
HU.UN4
x_w @_5_n
HU.UN5
x_w @_6_n
i_1_N
i_2_N
i_3_N
i_4_N
i_5_N
i_6_N
i_1_n
i_2_n
i_3_n
i_4_n
i_5_n
i_6_n
ts\_j_1
ts\_j_2
ts\_j_3
ts\_j_4
ts\_j_5
ts\_j_6
ts\ i_1
JI.I1
ts\ i_2
JI.I2
ts\ i_3
JI.I3
ts\ i_4
JI.I4
ts\ i_5
JI.I5
ts\ i_6
ts\ i_1_n
JI.IN1
ts\ i_2_n
JI.IN2
ts\ i_3_n
JI.IN3
ts\ i_4_n
JI.IN4
ts\ i_5_n
JI.IN5
ts\ i_6_n
ts\ i_1_N
JI.IG1
ts\ i_2_N
JI.IG2
ts\ i_3_N
JI.IG3
ts\ i_4_N
JI.IG4
ts\ i_5_N
JI.IG5
ts\ i_6_N
ts\_j_1 a_1_n
JI.AN1
ts\_j_2 a_2_n
JI.AN2
ts\_j_3 a_3_n
JI.AN3
ts\_j_4 a_4_n
JI.AN4
ts\_j_5 a_5_n
JI.AN5
ts\_j_6 a_6_n
ts\_j_1 a_1
JI.A1
ts\_j_2 a_2
JI.A2
ts\_j_3 a_3
JI.A3
ts\_j_4 a_4
JI.A4
ts\_j_5 a_5
JI.A5
ts\_j_6 a_6
ts\_j_1 aU_1
JI.AO1
ts\_j_2 aU_2
JI.AO2
ts\_j_3 aU_3
JI.AO3
ts\_j_4 aU_4
JI.AO4
ts\_j_5 aU_5
JI.AO5
ts\_j_6 aU_6
ts\_j_1 E_1
JI.IE1
ts\_j_2 E_2
JI.IE2
ts\_j_3 E_3
JI.IE3
ts\_j_4 E_4
JI.IE4
ts\_j_5 E_5
JI.IE5
ts\_j_6 E_6
ts\_j_1 oU_1
JI.OU1
ts\_j_2 oU_2
JI.OU2
ts\_j_3 oU_3
JI.OU3
ts\_j_4 oU_4
JI.OU4
ts\_j_5 oU_5
JI.OU5
ts\_j_6 oU_6
ts\_j_1 A_1_N
JI.AG1
ts\_j_2 A_2_N
JI.AG2
ts\_j_3 A_3_N
JI.AG3
ts\_j_4 A_4_N
JI.AG4
ts\_j_5 A_5_N
JI.AG5
ts\_j_6 A_6_N
ts\_j_1 o_1_N
JI.OG1
ts\_j_2 o_2_N
JI.OG2
ts\_j_3 o_3_N
JI.OG3
ts\_j_4 o_4_N
JI.OG4
ts\_j_5 o_5_N
JI.OG5
ts\_j_6 o_6_N
ts\ y_1
JU.YU1
ts\ y_2
JU.YU2
ts\ y_3
JU.YU3
ts\ y_4
JU.YU4
ts\ y_5
JU.YU5
ts\ y_6
ts\_H_1
ts\_H_2
ts\_H_3
ts\_H_4
ts\_H_5
ts\_H_6
ts\_H_1 a_1_n
JU.AN1
ts\_H_2 a_2_n
JU.AN2
ts\_H_3 a_3_n
JU.AN3
ts\_H_4 a_4_n
JU.AN4
ts\_H_5 a_5_n
JU.AN5
ts\_H_6 a_6_n
ts\_H_1 E_1
JU.IE1
ts\_H_2 E_2
JU.IE2
ts\_H_3 E_3
JU.IE3
ts\_H_4 E_4
JU.IE4
ts\_H_5 E_5
JU.IE5
ts\_H_6 E_6
ts\_H_1 i_1_n
JU.IN1
ts\_H_2 i_2_n
JU.IN2
ts\_H_3 i_3_n
JU.IN3
ts\_H_4 i_4_n
JU.IN4
ts\_H_5 i_5_n
JU.IN5
ts\_H_6 i_6_n
k_h_w
k_h o_1_N
KU.OG1
k_h o_2_N
KU.OG2
k_h o_3_N
KU.OG3
k_h o_4_N
KU.OG4
k_h o_5_N
KU.OG5
k_h o_6_N
k_h u_1
KU.U1
k_h u_2
KU.U2
k_h u_3
KU.U3
k_h u_4
KU.U4
k_h u_5
KU.U5
k_h u_6
k_h_w @_1_n
KU.UN1
k_h_w @_2_n
KU.UN2
k_h_w @_3_n
KU.UN3
k_h_w @_4_n
KU.UN4
k_h_w @_5_n
KU.UN5
k_h_w @_6_n
l_j_1
l_j_2
l_j_3
l_j_4
l_j_5
l_j_6
l i_1
LI.I1
l i_2
LI.I2
l i_3
LI.I3
l i_4
LI.I4
l i_5
LI.I5
l i_6
l i_1_n
LI.IN1
l i_2_n
LI.IN2
l i_3_n
LI.IN3
l i_4_n
LI.IN4
l i_5_n
LI.IN5
l i_6_n
l i_1_N
LI.IG1
l i_2_N
LI.IG2
l i_3_N
LI.IG3
l i_4_N
LI.IG4
l i_5_N
LI.IG5
l i_6_N
l_j_1 a_1_n
LI.AN1
l_j_2 a_2_n
LI.AN2
l_j_3 a_3_n
LI.AN3
l_j_4 a_4_n
LI.AN4
l_j_5 a_5_n
LI.AN5
l_j_6 a_6_n
l_j_1 a_1
LI.A1
l_j_2 a_2
LI.A2
l_j_3 a_3
LI.A3
l_j_4 a_4
LI.A4
l_j_5 a_5
LI.A5
l_j_6 a_6
l_j_1 aU_1
LI.AO1
l_j_2 aU_2
LI.AO2
l_j_3 aU_3
LI.AO3
l_j_4 aU_4
LI.AO4
l_j_5 aU_5
LI.AO5
l_j_6 aU_6
l_j_1 E_1
LI.IE1
l_j_2 E_2
LI.IE2
l_j_3 E_3
LI.IE3
l_j_4 E_4
LI.IE4
l_j_5 E_5
LI.IE5
l_j_6 E_6
l_j_1 oU_1
LI.OU1
l_j_2 oU_2
LI.OU2
l_j_3 oU_3
LI.OU3
l_j_4 oU_4
LI.OU4
l_j_5 oU_5
LI.OU5
l_j_6 oU_6
l_j_1 A_1_N
LI.AG1
l_j_2 A_2_N
LI.AG2
l_j_3 A_3_N
LI.AG3
l_j_4 A_4_N
LI.AG4
l_j_5 A_5_N
LI.AG5
l_j_6 A_6_N
l o_1_N
LU.OG1
l o_2_N
LU.OG2
l o_3_N
LU.OG3
l o_4_N
LU.OG4
l o_5_N
LU.OG5
l o_6_N
l u_1
LU.U1
l u_2
LU.U2
l u_3
LU.U3
l u_4
LU.U4
l u_5
LU.U5
l u_6
l_w @_1_n
LU.UN1
l_w @_2_n
LU.UN2
l_w @_3_n
LU.UN3
l_w @_4_n
LU.UN4
l_w @_5_n
LU.UN5
l_w @_6_n
l_H_1
l_H_2
l_H_3
l_H_4
l_H_5
l_H_6
l_H_1 E_1
LYU.IE1
l_H_2 E_2
LYU.IE2
l_H_3 E_3
LYU.IE3
l_H_4 E_4
LYU.IE4
l_H_5 E_5
LYU.IE5
l_H_6 E_6
l y_1
LYU.YU1
l y_2
LYU.YU2
l y_3
LYU.YU3
l y_4
LYU.YU4
l y_5
LYU.YU5
l y_6
m_j_1
m_j_2
m_j_3
m_j_4
m_j_5
m_j_6
m u_1
MU.U1
m u_2
MU.U2
m u_3
MU.U3
m u_4
MU.U4
m u_5
MU.U5
m u_6
m i_1
MI.I1
m i_2
MI.I2
m i_3
MI.I3
m i_4
MI.I4
m i_5
MI.I5
m i_6
m i_1_n
MI.IN1
m i_2_n
MI.IN2
m i_3_n
MI.IN3
m i_4_n
MI.IN4
m i_5_n
MI.IN5
m i_6_n
m i_1_N
MI.IG1
m i_2_N
MI.IG2
m i_3_N
MI.IG3
m i_4_N
MI.IG4
m i_5_N
MI.IG5
m i_6_N
m_j_1 a_1_n
MI.AN1
m_j_2 a_2_n
MI.AN2
m_j_3 a_3_n
MI.AN3
m_j_4 a_4_n
MI.AN4
m_j_5 a_5_n
MI.AN5
m_j_6 a_6_n
m_j_1 aU_1
MI.AO1
m_j_2 aU_2
MI.AO2
m_j_3 aU_3
MI.AO3
m_j_4 aU_4
MI.AO4
m_j_5 aU_5
MI.AO5
m_j_6 aU_6
m_j_1 E_1
MI.IE1
m_j_2 E_2
MI.IE2
m_j_3 E_3
MI.IE3
m_j_4 E_4
MI.IE4
m_j_5 E_5
MI.IE5
m_j_6 E_6
m_j_1 oU_1
MI.OU1
m_j_2 oU_2
MI.OU2
m_j_3 oU_3
MI.OU3
m_j_4 oU_4
MI.OU4
m_j_5 oU_5
MI.OU5
m_j_6 oU_6
n_j_1
n_j_2
n_j_3
n_j_4
n_j_5
n_j_6
n i_1
NI.I1
n i_2
NI.I2
n i_3
NI.I3
n i_4
NI.I4
n i_5
NI.I5
n i_6
n i_1_n
NI.IN1
n i_2_n
NI.IN2
n i_3_n
NI.IN3
n i_4_n
NI.IN4
n i_5_n
NI.IN5
n i_6_n
n i_1_N
NI.IG1
n i_2_N
NI.IG2
n i_3_N
NI.IG3
n i_4_N
NI.IG4
n i_5_N
NI.IG5
n i_6_N
n_j_1 a_1_n
NI.AN1
n_j_2 a_2_n
NI.AN2
n_j_3 a_3_n
NI.AN3
n_j_4 a_4_n
NI.AN4
n_j_5 a_5_n
NI.AN5
n_j_6 a_6_n
n_j_1 aU_1
NI.AO1
n_j_2 aU_2
NI.AO2
n_j_3 aU_3
NI.AO3
n_j_4 aU_4
NI.AO4
n_j_5 aU_5
NI.AO5
n_j_6 aU_6
n_j_1 E_1
NI.IE1
n_j_2 E_2
NI.IE2
n_j_3 E_3
NI.IE3
n_j_4 E_4
NI.IE4
n_j_5 E_5
NI.IE5
n_j_6 E_6
n_j_1 oU_1
NI.OU1
n_j_2 oU_2
NI.OU2
n_j_3 oU_3
NI.OU3
n_j_4 oU_4
NI.OU4
n_j_5 oU_5
NI.OU5
n_j_6 oU_6
n_j_1 A_1_N
NI.AG1
n_j_2 A_2_N
NI.AG2
n_j_3 A_3_N
NI.AG3
n_j_4 A_4_N
NI.AG4
n_j_5 A_5_N
NI.AG5
n_j_6 A_6_N
n o_1_N
NU.OG1
n o_2_N
NU.OG2
n o_3_N
NU.OG3
n o_4_N
NU.OG4
n o_5_N
NU.OG5
n o_6_N
n u_1
NU.U1
n u_2
NU.U2
n u_3
NU.U3
n u_4
NU.U4
n u_5
NU.U5
n u_6
n_H_1
n_H_2
n_H_3
n_H_4
n_H_5
n_H_6
n_H_1 E_1
NYU.IE1
n_H_2 E_2
NYU.IE2
n_H_3 E_3
NYU.IE3
n_H_4 E_4
NYU.IE4
n_H_5 E_5
NYU.IE5
n_H_6 E_6
n y_1
NYU.YU1
n y_2
NYU.YU2
n y_3
NYU.YU3
n y_4
NYU.YU4
n y_5
NYU.YU5
n y_6
o_1_N
o_2_N
o_3_N
o_4_N
o_5_N
o_6_N
oU_1
oU_2
oU_3
oU_4
oU_5
oU_6
p_h_j_1
p_h_j_2
p_h_j_3
p_h_j_4
p_h_j_5
p_h_j_6
p_h i_1
PI.I1
p_h i_2
PI.I2
p_h i_3
PI.I3
p_h i_4
PI.I4
p_h i_5
PI.I5
p_h i_6
p_h i_1_n
PI.IN1
p_h i_2_n
PI.IN2
p_h i_3_n
PI.IN3
p_h i_4_n
PI.IN4
p_h i_5_n
PI.IN5
p_h i_6_n
p_h i_1_N
PI.IG1
p_h i_2_N
PI.IG2
p_h i_3_N
PI.IG3
p_h i_4_N
PI.IG4
p_h i_5_N
PI.IG5
p_h i_6_N
p_h_j_1 a_1_n
PI.AN1
p_h_j_2 a_2_n
PI.AN2
p_h_j_3 a_3_n
PI.AN3
p_h_j_4 a_4_n
PI.AN4
p_h_j_5 a_5_n
PI.AN5
p_h_j_6 a_6_n
p_h_j_1 aU_1
PI.AO1
p_h_j_2 aU_2
PI.AO2
p_h_j_3 aU_3
PI.AO3
p_h_j_4 aU_4
PI.AO4
p_h_j_5 aU_5
PI.AO5
p_h_j_6 aU_6
p_h_j_1 E_1
PI.IE1
p_h_j_2 E_2
PI.IE2
p_h_j_3 E_3
PI.IE3
p_h_j_4 E_4
PI.IE4
p_h_j_5 E_5
PI.IE5
p_h_j_6 E_6
ts\_h_j_1
ts\_h_j_2
ts\_h_j_3
ts\_h_j_4
ts\_h_j_5
ts\_h_j_6
ts\_h i_1
QI.I1
ts\_h i_2
QI.I2
ts\_h i_3
QI.I3
ts\_h i_4
QI.I4
ts\_h i_5
QI.I5
ts\_h i_6
ts\_h i_1_n
QI.IN1
ts\_h i_2_n
QI.IN2
ts\_h i_3_n
QI.IN3
ts\_h i_4_n
QI.IN4
ts\_h i_5_n
QI.IN5
ts\_h i_6_n
ts\_h i_1_N
QI.IG1
ts\_h i_2_N
QI.IG2
ts\_h i_3_N
QI.IG3
ts\_h i_4_N
QI.IG4
ts\_h i_5_N
QI.IG5
ts\_h i_6_N
ts\_h_j_1 a_1_n
QI.AN1
ts\_h_j_2 a_2_n
QI.AN2
ts\_h_j_3 a_3_n
QI.AN3
ts\_h_j_4 a_4_n
QI.AN4
ts\_h_j_5 a_5_n
QI.AN5
ts\_h_j_6 a_6_n
ts\_h_j_1 a_1
QI.A1
ts\_h_j_2 a_2
QI.A2
ts\_h_j_3 a_3
QI.A3
ts\_h_j_4 a_4
QI.A4
ts\_h_j_5 a_5
QI.A5
ts\_h_j_6 a_6
ts\_h_j_1 aU_1
QI.AO1
ts\_h_j_2 aU_2
QI.AO2
ts\_h_j_3 aU_3
QI.AO3
ts\_h_j_4 aU_4
QI.AO4
ts\_h_j_5 aU_5
QI.AO5
ts\_h_j_6 aU_6
ts\_h_j_1 E_1
QI.IE1
ts\_h_j_2 E_2
QI.IE2
ts\_h_j_3 E_3
QI.IE3
ts\_h_j_4 E_4
QI.IE4
ts\_h_j_5 E_5
QI.IE5
ts\_h_j_6 E_6
ts\_h_j_1 oU_1
QI.OU1
ts\_h_j_2 oU_2
QI.OU2
ts\_h_j_3 oU_3
QI.OU3
ts\_h_j_4 oU_4
QI.OU4
ts\_h_j_5 oU_5
QI.OU5
ts\_h_j_6 oU_6
ts\_h_j_1 A_1_N
QI.AG1
ts\_h_j_2 A_2_N
QI.AG2
ts\_h_j_3 A_3_N
QI.AG3
ts\_h_j_4 A_4_N
QI.AG4
ts\_h_j_5 A_5_N
QI.AG5
ts\_h_j_6 A_6_N
ts\_h_j_1 o_1_N
QI.OG1
ts\_h_j_2 o_2_N
QI.OG2
ts\_h_j_3 o_3_N
QI.OG3
ts\_h_j_4 o_4_N
QI.OG4
ts\_h_j_5 o_5_N
QI.OG5
ts\_h_j_6 o_6_N
ts\_h y_1
QU.YU1
ts\_h y_2
QU.YU2
ts\_h y_3
QU.YU3
ts\_h y_4
QU.YU4
ts\_h y_5
QU.YU5
ts\_h y_6
ts\_h_H_1
ts\_h_H_2
ts\_h_H_3
ts\_h_H_4
ts\_h_H_5
ts\_h_H_6
ts\_h_H_1 a_1_n
QU.AN1
ts\_h_H_2 a_2_n
QU.AN2
ts\_h_H_3 a_3_n
QU.AN3
ts\_h_H_4 a_4_n
QU.AN4
ts\_h_H_5 a_5_n
QU.AN5
ts\_h_H_6 a_6_n
ts\_h_H_1 i_1_n
QU.IN1
ts\_h_H_2 i_2_n
QU.IN2
ts\_h_H_3 i_3_n
QU.IN3
ts\_h_H_4 i_4_n
QU.IN4
ts\_h_H_5 i_5_n
QU.IN5
ts\_h_H_6 i_6_n
ts\_h_H_1 E_1
QU.IE1
ts\_h_H_2 E_2
QU.IE2
ts\_h_H_3 E_3
QU.IE3
ts\_h_H_4 E_4
QU.IE4
ts\_h_H_5 E_5
QU.IE5
ts\_h_H_6 E_6
z`_w
z` u_1
RU.U1
z` u_2
RU.U2
z` u_3
RU.U3
z` u_4
RU.U4
z` u_6
z`_w @_1_n
RU.UN1
z`_w @_2_n
RU.UN2
z`_w @_3_n
RU.UN3
z`_w @_4_n
RU.UN4
z`_w @_5_n
RU.UN5
z`_w @_6_n
s`_w
s` u_1
SHU.U1
s` u_2
SHU.U2
s` u_3
SHU.U3
s` u_4
SHU.U4
s` u_5
SHU.U5
s` u_6
s`_w @_1_n
SHU.UN1
s`_w @_2_n
SHU.UN2
s`_w @_3_n
SHU.UN3
s`_w @_4_n
SHU.UN4
s`_w @_5_n
SHU.UN5
s`_w @_6_n
s o_1_N
SU.OG1
s o_2_N
SU.OG2
s o_3_N
SU.OG3
s o_4_N
SU.OG4
s o_5_N
SU.OG5
s o_6_N
s u_1
SU.U1
s u_2
SU.U2
s u_3
SU.U3
s u_4
SU.U4
s u_5
SU.U5
s u_6
s_w @_1_n
SU.UN1
s_w @_2_n
SU.UN2
s_w @_3_n
SU.UN3
s_w @_4_n
SU.UN4
s_w @_5_n
SU.UN5
s_w @_6_n
t_h_j_1
t_h_j_2
t_h_j_3
t_h_j_4
t_h_j_5
t_h_j_6
t_h i_1
TI.I1
t_h i_2
TI.I2
t_h i_3
TI.I3
t_h i_4
TI.I4
t_h i_5
TI.I5
t_h i_6
t_h i_1_N
TI.IG1
t_h i_2_N
TI.IG2
t_h i_3_N
TI.IG3
t_h i_4_N
TI.IG4
t_h i_5_N
TI.IG5
t_h i_6_N
t_h_j_1 a_1_n
TI.AN1
t_h_j_2 a_2_n
TI.AN2
t_h_j_3 a_3_n
TI.AN3
t_h_j_4 a_4_n
TI.AN4
t_h_j_5 a_5_n
TI.AN5
t_h_j_6 a_6_n
TI.AN6
t_h_j_1 aU_1
TI.AO1
t_h_j_2 aU_2
TI.AO2
t_h_j_3 aU_3
TI.AO3
t_h_j_4 aU_4
TI.AO4
t_h_j_5 aU_5
TI.AO5
t_h_j_6 aU_6
t_h_j_1 E_1
TI.IE1
t_h_j_2 E_2
TI.IE2
t_h_j_3 E_3
TI.IE3
t_h_j_4 E_4
TI.IE4
t_h_j_5 E_5
TI.IE5
t_h_j_6 E_6
t_h o_1_N
TU.OG1
t_h o_2_N
TU.OG2
t_h o_3_N
TU.OG3
t_h o_4_N
TU.OG4
t_h o_5_N
TU.OG5
t_h o_6_N
t_h_w
t_h u_1
TU.U1
t_h u_2
TU.U2
t_h u_3
TU.U3
t_h u_4
TU.U4
t_h u_5
TU.U5
t_h u_6
t_h_w @_1_n
TU.UN1
t_h_w @_2_n
TU.UN2
t_h_w @_3_n
TU.UN3
t_h_w @_4_n
TU.UN4
t_h_w @_5_n
TU.UN5
t_h_w @_6_n
u_1_n
u_2_n
u_3_n
u_4_n
u_5_n
u_6_n
s\_j_1
s\_j_2
s\_j_3
s\_j_4
s\_j_5
s\_j_6
s\ i_1
XI.I1
s\ i_2
XI.I2
s\ i_3
XI.I3
s\ i_4
XI.I4
s\ i_5
XI.I5
s\ i_6
s\ i_1_n
XI.IN1
s\ i_2_n
XI.IN2
s\ i_3_n
XI.IN3
s\ i_4_n
XI.IN4
s\ i_5_n
XI.IN5
s\ i_6_n
s\ i_1_N
XI.IG1
s\ i_2_N
XI.IG2
s\ i_3_N
XI.IG3
s\ i_4_N
XI.IG4
s\ i_5_N
XI.IG5
s\ i_6_N
s\_j_1 a_1_n
XI.AN1
s\_j_2 a_2_n
XI.AN2
s\_j_3 a_3_n
XI.AN3
s\_j_4 a_4_n
XI.AN4
s\_j_5 a_5_n
XI.AN5
s\_j_6 a_6_n
s\_j_1 a_1
XI.A1
s\_j_2 a_2
XI.A2
s\_j_3 a_3
XI.A3
s\_j_4 a_4
XI.A4
s\_j_5 a_5
XI.A5
s\_j_6 a_6
s\_j_1 aU_1
XI.AO1
s\_j_2 aU_2
XI.AO2
s\_j_3 aU_3
XI.AO3
s\_j_4 aU_4
XI.AO4
s\_j_5 aU_5
XI.AO5
s\_j_6 aU_6
s\_j_1 E_1
XI.IE1
s\_j_2 E_2
XI.IE2
s\_j_3 E_3
XI.IE3
s\_j_4 E_4
XI.IE4
s\_j_5 E_5
XI.IE5
s\_j_6 E_6
s\_j_1 oU_1
XI.OU1
s\_j_2 oU_2
XI.OU2
s\_j_3 oU_3
XI.OU3
s\_j_4 oU_4
XI.OU4
s\_j_5 oU_5
XI.OU5
s\_j_6 oU_6
s\_j_1 A_1_N
XI.AG1
s\_j_2 A_2_N
XI.AG2
s\_j_3 A_3_N
XI.AG3
s\_j_4 A_4_N
XI.AG4
s\_j_5 A_5_N
XI.AG5
s\_j_6 A_6_N
s\_j_1 o_1_N
XI.OG1
s\_j_2 o_2_N
XI.OG2
s\_j_3 o_3_N
XI.OG3
s\_j_4 o_4_N
XI.OG4
s\_j_5 o_5_N
XI.OG5
s\_j_6 o_6_N
s\ y_1
XU.YU1
s\ y_2
XU.YU2
s\ y_3
XU.YU3
s\ y_4
XU.YU4
s\ y_5
XU.YU5
s\ y_6
s\_H_1
s\_H_2
s\_H_3
s\_H_4
s\_H_5
s\_H_6
s\_H_1 a_1_n
XU.AN1
s\_H_2 a_2_n
XU.AN2
s\_H_3 a_3_n
XU.AN3
s\_H_4 a_4_n
XU.AN4
s\_H_5 a_5_n
XU.AN5
s\_H_6 a_6_n
s\_H_1 i_1_n
XU.IN1
s\_H_2 i_2_n
XU.IN2
s\_H_3 i_3_n
XU.IN3
s\_H_4 i_4_n
XU.IN4
s\_H_5 i_5_n
XU.IN5
s\_H_6 i_6_n
s\_H_1 E_1
XU.IE1
s\_H_2 E_2
XU.IE2
s\_H_3 E_3
XU.IE3
s\_H_4 E_4
XU.IE4
s\_H_5 E_5
XU.IE5
s\_H_6 E_6
j_1 i_1
Y.I1
j_2 i_2
Y.I2
j_3 i_3
Y.I3
j_4 i_4
Y.I4
j_5 i_5
Y.I5
j_6 i_6
j_1 a_1
Y.A1
j_2 a_2
Y.A2
j_3 a_3
Y.A3
j_4 a_4
Y.A4
j_5 a_5
Y.A5
j_6 a_6
j_1 aU_1
Y.AO1
j_2 aU_2
Y.AO2
j_3 aU_3
Y.AO3
j_4 aU_4
Y.AO4
j_5 aU_5
Y.AO5
j_6 aU_6
j_1 E_1
Y.IE1
j_2 E_2
Y.IE2
j_3 E_3
Y.IE3
j_4 E_4
Y.IE4
j_5 E_5
Y.IE5
j_6 E_6
j_1 oU_1
Y.OU1
j_2 oU_2
Y.OU2
j_3 oU_3
Y.OU3
j_4 oU_4
Y.OU4
j_5 oU_5
Y.OU5
j_6 oU_6
j_1 i_1_n
Y.IN1
j_2 i_2_n
Y.IN2
j_3 i_3_n
Y.IN3
j_4 i_4_n
Y.IN4
j_5 i_5_n
Y.IN5
j_6 i_6_n
j_1 A_1_N
Y.AG1
j_2 A_2_N
Y.AG2
j_3 A_3_N
Y.AG3
j_4 A_4_N
Y.AG4
j_5 A_5_N
Y.AG5
j_6 A_6_N
j_1 i_1_N
Y.IG1
j_2 i_2_N
Y.IG2
j_3 i_3_N
Y.IG3
j_4 i_4_N
Y.IG4
j_5 i_5_N
Y.IG5
j_6 i_6_N
j_1 o_1_N
Y.OG1
j_2 o_2_N
Y.OG2
j_3 o_3_N
Y.OG3
j_4 o_4_N
Y.OG4
j_5 o_5_N
Y.OG5
j_6 o_6_N
j_1 a_1_n
Y.AN1
j_2 a_2_n
Y.AN2
j_3 a_3_n
Y.AN3
j_4 a_4_n
Y.AN4
j_5 a_5_n
Y.AN5
j_6 a_6_n
j_1 y_1
YU.YU1
j_2 y_2
YU.YU2
j_3 y_3
YU.YU3
j_4 y_4
YU.YU4
j_5 y_5
YU.YU5
j_6 y_6
j_H_1
j_H_2
j_H_3
j_H_4
j_H_5
j_H_6
j_H_1 a_1_n
YU.AN1
j_H_2 a_2_n
YU.AN2
j_H_3 a_3_n
YU.AN3
j_H_4 a_4_n
YU.AN4
j_H_5 a_5_n
YU.AN5
j_H_6 a_6_n
j_H_1 i_1_n
YU.IN1
j_H_2 i_2_n
YU.IN2
j_H_3 i_3_n
YU.IN3
j_H_4 i_4_n
YU.IN4
j_H_5 i_5_n
YU.IN5
j_H_6 i_6_n
j_H_1 E_1
YU.IE1
j_H_2 E_2
YU.IE2
j_H_3 E_3
YU.IE3
j_H_4 E_4
YU.IE4
j_H_5 E_5
YU.IE5
j_H_6 E_6
ts`_w
ts` o_1_N
ZHU.OG1
ts` o_2_N
ZHU.OG2
ts` o_3_N
ZHU.OG3
ts` o_4_N
ZHU.OG4
ts` o_5_N
ZHU.OG5
ts` o_6_N
ts` u_1
ZHU.U1
ts` u_2
ZHU.U2
ts` u_3
ZHU.U3
ts` u_4
ZHU.U4
ts` u_5
ZHU.U5
ts` u_6
ts`_w @_1_n
ZHU.UN1
ts`_w @_2_n
ZHU.UN2
ts`_w @_3_n
ZHU.UN3
ts`_w @_4_n
ZHU.UN4
ts`_w @_5_n
ZHU.UN5
ts`_w @_6_n
ts_w
ts o_1_N
ZU.OG1
ts o_2_N
ZU.OG2
ts o_3_N
ZU.OG3
ts o_4_N
ZU.OG4
ts o_5_N
ZU.OG5
ts o_6_N
ts u_1
ZU.U1
ts u_2
ZU.U2
ts u_3
ZU.U3
ts u_4
ZU.U4
ts u_5
ZU.U5
ts u_6
ts_w @_1_n
ZU.UN1
ts_w @_2_n
ZU.UN2
ts_w @_3_n
ZU.UN3
ts_w @_4_n
ZU.UN4
ts_w @_5_n
ZU.UN5
ts_w @_6_n
a_1_n r\
AN1.R
aI_1 r\
AI1.R
p_j_1 a_1_n r\
BI.AN1.R
p_h_j_1 a_1_n r\
PI.AN1.R
t_j_1 a_1_n r\
DI.AN1.R
t_h_j_1 a_1_n r\
TI.AN1.R
l_j_1 a_1_n r\
LI.AN1.R
m_j_1 a_1_n r\
MI.AN1.R
n_j_1 a_1_n r\
NI.AN1.R
ts\_j_1 a_1_n r\
JI.AN1.R
ts\_H_1 a_1_n r\
JU.AN1.R
ts\_h_j_1 a_1_n r\
QI.AN1.R
ts\_h_H_1 a_1_n r\
QU.AN1.R
s\_j_1 a_1_n r\
XI.AN1.R
s\_H_1 a_1_n r\
XU.AN1.R
j_1 a_1_n r\
Y.AN1.R
j_H_1 a_1_n r\
YU.AN1.R
a_2_n r\
AN2.R
aI_2 r\
AI2.R
p_j_2 a_2_n r\
BI.AN2.R
p_h_j_2 a_2_n r\
PI.AN2.R
t_j_2 a_2_n r\
DI.AN2.R
t_h_j_2 a_2_n r\
TI.AN2.R
l_j_2 a_2_n r\
LI.AN2.R
m_j_2 a_2_n r\
MI.AN2.R
n_j_2 a_2_n r\
NI.AN2.R
ts\_j_2 a_2_n r\
JI.AN2.R
ts\_H_2 a_2_n r\
JU.AN2.R
ts\_h_j_2 a_2_n r\
QI.AN2.R
ts\_h_H_2 a_2_n r\
QU.AN2.R
s\_j_2 a_2_n r\
XI.AN2.R
s\_H_2 a_2_n r\
XU.AN2.R
j_2 a_2_n r\
Y.AN2.R
j_H_2 a_2_n r\
YU.AN2.R
a_3_n r\
AN3.R
aI_3 r\
AI3.R
p_j_3 a_3_n r\
BI.AN3.R
p_h_j_3 a_3_n r\
PI.AN3.R
t_j_3 a_3_n r\
DI.AN3.R
t_h_j_3 a_3_n r\
TI.AN3.R
l_j_3 a_3_n r\
LI.AN3.R
m_j_3 a_3_n r\
MI.AN3.R
n_j_3 a_3_n r\
NI.AN3.R
ts\_j_3 a_3_n r\
JI.AN3.R
ts\_H_3 a_3_n r\
JU.AN3.R
ts\_h_j_3 a_3_n r\
QI.AN3.R
ts\_h_H_3 a_3_n r\
QU.AN3.R
s\_j_3 a_3_n r\
XI.AN3.R
s\_H_3 a_3_n r\
XU.AN3.R
j_3 a_3_n r\
Y.AN3.R
j_H_3 a_3_n r\
YU.AN3.R
a_4_n r\
AN4.R
aI_4 r\
AI4.R
p_j_4 a_4_n r\
BI.AN4.R
p_h_j_4 a_4_n r\
PI.AN4.R
t_j_4 a_4_n r\
DI.AN4.R
t_h_j_4 a_4_n r\
TI.AN4.R
l_j_4 a_4_n r\
LI.AN4.R
m_j_4 a_4_n r\
MI.AN4.R
n_j_4 a_4_n r\
NI.AN4.R
ts\_j_4 a_4_n r\
JI.AN4.R
ts\_H_4 a_4_n r\
JU.AN4.R
ts\_h_j_4 a_4_n r\
QI.AN4.R
ts\_h_H_4 a_4_n r\
QU.AN4.R
s\_j_4 a_4_n r\
XI.AN4.R
s\_H_4 a_4_n r\
XU.AN4.R
j_4 a_4_n r\
Y.AN4.R
j_H_4 a_4_n r\
YU.AN4.R
a_5_n r\
AN5.R
aI_5 r\
AI5.R
p_j_5 a_5_n r\
BI.AN5.R
p_h_j_5 a_5_n r\
PI.AN5.R
t_j_5 a_5_n r\
DI.AN5.R
t_h_j_5 a_5_n r\
TI.AN5.R
l_j_5 a_5_n r\
LI.AN5.R
m_j_5 a_5_n r\
MI.AN5.R
n_j_5 a_5_n r\
NI.AN5.R
ts\_j_5 a_5_n r\
JI.AN5.R
ts\_H_5 a_5_n r\
JU.AN5.R
ts\_h_j_5 a_5_n r\
QI.AN5.R
ts\_h_H_5 a_5_n r\
QU.AN5.R
s\_j_5 a_5_n r\
XI.AN5.R
s\_H_5 a_5_n r\
XU.AN5.R
j_5 a_5_n r\
Y.AN5.R
j_H_5 a_5_n r\
YU.AN5.R
a_6_n r\
aI_6 r\
p_j_6 a_6_n r\
p_h_j_6 a_6_n r\
t_j_6 a_6_n r\
t_h_j_6 a_6_n r\
l_j_6 a_6_n r\
m_j_6 a_6_n r\
n_j_6 a_6_n r\
ts\_j_6 a_6_n r\
ts\_H_6 a_6_n r\
ts\_h_j_6 a_6_n r\
ts\_h_H_6 a_6_n r\
s\_j_6 a_6_n r\
s\_H_6 a_6_n r\
j_6 a_6_n r\
j_H_6 a_6_n r\
a_1 r\
A1.R
a_2 r\
A2.R
a_3 r\
A3.R
a_4 r\
A4.R
a_5 r\
A5.R
a_6 r\
j_1 a_1 r\
Y.A1.R
j_2 a_2 r\
Y.A2.R
j_3 a_3 r\
Y.A3.R
j_4 a_4 r\
Y.A4.R
j_5 a_5 r\
Y.A5.R
j_6 a_6 r\
l_j_1 a_1 r\
LI.A1.R
l_j_2 a_2 r\
LI.A2.R
l_j_3 a_3 r\
LI.A3.R
l_j_4 a_4 r\
LI.A4.R
l_j_5 a_5 r\
LI.A5.R
l_j_6 a_6 r\
ts\_j_1 a_1 r\
JI.A1.R
ts\_j_2 a_2 r\
JI.A2.R
ts\_j_3 a_3 r\
JI.A3.R
ts\_j_4 a_4 r\
JI.A4.R
ts\_j_5 a_5 r\
JI.A5.R
ts\_j_6 a_6 r\
ts\_h_j_1 a_1 r\
QI.A1.R
ts\_h_j_2 a_2 r\
QI.A2.R
ts\_h_j_3 a_3 r\
QI.A3.R
ts\_h_j_4 a_4 r\
QI.A4.R
ts\_h_j_5 a_5 r\
QI.A5.R
ts\_h_j_6 a_6 r\
s\_j_1 a_1 r\
XI.A1.R
s\_j_2 a_2 r\
XI.A2.R
s\_j_3 a_3 r\
XI.A3.R
s\_j_4 a_4 r\
XI.A4.R
s\_j_5 a_5 r\
XI.A5.R
s\_j_6 a_6 r\
aU_1 r\
AO1.R
aU_2 r\
AO2.R
aU_3 r\
AO3.R
aU_4 r\
AO4.R
aU_5 r\
AO5.R
aU_6 r\
p_j_1 aU_1 r\
BI.AO1.R
p_j_2 aU_2 r\
BI.AO2.R
p_j_3 aU_3 r\
BI.AO3.R
p_j_4 aU_4 r\
BI.AO4.R
p_j_5 aU_5 r\
BI.AO5.R
p_j_6 aU_6 r\
p_h_j_1 aU_1 r\
PI.AO1.R
p_h_j_2 aU_2 r\
PI.AO2.R
p_h_j_3 aU_3 r\
PI.AO3.R
p_h_j_4 aU_4 r\
PI.AO4.R
p_h_j_5 aU_5 r\
PI.AO5.R
p_h_j_6 aU_6 r\
t_j_1 aU_1 r\
DI.AO1.R
t_j_2 aU_2 r\
DI.AO2.R
t_j_3 aU_3 r\
DI.AO3.R
t_j_4 aU_4 r\
DI.AO4.R
t_j_5 aU_5 r\
DI.AO5.R
t_j_6 aU_6 r\
t_h_j_1 aU_1 r\
TI.AO1.R
t_h_j_2 aU_2 r\
TI.AO2.R
t_h_j_3 aU_3 r\
TI.AO3.R
t_h_j_4 aU_4 r\
TI.AO4.R
t_h_j_5 aU_5 r\
TI.AO5.R
t_h_j_6 aU_6 r\
l_j_1 aU_1 r\
LI.AO1.R
l_j_2 aU_2 r\
LI.AO2.R
l_j_3 aU_3 r\
LI.AO3.R
l_j_4 aU_4 r\
LI.AO4.R
l_j_5 aU_5 r\
LI.AO5.R
l_j_6 aU_6 r\
m_j_1 aU_1 r\
MI.AO1.R
m_j_2 aU_2 r\
MI.AO2.R
m_j_3 aU_3 r\
MI.AO3.R
m_j_4 aU_4 r\
MI.AO4.R
m_j_5 aU_5 r\
MI.AO5.R
m_j_6 aU_6 r\
n_j_1 aU_1 r\
NI.AO1.R
n_j_2 aU_2 r\
NI.AO2.R
n_j_3 aU_3 r\
NI.AO3.R
n_j_4 aU_4 r\
NI.AO4.R
n_j_5 aU_5 r\
NI.AO5.R
n_j_6 aU_6 r\
ts\_j_1 aU_1 r\
JI.AO1.R
ts\_j_2 aU_2 r\
JI.AO2.R
ts\_j_3 aU_3 r\
JI.AO3.R
ts\_j_4 aU_4 r\
JI.AO4.R
ts\_j_5 aU_5 r\
JI.AO5.R
ts\_j_6 aU_6 r\
ts\_h_j_1 aU_1 r\
QI.AO1.R
ts\_h_j_2 aU_2 r\
QI.AO2.R
ts\_h_j_3 aU_3 r\
QI.AO3.R
ts\_h_j_4 aU_4 r\
QI.AO4.R
ts\_h_j_5 aU_5 r\
QI.AO5.R
ts\_h_j_6 aU_6 r\
s\_j_1 aU_1 r\
XI.AO1.R
s\_j_2 aU_2 r\
XI.AO2.R
s\_j_3 aU_3 r\
XI.AO3.R
s\_j_4 aU_4 r\
XI.AO4.R
s\_j_5 aU_5 r\
XI.AO5.R
s\_j_6 aU_6 r\
j_1 aU_1 r\
Y.AO1.R
j_2 aU_2 r\
Y.AO2.R
j_3 aU_3 r\
Y.AO3.R
j_4 aU_4 r\
Y.AO4.R
j_5 aU_5 r\
Y.AO5.R
j_6 aU_6 r\
@_1_n r\
EN1.R
1_1 r\
IH1.R
M_1 r\
eI_1 r\
EI1.R
y_1 r\
YU1.R
n y_1 r\
NYU.YU1.R
l y_1 r\
LYU.YU1.R
ts\ y_1 r\
JU.YU1.R
ts\_h y_1 r\
QU.YU1.R
s\ y_1 r\
XU.YU1.R
j_1 y_1 r\
YU.YU1.R
i_1_n r\
IN1.R
i_1 r\
I1.R
p i_1_n r\
BI.IN1.R
p_h i_1_n r\
PI.IN1.R
m i_1_n r\
MI.IN1.R
n i_1_n r\
NI.IN1.R
l i_1_n r\
LI.IN1.R
ts\ i_1_n r\
JI.IN1.R
ts\_h i_1_n r\
QI.IN1.R
s\ i_1_n r\
XI.IN1.R
j_1 i_1_n r\
Y.IN1.R
t_w @_1_n r\
DU.UN1.R
t_h_w @_1_n r\
TU.UN1.R
l_w @_1_n r\
LU.UN1.R
k_w @_1_n r\
GU.UN1.R
k_h_w @_1_n r\
KU.UN1.R
x_w @_1_n r\
HU.UN1.R
ts_w @_1_n r\
ZU.UN1.R
ts`_w @_1_n r\
ZHU.UN1.R
ts_h_w @_1_n r\
CU.UN1.R
ts`_h_w @_1_n r\
CHU.UN1.R
s_w @_1_n r\
SU.UN1.R
s`_w @_1_n r\
SHU.UN1.R
z`_w @_1_n r\
RU.UN1.R
p i_1 r\
BI.I1.R
p_h i_1 r\
PI.I1.R
t i_1 r\
DI.I1.R
t_h i_1 r\
TI.I1.R
l i_1 r\
LI.I1.R
m i_1 r\
MI.I1.R
n i_1 r\
NI.I1.R
ts\ i_1 r\
JI.I1.R
ts\_h i_1 r\
QI.I1.R
s\ i_1 r\
XI.I1.R
j_1 i_1 r\
Y.I1.R
@_2_n r\
EN2.R
1_2 r\
IH2.R
M_2 r\
eI_2 r\
EI2.R
y_2 r\
YU2.R
n y_2 r\
NYU.YU2.R
l y_2 r\
LYU.YU2.R
ts\ y_2 r\
JU.YU2.R
ts\_h y_2 r\
QU.YU2.R
s\ y_2 r\
XU.YU2.R
j_2 y_2 r\
YU.YU2.R
i_2_n r\
IN2.R
i_2 r\
I2.R
p i_2_n r\
BI.IN2.R
p_h i_2_n r\
PI.IN2.R
m i_2_n r\
MI.IN2.R
n i_2_n r\
NI.IN2.R
l i_2_n r\
LI.IN2.R
ts\ i_2_n r\
JI.IN2.R
ts\_h i_2_n r\
QI.IN2.R
s\ i_2_n r\
XI.IN2.R
j_2 i_2_n r\
Y.IN2.R
t_w @_2_n r\
DU.UN2.R
t_h_w @_2_n r\
TU.UN2.R
l_w @_2_n r\
LU.UN2.R
k_w @_2_n r\
GU.UN2.R
k_h_w @_2_n r\
KU.UN2.R
x_w @_2_n r\
HU.UN2.R
ts_w @_2_n r\
ZU.UN2.R
ts`_w @_2_n r\
ZHU.UN2.R
ts_h_w @_2_n r\
CU.UN2.R
ts`_h_w @_2_n r\
CHU.UN2.R
s_w @_2_n r\
SU.UN2.R
s`_w @_2_n r\
SHU.UN2.R
z`_w @_2_n r\
RU.UN2.R
p i_2 r\
BI.I2.R
p_h i_2 r\
PI.I2.R
t i_2 r\
DI.I2.R
t_h i_2 r\
TI.I2.R
l i_2 r\
LI.I2.R
m i_2 r\
MI.I2.R
n i_2 r\
NI.I2.R
ts\ i_2 r\
JI.I2.R
ts\_h i_2 r\
QI.I2.R
s\ i_2 r\
XI.I2.R
j_2 i_2 r\
Y.I2.R
@_3_n r\
EN3.R
1_3 r\
IH3.R
M_3 r\
eI_3 r\
EI3.R
y_3 r\
YU3.R
n y_3 r\
NYU.YU3.R
l y_3 r\
LYU.YU3.R
ts\ y_3 r\
JU.YU3.R
ts\_h y_3 r\
QU.YU3.R
s\ y_3 r\
XU.YU3.R
j_3 y_3 r\
YU.YU3.R
i_3_n r\
IN3.R
i_3 r\
I3.R
p i_3_n r\
BI.IN3.R
p_h i_3_n r\
PI.IN3.R
m i_3_n r\
MI.IN3.R
n i_3_n r\
NI.IN3.R
l i_3_n r\
LI.IN3.R
ts\ i_3_n r\
JI.IN3.R
ts\_h i_3_n r\
QI.IN3.R
s\ i_3_n r\
XI.IN3.R
j_3 i_3_n r\
Y.IN3.R
t_w @_3_n r\
DU.UN3.R
t_h_w @_3_n r\
TU.UN3.R
l_w @_3_n r\
LU.UN3.R
k_w @_3_n r\
GU.UN3.R
k_h_w @_3_n r\
KU.UN3.R
x_w @_3_n r\
HU.UN3.R
ts_w @_3_n r\
ZU.UN3.R
ts`_w @_3_n r\
ZHU.UN3.R
ts_h_w @_3_n r\
CU.UN3.R
ts`_h_w @_3_n r\
CHU.UN3.R
s_w @_3_n r\
SU.UN3.R
s`_w @_3_n r\
SHU.UN3.R
z`_w @_3_n r\
RU.UN3.R
p i_3 r\
BI.I3.R
p_h i_3 r\
PI.I3.R
t i_3 r\
DI.I3.R
t_h i_3 r\
TI.I3.R
l i_3 r\
LI.I3.R
m i_3 r\
MI.I3.R
n i_3 r\
NI.I3.R
ts\ i_3 r\
JI.I3.R
ts\_h i_3 r\
QI.I3.R
s\ i_3 r\
XI.I3.R
j_3 i_3 r\
Y.I3.R
@_4_n r\
EN4.R
1_4 r\
IH4.R
M_4 r\
eI_4 r\
EI4.R
y_4 r\
YU4.R
n y_4 r\
NYU.YU4.R
l y_4 r\
LYU.YU4.R
ts\ y_4 r\
JU.YU4.R
ts\_h y_4 r\
QU.YU4.R
s\ y_4 r\
XU.YU4.R
j_4 y_4 r\
YU.YU4.R
i_4_n r\
IN4.R
i_4 r\
I4.R
p i_4_n r\
BI.IN4.R
p_h i_4_n r\
PI.IN4.R
m i_4_n r\
MI.IN4.R
n i_4_n r\
NI.IN4.R
l i_4_n r\
LI.IN4.R
ts\ i_4_n r\
JI.IN4.R
ts\_h i_4_n r\
QI.IN4.R
s\ i_4_n r\
XI.IN4.R
j_4 i_4_n r\
Y.IN4.R
t_w @_4_n r\
DU.UN4.R
t_h_w @_4_n r\
TU.UN4.R
l_w @_4_n r\
LU.UN4.R
k_w @_4_n r\
GU.UN4.R
k_h_w @_4_n r\
KU.UN4.R
x_w @_4_n r\
HU.UN4.R
ts_w @_4_n r\
ZU.UN4.R
ts`_w @_4_n r\
ZHU.UN4.R
ts_h_w @_4_n r\
CU.UN4.R
ts`_h_w @_4_n r\
CHU.UN4.R
s_w @_4_n r\
SU.UN4.R
s`_w @_4_n r\
SHU.UN4.R
z`_w @_4_n r\
RU.UN4.R
p i_4 r\
BI.I4.R
p_h i_4 r\
PI.I4.R
t i_4 r\
DI.I4.R
t_h i_4 r\
TI.I4.R
l i_4 r\
LI.I4.R
m i_4 r\
MI.I4.R
n i_4 r\
NI.I4.R
ts\ i_4 r\
JI.I4.R
ts\_h i_4 r\
QI.I4.R
s\ i_4 r\
XI.I4.R
j_4 i_4 r\
Y.I4.R
@_5_n r\
EN5.R
1_5 r\
IH5.R
M_5 r\
eI_5 r\
EI5.R
y_5 r\
YU5.R
n y_5 r\
NYU.YU5.R
l y_5 r\
LYU.YU5.R
ts\ y_5 r\
JU.YU5.R
ts\_h y_5 r\
QU.YU5.R
s\ y_5 r\
XU.YU5.R
j_5 y_5 r\
YU.YU5.R
i_5_n r\
IN5.R
i_5 r\
I5.R
p i_5_n r\
BI.IN5.R
p_h i_5_n r\
PI.IN5.R
m i_5_n r\
MI.IN5.R
n i_5_n r\
NI.IN5.R
l i_5_n r\
LI.IN5.R
ts\ i_5_n r\
JI.IN5.R
ts\_h i_5_n r\
QI.IN5.R
s\ i_5_n r\
XI.IN5.R
j_5 i_5_n r\
Y.IN5.R
t_w @_5_n r\
DU.UN5.R
t_h_w @_5_n r\
TU.UN5.R
l_w @_5_n r\
LU.UN5.R
k_w @_5_n r\
GU.UN5.R
k_h_w @_5_n r\
KU.UN5.R
x_w @_5_n r\
HU.UN5.R
ts_w @_5_n r\
ZU.UN5.R
ts`_w @_5_n r\
ZHU.UN5.R
ts_h_w @_5_n r\
CU.UN5.R
ts`_h_w @_5_n r\
CHU.UN5.R
s_w @_5_n r\
SU.UN5.R
s`_w @_5_n r\
SHU.UN5.R
z`_w @_5_n r\
RU.UN5.R
p i_5 r\
BI.I5.R
p_h i_5 r\
PI.I5.R
t i_5 r\
DI.I5.R
t_h i_5 r\
TI.I5.R
l i_5 r\
LI.I5.R
m i_5 r\
MI.I5.R
n i_5 r\
NI.I5.R
ts\ i_5 r\
JI.I5.R
ts\_h i_5 r\
QI.I5.R
s\ i_5 r\
XI.I5.R
j_5 i_5 r\
Y.I5.R
@_6_n r\
1_6 r\
M_6 r\
eI_6 r\
y_6 r\
n y_6 r\
l y_6 r\
ts\ y_6 r\
ts\_h y_6 r\
s\ y_6 r\
j_6 y_6 r\
i_6_n r\
i_6 r\
p i_6_n r\
p_h i_6_n r\
m i_6_n r\
n i_6_n r\
l i_6_n r\
ts\ i_6_n r\
ts\_h i_6_n r\
s\ i_6_n r\
j_6 i_6_n r\
t_w @_6_n r\
t_h_w @_6_n r\
l_w @_6_n r\
k_w @_6_n r\
k_h_w @_6_n r\
x_w @_6_n r\
ts_w @_6_n r\
ts`_w @_6_n r\
ts_h_w @_6_n r\
ts`_h_w @_6_n r\
s_w @_6_n r\
s`_w @_6_n r\
z`_w @_6_n r\
p i_6 r\
p_h i_6 r\
t i_6 r\
t_h i_6 r\
l i_6 r\
m i_6 r\
n i_6 r\
ts\ i_6 r\
ts\_h i_6 r\
s\ i_6 r\
j_6 i_6 r\
O_1 r\
O1.R
O_2 r\
O2.R
O_3 r\
O3.R
O_4 r\
O4.R
O_5 r\
O5.R
O_6 r\
p O_1 r\
BU.O1.R
p O_2 r\
BU.O2.R
p O_3 r\
BU.O3.R
p O_4 r\
BU.O4.R
p O_5 r\
BU.O5.R
p O_6 r\
oU_1 r\
OU1.R
oU_2 r\
OU2.R
oU_3 r\
OU3.R
oU_4 r\
OU4.R
oU_5 r\
OU5.R
oU_6 r\
t_j_1 oU_1 r\
DI.OU1.R
t_j_2 oU_2 r\
DI.OU2.R
t_j_3 oU_3 r\
DI.OU3.R
t_j_4 oU_4 r\
DI.OU4.R
t_j_5 oU_5 r\
DI.OU5.R
t_j_6 oU_6 r\
l_j_1 oU_1 r\
LI.OU1.R
l_j_2 oU_2 r\
LI.OU2.R
l_j_3 oU_3 r\
LI.OU3.R
l_j_4 oU_4 r\
LI.OU4.R
l_j_5 oU_5 r\
LI.OU5.R
l_j_6 oU_6 r\
m_j_1 oU_1 r\
MI.OU1.R
m_j_2 oU_2 r\
MI.OU2.R
m_j_3 oU_3 r\
MI.OU3.R
m_j_4 oU_4 r\
MI.OU4.R
m_j_5 oU_5 r\
MI.OU5.R
m_j_6 oU_6 r\
n_j_1 oU_1 r\
NI.OU1.R
n_j_2 oU_2 r\
NI.OU2.R
n_j_3 oU_3 r\
NI.OU3.R
n_j_4 oU_4 r\
NI.OU4.R
n_j_5 oU_5 r\
NI.OU5.R
n_j_6 oU_6 r\
ts\_j_1 oU_1 r\
JI.OU1.R
ts\_j_2 oU_2 r\
JI.OU2.R
ts\_j_3 oU_3 r\
JI.OU3.R
ts\_j_4 oU_4 r\
JI.OU4.R
ts\_j_5 oU_5 r\
JI.OU5.R
ts\_j_6 oU_6 r\
ts\_h_j_1 oU_1 r\
QI.OU1.R
ts\_h_j_2 oU_2 r\
QI.OU2.R
ts\_h_j_3 oU_3 r\
QI.OU3.R
ts\_h_j_4 oU_4 r\
QI.OU4.R
ts\_h_j_5 oU_5 r\
QI.OU5.R
ts\_h_j_6 oU_6 r\
s\_j_1 oU_1 r\
XI.OU1.R
s\_j_2 oU_2 r\
XI.OU2.R
s\_j_3 oU_3 r\
XI.OU3.R
s\_j_4 oU_4 r\
XI.OU4.R
s\_j_5 oU_5 r\
XI.OU5.R
s\_j_6 oU_6 r\
j_1 oU_1 r\
Y.OU1.R
j_2 oU_2 r\
Y.OU2.R
j_3 oU_3 r\
Y.OU3.R
j_4 oU_4 r\
Y.OU4.R
j_5 oU_5 r\
Y.OU5.R
j_6 oU_6 r\
i_1_N r\
IG1.R
i_2_N r\
IG2.R
i_3_N r\
IG3.R
i_4_N r\
IG4.R
i_5_N r\
IG5.R
i_6_N r\
p i_1_N r\
BI.IG1.R
p i_2_N r\
BI.IG2.R
p i_3_N r\
BI.IG3.R
p i_4_N r\
BI.IG4.R
p i_5_N r\
BI.IG5.R
p i_6_N r\
p_h i_1_N r\
PI.IG1.R
p_h i_2_N r\
PI.IG2.R
p_h i_3_N r\
PI.IG3.R
p_h i_4_N r\
PI.IG4.R
p_h i_5_N r\
PI.IG5.R
p_h i_6_N r\
t i_1_N r\
DI.IG1.R
t i_2_N r\
DI.IG2.R
t i_3_N r\
DI.IG3.R
t i_4_N r\
DI.IG4.R
t i_5_N r\
DI.IG5.R
t i_6_N r\
t_h i_1_N r\
TI.IG1.R
t_h i_2_N r\
TI.IG2.R
t_h i_3_N r\
TI.IG3.R
t_h i_4_N r\
TI.IG4.R
t_h i_5_N r\
TI.IG5.R
t_h i_6_N r\
l i_1_N r\
LI.IG1.R
l i_2_N r\
LI.IG2.R
l i_3_N r\
LI.IG3.R
l i_4_N r\
LI.IG4.R
l i_5_N r\
LI.IG5.R
l i_6_N r\
m i_1_N r\
MI.IG1.R
m i_2_N r\
MI.IG2.R
m i_3_N r\
MI.IG3.R
m i_4_N r\
MI.IG4.R
m i_5_N r\
MI.IG5.R
m i_6_N r\
n i_1_N r\
NI.IG1.R
n i_2_N r\
NI.IG2.R
n i_3_N r\
NI.IG3.R
n i_4_N r\
NI.IG4.R
n i_5_N r\
NI.IG5.R
n i_6_N r\
ts\ i_1_N r\
JI.IG1.R
ts\ i_2_N r\
JI.IG2.R
ts\ i_3_N r\
JI.IG3.R
ts\ i_4_N r\
JI.IG4.R
ts\ i_5_N r\
JI.IG5.R
ts\ i_6_N r\
ts\_h i_1_N r\
QI.IG1.R
ts\_h i_2_N r\
QI.IG2.R
ts\_h i_3_N r\
QI.IG3.R
ts\_h i_4_N r\
QI.IG4.R
ts\_h i_5_N r\
QI.IG5.R
ts\_h i_6_N r\
s\ i_1_N r\
XI.IG1.R
s\ i_2_N r\
XI.IG2.R
s\ i_3_N r\
XI.IG3.R
s\ i_4_N r\
XI.IG4.R
s\ i_5_N r\
XI.IG5.R
s\ i_6_N r\
j_1 i_1_N r\
Y.IG1.R
j_2 i_2_N r\
Y.IG2.R
j_3 i_3_N r\
Y.IG3.R
j_4 i_4_N r\
Y.IG4.R
j_5 i_5_N r\
Y.IG5.R
j_6 i_6_N r\
@_1_N r\
EG1.R
@_2_N r\
EG2.R
@_3_N r\
EG3.R
@_4_N r\
EG4.R
@_5_N r\
EG5.R
@_6_N r\
u_1 r\
U1.R
u_2 r\
U2.R
u_3 r\
U3.R
u_4 r\
U4.R
u_5 r\
U5.R
u_6 r\
p u_1 r\
BU.U1.R
p u_2 r\
BU.U2.R
p u_3 r\
BU.U3.R
p u_4 r\
BU.U4.R
p u_5 r\
BU.U5.R
p u_6 r\
t u_1 r\
DU.U1.R
t u_2 r\
DU.U2.R
t u_3 r\
DU.U3.R
t u_4 r\
DU.U4.R
t u_5 r\
DU.U5.R
t u_6 r\
t_h u_1 r\
TU.U1.R
t_h u_2 r\
TU.U2.R
t_h u_3 r\
TU.U3.R
t_h u_4 r\
TU.U4.R
t_h u_5 r\
TU.U5.R
t_h u_6 r\
l u_1 r\
LU.U1.R
l u_2 r\
LU.U2.R
l u_3 r\
LU.U3.R
l u_4 r\
LU.U4.R
l u_5 r\
LU.U5.R
l u_6 r\
m u_1 r\
MU.U1.R
m u_2 r\
MU.U2.R
m u_3 r\
MU.U3.R
m u_4 r\
MU.U4.R
m u_5 r\
MU.U5.R
m u_6 r\
n u_1 r\
NU.U1.R
n u_2 r\
NU.U2.R
n u_3 r\
NU.U3.R
n u_4 r\
NU.U4.R
n u_5 r\
NU.U5.R
n u_6 r\
k u_1 r\
GU.U1.R
k u_2 r\
GU.U2.R
k u_3 r\
GU.U3.R
k u_4 r\
GU.U4.R
k u_5 r\
GU.U5.R
k u_6 r\
k_h u_1 r\
KU.U1.R
k_h u_2 r\
KU.U2.R
k_h u_3 r\
KU.U3.R
k_h u_4 r\
KU.U4.R
k_h u_5 r\
KU.U5.R
k_h u_6 r\
x u_1 r\
HU.U1.R
x u_2 r\
HU.U2.R
x u_3 r\
HU.U3.R
x u_4 r\
HU.U4.R
x u_5 r\
HU.U5.R
x u_6 r\
ts u_1 r\
ZU.U1.R
ts u_2 r\
ZU.U2.R
ts u_3 r\
ZU.U3.R
ts u_4 r\
ZU.U4.R
ts u_5 r\
ZU.U5.R
ts u_6 r\
ts_h u_1 r\
CU.U1.R
ts_h u_2 r\
CU.U2.R
ts_h u_3 r\
CU.U3.R
ts_h u_4 r\
CU.U4.R
ts_h u_5 r\
CU.U5.R
ts_h u_6 r\
s u_1 r\
SU.U1.R
s u_2 r\
SU.U2.R
s u_3 r\
SU.U3.R
s u_4 r\
SU.U4.R
s u_5 r\
SU.U5.R
s u_6 r\
ts` u_1 r\
ZHU.U1.R
ts` u_2 r\
ZHU.U2.R
ts` u_3 r\
ZHU.U3.R
ts` u_4 r\
ZHU.U4.R
ts` u_5 r\
ZHU.U5.R
ts` u_6 r\
ts`_h u_1 r\
CHU.U1.R
ts`_h u_2 r\
CHU.U2.R
ts`_h u_3 r\
CHU.U3.R
ts`_h u_4 r\
CHU.U4.R
ts`_h u_5 r\
CHU.U5.R
ts`_h u_6 r\
s` u_1 r\
SHU.U1.R
s` u_2 r\
SHU.U2.R
s` u_3 r\
SHU.U3.R
s` u_4 r\
SHU.U4.R
s` u_5 r\
SHU.U5.R
s` u_6 r\
z` u_1 r\
RU.U1.R
z` u_2 r\
RU.U2.R
z` u_3 r\
RU.U3.R
z` u_4 r\
RU.U4.R
z` u_5 r\
RU.U5.R
z` u_6 r\
7_1 r\
E1.R
7_2 r\
E2.R
7_3 r\
E3.R
7_4 r\
E4.R
7_5 r\
E5.R
7_6 r\
A_1_N r\
AG1.R
A_2_N r\
AG2.R
A_3_N r\
AG3.R
A_4_N r\
AG4.R
A_5_N r\
AG5.R
A_6_N r\
ts\_j_1 A_1_N r\
JI.AG1.R
ts\_j_2 A_2_N r\
JI.AG2.R
ts\_j_3 A_3_N r\
JI.AG3.R
ts\_j_4 A_4_N r\
JI.AG4.R
ts\_j_5 A_5_N r\
JI.AG5.R
ts\_j_6 A_6_N r\
l_j_1 A_1_N r\
LI.AG1.R
l_j_2 A_2_N r\
LI.AG2.R
l_j_3 A_3_N r\
LI.AG3.R
l_j_4 A_4_N r\
LI.AG4.R
l_j_5 A_5_N r\
LI.AG5.R
l_j_6 A_6_N r\
n_j_1 A_1_N r\
NI.AG1.R
n_j_2 A_2_N r\
NI.AG2.R
n_j_3 A_3_N r\
NI.AG3.R
n_j_4 A_4_N r\
NI.AG4.R
n_j_5 A_5_N r\
NI.AG5.R
n_j_6 A_6_N r\
ts\_h_j_1 A_1_N r\
QI.AG1.R
ts\_h_j_2 A_2_N r\
QI.AG2.R
ts\_h_j_3 A_3_N r\
QI.AG3.R
ts\_h_j_4 A_4_N r\
QI.AG4.R
ts\_h_j_5 A_5_N r\
QI.AG5.R
ts\_h_j_6 A_6_N r\
s\_j_1 A_1_N r\
XI.AG1.R
s\_j_2 A_2_N r\
XI.AG2.R
s\_j_3 A_3_N r\
XI.AG3.R
s\_j_4 A_4_N r\
XI.AG4.R
s\_j_5 A_5_N r\
XI.AG5.R
s\_j_6 A_6_N r\
j_1 A_1_N r\
Y.AG1.R
j_2 A_2_N r\
Y.AG2.R
j_3 A_3_N r\
Y.AG3.R
j_4 A_4_N r\
Y.AG4.R
j_5 A_5_N r\
Y.AG5.R
j_6 A_6_N r\
o_1_N r\
OG1.R
o_2_N r\
OG2.R
o_3_N r\
OG3.R
o_4_N r\
OG4.R
o_5_N r\
OG5.R
o_6_N r\
ts`_h o_1_N r\
CHU.OG1.R
ts`_h o_2_N r\
CHU.OG2.R
ts`_h o_3_N r\
CHU.OG3.R
ts`_h o_4_N r\
CHU.OG4.R
ts`_h o_5_N r\
CHU.OG5.R
ts`_h o_6_N r\
ts_h o_1_N r\
CU.OG1.R
ts_h o_2_N r\
CU.OG2.R
ts_h o_3_N r\
CU.OG3.R
ts_h o_4_N r\
CU.OG4.R
ts_h o_5_N r\
CU.OG5.R
ts_h o_6_N r\
t o_1_N r\
DU.OG1.R
t o_2_N r\
DU.OG2.R
t o_3_N r\
DU.OG3.R
t o_4_N r\
DU.OG4.R
t o_5_N r\
DU.OG5.R
t o_6_N r\
k o_1_N r\
GU.OG1.R
k o_2_N r\
GU.OG2.R
k o_3_N r\
GU.OG3.R
k o_4_N r\
GU.OG4.R
k o_5_N r\
GU.OG5.R
k o_6_N r\
x o_1_N r\
HU.OG1.R
x o_2_N r\
HU.OG2.R
x o_3_N r\
HU.OG3.R
x o_4_N r\
HU.OG4.R
x o_5_N r\
HU.OG5.R
x o_6_N r\
ts\_j_1 o_1_N r\
JI.OG1.R
ts\_j_2 o_2_N r\
JI.OG2.R
ts\_j_3 o_3_N r\
JI.OG3.R
ts\_j_4 o_4_N r\
JI.OG4.R
ts\_j_5 o_5_N r\
JI.OG5.R
ts\_j_6 o_6_N r\
k_h o_1_N r\
KU.OG1.R
k_h o_2_N r\
KU.OG2.R
k_h o_3_N r\
KU.OG3.R
k_h o_4_N r\
KU.OG4.R
k_h o_5_N r\
KU.OG5.R
k_h o_6_N r\
l o_1_N r\
LU.OG1.R
l o_2_N r\
LU.OG2.R
l o_3_N r\
LU.OG3.R
l o_4_N r\
LU.OG4.R
l o_5_N r\
LU.OG5.R
l o_6_N r\
n o_1_N r\
NU.OG1.R
n o_2_N r\
NU.OG2.R
n o_3_N r\
NU.OG3.R
n o_4_N r\
NU.OG4.R
n o_5_N r\
NU.OG5.R
n o_6_N r\
ts\_h_j_1 o_1_N r\
QI.OG1.R
ts\_h_j_2 o_2_N r\
QI.OG2.R
ts\_h_j_3 o_3_N r\
QI.OG3.R
ts\_h_j_4 o_4_N r\
QI.OG4.R
ts\_h_j_5 o_5_N r\
QI.OG5.R
ts\_h_j_6 o_6_N r\
s o_1_N r\
SU.OG1.R
s o_2_N r\
SU.OG2.R
s o_3_N r\
SU.OG3.R
s o_4_N r\
SU.OG4.R
s o_5_N r\
SU.OG5.R
s o_6_N r\
t_h o_1_N r\
TU.OG1.R
t_h o_2_N r\
TU.OG2.R
t_h o_3_N r\
TU.OG3.R
t_h o_4_N r\
TU.OG4.R
t_h o_5_N r\
TU.OG5.R
t_h o_6_N r\
s\_j_1 o_1_N r\
XI.OG1.R
s\_j_2 o_2_N r\
XI.OG2.R
s\_j_3 o_3_N r\
XI.OG3.R
s\_j_4 o_4_N r\
XI.OG4.R
s\_j_5 o_5_N r\
XI.OG5.R
s\_j_6 o_6_N r\
j_1 o_1_N r\
Y.OG1.R
j_2 o_2_N r\
Y.OG2.R
j_3 o_3_N r\
Y.OG3.R
j_4 o_4_N r\
Y.OG4.R
j_5 o_5_N r\
Y.OG5.R
j_6 o_6_N r\
ts` o_1_N r\
ZHU.OG1.R
ts` o_2_N r\
ZHU.OG2.R
ts` o_3_N r\
ZHU.OG3.R
ts` o_4_N r\
ZHU.OG4.R
ts` o_5_N r\
ZHU.OG5.R
ts` o_6_N r\
ts o_1_N r\
ZU.OG1.R
ts o_2_N r\
ZU.OG2.R
ts o_3_N r\
ZU.OG3.R
ts o_4_N r\
ZU.OG4.R
ts o_5_N r\
ZU.OG5.R
ts o_6_N r\
E_1 r\
IE1.R
E_2 r\
IE2.R
E_3 r\
IE3.R
E_4 r\
IE4.R
E_5 r\
IE5.R
E_6 r\
p_j_1 E_1 r\
BI.IE1.R
p_j_2 E_2 r\
BI.IE2.R
p_j_3 E_3 r\
BI.IE3.R
p_j_4 E_4 r\
BI.IE4.R
p_j_5 E_5 r\
BI.IE5.R
p_j_6 E_6 r\
t_j_1 E_1 r\
DI.IE1.R
t_j_2 E_2 r\
DI.IE2.R
t_j_3 E_3 r\
DI.IE3.R
t_j_4 E_4 r\
DI.IE4.R
t_j_5 E_5 r\
DI.IE5.R
t_j_6 E_6 r\
ts\_j_1 E_1 r\
JI.IE1.R
ts\_j_2 E_2 r\
JI.IE2.R
ts\_j_3 E_3 r\
JI.IE3.R
ts\_j_4 E_4 r\
JI.IE4.R
ts\_j_5 E_5 r\
JI.IE5.R
ts\_j_6 E_6 r\
ts\_H_1 E_1 r\
JU.IE1.R
ts\_H_2 E_2 r\
JU.IE2.R
ts\_H_3 E_3 r\
JU.IE3.R
ts\_H_4 E_4 r\
JU.IE4.R
ts\_H_5 E_5 r\
JU.IE5.R
ts\_H_6 E_6 r\
l_j_1 E_1 r\
LI.IE1.R
l_j_2 E_2 r\
LI.IE2.R
l_j_3 E_3 r\
LI.IE3.R
l_j_4 E_4 r\
LI.IE4.R
l_j_5 E_5 r\
LI.IE5.R
l_j_6 E_6 r\
l_H_1 E_1 r\
LYU.IE1.R
l_H_2 E_2 r\
LYU.IE2.R
l_H_3 E_3 r\
LYU.IE3.R
l_H_4 E_4 r\
LYU.IE4.R
l_H_5 E_5 r\
LYU.IE5.R
l_H_6 E_6 r\
m_j_1 E_1 r\
MI.IE1.R
m_j_2 E_2 r\
MI.IE2.R
m_j_3 E_3 r\
MI.IE3.R
m_j_4 E_4 r\
MI.IE4.R
m_j_5 E_5 r\
MI.IE5.R
m_j_6 E_6 r\
n_j_1 E_1 r\
NI.IE1.R
n_j_2 E_2 r\
NI.IE2.R
n_j_3 E_3 r\
NI.IE3.R
n_j_4 E_4 r\
NI.IE4.R
n_j_5 E_5 r\
NI.IE5.R
n_j_6 E_6 r\
n_H_1 E_1 r\
NYU.IE1.R
n_H_2 E_2 r\
NYU.IE2.R
n_H_3 E_3 r\
NYU.IE3.R
n_H_4 E_4 r\
NYU.IE4.R
n_H_5 E_5 r\
NYU.IE5.R
n_H_6 E_6 r\
p_h_j_1 E_1 r\
PI.IE1.R
p_h_j_2 E_2 r\
PI.IE2.R
p_h_j_3 E_3 r\
PI.IE3.R
p_h_j_4 E_4 r\
PI.IE4.R
p_h_j_5 E_5 r\
PI.IE5.R
p_h_j_6 E_6 r\
ts\_h_j_1 E_1 r\
QI.IE1.R
ts\_h_j_2 E_2 r\
QI.IE2.R
ts\_h_j_3 E_3 r\
QI.IE3.R
ts\_h_j_4 E_4 r\
QI.IE4.R
ts\_h_j_5 E_5 r\
QI.IE5.R
ts\_h_j_6 E_6 r\
ts\_h_H_1 E_1 r\
QU.IE1.R
ts\_h_H_2 E_2 r\
QU.IE2.R
ts\_h_H_3 E_3 r\
QU.IE3.R
ts\_h_H_4 E_4 r\
QU.IE4.R
ts\_h_H_5 E_5 r\
QU.IE5.R
ts\_h_H_6 E_6 r\
t_h_j_1 E_1 r\
TI.IE1.R
t_h_j_2 E_2 r\
TI.IE2.R
t_h_j_3 E_3 r\
TI.IE3.R
t_h_j_4 E_4 r\
TI.IE4.R
t_h_j_5 E_5 r\
TI.IE5.R
t_h_j_6 E_6 r\
s\_j_1 E_1 r\
XI.IE1.R
s\_j_2 E_2 r\
XI.IE2.R
s\_j_3 E_3 r\
XI.IE3.R
s\_j_4 E_4 r\
XI.IE4.R
s\_j_5 E_5 r\
XI.IE5.R
s\_j_6 E_6 r\
s\_H_1 E_1 r\
XU.IE1.R
s\_H_2 E_2 r\
XU.IE2.R
s\_H_3 E_3 r\
XU.IE3.R
s\_H_4 E_4 r\
XU.IE4.R
s\_H_5 E_5 r\
XU.IE5.R
s\_H_6 E_6 r\
j_1 E_1 r\
Y.IE1.R
j_2 E_2 r\
Y.IE2.R
j_3 E_3 r\
Y.IE3.R
j_4 E_4 r\
Y.IE4.R
j_5 E_5 r\
Y.IE5.R
j_6 E_6 r\
j_H_1 E_1 r\
YU.IE1.R
j_H_2 E_2 r\
YU.IE2.R
j_H_3 E_3 r\
YU.IE3.R
j_H_4 E_4 r\
YU.IE4.R
j_H_5 E_5 r\
YU.IE5.R
j_H_6 E_6 r\
n a_1
N.A1
n a_2
N.A2
n a_3
N.A3
n a_4
N.A4
n a_5
N.A5
n a_6
n 7_1
N.E1
n 7_2
N.E2
n 7_3
N.E3
n 7_4
N.E4
n 7_5
N.E5
n 7_6
n aI_1
N.AI1
n aI_2
N.AI2
n aI_3
N.AI3
n aI_4
N.AI4
n aI_5
N.AI5
n aI_6
n eI_1
N.EI1
n eI_2
N.EI2
n eI_3
N.EI3
n eI_4
N.EI4
n eI_5
N.EI5
n eI_6
n aU_1
N.AO1
n aU_2
N.AO2
n aU_3
N.AO3
n aU_4
N.AO4
n aU_5
N.AO5
n aU_6
n oU_1
N.OU1
n oU_2
N.OU2
n oU_3
N.OU3
n oU_4
N.OU4
n oU_5
N.OU5
n oU_6
n a_1_n
N.AN1
n a_2_n
N.AN2
n a_3_n
N.AN3
n a_4_n
N.AN4
n a_5_n
N.AN5
n a_6_n
n @_1_n
N.EN1
n @_2_n
N.EN2
n @_3_n
N.EN3
n @_4_n
N.EN4
n @_5_n
N.EN5
n @_6_n
n A_1_N
N.AG1
n A_2_N
N.AG2
n A_3_N
N.AG3
n A_4_N
N.AG4
n A_5_N
N.AG5
n A_6_N
n @_1_N
N.EG1
n @_2_N
N.EG2
n @_3_N
N.EG3
n @_4_N
N.EG4
n @_5_N
N.EG5
n @_6_N
n_w O_1
NU.O1
n_w O_2
NU.O2
n_w O_3
NU.O3
n_w O_4
NU.O4
n_w O_5
NU.O5
n_w O_6
n_w a_1_n
NU.AN1
n_w a_2_n
NU.AN2
n_w a_3_n
NU.AN3
n_w a_4_n
NU.AN4
n_w a_5_n
NU.AN5
n_w a_6_n
n a_1 r\
N.A1.R
n a_2 r\
N.A2.R
n a_3 r\
N.A3.R
n a_4 r\
N.A4.R
n a_5 r\
N.A5.R
n a_6 r\
n 7_1 r\
N.E1.R
n 7_2 r\
N.E2.R
n 7_3 r\
N.E3.R
n 7_4 r\
N.E4.R
n 7_5 r\
N.E5.R
n 7_6 r\
n aI_1 r\
N.AI1.R
n aI_2 r\
N.AI2.R
n aI_3 r\
N.AI3.R
n aI_4 r\
N.AI4.R
n aI_5 r\
N.AI5.R
n aI_6 r\
n eI_1 r\
N.EI1.R
n eI_2 r\
N.EI2.R
n eI_3 r\
N.EI3.R
n eI_4 r\
N.EI4.R
n eI_5 r\
N.EI5.R
n eI_6 r\
n aU_1 r\
N.AO1.R
n aU_2 r\
N.AO2.R
n aU_3 r\
N.AO3.R
n aU_4 r\
N.AO4.R
n aU_5 r\
N.AO5.R
n aU_6 r\
n oU_1 r\
N.OU1.R
n oU_2 r\
N.OU2.R
n oU_3 r\
N.OU3.R
n oU_4 r\
N.OU4.R
n oU_5 r\
N.OU5.R
n oU_6 r\
n a_1_n r\
N.AN1.R
n a_2_n r\
N.AN2.R
n a_3_n r\
N.AN3.R
n a_4_n r\
N.AN4.R
n a_5_n r\
N.AN5.R
n a_6_n r\
n @_1_n r\
N.EN1.R
n @_2_n r\
N.EN2.R
n @_3_n r\
N.EN3.R
n @_4_n r\
N.EN4.R
n @_5_n r\
N.EN5.R
n @_6_n r\
n A_1_N r\
N.AG1.R
n A_2_N r\
N.AG2.R
n A_3_N r\
N.AG3.R
n A_4_N r\
N.AG4.R
n A_5_N r\
N.AG5.R
n A_6_N r\
n @_1_N r\
N.EG1.R
n @_2_N r\
N.EG2.R
n @_3_N r\
N.EG3.R
n @_4_N r\
N.EG4.R
n @_5_N r\
N.EG5.R
n @_6_N r\
n_w O_1 r\
NU.O1.R
n_w O_2 r\
NU.O2.R
n_w O_3 r\
NU.O3.R
n_w O_4 r\
NU.O4.R
n_w O_5 r\
NU.O5.R
n_w O_6 r\
n_w a_1_n r\
NU.AN1.R
n_w a_2_n r\
NU.AN2.R
n_w a_3_n r\
NU.AN3.R
n_w a_4_n r\
NU.AN4.R
n_w a_5_n r\
NU.AN5.R
n_w a_6_n r\
system
1.#INF
ProcessingGraph: Unknown blocktype '
', did you forget to call 'registerBlockType'?
final
graph-output
graph-input
Block ID allready exist: 
Missing (or empty) block-type for block ID: 
Creating graph connection: 
Unknown block identifier in 'receives-from': 
No config block allowed for '
updateConfiguration called for nonexisting block id: 
receive-from
Invalid connection syntax in: 
Block has no outgoing connections: 
' can have no outgoing connections
Block has no incomming connections: 
' can have no incomming connections
 graph connectivity error(s)
Block name lookup not supported for this graph type!
Multiple inputs not supported for (legacy) block config format
Invalid block index: 
merge-style
type of merge performed
PDecTranslatorBlock
mt model file name
maximum number of active beams in pruning
as-beam
as_beam pruning value
rs-beam
rs_beam pruning value
confidence-threshold
confidence threshold
lm-model-file
path to language model file
lm-weight
language model weight
veto-factor
MT defcoding veto factor
veto-factor-exclude-input-tags
MT decoding, exclude input tags in  veto factor computation
veto-factor-num-external-input-tags
MT decoding, num externally provided tags to exclude for veto factor
norm-costs
normalize costs in mt decoding? (backward compatible version)
norm-mode
normalize costs in mt decoding? (off|length|gnmt)
norm-alpha
normalization alpha parameter
norm-sigma
normalization sigma parameter
unk-replace
max-seq-length
maximum decoding sequence length
max-seq-length-relative
maximum decoding sequence length as factor of input length
max-seq-length-floor
maximum decoding sequence length floor (used with input length factor)
lm-mode
lm mode
confidence model file
stop-mode
stop mode in mt decoding (nbeam|best|finished_score)
block-control
flow control for block sequence (<empty>|optional|optional_stop_on_success)
shortlist-lang-pair
language pair used for shortlist
shortlist-cond-n
top n in condition table used for shortlist
shortlist-freq-n
top n in freq words used for shortlist
maximum entries in nbest list to produce (default to same as 'beam'}
stop-mode-finished-score-beam
number of finished hypotheses considered for finished score stop mode (default: 1)
stream-buffer-n
stream decoding initial read length (effective read buffer)
stream-block-m
stream decoding read/write length (block size for looped read/write calls)
stream-stabilize
stabilize partial stream decoding results after each read/write block
use memory map
phrase-book-mode
phrase book mode
pron-guide-model-file
pron guide model file
pron-guide-preprocessing
pron guide preprocessing (splitting into characters and <space> insertion)
romanizer
phrasebook-case-sensitve
case sensitive phrase book?
filter-list-file
filter list file
pb-file-list
phrase book file list
maximum entries in nbest list to produce
reset-meta-info
reset metaInfo json
source-locale
source locale
target-locale
target locale
source-token
source tag for multilingual model
target-token
target tag for multilingual model
share-translation-model
share translation model
PDecPhraseBookBlock
filter-redundant-tags
flag on whether to filter out or keep hypotheses with redundant tags
tag-to-meta-json-file
a json file that contains a mapping between tags and their corresponding string in the meta info 
AlignmentProcessorBlock
source
segmentor-encode
pdec-decode
segmentor-decode
tokenized
word-level-alignments
If set to true, then the BPE level alignments are merged into word level alignments
avoid-crossing-words
If set to True, then the Alignment Processor Block expects the tokenized translations and the alignment ranges do not cross the tokenized words
AmbiguityAnnotatorBlock
disambiguation-dictionary-file
disambiguation dictionary file
max-match-length
maximum token sequence length in matching
prefer-position
prefer early match position over multiword matches
prefer-multiword
prefer longer multiword matches to shorter ones
multisense-keep
number of senses to keep when several senses match a word in a hypotheses
case-sensitive
used to disable phrase book block
filter-entries
filter to make translations unique
normalization-pattern-file
apply regular expressions from file for normalized lookup
SimpleTokenizerBlock
tokenizer-file
tokenizer regular expression replacement (sed / perl -p style)
PhraseBookBlock
InputHammerBlock
strip-token
strip tokenizer artefacts on romanizer input
SentencePieceBlock
sentence-piece-file
sentence piece model file
action
encode
action to perform (encode/decode/decode-api)
src-locale
the source locale
tgt-locale
the target locale
features
list of features
src-ovs-file
the source OVS file
tgt-ovs-file
the target OVS file
fertility-file
the fertility file
min-trans-len-percent
the minimum translation length (in percent of expected length)
max-trans-len-percent
the maximum translation length (in percent of expected length)
regex-file
the regular expression file
PDecForceAlignBlock
target
full-context
model is a full-context model (TODO: REMOVE THIS OPTIONS)
maximum entries in target nbest list to process
FilterBlock
maximum nbest list size (default: don't limit nbest size)
annotation-based-filtering
filter based on annotation in the metainfo
SelectBlock
control
value
match-key
metadata key to match on
match-pattern
metadata value match pattern
match-wildcard
wildcard string for match-pattern, that can match any subtree
locale
locale for case mapping (if not set use locale independent mapping)
capitalize-camel-case
Capitalize camel-case first tokens
exception-file
Path to file with additional exceptions that should not be capitalized
TokenizerBlock
output-tokens
control if tokenization affects the translation tokens or just meta info.
locale for tokenization (if not set use locale independent mapping)
deep copy constructor not implemented in the case of vectorized_weights.
<ParamStddev>
<LearnRateCoef>
<RandomSeed>
<InitTransformType>
<GradientNormType>
<MaxGrad>
 (ParamStddev|LearnRateCoef|InitTransformType|RandomSeed|GradientNormType|MaxGrad)
Linearity().NumRows() == mat.NumRows() && Linearity().NumCols() == mat.NumCols()
unrecognized config token 
 linearity
  linearity_grad
, lr-coef 
Unexpected mismatch in indexes: 
Unimplemented except for BaseFloat weights
Weights are already vectorized
Performing  vectorization of linear component
veccorrs->size() == linearity_corr_.size()
LinearityCorr(ic).NumRows() * LinearityCorr(ic).NumCols() == NumParams()
Done  vectorization of linear component
the multi batch gradient quantization does not work yet
Wrong quantizer type (neither 
 nor 
 ): 
Insufficient storage area: 
 needed: 
(end) <= (Bits())
/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/EmbeddedAcousticRecognition-261.8/libquasar/libkaldi/tools/openfst/src/extensions/ngram/bitmap-index.cc
You cannot call FinalizeDecoding() and then call 
GetRawLattice() with use_final_probs == false
GetRawLattice: no tokens active on frame 
: not producing lattice.
init:
 buckets:
 load:
 max:
No tokens alive [doing pruning].. warning first time only for each utterance
Negative extra_cost: 
No tokens alive at end of file
No tokens alive [doing pruning]
PruneActiveTokens: pruned tokens from 
pruned tokens from 
Error, no surviving tokens: frame is 
using RNN style LM in the decoder
v != nullptr
capacity_ > 0
am-scale
Scaling factor for acoustic likelihoods
nbest-size
number of NBest from 1st pass used for interpolation weight estimation
nnlm-nce-norm-factor-list
the normalization factor for NCE trained NNLMs, use comma to separate multiple ones
rnnlm-max-context-size
maximal context for RNN style LM, no-op for other style of LMs
big-g-fst-file-list
list of BigGrammar FST filename, use comma to separate multiple ones
big-g-nnet-file-list
list of BigGrammar NNLM filename, use comma to separate multiple ones
nnet-map-file-ext
the file extension name of the corresponding NNLM word map file
Map FST/NNLM models into memory (requires aligned models)
lattice-beam
the lattice beam for the rescored lattice
wordmap
Could not read the NNLM normalization factor info
the number of NNLM files and the number of NNLM norm factors do not match
The rescoring LM interpolation weights:
Rescoring with 
 symbol(s) for left context from 
 word(s)
Total LM cost after rescoring = 
'%c'
[character %d]
dynamic_cast<CEInferenceNet* const>(extra_nnet_) != nullptr
Backed by either TensorFlow or Espresso.
the NCE normalization factor is 
HIT vs MISS: 
lm-score 
, penultimate cache 
Compile with USE_TENSORFLOW=ON to use TensorFlow models
No ComputeEngineConfigItf for model file: 
.espresso/code.nitroir
.espresso.net
Found missing recognizer request handlers.
Initialized SyncSpeechRecognizer with config 
decodables.
frontends.
SyncSpeechRecognizer not initialized
opts_.max_steps > 0
bos_index_ >= 0 && eos_index_ >= 0
Decoding output contains BOS label (
). Mapping it to label 0.
Decoding output contains label 0. Mapping it to BOS label (
fst-phonomap-file
Phonomap file as an fst. This must be input-arc sorted
phonetic-syms-file
Symbol table file representing the phone set.
corrections.
Invalid format for boolean argument [expected true or false]: 
Use add() to append array elements
Leaves can't have children
Can't add a value dictionary-like to a tree that is already array-like
Can't add a value array-like to a tree that is already dictionary-like
nested erase() not implemented
expected value
expected key string
expected ':'
expected '}' or ','
void boost::property_tree::json_parser::detail::source<boost::property_tree::json_parser::detail::encoding<char>, std::__1::istreambuf_iterator<char, std::__1::char_traits<char> >, std::__1::istreambuf_iterator<char, std::__1::char_traits<char> > >::parse_error(const char *) [Encoding = boost::property_tree::json_parser::detail::encoding<char>, Iterator = std::__1::istreambuf_iterator<char, std::__1::char_traits<char> >, Sentinel = std::__1::istreambuf_iterator<char, std::__1::char_traits<char> >]
/System/Volumes/Data/SWE/iOS/BuildRoots/BuildRoot890/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator14.0.Internal.sdk/usr/local/include/boost/property_tree/json_parser/detail/parser.hpp
<unspecified file>
expected ']' or ','
unterminated string
invalid code sequence
invalid escape sequence
invalid codepoint, stray low surrogate
invalid codepoint, stray high surrogate
expected codepoint reference after high surrogate
expected low surrogate after high surrogate
expected 'true'
expected 'false'
expected 'null'
expected digits after -
need at least one digit after '.'
need at least one digit in exponent
garbage after data
cannot open file
void boost::property_tree::json_parser::read_json(const std::string &, Ptree &, const std::locale &) [Ptree = boost::property_tree::basic_ptree<std::__1::basic_string<char>, std::__1::basic_string<char>, std::__1::less<std::__1::basic_string<char> > >]
/System/Volumes/Data/SWE/iOS/BuildRoots/BuildRoot890/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator14.0.Internal.sdk/usr/local/include/boost/property_tree/json_parser.hpp
void boost::property_tree::json_parser::write_json(const std::string &, const Ptree &, const std::locale &, bool) [Ptree = boost::property_tree::basic_ptree<std::__1::basic_string<char>, std::__1::basic_string<char>, std::__1::less<std::__1::basic_string<char> > >]
ptree contains data that cannot be represented in JSON format
void boost::property_tree::json_parser::write_json_internal(std::basic_ostream<typename Ptree::key_type::value_type> &, const Ptree &, const std::string &, bool) [Ptree = boost::property_tree::basic_ptree<std::__1::basic_string<char>, std::__1::basic_string<char>, std::__1::less<std::__1::basic_string<char> > >]
/System/Volumes/Data/SWE/iOS/BuildRoots/BuildRoot890/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator14.0.Internal.sdk/usr/local/include/boost/property_tree/json_parser/detail/write.hpp
write error
0123456789ABCDEF
hanning
hamming
rectangular
Invalid window type 
Inconsistent setting: center=true but lookahead is set to 
Flooring variance When normalizing variance, floored 
 elements; num-frames was 
Detected latency overflow, change to int_max.
dup stat: token=
, source=
Empty tokenStrings received
Empty tokenStrings[0] received
Token=
 found in Lexicon, prons=
Skipping invalid token=
 found in PronCache
Failed to generated pronunciations for word=
in backoff window, skip updating pron cache for token 
Byte-range queried for number of codepoints seems to intersect a codepoint
Config:
Token: 
 not found in raw string input: 
Char ranges in the word char map exceeds total number of characters
Mismatch in sizes of alignment queries and projections from the first leg don't match.
alignment-queries
Json corresponding to alignment-queries cannot be parsed.
projections
AlignmentProcessorBlock::handleSourceInput() called called with empty input
AlignmentProcessorBlock::handleSourceInput() called called with multiple inputs
For alignment mapping to work properly, ensure whole string provided as first token.
Query range [
] is out of bounds.
] is illegal.
AlignmentProcessorBlock::handleSegmentEncInput() called called with empty input
AlignmentProcessorBlock::handleSegmentEncInput() called called with multiple inputs
AlignmentProcessorBlock::handlePDecInput() called with empty input
AlignmentProcessorBlock::handleSegmentDecInput() called with empty input
AlignmentProcessorBlock::handleTokenizedInput() called with empty input
size of n-best list from segment-decoder and PDec-translator are different
Tokenizer did not return same number of phrases as the Translator.
Disambiguation symbol 
 is also a phone.
Determinization aborted since passed 
 states.
max-states reached in determinization
Determinization terminated since passed 
 states, partial results will be generated.
Determinization aborted since looped more than 
 times during epsilon closure.
looped more than max-states times in determinization
DeterminizerStar: FST was not functional -> not determinizable
First string: 
Second string: 
Non-functional FST: cannot determinize.
Debug function called (probably SIGUSR1 caught).
Nothing to trace back
Traceback did not reach start state (possibly debug-code error)
Traceback below (or on standard error) in format ilabel (olabel olabel) ilabel (olabel) ...
EncodeMapper: Label-encoded arc has different input and output labels
EncodeMapper: Weight-encoded arc has non-trivial weight
EncodeMapper: decode failed
EncodeTable::Decode: unknown decode key: 
FST is not an unweighted acceptor
Acyclic Minimization
Cyclic Minimization
Weight::Properties() & kIdempotent
../libquasar/libkaldi/tools/openfst/src/include/fst/minimize.h
PrePartition
Initial Partition: 
Context FST created but there are no phone symbols: probably input FST was empty.
context
ContextFst: CreateArc, invalid olabel supplied [confusion about phone list or disambig symbols?]: 
ContextFst copying not yet supported [not hard, but would have to test.]
ContextMatcher: bad match type
TableMatcher: bad match type
final_weight.String().empty()
final_weight.Weight().Value1() == 0.0
final_weight.Weight().Value2() == 0.0
Total forward probability over lattice = 
, while total backward probability = 
Non-finite total probability in lattice (
). Numeric problems with model?
best cost = 
path len=
 mean conf=
[stack trace: ]
ivector file 
 cannot be opened
Landmark hash ark file 
imposterMean=
imposterStd=
Name of nnet file
Threshold to apply to ivector score
ivector-fingerprint-ark-file
ark file with ivectors for fingerprints
ivector-imposter-ark-file
ark file with ivectors with imposters
trigger-preceding-max-ms
Maximum amount of audio used before trigger phrase
trigger-trailing-min-ms
Minimum amount of audio used after trigger phrase
trigger-trailing-max-ms
Maximum amount of audio used after trigger phrase
trigger-num-tokens
The number of tokens in the trigger phrase (two for hey siri)
ivector-threshold
ivector-score-bias
Bias to apply to ivector score when combining with lmark
lmark-hash-strategy
Hashing strategy (e.g. 3x3)
lmark-hash-start-idx
Feature start idx for hashing
lmark-hash-end-idx
Feature end idx for hashing
lmark-hash-fingerprint-ark-file
ark file with landmark hash vectors for fingerprints
lmark-hash-imposter-ark-file
ark file with landmark hash vectors for imposters
lmark-min-len
Min num frames for computing similarity between landmark hash vectors
lmark-max-len
Max num frames for computing similarity between landmark hash vectors
lmark-threshold
Threshold to apply to landmark similarity
imposter ivector file 
 is empty
fp-ivectors=enabled
Unrecognized hash strategy string 
Landmark params not properly set
fp-landmark=enabled
Invalid fbank dims. 
Expected: 
 Got: 
Encountered zero iVector
Speaker embedding=
Index=
 similarity=
 exceeded threshold=
Did not match any known fingerprints
Trigger phrase not detected
Not enough audio to make a decision.
Hash strategy 
 is not implemented
Landmark hash=
] Unnormalized landmark hash score: 
] T-normalized landmark hash score: 
FingerprintDetector not run on input origin 
Error: Utterance features were improperly cached.
Zero-length utterance. Rejecting utterance.
Error: getAudioProcessingWindow failed
Processed Frames: 
Best i-vector match score=
 index=
Adjusted i-vector score=
 thres=
FingerprintAlgo
FingerprintIndex
FingerprintScore
FingerprintDetected
FingerprintDetected=
 MatchingIndex=
 matchingScore=
num-ceps
Number of cepstra in MFCC computation (including C0)
use-energy
Use energy (not C0) in MFCC computation
energy-floor
Floor on energy (absolute, not relative) in MFCC computation
raw-energy
If true, compute energy before preemphasis and windowing
cepstral-lifter
Constant that controls scaling of MFCCs
htk-compat
If true, put energy or C0 last and use a factor of sqrt(2) on C0.  Warning: not sufficient to get HTK compatible features (need to change other parameters).
sample-frequency
Waveform data sample frequency (must match the waveform file, if specified there)
frame-length
Frame length in milliseconds
frame-shift
Frame shift in milliseconds
preemphasis-coefficient
Coefficient for use in signal preemphasis
remove-dc-offset
Subtract mean from waveform on each frame
dither
Dithering constant (0.0 means no dither)
window-type
Type of window ("hamming"|"hanning"|"povey"|"rectangular")
round-to-power-of-two
If true, round window size to power of two.
snip-edges
If true, end effects will be handled by outputting only frames that completely fit in the file, and the number of frames depends on the frame-length.  If false, the number of frames depends only on the frame-shift, and we reflect the data at the ends.
num-mel-bins
Number of triangular mel-frequency bins
low-freq
Low cutoff frequency for mel bins
high-freq
High cutoff frequency for mel bins (if < 0, offset from Nyquist)
vtln-low
Low inflection point in piecewise linear VTLN warping function
vtln-high
High inflection point in piecewise linear VTLN warping function (if negative, offset from high-mel-freq
debug-mel
Print out debugging information for mel bin computation
cmn-window
Window in frames for running average CMN computation
min-cmn-window
Minimum CMN window used at start of decoding (adds latency only at start). Only applicable if center == false, ignored otherwise.
norm-vars
If true, normalize variance to one.
center
If true, use a window centered on the current frame (to the extent possible, modulo end effects). If false, window is set based on "cmn-window" and "lookahead".
lookahead
Number of frames to look ahead for online CMN. Ignored if center==true.
SequentialTableReader<Holder>::Open(), could not close previously open object.
Invalid rspecifier 
Trying to use empty SequentialTableReader (perhaps you 
passed the empty string as an argument to a program?)
TableReader::Open, error closing previous input (only warning, since permissive mode).
TableReader::Open, error closing previous input.
TableReader: failed to open stream 
TableReader: error beginning to read table (wrong filename?): 
Done() called on TableReader object at the wrong time.
IsOpen() called on invalid object.
Key() called on TableReader object at the wrong time.
Value() called on TableReader object at the wrong time.
KaldiObjectHolder::Value() called wrongly.
TableReader: FreeCurernt called at the wrong time.
TableReader: Next() called wrongly.
Error reading archive 
Invalid archive file format: expected space after key 
, got character 
, reading 
Object read failed, reading archive 
Reading Table object, failed reading binary header
Exception caught reading Table object 
Close() called on TableReader twice or otherwise wrongly.
Error detected closing TableReader for archive 
 but ignoring 
it as permissive mode specified.
TableReader: reading archive failed: 
TableReader::Open, error closing previous input 
Failed to open script file 
TableReader: failed to load object from 
 (to suppress this error, add the permissive 
(p, ) option to the rspecifier.
TableReader: you called Value() after FreeCurrent().
TableReader: Value() called at the wrong time.
TableReader: LoadCurrent() called at the wrong time.
TableReader: failed to open file 
TableReader: FreeCurrent called at the wrong time.
SequentialTableReader, reading script file: Next called wrongly.
Close() called on input that was not open.
Close() called on scp file with read error, ignoring the error because permissive mode specified.
TableReader: reading script file failed: from scp 
empty CTC keyword
<EncoderInput>
<DecoderParentIds>
<DecoderInput>
<DecoderCheck>
<DecoderSuccess>
<DecoderOutput>
<DecoderAttention>
<Encode>
<Reset>
<InputShapeTemplate>
<FrameSubsamplingFactor>
<BOSIndex>
<EOSIndex>
<SilIndex>
<Beam>
Input shape template [
] must include the R and C tokens.
] includes multiple R tokens.
] includes multiple C tokens.
] includes tokens other than R, C and 1.
] must include the R token.
] must include the C token.
in->GetNumDims() == input_shape_template_.ndim
in->GetDimSize(input_shape_template_.col_index) == InputDim()
num_elements % num_rows == 0
encoder_input
decoder_parent_ids
decoder_input
decoder_output
decoder_attention
reset
Attempt to write into immutable matrix
Too many rows*cols for 8-bit Matrix
Quantized matrix improperly serialized
unimplemented
New stride (
) must not be smaller than
 the current stride (
) must be a multiple of 
current stride (
Non matching dimensions: Rows:
 VectorDim:
Non matching dimensions: Cols:
matrix A and B can not be transposed at the same time, not implemented yet
Memory allocation failed when initializing CuVector 
with dimension 
 object size in bytes: 
word-syms-file
word symbol table text format filename
HCLG FST filename
Could not read symbol table from text file 
/sil_S/
/sil_B/
/sil_I/
/sil_E/
Problem decoding utterance.
FINAL RESULT:
Result Choice[
Pronounciation Choice[
SymbolTable::ReadText: Can't open file 
update-interval
Beam update interval in frames
beam-update
Beam update rate
max-beam-update
Max beam update rate
inter-utt-sil
Maximum # of silence frames to trigger new utterance
max-utt-sil
Maximum # of silence frames to trigger end of speech while no speech presented
max-utt-length
If the utterance becomes longer than this number of frames, shorter silence is acceptable as an utterance separator
det-max-mem
Maximum approximate memory usage in determinization (real usage might be many times this)
det-max-loop
Option used to detect a particular type of determinization failure, typically due to invalid input (e.g., negative-cost loops)
Decoding beam.
Decoder max active states.
min-active
Decoder minimum #active states.
Lattice generation beam
prune-interval
Interval (in frames) at which to prune tokens
determinize-lattice
If true, determinize the lattice (in a special sense, keeping only best pdf-sequence for each word-sequence).
Increment used in decoding-- this parameter is obscure and relates to a speedup in the way the max-active constraint is applied.  Larger is more accurate.
Setting used in decoder to control hash behavior
word-ins-penalty
Word insertion penalty applied to each word
delta
Tolerance used in determinization
max-mem
Maximum approximate memory usage in determinization (real usage might be many times this).
phone-determinize
If true, do an initial pass of determinization on both phones and words (see also --word-determinize)
word-determinize
If true, do a second pass of determinization on words only (see also --phone-determinize)
minimize
If true, push and minimize after determinization.
Could not topologically sort lattice: this probably means it has bad properties e.g. epsilon cycles.  Your LM or lexicon might be broken, e.g. LM with epsilon cycles or lexicon with empty words.
determinization did not succeed(partial output will be pruned tighter than the specified beam.)
UTF8StringToLabels: continuation byte as lead byte
UTF8StringToLabels: truncated utf-8 byte sequence
UTF8StringToLabels: missing/invalid continuation byte
UTF8StringToLabels: Invalid character found: 
StringCompiler::ConvertSymbolToLabel: Symbol "
" is not mapped to any integer label, symbol table = 
StringCompiler::ConvertSymbolToLabel: Bad label integer 
Union: input/output symbol tables of 1st argument 
do not match input/output symbol tables of 2nd argument
Beam: 
; Speed: 
 xRT
Changed confidence for slot=
1best: 
phrase=
 orig: 
 new: 
Unsupported n-best index configuration
n-best output size is wrong
am-file
Acoustic model (transition model) filename
Decoding beam
first-pass-lattice-beam
First pass lattice beam
Decoding lattice beam
retry-beam
Fall-back decoding beam
HCP FST filename
tree-file
Tree file
phone-map-file
Phone mappings file
Conversion of alignments in lattice is only supported for models with context width = 1, other models will result in alignments which do not properly consider cross-word contexts
Problem decoding utterance for re-alignment.
Determinization finished earlier than the beam
kaldi::OnlineDecodableNnet1Lazy is required at this point in the first pass with configured realign-model parameter.
opts_.beam > 0
Input dimension of parallel component and input dimensions of nested networks do not match.
Output dimension of parallel component and output dimensions of nested networks do not match.
No limiting of nbest output size
Invalid value for nbest option!
limiting n-best size to 
using metainfo annotation to filter nbest
simple nbest size limiting
senses
sending 
 alternatives without limiting
 alternatives, limiting (original n-best: 
 alternatives, too few to limit
no hypotheses, sending empty list of hypotheses
only one hypothesis, sending it
1-best hypothesis is low confidence, sending only this hypothesis
1-best hypothesis has no ambiguity annotation, sending only this hypothesis
no ambiguity found: 
 alternative(s)
ambiguity found: 
 alternatives
The number of recognition request parameters is 
 (requirement is 3)
 (requirement is 5 for config file ver 15.0+)
Illegal char '*' found in task type 
Illegal char '*' found in device type 
farField type must be '*', 'true', or 'false': 
Illegal char '*' found in bluetooth device id 
Could not find the recognizer components for the params samplingRate=
 task=
 device=
 farField=
 bluetoothDeviceId=
Could not make Unicode regex: 
Could not open BreakIterator: 
<NumCells>
<BiasMean>
<BiasRange>
<ForgetGateBiasMean>
<ForgetGateBiasRange>
<ProjectionLearnRateCoef>
<MaxNorm>
<MaxCell>
<NoPeep>
<OutputCellValues>
Invalid token 
. Allowed tokens: 
(NumCells|BiasMean|BiasRange|ForgetGateBiasMean|ForgetGateBiasRange|ParamStddev|LearnRateCoef|ProjectionLearnRateCoef|MaxNorm|
MaxGrad|MaxCell|NoPeep|InitTransformType|GradientNormType|RandomSeed)
bias_ thought to be initialized here
# LSTM cells (
) should not be less than output dim (
input_weights_ thougth to be un-initialized here
recurrent_weights_ thougth to be un-initialized here
peephole_weights_ thougth to be un-initialized here
bias_ thougth to be un-initialized here
projection_weights_ thougth to be un-initialized here
 Input weights:
 Recurrent weights:
 Bias:
 Forget gate bias:
 Peephole weights:
 Projection weights:
  Gradients are uninitialized
 For batch 
  Number of cells : 
  Input weights gradient: 
  Recurrent weights gradient: 
  Bias gradient: 
  Peephole weights gradient: 
  Projection weights gradient: 
  Gates values: 
  Cell values: 
  Cell outputs: 
  Cell outputs gated: 
  Output values: 
  Gates diff: 
  Cell diff: 
  Cell out gated diff: 
  Output diff: 
Accumulating gradients for batch id = 
Reset previous states for utts 
input_weights_
recurrent_weights_
peephole_weights_
projection_weights_
input_weights_gradient_.size() > ib
input_weights_gradient_[ib]
recurrent_weights_gradient_.size() > ib
recurrent_weights_gradient_[ib]
bias_gradient_.size() > ib
bias_gradient_[ib]
has_peepholes_
peephole_weights_gradient_.size() > ib
peephole_weights_gradient_[ib]
has_projection_layer_
projection_weights_gradient_.size() > ib
projection_weights_gradient_[ib]
input_weights_ thought to be un-initialized here
recurrent_weights_ thought to be un-initialized here
bias_ thought to be un-initialized here
peephole_weights_ thought to be un-initialized here
projection_weights_ thought to be un-initialized here
Allocated memory for the parameters: 
Allocating forward buffers for batch 
; batch size = 
Allocating backward buffers for batch 
input_weights_gradient_.size() == 0
recurrent_weights_gradient_.size() == 0
bias_gradient_.size() == 0
peephole_weights_gradient_.size() == 0
projection_weights_gradient_.size() == 0
Allocated memory for the gradients: 
Saving last output and cell state for batch 
Input weights #rows = 
; expecting 
; #cells = 
Input weights #columns = 
 (same as input dim)
Recurrent weights #rows = 
Recurrent weights #columns = 
 (same as output dim)
Peephole weights #rows = 
Peephole weights #columns = 
 (same as #cells)
Bias dim = 
Projection weights #rows = 
Projection weights #columns = 
learn_rate_coeff_ must not be negative; found: 
projection_learn_rate_coeff_ must not be negative; found: 
max_norm_ must not be negative; found: 
max_grad_ must not be negative; found: 
max_cell_values_ must not be negative; found: 
Performing  vectorization of lstm component
gradients_valid_ is thought to be false here
input_weights_gradient_[ic]->NumRows() == InputWeights().NumRows() && input_weights_gradient_[ic]->NumCols() == InputWeights().NumCols()
recurrent_weights_gradient_[ic]->NumRows() == RecurrentWeights().NumRows() && recurrent_weights_gradient_[ic]->NumCols() == RecurrentWeights().NumCols()
bias_gradient_[ic]->Dim() == Bias().Dim()
peephole_weights_gradient_[ic]->NumRows() == PeepholeWeights().NumRows() && peephole_weights_gradient_[ic]->NumCols() == PeepholeWeights().NumCols()
projection_weights_gradient_[ic]->NumRows() == ProjectionWeights().NumRows() && projection_weights_gradient_[ic]->NumCols() == ProjectionWeights().NumCols()
Done vectorization of lstm component
Must first call init() for 
 before calling createDecodable().
Building Decodable 
Unknown decodable type "
matrix-scaled
matrix-scaled-mapped
matrix-scaled-mapped-tm
ctc-online-kwd
dummy
nnet1-lazy
Acoustic model (transition model) filename (only used for lattice stuff)
tid2pdf-file
Text file of ints representing PDF IDs for transition IDs 0, 1, 2, ... 
Read transModel
Using TID2PDF file
Created OnlineDecodableMatrixScaled decodable
decodable type "
Created OnlineDecodableMatrixScaledMapped decodable
OnlineDecodableMatrixScaledMapped: mismatch, matrix has 
 rows but transition-model has 
 pdf-ids.
tm-weight
Weight factor for tm likelihoods
Created OnlineDecodableMatrixScaledMappedTm decodable
Created OnlineDecodableIdenticalMatrix decodable
class-frame-counts-file
File containing vector with frame-counts of pdfs to compute log-priors. This is the same as class-frame-counts, but allows paths that are relative to the json config file (class-frame-counts requires absolute paths). If class-frame-counts is also specified, this param will override it.
Name of nnet model file
File for feature transform in front of nnet's main network (in nnet format)
skip-frames
Number of frames to be skipped in nnet computation.
use-gpu-id
Unused, kaldi is compiled w/o CUDA
silence-model-file
Name of nnet model file for computing silence posteriors
compute-sil-model-posteriors-from-realign-model
True if penultimate activations from realign model are the input to the silence model, otherwise use the penultimate activations from the main acoustic model
workspace-size-kb
Workspace size in Kilo Bytes
realign-model-file
Name of nnet model file for computing posteriors for later realignment of 1st/2nd pass lattices
realign-class-frame-counts-file
File containing vector with frame counts of pdfs to compute log-priors. This is the same as class-frame-counts, but allows paths that are relative to the json config file (class-frame-counts requires absolute paths). If class-frame-counts is also specified, this param will override it.
compute-realign-model-posteriors-from-penultimate
True if penultimate activations from main acoustic model are the input to the realignment model, otherwise use the same features as the main acoustic model as input
skip-blanks-threshold
Threshold for skipping frames with a CTC trained acoustic model, applied to posterior probability of the blank symbol
blank-pdf-id
Pdf-id of blank symbol of CTC trained acoustic model, used in combination with skip-blanks-threshold
skip-across-batch
Make skip-frames deterministic by skipping across batches instead of within batches (default: false).
class-frame-counts
Vector with frame-counts of pdfs to compute log-priors. (priors are typically subtracted from log-posteriors or pre-softmax activations)
prior-scale
Scaling factor to be applied on pdf-log-priors
prior-cutoff
Classes with priors lower than cutoff will have 0 likelihood
Read mapped nnetTransf
Read nnetTransf
Read pdfPrior
Read model file for computing silence posteriors=
Read model file for computing realignment posteriors=
Created OnlineDecodableNnet1LazyDecodable decodable
Skipping 
 frames may not give you good results.
Parameters realign_model_input_is_penultimate_ and sil_model_input_is_realign_penultimate_ cannot both be true at the same time.
Realignment model (nnet_realign) must be set in order to pass its penultimate activations to the silence model.
skip_across_batch cannot be set if you aren't frame skipping
skip_across_batch does not work with skip_blanks_threshold or nnet_realign
nnet transformation contains splicing, which is not 
supported by OnlineDecodableNnet1Lazy. Use a separate splice 
operation to perform splicing.
nnet contains splicing, which is not supported by 
OnlineDecodableNnet1Lazy. Use a separate splice operation to 
perform splicing.
Failed to compile unicode outliers regex
sanitized string is empty
Pruned state-level lattice with beam 
 and retrying determinization with that beam.
Effective beam 
 was less than beam 
 * cutoff 
, pruning raw 
lattice with new beam 
 and retrying.
Both --phone-determinize and --word-determinize are set to 
false, copying lattice without determinization.
Doing first pass of determinization on phone + word 
lattices.
Doing second pass of determinization on word lattices.
Pushing and minimizing on word lattices.
Topological sorting of state-level lattice failed (probably
 your lexicon has empty words or your LM has epsilon cycles
Lattice determinization terminated but not 
 because of lattice-beam.  (#states, #arcs) is ( 
 ), versus limits ( 
 ) (else, may be memory limit).
Total weight of input lattice is zero.
Lattice determinization aborted since looped more than 
Cost below best cost was encountered:
Rebuilt repository in determinize-lattice: repository shrank from 
 bytes (approximately)
Did not reach requested beam in determinize-lattice: 
size exceeds maximum 
 bytes; (repo,arcs,elems) = (
), after rebuilding, repo size was 
, effective beam was 
 vs. requested beam 
Rebuilding repository.
empty subset
Zero weight!
New cost is less (check the difference is small) 
LDContext
T{LDContext={map<quasar::Locale, double, std::__1::less<quasar::Locale>, std::__1::allocator<std::__1::pair<const quasar::Locale, double> > >={__tree<std::__1::__value_type<quasar::Locale, double>, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true>, std::__1::allocator<std::__1::__value_type<quasar::Locale, double> > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<quasar::Locale, double>, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true> >=Q}}}{optional<std::__1::set<quasar::Locale, std::__1::less<quasar::Locale>, std::__1::allocator<quasar::Locale> > >=(?=c{set<quasar::Locale, std::__1::less<quasar::Locale>, std::__1::allocator<quasar::Locale> >={__tree<quasar::Locale, std::__1::less<quasar::Locale>, std::__1::allocator<quasar::Locale> >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<quasar::Locale, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::less<quasar::Locale> >=Q}}})B}{optional<quasar::Locale>=(?=c{Locale={basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}})B}{optional<bool>=(?=cB)B}{optional<std::__1::vector<quasar::Locale, std::__1::allocator<quasar::Locale> > >=(?=c{vector<quasar::Locale, std::__1::allocator<quasar::Locale> >=^{Locale}^{Locale}{__compressed_pair<quasar::Locale *, std::__1::allocator<quasar::Locale> >=^{Locale}}})B}{optional<std::__1::map<quasar::Locale, double, std::__1::less<quasar::Locale>, std::__1::allocator<std::__1::pair<const quasar::Locale, double> > > >=(?=c{map<quasar::Locale, double, std::__1::less<quasar::Locale>, std::__1::allocator<std::__1::pair<const quasar::Locale, double> > >={__tree<std::__1::__value_type<quasar::Locale, double>, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true>, std::__1::allocator<std::__1::__value_type<quasar::Locale, double> > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<quasar::Locale, double>, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true> >=Q}}})B}{optional<std::__1::map<quasar::Locale, double, std::__1::less<quasar::Locale>, std::__1::allocator<std::__1::pair<const quasar::Locale, double> > > >=(?=c{map<quasar::Locale, double, std::__1::less<quasar::Locale>, std::__1::allocator<std::__1::pair<const quasar::Locale, double> > >={__tree<std::__1::__value_type<quasar::Locale, double>, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true>, std::__1::allocator<std::__1::__value_type<quasar::Locale, double> > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<quasar::Locale, double>, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true> >=Q}}})B}{optional<quasar::Locale>=(?=c{Locale={basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}})B}{optional<quasar::Locale>=(?=c{Locale={basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}})B}{optional<std::__1::map<quasar::Locale, double, std::__1::less<quasar::Locale>, std::__1::allocator<std::__1::pair<const quasar::Locale, double> > > >=(?=c{map<quasar::Locale, double, std::__1::less<quasar::Locale>, std::__1::allocator<std::__1::pair<const quasar::Locale, double> > >={__tree<std::__1::__value_type<quasar::Locale, double>, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true>, std::__1::allocator<std::__1::__value_type<quasar::Locale, double> > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<quasar::Locale, double>, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true> >=Q}}})B}},R
languagePriors
T@"NSDictionary",C,N,V_languagePriors
dictationLanguages
T@"NSSet",C,N,V_dictationLanguages
currentDictationLanguage
T@"NSString",C,N,V_currentDictationLanguage
wasLanguageToggled
T@"NSNumber",C,N,V_wasLanguageToggled
multilingualKeyboardLanguages
T@"NSArray",C,N,V_multilingualKeyboardLanguages
keyboardConvoLanguagePriors
T@"NSDictionary",C,N,V_keyboardConvoLanguagePriors
keyboardGlobalLanguagePriors
T@"NSDictionary",C,N,V_keyboardGlobalLanguagePriors
previousMessageLanguage
T@"NSString",C,N,V_previousMessageLanguage
globalLastKeyboardUsed
T@"NSString",C,N,V_globalLastKeyboardUsed
dictationLanguagePriors
T@"NSDictionary",C,N,V_dictationLanguagePriors
recentMessages
T@"NSArray",C,N,V_recentMessages
v32@?0@8@16^B24
Invalid or out-of-range hex value
Found token separator char in token: "
Found unassigned code point 
 in string "
Unicode normalization failed for:
Input string is not Unicode normalized:
Found illegal char with value 
~U is not followed by 8 hex digits
~U is not followed by a valid unloggly code point
~w is not followed by 2 hex digits
~w followed by hexValue=
Encountered invalid tilde char: 
Unicode normalization failed for :
Illegal occurrence of ^ in HatText token 
Illegal use of ^ followed by value 
 in HatText token 
Conversion failed for qsr token 
Illegal occurrence of ~U in QsrText token 
Illegal occurrence of ~w in QsrText token 
Unsupported occurrence of ~w in QsrText token 
Illegal use of ~ in QsrText token 
Illegal occurrence of ~U in QsrText string 
Illegal occurrence of ~w in QsrText string 
Unsupported occurrence of ~w in QsrText string 
Illegal use of ~ in QsrText string 
) -> 
Failed to encode srcToken="
" dstToken="
u_strFromUTF8() failed with error=
Unicode NFC normalization failed.
u_strToUTF8() failed with error=
pre = "
post = "
map = 
<InFeatureMaps>
<OutFeatureMaps>
<PatchStep>
<SectionStep>
<SectionSize>
<FilterSize>
<InSharedBands>
<PoolSize>
<PoolStep>
<BiasLearnRateCoef>
 (ParamStddev|BiasMean|BiasRange|InFeatureMaps|OutFeatureMaps|PatchStep|SectionStep|SectionSize|FilterSize|LearnRateCoef|BiasLearnRateCoef|MaxNorm|RandomSeed)
ConvolutionalMaxPoolingComponent: Invalid max pooling size
ConvolutionalMaxPoolingComponent: Max pooling step must be >= 1
ConvolutionalMaxPoolingComponent: output dim mismatch
ConvolutionalMaxPoolingComponent: input dim mismatch
ConvolutionalMaxPoolingComponent: too few input bands to compute the output
pointer is thought to be un-initialized here
<Filters>
<Bias>
  filters
  filters_grad
, max-norm 
  bias_grad
 , # of sections: 
, section size after pooling: 
Backpropagation of CNN ConvolutionalMaxPoolingComponent is not supported for quantized weights
Not supported for quantized weights
Unimplemented
Backpropagation of CNN ConvolutionalMaxPoolingComponent is not supported on CPU
ConvolutionalMaxPoolingComponent::AccumGradients can't be called before ConvolutionalMaxPoolingComponent::Backpropagate
Performing vectorization of convolutional maxpooling component
(nlinparams + Bias().Dim()) == NumParams()
veccorrs->size() == filters_grad_.size() && veccorrs->size() == bias_grad_.size()
(filters_grad_[ic]->NumRows() * filters_grad_[ic]->NumCols() + bias_grad_[ic]->Dim()) == NumParams()
Done  vectorization of convolutional maxpooling component
<NumBands>
 (NumBands)
NumBands should be > 0
Invalid NumBands value
 CnnRearrange 
<PrePadding>
<PostPadding>
<Postamble>
<PadValue>
Invalid pre and post padding sizes
Invalid postamble size
 PaddingComponent 
<FmapXLen>
<FmapYLen>
<PadTop>
<PadBottom>
<PadLeft>
<PadRight>
h > 0 && w > 0
num_to_trim_h < h
num_to_trim_w < w
input_dim_ % (h * w) == 0
output_dim_ % (out_h * out_w) == 0
c == out_c
Config file must be loaded before calling this method.
File 
 not found.
remove child: 
override config version << 
 is incompatible with main config version: 
override config type << 
 is not the same as main config type: 
model-info.version
override config language [
] is not the same as main config langauge [
We only support override of speech model.
This method can be called only once throughout the lifetime of this object.
Reading json file 
Config override: 
Set json config file path to 
failed to parse json file 
, error: 
version-major
version-minor
Config file version is missing. 
Reading version 
 as 15.0
Version of currently loaded config file: 
 Supported config file version: 
 (minimum supported version: 
Config file version 
 is lower than the minimum supported version 
 is higher than the supported version 
 is lower than the current supported version 
). Please update the config file ASAP.
Config file does not have speech model-info node.
Config file does not have mt-model-info node.
Config file does not have model-info node.
model-info
mt-model-info
Only one of model-info and mt-model-info can exist in the config
model-info.language
model-info.os-types
Empty model-info.os-types
model-info.sampling-rates
Empty model-info.sampling-rates
model-info.tasks
Empty model-info.tasks
model-info.phoneset-version
model-info.acoustic-profile-version
lme-create.template-map
ACE category name 
 occurs twice in lme-create.template-map
lme-create.name-enumerator-map
Quasar template name 
 occurs twice in lme-create.name-enumerator-map
type
g2p.model-version
model-info.hybrid-endpointer-version
Error parsing model-info 
mt-model-info.version
mt-model-info.source-language
mt-model-info.target-language
mt-model-info.language-pairs
invalid language pair: 
mt-model-info.tasks
'mt-model-info.tasks' must be dictionary of task specific language pair lists, when no global language pair(s) provided
task specific language pair lists require minimum config version 
language-pairs
no 'language-pairs' section in task section '
Non source and target language pair.
Empty mt-model-info.tasks
missing decoder config for task 
language-pair-specific-settings
invalid language pair name: 
missing specific setting, this should not happen.
source language 
 using 
' tokenizer.
target language 
Error parsing mt-model-info 
hybrid-client-configs
hybrid-client-configs.hybrid-ep-thresholds
hybrid-client-configs.hybrid-ep-extra-delay-frequency
%s : %s
%s : %d
%s : %f
parameter [
] is not in original config.
] is not a leaf node.
-file
nt-fsts.\NT-bizname
g2p-blacklist
-directory
-ark-file
ark:
-file-list
rule-fst
Could not find required name "
Parameter "
" requires minimum version 
 but config version is 
" requires maximum version 
Ignoring unrecognized option 
Required parameter "
" not found
Prefix must end with '.' : 
Incompatible system config version. Needs to be >= 
 to use 
Incompatible system config version. Needs to be <= 
Invalid integer option "
Invalid floating-point option "
Parameter name 
 already registered
boost::bad_format_string: format-string is ill-formed
boost::too_many_args: format-string referred to fewer arguments than were passed
boost::too_few_args: format-string referred to more arguments than were passed
VersionUnsupported: 
result-combiner
result-combiner.
1.0,1.0
compute-conf
Whether to use existing confidence or re-compute a score from the tokens, default = true.
nbest-depth
The maximum number of alternatives to allow in the combined output, default = 10.
system-weights
A comma-separated list of weights to apply to each system, in the same order as the provided system input, default is 1.0,1.0.
contact-first@contact-middle@contact-last@appname-first@appname-last,contact-first@contact-middle@contact-last@appname-first@appname-last
backbone-system
The index of the system to use as the reference/backbone system. This is the default system, and the one which is used for alignment.
eps-backbone
The epsilon confidence score for epsilons inserted into the backbone.
eps-alternative
The epsilon confidence score for epsilons inserted into the alternative systems.
do-selection
Switch to control whether to do system selection or combination, default is 'true' (i.e. do selection only).
combine-any-region
Switch to control whether, if regions are specified, to do region combination within the entire utterance, if the region exists at all in the two CNs.
combine-in-region-only
Switch to control whether, if regions are specified, to do region combination only in slots where the region exists.
confidence-delta
The delta by which the competing systems must be better than the backbone in order to be considered better.
region-list
List of regional terminals to mach for use for system combination (works with region-combine options). Comma-separated for each system, and @-separated for each region within a system (e.g. contact-first@appname-first,contact-last).
do-flatten
Switch to control whether to flatten the confusion network such that only a 1-best combination/selection is performed.
do-partial-merge
Switch to control whether to allow merging a partial hypothesis with a longer one before doign selection.
max-partial-shift
The amount of jitter or shift to allow when deciding whether to merge a longer hypothesis with a partial one.
truncation-delta-milliseconds
Skip system combination if (backbone speech end - competing speech end) >= this value. Value can be positive or negative. This prevents truncation if the CN being combined with is too short. By default, we don't enable this check, value = huge number.
Could not read system weight info
Number of systems is 
System 
 Number of alternatives is 
Alternative = 
Final alternatives list:
DECODER OPTION in slot 
 word 
 score = 
 phoneSeq 
CONSENSUS in slot 
 selected word 
End time of competing confusion network is 
ConfusionNetworkMerge: Backbone word starts at the same time as the end of the competing CN. Merge starting at 
ConfusionNetworkMerge: Exceeded the maximum allowable shift amount (
) with 
 won't try to merge anymore.
ConfusionNetworkMerge: Backbone word starts before the end of the competing CN, ends after and covers more audio. Merge starting at 
ConfusionNetworkMerge: We have exceeded the maximum allowable shift amount (
 we won't try to merge anymore.
ConfusionNetworkMerge: Backbone word starts after end of the competing CN, and haven't started merging yet, and the word doesn't start too long after. Merge starting at 
Merging the word/words in slot 
 onto the end of the competing confusion network
Found a region of interest in the confusion network
Could not find a region of interest in the confusion network
BestConfidence is 
Competing Confidence for system 
 is 
Best system End Time is 
End time for competing system 
Competing system does not cover enough speech (max truncation is 
 ,current truncation is 
Exiting selection logic
Proceeding with selection logic using merged partial confusion network
Switching selected system from 
 new score = 
 old score = 
Selected system is 
FINAL HYPOTHESIS IS  : 
text=
 tokens=[
DecodableMatrixScaledMapped: mismatch, matrix has 
length-penalty
if >= 0, use this value as length penalty weight. Default means using the default in the graph
mmapped-graph
is it a memory mapped graph?
num-inter-op-threads
The maximum number of threads for inter ops in TF graph
num-intra-op-threads
The maximum number of threads for intra ops in TF graph
default-device
TF default device
allow-soft-placement
TF allow soft placement
log-device-placement
TF log device placement
profiling-granularity
Level of profiling (higher means more precise breakdown per operation)
model-config-file
The config file for the model
model-config-binary
is the config file binary?
model-config-end-token
The config file's end token
number of frames in each batch
pad-size
if the whole audio is too short, pad to this length
model-beam
the beam size used in the model
time-reduction-factor
source sequence length reduction factor in the model
max-decode-length
the maximum number of decoding steps
coverage-penalty
if > 0, use this value as the coverage penalty.
utt-end-beam
if > 0, use this beam at the utterance end.
split
 tokens active.
call to empty boost::function
illegal count weight or 
line too long?
phrase-length-limit
max-num-enumerations
tag-sequences
we should have allocated enough space, instead we get in 
this expensive copy/resize on GPU. buffer size 
 , current end 
 , incoming data size 
read
AlignInput: can't determine stream position
AlignOutput: can't determine stream position
FstHeader::Read: Bad FST header: 
FstHeader::Read: read failed: 
Unknown file read mode 
Invalid UTF8 string:
Could not extract UTF8 length: 
Could not extract UTF8 chars: 
Regex compilation failed for:
Failed to initialize regex: 
Could not set regext text: 
Could not create space text: 
Error getting capacity for splitting text: 
Could not set regex text: 
Could not set region: 
Could not trim: 
Could not create input text: 
Could not create to text: 
Could not replace text with regex: 
Could not get utf-8 string: 
) Could not decode UTF8: 
) Could not set regex input: 
) Failed to apply regex: 
Could not extract UTF16 length: 
Could not extract UTF16 chars: 
BreakIterator construction failed: 
Error writing compressed matrix to stream.
Reading aligned matrix as a stream
Expected token 
. This could mean that you're trying to memory map an unaligned file.
Seeking for aligned data failed
Failed to read header
Failed to read data.
AddSrcBos
Unknown label not described in the model
no symbol 
Decoder hit max sentence length : 
<UnkMode>
<UnkToken>
<Version>
<NumBpe>
Expected to read number of BPE units now, but got 
BPE model version: 
# of BPE model entries : 
 # of chars 
BPE model unk mode = 
, unk token = 
keep
char2unk
word2unk
dropchar
dropword
Unknown unk mode : 
Wrong number of fields, ignoring : 
Unknown BPE unknown mode
 diff 
NoGradNorm
token
T@"NSString",C,N,V_token
T@"NSArray",C,N,V_pronunciations
 correctedUtterances=%@
correctedUtterances
T@"NSArray",R,C,N,V_correctedUtterances
Input symbol id 
 missing from target vocabulary
Output symbol id 
Building NameEnumerator 
simple
raw-copy
exhaustive
regex
derived
Unknown NameEnumerator "
prefilter input
<DNFList>
Skipping tag 
Input hammer has 
 known entries it will remove
Add tag 
 to pass lists
Not configured for locale : 
 on line 
Input hammer has DNF 
 known entries across 
 locales it will leave in place
RemoveUnderScores = 
, StripTokenLocales = 
, # of entries 
</DNFList>
<RemoveUnderScores>
<StripTokenLocales>
Locale not in pass list 
Input hammer did not change anything 
Input hammer removed tags 
Lattice word alignment failed. Cannot obtain word hyp lattice.
Empty word-aligned lattice. Cannot obtain word hyp lattice.
Could not load general voc
Sdapi has errored. Dying.
Could not tokenize
Could not get info from tokenized result
Failed TPToken_GetResultData with error code : 
Failed TPToken_DeleteResult with error code : 
No starting states!
Unsupported storage type 
Must have at least 3 mel bins
Bad values in options: low-freq 
 and high-freq 
 vs. nyquist 
Bad values in options: vtln-low 
 and vtln-high 
, versus 
low-freq 
Invalid indexing. You may have set --num-mel-bins too large.
bin 
, offset = 
, vec = 
MEL BANKS:
error: %s
memory error: %s
Initialized profile service failed 
Initialization of profile service succeeded 
Initialization of textproc failed 
Initialization of textproc succeeded 
Loading of general voc failed for voc=
, svc=
 with value=
Loading succeeded for voc=
 and svc=
Loaded CP1252 voc
Loaded UTF8 voc
locale: 
modelVersion: 
languageId: 
emptyDeltaVoc: 
pgVoc: 
generalVoc: 
paramsetHolder: 
generalVocTP: 
generalSvcTP: 
lexiconTP: 
staticTokenTP: 
staticItnTP: 
NcsDatapackManager loaded locale 
Error: Voc does not contain the tokencoll collation table
oh no:
 gave us 
Could not open lexicon
Could not open ITN
Could not do TPToken_Open
com.apple.siri
sdapi
SDhAdapter
SDAdaptAlignment
SDAdaptMethod
SDAdaptResultCode
SDhAdaptAccumResult
SDhAdaptApplyResult
SDAdapterInfo
SDAdaptConfigAndStatsItem
SDAdaptAccumResultInfo
SDAdaptApplyResultInfo
SDhChannel
SDChannelType
SDChannelResultCode
SDChannelFileFormat
SDExtChanDataType
SDWaveEncodingType
SDSignalFormat
SDChannelInfo
SDExtChanServerEventResult
SDExtChanServerEventType
SDExtChanServerEventSink
SDExtChanClientEventType
SDExtChanClientEventSource
SDExternalChannel
SDhColl
SDhCorpus
SDhCorpusWord
SDCorpusDocumentInfo
SDCorpusInfo
SDFPExceptionType
SDMemStats
SDEnvContainerType
SDEnvSpec
SDhEnvHolder
SDEnvHolderSource
SDEnvHolderInfo
SDInteger
SDUnsigned
SDUnsigned16
SDArraySize
SDByte
SDBool
SDChar
SDWideChar
SDFileSpec
SDInteger64
SDUnsigned64
SDDuration
SDUttFrameDuration
SDRecogFrameDuration
SDMicrosecTime
SDCycleTime
SDUserData
SDUniqueId
SDMemoryErrorUserData
SDErrorUserData
SDLogUserData
SDSnapTime
SDPlatformInfo
SDInitializeResultCode
SDFinalizeResultCode
SDProgressCallback
SDReallocateArrayCallback
SDMemoryErrorHandler
SDErrorHandler
SDLogHandler
SDAccumCallback
SDApplyCallback
SDFileFormat
SDFileSupportType
SDFileCompatibility
SDSaveResultCode
SDhGlobalParam
SDParamType
SDParamQueryMode
SDhLattice
SDTokenType
SDRuleParseTokenType
SDConfidence
SDLatticeInfo
SDChoiceConfidencePredictors
SDChoiceInfo
SDTokenConfidencePredictors
SDToken
SDPartialToken
SDRuleParseToken
SDLatticeLink
SDChoiceTokenConfidencePredictors
SDChoiceToken
SDLmAdaptMode
SDLmClearLoadedType
SDhWeights
SDhTopicLmSlot
SDhFactoryCorrectiveLm
SDTopicWeight
SDWeightsInfo
SDLmScoreComponentType
SDDetailedLmScore
SDInitCheckRecord
SDInitTypeSize
SDhAdapterParamSet
SDhChannelParamSet
SDhConfidenceParamSet
SDhLatticeNBestParamSet
SDhLatticePostProbParamSet
SDhPrefiltererBuildParamSet
SDhPrefiltererSearchParamSet
SDhPronGuessParamSet
SDhSausageParamSet
SDhSearchParamSet
SDhSearchCrossLayerParamSet
SDhUserDeltaParamSet
SDParamSetContainerType
SDParamSetSpec
SDParamSetInfo
SDhParamSetHolder
SDParamSetHolderInfo
SDhParamSetParam
SDPrefiltererInfo
SDhPrefilterer
SDhPrefilterResult
SDProfileStyle
SDFunctionDemangleStyle
SDhRecognizer
SDPronGuessResultCode
SDRecognizerInfo
SDWordAlignInfo
SDhSegmentResult
SDSegmentationScores
SDPartialResultScore
SDhRepro
SDReproType
SDReproInfo
SDhRule
SDRuleItemType
SDRuleOperType
SDRuleInfo
SDRuleItem
SDRuleSpec
SDhSausage
SDSausageTokenType
SDSausageInfo
SDSausageToken
SDSausageChoiceToken
SDhSigProc
SDSigProcAdaptationDataType
SDSigProcInfo
SDhState
SDStateInfo
SDStateSpec
SDStateWordSpec
SDhTransducer
SDStateTransducerSpec
SDhUser
SDUserCovarianceType
SDUserInfo
SDhUtt
SDUttType
SDEnergyStatus
SDPitchStatus
SDFrameType
SDUttTimeStamp
SDUttInfo
SDUttFrameInfo
SDhUttFile
SDUttFileFormat
SDhVoc
SDCharType
SDVocTagSetType
SDVocInfo
SDhWord
SDWordSourceType
SDWordInfo
SDWordSpec
datapackDir
locales
name
modelVersion
languageId
language_model_set
acoustic_model_set
empty_delta_voc
pg_voc
general_voc
paramset_holder
textproc_model_set.model_voc
textproc_model_set.model_svc
textproc_model_set.lexicon
textproc_model_set.static_token
textproc_model_set.static_itn
EARAudioReader.m
Could not make Opus decoder: %d
Only expecting to get 1 Opus packet at a time, not %lu
i32@?0^I8^{AudioBufferList=I[1{AudioBuffer=II^v}]}16^^{AudioStreamPacketDescription}24
Opus ecoder gave us %d bytes bytes but we really only expected %d
Could not finish Opus decoding for offline only mode: %d
v24@?0@"NSData"8^B16
<LMstate>
 ...
warning: word probs for this context sum to 
 != 1 : 
too many words per sentence
bad n-best hyp format
%g %g %lu
could not create socket: 
could not bind socket: 
could not accept connection: 
fork failed: 
client 
: connection accepted
probserver ready
: send: 
_R_E_M_O_T_E_L_M_V=2
%s %g
%s %llu %u
%s command unknown
 probabilities served
nonword 
 has nonzero probability 
read() method not implemented
write() method not implemented
 at time 
Repetition
Length
The feature type '
' is not supported
src-ovs-file not present in the config
tgt-ovs-file not present in the config
Registered OVS Feature
OVS file '
' has 
regex-file not present in the config
Registered Repetition Feature
Regular expression file for repetition error detection'
Language '
' not supported for regular experssion in repetition feature
Repetition feature has read the regular expressions from file 
min-trans-len-percent not present in the config
max-trans-len-percent not present in the config
fertility-file not present in the config
Registered Length Feature
Fertility file '
The fertility file is should contain exactly two fields <word  fertility>
WRITE 
EMPTY 
CANCEL 
.recorded_state_accesses
Writing accessed states for 
utt-detect.
utt-detect
g-fst-file
Grammar FST filename
inv-g-fst-file
Inverted Grammar FST filename (overrides uninverted)
big-g-fst-weight-list
the interpolation weights for the FST LMs, use comma to separate multiple ones
max-total-extra-weight
Max first pass weight for limiting total weight of all extra LMs in the first pass - all-app LM and possibly one more app specific LM
big-g-nnet-weight-list
the interpolation weights for the NNLMs, use comma to separate multiple ones
silence-phone-list
List of silence phones.
phone-syms-file
Phone symbol table (text format) filename
enable-state-access-recording
Record which states in each FST are accessed, to allow for efficient reordering
recog-progress-freq
Frequency(in milliseconds) of reporting recognition progress
enable-endpointing
Enable server endpointing
streaming-conf-model-file
Filename for streaming confidence model file, format <WEIGHT> <FEATURE> (one per line)
streaming-conf-normstats-file
Filename for normalization statistics file for streaming confidence, format <FEATURES-LIST>
 <MEANS-LIST>
 <Standard-Deviations-LIST>
 (each line has a comma separated value for all features)
use-endpoint-for-utt-detect
Use endpoint configuration for doing utterance detection
autocomplete-partial-result
Allow partial result to hallucinate word even if speaker hasn't finished saying it yet. For example, Pneumonoultramicroscopicsilicovolcanoconiosis is recognized after a few syllables.
compute-trailing-silence-from-lattice
True if trailing silence should be computed from the lattice, otherwise use a separate two-state machine to compute trailing silence separately (set this parameter to false if a CTC trained acoustic model is being used).
enable-eager
Enable eager
use-partial-traceback-with-final-cost
For partial results, use traceback which taking final cost into account.
If non-empty: This is a key into the top-level 'spg' dictionary of the config file, and this decoder will run a SilencePosteriorGenerator configured from the corresponding dictionary value. If empty: This decoder will not run a SilencePosteriorGenerator.
Using pre-inverted grammar: 
Using regular grammar, need to negate in memory: 
gInvFst: input label is not sorted!
State access recording is enabled. This will slow decoding, so disregard performance.
No BigG FST or NNLM specified. Hint: This is a BigLm decoder.
bigGFst: input label is not sorted!
Could not read FST LM interpolation weight info
The number of big FST LMs and the number of weights mismatch
Could not read NN LM interpolation weight info
The number of big NN LMs and the number of weights mismatch
Language model weight must be 1 when using a single LM
 but does not match 
the auto-determined silence label 
Failed to read phone symbol table file: 
No silence phones given!
ERROR 1: Cannot compute pause counts - word boundary info is missing
ERROR 2: autocomplete-partial-result is false (default), but word-boundary-int-file is missing.
Option 1: Set autocomplete-partial-result=true. This is *usually* done only for 'srch' and 'srch'-variant (WebSearch) decoder chains. This is required if the model doesn't have word-boundary-int-file.
Option 2: Keep using autocomplete-partial-result=false, but add a word-boundary-int-file. This is *usually* done for all other tasks.
needPauseCounts=true and autocomplete-partial-result=true is not supported yet.
Eager disabled because word-boundary-int-file is missing.
VoiceTrigger phrase word "
" not found in symbol table.
VoiceTriggerPhrase not set. This could lead to wrong endpointing that clips any payload after "Hey Siri"
Decoding beam: 
Finished initializing OnlineLatticeBiglmFasterDecoder.
some FST/NN LMs failed to load
Using 
Created new decoder
uttDetector: 
endPointer: 
Feature extraction misconfigured
RaiseToSpeak
eagerDecisionLog
MATCH
NOMATCH
eagerOutputLog
Failed to get recognition lattice
Average number of active tokens: 
Last frame processed 
EstimatedEpTruncation
EstimatedEndPointerTrailingSilence
Server side end pointer first triggered frame 
ProcessEmittingWallMs
ProcessEmittingCpuMs
ProcessNonemittingWallMs
ProcessNonemittingCpuMs
PruneActiveTokensWallMs
PruneActiveTokensCpuMs
Recognition cancelled
spg batch size > 1 unexpected because spg->config.frameByFrame should be set
spgSilenceFramesCount=
 spgSilencePosterior=
 spgSilenceProbabilityRaw=
Raw pauses = [
], words = [
Server side end pointer triggered frame 
ep-features
Reporting end point status=
Since endpointer is not enabled ignoring utterance 
Utterance detector triggered 
Utterance detector force triggered because current utterance has too many frames: 
Sending recognition progress report for frameCount=
 processedAudioDurationMs=
This should only be called if endPointer exists
rt-min
Approximate minimum decoding run time factor
rt-max
Approximate maximum decoding run time factor
max-total-forward-links
Max total allocated forward links at any time.
small-lm-prune-beam-diff
Pruning threshold for small LM before checking with big LM; smaller prunes more aggresively
early-endpoint-threshold
Threshold for early endpoint detection
pause-threshold-list
Comma-separated list for pause-threshold vector, which is used for determining the pause-counts vector that is an endpointer feature. pause-counts[n] is the number of interword pauses >= pause-threshold[n]. For example, pause-threshold=[3,30,100] and pauses of 90 frames and 100 frames will result in pause-counts=[2,2,1].
pauses-as-bool
Needs pause-threshold-list. If true, then pause-threshold vector is used to create a pause-counts vector,where pause-counts[n] is a boolean for asserting interword pauses >= pause-threshold[n]. For example, pause-threshold=[3,30,100] and pause of 90 frames will result in pause-counts=[1,1,0].
Delaying the endpointer trigger decision by the given amount of time (in msec), when specified in recog request.
use-nnet
Use nnet for utterance detection if true
left-context
Use left context for utterance detection if true
hard-max-utt-length-ms
If the utterance exceeds this length, force trigger the utterance detector. Ignored if <= 0. It is named 'hard' because there is a softer 'max-utt-length' config that does not trigger right away when exceeded.
same-state-transition-probability
Same state transition probablity
acoustic-evidence-deweighting-power
Acoustic evidence deweighting power
Invalid word symbol, clipping left context: 
count > 0
: Could not vm_allocate 
: Could not vm_deallocate 
 bytes of 
Error in ProcessNonemitting: no surviving tokens: frame is 
Ran out of forward links in storage
PruneActiveTokensFinal: pruned tokens from 
 links from 
 pruned_tok_frames_ 
 pruned_link_toks_ 
No tokens alive at end of file
No tokens alive [doing pruning].. warning first time only for each utterance
link_extra_cost is NAN
No tokens alive [doing pruning]
: not producing lattice.
GetRawLattice: NumStates 
 NumArcs 
 NumFinal 
Cannot undo PruneActiveTokensFinal(undoable=false)
UndoPruneActiveTokensFinal: restored tokens from 
Skipping compaction final pruning because has been done
Compacted in 
 ms 
tokens 
 and forward links 
Move the partial traceback to the end of word phone
Pause error - Consecutive word-end
Pause error - Word with missing startframe or endframe
Pause error - Word-end before word-begin
Pause error - Word spans into next word
Pause error - Found more word times than words
SplitRadixComplexFft called with invalid number of points 
Error: logn is out of bounds in SRFFT
State access recording requires ExpandedFST
 config:
tokenizer output
text
an input to the AmbiguityAnnotatorBlock has not come from a TokenizerBlock
length
received 
-token source: ["
in hypothesis 
 is translated as "
 in sense 
limiting senses to 
 before limit
 after limit
found the sense "
" in 1-best
" in hypothesis 
tokenizer input
source span: 
no alternatives
defLocale
source match
source index
source length
target match
target index
target length
formality
gender
explicit
lexid
these source spans: 
 are ambiguous
no source spans are ambiguous
TransitionModel::TripleToTransitionState, triple not found.
 (incompatible tree and model?)
ComputeDerivedOfProbs(): non-self-loop prob is 
<TransitionModel>
<Triples>
</Triples>
<LogProbs>
</LogProbs>
</TransitionModel>
region[
Unknown component type: 
Unknown gradient normalizaiton type: 
Unknown matrix initialization type: 
please update to formatted name 
 ASAP, you used 
Unknown component type marker: 
Unknown gradient normalization marker: 
Unknown matrix initialization marker: 
Missing type: 
<Nnet>
</Nnet>
the L2 Norm clipping value must be greater than 0, you set 
either the gradient or the gradient norm data is not initialized
the gradient clipping value must be greater than 0, you set 
the gradient data is not initialized
the factor in RMSPROP must be [0, 1], you set 
The input dimension is not divisible by the output dimension
Not implmented! Should not be called!!!
Non-matching dims! Input batch size: 
 output dim : 
Requested output for invalid unit: 
; total units = 
Relaxation factor must be positive; found: 
<RelaxFactor>
<BlockDims>
 (BlockDims)
Total block dimensions and output dimension mismatch
<DropoutRetention>
 (DropoutRetention)
<Alpha>
  frame_offsets 
<ReadVector>
<BuildVector>
</BuildVector>
 (ReadVector|BuildVector)
Error parsing <BuildVector>
Not implemented!
Unity component doesn't expect any tokens
<DuplicateStart>
<DuplicateSize>
<NumDuplicates>
 (DuplicateStart|DuplicateSize|NumDuplicates)
Requested duplication doesn't match the output and input sizes
Duplication parameters out of range
 shift_data
  shift_data_grad
<InitParam>
 (InitParam|LearnRateCoef|GradientNormType|MaxGrad)
 scale_data
  scale_data_grad
 (InitParam)
<VisibleType>
<HiddenType>
<VisibleBiasMean>
<VisibleBiasRange>
<HiddenBiasMean>
<HiddenBiasRange>
<VisibleBiasCmvnFilename>
 Typo in config?
 (VisibleType|HiddenType|VisibleBiasMean|VisibleBiasRange|HiddenBiasMean|HiddenBiasRange|ParamStddev|VisibleBiasCmvnFilename|RandomSeed)
bern
Bernoulli
gauss
Gaussian
Wrong <VisibleType>
Wrong <HiddenType>
Initializing from <VisibleBiasCmvnFilename> 
Unknown type 
Nonmatching dims, component:
pos_vis
pos_hid
neg_vis
Mismatch between pos_vis and neg_vis variances, 
danger of weight explosion. a) Reducing weights with scale 
 b) Lowering learning rate to 
 [pos_vis_std:
,neg_vis_std:
'inf' in 
'nan' in 
Forcing the variance to be non-negative! 
->0.0
<MSDims>
 (MSDims)
this implementation only models the strict recurrent component, i.e, it requests the input 
and output dimensions be the same,  you set input/out dimension to 
<Nonlinearity>
 (Nonlinearity|ParamStddev|BiasMean|BiasRange|LearnRateCoef|BiasLearnRateCoef|MaxNorm|RandomSeed|MaxGrad|InitTransformType|GradientNormType)
 bias
  linearity_grad is uninitialized
  bias_grad is uninitialized
Unknown nonlinearity type: 
 filters: 
 bias: 
<PatchDim>
<PatchStride>
 (ParamStddev|BiasMean|BiasRange|PatchDim|PatchStep|PatchStride|MaxNorm|GradientNormType|MaxGrad|RandomSeed)
num_splice 
num_patches 
filter_dim 
num_filters 
<PoolStride>
<Scale>
 (PoolSize|PoolStep|PoolStride|Scale)
 (PoolSize|PoolStep|PoolStride)
<PoolXLen>
<PoolYLen>
<PoolXStep>
<PoolYStep>
 (FmapXLen|FmapYLen|PoolXLen|PoolYLen|PoolXStep|PoolYStep)
num_fmaps 
Invalid component parameters
<SpliceLength>
<RowStride>
<TimeLength>
nested_network {
nested_gradient {
<NestedNnetFilename>
<NestedNnetProto>
<LearnRateFactor>
  (offset,weights) : 
  lr-coef 
  (offset,weights_grad) : 
<FeatureDim>
<CentralOffset>
<PoolWeight>
<Normalize>
 (FeatureDim|CentralOffset <vec>|PoolSize <vec>|LearnRateCoef|Normalize)
Initializing from pool-weight vector
<FrameOffset>
<FrameWeight>
the multi subbatch version for this class is not implemented yet
the ParallelComponent has history size 
 , but the input history data has dimension 
the network has history size 
</NestedNnetFilename>
</NestedNnetProto>
, typo in config?
 (NestedNnetFilename|NestedNnetProto)
<NestedNnetCount>
<NestedNnet>
</ParallelComponent>
Two different learning rates: 
nested_network #
nested_gradient #
nested_propagate #
nested_backpropagate #
<NumComponents>
The input dimension is not divisible by the number of components
The output dimension does not match the dimension of individual component
<ComponentWeight>
</InterpolationComponent>
 CompressedWordVec table
 WordVec table
 we don't save intermediate gradient
<FillerSymbolId>
 (ParamStddev|LearnRateCoef|VocabSize|RandomSeed|InitTransformType|GradientNormType|MaxGrad)
invalid vocabulary size 
it doesn't make sense to initialize the word vec as an identify matrix
RMSPROP is not implemented in word embedding yet
not implemented
, bias-lr-coef 
 (ParamStddev|BiasMean|BiasRange|LearnRateCoef|BiasLearnRateCoef|InitTransformType|RandomSeed|GradientNormType|MaxGrad)
it does not make sense to do RMSPROP in this component
 CompressedWordTrans table
<AffineTransform>
<LinearTransform>
<Quantized8BitLinearTransform>
<Quantized16BitLinearTransform>
<SharedNceComponent>
<ConvolutionalComponent>
<ConvolutionalMaxPoolingComponent>
<Quantized8BitConvolutionalMaxPoolingComponent>
<Quantized16BitConvolutionalMaxPoolingComponent>
<Convolutional2DComponent>
<Quantized8BitConvolutional2DComponent>
<Quantized16BitConvolutional2DComponent>
<LstmComponent>
<Quantized8BitLstmComponent>
<Quantized16BitLstmComponent>
<GatedRecurrentUnit>
<Recurrent>
<BidirectionalRecurrentComponent>
<WordVecComponent>
<FofeWordVecComponent>
<WordMultiVecComponent>
<CompressedWordMultiVecComponent>
<CompressedWordVecComponent>
<FixedAttentionComponent>
<MovingAttentionComponent>
<GlobalAttentionComponent>
<GlobalRecurrentAttention>
<ScaledDotAttention>
<MultiHeadAttention>
<SupervisedMultiHeadAttention>
<SelfAttention>
<AverageAttention>
<LayerNorm>
<Softmax>
<LogSoftmax>
<BlockSoftmax>
<MultiSoftmax>
<RelaxedSoftmax>
<Sigmoid>
<Tanh>
<Dropout>
<Maxout>
<Rectified>
<ExponentialLinear>
<ScaledExponentialLinear>
<PNorm>
<Rbm>
<Splice>
<Desplice>
<Copy>
<CnnRearrangeComponent>
<PaddingComponent>
<Padding2DComponent>
<AddShift>
<Rescale>
<QuantizedAffineTransform>
<Quantized16BitAffineTransform>
<NormalizeComponent>
<KlHmm>
<AveragePoolingComponent>
<AveragePooling2DComponent>
<MaxPoolingComponent>
<MaxPooling2DComponent>
<SentenceAveragingComponent>
<FramePoolingComponent>
<ParallelComponent>
<Duplicate>
<Identity>
<TemporalMaxPooling>
<InterpolationComponent>
<CompressedWordTransComponent>
<VectorwiseQuantized8BitAffineTransform>
<VectorwiseQuantized16BitAffineTransform>
ClipValue
ClipL2Norm
Rmsprop
Identity
Uniform
Gauss
  linearity is vectorwise quantized
sentencepiece encoder input
sentencepiece encoder output
sentencepiece decoder input
sentencepiece decoder output
sentence confidence
low confidence
word confidences
subword confidences
decode
decode-api
decode-space
Unknown sentence piece action: 
SentencePiece error while loading file '
firstleg 
Config Version is not high enough for index rule denumeration
Enumeration rules not configured
The default tag for denumeration
Config Version is not high enough for denumeration
LmeWordTagger not used
Unsupported number of lme-word-taggers
Unsupported lme-word-tagger
lme-word-tagger
index-rule-tagger
rules
index
default-tag
Invalid string: %@
Topological sorting of state-level lattice failed (probably your lexicon has empty words or your LM has epsilon cycles; this  is a bad idea.)
Minimizing lattice with self-loops (lattices should not have self-loops)
Largest equivalence group (using hash) is 
, minimization might be slow.
Removing 
 states.
warning: maximum tagged index lowered to 
maximum number of tagged words (
) exceeded
maximum number of tags (
%s%c%s
%c%s
QuasarC
[QSR] FATAL %s
[QSR] ERROR %s
[QSR] WARN %s
[QSR] PRODINFO %s
[QSR] INFO %s
[QSR] DEBUG %s
[QSR] TRACE %s
Token(
en-like
zh-like
algorithm
Algorithm name. Possible values: en-like, zh-like
Invalid algorithm
Index error: [
-derived
Tag with multiple words: 
\contact-first-phonetic
\contact-last-phonetic
\contact-first-derived
\contact-last-derived
syms
<sigma>
<rho>
<phi>
lattice-
.fst
wmapper-
rpathcounter-
mapper-cd-
 symbol '
' missing from target symbol table.
Target symbol table missing: 
 input symbols.
 output symbols.
Push: pushing type is set to 0: 
pushing neither labels nor weights.
ShortestDistance: Weight needs to be right distributive: 
ShortestDistance: first_path option disallowed when 
Weight does not have the path property: 
Reweight: Reweighting to the final states requires 
Weight to be right distributive: 
Reweight: Reweighting to the initial state requires 
Weight to be left distributive: 
right_gallic_
right_gallic
left_gallic
ArcMapFst: non-zero arc labels for superfinal arc
StringWeight::Divide: only right division is defined 
for the right string semiring
factor_weight
FactorWeightFst: factor mode is set to 0: 
factoring neither arc weights nor final weights.
FromGallicMapper: unrepresentable weight: 
 for arc with ilabel = 
, olabel = 
, nextstate = 
CompositeWeightWriter: 
FLAGS_fst_weight_separator.size() is not equal to 1
FLAGS_fst_weight_parentheses.size() is not equal to 2
Epsilon
BadString
SigmaMatcher: bad match type
SigmaMatcher: 0 cannot be used as sigma_label
SigmaMatcher:: bad match type: 
SigmaMatcher::Find: bad label (sigma)
RhoMatcher: bad match type
RhoMatcher: 0 cannot be used as rho_label
RhoMatcher:: bad match type: 
RhoMatcher::Find: bad label (rho)
resize overflow
sparsehash: FATAL ERROR: failed to reallocate %lu elements for ptr %p
insert overflow
DeterminizeFst: 
a state table can not be passed with transducer input
StringWeight::Divide: 
only explicit left or right division is defined 
for the 
 semiring
restricted_string
StringWeight::Plus: unequal arguments 
(non-functional FST?)
 w1 = 
 w2 = 
EmptySet
BadSet
gallic_
StringWeight::Divide: only left division is defined 
for the left string semiring
_from_gallic
GallicToNewSymbolMapper: unrepresentable weight: 
number of start/end LME class tags doesn't match: 
cannot find 
 in the vocab file
 LME classes, their IDs are not contiguous
seeva-step
encoder-model-file
seeva inference encoder graph file
decoder-model-file
seeva inference decoder graph file
num-encoder-states
number of encoder states
num-decoder-states
number of decoder states
align-state-list
alignment state indices in the decoder states
vocab-file
the vocab file for the model output token
vocab-is-binary
vocab file is binary
model-format-version
model format version
feature transform file
lme-start-tag-list
a list of LME start tag
lme-end-tag-list
a list of LME end tag
speller-fst-file
the speller FST file
Inverted small grammar FST filename
lm-unknown-word
the unknown word (OOV) in the LM
the lm beam should be no less than the model beam, 
loaded an inverted G, make sure the speller FST is weighted
do not have an inverted G, make sure the speller FST is unweighted
spellerFst: input label is not sorted
cannot find the OOV word 
 in the symbol table
Finished initializing OnlineSeevaStepBigLmDecoder
/cpu:0
lme-score-scale
scale the LME FST score when LME is active
nonlme-score-scale
scale the nonLME arc score when LME is active.
lm-score-scale
scale external LM score when available
lm-miss-penalty
penalty for missing LM arc
lm-miss-final-penalty
penalty for missing LM arc in final
lm-beam
use this beam value for the external LM
lme-beam
use this beam value for the LME arcs
length-penalty-lm
the length penalty value when using external LM
online-las-beam-search
LAS model (TF/Espresso/CoreML graph)
batch size
token-delimiter
token delimiter
decoderOpts.beam == inferenceNet->Beam()
Batch size is not an integer multiple of the frame subsampling factor. 
Encoder might drop frames.
Decoder did not reach end-state, outputting partial traceback.
Failed to get raw recognition lattice.
remove-eos
remove EOS labels from output
remove-sil
remove silence labels from output
max-steps
maximum number of decoder steps
beam width (must match the model)
length penalty
coverage penalty
dictation-languages
current-dictation-language
was-language-toggled
multilingual-keyboard-languages
keyboard-convo-language-priors
keyboard-global-language-priors
previous-message-language
global-last-keyboard-used
dictation-language-priors
Clipping left context because of unknown word: "
Clipped too big left context: 
 words; limit is 
bitmap-color
The value of the 
 in region 
 field has to be a positive integer but is 
Metainfo does not contain any alignment spans
error parsing Json >
 ||| 
error parsing Json <
Not caching word with too many prons: "
" has 
 prons
Skipping illegal word: "
Encoding should be either QsrText or NotEncoded
Skipping illegal Word
UNKNOWN
: nWords = 
: orthography = 
: nProns = 
: pron = 
Ignoring corrupted prons: orthography = 
, nProns = 
enumerationTypeMap dump, key=
enumerationTypeMap dump, enumerationType=
: nMapSize = 
: key = 
: enumerationType = 
Duplicate key is being added to enumerationTypeMap with key=
Invalid write version choice: 
, it is now set to: 
done.
formatVersion=
Failed to read LmeData stream. Incorrect version: 
Error reading LmeData stream: 
LME STREAM DUMP [Body]
: g2pModelVersion = 
: symTableFirstKey = 
: symTableLastKey = 
: fstSize = 
: phoneSetVersion = 
LME STREAM DUMP [Pron Cache]
: templateName = 
: <FST>
: <symTable:
 symbols>
LME data stream successfully read with 
 symbols; 
) ~ "
LME STREAM DUMP         
LME data stream version is old, but still supported. Current write version is 
 and stream version is 
Matrix::Read, size mismatch 
Can not map into the wrong matrix data type
: Seeking failed
: Reading whole matrix failed
: Reading a matrix row failed
: Seek for padding 
: Expected "[", got EOF
: Expected "[", got "
Matrix has inconsistent #cols: 
 vs.
 (processing row
Failed to read matrix from stream.  
Wrong sized arguments
Wrong size of arguments.
index item is bigger than the voc size 
index 
 is too big for matrix that has rows = 
Failed to write matrix to stream: stream not good
Failed to write matrix to stream
 [ ]
Left context for utterance detection does not work. Ignoring user-provided value of allowUttDetectLeftContext and disabling left context.
AddConfigOverride() can only be called before init()
speaker-code-training
speaker-code-training.
Initialized SpeechRecognizer with config 
SpeechRecognizer must be in initialized state before you call runAsync(). 
Hint: Make sure you call waitForAsyncRecogToFinish() before calling runAsync() again.
Utterance concatenation should only be used with utterance detection
Eager + utterance detection without concatenation is not allowed
Running runSyncAndMarkEndOfRun() in separate thread
Cancelling recognition
This function can only be called in Recognizing or Cancelling state
finalResultTokens
geoLocationStatusUponRunAsync
Symbol table list passed to runSync() must start empty
Invalid recognition request parameters
Speaker code training is enabled, going to cache features and labels as training data
Created OnlineFeatInputItf chain
Frontend and SPG frame durations differ: 
End of recognition.
Start recognition of a new utterance...
Ran out of forward link storage during decode: 
Ran out of token storage during decode: 
Reporting empty result due to thrown exception during decode
far_field
SpeechRecognizer must be initialized before calling runSync()
Symbol table list passed to runSyncUtterance() must start empty
uttNum
jsonConfigFilePath
taskType
recognizerComponents
enableWhisperDetection
numLmeDataStreams
utteranceDetection
utteranceConcatenation
epExtraDelay
InputOrigin
LME DataStreams=
 samplingRate=
 taskType=
 deviceId=
 enableWhisperDetection=
 endpointerExtraDelay=
 inputOrigin=
 highPriority=
You have provided a reference transcript, which will trigger error-blaming (if specified in 
the config file). This is an EXPERIMENTAL feature that uses lots of memory and incurs lots of 
latency!
runSync:initTime
There is no decoder which affects recognition, this must be a configuration error.
eagerRequested
Eager disabled: not supported by first-pass decoder: 
Eager disabled: silence posterior required but not available: 
Eager disabled: not supported by second-pass decoder: 
eagerUsed
Waiting for first valid feature frame of first utterance...
uttDetectAbort
Rejected
geoLocationStatusUponRequestComplete
recognitionStatus
Feature buffer is null or reversed pdf is empty, skip training.
Populating training data, original feature size: 
, alignment size: 
Reaches the end of labels, aligned features size: 
, label size: 
Training data is populated, aligned feature size: 
Training is not enabled!
Recognition is not final, concatenating alignments, feature buffer size: 
, label buffer size: 
, pdfs size: 
, num frames: 
Label concatenation is completed, label buffer size: 
audioReadTime
featureComputeTime
whisperScore
whisperDetected
utteranceLength
audioEndTime
utteranceEndTime
timeElapsedSinceRunAsyncCall
timeElapsedSinceRunSyncCall
EagerUsed
recognizer-components
DidConfNetCombination
ConfNetWaitTimeMs
ConfNetworkCombinedNbestSourceID
ConfNetworkCombinerStartTimeMs
LastWordClipped
Write results got a NULL lattice
NullLattice
Recognition is going to fail because of NULL lattice. Padding labels to align with features
Recognition is final and successful, populating data from cached features and labels for training.
PartialResultsAvgLagMs
PartialResultsToggleCount
FasterPartialResultsAvgLagMs
FasterPartialResultsToggleCount
Shortest path cost: 
lmeStatus
Lattice was not NULL, but failed to generate any choices
NoChoices
RecogThreadCpuTimeMs
EosToPreItnMs
lm_interp_weights
training-nnet-file
Training neural network path
max-feature-cache-size
Max feature cache size for training
learning-rate
Learning rate of the training
training-nnet-version
Training neural network version
The interval which will be used for updating the speaker code for training, default is 64
Training mini batch size, default is 1
thread constructor failed
unique_lock::unlock: not locked
unique_lock::lock: references null mutex
unique_lock::lock: already locked
Invalid recognizer specifier "
", must have 3 components
spg.
 references spg that does not exist: 
Models must be loaded before calling lookupRecognizerComponents.
Models must be loaded before calling getSpgConfig.
Invalid SilencePosteriorGeneratorConfig name "
rule-config-file
rule-type
Rule config file does not exist or it is a directory. File path = 
Read rule config file = 
Failed to parse config file = 
rule: 
 is not valid.
clone-from field is invalid. Rule config file path=
clone-from
pre-alt-gen
post-alt-gen
alt-gen
We do not support step = 
Enumeration is calculated already.
more than 
 fields per line
 words in hyp
(%lf)
bad Decipher score: 
badly formatted hyp
 tokens in hyp
bad acoustic score: 
bad LM score: 
bad word count: 
warning: hyp contains zero prob words: 
warning: hyp contains OOV words: 
Could not open decoding-graph FST 
Reading FST: error reading FST header.
FST with arc type 
 not supported.
const
Reading FST: unsupported hammer FST type: 
Error reading FST (after reading header).
Hammer didn't change any text. Therefore returning the original input.
Number of outputs (n) cannot be less than 1.
, start silence: 
Empty tokenName
Pre-text-proc Choice[
Post-text-proc Choice[
Pre-sanitization: 
Post-sanitization Choice[
modelFile doesn't exist, or it's a directory: 
Key not found: 
post-itn-hammer configured key='
' prefix=
Empty post-itn-hammer rule
, jsonConfigPath=
 configured
itn2 configured key='
ignogre itn2 config of 
, what we are looking for is 
Failed to configure itn2
Ignore unknown node text-proc.
Key does not match 'locale' or 'locale::keyboard': 
Locale cannot include leading/trailing whitespace: 
Keyboard cannot include leading/trailing whitespace: 
Locale with separator '
' not supported: 
Keyboard with separator '
Locale=
 should only be used with keyboard=*
Keyboard=* is reserved for internal use
There are itn2 models, but cannot find one for locale=
empty ITN input tokens
locale=
 keyboard="
 itn2="
empty sanitizer input tokens
empty postItnHammer input tokens
 postItnHammer="
post-itn-hammer
default
sanitizer
itn2
lattice-proc
ConstFst::Read: Alignment failed: 
ConstFst::Read: Read failed: 
Could not align file during write after header
Could not align file during write after writing states
ConstFst Write write failed: 
Inconsistent number of arcs observed during write
help
[]~#^_-+=:.,/
'\''
"`$\
Invalid parameters supplied to OnlineLdaInput
Invalid parameters supplied to OnlineTransformInput
end_pad_ > 0
input.NumRows() <= strict_batch_size_ + total_batch_context_
NaN in features
inf in features
Batch 
Must use penultimate-compatible AM with silence nnet
Frames consumed by model (
) does not match frames added by batchwise splicing (
). Hint: Are batch-left-context and batch-right-context correct for this model?
orig_input_size + frames_padded - total_batch_context_ == output->NumRows()
output->NumRows() == sil_post->NumRows()
NaN in NNet output
inf in NNet output
input.NumRows() <= strict_batch_size_
There is extra input, rows=
, cols=
extra_input_.NumRows() == 1 && feats.NumRows() >= 1
orig_input_size + frames_padded == output->NumRows()
(!has_sil_post_ && next_sil_post.NumRows() == 0) || (has_sil_post_ && next_features.NumRows() == next_sil_post.NumRows())
Unexpected point reached in code: 
possibly you are skipping frames?
Attempting to get a discarded frame.
Attempt get frame without check its validity.
<blk>
keyword-spotting
The threshold for the keyword score
frame-offset
frame offset
do-viterbi
apply viterbi for keyword detection
tokens-file
symbole table file
keyword-list-file
list of keywords and their corresponding tokens sequence
Number of frames that get decoded in one go
do-batch-reset
Reset scores after each batch result
do-top-result-only
Only return the best keyword score
Number of labels: 
Blank label "
Blank label index: 
Invalid keyword-phrase line
Adding keyword: 
Symbol "
Number of keywords: 
keyword mismatch 
Error: no utterance features were provided
No keywords found.
Start of batches
unmatched  posterior matrix dimension and number of symbols
empty posterior matrix
About to process 
 frames in batch
KWD 
End of batch
End of batches
keyword detected
no keywords detected
keyword search finished with 
 detected hypothesis.
Missing voicing regions in audio analytics
Voiced region start: 
 end:
Voicing threshold=
 mean=
 stddev=
the base lexicon is empty
the base symbol table is empty
the number of templates in the user data is zero
insufficient number of word disambiguation symbols in the graph, 
 . deleting offending pronunciations.
number of word symbols before LME: 
number of word symbols after LME: 
LME: number of disambiguation symbols is 
the optional silence 
 is not defined in the symbol table
the word boundary string can only have non-space characters, you set it (
number of prons, pre/post-compound:
 #comp_words:
can not find symbol 
 in the input symbol table
LME: no available user data for 
-th template
LME: detected a zero frequency - ignoring this word
not in the compound mode, and the number of words in this entry is more than 1, use CreateFst() instead
remove excessive homophone prons without removing words, rebuild the FST now
has to remove 
 words, rebuild the FST now
LME: spent 
 seconds on creating the compound lexicon for 
 items
the output symtable is not empty
NaturalLess: Weight type is not idempotent: 
DeterminizeFst: Weight needs to have the 
path property to disambiguate output: 
 before calling createOnlineFeInput().
subsample
stride
Take every n'th feature, for this value of stride(with negative value, repeats each feature n times)
' cannot occur at the first stage of feature-extract
Building FeatureExtractor 
cmvn
fbank
fbankwithpitch
mfcc
nnet-forward
nnet-forward-skip
splice
transform
cache-input
compute-ahead-input
fbank-with-audio-analytics
append
Unknown feature-extract type "
Finished reading matrix file 
Minumum CMN window used at start of decoding (adds latency only at start). 
init-cmvn-stats-file
Stats File for warm-start online CMVN
prior-count
number of frames used from prior CMVN stats file
buffer-output
Use OnlineBufferingInput
cmvn-window
Window in frames for running average CMVN computation
min-cmvn-window
Minumum CMVN window used at start of decoding (adds latency only at start). 
low-watermark
Low watermark (in number of frames) for audio buffer read. Ignored if <= 0.
resample-freq
The frequency to resample to.
resample-cutoff-hz
The cutoff for the filter for resampling the audio
resample-num-zeros
Controls sharpness of filter.
' can only occur at the first stage of feature-extract
analytics-sample-frequency
analytics-frame-length
analytics-frame-shift
analytics-preemphasis-coefficient
Coefficient for use in signal preemphasis (deprecated)
min-f0
min. F0 to search for (Hz)
max-f0
max. F0 to search for (Hz)
soft-min-f0
Minimum f0, applied in soft way, must not exceed min-f0
penalty-factor
cost factor for FO change.
lowpass-cutoff
cutoff frequency for LowPass filter (Hz) 
resample-frequency
Frequency that we down-sample the signal to. Must be more than twice lowpass-cutoff
delta-pitch
Smallest relative change in pitch that our algorithm measures
nccf-ballast
Increasing this factor reduces NCCF for quiet frames
nccf-ballast-online
This is useful mainly for debug; it affects how the NCCF ballast is computed.
lowpass-filter-width
Integer that determines filter width of lowpass filter, more gives sharper filter
upsample-filter-width
Integer that determines filter width when upsampling NCCF
frames-per-chunk
Only relevant for offline pitch extraction (e.g. compute-kaldi-pitch-feats), you can set it to a small nonzero value, such as 10, for better feature compatibility with online decoding (affects energy normalization in the algorithm)
simulate-first-pass-online
If true, compute-kaldi-pitch-feats will output features that correspond to what an online decoder would see in the first pass of decoding-- not the final version of the features, which is the default.  Relevant if --frames-per-chunk > 0
recompute-frame
Only relevant for online pitch extraction, or for compatibility with online pitch extraction.  A non-critical parameter; the frame at which we recompute some of the forward pointers, after revising our estimate of the signal energy.  Relevant if--frames-per-chunk > 0
max-frames-latency
Maximum number of frames of latency that we allow pitch tracking to introduce into the feature processing (affects output only if --frames-per-chunk > 0 and --simulate-first-pass-online=true
analytics-snip-edges
If this is set to false, the incomplete frames near the ending edge won't be snipped, so that the number of frames is the file size divided by the frame-shift. This makes different types of features give the same number of frames.
pitch-viterbi-window
Number of frames over which we want to run viterbi for computing pitch.
lda-matrix-file
LDA matrix filename
Number of frames of left context
right-context
Number of frames of right context
no-softmax
No softmax on MLP output (or remove it if found), the pre-softmax activations will be used as log-likelihoods, log-priors will be subtracted
apply-log
Transform MLP output to logscale
batch-left-context
Number of frames of left context to prepend to the batch as extra rows
batch-right-context
Number of frames of right context to append to the batch as extra rows
strict-batch-size
Batch size applied just for this extractor. Ignored if <= 0. Unlike feature-read.batch-size, which is just a hint, this batch size is so strict that even the last batch will be padded to exactly this size with copies of the last frame if the last batch is too small. (The padding is removed from the output). Excludes context frames (actual batch size is strict-batch-size + batch-left-context + batch-right-context).
zero-pad
Zero pad the features, instead of last frame padding, to reach the strict-batch-size requirementvalid only when strict-batch-size is also specified
append-pad-info
Append the pad info as an additional row in the input matrixThe first element of the appended row is the number of padded rows, which excludes this extra appended rowvalid only when strict-batch-size is also specified
Nonsense option combination : --apply-log=true and --no-softmax=true
Option --class-frame-counts has to be used together with 
--no-softmax or --apply-log
Used --apply-log=true, but nnet 
 does not have <softmax> as last component!
Batch size applied just for this extractor. Ignored if <= 0. Unlike feature-read.batch-size, which is just a hint, this batch size is so strict that even the last batch will be padded to exactly this size with copies of the last frame if the last batch is too small. (The padding is removed from the output). Includes skipped frames (neural network sees `ceil(strict-batch-size / (1 + skip-frames))` frames at a time.
File for any linear (or affine) feature transformation
cache-data
If true, cache all data (e.g. fbank feats)
cache-analytics
If true, cache all analytics data
delta-order
Order of delta computation
delta-window
Parameter controlling window for delta computation (actual window size for each delta order is 1 + 2*delta-window-size)
Add an extra dimension with energy to the FBANK output.
Floor on energy (absolute, not relative) in FBANK computation
If true, put energy last.  Warning: not sufficient to get HTK compatible features (need to change other parameters).
use-log-fbank
If true, produce log-filterbank, else produce linear.
cache-energy
If true, cache energy values.
Frequency that we down-sample the signal to.  Must be more than twice lowpass-cutoff
pitch-scale
Scaling factor for the final normalized log-pitch value
pov-scale
Scaling factor for final POV (probability of voicing) feature
pov-offset
This can be used to add an offset to the POV feature. Intended for use in online decoding as a substitute for  CMN.
delta-pitch-scale
Term to scale the final delta log-pitch feature
delta2-pitch-scale
Term to scale the final 2nd-order log-pitch feature
delta-pitch-noise-stddev
Standard deviation for noise we add to the delta log-pitch (before scaling); should be about the same as delta-pitch option to pitch creation.  The purpose is to get rid of peaks in the delta-pitch caused by discretization of pitch values.
normalization-left-context
Left-context (in frames) for moving window normalization
normalization-right-context
Right-context (in frames) for moving window normalization
Number of frames on each side of central frame, to use for delta window.
delay
Number of frames by which the pitch information is delayed.
add-pov-feature
If true, the warped NCCF is added to output features
add-normalized-log-pitch
If true, the log-pitch with POV-weighted mean subtraction over 1.5 second window is added to output features
add-delta-pitch
If true, time derivative of log-pitch is added to output features
add-delta2-pitch
If true, 2nd order time derivative of log-pitch is added to output features
add-raw-log-pitch
If true, log(pitch) is added to output features
use-pitch
Add extra dimensions for pitch to the FBANK output.
add-pitch-period
If true, pitch period is added to output features
add-pov
If true, probability of voicing is added to output features
add-max-amplitude
If true, max amplitude is added to output features
No feature vectors requested?!
append-pad-info cannot be set if strict-batch-size is <= 0
zero-pad cannot be set if strict-batch-size is <= 0
supported by OnlineNnetForwardInput. Use a separate splice 
OnlineNnetForwardInput. Use a separate splice operation to 
ComputeAheadFeatInput
Invalid partition id 
 has to be in range [0,
Requested word position is out of bounds 
Supplied word position index 
, is out of bounds in ErrorRegion, should be in range [0,
Algorithmic error, do not know what to do with level 
Supplied region_id is out of bound, have only 
 regions, asked for 
--------------------------------------------
From frame 
LM scores:
Hyp 
AM scores: 
Ref: 
Hyp: 
Ref Models:
Hyp Models:
Ref Phones:
Hyp Phones:
Ref Scores:
Hyp Scores:
           
Supplied frame is not part of given transition ids
num-of-words
num-trailing-sil
end-of-sentence
pause-counts
silence-posterior
client-silence-frames-count-ms
client-silence-probability
silence-posterior-nf
server-features-latency
eager-result-end-time
spg-silence-frames-count
spg-silence-posterior
spg-silence-probability-raw
Read endpoint model file =
Writing to json string failed. 
BasicEndPointer inter-utt-sil=
, max-utt-length=
, max-utt-sil=
Feature unknown, features allowed are: 
NNet model file for endpointing cannot be empty when use-nnet-endpointer is set
Empty feature list (endpoint.feature-list). Specify features from: 
Invalid pause-threshold-list string 
pause-threshold-list should not be empty if pauses-as-bool is set
NnetEndPointer endpoint-threshold=
num-frames
sequence-of-words
num-input-label-words
stream-conf
com.apple.sequoia.tokenizer
mini.json
ncs/dispatch.voc
ncs/lexicon.enh
ncs/itn_s.enh
outputLocale
T@"NSLocale",R,N,V_outputLocale
Geo config file loaded but some parts of config JSON have never been used
Dumping unused parts of geo config JSON ...
Finished loading geography from 
geo-config-version
Unsupported geo config version 
cache-region-id-enabled
regions
Loaded circle geoRegion="
Same 
Loaded bitmap geoRegion="
Internal error. At this point geoRegion=
 must have either bitmap or circle info
Loaded geoCircleRegions=
 geoBitmapRegions=
regions-bitmap
The regions-bitmap section is not available
The config file contains some bitmap regions but the 
 field is missing
Geo ClassLM template=
 assigned to FST from geoRegion=
 based on regions bitmap
Using regionId 
 instead of location
 based on known region id
Internal error, known location expected but got 
Computing geo context for 
Internal error, unknown location expected but got 
Access to geo location denied
 based on cached region id
Cannot resolve regionId=
Location is within max radius of geoRegion=
 based on circle regions
No audio left, and endOfAudio set. Returning false.
Waiting for more audio or endOfAudio
Copied 
 samples (
) into data
returning code: 
Maximum buffer length 
 has been reached. All additional audio will be dropped.
Maximum ring size 
Clipped audio length 
Added 
 samples: 
Signalling end of audio...
PacketsReceived="
Server endpoint triggered so moving buffer marker to end of buffer.
It does not make sense for maxRingSizeSeconds (limit on the amount of unread audio queued in the buffer) to be greater than maxBufferLenReached (limit on the total amount of audio written to the buffer)
circular_buffer
Word(
lmeType: 
 is not listed in lmeTypeInOffsetOrder.
Unchecked
Detected
Not Detected
freezing component 
 (1-based) in this Update
Components to propagate (startCompIdx=
, num_comps=
) must not be greater than 
#components in the network (
Components to propagate to (
Freezing specified components (1-based):
<NnetProto>
Missing </NnetProto> at the end.
</NnetProto>
The network '
' is empty.
Dimensionality mismatch!
 Previous layer output:
 Current layer input:
Could not read any components
Nnet already mapped from a file
The mapped network '
num-components 
input-dim 
output-dim 
number-of-parameters 
component 
### No gradient info
### Gradient stats :
Component 
### Forward propagation buffers not initialized
### Forward propagation buffer content, note in the parallel GPU training, this only includes the first subbatch content :
[0] output of <Input> 
] output of 
### Backward propagation buffers not initialized
### Backward propagation buffer content, Note in multi subbatch case, only the first subbatch is reported :
[0] diff of <Input> 
] diff-output of 
Dimension mismatch between output/input of components 
 <--> 
The word vec component can only be the first component
The word multivec component can only be the first component
The compressed word vec component can only be the first component
a recurrent trainer option. 
a regular trainer option. 
workspace_size_bytes >= 0
Set workspace of 
 bytes for 
 sub-batches
xent
Invalid set to freeze ( non-unique components ): --freeze-components 
Using workspace of size: 
 KBs
Unknown objective function code : 
At iteration 
linearity_corr_.size() > batch_idx
linearity_corr_[batch_idx]
bias_corr_.size() > batch_idx
bias_corr_[batch_idx]
, and Recurrent style components have additional configurations 
bptt_steps 
num_sequences 
NnetTrainOptions : 
learn_rate 
momentum 
l2_penalty 
l1_penalty 
qtype_compact_grad 
step_compact_grad 
num_subbatches 
average_gradients 
vectorize_weights 
The GPU ID for the matrix randomizer is 
Removing softmax from the nnet 
last_component_idx_ >= 0
Memory mapping failed. Not a valid Kaldi binary file: 
Memory mapping failed. mapped_file_ is NULL
memory mapped file 
Performing vectorization of affine transform component
(nlinparams + bias_->Dim()) == NumParams()
veccorrs->size() == linearity_corr_.size() && veccorrs->size() == bias_corr_.size()
(LinearityCorr(ic).NumRows() * LinearityCorr(ic).NumCols() + bias_corr_[ic]->Dim()) == NumParams()
Done  vectorization of affine transform component
 (ParamStddev|BiasMean|BiasRange|LearnRateCoef|BiasLearnRateCoef|MaxNorm|InitTransformType|GradientNormType|MaxGrad|RandomSeed)
Bias().Dim() == vec.Dim()
data
T{shared_ptr<quasar::LmData>=^{LmData}^{__shared_weak_count}},R,N,V_data
roundingEnabled
TB,N,V_roundingEnabled
model
T{shared_ptr<quasar::LmModel>=^{LmModel}^{__shared_weak_count}},R,N,V_model
prons
T@"NSSet",R,N,V_prons
Ti,R,N,V_frequency
T{shared_ptr<quasar::AppLmData>=^{AppLmData}^{__shared_weak_count}},R,N,Vdata
orderedOovs
T@"NSArray",R,N
quasar.lm
\unknown-first
there are different number of items in the weights list
there are different number of items in each vector
weights should sum to one (i.e. not in log scale)
linear weights converged after 
 iterations
Last state of linear clat is not a final state (perhaps text contains \CS-xx-start without \CS-xx-end?) LM score will not be accurate.
fail to top-sort the rescored lattice
no old LM defined
total number of old LMs is 
 , but the number of interpolation weights is 
no new LM defined
total number of new LMs is 
Failed to limit interp_weights2
can not perform LM rescoring on the lattice
Failed to get a best path in the lattice
Failed to get new total LM score
max_weights: 
Initial weights 
Total number of weights is 
 , but the number of max weights is 
LM should not have been added to DeterministicOnDemandFstCreator. max_weight <= 0: 
Unimplemented. num_effective_max_weights > 1: 
Final weights: 
Division by zero [0/0] in CompactLatticeWeightTpl
Error: division by zero in CompactLatticeWeightTpl::Divide()
Error in Divide (CompactLatticeWeightTpl): cannot divide, length mismatch.
Error in Divide (CompactLatticeWeighTpl): cannot divide, data mismatch.
Cannot divide CompactLatticeWeightTpl with DIVIDE_ANY.
invalid deterministic on-demand FST
can not find label 
 from state 
 . Wrong LM intput?
only linear weight estimation has been implemented now
Caught exception doing lattice determinization
Memory allocation error doing lattice determinization; using 
 bytes (max = 
 (repo,arcs,elems) = (
[empty subset]
Failure in determinize-lattice: size exceeds maximum 
warning: mixture prior out of range: 
too many words in line
ARPA
lm ngram order
weight
lm prior weight
lm type
allowed options for mixture LM 
 are
error in ngram lm
error in class defintions lm
COUNTLM
error in count-lm 
MAXENT
error in maxent lm 
LMCLIENT
 is not a valid LM type
[post=
[probs=
 in geo config version 
, upgrade to version 
 to avoid this warning
EAR Initialization failed for custom-lm, error:
CustomLMBuilderErrorDomain
%@/oovProfile.txt
com.apple.ear
EARPSRAudioProcessor
delegate
T@"<EARPSRAudioProcessorDelegate>",W,N,V_delegate
configRoot
T@"NSString",&,N,V_configRoot
queue
T@"NSObject<OS_dispatch_queue>",&,N,V_queue
word-syms-marisa-file
Base word symbol table in MARISA trie format (overrides other format files)
word-syms-map-file
Base word symbol table mappable format filename (overrides text and binary format file)
word-syms-binary-file
Base word symbol table binary format filename (overrides text format file)
Base word symbol table text format filename
Could not read symbol table from marisa file 
Could not read symbol table from mappable file 
Could not read symbol table from binary file 
No word symbol table file specified.
Failed to convert HatText token to QsrText token:
Failed to convert QsrText token to HatText token:
Programming error: Invalid output encoding
<SourceDotTransform>
this is not an updatable component, you used 
<TargetDotTransform>
<SourceAddTransform>
<TargetAddTransform>
Reading attention model
read source dot transform failed
read target dot transform failed
read source add transform failed
## Source Dot Transform: input-dim 
## Target Dot Transform: input-dim 
## Source Add Transform: input-dim 
## Target Add Transform: input-dim 
source state dimension is 
 , but the source dot transform has input dim 
 , but the source add transform has input dim 
the component has input dim 
 , but the target dot transform has input dim 
 , but the target add transform has input dim 
the source and target dot transform has different output dim 
the source and target add transform has different output dim 
the source/target add transform has output dim 
 , but the component has output dim 
it doesn't make sense to use a non-reccurent network here
cannot initialize source dot transform from 
cannot initialize target dot transform from 
it doesn't make sense to use a non-recurrent network here
## Internal recurrent network info 
not implemented yet
the internal recurrent network has output dim 
the internal network takes input dimension 
 , that is not equal the sum of 
source vector dimension 
target input network dim 
the internal network has output dim 
Could not read mapped file
SymbolTable::Read: Can't open file 
Could not read magic header
Magic header was wrong
Could not read number of words
Slow symbol table initialization and sorting! This should NEVER be called for perf or memory critical workloads
 are padded words
Slow linear search called! This is OK if called during recognition initialization, but should 
NEVER be called during online recognition.
Logic error (this should not happen).
pass
match
.frontend
.nfhat
Silence posterior generator created with incorrect version
frameByFrame requires output batch size of 1
Input lattice must be topologically sorted.
_LT_
Cannot read munge file: 
Number of munge rules: 
This should not be called with empty tokens
Munge line with non-space whitespace: 
Munge line missing probability: 
Probabilistic munge rules not implemented (probability must be 1.0): 
Munge line with more than 1 '<-'
/REJECT/
Munge line with empty rhs: 
Munge line with invalid lhs: 
Munge line with invalid rhs: 
MergedMungeRule: 
 {rhs=
 lhs=
 reject=
BasicMungeRule: {rhs=
 startAnchor=
 endAnchor=
%s%u
warning: failed to add 
 to vocabulary
warning: line contains only one token
warning: failed to add alias 
 for word 
%u %s
malformed vocab index line
Vector<Real>::Read, adding but dimensions mismatch 
Error reading vector data (binary mode); truncated stream? (size = 
EOF while trying to read vector.
Expected "[" but got 
Failed to read number.
Expected whitespace after number.
Reading negative infinite value into vector.
Reading negative NaN value into vector.
Expecting numeric vector data, got 
After end of vector data, read error.
EOF while reading vector data.
Newline found while reading vector (maybe it's a matrix?)
Reading infinite value into vector.
Reading NaN value into vector.
Failed to read vector from stream.  
SoftMax produced NaN on vector
Empty vector
Failed to write vector to stream
UTF-8
UTF-16LE
UTF-16BE
conversion from UTF-16
 not supported
iconv
line 
offset 
offset unknown 
In class File, failed writing to buffer
Reading LmModel dir=
Reading LmModel currentDir=
maxRescoreWeight
Unknown exception
C++ exception: 
Type of model. Examples: 'dummy' or 'ngram'
Interpolation weight
max-rescore-weight
Max rescoring weight: 0 = exclude from rescoring, 1 = use in rescoring as usual, betw 0 and 1 = limit rescoring weight chosen by EM algorithm
deserialize-test
Test if the new model can be read before it is installed
Not enough data. Skip training
Destination is empty
Reserved metadata key: 
Coordinated rename failed. This should never happen and is a bug!
totalTime
times
ngram
Unknown model type: 
lm.json
lm-personalize.model
/garbage
/current
Testing deserialization
Deserialization test failed.
/next
Non-finite loss (
) in cross-entropy calculation
Non-finite entropy (
Posterior pdf-id out of NN-output dimension, please check number of pdfs by 'hmm-info'.
 nn-outputs : 
, posterior pdf-id : 
ProgressLoss[
h]: 
 (Xent)
Can't collect performance from non Xent object
AvgLoss: 
 (Xent), 
[AvgXent: 
, AvgTargetEnt: 
progress: [
FRAME_ACCURACY >> 
% <<
Loss
Entropy
Correct
Frames
) in MSE calculation
 (Mse)
Can't collect performance from non Mse object
 (Mse), 
[RMS 
Not implemented
Not Implemented
Coding error: the number of arcs has changed after node-merging
Malformed phrasebook line:
failed to open phrasebook file 
Loading phrasebook: 
# of keys: 
found invalid synset name '
' in phrasebook
wordnet
found entry without 'syn' field in wordnet phrasebook for '
disable
input
output
cost
norm_cost
status
phrasebook_exact
1000
 1000
string_view::substr
WatermarkDetector2 not run on input origin 
WatermarkDetector2 not supported for sampling rate=
WatermarkDetector2: missing trigger phrase endTime.
WatermarkDetector2: not enough audio cached.
WatermarkDetector2: Trigger phrase not detected
WatermarkDetector2: score=
 detected=
Watermark2Score
Watermark2Detected
Watermark2StartTimeSecs
Threshold value to detect a watermark
anti-notch-offset
Frequency (in Hz) of anti notch offset
notch-width
Frequency (in Hz) of width of notch
notch-freq
comma separated list of notch frequencies
classifier
comma separated list of classifier values
unknown keyword
#remaining_frames for fbank 
 and energy 
 don't match!
mismatch between finished pitch frames and remaining frames+new wav frames: 
 v.s. 
T@"NSString",R,N,V_text
Tf,R,N,V_confidence
precededBySpace
TB,R,N,V_precededBySpace
followedBySpace
TB,R,N,V_followedBySpace
gtmin
gtmax
cdiscount
ndiscount
wbdiscount
kndiscount
ukndiscount
kn-counts-modified
interpolate
write
Mismatch in number of key and value pairs in ScaledDotAttention, got 
 keys and 
 values
Mismatch of key matrix input in ScaledDotAttention, expected 
, but got 
Mismatch of value matrix input in ScaledDotAttention, expected 
SetKeyValueStores needs to be called in ScaledDotAttention for attention to work
<AddQuery>
<QueryTransform>
<KeyTransform>
<ValueTransform>
<OutputTransform>
Reading ScaledDotAttention component
reading query transform failed
reading key transform failed
reading value transform failed
reading output transform failed
<NumberHeads>
Reading MultiHeadAttention component
<SupervisedHeads>
Reading SupervisedMultiHeadAttention component
Reading SelfAttention component
<Attention>
failed to read attention component in SelfAttention
ResetHistoryState for SelfAttention makes only sense if all utterances get reset at the same time
<AverageFfn>
<Gate>
Reading AverageAttention component
reading average feed-forward network failed
done
reading input gate network failed
</AverageAttention>
Recurrent neural networks are not supported inside the average attention component.
ResetHistoryState for AverageAttention makes only sense if all utterances get reset at the same time
Unsupported FST type: 
ngram-count-flags
SRILM ngram-count flags
fst-type
fst format (default: squeezed_acceptor)
fst-basename
basename of FST file (default: bigG)
arpa-lm-output-file-name
output arpa language model file name (default: "")
ngram-counts-output-file-name
output ngram counts file name (default: "")
-text
-vocab
ngram-count-flags is not allowed to contain 
ngram-count-flags is not allowed to write flag: 
other input types not yet implemented
ngram-count
ngram-count failed with status: 
ngram-count failed to generate lm
Built ngram with order 
visitor
free
MutableArcIterator
RmEpsilon
MinimizeEncoded
ArcSort1
Project
addUnseenWords
Add unseen words failed
ArcSort2
Verify
FST verification failed
FST properties incorrect
Convert
FstConvert
handle
squeezed_acceptor
bigG
There are no unseen words in vocab
Encountered more than 1 arc with <unseen>
No arc with <unseen>
numArcsAdded 
 numArcsToAdd 
Incorrect number of arcs added. This is a bug.
Verify: Fst start state ID unset
Verify: Fst start state ID exceeds number of states 
Verify: Fst input label ID of arc at position 
 of state 
 is negative
Verify: Fst input label ID 
 of arc at position 
 is missing from input symbol table "
Verify: Fst output label ID of arc at position 
Verify: Fst output label ID 
 is missing from output symbol table "
Verify: Fst weight of arc at position 
 is invalid
Verify: Fst destination state ID of arc at position 
 exceeds number of states
Verify: Fst final weight of state 
Verify: Fst error property is set
Verify: stored Fst properties incorrect 
(props1 = stored props, props2 = tested)
NGramFst only accepts OpenGRM langauge models as input
Could not identify unigram state.
Unigram state 
 has no arcs.
Number of contexts arcs != number of states - 1
Number of contexts != number of states
Input fst is not structured properly
Structure problems detected during construction
Not enough bits for quantization: 
Malformed file
_quantized
reduced
_transducer
Too much data for reduced file format: 
 missing in new FST!
_acceptor
squeezed
Too much data for squeezed file format: 
Could not align file during write after states
Could not align file during write after arcs
enabled 
 modelLanguage 
 requestLanguage 
Have result
Result is model
Model is compatible with recognizer. Returning it. Elapsed 
Returning nullptr. Elapsed 
 task 
 appName 
com.apple.MobileSMS
Unsupported task or app
Returning nullptr. Elapsed 0
Failed TPLexicon_GetInfo()
could not format word sequence: 
could not get text of word sequence
could not get result
could not get result Alignment 
result could not be deleted
Input not monotonic
Adjacent 'ID'
Adjacent 'DI'
Unexpected character
Invalid alignment string
String is all I's, all D's, or empty
Output not monotonic
Coding error. addAudio() called after endAudio()
(BiasMean|BiasRange|ParamStddev|LearnRateCoef|MaxNorm|MaxGrad|InitTransformType
|GradientNormType|RandomSeed)
 Gate recurrent weights:
 Activation recurrent weights:
  Gate recurrent weights gradient: 
  Activation recurrent weights gradient: 
  Candidate activations: 
  Activations: 
  Candidate activation diff: 
  Activation diff: 
; output dim = 
Gate recurrent weights #rows = 
Gate recurrent weights #columns = 
Activation recurrent weights #rows = 
Activation recurrent weights #columns = 
Saving last activation batch 
v16@?0@"NSURL"8
Unknown protection class: 
Failed to set protection class for path: 
 error: 
Did not get correct batch [
) for frame 
Request for expired frame (
): current frame offset is 
Request for invalid frame (
): you need to check
 IsLastFrame, or, for frame zero, check that the input is valid.
Could not calculate silence posterior for frame=
, current frame offset is=
Silence posterior cache incorrectly calculated rows=
Requested posteriors for realignment do no longer exist.
Realignment model posterior cache is empty, make sure that acoustic model for realignment is configured correctly
Request for invalid frame (you need to check IsLastFrame,
 or, for frame zero, check that the input is valid.
LogLikelihood() must be called before this method as silence posteriors are pre-computed there
audioResultMat
T@"NSData",&,N,V_audioResultMat
audioResultsNumVectors
TQ,N,V_audioResultsNumVectors
audioResultsVectorSize
TQ,N,V_audioResultsVectorSize
EARAudioResultsGenerator
T@"<EARAudioResultsGeneratorDelegate>",W,N,V_delegate
This class is internal to Quasar, and this function is never called
Decoding for only the last utterance failed. Updating recogStatus to success
Sanitization returned empty string
Tokenizer returned empty tokens
Pronguesser returned empty prons for orthography 
orth
freq
profile
LmeDataFactory already initialized.
lme-create.
lme-create
Failed to find 
 in template-map, skipped.
params
lme-create.name-enumerator-map.
.params.
name-scale-map
name-average-cost-map
name-deviation-cost-map
read mmaped lexicon from 
Could not read lexicon data from mmaped source 
can not open 
Cannot open g2p rewrite file 
G2P blacklist does not support rewrite rules
Malformed g2p rewrite file line=
g2p rewrite file contains whitespace line=
Failed to encode g2p rewrite entry in QsrText: 
G2P rewrite rule 
G2P rewrite size=
LmeDataFactory initialized.
LmeDataFactory not initialized.
Starting LME for new speaker.
AOT LME data has already been provided.
LME data has phone set version 
 which is different from model phone set version 
Adding AOT LME for speaker. lmeDataStatus=
, nextLmeStartSymbolKey[AotLme]=
Multipe LmeType in single user data is not supported.
is UserData empty? not able to tell which lmeType from userData which has size: 
generate Lme Data for lmeType: 
Serializing.
Deserialization test failed. Cannot properly serialize this data.
Deserialization test passed.
User data is empty
Lme enumerating return NothingToDo, errorCode=
Lme enumerating failed, errorCode=
Failed to build the LME fst using the direct method
_num_word_homophones=
_num_fst_paths=
_num_word_homophones
_num_fst_paths
Failed to build the LME fst
LmeEnumeratingTimeMs=
, lmeFstCreatingTimeMs=
, maxPronsPerWordSeen=
LmeEnumeratingTimeMs
LmeFstCreatingTimeMs
Created lmeData.symTable
lmeData.symTableFirstKey = 
 lmeData.symTableLastKey = 
Ignoring user data key 
Getting LME data for userDataKey = 
 quasarTemplateName = 
No supported templates were found in userData. Only the templates specified under 
"supported-lme-template-list" in the json config file are supported.
Skipping name containing bad word:
Skipping name containing bad word
Could not find enumerator for quasar template 
Enumeration type:
Word has empty orthography
Word with hex sequence 
has frequency 
Word has no prons, orthography=
Word has pron with 
 phones, exceeds maxPronLen=
, orthography=
Rewriting from=
 to=
Could not read magic header from 
Magic header was wrong in 
Could not read the number of words from the mapped file 
Could not read the offset region in the mapped file 
base-dict-file
Base lexicon file
base-dict-mapped-file
Base lexicon file, mmap-able (overrides text lexicon file)
lme-scale
Scaling factor for the LME FST
lme-average-cost
the cost of entering an LME FST
lme-deviation-cost
the cost of deviating from an average size LME class
supported-lme-template-plist
Comma-delimited LME template names, ordered by enrollment priority
supported-lme-template-list
Comma-delimited LME template names
contacts-template-name
Quasar template name for user's contact names
appcontacts-template-name
Quasar template name for 3rd-party app contact names
max-num-enumerated-contacts
Maximum number of contacts (e.g. in NT-contact and NT-appcontact) to allow in a user's profile
just-in-time-template-name
Just in time LME template name
template-map
Mapping from ACE category names to Quasar template names
name-enumerator-map
Mapping from Quasar template names to enumerator names
max-prons-compound-word
Maximum number of pronunciations for compound words
During G2P, empty prons will be returned for tokens listed in this file. File format: same as a lexicon text file (not hat encoded) with the prons removed so that only one column remains per line. Order does not matter.
g2p-rewrite-file
File format: If a rule is in the form of 'A -> B' (whitespace optional), then rewrite token A to token B before doing G2P. If a rule is in the form of 'A', then rewrite A to an empty string. This 2nd rule has the same format and effect as g2p-blacklist entries and therefore makes g2p-rewrite-file a superset of g2p-blacklist.
LME scale for specific Quasar template names
the cost of entering an LME FST for a specific template
the cost of deviating from an average size LME class for a specific template
Exceeded enumeration limit. Stopped enumerating.
\NT-buzz
\NT-contact
\NT-appcontact
fallback
both
phrase_book_only
unknown phrase-book-mode: 
integrated
rescore_bpe
rescore_word
unknown lm-mode: 
gnmt
unknown 'norm-mode': 
specifying both 'norm-cost' (old parameter name) and 'norm-mode' (new name) at the same time is not allowed.
nbeam
best
finished_score
unknown stop-mode: 
Using meta data from phrasebook loaded inside of PDec - deprecated in MT production!
use shared phrasebook: 
load phrasebook: 
Cache phrasebook: 
failed loading phrasebook: 
<constructor argument>
Model file name not supplied (configuration value 'model-file' is empty)
PDecTranslatorBlock does not support stream-decoding
Failed to read lm fst from: 
Invalid entry terminating ReadRaw : 
 phrasebook entries
Apply BPE source : 
Apply BPE target : 
enable
Failed to read model from 
Already mapped from a file
Using the special symbols ids <unk>=
, <s> = 
, </s> = 
Applying log to output probs 
Has BPE Model
No embedded BPE Model
Configuring multilang decorator
<HasPhraseBook>
# PhraseBook entries 
No phrasebook in the model
Reading phrasebook
<PhraseBook>
num_entries 
</PhraseBook>
# of keys 
Extract quality transform
Failed to extract quality transform
Quality transform : 
remove-softmax must be set for quality transform, setting to true
Reading tag filters from : 
Nbestlist cannot be null
Total # of phrasebook matches : 
Word level LM re-scoring
Applying confidence scores to n-best list
Decoder beam (
) should not be negative.
Decoder confidence threshold (
) should be in the range [0, 1000].
Decoder maximum nbest list size (
model does not support the use of src/tar tags
A Both type TagFormat requires non-empty source and target tags
SrcTag cannot be empty for TagFormat::Src
TarTag cannot be empty for TagFormat::Tar
<src-
> <tar-
Source locale 
, Target locale 
 source tag 
 target locale 
, # of phrasebooks 
BPE input 
FindInPhraseBooks # 
Phrasebook fallback match
Phrasebook locale match
, phrasebook idx=
Re-decode without LM 
Couldn't find symbol 
 or <unk> UNK symbol
Input : 
Select decoder for 
Selected 
Decoder for 
 not found
Try to find decoder for 
 not found; random decoder selected
No tar tag specified but required by model; random decoder selected
Greedy decoding
Beam decoding
input_batch_idx: 
hyp_idx: 
Final word in hyp list
Skipping target eos symbol
Nothing left in heap
Beam decoder hit maximum sequence length
Pruned all hyps, nothing left to expand
dropping worse identical hyp; score-diff: 
using lattice state:
Adding invalid arc 
At output position 
, # surviving hypotheses: 
No hyps finished, setting 
 partial hyps to final
Setting longest vetoted translation as best 
# of cached states 
Didn't extract any paths from the lattice
Initializing NbestCompare. alpha: 
, sigma: 
Looking for UNK symbol 
UNK label : 
No UNK symbol in translation model vocabulary
Language model does not have output symbol table
LM UNK ID 
Language model does not have OOV symbol : 
 in LM
Word lookup failure : 
 (label=
Old Cost = 
, New cost = 
, Hyp = 
 finalcost=
Error converting BPE to word list 
Not applying BPE to target
Alignment cost 
decoder
vetoed
stopped
phrasebook_fuzzy
subword string
TextSanitizer is already initialized
[^\u0000-\uFFEF]
Failed to compile special characters regex
(\s)+
Failed to compile duplicate spaces regex
[\p{C}]+
Failed to compile control characters regex
TextSanitizer is not initialized
Empty string received.
wstring_convert failed for text: 
Failed to normalize 
Could not open UTF8: : 
Failed to replace unicode characters in range [\u0000-\uFFEF]: 
Failed to remove some special characters: 
Failed to remove redundant space characters: 
Failed to remove control characters: 
Intermediate basic sanitization result=
If silence posteriors are available, trigger only when the average silence posterior is >= this value. Otherwise, ignore this value.
silence-window
Sliding window size (in frames) for silence posterior average. Silence posterior is ignored if this value is <= 0.
stable-partials
Trigger only after the number of stable partial results (one per frame) exceeds this value. (Eager's stabilization is unrelated to ResultStreamStabilizer stabilization). Regardless of this value, the trigger always looks for at least 1 stable partial result.
early
backoff
max-triggers
Ignored if <= 0: Maximum number of eager result triggers. Once exceeded, no more eager results are created.
require-silence-posterior
If true, disable eager for requests that don't have silence posteriors. Defaults to true since 'false eager results' increase without silence posteriors. Set this to false for experimentation or if the number of 'false eager results' is acceptable.
Debug mode: require-silence-posterior=false and trigger every frame without affecting state machine
{silencePosterior=
 silenceWindow=
 stablePartials=
{early=
 backoff=
 maxTriggers=
 requireSilencePosterior=
 debug=
{frame=
 finalActive=
 words=[
 ids=[
 trailingSilence=
 silencePosterior=
 allowTrigger=
n must be positive
init() was not called
Cannot compute average of 0 items
ENABLED 
 hasSilencePosterior=
trigger=
 numTriggers=
 thisFrame=
 avgSilPost={
 numStable=
INVALID 
INVALIDATED 
TRIGGER 
TRIGGERED 
Invalidate and trigger shouldn't happen on the same frame
Bad state transition: triggered 
silence phone probability must be [0,1) 
invalid silence phone value <
the input lexicon is empty
Cannot dereference iterator that is already at the end
Cannot increment iterator that is already at the end
[OOV context]
H-MAXENT 0.1
# %ld %ld %ld %ld
Reading 
 contexts...
<word> <weight> expected
format error in H-MAXENT file
H-MAXENT 0.1
# %ld %ld %ld %ld
%s %f
Counting counts of order 1 
Counting counts of order 
Contexts:
Creating feature contexts...
Indexing contexts of order 
Creating reverse context index...
WARNING: Data contains n-grams that cannot be properly mapped the nodes of the Maximum Entropy model structure;
         If you are adapting a prior model, use also adaptation data (with weight 0) for creating the prior model
Creating count contexts...
Coding error: SyncDecoder 
 has already been initialized.
Ignoring unknown SyncDecoder type "
Recognition will crash if you try to use it
mt-decoders
blocks
graph
block-definitions
block
block-type
PDEC
missing source or target locale, skipping parsing language-pair-specific-settings
block definition '
' (referenced in '
]') not found
<overlay-settings>
Changing phrase book mode using command line overlay causes use of previously ignored translation model file: 
.graph
missing source or target locale!
Unknown block definition name: 
Machine translation configuration for task '
' not found!
Assuming legacy (non-graph) config format, deprecated for production MT configurations!
missing source or target locale, skipping parsing 
No language pair specific settings found (this might be a configuration error).
Config file does not support task: 
Config file does not support language pair: 
__NONE__
mt-quasar-config.json
siri
EMTTranslator.mm
Task string cannot be nil
com.apple.sequoia
v32@?0@"SFTranscriptionSegment"8Q16^B24
callbackQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_callbackQueue
framework
<unspecifed>
<unknown>
Stream failure detected.
state ID
FstPrinter: Integer 
 is not mapped to any textual symbol
, symbol table = 
, destination = 
arc input label
arc output label
 000000000000
ConstantEventMap::Write(), could not write to stream.
Could not map value 
 for key 
Multiple values map to the same point: this code cannot 
handle this case.
TableEventMap::Write(), could not write to stream.
Value 
, for key 
, cannot be mapped.
SplitEventMap::Write(), could not write to stream.
SplitEventMap::Read, NULL pointers.
EventMap::MaxResult(), empty result
Empty phone in phonetic sequence: 
Could not interpret 
 as a phone. Found in phonetic sequence: 
weight must be between 0 and 1 inclusive (weight=%f)
total weight must be between 0 and 1 inclusive (weight=%f, current total weight=%f)
totalWeight
Tf,R,N,V_totalWeight
word 
 has multiple class memberships
class 
 expands to string of more than one word
Quasar Itn missing in configuration
T@"NSString",C,N,V_language
min-voicing-duration
Minimum duration of voicing
acoustic-feature-window-width
Minimum width of the normalization window for acoustic audio analytics features
No audio features generated. Rejecting utterance.
Audio analytics finished..
 score= 
Cycles detected in lattice.
Invalid list of region specifiers provided 
Using non-terminal regions for combination from 
Splitting into labels : 
 Check start 
 end 
 against start 
 lab in lat 
 lab in check 
Found state 
 id 
 start 
 For MBR start 
 distance is 
Match 
not_in_static_vocab
 Find Overlapping With 
Word with ID = 
 does not exist in word map. Is a dynamic vocabulary being used?
No arc to continue with
Recomputing TBP on Ref Interval 
 for arc on 
Recomputed TBP is 
 post score avg is 
Compact Lattice Current state=
 ARC ilabel: 
 olabel: 
 weight1: 
 weight2: 
Next State=
 duration = 
 word is 
Original Duration Was 
 without silence it is 
Warning - state Time Mismatch - 
Time = 
 not in state posterior map...
Couldn't find state 
 defaulting posterior to 0, w1=
 w2=
No states in the word posterior computation - this may be because the word has 0 duration (could happen for class LM)
Utterance ID is 
Needed to find 
 actually only found 
Couldn't find arc
Warning: MISMATCH BETWEEN LENGTH OF 1-BEST and LENGTH OF CONFIDENCE VECTOR
Finished generating 1-best word-level confidence features for 
 words in utterance 
Add Candidate: 
 to candidate/confusion set
Candidate Update: 
Confidence score @ word 
 MBR SCORE IS 
Confidence score @ alt word 
Using special symbol for silence = 
Adding hypothesis number 
 additional cost for non 1-best 
Adding 1-best [
] pen= 0.0 score= 
Add 1-Best word 
 confidence 
Adding alternative [
] pen= 
Was not able to topologically sort lattice (cycles found?)
INIT
MODEL
No Confidence Model Supplied.
Read in Confidence Model , added 
Scaling feature 
 with value of 
 by weight = 
Warning - confidence is NaN or inf, or will be inf in log - confidence model could be bad/compromised. Defaulting to 1.0
Confidence score is 
Rank in list = 
 Orig = 
 sc= 
 HIGH 
p_avg
p_max
p_min
p_geo
comb_score
lm_post
am_post
n_match
n_intersect
p_wcr
p_uni_lm
p_avg_low
p_avg_high
p_avg_diffhigh
p_avg_difflow
rank_score
low_rank_score
high_rank_score
delta_low
delta_high
p_mbr
p_fan_out
n_fan_out
p_fan_in
n_fan_in
n_wrd_inutt
avg_depth
avg_post
avg_ac
avg_lm
avg_conf
avg_like
avg_likelow
avg_likehigh
avg_ac_like
avg_ac_likelow
avg_ac_likehigh
ob_start
ob_dur
ob_p_avg
ob_p_max
ob_p_min
ob_p_geo
ob_comb_score
ob_lm_post
ob_am_post
ob_n_match
ob_n_intersect
ob_p_wcr
ob_p_uni_lm
ob_p_avg_low
ob_p_avg_high
ob_p_avg_diffhigh
ob_p_avg_difflow
ob_rank_score
ob_low_rank_score
ob_high_rank_score
ob_delta_low
ob_delta_high
ob_p_mbr
ob_p_fan_out
ob_n_fan_out
ob_p_fan_in
ob_n_fan_in
cand_p_avg
cand_p_min
cand_p_max
is_eps
alt_hyp_overlap
hyp_sub_alt_prev
hyp_sub_alt
hyp_sub_alt_next
alt_sub_hyp_prev
alt_sub_hyp
alt_sub_hyp_next
alt_lthalf_hyp
hyp_lthalf_alt
alt_in_prev
alt_prev_score
alt_in_next
alt_next_score
alt_tbp
ob_tbp
num_in_confset
prev_in_ob
next_in_ob
prev_best_score
next_best_score
cand_avg_p_avg
cand_avg_tbp
cand_avg_p_max
cand_avg_p_min
cand_wrd_len
sub_compound_left
sub_compound_right
is_lme_word
ob_is_lme_word
alt_has_lme_word
is_one_best
phonetic_dist_to_ob
min_phonetic_dist_confset
Too many states on the stack. There may be a cycle.
LabelsToUTF8String: Bad code point: 
LabelsToUTF8String: Invalid character found: 
Context size mismatch, ilabel-info [from context FST is 
, context-dependency object expects 
phone == 0.  Possibly you are trying to get a reversed FST with a non-central "central position" P (i.e. asymmetric context), but forgot to initialize the ContextFst object with P as N-1-P (or it could be a simpler problem)
phone == 0.  Some mismatch happened, or there is a code error.
GetHmmAsFst: context-dependency object could not produce 
an answer: pdf-class = 
 ctx-window = 
.  This probably points to either a coding error in some graph-building process, a mismatch of topology with context-dependency object, the wrong FST being passed on a command-line, or something of  that general nature.
tree did not succeed in converting phone window 
ConvertAlignment: could not map phone 
ConvertAlignment: error converting alingment, possibly different topologies?
AddTransitionProbs: invalid symbol 
 on graph input side.
 on lattice input side.
AddSelfLoops: graph already has self-loops.
Label 
 neither 0, nor a disambiguation symbol 
(#transition id = 
T@"NSLocale",R,N,V_locale
T@"NSArray",R,N,V_tokens
lowConfidence
TB,R,N,V_lowConfidence
metaInfo
T@"NSString",R,N,V_metaInfo
cache-size
Cache size for lazy replace operation
enable-lme
Enable LME
lme-sym-start-key
Starting key value for LME symbols
classLM-fst-file-list
list of classLM FST filenames, use comma to separate multiple ones
classLM-template-list
list of classLM templates, in the same order as the classLM-fst-file-list
" in base symbol table
Cached template ID 
 for 
The number of classLM templates = 
, which does not match the number of classLM Fst files = 
Expected range start to be symbol id 1 and a phone word: 
Expected range end to be a disambiguation symbol: 
Disabling small LM pruning for symbols [
:lmeLoadingTime
LME data stream 
 is null.
 has phone set version 
. This data stream will not be used.
Bad LME data (empty): stream=
, symTableFirstKey=
, symTableLastKey=
Bad LME data (invalid last key): stream=
, symTable->AvailableKey()=
 in blob is not supported by datapack.
 in blob uses different enumeration type (
) in datapack.
G2P model version 
 in blob is older than datapack's version 
Ignoring unsupported template 
 in stream # 
geoLocationStatus
ClassLM template 
 assigned to FST from 
classlm_origin[
geoContextFound
geoLastRegionIdWasCached
geoLastRegionIdCacheMiss
Using decoder-specific classLM slot for template=
, location-specific slot not available
Filtering out unsupported classLM template=
Japanese derived
Unable to get character type for some characters in the orthography
Lattice score cache indices = 
 vals = 
Supplied frame 
 is out of range of cache which is in [0,
Pdf 
 is not in cache for frame 
lm-scale
Scaling factor for LM probabilities. Note: the ratio acoustic-scale/lm-scale is all that matters.
 frames
forced alignment source
forced alignment target
PDecForceAlignBlock 'source' input must not be empty
Inconsistent alignment dimension!
invalid evaluation task specification 
invalid data specifier: 
invalid metric specifier: 
invalid optimization specifier: 
select-based-on
optimization-method
best-weight
weight list contains invalid range specification (should be e.g."0.0:0.2:10.0")
weight list range specification exceeds maximum number of weights: 
weight list should be comma-separated list of maximum size 
latitude
Latitude used in evaluation
longitude
Longitude used in evaluation
evaluation-metrics
List of metrics calculated during evaluation (e.g. dev-ppl, test-wer)
select-model-based-on
Metric based on which the best model is selected (i.e. usually dev-ppl)
Method to find the best model: "interpolation"(default) or "sweep-weights"
sweep-weights
Range of interpolation weights tested with optimization "sweep-weights"
min-audio
Required number of audio files
max-audio
Maximum number of audio files
remove-unk
If true simply removes all OOVs from input
min-weight
If final weight <= this value, model will not be used
max-weight
Weight will get clipped to this value when saving model
min-pass-rate
If >= 0: Fail the evaluation if ANY computeTextStats() call (1) returns failure OR (2) returns success but doesn't process enough utterances correctly to meet this threshold
min-unadapted-dev-ppl
If >= 0: Model will not be used if this condition is not met
max-unadapted-dev-ppl
min-best-weight-dev-ppl
max-best-weight-dev-ppl
min-dev-ppl-abs-improvement
min-dev-ppl-rel-improvement
task-name
Name of the task to lookup, e.g., Dictation
decoder-chain-name
Name of the decoder for the given task from which to take the bigG FST, e.g., msg
dev-ppl
Model selection can only be done on a single metric (select-model-based-on)
invalid choice of min-audio and max-audio
sweep-weights specified in wrong format
Adding 0.0 to sweep-weight list for optimization method "
Adding 1.0 to sweep-weight list for optimization method "
std::is_sorted(evalWeightsList.begin(), evalWeightsList.end())
minWeight >= 0.0 && minWeight <= 1.0 && maxWeight >= 0.0 && maxWeight <= 1.0
First task should be on tuning on dev set
For interpolated models, we should evaluate weights 0 and 1
Task failed
model-selection
bestWeight (
) exceeds maxWeight (
). Clipping to maxWeight
) is below minWeight (
). Model will not be used
PPL checks failed
Running evaluation task 
 with 
 utterances
no text data available for 
computeTextStats failed
Pass rate: 
 passes: 
 total: 
Pass rate too low
perplexity interpolation failed for weight 
no audio data available for 
invalid evaluation metric
computing text stats for weight 
 FAILED
perplexity calculation failed, numTokens is 
bestWeights should be empty
best weight estimation for perplexity interpolation failed
best weights have wrong size or don't sum up to one
invalid optimization method
model selection returned an invalid weight
best weight: 
 PPL: 
checkPPL 
: No CorpusStat
: ppl 
 minPpl 
 maxPpl 
checkPPL: absImprovement 
 relImprovement 
lm-personalize.evaluator
num-nbest-hyps-to-expect-at-input must be provided for using model-based confidence
Filename for confidence model file. Each line must have the format: intercept <value> OR, <FEATURE> <WEIGHT> [ <FEATURE-MEAN> [ <FEATURE-STD> ] ](feature mean and std values are both optional, could be provided for feature normalization)
token-unigram-freqs
Name of the file with token unigram frequencies
num-input-hyps
number of hypotheses to expect as input to the confidence feature extractor
num-output-hyps
number of hypotheses to produce confidence values for
Unknown option "-%s";
  type "%s -help" for information
Warning: %s option "-%s" needs an argument
Warning: option "-%s" got a non-numeric argument "%s".  Using default: %d
Warning: option "-%s" got a negative argument "%s".  Using default: %u.
Warning: option "-%s" got non-floating-point argument "%s".  Using default: %lg.
Usage of command "%s"
 -%s%-*s %s
Default value: %d
Default value: %u
Default value: %lg
Default value: "%s"
 -help%-*s Print this message
%s: can't represent the time "%s".
%s: can't parse "%s" as a time.
total memory 
, used 
, wasted 
allocations of size 
allocations of size >= 
<NullWord>
<ContextSize>
<SymbolToWord>
<WordToSymbol>
<PhoneWordSymbol>
Tried to add overlapping and/or out-of-order symbol table to symbol table list: 
symTableFirstKey=
, previous symbol table's last key=
Word ID 
 not in symbol table 
 with start key 
Got word: 
) from symbol table 
 is already in the symbol list - indices in different symbol tables are not distinct
Found an empty LME word, which should not happen
seeva-greedy
model file
list of vocab
transform file
SeevaModel/__QNNI__source_input
SeevaModel/__QNNO__prediction
<spc>
@[^#]*#|#[^@]*@
EARSyncPSRAudioProcessor
T@"<EARSyncPSRAudioProcessorDelegate>",W,N,V_delegate
<LeftContext>
<RightContext>
<SourceReversed>
<NoTargetConcat>
<ReattachTarget>
<DotProductRelation>
 (SourceStateDimension|MaxAttentions|LeftContext|RightContext)
component is not initialized, left and right context is 
The target input is concatenated. component has input dim 
The target input is not concatenated. component has input dim 
 , and output dim 
, and you requested to reattch the target, however, 
the internal component has output dim 
component has output dim 
 does not match the internal component's output dim 
the maximum attention is 
 , that does not match the left_context + 1 + right_context, you defined left/right context as 
the source state must have the same dimension as the input dimension of the component if want to take the dot product between them
if not taking the dot production relation from the source and target, you must at least concatenate or reattach the target
Internal error, unexpected pixel size 
Cannot open bitmap file 
Unexpected magic 
Bitmap width must be positive but was 
Bitmap height must be positive but was 
Whitespace expected before binary data
PGM header suggests different file size than actual size, expected=
 actual=
Could not map file 
 into memory
Mapped a PGM bitmap fileName=
 width=
 height=
 maxGreyValue=
latency
numFramesProcessed
totalWallTime
acousticLatency
contextModelLatency
localeSpecificMetrics
languageCode
posterior
messageLanguageTaggingLatency
isConfident
detectedLocale
conversationMessagePriors
lastMessageLanguage
numAcousticRuns
acousticScores
Invalid locale string given 
Logging LDContext
priors=
dictation_locales=[
current_dictaion_locale=
was_language_toggled=
multilingual_keyboard_locales=[
keyboard_convo_locale_priors=
keyboard_global_locale_priors=
previous_message_locale=
global_last_keyboard_used=
dictation_locale_priors=
window-size
The number of frames to be considered per decision. In flexible input size, this is the minimum window.
feature-dim
The dimension size of the features.
languages-list
Comma separated list of languages
compiled-model-file
The name of the compiled model file
model-input-name
The name of the key for the model input
model-output-name
The name of the key for the model output
use-flexible-model
Whether or not the model accepts flexible (variable) input size.
max-window-size
The maximum size window for processing. Only works with flexible input size enabled.
use-cpu-only
Only use the CPU for inference
send-only-final-result
Do not send incremental results, send only the final result. Fixed input will always only send the final result.
minimum-confidence
For flexible input size, the minimum confidence for sending early results back. Only works with flexible input size enabled.
prediction-interval
The interval which we should make decisions (-1 is only once). Only works with flexible input size enabled.
ui-minimum-confidence
Determines whether or no the UI should consider the result non-confident. Should be greater than or equal to minimum-confidence.
input-tensor-shape
The shape of the input tensor specified by (dims, row index, col index).
Only use prediction interval with variable size input.
Max window size much be configured for flexible model
Must unable useFlexibleModel to have variable input size.
Maximum window size configured to be less than window size
Shape of the input tensor must be specified through (dims, row index, col index).
Input tensor row index must be non-negative and less than input tensor dims.
Input tensor col index must be non-negative less than input tensor dims.
Context provided no locale priors.
No acoustic posteriors.
Using dummy context model. Since acoustic posteriors are equal, defaulting to dictationLocales and currentDictationLocale from the context.
core-ml
acousticLanguagePosteriors
dictationLocales
currentDictationLocale
wasLocaleToggled
multilingualKeyboardLocales
keyboardConvoLocalePriors
keyboardGlobalLocalePriors
previousMessageLocale
dictationLocalePriors
path to the model file
supported-locales
the locales understood by the model
supported-languages
the languages understood by the model
model-file-format
the format of the model file, must be "core-ml"
model-input-names
the input features expected by the model
the output feature that contains the locale posteriors
Invalid model file format "
Model input names contains duplicates
Invalid context-aware input feature name "
language-detectors
Configuration is incorrect. Only two components are supported.
ld-frontends.
ld-inference-model.
Something went wrong initializing the model.
override-locale-language-map
ld-context-aware-model
 found in config file, but no ContextAwareLDModelFactory was provided.
Something went wrong initializing the ContextAwareLDModelConfig.
Invalid sampling rate 
given.
Resetting for new request.
Version 118 or greater is required.
Unable to reset model.
 frames of audio.
Data is empty
Reached maximum window size. Treating this as the end of audio.
Not enough features yet to meet minimum window size.
Waiting until the next predictionInterval to run.
Running LanguageDetector with 
Something went wrong in LD inference.
Error in processing acoustic result.
Error running acoustic model.
No valid window found. Running contextual model based on equal acoustic priors.
Contextual model failed to run properly.
Language detector max confidence: 
Metrics for locale not in input: 
No context.
Empty priors.
If dictation priors are defined, then dictation locales must be.
4, 1, 2
Symbol: '
' not found in input symbols table.
 Mapping to null...
Not enough space
Invalid UTF-8
Invalid code point
bitset set argument out of range
LmeDataNotChecked
LmeDataOK
LmeDataNull
LmeDataOKButVersionOutdated
LmeDataVersionUnsupported
LmeDataPhoneSetMismatch
LmeDataCorrupt
Unknown
LmeNotUsed
LmeUsedNotRecognized
LmeUsedAndRecognized
, phoneSeq: 
, startSil: 
, confidence: 
, ipaPhoneSeq: 
OriginalToken: 
CandidateToken: 
There should be one cost for each result choice
concatNbest aChoices=
 bChoicesOrig=
 bChoices=
concatNbest[
 cost=(
 aIndex=
 bIndex=
Inconsistent number of columns. Expected 
 got 
Failed to open file: 
max-slot-depth
If >0, the max number of words to allow in each slot of the confusion network.
alt-confidence-model-file
eps-confidence-model-file
Filename for epsilon confidence model file, format <FEATURE> <WEIGHT> (one per line)
scale-low
Acoustic scaling factor (divisor) for low-end, eg, 2 (for a standard divisor of 12 = 0.08333)
scale-high
Acoustic scaling factor (divisor) for high-end, eg, 20 (for a standard divisor of 12 = 0.08333)
acoustic-scale
Scaling factor for acoustic likelihoods, default 0.08333
do-acoustic-stability
Turn computation of acoustic stability features (at multiple acoustic scales) on/off with true(default)/false.
do-process-alternatives
Control whether or not to process alternatives in the sausage network, or run in 1-Best mode, using true(default)/false.
do-process-sausage
Turn computation of features derived from the structure of the sausage network on/off with true(default)/false.
do-process-rank
Turn computation of rank-based features (at multiple acoustic scales) on/off with true(default)/false.
do-process-faninout
Turn computation of contextual posterior features related to fan-in and fan-out context on/off with true(default)/false.
do-process-post
Turn computation of lattice state posteriors (used for time-based-posterior and other measures) on/off with true(default)/false.
Turn computation of confidence score from the model off, effectively generating the time-based posterior as the confidence score,turn on/off with true(default)/false.
do-add-epsilon
Turn computation of epsilon confidence score on, this will use the supplied epsilon confidence model parameters score,turn on/off with true(default)/false.
decode-mbr
If true, do Minimum Bayes Risk decoding (else, Maximum a Posteriori)
number of NBest hypotheses to produce hypotheses (with confidence) for.
Prune incoming lattice to this beam
Finished initializing OnlineLatticeConfidenceDecoder.
sausage-labels
symList.size() != symListWords.size()
Note: Have trimmed confusion network slot depth from 
tokenDur: 
speechDur: 
%u blocks of %u-word chunks
T{shared_ptr<kaldi::quasar::LmHandle>=^{LmHandle}^{__shared_weak_count}},R,N,V_handle
leftNnetWordmapExist || rightNnetWordmapExist
Malformed wordmap files. fileBasename=
, fileExtension=
Could not read the NNLM word map file 
Malformed LM neural network file name, fileBasename=
found object in map for fst 
ngram_quantized
reduced_transducer
reduced_acceptor
reduced_quantized_transducer
reduced_quantized_acceptor
squeezed_transducer
squeezed_quantized_transducer
squeezed_quantized_acceptor
Reading FST: unsupported FST type: 
loaded 
 pages of 
NGramFst::Read: Alignment failed: 
NGramFst::Read: Read failed: 
ReducedFst::Read: Alignment failed: 
ReducedFst::Read: Read failed: 
SqueezedFst::Read: Alignment failed before aligning states region: 
SqueezedFst::Read: Alignment failed before aligning arcs region: 
SqueezedFst::Read: Read failed after reading states and arcs: 
Falling back to slow loading for 
SqueezedFst::Read: Alignment failed before aligning final states region: 
SqueezedFst::Read: Read failed after reading final states: 
silenceFramesCountMs
Td,N,V_silenceFramesCountMs
silenceProbability
Td,N,V_silenceProbability
silenceDurationMs
Td,N,V_silenceDurationMs
processedAudioMs
Td,N,V_processedAudioMs
EARSPG: SilencePosteriorGenerator Config file does not exist at %@
resetForNewRequest
T@"<EARCaesuraSilencePosteriorGeneratorDelegate>",W,N,V_delegate
 or 
<Function>
<OutputTensor>
Not tested yet
Can't deal with this yet
CoreML feature provider creation failed: 
CoreML evaluation failed: 
Output was not a multiarray: 
Asked for float32 of a non-float32 buffer
CoreMLTensorData copy failed: 
Copy failed: 
Asked for int32 of a non-int32 buffer
CoreMLTensorData create failed: 
unsupport matrix data configuration
Could not make MLMultiArray: 
not supported MLMultiArray data type: 
<FiltXLen>
<FiltYLen>
<FiltXStep>
<FiltYStep>
<PadX>
<PadY>
 (ParamStddev|BiasMean|BiasRange|FmapXLen|FmapYLen|FiltXLen|FiltYLen|FiltXStep|FiltYStep|ConnectFmap|LearnRateCoef|BiasLearnRateCoef|RandomSeed|GradientNormType|MaxGrad)
input_dim_ % (fmap_x_len_ * fmap_y_len_) == 0
output_dim_ % (out_fmap_x_len * out_fmap_y_len) == 0
filters_->NumRows() == num_output_fmaps && filters_->NumCols() == num_input_fmaps * filt_x_len_ * filt_y_len_
wei_src.Dim() == NumParams()
 OutSizeX:
 OutSizeY:
 InFmaps:
 OutFmaps:
Performing vectorization of convolutional 2d component
Done  vectorization of convolutional 2D component
Convolutional2DComponent needs workspace set to perform back-propagation
Unsupported BNNS filter weight arrangement
It did not work
BNNS only supports one batch
Unsupported
After assign, Convolution filter has padding? 
Reading Whe_
Whe_.Dims() 
Reading Whd_
Whd_.Dims() 
Reading Whc_
Whc_.Dims() 
Handover is not supported for stream input.
Model type requires full handover.
BidirectionalEncoder is not supported for stream input.
Un-supported model type : 
Left symbol sequence : 
 (# 
Right symbol sequence : 
Empty source/target sentence. Skipping alignment.
 including </s>) 
Constrained Softmax with force alignment decoding is not Supported!
osyms
<SymbolTable>
</SymbolTable>
<ModelType>
Full ModelType 
Undefined Torch model type
ModelType 
TorchN
TorchM
TorchT
TorchF
Unsupported Torch model type : 
Processing token 
Found BPE token
SHORTLIST
Found SHORTLIST token
TMPATT
Found TMPATT token
CHILD
PyTorch
Found PyTorch token
DotT
Found DotT token
AddTag:
Extracted add tag : 
AddTag value 
TagFormat:
Extracted tag format : 
TagFormat value 
ShareEmbed
Found shared embeddings token
EncPos
Found encoder position embedding token
DecPos
Found decoder position embedding token
Found add beginning of sentence tag
AddSrcEos
Found add end of sentence tag
AlignModel
ShiftedAlignments
MultipleDecoders
Found multiple decoders token
Unknown model sub tag 
dot attention 
<NumDecoders>
<DecoderLanguage>
<HandoverCellStateOnly>
<HasHandoverLayer>
Handover layer not supported with PyTorch models 
 Cell handover 
 Has handover layer 
<HasInputSymbolTable>
Has input symbol table 
isyms
Embedded input symbols could not read
PyTorch require symbol table
Special input symbol(s) not defined <s> </s> <unk> 
Overridding default input symbols <<unk> = 
, </s> =  
<HasOutputSymbolTable>
Has output symbol table 
Embedded output symbols could not read
PyTorch requires symbol table
Special output symbol(s) not defined <s> </s> <unk> 
Overridding default output symbols <<unk> = 
Trying to read embedded BPE model 
Number of BPE entries : 
Trying to read Shortlist
Searching for SupervisedMultiHeadAttention component
Done reading model 
use coverage penalty 
number of frames in each batch, if <0 will feed whole speech in one batch
encoder-only
only streaming the encoder, no partial results
length-penalty-stream
if >= 0, use this value as length penalty during streaming. Otherwise use the value in the graph
if > 0, use this value as the coverage penalty. Otherwise use the value in the graph
cover-pen-ceil
the maximum coverage penalty
cover-pen-step-size
dynamically adjusting coverage penalty with this step size
silence-thresh
if > 0, turn on dynamic coverage penalty when encounter this amount of silence
min-input-count
if > 0, set the minimum number of frames to start streaming. Otherwise use the value in the graph
min-input-left
if > 0, set the minimum number of frames for leftover during streaming. Otherwise use the value in the graph
min-aln-weight
if > 0, set the minimum alignment weight during streaming. Otherwise use the value in the graph
min-init-aln
if > 0, set the minimum initial peak alignment value for the streaming. Otherwise use the value in the graph
min-cont-aln
if > 0, set the minimum continuous peak alignment value for the streaming. Otherwise use the value in the graph
aln-step-size
reduce the min-aln value by this size to increase streaming
min-aln-floor
the aln-value floor when reduction happens
max-input-count
if > 0 && < received_frames, reduce min-aln value to generate partial result if not already so
count-step-size
adjust the min-aln value according to this frequency
init-stable-tokens
number of tokens needed for stablizing the streaming inference at the initial stage
cont-stable-tokens
number of tokens needed for stablizing the streaming inference
dynamic-stable-tokens
turn on dynamic stable tokens to encourage streaming
min-token-floor
the stable token floor when reduction happens
if > 0, use this beam at the utterance end. Otherwise use the value in the graph
if > 0, scale the LME FST score. Otherwise use the value in the graph
if > 0, scale the nonLME arc score when LME is active. Otherwise use the value in the graph
<Topology>
</Topology>
<TopologyEntry>
Reading HmmTopology object, expected </Topology> or <TopologyEntry>, got 
<ForPhones>
Reading HmmTopology object, unexpected end of file while expecting phones.
</ForPhones>
Reading HmmTopology object, expected integer, got instead 
</TopologyEntry>
<State>
Expected </TopologyEntry> or <State>, got instead 
States are expected to be in order from zero, expected 
<PdfClass>
<Transition>
<Final>
You are trying to read old-format topology with new Kaldi.
</State>
Reading HmmTopology,  unexpected token 
Phone with index 
 appears in multiple topology entries.
HmmTopology::Check(), empty object.
HmmTopology::Check(), phone has no valid index.
HmmTopoloy::Check(), entry with no corresponding phones.
HmmTopology::Check(), cannot only have one state (i.e., must have at least one emitting state).
HmmTopology::Check(), last state must have no transitions.
HmmTopology::Check(), last state must not be emitting.
HmmTopology::Check(), negative or zero transition prob.
We do not allow any state to be nonemitting and have a transition to the final-state (this would stop the SplitToPhones function from identifying the last state of a phone.
HmmTopology::Check(), invalid dest state 
HmmTopology::Check(), duplicate transition found.
Total probability for state 
 in topology entry is 
HmmTopology::Check, state 
 has no input transitions.
HmmTopology::Check(), pdf_classes are expected to be contiguous and start from zero.
TopologyForPhone(), phone 
 not covered.
feature index=
 is in models file but missing in normstats file.
 is in normstats file but missing in model file.
Invalid line in file=
 line=
Did not find feature=
Atleast one feature weight and Intercept is needed in model file=
Successfully loaded streaming confidence model file=
Confidence model file connot be empty. Missing configuration parameter confidence-model-file
Normalization statistics is not in the correct format
Number of features does not match with model file, 
Incorrect number of feature means, 
Incorrect number of feature stddevs, 
Standard deviation is 0 for feature=
Unknown feature=
 in normalization statistics file
Successfully loaded streaming confidence normalization stats file=
Confidence normalization stats file cannot be empty. Missing configuration parameter norm-stats-file
Missing feature index=
 in input features
 feature[
 in means or stddev stats
Evaluated features=
, confidence=
INTERCEPT
isfirst
isinside
avg_active
avg_bestcost
avg_epsilenceframes
No frames fit in file (#samples is 
Non-finite log energy found for frame 
PTree::Error, Error reading JSON config file: 
PTree::JsonParseError, Error reading JSON config file: 
creating PhonetisaurusG2P object
creating PDecG2P object 
Unknown quasar G2P engine type: 
PNSR
Coordinates out of bounds latitude=
 longitude=
This or other location undefined, can't computer distance
lat=DENIED lon=DENIED
lat=UNDEFINED lon=UNDEFINED
lat=
 lon=
DENIED
UNDEFINED
Unexpected location variant 
KNOWN
num-best
PhonetisaurusG2P Config: model=
, nBest=
g2p model file doesn't exist, or it's a directory: 
Phonetisaurus failed to load model!
Increase nbest, and try again. nbest=
+Tgram]
 <= 0
max-seq-length-veto-factor
PDecG2P Config: model=
, beam=
, lmWeight=
, maxSeqLength=
, vetoFactor=
, lmModelFile=
, maxLengthVetoFactor=
Reducing maximum sequence length from 
 because of max-seq-length-veto-factor
Connected 
 states without outgoing arcs.
Cannot find symbol: 
-grams
Undefined GCD since m = 0, n = 0.
Changing word 
Iter = 
, delta-Q = 
Iterating too many times in MbrDecode; stopping.
Edit distance increased: 
L = 
Invalid b_arc value
sum of gamma[
,s] is 
Times out of order
MBR Sausage Alignment Epsilon Symbol is 
Invalid path found.
#Corrections: QsrText-encoded keyword: 
default-n-best-size
The default value for n-best size.
corrections.keyword-finder
keyword-finder.
corrections.sanitization
#Corrections: No sanitization model is provided.
#Corrections: Keyword Finder returning due to null input (not necessarily an error).
#Corrections: Keyword Finder original input utterance: 
#Corrections: Keyword: 
#Corrections: Keyword pronunciation: 
#Corrections: Keyword location: 
#Corrections: Edit distance: 
#Corrections: 
 KWF results from 
-best list
#Corrections: Pre-itn stitched result 
<NumGroups>
<NumTables>
<VocabSizes>
<MaxItems>
<EmbedDimensions>
<AssignedTable>
<InitializeToConcat>
<UseTransform>
, a typo in config? 
(NumGroups|VocabSizes|MaxDimensions|EmbedDimensions|LearnRateCoef|ParamStddev|RandomSeed|InitTransformType|GradientNormType|MaxGrad)
<FeatureTransform>
require an updatable component, you used 
dimension mismatch, cannot initialize to concatenation, expected dim is 
 actual dim is 
cannot initialize to concatenation for this transform
initialized the transform for concatenation
it doesn't make sense to initialize the embedding table as an identify matrix
, a typo in config? (NumGroups|VocabSizes|MaxDimensions|EmbedDimensions|LearnRateCoef)
failed to read feature transform
## Embedding Table: 
## Feature Transform: input-dim 
No intermediate gradients for embedding tables, here is the gradient info for the transforms: 
RMSPROP is not implemented in word multi embedding yet
must have at least one group, you used 
must have at least one embedding table, you used 
there are only 
 groups, but you set 
 embedding tables
 groups, but the number vocab list size is 
 groups, but the max item list size is 
 groups, but the embedding dim list size is 
 groups, but 
 groups have assigned tables
the actual number of embedding tables is 
 and different than 
 groups, but the number of feature transforms is 
the 
-th group has assigned table index 
 , the number of tables is 
-th group has invalid vocab size 
-th group has invalid max item value 
-th group has invalid embedding dimension value 
-th group has mismatched embedding table and vocab size 
-th group has mismatched embedding table and embedding dim 
-th group has mismatched embedding table and feature transform 
-th group has feature transform output dim 
 does not match component output dim 
input dim of the component is 
 , while the input dim defined in max items is 
Total embedding size of 
 doesn't match the component output size of 
 when transforms are not used
Not implemented yet when transforms are used
WordMultiVecComponent doesn't support multi-batches yet
Using transform with gradient compression is not supported yet
Performing vectorization of WordMultiVecComponent
veccorrs->size() == 1
Done  vectorization of WordMultiVecComponent
Write failure in WriteBasicType<bool>
Read failure in ReadBasicType<bool>, file position is 
ReadBasicType: expected float, saw 
ReadBasicType: failed to read, at file position 
Write failure in WriteToken.
ReadToken, failed to read token at file position 
ReadToken, expected space after token, saw instead 
Error ungetting '<' in PeekToken
Failed to read token [started at file position 
], expected 
Expected token "
", got instead "
<ComputePlatform>
<CheckpointName>
ret == ESPRESSO_STATUS_SUCCESS
Set function name for checkpoint failed, error=
plan_ != nullptr
Espresso failed query blob info 
Espresso failed to reset plan with 
Espresso failed to declare input `
' with 
Espresso failed to declare output `
Espresso failed to unpack shape for input `
Espresso failed to change input blob shapes with 
Espresso failed to build plan with 
Failed to bind buffer for input=
, error=
Failed to bind buffer for static output=
Failed to run checkpoint network, error=
Failed to set function to main, error=
Failed to run main network, error=
Failed to bind buffer for dynamic output=
ANE_RUNTIME
METAL
CPU_ALT
Unknown platform: 
Set compute platform to 
batch_config_
Tensor rank is greater than 2: 
unsupported storage type.
bitmap-file
lon-left
lon-right
The value of 
 is not greater than 
lat-bottom
lat-top
Bitmap file name cannot be empty!
.pgm
The bitmap file 
 has unexpected suffix, should be 
Loaded regions bitmap width=
Cannot use degenerate regions bitmap width=
Internal error, expecting a real location at this point
The value 
 is not a valid longitude
 is not a valid latitude
This is a FOFE model
penultimate 
Illegal value for 'phrase-book-mode' in 'PDecPhraseBookBlock': 
loggingDict
T@"NSDictionary",C,N,V_loggingDict
T@"_EARLanguageDetectorRequestContext",C,N,V_context
T@"NSDictionary",C,N,V_confidences
TB,N,V_isConfident
Failed to allocate array
Failed to create feature provider
Error during prediction
EARLanguageDetector
_EARLanguageDetector init failed
The configuration file or models for _EARLanguageDetector are incorrect.
featureQueuePriority
TI,N,V_featureQueuePriority
arc_output_model_file.empty()
output_model_file.empty()
writeBinaryCount: count 
 is too large
readBinaryCount: incomplete long count
readBinaryCount: incomplete long long count
notch-detector.hfpower.txt
notch-detector.wt.txt
notch-detector.weighted.spectrum.txt
avlo = 
  avhi = 
bands_below.lo = 
, bands_below.hi = 
bands_notch.lo = 
, bands_notch.hi = 
bands_above.lo = 
, bands_above.hi = 
bands_across.lo = 
, bands_across.hi = 
notch-detector.peak.txt
quasar
%{public}s
wait-milliseconds
The number of milliseconds to wait for a confusion network to become available in the cache
No confusion network cache found.
No confusion network found in decodeChainOutput. Doing nothing.
This doesn't work when utt detect/concatenation is enabled. Doing nothing.
No confusion network found in cache. Doing nothing.
Detected phrases in confusion network - backing off to flattened 1-best (this is OK)
Combined sausage is empty. Doing nothing.
Tokens not monotonic and have been corrected.
mismatch between finished audio analytics frames and remaining frames+new wav frames: 
symbol table file
Reset scores after each result
DP contains no keywords for detection
Coding error. Keyword 
Dimension mismatch. Code or DP error
Frames seen so far: 
Error reading phone map from 
 (bad line 
Read empty phone map from 
illegal skip prob line
bad skip prob value 
%s %lg
iteration 
log likelihood = 
cannot write data to zero size vector
inputDataType 
 numDocumentsRejected 
 numSentencesRejected 
 numDocuments 
 numSentences 
 numTokens 
 numTokensOOV 
numDocumentsRejected
numSentencesRejected
numDocuments
numSentences
numTokens
numTokensOOV
train-dev-test-split
Comma-separated list of 3 positive numbers that should sum to 1. Example: 0.7:0.2:0.1 means data will be split as follows: 70%% train, 20%% dev, and 10%% test
sources
Comma-separated list of sources. They can be anything since the caller is responsible for interpreting them.
query-limit
Query limit. The caller is responsible for interpreting this.
max-age-days
Maximum age of data. The caller is responsible for interpreting this.
min-age-days
Minimum age of data. The caller is responsible for interpreting this.
min-words
Minimum number of total words for training to proceed.
max-words
Maximum number of total words to use.
oov-replacement
Replace OOVs with this token
filter-language
If true, filter text by Language ID
external-data-file
Optionally provide an external data file as general test set to evaluate over-adaptation
external-train-dev-test-split
Will split into common train & dev sets, but keeping an extra external test set.Comma-separated list of 3 positive numbers that should sum to 1. Example: 0.1:0.2:0.7 means external data will be split as follows: 10%% train, 20%% dev, and 70%% external
munge-file
Munge file. See documentation in Munger.hpp
min-sentence-ppl
If >= 0: sentences with background LM PPL < this value are rejected.
max-sentence-ppl
If >= 0: sentences with background LM PPL > this value are rejected.
max-sentence-oov-ratio
If >= 0: sentences with OOV ratio > this value are rejected.
max-sentence-oov-count
If >= 0: sentences with OOV count > this value are rejected.
max-document-length
If > 0: documents with length (UTF8 bytes) > this value are rejected.
max-sentences-per-document
If > 0: documents with number of sentences > this value are rejected.
max-sentence-length
If > 0: sentences with length (UTF8 bytes) > this value are rejected.
max-token-length
If > 0: sentences with token length (UTF8 bytes) > this value are rejected.
sanitizer-special-chars-pattern
Override pattern for TextSanitizer mSpecialChars.
filter-language-list
Comma-separated list of languages to keep using Language ID. Default: model-info.language.split('_')[0]. Example default: 'en' for 'en_US'
input-type
Format of input data (e.g. ngram-counts). Default: plain-text
invalid input data type specifier: 
min-words should be a single int or a comma-separated list of size 1..
minWords.size() == NumDataSetTypes
train-dev-test-split should be comma-separated list of size 
splitOffsets: 
train-dev-test-split values should sum to 1
external-train-dev-test-split should be comma-separated list of size 
externalSplitOffsets: 
external-train-dev-test-split values should sum to 1
.lattice-biglm-lme-faster
Unsupported config: first decoder is not lattice-biglm-lme-faster
Unsupported config: first decoder lacks word-syms-map-file
Could not create symbol table
symbolTable init 
Unsupported config: first decoder must have only one big G FST
Label out of bounds: 
 symbols in bigG 
/WORD-DIS-1/
Filtering by languages 
Creating lmScorer. minSentencePpl=
 maxSentencePpl=
external
Train data: 
Dev data: 
Test data: 
External test data: 
symbol=
 id=
Could not find symbol: 
Symbol out of range: 
Symbol has wrong value in symbolInBigG: 
externalSplitOffsets.size() == NumPartitions
splitOffsets.size() == NumPartitions
external data file doesn't exist: 
Reading external data file 
Reject due to document length
Reject due to sentences per document
RECEIVED 
ADDED 
Reject due to empty
oovRatio=
 numTokensOOV=
Reject due to high oov ratio
Reject due to high oov count
Reject due to no ppl
ppl=
Reject due to low ppl
Reject due to high ppl
invalid input sentence: 
Reject due to sentence length
Reject due to token length
numSymbolsInTrainSet 
lm-personalize.data
commandId
T@"NSString",R,C,N,V_commandId
tagSequence
T@"NSArray",R,C,N,V_tagSequence
commandTaggings
T@"NSArray",R,C,N,V_commandTaggings
Cannot have leading or trailing space in filename "
Found ~ at the beginning of filename "
". Shell like path expansions not supported.
Found what looks like an rspecifier instead of a filename "
Trying to classify rxfilename with pipe symbol in the wrong place (pipe without | at the end?): 
Error opening input stream 
Invalid input filename format 
Input::Stream(), not open.
open called on already open file.
, errno is 
Pipe 
 had nonzero return status 
FileInputImpl::Open(), 
FileInputImpl::Stream(), file is not open.
FileInputImpl::Close(), file is not open.
StandardInputImpl::Open(), open called on already open file.
StandardInputImpl::Stream(), object not initialized.
StandardInputImpl::Close(), file is not open.
Failed opening pipe for reading, command is: 
Pipe opened with command 
 is empty.
PipeInputImpl::Stream(), object not initialized.
PipeInputImpl::Close(), file is not open.
Cannot get offset from filename 
 (possibly you compiled in 32-bit and have a >32-bit
 byte offset into a file; you'll have to compile 64-bit.
 OOVs
 zeroprobs, 
logprob= 
 ppl= 
 ppl= undefined
 ppl1= 
 ppl1= undefined
 words,
 rank1= 
 rank5= 
 rank10= 
 words+sents,
 rank1wSent= 
 rank5wSent= 
 rank10wSent= 
 qloss= 
 absloss= 
"). 
Trailing whitespace not allowd in rspecifier (found "
Will treat this as kNoRspecifier.
SRILM release %s
1.7.1
 (with third-party contributions)
Program version %s
This software is subject to the SRILM Community Research License Version
1.0 (the "License"); you may not use this software except in compliance
with the License.  A copy of the License is included in the SRILM root
directory in the "License" file.  Software distributed under the License
is distributed on an "AS IS" basis, WITHOUT WARRANTY OF ANY KIND, either
express or implied.  See the License for the specific language governing
rights and limitations under the License.
This software is Copyright (c) 1995-2014 SRI International.  All rights
reserved.
Portions of this software are
Copyright (c) 2002-2005 Jeff Bilmes
Copyright (c) 2009-2013 Tanel Alumae
Copyright (c) 2012-2013 Microsoft Corp.
SRILM also includes open-source software as listed in the
ACKNOWLEDGEMENTS file in the SRILM root directory.
If this software was obtained under a commercial license agreement with
SRI then the provisions therein govern the use of the software and the
above notice does not apply.
Support for compressed files is included.
%u@%255s
%64s
server host 
 not found
socket: server 
connect: server 
server 
: could not read banner
send: server 
: protocol version 2 not supported
recv: server 
: unexpected return: 
%lu %u
: send 
text mapper entries must be unique
Overriding parameter: 
Overrides JSON does not contain section for '
'.  Skipping.
Json config filename=
Overrides JSON does not exist in datapack; falling back to default overrides.
non_acoustic_default
dictation_cs50
dictation
Failed to load paramset holder
Loaded paramset holder file:  
Could not find file 
Could not laod Empty voc
Could not load PG voc
Mandatory config field missing
Pronguess paramset value is not valid.
Search paramset value is not valid.
Lattice-nbest paramset value is not valid.
FragmentWordsState
OptionalPronWordsState
Generating pronunciations for orthography=
, spoken-form=
Orthography=
, Prons=
pronguess_paramset_name
search_paramset_name
lattice_nbest_paramset_name
napg_params
overrides
title_format
pronguess_overrides
search_overrides
lattice_nbest_overrides
Number of output lattice states is getting out of hand, aborting conversion
Could not find arc for input_state 
 olabel 
 in LM. Failed to reconstruct lattice (incompatible LM?).
Acoustic model file
Phone table file
optional-silence
Optional silence phone
silence-prob
Silence probability (0.0 to 1.0)
Word boundary file
align-lattice-expand-limit
Lattice expansion limit when doing word alignment(0 for none)
reconstruct-lattice-expand-limit
Lattice expansion limit when doing lattice reconstruction(0 for none)
big-g-fst-file
Negative SmallG FST filename
raw-smallg-fst-file
SmallG FST (with no phone or word loops for nonterminals) filename
extended-report
Set to false if only the concise error-report should be generated.
lm-context-length
Language model context length (e.g. 4-gram has length 3)
overlap-percentage
Required overlap in percent of two regions in reference and hypothesis to be viewed as the same region.
json-output-format
True if error reports should be formatted as JSON file.
You have not specified unpronounced-word-file. This will prevent you from using class LM tags 
like \CS-GeoBizName-start and \CS-GeoBizName-end in the ref transcription for error blamer. 
Created lexicon FST
WORD-DIS-
 phone words (including word disambig symbols) in base word table
inv-g-fst-file is now ignored because it does not work with class LMs. 
Please use raw-smallg-fst-file.
The number of big FST LMs + NN LMs doesn't match the number of weights (FST LMs + NN LMs)
Word alignment failed.
Word alignment lattice empty.
Lattice reconstruction failed.
 not found in symbol table(s).
 has word ID 0.
Ref transcription word: 
, ID: 
HypoStartFrame
HypoEndFrame
RefStartFrame
RefEndFrame
RefLmCost
HypoLmCost
RefAmCost
HypoAmCost
RefWords
HypoWords
Confusions
RefModel
HypoModel
RefPhone
HypoPhone
Word
StartFrame
EndFrame
LmCost
AmCost
RefTotalCost
HypoTotalCost
RefGraphCost
HypoGraphCost
Attributes
ErrorRegions
PresentInLattice
RankInLattice
Recoverable
AmScaleFactorToRecover
ReferenceInfo
No reference transcription provided.
no first pass LM defined
total number of LMs is 
, but the number of interpolation weights is 
Left context labels not yet implemented.
Failed to map compound LME words. LME data is probably corrupt.
Could not map all words to symbol ids.
failed-words
Failed to create decoding graph.
 Hint: Are all the ref words in the pron lexicon?
Encountered problem while creating decoding graph for reference.
Retrying utterance with beam 
Problem decoding utterance for forced alignment.
Encountered problem while force aligning the reference.
Word alignment failed for reference lattice. Aborting error-blaming.
Encountered problem while word-aligning the reference lattice.
Reference lattice reconstruction failed. Aborting error-blaming.
Encountered problem while reconstructing the reference lattice.
Word alignment failed for hypothesis lattice. Aborting error-blaming.
Encountered problem while word-aligning the hypothesis lattice.
Hypothesis lattice reconstruction failed.
Encountered problem while reconstructing the hypothesis lattice.
LM rescoring in error-blamer was not successful.
LM rescoring was not successful.
Lattice reconstruction with smallG failed.
Encountered problem while trying to reconstruct lattices with smallG.
smallG
transition-scale
Scale of transition probabilities (excluding self-loops)
self-loop-scale
Scale of self-loop vs. non-self-loop probability mass 
Reorder transition ids for greater decoding efficiency.
rm-eps
Remove [most] epsilons before minimization (only applicable if disambig symbols present)
Unable to parse input string.
Pre-alignment tokens not monotonic.
Aligner failed. There is a BUG. FIX THIS!!!
 alignment=
 src=[
] dest=[
Hammer rewrite failed.
seeva
seeva inference graph file
the vocab file that describes model output token
@[a-z]*#|#[a-z]*@
Unsupported model format version.
SeevaModel/__QNNI__length_penalty_weight
SeevaModel/__QNNI__coverage_penalty_weight
SeevaModel/__QNNI__minimum_input_count
SeevaModel/__QNNI__minimum_input_left
SeevaModel/__QNNI__minimum_alignment_weight
SeevaModel/__QNNI__minimum_peak_alignment
SeevaModel/__QNNI__stable_tokens
SeevaModel/__QNNI__utt_end_beam
SeevaModel/__QNNI__trace_back
SeevaModel/decoder/__QNNO__nbest_list
SeevaModel/decoder/__QNNO__nbest_score
SeevaModel/decoder/__QNNO__graph_reset
SeevaModel/decoder/__QNNO__partial_result
SeevaModel/decoder/__QNNO__encoder_only
SeevaModel/__QNNI__lme_fst_header
SeevaModel/__QNNI__lme_fst_states
SeevaModel/__QNNI__lme_fst_arcs
SeevaModel/__QNNI__lme_score_scale
SeevaModel/__QNNI__nonlme_score_scale
Version mismatch for PronChoice
Unknown format for pronunciation string
Empty pronunciations for one of the tokens. Exiting with 0 pron combinations.
pron combination = 
, logWeight = 
Cycles detected in lattice
Invalid lattice: different paths have a different number of frames
Utterance does not seem to have a consistent length.
Utterance does not have a final-state.
Invalid lattice: final state before max_time
Topological sorting failed
Done Topo Sort
Failure in best-path algorithm for lattice (infinite costs?)
Add 
 ilabel 
 usedarcind 
 weight 
Rescoring empty lattice
the DeterministicOnDemandFst is invalid
invalid arc.olabel 
cannot find arc with label 
 on state 
 in the LM FST, wrong input?
POSITION = 
 FROM: 
 TO: 
 WORD = 
 PROB = 
 EXPANDPROB = 
class expansion contains no words
%s %lf
varprune
pruning threshold for variable order ngrams
debugging level for LM
recompute
recompute lower-order counts by summation
sort
sort ngrams output
write-order
output ngram counts order
file tag to use in messages
text file to read
text-has-weights
text file contains count weights
counts file to read
intersect
intersect counts with this file
read-with-mincounts
apply minimum counts when reading counts file
read-google
Google counts directory to read
counts file to write
write1
1gram counts file to write
write2
2gram counts file to write
write3
3gram counts file to write
write4
4gram counts file to write
write5
5gram counts file to write
write6
6gram counts file to write
write7
7gram counts file to write
write8
8gram counts file to write
write9
9gram counts file to write
write-binary
binary counts file to write
lower GT discounting cutoff
upper GT discounting cutoff
gt1min
lower 1gram discounting cutoff
gt1max
upper 1gram discounting cutoff
gt2min
lower 2gram discounting cutoff
gt2max
upper 2gram discounting cutoff
gt3min
lower 3gram discounting cutoff
gt3max
upper 3gram discounting cutoff
gt4min
lower 4gram discounting cutoff
gt4max
upper 4gram discounting cutoff
gt5min
lower 5gram discounting cutoff
gt5max
upper 5gram discounting cutoff
gt6min
lower 6gram discounting cutoff
gt6max
upper 6gram discounting cutoff
gt7min
lower 7gram discounting cutoff
gt7max
upper 7gram discounting cutoff
gt8min
lower 8gram discounting cutoff
gt8max
upper 8gram discounting cutoff
gt9min
lower 9gram discounting cutoff
gt9max
upper 9gram discounting cutoff
Good-Turing discount parameter file
Good-Turing 1gram discounts
Good-Turing 2gram discounts
Good-Turing 3gram discounts
Good-Turing 4gram discounts
Good-Turing 5gram discounts
Good-Turing 6gram discounts
Good-Turing 7gram discounts
Good-Turing 8gram discounts
Good-Turing 9gram discounts
discounting constant
cdiscount1
1gram discounting constant
cdiscount2
2gram discounting constant
cdiscount3
3gram discounting constant
cdiscount4
4gram discounting constant
cdiscount5
5gram discounting constant
cdiscount6
6gram discounting constant
cdiscount7
7gram discounting constant
cdiscount8
8gram discounting constant
cdiscount9
9gram discounting constant
use natural discounting
ndiscount1
1gram natural discounting
ndiscount2
2gram natural discounting
ndiscount3
3gram natural discounting
ndiscount4
4gram natural discounting
ndiscount5
5gram natural discounting
ndiscount6
6gram natural discounting
ndiscount7
7gram natural discounting
ndiscount8
8gram natural discounting
ndiscount9
9gram natural discounting
addsmooth
additive smoothing constant
addsmooth1
1gram additive smoothing constant
addsmooth2
2gram additive smoothing constant
addsmooth3
3gram additive smoothing constant
addsmooth4
4gram additive smoothing constant
addsmooth5
5gram additive smoothing constant
addsmooth6
6gram additive smoothing constant
addsmooth7
7gram additive smoothing constant
addsmooth8
8gram additive smoothing constant
addsmooth9
9gram additive smoothing constant
use Witten-Bell discounting
wbdiscount1
1gram Witten-Bell discounting
wbdiscount2
2gram Witten-Bell discounting
wbdiscount3
3gram Witten-Bell discounting
wbdiscount4
4gram Witten-Bell discounting
wbdiscount5
5gram Witten-Bell discounting
wbdiscount6
6gram Witten-Bell discounting
wbdiscount7
7gram Witten-Bell discounting
wbdiscount8
8gram Witten-Bell discounting
wbdiscount9
9gram Witten-Bell discounting
use modified Kneser-Ney discounting
kndiscount1
1gram modified Kneser-Ney discounting
kndiscount2
2gram modified Kneser-Ney discounting
kndiscount3
3gram modified Kneser-Ney discounting
kndiscount4
4gram modified Kneser-Ney discounting
kndiscount5
5gram modified Kneser-Ney discounting
kndiscount6
6gram modified Kneser-Ney discounting
kndiscount7
7gram modified Kneser-Ney discounting
kndiscount8
8gram modified Kneser-Ney discounting
kndiscount9
9gram modified Kneser-Ney discounting
use original Kneser-Ney discounting
ukndiscount1
1gram original Kneser-Ney discounting
ukndiscount2
2gram original Kneser-Ney discounting
ukndiscount3
3gram original Kneser-Ney discounting
ukndiscount4
4gram original Kneser-Ney discounting
ukndiscount5
5gram original Kneser-Ney discounting
ukndiscount6
6gram original Kneser-Ney discounting
ukndiscount7
7gram original Kneser-Ney discounting
ukndiscount8
8gram original Kneser-Ney discounting
ukndiscount9
9gram original Kneser-Ney discounting
Kneser-Ney discount parameter file
Kneser-Ney 1gram discounts
Kneser-Ney 2gram discounts
Kneser-Ney 3gram discounts
Kneser-Ney 4gram discounts
Kneser-Ney 5gram discounts
Kneser-Ney 6gram discounts
Kneser-Ney 7gram discounts
Kneser-Ney 8gram discounts
Kneser-Ney 9gram discounts
input counts already modified for KN smoothing
kn-modify-counts-at-end
modify counts after discount estimation rather than before
use interpolated estimates
interpolate1
use interpolated 1gram estimates
interpolate2
use interpolated 2gram estimates
interpolate3
use interpolated 3gram estimates
interpolate4
use interpolated 4gram estimates
interpolate5
use interpolated 5gram estimates
interpolate6
use interpolated 6gram estimates
interpolate7
use interpolated 7gram estimates
interpolate8
use interpolated 8gram estimates
interpolate9
use interpolated 9gram estimates
LM to estimate
write-binary-lm
output LM in binary format
init-lm
initial LM for EM estimation
keep <unk> in LM
meta-tag
meta tag used to input count-of-count information
use fractional counts
closed-form-doug-paul-hack
use a closed-form formula for the Doug Paul Hack
build a tagged LM
train a count-based LM
build a skip N-gram LM
skip-init
default initial skip probability
em-iters
max number of EM iterations
em-delta
min log likelihood delta for EM
Estimate maximum entropy model
maxent-alpha
The L1 regularisation constant for max-ent estimation
maxent-sigma2
The L2 regularisation constant for max-ent estimation (default: 6 for estimation, 0.5 for adaptation)
Save estimated max-ent model as a regular ARPA backoff model
trust-totals
trust lower-order counts for estimation
limit count reading to specified vocabulary
write vocab to file
write-vocab-index
write vocab index map to file
the default action is to write counts to stdout
fractional counts, variable, tagged, stop-word Ngram and skip N-gram models are mutually exclusive
conflicting default discounting options
error reading Google counts from 
LM order must be positive -- set to 1
conflicting discounting options for order 
using NaturalDiscount for 
using WittenBell for 
using ConstDiscount for 
using AddSmooth for 
using KneserNey for 
using ModKneserNey for 
using GoodTuring for 
error in reading discount parameter file 
error in discount estimator for order 
Closed-form Doug Paul Hack is not supported in combination with a count-based LM.
format error in init-lm file
count-lm estimation needs initial model
cannot use -float-counts with count-lm
LM estimation failed
Closed-form Doug Paul Hack is not supported in combination with a maximum-entropy LM.
format error in maxent prior (-init-lm) file
Maxent LM estimation failed
: Cannot find key: 
Unknown location
Building appendable feature 
sampling-rate
location
Unknown appendable feature: 
Rejected client conf network due to invalid HatText encoding
Stored conf network!
regular expression replacer in: 
regular expression replacer out: 
Only (global) replacement operations are supported, got 
 with specifier 
read expression: "
", mapping to "
RegularExpressionReplacer read in 
 regular expressions
Begin
Both
None
Unknown AddTag format
bothAsOne
bothasone
bothSeparate
bothseparate
Unknown tag format 
lexeme
grapheme
phoneme
lexemes
T@"NSMutableArray",C,N,V_lexemes
Pushing weights of empty compact lattice
Lattice has non-coaccessible states.
Sanitizer already initialized.
Initialized Sanitizer
Neural net file
order %u
mixweights %u
 %lg
countmodulus %s
vocabsize %s
totalcount %s
counts -
google-counts %s
counts %s
order %u
vocabsize %99s
totalcount %99s
countmodulus %99s
mixweights %u
premature end to mixture weights
%lg%n
incomplete mixture weight vector
counts %1023s
google-counts %1023s
warning: zero denominator count for ngram 
posterior counts 
warning: no data to estimate mixture weight 
for count 
, order 
Supplied utterance id is out of bounds
RefDurations
HypoDurations
Reference
Hypothesis
RefTotalScore
HypoTotalScore
RefAmScore
HypoAmScore
Reference is not in hypo lattice
Reference is in hypo lattice (Rank: 
) and 
cannot be recovered
can be recovered by multiplying the current acoustic-scale with 
Not able to convert given phone_id 
, check if given phone symbol table is the correct one.
fst_custom.fst
decoders
lattice-biglm-lme-faster.big-g-fst-file-list
big-g-fst-file-list not found for decoder 
lattice-biglm-lme-faster.word-syms-map-file
Symbol-table file not found in json file 
lmeDataFactory initialization failed!
G2P model does not exist
1shot_new.json
{{TEMPLATE}}
\NT-unknown
Failed to tokenize
Tokenizer could not tokenize
template list not found for used template 
template list not found for used template: 
template names should be enclosed in {} and contain only one word (lowercase)
Number of OOVs = 
No OOVs
could not get LME data
Template names should be enclosed in {} and contain only one word (in lowercase)
No templates provided
Template names should be enclosed in {} and contain only one word
Template list found more than once for : 
Input FST is cyclic
Could not write fst to file path 
Could not write fst to file
Step name must be 
mutually-exclusive-group
from
validate-brackets
validate-brackets will be overwritten by validate-brackets = 
(?i)
split-case-sensitive
max-alt
max-alt will be overwritten by max-alt = 
split-case-sensitive will be overwritten by split-case-sensitive = 
\g<0>
WARNING: asking to round a value to 0 significant figures makes no sense 
 answer is 0.
total
Task 
 not found in config
Multiple decoder chains for task 
Decoder chain 
 not found in config for task 
SeevaModel/encoder/__QNNO__encoder_output
SeevaModel/encoder/__QNNI__encoder_state_
SeevaModel/encoder/__QNNO__encoder_state_
SeevaModel/__QNNI__target_input
SeevaModel/__QNNI__encoder_output
SeevaModel/decoder/__QNNO__decoder_full_score
SeevaModel/decoder/__QNNI__decoder_state_
SeevaModel/decoder/__QNNO__decoder_state_
Empty silence phones
creating PDecTranslatorFactory
Unrecognized commandId=
\all-caps
\all-caps-on
\all-caps-off
\cap
\spelling-cap
\caps-on
\caps-off
\no-caps
\no-caps-on
\no-caps-off
\no-space
\no-space-on
\no-space-off
\new-line
\new-paragraph
.\period-paragraph
\tab-key
\no-break-space
\spelling-no-break-space
\space-bar
\backslash
\spelling-backslash
ucasemap_utf8ToUpper failed
ucasemap_utf8ToTitle failed
generic
Unknown error
boost::filesystem::current_path
boost::filesystem::last_write_time
boost::filesystem::remove
boost::filesystem::remove_all
boost::filesystem::rename
boost::filesystem::status
boost::filesystem::directory_iterator::construct
boost::filesystem::directory_iterator::operator++
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/agent.cc
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/agent.cc:13: MARISA_NULL_ERROR: str == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/agent.cc:36: MARISA_STATE_ERROR: state_.get() != NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/agent.cc:38: MARISA_MEMORY_ERROR: state_.get() == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/scoped-ptr.h
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/scoped-ptr.h:19: MARISA_RESET_ERROR: (ptr != NULL) && (ptr == ptr_)
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/io/mapper.cc
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/io/mapper.cc:63: MARISA_NULL_ERROR: (ptr == NULL) && (size != 0)
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/io/mapper.cc:71: MARISA_STATE_ERROR: !is_open()
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/io/mapper.cc:72: MARISA_IO_ERROR: size > avail_
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/io/mapper.cc:99: MARISA_STATE_ERROR: !is_open()
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/io/mapper.cc:100: MARISA_IO_ERROR: size > avail_
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/louds-trie.cc
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/louds-trie.cc:73: MARISA_BOUND_ERROR: agent.query().id() >= size()
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/louds-trie.cc:451: MARISA_MEMORY_ERROR: next_trie_.get() == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/louds-trie.cc:468: MARISA_MEMORY_ERROR: next_trie_.get() == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/louds-trie.cc:542: MARISA_MEMORY_ERROR: next_trie_.get() == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/config.h
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/config.h:59: MARISA_CODE_ERROR: (config_flags & ~MARISA_CONFIG_MASK) != 0
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/config.h:101: MARISA_CODE_ERROR: undefined cache level
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/config.h:121: MARISA_CODE_ERROR: undefined tail mode
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/config.h:141: MARISA_CODE_ERROR: undefined node order
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/header.h
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/header.h:21: MARISA_FORMAT_ERROR: !test_header(ptr)
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/../io/mapper.h
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/../io/mapper.h:28: MARISA_NULL_ERROR: (objs == NULL) && (num_objs != 0)
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/../io/mapper.h:30: MARISA_SIZE_ERROR: num_objs > (MARISA_SIZE_MAX / sizeof(T))
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/../vector/bit-vector.h
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/../vector/bit-vector.h:52: MARISA_SIZE_ERROR: size_ == MARISA_UINT32_MAX
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/../vector/vector.h
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/../vector/vector.h:100: MARISA_STATE_ERROR: fixed_
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/../vector/bit-vector.h:135: MARISA_FORMAT_ERROR: temp_num_1s > size_
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/../vector/vector.h:202: MARISA_FORMAT_ERROR: (total_size % sizeof(T)) != 0
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/../vector/vector.h:107: MARISA_STATE_ERROR: fixed_
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/../vector/flat-vector.h
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/../vector/flat-vector.h:134: MARISA_FORMAT_ERROR: temp_value_size > 32
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/louds-trie.cc:428: MARISA_MEMORY_ERROR: std::bad_alloc
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/../algorithm/../../scoped-ptr.h
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/../algorithm/../../scoped-ptr.h:19: MARISA_RESET_ERROR: (ptr != NULL) && (ptr == ptr_)
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/tail.cc
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/tail.cc:13: MARISA_NULL_ERROR: offsets == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/tail.cc:36: MARISA_CODE_ERROR: undefined tail mode
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/tail.cc:170: MARISA_RANGE_ERROR: current.length() == 0
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/tail.cc:192: MARISA_SIZE_ERROR: buf_.size() > MARISA_UINT32_MAX
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/vector/vector.h
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/vector/vector.h:100: MARISA_STATE_ERROR: fixed_
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/keyset.cc
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/keyset.cc:50: MARISA_NULL_ERROR: str == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/keyset.cc:61: MARISA_NULL_ERROR: (ptr == NULL) && (length != 0)
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/keyset.cc:62: MARISA_SIZE_ERROR: length > MARISA_UINT32_MAX
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/keyset.cc:129: MARISA_MEMORY_ERROR: new_blocks.get() == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/keyset.cc:138: MARISA_MEMORY_ERROR: new_block.get() == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/keyset.cc:151: MARISA_MEMORY_ERROR: new_blocks.get() == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/keyset.cc:159: MARISA_MEMORY_ERROR: new_block.get() == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/keyset.cc:169: MARISA_MEMORY_ERROR: new_blocks.get() == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/keyset.cc:177: MARISA_MEMORY_ERROR: new_block.get() == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/trie.cc
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/trie.cc:14: MARISA_MEMORY_ERROR: temp.get() == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/trie.cc:33: MARISA_NULL_ERROR: (ptr == NULL) && (size != 0)
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/trie.cc:36: MARISA_MEMORY_ERROR: temp.get() == NULL
/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/EmbeddedAcousticRecognition-261.8/libquasar/libsentencepiece/src/bpe_model.cc
(index) >= (0)
(index) < (static_cast<int>(symbols.size()))
/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/EmbeddedAcousticRecognition-261.8/libquasar/libsentencepiece/src/builtin_pb/sentencepiece.pb.cc
sentencepiece.SentencePieceText.SentencePiece
sentencepiece.SentencePieceText
sentencepiece.NBestSentencePieceText
/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/EmbeddedAcousticRecognition-261.8/libquasar/libsentencepiece/src/builtin_pb/sentencepiece_model.pb.cc
sentencepiece.TrainerSpec
sentencepiece.NormalizerSpec
sentencepiece.SelfTestData.Sample
sentencepiece.SelfTestData
sentencepiece.ModelProto.SentencePiece
sentencepiece.ModelProto
Program terminated with an unrecoverable error.
Cancelled
Invalid argument
Deadline exceeded
Not found
Already exists
Permission denied
Unauthenticated
Resource exhausted
Failed precondition
Aborted
Out of range
Internal
Unavailable
Data loss
Unknown code:
/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/EmbeddedAcousticRecognition-261.8/libquasar/libsentencepiece/src/filesystem.cc
ReadAll is not supported for stdin.
/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/EmbeddedAcousticRecognition-261.8/libquasar/libsentencepiece/src/model_factory.cc
Unknown model_type: 
<pad>
piece must not be empty.
 is already defined.
unk is already defined.
unk is not defined.
src/model_interface.h
Not implemented.
/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/EmbeddedAcousticRecognition-261.8/libquasar/libsentencepiece/src/normalizer.cc
precompiled_charsmap is empty. use identity normalization.
(length) >= (0)
(norm_to_orig->size()) == (normalized->size() + 1)
Blob for normalization rule is broken.
(0) == (trie_->build(key.size(), const_cast<char **>(&key[0]), nullptr, nullptr))
src/util.h
'result' Must be non NULL
../libsentencepiece/third_party/darts_clone/darts.h:703: exception: failed to resize pool: std::bad_alloc
../libsentencepiece/third_party/darts_clone/darts.h:1141: exception: failed to insert key: negative value
../libsentencepiece/third_party/darts_clone/darts.h:1143: exception: failed to insert key: zero-length key
../libsentencepiece/third_party/darts_clone/darts.h:1157: exception: failed to insert key: invalid null character
../libsentencepiece/third_party/darts_clone/darts.h:1162: exception: failed to insert key: wrong key order
../libsentencepiece/third_party/darts_clone/darts.h:842: exception: failed to build rank index: std::bad_alloc
../libsentencepiece/third_party/darts_clone/darts.h:1380: exception: failed to modify unit: too large offset
../libsentencepiece/third_party/darts_clone/darts.h:1726: exception: failed to build double-array: invalid null character
../libsentencepiece/third_party/darts_clone/darts.h:1728: exception: failed to build double-array: negative value
../libsentencepiece/third_party/darts_clone/darts.h:1743: exception: failed to build double-array: wrong key order
/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/EmbeddedAcousticRecognition-261.8/libquasar/libsentencepiece/src/sentencepiece_processor.cc
input->ReadAll(&proto)
_status.ok()
std::stream API is deprecated. Use LoadFromSerializedProto() 
to load model from any serialized blob object.
model_proto->ParseFromArray(serialized.data(), serialized.size())
LOG(
 samples did not pass the test.
Self-test failures. See LOG(INFO).
model_
Model is not initialized.
normalizer_
Normalizer is not initialized.
type == TrainerSpec::UNIGRAM || type == TrainerSpec::BPE
Vocabulary constraint is only enabled in subword units.
(v.size()) >= (1)
!v[0].empty()
pieces
output container is null
detokenized
!w.empty()
Empty piece is not allowed.
(begin) < (norm_to_orig.size())
(end) < (norm_to_orig.size())
(orig_begin) <= (input.size())
(orig_end) <= (input.size())
(orig_begin) <= (orig_end)
(consumed) == (normalized.size())
all normalized characters are not consumed.
output proto is null
nbest_spt
!nbests.empty()
NBestEncode returns empty result.
(nbest_size) <= (512)
nbest_size must be nbest_size <= 512
Returns default value 
unknown extra_option type.
it != extra_option_map.end()
option "
" is not available.
!IsUnknown( PieceToId(util::min_string_view(model_->bos_piece().data())))
id for `
` is not defined.
!IsUnknown( PieceToId(util::min_string_view(model_->eos_piece().data())))
/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/EmbeddedAcousticRecognition-261.8/libquasar/libsentencepiece/src/unigram_model.cc
Failed to find the best path in Viterbi.
nbest_size >= 1. Returns empty result.
Too big agenda. shrinking
(num_nodes) < (trie_results.size())
no pieces are loaded.
cannot build double-array.
no entry is found in the trie.
 Error #
/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/EmbeddedAcousticRecognition-261.8/libquasar/libsentencepiece/third_party/protobuf-lite/arena.cc
CHECK failed: (min_bytes) <= (std::numeric_limits<size_t>::max() - kBlockHeaderSize): 
/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/EmbeddedAcousticRecognition-261.8/libquasar/libsentencepiece/third_party/protobuf-lite/coded_stream.cc
A protocol message was rejected because it was too big (more than 
 bytes).  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
CHECK failed: (buffer_size) >= (0): 
/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/EmbeddedAcousticRecognition-261.8/libquasar/libsentencepiece/third_party/protobuf-lite/common.cc
This program requires version 
 of the Protocol Buffer runtime library, but the installed version is 
.  Please update your library.  If you compiled the program yourself, make sure that your headers are from the same version of Protocol Buffers as your link-time library.  (Version verification failed in "
This program was compiled against version 
 of the Protocol Buffer runtime library, which is not compatible with the installed version (
).  Contact the program author for an update.  If you compiled the program yourself, make sure that your headers are from the same version of Protocol Buffers as your link-time library.  (Version verification failed in "
%d.%d.%d
[libprotobuf %s %s:%d] %s
/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/EmbeddedAcousticRecognition-261.8/libquasar/libsentencepiece/third_party/protobuf-lite/extension_set.cc
Non-primitive types can't be packed.
can't reach here.
/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/EmbeddedAcousticRecognition-261.8/libquasar/libsentencepiece/third_party/protobuf-lite/generated_message_util.cc
Not implemented field number 
CHECK failed: (scc->visit_status.load(std::memory_order_relaxed)) == (SCCInfoBase::kRunning): 
 with type 
/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/EmbeddedAcousticRecognition-261.8/libquasar/libsentencepiece/third_party/protobuf-lite/message_lite.cc
Exceeded maximum protobuf size of 2GB: 
CHECK failed: !coded_out.HadError(): 
parse
Can't 
 message of type "
" because it is missing required fields: 
CHECK failed: (byte_size_before_serialization) == (byte_size_after_serialization): 
 was modified concurrently during serialization.
CHECK failed: (bytes_produced_by_serialization) == (byte_size_before_serialization): 
Byte size calculation and serialization were inconsistent.  This may indicate a bug in protocol buffers or it may be caused by concurrent modification of 
This shouldn't be called if all the sizes are equal.
/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/EmbeddedAcousticRecognition-261.8/libquasar/libsentencepiece/third_party/protobuf-lite/wire_format_lite.cc
CHECK failed: (value.size()) <= (kint32max): 
/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/EmbeddedAcousticRecognition-261.8/libquasar/libsentencepiece/third_party/protobuf-lite/zero_copy_stream.cc
This ZeroCopyOutputStream doesn't support aliasing. Reaching here usually means a ZeroCopyOutputStream implementation bug.
/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/EmbeddedAcousticRecognition-261.8/libquasar/libsentencepiece/third_party/protobuf-lite/zero_copy_stream_impl_lite.cc
CHECK failed: (last_returned_size_) > (0): 
BackUp() can only be called after a successful Next().
CHECK failed: (count) <= (last_returned_size_): 
CHECK failed: (count) >= (0): 
CHECK failed: target_ != NULL: 
Cannot allocate buffer larger than kint32max for 
StringOutputStream.
CHECK failed: (count) <= (target_->size()): 
Audio buffer has been deallocated; not restarting recognition
Result stream wrapper has been deallocated; not restarting recognition
Error file sent for compilation does not exist. Not compiling.
Error determining compilation status: %@
Attempting to compile ANE model: %@
Found an error: %@
Compilation completed.
Skipping model that's already compiled: %@
Error file sent for purge does not exist. Not purging.
Attempting to purge ANE model: %@
Purge completed.
Got interrupt signal, going to interrupt training.
Training is not enabled, do nothing...
Recognition failure in execution %{public}@
Recognizer has been deallocated; not writing partial results
Recognizer has been deallocated; not writing final choices
Result stream has been deallocated; not writing final choices
Recognizer has been deallocated; not reporting result progress
Result stream has been deallocated; not reporting result progress
Recognizer has been deallocated; not writing end point data
Result stream has been deallocated; not writing end point data
Recognizer has been deallocated; not training speaker code.
Training instance has been deallocated; not training speaker code.
Features or labels are invalid, not feeding data for training, feature size: %zu, label size: %zu
Training starts, total samples: %zu
Training finishes, processed samples: %zu
Training result stream is allocated, writing training result
%{public}s
Initializing %@
File does not exist %@
Internal unknown exception
Internal C++ exception: %s
PSR: EARAudioProcessor Config file does not exist at %@
PSR: ERR: AudioProcessorPipeline created with incorrect version
endAudio
resetForNewRequest
ComputeTask done
dealloc
Config file does not exist at %{public}@
ARG: ERR: AudioProcessorPipeline created with incorrect version
Resetting audio result generator
Got valid result mat in sync fashion with numRows:%lu and numCols:%lu
Got valid result row in sync fashion with numCols:%lu
Ending audio
PSR: EARSyncAudioProcessor Config file does not exist at %@
Added %d samples, processed %d ms of audio so far
End audio: Processed %d ms of audio so far
Error loading context-aware model: %@
%s, error %@
No supported languages found in acousticPosteriors
context.currentDictationLanguage is empty, setting currentDictationLocale to zeroes.
context.wasLanguageToggled not set, defaulting to false.
context.multilingualKeyboardLanguages not set, setting multilingualKeyboardLocales to zeroes.
context.keyboardConvoLanguagePriors not set, setting keyboardConvoLocalePriors to uniform probability.
context.keyboardGlobalLanguagePriors not set, setting keyboardGlobalLocalePriors to uniform probability.
context.previousMessageLanguage not set, setting previousMessageLocale to zeroes.
context.globalLastKeyboardUsed not set, setting globalLastKeyboardUsed to zeroes.
context.dictationLanguagePriors not set, setting dictationLocalePriors to uniform probability.
Exception in EARContextAwareLDModelFactory::createModel: %s
Unsupported model file format "%s"
Identified languages of messages = %@
%@ maps to %@
There is no keyboard language for %@
Starting new request
previousMessageLanguage and keyboardConvoLanguagePriors are both set, so recentMessages will be ignored.
Unsupported locales (%s) found in context, will be ignored
Error initializing model.
Attempting to load model file: %@
Failed to reload CoreML model with error: %@
Failed to create feature multiarray with error %@
Failed to create feature provider with error %@
Error during prediction: %@
LanguageDetector: EARLanguageDetector model file does not exist at %@
Received didFinishProcessingFrames
Got an error when trying to print logging info
Logging Data: %@
Sending logging info to delegate
Received didComputeResult
Sending language detector result to delegate
Sending language detector confidences to delegate
_EARWordPart
_EARUserProfileBuilder
_EARUserProfile
_EAREndpointFeatures
_EARDefaultServerEndpointFeatures
_EAREndpointer
_EARSpeechRecognitionToken
NSCopying
_EARAcousticFeature
_EARAudioAnalytics
_EARLatticeMitigatorResult
_EARSpeechRecognition
_EARSpeechRecognitionResultPackage
_EARSpeechRecognitionResult
_EARSpeechRecognizer
_EARSpeechModelInfo
_EARSyncResultStreamHelper
_EARSpeechRecognitionResultStream
NSObject
EARSdapiHelper
_EARTransformUtil
_EARSpeechRecognitionAudioBuffer
_EARSyncSpeechRecognizer
_EARSystemResult
_EARCombinedResult
_EARResultCombiner
_EARLanguageDetectorRequestContext
_EARTextNormalization
_EARNnetUtil
EARTokenPronounciations
EARKeywordFinderResult
EARKeywordFinder
EARAudioReader
EARStringView
EMTTokenizer
_EARLmData
_EARLmModel
_EARLmEvaluator
_EARLmLoader
_EAROovToken
_EARAppLmData
_EARCustomLMBuilder
EARPSRAudioProcessor
EARCSpeechRecognitionResultStreamGlue
_EARLanguageDetectorAudioBuffer
EMTToken
EARAudioResult
EARAudioResultsGenerator
EMTTranslator
_EARLanguageModel
_EARFormatter
EMTResult
EARSyncPSRAudioProcessor
_EARLmHandle
EARClientSilenceFeatures
EARCaesuraSilencePosteriorGenerator
_EARLanguageDetectorLoggingInfo
_EARLanguageDetectorResult
_EARLanguageDetector
_EARCommandTagging
_EARCommandTaggingResult
_EARCommandTagger
_EARPlsParser
NSXMLParserDelegate
_EARTokenizer
stringWithUTF8String:
stringByStandardizingPath
fileSystemRepresentation
fileURLWithFileSystemRepresentation:isDirectory:relativeToURL:
numberWithDouble:
numberWithInt:
numberWithBool:
addObject:
setValue:forKey:
setValue:forKeyPath:
_initWithCommandTaggings:
countByEnumeratingWithState:objects:count:
objectForKey:
ear_toString
array
copy
_initWithQuasarToken:
quasarToken
quasarTokens
quasarPreItnTokens
_initWithQuasarCommandTagging:
init
initWithOrthography:pronunciations:tag:
initWithOrthography:pronunciations:tagName:frequency:
tagName
orthography
frequency
pronunciations
.cxx_destruct
_tagName
_orthography
_tag
_frequency
_pronunciations
EnsureSDAPIInitialized
UTF8String
localeIdentifier
initWithConfiguration:language:overrides:sdapiOverrides:generalVoc:emptyVoc:pgVoc:lexiconEnh:tokenEnh:paramsetHolder:
enumerateKeysAndObjectsUsingBlock:
dataWithBytes:length:
bytes
length
currentHandler
handleFailureInMethod:object:file:lineNumber:description:
initialize
isEasyToRecognizeWord:forLocale:
initWithConfiguration:withLanguage:withSdapiOverrides:withSdapiConfig:
initWithConfiguration:language:sdapiOverrides:generalVoc:emptyVoc:pgVoc:lexiconEnh:tokenEnh:paramsetHolder:
addWordWithParts:templateName:
removeAllWords
dataProfile
readUserProfile:
addPersonalizationData:
addPersonalizationJsonData:
writeOutUserDataToJson:withConfig:
pronunciationsForOrthography:
sanitizedStringWithString:
signalEndOfUserData
.cxx_construct
_userData
_dataFactory
_tokenizer
_g2p
_pronCache
_sanitizer
_personalizationRecipe
_quasarLmeData
initWithWordCount:trailingSilenceDuration:endOfSentenceLikelihood:pauseCounts:silencePosterior:clientSilenceFramesCountMs:clientSilenceProbability:silencePosteriorNF:serverFeaturesLatency:eagerResultEndTime:
componentsJoinedByString:
stringWithFormat:
initWithWordCount:trailingSilenceDuration:endOfSentenceLikelihood:pauseCounts:silencePosterior:clientSilenceFramesCountMs:clientSilenceProbability:silencePosteriorNF:serverFeaturesLatency:
description
wordCount
setWordCount:
trailingSilenceDuration
setTrailingSilenceDuration:
endOfSentenceLikelihood
setEndOfSentenceLikelihood:
pauseCounts
setPauseCounts:
silencePosterior
setSilencePosterior:
clientSilenceFramesCountMs
setClientSilenceFramesCountMs:
clientSilenceProbability
setClientSilenceProbability:
silencePosteriorNF
setSilencePosteriorNF:
serverFeaturesLatency
setServerFeaturesLatency:
eagerResultEndTime
setEagerResultEndTime:
_silencePosteriorNF
_serverFeaturesLatency
_wordCount
_trailingSilenceDuration
_endOfSentenceLikelihood
_pauseCounts
_silencePosterior
_clientSilenceFramesCountMs
_clientSilenceProbability
_eagerResultEndTime
initWithWordCount:trailingSilenceDuration:endOfSentenceLikelihood:silencePosterior:
initWithConfiguration:modelVersion:
defaultManager
fileExistsAtPath:
initWithConfiguration:
initWithConfiguration:delaysTrigger:modelVersion:
requestSupportedWithSamplingRate:
updateEndpointerThresholdWithValue:
updateEndpointerDelayedTriggerSwitch:
didEndpointWithFeatures:audioTimestamp:featuresToLog:endpointPosterior:extraDelayMs:
defaultServerEndpointFeatures
acceptEagerResultWithFeatures:featuresToLog:
_endpointer
unsignedIntValue
tokenName
hash
start
silenceStart
confidence
hasSpaceAfter
hasSpaceBefore
phoneSequence
ipaPhoneSequence
stringByAppendingFormat:
copyWithZone:
isEqual:
initWithTokenName:start:end:silenceStart:confidence:hasSpaceAfter:hasSpaceBefore:phoneSequence:ipaPhoneSequence:
_quasarToken
_initWithAcousticFeatureValues:frameDuration:
acousticFeatureValuePerFrame
frameDuration
_acousticFeatureValuePerFrame
_frameDuration
_initWithSpeechRecognitionFeatures:acousticFeatures:
speechRecognitionFeatures
acousticFeatures
_speechRecognitionFeatures
_acousticFeatures
initWithVersion:score:threshold:
version
score
threshold
_score
_threshold
_version
_initWithTokenPhraseChoiceList:
initWithCapacity:
numberWithUnsignedInt:
_initWithTokenSausage:interpretationIndices:
count
objectAtIndex:
intValue
addObjectsFromArray:
firstObject
_tokenPhraseChoiceList
_initWithNBestList:useHatText:
nBest
oneBest
granularizedRecognition
tokenSausage
interpretationIndices
_tokenSausage
_interpretationIndices
_initWithRecognition:preITNRecognition:recognitionIsFormatted:isFinal:audioAnalytics:utteranceStart:
_initWithRecognition:preITNRecognition:recognitionIsFormatted:isFinal:audioAnalytics:utteranceStart:latticeMitigatorResult:
_initWithTokens:preITNTokens:
_initWithRecognition:preITNRecognition:recognitionIsFormatted:isFinal:
_initWithRecognition:preITNRecognition:recognitionIsFormatted:isFinal:audioAnalytics:
nBestResults
recognition
preITNRecognition
recognitionIsFormatted
isFinal
audioAnalytics
utteranceStart
latticeMitigatorResult
_recognitionIsFormatted
_isFinal
_recognition
_preITNRecognition
_audioAnalytics
_utteranceStart
_latticeMitigatorResult
tokens
preITNTokens
_quasarTokens
_quasarPreItnTokens
formatWords:task:language:
initWithConfiguration:overrides:overrideConfigFiles:
enumerateObjectsUsingBlock:
initWithLanguage:withSdapiConfig:quasarConfig:
initWithConfiguration:overrides:overrideConfigFiles:generalVoc:lexiconEnh:itnEnh:
supportedByQuasarConfig:
initWithQuasarConfig:overrideConfigFiles:
initWithGeneralVoc:withLexiconEnh:withItnEnh:
initWithQuasarConfig:
initWithConfig:
stringByDeletingLastPathComponent
stringByAppendingPathComponent:
setLeftContext:
_restartActiveRecognition
runRecognitionWithResultStream:language:task:samplingRate:
enumerateDataSourcesAndWeightsUsingBlock:
runRecognitionWithResultStream:language:task:samplingRate:userProfileData:trainingResultStream:
_detachFromRecognizer
_audioBufferWithLangauge:task:samplingRate:userProfileData:resultStream:
_initWithAudioBuffer:speechRecognizer:
stringByReplacingOccurrencesOfString:withString:
_setUnderlyingBuffer:
addAudioSampleData:
endAudio
waitForCompletion
results
recognitionResultsWithAudioData:userProfileData:language:task:samplingRate:
needsANECompilationForModelAtURL:result:error:
modelWithContentsOfURL:error:
purgeANEIRForModelAtURL:error:
setObject:forKeyedSubscript:
minimumSupportedConfigurationVersion
maximumSupportedConfigurationVersion
rawTokenResultsFromRecognitionResults:
compileRecognizerModelsWithConfiguration:
purgeCompiledRecognizerModelsWithConfiguration:
initWithConfiguration:overrides:
initWithConfiguration:overrideConfigFiles:
initWithConfiguration:withLanguage:withSdapiConfig:
initWithConfiguration:withGeneralVoc:withLexiconEnh:withItnEnh:
initWithConfiguration:overrides:generalVoc:lexiconEnh:itnEnh:
initWithConfiguration:overrideConfigFiles:generalVoc:lexiconEnh:itnEnh:
initWithConfiguration:useQuasarFormatter:
modelInfo
setHighPriority:
setLeftContextText:
setUserProfileData:
setJitProfileData:
setSpeakerCode:
runRecognitionWithResultStream:
updateUserProfileData:
updateJitProfileData:
requestParametersWithUserProfileData:task:samplingRate:resultStream:extraLanguageModel:symbolTableList:
runRecognitionWithResultStream:trainingResultStream:language:task:samplingRate:
writeRecordedStateAccesses
recognitionResultsWithAudioData:userProfileData:language:task:samplingRate:extraLanguageModel:
cancelRecognition
interruptTraining
recognitionStatistics
recognitionUtterenceStatistics
getFormatterWithBlock:
_waitForInitialization
dumpModelVirtualMemoryInfo
setAlternateRawRecognitionTokenSausage:
getRecognizer
userProfileData
jitProfileData
detectUtterances
setDetectUtterances:
concatenateUtterances
setConcatenateUtterances:
endpointStart
setEndpointStart:
recognizeEagerCandidates
setRecognizeEagerCandidates:
farField
setFarField:
highPriority
maximumRecognitionDuration
setMaximumRecognitionDuration:
recognitionReplacements
setRecognitionReplacements:
recognitionConfidenceSubtraction
setRecognitionConfidenceSubtraction:
leftContext
inputOrigin
setInputOrigin:
deviceId
setDeviceId:
refTranscriptForErrorBlaming
setRefTranscriptForErrorBlaming:
bluetoothDeviceId
setBluetoothDeviceId:
userId
setUserId:
sessionId
setSessionId:
extraLmList
setExtraLmList:
speakerCode
_formatterQueue
_formatter
_trainingQueue
_training
_recognizer
_currentAudioBuffer
_currentResultStreamWrapper
_currentLanguage
_currentTask
_currentSamplingRate
_recognitionQueue
_configPath
_detectUtterances
_concatenateUtterances
_recognizeEagerCandidates
_farField
_highPriority
_userProfileData
_jitProfileData
_endpointStart
_maximumRecognitionDuration
_recognitionReplacements
_recognitionConfidenceSubtraction
_leftContext
_inputOrigin
_deviceId
_refTranscriptForErrorBlaming
_bluetoothDeviceId
_userId
_sessionId
_extraLmList
_speakerCode
setWithCapacity:
initWithInt:
samplingRates
tasks
language
phoneSetVersion
acousticProfileVersion
_speechModelInfo
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
superclass
debugDescription
speechRecognizer:didRecognizePartialResult:
speechRecognizer:didFinishRecognitionWithError:
speechRecognizer:didRecognizeFinalResults:
speechRecognizer:didRecognizeFinalResults:tokenSausage:nBestChoices:
speechRecognizer:didRecognizeFinalResultPackage:
speechRecognizer:didProcessAudioDuration:
speechRecognizer:didRecognizeRawEagerRecognitionCandidate:
speechRecognizer:didProduceEndpointFeaturesWithWordCount:trailingSilenceDuration:eosLikelihood:pauseCounts:silencePosterior:processedAudioDurationInMilliseconds:
speechRecognizer:didRecognizePartialResultNbest:
error
_finishSemaphore
_error
_results
raise:format:
condititionalProbabilityOfWordID:contextWordIDs:count:symbolLookupBlock:
dictionaryWithObjects:forKeys:count:
errorWithDomain:code:userInfo:
lowercaseString
setObject:forKey:
floatValue
numberWithFloat:
trainingResult:processedSamples:
handle
hatToQsrString:
hatToQsrStrings:
addAudioSamples:count:
triggerServerSideEndPointer
bufferedAudioDuration
_buffer
_queue
_speechRecognizer
_cancelled
_ended
formatWords:task:
getSpeechRecognitionResultFromTokens:taskName:
resetWithSamplingRate:language:taskType:userId:sessionId:deviceId:farField:audioSource:maxAudioBufferSizeSeconds:
resultsWithAddedAudio:numberOfSamples:taskName:
resultsWithAddedFloatAudio:numberOfSamples:taskName:
resultsWithEndedAudio
_syncRecognizer
sausage
setSausage:
nBestIndexes
setNBestIndexes:
confidences
setConfidences:
_sausage
_nBestIndexes
_confidences
nBestStrings
setNBestStrings:
nBestSourceIndexes
setNBestSourceIndexes:
originalRanks
setOriginalRanks:
_nBestStrings
_nBestSourceIndexes
_originalRanks
combinedResultWithSystemResults:
_combiner
unsignedLongValue
numberWithUnsignedLong:
modelDescription
inputDescriptionsByName
objectForKeyedSubscript:
multiArrayConstraint
shape
objectAtIndexedSubscript:
outputDescriptionsByName
initWithDictionary:error:
predictionFromFeatures:options:error:
setUsesCPUOnly:
featureValueForName:
multiArrayValue
featureNames
arrayWithObjects:count:
initWithDataPointer:shape:dataType:strides:deallocator:error:
strides
longValue
dataType
dataPointer
languagePriors
dictationLanguages
currentDictationLanguage
wasLanguageToggled
boolValue
multilingualKeyboardLanguages
keyboardConvoLanguagePriors
keyboardGlobalLanguagePriors
previousMessageLanguage
globalLastKeyboardUsed
dictationLanguagePriors
setLanguagePriors:
setDictationLanguages:
setCurrentDictationLanguage:
setWasLanguageToggled:
setMultilingualKeyboardLanguages:
setKeyboardConvoLanguagePriors:
setKeyboardGlobalLanguagePriors:
setPreviousMessageLanguage:
setGlobalLastKeyboardUsed:
setDictationLanguagePriors:
recentMessages
setRecentMessages:
contextFromLDContext:
LDContext
_languagePriors
_dictationLanguages
_currentDictationLanguage
_wasLanguageToggled
_multilingualKeyboardLanguages
_keyboardConvoLanguagePriors
_keyboardGlobalLanguagePriors
_previousMessageLanguage
_globalLastKeyboardUsed
_dictationLanguagePriors
_recentMessages
doubleValue
initWithNcsRoot:
tokenize:
munge:
initWithNcsRoot:mungeRuleFile:
initWithNcsRoot:mungeRules:
initWithMungeRules:
normalize:
_munger
doBackPropWithNnetModelFile:inputFeatureVector:inputTargetVector:inputLearningRate:inputFreezeComponents:inputNumLocalIterations:inputGradNormFactor:inputGradNormType:inputBatchSize:inputObjectiveFunction:outTrainingLosses:outModelLayersUpdated:
lastObject
doBackPropWithNnetModelFile:inputFeatureVector:inputTargetVector:inputLearningRate:inputFreezeComponents:inputNumLocalIterations:inputGradNormFactor:inputGradNormType:inputBatchSize:inputObjectiveFunction:outTrainingLoss:outModelLayersUpdated:
initWithToken:pronunciations:
_quasarProns
token
setToken:
setPronunciations:
_token
_initWithCorrectedUtterances:
correctedUtterances
_correctedUtterances
correctedResultWithKeyword:tokenizedKeyword:preItnSausage:preItnOneBest:preItnOneBestIndices:nbestSize:
_kwf
pathExtension
_opx_enumerateAudioBuffersWithBlock:
_avf_enumerateAudioBuffersWithBlock:
assetWithURL:
assetReaderWithAsset:error:
numberWithUnsignedInteger:
tracksWithMediaType:
assetReaderAudioMixOutputWithAudioTracks:audioSettings:
canAddOutput:
addOutput:
startReading
copyNextSampleBuffer
initWithLength:
mutableBytes
_opx_enumeratePacketsWithBlock:
fileHandleForReadingFromURL:error:
readDataUpToLength:error:
getBytes:length:
initWithFileURL:sampleRate:
enumerateAudioBuffersWithBlock:
_fileURL
_sampleRate
initWithBytes:length:encoding:
lengthOfBytesUsingEncoding:
getCString:maxLength:encoding:
ear_stringWithStringView:
URLByAppendingPathComponent:
path
text
formattedStringWithStrings:preToPostItnArray:
formattedStringWithStrings:
initWithModelURL:
format:preToPostItnMap:
format:
outputLocale
_outputLocale
tokenizerWithNcsRoot:
initWithConfiguration:ncsRoot:recognizerConfiguration:
addDocumentWithUUID:content:
addSentenceWithType:uuid:content:
roomForMoreData
sources
queryLimit
maxAge
minAge
metrics
roundingEnabled
setRoundingEnabled:
data
_roundingEnabled
_data
initWithConfiguration:root:
_initWithHandle:
trainWithData:
removeWithDirectory:
_initWithModel:
initFromDirectory:
trainWithData:shouldStop:
setWeight:
writeToDirectory:
weight
model
_model
initWithConfiguration:root:recognizerConfiguration:
runEvaluationWithData:handle:result:bestWeight:
initWithConfiguration:recognizerConfiguration:
runEvaluationWithData:handle:result:
runEvaluationWithData:handle:shouldStop:result:bestWeight:
_evaluator
fetchOrLoadModelWithDirectory:recognizer:
loadForRecognitionWithDirectory:recognizer:task:applicationName:
invalidate
_loader
initWithOrthography:prons:frequency:
prons
_prons
setProns:forWord:pronIsXsampa:
orderedOovs
initWithConfiguration:ncsRoot:recognizerConfigPath:
setXsampaProns:forWord:
setAsrProns:forWord:
generateLmeData:
mutableCopy
defaultCStringEncoding
stringWithCString:encoding:
writeToFile:options:error:
getFstGrammar:overrideFolder:weight:errorOut:
_customLMBuilder
initWithConfigFile:configRoot:sampleRate:delegate:queue:
_startComputeTask
delegate
processInfo
systemUptime
psrAudioProcessor:hasSpeakerVector:speakerVectorSize:processedAudioDurationMs:
psrAudioProcessor:hasResult:numElements:
psrAudioProcessor:finishedWithFinalSpeakerVector:speakerVectorSize:processedAudioDurationMs:
dealloc
initWithConfigFile:configRoot:sampleRate:delegate:
addAudio:
resetForNewRequest
configRoot
setConfigRoot:
setDelegate:
queue
setQueue:
_audioProcessor
_sysConfig
_configRoot
_delegate
initWithStream:
_stream
initWithConfiguration:usage:
commandId
tagSequence
tokensForTag:
commandTaggings
commandTaggingFromRecognitionResult:activeCommands:
parameterTagForIndex:
commandPhraseTagForIndex:
isParameterTag:
isCommandPhraseTag:
_initWithAudioBuffer:
precededBySpace
followedBySpace
initWithText:confidence:precededBySpace:followedBySpace:
_precededBySpace
_followedBySpace
_confidence
_text
initWithFilePresenter:
fileURLWithPath:
coordinateReadingItemAtURL:options:error:byAccessor:
coordinateWritingItemAtURL:options:error:byAccessor:
processString:
dominantLanguage
reset
createDirectoryAtURL:withIntermediateDirectories:attributes:error:
initWithAudioResultMat:vectorSize:numVectors:
audioResultMat
setAudioResultMat:
audioResultsNumVectors
setAudioResultsNumVectors:
audioResultsVectorSize
setAudioResultsVectorSize:
_audioResultMat
_audioResultsNumVectors
_audioResultsVectorSize
setLength:
appendData:
hasEARAudioResultMatrix:
hasEARAudioResultLastVector:
audioResultMatrix
audioResultLastVector
_isAudioSessionLive
_entireResultMatrix
_globalNumVectors
_vectorSize
_sessionFrameCount
dataWithCapacity:
appendBytes:length:
initWithModelURL:task:
translateSpeech:from:to:completion:
rawTranscription
segments
substring
translateTokens:from:to:completion:
translateString:from:to:completion:
_tokenizeString:
_translate:from:to:completion:
componentsSeparatedByString:
initWithLocale:tokens:confidence:lowConfidence:metaInfo:
loadTranslatorFrom:to:
translateSpeech:completion:
translateString:completion:
callbackQueue
setCallbackQueue:
_translatorFactory
_config
_translationQueue
_callbackQueue
addDataSource:weight:
totalWeight
_dataSources
_totalWeight
formattedStringWithStrings:task:
convertStringsToQuasarTokens:
getOrthography:
formattedStringWithStrings:preToPostItnArray:task:
formatWords:
initWithQuasarConfig:language:
formattedRecognitionWithNBestList:
setLanguage:
_itn
_language
removeLastObject
locale
lowConfidence
metaInfo
_lowConfidence
_locale
_tokens
_metaInfo
getLatestSuperVector
getProcessedAudioDurationMs
_scoreReportTimestamp
_handle
initWithSilenceFramesCountMs:silenceProbability:silenceDurationMs:silencePosterior:processedAudioMs:
silenceFramesCountMs
setSilenceFramesCountMs:
silenceProbability
setSilenceProbability:
silenceDurationMs
setSilenceDurationMs:
processedAudioMs
setProcessedAudioMs:
_silenceFramesCountMs
_silenceProbability
_silenceDurationMs
_processedAudioMs
initWithConfigFile:samplingRate:
initWithConfigFile:samplingRate:queue:
clientSilenceFeaturesAvailable:
silenceDurationEstimateAvailable:numEstimates:clientProcessedAudioMs:
initWithConfigFile:
addAudio:numSamples:
getFrameDurationMs
_silenceGenerator
_configFile
_samplingRate
_spgQueue
setComputeUnits:
modelWithContentsOfURL:configuration:error:
unsignedIntegerValue
initWithShape:dataType:error:
copyIntoMultiArray:error:
integerValue
loggingDict
setLoggingDict:
context
setContext:
_loggingDict
_context
isConfident
setIsConfident:
_isConfident
fileURLWithPath:isDirectory:
localizedDescription
setObject:atIndexedSubscript:
dictionaryWithCapacity:
dictionaryValue
initWithConfigFile:overrides:
quasarLocalesOfMessages:
arrayWithCapacity:
null
dominantLanguageForString:
isEqualToString:
updateContext:withMessageLocales:
localesOfMessages:
startRequestWith:context:delegate:
featureQueuePriority
setFeatureQueuePriority:
languageDetector
_featureQueuePriority
absoluteString
arrayWithObjects:
dictionaryWithObject:forKey:
dictionary
dictionaryWithObjects:forKeys:
languageDetectorDidCompleteProcessing:loggingInfo:
languageDetector:result:
languageDetector:confidences:
fileExistsAtPath:isDirectory:
createDirectoryAtPath:withIntermediateDirectories:attributes:error:
_tagging
_commandId
_tagSequence
_commandTaggings
_tagger
initWithData:
parse
dataWithContentsOfFile:
whitespaceAndNewlineCharacterSet
stringByTrimmingCharactersInSet:
appendString:
parserDidStartDocument:
parserDidEndDocument:
parser:foundNotationDeclarationWithName:publicID:systemID:
parser:foundUnparsedEntityDeclarationWithName:publicID:systemID:notationName:
parser:foundAttributeDeclarationWithName:forElement:type:defaultValue:
parser:foundElementDeclarationWithName:model:
parser:foundInternalEntityDeclarationWithName:value:
parser:foundExternalEntityDeclarationWithName:publicID:systemID:
parser:didStartElement:namespaceURI:qualifiedName:attributes:
parser:didEndElement:namespaceURI:qualifiedName:
parser:didStartMappingPrefix:toURI:
parser:didEndMappingPrefix:
parser:foundCharacters:
parser:foundIgnorableWhitespace:
parser:foundProcessingInstructionWithTarget:data:
parser:foundComment:
parser:foundCDATA:
parser:resolveExternalEntityName:systemID:
parser:parseErrorOccurred:
parser:validationErrorOccurred:
initWithFilePath:
lexemes
setLexemes:
parser
lexeme
elementValue
_lexemes
@40@0:8@16@24q32
@48@0:8@16@24@32Q40
@16@0:8
q16@0:8
Q16@0:8
v16@0:8
@"NSString"
@"NSSet"
B32@0:8@16@24
@48@0:8@16@24@32@40
@88@0:8@16@24@32@40@48@56@64@72@80
@96@0:8@16@24@32@40@48@56@64@72@80@88
v32@0:8@16@24
v24@0:8@16
@24@0:8@16
{map<std::__1::basic_string<char>, std::__1::vector<std::__1::vector<quasar::LmeDataFactoryBase::Word, std::__1::allocator<quasar::LmeDataFactoryBase::Word> >, std::__1::allocator<std::__1::vector<quasar::LmeDataFactoryBase::Word, std::__1::allocator<quasar::LmeDataFactoryBase::Word> > > >, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, std::__1::vector<std::__1::vector<quasar::LmeDataFactoryBase::Word, std::__1::allocator<quasar::LmeDataFactoryBase::Word> >, std::__1::allocator<std::__1::vector<quasar::LmeDataFactoryBase::Word, std::__1::allocator<quasar::LmeDataFactoryBase::Word> > > > > > >="__tree_"{__tree<std::__1::__value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::vector<quasar::LmeDataFactoryBase::Word, std::__1::allocator<quasar::LmeDataFactoryBase::Word> >, std::__1::allocator<std::__1::vector<quasar::LmeDataFactoryBase::Word, std::__1::allocator<quasar::LmeDataFactoryBase::Word> > > > >, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::vector<quasar::LmeDataFactoryBase::Word, std::__1::allocator<quasar::LmeDataFactoryBase::Word> >, std::__1::allocator<std::__1::vector<quasar::LmeDataFactoryBase::Word, std::__1::allocator<quasar::LmeDataFactoryBase::Word> > > > >, std::__1::less<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::vector<quasar::LmeDataFactoryBase::Word, std::__1::allocator<quasar::LmeDataFactoryBase::Word> >, std::__1::allocator<std::__1::vector<quasar::LmeDataFactoryBase::Word, std::__1::allocator<quasar::LmeDataFactoryBase::Word> > > > > > >="__begin_node_"^{__tree_end_node<std::__1::__tree_node_base<void *> *>}"__pair1_"{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::vector<quasar::LmeDataFactoryBase::Word, std::__1::allocator<quasar::LmeDataFactoryBase::Word> >, std::__1::allocator<std::__1::vector<quasar::LmeDataFactoryBase::Word, std::__1::allocator<quasar::LmeDataFactoryBase::Word> > > > >, void *> > >="__value_"{__tree_end_node<std::__1::__tree_node_base<void *> *>="__left_"^{__tree_node_base<void *>}}}"__pair3_"{__compressed_pair<unsigned long, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::vector<quasar::LmeDataFactoryBase::Word, std::__1::allocator<quasar::LmeDataFactoryBase::Word> >, std::__1::allocator<std::__1::vector<quasar::LmeDataFactoryBase::Word, std::__1::allocator<quasar::LmeDataFactoryBase::Word> > > > >, std::__1::less<std::__1::basic_string<char> >, true> >="__value_"Q}}}
{shared_ptr<quasar::LmeDataFactory>="__ptr_"^{LmeDataFactory}"__cntrl_"^{__shared_weak_count}}
{unique_ptr<sdapi::SdapiTokenizer, std::__1::default_delete<sdapi::SdapiTokenizer> >="__ptr_"{__compressed_pair<sdapi::SdapiTokenizer *, std::__1::default_delete<sdapi::SdapiTokenizer> >="__value_"^{SdapiTokenizer}}}
{unique_ptr<quasar::G2P, std::__1::default_delete<quasar::G2P> >="__ptr_"{__compressed_pair<quasar::G2P *, std::__1::default_delete<quasar::G2P> >="__value_"^{G2P}}}
{shared_ptr<quasar::PronCache<std::__1::basic_string<char>, std::__1::vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > > > >="__ptr_"^{PronCache<std::__1::basic_string<char>, std::__1::vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > > >}"__cntrl_"^{__shared_weak_count}}
{BasicTextSanitizer="_vptr$TextSanitizer"^^?"mUnicodeOutliers"{shared_ptr<quasar::URegularExpressionWrapper>="__ptr_"^{URegularExpressionWrapper}"__cntrl_"^{__shared_weak_count}}"mSpecialChars"{shared_ptr<quasar::URegularExpressionWrapper>="__ptr_"^{URegularExpressionWrapper}"__cntrl_"^{__shared_weak_count}}"mDupSpacePattern"{shared_ptr<quasar::URegularExpressionWrapper>="__ptr_"^{URegularExpressionWrapper}"__cntrl_"^{__shared_weak_count}}"mCtrlCharsPattern"{shared_ptr<quasar::URegularExpressionWrapper>="__ptr_"^{URegularExpressionWrapper}"__cntrl_"^{__shared_weak_count}}"state"i"UTF8_MAP"{unordered_map<std::__1::basic_string<char>, std::__1::basic_string<char>, std::__1::hash<std::__1::basic_string<char> >, std::__1::equal_to<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, std::__1::basic_string<char> > > >="__table_"{__hash_table<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::__unordered_map_hasher<std::__1::basic_string<char>, std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::hash<std::__1::basic_string<char> >, true>, std::__1::__unordered_map_equal<std::__1::basic_string<char>, std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::equal_to<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::basic_string<char> > > >="__bucket_list_"{unique_ptr<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, void *> *> *[], std::__1::__bucket_list_deallocator<std::__1::allocator<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, void *> *> *> > >="__ptr_"{__compressed_pair<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, void *> *> **, std::__1::__bucket_list_deallocator<std::__1::allocator<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, void *> *> *> > >="__value_"^^{__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, void *> *>}"__value_"{__bucket_list_deallocator<std::__1::allocator<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, void *> *> *> >="__data_"{__compressed_pair<unsigned long, std::__1::allocator<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, void *> *> *> >="__value_"Q}}}}"__p1_"{__compressed_pair<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, void *> *>, std::__1::allocator<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, void *> > >="__value_"{__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, void *> *>="__next_"^{__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, void *> *>}}}"__p2_"{__compressed_pair<unsigned long, std::__1::__unordered_map_hasher<std::__1::basic_string<char>, std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::hash<std::__1::basic_string<char> >, true> >="__value_"Q}"__p3_"{__compressed_pair<float, std::__1::__unordered_map_equal<std::__1::basic_string<char>, std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::equal_to<std::__1::basic_string<char> >, true> >="__value_"f}}}"unicode_map"{unordered_map<char32_t, char32_t, std::__1::hash<char32_t>, std::__1::equal_to<char32_t>, std::__1::allocator<std::__1::pair<const char32_t, char32_t> > >="__table_"{__hash_table<std::__1::__hash_value_type<char32_t, char32_t>, std::__1::__unordered_map_hasher<char32_t, std::__1::__hash_value_type<char32_t, char32_t>, std::__1::hash<char32_t>, true>, std::__1::__unordered_map_equal<char32_t, std::__1::__hash_value_type<char32_t, char32_t>, std::__1::equal_to<char32_t>, true>, std::__1::allocator<std::__1::__hash_value_type<char32_t, char32_t> > >="__bucket_list_"{unique_ptr<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<char32_t, char32_t>, void *> *> *[], std::__1::__bucket_list_deallocator<std::__1::allocator<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<char32_t, char32_t>, void *> *> *> > >="__ptr_"{__compressed_pair<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<char32_t, char32_t>, void *> *> **, std::__1::__bucket_list_deallocator<std::__1::allocator<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<char32_t, char32_t>, void *> *> *> > >="__value_"^^{__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<char32_t, char32_t>, void *> *>}"__value_"{__bucket_list_deallocator<std::__1::allocator<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<char32_t, char32_t>, void *> *> *> >="__data_"{__compressed_pair<unsigned long, std::__1::allocator<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<char32_t, char32_t>, void *> *> *> >="__value_"Q}}}}"__p1_"{__compressed_pair<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<char32_t, char32_t>, void *> *>, std::__1::allocator<std::__1::__hash_node<std::__1::__hash_value_type<char32_t, char32_t>, void *> > >="__value_"{__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<char32_t, char32_t>, void *> *>="__next_"^{__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<char32_t, char32_t>, void *> *>}}}"__p2_"{__compressed_pair<unsigned long, std::__1::__unordered_map_hasher<char32_t, std::__1::__hash_value_type<char32_t, char32_t>, std::__1::hash<char32_t>, true> >="__value_"Q}"__p3_"{__compressed_pair<float, std::__1::__unordered_map_equal<char32_t, std::__1::__hash_value_type<char32_t, char32_t>, std::__1::equal_to<char32_t>, true> >="__value_"f}}}}
{unique_ptr<quasar::PersonalizationRecipe, std::__1::default_delete<quasar::PersonalizationRecipe> >="__ptr_"{__compressed_pair<quasar::PersonalizationRecipe *, std::__1::default_delete<quasar::PersonalizationRecipe> >="__value_"^{PersonalizationRecipe}}}
{unique_ptr<quasar::LmeData, std::__1::default_delete<quasar::LmeData> >="__ptr_"{__compressed_pair<quasar::LmeData *, std::__1::default_delete<quasar::LmeData> >="__value_"^{LmeData}}}
@80@0:8q16q24d32@40d48d56d64f72f76
@88@0:8q16q24d32@40d48d56d64f72f76q80
v24@0:8q16
d16@0:8
v24@0:8d16
f16@0:8
v20@0:8f16
@"NSArray"
@40@0:8q16q24f32f36
@32@0:8@16^@24
@36@0:8@16B24^@28
B24@0:8Q16
v20@0:8B16
B56@0:8@16d24^@32^f40^i48
B32@0:8@16^@24
{unique_ptr<quasar::HybridEndpointer, std::__1::default_delete<quasar::HybridEndpointer> >="__ptr_"{__compressed_pair<quasar::HybridEndpointer *, std::__1::default_delete<quasar::HybridEndpointer> >="__value_"^{HybridEndpointer}}}
@24@0:8^{_NSZone=}16
B24@0:8@16
@80@0:8@16d24d32d40d48B56B60@64@72
@24@0:8r^{Token={basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}IIIfBB{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}}16
B16@0:8
{Token={basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}IIIfBB{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}}16@0:8
{Token="tokenName"{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >="__r_"{__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >="__value_"{__rep=""(?="__l"{__long="__cap_"Q"__size_"Q"__data_"*}"__s"{__short=""(?="__size_"C"__lx"c)"__data_"[23c]}"__r"{__raw="__words"[3Q]})}}}"startMilliseconds"I"endMilliseconds"I"silStartMilliSeconds"I"confidence"f"hasSpaceAfter"B"hasSpaceBefore"B"phoneSeq"{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >="__r_"{__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >="__value_"{__rep=""(?="__l"{__long="__cap_"Q"__size_"Q"__data_"*}"__s"{__short=""(?="__size_"C"__lx"c)"__data_"[23c]}"__r"{__raw="__words"[3Q]})}}}"ipaPhoneSeq"{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >="__r_"{__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >="__value_"{__rep=""(?="__l"{__long="__cap_"Q"__size_"Q"__data_"*}"__s"{__short=""(?="__size_"C"__lx"c)"__data_"[23c]}"__r"{__raw="__words"[3Q]})}}}}
@28@0:8@16f24
@32@0:8@16@24
@"NSDictionary"
@32@0:8@16f24f28
@28@0:8r^{vector<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> >, std::__1::allocator<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> > > >=^{vector<quasar::Token, std::__1::allocator<quasar::Token> >}^{vector<quasar::Token, std::__1::allocator<quasar::Token> >}{__compressed_pair<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> > *, std::__1::allocator<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> > > >=^{vector<quasar::Token, std::__1::allocator<quasar::Token> >}}}16B24
@24@0:8r^{pair<std::__1::vector<std::__1::vector<unsigned int, std::__1::allocator<unsigned int> >, std::__1::allocator<std::__1::vector<unsigned int, std::__1::allocator<unsigned int> > > >, std::__1::vector<std::__1::vector<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> >, std::__1::allocator<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> > > >, std::__1::allocator<std::__1::vector<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> >, std::__1::allocator<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> > > > > > >={vector<std::__1::vector<unsigned int, std::__1::allocator<unsigned int> >, std::__1::allocator<std::__1::vector<unsigned int, std::__1::allocator<unsigned int> > > >=^{vector<unsigned int, std::__1::allocator<unsigned int> >}^{vector<unsigned int, std::__1::allocator<unsigned int> >}{__compressed_pair<std::__1::vector<unsigned int, std::__1::allocator<unsigned int> > *, std::__1::allocator<std::__1::vector<unsigned int, std::__1::allocator<unsigned int> > > >=^{vector<unsigned int, std::__1::allocator<unsigned int> >}}}{vector<std::__1::vector<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> >, std::__1::allocator<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> > > >, std::__1::allocator<std::__1::vector<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> >, std::__1::allocator<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> > > > > >=^{vector<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> >, std::__1::allocator<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> > > >}^{vector<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> >, std::__1::allocator<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> > > >}{__compressed_pair<std::__1::vector<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> >, std::__1::allocator<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> > > > *, std::__1::allocator<std::__1::vector<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> >, std::__1::allocator<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> > > > > >=^{vector<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> >, std::__1::allocator<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> > > >}}}}16
{pair<std::__1::vector<std::__1::vector<unsigned int, std::__1::allocator<unsigned int> >, std::__1::allocator<std::__1::vector<unsigned int, std::__1::allocator<unsigned int> > > >, std::__1::vector<std::__1::vector<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> >, std::__1::allocator<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> > > >, std::__1::allocator<std::__1::vector<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> >, std::__1::allocator<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> > > > > > >={vector<std::__1::vector<unsigned int, std::__1::allocator<unsigned int> >, std::__1::allocator<std::__1::vector<unsigned int, std::__1::allocator<unsigned int> > > >=^{vector<unsigned int, std::__1::allocator<unsigned int> >}^{vector<unsigned int, std::__1::allocator<unsigned int> >}{__compressed_pair<std::__1::vector<unsigned int, std::__1::allocator<unsigned int> > *, std::__1::allocator<std::__1::vector<unsigned int, std::__1::allocator<unsigned int> > > >=^{vector<unsigned int, std::__1::allocator<unsigned int> >}}}{vector<std::__1::vector<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> >, std::__1::allocator<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> > > >, std::__1::allocator<std::__1::vector<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> >, std::__1::allocator<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> > > > > >=^{vector<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> >, std::__1::allocator<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> > > >}^{vector<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> >, std::__1::allocator<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> > > >}{__compressed_pair<std::__1::vector<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> >, std::__1::allocator<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> > > > *, std::__1::allocator<std::__1::vector<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> >, std::__1::allocator<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> > > > > >=^{vector<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> >, std::__1::allocator<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> > > >}}}}16@0:8
@40@0:8@16@24B32B36
@48@0:8@16@24B32B36@40
@56@0:8@16@24B32B36@40d48
@64@0:8@16@24B32B36@40d48@56
@"_EARSpeechRecognition"
@"_EARAudioAnalytics"
@"_EARLatticeMitigatorResult"
@64@0:8{vector<quasar::Token, std::__1::allocator<quasar::Token> >=^{Token}^{Token}{__compressed_pair<quasar::Token *, std::__1::allocator<quasar::Token> >=^{Token}}}16{vector<quasar::Token, std::__1::allocator<quasar::Token> >=^{Token}^{Token}{__compressed_pair<quasar::Token *, std::__1::allocator<quasar::Token> >=^{Token}}}40
{vector<quasar::Token, std::__1::allocator<quasar::Token> >=^{Token}^{Token}{__compressed_pair<quasar::Token *, std::__1::allocator<quasar::Token> >=^{Token}}}16@0:8
{vector<quasar::Token, std::__1::allocator<quasar::Token> >="__begin_"^{Token}"__end_"^{Token}"__end_cap_"{__compressed_pair<quasar::Token *, std::__1::allocator<quasar::Token> >="__value_"^{Token}}}
@40@0:8@16@24@32
@64@0:8@16@24@32@40@48@56
@56@0:8@16@24@32@40@48
@28@0:8@16B24
^{TextTokenizer=^^?}16@0:8
{shared_ptr<quasar::SpeechRequestData>=^{SpeechRequestData}^{__shared_weak_count}}72@0:8@16@24Q32{shared_ptr<quasar::RecogResultStreamBase>=^{RecogResultStreamBase}^{__shared_weak_count}}40@56r^{shared_ptr<quasar::SymbolTableList>=^{SymbolTableList}^{__shared_weak_count}}64
@56@0:8@16@24@32@40Q48
@64@0:8@16@24@32Q40@48@56
{shared_ptr<quasar::RecogAudioBufferBase>=^{RecogAudioBufferBase}^{__shared_weak_count}}64@0:8@16@24Q32@40{shared_ptr<quasar::RecogResultStreamBase>=^{RecogResultStreamBase}^{__shared_weak_count}}48
@64@0:8@16@24@32@40Q48@56
v24@0:8@?16
{shared_ptr<quasar::SpeechRecognizer>=^{SpeechRecognizer}^{__shared_weak_count}}16@0:8
@"NSObject<OS_dispatch_queue>"
@"_EARFormatter"
{shared_ptr<quasar::SpeakerCodeTraining>="__ptr_"^{SpeakerCodeTraining}"__cntrl_"^{__shared_weak_count}}
{shared_ptr<quasar::SpeechRecognizer>="__ptr_"^{SpeechRecognizer}"__cntrl_"^{__shared_weak_count}}
{unique_ptr<quasar::TextTokenizer, std::__1::default_delete<quasar::TextTokenizer> >="__ptr_"{__compressed_pair<quasar::TextTokenizer *, std::__1::default_delete<quasar::TextTokenizer> >="__value_"^{TextTokenizer}}}
@"_EARSpeechRecognitionAudioBuffer"
{weak_ptr<ResultStreamWrapper>="__ptr_"^{ResultStreamWrapper}"__cntrl_"^{__shared_weak_count}}
@"NSData"
{SpeechModelInfo="version"{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >="__r_"{__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >="__value_"{__rep=""(?="__l"{__long="__cap_"Q"__size_"Q"__data_"*}"__s"{__short=""(?="__size_"C"__lx"c)"__data_"[23c]}"__r"{__raw="__words"[3Q]})}}}"samplingRates"{set<int, std::__1::less<int>, std::__1::allocator<int> >="__tree_"{__tree<int, std::__1::less<int>, std::__1::allocator<int> >="__begin_node_"^{__tree_end_node<std::__1::__tree_node_base<void *> *>}"__pair1_"{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<int, void *> > >="__value_"{__tree_end_node<std::__1::__tree_node_base<void *> *>="__left_"^{__tree_node_base<void *>}}}"__pair3_"{__compressed_pair<unsigned long, std::__1::less<int> >="__value_"Q}}}"tasks"{set<std::__1::basic_string<char>, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::basic_string<char> > >="__tree_"{__tree<std::__1::basic_string<char>, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::basic_string<char> > >="__begin_node_"^{__tree_end_node<std::__1::__tree_node_base<void *> *>}"__pair1_"{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::basic_string<char>, void *> > >="__value_"{__tree_end_node<std::__1::__tree_node_base<void *> *>="__left_"^{__tree_node_base<void *>}}}"__pair3_"{__compressed_pair<unsigned long, std::__1::less<std::__1::basic_string<char> > >="__value_"Q}}}"osTypes"{set<std::__1::basic_string<char>, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::basic_string<char> > >="__tree_"{__tree<std::__1::basic_string<char>, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::basic_string<char> > >="__begin_node_"^{__tree_end_node<std::__1::__tree_node_base<void *> *>}"__pair1_"{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::basic_string<char>, void *> > >="__value_"{__tree_end_node<std::__1::__tree_node_base<void *> *>="__left_"^{__tree_node_base<void *>}}}"__pair3_"{__compressed_pair<unsigned long, std::__1::less<std::__1::basic_string<char> > >="__value_"Q}}}"language"{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >="__r_"{__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >="__value_"{__rep=""(?="__l"{__long="__cap_"Q"__size_"Q"__data_"*}"__s"{__short=""(?="__size_"C"__lx"c)"__data_"[23c]}"__r"{__raw="__words"[3Q]})}}}"phoneSetVersion"{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >="__r_"{__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >="__value_"{__rep=""(?="__l"{__long="__cap_"Q"__size_"Q"__data_"*}"__s"{__short=""(?="__size_"C"__lx"c)"__data_"[23c]}"__r"{__raw="__words"[3Q]})}}}"acousticProfileVersion"{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >="__r_"{__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >="__value_"{__rep=""(?="__l"{__long="__cap_"Q"__size_"Q"__data_"*}"__s"{__short=""(?="__size_"C"__lx"c)"__data_"[23c]}"__r"{__raw="__words"[3Q]})}}}"aceToQuasarTemplate"{map<std::__1::basic_string<char>, std::__1::basic_string<char>, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, std::__1::basic_string<char> > > >="__tree_"{__tree<std::__1::__value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::less<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__value_type<std::__1::basic_string<char>, std::__1::basic_string<char> > > >="__begin_node_"^{__tree_end_node<std::__1::__tree_node_base<void *> *>}"__pair1_"{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, void *> > >="__value_"{__tree_end_node<std::__1::__tree_node_base<void *> *>="__left_"^{__tree_node_base<void *>}}}"__pair3_"{__compressed_pair<unsigned long, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::less<std::__1::basic_string<char> >, true> >="__value_"Q}}}"quasarTemplateToAce"{map<std::__1::basic_string<char>, std::__1::vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > >, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, std::__1::vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > > > > >="__tree_"{__tree<std::__1::__value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > > >, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > > >, std::__1::less<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > > > > >="__begin_node_"^{__tree_end_node<std::__1::__tree_node_base<void *> *>}"__pair1_"{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > > >, void *> > >="__value_"{__tree_end_node<std::__1::__tree_node_base<void *> *>="__left_"^{__tree_node_base<void *>}}}"__pair3_"{__compressed_pair<unsigned long, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > > >, std::__1::less<std::__1::basic_string<char> >, true> >="__value_"Q}}}"quasarTemplateToEnumerationType"{map<std::__1::basic_string<char>, std::__1::basic_string<char>, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, std::__1::basic_string<char> > > >="__tree_"{__tree<std::__1::__value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::less<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__value_type<std::__1::basic_string<char>, std::__1::basic_string<char> > > >="__begin_node_"^{__tree_end_node<std::__1::__tree_node_base<void *> *>}"__pair1_"{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, void *> > >="__value_"{__tree_end_node<std::__1::__tree_node_base<void *> *>="__left_"^{__tree_node_base<void *>}}}"__pair3_"{__compressed_pair<unsigned long, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::less<std::__1::basic_string<char> >, true> >="__value_"Q}}}"g2pModelVersion"i"hybridEndpointerVersion"i}
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
v48@0:8@16@24@32@40
v32@0:8@16d24
v72@0:8@16q24q32d40@48d56q64
v32@0:8@"_EARSpeechRecognizer"16@"_EARSpeechRecognitionResult"24
v32@0:8@"_EARSpeechRecognizer"16@"NSError"24
v32@0:8@"_EARSpeechRecognizer"16@"NSArray"24
v48@0:8@"_EARSpeechRecognizer"16@"NSArray"24@"NSArray"32@"NSArray"40
v32@0:8@"_EARSpeechRecognizer"16@"_EARSpeechRecognitionResultPackage"24
v32@0:8@"_EARSpeechRecognizer"16d24
v32@0:8@"_EARSpeechRecognizer"16@"_EARSpeechRecognition"24
v72@0:8@"_EARSpeechRecognizer"16q24q32d40@"NSArray"48d56q64
@"NSObject<OS_dispatch_semaphore>"
@"NSError"
@40@0:8{shared_ptr<quasar::RecogAudioBufferBase>=^{RecogAudioBufferBase}^{__shared_weak_count}}16@32
v32@0:8r^s16Q24
v32@0:8{shared_ptr<quasar::RecogAudioBufferBase>=^{RecogAudioBufferBase}^{__shared_weak_count}}16
{shared_ptr<quasar::RecogAudioBufferBase>="__ptr_"^{RecogAudioBufferBase}"__cntrl_"^{__shared_weak_count}}
@"_EARSpeechRecognizer"
v76@0:8I16@20@28@36@44@52B60@64I72
@48@0:8{vector<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> >, std::__1::allocator<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> > > >=^{vector<quasar::Token, std::__1::allocator<quasar::Token> >}^{vector<quasar::Token, std::__1::allocator<quasar::Token> >}{__compressed_pair<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> > *, std::__1::allocator<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> > > >=^{vector<quasar::Token, std::__1::allocator<quasar::Token> >}}}16@40
@40@0:8@16Q24@32
{shared_ptr<quasar::SyncSpeechRecognizer>="__ptr_"^{SyncSpeechRecognizer}"__cntrl_"^{__shared_weak_count}}
{unique_ptr<quasar::ResultCombiner, std::__1::default_delete<quasar::ResultCombiner> >="__ptr_"{__compressed_pair<quasar::ResultCombiner *, std::__1::default_delete<quasar::ResultCombiner> >="__value_"^{ResultCombiner}}}
@24@0:8r^{LDContext={map<quasar::Locale, double, std::__1::less<quasar::Locale>, std::__1::allocator<std::__1::pair<const quasar::Locale, double> > >={__tree<std::__1::__value_type<quasar::Locale, double>, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true>, std::__1::allocator<std::__1::__value_type<quasar::Locale, double> > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<quasar::Locale, double>, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true> >=Q}}}{optional<std::__1::set<quasar::Locale, std::__1::less<quasar::Locale>, std::__1::allocator<quasar::Locale> > >=(?=c{set<quasar::Locale, std::__1::less<quasar::Locale>, std::__1::allocator<quasar::Locale> >={__tree<quasar::Locale, std::__1::less<quasar::Locale>, std::__1::allocator<quasar::Locale> >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<quasar::Locale, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::less<quasar::Locale> >=Q}}})B}{optional<quasar::Locale>=(?=c{Locale={basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}})B}{optional<bool>=(?=cB)B}{optional<std::__1::vector<quasar::Locale, std::__1::allocator<quasar::Locale> > >=(?=c{vector<quasar::Locale, std::__1::allocator<quasar::Locale> >=^{Locale}^{Locale}{__compressed_pair<quasar::Locale *, std::__1::allocator<quasar::Locale> >=^{Locale}}})B}{optional<std::__1::map<quasar::Locale, double, std::__1::less<quasar::Locale>, std::__1::allocator<std::__1::pair<const quasar::Locale, double> > > >=(?=c{map<quasar::Locale, double, std::__1::less<quasar::Locale>, std::__1::allocator<std::__1::pair<const quasar::Locale, double> > >={__tree<std::__1::__value_type<quasar::Locale, double>, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true>, std::__1::allocator<std::__1::__value_type<quasar::Locale, double> > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<quasar::Locale, double>, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true> >=Q}}})B}{optional<std::__1::map<quasar::Locale, double, std::__1::less<quasar::Locale>, std::__1::allocator<std::__1::pair<const quasar::Locale, double> > > >=(?=c{map<quasar::Locale, double, std::__1::less<quasar::Locale>, std::__1::allocator<std::__1::pair<const quasar::Locale, double> > >={__tree<std::__1::__value_type<quasar::Locale, double>, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true>, std::__1::allocator<std::__1::__value_type<quasar::Locale, double> > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<quasar::Locale, double>, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true> >=Q}}})B}{optional<quasar::Locale>=(?=c{Locale={basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}})B}{optional<quasar::Locale>=(?=c{Locale={basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}})B}{optional<std::__1::map<quasar::Locale, double, std::__1::less<quasar::Locale>, std::__1::allocator<std::__1::pair<const quasar::Locale, double> > > >=(?=c{map<quasar::Locale, double, std::__1::less<quasar::Locale>, std::__1::allocator<std::__1::pair<const quasar::Locale, double> > >={__tree<std::__1::__value_type<quasar::Locale, double>, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true>, std::__1::allocator<std::__1::__value_type<quasar::Locale, double> > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<quasar::Locale, double>, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true> >=Q}}})B}}16
{LDContext={map<quasar::Locale, double, std::__1::less<quasar::Locale>, std::__1::allocator<std::__1::pair<const quasar::Locale, double> > >={__tree<std::__1::__value_type<quasar::Locale, double>, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true>, std::__1::allocator<std::__1::__value_type<quasar::Locale, double> > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<quasar::Locale, double>, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true> >=Q}}}{optional<std::__1::set<quasar::Locale, std::__1::less<quasar::Locale>, std::__1::allocator<quasar::Locale> > >=(?=c{set<quasar::Locale, std::__1::less<quasar::Locale>, std::__1::allocator<quasar::Locale> >={__tree<quasar::Locale, std::__1::less<quasar::Locale>, std::__1::allocator<quasar::Locale> >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<quasar::Locale, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::less<quasar::Locale> >=Q}}})B}{optional<quasar::Locale>=(?=c{Locale={basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}})B}{optional<bool>=(?=cB)B}{optional<std::__1::vector<quasar::Locale, std::__1::allocator<quasar::Locale> > >=(?=c{vector<quasar::Locale, std::__1::allocator<quasar::Locale> >=^{Locale}^{Locale}{__compressed_pair<quasar::Locale *, std::__1::allocator<quasar::Locale> >=^{Locale}}})B}{optional<std::__1::map<quasar::Locale, double, std::__1::less<quasar::Locale>, std::__1::allocator<std::__1::pair<const quasar::Locale, double> > > >=(?=c{map<quasar::Locale, double, std::__1::less<quasar::Locale>, std::__1::allocator<std::__1::pair<const quasar::Locale, double> > >={__tree<std::__1::__value_type<quasar::Locale, double>, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true>, std::__1::allocator<std::__1::__value_type<quasar::Locale, double> > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<quasar::Locale, double>, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true> >=Q}}})B}{optional<std::__1::map<quasar::Locale, double, std::__1::less<quasar::Locale>, std::__1::allocator<std::__1::pair<const quasar::Locale, double> > > >=(?=c{map<quasar::Locale, double, std::__1::less<quasar::Locale>, std::__1::allocator<std::__1::pair<const quasar::Locale, double> > >={__tree<std::__1::__value_type<quasar::Locale, double>, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true>, std::__1::allocator<std::__1::__value_type<quasar::Locale, double> > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<quasar::Locale, double>, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true> >=Q}}})B}{optional<quasar::Locale>=(?=c{Locale={basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}})B}{optional<quasar::Locale>=(?=c{Locale={basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}})B}{optional<std::__1::map<quasar::Locale, double, std::__1::less<quasar::Locale>, std::__1::allocator<std::__1::pair<const quasar::Locale, double> > > >=(?=c{map<quasar::Locale, double, std::__1::less<quasar::Locale>, std::__1::allocator<std::__1::pair<const quasar::Locale, double> > >={__tree<std::__1::__value_type<quasar::Locale, double>, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true>, std::__1::allocator<std::__1::__value_type<quasar::Locale, double> > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<quasar::Locale, double>, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true> >=Q}}})B}}16@0:8
@"NSNumber"
@"_EARTokenizer"
{unique_ptr<quasar::Munger, std::__1::default_delete<quasar::Munger> >="__ptr_"{__compressed_pair<quasar::Munger *, std::__1::default_delete<quasar::Munger> >="__value_"^{Munger}}}
@96@0:8@16@24@32f40@44i52f56@60f68@72^f80^@88
@96@0:8@16@24@32f40@44i52f56@60f68@72^@80^@88
{TokenProns={basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}{vector<quasar::PronChoice, std::__1::allocator<quasar::PronChoice> >=^{PronChoice}^{PronChoice}{__compressed_pair<quasar::PronChoice *, std::__1::allocator<quasar::PronChoice> >=^{PronChoice}}}{vector<quasar::PronChoice, std::__1::allocator<quasar::PronChoice> >=^{PronChoice}^{PronChoice}{__compressed_pair<quasar::PronChoice *, std::__1::allocator<quasar::PronChoice> >=^{PronChoice}}}}16@0:8
@64@0:8@16@24@32@40@48q56
{unique_ptr<quasar::KeywordFinder, std::__1::default_delete<quasar::KeywordFinder> >="__ptr_"{__compressed_pair<quasar::KeywordFinder *, std::__1::default_delete<quasar::KeywordFinder> >="__value_"^{KeywordFinder}}}
@32@0:8@16Q24
@24@0:8@?16
@"NSURL"
{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}16@0:8
@32@0:8{basic_string_view<char, std::__1::char_traits<char> >=*Q}16
@"NSLocale"
v40@0:8Q16@24@32
{shared_ptr<quasar::LmData>=^{LmData}^{__shared_weak_count}}16@0:8
{shared_ptr<quasar::LmData>="__ptr_"^{LmData}"__cntrl_"^{__shared_weak_count}}
@32@0:8{shared_ptr<quasar::LmModel>=^{LmModel}^{__shared_weak_count}}16
B32@0:8@16@?24
{shared_ptr<quasar::LmModel>=^{LmModel}^{__shared_weak_count}}16@0:8
{shared_ptr<quasar::LmModel>="__ptr_"^{LmModel}"__cntrl_"^{__shared_weak_count}}
B40@0:8@16@24^@32
B48@0:8@16@24^@32^f40
B56@0:8@16@24@?32^@40^f48
{shared_ptr<quasar::LmEvaluator>="__ptr_"^{LmEvaluator}"__cntrl_"^{__shared_weak_count}}
{shared_ptr<quasar::LmLoader>="__ptr_"^{LmLoader}"__cntrl_"^{__shared_weak_count}}
@36@0:8@16@24i32
i16@0:8
v36@0:8@16@24B32
{shared_ptr<quasar::AppLmData>=^{AppLmData}^{__shared_weak_count}}16@0:8
{shared_ptr<quasar::AppLmData>="__ptr_"^{AppLmData}"__cntrl_"^{__shared_weak_count}}
B44@0:8@16@24f32^@36
{unique_ptr<quasar::CustomLMBuilder, std::__1::default_delete<quasar::CustomLMBuilder> >="__ptr_"{__compressed_pair<quasar::CustomLMBuilder *, std::__1::default_delete<quasar::CustomLMBuilder> >="__value_"^{CustomLMBuilder}}}
@48@0:8@16@24Q32@40
@56@0:8@16@24Q32@40@48
{shared_ptr<quasar::PSRAudioProcessor>="__ptr_"^{PSRAudioProcessor}"__cntrl_"^{__shared_weak_count}}
{SystemConfig="_vptr$OptionsItf"^^?"jsonConfigFilePath"{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >="__r_"{__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >="__value_"{__rep=""(?="__l"{__long="__cap_"Q"__size_"Q"__data_"*}"__s"{__short=""(?="__size_"C"__lx"c)"__data_"[23c]}"__r"{__raw="__words"[3Q]})}}}"configFileVersion"{Version="versionMajor"i"versionMinor"i}"configPath"{Path="str"{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >="__r_"{__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >="__value_"{__rep=""(?="__l"{__long="__cap_"Q"__size_"Q"__data_"*}"__s"{__short=""(?="__size_"C"__lx"c)"__data_"[23c]}"__r"{__raw="__words"[3Q]})}}}}"prefix"{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >="__r_"{__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >="__value_"{__rep=""(?="__l"{__long="__cap_"Q"__size_"Q"__data_"*}"__s"{__short=""(?="__size_"C"__lx"c)"__data_"[23c]}"__r"{__raw="__words"[3Q]})}}}"pTree"{PTree="dataType"i"dataValue"{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >="__r_"{__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >="__value_"{__rep=""(?="__l"{__long="__cap_"Q"__size_"Q"__data_"*}"__s"{__short=""(?="__size_"C"__lx"c)"__data_"[23c]}"__r"{__raw="__words"[3Q]})}}}"map"{vector<std::__1::pair<std::__1::basic_string<char>, quasar::PTree>, std::__1::allocator<std::__1::pair<std::__1::basic_string<char>, quasar::PTree> > >="__begin_"^{pair<std::__1::basic_string<char>, quasar::PTree>}"__end_"^{pair<std::__1::basic_string<char>, quasar::PTree>}"__end_cap_"{__compressed_pair<std::__1::pair<std::__1::basic_string<char>, quasar::PTree> *, std::__1::allocator<std::__1::pair<std::__1::basic_string<char>, quasar::PTree> > >="__value_"^{pair<std::__1::basic_string<char>, quasar::PTree>}}}"isALeaf"B}"speechModelInfo"{SpeechModelInfo="version"{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >="__r_"{__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >="__value_"{__rep=""(?="__l"{__long="__cap_"Q"__size_"Q"__data_"*}"__s"{__short=""(?="__size_"C"__lx"c)"__data_"[23c]}"__r"{__raw="__words"[3Q]})}}}"samplingRates"{set<int, std::__1::less<int>, std::__1::allocator<int> >="__tree_"{__tree<int, std::__1::less<int>, std::__1::allocator<int> >="__begin_node_"^{__tree_end_node<std::__1::__tree_node_base<void *> *>}"__pair1_"{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<int, void *> > >="__value_"{__tree_end_node<std::__1::__tree_node_base<void *> *>="__left_"^{__tree_node_base<void *>}}}"__pair3_"{__compressed_pair<unsigned long, std::__1::less<int> >="__value_"Q}}}"tasks"{set<std::__1::basic_string<char>, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::basic_string<char> > >="__tree_"{__tree<std::__1::basic_string<char>, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::basic_string<char> > >="__begin_node_"^{__tree_end_node<std::__1::__tree_node_base<void *> *>}"__pair1_"{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::basic_string<char>, void *> > >="__value_"{__tree_end_node<std::__1::__tree_node_base<void *> *>="__left_"^{__tree_node_base<void *>}}}"__pair3_"{__compressed_pair<unsigned long, std::__1::less<std::__1::basic_string<char> > >="__value_"Q}}}"osTypes"{set<std::__1::basic_string<char>, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::basic_string<char> > >="__tree_"{__tree<std::__1::basic_string<char>, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::basic_string<char> > >="__begin_node_"^{__tree_end_node<std::__1::__tree_node_base<void *> *>}"__pair1_"{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::basic_string<char>, void *> > >="__value_"{__tree_end_node<std::__1::__tree_node_base<void *> *>="__left_"^{__tree_node_base<void *>}}}"__pair3_"{__compressed_pair<unsigned long, std::__1::less<std::__1::basic_string<char> > >="__value_"Q}}}"language"{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >="__r_"{__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >="__value_"{__rep=""(?="__l"{__long="__cap_"Q"__size_"Q"__data_"*}"__s"{__short=""(?="__size_"C"__lx"c)"__data_"[23c]}"__r"{__raw="__words"[3Q]})}}}"phoneSetVersion"{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >="__r_"{__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >="__value_"{__rep=""(?="__l"{__long="__cap_"Q"__size_"Q"__data_"*}"__s"{__short=""(?="__size_"C"__lx"c)"__data_"[23c]}"__r"{__raw="__words"[3Q]})}}}"acousticProfileVersion"{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >="__r_"{__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >="__value_"{__rep=""(?="__l"{__long="__cap_"Q"__size_"Q"__data_"*}"__s"{__short=""(?="__size_"C"__lx"c)"__data_"[23c]}"__r"{__raw="__words"[3Q]})}}}"aceToQuasarTemplate"{map<std::__1::basic_string<char>, std::__1::basic_string<char>, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, std::__1::basic_string<char> > > >="__tree_"{__tree<std::__1::__value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::less<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__value_type<std::__1::basic_string<char>, std::__1::basic_string<char> > > >="__begin_node_"^{__tree_end_node<std::__1::__tree_node_base<void *> *>}"__pair1_"{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, void *> > >="__value_"{__tree_end_node<std::__1::__tree_node_base<void *> *>="__left_"^{__tree_node_base<void *>}}}"__pair3_"{__compressed_pair<unsigned long, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::less<std::__1::basic_string<char> >, true> >="__value_"Q}}}"quasarTemplateToAce"{map<std::__1::basic_string<char>, std::__1::vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > >, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, std::__1::vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > > > > >="__tree_"{__tree<std::__1::__value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > > >, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > > >, std::__1::less<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > > > > >="__begin_node_"^{__tree_end_node<std::__1::__tree_node_base<void *> *>}"__pair1_"{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > > >, void *> > >="__value_"{__tree_end_node<std::__1::__tree_node_base<void *> *>="__left_"^{__tree_node_base<void *>}}}"__pair3_"{__compressed_pair<unsigned long, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > > >, std::__1::less<std::__1::basic_string<char> >, true> >="__value_"Q}}}"quasarTemplateToEnumerationType"{map<std::__1::basic_string<char>, std::__1::basic_string<char>, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, std::__1::basic_string<char> > > >="__tree_"{__tree<std::__1::__value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::less<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__value_type<std::__1::basic_string<char>, std::__1::basic_string<char> > > >="__begin_node_"^{__tree_end_node<std::__1::__tree_node_base<void *> *>}"__pair1_"{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, void *> > >="__value_"{__tree_end_node<std::__1::__tree_node_base<void *> *>="__left_"^{__tree_node_base<void *>}}}"__pair3_"{__compressed_pair<unsigned long, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::less<std::__1::basic_string<char> >, true> >="__value_"Q}}}"g2pModelVersion"i"hybridEndpointerVersion"i}"translationModelInfo"{TranslationModelInfo="version"{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >="__r_"{__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >="__value_"{__rep=""(?="__l"{__long="__cap_"Q"__size_"Q"__data_"*}"__s"{__short=""(?="__size_"C"__lx"c)"__data_"[23c]}"__r"{__raw="__words"[3Q]})}}}"tasks"{set<std::__1::basic_string<char>, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::basic_string<char> > >="__tree_"{__tree<std::__1::basic_string<char>, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::basic_string<char> > >="__begin_node_"^{__tree_end_node<std::__1::__tree_node_base<void *> *>}"__pair1_"{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::basic_string<char>, void *> > >="__value_"{__tree_end_node<std::__1::__tree_node_base<void *> *>="__left_"^{__tree_node_base<void *>}}}"__pair3_"{__compressed_pair<unsigned long, std::__1::less<std::__1::basic_string<char> > >="__value_"Q}}}"languagePairs"{vector<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> > > >="__begin_"^{pair<std::__1::basic_string<char>, std::__1::basic_string<char> >}"__end_"^{pair<std::__1::basic_string<char>, std::__1::basic_string<char> >}"__end_cap_"{__compressed_pair<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> > *, std::__1::allocator<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> > > >="__value_"^{pair<std::__1::basic_string<char>, std::__1::basic_string<char> >}}}"taskSpecificLanguagePairs"{unordered_map<std::__1::basic_string<char>, std::__1::vector<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> > > >, std::__1::hash<std::__1::basic_string<char> >, std::__1::equal_to<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, std::__1::vector<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> > > > > > >="__table_"{__hash_table<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> > > > >, std::__1::__unordered_map_hasher<std::__1::basic_string<char>, std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> > > > >, std::__1::hash<std::__1::basic_string<char> >, true>, std::__1::__unordered_map_equal<std::__1::basic_string<char>, std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> > > > >, std::__1::equal_to<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> > > > > > >="__bucket_list_"{unique_ptr<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> > > > >, void *> *> *[], std::__1::__bucket_list_deallocator<std::__1::allocator<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> > > > >, void *> *> *> > >="__ptr_"{__compressed_pair<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> > > > >, void *> *> **, std::__1::__bucket_list_deallocator<std::__1::allocator<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> > > > >, void *> *> *> > >="__value_"^^{__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> > > > >, void *> *>}"__value_"{__bucket_list_deallocator<std::__1::allocator<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> > > > >, void *> *> *> >="__data_"{__compressed_pair<unsigned long, std::__1::allocator<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> > > > >, void *> *> *> >="__value_"Q}}}}"__p1_"{__compressed_pair<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> > > > >, void *> *>, std::__1::allocator<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> > > > >, void *> > >="__value_"{__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> > > > >, void *> *>="__next_"^{__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> > > > >, void *> *>}}}"__p2_"{__compressed_pair<unsigned long, std::__1::__unordered_map_hasher<std::__1::basic_string<char>, std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> > > > >, std::__1::hash<std::__1::basic_string<char> >, true> >="__value_"Q}"__p3_"{__compressed_pair<float, std::__1::__unordered_map_equal<std::__1::basic_string<char>, std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> > > > >, std::__1::equal_to<std::__1::basic_string<char> >, true> >="__value_"f}}}"pairSpecificSettings"{unordered_map<std::__1::basic_string<char>, quasar::TranslationPairSetting, std::__1::hash<std::__1::basic_string<char> >, std::__1::equal_to<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, quasar::TranslationPairSetting> > >="__table_"{__hash_table<std::__1::__hash_value_type<std::__1::basic_string<char>, quasar::TranslationPairSetting>, std::__1::__unordered_map_hasher<std::__1::basic_string<char>, std::__1::__hash_value_type<std::__1::basic_string<char>, quasar::TranslationPairSetting>, std::__1::hash<std::__1::basic_string<char> >, true>, std::__1::__unordered_map_equal<std::__1::basic_string<char>, std::__1::__hash_value_type<std::__1::basic_string<char>, quasar::TranslationPairSetting>, std::__1::equal_to<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__hash_value_type<std::__1::basic_string<char>, quasar::TranslationPairSetting> > >="__bucket_list_"{unique_ptr<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, quasar::TranslationPairSetting>, void *> *> *[], std::__1::__bucket_list_deallocator<std::__1::allocator<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, quasar::TranslationPairSetting>, void *> *> *> > >="__ptr_"{__compressed_pair<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, quasar::TranslationPairSetting>, void *> *> **, std::__1::__bucket_list_deallocator<std::__1::allocator<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, quasar::TranslationPairSetting>, void *> *> *> > >="__value_"^^{__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, quasar::TranslationPairSetting>, void *> *>}"__value_"{__bucket_list_deallocator<std::__1::allocator<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, quasar::TranslationPairSetting>, void *> *> *> >="__data_"{__compressed_pair<unsigned long, std::__1::allocator<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, quasar::TranslationPairSetting>, void *> *> *> >="__value_"Q}}}}"__p1_"{__compressed_pair<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, quasar::TranslationPairSetting>, void *> *>, std::__1::allocator<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, quasar::TranslationPairSetting>, void *> > >="__value_"{__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, quasar::TranslationPairSetting>, void *> *>="__next_"^{__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, quasar::TranslationPairSetting>, void *> *>}}}"__p2_"{__compressed_pair<unsigned long, std::__1::__unordered_map_hasher<std::__1::basic_string<char>, std::__1::__hash_value_type<std::__1::basic_string<char>, quasar::TranslationPairSetting>, std::__1::hash<std::__1::basic_string<char> >, true> >="__value_"Q}"__p3_"{__compressed_pair<float, std::__1::__unordered_map_equal<std::__1::basic_string<char>, std::__1::__hash_value_type<std::__1::basic_string<char>, quasar::TranslationPairSetting>, std::__1::equal_to<std::__1::basic_string<char> >, true> >="__value_"f}}}"taskLangPairSpecificSettings"{unordered_map<std::__1::basic_string<char>, std::__1::unordered_map<std::__1::basic_string<char>, quasar::TranslationPairSetting, std::__1::hash<std::__1::basic_string<char> >, std::__1::equal_to<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, quasar::TranslationPairSetting> > >, std::__1::hash<std::__1::basic_string<char> >, std::__1::equal_to<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, std::__1::unordered_map<std::__1::basic_string<char>, quasar::TranslationPairSetting, std::__1::hash<std::__1::basic_string<char> >, std::__1::equal_to<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, quasar::TranslationPairSetting> > > > > >="__table_"{__hash_table<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::unordered_map<std::__1::basic_string<char>, quasar::TranslationPairSetting, std::__1::hash<std::__1::basic_string<char> >, std::__1::equal_to<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, quasar::TranslationPairSetting> > > >, std::__1::__unordered_map_hasher<std::__1::basic_string<char>, std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::unordered_map<std::__1::basic_string<char>, quasar::TranslationPairSetting, std::__1::hash<std::__1::basic_string<char> >, std::__1::equal_to<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, quasar::TranslationPairSetting> > > >, std::__1::hash<std::__1::basic_string<char> >, true>, std::__1::__unordered_map_equal<std::__1::basic_string<char>, std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::unordered_map<std::__1::basic_string<char>, quasar::TranslationPairSetting, std::__1::hash<std::__1::basic_string<char> >, std::__1::equal_to<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, quasar::TranslationPairSetting> > > >, std::__1::equal_to<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::unordered_map<std::__1::basic_string<char>, quasar::TranslationPairSetting, std::__1::hash<std::__1::basic_string<char> >, std::__1::equal_to<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, quasar::TranslationPairSetting> > > > > >="__bucket_list_"{unique_ptr<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::unordered_map<std::__1::basic_string<char>, quasar::TranslationPairSetting, std::__1::hash<std::__1::basic_string<char> >, std::__1::equal_to<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, quasar::TranslationPairSetting> > > >, void *> *> *[], std::__1::__bucket_list_deallocator<std::__1::allocator<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::unordered_map<std::__1::basic_string<char>, quasar::TranslationPairSetting, std::__1::hash<std::__1::basic_string<char> >, std::__1::equal_to<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, quasar::TranslationPairSetting> > > >, void *> *> *> > >="__ptr_"{__compressed_pair<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::unordered_map<std::__1::basic_string<char>, quasar::TranslationPairSetting, std::__1::hash<std::__1::basic_string<char> >, std::__1::equal_to<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, quasar::TranslationPairSetting> > > >, void *> *> **, std::__1::__bucket_list_deallocator<std::__1::allocator<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::unordered_map<std::__1::basic_string<char>, quasar::TranslationPairSetting, std::__1::hash<std::__1::basic_string<char> >, std::__1::equal_to<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, quasar::TranslationPairSetting> > > >, void *> *> *> > >="__value_"^^{__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::unordered_map<std::__1::basic_string<char>, quasar::TranslationPairSetting, std::__1::hash<std::__1::basic_string<char> >, std::__1::equal_to<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, quasar::TranslationPairSetting> > > >, void *> *>}"__value_"{__bucket_list_deallocator<std::__1::allocator<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::unordered_map<std::__1::basic_string<char>, quasar::TranslationPairSetting, std::__1::hash<std::__1::basic_string<char> >, std::__1::equal_to<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, quasar::TranslationPairSetting> > > >, void *> *> *> >="__data_"{__compressed_pair<unsigned long, std::__1::allocator<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::unordered_map<std::__1::basic_string<char>, quasar::TranslationPairSetting, std::__1::hash<std::__1::basic_string<char> >, std::__1::equal_to<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, quasar::TranslationPairSetting> > > >, void *> *> *> >="__value_"Q}}}}"__p1_"{__compressed_pair<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::unordered_map<std::__1::basic_string<char>, quasar::TranslationPairSetting, std::__1::hash<std::__1::basic_string<char> >, std::__1::equal_to<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, quasar::TranslationPairSetting> > > >, void *> *>, std::__1::allocator<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::unordered_map<std::__1::basic_string<char>, quasar::TranslationPairSetting, std::__1::hash<std::__1::basic_string<char> >, std::__1::equal_to<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, quasar::TranslationPairSetting> > > >, void *> > >="__value_"{__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::unordered_map<std::__1::basic_string<char>, quasar::TranslationPairSetting, std::__1::hash<std::__1::basic_string<char> >, std::__1::equal_to<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, quasar::TranslationPairSetting> > > >, void *> *>="__next_"^{__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::unordered_map<std::__1::basic_string<char>, quasar::TranslationPairSetting, std::__1::hash<std::__1::basic_string<char> >, std::__1::equal_to<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, quasar::TranslationPairSetting> > > >, void *> *>}}}"__p2_"{__compressed_pair<unsigned long, std::__1::__unordered_map_hasher<std::__1::basic_string<char>, std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::unordered_map<std::__1::basic_string<char>, quasar::TranslationPairSetting, std::__1::hash<std::__1::basic_string<char> >, std::__1::equal_to<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, quasar::TranslationPairSetting> > > >, std::__1::hash<std::__1::basic_string<char> >, true> >="__value_"Q}"__p3_"{__compressed_pair<float, std::__1::__unordered_map_equal<std::__1::basic_string<char>, std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::unordered_map<std::__1::basic_string<char>, quasar::TranslationPairSetting, std::__1::hash<std::__1::basic_string<char> >, std::__1::equal_to<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, quasar::TranslationPairSetting> > > >, std::__1::equal_to<std::__1::basic_string<char> >, true> >="__value_"f}}}}"modelLoader"{shared_ptr<quasar::ModelLoader>="__ptr_"^{ModelLoader}"__cntrl_"^{__shared_weak_count}}"hybridClientConfigs"{HybridClientConfigs="hybridEndpointerThresholds"{map<int, std::__1::map<std::__1::basic_string<char>, double, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, double> > >, std::__1::less<int>, std::__1::allocator<std::__1::pair<const int, std::__1::map<std::__1::basic_string<char>, double, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, double> > > > > >="__tree_"{__tree<std::__1::__value_type<int, std::__1::map<std::__1::basic_string<char>, double, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, double> > > >, std::__1::__map_value_compare<int, std::__1::__value_type<int, std::__1::map<std::__1::basic_string<char>, double, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, double> > > >, std::__1::less<int>, true>, std::__1::allocator<std::__1::__value_type<int, std::__1::map<std::__1::basic_string<char>, double, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, double> > > > > >="__begin_node_"^{__tree_end_node<std::__1::__tree_node_base<void *> *>}"__pair1_"{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<int, std::__1::map<std::__1::basic_string<char>, double, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, double> > > >, void *> > >="__value_"{__tree_end_node<std::__1::__tree_node_base<void *> *>="__left_"^{__tree_node_base<void *>}}}"__pair3_"{__compressed_pair<unsigned long, std::__1::__map_value_compare<int, std::__1::__value_type<int, std::__1::map<std::__1::basic_string<char>, double, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, double> > > >, std::__1::less<int>, true> >="__value_"Q}}}"hybridEndpointerExtraDelayFrequency"{map<std::__1::basic_string<char>, int, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, int> > >="__tree_"{__tree<std::__1::__value_type<std::__1::basic_string<char>, int>, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, int>, std::__1::less<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__value_type<std::__1::basic_string<char>, int> > >="__begin_node_"^{__tree_end_node<std::__1::__tree_node_base<void *> *>}"__pair1_"{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<std::__1::basic_string<char>, int>, void *> > >="__value_"{__tree_end_node<std::__1::__tree_node_base<void *> *>="__left_"^{__tree_node_base<void *>}}}"__pair3_"{__compressed_pair<unsigned long, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, int>, std::__1::less<std::__1::basic_string<char> >, true> >="__value_"Q}}}}"mainModelVersion"{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >="__r_"{__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >="__value_"{__rep=""(?="__l"{__long="__cap_"Q"__size_"Q"__data_"*}"__s"{__short=""(?="__size_"C"__lx"c)"__data_"[23c]}"__r"{__raw="__words"[3Q]})}}}"boolMap"{map<std::__1::basic_string<char>, bool *, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, bool *> > >="__tree_"{__tree<std::__1::__value_type<std::__1::basic_string<char>, bool *>, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, bool *>, std::__1::less<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__value_type<std::__1::basic_string<char>, bool *> > >="__begin_node_"^{__tree_end_node<std::__1::__tree_node_base<void *> *>}"__pair1_"{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<std::__1::basic_string<char>, bool *>, void *> > >="__value_"{__tree_end_node<std::__1::__tree_node_base<void *> *>="__left_"^{__tree_node_base<void *>}}}"__pair3_"{__compressed_pair<unsigned long, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, bool *>, std::__1::less<std::__1::basic_string<char> >, true> >="__value_"Q}}}"intMap"{map<std::__1::basic_string<char>, int *, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, int *> > >="__tree_"{__tree<std::__1::__value_type<std::__1::basic_string<char>, int *>, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, int *>, std::__1::less<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__value_type<std::__1::basic_string<char>, int *> > >="__begin_node_"^{__tree_end_node<std::__1::__tree_node_base<void *> *>}"__pair1_"{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<std::__1::basic_string<char>, int *>, void *> > >="__value_"{__tree_end_node<std::__1::__tree_node_base<void *> *>="__left_"^{__tree_node_base<void *>}}}"__pair3_"{__compressed_pair<unsigned long, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, int *>, std::__1::less<std::__1::basic_string<char> >, true> >="__value_"Q}}}"uintMap"{map<std::__1::basic_string<char>, unsigned int *, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, unsigned int *> > >="__tree_"{__tree<std::__1::__value_type<std::__1::basic_string<char>, unsigned int *>, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, unsigned int *>, std::__1::less<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__value_type<std::__1::basic_string<char>, unsigned int *> > >="__begin_node_"^{__tree_end_node<std::__1::__tree_node_base<void *> *>}"__pair1_"{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<std::__1::basic_string<char>, unsigned int *>, void *> > >="__value_"{__tree_end_node<std::__1::__tree_node_base<void *> *>="__left_"^{__tree_node_base<void *>}}}"__pair3_"{__compressed_pair<unsigned long, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, unsigned int *>, std::__1::less<std::__1::basic_string<char> >, true> >="__value_"Q}}}"int64Map"{map<std::__1::basic_string<char>, long long *, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, long long *> > >="__tree_"{__tree<std::__1::__value_type<std::__1::basic_string<char>, long long *>, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, long long *>, std::__1::less<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__value_type<std::__1::basic_string<char>, long long *> > >="__begin_node_"^{__tree_end_node<std::__1::__tree_node_base<void *> *>}"__pair1_"{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<std::__1::basic_string<char>, long long *>, void *> > >="__value_"{__tree_end_node<std::__1::__tree_node_base<void *> *>="__left_"^{__tree_node_base<void *>}}}"__pair3_"{__compressed_pair<unsigned long, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, long long *>, std::__1::less<std::__1::basic_string<char> >, true> >="__value_"Q}}}"floatMap"{map<std::__1::basic_string<char>, float *, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, float *> > >="__tree_"{__tree<std::__1::__value_type<std::__1::basic_string<char>, float *>, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, float *>, std::__1::less<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__value_type<std::__1::basic_string<char>, float *> > >="__begin_node_"^{__tree_end_node<std::__1::__tree_node_base<void *> *>}"__pair1_"{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<std::__1::basic_string<char>, float *>, void *> > >="__value_"{__tree_end_node<std::__1::__tree_node_base<void *> *>="__left_"^{__tree_node_base<void *>}}}"__pair3_"{__compressed_pair<unsigned long, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, float *>, std::__1::less<std::__1::basic_string<char> >, true> >="__value_"Q}}}"doubleMap"{map<std::__1::basic_string<char>, double *, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, double *> > >="__tree_"{__tree<std::__1::__value_type<std::__1::basic_string<char>, double *>, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, double *>, std::__1::less<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__value_type<std::__1::basic_string<char>, double *> > >="__begin_node_"^{__tree_end_node<std::__1::__tree_node_base<void *> *>}"__pair1_"{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<std::__1::basic_string<char>, double *>, void *> > >="__value_"{__tree_end_node<std::__1::__tree_node_base<void *> *>="__left_"^{__tree_node_base<void *>}}}"__pair3_"{__compressed_pair<unsigned long, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, double *>, std::__1::less<std::__1::basic_string<char> >, true> >="__value_"Q}}}"stringMap"{map<std::__1::basic_string<char>, std::__1::basic_string<char> *, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, std::__1::basic_string<char> *> > >="__tree_"{__tree<std::__1::__value_type<std::__1::basic_string<char>, std::__1::basic_string<char> *>, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, std::__1::basic_string<char> *>, std::__1::less<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__value_type<std::__1::basic_string<char>, std::__1::basic_string<char> *> > >="__begin_node_"^{__tree_end_node<std::__1::__tree_node_base<void *> *>}"__pair1_"{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<std::__1::basic_string<char>, std::__1::basic_string<char> *>, void *> > >="__value_"{__tree_end_node<std::__1::__tree_node_base<void *> *>="__left_"^{__tree_node_base<void *>}}}"__pair3_"{__compressed_pair<unsigned long, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, std::__1::basic_string<char> *>, std::__1::less<std::__1::basic_string<char> >, true> >="__value_"Q}}}"stringVecMap"{map<std::__1::basic_string<char>, std::__1::vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > > *, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, std::__1::vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > > *> > >="__tree_"{__tree<std::__1::__value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > > *>, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > > *>, std::__1::less<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > > *> > >="__begin_node_"^{__tree_end_node<std::__1::__tree_node_base<void *> *>}"__pair1_"{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > > *>, void *> > >="__value_"{__tree_end_node<std::__1::__tree_node_base<void *> *>="__left_"^{__tree_node_base<void *>}}}"__pair3_"{__compressed_pair<unsigned long, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > > *>, std::__1::less<std::__1::basic_string<char> >, true> >="__value_"Q}}}"stringPairVecMap"{map<std::__1::basic_string<char>, std::__1::vector<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> > > > *, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, std::__1::vector<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> > > > *> > >="__tree_"{__tree<std::__1::__value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> > > > *>, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> > > > *>, std::__1::less<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> > > > *> > >="__begin_node_"^{__tree_end_node<std::__1::__tree_node_base<void *> *>}"__pair1_"{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> > > > *>, void *> > >="__value_"{__tree_end_node<std::__1::__tree_node_base<void *> *>="__left_"^{__tree_node_base<void *>}}}"__pair3_"{__compressed_pair<unsigned long, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> > > > *>, std::__1::less<std::__1::basic_string<char> >, true> >="__value_"Q}}}"paramMinVersionMap"{map<std::__1::basic_string<char>, quasar::SystemConfig::Version, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, quasar::SystemConfig::Version> > >="__tree_"{__tree<std::__1::__value_type<std::__1::basic_string<char>, quasar::SystemConfig::Version>, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, quasar::SystemConfig::Version>, std::__1::less<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__value_type<std::__1::basic_string<char>, quasar::SystemConfig::Version> > >="__begin_node_"^{__tree_end_node<std::__1::__tree_node_base<void *> *>}"__pair1_"{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<std::__1::basic_string<char>, quasar::SystemConfig::Version>, void *> > >="__value_"{__tree_end_node<std::__1::__tree_node_base<void *> *>="__left_"^{__tree_node_base<void *>}}}"__pair3_"{__compressed_pair<unsigned long, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, quasar::SystemConfig::Version>, std::__1::less<std::__1::basic_string<char> >, true> >="__value_"Q}}}"paramMaxVersionMap"{map<std::__1::basic_string<char>, quasar::SystemConfig::Version, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, quasar::SystemConfig::Version> > >="__tree_"{__tree<std::__1::__value_type<std::__1::basic_string<char>, quasar::SystemConfig::Version>, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, quasar::SystemConfig::Version>, std::__1::less<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__value_type<std::__1::basic_string<char>, quasar::SystemConfig::Version> > >="__begin_node_"^{__tree_end_node<std::__1::__tree_node_base<void *> *>}"__pair1_"{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<std::__1::basic_string<char>, quasar::SystemConfig::Version>, void *> > >="__value_"{__tree_end_node<std::__1::__tree_node_base<void *> *>="__left_"^{__tree_node_base<void *>}}}"__pair3_"{__compressed_pair<unsigned long, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, quasar::SystemConfig::Version>, std::__1::less<std::__1::basic_string<char> >, true> >="__value_"Q}}}"requiredParams"{map<std::__1::basic_string<char>, std::__1::set<std::__1::basic_string<char>, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::basic_string<char> > >, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, std::__1::set<std::__1::basic_string<char>, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::basic_string<char> > > > > >="__tree_"{__tree<std::__1::__value_type<std::__1::basic_string<char>, std::__1::set<std::__1::basic_string<char>, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::basic_string<char> > > >, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, std::__1::set<std::__1::basic_string<char>, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::basic_string<char> > > >, std::__1::less<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__value_type<std::__1::basic_string<char>, std::__1::set<std::__1::basic_string<char>, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::basic_string<char> > > > > >="__begin_node_"^{__tree_end_node<std::__1::__tree_node_base<void *> *>}"__pair1_"{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<std::__1::basic_string<char>, std::__1::set<std::__1::basic_string<char>, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::basic_string<char> > > >, void *> > >="__value_"{__tree_end_node<std::__1::__tree_node_base<void *> *>="__left_"^{__tree_node_base<void *>}}}"__pair3_"{__compressed_pair<unsigned long, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, std::__1::set<std::__1::basic_string<char>, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::basic_string<char> > > >, std::__1::less<std::__1::basic_string<char> >, true> >="__value_"Q}}}"state"i"configType"i}
@"<EARPSRAudioProcessorDelegate>"
@24@0:8^{EARCSpeechRecognitionResultStream=^v^?^?^?^?^?}16
{EARCSpeechRecognitionResultStream="ctx"^v"DisposeContext"^?"DidRecognizePartialResultTokens"^?"DidFinishRecognitionWithError"^?"DidRecognizeFinalResults"^?"DidProcessAudioDuration"^?}
@24@0:8r^{shared_ptr<quasar::RecogAudioBuffer>=^{RecogAudioBuffer}^{__shared_weak_count}}16
{shared_ptr<quasar::RecogAudioBuffer>="__ptr_"^{RecogAudioBuffer}"__cntrl_"^{__shared_weak_count}}
@36@0:8@16f24B28B32
@40@0:8@16Q24Q32
v24@0:8Q16
{shared_ptr<quasar::SyncPSRAudioProcessor>="__ptr_"^{SyncPSRAudioProcessor}"__cntrl_"^{__shared_weak_count}}
@"NSMutableData"
@"<EARAudioResultsGeneratorDelegate>"
v32@0:8@16@?24
v48@0:8@16@24@32@?40
{vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > >=^{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >}^{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >}{__compressed_pair<std::__1::basic_string<char> *, std::__1::allocator<std::__1::basic_string<char> > >=^{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >}}}24@0:8@16
v64@0:8{vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > >=^{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >}^{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >}{__compressed_pair<std::__1::basic_string<char> *, std::__1::allocator<std::__1::basic_string<char> > >=^{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >}}}16@40@48@?56
{shared_ptr<quasar::TranslatorFactory>="__ptr_"^{TranslatorFactory}"__cntrl_"^{__shared_weak_count}}
v28@0:8@16f24
{vector<std::__1::pair<id<_EARLanguageModelDataSource>, float>, std::__1::allocator<std::__1::pair<id<_EARLanguageModelDataSource>, float> > >="__begin_"^{pair<id<_EARLanguageModelDataSource>, float>}"__end_"^{pair<id<_EARLanguageModelDataSource>, float>}"__end_cap_"{__compressed_pair<std::__1::pair<id<_EARLanguageModelDataSource>, float> *, std::__1::allocator<std::__1::pair<id<_EARLanguageModelDataSource>, float> > >="__value_"^{pair<id<_EARLanguageModelDataSource>, float>}}}
{vector<quasar::Token, std::__1::allocator<quasar::Token> >=^{Token}^{Token}{__compressed_pair<quasar::Token *, std::__1::allocator<quasar::Token> >=^{Token}}}24@0:8@16
{vector<quasar::Token, std::__1::allocator<quasar::Token> >=^{Token}^{Token}{__compressed_pair<quasar::Token *, std::__1::allocator<quasar::Token> >=^{Token}}}24@0:8r^{vector<quasar::Token, std::__1::allocator<quasar::Token> >=^{Token}^{Token}{__compressed_pair<quasar::Token *, std::__1::allocator<quasar::Token> >=^{Token}}}16
{vector<quasar::Token, std::__1::allocator<quasar::Token> >=^{Token}^{Token}{__compressed_pair<quasar::Token *, std::__1::allocator<quasar::Token> >=^{Token}}}32@0:8r^{vector<quasar::Token, std::__1::allocator<quasar::Token> >=^{Token}^{Token}{__compressed_pair<quasar::Token *, std::__1::allocator<quasar::Token> >=^{Token}}}16@24
{vector<quasar::Token, std::__1::allocator<quasar::Token> >=^{Token}^{Token}{__compressed_pair<quasar::Token *, std::__1::allocator<quasar::Token> >=^{Token}}}40@0:8r^{vector<quasar::Token, std::__1::allocator<quasar::Token> >=^{Token}^{Token}{__compressed_pair<quasar::Token *, std::__1::allocator<quasar::Token> >=^{Token}}}16@24@32
{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}24@0:8r^{vector<quasar::Token, std::__1::allocator<quasar::Token> >=^{Token}^{Token}{__compressed_pair<quasar::Token *, std::__1::allocator<quasar::Token> >=^{Token}}}16
{unique_ptr<SpeechITN, std::__1::default_delete<SpeechITN> >="__ptr_"{__compressed_pair<SpeechITN *, std::__1::default_delete<SpeechITN> >="__value_"^{SpeechITN}}}
@48@0:8@16@24f32B36@40
@"<EARSyncPSRAudioProcessorDelegate>"
@32@0:8{shared_ptr<kaldi::quasar::LmHandle>=^{LmHandle}^{__shared_weak_count}}16
{shared_ptr<kaldi::quasar::LmHandle>=^{LmHandle}^{__shared_weak_count}}16@0:8
{shared_ptr<kaldi::quasar::LmHandle>="__ptr_"^{LmHandle}"__cntrl_"^{__shared_weak_count}}
@56@0:8d16d24d32d40d48
v32@0:8@16Q24
{shared_ptr<quasar::SilencePosteriorGenerator>="__ptr_"^{SilencePosteriorGenerator}"__cntrl_"^{__shared_weak_count}}
@"<EARCaesuraSilencePosteriorGeneratorDelegate>"
@"_EARLanguageDetectorRequestContext"
{vector<std::__1::optional<quasar::Locale>, std::__1::allocator<std::__1::optional<quasar::Locale> > >=^{optional<quasar::Locale>}^{optional<quasar::Locale>}{__compressed_pair<std::__1::optional<quasar::Locale> *, std::__1::allocator<std::__1::optional<quasar::Locale> > >=^{optional<quasar::Locale>}}}24@0:8@16
{shared_ptr<const quasar::LDContext>=^{LDContext}^{__shared_weak_count}}32@0:8r^{LDContext={map<quasar::Locale, double, std::__1::less<quasar::Locale>, std::__1::allocator<std::__1::pair<const quasar::Locale, double> > >={__tree<std::__1::__value_type<quasar::Locale, double>, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true>, std::__1::allocator<std::__1::__value_type<quasar::Locale, double> > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<quasar::Locale, double>, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true> >=Q}}}{optional<std::__1::set<quasar::Locale, std::__1::less<quasar::Locale>, std::__1::allocator<quasar::Locale> > >=(?=c{set<quasar::Locale, std::__1::less<quasar::Locale>, std::__1::allocator<quasar::Locale> >={__tree<quasar::Locale, std::__1::less<quasar::Locale>, std::__1::allocator<quasar::Locale> >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<quasar::Locale, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::less<quasar::Locale> >=Q}}})B}{optional<quasar::Locale>=(?=c{Locale={basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}})B}{optional<bool>=(?=cB)B}{optional<std::__1::vector<quasar::Locale, std::__1::allocator<quasar::Locale> > >=(?=c{vector<quasar::Locale, std::__1::allocator<quasar::Locale> >=^{Locale}^{Locale}{__compressed_pair<quasar::Locale *, std::__1::allocator<quasar::Locale> >=^{Locale}}})B}{optional<std::__1::map<quasar::Locale, double, std::__1::less<quasar::Locale>, std::__1::allocator<std::__1::pair<const quasar::Locale, double> > > >=(?=c{map<quasar::Locale, double, std::__1::less<quasar::Locale>, std::__1::allocator<std::__1::pair<const quasar::Locale, double> > >={__tree<std::__1::__value_type<quasar::Locale, double>, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true>, std::__1::allocator<std::__1::__value_type<quasar::Locale, double> > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<quasar::Locale, double>, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true> >=Q}}})B}{optional<std::__1::map<quasar::Locale, double, std::__1::less<quasar::Locale>, std::__1::allocator<std::__1::pair<const quasar::Locale, double> > > >=(?=c{map<quasar::Locale, double, std::__1::less<quasar::Locale>, std::__1::allocator<std::__1::pair<const quasar::Locale, double> > >={__tree<std::__1::__value_type<quasar::Locale, double>, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true>, std::__1::allocator<std::__1::__value_type<quasar::Locale, double> > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<quasar::Locale, double>, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true> >=Q}}})B}{optional<quasar::Locale>=(?=c{Locale={basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}})B}{optional<quasar::Locale>=(?=c{Locale={basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}})B}{optional<std::__1::map<quasar::Locale, double, std::__1::less<quasar::Locale>, std::__1::allocator<std::__1::pair<const quasar::Locale, double> > > >=(?=c{map<quasar::Locale, double, std::__1::less<quasar::Locale>, std::__1::allocator<std::__1::pair<const quasar::Locale, double> > >={__tree<std::__1::__value_type<quasar::Locale, double>, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true>, std::__1::allocator<std::__1::__value_type<quasar::Locale, double> > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<quasar::Locale, double>, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true> >=Q}}})B}}16r^{vector<std::__1::optional<quasar::Locale>, std::__1::allocator<std::__1::optional<quasar::Locale> > >=^{optional<quasar::Locale>}^{optional<quasar::Locale>}{__compressed_pair<std::__1::optional<quasar::Locale> *, std::__1::allocator<std::__1::optional<quasar::Locale> > >=^{optional<quasar::Locale>}}}24
@40@0:8Q16@24@32
I16@0:8
v20@0:8I16
{unique_ptr<quasar::LanguageDetector, std::__1::default_delete<quasar::LanguageDetector> >="__ptr_"{__compressed_pair<quasar::LanguageDetector *, std::__1::default_delete<quasar::LanguageDetector> >="__value_"^{LanguageDetector}}}
@24@0:8r^{CommandTagging={map<std::__1::basic_string<char>, std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> >, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> > > > >={__tree<std::__1::__value_type<std::__1::basic_string<char>, std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> > >, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> > >, std::__1::less<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__value_type<std::__1::basic_string<char>, std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> > > > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<std::__1::basic_string<char>, std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> > >, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> > >, std::__1::less<std::__1::basic_string<char> >, true> >=Q}}}{vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > >=^{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >}^{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >}{__compressed_pair<std::__1::basic_string<char> *, std::__1::allocator<std::__1::basic_string<char> > >=^{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >}}}{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}}16
{unique_ptr<quasar::CommandTagging, std::__1::default_delete<quasar::CommandTagging> >="__ptr_"{__compressed_pair<quasar::CommandTagging *, std::__1::default_delete<quasar::CommandTagging> >="__value_"^{CommandTagging}}}
@32@0:8@16q24
@24@0:8q16
{unique_ptr<quasar::CommandTagger, std::__1::default_delete<quasar::CommandTagger> >="__ptr_"{__compressed_pair<quasar::CommandTagger *, std::__1::default_delete<quasar::CommandTagger> >="__value_"^{CommandTagger}}}
v56@0:8@16@24@32@40@48
v40@0:8@16@24@32
v24@0:8@"NSXMLParser"16
v48@0:8@"NSXMLParser"16@"NSString"24@"NSString"32@"NSString"40
v56@0:8@"NSXMLParser"16@"NSString"24@"NSString"32@"NSString"40@"NSString"48
v40@0:8@"NSXMLParser"16@"NSString"24@"NSString"32
v56@0:8@"NSXMLParser"16@"NSString"24@"NSString"32@"NSString"40@"NSDictionary"48
v32@0:8@"NSXMLParser"16@"NSString"24
v32@0:8@"NSXMLParser"16@"NSData"24
@"NSData"40@0:8@"NSXMLParser"16@"NSString"24@"NSString"32
v32@0:8@"NSXMLParser"16@"NSError"24
@"NSXMLParser"
@"NSMutableDictionary"
@"NSMutableString"
@"NSMutableArray"
{unique_ptr<quasar::TextTokenizer, std::__1::default_delete<quasar::TextTokenizer> >={__compressed_pair<quasar::TextTokenizer *, std::__1::default_delete<quasar::TextTokenizer> >=^{TextTokenizer}}}24@0:8@16
{shared_ptr<quasar::TextTokenizer>="__ptr_"^{TextTokenizer}"__cntrl_"^{__shared_weak_count}}
@(#)$Id: ngram-count.cc,v 1.78 2013/09/16 06:50:23 stolcke Exp $
mcpl
