_N9inference18EspressoANEManagerE
N9inference26BNNSBroadcastElementkernelIfLm5EEE
N9inference12PermuteLayerIffLm5EEE
N9inference13AbstractLayerIffLm5EEE
N9inference13MontrealLayerILm5EEE
N10exceptions25NetworkIncompatibleEngineE
N10exceptions34NetworkFlatModelIncompatibleFormatE
N10exceptions25NetworkIncompatibleFormatE
N10exceptions23NetworkInValidNameErrorE
?(kn
N9inference18AttentionLayerSelfIffLm5EEE
N9inference14AttentionLayerIffLm5EEE
?N9inference22EmbeddingAdaptiveLayerIffLm5EEE
N9inference22EmbeddingAdaptiveLayerIafLm5EEE
N9inference13AbstractLayerIafLm5EEE
N9inference15EspressoManagerE
*?Ll
7Encoder
11EncoderMeta
11PerThreadSR
13EncoderOneInN
4LSTMIsE
13NeuralNetwork
15EstimatorScalarIfE
9EstimatorIfE
13EstimatorADAMIfE
15EstimatorAdaMaxIfE
4LSTMIfE
7Reverse
8Parallel
9FullLayerIsE
9FullLayerIfE
7Stacked
14RecurrentLayerIsE
6Direct
7SoftMaxIsE
3GRUIsE
3GRUIfE
18BatchNormalizationIsE
16ParallelSelectorIsE
4LSTMIaE
9FullLayerIaE
14RecurrentLayerIaE
7SoftMaxIaE
3GRUIaE
18BatchNormalizationIaE
16ParallelSelectorIaE
14RecurrentLayerIfE
7SoftMaxIfE
18BatchNormalizationIfE
16ParallelSelectorIfE
13OutputCluster
11EncoderBits
21EncoderOneInNTwoParts
11EncoderGray
18EncoderBitsFromMap
11EncoderCopy
N9inference9LSTMLayerIffLm5EEE
N9inference9LSTMLayerIafLm5EEE
?N9inference10BaseEngineE
N9inference16ActivationKernelIfEE
N9inference13ElementKernelIfEE
N9inference12MatrixKernelIaEE
N9inference13ElementKernelIaEE
N9inference15TransposeKernelIfEE
>N9inference17EspressoE5ManagerE
N9inference10SliceLayerIffLm5EEE
N9inference10SliceLayerIafLm5EEE
N9inference14NLModelBuilderE
N9inference22AbstractNetworkBuilderE
N9inference6layers12PoolingLayerIffLm5EEE
N9inference14KernelCompilerE
N9inference18QuantizationKernelIfaEE
N9inference18QuantizationKernelIffEE
N9inference11MergeKernelIfEE
N9inference10MeanKernelIfLm5EEE
N9inference12ConcatKernelIfLm5EEE
N9inference13PermuteKernelIfLm5EEE
N9inference13FunctionLayerIffLm5EEE
+N9inference18LayerNormalizationIffLm5EEE
CN9inference27BNNSBroadcastFunctionkernelIfLm5EEE
N9inference6layers16ConvolutionLayerIffLm5EEE
N9inference26AttentionLayerWithDotScoreIffLm5EEE
?N9inference20BNNSActivationKernelIfEE
@N9inference18QuantizationKernelIafEE
MbP?
MbP?
MbP?N10exceptions21UnknownExecptionErrorE
N9inference16FlatModelBuilderE
NSt3__120__shared_ptr_emplaceIN8Espresso4blobIfLi2EEENS_9allocatorIS3_EEEE
N8Espresso4blobIfLi2EEE
NSt3__120__shared_ptr_emplaceIN8Espresso4blobIfLi1EEENS_9allocatorIS3_EEEE
N8Espresso4blobIfLi1EEE
NSt3__120__shared_ptr_emplaceIN8Espresso4blobIfLi4EEENS_9allocatorIS3_EEEE
N8Espresso4blobIfLi4EEE
@N2ht5error15InvalidArgumentE
N2ht5error20ExceptionWithMessageE
N2ht5error12RuntimeErrorE
N2ht3opt15RandomOptimizerE
N2ht3opt17BlackBoxOptimizerE
N2ht3opt24GaussianProcessOptimizerIZ13runExperimentINS_2SEENS_2PIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht2gp24ProbabilityOfImprovementINS0_15GaussianProcessIZ13runExperimentINS_2SEENS_2PIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsNS0_4mean4DataIS9_EENS0_6kernel18SquaredExponentialIS9_EEEEEE
N2ht2gp19AcquisitionFunctionINS0_15GaussianProcessIZ13runExperimentINS_2SEENS_2PIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsNS0_4mean4DataIS9_EENS0_6kernel18SquaredExponentialIS9_EEEEEE
N2ht3opt16GeneticOptimizerIZ13runExperimentINS_2SEENS_2PIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht3opt20AcquisitionOptimizerINS_2gp24ProbabilityOfImprovementINS2_15GaussianProcessIZ13runExperimentINS_2SEENS_2PIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsNS2_4mean4DataISB_EENS2_6kernel18SquaredExponentialISB_EEEEEEEE
N2ht3opt15DirectOptimizerIZ13runExperimentINS_2SEENS_2PIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht3opt12NLOptWrapperILN5nlopt9algorithmE0EEE
N5nlopt16roundoff_limitedE
N5nlopt11forced_stopE
N2ht4stop13MaxIterationsE
N2ht4stop17StoppingConditionE
N2ht4stop7PlateauIZ13runExperimentINS_2SEENS_2PIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
NSt3__117bad_function_callE
N2ht3opt24GaussianProcessOptimizerIZ13runExperimentINS_2SEENS_2EIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht2gp19ExpectedImprovementINS0_15GaussianProcessIZ13runExperimentINS_2SEENS_2EIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsNS0_4mean4DataIS9_EENS0_6kernel18SquaredExponentialIS9_EEEEEE
N2ht2gp19AcquisitionFunctionINS0_15GaussianProcessIZ13runExperimentINS_2SEENS_2EIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsNS0_4mean4DataIS9_EENS0_6kernel18SquaredExponentialIS9_EEEEEE
N2ht3opt16GeneticOptimizerIZ13runExperimentINS_2SEENS_2EIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht3opt20AcquisitionOptimizerINS_2gp19ExpectedImprovementINS2_15GaussianProcessIZ13runExperimentINS_2SEENS_2EIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsNS2_4mean4DataISB_EENS2_6kernel18SquaredExponentialISB_EEEEEEEE
N2ht3opt15DirectOptimizerIZ13runExperimentINS_2SEENS_2EIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht4stop7PlateauIZ13runExperimentINS_2SEENS_2EIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht3opt24GaussianProcessOptimizerIZ13runExperimentINS_2SEENS_3UCBEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht2gp20UpperConfidenceBoundINS0_15GaussianProcessIZ13runExperimentINS_2SEENS_3UCBEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsNS0_4mean4DataIS9_EENS0_6kernel18SquaredExponentialIS9_EEEEEE
N2ht2gp19AcquisitionFunctionINS0_15GaussianProcessIZ13runExperimentINS_2SEENS_3UCBEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsNS0_4mean4DataIS9_EENS0_6kernel18SquaredExponentialIS9_EEEEEE
N2ht3opt16GeneticOptimizerIZ13runExperimentINS_2SEENS_3UCBEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht3opt20AcquisitionOptimizerINS_2gp20UpperConfidenceBoundINS2_15GaussianProcessIZ13runExperimentINS_2SEENS_3UCBEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsNS2_4mean4DataISB_EENS2_6kernel18SquaredExponentialISB_EEEEEEEE
N2ht3opt15DirectOptimizerIZ13runExperimentINS_2SEENS_3UCBEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht4stop7PlateauIZ13runExperimentINS_2SEENS_3UCBEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht3opt24GaussianProcessOptimizerIZ13runExperimentINS_5ARDSEENS_2PIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht2gp24ProbabilityOfImprovementINS0_15GaussianProcessIZ13runExperimentINS_5ARDSEENS_2PIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsNS0_4mean4DataIS9_EENS0_6kernel21ARDSquaredExponentialIS9_EEEEEE
N2ht2gp19AcquisitionFunctionINS0_15GaussianProcessIZ13runExperimentINS_5ARDSEENS_2PIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsNS0_4mean4DataIS9_EENS0_6kernel21ARDSquaredExponentialIS9_EEEEEE
N2ht3opt16GeneticOptimizerIZ13runExperimentINS_5ARDSEENS_2PIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht3opt20AcquisitionOptimizerINS_2gp24ProbabilityOfImprovementINS2_15GaussianProcessIZ13runExperimentINS_5ARDSEENS_2PIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsNS2_4mean4DataISB_EENS2_6kernel21ARDSquaredExponentialISB_EEEEEEEE
N2ht3opt15DirectOptimizerIZ13runExperimentINS_5ARDSEENS_2PIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht4stop7PlateauIZ13runExperimentINS_5ARDSEENS_2PIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht3opt24GaussianProcessOptimizerIZ13runExperimentINS_5ARDSEENS_2EIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht2gp19ExpectedImprovementINS0_15GaussianProcessIZ13runExperimentINS_5ARDSEENS_2EIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsNS0_4mean4DataIS9_EENS0_6kernel21ARDSquaredExponentialIS9_EEEEEE
N2ht2gp19AcquisitionFunctionINS0_15GaussianProcessIZ13runExperimentINS_5ARDSEENS_2EIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsNS0_4mean4DataIS9_EENS0_6kernel21ARDSquaredExponentialIS9_EEEEEE
N2ht3opt16GeneticOptimizerIZ13runExperimentINS_5ARDSEENS_2EIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht3opt20AcquisitionOptimizerINS_2gp19ExpectedImprovementINS2_15GaussianProcessIZ13runExperimentINS_5ARDSEENS_2EIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsNS2_4mean4DataISB_EENS2_6kernel21ARDSquaredExponentialISB_EEEEEEEE
N2ht3opt15DirectOptimizerIZ13runExperimentINS_5ARDSEENS_2EIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht4stop7PlateauIZ13runExperimentINS_5ARDSEENS_2EIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht3opt24GaussianProcessOptimizerIZ13runExperimentINS_5ARDSEENS_3UCBEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht2gp20UpperConfidenceBoundINS0_15GaussianProcessIZ13runExperimentINS_5ARDSEENS_3UCBEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsNS0_4mean4DataIS9_EENS0_6kernel21ARDSquaredExponentialIS9_EEEEEE
N2ht2gp19AcquisitionFunctionINS0_15GaussianProcessIZ13runExperimentINS_5ARDSEENS_3UCBEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsNS0_4mean4DataIS9_EENS0_6kernel21ARDSquaredExponentialIS9_EEEEEE
N2ht3opt16GeneticOptimizerIZ13runExperimentINS_5ARDSEENS_3UCBEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht3opt20AcquisitionOptimizerINS_2gp20UpperConfidenceBoundINS2_15GaussianProcessIZ13runExperimentINS_5ARDSEENS_3UCBEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsNS2_4mean4DataISB_EENS2_6kernel21ARDSquaredExponentialISB_EEEEEEEE
N2ht3opt15DirectOptimizerIZ13runExperimentINS_5ARDSEENS_3UCBEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht4stop7PlateauIZ13runExperimentINS_5ARDSEENS_3UCBEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht3opt24GaussianProcessOptimizerIZ13runExperimentINS_6MaternENS_2PIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht2gp24ProbabilityOfImprovementINS0_15GaussianProcessIZ13runExperimentINS_6MaternENS_2PIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsNS0_4mean4DataIS9_EENS0_6kernel16MaternFiveHalvesIS9_EEEEEE
N2ht2gp19AcquisitionFunctionINS0_15GaussianProcessIZ13runExperimentINS_6MaternENS_2PIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsNS0_4mean4DataIS9_EENS0_6kernel16MaternFiveHalvesIS9_EEEEEE
N2ht3opt16GeneticOptimizerIZ13runExperimentINS_6MaternENS_2PIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht3opt20AcquisitionOptimizerINS_2gp24ProbabilityOfImprovementINS2_15GaussianProcessIZ13runExperimentINS_6MaternENS_2PIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsNS2_4mean4DataISB_EENS2_6kernel16MaternFiveHalvesISB_EEEEEEEE
N2ht3opt15DirectOptimizerIZ13runExperimentINS_6MaternENS_2PIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht4stop7PlateauIZ13runExperimentINS_6MaternENS_2PIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht3opt24GaussianProcessOptimizerIZ13runExperimentINS_6MaternENS_2EIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht2gp19ExpectedImprovementINS0_15GaussianProcessIZ13runExperimentINS_6MaternENS_2EIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsNS0_4mean4DataIS9_EENS0_6kernel16MaternFiveHalvesIS9_EEEEEE
N2ht2gp19AcquisitionFunctionINS0_15GaussianProcessIZ13runExperimentINS_6MaternENS_2EIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsNS0_4mean4DataIS9_EENS0_6kernel16MaternFiveHalvesIS9_EEEEEE
N2ht3opt16GeneticOptimizerIZ13runExperimentINS_6MaternENS_2EIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht3opt20AcquisitionOptimizerINS_2gp19ExpectedImprovementINS2_15GaussianProcessIZ13runExperimentINS_6MaternENS_2EIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsNS2_4mean4DataISB_EENS2_6kernel16MaternFiveHalvesISB_EEEEEEEE
N2ht3opt15DirectOptimizerIZ13runExperimentINS_6MaternENS_2EIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht4stop7PlateauIZ13runExperimentINS_6MaternENS_2EIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht3opt24GaussianProcessOptimizerIZ13runExperimentINS_6MaternENS_3UCBEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht2gp20UpperConfidenceBoundINS0_15GaussianProcessIZ13runExperimentINS_6MaternENS_3UCBEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsNS0_4mean4DataIS9_EENS0_6kernel16MaternFiveHalvesIS9_EEEEEE
N2ht2gp19AcquisitionFunctionINS0_15GaussianProcessIZ13runExperimentINS_6MaternENS_3UCBEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsNS0_4mean4DataIS9_EENS0_6kernel16MaternFiveHalvesIS9_EEEEEE
N2ht3opt16GeneticOptimizerIZ13runExperimentINS_6MaternENS_3UCBEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht3opt20AcquisitionOptimizerINS_2gp20UpperConfidenceBoundINS2_15GaussianProcessIZ13runExperimentINS_6MaternENS_3UCBEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsNS2_4mean4DataISB_EENS2_6kernel16MaternFiveHalvesISB_EEEEEEEE
N2ht3opt15DirectOptimizerIZ13runExperimentINS_6MaternENS_3UCBEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht4stop7PlateauIZ13runExperimentINS_6MaternENS_3UCBEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
NSt3__110__function6__funcI24IterationCallbackWrapperNS_9allocatorIS2_EEFbRKN2ht14ProgressReportEEEE
NSt3__110__function6__baseIFbRKN2ht14ProgressReportEEEE
24IterationCallbackWrapper
NSt3__110__function6__funcIN2ht8defaults17IterationCallbackENS_9allocatorIS4_EEFbRKNS2_14ProgressReportEEEE
N2ht8defaults17IterationCallbackE
NSt3__110__function6__funcI22EvaluationBlockWrapperNS_9allocatorIS2_EEFdRKN2ht5QueryEEEE
NSt3__110__function6__baseIFdRKN2ht5QueryEEEE
22EvaluationBlockWrapper
N9inference27FullConnectionAdaptiveLayerIffLm5EEE
N9inference27FullConnectionAdaptiveLayerIafLm5EEE
N9inference21BNNSConvolutionKernelIfLm2EEE
N9inference16BNNSMatrixKernelIfEE
N9inference12MatrixKernelIfEE
N9inference14AbstractKernelE
N9inference16BNNSMatrixKernelIaEE
:N9inference10BNNSEngineE
N9inference7kernels17BNNSPoolingKernelIfEE
N9inference20EmbeddingLegacyLayerIffLm5EEE
N9inference20EmbeddingLegacyLayerIafLm5EEE
9PerThread
10ThreadPool
N9inference19FullConnectionLayerIffLm5EEE
N9inference19FullConnectionLayerIafLm5EEE
7PTMutex
N9inference12ReshapeLayerIffLm5EEE
N9inference12ReshapeLayerIafLm5EEE
N9inference16ExecutionManagerE
N9inference23BatchNormalizationLayerIffLm5EEE
N9inference14EmbeddingLayerIffLm5EEE
N9inference14EmbeddingLayerIafLm5EEE
NSt3__120__shared_ptr_emplaceIN9inference8DataBlobIfEENS_9allocatorIS3_EEEE
N9inference22AttentionLayerBahdenauIffLm5EEE
?UUUUUU
UUUUUU
?N9inference17BNNSElementKernelIfEE
N9inference13BNNSBMMKernelIfLm5EEE
N9inference18LowLatencyCompilerE
N9inference22BNNSQuantizationKernelIfaEE
N9inference12LookupKernelIaEE
N9inference22BNNSQuantizationKernelIafEE
N9inference12LookupKernelIfEE
NSt3__110__function6__funcIZN9inference18LowLatencyCompiler23compileConvolutionLayerEPNS2_6layers16ConvolutionLayerIffLm5EEEE3$_0NS_9allocatorIS8_EEFNS2_5utils6TensorIfLm4EEEiEEE
NSt3__110__function6__baseIFN9inference5utils6TensorIfLm4EEEiEEE
ZN9inference18LowLatencyCompiler23compileConvolutionLayerEPNS_6layers16ConvolutionLayerIffLm5EEEE3$_0
NSt3__110__function6__funcIZN9inference18LowLatencyCompiler23compileConvolutionLayerEPNS2_6layers16ConvolutionLayerIffLm5EEEE3$_1NS_9allocatorIS8_EEFNS2_5utils6TensorIfLm4EEEiEEE
ZN9inference18LowLatencyCompiler23compileConvolutionLayerEPNS_6layers16ConvolutionLayerIffLm5EEEE3$_1
NSt3__110__function6__funcIZN9inference18LowLatencyCompiler19compilePoolingLayerEPNS2_6layers12PoolingLayerIffLm5EEEE3$_2NS_9allocatorIS8_EEFNS2_5utils6TensorIfLm4EEEiEEE
ZN9inference18LowLatencyCompiler19compilePoolingLayerEPNS_6layers12PoolingLayerIffLm5EEEE3$_2
NSt3__110__function6__funcIZN9inference18LowLatencyCompiler19compilePoolingLayerEPNS2_6layers12PoolingLayerIffLm5EEEE3$_3NS_9allocatorIS8_EEFNS2_5utils6TensorIfLm4EEEiEEE
ZN9inference18LowLatencyCompiler19compilePoolingLayerEPNS_6layers12PoolingLayerIffLm5EEEE3$_3
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
unable to set priority on espresso plan with ANE_RUNTIME
unable to load model
Failed to build espresso plan
Failed to clean espresso plan
new config does not bind to new input shape
batchsize=
,seqlen=
Cannot declare runtime output on ANE
no supported
v8@?0
MontrealNeuralNetworkState
index
name
node_type
activation_type
weights
inputs
outputs
properties
input_coding
model_calculation
weight_attributes
weight_storage
weight_storage_range
vocab_size
embedding_dimension
custom
filter_size
stride_size
dropout_ratio
lstm_projection_cell_size
lstm_projection_clip_lower_bound
lstm_projection_clip_upper_bound
full_connection
batchnorm
activation
concatenation
embeddingNew
embedding
lstm
lstm_bidirectional
gru_bidirectional
convolution
pooling
pack_padded_sequence
squeeze
unsqueeze
view
contiguous
highway
flatten
reverse
permute
attentionWithDotScore
attentionWithConcatScore
attentionSelf
layernormalize
reshape
slice
adaptiveEmbedding
adaptiveFC
none
sigmoid
hard_sigmoid
tanh
tanh_scaled
softmax
relu
dropout
log_softmax
gelu
leakyReLU
geluFast
dense
onehot
float32
float16
int8
bias_included
transposed
lstm_order_igfo
lstm_combined_weight
batchnorm_integrated
attention_weight_integrated
attention_identity_key_proj
attention_identity_query_proj
lstm_combined_bias
zero_bias
nodes
weight
bias
hidden_weight
hidden_bias
reverse_weight
reverse_bias
reverse_hidden_weight
reverse_hidden_bias
peephole_weight
reverse_peephole_weight
projection_weight
running_mean
running_var
optimization
optimizer
adam
learning_rate
momentum
fileLocation
embeddingFileLocation
layerParameters
layerParametersSize
nHiddenNodes
inputEncoding
modelConfig
numThreads
errorCount
errorRate
logProbability
modelData
learningRate
beta1
beta2
estimatorType
None
sequence MRLModelRecognize
sequence MRLModelRecognizeVectorsTopN
MRLModelWrapper::MRLModelRecognizeVectorsTopN() float* allocate
sequence MRLModelRecognizeVectorsIncrementalTopN
full sequence MRLModelRecognizeTopN
MRLModelWrapper::MRLModelRecognizeTopN() token allocate
incremental MRLModelRecognizeIncrementalTopN
recognizeSequenceInternalFullBiDir, tokenID - activate all buffer to %d length
recognizeSequenceInternalFullBiDir, float* - activate all buffer to %d length
%@, 
    
array::at
com.apple.MRLNeuralNetwork
MRLNeuralNetworkOptionModelURLKey
MRLNeuralNetworkOptionModelDataKey
MRLNeuralNetworkOptionInputNamesKey
MRLNeuralNetworkOptionOutputNamesKey
MRLNeuralNetworkOptionEngineKey
MRLNeuralNetworkOptionQuantizationParamsKey
MRLNeuralNetworkOptionQuantizationSchemeNameKey
MRLNeuralNetworkOptionQuantizationSchemeLinearInt8RangeMinKey
MRLNeuralNetworkOptionQuantizationSchemeLinearInt8RangeMaxKey
MRLNeuralNetworkOptionModelNameKey
MRLNeuralNetworkOptionModelVersionKey
kMRLNeuralNetworkOptionModelTypeKey
MRLNeuralNetworkOptionQuantizationSchemeNameLinearInt8
MRLNeuralNetworkEvaluateInputDataKey
MRLNeuralNetworkEvaluateOutputLabelKey
Channel
Width
Height
InputDimension
SequenceLength
isChannelLast
isBatchFirst
DataType
ShapeDimension
MRLNeuralNetworkOptionANENetworkURLKey
MRLNeuralNetworkOptionANEStartNodeName
MRLNeuralNetworkOptionANEEndNodeName
Espresso
NLModel
FlatModel
EspressoE5RT
Invalid Engine. Support Engines = {CPU}
unknown exception
.espresso.net
Invalid Engine. Support Engines = {CPU, ANE}
Unable to load Espresso Model
Invalid Engine. Support Engines for E5RT = {CPU}
Unable to load E5RT Model
Unable to create network from data. 
.espresso.
Unknown expection
Please provide a valid input name. 
 input cannot be set
Unknown error. 
kMRLNeuralNetworkSingleInput
kMRLNeuralNetworkSingleOutput
Could not construct
Could not convert
MontrealNeuralNetwork
MontrealNeuralNetworkTensor
DictionaryRef_iterator iterator out of range.
Could not find item
_h_in
_c_in
_r_h_in
_r_c_in
_k_s_in
_v_s_in
_out
LMTRAINER
inputEncoding has wrong value!
not allowed 
Threaded recognize not supported
MRLModelWrapper, layer #0 
***Error executing ThreadPool.run()
***Error execuring ThreadPool.run()
do-not-us-this-path,from-raw-buffer
from MLNLP_CONFIG_MLKIT_LAYER_BY_LAYER
LSTM constructor
LSTM alloc, from constructor
prevM=
0x%lx
LSTM before reset 
LSTM AFTER reset 
LSTM alloc, from allocAll
v16@?0Q8
FullLayer constructor
FullLayer, from allocAll
RecurrentLayer from Constructor
RecurrentLayer from allocAll
SoftMax, from allocAll
GRU constructor
GRU alloc, from constructor
GRU before reset 
GRU AFTER reset 
GRU alloc, from allocAll
outvec0/gzx
outvec1/grx
outvec2/gox
inRange:yes
inRange:no
 [1 x 
BatchNormalization, from allocAll
From constructor
From allocAllBuffers
WARNING: Invalid (too large) Montreal id (%d) - IGNORE
corpus entry 
do-not-use-this-path,from-raw-buffer
SentenceRecognizer
NLModelContainerCreate
NLModelContainerCreateWithContentsOfURL
NLModelContainerCreateWithContainerData
NLModelContainerGetType
NLModelContainerGetSubtype
NLModelContainerGetRevision
NLModelContainerCopyInfoDictionary
NLModelContainerGetModelDataCount
NLModelContainerCopyModelDataAtIndex
NLModelContainerWriteToURL
/System/Library/PrivateFrameworks/CoreNLP.framework/CoreNLP
nodeStr
%@ == %%@
@16@?0@"NSArray"8
 %@ Name = %@ 
 %@ Node Type = %@ 
 %@ Activation Type = %@ 
 %@ Inputs With Dimensions = %@ 
 %@ Outputs With Dimension = %@ 
 %@ Inputs = %@ 
 %@ Outputs = %@ 
 %@ Weights = %@ 
 %@ Properties = %@ 
Failed to create NLModelContainer from file: %@
Failed to create NLModelContainer from model data
No saved model container
Unexpected Port: 
map::at:  key not found
filter
stride
unable to determine output shape of layer 
input shape not found at port 
output shape not found at port 
 %@ Name = %@
 %@ Dimension = %@
 %@ As Input
 %@ %@
 %@ As Output
tensor_input_%@_%@
tensor_output_%@_%@
com.apple.Montreal
Default
 %@ {
 %@ }
%@ %@ has 0 elements
%@ %@ is nil
%@ %@: %@ is invalid
 %@ [
 %@ %@
 %@ ]
 %@ %@ : %@
Tensor %@ is already present
Weight %@ is already present
Node %@ is already present
Model format incompatibale. Unable to build Flat model
Flat model file corrupted
Flat model version incorrect
Only kMRLNeuralNetworkWeight                                                    AttributeBatchNormalizationIntegrated weight attribute supported
Model name cannot be greater than 31 characters.
_after_input_transpose
_after_output_transpose
_input_t
_output_t
_before_softmax
_before_relu
_softmax
_relu
Unexpected type for 
HTParameterNameKey
HTParameterTypeKey
HTParameterDimensionKey
HTParameterMinimumValueKey
HTParameterMaximumValueKey
HTAlgorithmKey
HTKernelKey
HTAcquisitionKey
HTCallbackIntervalKey
HTStopConditionMaxIterationsKey
HTStopConditionPatienceKey
HTStopConditionMinDeltaKey
HTOptimizationDirectionKey
HTRandomSeedKey
HTInitialParameterValuesKey
HTParameterTypeIntegral
HTParameterTypeContinuous
HTAlgorithmRandom
HTAlgorithmGaussianProcess
HTKernelSquaredExponential
HTKernelARDSquaredExponential
HTKernelMaternFiveHalves
HTAcquisitionProbabilityOfImprovement
HTAcquisitionExpectedImprovement
HTAcquisitionUpperConfidenceBound
HTOptimizationDirectionMaximize
HTOptimizationDirectionMinimize
Name
MinimumValue
MaximumValue
Dimension
Type
Missing required key: 
Missing parameter value for parameter with name=
MaxIterations
Patience
MinDelta
Integral
Continuous
Unrecognized paramType: 
CallbackInterval
RandomSeed
InitialParameterValues
SquaredExponential
ARDSquaredExponential
MaternFiveHalves
Invalid kernel: 
Kernel
Acquisition
Algorithm
Direction
Random
GaussianProcess
ProbabilityOfImprovement
ExpectedImprovement
UpperConfidenceBound
Maximize
Minimize
Unexpected HyperTune key: 
[InvalidArgument] 
Unexpected optimizer name: 
Unexpected optimization direction: 
Invalid acquisition: 
Invalid optimizer in user config.
acquisition_optimizer
genetic_optimizer
nlopt failure
nlopt invalid argument
uninitialized nlopt::opt
nlopt roundoff-limited
nlopt forced stop
dimension mismatch
direct_optimizer
Early stopping already requested.
com.apple.HyperTune
 %@ Algorithm = %tu (Adam: %tu, SGD: %tu)
 %@ Learning Rate = %lf
 %@ Use Momentum = %lf
 %@ Gradient Clip Min = %@, Max = %@
v24@?0Q8@"NSString"16
Node_%@
Failed to merge %@ to the network as there is one which already exists with the same name
model_generate.XXXXX
model_container.nlmodel
tpThreadInit error
hw.activecpu
%@/network.json
Failed to extract network JSON
%@/description.json
Failed to extract description JSON
Failed to extract network JSON from model container
Node %@ contains empty inputs or outputs
Node %@ output is going nowhere?
Node %@ contains empty outputs
No unpack node?
 %@ Nodes = %@ 
Invalid rangeOrIndices for partial output. 
 has not been connected to any node in the network.
recompiling 
for 
Invalid node name: 
Invalid nodeName for partial output. 
 %@ Index = %@ 
 %@ Dimension = %@ 
%@/%@.json
%@ Source file %@ doesn't exist
%@ Cannot generate JSON weights file
%@ No weights file or data to add to data container
IPHONE_SIMULATOR_ROOT
Expected oututDims to have size 3 or 2.
dict does not have key: 
LSTM
Embedding
EmbeddingLegacy
Pooling
Convolution
Activation
BatchNormalization
Concatenation
FullConnection
LSTMBidirectional
GRUBidirectional
Unexpected NodeType: 
MLPModelTrainerDataLayoutKey
MLPModelTrainerDataLayoutHeightxWidthxFeatureChannels
MLPModelTrainerDataLayoutFeatureChannelsxHeightxWidth
MLPModelTrainerOptimizerAlgorithmKey
MLPModelTrainerOptimizerAdam
MLPModelTrainerOptimizerSGD
MLPModelTrainerNoImprovementWindowKey
MLPModelTrainerNumberOfEpochsKey
MLPModelTrainerLearningRateKey
MLPModelTrainerLearningRateDecayStepsKey
MLPModelTrainerLearningRateDecayRateKey
MLPModelTrainerLearningRateDecayStairCaseKey
MLPModelTrainerOptimizerMomentumKey
MLPModelTrainerGradientClipMinimum
MLPModelTrainerGradientClipMaximum
MLPModelTrainerBatchSizeKey
MLPModelTrainerEvaluationBatchSizeKey
MLPModelTrainerLossBatchSizeKey
MLPModelTrainerInputLengthKey
MLPModelTrainerInputHeightKey
MLPModelTrainerInputChannelsKey
MLPModelTrainerNumberOfLabelsKey
MLPModelTrainerComputeLossOnEvaluationKey
MLPModelTrainerVocabSizeKey
MLPModelTrainerEmbeddingDimensionKey
MLPModelGenerateFormatKey
MLPModelGenerateFormatJSON
MLPModelGenerateFormatCompact
MLPModelTrainerConfusionMatrixKey
MLPModelTrainerOverallAccuracyKey
MLPModelTrainerPerplexityKey
MLPModelTrainerBpcKey
MLPModelTrainerLossValueKey
MLPModelTrainerPerClassPrecisionKey
MLPModelTrainerPerClassRecallKey
MLPModelSampleDataFeatureValuesKey
MLPModelSampleDataLabelsKey
MLPModelSampleDataBatchOfSequencesKey
MLPModelSampleDataSequenceValuesKey
MLPModelSampleDataSequenceLabelsKey
tpThreadDispatch: thread %u not idle
***tpThread: Error waiting on condition; error %d; aborting.
***tpThreadInit: Error starting up server thread
***tpThreadInit: Error initializing pthreadCond
***tpThreadInit: Error initializing mutex
***tpThreadInit: malloc failure
***tpThread: internal error, actThreads = 0
***tpThread: Error acquiring lock; aborting.
tpThreadDispatch: pthread_cond_signal error
tpThreadDispatch: mutex error
tpThreadDispatch with threads still active
tpThreadDispatch: illegal numThreads
NULL args to nlopt_optimize
failure allocating elim_opt
NULL args to nlopt_optimize_
bounds %d fail %g <= %g <= %g
finite domain required for global algorithm
Unable to append the state
Incremental state should have sequence length of 1
Incremental state should have same shape as the past appended states
%s not found in state
Params specified that weights are being shared with Adaptive Embedding Layer. However, weights don't match.
Unsupported Engine type %d.
Cannot create context, Caught exception: %s
Unrecognized input name.
Unrecognized output name.
dict does not have key: %s
MontrealNNModelQuantization
MontrealNNDescriptionProtocol
NSObject
Utils
MontrealLogIndent
MontrealModelJSONParser
MontrealNNModelNode
MontrealNNModelTensor
NSCopying
MontrealNNDescription
MontrealNNModelOptimizerParam
MontrealNNGenerateNode
MontrealNNGenerateModel
MontrealNNModelNetwork
MontrealNNModelWeight
MLPInferenceResult
exMRL_dataForKey:
exMRL_arrayForKey:
length
errorWithDomain:code:userInfo:
count
bytes
mutableCopy
numberWithUnsignedInteger:
setObject:forKeyedSubscript:
objectAtIndexedSubscript:
unsignedIntegerValue
init
exMRL_stringForKey:
exMRL_numberForKey:
isEqual:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
description
debugDescription
TQ,R
T#,R
T@"NSString",R,C
description:indent:
jsonDescription
checkForValidity
generateJSONAtPath:
initWithDictionary:
weightStorage
weightStorageRange
.cxx_destruct
_weightStorage
_weightStorageRange
T@"NSString",R,V_weightStorage
T@"NSNumber",R,V_weightStorageRange
objectForKeyedSubscript:
exMRL_boolForKey:keyPresent:
boolValue
exMRL_boolForKey:
exMRL_dictionaryForKey:
exMRL_setForKey:
string
countByEnumeratingWithState:objects:count:
stringWithFormat:
appendString:
copy
exMRL_numberArrayDescription
initWithLevel:step:factor:
initWithCapacity:
indentWithLevel:step:factor:
indentWithLevel:
indentByFactor:
step
factor
level
_step
_factor
_level
T@"NSString",R,V_step
TQ,R,V_factor
T@"NSString",R,V_level
dictionary
array
numberWithUnsignedInt:
addObject:
numberWithDouble:
numberWithFloat:
floatValue
path
initWithJSONDir:
dataWithContentsOfFile:
JSONObjectWithData:options:error:
initWithURL:
createJSONFromFile:
jsonDir
network
infoDictionary
_jsonDir
_network
_infoDictionary
T@"NSString",R,V_jsonDir
T@"MontrealNNModelNetwork",R,V_network
T@"NSDictionary",R,V_infoDictionary
generateModelContainer
initWithFormat:arguments:
UTF8String
exceptionWithName:reason:userInfo:
name
arrayWithObjects:count:
nodeStr
inputs
outputs
checkForValidity:
addObjectsFromArray:
arrayWithCapacity:
predicateWithFormat:
filteredSetUsingPredicate:
anyObject
asInput
asOutput
containsObject:
indexOfObject:
objectAtIndex:
inputsWithDimensions
auditAndUpdateTensors:dimensionTensors:
outputsWithDimensions
removeObject:
parametersSet
setParametersSet:
appendFormat:
activations
weights
properties
createDataContainer
addEntriesFromDictionary:
initWithName:nodeStr:activations:properties:weights:
initWithDictionary:tensors:quantization:jsonDir:
setInputs:
setOutputs:
keepTensors:
parameters:
isValid
parameters
setParameters:
setInputsWithDimensions:
setOutputsWithDimensions:
quantization
_parametersSet
_nodeStr
_activations
_name
_properties
_inputs
_inputsWithDimensions
_outputs
_outputsWithDimensions
_weights
_quantization
_parameters
TB,V_parametersSet
T{?=qqqqqqq[8q]Q[8[4i]][4[4i]][16i][16f][16^v][16^v]},V_parameters
T@"NSString",R,V_nodeStr
T@"NSArray",R,V_activations
T@"NSString",R,V_name
valid
TB,R,GisValid
T@"NSDictionary",R,V_properties
T@"NSArray",&,N,V_inputs
T@"NSArray",&,N,V_inputsWithDimensions
T@"NSArray",&,N,V_outputs
T@"NSArray",&,N,V_outputsWithDimensions
T@"NSArray",R,V_weights
T@"MontrealNNModelQuantization",R,V_quantization
stringWithUTF8String:
fileURLWithPath:
initWithModelContainer:tensors:
nodes
allObjects
reason
weakObjectsHashTable
dimension
initWithName:dimension:
allocWithZone:
createInputs:inputChunks:nodeName:
createOutputs:outputChunks:nodeName:
copyWithZone:
tensorSize
_dimension
_asInput
_asOutput
T@"NSArray",R,V_dimension
T@"NSHashTable",R,V_asInput
T@"NSHashTable",R,V_asOutput
descriptionWithIndent:
initWithDictionary:quantization:jsonDir:
isEqualToString:
initWithOptimizerType:learningRate:momentum:gradientClipMin:gradientClipMax:
optimizerType
learningRate
momentum
gradientClipMin
gradientClipMax
_learningRate
_momentum
_optimizerType
_gradientClipMin
_gradientClipMax
TQ,R,V_optimizerType
Tf,R,V_learningRate
Tf,R,V_momentum
T@"NSNumber",R,V_gradientClipMin
T@"NSNumber",R,V_gradientClipMax
dataWithBytesNoCopy:length:freeWhenDone:
index
weightDataFormat
numberWithUnsignedLong:
initWithName:index:dimension:weightValues:
dataFromWeights:length:
initWithName:index:dimension:weightData:
numberWithInt:
dictionaryWithObjects:forKeys:count:
node
setObject:atIndexedSubscript:
initWithParameters:weightDataFormat:
generateNode:node:weightIter:inputs:outputs:
setInput:inputIndex:
weightIter
_weightIter
_node
_weightDataFormat
T{?=qqqqqqq[8q]Q[8[4i]][4[4i]][16i][16f][16^v][16^v]},R,V_parameters
TQ,R,V_weightIter
T@"MontrealNNModelNode",R,V_node
TQ,R,V_weightDataFormat
dealloc
setNodes:
weightFormat
networkInputs
networkOutputs
modelContainerPath
URLWithString:
stringByAppendingPathComponent:
defaultManager
stringWithFileSystemRepresentation:length:
initWithWeightFormat:
setNnObject:
nnObject
merge:
addInputs:
removeInput:
addOutputs:
removeOutput:
_nnObject
_weightFormat
TQ,R,V_weightFormat
T^{MontrealNeuralNetwork=},V_nnObject
T@"NSMutableDictionary",R,V_inputs
T@"NSMutableDictionary",R,V_outputs
initWithDictionary:tensors:quantization:optimizerParams:jsonDir:optimization:
validateNetworkTensors:
collapseNodes
validateNodeTensors
collapsePackUnpack:nodesToRemove:
removeView:nodesToRemove:
removeObjectsInArray:
removeAllObjects
removeObjectAtIndex:
insertObject:atIndex:
dataWithJSONObject:options:error:
writeToFile:atomically:
optimizerParams
_nodes
_optimizerParams
T@"NSArray",&,V_nodes
T@"NSArray",&,V_inputs
T@"NSArray",&,V_outputs
T@"MontrealNNModelOptimizerParam",R,V_optimizerParams
initWithName:index:dimension:
copyItemAtURL:toURL:error:
weightValues
fileExistsAtPath:
createflattenWeightsFile:
createConvertArrayToData:quantization:
weightData
createflattenWeightsHierarchy:
arrayWithArray:
dataWithBytes:length:
_index
_weightValues
_weightData
T@"NSNumber",R,V_index
T@"NSArray",R,V_weightValues
T@"NSData",R,V_weightData
.cxx_construct
confusionMatrix
logLikelihood
totalLoss
B24@0:8@16
#16@0:8
@16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B16@0:8
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
v32@0:8@16@24
v24@0:8@16
v32@0:8@"NSMutableString"16@"MontrealLogIndent"24
@"NSDictionary"16@0:8
v24@0:8@"NSString"16
@24@0:8@16
v16@0:8
@"NSString"
@"NSNumber"
B32@0:8@16^B24
@40@0:8@16@24Q32
@24@0:8Q16
@"MontrealNNModelNetwork"
@"NSDictionary"
@56@0:8@16@24@32@40@48
@48@0:8@16@24@32@40
@32@0:8@16@24
{?=qqqqqqq[8q]Q[8[4i]][4[4i]][16i][16f][16^v][16^v]}24@0:8^v16
{?=qqqqqqq[8q]Q[8[4i]][4[4i]][16i][16f][16^v][16^v]}16@0:8
v720@0:8{?=qqqqqqq[8q]Q[8[4i]][4[4i]][16i][16f][16^v][16^v]}16
v20@0:8B16
@"NSArray"
@"MontrealNNModelQuantization"
{?="nodeType"q"engineType"q"inputDataType"q"outputDataType"q"weightDataType"q"kernelDataType"q"inputEncoding"q"activations"[8q]"weightAttributes"Q"inputDimensions"[8[4i]]"outputDimensions"[4[4i]]"integers"[16i]"floats"[16f]"weights"[16^v]"biases"[16^v]}
@40@0:8^{?=qqqqqqq[8q]Q[8[4i]][4[4i]][16i][16f][16^v][16^v]}16@24@32
@24@0:8^{_NSZone=}16
@"NSHashTable"
@48@0:8Q16f24f28@32@40
f16@0:8
@32@0:8^{?=qqqqqqq[8q]Q[8[4i]][4[4i]][16i][16f][16^v][16^v]}16Q24
@32@0:8^f16Q24
Q56@0:8@16@24Q32@40@48
v32@0:8@16q24
@"MontrealNNModelNode"
v24@0:8^{MontrealNeuralNetwork=}16
^{MontrealNeuralNetwork=}16@0:8
^v16@0:8
^{MontrealNeuralNetwork=}
@"NSMutableDictionary"
@32@0:8^v16@24
@64@0:8@16@24@32@40@48Q56
@"MontrealNNModelOptimizerParam"
@40@0:8@16@24@32
@"NSData"
{map<unsigned int, std::map<unsigned int, unsigned int>, std::less<unsigned int>, std::allocator<std::pair<const unsigned int, std::map<unsigned int, unsigned int>>>>="__tree_"{__tree<std::__value_type<unsigned int, std::map<unsigned int, unsigned int>>, std::__map_value_compare<unsigned int, std::__value_type<unsigned int, std::map<unsigned int, unsigned int>>, std::less<unsigned int>, true>, std::allocator<std::__value_type<unsigned int, std::map<unsigned int, unsigned int>>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<unsigned int, std::map<unsigned int, unsigned int>>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<unsigned int, std::__value_type<unsigned int, std::map<unsigned int, unsigned int>>, std::less<unsigned int>, true>>="__value_"Q}}}
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
unable to set priority on espresso plan with ANE_RUNTIME
unable to load model
Failed to build espresso plan
Failed to clean espresso plan
new config does not bind to new input shape
batchsize=
,seqlen=
Cannot declare runtime output on ANE
no supported
v8@?0
MontrealNeuralNetworkState
index
name
node_type
activation_type
weights
inputs
outputs
properties
input_coding
model_calculation
weight_attributes
weight_storage
weight_storage_range
vocab_size
embedding_dimension
custom
filter_size
stride_size
dropout_ratio
lstm_projection_cell_size
lstm_projection_clip_lower_bound
lstm_projection_clip_upper_bound
full_connection
batchnorm
activation
concatenation
embeddingNew
embedding
lstm
lstm_bidirectional
gru_bidirectional
convolution
pooling
pack_padded_sequence
squeeze
unsqueeze
view
contiguous
highway
flatten
reverse
permute
attentionWithDotScore
attentionWithConcatScore
attentionSelf
layernormalize
reshape
slice
adaptiveEmbedding
adaptiveFC
none
sigmoid
hard_sigmoid
tanh
tanh_scaled
softmax
relu
dropout
log_softmax
gelu
leakyReLU
geluFast
dense
onehot
float32
float16
int8
bias_included
transposed
lstm_order_igfo
lstm_combined_weight
batchnorm_integrated
attention_weight_integrated
attention_identity_key_proj
attention_identity_query_proj
lstm_combined_bias
zero_bias
nodes
weight
bias
hidden_weight
hidden_bias
reverse_weight
reverse_bias
reverse_hidden_weight
reverse_hidden_bias
peephole_weight
reverse_peephole_weight
projection_weight
running_mean
running_var
optimization
optimizer
adam
learning_rate
momentum
fileLocation
embeddingFileLocation
layerParameters
layerParametersSize
nHiddenNodes
inputEncoding
modelConfig
numThreads
errorCount
errorRate
logProbability
modelData
learningRate
beta1
beta2
estimatorType
None
Evaluate: 
sequence MRLModelRecognize
sequence MRLModelRecognizeVectorsTopN
MRLModelWrapper::MRLModelRecognizeVectorsTopN() float* allocate
sequence MRLModelRecognizeVectorsIncrementalTopN
full sequence MRLModelRecognizeTopN
MRLModelWrapper::MRLModelRecognizeTopN() token allocate
incremental MRLModelRecognizeIncrementalTopN
recognizeSequenceInternalFullBiDir, tokenID - activate all buffer to %d length
recognizeSequenceInternalFullBiDir, float* - activate all buffer to %d length
%@, 
    
array::at
com.apple.MRLNeuralNetwork
MRLNeuralNetworkOptionModelURLKey
MRLNeuralNetworkOptionModelDataKey
MRLNeuralNetworkOptionInputNamesKey
MRLNeuralNetworkOptionOutputNamesKey
MRLNeuralNetworkOptionEngineKey
MRLNeuralNetworkOptionQuantizationParamsKey
MRLNeuralNetworkOptionQuantizationSchemeNameKey
MRLNeuralNetworkOptionQuantizationSchemeLinearInt8RangeMinKey
MRLNeuralNetworkOptionQuantizationSchemeLinearInt8RangeMaxKey
MRLNeuralNetworkOptionModelNameKey
MRLNeuralNetworkOptionModelVersionKey
kMRLNeuralNetworkOptionModelTypeKey
MRLNeuralNetworkOptionQuantizationSchemeNameLinearInt8
MRLNeuralNetworkEvaluateInputDataKey
MRLNeuralNetworkEvaluateOutputLabelKey
Channel
Width
Height
InputDimension
SequenceLength
isChannelLast
isBatchFirst
DataType
ShapeDimension
MRLNeuralNetworkOptionANENetworkURLKey
MRLNeuralNetworkOptionANEStartNodeName
MRLNeuralNetworkOptionANEEndNodeName
Espresso
NLModel
FlatModel
EspressoE5RT
Invalid Engine. Support Engines = {CPU}
unknown exception
.espresso.net
Invalid Engine. Support Engines = {CPU, ANE}
Unable to load Espresso Model
Invalid Engine. Support Engines for E5RT = {CPU}
Unable to load E5RT Model
Unable to create network from data. 
.espresso.
Unknown expection
Please provide a valid input name. 
 input cannot be set
Unknown error. 
kMRLNeuralNetworkSingleInput
kMRLNeuralNetworkSingleOutput
Could not construct
Could not convert
MontrealNeuralNetwork
MontrealNeuralNetworkTensor
DictionaryRef_iterator iterator out of range.
Could not find item
_h_in
_c_in
_r_h_in
_r_c_in
_k_s_in
_v_s_in
_out
LMTRAINER
inputEncoding has wrong value!
not allowed 
Threaded recognize not supported
MRLModelWrapper, layer #0 
***Error executing ThreadPool.run()
***Error execuring ThreadPool.run()
do-not-us-this-path,from-raw-buffer
from MLNLP_CONFIG_MLKIT_LAYER_BY_LAYER
LSTM constructor
LSTM alloc, from constructor
prevM=
0x%lx
LSTM before reset 
LSTM AFTER reset 
LSTM alloc, from allocAll
v16@?0Q8
FullLayer constructor
FullLayer
FullLayer, from allocAll
RecurrentLayer from Constructor
RecurrentLayer from allocAll
SoftMax, from allocAll
GRU constructor
GRU alloc, from constructor
GRU before reset 
GRU AFTER reset 
GRU alloc, from allocAll
outvec0/gzx
outvec1/grx
outvec2/gox
inRange:yes
inRange:no
 [1 x 
BatchNormalization, from allocAll
From constructor
From allocAllBuffers
WARNING: Invalid (too large) Montreal id (%d) - IGNORE
corpus entry 
do-not-use-this-path,from-raw-buffer
SentenceRecognizer
NLModelContainerCreate
NLModelContainerCreateWithContentsOfURL
NLModelContainerCreateWithContainerData
NLModelContainerGetType
NLModelContainerGetSubtype
NLModelContainerGetRevision
NLModelContainerCopyInfoDictionary
NLModelContainerGetModelDataCount
NLModelContainerCopyModelDataAtIndex
NLModelContainerWriteToURL
/System/Library/PrivateFrameworks/CoreNLP.framework/CoreNLP
/dev/urandom
nodeStr
%@ == %%@
@16@?0@"NSArray"8
 %@ Name = %@ 
 %@ Node Type = %@ 
 %@ Activation Type = %@ 
 %@ Inputs With Dimensions = %@ 
 %@ Outputs With Dimension = %@ 
 %@ Inputs = %@ 
 %@ Outputs = %@ 
 %@ Weights = %@ 
 %@ Properties = %@ 
Failed to create NLModelContainer from file: %@
Failed to create NLModelContainer from model data
No saved model container
Unexpected Port: 
map::at:  key not found
dilationStride
unable to determine output shape of layer 
input shape not found at port 
output shape not found at port 
 %@ Name = %@
 %@ Dimension = %@
 %@ As Input
 %@ %@
 %@ As Output
tensor_input_%@_%@
tensor_output_%@_%@
com.apple.Montreal
Default
 %@ {
 %@ }
%@ %@ has 0 elements
%@ %@ is nil
%@ %@: %@ is invalid
 %@ [
 %@ %@
 %@ ]
 %@ %@ : %@
Tensor %@ is already present
Weight %@ is already present
Node %@ is already present
Model format incompatibale. Unable to build Flat model
Flat model file corrupted
Flat model version incorrect
Only kMRLNeuralNetworkWeight                                                    AttributeBatchNormalizationIntegrated weight attribute supported
Model name cannot be greater than 31 characters.
self_attention
_after_input_transpose
_after_output_transpose
transpose
_input_t
instancenorm_1d
_output_t
elementwise
general_concat
_before_softmax
_before_relu
inner_product
_softmax
_relu
W_x_reverse
W_h_reverse
b_reverse
fast_reshape
Unexpected type for 
HTParameterNameKey
HTParameterTypeKey
HTParameterDimensionKey
HTParameterMinimumValueKey
HTParameterMaximumValueKey
HTAlgorithmKey
HTKernelKey
HTAcquisitionKey
HTCallbackIntervalKey
HTStopConditionMaxIterationsKey
HTStopConditionPatienceKey
HTStopConditionMinDeltaKey
HTOptimizationDirectionKey
HTRandomSeedKey
HTInitialParameterValuesKey
HTParameterTypeIntegral
HTParameterTypeContinuous
HTAlgorithmRandom
HTAlgorithmGaussianProcess
HTKernelSquaredExponential
HTKernelARDSquaredExponential
HTKernelMaternFiveHalves
HTAcquisitionProbabilityOfImprovement
HTAcquisitionExpectedImprovement
HTAcquisitionUpperConfidenceBound
HTOptimizationDirectionMaximize
HTOptimizationDirectionMinimize
Name
MinimumValue
MaximumValue
Dimension
Type
Missing required key: 
Missing parameter value for parameter with name=
MaxIterations
Patience
MinDelta
Integral
Continuous
Unrecognized paramType: 
CallbackInterval
RandomSeed
InitialParameterValues
SquaredExponential
ARDSquaredExponential
MaternFiveHalves
Invalid kernel: 
Kernel
Acquisition
Algorithm
Direction
Random
GaussianProcess
ProbabilityOfImprovement
ExpectedImprovement
UpperConfidenceBound
Maximize
Minimize
Unexpected HyperTune key: 
[InvalidArgument] 
Unexpected optimizer name: 
Unexpected optimization direction: 
Invalid acquisition: 
Invalid optimizer in user config.
acquisition_optimizer
genetic_optimizer
nlopt failure
nlopt invalid argument
uninitialized nlopt::opt
nlopt roundoff-limited
nlopt forced stop
dimension mismatch
direct_optimizer
Early stopping already requested.
com.apple.HyperTune
 %@ Algorithm = %tu (Adam: %tu, SGD: %tu)
 %@ Learning Rate = %lf
 %@ Use Momentum = %lf
 %@ Gradient Clip Min = %@, Max = %@
v24@?0Q8@"NSString"16
Node_%@
Failed to merge %@ to the network as there is one which already exists with the same name
model_generate.XXXXX
model_container.nlmodel
tpThreadInit error
hw.activecpu
%@/network.json
Failed to extract network JSON
%@/description.json
Failed to extract description JSON
Failed to extract network JSON from model container
Node %@ contains empty inputs or outputs
Node %@ output is going nowhere?
Node %@ contains empty outputs
No unpack node?
 %@ Nodes = %@ 
Invalid rangeOrIndices for partial output. 
 has not been connected to any node in the network.
recompiling 
for 
Invalid node name: 
Invalid nodeName for partial output. 
 %@ Index = %@ 
 %@ Dimension = %@ 
%@/%@.json
%@ Source file %@ doesn't exist
%@ Cannot generate JSON weights file
%@ No weights file or data to add to data container
IPHONE_SIMULATOR_ROOT
Expected oututDims to have size 3 or 2.
dict does not have key: 
LSTM
Embedding
EmbeddingLegacy
Pooling
Convolution
Activation
BatchNormalization
Concatenation
FullConnection
LSTMBidirectional
GRUBidirectional
Unexpected NodeType: 
MLPModelTrainerDataLayoutKey
MLPModelTrainerDataLayoutHeightxWidthxFeatureChannels
MLPModelTrainerDataLayoutFeatureChannelsxHeightxWidth
MLPModelTrainerOptimizerAlgorithmKey
MLPModelTrainerOptimizerAdam
MLPModelTrainerOptimizerSGD
MLPModelTrainerNoImprovementWindowKey
MLPModelTrainerNumberOfEpochsKey
MLPModelTrainerLearningRateKey
MLPModelTrainerLearningRateDecayStepsKey
MLPModelTrainerLearningRateDecayRateKey
MLPModelTrainerLearningRateDecayStairCaseKey
MLPModelTrainerOptimizerMomentumKey
MLPModelTrainerGradientClipMinimum
MLPModelTrainerGradientClipMaximum
MLPModelTrainerBatchSizeKey
MLPModelTrainerEvaluationBatchSizeKey
MLPModelTrainerLossBatchSizeKey
MLPModelTrainerInputLengthKey
MLPModelTrainerInputHeightKey
MLPModelTrainerInputChannelsKey
MLPModelTrainerNumberOfLabelsKey
MLPModelTrainerComputeLossOnEvaluationKey
MLPModelTrainerVocabSizeKey
MLPModelTrainerEmbeddingDimensionKey
MLPModelGenerateFormatKey
MLPModelGenerateFormatJSON
MLPModelGenerateFormatCompact
MLPModelTrainerConfusionMatrixKey
MLPModelTrainerOverallAccuracyKey
MLPModelTrainerPerplexityKey
MLPModelTrainerBpcKey
MLPModelTrainerLossValueKey
MLPModelTrainerPerClassPrecisionKey
MLPModelTrainerPerClassRecallKey
MLPModelSampleDataFeatureValuesKey
MLPModelSampleDataLabelsKey
MLPModelSampleDataBatchOfSequencesKey
MLPModelSampleDataSequenceValuesKey
MLPModelSampleDataSequenceLabelsKey
tpThreadDispatch: thread %u not idle
***tpThread: Error waiting on condition; error %d; aborting.
***tpThreadInit: Error starting up server thread
***tpThreadInit: Error initializing pthreadCond
***tpThreadInit: Error initializing mutex
***tpThreadInit: malloc failure
***tpThread: internal error, actThreads = 0
***tpThread: Error acquiring lock; aborting.
tpThreadDispatch: pthread_cond_signal error
tpThreadDispatch: mutex error
tpThreadDispatch with threads still active
tpThreadDispatch: illegal numThreads
NULL args to nlopt_optimize
failure allocating elim_opt
NULL args to nlopt_optimize_
bounds %d fail %g <= %g <= %g
finite domain required for global algorithm
N9inference18EspressoANEManagerE
.N9inference26BNNSBroadcastElementkernelIfLm5EEE
N9inference12PermuteLayerIffLm5EEE
N9inference13AbstractLayerIffLm5EEE
N9inference13MontrealLayerILm5EEE
"(2;CIOV\bj
"(9DJPV^djqN10exceptions25NetworkIncompatibleEngineE
N10exceptions25NetworkIncompatibleFormatE
N10exceptions23NetworkInValidNameErrorE
N9inference18AttentionLayerSelfIffLm5EEE
N9inference14AttentionLayerIffLm5EEE
N9inference22EmbeddingAdaptiveLayerIffLm5EEE
N9inference13AbstractLayerIafLm5EEE
N9inference15EspressoManagerE
*0Ih
7Encoder
11EncoderMeta
11PerThreadSR
13EncoderOneInN
4LSTMIsE
13NeuralNetwork
15EstimatorScalarIfE
9EstimatorIfE
13EstimatorADAMIfE
15EstimatorAdaMaxIfE
4LSTMIfE
7Reverse
8Parallel
9FullLayerIsE
9FullLayerIfE
7Stacked
14RecurrentLayerIsE
6Direct
7SoftMaxIsE
3GRUIsE
3GRUIfE
18BatchNormalizationIsE
16ParallelSelectorIsE
4LSTMIaE
9FullLayerIaE
14RecurrentLayerIaE
7SoftMaxIaE
3GRUIaE
18BatchNormalizationIaE
16ParallelSelectorIaE
14RecurrentLayerIfE
7SoftMaxIfE
18BatchNormalizationIfE
16ParallelSelectorIfE
13OutputCluster
11EncoderBits
21EncoderOneInNTwoParts
11EncoderGray
18EncoderBitsFromMap
11EncoderCopy
#<fff?F
N9inference9LSTMLayerIffLm5EEE
N9inference9LSTMLayerIafLm5EEE
 N9inference10BaseEngineE
N9inference16ActivationKernelIfEE
N9inference13ElementKernelIfEE
N9inference12MatrixKernelIaEE
N9inference13ElementKernelIaEE
N9inference15TransposeKernelIfEE
N9inference17EspressoE5ManagerE
N9inference10SliceLayerIffLm5EEE
N9inference10SliceLayerIafLm5EEE
N9inference14NLModelBuilderE
N9inference6layers12PoolingLayerIffLm5EEE
%/N9inference14KernelCompilerE
N9inference18QuantizationKernelIfaEE
N9inference18QuantizationKernelIffEE
N9inference11MergeKernelIfEE
N9inference10MeanKernelIfLm5EEE
N9inference12ConcatKernelIfLm5EEE
N9inference13PermuteKernelIfLm5EEE
N9inference13FunctionLayerIffLm5EEE
N9inference18LayerNormalizationIffLm5EEE
DGJM
N9inference27BNNSBroadcastFunctionkernelIfLm5EEE
N9inference6layers16ConvolutionLayerIffLm5EEE
N9inference26AttentionLayerWithDotScoreIffLm5EEE
[m4<WxN9inference20BNNSActivationKernelIfEE
N9inference18QuantizationKernelIafEE
*?9E7?
'7fff?
g_bKjN10exceptions34NetworkFlatModelIncompatibleFormatE
N10exceptions21UnknownExecptionErrorE
N9inference16FlatModelBuilderE
N9inference22AbstractNetworkBuilderE
NSt3__120__shared_ptr_emplaceIN8Espresso4blobIfLi2EEENS_9allocatorIS3_EEEE
N8Espresso4blobIfLi2EEE
NSt3__120__shared_ptr_emplaceIN8Espresso4blobIfLi1EEENS_9allocatorIS3_EEEE
N8Espresso4blobIfLi1EEE
NSt3__120__shared_ptr_emplaceIN8Espresso4blobIfLi4EEENS_9allocatorIS3_EEEE
N8Espresso4blobIfLi4EEE
"(3>JPVagmx
%N2ht5error15InvalidArgumentE
N2ht5error20ExceptionWithMessageE
N2ht5error12RuntimeErrorE
N2ht3opt15RandomOptimizerE
N2ht3opt17BlackBoxOptimizerE
N2ht3opt24GaussianProcessOptimizerIZ13runExperimentINS_2SEENS_2PIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht2gp24ProbabilityOfImprovementINS0_15GaussianProcessIZ13runExperimentINS_2SEENS_2PIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsNS0_4mean4DataIS9_EENS0_6kernel18SquaredExponentialIS9_EEEEEE
N2ht2gp19AcquisitionFunctionINS0_15GaussianProcessIZ13runExperimentINS_2SEENS_2PIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsNS0_4mean4DataIS9_EENS0_6kernel18SquaredExponentialIS9_EEEEEE
N2ht3opt16GeneticOptimizerIZ13runExperimentINS_2SEENS_2PIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht3opt20AcquisitionOptimizerINS_2gp24ProbabilityOfImprovementINS2_15GaussianProcessIZ13runExperimentINS_2SEENS_2PIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsNS2_4mean4DataISB_EENS2_6kernel18SquaredExponentialISB_EEEEEEEE
N2ht3opt15DirectOptimizerIZ13runExperimentINS_2SEENS_2PIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht3opt12NLOptWrapperILN5nlopt9algorithmE0EEE
N5nlopt16roundoff_limitedE
N5nlopt11forced_stopE
N2ht4stop13MaxIterationsE
N2ht4stop17StoppingConditionE
N2ht4stop7PlateauIZ13runExperimentINS_2SEENS_2PIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
NSt3__117bad_function_callE
N2ht3opt24GaussianProcessOptimizerIZ13runExperimentINS_2SEENS_2EIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht2gp19ExpectedImprovementINS0_15GaussianProcessIZ13runExperimentINS_2SEENS_2EIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsNS0_4mean4DataIS9_EENS0_6kernel18SquaredExponentialIS9_EEEEEE
N2ht2gp19AcquisitionFunctionINS0_15GaussianProcessIZ13runExperimentINS_2SEENS_2EIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsNS0_4mean4DataIS9_EENS0_6kernel18SquaredExponentialIS9_EEEEEE
N2ht3opt16GeneticOptimizerIZ13runExperimentINS_2SEENS_2EIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht3opt20AcquisitionOptimizerINS_2gp19ExpectedImprovementINS2_15GaussianProcessIZ13runExperimentINS_2SEENS_2EIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsNS2_4mean4DataISB_EENS2_6kernel18SquaredExponentialISB_EEEEEEEE
N2ht3opt15DirectOptimizerIZ13runExperimentINS_2SEENS_2EIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht4stop7PlateauIZ13runExperimentINS_2SEENS_2EIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht3opt24GaussianProcessOptimizerIZ13runExperimentINS_2SEENS_3UCBEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht2gp20UpperConfidenceBoundINS0_15GaussianProcessIZ13runExperimentINS_2SEENS_3UCBEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsNS0_4mean4DataIS9_EENS0_6kernel18SquaredExponentialIS9_EEEEEE
N2ht2gp19AcquisitionFunctionINS0_15GaussianProcessIZ13runExperimentINS_2SEENS_3UCBEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsNS0_4mean4DataIS9_EENS0_6kernel18SquaredExponentialIS9_EEEEEE
N2ht3opt16GeneticOptimizerIZ13runExperimentINS_2SEENS_3UCBEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht3opt20AcquisitionOptimizerINS_2gp20UpperConfidenceBoundINS2_15GaussianProcessIZ13runExperimentINS_2SEENS_3UCBEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsNS2_4mean4DataISB_EENS2_6kernel18SquaredExponentialISB_EEEEEEEE
N2ht3opt15DirectOptimizerIZ13runExperimentINS_2SEENS_3UCBEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht4stop7PlateauIZ13runExperimentINS_2SEENS_3UCBEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht3opt24GaussianProcessOptimizerIZ13runExperimentINS_5ARDSEENS_2PIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht2gp24ProbabilityOfImprovementINS0_15GaussianProcessIZ13runExperimentINS_5ARDSEENS_2PIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsNS0_4mean4DataIS9_EENS0_6kernel21ARDSquaredExponentialIS9_EEEEEE
N2ht2gp19AcquisitionFunctionINS0_15GaussianProcessIZ13runExperimentINS_5ARDSEENS_2PIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsNS0_4mean4DataIS9_EENS0_6kernel21ARDSquaredExponentialIS9_EEEEEE
N2ht3opt16GeneticOptimizerIZ13runExperimentINS_5ARDSEENS_2PIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht3opt20AcquisitionOptimizerINS_2gp24ProbabilityOfImprovementINS2_15GaussianProcessIZ13runExperimentINS_5ARDSEENS_2PIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsNS2_4mean4DataISB_EENS2_6kernel21ARDSquaredExponentialISB_EEEEEEEE
N2ht3opt15DirectOptimizerIZ13runExperimentINS_5ARDSEENS_2PIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht4stop7PlateauIZ13runExperimentINS_5ARDSEENS_2PIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht3opt24GaussianProcessOptimizerIZ13runExperimentINS_5ARDSEENS_2EIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht2gp19ExpectedImprovementINS0_15GaussianProcessIZ13runExperimentINS_5ARDSEENS_2EIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsNS0_4mean4DataIS9_EENS0_6kernel21ARDSquaredExponentialIS9_EEEEEE
N2ht2gp19AcquisitionFunctionINS0_15GaussianProcessIZ13runExperimentINS_5ARDSEENS_2EIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsNS0_4mean4DataIS9_EENS0_6kernel21ARDSquaredExponentialIS9_EEEEEE
N2ht3opt16GeneticOptimizerIZ13runExperimentINS_5ARDSEENS_2EIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht3opt20AcquisitionOptimizerINS_2gp19ExpectedImprovementINS2_15GaussianProcessIZ13runExperimentINS_5ARDSEENS_2EIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsNS2_4mean4DataISB_EENS2_6kernel21ARDSquaredExponentialISB_EEEEEEEE
N2ht3opt15DirectOptimizerIZ13runExperimentINS_5ARDSEENS_2EIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht4stop7PlateauIZ13runExperimentINS_5ARDSEENS_2EIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht3opt24GaussianProcessOptimizerIZ13runExperimentINS_5ARDSEENS_3UCBEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht2gp20UpperConfidenceBoundINS0_15GaussianProcessIZ13runExperimentINS_5ARDSEENS_3UCBEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsNS0_4mean4DataIS9_EENS0_6kernel21ARDSquaredExponentialIS9_EEEEEE
N2ht2gp19AcquisitionFunctionINS0_15GaussianProcessIZ13runExperimentINS_5ARDSEENS_3UCBEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsNS0_4mean4DataIS9_EENS0_6kernel21ARDSquaredExponentialIS9_EEEEEE
N2ht3opt16GeneticOptimizerIZ13runExperimentINS_5ARDSEENS_3UCBEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht3opt20AcquisitionOptimizerINS_2gp20UpperConfidenceBoundINS2_15GaussianProcessIZ13runExperimentINS_5ARDSEENS_3UCBEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsNS2_4mean4DataISB_EENS2_6kernel21ARDSquaredExponentialISB_EEEEEEEE
N2ht3opt15DirectOptimizerIZ13runExperimentINS_5ARDSEENS_3UCBEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht4stop7PlateauIZ13runExperimentINS_5ARDSEENS_3UCBEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht3opt24GaussianProcessOptimizerIZ13runExperimentINS_6MaternENS_2PIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht2gp24ProbabilityOfImprovementINS0_15GaussianProcessIZ13runExperimentINS_6MaternENS_2PIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsNS0_4mean4DataIS9_EENS0_6kernel16MaternFiveHalvesIS9_EEEEEE
N2ht2gp19AcquisitionFunctionINS0_15GaussianProcessIZ13runExperimentINS_6MaternENS_2PIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsNS0_4mean4DataIS9_EENS0_6kernel16MaternFiveHalvesIS9_EEEEEE
N2ht3opt16GeneticOptimizerIZ13runExperimentINS_6MaternENS_2PIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht3opt20AcquisitionOptimizerINS_2gp24ProbabilityOfImprovementINS2_15GaussianProcessIZ13runExperimentINS_6MaternENS_2PIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsNS2_4mean4DataISB_EENS2_6kernel16MaternFiveHalvesISB_EEEEEEEE
N2ht3opt15DirectOptimizerIZ13runExperimentINS_6MaternENS_2PIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht4stop7PlateauIZ13runExperimentINS_6MaternENS_2PIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht3opt24GaussianProcessOptimizerIZ13runExperimentINS_6MaternENS_2EIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht2gp19ExpectedImprovementINS0_15GaussianProcessIZ13runExperimentINS_6MaternENS_2EIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsNS0_4mean4DataIS9_EENS0_6kernel16MaternFiveHalvesIS9_EEEEEE
N2ht2gp19AcquisitionFunctionINS0_15GaussianProcessIZ13runExperimentINS_6MaternENS_2EIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsNS0_4mean4DataIS9_EENS0_6kernel16MaternFiveHalvesIS9_EEEEEE
N2ht3opt16GeneticOptimizerIZ13runExperimentINS_6MaternENS_2EIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht3opt20AcquisitionOptimizerINS_2gp19ExpectedImprovementINS2_15GaussianProcessIZ13runExperimentINS_6MaternENS_2EIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsNS2_4mean4DataISB_EENS2_6kernel16MaternFiveHalvesISB_EEEEEEEE
N2ht3opt15DirectOptimizerIZ13runExperimentINS_6MaternENS_2EIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht4stop7PlateauIZ13runExperimentINS_6MaternENS_2EIEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht3opt24GaussianProcessOptimizerIZ13runExperimentINS_6MaternENS_3UCBEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht2gp20UpperConfidenceBoundINS0_15GaussianProcessIZ13runExperimentINS_6MaternENS_3UCBEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsNS0_4mean4DataIS9_EENS0_6kernel16MaternFiveHalvesIS9_EEEEEE
N2ht2gp19AcquisitionFunctionINS0_15GaussianProcessIZ13runExperimentINS_6MaternENS_3UCBEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsNS0_4mean4DataIS9_EENS0_6kernel16MaternFiveHalvesIS9_EEEEEE
N2ht3opt16GeneticOptimizerIZ13runExperimentINS_6MaternENS_3UCBEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht3opt20AcquisitionOptimizerINS_2gp20UpperConfidenceBoundINS2_15GaussianProcessIZ13runExperimentINS_6MaternENS_3UCBEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsNS2_4mean4DataISB_EENS2_6kernel16MaternFiveHalvesISB_EEEEEEEE
N2ht3opt15DirectOptimizerIZ13runExperimentINS_6MaternENS_3UCBEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
N2ht4stop7PlateauIZ13runExperimentINS_6MaternENS_3UCBEENS_6ResultENS_6ConfigENS_14FunctionCallerEE6ParamsEE
NSt3__110__function6__funcI24IterationCallbackWrapperNS_9allocatorIS2_EEFbRKN2ht14ProgressReportEEEE
NSt3__110__function6__baseIFbRKN2ht14ProgressReportEEEE
24IterationCallbackWrapper
NSt3__110__function6__funcIN2ht8defaults17IterationCallbackENS_9allocatorIS4_EEFbRKNS2_14ProgressReportEEEE
N2ht8defaults17IterationCallbackE
NSt3__110__function6__funcI22EvaluationBlockWrapperNS_9allocatorIS2_EEFdRKN2ht5QueryEEEE
NSt3__110__function6__baseIFdRKN2ht5QueryEEEE
22EvaluationBlockWrapper
4N9inference27FullConnectionAdaptiveLayerIffLm5EEE
N9inference27FullConnectionAdaptiveLayerIafLm5EEE
N9inference21BNNSConvolutionKernelIfLm2EEE
N9inference16BNNSMatrixKernelIfEE
N9inference12MatrixKernelIfEE
N9inference14AbstractKernelE
N9inference16BNNSMatrixKernelIaEE
N9inference10BNNSEngineE
N9inference7kernels17BNNSPoolingKernelIfEE
N9inference20EmbeddingLegacyLayerIffLm5EEE
9PerThread
10ThreadPool
N9inference19FullConnectionLayerIffLm5EEE
N9inference19FullConnectionLayerIafLm5EEE
7PTMutex
N9inference12ReshapeLayerIffLm5EEE
N9inference12ReshapeLayerIafLm5EEE
N9inference16ExecutionManagerE
N9inference23BatchNormalizationLayerIffLm5EEE
N9inference20EmbeddingLegacyLayerIafLm5EEE
N9inference14EmbeddingLayerIffLm5EEE
N9inference14EmbeddingLayerIafLm5EEE
N9inference22EmbeddingAdaptiveLayerIafLm5EEE
NSt3__120__shared_ptr_emplaceIN9inference8DataBlobIfEENS_9allocatorIS3_EEEE
N9inference22AttentionLayerBahdenauIffLm5EEE
N9inference17BNNSElementKernelIfEE
"(7AMSYciox
N9inference13BNNSBMMKernelIfLm5EEE
N9inference18LowLatencyCompilerE
N9inference22BNNSQuantizationKernelIfaEE
N9inference12LookupKernelIaEE
N9inference22BNNSQuantizationKernelIafEE
N9inference12LookupKernelIfEE
NSt3__110__function6__funcIZN9inference18LowLatencyCompiler23compileConvolutionLayerEPNS2_6layers16ConvolutionLayerIffLm5EEEE3$_0NS_9allocatorIS8_EEFNS2_5utils6TensorIfLm4EEEiEEE
NSt3__110__function6__baseIFN9inference5utils6TensorIfLm4EEEiEEE
ZN9inference18LowLatencyCompiler23compileConvolutionLayerEPNS_6layers16ConvolutionLayerIffLm5EEEE3$_0
NSt3__110__function6__funcIZN9inference18LowLatencyCompiler23compileConvolutionLayerEPNS2_6layers16ConvolutionLayerIffLm5EEEE3$_1NS_9allocatorIS8_EEFNS2_5utils6TensorIfLm4EEEiEEE
ZN9inference18LowLatencyCompiler23compileConvolutionLayerEPNS_6layers16ConvolutionLayerIffLm5EEEE3$_1
NSt3__110__function6__funcIZN9inference18LowLatencyCompiler19compilePoolingLayerEPNS2_6layers12PoolingLayerIffLm5EEEE3$_2NS_9allocatorIS8_EEFNS2_5utils6TensorIfLm4EEEiEEE
ZN9inference18LowLatencyCompiler19compilePoolingLayerEPNS_6layers12PoolingLayerIffLm5EEEE3$_2
NSt3__110__function6__funcIZN9inference18LowLatencyCompiler19compilePoolingLayerEPNS2_6layers12PoolingLayerIffLm5EEEE3$_3NS_9allocatorIS8_EEFNS2_5utils6TensorIfLm4EEEiEEE
ZN9inference18LowLatencyCompiler19compilePoolingLayerEPNS_6layers12PoolingLayerIffLm5EEEE3$_3
Unable to append the state
Incremental state should have sequence length of 1
Incremental state should have same shape as the past appended states
%s not found in state
Params specified that weights are being shared with Adaptive Embedding Layer. However, weights don't match.
Unsupported Engine type %d.
Cannot create context, Caught exception: %s
Unrecognized input name.
Unrecognized output name.
dict does not have key: %s
MontrealNNModelQuantization
MontrealNNDescriptionProtocol
NSObject
Utils
MontrealLogIndent
MontrealModelJSONParser
MontrealNNModelNode
MontrealNNModelTensor
NSCopying
MontrealNNDescription
MontrealNNModelOptimizerParam
MontrealNNGenerateNode
MontrealNNGenerateModel
MontrealNNModelNetwork
MontrealNNModelWeight
MLPInferenceResult
reason
dictionary
copy
dataWithBytesNoCopy:length:freeWhenDone:
addObject:
objectAtIndexedSubscript:
initWithCapacity:
stringWithFileSystemRepresentation:length:
setObject:forKeyedSubscript:
floatValue
dataWithBytes:length:
appendFormat:
removeObjectsInArray:
containsObject:
initWithFormat:arguments:
numberWithFloat:
writeToFile:atomically:
setObject:atIndexedSubscript:
objectAtIndex:
arrayWithObjects:count:
addEntriesFromDictionary:
stringByAppendingPathComponent:
indexOfObject:
isEqualToString:
removeObjectAtIndex:
bytes
numberWithUnsignedLong:
filteredSetUsingPredicate:
anyObject
numberWithDouble:
arrayWithCapacity:
countByEnumeratingWithState:objects:count:
defaultManager
length
unsignedIntegerValue
errorWithDomain:code:userInfo:
boolValue
arrayWithArray:
predicateWithFormat:
string
allocWithZone:
fileURLWithPath:
removeObject:
fileExistsAtPath:
numberWithUnsignedInteger:
count
JSONObjectWithData:options:error:
dataWithJSONObject:options:error:
insertObject:atIndex:
UTF8String
copyItemAtURL:toURL:error:
allObjects
removeAllObjects
URLWithString:
path
dictionaryWithObjects:forKeys:count:
stringWithUTF8String:
array
numberWithUnsignedInt:
weakObjectsHashTable
numberWithInt:
mutableCopy
objectForKeyedSubscript:
stringWithFormat:
addObjectsFromArray:
appendString:
exceptionWithName:reason:userInfo:
dataWithContentsOfFile:
init
isEqual:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
description
debugDescription
TQ,R
T#,R
T@"NSString",R,C
description:indent:
jsonDescription
checkForValidity
generateJSONAtPath:
initWithDictionary:
weightStorage
weightStorageRange
.cxx_destruct
_weightStorage
_weightStorageRange
T@"NSString",R,V_weightStorage
T@"NSNumber",R,V_weightStorageRange
exMRL_stringForKey:
exMRL_numberForKey:
exMRL_boolForKey:
exMRL_boolForKey:keyPresent:
exMRL_dictionaryForKey:
exMRL_arrayForKey:
exMRL_setForKey:
exMRL_dataForKey:
exMRL_numberArrayDescription
indentWithLevel:
indentWithLevel:step:factor:
initWithLevel:step:factor:
indentByFactor:
step
factor
level
_step
_factor
_level
T@"NSString",R,V_step
TQ,R,V_factor
T@"NSString",R,V_level
initWithURL:
createJSONFromFile:
jsonDir
network
infoDictionary
_jsonDir
_network
_infoDictionary
T@"NSString",R,V_jsonDir
T@"MontrealNNModelNetwork",R,V_network
T@"NSDictionary",R,V_infoDictionary
initWithName:nodeStr:activations:properties:weights:
initWithDictionary:tensors:quantization:jsonDir:
auditAndUpdateTensors:dimensionTensors:
setInputs:
setOutputs:
keepTensors:
parameters:
createDataContainer
isValid
parameters
setParameters:
nodeStr
activations
name
properties
inputs
inputsWithDimensions
setInputsWithDimensions:
outputs
outputsWithDimensions
setOutputsWithDimensions:
weights
quantization
parametersSet
setParametersSet:
_parametersSet
_nodeStr
_activations
_name
_properties
_inputs
_inputsWithDimensions
_outputs
_outputsWithDimensions
_weights
_quantization
_parameters
TB,V_parametersSet
T{?=qqqqqqq[8q]Q[8[4i]][4[4i]][16i][16f][16^v][16^v]},V_parameters
T@"NSString",R,V_nodeStr
T@"NSArray",R,V_activations
T@"NSString",R,V_name
valid
TB,R,GisValid
T@"NSDictionary",R,V_properties
T@"NSArray",&,N,V_inputs
T@"NSArray",&,N,V_inputsWithDimensions
T@"NSArray",&,N,V_outputs
T@"NSArray",&,N,V_outputsWithDimensions
T@"NSArray",R,V_weights
T@"MontrealNNModelQuantization",R,V_quantization
createInputs:inputChunks:nodeName:
createOutputs:outputChunks:nodeName:
copyWithZone:
initWithName:dimension:
tensorSize
dimension
asInput
asOutput
_dimension
_asInput
_asOutput
T@"NSArray",R,V_dimension
T@"NSHashTable",R,V_asInput
T@"NSHashTable",R,V_asOutput
descriptionWithIndent:
checkForValidity:
initWithOptimizerType:learningRate:momentum:gradientClipMin:gradientClipMax:
optimizerType
learningRate
momentum
gradientClipMin
gradientClipMax
_learningRate
_momentum
_optimizerType
_gradientClipMin
_gradientClipMax
TQ,R,V_optimizerType
Tf,R,V_learningRate
Tf,R,V_momentum
T@"NSNumber",R,V_gradientClipMin
T@"NSNumber",R,V_gradientClipMax
initWithParameters:weightDataFormat:
dataFromWeights:length:
generateNode:node:weightIter:inputs:outputs:
setInput:inputIndex:
weightIter
node
weightDataFormat
_weightIter
_node
_weightDataFormat
T{?=qqqqqqq[8q]Q[8[4i]][4[4i]][16i][16f][16^v][16^v]},R,V_parameters
TQ,R,V_weightIter
T@"MontrealNNModelNode",R,V_node
TQ,R,V_weightDataFormat
dealloc
initWithWeightFormat:
setNnObject:
nnObject
merge:
generateModelContainer
modelContainerPath
addInputs:
removeInput:
addOutputs:
removeOutput:
networkInputs
networkOutputs
weightFormat
_nnObject
_weightFormat
TQ,R,V_weightFormat
T^{MontrealNeuralNetwork=},V_nnObject
T@"NSMutableDictionary",R,V_inputs
T@"NSMutableDictionary",R,V_outputs
initWithJSONDir:
initWithModelContainer:tensors:
initWithDictionary:tensors:quantization:optimizerParams:jsonDir:optimization:
validateNetworkTensors:
collapseNodes
validateNodeTensors
collapsePackUnpack:nodesToRemove:
removeView:nodesToRemove:
nodes
setNodes:
optimizerParams
_nodes
_optimizerParams
T@"NSArray",&,V_nodes
T@"NSArray",&,V_inputs
T@"NSArray",&,V_outputs
T@"MontrealNNModelOptimizerParam",R,V_optimizerParams
initWithName:index:dimension:
initWithName:index:dimension:weightData:
initWithName:index:dimension:weightValues:
initWithDictionary:quantization:jsonDir:
createflattenWeightsFile:
createflattenWeightsHierarchy:
createConvertArrayToData:quantization:
index
weightValues
weightData
_index
_weightValues
_weightData
T@"NSNumber",R,V_index
T@"NSArray",R,V_weightValues
T@"NSData",R,V_weightData
.cxx_construct
confusionMatrix
logLikelihood
totalLoss
B24@0:8@16
#16@0:8
@16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B16@0:8
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
v32@0:8@16@24
v24@0:8@16
v32@0:8@"NSMutableString"16@"MontrealLogIndent"24
@"NSDictionary"16@0:8
v24@0:8@"NSString"16
@24@0:8@16
v16@0:8
@"NSString"
@"NSNumber"
B32@0:8@16^B24
@40@0:8@16@24Q32
@24@0:8Q16
@"MontrealNNModelNetwork"
@"NSDictionary"
@56@0:8@16@24@32@40@48
@48@0:8@16@24@32@40
@32@0:8@16@24
{?=qqqqqqq[8q]Q[8[4i]][4[4i]][16i][16f][16^v][16^v]}24@0:8^v16
{?=qqqqqqq[8q]Q[8[4i]][4[4i]][16i][16f][16^v][16^v]}16@0:8
v720@0:8{?=qqqqqqq[8q]Q[8[4i]][4[4i]][16i][16f][16^v][16^v]}16
v20@0:8B16
@"NSArray"
@"MontrealNNModelQuantization"
{?="nodeType"q"engineType"q"inputDataType"q"outputDataType"q"weightDataType"q"kernelDataType"q"inputEncoding"q"activations"[8q]"weightAttributes"Q"inputDimensions"[8[4i]]"outputDimensions"[4[4i]]"integers"[16i]"floats"[16f]"weights"[16^v]"biases"[16^v]}
@40@0:8^{?=qqqqqqq[8q]Q[8[4i]][4[4i]][16i][16f][16^v][16^v]}16@24@32
@24@0:8^{_NSZone=}16
@"NSHashTable"
@48@0:8Q16f24f28@32@40
f16@0:8
@32@0:8^{?=qqqqqqq[8q]Q[8[4i]][4[4i]][16i][16f][16^v][16^v]}16Q24
@32@0:8^f16Q24
Q56@0:8@16@24Q32@40@48
v32@0:8@16q24
@"MontrealNNModelNode"
v24@0:8^{MontrealNeuralNetwork=}16
^{MontrealNeuralNetwork=}16@0:8
^v16@0:8
^{MontrealNeuralNetwork=}
@"NSMutableDictionary"
@32@0:8^v16@24
@64@0:8@16@24@32@40@48Q56
@"MontrealNNModelOptimizerParam"
@40@0:8@16@24@32
@"NSData"
{map<unsigned int, std::map<unsigned int, unsigned int>, std::less<unsigned int>, std::allocator<std::pair<const unsigned int, std::map<unsigned int, unsigned int>>>>="__tree_"{__tree<std::__value_type<unsigned int, std::map<unsigned int, unsigned int>>, std::__map_value_compare<unsigned int, std::__value_type<unsigned int, std::map<unsigned int, unsigned int>>, std::less<unsigned int>, true>, std::allocator<std::__value_type<unsigned int, std::map<unsigned int, unsigned int>>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<unsigned int, std::map<unsigned int, unsigned int>>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<unsigned int, std::__value_type<unsigned int, std::map<unsigned int, unsigned int>>, std::less<unsigned int>, true>>="__value_"Q}}}
