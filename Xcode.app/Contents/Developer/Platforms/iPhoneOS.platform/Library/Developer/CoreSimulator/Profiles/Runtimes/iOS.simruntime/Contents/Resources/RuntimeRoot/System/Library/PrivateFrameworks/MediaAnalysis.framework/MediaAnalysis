@(#)PROGRAM:MediaAnalysis  PROJECT:MediaAnalysis-1
fff>
mcpl)
333?
@CLST
N2ma15EncodeStatsAVE1E
B`e>;
$CV&
C2wACA
?16MAComputeRequest
>N2ma19SubtleMotionSegmentE
?33s?
@C22MAImageAnalysisRequest
NSt3__120__shared_ptr_emplaceI25VCPImageHumanPoseAnalyzerNS_9allocatorIS1_EEEE
fff?
N2ma17SlowMotionSegmentE
ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+%
14VCPProtoBounds
B>fff?
G!?=
Ga>R
=q=J
ff&?R
Q8?H
?N4dlib7array2dIhNS_33memory_manager_stateless_kernel_1IcEEEE
N4dlib10enumerableIhEE
N4dlib33memory_manager_stateless_kernel_1IhEE
?333?
?333?33
>N2ma12TrackSegmentE
N2ma11EncodeStatsE
?N2ma17DescriptorSegmentE
u?ff&?
>fff
'7NSt3__120__shared_ptr_emplaceI21VCPCNNEspressoContextNS_9allocatorIS1_EEEE
20MAImageComputeResult
<0L&=!
<yX(=4
<0L&=!
<yX(=
b=;p
Sc=;p
<5^:
e=X94
Y=X94</n#
=B`e<M
u`=e
w=B`e
N2ma18ObstructionSegmentE
MbP?
ffffff
N4dlib17sequence_kernel_2INS_21lbfgs_search_strategy11data_helperENS_33memory_manager_stateless_kernel_1IcEEEE
N4dlib10enumerableINS_21lbfgs_search_strategy11data_helperEEE
N4dlib7removerINS_21lbfgs_search_strategy11data_helperEEE
N4dlib33memory_manager_stateless_kernel_1IdEE
NSt3__110__function6__funcINS_6__bindIPFdRKN4dlib6matrixIdLl0ELl0ENS3_33memory_manager_stateless_kernel_1IcEENS3_16row_major_layoutEEEPfSB_SB_SB_bEJRKNS_12placeholders4__phILi1EEERSB_SJ_RA12_fRA126_fbEEENS_9allocatorISO_EEFdS8_EEE
NSt3__110__function6__baseIFdN4dlib6matrixIdLl0ELl0ENS2_33memory_manager_stateless_kernel_1IcEENS2_16row_major_layoutEEEEEE
NSt3__16__bindIPFdRKN4dlib6matrixIdLl0ELl0ENS1_33memory_manager_stateless_kernel_1IcEENS1_16row_major_layoutEEEPfS9_S9_S9_bEJRKNS_12placeholders4__phILi1EEERS9_SH_RA12_fRA126_fbEEE
NSt3__118__weak_result_typeIPFdRKN4dlib6matrixIdLl0ELl0ENS1_33memory_manager_stateless_kernel_1IcEENS1_16row_major_layoutEEEPfS9_S9_S9_bEEE
NSt3__110__function6__funcINS_6__bindIPFN4dlib6matrixIdLl0ELl0ENS3_33memory_manager_stateless_kernel_1IcEENS3_16row_major_layoutEEERKS8_PfSB_SB_SB_bEJRKNS_12placeholders4__phILi1EEERSB_SJ_RA12_fRA126_fbEEENS_9allocatorISO_EEFS8_S8_EEE
NSt3__110__function6__baseIFN4dlib6matrixIdLl0ELl0ENS2_33memory_manager_stateless_kernel_1IcEENS2_16row_major_layoutEEES7_EEE
NSt3__16__bindIPFN4dlib6matrixIdLl0ELl0ENS1_33memory_manager_stateless_kernel_1IcEENS1_16row_major_layoutEEERKS6_PfS9_S9_S9_bEJRKNS_12placeholders4__phILi1EEERS9_SH_RA12_fRA126_fbEEE
NSt3__118__weak_result_typeIPFN4dlib6matrixIdLl0ELl0ENS1_33memory_manager_stateless_kernel_1IcEENS1_16row_major_layoutEEERKS6_PfS9_S9_S9_bEEE
NSt3__117bad_function_callE
N4dlib11fatal_errorE
N4dlib5errorE
NSt3__110__function6__funcINS_6__bindIPFdRKN4dlib6matrixIdLl0ELl0ENS3_33memory_manager_stateless_kernel_1IcEENS3_16row_major_layoutEEEPfSB_SB_SB_SB_SB_SB_PiSB_SB_EJRKNS_12placeholders4__phILi1EEERSB_RA12_fSK_SK_SK_SK_SB_SC_SK_SK_EEENS_9allocatorISN_EEFdS8_EEE
NSt3__16__bindIPFdRKN4dlib6matrixIdLl0ELl0ENS1_33memory_manager_stateless_kernel_1IcEENS1_16row_major_layoutEEEPfS9_S9_S9_S9_S9_S9_PiS9_S9_EJRKNS_12placeholders4__phILi1EEERS9_RA12_fSI_SI_SI_SI_S9_SA_SI_SI_EEE
NSt3__118__weak_result_typeIPFdRKN4dlib6matrixIdLl0ELl0ENS1_33memory_manager_stateless_kernel_1IcEENS1_16row_major_layoutEEEPfS9_S9_S9_S9_S9_S9_PiS9_S9_EEE
NSt3__110__function6__funcINS_6__bindIPFN4dlib6matrixIdLl0ELl0ENS3_33memory_manager_stateless_kernel_1IcEENS3_16row_major_layoutEEERKS8_PfSB_SB_SB_SB_SB_SB_PiSB_SB_SB_EJRKNS_12placeholders4__phILi1EEERSB_RA12_fSK_SK_SK_SK_SB_SC_SK_SK_SK_EEENS_9allocatorISN_EEFS8_S8_EEE
NSt3__16__bindIPFN4dlib6matrixIdLl0ELl0ENS1_33memory_manager_stateless_kernel_1IcEENS1_16row_major_layoutEEERKS6_PfS9_S9_S9_S9_S9_S9_PiS9_S9_S9_EJRKNS_12placeholders4__phILi1EEERS9_RA12_fSI_SI_SI_SI_S9_SA_SI_SI_SI_EEE
NSt3__118__weak_result_typeIPFN4dlib6matrixIdLl0ELl0ENS1_33memory_manager_stateless_kernel_1IcEENS1_16row_major_layoutEEERKS6_PfS9_S9_S9_S9_S9_S9_PiS9_S9_S9_EEE
NSt3__110__function6__funcINS_6__bindIPFdRKN4dlib6matrixIdLl0ELl0ENS3_33memory_manager_stateless_kernel_1IcEENS3_16row_major_layoutEEEPfSB_EJRKNS_12placeholders4__phILi1EEERA126_fRA189_fEEENS_9allocatorISN_EEFdS8_EEE
NSt3__16__bindIPFdRKN4dlib6matrixIdLl0ELl0ENS1_33memory_manager_stateless_kernel_1IcEENS1_16row_major_layoutEEEPfS9_EJRKNS_12placeholders4__phILi1EEERA126_fRA189_fEEE
NSt3__118__weak_result_typeIPFdRKN4dlib6matrixIdLl0ELl0ENS1_33memory_manager_stateless_kernel_1IcEENS1_16row_major_layoutEEEPfS9_EEE
=AB/'
R[DmPJ>
@Z_g@
#=H!
@Aff
@333?
>43s?433?
333?43s?
@333?
?N2ma20SubjectMotionSegmentE
?28VCPProtoImageHumanPoseResult
@oDA
ffffff
333333
?N2ma14QualitySegmentE
N2ma19CameraMotionSegmentE
N2ma19MovingObjectSegmentE
?N2ma22InterestingnessSegmentE
16VCPProtoKeypoint
A22MAMovieAnalysisRequest
*>)\
?ff
N2ma12SceneSegmentE
333333
?lwh
N2ma15RotationSegmentE
N2ma15EncodeStatsAVE2E
N2ma13EncodeStatsHWE
BN2ma24FineSubjectMotionSegmentE
333?fff?ff
N2ma7SegmentE
N2ma13EncodeStatsSWE
Q9RI
Q9RI
7:RI
Q9RI
d*;4
>;_)K;
DX;B`e;
{r;l
k;B`e;
Q;_)K;
#;RI
7:RI
Q9RI
d*;4
7;_)K;
DX;B`e;
{r;o
{r;B`e;
DX;_)K;4
d*;RI
7:RI
Q9RI
7;_)K;
y;KY
3"<U
-<X94<
b<B`e<
4o<E
{r<!
ew<l
{r<E
h<B`e<e
#9<X94<
3"<RI
^;_)K;4
7:RI
Q9RI
k;KY
Q:RI
Q9RI
k:RI
DX;$
d*<4
?F<4
DX;4
Q:RI
>;B`e;'
#<X94<
z<KY
$=yX(=V
7=5^:=[
2D=]mE=
?F=]mE=
2D=\
<=5^:=
-2=2
+=yX(=
D<X94<
;B`e;
>;RI
{r<&
=R' =T
b=B`e=B>h=h
4o= Aq=
{r=F
{r= Aq=
(m=h
j=B>h=B`e=e
WJ=9
E6=|
%=R' =Qk
k:RI
7;B`e;
?$=V
b=B>h=D
s=Gry=
\~=n
\~=Gry=F
m=B>h=e
?$=v
;B`e;4
DX;'
3"<4
=R' =U
(=W[1=Z
B=_)K=a
S=d]\=
d=d]\=a
S=_)K=\
9=W[1=U
(=R' =P
j<<b
ew=I
{r<b
j<<>
ew<M
ew<>
=yX(=
A=;pN=
h=k+v=n
=k+v=
[=;pN=
5=yX(=
ew<b
7:RI
{r<M
7x=J{
/>:#
O/<N
=yX(=Y
U=B`e=
9#>/
$>0L&>
d*>1
'>0L&>/
Yu=B`e=
?F=Y
7=yX(=u
7;KY
=z6+=
/;=:
K=d]\=D
m=I.
V,>i
9>lx:>
<>6<=>
=>6<=>
;>lx:>l
u1>i
V,>
m=d]\=:
/;=z6+=
;_)K;
{r<)\
q,=6<==
Ga=F
s=J{
u >/
!N>`vO>
|P>`vO>
2D>7
~;>~
N=6<==
;_)K;o
<X94<
=z6+=6<==
ew=o
G!>ff&>
+>io0>F%5>
9>[B>>%uB>
qJ>_
QZ>?
+e>x
F>%uB>[B>>
9>F%5>io0>
+>ff&>
P=6<==z6+=u
/]<X94<r
Q9RI
{r<N
=yX(=
x=p_
/>aT
X>RI]>
Ga>f
n>W[q>}
=y>lxz>Zd{>
|>HP|>HP|>
|>Zd{>lxz>
s>W[q>
rh>f
Ga>RI]>P
/>o
/;=yX(=
y;RI
d*;KY
d*<b
ew=p_
2>Gr9>[
sW>v
8g>1
|>n4
3b>v
?>Gr9>
%>d;
Ga=:
d*<o
?F=d]\=F
8V>?
c>gDi>
t>5^z>$
>5^z>
4o>gDi>
s=d]\=
<;p
:_)K;RI
=yX(=
m=J{
P>>yX>
_>>yX>
kI>n
v>=yX(=
;_)K;
T<KY
L=B`e=I.
..>}
6>I.?>
h>iop>~
x>iop>
DX>r
G>I.?>}
c>]
=B`e=
;B`e;X9
c<)\
>B>(>W[1>lx:>
C>lx:>W[1>B>(>-!
;B`e;o
5=;pN=
>R' >z
!=>]
|P>]
g3>z
)>R' >b
xi=;pN=
{r;'
>R' >
m4>m
ZS>-
-r>HP|>
>HP|>
J*>R' >
?F<N
h=J{
H?>:#J>+
U>:#J>
m4>z
)>-!
=R' =
sW=k+v=(
>B>(>
g3>m
>>:#J>=
U>w-a>
l>w-a>=
U>:#J>m
g3>B>(>
=k+v=
:=R' =
#<B`
d*;u
Sc=n
%>W[1>
U>w-a>
\m>~
\m>w-a>+
!=>W[1>
Jj<1
d*;RI
=W[1=
..>lx:>]
ZS>]
F>lx:>
AO=W[1=
5<HP
7;RI
|P>-
:_)K;|
?$=\
Sc=o
/>>y
2>I.?>_
6Z>_
L>I.?>
%>>y
/>n4
Sc=\
;_)K;4
+=_)K=
(m=p
q,>#
q?_
q?h
q,>d;
(m=_)K=V
ew=r
\m>HP|>
c?r
>HP|>
%>>y
ew=a
2=tF
:B`e;
9=d]\=I
=d]\=Z
9=Qk
u`<RI
;B`e;
=R' =
d=&S
:p>7
R&?t
@=R' =
l=q=
~*>Gr9>p
H>>yX>
f%?=
+?-C,?
,?-C,?
h>>yX>p
H>Gr9>
{r<U
:0>[
_>iop>I
;.?{
;.?$
@"?$
>iop>
G!><
;X94<
fU=$
>ff&>
y'?u
c,?r
0?EG2?}
7?^K8?Y
8?^K8?
+5?}
3?EG2?
c,?u
y'?j
8V>9
5>ff&>
fU=|
<X94<B`
?n4 ?
,?I./?
1?I./?D
#?n4 ?
E6=tF
u >io0>
t>J{
$?B>(?
1?X94?
6?X94?
+?B>(?
@>io0>
@=B>h=
$>F%5>
sW>gDi>
V?E
%?gD)?
,?R'0?
S3?0L6?
>?R'@?
8E?a
B?R'@?_
9?0L6?
S3?R'0?
,?gD)?"
V?0
~{>gDi>
F>F%5>/
=B>h=
B<HP
41?4
=?io@?
H?q=J?
~K?(~L?6<M?H
M?6<M?(~L?
~K?q=J?U
B?io@?d
41?h
4o>v
WJ=F
s=Nb
->[B>>r
4!?"
1?]m5?
I<?Di??aTB?
O?2UP?
aQ?2UP?
E?aTB?Di??
8?]m5?
3b>r
O>[B>>V
=yX(=
N=Gry=*
0>%uB>
8g>5^z>
?n4 ?
$?gD)?h
F?GrI?
HN?2UP?
&R?F
V?p_W?
W?p_W?
&R?2UP?
K?GrI?}
-?gD)?
$?n4 ?
>5^z>
T>%uB>|
=Gry=
N=yX(=
Q<KY
S#>4
#?B>(?
41?]m5?c
A?o
X?GrY?
Z??W[?
[?h"\?h"\?
[??W[?
Z?GrY?~
\=?c
9?]m5?
,?B>(?
S#><
ZS=V
Y<RI
sW=n
qJ>RI]>
+?R'0?4
D?yXH?q
Q?tFT?}
Z?HP\?
_?R'`?
h`?R'`?$
]?HP\?h
V?tFT?n
K?yXH?
4?R'0?
p>RI]>
qJ>~
sW=2
<RI
~;>_
|@?o
D?yXH?
UO?A
R?]mU?~
c?=,d?Ttd?Ttd?=,d?
X?]mU?A
K?yXH?o
Ga>_
~;>
y'?D
1?0L6?
:?Di??
UO?X
.^?Nb`?aTb?
d?]me?
eg?+
Dh?+
f?]me?
d?aTb?Nb`?
UO?q
C?Di??
:?0L6?
V,>,
<B`e<
b='1
rh>[
*?I./?X94?
=?aTB?}
U?gDY?
I\?gDY?
F?aTB?d
9?X94?I./?u
rh>O
/>G
<B`e<
=5^:=B`e=q=
k>n4
;?io@?
E?GrI?
Q?]mU?
&b?O
(l?mVm??5n?
n??5n?mVm?
X?]mU?n
M?GrI?
E?io@?
=B`e=5^:=
<=B>h=
q?aT
:P?tFT?~
m?-!o?
Np?-!o?
X?tFT?
a!>r
=B>h=[
4o<z6
9#>X
\>W[q>
f%?
;?R'@?
g?U0j?
n?2Up?N
q?2Up?
l?U0j?
E?R'@?C
>W[q>?
(m=M
G!?=
,?EG2?
K?2UP?O
\?Nb`?}
?t?]mu?KYv?
v?KYv?]mu?
?t?<
c?Nb`?$
T?2UP?
7?EG2?$
G!?Zd
{r<V}
>0L&>l
;.?}
&R?+
^?aTb?
t?KYv?
w?>yx?
y?,ey?,ey?
y?>yx?
w?KYv?
e?aTb?
J9?}
9>0L&>tF
4o=\
B=Qk
2D= Aq=
'>lx:>
!N>x
8E?q=J?
X?HP\?
m?2Up?<
v?'1x?
ky?'1x?
r?2Up?
H`?HP\?~
O?q=J?
+5?{
!N>lx:>
= Aq=
t<RI
=]mE=
;>`vO>x
~K?2UP?
U?GrY?
a?]me?5
(l?-!o?N
?t?KYv?'1x?^
{?(~|?
|?(~|?
y?'1x?KYv?
?t?N
q?-!o?
(l?5
h?]me?
]?GrY?
U?2UP?
=y>x
d>`vO>
{r=]mE=
u<RI
ew<3
?F=F
+e>lxz>B>
eG?(~L?
aQ?4
j?mVm?
Np?S
s?]mu?
/|?q
w?]mu?S
Np?mVm?
aQ?(~L?
>lxz>
^)>=
?F=RI
)>6<=>
e>Zd{>9
R&?-C,?
$H?6<M?
V??W[?$
eg?c
j??5n?
s?KYv?>yx?
Wz?>yx?KYv?
4q??5n?c
_??W[?
&R?6<M?
2?-C,?
A ?:#
>Zd{>
4Q>6<=>
Yu=*
2?^K8?
R?p_W?
[?R'`?=,d?+
z?(~|?H
}?(~|?
g?=,d?R'`?
[?p_W?
=?^K8?\
d*>+
f>HP|>L7
W?h"\?
h`?Ttd?
Dh?6
>w?,ey?
C{?,ey?
Dh?Ttd?
h`?h"\?
!>?Y
>HP|>B
 <X9
f>HP|>L7
W?h"\?
h`?Ttd?
Dh?6
>w?,ey?
C{?,ey?
Dh?Ttd?
h`?h"\?
!>?Y
>HP|>B
 <X9
Yu=*
2?^K8?
R?p_W?
[?R'`?=,d?+
z?(~|?H
}?(~|?
g?=,d?R'`?
[?p_W?
=?^K8?\
d*>+
)>6<=>
e>Zd{>9
R&?-C,?
$H?6<M?
V??W[?$
eg?c
j??5n?
s?KYv?>yx?
Wz?>yx?KYv?
4q??5n?c
_??W[?
&R?6<M?
2?-C,?
A ?:#
>Zd{>
4Q>6<=>
ew<3
?F=F
+e>lxz>B>
eG?(~L?
aQ?4
j?mVm?
Np?S
s?]mu?
/|?q
w?]mu?S
Np?mVm?
aQ?(~L?
>lxz>
^)>=
?F=RI
=]mE=
;>`vO>x
~K?2UP?
U?GrY?
a?]me?5
(l?-!o?N
?t?KYv?'1x?^
{?(~|?
|?(~|?
y?'1x?KYv?
?t?N
q?-!o?
(l?5
h?]me?
]?GrY?
U?2UP?
=y>x
d>`vO>
{r=]mE=
u<RI
2D= Aq=
'>lx:>
!N>x
8E?q=J?
X?HP\?
m?2Up?<
v?'1x?
ky?'1x?
r?2Up?
H`?HP\?~
O?q=J?
+5?{
!N>lx:>
= Aq=
t<RI
{r<V}
>0L&>l
;.?}
&R?+
^?aTb?
t?KYv?
w?>yx?
y?,ey?,ey?
y?>yx?
w?KYv?
e?aTb?
J9?}
9>0L&>tF
4o=\
B=Qk
(m=M
G!?=
,?EG2?
K?2UP?O
\?Nb`?}
?t?]mu?KYv?
v?KYv?]mu?
?t?<
c?Nb`?$
T?2UP?
7?EG2?$
G!?Zd
4o<z6
9#>X
\>W[q>
f%?
;?R'@?
g?U0j?
n?2Up?N
q?2Up?
l?U0j?
E?R'@?C
>W[q>?
<=B>h=
q?aT
:P?tFT?~
m?-!o?
Np?-!o?
X?tFT?
a!>r
=B>h=[
=5^:=B`e=q=
k>n4
;?io@?
E?GrI?
Q?]mU?
&b?O
(l?mVm??5n?
n??5n?mVm?
X?]mU?n
M?GrI?
E?io@?
=B`e=5^:=
<B`e<
b='1
rh>[
*?I./?X94?
=?aTB?}
U?gDY?
I\?gDY?
F?aTB?d
9?X94?I./?u
rh>O
/>G
<B`e<
y'?D
1?0L6?
:?Di??
UO?X
.^?Nb`?aTb?
d?]me?
eg?+
Dh?+
f?]me?
d?aTb?Nb`?
UO?q
C?Di??
:?0L6?
V,>,
~;>_
|@?o
D?yXH?
UO?A
R?]mU?~
c?=,d?Ttd?Ttd?=,d?
X?]mU?A
K?yXH?o
Ga>_
~;>
Y<RI
sW=n
qJ>RI]>
+?R'0?4
D?yXH?q
Q?tFT?}
Z?HP\?
_?R'`?
h`?R'`?$
]?HP\?h
V?tFT?n
K?yXH?
4?R'0?
p>RI]>
qJ>~
sW=2
<RI
S#>4
#?B>(?
41?]m5?c
A?o
X?GrY?
Z??W[?
[?h"\?h"\?
[??W[?
Z?GrY?~
\=?c
9?]m5?
,?B>(?
S#><
ZS=V
=yX(=
N=Gry=*
0>%uB>
8g>5^z>
?n4 ?
$?gD)?h
F?GrI?
HN?2UP?
&R?F
V?p_W?
W?p_W?
&R?2UP?
K?GrI?}
-?gD)?
$?n4 ?
>5^z>
T>%uB>|
=Gry=
N=yX(=
Q<KY
WJ=F
s=Nb
->[B>>r
4!?"
1?]m5?
I<?Di??aTB?
O?2UP?
aQ?2UP?
E?aTB?Di??
8?]m5?
3b>r
O>[B>>V
41?4
=?io@?
H?q=J?
~K?(~L?6<M?H
M?6<M?(~L?
~K?q=J?U
B?io@?d
41?h
4o>v
@=B>h=
$>F%5>
sW>gDi>
V?E
%?gD)?
,?R'0?
S3?0L6?
>?R'@?
8E?a
B?R'@?_
9?0L6?
S3?R'0?
,?gD)?"
V?0
~{>gDi>
F>F%5>/
=B>h=
B<HP
u >io0>
t>J{
$?B>(?
1?X94?
6?X94?
+?B>(?
@>io0>
?n4 ?
,?I./?
1?I./?D
#?n4 ?
E6=tF
;X94<
fU=$
>ff&>
y'?u
c,?r
0?EG2?}
7?^K8?Y
8?^K8?
+5?}
3?EG2?
c,?u
y'?j
8V>9
5>ff&>
fU=|
<X94<B`
:0>[
_>iop>I
;.?{
;.?$
@"?$
>iop>
G!><
l=q=
~*>Gr9>p
H>>yX>
f%?=
+?-C,?
,?-C,?
h>>yX>p
H>Gr9>
{r<U
=R' =
d=&S
:p>7
R&?t
@=R' =
:B`e;
9=d]\=I
=d]\=Z
9=Qk
u`<RI
;B`e;
ew=r
\m>HP|>
c?r
>HP|>
%>>y
ew=a
2=tF
+=_)K=
(m=p
q,>#
q?_
q?h
q,>d;
(m=_)K=V
:_)K;|
?$=\
Sc=o
/>>y
2>I.?>_
6Z>_
L>I.?>
%>>y
/>n4
Sc=\
;_)K;4
|P>-
=W[1=
..>lx:>]
ZS>]
F>lx:>
AO=W[1=
5<HP
7;RI
d*;u
Sc=n
%>W[1>
U>w-a>
\m>~
\m>w-a>+
!=>W[1>
Jj<1
d*;RI
=R' =
sW=k+v=(
>B>(>
g3>m
>>:#J>=
U>w-a>
l>w-a>=
U>:#J>m
g3>B>(>
=k+v=
:=R' =
#<B`
h=J{
H?>:#J>+
U>:#J>
m4>z
)>-!
>R' >
m4>m
ZS>-
-r>HP|>
>HP|>
J*>R' >
?F<N
5=;pN=
>R' >z
!=>]
|P>]
g3>z
)>R' >b
xi=;pN=
{r;'
;B`e;X9
c<)\
>B>(>W[1>lx:>
C>lx:>W[1>B>(>-!
;B`e;o
T<KY
L=B`e=I.
..>}
6>I.?>
h>iop>~
x>iop>
DX>r
G>I.?>}
c>]
=B`e=
:_)K;RI
=yX(=
m=J{
P>>yX>
_>>yX>
kI>n
v>=yX(=
;_)K;
?F=d]\=F
8V>?
c>gDi>
t>5^z>$
>5^z>
4o>gDi>
s=d]\=
<;p
d*;KY
d*<b
ew=p_
2>Gr9>[
sW>v
8g>1
|>n4
3b>v
?>Gr9>
%>d;
Ga=:
d*<o
Q9RI
{r<N
=yX(=
x=p_
/>aT
X>RI]>
Ga>f
n>W[q>}
=y>lxz>Zd{>
|>HP|>HP|>
|>Zd{>lxz>
s>W[q>
rh>f
Ga>RI]>P
/>o
/;=yX(=
y;RI
<X94<
=z6+=6<==
ew=o
G!>ff&>
+>io0>F%5>
9>[B>>%uB>
qJ>_
QZ>?
+e>x
F>%uB>[B>>
9>F%5>io0>
+>ff&>
P=6<==z6+=u
/]<X94<r
;_)K;
{r<)\
q,=6<==
Ga=F
s=J{
u >/
!N>`vO>
|P>`vO>
2D>7
~;>~
N=6<==
;_)K;o
7;KY
=z6+=
/;=:
K=d]\=D
m=I.
V,>i
9>lx:>
<>6<=>
=>6<=>
;>lx:>l
u1>i
V,>
m=d]\=:
/;=z6+=
=yX(=Y
U=B`e=
9#>/
$>0L&>
d*>1
'>0L&>/
Yu=B`e=
?F=Y
7=yX(=u
{r<M
7x=J{
/>:#
O/<N
=yX(=
A=;pN=
h=k+v=n
=k+v=
[=;pN=
5=yX(=
ew<b
7:RI
j<<>
ew<M
ew<>
j<<b
ew=I
{r<b
DX;'
3"<4
=R' =U
(=W[1=Z
B=_)K=a
S=d]\=
d=d]\=a
S=_)K=\
9=W[1=U
(=R' =P
7;B`e;
?$=V
b=B>h=D
s=Gry=
\~=n
\~=Gry=F
m=B>h=e
?$=v
;B`e;4
{r<&
=R' =T
b=B`e=B>h=h
4o= Aq=
{r=F
{r= Aq=
(m=h
j=B>h=B`e=e
WJ=9
E6=|
%=R' =Qk
k:RI
>;B`e;'
#<X94<
z<KY
$=yX(=V
7=5^:=[
2D=]mE=
?F=]mE=
2D=\
<=5^:=
-2=2
+=yX(=
D<X94<
;B`e;
>;RI
DX;$
d*<4
?F<4
DX;4
Q:RI
Q9RI
k:RI
Q9RI
k;KY
Q:RI
Q9RI
7;_)K;
y;KY
3"<U
-<X94<
b<B`e<
4o<E
{r<!
ew<l
{r<E
h<B`e<e
#9<X94<
3"<RI
^;_)K;4
7:RI
Q9RI
d*;4
7;_)K;
DX;B`e;
{r;o
{r;B`e;
DX;_)K;4
d*;RI
7:RI
Q9RI
d*;4
>;_)K;
DX;B`e;
{r;l
k;B`e;
Q;_)K;
#;RI
7:RI
Q9RI
7:RI
Q9RI
B>q=J?
~|zxvuusqpnmkjiggfecba`_^]]\[ZYXWVUTTSRQQPONNMMLKKJIIHGGGFFEDDCCBBBAA@@??>>===<<;;:::999888776666555444333322211110000////.....----,,,,+++++*****)))))((((('''''''&&&&&&%%%%%%$$$$$$$########""""""!!!!!!!!!        X|E
+>>%I
%@ %@
timeRange
confidence
B8@?0
variation = %6.2f
creationDate
uuid
mediaanalysisd
private/com.apple.mediaanalysisd/caches/vision
verifiedType = %@ OR verifiedType = %@
B24@?0@"PHPerson"8@"NSDictionary"16
asset in (%@)
any person.personUUID in %@
total-allowed
ANY detectedFaces.uuid IN %@
PVPersonClusterManager
Unable to find class %s
v8@?0
com.apple.mediaanalysis.reachability
Not c
None
TransientConnection
Reachable
ConnectionRequired
ConnectionOnTraffic
InterventionRequired
ConnectionOnDemand
IsLocalAddress
IsDirect
IsWWAN
qualityScore
distanceToPreviousScene
flickerScore
sceneprintDistanceToPreviousScene
SceneResults
QualityResults
CameraMotionResults
SubjectMotionResults
FineSubjectMotionResults
SubtleMotionResults
TrackSegments
OrientationResults
IrisRecommendResults
IrisSharpnessResults
PreEncodeResults
MovingObjectsResults
FeatureVectorResults
SceneprintResults
ObstructionResults
InterestingnessResults
flags
quality
attributes
start
duration
distance
sceneprintDistance
featureVector
Data
orientation
objectBounds
slowMoFlicker
sceneprint
index
junk
summaryTimerange
duplicate
MetaFocusResults
MetaMotionResults
MetaMotionProcessedResults
q24@?0@"PHAssetResource"8@"PHAssetResource"16
B16@?0@"PHAssetResource"8
mammal
bird
people
adult
animal
stuffed_animals
fire
fireplace
embers
flame
beach
liquid
ocean
lake
creek
river
snow
jacuzzi
pool
grass
plant
coral_reef
foliage
tree
grill
waterways
shore
waterfall
thunderstorm
manhole
aurora
light
spotlight
smoking_item
flag
flagpole
underwater
candle
kettle
teapot
storm
tornado
lightning
blossom
surfing
pyrotechnics
blizzard
fountain
billboards
curtain
lamp
drinking_glass
fondue
blender
storefront
garden
shrub
firecracker
bubble_soap
watersport
haze
volcano
aquarium
fishtank
flower
seaweed
jellyfish
fish
flashlight
bonfire
smoking
lakeshore
sparkler
sparkling_wine
shower
geyser
actionScore
v32@?0@"NSNumber"8@"VCPFace"16^B24
v32@?0@"NSNumber"8@"VCPVideoObjectTracker"16^B24
q24@?0@"VCPFace"8@"VCPFace"16
/tmp/
v32@?0@"NSNumber"8@"VNFaceprint"16^B24
v32@?0@"NSNumber"8@"NSNumber"16^B24
Home face identification task cancelled
No face present in face crop
Photos identity model not present
%@ | %@
{{%.*g, %.*g}, {%.*g, %.*g}}
timestamp
qualityScoreForLivePhoto
visualPleasingScore
overallFaceQualityScore
exposureScore
penaltyScore
textureScore
sharpness
faceResults
globalQualityScore
contentScore
expressionChangeScore
vector
v24@?0Q8^B16
v32@?0@"NSNumber"8Q16^B24
VCPClusteringStatusIsClustering
VCPClusteringStatusClusterRebuildRequired
VCPClusteringStatusEligibleFacesCount
VCPClusteringStatusPendingFacesCount
VCPSuggestionUpdateStarted
VCPSuggestionUpdateFinished
VCPSuggestionUpdateCancelled
com.apple.mediaanalysisd.clusterer.processing
com.apple.mediaanalysis.scheduleclustering
VCPFaceProcessingClusterFacesCoreAnalyticsCollection
v24@?0@"NSString"8^B16
com.apple.mediaanalysisd.photos.faceclustering
ClusteringSequence
FacesAddToClustering
FacesRemoveFromClustering
FacesInClusterBeforeClustering
ClusteringInterval
TotalAssetCount
ProcessingQoS
com.apple.mediaanalysisd.optional_clustering
com.apple.mediaanalysisd.forced_clustering
Operation cancelled
v32@?0@"NSNumber"8@"NSOrderedSet"16^B24
VCPVisionFgMapping_Prepare
v32@?0@"NSCountedSet"8Q16^B24
q24@?0@"NSCountedSet"8@"NSCountedSet"16
v24@?0@"NSNumber"8^B16
VCPClusterCompareTimestamp
VCPClusterer: Failed to get face CSNs from cluster cache, which should not be used
PVErrorInvalidClusterCacheFile - %@
VCPClusterer: Failed to get Vision cluster state - %@
VisionClusterState
clusteringType
threshold
VCPClusterer: Failed to archive cluster snapshot
VCPClusterer: Failed to rename file from '%@' to '%@'. Error = %d
VCPClusterer: Failed to write cluster snapshot to file '%@'
missing parameter clusterState
VCPClusterer: Cluster snapshot file '%s' is too small
VCPClusterer: Invalid magic number found in '%s'
VCPClusterer: Invalid version in '%s', %d != %d
VCPClusterer: Failed to read MD5 from header of '%s'
VCPClusterer: Failed to compute MD5 of '%s'
VCPClusterer: Failed MD5 check for '%s'
VCPClusterer: Failed to read size of vision cluster state blob from '%s'
VCPClusterer: Failed to read vision cluster state blob from '%s'
VCPClusterer: Failed to open cluster cache file '%s'
cmap
CVMLClusterState
CVMLClusteringAlgorithm_Greedy
VCPClusterer: Failed to restore cluster cache
VCPClusterer: Failed to restore cluster cache std::exception %s
VCPClusterer: Failed to restore cluster cache due to device ran out of memory
VCPClusterer needs a full sync
missing updateHandler
VCPClusterer is not ready
VCPClusterer: Failed to get suggestions from Vision framework %@
v32@?0@"VNCluster"8Q16^B24
v32@?0@"NSSet"8Q16^B24
q24@?0@"NSMutableSet"8@"NSMutableSet"16
VCPClustererBringUpState
clustererState.plist
need full sync
need to compare clusters
need to reset cluster cache
need to reset library clusters
need update
ready
clustering
have unsaved cluster cache
saving cluster cache
have new cluster cache
unknown (error)
AlgoFaceClusterCache.data
temp
Error: failed to processImage
highlightScore
@"VCPMADVIRemoveBackgroundResource"8@?0
VCPMADVIRemoveBackgroundTask
Image loading failed
Failed to obtain image from Vision
Multiple cadence options specified
%@ value must be NSNumber
%@ value must be poisitive
%@ is not supported
v32@?0@"NSString"8@16^B24
v24@?0@"NSDictionary"8@"NSError"16
Full analysis asset processing task cancelled
[%@] Failed to analyze on-demand
VCPFullAnalysisAssetProcessingTask processing failed
AllowOnDemand
InProcess
SceneprintRevision
com.apple.mediaanalysis.service.management
com.apple.mediaanalysis.service.handler
MediaAnalysisService
Error issuing sandbox extension
v16@?0d8
[MediaAnalysis] Error connecting to background analysis service
v16@?0@"NSError"8
Assets from multiple libraries not supported
v24@?0@"NSString"8@"NSError"16
PersonProcessingDeletePersons
PersonProcessingClusterFaces
PersonProcessingIncrementalFaceClustering
PersonProcessingRunBuildPersons
PersonProcessingIncrementalPersonBuilding
PersonProcessingRunPromotePersons
PersonProcessingRebuildFaceIDModel
PersonProcessingClassifyContactPictures
faceCSN
faceIdentifier
personIdentifier
personFaceCount
confirmed
status
requestAdvancedStatus
advancedStatus
PLPhotoAnalysisVisionServiceFaceReclusteringThreshold
PLPhotoAnalysisVisionServiceFaceReclusteringDeletePersons
PLPhotoAnalysisVisionServiceFaceReclusteringShouldRecluster
personLocalIdentifier
v24@?0@"NSArray"8@"NSError"16
v20@?0B8@"NSError"12
model_info.json
net_file
revision
config
loadModel
res_256x160
res_160x256
cnn_human_pose_lite_v2.espresso.net
input
before filter: frame(%d): time_stamp=%f, ave_motion=(%f,%f)
frame(%d): time_stamp=%f, ave_motion=(%f,%f), acc_var=(%f, %f), motion_chg=(%f, %f)
q24@?0@8@16
VCPMADImageSafetyClassificationResource
@"VCPMADImageSafetyClassificationResource"8@?0
[ImageSafety] Before decode
Image pre-processing failed
[ImageSafety] Before inference
CVNLPCommSafetyHandler unavailable
[ImageSafety] After inference
[VCPPhotosFace] Missing faceObservation and humanObservation
@"VNRequest"16@?0#8
@"VNObservation"24@?0@"NSUUID"8@"VNRequest"16
[VCPPhotosFace] Invalid faceprint and torsoprint
[VCPPhotosFace] Unable to serialize faceTorsoprint - %@
[VCPPhotosFace] Unable to determine normalized face bounding { { %f, %f } { %f, %f } }
%@ (%@), %@ (v%d) (%.2f, %.2f, %.2f) (%.2f, %.2f, %.2f, %.2f) quality: %.2f
Human
bounds
cnn_facepose.espresso.net
VCPPoseEspresso
@"VCPCNNModelEspresso"8@?0
quality_head.espresso.net
output
ImageAnalysis
MovieAnalysis
MAComputeRequestClass
q24@?0@"VNClassificationObservation"8@"VNClassificationObservation"16
q24@?0@"VCPClassification"8@"VCPClassification"16
featureBlob
checksum
data
SceneprintHyperplaneLSH, 
NeuralHyperplaneLSH, 
Unknown
com.apple.mediaanalysisd.timer
rawTime
homography
keypoints
v32@?0@"PHFace"8Q16^B24
VNFaceGazeDirectionUnknown
VNFaceGazeDirectionCamera
VNFaceGazeDirectionAnotherFace
VNFaceGazeDirectionCommonLocation
VNFaceGazeDirectionSomewhereElse
VNFaceGazeDirectionDifficultToSay
Error VNFaceGazeDirection: %lu
PHFaceGazeTypeCannotInferGaze
PHFaceGazeTypeLookingAtCamera
PHFaceGazeTypeLookingAtAnotherFace
PHFaceGazeTypeLookingAtCommonLocation
PHFaceGazeTypeOther
Error PHFaceGazeType: %d
sceneprintBlob
absoluteScore
relativeScore
humanScore
faceId
Action
NumOfValidFrames
ActionScore
seg %d: [%d, %d], sceneCut=%d
prev(%d) [%d, %d][%6.1f, %6.1f] qs = %6.2f, curr(%d) [%d, %d] [%6.1f, %6.1f]qs = %6.2f:
dist({%d %d}, {%d %d}) = %6.2f, th = %6.2f
prev: type = %d, fast = %d, gmv_sum {%6.1f, %6.1f}, merge = %d, split = 0
curr: type = %d, fast = %d, gmv_sum {%6.1f, %6.1f}, merge = %d, split = 0
segments
cnn_content.dat
v16@?0^{opaqueCMSampleBuffer=}8
MediaAnalysis
SceneNetV5
eyeExpression
mouthExpression
position
isCloseup
faceQuality
VCPMADVIResource
curationScore
com.apple.MediaAnalysis
com.apple.mediaanalysisd
forceCPU
forceNNGraph
sharedContext
shared 
VCPWallpaperAnalyzer.sharedModelPool
@"VCPObjectPool"8@?0
quantized_9hy8wvx5wz_iteration_47_model.espresso.net
quantized_5c7q2hh2zk_iteration_35_model.espresso.net
height
width
com.apple.mediaanalysis.VCPClientDatabaseManager
/tmp/com.apple.mediaanalysisd/VideoCaptionEncoderTest/
/tmp/com.apple.mediaanalysisd/VideoCaptionDecoderTest/
/tmp/com.apple.mediaanalysisd/ImageCaptionModelTest/
com.apple.MobileAsset.VCPMobileAssets
v16@?0q8
Model
AssetName
Version
VideoCaptionEncoder
v16@?0@"MAProgressNotification"8
v24@?0q8@"NSError"16
ClonedVideoCaptionDecoder
ClonedVideoCaptionEncoder
com.apple.mediaanalysis.VCPVideoTrackSyncDecoder
classification
[VCPVNImageprintWrapper] Invalid imageprint type %lu
Cannot calculate distance - missing the other imageprint
Cannot calculate distance - mismatched imageprint type (%lu vs %lu)
Cannot calculate distance - mismatched versions (%d vs %d)
Cannot calculate distance - unarchive self.data - %@
Cannot calculate distance - unarchive theOtherImageprint.data - %@
torso-only
face-only
Cannot get distance between faceprints. Distance function returns nil
type: %lu, version: %d, and data[length:%lu]: <%p>
v32@?0@"NSNumber"8@"NSArray"16^B24
com.apple.mediaanalysis.VCPSharedInstanceManager
VCPAnalysisProgressQueryScanPhotoLibraryFetch
faceAdjustmentVersion != nil
mediaAnalysisAttributes.characterRecognitionAttributes.algorithmVersion >= %d
mediaAnalysisAttributes.visualSearchAttributes.algorithmVersion >= %d
additionalAttributes.sceneAnalysisVersion >= %d &&  additionalAttributes.sceneAnalysisVersion != %d
VCPAnalysisProgressQueryExpressPathFetchTotalCount
VCPAnalysisProgressQueryExpressPathFetchProcessedCount
VCPAnalysisProgressQueryProgressDetail
VCPAnalysisProgressQueryProgress
VCPAnalysisProgressQueryCachedFaceAnalysisProgress
SalientRegions
bound
plistRepresentation
q24@?0@"VCPSaliencyRegion"8@"VCPSaliencyRegion"16
hand_keypoint_detector_acc.espresso.net
cnn_moflow.espresso.net
landscape_1024x448
square_320x320
input_image_1
input_image_2
zeros
landscape_384x256
landscape_448x320
landscape_640x512
landscape_896x640
portrait_256x384
portrait_320x448
portrait_512x640
portrait_640x896
square_256x256
square_512x512
square_640x640
VCPMoflowEspresso
com.apple.mediaanalysis.VCPVideoProcessorSession
Video processing requests must have completion handler
Specified request already active; cannot add
Failed to create request with specified configuration
Specified request not found; cannot remove
Sample buffer does not contain video frame
Sample buffer must contain uncompressed video
faceSharpness
vnpersonsmodel.bin
vnpetsmodel.bin
Point0
Point1
Radius
Theta
Length
Hand_waving
Hand_clapping
Dancing
Walking
Running
Jumping
cnn_human_action.espresso.net
salientRegion
salientScore
q24@?0@"NSDictionary"8@"NSDictionary"16
/var/mobile/Media/MediaAnalysis
private/com.apple.mediaanalysisd/MediaAnalysis
mediaanalysis.db
kindSubtype != %d
kind == %d
PhotoAnalysisServicePreferences.plist
faceWorkerState.plist
(faceAlgorithmVersion = %d) AND (clusterSequenceNumber = 0) AND (((hidden = 0) AND (manual = 0) AND ((trainingType = %d) OR (trainingType = nil))) OR ((trainingType = %d) OR (trainingType = %d) OR (trainingType = %d)))
SyndPL
Tracking
TrackingScore
AveStats
Failed to parse AVE statistics frame attachment; re-generating statistics
summaryIsTrimmed
livePhoto
movie
AutoplayScore
MotionScore
SubjectScore
ExposureChange
landscape_1024x432
privECMVct
privEMBVct
privDFArray
privET
privImgG
privTZF
privAFS
privAFSt
privFM
relSampleTime
trajectoryHomography
presentingTimestampInNanos
originalPresentingTimestampInNanos
sequenceAdjusterRecipe
sequenceAdjusterDisplacement
interpolatedFrame
LivePhotoMetadataSetupDataVersion
FrameworkVersions
CMCaptureCore
Error: failed to analyze motion flow
mediaAnalysisVersionState.plist
VCPFaceProcessingVersionManager-%@
@"VCPFaceProcessingVersionManager"8@?0
FaceProcessingInternalVersion
Reset none
Reset AnalysisStates
Reset Clustering
shotType
basic_string
humanPoseResults
version
AutoLoop
Bounce
LongExposure
Stabilize
NormStabilizeInstructions
MinVersion
Params
loopFlavor
loopEnergy
outputFrameDur
stabCropRect
stabilizeResult
Width
Height
frameInstructions
face_model_tensor.dat
face_model_landmark_coordinates.dat
face_model_boundary.dat
com.apple.mediaanalysisd.VCPFaceShapeUpdate
Error detected at line 
Error detected in file 
Submodules/dlib/dlib/optimization/optimization.h
Error detected in function 
double dlib::find_min_box_constrained(search_strategy_type, stop_strategy_type, const funct &, const funct_der &, T &, const matrix_exp<EXP1> &, const matrix_exp<EXP2> &) [search_strategy_type = dlib::lbfgs_search_strategy, stop_strategy_type = dlib::objective_delta_stop_strategy, funct = std::function<double (dlib::matrix<double, 0, 0>)>, funct_der = std::function<dlib::matrix<double, 0, 0> (dlib::matrix<double, 0, 0>)>, T = dlib::matrix<double, 51, 1>, EXP1 = dlib::matrix_op<dlib::op_uniform_matrix_3<double>>, EXP2 = dlib::matrix_op<dlib::op_uniform_matrix_3<double>>]
Failing expression was 
is_col_vector(x) && is_col_vector(x_lower) && is_col_vector(x_upper) && x.size() == x_lower.size() && x.size() == x_upper.size()
double find_min_box_constrained()
 The inputs to this function must be equal length column vectors.
 is_col_vector(x):       
 is_col_vector(x_upper): 
 x.size():               
 x_lower.size():         
 x_upper.size():         
The objective function generated non-finite outputs
 ************************** FATAL ERROR DETECTED ************************** 
 ************************** FATAL ERROR DETECTED ************************** 
 ************************** FATAL ERROR DETECTED ************************** 
Two fatal errors have been detected, the first was inappropriately ignored. 
To prevent further fatal errors from being ignored this application will be 
terminated immediately and you should go fix this buggy program.
The error message from this fatal error was:
**************************** FATAL ERROR DETECTED ****************************
******************************************************************************
EPORT_IN_USE
ETIMEOUT
ECONNECTION
ELISTENER
ERESOLVE
EMONITOR
ECREATE_THREAD
ECREATE_MUTEX
ECREATE_SIGNALER
EUNSPECIFIED
EGENERAL_TYPE1
EGENERAL_TYPE2
EGENERAL_TYPE3
EINVALID_OPTION
ETOO_FEW_ARGS
ETOO_MANY_ARGS
ESOCKET
ETHREAD
EGUI
EFATAL
EBROKEN_ASSERT
EIMAGE_LOAD
EDIR_CREATE
EINCOMPATIBLE_OPTIONS
EMISSING_REQUIRED_OPTION
EINVALID_OPTION_ARG
EMULTIPLE_OCCURANCES
ECONFIG_READER
EIMAGE_SAVE
ECAST_TO_STRING
ESTRING_CAST
EUTF8_TO_UTF32
EOPTION_PARSE
undefined error type
iteration: 
   objective: 
Submodules/dlib/dlib/matrix/matrix.h
const dlib::matrix::literal_assign_helper &dlib::matrix<double, 2, 2>::literal_assign_helper::operator,(const T &) const [T = double, num_rows = 2, num_cols = 2, mem_manager = dlib::memory_manager_stateless_kernel_1<char>, layout = dlib::row_major_layout]
r < m->nr() && c < m->nc()
You have used the matrix comma based assignment incorrectly by attempting to
supply more values than there are elements in the matrix object being assigned to.
Did you forget to call set_size()?
 r: 
 c: 
 m->nr(): 
 m->nc(): 
dlib::matrix<double, 2, 2>::literal_assign_helper::~literal_assign_helper() [T = double, num_rows = 2, num_cols = 2, mem_manager = dlib::memory_manager_stateless_kernel_1<char>, layout = dlib::row_major_layout]
!has_been_used || r == m->nr()
You have used the matrix comma based assignment incorrectly by failing to
supply a full set of values for every element of a matrix object.
const dlib::matrix::literal_assign_helper &dlib::matrix<double, 2, 1>::literal_assign_helper::operator,(const T &) const [T = double, num_rows = 2, num_cols = 1, mem_manager = dlib::memory_manager_stateless_kernel_1<char>, layout = dlib::row_major_layout]
dlib::matrix<double, 2, 1>::literal_assign_helper::~literal_assign_helper() [T = double, num_rows = 2, num_cols = 1, mem_manager = dlib::memory_manager_stateless_kernel_1<char>, layout = dlib::row_major_layout]
You have to supply column vectors to this function
double dlib::find_min_using_approximate_derivatives(search_strategy_type, stop_strategy_type, const funct &, T &, double, double) [search_strategy_type = dlib::lbfgs_search_strategy, stop_strategy_type = dlib::objective_delta_stop_strategy, funct = std::function<double (dlib::matrix<double, 0, 0>)>, T = dlib::matrix<double, 6, 1>]
is_col_vector(x) && derivative_eps > 0
double find_min_using_approximate_derivatives()
x.nc():         
derivative_eps: 
cnn_landmark.espresso.net
VCPFaceLandmarkEspresso
mediaanalysis://asset.mov
VCPMADVITextLookupTask
@"VIImage"8@?0
Failed to create text lookup query context
v24@?0@"VITextLookupResult"8@"NSError"16
VIService_TextLookup
vanishingPoint
dominantLine
v32@?0@"NSString"8@"NSNumber"16^B24
<%@ %p, 
active cost: %d,
inactive cost: %d>
cnn_smile.espresso.net
VCPSmileEspresso
highlight_head.espresso.net
input1
input2
var_165
CVPixelbuffer not IOSurface backed
activityID: %@, 
startTime: %@, 
duration: %f(sec), 
exitStatus: %d>
idx (%tu) is out of range (%tu)
timeValue
homographyParam
timeScale
epoch
errorCode
loopFadeLen
loopPeriod
loopStart
sport
cnn_activitylevel.dat
HighlightMaxDuration
HighlightTargetDuration
HighlightStartRange
HighlightTolerance
HighlightIndex
HighlightBestTrim
HighlightFullResult
v32@?0@"VCPMovieHighlight"8Q16^B24
com.apple.homekitanalysis.session.management
com.apple.homekitanalysis.session.handler
[HomeKit] XPC connection invalidated. Please restart the session.
No result handler registered
No VCPHomeKitAnalysisSession; cannot process message
HMIVideoAnalyzer
com.apple.mediaanalysis.sql
SELECT id, version, dateModified, dateAnalyzed, analysisTypes, flags, quality, masterFingerprint, adjustedFingerprint
, statsFlags
 FROM Assets WHERE localIdentifier=(?);
SELECT resultsType, results FROM Results WHERE assetId=(?);
SELECT resultsType, results FROM Results WHERE assetId=(?
) AND resultsType IN (?
SELECT id, localIdentifier, version, dateModified, dateAnalyzed, analysisTypes, flags, quality, masterFingerprint, adjustedFingerprint
 FROM Assets WHERE localIdentifier IN (?
SELECT assetId, resultsType, results FROM Results WHERE assetId IN (?
SELECT date FROM Blacklist WHERE localIdentifier=(?) AND count>=(?);
i8@?0
SELECT localIdentifier FROM Blacklist WHERE count>=(?) AND localIdentifier IN (?
SELECT localIdentifier FROM Blacklist WHERE count>=(?);
SELECT localIdentifier FROM Assets WHERE dateAnalyzed>=(?) UNION SELECT localIdentifier FROM Blacklist WHERE count>=(?) AND date>=(?);
SELECT localIdentifier, status, attempts, date FROM ProcessingStatus WHERE taskID=(?) AND status!=(?) AND localIdentifier IN (?
SELECT localIdentifier FROM ProcessingStatus WHERE taskID=(?) AND status=(?);
SELECT COUNT(*) FROM ProcessingStatus WHERE taskID=(?) AND status=(?);
SELECT value FROM KeyValueStore WHERE key = (?);
SELECT activityID, startTime, duration, exitStatus FROM BackgroundActivitySchedulingHistory WHERE activityID=(?) AND startTime>=(?);
value
timescale
Orientation
Regions
Home resident maintenance task cancelled
HMITaskService
[VCPMADServiceImageProcessing] Specified identifier not found (%@)
[ImageProcessingTask%d] Identifier %@
Request was canceled
VCPVideoCNNBackboneEspresso
video_backbone.espresso.net
AveragePool_258_out
ReduceMean_264
Add_182_out
Pad_257_out
activityScore
ErrorCode
@"VNSession"8@?0
com.apple/PhotoVision/FaceCrop/
PVFC
PVFC:PVFC
PVFC_VER
PVFC_FB
PVFC_CB
PVFC_GID
tiff:Orientation
Could not set output orientation
Could not register face crop namespace
Could not generate serialized metadata representation
Could not convert metadata representation into serialized format
Could not set face crop metadata
Could not create image source
No meta data exists on image
unexpected nil image source
invalid image source
zero dimensioned face rect submitted
could not create cropped face crop image
could not create face crop metadata
public.jpeg
could not create face crop data
could not write face crop data
VCPFaceCropUtils : newFaceCropFromImageData - %@
image url is nil
Could not create image ref
Could not create face rect
VCPFaceCropUtils:newFaceCropFromImageURL - %@
image data is nil
Could not create image source from data
VCPFaceCropUtils:newFaceCropFromImageData - %@
invalid face crop supplied
VCPFaceCropUtils:faceBoundsFromFaceCrop -- %@
VCPFaceCropUtils:cropBoundsInOriginalImageFromFaceCrop -- %@
the supplied data is not a facecrop
could not create an image source
Could not retrieve image properties
VCPFaceCropUtils:faceCropDimensionsFromFaceCrop -- %@
could not create image ref
Could not create image for rendering
Could not create buffer for rendering
Could not create srgb colorspace
Could not create cropped and subsampled image
Could not create bitmap context
Face
@"VCPMADMachineReadableCodeResource"8@?0
VCPMADVIMachineReadableCodeDetectionTask
flow_estimation_%d
t_38
v16@?0^{?=ii*}8
interestScore
com.apple.mediaanalysisd.realtime
ContentType
faceMetadataArray
realtimeFaceRect
realtimeFaceRoll
realtimeFaceYaw
PriorityScore
v32@?0@8Q16^B24
%@ <%p>:
  person1LocalIdentifier  : %@
  person2LocalIdentifier  : %@
  reason                  : %@
asset.dateCreated
asset.addedDate
asset.filename
centerX
centerY
(verifiedType = %d) OR (verifiedType = %d)
(faceAlgorithmVersion = %d) AND (((hidden = 0) AND (manual = 0) AND ((trainingType = %d) OR (trainingType = nil))) OR ((trainingType = %d) OR (trainingType = %d) OR (trainingType = %d)))
(clusterSequenceNumber > 0)
(manual == 0) AND (faceAlgorithmVersion = %d)
Could not access the library
Canceled operation to get CSNs of faces missing from the library
v40@?0@"NSArray"8{_NSRange=QQ}16^B32
v32@?0@"NSString"8@"PHFetchResult"16^B24
(clusterSequenceNumber in %@)
Canceled operation to ungroup faces
v16@?0^B8
Canceled operation to uncluster faces
(clusterSequenceNumber = 0)
((clusterSequenceNumber > 0) AND (faceGroup = nil))
could not access the library
Canceled operation to cleanup grouped faces with CSN=0
No faceGroups found for person with localIdentifier '%@'
Failed to fetch faces from the faceGroup that contributed the most number of face to person with localIdentifier '%@'
(clusterSequenceNumber in %@) AND (trainingType = %d OR trainingType = %d OR trainingType = %d)
(clusterSequenceNumber in %@) AND (trainingType = %d OR trainingType = %d)
v32@?0@"PHPerson"8Q16^B24
v32@?0@"NSNumber"8@"NSSet"16^B24
photoLibrary is nil
trainingType != %d
VisionFgMapping_LookingAfterNewClusteredFace
VisionFgMapping_LookingForConflictingCluster
VisionFgMapping_ResolveConflictingCluster
v32@?0@"NSNumber"8@"NSDictionary"16^B24
VisionFgMapping_ResolveConflictL0Clusters
VisionFgMapping_Process
clusterSequenceNumber IN %@
@"PHFace"16@?0@"NSNumber"8
Saving clustering results cancelled
Canceled operation to reset library clusters
keyFace == nil
[UpdateKeyFaces] Failed to find persons %@
-[VCPPhotosPersistenceDelegate updateKeyFacesOfPersonsWithLocalIdentifiers:forceUpdate:cancelOrExtendTimeoutBlock:error:]
[UpdateKeyFaces] Operation canceled
Unimplemented %s in VCPPhotosPersistenceDelecate
-[VCPPhotosPersistenceDelegate invalidFaceClusterSequenceNumbersInClusterSequenceNumbers:canceler:error:]
-[VCPPhotosPersistenceDelegate ungroupFaceClusterSequenceNumbers:batchSizeForUnclusteringFaces:canceler:error:]
-[VCPPhotosPersistenceDelegate cleanupUngroupedFacesWithNonZeroClusterSequenceNumbersWithCanceler:error:]
-[VCPPhotosPersistenceDelegate cleanupGroupedFacesWithClusterSequenceNumberSetToZeroWithCanceler:error:]
-[VCPPhotosPersistenceDelegate persistChangesToAlgorithmicFaceGroups:faceCSNByLocalIdentifierForNewlyClusteredFaces:faceCSNsOfUnclusteredFaces:localIdentifiersOfUnclusteredFaces:persistenceCompletionBlock:canceler:error:]
-[VCPPhotosPersistenceDelegate resetLibraryClustersWithCanceler:error:]
-[VCPPhotosPersistenceDelegate updateKeyFacesOfPersonsWithLocalIdentifiers:forceUpdate:canceler:error:]
-[VCPPhotosPersistenceDelegate bestRepresentativeFaceForPerson:qualityMeasureByFace:canceler:]
-[VCPPhotosPersistenceDelegate bestRepresentativeFaceForPerson:qualityMeasureByFace:candidateFaces:canceler:]
-[VCPPhotosPersistenceDelegate associateFace:withFaceCrop:error:]
-[VCPPhotosPersistenceDelegate clearDirtyStateOnFaceCrops:error:]
-[VCPPhotosPersistenceDelegate dirtyFaceCropsWithLimit:]
-[VCPPhotosPersistenceDelegate faceAssociatedWithFaceCrop:]
-[VCPPhotosPersistenceDelegate facesFromAsset:]
-[VCPPhotosPersistenceDelegate persistFaces:deleteFaces:forAsset:persistedFaces:error:]
-[VCPPhotosPersistenceDelegate persistGeneratedFaceCrops:error:]
-[VCPPhotosPersistenceDelegate recordNeedToPersonBuildOnFaceGroupContainingFace:error:]
-[VCPPhotosPersistenceDelegate suggestedPersonLocalIdentifierForPersonLocalIdentifier:faceClusterer:canceler:context:error:]
-[VCPPhotosPersistenceDelegate updateFaceprint:ofPersistedFace:error:]
-[VCPPhotosPersistenceDelegate buildPersonsWithFaceClusterer:keyFaceUpdateBlock:canceler:context:extendTimeoutBlock:]
(personBuilderState = %ld)
Canceled cleaning up merge candidates of verified persons
v24@?0@"PHFetchResult"8@"NSMutableSet"16
v24@?0@"VCPMergeCandidatePair"8^B16
Canceled cleaning up merge candidates
(trainingType = %d) || (trainingType = %d)
v32@?0@"PHPerson"8@"NSString"16^B24
B24@?0@"VCPMergeCandidatePair"8@"NSDictionary"16
(clusterSequenceNumber IN %@)
Person building cancelled
clusterSequenceNumber = %ld
clusterSequenceNumber != %ld
[FaceCropAdjustment][%@-%d]
v32@?0@"NSString"8@"PHFaceCrop"16^B24
v32@?0@"PHFace"8@"PHPerson"16^B24
v24@?0@"NSDictionary"8q16
v32@?0@"NSString"8@"NSMutableArray"16^B24
q24@?0@"PHFaceCrop"8@"PHFaceCrop"16
v32@?0@"PHFaceCrop"8Q16^B24
MADProcessNewlyClusteredFaceCrops
invalid merge candidate pair created from cluster rejections
potential invalid merge candidate pair created from cluster rejections
invalid merge candidate pair from cluster rejection for verified person
potential invalid merge candidate pair from cluster rejection for verified person
B16@?0^@8
no training faces in level1 cluster - create 'unverified person : verified/migrated person' candidate pair
all training faces on single verified person in level1 cluster - create 'unverified person : training person' candidate pair
all training faces on single verified person in level1 cluster - create 'unverified person : verified person' candidate pair
all training faces on single verified person in level1 cluster - create 'training person : verified person' candidate pair
invalid merge candidate pair because we may have a dirty level0 cluster
multiple training persons in level0 cluster - create 'training person : training person' pair
clusterSequenceNumber
single training person in level0 cluster - create 'training person : verified person with confirmed face' pair
single training person in level0 cluster - create 'verified persons with confirmed face : verified persons with confirmed face' pair
invalid merge candidate pair because one person has face rejected for the other
invalid merge candidate pair because we have > 3 verified persons in the face group
single training person in level1 cluster - create 'training person : verified person with confirmed face' pair
single training person in level1 cluster - create 'verified persons with confirmed face : verified persons with confirmed face' pair
level1 cluster - create 'training person : training person' pair
level1 cluster - create 'unverifed person : training person' pair
invalid merge candidate pair: a cluster rejection
v32@?0@"NSMutableSet"8@"NSMapTable"16@"NSSet"24
invalid merge candidate pair:a face on verified person but cluster-rejected on another verified person
-[VCPPhotosPersistenceDelegate buildPersonWithFaceClusterer:keyFaceUpdateBlock:context:cancelOrExtendTimeoutBlock:]
VCPFaceProcessingBuildPersonsCoreAnalyticsCollection
com.apple.mediaanalysisd.photos.personbuilding
BuildingInterval
BuildingSequence
ClusterCount
ClusterFaceCount
FaceGroupCount
FaceGroupCountNeedToBuild
faceLocalIdentifier is nil
fetched %lu faces for %@
clusterSequenceNumber is nil
personLocalIdentifier is nil
fetched %lu persons for %@
Got a 'nil' photoLibrary. Cannot remove auto assigned faces
(manual = 0) AND ((nameSource = %d) OR (nameSource = %d) OR (nameSource = %d)) AND ((trainingType = %d) OR (trainingType = nil))
Operation to remove faces from verified persons has been canceled
Failed to removed faces from person with localIdentifiers '%@'
not known
PGGraphHelper
exposure
underExpose
q24@?0@"PHSceneClassification"8@"PHSceneClassification"16
@"VCPMADVIDocumentRecognitionResource"8@?0
VCPMADVIDocumentRecognitionTask
VCPMADPersonIdentificationTaskResource
@"VCPMADPersonIdentificationTaskResource"8@?0
VCPMADPersonIdentificationTask
[%@] Failed to configuate VNDetectFaceRectanglesRequest
[%@] Failed to configuate VNCreateFaceprintRequest
[%@] Failed to detect faces - %@
q24@?0@"VNFaceObservation"8@"VNFaceObservation"16
[%@] Failed to print faces - %@
{{x:%.*f, y:%.*f}, {width:%.*f, height:%.*f}} 
com.apple.mediaanalysis
com.apple.mediaanalysisd.analysis
com.apple.mediaanalysisd.photos
com.apple.mediaanalysisd.homekit
com.apple.mediaanalysisd.homekitsession
dateModified
dateAnalyzed
masterFingerprint
adjustedFingerprint
performedAnalysisTypes
statsFlags
metadataRanges
SyncPoint
FaceResults
ShotTypeResults
VoiceResults
MLQualityResults
JunkResults
BlurResults
ExposureResults
MLCameraMotionResults
DistanceResults
SaliencyResults
CompositionResults
ClassificationResults
MusicResults
UtteranceResults
ActivityLevelResults
FacePrintResults
PetsResults
PetsFaceResults
PetsKeypointsResults
PetsActionResults
MovieSummaryResults
SettlingEffectsGatingResults
MovieHighlightResults
MovieHighlightScoreResults
MLHighlightScoreResults
KeyFrameResults
KeyFrameBlurResults
KeyFrameStillResults
TrackingResults
LivePhotoEffectsResults
ParallaxResults
WallpaperExportResults
WallpaperPosterConfigDataResults
FaceQualityResults
SceneChangeResults
ApplauseResults
BabbleResults
CheeringResults
LaughterResults
AudioQualityResults
HumanPoseResults
HumanActionResults
HumanPoseInternalResults
HandsResults
LoudnessResults
KeyFrameResourceResults
VideoStabilizationResults
SongResults
HumanActionClassificationResults
InterpolationResults
WPResults
RotationAnalysisResults
ColorNormalizationResults
VideoCaptionResults
ImageCaptionResults
SettlingEffectResults
FaceQualityFlag
energyValues
peakValues
facePosition
faceBounds
facePoseYaw
facePrint
sharpnessFaces
saliencyBounds
saliencyConfidence
songSignature
wallpaperScore
probableRotation
probableRotationConfidence
colorNormalizationData
vanishingPointConfidence
neighbor
neighborDateModified
gyroStabilization
analysisConfidence
stabilizationRecipe
interpolationURL
settlingEffectURL
petsBounds
petsConfidence
petsKeypoints
petsAction
petsAbsoluteScore
petsRelativeScore
keyFrameTime
keyFrameScore
bestPlaybackCrop
maxHighlightStart
maxHighlightDuration
audioQuality
loopSuggestionState
longExposureSuggestionState
livePhotoEffectsRecipe
livePhotoEffectsGatingDescriptions
livePhotoEffectsMatchingScenes
aesthetic
sceneClassification
saliency
saliencyObjectness
duplicateMatchingFeature
duplicateMatchingAlternateFeature
overallScore
allScores
wellFramedSubjectScore
wellChosenBackgroundScore
tastefullyBlurredScore
sharplyFocusedSubjectScore
wellTimedShotScore
pleasantLightingScore
pleasantReflectionsScore
harmoniousColorScore
livelyColorScore
pleasantSymmetryScore
pleasantPatternScore
immersivenessScore
pleasantPerspectiveScore
pleasantPostProcessingScore
noiseScore
failureScore
pleasantCompositionScore
interestingSubjectScore
intrusiveObjectPresenceScore
pleasantCameraTiltScore
lowKeyLightingScore
acceptableCrop
preferredCrop
humanBounds
humanKeypoints
humanConfidence
humanID
humanActions
torsoPrint
handsBounds
handsKeypoints
handsKeypointsConfidents
handsID
videoCaptionText
videoCaptionConfidence
imageCaptionText
imageCaptionConfidence
frameQualityScore
faceQualityScore
sharpnessScore
texture
stillTime
flashFired
QualityOfService
DutyCycling
VCPTaskIDs
ForcePublish
GyroStabilization
PixelStabilization
MaxNumberOfAssetToProcess
ForceFullScan
Full Face, 
Face, 
Voice, 
Full Scene, 
Scene, 
Junk, 
Blur, 
Exposure, 
Distance, 
Feature, 
Saliency, 
Composition, 
Classification, 
ActivityLevel, 
CurationScore, 
Pets, 
PetsPose, 
MovieCuration, 
Effects, 
Parallax, 
Wallpaper Export, 
Face Quality, 
Audio Classification, 
Human pose, 
Loudness Measure, 
Hands, 
Video Stabilization Pixel, 
Video Stabilization Gyro, 
Gyro Analytics, 
ML Video Attributes, 
Song detection, 
Settling effect, 
Human action, 
Iris Recommendation, 
Video Caption, 
Audio Quality, 
v32@?0@"NSString"8@"NSArray"16^B24
mShortInputDecision
mPreGateStillMetadataDecision
mPreGateVideoTrimDecision
mPreGateVideoMLDecision
mPreGateFacesDecision
stabilizeGateDecision
postGateDecision
finalDecision
loopActivityDecision
bounceActivityDecision
longexpActivityDecision
ALGatingResultError
ALGatingResultUnset
ALGatingResultFail
ALGatingResultPass
SceneAnalysis
FaceAnalysis
EffectsAnalysis
Sceneprint
VideoStabilization
MultiWorkerAnalysis
QuickFaceIdentification
EmbeddingAnalysis
OCRAnalysis
MovieHighlightProcessing
VisualSearchAnalysis
FilesystemAnalysis
Unknown(%lu)
autobahn-nature
autobahn-city
autobahn-citynatureish
otgx_csfbtu_gfnbmf
otgx_csfbtu_nbmf
otgx_cvuupdlt
otgx_hfojubmt_gfnbmf
otgx_hfojubmt_nbmf
otgx_opof
otgx_voefsxfbs
otgx_boz
otgx_fyqmjdju
otgx_hfojubmt
meme_document_check_or_checkbook
meme_curation_meme
meme_curation_screenshot
meme_document_boarding_pass
meme_document_currency_or_bill
meme_document_driving_license
meme_document_office_badge
meme_document_passport
meme_document_receipt
meme_document_social_security_number
meme_hier_negative
meme_hier_document
meme_hier_curation
meme_negative
meme_document
meme_screenshot_etc
hier_text_document
hier_tragic_failure
tragic_failure
screenshot
bad_framing
bad_lighting
blurry
food_or_drink
junk_other
medical_reference
negative
receipt_or_document
repair_reference
shopping_reference
utility_reference
junk_negative
hier_negative
junk_non_memorable
hier_non_memorable
junk_poor_quality
hier_poor_quality
No Resource
Download Throttled
Soft Failure
Hard Failure
Duplicate Failure
Upload Failure
PhotoLibraries
ImageTooSmall
UsingBestResource
FacesToDelete
FacesToPersist
VisionClustersMinusLibraryClusters
LibraryClustersMinusVisionClusters
failed
processed
pet-vip-status
person-vip-status
prioritized-processed
prioritized-total-allowed
full-analysis-complete-processed
full-analysis-partial-processed
Confidence
BoundingBox
UserInteractive
UserInitiated
Default
Utility
Background
Unspecified
OptInStatus
FileURL
GroundTruthURL
PersonIdentifier
PersonInformation
UserLabeledGender
UserLabeledAge
UserLabeledEthnicity
ModifyPersonRequest
SubTasks
NumberOfAssetsAllowedForPhotosFaceProcessing
NumberOfAssetsAnalyzedForPhotosFaceProcessing
NumberOfPrioritizedAssetsAnalyzedForPhotosFaceProcessing
NumberOfPrioritizedAssetsAllowedForPhotosFaceProcessing
Success
Canceled
Status Error
Parameter Error
Unknown Error
resident: %@, virtual: %@, phys_footprint: %@, phys_footprint_peak: %@.
resident: N/A, virtual: N/A, phys_footprint: N/A, phys_footprint_peak: N/A.
supportedRevisions
supportedPrivateRevisions
MediaAnalysisVersion
LatestVersionTimeStamp
MediaAnalysisCompleteTimestamp
MediaAnalysisProgressPercentage
SceneAnalysisVersion
LatestSceneAnalysisVersionTimestamp
SceneAnalysisCompleteTimestamp
SceneAnalysisProgressPercentage
FaceAnalysisVersion
LatestFaceAnalysisVersionTimestamp
FaceAnalysisCompleteTimestamp
FaceAnalysisProgressPercentage
PrioritizedFaceAnalysisCompleteTimestamp
PrioritizedFaceAnalysisProgressPercentage
OCRAnalysisVersion
LatestOCRAnalysisVersionTimestamp
OCRAnalysisCompleteTimestamp
OCRAnalysisProgressPercentage
VisualSearchAnalysisVersion
LatestVisualSearchAnalysisVersionTimestamp
VisualSearchAnalysisCompleteTimestamp
VisualSearchAnalysisProgressPercentage
EmbeddingAnalysisVersion
LatestEmbeddingAnalysisVersionTimestamp
EmbeddingAnalysisCompleteTimestamp
EmbeddingAnalysisProgressPercentage
Bytes
%llu %@
Error: failed to processSampleBuffer
cnn_faceblur.dat
feature_extraction
t_19
t_57
t_76
t_95
t_114
types
date
typesWide
assetIdentifier
assetModificationDate
assetMasterFingerprint
assetAdjustedFingerprint
imageBlurResults
imageCompositionResults
imageFaceResults
imageFeatureResults
imageJunkResults
imageSaliencyResults
imageShotTypeResults
imagePetsResults
imagePetsFaceResults
imageSceneprintResults
livePhotoEffectsResults
livePhotoRecommendationResults
livePhotoSharpnessResults
livePhotoKeyFrameResults
livePhotoKeyFrameStillResults
movieActivityLevelResults
movieCameraMotionResults
movieClassificationResults
movieFaceResults
movieFaceprintResults
movieFeatureResults
movieFineSubjectMotionResults
movieInterestingnessResults
movieMovingObjectResults
movieMusicResults
movieObstructionResults
movieOrientationResults
moviePreEncodeResults
movieQualityResults
movieSaliencyResults
movieSceneResults
movieSceneprintResults
movieSubjectMotionResults
movieSubtleMotionResults
movieUtteranceResults
movieVoiceResults
movieSummaryResults
movieHighlightResults
imageExposureResults
imageHumanPoseResults
movieHumanPoseResults
movieApplauseResults
movieBabbleResults
movieCheeringResults
movieLaughterResults
movieHumanActionResults
movieLoudnessResults
moviePetsResults
moviePetsFaceResults
movieStabilizationResults
movieHighlightScoreResults
livePhotoHumanActionClassificationResults
movieAudioQualityResults
OCR/MRC
GlobalXSum
GlobalYSum
Type
cnn_lm.dat
Cannot generate facecrop without originating face
Failed to find originating PHFace %@
Failed to generate facecrop on manual originating face %@
Facecrop is nil
Missing image data from facecrop %@
Invalid facecrop image data %@
Invalid facecrop bounding box %@
Facecrop image size equals to 0
Failed to normalize bound %@ with image (%.0fx%.0f)
Failed to obtain the facecrop image dimensions
Failed to create VNImageRequestHandler
Failed to set VNDetectFaceRectanglesRequest
Failed to set VNCreateFaceprintRequest
Failed to analyze facecrop - %@
Failed to create faceprint - %@
Failed to wrap faceprint/faceTorsoprint
Face has already been persisted with a facecrop
Face does not have a faceprint
Failed to fetch facecrop
Failed to persist face and facecrop
[FaceCropManager] faceLocalIdentifier is nil
[FaceCropManager] Fetched %lu faces with face identifier %@, should be 1
[FaceCropManager] Failed to fetch face %@
yyyyMMdd
en_US_POSIX
FaceIDModelLastGenerationKey
PetIDModelLastGenerationKey
Person
com.apple.mediaanalysis.quickfaceid.management
VCPPersonVIPLoadModel
VCPPetVIPLoadModel
nameSource == %ld
verifiedType = %@
faceCount
nameSource != %ld
VCPPetVIPGenerateModel
isInVIPModel == YES
roll == 0.0
graph
user
VCPPersonVIPGenerateModel
VCPCNNBlurAnalyzerEspresso.sharedModelPool-%lu
cnn_blurV2.espresso.net
cnn_blur.espresso.net
VCPBlurEspresso
res_299x299
res_400x400
res_400x300
res_300x400
yyyy-MM-dd-HH-mm-ss
suggestionLog_
suggestions.html
function addPlaceHolders() {
addPlaceholdersForSet("visionInput", inputFaces);
addPlaceholdersForSet("visionOutput", outputFaces);
addPlaceholdersForSet("visionFiltered", filteredFaces);
function isElementHidden(element) {
var style = window.getComputedStyle(element);
return (style.display === 'none')
function updateVisibility() {
var allDivs = document.getElementsByTagName("div");
for (var i = 0; i < allDivs.length; i++) {
var d = allDivs[i];
if (!d.attributes["img"]) continue;
var rect = d.getBoundingClientRect();
if (
rect.top >= -100 &&
rect.left >= -100 &&
rect.bottom - 100 <= (window.innerHeight || document.documentElement.clientHeight) &&
rect.right - 100 <= (window.innerWidth || document.documentElement.clientWidth)
if (d.childNodes.length == 0) {
d.innerHTML = "<img src='" + d.attributes["img"].value + "' width='100' height='100'>";
else {
if (d.childNodes.length != 0) {
d.innerHTML = "";
function addPlaceholdersForSet(containerId, elements) {
var content = "";
for (var i = 0; i < elements.length; i++) {
content += "<div style='float: left; width: 100px; height: 100px; margin: 3px; background-color: darkgray' img='" + elements[i] + "'></div>"
document.getElementById(containerId).innerHTML = content;
document.onscroll = function (e) {
updateVisibility();
</script>
</head>
<body>
<p>Vision input:</p>
<div id="visionInput">
</div>
<p style="clear: both;">Vision output:</p>
<div id="visionOutput">
</div>
<p style="clear: both;">Vision filtered output:</p>
<div id="visionFiltered">
</div>
</div>
<script>
document.addEventListener("DOMContentLoaded", function (event) {
addPlaceHolders();
</script>
</body>
</html>
could not obtain access to the photo library
photo library could not provide suggestions
_suggestionsForPersonWithLocalIdentifier cancelled
v16@?0Q8
<html>
<head>
<script>
 var inputFaces = [
v32@?0@"NSString"8@"NSArray"16@"NSError"24
var outputFaces = [
var filteredFaces = [
suggestPersonsForPersonWithLocalIdentifier cancelled
Input parameter is empty or nil: '%@'
Failed to find persons with local identifiers: '%@'
VCPClusterer is nil
verifiedType != %d
VCPFaceProcessingDeleteAllVerifiedPersons
succeeded
VCPFaceProcessingReclusterFacesWithThreshold
VCPFaceProcessingBuildPersons
VCPBuildPersons failed %d
VCPFaceProcessingPromotePersons
VCPPromotePersons failed %d
Failed to rebuild persons (error: %d)
Failed to promote persons (error: %d)
B32@?0@"NSDictionary"8Q16^B24
PVPersonPromoter
Memories
iMovie
v48@?0^{CGImage=}8{?=qiIq}16@"NSError"40
IrisObjectsResults
MetaStabilizationResults
MetaStabilizationFrameResults
MetaHomographyDimensionResults
MetaHomographyResults
MetaPresentationTimeResults
MetaMotionBlurResults
MetaPTSInNanosResults
MetaOriginalPTSInNanosResults
MetaItemPTSResultsKey
MetaAdjusterResults
MetaAdjusterRecipeResults
MetaAdjusterDisplacementKey
MetaInterpolatedFrameKey
MetaLensSwitchResults
autoplay_head.espresso.net
var_99
NotImplementedException
[VideoTrackDecoder status] should not be called
[VideoTrackDecoder copyNextSampleBuffer] should not be called
[VideoTrackDecoder getNextCaptureSampleBuffer] should not be called
  state            : %d
  originating face : %@
action_repetition_counter
mlmodelc
VCPMADVIVisualSearchGatingTask
<redacted>
Failed to create visual search query context
VIService_VisualSearchGating
v32@?0@"VIParseResult"8@"NSData"16@"NSError"24
.espresso.net
callback queue
Create Context Error
Create Plan Error
%@ Load Error
Build Model Error
Select Configuration Error
Build Plan Error
Clean Plan Error
B24@?0@"NSString"8@"NSDictionary"16
VCPFaceAnalyzerFillMissingFaceprint
VCPFaceAnalyzerFaceQuality
aggregated
faceID
faceprintBlob
Live Photo
Pano Photo
Screenshot
HDR Photo
SDOF Photo
Photo
Slow-mo Movie
Timelapse Movie
Movie
VCPMADVIVisualSearchTask
v24@?0@"VISearchResult"8@"NSError"16
VIService_ParsedVisualSearch
VIService_VisualSearch
cnn_smile.dat
Failed to load asset
Asset contains no video tracks
Failed to create video track output
Failed to start decoding video track
Video processor cancelled
Failed to complete video decoding
recipeBlob
keyFrame
playbackCrop
colorNormalizationBlob
hasAction
Video stabilization task cancelled
Video stabilization processing failed
VideoCNN
Skeleton
enabled
formatDescriptions
naturalSize
nominalFrameRate
preferredTransform
tracks
res_384x384
q24@?0@"NSNumber"8@"NSNumber"16
res_%dx%d
obstructionScore
VCPMADServiceImageProcessingTask
%@ not currently implemented
q24@?0@"NSObject<VCPMADServiceImageProcessingSubtaskProtocol><VCPMADTaskProtocol>"8@"NSObject<VCPMADServiceImageProcessingSubtaskProtocol><VCPMADTaskProtocol>"16
[MediaAnalysis][%@]Unable to open movie, skip
[MediaAnalysis][%@]Failed to create asset
[%@] Analysis cancelled
[%@] Analysis failed to complete
outputFrameDurValue
cropRectX
cropRectY
cropRectHeight
cropRectWidth
autoloop
bounce
longexposure
stabilize
minVersion
cnn_blink.espresso.net
VCPGazeEspresso
PersonBuilderMergeCandidatesEnabled
PersonBuilderLastMinimumFaceGroupSizeForCreatingMergeCandidates
personBuilderState != %lu
VCPFaceProcessingCleanupMergeCandidates
v16@?0@"NSArray"8
VCPPersonBuilder_UpdateKeyface
statisticsBlob
@"VCPMADVIRectangleDetectionResource"8@?0
VCPMADVIRectangleDetectionTask
com.apple.mediaanalysis.SceneProcessingGroup
MonzaV4_1
@"CVNLPCommSafetyHandler"8@?0
%@%@
classID
size
score
v32@?0@"VNRecognizedObjectObservation"8Q16^B24
v24@?0@"PFSceneTaxonomyNode"8^B16
v32@?0@"NSDictionary"8Q16^B24
meme_
v32@?0@"NSString"8@"NSString"16^B24
cnn_human_pose_single.espresso.net
subjectMotionScore
motionDivScore
objectsMotion
globalMotion
interestingnessScore
trackingScore
sceneChangeScore
browDown_L
browDown_R
browInnerUp
browOuterUp_L
browOuterUp_R
cheekPuff
cheekSquint_L
cheekSquint_R
eyeBlink_L
eyeBlink_R
eyeLookDown_L
eyeLookDown_R
eyeLookIn_L
eyeLookIn_R
eyeLookOut_L
eyeLookOut_R
eyeLookUp_L
eyeLookUp_R
eyeSquint_L
eyeSquint_R
eyeWide_L
eyeWide_R
jawForward
jawLeft
jawOpen
jawRight
mouthClose
mouthDimple_L
mouthDimple_R
mouthFrown_L
mouthFrown_R
mouthFunnel
mouthLeft
mouthLowerDown_L
mouthLowerDown_R
mouthPress_L
mouthPress_R
mouthPucker
mouthRight
mouthRollLower
mouthRollUpper
mouthShrugLower
mouthShrugUpper
mouthSmile_L
mouthSmile_R
mouthStretch_L
mouthStretch_R
mouthUpperUp_L
mouthUpperUp_R
noseSneer_L
noseSneer_R
tongueOut
focalLengthInPixels
objects
faceRollAngles
faceAnchor
vertices
transform
blendshapes
geometry
dispatchQueue
regionsOfInterest
aggSubjectMotionScore
turboMode
frameWidth
frameHeight
VCPCaptureAnalysis
v28@?0f8f12Q16i24
cnn_pets.espresso.net
VCPPetsEspresso
res_0
res_1
res_2
gesture_recognition.espresso.net
cnn_human_pose.espresso.net
AllowOnDemandPixel
AllowOnDemandGyro
AllowStreaming
KeepPrivateResults
MaxHighlightDuration
Standalone
StoreAnalysis
ScaledSlomoTime
com.apple.mediaanalysis.ondemand
com.apple.mediaanalysis.storage
com.apple.mediaanalysis.VCPMediaAnalyzer.sandboxQueue
com.apple.mediaanalysis.VCPMediaAnalyzer.cancelQueue
v16@?0@"NSString"8
VCPMediaAnalyzer
Sceneprint task cancelled
[%@] Thumbnail is not locally available
[%@] Failed to load thumbnail image
[%@] Failed to set revision %lu - %@
[%@] Invalid sceneprint result
45.1
mediaType == %d
kind == %d && kindSubtype != %d
mediaType == %d && !((mediaSubtype & %d) == %d)
kindSubtype == %d
(mediaSubtype & %d) == %d
!((mediaSubtype & %d) == %d)
mediaAnalysisAttributes.mediaAnalysisVersion < %d
kindSubtype != %d && SUBQUERY(additionalAttributes.sceneClassifications, $s, $s.sceneIdentifier = %d AND $s.confidence > %f).@count > 0
kindSubtype != %d && SUBQUERY(additionalAttributes.sceneClassifications, $s, $s.sceneIdentifier = %d AND $s.confidence > %f).@count = 0
SUBQUERY(additionalAttributes.sceneClassifications, $s, $s.sceneIdentifier = %d AND $s.confidence >= %f).@count > 0
SUBQUERY(additionalAttributes.sceneClassifications, $s, $s.sceneIdentifier = %d AND $s.confidence >= %f).@count = 0
additionalAttributes.sceneAnalysisVersion != %d || adjustmentTimestamp != additionalAttributes.sceneAnalysisTimestamp
adjustmentTimestamp != faceAdjustmentVersion
mediaAnalysisAttributes.characterRecognitionAttributes = NULL || mediaAnalysisAttributes.characterRecognitionAttributes.algorithmVersion != %d || adjustmentTimestamp != mediaAnalysisAttributes.characterRecognitionAttributes.adjustmentVersion
mediaAnalysisAttributes.visualSearchAttributes = NULL || mediaAnalysisAttributes.visualSearchAttributes.algorithmVersion != %d || adjustmentTimestamp != mediaAnalysisAttributes.visualSearchAttributes.adjustmentVersion
VCPMADVisionResource
output1
output2
output3
cnn_hand_detector_v2.espresso.net
VCPMAMLModel-%@
@"VCPMAMLModel"8@?0
maxNumberHands
humanActionWindowSize
motionFlowComputationAccuracy
v32@?0@"NSString"8@"NSString"16@"NSError"24
identifier
mediaanalysis://in-memory
com.apple.mediaanalysisd.VCPInMemoryAVAsset
v24@?0^v8Q16
Frame: %u
textureness
hasFlash
supportedImageSizeSet
v16@?0@"NSData"8
Destructive Trim Range: [%.2f - %.2f]
after repare
after consecutive short merge
after sparse short merge
after post processing
=========Segment %s==========
v32@?0@"VCPSegment"8Q16^B24
 [%.2f - %.2f]: %.2f
--[%.2f - %.2f]
com.apple.mediaanalysis.VCPDefaultPhotoLibraryManager
precision
personID
validFaceCount
identitySize
recall
AutoCounterGroundTruth.plist
[AutoCounter] Cannot load ground truth file URL
no_name
AddedDate
unknown
unverified
verifiedType
personName
faceRect
faceGroupID
faceprint
momentIdentifier
[AutoCounter] Failed to fetch person (%@)
FacesPerAsset
OptInDate
OptInDateSinceReferenceDate
OptInMADFaceVersion
OptInDetectionModelVersion
OptInRecognitionModelVersion
FaceCount
AssetCount
AdditionalInformation
AutoCounterClusters_Ver%d_DetectionVer%lu_RecognitionVer%lu.plist
[AutoCounter] Failed to retrive export URL
mergecandidates
faces
assetInformation
[AutoCounter] Failed to process FaceGroups
v32@?0@"NSString"8@"NSDictionary"16^B24
AutoCounterClusterAssetsToFaces_Ver%d_DetectionVer%lu_RecognitionVer%lu.plist
phFaceID
gtFaceID
gtPersonID
v32@?0@"NSString"8@"NSSet"16^B24
com.apple.photos.autocounter
date_optin
detection_version_current
detection_version_optin
mad_version_current
mad_version_optin
person_id
promoter_clusters
promoter_clusters_duplicates
promoter_precision
promoter_recall
promoter_version_current
promoter_version_optin
recognition_version_current
recognition_version_optin
total_assets
total_assets_optin
total_faces
total_faces_optin
type
userLabeledAge
userLabeledEthnicity
userLabeledGender
vision_clusters
vision_clusters_duplicates
vision_precision
vision_recall
nightly
nightly-Ver%d_DetectionVer%lu_RecognitionVer%lu_PersonVer%lu
AutoCounterCoreAnalytics
%@_Ver%d_DetectionVer%lu_RecognitionVer%lu.plist
self.lastPathComponent BEGINSWITH %@
v32@?0@"NSURL"8Q16^B24
visionCluster
weightedAveragePrecision
weightedAverageRecall
numSingletons
numValidSingletons
precisionPerCluster
recallPerPersonToGroundTruth
recallPerPersonExcludeMissDetection
personCluster
identity
PVPersonPromoterVersion
Apple
cnn_saliency.dat
VCPMADVIUserFeedbackTask
VIService_UserFeedback
@"VCPMADVIVisualSearchResource"8@?0
mdta/com.apple.quicktime.live-photo-info
propertyKey %s 
result is nil %s
sum = %6.2f, tracking_score = %6.2f
Target Captured @ [%5.0f, %5.0f, %5.0f, %5.0f]
initial @ [%d %d] s = %6.5f
stop    @ [%d %d] s = %6.5f
lost = %d
[%6.2f, %6.2f, %6.2f, %6.2f]
box0: (x = %2.1f, y = %2.1f, w = %2.1f, h = %2.1f)
box1: (x = %2.1f, y = %2.1f, w = %2.1f, h = %2.1f)
box : (x = %2.1f, y = %2.1f, w = %2.1f, h = %2.1f)
overlap_area = %6.2f, max_area = %6.2f, weight = %6.2f
derr = %6.2f, terr = %6.2f
add new expert with weight %6.2f
expert %d was replaced: voting weight(%6.2f --> %6.2f)!
after voting --> update target
detector and tracker did not match well --> experts vote
detector and tracker matched well --> update experts
VCPImageHumanActionEspresso
cnn_image_human_action.espresso.net
res_192x192
hand_keypoint_detector.espresso.net
regressiontree_landmark.dat
rtree_landmark_tracking.dat
com.apple.mediaanalysisd.VCPVideoFaceValidation
face_validation_warp_tri_list.dat
face_validation_warp
face_validation_warp_params.dat
%@_%d.dat
com.apple.mediaanalysis.VCPImageManager.transcodeQueue
VCPImageManager
@"VCPImageManager"8@?0
MADImageManagerEncode_%.3f_unpadded.jpg
MADImageManagerEncode_%.3f_padded.jpg
/Library/Audio/Tunings/Generic/AU/aufx-epv2-mediaanalysis-appl.plist
cnn_pose.dat
motionType
isFast
sourceSize
inputBounds
VCPVideoCNNActionClassifierEspresso
VCPVideoCNNActionClassifierEspressoStage1
action_recognition_head.espresso.net
action_taxonomy.plist
boxes
action_recognition_head_stage1.espresso.net
q24@?0@"PHFace"8@"PHFace"16
cnn_saliency.espresso.net
VCPSaliencyFullEspresso
energy
peak
%@ canceled
%@ is not yet implemented
frame idx = %d
size = %d, track_target_exist = %d, target_lost = %d, tracking_score = %6.2f
com.apple.homekitanalysis.service.management
com.apple.homekitanalysis.service.handler
Failed to fetch person by local identifier (%@)
HMIAnalysisService
Failed to create VNAlignFaceRectangleRequest
Failed to exercise Vision request - %@
UserOrig
UserAlgo
NoUserAlgo
NoAlgo
cnn_person_detector.espresso.net
PetsRegions
PetsFaceRegions
{CGRect={CGPoint=dd}{CGSize=dd}}
res_256x256
VCPHumanPoseEspresso
res_320x192
res_192x320
clusterer is not available
Face clustering threshold should be in the range: [0.1, 1.0]
VCPFaceProcessingResetFaceClusteringState
VCPFaceProcessingPerformFaceClusteringAndWait
backwarpNonInterleaved
LogLevel
yyyy-MM-dd HH:mm:ss
autoPlayable
Angle
cnn_blur.dat
iChatUsageString
EnableStatsCollect
EnableUserQPForFacetime
EnableUserRefForFacetime
EnableWeightedPrediction
UserFrameType
ReferenceFrameNumDriver
ReferenceL0
UserQpMap
MBStatistics
NotSync
ClonedImageCaptionModel
en-US
Failed to load imageURL: %@
NeuralHash+LSH invalid imageSignatureHash
Invalid NeuralHash+LSH (=)
v20@?0f8^B12
VCPFaceProcessingPromotePersonsCoreAnalyticsCollection
com.apple.mediaanalysisd.photos.personpromoting
GraphVerifiedPersonCount
PromotingInterval
PromotingSequence
TotalFaceCount
UnverifiedPersonCount
UserVerifiedPersonCount
com.apple.Photos
Received action score %f - %f
=========%s==========
[%.2f - %.2f]: %.2f
capturePointSegmentIdx: %d
----[%.2f - %.2f]
startIdx = %d, endIdx = %d, count = %d, [%f, %f] with score %f captureTime=%f
interesting trim: [%f, %f], score = %.2f
 --[%.2f - %.2f]
===========SceneChangeSegments=============
[%f, %f]
Measurement
Min (s)
Max (s)
Avg (s)
Total
Count
Minimum
Maximum
Average
signpost
com.apple.mediaanalysisd.livephotoeffectanalysisresults
com.apple.mediaanalysisd.moviecurationresults
com.apple.mediaanalysisd.livephotokeyframeresults
com.apple.mediaanalysisd.das.dutycycle
com.apple.mediaanalysisd.das.dutycycle.task
com.apple.mediaanalysisd.analysis.pets
com.apple.mediaanalysisd.livePhotoFillingGaps
LivePhotoEffectsShortInputDecision
LivePhotoEffectsPreGateStillMetadataDecision
LivePhotoEffectsPreGateVideoTrimDecision
LivePhotoEffectsPreGateVideoMLDecision
LivePhotoEffectsPreGateFacesDecision
LivePhotoEffectsStabilizeGateDecision
LivePhotoEffectsPostGateDecision
LivePhotoEffectsFinalGateDecision
LivePhotoEffectsLoopActivityDecision
LivePhotoEffectsBounceActivityDecision
LivePhotoEffectsLongexpActivityDecision
LivePhotoEffectsStabilizeResult
MediaType
AutoPlayableScore
SummaryDuration
IsTrimmed
KeyFrameIsSuggested
KeyFrameScoreDifference
KeyFrameTimestampOffset
KeyFrameIsFaceQualityDominant
KeyFrameIsSharpnessDominant
KeyFrameIsSemanticDominant
KeyFrameIsSuggestedEdit
KeyFrameScoreDifferenceEdit
KeyFrameTimestampOffsetEdit
KeyFrameIsFaceQualityDominantEdit
KeyFrameIsSharpnessDominantEdit
KeyFrameIsSemanticDominantEdit
previousQoS
previousQoSDuration
requestedQoS
taskName
taskStatus
DownloadAssetCount
DownloadBytes
Duration
Delay
AvgSpeed
AssetType
NumberOfPetFacesDetected
NumberOfPetsDetected
ResourceType
SceneType
AggregatedBoundingBoxSizeRatio
LargestBoundingBoxSizeRatio
com.apple.mediaanalysis.coreanalytics
VCPMADCoreAnalyticsManager
@"VCPMADCoreAnalyticsManager"8@?0
SHMutableSignature
correlationNonInterleaved
[VCPAsset %@] should not be called
mediaType
mediaSubtypes
pixelWidth
pixelHeight
exif
imageWithPreferredDimension:
imageWithPreferredDimension:orientation
movie:
isMovieResourceLocalAvailable:
originalMovie:
Start
FramesPerSecond
v16@?0@"NSURL"8
VCPDownloadResource
inputBoundsX
inputBoundsY
inputBoundsHeight
inputBoundsWidth
sourceSizeHeight
sourceSizeWidth
homographyParams
cnn_pet_pose.espresso.net
cameramotiontype_head.espresso.net
cameramotionscore_head.espresso.net
VCPMADResourceManager
@"VCPMADResourceManager"8@?0
q24@?0@"VCPMADResourceEntry"8@"VCPMADResourceEntry"16
com.apple.mediaanalysisd.VCPMADResourceManager
DeviceClass
iPad
pLzf7OiX5nWAPUMj7BfI4Q
marketing-name
inputImage
angle
v24@?0@"MLModel"8@"NSError"16
Getting no object IDs when fetching assets on moment %@
Reachability initialization failed; assuming no connection
Reachability flags invalid; assuming no connection
%sonnected to internet via WiFi/Ethernet
Network reachability flag changed to: %@
Human action - no PHFaces found
Failed to lock CVPixelBuffer (%p, %d)
Cannot lock NULL CVPixelBuffer
Lock attempt failed; cannot unlock buffer
Multiple unlock attempts; cannot unlock buffer
Failed to unlock CVPixelBuffer (%p, %d)
Failed to allocate memory
[VCPVideoFullFaceDetector] Detected face %@
[VCPVideoFullFaceDetector] Failed to detect faces - %@
Failed to retrieve faceprint revision from key faces
Failed to create Vision clusterer - %@
Failed to cluster faces - %@
Creating faceprint for face crop
Multiple faces present in face crop; using first
Loading quick identification model
Performing quick identification
Quick identification match found: %@
No quick identification match found
Home face identification task failed (%@)
inferenceHandKeypointCallFromSPI
Failed to allocate textureness or dst buffer for image resolution %dx%d
[MediaAnalysis] Image descriptor - found more than 1 VNImageprintObservations
VNImageprint init error: %@
VCPClusterer: Terminating ...
VCPClusterer: Terminated
VCPClusterer: Cluster triggering set to %lu
VCPClusterer: Scheduling to remove %lu faces and add %lu faces
VCPClusterer: total remove %lu faces and add %lu faces
VCPFaceProcessingClusterFacesCoreAnalyticsCollection
VCPClusterer: Removing %lu faces from cluster cache
VCPClusterer: Failed to cluster(removing) faces - %@
VCPClusterer: Removed %lu faces from cluster cache [time: %f secs]
VCPClusterer: Adding %lu faces to cluster cache
VCPClusterer: Number of orderedFaceIdentifiers (%lu) != number of _faceIdStrsToAdd (%lu)
VCPClusterer: missing localIdentifiers : %@
VCPClusterer: %lu faces to cluster, already took %f seconds
VCPClusterer: %lu faces in current batch, %lu faces remain
VCPClusteringGetFaceObservations
VCPClusterer: Number of faceTorsoprintsToAdd (%lu) !=  number to cluster (%lu)
VCPClusterer: Failed to cluster(adding) faces - %@
VCPClusterer: Added %lu faces to cluster cache
VCPClusteringBatch
VCPClusterer: Added faces to cluster cache [time: %f secs]
VCPClusterer: Start clustering
VCPClusterer: Finished clustering %lu faces, with normalized %.2f millisecond per face
VCPClusterer: Vision failed to cluster - %@
[VisionFgMapping] Preparing Vision Clusters (size: %ld) to Photos FaceGroup
VCPVisionFgMapping_Prepare
VCPClusterer: Failed to save cluster cache - %@
VCPClusterer: Start to update database models
VCPClusterer: Failed to persist FaceGroups; will try next time - %@
VCPClusterer: Updated database models
VCPClusterer: Cannot cluster image print type %lu
VCPClusterer: Failed to get VNFaceTorsoprint from face %@ - %@
VCPClusterer: Missing faceprint data for face %@
VCPClusterer: Failed to remove empty FaceGroup(s) - %@
VCPClusterer: Start quick-syncing cluster cache with library
VCPClusterer: Failed to clean faces with valid CSN but not in any FaceGroup - %@
VCPClusterer: Failed to clean faces with CSN = 0 but found in any FaceGroup - %@
VCPClusterer: Number of clustered faces in the cluster cache (%lu) < number of clustered faces in the library (%lu)
VCPClusterer: Quick-syncing cluster cache with library, found > 10%% (%5.2f) difference in the number of faces that are in the cluster cache versus library
VCPClusterer: Finished quick-syncing cluster cache with library. Elapsed time: %f
VCPClusterer: Start syncing cluster cache with library ...
VCPClusterer: Retrieving clusters from cluster cache ...
VCPClusterer: Retrieved clusters from cluster cache
VCPClusterer: Failed to retrieve clusters from cluster cache - %@
VCPClusterer: Retrieving clusters from library ...
VCPClusterer: Retrieved clusters from library
VCPClusterer: Failed to retrieve clusters from library - %@
VCPClusterer: Syncing cluster cache with library, found %lu non-singleton clusters in the cluster cache that do not match those in the library
VCPClusterer: Syncing cluster cache with library, found %lu clusters in the library cache that do not match those in the cluster cache
VCPClusterer: Syncing cluster cache with library, found > 20%% (%5.2f) difference in the number of faces are in the cluster cache versus library
VCPClusterer: Failed to ungroup faces - %@
VCPClusterer: Successfully reset cluster cache - %@
VCPClusterer: Failed to reset cluster cache - %@ - %@
VCPClusterer: Deleting FaceGroups and reset CSN of all previously clustered faces
VCPClusterer: Canceled syncing cluster cache [point: %d do loop]
VCPClusterer: Retry deleting FaceGroups and reset CSN of all previously clustered faces. Attempt %d of %d.
VCPClusterer: Deleted FaceGroups and reset CSN of all previously clustered faces
VCPClusterer: Failed to delete face groups and reset CSN of all previously clustered faces - %@
VCPClusterer: Syncing cluster cache with library - %@
VCPClusterer: Schedule adding %lu faces to the cluster state
VCPClusterer: Failed to get faces that are no longer present in the library
VCPClusterer: Canceled syncing cluster cache [point: %d]
VCPClusterer: Schedule removing %lu faces from the cluster state
VCPClusterer: Finished syncing cluster cache with library - %@
%@ - %@
Creating VNClustererBuilder with context.processingVersion:%d, type: %@, cachePath: %@, faceprintRequestRevision-%lu threshold-%.2f, torsoprintRequestRevision-%lu threshold-%.2f
VCPClusterer: Started resetting cluster cache ... 
VCPClusterer: Failed to remove all cluster cache files - %@
VCPClusterer: Created a new cluster cache
VCPClusterer: Failed to save a new cluster cache - %@
VCPClusterer: Finished resetting cluster cache
VCPClusterer: Failed to create a new cluster cache - %@
VCPClusterer: Failed to get old vision cluster cache filenames from vision cluster state
VCPClusterer: Failed to remove cluster mmap file at '%@' - %@
VCPClusterer: Failed to restore Vision clustering state - %@
VCPClusterer: Failed to unarchive cluster cache data blob from '%@'
VCPClusterer: Resetting cluster cache files - %@
VCPClusterer: Started restoring cluster cache
VCPClusterer: Failed to restore cluster cache - %@
VCPClusterer: Failed to restore cluster cache
VCPClusterer: Failed to restore cluster cache with std::exception %s
VCPClusterer: Restored cluster cache. Clusterer bring-up state - %@, time to restore: %f secs
[VisionFgMapping] Checking l1-cluster %@ (%ld faces) for conflict
[VisionFgMapping] Resolving conflict l0-cluster %@ in l1-cluster %@
VCPClusterer: Failed to get Vision clusters - %@
VCPClusterer: Retrieving clusters in cluster cache ...
VCPClusterer: Failed to retrieve clusters in cluster cache - %@
VCPClusterer: Retrieving clusters in library ...
VCPClusterer: Failed to retrieve clusters in library - %@
VCPClusterer: Comparing clusters
VCPClusterer: Failed to remove cluster snapshot at '%@': %@
VCPClusterer: Failed to remove cluster mmap file at '%@': %@
VCPClusterer: Bring-up state transition: %@ -> %@
VCPClusterer - _calculateChecksumMD5ForFile: error reading %zu bytes from file
Not implemented, please use initWithOptions
Incompatible request (%@) specified to %@
[RemoveBackground][%@] running (Mask: %d, Crop: %d, In-Place: %d)...
[RemoveBackground][%@] Skipping for ineligible image
[RemoveBackground][%@] Checking for cached image handler...
[RemoveBackground][%@] Matched cached image handler(!)
[RemoveBackground][%@] No cached image handler
[RemoveBackground][%@] Cached image handler does not match
[RemoveBackground][%@] Resetting cached image handler
VCPMADVIRemoveBackgroundTask image loading failed
[RemoveBackground] Image is screenshot - detecting ROI
[RemoveBackground] Failed to detect screenshot ROI (%@)
[RemoveBackground] Screenshot has no ROI (%@)
[RemoveBackground] Screenshot ROI: (%0.2f, %0.2f) %0.2fx%0.2f Confidence: %0.2f [1 of %d]
VNImageRequestHandler_init
[RemoveBackground] Set VNProcessingDevice: %@ (%@)
[RemoveBackground] Perform-in-place requested for ineligible input; ignoring
[%@] In Place: %d Crop: %d  Mask: %d  ROI: (%0.2f, %0.2f) %0.2fx%0.2f
VNImageRequestHandler_performRequests
[RemoveBackground][%@] Caching image handler (resolution %dx%d, orientation %d)
[RemoveBackground] No observations produced for image
[RemoveBackground][%@] complete
Invalid VNRequest configuration (%@)
VNRequest must be non-nil
[MediaAnalysis][%@] Analysis requested for blacklisted asset
[MediaAnalysis][%@] Existing analysis based on old modification
[MediaAnalysis][%@] Existing analysis based on degraded asset
[MediaAnalysis][%@] Existing analysis satisfies request (%@)
[MediaAnalysis][%@] Existing analysis doesn't match asset state
[MediaAnalysis][%@] Existing analysis doesn't satisfy request (%@)
[MediaAnalysis][%@] Generating analysis on-demand: %@
  [%@] Analysis cancelled
  [%@] Analysis failed to complete
Unsupported photo analysis type %@
Unsupported movie analysis type %@
VCPFullAnalysisAssetProcessingTask
VCPFullAnalysisAssetProcessingTask processing failed
Media analysis client XPC connection interrupted
Media analysis client XPC connection invalidated
[MediaAnalysis] [MediaAnalyzer requestAnalysisTypes] call with invalid resourceURLs
Failed to issue sandbox extension on %@
[MediaAnalysis] Error connecting to background analysis service
[MediaAnalysis] Request %d has completed
[MediaAnalysis] Error connecting to Photos background analysis service
[MediaAnalysis] Unsupported task %lu
[MediaAnalysis] Asset processing request %d has completed
In-Process quick face identification not supported
[MediaAnalysis] Error connecting to Photos Quick Face Identification service
[MediaAnalysis] Request %d is %.2f%% complete
[MediaAnalysis] Unknown analysis request %d; dropping cancellation request
[MediaAnalysis] No active analysis requests; dropping cancellation request
[MediaAnalysis] Failed to cancel background analysis: %@
[MediaAnalysis] Background analysis canceled
[MediaAnalysis] Error connecting to background analysis service: %@
[MediaAnalysis] Error connecting to request PersonPromoterStatus service
[MediaAnalysis] Request Person Preference %d has completed
[MediaAnalysis] Request VIP model filepath Preference %d has completed
[MediaAnalysis] Error connecting to request SuggestedPersons service
[MediaAnalysis] Request SuggestedPersons %d has completed
[MediaAnalysis] Error connecting to request UpdateKeyFacesOfPersons service
[MediaAnalysis] Request UpdateKeyFacesOfPersons %d has completed
[MediaAnalysis] Error connecting to request FaceCandidatesforKeyFace service
[MediaAnalysis] Request FaceCandidatesforKeyFace %d has completed
[MediaAnalysis] Error connecting to request ResetFaceClassificationModel service
[MediaAnalysis] Request ResetFaceClassificationModel %d has completed
[MediaAnalysis] Error connecting to request ResetPetClassificationModel service
[MediaAnalysis] Request ResetPetClassificationModel %d has completed
[MediaAnalysis] Error connecting to request SuggestedMePersonIdentifier service
[MediaAnalysis] Request SuggestedMePersonIdentifier %d has completed
[MediaAnalysis] Request PersonPromoterStatus %d has completed
[MediaAnalysis] Error connecting to request Face and Person workflow
[MediaAnalysis] Request Face and Person workflow %d has completed
[MediaAnalysis] Error connecting to request ClusterCacheValidation service
[MediaAnalysis] Request ClusterCacheValidation %d has completed
[MediaAnalysis] Error connecting to request ResetFaceClusteringState service
[MediaAnalysis] Request ResetFaceClusteringState %d has completed
[MediaAnalysis] Error connecting to request ReclusterFaces service
[MediaAnalysis] Request ReclusterFaces %d has completed
[MediaAnalysis] Error connecting to request RebuildPersons service
[MediaAnalysis] Request RebuildPersons %d has completed
[MediaAnalysis] Error connecting to query AutoCounter Opt-In status service
[MediaAnalysis] Query AutoCounter Opt-In status %d has completed
[MediaAnalysis] Error connecting to request Opt-In AutoCounter
[MediaAnalysis] Request Opt-In AutoCounter %d has completed
[MediaAnalysis] Error connecting to request AutoCounter dump
[MediaAnalysis] Request AutoCounter dump %d has completed
[MediaAnalysis] Error connecting to request AutoCounter calculation
[MediaAnalysis] Request AutoCounter calculation %d has completed
[MediaAnalysis] Request AutoCounter SIML validation %d has completed
[MediaAnalysis] Faces must be non-empty and completion block must be non-nil
[MediaAnalysis] Faces must all be from the same Photo Library
[MediaAnalysis] Error connecting to Media Analysis
[MediaAnalysis] nil specified for non-nullable parameter
VCPVideoCaptionEncoder: start loading model at: %@
VCPVideoCaptionEncoder: model to load %@
VCPVideoCaptionEncoder: inputBlob.nframes = %d, inputBlob.height = %d, inputBlob.width = %d, inputBlob.channels = %d
VCPVideoCaptionEncoder: successfully loaded model
 keypointsToObservation - unexpected keypoints count
incompatible input buffer size/format, check requiredInputFormat
CVNLPCommSafetyHandler_init
Failed to create CVNLPCommSafetyHandler: %@
VCPMADImageSafetyClassificationTask running...
VCPMADImageSafetyClassificationTask image loading failed
VCPMADImageSafetyClassificationTask image pre-processing failed
CVNLPCommSafetyHandler_scale
CVNLPCommSafetyHandler unavailable for classifying pixel buffer
CVNLPCommSafetyHandler_classifyPixelBuffer
VCPMADImageSafetyClassificationTask failed (%@)
VCPMADImageSafetyClassificationTask complete
[VCPPhotosFace] faceprint.confidence is too low (%.3f < 0.1) %@ - junkinessIndex: %.3f
[VCPPhotosFace] Accepting faceprint with confidence: %.3f %@ - junkinessIndex: %.3f
[VCPPhotosFace] Missing results for roll information
[VCPPhotosFace] Missing results from VNDetectFaceCaptureQualityRequest
[VCPPhotosFace] Missing results for yaw information
[VCPPhotosFace] Missing results from VNDetectFaceExpressionsRequest
[VCPPhotosFace] Missing results from VNClassifyFaceAttributesRequest
[VCPPhotosFace] Gaze: mask: %s, VNFaceGazeDirection: %@, PHFaceGazeType: %@ at (%.3f, %.3f)
[VCPPhotosFace] Missing results from VNDetectFaceGazeRequest
[PhotosFace] Fail to generate VCPPhotosFace from %@ and %@ - %@
[PhotosFace] Generate VCPPhotosFace %@ from %@ and %@
[PhotosFace] Fail to generate VCPPhotosFace %@ from %@ and %@ - invalid imageprint
[PhotosFace] Fail to generate face only VCPPhotosFace from %@ - %@
[PhotosFace] Generate face only VCPPhotosFace %@ from %@
[PhotosFace] Fail to generate VCPPhotosFace %@ from %@ - invalid imageprint
[PhotosFace] Failed to serialize torsoprint; %@
[PhotosFace] torsoOnlyObservation failed to return a faceprint
[PhotosFace] Ignoring co-locating animalObservation %@
[PhotosFace] Unable to determine normalized bounding box { { %f, %f } { %f, %f } }
[PhotosFace] Failed to serialize animalprintData; %@
[PhotosFace] animalObservation failed to return a faceprint
[PhotosFace] Generate VCPPhotosFace %@ from %@
[PhotosFace] IoU %f %@ %@
[VCPCNNEspressoContext] created CPU context
[VCPCNNEspressoContext] Failed to CPU context
[VCPCNNEspressoContext] created MPSGraph context
[VCPCNNEspressoContext] Failed to create MPSGraph context, fall back to CPU context
[VCPCNNEspressoContext] created preferred context
[VCPCNNEspressoContext] Failed to create ANE context, fall back to MPS context
[VCPCNNEspressoContext] Failed to create MPS context, fall back to CPU context
[VCPCNNEspressoContext] sharing CPU context
[VCPCNNEspressoContext] sharing MPSGraph context
[VCPCNNEspressoContext] sharing preferred context
[VCPCNNEspressoContext] dealloc shared context; keep alive
[VCPCNNEspressoContext] dealloc context;
[VCPCNNEspressoContext] No valid context; skip dealloc
Choosing asset resource from preferred list: %@
Network is available, filtering list to remove the CPL Thumb, new list is: %@
No resources locally available, returning a downloadable hi-res resource: %@
[Face] Failed setting %@ private revision: %@, umbrellaVersion: %d
[FaceConfiguration] No proper vision model revision for %@ with umbrellaVersion: %d
VCPObjectPool failed to allocate object
Failed to get the ideal size of request %@ with revision %lu
Failed to set %@::setRevision %lu: %@
Request %@ (revision %lu) ideal size %@
Ideal size for request %@ not cached
[MediaAnalysis] Junk analayzer - unexpected %d VNObservations
VIService_init
[CNNModelEspresso] Creating %@context for %@
[CNNModelEspresso] Created %scontext (CPU:%d, MPSGraph:%d)), storage type %d
Invalid sceneprint revision: %lu (required %lu)
Failed to open analysis database for Photo Library (%@)
Specified Photo Library has no URL (<%@>); cannot find analysis database
Cloning model: %@
Deleting old clone directory for caption model: %@
Could not delete old clone directory for caption model: %@. error: %@
Creating clone directory for caption model: %@
Could not create clone directory for caption model: %@. error: %@
Cloning caption model: '%@' to: '%@'
Could not clone caption model. clonefile(%@, %@, %o) FAILED with (%d : %s)
Video captioning mode: VCPVideoCaptionMode_Off
Download meta data reply %ld
Queried asset metadata with result: %ld
No video caption encoder query results
Asset %@ not present - downloading
Progress callback: %lld %lld
Downloaded asset with result %li, error? %@
Space not available to download asset %lli
Video caption decoder test model not exist at %@, skip video caption analysis
Unable to obatain video caption decoder model from Accessibility
Video caption encoder test model not exist at %@, skip video caption analysis
Failed to create CVNLPVideoCaptioningModel (%@)
Error to generate video caption with CVNLPVideoCaptioningModel (%@)
Incomparable images: this - %@ vs that - %@
VCPVideoKeyFrameBlurAnalyzer
VCPVideoKeyFrameFaceQualityAnalyzer
Query progress: unsupport taskID %lu - %@
Query progress: output parameter statistics must be non-nil
Query progress: scan library for %lu - %@
VCPAnalysisProgressQueryScanPhotoLibraryFetch
Query progress: unsupported taskID (%lu)
VCPAnalysisProgressQueryExpressPathFetchTotalCount
VCPAnalysisProgressQueryExpressPathFetchProcessedCount
Query progress: unsupported taskID (%@)
VCPAnalysisProgressQueryProgressDetail
VCPAnalysisProgressQueryProgress
Query cached face progress: %lu out of %lu
VCPAnalysisProgressQueryCachedFaceAnalysisProgress
[EmbeddingOnDemand] Incompatible request (%@) specified to %@
[EmbeddingOnDemand] Incompatible imageAsset (%@) specified to %@
VCPMADEmbeddingGenerationTask not supported on this platform
Multiple sampling times (%0.1fs) intersect frame at %lld/%d
%@ skipping sample %lld at %lld/%d
%@ failed for sample at %lld/%d (%@)
QuickFaceID: Failed to create faceprint from data : %@
QuickFaceID: Failed to create animalprint from data : %@
QuickFaceID: Passing classify face confidence: %f
QuickFaceID: Failed passing classify face confidence: %f
QuickFaceID: Failed to predict at all
QuickFaceID Pet: Passing classify pet confidence: %f
QuickFaceID Pet: Failed passing classify pet confidence: %f
QuickFaceID Pet: Failed to predict pet at all
QuickFaceID %@ Model path is nil; skip loading
Failed to load VIP %@ Model
No persistentStorageDirectoryURL for photoLibrary: %@
Unable to serialize library analysis preferences for %@: %@
Unable to write library analysis preferences for %@: %@
Key for setLibraryAnalysisPreferencesValue is nil
Failed to fetch VIP model file path with unknown VCPMAVIPType (%lu)
Failed to fetch VIP model last generation date with unknown VCPMAVIPType (%lu)
Not requiring processing for unknown taskID %lu
Fail in generating motion flow
[FaceModelBump] Failed to update version state - %@
[FaceModelBump] No persistentURL to update version state - %@
[FaceModelBump] Resetting face data ... (%@)
[FaceModelBump] Failed to reset Face Analysis data for PhotoLibrary %@
Face Quality Results mismatch with detected Faces (%lu vs %lu)
Error: FaceQualityScore should not contain results! (size = %lu, timestamp=%.2f)
time=%.2f sharpness=%.2f, faceSharpness=%.2f, cameraM=%.2f, subjectM=%.2f, junk=%.2f, obstr=%.2f, exposure=%.2f, score=%.2f
Error -[VNCreateSceneprintRequest setRevision:error:]
Error -[VNImageRequestHandler requestHandler:error:]
NSKeyedUnarchiver error: %@
 VCPFaceShapeModel - caught exception in find_min_box_constrained()
VCPFaceShapeModel - caught exception in find_min()
 VCPFaceShapeModel - caught exception in find_min_using_approximate_derivatives()
Query context: %@
VCPMADVITextLookupTask running...
VCPMADVITextLookupTask image loading failed
VCPMADVITextLookupTask failed to create text lookup query context (%@)
VIService_TextLookup
VCPMADVITextLookupTask complete (%d)
%@ does not implement purge
Real-time analysis client XPC connection interrupted
Real-time analysis client XPC connection invalidated
Pixel buffer not IOSurface-backed; dropping analysis request
Real-time analysis client XPC connection error
Not all needed analysis are available for video highlights.
[%.2f - %.2f] expressionScore=%.2f, actionScore=%.2f, voiceScore=%.2f, Score=%.2f
[%.2f - %.2f] keyFrameScore=%.2f, expressionScore=%.2f, actionScore=%.2f, voiceScore=%.2f, humanActionScore=%.2f, humanPoseScore=%0.2f, qualityJunkScore = %.2f, mlQualityScore = %.2f, Score=%.2f
[HomeKit] Failed to connect to analysis service (%@)
[HomeKit] VCPHomeKitAnalysisSession initialization fails (%@)
[HomeKit] Client XPC connection interrupted
[HomeKit] Client XPC connection invalidated
[HomeKit] Error connecting to background analysis service
[VCPDatabaseReader] No database file exists
[VCPDatabaseReader] Failed to open database: %d
[VCPDatabaseReader] Failed to set busy handler: %d
[MediaAnalysis] Unknown result key for result type %u
[VCPDatabaseReader] Database already opened, failed to execute query block: %d
[VCPDatabaseReader] Failed to execute query block: %d
[MediaAnalysis] Error querying blacklist status for %@
[MediaAnalysis] Failed to query blacklisted assets
[MediaAnalysis] Failed to query asset %@
[MediaAnalysis] Failed to query analysis properties of asset %@
[MediaAnalysis] queryAnalysesForAssets Failed
[MediaAnalysis] Failed to query assets since %@
[MediaAnalysis] Failed to query failed assets for taskID: %lu
[MediaAnalysis] WARNING: ProcessingStatus entry with nil localIdentifier
Failed to query KeyValueStore (error code: %d)
Failed to query scheduling history for background activity %@
[VCPDatabaseReader] Error SQLITE_BUSY encountered, attempting first retry
[VCPDatabaseReader] busy timeout has passed since first retry, stop retrying
Failed to extract NSArray from column %d (%@)
Orientation value %u invalid, assuming kCGImagePropertyOrientationUp
Running Home Resident Maintenance task
Canceling Home Resident Maintenance task (%d)
HomeAI request submitted (%d)
[VCPMADServiceImageProcessing] Fetching Photos asset with identifier %@
[VCPMADServiceImageProcessing] Fetch returned multiple assets for identifier (%@)
[ImageProcessingTask%d] Build task for asset (%@)
[ImageProcessingTask%d] Failed to fetch asset (%@) - %@
[ImageProcessingTask%d] Failed to process asset (%@) - %@
[ImageProcessingTask%d] Finished processing asset (%@)
Request canceled
%@ returned unexpected status (%d)
VCPMADServiceImageProcessingTaskBatch_Run
Failed to create VNGeneratePhotosAdjustmentsRequest
Failed to set VNGeneratePhotosAdjustmentsRequest::setRevision %lu: %@
VNGeneratePhotosAdjustmentsRequest failed
[FaceCropGeneration] Scaling down from %.0fx%.0f with factor: %.3f
[FaceCropGeneration] Scaling up from %.0fx%.0f with factor: %.3f
Invalid orientation found: %d. Using a default value of 1
 [%@] QuickFaceDetect: failed to persist classification results: %@
   [%@] Ignoring analysis results for Montage asset
 [%@] QuickFaceDetect: analyzing asset (deferType: %d)
 [%@] QuickFaceDetect: processed %lu faces
[SceneNet] Failed to find label for identifier %d
[NSFW] Failed to find label for identifier %d
VCPMADVIMachineReadableCodeDetectionTask running...
[MRC] Custom request configuration; overriding to use cached data
VCPMADVIMachineReadableCodeDetectionTask image loading failed
Failed to configure VNDetectBarcodesRequest
[MRC] Custom request configuration; not persisting result
VCPMADVIMachineReadableCodeDetectionTask complete
Flow decoder: fail to bind inputFeature
Flow decoder: fail to bind correlation
Flow decoder: fail to bind upscaled flow
Flow decoder: fail to bind output flow
Flow decoder: fail to bind buffers
Flow decoder: executing callback
Flow decoder: fail to execute
    Pixel Stabilization confidence doesn't pass the threshold
Found %lu faces with CSN > 0 but not in any face groups
[VisionFgMapping] Vision Cluster with single l0clusters; skip de-conflict
[VisionFgMapping] Vision Cluster contains %lu conflicting people
[VisionFgMapping] Conflicting person %@
[VisionFgMapping] Vision Cluster has conflicting l0cluster %@
[VisionFgMapping] Vision Cluster does not have conflicting l0clusters
[VisionFgMapping] Persisting %ld Vision Clusters to Photos FaceGroup
[VisionFgMapping] Invalid csn (%@) for newly clustered face %@
VisionFgMapping_LookingAfterNewClusteredFace
VisionFgMapping_LookingForConflictingCluster
[VisionFgMapping] Split Cluster %@ with %ld faces with representing face csn %@
[VisionFgMapping] 
 csn: %ld 
[VisionFgMapping] Cannot exclude invalid l0RepresentingCSN %@ in l1Cluster %@
[VisionFgMapping] Output (remaining) Cluster %@ -> %@ with %ld faces
VisionFgMapping_ResolveConflictingCluster
[VisionFgMapping] Output (no-touch) Cluster %@ with %ld faces
VisionFgMapping_ResolveConflictL0Clusters
VisionFgMapping_Process
PersistFaceGroups: Photo library is missing a face with CSN = %@
PersistFaceGroups: Faces with these CSNs will be removed from the cluster cache: %@
PersistFaceGroups: Faces with these localIdentifiers will be re-clustered: %@
PersistFaceGroups: We should not get here! If we did, then we have a previously clustered face without a face group!
PersistFaceGroups: Failed to create a face group change request to add faces!
PersistFaceGroups: Failed to find a faceGroup for face '%@' with CSN: %d
PersistFaceGroups: No faces added to face groups!
PersistFaceGroups: Failed to find face with localIdentier: %@. Could not set its CSN to %@
PersistFaceGroups: Set personBuilderState of faceGroups: %@
PersistFaceGroups: Failed to delete empty face groups with error: %@
PersistFaceGroups: Canceled updating key faces unverified persons after persisting face groups.
PersistFaceGroups: Failed to update key faces unverified persons after persisting face groups. Error: %@
%s: %@
[UpdateKeyFaces] Person %@ already has a keyface; skipping
[UpdateKeyFaces] Failed to find a representing face for Person %@ (verified type %ld)
[UpdateKeyFaces] Updating Person %@ (verified type %ld) with key face %@
[UpdateKeyFaces] Found %lu face groups for unverified person)
[UpdateKeyFaces] Failed to persist key face - %@
Warning: cannot handle representativeness with imageprint type %d; ignoring
Warning: Couldn't get faceprint data for face: %@; ignoring
representativeness selection receives a torso-only print; ignoring
Failed to get VNFaceTorsoprint from faceprint data - %@
Warning: Could not get representativeness for faces, error: %@
PersonBuilder: Deleted duplicate graph-verified persons '%@' from face group %@
PersonBuilder: Failed to delete duplicate graph-verified persons '%@' from face group %@
PersonBuilder: Deduped graph-verified persons '%@' from face group %@
PersonBuilder: Failed to dedupe graph-verified persons '%@' from face group %@
personLocalIdentifier for PHFace %@ is null; skip processing
Found no persons rejected for a rejection training face: %@
PersonBuilder: Did not find merge candidate persons with local identifiers: '%@'
PersonBuilder: Found invalid merge candidate pair ['%@' : '%@']
PersonBuilder: Already found merge candidate pair ['%@' : '%@']
PersonBuilder: persist results for facegroup %@
PersonBuilder: Could not create merge candidate pair '%@' : '%@'
PersonBuilder: Could not create invalid merge candidate pair '%@' : '%@'
PersonBuilder: Cleared personBuilderState of faceGroup: '%@'
Could not find a face with clusterSequenceNumber '%@' in the library
%@ Checking face %@
%@ Failed to find face
%@ No valid person
%@ Found person(s) %@
%@ Person mismatch: face (%@) personLocalIdentifier %@ vs faceCropPerson %@ (%ld)
[FaceCropAdjustment] Correcting %lu training face -> person
[FaceCropAdjustment] Failed to find person for face %@
[FaceCropAdjustment] Correcting face %@ from %@ to %@, with nameSource:%ld
[FaceCropAdjustment] Checking %lu rejected person(s)
[RejectedFaceCrop] To remove face %@ for person %@
[FaceCropAdjustment] Removing %lu faces for person %@
[FaceCropAdjustment] Remove face %@ for person %@
[FaceCropAdjustment] Failed to update person - %@
[PHFaceCrop Dedupe] PHFaceCrop without localIdentifier - %@
[PHFaceCrop Dedupe] PHFace without localIdentifier - %@
[PHFaceCrop Dedupe] Missing PHFaceX[%@]
[PHFaceCrop Dedupe] PHFaceX[%@] without faceprint
[PHFaceCrop Dedupe] Missing PHFaceY[%@]
[PHFaceCrop Dedupe] Unmatched training type PHFaceX[%@](%d) and PHFaceY[%@](%d)
[PHFaceCrop Dedupe] PHFaceY[%@] without faceprint
[PHFaceCrop Dedupe] Duplicated with distance: %f [%@:%d] vs [%@:%d]
[PHFaceCrop Dedupe] Distance: %f [%@] vs [%@] - %@
[PHFaceCrop Dedupe] Processing duplications
[PHFaceCrop Dedupe] %lu duplications - %@
[PHFaceCrop Dedupe] Removing %@ dupe to %@
[FaceCrop] Processing newly clustered face crops in %lu PHFaceGroup; start processing ...
[FaceCrop] Fetched %lu PHFaceCrop in PHFaceGroup (%@); skip
[FaceCrop] Fetched %lu newly clustered PHFaceCrop in PHFaceGroup (%@); skip
[FaceCropAdjustment] Fetched %lu PHFaceCrops in PHFaceGroup (%@); start processing ...
[FaceCropAdjustment] Processing finished
[PHFaceCrop Dedupe] Fetched %lu PHFaceCrop in PHFaceGroup (%@); skip
[PHFaceCrop Dedupe] Fetched %lu PHFaceCrops in PHFaceGroup (%@); start dedupping ...
[FaceCrop] Updated %lu PHFaceCrops
[FaceCrop] Failed to update %lu PHFaceCrops - %@
[FaceCrop] Removed %lu duplicated PHFaceCrops
[FaceCrop] Failed to remove %lu duplicated PHFaceCrops - %@
MADProcessNewlyClusteredFaceCrops
PersonBuilder: Got a 'nil' photoLibrary. Cannot build persons
PersonBuilder: Failed to find unverified person for faceGroups '%@'; These will be fixed up and retried later
PersonBuilder: Failed to fix up face groups without unverified person. Error: '%@'
PersonBuilder: Person Building faceGroup '%@'
PersonBuilder: Failed to find unverified person [unverifiedPerson: %@, unverifiedPersonLocalIdentifier: %@] for faceGroup '%@', skipping this face group
%lu Quick classification face to retain: %@
%lu Quick classification face to reassign: %@
PersonBuilder: Quick classification face: %lu retained, %lu reassigned
[VisionFgMapping] Failed to find conflicting l0cluster (expect csn: %@)
PersonBuilder: We may have a dirty level0 cluster, persons with training faces: %@
PersonBuilder: We may have a dirty level0 cluster, verified persons with confirmed face: %@
PersonBuilder: Unnamed unconfirmed faces in face group, '%@', without a training face: %@
PersonBuilder: Found training rejection, unassigned faces on trainingPersonLocalIdentifier in level0 cluster: %@
PersonBuilder: Skip processing level0 cluster since we have rejected face for training person '%@' in level1 cluster
PersonBuilder: Failed to build persons [Error: '%@']
PersonBuilder: ---> buildPersonWithFaceClusterer, %s
VCPFaceProcessingBuildPersonsCoreAnalyticsCollection
PersonBuilder: Person Building is Disabled!
PersonBuilder: Cleared personBuilderState of faceGroups: %@
PersonBuilder: Failed to clear personBuilderState of faceGroups: %@, error: %@
PersonBuilder: <--- buildPersonWithFaceClusterer
Got a 'nil' photoLibrary. Cannot remove auto assigned faces
Failed to remove auto-assigned faces from person '%@', error: %@
  [%@] No scene classification result fetched from pre analysis
Scene identifier %u has no name; ignoring
[MediaAnalysis][%@] No slow-mo timestamp mapping file URL found
[MediaAnalysis][%@] No slow-mo timestamp mapping file found
[%@] Asset has no small video derivative; cannot download
VCPMADVIDocumentRecognitionTask running...
[DocumentRecognition] Custom request configuration; overriding to use cached data
VCPMADVIDocumentRecognitionTask image loading failed
[DocumentRecognition] Set VNProcessingDevice: %@ (%@)
[DocumentRecognition] Custom request configuration; not persisting result
VCPMADVIDocumentRecognitionTask complete
Cannot load Person Identity Model - %@
Person Identity Model not exist - %@
PersonIdentityModel_init
[%@] running...
[%@] complete
[%@] complete without on-demand process
[%@] image loading failed
VCPMADPersonIdentificationTask_createVisionImageRequest
VCPMADPersonIdentificationTask_detectFace
[%@] No face detected from CVPixelBuffer
[%@] Detected %lu faces, identifying ...
[%@] Detected %lu faces, identifying top %lu faces (by confidence) ...
VCPMADPersonIdentificationTask_generateFaceprint
[%@] No face to identify from CVPixelBuffer
[%@] Failed to classify face (%@) - %@; skipping
[%@] No valid identification to face (%@); skipping
[%@] prediction: %@, confidence: %.3f at %@
[%@] Failed to fetch person with identifier %@; skipping
[%@] Identified %lu faces
VCPMADPersonIdentificationTask_identifyFace
[%@] complete with on-demand analysis
Unknown Media Analysis version specified (%d)
[MediaAnalysis] No slow-mo timerange mapper available, fall back to Scaled Time
[MediaAnalysis] No slow-mo timerange mapper available, fall back to Original Time
Invalid Live Photo Gating result type key [%@]
VCPVersionForTask not implemented for %@ (%d); using MediaAnalysisVersion (%d)
  [%@] Unknown analysis version %d; discarding
Failed to get memory information
Failed to query supported revision; %@ does not support
Unsupported revision (%lu) for %@
Checking revision for %@ is not supporteds
Feature extractor: fail to bind input
Feature extractor: fail to bind output at level %d
Feature extractor: fail to bind buffers
Feature extractor: executing callback
Feature extractor: fail to execute
[OCR][%@] Re-using cached results
[VS][%@] Re-using cached results
VCPMADServiceImageURLAsset_Decode
VCPMADServiceImageDataAsset_Decode
[Faces][%@] Asset not processed or outdated
[Faces][%@] Loading existing results from Photos
[NSFW][%@] Asset not processed or outdated
[NSFW][%@] Loading existing results from Photos
[SceneNet][%@] Asset not processed or outdated
[SceneNet][%@] Loading existing results from Photos
[SceneNet] No scene label name for scene id %d
[%@] Ineligible Confidence: %0.3f
[%@] Ineligible Confidence: -
[%@] Selecting resource for Asset Type: %@ [%d/%d] Resolution: %dx%d
[%@] Evaluating resource (Type: %d Resolution: %dx%d)
[%@] Resource not locally available; skipping resource
[%@] Purging resource cache to load uncommon resource (%@)
[%@] Purging resource cache to load large resource (%dx%d)
[%@] Failed to load orientation
[%@] Loaded resource (Type: %d Actual Resolution: %dx%d, orientation %d)
[%@] Failed to load resource (Type: %d)
VCPMADServiceImageAsset_Decode
[%@] Failed to find/decode high-res image resource
[%@] Evaluating high-resolution resource (Type: %d Resolution: %dx%d)
[%@] Evaluating fall-back resource (Type: %d Resolution: %dx%d)
[%@][%@] Deferring persistence until OCR available
[%@][%@] Deferring persistence until MRC available
[%@][%@] Asset has invalid adjustment version (%@); cannot persist results to Photos
[%@][%@] Persisting results to Photos
VNDocumentObservation_archive
[%@][%@] Failed to archive OCR observation
[%@][%@] No text recognized; skipping archive/persistence
VNBarcodeObservation_archive
[%@][%@] Failed to archive MRC observations
[%@][%@] No MR Codes recognized; skipping archive/persistence
[%@][%@] Successfully persisted results to Photos
[%@][%@] Failed to persist results to Photos
[OCR][%@] Checking for existing results from Photos
[OCR][%@] Loading existing results from Photos
[OCR][%@] Failed to unarchive existing Photos results
[OCR][%@] Photos results exist, but no text was recognized
[OCR][%@] Asset does not have existing results
[OCR][%@] Successfully reused existing results
[MRC][%@] Checking for existing results from Photos
[MRC][%@] Loading existing results from Photos
[MRC][%@] Failed to unarchive existing Photos results
[MRC][%@] Photos results exist, but no text was recognized
[MRC][%@] Asset does not have existing results
[MRC][%@] Successfully reused existing results
[VS][%@] Checking for existing results from Photos
[VS][%@] Loading existing results from Photos
[VS][%@] Photos results exist, but empty
[VS][%@] Asset does not have existing results
[VS][%@] Successfully reused existing results
[VS][%@] Asset has invalid adjustment version (%@); cannot persist results to Photos
[VS][%@] Persisting results to Photos
[VS][%@] Successfully persisted results to Photos
[VS][%@] Failed to persist results to Photos
[FaceCropManager][%@] Publish facecrop for face %@
[FaceCropManager][%@] No face detected; force faceprinting
[FaceCropManager] Failed to create VCPPhotosFace - %@
[FaceCropManager][%@] Failed to faceprint - %@
[FaceCropManager][%@] Failed to associate with face %@ - %@
[FacecropManager][%@] Associated with face %@
[FacecropManager] Updating faceprint for face %@
[FaceCropManager][%@] Failed to generate FaceCrop face - %@
[FaceCropManager][%@] Failed to update faceprint of associated face %@  - %@
[FaceCropManager] Set personBuilderState of faceGroup %@ for face %@
[FaceCropManager][%@] Analyzing facecrop (%.0fx%.0f)
[FaceCropManager][%@] Not in a dirty state (state:%d, expect:%d); skipping process
[FaceCropManager][%@] FaceCrop does not have data
[FaceCropManager][%@] existing face %@
[FaceCropManager][%@] Failed to update associated face %@ - %@
[FaceCropManager][%@] Failed to record needing to Person Building for face %@ - %@
[FaceCropManager][%@] Asset has face; skip facecrop generation
[FaceCropManager][%@] Facecrop will not be generated for the manual face %@
[FaceCropManager][%@] Too small facecrop (%.0fx%.0f) using resource %@ (%@)
[FaceCropManager][%@] Generated %lu facecrop(s)
[FaceCropManager] Library has %lu dirty face crops to analyze
[FaceCropManager] Failed to process dirty facecrop %@ - %@
VCPFaceProcessingDirtyFaceCrops
QuickFaceID Model: persistent storageDirectoryURL is nil
QuickFaceID Model: cannot load Persons Model: %@
VCPPersonVIPLoadModel
QuickFaceID Model: model with VNCreateFaceprintRequest revision %lu (FaceProcessing Version%d)
QuickFaceID Model: system is using VNCreateFaceprintRequest revision %lu (FaceProcessing Version%d)
QuickFaceID: failed to initialize face analyzer
QuickFaceID Pet Model: persistent storageDirectoryURL is nil; skip loading Model
QuickFaceID Pet Model: cannot load Model: %@
VCPPetVIPLoadModel
[%@] QuickFaceID: matching person %@
[%@] QuickFaceID: no matching person at location (%.3f, %.3f) - %@
[%@] QuickFaceID: no matching person at location (%.3f, %.3f)
[%@] Ignoring analysis results for Montage asset
QuickFaceID Persons Model is not ready; skip processing
[%@] QuickFaceID: analyzing asset (deferType: %d)
[%@] QuickFaceID: asset is not image
[%@] QuickFaceID: detecting faces
[%@] QuickFaceID: %lu detected faces
[%@] QuickFaceID: processed %lu faces
VCPPersonVIPAssetProcessing
QuickFaceID Pets Model is not ready; skip classifying
QuickFaceID Pet: pet (PHFace) %@ already has a nameSource %ld for petPerson %@; skip
QuickFaceID Pet: pet (PHFace) %@ is used to train this VIP model with petPerson %@; skip
QuickFaceID Pet: Could not create animalprint for pet (PHFace) %@ - %@
QuickFaceID Pet: Failed to classify %@ - %@; skip
QuickFaceID Pet: did not match %@ (at %.3f, %.3f)
QuickFaceID Pet: classified %@ to petPerson %@
QuickFaceID Pet: no petPerson %@; skipping
QuickFaceID Pet: failed to persist pet classification results: %@
QuickFaceID Pet: classified and persisted %lu Pet PHFace
[PersonIdentification] Unsupported library - %@
[PersonIdentification] No face needs to identify
[PersonIdentification] Identifying %lu faces
[PersonIdentification] VIP Persons Model is not ready
[PersonIdentification][%@] Failed to obtain faceprint; skipping
[PersonIdentification][%@] Failed to obtain face observation; skipping
[PersonIdentification][%@] Face identification process failed (%@); skipping
[PersonIdentification][%@] Face identified as %@ confidence:%.2f
[PersonIdentification][%@] Face not identified, confidence:%@
[PersonIdentification] Identified %lu out of %lu faces
[PersonIdentification] Successfully persisted identification results
[PersonIdentification] Failed to persist identification results - %@
QuickFaceID Model: unknown VIP type (%lu); no entity fetched
QuickFaceID Pets Model: Begin Pets model generation
QuickFaceID Pets Model: Failed to initialize VNAnimalObservation
QuickFaceID Pets Model: Failed to create VNEntityIdentificationModelConfiguration - %@
Failed to create VNMutableEntityIdentificationModel - %@
QuickFaceID Pets Model: Model generation cancelled; quitting
QuickFaceID Pets Model: petPerson: %@, petFaceFetchResult(%lu): %@
QuickFaceID Pets Model: Could not create animalprint for pet (PHFace): %@ - %@
QuickFaceID Pets Model: Could not add animalObservation to model for pet (PHFace): %@.
QuickFaceID Pets Model: animalObservations(%lu): %@
QuickFaceID Pets Model: Could not add animalprint to model - %@
VCPPetVIPGenerateModel
QuickFaceID Pets Model: Finished model generation
QuickFaceID Pets Model: Failed to persist pet model %@
QuickFaceID Pets Model: Could not get animalObservations for pet %@ - %@
QuickFaceID Pets Model: Could not persist isInVIPModel on trained pets - %@
QuickFaceID Pets Model: Finished model generation and persistence
QuickFaceID Model: Begin model generation
QuickFaceID Model: Model generation cancelled. Quitting
QuickFaceID: Building %@-confirmed person %@ (%@)
FaceID Model: fetched %lu faces
FaceID Model: fetched %lu faces without roll predicate
QuickFaceID Model: Could not create faceprint for face: %@. Error: %@
QuickFaceID Model: Could not add faceprint to model for face: %@.
QuickFaceID Model: Could not add faceprints to model. Error: %@
QuickFaceID: Built using %lu faces for person %@ (%@)
VCPPersonVIPGenerateModel
QuickFaceID Model: Finished model generation
QuickFaceID Model: Failed to persist model %@
QuickFaceID Model: Could not get face observations for person %@ - %@
QuickFaceID Model: Could not persist isInVIPModel on trained faces - %@
QuickFaceID Model: Finished model generation and persistence
QuickFaceID %@ Model: Last job generation %.0fs ago, job is due = %@
QuickFaceID [FastMigration]: asset processing progress: total: %ld, processed: %ld, failed: %ld
QuickFaceID [FastMigration]: asset processing rate: processed>90%%: %s, failure>10%%: %s, pass: %s
QuickFaceID [FastMigration]: persistent storageDirectoryURL is nil
QuickFaceID [FastMigration]: cannot load Persons Model: %@
QuickFaceID %@ Model: ignoreLastGenerationTime: %s
QuickFaceID %@ Model: No need to generate model
QuickFaceID Model: unknown VIP type (%lu); no model generated
Restore clusterer error (ClusterState = %ld): %@
Restored clusterer, ClusterState = %ld
UpdateKeyFaces for: '%@'
could not update key faces for suggestions: %@
Loaded clustererState: %ld
Returning no suggestions because the clusterer is working
suggestions first phase query start
suggestions first phase query end
suggestions middle phase query start (includes face groups for person query)
suggestions middle phase query end
suggestions last phase query start
suggestions last phase query end
Querying suggestions for person %@ (Photos: %@ to-be-confirmed, %@ to-be-rejected suggestions)
Returning %lu suggestions for person %@
Input parameter is empty or nil: '%@'
Persons Model: Failed to remove model at %@ - %@
Pets Model: Failed to remove model at %@ - %@
Person Processing: Starting Deleting Persons
VCPFaceProcessingDeleteAllVerifiedPersons
Person Processing: Deleting Persons %@
Person Processing: Starting Face Reclustering
VCPFaceProcessingReclusterFacesWithThreshold
Person Processing: Face Clustering %@
Person Processing: Starting Person Building
VCPFaceProcessingBuildPersons
Person Processing: Person Building %@
Person Processing: Starting Person Promotion
VCPFaceProcessingPromotePersons
Person Processing: Person Promotion %@
AVAsset: Montage asset detected
Failed to decode first frame (%@)
[CGImage->CVPixelBuffer] Failed to create CVPixelBuffer with existing IOSurface
[CGImage->CVPixelBuffer] CGImage not IOSurface backed
[CGImage->CVPixelBuffer] Failed to allocate CVPixelBuffer
[CGImage->CVPixelBuffer] Failed to allocate CGContext
[MediaAnalysis] Sample at %lld/%d is being extended %0.1fx
[MediaAnalysis] Requested post process highlight with NULL input analysis
[MediaAnalysis] Post-process highlights returned NULL
[MediaAnalysisResultsTypesForAnalysisTypes] Unknown result type
VideoPetActionAnalyzer: _scoreAbsoluteMax = %f, _scoreRelativeMax =%f
VCPVideoPetsActionTracker
VideoPetActionAnalyzer: finishAnalysisPass
  Extreme aspect ratio %f; initialization failed
[VideoTrackDecoder] Decoded frame and setting mismatch: actual padding right: %zupx, bottom: %zupx (expected right: %zupx, bottom: %zupx)
[VCPFaceCrop][%@] Failed to generate FaceCrop data - %@
[VCPFaceCrop][%@] Failed to create VCPFaceCrop instance
[%@] VCPCoreMLRequest Failed to open model file at url %@
VCPMADVIVisualSearchGatingTask running...
[VS] Cached parse result empty; returning empty result
VCPMADVIVisualSearchGatingTask failed to create visual search query context (%@)
VCPMADVIVisualSearchGatingTask image loading failed
VIService_VisualSearchGating
VCPMADVIVisualSearchGatingTask complete (%d)
VCPFaceAnalyzerImageRequestHandlerPerformRequest
[FaceAnalyzer] Failed to perform requests - %@
[FaceAnalyzer] Failed to create blur/exposure request
[FaceAnalyzer] Blur score %f out of bound [%f, %f]
[FaceAnalyzer] Failed to perform blur requests - %@
[FaceAnalyzer] Exposure score %f out of bound [%f, %f]
[FaceAnalyzer] Failed to perform exposure requests - %@
VCPFaceAnalyzerBlurExposureAnalysis
VCPFaceAnalyzerVCPFaceCreation
[VCPFaceAnalyzer][%@] Failed to create VCPPhotosFace from PHFace %@
VCPFaceAnalyzerVerifyAndMergeFaces
[FaceAnalyzer][%@] Resource (%d) has invalid dimensions (%dx%d); falling back to asset
[FaceAnalyzer][%@] Invalid dimensions (%dx%d)
VCPFaceProcessingFastPathDecodeAsset
[FaceAnalyzer][%@] Failed to decode image
[FaceAnalyzer][%@] Failed to decode orientation (%d)
VCPFaceAnalyzerLoadImageRequestHandler
[FaceAnalyzer][%@] Failed to create VNImageRequestHandler
[FaceAnalyzer][%@] Loaded local resource (%dx%d orientation:%d)
[FaceAnalyzer][%@] Failed to analyze resource
VCPFaceAnalyzerPerformAnalysis
[FaceAnalyzer][%@] Failed to refine analysis
VCPFaceAnalyzerRefineAnalysis
[FaceAnalyzer][%@] Face refine completed: detected %lu | persist: %lu | delete: %lu
[FaceAnalyzer][%@] Missing local resource %@
[FaceAnalyzer] face (center-x:%.2f, center-y:%.2f, size:%.2f) -> boundingBox (x:%.2f, y:%.2f, width:%.2f, height:%.2f)
[FaceAnalyzer] Failed to generate VNFaceObservation from face %@
[FaceAnalyzer] All faces contain valid faceprint
[FaceAnalyzer] Updating %lu faces with missing faceprint
[FaceAnalyzer] Failed to create VNImageRequestHandler for face quality analysis
[FaceAnalyzer] Faceprint VNImageRequestHandler::performRequests: %@
[FaceAnalyzer] faceprint.confidence is too low (%.3f < 0.1) %@ - junkinessIndex: %.3f
[FaceAnalyzer] Accepting faceprint with confidence: %.3f %@ - junkinessIndex: %.3f
[FaceAnalyzer] Update faceprint for face %@
[FaceAnalyzer] Unable to serialize faceTorsoprint - %@
[FaceAnalyzer] No valid faceprint from observation %@
[FaceAnalyzer] Failed to get faceprint for face %@
VCPFaceAnalyzerFillMissingFaceprint
[FaceAnalyzer][%@] No face detected; skip face quality analysis
[FaceAnalyzer][%@] No valid face observations from %lu faces; skip face quality analysis
[FaceAnalyzer] Analyzing %lu face observations for face quality
[FaceAnalyzer] Failed to set Face Quality revision (%lu) - %@
[FaceAnalyzer] Failed to perform Face Quality request - %@
[FaceAnalyzer][%@][%@] No valid Face Quality score; skipping
VCPFaceAnalyzerFaceQuality
[%@] Asset has no small video derivative; skipping
[%@] File size exceeds streaming threshold; skipping
[%@] Duration exceeds streaming threshold; skipping
Unknown VCPTaskID (%lu); redirect to VCPTaskID_MediaAnalysis
[%@] Processing image at scaled resolution (%dx%d)
[%@] Processing image at subsampled resolution (%dx%d)
[%@] Processing image at full resolution (%dx%d)
[%@] Invalid target resolution (%d)
[%@] Resource (%d) has invalid dimensions (%dx%d); falling back to asset
[%@] Asset has invalid dimensions (%dx%d)
-[PHAsset vcp_needsProcessingForTask] not implemented for %@
[%@] Montage asset detected
[%@] Text Confidence: %0.2f Passed Gating: %d
[%@] Text Confidence: 0.00f Passed Gating: 0 [Absent]
[%@] Asset scene properties unavailable or out-of-date
VCPMADVIVisualSearchTask running...
VCPMADVIVisualSearchTask image loading failed
VCPMADVIVisualSearchTask failed to create visual search query context (%@)
[VisualSearch] Using client provided OCR results
VIService_ParsedVisualSearch
VIService_VisualSearch
VCPMADVIVisualSearchTask complete (%d)
VCPVideoStabilizationAssetProcessingTask
Video Stabilization processing failed
Video caption test mode
Video caption is not enabled by defaults write
Video caption only support live photos
Video captioning model not found or user not turning on Image Descriptions in Accessibility
  [%@] Existing analysis outdated; dropping
VCPLightVideoAnalyzer
Movie analyzer perform VCPPhotosQuickFaceDetection
VCPPhotosQuickFaceDetection
VCPVideoCaptionAnalyzer
VCPVideoStabilizerPixel
VCPVideoFaceDetector
VCPFullVideoAnalyzer
VCPVideoSceneClassifier
VCPVideoActivityAnalyzer
VCPVideoSaliencyAnalyzer
VCPVideoHumanActionAnalyzer
videoCaptionAnalyzer
VCPVideoHumanActionClassifier
VCPVideoPetsAnalyzer
VCPVideoPetActionAnalyzer
VCPMovieCurationAnalyzer
VCPVideoStabilizer
VCPSettlingEffectAnalyzer
VCPVideoCNNAnalyzer
    Analyzing Video Segment - Track ID: %d Start: %lld/%d (%0.3fs) End: %lld/%d (%0.3fs)
VCPAudioAnalyzer
    Video track has invalid full frame dimensions (%.f,%.f)
    Video track has invalid clean aperture rect
VCPVideoStabilizerGyro
  [%@] Asset doesn't have gyro metadata
  [%@] Asset does not have valid video track; all %lu tracks: %@
    Video track has invalid dimensions (%.f,%.f)
VCPMovieAnalyzer
ImageHandAnalyzer: input image aspectRatio = %f
ImageHandAnalyzer: aspectRatio = %@, queryAspectRatioVal = %@
ImageHandAnalyzer: feasibleShapeIndex = %d
ImageHandAnalyzer: detectorHeight = %d, detectorWidth = %d
VCPMADServiceImageProcessingTask_Run
[MotionFlow] Failed to lock/unlock pixelbuffer (errcode: %d)
  [%@] Processing
[MediaAnalysis][%@]Unable to open movie, skip
[MediaAnalysis][%@]Failed to create asset
    Analyzing Audio Track - ID: %d Start: %lld/%d (%0.3fs) End: %lld/%d (%0.3fs)
Error resetting all FaceGroups Person Builder state: %@
Failed to clean up merge candidates. Error: %@
VCPFaceProcessingCleanupMergeCandidates
->->-> Enabling personBuilderMergeCandidates
Failed to update key faces - %@
VCPPersonBuilder_UpdateKeyface
VCPMADVIRectangleDetectionTask running...
VCPMADVIRectangleDetectionTask image loading failed
[RectangleDetection] Set VNProcessingDevice: %@ (%@)
VCPMADVIRectangleDetectionTask complete
[VCPPreAnalyzer] Failed to create VCPPoolBasedPixelBufferCreator for monochrome
 [ProbableRotation] Failed to load %@
[VCPPreAnalyzer] Failed to create VCPPoolBasedPixelBufferCreator for rotation
VCPSceneAnalyzerReleaseCachedResources
Failed to create VNClassifyImageAestheticsRequest
Failed to create VNSceneClassificationRequest
Failed to create VNCreateSceneprintRequest
Failed to create VNClassifyJunkImageRequest
Failed to create VNGenerateAttentionBasedSaliencyImageRequest
Failed to set VNClassifyImageAestheticsRequest::setRevision %lu: %@
Failed to set VNSceneClassificationRequest::setRevision %lu: %@
Failed to set VNCreateSceneprintRequest::setRevision %lu: %@
Failed to set VNGenerateAttentionBasedSaliencyImageRequest::setRevision %lu: %@
Failed to set VNClassifyJunkImageRequest::setRevision %lu: %@
Failed to set VNRecognizeObjectsRequest::setRevision %lu: %@
Failed to set VNGenerateObjectnessBasedSaliencyImageRequest::setRevision %lu: %@
Failed to set VNClassifySignificantEventRequest::setRevision %lu: %@
Failed to set VNClassifySemanticDevelopmentGatingRequest::setRevision %lu: %@
Failed to set VNClassifyCityNatureImageRequest::setRevision %lu: %@
Failed to create %@
Unsupported observation label in VCPSpecialLabelToSceneClassificationID %@
Unsupported observation label %@
[DO] detectedObjects count is 0; skip detectedObjects
[DO] invalid confidenceMax: %f; skip detectedObjects
[DO] Failed to choose the best bounding box c_max: %f, c_threshold (0.8x): %f from %@
[DO] Unsupported observation label in PFSceneTaxonomyNode %@
Unsupported observation label in PFSceneTaxonomyNode: %@
Ignoring SceneNet result for tiny image
Unsupported observation label in VCPSpecialLabelToSceneClassificationID %@ (%@)
Unnormalized saliencyRequest bounding box %@; skip
Unnormalized saliencyRequest narrowed bounding box %@; skip
Unnormalized salientObject narrowed bounding box %@; skip
Error creating VNRequest
Unknown ideal dimension for VNRequests (%@), using image dimension %dx%d
Only one VNRequest (%@) for dimension %dx%d; consider coalescing to common resolution
%dx%d
VCPSceneAnalyzerImageRequestHandlerPerformRequest
Failed to run VNImageRequestHandler::performRequests: %@
CVNLPCommSafetyHandler unavailable for IVS
CVNLPCommSafetyHandler_IVS
Failed to run CVNLPCommSafetyHandler::generateClassificationScoresForPixelBuffer:error: %@
VCPSceneAnalyzerImageBlurAnalysis
VCPSceneAnalyzerExposureAnalysis
VCPSceneAnalyzerRotationAnalysisScaling
[ProbableRotation] invalid coreML results
VCPSceneAnalyzerRotationAnalysisInference
No sceneprint data for WP analysis; return default value
VCPWallpaperAnalysis
VCPSceneAnalyzerLoadImageRequestHandler
Failed to load imageURL: %@
VCPSceneAnalyzerPerformAnalysis
VCPFaceGeometry initWithCoder - vertices data missing
VCPFaceAnchor initWithCoder - unexpected size of transform data
VCPCaptureAnalysis - missing resolution properties for prewarming
CNNFastGestureRecognition: start loading model
CNNFastGestureRecognition: inputBlob.height = %d, inputBlob.width = %d, inputBlob.channels = %d
CNNFastGestureRecognition: successfully loaded model
[MotionFlowSubtleMotionAnalyzer] Failed to request flow from VCPMotionFlowRequest: %@
Motion flow is null
Fail to initialize motionFlowAnalyzer
[VCPMediaAnalyzer] Client XPC connection interrupted
[VCPMediaAnalyzer] Client XPC connection invalidated
[VCPMediaAnalyzer] Acquiring media analysis directory sandbox extension...
[VCPMediaAnalyzer] Failed to establish connection or connection lost to service %@; %@
[VCPMediaAnalyzer] Failed to consume media analysis directory sandbox extension
[VCPMediaAnalyzer] Consumed media analysis directory sandbox extension
[MediaAnalysis] failed to get database sandbox extension
[MediaAnalysis] failed to consume sandbox extension
[MediaAnalysis] Consumed sandbox extension
[MediaAnalysis] Failed to obtain analysis sandbox extension for Photo Library (%@); client may not be able to open analysis database
[MediaAnalysis] Requested max highlight duration longer than %.2fs, fall back to %.2fs
[MediaAnalysis][%@] No valid on-demand analysis; skipping
[MediaAnalysis][%@] Storing on-demand analysis
[MediaAnalysis][%@] Failed to store on-demand analysis - %@
[MediaAnalysis][%@]Unable to open movie
[MediaAnalysis][%@] Received analysis request: %@
[MediaAnalysis][%@] Analysis served: (%@)
[MediaAnalysis] [MediaAnalyzer requestAnalysisForAsset] call from invalid instance
[MediaAnalysis] Failed to obtain database for Photo Library %@
[MediaAnalysis] Cancelling request %d
[MediaAnalysis] Failed to find request %d; cannot cancel
[MediaAnalysis] [MediaAnalyzer assetsAnalyzedSinceDate] call from invalid instance
[MediaAnalysis] Failed to obtain database for Photo Library (%@)
Cannot load %@ for %@, NSData length: %lu, content: %@
Cannot load %@ from PHAsset, NSData length: %lu, content: %@
[MediaAnalysis] [MediaAnalyzer distanceFromAsset] call from invalid instance
[MediaAnalysis] Failed to obtain database for assets
[MediaAnalysis] failed to request analyses
[MediaAnalysis] [requestAnalysesForAssets] call from invalid instance
[MediaAnalysis] [requestAnalysesForAssets] in standalone mode but on-demand not allowed
[MediaAnalysis] call from invalid instance
[MediaAnalysis] on-demand analysis requested in standalone mode
Warning: On demand analysis is not supported.
[MediaAnalysis] Failed to obtain database for collection %@
[MediaAnalysis] [requestLivePhotoEffectsForAssets] call from invalid instance
[MediaAnalysis] [requestLivePhotoEffectsForAssets] in standalone mode but on-demand not allowed
Sceneprint task failed (%@)
Error: MAD tracked taxonomy is not the latest in Photos!
Loading PFSceneTaxonomy identifier %@
Failed to initialize PFSceneTaxonomy w/identifier %@ (%@)
Error: MAD tracked taxonomy identifier %@ does not match the latest in Photos: %@!
[PFSceneTaxonomy(MediaAnalysis)] - Failed find scene name for scene id %d
[PFSceneTaxonomy(MediaAnalysis)] - Failed to find scene id for scene name %@
Video track rotation angle is not multiple of 90
Predicate requested for unsupported task (%@) & priority (%d)
Predicate requested for unsupported task (%@)
VNSession_init
CNNHandsDetector: Loading model %@
CNNHandsDetector: adopting model config: %@
CNNHandsDetectorEspresso: updating model config to %@
copyImageToBGRHandDetectorCallFromSPI
scalerHandDetectorCallFromSPI
inferenceHandDetectorCallFromSPI
CNNHandsDetector: hand class index: %d
[%@][MAMLModel] Failed to open model file at url %@
[%@][MAMLModel] Failed to load compiled model (%@): %@
[MAMLModel] Input feature %@ %ldx%ld %ld
[MAMLModel] Missing inputImage feature description %@
[MAMLModel] Mismatched inputImage width (%ld) and height (%ld)
[MAMLModel] Output feature %@ %@
[MAMLModel] Missing output feature %@
  [%@] Fingerprint requested for asset with no objectID
  [%@] Fingerprinting failed
  Fullfilled content request: %@
  Fullfilled data request: %@
Failed to query ideal dimension for request %@ due to empty supportedImageSizeSet
Failed to query ideal dimension for request %@ because the request does not conform to VNImageIdealImageSizeProviding protocol
Failed to configure %@
[DAS QoS] %@: %@ (%@) download %lu bytes
Requested resource exceeds maximum supported size
Resource already in the buffer. Skip downloading.
requestDownloadOfResource: %@
Download progress: %.2f
    Received %llu bytes (Overall: %llu/%llu)
Data received exceeds maximum supported size
Failed to download asset resource (%@)
Successfully downloaded asset resource
Failed to issue resource request
Download resource timed-out
Cancelling download
queryActionResultForPHFace : no action results
queryActionResultForPHFace : not find the best highlight
queryActionResultForPHFace : no faceprint data for face: %@
queryActionResultForPHFace : failed to get VNFaceTorsoprint %@
queryActionResultForPHFace : failed to decode torsoprintAction
queryActionResultForPHFace : failed to get compute torsoprint distance
queryActionResultForPHFace : torsoprint distance with %@, %f
queryActionResultForPHFace : failed to get torsoprints
Connecting to system photo library...
Opening system photo library...
Opened system photo library
Failed to open system photo library (%@)
Failed to obtain system photo library URL
Closed Photo Library
Photo Library unavailable (%@); closing Photo Library...
  [%@] Failed to decode last frame of video, fall back to thumbnail 
[AutoCounter] feature not supported on this OS variant
[AutoCounter] Failed to find asset for face: %@; skip
[AutoCounter] Asset without cloudIdentifier, use localIdentifier: %@
[AutoCounter] Person without localIdentifier; use face.personLocalidentifier
[AutoCounter] Face without personLocalIdentifier; skip
[AutoCounter] Fetched face/person not matching required person; skip
[AutoCounter] Face in a facegroup without localIdentifier; skip
[AutoCounter] No valid faceprint data; leave as unknown
[AutoCounter] No valid momentLocalIdentifier; leave as 'unknown'
[AutoCounter] Face without localIdentifier; skip
[AutoCounter] Failed to fetch person %@
[AutoCounter] Fail to load groundtruth file
[AutoCounter] Person (%@) already opt-in; skip
[AutoCounter] Cannot write opt-in groundtruth to %@ : %@
[AutoCounter] Export URL: %@
[AutoCounter] Failed to find facegroup for mergeCandidate: %@
[AutoCounter] Reach kVCPMaximumNumberOfMergeCandidatesShown (%lu); skip the rest
[AutoCounter][ClusterDump] FaceGroupCount %lu
[AutoCounter][ClusterDump] FaceCount %lu
[AutoCounter] Saved cluster state to %@
[AutoCounter] Cannot write to %@ : %@
[AutoCounter][P/R][GT] Fail to load groundtruth file: %@
[AutoCounter][P/R][GT] Invalid faceID for face: %@; ignore
[AutoCounter][P/R][GT] Invalid PersonID for faceID: %@; ignore
[AutoCounter][P/R][GT] Load faceID: %@ for PersonID: %@
[AutoCounter] Saved assets-to-faces details to %@
[AutoCounter] Cannot write assets-to-faces to %@ : %@
[AutoCounter][P/R] Fail to load cluster state file: %@
[AutoCounter][P/R] Cluster contains no asset information
[AutoCounter][P/R] Cluster contains no data
[AutoCounter][P/R] Invalid information for asset %@ in cluster; ignore
[AutoCounter][P/R] Invalid ID(s) in cluster: %@; ignore
[AutoCounter][P/R] Invalid face rectangle in cluster state for faceID:%@; ignore
[AutoCounter][P/R] processing cluster state faceID: %@ forPersonID: %@
[AutoCounter][P/R] Invalid ground truth rect for faceID:%@
[AutoCounter][P/R][%@] %.4f library: %@, gt: %@ (fid:%@, pid:%@)
[AutoCounter][P/R] Co-location mapping faceID:faceGroupID %@:%@ -> %@:%@
[AutoCounter][P/R] Cannot find asset for id %@
[AutoCounter][P/R] Precision for FaceGroup (of size %d) for personID %@ (of size %lu) is %f
[AutoCounter][P/R] Valid singleton count = %lu, invalid singleton count = %lu
[AutoCounter][P/R] Valid face count for person %@ is %d
[AutoCounter][P/R] personID %@ Recall (of size %lu) is %f
[AutoCounter][P/R] personID %@ Recall (exclude detection miss) (of size %lu) is %f
[AutoCounter][P/R] Weighted Precision: %f, Weighted Recall: %f (number of best face: %.0f)
[AutoCounter][P/R] Weighted Recall (exclude detection miss): %f (number of best face: %.0f)
[AutoCounter][P/R][PV] Processing person cluster %@ with %lu faces
[AutoCounter][P/R][PV] Invalid faceID in person cluster: %@; ignore
[AutoCounter][P/R][PV] Failed to fetch asset for face %@; ignore
[AutoCounter][P/R][PV] Asset without cloudIdentifier, use localIdentifier: %@
[AutoCounter][P/R][PV] Invalid face rectangle in person cluster state for face: %@; ignore
[AutoCounter][P/R][PV] processing person cluster faceID: %@ for PersonID: %@ and clusterID: %@
[AutoCounter][P/R][PV] Valid faceID mapping faceID:personID %@:%@ -> %@:%@
[AutoCounter][P/R][PV] Invalid faceID mapping faceID:faceGroupID %@:%@ -> %@:%@
[AutoCounter][P/R][PV] Invalid ground truth face rectangle for faceID:%@
[AutoCounter][P/R][PV] Valid co-locate mapping faceID:personID %@:%@ -> %@:%@
[AutoCounter][P/R][PV] Invalid co-location mapping faceID:faceGroupID %@:%@ -> %@:%@
[AutoCounter][P/R][PV] Precision for cluster (of size %d) for personID %@ (of size %lu) is %f
[AutoCounter][P/R][PV] Valid singleton count = %lu, invalid singleton count = %lu
[AutoCounter][P/R][PV] Recall for personID %@ (of size %lu) is %f
[AutoCounter][P/R][PV] Weighted Precision: %f, Weighted Recall: %f
[AutoCounter][CA] Report CoreAnalytics: %@
[AutoCounter][CA] Failed to retrive CoreAnalytics export URL
[AutoCounter][CA] Saved CoreAnalytics to %@
[AutoCounter][CA] Cannot write CoreAnalytics to %@ - %@
[AutoCounter][CA] Cannot retrieve CoreAnalytics files %@
[AutoCounter][CA] Files in folder %@
[AutoCounter][CA] Report CoreAnalytics files: %@
[AutoCounter][CA] Report CoreAnalytics file: %@
[AutoCounter][CA] Finished reporting CoreAnalytics %@
[AutoCounter][P/R] Failed to measure Vision cluster state against ground truth
[AutoCounter][P/R][PV] Failed to measure Person cluster state against ground truth
[AutoCounter][P/R][PV] Failed to report CoreAnalytics
[AutoCounter][P/R][SIMLGT] Failed to load SIML ground truth - %@
[AutoCounter][P/R][SIMLGT] Failed to serialize SIML ground truth - %@
[AutoCounter][P/R][SIMLGT] Load faceID: %@ for PersonID: %@
[AutoCounter][P/R][SIML] Failed to export current clusters states
[AutoCounter][P/R][SIML] Validate cluster state  %@ against ground truth %@
[AutoCounter][P/R][SIML] Failed to measure Vision cluster state against SIML ground truth
VCPMADVIUserFeedbackTask running...
VCPMADVIUserFeedbackTask image loading failed
VIService_UserFeedback
VCPMADVIUserFeedbackTask complete (%d)
[MediaAnalysis] [VCPVideoMetaAnalyzer] Unknown analysis type %@
Image Action classifier - merged actions for face  %@
Image Action classifier - torso or face not detected %@
Image Action classifier - PHFace gated out by age attribute
Image Action classifier - action class %d with confidence %f
VCPPriorityAnalysis - Start initializing
VCPPriorityAnalysis - Finished initializing hand detector
VCPPriorityAnalysis - Finished initializing hand keypoint detector
VCPPriorityAnalysis - Finished initializing gesture recognizer
VCPPriorityAnalysis - Number of hand detected %lu
VCPPriorityAnalysis - dominant hand: %d, hand chirality counter: left: %d, right: %d
VCPPriorityAnalysis - frame interval %f ms
VCPPriorityAnalysis - gestureScoreRightHand %f, gestureScoreLeftHand %f
VCPPriorityAnalysis - gesture score = %f, priority score after thresholding = %f
VCPPriorityAnalysis - Analysis subsampling ratio = %f
VCPPriorityAnalysis - Face yaw: %d
VCPPriorityAnalysis - output priority score = %f
VCPLandmarkValidator failed to validate image (%d)
[ImageManager] kCVPixelFormatType_32BGRA with kCGColorSpaceModelMonochrome, replace with DeviceRGB
[Decode] Accelerated decoding done; CVPixelBuffer: %dx%d, stride:%d, pixelFormat:%d
[Decode] Downscaling %zux%zu --> %zux%zu
[Decode] Slow %@ %.0fx%.0f --> maxDimension:%lu, pixelFormat:%d 
[Decode] %.0fx%.0f --> %zu; subsampling %dx on decode
[Decode] Failed to create CVPixelBuffer from IOSurface; falling back to rendering path
[Decode] Failed to obtain IOSurface; falling back to rendering path
[Decode] Slow decoding done; CVPixelBuffer: %dx%d, stride:%d, pixelFormat:%d
[Decode] Accelerate %@ %.0fx%.0f --> maxDimension:%lu, pixelFormat:%d 
[Decode] Accelerated decode failed; falling back to CGImage
Failed to load pixel buffer due to invalid nil url
Failed to load url %@ (%@)
[ImageManagerEncode] inputCVPixelBuffer cannot be NULL
[ImageManagerEncode] outputJPEGData cannot be nil
[ImageManagerEncode] targetBitStreamLength cannot be 0
[ImageManagerEncode] Encoding CVPixelBuffer -> JPEG (%lu Bytes)
[ImageManagerEncode] Failed to create compression session
[ImageManagerEncode] Fail to open compression container
[ImageManagerEncode] Fail to image buffer
[ImageManagerEncode] Fail to get transcoded data
[ImageManagerEncode] Oversized data (%luBytes)
[ImageManagerEncode] Padding JPEG with %lu Bytes
[ImageManagerEncode] Exporting reencoded JPEGs
VCPHandPoseImageRequest options: _revision = %d
copyImageToBGRHandKeypointCallFromSPI
preProcessingHandKeypointCallFromSPI
Action classifier - empty torso bound in PHFace %@
Action classifier - found torso bound in PHFace %@
[PreAnalysis] Pre-warmed image unused (%dx%d)
[PreAnalysis] Image not pre-warmed; creating on-demand (%dx%d)
%@ canceled (%@)
%@ failed (%@)
HomeKit analysis client XPC connection interrupted
HomeKit analysis client XPC connection invalidated
[HomeKitAnalysis] Error connecting to background analysis service
[HomeKitAnalysis] Request %d is %.2f%% complete
[HomeKitAnalysis] Unknown analysis request %d; dropping cancellation request
[HomeKitAnalysis] No active analysis requests; dropping cancellation request
[VCPFaceMerger] Failed to align face observation - %@
[VCPFaceMerger] Missing face for observation %@ from mapping
[VCPFaceMerger] Bounding box aligner returned an empty rectange
[VCPFaceMerger] Cannot merge face (v%lu, type-%d) with face %@ (v%lu, type-%d, %s imageprint)
[VCPFaceMerger] Cannot merge face with face %@ - distance %f > threashold %f
[VCPFaceMerger] Cannot merge face with face %@ - distance calculation failed %@
[VCPFaceMerger] Cannot Merge in final stage: [mutableDetectedFaces containsObject:detectedFace] %@ [facesToDelete containsObject:matchedExistingFace] %@ 
invalid buffer size %dx%d or pixel format %u
[VCPFaceClusterer] Failed to restore clusterer (state unknown) - %@
[VCPFaceClusterer] Restored Face Clusterer with ClusterState = %ld
Reset restore clusterer error (ClusterState = %ld): %@
Reset restored clusterer, ClusterState = %ld
Person Processing: Starting Reset Face Clustering
VCPFaceProcessingResetFaceClusteringState
Person Processing: Reset Face Clustering Done
Person Processing: Starting Face Clustering
VCPFaceProcessingPerformFaceClusteringAndWait
Person Processing: Face Clustering Done
---> Start face clustering (%ld) with clustering status: %@
---> Finished face clustering (%ld) with clustering status: %@
VCPFaceProcessingClusterFaces
---> Start face clustering as need (%ld) with clustering status: %@
VCPFaceProcessingClusterFacesIfNecessary
  Analyzing degraded version of Movie
Video caption not enabled by defaults write
Image caption test model not exist at %@, not generating image caption
Image captioning model not found or user not turning on Image Descriptions in Accessibility
  [%@] missing Pre Analysis result
  Analyzing degraded version of Photo
VCPImageFaceDetector
VCPImageFaceExpressionAnalyzer
Failed to create CVNLPCaptionHandlerRef (%@)
VCPImageJunkAnalyzer
VCPImageBlurAnalyzer
VCPLowResImageBlurAnalyzer
VCPImageExposureAnalyzer
VCPImageLivePhotoBlurAnalyzer
VCPImageCompositionAnalyzer
VCPImageDescriptor
VCPImageSaliencyAnalyzer
VCPImagePetsAnalyzer
VCPImagePetKeypointsAnalyzer
VCPImageHumanPoseAnalyzer
Human action on Live Photo requires paired movie, skip analyzing still
VCPImageHumanActionAnalyzer
VCPImageHandsAnalyzer
VCPLivePhotoAnalysis
Live Photo w/o local movie resource and streaming not allowed, skip paired movie analysis
VCPEffectsAnalyzer
[MediaAnalysis] PhotoAnalyzer - Original movie is not available, skip effects analysis
VCPParallaxAnalyzer
VCPFaceQualityAnalysis
VCPLivePhotoKeyFrameAnalyzer
VCPPhotoAnalyzer
VCPEmbeddingAnalyzerLoadImageRequestHandler
VCPNeuralHashprintRequest
NeuralHashprint Vision request failed: %lu - %@
VCPImageHashSignatureRequest
NeuralHash+LSH Vision request failed: %lu - %@
NeuralHash+LSH invalid imageSignatureHash
NeuralHash+LSH failed to encode hash: %@
Invalid NeuralHash+LSH (=)
Cannot create VCPPersonBuilder
---> Canceling VCPBuildPersons
VCPBuildPersons canceled
VCPBuildPersons failed: %@
Cannot create PVPersonPromoter
---> Canceling VCPPromotePersons
Person Processing: Starting Person Promoting
VCPFaceProcessingPromotePersonsCoreAnalyticsCollection
Person Processing: Person Promoting %@
VCPPromotePersons canceled
VCPPromotePersons failed
Cannot create PVPersonPromoter for evaluation
---> Canceling VCPFetchPersonPromoterClusterForEvaluation
Person Processing: Start evaluatePersonPromoterWithUpdateBlock
Person Processing: Retrieved %lu unverified person
Person Processing: evaluatePersonPromoterWithUpdateBlock canceled
Unknown Photos Face Processing umbrella version %d
[Perf] %s: %0.6fs
%-40s  %10s  %10s  %10s  %10s  %10s
  %-38s  %10.6f  %10.6f  %10.6f  %10.6f  %10zu
[CoreAnalyticManager] Session event name is nil; skipping
[CoreAnalyticManager] Session fields name is nil for event %@; skipping
[CoreAnalyticManager] Start session event %@ (total session count %lu)
[CoreAnalyticManager] Ignore 0-accumulation for event %@ field %@
[CoreAnalyticManager] Session event %@ not available
[CoreAnalyticManager] Session event %@ not available; skip sending
[CoreAnalyticManager] flushing analytics ... 
[CoreAnalyticManager] flushSessionAnalytics (total count %lu)
Failed to analyzeDetectedFaces - %@
song analysis failed %@
  [%@] Need Face Processing: no faceAdjustmentVersion
  [%@] Need Face Processing: faceAdjustmentVersion %@ != adjustmentTimestamp %@
Attempt to download resource: %@
[%@] Download progress: %.2f
Download resource timed-out (ID:%d)
Cancelling download (ID:%d)
[FileBasedDownload] Downloaded resource to file url: %@
[FileBasedDownload] Failed to download asset resource (%@)
[FileBasedDownload] Successfully downloaded asset resource
[FileBasedDownload] Failed to issue resource request
[FileBasedDownload][%@] Downloading %@
VCPDownloadResource
[FileBasedDownload][%@] Progress: %.2f
[FileBasedDownload][%@] URL: %@
[FileBasedDownload][%@] Failed on resource %@ - %@
[FileBasedDownload][%@] Success!
[FileBasedDownload][%@] Failed to issue resource request
Wrong outHeight in parseHeatmap2Keypoints
Wrong outWidth in parseHeatmap2Keypoints
[ResourceManager] Invalid cost detected (%ld); clipped to %ld
[ResourceManager] Updating budget (%ld --> %ld)
[ResourceManager] Hit usage timeout; purging resources
[ResourceManager] Request to reserve budget [Budget: %ld][Target: %ld]
[ResourceManager] Pruning inactive resources
[ResourceManager] Purging inactive resource (%@)
[ResourceManager] Failed to reserve budget [Budget: %ld][Target: %ld]
[ResourceManager] Request to activate %@
[ResourceManager] Resource not cached (%@)
[ResourceManager] Resource cached but not active (%@)
[ResourceManager] Activating resource (%@)
[ResourceManager] Resource cached and active (%@)
[ResourceManager] Active resource cost has increased (%@)
[ResourceManager] Active resources exceed budget
[ResourceManager] Active count %d
[ResourceManager] Request to deactivate %@
[ResourceManager] Resource transition active --> inactive (%@)
[ResourceManager] Received request to deactivate un-tracked resource (%@)
[ResourceManager] Request to purge inactive resources
[ResourceManager] Skipping active resource (%@)
[ResourceManager] Purging %@
[ResourceManager] Purging active resource (%@)
[ResourceManager] Request to purge all resources
Requested unavailable frame %d (Frame Count: %d  Buffer Depth: %d)
Unexpected media type (%lu)
[%@] Unexpected media type (%d)
[MotionFlowAnalyzer] Failed to request flow from VCPMotionFlowRequest: %@
Gyro analytics stored via dodML
Could not load MonzaV4_1.mlmodelc in the bundle resource
softlink:r:path:/System/Library/PrivateFrameworks/PhotoVision.framework/PhotoVision
softlink:r:path:/System/Library/PrivateFrameworks/HomeAI.framework/HomeAI
softlink:r:path:/System/Library/PrivateFrameworks/HomeAI.framework/HomeAI
softlink:r:path:/System/Library/PrivateFrameworks/PhotosGraph.framework/PhotosGraph
softlink:r:path:/System/Library/PrivateFrameworks/PhotoVision.framework/PhotoVision
softlink:r:path:/System/Library/PrivateFrameworks/PhotoVision.framework/PhotoVision
softlink:r:path:/System/Library/PrivateFrameworks/HomeAI.framework/HomeAI
softlink:r:path:/System/Library/PrivateFrameworks/PhotoVision.framework/PhotoVision
softlink:r:path:/System/Library/Frameworks/ShazamKit.framework/ShazamKit
VCPProtoMovieLaughterResult
NSCopying
VCPPetsRegion
VCPVideoPetsAnalyzer
VCPSettlingEffectAnalyzer
PVPhotoLibraryProtocol
NSObject
LegacyConversion
VCPProtoResultLegacyConversionProtocol
VCPInternetReachability
VCPVideoCNNAnalyzer
VCPProtoMovieSceneResult
VCPMAMLFeatureProvider
MLFeatureProvider
VCPVoiceDetector
VCPProtoMovieAudioQualityResult
PHAssetResource
VCPFullVideoAnalyzer
VCPProtoMovieFineSubjectMotionResult
BackwardCompatability
VCPVideoFullFaceDetector
CMTimeRange
VCPHomeFaceIdentificationTask
VCPMADTaskProtocol
VCPFingerprint
VCPCNNHandKeypointsDetectorEspresso
VCPImageExposurePreAnalyzer
VCPImageDescriptor
VCPDistanceDescriptorProtocol
VCPProtoLivePhotoKeyFrameResult
VCPCNNDataGPU
VCPVideoMetaFaceAnalyzer
VCPProtoKeypoint
PVFaceProtocol
VCPSuggestionRequest
VCPClusterer
PVFaceClusteringProtocol
VCPHumanPoseImageRequest
VCPVideoCNNTask
VCPProtoMovieHighlightScoreResult
VCPMADVIRemoveBackgroundCachedImageHandler
VCPMADVIRemoveBackgroundResource
VCPMADVIRemoveBackgroundTask
VCPMADServiceImageProcessingSubtaskProtocol
VCPVideoProcessorNode
VCPImageConverter
VCPFullAnalysisAssetProcessingTask
VCPMediaAnalysisServerProtocol
VCPMediaAnalysisClientProtocol
VCPMediaAnalysisService
FaceSuggestions
PersonBuilderAndPromoter
InternalTools
Hubble
VCPVideoCaptionEncoder
VCPHumanPoseEspressoSession
CMTime
VCPCNNPetsDetector
VCPMADImageSafetyClassificationResource
VCPMADImageSafetyClassificationTask
VCPCNNSmileDetector
VCPPhotosFace
PFPhotosFaceRepresentation
VCPCNNEspressoContext
VCPProtoMoviePetsFaceResult
VCPCNNPoseEstimatorEspresso
VCPVideoCNNQuality
VCPSegment
VCPClassification
VCPVideoSceneClassifier
VCPProtoImageFeatureResult
VCPTimer
VCPProtoImageHumanPoseResult
VCPProtoMovieQualityResult
VCPPhotosFaceProcessingContext
VCPFaceUtils
VCPProtoImageSceneprintResult
VCPProtoMovieSubtleMotionResult
VCPProtoMovieHumanActionResult
CGRect
VCPVideoPixelStabilizer
VCPContentAnalysis
VCPLightMotionAnalyzer
VCPLoaned
VCPObjectPool
VCPCNNFullConnectionBlockScalar
VCPProtoMovieSaliencyResult
VCPPreAnalysisRequests
VCPProtoImageFaceResult
VCPJunkAnalyzer
VCPVideoMetaMotionAnalyzer
VCPVideoMetaMotionSegment
VCPMADVIResource
VCPProtoVideoKeyFrame
VCPMediaAnalysis
VCPCNNModelEspresso
VCPWallpaperAnalyzer
MercuryBase64
VCPCNNPoolingBlockGPU
VCPClientDatabaseManager
VCPEdgeDetector
VCPVideoCaptionAnalyzer
VCPVideoTrackSyncDecoder
VCPProtoMovieClassificationResult
VCPVNImageprintWrapper
VCPVideoKeyFrameAnalyzer
VCPMetaSegment
VCPSharedInstanceManager
VCPMetaTrackDecoder
VCPAnalysisProgressQuery
VCPCNNConvBlockVector
VCPSaliencyRegion
VCPVideoSaliencyAnalyzer
VCPHandPoseVideoRequest
VCPMoFlowSingleEspresso
VCPImageQualityAnalyzer
VCPMADEmbeddingGenerationTask
VCPVideoProcessorSession
VCPProtoImageBlurResult
VCPFaceIDModel
VCPVanishingPointDetector
VCPVideoHumanActionClassifier
VCPImageSaliencyAnalyzer
MediaAnalysis
VCPMovieCurationAnalyzer
VCPMovieHighlight
VCPModelR2D2
PVAssetProtocol
VCPProtoMovieUtteranceResult
VCPProtoImageSaliencyResult
VCPMotionFlowRequest
VCPImageCompositionAnalyzer
VCPFaceProcessingVersionManager
VCPLightVideoAnalyzer
VCPVideoKeyFrame
VCPSceneprintDescriptor
VCPProtoImageShotTypeResult
VCPProtoImagePetsFaceResult
VCPImagePetsAnalyzer
VCPVideoFacePoseFilter
VCPCNNFullConnectionBlockGPU
PVPersonProtocol
VCPProtoBounds
VCPFace
VCPFaceDetectionRange
VCPFaceShapeModel
VCPCNNFaceLandmarkDetectorEspresso
VCPMADVITextLookupTask
VCPProtoImageCompositionResult
VCPImageFaceDetector
VCPMADResource
VCPCNNSmileDetectorEspresso
VCPVideoCNNHighlight
VCPRealTimeAnalysisServerProtocol
VCPRealTimeAnalysisClientProtocol
VCPRealTimeAnalysisService
MADActivitySchedulingRecord
CGPoint
VCPVideoPersonDetector
VCPProtoLivePhotoFrameInstruction
VCPFaceTensorModel
VCPProcessingStatusEntry
VCPProtoLivePhotoVariationParams
VCPImagePetsKeypointsAnalyzer
VCPVideoActivityAnalyzer
VCPCompactResult
VCPVideoGlobalAnalyzer
VCPCNNPoolingBlock
VCPProtoMovieHumanPoseResult
VCPExpressionSegment
VCPMovieHighlightAnalyzer
VCPHomeKitAnalysisSessionServerProtocol
VCPHomeKitAnalysisSessionClientProtocol
VCPHomeKitAnalysisSession
VCPHomeKitSessionExportedObject
VCPDatabaseReader
VCPProtoTime
VCPURLAsset
Image
LivePhoto
Movie
VCPExifAnalyzer
VCPHomeResidentMaintenanceTask
VCPMADServiceImageProcessingTaskBatch
VCPVideoCNNBackbone
VCPLoudnessAnalyzer
VCPProtoMovieActivityLevelResult
VCPColorNormalizationAnalyzer
VCPFaceCropUtils
VCPPhotosQuickFaceDetectionManager
VisualSearch
VCPMADMachineReadableCodeResource
VCPMADVIMachineReadableCodeDetectionTask
VCPHuman
VCPFlowDecoder
VCPProtoMovieInterestingnessResult
VCPLandmarkValidator
VCPVideoStabilizer
VCPPhotosPersistenceDelegateAdditions
VCPMergeCandidatePair
VCPPhotosPersistenceDelegate
PVPersonPromoterDelegate
VCPProtoImageExposureResult
VCPProtoMovieFeatureResult
VCPPhotosAsset
VCPMADVIDocumentRecognitionResource
VCPMADVIDocumentRecognitionTask
VCPMADPersonIdentificationTaskResource
VCPMADPersonIdentificationTask
VCPBlurAnalyzer
VCPHumanPoseVideoRequest
VCPImageBlurAnalyzer
VCPFlowFeatureExtractor
VCPImageExposureAnalyzer
VCPProtoAssetAnalysis
VCPMADServiceImagePixelBufferAsset
VCPMADServiceImageURLAsset
VCPMADServiceImageDataAsset
VCPMADServiceImagePhotosAsset
VCPMADServiceImageAsset
VCPCNNFaceLandmarkDetectorMPS
VCPVideoObjectTracker
VCPFaceCropManager
VCPPhotosQuickFaceIdentificationManager
VCPCNNBlurAnalyzerEspresso
VCPVideMetaOrientationAnalyzer
VCPFaceProcessingServiceWorker
VCPVideoTrackSubsamplingDecoder
VCPFrameAnalysisStats
VCPVideoCNNAutoplay
VCPVideoPetsActionAnalyzer
VCPVideoKeyFrameResult
VCPMovieHighlightResult
VCPMovieCurationResults
VCPVideoTrackDecoder
VCPFaceCrop
VCPCoreMLRequest
VCPFrameScoreFilter
VCPProtoMovieBabbleResult
VCPMADVIVisualSearchGatingTask
VCPEspressoModel
VCPFaceAnalyzer
MovieResource
VCPSoundDetector
SNResultsObserving
VCPSoundClassifier
VCPAudioClassifier
VCPProtoMovieFaceprintResult
VCPCNNBlock
MediaAnalysisPhoto
MediaAnalysisMovie
MediaAnalysisSceneProcessing
MediaAnalysisOCRProcessing
MediaAnalysisVisualSearchProcessing
VCPMADVIVisualSearchTask
VCPGeometryUtils
VCPProtoMovieCheeringResult
VCPProtoMovieMusicResult
VCPCNNFaceLandmarkDetector
VCPCNNSmileDetectorMPS
VCPCNNConvBlockGPU
VCPVideoProcessor
VCPProtoMovieStabilizationResult
VCPProtoMovieHighlightResult
VCPCNNFullConnectionBlock
VCPHomeKitMotionAnalyzer
VCPProtoMovieSceneprintResult
CMTimerange
VCPSlowmo
VCPProtoMovieSubjectMotionResult
VCPBoundingBox
VCPCNNPoseEstimator
VCPVideoStabilizationAssetProcessingTask
VCPMovieAnalyzer
VCPImageHandsAnalyzer
VCPProtoMovieObstructionResult
VCPMADServiceImageProcessingTask
VCPProtoLivePhotoEffectsResult
VCPCNNBlurAnalyzer
VCPProtoLivePhotoRecommendationResult
VCPDatabaseBatchIterator
PVFetchResultProtocol
NSFastEnumeration
VCPProtoTimeRange
VCPImageLivePhotoBlurAnalyzer
VCPFullAnalysisURLProcessingTask
PVFaceGroupProtocol
VCPProtoLivePhotoEffectsRecipe
VCPProtoLivePhotoHumanActionClassificationResult
VCPAudioAnalyzer
VCPCNNGazeAnalysis
VCPPersonBuilder
VCPImageHumanPoseAnalyzerTopDown
VCPProtoMoviePreEncodeResult
VCPMADVIRectangleDetectionResource
VCPMADVIRectangleDetectionTask
VCPPreAnalyzer
VCPVideoTrackStandardDecoder
VCPCNNPersonKeypointsDetector
VCPFaceGeometry
NSSecureCoding
NSCoding
VCPFaceAnchor
VCPCaptureAnalysisSession
VCPCNNPetsDetectorEspresso
VCPCNNFastGestureRecognition
VCPMotionFlowSubtleMotionAnalyzer
VCPEffectsAnalyzer
VCPVideoFaceDetector
VCPGaborFilter
VCPCancelToken
VCPStorageServiceProtocol
VCPMediaAnalyzer
VCPPhotosSceneprintAssetProcessingTask
PVMomentProtocol
VCPImageAnalyzer
VCPVideoMetaLensSwitchAnalyzer
VCPVideoMetaLivePhotoMetaAnalyzer
VCPCNNData
VCPHoughTransform
VCPRTLandmarkDetector
VCPCNNConvBlock
VCPCNNConvBlockScalar
VCPProtoImagePetsResult
VCPMADVisionResource
VCPCNNHandsDetector
VCPMAMLModel
VCPCNNPoolingBlockVector
VCPRequest
VCPProtoClassification
VCPInMemoryAVAsset
AVAssetResourceLoaderDelegate
VCPProtoMovieFaceResult
VCPProtoLivePhotoKeyFrameStillResult
VCPDownloadManager
VCPTransforms
VCPActionAnalyzer
MediaAnalysisResults
MediaAnalysisPauseResume
VCPImageMotionFlowAnalyzer
VCPDefaultPhotoLibraryManager
PHPhotoLibraryAvailabilityObserver
VCPInterAssetAnalyzer
VCPClusteringAccuracyMeasures
VCPPhotosAutoCounterWorker
VCPProtoPoint
Exif
VCPImageSaliencyAnalyzerFull
VCPMADVIUserFeedbackTask
VCPMADVIVisualSearchResource
VCPVideoMetaAnalyzer
VCPKeypoint
VCPPersonObservation
VCPHandObservation
VCPMotionFlowObservation
VCPImageHumanActionAnalyzer
VCPProtoMovieApplauseResult
VCPPriorityAnalysis
VCPVideoFaceMeshAnalyzer
bRVA
VCPImageManager
VCPHandPoseImageRequest
VCPCNNHandKeypointsDetector
VCPVoiceDetectorV2
VCPCNNPoseEstimatorMPS
VCPProtoImageJunkResult
VCPProtoMovieCameraMotionResult
VCPVideoCNNActionClassifier
VCPImageSaliencyAnalyzerFullEspresso
VCPCNNFlattenBlock
VCPVideoMetaFocusAnalyzer
VCPVideoMetaFocusSegment
VCPProtoMovieLoudnessResult
VCPPreAnalysisImageEntry
VCPPreAnalysisImage
VCPMABaseTask
VCPHomeKitAnalysisServerProtocol
VCPHomeKitAnalysisClientProtocol
VCPHomeKitAnalysisService
Client
Resident
VCPPhotosFacePair
VCPFaceMerger
VCPLivePhotoKeyFrameAnalyzer
VCPCNNPersonDetector
VCPPoolBasedPixelBufferCreator
VCPParallaxAnalyzer
VCPImageFaceExpressionAnalyzer
VCPTimeMeasurement
VCPImageHumanPoseAnalyzer
VCPFaceClusterer
VCPBackwarp
VCPLogManager
VCPProtoMovieSummaryResult
VCPPreAnalysisImageLoader
VCPProtoMovieVoiceResult
VCPCNNMetalContext
VCPCNNBlurAnalyzerMPS
VCPPhotoAnalyzer
VCPMAEmbeddingAnalyzer
VCPTrimAnalyzer
VCPSceneChangeAnalyzer
VCPSceneChangeSegment
VCPMADCoreAnalyticsManager
VCPProtoMovieOrientationResult
VCPSceneProcessingImageManager
VCPImageFaceQualityAnalyzer
VCPVideoLightFaceDetector
VCPProtoMoviePetsResult
VCPVideoAnalyzer
VCPPnPSolver
VCPSongDetector
VCPProtoLivePhotoKeyFrameFaceResult
VCPCorrelation
VCPVideoHumanActionAnalyzer
VCPAsset
VCPPHFaces
VCPProtoLine
VCPProtoMovieStabilizationRecipe
VCPCNNPetsKeypointsDetector
VCPVideoFacePoseAnalyzer
VCPVideoCNNCameraMotion
VCPVideoActivityDescriptor
VCPCNNModel
VCPMADResourceLock
VCPMADResourceEntry
VCPMADResourceManager
VCPProtoMovieMovingObjectResult
VCPDeviceInformation
VCPCNNPoolingBlockScalar
FullAnalysis
VCPMotionFlowAnalyzer
VCPProtoLivePhotoSharpnessResult
VCPVideoGyroStabilizer
MonzaV4_1Input
MonzaV4_1Output
MonzaV4_1
VCPCtrTracker
VCPBaseTracker
.cxx_destruct
T@"NSData",&,N,V_sceneprintBlob
ComputeSceneDelta:
T@"NSDictionary",R,N,V_analysis
ExtractActivityDescriptorFromStats:
T@"NSString",R,N,V_clientTeamID
PrintSegments
T@"VCPProtoBounds",&,N,V_bounds
T#,R
T@"VNTorsoprint",&,V_torsoprint
T@"<MTLCommandQueue>",&,V_commandQueue
TB,N,V_hasFlash
T@"<PVFaceProtocol>",&,N
TB,N,V_maskOnly
T@"MLModel",R,N,V_model
TQ,R,N,V_status
T@"NSArray",&,N,V_keypoints
TS,N,V_gazeType
T@"NSArray",C,N,V_barcodeObservations
TS,N,V_poseType
T@"NSArray",R,&,N
T^q,R,N
T@"NSArray",R,V_cflags
Td,N,V_duration
T@"NSData",&,N,V_colorNormalization
Tf,N,V_faceArea
T@"NSData",&,N,V_faceprintBlob
Tf,V_confidence
T@"NSData",&,N,V_recipeBlob
Ti,N,V_personID
T@"NSData",R,N
Ti,N,V_revision
T@"NSDate",N,V_startTime
Ti,R,V_logLevel
T@"NSDate",R,N,V_lastRetryDate
Tr^,R,N
T@"NSDictionary",R
T@"NSDictionary",R,N
_actionAnalyzer
T@"NSDictionary",R,N,V_objectsMotion
_activeKeyFrame
T@"NSMutableArray",&,N,V_detectedFaces
_allowStreaming
T@"NSMutableArray",&,N,V_faceResults
_assets
T@"NSMutableArray",&,N,V_imageBlurResults
_backwarpKernel
T@"NSMutableArray",&,N,V_imageExposureResults
_bounce
T@"NSMutableArray",&,N,V_imageFeatureResults
_budget
T@"NSMutableArray",&,N,V_imageJunkResults
_cancel
T@"NSMutableArray",&,N,V_imagePetsResults
_clientBundleID
T@"NSMutableArray",&,N,V_imageSceneprintResults
_clusterBuilder
T@"NSMutableArray",&,N,V_keypoints
_cnnInputHeight
T@"NSMutableArray",&,N,V_livePhotoHumanActionClassificationResults
_configureRequest:withRevision:
T@"NSMutableArray",&,N,V_livePhotoKeyFrameStillResults
_cropRectHeight
T@"NSMutableArray",&,N,V_livePhotoSharpnessResults
_curExprWeights
T@"NSMutableArray",&,N,V_movieActivityLevelResults
_detectionModeCounterShapeModel
T@"NSMutableArray",&,N,V_movieAudioQualityResults
_downScaleWidth
T@"NSMutableArray",&,N,V_movieCameraMotionResults
_embeddingWidth
T@"NSMutableArray",&,N,V_movieClassificationResults
_energy
T@"NSMutableArray",&,N,V_movieFaceprintResults
_expressionType
T@"NSMutableArray",&,N,V_movieFineSubjectMotionResults
_faceId
T@"NSMutableArray",&,N,V_movieHighlightScoreResults
_facialHairType
T@"NSMutableArray",&,N,V_movieHumanPoseResults
_filter
T@"NSMutableArray",&,N,V_movieLaughterResults
T@"NSMutableArray",&,N,V_movieMovingObjectResults
_generateOutput
T@"NSMutableArray",&,N,V_movieObstructionResults
_groups
T@"NSMutableArray",&,N,V_moviePetsFaceResults
_height
T@"NSMutableArray",&,N,V_moviePreEncodeResults
_hidden
T@"NSMutableArray",&,N,V_movieSaliencyResults
_humanPoseScore
T@"NSMutableArray",&,N,V_movieSceneprintResults
_imageGenerator
T@"NSMutableArray",&,N,V_movieSubjectMotionResults
_inputNumFrames
T@"NSMutableArray",&,N,V_movieSummaryResults
_isAutoPlayable
T@"NSMutableArray",&,N,V_movieVoiceResults
_isHeadingFrame
T@"NSMutableArray",&,V_faceQualityScores
_isSegmentPoint
T@"NSMutableArray",&,V_precisionPerCluster
_length
T@"NSMutableArray",&,V_recallPerPersonToGroundTruth
_loadImageURL:withSession:reencodedImageData:andRequestHandler:
T@"NSMutableArray",&,V_voiceDetections
_master
T@"NSMutableArray",W,V_inputSize
_mediaAnalysisServiceConnection
T@"NSMutableDictionary",&,N,V_results
_motionDivScore
T@"NSSet",R,N
_nextSampleTime
T@"NSString",&,N,V_assetIdentifier
_numInternalLms
T@"NSString",&,N,V_faceId
_numTri
T@"NSString",&,V_sceneId
_object
T@"NSString",C,N,V_groupingIdentifier
_output
T@"NSString",R,C
_outputFrameIdx
T@"NSString",R,N
_personDetector
T@"NSString",R,N,V_inputFeatureName
_photoSharpness
T@"NSString",R,N,V_outputFeatureName
_preferredAngle
T@"NSString",R,V_adjusted
_prevHandCenter
T@"NSString",R,V_person1LocalIdentifier
_privateResults
T@"NSString",R,V_reason
_processingMode
T@"NSURL",R,N
T@"PHAsset",R,N,V_phAsset
_qualityMeasure
T@"VCPCNNData",&,V_output
_reader
T@"VCPCNNData",W,V_input
_region
T@"VCPCNNMetalContext",W,V_context
_requestHandler
T@"VCPFingerprint",R,N
_resultsHandler
T@"VCPImageDescriptor",&,N,V_descriptor
_sampleDuration
T@"VCPMADVIRemoveBackgroundCachedImageHandler",&,N,V_cachedImageHandler
_sandboxHandles
T@"VCPPhotosFace",R,N,V_face2
_sceneprintBlob
T@"VCPProtoBounds",&,N,V_playbackCrop
_source
T@"VCPProtoLivePhotoVariationParams",&,N,V_autoloop
_stabilityScore
T@"VCPProtoLivePhotoVariationParams",&,N,V_longexposure
_status
T@"VCPProtoPoint",&,N,V_end
_suggestionLock
T@"VCPProtoPoint",&,N,V_vanishingPoint
_summaryResults
T@"VCPProtoTime",&,N,V_timestamp
_timeOfInterest
T@"VCPProtoVideoKeyFrame",&,N,V_keyFrame
_transformImage
T@"VCPVideoActivityDescriptor",&,N,V_videoActivityDescriptor
_updateFace:withFaceCrop:error:
T@"VCPVideoKeyFrameResult",R,N,V_keyFrame
_updatedFaceGroupByFGLocalIdentifierFromClusterCSNs:fetchLimit:
T@"VN1JC7R3k4455fKQz0dY1VhQ",&,N,V_adjustmentsRequest
_validDimension
T@"VN6Mb1ME89lyW3HpahkEygIG",&,N,V_tabooRequest
T@"VNClassifyCityNatureImageRequest",&,N,V_cityNatureRequest
_visionCanceler
T@"VNClassifyJunkImageRequest",&,N,V_junkImageRequest
_weight
T@"VNClassifyPotentialLandmarkRequest",&,N,V_landmarkRequest
T@"VNCreateSceneprintRequest",&,N,V_sceneprintRawRequest
addMovieInterestingnessResults:
T@"VNFaceObservation",&,V_observation
ageType
T@"VNGenerateObjectnessBasedSaliencyImageRequest",&,N,V_saliencyObjectnessRequest
analysisService
T@"VNRecognizeDocumentElementsRequest",&,N,V_documentRequest
analyzeFrame:withTimestamp:andDuration:properties:flags:cancel:
T@"VNRequest",R,N,V_request
assetId
T@"VNSession",R,N
autoCancellable
T@?,C,N,V_cancel
blurrinessScore
T@?,C,V_progressHandler
bundleForClass:
T@?,R,N,V_completionHandler
cachesResources
TB,D,N
centerX
TB,N,V_allowStreaming
classifications
TB,N,V_cancelled
clearMovieClassificationResults
TB,N,V_frameProcessedByFaceDetector
clearTimeValues
TB,N,V_frameProcessedByPetsActionAnalyzer
cnnData
TB,N,V_gyroStabilization
completeStorage
TB,N,V_hasAction
computeHighlightScoreOfSegment:
TB,N,V_hidden
conformsToType:
TB,N,V_isCloseup
contentAnalysis
TB,N,V_isHeadingFrame
convBlockClass:
TB,N,V_isLeftEyeClosed
copyTo:
TB,N,V_isSettlingOK
createInput:withBuffer:cnnInputHeight:cnnInputWidth:faceBounds:
TB,N,V_isTrimmed
dataWithLength:
TB,N,V_personBuilderMergeCandidatesDisabled
destroy
TB,N,V_validStabilization
detector:sharedModel:modelName:
TB,R,N
domains
TB,R,N,V_hasCachedParseData
embeddingHeight
TB,R,N,V_isHighResDecoded
endDate
TB,R,V_processAborted
espressoContext
TB,V_clusterIncludeTorsoOnlyFaces
expectedClasses
TB,V_generateOutput
facePrimarySuggestionsThreshold
TB,V_leftEyeClosed
facesFromAsset:
TB,V_personBuildingDisabled
finalizeAtTime:
TB,V_rightEyeClosed
forward
TB,V_smile
getPose
TB,V_trackingMode
hadZoom
TB,Vstable
handler
TI,N,V_flags
hasFlickerScore
TI,N,V_orientation
imageCompositionResultsAtIndex:
TI,N,V_version
imageDimensions
TI,R,N,V_orientation
includeRotation
TQ,N,V_activityID
initWithAnimalprint:confidence:
TQ,N,V_clustererBringUpState
initWithDevice:
TQ,N,V_longExposureSuggestionState
initWithParameters:poolY:chunk:
TQ,N,V_statsFlags
isDirty
TQ,R
isImage
TQ,R,N,V_attempts
isLeftEyeClosed
TQ,R,N,V_numOfFrames
isPhoto
TQ,R,N,V_type
isReady
TQ,R,V_type
isVideo
TQ,V_advancedStatusMergeCandidateLimit
landmarkRequest
TQ,V_faceID
localIdentifier
TQ,V_maxFaceCountForClustering
lowercaseString
TQ,V_minimumFaceGroupSizeForCreatingMergeCandidates
maxZoom
TQ,V_position
migrateFaceProcessingToVersion:
TS,N,V_ethnicityType
minZoom
TS,N,V_eyesState
mouthExpression
TS,N,V_glassesType
movieHighlightScoreResultsCount
TS,N,V_headgearType
movieInterestingnessResultsType
TS,N,V_skintoneType
movieOrientationResultsAtIndex:
TS,R,N
newCommandQueue
T^f,R
normalizedRectForRect:inBounds:
T^f,R,V_meanBlendshape
numberWithBool:
T^f,R,V_outputBeforeSpatiialPooling
objectKnowledge
T^f,R,V_outputRes4
originatingFace
T^f,R,V_videoEmbedding
payload
T^f,V_orientation
petsActionScore
T^v,N,V_analysisResultRef
photoLibraryURL
T^v,R,N,V_espressoContext
photosFaceRepresentationCenterY
T^{CGPoint=dd},VP
pixelBufferWithFormat:andMaxDimension:fromImageURL:orientation:
T^{__CVBuffer=},R,N
pixelsHighRange
Td,N,V_blurScore
pointWithPoint:
Td,N,V_bodyCenterY
predictedPersonUniqueIdentifier
Td,N,V_bodyWidth
processAndEstimateQualityScore:
Td,N,V_centerY
processPets:petsBounds:dominantPetIdx:frame:timestamp:duration:
Td,N,V_energy
progressHandler
Td,N,V_gazeCenterX
pv_performChangesAndWait:error:
Td,N,V_height
queryID
Td,N,V_poseYaw
ratioOfAssetsWithFacesProcessed
Td,N,V_roll
refineRegionsWithRequest:error:
Td,N,V_timestamp
releaseStorages
Td,N,V_x
requestRevision
Td,N,V_y
requestedOffset
Td,R,N
results
Td,R,V_elapsedTimeSeconds
saliencyRequest
Tf,N,V_absoluteScore
sceneId
Tf,N,V_activityScore
searchThreshold
Tf,N,V_autoplayScore
service
Tf,N,V_cameraMotionScore
Tf,N,V_confidence
setActiveCount:
Tf,N,V_cropFraction
setBodyCenterX:
Tf,N,V_cropRectWidth
setBox:
Tf,N,V_cropRectY
setContentType:
Tf,N,V_distanceToPreviousScene
setEnd:
Tf,N,V_exposureScore
setFaceQuality:
Tf,N,V_expressionScore
setFaceStatsFlag:detectedFaces:
Tf,N,V_faceSharpness
setFocusStatus:
Tf,N,V_frameExpressionScore
setGazeCenterX:
Tf,N,V_highlightScore
setGlassesType:
Tf,N,V_humanPoseScore
setInputImageWithCGImage:error:
Tf,N,V_inputBoundsHeight
setLongExposureSuggestionState:
Tf,N,V_inputBoundsX
setManualOrder:
Tf,N,V_interestScore
setMemeRequest:
Tf,N,V_junkScore
setMotionParam:
Tf,N,V_maxZoom
setMovieInterestingnessResults:
Tf,N,V_motionScore
setObservation:
Tf,N,V_overallFaceQualityScore
setOutputBlobs:
Tf,N,V_petsActionScore
setReachabilityForFlags:update:
Tf,N,V_relativeActionScore
setSourceWidth:
Tf,N,V_sceneprintDistanceToPreviousScene
setTextureType:
Tf,N,V_semanticScore
setUnderExpose:
Tf,N,V_sourceSizeHeight
setYaw:
Tf,N,V_stillTime
sexType
Tf,N,V_subjectScore
signpostPayload
Tf,N,V_textureness
smilingCategory
Tf,N,V_visualPleasingScore
sourceSizeWidth
Tf,N,V_x
startPointValue
Tf,R,N
stringByAppendingPathComponent:
Tf,R,N,V_exposureScore
surroundingText
Tf,R,V_actionScore
timeWithCMTime:
Tf,R,V_qualityScore
typeDescription
Tf,R,V_subtleMotionScore
unregisterAvailabilityObserver:
Tf,V_absMotion
updateModelByAddingFaces:error:
Tf,V_duration
vcp_description
Tf,V_faceClusteringThreshold
vcp_fingerprint
Tf,V_facePrimarySuggestionsThreshold
vcp_isLivePhoto
Tf,V_flag
vcp_needsVisualSearchProcessing
Tf,V_maxX
vcp_queryActionResultForPHFace:
Tf,V_minX
vcp_setQuality:
Tf,V_numSingletons
vcp_setVersion:
Tf,V_obstructionScore
version
Tf,V_score
wellKnownPhotoLibraryIdentifier
Tf,V_sumConfidence
Tf,V_weightedAveragePrecision
.cxx_construct
T@"NSArray",R,N
CalculateDotProductOfChunk
T@"NSData",&,N,V_statisticsBlob
DetectLinesWithThreshold:output:
T@"NSMutableArray",&,N,V_bounds
JSONObjectWithData:options:error:
T@"NSValue",R,N
SetKeyFramesForSegments:
T@"VCPProtoTime",&,N,V_duration
T@"<MTLCommandBuffer>",&,V_commandBuffer
T@,R,N,V_object
T@"<MTLDevice>",&,V_device
TB,N,V_hasSmile
T@"CLLocation",R,N
TB,R,N,GisReady
T@"MLMultiArray",&,N,V_angle
TQ,R,N,V_taskID
T@"NSArray",&,V_sceneResults
TS,N,V_hairType
T@"NSArray",C,N,V_documentObservations
T^f,R,N
T@"NSArray",R,N,V_globalMotion
T^{__CVBuffer=},N,V_pixelBuffer
T@"NSArray",R,V_csns
Tf,N,V_exposure
T@"NSData",&,N,V_colorNormalizationBlob
Tf,N,V_qualityScoreForLivePhoto
T@"NSData",&,N,V_featureBlob
Tf,V_faceClusteringAgeThreshold
T@"NSData",C,N,V_cachedParseData
Ti,N,V_position
T@"NSData",R,N,V_data
Ti,N,V_shotType
T@"NSDate",R,N
Ti,V_classIndex
T@"NSDictionary",&,N,V_results
T{?=[4]},V_pose
T@"NSDictionary",R,&,N
_action
T@"NSDictionary",R,N,V_blendShapes
_active
T@"NSMutableArray",&,N,V_classifications
_activityScores
T@"NSMutableArray",&,N,V_faceQualityScores
_alphas
T@"NSMutableArray",&,N,V_frameInstructions
_audioTimestamp
T@"NSMutableArray",&,N,V_imageCompositionResults
_blocks
T@"NSMutableArray",&,N,V_imageFaceResults
_bounds
T@"NSMutableArray",&,N,V_imageHumanPoseResults
_buffer
T@"NSMutableArray",&,N,V_imagePetsFaceResults
_cflags
T@"NSMutableArray",&,N,V_imageSaliencyResults
_closeSuggestionsLoggingSession
T@"NSMutableArray",&,N,V_imageShotTypeResults
_clusteringType
T@"NSMutableArray",&,N,V_livePhotoEffectsResults
_cnnOutputWidth
T@"NSMutableArray",&,N,V_livePhotoKeyFrameResults
_connectionLock
T@"NSMutableArray",&,N,V_livePhotoRecommendationResults
_curBlendshapes
T@"NSMutableArray",&,N,V_motionBlurVector
_decodeFinished
T@"NSMutableArray",&,N,V_movieApplauseResults
_device
T@"NSMutableArray",&,N,V_movieBabbleResults
_downsampleBeforeFaceProcessing
T@"NSMutableArray",&,N,V_movieCheeringResults
_encodeAnalysis
T@"NSMutableArray",&,N,V_movieFaceResults
_existingScenes
T@"NSMutableArray",&,N,V_movieFeatureResults
_faceID
T@"NSMutableArray",&,N,V_movieHighlightResults
_facesFromFaceGroupWithMostNumberOfFacesOnPerson:options:error:
T@"NSMutableArray",&,N,V_movieHumanActionResults
_featureResults
T@"NSMutableArray",&,N,V_movieInterestingnessResults
_frameTimeRange
T@"NSMutableArray",&,N,V_movieLoudnessResults
T@"NSMutableArray",&,N,V_movieMusicResults
_groundTruthURL
T@"NSMutableArray",&,N,V_movieOrientationResults
_handID
T@"NSMutableArray",&,N,V_moviePetsResults
_heightBlockNum
T@"NSMutableArray",&,N,V_movieQualityResults
_highlightScore
T@"NSMutableArray",&,N,V_movieSceneResults
_idealHistogram
T@"NSMutableArray",&,N,V_movieStabilizationResults
_inputBlobNames
T@"NSMutableArray",&,N,V_movieSubtleMotionResults
_inputSemaphore
T@"NSMutableArray",&,N,V_movieUtteranceResults
_isFast
T@"NSMutableArray",&,N,V_petsDetections
_isIris
T@"NSMutableArray",&,V_outputSize
_keyFrameScores
T@"NSMutableArray",&,V_recallPerPersonExcludeMissDetection
_livePhotoRecommendationResults
T@"NSMutableArray",&,V_size
_manual
T@"NSMutableArray",R,&,N,V_highlights
_meanBlendshape
T@"NSMutableDictionary",&,N,V_frameResults
_modelLandmarks
T@"NSMutableDictionary",R,V_clusterFlagByClusterId
_mutableResults
T@"NSString",&,N,V_assetAdjustedFingerprint
_numBoundaryLms
T@"NSString",&,N,V_assetMasterFingerprint
_numOfLandmarks
T@"NSString",&,N,V_signpostPayload
_numberOfFrames
T@"NSString",C,N,V_adjustmentVersion
_offset
T@"NSString",C,N,V_personLocalIdentifier
_outputBeforeFc
T@"NSString",R,C,N,V_localIdentifier
_pairedAssetURL
T@"NSString",R,N,V_clientBundleID
_petsDetections
T@"NSString",R,N,V_localIdentifier
_points3DCamera
T@"NSString",R,N,V_resConfig
_preferredWidth
T@"NSString",R,V_master
_prevLM
T@"NSString",R,V_person2LocalIdentifier
_processAborted
T@"NSString",R,V_requestId
_progressBlocks
T@"PHAsset",R,N,V_asset
T@"PHFetchResult",R,N
_qualityResults
T@"VCPCNNData",R,V_output
_reason
T@"VCPCNNMetalContext",R,V_context
_reportPetsAnalysisWithResults:
T@"VCPFaceGeometry",R,N,V_geometry
_reserveBudget:
T@"VCPHomeKitAnalysisSession",W,N,V_weakSession
_rightEyeClosed
T@"VCPMADResource",&,N,V_resource
_samplesForProcessingBufferList
T@"VCPPhotosFace",R,N,V_face1
_scaler
T@"VCPProtoBounds",&,N,V_faceBounds
_screenProgress
T@"VCPProtoLine",&,N,V_dominantLine
_sqlSerialQueue
T@"VCPProtoLivePhotoVariationParams",&,N,V_bounce
_statisticsBlob
T@"VCPProtoLivePhotoVariationParams",&,N,V_stabilize
_stride
T@"VCPProtoPoint",&,N,V_start
_sumMotionParam
T@"VCPProtoTime",&,N,V_start
_taskID
T@"VCPProtoTimeRange",&,N,V_timeRange
_transcodeQueue
T@"VCPVNImageprintWrapper",&,N,V_imageprintWrapper
T@"VCPVideoKeyFrame",&,N,V_keyFrame
_updateFaceprint:forFace:error:
T@"VIService",R,N
_useGPU
T@"VN5kJNH3eYuyaLxNpZr5Z7zi",&,N,V_semanticRequest
_vanishingPoint
T@"VNCanceller",R,V_canceller
_videoEmbedding
T@"VNClassifyImageAestheticsRequest",&,N,V_aestheticsRequest
_visionClusterMemmapFileInCacheDirectoryURL:clusterState:error:
T@"VNClassifyMemeImageRequest",&,N,V_memeRequest
T@"VNCreateImageFingerprintsRequest",&,N,V_imagefingerprintsRequest
addFaceResults:
T@"VNCreateSceneprintRequest",&,N,V_sceneprintRequest
addSettling:to:
T@"VNGenerateAttentionBasedSaliencyImageRequest",&,N,V_saliencyRequest
allKeys
T@"VNImageRequestHandler",R,N,V_requestHandler
analyzeFrame:withBox:keypoints:
T@"VNRecognizeObjectsRequest",&,N,V_objectRequest
arrayWithArray:
T@"VNSceneClassificationRequest",&,N,V_classificationRequest
assetIdentifier
T@"VNVYvzEtX1JlUdu8xx5qhDI",&,N,V_nsfwRequest
base64EncodedStringWithOptions:
T@?,C,N,V_cancelBlock
T@?,C,V_updateHandler
cachedParseData
calculateAndReportClusterAccuracyWithVisionClusterURL:andPersonClusters:withGroundtruth:results:extendTimeoutBlock:cancelBlock:
TB,N
centerY
TB,N,V_autoPlayable
classifyVIPPets
TB,N,V_faceDominated
clearMovieHighlightScoreResults
TB,N,V_frameProcessedByHumanAnalyzer
cloudIdentifier
TB,N,V_frameProcessedByVideoAnalyzer
cnnOutputHeight
TB,N,V_hadZoom
compressCVPixelBuffer:toJPEGData:targetBitStreamLength:padding:
TB,N,V_hasFaceMask
computeOverallFaceQualityScore:
TB,N,V_isAutoPlayable
containsObject:
TB,N,V_isFast
context
TB,N,V_isInTrash
copyScoresFrom:
TB,N,V_isRightEyeClosed
countForObject:
TB,N,V_isTooSmall
createModelWithHeight:srcWidth:
TB,N,V_manual
dealloc
TB,N,V_subMbMotionAvailable
detectPoseForFace:inBuffer:yaw:
TB,R
documentRequest
TB,R,N,V_bufferRotated
drawImage:pixelFormat:withOrientation:maxDimension:pixelBuffer:
TB,R,N,V_hasWifiOrEthernetConnection
TB,R,N,V_useCPUOnly
errorWithStatus:andDescription:
TB,R,V_started
execute
TB,V_faceClusteringDisabled
expressionScore
TB,V_isInputOutput
faceResultsType
TB,V_personBuilderMergeCandidatesDisabled
fetchPersonForFaceCrop:options:
TB,V_quarantineTwinsOnAssetEnabled
fingerprintWithMaster:adjusted:
TB,V_sdof
fullPixelBuffer:toScaledBuffer:
TB,V_suggestionsLogEnabled
glassesCategory
TB,VlostTrack
handKeypointsDetection:box:keypoints:keypointConfidence:forGFT:
TI,N,V_faceID
hasContentScore
TI,N,V_identifier
hasPlaybackCrop
TI,N,V_types
imageConstraint
TI,R,N,V_inputPixelFormat
includeDocument
TI,R,N,V_revision
initNewContext:
TQ,N,V_algorithmVersion
initWithConfig:
TQ,N,V_count
initWithFormat:
TQ,N,V_loopSuggestionState
initWithResultItems:andPayload:
TQ,N,V_typesWide
isEqualToValue:
TQ,R,N
isJunkTimeRange:basedOnResults:
TQ,R,N,V_frameInterval
isMovie
TQ,R,N,V_numOfValidFrames
isProxy
TQ,R,N,V_vertexCount
isShort
TQ,R,V_vertexCount
keyFace
TQ,V_advancedStatusVerifiedPersonLimit
livePhotoEffectsResultsAtIndex:
TQ,V_flags
lookupTextWithQuery:completion:
TQ,V_minFaceCountToTriggerClustering
mad_internalPredicateForTaskID:
TQ,V_minimumSuggestionSize
maximumHierarchicalObservations
TS,N,V_ageType
minFaceCountToTriggerClustering
TS,N,V_expressionType
motionParamDiff
TS,N,V_facialHairType
movieClassificationResultsCount
TS,N,V_hairColorType
movieHumanActionResultsAtIndex:
TS,N,V_sexType
movieObstructionResultsAtIndex:
TS,N,V_smileType
multiArrayValue
T^,R,V_meshVertices
newFaceCropFromImageData:withFaceRect:groupingIdentifier:error:
T^f,R,V_componentsBlendshape
T^f,R,V_outputBeforeFc
numberWithChar:
T^f,R,V_outputBeforeTemporalPooling
objects
T^f,R,V_tensorCoeff
parseKeypoints:
T^f,V_data
persons
T^i,R,V_blendshapeComponentIndex
phAsset
T^v,N,V_correctionResultRef
photosFaceRepresentationCenterX
T^{CGPoint=dd}
photosFaceRepresentationQuality
T^{__CVBuffer=},N,V_inputImage
pixelFormatType
Td,N,V_assetModificationDate
pixelsWideRange
Td,N,V_bodyCenterX
poseYaw
Td,N,V_bodyHeight
predictionFromInputImage:error:
Td,N,V_centerX
processImage:withOptions:error:
Td,N,V_date
processVideoFragmentAssetData:withOptions:andCompletionHandler:
Td,N,V_exposureScore
pv_fetchMoments
Td,N,V_gazeCenterY
quality
Td,N,V_peak
queryProgress:forPhotoLibrary:andTaskID:withExtendTimeoutBlock:
Td,N,V_quality
rectFromPHFace:
Td,N,V_size
release
Td,N,V_width
request
Td,N,V_x0
requestedLength
Td,N,V_y0
resourceForAsset:withResources:
Td,R,N,V_distance
Tf,N,V_absoluteActionScore
saveAndReturnCurrentModelState:
Tf,N,V_actionScore
sceneIdentifier
Tf,N,V_analysisConfidence
semanticRequest
Tf,N,V_averageScore
session
Tf,N,V_colorfulnessScore
setActionScore:
Tf,N,V_contentScore
setArrayLength:
Tf,N,V_cropRectHeight
setBodyCenterY:
Tf,N,V_cropRectX
setCancelBlock:
Tf,N,V_curationScore
setCurrentCost:
Tf,N,V_exposureChangeScore
setFaceClusteringJunkThreshold:
Tf,N,V_expressionChangeScore
setFaceResults:
Tf,N,V_faceQuality
setFeatureBlob:
Tf,N,V_flickerScore
setFrameLength:
Tf,N,V_globalQualityScore
setGazeCenterY:
Tf,N,V_humanActionScore
setHasFaceMask:
Tf,N,V_humanScore
setKeyFrameTime:isHeadingFrame:
Tf,N,V_inputBoundsWidth
setLoopFadeLen:
Tf,N,V_inputBoundsY
setMaximumSize:
Tf,N,V_interestingnessScore
setMinimumSize:
Tf,N,V_maxHighlightDuration
setMotionScore:
Tf,N,V_minZoom
setNsfwRequest:
Tf,N,V_obstructionScore
setOrientation:
Tf,N,V_penaltyScore
setPixelBuffer:
Tf,N,V_qualityScore
setRequestedTimeToleranceAfter:
Tf,N,V_relativeScore
setSymbologies:
Tf,N,V_score
setTextureness:
Tf,N,V_sharpness
setWeakSession:
Tf,N,V_sourceSizeWidth
settlingEffects
Tf,N,V_subjectActionScore
sharedModelPool
Tf,N,V_textureScore
slowMotionRampInRangeForExport:
Tf,N,V_underExpose
softmax
Tf,N,V_voiceScore
stabilizeResult
Tf,N,V_y
started
Tf,R,N,V_confidence
stringFromDate:
Tf,R,N,V_score
timeValuesCount
Tf,R,V_motionDivScore
trackID
Tf,R,V_sharpness
uiScale
Tf,R,V_textureScore
updateDuration:
Tf,V_actionScore
usePHAssetScene
Tf,V_faceClusteringJunkThreshold
vcp_enabledTracksWithMediaType:
Tf,V_faceMergeFaceprintDistanceThreshold
vcp_isDecodable
Tf,V_faceQuality
vcp_isSdofPhoto
Tf,V_interestingnessScore
vcp_orientation
Tf,V_maxY
vcp_quickFaceClassificationDone
Tf,V_minY
vcp_setResults:
Tf,V_numValidSingletons
vcp_vipModelFilepathForVIPType:
Tf,V_qualityScore
voiceDetections
Tf,V_stabilityScore
Tf,V_trackingScore
Tf,V_weightedAverageRecall
Ti,N,V_chirality
Ti,N,V_cropRectHeight
Ti,N,V_cropRectWidth
Ti,N,V_cropRectX
Ti,N,V_cropRectY
Ti,N,V_errorCode
Ti,N,V_exitStatus
Ti,N,V_eyeExpression
Ti,N,V_faceID
Ti,N,V_flags
Ti,N,V_handID
Ti,N,V_loopFadeLen
Ti,N,V_loopPeriod
Ti,N,V_loopStart
Ti,N,V_minVersion
Ti,N,V_motionType
Ti,N,V_mouthExpression
Ti,N,V_orientation
Ti,N,V_stabilizeResult
Ti,N,V_timeScale
Ti,N,V_timescale
Ti,N,V_trainingType
Ti,N,V_version
Ti,N,V_yaw
Ti,R,N,V_cnnOutputHeight
Ti,R,N,V_cnnOutputWidth
Ti,R,N,V_lostCount
Ti,R,N,V_version
Ti,R,V_embeddingChannels
Ti,R,V_embeddingHeight
Ti,R,V_embeddingSequenceLength
Ti,R,V_embeddingWidth
Ti,R,V_numVertices
Ti,V_detectionModeCounterShapeModel
Ti,V_processingMode
Ti,V_processingVersion
Ti,V_trackID
Tq,D,N
Tq,N
Tq,N,V_activeCount
Tq,N,V_clusterSequenceNumber
Tq,N,V_currentCost
Tq,N,V_epoch
Tq,N,V_nameSource
Tq,N,V_outputFrameDurValue
Tq,N,V_qualityMeasure
Tq,N,V_sourceHeight
Tq,N,V_sourceWidth
Tq,N,V_timeValue
Tq,N,V_value
Tq,R,N
Tq,R,N,V_inputSize
Tq,R,V_status
Tq,V_focusStatus
Tq,V_yaw
Tr^f,R,N
Transform
Ts,N,V_detectionType
Ts,N,V_state
T{?=[4]},R,N,V_pose
T{?=[4]},R,N,V_transform
T{?=^v^v[4Q][4Q]QQQQQQQQQQi},N,V_inputBlob
T{?=^v^v[4Q][4Q]QQQQQQQQQQi},N,V_outputBlob
T{?=qiIq},N,V_timestamp
T{?=qiIq},R,N,V_start
T{?=qiIq},R,N,V_timeInterval
T{?=qiIq},R,N,V_timeStamp
T{?=qiIq},V_last
T{?=qiIq},V_start
T{?={?=qiIq}{?=qiIq}},N,V_timeRange
T{?={?=qiIq}{?=qiIq}},N,V_timerange
T{?={?=qiIq}{?=qiIq}},R,N
T{?={?=qiIq}{?=qiIq}},R,N,V_timeRange
T{?={?=qiIq}{?=qiIq}},R,N,V_timerange
T{?={?=qiIq}{?=qiIq}},V_timerange
T{CGPoint=dd},N,V_location
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_bestPlaybackCrop
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,V_objectBounds
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,V_objectBoundsInitial
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,V_regionOfInterest
T{CGRect={CGPoint=dd}{CGSize=dd}},V_bound
T{CGRect={CGPoint=dd}{CGSize=dd}},V_bounds
T{CGSize=dd},R,N,V_resolution
T{CLLocationCoordinate2D=dd},R,N
T{array<float, 6UL>=[6f]},N,V_motionParam
T{array<float, 6UL>=[6f]},N,V_motionParamDiff
T{vector<espresso_buffer_t, std::allocator<espresso_buffer_t>>=^{?}^{?}{__compressed_pair<espresso_buffer_t *, std::allocator<espresso_buffer_t>>=^{?}}},N,V_inputBlobs
T{vector<espresso_buffer_t, std::allocator<espresso_buffer_t>>=^{?}^{?}{__compressed_pair<espresso_buffer_t *, std::allocator<espresso_buffer_t>>=^{?}}},N,V_outputBlobs
URLByAppendingPathComponent:
URLByAppendingPathComponent:isDirectory:
URLByAppendingPathExtension:
URLByDeletingLastPathComponent
URLForDirectory:inDomain:appropriateForURL:create:error:
URLForResource:withExtension:
URLOfModelInThisBundle
URLWithString:
URLWithString:relativeToURL:
UTF8String
UUID
UUIDString
VN1uMyFtnYEWjbrdx3yAuDndKkPeyzNJhB
VN2riiZbQrloRhCzYW56f0rk4N3ROe151S
VN3iT1YRjjnIuELobV1olJiO1vvItN6Kdq
VN4UfLbvVUqMvYV8bbGFQcxg5yRLm8ekI1
VN7exwFFmQF0AI9P7FjBljwEFu7QYUGCYE
VN7fiLHgGnvqPqG63cfDUCK4Xm8obUuWoP
VNpLorzxnyAlLcPFNcKhgoNCmy9b5BRWyk
_LM2D
_LM3D
_SNAnalyzer
_absMotion
_absoluteActionScore
_absoluteScore
_accHalfHeight
_accHeight
_accWidth
_accumulatedChangesCount
_accumulator
_actionResults
_actionScore
_actionScoreAbsolute
_actionScoreRelative
_actions
_activeConfidence
_activeCount
_activeEnd
_activeFaces
_activeFrameIndices
_activeHinkleyDetector
_activePoseResults
_activeRegions
_activeScore
_activeSegment
_activeStart
_activeThreshold
_activityDescriptor
_activityID
_activityScore
_addClassificationResults:analysis:
_adjustConfirmingAndRejectionWithFaces:faceCrops:cancelOrExtendTimeoutBlock:
_adjusted
_adjusterArray
_adjustmentVersion
_adjustmentsRequest
_advancedStatusMergeCandidateLimit
_advancedStatusVerifiedPersonLimit
_aestheticsRequest
_ageType
_aggregatedResults
_algorithmVersion
_alignBoundingBoxOfFaces:withRequestHandler:orientedWidth:orientedHeight:
_alignFaceObservations:withRequestHandler:error:
_allFaces
_allocator
_allowANE
_allowOnDemand
_analysis
_analysisConfidence
_analysisDict
_analysisInput
_analysisPreferencesURL
_analysisQueue
_analysisResultRef
_analysisSessionRef
_analysisTypes
_analyzeOndemand:forAnalysisTypes:withExistingAnalysis:andOptions:storeAnalysis:cancelBlock:
_analyzeWithStart:andDuration:error:
_analyzer
_angle
_angleStable
_angleStep
_anonymizedName:
_appendToSuggestionsLog:
_argbPixelBuffer
_argbTransferSession
_asset
_assetAdjustedFingerprint
_assetIdentifier
_assetMasterFingerprint
_assetModificationDate
_assetReader
_assetURL
_associateFace:withFaceCrop:error:
_asyncBlendshapes
_asyncExtMat
_asyncLm2d
_asyncLmBlendshapes
_asyncWeights
_attempts
_audioAnalyzer
_audioBufferList
_audioClassifier
_audioQualityAggregated
_audioQualityResults
_audioStream
_audioUnit
_autoPlayable
_autoloop
_autoplay
_autoplayScore
_avAsset
_averageScore
_backbone
_backwarp
_barcodeObservations
_batchAnalyses
_batchNorm
_batchSize
_bestFaceForFaceDetectionRequest:withRect:
_bestPlaybackCrop
_bestTrimTimeRange
_bias
_bilinearScale
_blendShapeDelta
_blendShapes
_blendshapeComponentIndex
_block
_blockSize
_blurAnalyzer
_blurScore
_bodyArray
_bodyCenterX
_bodyCenterY
_bodyHeight
_bodyWidth
_bound
_boundaryLandmarkValidity
_boundaryLmIndices
_boundaryLmUpdated
_boundaryVertices
_bringUpStateDescription:
_bufferHeight
_bufferRotated
_bufferWidth
_bufferedSamples
_buildPersonsFromUpdatedFaceGroups:faceClusterer:keyFaceUpdateBlock:cancelOrExtendTimeoutBlock:context:
_cacheDirUrl
_cacheFileUrl
_cachedExif
_cachedImageDimensions
_cachedImageHandler
_cachedParseData
_cachedRequestIdealDimension
_cachedResources
_cachedScenes
_calculateIoUBetweenObservation:andObservation:
_calculateOverlappingBetweenFaceObservation:andHumanObservation:
_callbackQueue
_cameraMotion
_cameraMotionConfidences
_cameraMotionParams
_cameraMotionResults
_cameraMotionScore
_cameraOrientation
_cancelBlock
_cancelClusteringAndRestoreClusterCache:
_cancelDecode
_cancelOrExtendTimeoutBlock
_cancelQueue
_cancelTokens
_canceled
_cancellable
_cancelled
_canceller
_captureTime
_categorizeGroupedFacesInFetchResult:intoFaceLocalIdentifiersByFaceGroup:ungroupedFaceLocalIdentifiers:cancelOrExtendTimeoutBlock:photoLibrary:
_centerX
_centerY
_cgContext
_chCount
_chPtSelected
_chPts
_checkAnalysisRequests:forTooSmallFaceObservations:withAnalysisResults:
_checkDuplicate:withAsset:duplicate:
_chirality
_chunk
_cityNatureRequest
_classIndex
_classIndexTracker
_classificationRequest
_classificationResults
_classifications
_classifiers
_classifyFaces:forAsset:detectedPersons:
_cleanupMergeCandidatesForVerifiedPersons:minimumFaceGroupSize:cancelOrExtendTimeoutBlock:error:
_clearDirtyStateOnFaceCrop:error:
_clientTeamID
_clusterDumpFaceFetched
_clusterFlagByClusterId
_clusterIncludeTorsoOnlyFaces
_clusterSequenceNumber
_clusterer
_clustererBringUpState
_cnnInputWidth
_cnnOutputHeight
_collectSceneAnalysisResults:fromRequests:wpResults:ivsResults:abnormalDimension:
_colorNormalization
_colorNormalizationAnalyzer
_colorNormalizationBlob
_colorfulness
_colorfulnessScore
_commandBuffer
_commandQueue
_completePersonBuildingWithPersonsToUpdate:facesToRemoveByPerson:facesToAddByPerson:updateFaceGroup:newMergeCandidatePairs:newInvalidMergeCandidatePairs:faceInFaceGroupByCSN:personCache:keyFaceUpdateBlock:cancelOrExtendTimeoutBlock:context:error:
_completionHandler
_componentsBlendshape
_computationAccuracy
_computeFingerPrintsOfAsset:completionHandler:
_confidence
_confidenceMap
_confidences
_configureRequest:
_configureRequest:withRevision:preferANE:
_configureRequestWithRevision:
_connection
_contentScore
_context
_contrast
_controlPointsCamera
_controlPointsWorld
_convertFromBuffer:toLumaPixelBuffer:abnormalDimension:
_copyImageAtURLToSuggestionsLoggingSession:
_correctionResultRef
_correlation
_correlationKernel
_correlationTracker
_count
_countAnalysisWithAssetBatch:andDatabase:andTaskID:
_countEmbeddingAnalysisWithAssetBatch:
_countFaceAnalysisWithAssetBatch:
_countFailuresWithAssetBatch:andDatabase:andTaskID:
_countMediaAnalysisWithAssetBatch:andDatabase:analyzedCount:completeAnalyzedCount:partialAnalyzedCount:
_countOCRAnalysisWithAssetBatch:
_countSceneAnalysisWithAssetBatch:
_countVisualSearchAnalysisWithAssetBatch:
_createBlurRequests:andExposureRequests:forFaceObservations:
_createPixelBuffer:withColorSpace:fromPixelBuffer:
_createPixelBuffer:withMinorDimension:fromFullPixelBuffer:
_createPixelBuffer:withWidth:andHeight:
_createPixelBufferPool:withBufferWidth:bufferHeight:andPixelFormat:
_createPixelBufferWithWidth:height:pixelFormat:pixelBuffer:
_createRequests:withMediaType:
_crop
_cropFraction
_cropRectWidth
_cropRectX
_cropRectY
_cropSize
_csns
_ctx
_cur2D
_curCoeff
_curLM
_curMesh
_curationScore
_curationThreshold
_currentCost
_currentSample
_currentStatus
_currentStatusSnapshot
_currentStatusSnapshotIsValid
_currentStatusSnapshotLock
_currentSuggestionRequest
_data
_dataTask
_database
_databaseForPhotoLibrary:
_databases
_date
_deSerializedMetaBuffer
_decodeEnd
_decodeError
_decodeSession
_decodedFrames
_decoderSettings
_defaultAssetFetchOptions
_defaultAssetPropertySets
_defaultFacePropertySets
_defaultFetchOptions
_defaultPhotoLibrary
_defaultPhotoLibraryURL
_deleteAllVerifiedPersonsWithError:
_descriptor
_descriptorResults
_detectDuplicationInExistingFaceCrops:withFetchedFaces:faceCropFaceIdentifiersToEvaluate:duplicationResults:cancelOrExtendTimeoutBlock:
_detectedFaces
_detectionModeCounter
_detectionType
_detectionVersion
_detections
_detectors
_diff
_diffFlipCount
_diffVariance
_distance
_distanceToPreviousScene
_distanceVariance
_documentObservations
_documentRequest
_dominantHand
_dominantLine
_downScaleHeight
_downloadGroup
_dumpAssetsToFaces
_dumpFaceprint
_duplicateFaceCSNsOnAssetForPerson:faceCSNsOnPerson:faceByCSNCache:
_duration
_edgeMap
_edgeWeightMap
_elapsedTimeSeconds
_embeddingChannels
_embeddingHeight
_embeddingSequenceLength
_enableSceneAssetConcurrency
_encodeSession
_end
_endTime
_enoughFrames
_enumeratePersonsWithLocalIdentifiers:fetchOptions:personCache:usingBlock:
_epoch
_errorCode
_espressoContext
_ethnicityType
_eulerAngle
_executedOnGPU
_existingAnalysis
_existingFaceprints
_existingFacesFromAsset:
_existingHands
_existingPersons
_existingPersonsArray
_existingResults
_exitStatus
_exportAssetsToFacesDetails:
_exportReencodedJPEG
_exposure
_exposureChangeScore
_exposureScore
_exprWeightDiagMatrix
_expressionChangeScore
_expressionScore
_expressionSegments
_extractAndSortBoundingBoxFromDetectedObjects:
_extrinsicMatrix
_eyeExpression
_eyesState
_face1
_face2
_faceAnalyzer
_faceArea
_faceAssociatedWithFaceCrop:
_faceBounds
_faceCSNsInClusterCache
_faceCSNsToRemove
_faceClusterer
_faceClusteringAgeThreshold
_faceClusteringDisabled
_faceClusteringJunkThreshold
_faceClusteringThreshold
_faceCount
_faceCropData
_faceDetector
_faceDominated
_faceFromFaceCrop:error:
_faceHeatMap
_faceIdStrsToAdd
_faceInput
_faceMergeFaceprintDistanceThreshold
_faceMerger
_faceModel
_faceObservationsWithBoundingBoxFromFaces:withFaceHashMapping:
_facePrimarySuggestionsThreshold
_facePrints
_faceProcessingContext
_faceProcessingPassGoalWithExtendTimeout:
_faceQuality
_faceQualityAnalyzer
_faceQualityScores
_faceRanges
_faceResults
_faceSharpness
_faceToFaceCountMapForFaces:
_faceTorsoprintsFromFaceCSNs:
_faceTorsoprintsFromFaceIdentifiers:assignClusterSeqNumberIfNeeded:updatedFaces:groupingIdentifiers:
_faceTorsoprintsFromFaces:assignClusterSeqNumberIfNeeded:updatedFaces:
_faceTrackers
_faceValidator
_faceprintBlob
_faceprintFastMode
_faces
_fastFaceMigrationEnabled
_fastGestureDetector
_featureBlob
_featureBlobNames
_featureChannels
_featureExtractor
_featureName
_fetchPeopleHomePersons
_fetchPersonWithIdentifier:facesPerAsset:assetInformation:extendTimeoutBlock:cancelBlock:
_fetchPersonsToFeedVIPModel:allowUnverifiedPerson:
_fetchPetsToFeedVIPModel
_fetchResultForGroupedFacesWithClusterSequenceNumberSetToZeroInPhotoLibrary:
_fetchResultForUngroupedFacesWithNonZeroClusterSequenceNumberInPhotoLibrary:
_filepath
_filterBanks
_filterNum
_filterSize
_finalizeSuggestionsLog
_finalized
_fineActionResults
_firstBuffer
_firstFrame
_firstLocallyAvailableResourceFromResources:
_flag
_flags
_flickerScore
_flow
_flowDecoder
_flowDecoderSemaphore
_flowHeight
_flowWidth
_flushModel
_focalLengthInPixels
_focusStatus
_forceCPU
_forceNNGraph
_formatDescription
_frame
_frameArray
_frameBuffer
_frameCount
_frameCounter
_frameEndTimeStamp
_frameExpressionScore
_frameFaceResults
_frameHeight
_frameIndex
_frameInstructions
_frameInterval
_frameNum
_framePTSResults
_framePosition
_frameProcessedByFaceDetector
_frameProcessedByHumanAnalyzer
_frameProcessedByPetsActionAnalyzer
_frameProcessedByVideoAnalyzer
_frameResults
_frameSize
_frameStartTimeStamp
_frameStats
_frameTimestampArray
_frameWidth
_gaborFilter
_gazeCenterX
_gazeCenterY
_gazeType
_generateAndAssociateFaceprintedFaceForFaceCrop:faceCropFaceLocalIdentifier:error:
_generateLastFrameDistanceDescriptor:withDescriptorClass:forAsset:
_generatePersonsModelWithExtendTimeoutBlock:cancel:evaluationMode:allowUnverifiedPerson:
_generatePetsModelWithExtendTimeoutBlock:cancel:
_generateSceneClassifications:fromRequests:
_generateVideoCaption
_geometry
_getDatabaseSandboxExtensionForPhotoLibraryURL:
_getDistanceDescriptorClass
_getMergeCandidates:invalidMergeCandidates:forPersonsWithLocalIdentifiers:
_getRejectedTrainingFaceCSNs:rejectedFaceCSNs:rejectedPersonLocalIdentifiers:forPerson:faceInFaceGroupByCSN:
_getSHRevision
_getSandboxExtensionForMediaAnalysisDatabaseWithPhotoLibraryURL:
_getSceneDescriptors:asDescriptorClass:withSceneRange:andAnalysisResults:
_getThumbnailForAsset:withResouces:andPixelFormat:
_getTrainingFacesByPerson:confirmedFaceCSNs:faceCSNsByPerson:faceCSNsByMigratedPerson:faceCSNsByQuickClassificationPerson:mergeCandidates:invalidMergeCandidates:rejectedPersonsByPerson:faceInFaceGroupByCSN:inFaces:personCache:cancelOrExtendTimeoutBlock:
_glassesType
_globalMotion
_globalQualityScore
_gradient
_gradientMag
_gradientX
_gradientY
_group
_groupingIdentifier
_guidedFilter
_gyroHomographyDimension
_gyroHomographyIsValid
_gyroStabilization
_hadFlash
_hadZoom
_hairColorType
_hairType
_handChiralityCounter
_handDetectedInPreviousFrame
_handKeypointTracker
_handler
_handlerQueue
_handsDetector
_handsKeypointsDetector
_has
_hasAction
_hasCachedParseData
_hasFaceMask
_hasFaceOrPet
_hasFlash
_hasInterestingScene
_hasSmile
_hasWifiOrEthernetConnection
_hash
_headgearType
_heatmapNms
_heightExt
_heightInMb
_heightPadded
_highResOrientation
_highResPixelBuffer
_highlight
_highlightAnalyzer
_highlightResults
_highlights
_hinkleyDetector
_homeKitMotionAnalyzer
_homographyParams
_homographyResults
_humanActionResults
_humanActionScore
_humanActionWindowSize
_humanPoseResults
_humanRect
_humanScore
_identifier
_identityInit
_idxCurrent
_idxLast
_ignoreFace
_image
_imageAsset
_imageBlurResults
_imageBlurTextureScore
_imageCaptionModel
_imageCompositionResults
_imageData
_imageExposureResults
_imageExposureTime
_imageFaceResults
_imageFeature
_imageFeatureResults
_imageFiltered
_imageHumanPoseResults
_imageJunkResults
_imageLoader
_imageManager
_imagePetsFaceResults
_imagePetsResults
_imagePrint
_imageSaliencyResults
_imageSceneprintResults
_imageShotTypeResults
_imageURL
_imagefingerprintsRequest
_imageprintWrapper
_inDetectionMode
_inTrimEnd
_inTrimStart
_inactiveDate
_includeCN
_includeDMF
_includeDO
_includeDocument
_includeIVS
_includeLM
_includeMeme
_includeNSFW
_includePA
_includeRotation
_includeSDG
_includeSE
_includeSO
_includeTorsoOnlyFaces
_includeWP
_initialized
_input
_inputBlob
_inputBlobName
_inputBlobs
_inputBoundsHeight
_inputBoundsWidth
_inputBoundsX
_inputBoundsY
_inputBuffer
_inputChannels
_inputData
_inputFeatureName
_inputHeight
_inputImage
_inputKeyFrameResults
_inputNames
_inputPixelFormat
_inputSize
_inputWidth
_inputsData
_insertBoundingBox:toSortedBoundingBoxes:
_interestScore
_interestingness
_interestingnessResults
_interestingnessScore
_internalConstraintResults
_internalFrameScenes
_internalLandmarkDetector
_internalResults
_interpolatedFrameArray
_interruptionHander
_intrinsicMatrix
_irisAnalyses
_irisAnalysis
_isCaptureAnalysis
_isCloseup
_isColocatingAnimalObservation:withFaceObservations:orTorsoObservations:
_isHighResDecoded
_isInTrash
_isInputOutput
_isLeftEyeClosed
_isLivePhoto
_isMaxTrim
_isMovieWithMediaType:
_isOneShot
_isPanoWithMediaType:andMediaSubtypes:
_isRightEyeClosed
_isSDOFWithMediaType:andMediaSubtypes:
_isSettlingOK
_isSlowMo
_isTimelapse
_isTooSmall
_isTrimmed
_ivsPool
_junkImageRequest
_junkResults
_junkScore
_keepCurrentPersonsModelWithExtendTimeout:
_keyFaces
_keyFrame
_keyFrameAnalyzer
_keyFrameResults
_keyFrames
_keyPersonResults
_keyPetResults
_keypoints
_landmarkDetector
_landmarkRequest
_landmarks
_last
_lastHumanTimestamp
_lastJawOpenness
_lastMinimumFaceGroupSizeForCreatingMergeCandidates
_lastPetTimestamp
_lastProcessTime
_lastRetryDate
_lastTimestamp
_lastVertices
_lastestFaceID
_latestFrameArea
_latestRegions
_latestTrackID
_launchOnce
_leftEyeClosed
_leftHandKeypointTracker
_level0ClusterIdForFaceCSN:level0Clusters:
_lightMotionAnalyzer
_livePhotoEffectsResults
_livePhotoHumanActionClassificationResults
_livePhotoKeyFrameResults
_livePhotoKeyFrameStillResults
_livePhotoSharpnessResults
_livePhotoStillDisplayTime
_lm3dBlendshapeComponents
_lm3dBlendshapes
_lm3dMeanBlendshapes
_lmCoord
_lmDetector
_lmTracker
_lmWeight
_loadGroundTruth:error:
_loadGroundTruthURL:toGroundTruth:error:
_loadImageRequestHandler:orientation:bufferWidth:bufferHeight:withResource:resourceURL:andAsset:
_loadModel
_loadModelAtPath:error:
_loadPersonsModelAndInitializeFaceAnalyzer
_loadPetsModel
_loadPetsModelAtPath:error:
_loadResources
_localIdentifier
_localIdentifiersOfUnverifiedPersonsAssociatedWithFaceGroups:cancelOrExtendTimeoutBlock:
_location
_logFaceToSuggestionsLog:
_logLevel
_longExposureSuggestionState
_longexposure
_loopFadeLen
_loopPeriod
_loopStart
_loopSuggestionState
_lostCount
_lostTrackCounter
_loudnessAnalyzer
_loudnessResults
_loudnessSampleBuffer
_management
_managementQueue
_mapHeight
_mapWidth
_maskOnly
_maxDurationInSeconds
_maxFaceCountForClustering
_maxHighlightDuration
_maxHighlightScore
_maxNumHands
_maxNumRegions
_maxScore
_maxX
_maxY
_maxZoom
_mean
_meanLandmarkLoc
_measureClusterWithClusterStateURL:groundTruthFaceCountPerPerson:groundTruthPersonInformation:groundTruthFaceToPerson:groundTruthAssetToFaces:measures:extendTimeoutBlock:cancelBlock:
_measurePVPersonClusters:groundTruthFaceCountPerPerson:groundTruthPersonInformation:groundTruthFaceToPerson:groundTruthAssetToFaces:measures:extendTimeoutBlock:cancelBlock:
_mediaSubtypes
_mediaType
_memeRequest
_mergeDistanceThreshold
_meshAnalyzer
_meshVertices
_metaAnalysisTypesForAsset:
_metaFocusAnalyzer
_metaLensSwitchAnalzer
_metaMotionAnalyzer
_metaMotionResults
_metaTracks
_metadata
_metadataAnalysis
_metadataItemTimestampArray
_metadataStabilizationArray
_minDetections
_minDurationInSeconds
_minFaceCountToTriggerClustering
_minHighlightDuration
_minHighlightScore
_minSize
_minVersion
_minX
_minY
_minZoom
_minimumFaceGroupSizeForCreatingMergeCandidates
_minimumSuggestionSize
_mlHighlightScoreResults
_mlQualityResults
_model
_modelEspresso
_modelEspressoStage1
_modelLastGenerationDidExceedTimeIntervalForType:
_modelOutput16bit
_modelOutputSize
_modelURL
_modified
_moflowRequest
_momentaryEnergyValues
_monochromeBufferCreator
_motionBlurVector
_motionFilter
_motionFlowAnalyzer
_motionFlowComputationAccuracy
_motionMagnitude
_motionMagnitudeHistogram
_motionParam
_motionParamDiff
_motionScore
_motionScoreModel
_motionType
_motionTypeModel
_mouthExpression
_movie
_movieActivityLevelResults
_movieApplauseResults
_movieAudioQualityResults
_movieBabbleResults
_movieCameraMotionResults
_movieCheeringResults
_movieClassificationResults
_movieFaceResults
_movieFaceprintResults
_movieFeatureResults
_movieFineSubjectMotionResults
_movieHighlightResults
_movieHighlightScoreResults
_movieHumanActionResults
_movieHumanPoseResults
_movieInterestingnessResults
_movieLaughterResults
_movieLoudnessResults
_movieMovingObjectResults
_movieMusicResults
_movieObstructionResults
_movieOrientationResults
_moviePetsFaceResults
_moviePetsResults
_moviePreEncodeResults
_movieQualityResults
_movieSaliencyResults
_movieSceneResults
_movieSceneprintResults
_movieStabilizationResults
_movieSubjectMotionResults
_movieSubtleMotionResults
_movieSummaryResults
_movieUtteranceResults
_movieVoiceResults
_movingObjects
_mtlLibrary
_musicDetections
_mutex
_nameSource
_needToGenerateModelWithType:ignoreLastGenerationTime:withExtendTimeout:
_net
_netFileUrl
_neuronType
_nextClusterTriggeringAccumulatedChangesCount
_nextRequestID
_nextSample
_nextSampleBuffer
_nextSeqNum
_noResultStrip
_nodes
_nonMaxSuppressed
_nonPanoPreWarmDimensions
_nsfwRequest
_num
_numBlendshapePlusOne
_numBoundaryVertices
_numClass
_numComponents
_numFacesLastFrame
_numFilterTabs
_numFrmsSinceLastShapeUpdate
_numIdentities
_numLevels
_numNeurons
_numOfFrames
_numOfScores
_numOfValidFrames
_numOrientations
_numPoints
_numScales
_numSingletons
_numValidSingletons
_numVertices
_obfuscateLabelName:
_objectBounds
_objectBoundsInitial
_objectRequest
_objects
_objectsMotion
_observation
_obstruction
_obstructionAnalysis
_obstructionResults
_obstructionScore
_offline
_onDemandGyro
_onDemandPixel
_onceExif
_onceScenes
_openSuggestionsLoggingSession
_options
_orientation
_orientationResponses
_orientationResults
_orientionMap
_originalFrameTimestampArray
_originatingFace
_outpuBlobName
_outputBeforeSpatiialPooling
_outputBeforeTemporalPooling
_outputBlob
_outputBlobs
_outputFeatureName
_outputFlow
_outputFrameDurValue
_outputNames
_outputRes4
_outputSemaphore
_outputSize
_outputsData
_outstandingSuggestionRequests
_overallActivityLevel
_overallFaceQualityScore
_overlapRatioOf:with:
_padSize
_padding
_panoVNRequestMethod
_parseClassificationObservations:toClassificationResults:
_parseClassificationObservations:withPrefix:toClassificationResults:
_parseGroundTruthWithURL:faceCountPerPerson:personInformation:faceToPerson:assetToFaces:extendTimeoutBlock:cancelBlock:
_parseSIMLGroundTruthWithURL:faceCountPerPerson:personInformation:faceToPerson:assetToFaces:extendTimeoutBlock:cancelBlock:
_pcmBuffer
_peak
_peakValues
_penaltyScore
_peopleThreshold
_performAnalysis:mediaType:mediaSubtypes:abnormalDimension:colorPixelBuffer:andLumaPixelBuffer:image:
_performAnalysis:withRequestHandler:quickMode:sourceWidth:sourceHeight:
_performAndPersistClustersWithFaceTorsoprintsToAdd:groupingIdentifiersToAdd:faceTorsoprintsToRemove:updatedFaces:cancelOrExtendTimeoutBlock:error:
_performBlurAnalysis:withLumaPixelBuffer:abnormalDimension:isSDOF:
_performBlurAnalysis:withPixelBuffer:usingAnalyzer:
_performExposureAnalysis:withLumaPixelBuffer:
_performRotationAnalysis:withColorPixelBuffer:
_performSceneAnalysis:image:mediaType:mediaSubtypes:abnormalDimension:
_performWallpaperAnalysis:withSceneprint:
_persistFaces:forAsset:
_persistGeneratedFaceCrops:forAsset:error:
_persistPersonsModel:evaluationMode:error:
_persistPetsModel:error:
_persistenceDelegate
_person1LocalIdentifier
_person2LocalIdentifier
_personBuilderMergeCandidatesDisabled
_personBuilderMergeCandidatesEnabled
_personBuildingDisabled
_personClusterVersion
_personID
_personIdentityModel
_personKeypointsDetector
_personLocalIdentifier
_persons
_personsModel
_petRect
_petsActionScore
_petsActiveRegions
_petsAnalyer
_petsDetector
_petsDominant
_petsFaceActiveRegions
_petsFaceDetections
_petsFaceStart
_petsKeypointsDetector
_petsModel
_petsResults
_petsStart
_phAsset
_phFaceFlags
_phFaceResults
_phFaceSortDescriptors
_phFaces
_phPeopleSortDescriptors
_photoLibrary
_photoOffset
_photoSharpnessReliable
_photolibrary
_pixelBuffer
_pixelBufferPools
_pixelFormat
_pixelHeight
_pixelMean
_pixelVar
_pixelWidth
_plan
_playbackCrop
_points2D
_points3D
_pointsImage
_pointsWorld
_pool
_pooledPixelBuffer:withDimension:
_pose
_poseAnalyzer
_poseEstimator
_poseRequest
_poseResults
_poseSolver
_poseType
_poseYaw
_position
_postInference
_postProcessMovieHighlights:analysis:withOptions:
_postProcessStart
_postTasks
_preAnalysisSharpnessScore
_preWarmed
_precisionPerCluster
_preencodeAnalysis
_preferredFormat
_preferredHeight
_preferredMetalDevice
_preferredTimeRange
_preferredTransform
_prepareLivePhotoScenes
_prevComputedScore
_prevEstimatedCenterMv
_prevExprWeights
_prevFrameHandKeypoint
_prevMotionParamDiff
_prevTimeSignLanguageDetected
_prevTimeStampHandDetected
_previousContentType
_previousCovar
_previousState
_previousStateIsValid
_privateMutableResults
_privateTasks
_processBoundingBoxFromDetectedObjects:forSceneClassID:
_processDirtyFaceCrop:faceCropFaceLocalIdentifier:error:
_processFetchedFaceGroup:forPersonID:facesPerAsset:assetInformation:extendTimeoutBlock:cancelBlock:
_processFormat
_processNewlyClusteredFaceCropsInFaceGroups:cancelOrExtendTimeoutBlock:
_processedPredicateForTaskID:
_processingGroup
_processingQueue
_processingQueueDetermineNextClusterTriggeringAccumulatedChangesCountIfNecessary
_processingQueueGetFaceClusterSequenceNumbersInClusterCache:lastClusterSequenceNumber:error:
_processingQueueGetVisionClusters:minimumClusterSize:returnClusterAsCountedSet:excludedL0ClustersByL1ClusterId:cancelOrExtendTimeoutBlock:error:
_processingQueuePerformForcedFaceClustering:cancelOrExtendTimeoutBlock:
_processingQueueQuickSyncClustererWithPhotoLibraryUsingFacesInClusterCache:visionClusters:cancelOrExtendTimeoutBlock:
_processingQueueResetClusterCache:
_processingQueueRestoreClusterCacheAndSyncWithLibrary:cancelOrExtendTimeoutBlock:error:
_processingQueueRestoreClusteringCacheWithCacheDirectoryURL:clusterState:threshold:error:
_processingQueueRestoreFromClusterSnapshotFileAtURL:error:
_processingQueueSaveClusterCache:
_processingQueueSyncClustererWithPhotoLibraryUsingFacesInClusterCache:cancelOrExtendTimeoutBlock:
_processingVersion
_progressFromWorkerStatesDictionary:
_progressHandler
_properties
_propertyDictionary
_propertyDictionaryFileURL
_propertyDictionaryLock
_prune
_ptrFirst
_ptrLast
_publicMutableResults
_purgeAllResources
_quality
_qualityResuls
_qualityScore
_qualityScoreForLivePhoto
_quantFactor
_quarantineTwinsOnAssetEnabled
_queryDistanceDescriptor:ofAsset:withExistingAnalysis:andDatabase:timeRange:lastFeature:isDegraded:
_queryProgressDetailExpress:forPhotoLibrary:andTaskID:
_queryProgressDetailExpressEmbeddingAnalysis:forPhotoLibrary:
_queryValue:forKey:
_queue
_reLU
_reachability
_readFaceAnalysisState
_readPropertyDictionary
_readerOutput
_readerOutputAdaptor
_ready
_rebuildClusterer
_recallPerPersonExcludeMissDetection
_recallPerPersonToGroundTruth
_recipeBlob
_recognitionVersion
_recordClusterRebuildRequired:
_recordClusteringState:
_recordCountOfPendingFacesToAdd:
_recordCurrentStatus:
_recordIncrementCountOfPendingFacesToAdd:
_recordNeedToPersonBuildOnFaceGroupContainingFace:error:
_regionCrop
_regionOfInterest
_regions
_relativeActionScore
_relativeScore
_removeEmptyGroups
_removeVisionClusterCacheFilesNotReferencedByVisionClusterState:
_reportCoreAnalyticsWithVisionClusterMeasure:personClusterMeasure:personClusters:andGroundTruthInformation:
_reportDownload:
_representativenessByFaceCSNFromFaces:cancelOrExtendTimeoutBlock:
_request
_requestAnalyses
_requestAnalysis:forAsset:withExistingAnalysis:andDatabase:andOptions:cancelBlock:
_requestBestTrim
_requestFullResult
_requestId
_requestedAnalyses
_requests
_requirePHFaceAnalysis
_resConfig
_reservedIDs
_resetFaceClusterSequenceNumberOfFacesInFetchResult:inPhotoLibrary:cancelOrExtendTimeoutBlock:error:
_resetFaceClusteringState:
_resolution
_resolveConflictingL0ClustersFromVNClusters:excludedL0ClustersByL1ClusterId:cancelOrExtendTimeoutBlock:
_resource
_resourceManager
_resources
_results
_resultsKey
_resultsTypes
_revision
_rgbColorSpace
_rgbFrame
_rgbToYuv
_rightHandKeypointTracker
_roll
_rotMatrix
_rotationAngle
_rotationAngleForFacePose
_rotationBufferCreator
_rotationModel
_rotator
_rotatorForFacePose
_saliencyAnalyer
_saliencyObjectnessRequest
_saliencyRequest
_saliencyResults
_sampleBatchSize
_sampleBuffer
_sampleFlag
_sampleRate
_samplesFor100ms
_sandboxQueue
_saveKeypoints
_scale
_scaledPixelBuffers
_scanPhotoLibrary:withTaskID:statistics:andExtendTimeoutBlock:
_sceneAnalysis
_sceneChangeAnalyzer
_sceneDeltaBuffer
_sceneId
_sceneResults
_sceneSegments
_sceneSwitchFrequency
_sceneType
_sceneprint
_sceneprintDistanceToPreviousScene
_sceneprintRawRequest
_sceneprintRequest
_score
_scoreAbsoluteMax
_scoreArray
_scoreRelativeMax
_sdof
_secondBuffer
_semanticRequest
_semanticScore
_semaphore
_service
_session
_sessionAnalytics
_sessionAnalyticsSentCount
_sessionPool
_setAllFaceGroupsNeedPersonBuilding
_setBudget:
_setFaceAnalysisStateValue:forKey:
_setPropertyDictionaryValue:forKey:
_setupMediaAnalysisServiceConnection
_sexType
_shapeModel
_shapeUpdateInProgress
_sharedModel
_sharpness
_sharpnessBlocks
_shotType
_signature
_signpostPayload
_singleAnalyticsSentCount
_singleFrameExecutionTime
_size
_skintoneType
_skip
_skipNumFramesBothEnds
_smile
_smileDetector
_smileType
_songDetector
_sortedViableFaceMergePairsFromQueryFaces:andCandidateFaces:
_sourceHeight
_sourcePixelBuffer
_sourceSizeHeight
_sourceSizeWidth
_sourceWidth
_sportsSceneId
_srcHeight
_srcWidth
_stabilizationType
_stabilize
_stabilizeResult
_standalone
_start
_startAndSyncClusterCacheWithLibrary:reply:
_startLevel
_startRange
_startTime
_started
_state
_stats
_statsFlags
_std
_stillTime
_storage
_storageGroup
_storageQueue
_stridePadded
_subMb
_subMbMotionAvailable
_subjectAction
_subjectActionScore
_subjectScore
_subtasks
_subtleMotionAnalyzer
_subtleMotionResults
_subtleMotionScore
_suggestionLoggingDirectory
_suggestionLoggingSessionOpen
_suggestionsForPersonLocalIdentifier:clusterSequenceNumbers:excludePersonLocalIdentifiers:cancel:context:error:
_suggestionsForPersonWithLocalIdentifier:toBeConfirmedPersonSuggestions:toBeRejectedPersonSuggestions:cancel:error:
_suggestionsLogEnabled
_suggestionsLoggingEnabled
_sumConfidence
_sumOfScore
_supportConditionalAnalysis
_tabooRequest
_targetDurationInSeconds
_targetHighlightIndex
_tasks
_taxonomy
_tensorCoeff
_tensorModel
_textureScore
_textureness
_threshold
_timeEnd
_timeInterval
_timeLastDetection
_timeLastProcess
_timeLastProcessFullFrame
_timeLastTracking
_timeRange
_timeScale
_timeStamp
_timeStart
_timeValue
_timeValues
_timebase
_timer
_timerange
_timescale
_timestamp
_timestampOfLastClusterComparison
_toleranceInSeconds
_torsoprint
_track
_trackID
_trackOutput
_trackReader
_trackScoreFilter
_trackStart
_tracker
_trackers
_tracking
_trackingMode
_trackingModeCounter
_trackingScore
_trainingType
_trans
_transArray
_transaction
_transferSession
_transform
_transformedCoeff
_transformedImageHeight
_transformedImageWidth
_triIndexMap
_triList
_trimAnalyzer
_turbo
_type
_types
_typesToRemove:requested:
_typesWide
_underExpose
_ungroupFaceClusterSequenceNumbers:cancelOrExtendTimeoutBlock:error:
_uniformTypeIdentifier
_updateAnalysisPreferencesWithEntries:keysToRemove:
_updateCurrentProcessingVersion:
_updateFaceCSNsToAddByPerson:faceCSNsToRemoveByPerson:faceInFaceGroupByCSN:faceCSNsByPersonLocalIdentifier:faceCSNsByMigratedPersonLocalIdentifier:personsToUpdate:
_updateHandler
_updateShapeGroup
_updateShapeQueue
_updateVersionStateFileWithError:
_url
_useCPUOnly
_useMoflow
_useR14J9
_useR2D2
_useSingleEspressoModel
_utteranceDetections
_valAngle
_valBuffer
_valBufferRotated
_valLM
_valid
_validActivityScores
_validFrames
_validStabilization
_validateFailedOnce
_validationGroup
_validationQueue
_validationScore
_value
_vcpFaceCropFromPHFaceCrop:
_verbose
_version
_versionState
_versionStateURL
_vertexCount
_vertices
_videoActivityDescriptor
_videoAnalysis
_videoCaptionDecoder
_videoCaptionEncoder
_videoCaptionEncoderAsset
_videoCaptionResult
_videoFrameAnalysis
_vipStatusForPhotoLibrary:andType:
_visionClusterStateDataBlobFromClusterSnapshotFileAtURL:error:
_visualPleasingScore
_vnFaceAttributeAgeToPHFaceAgeTypeMap
_vnFaceAttributeEthnicityToPHFaceEthnicityType
_vnFaceAttributeEyesToPHEyesStateMap
_vnFaceAttributeFacialHairToPHFaceExpressionType
_vnFaceAttributeFacialHairToPHFacialHairTypeMap
_vnFaceAttributeGlassesToPHFaceGlassesTypeMap
_vnFaceAttributeHairColorToPHFaceHairColorTypeMap
_vnFaceAttributeHairTypeToPHFaceHairType
_vnFaceAttributeHeadGearToPHFaceHeadGearType
_vnFaceAttributePoseToPHFacePoseType
_vnFaceAttributeSexToPHFaceSexTypeMap
_vnFaceAttributeSkintoneToPHFaceSkintoneType
_vnFaceAttributeSmileToPHFaceSmileTypeMap
_vnFaceGazeDirectionToPHFaceGazeType
_voiceActivity
_voiceActivityNew
_voiceDetections
_voiceDetector
_voiceResults
_voiceScore
_voiceStart
_weakRequest
_weakSession
_weightedAveragePrecision
_weightedAverageRecall
_width
_widthBlockNum
_widthExt
_widthInMb
_widthPadded
_yaw
_yuvFrames
absMotion
absoluteActionScore
absoluteScore
absoluteString
absoluteURL
acceleratedDecodeImageData:pixelFormat:maxDimension:pixelBuffer:orientation:flushCache:
accumulateDoubleValue:forField:andEvent:
accumulateInt64Value:forField:andEvent:
actionScore
actionScoreForTimerange:
actionScoreInTimeRange:
activateResource:
activeCost
activeCount
activeSegment
activityID
activityScore
add:
addActiveResults:
addAggregatedScenes:timerange:
addBounds:
addClassification:
addClusterPrecision:forPersonID:personFaceCount:validFaceCount:identitySize:
addDetectionFromTime:toTime:confidence:
addDetectionFromTime:toTime:result:
addDetectionToDict:withActiveRegions:forPetsDetections:fromTime:
addEntriesFromDictionary:
addFaceObservations:forPersonIdentifier:toModel:error:
addFaceObservations:toPersonWithUniqueIdentifier:error:
addFaceResults:flags:
addFaces:
addFetchPropertySets:
addFrameInstructions:
addHighlight:to:
addHomographyParam:
addHomographyParams:
addIdentityRecallExcludeMissDetection:forPersonID:personFaceCount:identitySize:
addIdentityRecallToGroundTruth:forPersonID:personFaceCount:identitySize:
addImageBlurResults:
addImageCompositionResults:
addImageExposureResults:
addImageFaceResults:
addImageFeatureResults:
addImageHumanPoseResults:
addImageJunkResults:
addImagePetsFaceResults:
addImagePetsResults:
addImageSaliencyResults:
addImageSceneprintResults:
addImageShotTypeResults:
addInvalidMergeCandidatePersons:
addKeypoints:
addKeypointsToNSArray:keypointConfidence:handBox:keypointsArray:
addLivePhotoEffectsResults:
addLivePhotoHumanActionClassificationResults:
addLivePhotoKeyFrameResults:
addLivePhotoKeyFrameStillResults:
addLivePhotoRecommendationResults:
addLivePhotoSharpnessResults:
addMergeCandidatePersons:
addMovieActivityLevelResults:
addMovieApplauseResults:
addMovieAudioQualityResults:
addMovieBabbleResults:
addMovieCameraMotionResults:
addMovieCheeringResults:
addMovieClassificationResults:
addMovieFaceResults:
addMovieFaceprintResults:
addMovieFeatureResults:
addMovieFineSubjectMotionResults:
addMovieHighlightResults:
addMovieHighlightScoreResults:
addMovieHumanActionResults:
addMovieHumanPoseResults:
addMovieLaughterResults:
addMovieLoudnessResults:
addMovieMovingObjectResults:
addMovieMusicResults:
addMovieObstructionResults:
addMovieOrientationResults:
addMoviePetsFaceResults:
addMoviePetsResults:
addMoviePreEncodeResults:
addMovieQualityResults:
addMovieSaliencyResults:
addMovieSceneResults:
addMovieSceneprintResults:
addMovieStabilizationResults:
addMovieSubjectMotionResults:
addMovieSubtleMotionResults:
addMovieSummaryResults:
addMovieUtteranceResults:
addMovieVoiceResults:
addObject:
addObjectsFromArray:
addObservations:toEntityWithUniqueIdentifier:error:
addOutput:
addRequest:withConfiguration:error:
addRequest:withObserver:error:
addResult:start:duration:keyIsName:
addResult:to:forKey:optional:
addSceneAnalysisResult:to:clipRange:
addSceneAnalysisResult:to:optional:
addSceneClassificationContributionToActivityLevel:
addSceneSwitchFrequencyConstributionToActivityLevel:
addSegment:
addSegmentToResults
addSummary:to:
addTimeValue:
addedDate
adjustScoreByFace
adjusted
adjustmentKeys
adjustmentTimestamp
adjustmentValuesForKey:
adjustmentVersion
adjustmentsRequest
advancedStatus
advancedStatusMergeCandidateLimit
advancedStatusVerifiedPersonLimit
aestheticScore
aestheticsRequest
ageCategory
aggregateAnalysisForTypes:withFramesMeta:properties:
aggregateTileResults:tileRect:imageSize:landscape:results:
aggregateWith:
aggregatedResults
algorithmVersion
alignedBoundingBoxAsCGRect
allClusteredFaceIdsAndReturnError:
allObjects
allScenes
allValues
allocBuffers:
allocWithZone:
allocateCorreleationBuffer:forLevel:
allocateFeatures
allocateInputAndOutputBuffers
allocateStorages
allowFastPathDecodeWithUniformType:pixelWidth:andPixelHeight:
allowOnDemand
allowStreaming
allowedClasses
analysis
analysisConfidence
analysisResultRef
analysisType
analyzeAsset:cancel:results:
analyzeAsset:flags:
analyzeAsset:onDemand:cancel:statsFlags:results:
analyzeAsset:results:
analyzeAsset:streamed:
analyzeAsset:withOptions:
analyzeAsset:withResource:resourceURL:quickMode:results:
analyzeAudioBuffer:
analyzeAudioBuffer:atAudioFramePosition:
analyzeBodyArray:
analyzeCGImage:results:
analyzeDetectedFaces:faceResults:cancel:
analyzeFaceQuality:withAsset:andCancelBlock:
analyzeFrame:withFaceBounds:
analyzeFrame:withFaceRect:withRotation:withTimestamp:
analyzeFrame:withTimestamp:
analyzeFrame:withTimestamp:andDuration:completion:
analyzeFrame:withTimestamp:andDuration:flags:
analyzeFrame:withTimestamp:andDuration:flags:cancel:
analyzeFrame:withTimestamp:andDuration:flags:frameStats:
analyzeFrameForPose:withFaceRect:withTimestamp:
analyzeFrameWithTimeRange:analysisData:
analyzeFrameWithTimeRange:andActionScore:
analyzeImage:performedAnalyses:cancel:
analyzeImageQuality:irisPhotoOffsetSec:cancel:
analyzeImages:secondImage:cancel:
analyzeKeyFrame:withTimestamp:andDuration:flags:
analyzeLivePhotoKeyFrame:irisPhotoOffsetSec:originalIrisPhotoOffsetSec:photoTextureScore:hadFlash:cancel:
analyzeMotionStability:motionParamDiff:
analyzeOndemand:forAnalysisTypes:withExistingAnalysis:error:
analyzeOndemand:pairedURL:forAnalysisTypes:error:
analyzeOverallQuality:isSettlingEffect:
analyzeOverallQuality:withFpsRate:
analyzePixelBuffer:flags:petsDetections:results:cancel:
analyzePixelBuffer:flags:results:cancel:
analyzePixelBuffer:flags:withPreAnalysisScore:results:cancel:
analyzePixelBuffer:withFrame:withTimestamp:andDuration:cancel:
analyzePixelBuffer:withFrame:withTimestamp:andDuration:hasSubtleScene:cancel:
analyzePixelBuffer:withTimestamp:andDuration:properties:completion:
analyzePixelBuffer:withTimestamp:andDuration:properties:error:
analyzePixelBufferInTiles:results:cancel:
analyzeSampleBuffer:
analyzeVideoSegment:timerange:forAnalysisTypes:cancel:
analyzeVideoTrack:start:forAnalysisTypes:cancel:
analyzeWithImageURL:mediaType:mediaSubtypes:abnormalDimension:completionHandler:
analyzeWithImageURL:requestTypes:reencode:completionHandler:
analyzeWithLightweightOption:aspectRatio:computationAccuracy:forceCPU:sharedModel:flushModel:cancel:
analyzeWithSceneprint:results:cancel:
analyzeWithStart:andDuration:error:
analyzer
analyzerForAnalysisTypes:withPreferredTransform:properties:
analyzerForTrackType:withTransform:requestAnalyses:formatDescription:
analyzerWith:prune:
analyzerWithRevision:
analyzerWithVCPAsset:forAnalysisTypes:
analyzerWithVCPAsset:withExistingAnalysis:forAnalysisTypes:
andPredicateWithSubpredicates:
angle
animalObservationFromAnimalprintData:
animalprint
anonymizedName
anyObject
appendBuffer:atTime:error:
appendData:
appendFormat:
appendString:
approximateCoordinate
approximateLocation
archivedDataWithRootObject:requiringSecureCoding:error:
area
array
arrayByAddingObjectsFromArray:
arrayLength
arrayWithCapacity:
arrayWithContentsOfURL:
arrayWithObject:
arrayWithObjects:
arrayWithObjects:count:
asset
assetActionScoreFromAnalysis:
assetActivityLevelFromAnalysisResults:
assetAdjustedFingerprint
assetCameraMotionScoreFromAnalysis:
assetExpressionScoreFromAnalysis:
assetImageGeneratorWithAsset:
assetJunkScoreFromAnalysis:
assetLocalIdentifier
assetMasterFingerprint
assetModificationDate
assetQualityScoreFromAnalysis:withFpsRate:
assetReaderOutputMetadataAdaptorWithAssetReaderTrackOutput:
assetReaderSampleReferenceOutputWithTrack:
assetReaderTrackOutputWithTrack:outputSettings:
assetReaderWithAsset:error:
assetResourcesForAsset:
assetResourcesForAsset:includeDerivatives:
assetVoiceScoreFromAnalysis:
assetWithData:
assetWithIdentifier:isCloudIdentifier:error:
assetWithImageData:uniformTypeIdentifier:identifier:clientBundleID:clientTeamID:
assetWithPHAsset:
assetWithPhotosAsset:clientBundleID:clientTeamID:
assetWithPhotosAsset:pixelBuffer:orientation:clientBundleID:clientTeamID:
assetWithPixelBuffer:orientation:identifier:clientBundleID:clientTeamID:
assetWithURL:
assetWithURL:identifier:clientBundleID:clientTeamID:
assetsAnalyzedSinceDate:completionHandler:
assetsFromPhotoLibrary:analyzedSinceDate:completionHandler:
assignPropertiesOfVCPPhotosFace:toPHFaceChangeRequest:
associateFace:withFaceCrop:error:
associateFaceWithPersonUUID:
associateHands:withExisingHands:
associatePerson:withPHFaces:
associatePersons:withExisingPersons:
attachProgressCallBack:
attachSalientRegions:toPixelBuffer:
attempts
attributes
attributesOfItemAtPath:error:
audioFormatRequirements
audioQualityScore:
autoLiveMotionScore:
autoPlayable
autoloop
autoplayScore
autorelease
availableMetadataFormats
averageOrientationResponses:withCurrentMap:
averageScore
barcodeObservations
becomeCurrentWithPendingUnitCount:
bestPlaybackCrop
bestRepresentativeFaceForPerson:qualityMeasureByFace:cancelOrExtendTimeoutBlock:
bestRepresentativeFaceForPerson:qualityMeasureByFace:canceler:
bestRepresentativeFaceForPerson:qualityMeasureByFace:candidateFaces:cancelOrExtendTimeoutBlock:
bestRepresentativeFaceForPerson:qualityMeasureByFace:candidateFaces:canceler:
bestTrimTimeRange
bindWithBuffers:correlation:flow:outputFlow:
bindWithBuffers:imgFeature:
blacklistedLocalIdentifiersFromAssets:
blendShapes
blendshapeComponentIndex
blockContentDetection:
blurScore
bodyCenterX
bodyCenterY
bodyDistance:withBodyB:
bodyHeight
bodyWidth
boolValue
bounce
bound
boundDistance:relativeTo:landscape:
boundingBox
bounds
boundsAtIndex:
boundsCount
boundsType
boundsWithCGRect:
bufferAllocCPU
bufferRotated
buildModelWithConfig:error:
buildPersonWithFaceClusterer:keyFaceUpdateBlock:context:cancelOrExtendTimeoutBlock:
buildPersonsWithFaceClusterer:keyFaceUpdateBlock:canceler:context:extendTimeoutBlock:
bundleWithIdentifier:
bytes
cacheHitWithQueryID:cachedResultQueryID:
cachePath
cachedImageHandler
calculateAndReportClusterAccuracyWithVisionClusterURL:andPersonClusters:results:extendTimeoutBlock:cancelBlock:
calculateBlendshapeWeights:prevWeights:lmBlendshapes:maxIter:
calculateCandidateScoreWithRangeAdjust:endIdx:candidateTimeRange:captureTime:
calculateConfidence:lineDistance:vaninshingPoint:vanishingPointConfidence:
calculateDistance:toWrapper:andError:
calculateFaceRectFromPrevLM:result:numOfLandmarks:
calculateFrameDifference:
calculateIdentityCoefficients:extrinsicMatrix:pts2D:exprWeights:lm3DMeanBlendshapes:lm3DComponents:maxIter:
calculateMesh:numVertices:blendshapes:outputMesh:
calculateModelBlendshapes:outputBlendshapes:
calculateOrientationResponses
calculatePosePnpSolver:
calculatePriorityScore:ofPixelBuffer:withMetadata:
calculateScoreFromNetworkOutput:outChannel:outHeight:outWidth:textureness:contrast:imgWidth:
calculateScoreFromNetworkOutputV2:
calculateTextureness:height:width:sdof:result:
cameraActivityfromQuality:
cameraMotionDetection:
cameraMotionScore
cameraMotionScoreForTimerange:
canAddOutput:
canAnalyzeUndegraded:withResources:
canDecodeAcceleratedUniformTypeIdentifier:
canRenderVariation
canReuseResultsForRequest
canUseLastFrameOfAsset:withResources:
cancel
cancelAllRequests
cancelAllSuggestionRequests
cancelAnalysisWithRequestID:
cancelBackgroundActivity
cancelBackgroundActivityWithReply:
cancelBlock
cancelClustering
cancelDataRequest:
cancelReading
cancelRequest:
cancelSuggestionRequest:
cancelTask:
cancelled
canceller
catalogIDs
cflags
changeRequestForAsset:
changeRequestForDedupingGraphPersons:
changeRequestForFace:
changeRequestForFaceCrop:
changeRequestForFaceGroup:
changeRequestForPerson:
characterAtIndex:
characterRecognitionProperties
characterSetWithCharactersInString:
checkAutoPlayable
checkCameraZoom:
checkCameraZoom:cameraMotionResults:
checkFaceDominant
checkResolutionChange:withRotation:
checkTimeRangeConsistency
checkTimeout
checkTrimAt:captureTime:
chirality
chunkFourForward
cityNatureRequest
class
classIndex
classificationAtIndex:
classificationForIdentifier:
classificationRequest
classificationType
classificationsCount
classifyAnimalObservation:withModel:error:
classifyFaceObservation:withModel:error:
classifyFaceObservation:withPersonsModel:error:
classifyPixelBuffer:stagedText:inConversationWithIdentifier:error:
cleanupGroupedFacesWithClusterSequenceNumberSetToZero:error:
cleanupGroupedFacesWithClusterSequenceNumberSetToZeroWithCanceler:error:
cleanupMergeCandidatesWithMinimumFaceGroupSize:cancelOrExtendTimeoutBlock:error:
cleanupUngroupedFacesWithNonZeroClusterSequenceNumbers:error:
cleanupUngroupedFacesWithNonZeroClusterSequenceNumbersWithCanceler:error:
cleanupWithOptions:error:
clearBounds
clearCacheWithOption:
clearClassifications
clearDirtyStateOnFaceCrops:error:
clearFaceResults
clearFrameInstructions
clearHomographyParams
clearImageBlurResults
clearImageCompositionResults
clearImageExposureResults
clearImageFaceResults
clearImageFeatureResults
clearImageHumanPoseResults
clearImageJunkResults
clearImagePetsFaceResults
clearImagePetsResults
clearImageSaliencyResults
clearImageSceneprintResults
clearImageShotTypeResults
clearKeypoints
clearLivePhotoEffectsResults
clearLivePhotoHumanActionClassificationResults
clearLivePhotoKeyFrameResults
clearLivePhotoKeyFrameStillResults
clearLivePhotoRecommendationResults
clearLivePhotoSharpnessResults
clearMovieActivityLevelResults
clearMovieApplauseResults
clearMovieAudioQualityResults
clearMovieBabbleResults
clearMovieCameraMotionResults
clearMovieCheeringResults
clearMovieFaceResults
clearMovieFaceprintResults
clearMovieFeatureResults
clearMovieFineSubjectMotionResults
clearMovieHighlightResults
clearMovieHumanActionResults
clearMovieHumanPoseResults
clearMovieInterestingnessResults
clearMovieLaughterResults
clearMovieLoudnessResults
clearMovieMovingObjectResults
clearMovieMusicResults
clearMovieObstructionResults
clearMovieOrientationResults
clearMoviePetsFaceResults
clearMoviePetsResults
clearMoviePreEncodeResults
clearMovieQualityResults
clearMovieSaliencyResults
clearMovieSceneResults
clearMovieSceneprintResults
clearMovieStabilizationResults
clearMovieSubjectMotionResults
clearMovieSubtleMotionResults
clearMovieSummaryResults
clearMovieUtteranceResults
clearMovieVoiceResults
clientBundleID
clientTeamID
clipResults:
cloneCaptionModel:to:
close
closeDatabase
closedefaultPhotoLibrary
clsDistanceIdentity
clusterAndWaitWithCancelOrExtendTimeoutBlock:
clusterCount
clusterFaces
clusterFacesIfNecessary
clusterFlagByClusterId
clusterId
clusterIfNecessaryAndWaitWithCancelOrExtendTimeoutBlock:
clusterIncludeTorsoOnlyFaces
clusterSequenceNumber
clusteredFaceCount
clusteredFaceIdsForClusterContainingFaceId:error:
clusterer
clustererBringUpState
clustererBuilderWithOptions:error:
clustererIsReadyToReturnSuggestions
clustererModelFileNamesFromState:storedInPath:error:
clustererState
cnnDataClass
cnnDataWithGPUContext:
cnnDataWithPlane:height:width:context:
cnnOutputWidth
code
colorNormalization
colorNormalizationBlob
colorfulnessScore
combineBufferTo:flowX:flowY:
combineMLHighlightScore
commandBuffer
commandQueue
commit
compare:
compare:options:
compareFace:withFace:
compareNumericVersion:withReferenceVersion:
compareObjectsOfInterest:withScenes:
compareSoftwareStackVersion:withReferenceVersion:
completionHandler
componentsBlendshape
componentsSeparatedByString:
composition
computeActionFaceTrimFor:
computeActionScore
computeActionScoreForPerson:
computeActionScoreInTimerange:
computeActivityScoreAtTime:
computeBarycentricCoordinates
computeBestPlaybackCrop:
computeCNNBasedSharpness:sharpnessScore:textureScore:contrast:cancel:
computeCNNFaceSharpness:result:cancel:
computeColorNormalization
computeCommandEncoder
computeContentScore
computeControlPointsCamera:Vt:
computeCurationScore
computeCurationScoreComponents
computeDistance:fromArray:toArray:
computeDistance:toDescriptor:
computeDistance:withDescriptorClass:fromAsset:toAsset:
computeDistance:withDistanceFunction:error:
computeExposureScoreOfFrame:
computeExpressionScore
computeExpressionScoreInTimerange:
computeFaceQualityOfFrame:
computeGlobalQuality
computeGlobalQualityForLivePhoto
computeGyroSharpness:
computeHighlightScoreOfRange:
computeHighlightScoreResults
computeHumanActionScoreInTimerange:
computeHumanPoseScoreInTimerange:
computeIntersectionOverUnion:
computeL6x10:L6x10:
computeLandmarks:
computeLocalSharpness:
computeMLHighlightScoreForTimerange:
computeMLQualityScoreForTimerange:
computeMinDistanceBetween:withSet:
computeMotionDivScore:
computeNoiseLevel:width:height:stride:textureness:
computePenaltyScore
computePoints3DCamera
computePoseScore:
computeProjectionError:T:
computeQualityTrimFor:withKeyFrame:
computeR6x1:
computeRT:T:
computeRampToTargetRate:forExport:outTimeSteps:outIntermediateRates:
computeRegionNoise:blockTextureness:average:width:height:stride:
computeRegionSharpness:width:height:stride:
computeRegionsofInterest
computeSVDVt:Vt:
computeScore:width:height:posX:posY:
computeScoreForPhoto:withRefKeyFrame:
computeScoreFromAction
computeScoreFromColorfulness
computeScoreFromExposure
computeSharpnessOfFrame:
computeSharpnessScore:forFacesInImage:
computeSharpnessScore:forObjects:inImage:
computeSharpnessScore:textureness:contrast:imgWidth:cancel:
computeSmileScore:
computeSteadyTranslationTrimFor:
computeSubtleMotionScoreInTimerange:
computeTrimWithHighlightScoreFor:
computeVar:index2:interVar:intraVar:
computeVarWithID:index1:index2:interVar:intraVar:
computeVisualPleasingScore
computeVoiceScoreInTimeRange:
confidence
configForAspectRatio:
configInputBasedOnDevice
configuration
configureGPU
configureGaussNewton:R6x1:betas:jacobian:residual:
configureRequest:withRevision:
configureVNRequest:withClass:andProcessingVersion:
configureVNRequest:withClass:andVisionRevision:
conformsToProtocol:
connection
constructBlock:context:
containsIndex:
contentInformationRequest
contentScore
contents
contentsOfDirectoryAtURL:includingPropertiesForKeys:options:error:
contextWithDictionary:error:
contextWithPhotoLibrary:
convBlockWithFilterSize:filterNum:chunk:reLU:padding:
convBlockWithFilterSize:filterNum:chunk:reLU:padding:groups:stride:batchNorm:
conversationIdentifier
convertAnalysisResult
convertCPUData2GPU
convertFlow:
convertGPUData2CPU
convertImage:yuvFrame:
convertLivePhotoBinary:toDictionary:
convertLivePhotoStruct:toDictionary:
convertPixelBuffer:toPixelBuffer:withPixelFormat:
convertPixelBuffer:toPixelFormat:flushCache:
convertResultsToDict:results:
convertSingleResultToDict:keypointConfidence:box:results:
convertToOriginalTimeFromScaledTime:forExport:
coordinate
copy
copyBlock:withStride:toBlock:
copyBufferFrom:fromStride:toPtr:toStride:toWidth:toHeight:
copyCGImageAtTime:actualTime:error:
copyFrom:
copyImage:toBuffer:withChannels:
copyImage:toData:
copyImage:toData:withChannels:
copyImage:toData:withChunk:
copyImage:withChannels:
copyImage:withChunk:
copyItemAtURL:toURL:error:
copyNextMetadataGroup
copyNextSampleBuffer
copyWithZone:
correctSigns
correctionResultRef
count
countByEnumeratingWithState:objects:count:
countForTaskID:withProcessingStatus:
countOfClusteredFaces
countOfClusteringEligibleFaces
countOfFaces
countOfUnclusteredClusteringEligibleFaces
cplStatus
createContextPreferred
createContextWithForceCPU
createContextWithMPSGraph
createDecoderForTrack:timerange:forAnalysisTypes:
createDirectoryAtURL:withIntermediateDirectories:attributes:error:
createFaceHeatMap:imageFaces:
createGaborFilterKernel:sigmaX:sigmaY:lambda:thetaInDegree:phaseInDegree:
createInput:keypoints:
createInput:withBuffer:
createInput:withBuffer:cnnInputHeight:cnnInputWidth:
createInput:withBuffer:cnnInputHeight:cnnInputWidth:box:
createInput:withBuffer:cnnInputHeight:cnnInputWidth:crop:
createInput:withBuffer:inputHeight:inputWidth:
createInput:withBuffer:modelInputHeight:modelInputWidth:
createInput:withImage:modelInputHeight:modelInputWidth:
createModel
createModel:srcWidth:
createModelWithResConfig:
createModules:
createOutputMetadataFromDictionary:
createPixelBuffer:
createPixelBufferWithWidth:height:pixelFormat:pixelBuffer:
createQueryContextWithError:
createVideoAnalyzer:withFrameStats:
creationDate
creationRequestForFace
creationRequestForFaceGroup
creationRequestsForFaceCropsWithOriginatingFace:resourceData:
cropAndScale:regionCrop:
cropBoundsInOriginalImageFromFaceCrop:error:
cropFraction
cropRectHeight
cropRectWidth
cropRectX
cropRectY
cropToFit
croppedBoundingBox
csns
curateMovieAssetsForCollection:withAlreadyCuratedAssets:andDesiredCount:allowOnDemand:
curationProperties
curationScore
currentBudget
currentCost
currentLocale
currentOutstandingTasksWithReply:
currentProcessingVersion
cvtHeatmaps2Keypoints:outHeight:outWidth:inHeight:inWidth:outChannel:keypoints:keypointConfidence:offset:
data
dataForResource:
dataRequest
dataType
dataUsingEncoding:
dataUsingEncoding:allowLossyConversion:
dataValue
dataWithBytes:length:
dataWithBytesNoCopy:length:freeWhenDone:
dataWithContentsOfURL:
dataWithContentsOfURL:options:error:
dataWithJSONObject:options:error:
dataWithPropertyList:format:options:error:
databaseForPhotoLibrary:
date
dateByAddingTimeInterval:
dateFormatter
dateWithTimeIntervalSinceReferenceDate:
deactivateResource:
debugDescription
decideLensSwitchPoint:
decideSegmentPointBasedOn:
decideSegmentPointBasedOnActionScore:
decideSegmentPointUsingHinkleyDetector:
decodeDimensionsForTrack:
decodeImageSource:withUniformTypeIdentifier:pixelFormat:maxDimension:orientation:pixelBuffer:
decodeObjectOfClass:forKey:
decodeSample:sample:
decodeTask
dedupeGraphVerifiedPersonsInFaceGroup:personCache:
defaultANEDevice
defaultDesiredKeys
defaultManager
defaultMetalDevice
defaultPhotoLibrary
defaultProcessingVersion
deferredProcessingNeeded
deleteEmptyGroupsAndReturnError:
deleteFaceCrops:
deleteFaceGroups:
deletePersons:
densityClusteringForObjects:maximumDistance:minimumNumberOfObjects:withDistanceBlock:
dependencies
description
descriptor
descriptorData
descriptorWithData:
descriptorWithImage:
descriptors
deserializeStabilizationRecipeInAttributes:
detailedDescription
detect
detect:withConfidence:dominantLine:
detectEyeOpennessForFace:inBuffer:eyeOpenness:
detectFaces:faces:
detectLandmark:width:height:stride:facerect:prevResult:result:
detectPersons:persons:
detectPixelBuffer:contentType:
detectSmileForFace:inBuffer:smile:
detectTrackFacesInFrame:withTimestamp:faces:
detectWithSigma:lowThreshold:highThreshold:
detectedFaces
detectionModeCounterShapeModel
detectionType
detector
detector:
detector:forceCPU:sharedModel:inputConfig:revision:
detectors
deterministicallyOrderedFaceIdentifiersWithLocalIdentifiers:faceprintVersion:
device
deviceForMetalDevice:
dictionary
dictionaryRepresentation
dictionaryWithCapacity:
dictionaryWithContentsOfURL:
dictionaryWithDictionary:
dictionaryWithObjects:forKeys:count:
dictionaryWithObjectsAndKeys:
differencesBetweenClusterCacheAndLibrary:excludedL0ClustersByL1ClusterId:cancelOrExtendTimeoutBlock:
direction
dirtyFaceCropsWithLimit:
dispatchThreadgroups:threadsPerThreadgroup:
displayLabel
displayMessage
distance
distanceBetweenClustersWithFaceId:andFaceId:error:
distanceBetweenLevel0ClusterIdentifiedByFaceCSN:andLevel0ClusterIdentifiedByFaceCSN:error:
distanceBetweenLevel1Clusters:error:
distanceFromAsset:timeRange:toAsset:timeRange:duplicate:distance:
distanceFromAsset:toAsset:duplicate:distance:
distanceIdentity
distanceToImageprint:error:
distanceToPreviousScene
distancesFromClustersIdentifiedByFaceCSNs:toClustersIdentifiedByFaceCSNs:error:
distantPast
documentElements
documentObservations
domain
domainInfo
domainKey
dominantLine
doubleValue
downloadVideoCaptionEncoderIfNeeded
downscaleImage:scaledImage:majorDimension:
drawLine:width:height:stride:point0:point1:drawPoint:
drawRectangle:width:height:stride:keypoints:
duration
dynamicForward:paramFileUrl:cancel:
elapsedTimeSeconds
elementCount
elementType
embeddingChannels
embeddingSequenceLength
embeddingWidth
enableGating
enableMoflow
enableR2D2
encodeHashDescriptorWithBase64EncodingAndReturnError:
encodeObject:forKey:
encodeToCommandBuffer:firstInput:secondInput:correlation:
encodeToCommandBuffer:input:output:flow:upscaledFlow:
encodeToCommandBuffer:sourceTexture:destinationTexture:
encodeToCommandBuffer:sourceTextureArray:guidanceTexture:constraintsTextureArray:numberOfIterations:destinationTextureArray:
encodeWithCoder:
encodedData
endEncoding
endEntryPoint
endPointValue
energy
entityPredictionsForObservation:limit:canceller:error:
entityUniqueIdentifier
entryForResource:
entryWithLocalIdentifier:andTaskID:andStatus:andAttempts:andLastRetryDate:
enumerateFetchResult:withBatchSize:handler:
enumerateIndexesUsingBlock:
enumerateKeysAndObjectsUsingBlock:
enumerateObjectsUsingBlock:
epoch
errorCode
errorWithDescription:
errorWithDomain:code:userInfo:
espressoForward:
espressoForwardInputs:
estimateBetasN1:R6x1:betas:
estimateBetasN2:R6x1:betas:
estimateBetasN3:R6x1:betas:
estimateDistance:prevHomography:
estimateExpressionScore:encodeStats:frameWidth:frameHeight:
estimateExtrinsicsWith:andPoints3D:andNumPoints:
estimateFlow:correlation:flow:outputFlow:callback:
estimateFlowForLevel:upperFlow:outputFlow:
estimateMotionBetweenFirstImage:andSecondImage:error:
estimateMotionBetweenFirstImage:andSecondImage:withUpsample:withGuidedImage:error:
estimateMotionFlow:
estimatePose:
estimateQualityScore:
estimateRT:betas:R:T:projectionError:
estimatedAssetCount
estimator
ethnicityType
eulerAnglesToRotation:R:
evaluatePersonPromoterWithUpdateBlock:
evaluateSegment:
evaluateWithObject:
exceptionWithName:reason:userInfo:
executeDatabaseBlock:
executionNanoseconds
exif
existingAnalysisForMovieAnalyzer
exists
exitStatus
exportClustersStates:error:extendTimeoutBlock:cancelBlock:
exportResultsWithPropertyKey:toLegacyDictionary:withKey:
exportToLegacyDictionary
exportToLegacyDictionaryFromFrameInstruction:
exportToLegacyDictionaryFromParam:withLoopFlavor:
exportWallpaperForAsset:cancel:results:
exposure
exposureChangeScore
exposureScore
exposureTimeSeconds
expressionChangeScore
expressionScoreForTimerange:
expressionType
expressionsAndConfidence
extractFeatureFromImage:toFeature:
extractFeatureFromImage:toFeature:callback:
extractFeaturesFromFirst:andSecond:
extractRequiredClassificationInfoFrom:toArray:
extractRequiredFaceInfoFrom:toArray:
extractRequiredInfoFrom:toArray:
extractUsefulAreaFrom:to:withOffset:stridePadded:width:height:
eyeExpression
eyesCategory
eyesState
face1
face2
faceAdjustmentVersion
faceAlgorithmVersion
faceArea
faceAssociatedWithFaceCrop:
faceAttributes
faceBounds
faceBounds:height:
faceBoundsFromFaceCrop:error:
faceBoundsWithTransform:height:transform:
faceCandidatesforKeyFaceForPersonsWithLocalIdentifiers:context:reply:
faceCaptureQuality
faceClusterSequenceNumbersOfFacesWithClusterSequenceNumbers:error:
faceClusterSequenceNumbersOfKeyFacesInAlgorithmicFaceGroupsForPerson:verifiedClusterSequenceNumbers:
faceClusteringAgeThreshold
faceClusteringDisabled
faceClusteringJunkThreshold
faceClusteringProperties
faceClusteringThreshold
faceCount
faceCountInFaceGroup
faceCropData
faceCropDimensionsFromFaceCrop:error:
faceDetection:faces:cancel:
faceDetector
faceDetectorVisionRevision
faceDetectorWithTransform:withExistingFaceprints:frameStats:tracking:faceDominated:cancel:
faceDominated
faceFromFaceObservation:humanObservation:sourceWidth:sourceHeight:visionRequests:processingVersion:force:andError:
faceFromPHFace:copyOption:
faceHairCategory
faceID
faceId
faceJunkinessIndex
faceMergeFaceprintDistanceThreshold
faceObservationFromFaceprintData:
faceObservationWithRequestRevision:boundingBox:andAlignedBoundingBox:
faceProcessingContext
faceQuality
faceQualityScores
faceRanges
faceRectFromNormalizedCenterX:normalizedCenterY:normalizedSize:sourceWidth:sourceHeight:
faceResults
faceResultsAtIndex:
faceResultsCount
faceSharpness
faceWithLocalIdentifier:
faceprint
faceprintBlob
faceprintData
faceprintRequestRevision
faceprintRevisionForPersonModel:
faceprintVersion
faces
facesForClusteringWithLocalIdentifiers:faceprintVersion:groupingIdentifiers:
facesFromFaceObservations:humanObservations:animalObservations:sourceWidth:sourceHeight:visionRequests:blurScorePerFace:exposureScorePerFace:tooSmallFaceObservations:processingVersion:
facesFromPHFetchResult:copyOption:
facialHairType
failureScore
fastSignLanguageDetection:ofPixelBuffer:withMetadata:
favorite
fcBlockWithNumNeurons:NeuronType:
featureBlob
featureIdentifier
featureNames
featureProviderWithCVPixelBuffer:andFeatureName:
featureValueForName:
featureValueWithCGImage:pixelsWide:pixelsHigh:pixelFormatType:options:error:
featureValueWithImageAtURL:pixelsWide:pixelsHigh:pixelFormatType:options:error:
featureValueWithMultiArray:
featureValueWithPixelBuffer:
featuresAtIndex:
fetchAndComputeScoreForKeyFrame:withResult:
fetchAssetCollectionsWithLocalIdentifiers:options:
fetchAssetCollectionsWithType:subtype:options:
fetchAssetsForFaceGroups:options:
fetchAssetsForFaces:options:
fetchAssetsForPersons:options:
fetchAssetsGroupedByFaceUUIDForFaces:
fetchAssetsInAssetCollection:options:
fetchAssetsMatchingAdjustedFingerPrint:photoLibrary:
fetchAssetsMatchingMasterFingerPrint:photoLibrary:
fetchAssetsWithCloudIdentifiers:options:
fetchAssetsWithLocalIdentifiers:options:
fetchAssetsWithMediaType:options:
fetchAssetsWithOptions:
fetchAssociatedPersonsGroupedByFaceGroupLocalIdentifierForFaceGroups:options:
fetchEmptyFaceGroupsWithOptions:
fetchEntityForModelType:evaluationMode:allowUnverifiedPerson:
fetchFaceCropByFaceLocalIdentifierForFaces:fetchOptions:
fetchFaceCropsNeedingFaceDetectionWithOptions:
fetchFaceCropsWithLocalIdentifiers:options:
fetchFaceGroupsForPerson:options:
fetchFaceGroupsGroupedByFaceLocalIdentifierForFaces:options:
fetchFaceGroupsWithFace:options:
fetchFaceGroupsWithOptions:
fetchFaceWithClusterSequenceNumber:error:
fetchFaceWithLocalIdentifier:error:
fetchFaces
fetchFacesForFaceCrop:options:
fetchFacesForPerson:options:
fetchFacesGroupedByAssetLocalIdentifierForAssets:options:
fetchFacesInAsset:options:
fetchFacesInFaceGroup:options:
fetchFacesOnAssetWithFace:options:
fetchFacesWithLocalIdentifiers:options:
fetchFacesWithOptions:
fetchInvalidMergeCandidatePersonsForPerson:options:
fetchKeyFaceForFaceGroup:options:
fetchKeyFaceForPerson:options:
fetchMergeCandidatePersonsForPerson:options:
fetchMomentUUIDByAssetUUIDForAssets:options:
fetchMomentsForAssetsWithLocalIdentifiers:options:
fetchMomentsWithOptions:
fetchOptionsWithInclusiveDefaultsForPhotoLibrary:
fetchPersonAssociatedWithFaceGroup:options:
fetchPersonWithFace:options:
fetchPersonWithLocalIdentifier:options:error:
fetchPersonsForAssetCollection:options:
fetchPersonsGroupedByAssetLocalIdentifierForAssets:options:
fetchPersonsWithLocalIdentifiers:options:
fetchPersonsWithOptions:
fetchPropertySetsIfNeeded
fetchRejectedFacesForPerson:options:
fetchRejectedPersonsForFace:options:
fetchSceneClassificationsGroupedByAssetLocalIdentifierForAssets:
fetchedObjectIDs
fetchedObjects
fileExistsAtPath:
fileExistsAtPath:isDirectory:
fileSize
fileSystemRepresentation
fileURLWithPath:
fileURLWithPath:isDirectory:
filename
filterDescriptorWithWidth:height:arrayLength:kernelSpatialDiameter:kernelTemporalDiameter:epsilon:sourceChannels:guideChannels:preallocateIntermediates:
filterUsingPredicate:
filteredArrayUsingPredicate:
filteringPose:
finalizeAnalysis
finalizeAnalysisAtTime:
finalizeAnalysisPass:
finalizeKeyFrame
finalizeWithDestructiveTrimStart:trimEnd:
finalizeWithDestructiveTrimStart:trimEnd:andCaptureTime:
findBestHighlightSegment:targetTrim:
findBestTrim:
findMetaTrackforType:
findNextSample:timerange:
fingerprint
fingerprintHashes
finishAnalysisPass:
finishAnalysisPass:fpsRate:
finishAnalysisPass:withStillImageBuffer:
finishDecoding
finishEncoding
finishLoading
firstObject
fitOneImage:
flag
flags
flagsForOrientation:width:height:
flagsFromKeypoints:withMinConfidence:
flickerScore
flipTransform:
floatValue
flowScalingTo:flowBufferY:scalerX:scalerY:
flowScalingTo:scalerX:scalerY:
flush
flushCache
flushWithEndTime:error:
focalPoint
focusStatus
forcePersonDetection
formatDescriptions
forward:
frameExpressionScore
frameFaceResults
frameInstructions
frameInstructionsAtIndex:
frameInstructionsCount
frameInstructionsType
frameInterval
frameLength
frameProcessedByFaceDetector
frameProcessedByHumanAnalyzer
frameProcessedByPetsActionAnalyzer
frameProcessedByVideoAnalyzer
frameResults
frameScenes
freeModel
gatherAvailableRequests
gatingPayload
gatingResultItems
gaze
gazeCenterX
gazeCenterY
gazeMask
gazeType
generateActivityDescriptor
generateAndPersistFaceCropsForFaces:withAsset:resource:resourceURL:error:
generateCGImageAsynchronouslyForTime:completionHandler:
generateCaption:error:
generateClassificationScoresForPixelBuffer:error:
generateCurationSegment
generateDistanceDescriptor:withDescriptorClass:forAsset:withResources:lastFrame:
generateExpressionSegments:
generateFaceCropsForFace:resourceURL:groupingIdentifier:
generateHandKeypoints:keypointConfidence:offset:
generateHandsBoxes:
generateHandsRegions:boxes:maxNumRegions:
generateHighlights
generateHumanPose:
generateInterestingTrimBasedOnCaptureTime:
generateKeyFrameResource:
generateLineWeightMap:weightMap:
generateLivePhotoRecommendationForResults:andPrivateResults:usingFaceAction:
generateMotionFlow
generateMovieCurations
generateOrientationMap
generateOutput
generatePersonBoxes:
generatePersonRegions:boxes:maxNumRegions:
generatePetsBoxes:faceBoxes:cancel:
generatePetsRegions:outHeight:outWidth:boxes:faceBoxes:maxNumRegions:
generateSalientRegion:outHeight:outWidth:
generateSubleMotionScore:
generateThresholds:withConfidences:
generateVIPModelWithType:ignoreLastGenerationTime:evaluationMode:allowUnverifiedPerson:modelGenerated:extendTimeout:andCancel:
generateVNImageprintWithType:archiveData:andError:
geometry
gestureDetection:score:
getAllClustersAndReturnError:
getBytes:bytesPerRow:bytesPerImage:fromRegion:mipmapLevel:slice:
getBytes:length:
getCGRectWithClipWidth:height:
getClosestAspectRatio:
getClusters:threshold:utilizingGPU:cancelOrExtendTimeoutBlock:error:
getControlPoints
getDetectionScore:
getEnableMovieHumanAction
getEspressoContext
getEulerAngle:
getFaceClusters:clusteringThreshold:utilizingGPU:cancelOrExtendTimeoutBlock:error:
getFaceHeat:
getFaceScoreFromOutput:ratio:
getFirstAtomWithFourCharCode:fromSetupData:
getFlowToBuffer:
getFlowWithHeight:andWidth:
getGPUContext
getHumanActionClassiferType
getInputBuffer
getInputBuffer:srcWidth:cnnInputHeight:cnnInputWidth:
getInputBuffer:srcWidth:cnnInputHeight:cnnInputWidth:offset:
getInternal3dLandmarksCoordinates:lm3dPos:
getLocalUrl
getMaximumHighlightInSec
getMinimumHighlightInSec
getNextCaptureSampleBuffer
getObject
getOneInternalLandmarkCoordinates:lmCoord:lmWeight:lm3dPos:
getPlanPhase
getPoseParam
getResourceValue:forKey:error:
getRevision
getSalientRegions:
getSceneSwichFrequency
getSetupDataFrom:
getTranscript
gist
glassesType
globalMotion
globalQualityScore
globalSession
glyphName
gpsHorizontalAccuracy
gradientEstimation:width:height:gradient:gradientMag:
groupedClusterSequenceNumbersOfFacesInFaceGroupsOfMinimumSize:error:
groupingIdentifier
groupingIdentifierFromFaceCrop:error:
guidedUpsampling:inBGRA:
gyroHomographyVersionIsValid:
gyroStabilization
hadFlash
hairColorCategory
hairColorType
hairType
handDistance:withhandB:
handID
handleTimerEvent
handsDetection:handsRegions:cancel:
harmoniousColorScore
hasAction
hasAdjustments
hasAssetAdjustedFingerprint
hasBounds
hasCachedParseData
hasColorNormalizationBlob
hasDistanceToPreviousScene
hasEpoch
hasFaceId
hasFaceMask
hasFaceQuality
hasFaceSharpness
hasFlags
hasFlash
hasFocalPoint
hasGlobalQualityScore
hasGoodSubjectAction
hasKeyFrame
hasLoopFadeLen
hasLoopPeriod
hasLoopStart
hasMeaningfulSceneSegment:withFpsRate:
hasPrefix:
hasProcessedForLibrary:
hasQuality
hasRecipeBlob
hasSceneprintDistanceToPreviousScene
hasSlowMotionAdjustments
hasSmile
hasStatsFlags
hasTypesWide
hasUnderExpose
hasValidSceneProcessing
hasWifiOrEthernetConnection
hash
hashData
headgearType
height
hidden
highPrecisionThreshold
highRecallThreshold
highlightScore
highlightScoreForTimeRange:average:
highlightScoreResults
highlights
hintDomain
homographyParamAtIndex:
homographyParams
homographyParamsAtIndex:
homographyParamsCount
humanActionScore
humanPoseScore
humanScore
idealDimension
identifier
identifyConflictingL0Clusters:csnToRejectedPersonForNewlyClusteredFaces:csnToConfirmedPersonForNewlyClusteredFaces:
imageAnalysisFromLegacyDictionary:
imageAssetWithURL:
imageBlurResults
imageBlurResultsAtIndex:
imageBlurResultsCount
imageBlurResultsType
imageBufferValue
imageCaptionModelTestURL
imageCompositionResults
imageCompositionResultsCount
imageCompositionResultsType
imageCreationOptions
imageExposureResults
imageExposureResultsAtIndex:
imageExposureResultsCount
imageExposureResultsType
imageFaceResults
imageFaceResultsAtIndex:
imageFaceResultsCount
imageFaceResultsType
imageFeatureResults
imageFeatureResultsAtIndex:
imageFeatureResultsCount
imageFeatureResultsType
imageForResource:pixelFormat:
imageForResource:pixelFormat:maxDimension:
imageForResource:pixelFormat:maxDimension:orientation:
imageHumanPoseResults
imageHumanPoseResultsAtIndex:
imageHumanPoseResultsCount
imageHumanPoseResultsType
imageJunkResults
imageJunkResultsAtIndex:
imageJunkResultsCount
imageJunkResultsType
imageManager
imageNeuralHashprint
imagePetsFaceResults
imagePetsFaceResultsAtIndex:
imagePetsFaceResultsCount
imagePetsFaceResultsType
imagePetsResults
imagePetsResultsAtIndex:
imagePetsResultsCount
imagePetsResultsType
imageRegions
imageSaliencyResults
imageSaliencyResultsAtIndex:
imageSaliencyResultsCount
imageSaliencyResultsType
imageSceneprintResults
imageSceneprintResultsAtIndex:
imageSceneprintResultsCount
imageSceneprintResultsType
imageShotTypeResults
imageShotTypeResultsAtIndex:
imageShotTypeResultsCount
imageShotTypeResultsType
imageSignatureHash
imageType
imageURL
imageWithPixelBuffer:orientation:
imageWithPreferredDimension:
imageWithPreferredDimension:orientation:
imagefingerprintsRequest
imageprint
imageprintWrapper
immersivenessScore
inactiveCost
includeCN
includeDMF
includeDO
includeIVS
includeJunk
includeLM
includeMeme
includeNSFW
includePA
includeSDG
includeSE
includeSO
includeWP
increaseLengthBy:
indexOfObject:inSortedRange:options:usingComparator:
indexSetWithIndexesInRange:
indexesOfObjectsPassingTest:
inference:
inference:duration:
init
init:sharedModel:modelName:
initForReadingFromData:error:
initFromConfigFile:numStage:numLandmarks:numTreePerStage:depthOfTree:numFeatures:
initImageTransform:transformedImageWidth:transformedImageHeight:
initModelWithName:andConfig:
initModule:config:cancel:
initRequiringSecureCoding:
initStandardFormatWithSampleRate:channels:
initWith:confidence:
initWithAVAsset:forAnalysisTypes:
initWithAbsMotion:atTime:
initWithAllocator:
initWithAnalysisResults:
initWithAnalysisType:isLivePhoto:photoOffset:hadFlash:hadZoom:isTimelapse:preferredTimeRange:asset:
initWithAnalysisTypes:forStreaming:
initWithAnalysisTypes:transform:timeRange:isLivePhoto:photoOffset:frameStats:hadFlash:hadZoom:keyFrameResults:isTimelapse:preferredTimeRange:asset:
initWithAnalysisTypes:withPreferredTransform:withFocalLengthInPixels:withAnalysisQueue:withTurbo:
initWithAngle:
initWithAnnotations:revision:
initWithAsset:error:
initWithAssets:analysisTypes:options:progressHandler:andCompletionHandler:
initWithAssets:andOptions:andCompletionHandler:
initWithAssets:options:andCompletionHandler:
initWithBase64EncodedString:options:
initWithBufferWidth:bufferHeight:andPixelFormat:
initWithBytesNoCopy:length:deallocator:
initWithCGImage:options:session:
initWithCMSampleBuffer:orientation:options:
initWithCVPixelBuffer:andFeatureName:
initWithCVPixelBuffer:options:
initWithCVPixelBuffer:options:session:
initWithCVPixelBuffer:orientation:options:session:
initWithCapacity:
initWithCenterAndSize:y:width:height:confidence:
initWithClassifierIdentifier:error:
initWithClientBundleID:andClientTeamID:
initWithCloudIdentifierRequests:photoLibrary:clientBundleID:clientTeamID:cancelBlock:andCompletionHandler:
initWithCoder:
initWithCommonFormat:sampleRate:channels:interleaved:
initWithCompletionHandler:
initWithConfiguration:
initWithConfiguration:error:
initWithContentsOfFile:
initWithContentsOfURL:
initWithContentsOfURL:configuration:error:
initWithContentsOfURL:error:
initWithContext:
initWithData:
initWithData:encoding:
initWithData:options:
initWithData:orientation:options:
initWithDatabaseReader:forAssets:resultsTypes:batchSize:
initWithDevice:filterDescriptor:
initWithDictionary:
initWithDomain:knowledgeGraphID:title:thumbnailURL:thumbnailAspectRatio:shortDescription:detailedDescription:webURL:knowledgeProperties:
initWithDomain:label:glyphName:hasFocalPoint:focalPoint:displayLabel:displayMessage:
initWithEdgeMap:mapWidth:mapHeight:angleStep:
initWithFace:andFace:distance:
initWithFaceAnnotations:humanAnnotations:nsfwAnnotations:textBlockAnnotation:scenenetAnnotation:barcodeAnnotation:
initWithFaceClusterIds:clusterFlags:updateHandler:
initWithFaceCrop:andCompletionHandler:
initWithFaceCropData:originatingFace:
initWithFaceObservations:
initWithFaceResults:
initWithFaceResults:sdof:
initWithFaceResults:sdof:revision:
initWithFaceprint:torsoprint:
initWithFaceprintData:faceprintVersion:
initWithFeatureProviderArray:
initWithFilterTabs:distanceVariance:diffVariance:
initWithFlagHasFaceOrPet:
initWithFocalLengthInPixels:
initWithFocalLengthInPixels:offline:isFastMode:
initWithFocalLengthInPixels:principalPoint:cameraTowardsPositiveZ:
initWithFocusStatus:atTime:
initWithForceCPU:forceNNGraph:shared:
initWithForceCPU:sharedModel:
initWithFrameRate:timeRange:
initWithFrameStats:
initWithFrameStats:timeOfInterest:
initWithFrameStats:timeOfInterest:phFaces:
initWithFrameWidthInMb:heightInMb:
initWithGPUContext:
initWithIdentifier:error:
initWithImage:
initWithImage:annotation:normalizedRegionOfInterest:domainsOfInterest:queryContext:
initWithImage:edgeMap:width:height:widthExtension:heightExtension:
initWithImage:regionOfInterest:imageType:preferredMetalDevice:
initWithImage:userFeedbackPayload:sfReportData:reportIdentifier:
initWithImageAsset:requestHandler:regionOfInterest:
initWithImageData:uniformTypeIdentifier:identifier:clientBundleID:clientTeamID:
initWithImageLoader:imageSize:
initWithImageSignatureprintType:imageSignatureHashType:
initWithImageURL:andMovieURL:
initWithImageURL:isSDOF:
initWithImageprintType:version:andData:
initWithIndexesInRange:
initWithInputImage:
initWithInputImageAtURL:error:
initWithInputImageFromCGImage:error:
initWithIntervalNanoseconds:isOneShot:andBlock:
initWithIsSensitive:andAttributes:
initWithKeypointsOption:aspectRatio:lightweight:forceCPU:sharedModel:flushModel:
initWithKeypointsOption:forceCPU:sharedModel:aspectRatio:modelName:revision:
initWithLabel:normalizedBoundingBox:confidence:
initWithLightweightOption:aspectRatio:computationAccuracy:forceCPU:sharedModel:flushModel:cancel:
initWithLivePhoto:
initWithLocalIdentifier:
initWithLocalIdentifier:andTaskID:andStatus:andAttempts:andLastRetryDate:
initWithLocalIdentifier:faceCropData:
initWithLocaleIdentifier:
initWithMLModel:
initWithMachServiceName:options:
initWithMaster:adjusted:
initWithMaxNumRegions:
initWithMaxNumRegions:forceCPU:sharedModel:
initWithMaxNumRegions:forceCPU:sharedModel:inputConfig:
initWithMaxNumRegions:forceCPU:sharedModel:inputConfig:revision:
initWithMaxNumRegions:prune:
initWithMetadata:sourceSize:cropRect:
initWithMode:
initWithModelFile:
initWithModelFile:paramFile:numTri:triList:angle:
initWithModelName:
initWithModelPath:
initWithMonochromeBufferCreator:
initWithMovieURL:
initWithMovingObjectsResults:
initWithNormalizedBoundingBox:andDomains:
initWithNormalizedBoundingBox:regionAttributes:andSearchSections:
initWithNumberOfScales:numOfOrientations:width:height:
initWithObject:fromPool:
initWithObjectBounds:inFrame:timestamp:
initWithObjectIdentifier:imageURL:thumbnailURL:metadata:
initWithObservations:
initWithOptions:
initWithOptions:andCompletionHandler:
initWithOptions:andExistingResults:
initWithOptions:cancel:
initWithOptions:error:
initWithPCMFormat:frameCapacity:
initWithPHAsset:
initWithPHAsset:withExistingAnalysis:forAnalysisTypes:
initWithPHAsset:withPausedAnalysis:forAnalysisTypes:
initWithPHFaces:
initWithPHFaces:existingResults:
initWithParameters:
initWithParameters:NeuronType:
initWithParameters:filterNum:chunk:reLU:padding:groups:stride:batchNorm:
initWithParameters:height:width:context:
initWithParameters:inputNames:outputNames:properties:
initWithParameters:useGPU:
initWithPerson:andPerson:reason:
initWithPersonIdentifier:personName:boundingBox:andConfidence:
initWithPhotoLibrary:
initWithPhotoLibrary:andContext:
initWithPhotoLibrary:andDelegate:
initWithPhotoLibrary:andFaceClusterer:andContext:
initWithPhotoLibrary:context:cancelOrExtendTimeoutBlock:
initWithPhotoLibraryURL:
initWithPhotosAsset:clientBundleID:clientTeamID:
initWithPhotosAsset:pixelBuffer:orientation:clientBundleID:clientTeamID:
initWithPixelBuffer:
initWithPixelBuffer:orientation:andIdentifier:clientBundleID:clientTeamID:
initWithPixelFormat:
initWithPlistRepresentation:
initWithPostProcessOptions:
initWithProperties:forAnalysisTypes:
initWithProperties:withResultsHandler:andInterruptionHandler:
initWithQueryTerm:hintDomain:textContext:imageContext:annotation:queryContext:
initWithQueue:turbo:
initWithRegionOfInterest:domains:
initWithRequest:andConfiguration:
initWithRequest:imageAsset:andSignpostPayload:
initWithRequestAnalyses:formatDescription:
initWithRequests:forAsset:cancelBlock:andCompletionHandler:
initWithResource:
initWithResourceManager:andResource:
initWithResultItems:
initWithResultItems:andUserFeedbackPayload:
initWithRevision:
initWithSampleBuffer:
initWithSceneId:withDuration:withConfidence:
initWithSearchSections:
initWithSoundIdentifier:
initWithState:error:
initWithSurface:cropRect:confidence:
initWithSurroundingText:normalizedBoundingBoxes:
initWithThreshold:
initWithTime:andScore:
initWithTimeOfInteret:frameRate:isLivePhoto:phFaces:timeRange:requestedAnalyses:
initWithTimeRange:
initWithTimeRange:score:andKeyFrame:
initWithTimerange:andScore:
initWithTimestamp:score:valid:
initWithTimestamps:andTrack:
initWithTrack:
initWithTrack:timerange:
initWithTrack:timerange:atInterval:
initWithTrack:timerange:withSettings:applyTransform:
initWithTrackStart:threshold:resultsKey:
initWithTransform:
initWithTransform:blendShapes:geometry:
initWithTransform:frameStats:faceDominated:
initWithTransform:timeRange:isLivePhoto:frameStats:keyFrameResults:
initWithTransform:withExistingFaceprints:frameStats:
initWithType:
initWithType:cachePath:state:threshold:requestRevision:
initWithType:cachePath:state:threshold:torsoThreshold:requestRevision:torsoprintRequestRevision:
initWithTypes:
initWithURL:
initWithURL:identifier:clientBundleID:clientTeamID:
initWithURL:options:
initWithURLAsset:withOptions:analysisTypes:progressHandler:completionHandler:
initWithUUIDBytes:
initWithUUIDString:
initWithVCPAsset:withExistingAnalysis:forAnalysisTypes:
initWithVertices:vertexCount:
initWithVideoAsset:videoAdjustments:
initWithVideoTrack:withMetaOrientation:withPrivateResults:withFrameStats:isTimelapse:isIris:irisPhotoOffsetSec:irisPhotoExposureSec:slowMoRate:faceDominated:
initWithWidth:height:
initWithXYAndSize:y:width:height:confidence:
input
inputBlob
inputBlobs
inputBoundsHeight
inputBoundsWidth
inputBoundsX
inputBoundsY
inputDescriptionsByName
inputFaceObservations
inputFeatureName
inputImage
inputPixelFormat
inputSize
insertObject:atIndex:
insertTimeRange:ofAsset:atTime:error:
instancesRespondToSelector:
intValue
integerValue
interestScore
interestingSubjectScore
interestingnessScore
interfaceWithProtocol:
internalPredicate
interrupt
intersect:
intersectSet:
intersectionOverUnion:rect:
intersectsSet:
intrusiveObjectPresenceScore
invalidFaceClusterSequenceNumbersInClusterSequenceNumbers:cancelOrExtendTimeoutBlock:error:
invalidFaceClusterSequenceNumbersInClusterSequenceNumbers:canceler:error:
invalidate
isActive:
isAnalysisResultNeeded:
isAssetBlacklisted:blacklistDate:
isAutoPlayable
isCanceled
isCloseup
isCloudPhotoLibraryEnabled
isCoarse
isConfirmedFaceCropGenerationPending
isContentTooShort
isCurated:
isDimensionUnknown:
isDuplicate:withRect:
isEnabled
isEqual:
isEqualToDate:
isEqualToFingerprint:
isEqualToNumber:
isEqualToString:
isExceedingQuota
isFast
isFilterSizeSupported:
isGoodQuality:
isGuestAsset
isHDR
isHeadingFrame
isHidden
isHighResDecoded
isHomePod
isIdentityInit
isInImage:width:height:
isInTrash
isInVIPModel
isInputOutput
isKindOfClass:
isLivePhoto
isLivePhotoKeyFrameEnabled
isLocallyAvailable
isMLHighlightEnabled
isMemberOfClass:
isMovieResourceLocalAvailable
isMultiLibraryModeEnabled
isOutOfBoundary:
isPano
isReadyToReturnSuggestions
isRightEyeClosed
isSDOF
isScoreValid:
isScreenshot
isSegmentPoint
isSensitive
isSettlingEffectPregatingEnabled
isSettlingOK
isSlowmo
isStableMetaMotion:
isSystemPhotoLibrary
isTimelapse
isTimestampSkipable:
isTooSmall
isTracked
isTrimmed
isValidFaceCrop:
isValidFaceprint
isValidTorsoprint
isVerified
isVerticalOrHorizontal:
items
iteratorForAssets:withDatabaseReader:resultTypes:batchSize:
junkImageRequest
junkScore
junkScoreForTimerange:lengthScale:
kalmanFiltering:T:
keyEnumerator
keyFaceForPerson:qualityMeasureByFace:updateBlock:
keyFrame
keyFrameScores
keyFrames
keypoints
keypointsAtIndex:
keypointsCount
keypointsFromObservations:
keypointsFromTensor:width:height:channels:withOptions:results:
keypointsFromTensor:withOptions:results:
keypointsToObservation:
keypointsType
knowledgeGraphID
knowledgeProperties
l1ClusteredFaceIdsGroupedByL0ClustersForClustersContainingFaceIds:error:
label
labelName
labels
landmarks
languages
last
lastCompletePrefetchDate
lastObject
lastPathComponent
lastRetryDate
lastSuccessfulSyncDate
latestTaxonomyIdentifier
leftEyeClosed
length
level0ClusterAsFaceCSNsByLevel0KeyFaceCSNForClusterIdentifiedByFaceCSN:error:
librarySpecificFetchOptions
lineFromPoint:toPoint:
livePhotoAssetWithImageURL:andMovieURL:
livePhotoEffectsResults
livePhotoEffectsResultsCount
livePhotoEffectsResultsType
livePhotoHumanActionClassificationResults
livePhotoHumanActionClassificationResultsAtIndex:
livePhotoHumanActionClassificationResultsCount
livePhotoHumanActionClassificationResultsType
livePhotoKeyFrameResults
livePhotoKeyFrameResultsAtIndex:
livePhotoKeyFrameResultsCount
livePhotoKeyFrameResultsType
livePhotoKeyFrameStillResults
livePhotoKeyFrameStillResultsAtIndex:
livePhotoKeyFrameStillResultsCount
livePhotoKeyFrameStillResultsType
livePhotoRecommendationResults
livePhotoRecommendationResultsAtIndex:
livePhotoRecommendationResultsCount
livePhotoRecommendationResultsType
livePhotoSharpnessResults
livePhotoSharpnessResultsAtIndex:
livePhotoSharpnessResultsCount
livePhotoSharpnessResultsType
livelyColorScore
loadAnalysisResults:
loadAnalysisResults:audioResults:
loadAnalysisResultsFrom:actionAnalyzer:atTime:
loadContentsOfURL:configuration:completionHandler:
loadFullPixelBuffer:scaledPixelBuffer299:scaledPixelBuffer360:fromImageURL:abnormalDimension:
loadHighResPixelBuffer:orientation:
loadHighlightScoreResults:
loadImageURL:abnormalDimension:withNonPanoPreWarmSizes:toColorPixelBuffer:lumaPixelBuffer:andImage:
loadKeyFrameResult:timestamp:
loadKeyFrameResults:
loadModel
loadModel:
loadPersonModelAtPath:error:
loadPersonsModelAndInitializeFaceAnalyzerWrapper
loadPixelBuffer:orientation:
loadPropertiesForAsset:
loadVIPModelAtPath:withVIPType:error:
loadValuesAsynchronouslyForKeys:completionHandler:
loadVideoAnalysisResults:audioAnalysisResults:videoCNNResults:andFaceRanges:frameSize:
loadWeights:inputDim:outputDim:quantFactor:
loadWithConfiguration:completionHandler:
localIdentifierWithUUID:
localizedDescription
localizedStringFromDate:dateStyle:timeStyle:
location
locationChange:relativeTo:landscape:
locationCoordinate
lock
logLevel
logMemoryWithMessage:
loggingEnabled
longExposureSuggestionState
longLongValue
longValue
longexposure
loopFadeLen
loopPeriod
loopStart
loopSuggestionState
lostCount
lostTrack
lostTrackInd
lowKeyLightingScore
machineReadableCodeData
machineReadableCodeElements
mad_PHFaceGazeTypeDescription:
mad_PHValueFromVNAgeCategoryLabel:
mad_PHValueFromVNEthnicityCategoryLabel:
mad_PHValueFromVNExpressionCategoryLabel:
mad_PHValueFromVNEyesCategoryLabel:
mad_PHValueFromVNFaceGazeDirection:
mad_PHValueFromVNFaceHairCategoryLabel:
mad_PHValueFromVNFaceHairCategoryV2Label:
mad_PHValueFromVNGlassesCategoryLabel:
mad_PHValueFromVNHairColorCategoryLabel:
mad_PHValueFromVNHeadgearCategoryLabel:
mad_PHValueFromVNPoseCategoryLabel:
mad_PHValueFromVNSexCategoryLabel:
mad_PHValueFromVNSkintoneCategoryLabel:
mad_PHValueFromVNSmilingCategoryLabel:
mad_VNFaceGazeDirectionDescription:
mad_countOfUnclusteredFaces
mad_defaultRequest
mad_internalPredicateNeedsProcessingForTaskID:
mad_internalPredicateWithPriority:forTaskID:
mad_isExpectedTaxonomy
mad_nonPrioritizedAssetsForFaceDetectionInternalPredicate
mad_prioritizedAssetsForFaceDetectionInternalPredicate
mad_sceneIdFromSceneName:
mad_sceneNameFromSceneId:
mad_unclusteredFacesFetchOptions
main
mainFileURL
makeValidationDecision
manual
manualOrder
mapAvailableRequestsToResolution
mapToCameraNegativeZ
marketingName
maskOnly
master
matchesImageAsset:
maxFaceCountForClustering
maxHighlightDuration
maxSizeBytes
maxTrimMovieHighlight:
maxX
maxY
maximumAspectRatio
maximumCandidateCount
maximumFaceCount
maximumLeafObservations
maximumObservations
meanBlendshape
mediaAnalysisProperties
mediaSubtypes
mediaType
memeRequest
mergeCandidatePairWithPerson:andPerson:reason:
mergeConsecutiveShortSegments
mergeExistingFaces:andDetectedFaces:withRequestHandler:orientedWidth:orientedHeight:assetWidth:assetHeight:
mergeFrom:
mergeSameTypeSegments
mergeSegment:
mergeSimilarSegments
mergeSparseShortSegments
meshVertices
metadata
metadataForFormat:
metadataItemsFromArray:filteredByIdentifier:
metadataItemsFromArray:withKey:keySpace:
minProcessTimeIntervalInSecs
minVersion
minX
minY
minimumAspectRatio
minimumConfidence
minimumFaceGroupSizeForCreatingMergeCandidates
minimumSize
minimumSuggestionSize
minimumUnverifiedFaceCount
minimumVerifiedFaceCount
minusSet:
mode
model
modelDescription
modelFromURL:options:error:
modelURLForType:timeout:
modelWithConfiguration:error:
modelWithContentsOfURL:configuration:error:
modelWithContentsOfURL:error:
modificationDate
modulateByExposure
modulateByJunk
modulateByTimeRange
momentSortDescriptors
motionBlurVector
motionDivScore
motionParam
motionScore
motionType
moveBoundaryLandmarks:output:isInput:
movie
movieActivityLevelResults
movieActivityLevelResultsAtIndex:
movieActivityLevelResultsCount
movieActivityLevelResultsType
movieAnalysisFromLegacyDictionary:
movieApplauseResults
movieApplauseResultsAtIndex:
movieApplauseResultsCount
movieApplauseResultsType
movieAssetWithURL:
movieAudioQualityResults
movieAudioQualityResultsAtIndex:
movieAudioQualityResultsCount
movieAudioQualityResultsType
movieBabbleResults
movieBabbleResultsAtIndex:
movieBabbleResultsCount
movieBabbleResultsType
movieCameraMotionResults
movieCameraMotionResultsAtIndex:
movieCameraMotionResultsCount
movieCameraMotionResultsType
movieCheeringResults
movieCheeringResultsAtIndex:
movieCheeringResultsCount
movieCheeringResultsType
movieClassificationResults
movieClassificationResultsAtIndex:
movieClassificationResultsType
movieFaceResults
movieFaceResultsAtIndex:
movieFaceResultsCount
movieFaceResultsType
movieFaceprintResults
movieFaceprintResultsAtIndex:
movieFaceprintResultsCount
movieFaceprintResultsType
movieFeatureResults
movieFeatureResultsAtIndex:
movieFeatureResultsCount
movieFeatureResultsType
movieFineSubjectMotionResults
movieFineSubjectMotionResultsAtIndex:
movieFineSubjectMotionResultsCount
movieFineSubjectMotionResultsType
movieHighlightResults
movieHighlightResultsAtIndex:
movieHighlightResultsCount
movieHighlightResultsType
movieHighlightScoreResults
movieHighlightScoreResultsAtIndex:
movieHighlightScoreResultsType
movieHumanActionResults
movieHumanActionResultsCount
movieHumanActionResultsType
movieHumanPoseResults
movieHumanPoseResultsAtIndex:
movieHumanPoseResultsCount
movieHumanPoseResultsType
movieInterestingnessResults
movieInterestingnessResultsAtIndex:
movieInterestingnessResultsCount
movieLaughterResults
movieLaughterResultsAtIndex:
movieLaughterResultsCount
movieLaughterResultsType
movieLoudnessResults
movieLoudnessResultsAtIndex:
movieLoudnessResultsCount
movieLoudnessResultsType
movieMovingObjectResults
movieMovingObjectResultsAtIndex:
movieMovingObjectResultsCount
movieMovingObjectResultsType
movieMusicResults
movieMusicResultsAtIndex:
movieMusicResultsCount
movieMusicResultsType
movieObstructionResults
movieObstructionResultsCount
movieObstructionResultsType
movieOrientationResults
movieOrientationResultsCount
movieOrientationResultsType
moviePetsFaceResults
moviePetsFaceResultsAtIndex:
moviePetsFaceResultsCount
moviePetsFaceResultsType
moviePetsResults
moviePetsResultsAtIndex:
moviePetsResultsCount
moviePetsResultsType
moviePreEncodeResults
moviePreEncodeResultsAtIndex:
moviePreEncodeResultsCount
moviePreEncodeResultsType
movieQualityResults
movieQualityResultsAtIndex:
movieQualityResultsCount
movieQualityResultsType
movieSaliencyResults
movieSaliencyResultsAtIndex:
movieSaliencyResultsCount
movieSaliencyResultsType
movieSceneResults
movieSceneResultsAtIndex:
movieSceneResultsCount
movieSceneResultsType
movieSceneprintResults
movieSceneprintResultsAtIndex:
movieSceneprintResultsCount
movieSceneprintResultsType
movieStabilizationResults
movieStabilizationResultsAtIndex:
movieStabilizationResultsCount
movieStabilizationResultsType
movieSubjectMotionResults
movieSubjectMotionResultsAtIndex:
movieSubjectMotionResultsCount
movieSubjectMotionResultsType
movieSubtleMotionResults
movieSubtleMotionResultsAtIndex:
movieSubtleMotionResultsCount
movieSubtleMotionResultsType
movieSummary
movieSummaryResults
movieSummaryResultsAtIndex:
movieSummaryResultsCount
movieSummaryResultsType
movieUtteranceResults
movieUtteranceResultsAtIndex:
movieUtteranceResultsCount
movieUtteranceResultsType
movieVoiceResults
movieVoiceResultsAtIndex:
movieVoiceResultsCount
movieVoiceResultsType
multiLevelSocialGroupsWithPersonClusterManager:forPersons:updateBlock:
mutableAudioBufferList
mutableBytes
mutableCopy
name
nameSource
narrowedBoundingBox
naturalSize
needsFullSync
needsPersonBuilding
needsUpdate
newAllFacesFetchOptionsWithPhotoLibrary:
newAllPersonsFetchOptionsWithPhotoLibrary:
newAllPersonsWithAtLeastOneFaceFetchOptionsWithPhotoLibrary:
newAssetFetchOptionsWithPhotoLibrary:
newBufferWithIOSurface:
newBufferWithLength:options:
newComputePipelineStateWithFunction:error:
newConfigurationForEntityPrintsGeneratedByRequest:error:
newDefaultLibraryWithBundle:error:
newDictionaryPopulatedWithFaceCropDataFromImageData:
newDictionaryRepresentationOfFaceCropDataFromFaceBox:andCropRegion:andGroupingIdentifier:
newFaceCropFromCGImageSource:withFaceRect:groupingIdentifier:error:
newFaceCropFromImageURL:withNormalizedFaceRect:groupingIdentifier:error:
newFacesDeterministicSortDescriptors
newFunctionWithName:
newLinearTextureWithDescriptor:offset:bytesPerRow:bytesPerImage:
newMutablePersonsModel
newTextureWithDescriptor:
newTextureWithDescriptor:iosurface:plane:
newVerifiedPersonsFetchOptionsWithPhotoLibrary:
newVerifiedPersonsWithAtLeastOneFaceFetchOptionsWithPhotoLibrary:
newVisibleFacesFetchOptionsWithPhotoLibrary:
next
nextBatch
nextObject
nextTimedMetadataGroup
nodeForName:
nodeForSceneClassId:
nodeWithRequest:andConfiguration:
noiseReduction:sigma:imageFiltered:
noiseScore
nominalFrameRate
nonGroupedGroupID
nonMaxSuppression:
normDistance:point2:
normalization
normalization:
normalizeActivityDescriptor
normalizedBoundingBox
normalizedBoundingBoxes
normalizedFaceRect
normalizedRectForRect:inBoundsOfSize:
notifyLibraryAvailableAtURL:
nsfwClassifications
nsfwRequest
null
numOfFrames
numOfValidFrames
numSingletons
numValidSingletons
numVertices
numberFromString:
numberOfAccumulatedClusterChanges
numberOfFacesPendingClustering
numberValue
numberWithDouble:
numberWithFloat:
numberWithInt:
numberWithInteger:
numberWithLongLong:
numberWithShort:
numberWithUnsignedChar:
numberWithUnsignedInt:
numberWithUnsignedInteger:
numberWithUnsignedLong:
numberWithUnsignedLongLong:
object
objectAtIndex:
objectAtIndexedSubscript:
objectBounds
objectBoundsInitial
objectEnumerator
objectForKey:
objectForKeyedSubscript:
objectID
objectIdentifier
objectPoolWithAllocator:
objectRequest
objectsAtIndexes:
objectsMotion
observation
observationWithBoundingBox:
observationWithRequestRevision:boundingBox:
obstructionScore
ontologyNode
openAndWaitWithUpgrade:error:
openDatabase
optInPerson:error:extendTimeoutBlock:cancelBlock:
optInPersonCount
optInStatus:error:
optimizeBetas:R6x1:betas:
optimizeProjectionMatrix:tracking:firstPass:
orPredicateWithSubpredicates:
orientation
originalFilename
originalMovie
originalMovieSize
originalPhotoOffsetSeconds
originalTimeForScaledTime:
otherFacesOnAssetWithFace:options:
output
outputBeforeFc
outputBeforeSpatiialPooling
outputBeforeTemporalPooling
outputBlob
outputBlobs
outputDescriptionsByName
outputFeatureName
outputFrameDurValue
outputRes4
outputScaling
outputSize
overallFaceQualityScore
pairWithFace:andFace:distance:
parseFlowCacheVersion
parseHeader:startColumn:analysis:
parseHeatmap2Keypoints:
parsePersons:width:height:
parseResults:observations:
parseResults:toDetections:atTime:fromTime:addActiveRegions:
parseResults:typeColumn:dataColumn:results:
parseWithVisualQuery:cachedResults:completion:
path
pathExtension
pathForResource:ofType:
peak
penaltyScore
performCancellableChangesAndWait:error:
performChanges:completionHandler:
performChangesAndWait:error:
performInPlace
performMetadataAnalysisOnAsset:withCancelBlock:
performPersonBuildingWithCancelOrExtendTimeoutBlock:error:
performRequests:error:
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
performSocialGroupsIdentifiersWithPersonClusterManager:forPersons:overTheYearsComputation:updateBlock:
persistChangesToAlgorithmicFaceGroups:faceCSNByLocalIdentifierForNewlyClusteredFaces:faceCSNsOfUnclusteredFaces:localIdentifiersOfUnclusteredFaces:persistenceCompletionBlock:canceler:error:
persistChangesToAlgorithmicFaceGroups:l1ClustersByFaceCSNRepresentingFaceGroup:l0ClustersByFaceCSNRepresentingFaceGroup:faceCSNByLocalIdentifierForNewlyClusteredFaces:faceCSNsOfUnclusteredFaces:localIdentifiersOfUnclusteredFaces:persistenceCompletionBlock:cancelOrExtendTimeoutBlock:error:
persistFaces:deleteFaces:forAsset:persistedFaces:error:
persistGeneratedFaceCrops:error:
persistModel:toPath:error:
persistOCRMRC
persistPetsModel:toPath:error:
persistenceDelegate_enumerateInChunksOfSize:withOverageAllowance:usingBlock:
persistentDomainForName:
person1LocalIdentifier
person2LocalIdentifier
personBuilderMergeCandidatesDisabled
personBuildingDisabled
personDetection:personRegions:cancel:
personID
personIdentificationForSyndicationPhotoLibrary:withCancelOrExtendTimeoutBlock:
personIdentityModel
personLocalIdentifier
personLocalIdentifiers
personModelFilepathForPhotoLibrary:
personPromoterStatusWithContext:reply:
personVIPModelFileName
petClassificationThreshold
petVIPModelFileName
petsDetection:petsRegions:petsFaceRegions:cancel:
petsDetections
phFaceFromVCPPhotosFace:withFetchOptions:
phFacesFromVCPPhotosFaces:withFetchOptions:
photoIrisProperties
photoIrisStillDisplayTime
photoLibrary
photoLibraryDidBecomeUnavailable:
photoOffsetSeconds
photosFaceRepresentationBlurScore
photosFaceRepresentationClusterSequenceNumber
photosFaceRepresentationHasSmile
photosFaceRepresentationIsLeftEyeClosed
photosFaceRepresentationIsRightEyeClosed
photosFaceRepresentationLocalIdentifier
photosFaceRepresentationQualityMeasure
photosFaceRepresentationRoll
photosFaceRepresentationSize
photosFaceRepresentationSourceHeight
photosFaceRepresentationSourceWidth
pickHighlightsFrom:
pickKeyFramesInRange:
pixelBuffer
pixelBuffer:width:height:
pixelBufferWithFormat:andMaxDimension:fromData:withUniformTypeIdentifier:flushCache:orientation:
pixelBufferWithFormat:andMaxDimension:fromImageURL:
pixelBufferWithFormat:andMaxDimension:fromImageURL:flushCache:orientation:
pixelBufferWithFormat:fromImageURL:flushCache:
pixelBufferWithFormat:fromImageURL:flushCache:orientation:
pixelHeight
pixelWidth
pixelsHigh
pixelsWide
placeholderForCreatedFace
placeholderForCreatedFaceGroup
planDestroy
playbackCrop
pleasantCameraTiltScore
pleasantCompositionScore
pleasantLightingScore
pleasantPatternScore
pleasantPerspectiveScore
pleasantPostProcessingScore
pleasantReflectionsScore
pleasantSymmetryScore
plistRepresentation
pointFromNormalizedPoint:inBounds:
pointValue
poolingBlockWithPoolX:poolY:chunk:
pose
poseType
position
postProcBoxes:maxNumRegions:
postProcess
postProcessAutoPlayable:
postProcessKeyFrames
postProcessMLHighlightScore
postProcessMovieHighlight:
postProcessMovieHighlightDuration:withOptions:
postProcessOrientationResults
postProcessSegmentsWithCaptureTime:trimStart:
preProcessQualityResults:interestingnessResults:obstructionResults:classificationResults:fineActionResults:faceResults:sceneSwitchFrequency:
preProcessing:
preWarmWidth:andHeight:
precisionPerCluster
predicate
predicateWithBlock:
predicateWithFormat:
predictPersonFromFaceObservation:limit:canceller:error:
predictionFromFeatures:error:
predictionFromFeatures:options:error:
predictionsFromBatch:options:error:
predictionsFromInputs:options:error:
preferredInputFormat:height:format:
preferredInputSizeWithOptions:error:
preferredLanguages
preferredPixelFormat
preferredResourcesForFaceProcessingWithAsset:
preferredTransform
prepareActivityStats
prepareAnalyzerWithCVPixelBuffer:cancel:
prepareData:
prepareFaceBlurModel:
prepareFrameStats:
prepareImage:
prepareLivePhotoAnalysisByScenes:
prepareModel
prepareModelForSourceWidth:andSourceHeight:
prepareModelInput:
prepareModelInputs:
prepareModelWithConfig:
prepareModelWithFile:engine:config:error:
prepareNetworkFromURL:withInputSize:
preparePostProcessingStatsFromFaceRange:junkResults:
prepareRequiredQualityResult:junkDetectionResult:descriptorResult:faceResult:petsResult:saliencyResult:actionResult:subtleMotionResult:voiceResult:keyFrameResult:sceneResults:humanActionResults:humanPoseResults:cameraMotionResults:orientationResults:mlHighlightScoreResults:mlQualityResults:frameSize:
prepareTrimmingWithTrimStart:andTrimEnd:
prepareVideoAnalysisByScenes:
prepareWithLightweightOption:aspectRatio:forceCPU:sharedModel:flushModel:
prepareWithLightweightOption:aspectRatio:numLevels:startLevel:cancel:
prewarmWithProperties:
prewarmWithWidth:height:
printSegments:
printStats
priorityAnalysis
privateFileURL
privateResults
process:
processAborted
processAsset:
processAsset:onDemandDetection:detectedFaces:detectedPersons:
processAudioSamples:timestamp:
processDirtyFaceCrops:withCancelBlock:andExtendTimeoutBlock:
processExistingAnalyses:
processExistingAnalysisForTimeRange:analysisTypes:
processFrame:withOptions:results:
processFrameMetadata:
processFrameScore:validScore:
processIdentifier
processInfo
processMessageWithOptions:andCompletionHandler:
processMessageWithOptions:andReply:
processMetaTrackForType:cancel:flags:
processMetadataGroup:flags:
processName
processPersons:humanBounds:dominantPersonIdx:frame:timestamp:duration:
processPersons:width:height:
processResults:withReply:
processSampleBuffer:
processSampleBuffer:error:
processSampleBuffer:withEndTime:error:
processSampleBuffer:withOptions:error:
processTile:results:cancel:
processVideoFragmentAssetData:withOptions:andErrorHandler:
processVideoFragmentAssetData:withOptions:andReply:
processWithFilterScaleIdx:orientIdx:srcImage:outImage:width:height:
processingDevice
processingMode
processingVersion
progressWithTotalUnitCount:
progressWithTotalUnitCount:parent:pendingUnitCount:
project3Dto2D:intrinsinc:extrinsic:numVert:out2dpts:
projectAndUpdateBoundary
promoteUnverifiedPersonsWithUpdateBlock:
propertyListWithData:options:format:error:
pruneRegions:
pruneRegions:withOverlapRatio:
publicResults
purge
purgeAllResources
purgeInactiveResources
pv_addMergeCandidatePersons:
pv_faceProcessingProgress
pv_fetchAssetsForFaceGroup:
pv_fetchAssetsForFaceLocalIdentifiers:
pv_fetchAssetsForPerson:
pv_fetchAssetsInMoment:
pv_fetchAssetsWithLocalIdentifiers:
pv_fetchCandidatePersonsForPerson:
pv_fetchFaceGroups
pv_fetchFaceGroupsForPerson:
pv_fetchFacesForFaceGroup:
pv_fetchFacesForPerson:
pv_fetchFacesForPerson:inMoment:
pv_fetchFacesForPersonLocalIdentifiers:inMoment:
pv_fetchFacesGroupedByAssetLocalIdentifierForAssets:
pv_fetchFacesWithLocalIdentifiers:
pv_fetchInvalidAssetIdentifiersForCommonComparison
pv_fetchInvalidCandidatePersonsForPerson:
pv_fetchMomentsForAssetsWithLocalIdentifiers:
pv_fetchMomentsForPerson:
pv_fetchMomentsWithLocalIdentifiers:
pv_fetchPersonsGroupedByAssetLocalIdentifierForAssets:
pv_fetchPersonsInMoment:
pv_fetchPersonsWithLocalIdentifiers:
pv_fetchPersonsWithType:
pv_lastAssetDate
pv_numberOfFacesWithFaceprints
pv_persistentStorageDirectoryURL
quadratureTolerance
qualityMeasure
qualityMeasureForFace:countOfFacesOnAsset:
qualityMeasureWithCountOfFacesOnAsset:
qualityScore
qualityScoreForLivePhoto
qualityScoreForTimerange:
quarantineTwinsOnAssetEnabled
queryAnalysesForAssets:withTypes:
queryAnalysisForAsset:
queryAnalysisForAsset:withTypes:
queryAnalysisPropertiesForAsset:
queryAnalysisPropertiesForAssets:
queryAssetsAnalyzedSince:
queryAutoCounterOptInStatus:withPhotoLibraryURL:personLocalIdentifiers:andReply:
queryAutoCounterOptInStatusForPhotoLibraryURL:withPersonLocalIdentifiers:completionHandler:
queryBlacklistedLocalIdentifiers
queryCachedFaceAnalysisProgress:forPhotoLibrary:
queryCachedFaceAnalysisProgress:forPhotoLibrary:withExtendTimeoutBlock:
queryFailedProcessingStatusFromAssets:forTaskID:
queryHeaderForAsset:analysis:assetId:
queryHeadersForAssets:analyses:idMap:
queryLocalIdentifiersForTaskID:withStatus:
queryMetaDataSync
queryPerformanceMeasurementsWithReply:
queryProgress:forPhotoLibrary:andTaskID:
queryProgressDetail:forPhotoLibrary:andTaskID:
queryProgressDetail:forPhotoLibrary:andTaskID:withExtendTimeoutBlock:
queryProgressDetail:forPhotoLibraryURL:andTaskID:
queryProgressDetail:forPhotoLibraryURL:andTaskID:withExtendTimeoutBlock:
queryResultsForAssetId:analysis:
queryResultsForAssetId:withTypes:analysis:
queryResultsForAssets:withTypes:batchResults:
querySchedulingHistoryRecords:forActivityID:sinceDate:
queryTerm
queryWithPixelBuffer:orientation:imageRegions:textBlockAnnotation:queryContext:payload:
queryWithPixelBuffer:orientation:normalizedRegionOfInterest:annotation:queryContext:
quickAnalyzeAsset:results:
quickClassificationFaceAdjustmentVersion
raise
rampDown
rampUp
randInit
rangeOfCharacterFromSet:options:
reInitModel
readFrom:
readFromDisk:quantFactor:
readGyroHomographyDimension:
readSoftwareStackVersion:
readWeightsBias:weights:bias:inputDim:outputDim:quantFactor:
ready
reallocGPUTemporalBuffers
reason
rebuildPersonsWithContext:reply:extendTimeout:cancel:
recallPerPersonExcludeMissDetection
recallPerPersonToGroundTruth
recipeBlob
reclusterFacesWithContext:reply:extendTimeout:cancel:
reclusterFacesWithThreshold:shouldRecluster:error:
recordNeedToPersonBuildOnFaceGroupContainingFace:error:
rectFromMappingNormalizedRect:toBounds:
rectFromMappingNormalizedRect:toBoundsOfSize:
rectValue
reestimateProjectionMatrixPnP
referenceSoftwareStackVersion
referralURL
refineAnalysis:requestHandler:forAsset:orientedWidth:orientedHeight:
refinedRegions
regionOfInterest
regionOfInterestResults
regionsOfInterest
registerAvailabilityObserver:
registerClient:forPhotoLibraryURL:withReply:
relativeActionScore
relativeScore
releaseCachedResources
releaseFeatureBuffers
releaseInputAndOutputBuffers
releaseMemory
remoteObjectProxyWithErrorHandler:
removeAllObjects
removeAutoAssignedFacesFromVerifiedPersonsAndPrepareForPersonBuilding:cancelOrExtendTimeoutBlock:error:
removeClusteringStateCacheWithURL:error:
removeFaces:
removeIndex:
removeItemAtPath:error:
removeItemAtURL:error:
removeLastObject
removeMergeCandidatePersons:
removeObject:
removeObjectAtIndex:
removeObjectForKey:
removeObjectsAtIndexes:
removeObjectsForKeys:
removeObjectsInArray:
removeRequest:error:
removeSmallestKeyFace
removeTrack:
replaceCoordinatesAndFeaturesFromDetectedFace:
replaceObjectAtIndex:withObject:
replaceRegion:mipmapLevel:slice:withBytes:bytesPerRow:bytesPerImage:
reportIdentifier
reportLivePhotoKeyFrameAnalysisResults:selectedKeyFrame:originalStillKeyFrame:stillScore:stillFQScore:stillTimestamp:useSemanticOnly:isKeyFrameSuggested:
reportMovieCurationAnalysisResults:withSummaryAnalytics:
reportProgress:forRequest:
reportProgressForPhotoLibrary:taskID:logMessage:withExtendTimeoutBlock:
representativenessForFaces:error:
request:didFailWithError:
request:didProduceResult:
requestAnalysesForAssets:analysisTypes:allowOndemand:progressHandler:completionHandler:
requestAnalysis:forAsset:andDatabase:error:
requestAnalysis:forAssets:withOptions:andProgressHandler:andCompletionHandler:
requestAnalysis:forAssets:withOptions:andProgressHandler:andError:
requestAnalysis:ofAssetData:withProperties:progressHandler:andCompletionHandler:
requestAnalysis:ofAssetSurface:withProperties:progressHandler:andCompletionHandler:
requestAnalysis:ofFragmentData:withRequestID:properties:andReply:
requestAnalysis:ofFragmentSurface:withRequestID:properties:andReply:
requestAnalysis:ofIOSurface:withProperties:withReply:
requestAnalysis:ofPixelBuffer:withProperties:withCompletionHandler:
requestAnalysisForAsset:analysisTypes:progressHandler:completionHandler:
requestAnalysisTypes:forAssetWithResourceURLs:withOptions:error:
requestAnalysisTypes:forAssetWithResourceURLs:withOptions:progressHandler:andCompletionHandler:
requestAnalysisTypes:forAssets:allowOndemand:progressHandler:error:
requestAnalysisTypes:forAssets:withOptions:andProgressHandler:cancelBlock:analyses:
requestAnalysisTypes:forAssets:withOptions:progressHandler:andCompletionHandler:
requestAssetAnalysis:forLocalIdentifiers:fromPhotoLibraryWithURL:withOptions:analysisTypes:withReply:
requestAssetAnalysis:forPhotoLibraryURL:withLocalIdentifiers:realTime:withReply:
requestAssetProcessing:withTaskID:forLocalIdentifiers:fromPhotoLibraryWithURL:withOptions:andReply:
requestAutoCounterAccuracyCalculation:withPhotoLibraryURL:andReply:
requestAutoCounterAccuracyCalculation:withPhotoLibraryURL:clusterStateURL:groundTruthURL:andReply:
requestAutoCounterAccuracyCalculationForPhotoLibraryURL:clusterStateURL:groundTruthURL:completionHandler:
requestAutoCounterAccuracyCalculationForPhotoLibraryURL:completionHandler:
requestAutoCounterSIMLValidation:withPhotoLibraryURL:simlGroundTruthURL:andReply:
requestAutoCounterSIMLValidationForPhotoLibraryURL:simlGroundTruthURL:completionHandler:
requestBackgroundAnalysisForAssets:fromPhotoLibraryWithURL:realTime:progessHandler:completionHandler:
requestBackgroundAnalysisForAssets:realTime:progessHandler:completionHandler:
requestBackgroundProcessingWithTaskID:forPhotoLibrary:progessHandler:completionHandler:
requestClusterCacheValidation:withPhotoLibraryURL:andReply:
requestClusterCacheValidationWithPhotoLibraryURL:progressHandler:completionHandler:
requestDataForAssetResource:options:dataReceivedHandler:completionHandler:
requestDidComplete:
requestDownloadOfResource:
requestDumpAutoCounter:withPhotoLibraryURL:andReply:
requestDumpAutoCounterForPhotoLibraryURL:completionHandler:
requestFaceCandidatesforKeyFace:withPersonsWithLocalIdentifiers:andPhotoLibraryURL:andReply:
requestFaceCandidatesforKeyFaceForPersonsWithLocalIdentifiers:photoLibraryURL:progessHandler:completionHandler:
requestFaceProcessingForAssets:withOptions:progressHandler:andCompletionHandler:
requestFaceProcessingForPhotoLibrary:withOptions:progressHandler:andCompletionHandler:
requestFileURLForAssetResource:options:urlReceivedHandler:completionHandler:
requestFullProcessingForPhotoLibrary:withOptions:progressHandler:andCompletionHandler:
requestHandler
requestId
requestIdentification:forFaceCrop:withOptions:andReply:
requestIdentificationForFaceCrop:withOptions:andCompletionHandler:
requestIdentificationOfFaces:withCompletionHandler:
requestIdentificationOfFacesWithLocalIdentifiers:fromPhotoLibraryWithURL:withRequestID:andReply:
requestImageProcessing:forAssetURL:withSandboxToken:identifier:requestID:andReply:
requestImageProcessing:forAssetWithCloudIdentifier:requestID:andReply:
requestImageProcessing:forAssetWithIdentifier:identifierType:fromPhotoLibraryWithURL:requestID:andReply:
requestImageProcessing:forIOSurface:withOrientation:assetLocalIdentifier:photoLibraryURL:requestID:andReply:
requestImageProcessing:forIOSurface:withOrientation:identifier:requestID:andReply:
requestImageProcessing:forImageData:withUniformTypeIdentifier:identifier:requestID:andReply:
requestImageProcessingWithCloudIdentifierRequests:requestID:andReply:
requestLibraryProcessing:withTaskID:forPhotoLibraryURL:withOptions:andReply:
requestLivePhotoEffectsForAssets:allowOnDemand:flags:
requestLivePhotoEffectsForAssets:withOptions:progressHandler:andCompletionHandler:
requestMediaAnalysisDatabaseAccessSandboxExtensionWithPhotoLibraryURL:andReply:
requestMovieHighlightsForAssets:withOptions:
requestMultiWorkerProcessingForPhotoLibrary:withOptions:progressHandler:andCompletionHandler:
requestOptInAutoCounter:withPhotoLibraryURL:persons:andReply:
requestOptInAutoCounterForPhotoLibraryURL:withPersons:completionHandler:
requestPersonPreferenceForPhotoLibraryURL:andReply:
requestPersonPreferenceForPhotoLibraryURL:completionHandler:
requestPersonProcessingForPhotoLibraryURL:options:progressHandler:completionHandler:
requestPersonPromoterStatus:withAdvancedFlag:andPhotoLibraryURL:andReply:
requestPersonPromoterStatusWithAdvancedFlag:photoLibraryURL:progressHandler:completionHandler:
requestProcessingTypes:forAssetsWithLocalIdentifiers:fromPhotoLibraryWithURL:progressHandler:completionHandler:
requestProcessingTypes:forAssetsWithLocalIdentifiers:fromPhotoLibraryWithURL:withRequestID:andReply:
requestProcessingWithTaskID:forAssets:withOptions:progressHandler:andCompletionHandler:
requestProcessingWithTaskID:forPhotoLibrary:withOptions:progessHandler:andCompletionHandler:
requestQuickFaceIdentificationForPhotoLibraryURL:withOptions:andCompletionHandler:
requestRebuildPersons:withLocalIdentifiers:andPhotoLibraryURL:andReply:
requestRebuildPersonsWithLocalIdentifiers:photoLibraryURL:progressHandler:completionHandler:
requestReclusterFaces:withPhotoLibraryURL:andReply:
requestReclusterFacesWithPhotoLibraryURL:progressHandler:completionHandler:
requestResetFaceClassificationModel:withPhotoLibraryURL:andReply:
requestResetFaceClassificationModelForPhotoLibraryURL:progressHandler:completionHandler:
requestResetFaceClusteringState:withPhotoLibraryURL:andReply:
requestResetFaceClusteringStateWithPhotoLibraryURL:progressHandler:completionHandler:
requestResetPetClassificationModel:withPhotoLibraryURL:andReply:
requestResetPetClassificationModelForPhotoLibraryURL:progressHandler:completionHandler:
requestResidentMaintenance:withOptions:andReply:
requestResidentMaintenanceWithOptions:andCompletionHandler:
requestSceneProcessingForAssets:withOptions:progressHandler:andCompletionHandler:
requestSceneProcessingForPhotoLibrary:withOptions:progressHandler:andCompletionHandler:
requestSceneprintProcessingForAssets:withOptions:progressHandler:andCompletionHandler:
requestSuggestedMePersonIdentifier:withContext:andPhotoLibraryURL:andReply:
requestSuggestedMePersonIdentifierAtURL:withError:
requestSuggestedMePersonIdentifierWithContext:photoLibraryURL:progressHandler:completionHandler:
requestSuggestedMePersonIdentifierWithContext:reply:
requestSuggestedPersons:withPersonWithLocalIdentifier:toBeConfirmedPersonSuggestions:toBeRejectedPersonSuggestions:andPhotoLibraryURL:andReply:
requestSuggestedPersonsForPersonWithLocalIdentifier:toBeConfirmedPersonSuggestions:toBeRejectedPersonSuggestions:photoLibraryURL:progessHandler:completionHandler:
requestSuggestionsForFaceClusterSequenceNumbers:withClusteringFlags:updateHandler:error:
requestURLAssetAnalysis:forAssetWithResourcePaths:withOptions:analysisTypes:sandboxTokens:withReply:
requestUpdateKeyFacesOfPersons:withLocalIdentifiers:andForceUpdate:andPhotoLibraryURL:andReply:
requestUpdateKeyFacesOfPersonsWithLocalIdentifiers:forceUpdate:photoLibraryURL:progessHandler:completionHandler:
requestVIPModelFilepathForPhotoLibraryURL:forModelType:completionHandler:
requestVIPModelStorageFilepathForPhotoLibraryURL:forModelType:andReply:
requestVideoStabilizationForAssets:withOptions:progressHandler:andCompletionHandler:
requestWallpaperUpgrade:atSourceURL:toDestinationURL:withOptions:sandboxTokens:andReply:
requestWithFaceClusterIds:clusterFlags:updateHandler:
requiredInputFormat:height:format:
resConfig
reserveBudget:
reset
resetActivityStatsAtTime:
resetAnalysisDataWithResetLevel:error:
resetBytesInRange:
resetFaceAnalysisWithResetLevel:completionHandler:
resetFaceClusteringState:
resetFaceClusteringStateWithContext:reply:
resetIdentityAndExpressions
resetInterruption
resetLevelDescription:
resetLibraryClustersWithCancelOrExtendTimeoutBlock:error:
resetLibraryClustersWithCanceler:error:
resetPerformanceMeasurements
resetPersonsModelWithReply:
resetPetsModelWithReply:
resetSegment:
resetSegment:atTime:
resetSharedInstanceWithIdentifier:
resetStatsFlag
resignCurrent
resize:height:
resolution
resource
resourceData
resourceForFaceProcessing:allowStreaming:
resourceForFaceProcessingWithAsset:allowStreaming:
resourceLoader
resourceLoader:didCancelAuthenticationChallenge:
resourceLoader:didCancelLoadingRequest:
resourceLoader:shouldWaitForLoadingOfRequestedResource:
resourceLoader:shouldWaitForRenewalOfRequestedResource:
resourceLoader:shouldWaitForResponseToAuthenticationChallenge:
resourceRequirement
resourceURL
resources
respondWithData:
respondsToSelector:
restoreClusterCacheAndSyncWithLibrary:cancelOrExtendTimeoutBlock:error:
resultFromLegacyDictionary:
resultItems
resultsAsArray
resultsAsSet
resume
retain
retainCount
retrieveBoxes:outHeight:outWidth:boxes:anchorBox:
returnMask
returnObject:
reverseObjectEnumerator
reviseFrameTrackScore:saliencyRegions:
revision
rightEyeClosed
roll
rotateLandmarks:width:height:landmarks:numLandmarks:
rotateTransform:byAngle:
rotationToEulerAngles:angles:
run:
run:withPersons:andRegionCrop:atTime:andDuration:
runTasks:duration:persons:regionCrop:
saliencyDetection:salientRegions:cancel:
saliencyObjectnessRequest
salientObjects
salientRegionsFromPixelBuffer:
saveKeypoints
saveStabilizationRecipe
scaleBasedOnFaceForTimeRange:
scaleFlowTo:
scaleForTimeRange:basedOnFace:
scaleImage:toData:withWidth:andHeight:
scalePixelBuffer:toPixelBuffer:width:height:
scaleRect:scaleX:scaleY:
scaleRegion:ofImage:toData:withWidth:andHeight:
scaleTimeRange:toDuration:
scaledTimeForOriginalTime:
sceneAnalysisProperties
sceneAnalysisTimestamp
sceneAnalysisVersion
sceneClassId
sceneClassifications
sceneResults
scenenetClassifications
sceneprint
sceneprintBlob
sceneprintDistanceToPreviousScene
sceneprintProperties
sceneprintRawRequest
sceneprintRequest
sceneprints
scenes
scheduleClusteringAfterRemovingFaceCSNs:addingFaceIdStrs:
scheduleClusteringOfFacesWithLocalIdentifiers:
scheduleUnclusteringOfFacesWithClusterSequenceNumbers:
score
sdof
sdofImageAssetWithURL:
searchFeatureVectorOfSegment:
searchSections
searchVanishingPointandDominantLine:lineGroup:vanishingPoint:vanishingPointConfidence:dominantLine:
searchWithParsedVisualQuery:completion:
searchWithVisualQuery:completion:
sections
seedAnalyzersWithPixelBuffer:startTime:
segments
selectHighlights
selectHighlightsForTimelapse
selectKeyFrameRangeWithMotion:stillTimestamp:isMetaMotion:
selectRepresentativeFromFaces:qualityMeasureByLocalIdentifier:representativenessByCSN:candidateFaces:
self
semanticScore
sendEvent:withAnalytics:
sendSessionEvent:
serialQueue_
serialize
serializeStateAndReturnError:
sessionWithProperties:andResultsHandler:
sessionWithProperties:withResultsHandler:andInterruptionHandler:
setAbsMotion:
setAbsoluteActionScore:
setAbsoluteScore:
setActivityID:
setActivityLevel:
setActivityScore:
setAdjustmentVersion:
setAdjustmentsRequest:
setAdvancedStatusMergeCandidateLimit:
setAdvancedStatusVerifiedPersonLimit:
setAestheticsRequest:
setAgeType:
setAlgorithmVersion:
setAllowStreaming:
setAllowsCellularAccess:
setAnalysisConfidence:
setAnalysisResultRef:
setAngle:
setAppliesPreferredTrackTransform:
setAssetAdjustedFingerprint:
setAssetIdentifier:
setAssetMasterFingerprint:
setAssetModificationDate:
setAttributesFromLegacyDictionary:
setAutoPlayable:
setAutoloop:
setAutoplayScore:
setAverageScore:
setBarcodeObservations:
setBestPlaybackCrop:
setBlurAnalyzerFaceResults:
setBlurDeterminationMethod:
setBlurScore:
setBodyHeight:
setBodyWidth:
setBounce:
setBound:
setBounds:
setBuffer:offset:atIndex:
setByteRangeAccessSupported:
setCachedImageHandler:
setCachedParseData:
setCachedParseData:overwriteExisting:
setCameraIntrinsics:uc:vc:
setCameraMotionScore:
setCancel:
setCancelled:
setCenterAndSizeFromNormalizedFaceRect:
setCenterX:
setCenterY:
setCharacterRecognitionData:machineReadableCodeData:algorithmVersion:adjustmentVersion:
setChirality:
setChunkSizeForFetch:
setCityNatureRequest:
setClassIndex:
setClasses:forSelector:argumentIndex:ofReply:
setClassificationRequest:
setClassifications:
setClusterIncludeTorsoOnlyFaces:
setClusterSequenceNumber:
setClustererBringUpState:
setColorNormalization:
setColorNormalizationBlob:
setColorfulnessScore:
setCommandBuffer:
setCommandQueue:
setComputePipelineState:
setConfidence:
setContentLength:
setContentScore:
setContext:
setCorrectionResultRef:
setCount:
setCropFraction:
setCropRectHeight:
setCropRectWidth:
setCropRectX:
setCropRectY:
setCropResult:
setCurationScore:
setData:
setDate:
setDateFormat:
setDelegate:queue:
setDescriptor:
setDetectedFaces:
setDetectionLevel:
setDetectionModeCounterShapeModel:
setDetectionType:
setDevice:
setDiscretionary:
setDistanceToPreviousScene:
setDocumentObservations:
setDocumentRequest:
setDominantLine:
setDownloadIntent:
setDownloadIsTransient:
setDownloadPriority:
setDuration:
setEnergy:
setEpoch:
setError:
setErrorCode:
setEthnicityType:
setExcludeMontageAssets:
setExecutionNanoseconds:
setExitStatus:
setExportedInterface:
setExportedObject:
setExposure:
setExposureChangeScore:
setExposureScore:
setExpressionChangeScore:
setExpressionScore:
setExpressionType:
setEyeExpression:
setEyesState:
setFace:
setFaceAdjustmentVersion:
setFaceAlgorithmVersion:
setFaceArea:
setFaceBounds:
setFaceClusteringAgeThreshold:
setFaceClusteringDisabled:
setFaceClusteringThreshold:
setFaceDominated:
setFaceExpressionType:
setFaceID:
setFaceId:
setFaceMergeFaceprintDistanceThreshold:
setFacePrimarySuggestionsThreshold:
setFaceQualityScores:
setFaceSharpness:
setFaceTorsoprint:
setFaceprint:
setFaceprintBlob:
setFacialHairType:
setFeatureShape:height:width:level:
setFetchLimit:
setFetchPropertySets:
setFlag:
setFlags:
setFlickerScore:
setForceFaceprintCreation:
setFrame:
setFrameExpressionScore:
setFrameInstructions:
setFrameProcessedByFaceDetector:
setFrameProcessedByHumanAnalyzer:
setFrameProcessedByPetsActionAnalyzer:
setFrameProcessedByVideoAnalyzer:
setFrameResults:
setGazeType:
setGenerateOutput:
setGlobalQualityScore:
setGroupingIdentifier:
setGyroSharpnessParam:homographyResults:livePhotoStillDisplayTime:imageExposureTime:
setGyroStabilization:
setHadZoom:
setHairColorType:
setHairType:
setHandID:
setHasAction:
setHasContentScore:
setHasDistanceToPreviousScene:
setHasEpoch:
setHasFaceQuality:
setHasFaceSharpness:
setHasFlags:
setHasFlash:
setHasFlickerScore:
setHasGlobalQualityScore:
setHasLoopFadeLen:
setHasLoopPeriod:
setHasLoopStart:
setHasQuality:
setHasSceneprintDistanceToPreviousScene:
setHasSmile:
setHasStatsFlags:
setHasTypesWide:
setHasUnderExpose:
setHeadgearType:
setHeight:
setHidden:
setHighlightScore:
setHomographyParams:count:
setHumanActionScore:
setHumanPoseScore:
setHumanScore:
setIdentifier:
setImageBlurResults:
setImageCompositionResults:
setImageExposureResults:
setImageFaceResults:
setImageFeatureResults:
setImageHumanPoseResults:
setImageJunkResults:
setImagePetsFaceResults:
setImagePetsResults:
setImageSaliencyResults:
setImageSceneprintResults:
setImageShotTypeResults:
setImagefingerprintsRequest:
setImageprintWrapper:
setInTrash:
setIncludeAllBurstAssets:
setIncludeAssetSourceTypes:
setIncludeGuestAssets:
setIncludeHiddenAssets:
setIncludeNonvisibleFaces:
setIncludeOnlyFacesInFaceGroups:
setIncludeOnlyFacesWithFaceprints:
setIncludeTorsoOnlyDetectionData:
setIncludeTorsoOnlyPerson:
setIncludeTrashedAssets:
setIncludedDetectionTypes:
setInput:
setInputBlob:
setInputBlobs:
setInputBoundsHeight:
setInputBoundsWidth:
setInputBoundsX:
setInputBoundsY:
setInputFaceObservations:
setInputImage:
setInputImageWithURL:error:
setInputSignatureprint:
setInputSize:
setInterestScore:
setInterestingnessScore:
setInternalPredicate:
setInternalSortDescriptors:
setInterruptionHandler:
setInvalidationHandler:
setIsAutoPlayable:
setIsCloseup:
setIsFast:
setIsHeadingFrame:
setIsInTrash:
setIsInVIPModel:
setIsInputOutput:
setIsLeftEyeClosed:
setIsRightEyeClosed:
setIsSettlingOK:
setIsTooSmall:
setIsTrimmed:
setIsVerified:
setJunkImageRequest:
setJunkScore:
setKeyFace:
setKeyFace:forCluster:
setKeyFrame:
setKeypoints:
setLandmarkRequest:
setLast:
setLastMinimumFaceGroupSizeForCreatingMergeCandidate:
setLeftEyeClosed:
setLivePhotoEffectsResults:
setLivePhotoHumanActionClassificationResults:
setLivePhotoKeyFrameResults:
setLivePhotoKeyFrameStillResults:
setLivePhotoRecommendationResults:
setLivePhotoSharpnessResults:
setLocale:
setLocation:
setLongexposure:
setLoopPeriod:
setLoopStart:
setLoopSuggestionState:
setLostTrackInd:
setManual:
setMaskOnly:
setMaxFaceCountForClustering:
setMaxHighlightDuration:
setMaxX:
setMaxY:
setMaxZoom:
setMaximumAspectRatio:
setMaximumCandidateCount:
setMaximumHierarchicalObservations:
setMaximumIdentities:
setMaximumIntermediateSideLength:
setMaximumLeafObservations:
setMaximumObservations:
setMaximumTrainingFaceprintsPerIdentity:
setMetalContextPriority:
setMinFaceCountToTriggerClustering:
setMinVersion:
setMinX:
setMinY:
setMinZoom:
setMinimumAspectRatio:
setMinimumConfidence:
setMinimumFaceGroupSizeForCreatingMergeCandidates:
setMinimumSuggestionSize:
setMinimumUnverifiedFaceCount:
setMinimumVerifiedFaceCount:
setMotionBlurVector:
setMotionParamDiff:
setMotionStatsFlag:cameraMotion:subjectAction:interestingness:obstruction:colorfulness:exposureScore:humanActionStatsFlag:humanPoseScore:humanActionScore:subMb:
setMotionType:
setMouthExpression:
setMovieActivityLevelResults:
setMovieApplauseResults:
setMovieAudioQualityResults:
setMovieBabbleResults:
setMovieCameraMotionResults:
setMovieCheeringResults:
setMovieClassificationResults:
setMovieFaceResults:
setMovieFaceprintResults:
setMovieFeatureResults:
setMovieFineSubjectMotionResults:
setMovieHighlightResults:
setMovieHighlightScoreResults:
setMovieHumanActionResults:
setMovieHumanPoseResults:
setMovieLaughterResults:
setMovieLoudnessResults:
setMovieMovingObjectResults:
setMovieMusicResults:
setMovieObstructionResults:
setMovieOrientationResults:
setMoviePetsFaceResults:
setMoviePetsResults:
setMoviePreEncodeResults:
setMovieQualityResults:
setMovieSaliencyResults:
setMovieSceneResults:
setMovieSceneprintResults:
setMovieStabilizationResults:
setMovieSubjectMotionResults:
setMovieSubtleMotionResults:
setMovieSummaryResults:
setMovieUtteranceResults:
setMovieVoiceResults:
setNameSource:
setNetworkAccessAllowed:
setNextCaptureFrame:
setNumSingletons:
setNumValidSingletons:
setObject:atIndexedSubscript:
setObject:forKey:
setObject:forKeyedSubscript:
setObjectRequest:
setObstructionScore:
setOutput:
setOutputBlob:
setOutputFrameDurValue:
setOutputSize:
setOverallFaceQualityScore:
setPeak:
setPenaltyScore:
setPerformInPlace:
setPersonBuilderMergeCandidatesDisabled:
setPersonBuilderMergeCandidatesEnabled:
setPersonBuilderState:
setPersonBuildingDisabled:
setPersonContext:
setPersonID:
setPersonId:
setPersonLocalIdentifier:
setPetsActionScore:
setPetsDetections:
setPhotoLibrary:
setPlaybackCrop:
setPose:
setPoseType:
setPoseYaw:
setPosition:
setPrecisionPerCluster:
setPrecisionRecallThreshold:
setPredicate:
setPreferBackgroundProcessing:
setPreferredMetalDevice:
setProcessed:forLibrary:
setProcessingDevice:
setProcessingMode:
setProcessingVersion:
setProgressHandler:
setPruneAfterAvailableOnLowDisk:
setQuadratureTolerance:
setQuality:
setQualityMeasure:
setQualityScore:
setQualityScoreForLivePhoto:
setQuarantineTwinsOnAssetEnabled:
setReadOnly:
setRecallPerPersonExcludeMissDetection:
setRecallPerPersonToGroundTruth:
setRecipeBlob:
setRecognitionLanguages:
setRecognize:
setRegionOfInterest:
setRelativeActionScore:
setRelativeScore:
setRemoteObjectInterface:
setRequestedTimeToleranceBefore:
setResource:
setResults:
setResults:withClass:forPropertyKey:
setReturnAllResults:
setReturnMask:
setRevision:
setRevision:error:
setRightEyeClosed:
setRoll:
setSaliencyObjectnessRequest:
setSaliencyRequest:
setSceneId:
setSceneResults:
setSceneprintBlob:
setSceneprintDistanceToPreviousScene:
setSceneprintRawRequest:
setSceneprintRequest:
setScore:
setSdof:
setSemanticRequest:
setSemanticScore:
setSexType:
setSharpness:
setShotType:
setShouldPrefetchCount:
setSignpostPayload:
setSize:
setSkintoneType:
setSmile:
setSmileType:
setSortDescriptors:
setSourceHeight:
setSourceSizeHeight:
setSourceSizeWidth:
setStabilityScore:
setStabilize:
setStabilizeResult:
setStableInd:
setStart:
setStartTime:
setState:
setStatisticsBlob:
setStatsFlags:
setStillTime:
setSubMbMotionAvailable:
setSubjectActionScore:
setSubjectScore:
setSuggestionsLogEnabled:
setSumConfidence:
setTabooRequest:
setTexture:atIndex:
setTextureScore:
setThirdPartyObject:
setTimeRange:
setTimeScale:
setTimeValue:
setTimeValues:count:
setTimeZone:
setTimeoutIntervalForResource:
setTimerange:
setTimescale:
setTimestamp:
setTorsoprint:
setTrackID:
setTrackingMode:
setTrackingScore:
setTrainingType:
setTypes:
setTypesWide:
setUpdateHandler:
setUsage:
setUseSegmentationPregating:
setUsesLanguageDetection:
setValidStabilization:
setValue:
setValue:forField:andEvent:
setValue:forKey:
setVanishingPoint:
setVerifiedPersonTypes:
setVerifiedType:
setVersion:
setVideoActivityDescriptor:
setVisualPleasingScore:
setVisualSearchData:algorithmVersion:adjustmentVersion:
setVoiceDetections:
setVoiceScore:
setWantsIncrementalChangeDetails:
setWeightedAveragePrecision:
setWeightedAverageRecall:
setWidth:
setWindowDuration:
setWithArray:
setWithCapacity:
setWithObject:
setWithSet:
setX0:
setX:
setY0:
setY:
settings
settlingExposureChangeScore:
settlingMotionScore:
settlingSubjectScore:
setupModel:
setupTrackerWithReferenceFrame:withROI:
setupWithAudioStream:
setupWithSample:andSampleBatchSize:
setupWithSample:andTrackDuration:
setupWithSample:trackDuration:andSampleBatchSize:
sfReportData
sharedAnalysisService
sharedContextPreferred:
sharedContextWithForceCPU:
sharedContextWithMPSGraph:
sharedDatabaseForPhotoLibrary:
sharedDatabaseManager
sharedImageManager
sharedInstance
sharedInstanceWithIdentifier:andCreationBlock:
sharedInstances_
sharedLogManager
sharedManager
sharedManagerForPhotoLibrary:
sharedMediaAnalyzer
sharedModel:
sharedModel:inputNames:
sharedModel:inputNames:properties:
sharedModel:outputNames:properties:
sharedModelPoolWithRevision:
sharedModelStage1:inputNames:properties:
sharedPhotoLibrary
sharedResource
sharplyFocusedSubjectScore
sharpness
sharpnessRevision
shortDescription
shotType
shouldCutAt:stillPTS:withCut:
shouldProcessSampleWithTimeRange:atSamplingInterval:
shouldQueryInternalFields
signalCancellation
size
sizeValue
skintoneType
slomoRange
slowMotionRampOutRangeForExport:
slowMotionRate
slowMotionTimeRange
slowmoRate
smile
smileType
smoothFiltering:width:height:
socialGroupsOverTheYearsWithPersonClusterManager:forPersons:updateBlock:
sortDescriptorWithKey:ascending:
sortUsingComparator:
sortedArrayUsingComparator:
sortedArrayUsingSelector:
sortedViableMergeCandidateFacesFor:from:ignoreSourceAssetDimensions:matchScores:
sourceHeight
sourcePixelBuffer
sourceSizeHeight
sourceWidth
spaceCheck:
spatialDescriptorWithMvMagnitudeMean:
spatialPooling
stabilityScore
stabilize
stable
stableInd
stagedText
standardUserDefaults
start
startCatalogDownload:then:
startDate
startDownload:completionWithError:
startEntryPointWithQueryID:
startReading
startSessionWithProperties:andReply:
startTime
state
statisticsBlob
statsFlags
status
stillTime
stop
storeAnalysis:forAsset:fromPhotoLibraryURL:withReply:
storeAnalytics:isLivePhoto:
storeFrameResults
storeResults:
straightForwardForChunkFour
streamedMovie
string
stringByAppendingFormat:
stringByAppendingString:
stringByDeletingPathExtension
stringByReplacingOccurrencesOfString:withString:options:range:
stringForObjectValue:
stringValue
stringWithFormat:
stringWithString:
stringWithUTF8String:
strongToStrongObjectsMapTable
subMbMotionAvailable
subarrayWithRange:
subjectActionScore
subjectActivityInTimeRange:fromResults:
subjectScore
submitTaskWithOptions:completionHandler:
submitUserFeedback:completion:
substringToIndex:
subtleMotionScore
subtleMotionScoreForTimerange:
suggestPersonsForPersonWithLocalIdentifier:toBeConfirmedPersonSuggestions:toBeRejectedPersonSuggestions:context:reply:cancel:
suggestedFaceClusterSequenceNumbersForFaceClusterSequenceNumbersRepresentingClusters:error:
suggestedMeIdentifierWithPersonClusterManager:forPersons:updateBlock:
suggestedPersonLocalIdentifierForPersonLocalIdentifier:faceClusterer:canceler:context:error:
suggestionsForClustersWithFaceIds:affinityThreshold:canceller:error:
suggestionsForPersonLocalIdentifier:clusterSequenceNumbers:excludePersonLocalIdentifiers:minimumSuggestionFaceCount:
suggestionsLogEnabled
sumConfidence
sumOfScore
superclass
supportGPU
supportVectorForward
supportedImageSizeSet
supportedPrivateRevisions
supportedRevisions
supportsFeatureSet:
supportsSecureCoding
symbologies
synchronousRemoteObjectProxyWithErrorHandler:
systemPhotoLibraryURL
tabooRequest
targetExtendRange:maxRange:
targetMovieHighlight:mergedRange:maxRange:
targetProcessRange:maxRange:
targetTrimRange:searchRange:
taskForURLAsset:withOptions:analysisTypes:progressHandler:completionHandler:
taskID
taskName
taskService
taskWithAsset:andAnalysisTypes:andOptions:andProgressHandler:andCompletionHandler:
taskWithAssets:andOptions:andCompletionHandler:
taskWithAssets:options:andCompletionHandler:
taskWithCloudIdentifierRequests:photoLibrary:clientBundleID:clientTeamID:cancelBlock:andCompletionHandler:
taskWithFaceCrop:andCompletionHandler:
taskWithOptions:andCompletionHandler:
taskWithRequest:imageAsset:andSignpostPayload:
taskWithRequests:forAsset:cancelBlock:andCompletionHandler:
tastefullyBlurredScore
tensorCoeff
terminate
textBlockWithDocumentObservations:
textElements
texture2DDescriptorWithPixelFormat:width:height:mipmapped:
textureScore
textureness
thirdPartyObject
threshold
thumbnailAspectRatio
thumbnailResource
thumbnailSizeForAsset:withResources:
thumbnailURL
time
timeInterval
timeIntervalSinceDate:
timeIntervalSinceReferenceDate
timeRange
timeRangeMapperForSourceDuration:slowMotionRate:slowMotionTimeRange:forExport:
timeRangeValue
timeRangeWithCMTimeRange:
timeScale
timeStamp
timeValue
timeValueAtIndex:
timeValues
timeZoneForSecondsFromGMT:
timelapseRate
timerWithInterval:unit:oneShot:andBlock:
timerWithIntervalSeconds:isOneShot:andBlock:
timerange
timescale
timestamp
title
torsoThreshold
torsoprint
torsoprintRequestRevision
totalExpected
totalWritten
track
trackFaceMesh:
trackInFrame:
trackObjectInFrame:
trackingMode
trackingScore
tracks
tracksWithMediaType:
trainingFaceObservationsForPersonWithUniqueIdentifier:canceller:error:
trainingObservationsForEntityWithUniqueIdentifier:canceller:error:
trainingType
transform
transformForAngle:pixelBuffer:
transformUprightAboutTopLeft:
trimSegment:fromStart:
type
typeWithIdentifier:
types
typesWide
unarchivedObjectOfClass:fromData:error:
unarchivedObjectOfClasses:fromData:error:
unclusteredClusteringEligibleFaceLocalIdentifiers:
underExpose
ungroupFaceClusterSequenceNumbers:batchSizeForUnclusteringFaces:cancelOrExtendTimeoutBlock:error:
ungroupFaceClusterSequenceNumbers:batchSizeForUnclusteringFaces:canceler:error:
uniformTypeIdentifier
unimplementedExceptionForMethodName:
union:
unionSet:
unlock
unsignedIntValue
unsignedIntegerValue
unsignedLongValue
updateActiveThreshold
updateBoundary3dLandmarkBlendshapes:numBlendshapes:pts2D:lm2D:lmBlendshapes:
updateBoundaryLandmarkCoordinates:pts2D:lm2D:lm3dPos:
updateBoundaryLmForShapeOptimization
updateConfidence:prevBound:newBound:width:height:
updateCropHeatMap:withResults:timeRange:resultsKey:
updateCurationThreshold
updateDegradedFlagForMajorDimension:
updateFaceHeatMap:
updateFaceprint:ofPersistedFace:error:
updateFocalLengthInPixels:
updateHandler
updateIdentityShape:
updateIntrinsic:vc:
updateIntrinsicWhenRotated
updateKeyFacesOfPersonsWithLocalIdentifiers:forceUpdate:cancelOrExtendTimeoutBlock:error:
updateKeyFacesOfPersonsWithLocalIdentifiers:forceUpdate:canceler:error:
updateKeyFacesOfPersonsWithLocalIdentifiers:forceUpdate:context:reply:
updateMeshAndLm3dAfterExpressionChange
updateMeshVertices
updateMissingFaceprintForFaces:withAsset:
updateModelByAddingFaces:andRemovingFaces:canceller:error:
updateModelByAddingPersons:withGroupingIdentifiers:andRemovingPersons:canceller:error:
updateModelForAspectRatio:
updateModelForAspectRatio:computationAccuracy:
updateModelWithConfig:error:
updateModelWithResConfig:
updateModulesWithConfig:
updatePreferredTransform:properties:
updateSegment:
updateSegment:atTime:
updateSegment:score:valid:
updateShapeCoeff:extrinsicMatrix:pts2D:exprWeights:outputblendshapes:
updateWithExistingFaces
updateWithFirstFrame:score:valid:
updateWithOptions:error:
upgradeWallPaperAtURL:toURL:cancel:results:
urlForApplicationDataFolderIdentifier:
useCPUOnly
useGPU
usePHAssetData
useSceneprintInSceneAnalysis
userFeedbackPayload
usesCPUOnly
usesLanguageDetection
uuid
uuidFromLocalIdentifier:
validStabilization
validateActivityScores
validateClusterAccuracyWithSIMLGroundtruth:results:extendTimeoutBlock:cancelBlock:
validateClusterCacheWithContext:cancelOrExtendTimeoutBlock:reply:
validateConfiguration:withError:
validateCost:
validateDecodedFrame:withSettings:
validateFace:eulerAngles:
validateOneImage:landmarks:numofLandmarks:score:
validationScoreOfTimeRange:fromResult:startIdx:
value
valueForField:andEvent:
valueForKey:
valueWithBytes:objCType:
valueWithCMTime:
valueWithSize:
vanishingPoint
vcp_PHFaces:
vcp_abnormalImageDimensionForSceneNet
vcp_addEntriesFromResults:
vcp_addFlags:
vcp_addStatsFlags:
vcp_addTypes:
vcp_adjustmentsResource
vcp_allAcceptableResourcesForAsset:
vcp_allResourcesForAsset:
vcp_allowInMemoryDownload
vcp_analysisPreferences
vcp_annotationWithTypes:
vcp_anyAssetsForTaskID:
vcp_appendResult:forKey:
vcp_appendResults:
vcp_ascendingSizeComparator
vcp_assetCountForTaskID:
vcp_assetCountWithInternalPredicate:forTaskID:
vcp_assetCountWithMediaType:forTaskID:
vcp_assetWithoutAdjustments:duration:
vcp_avAsset
vcp_avAsset:
vcp_captureDeviceMake
vcp_captureDeviceModel
vcp_childWithPendingUnitCount:
vcp_cleanApertureRect
vcp_confidenceForSceneIdentifier:
vcp_convertToOriginalTimerangeFromScaledTimerange:
vcp_dateAnalyzed
vcp_dateModified
vcp_defaultMediaAnalysisDatabaseFilepath
vcp_defaultPhotoLibrary
vcp_defaultURL
vcp_degraded
vcp_descendingSizeComparator
vcp_eligibleForStreaming:
vcp_eligibleForVideoDownload:
vcp_endTime
vcp_exifFromImageURL:
vcp_faceAnalysisStateFilepath
vcp_faceRectFrom:
vcp_fetchAssetsMatchingFingerprint:forPhotoLibrary:
vcp_fetchOptionsForLibrary:forTaskID:
vcp_fileSize
vcp_fingerprint:
vcp_firstEnabledTrackWithMediaType:
vcp_flags
vcp_flagsForPHFace:withFaceRect:
vcp_flashFired
vcp_fullAnalysisPredatesVersionInternalPredicate:
vcp_fullAnalysisTypes
vcp_fullAnalysisTypesForAssetType:
vcp_fullAnalysisTypesForResources:
vcp_fullFrameSize
vcp_getFpsRate
vcp_hasAdjustments:
vcp_hasBody
vcp_hasExtremeAbnormalDimensionForScene
vcp_hasFace
vcp_hasLocalAdjustments
vcp_hasLocalMovie:
vcp_hasLocalPhoto:
vcp_hasLocalSlowmo:
vcp_highResImageResourcesForAsset:
vcp_idealDimension
vcp_imageOrientation
vcp_imagesPredicate:
vcp_inMemoryDownload:withTaskID:toData:cancel:
vcp_isAppleCapture
vcp_isCPLDownloadComplete
vcp_isCPLEnabled
vcp_isCPLSyncComplete
vcp_isDownloadGated
vcp_isLocallyAvailable
vcp_isMercuryBase64
vcp_isMontage
vcp_isMontageWithTaskID:
vcp_isMovie
vcp_isOriginalLocal
vcp_isPano
vcp_isPhoto
vcp_isPhotoResourceUsable:
vcp_isShortMovie
vcp_isSyndicationLibrary
vcp_isVideoResourceUsable:
vcp_isVideoSlowmo
vcp_isVideoTimelapse
vcp_keyFrameWithMaxDimension:
vcp_libraryScaleShortDescription
vcp_livePhotoStillDisplayTime
vcp_livePhotosPredicate:
vcp_localMovieResourcesSorted:
vcp_localPhotoResourcesSorted:
vcp_majorDimensionForResource:withTargetResolution:
vcp_mediaAnalysisBundle
vcp_mediaAnalysisDatabaseFilepath
vcp_mediaAnalysisDirectory
vcp_mercuryBase64ToLocalIdentifier
vcp_modificationDate
vcp_moviesPredicate:
vcp_mutableResults
vcp_needFaceProcessing
vcp_needSceneProcessing
vcp_needsOCRProcessing
vcp_needsProcessingForTask:
vcp_nonPanoPredicate:
vcp_normalizedBodyBounds
vcp_normalizedFaceBounds
vcp_ocrGatingThreshold
vcp_ocrMajorDimensionForResource:
vcp_originalResource
vcp_originalSize
vcp_originalVideoResource
vcp_passedOCRGating
vcp_photoResourcesSorted:
vcp_quality
vcp_queryPHFaces:results:
vcp_removeResultForKey:
vcp_removeSyncPoint
vcp_reportDownload:withTaskID:
vcp_requestFileURLForAssetResource:withTaskID:timeoutHandler:urlHandler:andCompletionHandler:
vcp_requestFileURLForAssetResource:withTaskID:toResourceURL:cancel:
vcp_requiredFaceLibraryProcessingSubTasks
vcp_requiresDownloadForTask:
vcp_requiresProcessingForTask:
vcp_resourceWithType:
vcp_results
vcp_scaleRampWithIntervals:andRates:inSlowmoTimerange:withTimeMapping:inComposition:
vcp_scaleSlowmoTimeRange:withTimeMapping:inComposition:
vcp_scaledExposureTime
vcp_sceneRequest
vcp_sceneRequestForWallpaper
vcp_sceneRequestWithRequestClass:andRevision:
vcp_scenenetAnnotation
vcp_setAnalysisPreferencesValue:forKey:
vcp_setDateAnalyzed:
vcp_setDateModified:
vcp_setFingerprint:
vcp_setFlags:
vcp_setResult:forKey:
vcp_setStatsFlags:
vcp_setSyncPoint:
vcp_setTimerange:
vcp_setTypes:
vcp_sharedModelWithModelName:
vcp_sharedTaxonomy
vcp_size
vcp_smallMovieDerivativeResource
vcp_smallResourceMeetingCriteria:
vcp_sortBySize
vcp_startTime
vcp_statsFlags
vcp_stillImagesPredicate:
vcp_streamedVideo
vcp_supportsInMemoryDownload
vcp_syncPoint
vcp_targetMajorDimensionForImageWithWidth:height:andMinPreferredMinorDimension:
vcp_taskWithImageAsset:andSignpostPayload:
vcp_textAnnotation
vcp_thumbnailResource
vcp_time
vcp_timerange
vcp_typeDescription
vcp_types
vcp_uniformTypeIdentifier
vcp_updateModelByAddingFaces:error:
vcp_usePHFace
vcp_usePHFaceExpression
vcp_version
vcp_vipModelLastGenerationDateForVIPType:
vcp_visionCacheStorageDirectoryURL
verifiedType
vertexCount
vertices
videoActivityDescriptor
videoCaptionDecoderTestURL
videoCaptionEncoderTestURL
videoEmbedding
videoStabilizerforAnalysisType:withMetadata:sourceSize:cropRect:
visionSession
visualPleasingScore
visualPleasingScoreForTimerange:
visualSearchData
visualSearchProperties
visualUnderstanding
voiceScore
voiceScoreForTimerange:
voteVanishingPoint:
waitUntilCompleted
warnings
wasSignalled
weakSession
webURL
weightedAveragePrecision
weightedAverageRecall
wellChosenBackgroundScore
wellFramedSubjectScore
wellTimedShotScore
width
workerWithPhotoLibrary:
workerWithPhotoLibrary:andContext:
wrapperWithImageprintType:version:andData:
writeTo:
writeToFile:atomically:
writeToURL:atomically:
writeToURL:error:
writeToURL:options:error:
zone
@24@0:8^{_NSZone=}16
@16@0:8
B24@0:8@16
v24@0:8@16
Q16@0:8
f16@0:8
v20@0:8f16
v16@0:8
@"VCPProtoTimeRange"
@52@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16f48
{CGRect={CGPoint=dd}{CGSize=dd}}16@0:8
v48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
{CGRect="origin"{CGPoint="x"d"y"d}"size"{CGSize="width"d"height"d}}
@64@0:8{CGAffineTransform=dddddd}16
@72@0:8@16@24{?=qiIq}32^{?=qiIq}56@64
i88@0:8^{__CVBuffer=}16{?=qiIq}24{?=qiIq}48^Q72@80
i80@0:8^{__CVBuffer=}16{?=qiIq}24{?=qiIq}48^Q72
v104@0:8{?={?=qiIq}{?=qiIq}}16@64@72{?=qiIq}80
i64@0:8{?={?=qiIq}{?=qiIq}}16
@"NSMutableArray"
{?="value"q"timescale"i"flags"I"epoch"q}
@"VCPImagePetsAnalyzer"
@"NSArray"
@32@0:8@16@24
i72@0:8{?={?=qiIq}{?=qiIq}}16^{__CVBuffer=}64
B16@0:8
v20@0:8B16
B32@0:8@?16^@24
@24@0:8@16
@24@0:8Q16
d24@0:8@16
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
@"NSURL"16@0:8
B32@0:8@?<v@?>16^@24
@"<PVFetchResultProtocol>"24@0:8@"NSArray"16
@"<PVFetchResultProtocol>"24@0:8Q16
@"<PVFetchResultProtocol>"24@0:8@"<PVMomentProtocol>"16
@"<PVFetchResultProtocol>"24@0:8@"<PVPersonProtocol>"16
@"NSDictionary"24@0:8@"<PVFetchResultProtocol>"16
@"<PVFetchResultProtocol>"32@0:8@"<PVPersonProtocol>"16@"<PVMomentProtocol>"24
@"<PVFetchResultProtocol>"32@0:8@"NSArray"16@"<PVMomentProtocol>"24
@"<PVFetchResultProtocol>"24@0:8@"<PVFaceGroupProtocol>"16
@"<PVFetchResultProtocol>"16@0:8
@"<PVFetchResultProtocol>"24@0:8@"<NSFastEnumeration>"16
@"NSDate"16@0:8
@"NSSet"16@0:8
@"NSDictionary"16@0:8
@24@0:8@"NSDictionary"16
v24@0:8I16B20
@"NSObject<OS_dispatch_queue>"
^{__SCNetworkReachability=}
@96@0:8@16f24B28@32{?={?=qiIq}{?=qiIq}}40Q88
i20@0:8f16
i28@0:8^{__CVBuffer=}16i24
i56@0:8@16@24{?=qiIq}32
i32@0:8@16@24
{?=qiIq}40@0:8{?=qiIq}16
i104@0:8{?=qiIq}16{?=qiIq}40@64{CGRect={CGPoint=dd}{CGSize=dd}}72
@"VCPVideoCNNBackbone"
@"VCPTransforms"
@"VCPVideoPersonDetector"
@"NSString"
@"VCPVideoCNNAutoplay"
@"VCPVideoCNNCameraMotion"
@"VCPVideoCNNQuality"
@"VCPVideoCNNHighlight"
{?="distanceToPreviousScene"b1"flickerScore"b1"sceneprintDistanceToPreviousScene"b1}
@32@0:8^{__CVBuffer=}16@24
@"MLFeatureValue"24@0:8@"NSString"16
^{__CVBuffer=}
v40@0:8r^{?=qiIq}16r^{?=qiIq}24@32
i28@0:8^{opaqueCMSampleBuffer=}16i24
i16@0:8
i24@0:8r^{AudioStreamBasicDescription=dIIIIIIII}16
i88@0:8^{AudioBufferList=I[1{AudioBuffer=II^v}]}16{AudioTimeStamp=dQdQ{SMPTETime=ssIIIssss}II}24
i24@0:8r^{?=qiIq}16
@"NSDictionary"
{AudioStreamBasicDescription="mSampleRate"d"mFormatID"I"mFormatFlags"I"mBytesPerPacket"I"mFramesPerPacket"I"mBytesPerFrame"I"mChannelsPerFrame"I"mBitsPerChannel"I"mReserved"I}
B20@0:8B16
@24@0:8@?16
@20@0:8B16
@72@0:8@16@24@32@40B48B52f56f60f64B68
i48@0:8^{__CVBuffer=}16{?=qiIq}24
i88@0:8^{__CVBuffer=}16{?=qiIq}24{?=qiIq}48^Q72@?80
i96@0:8^{__CVBuffer=}16{?=qiIq}24{?=qiIq}48@72^Q80@?88
i40@0:8{?=qiIq}16
f40@0:8@16^{EncodeStats=^^?^B^B^{MotionVector}^{MotionVector}^{MotionVector}^{MotionVector}^S^S^I^S^S^S^S^S^S^S^S^S^S^SIBBBii}24i32i36
i20@0:8i16
v24@0:8^v16
f24@0:8^v16
i36@0:8@16@24B32
i80@0:8@16@24{?={?=qiIq}{?=qiIq}}32
i44@0:8^{__CFArray=}16@24@32B40
v24@0:8^{__CVBuffer=}16
v32@0:8^v16@24
@64@0:8{?={?=qiIq}{?=qiIq}}16
^{MotionFilter=^{FrameBuffer}BB}
^{MetaDataAnalysis=B^{FrameBuffer}{Translation=fff}{Translation=fff}}
^{IrisAnalysis=ffiiB^{__CFArray}}
{FrameBuffer="frame_count_"i"buffer_"[35{Frame="frame_idx_"i"timestamp_"{?="value"q"timescale"i"flags"I"epoch"q}"duration_"{?="value"q"timescale"i"flags"I"epoch"q}"ave_motion_"{Translation="x_"f"y_"f"z_"f}"org_motion_"{Translation="x_"f"y_"f"z_"f}"quality_score_"f"distortion_"Q"distortion_norm_"f"motion_change_"{Translation="x_"f"y_"f"z_"f}"compressed_bytes_"I"blur_"B"acc_var_"{Translation="x_"f"y_"f"z_"f}"texture_"f"motion_result_"{MotionResult="significant_values_"[6f]"confidence_"[6f]"fine_action_score_"f"action_score_"f"track_score_"f"rotation_angle_"f"subtle_motion_score_"f"is_stable_"B"action_blocks_"i"action_motion_"f"valid_mb_"B"valid_submb_"B"support_size_"i"residual_var_"f"gmv_"[2f]"motion_param_"{array<float, 6UL>="__elems_"[6f]}"motion_param_diff_"{array<float, 6UL>="__elems_"[6f]}"duration_"{?="value"q"timescale"i"flags"I"epoch"q}"scene_delta_"f"scene_delta_ratio_"f"objects_"{Vector<ma::Object *>="vector_"^{__CFArray}}"detect_objects_"{Vector<ma::Object *>="vector_"^{__CFArray}}"imported_objects_"{Vector<ma::Object *>="vector_"^{__CFArray}}}"flow_"^f"interestingness_"f"obstruction_"f"colorfulness_score_"f"histogram_"{Histogram="extremities_"f"overexposes_"f"histogram_"[3^i]"moments_hist_"[2^i]}}]}
{Histogram="extremities_"f"overexposes_"f"histogram_"[3^i]"moments_hist_"[2^i]}
@"NSMutableDictionary"
@"VCPFrameAnalysisStats"
@"VCPFrameScoreFilter"
@"VCPMotionFlowSubtleMotionAnalyzer"
@"VCPMotionFlowAnalyzer"
@32@0:8@16^@24
@80@0:8{CGAffineTransform=dddddd}16@64@72
i32@0:8^{__CVBuffer=}16@24
B32@0:8@16@24
B84@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48B80
i56@0:8^{__CVBuffer=}16{?=qiIq}24@48
@"VCPCNNSmileDetector"
@"VCPCNNPoseEstimator"
{?={?=qiIq}{?=qiIq}}16@0:8
@32@0:8@16@?24
v32@0:8@16Q24
B24@0:8^@16
@"NSData"
{atomic<bool>="__a_"{__cxx_atomic_impl<bool, std::__cxx_atomic_base_impl<bool>>="__a_value"AB}}
@32@0:8B16B20@24
^f48@0:8i16i20^i24^i32^f40
i36@0:8^{CGPoint=dd}16^f24f32
@"VCPCNNModelEspresso"
f56@0:8*16*24*32i40i44q48
f48@0:8*16i24i28q32*40
i48@0:8^{__CVBuffer=}16^Q24^@32@?40
@24@0:8^{__CVBuffer=}16
i32@0:8^f16@24
@"NSData"16@0:8
i32@0:8^f16@"<VCPDistanceDescriptorProtocol>"24
@24@0:8@"NSData"16
@"VNImageprint"
d16@0:8
v24@0:8d16
{?="contentScore"b1"globalQualityScore"b1}
i20@0:8B16
{CGAffineTransform=dddddd}64@0:8{CGAffineTransform=dddddd}16
i32@0:8@16^Q24
{CGAffineTransform="a"d"b"d"c"d"d"d"tx"d"ty"d}
v24@0:8q16
q16@0:8
S16@0:8
@40@0:8@16@24@?32
@?16@0:8
v24@0:8@?16
@"VNCanceller"
B32@0:8@16^@24
@32@0:8Q16^@24
@40@0:8Q16Q24^@32
@40@0:8@16@24^@32
@"NSDictionary"32@0:8Q16^@24
@"NSNumber"40@0:8Q16Q24^@32
@"NSDictionary"40@0:8@"NSArray"16@"NSArray"24^@32
v32@0:8@16@24
B28@0:8B16@?20
v24@0:8Q16
v40@0:8{?=QQBB}16
B64@0:8@16@24@32@40@?48^@56
@44@0:8@16B24@28@36
@36@0:8@16B24@28
v40@0:8@16^@24@?32
v32@0:8@16@?24
B40@0:8^@16^Q24^@32
B48@0:8@16@24@32^@40
B36@0:8B16@?20^@28
Q36@0:8B16@?20^@28
@48@0:8@16@24@?32^@40
@40@0:8@16^@24@?32
B60@0:8@16Q24B32^@36@?44^@52
@40@0:8^@16^@24@?32
B56@0:8^@16^d24^B32@?40^@48
@"PHPhotoLibrary"
@"VCPPhotosPersistenceDelegate"
@"NSObject<OS_dispatch_group>"
@"VCPPhotosFaceProcessingContext"
@"NSURL"
@"NSNumber"
@"NSSet"
@"NSMutableSet"
@"VNClustererBuilder"
@"VCPSuggestionRequest"
@"NSLock"
{?="countOfEligibleFaces"Q"countOfFacesPendingToAdd"Q"isClustering"B"rebuildRequired"B}
@"NSDate"
{mach_timebase_info="numer"I"denom"I}
@40@0:8^{__CVBuffer=}16@24^@32
{CGSize=dd}32@0:8@16^@24
I16@0:8
@"VCPImageHumanPoseAnalyzer"
i24@0:8@16
i112@0:8@16@24{CGRect={CGPoint=dd}{CGSize=dd}}32{?=qiIq}64{?=qiIq}88
@64@0:8@16@24{CGRect={CGPoint=dd}{CGSize=dd}}32
{CGSize="width"d"height"d}
@"VNImageRequestHandler"
@"VCPMADVIRemoveBackgroundCachedImageHandler"
@40@0:8@16@24@32
@40@0:8@"MADRequest"16@"VCPMADServiceImageAsset"24@"NSString"32
@"NSArray"16@0:8
v24@0:8@"<MTLDevice>"16
@"MADVIRemoveBackgroundRequest"
@"VCPMADServiceImageAsset"
@"<MTLDevice>"
@"VNImageBasedRequest"
{?=qiIq}16@0:8
@"VNRequest"
@20@0:8i16
i24@0:8i16i20
i32@0:8^{CGImage=}16^^{__CVBuffer}24
^{CGColorSpace=}
^{CGContext=}
^{__CVPixelBufferPool=}
^{OpaqueVTPixelTransferSession=}
@56@0:8@16Q24@32@?40@?48
@48@0:8Q16@24@32^@40
@48@0:8@16Q24@32^@40
@"VCPDatabaseReader"
v56@0:8@16@24I32@36i44@?48
v60@0:8@16@24@32@40i48@?52
v60@0:8@16@24Q32@40i48@?52
v64@0:8@16@24I32@36@44i52@?56
v44@0:8@16@24i32@?36
v36@0:8@16i24@?28
v32@0:8Q16Q24
v60@0:8i16@20@28Q36@44@?52
v60@0:8i16@20@28@36Q44@?52
v48@0:8i16@20@28B36@?40
v52@0:8i16Q20@28@36@?44
v60@0:8i16Q20@28@36@44@?52
v60@0:8i16@20@28@36@44@?52
v20@0:8i16
v48@0:8i16@20B28@32@?40
v44@0:8i16@20@28@?36
v36@0:8i16@20@?28
v40@0:8i16B20@24@?32
v40@0:8@16Q24@?32
v52@0:8i16@20@28@36@?44
v52@0:8Q16@24@32i40@?44
v32@0:8@"NSURL"16@?<v@?@"NSString">24
v56@0:8@"NSArray"16@"IOSurface"24I32@"NSString"36i44@?<v@?@"NSArray"@"NSError">48
v60@0:8@"NSArray"16@"NSURL"24@"NSString"32@"NSString"40i48@?<v@?@"NSArray"@"NSError">52
v60@0:8@"NSArray"16@"NSData"24@"UTType"32@"NSString"40i48@?<v@?@"NSArray"@"NSError">52
v60@0:8@"NSArray"16@"NSString"24Q32@"NSURL"40i48@?<v@?@"NSArray"@"NSError">52
v64@0:8@"NSArray"16@"IOSurface"24I32@"NSString"36@"NSURL"44i52@?<v@?@"NSArray"@"NSError">56
v44@0:8@"NSArray"16@"NSString"24i32@?<v@?@"NSArray"@"NSError">36
v36@0:8@"NSDictionary"16i24@?<v@?@"NSDictionary"@"NSError">28
v24@0:8@?<v@?@"NSDictionary">16
v60@0:8i16@"NSArray"20@"NSDictionary"28Q36@"NSArray"44@?<v@?@"NSDictionary"@"NSError">52
v60@0:8i16@"NSArray"20@"NSURL"28@"NSDictionary"36Q44@?<v@?@"NSDictionary"@"NSError">52
v48@0:8i16@"NSURL"20@"NSArray"28B36@?<v@?@"NSDictionary"@"NSError">40
v52@0:8i16Q20@"NSURL"28@"NSDictionary"36@?<v@?@"NSError">44
v60@0:8i16Q20@"NSArray"28@"NSURL"36@"NSDictionary"44@?<v@?@"NSDictionary"@"NSError">52
v60@0:8i16@"NSURL"20@"NSURL"28@"NSDictionary"36@"NSArray"44@?<v@?@"NSDictionary"@"NSError">52
v24@0:8@?<v@?@"NSError">16
v24@0:8@?<v@?Q>16
v24@0:8@"NSURL"16
v60@0:8i16@"NSString"20@"NSArray"28@"NSArray"36@"NSURL"44@?<v@?@"NSArray"@"NSError">52
v48@0:8i16@"NSArray"20B28@"NSURL"32@?<v@?B@"NSError">40
v44@0:8i16@"NSArray"20@"NSURL"28@?<v@?@"NSArray"@"NSError">36
v36@0:8i16@"NSURL"20@?<v@?B@"NSError">28
v44@0:8i16@"NSDictionary"20@"NSURL"28@?<v@?@"NSString"@"NSError">36
v40@0:8i16B20@"NSURL"24@?<v@?@"NSDictionary"@"NSError">32
v36@0:8i16@"NSURL"20@?<v@?@"NSDictionary"@"NSError">28
v44@0:8i16@"NSArray"20@"NSURL"28@?<v@?B@"NSError">36
v32@0:8@"NSURL"16@?<v@?@"NSDictionary"@"NSError">24
v40@0:8@"NSURL"16Q24@?<v@?@"NSString"@"NSError">32
v44@0:8i16@"NSURL"20@"NSArray"28@?<v@?@"NSDictionary"@"NSError">36
v52@0:8i16@"NSURL"20@"NSURL"28@"NSURL"36@?<v@?@"NSDictionary"@"NSError">44
v44@0:8i16@"NSURL"20@"NSURL"28@?<v@?@"NSDictionary"@"NSError">36
v44@0:8@"NSArray"16@"NSURL"24i32@?<v@?@"NSDictionary"@"NSError">36
v52@0:8Q16@"NSArray"24@"NSURL"32i40@?<v@?@"NSError">44
v28@0:8d16i24
i40@0:8^f16@24Q32
i48@0:8^f16@24Q32@?40
i32@0:8^@16@24
i40@0:8^@16@24@?32
i40@0:8^@16@24Q32
i48@0:8^@16@24Q32@?40
i56@0:8Q16@24@32@?40@?48
i52@0:8@16@24B32@?36@?44
i44@0:8@16B24@?28@?36
i48@0:8Q16@24@?32@?40
i48@0:8@16@24@?32@?40
i40@0:8@16@24@?32
i32@0:8@16@?24
i40@0:8@16Q24@?32
@"NSXPCConnection"
i64@0:8@16@24@32@40@?48@?56
i52@0:8@16B24@28@?36@?44
i40@0:8@16@?24@?32
i44@0:8B16@20@?28@?36
i48@0:8@16@24@32@?40
i24@0:8^f16
^f16@0:8
i40@0:8^{?=^v^v[4Q][4Q]QQQQQQQQQQi}16@24@32
i64@0:8^ 16Q24Q32Q40@48@56
i40@0:8^i16^i24^I32
i40@0:8^{__CVBuffer=}16@24@32
{?="plan"^v"network_index"i}
{?="data"^v"reserved"^v"dim"[4Q]"stride"[4Q]"width"Q"height"Q"channels"Q"batch_number"Q"sequence_length"Q"stride_width"Q"stride_height"Q"stride_channels"Q"stride_batch_number"Q"stride_sequence_length"Q"storage_type"i}
@40@0:8{?=qiIq}16
i36@0:8^{__CVBuffer=}16^f24i32
i40@0:8^f16^{__CVBuffer=}24i32i36
^f40@0:8i16i20^i24^i32
i52@0:8^f16i24i28@32@40i48
i28@0:8@16i24
i48@0:8^{__CVBuffer=}16@24@32@?40
@"CVNLPCommSafetyHandler"
@"MADImageSafetyClassificationRequest"
i64@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16^{__CVBuffer=}48^B56
@72@0:8@16@24Q32Q40@48i56B60^@64
@92@0:8@16@24@32Q40Q48@56@64@72@80i88
@32@0:8@16q24
d32@0:8@16@24
B40@0:8@16@24@32
B48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
q24@0:8Q16
s16@0:8
v20@0:8s16
v20@0:8S16
@"VCPVNImageprintWrapper"
^v16@0:8
^v20@0:8B16
@28@0:8B16B20B24
@"VCPProtoBounds"
@48@0:8{?=qiIq}16f40B44
v72@0:8{?={?=qiIq}{?=qiIq}}16f64B68
v40@0:8{?=qiIq}16
v44@0:8{?=qiIq}16B40
v64@0:8{?={?=qiIq}{?=qiIq}}16
{?="start"{?="value"q"timescale"i"flags"I"epoch"q}"duration"{?="value"q"timescale"i"flags"I"epoch"q}}
@32@0:8@16f24f28
v76@0:8@16{?=qiIq}24{?=qiIq}48B72
v72@0:8@16{?={?=qiIq}{?=qiIq}}24
@44@0:8Q16Q24B32@?36
@36@0:8Q16B24@?28
@"NSObject<OS_dispatch_source>"
S24@0:8@16
@24@0:8q16
@20@0:8S16
S24@0:8q16
@28@0:8@16B24
i40@0:8^@16#24Q32
i36@0:8^@16#24i32
{CGRect={CGPoint=dd}{CGSize=dd}}56@0:8d16d24d32d40d48
@48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
v40@0:8*16Q24^f32
i24@0:8^Q16
i32@0:8^{__CVBuffer=}16^Q24
@"VCPCNNModel"
@"VCPCNNData"
f24@0:8@16
i32@0:8[6f]16[6f]24
i24@0:8^v16
i24@0:8^{EncodeStats=^^?^B^B^{MotionVector}^{MotionVector}^{MotionVector}^{MotionVector}^S^S^I^S^S^S^S^S^S^S^S^S^S^SIBBBii}16
v80@0:8^{__CVBuffer=}16{?=qiIq}24{?=qiIq}48@?72
{Frame="frame_idx_"i"timestamp_"{?="value"q"timescale"i"flags"I"epoch"q}"duration_"{?="value"q"timescale"i"flags"I"epoch"q}"ave_motion_"{Translation="x_"f"y_"f"z_"f}"org_motion_"{Translation="x_"f"y_"f"z_"f}"quality_score_"f"distortion_"Q"distortion_norm_"f"motion_change_"{Translation="x_"f"y_"f"z_"f}"compressed_bytes_"I"blur_"B"acc_var_"{Translation="x_"f"y_"f"z_"f}"texture_"f"motion_result_"{MotionResult="significant_values_"[6f]"confidence_"[6f]"fine_action_score_"f"action_score_"f"track_score_"f"rotation_angle_"f"subtle_motion_score_"f"is_stable_"B"action_blocks_"i"action_motion_"f"valid_mb_"B"valid_submb_"B"support_size_"i"residual_var_"f"gmv_"[2f]"motion_param_"{array<float, 6UL>="__elems_"[6f]}"motion_param_diff_"{array<float, 6UL>="__elems_"[6f]}"duration_"{?="value"q"timescale"i"flags"I"epoch"q}"scene_delta_"f"scene_delta_ratio_"f"objects_"{Vector<ma::Object *>="vector_"^{__CFArray}}"detect_objects_"{Vector<ma::Object *>="vector_"^{__CFArray}}"imported_objects_"{Vector<ma::Object *>="vector_"^{__CFArray}}}"flow_"^f"interestingness_"f"obstruction_"f"colorfulness_score_"f"histogram_"{Histogram="extremities_"f"overexposes_"f"histogram_"[3^i]"moments_hist_"[2^i]}}
^{EncodeStatsHW=^^?^B^B^{MotionVector}^{MotionVector}^{MotionVector}^{MotionVector}^S^S^I^S^S^S^S^S^S^S^S^S^S^SIBBBiii^{OpaqueVTCompressionSession}^{__CFData}{?=qiIq}iiB}
[6[5f]]
@"VCPObjectPool"
i36@0:8^{__sFILE=*iiss{__sbuf=*i}i^v^?^?^?^?{__sbuf=*i}^{__sFILEX}i[3C][1C]{__sbuf=*i}iq}16i24i28i32
@"VNClassifyImageAestheticsRequest"
@"VNSceneClassificationRequest"
@"VNCreateSceneprintRequest"
@"VNGenerateAttentionBasedSaliencyImageRequest"
@"VNClassifyJunkImageRequest"
@"VNRecognizeObjectsRequest"
@"VNGenerateObjectnessBasedSaliencyImageRequest"
@"VNClassifyPotentialLandmarkRequest"
@"VNVYvzEtX1JlUdu8xx5qhDI"
@"VN6Mb1ME89lyW3HpahkEygIG"
@"VN5kJNH3eYuyaLxNpZr5Z7zi"
@"VNClassifyMemeImageRequest"
@"VN1JC7R3k4455fKQz0dY1VhQ"
@"VNRecognizeDocumentElementsRequest"
@"VNClassifyCityNatureImageRequest"
@"VNCreateImageFingerprintsRequest"
{?="faceQuality"b1}
B20@0:8f16
{HinkleyDetector="sensitivity_"f"threshold_"f"min_length_"i"stats_"{HinkleyStats="upper_"f"lower_"f"max_"f"min_"f}}
@"VCPVideoMetaMotionSegment"
@44@0:8f16{?=qiIq}20
v44@0:8f16{?=qiIq}20
@"VIService"
@"VCPProtoTime"
@48@0:8@16@24@32@40
i40@0:8{vector<float *, std::allocator<float *>>=^^f^^f{__compressed_pair<float **, std::allocator<float *>>=^^f}}16
v24@0:8^f16
{vector<espresso_buffer_t, std::allocator<espresso_buffer_t>>=^{?}^{?}{__compressed_pair<espresso_buffer_t *, std::allocator<espresso_buffer_t>>=^{?}}}16@0:8
v40@0:8{vector<espresso_buffer_t, std::allocator<espresso_buffer_t>>=^{?}^{?}{__compressed_pair<espresso_buffer_t *, std::allocator<espresso_buffer_t>>=^{?}}}16
{?=^v^v[4Q][4Q]QQQQQQQQQQi}16@0:8
v184@0:8{?=^v^v[4Q][4Q]QQQQQQQQQQi}16
@"VCPCNNEspressoContext"
{vector<espresso_buffer_t, std::allocator<espresso_buffer_t>>="__begin_"^{?}"__end_"^{?}"__end_cap_"{__compressed_pair<espresso_buffer_t *, std::allocator<espresso_buffer_t>>="__value_"^{?}}}
i40@0:8@16^@24@?32
@"VCPLoaned"
@56@0:8^f16^f24Q32Q40i48i52
i28@0:8f16f20f24
i36@0:8^f16f24^f28
i64@0:8^f16Q24Q32{DSPSplitComplex=^f^f}40^f56
B28@0:8i16i20i24
{DSPSplitComplex="realp"^f"imagp"^f}
@68@0:8f16{?={?=qiIq}{?=qiIq}}20
i64@0:8{?=qiIq}16{?=qiIq}40
@"VCPVideoCaptionEncoder"
@"MAAsset"
@32@0:8@16r^{?={?=qiIq}{?=qiIq}}24
i28@0:8B16^{?={?=qiIq}{?=qiIq}}20
i72@0:8{?={?=qiIq}{?=qiIq}}16^^{opaqueCMSampleBuffer}64
^{opaqueCMSampleBuffer=}16@0:8
@"AVAssetReader"
@"AVAssetReaderSampleReferenceOutput"
@"NSObject<OS_dispatch_semaphore>"
[2^{opaqueCMSampleBuffer}]
@36@0:8Q16i24@28
@40@0:8Q16@24^@32
B40@0:8^f16@24^@32
@132@0:8{CGAffineTransform=dddddd}16{?={?=qiIq}{?=qiIq}}64B112@116@124
i24@0:8^{__CVBuffer=}16
f32@0:8@16@24
@"VCPImageBlurAnalyzer"
@"VCPImageFaceQualityAnalyzer"
@"VCPVideoKeyFrame"
@"AVAssetReaderTrackOutput"
@"AVAssetReaderOutputMetadataAdaptor"
v56@0:8@16@24^Q32^Q40^Q48
Q24@0:8@16
Q40@0:8@16@24Q32
Q32@0:8@16Q24
i48@0:8@16Q24^@32@?40
v48@0:8@16Q24@32@?40
B20@0:8i16
@48@0:8i16i20i24B28B32i36i40B44
i28@0:8^{__sFILE=*iiss{__sbuf=*i}i^v^?^?^?^?{__sbuf=*i}^{__sFILEX}i[3C][1C]{__sbuf=*i}iq}16s24
v32@0:8@16^{__CVBuffer=}24
f92@0:8f16{CGRect={CGPoint=dd}{CGSize=dd}}20{CGRect={CGPoint=dd}{CGSize=dd}}52i84i88
@28@0:8@16f24
f84@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48B80
@"VCPImageSaliencyAnalyzer"
@40@0:8^{opaqueCMSampleBuffer=}16@24^@32
@"VCPImageHandsAnalyzer"
i40@0:8B16@20B28B32B36
i40@0:8^{__CVBuffer=}16^{__CVBuffer=}24@?32
^f32@0:8^i16^i24
i32@0:8^{__CVBuffer=}16f24f28
i40@0:8^{__CVBuffer=}16^{__CVBuffer=}24f32f36
i28@0:8@16I24
{vector<float *, std::allocator<float *>>="__begin_"^^f"__end_"^^f"__end_cap_"{__compressed_pair<float **, std::allocator<float *>>="__value_"^^f}}
i36@0:8@16f24@?28
@"MADEmbeddingGenerationRequest"
B40@0:8@16@24^@32
B88@0:8{?={?=qiIq}{?=qiIq}}16{?=qiIq}64
B56@0:8^{opaqueCMSampleBuffer=}16{?=qiIq}24^@48
B32@0:8^{opaqueCMSampleBuffer=}16^@24
B48@0:8{?=qiIq}16^@40
v20@0:8I16
{CF<opaqueCMSampleBuffer *>="value_"^{opaqueCMSampleBuffer}}
{?="faceSharpness"b1}
@40@0:8@16Q24^@32
i40@0:8^{CGPoint=dd}16^f24^@32
v64@0:8^f16^f24Q32Q40Q48Q56
v28@0:8i16^f20
v40@0:8^f16Q24Q32
i56@0:8^f16@24^{CGPoint=dd}32^f40^@48
i52@0:8@16f24{CGPoint=dd}28^f44
i32@0:8@16^f24
[8^f]
@"VCPGaborFilter"
@"VCPHumanPoseImageRequest"
@24@0:8i16B20
i40@0:8^{__CVBuffer=}16^f24i32i36
f40@0:8^f16i24i28i32i36
i32@0:8^f16i24i28
i24@0:8@?16
i40@0:8^{__CVBuffer=}16@24@?32
i84@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24{CGSize=dd}56B72@76
[5{CGRect="origin"{CGPoint="x"d"y"d}"size"{CGSize="width"d"height"d}}]
[5f]
B24@0:8Q16
Q24@0:8Q16
Q32@0:8q16Q24
@212@0:8Q16{CGAffineTransform=dddddd}24{?={?=qiIq}{?=qiIq}}72B120f124@128B136B140@144B152{?={?=qiIq}{?=qiIq}}156@204
v64@0:8@16@24@32@40{CGSize=dd}48
@"VCPVideoKeyFrameAnalyzer"
@"VCPMovieHighlightAnalyzer"
@"VCPImageDescriptor"
i44@0:8B16@20i28i32@?36
i28@0:8^^{__CVBuffer}16I24
i32@0:8^{__CVBuffer=}16^{__CVBuffer=}24
i32@0:8^{__CVBuffer=}16^{?=[7{?=iii}][7^{__CVBuffer}]}24
i36@0:8i16^{__CVBuffer=}20^{__CVBuffer=}28
i36@0:8^{__CVBuffer=}16^{__CVBuffer=}24i32
i40@0:8^{__CVBuffer=}16^{__CVBuffer=}24i32i36
@"VCPFlowFeatureExtractor"
[7@"VCPFlowDecoder"]
@"VCPCorrelation"
@"VCPBackwarp"
[2{?="featureShape"[7{?="channels"i"height"i"width"i}]"feature"[7^{__CVBuffer}]}]
{?="correlations"[7^{__CVBuffer}]"flows"[7^{__CVBuffer}]"upscaledFlows"[7^{__CVBuffer}]"warpedBuffers"[7^{__CVBuffer}]}
{CLLocationCoordinate2D=dd}16@0:8
i44@0:8Q16Q24i32^^{__CVBuffer}36
i36@0:8^{__CVBuffer=}16^^{__CVBuffer}24i32
@40@0:8^{__CVBuffer=}16^{__CVBuffer=}24^@32
@52@0:8^{__CVBuffer=}16^{__CVBuffer=}24B32^{__CVBuffer=}36^@44
@"VCPImageMotionFlowAnalyzer"
i32@0:8q16^@24
@32@0:8@16Q24
i40@0:8@16@?24^Q32
i32@0:8@?16^Q24
@"AVAsset"
i48@0:8@16{?=qiIq}24
v28@0:8B16@20
v60@0:8B16f20f24f28f32f36f40B44f48f52B56
@"VNSceneprint"
@"VCPCNNPetsDetector"
i32@0:8[3[3f]]16[3f]24
i32@0:8[3f]16[3[3f]]24
i32@0:8[3f]16[3f]24
i24@0:8^{?=[4]}16
{Matrix<float, 12U, 1U, false>="m_data"[12f]}
{Matrix<float, 12U, 12U, false>="m_data"[144f]}
v24@0:8@"<PVFetchResultProtocol>"16
@"<PVFaceProtocol>"16@0:8
v24@0:8@"<PVFaceProtocol>"16
Q36@0:8B16Q20Q28
{CGRect={CGPoint=dd}{CGSize=dd}}32@0:8Q16Q24
{CGRect={CGPoint=dd}{CGSize=dd}}80@0:8Q16Q24{CGAffineTransform=dddddd}32
@"VNFaceObservation"
v24@0:8f16f20
v52@0:8^f16^f24^f32i40^f44
v48@0:8r^f16r^i24r^f32^f40
v48@0:8r^f16r^f24r^f32^f40
v32@0:8r^f16^f24
v52@0:8r^f16i24r^f28r^f36^f44
v36@0:8r^f16^f24B32
B24@0:8^f16
v56@0:8^f16^f24^f32^f40^f48
v44@0:8^f16^f24^f32i40
v68@0:8^f16^f24^f32^f40^f48^f56i64
{matrix<double, 6L, 1L, dlib::memory_manager_stateless_kernel_1<char>, dlib::row_major_layout>={layout<double, 6L, 1L, dlib::memory_manager_stateless_kernel_1<char>, 1>=[6d]}}16@0:8
B28@0:8i16B20B24
{?=[4]}16@0:8
^16@0:8
@"VCPFaceTensorModel"
^{?=ffi}
[8f]
[9f]
[12f]
[3f]
[126f]
[189f]
@"VCPPnPSolver"
[51f]
@24@0:8^@16
@"MADVITextLookupRequest"
@"<VICancellable>"
@"VCPProtoLine"
@"VCPProtoPoint"
B80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48
v48@0:8Q16@24@32@?40
v48@0:8Q16@"IOSurface"24@"NSDictionary"32@?<v@?@"NSDictionary"@"NSError">40
@28@0:8i16@20
v48@0:8Q16^{__CVBuffer=}24@32@?40
{CGPoint=dd}16@0:8
@48@0:8{CGPoint=dd}16{CGPoint=dd}32
f24@0:8Q16
v32@0:8^f16Q24
{?="list"^f"count"Q"size"Q}
@24@0:8^{__sFILE=*iiss{__sbuf=*i}i^v^?^?^?^?{__sbuf=*i}^{__sFILEX}i[3C][1C]{__sbuf=*i}iq}16
v32@0:8^f16^f24
v44@0:8^f16i24^f28^f36
^i16@0:8
@56@0:8@16Q24Q32Q40@48
{?="loopFadeLen"b1"loopPeriod"b1"loopStart"b1}
@28@0:8i16B20B24
i56@0:8^{__CVBuffer=}16^Q24@32^@40@?48
@"VCPCNNPetsKeypointsDetector"
i68@0:8@16@24@32@40@48@56f64
f80@0:8{?={?=qiIq}{?=qiIq}}16@64^i72
f64@0:8{?={?=qiIq}{?=qiIq}}16
i68@0:8{?={?=qiIq}{?=qiIq}}16f64
@"VCPVideoActivityDescriptor"
@68@0:8{?={?=qiIq}{?=qiIq}}16f64
f28@0:8@16f24
B72@0:8{?={?=qiIq}{?=qiIq}}16@64
B28@0:8@16f24
f72@0:8{?={?=qiIq}{?=qiIq}}16@64
f20@0:8f16
@28@0:8i16i20i24
@100@0:8Q16B24f28B32B36B40{?={?=qiIq}{?=qiIq}}44@92
i168@0:8@16@24@32@40@48@56@64@72@80@88@96@104@112@120@128@136@144{CGSize=dd}152
B64@0:8{?={?=qiIq}{?=qiIq}}16
@120@0:8@16{?={?=qiIq}{?=qiIq}}24{?={?=qiIq}{?=qiIq}}72
@112@0:8{?={?=qiIq}{?=qiIq}}16{?={?=qiIq}{?=qiIq}}64
{?={?=qiIq}{?=qiIq}}64@0:8{?={?=qiIq}{?=qiIq}}16
f68@0:8{?={?=qiIq}{?=qiIq}}16B64
@68@0:8{?={?=qiIq}{?=qiIq}}16B64
i64@0:8{array<float, 6UL>=[6f]}16{array<float, 6UL>=[6f]}40
B88@0:8^f16@24{?={?=qiIq}{?=qiIq}}32@80
{CGRect={CGPoint=dd}{CGSize=dd}}64@0:8{?={?=qiIq}{?=qiIq}}16
{?={?=qiIq}{?=qiIq}}68@0:8{?={?=qiIq}{?=qiIq}}16B64
@"AVAssetImageGenerator"
{array<float, 6UL>="__elems_"[6f]}
@"VCPColorNormalizationAnalyzer"
v40@0:8@16@24@?32
v32@0:8@"NSDictionary"16@?<v@?@"NSError">24
v32@0:8@"NSDictionary"16@?<v@?@"NSDictionary"@"NSError">24
v40@0:8@"NSData"16@"NSDictionary"24@?<v@?@"NSDictionary"@"NSError">32
@40@0:8@16@?24@?32
{CF<const opaqueCMFormatDescription *>="value_"^{opaqueCMFormatDescription}}
@"VCPHomeKitAnalysisSession"
i36@0:8^{sqlite3_stmt=}16i24@28
i40@0:8^{sqlite3_stmt=}16i24i28@32
i40@0:8@16^@24^q32
i32@0:8q16@24
i40@0:8q16@24@32
i40@0:8@16@24@32
@32@0:8Q16Q24
Q32@0:8Q16Q24
i32@0:8^q16@24
q24@0:8@16
i40@0:8^@16Q24@32
^{sqlite3=}
@"AVURLAsset"
^{__CVBuffer=}24@0:8Q16
^{__CVBuffer=}32@0:8Q16^I24
{CGAffineTransform=dddddd}20@0:8I16
i32@0:8^Q16^@24
@64@0:8@16@24@32@40@?48@?56
@36@0:8@16B24^@28
@"AVAudioPCMBuffer"
^{LkFsMeasure=IIqBIIddddqqIII[30[6f]]^f^f^f^{DspLibBiquad}^{DspLibBiquad}}
^{CAStreamBasicDescription=dIIIIIIII}
{vector<double, std::allocator<double>>="__begin_"^d"__end_"^d"__end_cap_"{__compressed_pair<double *, std::allocator<double>>="__value_"^d}}
{vector<float, std::allocator<float>>="__begin_"^f"__end_"^f"__end_cap_"{__compressed_pair<float *, std::allocator<float>>="__value_"^f}}
^{AUOutputBL={CAStreamBasicDescription=dIIIIIIII}*^{AudioBufferList}III}
i32@0:8^{CGImage=}16^@24
^{CGImageMetadata=}24@0:8@16
@88@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48@80
@72@0:8r^{CGImageSource=}16{CGRect={CGPoint=dd}{CGSize=dd}}24@56^@64
@72@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24@56^@64
{CGRect={CGPoint=dd}{CGSize=dd}}32@0:8@16^@24
@"VCPFaceAnalyzer"
@"MADVIMachineReadableCodeDetectionRequest"
Q28@0:8@16f24
@"VNTorsoprint"
@36@0:8i16@20@?28
i48@0:8^{__CVBuffer=}16^{__CVBuffer=}24^{__CVBuffer=}32^{__CVBuffer=}40
i56@0:8^{__CVBuffer=}16^{__CVBuffer=}24^{__CVBuffer=}32^{__CVBuffer=}40@?48
@52@0:8@16^{__sFILE=*iiss{__sbuf=*i}i^v^?^?^?^?{__sbuf=*i}^{__sFILEX}i[3C][1C]{__sbuf=*i}iq}24C32*36^f44
i44@0:8^{__CVBuffer=}16^f24i32^f36
@80@0:8Q16@24{CGSize=dd}32{CGRect={CGPoint=dd}{CGSize=dd}}48
v40@0:8Q16Q24@?32
@44@0:8@16@24B32@?36
@48@0:8@16d24Q32@?40
@"<PVFaceProtocol>"40@0:8@"<PVPersonProtocol>"16@"NSMapTable"24@?<v@?f^B>32
@"NSString"40@0:8@"PVPersonClusterManager"16@"NSSet"24@?<v@?f^B>32
@"NSArray"44@0:8@"PVPersonClusterManager"16@"NSSet"24B32@?<v@?f^B>36
@"NSArray"48@0:8@"NSArray"16d24Q32@?<d@?@@>40
@28@0:8@16i24
@36@0:8@16i24@28
@40@0:8@16@?24^@32
v56@0:8@16@24^@32@?40@48
B48@0:8@16Q24@?32^@40
B40@0:8@16@?24^@32
B48@0:8@16@24@?32^@40
B88@0:8@16@24@32@40@48@56@?64@?72^@80
B44@0:8@16B24@?28^@36
@48@0:8@16@24@32@?40
B48@0:8@16Q24@32^@40
B72@0:8@16@24@32@40@?48@56^@64
B44@0:8@16B24@28^@36
B56@0:8@16@24@32^@40^@48
@56@0:8@16@24@32@40^@48
v56@0:8@16@?24@32@40@?48
B40@0:8Q16@?24^@32
@32@0:8@?16Q24
v48@0:8@16@24@32@?40
v40@0:8@16@24@32
v112@0:8^@16^@24^@32^@40^@48^@56^@64^@72^@80@88@96@?104
v56@0:8^@16^@24^@32@40@48
B112@0:8@16@24@32@40@48@56@64@72@?80@?88@96^@104
Q32@0:8Q16@24
v64@0:8@16@24@32@40@48@56
v56@0:8@16@24@32^@40@?48
v56@0:8@16@24@?32@?40@48
v48@0:8@16@?24@32@?40
{?="underExpose"b1}
@"PHAsset"
{CGSize=dd}16@0:8
@"MADVIDocumentRecognitionRequest"
@"VNPersonsModel"
@"MADPersonIdentificationRequest"
f40@0:8*16i24i28q32
i40@0:8^f16@24^{__CVBuffer=}32
v48@0:8@16i24i28^f32^f40
f48@0:8{CGPoint=dd}16{CGPoint=dd}32
@36@0:8@16B24Q28
v40@0:8@16@24f32f36
i40@0:8^{__CVBuffer=}16^f24@?32
i32@0:8^f16^{__CVBuffer=}24
i48@0:8^{CGRect={CGPoint=dd}{CGSize=dd}}16^{__CVBuffer=}24@32i40i44
i52@0:8^{__CVBuffer=}16^Q24f32^@36@?44
[16f]
@"VCPCNNBlurAnalyzer"
i40@0:8^{__CVBuffer=}16^{?=[7{?=iii}][7^{__CVBuffer}]}24@?32
i36@0:8^{?=iii}16i24i28i32
{?="quality"b1"statsFlags"b1"typesWide"b1}
@52@0:8^{__CVBuffer=}16I24@28@36@44
i32@0:8^^{__CVBuffer}16^I24
v28@0:8@16B24
{CF<__CVBuffer *>="value_"^{__CVBuffer}}
@56@0:8@16@24@32@40@48
@"UTType"
@52@0:8@16^{__CVBuffer=}24I32@36@44
@80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16^{__CVBuffer=}48{?=qiIq}56
@"VCPCtrTracker"
@56@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24
B40@0:8@16^@24^@32
B56@0:8@16@24@32@40^@48
i40@0:8^Q16@?24@?32
i40@0:8@16@24^@32
i44@0:8@16B24^@28^@36
B36@0:8@16B24^@28
@24@0:8B16B20
@32@0:8Q16B24B28
i32@0:8@?16@?24
i40@0:8@?16@?24B32B36
B24@0:8@?16
B36@0:8Q16B24@?28
i60@0:8Q16B24B28B32^B36@?44@?52
@"VNEntityIdentificationModel"
f24@0:8^f16
i48@0:8^f16*24f32i36@?40
v56@0:8*16q24^f32q40i48i52
v28@0:8B16@?20
v44@0:8@16B24@28@?36
@64@0:8@16@24@32@?40@48^@56
@56@0:8@16@24@32@?40^@48
v64@0:8@16@24@32@40@?48@?56
v40@0:8@16@?24@?32
v48@0:8@16@?24@?32@?40
@"VCPClusterer"
@40@0:8@16r^{?={?=qiIq}{?=qiIq}}24r^{?=qiIq}32
^{opaqueCMSampleBuffer=}
{array<float, 6UL>=[6f]}16@0:8
v40@0:8{array<float, 6UL>=[6f]}16
v40@0:8i16i20^f24^f32
{CGRect={CGPoint=dd}{CGSize=dd}}56@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16f48f52
f80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48
i92@0:8@16@24i32^{__CVBuffer=}36{?=qiIq}44{?=qiIq}68
@"VCPImagePetsKeypointsAnalyzer"
@"VCPVideoObjectTracker"
@44@0:8{?=qiIq}16f40
@76@0:8{?={?=qiIq}{?=qiIq}}16f64@68
@"VCPVideoKeyFrameResult"
{?=ii}24@0:8@16
B32@0:8^{__CVBuffer=}16@24
@"AVAssetTrack"
@"VCPPhotosFace"
@"MLModel"
@28@0:8i16f20f24
f24@0:8f16B20
@"MADVIVisualSearchGatingRequest"
B44@0:8@16i24@28^@36
i40@0:8^@16^@24@32
i52@0:8^@16@24B32Q36Q44
i56@0:8^@16@24@32Q40Q48
i72@0:8^@16^I24^i32^i40@48@56@64
i52@0:8@16@24@32B40^@44
i32@0:8@16^@24
@"VCPFaceMerger"
v32@0:8@"<SNRequest>"16@"<SNResult>"24
v32@0:8@"<SNRequest>"16@"NSError"24
v24@0:8@"<SNRequest>"16
@52@0:8{?=qiIq}16f40@44
v36@0:8r^{?=qiIq}16r^{?=qiIq}24f32
i52@0:8^{opaqueCMSampleBuffer=}16{?=qiIq}24i48
@"SNAudioStreamAnalyzer"
@"VCPCNNMetalContext"
Q40@0:8Q16Q24Q32
@20@0:8I16
@"MADVIVisualSearchRequest"
{CGRect={CGPoint=dd}{CGSize=dd}}64@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGSize=dd}48
{CGRect={CGPoint=dd}{CGSize=dd}}80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48
{CGPoint=dd}64@0:8{CGPoint=dd}16{CGRect={CGPoint=dd}{CGSize=dd}}32
i56@0:8^{__CVBuffer=}16{CGRect={CGPoint=dd}{CGSize=dd}}24
B72@0:8{?=qiIq}16{?=qiIq}40^@64
@"VCPVideoProcessorSession"
@"VCPProtoVideoKeyFrame"
@24@0:8i16i20
i52@0:8^{__sFILE=*iiss{__sbuf=*i}i^v^?^?^?^?{__sbuf=*i}^{__sFILEX}i[3C][1C]{__sbuf=*i}iq}16^f24^f32i40i44i48
{Scaler="pool_"^{__CVPixelBufferPool}"width_"i"height_"i"crop_rect_"{CGRect="origin"{CGPoint="x"d"y"d}"size"{CGSize="width"d"height"d}}"sw_scaler_"^{OpaqueVTPixelTransferSession}}
{vector<__CVBuffer *, std::allocator<__CVBuffer *>>="__begin_"^^{__CVBuffer}"__end_"^^{__CVBuffer}"__end_cap_"{__compressed_pair<__CVBuffer **, std::allocator<__CVBuffer *>>="__value_"^^{__CVBuffer}}}
v80@0:8{?={?=qiIq}{?=qiIq}}16@64@72
v96@0:8@16@24{?={?=qiIq}{?=qiIq}}32@80@88
@32@0:8@16d24
@36@0:8f16f20f24f28f32
{CGRect={CGPoint=dd}{CGSize=dd}}24@0:8f16f20
i64@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16^{__CVBuffer=}48^q56
@40@0:8@16@24Q32
@72@0:8{?={?=qiIq}{?=qiIq}}16^Q64
@40@0:8@16r^{?={?=qiIq}{?=qiIq}}24Q32
i48@0:8@16r^{?={?=qiIq}{?=qiIq}}24Q32@?40
i64@0:8@16{?=qiIq}24Q48@?56
@32@0:8@?16^B24
@"VCPAsset"
@48@0:8i16B20B24@28@36i44
i48@0:8[21{CGPoint=dd}]16^f24@32@40
@"VCPCNNHandsDetector"
@"VCPCNNHandKeypointsDetector"
@48@0:8@16@24@?32@?40
i48@0:8^{CGRect={CGPoint=dd}{CGSize=dd}}16^{__CVBuffer=}24^f32i40i44
f52@0:8^f16i24i28i32*36f44i48
i52@0:8^{__CVBuffer=}16^f24^f32f40@?44
@44@0:8@16@24@32i40
Q40@0:8^{?=Q^@^Q[5Q]}16^@24Q32
@56@0:8@16@24Q32@?40@?48
@"VCPProtoLivePhotoVariationParams"
{?="epoch"b1"flags"b1}
@28@0:8Q16B24
i48@0:8^{opaqueCMSampleBuffer=}16{?=qiIq}24
i24@0:8^{opaqueCMSampleBuffer=}16
i40@0:8@16@?24^@32
{AudioTimeStamp="mSampleTime"d"mHostTime"Q"mRateScalar"d"mWordClockTime"Q"mSMPTETime"{SMPTETime="mSubframes"s"mSubframeDivisor"s"mCounter"I"mType"I"mFlags"I"mHours"s"mMinutes"s"mSeconds"s"mFrames"s}"mFlags"I"mReserved"I}
{AudioBufferList="mNumberBuffers"I"mBuffers"[1{AudioBuffer="mNumberChannels"I"mDataByteSize"I"mData"^v}]}
@"VCPVoiceDetector"
@"VCPAudioClassifier"
@"VCPLoudnessAnalyzer"
@"VCPSongDetector"
i32@0:8^{__CVBuffer=}16^f24
i72@0:8^f16^{__CVBuffer=}24i32i36{CGRect={CGPoint=dd}{CGSize=dd}}40
@"VCPFaceClusterer"
@36@0:8i16B20B24@28
@"VCPCNNPersonDetector"
@"VCPCNNPersonKeypointsDetector"
@"MADVIRectangleDetectionRequest"
B32@0:8q16Q24
B24@0:8q16
i32@0:8@16q24
i56@0:8^@16@24@32@40Q48
i56@0:8^@16@24q32Q40Q48
i40@0:8^@16^{__CVBuffer=}24@32
i44@0:8^@16^{__CVBuffer=}24Q32B40
i32@0:8^@16^{__CVBuffer=}24
i72@0:8^@16q24Q32Q40^{__CVBuffer=}48^{__CVBuffer=}56@64
v56@0:8@16q24Q32Q40@?48
@"VCPPreAnalysisImageLoader"
@"VCPPoolBasedPixelBufferCreator"
@"VCPMAMLModel"
@44@0:8@16r^{?={?=qiIq}{?=qiIq}}24@32B40
i48@0:8^f16^{__CVBuffer=}24i32i36@40
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
@32@0:8r^16Q24
r^16@0:8
@96@0:8{?=[4]}16@80@88
@"VCPFaceGeometry"
{?="columns"[4]}
@80@0:8Q16{CGAffineTransform=dddddd}24@72
@40@0:8Q16@24@32
@88@0:8Q16{CGAffineTransform=dddddd}24f72@76B84
B32@0:8r^{CGAffineTransform=dddddd}16@24
{CGAffineTransform=dddddd}28@0:8i16^{__CVBuffer=}20
{?=[4]}84@0:8{?=[4]}16i80
@88@0:8^{__CVBuffer=}16{?=qiIq}24{?=qiIq}48@72^@80
i88@0:8^{__CVBuffer=}16{?=qiIq}24{?=qiIq}48@72@?80
i72@0:8{?={?=qiIq}{?=qiIq}}16@64
B68@0:8{?=qiIq}16{?=qiIq}40B64
@"VCPVideoFacePoseAnalyzer"
@"VCPVideoFaceMeshAnalyzer"
@"VCPFullVideoAnalyzer"
@"VCPAudioAnalyzer"
@"VCPVideoFullFaceDetector"
@"VCPSceneChangeAnalyzer"
@"VCPLightMotionAnalyzer"
@"VCPTrimAnalyzer"
@"VCPHomeKitMotionAnalyzer"
^{Rotator=^{__CVPixelBufferPool}iii^{OpaqueVTPixelRotationSession}}
i32@0:8^{__CVBuffer=}16@?24
i92@0:8^{__CVBuffer=}16^v24{?=qiIq}32{?=qiIq}56i80@?84
@"VCPMotionFlowRequest"
i52@0:8@16B24@?28^Q36^@44
@96@0:8{CGAffineTransform=dddddd}16@64@72B80B84@?88
@40@0:8i16i20Q24Q32
i56@0:8i16i20r^f24^f32Q40Q48
i60@0:8{Kernel=^fQQ}16f40f44f48f52f56
^^{Kernel}
v48@0:8@"NSDictionary"16@"NSString"24@"NSURL"32@?<v@?>40
v40@0:8@"NSString"16@"NSURL"24@?<v@?@"NSString">32
@60@0:8@16Q24@32@40B48@?52
@48@0:8@16@24Q32^@40
@64@0:8Q16@24@32@40@48@?56
i48@0:8@16Q24@?32@?40
v40@0:8@16@24^q32
v88@0:8@16#24{?={?=qiIq}{?=qiIq}}32@80
@108@0:8#16@24@32@40{?={?=qiIq}{?=qiIq}}48B96^B100
v48@0:8@16@24^q32^f40
v144@0:8@16{?={?=qiIq}{?=qiIq}}24@72{?={?=qiIq}{?=qiIq}}80^q128^f136
i64@0:8Q16@24@32@?40@?48@56
i52@0:8@16Q24B32@?36@?44
@52@0:8Q16@24B32@?36^@44
@56@0:8Q16@24@32@?40^@48
@44@0:8@16@24Q32B40
{?={?=qiIq}{?=qiIq}}32@0:8@16@24
{atomic<int>="__a_"{__cxx_atomic_impl<int, std::__cxx_atomic_base_impl<int>>="__a_value"Ai}}
i44@0:8^f16i24i28B32*36
@32@0:8Q16^{opaqueCMFormatDescription=}24
B24@0:8^{opaqueCMFormatDescription=}16
{CGSize=dd}24@0:8^{opaqueCMFormatDescription=}16
@24@0:8^{opaqueCMFormatDescription=}16
^{__CFData=}24@0:8^{opaqueCMFormatDescription=}16
^{__CFData=}28@0:8I16^{__CFData=}20
i32@0:8^{FigLivePhotoMetadata=I{FigLivePhotoMetadataV1Struct=fqffffffccSI[0{FigLivePhotoDetectedFaceV1Struct=qffffisS}]}}16@24
{CGVector="dx"d"dy"d}
@"NSMutableData"
@"VCPVideoMetaFocusAnalyzer"
@"VCPVideoMetaMotionAnalyzer"
@"VCPVideoMetaLensSwitchAnalyzer"
@32@0:8{CGPoint=dd}16
@36@0:8i16i20i24@28
@36@0:8^f16i24i28f32
i28@0:8i16@20
@44@0:8@16i24i28i32i36i40
v60@0:8*16i24i28i32^f36^f44^f52
v36@0:8^f16^f24i32
^{LandmarkDetector=iiiiiiiB^f^f^f^i^{ZPoint}^{RegressionTree}^?}
#20@0:8i16
@36@0:8i16i20i24B28B32
@"VNSession"
@40@0:8i16B20B24@28i36
i48@0:8^f16i24i28@32[3[2f]]40
i36@0:8r^v16@24i32
i72@0:8*16i24i28i32{CGPoint=dd}36{CGPoint=dd}52I68
i44@0:8*16i24i28i32^{CGPoint=dd}36
B32@0:8@"AVAssetResourceLoader"16@"AVAssetResourceLoadingRequest"24
B32@0:8@"AVAssetResourceLoader"16@"AVAssetResourceRenewalRequest"24
v32@0:8@"AVAssetResourceLoader"16@"AVAssetResourceLoadingRequest"24
B32@0:8@"AVAssetResourceLoader"16@"NSURLAuthenticationChallenge"24
v32@0:8@"AVAssetResourceLoader"16@"NSURLAuthenticationChallenge"24
@32@0:8#16Q24
@"NSURLSessionDataTask"
^{__CVBuffer=}56@0:8^{__CVBuffer=}16{CGRect={CGPoint=dd}{CGSize=dd}}24
@"VCPSegment"
^{HinkleyDetector=ffi{HinkleyStats=ffff}}
@52@0:8B16@20I28B32B36B40@?44
i40@0:8^{__CVBuffer=}16^{__CVBuffer=}24^{__CVBuffer=}32
@"<MTLDeviceSPI>"
@"<MTLCommandQueue>"
@"MPSImageBilinearScale"
@"MPSImageSpatioTemporalGuidedFilter"
v24@0:8@"PHPhotoLibrary"16
{CGSize=dd}32@0:8@16@24
i40@0:8^@16#24@32
^{__CVBuffer=}36@0:8@16@24i32
i52@0:8^@16#24@32@40B48
i48@0:8^f16@24@32@40
i40@0:8^f16@24@32
v52@0:8f16@20Q28Q36Q44
v44@0:8f16@20Q28Q36
i40@0:8@16^@24^@32
i32@0:8^@16^@24
v56@0:8@16@24@32@?40@?48
B48@0:8@16^@24@?32@?40
i48@0:8^@16^@24@?32@?40
d80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48
i72@0:8@16^@24^@32^@40^@48@?56@?64
i80@0:8@16@24@32@40@48^@56@?64@?72
i48@0:8@16@24@32@40
i64@0:8@16@24@32^@40@?48@?56
i56@0:8@16@24^@32@?40@?48
i48@0:8@16^@24@?32@?40
@"MADVIUserFeedbackRequest"
@88@0:8@16{CGAffineTransform=dddddd}24Q72^{opaqueCMFormatDescription=}80
B40@0:8@16#24@32
v32@0:8{CGPoint=dd}16
{CGPoint="x"d"y"d}
^{__CVBuffer=}16@0:8
{CGRect={CGPoint=dd}{CGSize=dd}}24@0:8@16
@"PHFetchResult"
i48@0:8^{CGPoint=dd}16[21f]24@32@40
i40@0:8^f16^{__CVBuffer=}24@32
{vector<int, std::allocator<int>>="__begin_"^i"__end_"^i"__end_cap_"{__compressed_pair<int *, std::allocator<int>>="__value_"^i}}
@"VCPCNNFastGestureRecognition"
@28@0:8f16B20B24
v40@0:8i16i20i24^f28i36
i84@0:8^{__CVBuffer=}16{CGRect={CGPoint=dd}{CGSize=dd}}24i56{?=qiIq}60
r^f16@0:8
@"VCPRTLandmarkDetector"
@"VCPFaceShapeModel"
[5@"VCPLandmarkValidator"]
B40@0:8@16Q24Q32
i32@0:8^^{__CVBuffer}16i24B28
i56@0:8@16i24Q28^^{__CVBuffer}36^I44B52
i48@0:8^{CGImage=}16i24I28Q32^^{__CVBuffer}40
i60@0:8^{CGImageSource=}16@24i32Q36^I44^^{__CVBuffer}52
^{__CVBuffer=}56@0:8i16Q20@28@36B44^I48
^{__CVBuffer=}28@0:8@16i24
^{__CVBuffer=}36@0:8@16i24Q28
^{__CVBuffer=}44@0:8@16i24Q28^I36
^{__CVBuffer=}32@0:8i16@20B28
^{__CVBuffer=}48@0:8i16Q20@28B36^I40
^{__CVBuffer=}40@0:8i16@20B28^I32
^{__CVBuffer=}36@0:8i16Q20@28
^{__CVBuffer=}44@0:8i16Q20@28^I36
i44@0:8^{__CVBuffer=}16^@24Q32B40
^{CMPhotoCompressionSession=}
^{CMPhotoDecompressionSession=}
i64@0:8^f16i24i28i32i36i40^{CGPoint=dd}44^f52f60
i52@0:8^{__CVBuffer=}16@24[21{CGPoint=dd}]32[21f]40B48
^{OpaqueAudioComponentInstance=}
@"VCPVideoMetaFocusSegment"
@48@0:8q16{?=qiIq}24
v48@0:8q16{?=qiIq}24
i32@0:8Q16Q24
i40@0:8^^{__CVBuffer}16Q24Q32
v52@0:8Q16@24i32@36@?44
v52@0:8Q16@"NSData"24i32@"NSDictionary"36@?<v@?@"NSDictionary"@"NSError">44
v52@0:8Q16@"IOSurface"24i32@"NSDictionary"36@?<v@?@"NSDictionary"@"NSError">44
v44@0:8i16@"NSData"20@"NSDictionary"28@?<v@?@"NSString"@"NSError">36
v36@0:8i16@"NSDictionary"20@?<v@?@"NSDictionary"@"NSError">28
@40@0:8@16@24d32
@24@0:8d16
v48@0:8@16@24Q32Q40
@72@0:8@16@24@32Q40Q48Q56Q64
{?={?=qiIq}{?=qiIq}}32@0:8@16f24B28
i48@0:8@16f24f28f32B36@?40
i56@0:8B16@20@28f36f40f44B48B52
f28@0:8f16@20
f48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
@36@0:8q16q24I32
i44@0:8^^{__CVPixelBufferPool}16q24q32I40
i24@0:8^^{__CVBuffer}16
{CF<__CVPixelBufferPool *>="value_"^{__CVPixelBufferPool}}
i48@0:8@16@24@?32^@40
@44@0:8B16@20B28B32B36B40
i28@0:8f16i20i24
i56@0:8@16@24@32@40@48
@"<MTLComputePipelineState>"
@"<MTLLibrary>"
i40@0:8^{__CVBuffer=}16^^{__CVBuffer}24Q32
i64@0:8@16Q24@32^^{__CVBuffer}40^^{__CVBuffer}48^@56
@"VCPSceneProcessingImageManager"
{CF<OpaqueVTPixelTransferSession *>="value_"^{OpaqueVTPixelTransferSession}}
@"<MTLCommandBuffer>"
i40@0:8^Q16^Q24@?32
@32@0:8@?16@24
v36@0:8@16Q24B32
i48@0:8@16@24^@32^@40
v44@0:8@16Q24B32@?36
i88@0:8{?=qiIq}16{?=qiIq}40{?=qiIq}64
f56@0:8i16i20^{?={?=qiIq}{?=qiIq}}24{?=qiIq}32
B40@0:8{?=qiIq}16
B64@0:8{?=qiIq}16{?=qiIq}40
@"VCPActionAnalyzer"
B24@0:8^v16
[10f]
@"VCPSceneChangeSegment"
v40@0:8q16@24@32
v40@0:8d16@24@32
i40@0:8^^{__CVBuffer}16Q24^{__CVBuffer=}32
i32@0:8^^{__CVBuffer}16Q24
i40@0:8^^{__CVBuffer}16^{CGColorSpace=}24^{__CVBuffer=}32
i56@0:8^^{__CVBuffer}16^^{__CVBuffer}24^^{__CVBuffer}32@40Q48
i48@0:8^{__CVBuffer=}16^^{__CVBuffer}24Q32Q40
@76@0:8{CGAffineTransform=dddddd}16@64B72
@40@0:8f16{CGPoint=dd}20B36
v32@0:8r^f16^v24
i32@0:8^v16^v24
i40@0:8^v16^v24^f32
f32@0:8[3[3f]]16[3f]24
i56@0:8^v16r^f24[3[3f]]32[3f]40^f48
i56@0:8^v16^v24[4f]32^v40^v48
i40@0:8^v16^v24[4f]32
i36@0:8r^f16r^f24i32
v80@0:8{?=[4]}16
[4[3f]]
@"SHMutableSignature"
@56@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48
Q56@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24
i56@0:8@16Q24@?32@?40@?48
^q16@0:8
v32@0:8^q16Q24
{?="list"^q"count"Q"size"Q}
@20@0:8f16
i80@0:8^{__CVBuffer=}16{CGRect={CGPoint=dd}{CGSize=dd}}24{?=qiIq}56
@"VCPCNNFaceLandmarkDetector"
@"VCPVideoFacePoseFilter"
[14f]
[21f]
v24@0:8^{EncodeStats=^^?^B^B^{MotionVector}^{MotionVector}^{MotionVector}^{MotionVector}^S^S^I^S^S^S^S^S^S^S^S^S^S^SIBBBii}16
@24@0:8s16B20
[200@"VCPCNNBlock"]
@"VCPMADResourceManager"
@"VCPMADResource"
q24@0:8q16
@"VCPTimer"
@"NSObject<OS_os_transaction>"
i88@0:8^{__CVBuffer=}16^v24{?=qiIq}32{?=qiIq}56@?80
@72@0:8@16{CGSize=dd}24{CGRect={CGPoint=dd}{CGSize=dd}}40
v68@0:8{CGAffineTransform=dddddd}16B64
@32@0:8^{CGImage=}16^@24
B32@0:8^{CGImage=}16^@24
@"MLMultiArray"
@32@0:8^{__CVBuffer=}16^@24
v32@0:8^{__CVBuffer=}16^{CGPoint=dd}24
^{CGPoint=dd}16@0:8
v24@0:8^{CGPoint=dd}16
^{CGPoint=dd}
^{?=^{?}^{?}^{?}^{tplTracker_resampler_context}^{?}}
mcpl
v024
v024
mcpl
gepj
ARGB
@(#)PROGRAM:MediaAnalysis  PROJECT:MediaAnalysis-1
fff>
mcpl)
333?
#/;GS_k
L>N2ma15EncodeStatsAVE1E
B`e>;
$CV&
C2wACA
?16MAComputeRequest
'3?H
>N2ma19SubtleMotionSegmentE
?33s?22MAImageAnalysisRequest
NSt3__120__shared_ptr_emplaceI25VCPImageHumanPoseAnalyzerNS_9allocatorIS1_EEEE
fff?
"<Vp
N2ma17SlowMotionSegmentE
ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+%
14VCPProtoBounds
@pEff
B>fff?
G!?=
Ga>R
=q=J
ff&?R
Q8?H
?N4dlib7array2dIhNS_33memory_manager_stateless_kernel_1IcEEEE
N4dlib10enumerableIhEE
N4dlib33memory_manager_stateless_kernel_1IhEE
?333?
?333?
>N2ma12TrackSegmentE
N2ma11EncodeStatsE
?N2ma17DescriptorSegmentE
u?ff&?
>fff
'7NSt3__120__shared_ptr_emplaceI21VCPCNNEspressoContextNS_9allocatorIS1_EEEE
20MAImageComputeResult
<0L&=!
<yX(=4
<0L&=!
<yX(=
b=;p
Sc=;p
<5^:
e=X94
Y=X94</n#
=B`e<M
u`=e
w=B`e
N2ma18ObstructionSegmentE
MbP?
?ffffff
N4dlib17sequence_kernel_2INS_21lbfgs_search_strategy11data_helperENS_33memory_manager_stateless_kernel_1IcEEEE
N4dlib10enumerableINS_21lbfgs_search_strategy11data_helperEEE
N4dlib7removerINS_21lbfgs_search_strategy11data_helperEEE
N4dlib33memory_manager_stateless_kernel_1IdEE
NSt3__110__function6__funcINS_6__bindIPFdRKN4dlib6matrixIdLl0ELl0ENS3_33memory_manager_stateless_kernel_1IcEENS3_16row_major_layoutEEEPfSB_SB_SB_bEJRKNS_12placeholders4__phILi1EEERSB_SJ_RA12_fRA126_fbEEENS_9allocatorISO_EEFdS8_EEE
NSt3__110__function6__baseIFdN4dlib6matrixIdLl0ELl0ENS2_33memory_manager_stateless_kernel_1IcEENS2_16row_major_layoutEEEEEE
NSt3__16__bindIPFdRKN4dlib6matrixIdLl0ELl0ENS1_33memory_manager_stateless_kernel_1IcEENS1_16row_major_layoutEEEPfS9_S9_S9_bEJRKNS_12placeholders4__phILi1EEERS9_SH_RA12_fRA126_fbEEE
NSt3__118__weak_result_typeIPFdRKN4dlib6matrixIdLl0ELl0ENS1_33memory_manager_stateless_kernel_1IcEENS1_16row_major_layoutEEEPfS9_S9_S9_bEEE
NSt3__110__function6__funcINS_6__bindIPFN4dlib6matrixIdLl0ELl0ENS3_33memory_manager_stateless_kernel_1IcEENS3_16row_major_layoutEEERKS8_PfSB_SB_SB_bEJRKNS_12placeholders4__phILi1EEERSB_SJ_RA12_fRA126_fbEEENS_9allocatorISO_EEFS8_S8_EEE
NSt3__110__function6__baseIFN4dlib6matrixIdLl0ELl0ENS2_33memory_manager_stateless_kernel_1IcEENS2_16row_major_layoutEEES7_EEE
NSt3__16__bindIPFN4dlib6matrixIdLl0ELl0ENS1_33memory_manager_stateless_kernel_1IcEENS1_16row_major_layoutEEERKS6_PfS9_S9_S9_bEJRKNS_12placeholders4__phILi1EEERS9_SH_RA12_fRA126_fbEEE
NSt3__118__weak_result_typeIPFN4dlib6matrixIdLl0ELl0ENS1_33memory_manager_stateless_kernel_1IcEENS1_16row_major_layoutEEERKS6_PfS9_S9_S9_bEEE
NSt3__117bad_function_callE
N4dlib11fatal_errorE
N4dlib5errorE
NSt3__110__function6__funcINS_6__bindIPFdRKN4dlib6matrixIdLl0ELl0ENS3_33memory_manager_stateless_kernel_1IcEENS3_16row_major_layoutEEEPfSB_SB_SB_SB_SB_SB_PiSB_SB_EJRKNS_12placeholders4__phILi1EEERSB_RA12_fSK_SK_SK_SK_SB_SC_SK_SK_EEENS_9allocatorISN_EEFdS8_EEE
NSt3__16__bindIPFdRKN4dlib6matrixIdLl0ELl0ENS1_33memory_manager_stateless_kernel_1IcEENS1_16row_major_layoutEEEPfS9_S9_S9_S9_S9_S9_PiS9_S9_EJRKNS_12placeholders4__phILi1EEERS9_RA12_fSI_SI_SI_SI_S9_SA_SI_SI_EEE
NSt3__118__weak_result_typeIPFdRKN4dlib6matrixIdLl0ELl0ENS1_33memory_manager_stateless_kernel_1IcEENS1_16row_major_layoutEEEPfS9_S9_S9_S9_S9_S9_PiS9_S9_EEE
NSt3__110__function6__funcINS_6__bindIPFN4dlib6matrixIdLl0ELl0ENS3_33memory_manager_stateless_kernel_1IcEENS3_16row_major_layoutEEERKS8_PfSB_SB_SB_SB_SB_SB_PiSB_SB_SB_EJRKNS_12placeholders4__phILi1EEERSB_RA12_fSK_SK_SK_SK_SB_SC_SK_SK_SK_EEENS_9allocatorISN_EEFS8_S8_EEE
NSt3__16__bindIPFN4dlib6matrixIdLl0ELl0ENS1_33memory_manager_stateless_kernel_1IcEENS1_16row_major_layoutEEERKS6_PfS9_S9_S9_S9_S9_S9_PiS9_S9_S9_EJRKNS_12placeholders4__phILi1EEERS9_RA12_fSI_SI_SI_SI_S9_SA_SI_SI_SI_EEE
NSt3__118__weak_result_typeIPFN4dlib6matrixIdLl0ELl0ENS1_33memory_manager_stateless_kernel_1IcEENS1_16row_major_layoutEEERKS6_PfS9_S9_S9_S9_S9_S9_PiS9_S9_S9_EEE
NSt3__110__function6__funcINS_6__bindIPFdRKN4dlib6matrixIdLl0ELl0ENS3_33memory_manager_stateless_kernel_1IcEENS3_16row_major_layoutEEEPfSB_EJRKNS_12placeholders4__phILi1EEERA126_fRA189_fEEENS_9allocatorISN_EEFdS8_EEE
NSt3__16__bindIPFdRKN4dlib6matrixIdLl0ELl0ENS1_33memory_manager_stateless_kernel_1IcEENS1_16row_major_layoutEEEPfS9_EJRKNS_12placeholders4__phILi1EEERA126_fRA189_fEEE
NSt3__118__weak_result_typeIPFdRKN4dlib6matrixIdLl0ELl0ENS1_33memory_manager_stateless_kernel_1IcEENS1_16row_major_layoutEEEPfS9_EEE
=AB/'
R[DmPJ>
@Z_g@
@333?
>43s?433?LL
@333?
?N2ma20SubjectMotionSegmentE
228VCPProtoImageHumanPoseResult
@oDA
ffffff
?333333
N2ma14QualitySegmentE
N2ma19CameraMotionSegmentE
?N2ma19MovingObjectSegmentE
:L=ix
/ L[
AGA)\
N2ma22InterestingnessSegmentE
16VCPProtoKeypoint
,=zz
22MAMovieAnalysisRequest
!&/+
xfua2vpe
?ff
N2ma12SceneSegmentE
333333
@lwh
N2ma15RotationSegmentE
N2ma15EncodeStatsAVE2E
N2ma13EncodeStatsHWE
BN2ma24FineSubjectMotionSegmentE
333?fff?ff
N2ma7SegmentE
N2ma13EncodeStatsSWE
 ,8DP\ht
Q9RI
Q9RI
7:RI
Q9RI
d*;4
>;_)K;
DX;B`e;
{r;l
k;B`e;
Q;_)K;
#;RI
7:RI
Q9RI
d*;4
7;_)K;
DX;B`e;
{r;o
{r;B`e;
DX;_)K;4
d*;RI
7:RI
Q9RI
7;_)K;
y;KY
3"<U
-<X94<
b<B`e<
4o<E
{r<!
ew<l
{r<E
h<B`e<e
#9<X94<
3"<RI
^;_)K;4
7:RI
Q9RI
k;KY
Q:RI
Q9RI
k:RI
DX;$
d*<4
?F<4
DX;4
Q:RI
>;B`e;'
#<X94<
z<KY
$=yX(=V
7=5^:=[
2D=]mE=
?F=]mE=
2D=\
<=5^:=
-2=2
+=yX(=
D<X94<
;B`e;
>;RI
{r<&
=R' =T
b=B`e=B>h=h
4o= Aq=
{r=F
{r= Aq=
(m=h
j=B>h=B`e=e
WJ=9
E6=|
%=R' =Qk
k:RI
7;B`e;
?$=V
b=B>h=D
s=Gry=
\~=n
\~=Gry=F
m=B>h=e
?$=v
;B`e;4
DX;'
3"<4
=R' =U
(=W[1=Z
B=_)K=a
S=d]\=
d=d]\=a
S=_)K=\
9=W[1=U
(=R' =P
j<<b
ew=I
{r<b
j<<>
ew<M
ew<>
=yX(=
A=;pN=
h=k+v=n
=k+v=
[=;pN=
5=yX(=
ew<b
7:RI
{r<M
7x=J{
/>:#
O/<N
=yX(=Y
U=B`e=
9#>/
$>0L&>
d*>1
'>0L&>/
Yu=B`e=
?F=Y
7=yX(=u
7;KY
=z6+=
/;=:
K=d]\=D
m=I.
V,>i
9>lx:>
<>6<=>
=>6<=>
;>lx:>l
u1>i
V,>
m=d]\=:
/;=z6+=
;_)K;
{r<)\
q,=6<==
Ga=F
s=J{
u >/
!N>`vO>
|P>`vO>
2D>7
~;>~
N=6<==
;_)K;o
<X94<
=z6+=6<==
ew=o
G!>ff&>
+>io0>F%5>
9>[B>>%uB>
qJ>_
QZ>?
+e>x
F>%uB>[B>>
9>F%5>io0>
+>ff&>
P=6<==z6+=u
/]<X94<r
Q9RI
{r<N
=yX(=
x=p_
/>aT
X>RI]>
Ga>f
n>W[q>}
=y>lxz>Zd{>
|>HP|>HP|>
|>Zd{>lxz>
s>W[q>
rh>f
Ga>RI]>P
/>o
/;=yX(=
y;RI
d*;KY
d*<b
ew=p_
2>Gr9>[
sW>v
8g>1
|>n4
3b>v
?>Gr9>
%>d;
Ga=:
d*<o
?F=d]\=F
8V>?
c>gDi>
t>5^z>$
>5^z>
4o>gDi>
s=d]\=
<;p
:_)K;RI
=yX(=
m=J{
P>>yX>
_>>yX>
kI>n
v>=yX(=
;_)K;
T<KY
L=B`e=I.
..>}
6>I.?>
h>iop>~
x>iop>
DX>r
G>I.?>}
c>]
=B`e=
;B`e;X9
c<)\
>B>(>W[1>lx:>
C>lx:>W[1>B>(>-!
;B`e;o
5=;pN=
>R' >z
!=>]
|P>]
g3>z
)>R' >b
xi=;pN=
{r;'
>R' >
m4>m
ZS>-
-r>HP|>
>HP|>
J*>R' >
?F<N
h=J{
H?>:#J>+
U>:#J>
m4>z
)>-!
=R' =
sW=k+v=(
>B>(>
g3>m
>>:#J>=
U>w-a>
l>w-a>=
U>:#J>m
g3>B>(>
=k+v=
:=R' =
#<B`
d*;u
Sc=n
%>W[1>
U>w-a>
\m>~
\m>w-a>+
!=>W[1>
Jj<1
d*;RI
=W[1=
..>lx:>]
ZS>]
F>lx:>
AO=W[1=
5<HP
7;RI
|P>-
:_)K;|
?$=\
Sc=o
/>>y
2>I.?>_
6Z>_
L>I.?>
%>>y
/>n4
Sc=\
;_)K;4
+=_)K=
(m=p
q,>#
q?_
q?h
q,>d;
(m=_)K=V
ew=r
\m>HP|>
c?r
>HP|>
%>>y
ew=a
2=tF
:B`e;
9=d]\=I
=d]\=Z
9=Qk
u`<RI
;B`e;
=R' =
d=&S
:p>7
R&?t
@=R' =
l=q=
~*>Gr9>p
H>>yX>
f%?=
+?-C,?
,?-C,?
h>>yX>p
H>Gr9>
{r<U
:0>[
_>iop>I
;.?{
;.?$
@"?$
>iop>
G!><
;X94<
fU=$
>ff&>
y'?u
c,?r
0?EG2?}
7?^K8?Y
8?^K8?
+5?}
3?EG2?
c,?u
y'?j
8V>9
5>ff&>
fU=|
<X94<B`
?n4 ?
,?I./?
1?I./?D
#?n4 ?
E6=tF
u >io0>
t>J{
$?B>(?
1?X94?
6?X94?
+?B>(?
@>io0>
@=B>h=
$>F%5>
sW>gDi>
V?E
%?gD)?
,?R'0?
S3?0L6?
>?R'@?
8E?a
B?R'@?_
9?0L6?
S3?R'0?
,?gD)?"
V?0
~{>gDi>
F>F%5>/
=B>h=
B<HP
41?4
=?io@?
H?q=J?
~K?(~L?6<M?H
M?6<M?(~L?
~K?q=J?U
B?io@?d
41?h
4o>v
WJ=F
s=Nb
->[B>>r
4!?"
1?]m5?
I<?Di??aTB?
O?2UP?
aQ?2UP?
E?aTB?Di??
8?]m5?
3b>r
O>[B>>V
=yX(=
N=Gry=*
0>%uB>
8g>5^z>
?n4 ?
$?gD)?h
F?GrI?
HN?2UP?
&R?F
V?p_W?
W?p_W?
&R?2UP?
K?GrI?}
-?gD)?
$?n4 ?
>5^z>
T>%uB>|
=Gry=
N=yX(=
Q<KY
S#>4
#?B>(?
41?]m5?c
A?o
X?GrY?
Z??W[?
[?h"\?h"\?
[??W[?
Z?GrY?~
\=?c
9?]m5?
,?B>(?
S#><
ZS=V
Y<RI
sW=n
qJ>RI]>
+?R'0?4
D?yXH?q
Q?tFT?}
Z?HP\?
_?R'`?
h`?R'`?$
]?HP\?h
V?tFT?n
K?yXH?
4?R'0?
p>RI]>
qJ>~
sW=2
<RI
~;>_
|@?o
D?yXH?
UO?A
R?]mU?~
c?=,d?Ttd?Ttd?=,d?
X?]mU?A
K?yXH?o
Ga>_
~;>
y'?D
1?0L6?
:?Di??
UO?X
.^?Nb`?aTb?
d?]me?
eg?+
Dh?+
f?]me?
d?aTb?Nb`?
UO?q
C?Di??
:?0L6?
V,>,
<B`e<
b='1
rh>[
*?I./?X94?
=?aTB?}
U?gDY?
I\?gDY?
F?aTB?d
9?X94?I./?u
rh>O
/>G
<B`e<
=5^:=B`e=q=
k>n4
;?io@?
E?GrI?
Q?]mU?
&b?O
(l?mVm??5n?
n??5n?mVm?
X?]mU?n
M?GrI?
E?io@?
=B`e=5^:=
<=B>h=
q?aT
:P?tFT?~
m?-!o?
Np?-!o?
X?tFT?
a!>r
=B>h=[
4o<z6
9#>X
\>W[q>
f%?
;?R'@?
g?U0j?
n?2Up?N
q?2Up?
l?U0j?
E?R'@?C
>W[q>?
(m=M
G!?=
,?EG2?
K?2UP?O
\?Nb`?}
?t?]mu?KYv?
v?KYv?]mu?
?t?<
c?Nb`?$
T?2UP?
7?EG2?$
G!?Zd
{r<V}
>0L&>l
;.?}
&R?+
^?aTb?
t?KYv?
w?>yx?
y?,ey?,ey?
y?>yx?
w?KYv?
e?aTb?
J9?}
9>0L&>tF
4o=\
B=Qk
2D= Aq=
'>lx:>
!N>x
8E?q=J?
X?HP\?
m?2Up?<
v?'1x?
ky?'1x?
r?2Up?
H`?HP\?~
O?q=J?
+5?{
!N>lx:>
= Aq=
t<RI
=]mE=
;>`vO>x
~K?2UP?
U?GrY?
a?]me?5
(l?-!o?N
?t?KYv?'1x?^
{?(~|?
|?(~|?
y?'1x?KYv?
?t?N
q?-!o?
(l?5
h?]me?
]?GrY?
U?2UP?
=y>x
d>`vO>
{r=]mE=
u<RI
ew<3
?F=F
+e>lxz>B>
eG?(~L?
aQ?4
j?mVm?
Np?S
s?]mu?
/|?q
w?]mu?S
Np?mVm?
aQ?(~L?
>lxz>
^)>=
?F=RI
)>6<=>
e>Zd{>9
R&?-C,?
$H?6<M?
V??W[?$
eg?c
j??5n?
s?KYv?>yx?
Wz?>yx?KYv?
4q??5n?c
_??W[?
&R?6<M?
2?-C,?
A ?:#
>Zd{>
4Q>6<=>
Yu=*
2?^K8?
R?p_W?
[?R'`?=,d?+
z?(~|?H
}?(~|?
g?=,d?R'`?
[?p_W?
=?^K8?\
d*>+
f>HP|>L7
W?h"\?
h`?Ttd?
Dh?6
>w?,ey?
C{?,ey?
Dh?Ttd?
h`?h"\?
!>?Y
>HP|>B
 <X9
f>HP|>L7
W?h"\?
h`?Ttd?
Dh?6
>w?,ey?
C{?,ey?
Dh?Ttd?
h`?h"\?
!>?Y
>HP|>B
 <X9
Yu=*
2?^K8?
R?p_W?
[?R'`?=,d?+
z?(~|?H
}?(~|?
g?=,d?R'`?
[?p_W?
=?^K8?\
d*>+
)>6<=>
e>Zd{>9
R&?-C,?
$H?6<M?
V??W[?$
eg?c
j??5n?
s?KYv?>yx?
Wz?>yx?KYv?
4q??5n?c
_??W[?
&R?6<M?
2?-C,?
A ?:#
>Zd{>
4Q>6<=>
ew<3
?F=F
+e>lxz>B>
eG?(~L?
aQ?4
j?mVm?
Np?S
s?]mu?
/|?q
w?]mu?S
Np?mVm?
aQ?(~L?
>lxz>
^)>=
?F=RI
=]mE=
;>`vO>x
~K?2UP?
U?GrY?
a?]me?5
(l?-!o?N
?t?KYv?'1x?^
{?(~|?
|?(~|?
y?'1x?KYv?
?t?N
q?-!o?
(l?5
h?]me?
]?GrY?
U?2UP?
=y>x
d>`vO>
{r=]mE=
u<RI
2D= Aq=
'>lx:>
!N>x
8E?q=J?
X?HP\?
m?2Up?<
v?'1x?
ky?'1x?
r?2Up?
H`?HP\?~
O?q=J?
+5?{
!N>lx:>
= Aq=
t<RI
{r<V}
>0L&>l
;.?}
&R?+
^?aTb?
t?KYv?
w?>yx?
y?,ey?,ey?
y?>yx?
w?KYv?
e?aTb?
J9?}
9>0L&>tF
4o=\
B=Qk
(m=M
G!?=
,?EG2?
K?2UP?O
\?Nb`?}
?t?]mu?KYv?
v?KYv?]mu?
?t?<
c?Nb`?$
T?2UP?
7?EG2?$
G!?Zd
4o<z6
9#>X
\>W[q>
f%?
;?R'@?
g?U0j?
n?2Up?N
q?2Up?
l?U0j?
E?R'@?C
>W[q>?
<=B>h=
q?aT
:P?tFT?~
m?-!o?
Np?-!o?
X?tFT?
a!>r
=B>h=[
=5^:=B`e=q=
k>n4
;?io@?
E?GrI?
Q?]mU?
&b?O
(l?mVm??5n?
n??5n?mVm?
X?]mU?n
M?GrI?
E?io@?
=B`e=5^:=
<B`e<
b='1
rh>[
*?I./?X94?
=?aTB?}
U?gDY?
I\?gDY?
F?aTB?d
9?X94?I./?u
rh>O
/>G
<B`e<
y'?D
1?0L6?
:?Di??
UO?X
.^?Nb`?aTb?
d?]me?
eg?+
Dh?+
f?]me?
d?aTb?Nb`?
UO?q
C?Di??
:?0L6?
V,>,
~;>_
|@?o
D?yXH?
UO?A
R?]mU?~
c?=,d?Ttd?Ttd?=,d?
X?]mU?A
K?yXH?o
Ga>_
~;>
Y<RI
sW=n
qJ>RI]>
+?R'0?4
D?yXH?q
Q?tFT?}
Z?HP\?
_?R'`?
h`?R'`?$
]?HP\?h
V?tFT?n
K?yXH?
4?R'0?
p>RI]>
qJ>~
sW=2
<RI
S#>4
#?B>(?
41?]m5?c
A?o
X?GrY?
Z??W[?
[?h"\?h"\?
[??W[?
Z?GrY?~
\=?c
9?]m5?
,?B>(?
S#><
ZS=V
=yX(=
N=Gry=*
0>%uB>
8g>5^z>
?n4 ?
$?gD)?h
F?GrI?
HN?2UP?
&R?F
V?p_W?
W?p_W?
&R?2UP?
K?GrI?}
-?gD)?
$?n4 ?
>5^z>
T>%uB>|
=Gry=
N=yX(=
Q<KY
WJ=F
s=Nb
->[B>>r
4!?"
1?]m5?
I<?Di??aTB?
O?2UP?
aQ?2UP?
E?aTB?Di??
8?]m5?
3b>r
O>[B>>V
41?4
=?io@?
H?q=J?
~K?(~L?6<M?H
M?6<M?(~L?
~K?q=J?U
B?io@?d
41?h
4o>v
@=B>h=
$>F%5>
sW>gDi>
V?E
%?gD)?
,?R'0?
S3?0L6?
>?R'@?
8E?a
B?R'@?_
9?0L6?
S3?R'0?
,?gD)?"
V?0
~{>gDi>
F>F%5>/
=B>h=
B<HP
u >io0>
t>J{
$?B>(?
1?X94?
6?X94?
+?B>(?
@>io0>
?n4 ?
,?I./?
1?I./?D
#?n4 ?
E6=tF
;X94<
fU=$
>ff&>
y'?u
c,?r
0?EG2?}
7?^K8?Y
8?^K8?
+5?}
3?EG2?
c,?u
y'?j
8V>9
5>ff&>
fU=|
<X94<B`
:0>[
_>iop>I
;.?{
;.?$
@"?$
>iop>
G!><
l=q=
~*>Gr9>p
H>>yX>
f%?=
+?-C,?
,?-C,?
h>>yX>p
H>Gr9>
{r<U
=R' =
d=&S
:p>7
R&?t
@=R' =
:B`e;
9=d]\=I
=d]\=Z
9=Qk
u`<RI
;B`e;
ew=r
\m>HP|>
c?r
>HP|>
%>>y
ew=a
2=tF
+=_)K=
(m=p
q,>#
q?_
q?h
q,>d;
(m=_)K=V
:_)K;|
?$=\
Sc=o
/>>y
2>I.?>_
6Z>_
L>I.?>
%>>y
/>n4
Sc=\
;_)K;4
|P>-
=W[1=
..>lx:>]
ZS>]
F>lx:>
AO=W[1=
5<HP
7;RI
d*;u
Sc=n
%>W[1>
U>w-a>
\m>~
\m>w-a>+
!=>W[1>
Jj<1
d*;RI
=R' =
sW=k+v=(
>B>(>
g3>m
>>:#J>=
U>w-a>
l>w-a>=
U>:#J>m
g3>B>(>
=k+v=
:=R' =
#<B`
h=J{
H?>:#J>+
U>:#J>
m4>z
)>-!
>R' >
m4>m
ZS>-
-r>HP|>
>HP|>
J*>R' >
?F<N
5=;pN=
>R' >z
!=>]
|P>]
g3>z
)>R' >b
xi=;pN=
{r;'
;B`e;X9
c<)\
>B>(>W[1>lx:>
C>lx:>W[1>B>(>-!
;B`e;o
T<KY
L=B`e=I.
..>}
6>I.?>
h>iop>~
x>iop>
DX>r
G>I.?>}
c>]
=B`e=
:_)K;RI
=yX(=
m=J{
P>>yX>
_>>yX>
kI>n
v>=yX(=
;_)K;
?F=d]\=F
8V>?
c>gDi>
t>5^z>$
>5^z>
4o>gDi>
s=d]\=
<;p
d*;KY
d*<b
ew=p_
2>Gr9>[
sW>v
8g>1
|>n4
3b>v
?>Gr9>
%>d;
Ga=:
d*<o
Q9RI
{r<N
=yX(=
x=p_
/>aT
X>RI]>
Ga>f
n>W[q>}
=y>lxz>Zd{>
|>HP|>HP|>
|>Zd{>lxz>
s>W[q>
rh>f
Ga>RI]>P
/>o
/;=yX(=
y;RI
<X94<
=z6+=6<==
ew=o
G!>ff&>
+>io0>F%5>
9>[B>>%uB>
qJ>_
QZ>?
+e>x
F>%uB>[B>>
9>F%5>io0>
+>ff&>
P=6<==z6+=u
/]<X94<r
;_)K;
{r<)\
q,=6<==
Ga=F
s=J{
u >/
!N>`vO>
|P>`vO>
2D>7
~;>~
N=6<==
;_)K;o
7;KY
=z6+=
/;=:
K=d]\=D
m=I.
V,>i
9>lx:>
<>6<=>
=>6<=>
;>lx:>l
u1>i
V,>
m=d]\=:
/;=z6+=
=yX(=Y
U=B`e=
9#>/
$>0L&>
d*>1
'>0L&>/
Yu=B`e=
?F=Y
7=yX(=u
{r<M
7x=J{
/>:#
O/<N
=yX(=
A=;pN=
h=k+v=n
=k+v=
[=;pN=
5=yX(=
ew<b
7:RI
j<<>
ew<M
ew<>
j<<b
ew=I
{r<b
DX;'
3"<4
=R' =U
(=W[1=Z
B=_)K=a
S=d]\=
d=d]\=a
S=_)K=\
9=W[1=U
(=R' =P
7;B`e;
?$=V
b=B>h=D
s=Gry=
\~=n
\~=Gry=F
m=B>h=e
?$=v
;B`e;4
{r<&
=R' =T
b=B`e=B>h=h
4o= Aq=
{r=F
{r= Aq=
(m=h
j=B>h=B`e=e
WJ=9
E6=|
%=R' =Qk
k:RI
>;B`e;'
#<X94<
z<KY
$=yX(=V
7=5^:=[
2D=]mE=
?F=]mE=
2D=\
<=5^:=
-2=2
+=yX(=
D<X94<
;B`e;
>;RI
DX;$
d*<4
?F<4
DX;4
Q:RI
Q9RI
k:RI
Q9RI
k;KY
Q:RI
Q9RI
7;_)K;
y;KY
3"<U
-<X94<
b<B`e<
4o<E
{r<!
ew<l
{r<E
h<B`e<e
#9<X94<
3"<RI
^;_)K;4
7:RI
Q9RI
d*;4
7;_)K;
DX;B`e;
{r;o
{r;B`e;
DX;_)K;4
d*;RI
7:RI
Q9RI
d*;4
>;_)K;
DX;B`e;
{r;l
k;B`e;
Q;_)K;
#;RI
7:RI
Q9RI
7:RI
Q9RI
B>q=J?
~|zxvuusqpnmkjiggfecba`_^]]\[ZYXWVUTTSRQQPONNMMLKKJIIHGGGFFEDDCCBBBAA@@??>>===<<;;:::999888776666555444333322211110000////.....----,,,,+++++*****)))))((((('''''''&&&&&&%%%%%%$$$$$$$########""""""!!!!!!!!!        X|E
+>>%I
%@ %@
timeRange
confidence
B8@?0
variation = %6.2f
creationDate
uuid
mediaanalysisd
private/com.apple.mediaanalysisd/caches/vision
verifiedType = %@ OR verifiedType = %@
B24@?0@"PHPerson"8@"NSDictionary"16
asset in (%@)
any person.personUUID in %@
total-allowed
ANY detectedFaces.uuid IN %@
PVPersonClusterManager
Unable to find class %s
v8@?0
com.apple.mediaanalysis.reachability
Not c
None
TransientConnection
Reachable
ConnectionRequired
ConnectionOnTraffic
InterventionRequired
ConnectionOnDemand
IsLocalAddress
IsDirect
IsWWAN
qualityScore
distanceToPreviousScene
flickerScore
sceneprintDistanceToPreviousScene
SceneResults
QualityResults
CameraMotionResults
SubjectMotionResults
FineSubjectMotionResults
SubtleMotionResults
TrackSegments
OrientationResults
IrisRecommendResults
IrisSharpnessResults
PreEncodeResults
MovingObjectsResults
FeatureVectorResults
SceneprintResults
ObstructionResults
InterestingnessResults
flags
quality
attributes
start
duration
distance
sceneprintDistance
featureVector
Data
orientation
objectBounds
slowMoFlicker
sceneprint
index
junk
summaryTimerange
duplicate
MetaFocusResults
MetaMotionResults
MetaMotionProcessedResults
q24@?0@"PHAssetResource"8@"PHAssetResource"16
B16@?0@"PHAssetResource"8
mammal
bird
people
adult
animal
stuffed_animals
fire
fireplace
embers
flame
beach
liquid
ocean
lake
creek
river
snow
jacuzzi
pool
grass
plant
coral_reef
foliage
tree
grill
waterways
shore
waterfall
thunderstorm
manhole
aurora
light
spotlight
smoking_item
flag
flagpole
underwater
candle
kettle
teapot
storm
tornado
lightning
blossom
surfing
pyrotechnics
blizzard
fountain
billboards
curtain
lamp
drinking_glass
fondue
blender
storefront
garden
shrub
firecracker
bubble_soap
watersport
haze
volcano
aquarium
fishtank
flower
seaweed
jellyfish
fish
flashlight
bonfire
smoking
lakeshore
sparkler
sparkling_wine
shower
geyser
actionScore
v32@?0@"NSNumber"8@"VCPFace"16^B24
v32@?0@"NSNumber"8@"VCPVideoObjectTracker"16^B24
q24@?0@"VCPFace"8@"VCPFace"16
/tmp/
v32@?0@"NSNumber"8@"VNFaceprint"16^B24
v32@?0@"NSNumber"8@"NSNumber"16^B24
Home face identification task cancelled
No face present in face crop
Photos identity model not present
%@ | %@
{{%.*g, %.*g}, {%.*g, %.*g}}
timestamp
qualityScoreForLivePhoto
visualPleasingScore
overallFaceQualityScore
exposureScore
penaltyScore
textureScore
sharpness
faceResults
globalQualityScore
contentScore
expressionChangeScore
vector
v24@?0Q8^B16
v32@?0@"NSNumber"8Q16^B24
VCPClusteringStatusIsClustering
VCPClusteringStatusClusterRebuildRequired
VCPClusteringStatusEligibleFacesCount
VCPClusteringStatusPendingFacesCount
VCPSuggestionUpdateStarted
VCPSuggestionUpdateFinished
VCPSuggestionUpdateCancelled
com.apple.mediaanalysisd.clusterer.processing
com.apple.mediaanalysis.scheduleclustering
VCPFaceProcessingClusterFacesCoreAnalyticsCollection
v24@?0@"NSString"8^B16
com.apple.mediaanalysisd.photos.faceclustering
ClusteringSequence
FacesAddToClustering
FacesRemoveFromClustering
FacesInClusterBeforeClustering
ClusteringInterval
TotalAssetCount
ProcessingQoS
com.apple.mediaanalysisd.optional_clustering
com.apple.mediaanalysisd.forced_clustering
Operation cancelled
v32@?0@"NSNumber"8@"NSOrderedSet"16^B24
VCPVisionFgMapping_Prepare
v32@?0@"NSCountedSet"8Q16^B24
q24@?0@"NSCountedSet"8@"NSCountedSet"16
v24@?0@"NSNumber"8^B16
VCPClusterCompareTimestamp
VCPClusterer: Failed to get face CSNs from cluster cache, which should not be used
PVErrorInvalidClusterCacheFile - %@
VCPClusterer: Failed to get Vision cluster state - %@
VisionClusterState
clusteringType
threshold
VCPClusterer: Failed to archive cluster snapshot
VCPClusterer: Failed to rename file from '%@' to '%@'. Error = %d
VCPClusterer: Failed to write cluster snapshot to file '%@'
missing parameter clusterState
VCPClusterer: Cluster snapshot file '%s' is too small
VCPClusterer: Invalid magic number found in '%s'
VCPClusterer: Invalid version in '%s', %d != %d
VCPClusterer: Failed to read MD5 from header of '%s'
VCPClusterer: Failed to compute MD5 of '%s'
VCPClusterer: Failed MD5 check for '%s'
VCPClusterer: Failed to read size of vision cluster state blob from '%s'
VCPClusterer: Failed to read vision cluster state blob from '%s'
VCPClusterer: Failed to open cluster cache file '%s'
cmap
CVMLClusterState
CVMLClusteringAlgorithm_Greedy
VCPClusterer: Failed to restore cluster cache
VCPClusterer: Failed to restore cluster cache std::exception %s
VCPClusterer: Failed to restore cluster cache due to device ran out of memory
VCPClusterer needs a full sync
missing updateHandler
VCPClusterer is not ready
VCPClusterer: Failed to get suggestions from Vision framework %@
v32@?0@"VNCluster"8Q16^B24
v32@?0@"NSSet"8Q16^B24
q24@?0@"NSMutableSet"8@"NSMutableSet"16
VCPClustererBringUpState
clustererState.plist
need full sync
need to compare clusters
need to reset cluster cache
need to reset library clusters
need update
ready
clustering
have unsaved cluster cache
saving cluster cache
have new cluster cache
unknown (error)
AlgoFaceClusterCache.data
temp
Error: failed to processImage
highlightScore
@"VCPMADVIRemoveBackgroundResource"8@?0
VCPMADVIRemoveBackgroundTask
Image loading failed
Failed to obtain image from Vision
Multiple cadence options specified
%@ value must be NSNumber
%@ value must be poisitive
%@ is not supported
v32@?0@"NSString"8@16^B24
v24@?0@"NSDictionary"8@"NSError"16
Full analysis asset processing task cancelled
[%@] Failed to analyze on-demand
VCPFullAnalysisAssetProcessingTask processing failed
AllowOnDemand
InProcess
SceneprintRevision
com.apple.mediaanalysis.service.management
com.apple.mediaanalysis.service.handler
MediaAnalysisService
Error issuing sandbox extension
v16@?0d8
[MediaAnalysis] Error connecting to background analysis service
v16@?0@"NSError"8
Assets from multiple libraries not supported
v24@?0@"NSString"8@"NSError"16
PersonProcessingDeletePersons
PersonProcessingClusterFaces
PersonProcessingIncrementalFaceClustering
PersonProcessingRunBuildPersons
PersonProcessingIncrementalPersonBuilding
PersonProcessingRunPromotePersons
PersonProcessingRebuildFaceIDModel
PersonProcessingClassifyContactPictures
faceCSN
faceIdentifier
personIdentifier
personFaceCount
confirmed
status
requestAdvancedStatus
advancedStatus
PLPhotoAnalysisVisionServiceFaceReclusteringThreshold
PLPhotoAnalysisVisionServiceFaceReclusteringDeletePersons
PLPhotoAnalysisVisionServiceFaceReclusteringShouldRecluster
personLocalIdentifier
v24@?0@"NSArray"8@"NSError"16
v20@?0B8@"NSError"12
model_info.json
net_file
revision
config
loadModel
res_256x160
res_160x256
cnn_human_pose_lite_v2.espresso.net
input
before filter: frame(%d): time_stamp=%f, ave_motion=(%f,%f)
frame(%d): time_stamp=%f, ave_motion=(%f,%f), acc_var=(%f, %f), motion_chg=(%f, %f)
q24@?0@8@16
VCPMADImageSafetyClassificationResource
@"VCPMADImageSafetyClassificationResource"8@?0
[ImageSafety] Before decode
Image pre-processing failed
[ImageSafety] Before inference
CVNLPCommSafetyHandler unavailable
[ImageSafety] After inference
[VCPPhotosFace] Missing faceObservation and humanObservation
@"VNRequest"16@?0#8
@"VNObservation"24@?0@"NSUUID"8@"VNRequest"16
[VCPPhotosFace] Invalid faceprint and torsoprint
[VCPPhotosFace] Unable to serialize faceTorsoprint - %@
[VCPPhotosFace] Unable to determine normalized face bounding { { %f, %f } { %f, %f } }
%@ (%@), %@ (v%d) (%.2f, %.2f, %.2f) (%.2f, %.2f, %.2f, %.2f) quality: %.2f
Human
bounds
cnn_facepose.espresso.net
VCPPoseEspresso
@"VCPCNNModelEspresso"8@?0
quality_head.espresso.net
output
ImageAnalysis
MovieAnalysis
MAComputeRequestClass
q24@?0@"VNClassificationObservation"8@"VNClassificationObservation"16
q24@?0@"VCPClassification"8@"VCPClassification"16
featureBlob
checksum
data
SceneprintHyperplaneLSH, 
NeuralHyperplaneLSH, 
Unknown
com.apple.mediaanalysisd.timer
rawTime
homography
keypoints
v32@?0@"PHFace"8Q16^B24
VNFaceGazeDirectionUnknown
VNFaceGazeDirectionCamera
VNFaceGazeDirectionAnotherFace
VNFaceGazeDirectionCommonLocation
VNFaceGazeDirectionSomewhereElse
VNFaceGazeDirectionDifficultToSay
Error VNFaceGazeDirection: %lu
PHFaceGazeTypeCannotInferGaze
PHFaceGazeTypeLookingAtCamera
PHFaceGazeTypeLookingAtAnotherFace
PHFaceGazeTypeLookingAtCommonLocation
PHFaceGazeTypeOther
Error PHFaceGazeType: %d
sceneprintBlob
absoluteScore
relativeScore
humanScore
faceId
Action
NumOfValidFrames
ActionScore
seg %d: [%d, %d], sceneCut=%d
prev(%d) [%d, %d][%6.1f, %6.1f] qs = %6.2f, curr(%d) [%d, %d] [%6.1f, %6.1f]qs = %6.2f:
dist({%d %d}, {%d %d}) = %6.2f, th = %6.2f
prev: type = %d, fast = %d, gmv_sum {%6.1f, %6.1f}, merge = %d, split = 0
curr: type = %d, fast = %d, gmv_sum {%6.1f, %6.1f}, merge = %d, split = 0
segments
cnn_content.dat
v16@?0^{opaqueCMSampleBuffer=}8
MediaAnalysis
SceneNetV5
eyeExpression
mouthExpression
position
isCloseup
faceQuality
VCPMADVIResource
curationScore
com.apple.MediaAnalysis
com.apple.mediaanalysisd
forceCPU
forceNNGraph
sharedContext
shared 
VCPWallpaperAnalyzer.sharedModelPool
@"VCPObjectPool"8@?0
quantized_9hy8wvx5wz_iteration_47_model.espresso.net
quantized_5c7q2hh2zk_iteration_35_model.espresso.net
height
width
com.apple.mediaanalysis.VCPClientDatabaseManager
/tmp/com.apple.mediaanalysisd/VideoCaptionEncoderTest/
/tmp/com.apple.mediaanalysisd/VideoCaptionDecoderTest/
/tmp/com.apple.mediaanalysisd/ImageCaptionModelTest/
com.apple.MobileAsset.VCPMobileAssets
v16@?0q8
Model
AssetName
Version
VideoCaptionEncoder
v16@?0@"MAProgressNotification"8
v24@?0q8@"NSError"16
ClonedVideoCaptionDecoder
ClonedVideoCaptionEncoder
com.apple.mediaanalysis.VCPVideoTrackSyncDecoder
classification
[VCPVNImageprintWrapper] Invalid imageprint type %lu
Cannot calculate distance - missing the other imageprint
Cannot calculate distance - mismatched imageprint type (%lu vs %lu)
Cannot calculate distance - mismatched versions (%d vs %d)
Cannot calculate distance - unarchive self.data - %@
Cannot calculate distance - unarchive theOtherImageprint.data - %@
torso-only
face-only
Cannot get distance between faceprints. Distance function returns nil
type: %lu, version: %d, and data[length:%lu]: <%p>
v32@?0@"NSNumber"8@"NSArray"16^B24
com.apple.mediaanalysis.VCPSharedInstanceManager
VCPAnalysisProgressQueryScanPhotoLibraryFetch
faceAdjustmentVersion != nil
mediaAnalysisAttributes.characterRecognitionAttributes.algorithmVersion >= %d
mediaAnalysisAttributes.visualSearchAttributes.algorithmVersion >= %d
additionalAttributes.sceneAnalysisVersion >= %d &&  additionalAttributes.sceneAnalysisVersion != %d
VCPAnalysisProgressQueryExpressPathFetchTotalCount
VCPAnalysisProgressQueryExpressPathFetchProcessedCount
VCPAnalysisProgressQueryProgressDetail
VCPAnalysisProgressQueryProgress
VCPAnalysisProgressQueryCachedFaceAnalysisProgress
SalientRegions
bound
plistRepresentation
q24@?0@"VCPSaliencyRegion"8@"VCPSaliencyRegion"16
hand_keypoint_detector_acc.espresso.net
cnn_moflow.espresso.net
landscape_1024x448
square_320x320
input_image_1
input_image_2
zeros
landscape_384x256
landscape_448x320
landscape_640x512
landscape_896x640
portrait_256x384
portrait_320x448
portrait_512x640
portrait_640x896
square_256x256
square_512x512
square_640x640
VCPMoflowEspresso
com.apple.mediaanalysis.VCPVideoProcessorSession
Video processing requests must have completion handler
Specified request already active; cannot add
Failed to create request with specified configuration
Specified request not found; cannot remove
Sample buffer does not contain video frame
Sample buffer must contain uncompressed video
faceSharpness
vnpersonsmodel.bin
vnpetsmodel.bin
Point0
Point1
Radius
Theta
Length
Hand_waving
Hand_clapping
Dancing
Walking
Running
Jumping
cnn_human_action.espresso.net
salientRegion
salientScore
q24@?0@"NSDictionary"8@"NSDictionary"16
/var/mobile/Media/MediaAnalysis
private/com.apple.mediaanalysisd/MediaAnalysis
mediaanalysis.db
kindSubtype != %d
kind == %d
PhotoAnalysisServicePreferences.plist
faceWorkerState.plist
(faceAlgorithmVersion = %d) AND (clusterSequenceNumber = 0) AND (((hidden = 0) AND (manual = 0) AND ((trainingType = %d) OR (trainingType = nil))) OR ((trainingType = %d) OR (trainingType = %d) OR (trainingType = %d)))
SyndPL
Tracking
TrackingScore
AveStats
Failed to parse AVE statistics frame attachment; re-generating statistics
summaryIsTrimmed
livePhoto
movie
AutoplayScore
MotionScore
SubjectScore
ExposureChange
landscape_1024x432
privECMVct
privEMBVct
privDFArray
privET
privImgG
privTZF
privAFS
privAFSt
privFM
relSampleTime
trajectoryHomography
presentingTimestampInNanos
originalPresentingTimestampInNanos
sequenceAdjusterRecipe
sequenceAdjusterDisplacement
interpolatedFrame
LivePhotoMetadataSetupDataVersion
FrameworkVersions
CMCaptureCore
Error: failed to analyze motion flow
mediaAnalysisVersionState.plist
VCPFaceProcessingVersionManager-%@
@"VCPFaceProcessingVersionManager"8@?0
FaceProcessingInternalVersion
Reset none
Reset AnalysisStates
Reset Clustering
shotType
basic_string
humanPoseResults
version
AutoLoop
Bounce
LongExposure
Stabilize
NormStabilizeInstructions
MinVersion
Params
loopFlavor
loopEnergy
outputFrameDur
stabCropRect
stabilizeResult
Width
Height
frameInstructions
face_model_tensor.dat
face_model_landmark_coordinates.dat
face_model_boundary.dat
com.apple.mediaanalysisd.VCPFaceShapeUpdate
Error detected at line 
Error detected in file 
Submodules/dlib/dlib/optimization/optimization.h
Error detected in function 
double dlib::find_min_box_constrained(search_strategy_type, stop_strategy_type, const funct &, const funct_der &, T &, const matrix_exp<EXP1> &, const matrix_exp<EXP2> &) [search_strategy_type = dlib::lbfgs_search_strategy, stop_strategy_type = dlib::objective_delta_stop_strategy, funct = std::function<double (dlib::matrix<double, 0, 0>)>, funct_der = std::function<dlib::matrix<double, 0, 0> (dlib::matrix<double, 0, 0>)>, T = dlib::matrix<double, 51, 1>, EXP1 = dlib::matrix_op<dlib::op_uniform_matrix_3<double>>, EXP2 = dlib::matrix_op<dlib::op_uniform_matrix_3<double>>]
Failing expression was 
is_col_vector(x) && is_col_vector(x_lower) && is_col_vector(x_upper) && x.size() == x_lower.size() && x.size() == x_upper.size()
double find_min_box_constrained()
 The inputs to this function must be equal length column vectors.
 is_col_vector(x):       
 is_col_vector(x_upper): 
 x.size():               
 x_lower.size():         
 x_upper.size():         
The objective function generated non-finite outputs
 ************************** FATAL ERROR DETECTED ************************** 
 ************************** FATAL ERROR DETECTED ************************** 
 ************************** FATAL ERROR DETECTED ************************** 
Two fatal errors have been detected, the first was inappropriately ignored. 
To prevent further fatal errors from being ignored this application will be 
terminated immediately and you should go fix this buggy program.
The error message from this fatal error was:
**************************** FATAL ERROR DETECTED ****************************
******************************************************************************
EPORT_IN_USE
ETIMEOUT
ECONNECTION
ELISTENER
ERESOLVE
EMONITOR
ECREATE_THREAD
ECREATE_MUTEX
ECREATE_SIGNALER
EUNSPECIFIED
EGENERAL_TYPE1
EGENERAL_TYPE2
EGENERAL_TYPE3
EINVALID_OPTION
ETOO_FEW_ARGS
ETOO_MANY_ARGS
ESOCKET
ETHREAD
EGUI
EFATAL
EBROKEN_ASSERT
EIMAGE_LOAD
EDIR_CREATE
EINCOMPATIBLE_OPTIONS
EMISSING_REQUIRED_OPTION
EINVALID_OPTION_ARG
EMULTIPLE_OCCURANCES
ECONFIG_READER
EIMAGE_SAVE
ECAST_TO_STRING
ESTRING_CAST
EUTF8_TO_UTF32
EOPTION_PARSE
undefined error type
iteration: 
   objective: 
Submodules/dlib/dlib/matrix/matrix.h
const dlib::matrix::literal_assign_helper &dlib::matrix<double, 2, 2>::literal_assign_helper::operator,(const T &) const [T = double, num_rows = 2, num_cols = 2, mem_manager = dlib::memory_manager_stateless_kernel_1<char>, layout = dlib::row_major_layout]
r < m->nr() && c < m->nc()
You have used the matrix comma based assignment incorrectly by attempting to
supply more values than there are elements in the matrix object being assigned to.
Did you forget to call set_size()?
 r: 
 c: 
 m->nr(): 
 m->nc(): 
dlib::matrix<double, 2, 2>::literal_assign_helper::~literal_assign_helper() [T = double, num_rows = 2, num_cols = 2, mem_manager = dlib::memory_manager_stateless_kernel_1<char>, layout = dlib::row_major_layout]
!has_been_used || r == m->nr()
You have used the matrix comma based assignment incorrectly by failing to
supply a full set of values for every element of a matrix object.
const dlib::matrix::literal_assign_helper &dlib::matrix<double, 2, 1>::literal_assign_helper::operator,(const T &) const [T = double, num_rows = 2, num_cols = 1, mem_manager = dlib::memory_manager_stateless_kernel_1<char>, layout = dlib::row_major_layout]
dlib::matrix<double, 2, 1>::literal_assign_helper::~literal_assign_helper() [T = double, num_rows = 2, num_cols = 1, mem_manager = dlib::memory_manager_stateless_kernel_1<char>, layout = dlib::row_major_layout]
You have to supply column vectors to this function
double dlib::find_min_using_approximate_derivatives(search_strategy_type, stop_strategy_type, const funct &, T &, double, double) [search_strategy_type = dlib::lbfgs_search_strategy, stop_strategy_type = dlib::objective_delta_stop_strategy, funct = std::function<double (dlib::matrix<double, 0, 0>)>, T = dlib::matrix<double, 6, 1>]
is_col_vector(x) && derivative_eps > 0
double find_min_using_approximate_derivatives()
x.nc():         
derivative_eps: 
cnn_landmark.espresso.net
VCPFaceLandmarkEspresso
mediaanalysis://asset.mov
VCPMADVITextLookupTask
@"VIImage"8@?0
Failed to create text lookup query context
v24@?0@"VITextLookupResult"8@"NSError"16
VIService_TextLookup
vanishingPoint
dominantLine
v32@?0@"NSString"8@"NSNumber"16^B24
<%@ %p, 
active cost: %d,
inactive cost: %d>
cnn_smile.espresso.net
VCPSmileEspresso
highlight_head.espresso.net
input1
input2
var_165
CVPixelbuffer not IOSurface backed
activityID: %@, 
startTime: %@, 
duration: %f(sec), 
exitStatus: %d>
idx (%tu) is out of range (%tu)
timeValue
homographyParam
timeScale
epoch
errorCode
loopFadeLen
loopPeriod
loopStart
sport
cnn_activitylevel.dat
HighlightMaxDuration
HighlightTargetDuration
HighlightStartRange
HighlightTolerance
HighlightIndex
HighlightBestTrim
HighlightFullResult
v32@?0@"VCPMovieHighlight"8Q16^B24
com.apple.homekitanalysis.session.management
com.apple.homekitanalysis.session.handler
[HomeKit] XPC connection invalidated. Please restart the session.
No result handler registered
No VCPHomeKitAnalysisSession; cannot process message
HMIVideoAnalyzer
com.apple.mediaanalysis.sql
SELECT id, version, dateModified, dateAnalyzed, analysisTypes, flags, quality, masterFingerprint, adjustedFingerprint
, statsFlags
 FROM Assets WHERE localIdentifier=(?);
SELECT resultsType, results FROM Results WHERE assetId=(?);
SELECT resultsType, results FROM Results WHERE assetId=(?
) AND resultsType IN (?
SELECT id, localIdentifier, version, dateModified, dateAnalyzed, analysisTypes, flags, quality, masterFingerprint, adjustedFingerprint
 FROM Assets WHERE localIdentifier IN (?
SELECT assetId, resultsType, results FROM Results WHERE assetId IN (?
SELECT date FROM Blacklist WHERE localIdentifier=(?) AND count>=(?);
i8@?0
SELECT localIdentifier FROM Blacklist WHERE count>=(?) AND localIdentifier IN (?
SELECT localIdentifier FROM Blacklist WHERE count>=(?);
SELECT localIdentifier FROM Assets WHERE dateAnalyzed>=(?) UNION SELECT localIdentifier FROM Blacklist WHERE count>=(?) AND date>=(?);
SELECT localIdentifier, status, attempts, date FROM ProcessingStatus WHERE taskID=(?) AND status!=(?) AND localIdentifier IN (?
SELECT localIdentifier FROM ProcessingStatus WHERE taskID=(?) AND status=(?);
SELECT COUNT(*) FROM ProcessingStatus WHERE taskID=(?) AND status=(?);
SELECT value FROM KeyValueStore WHERE key = (?);
SELECT activityID, startTime, duration, exitStatus FROM BackgroundActivitySchedulingHistory WHERE activityID=(?) AND startTime>=(?);
value
timescale
Orientation
Regions
Home resident maintenance task cancelled
HMITaskService
[VCPMADServiceImageProcessing] Specified identifier not found (%@)
[ImageProcessingTask%d] Identifier %@
Request was canceled
VCPVideoCNNBackboneEspresso
video_backbone.espresso.net
AveragePool_258_out
ReduceMean_264
Add_182_out
Pad_257_out
activityScore
ErrorCode
@"VNSession"8@?0
com.apple/PhotoVision/FaceCrop/
PVFC
PVFC:PVFC
PVFC_VER
PVFC_FB
PVFC_CB
PVFC_GID
tiff:Orientation
Could not set output orientation
Could not register face crop namespace
Could not generate serialized metadata representation
Could not convert metadata representation into serialized format
Could not set face crop metadata
Could not create image source
No meta data exists on image
unexpected nil image source
invalid image source
zero dimensioned face rect submitted
could not create cropped face crop image
could not create face crop metadata
public.jpeg
could not create face crop data
could not write face crop data
VCPFaceCropUtils : newFaceCropFromImageData - %@
image url is nil
Could not create image ref
Could not create face rect
VCPFaceCropUtils:newFaceCropFromImageURL - %@
image data is nil
Could not create image source from data
VCPFaceCropUtils:newFaceCropFromImageData - %@
invalid face crop supplied
VCPFaceCropUtils:faceBoundsFromFaceCrop -- %@
VCPFaceCropUtils:cropBoundsInOriginalImageFromFaceCrop -- %@
the supplied data is not a facecrop
could not create an image source
Could not retrieve image properties
VCPFaceCropUtils:faceCropDimensionsFromFaceCrop -- %@
could not create image ref
Could not create image for rendering
Could not create buffer for rendering
Could not create srgb colorspace
Could not create cropped and subsampled image
Could not create bitmap context
Face
@"VCPMADMachineReadableCodeResource"8@?0
VCPMADVIMachineReadableCodeDetectionTask
flow_estimation_%d
t_38
v16@?0^{?=ii*}8
interestScore
com.apple.mediaanalysisd.realtime
ContentType
faceMetadataArray
realtimeFaceRect
realtimeFaceRoll
realtimeFaceYaw
PriorityScore
v32@?0@8Q16^B24
%@ <%p>:
  person1LocalIdentifier  : %@
  person2LocalIdentifier  : %@
  reason                  : %@
asset.dateCreated
asset.addedDate
asset.filename
centerX
centerY
(verifiedType = %d) OR (verifiedType = %d)
(faceAlgorithmVersion = %d) AND (((hidden = 0) AND (manual = 0) AND ((trainingType = %d) OR (trainingType = nil))) OR ((trainingType = %d) OR (trainingType = %d) OR (trainingType = %d)))
(clusterSequenceNumber > 0)
(manual == 0) AND (faceAlgorithmVersion = %d)
Could not access the library
Canceled operation to get CSNs of faces missing from the library
v40@?0@"NSArray"8{_NSRange=QQ}16^B32
v32@?0@"NSString"8@"PHFetchResult"16^B24
(clusterSequenceNumber in %@)
Canceled operation to ungroup faces
v16@?0^B8
Canceled operation to uncluster faces
(clusterSequenceNumber = 0)
((clusterSequenceNumber > 0) AND (faceGroup = nil))
could not access the library
Canceled operation to cleanup grouped faces with CSN=0
No faceGroups found for person with localIdentifier '%@'
Failed to fetch faces from the faceGroup that contributed the most number of face to person with localIdentifier '%@'
(clusterSequenceNumber in %@) AND (trainingType = %d OR trainingType = %d OR trainingType = %d)
(clusterSequenceNumber in %@) AND (trainingType = %d OR trainingType = %d)
v32@?0@"PHPerson"8Q16^B24
v32@?0@"NSNumber"8@"NSSet"16^B24
photoLibrary is nil
trainingType != %d
VisionFgMapping_LookingAfterNewClusteredFace
VisionFgMapping_LookingForConflictingCluster
VisionFgMapping_ResolveConflictingCluster
v32@?0@"NSNumber"8@"NSDictionary"16^B24
VisionFgMapping_ResolveConflictL0Clusters
VisionFgMapping_Process
clusterSequenceNumber IN %@
@"PHFace"16@?0@"NSNumber"8
Saving clustering results cancelled
Canceled operation to reset library clusters
keyFace == nil
[UpdateKeyFaces] Failed to find persons %@
-[VCPPhotosPersistenceDelegate updateKeyFacesOfPersonsWithLocalIdentifiers:forceUpdate:cancelOrExtendTimeoutBlock:error:]
[UpdateKeyFaces] Operation canceled
Unimplemented %s in VCPPhotosPersistenceDelecate
-[VCPPhotosPersistenceDelegate invalidFaceClusterSequenceNumbersInClusterSequenceNumbers:canceler:error:]
-[VCPPhotosPersistenceDelegate ungroupFaceClusterSequenceNumbers:batchSizeForUnclusteringFaces:canceler:error:]
-[VCPPhotosPersistenceDelegate cleanupUngroupedFacesWithNonZeroClusterSequenceNumbersWithCanceler:error:]
-[VCPPhotosPersistenceDelegate cleanupGroupedFacesWithClusterSequenceNumberSetToZeroWithCanceler:error:]
-[VCPPhotosPersistenceDelegate persistChangesToAlgorithmicFaceGroups:faceCSNByLocalIdentifierForNewlyClusteredFaces:faceCSNsOfUnclusteredFaces:localIdentifiersOfUnclusteredFaces:persistenceCompletionBlock:canceler:error:]
-[VCPPhotosPersistenceDelegate resetLibraryClustersWithCanceler:error:]
-[VCPPhotosPersistenceDelegate updateKeyFacesOfPersonsWithLocalIdentifiers:forceUpdate:canceler:error:]
-[VCPPhotosPersistenceDelegate bestRepresentativeFaceForPerson:qualityMeasureByFace:canceler:]
-[VCPPhotosPersistenceDelegate bestRepresentativeFaceForPerson:qualityMeasureByFace:candidateFaces:canceler:]
-[VCPPhotosPersistenceDelegate associateFace:withFaceCrop:error:]
-[VCPPhotosPersistenceDelegate clearDirtyStateOnFaceCrops:error:]
-[VCPPhotosPersistenceDelegate dirtyFaceCropsWithLimit:]
-[VCPPhotosPersistenceDelegate faceAssociatedWithFaceCrop:]
-[VCPPhotosPersistenceDelegate facesFromAsset:]
-[VCPPhotosPersistenceDelegate persistFaces:deleteFaces:forAsset:persistedFaces:error:]
-[VCPPhotosPersistenceDelegate persistGeneratedFaceCrops:error:]
-[VCPPhotosPersistenceDelegate recordNeedToPersonBuildOnFaceGroupContainingFace:error:]
-[VCPPhotosPersistenceDelegate suggestedPersonLocalIdentifierForPersonLocalIdentifier:faceClusterer:canceler:context:error:]
-[VCPPhotosPersistenceDelegate updateFaceprint:ofPersistedFace:error:]
-[VCPPhotosPersistenceDelegate buildPersonsWithFaceClusterer:keyFaceUpdateBlock:canceler:context:extendTimeoutBlock:]
(personBuilderState = %ld)
Canceled cleaning up merge candidates of verified persons
v24@?0@"PHFetchResult"8@"NSMutableSet"16
v24@?0@"VCPMergeCandidatePair"8^B16
Canceled cleaning up merge candidates
(trainingType = %d) || (trainingType = %d)
v32@?0@"PHPerson"8@"NSString"16^B24
B24@?0@"VCPMergeCandidatePair"8@"NSDictionary"16
(clusterSequenceNumber IN %@)
Person building cancelled
clusterSequenceNumber = %ld
clusterSequenceNumber != %ld
[FaceCropAdjustment][%@-%d]
v32@?0@"NSString"8@"PHFaceCrop"16^B24
v32@?0@"PHFace"8@"PHPerson"16^B24
v24@?0@"NSDictionary"8q16
v32@?0@"NSString"8@"NSMutableArray"16^B24
q24@?0@"PHFaceCrop"8@"PHFaceCrop"16
v32@?0@"PHFaceCrop"8Q16^B24
MADProcessNewlyClusteredFaceCrops
invalid merge candidate pair created from cluster rejections
potential invalid merge candidate pair created from cluster rejections
invalid merge candidate pair from cluster rejection for verified person
potential invalid merge candidate pair from cluster rejection for verified person
B16@?0^@8
no training faces in level1 cluster - create 'unverified person : verified/migrated person' candidate pair
all training faces on single verified person in level1 cluster - create 'unverified person : training person' candidate pair
all training faces on single verified person in level1 cluster - create 'unverified person : verified person' candidate pair
all training faces on single verified person in level1 cluster - create 'training person : verified person' candidate pair
invalid merge candidate pair because we may have a dirty level0 cluster
multiple training persons in level0 cluster - create 'training person : training person' pair
clusterSequenceNumber
single training person in level0 cluster - create 'training person : verified person with confirmed face' pair
single training person in level0 cluster - create 'verified persons with confirmed face : verified persons with confirmed face' pair
invalid merge candidate pair because one person has face rejected for the other
invalid merge candidate pair because we have > 3 verified persons in the face group
single training person in level1 cluster - create 'training person : verified person with confirmed face' pair
single training person in level1 cluster - create 'verified persons with confirmed face : verified persons with confirmed face' pair
level1 cluster - create 'training person : training person' pair
level1 cluster - create 'unverifed person : training person' pair
invalid merge candidate pair: a cluster rejection
v32@?0@"NSMutableSet"8@"NSMapTable"16@"NSSet"24
invalid merge candidate pair:a face on verified person but cluster-rejected on another verified person
-[VCPPhotosPersistenceDelegate buildPersonWithFaceClusterer:keyFaceUpdateBlock:context:cancelOrExtendTimeoutBlock:]
VCPFaceProcessingBuildPersonsCoreAnalyticsCollection
com.apple.mediaanalysisd.photos.personbuilding
BuildingInterval
BuildingSequence
ClusterCount
ClusterFaceCount
FaceGroupCount
FaceGroupCountNeedToBuild
faceLocalIdentifier is nil
fetched %lu faces for %@
clusterSequenceNumber is nil
personLocalIdentifier is nil
fetched %lu persons for %@
Got a 'nil' photoLibrary. Cannot remove auto assigned faces
(manual = 0) AND ((nameSource = %d) OR (nameSource = %d) OR (nameSource = %d)) AND ((trainingType = %d) OR (trainingType = nil))
Operation to remove faces from verified persons has been canceled
Failed to removed faces from person with localIdentifiers '%@'
not known
PGGraphHelper
exposure
underExpose
q24@?0@"PHSceneClassification"8@"PHSceneClassification"16
@"VCPMADVIDocumentRecognitionResource"8@?0
VCPMADVIDocumentRecognitionTask
VCPMADPersonIdentificationTaskResource
@"VCPMADPersonIdentificationTaskResource"8@?0
VCPMADPersonIdentificationTask
[%@] Failed to configuate VNDetectFaceRectanglesRequest
[%@] Failed to configuate VNCreateFaceprintRequest
[%@] Failed to detect faces - %@
q24@?0@"VNFaceObservation"8@"VNFaceObservation"16
[%@] Failed to print faces - %@
{{x:%.*f, y:%.*f}, {width:%.*f, height:%.*f}} 
com.apple.mediaanalysis
com.apple.mediaanalysisd.analysis
com.apple.mediaanalysisd.photos
com.apple.mediaanalysisd.homekit
com.apple.mediaanalysisd.homekitsession
dateModified
dateAnalyzed
masterFingerprint
adjustedFingerprint
performedAnalysisTypes
statsFlags
metadataRanges
SyncPoint
FaceResults
ShotTypeResults
VoiceResults
MLQualityResults
JunkResults
BlurResults
ExposureResults
MLCameraMotionResults
DistanceResults
SaliencyResults
CompositionResults
ClassificationResults
MusicResults
UtteranceResults
ActivityLevelResults
FacePrintResults
PetsResults
PetsFaceResults
PetsKeypointsResults
PetsActionResults
MovieSummaryResults
SettlingEffectsGatingResults
MovieHighlightResults
MovieHighlightScoreResults
MLHighlightScoreResults
KeyFrameResults
KeyFrameBlurResults
KeyFrameStillResults
TrackingResults
LivePhotoEffectsResults
ParallaxResults
WallpaperExportResults
WallpaperPosterConfigDataResults
FaceQualityResults
SceneChangeResults
ApplauseResults
BabbleResults
CheeringResults
LaughterResults
AudioQualityResults
HumanPoseResults
HumanActionResults
HumanPoseInternalResults
HandsResults
LoudnessResults
KeyFrameResourceResults
VideoStabilizationResults
SongResults
HumanActionClassificationResults
InterpolationResults
WPResults
RotationAnalysisResults
ColorNormalizationResults
VideoCaptionResults
ImageCaptionResults
SettlingEffectResults
FaceQualityFlag
energyValues
peakValues
facePosition
faceBounds
facePoseYaw
facePrint
sharpnessFaces
saliencyBounds
saliencyConfidence
songSignature
wallpaperScore
probableRotation
probableRotationConfidence
colorNormalizationData
vanishingPointConfidence
neighbor
neighborDateModified
gyroStabilization
analysisConfidence
stabilizationRecipe
interpolationURL
settlingEffectURL
petsBounds
petsConfidence
petsKeypoints
petsAction
petsAbsoluteScore
petsRelativeScore
keyFrameTime
keyFrameScore
bestPlaybackCrop
maxHighlightStart
maxHighlightDuration
audioQuality
loopSuggestionState
longExposureSuggestionState
livePhotoEffectsRecipe
livePhotoEffectsGatingDescriptions
livePhotoEffectsMatchingScenes
aesthetic
sceneClassification
saliency
saliencyObjectness
duplicateMatchingFeature
duplicateMatchingAlternateFeature
overallScore
allScores
wellFramedSubjectScore
wellChosenBackgroundScore
tastefullyBlurredScore
sharplyFocusedSubjectScore
wellTimedShotScore
pleasantLightingScore
pleasantReflectionsScore
harmoniousColorScore
livelyColorScore
pleasantSymmetryScore
pleasantPatternScore
immersivenessScore
pleasantPerspectiveScore
pleasantPostProcessingScore
noiseScore
failureScore
pleasantCompositionScore
interestingSubjectScore
intrusiveObjectPresenceScore
pleasantCameraTiltScore
lowKeyLightingScore
acceptableCrop
preferredCrop
humanBounds
humanKeypoints
humanConfidence
humanID
humanActions
torsoPrint
handsBounds
handsKeypoints
handsKeypointsConfidents
handsID
videoCaptionText
videoCaptionConfidence
imageCaptionText
imageCaptionConfidence
frameQualityScore
faceQualityScore
sharpnessScore
texture
stillTime
flashFired
QualityOfService
DutyCycling
VCPTaskIDs
ForcePublish
GyroStabilization
PixelStabilization
MaxNumberOfAssetToProcess
ForceFullScan
Full Face, 
Face, 
Voice, 
Full Scene, 
Scene, 
Junk, 
Blur, 
Exposure, 
Distance, 
Feature, 
Saliency, 
Composition, 
Classification, 
ActivityLevel, 
CurationScore, 
Pets, 
PetsPose, 
MovieCuration, 
Effects, 
Parallax, 
Wallpaper Export, 
Face Quality, 
Audio Classification, 
Human pose, 
Loudness Measure, 
Hands, 
Video Stabilization Pixel, 
Video Stabilization Gyro, 
Gyro Analytics, 
ML Video Attributes, 
Song detection, 
Settling effect, 
Human action, 
Iris Recommendation, 
Video Caption, 
Audio Quality, 
v32@?0@"NSString"8@"NSArray"16^B24
mShortInputDecision
mPreGateStillMetadataDecision
mPreGateVideoTrimDecision
mPreGateVideoMLDecision
mPreGateFacesDecision
stabilizeGateDecision
postGateDecision
finalDecision
loopActivityDecision
bounceActivityDecision
longexpActivityDecision
ALGatingResultError
ALGatingResultUnset
ALGatingResultFail
ALGatingResultPass
SceneAnalysis
FaceAnalysis
EffectsAnalysis
Sceneprint
VideoStabilization
MultiWorkerAnalysis
QuickFaceIdentification
EmbeddingAnalysis
OCRAnalysis
MovieHighlightProcessing
VisualSearchAnalysis
FilesystemAnalysis
Unknown(%lu)
autobahn-nature
autobahn-city
autobahn-citynatureish
otgx_csfbtu_gfnbmf
otgx_csfbtu_nbmf
otgx_cvuupdlt
otgx_hfojubmt_gfnbmf
otgx_hfojubmt_nbmf
otgx_opof
otgx_voefsxfbs
otgx_boz
otgx_fyqmjdju
otgx_hfojubmt
meme_document_check_or_checkbook
meme_curation_meme
meme_curation_screenshot
meme_document_boarding_pass
meme_document_currency_or_bill
meme_document_driving_license
meme_document_office_badge
meme_document_passport
meme_document_receipt
meme_document_social_security_number
meme_hier_negative
meme_hier_document
meme_hier_curation
meme_negative
meme_document
meme_screenshot_etc
hier_text_document
hier_tragic_failure
tragic_failure
screenshot
bad_framing
bad_lighting
blurry
food_or_drink
junk_other
medical_reference
negative
receipt_or_document
repair_reference
shopping_reference
utility_reference
junk_negative
hier_negative
junk_non_memorable
hier_non_memorable
junk_poor_quality
hier_poor_quality
No Resource
Download Throttled
Soft Failure
Hard Failure
Duplicate Failure
Upload Failure
PhotoLibraries
ImageTooSmall
UsingBestResource
FacesToDelete
FacesToPersist
VisionClustersMinusLibraryClusters
LibraryClustersMinusVisionClusters
failed
processed
pet-vip-status
person-vip-status
prioritized-processed
prioritized-total-allowed
full-analysis-complete-processed
full-analysis-partial-processed
Confidence
BoundingBox
UserInteractive
UserInitiated
Default
Utility
Background
Unspecified
OptInStatus
FileURL
GroundTruthURL
PersonIdentifier
PersonInformation
UserLabeledGender
UserLabeledAge
UserLabeledEthnicity
ModifyPersonRequest
SubTasks
NumberOfAssetsAllowedForPhotosFaceProcessing
NumberOfAssetsAnalyzedForPhotosFaceProcessing
NumberOfPrioritizedAssetsAnalyzedForPhotosFaceProcessing
NumberOfPrioritizedAssetsAllowedForPhotosFaceProcessing
Success
Canceled
Status Error
Parameter Error
Unknown Error
resident: %@, virtual: %@, phys_footprint: %@, phys_footprint_peak: %@.
resident: N/A, virtual: N/A, phys_footprint: N/A, phys_footprint_peak: N/A.
supportedRevisions
supportedPrivateRevisions
MediaAnalysisVersion
LatestVersionTimeStamp
MediaAnalysisCompleteTimestamp
MediaAnalysisProgressPercentage
SceneAnalysisVersion
LatestSceneAnalysisVersionTimestamp
SceneAnalysisCompleteTimestamp
SceneAnalysisProgressPercentage
FaceAnalysisVersion
LatestFaceAnalysisVersionTimestamp
FaceAnalysisCompleteTimestamp
FaceAnalysisProgressPercentage
PrioritizedFaceAnalysisCompleteTimestamp
PrioritizedFaceAnalysisProgressPercentage
OCRAnalysisVersion
LatestOCRAnalysisVersionTimestamp
OCRAnalysisCompleteTimestamp
OCRAnalysisProgressPercentage
VisualSearchAnalysisVersion
LatestVisualSearchAnalysisVersionTimestamp
VisualSearchAnalysisCompleteTimestamp
VisualSearchAnalysisProgressPercentage
EmbeddingAnalysisVersion
LatestEmbeddingAnalysisVersionTimestamp
EmbeddingAnalysisCompleteTimestamp
EmbeddingAnalysisProgressPercentage
Bytes
%llu %@
Error: failed to processSampleBuffer
cnn_faceblur.dat
feature_extraction
t_19
t_57
t_76
t_95
t_114
types
date
typesWide
assetIdentifier
assetModificationDate
assetMasterFingerprint
assetAdjustedFingerprint
imageBlurResults
imageCompositionResults
imageFaceResults
imageFeatureResults
imageJunkResults
imageSaliencyResults
imageShotTypeResults
imagePetsResults
imagePetsFaceResults
imageSceneprintResults
livePhotoEffectsResults
livePhotoRecommendationResults
livePhotoSharpnessResults
livePhotoKeyFrameResults
livePhotoKeyFrameStillResults
movieActivityLevelResults
movieCameraMotionResults
movieClassificationResults
movieFaceResults
movieFaceprintResults
movieFeatureResults
movieFineSubjectMotionResults
movieInterestingnessResults
movieMovingObjectResults
movieMusicResults
movieObstructionResults
movieOrientationResults
moviePreEncodeResults
movieQualityResults
movieSaliencyResults
movieSceneResults
movieSceneprintResults
movieSubjectMotionResults
movieSubtleMotionResults
movieUtteranceResults
movieVoiceResults
movieSummaryResults
movieHighlightResults
imageExposureResults
imageHumanPoseResults
movieHumanPoseResults
movieApplauseResults
movieBabbleResults
movieCheeringResults
movieLaughterResults
movieHumanActionResults
movieLoudnessResults
moviePetsResults
moviePetsFaceResults
movieStabilizationResults
movieHighlightScoreResults
livePhotoHumanActionClassificationResults
movieAudioQualityResults
OCR/MRC
GlobalXSum
GlobalYSum
Type
cnn_lm.dat
Cannot generate facecrop without originating face
Failed to find originating PHFace %@
Failed to generate facecrop on manual originating face %@
Facecrop is nil
Missing image data from facecrop %@
Invalid facecrop image data %@
Invalid facecrop bounding box %@
Facecrop image size equals to 0
Failed to normalize bound %@ with image (%.0fx%.0f)
Failed to obtain the facecrop image dimensions
Failed to create VNImageRequestHandler
Failed to set VNDetectFaceRectanglesRequest
Failed to set VNCreateFaceprintRequest
Failed to analyze facecrop - %@
Failed to create faceprint - %@
Failed to wrap faceprint/faceTorsoprint
Face has already been persisted with a facecrop
Face does not have a faceprint
Failed to fetch facecrop
Failed to persist face and facecrop
[FaceCropManager] faceLocalIdentifier is nil
[FaceCropManager] Fetched %lu faces with face identifier %@, should be 1
[FaceCropManager] Failed to fetch face %@
yyyyMMdd
en_US_POSIX
FaceIDModelLastGenerationKey
PetIDModelLastGenerationKey
Person
com.apple.mediaanalysis.quickfaceid.management
VCPPersonVIPLoadModel
VCPPetVIPLoadModel
nameSource == %ld
verifiedType = %@
faceCount
nameSource != %ld
VCPPetVIPGenerateModel
isInVIPModel == YES
roll == 0.0
graph
user
VCPPersonVIPGenerateModel
VCPCNNBlurAnalyzerEspresso.sharedModelPool-%lu
cnn_blurV2.espresso.net
cnn_blur.espresso.net
VCPBlurEspresso
res_299x299
res_400x400
res_400x300
res_300x400
yyyy-MM-dd-HH-mm-ss
suggestionLog_
suggestions.html
function addPlaceHolders() {
addPlaceholdersForSet("visionInput", inputFaces);
addPlaceholdersForSet("visionOutput", outputFaces);
addPlaceholdersForSet("visionFiltered", filteredFaces);
function isElementHidden(element) {
var style = window.getComputedStyle(element);
return (style.display === 'none')
function updateVisibility() {
var allDivs = document.getElementsByTagName("div");
for (var i = 0; i < allDivs.length; i++) {
var d = allDivs[i];
if (!d.attributes["img"]) continue;
var rect = d.getBoundingClientRect();
if (
rect.top >= -100 &&
rect.left >= -100 &&
rect.bottom - 100 <= (window.innerHeight || document.documentElement.clientHeight) &&
rect.right - 100 <= (window.innerWidth || document.documentElement.clientWidth)
if (d.childNodes.length == 0) {
d.innerHTML = "<img src='" + d.attributes["img"].value + "' width='100' height='100'>";
else {
if (d.childNodes.length != 0) {
d.innerHTML = "";
function addPlaceholdersForSet(containerId, elements) {
var content = "";
for (var i = 0; i < elements.length; i++) {
content += "<div style='float: left; width: 100px; height: 100px; margin: 3px; background-color: darkgray' img='" + elements[i] + "'></div>"
document.getElementById(containerId).innerHTML = content;
document.onscroll = function (e) {
updateVisibility();
</script>
</head>
<body>
<p>Vision input:</p>
<div id="visionInput">
</div>
<p style="clear: both;">Vision output:</p>
<div id="visionOutput">
</div>
<p style="clear: both;">Vision filtered output:</p>
<div id="visionFiltered">
</div>
</div>
<script>
document.addEventListener("DOMContentLoaded", function (event) {
addPlaceHolders();
</script>
</body>
</html>
could not obtain access to the photo library
photo library could not provide suggestions
_suggestionsForPersonWithLocalIdentifier cancelled
v16@?0Q8
<html>
<head>
<script>
 var inputFaces = [
v32@?0@"NSString"8@"NSArray"16@"NSError"24
var outputFaces = [
var filteredFaces = [
suggestPersonsForPersonWithLocalIdentifier cancelled
Input parameter is empty or nil: '%@'
Failed to find persons with local identifiers: '%@'
VCPClusterer is nil
verifiedType != %d
VCPFaceProcessingDeleteAllVerifiedPersons
succeeded
VCPFaceProcessingReclusterFacesWithThreshold
VCPFaceProcessingBuildPersons
VCPBuildPersons failed %d
VCPFaceProcessingPromotePersons
VCPPromotePersons failed %d
Failed to rebuild persons (error: %d)
Failed to promote persons (error: %d)
B32@?0@"NSDictionary"8Q16^B24
PVPersonPromoter
Memories
iMovie
v48@?0^{CGImage=}8{?=qiIq}16@"NSError"40
IrisObjectsResults
MetaStabilizationResults
MetaStabilizationFrameResults
MetaHomographyDimensionResults
MetaHomographyResults
MetaPresentationTimeResults
MetaMotionBlurResults
MetaPTSInNanosResults
MetaOriginalPTSInNanosResults
MetaItemPTSResultsKey
MetaAdjusterResults
MetaAdjusterRecipeResults
MetaAdjusterDisplacementKey
MetaInterpolatedFrameKey
MetaLensSwitchResults
autoplay_head.espresso.net
var_99
NotImplementedException
[VideoTrackDecoder status] should not be called
[VideoTrackDecoder copyNextSampleBuffer] should not be called
[VideoTrackDecoder getNextCaptureSampleBuffer] should not be called
  state            : %d
  originating face : %@
action_repetition_counter
mlmodelc
VCPMADVIVisualSearchGatingTask
<redacted>
Failed to create visual search query context
VIService_VisualSearchGating
v32@?0@"VIParseResult"8@"NSData"16@"NSError"24
.espresso.net
callback queue
Create Context Error
Create Plan Error
%@ Load Error
Build Model Error
Select Configuration Error
Build Plan Error
Clean Plan Error
B24@?0@"NSString"8@"NSDictionary"16
VCPFaceAnalyzerFillMissingFaceprint
VCPFaceAnalyzerFaceQuality
aggregated
faceID
faceprintBlob
Live Photo
Pano Photo
Screenshot
HDR Photo
SDOF Photo
Photo
Slow-mo Movie
Timelapse Movie
Movie
VCPMADVIVisualSearchTask
v24@?0@"VISearchResult"8@"NSError"16
VIService_ParsedVisualSearch
VIService_VisualSearch
cnn_smile.dat
Failed to load asset
Asset contains no video tracks
Failed to create video track output
Failed to start decoding video track
Video processor cancelled
Failed to complete video decoding
recipeBlob
keyFrame
playbackCrop
colorNormalizationBlob
hasAction
Video stabilization task cancelled
Video stabilization processing failed
VideoCNN
Skeleton
enabled
formatDescriptions
naturalSize
nominalFrameRate
preferredTransform
tracks
res_384x384
q24@?0@"NSNumber"8@"NSNumber"16
res_%dx%d
obstructionScore
VCPMADServiceImageProcessingTask
%@ not currently implemented
q24@?0@"NSObject<VCPMADServiceImageProcessingSubtaskProtocol><VCPMADTaskProtocol>"8@"NSObject<VCPMADServiceImageProcessingSubtaskProtocol><VCPMADTaskProtocol>"16
[MediaAnalysis][%@]Unable to open movie, skip
[MediaAnalysis][%@]Failed to create asset
[%@] Analysis cancelled
[%@] Analysis failed to complete
outputFrameDurValue
cropRectX
cropRectY
cropRectHeight
cropRectWidth
autoloop
bounce
longexposure
stabilize
minVersion
cnn_blink.espresso.net
VCPGazeEspresso
PersonBuilderMergeCandidatesEnabled
PersonBuilderLastMinimumFaceGroupSizeForCreatingMergeCandidates
personBuilderState != %lu
VCPFaceProcessingCleanupMergeCandidates
v16@?0@"NSArray"8
VCPPersonBuilder_UpdateKeyface
statisticsBlob
@"VCPMADVIRectangleDetectionResource"8@?0
VCPMADVIRectangleDetectionTask
com.apple.mediaanalysis.SceneProcessingGroup
MonzaV4_1
@"CVNLPCommSafetyHandler"8@?0
%@%@
classID
size
score
v32@?0@"VNRecognizedObjectObservation"8Q16^B24
v24@?0@"PFSceneTaxonomyNode"8^B16
v32@?0@"NSDictionary"8Q16^B24
meme_
v32@?0@"NSString"8@"NSString"16^B24
cnn_human_pose_single.espresso.net
subjectMotionScore
motionDivScore
objectsMotion
globalMotion
interestingnessScore
trackingScore
sceneChangeScore
browDown_L
browDown_R
browInnerUp
browOuterUp_L
browOuterUp_R
cheekPuff
cheekSquint_L
cheekSquint_R
eyeBlink_L
eyeBlink_R
eyeLookDown_L
eyeLookDown_R
eyeLookIn_L
eyeLookIn_R
eyeLookOut_L
eyeLookOut_R
eyeLookUp_L
eyeLookUp_R
eyeSquint_L
eyeSquint_R
eyeWide_L
eyeWide_R
jawForward
jawLeft
jawOpen
jawRight
mouthClose
mouthDimple_L
mouthDimple_R
mouthFrown_L
mouthFrown_R
mouthFunnel
mouthLeft
mouthLowerDown_L
mouthLowerDown_R
mouthPress_L
mouthPress_R
mouthPucker
mouthRight
mouthRollLower
mouthRollUpper
mouthShrugLower
mouthShrugUpper
mouthSmile_L
mouthSmile_R
mouthStretch_L
mouthStretch_R
mouthUpperUp_L
mouthUpperUp_R
noseSneer_L
noseSneer_R
tongueOut
focalLengthInPixels
objects
faceRollAngles
faceAnchor
vertices
transform
blendshapes
geometry
dispatchQueue
regionsOfInterest
aggSubjectMotionScore
turboMode
frameWidth
frameHeight
VCPCaptureAnalysis
v28@?0f8f12Q16i24
cnn_pets.espresso.net
VCPPetsEspresso
res_0
res_1
res_2
gesture_recognition.espresso.net
cnn_human_pose.espresso.net
AllowOnDemandPixel
AllowOnDemandGyro
AllowStreaming
KeepPrivateResults
MaxHighlightDuration
Standalone
StoreAnalysis
ScaledSlomoTime
com.apple.mediaanalysis.ondemand
com.apple.mediaanalysis.storage
com.apple.mediaanalysis.VCPMediaAnalyzer.sandboxQueue
com.apple.mediaanalysis.VCPMediaAnalyzer.cancelQueue
v16@?0@"NSString"8
VCPMediaAnalyzer
Sceneprint task cancelled
[%@] Thumbnail is not locally available
[%@] Failed to load thumbnail image
[%@] Failed to set revision %lu - %@
[%@] Invalid sceneprint result
45.1
mediaType == %d
kind == %d && kindSubtype != %d
mediaType == %d && !((mediaSubtype & %d) == %d)
kindSubtype == %d
(mediaSubtype & %d) == %d
!((mediaSubtype & %d) == %d)
mediaAnalysisAttributes.mediaAnalysisVersion < %d
kindSubtype != %d && SUBQUERY(additionalAttributes.sceneClassifications, $s, $s.sceneIdentifier = %d AND $s.confidence > %f).@count > 0
kindSubtype != %d && SUBQUERY(additionalAttributes.sceneClassifications, $s, $s.sceneIdentifier = %d AND $s.confidence > %f).@count = 0
SUBQUERY(additionalAttributes.sceneClassifications, $s, $s.sceneIdentifier = %d AND $s.confidence >= %f).@count > 0
SUBQUERY(additionalAttributes.sceneClassifications, $s, $s.sceneIdentifier = %d AND $s.confidence >= %f).@count = 0
additionalAttributes.sceneAnalysisVersion != %d || adjustmentTimestamp != additionalAttributes.sceneAnalysisTimestamp
adjustmentTimestamp != faceAdjustmentVersion
mediaAnalysisAttributes.characterRecognitionAttributes = NULL || mediaAnalysisAttributes.characterRecognitionAttributes.algorithmVersion != %d || adjustmentTimestamp != mediaAnalysisAttributes.characterRecognitionAttributes.adjustmentVersion
mediaAnalysisAttributes.visualSearchAttributes = NULL || mediaAnalysisAttributes.visualSearchAttributes.algorithmVersion != %d || adjustmentTimestamp != mediaAnalysisAttributes.visualSearchAttributes.adjustmentVersion
VCPMADVisionResource
output1
output2
output3
cnn_hand_detector_v2.espresso.net
VCPMAMLModel-%@
@"VCPMAMLModel"8@?0
maxNumberHands
humanActionWindowSize
motionFlowComputationAccuracy
v32@?0@"NSString"8@"NSString"16@"NSError"24
identifier
mediaanalysis://in-memory
com.apple.mediaanalysisd.VCPInMemoryAVAsset
v24@?0^v8Q16
Frame: %u
textureness
hasFlash
supportedImageSizeSet
v16@?0@"NSData"8
Destructive Trim Range: [%.2f - %.2f]
after repare
after consecutive short merge
after sparse short merge
after post processing
=========Segment %s==========
v32@?0@"VCPSegment"8Q16^B24
 [%.2f - %.2f]: %.2f
--[%.2f - %.2f]
com.apple.mediaanalysis.VCPDefaultPhotoLibraryManager
precision
personID
validFaceCount
identitySize
recall
AutoCounterGroundTruth.plist
[AutoCounter] Cannot load ground truth file URL
no_name
AddedDate
unknown
unverified
verifiedType
personName
faceRect
faceGroupID
faceprint
momentIdentifier
[AutoCounter] Failed to fetch person (%@)
FacesPerAsset
OptInDate
OptInDateSinceReferenceDate
OptInMADFaceVersion
OptInDetectionModelVersion
OptInRecognitionModelVersion
FaceCount
AssetCount
AdditionalInformation
AutoCounterClusters_Ver%d_DetectionVer%lu_RecognitionVer%lu.plist
[AutoCounter] Failed to retrive export URL
mergecandidates
faces
assetInformation
[AutoCounter] Failed to process FaceGroups
v32@?0@"NSString"8@"NSDictionary"16^B24
AutoCounterClusterAssetsToFaces_Ver%d_DetectionVer%lu_RecognitionVer%lu.plist
phFaceID
gtFaceID
gtPersonID
v32@?0@"NSString"8@"NSSet"16^B24
com.apple.photos.autocounter
date_optin
detection_version_current
detection_version_optin
mad_version_current
mad_version_optin
person_id
promoter_clusters
promoter_clusters_duplicates
promoter_precision
promoter_recall
promoter_version_current
promoter_version_optin
recognition_version_current
recognition_version_optin
total_assets
total_assets_optin
total_faces
total_faces_optin
type
userLabeledAge
userLabeledEthnicity
userLabeledGender
vision_clusters
vision_clusters_duplicates
vision_precision
vision_recall
nightly
nightly-Ver%d_DetectionVer%lu_RecognitionVer%lu_PersonVer%lu
AutoCounterCoreAnalytics
%@_Ver%d_DetectionVer%lu_RecognitionVer%lu.plist
self.lastPathComponent BEGINSWITH %@
v32@?0@"NSURL"8Q16^B24
visionCluster
weightedAveragePrecision
weightedAverageRecall
numSingletons
numValidSingletons
precisionPerCluster
recallPerPersonToGroundTruth
recallPerPersonExcludeMissDetection
personCluster
identity
PVPersonPromoterVersion
Apple
cnn_saliency.dat
VCPMADVIUserFeedbackTask
VIService_UserFeedback
@"VCPMADVIVisualSearchResource"8@?0
mdta/com.apple.quicktime.live-photo-info
propertyKey %s 
result is nil %s
sum = %6.2f, tracking_score = %6.2f
Target Captured @ [%5.0f, %5.0f, %5.0f, %5.0f]
initial @ [%d %d] s = %6.5f
stop    @ [%d %d] s = %6.5f
lost = %d
[%6.2f, %6.2f, %6.2f, %6.2f]
box0: (x = %2.1f, y = %2.1f, w = %2.1f, h = %2.1f)
box1: (x = %2.1f, y = %2.1f, w = %2.1f, h = %2.1f)
box : (x = %2.1f, y = %2.1f, w = %2.1f, h = %2.1f)
overlap_area = %6.2f, max_area = %6.2f, weight = %6.2f
derr = %6.2f, terr = %6.2f
add new expert with weight %6.2f
expert %d was replaced: voting weight(%6.2f --> %6.2f)!
after voting --> update target
detector and tracker did not match well --> experts vote
detector and tracker matched well --> update experts
VCPImageHumanActionEspresso
cnn_image_human_action.espresso.net
compatible
IODeviceTree:/arm-io
res_192x192
hand_keypoint_detector.espresso.net
regressiontree_landmark.dat
rtree_landmark_tracking.dat
com.apple.mediaanalysisd.VCPVideoFaceValidation
face_validation_warp_tri_list.dat
face_validation_warp
face_validation_warp_params.dat
%@_%d.dat
com.apple.mediaanalysis.VCPImageManager.transcodeQueue
VCPImageManager
@"VCPImageManager"8@?0
MADImageManagerEncode_%.3f_unpadded.jpg
MADImageManagerEncode_%.3f_padded.jpg
/Library/Audio/Tunings/Generic/AU/aufx-epv2-mediaanalysis-appl.plist
cnn_pose.dat
motionType
isFast
sourceSize
inputBounds
VCPVideoCNNActionClassifierEspresso
VCPVideoCNNActionClassifierEspressoStage1
action_recognition_head.espresso.net
action_taxonomy.plist
boxes
action_recognition_head_stage1.espresso.net
q24@?0@"PHFace"8@"PHFace"16
cnn_saliency.espresso.net
VCPSaliencyFullEspresso
energy
peak
%@ canceled
%@ is not yet implemented
frame idx = %d
size = %d, track_target_exist = %d, target_lost = %d, tracking_score = %6.2f
com.apple.homekitanalysis.service.management
com.apple.homekitanalysis.service.handler
Failed to fetch person by local identifier (%@)
HMIAnalysisService
Failed to create VNAlignFaceRectangleRequest
Failed to exercise Vision request - %@
UserOrig
UserAlgo
NoUserAlgo
NoAlgo
cnn_person_detector.espresso.net
PetsRegions
PetsFaceRegions
{CGRect={CGPoint=dd}{CGSize=dd}}
res_256x256
VCPHumanPoseEspresso
res_320x192
res_192x320
clusterer is not available
Face clustering threshold should be in the range: [0.1, 1.0]
VCPFaceProcessingResetFaceClusteringState
VCPFaceProcessingPerformFaceClusteringAndWait
backwarpNonInterleaved
LogLevel
yyyy-MM-dd HH:mm:ss
autoPlayable
Angle
cnn_blur.dat
iChatUsageString
EnableStatsCollect
EnableUserQPForFacetime
EnableUserRefForFacetime
EnableWeightedPrediction
UserFrameType
ReferenceFrameNumDriver
ReferenceL0
UserQpMap
MBStatistics
NotSync
ClonedImageCaptionModel
en-US
Failed to load imageURL: %@
NeuralHash+LSH invalid imageSignatureHash
Invalid NeuralHash+LSH (=)
v20@?0f8^B12
VCPFaceProcessingPromotePersonsCoreAnalyticsCollection
com.apple.mediaanalysisd.photos.personpromoting
GraphVerifiedPersonCount
PromotingInterval
PromotingSequence
TotalFaceCount
UnverifiedPersonCount
UserVerifiedPersonCount
com.apple.Photos
Received action score %f - %f
=========%s==========
[%.2f - %.2f]: %.2f
capturePointSegmentIdx: %d
----[%.2f - %.2f]
startIdx = %d, endIdx = %d, count = %d, [%f, %f] with score %f captureTime=%f
interesting trim: [%f, %f], score = %.2f
 --[%.2f - %.2f]
===========SceneChangeSegments=============
[%f, %f]
Measurement
Min (s)
Max (s)
Avg (s)
Total
Count
Minimum
Maximum
Average
signpost
com.apple.mediaanalysisd.livephotoeffectanalysisresults
com.apple.mediaanalysisd.moviecurationresults
com.apple.mediaanalysisd.livephotokeyframeresults
com.apple.mediaanalysisd.das.dutycycle
com.apple.mediaanalysisd.das.dutycycle.task
com.apple.mediaanalysisd.analysis.pets
com.apple.mediaanalysisd.livePhotoFillingGaps
LivePhotoEffectsShortInputDecision
LivePhotoEffectsPreGateStillMetadataDecision
LivePhotoEffectsPreGateVideoTrimDecision
LivePhotoEffectsPreGateVideoMLDecision
LivePhotoEffectsPreGateFacesDecision
LivePhotoEffectsStabilizeGateDecision
LivePhotoEffectsPostGateDecision
LivePhotoEffectsFinalGateDecision
LivePhotoEffectsLoopActivityDecision
LivePhotoEffectsBounceActivityDecision
LivePhotoEffectsLongexpActivityDecision
LivePhotoEffectsStabilizeResult
MediaType
AutoPlayableScore
SummaryDuration
IsTrimmed
KeyFrameIsSuggested
KeyFrameScoreDifference
KeyFrameTimestampOffset
KeyFrameIsFaceQualityDominant
KeyFrameIsSharpnessDominant
KeyFrameIsSemanticDominant
KeyFrameIsSuggestedEdit
KeyFrameScoreDifferenceEdit
KeyFrameTimestampOffsetEdit
KeyFrameIsFaceQualityDominantEdit
KeyFrameIsSharpnessDominantEdit
KeyFrameIsSemanticDominantEdit
previousQoS
previousQoSDuration
requestedQoS
taskName
taskStatus
DownloadAssetCount
DownloadBytes
Duration
Delay
AvgSpeed
AssetType
NumberOfPetFacesDetected
NumberOfPetsDetected
ResourceType
SceneType
AggregatedBoundingBoxSizeRatio
LargestBoundingBoxSizeRatio
com.apple.mediaanalysis.coreanalytics
VCPMADCoreAnalyticsManager
@"VCPMADCoreAnalyticsManager"8@?0
SHMutableSignature
correlationNonInterleaved
[VCPAsset %@] should not be called
mediaType
mediaSubtypes
pixelWidth
pixelHeight
exif
imageWithPreferredDimension:
imageWithPreferredDimension:orientation
movie:
isMovieResourceLocalAvailable:
originalMovie:
Start
FramesPerSecond
v16@?0@"NSURL"8
VCPDownloadResource
inputBoundsX
inputBoundsY
inputBoundsHeight
inputBoundsWidth
sourceSizeHeight
sourceSizeWidth
homographyParams
cnn_pet_pose.espresso.net
cameramotiontype_head.espresso.net
cameramotionscore_head.espresso.net
VCPMADResourceManager
@"VCPMADResourceManager"8@?0
q24@?0@"VCPMADResourceEntry"8@"VCPMADResourceEntry"16
com.apple.mediaanalysisd.VCPMADResourceManager
DeviceClass
iPad
pLzf7OiX5nWAPUMj7BfI4Q
marketing-name
inputImage
angle
v24@?0@"MLModel"8@"NSError"16
Getting no object IDs when fetching assets on moment %@
Reachability initialization failed; assuming no connection
Reachability flags invalid; assuming no connection
%sonnected to internet via WiFi/Ethernet
Network reachability flag changed to: %@
Human action - no PHFaces found
Failed to lock CVPixelBuffer (%p, %d)
Cannot lock NULL CVPixelBuffer
Lock attempt failed; cannot unlock buffer
Multiple unlock attempts; cannot unlock buffer
Failed to unlock CVPixelBuffer (%p, %d)
Failed to allocate memory
[VCPVideoFullFaceDetector] Detected face %@
[VCPVideoFullFaceDetector] Failed to detect faces - %@
Failed to retrieve faceprint revision from key faces
Failed to create Vision clusterer - %@
Failed to cluster faces - %@
Creating faceprint for face crop
Multiple faces present in face crop; using first
Loading quick identification model
Performing quick identification
Quick identification match found: %@
No quick identification match found
Home face identification task failed (%@)
inferenceHandKeypointCallFromSPI
Failed to allocate textureness or dst buffer for image resolution %dx%d
[MediaAnalysis] Image descriptor - found more than 1 VNImageprintObservations
VNImageprint init error: %@
VCPClusterer: Terminating ...
VCPClusterer: Terminated
VCPClusterer: Cluster triggering set to %lu
VCPClusterer: Scheduling to remove %lu faces and add %lu faces
VCPClusterer: total remove %lu faces and add %lu faces
VCPFaceProcessingClusterFacesCoreAnalyticsCollection
VCPClusterer: Removing %lu faces from cluster cache
VCPClusterer: Failed to cluster(removing) faces - %@
VCPClusterer: Removed %lu faces from cluster cache [time: %f secs]
VCPClusterer: Adding %lu faces to cluster cache
VCPClusterer: Number of orderedFaceIdentifiers (%lu) != number of _faceIdStrsToAdd (%lu)
VCPClusterer: missing localIdentifiers : %@
VCPClusterer: %lu faces to cluster, already took %f seconds
VCPClusterer: %lu faces in current batch, %lu faces remain
VCPClusteringGetFaceObservations
VCPClusterer: Number of faceTorsoprintsToAdd (%lu) !=  number to cluster (%lu)
VCPClusterer: Failed to cluster(adding) faces - %@
VCPClusterer: Added %lu faces to cluster cache
VCPClusteringBatch
VCPClusterer: Added faces to cluster cache [time: %f secs]
VCPClusterer: Start clustering
VCPClusterer: Finished clustering %lu faces, with normalized %.2f millisecond per face
VCPClusterer: Vision failed to cluster - %@
[VisionFgMapping] Preparing Vision Clusters (size: %ld) to Photos FaceGroup
VCPVisionFgMapping_Prepare
VCPClusterer: Failed to save cluster cache - %@
VCPClusterer: Start to update database models
VCPClusterer: Failed to persist FaceGroups; will try next time - %@
VCPClusterer: Updated database models
VCPClusterer: Cannot cluster image print type %lu
VCPClusterer: Failed to get VNFaceTorsoprint from face %@ - %@
VCPClusterer: Missing faceprint data for face %@
VCPClusterer: Failed to remove empty FaceGroup(s) - %@
VCPClusterer: Start quick-syncing cluster cache with library
VCPClusterer: Failed to clean faces with valid CSN but not in any FaceGroup - %@
VCPClusterer: Failed to clean faces with CSN = 0 but found in any FaceGroup - %@
VCPClusterer: Number of clustered faces in the cluster cache (%lu) < number of clustered faces in the library (%lu)
VCPClusterer: Quick-syncing cluster cache with library, found > 10%% (%5.2f) difference in the number of faces that are in the cluster cache versus library
VCPClusterer: Finished quick-syncing cluster cache with library. Elapsed time: %f
VCPClusterer: Start syncing cluster cache with library ...
VCPClusterer: Retrieving clusters from cluster cache ...
VCPClusterer: Retrieved clusters from cluster cache
VCPClusterer: Failed to retrieve clusters from cluster cache - %@
VCPClusterer: Retrieving clusters from library ...
VCPClusterer: Retrieved clusters from library
VCPClusterer: Failed to retrieve clusters from library - %@
VCPClusterer: Syncing cluster cache with library, found %lu non-singleton clusters in the cluster cache that do not match those in the library
VCPClusterer: Syncing cluster cache with library, found %lu clusters in the library cache that do not match those in the cluster cache
VCPClusterer: Syncing cluster cache with library, found > 20%% (%5.2f) difference in the number of faces are in the cluster cache versus library
VCPClusterer: Failed to ungroup faces - %@
VCPClusterer: Successfully reset cluster cache - %@
VCPClusterer: Failed to reset cluster cache - %@ - %@
VCPClusterer: Deleting FaceGroups and reset CSN of all previously clustered faces
VCPClusterer: Canceled syncing cluster cache [point: %d do loop]
VCPClusterer: Retry deleting FaceGroups and reset CSN of all previously clustered faces. Attempt %d of %d.
VCPClusterer: Deleted FaceGroups and reset CSN of all previously clustered faces
VCPClusterer: Failed to delete face groups and reset CSN of all previously clustered faces - %@
VCPClusterer: Syncing cluster cache with library - %@
VCPClusterer: Schedule adding %lu faces to the cluster state
VCPClusterer: Failed to get faces that are no longer present in the library
VCPClusterer: Canceled syncing cluster cache [point: %d]
VCPClusterer: Schedule removing %lu faces from the cluster state
VCPClusterer: Finished syncing cluster cache with library - %@
%@ - %@
Creating VNClustererBuilder with context.processingVersion:%d, type: %@, cachePath: %@, faceprintRequestRevision-%lu threshold-%.2f, torsoprintRequestRevision-%lu threshold-%.2f
VCPClusterer: Started resetting cluster cache ... 
VCPClusterer: Failed to remove all cluster cache files - %@
VCPClusterer: Created a new cluster cache
VCPClusterer: Failed to save a new cluster cache - %@
VCPClusterer: Finished resetting cluster cache
VCPClusterer: Failed to create a new cluster cache - %@
VCPClusterer: Failed to get old vision cluster cache filenames from vision cluster state
VCPClusterer: Failed to remove cluster mmap file at '%@' - %@
VCPClusterer: Failed to restore Vision clustering state - %@
VCPClusterer: Failed to unarchive cluster cache data blob from '%@'
VCPClusterer: Resetting cluster cache files - %@
VCPClusterer: Started restoring cluster cache
VCPClusterer: Failed to restore cluster cache - %@
VCPClusterer: Failed to restore cluster cache
VCPClusterer: Failed to restore cluster cache with std::exception %s
VCPClusterer: Restored cluster cache. Clusterer bring-up state - %@, time to restore: %f secs
[VisionFgMapping] Checking l1-cluster %@ (%ld faces) for conflict
[VisionFgMapping] Resolving conflict l0-cluster %@ in l1-cluster %@
VCPClusterer: Failed to get Vision clusters - %@
VCPClusterer: Retrieving clusters in cluster cache ...
VCPClusterer: Failed to retrieve clusters in cluster cache - %@
VCPClusterer: Retrieving clusters in library ...
VCPClusterer: Failed to retrieve clusters in library - %@
VCPClusterer: Comparing clusters
VCPClusterer: Failed to remove cluster snapshot at '%@': %@
VCPClusterer: Failed to remove cluster mmap file at '%@': %@
VCPClusterer: Bring-up state transition: %@ -> %@
VCPClusterer - _calculateChecksumMD5ForFile: error reading %zu bytes from file
Not implemented, please use initWithOptions
Incompatible request (%@) specified to %@
[RemoveBackground][%@] running (Mask: %d, Crop: %d, In-Place: %d)...
[RemoveBackground][%@] Skipping for ineligible image
[RemoveBackground][%@] Checking for cached image handler...
[RemoveBackground][%@] Matched cached image handler(!)
[RemoveBackground][%@] No cached image handler
[RemoveBackground][%@] Cached image handler does not match
[RemoveBackground][%@] Resetting cached image handler
VCPMADVIRemoveBackgroundTask image loading failed
[RemoveBackground] Image is screenshot - detecting ROI
[RemoveBackground] Failed to detect screenshot ROI (%@)
[RemoveBackground] Screenshot has no ROI (%@)
[RemoveBackground] Screenshot ROI: (%0.2f, %0.2f) %0.2fx%0.2f Confidence: %0.2f [1 of %d]
VNImageRequestHandler_init
[RemoveBackground] Set VNProcessingDevice: %@ (%@)
[RemoveBackground] Perform-in-place requested for ineligible input; ignoring
[%@] In Place: %d Crop: %d  Mask: %d  ROI: (%0.2f, %0.2f) %0.2fx%0.2f
VNImageRequestHandler_performRequests
[RemoveBackground][%@] Caching image handler (resolution %dx%d, orientation %d)
[RemoveBackground] No observations produced for image
[RemoveBackground][%@] complete
Invalid VNRequest configuration (%@)
VNRequest must be non-nil
[MediaAnalysis][%@] Analysis requested for blacklisted asset
[MediaAnalysis][%@] Existing analysis based on old modification
[MediaAnalysis][%@] Existing analysis based on degraded asset
[MediaAnalysis][%@] Existing analysis satisfies request (%@)
[MediaAnalysis][%@] Existing analysis doesn't match asset state
[MediaAnalysis][%@] Existing analysis doesn't satisfy request (%@)
[MediaAnalysis][%@] Generating analysis on-demand: %@
  [%@] Analysis cancelled
  [%@] Analysis failed to complete
Unsupported photo analysis type %@
Unsupported movie analysis type %@
VCPFullAnalysisAssetProcessingTask
VCPFullAnalysisAssetProcessingTask processing failed
Media analysis client XPC connection interrupted
Media analysis client XPC connection invalidated
[MediaAnalysis] [MediaAnalyzer requestAnalysisTypes] call with invalid resourceURLs
Failed to issue sandbox extension on %@
[MediaAnalysis] Error connecting to background analysis service
[MediaAnalysis] Request %d has completed
[MediaAnalysis] Error connecting to Photos background analysis service
[MediaAnalysis] Unsupported task %lu
[MediaAnalysis] Asset processing request %d has completed
In-Process quick face identification not supported
[MediaAnalysis] Error connecting to Photos Quick Face Identification service
[MediaAnalysis] Request %d is %.2f%% complete
[MediaAnalysis] Unknown analysis request %d; dropping cancellation request
[MediaAnalysis] No active analysis requests; dropping cancellation request
[MediaAnalysis] Failed to cancel background analysis: %@
[MediaAnalysis] Background analysis canceled
[MediaAnalysis] Error connecting to background analysis service: %@
[MediaAnalysis] Error connecting to request PersonPromoterStatus service
[MediaAnalysis] Request Person Preference %d has completed
[MediaAnalysis] Request VIP model filepath Preference %d has completed
[MediaAnalysis] Error connecting to request SuggestedPersons service
[MediaAnalysis] Request SuggestedPersons %d has completed
[MediaAnalysis] Error connecting to request UpdateKeyFacesOfPersons service
[MediaAnalysis] Request UpdateKeyFacesOfPersons %d has completed
[MediaAnalysis] Error connecting to request FaceCandidatesforKeyFace service
[MediaAnalysis] Request FaceCandidatesforKeyFace %d has completed
[MediaAnalysis] Error connecting to request ResetFaceClassificationModel service
[MediaAnalysis] Request ResetFaceClassificationModel %d has completed
[MediaAnalysis] Error connecting to request ResetPetClassificationModel service
[MediaAnalysis] Request ResetPetClassificationModel %d has completed
[MediaAnalysis] Error connecting to request SuggestedMePersonIdentifier service
[MediaAnalysis] Request SuggestedMePersonIdentifier %d has completed
[MediaAnalysis] Request PersonPromoterStatus %d has completed
[MediaAnalysis] Error connecting to request Face and Person workflow
[MediaAnalysis] Request Face and Person workflow %d has completed
[MediaAnalysis] Error connecting to request ClusterCacheValidation service
[MediaAnalysis] Request ClusterCacheValidation %d has completed
[MediaAnalysis] Error connecting to request ResetFaceClusteringState service
[MediaAnalysis] Request ResetFaceClusteringState %d has completed
[MediaAnalysis] Error connecting to request ReclusterFaces service
[MediaAnalysis] Request ReclusterFaces %d has completed
[MediaAnalysis] Error connecting to request RebuildPersons service
[MediaAnalysis] Request RebuildPersons %d has completed
[MediaAnalysis] Error connecting to query AutoCounter Opt-In status service
[MediaAnalysis] Query AutoCounter Opt-In status %d has completed
[MediaAnalysis] Error connecting to request Opt-In AutoCounter
[MediaAnalysis] Request Opt-In AutoCounter %d has completed
[MediaAnalysis] Error connecting to request AutoCounter dump
[MediaAnalysis] Request AutoCounter dump %d has completed
[MediaAnalysis] Error connecting to request AutoCounter calculation
[MediaAnalysis] Request AutoCounter calculation %d has completed
[MediaAnalysis] Request AutoCounter SIML validation %d has completed
[MediaAnalysis] Faces must be non-empty and completion block must be non-nil
[MediaAnalysis] Faces must all be from the same Photo Library
[MediaAnalysis] Error connecting to Media Analysis
[MediaAnalysis] nil specified for non-nullable parameter
VCPVideoCaptionEncoder: start loading model at: %@
VCPVideoCaptionEncoder: model to load %@
VCPVideoCaptionEncoder: inputBlob.nframes = %d, inputBlob.height = %d, inputBlob.width = %d, inputBlob.channels = %d
VCPVideoCaptionEncoder: successfully loaded model
 keypointsToObservation - unexpected keypoints count
incompatible input buffer size/format, check requiredInputFormat
CVNLPCommSafetyHandler_init
Failed to create CVNLPCommSafetyHandler: %@
VCPMADImageSafetyClassificationTask running...
VCPMADImageSafetyClassificationTask image loading failed
VCPMADImageSafetyClassificationTask image pre-processing failed
CVNLPCommSafetyHandler_scale
CVNLPCommSafetyHandler unavailable for classifying pixel buffer
CVNLPCommSafetyHandler_classifyPixelBuffer
VCPMADImageSafetyClassificationTask failed (%@)
VCPMADImageSafetyClassificationTask complete
[VCPPhotosFace] faceprint.confidence is too low (%.3f < 0.1) %@ - junkinessIndex: %.3f
[VCPPhotosFace] Accepting faceprint with confidence: %.3f %@ - junkinessIndex: %.3f
[VCPPhotosFace] Missing results for roll information
[VCPPhotosFace] Missing results from VNDetectFaceCaptureQualityRequest
[VCPPhotosFace] Missing results for yaw information
[VCPPhotosFace] Missing results from VNDetectFaceExpressionsRequest
[VCPPhotosFace] Missing results from VNClassifyFaceAttributesRequest
[VCPPhotosFace] Gaze: mask: %s, VNFaceGazeDirection: %@, PHFaceGazeType: %@ at (%.3f, %.3f)
[VCPPhotosFace] Missing results from VNDetectFaceGazeRequest
[PhotosFace] Fail to generate VCPPhotosFace from %@ and %@ - %@
[PhotosFace] Generate VCPPhotosFace %@ from %@ and %@
[PhotosFace] Fail to generate VCPPhotosFace %@ from %@ and %@ - invalid imageprint
[PhotosFace] Fail to generate face only VCPPhotosFace from %@ - %@
[PhotosFace] Generate face only VCPPhotosFace %@ from %@
[PhotosFace] Fail to generate VCPPhotosFace %@ from %@ - invalid imageprint
[PhotosFace] Failed to serialize torsoprint; %@
[PhotosFace] torsoOnlyObservation failed to return a faceprint
[PhotosFace] Ignoring co-locating animalObservation %@
[PhotosFace] Unable to determine normalized bounding box { { %f, %f } { %f, %f } }
[PhotosFace] Failed to serialize animalprintData; %@
[PhotosFace] animalObservation failed to return a faceprint
[PhotosFace] Generate VCPPhotosFace %@ from %@
[PhotosFace] IoU %f %@ %@
[VCPCNNEspressoContext] created CPU context
[VCPCNNEspressoContext] Failed to CPU context
[VCPCNNEspressoContext] created MPSGraph context
[VCPCNNEspressoContext] Failed to create MPSGraph context, fall back to CPU context
[VCPCNNEspressoContext] created preferred context
[VCPCNNEspressoContext] Failed to create ANE context, fall back to MPS context
[VCPCNNEspressoContext] Failed to create MPS context, fall back to CPU context
[VCPCNNEspressoContext] sharing CPU context
[VCPCNNEspressoContext] sharing MPSGraph context
[VCPCNNEspressoContext] sharing preferred context
[VCPCNNEspressoContext] dealloc shared context; keep alive
[VCPCNNEspressoContext] dealloc context;
[VCPCNNEspressoContext] No valid context; skip dealloc
Choosing asset resource from preferred list: %@
Network is available, filtering list to remove the CPL Thumb, new list is: %@
No resources locally available, returning a downloadable hi-res resource: %@
[Face] Failed setting %@ private revision: %@, umbrellaVersion: %d
[FaceConfiguration] No proper vision model revision for %@ with umbrellaVersion: %d
VCPObjectPool failed to allocate object
Failed to get the ideal size of request %@ with revision %lu
Failed to set %@::setRevision %lu: %@
Request %@ (revision %lu) ideal size %@
Ideal size for request %@ not cached
[MediaAnalysis] Junk analayzer - unexpected %d VNObservations
VIService_init
[CNNModelEspresso] Creating %@context for %@
[CNNModelEspresso] Created %scontext (CPU:%d, MPSGraph:%d)), storage type %d
Invalid sceneprint revision: %lu (required %lu)
Failed to open analysis database for Photo Library (%@)
Specified Photo Library has no URL (<%@>); cannot find analysis database
Cloning model: %@
Deleting old clone directory for caption model: %@
Could not delete old clone directory for caption model: %@. error: %@
Creating clone directory for caption model: %@
Could not create clone directory for caption model: %@. error: %@
Cloning caption model: '%@' to: '%@'
Could not clone caption model. clonefile(%@, %@, %o) FAILED with (%d : %s)
Video captioning mode: VCPVideoCaptionMode_Off
Download meta data reply %ld
Queried asset metadata with result: %ld
No video caption encoder query results
Asset %@ not present - downloading
Progress callback: %lld %lld
Downloaded asset with result %li, error? %@
Space not available to download asset %lli
Video caption decoder test model not exist at %@, skip video caption analysis
Unable to obatain video caption decoder model from Accessibility
Video caption encoder test model not exist at %@, skip video caption analysis
Failed to create CVNLPVideoCaptioningModel (%@)
Error to generate video caption with CVNLPVideoCaptioningModel (%@)
Incomparable images: this - %@ vs that - %@
VCPVideoKeyFrameBlurAnalyzer
VCPVideoKeyFrameFaceQualityAnalyzer
Query progress: unsupport taskID %lu - %@
Query progress: output parameter statistics must be non-nil
Query progress: scan library for %lu - %@
VCPAnalysisProgressQueryScanPhotoLibraryFetch
Query progress: unsupported taskID (%lu)
VCPAnalysisProgressQueryExpressPathFetchTotalCount
VCPAnalysisProgressQueryExpressPathFetchProcessedCount
Query progress: unsupported taskID (%@)
VCPAnalysisProgressQueryProgressDetail
VCPAnalysisProgressQueryProgress
Query cached face progress: %lu out of %lu
VCPAnalysisProgressQueryCachedFaceAnalysisProgress
[EmbeddingOnDemand] Incompatible request (%@) specified to %@
[EmbeddingOnDemand] Incompatible imageAsset (%@) specified to %@
VCPMADEmbeddingGenerationTask not supported on this platform
Multiple sampling times (%0.1fs) intersect frame at %lld/%d
%@ skipping sample %lld at %lld/%d
%@ failed for sample at %lld/%d (%@)
QuickFaceID: Failed to create faceprint from data : %@
QuickFaceID: Failed to create animalprint from data : %@
QuickFaceID: Passing classify face confidence: %f
QuickFaceID: Failed passing classify face confidence: %f
QuickFaceID: Failed to predict at all
QuickFaceID Pet: Passing classify pet confidence: %f
QuickFaceID Pet: Failed passing classify pet confidence: %f
QuickFaceID Pet: Failed to predict pet at all
QuickFaceID %@ Model path is nil; skip loading
Failed to load VIP %@ Model
No persistentStorageDirectoryURL for photoLibrary: %@
Unable to serialize library analysis preferences for %@: %@
Unable to write library analysis preferences for %@: %@
Key for setLibraryAnalysisPreferencesValue is nil
Failed to fetch VIP model file path with unknown VCPMAVIPType (%lu)
Failed to fetch VIP model last generation date with unknown VCPMAVIPType (%lu)
Not requiring processing for unknown taskID %lu
Fail in generating motion flow
[FaceModelBump] Failed to update version state - %@
[FaceModelBump] No persistentURL to update version state - %@
[FaceModelBump] Resetting face data ... (%@)
[FaceModelBump] Failed to reset Face Analysis data for PhotoLibrary %@
Face Quality Results mismatch with detected Faces (%lu vs %lu)
Error: FaceQualityScore should not contain results! (size = %lu, timestamp=%.2f)
time=%.2f sharpness=%.2f, faceSharpness=%.2f, cameraM=%.2f, subjectM=%.2f, junk=%.2f, obstr=%.2f, exposure=%.2f, score=%.2f
Error -[VNCreateSceneprintRequest setRevision:error:]
Error -[VNImageRequestHandler requestHandler:error:]
NSKeyedUnarchiver error: %@
 VCPFaceShapeModel - caught exception in find_min_box_constrained()
VCPFaceShapeModel - caught exception in find_min()
 VCPFaceShapeModel - caught exception in find_min_using_approximate_derivatives()
Query context: %@
VCPMADVITextLookupTask running...
VCPMADVITextLookupTask image loading failed
VCPMADVITextLookupTask failed to create text lookup query context (%@)
VIService_TextLookup
VCPMADVITextLookupTask complete (%d)
%@ does not implement purge
Real-time analysis client XPC connection interrupted
Real-time analysis client XPC connection invalidated
Pixel buffer not IOSurface-backed; dropping analysis request
Real-time analysis client XPC connection error
Not all needed analysis are available for video highlights.
[%.2f - %.2f] expressionScore=%.2f, actionScore=%.2f, voiceScore=%.2f, Score=%.2f
[%.2f - %.2f] keyFrameScore=%.2f, expressionScore=%.2f, actionScore=%.2f, voiceScore=%.2f, humanActionScore=%.2f, humanPoseScore=%0.2f, qualityJunkScore = %.2f, mlQualityScore = %.2f, Score=%.2f
[HomeKit] Failed to connect to analysis service (%@)
[HomeKit] VCPHomeKitAnalysisSession initialization fails (%@)
[HomeKit] Client XPC connection interrupted
[HomeKit] Client XPC connection invalidated
[HomeKit] Error connecting to background analysis service
[VCPDatabaseReader] No database file exists
[VCPDatabaseReader] Failed to open database: %d
[VCPDatabaseReader] Failed to set busy handler: %d
[MediaAnalysis] Unknown result key for result type %u
[VCPDatabaseReader] Database already opened, failed to execute query block: %d
[VCPDatabaseReader] Failed to execute query block: %d
[MediaAnalysis] Error querying blacklist status for %@
[MediaAnalysis] Failed to query blacklisted assets
[MediaAnalysis] Failed to query asset %@
[MediaAnalysis] Failed to query analysis properties of asset %@
[MediaAnalysis] queryAnalysesForAssets Failed
[MediaAnalysis] Failed to query assets since %@
[MediaAnalysis] Failed to query failed assets for taskID: %lu
[MediaAnalysis] WARNING: ProcessingStatus entry with nil localIdentifier
Failed to query KeyValueStore (error code: %d)
Failed to query scheduling history for background activity %@
[VCPDatabaseReader] Error SQLITE_BUSY encountered, attempting first retry
[VCPDatabaseReader] busy timeout has passed since first retry, stop retrying
Failed to extract NSArray from column %d (%@)
Orientation value %u invalid, assuming kCGImagePropertyOrientationUp
Running Home Resident Maintenance task
Canceling Home Resident Maintenance task (%d)
HomeAI request submitted (%d)
[VCPMADServiceImageProcessing] Fetching Photos asset with identifier %@
[VCPMADServiceImageProcessing] Fetch returned multiple assets for identifier (%@)
[ImageProcessingTask%d] Build task for asset (%@)
[ImageProcessingTask%d] Failed to fetch asset (%@) - %@
[ImageProcessingTask%d] Failed to process asset (%@) - %@
[ImageProcessingTask%d] Finished processing asset (%@)
Request canceled
%@ returned unexpected status (%d)
VCPMADServiceImageProcessingTaskBatch_Run
Failed to create VNGeneratePhotosAdjustmentsRequest
Failed to set VNGeneratePhotosAdjustmentsRequest::setRevision %lu: %@
VNGeneratePhotosAdjustmentsRequest failed
[FaceCropGeneration] Scaling down from %.0fx%.0f with factor: %.3f
[FaceCropGeneration] Scaling up from %.0fx%.0f with factor: %.3f
Invalid orientation found: %d. Using a default value of 1
 [%@] QuickFaceDetect: failed to persist classification results: %@
   [%@] Ignoring analysis results for Montage asset
 [%@] QuickFaceDetect: analyzing asset (deferType: %d)
 [%@] QuickFaceDetect: processed %lu faces
[SceneNet] Failed to find label for identifier %d
[NSFW] Failed to find label for identifier %d
VCPMADVIMachineReadableCodeDetectionTask running...
[MRC] Custom request configuration; overriding to use cached data
VCPMADVIMachineReadableCodeDetectionTask image loading failed
Failed to configure VNDetectBarcodesRequest
[MRC] Custom request configuration; not persisting result
VCPMADVIMachineReadableCodeDetectionTask complete
Flow decoder: fail to bind inputFeature
Flow decoder: fail to bind correlation
Flow decoder: fail to bind upscaled flow
Flow decoder: fail to bind output flow
Flow decoder: fail to bind buffers
Flow decoder: executing callback
Flow decoder: fail to execute
    Pixel Stabilization confidence doesn't pass the threshold
Found %lu faces with CSN > 0 but not in any face groups
[VisionFgMapping] Vision Cluster with single l0clusters; skip de-conflict
[VisionFgMapping] Vision Cluster contains %lu conflicting people
[VisionFgMapping] Conflicting person %@
[VisionFgMapping] Vision Cluster has conflicting l0cluster %@
[VisionFgMapping] Vision Cluster does not have conflicting l0clusters
[VisionFgMapping] Persisting %ld Vision Clusters to Photos FaceGroup
[VisionFgMapping] Invalid csn (%@) for newly clustered face %@
VisionFgMapping_LookingAfterNewClusteredFace
VisionFgMapping_LookingForConflictingCluster
[VisionFgMapping] Split Cluster %@ with %ld faces with representing face csn %@
[VisionFgMapping] 
 csn: %ld 
[VisionFgMapping] Cannot exclude invalid l0RepresentingCSN %@ in l1Cluster %@
[VisionFgMapping] Output (remaining) Cluster %@ -> %@ with %ld faces
VisionFgMapping_ResolveConflictingCluster
[VisionFgMapping] Output (no-touch) Cluster %@ with %ld faces
VisionFgMapping_ResolveConflictL0Clusters
VisionFgMapping_Process
PersistFaceGroups: Photo library is missing a face with CSN = %@
PersistFaceGroups: Faces with these CSNs will be removed from the cluster cache: %@
PersistFaceGroups: Faces with these localIdentifiers will be re-clustered: %@
PersistFaceGroups: We should not get here! If we did, then we have a previously clustered face without a face group!
PersistFaceGroups: Failed to create a face group change request to add faces!
PersistFaceGroups: Failed to find a faceGroup for face '%@' with CSN: %d
PersistFaceGroups: No faces added to face groups!
PersistFaceGroups: Failed to find face with localIdentier: %@. Could not set its CSN to %@
PersistFaceGroups: Set personBuilderState of faceGroups: %@
PersistFaceGroups: Failed to delete empty face groups with error: %@
PersistFaceGroups: Canceled updating key faces unverified persons after persisting face groups.
PersistFaceGroups: Failed to update key faces unverified persons after persisting face groups. Error: %@
%s: %@
[UpdateKeyFaces] Person %@ already has a keyface; skipping
[UpdateKeyFaces] Failed to find a representing face for Person %@ (verified type %ld)
[UpdateKeyFaces] Updating Person %@ (verified type %ld) with key face %@
[UpdateKeyFaces] Found %lu face groups for unverified person)
[UpdateKeyFaces] Failed to persist key face - %@
Warning: cannot handle representativeness with imageprint type %d; ignoring
Warning: Couldn't get faceprint data for face: %@; ignoring
representativeness selection receives a torso-only print; ignoring
Failed to get VNFaceTorsoprint from faceprint data - %@
Warning: Could not get representativeness for faces, error: %@
PersonBuilder: Deleted duplicate graph-verified persons '%@' from face group %@
PersonBuilder: Failed to delete duplicate graph-verified persons '%@' from face group %@
PersonBuilder: Deduped graph-verified persons '%@' from face group %@
PersonBuilder: Failed to dedupe graph-verified persons '%@' from face group %@
personLocalIdentifier for PHFace %@ is null; skip processing
Found no persons rejected for a rejection training face: %@
PersonBuilder: Did not find merge candidate persons with local identifiers: '%@'
PersonBuilder: Found invalid merge candidate pair ['%@' : '%@']
PersonBuilder: Already found merge candidate pair ['%@' : '%@']
PersonBuilder: persist results for facegroup %@
PersonBuilder: Could not create merge candidate pair '%@' : '%@'
PersonBuilder: Could not create invalid merge candidate pair '%@' : '%@'
PersonBuilder: Cleared personBuilderState of faceGroup: '%@'
Could not find a face with clusterSequenceNumber '%@' in the library
%@ Checking face %@
%@ Failed to find face
%@ No valid person
%@ Found person(s) %@
%@ Person mismatch: face (%@) personLocalIdentifier %@ vs faceCropPerson %@ (%ld)
[FaceCropAdjustment] Correcting %lu training face -> person
[FaceCropAdjustment] Failed to find person for face %@
[FaceCropAdjustment] Correcting face %@ from %@ to %@, with nameSource:%ld
[FaceCropAdjustment] Checking %lu rejected person(s)
[RejectedFaceCrop] To remove face %@ for person %@
[FaceCropAdjustment] Removing %lu faces for person %@
[FaceCropAdjustment] Remove face %@ for person %@
[FaceCropAdjustment] Failed to update person - %@
[PHFaceCrop Dedupe] PHFaceCrop without localIdentifier - %@
[PHFaceCrop Dedupe] PHFace without localIdentifier - %@
[PHFaceCrop Dedupe] Missing PHFaceX[%@]
[PHFaceCrop Dedupe] PHFaceX[%@] without faceprint
[PHFaceCrop Dedupe] Missing PHFaceY[%@]
[PHFaceCrop Dedupe] Unmatched training type PHFaceX[%@](%d) and PHFaceY[%@](%d)
[PHFaceCrop Dedupe] PHFaceY[%@] without faceprint
[PHFaceCrop Dedupe] Duplicated with distance: %f [%@:%d] vs [%@:%d]
[PHFaceCrop Dedupe] Distance: %f [%@] vs [%@] - %@
[PHFaceCrop Dedupe] Processing duplications
[PHFaceCrop Dedupe] %lu duplications - %@
[PHFaceCrop Dedupe] Removing %@ dupe to %@
[FaceCrop] Processing newly clustered face crops in %lu PHFaceGroup; start processing ...
[FaceCrop] Fetched %lu PHFaceCrop in PHFaceGroup (%@); skip
[FaceCrop] Fetched %lu newly clustered PHFaceCrop in PHFaceGroup (%@); skip
[FaceCropAdjustment] Fetched %lu PHFaceCrops in PHFaceGroup (%@); start processing ...
[FaceCropAdjustment] Processing finished
[PHFaceCrop Dedupe] Fetched %lu PHFaceCrop in PHFaceGroup (%@); skip
[PHFaceCrop Dedupe] Fetched %lu PHFaceCrops in PHFaceGroup (%@); start dedupping ...
[FaceCrop] Updated %lu PHFaceCrops
[FaceCrop] Failed to update %lu PHFaceCrops - %@
[FaceCrop] Removed %lu duplicated PHFaceCrops
[FaceCrop] Failed to remove %lu duplicated PHFaceCrops - %@
MADProcessNewlyClusteredFaceCrops
PersonBuilder: Got a 'nil' photoLibrary. Cannot build persons
PersonBuilder: Failed to find unverified person for faceGroups '%@'; These will be fixed up and retried later
PersonBuilder: Failed to fix up face groups without unverified person. Error: '%@'
PersonBuilder: Person Building faceGroup '%@'
PersonBuilder: Failed to find unverified person [unverifiedPerson: %@, unverifiedPersonLocalIdentifier: %@] for faceGroup '%@', skipping this face group
%lu Quick classification face to retain: %@
%lu Quick classification face to reassign: %@
PersonBuilder: Quick classification face: %lu retained, %lu reassigned
[VisionFgMapping] Failed to find conflicting l0cluster (expect csn: %@)
PersonBuilder: We may have a dirty level0 cluster, persons with training faces: %@
PersonBuilder: We may have a dirty level0 cluster, verified persons with confirmed face: %@
PersonBuilder: Unnamed unconfirmed faces in face group, '%@', without a training face: %@
PersonBuilder: Found training rejection, unassigned faces on trainingPersonLocalIdentifier in level0 cluster: %@
PersonBuilder: Skip processing level0 cluster since we have rejected face for training person '%@' in level1 cluster
PersonBuilder: Failed to build persons [Error: '%@']
PersonBuilder: ---> buildPersonWithFaceClusterer, %s
VCPFaceProcessingBuildPersonsCoreAnalyticsCollection
PersonBuilder: Person Building is Disabled!
PersonBuilder: Cleared personBuilderState of faceGroups: %@
PersonBuilder: Failed to clear personBuilderState of faceGroups: %@, error: %@
PersonBuilder: <--- buildPersonWithFaceClusterer
Got a 'nil' photoLibrary. Cannot remove auto assigned faces
Failed to remove auto-assigned faces from person '%@', error: %@
  [%@] No scene classification result fetched from pre analysis
Scene identifier %u has no name; ignoring
[MediaAnalysis][%@] No slow-mo timestamp mapping file URL found
[MediaAnalysis][%@] No slow-mo timestamp mapping file found
[%@] Asset has no small video derivative; cannot download
VCPMADVIDocumentRecognitionTask running...
[DocumentRecognition] Custom request configuration; overriding to use cached data
VCPMADVIDocumentRecognitionTask image loading failed
[DocumentRecognition] Set VNProcessingDevice: %@ (%@)
[DocumentRecognition] Custom request configuration; not persisting result
VCPMADVIDocumentRecognitionTask complete
Cannot load Person Identity Model - %@
Person Identity Model not exist - %@
PersonIdentityModel_init
[%@] running...
[%@] complete
[%@] complete without on-demand process
[%@] image loading failed
VCPMADPersonIdentificationTask_createVisionImageRequest
VCPMADPersonIdentificationTask_detectFace
[%@] No face detected from CVPixelBuffer
[%@] Detected %lu faces, identifying ...
[%@] Detected %lu faces, identifying top %lu faces (by confidence) ...
VCPMADPersonIdentificationTask_generateFaceprint
[%@] No face to identify from CVPixelBuffer
[%@] Failed to classify face (%@) - %@; skipping
[%@] No valid identification to face (%@); skipping
[%@] prediction: %@, confidence: %.3f at %@
[%@] Failed to fetch person with identifier %@; skipping
[%@] Identified %lu faces
VCPMADPersonIdentificationTask_identifyFace
[%@] complete with on-demand analysis
Unknown Media Analysis version specified (%d)
[MediaAnalysis] No slow-mo timerange mapper available, fall back to Scaled Time
[MediaAnalysis] No slow-mo timerange mapper available, fall back to Original Time
Invalid Live Photo Gating result type key [%@]
VCPVersionForTask not implemented for %@ (%d); using MediaAnalysisVersion (%d)
  [%@] Unknown analysis version %d; discarding
Failed to get memory information
Failed to query supported revision; %@ does not support
Unsupported revision (%lu) for %@
Checking revision for %@ is not supporteds
Feature extractor: fail to bind input
Feature extractor: fail to bind output at level %d
Feature extractor: fail to bind buffers
Feature extractor: executing callback
Feature extractor: fail to execute
[OCR][%@] Re-using cached results
[VS][%@] Re-using cached results
VCPMADServiceImageURLAsset_Decode
VCPMADServiceImageDataAsset_Decode
[Faces][%@] Asset not processed or outdated
[Faces][%@] Loading existing results from Photos
[NSFW][%@] Asset not processed or outdated
[NSFW][%@] Loading existing results from Photos
[SceneNet][%@] Asset not processed or outdated
[SceneNet][%@] Loading existing results from Photos
[SceneNet] No scene label name for scene id %d
[%@] Ineligible Confidence: %0.3f
[%@] Ineligible Confidence: -
[%@] Selecting resource for Asset Type: %@ [%d/%d] Resolution: %dx%d
[%@] Evaluating resource (Type: %d Resolution: %dx%d)
[%@] Resource not locally available; skipping resource
[%@] Purging resource cache to load uncommon resource (%@)
[%@] Purging resource cache to load large resource (%dx%d)
[%@] Failed to load orientation
[%@] Loaded resource (Type: %d Actual Resolution: %dx%d, orientation %d)
[%@] Failed to load resource (Type: %d)
VCPMADServiceImageAsset_Decode
[%@] Failed to find/decode high-res image resource
[%@] Evaluating high-resolution resource (Type: %d Resolution: %dx%d)
[%@] Evaluating fall-back resource (Type: %d Resolution: %dx%d)
[%@][%@] Deferring persistence until OCR available
[%@][%@] Deferring persistence until MRC available
[%@][%@] Asset has invalid adjustment version (%@); cannot persist results to Photos
[%@][%@] Persisting results to Photos
VNDocumentObservation_archive
[%@][%@] Failed to archive OCR observation
[%@][%@] No text recognized; skipping archive/persistence
VNBarcodeObservation_archive
[%@][%@] Failed to archive MRC observations
[%@][%@] No MR Codes recognized; skipping archive/persistence
[%@][%@] Successfully persisted results to Photos
[%@][%@] Failed to persist results to Photos
[OCR][%@] Checking for existing results from Photos
[OCR][%@] Loading existing results from Photos
[OCR][%@] Failed to unarchive existing Photos results
[OCR][%@] Photos results exist, but no text was recognized
[OCR][%@] Asset does not have existing results
[OCR][%@] Successfully reused existing results
[MRC][%@] Checking for existing results from Photos
[MRC][%@] Loading existing results from Photos
[MRC][%@] Failed to unarchive existing Photos results
[MRC][%@] Photos results exist, but no text was recognized
[MRC][%@] Asset does not have existing results
[MRC][%@] Successfully reused existing results
[VS][%@] Checking for existing results from Photos
[VS][%@] Loading existing results from Photos
[VS][%@] Photos results exist, but empty
[VS][%@] Asset does not have existing results
[VS][%@] Successfully reused existing results
[VS][%@] Asset has invalid adjustment version (%@); cannot persist results to Photos
[VS][%@] Persisting results to Photos
[VS][%@] Successfully persisted results to Photos
[VS][%@] Failed to persist results to Photos
[FaceCropManager][%@] Publish facecrop for face %@
[FaceCropManager][%@] No face detected; force faceprinting
[FaceCropManager] Failed to create VCPPhotosFace - %@
[FaceCropManager][%@] Failed to faceprint - %@
[FaceCropManager][%@] Failed to associate with face %@ - %@
[FacecropManager][%@] Associated with face %@
[FacecropManager] Updating faceprint for face %@
[FaceCropManager][%@] Failed to generate FaceCrop face - %@
[FaceCropManager][%@] Failed to update faceprint of associated face %@  - %@
[FaceCropManager] Set personBuilderState of faceGroup %@ for face %@
[FaceCropManager][%@] Analyzing facecrop (%.0fx%.0f)
[FaceCropManager][%@] Not in a dirty state (state:%d, expect:%d); skipping process
[FaceCropManager][%@] FaceCrop does not have data
[FaceCropManager][%@] existing face %@
[FaceCropManager][%@] Failed to update associated face %@ - %@
[FaceCropManager][%@] Failed to record needing to Person Building for face %@ - %@
[FaceCropManager][%@] Asset has face; skip facecrop generation
[FaceCropManager][%@] Facecrop will not be generated for the manual face %@
[FaceCropManager][%@] Too small facecrop (%.0fx%.0f) using resource %@ (%@)
[FaceCropManager][%@] Generated %lu facecrop(s)
[FaceCropManager] Library has %lu dirty face crops to analyze
[FaceCropManager] Failed to process dirty facecrop %@ - %@
VCPFaceProcessingDirtyFaceCrops
QuickFaceID Model: persistent storageDirectoryURL is nil
QuickFaceID Model: cannot load Persons Model: %@
VCPPersonVIPLoadModel
QuickFaceID Model: model with VNCreateFaceprintRequest revision %lu (FaceProcessing Version%d)
QuickFaceID Model: system is using VNCreateFaceprintRequest revision %lu (FaceProcessing Version%d)
QuickFaceID: failed to initialize face analyzer
QuickFaceID Pet Model: persistent storageDirectoryURL is nil; skip loading Model
QuickFaceID Pet Model: cannot load Model: %@
VCPPetVIPLoadModel
[%@] QuickFaceID: matching person %@
[%@] QuickFaceID: no matching person at location (%.3f, %.3f) - %@
[%@] QuickFaceID: no matching person at location (%.3f, %.3f)
[%@] Ignoring analysis results for Montage asset
QuickFaceID Persons Model is not ready; skip processing
[%@] QuickFaceID: analyzing asset (deferType: %d)
[%@] QuickFaceID: asset is not image
[%@] QuickFaceID: detecting faces
[%@] QuickFaceID: %lu detected faces
[%@] QuickFaceID: processed %lu faces
VCPPersonVIPAssetProcessing
QuickFaceID Pets Model is not ready; skip classifying
QuickFaceID Pet: pet (PHFace) %@ already has a nameSource %ld for petPerson %@; skip
QuickFaceID Pet: pet (PHFace) %@ is used to train this VIP model with petPerson %@; skip
QuickFaceID Pet: Could not create animalprint for pet (PHFace) %@ - %@
QuickFaceID Pet: Failed to classify %@ - %@; skip
QuickFaceID Pet: did not match %@ (at %.3f, %.3f)
QuickFaceID Pet: classified %@ to petPerson %@
QuickFaceID Pet: no petPerson %@; skipping
QuickFaceID Pet: failed to persist pet classification results: %@
QuickFaceID Pet: classified and persisted %lu Pet PHFace
[PersonIdentification] Unsupported library - %@
[PersonIdentification] No face needs to identify
[PersonIdentification] Identifying %lu faces
[PersonIdentification] VIP Persons Model is not ready
[PersonIdentification][%@] Failed to obtain faceprint; skipping
[PersonIdentification][%@] Failed to obtain face observation; skipping
[PersonIdentification][%@] Face identification process failed (%@); skipping
[PersonIdentification][%@] Face identified as %@ confidence:%.2f
[PersonIdentification][%@] Face not identified, confidence:%@
[PersonIdentification] Identified %lu out of %lu faces
[PersonIdentification] Successfully persisted identification results
[PersonIdentification] Failed to persist identification results - %@
QuickFaceID Model: unknown VIP type (%lu); no entity fetched
QuickFaceID Pets Model: Begin Pets model generation
QuickFaceID Pets Model: Failed to initialize VNAnimalObservation
QuickFaceID Pets Model: Failed to create VNEntityIdentificationModelConfiguration - %@
Failed to create VNMutableEntityIdentificationModel - %@
QuickFaceID Pets Model: Model generation cancelled; quitting
QuickFaceID Pets Model: petPerson: %@, petFaceFetchResult(%lu): %@
QuickFaceID Pets Model: Could not create animalprint for pet (PHFace): %@ - %@
QuickFaceID Pets Model: Could not add animalObservation to model for pet (PHFace): %@.
QuickFaceID Pets Model: animalObservations(%lu): %@
QuickFaceID Pets Model: Could not add animalprint to model - %@
VCPPetVIPGenerateModel
QuickFaceID Pets Model: Finished model generation
QuickFaceID Pets Model: Failed to persist pet model %@
QuickFaceID Pets Model: Could not get animalObservations for pet %@ - %@
QuickFaceID Pets Model: Could not persist isInVIPModel on trained pets - %@
QuickFaceID Pets Model: Finished model generation and persistence
QuickFaceID Model: Begin model generation
QuickFaceID Model: Model generation cancelled. Quitting
QuickFaceID: Building %@-confirmed person %@ (%@)
FaceID Model: fetched %lu faces
FaceID Model: fetched %lu faces without roll predicate
QuickFaceID Model: Could not create faceprint for face: %@. Error: %@
QuickFaceID Model: Could not add faceprint to model for face: %@.
QuickFaceID Model: Could not add faceprints to model. Error: %@
QuickFaceID: Built using %lu faces for person %@ (%@)
VCPPersonVIPGenerateModel
QuickFaceID Model: Finished model generation
QuickFaceID Model: Failed to persist model %@
QuickFaceID Model: Could not get face observations for person %@ - %@
QuickFaceID Model: Could not persist isInVIPModel on trained faces - %@
QuickFaceID Model: Finished model generation and persistence
QuickFaceID %@ Model: Last job generation %.0fs ago, job is due = %@
QuickFaceID [FastMigration]: asset processing progress: total: %ld, processed: %ld, failed: %ld
QuickFaceID [FastMigration]: asset processing rate: processed>90%%: %s, failure>10%%: %s, pass: %s
QuickFaceID [FastMigration]: persistent storageDirectoryURL is nil
QuickFaceID [FastMigration]: cannot load Persons Model: %@
QuickFaceID %@ Model: ignoreLastGenerationTime: %s
QuickFaceID %@ Model: No need to generate model
QuickFaceID Model: unknown VIP type (%lu); no model generated
Restore clusterer error (ClusterState = %ld): %@
Restored clusterer, ClusterState = %ld
UpdateKeyFaces for: '%@'
could not update key faces for suggestions: %@
Loaded clustererState: %ld
Returning no suggestions because the clusterer is working
suggestions first phase query start
suggestions first phase query end
suggestions middle phase query start (includes face groups for person query)
suggestions middle phase query end
suggestions last phase query start
suggestions last phase query end
Querying suggestions for person %@ (Photos: %@ to-be-confirmed, %@ to-be-rejected suggestions)
Returning %lu suggestions for person %@
Input parameter is empty or nil: '%@'
Persons Model: Failed to remove model at %@ - %@
Pets Model: Failed to remove model at %@ - %@
Person Processing: Starting Deleting Persons
VCPFaceProcessingDeleteAllVerifiedPersons
Person Processing: Deleting Persons %@
Person Processing: Starting Face Reclustering
VCPFaceProcessingReclusterFacesWithThreshold
Person Processing: Face Clustering %@
Person Processing: Starting Person Building
VCPFaceProcessingBuildPersons
Person Processing: Person Building %@
Person Processing: Starting Person Promotion
VCPFaceProcessingPromotePersons
Person Processing: Person Promotion %@
AVAsset: Montage asset detected
Failed to decode first frame (%@)
[CGImage->CVPixelBuffer] Failed to create CVPixelBuffer with existing IOSurface
[CGImage->CVPixelBuffer] CGImage not IOSurface backed
[CGImage->CVPixelBuffer] Failed to allocate CVPixelBuffer
[CGImage->CVPixelBuffer] Failed to allocate CGContext
[MediaAnalysis] Sample at %lld/%d is being extended %0.1fx
[MediaAnalysis] Requested post process highlight with NULL input analysis
[MediaAnalysis] Post-process highlights returned NULL
[MediaAnalysisResultsTypesForAnalysisTypes] Unknown result type
VideoPetActionAnalyzer: _scoreAbsoluteMax = %f, _scoreRelativeMax =%f
VCPVideoPetsActionTracker
VideoPetActionAnalyzer: finishAnalysisPass
  Extreme aspect ratio %f; initialization failed
[VideoTrackDecoder] Decoded frame and setting mismatch: actual padding right: %zupx, bottom: %zupx (expected right: %zupx, bottom: %zupx)
[VCPFaceCrop][%@] Failed to generate FaceCrop data - %@
[VCPFaceCrop][%@] Failed to create VCPFaceCrop instance
[%@] VCPCoreMLRequest Failed to open model file at url %@
VCPMADVIVisualSearchGatingTask running...
[VS] Cached parse result empty; returning empty result
VCPMADVIVisualSearchGatingTask failed to create visual search query context (%@)
VCPMADVIVisualSearchGatingTask image loading failed
VIService_VisualSearchGating
VCPMADVIVisualSearchGatingTask complete (%d)
VCPFaceAnalyzerImageRequestHandlerPerformRequest
[FaceAnalyzer] Failed to perform requests - %@
[FaceAnalyzer] Failed to create blur/exposure request
[FaceAnalyzer] Blur score %f out of bound [%f, %f]
[FaceAnalyzer] Failed to perform blur requests - %@
[FaceAnalyzer] Exposure score %f out of bound [%f, %f]
[FaceAnalyzer] Failed to perform exposure requests - %@
VCPFaceAnalyzerBlurExposureAnalysis
VCPFaceAnalyzerVCPFaceCreation
[VCPFaceAnalyzer][%@] Failed to create VCPPhotosFace from PHFace %@
VCPFaceAnalyzerVerifyAndMergeFaces
[FaceAnalyzer][%@] Resource (%d) has invalid dimensions (%dx%d); falling back to asset
[FaceAnalyzer][%@] Invalid dimensions (%dx%d)
VCPFaceProcessingFastPathDecodeAsset
[FaceAnalyzer][%@] Failed to decode image
[FaceAnalyzer][%@] Failed to decode orientation (%d)
VCPFaceAnalyzerLoadImageRequestHandler
[FaceAnalyzer][%@] Failed to create VNImageRequestHandler
[FaceAnalyzer][%@] Loaded local resource (%dx%d orientation:%d)
[FaceAnalyzer][%@] Failed to analyze resource
VCPFaceAnalyzerPerformAnalysis
[FaceAnalyzer][%@] Failed to refine analysis
VCPFaceAnalyzerRefineAnalysis
[FaceAnalyzer][%@] Face refine completed: detected %lu | persist: %lu | delete: %lu
[FaceAnalyzer][%@] Missing local resource %@
[FaceAnalyzer] face (center-x:%.2f, center-y:%.2f, size:%.2f) -> boundingBox (x:%.2f, y:%.2f, width:%.2f, height:%.2f)
[FaceAnalyzer] Failed to generate VNFaceObservation from face %@
[FaceAnalyzer] All faces contain valid faceprint
[FaceAnalyzer] Updating %lu faces with missing faceprint
[FaceAnalyzer] Failed to create VNImageRequestHandler for face quality analysis
[FaceAnalyzer] Faceprint VNImageRequestHandler::performRequests: %@
[FaceAnalyzer] faceprint.confidence is too low (%.3f < 0.1) %@ - junkinessIndex: %.3f
[FaceAnalyzer] Accepting faceprint with confidence: %.3f %@ - junkinessIndex: %.3f
[FaceAnalyzer] Update faceprint for face %@
[FaceAnalyzer] Unable to serialize faceTorsoprint - %@
[FaceAnalyzer] No valid faceprint from observation %@
[FaceAnalyzer] Failed to get faceprint for face %@
VCPFaceAnalyzerFillMissingFaceprint
[FaceAnalyzer][%@] No face detected; skip face quality analysis
[FaceAnalyzer][%@] No valid face observations from %lu faces; skip face quality analysis
[FaceAnalyzer] Analyzing %lu face observations for face quality
[FaceAnalyzer] Failed to set Face Quality revision (%lu) - %@
[FaceAnalyzer] Failed to perform Face Quality request - %@
[FaceAnalyzer][%@][%@] No valid Face Quality score; skipping
VCPFaceAnalyzerFaceQuality
[%@] Asset has no small video derivative; skipping
[%@] File size exceeds streaming threshold; skipping
[%@] Duration exceeds streaming threshold; skipping
Unknown VCPTaskID (%lu); redirect to VCPTaskID_MediaAnalysis
[%@] Processing image at scaled resolution (%dx%d)
[%@] Processing image at subsampled resolution (%dx%d)
[%@] Processing image at full resolution (%dx%d)
[%@] Invalid target resolution (%d)
[%@] Resource (%d) has invalid dimensions (%dx%d); falling back to asset
[%@] Asset has invalid dimensions (%dx%d)
-[PHAsset vcp_needsProcessingForTask] not implemented for %@
[%@] Montage asset detected
[%@] Text Confidence: %0.2f Passed Gating: %d
[%@] Text Confidence: 0.00f Passed Gating: 0 [Absent]
[%@] Asset scene properties unavailable or out-of-date
VCPMADVIVisualSearchTask running...
VCPMADVIVisualSearchTask image loading failed
VCPMADVIVisualSearchTask failed to create visual search query context (%@)
[VisualSearch] Using client provided OCR results
VIService_ParsedVisualSearch
VIService_VisualSearch
VCPMADVIVisualSearchTask complete (%d)
VCPVideoStabilizationAssetProcessingTask
Video Stabilization processing failed
Video caption test mode
Video caption is not enabled by defaults write
Video caption only support live photos
Video captioning model not found or user not turning on Image Descriptions in Accessibility
  [%@] Existing analysis outdated; dropping
VCPLightVideoAnalyzer
Movie analyzer perform VCPPhotosQuickFaceDetection
VCPPhotosQuickFaceDetection
VCPVideoCaptionAnalyzer
VCPVideoStabilizerPixel
VCPVideoFaceDetector
VCPFullVideoAnalyzer
VCPVideoSceneClassifier
VCPVideoActivityAnalyzer
VCPVideoSaliencyAnalyzer
VCPVideoHumanActionAnalyzer
videoCaptionAnalyzer
VCPVideoHumanActionClassifier
VCPVideoPetsAnalyzer
VCPVideoPetActionAnalyzer
VCPMovieCurationAnalyzer
VCPVideoStabilizer
VCPSettlingEffectAnalyzer
VCPVideoCNNAnalyzer
    Analyzing Video Segment - Track ID: %d Start: %lld/%d (%0.3fs) End: %lld/%d (%0.3fs)
VCPAudioAnalyzer
    Video track has invalid full frame dimensions (%.f,%.f)
    Video track has invalid clean aperture rect
VCPVideoStabilizerGyro
  [%@] Asset doesn't have gyro metadata
  [%@] Asset does not have valid video track; all %lu tracks: %@
    Video track has invalid dimensions (%.f,%.f)
VCPMovieAnalyzer
ImageHandAnalyzer: input image aspectRatio = %f
ImageHandAnalyzer: aspectRatio = %@, queryAspectRatioVal = %@
ImageHandAnalyzer: feasibleShapeIndex = %d
ImageHandAnalyzer: detectorHeight = %d, detectorWidth = %d
VCPMADServiceImageProcessingTask_Run
[MotionFlow] Failed to lock/unlock pixelbuffer (errcode: %d)
  [%@] Processing
[MediaAnalysis][%@]Unable to open movie, skip
[MediaAnalysis][%@]Failed to create asset
    Analyzing Audio Track - ID: %d Start: %lld/%d (%0.3fs) End: %lld/%d (%0.3fs)
Error resetting all FaceGroups Person Builder state: %@
Failed to clean up merge candidates. Error: %@
VCPFaceProcessingCleanupMergeCandidates
->->-> Enabling personBuilderMergeCandidates
Failed to update key faces - %@
VCPPersonBuilder_UpdateKeyface
VCPMADVIRectangleDetectionTask running...
VCPMADVIRectangleDetectionTask image loading failed
[RectangleDetection] Set VNProcessingDevice: %@ (%@)
VCPMADVIRectangleDetectionTask complete
[VCPPreAnalyzer] Failed to create VCPPoolBasedPixelBufferCreator for monochrome
 [ProbableRotation] Failed to load %@
[VCPPreAnalyzer] Failed to create VCPPoolBasedPixelBufferCreator for rotation
VCPSceneAnalyzerReleaseCachedResources
Failed to create VNClassifyImageAestheticsRequest
Failed to create VNSceneClassificationRequest
Failed to create VNCreateSceneprintRequest
Failed to create VNClassifyJunkImageRequest
Failed to create VNGenerateAttentionBasedSaliencyImageRequest
Failed to set VNClassifyImageAestheticsRequest::setRevision %lu: %@
Failed to set VNSceneClassificationRequest::setRevision %lu: %@
Failed to set VNCreateSceneprintRequest::setRevision %lu: %@
Failed to set VNGenerateAttentionBasedSaliencyImageRequest::setRevision %lu: %@
Failed to set VNClassifyJunkImageRequest::setRevision %lu: %@
Failed to set VNRecognizeObjectsRequest::setRevision %lu: %@
Failed to set VNGenerateObjectnessBasedSaliencyImageRequest::setRevision %lu: %@
Failed to set VNClassifySignificantEventRequest::setRevision %lu: %@
Failed to set VNClassifySemanticDevelopmentGatingRequest::setRevision %lu: %@
Failed to set VNClassifyCityNatureImageRequest::setRevision %lu: %@
Failed to create %@
Unsupported observation label in VCPSpecialLabelToSceneClassificationID %@
Unsupported observation label %@
[DO] detectedObjects count is 0; skip detectedObjects
[DO] invalid confidenceMax: %f; skip detectedObjects
[DO] Failed to choose the best bounding box c_max: %f, c_threshold (0.8x): %f from %@
[DO] Unsupported observation label in PFSceneTaxonomyNode %@
Unsupported observation label in PFSceneTaxonomyNode: %@
Ignoring SceneNet result for tiny image
Unsupported observation label in VCPSpecialLabelToSceneClassificationID %@ (%@)
Unnormalized saliencyRequest bounding box %@; skip
Unnormalized saliencyRequest narrowed bounding box %@; skip
Unnormalized salientObject narrowed bounding box %@; skip
Error creating VNRequest
Unknown ideal dimension for VNRequests (%@), using image dimension %dx%d
Only one VNRequest (%@) for dimension %dx%d; consider coalescing to common resolution
%dx%d
VCPSceneAnalyzerImageRequestHandlerPerformRequest
Failed to run VNImageRequestHandler::performRequests: %@
CVNLPCommSafetyHandler unavailable for IVS
CVNLPCommSafetyHandler_IVS
Failed to run CVNLPCommSafetyHandler::generateClassificationScoresForPixelBuffer:error: %@
VCPSceneAnalyzerImageBlurAnalysis
VCPSceneAnalyzerExposureAnalysis
VCPSceneAnalyzerRotationAnalysisScaling
[ProbableRotation] invalid coreML results
VCPSceneAnalyzerRotationAnalysisInference
No sceneprint data for WP analysis; return default value
VCPWallpaperAnalysis
VCPSceneAnalyzerLoadImageRequestHandler
Failed to load imageURL: %@
VCPSceneAnalyzerPerformAnalysis
VCPFaceGeometry initWithCoder - vertices data missing
VCPFaceAnchor initWithCoder - unexpected size of transform data
VCPCaptureAnalysis - missing resolution properties for prewarming
CNNFastGestureRecognition: start loading model
CNNFastGestureRecognition: inputBlob.height = %d, inputBlob.width = %d, inputBlob.channels = %d
CNNFastGestureRecognition: successfully loaded model
[MotionFlowSubtleMotionAnalyzer] Failed to request flow from VCPMotionFlowRequest: %@
Fail to initialize motionFlowAnalyzer
Motion flow is null
[VCPMediaAnalyzer] Client XPC connection interrupted
[VCPMediaAnalyzer] Client XPC connection invalidated
[VCPMediaAnalyzer] Acquiring media analysis directory sandbox extension...
[VCPMediaAnalyzer] Failed to establish connection or connection lost to service %@; %@
[VCPMediaAnalyzer] Failed to consume media analysis directory sandbox extension
[VCPMediaAnalyzer] Consumed media analysis directory sandbox extension
[MediaAnalysis] failed to get database sandbox extension
[MediaAnalysis] failed to consume sandbox extension
[MediaAnalysis] Consumed sandbox extension
[MediaAnalysis] Failed to obtain analysis sandbox extension for Photo Library (%@); client may not be able to open analysis database
[MediaAnalysis] Requested max highlight duration longer than %.2fs, fall back to %.2fs
[MediaAnalysis][%@] No valid on-demand analysis; skipping
[MediaAnalysis][%@] Storing on-demand analysis
[MediaAnalysis][%@] Failed to store on-demand analysis - %@
[MediaAnalysis][%@]Unable to open movie
[MediaAnalysis][%@] Received analysis request: %@
[MediaAnalysis][%@] Analysis served: (%@)
[MediaAnalysis] [MediaAnalyzer requestAnalysisForAsset] call from invalid instance
[MediaAnalysis] Failed to obtain database for Photo Library %@
[MediaAnalysis] Cancelling request %d
[MediaAnalysis] Failed to find request %d; cannot cancel
[MediaAnalysis] [MediaAnalyzer assetsAnalyzedSinceDate] call from invalid instance
[MediaAnalysis] Failed to obtain database for Photo Library (%@)
Cannot load %@ for %@, NSData length: %lu, content: %@
Cannot load %@ from PHAsset, NSData length: %lu, content: %@
[MediaAnalysis] [MediaAnalyzer distanceFromAsset] call from invalid instance
[MediaAnalysis] Failed to obtain database for assets
[MediaAnalysis] failed to request analyses
[MediaAnalysis] [requestAnalysesForAssets] call from invalid instance
[MediaAnalysis] [requestAnalysesForAssets] in standalone mode but on-demand not allowed
[MediaAnalysis] call from invalid instance
[MediaAnalysis] on-demand analysis requested in standalone mode
Warning: On demand analysis is not supported.
[MediaAnalysis] Failed to obtain database for collection %@
[MediaAnalysis] [requestLivePhotoEffectsForAssets] call from invalid instance
[MediaAnalysis] [requestLivePhotoEffectsForAssets] in standalone mode but on-demand not allowed
Sceneprint task failed (%@)
Error: MAD tracked taxonomy is not the latest in Photos!
Loading PFSceneTaxonomy identifier %@
Failed to initialize PFSceneTaxonomy w/identifier %@ (%@)
Error: MAD tracked taxonomy identifier %@ does not match the latest in Photos: %@!
[PFSceneTaxonomy(MediaAnalysis)] - Failed find scene name for scene id %d
[PFSceneTaxonomy(MediaAnalysis)] - Failed to find scene id for scene name %@
Video track rotation angle is not multiple of 90
Predicate requested for unsupported task (%@) & priority (%d)
Predicate requested for unsupported task (%@)
VNSession_init
CNNHandsDetector: Loading model %@
CNNHandsDetector: adopting model config: %@
CNNHandsDetectorEspresso: updating model config to %@
copyImageToBGRHandDetectorCallFromSPI
scalerHandDetectorCallFromSPI
inferenceHandDetectorCallFromSPI
CNNHandsDetector: hand class index: %d
[%@][MAMLModel] Failed to open model file at url %@
[%@][MAMLModel] Failed to load compiled model (%@): %@
[MAMLModel] Input feature %@ %ldx%ld %ld
[MAMLModel] Missing inputImage feature description %@
[MAMLModel] Mismatched inputImage width (%ld) and height (%ld)
[MAMLModel] Output feature %@ %@
[MAMLModel] Missing output feature %@
  [%@] Fingerprint requested for asset with no objectID
  [%@] Fingerprinting failed
  Fullfilled content request: %@
  Fullfilled data request: %@
Failed to query ideal dimension for request %@ due to empty supportedImageSizeSet
Failed to query ideal dimension for request %@ because the request does not conform to VNImageIdealImageSizeProviding protocol
Failed to configure %@
[DAS QoS] %@: %@ (%@) download %lu bytes
Requested resource exceeds maximum supported size
Resource already in the buffer. Skip downloading.
requestDownloadOfResource: %@
Download progress: %.2f
    Received %llu bytes (Overall: %llu/%llu)
Data received exceeds maximum supported size
Failed to download asset resource (%@)
Successfully downloaded asset resource
Failed to issue resource request
Download resource timed-out
Cancelling download
queryActionResultForPHFace : no action results
queryActionResultForPHFace : not find the best highlight
queryActionResultForPHFace : no faceprint data for face: %@
queryActionResultForPHFace : failed to get VNFaceTorsoprint %@
queryActionResultForPHFace : failed to decode torsoprintAction
queryActionResultForPHFace : failed to get compute torsoprint distance
queryActionResultForPHFace : torsoprint distance with %@, %f
queryActionResultForPHFace : failed to get torsoprints
Connecting to system photo library...
Opening system photo library...
Opened system photo library
Failed to open system photo library (%@)
Failed to obtain system photo library URL
Closed Photo Library
Photo Library unavailable (%@); closing Photo Library...
  [%@] Failed to decode last frame of video, fall back to thumbnail 
[AutoCounter] feature not supported on this OS variant
[AutoCounter] Failed to find asset for face: %@; skip
[AutoCounter] Asset without cloudIdentifier, use localIdentifier: %@
[AutoCounter] Person without localIdentifier; use face.personLocalidentifier
[AutoCounter] Face without personLocalIdentifier; skip
[AutoCounter] Fetched face/person not matching required person; skip
[AutoCounter] Face in a facegroup without localIdentifier; skip
[AutoCounter] No valid faceprint data; leave as unknown
[AutoCounter] No valid momentLocalIdentifier; leave as 'unknown'
[AutoCounter] Face without localIdentifier; skip
[AutoCounter] Failed to fetch person %@
[AutoCounter] Fail to load groundtruth file
[AutoCounter] Person (%@) already opt-in; skip
[AutoCounter] Cannot write opt-in groundtruth to %@ : %@
[AutoCounter] Export URL: %@
[AutoCounter] Failed to find facegroup for mergeCandidate: %@
[AutoCounter] Reach kVCPMaximumNumberOfMergeCandidatesShown (%lu); skip the rest
[AutoCounter][ClusterDump] FaceGroupCount %lu
[AutoCounter][ClusterDump] FaceCount %lu
[AutoCounter] Saved cluster state to %@
[AutoCounter] Cannot write to %@ : %@
[AutoCounter][P/R][GT] Fail to load groundtruth file: %@
[AutoCounter][P/R][GT] Invalid faceID for face: %@; ignore
[AutoCounter][P/R][GT] Invalid PersonID for faceID: %@; ignore
[AutoCounter][P/R][GT] Load faceID: %@ for PersonID: %@
[AutoCounter] Saved assets-to-faces details to %@
[AutoCounter] Cannot write assets-to-faces to %@ : %@
[AutoCounter][P/R] Fail to load cluster state file: %@
[AutoCounter][P/R] Cluster contains no asset information
[AutoCounter][P/R] Cluster contains no data
[AutoCounter][P/R] Invalid information for asset %@ in cluster; ignore
[AutoCounter][P/R] Invalid ID(s) in cluster: %@; ignore
[AutoCounter][P/R] Invalid face rectangle in cluster state for faceID:%@; ignore
[AutoCounter][P/R] processing cluster state faceID: %@ forPersonID: %@
[AutoCounter][P/R] Invalid ground truth rect for faceID:%@
[AutoCounter][P/R][%@] %.4f library: %@, gt: %@ (fid:%@, pid:%@)
[AutoCounter][P/R] Co-location mapping faceID:faceGroupID %@:%@ -> %@:%@
[AutoCounter][P/R] Cannot find asset for id %@
[AutoCounter][P/R] Precision for FaceGroup (of size %d) for personID %@ (of size %lu) is %f
[AutoCounter][P/R] Valid singleton count = %lu, invalid singleton count = %lu
[AutoCounter][P/R] Valid face count for person %@ is %d
[AutoCounter][P/R] personID %@ Recall (of size %lu) is %f
[AutoCounter][P/R] personID %@ Recall (exclude detection miss) (of size %lu) is %f
[AutoCounter][P/R] Weighted Precision: %f, Weighted Recall: %f (number of best face: %.0f)
[AutoCounter][P/R] Weighted Recall (exclude detection miss): %f (number of best face: %.0f)
[AutoCounter][P/R][PV] Processing person cluster %@ with %lu faces
[AutoCounter][P/R][PV] Invalid faceID in person cluster: %@; ignore
[AutoCounter][P/R][PV] Failed to fetch asset for face %@; ignore
[AutoCounter][P/R][PV] Asset without cloudIdentifier, use localIdentifier: %@
[AutoCounter][P/R][PV] Invalid face rectangle in person cluster state for face: %@; ignore
[AutoCounter][P/R][PV] processing person cluster faceID: %@ for PersonID: %@ and clusterID: %@
[AutoCounter][P/R][PV] Valid faceID mapping faceID:personID %@:%@ -> %@:%@
[AutoCounter][P/R][PV] Invalid faceID mapping faceID:faceGroupID %@:%@ -> %@:%@
[AutoCounter][P/R][PV] Invalid ground truth face rectangle for faceID:%@
[AutoCounter][P/R][PV] Valid co-locate mapping faceID:personID %@:%@ -> %@:%@
[AutoCounter][P/R][PV] Invalid co-location mapping faceID:faceGroupID %@:%@ -> %@:%@
[AutoCounter][P/R][PV] Precision for cluster (of size %d) for personID %@ (of size %lu) is %f
[AutoCounter][P/R][PV] Valid singleton count = %lu, invalid singleton count = %lu
[AutoCounter][P/R][PV] Recall for personID %@ (of size %lu) is %f
[AutoCounter][P/R][PV] Weighted Precision: %f, Weighted Recall: %f
[AutoCounter][CA] Report CoreAnalytics: %@
[AutoCounter][CA] Failed to retrive CoreAnalytics export URL
[AutoCounter][CA] Saved CoreAnalytics to %@
[AutoCounter][CA] Cannot write CoreAnalytics to %@ - %@
[AutoCounter][CA] Cannot retrieve CoreAnalytics files %@
[AutoCounter][CA] Files in folder %@
[AutoCounter][CA] Report CoreAnalytics files: %@
[AutoCounter][CA] Report CoreAnalytics file: %@
[AutoCounter][CA] Finished reporting CoreAnalytics %@
[AutoCounter][P/R] Failed to measure Vision cluster state against ground truth
[AutoCounter][P/R][PV] Failed to measure Person cluster state against ground truth
[AutoCounter][P/R][PV] Failed to report CoreAnalytics
[AutoCounter][P/R][SIMLGT] Failed to load SIML ground truth - %@
[AutoCounter][P/R][SIMLGT] Failed to serialize SIML ground truth - %@
[AutoCounter][P/R][SIMLGT] Load faceID: %@ for PersonID: %@
[AutoCounter][P/R][SIML] Failed to export current clusters states
[AutoCounter][P/R][SIML] Validate cluster state  %@ against ground truth %@
[AutoCounter][P/R][SIML] Failed to measure Vision cluster state against SIML ground truth
VCPMADVIUserFeedbackTask running...
VCPMADVIUserFeedbackTask image loading failed
VIService_UserFeedback
VCPMADVIUserFeedbackTask complete (%d)
[MediaAnalysis] [VCPVideoMetaAnalyzer] Unknown analysis type %@
Image Action classifier - merged actions for face  %@
Image Action classifier - torso or face not detected %@
Image Action classifier - PHFace gated out by age attribute
Image Action classifier - action class %d with confidence %f
Unknown device type; this may adversely impact capabilities & performance
VCPPriorityAnalysis - Start initializing
VCPPriorityAnalysis - Finished initializing hand detector
VCPPriorityAnalysis - Finished initializing hand keypoint detector
VCPPriorityAnalysis - Finished initializing gesture recognizer
VCPPriorityAnalysis - Number of hand detected %lu
VCPPriorityAnalysis - dominant hand: %d, hand chirality counter: left: %d, right: %d
VCPPriorityAnalysis - frame interval %f ms
VCPPriorityAnalysis - gestureScoreRightHand %f, gestureScoreLeftHand %f
VCPPriorityAnalysis - gesture score = %f, priority score after thresholding = %f
VCPPriorityAnalysis - Analysis subsampling ratio = %f
VCPPriorityAnalysis - Face yaw: %d
VCPPriorityAnalysis - output priority score = %f
VCPLandmarkValidator failed to validate image (%d)
[ImageManager] kCVPixelFormatType_32BGRA with kCGColorSpaceModelMonochrome, replace with DeviceRGB
[Decode] Accelerated decoding done; CVPixelBuffer: %dx%d, stride:%d, pixelFormat:%d
[Decode] Downscaling %zux%zu --> %zux%zu
[Decode] Slow %@ %.0fx%.0f --> maxDimension:%lu, pixelFormat:%d 
[Decode] %.0fx%.0f --> %zu; subsampling %dx on decode
[Decode] Failed to create CVPixelBuffer from IOSurface; falling back to rendering path
[Decode] Failed to obtain IOSurface; falling back to rendering path
[Decode] Slow decoding done; CVPixelBuffer: %dx%d, stride:%d, pixelFormat:%d
[Decode] Accelerate %@ %.0fx%.0f --> maxDimension:%lu, pixelFormat:%d 
[Decode] Accelerated decode failed; falling back to CGImage
Failed to load pixel buffer due to invalid nil url
Failed to load url %@ (%@)
[ImageManagerEncode] inputCVPixelBuffer cannot be NULL
[ImageManagerEncode] outputJPEGData cannot be nil
[ImageManagerEncode] targetBitStreamLength cannot be 0
[ImageManagerEncode] Encoding CVPixelBuffer -> JPEG (%lu Bytes)
[ImageManagerEncode] Failed to create compression session
[ImageManagerEncode] Fail to open compression container
[ImageManagerEncode] Fail to image buffer
[ImageManagerEncode] Fail to get transcoded data
[ImageManagerEncode] Oversized data (%luBytes)
[ImageManagerEncode] Padding JPEG with %lu Bytes
[ImageManagerEncode] Exporting reencoded JPEGs
VCPHandPoseImageRequest options: _revision = %d
copyImageToBGRHandKeypointCallFromSPI
preProcessingHandKeypointCallFromSPI
Action classifier - empty torso bound in PHFace %@
Action classifier - found torso bound in PHFace %@
[PreAnalysis] Pre-warmed image unused (%dx%d)
[PreAnalysis] Image not pre-warmed; creating on-demand (%dx%d)
%@ canceled (%@)
%@ failed (%@)
HomeKit analysis client XPC connection interrupted
HomeKit analysis client XPC connection invalidated
[HomeKitAnalysis] Error connecting to background analysis service
[HomeKitAnalysis] Request %d is %.2f%% complete
[HomeKitAnalysis] Unknown analysis request %d; dropping cancellation request
[HomeKitAnalysis] No active analysis requests; dropping cancellation request
[VCPFaceMerger] Failed to align face observation - %@
[VCPFaceMerger] Missing face for observation %@ from mapping
[VCPFaceMerger] Bounding box aligner returned an empty rectange
[VCPFaceMerger] Cannot merge face (v%lu, type-%d) with face %@ (v%lu, type-%d, %s imageprint)
[VCPFaceMerger] Cannot merge face with face %@ - distance %f > threashold %f
[VCPFaceMerger] Cannot merge face with face %@ - distance calculation failed %@
[VCPFaceMerger] Cannot Merge in final stage: [mutableDetectedFaces containsObject:detectedFace] %@ [facesToDelete containsObject:matchedExistingFace] %@ 
invalid buffer size %dx%d or pixel format %u
[VCPFaceClusterer] Failed to restore clusterer (state unknown) - %@
[VCPFaceClusterer] Restored Face Clusterer with ClusterState = %ld
Reset restore clusterer error (ClusterState = %ld): %@
Reset restored clusterer, ClusterState = %ld
Person Processing: Starting Reset Face Clustering
VCPFaceProcessingResetFaceClusteringState
Person Processing: Reset Face Clustering Done
Person Processing: Starting Face Clustering
VCPFaceProcessingPerformFaceClusteringAndWait
Person Processing: Face Clustering Done
---> Start face clustering (%ld) with clustering status: %@
---> Finished face clustering (%ld) with clustering status: %@
VCPFaceProcessingClusterFaces
---> Start face clustering as need (%ld) with clustering status: %@
VCPFaceProcessingClusterFacesIfNecessary
  Analyzing degraded version of Movie
Video caption not enabled by defaults write
Image caption test model not exist at %@, not generating image caption
Image captioning model not found or user not turning on Image Descriptions in Accessibility
  [%@] missing Pre Analysis result
  Analyzing degraded version of Photo
VCPImageFaceDetector
VCPImageFaceExpressionAnalyzer
Failed to create CVNLPCaptionHandlerRef (%@)
VCPImageJunkAnalyzer
VCPImageBlurAnalyzer
VCPLowResImageBlurAnalyzer
VCPImageExposureAnalyzer
VCPImageLivePhotoBlurAnalyzer
VCPImageCompositionAnalyzer
VCPImageDescriptor
VCPImageSaliencyAnalyzer
VCPImagePetsAnalyzer
VCPImagePetKeypointsAnalyzer
VCPImageHumanPoseAnalyzer
Human action on Live Photo requires paired movie, skip analyzing still
VCPImageHumanActionAnalyzer
VCPImageHandsAnalyzer
VCPLivePhotoAnalysis
Live Photo w/o local movie resource and streaming not allowed, skip paired movie analysis
VCPEffectsAnalyzer
[MediaAnalysis] PhotoAnalyzer - Original movie is not available, skip effects analysis
VCPParallaxAnalyzer
VCPFaceQualityAnalysis
VCPLivePhotoKeyFrameAnalyzer
VCPPhotoAnalyzer
VCPEmbeddingAnalyzerLoadImageRequestHandler
VCPNeuralHashprintRequest
NeuralHashprint Vision request failed: %lu - %@
VCPImageHashSignatureRequest
NeuralHash+LSH Vision request failed: %lu - %@
NeuralHash+LSH invalid imageSignatureHash
NeuralHash+LSH failed to encode hash: %@
Invalid NeuralHash+LSH (=)
Cannot create VCPPersonBuilder
---> Canceling VCPBuildPersons
VCPBuildPersons canceled
VCPBuildPersons failed: %@
Cannot create PVPersonPromoter
---> Canceling VCPPromotePersons
Person Processing: Starting Person Promoting
VCPFaceProcessingPromotePersonsCoreAnalyticsCollection
Person Processing: Person Promoting %@
VCPPromotePersons canceled
VCPPromotePersons failed
Cannot create PVPersonPromoter for evaluation
---> Canceling VCPFetchPersonPromoterClusterForEvaluation
Person Processing: Start evaluatePersonPromoterWithUpdateBlock
Person Processing: Retrieved %lu unverified person
Person Processing: evaluatePersonPromoterWithUpdateBlock canceled
Unknown Photos Face Processing umbrella version %d
[Perf] %s: %0.6fs
%-40s  %10s  %10s  %10s  %10s  %10s
  %-38s  %10.6f  %10.6f  %10.6f  %10.6f  %10zu
[CoreAnalyticManager] Session event name is nil; skipping
[CoreAnalyticManager] Session fields name is nil for event %@; skipping
[CoreAnalyticManager] Start session event %@ (total session count %lu)
[CoreAnalyticManager] Ignore 0-accumulation for event %@ field %@
[CoreAnalyticManager] Session event %@ not available
[CoreAnalyticManager] Session event %@ not available; skip sending
[CoreAnalyticManager] flushing analytics ... 
[CoreAnalyticManager] flushSessionAnalytics (total count %lu)
Failed to analyzeDetectedFaces - %@
song analysis failed %@
  [%@] Need Face Processing: no faceAdjustmentVersion
  [%@] Need Face Processing: faceAdjustmentVersion %@ != adjustmentTimestamp %@
Attempt to download resource: %@
[%@] Download progress: %.2f
Download resource timed-out (ID:%d)
Cancelling download (ID:%d)
[FileBasedDownload] Downloaded resource to file url: %@
[FileBasedDownload] Failed to download asset resource (%@)
[FileBasedDownload] Successfully downloaded asset resource
[FileBasedDownload] Failed to issue resource request
[FileBasedDownload][%@] Downloading %@
VCPDownloadResource
[FileBasedDownload][%@] Progress: %.2f
[FileBasedDownload][%@] URL: %@
[FileBasedDownload][%@] Failed on resource %@ - %@
[FileBasedDownload][%@] Success!
[FileBasedDownload][%@] Failed to issue resource request
Wrong outHeight in parseHeatmap2Keypoints
Wrong outWidth in parseHeatmap2Keypoints
[ResourceManager] Invalid cost detected (%ld); clipped to %ld
[ResourceManager] Updating budget (%ld --> %ld)
[ResourceManager] Hit usage timeout; purging resources
[ResourceManager] Request to reserve budget [Budget: %ld][Target: %ld]
[ResourceManager] Pruning inactive resources
[ResourceManager] Purging inactive resource (%@)
[ResourceManager] Failed to reserve budget [Budget: %ld][Target: %ld]
[ResourceManager] Request to activate %@
[ResourceManager] Resource not cached (%@)
[ResourceManager] Resource cached but not active (%@)
[ResourceManager] Activating resource (%@)
[ResourceManager] Resource cached and active (%@)
[ResourceManager] Active resource cost has increased (%@)
[ResourceManager] Active resources exceed budget
[ResourceManager] Active count %d
[ResourceManager] Request to deactivate %@
[ResourceManager] Resource transition active --> inactive (%@)
[ResourceManager] Received request to deactivate un-tracked resource (%@)
[ResourceManager] Request to purge inactive resources
[ResourceManager] Skipping active resource (%@)
[ResourceManager] Purging %@
[ResourceManager] Purging active resource (%@)
[ResourceManager] Request to purge all resources
Requested unavailable frame %d (Frame Count: %d  Buffer Depth: %d)
Unexpected media type (%lu)
[%@] Unexpected media type (%d)
[MotionFlowAnalyzer] Failed to request flow from VCPMotionFlowRequest: %@
Gyro analytics stored via dodML
Could not load MonzaV4_1.mlmodelc in the bundle resource
softlink:r:path:/System/Library/PrivateFrameworks/PhotoVision.framework/PhotoVision
softlink:r:path:/System/Library/PrivateFrameworks/HomeAI.framework/HomeAI
softlink:r:path:/System/Library/PrivateFrameworks/HomeAI.framework/HomeAI
softlink:r:path:/System/Library/PrivateFrameworks/PhotosGraph.framework/PhotosGraph
softlink:r:path:/System/Library/PrivateFrameworks/PhotoVision.framework/PhotoVision
softlink:r:path:/System/Library/PrivateFrameworks/PhotoVision.framework/PhotoVision
softlink:r:path:/System/Library/PrivateFrameworks/HomeAI.framework/HomeAI
softlink:r:path:/System/Library/PrivateFrameworks/PhotoVision.framework/PhotoVision
softlink:r:path:/System/Library/Frameworks/ShazamKit.framework/ShazamKit
VCPProtoMovieLaughterResult
NSCopying
VCPPetsRegion
VCPVideoPetsAnalyzer
VCPSettlingEffectAnalyzer
PVPhotoLibraryProtocol
NSObject
LegacyConversion
VCPProtoResultLegacyConversionProtocol
VCPInternetReachability
VCPVideoCNNAnalyzer
VCPProtoMovieSceneResult
VCPMAMLFeatureProvider
MLFeatureProvider
VCPVoiceDetector
VCPProtoMovieAudioQualityResult
PHAssetResource
VCPFullVideoAnalyzer
VCPProtoMovieFineSubjectMotionResult
BackwardCompatability
VCPVideoFullFaceDetector
CMTimeRange
VCPHomeFaceIdentificationTask
VCPMADTaskProtocol
VCPFingerprint
VCPCNNHandKeypointsDetectorEspresso
VCPImageExposurePreAnalyzer
VCPImageDescriptor
VCPDistanceDescriptorProtocol
VCPProtoLivePhotoKeyFrameResult
VCPCNNDataGPU
VCPVideoMetaFaceAnalyzer
VCPProtoKeypoint
PVFaceProtocol
VCPSuggestionRequest
VCPClusterer
PVFaceClusteringProtocol
VCPHumanPoseImageRequest
VCPVideoCNNTask
VCPProtoMovieHighlightScoreResult
VCPMADVIRemoveBackgroundCachedImageHandler
VCPMADVIRemoveBackgroundResource
VCPMADVIRemoveBackgroundTask
VCPMADServiceImageProcessingSubtaskProtocol
VCPVideoProcessorNode
VCPImageConverter
VCPFullAnalysisAssetProcessingTask
VCPMediaAnalysisServerProtocol
VCPMediaAnalysisClientProtocol
VCPMediaAnalysisService
FaceSuggestions
PersonBuilderAndPromoter
InternalTools
Hubble
VCPVideoCaptionEncoder
VCPHumanPoseEspressoSession
CMTime
VCPCNNPetsDetector
VCPMADImageSafetyClassificationResource
VCPMADImageSafetyClassificationTask
VCPCNNSmileDetector
VCPPhotosFace
PFPhotosFaceRepresentation
VCPCNNEspressoContext
VCPProtoMoviePetsFaceResult
VCPCNNPoseEstimatorEspresso
VCPVideoCNNQuality
VCPSegment
VCPClassification
VCPVideoSceneClassifier
VCPProtoImageFeatureResult
VCPTimer
VCPProtoImageHumanPoseResult
VCPProtoMovieQualityResult
VCPPhotosFaceProcessingContext
VCPFaceUtils
VCPProtoImageSceneprintResult
VCPProtoMovieSubtleMotionResult
VCPProtoMovieHumanActionResult
CGRect
VCPVideoPixelStabilizer
VCPContentAnalysis
VCPLightMotionAnalyzer
VCPLoaned
VCPObjectPool
VCPCNNFullConnectionBlockScalar
VCPProtoMovieSaliencyResult
VCPPreAnalysisRequests
VCPProtoImageFaceResult
VCPJunkAnalyzer
VCPVideoMetaMotionAnalyzer
VCPVideoMetaMotionSegment
VCPMADVIResource
VCPProtoVideoKeyFrame
VCPMediaAnalysis
VCPCNNModelEspresso
VCPWallpaperAnalyzer
MercuryBase64
VCPCNNPoolingBlockGPU
VCPClientDatabaseManager
VCPEdgeDetector
VCPVideoCaptionAnalyzer
VCPVideoTrackSyncDecoder
VCPProtoMovieClassificationResult
VCPVNImageprintWrapper
VCPVideoKeyFrameAnalyzer
VCPMetaSegment
VCPSharedInstanceManager
VCPMetaTrackDecoder
VCPAnalysisProgressQuery
VCPCNNConvBlockVector
VCPSaliencyRegion
VCPVideoSaliencyAnalyzer
VCPHandPoseVideoRequest
VCPMoFlowSingleEspresso
VCPImageQualityAnalyzer
VCPMADEmbeddingGenerationTask
VCPVideoProcessorSession
VCPProtoImageBlurResult
VCPFaceIDModel
VCPVanishingPointDetector
VCPVideoHumanActionClassifier
VCPImageSaliencyAnalyzer
MediaAnalysis
VCPMovieCurationAnalyzer
VCPMovieHighlight
VCPModelR2D2
PVAssetProtocol
VCPProtoMovieUtteranceResult
VCPProtoImageSaliencyResult
VCPMotionFlowRequest
VCPImageCompositionAnalyzer
VCPFaceProcessingVersionManager
VCPLightVideoAnalyzer
VCPVideoKeyFrame
VCPSceneprintDescriptor
VCPProtoImageShotTypeResult
VCPProtoImagePetsFaceResult
VCPImagePetsAnalyzer
VCPVideoFacePoseFilter
VCPCNNFullConnectionBlockGPU
PVPersonProtocol
VCPProtoBounds
VCPFace
VCPFaceDetectionRange
VCPFaceShapeModel
VCPCNNFaceLandmarkDetectorEspresso
VCPMADVITextLookupTask
VCPProtoImageCompositionResult
VCPImageFaceDetector
VCPMADResource
VCPCNNSmileDetectorEspresso
VCPVideoCNNHighlight
VCPRealTimeAnalysisServerProtocol
VCPRealTimeAnalysisClientProtocol
VCPRealTimeAnalysisService
MADActivitySchedulingRecord
CGPoint
VCPVideoPersonDetector
VCPProtoLivePhotoFrameInstruction
VCPFaceTensorModel
VCPProcessingStatusEntry
VCPProtoLivePhotoVariationParams
VCPImagePetsKeypointsAnalyzer
VCPVideoActivityAnalyzer
VCPCompactResult
VCPVideoGlobalAnalyzer
VCPCNNPoolingBlock
VCPProtoMovieHumanPoseResult
VCPExpressionSegment
VCPMovieHighlightAnalyzer
VCPHomeKitAnalysisSessionServerProtocol
VCPHomeKitAnalysisSessionClientProtocol
VCPHomeKitAnalysisSession
VCPHomeKitSessionExportedObject
VCPDatabaseReader
VCPProtoTime
VCPURLAsset
Image
LivePhoto
Movie
VCPExifAnalyzer
VCPHomeResidentMaintenanceTask
VCPMADServiceImageProcessingTaskBatch
VCPVideoCNNBackbone
VCPLoudnessAnalyzer
VCPProtoMovieActivityLevelResult
VCPColorNormalizationAnalyzer
VCPFaceCropUtils
VCPPhotosQuickFaceDetectionManager
VisualSearch
VCPMADMachineReadableCodeResource
VCPMADVIMachineReadableCodeDetectionTask
VCPHuman
VCPFlowDecoder
VCPProtoMovieInterestingnessResult
VCPLandmarkValidator
VCPVideoStabilizer
VCPPhotosPersistenceDelegateAdditions
VCPMergeCandidatePair
VCPPhotosPersistenceDelegate
PVPersonPromoterDelegate
VCPProtoImageExposureResult
VCPProtoMovieFeatureResult
VCPPhotosAsset
VCPMADVIDocumentRecognitionResource
VCPMADVIDocumentRecognitionTask
VCPMADPersonIdentificationTaskResource
VCPMADPersonIdentificationTask
VCPBlurAnalyzer
VCPHumanPoseVideoRequest
VCPImageBlurAnalyzer
VCPFlowFeatureExtractor
VCPImageExposureAnalyzer
VCPProtoAssetAnalysis
VCPMADServiceImagePixelBufferAsset
VCPMADServiceImageURLAsset
VCPMADServiceImageDataAsset
VCPMADServiceImagePhotosAsset
VCPMADServiceImageAsset
VCPCNNFaceLandmarkDetectorMPS
VCPVideoObjectTracker
VCPFaceCropManager
VCPPhotosQuickFaceIdentificationManager
VCPCNNBlurAnalyzerEspresso
VCPVideMetaOrientationAnalyzer
VCPFaceProcessingServiceWorker
VCPVideoTrackSubsamplingDecoder
VCPFrameAnalysisStats
VCPVideoCNNAutoplay
VCPVideoPetsActionAnalyzer
VCPVideoKeyFrameResult
VCPMovieHighlightResult
VCPMovieCurationResults
VCPVideoTrackDecoder
VCPFaceCrop
VCPCoreMLRequest
VCPFrameScoreFilter
VCPProtoMovieBabbleResult
VCPMADVIVisualSearchGatingTask
VCPEspressoModel
VCPFaceAnalyzer
MovieResource
VCPSoundDetector
SNResultsObserving
VCPSoundClassifier
VCPAudioClassifier
VCPProtoMovieFaceprintResult
VCPCNNBlock
MediaAnalysisPhoto
MediaAnalysisMovie
MediaAnalysisSceneProcessing
MediaAnalysisOCRProcessing
MediaAnalysisVisualSearchProcessing
VCPMADVIVisualSearchTask
VCPGeometryUtils
VCPProtoMovieCheeringResult
VCPProtoMovieMusicResult
VCPCNNFaceLandmarkDetector
VCPCNNSmileDetectorMPS
VCPCNNConvBlockGPU
VCPVideoProcessor
VCPProtoMovieStabilizationResult
VCPProtoMovieHighlightResult
VCPCNNFullConnectionBlock
VCPHomeKitMotionAnalyzer
VCPProtoMovieSceneprintResult
CMTimerange
VCPSlowmo
VCPProtoMovieSubjectMotionResult
VCPBoundingBox
VCPCNNPoseEstimator
VCPVideoStabilizationAssetProcessingTask
VCPMovieAnalyzer
VCPImageHandsAnalyzer
VCPProtoMovieObstructionResult
VCPMADServiceImageProcessingTask
VCPProtoLivePhotoEffectsResult
VCPCNNBlurAnalyzer
VCPProtoLivePhotoRecommendationResult
VCPDatabaseBatchIterator
PVFetchResultProtocol
NSFastEnumeration
VCPProtoTimeRange
VCPImageLivePhotoBlurAnalyzer
VCPFullAnalysisURLProcessingTask
PVFaceGroupProtocol
VCPProtoLivePhotoEffectsRecipe
VCPProtoLivePhotoHumanActionClassificationResult
VCPAudioAnalyzer
VCPCNNGazeAnalysis
VCPPersonBuilder
VCPImageHumanPoseAnalyzerTopDown
VCPProtoMoviePreEncodeResult
VCPMADVIRectangleDetectionResource
VCPMADVIRectangleDetectionTask
VCPPreAnalyzer
VCPVideoTrackStandardDecoder
VCPCNNPersonKeypointsDetector
VCPFaceGeometry
NSSecureCoding
NSCoding
VCPFaceAnchor
VCPCaptureAnalysisSession
VCPCNNPetsDetectorEspresso
VCPCNNFastGestureRecognition
VCPMotionFlowSubtleMotionAnalyzer
VCPEffectsAnalyzer
VCPVideoFaceDetector
VCPGaborFilter
VCPCancelToken
VCPStorageServiceProtocol
VCPMediaAnalyzer
VCPPhotosSceneprintAssetProcessingTask
PVMomentProtocol
VCPImageAnalyzer
VCPVideoMetaLensSwitchAnalyzer
VCPVideoMetaLivePhotoMetaAnalyzer
VCPCNNData
VCPHoughTransform
VCPRTLandmarkDetector
VCPCNNConvBlock
VCPCNNConvBlockScalar
VCPProtoImagePetsResult
VCPMADVisionResource
VCPCNNHandsDetector
VCPMAMLModel
VCPCNNPoolingBlockVector
VCPRequest
VCPProtoClassification
VCPInMemoryAVAsset
AVAssetResourceLoaderDelegate
VCPProtoMovieFaceResult
VCPProtoLivePhotoKeyFrameStillResult
VCPDownloadManager
VCPTransforms
VCPActionAnalyzer
MediaAnalysisResults
MediaAnalysisPauseResume
VCPImageMotionFlowAnalyzer
VCPDefaultPhotoLibraryManager
PHPhotoLibraryAvailabilityObserver
VCPInterAssetAnalyzer
VCPClusteringAccuracyMeasures
VCPPhotosAutoCounterWorker
VCPProtoPoint
Exif
VCPImageSaliencyAnalyzerFull
VCPMADVIUserFeedbackTask
VCPMADVIVisualSearchResource
VCPVideoMetaAnalyzer
VCPKeypoint
VCPPersonObservation
VCPHandObservation
VCPMotionFlowObservation
VCPImageHumanActionAnalyzer
VCPProtoMovieApplauseResult
VCPPriorityAnalysis
VCPVideoFaceMeshAnalyzer
bRVA
VCPImageManager
VCPHandPoseImageRequest
VCPCNNHandKeypointsDetector
VCPVoiceDetectorV2
VCPCNNPoseEstimatorMPS
VCPProtoImageJunkResult
VCPProtoMovieCameraMotionResult
VCPVideoCNNActionClassifier
VCPImageSaliencyAnalyzerFullEspresso
VCPCNNFlattenBlock
VCPVideoMetaFocusAnalyzer
VCPVideoMetaFocusSegment
VCPProtoMovieLoudnessResult
VCPPreAnalysisImageEntry
VCPPreAnalysisImage
VCPMABaseTask
VCPHomeKitAnalysisServerProtocol
VCPHomeKitAnalysisClientProtocol
VCPHomeKitAnalysisService
Client
Resident
VCPPhotosFacePair
VCPFaceMerger
VCPLivePhotoKeyFrameAnalyzer
VCPCNNPersonDetector
VCPPoolBasedPixelBufferCreator
VCPParallaxAnalyzer
VCPImageFaceExpressionAnalyzer
VCPTimeMeasurement
VCPImageHumanPoseAnalyzer
VCPFaceClusterer
VCPBackwarp
VCPLogManager
VCPProtoMovieSummaryResult
VCPPreAnalysisImageLoader
VCPProtoMovieVoiceResult
VCPCNNMetalContext
VCPCNNBlurAnalyzerMPS
VCPPhotoAnalyzer
VCPMAEmbeddingAnalyzer
VCPTrimAnalyzer
VCPSceneChangeAnalyzer
VCPSceneChangeSegment
VCPMADCoreAnalyticsManager
VCPProtoMovieOrientationResult
VCPSceneProcessingImageManager
VCPImageFaceQualityAnalyzer
VCPVideoLightFaceDetector
VCPProtoMoviePetsResult
VCPVideoAnalyzer
VCPPnPSolver
VCPSongDetector
VCPProtoLivePhotoKeyFrameFaceResult
VCPCorrelation
VCPVideoHumanActionAnalyzer
VCPAsset
VCPPHFaces
VCPProtoLine
VCPProtoMovieStabilizationRecipe
VCPCNNPetsKeypointsDetector
VCPVideoFacePoseAnalyzer
VCPVideoCNNCameraMotion
VCPVideoActivityDescriptor
VCPCNNModel
VCPMADResourceLock
VCPMADResourceEntry
VCPMADResourceManager
VCPProtoMovieMovingObjectResult
VCPDeviceInformation
VCPCNNPoolingBlockScalar
FullAnalysis
VCPMotionFlowAnalyzer
VCPProtoLivePhotoSharpnessResult
VCPVideoGyroStabilizer
MonzaV4_1Input
MonzaV4_1Output
MonzaV4_1
VCPCtrTracker
VCPBaseTracker
.cxx_destruct
T@"NSData",&,N,V_sceneprintBlob
ComputeSceneDelta:
T@"NSDictionary",R,N,V_analysis
ExtractActivityDescriptorFromStats:
T@"NSString",R,N,V_clientTeamID
PrintSegments
T@"VCPProtoBounds",&,N,V_bounds
T#,R
T@"VNTorsoprint",&,V_torsoprint
T@"<MTLCommandQueue>",&,V_commandQueue
TB,N,V_hasFlash
T@"<PVFaceProtocol>",&,N
TB,N,V_maskOnly
T@"MLModel",R,N,V_model
TQ,R,N,V_status
T@"NSArray",&,N,V_keypoints
TS,N,V_gazeType
T@"NSArray",C,N,V_barcodeObservations
TS,N,V_poseType
T@"NSArray",R,&,N
T^q,R,N
T@"NSArray",R,V_cflags
Td,N,V_duration
T@"NSData",&,N,V_colorNormalization
Tf,N,V_faceArea
T@"NSData",&,N,V_faceprintBlob
Tf,V_confidence
T@"NSData",&,N,V_recipeBlob
Ti,N,V_personID
T@"NSData",R,N
Ti,N,V_revision
T@"NSDate",N,V_startTime
Ti,R,V_logLevel
T@"NSDate",R,N,V_lastRetryDate
Tr^,R,N
T@"NSDictionary",R
T@"NSDictionary",R,N
_actionAnalyzer
T@"NSDictionary",R,N,V_objectsMotion
_activeKeyFrame
T@"NSMutableArray",&,N,V_detectedFaces
_allowStreaming
T@"NSMutableArray",&,N,V_faceResults
_assets
T@"NSMutableArray",&,N,V_imageBlurResults
_backwarpKernel
T@"NSMutableArray",&,N,V_imageExposureResults
_bounce
T@"NSMutableArray",&,N,V_imageFeatureResults
_budget
T@"NSMutableArray",&,N,V_imageJunkResults
_cancel
T@"NSMutableArray",&,N,V_imagePetsResults
_clientBundleID
T@"NSMutableArray",&,N,V_imageSceneprintResults
_clusterBuilder
T@"NSMutableArray",&,N,V_keypoints
_cnnInputHeight
T@"NSMutableArray",&,N,V_livePhotoHumanActionClassificationResults
_configureRequest:withRevision:
T@"NSMutableArray",&,N,V_livePhotoKeyFrameStillResults
_cropRectHeight
T@"NSMutableArray",&,N,V_livePhotoSharpnessResults
_curExprWeights
T@"NSMutableArray",&,N,V_movieActivityLevelResults
_detectionModeCounterShapeModel
T@"NSMutableArray",&,N,V_movieAudioQualityResults
_downScaleWidth
T@"NSMutableArray",&,N,V_movieCameraMotionResults
_embeddingWidth
T@"NSMutableArray",&,N,V_movieClassificationResults
_energy
T@"NSMutableArray",&,N,V_movieFaceprintResults
_expressionType
T@"NSMutableArray",&,N,V_movieFineSubjectMotionResults
_faceId
T@"NSMutableArray",&,N,V_movieHighlightScoreResults
_facialHairType
T@"NSMutableArray",&,N,V_movieHumanPoseResults
_filter
T@"NSMutableArray",&,N,V_movieLaughterResults
T@"NSMutableArray",&,N,V_movieMovingObjectResults
_generateOutput
T@"NSMutableArray",&,N,V_movieObstructionResults
_groups
T@"NSMutableArray",&,N,V_moviePetsFaceResults
_height
T@"NSMutableArray",&,N,V_moviePreEncodeResults
_hidden
T@"NSMutableArray",&,N,V_movieSaliencyResults
_humanPoseScore
T@"NSMutableArray",&,N,V_movieSceneprintResults
_imageGenerator
T@"NSMutableArray",&,N,V_movieSubjectMotionResults
_inputNumFrames
T@"NSMutableArray",&,N,V_movieSummaryResults
_isAutoPlayable
T@"NSMutableArray",&,N,V_movieVoiceResults
_isHeadingFrame
T@"NSMutableArray",&,V_faceQualityScores
_isSegmentPoint
T@"NSMutableArray",&,V_precisionPerCluster
_length
T@"NSMutableArray",&,V_recallPerPersonToGroundTruth
_loadImageURL:withSession:reencodedImageData:andRequestHandler:
T@"NSMutableArray",&,V_voiceDetections
_master
T@"NSMutableArray",W,V_inputSize
_mediaAnalysisServiceConnection
T@"NSMutableDictionary",&,N,V_results
_motionDivScore
T@"NSSet",R,N
_nextSampleTime
T@"NSString",&,N,V_assetIdentifier
_numInternalLms
T@"NSString",&,N,V_faceId
_numTri
T@"NSString",&,V_sceneId
_object
T@"NSString",C,N,V_groupingIdentifier
_output
T@"NSString",R,C
_outputFrameIdx
T@"NSString",R,N
_personDetector
T@"NSString",R,N,V_inputFeatureName
_photoSharpness
T@"NSString",R,N,V_outputFeatureName
_preferredAngle
T@"NSString",R,V_adjusted
_prevHandCenter
T@"NSString",R,V_person1LocalIdentifier
_privateResults
T@"NSString",R,V_reason
_processingMode
T@"NSURL",R,N
T@"PHAsset",R,N,V_phAsset
_qualityMeasure
T@"VCPCNNData",&,V_output
_reader
T@"VCPCNNData",W,V_input
_region
T@"VCPCNNMetalContext",W,V_context
_requestHandler
T@"VCPFingerprint",R,N
_resultsHandler
T@"VCPImageDescriptor",&,N,V_descriptor
_sampleDuration
T@"VCPMADVIRemoveBackgroundCachedImageHandler",&,N,V_cachedImageHandler
_sandboxHandles
T@"VCPPhotosFace",R,N,V_face2
_sceneprintBlob
T@"VCPProtoBounds",&,N,V_playbackCrop
_source
T@"VCPProtoLivePhotoVariationParams",&,N,V_autoloop
_stabilityScore
T@"VCPProtoLivePhotoVariationParams",&,N,V_longexposure
_status
T@"VCPProtoPoint",&,N,V_end
_suggestionLock
T@"VCPProtoPoint",&,N,V_vanishingPoint
_summaryResults
T@"VCPProtoTime",&,N,V_timestamp
_timeOfInterest
T@"VCPProtoVideoKeyFrame",&,N,V_keyFrame
_transformImage
T@"VCPVideoActivityDescriptor",&,N,V_videoActivityDescriptor
_updateFace:withFaceCrop:error:
T@"VCPVideoKeyFrameResult",R,N,V_keyFrame
_updatedFaceGroupByFGLocalIdentifierFromClusterCSNs:fetchLimit:
T@"VN1JC7R3k4455fKQz0dY1VhQ",&,N,V_adjustmentsRequest
_validDimension
T@"VN6Mb1ME89lyW3HpahkEygIG",&,N,V_tabooRequest
T@"VNClassifyCityNatureImageRequest",&,N,V_cityNatureRequest
_visionCanceler
T@"VNClassifyJunkImageRequest",&,N,V_junkImageRequest
_weight
T@"VNClassifyPotentialLandmarkRequest",&,N,V_landmarkRequest
T@"VNCreateSceneprintRequest",&,N,V_sceneprintRawRequest
addMovieInterestingnessResults:
T@"VNFaceObservation",&,V_observation
ageType
T@"VNGenerateObjectnessBasedSaliencyImageRequest",&,N,V_saliencyObjectnessRequest
analysisService
T@"VNRecognizeDocumentElementsRequest",&,N,V_documentRequest
analyzeFrame:withTimestamp:andDuration:properties:flags:cancel:
T@"VNRequest",R,N,V_request
assetId
T@"VNSession",R,N
autoCancellable
T@?,C,N,V_cancel
blurrinessScore
T@?,C,V_progressHandler
bundleForClass:
T@?,R,N,V_completionHandler
cachesResources
TB,D,N
centerX
TB,N,V_allowStreaming
classifications
TB,N,V_cancelled
clearMovieClassificationResults
TB,N,V_frameProcessedByFaceDetector
clearTimeValues
TB,N,V_frameProcessedByPetsActionAnalyzer
cnnData
TB,N,V_gyroStabilization
completeStorage
TB,N,V_hasAction
computeHighlightScoreOfSegment:
TB,N,V_hidden
conformsToType:
TB,N,V_isCloseup
contentAnalysis
TB,N,V_isHeadingFrame
convBlockClass:
TB,N,V_isLeftEyeClosed
copyTo:
TB,N,V_isSettlingOK
createInput:withBuffer:cnnInputHeight:cnnInputWidth:faceBounds:
TB,N,V_isTrimmed
dataWithLength:
TB,N,V_personBuilderMergeCandidatesDisabled
destroy
TB,N,V_validStabilization
detector:sharedModel:modelName:
TB,R,N
domains
TB,R,N,V_hasCachedParseData
embeddingHeight
TB,R,N,V_isHighResDecoded
endDate
TB,R,V_processAborted
espressoContext
TB,V_clusterIncludeTorsoOnlyFaces
expectedClasses
TB,V_generateOutput
facePrimarySuggestionsThreshold
TB,V_leftEyeClosed
facesFromAsset:
TB,V_personBuildingDisabled
finalizeAtTime:
TB,V_rightEyeClosed
forward
TB,V_smile
getPose
TB,V_trackingMode
hadZoom
TB,Vstable
handler
TI,N,V_flags
hasFlickerScore
TI,N,V_orientation
imageCompositionResultsAtIndex:
TI,N,V_version
imageDimensions
TI,R,N,V_orientation
includeRotation
TQ,N,V_activityID
initWithAnimalprint:confidence:
TQ,N,V_clustererBringUpState
initWithDevice:
TQ,N,V_longExposureSuggestionState
initWithParameters:poolY:chunk:
TQ,N,V_statsFlags
isDirty
TQ,R
isImage
TQ,R,N,V_attempts
isLeftEyeClosed
TQ,R,N,V_numOfFrames
isPhoto
TQ,R,N,V_type
isReady
TQ,R,V_type
isVideo
TQ,V_advancedStatusMergeCandidateLimit
landmarkRequest
TQ,V_faceID
localIdentifier
TQ,V_maxFaceCountForClustering
lowercaseString
TQ,V_minimumFaceGroupSizeForCreatingMergeCandidates
maxZoom
TQ,V_position
migrateFaceProcessingToVersion:
TS,N,V_ethnicityType
minZoom
TS,N,V_eyesState
mouthExpression
TS,N,V_glassesType
movieHighlightScoreResultsCount
TS,N,V_headgearType
movieInterestingnessResultsType
TS,N,V_skintoneType
movieOrientationResultsAtIndex:
TS,R,N
newCommandQueue
T^f,R
normalizedRectForRect:inBounds:
T^f,R,V_meanBlendshape
numberWithBool:
T^f,R,V_outputBeforeSpatiialPooling
objectKnowledge
T^f,R,V_outputRes4
originatingFace
T^f,R,V_videoEmbedding
payload
T^f,V_orientation
petsActionScore
T^v,N,V_analysisResultRef
photoLibraryURL
T^v,R,N,V_espressoContext
photosFaceRepresentationCenterY
T^{CGPoint=dd},VP
pixelBufferWithFormat:andMaxDimension:fromImageURL:orientation:
T^{__CVBuffer=},R,N
pixelsHighRange
Td,N,V_blurScore
pointWithPoint:
Td,N,V_bodyCenterY
predictedPersonUniqueIdentifier
Td,N,V_bodyWidth
processAndEstimateQualityScore:
Td,N,V_centerY
processPets:petsBounds:dominantPetIdx:frame:timestamp:duration:
Td,N,V_energy
progressHandler
Td,N,V_gazeCenterX
pv_performChangesAndWait:error:
Td,N,V_height
queryID
Td,N,V_poseYaw
ratioOfAssetsWithFacesProcessed
Td,N,V_roll
refineRegionsWithRequest:error:
Td,N,V_timestamp
releaseStorages
Td,N,V_x
requestRevision
Td,N,V_y
requestedOffset
Td,R,N
results
Td,R,V_elapsedTimeSeconds
saliencyRequest
Tf,N,V_absoluteScore
sceneId
Tf,N,V_activityScore
searchThreshold
Tf,N,V_autoplayScore
service
Tf,N,V_cameraMotionScore
Tf,N,V_confidence
setActiveCount:
Tf,N,V_cropFraction
setBodyCenterX:
Tf,N,V_cropRectWidth
setBox:
Tf,N,V_cropRectY
setContentType:
Tf,N,V_distanceToPreviousScene
setEnd:
Tf,N,V_exposureScore
setFaceQuality:
Tf,N,V_expressionScore
setFaceStatsFlag:detectedFaces:
Tf,N,V_faceSharpness
setFocusStatus:
Tf,N,V_frameExpressionScore
setGazeCenterX:
Tf,N,V_highlightScore
setGlassesType:
Tf,N,V_humanPoseScore
setInputImageWithCGImage:error:
Tf,N,V_inputBoundsHeight
setLongExposureSuggestionState:
Tf,N,V_inputBoundsX
setManualOrder:
Tf,N,V_interestScore
setMemeRequest:
Tf,N,V_junkScore
setMotionParam:
Tf,N,V_maxZoom
setMovieInterestingnessResults:
Tf,N,V_motionScore
setObservation:
Tf,N,V_overallFaceQualityScore
setOutputBlobs:
Tf,N,V_petsActionScore
setReachabilityForFlags:update:
Tf,N,V_relativeActionScore
setSourceWidth:
Tf,N,V_sceneprintDistanceToPreviousScene
setTextureType:
Tf,N,V_semanticScore
setUnderExpose:
Tf,N,V_sourceSizeHeight
setYaw:
Tf,N,V_stillTime
sexType
Tf,N,V_subjectScore
signpostPayload
Tf,N,V_textureness
smilingCategory
Tf,N,V_visualPleasingScore
sourceSizeWidth
Tf,N,V_x
startPointValue
Tf,R,N
stringByAppendingPathComponent:
Tf,R,N,V_exposureScore
surroundingText
Tf,R,V_actionScore
timeWithCMTime:
Tf,R,V_qualityScore
typeDescription
Tf,R,V_subtleMotionScore
unregisterAvailabilityObserver:
Tf,V_absMotion
updateModelByAddingFaces:error:
Tf,V_duration
vcp_description
Tf,V_faceClusteringThreshold
vcp_fingerprint
Tf,V_facePrimarySuggestionsThreshold
vcp_isLivePhoto
Tf,V_flag
vcp_needsVisualSearchProcessing
Tf,V_maxX
vcp_queryActionResultForPHFace:
Tf,V_minX
vcp_setQuality:
Tf,V_numSingletons
vcp_setVersion:
Tf,V_obstructionScore
version
Tf,V_score
wellKnownPhotoLibraryIdentifier
Tf,V_sumConfidence
Tf,V_weightedAveragePrecision
.cxx_construct
T@"NSArray",R,N
CalculateDotProductOfChunk
T@"NSData",&,N,V_statisticsBlob
DetectLinesWithThreshold:output:
T@"NSMutableArray",&,N,V_bounds
JSONObjectWithData:options:error:
T@"NSValue",R,N
SetKeyFramesForSegments:
T@"VCPProtoTime",&,N,V_duration
T@"<MTLCommandBuffer>",&,V_commandBuffer
T@,R,N,V_object
T@"<MTLDevice>",&,V_device
TB,N,V_hasSmile
T@"CLLocation",R,N
TB,R,N,GisReady
T@"MLMultiArray",&,N,V_angle
TQ,R,N,V_taskID
T@"NSArray",&,V_sceneResults
TS,N,V_hairType
T@"NSArray",C,N,V_documentObservations
T^f,R,N
T@"NSArray",R,N,V_globalMotion
T^{__CVBuffer=},N,V_pixelBuffer
T@"NSArray",R,V_csns
Tf,N,V_exposure
T@"NSData",&,N,V_colorNormalizationBlob
Tf,N,V_qualityScoreForLivePhoto
T@"NSData",&,N,V_featureBlob
Tf,V_faceClusteringAgeThreshold
T@"NSData",C,N,V_cachedParseData
Ti,N,V_position
T@"NSData",R,N,V_data
Ti,N,V_shotType
T@"NSDate",R,N
Ti,V_classIndex
T@"NSDictionary",&,N,V_results
T{?=[4]},V_pose
T@"NSDictionary",R,&,N
_action
T@"NSDictionary",R,N,V_blendShapes
_active
T@"NSMutableArray",&,N,V_classifications
_activityScores
T@"NSMutableArray",&,N,V_faceQualityScores
_alphas
T@"NSMutableArray",&,N,V_frameInstructions
_audioTimestamp
T@"NSMutableArray",&,N,V_imageCompositionResults
_blocks
T@"NSMutableArray",&,N,V_imageFaceResults
_bounds
T@"NSMutableArray",&,N,V_imageHumanPoseResults
_buffer
T@"NSMutableArray",&,N,V_imagePetsFaceResults
_cflags
T@"NSMutableArray",&,N,V_imageSaliencyResults
_closeSuggestionsLoggingSession
T@"NSMutableArray",&,N,V_imageShotTypeResults
_clusteringType
T@"NSMutableArray",&,N,V_livePhotoEffectsResults
_cnnOutputWidth
T@"NSMutableArray",&,N,V_livePhotoKeyFrameResults
_connectionLock
T@"NSMutableArray",&,N,V_livePhotoRecommendationResults
_curBlendshapes
T@"NSMutableArray",&,N,V_motionBlurVector
_decodeFinished
T@"NSMutableArray",&,N,V_movieApplauseResults
_device
T@"NSMutableArray",&,N,V_movieBabbleResults
_downsampleBeforeFaceProcessing
T@"NSMutableArray",&,N,V_movieCheeringResults
_encodeAnalysis
T@"NSMutableArray",&,N,V_movieFaceResults
_existingScenes
T@"NSMutableArray",&,N,V_movieFeatureResults
_faceID
T@"NSMutableArray",&,N,V_movieHighlightResults
_facesFromFaceGroupWithMostNumberOfFacesOnPerson:options:error:
T@"NSMutableArray",&,N,V_movieHumanActionResults
_featureResults
T@"NSMutableArray",&,N,V_movieInterestingnessResults
_frameTimeRange
T@"NSMutableArray",&,N,V_movieLoudnessResults
T@"NSMutableArray",&,N,V_movieMusicResults
_groundTruthURL
T@"NSMutableArray",&,N,V_movieOrientationResults
_handID
T@"NSMutableArray",&,N,V_moviePetsResults
_heightBlockNum
T@"NSMutableArray",&,N,V_movieQualityResults
_highlightScore
T@"NSMutableArray",&,N,V_movieSceneResults
_idealHistogram
T@"NSMutableArray",&,N,V_movieStabilizationResults
_inputBlobNames
T@"NSMutableArray",&,N,V_movieSubtleMotionResults
_inputSemaphore
T@"NSMutableArray",&,N,V_movieUtteranceResults
_isFast
T@"NSMutableArray",&,N,V_petsDetections
_isIris
T@"NSMutableArray",&,V_outputSize
_keyFrameScores
T@"NSMutableArray",&,V_recallPerPersonExcludeMissDetection
_livePhotoRecommendationResults
T@"NSMutableArray",&,V_size
_manual
T@"NSMutableArray",R,&,N,V_highlights
_meanBlendshape
T@"NSMutableDictionary",&,N,V_frameResults
_modelLandmarks
T@"NSMutableDictionary",R,V_clusterFlagByClusterId
_mutableResults
T@"NSString",&,N,V_assetAdjustedFingerprint
_numBoundaryLms
T@"NSString",&,N,V_assetMasterFingerprint
_numOfLandmarks
T@"NSString",&,N,V_signpostPayload
_numberOfFrames
T@"NSString",C,N,V_adjustmentVersion
_offset
T@"NSString",C,N,V_personLocalIdentifier
_outputBeforeFc
T@"NSString",R,C,N,V_localIdentifier
_pairedAssetURL
T@"NSString",R,N,V_clientBundleID
_petsDetections
T@"NSString",R,N,V_localIdentifier
_points3DCamera
T@"NSString",R,N,V_resConfig
_preferredWidth
T@"NSString",R,V_master
_prevLM
T@"NSString",R,V_person2LocalIdentifier
_processAborted
T@"NSString",R,V_requestId
_progressBlocks
T@"PHAsset",R,N,V_asset
T@"PHFetchResult",R,N
_qualityResults
T@"VCPCNNData",R,V_output
_reason
T@"VCPCNNMetalContext",R,V_context
_reportPetsAnalysisWithResults:
T@"VCPFaceGeometry",R,N,V_geometry
_reserveBudget:
T@"VCPHomeKitAnalysisSession",W,N,V_weakSession
_rightEyeClosed
T@"VCPMADResource",&,N,V_resource
_samplesForProcessingBufferList
T@"VCPPhotosFace",R,N,V_face1
_scaler
T@"VCPProtoBounds",&,N,V_faceBounds
_screenProgress
T@"VCPProtoLine",&,N,V_dominantLine
_sqlSerialQueue
T@"VCPProtoLivePhotoVariationParams",&,N,V_bounce
_statisticsBlob
T@"VCPProtoLivePhotoVariationParams",&,N,V_stabilize
_stride
T@"VCPProtoPoint",&,N,V_start
_sumMotionParam
T@"VCPProtoTime",&,N,V_start
_taskID
T@"VCPProtoTimeRange",&,N,V_timeRange
_transcodeQueue
T@"VCPVNImageprintWrapper",&,N,V_imageprintWrapper
T@"VCPVideoKeyFrame",&,N,V_keyFrame
_updateFaceprint:forFace:error:
T@"VIService",R,N
_useGPU
T@"VN5kJNH3eYuyaLxNpZr5Z7zi",&,N,V_semanticRequest
_vanishingPoint
T@"VNCanceller",R,V_canceller
_videoEmbedding
T@"VNClassifyImageAestheticsRequest",&,N,V_aestheticsRequest
_visionClusterMemmapFileInCacheDirectoryURL:clusterState:error:
T@"VNClassifyMemeImageRequest",&,N,V_memeRequest
T@"VNCreateImageFingerprintsRequest",&,N,V_imagefingerprintsRequest
addFaceResults:
T@"VNCreateSceneprintRequest",&,N,V_sceneprintRequest
addSettling:to:
T@"VNGenerateAttentionBasedSaliencyImageRequest",&,N,V_saliencyRequest
allKeys
T@"VNImageRequestHandler",R,N,V_requestHandler
analyzeFrame:withBox:keypoints:
T@"VNRecognizeObjectsRequest",&,N,V_objectRequest
arrayWithArray:
T@"VNSceneClassificationRequest",&,N,V_classificationRequest
assetIdentifier
T@"VNVYvzEtX1JlUdu8xx5qhDI",&,N,V_nsfwRequest
base64EncodedStringWithOptions:
T@?,C,N,V_cancelBlock
T@?,C,V_updateHandler
cachedParseData
calculateAndReportClusterAccuracyWithVisionClusterURL:andPersonClusters:withGroundtruth:results:extendTimeoutBlock:cancelBlock:
TB,N
centerY
TB,N,V_autoPlayable
classifyVIPPets
TB,N,V_faceDominated
clearMovieHighlightScoreResults
TB,N,V_frameProcessedByHumanAnalyzer
cloudIdentifier
TB,N,V_frameProcessedByVideoAnalyzer
cnnOutputHeight
TB,N,V_hadZoom
compressCVPixelBuffer:toJPEGData:targetBitStreamLength:padding:
TB,N,V_hasFaceMask
computeOverallFaceQualityScore:
TB,N,V_isAutoPlayable
containsObject:
TB,N,V_isFast
context
TB,N,V_isInTrash
copyScoresFrom:
TB,N,V_isRightEyeClosed
countForObject:
TB,N,V_isTooSmall
createModelWithHeight:srcWidth:
TB,N,V_manual
dealloc
TB,N,V_subMbMotionAvailable
detectPoseForFace:inBuffer:yaw:
TB,R
documentRequest
TB,R,N,V_bufferRotated
drawImage:pixelFormat:withOrientation:maxDimension:pixelBuffer:
TB,R,N,V_hasWifiOrEthernetConnection
TB,R,N,V_useCPUOnly
errorWithStatus:andDescription:
TB,R,V_started
execute
TB,V_faceClusteringDisabled
expressionScore
TB,V_isInputOutput
faceResultsType
TB,V_personBuilderMergeCandidatesDisabled
fetchPersonForFaceCrop:options:
TB,V_quarantineTwinsOnAssetEnabled
fingerprintWithMaster:adjusted:
TB,V_sdof
fullPixelBuffer:toScaledBuffer:
TB,V_suggestionsLogEnabled
glassesCategory
TB,VlostTrack
handKeypointsDetection:box:keypoints:keypointConfidence:forGFT:
TI,N,V_faceID
hasContentScore
TI,N,V_identifier
hasPlaybackCrop
TI,N,V_types
imageConstraint
TI,R,N,V_inputPixelFormat
includeDocument
TI,R,N,V_revision
initNewContext:
TQ,N,V_algorithmVersion
initWithConfig:
TQ,N,V_count
initWithFormat:
TQ,N,V_loopSuggestionState
initWithResultItems:andPayload:
TQ,N,V_typesWide
isEqualToValue:
TQ,R,N
isJunkTimeRange:basedOnResults:
TQ,R,N,V_frameInterval
isMovie
TQ,R,N,V_numOfValidFrames
isProxy
TQ,R,N,V_vertexCount
isShort
TQ,R,V_vertexCount
keyFace
TQ,V_advancedStatusVerifiedPersonLimit
livePhotoEffectsResultsAtIndex:
TQ,V_flags
lookupTextWithQuery:completion:
TQ,V_minFaceCountToTriggerClustering
mad_internalPredicateForTaskID:
TQ,V_minimumSuggestionSize
maximumHierarchicalObservations
TS,N,V_ageType
minFaceCountToTriggerClustering
TS,N,V_expressionType
motionParamDiff
TS,N,V_facialHairType
movieClassificationResultsCount
TS,N,V_hairColorType
movieHumanActionResultsAtIndex:
TS,N,V_sexType
movieObstructionResultsAtIndex:
TS,N,V_smileType
multiArrayValue
T^,R,V_meshVertices
newFaceCropFromImageData:withFaceRect:groupingIdentifier:error:
T^f,R,V_componentsBlendshape
T^f,R,V_outputBeforeFc
numberWithChar:
T^f,R,V_outputBeforeTemporalPooling
objects
T^f,R,V_tensorCoeff
parseKeypoints:
T^f,V_data
persons
T^i,R,V_blendshapeComponentIndex
phAsset
T^v,N,V_correctionResultRef
photosFaceRepresentationCenterX
T^{CGPoint=dd}
photosFaceRepresentationQuality
T^{__CVBuffer=},N,V_inputImage
pixelFormatType
Td,N,V_assetModificationDate
pixelsWideRange
Td,N,V_bodyCenterX
poseYaw
Td,N,V_bodyHeight
predictionFromInputImage:error:
Td,N,V_centerX
processImage:withOptions:error:
Td,N,V_date
processVideoFragmentAssetData:withOptions:andCompletionHandler:
Td,N,V_exposureScore
pv_fetchMoments
Td,N,V_gazeCenterY
quality
Td,N,V_peak
queryProgress:forPhotoLibrary:andTaskID:withExtendTimeoutBlock:
Td,N,V_quality
rectFromPHFace:
Td,N,V_size
release
Td,N,V_width
request
Td,N,V_x0
requestedLength
Td,N,V_y0
resourceForAsset:withResources:
Td,R,N,V_distance
Tf,N,V_absoluteActionScore
saveAndReturnCurrentModelState:
Tf,N,V_actionScore
sceneIdentifier
Tf,N,V_analysisConfidence
semanticRequest
Tf,N,V_averageScore
session
Tf,N,V_colorfulnessScore
setActionScore:
Tf,N,V_contentScore
setArrayLength:
Tf,N,V_cropRectHeight
setBodyCenterY:
Tf,N,V_cropRectX
setCancelBlock:
Tf,N,V_curationScore
setCurrentCost:
Tf,N,V_exposureChangeScore
setFaceClusteringJunkThreshold:
Tf,N,V_expressionChangeScore
setFaceResults:
Tf,N,V_faceQuality
setFeatureBlob:
Tf,N,V_flickerScore
setFrameLength:
Tf,N,V_globalQualityScore
setGazeCenterY:
Tf,N,V_humanActionScore
setHasFaceMask:
Tf,N,V_humanScore
setKeyFrameTime:isHeadingFrame:
Tf,N,V_inputBoundsWidth
setLoopFadeLen:
Tf,N,V_inputBoundsY
setMaximumSize:
Tf,N,V_interestingnessScore
setMinimumSize:
Tf,N,V_maxHighlightDuration
setMotionScore:
Tf,N,V_minZoom
setNsfwRequest:
Tf,N,V_obstructionScore
setOrientation:
Tf,N,V_penaltyScore
setPixelBuffer:
Tf,N,V_qualityScore
setRequestedTimeToleranceAfter:
Tf,N,V_relativeScore
setSymbologies:
Tf,N,V_score
setTextureness:
Tf,N,V_sharpness
setWeakSession:
Tf,N,V_sourceSizeWidth
settlingEffects
Tf,N,V_subjectActionScore
sharedModelPool
Tf,N,V_textureScore
slowMotionRampInRangeForExport:
Tf,N,V_underExpose
softmax
Tf,N,V_voiceScore
stabilizeResult
Tf,N,V_y
started
Tf,R,N,V_confidence
stringFromDate:
Tf,R,N,V_score
timeValuesCount
Tf,R,V_motionDivScore
trackID
Tf,R,V_sharpness
uiScale
Tf,R,V_textureScore
updateDuration:
Tf,V_actionScore
usePHAssetScene
Tf,V_faceClusteringJunkThreshold
vcp_enabledTracksWithMediaType:
Tf,V_faceMergeFaceprintDistanceThreshold
vcp_isDecodable
Tf,V_faceQuality
vcp_isSdofPhoto
Tf,V_interestingnessScore
vcp_orientation
Tf,V_maxY
vcp_quickFaceClassificationDone
Tf,V_minY
vcp_setResults:
Tf,V_numValidSingletons
vcp_vipModelFilepathForVIPType:
Tf,V_qualityScore
voiceDetections
Tf,V_stabilityScore
Tf,V_trackingScore
Tf,V_weightedAverageRecall
Ti,N,V_chirality
Ti,N,V_cropRectHeight
Ti,N,V_cropRectWidth
Ti,N,V_cropRectX
Ti,N,V_cropRectY
Ti,N,V_errorCode
Ti,N,V_exitStatus
Ti,N,V_eyeExpression
Ti,N,V_faceID
Ti,N,V_flags
Ti,N,V_handID
Ti,N,V_loopFadeLen
Ti,N,V_loopPeriod
Ti,N,V_loopStart
Ti,N,V_minVersion
Ti,N,V_motionType
Ti,N,V_mouthExpression
Ti,N,V_orientation
Ti,N,V_stabilizeResult
Ti,N,V_timeScale
Ti,N,V_timescale
Ti,N,V_trainingType
Ti,N,V_version
Ti,N,V_yaw
Ti,R,N,V_cnnOutputHeight
Ti,R,N,V_cnnOutputWidth
Ti,R,N,V_lostCount
Ti,R,N,V_version
Ti,R,V_embeddingChannels
Ti,R,V_embeddingHeight
Ti,R,V_embeddingSequenceLength
Ti,R,V_embeddingWidth
Ti,R,V_numVertices
Ti,V_detectionModeCounterShapeModel
Ti,V_processingMode
Ti,V_processingVersion
Ti,V_trackID
Tq,D,N
Tq,N
Tq,N,V_activeCount
Tq,N,V_clusterSequenceNumber
Tq,N,V_currentCost
Tq,N,V_epoch
Tq,N,V_nameSource
Tq,N,V_outputFrameDurValue
Tq,N,V_qualityMeasure
Tq,N,V_sourceHeight
Tq,N,V_sourceWidth
Tq,N,V_timeValue
Tq,N,V_value
Tq,R,N
Tq,R,N,V_inputSize
Tq,R,V_status
Tq,V_focusStatus
Tq,V_yaw
Tr^f,R,N
Transform
Ts,N,V_detectionType
Ts,N,V_state
T{?=[4]},R,N,V_pose
T{?=[4]},R,N,V_transform
T{?=^v^v[4Q][4Q]QQQQQQQQQQi},N,V_inputBlob
T{?=^v^v[4Q][4Q]QQQQQQQQQQi},N,V_outputBlob
T{?=qiIq},N,V_timestamp
T{?=qiIq},R,N,V_start
T{?=qiIq},R,N,V_timeInterval
T{?=qiIq},R,N,V_timeStamp
T{?=qiIq},V_last
T{?=qiIq},V_start
T{?={?=qiIq}{?=qiIq}},N,V_timeRange
T{?={?=qiIq}{?=qiIq}},N,V_timerange
T{?={?=qiIq}{?=qiIq}},R,N
T{?={?=qiIq}{?=qiIq}},R,N,V_timeRange
T{?={?=qiIq}{?=qiIq}},R,N,V_timerange
T{?={?=qiIq}{?=qiIq}},V_timerange
T{CGPoint=dd},N,V_location
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_bestPlaybackCrop
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,V_objectBounds
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,V_objectBoundsInitial
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,V_regionOfInterest
T{CGRect={CGPoint=dd}{CGSize=dd}},V_bound
T{CGRect={CGPoint=dd}{CGSize=dd}},V_bounds
T{CGSize=dd},R,N,V_resolution
T{CLLocationCoordinate2D=dd},R,N
T{array<float, 6UL>=[6f]},N,V_motionParam
T{array<float, 6UL>=[6f]},N,V_motionParamDiff
T{vector<espresso_buffer_t, std::allocator<espresso_buffer_t>>=^{?}^{?}{__compressed_pair<espresso_buffer_t *, std::allocator<espresso_buffer_t>>=^{?}}},N,V_inputBlobs
T{vector<espresso_buffer_t, std::allocator<espresso_buffer_t>>=^{?}^{?}{__compressed_pair<espresso_buffer_t *, std::allocator<espresso_buffer_t>>=^{?}}},N,V_outputBlobs
URLByAppendingPathComponent:
URLByAppendingPathComponent:isDirectory:
URLByAppendingPathExtension:
URLByDeletingLastPathComponent
URLForDirectory:inDomain:appropriateForURL:create:error:
URLForResource:withExtension:
URLOfModelInThisBundle
URLWithString:
URLWithString:relativeToURL:
UTF8String
UUID
UUIDString
VN1uMyFtnYEWjbrdx3yAuDndKkPeyzNJhB
VN2riiZbQrloRhCzYW56f0rk4N3ROe151S
VN3iT1YRjjnIuELobV1olJiO1vvItN6Kdq
VN4UfLbvVUqMvYV8bbGFQcxg5yRLm8ekI1
VN7exwFFmQF0AI9P7FjBljwEFu7QYUGCYE
VN7fiLHgGnvqPqG63cfDUCK4Xm8obUuWoP
VNpLorzxnyAlLcPFNcKhgoNCmy9b5BRWyk
_LM2D
_LM3D
_SNAnalyzer
_absMotion
_absoluteActionScore
_absoluteScore
_accHalfHeight
_accHeight
_accWidth
_accumulatedChangesCount
_accumulator
_actionResults
_actionScore
_actionScoreAbsolute
_actionScoreRelative
_actions
_activeConfidence
_activeCount
_activeEnd
_activeFaces
_activeFrameIndices
_activeHinkleyDetector
_activePoseResults
_activeRegions
_activeScore
_activeSegment
_activeStart
_activeThreshold
_activityDescriptor
_activityID
_activityScore
_addClassificationResults:analysis:
_adjustConfirmingAndRejectionWithFaces:faceCrops:cancelOrExtendTimeoutBlock:
_adjusted
_adjusterArray
_adjustmentVersion
_adjustmentsRequest
_advancedStatusMergeCandidateLimit
_advancedStatusVerifiedPersonLimit
_aestheticsRequest
_ageType
_aggregatedResults
_algorithmVersion
_alignBoundingBoxOfFaces:withRequestHandler:orientedWidth:orientedHeight:
_alignFaceObservations:withRequestHandler:error:
_allFaces
_allocator
_allowANE
_allowOnDemand
_analysis
_analysisConfidence
_analysisDict
_analysisInput
_analysisPreferencesURL
_analysisQueue
_analysisResultRef
_analysisSessionRef
_analysisTypes
_analyzeOndemand:forAnalysisTypes:withExistingAnalysis:andOptions:storeAnalysis:cancelBlock:
_analyzeWithStart:andDuration:error:
_analyzer
_angle
_angleStable
_angleStep
_anonymizedName:
_appendToSuggestionsLog:
_argbPixelBuffer
_argbTransferSession
_asset
_assetAdjustedFingerprint
_assetIdentifier
_assetMasterFingerprint
_assetModificationDate
_assetReader
_assetURL
_associateFace:withFaceCrop:error:
_asyncBlendshapes
_asyncExtMat
_asyncLm2d
_asyncLmBlendshapes
_asyncWeights
_attempts
_audioAnalyzer
_audioBufferList
_audioClassifier
_audioQualityAggregated
_audioQualityResults
_audioStream
_audioUnit
_autoPlayable
_autoloop
_autoplay
_autoplayScore
_avAsset
_averageScore
_backbone
_backwarp
_barcodeObservations
_batchAnalyses
_batchNorm
_batchSize
_bestFaceForFaceDetectionRequest:withRect:
_bestPlaybackCrop
_bestTrimTimeRange
_bias
_bilinearScale
_blendShapeDelta
_blendShapes
_blendshapeComponentIndex
_block
_blockSize
_blurAnalyzer
_blurScore
_bodyArray
_bodyCenterX
_bodyCenterY
_bodyHeight
_bodyWidth
_bound
_boundaryLandmarkValidity
_boundaryLmIndices
_boundaryLmUpdated
_boundaryVertices
_bringUpStateDescription:
_bufferHeight
_bufferRotated
_bufferWidth
_bufferedSamples
_buildPersonsFromUpdatedFaceGroups:faceClusterer:keyFaceUpdateBlock:cancelOrExtendTimeoutBlock:context:
_cacheDirUrl
_cacheFileUrl
_cachedExif
_cachedImageDimensions
_cachedImageHandler
_cachedParseData
_cachedRequestIdealDimension
_cachedResources
_cachedScenes
_calculateIoUBetweenObservation:andObservation:
_calculateOverlappingBetweenFaceObservation:andHumanObservation:
_callbackQueue
_cameraMotion
_cameraMotionConfidences
_cameraMotionParams
_cameraMotionResults
_cameraMotionScore
_cameraOrientation
_cancelBlock
_cancelClusteringAndRestoreClusterCache:
_cancelDecode
_cancelOrExtendTimeoutBlock
_cancelQueue
_cancelTokens
_canceled
_cancellable
_cancelled
_canceller
_captureTime
_categorizeGroupedFacesInFetchResult:intoFaceLocalIdentifiersByFaceGroup:ungroupedFaceLocalIdentifiers:cancelOrExtendTimeoutBlock:photoLibrary:
_centerX
_centerY
_cgContext
_chCount
_chPtSelected
_chPts
_checkAnalysisRequests:forTooSmallFaceObservations:withAnalysisResults:
_checkDuplicate:withAsset:duplicate:
_chirality
_chunk
_cityNatureRequest
_classIndex
_classIndexTracker
_classificationRequest
_classificationResults
_classifications
_classifiers
_classifyFaces:forAsset:detectedPersons:
_cleanupMergeCandidatesForVerifiedPersons:minimumFaceGroupSize:cancelOrExtendTimeoutBlock:error:
_clearDirtyStateOnFaceCrop:error:
_clientTeamID
_clusterDumpFaceFetched
_clusterFlagByClusterId
_clusterIncludeTorsoOnlyFaces
_clusterSequenceNumber
_clusterer
_clustererBringUpState
_cnnInputWidth
_cnnOutputHeight
_collectSceneAnalysisResults:fromRequests:wpResults:ivsResults:abnormalDimension:
_colorNormalization
_colorNormalizationAnalyzer
_colorNormalizationBlob
_colorfulness
_colorfulnessScore
_commandBuffer
_commandQueue
_completePersonBuildingWithPersonsToUpdate:facesToRemoveByPerson:facesToAddByPerson:updateFaceGroup:newMergeCandidatePairs:newInvalidMergeCandidatePairs:faceInFaceGroupByCSN:personCache:keyFaceUpdateBlock:cancelOrExtendTimeoutBlock:context:error:
_completionHandler
_componentsBlendshape
_computationAccuracy
_computeFingerPrintsOfAsset:completionHandler:
_confidence
_confidenceMap
_confidences
_configureRequest:
_configureRequest:withRevision:preferANE:
_configureRequestWithRevision:
_connection
_contentScore
_context
_contrast
_controlPointsCamera
_controlPointsWorld
_convertFromBuffer:toLumaPixelBuffer:abnormalDimension:
_copyImageAtURLToSuggestionsLoggingSession:
_correctionResultRef
_correlation
_correlationKernel
_correlationTracker
_count
_countAnalysisWithAssetBatch:andDatabase:andTaskID:
_countEmbeddingAnalysisWithAssetBatch:
_countFaceAnalysisWithAssetBatch:
_countFailuresWithAssetBatch:andDatabase:andTaskID:
_countMediaAnalysisWithAssetBatch:andDatabase:analyzedCount:completeAnalyzedCount:partialAnalyzedCount:
_countOCRAnalysisWithAssetBatch:
_countSceneAnalysisWithAssetBatch:
_countVisualSearchAnalysisWithAssetBatch:
_createBlurRequests:andExposureRequests:forFaceObservations:
_createPixelBuffer:withColorSpace:fromPixelBuffer:
_createPixelBuffer:withMinorDimension:fromFullPixelBuffer:
_createPixelBuffer:withWidth:andHeight:
_createPixelBufferPool:withBufferWidth:bufferHeight:andPixelFormat:
_createPixelBufferWithWidth:height:pixelFormat:pixelBuffer:
_createRequests:withMediaType:
_crop
_cropFraction
_cropRectWidth
_cropRectX
_cropRectY
_cropSize
_csns
_ctx
_cur2D
_curCoeff
_curLM
_curMesh
_curationScore
_curationThreshold
_currentCost
_currentSample
_currentStatus
_currentStatusSnapshot
_currentStatusSnapshotIsValid
_currentStatusSnapshotLock
_currentSuggestionRequest
_data
_dataTask
_database
_databaseForPhotoLibrary:
_databases
_date
_deSerializedMetaBuffer
_decodeEnd
_decodeError
_decodeSession
_decodedFrames
_decoderSettings
_defaultAssetFetchOptions
_defaultAssetPropertySets
_defaultFacePropertySets
_defaultFetchOptions
_defaultPhotoLibrary
_defaultPhotoLibraryURL
_deleteAllVerifiedPersonsWithError:
_descriptor
_descriptorResults
_detectDuplicationInExistingFaceCrops:withFetchedFaces:faceCropFaceIdentifiersToEvaluate:duplicationResults:cancelOrExtendTimeoutBlock:
_detectedFaces
_detectionModeCounter
_detectionType
_detectionVersion
_detections
_detectors
_diff
_diffFlipCount
_diffVariance
_distance
_distanceToPreviousScene
_distanceVariance
_documentObservations
_documentRequest
_dominantHand
_dominantLine
_downScaleHeight
_downloadGroup
_dumpAssetsToFaces
_dumpFaceprint
_duplicateFaceCSNsOnAssetForPerson:faceCSNsOnPerson:faceByCSNCache:
_duration
_edgeMap
_edgeWeightMap
_elapsedTimeSeconds
_embeddingChannels
_embeddingHeight
_embeddingSequenceLength
_enableSceneAssetConcurrency
_encodeSession
_end
_endTime
_enoughFrames
_enumeratePersonsWithLocalIdentifiers:fetchOptions:personCache:usingBlock:
_epoch
_errorCode
_espressoContext
_ethnicityType
_eulerAngle
_executedOnGPU
_existingAnalysis
_existingFaceprints
_existingFacesFromAsset:
_existingHands
_existingPersons
_existingPersonsArray
_existingResults
_exitStatus
_exportAssetsToFacesDetails:
_exportReencodedJPEG
_exposure
_exposureChangeScore
_exposureScore
_exprWeightDiagMatrix
_expressionChangeScore
_expressionScore
_expressionSegments
_extractAndSortBoundingBoxFromDetectedObjects:
_extrinsicMatrix
_eyeExpression
_eyesState
_face1
_face2
_faceAnalyzer
_faceArea
_faceAssociatedWithFaceCrop:
_faceBounds
_faceCSNsInClusterCache
_faceCSNsToRemove
_faceClusterer
_faceClusteringAgeThreshold
_faceClusteringDisabled
_faceClusteringJunkThreshold
_faceClusteringThreshold
_faceCount
_faceCropData
_faceDetector
_faceDominated
_faceFromFaceCrop:error:
_faceHeatMap
_faceIdStrsToAdd
_faceInput
_faceMergeFaceprintDistanceThreshold
_faceMerger
_faceModel
_faceObservationsWithBoundingBoxFromFaces:withFaceHashMapping:
_facePrimarySuggestionsThreshold
_facePrints
_faceProcessingContext
_faceProcessingPassGoalWithExtendTimeout:
_faceQuality
_faceQualityAnalyzer
_faceQualityScores
_faceRanges
_faceResults
_faceSharpness
_faceToFaceCountMapForFaces:
_faceTorsoprintsFromFaceCSNs:
_faceTorsoprintsFromFaceIdentifiers:assignClusterSeqNumberIfNeeded:updatedFaces:groupingIdentifiers:
_faceTorsoprintsFromFaces:assignClusterSeqNumberIfNeeded:updatedFaces:
_faceTrackers
_faceValidator
_faceprintBlob
_faceprintFastMode
_faces
_fastFaceMigrationEnabled
_fastGestureDetector
_featureBlob
_featureBlobNames
_featureChannels
_featureExtractor
_featureName
_fetchPeopleHomePersons
_fetchPersonWithIdentifier:facesPerAsset:assetInformation:extendTimeoutBlock:cancelBlock:
_fetchPersonsToFeedVIPModel:allowUnverifiedPerson:
_fetchPetsToFeedVIPModel
_fetchResultForGroupedFacesWithClusterSequenceNumberSetToZeroInPhotoLibrary:
_fetchResultForUngroupedFacesWithNonZeroClusterSequenceNumberInPhotoLibrary:
_filepath
_filterBanks
_filterNum
_filterSize
_finalizeSuggestionsLog
_finalized
_fineActionResults
_firstBuffer
_firstFrame
_firstLocallyAvailableResourceFromResources:
_flag
_flags
_flickerScore
_flow
_flowDecoder
_flowDecoderSemaphore
_flowHeight
_flowWidth
_flushModel
_focalLengthInPixels
_focusStatus
_forceCPU
_forceNNGraph
_formatDescription
_frame
_frameArray
_frameBuffer
_frameCount
_frameCounter
_frameEndTimeStamp
_frameExpressionScore
_frameFaceResults
_frameHeight
_frameIndex
_frameInstructions
_frameInterval
_frameNum
_framePTSResults
_framePosition
_frameProcessedByFaceDetector
_frameProcessedByHumanAnalyzer
_frameProcessedByPetsActionAnalyzer
_frameProcessedByVideoAnalyzer
_frameResults
_frameSize
_frameStartTimeStamp
_frameStats
_frameTimestampArray
_frameWidth
_gaborFilter
_gazeCenterX
_gazeCenterY
_gazeType
_generateAndAssociateFaceprintedFaceForFaceCrop:faceCropFaceLocalIdentifier:error:
_generateLastFrameDistanceDescriptor:withDescriptorClass:forAsset:
_generatePersonsModelWithExtendTimeoutBlock:cancel:evaluationMode:allowUnverifiedPerson:
_generatePetsModelWithExtendTimeoutBlock:cancel:
_generateSceneClassifications:fromRequests:
_generateVideoCaption
_geometry
_getDatabaseSandboxExtensionForPhotoLibraryURL:
_getDistanceDescriptorClass
_getMergeCandidates:invalidMergeCandidates:forPersonsWithLocalIdentifiers:
_getRejectedTrainingFaceCSNs:rejectedFaceCSNs:rejectedPersonLocalIdentifiers:forPerson:faceInFaceGroupByCSN:
_getSHRevision
_getSandboxExtensionForMediaAnalysisDatabaseWithPhotoLibraryURL:
_getSceneDescriptors:asDescriptorClass:withSceneRange:andAnalysisResults:
_getThumbnailForAsset:withResouces:andPixelFormat:
_getTrainingFacesByPerson:confirmedFaceCSNs:faceCSNsByPerson:faceCSNsByMigratedPerson:faceCSNsByQuickClassificationPerson:mergeCandidates:invalidMergeCandidates:rejectedPersonsByPerson:faceInFaceGroupByCSN:inFaces:personCache:cancelOrExtendTimeoutBlock:
_glassesType
_globalMotion
_globalQualityScore
_gradient
_gradientMag
_gradientX
_gradientY
_group
_groupingIdentifier
_guidedFilter
_gyroHomographyDimension
_gyroHomographyIsValid
_gyroStabilization
_hadFlash
_hadZoom
_hairColorType
_hairType
_handChiralityCounter
_handDetectedInPreviousFrame
_handKeypointTracker
_handler
_handlerQueue
_handsDetector
_handsKeypointsDetector
_has
_hasAction
_hasCachedParseData
_hasFaceMask
_hasFaceOrPet
_hasFlash
_hasInterestingScene
_hasSmile
_hasWifiOrEthernetConnection
_hash
_headgearType
_heatmapNms
_heightExt
_heightInMb
_heightPadded
_highResOrientation
_highResPixelBuffer
_highlight
_highlightAnalyzer
_highlightResults
_highlights
_hinkleyDetector
_homeKitMotionAnalyzer
_homographyParams
_homographyResults
_humanActionResults
_humanActionScore
_humanActionWindowSize
_humanPoseResults
_humanRect
_humanScore
_identifier
_identityInit
_idxCurrent
_idxLast
_ignoreFace
_image
_imageAsset
_imageBlurResults
_imageBlurTextureScore
_imageCaptionModel
_imageCompositionResults
_imageData
_imageExposureResults
_imageExposureTime
_imageFaceResults
_imageFeature
_imageFeatureResults
_imageFiltered
_imageHumanPoseResults
_imageJunkResults
_imageLoader
_imageManager
_imagePetsFaceResults
_imagePetsResults
_imagePrint
_imageSaliencyResults
_imageSceneprintResults
_imageShotTypeResults
_imageURL
_imagefingerprintsRequest
_imageprintWrapper
_inDetectionMode
_inTrimEnd
_inTrimStart
_inactiveDate
_includeCN
_includeDMF
_includeDO
_includeDocument
_includeIVS
_includeLM
_includeMeme
_includeNSFW
_includePA
_includeRotation
_includeSDG
_includeSE
_includeSO
_includeTorsoOnlyFaces
_includeWP
_initialized
_input
_inputBlob
_inputBlobName
_inputBlobs
_inputBoundsHeight
_inputBoundsWidth
_inputBoundsX
_inputBoundsY
_inputBuffer
_inputChannels
_inputData
_inputFeatureName
_inputHeight
_inputImage
_inputKeyFrameResults
_inputNames
_inputPixelFormat
_inputSize
_inputWidth
_inputsData
_insertBoundingBox:toSortedBoundingBoxes:
_interestScore
_interestingness
_interestingnessResults
_interestingnessScore
_internalConstraintResults
_internalFrameScenes
_internalLandmarkDetector
_internalResults
_interpolatedFrameArray
_interruptionHander
_intrinsicMatrix
_irisAnalyses
_irisAnalysis
_isCaptureAnalysis
_isCloseup
_isColocatingAnimalObservation:withFaceObservations:orTorsoObservations:
_isHighResDecoded
_isInTrash
_isInputOutput
_isLeftEyeClosed
_isLivePhoto
_isMaxTrim
_isMovieWithMediaType:
_isOneShot
_isPanoWithMediaType:andMediaSubtypes:
_isRightEyeClosed
_isSDOFWithMediaType:andMediaSubtypes:
_isSettlingOK
_isSlowMo
_isTimelapse
_isTooSmall
_isTrimmed
_ivsPool
_junkImageRequest
_junkResults
_junkScore
_keepCurrentPersonsModelWithExtendTimeout:
_keyFaces
_keyFrame
_keyFrameAnalyzer
_keyFrameResults
_keyFrames
_keyPersonResults
_keyPetResults
_keypoints
_landmarkDetector
_landmarkRequest
_landmarks
_last
_lastHumanTimestamp
_lastJawOpenness
_lastMinimumFaceGroupSizeForCreatingMergeCandidates
_lastPetTimestamp
_lastProcessTime
_lastRetryDate
_lastTimestamp
_lastVertices
_lastestFaceID
_latestFrameArea
_latestRegions
_latestTrackID
_launchOnce
_leftEyeClosed
_leftHandKeypointTracker
_level0ClusterIdForFaceCSN:level0Clusters:
_lightMotionAnalyzer
_livePhotoEffectsResults
_livePhotoHumanActionClassificationResults
_livePhotoKeyFrameResults
_livePhotoKeyFrameStillResults
_livePhotoSharpnessResults
_livePhotoStillDisplayTime
_lm3dBlendshapeComponents
_lm3dBlendshapes
_lm3dMeanBlendshapes
_lmCoord
_lmDetector
_lmTracker
_lmWeight
_loadGroundTruth:error:
_loadGroundTruthURL:toGroundTruth:error:
_loadImageRequestHandler:orientation:bufferWidth:bufferHeight:withResource:resourceURL:andAsset:
_loadModel
_loadModelAtPath:error:
_loadPersonsModelAndInitializeFaceAnalyzer
_loadPetsModel
_loadPetsModelAtPath:error:
_loadResources
_localIdentifier
_localIdentifiersOfUnverifiedPersonsAssociatedWithFaceGroups:cancelOrExtendTimeoutBlock:
_location
_logFaceToSuggestionsLog:
_logLevel
_longExposureSuggestionState
_longexposure
_loopFadeLen
_loopPeriod
_loopStart
_loopSuggestionState
_lostCount
_lostTrackCounter
_loudnessAnalyzer
_loudnessResults
_loudnessSampleBuffer
_management
_managementQueue
_mapHeight
_mapWidth
_maskOnly
_maxDurationInSeconds
_maxFaceCountForClustering
_maxHighlightDuration
_maxHighlightScore
_maxNumHands
_maxNumRegions
_maxScore
_maxX
_maxY
_maxZoom
_mean
_meanLandmarkLoc
_measureClusterWithClusterStateURL:groundTruthFaceCountPerPerson:groundTruthPersonInformation:groundTruthFaceToPerson:groundTruthAssetToFaces:measures:extendTimeoutBlock:cancelBlock:
_measurePVPersonClusters:groundTruthFaceCountPerPerson:groundTruthPersonInformation:groundTruthFaceToPerson:groundTruthAssetToFaces:measures:extendTimeoutBlock:cancelBlock:
_mediaSubtypes
_mediaType
_memeRequest
_mergeDistanceThreshold
_meshAnalyzer
_meshVertices
_metaAnalysisTypesForAsset:
_metaFocusAnalyzer
_metaLensSwitchAnalzer
_metaMotionAnalyzer
_metaMotionResults
_metaTracks
_metadata
_metadataAnalysis
_metadataItemTimestampArray
_metadataStabilizationArray
_minDetections
_minDurationInSeconds
_minFaceCountToTriggerClustering
_minHighlightDuration
_minHighlightScore
_minSize
_minVersion
_minX
_minY
_minZoom
_minimumFaceGroupSizeForCreatingMergeCandidates
_minimumSuggestionSize
_mlHighlightScoreResults
_mlQualityResults
_model
_modelEspresso
_modelEspressoStage1
_modelLastGenerationDidExceedTimeIntervalForType:
_modelOutput16bit
_modelOutputSize
_modelURL
_modified
_moflowRequest
_momentaryEnergyValues
_monochromeBufferCreator
_motionBlurVector
_motionFilter
_motionFlowAnalyzer
_motionFlowComputationAccuracy
_motionMagnitude
_motionMagnitudeHistogram
_motionParam
_motionParamDiff
_motionScore
_motionScoreModel
_motionType
_motionTypeModel
_mouthExpression
_movie
_movieActivityLevelResults
_movieApplauseResults
_movieAudioQualityResults
_movieBabbleResults
_movieCameraMotionResults
_movieCheeringResults
_movieClassificationResults
_movieFaceResults
_movieFaceprintResults
_movieFeatureResults
_movieFineSubjectMotionResults
_movieHighlightResults
_movieHighlightScoreResults
_movieHumanActionResults
_movieHumanPoseResults
_movieInterestingnessResults
_movieLaughterResults
_movieLoudnessResults
_movieMovingObjectResults
_movieMusicResults
_movieObstructionResults
_movieOrientationResults
_moviePetsFaceResults
_moviePetsResults
_moviePreEncodeResults
_movieQualityResults
_movieSaliencyResults
_movieSceneResults
_movieSceneprintResults
_movieStabilizationResults
_movieSubjectMotionResults
_movieSubtleMotionResults
_movieSummaryResults
_movieUtteranceResults
_movieVoiceResults
_movingObjects
_mtlLibrary
_musicDetections
_mutex
_nameSource
_needToGenerateModelWithType:ignoreLastGenerationTime:withExtendTimeout:
_net
_netFileUrl
_neuronType
_nextClusterTriggeringAccumulatedChangesCount
_nextRequestID
_nextSample
_nextSampleBuffer
_nextSeqNum
_noResultStrip
_nodes
_nonMaxSuppressed
_nonPanoPreWarmDimensions
_nsfwRequest
_num
_numBlendshapePlusOne
_numBoundaryVertices
_numClass
_numComponents
_numFacesLastFrame
_numFilterTabs
_numFrmsSinceLastShapeUpdate
_numIdentities
_numLevels
_numNeurons
_numOfFrames
_numOfScores
_numOfValidFrames
_numOrientations
_numPoints
_numScales
_numSingletons
_numValidSingletons
_numVertices
_obfuscateLabelName:
_objectBounds
_objectBoundsInitial
_objectRequest
_objects
_objectsMotion
_observation
_obstruction
_obstructionAnalysis
_obstructionResults
_obstructionScore
_offline
_onDemandGyro
_onDemandPixel
_onceExif
_onceScenes
_openSuggestionsLoggingSession
_options
_orientation
_orientationResponses
_orientationResults
_orientionMap
_originalFrameTimestampArray
_originatingFace
_outpuBlobName
_outputBeforeSpatiialPooling
_outputBeforeTemporalPooling
_outputBlob
_outputBlobs
_outputFeatureName
_outputFlow
_outputFrameDurValue
_outputNames
_outputRes4
_outputSemaphore
_outputSize
_outputsData
_outstandingSuggestionRequests
_overallActivityLevel
_overallFaceQualityScore
_overlapRatioOf:with:
_padSize
_padding
_panoVNRequestMethod
_parseClassificationObservations:toClassificationResults:
_parseClassificationObservations:withPrefix:toClassificationResults:
_parseGroundTruthWithURL:faceCountPerPerson:personInformation:faceToPerson:assetToFaces:extendTimeoutBlock:cancelBlock:
_parseSIMLGroundTruthWithURL:faceCountPerPerson:personInformation:faceToPerson:assetToFaces:extendTimeoutBlock:cancelBlock:
_pcmBuffer
_peak
_peakValues
_penaltyScore
_peopleThreshold
_performAnalysis:mediaType:mediaSubtypes:abnormalDimension:colorPixelBuffer:andLumaPixelBuffer:image:
_performAnalysis:withRequestHandler:quickMode:sourceWidth:sourceHeight:
_performAndPersistClustersWithFaceTorsoprintsToAdd:groupingIdentifiersToAdd:faceTorsoprintsToRemove:updatedFaces:cancelOrExtendTimeoutBlock:error:
_performBlurAnalysis:withLumaPixelBuffer:abnormalDimension:isSDOF:
_performBlurAnalysis:withPixelBuffer:usingAnalyzer:
_performExposureAnalysis:withLumaPixelBuffer:
_performRotationAnalysis:withColorPixelBuffer:
_performSceneAnalysis:image:mediaType:mediaSubtypes:abnormalDimension:
_performWallpaperAnalysis:withSceneprint:
_persistFaces:forAsset:
_persistGeneratedFaceCrops:forAsset:error:
_persistPersonsModel:evaluationMode:error:
_persistPetsModel:error:
_persistenceDelegate
_person1LocalIdentifier
_person2LocalIdentifier
_personBuilderMergeCandidatesDisabled
_personBuilderMergeCandidatesEnabled
_personBuildingDisabled
_personClusterVersion
_personID
_personIdentityModel
_personKeypointsDetector
_personLocalIdentifier
_persons
_personsModel
_petRect
_petsActionScore
_petsActiveRegions
_petsAnalyer
_petsDetector
_petsDominant
_petsFaceActiveRegions
_petsFaceDetections
_petsFaceStart
_petsKeypointsDetector
_petsModel
_petsResults
_petsStart
_phAsset
_phFaceFlags
_phFaceResults
_phFaceSortDescriptors
_phFaces
_phPeopleSortDescriptors
_photoLibrary
_photoOffset
_photoSharpnessReliable
_photolibrary
_pixelBuffer
_pixelBufferPools
_pixelFormat
_pixelHeight
_pixelMean
_pixelVar
_pixelWidth
_plan
_playbackCrop
_points2D
_points3D
_pointsImage
_pointsWorld
_pool
_pooledPixelBuffer:withDimension:
_pose
_poseAnalyzer
_poseEstimator
_poseRequest
_poseResults
_poseSolver
_poseType
_poseYaw
_position
_postInference
_postProcessMovieHighlights:analysis:withOptions:
_postProcessStart
_postTasks
_preAnalysisSharpnessScore
_preWarmed
_precisionPerCluster
_preencodeAnalysis
_preferredFormat
_preferredHeight
_preferredMetalDevice
_preferredTimeRange
_preferredTransform
_prepareLivePhotoScenes
_prevComputedScore
_prevEstimatedCenterMv
_prevExprWeights
_prevFrameHandKeypoint
_prevMotionParamDiff
_prevTimeSignLanguageDetected
_prevTimeStampHandDetected
_previousContentType
_previousCovar
_previousState
_previousStateIsValid
_privateMutableResults
_privateTasks
_processBoundingBoxFromDetectedObjects:forSceneClassID:
_processDirtyFaceCrop:faceCropFaceLocalIdentifier:error:
_processFetchedFaceGroup:forPersonID:facesPerAsset:assetInformation:extendTimeoutBlock:cancelBlock:
_processFormat
_processNewlyClusteredFaceCropsInFaceGroups:cancelOrExtendTimeoutBlock:
_processedPredicateForTaskID:
_processingGroup
_processingQueue
_processingQueueDetermineNextClusterTriggeringAccumulatedChangesCountIfNecessary
_processingQueueGetFaceClusterSequenceNumbersInClusterCache:lastClusterSequenceNumber:error:
_processingQueueGetVisionClusters:minimumClusterSize:returnClusterAsCountedSet:excludedL0ClustersByL1ClusterId:cancelOrExtendTimeoutBlock:error:
_processingQueuePerformForcedFaceClustering:cancelOrExtendTimeoutBlock:
_processingQueueQuickSyncClustererWithPhotoLibraryUsingFacesInClusterCache:visionClusters:cancelOrExtendTimeoutBlock:
_processingQueueResetClusterCache:
_processingQueueRestoreClusterCacheAndSyncWithLibrary:cancelOrExtendTimeoutBlock:error:
_processingQueueRestoreClusteringCacheWithCacheDirectoryURL:clusterState:threshold:error:
_processingQueueRestoreFromClusterSnapshotFileAtURL:error:
_processingQueueSaveClusterCache:
_processingQueueSyncClustererWithPhotoLibraryUsingFacesInClusterCache:cancelOrExtendTimeoutBlock:
_processingVersion
_progressFromWorkerStatesDictionary:
_progressHandler
_properties
_propertyDictionary
_propertyDictionaryFileURL
_propertyDictionaryLock
_prune
_ptrFirst
_ptrLast
_publicMutableResults
_purgeAllResources
_quality
_qualityResuls
_qualityScore
_qualityScoreForLivePhoto
_quantFactor
_quarantineTwinsOnAssetEnabled
_queryDistanceDescriptor:ofAsset:withExistingAnalysis:andDatabase:timeRange:lastFeature:isDegraded:
_queryProgressDetailExpress:forPhotoLibrary:andTaskID:
_queryProgressDetailExpressEmbeddingAnalysis:forPhotoLibrary:
_queryValue:forKey:
_queue
_reLU
_reachability
_readFaceAnalysisState
_readPropertyDictionary
_readerOutput
_readerOutputAdaptor
_ready
_rebuildClusterer
_recallPerPersonExcludeMissDetection
_recallPerPersonToGroundTruth
_recipeBlob
_recognitionVersion
_recordClusterRebuildRequired:
_recordClusteringState:
_recordCountOfPendingFacesToAdd:
_recordCurrentStatus:
_recordIncrementCountOfPendingFacesToAdd:
_recordNeedToPersonBuildOnFaceGroupContainingFace:error:
_regionCrop
_regionOfInterest
_regions
_relativeActionScore
_relativeScore
_removeEmptyGroups
_removeVisionClusterCacheFilesNotReferencedByVisionClusterState:
_reportCoreAnalyticsWithVisionClusterMeasure:personClusterMeasure:personClusters:andGroundTruthInformation:
_reportDownload:
_representativenessByFaceCSNFromFaces:cancelOrExtendTimeoutBlock:
_request
_requestAnalyses
_requestAnalysis:forAsset:withExistingAnalysis:andDatabase:andOptions:cancelBlock:
_requestBestTrim
_requestFullResult
_requestId
_requestedAnalyses
_requests
_requirePHFaceAnalysis
_resConfig
_reservedIDs
_resetFaceClusterSequenceNumberOfFacesInFetchResult:inPhotoLibrary:cancelOrExtendTimeoutBlock:error:
_resetFaceClusteringState:
_resolution
_resolveConflictingL0ClustersFromVNClusters:excludedL0ClustersByL1ClusterId:cancelOrExtendTimeoutBlock:
_resource
_resourceManager
_resources
_results
_resultsKey
_resultsTypes
_revision
_rgbColorSpace
_rgbFrame
_rgbToYuv
_rightHandKeypointTracker
_roll
_rotMatrix
_rotationAngle
_rotationAngleForFacePose
_rotationBufferCreator
_rotationModel
_rotator
_rotatorForFacePose
_saliencyAnalyer
_saliencyObjectnessRequest
_saliencyRequest
_saliencyResults
_sampleBatchSize
_sampleBuffer
_sampleFlag
_sampleRate
_samplesFor100ms
_sandboxQueue
_saveKeypoints
_scale
_scaledPixelBuffers
_scanPhotoLibrary:withTaskID:statistics:andExtendTimeoutBlock:
_sceneAnalysis
_sceneChangeAnalyzer
_sceneDeltaBuffer
_sceneId
_sceneResults
_sceneSegments
_sceneSwitchFrequency
_sceneType
_sceneprint
_sceneprintDistanceToPreviousScene
_sceneprintRawRequest
_sceneprintRequest
_score
_scoreAbsoluteMax
_scoreArray
_scoreRelativeMax
_sdof
_secondBuffer
_semanticRequest
_semanticScore
_semaphore
_service
_session
_sessionAnalytics
_sessionAnalyticsSentCount
_sessionPool
_setAllFaceGroupsNeedPersonBuilding
_setBudget:
_setFaceAnalysisStateValue:forKey:
_setPropertyDictionaryValue:forKey:
_setupMediaAnalysisServiceConnection
_sexType
_shapeModel
_shapeUpdateInProgress
_sharedModel
_sharpness
_sharpnessBlocks
_shotType
_signature
_signpostPayload
_singleAnalyticsSentCount
_singleFrameExecutionTime
_size
_skintoneType
_skip
_skipNumFramesBothEnds
_smile
_smileDetector
_smileType
_songDetector
_sortedViableFaceMergePairsFromQueryFaces:andCandidateFaces:
_sourceHeight
_sourcePixelBuffer
_sourceSizeHeight
_sourceSizeWidth
_sourceWidth
_sportsSceneId
_srcHeight
_srcWidth
_stabilizationType
_stabilize
_stabilizeResult
_standalone
_start
_startAndSyncClusterCacheWithLibrary:reply:
_startLevel
_startRange
_startTime
_started
_state
_stats
_statsFlags
_std
_stillTime
_storage
_storageGroup
_storageQueue
_stridePadded
_subMb
_subMbMotionAvailable
_subjectAction
_subjectActionScore
_subjectScore
_subtasks
_subtleMotionAnalyzer
_subtleMotionResults
_subtleMotionScore
_suggestionLoggingDirectory
_suggestionLoggingSessionOpen
_suggestionsForPersonLocalIdentifier:clusterSequenceNumbers:excludePersonLocalIdentifiers:cancel:context:error:
_suggestionsForPersonWithLocalIdentifier:toBeConfirmedPersonSuggestions:toBeRejectedPersonSuggestions:cancel:error:
_suggestionsLogEnabled
_suggestionsLoggingEnabled
_sumConfidence
_sumOfScore
_supportConditionalAnalysis
_tabooRequest
_targetDurationInSeconds
_targetHighlightIndex
_tasks
_taxonomy
_tensorCoeff
_tensorModel
_textureScore
_textureness
_threshold
_timeEnd
_timeInterval
_timeLastDetection
_timeLastProcess
_timeLastProcessFullFrame
_timeLastTracking
_timeRange
_timeScale
_timeStamp
_timeStart
_timeValue
_timeValues
_timebase
_timer
_timerange
_timescale
_timestamp
_timestampOfLastClusterComparison
_toleranceInSeconds
_torsoprint
_track
_trackID
_trackOutput
_trackReader
_trackScoreFilter
_trackStart
_tracker
_trackers
_tracking
_trackingMode
_trackingModeCounter
_trackingScore
_trainingType
_trans
_transArray
_transaction
_transferSession
_transform
_transformedCoeff
_transformedImageHeight
_transformedImageWidth
_triIndexMap
_triList
_trimAnalyzer
_turbo
_type
_types
_typesToRemove:requested:
_typesWide
_underExpose
_ungroupFaceClusterSequenceNumbers:cancelOrExtendTimeoutBlock:error:
_uniformTypeIdentifier
_updateAnalysisPreferencesWithEntries:keysToRemove:
_updateCurrentProcessingVersion:
_updateFaceCSNsToAddByPerson:faceCSNsToRemoveByPerson:faceInFaceGroupByCSN:faceCSNsByPersonLocalIdentifier:faceCSNsByMigratedPersonLocalIdentifier:personsToUpdate:
_updateHandler
_updateShapeGroup
_updateShapeQueue
_updateVersionStateFileWithError:
_url
_useCPUOnly
_useMoflow
_useR14J9
_useR2D2
_useSingleEspressoModel
_utteranceDetections
_valAngle
_valBuffer
_valBufferRotated
_valLM
_valid
_validActivityScores
_validFrames
_validStabilization
_validateFailedOnce
_validationGroup
_validationQueue
_validationScore
_value
_vcpFaceCropFromPHFaceCrop:
_verbose
_version
_versionState
_versionStateURL
_vertexCount
_vertices
_videoActivityDescriptor
_videoAnalysis
_videoCaptionDecoder
_videoCaptionEncoder
_videoCaptionEncoderAsset
_videoCaptionResult
_videoFrameAnalysis
_vipStatusForPhotoLibrary:andType:
_visionClusterStateDataBlobFromClusterSnapshotFileAtURL:error:
_visualPleasingScore
_vnFaceAttributeAgeToPHFaceAgeTypeMap
_vnFaceAttributeEthnicityToPHFaceEthnicityType
_vnFaceAttributeEyesToPHEyesStateMap
_vnFaceAttributeFacialHairToPHFaceExpressionType
_vnFaceAttributeFacialHairToPHFacialHairTypeMap
_vnFaceAttributeGlassesToPHFaceGlassesTypeMap
_vnFaceAttributeHairColorToPHFaceHairColorTypeMap
_vnFaceAttributeHairTypeToPHFaceHairType
_vnFaceAttributeHeadGearToPHFaceHeadGearType
_vnFaceAttributePoseToPHFacePoseType
_vnFaceAttributeSexToPHFaceSexTypeMap
_vnFaceAttributeSkintoneToPHFaceSkintoneType
_vnFaceAttributeSmileToPHFaceSmileTypeMap
_vnFaceGazeDirectionToPHFaceGazeType
_voiceActivity
_voiceActivityNew
_voiceDetections
_voiceDetector
_voiceResults
_voiceScore
_voiceStart
_weakRequest
_weakSession
_weightedAveragePrecision
_weightedAverageRecall
_width
_widthBlockNum
_widthExt
_widthInMb
_widthPadded
_yaw
_yuvFrames
absMotion
absoluteActionScore
absoluteScore
absoluteString
absoluteURL
acceleratedDecodeImageData:pixelFormat:maxDimension:pixelBuffer:orientation:flushCache:
accumulateDoubleValue:forField:andEvent:
accumulateInt64Value:forField:andEvent:
actionScore
actionScoreForTimerange:
actionScoreInTimeRange:
activateResource:
activeCost
activeCount
activeSegment
activityID
activityScore
add:
addActiveResults:
addAggregatedScenes:timerange:
addBounds:
addClassification:
addClusterPrecision:forPersonID:personFaceCount:validFaceCount:identitySize:
addDetectionFromTime:toTime:confidence:
addDetectionFromTime:toTime:result:
addDetectionToDict:withActiveRegions:forPetsDetections:fromTime:
addEntriesFromDictionary:
addFaceObservations:forPersonIdentifier:toModel:error:
addFaceObservations:toPersonWithUniqueIdentifier:error:
addFaceResults:flags:
addFaces:
addFetchPropertySets:
addFrameInstructions:
addHighlight:to:
addHomographyParam:
addHomographyParams:
addIdentityRecallExcludeMissDetection:forPersonID:personFaceCount:identitySize:
addIdentityRecallToGroundTruth:forPersonID:personFaceCount:identitySize:
addImageBlurResults:
addImageCompositionResults:
addImageExposureResults:
addImageFaceResults:
addImageFeatureResults:
addImageHumanPoseResults:
addImageJunkResults:
addImagePetsFaceResults:
addImagePetsResults:
addImageSaliencyResults:
addImageSceneprintResults:
addImageShotTypeResults:
addInvalidMergeCandidatePersons:
addKeypoints:
addKeypointsToNSArray:keypointConfidence:handBox:keypointsArray:
addLivePhotoEffectsResults:
addLivePhotoHumanActionClassificationResults:
addLivePhotoKeyFrameResults:
addLivePhotoKeyFrameStillResults:
addLivePhotoRecommendationResults:
addLivePhotoSharpnessResults:
addMergeCandidatePersons:
addMovieActivityLevelResults:
addMovieApplauseResults:
addMovieAudioQualityResults:
addMovieBabbleResults:
addMovieCameraMotionResults:
addMovieCheeringResults:
addMovieClassificationResults:
addMovieFaceResults:
addMovieFaceprintResults:
addMovieFeatureResults:
addMovieFineSubjectMotionResults:
addMovieHighlightResults:
addMovieHighlightScoreResults:
addMovieHumanActionResults:
addMovieHumanPoseResults:
addMovieLaughterResults:
addMovieLoudnessResults:
addMovieMovingObjectResults:
addMovieMusicResults:
addMovieObstructionResults:
addMovieOrientationResults:
addMoviePetsFaceResults:
addMoviePetsResults:
addMoviePreEncodeResults:
addMovieQualityResults:
addMovieSaliencyResults:
addMovieSceneResults:
addMovieSceneprintResults:
addMovieStabilizationResults:
addMovieSubjectMotionResults:
addMovieSubtleMotionResults:
addMovieSummaryResults:
addMovieUtteranceResults:
addMovieVoiceResults:
addObject:
addObjectsFromArray:
addObservations:toEntityWithUniqueIdentifier:error:
addOutput:
addRequest:withConfiguration:error:
addRequest:withObserver:error:
addResult:start:duration:keyIsName:
addResult:to:forKey:optional:
addSceneAnalysisResult:to:clipRange:
addSceneAnalysisResult:to:optional:
addSceneClassificationContributionToActivityLevel:
addSceneSwitchFrequencyConstributionToActivityLevel:
addSegment:
addSegmentToResults
addSummary:to:
addTimeValue:
addedDate
adjustScoreByFace
adjusted
adjustmentKeys
adjustmentTimestamp
adjustmentValuesForKey:
adjustmentVersion
adjustmentsRequest
advancedStatus
advancedStatusMergeCandidateLimit
advancedStatusVerifiedPersonLimit
aestheticScore
aestheticsRequest
ageCategory
aggregateAnalysisForTypes:withFramesMeta:properties:
aggregateTileResults:tileRect:imageSize:landscape:results:
aggregateWith:
aggregatedResults
algorithmVersion
alignedBoundingBoxAsCGRect
allClusteredFaceIdsAndReturnError:
allObjects
allScenes
allValues
allocBuffers:
allocWithZone:
allocateCorreleationBuffer:forLevel:
allocateFeatures
allocateInputAndOutputBuffers
allocateStorages
allowFastPathDecodeWithUniformType:pixelWidth:andPixelHeight:
allowOnDemand
allowStreaming
allowedClasses
analysis
analysisConfidence
analysisResultRef
analysisType
analyzeAsset:cancel:results:
analyzeAsset:flags:
analyzeAsset:onDemand:cancel:statsFlags:results:
analyzeAsset:results:
analyzeAsset:streamed:
analyzeAsset:withOptions:
analyzeAsset:withResource:resourceURL:quickMode:results:
analyzeAudioBuffer:
analyzeAudioBuffer:atAudioFramePosition:
analyzeBodyArray:
analyzeCGImage:results:
analyzeDetectedFaces:faceResults:cancel:
analyzeFaceQuality:withAsset:andCancelBlock:
analyzeFrame:withFaceBounds:
analyzeFrame:withFaceRect:withRotation:withTimestamp:
analyzeFrame:withTimestamp:
analyzeFrame:withTimestamp:andDuration:completion:
analyzeFrame:withTimestamp:andDuration:flags:
analyzeFrame:withTimestamp:andDuration:flags:cancel:
analyzeFrame:withTimestamp:andDuration:flags:frameStats:
analyzeFrameForPose:withFaceRect:withTimestamp:
analyzeFrameWithTimeRange:analysisData:
analyzeFrameWithTimeRange:andActionScore:
analyzeImage:performedAnalyses:cancel:
analyzeImageQuality:irisPhotoOffsetSec:cancel:
analyzeImages:secondImage:cancel:
analyzeKeyFrame:withTimestamp:andDuration:flags:
analyzeLivePhotoKeyFrame:irisPhotoOffsetSec:originalIrisPhotoOffsetSec:photoTextureScore:hadFlash:cancel:
analyzeMotionStability:motionParamDiff:
analyzeOndemand:forAnalysisTypes:withExistingAnalysis:error:
analyzeOndemand:pairedURL:forAnalysisTypes:error:
analyzeOverallQuality:isSettlingEffect:
analyzeOverallQuality:withFpsRate:
analyzePixelBuffer:flags:petsDetections:results:cancel:
analyzePixelBuffer:flags:results:cancel:
analyzePixelBuffer:flags:withPreAnalysisScore:results:cancel:
analyzePixelBuffer:withFrame:withTimestamp:andDuration:cancel:
analyzePixelBuffer:withFrame:withTimestamp:andDuration:hasSubtleScene:cancel:
analyzePixelBuffer:withTimestamp:andDuration:properties:completion:
analyzePixelBuffer:withTimestamp:andDuration:properties:error:
analyzePixelBufferInTiles:results:cancel:
analyzeSampleBuffer:
analyzeVideoSegment:timerange:forAnalysisTypes:cancel:
analyzeVideoTrack:start:forAnalysisTypes:cancel:
analyzeWithImageURL:mediaType:mediaSubtypes:abnormalDimension:completionHandler:
analyzeWithImageURL:requestTypes:reencode:completionHandler:
analyzeWithLightweightOption:aspectRatio:computationAccuracy:forceCPU:sharedModel:flushModel:cancel:
analyzeWithSceneprint:results:cancel:
analyzeWithStart:andDuration:error:
analyzer
analyzerForAnalysisTypes:withPreferredTransform:properties:
analyzerForTrackType:withTransform:requestAnalyses:formatDescription:
analyzerWith:prune:
analyzerWithRevision:
analyzerWithVCPAsset:forAnalysisTypes:
analyzerWithVCPAsset:withExistingAnalysis:forAnalysisTypes:
andPredicateWithSubpredicates:
angle
animalObservationFromAnimalprintData:
animalprint
anonymizedName
anyObject
appendBuffer:atTime:error:
appendData:
appendFormat:
appendString:
approximateCoordinate
approximateLocation
archivedDataWithRootObject:requiringSecureCoding:error:
area
array
arrayByAddingObjectsFromArray:
arrayLength
arrayWithCapacity:
arrayWithContentsOfURL:
arrayWithObject:
arrayWithObjects:
arrayWithObjects:count:
asset
assetActionScoreFromAnalysis:
assetActivityLevelFromAnalysisResults:
assetAdjustedFingerprint
assetCameraMotionScoreFromAnalysis:
assetExpressionScoreFromAnalysis:
assetImageGeneratorWithAsset:
assetJunkScoreFromAnalysis:
assetLocalIdentifier
assetMasterFingerprint
assetModificationDate
assetQualityScoreFromAnalysis:withFpsRate:
assetReaderOutputMetadataAdaptorWithAssetReaderTrackOutput:
assetReaderSampleReferenceOutputWithTrack:
assetReaderTrackOutputWithTrack:outputSettings:
assetReaderWithAsset:error:
assetResourcesForAsset:
assetResourcesForAsset:includeDerivatives:
assetVoiceScoreFromAnalysis:
assetWithData:
assetWithIdentifier:isCloudIdentifier:error:
assetWithImageData:uniformTypeIdentifier:identifier:clientBundleID:clientTeamID:
assetWithPHAsset:
assetWithPhotosAsset:clientBundleID:clientTeamID:
assetWithPhotosAsset:pixelBuffer:orientation:clientBundleID:clientTeamID:
assetWithPixelBuffer:orientation:identifier:clientBundleID:clientTeamID:
assetWithURL:
assetWithURL:identifier:clientBundleID:clientTeamID:
assetsAnalyzedSinceDate:completionHandler:
assetsFromPhotoLibrary:analyzedSinceDate:completionHandler:
assignPropertiesOfVCPPhotosFace:toPHFaceChangeRequest:
associateFace:withFaceCrop:error:
associateFaceWithPersonUUID:
associateHands:withExisingHands:
associatePerson:withPHFaces:
associatePersons:withExisingPersons:
attachProgressCallBack:
attachSalientRegions:toPixelBuffer:
attempts
attributes
attributesOfItemAtPath:error:
audioFormatRequirements
audioQualityScore:
autoLiveMotionScore:
autoPlayable
autoloop
autoplayScore
autorelease
availableMetadataFormats
averageOrientationResponses:withCurrentMap:
averageScore
barcodeObservations
becomeCurrentWithPendingUnitCount:
bestPlaybackCrop
bestRepresentativeFaceForPerson:qualityMeasureByFace:cancelOrExtendTimeoutBlock:
bestRepresentativeFaceForPerson:qualityMeasureByFace:canceler:
bestRepresentativeFaceForPerson:qualityMeasureByFace:candidateFaces:cancelOrExtendTimeoutBlock:
bestRepresentativeFaceForPerson:qualityMeasureByFace:candidateFaces:canceler:
bestTrimTimeRange
bindWithBuffers:correlation:flow:outputFlow:
bindWithBuffers:imgFeature:
blacklistedLocalIdentifiersFromAssets:
blendShapes
blendshapeComponentIndex
blockContentDetection:
blurScore
bodyCenterX
bodyCenterY
bodyDistance:withBodyB:
bodyHeight
bodyWidth
boolValue
bounce
bound
boundDistance:relativeTo:landscape:
boundingBox
bounds
boundsAtIndex:
boundsCount
boundsType
boundsWithCGRect:
bufferAllocCPU
bufferRotated
buildModelWithConfig:error:
buildPersonWithFaceClusterer:keyFaceUpdateBlock:context:cancelOrExtendTimeoutBlock:
buildPersonsWithFaceClusterer:keyFaceUpdateBlock:canceler:context:extendTimeoutBlock:
bundleWithIdentifier:
bytes
cacheHitWithQueryID:cachedResultQueryID:
cachePath
cachedImageHandler
calculateAndReportClusterAccuracyWithVisionClusterURL:andPersonClusters:results:extendTimeoutBlock:cancelBlock:
calculateBlendshapeWeights:prevWeights:lmBlendshapes:maxIter:
calculateCandidateScoreWithRangeAdjust:endIdx:candidateTimeRange:captureTime:
calculateConfidence:lineDistance:vaninshingPoint:vanishingPointConfidence:
calculateDistance:toWrapper:andError:
calculateFaceRectFromPrevLM:result:numOfLandmarks:
calculateFrameDifference:
calculateIdentityCoefficients:extrinsicMatrix:pts2D:exprWeights:lm3DMeanBlendshapes:lm3DComponents:maxIter:
calculateMesh:numVertices:blendshapes:outputMesh:
calculateModelBlendshapes:outputBlendshapes:
calculateOrientationResponses
calculatePosePnpSolver:
calculatePriorityScore:ofPixelBuffer:withMetadata:
calculateScoreFromNetworkOutput:outChannel:outHeight:outWidth:textureness:contrast:imgWidth:
calculateScoreFromNetworkOutputV2:
calculateTextureness:height:width:sdof:result:
cameraActivityfromQuality:
cameraMotionDetection:
cameraMotionScore
cameraMotionScoreForTimerange:
canAddOutput:
canAnalyzeUndegraded:withResources:
canDecodeAcceleratedUniformTypeIdentifier:
canRenderVariation
canReuseResultsForRequest
canUseLastFrameOfAsset:withResources:
cancel
cancelAllRequests
cancelAllSuggestionRequests
cancelAnalysisWithRequestID:
cancelBackgroundActivity
cancelBackgroundActivityWithReply:
cancelBlock
cancelClustering
cancelDataRequest:
cancelReading
cancelRequest:
cancelSuggestionRequest:
cancelTask:
cancelled
canceller
catalogIDs
cflags
changeRequestForAsset:
changeRequestForDedupingGraphPersons:
changeRequestForFace:
changeRequestForFaceCrop:
changeRequestForFaceGroup:
changeRequestForPerson:
characterAtIndex:
characterRecognitionProperties
characterSetWithCharactersInString:
checkAutoPlayable
checkCameraZoom:
checkCameraZoom:cameraMotionResults:
checkFaceDominant
checkResolutionChange:withRotation:
checkTimeRangeConsistency
checkTimeout
checkTrimAt:captureTime:
chirality
chunkFourForward
cityNatureRequest
class
classIndex
classificationAtIndex:
classificationForIdentifier:
classificationRequest
classificationType
classificationsCount
classifyAnimalObservation:withModel:error:
classifyFaceObservation:withModel:error:
classifyFaceObservation:withPersonsModel:error:
classifyPixelBuffer:stagedText:inConversationWithIdentifier:error:
cleanupGroupedFacesWithClusterSequenceNumberSetToZero:error:
cleanupGroupedFacesWithClusterSequenceNumberSetToZeroWithCanceler:error:
cleanupMergeCandidatesWithMinimumFaceGroupSize:cancelOrExtendTimeoutBlock:error:
cleanupUngroupedFacesWithNonZeroClusterSequenceNumbers:error:
cleanupUngroupedFacesWithNonZeroClusterSequenceNumbersWithCanceler:error:
cleanupWithOptions:error:
clearBounds
clearCacheWithOption:
clearClassifications
clearDirtyStateOnFaceCrops:error:
clearFaceResults
clearFrameInstructions
clearHomographyParams
clearImageBlurResults
clearImageCompositionResults
clearImageExposureResults
clearImageFaceResults
clearImageFeatureResults
clearImageHumanPoseResults
clearImageJunkResults
clearImagePetsFaceResults
clearImagePetsResults
clearImageSaliencyResults
clearImageSceneprintResults
clearImageShotTypeResults
clearKeypoints
clearLivePhotoEffectsResults
clearLivePhotoHumanActionClassificationResults
clearLivePhotoKeyFrameResults
clearLivePhotoKeyFrameStillResults
clearLivePhotoRecommendationResults
clearLivePhotoSharpnessResults
clearMovieActivityLevelResults
clearMovieApplauseResults
clearMovieAudioQualityResults
clearMovieBabbleResults
clearMovieCameraMotionResults
clearMovieCheeringResults
clearMovieFaceResults
clearMovieFaceprintResults
clearMovieFeatureResults
clearMovieFineSubjectMotionResults
clearMovieHighlightResults
clearMovieHumanActionResults
clearMovieHumanPoseResults
clearMovieInterestingnessResults
clearMovieLaughterResults
clearMovieLoudnessResults
clearMovieMovingObjectResults
clearMovieMusicResults
clearMovieObstructionResults
clearMovieOrientationResults
clearMoviePetsFaceResults
clearMoviePetsResults
clearMoviePreEncodeResults
clearMovieQualityResults
clearMovieSaliencyResults
clearMovieSceneResults
clearMovieSceneprintResults
clearMovieStabilizationResults
clearMovieSubjectMotionResults
clearMovieSubtleMotionResults
clearMovieSummaryResults
clearMovieUtteranceResults
clearMovieVoiceResults
clientBundleID
clientTeamID
clipResults:
cloneCaptionModel:to:
close
closeDatabase
closedefaultPhotoLibrary
clsDistanceIdentity
clusterAndWaitWithCancelOrExtendTimeoutBlock:
clusterCount
clusterFaces
clusterFacesIfNecessary
clusterFlagByClusterId
clusterId
clusterIfNecessaryAndWaitWithCancelOrExtendTimeoutBlock:
clusterIncludeTorsoOnlyFaces
clusterSequenceNumber
clusteredFaceCount
clusteredFaceIdsForClusterContainingFaceId:error:
clusterer
clustererBringUpState
clustererBuilderWithOptions:error:
clustererIsReadyToReturnSuggestions
clustererModelFileNamesFromState:storedInPath:error:
clustererState
cnnDataClass
cnnDataWithGPUContext:
cnnDataWithPlane:height:width:context:
cnnOutputWidth
code
colorNormalization
colorNormalizationBlob
colorfulnessScore
combineBufferTo:flowX:flowY:
combineMLHighlightScore
commandBuffer
commandQueue
commit
compare:
compare:options:
compareFace:withFace:
compareNumericVersion:withReferenceVersion:
compareObjectsOfInterest:withScenes:
compareSoftwareStackVersion:withReferenceVersion:
completionHandler
componentsBlendshape
componentsSeparatedByString:
composition
computeActionFaceTrimFor:
computeActionScore
computeActionScoreForPerson:
computeActionScoreInTimerange:
computeActivityScoreAtTime:
computeBarycentricCoordinates
computeBestPlaybackCrop:
computeCNNBasedSharpness:sharpnessScore:textureScore:contrast:cancel:
computeCNNFaceSharpness:result:cancel:
computeColorNormalization
computeCommandEncoder
computeContentScore
computeControlPointsCamera:Vt:
computeCurationScore
computeCurationScoreComponents
computeDistance:fromArray:toArray:
computeDistance:toDescriptor:
computeDistance:withDescriptorClass:fromAsset:toAsset:
computeDistance:withDistanceFunction:error:
computeExposureScoreOfFrame:
computeExpressionScore
computeExpressionScoreInTimerange:
computeFaceQualityOfFrame:
computeGlobalQuality
computeGlobalQualityForLivePhoto
computeGyroSharpness:
computeHighlightScoreOfRange:
computeHighlightScoreResults
computeHumanActionScoreInTimerange:
computeHumanPoseScoreInTimerange:
computeIntersectionOverUnion:
computeL6x10:L6x10:
computeLandmarks:
computeLocalSharpness:
computeMLHighlightScoreForTimerange:
computeMLQualityScoreForTimerange:
computeMinDistanceBetween:withSet:
computeMotionDivScore:
computeNoiseLevel:width:height:stride:textureness:
computePenaltyScore
computePoints3DCamera
computePoseScore:
computeProjectionError:T:
computeQualityTrimFor:withKeyFrame:
computeR6x1:
computeRT:T:
computeRampToTargetRate:forExport:outTimeSteps:outIntermediateRates:
computeRegionNoise:blockTextureness:average:width:height:stride:
computeRegionSharpness:width:height:stride:
computeRegionsofInterest
computeSVDVt:Vt:
computeScore:width:height:posX:posY:
computeScoreForPhoto:withRefKeyFrame:
computeScoreFromAction
computeScoreFromColorfulness
computeScoreFromExposure
computeSharpnessOfFrame:
computeSharpnessScore:forFacesInImage:
computeSharpnessScore:forObjects:inImage:
computeSharpnessScore:textureness:contrast:imgWidth:cancel:
computeSmileScore:
computeSteadyTranslationTrimFor:
computeSubtleMotionScoreInTimerange:
computeTrimWithHighlightScoreFor:
computeVar:index2:interVar:intraVar:
computeVarWithID:index1:index2:interVar:intraVar:
computeVisualPleasingScore
computeVoiceScoreInTimeRange:
confidence
configForAspectRatio:
configInputBasedOnDevice
configuration
configureGPU
configureGaussNewton:R6x1:betas:jacobian:residual:
configureRequest:withRevision:
configureVNRequest:withClass:andProcessingVersion:
configureVNRequest:withClass:andVisionRevision:
conformsToProtocol:
connection
constructBlock:context:
containsIndex:
contentInformationRequest
contentScore
contents
contentsOfDirectoryAtURL:includingPropertiesForKeys:options:error:
contextWithDictionary:error:
contextWithPhotoLibrary:
convBlockWithFilterSize:filterNum:chunk:reLU:padding:
convBlockWithFilterSize:filterNum:chunk:reLU:padding:groups:stride:batchNorm:
conversationIdentifier
convertAnalysisResult
convertCPUData2GPU
convertFlow:
convertGPUData2CPU
convertImage:yuvFrame:
convertLivePhotoBinary:toDictionary:
convertLivePhotoStruct:toDictionary:
convertPixelBuffer:toPixelBuffer:withPixelFormat:
convertPixelBuffer:toPixelFormat:flushCache:
convertResultsToDict:results:
convertSingleResultToDict:keypointConfidence:box:results:
convertToOriginalTimeFromScaledTime:forExport:
coordinate
copy
copyBlock:withStride:toBlock:
copyBufferFrom:fromStride:toPtr:toStride:toWidth:toHeight:
copyCGImageAtTime:actualTime:error:
copyFrom:
copyImage:toBuffer:withChannels:
copyImage:toData:
copyImage:toData:withChannels:
copyImage:toData:withChunk:
copyImage:withChannels:
copyImage:withChunk:
copyItemAtURL:toURL:error:
copyNextMetadataGroup
copyNextSampleBuffer
copyWithZone:
correctSigns
correctionResultRef
count
countByEnumeratingWithState:objects:count:
countForTaskID:withProcessingStatus:
countOfClusteredFaces
countOfClusteringEligibleFaces
countOfFaces
countOfUnclusteredClusteringEligibleFaces
cplStatus
createContextPreferred
createContextWithForceCPU
createContextWithMPSGraph
createDecoderForTrack:timerange:forAnalysisTypes:
createDirectoryAtURL:withIntermediateDirectories:attributes:error:
createFaceHeatMap:imageFaces:
createGaborFilterKernel:sigmaX:sigmaY:lambda:thetaInDegree:phaseInDegree:
createInput:keypoints:
createInput:withBuffer:
createInput:withBuffer:cnnInputHeight:cnnInputWidth:
createInput:withBuffer:cnnInputHeight:cnnInputWidth:box:
createInput:withBuffer:cnnInputHeight:cnnInputWidth:crop:
createInput:withBuffer:inputHeight:inputWidth:
createInput:withBuffer:modelInputHeight:modelInputWidth:
createInput:withImage:modelInputHeight:modelInputWidth:
createModel
createModel:srcWidth:
createModelWithResConfig:
createModules:
createOutputMetadataFromDictionary:
createPixelBuffer:
createPixelBufferWithWidth:height:pixelFormat:pixelBuffer:
createQueryContextWithError:
createVideoAnalyzer:withFrameStats:
creationDate
creationRequestForFace
creationRequestForFaceGroup
creationRequestsForFaceCropsWithOriginatingFace:resourceData:
cropAndScale:regionCrop:
cropBoundsInOriginalImageFromFaceCrop:error:
cropFraction
cropRectHeight
cropRectWidth
cropRectX
cropRectY
cropToFit
croppedBoundingBox
csns
curateMovieAssetsForCollection:withAlreadyCuratedAssets:andDesiredCount:allowOnDemand:
curationProperties
curationScore
currentBudget
currentCost
currentLocale
currentOutstandingTasksWithReply:
currentProcessingVersion
cvtHeatmaps2Keypoints:outHeight:outWidth:inHeight:inWidth:outChannel:keypoints:keypointConfidence:offset:
data
dataForResource:
dataRequest
dataType
dataUsingEncoding:
dataUsingEncoding:allowLossyConversion:
dataValue
dataWithBytes:length:
dataWithBytesNoCopy:length:freeWhenDone:
dataWithContentsOfURL:
dataWithContentsOfURL:options:error:
dataWithJSONObject:options:error:
dataWithPropertyList:format:options:error:
databaseForPhotoLibrary:
date
dateByAddingTimeInterval:
dateFormatter
dateWithTimeIntervalSinceReferenceDate:
deactivateResource:
debugDescription
decideLensSwitchPoint:
decideSegmentPointBasedOn:
decideSegmentPointBasedOnActionScore:
decideSegmentPointUsingHinkleyDetector:
decodeDimensionsForTrack:
decodeImageSource:withUniformTypeIdentifier:pixelFormat:maxDimension:orientation:pixelBuffer:
decodeObjectOfClass:forKey:
decodeSample:sample:
decodeTask
dedupeGraphVerifiedPersonsInFaceGroup:personCache:
defaultANEDevice
defaultDesiredKeys
defaultManager
defaultMetalDevice
defaultPhotoLibrary
defaultProcessingVersion
deferredProcessingNeeded
deleteEmptyGroupsAndReturnError:
deleteFaceCrops:
deleteFaceGroups:
deletePersons:
densityClusteringForObjects:maximumDistance:minimumNumberOfObjects:withDistanceBlock:
dependencies
description
descriptor
descriptorData
descriptorWithData:
descriptorWithImage:
descriptors
deserializeStabilizationRecipeInAttributes:
detailedDescription
detect
detect:withConfidence:dominantLine:
detectEyeOpennessForFace:inBuffer:eyeOpenness:
detectFaces:faces:
detectLandmark:width:height:stride:facerect:prevResult:result:
detectPersons:persons:
detectPixelBuffer:contentType:
detectSmileForFace:inBuffer:smile:
detectTrackFacesInFrame:withTimestamp:faces:
detectWithSigma:lowThreshold:highThreshold:
detectedFaces
detectionModeCounterShapeModel
detectionType
detector
detector:
detector:forceCPU:sharedModel:inputConfig:revision:
detectors
deterministicallyOrderedFaceIdentifiersWithLocalIdentifiers:faceprintVersion:
device
deviceForMetalDevice:
dictionary
dictionaryRepresentation
dictionaryWithCapacity:
dictionaryWithContentsOfURL:
dictionaryWithDictionary:
dictionaryWithObjects:forKeys:count:
dictionaryWithObjectsAndKeys:
differencesBetweenClusterCacheAndLibrary:excludedL0ClustersByL1ClusterId:cancelOrExtendTimeoutBlock:
direction
dirtyFaceCropsWithLimit:
dispatchThreadgroups:threadsPerThreadgroup:
displayLabel
displayMessage
distance
distanceBetweenClustersWithFaceId:andFaceId:error:
distanceBetweenLevel0ClusterIdentifiedByFaceCSN:andLevel0ClusterIdentifiedByFaceCSN:error:
distanceBetweenLevel1Clusters:error:
distanceFromAsset:timeRange:toAsset:timeRange:duplicate:distance:
distanceFromAsset:toAsset:duplicate:distance:
distanceIdentity
distanceToImageprint:error:
distanceToPreviousScene
distancesFromClustersIdentifiedByFaceCSNs:toClustersIdentifiedByFaceCSNs:error:
distantPast
documentElements
documentObservations
domain
domainInfo
domainKey
dominantLine
doubleValue
downloadVideoCaptionEncoderIfNeeded
downscaleImage:scaledImage:majorDimension:
drawLine:width:height:stride:point0:point1:drawPoint:
drawRectangle:width:height:stride:keypoints:
duration
dynamicForward:paramFileUrl:cancel:
elapsedTimeSeconds
elementCount
elementType
embeddingChannels
embeddingSequenceLength
embeddingWidth
enableGating
enableMoflow
enableR2D2
encodeHashDescriptorWithBase64EncodingAndReturnError:
encodeObject:forKey:
encodeToCommandBuffer:firstInput:secondInput:correlation:
encodeToCommandBuffer:input:output:flow:upscaledFlow:
encodeToCommandBuffer:sourceTexture:destinationTexture:
encodeToCommandBuffer:sourceTextureArray:guidanceTexture:constraintsTextureArray:numberOfIterations:destinationTextureArray:
encodeWithCoder:
encodedData
endEncoding
endEntryPoint
endPointValue
energy
entityPredictionsForObservation:limit:canceller:error:
entityUniqueIdentifier
entryForResource:
entryWithLocalIdentifier:andTaskID:andStatus:andAttempts:andLastRetryDate:
enumerateFetchResult:withBatchSize:handler:
enumerateIndexesUsingBlock:
enumerateKeysAndObjectsUsingBlock:
enumerateObjectsUsingBlock:
epoch
errorCode
errorWithDescription:
errorWithDomain:code:userInfo:
espressoForward:
espressoForwardInputs:
estimateBetasN1:R6x1:betas:
estimateBetasN2:R6x1:betas:
estimateBetasN3:R6x1:betas:
estimateDistance:prevHomography:
estimateExpressionScore:encodeStats:frameWidth:frameHeight:
estimateExtrinsicsWith:andPoints3D:andNumPoints:
estimateFlow:correlation:flow:outputFlow:callback:
estimateFlowForLevel:upperFlow:outputFlow:
estimateMotionBetweenFirstImage:andSecondImage:error:
estimateMotionBetweenFirstImage:andSecondImage:withUpsample:withGuidedImage:error:
estimateMotionFlow:
estimatePose:
estimateQualityScore:
estimateRT:betas:R:T:projectionError:
estimatedAssetCount
estimator
ethnicityType
eulerAnglesToRotation:R:
evaluatePersonPromoterWithUpdateBlock:
evaluateSegment:
evaluateWithObject:
exceptionWithName:reason:userInfo:
executeDatabaseBlock:
executionNanoseconds
exif
existingAnalysisForMovieAnalyzer
exists
exitStatus
exportClustersStates:error:extendTimeoutBlock:cancelBlock:
exportResultsWithPropertyKey:toLegacyDictionary:withKey:
exportToLegacyDictionary
exportToLegacyDictionaryFromFrameInstruction:
exportToLegacyDictionaryFromParam:withLoopFlavor:
exportWallpaperForAsset:cancel:results:
exposure
exposureChangeScore
exposureScore
exposureTimeSeconds
expressionChangeScore
expressionScoreForTimerange:
expressionType
expressionsAndConfidence
extractFeatureFromImage:toFeature:
extractFeatureFromImage:toFeature:callback:
extractFeaturesFromFirst:andSecond:
extractRequiredClassificationInfoFrom:toArray:
extractRequiredFaceInfoFrom:toArray:
extractRequiredInfoFrom:toArray:
extractUsefulAreaFrom:to:withOffset:stridePadded:width:height:
eyeExpression
eyesCategory
eyesState
face1
face2
faceAdjustmentVersion
faceAlgorithmVersion
faceArea
faceAssociatedWithFaceCrop:
faceAttributes
faceBounds
faceBounds:height:
faceBoundsFromFaceCrop:error:
faceBoundsWithTransform:height:transform:
faceCandidatesforKeyFaceForPersonsWithLocalIdentifiers:context:reply:
faceCaptureQuality
faceClusterSequenceNumbersOfFacesWithClusterSequenceNumbers:error:
faceClusterSequenceNumbersOfKeyFacesInAlgorithmicFaceGroupsForPerson:verifiedClusterSequenceNumbers:
faceClusteringAgeThreshold
faceClusteringDisabled
faceClusteringJunkThreshold
faceClusteringProperties
faceClusteringThreshold
faceCount
faceCountInFaceGroup
faceCropData
faceCropDimensionsFromFaceCrop:error:
faceDetection:faces:cancel:
faceDetector
faceDetectorVisionRevision
faceDetectorWithTransform:withExistingFaceprints:frameStats:tracking:faceDominated:cancel:
faceDominated
faceFromFaceObservation:humanObservation:sourceWidth:sourceHeight:visionRequests:processingVersion:force:andError:
faceFromPHFace:copyOption:
faceHairCategory
faceID
faceId
faceJunkinessIndex
faceMergeFaceprintDistanceThreshold
faceObservationFromFaceprintData:
faceObservationWithRequestRevision:boundingBox:andAlignedBoundingBox:
faceProcessingContext
faceQuality
faceQualityScores
faceRanges
faceRectFromNormalizedCenterX:normalizedCenterY:normalizedSize:sourceWidth:sourceHeight:
faceResults
faceResultsAtIndex:
faceResultsCount
faceSharpness
faceWithLocalIdentifier:
faceprint
faceprintBlob
faceprintData
faceprintRequestRevision
faceprintRevisionForPersonModel:
faceprintVersion
faces
facesForClusteringWithLocalIdentifiers:faceprintVersion:groupingIdentifiers:
facesFromFaceObservations:humanObservations:animalObservations:sourceWidth:sourceHeight:visionRequests:blurScorePerFace:exposureScorePerFace:tooSmallFaceObservations:processingVersion:
facesFromPHFetchResult:copyOption:
facialHairType
failureScore
fastSignLanguageDetection:ofPixelBuffer:withMetadata:
favorite
fcBlockWithNumNeurons:NeuronType:
featureBlob
featureIdentifier
featureNames
featureProviderWithCVPixelBuffer:andFeatureName:
featureValueForName:
featureValueWithCGImage:pixelsWide:pixelsHigh:pixelFormatType:options:error:
featureValueWithImageAtURL:pixelsWide:pixelsHigh:pixelFormatType:options:error:
featureValueWithMultiArray:
featureValueWithPixelBuffer:
featuresAtIndex:
fetchAndComputeScoreForKeyFrame:withResult:
fetchAssetCollectionsWithLocalIdentifiers:options:
fetchAssetCollectionsWithType:subtype:options:
fetchAssetsForFaceGroups:options:
fetchAssetsForFaces:options:
fetchAssetsForPersons:options:
fetchAssetsGroupedByFaceUUIDForFaces:
fetchAssetsInAssetCollection:options:
fetchAssetsMatchingAdjustedFingerPrint:photoLibrary:
fetchAssetsMatchingMasterFingerPrint:photoLibrary:
fetchAssetsWithCloudIdentifiers:options:
fetchAssetsWithLocalIdentifiers:options:
fetchAssetsWithMediaType:options:
fetchAssetsWithOptions:
fetchAssociatedPersonsGroupedByFaceGroupLocalIdentifierForFaceGroups:options:
fetchEmptyFaceGroupsWithOptions:
fetchEntityForModelType:evaluationMode:allowUnverifiedPerson:
fetchFaceCropByFaceLocalIdentifierForFaces:fetchOptions:
fetchFaceCropsNeedingFaceDetectionWithOptions:
fetchFaceCropsWithLocalIdentifiers:options:
fetchFaceGroupsForPerson:options:
fetchFaceGroupsGroupedByFaceLocalIdentifierForFaces:options:
fetchFaceGroupsWithFace:options:
fetchFaceGroupsWithOptions:
fetchFaceWithClusterSequenceNumber:error:
fetchFaceWithLocalIdentifier:error:
fetchFaces
fetchFacesForFaceCrop:options:
fetchFacesForPerson:options:
fetchFacesGroupedByAssetLocalIdentifierForAssets:options:
fetchFacesInAsset:options:
fetchFacesInFaceGroup:options:
fetchFacesOnAssetWithFace:options:
fetchFacesWithLocalIdentifiers:options:
fetchFacesWithOptions:
fetchInvalidMergeCandidatePersonsForPerson:options:
fetchKeyFaceForFaceGroup:options:
fetchKeyFaceForPerson:options:
fetchMergeCandidatePersonsForPerson:options:
fetchMomentUUIDByAssetUUIDForAssets:options:
fetchMomentsForAssetsWithLocalIdentifiers:options:
fetchMomentsWithOptions:
fetchOptionsWithInclusiveDefaultsForPhotoLibrary:
fetchPersonAssociatedWithFaceGroup:options:
fetchPersonWithFace:options:
fetchPersonWithLocalIdentifier:options:error:
fetchPersonsForAssetCollection:options:
fetchPersonsGroupedByAssetLocalIdentifierForAssets:options:
fetchPersonsWithLocalIdentifiers:options:
fetchPersonsWithOptions:
fetchPropertySetsIfNeeded
fetchRejectedFacesForPerson:options:
fetchRejectedPersonsForFace:options:
fetchSceneClassificationsGroupedByAssetLocalIdentifierForAssets:
fetchedObjectIDs
fetchedObjects
fileExistsAtPath:
fileExistsAtPath:isDirectory:
fileSize
fileSystemRepresentation
fileURLWithPath:
fileURLWithPath:isDirectory:
filename
filterDescriptorWithWidth:height:arrayLength:kernelSpatialDiameter:kernelTemporalDiameter:epsilon:sourceChannels:guideChannels:preallocateIntermediates:
filterUsingPredicate:
filteredArrayUsingPredicate:
filteringPose:
finalizeAnalysis
finalizeAnalysisAtTime:
finalizeAnalysisPass:
finalizeKeyFrame
finalizeWithDestructiveTrimStart:trimEnd:
finalizeWithDestructiveTrimStart:trimEnd:andCaptureTime:
findBestHighlightSegment:targetTrim:
findBestTrim:
findMetaTrackforType:
findNextSample:timerange:
fingerprint
fingerprintHashes
finishAnalysisPass:
finishAnalysisPass:fpsRate:
finishAnalysisPass:withStillImageBuffer:
finishDecoding
finishEncoding
finishLoading
firstObject
fitOneImage:
flag
flags
flagsForOrientation:width:height:
flagsFromKeypoints:withMinConfidence:
flickerScore
flipTransform:
floatValue
flowScalingTo:flowBufferY:scalerX:scalerY:
flowScalingTo:scalerX:scalerY:
flush
flushCache
flushWithEndTime:error:
focalPoint
focusStatus
forcePersonDetection
formatDescriptions
forward:
frameExpressionScore
frameFaceResults
frameInstructions
frameInstructionsAtIndex:
frameInstructionsCount
frameInstructionsType
frameInterval
frameLength
frameProcessedByFaceDetector
frameProcessedByHumanAnalyzer
frameProcessedByPetsActionAnalyzer
frameProcessedByVideoAnalyzer
frameResults
frameScenes
freeModel
gatherAvailableRequests
gatingPayload
gatingResultItems
gaze
gazeCenterX
gazeCenterY
gazeMask
gazeType
generateActivityDescriptor
generateAndPersistFaceCropsForFaces:withAsset:resource:resourceURL:error:
generateCGImageAsynchronouslyForTime:completionHandler:
generateCaption:error:
generateClassificationScoresForPixelBuffer:error:
generateCurationSegment
generateDistanceDescriptor:withDescriptorClass:forAsset:withResources:lastFrame:
generateExpressionSegments:
generateFaceCropsForFace:resourceURL:groupingIdentifier:
generateHandKeypoints:keypointConfidence:offset:
generateHandsBoxes:
generateHandsRegions:boxes:maxNumRegions:
generateHighlights
generateHumanPose:
generateInterestingTrimBasedOnCaptureTime:
generateKeyFrameResource:
generateLineWeightMap:weightMap:
generateLivePhotoRecommendationForResults:andPrivateResults:usingFaceAction:
generateMotionFlow
generateMovieCurations
generateOrientationMap
generateOutput
generatePersonBoxes:
generatePersonRegions:boxes:maxNumRegions:
generatePetsBoxes:faceBoxes:cancel:
generatePetsRegions:outHeight:outWidth:boxes:faceBoxes:maxNumRegions:
generateSalientRegion:outHeight:outWidth:
generateSubleMotionScore:
generateThresholds:withConfidences:
generateVIPModelWithType:ignoreLastGenerationTime:evaluationMode:allowUnverifiedPerson:modelGenerated:extendTimeout:andCancel:
generateVNImageprintWithType:archiveData:andError:
geometry
gestureDetection:score:
getAllClustersAndReturnError:
getBytes:bytesPerRow:bytesPerImage:fromRegion:mipmapLevel:slice:
getBytes:length:
getCGRectWithClipWidth:height:
getClosestAspectRatio:
getClusters:threshold:utilizingGPU:cancelOrExtendTimeoutBlock:error:
getControlPoints
getDetectionScore:
getEnableMovieHumanAction
getEspressoContext
getEulerAngle:
getFaceClusters:clusteringThreshold:utilizingGPU:cancelOrExtendTimeoutBlock:error:
getFaceHeat:
getFaceScoreFromOutput:ratio:
getFirstAtomWithFourCharCode:fromSetupData:
getFlowToBuffer:
getFlowWithHeight:andWidth:
getGPUContext
getHumanActionClassiferType
getInputBuffer
getInputBuffer:srcWidth:cnnInputHeight:cnnInputWidth:
getInputBuffer:srcWidth:cnnInputHeight:cnnInputWidth:offset:
getInternal3dLandmarksCoordinates:lm3dPos:
getLocalUrl
getMaximumHighlightInSec
getMinimumHighlightInSec
getNextCaptureSampleBuffer
getObject
getOneInternalLandmarkCoordinates:lmCoord:lmWeight:lm3dPos:
getPlanPhase
getPoseParam
getResourceValue:forKey:error:
getRevision
getSalientRegions:
getSceneSwichFrequency
getSetupDataFrom:
getTranscript
gist
glassesType
globalMotion
globalQualityScore
globalSession
glyphName
gpsHorizontalAccuracy
gradientEstimation:width:height:gradient:gradientMag:
groupedClusterSequenceNumbersOfFacesInFaceGroupsOfMinimumSize:error:
groupingIdentifier
groupingIdentifierFromFaceCrop:error:
guidedUpsampling:inBGRA:
gyroHomographyVersionIsValid:
gyroStabilization
hadFlash
hairColorCategory
hairColorType
hairType
handDistance:withhandB:
handID
handleTimerEvent
handsDetection:handsRegions:cancel:
harmoniousColorScore
hasAction
hasAdjustments
hasAssetAdjustedFingerprint
hasBounds
hasCachedParseData
hasColorNormalizationBlob
hasDistanceToPreviousScene
hasEpoch
hasFaceId
hasFaceMask
hasFaceQuality
hasFaceSharpness
hasFlags
hasFlash
hasFocalPoint
hasGlobalQualityScore
hasGoodSubjectAction
hasKeyFrame
hasLoopFadeLen
hasLoopPeriod
hasLoopStart
hasMeaningfulSceneSegment:withFpsRate:
hasPrefix:
hasProcessedForLibrary:
hasQuality
hasRecipeBlob
hasSceneprintDistanceToPreviousScene
hasSlowMotionAdjustments
hasSmile
hasStatsFlags
hasTypesWide
hasUnderExpose
hasValidSceneProcessing
hasWifiOrEthernetConnection
hash
hashData
headgearType
height
hidden
highPrecisionThreshold
highRecallThreshold
highlightScore
highlightScoreForTimeRange:average:
highlightScoreResults
highlights
hintDomain
homographyParamAtIndex:
homographyParams
homographyParamsAtIndex:
homographyParamsCount
humanActionScore
humanPoseScore
humanScore
idealDimension
identifier
identifyConflictingL0Clusters:csnToRejectedPersonForNewlyClusteredFaces:csnToConfirmedPersonForNewlyClusteredFaces:
imageAnalysisFromLegacyDictionary:
imageAssetWithURL:
imageBlurResults
imageBlurResultsAtIndex:
imageBlurResultsCount
imageBlurResultsType
imageBufferValue
imageCaptionModelTestURL
imageCompositionResults
imageCompositionResultsCount
imageCompositionResultsType
imageCreationOptions
imageExposureResults
imageExposureResultsAtIndex:
imageExposureResultsCount
imageExposureResultsType
imageFaceResults
imageFaceResultsAtIndex:
imageFaceResultsCount
imageFaceResultsType
imageFeatureResults
imageFeatureResultsAtIndex:
imageFeatureResultsCount
imageFeatureResultsType
imageForResource:pixelFormat:
imageForResource:pixelFormat:maxDimension:
imageForResource:pixelFormat:maxDimension:orientation:
imageHumanPoseResults
imageHumanPoseResultsAtIndex:
imageHumanPoseResultsCount
imageHumanPoseResultsType
imageJunkResults
imageJunkResultsAtIndex:
imageJunkResultsCount
imageJunkResultsType
imageManager
imageNeuralHashprint
imagePetsFaceResults
imagePetsFaceResultsAtIndex:
imagePetsFaceResultsCount
imagePetsFaceResultsType
imagePetsResults
imagePetsResultsAtIndex:
imagePetsResultsCount
imagePetsResultsType
imageRegions
imageSaliencyResults
imageSaliencyResultsAtIndex:
imageSaliencyResultsCount
imageSaliencyResultsType
imageSceneprintResults
imageSceneprintResultsAtIndex:
imageSceneprintResultsCount
imageSceneprintResultsType
imageShotTypeResults
imageShotTypeResultsAtIndex:
imageShotTypeResultsCount
imageShotTypeResultsType
imageSignatureHash
imageType
imageURL
imageWithPixelBuffer:orientation:
imageWithPreferredDimension:
imageWithPreferredDimension:orientation:
imagefingerprintsRequest
imageprint
imageprintWrapper
immersivenessScore
inactiveCost
includeCN
includeDMF
includeDO
includeIVS
includeJunk
includeLM
includeMeme
includeNSFW
includePA
includeSDG
includeSE
includeSO
includeWP
increaseLengthBy:
indexOfObject:inSortedRange:options:usingComparator:
indexSetWithIndexesInRange:
indexesOfObjectsPassingTest:
inference:
inference:duration:
init
init:sharedModel:modelName:
initForReadingFromData:error:
initFromConfigFile:numStage:numLandmarks:numTreePerStage:depthOfTree:numFeatures:
initImageTransform:transformedImageWidth:transformedImageHeight:
initModelWithName:andConfig:
initModule:config:cancel:
initRequiringSecureCoding:
initStandardFormatWithSampleRate:channels:
initWith:confidence:
initWithAVAsset:forAnalysisTypes:
initWithAbsMotion:atTime:
initWithAllocator:
initWithAnalysisResults:
initWithAnalysisType:isLivePhoto:photoOffset:hadFlash:hadZoom:isTimelapse:preferredTimeRange:asset:
initWithAnalysisTypes:forStreaming:
initWithAnalysisTypes:transform:timeRange:isLivePhoto:photoOffset:frameStats:hadFlash:hadZoom:keyFrameResults:isTimelapse:preferredTimeRange:asset:
initWithAnalysisTypes:withPreferredTransform:withFocalLengthInPixels:withAnalysisQueue:withTurbo:
initWithAngle:
initWithAnnotations:revision:
initWithAsset:error:
initWithAssets:analysisTypes:options:progressHandler:andCompletionHandler:
initWithAssets:andOptions:andCompletionHandler:
initWithAssets:options:andCompletionHandler:
initWithBase64EncodedString:options:
initWithBufferWidth:bufferHeight:andPixelFormat:
initWithBytesNoCopy:length:deallocator:
initWithCGImage:options:session:
initWithCMSampleBuffer:orientation:options:
initWithCVPixelBuffer:andFeatureName:
initWithCVPixelBuffer:options:
initWithCVPixelBuffer:options:session:
initWithCVPixelBuffer:orientation:options:session:
initWithCapacity:
initWithCenterAndSize:y:width:height:confidence:
initWithClassifierIdentifier:error:
initWithClientBundleID:andClientTeamID:
initWithCloudIdentifierRequests:photoLibrary:clientBundleID:clientTeamID:cancelBlock:andCompletionHandler:
initWithCoder:
initWithCommonFormat:sampleRate:channels:interleaved:
initWithCompletionHandler:
initWithConfiguration:
initWithConfiguration:error:
initWithContentsOfFile:
initWithContentsOfURL:
initWithContentsOfURL:configuration:error:
initWithContentsOfURL:error:
initWithContext:
initWithData:
initWithData:encoding:
initWithData:options:
initWithData:orientation:options:
initWithDatabaseReader:forAssets:resultsTypes:batchSize:
initWithDevice:filterDescriptor:
initWithDictionary:
initWithDomain:knowledgeGraphID:title:thumbnailURL:thumbnailAspectRatio:shortDescription:detailedDescription:webURL:knowledgeProperties:
initWithDomain:label:glyphName:hasFocalPoint:focalPoint:displayLabel:displayMessage:
initWithEdgeMap:mapWidth:mapHeight:angleStep:
initWithFace:andFace:distance:
initWithFaceAnnotations:humanAnnotations:nsfwAnnotations:textBlockAnnotation:scenenetAnnotation:barcodeAnnotation:
initWithFaceClusterIds:clusterFlags:updateHandler:
initWithFaceCrop:andCompletionHandler:
initWithFaceCropData:originatingFace:
initWithFaceObservations:
initWithFaceResults:
initWithFaceResults:sdof:
initWithFaceResults:sdof:revision:
initWithFaceprint:torsoprint:
initWithFaceprintData:faceprintVersion:
initWithFeatureProviderArray:
initWithFilterTabs:distanceVariance:diffVariance:
initWithFlagHasFaceOrPet:
initWithFocalLengthInPixels:
initWithFocalLengthInPixels:offline:isFastMode:
initWithFocalLengthInPixels:principalPoint:cameraTowardsPositiveZ:
initWithFocusStatus:atTime:
initWithForceCPU:forceNNGraph:shared:
initWithForceCPU:sharedModel:
initWithFrameRate:timeRange:
initWithFrameStats:
initWithFrameStats:timeOfInterest:
initWithFrameStats:timeOfInterest:phFaces:
initWithFrameWidthInMb:heightInMb:
initWithGPUContext:
initWithIdentifier:error:
initWithImage:
initWithImage:annotation:normalizedRegionOfInterest:domainsOfInterest:queryContext:
initWithImage:edgeMap:width:height:widthExtension:heightExtension:
initWithImage:regionOfInterest:imageType:preferredMetalDevice:
initWithImage:userFeedbackPayload:sfReportData:reportIdentifier:
initWithImageAsset:requestHandler:regionOfInterest:
initWithImageData:uniformTypeIdentifier:identifier:clientBundleID:clientTeamID:
initWithImageLoader:imageSize:
initWithImageSignatureprintType:imageSignatureHashType:
initWithImageURL:andMovieURL:
initWithImageURL:isSDOF:
initWithImageprintType:version:andData:
initWithIndexesInRange:
initWithInputImage:
initWithInputImageAtURL:error:
initWithInputImageFromCGImage:error:
initWithIntervalNanoseconds:isOneShot:andBlock:
initWithIsSensitive:andAttributes:
initWithKeypointsOption:aspectRatio:lightweight:forceCPU:sharedModel:flushModel:
initWithKeypointsOption:forceCPU:sharedModel:aspectRatio:modelName:revision:
initWithLabel:normalizedBoundingBox:confidence:
initWithLightweightOption:aspectRatio:computationAccuracy:forceCPU:sharedModel:flushModel:cancel:
initWithLivePhoto:
initWithLocalIdentifier:
initWithLocalIdentifier:andTaskID:andStatus:andAttempts:andLastRetryDate:
initWithLocalIdentifier:faceCropData:
initWithLocaleIdentifier:
initWithMLModel:
initWithMachServiceName:options:
initWithMaster:adjusted:
initWithMaxNumRegions:
initWithMaxNumRegions:forceCPU:sharedModel:
initWithMaxNumRegions:forceCPU:sharedModel:inputConfig:
initWithMaxNumRegions:forceCPU:sharedModel:inputConfig:revision:
initWithMaxNumRegions:prune:
initWithMetadata:sourceSize:cropRect:
initWithMode:
initWithModelFile:
initWithModelFile:paramFile:numTri:triList:angle:
initWithModelName:
initWithModelPath:
initWithMonochromeBufferCreator:
initWithMovieURL:
initWithMovingObjectsResults:
initWithNormalizedBoundingBox:andDomains:
initWithNormalizedBoundingBox:regionAttributes:andSearchSections:
initWithNumberOfScales:numOfOrientations:width:height:
initWithObject:fromPool:
initWithObjectBounds:inFrame:timestamp:
initWithObjectIdentifier:imageURL:thumbnailURL:metadata:
initWithObservations:
initWithOptions:
initWithOptions:andCompletionHandler:
initWithOptions:andExistingResults:
initWithOptions:cancel:
initWithOptions:error:
initWithPCMFormat:frameCapacity:
initWithPHAsset:
initWithPHAsset:withExistingAnalysis:forAnalysisTypes:
initWithPHAsset:withPausedAnalysis:forAnalysisTypes:
initWithPHFaces:
initWithPHFaces:existingResults:
initWithParameters:
initWithParameters:NeuronType:
initWithParameters:filterNum:chunk:reLU:padding:groups:stride:batchNorm:
initWithParameters:height:width:context:
initWithParameters:inputNames:outputNames:properties:
initWithParameters:useGPU:
initWithPerson:andPerson:reason:
initWithPersonIdentifier:personName:boundingBox:andConfidence:
initWithPhotoLibrary:
initWithPhotoLibrary:andContext:
initWithPhotoLibrary:andDelegate:
initWithPhotoLibrary:andFaceClusterer:andContext:
initWithPhotoLibrary:context:cancelOrExtendTimeoutBlock:
initWithPhotoLibraryURL:
initWithPhotosAsset:clientBundleID:clientTeamID:
initWithPhotosAsset:pixelBuffer:orientation:clientBundleID:clientTeamID:
initWithPixelBuffer:
initWithPixelBuffer:orientation:andIdentifier:clientBundleID:clientTeamID:
initWithPixelFormat:
initWithPlistRepresentation:
initWithPostProcessOptions:
initWithProperties:forAnalysisTypes:
initWithProperties:withResultsHandler:andInterruptionHandler:
initWithQueryTerm:hintDomain:textContext:imageContext:annotation:queryContext:
initWithQueue:turbo:
initWithRegionOfInterest:domains:
initWithRequest:andConfiguration:
initWithRequest:imageAsset:andSignpostPayload:
initWithRequestAnalyses:formatDescription:
initWithRequests:forAsset:cancelBlock:andCompletionHandler:
initWithResource:
initWithResourceManager:andResource:
initWithResultItems:
initWithResultItems:andUserFeedbackPayload:
initWithRevision:
initWithSampleBuffer:
initWithSceneId:withDuration:withConfidence:
initWithSearchSections:
initWithSoundIdentifier:
initWithState:error:
initWithSurface:cropRect:confidence:
initWithSurroundingText:normalizedBoundingBoxes:
initWithThreshold:
initWithTime:andScore:
initWithTimeOfInteret:frameRate:isLivePhoto:phFaces:timeRange:requestedAnalyses:
initWithTimeRange:
initWithTimeRange:score:andKeyFrame:
initWithTimerange:andScore:
initWithTimestamp:score:valid:
initWithTimestamps:andTrack:
initWithTrack:
initWithTrack:timerange:
initWithTrack:timerange:atInterval:
initWithTrack:timerange:withSettings:applyTransform:
initWithTrackStart:threshold:resultsKey:
initWithTransform:
initWithTransform:blendShapes:geometry:
initWithTransform:frameStats:faceDominated:
initWithTransform:timeRange:isLivePhoto:frameStats:keyFrameResults:
initWithTransform:withExistingFaceprints:frameStats:
initWithType:
initWithType:cachePath:state:threshold:requestRevision:
initWithType:cachePath:state:threshold:torsoThreshold:requestRevision:torsoprintRequestRevision:
initWithTypes:
initWithURL:
initWithURL:identifier:clientBundleID:clientTeamID:
initWithURL:options:
initWithURLAsset:withOptions:analysisTypes:progressHandler:completionHandler:
initWithUUIDBytes:
initWithUUIDString:
initWithVCPAsset:withExistingAnalysis:forAnalysisTypes:
initWithVertices:vertexCount:
initWithVideoAsset:videoAdjustments:
initWithVideoTrack:withMetaOrientation:withPrivateResults:withFrameStats:isTimelapse:isIris:irisPhotoOffsetSec:irisPhotoExposureSec:slowMoRate:faceDominated:
initWithWidth:height:
initWithXYAndSize:y:width:height:confidence:
input
inputBlob
inputBlobs
inputBoundsHeight
inputBoundsWidth
inputBoundsX
inputBoundsY
inputDescriptionsByName
inputFaceObservations
inputFeatureName
inputImage
inputPixelFormat
inputSize
insertObject:atIndex:
insertTimeRange:ofAsset:atTime:error:
instancesRespondToSelector:
intValue
integerValue
interestScore
interestingSubjectScore
interestingnessScore
interfaceWithProtocol:
internalPredicate
interrupt
intersect:
intersectSet:
intersectionOverUnion:rect:
intersectsSet:
intrusiveObjectPresenceScore
invalidFaceClusterSequenceNumbersInClusterSequenceNumbers:cancelOrExtendTimeoutBlock:error:
invalidFaceClusterSequenceNumbersInClusterSequenceNumbers:canceler:error:
invalidate
isActive:
isAnalysisResultNeeded:
isAssetBlacklisted:blacklistDate:
isAutoPlayable
isCanceled
isCloseup
isCloudPhotoLibraryEnabled
isCoarse
isConfirmedFaceCropGenerationPending
isContentTooShort
isCurated:
isDimensionUnknown:
isDuplicate:withRect:
isEnabled
isEqual:
isEqualToDate:
isEqualToFingerprint:
isEqualToNumber:
isEqualToString:
isExceedingQuota
isFast
isFilterSizeSupported:
isGoodQuality:
isGuestAsset
isHDR
isHeadingFrame
isHidden
isHighResDecoded
isHomePod
isIdentityInit
isInImage:width:height:
isInTrash
isInVIPModel
isInputOutput
isKindOfClass:
isLivePhoto
isLivePhotoKeyFrameEnabled
isLocallyAvailable
isMLHighlightEnabled
isMemberOfClass:
isMovieResourceLocalAvailable
isMultiLibraryModeEnabled
isOutOfBoundary:
isPano
isReadyToReturnSuggestions
isRightEyeClosed
isSDOF
isScoreValid:
isScreenshot
isSegmentPoint
isSensitive
isSettlingEffectPregatingEnabled
isSettlingOK
isSlowmo
isStableMetaMotion:
isSystemPhotoLibrary
isTimelapse
isTimestampSkipable:
isTooSmall
isTracked
isTrimmed
isValidFaceCrop:
isValidFaceprint
isValidTorsoprint
isVerified
isVerticalOrHorizontal:
items
iteratorForAssets:withDatabaseReader:resultTypes:batchSize:
junkImageRequest
junkScore
junkScoreForTimerange:lengthScale:
kalmanFiltering:T:
keyEnumerator
keyFaceForPerson:qualityMeasureByFace:updateBlock:
keyFrame
keyFrameScores
keyFrames
keypoints
keypointsAtIndex:
keypointsCount
keypointsFromObservations:
keypointsFromTensor:width:height:channels:withOptions:results:
keypointsFromTensor:withOptions:results:
keypointsToObservation:
keypointsType
knowledgeGraphID
knowledgeProperties
l1ClusteredFaceIdsGroupedByL0ClustersForClustersContainingFaceIds:error:
label
labelName
labels
landmarks
languages
last
lastCompletePrefetchDate
lastObject
lastPathComponent
lastRetryDate
lastSuccessfulSyncDate
latestTaxonomyIdentifier
leftEyeClosed
length
level0ClusterAsFaceCSNsByLevel0KeyFaceCSNForClusterIdentifiedByFaceCSN:error:
librarySpecificFetchOptions
lineFromPoint:toPoint:
livePhotoAssetWithImageURL:andMovieURL:
livePhotoEffectsResults
livePhotoEffectsResultsCount
livePhotoEffectsResultsType
livePhotoHumanActionClassificationResults
livePhotoHumanActionClassificationResultsAtIndex:
livePhotoHumanActionClassificationResultsCount
livePhotoHumanActionClassificationResultsType
livePhotoKeyFrameResults
livePhotoKeyFrameResultsAtIndex:
livePhotoKeyFrameResultsCount
livePhotoKeyFrameResultsType
livePhotoKeyFrameStillResults
livePhotoKeyFrameStillResultsAtIndex:
livePhotoKeyFrameStillResultsCount
livePhotoKeyFrameStillResultsType
livePhotoRecommendationResults
livePhotoRecommendationResultsAtIndex:
livePhotoRecommendationResultsCount
livePhotoRecommendationResultsType
livePhotoSharpnessResults
livePhotoSharpnessResultsAtIndex:
livePhotoSharpnessResultsCount
livePhotoSharpnessResultsType
livelyColorScore
loadAnalysisResults:
loadAnalysisResults:audioResults:
loadAnalysisResultsFrom:actionAnalyzer:atTime:
loadContentsOfURL:configuration:completionHandler:
loadFullPixelBuffer:scaledPixelBuffer299:scaledPixelBuffer360:fromImageURL:abnormalDimension:
loadHighResPixelBuffer:orientation:
loadHighlightScoreResults:
loadImageURL:abnormalDimension:withNonPanoPreWarmSizes:toColorPixelBuffer:lumaPixelBuffer:andImage:
loadKeyFrameResult:timestamp:
loadKeyFrameResults:
loadModel
loadModel:
loadPersonModelAtPath:error:
loadPersonsModelAndInitializeFaceAnalyzerWrapper
loadPixelBuffer:orientation:
loadPropertiesForAsset:
loadVIPModelAtPath:withVIPType:error:
loadValuesAsynchronouslyForKeys:completionHandler:
loadVideoAnalysisResults:audioAnalysisResults:videoCNNResults:andFaceRanges:frameSize:
loadWeights:inputDim:outputDim:quantFactor:
loadWithConfiguration:completionHandler:
localIdentifierWithUUID:
localizedDescription
localizedStringFromDate:dateStyle:timeStyle:
location
locationChange:relativeTo:landscape:
locationCoordinate
lock
logLevel
logMemoryWithMessage:
loggingEnabled
longExposureSuggestionState
longLongValue
longValue
longexposure
loopFadeLen
loopPeriod
loopStart
loopSuggestionState
lostCount
lostTrack
lostTrackInd
lowKeyLightingScore
machineReadableCodeData
machineReadableCodeElements
mad_PHFaceGazeTypeDescription:
mad_PHValueFromVNAgeCategoryLabel:
mad_PHValueFromVNEthnicityCategoryLabel:
mad_PHValueFromVNExpressionCategoryLabel:
mad_PHValueFromVNEyesCategoryLabel:
mad_PHValueFromVNFaceGazeDirection:
mad_PHValueFromVNFaceHairCategoryLabel:
mad_PHValueFromVNFaceHairCategoryV2Label:
mad_PHValueFromVNGlassesCategoryLabel:
mad_PHValueFromVNHairColorCategoryLabel:
mad_PHValueFromVNHeadgearCategoryLabel:
mad_PHValueFromVNPoseCategoryLabel:
mad_PHValueFromVNSexCategoryLabel:
mad_PHValueFromVNSkintoneCategoryLabel:
mad_PHValueFromVNSmilingCategoryLabel:
mad_VNFaceGazeDirectionDescription:
mad_countOfUnclusteredFaces
mad_defaultRequest
mad_internalPredicateNeedsProcessingForTaskID:
mad_internalPredicateWithPriority:forTaskID:
mad_isExpectedTaxonomy
mad_nonPrioritizedAssetsForFaceDetectionInternalPredicate
mad_prioritizedAssetsForFaceDetectionInternalPredicate
mad_sceneIdFromSceneName:
mad_sceneNameFromSceneId:
mad_unclusteredFacesFetchOptions
main
mainFileURL
makeValidationDecision
manual
manualOrder
mapAvailableRequestsToResolution
mapToCameraNegativeZ
marketingName
maskOnly
master
matchesImageAsset:
maxFaceCountForClustering
maxHighlightDuration
maxSizeBytes
maxTrimMovieHighlight:
maxX
maxY
maximumAspectRatio
maximumCandidateCount
maximumFaceCount
maximumLeafObservations
maximumObservations
meanBlendshape
mediaAnalysisProperties
mediaSubtypes
mediaType
memeRequest
mergeCandidatePairWithPerson:andPerson:reason:
mergeConsecutiveShortSegments
mergeExistingFaces:andDetectedFaces:withRequestHandler:orientedWidth:orientedHeight:assetWidth:assetHeight:
mergeFrom:
mergeSameTypeSegments
mergeSegment:
mergeSimilarSegments
mergeSparseShortSegments
meshVertices
metadata
metadataForFormat:
metadataItemsFromArray:filteredByIdentifier:
metadataItemsFromArray:withKey:keySpace:
minProcessTimeIntervalInSecs
minVersion
minX
minY
minimumAspectRatio
minimumConfidence
minimumFaceGroupSizeForCreatingMergeCandidates
minimumSize
minimumSuggestionSize
minimumUnverifiedFaceCount
minimumVerifiedFaceCount
minusSet:
mode
model
modelDescription
modelFromURL:options:error:
modelURLForType:timeout:
modelWithConfiguration:error:
modelWithContentsOfURL:configuration:error:
modelWithContentsOfURL:error:
modificationDate
modulateByExposure
modulateByJunk
modulateByTimeRange
momentSortDescriptors
motionBlurVector
motionDivScore
motionParam
motionScore
motionType
moveBoundaryLandmarks:output:isInput:
movie
movieActivityLevelResults
movieActivityLevelResultsAtIndex:
movieActivityLevelResultsCount
movieActivityLevelResultsType
movieAnalysisFromLegacyDictionary:
movieApplauseResults
movieApplauseResultsAtIndex:
movieApplauseResultsCount
movieApplauseResultsType
movieAssetWithURL:
movieAudioQualityResults
movieAudioQualityResultsAtIndex:
movieAudioQualityResultsCount
movieAudioQualityResultsType
movieBabbleResults
movieBabbleResultsAtIndex:
movieBabbleResultsCount
movieBabbleResultsType
movieCameraMotionResults
movieCameraMotionResultsAtIndex:
movieCameraMotionResultsCount
movieCameraMotionResultsType
movieCheeringResults
movieCheeringResultsAtIndex:
movieCheeringResultsCount
movieCheeringResultsType
movieClassificationResults
movieClassificationResultsAtIndex:
movieClassificationResultsType
movieFaceResults
movieFaceResultsAtIndex:
movieFaceResultsCount
movieFaceResultsType
movieFaceprintResults
movieFaceprintResultsAtIndex:
movieFaceprintResultsCount
movieFaceprintResultsType
movieFeatureResults
movieFeatureResultsAtIndex:
movieFeatureResultsCount
movieFeatureResultsType
movieFineSubjectMotionResults
movieFineSubjectMotionResultsAtIndex:
movieFineSubjectMotionResultsCount
movieFineSubjectMotionResultsType
movieHighlightResults
movieHighlightResultsAtIndex:
movieHighlightResultsCount
movieHighlightResultsType
movieHighlightScoreResults
movieHighlightScoreResultsAtIndex:
movieHighlightScoreResultsType
movieHumanActionResults
movieHumanActionResultsCount
movieHumanActionResultsType
movieHumanPoseResults
movieHumanPoseResultsAtIndex:
movieHumanPoseResultsCount
movieHumanPoseResultsType
movieInterestingnessResults
movieInterestingnessResultsAtIndex:
movieInterestingnessResultsCount
movieLaughterResults
movieLaughterResultsAtIndex:
movieLaughterResultsCount
movieLaughterResultsType
movieLoudnessResults
movieLoudnessResultsAtIndex:
movieLoudnessResultsCount
movieLoudnessResultsType
movieMovingObjectResults
movieMovingObjectResultsAtIndex:
movieMovingObjectResultsCount
movieMovingObjectResultsType
movieMusicResults
movieMusicResultsAtIndex:
movieMusicResultsCount
movieMusicResultsType
movieObstructionResults
movieObstructionResultsCount
movieObstructionResultsType
movieOrientationResults
movieOrientationResultsCount
movieOrientationResultsType
moviePetsFaceResults
moviePetsFaceResultsAtIndex:
moviePetsFaceResultsCount
moviePetsFaceResultsType
moviePetsResults
moviePetsResultsAtIndex:
moviePetsResultsCount
moviePetsResultsType
moviePreEncodeResults
moviePreEncodeResultsAtIndex:
moviePreEncodeResultsCount
moviePreEncodeResultsType
movieQualityResults
movieQualityResultsAtIndex:
movieQualityResultsCount
movieQualityResultsType
movieSaliencyResults
movieSaliencyResultsAtIndex:
movieSaliencyResultsCount
movieSaliencyResultsType
movieSceneResults
movieSceneResultsAtIndex:
movieSceneResultsCount
movieSceneResultsType
movieSceneprintResults
movieSceneprintResultsAtIndex:
movieSceneprintResultsCount
movieSceneprintResultsType
movieStabilizationResults
movieStabilizationResultsAtIndex:
movieStabilizationResultsCount
movieStabilizationResultsType
movieSubjectMotionResults
movieSubjectMotionResultsAtIndex:
movieSubjectMotionResultsCount
movieSubjectMotionResultsType
movieSubtleMotionResults
movieSubtleMotionResultsAtIndex:
movieSubtleMotionResultsCount
movieSubtleMotionResultsType
movieSummary
movieSummaryResults
movieSummaryResultsAtIndex:
movieSummaryResultsCount
movieSummaryResultsType
movieUtteranceResults
movieUtteranceResultsAtIndex:
movieUtteranceResultsCount
movieUtteranceResultsType
movieVoiceResults
movieVoiceResultsAtIndex:
movieVoiceResultsCount
movieVoiceResultsType
multiLevelSocialGroupsWithPersonClusterManager:forPersons:updateBlock:
mutableAudioBufferList
mutableBytes
mutableCopy
name
nameSource
narrowedBoundingBox
naturalSize
needsFullSync
needsPersonBuilding
needsUpdate
newAllFacesFetchOptionsWithPhotoLibrary:
newAllPersonsFetchOptionsWithPhotoLibrary:
newAllPersonsWithAtLeastOneFaceFetchOptionsWithPhotoLibrary:
newAssetFetchOptionsWithPhotoLibrary:
newBufferWithIOSurface:
newBufferWithLength:options:
newComputePipelineStateWithFunction:error:
newConfigurationForEntityPrintsGeneratedByRequest:error:
newDefaultLibraryWithBundle:error:
newDictionaryPopulatedWithFaceCropDataFromImageData:
newDictionaryRepresentationOfFaceCropDataFromFaceBox:andCropRegion:andGroupingIdentifier:
newFaceCropFromCGImageSource:withFaceRect:groupingIdentifier:error:
newFaceCropFromImageURL:withNormalizedFaceRect:groupingIdentifier:error:
newFacesDeterministicSortDescriptors
newFunctionWithName:
newLinearTextureWithDescriptor:offset:bytesPerRow:bytesPerImage:
newMutablePersonsModel
newTextureWithDescriptor:
newTextureWithDescriptor:iosurface:plane:
newVerifiedPersonsFetchOptionsWithPhotoLibrary:
newVerifiedPersonsWithAtLeastOneFaceFetchOptionsWithPhotoLibrary:
newVisibleFacesFetchOptionsWithPhotoLibrary:
next
nextBatch
nextObject
nextTimedMetadataGroup
nodeForName:
nodeForSceneClassId:
nodeWithRequest:andConfiguration:
noiseReduction:sigma:imageFiltered:
noiseScore
nominalFrameRate
nonGroupedGroupID
nonMaxSuppression:
normDistance:point2:
normalization
normalization:
normalizeActivityDescriptor
normalizedBoundingBox
normalizedBoundingBoxes
normalizedFaceRect
normalizedRectForRect:inBoundsOfSize:
notifyLibraryAvailableAtURL:
nsfwClassifications
nsfwRequest
null
numOfFrames
numOfValidFrames
numSingletons
numValidSingletons
numVertices
numberFromString:
numberOfAccumulatedClusterChanges
numberOfFacesPendingClustering
numberValue
numberWithDouble:
numberWithFloat:
numberWithInt:
numberWithInteger:
numberWithLongLong:
numberWithShort:
numberWithUnsignedChar:
numberWithUnsignedInt:
numberWithUnsignedInteger:
numberWithUnsignedLong:
numberWithUnsignedLongLong:
object
objectAtIndex:
objectAtIndexedSubscript:
objectBounds
objectBoundsInitial
objectEnumerator
objectForKey:
objectForKeyedSubscript:
objectID
objectIdentifier
objectPoolWithAllocator:
objectRequest
objectsAtIndexes:
objectsMotion
observation
observationWithBoundingBox:
observationWithRequestRevision:boundingBox:
obstructionScore
ontologyNode
openAndWaitWithUpgrade:error:
openDatabase
optInPerson:error:extendTimeoutBlock:cancelBlock:
optInPersonCount
optInStatus:error:
optimizeBetas:R6x1:betas:
optimizeProjectionMatrix:tracking:firstPass:
orPredicateWithSubpredicates:
orientation
originalFilename
originalMovie
originalMovieSize
originalPhotoOffsetSeconds
originalTimeForScaledTime:
otherFacesOnAssetWithFace:options:
output
outputBeforeFc
outputBeforeSpatiialPooling
outputBeforeTemporalPooling
outputBlob
outputBlobs
outputDescriptionsByName
outputFeatureName
outputFrameDurValue
outputRes4
outputScaling
outputSize
overallFaceQualityScore
pairWithFace:andFace:distance:
parseFlowCacheVersion
parseHeader:startColumn:analysis:
parseHeatmap2Keypoints:
parsePersons:width:height:
parseResults:observations:
parseResults:toDetections:atTime:fromTime:addActiveRegions:
parseResults:typeColumn:dataColumn:results:
parseWithVisualQuery:cachedResults:completion:
path
pathExtension
pathForResource:ofType:
peak
penaltyScore
performCancellableChangesAndWait:error:
performChanges:completionHandler:
performChangesAndWait:error:
performInPlace
performMetadataAnalysisOnAsset:withCancelBlock:
performPersonBuildingWithCancelOrExtendTimeoutBlock:error:
performRequests:error:
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
performSocialGroupsIdentifiersWithPersonClusterManager:forPersons:overTheYearsComputation:updateBlock:
persistChangesToAlgorithmicFaceGroups:faceCSNByLocalIdentifierForNewlyClusteredFaces:faceCSNsOfUnclusteredFaces:localIdentifiersOfUnclusteredFaces:persistenceCompletionBlock:canceler:error:
persistChangesToAlgorithmicFaceGroups:l1ClustersByFaceCSNRepresentingFaceGroup:l0ClustersByFaceCSNRepresentingFaceGroup:faceCSNByLocalIdentifierForNewlyClusteredFaces:faceCSNsOfUnclusteredFaces:localIdentifiersOfUnclusteredFaces:persistenceCompletionBlock:cancelOrExtendTimeoutBlock:error:
persistFaces:deleteFaces:forAsset:persistedFaces:error:
persistGeneratedFaceCrops:error:
persistModel:toPath:error:
persistOCRMRC
persistPetsModel:toPath:error:
persistenceDelegate_enumerateInChunksOfSize:withOverageAllowance:usingBlock:
persistentDomainForName:
person1LocalIdentifier
person2LocalIdentifier
personBuilderMergeCandidatesDisabled
personBuildingDisabled
personDetection:personRegions:cancel:
personID
personIdentificationForSyndicationPhotoLibrary:withCancelOrExtendTimeoutBlock:
personIdentityModel
personLocalIdentifier
personLocalIdentifiers
personModelFilepathForPhotoLibrary:
personPromoterStatusWithContext:reply:
personVIPModelFileName
petClassificationThreshold
petVIPModelFileName
petsDetection:petsRegions:petsFaceRegions:cancel:
petsDetections
phFaceFromVCPPhotosFace:withFetchOptions:
phFacesFromVCPPhotosFaces:withFetchOptions:
photoIrisProperties
photoIrisStillDisplayTime
photoLibrary
photoLibraryDidBecomeUnavailable:
photoOffsetSeconds
photosFaceRepresentationBlurScore
photosFaceRepresentationClusterSequenceNumber
photosFaceRepresentationHasSmile
photosFaceRepresentationIsLeftEyeClosed
photosFaceRepresentationIsRightEyeClosed
photosFaceRepresentationLocalIdentifier
photosFaceRepresentationQualityMeasure
photosFaceRepresentationRoll
photosFaceRepresentationSize
photosFaceRepresentationSourceHeight
photosFaceRepresentationSourceWidth
pickHighlightsFrom:
pickKeyFramesInRange:
pixelBuffer
pixelBuffer:width:height:
pixelBufferWithFormat:andMaxDimension:fromData:withUniformTypeIdentifier:flushCache:orientation:
pixelBufferWithFormat:andMaxDimension:fromImageURL:
pixelBufferWithFormat:andMaxDimension:fromImageURL:flushCache:orientation:
pixelBufferWithFormat:fromImageURL:flushCache:
pixelBufferWithFormat:fromImageURL:flushCache:orientation:
pixelHeight
pixelWidth
pixelsHigh
pixelsWide
placeholderForCreatedFace
placeholderForCreatedFaceGroup
planDestroy
playbackCrop
pleasantCameraTiltScore
pleasantCompositionScore
pleasantLightingScore
pleasantPatternScore
pleasantPerspectiveScore
pleasantPostProcessingScore
pleasantReflectionsScore
pleasantSymmetryScore
plistRepresentation
pointFromNormalizedPoint:inBounds:
pointValue
poolingBlockWithPoolX:poolY:chunk:
pose
poseType
position
postProcBoxes:maxNumRegions:
postProcess
postProcessAutoPlayable:
postProcessKeyFrames
postProcessMLHighlightScore
postProcessMovieHighlight:
postProcessMovieHighlightDuration:withOptions:
postProcessOrientationResults
postProcessSegmentsWithCaptureTime:trimStart:
preProcessQualityResults:interestingnessResults:obstructionResults:classificationResults:fineActionResults:faceResults:sceneSwitchFrequency:
preProcessing:
preWarmWidth:andHeight:
precisionPerCluster
predicate
predicateWithBlock:
predicateWithFormat:
predictPersonFromFaceObservation:limit:canceller:error:
predictionFromFeatures:error:
predictionFromFeatures:options:error:
predictionsFromBatch:options:error:
predictionsFromInputs:options:error:
preferredInputFormat:height:format:
preferredInputSizeWithOptions:error:
preferredLanguages
preferredPixelFormat
preferredResourcesForFaceProcessingWithAsset:
preferredTransform
prepareActivityStats
prepareAnalyzerWithCVPixelBuffer:cancel:
prepareData:
prepareFaceBlurModel:
prepareFrameStats:
prepareImage:
prepareLivePhotoAnalysisByScenes:
prepareModel
prepareModelForSourceWidth:andSourceHeight:
prepareModelInput:
prepareModelInputs:
prepareModelWithConfig:
prepareModelWithFile:engine:config:error:
prepareNetworkFromURL:withInputSize:
preparePostProcessingStatsFromFaceRange:junkResults:
prepareRequiredQualityResult:junkDetectionResult:descriptorResult:faceResult:petsResult:saliencyResult:actionResult:subtleMotionResult:voiceResult:keyFrameResult:sceneResults:humanActionResults:humanPoseResults:cameraMotionResults:orientationResults:mlHighlightScoreResults:mlQualityResults:frameSize:
prepareTrimmingWithTrimStart:andTrimEnd:
prepareVideoAnalysisByScenes:
prepareWithLightweightOption:aspectRatio:forceCPU:sharedModel:flushModel:
prepareWithLightweightOption:aspectRatio:numLevels:startLevel:cancel:
prewarmWithProperties:
prewarmWithWidth:height:
printSegments:
printStats
priorityAnalysis
privateFileURL
privateResults
process:
processAborted
processAsset:
processAsset:onDemandDetection:detectedFaces:detectedPersons:
processAudioSamples:timestamp:
processDirtyFaceCrops:withCancelBlock:andExtendTimeoutBlock:
processExistingAnalyses:
processExistingAnalysisForTimeRange:analysisTypes:
processFrame:withOptions:results:
processFrameMetadata:
processFrameScore:validScore:
processInfo
processMessageWithOptions:andCompletionHandler:
processMessageWithOptions:andReply:
processMetaTrackForType:cancel:flags:
processMetadataGroup:flags:
processName
processPersons:humanBounds:dominantPersonIdx:frame:timestamp:duration:
processPersons:width:height:
processResults:withReply:
processSampleBuffer:
processSampleBuffer:error:
processSampleBuffer:withEndTime:error:
processSampleBuffer:withOptions:error:
processTile:results:cancel:
processVideoFragmentAssetData:withOptions:andErrorHandler:
processVideoFragmentAssetData:withOptions:andReply:
processWithFilterScaleIdx:orientIdx:srcImage:outImage:width:height:
processingDevice
processingMode
processingVersion
progressWithTotalUnitCount:
progressWithTotalUnitCount:parent:pendingUnitCount:
project3Dto2D:intrinsinc:extrinsic:numVert:out2dpts:
projectAndUpdateBoundary
promoteUnverifiedPersonsWithUpdateBlock:
propertyListWithData:options:format:error:
pruneRegions:
pruneRegions:withOverlapRatio:
publicResults
purge
purgeAllResources
purgeInactiveResources
pv_addMergeCandidatePersons:
pv_faceProcessingProgress
pv_fetchAssetsForFaceGroup:
pv_fetchAssetsForFaceLocalIdentifiers:
pv_fetchAssetsForPerson:
pv_fetchAssetsInMoment:
pv_fetchAssetsWithLocalIdentifiers:
pv_fetchCandidatePersonsForPerson:
pv_fetchFaceGroups
pv_fetchFaceGroupsForPerson:
pv_fetchFacesForFaceGroup:
pv_fetchFacesForPerson:
pv_fetchFacesForPerson:inMoment:
pv_fetchFacesForPersonLocalIdentifiers:inMoment:
pv_fetchFacesGroupedByAssetLocalIdentifierForAssets:
pv_fetchFacesWithLocalIdentifiers:
pv_fetchInvalidAssetIdentifiersForCommonComparison
pv_fetchInvalidCandidatePersonsForPerson:
pv_fetchMomentsForAssetsWithLocalIdentifiers:
pv_fetchMomentsForPerson:
pv_fetchMomentsWithLocalIdentifiers:
pv_fetchPersonsGroupedByAssetLocalIdentifierForAssets:
pv_fetchPersonsInMoment:
pv_fetchPersonsWithLocalIdentifiers:
pv_fetchPersonsWithType:
pv_lastAssetDate
pv_numberOfFacesWithFaceprints
pv_persistentStorageDirectoryURL
quadratureTolerance
qualityMeasure
qualityMeasureForFace:countOfFacesOnAsset:
qualityMeasureWithCountOfFacesOnAsset:
qualityScore
qualityScoreForLivePhoto
qualityScoreForTimerange:
quarantineTwinsOnAssetEnabled
queryAnalysesForAssets:withTypes:
queryAnalysisForAsset:
queryAnalysisForAsset:withTypes:
queryAnalysisPropertiesForAsset:
queryAnalysisPropertiesForAssets:
queryAssetsAnalyzedSince:
queryAutoCounterOptInStatus:withPhotoLibraryURL:personLocalIdentifiers:andReply:
queryAutoCounterOptInStatusForPhotoLibraryURL:withPersonLocalIdentifiers:completionHandler:
queryBlacklistedLocalIdentifiers
queryCachedFaceAnalysisProgress:forPhotoLibrary:
queryCachedFaceAnalysisProgress:forPhotoLibrary:withExtendTimeoutBlock:
queryFailedProcessingStatusFromAssets:forTaskID:
queryHeaderForAsset:analysis:assetId:
queryHeadersForAssets:analyses:idMap:
queryLocalIdentifiersForTaskID:withStatus:
queryMetaDataSync
queryPerformanceMeasurementsWithReply:
queryProgress:forPhotoLibrary:andTaskID:
queryProgressDetail:forPhotoLibrary:andTaskID:
queryProgressDetail:forPhotoLibrary:andTaskID:withExtendTimeoutBlock:
queryProgressDetail:forPhotoLibraryURL:andTaskID:
queryProgressDetail:forPhotoLibraryURL:andTaskID:withExtendTimeoutBlock:
queryResultsForAssetId:analysis:
queryResultsForAssetId:withTypes:analysis:
queryResultsForAssets:withTypes:batchResults:
querySchedulingHistoryRecords:forActivityID:sinceDate:
queryTerm
queryWithPixelBuffer:orientation:imageRegions:textBlockAnnotation:queryContext:payload:
queryWithPixelBuffer:orientation:normalizedRegionOfInterest:annotation:queryContext:
quickAnalyzeAsset:results:
quickClassificationFaceAdjustmentVersion
raise
rampDown
rampUp
randInit
rangeOfCharacterFromSet:options:
reInitModel
readFrom:
readFromDisk:quantFactor:
readGyroHomographyDimension:
readSoftwareStackVersion:
readWeightsBias:weights:bias:inputDim:outputDim:quantFactor:
ready
reallocGPUTemporalBuffers
reason
rebuildPersonsWithContext:reply:extendTimeout:cancel:
recallPerPersonExcludeMissDetection
recallPerPersonToGroundTruth
recipeBlob
reclusterFacesWithContext:reply:extendTimeout:cancel:
reclusterFacesWithThreshold:shouldRecluster:error:
recordNeedToPersonBuildOnFaceGroupContainingFace:error:
rectFromMappingNormalizedRect:toBounds:
rectFromMappingNormalizedRect:toBoundsOfSize:
rectValue
reestimateProjectionMatrixPnP
referenceSoftwareStackVersion
referralURL
refineAnalysis:requestHandler:forAsset:orientedWidth:orientedHeight:
refinedRegions
regionOfInterest
regionOfInterestResults
regionsOfInterest
registerAvailabilityObserver:
registerClient:forPhotoLibraryURL:withReply:
relativeActionScore
relativeScore
releaseCachedResources
releaseFeatureBuffers
releaseInputAndOutputBuffers
releaseMemory
remoteObjectProxyWithErrorHandler:
removeAllObjects
removeAutoAssignedFacesFromVerifiedPersonsAndPrepareForPersonBuilding:cancelOrExtendTimeoutBlock:error:
removeClusteringStateCacheWithURL:error:
removeFaces:
removeIndex:
removeItemAtPath:error:
removeItemAtURL:error:
removeLastObject
removeMergeCandidatePersons:
removeObject:
removeObjectAtIndex:
removeObjectForKey:
removeObjectsAtIndexes:
removeObjectsForKeys:
removeObjectsInArray:
removeRequest:error:
removeSmallestKeyFace
removeTrack:
replaceCoordinatesAndFeaturesFromDetectedFace:
replaceObjectAtIndex:withObject:
replaceRegion:mipmapLevel:slice:withBytes:bytesPerRow:bytesPerImage:
reportIdentifier
reportLivePhotoKeyFrameAnalysisResults:selectedKeyFrame:originalStillKeyFrame:stillScore:stillFQScore:stillTimestamp:useSemanticOnly:isKeyFrameSuggested:
reportMovieCurationAnalysisResults:withSummaryAnalytics:
reportProgress:forRequest:
reportProgressForPhotoLibrary:taskID:logMessage:withExtendTimeoutBlock:
representativenessForFaces:error:
request:didFailWithError:
request:didProduceResult:
requestAnalysesForAssets:analysisTypes:allowOndemand:progressHandler:completionHandler:
requestAnalysis:forAsset:andDatabase:error:
requestAnalysis:forAssets:withOptions:andProgressHandler:andCompletionHandler:
requestAnalysis:forAssets:withOptions:andProgressHandler:andError:
requestAnalysis:ofAssetData:withProperties:progressHandler:andCompletionHandler:
requestAnalysis:ofAssetSurface:withProperties:progressHandler:andCompletionHandler:
requestAnalysis:ofFragmentData:withRequestID:properties:andReply:
requestAnalysis:ofFragmentSurface:withRequestID:properties:andReply:
requestAnalysis:ofIOSurface:withProperties:withReply:
requestAnalysis:ofPixelBuffer:withProperties:withCompletionHandler:
requestAnalysisForAsset:analysisTypes:progressHandler:completionHandler:
requestAnalysisTypes:forAssetWithResourceURLs:withOptions:error:
requestAnalysisTypes:forAssetWithResourceURLs:withOptions:progressHandler:andCompletionHandler:
requestAnalysisTypes:forAssets:allowOndemand:progressHandler:error:
requestAnalysisTypes:forAssets:withOptions:andProgressHandler:cancelBlock:analyses:
requestAnalysisTypes:forAssets:withOptions:progressHandler:andCompletionHandler:
requestAssetAnalysis:forLocalIdentifiers:fromPhotoLibraryWithURL:withOptions:analysisTypes:withReply:
requestAssetAnalysis:forPhotoLibraryURL:withLocalIdentifiers:realTime:withReply:
requestAssetProcessing:withTaskID:forLocalIdentifiers:fromPhotoLibraryWithURL:withOptions:andReply:
requestAutoCounterAccuracyCalculation:withPhotoLibraryURL:andReply:
requestAutoCounterAccuracyCalculation:withPhotoLibraryURL:clusterStateURL:groundTruthURL:andReply:
requestAutoCounterAccuracyCalculationForPhotoLibraryURL:clusterStateURL:groundTruthURL:completionHandler:
requestAutoCounterAccuracyCalculationForPhotoLibraryURL:completionHandler:
requestAutoCounterSIMLValidation:withPhotoLibraryURL:simlGroundTruthURL:andReply:
requestAutoCounterSIMLValidationForPhotoLibraryURL:simlGroundTruthURL:completionHandler:
requestBackgroundAnalysisForAssets:fromPhotoLibraryWithURL:realTime:progessHandler:completionHandler:
requestBackgroundAnalysisForAssets:realTime:progessHandler:completionHandler:
requestBackgroundProcessingWithTaskID:forPhotoLibrary:progessHandler:completionHandler:
requestClusterCacheValidation:withPhotoLibraryURL:andReply:
requestClusterCacheValidationWithPhotoLibraryURL:progressHandler:completionHandler:
requestDataForAssetResource:options:dataReceivedHandler:completionHandler:
requestDidComplete:
requestDownloadOfResource:
requestDumpAutoCounter:withPhotoLibraryURL:andReply:
requestDumpAutoCounterForPhotoLibraryURL:completionHandler:
requestFaceCandidatesforKeyFace:withPersonsWithLocalIdentifiers:andPhotoLibraryURL:andReply:
requestFaceCandidatesforKeyFaceForPersonsWithLocalIdentifiers:photoLibraryURL:progessHandler:completionHandler:
requestFaceProcessingForAssets:withOptions:progressHandler:andCompletionHandler:
requestFaceProcessingForPhotoLibrary:withOptions:progressHandler:andCompletionHandler:
requestFileURLForAssetResource:options:urlReceivedHandler:completionHandler:
requestFullProcessingForPhotoLibrary:withOptions:progressHandler:andCompletionHandler:
requestHandler
requestId
requestIdentification:forFaceCrop:withOptions:andReply:
requestIdentificationForFaceCrop:withOptions:andCompletionHandler:
requestIdentificationOfFaces:withCompletionHandler:
requestIdentificationOfFacesWithLocalIdentifiers:fromPhotoLibraryWithURL:withRequestID:andReply:
requestImageProcessing:forAssetURL:withSandboxToken:identifier:requestID:andReply:
requestImageProcessing:forAssetWithCloudIdentifier:requestID:andReply:
requestImageProcessing:forAssetWithIdentifier:identifierType:fromPhotoLibraryWithURL:requestID:andReply:
requestImageProcessing:forIOSurface:withOrientation:assetLocalIdentifier:photoLibraryURL:requestID:andReply:
requestImageProcessing:forIOSurface:withOrientation:identifier:requestID:andReply:
requestImageProcessing:forImageData:withUniformTypeIdentifier:identifier:requestID:andReply:
requestImageProcessingWithCloudIdentifierRequests:requestID:andReply:
requestLibraryProcessing:withTaskID:forPhotoLibraryURL:withOptions:andReply:
requestLivePhotoEffectsForAssets:allowOnDemand:flags:
requestLivePhotoEffectsForAssets:withOptions:progressHandler:andCompletionHandler:
requestMediaAnalysisDatabaseAccessSandboxExtensionWithPhotoLibraryURL:andReply:
requestMovieHighlightsForAssets:withOptions:
requestMultiWorkerProcessingForPhotoLibrary:withOptions:progressHandler:andCompletionHandler:
requestOptInAutoCounter:withPhotoLibraryURL:persons:andReply:
requestOptInAutoCounterForPhotoLibraryURL:withPersons:completionHandler:
requestPersonPreferenceForPhotoLibraryURL:andReply:
requestPersonPreferenceForPhotoLibraryURL:completionHandler:
requestPersonProcessingForPhotoLibraryURL:options:progressHandler:completionHandler:
requestPersonPromoterStatus:withAdvancedFlag:andPhotoLibraryURL:andReply:
requestPersonPromoterStatusWithAdvancedFlag:photoLibraryURL:progressHandler:completionHandler:
requestProcessingTypes:forAssetsWithLocalIdentifiers:fromPhotoLibraryWithURL:progressHandler:completionHandler:
requestProcessingTypes:forAssetsWithLocalIdentifiers:fromPhotoLibraryWithURL:withRequestID:andReply:
requestProcessingWithTaskID:forAssets:withOptions:progressHandler:andCompletionHandler:
requestProcessingWithTaskID:forPhotoLibrary:withOptions:progessHandler:andCompletionHandler:
requestQuickFaceIdentificationForPhotoLibraryURL:withOptions:andCompletionHandler:
requestRebuildPersons:withLocalIdentifiers:andPhotoLibraryURL:andReply:
requestRebuildPersonsWithLocalIdentifiers:photoLibraryURL:progressHandler:completionHandler:
requestReclusterFaces:withPhotoLibraryURL:andReply:
requestReclusterFacesWithPhotoLibraryURL:progressHandler:completionHandler:
requestResetFaceClassificationModel:withPhotoLibraryURL:andReply:
requestResetFaceClassificationModelForPhotoLibraryURL:progressHandler:completionHandler:
requestResetFaceClusteringState:withPhotoLibraryURL:andReply:
requestResetFaceClusteringStateWithPhotoLibraryURL:progressHandler:completionHandler:
requestResetPetClassificationModel:withPhotoLibraryURL:andReply:
requestResetPetClassificationModelForPhotoLibraryURL:progressHandler:completionHandler:
requestResidentMaintenance:withOptions:andReply:
requestResidentMaintenanceWithOptions:andCompletionHandler:
requestSceneProcessingForAssets:withOptions:progressHandler:andCompletionHandler:
requestSceneProcessingForPhotoLibrary:withOptions:progressHandler:andCompletionHandler:
requestSceneprintProcessingForAssets:withOptions:progressHandler:andCompletionHandler:
requestSuggestedMePersonIdentifier:withContext:andPhotoLibraryURL:andReply:
requestSuggestedMePersonIdentifierAtURL:withError:
requestSuggestedMePersonIdentifierWithContext:photoLibraryURL:progressHandler:completionHandler:
requestSuggestedMePersonIdentifierWithContext:reply:
requestSuggestedPersons:withPersonWithLocalIdentifier:toBeConfirmedPersonSuggestions:toBeRejectedPersonSuggestions:andPhotoLibraryURL:andReply:
requestSuggestedPersonsForPersonWithLocalIdentifier:toBeConfirmedPersonSuggestions:toBeRejectedPersonSuggestions:photoLibraryURL:progessHandler:completionHandler:
requestSuggestionsForFaceClusterSequenceNumbers:withClusteringFlags:updateHandler:error:
requestURLAssetAnalysis:forAssetWithResourcePaths:withOptions:analysisTypes:sandboxTokens:withReply:
requestUpdateKeyFacesOfPersons:withLocalIdentifiers:andForceUpdate:andPhotoLibraryURL:andReply:
requestUpdateKeyFacesOfPersonsWithLocalIdentifiers:forceUpdate:photoLibraryURL:progessHandler:completionHandler:
requestVIPModelFilepathForPhotoLibraryURL:forModelType:completionHandler:
requestVIPModelStorageFilepathForPhotoLibraryURL:forModelType:andReply:
requestVideoStabilizationForAssets:withOptions:progressHandler:andCompletionHandler:
requestWallpaperUpgrade:atSourceURL:toDestinationURL:withOptions:sandboxTokens:andReply:
requestWithFaceClusterIds:clusterFlags:updateHandler:
requiredInputFormat:height:format:
resConfig
reserveBudget:
reset
resetActivityStatsAtTime:
resetAnalysisDataWithResetLevel:error:
resetBytesInRange:
resetFaceAnalysisWithResetLevel:completionHandler:
resetFaceClusteringState:
resetFaceClusteringStateWithContext:reply:
resetIdentityAndExpressions
resetInterruption
resetLevelDescription:
resetLibraryClustersWithCancelOrExtendTimeoutBlock:error:
resetLibraryClustersWithCanceler:error:
resetPerformanceMeasurements
resetPersonsModelWithReply:
resetPetsModelWithReply:
resetSegment:
resetSegment:atTime:
resetSharedInstanceWithIdentifier:
resetStatsFlag
resignCurrent
resize:height:
resolution
resource
resourceData
resourceForFaceProcessing:allowStreaming:
resourceForFaceProcessingWithAsset:allowStreaming:
resourceLoader
resourceLoader:didCancelAuthenticationChallenge:
resourceLoader:didCancelLoadingRequest:
resourceLoader:shouldWaitForLoadingOfRequestedResource:
resourceLoader:shouldWaitForRenewalOfRequestedResource:
resourceLoader:shouldWaitForResponseToAuthenticationChallenge:
resourceRequirement
resourceURL
resources
respondWithData:
respondsToSelector:
restoreClusterCacheAndSyncWithLibrary:cancelOrExtendTimeoutBlock:error:
resultFromLegacyDictionary:
resultItems
resultsAsArray
resultsAsSet
resume
retain
retainCount
retrieveBoxes:outHeight:outWidth:boxes:anchorBox:
returnMask
returnObject:
reverseObjectEnumerator
reviseFrameTrackScore:saliencyRegions:
revision
rightEyeClosed
roll
rotateLandmarks:width:height:landmarks:numLandmarks:
rotateTransform:byAngle:
rotationToEulerAngles:angles:
run:
run:withPersons:andRegionCrop:atTime:andDuration:
runTasks:duration:persons:regionCrop:
saliencyDetection:salientRegions:cancel:
saliencyObjectnessRequest
salientObjects
salientRegionsFromPixelBuffer:
saveKeypoints
saveStabilizationRecipe
scaleBasedOnFaceForTimeRange:
scaleFlowTo:
scaleForTimeRange:basedOnFace:
scaleImage:toData:withWidth:andHeight:
scalePixelBuffer:toPixelBuffer:width:height:
scaleRect:scaleX:scaleY:
scaleRegion:ofImage:toData:withWidth:andHeight:
scaleTimeRange:toDuration:
scaledTimeForOriginalTime:
sceneAnalysisProperties
sceneAnalysisTimestamp
sceneAnalysisVersion
sceneClassId
sceneClassifications
sceneResults
scenenetClassifications
sceneprint
sceneprintBlob
sceneprintDistanceToPreviousScene
sceneprintProperties
sceneprintRawRequest
sceneprintRequest
sceneprints
scenes
scheduleClusteringAfterRemovingFaceCSNs:addingFaceIdStrs:
scheduleClusteringOfFacesWithLocalIdentifiers:
scheduleUnclusteringOfFacesWithClusterSequenceNumbers:
score
sdof
sdofImageAssetWithURL:
searchFeatureVectorOfSegment:
searchSections
searchVanishingPointandDominantLine:lineGroup:vanishingPoint:vanishingPointConfidence:dominantLine:
searchWithParsedVisualQuery:completion:
searchWithVisualQuery:completion:
sections
seedAnalyzersWithPixelBuffer:startTime:
segments
selectHighlights
selectHighlightsForTimelapse
selectKeyFrameRangeWithMotion:stillTimestamp:isMetaMotion:
selectRepresentativeFromFaces:qualityMeasureByLocalIdentifier:representativenessByCSN:candidateFaces:
self
semanticScore
sendEvent:withAnalytics:
sendSessionEvent:
serialQueue_
serialize
serializeStateAndReturnError:
sessionWithProperties:andResultsHandler:
sessionWithProperties:withResultsHandler:andInterruptionHandler:
setAbsMotion:
setAbsoluteActionScore:
setAbsoluteScore:
setActivityID:
setActivityLevel:
setActivityScore:
setAdjustmentVersion:
setAdjustmentsRequest:
setAdvancedStatusMergeCandidateLimit:
setAdvancedStatusVerifiedPersonLimit:
setAestheticsRequest:
setAgeType:
setAlgorithmVersion:
setAllowStreaming:
setAllowsCellularAccess:
setAnalysisConfidence:
setAnalysisResultRef:
setAngle:
setAppliesPreferredTrackTransform:
setAssetAdjustedFingerprint:
setAssetIdentifier:
setAssetMasterFingerprint:
setAssetModificationDate:
setAttributesFromLegacyDictionary:
setAutoPlayable:
setAutoloop:
setAutoplayScore:
setAverageScore:
setBarcodeObservations:
setBestPlaybackCrop:
setBlurAnalyzerFaceResults:
setBlurDeterminationMethod:
setBlurScore:
setBodyHeight:
setBodyWidth:
setBounce:
setBound:
setBounds:
setBuffer:offset:atIndex:
setByteRangeAccessSupported:
setCachedImageHandler:
setCachedParseData:
setCachedParseData:overwriteExisting:
setCameraIntrinsics:uc:vc:
setCameraMotionScore:
setCancel:
setCancelled:
setCenterAndSizeFromNormalizedFaceRect:
setCenterX:
setCenterY:
setCharacterRecognitionData:machineReadableCodeData:algorithmVersion:adjustmentVersion:
setChirality:
setChunkSizeForFetch:
setCityNatureRequest:
setClassIndex:
setClasses:forSelector:argumentIndex:ofReply:
setClassificationRequest:
setClassifications:
setClusterIncludeTorsoOnlyFaces:
setClusterSequenceNumber:
setClustererBringUpState:
setColorNormalization:
setColorNormalizationBlob:
setColorfulnessScore:
setCommandBuffer:
setCommandQueue:
setComputePipelineState:
setConfidence:
setContentLength:
setContentScore:
setContext:
setCorrectionResultRef:
setCount:
setCropFraction:
setCropRectHeight:
setCropRectWidth:
setCropRectX:
setCropRectY:
setCropResult:
setCurationScore:
setData:
setDate:
setDateFormat:
setDelegate:queue:
setDescriptor:
setDetectedFaces:
setDetectionLevel:
setDetectionModeCounterShapeModel:
setDetectionType:
setDevice:
setDiscretionary:
setDistanceToPreviousScene:
setDocumentObservations:
setDocumentRequest:
setDominantLine:
setDownloadIntent:
setDownloadIsTransient:
setDownloadPriority:
setDuration:
setEnergy:
setEpoch:
setError:
setErrorCode:
setEthnicityType:
setExcludeMontageAssets:
setExecutionNanoseconds:
setExitStatus:
setExportedInterface:
setExportedObject:
setExposure:
setExposureChangeScore:
setExposureScore:
setExpressionChangeScore:
setExpressionScore:
setExpressionType:
setEyeExpression:
setEyesState:
setFace:
setFaceAdjustmentVersion:
setFaceAlgorithmVersion:
setFaceArea:
setFaceBounds:
setFaceClusteringAgeThreshold:
setFaceClusteringDisabled:
setFaceClusteringThreshold:
setFaceDominated:
setFaceExpressionType:
setFaceID:
setFaceId:
setFaceMergeFaceprintDistanceThreshold:
setFacePrimarySuggestionsThreshold:
setFaceQualityScores:
setFaceSharpness:
setFaceTorsoprint:
setFaceprint:
setFaceprintBlob:
setFacialHairType:
setFeatureShape:height:width:level:
setFetchLimit:
setFetchPropertySets:
setFlag:
setFlags:
setFlickerScore:
setForceFaceprintCreation:
setFrame:
setFrameExpressionScore:
setFrameInstructions:
setFrameProcessedByFaceDetector:
setFrameProcessedByHumanAnalyzer:
setFrameProcessedByPetsActionAnalyzer:
setFrameProcessedByVideoAnalyzer:
setFrameResults:
setGazeType:
setGenerateOutput:
setGlobalQualityScore:
setGroupingIdentifier:
setGyroSharpnessParam:homographyResults:livePhotoStillDisplayTime:imageExposureTime:
setGyroStabilization:
setHadZoom:
setHairColorType:
setHairType:
setHandID:
setHasAction:
setHasContentScore:
setHasDistanceToPreviousScene:
setHasEpoch:
setHasFaceQuality:
setHasFaceSharpness:
setHasFlags:
setHasFlash:
setHasFlickerScore:
setHasGlobalQualityScore:
setHasLoopFadeLen:
setHasLoopPeriod:
setHasLoopStart:
setHasQuality:
setHasSceneprintDistanceToPreviousScene:
setHasSmile:
setHasStatsFlags:
setHasTypesWide:
setHasUnderExpose:
setHeadgearType:
setHeight:
setHidden:
setHighlightScore:
setHomographyParams:count:
setHumanActionScore:
setHumanPoseScore:
setHumanScore:
setIdentifier:
setImageBlurResults:
setImageCompositionResults:
setImageExposureResults:
setImageFaceResults:
setImageFeatureResults:
setImageHumanPoseResults:
setImageJunkResults:
setImagePetsFaceResults:
setImagePetsResults:
setImageSaliencyResults:
setImageSceneprintResults:
setImageShotTypeResults:
setImagefingerprintsRequest:
setImageprintWrapper:
setInTrash:
setIncludeAllBurstAssets:
setIncludeAssetSourceTypes:
setIncludeGuestAssets:
setIncludeHiddenAssets:
setIncludeNonvisibleFaces:
setIncludeOnlyFacesInFaceGroups:
setIncludeOnlyFacesWithFaceprints:
setIncludeTorsoOnlyDetectionData:
setIncludeTorsoOnlyPerson:
setIncludeTrashedAssets:
setIncludedDetectionTypes:
setInput:
setInputBlob:
setInputBlobs:
setInputBoundsHeight:
setInputBoundsWidth:
setInputBoundsX:
setInputBoundsY:
setInputFaceObservations:
setInputImage:
setInputImageWithURL:error:
setInputSignatureprint:
setInputSize:
setInterestScore:
setInterestingnessScore:
setInternalPredicate:
setInternalSortDescriptors:
setInterruptionHandler:
setInvalidationHandler:
setIsAutoPlayable:
setIsCloseup:
setIsFast:
setIsHeadingFrame:
setIsInTrash:
setIsInVIPModel:
setIsInputOutput:
setIsLeftEyeClosed:
setIsRightEyeClosed:
setIsSettlingOK:
setIsTooSmall:
setIsTrimmed:
setIsVerified:
setJunkImageRequest:
setJunkScore:
setKeyFace:
setKeyFace:forCluster:
setKeyFrame:
setKeypoints:
setLandmarkRequest:
setLast:
setLastMinimumFaceGroupSizeForCreatingMergeCandidate:
setLeftEyeClosed:
setLivePhotoEffectsResults:
setLivePhotoHumanActionClassificationResults:
setLivePhotoKeyFrameResults:
setLivePhotoKeyFrameStillResults:
setLivePhotoRecommendationResults:
setLivePhotoSharpnessResults:
setLocale:
setLocation:
setLongexposure:
setLoopPeriod:
setLoopStart:
setLoopSuggestionState:
setLostTrackInd:
setManual:
setMaskOnly:
setMaxFaceCountForClustering:
setMaxHighlightDuration:
setMaxX:
setMaxY:
setMaxZoom:
setMaximumAspectRatio:
setMaximumCandidateCount:
setMaximumHierarchicalObservations:
setMaximumIdentities:
setMaximumIntermediateSideLength:
setMaximumLeafObservations:
setMaximumObservations:
setMaximumTrainingFaceprintsPerIdentity:
setMetalContextPriority:
setMinFaceCountToTriggerClustering:
setMinVersion:
setMinX:
setMinY:
setMinZoom:
setMinimumAspectRatio:
setMinimumConfidence:
setMinimumFaceGroupSizeForCreatingMergeCandidates:
setMinimumSuggestionSize:
setMinimumUnverifiedFaceCount:
setMinimumVerifiedFaceCount:
setMotionBlurVector:
setMotionParamDiff:
setMotionStatsFlag:cameraMotion:subjectAction:interestingness:obstruction:colorfulness:exposureScore:humanActionStatsFlag:humanPoseScore:humanActionScore:subMb:
setMotionType:
setMouthExpression:
setMovieActivityLevelResults:
setMovieApplauseResults:
setMovieAudioQualityResults:
setMovieBabbleResults:
setMovieCameraMotionResults:
setMovieCheeringResults:
setMovieClassificationResults:
setMovieFaceResults:
setMovieFaceprintResults:
setMovieFeatureResults:
setMovieFineSubjectMotionResults:
setMovieHighlightResults:
setMovieHighlightScoreResults:
setMovieHumanActionResults:
setMovieHumanPoseResults:
setMovieLaughterResults:
setMovieLoudnessResults:
setMovieMovingObjectResults:
setMovieMusicResults:
setMovieObstructionResults:
setMovieOrientationResults:
setMoviePetsFaceResults:
setMoviePetsResults:
setMoviePreEncodeResults:
setMovieQualityResults:
setMovieSaliencyResults:
setMovieSceneResults:
setMovieSceneprintResults:
setMovieStabilizationResults:
setMovieSubjectMotionResults:
setMovieSubtleMotionResults:
setMovieSummaryResults:
setMovieUtteranceResults:
setMovieVoiceResults:
setNameSource:
setNetworkAccessAllowed:
setNextCaptureFrame:
setNumSingletons:
setNumValidSingletons:
setObject:atIndexedSubscript:
setObject:forKey:
setObject:forKeyedSubscript:
setObjectRequest:
setObstructionScore:
setOutput:
setOutputBlob:
setOutputFrameDurValue:
setOutputSize:
setOverallFaceQualityScore:
setPeak:
setPenaltyScore:
setPerformInPlace:
setPersonBuilderMergeCandidatesDisabled:
setPersonBuilderMergeCandidatesEnabled:
setPersonBuilderState:
setPersonBuildingDisabled:
setPersonContext:
setPersonID:
setPersonId:
setPersonLocalIdentifier:
setPetsActionScore:
setPetsDetections:
setPhotoLibrary:
setPlaybackCrop:
setPose:
setPoseType:
setPoseYaw:
setPosition:
setPrecisionPerCluster:
setPrecisionRecallThreshold:
setPredicate:
setPreferBackgroundProcessing:
setPreferredMetalDevice:
setProcessed:forLibrary:
setProcessingDevice:
setProcessingMode:
setProcessingVersion:
setProgressHandler:
setPruneAfterAvailableOnLowDisk:
setQuadratureTolerance:
setQuality:
setQualityMeasure:
setQualityScore:
setQualityScoreForLivePhoto:
setQuarantineTwinsOnAssetEnabled:
setReadOnly:
setRecallPerPersonExcludeMissDetection:
setRecallPerPersonToGroundTruth:
setRecipeBlob:
setRecognitionLanguages:
setRecognize:
setRegionOfInterest:
setRelativeActionScore:
setRelativeScore:
setRemoteObjectInterface:
setRequestedTimeToleranceBefore:
setResource:
setResults:
setResults:withClass:forPropertyKey:
setReturnAllResults:
setReturnMask:
setRevision:
setRevision:error:
setRightEyeClosed:
setRoll:
setSaliencyObjectnessRequest:
setSaliencyRequest:
setSceneId:
setSceneResults:
setSceneprintBlob:
setSceneprintDistanceToPreviousScene:
setSceneprintRawRequest:
setSceneprintRequest:
setScore:
setSdof:
setSemanticRequest:
setSemanticScore:
setSexType:
setSharpness:
setShotType:
setShouldPrefetchCount:
setSignpostPayload:
setSize:
setSkintoneType:
setSmile:
setSmileType:
setSortDescriptors:
setSourceHeight:
setSourceSizeHeight:
setSourceSizeWidth:
setStabilityScore:
setStabilize:
setStabilizeResult:
setStableInd:
setStart:
setStartTime:
setState:
setStatisticsBlob:
setStatsFlags:
setStillTime:
setSubMbMotionAvailable:
setSubjectActionScore:
setSubjectScore:
setSuggestionsLogEnabled:
setSumConfidence:
setTabooRequest:
setTexture:atIndex:
setTextureScore:
setThirdPartyObject:
setTimeRange:
setTimeScale:
setTimeValue:
setTimeValues:count:
setTimeZone:
setTimeoutIntervalForResource:
setTimerange:
setTimescale:
setTimestamp:
setTorsoprint:
setTrackID:
setTrackingMode:
setTrackingScore:
setTrainingType:
setTypes:
setTypesWide:
setUpdateHandler:
setUsage:
setUseSegmentationPregating:
setUsesLanguageDetection:
setValidStabilization:
setValue:
setValue:forField:andEvent:
setValue:forKey:
setVanishingPoint:
setVerifiedPersonTypes:
setVerifiedType:
setVersion:
setVideoActivityDescriptor:
setVisualPleasingScore:
setVisualSearchData:algorithmVersion:adjustmentVersion:
setVoiceDetections:
setVoiceScore:
setWantsIncrementalChangeDetails:
setWeightedAveragePrecision:
setWeightedAverageRecall:
setWidth:
setWindowDuration:
setWithArray:
setWithCapacity:
setWithObject:
setWithSet:
setX0:
setX:
setY0:
setY:
settings
settlingExposureChangeScore:
settlingMotionScore:
settlingSubjectScore:
setupModel:
setupTrackerWithReferenceFrame:withROI:
setupWithAudioStream:
setupWithSample:andSampleBatchSize:
setupWithSample:andTrackDuration:
setupWithSample:trackDuration:andSampleBatchSize:
sfReportData
sharedAnalysisService
sharedContextPreferred:
sharedContextWithForceCPU:
sharedContextWithMPSGraph:
sharedDatabaseForPhotoLibrary:
sharedDatabaseManager
sharedImageManager
sharedInstance
sharedInstanceWithIdentifier:andCreationBlock:
sharedInstances_
sharedLogManager
sharedManager
sharedManagerForPhotoLibrary:
sharedMediaAnalyzer
sharedModel:
sharedModel:inputNames:
sharedModel:inputNames:properties:
sharedModel:outputNames:properties:
sharedModelPoolWithRevision:
sharedModelStage1:inputNames:properties:
sharedPhotoLibrary
sharedResource
sharplyFocusedSubjectScore
sharpness
sharpnessRevision
shortDescription
shotType
shouldCutAt:stillPTS:withCut:
shouldProcessSampleWithTimeRange:atSamplingInterval:
shouldQueryInternalFields
signalCancellation
size
sizeValue
skintoneType
slomoRange
slowMotionRampOutRangeForExport:
slowMotionRate
slowMotionTimeRange
slowmoRate
smile
smileType
smoothFiltering:width:height:
socialGroupsOverTheYearsWithPersonClusterManager:forPersons:updateBlock:
sortDescriptorWithKey:ascending:
sortUsingComparator:
sortedArrayUsingComparator:
sortedArrayUsingSelector:
sortedViableMergeCandidateFacesFor:from:ignoreSourceAssetDimensions:matchScores:
sourceHeight
sourcePixelBuffer
sourceSizeHeight
sourceWidth
spaceCheck:
spatialDescriptorWithMvMagnitudeMean:
spatialPooling
stabilityScore
stabilize
stable
stableInd
stagedText
standardUserDefaults
start
startCatalogDownload:then:
startDate
startDownload:completionWithError:
startEntryPointWithQueryID:
startReading
startSessionWithProperties:andReply:
startTime
state
statisticsBlob
statsFlags
status
stillTime
stop
storeAnalysis:forAsset:fromPhotoLibraryURL:withReply:
storeAnalytics:isLivePhoto:
storeFrameResults
storeResults:
straightForwardForChunkFour
streamedMovie
string
stringByAppendingFormat:
stringByAppendingString:
stringByDeletingPathExtension
stringByReplacingOccurrencesOfString:withString:options:range:
stringForObjectValue:
stringValue
stringWithFormat:
stringWithString:
stringWithUTF8String:
strongToStrongObjectsMapTable
subMbMotionAvailable
subarrayWithRange:
subjectActionScore
subjectActivityInTimeRange:fromResults:
subjectScore
submitTaskWithOptions:completionHandler:
submitUserFeedback:completion:
substringToIndex:
subtleMotionScore
subtleMotionScoreForTimerange:
suggestPersonsForPersonWithLocalIdentifier:toBeConfirmedPersonSuggestions:toBeRejectedPersonSuggestions:context:reply:cancel:
suggestedFaceClusterSequenceNumbersForFaceClusterSequenceNumbersRepresentingClusters:error:
suggestedMeIdentifierWithPersonClusterManager:forPersons:updateBlock:
suggestedPersonLocalIdentifierForPersonLocalIdentifier:faceClusterer:canceler:context:error:
suggestionsForClustersWithFaceIds:affinityThreshold:canceller:error:
suggestionsForPersonLocalIdentifier:clusterSequenceNumbers:excludePersonLocalIdentifiers:minimumSuggestionFaceCount:
suggestionsLogEnabled
sumConfidence
sumOfScore
superclass
supportGPU
supportVectorForward
supportedImageSizeSet
supportedPrivateRevisions
supportedRevisions
supportsFeatureSet:
supportsSecureCoding
symbologies
synchronousRemoteObjectProxyWithErrorHandler:
systemPhotoLibraryURL
tabooRequest
targetExtendRange:maxRange:
targetMovieHighlight:mergedRange:maxRange:
targetProcessRange:maxRange:
targetTrimRange:searchRange:
taskForURLAsset:withOptions:analysisTypes:progressHandler:completionHandler:
taskID
taskName
taskService
taskWithAsset:andAnalysisTypes:andOptions:andProgressHandler:andCompletionHandler:
taskWithAssets:andOptions:andCompletionHandler:
taskWithAssets:options:andCompletionHandler:
taskWithCloudIdentifierRequests:photoLibrary:clientBundleID:clientTeamID:cancelBlock:andCompletionHandler:
taskWithFaceCrop:andCompletionHandler:
taskWithOptions:andCompletionHandler:
taskWithRequest:imageAsset:andSignpostPayload:
taskWithRequests:forAsset:cancelBlock:andCompletionHandler:
tastefullyBlurredScore
tensorCoeff
terminate
textBlockWithDocumentObservations:
textElements
texture2DDescriptorWithPixelFormat:width:height:mipmapped:
textureScore
textureness
thirdPartyObject
threshold
thumbnailAspectRatio
thumbnailResource
thumbnailSizeForAsset:withResources:
thumbnailURL
time
timeInterval
timeIntervalSinceDate:
timeIntervalSinceReferenceDate
timeRange
timeRangeMapperForSourceDuration:slowMotionRate:slowMotionTimeRange:forExport:
timeRangeValue
timeRangeWithCMTimeRange:
timeScale
timeStamp
timeValue
timeValueAtIndex:
timeValues
timeZoneForSecondsFromGMT:
timelapseRate
timerWithInterval:unit:oneShot:andBlock:
timerWithIntervalSeconds:isOneShot:andBlock:
timerange
timescale
timestamp
title
torsoThreshold
torsoprint
torsoprintRequestRevision
totalExpected
totalWritten
track
trackFaceMesh:
trackInFrame:
trackObjectInFrame:
trackingMode
trackingScore
tracks
tracksWithMediaType:
trainingFaceObservationsForPersonWithUniqueIdentifier:canceller:error:
trainingObservationsForEntityWithUniqueIdentifier:canceller:error:
trainingType
transform
transformForAngle:pixelBuffer:
transformUprightAboutTopLeft:
trimSegment:fromStart:
type
typeWithIdentifier:
types
typesWide
unarchivedObjectOfClass:fromData:error:
unarchivedObjectOfClasses:fromData:error:
unclusteredClusteringEligibleFaceLocalIdentifiers:
underExpose
ungroupFaceClusterSequenceNumbers:batchSizeForUnclusteringFaces:cancelOrExtendTimeoutBlock:error:
ungroupFaceClusterSequenceNumbers:batchSizeForUnclusteringFaces:canceler:error:
uniformTypeIdentifier
unimplementedExceptionForMethodName:
union:
unionSet:
unlock
unsignedIntValue
unsignedIntegerValue
unsignedLongValue
updateActiveThreshold
updateBoundary3dLandmarkBlendshapes:numBlendshapes:pts2D:lm2D:lmBlendshapes:
updateBoundaryLandmarkCoordinates:pts2D:lm2D:lm3dPos:
updateBoundaryLmForShapeOptimization
updateConfidence:prevBound:newBound:width:height:
updateCropHeatMap:withResults:timeRange:resultsKey:
updateCurationThreshold
updateDegradedFlagForMajorDimension:
updateFaceHeatMap:
updateFaceprint:ofPersistedFace:error:
updateFocalLengthInPixels:
updateHandler
updateIdentityShape:
updateIntrinsic:vc:
updateIntrinsicWhenRotated
updateKeyFacesOfPersonsWithLocalIdentifiers:forceUpdate:cancelOrExtendTimeoutBlock:error:
updateKeyFacesOfPersonsWithLocalIdentifiers:forceUpdate:canceler:error:
updateKeyFacesOfPersonsWithLocalIdentifiers:forceUpdate:context:reply:
updateMeshAndLm3dAfterExpressionChange
updateMeshVertices
updateMissingFaceprintForFaces:withAsset:
updateModelByAddingFaces:andRemovingFaces:canceller:error:
updateModelByAddingPersons:withGroupingIdentifiers:andRemovingPersons:canceller:error:
updateModelForAspectRatio:
updateModelForAspectRatio:computationAccuracy:
updateModelWithConfig:error:
updateModelWithResConfig:
updateModulesWithConfig:
updatePreferredTransform:properties:
updateSegment:
updateSegment:atTime:
updateSegment:score:valid:
updateShapeCoeff:extrinsicMatrix:pts2D:exprWeights:outputblendshapes:
updateWithExistingFaces
updateWithFirstFrame:score:valid:
updateWithOptions:error:
upgradeWallPaperAtURL:toURL:cancel:results:
urlForApplicationDataFolderIdentifier:
useCPUOnly
useGPU
usePHAssetData
useSceneprintInSceneAnalysis
userFeedbackPayload
usesCPUOnly
usesLanguageDetection
uuid
uuidFromLocalIdentifier:
validStabilization
validateActivityScores
validateClusterAccuracyWithSIMLGroundtruth:results:extendTimeoutBlock:cancelBlock:
validateClusterCacheWithContext:cancelOrExtendTimeoutBlock:reply:
validateConfiguration:withError:
validateCost:
validateDecodedFrame:withSettings:
validateFace:eulerAngles:
validateOneImage:landmarks:numofLandmarks:score:
validationScoreOfTimeRange:fromResult:startIdx:
value
valueForField:andEvent:
valueForKey:
valueWithBytes:objCType:
valueWithCMTime:
valueWithSize:
vanishingPoint
vcp_PHFaces:
vcp_abnormalImageDimensionForSceneNet
vcp_addEntriesFromResults:
vcp_addFlags:
vcp_addStatsFlags:
vcp_addTypes:
vcp_adjustmentsResource
vcp_allAcceptableResourcesForAsset:
vcp_allResourcesForAsset:
vcp_allowInMemoryDownload
vcp_analysisPreferences
vcp_annotationWithTypes:
vcp_anyAssetsForTaskID:
vcp_appendResult:forKey:
vcp_appendResults:
vcp_ascendingSizeComparator
vcp_assetCountForTaskID:
vcp_assetCountWithInternalPredicate:forTaskID:
vcp_assetCountWithMediaType:forTaskID:
vcp_assetWithoutAdjustments:duration:
vcp_avAsset
vcp_avAsset:
vcp_captureDeviceMake
vcp_captureDeviceModel
vcp_childWithPendingUnitCount:
vcp_cleanApertureRect
vcp_confidenceForSceneIdentifier:
vcp_convertToOriginalTimerangeFromScaledTimerange:
vcp_dateAnalyzed
vcp_dateModified
vcp_defaultMediaAnalysisDatabaseFilepath
vcp_defaultPhotoLibrary
vcp_defaultURL
vcp_degraded
vcp_descendingSizeComparator
vcp_eligibleForStreaming:
vcp_eligibleForVideoDownload:
vcp_endTime
vcp_exifFromImageURL:
vcp_faceAnalysisStateFilepath
vcp_faceRectFrom:
vcp_fetchAssetsMatchingFingerprint:forPhotoLibrary:
vcp_fetchOptionsForLibrary:forTaskID:
vcp_fileSize
vcp_fingerprint:
vcp_firstEnabledTrackWithMediaType:
vcp_flags
vcp_flagsForPHFace:withFaceRect:
vcp_flashFired
vcp_fullAnalysisPredatesVersionInternalPredicate:
vcp_fullAnalysisTypes
vcp_fullAnalysisTypesForAssetType:
vcp_fullAnalysisTypesForResources:
vcp_fullFrameSize
vcp_getFpsRate
vcp_hasAdjustments:
vcp_hasBody
vcp_hasExtremeAbnormalDimensionForScene
vcp_hasFace
vcp_hasLocalAdjustments
vcp_hasLocalMovie:
vcp_hasLocalPhoto:
vcp_hasLocalSlowmo:
vcp_highResImageResourcesForAsset:
vcp_idealDimension
vcp_imageOrientation
vcp_imagesPredicate:
vcp_inMemoryDownload:withTaskID:toData:cancel:
vcp_isAppleCapture
vcp_isCPLDownloadComplete
vcp_isCPLEnabled
vcp_isCPLSyncComplete
vcp_isDownloadGated
vcp_isLocallyAvailable
vcp_isMercuryBase64
vcp_isMontage
vcp_isMontageWithTaskID:
vcp_isMovie
vcp_isOriginalLocal
vcp_isPano
vcp_isPhoto
vcp_isPhotoResourceUsable:
vcp_isShortMovie
vcp_isSyndicationLibrary
vcp_isVideoResourceUsable:
vcp_isVideoSlowmo
vcp_isVideoTimelapse
vcp_keyFrameWithMaxDimension:
vcp_libraryScaleShortDescription
vcp_livePhotoStillDisplayTime
vcp_livePhotosPredicate:
vcp_localMovieResourcesSorted:
vcp_localPhotoResourcesSorted:
vcp_majorDimensionForResource:withTargetResolution:
vcp_mediaAnalysisBundle
vcp_mediaAnalysisDatabaseFilepath
vcp_mediaAnalysisDirectory
vcp_mercuryBase64ToLocalIdentifier
vcp_modificationDate
vcp_moviesPredicate:
vcp_mutableResults
vcp_needFaceProcessing
vcp_needSceneProcessing
vcp_needsOCRProcessing
vcp_needsProcessingForTask:
vcp_nonPanoPredicate:
vcp_normalizedBodyBounds
vcp_normalizedFaceBounds
vcp_ocrGatingThreshold
vcp_ocrMajorDimensionForResource:
vcp_originalResource
vcp_originalSize
vcp_originalVideoResource
vcp_passedOCRGating
vcp_photoResourcesSorted:
vcp_quality
vcp_queryPHFaces:results:
vcp_removeResultForKey:
vcp_removeSyncPoint
vcp_reportDownload:withTaskID:
vcp_requestFileURLForAssetResource:withTaskID:timeoutHandler:urlHandler:andCompletionHandler:
vcp_requestFileURLForAssetResource:withTaskID:toResourceURL:cancel:
vcp_requiredFaceLibraryProcessingSubTasks
vcp_requiresDownloadForTask:
vcp_requiresProcessingForTask:
vcp_resourceWithType:
vcp_results
vcp_scaleRampWithIntervals:andRates:inSlowmoTimerange:withTimeMapping:inComposition:
vcp_scaleSlowmoTimeRange:withTimeMapping:inComposition:
vcp_scaledExposureTime
vcp_sceneRequest
vcp_sceneRequestForWallpaper
vcp_sceneRequestWithRequestClass:andRevision:
vcp_scenenetAnnotation
vcp_setAnalysisPreferencesValue:forKey:
vcp_setDateAnalyzed:
vcp_setDateModified:
vcp_setFingerprint:
vcp_setFlags:
vcp_setResult:forKey:
vcp_setStatsFlags:
vcp_setSyncPoint:
vcp_setTimerange:
vcp_setTypes:
vcp_sharedModelWithModelName:
vcp_sharedTaxonomy
vcp_size
vcp_smallMovieDerivativeResource
vcp_smallResourceMeetingCriteria:
vcp_sortBySize
vcp_startTime
vcp_statsFlags
vcp_stillImagesPredicate:
vcp_streamedVideo
vcp_supportsInMemoryDownload
vcp_syncPoint
vcp_targetMajorDimensionForImageWithWidth:height:andMinPreferredMinorDimension:
vcp_taskWithImageAsset:andSignpostPayload:
vcp_textAnnotation
vcp_thumbnailResource
vcp_time
vcp_timerange
vcp_typeDescription
vcp_types
vcp_uniformTypeIdentifier
vcp_updateModelByAddingFaces:error:
vcp_usePHFace
vcp_usePHFaceExpression
vcp_version
vcp_vipModelLastGenerationDateForVIPType:
vcp_visionCacheStorageDirectoryURL
verifiedType
vertexCount
vertices
videoActivityDescriptor
videoCaptionDecoderTestURL
videoCaptionEncoderTestURL
videoEmbedding
videoStabilizerforAnalysisType:withMetadata:sourceSize:cropRect:
visionSession
visualPleasingScore
visualPleasingScoreForTimerange:
visualSearchData
visualSearchProperties
visualUnderstanding
voiceScore
voiceScoreForTimerange:
voteVanishingPoint:
waitUntilCompleted
warnings
wasSignalled
weakSession
webURL
weightedAveragePrecision
weightedAverageRecall
wellChosenBackgroundScore
wellFramedSubjectScore
wellTimedShotScore
width
workerWithPhotoLibrary:
workerWithPhotoLibrary:andContext:
wrapperWithImageprintType:version:andData:
writeTo:
writeToFile:atomically:
writeToURL:atomically:
writeToURL:error:
writeToURL:options:error:
zone
@24@0:8^{_NSZone=}16
@16@0:8
B24@0:8@16
v24@0:8@16
Q16@0:8
f16@0:8
v20@0:8f16
v16@0:8
@"VCPProtoTimeRange"
@52@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16f48
{CGRect={CGPoint=dd}{CGSize=dd}}16@0:8
v48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
{CGRect="origin"{CGPoint="x"d"y"d}"size"{CGSize="width"d"height"d}}
@64@0:8{CGAffineTransform=dddddd}16
@72@0:8@16@24{?=qiIq}32^{?=qiIq}56@64
i88@0:8^{__CVBuffer=}16{?=qiIq}24{?=qiIq}48^Q72@80
i80@0:8^{__CVBuffer=}16{?=qiIq}24{?=qiIq}48^Q72
v104@0:8{?={?=qiIq}{?=qiIq}}16@64@72{?=qiIq}80
i64@0:8{?={?=qiIq}{?=qiIq}}16
@"NSMutableArray"
{?="value"q"timescale"i"flags"I"epoch"q}
@"VCPImagePetsAnalyzer"
@"NSArray"
@32@0:8@16@24
i72@0:8{?={?=qiIq}{?=qiIq}}16^{__CVBuffer=}64
B16@0:8
v20@0:8B16
B32@0:8@?16^@24
@24@0:8@16
@24@0:8Q16
d24@0:8@16
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
@"NSURL"16@0:8
B32@0:8@?<v@?>16^@24
@"<PVFetchResultProtocol>"24@0:8@"NSArray"16
@"<PVFetchResultProtocol>"24@0:8Q16
@"<PVFetchResultProtocol>"24@0:8@"<PVMomentProtocol>"16
@"<PVFetchResultProtocol>"24@0:8@"<PVPersonProtocol>"16
@"NSDictionary"24@0:8@"<PVFetchResultProtocol>"16
@"<PVFetchResultProtocol>"32@0:8@"<PVPersonProtocol>"16@"<PVMomentProtocol>"24
@"<PVFetchResultProtocol>"32@0:8@"NSArray"16@"<PVMomentProtocol>"24
@"<PVFetchResultProtocol>"24@0:8@"<PVFaceGroupProtocol>"16
@"<PVFetchResultProtocol>"16@0:8
@"<PVFetchResultProtocol>"24@0:8@"<NSFastEnumeration>"16
@"NSDate"16@0:8
@"NSSet"16@0:8
@"NSDictionary"16@0:8
@24@0:8@"NSDictionary"16
v24@0:8I16B20
@"NSObject<OS_dispatch_queue>"
^{__SCNetworkReachability=}
@96@0:8@16f24B28@32{?={?=qiIq}{?=qiIq}}40Q88
i20@0:8f16
i28@0:8^{__CVBuffer=}16i24
i56@0:8@16@24{?=qiIq}32
i32@0:8@16@24
{?=qiIq}40@0:8{?=qiIq}16
i104@0:8{?=qiIq}16{?=qiIq}40@64{CGRect={CGPoint=dd}{CGSize=dd}}72
@"VCPVideoCNNBackbone"
@"VCPTransforms"
@"VCPVideoPersonDetector"
@"NSString"
@"VCPVideoCNNAutoplay"
@"VCPVideoCNNCameraMotion"
@"VCPVideoCNNQuality"
@"VCPVideoCNNHighlight"
{?="distanceToPreviousScene"b1"flickerScore"b1"sceneprintDistanceToPreviousScene"b1}
@32@0:8^{__CVBuffer=}16@24
@"MLFeatureValue"24@0:8@"NSString"16
^{__CVBuffer=}
v40@0:8r^{?=qiIq}16r^{?=qiIq}24@32
i28@0:8^{opaqueCMSampleBuffer=}16i24
i16@0:8
i24@0:8r^{AudioStreamBasicDescription=dIIIIIIII}16
i88@0:8^{AudioBufferList=I[1{AudioBuffer=II^v}]}16{AudioTimeStamp=dQdQ{SMPTETime=ssIIIssss}II}24
i24@0:8r^{?=qiIq}16
@"NSDictionary"
{AudioStreamBasicDescription="mSampleRate"d"mFormatID"I"mFormatFlags"I"mBytesPerPacket"I"mFramesPerPacket"I"mBytesPerFrame"I"mChannelsPerFrame"I"mBitsPerChannel"I"mReserved"I}
B20@0:8B16
@24@0:8@?16
@20@0:8B16
@72@0:8@16@24@32@40B48B52f56f60f64B68
i48@0:8^{__CVBuffer=}16{?=qiIq}24
i88@0:8^{__CVBuffer=}16{?=qiIq}24{?=qiIq}48^Q72@?80
i96@0:8^{__CVBuffer=}16{?=qiIq}24{?=qiIq}48@72^Q80@?88
i40@0:8{?=qiIq}16
f40@0:8@16^{EncodeStats=^^?^B^B^{MotionVector}^{MotionVector}^{MotionVector}^{MotionVector}^S^S^I^S^S^S^S^S^S^S^S^S^S^SIBBBii}24i32i36
i20@0:8i16
v24@0:8^v16
f24@0:8^v16
i36@0:8@16@24B32
i80@0:8@16@24{?={?=qiIq}{?=qiIq}}32
i44@0:8^{__CFArray=}16@24@32B40
v24@0:8^{__CVBuffer=}16
v32@0:8^v16@24
@64@0:8{?={?=qiIq}{?=qiIq}}16
^{MotionFilter=^{FrameBuffer}BB}
^{MetaDataAnalysis=B^{FrameBuffer}{Translation=fff}{Translation=fff}}
^{IrisAnalysis=ffiiB^{__CFArray}}
{FrameBuffer="frame_count_"i"buffer_"[35{Frame="frame_idx_"i"timestamp_"{?="value"q"timescale"i"flags"I"epoch"q}"duration_"{?="value"q"timescale"i"flags"I"epoch"q}"ave_motion_"{Translation="x_"f"y_"f"z_"f}"org_motion_"{Translation="x_"f"y_"f"z_"f}"quality_score_"f"distortion_"Q"distortion_norm_"f"motion_change_"{Translation="x_"f"y_"f"z_"f}"compressed_bytes_"I"blur_"B"acc_var_"{Translation="x_"f"y_"f"z_"f}"texture_"f"motion_result_"{MotionResult="significant_values_"[6f]"confidence_"[6f]"fine_action_score_"f"action_score_"f"track_score_"f"rotation_angle_"f"subtle_motion_score_"f"is_stable_"B"action_blocks_"i"action_motion_"f"valid_mb_"B"valid_submb_"B"support_size_"i"residual_var_"f"gmv_"[2f]"motion_param_"{array<float, 6UL>="__elems_"[6f]}"motion_param_diff_"{array<float, 6UL>="__elems_"[6f]}"duration_"{?="value"q"timescale"i"flags"I"epoch"q}"scene_delta_"f"scene_delta_ratio_"f"objects_"{Vector<ma::Object *>="vector_"^{__CFArray}}"detect_objects_"{Vector<ma::Object *>="vector_"^{__CFArray}}"imported_objects_"{Vector<ma::Object *>="vector_"^{__CFArray}}}"flow_"^f"interestingness_"f"obstruction_"f"colorfulness_score_"f"histogram_"{Histogram="extremities_"f"overexposes_"f"histogram_"[3^i]"moments_hist_"[2^i]}}]}
{Histogram="extremities_"f"overexposes_"f"histogram_"[3^i]"moments_hist_"[2^i]}
@"NSMutableDictionary"
@"VCPFrameAnalysisStats"
@"VCPFrameScoreFilter"
@"VCPMotionFlowSubtleMotionAnalyzer"
@"VCPMotionFlowAnalyzer"
@32@0:8@16^@24
@80@0:8{CGAffineTransform=dddddd}16@64@72
i32@0:8^{__CVBuffer=}16@24
B32@0:8@16@24
B84@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48B80
i56@0:8^{__CVBuffer=}16{?=qiIq}24@48
@"VCPCNNSmileDetector"
@"VCPCNNPoseEstimator"
{?={?=qiIq}{?=qiIq}}16@0:8
@32@0:8@16@?24
v32@0:8@16Q24
B24@0:8^@16
@"NSData"
{atomic<bool>="__a_"{__cxx_atomic_impl<bool, std::__cxx_atomic_base_impl<bool>>="__a_value"AB}}
@32@0:8B16B20@24
^f48@0:8i16i20^i24^i32^f40
i36@0:8^{CGPoint=dd}16^f24f32
@"VCPCNNModelEspresso"
f56@0:8*16*24*32i40i44q48
f48@0:8*16i24i28q32*40
i48@0:8^{__CVBuffer=}16^Q24^@32@?40
@24@0:8^{__CVBuffer=}16
i32@0:8^f16@24
@"NSData"16@0:8
i32@0:8^f16@"<VCPDistanceDescriptorProtocol>"24
@24@0:8@"NSData"16
@"VNImageprint"
d16@0:8
v24@0:8d16
{?="contentScore"b1"globalQualityScore"b1}
i20@0:8B16
{CGAffineTransform=dddddd}64@0:8{CGAffineTransform=dddddd}16
i32@0:8@16^Q24
{CGAffineTransform="a"d"b"d"c"d"d"d"tx"d"ty"d}
v24@0:8q16
q16@0:8
S16@0:8
@40@0:8@16@24@?32
@?16@0:8
v24@0:8@?16
@"VNCanceller"
B32@0:8@16^@24
@32@0:8Q16^@24
@40@0:8Q16Q24^@32
@40@0:8@16@24^@32
@"NSDictionary"32@0:8Q16^@24
@"NSNumber"40@0:8Q16Q24^@32
@"NSDictionary"40@0:8@"NSArray"16@"NSArray"24^@32
v32@0:8@16@24
B28@0:8B16@?20
v24@0:8Q16
v40@0:8{?=QQBB}16
B64@0:8@16@24@32@40@?48^@56
@44@0:8@16B24@28@36
@36@0:8@16B24@28
v40@0:8@16^@24@?32
v32@0:8@16@?24
B40@0:8^@16^Q24^@32
B48@0:8@16@24@32^@40
B36@0:8B16@?20^@28
Q36@0:8B16@?20^@28
@48@0:8@16@24@?32^@40
@40@0:8@16^@24@?32
B60@0:8@16Q24B32^@36@?44^@52
@40@0:8^@16^@24@?32
B56@0:8^@16^d24^B32@?40^@48
@"PHPhotoLibrary"
@"VCPPhotosPersistenceDelegate"
@"NSObject<OS_dispatch_group>"
@"VCPPhotosFaceProcessingContext"
@"NSURL"
@"NSNumber"
@"NSSet"
@"NSMutableSet"
@"VNClustererBuilder"
@"VCPSuggestionRequest"
@"NSLock"
{?="countOfEligibleFaces"Q"countOfFacesPendingToAdd"Q"isClustering"B"rebuildRequired"B}
@"NSDate"
{mach_timebase_info="numer"I"denom"I}
@40@0:8^{__CVBuffer=}16@24^@32
{CGSize=dd}32@0:8@16^@24
I16@0:8
@"VCPImageHumanPoseAnalyzer"
i24@0:8@16
i112@0:8@16@24{CGRect={CGPoint=dd}{CGSize=dd}}32{?=qiIq}64{?=qiIq}88
@64@0:8@16@24{CGRect={CGPoint=dd}{CGSize=dd}}32
{CGSize="width"d"height"d}
@"VNImageRequestHandler"
@"VCPMADVIRemoveBackgroundCachedImageHandler"
@40@0:8@16@24@32
@40@0:8@"MADRequest"16@"VCPMADServiceImageAsset"24@"NSString"32
@"NSArray"16@0:8
v24@0:8@"<MTLDevice>"16
@"MADVIRemoveBackgroundRequest"
@"VCPMADServiceImageAsset"
@"<MTLDevice>"
@"VNImageBasedRequest"
{?=qiIq}16@0:8
@"VNRequest"
@20@0:8i16
i24@0:8i16i20
i32@0:8^{CGImage=}16^^{__CVBuffer}24
^{CGColorSpace=}
^{CGContext=}
^{__CVPixelBufferPool=}
^{OpaqueVTPixelTransferSession=}
@56@0:8@16Q24@32@?40@?48
@48@0:8Q16@24@32^@40
@48@0:8@16Q24@32^@40
@"VCPDatabaseReader"
v56@0:8@16@24I32@36i44@?48
v60@0:8@16@24@32@40i48@?52
v60@0:8@16@24Q32@40i48@?52
v64@0:8@16@24I32@36@44i52@?56
v44@0:8@16@24i32@?36
v36@0:8@16i24@?28
v32@0:8Q16Q24
v60@0:8i16@20@28Q36@44@?52
v60@0:8i16@20@28@36Q44@?52
v48@0:8i16@20@28B36@?40
v52@0:8i16Q20@28@36@?44
v60@0:8i16Q20@28@36@44@?52
v60@0:8i16@20@28@36@44@?52
v20@0:8i16
v48@0:8i16@20B28@32@?40
v44@0:8i16@20@28@?36
v36@0:8i16@20@?28
v40@0:8i16B20@24@?32
v40@0:8@16Q24@?32
v52@0:8i16@20@28@36@?44
v52@0:8Q16@24@32i40@?44
v32@0:8@"NSURL"16@?<v@?@"NSString">24
v56@0:8@"NSArray"16@"IOSurface"24I32@"NSString"36i44@?<v@?@"NSArray"@"NSError">48
v60@0:8@"NSArray"16@"NSURL"24@"NSString"32@"NSString"40i48@?<v@?@"NSArray"@"NSError">52
v60@0:8@"NSArray"16@"NSData"24@"UTType"32@"NSString"40i48@?<v@?@"NSArray"@"NSError">52
v60@0:8@"NSArray"16@"NSString"24Q32@"NSURL"40i48@?<v@?@"NSArray"@"NSError">52
v64@0:8@"NSArray"16@"IOSurface"24I32@"NSString"36@"NSURL"44i52@?<v@?@"NSArray"@"NSError">56
v44@0:8@"NSArray"16@"NSString"24i32@?<v@?@"NSArray"@"NSError">36
v36@0:8@"NSDictionary"16i24@?<v@?@"NSDictionary"@"NSError">28
v24@0:8@?<v@?@"NSDictionary">16
v60@0:8i16@"NSArray"20@"NSDictionary"28Q36@"NSArray"44@?<v@?@"NSDictionary"@"NSError">52
v60@0:8i16@"NSArray"20@"NSURL"28@"NSDictionary"36Q44@?<v@?@"NSDictionary"@"NSError">52
v48@0:8i16@"NSURL"20@"NSArray"28B36@?<v@?@"NSDictionary"@"NSError">40
v52@0:8i16Q20@"NSURL"28@"NSDictionary"36@?<v@?@"NSError">44
v60@0:8i16Q20@"NSArray"28@"NSURL"36@"NSDictionary"44@?<v@?@"NSDictionary"@"NSError">52
v60@0:8i16@"NSURL"20@"NSURL"28@"NSDictionary"36@"NSArray"44@?<v@?@"NSDictionary"@"NSError">52
v24@0:8@?<v@?@"NSError">16
v24@0:8@?<v@?Q>16
v24@0:8@"NSURL"16
v60@0:8i16@"NSString"20@"NSArray"28@"NSArray"36@"NSURL"44@?<v@?@"NSArray"@"NSError">52
v48@0:8i16@"NSArray"20B28@"NSURL"32@?<v@?B@"NSError">40
v44@0:8i16@"NSArray"20@"NSURL"28@?<v@?@"NSArray"@"NSError">36
v36@0:8i16@"NSURL"20@?<v@?B@"NSError">28
v44@0:8i16@"NSDictionary"20@"NSURL"28@?<v@?@"NSString"@"NSError">36
v40@0:8i16B20@"NSURL"24@?<v@?@"NSDictionary"@"NSError">32
v36@0:8i16@"NSURL"20@?<v@?@"NSDictionary"@"NSError">28
v44@0:8i16@"NSArray"20@"NSURL"28@?<v@?B@"NSError">36
v32@0:8@"NSURL"16@?<v@?@"NSDictionary"@"NSError">24
v40@0:8@"NSURL"16Q24@?<v@?@"NSString"@"NSError">32
v44@0:8i16@"NSURL"20@"NSArray"28@?<v@?@"NSDictionary"@"NSError">36
v52@0:8i16@"NSURL"20@"NSURL"28@"NSURL"36@?<v@?@"NSDictionary"@"NSError">44
v44@0:8i16@"NSURL"20@"NSURL"28@?<v@?@"NSDictionary"@"NSError">36
v44@0:8@"NSArray"16@"NSURL"24i32@?<v@?@"NSDictionary"@"NSError">36
v52@0:8Q16@"NSArray"24@"NSURL"32i40@?<v@?@"NSError">44
v28@0:8d16i24
i40@0:8^f16@24Q32
i48@0:8^f16@24Q32@?40
i32@0:8^@16@24
i40@0:8^@16@24@?32
i40@0:8^@16@24Q32
i48@0:8^@16@24Q32@?40
i56@0:8Q16@24@32@?40@?48
i52@0:8@16@24B32@?36@?44
i44@0:8@16B24@?28@?36
i48@0:8Q16@24@?32@?40
i48@0:8@16@24@?32@?40
i40@0:8@16@24@?32
i32@0:8@16@?24
i40@0:8@16Q24@?32
@"NSXPCConnection"
i64@0:8@16@24@32@40@?48@?56
i52@0:8@16B24@28@?36@?44
i40@0:8@16@?24@?32
i44@0:8B16@20@?28@?36
i48@0:8@16@24@32@?40
i24@0:8^f16
^f16@0:8
i40@0:8^{?=^v^v[4Q][4Q]QQQQQQQQQQi}16@24@32
i64@0:8^ 16Q24Q32Q40@48@56
i40@0:8^i16^i24^I32
i40@0:8^{__CVBuffer=}16@24@32
{?="plan"^v"network_index"i}
{?="data"^v"reserved"^v"dim"[4Q]"stride"[4Q]"width"Q"height"Q"channels"Q"batch_number"Q"sequence_length"Q"stride_width"Q"stride_height"Q"stride_channels"Q"stride_batch_number"Q"stride_sequence_length"Q"storage_type"i}
@40@0:8{?=qiIq}16
i36@0:8^{__CVBuffer=}16^f24i32
i40@0:8^f16^{__CVBuffer=}24i32i36
^f40@0:8i16i20^i24^i32
i52@0:8^f16i24i28@32@40i48
i28@0:8@16i24
i48@0:8^{__CVBuffer=}16@24@32@?40
@"CVNLPCommSafetyHandler"
@"MADImageSafetyClassificationRequest"
i64@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16^{__CVBuffer=}48^B56
@72@0:8@16@24Q32Q40@48i56B60^@64
@92@0:8@16@24@32Q40Q48@56@64@72@80i88
@32@0:8@16q24
d32@0:8@16@24
B40@0:8@16@24@32
B48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
q24@0:8Q16
s16@0:8
v20@0:8s16
v20@0:8S16
@"VCPVNImageprintWrapper"
^v16@0:8
^v20@0:8B16
@28@0:8B16B20B24
@"VCPProtoBounds"
@48@0:8{?=qiIq}16f40B44
v72@0:8{?={?=qiIq}{?=qiIq}}16f64B68
v40@0:8{?=qiIq}16
v44@0:8{?=qiIq}16B40
v64@0:8{?={?=qiIq}{?=qiIq}}16
{?="start"{?="value"q"timescale"i"flags"I"epoch"q}"duration"{?="value"q"timescale"i"flags"I"epoch"q}}
@32@0:8@16f24f28
v76@0:8@16{?=qiIq}24{?=qiIq}48B72
v72@0:8@16{?={?=qiIq}{?=qiIq}}24
@44@0:8Q16Q24B32@?36
@36@0:8Q16B24@?28
@"NSObject<OS_dispatch_source>"
S24@0:8@16
@24@0:8q16
@20@0:8S16
S24@0:8q16
@28@0:8@16B24
i40@0:8^@16#24Q32
i36@0:8^@16#24i32
{CGRect={CGPoint=dd}{CGSize=dd}}56@0:8d16d24d32d40d48
@48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
v40@0:8*16Q24^f32
i24@0:8^Q16
i32@0:8^{__CVBuffer=}16^Q24
@"VCPCNNModel"
@"VCPCNNData"
f24@0:8@16
i32@0:8[6f]16[6f]24
i24@0:8^v16
i24@0:8^{EncodeStats=^^?^B^B^{MotionVector}^{MotionVector}^{MotionVector}^{MotionVector}^S^S^I^S^S^S^S^S^S^S^S^S^S^SIBBBii}16
v80@0:8^{__CVBuffer=}16{?=qiIq}24{?=qiIq}48@?72
{Frame="frame_idx_"i"timestamp_"{?="value"q"timescale"i"flags"I"epoch"q}"duration_"{?="value"q"timescale"i"flags"I"epoch"q}"ave_motion_"{Translation="x_"f"y_"f"z_"f}"org_motion_"{Translation="x_"f"y_"f"z_"f}"quality_score_"f"distortion_"Q"distortion_norm_"f"motion_change_"{Translation="x_"f"y_"f"z_"f}"compressed_bytes_"I"blur_"B"acc_var_"{Translation="x_"f"y_"f"z_"f}"texture_"f"motion_result_"{MotionResult="significant_values_"[6f]"confidence_"[6f]"fine_action_score_"f"action_score_"f"track_score_"f"rotation_angle_"f"subtle_motion_score_"f"is_stable_"B"action_blocks_"i"action_motion_"f"valid_mb_"B"valid_submb_"B"support_size_"i"residual_var_"f"gmv_"[2f]"motion_param_"{array<float, 6UL>="__elems_"[6f]}"motion_param_diff_"{array<float, 6UL>="__elems_"[6f]}"duration_"{?="value"q"timescale"i"flags"I"epoch"q}"scene_delta_"f"scene_delta_ratio_"f"objects_"{Vector<ma::Object *>="vector_"^{__CFArray}}"detect_objects_"{Vector<ma::Object *>="vector_"^{__CFArray}}"imported_objects_"{Vector<ma::Object *>="vector_"^{__CFArray}}}"flow_"^f"interestingness_"f"obstruction_"f"colorfulness_score_"f"histogram_"{Histogram="extremities_"f"overexposes_"f"histogram_"[3^i]"moments_hist_"[2^i]}}
^{EncodeStatsHW=^^?^B^B^{MotionVector}^{MotionVector}^{MotionVector}^{MotionVector}^S^S^I^S^S^S^S^S^S^S^S^S^S^SIBBBiii^{OpaqueVTCompressionSession}^{__CFData}{?=qiIq}iiB}
[6[5f]]
@"VCPObjectPool"
i36@0:8^{__sFILE=*iiss{__sbuf=*i}i^v^?^?^?^?{__sbuf=*i}^{__sFILEX}i[3C][1C]{__sbuf=*i}iq}16i24i28i32
@"VNClassifyImageAestheticsRequest"
@"VNSceneClassificationRequest"
@"VNCreateSceneprintRequest"
@"VNGenerateAttentionBasedSaliencyImageRequest"
@"VNClassifyJunkImageRequest"
@"VNRecognizeObjectsRequest"
@"VNGenerateObjectnessBasedSaliencyImageRequest"
@"VNClassifyPotentialLandmarkRequest"
@"VNVYvzEtX1JlUdu8xx5qhDI"
@"VN6Mb1ME89lyW3HpahkEygIG"
@"VN5kJNH3eYuyaLxNpZr5Z7zi"
@"VNClassifyMemeImageRequest"
@"VN1JC7R3k4455fKQz0dY1VhQ"
@"VNRecognizeDocumentElementsRequest"
@"VNClassifyCityNatureImageRequest"
@"VNCreateImageFingerprintsRequest"
{?="faceQuality"b1}
B20@0:8f16
{HinkleyDetector="sensitivity_"f"threshold_"f"min_length_"i"stats_"{HinkleyStats="upper_"f"lower_"f"max_"f"min_"f}}
@"VCPVideoMetaMotionSegment"
@44@0:8f16{?=qiIq}20
v44@0:8f16{?=qiIq}20
@"VIService"
@"VCPProtoTime"
@48@0:8@16@24@32@40
i40@0:8{vector<float *, std::allocator<float *>>=^^f^^f{__compressed_pair<float **, std::allocator<float *>>=^^f}}16
v24@0:8^f16
{vector<espresso_buffer_t, std::allocator<espresso_buffer_t>>=^{?}^{?}{__compressed_pair<espresso_buffer_t *, std::allocator<espresso_buffer_t>>=^{?}}}16@0:8
v40@0:8{vector<espresso_buffer_t, std::allocator<espresso_buffer_t>>=^{?}^{?}{__compressed_pair<espresso_buffer_t *, std::allocator<espresso_buffer_t>>=^{?}}}16
{?=^v^v[4Q][4Q]QQQQQQQQQQi}16@0:8
v184@0:8{?=^v^v[4Q][4Q]QQQQQQQQQQi}16
@"VCPCNNEspressoContext"
{vector<espresso_buffer_t, std::allocator<espresso_buffer_t>>="__begin_"^{?}"__end_"^{?}"__end_cap_"{__compressed_pair<espresso_buffer_t *, std::allocator<espresso_buffer_t>>="__value_"^{?}}}
i40@0:8@16^@24@?32
@"VCPLoaned"
@56@0:8^f16^f24Q32Q40i48i52
i28@0:8f16f20f24
i36@0:8^f16f24^f28
i64@0:8^f16Q24Q32{DSPSplitComplex=^f^f}40^f56
B28@0:8i16i20i24
{DSPSplitComplex="realp"^f"imagp"^f}
@68@0:8f16{?={?=qiIq}{?=qiIq}}20
i64@0:8{?=qiIq}16{?=qiIq}40
@"VCPVideoCaptionEncoder"
@"MAAsset"
@32@0:8@16r^{?={?=qiIq}{?=qiIq}}24
i28@0:8B16^{?={?=qiIq}{?=qiIq}}20
i72@0:8{?={?=qiIq}{?=qiIq}}16^^{opaqueCMSampleBuffer}64
^{opaqueCMSampleBuffer=}16@0:8
@"AVAssetReader"
@"AVAssetReaderSampleReferenceOutput"
@"NSObject<OS_dispatch_semaphore>"
[2^{opaqueCMSampleBuffer}]
@36@0:8Q16i24@28
@40@0:8Q16@24^@32
B40@0:8^f16@24^@32
@132@0:8{CGAffineTransform=dddddd}16{?={?=qiIq}{?=qiIq}}64B112@116@124
i24@0:8^{__CVBuffer=}16
f32@0:8@16@24
@"VCPImageBlurAnalyzer"
@"VCPImageFaceQualityAnalyzer"
@"VCPVideoKeyFrame"
@"AVAssetReaderTrackOutput"
@"AVAssetReaderOutputMetadataAdaptor"
v56@0:8@16@24^Q32^Q40^Q48
Q24@0:8@16
Q40@0:8@16@24Q32
Q32@0:8@16Q24
i48@0:8@16Q24^@32@?40
v48@0:8@16Q24@32@?40
B20@0:8i16
@48@0:8i16i20i24B28B32i36i40B44
i28@0:8^{__sFILE=*iiss{__sbuf=*i}i^v^?^?^?^?{__sbuf=*i}^{__sFILEX}i[3C][1C]{__sbuf=*i}iq}16s24
v32@0:8@16^{__CVBuffer=}24
f92@0:8f16{CGRect={CGPoint=dd}{CGSize=dd}}20{CGRect={CGPoint=dd}{CGSize=dd}}52i84i88
@28@0:8@16f24
f84@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48B80
@"VCPImageSaliencyAnalyzer"
@40@0:8^{opaqueCMSampleBuffer=}16@24^@32
@"VCPImageHandsAnalyzer"
i40@0:8B16@20B28B32B36
i40@0:8^{__CVBuffer=}16^{__CVBuffer=}24@?32
^f32@0:8^i16^i24
i32@0:8^{__CVBuffer=}16f24f28
i40@0:8^{__CVBuffer=}16^{__CVBuffer=}24f32f36
i28@0:8@16I24
{vector<float *, std::allocator<float *>>="__begin_"^^f"__end_"^^f"__end_cap_"{__compressed_pair<float **, std::allocator<float *>>="__value_"^^f}}
i36@0:8@16f24@?28
@"MADEmbeddingGenerationRequest"
B40@0:8@16@24^@32
B88@0:8{?={?=qiIq}{?=qiIq}}16{?=qiIq}64
B56@0:8^{opaqueCMSampleBuffer=}16{?=qiIq}24^@48
B32@0:8^{opaqueCMSampleBuffer=}16^@24
B48@0:8{?=qiIq}16^@40
v20@0:8I16
{CF<opaqueCMSampleBuffer *>="value_"^{opaqueCMSampleBuffer}}
{?="faceSharpness"b1}
@40@0:8@16Q24^@32
i40@0:8^{CGPoint=dd}16^f24^@32
v64@0:8^f16^f24Q32Q40Q48Q56
v28@0:8i16^f20
v40@0:8^f16Q24Q32
i56@0:8^f16@24^{CGPoint=dd}32^f40^@48
i52@0:8@16f24{CGPoint=dd}28^f44
i32@0:8@16^f24
[8^f]
@"VCPGaborFilter"
@"VCPHumanPoseImageRequest"
@24@0:8i16B20
i40@0:8^{__CVBuffer=}16^f24i32i36
f40@0:8^f16i24i28i32i36
i32@0:8^f16i24i28
i24@0:8@?16
i40@0:8^{__CVBuffer=}16@24@?32
i84@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24{CGSize=dd}56B72@76
[5{CGRect="origin"{CGPoint="x"d"y"d}"size"{CGSize="width"d"height"d}}]
[5f]
B24@0:8Q16
Q24@0:8Q16
Q32@0:8q16Q24
@212@0:8Q16{CGAffineTransform=dddddd}24{?={?=qiIq}{?=qiIq}}72B120f124@128B136B140@144B152{?={?=qiIq}{?=qiIq}}156@204
v64@0:8@16@24@32@40{CGSize=dd}48
@"VCPVideoKeyFrameAnalyzer"
@"VCPMovieHighlightAnalyzer"
@"VCPImageDescriptor"
i44@0:8B16@20i28i32@?36
i28@0:8^^{__CVBuffer}16I24
i32@0:8^{__CVBuffer=}16^{__CVBuffer=}24
i32@0:8^{__CVBuffer=}16^{?=[7{?=iii}][7^{__CVBuffer}]}24
i36@0:8i16^{__CVBuffer=}20^{__CVBuffer=}28
i36@0:8^{__CVBuffer=}16^{__CVBuffer=}24i32
i40@0:8^{__CVBuffer=}16^{__CVBuffer=}24i32i36
@"VCPFlowFeatureExtractor"
[7@"VCPFlowDecoder"]
@"VCPCorrelation"
@"VCPBackwarp"
[2{?="featureShape"[7{?="channels"i"height"i"width"i}]"feature"[7^{__CVBuffer}]}]
{?="correlations"[7^{__CVBuffer}]"flows"[7^{__CVBuffer}]"upscaledFlows"[7^{__CVBuffer}]"warpedBuffers"[7^{__CVBuffer}]}
{CLLocationCoordinate2D=dd}16@0:8
i44@0:8Q16Q24i32^^{__CVBuffer}36
i36@0:8^{__CVBuffer=}16^^{__CVBuffer}24i32
@40@0:8^{__CVBuffer=}16^{__CVBuffer=}24^@32
@52@0:8^{__CVBuffer=}16^{__CVBuffer=}24B32^{__CVBuffer=}36^@44
@"VCPImageMotionFlowAnalyzer"
i32@0:8q16^@24
@32@0:8@16Q24
i40@0:8@16@?24^Q32
i32@0:8@?16^Q24
@"AVAsset"
i48@0:8@16{?=qiIq}24
v28@0:8B16@20
v60@0:8B16f20f24f28f32f36f40B44f48f52B56
@"VNSceneprint"
@"VCPCNNPetsDetector"
i32@0:8[3[3f]]16[3f]24
i32@0:8[3f]16[3[3f]]24
i32@0:8[3f]16[3f]24
i24@0:8^{?=[4]}16
{Matrix<float, 12U, 1U, false>="m_data"[12f]}
{Matrix<float, 12U, 12U, false>="m_data"[144f]}
v24@0:8@"<PVFetchResultProtocol>"16
@"<PVFaceProtocol>"16@0:8
v24@0:8@"<PVFaceProtocol>"16
Q36@0:8B16Q20Q28
{CGRect={CGPoint=dd}{CGSize=dd}}32@0:8Q16Q24
{CGRect={CGPoint=dd}{CGSize=dd}}80@0:8Q16Q24{CGAffineTransform=dddddd}32
@"VNFaceObservation"
v24@0:8f16f20
v52@0:8^f16^f24^f32i40^f44
v48@0:8r^f16r^i24r^f32^f40
v48@0:8r^f16r^f24r^f32^f40
v32@0:8r^f16^f24
v52@0:8r^f16i24r^f28r^f36^f44
v36@0:8r^f16^f24B32
B24@0:8^f16
v56@0:8^f16^f24^f32^f40^f48
v44@0:8^f16^f24^f32i40
v68@0:8^f16^f24^f32^f40^f48^f56i64
{matrix<double, 6L, 1L, dlib::memory_manager_stateless_kernel_1<char>, dlib::row_major_layout>={layout<double, 6L, 1L, dlib::memory_manager_stateless_kernel_1<char>, 1>=[6d]}}16@0:8
B28@0:8i16B20B24
{?=[4]}16@0:8
^16@0:8
@"VCPFaceTensorModel"
^{?=ffi}
[8f]
[9f]
[12f]
[3f]
[126f]
[189f]
@"VCPPnPSolver"
[51f]
@24@0:8^@16
@"MADVITextLookupRequest"
@"<VICancellable>"
@"VCPProtoLine"
@"VCPProtoPoint"
B80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48
v48@0:8Q16@24@32@?40
v48@0:8Q16@"IOSurface"24@"NSDictionary"32@?<v@?@"NSDictionary"@"NSError">40
@28@0:8i16@20
v48@0:8Q16^{__CVBuffer=}24@32@?40
{CGPoint=dd}16@0:8
@48@0:8{CGPoint=dd}16{CGPoint=dd}32
f24@0:8Q16
v32@0:8^f16Q24
{?="list"^f"count"Q"size"Q}
@24@0:8^{__sFILE=*iiss{__sbuf=*i}i^v^?^?^?^?{__sbuf=*i}^{__sFILEX}i[3C][1C]{__sbuf=*i}iq}16
v32@0:8^f16^f24
v44@0:8^f16i24^f28^f36
^i16@0:8
@56@0:8@16Q24Q32Q40@48
{?="loopFadeLen"b1"loopPeriod"b1"loopStart"b1}
@28@0:8i16B20B24
i56@0:8^{__CVBuffer=}16^Q24@32^@40@?48
@"VCPCNNPetsKeypointsDetector"
i68@0:8@16@24@32@40@48@56f64
f80@0:8{?={?=qiIq}{?=qiIq}}16@64^i72
f64@0:8{?={?=qiIq}{?=qiIq}}16
i68@0:8{?={?=qiIq}{?=qiIq}}16f64
@"VCPVideoActivityDescriptor"
@68@0:8{?={?=qiIq}{?=qiIq}}16f64
f28@0:8@16f24
B72@0:8{?={?=qiIq}{?=qiIq}}16@64
B28@0:8@16f24
f72@0:8{?={?=qiIq}{?=qiIq}}16@64
f20@0:8f16
@28@0:8i16i20i24
@100@0:8Q16B24f28B32B36B40{?={?=qiIq}{?=qiIq}}44@92
i168@0:8@16@24@32@40@48@56@64@72@80@88@96@104@112@120@128@136@144{CGSize=dd}152
B64@0:8{?={?=qiIq}{?=qiIq}}16
@120@0:8@16{?={?=qiIq}{?=qiIq}}24{?={?=qiIq}{?=qiIq}}72
@112@0:8{?={?=qiIq}{?=qiIq}}16{?={?=qiIq}{?=qiIq}}64
{?={?=qiIq}{?=qiIq}}64@0:8{?={?=qiIq}{?=qiIq}}16
f68@0:8{?={?=qiIq}{?=qiIq}}16B64
@68@0:8{?={?=qiIq}{?=qiIq}}16B64
i64@0:8{array<float, 6UL>=[6f]}16{array<float, 6UL>=[6f]}40
B88@0:8^f16@24{?={?=qiIq}{?=qiIq}}32@80
{CGRect={CGPoint=dd}{CGSize=dd}}64@0:8{?={?=qiIq}{?=qiIq}}16
{?={?=qiIq}{?=qiIq}}68@0:8{?={?=qiIq}{?=qiIq}}16B64
@"AVAssetImageGenerator"
{array<float, 6UL>="__elems_"[6f]}
@"VCPColorNormalizationAnalyzer"
v40@0:8@16@24@?32
v32@0:8@"NSDictionary"16@?<v@?@"NSError">24
v32@0:8@"NSDictionary"16@?<v@?@"NSDictionary"@"NSError">24
v40@0:8@"NSData"16@"NSDictionary"24@?<v@?@"NSDictionary"@"NSError">32
@40@0:8@16@?24@?32
{CF<const opaqueCMFormatDescription *>="value_"^{opaqueCMFormatDescription}}
@"VCPHomeKitAnalysisSession"
i36@0:8^{sqlite3_stmt=}16i24@28
i40@0:8^{sqlite3_stmt=}16i24i28@32
i40@0:8@16^@24^q32
i32@0:8q16@24
i40@0:8q16@24@32
i40@0:8@16@24@32
@32@0:8Q16Q24
Q32@0:8Q16Q24
i32@0:8^q16@24
q24@0:8@16
i40@0:8^@16Q24@32
^{sqlite3=}
@"AVURLAsset"
^{__CVBuffer=}24@0:8Q16
^{__CVBuffer=}32@0:8Q16^I24
{CGAffineTransform=dddddd}20@0:8I16
i32@0:8^Q16^@24
@64@0:8@16@24@32@40@?48@?56
@36@0:8@16B24^@28
@"AVAudioPCMBuffer"
^{LkFsMeasure=IIqBIIddddqqIII[30[6f]]^f^f^f^{DspLibBiquad}^{DspLibBiquad}}
^{CAStreamBasicDescription=dIIIIIIII}
{vector<double, std::allocator<double>>="__begin_"^d"__end_"^d"__end_cap_"{__compressed_pair<double *, std::allocator<double>>="__value_"^d}}
{vector<float, std::allocator<float>>="__begin_"^f"__end_"^f"__end_cap_"{__compressed_pair<float *, std::allocator<float>>="__value_"^f}}
^{AUOutputBL={CAStreamBasicDescription=dIIIIIIII}*^{AudioBufferList}III}
i32@0:8^{CGImage=}16^@24
^{CGImageMetadata=}24@0:8@16
@88@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48@80
@72@0:8r^{CGImageSource=}16{CGRect={CGPoint=dd}{CGSize=dd}}24@56^@64
@72@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24@56^@64
{CGRect={CGPoint=dd}{CGSize=dd}}32@0:8@16^@24
@"VCPFaceAnalyzer"
@"MADVIMachineReadableCodeDetectionRequest"
Q28@0:8@16f24
@"VNTorsoprint"
@36@0:8i16@20@?28
i48@0:8^{__CVBuffer=}16^{__CVBuffer=}24^{__CVBuffer=}32^{__CVBuffer=}40
i56@0:8^{__CVBuffer=}16^{__CVBuffer=}24^{__CVBuffer=}32^{__CVBuffer=}40@?48
@52@0:8@16^{__sFILE=*iiss{__sbuf=*i}i^v^?^?^?^?{__sbuf=*i}^{__sFILEX}i[3C][1C]{__sbuf=*i}iq}24C32*36^f44
i44@0:8^{__CVBuffer=}16^f24i32^f36
@80@0:8Q16@24{CGSize=dd}32{CGRect={CGPoint=dd}{CGSize=dd}}48
v40@0:8Q16Q24@?32
@44@0:8@16@24B32@?36
@48@0:8@16d24Q32@?40
@"<PVFaceProtocol>"40@0:8@"<PVPersonProtocol>"16@"NSMapTable"24@?<v@?f^B>32
@"NSString"40@0:8@"PVPersonClusterManager"16@"NSSet"24@?<v@?f^B>32
@"NSArray"44@0:8@"PVPersonClusterManager"16@"NSSet"24B32@?<v@?f^B>36
@"NSArray"48@0:8@"NSArray"16d24Q32@?<d@?@@>40
@28@0:8@16i24
@36@0:8@16i24@28
@40@0:8@16@?24^@32
v56@0:8@16@24^@32@?40@48
B48@0:8@16Q24@?32^@40
B40@0:8@16@?24^@32
B48@0:8@16@24@?32^@40
B88@0:8@16@24@32@40@48@56@?64@?72^@80
B44@0:8@16B24@?28^@36
@48@0:8@16@24@32@?40
B48@0:8@16Q24@32^@40
B72@0:8@16@24@32@40@?48@56^@64
B44@0:8@16B24@28^@36
B56@0:8@16@24@32^@40^@48
@56@0:8@16@24@32@40^@48
v56@0:8@16@?24@32@40@?48
B40@0:8Q16@?24^@32
@32@0:8@?16Q24
v48@0:8@16@24@32@?40
v40@0:8@16@24@32
v112@0:8^@16^@24^@32^@40^@48^@56^@64^@72^@80@88@96@?104
v56@0:8^@16^@24^@32@40@48
B112@0:8@16@24@32@40@48@56@64@72@?80@?88@96^@104
Q32@0:8Q16@24
v64@0:8@16@24@32@40@48@56
v56@0:8@16@24@32^@40@?48
v56@0:8@16@24@?32@?40@48
v48@0:8@16@?24@32@?40
{?="underExpose"b1}
@"PHAsset"
{CGSize=dd}16@0:8
@"MADVIDocumentRecognitionRequest"
@"VNPersonsModel"
@"MADPersonIdentificationRequest"
f40@0:8*16i24i28q32
i40@0:8^f16@24^{__CVBuffer=}32
v48@0:8@16i24i28^f32^f40
f48@0:8{CGPoint=dd}16{CGPoint=dd}32
@36@0:8@16B24Q28
v40@0:8@16@24f32f36
i40@0:8^{__CVBuffer=}16^f24@?32
i32@0:8^f16^{__CVBuffer=}24
i48@0:8^{CGRect={CGPoint=dd}{CGSize=dd}}16^{__CVBuffer=}24@32i40i44
i52@0:8^{__CVBuffer=}16^Q24f32^@36@?44
[16f]
@"VCPCNNBlurAnalyzer"
i40@0:8^{__CVBuffer=}16^{?=[7{?=iii}][7^{__CVBuffer}]}24@?32
i36@0:8^{?=iii}16i24i28i32
{?="quality"b1"statsFlags"b1"typesWide"b1}
@52@0:8^{__CVBuffer=}16I24@28@36@44
i32@0:8^^{__CVBuffer}16^I24
v28@0:8@16B24
{CF<__CVBuffer *>="value_"^{__CVBuffer}}
@56@0:8@16@24@32@40@48
@"UTType"
@52@0:8@16^{__CVBuffer=}24I32@36@44
@80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16^{__CVBuffer=}48{?=qiIq}56
@"VCPCtrTracker"
@56@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24
B40@0:8@16^@24^@32
B56@0:8@16@24@32@40^@48
i40@0:8^Q16@?24@?32
i40@0:8@16@24^@32
i44@0:8@16B24^@28^@36
B36@0:8@16B24^@28
@24@0:8B16B20
@32@0:8Q16B24B28
i32@0:8@?16@?24
i40@0:8@?16@?24B32B36
B24@0:8@?16
B36@0:8Q16B24@?28
i60@0:8Q16B24B28B32^B36@?44@?52
@"VNEntityIdentificationModel"
f24@0:8^f16
i48@0:8^f16*24f32i36@?40
v56@0:8*16q24^f32q40i48i52
v28@0:8B16@?20
v44@0:8@16B24@28@?36
@64@0:8@16@24@32@?40@48^@56
@56@0:8@16@24@32@?40^@48
v64@0:8@16@24@32@40@?48@?56
v40@0:8@16@?24@?32
v48@0:8@16@?24@?32@?40
@"VCPClusterer"
@40@0:8@16r^{?={?=qiIq}{?=qiIq}}24r^{?=qiIq}32
^{opaqueCMSampleBuffer=}
{array<float, 6UL>=[6f]}16@0:8
v40@0:8{array<float, 6UL>=[6f]}16
v40@0:8i16i20^f24^f32
{CGRect={CGPoint=dd}{CGSize=dd}}56@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16f48f52
f80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48
i92@0:8@16@24i32^{__CVBuffer=}36{?=qiIq}44{?=qiIq}68
@"VCPImagePetsKeypointsAnalyzer"
@"VCPVideoObjectTracker"
@44@0:8{?=qiIq}16f40
@76@0:8{?={?=qiIq}{?=qiIq}}16f64@68
@"VCPVideoKeyFrameResult"
{?=ii}24@0:8@16
B32@0:8^{__CVBuffer=}16@24
@"AVAssetTrack"
@"VCPPhotosFace"
@"MLModel"
@28@0:8i16f20f24
f24@0:8f16B20
@"MADVIVisualSearchGatingRequest"
B44@0:8@16i24@28^@36
i40@0:8^@16^@24@32
i52@0:8^@16@24B32Q36Q44
i56@0:8^@16@24@32Q40Q48
i72@0:8^@16^I24^i32^i40@48@56@64
i52@0:8@16@24@32B40^@44
i32@0:8@16^@24
@"VCPFaceMerger"
v32@0:8@"<SNRequest>"16@"<SNResult>"24
v32@0:8@"<SNRequest>"16@"NSError"24
v24@0:8@"<SNRequest>"16
@52@0:8{?=qiIq}16f40@44
v36@0:8r^{?=qiIq}16r^{?=qiIq}24f32
i52@0:8^{opaqueCMSampleBuffer=}16{?=qiIq}24i48
@"SNAudioStreamAnalyzer"
@"VCPCNNMetalContext"
Q40@0:8Q16Q24Q32
@20@0:8I16
@"MADVIVisualSearchRequest"
{CGRect={CGPoint=dd}{CGSize=dd}}64@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGSize=dd}48
{CGRect={CGPoint=dd}{CGSize=dd}}80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48
{CGPoint=dd}64@0:8{CGPoint=dd}16{CGRect={CGPoint=dd}{CGSize=dd}}32
i56@0:8^{__CVBuffer=}16{CGRect={CGPoint=dd}{CGSize=dd}}24
B72@0:8{?=qiIq}16{?=qiIq}40^@64
@"VCPVideoProcessorSession"
@"VCPProtoVideoKeyFrame"
@24@0:8i16i20
i52@0:8^{__sFILE=*iiss{__sbuf=*i}i^v^?^?^?^?{__sbuf=*i}^{__sFILEX}i[3C][1C]{__sbuf=*i}iq}16^f24^f32i40i44i48
{Scaler="pool_"^{__CVPixelBufferPool}"width_"i"height_"i"crop_rect_"{CGRect="origin"{CGPoint="x"d"y"d}"size"{CGSize="width"d"height"d}}"sw_scaler_"^{OpaqueVTPixelTransferSession}}
{vector<__CVBuffer *, std::allocator<__CVBuffer *>>="__begin_"^^{__CVBuffer}"__end_"^^{__CVBuffer}"__end_cap_"{__compressed_pair<__CVBuffer **, std::allocator<__CVBuffer *>>="__value_"^^{__CVBuffer}}}
v80@0:8{?={?=qiIq}{?=qiIq}}16@64@72
v96@0:8@16@24{?={?=qiIq}{?=qiIq}}32@80@88
@32@0:8@16d24
@36@0:8f16f20f24f28f32
{CGRect={CGPoint=dd}{CGSize=dd}}24@0:8f16f20
i64@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16^{__CVBuffer=}48^q56
@40@0:8@16@24Q32
@72@0:8{?={?=qiIq}{?=qiIq}}16^Q64
@40@0:8@16r^{?={?=qiIq}{?=qiIq}}24Q32
i48@0:8@16r^{?={?=qiIq}{?=qiIq}}24Q32@?40
i64@0:8@16{?=qiIq}24Q48@?56
@32@0:8@?16^B24
@"VCPAsset"
@48@0:8i16B20B24@28@36i44
i48@0:8[21{CGPoint=dd}]16^f24@32@40
@"VCPCNNHandsDetector"
@"VCPCNNHandKeypointsDetector"
@48@0:8@16@24@?32@?40
i48@0:8^{CGRect={CGPoint=dd}{CGSize=dd}}16^{__CVBuffer=}24^f32i40i44
f52@0:8^f16i24i28i32*36f44i48
i52@0:8^{__CVBuffer=}16^f24^f32f40@?44
@44@0:8@16@24@32i40
Q40@0:8^{?=Q^@^Q[5Q]}16^@24Q32
@56@0:8@16@24Q32@?40@?48
@"VCPProtoLivePhotoVariationParams"
{?="epoch"b1"flags"b1}
@28@0:8Q16B24
i48@0:8^{opaqueCMSampleBuffer=}16{?=qiIq}24
i24@0:8^{opaqueCMSampleBuffer=}16
i40@0:8@16@?24^@32
{AudioTimeStamp="mSampleTime"d"mHostTime"Q"mRateScalar"d"mWordClockTime"Q"mSMPTETime"{SMPTETime="mSubframes"s"mSubframeDivisor"s"mCounter"I"mType"I"mFlags"I"mHours"s"mMinutes"s"mSeconds"s"mFrames"s}"mFlags"I"mReserved"I}
{AudioBufferList="mNumberBuffers"I"mBuffers"[1{AudioBuffer="mNumberChannels"I"mDataByteSize"I"mData"^v}]}
@"VCPVoiceDetector"
@"VCPAudioClassifier"
@"VCPLoudnessAnalyzer"
@"VCPSongDetector"
i32@0:8^{__CVBuffer=}16^f24
i72@0:8^f16^{__CVBuffer=}24i32i36{CGRect={CGPoint=dd}{CGSize=dd}}40
@"VCPFaceClusterer"
@36@0:8i16B20B24@28
@"VCPCNNPersonDetector"
@"VCPCNNPersonKeypointsDetector"
@"MADVIRectangleDetectionRequest"
B32@0:8q16Q24
B24@0:8q16
i32@0:8@16q24
i56@0:8^@16@24@32@40Q48
i56@0:8^@16@24q32Q40Q48
i40@0:8^@16^{__CVBuffer=}24@32
i44@0:8^@16^{__CVBuffer=}24Q32B40
i32@0:8^@16^{__CVBuffer=}24
i72@0:8^@16q24Q32Q40^{__CVBuffer=}48^{__CVBuffer=}56@64
v56@0:8@16q24Q32Q40@?48
@"VCPPreAnalysisImageLoader"
@"VCPPoolBasedPixelBufferCreator"
@"VCPMAMLModel"
@44@0:8@16r^{?={?=qiIq}{?=qiIq}}24@32B40
i48@0:8^f16^{__CVBuffer=}24i32i36@40
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
@32@0:8r^16Q24
r^16@0:8
@96@0:8{?=[4]}16@80@88
@"VCPFaceGeometry"
{?="columns"[4]}
@80@0:8Q16{CGAffineTransform=dddddd}24@72
@40@0:8Q16@24@32
@88@0:8Q16{CGAffineTransform=dddddd}24f72@76B84
B32@0:8r^{CGAffineTransform=dddddd}16@24
{CGAffineTransform=dddddd}28@0:8i16^{__CVBuffer=}20
{?=[4]}84@0:8{?=[4]}16i80
@88@0:8^{__CVBuffer=}16{?=qiIq}24{?=qiIq}48@72^@80
i88@0:8^{__CVBuffer=}16{?=qiIq}24{?=qiIq}48@72@?80
i72@0:8{?={?=qiIq}{?=qiIq}}16@64
B68@0:8{?=qiIq}16{?=qiIq}40B64
@"VCPVideoFacePoseAnalyzer"
@"VCPVideoFaceMeshAnalyzer"
@"VCPFullVideoAnalyzer"
@"VCPAudioAnalyzer"
@"VCPVideoFullFaceDetector"
@"VCPSceneChangeAnalyzer"
@"VCPLightMotionAnalyzer"
@"VCPTrimAnalyzer"
@"VCPHomeKitMotionAnalyzer"
^{Rotator=^{__CVPixelBufferPool}iii^{OpaqueVTPixelRotationSession}}
i32@0:8^{__CVBuffer=}16@?24
i92@0:8^{__CVBuffer=}16^v24{?=qiIq}32{?=qiIq}56i80@?84
@"VCPMotionFlowRequest"
i52@0:8@16B24@?28^Q36^@44
@96@0:8{CGAffineTransform=dddddd}16@64@72B80B84@?88
@40@0:8i16i20Q24Q32
i56@0:8i16i20r^f24^f32Q40Q48
i60@0:8{Kernel=^fQQ}16f40f44f48f52f56
^^{Kernel}
v48@0:8@"NSDictionary"16@"NSString"24@"NSURL"32@?<v@?>40
v40@0:8@"NSString"16@"NSURL"24@?<v@?@"NSString">32
@60@0:8@16Q24@32@40B48@?52
@48@0:8@16@24Q32^@40
@64@0:8Q16@24@32@40@48@?56
i48@0:8@16Q24@?32@?40
v40@0:8@16@24^q32
v88@0:8@16#24{?={?=qiIq}{?=qiIq}}32@80
@108@0:8#16@24@32@40{?={?=qiIq}{?=qiIq}}48B96^B100
v48@0:8@16@24^q32^f40
v144@0:8@16{?={?=qiIq}{?=qiIq}}24@72{?={?=qiIq}{?=qiIq}}80^q128^f136
i64@0:8Q16@24@32@?40@?48@56
i52@0:8@16Q24B32@?36@?44
@52@0:8Q16@24B32@?36^@44
@56@0:8Q16@24@32@?40^@48
@44@0:8@16@24Q32B40
{?={?=qiIq}{?=qiIq}}32@0:8@16@24
{atomic<int>="__a_"{__cxx_atomic_impl<int, std::__cxx_atomic_base_impl<int>>="__a_value"Ai}}
i44@0:8^f16i24i28B32*36
@32@0:8Q16^{opaqueCMFormatDescription=}24
B24@0:8^{opaqueCMFormatDescription=}16
{CGSize=dd}24@0:8^{opaqueCMFormatDescription=}16
@24@0:8^{opaqueCMFormatDescription=}16
^{__CFData=}24@0:8^{opaqueCMFormatDescription=}16
^{__CFData=}28@0:8I16^{__CFData=}20
i32@0:8^{FigLivePhotoMetadata=I{FigLivePhotoMetadataV1Struct=fqffffffccSI[0{FigLivePhotoDetectedFaceV1Struct=qffffisS}]}}16@24
{CGVector="dx"d"dy"d}
@"NSMutableData"
@"VCPVideoMetaFocusAnalyzer"
@"VCPVideoMetaMotionAnalyzer"
@"VCPVideoMetaLensSwitchAnalyzer"
@32@0:8{CGPoint=dd}16
@36@0:8i16i20i24@28
@36@0:8^f16i24i28f32
i28@0:8i16@20
@44@0:8@16i24i28i32i36i40
v60@0:8*16i24i28i32^f36^f44^f52
v36@0:8^f16^f24i32
^{LandmarkDetector=iiiiiiiB^f^f^f^i^{ZPoint}^{RegressionTree}^?}
#20@0:8i16
@36@0:8i16i20i24B28B32
@"VNSession"
@40@0:8i16B20B24@28i36
i48@0:8^f16i24i28@32[3[2f]]40
i36@0:8r^v16@24i32
i72@0:8*16i24i28i32{CGPoint=dd}36{CGPoint=dd}52i68
i44@0:8*16i24i28i32^{CGPoint=dd}36
B32@0:8@"AVAssetResourceLoader"16@"AVAssetResourceLoadingRequest"24
B32@0:8@"AVAssetResourceLoader"16@"AVAssetResourceRenewalRequest"24
v32@0:8@"AVAssetResourceLoader"16@"AVAssetResourceLoadingRequest"24
B32@0:8@"AVAssetResourceLoader"16@"NSURLAuthenticationChallenge"24
v32@0:8@"AVAssetResourceLoader"16@"NSURLAuthenticationChallenge"24
@32@0:8#16Q24
@"NSURLSessionDataTask"
^{__CVBuffer=}56@0:8^{__CVBuffer=}16{CGRect={CGPoint=dd}{CGSize=dd}}24
@"VCPSegment"
^{HinkleyDetector=ffi{HinkleyStats=ffff}}
@52@0:8B16@20I28B32B36B40@?44
i40@0:8^{__CVBuffer=}16^{__CVBuffer=}24^{__CVBuffer=}32
@"<MTLDeviceSPI>"
@"<MTLCommandQueue>"
@"MPSImageBilinearScale"
@"MPSImageSpatioTemporalGuidedFilter"
v24@0:8@"PHPhotoLibrary"16
{CGSize=dd}32@0:8@16@24
i40@0:8^@16#24@32
^{__CVBuffer=}36@0:8@16@24i32
i52@0:8^@16#24@32@40B48
i48@0:8^f16@24@32@40
i40@0:8^f16@24@32
v52@0:8f16@20Q28Q36Q44
v44@0:8f16@20Q28Q36
i40@0:8@16^@24^@32
i32@0:8^@16^@24
v56@0:8@16@24@32@?40@?48
B48@0:8@16^@24@?32@?40
i48@0:8^@16^@24@?32@?40
d80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48
i72@0:8@16^@24^@32^@40^@48@?56@?64
i80@0:8@16@24@32@40@48^@56@?64@?72
i48@0:8@16@24@32@40
i64@0:8@16@24@32^@40@?48@?56
i56@0:8@16@24^@32@?40@?48
i48@0:8@16^@24@?32@?40
@"MADVIUserFeedbackRequest"
@88@0:8@16{CGAffineTransform=dddddd}24Q72^{opaqueCMFormatDescription=}80
B40@0:8@16#24@32
v32@0:8{CGPoint=dd}16
{CGPoint="x"d"y"d}
^{__CVBuffer=}16@0:8
{CGRect={CGPoint=dd}{CGSize=dd}}24@0:8@16
@"PHFetchResult"
i48@0:8^{CGPoint=dd}16[21f]24@32@40
i40@0:8^f16^{__CVBuffer=}24@32
{vector<int, std::allocator<int>>="__begin_"^i"__end_"^i"__end_cap_"{__compressed_pair<int *, std::allocator<int>>="__value_"^i}}
@"VCPCNNFastGestureRecognition"
@28@0:8f16B20B24
v40@0:8i16i20i24^f28i36
i84@0:8^{__CVBuffer=}16{CGRect={CGPoint=dd}{CGSize=dd}}24i56{?=qiIq}60
r^f16@0:8
@"VCPRTLandmarkDetector"
@"VCPFaceShapeModel"
[5@"VCPLandmarkValidator"]
B40@0:8@16Q24Q32
i32@0:8^^{__CVBuffer}16i24B28
i56@0:8@16i24Q28^^{__CVBuffer}36^I44B52
i48@0:8^{CGImage=}16i24I28Q32^^{__CVBuffer}40
i60@0:8^{CGImageSource=}16@24i32Q36^I44^^{__CVBuffer}52
^{__CVBuffer=}56@0:8i16Q20@28@36B44^I48
^{__CVBuffer=}28@0:8@16i24
^{__CVBuffer=}36@0:8@16i24Q28
^{__CVBuffer=}44@0:8@16i24Q28^I36
^{__CVBuffer=}32@0:8i16@20B28
^{__CVBuffer=}48@0:8i16Q20@28B36^I40
^{__CVBuffer=}40@0:8i16@20B28^I32
^{__CVBuffer=}36@0:8i16Q20@28
^{__CVBuffer=}44@0:8i16Q20@28^I36
i44@0:8^{__CVBuffer=}16^@24Q32B40
^{CMPhotoCompressionSession=}
^{CMPhotoDecompressionSession=}
i64@0:8^f16i24i28i32i36i40^{CGPoint=dd}44^f52f60
i52@0:8^{__CVBuffer=}16@24[21{CGPoint=dd}]32[21f]40B48
^{OpaqueAudioComponentInstance=}
@"VCPVideoMetaFocusSegment"
@48@0:8q16{?=qiIq}24
v48@0:8q16{?=qiIq}24
i32@0:8Q16Q24
i40@0:8^^{__CVBuffer}16Q24Q32
v52@0:8Q16@24i32@36@?44
v52@0:8Q16@"NSData"24i32@"NSDictionary"36@?<v@?@"NSDictionary"@"NSError">44
v52@0:8Q16@"IOSurface"24i32@"NSDictionary"36@?<v@?@"NSDictionary"@"NSError">44
v44@0:8i16@"NSData"20@"NSDictionary"28@?<v@?@"NSString"@"NSError">36
v36@0:8i16@"NSDictionary"20@?<v@?@"NSDictionary"@"NSError">28
@40@0:8@16@24d32
@24@0:8d16
v48@0:8@16@24Q32Q40
@72@0:8@16@24@32Q40Q48Q56Q64
{?={?=qiIq}{?=qiIq}}32@0:8@16f24B28
i48@0:8@16f24f28f32B36@?40
i56@0:8B16@20@28f36f40f44B48B52
f28@0:8f16@20
f48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
@36@0:8q16q24I32
i44@0:8^^{__CVPixelBufferPool}16q24q32I40
i24@0:8^^{__CVBuffer}16
{CF<__CVPixelBufferPool *>="value_"^{__CVPixelBufferPool}}
i48@0:8@16@24@?32^@40
@44@0:8B16@20B28B32B36B40
i28@0:8f16i20i24
i56@0:8@16@24@32@40@48
@"<MTLComputePipelineState>"
@"<MTLLibrary>"
i40@0:8^{__CVBuffer=}16^^{__CVBuffer}24Q32
i64@0:8@16Q24@32^^{__CVBuffer}40^^{__CVBuffer}48^@56
@"VCPSceneProcessingImageManager"
{CF<OpaqueVTPixelTransferSession *>="value_"^{OpaqueVTPixelTransferSession}}
@"<MTLCommandBuffer>"
i40@0:8^Q16^Q24@?32
@32@0:8@?16@24
v36@0:8@16Q24B32
i48@0:8@16@24^@32^@40
v44@0:8@16Q24B32@?36
i88@0:8{?=qiIq}16{?=qiIq}40{?=qiIq}64
f56@0:8i16i20^{?={?=qiIq}{?=qiIq}}24{?=qiIq}32
B40@0:8{?=qiIq}16
B64@0:8{?=qiIq}16{?=qiIq}40
@"VCPActionAnalyzer"
B24@0:8^v16
[10f]
@"VCPSceneChangeSegment"
v40@0:8q16@24@32
v40@0:8d16@24@32
i40@0:8^^{__CVBuffer}16Q24^{__CVBuffer=}32
i32@0:8^^{__CVBuffer}16Q24
i40@0:8^^{__CVBuffer}16^{CGColorSpace=}24^{__CVBuffer=}32
i56@0:8^^{__CVBuffer}16^^{__CVBuffer}24^^{__CVBuffer}32@40Q48
i48@0:8^{__CVBuffer=}16^^{__CVBuffer}24Q32Q40
@76@0:8{CGAffineTransform=dddddd}16@64B72
@40@0:8f16{CGPoint=dd}20B36
v32@0:8r^f16^v24
i32@0:8^v16^v24
i40@0:8^v16^v24^f32
f32@0:8[3[3f]]16[3f]24
i56@0:8^v16r^f24[3[3f]]32[3f]40^f48
i56@0:8^v16^v24[4f]32^v40^v48
i40@0:8^v16^v24[4f]32
i36@0:8r^f16r^f24i32
v80@0:8{?=[4]}16
[4[3f]]
@"SHMutableSignature"
@56@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48
Q56@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24
i56@0:8@16Q24@?32@?40@?48
^q16@0:8
v32@0:8^q16Q24
{?="list"^q"count"Q"size"Q}
@20@0:8f16
i80@0:8^{__CVBuffer=}16{CGRect={CGPoint=dd}{CGSize=dd}}24{?=qiIq}56
@"VCPCNNFaceLandmarkDetector"
@"VCPVideoFacePoseFilter"
[14f]
[21f]
v24@0:8^{EncodeStats=^^?^B^B^{MotionVector}^{MotionVector}^{MotionVector}^{MotionVector}^S^S^I^S^S^S^S^S^S^S^S^S^S^SIBBBii}16
@24@0:8s16B20
[200@"VCPCNNBlock"]
@"VCPMADResourceManager"
@"VCPMADResource"
q24@0:8q16
@"VCPTimer"
@"NSObject<OS_os_transaction>"
i88@0:8^{__CVBuffer=}16^v24{?=qiIq}32{?=qiIq}56@?80
@72@0:8@16{CGSize=dd}24{CGRect={CGPoint=dd}{CGSize=dd}}40
v68@0:8{CGAffineTransform=dddddd}16B64
@32@0:8^{CGImage=}16^@24
B32@0:8^{CGImage=}16^@24
@"MLMultiArray"
@32@0:8^{__CVBuffer=}16^@24
v32@0:8^{__CVBuffer=}16^{CGPoint=dd}24
^{CGPoint=dd}16@0:8
v24@0:8^{CGPoint=dd}16
^{CGPoint=dd}
^{?=^{?}^{?}^{?}^{tplTracker_resampler_context}^{?}}
mcpl
v024
v024
mcpl
gepj
ARGB
