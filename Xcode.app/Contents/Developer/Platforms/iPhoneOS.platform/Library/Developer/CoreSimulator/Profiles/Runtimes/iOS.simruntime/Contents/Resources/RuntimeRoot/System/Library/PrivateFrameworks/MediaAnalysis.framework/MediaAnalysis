@(#)PROGRAM:MediaAnalysis  PROJECT:MediaAnalysis-1
fff>
mcpl)
333?
@N2ma15EncodeStatsAVE1E
B`e>;
$CV&
C2wACA
?16MAComputeRequest
>N2ma19SubtleMotionSegmentE
?33s?
@C22MAImageAnalysisRequest
NSt3__120__shared_ptr_emplaceI25VCPImageHumanPoseAnalyzerNS_9allocatorIS1_EEEE
fff?
N2ma17SlowMotionSegmentE
ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+%
14VCPProtoBounds
B>fff?
G!?=
Ga>R
=q=J
ff&?R
Q8?H
?N4dlib7array2dIhNS_33memory_manager_stateless_kernel_1IcEEEE
N4dlib10enumerableIhEE
N4dlib33memory_manager_stateless_kernel_1IhEE
?333?
?333?33
>N2ma12TrackSegmentE
N2ma11EncodeStatsE
>N2ma17DescriptorSegmentE
u?ff&?
>fff
'7NSt3__120__shared_ptr_emplaceI21VCPCNNEspressoContextNS_9allocatorIS1_EEEE
20MAImageComputeResult
<0L&=!
<yX(=4
<0L&=!
<yX(=
b=;p
Sc=;p
<5^:
e=X94
Y=X94</n#
=B`e<M
u`=e
w=B`e
N2ma18ObstructionSegmentE
MbP?
?ffffff
N4dlib17sequence_kernel_2INS_21lbfgs_search_strategy11data_helperENS_33memory_manager_stateless_kernel_1IcEEEE
N4dlib10enumerableINS_21lbfgs_search_strategy11data_helperEEE
N4dlib7removerINS_21lbfgs_search_strategy11data_helperEEE
N4dlib33memory_manager_stateless_kernel_1IdEE
NSt3__110__function6__funcINS_6__bindIPFdRKN4dlib6matrixIdLl0ELl0ENS3_33memory_manager_stateless_kernel_1IcEENS3_16row_major_layoutEEEPfSB_SB_SB_bEJRKNS_12placeholders4__phILi1EEERSB_SJ_RA12_fRA126_fbEEENS_9allocatorISO_EEFdS8_EEE
NSt3__110__function6__baseIFdN4dlib6matrixIdLl0ELl0ENS2_33memory_manager_stateless_kernel_1IcEENS2_16row_major_layoutEEEEEE
NSt3__16__bindIPFdRKN4dlib6matrixIdLl0ELl0ENS1_33memory_manager_stateless_kernel_1IcEENS1_16row_major_layoutEEEPfS9_S9_S9_bEJRKNS_12placeholders4__phILi1EEERS9_SH_RA12_fRA126_fbEEE
NSt3__118__weak_result_typeIPFdRKN4dlib6matrixIdLl0ELl0ENS1_33memory_manager_stateless_kernel_1IcEENS1_16row_major_layoutEEEPfS9_S9_S9_bEEE
NSt3__110__function6__funcINS_6__bindIPFN4dlib6matrixIdLl0ELl0ENS3_33memory_manager_stateless_kernel_1IcEENS3_16row_major_layoutEEERKS8_PfSB_SB_SB_bEJRKNS_12placeholders4__phILi1EEERSB_SJ_RA12_fRA126_fbEEENS_9allocatorISO_EEFS8_S8_EEE
NSt3__110__function6__baseIFN4dlib6matrixIdLl0ELl0ENS2_33memory_manager_stateless_kernel_1IcEENS2_16row_major_layoutEEES7_EEE
NSt3__16__bindIPFN4dlib6matrixIdLl0ELl0ENS1_33memory_manager_stateless_kernel_1IcEENS1_16row_major_layoutEEERKS6_PfS9_S9_S9_bEJRKNS_12placeholders4__phILi1EEERS9_SH_RA12_fRA126_fbEEE
NSt3__118__weak_result_typeIPFN4dlib6matrixIdLl0ELl0ENS1_33memory_manager_stateless_kernel_1IcEENS1_16row_major_layoutEEERKS6_PfS9_S9_S9_bEEE
NSt3__117bad_function_callE
N4dlib11fatal_errorE
N4dlib5errorE
NSt3__110__function6__funcINS_6__bindIPFdRKN4dlib6matrixIdLl0ELl0ENS3_33memory_manager_stateless_kernel_1IcEENS3_16row_major_layoutEEEPfSB_SB_SB_SB_SB_SB_PiSB_SB_EJRKNS_12placeholders4__phILi1EEERSB_RA12_fSK_SK_SK_SK_SB_SC_SK_SK_EEENS_9allocatorISN_EEFdS8_EEE
NSt3__16__bindIPFdRKN4dlib6matrixIdLl0ELl0ENS1_33memory_manager_stateless_kernel_1IcEENS1_16row_major_layoutEEEPfS9_S9_S9_S9_S9_S9_PiS9_S9_EJRKNS_12placeholders4__phILi1EEERS9_RA12_fSI_SI_SI_SI_S9_SA_SI_SI_EEE
NSt3__118__weak_result_typeIPFdRKN4dlib6matrixIdLl0ELl0ENS1_33memory_manager_stateless_kernel_1IcEENS1_16row_major_layoutEEEPfS9_S9_S9_S9_S9_S9_PiS9_S9_EEE
NSt3__110__function6__funcINS_6__bindIPFN4dlib6matrixIdLl0ELl0ENS3_33memory_manager_stateless_kernel_1IcEENS3_16row_major_layoutEEERKS8_PfSB_SB_SB_SB_SB_SB_PiSB_SB_SB_EJRKNS_12placeholders4__phILi1EEERSB_RA12_fSK_SK_SK_SK_SB_SC_SK_SK_SK_EEENS_9allocatorISN_EEFS8_S8_EEE
NSt3__16__bindIPFN4dlib6matrixIdLl0ELl0ENS1_33memory_manager_stateless_kernel_1IcEENS1_16row_major_layoutEEERKS6_PfS9_S9_S9_S9_S9_S9_PiS9_S9_S9_EJRKNS_12placeholders4__phILi1EEERS9_RA12_fSI_SI_SI_SI_S9_SA_SI_SI_SI_EEE
NSt3__118__weak_result_typeIPFN4dlib6matrixIdLl0ELl0ENS1_33memory_manager_stateless_kernel_1IcEENS1_16row_major_layoutEEERKS6_PfS9_S9_S9_S9_S9_S9_PiS9_S9_S9_EEE
NSt3__110__function6__funcINS_6__bindIPFdRKN4dlib6matrixIdLl0ELl0ENS3_33memory_manager_stateless_kernel_1IcEENS3_16row_major_layoutEEEPfSB_EJRKNS_12placeholders4__phILi1EEERA126_fRA189_fEEENS_9allocatorISN_EEFdS8_EEE
NSt3__16__bindIPFdRKN4dlib6matrixIdLl0ELl0ENS1_33memory_manager_stateless_kernel_1IcEENS1_16row_major_layoutEEEPfS9_EJRKNS_12placeholders4__phILi1EEERA126_fRA189_fEEE
NSt3__118__weak_result_typeIPFdRKN4dlib6matrixIdLl0ELl0ENS1_33memory_manager_stateless_kernel_1IcEENS1_16row_major_layoutEEEPfS9_EEE
=AB/'
R[DmPJ>
@Z_g@
#=H!
@Aff
@333?
>43s?433?
333?43s?
@333?
?N2ma20SubjectMotionSegmentE
?28VCPProtoImageHumanPoseResult
@oDA
ffffff
333333
N2ma14QualitySegmentE
N2ma19CameraMotionSegmentE
?N2ma19MovingObjectSegmentE
?N2ma22InterestingnessSegmentE
16VCPProtoKeypoint
A22MAMovieAnalysisRequest
*>)\
@gEff
N2ma12SceneSegmentE
333333
]@lwh
N2ma15RotationSegmentE
N2ma15EncodeStatsAVE2E
N2ma13EncodeStatsHWE
BN2ma24FineSubjectMotionSegmentE
333?fff?ff
N2ma7SegmentE
N2ma13EncodeStatsSWE
Q9RI
Q9RI
7:RI
Q9RI
d*;4
>;_)K;
DX;B`e;
{r;l
k;B`e;
Q;_)K;
#;RI
7:RI
Q9RI
d*;4
7;_)K;
DX;B`e;
{r;o
{r;B`e;
DX;_)K;4
d*;RI
7:RI
Q9RI
7;_)K;
y;KY
3"<U
-<X94<
b<B`e<
4o<E
{r<!
ew<l
{r<E
h<B`e<e
#9<X94<
3"<RI
^;_)K;4
7:RI
Q9RI
k;KY
Q:RI
Q9RI
k:RI
DX;$
d*<4
?F<4
DX;4
Q:RI
>;B`e;'
#<X94<
z<KY
$=yX(=V
7=5^:=[
2D=]mE=
?F=]mE=
2D=\
<=5^:=
-2=2
+=yX(=
D<X94<
;B`e;
>;RI
{r<&
=R' =T
b=B`e=B>h=h
4o= Aq=
{r=F
{r= Aq=
(m=h
j=B>h=B`e=e
WJ=9
E6=|
%=R' =Qk
k:RI
7;B`e;
?$=V
b=B>h=D
s=Gry=
\~=n
\~=Gry=F
m=B>h=e
?$=v
;B`e;4
DX;'
3"<4
=R' =U
(=W[1=Z
B=_)K=a
S=d]\=
d=d]\=a
S=_)K=\
9=W[1=U
(=R' =P
j<<b
ew=I
{r<b
j<<>
ew<M
ew<>
=yX(=
A=;pN=
h=k+v=n
=k+v=
[=;pN=
5=yX(=
ew<b
7:RI
{r<M
7x=J{
/>:#
O/<N
=yX(=Y
U=B`e=
9#>/
$>0L&>
d*>1
'>0L&>/
Yu=B`e=
?F=Y
7=yX(=u
7;KY
=z6+=
/;=:
K=d]\=D
m=I.
V,>i
9>lx:>
<>6<=>
=>6<=>
;>lx:>l
u1>i
V,>
m=d]\=:
/;=z6+=
;_)K;
{r<)\
q,=6<==
Ga=F
s=J{
u >/
!N>`vO>
|P>`vO>
2D>7
~;>~
N=6<==
;_)K;o
<X94<
=z6+=6<==
ew=o
G!>ff&>
+>io0>F%5>
9>[B>>%uB>
qJ>_
QZ>?
+e>x
F>%uB>[B>>
9>F%5>io0>
+>ff&>
P=6<==z6+=u
/]<X94<r
Q9RI
{r<N
=yX(=
x=p_
/>aT
X>RI]>
Ga>f
n>W[q>}
=y>lxz>Zd{>
|>HP|>HP|>
|>Zd{>lxz>
s>W[q>
rh>f
Ga>RI]>P
/>o
/;=yX(=
y;RI
d*;KY
d*<b
ew=p_
2>Gr9>[
sW>v
8g>1
|>n4
3b>v
?>Gr9>
%>d;
Ga=:
d*<o
?F=d]\=F
8V>?
c>gDi>
t>5^z>$
>5^z>
4o>gDi>
s=d]\=
<;p
:_)K;RI
=yX(=
m=J{
P>>yX>
_>>yX>
kI>n
v>=yX(=
;_)K;
T<KY
L=B`e=I.
..>}
6>I.?>
h>iop>~
x>iop>
DX>r
G>I.?>}
c>]
=B`e=
;B`e;X9
c<)\
>B>(>W[1>lx:>
C>lx:>W[1>B>(>-!
;B`e;o
5=;pN=
>R' >z
!=>]
|P>]
g3>z
)>R' >b
xi=;pN=
{r;'
>R' >
m4>m
ZS>-
-r>HP|>
>HP|>
J*>R' >
?F<N
h=J{
H?>:#J>+
U>:#J>
m4>z
)>-!
=R' =
sW=k+v=(
>B>(>
g3>m
>>:#J>=
U>w-a>
l>w-a>=
U>:#J>m
g3>B>(>
=k+v=
:=R' =
#<B`
d*;u
Sc=n
%>W[1>
U>w-a>
\m>~
\m>w-a>+
!=>W[1>
Jj<1
d*;RI
=W[1=
..>lx:>]
ZS>]
F>lx:>
AO=W[1=
5<HP
7;RI
|P>-
:_)K;|
?$=\
Sc=o
/>>y
2>I.?>_
6Z>_
L>I.?>
%>>y
/>n4
Sc=\
;_)K;4
+=_)K=
(m=p
q,>#
q?_
q?h
q,>d;
(m=_)K=V
ew=r
\m>HP|>
c?r
>HP|>
%>>y
ew=a
2=tF
:B`e;
9=d]\=I
=d]\=Z
9=Qk
u`<RI
;B`e;
=R' =
d=&S
:p>7
R&?t
@=R' =
l=q=
~*>Gr9>p
H>>yX>
f%?=
+?-C,?
,?-C,?
h>>yX>p
H>Gr9>
{r<U
:0>[
_>iop>I
;.?{
;.?$
@"?$
>iop>
G!><
;X94<
fU=$
>ff&>
y'?u
c,?r
0?EG2?}
7?^K8?Y
8?^K8?
+5?}
3?EG2?
c,?u
y'?j
8V>9
5>ff&>
fU=|
<X94<B`
?n4 ?
,?I./?
1?I./?D
#?n4 ?
E6=tF
u >io0>
t>J{
$?B>(?
1?X94?
6?X94?
+?B>(?
@>io0>
@=B>h=
$>F%5>
sW>gDi>
V?E
%?gD)?
,?R'0?
S3?0L6?
>?R'@?
8E?a
B?R'@?_
9?0L6?
S3?R'0?
,?gD)?"
V?0
~{>gDi>
F>F%5>/
=B>h=
B<HP
41?4
=?io@?
H?q=J?
~K?(~L?6<M?H
M?6<M?(~L?
~K?q=J?U
B?io@?d
41?h
4o>v
WJ=F
s=Nb
->[B>>r
4!?"
1?]m5?
I<?Di??aTB?
O?2UP?
aQ?2UP?
E?aTB?Di??
8?]m5?
3b>r
O>[B>>V
=yX(=
N=Gry=*
0>%uB>
8g>5^z>
?n4 ?
$?gD)?h
F?GrI?
HN?2UP?
&R?F
V?p_W?
W?p_W?
&R?2UP?
K?GrI?}
-?gD)?
$?n4 ?
>5^z>
T>%uB>|
=Gry=
N=yX(=
Q<KY
S#>4
#?B>(?
41?]m5?c
A?o
X?GrY?
Z??W[?
[?h"\?h"\?
[??W[?
Z?GrY?~
\=?c
9?]m5?
,?B>(?
S#><
ZS=V
Y<RI
sW=n
qJ>RI]>
+?R'0?4
D?yXH?q
Q?tFT?}
Z?HP\?
_?R'`?
h`?R'`?$
]?HP\?h
V?tFT?n
K?yXH?
4?R'0?
p>RI]>
qJ>~
sW=2
<RI
~;>_
|@?o
D?yXH?
UO?A
R?]mU?~
c?=,d?Ttd?Ttd?=,d?
X?]mU?A
K?yXH?o
Ga>_
~;>
y'?D
1?0L6?
:?Di??
UO?X
.^?Nb`?aTb?
d?]me?
eg?+
Dh?+
f?]me?
d?aTb?Nb`?
UO?q
C?Di??
:?0L6?
V,>,
<B`e<
b='1
rh>[
*?I./?X94?
=?aTB?}
U?gDY?
I\?gDY?
F?aTB?d
9?X94?I./?u
rh>O
/>G
<B`e<
=5^:=B`e=q=
k>n4
;?io@?
E?GrI?
Q?]mU?
&b?O
(l?mVm??5n?
n??5n?mVm?
X?]mU?n
M?GrI?
E?io@?
=B`e=5^:=
<=B>h=
q?aT
:P?tFT?~
m?-!o?
Np?-!o?
X?tFT?
a!>r
=B>h=[
4o<z6
9#>X
\>W[q>
f%?
;?R'@?
g?U0j?
n?2Up?N
q?2Up?
l?U0j?
E?R'@?C
>W[q>?
(m=M
G!?=
,?EG2?
K?2UP?O
\?Nb`?}
?t?]mu?KYv?
v?KYv?]mu?
?t?<
c?Nb`?$
T?2UP?
7?EG2?$
G!?Zd
{r<V}
>0L&>l
;.?}
&R?+
^?aTb?
t?KYv?
w?>yx?
y?,ey?,ey?
y?>yx?
w?KYv?
e?aTb?
J9?}
9>0L&>tF
4o=\
B=Qk
2D= Aq=
'>lx:>
!N>x
8E?q=J?
X?HP\?
m?2Up?<
v?'1x?
ky?'1x?
r?2Up?
H`?HP\?~
O?q=J?
+5?{
!N>lx:>
= Aq=
t<RI
=]mE=
;>`vO>x
~K?2UP?
U?GrY?
a?]me?5
(l?-!o?N
?t?KYv?'1x?^
{?(~|?
|?(~|?
y?'1x?KYv?
?t?N
q?-!o?
(l?5
h?]me?
]?GrY?
U?2UP?
=y>x
d>`vO>
{r=]mE=
u<RI
ew<3
?F=F
+e>lxz>B>
eG?(~L?
aQ?4
j?mVm?
Np?S
s?]mu?
/|?q
w?]mu?S
Np?mVm?
aQ?(~L?
>lxz>
^)>=
?F=RI
)>6<=>
e>Zd{>9
R&?-C,?
$H?6<M?
V??W[?$
eg?c
j??5n?
s?KYv?>yx?
Wz?>yx?KYv?
4q??5n?c
_??W[?
&R?6<M?
2?-C,?
A ?:#
>Zd{>
4Q>6<=>
Yu=*
2?^K8?
R?p_W?
[?R'`?=,d?+
z?(~|?H
}?(~|?
g?=,d?R'`?
[?p_W?
=?^K8?\
d*>+
f>HP|>L7
W?h"\?
h`?Ttd?
Dh?6
>w?,ey?
C{?,ey?
Dh?Ttd?
h`?h"\?
!>?Y
>HP|>B
 <X9
f>HP|>L7
W?h"\?
h`?Ttd?
Dh?6
>w?,ey?
C{?,ey?
Dh?Ttd?
h`?h"\?
!>?Y
>HP|>B
 <X9
Yu=*
2?^K8?
R?p_W?
[?R'`?=,d?+
z?(~|?H
}?(~|?
g?=,d?R'`?
[?p_W?
=?^K8?\
d*>+
)>6<=>
e>Zd{>9
R&?-C,?
$H?6<M?
V??W[?$
eg?c
j??5n?
s?KYv?>yx?
Wz?>yx?KYv?
4q??5n?c
_??W[?
&R?6<M?
2?-C,?
A ?:#
>Zd{>
4Q>6<=>
ew<3
?F=F
+e>lxz>B>
eG?(~L?
aQ?4
j?mVm?
Np?S
s?]mu?
/|?q
w?]mu?S
Np?mVm?
aQ?(~L?
>lxz>
^)>=
?F=RI
=]mE=
;>`vO>x
~K?2UP?
U?GrY?
a?]me?5
(l?-!o?N
?t?KYv?'1x?^
{?(~|?
|?(~|?
y?'1x?KYv?
?t?N
q?-!o?
(l?5
h?]me?
]?GrY?
U?2UP?
=y>x
d>`vO>
{r=]mE=
u<RI
2D= Aq=
'>lx:>
!N>x
8E?q=J?
X?HP\?
m?2Up?<
v?'1x?
ky?'1x?
r?2Up?
H`?HP\?~
O?q=J?
+5?{
!N>lx:>
= Aq=
t<RI
{r<V}
>0L&>l
;.?}
&R?+
^?aTb?
t?KYv?
w?>yx?
y?,ey?,ey?
y?>yx?
w?KYv?
e?aTb?
J9?}
9>0L&>tF
4o=\
B=Qk
(m=M
G!?=
,?EG2?
K?2UP?O
\?Nb`?}
?t?]mu?KYv?
v?KYv?]mu?
?t?<
c?Nb`?$
T?2UP?
7?EG2?$
G!?Zd
4o<z6
9#>X
\>W[q>
f%?
;?R'@?
g?U0j?
n?2Up?N
q?2Up?
l?U0j?
E?R'@?C
>W[q>?
<=B>h=
q?aT
:P?tFT?~
m?-!o?
Np?-!o?
X?tFT?
a!>r
=B>h=[
=5^:=B`e=q=
k>n4
;?io@?
E?GrI?
Q?]mU?
&b?O
(l?mVm??5n?
n??5n?mVm?
X?]mU?n
M?GrI?
E?io@?
=B`e=5^:=
<B`e<
b='1
rh>[
*?I./?X94?
=?aTB?}
U?gDY?
I\?gDY?
F?aTB?d
9?X94?I./?u
rh>O
/>G
<B`e<
y'?D
1?0L6?
:?Di??
UO?X
.^?Nb`?aTb?
d?]me?
eg?+
Dh?+
f?]me?
d?aTb?Nb`?
UO?q
C?Di??
:?0L6?
V,>,
~;>_
|@?o
D?yXH?
UO?A
R?]mU?~
c?=,d?Ttd?Ttd?=,d?
X?]mU?A
K?yXH?o
Ga>_
~;>
Y<RI
sW=n
qJ>RI]>
+?R'0?4
D?yXH?q
Q?tFT?}
Z?HP\?
_?R'`?
h`?R'`?$
]?HP\?h
V?tFT?n
K?yXH?
4?R'0?
p>RI]>
qJ>~
sW=2
<RI
S#>4
#?B>(?
41?]m5?c
A?o
X?GrY?
Z??W[?
[?h"\?h"\?
[??W[?
Z?GrY?~
\=?c
9?]m5?
,?B>(?
S#><
ZS=V
=yX(=
N=Gry=*
0>%uB>
8g>5^z>
?n4 ?
$?gD)?h
F?GrI?
HN?2UP?
&R?F
V?p_W?
W?p_W?
&R?2UP?
K?GrI?}
-?gD)?
$?n4 ?
>5^z>
T>%uB>|
=Gry=
N=yX(=
Q<KY
WJ=F
s=Nb
->[B>>r
4!?"
1?]m5?
I<?Di??aTB?
O?2UP?
aQ?2UP?
E?aTB?Di??
8?]m5?
3b>r
O>[B>>V
41?4
=?io@?
H?q=J?
~K?(~L?6<M?H
M?6<M?(~L?
~K?q=J?U
B?io@?d
41?h
4o>v
@=B>h=
$>F%5>
sW>gDi>
V?E
%?gD)?
,?R'0?
S3?0L6?
>?R'@?
8E?a
B?R'@?_
9?0L6?
S3?R'0?
,?gD)?"
V?0
~{>gDi>
F>F%5>/
=B>h=
B<HP
u >io0>
t>J{
$?B>(?
1?X94?
6?X94?
+?B>(?
@>io0>
?n4 ?
,?I./?
1?I./?D
#?n4 ?
E6=tF
;X94<
fU=$
>ff&>
y'?u
c,?r
0?EG2?}
7?^K8?Y
8?^K8?
+5?}
3?EG2?
c,?u
y'?j
8V>9
5>ff&>
fU=|
<X94<B`
:0>[
_>iop>I
;.?{
;.?$
@"?$
>iop>
G!><
l=q=
~*>Gr9>p
H>>yX>
f%?=
+?-C,?
,?-C,?
h>>yX>p
H>Gr9>
{r<U
=R' =
d=&S
:p>7
R&?t
@=R' =
:B`e;
9=d]\=I
=d]\=Z
9=Qk
u`<RI
;B`e;
ew=r
\m>HP|>
c?r
>HP|>
%>>y
ew=a
2=tF
+=_)K=
(m=p
q,>#
q?_
q?h
q,>d;
(m=_)K=V
:_)K;|
?$=\
Sc=o
/>>y
2>I.?>_
6Z>_
L>I.?>
%>>y
/>n4
Sc=\
;_)K;4
|P>-
=W[1=
..>lx:>]
ZS>]
F>lx:>
AO=W[1=
5<HP
7;RI
d*;u
Sc=n
%>W[1>
U>w-a>
\m>~
\m>w-a>+
!=>W[1>
Jj<1
d*;RI
=R' =
sW=k+v=(
>B>(>
g3>m
>>:#J>=
U>w-a>
l>w-a>=
U>:#J>m
g3>B>(>
=k+v=
:=R' =
#<B`
h=J{
H?>:#J>+
U>:#J>
m4>z
)>-!
>R' >
m4>m
ZS>-
-r>HP|>
>HP|>
J*>R' >
?F<N
5=;pN=
>R' >z
!=>]
|P>]
g3>z
)>R' >b
xi=;pN=
{r;'
;B`e;X9
c<)\
>B>(>W[1>lx:>
C>lx:>W[1>B>(>-!
;B`e;o
T<KY
L=B`e=I.
..>}
6>I.?>
h>iop>~
x>iop>
DX>r
G>I.?>}
c>]
=B`e=
:_)K;RI
=yX(=
m=J{
P>>yX>
_>>yX>
kI>n
v>=yX(=
;_)K;
?F=d]\=F
8V>?
c>gDi>
t>5^z>$
>5^z>
4o>gDi>
s=d]\=
<;p
d*;KY
d*<b
ew=p_
2>Gr9>[
sW>v
8g>1
|>n4
3b>v
?>Gr9>
%>d;
Ga=:
d*<o
Q9RI
{r<N
=yX(=
x=p_
/>aT
X>RI]>
Ga>f
n>W[q>}
=y>lxz>Zd{>
|>HP|>HP|>
|>Zd{>lxz>
s>W[q>
rh>f
Ga>RI]>P
/>o
/;=yX(=
y;RI
<X94<
=z6+=6<==
ew=o
G!>ff&>
+>io0>F%5>
9>[B>>%uB>
qJ>_
QZ>?
+e>x
F>%uB>[B>>
9>F%5>io0>
+>ff&>
P=6<==z6+=u
/]<X94<r
;_)K;
{r<)\
q,=6<==
Ga=F
s=J{
u >/
!N>`vO>
|P>`vO>
2D>7
~;>~
N=6<==
;_)K;o
7;KY
=z6+=
/;=:
K=d]\=D
m=I.
V,>i
9>lx:>
<>6<=>
=>6<=>
;>lx:>l
u1>i
V,>
m=d]\=:
/;=z6+=
=yX(=Y
U=B`e=
9#>/
$>0L&>
d*>1
'>0L&>/
Yu=B`e=
?F=Y
7=yX(=u
{r<M
7x=J{
/>:#
O/<N
=yX(=
A=;pN=
h=k+v=n
=k+v=
[=;pN=
5=yX(=
ew<b
7:RI
j<<>
ew<M
ew<>
j<<b
ew=I
{r<b
DX;'
3"<4
=R' =U
(=W[1=Z
B=_)K=a
S=d]\=
d=d]\=a
S=_)K=\
9=W[1=U
(=R' =P
7;B`e;
?$=V
b=B>h=D
s=Gry=
\~=n
\~=Gry=F
m=B>h=e
?$=v
;B`e;4
{r<&
=R' =T
b=B`e=B>h=h
4o= Aq=
{r=F
{r= Aq=
(m=h
j=B>h=B`e=e
WJ=9
E6=|
%=R' =Qk
k:RI
>;B`e;'
#<X94<
z<KY
$=yX(=V
7=5^:=[
2D=]mE=
?F=]mE=
2D=\
<=5^:=
-2=2
+=yX(=
D<X94<
;B`e;
>;RI
DX;$
d*<4
?F<4
DX;4
Q:RI
Q9RI
k:RI
Q9RI
k;KY
Q:RI
Q9RI
7;_)K;
y;KY
3"<U
-<X94<
b<B`e<
4o<E
{r<!
ew<l
{r<E
h<B`e<e
#9<X94<
3"<RI
^;_)K;4
7:RI
Q9RI
d*;4
7;_)K;
DX;B`e;
{r;o
{r;B`e;
DX;_)K;4
d*;RI
7:RI
Q9RI
d*;4
>;_)K;
DX;B`e;
{r;l
k;B`e;
Q;_)K;
#;RI
7:RI
Q9RI
7:RI
Q9RI
q=J?\
~|zxvuusqpnmkjiggfecba`_^]]\[ZYXWVUTTSRQQPONNMMLKKJIIHGGGFFEDDCCBBBAA@@??>>===<<;;:::999888776666555444333322211110000////.....----,,,,+++++*****)))))((((('''''''&&&&&&%%%%%%$$$$$$$########""""""!!!!!!!!!        X|E
+>>%I
%@ %@
timeRange
confidence
B8@?0
variation = %6.2f
creationDate
uuid
mediaanalysisd
private/com.apple.mediaanalysisd/caches/vision
verifiedType = %@ OR verifiedType = %@
B24@?0@"PHPerson"8@"NSDictionary"16
asset in (%@)
any person.personUUID in %@
total-allowed
ANY detectedFaces.uuid IN %@
PVPersonClusterManager
Unable to find class %s
v8@?0
com.apple.mediaanalysis.reachability
Not c
None
TransientConnection
Reachable
ConnectionRequired
ConnectionOnTraffic
InterventionRequired
ConnectionOnDemand
IsLocalAddress
IsDirect
IsWWAN
qualityScore
distanceToPreviousScene
flickerScore
sceneprintDistanceToPreviousScene
SceneResults
QualityResults
CameraMotionResults
SubjectMotionResults
FineSubjectMotionResults
SubtleMotionResults
TrackSegments
OrientationResults
IrisRecommendResults
IrisSharpnessResults
PreEncodeResults
MovingObjectsResults
FeatureVectorResults
SceneprintResults
ObstructionResults
InterestingnessResults
flags
quality
attributes
start
duration
distance
sceneprintDistance
featureVector
Data
orientation
objectBounds
slowMoFlicker
sceneprint
index
junk
summaryTimerange
duplicate
MetaFocusResults
MetaMotionResults
MetaMotionProcessedResults
q24@?0@"PHAssetResource"8@"PHAssetResource"16
B16@?0@"PHAssetResource"8
mammal
bird
people
adult
animal
stuffed_animals
fire
fireplace
embers
flame
beach
liquid
ocean
lake
creek
river
snow
jacuzzi
pool
grass
plant
coral_reef
foliage
tree
grill
waterways
shore
waterfall
thunderstorm
manhole
aurora
light
spotlight
smoking_item
flag
flagpole
underwater
candle
kettle
teapot
storm
tornado
lightning
blossom
surfing
pyrotechnics
blizzard
fountain
billboards
curtain
lamp
drinking_glass
fondue
blender
storefront
garden
shrub
firecracker
bubble_soap
watersport
haze
volcano
aquarium
fishtank
flower
seaweed
jellyfish
fish
flashlight
bonfire
smoking
lakeshore
sparkler
sparkling_wine
shower
geyser
actionScore
v32@?0@"NSNumber"8@"VCPFace"16^B24
v32@?0@"NSNumber"8@"VCPVideoObjectTracker"16^B24
q24@?0@"VCPFace"8@"VCPFace"16
/tmp/
v32@?0@"NSNumber"8@"VNFaceprint"16^B24
v32@?0@"NSNumber"8@"NSNumber"16^B24
Home face identification task cancelled
No face present in face crop
Photos identity model not present
%@ | %@
{{%.*g, %.*g}, {%.*g, %.*g}}
timestamp
qualityScoreForLivePhoto
visualPleasingScore
overallFaceQualityScore
exposureScore
penaltyScore
textureScore
sharpness
faceResults
globalQualityScore
contentScore
expressionChangeScore
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
v24@?0Q8^B16
v32@?0@"NSNumber"8Q16^B24
VCPClusteringStatusIsClustering
VCPClusteringStatusClusterRebuildRequired
VCPClusteringStatusEligibleFacesCount
VCPClusteringStatusPendingFacesCount
VCPSuggestionUpdateStarted
VCPSuggestionUpdateFinished
VCPSuggestionUpdateCancelled
com.apple.mediaanalysisd.clusterer.processing
com.apple.mediaanalysis.scheduleclustering
VCPFaceProcessingClusterFacesCoreAnalyticsCollection
v24@?0@"NSString"8^B16
com.apple.mediaanalysisd.photos.faceclustering
ClusteringSequence
FacesAddToClustering
FacesRemoveFromClustering
FacesInClusterBeforeClustering
ClusteringInterval
TotalAssetCount
ProcessingQoS
com.apple.mediaanalysisd.optional_clustering
com.apple.mediaanalysisd.forced_clustering
Operation cancelled
v32@?0@"NSNumber"8@"NSOrderedSet"16^B24
VCPVisionFgMapping_Prepare
v32@?0@"NSCountedSet"8Q16^B24
q24@?0@"NSCountedSet"8@"NSCountedSet"16
v24@?0@"NSNumber"8^B16
VCPClusterCompareTimestamp
VCPClusterer: Failed to get face CSNs from cluster cache, which should not be used
PVErrorInvalidClusterCacheFile - %@
VCPClusterer: Failed to get Vision cluster state - %@
VisionClusterState
clusteringType
threshold
VCPClusterer: Failed to archive cluster snapshot
VCPClusterer: Failed to rename file from '%@' to '%@'. Error = %d
VCPClusterer: Failed to write cluster snapshot to file '%@'
missing parameter clusterState
VCPClusterer: Cluster snapshot file '%s' is too small
VCPClusterer: Invalid magic number found in '%s'
VCPClusterer: Invalid version in '%s', %d != %d
VCPClusterer: Failed to read MD5 from header of '%s'
VCPClusterer: Failed to compute MD5 of '%s'
VCPClusterer: Failed MD5 check for '%s'
VCPClusterer: Failed to read size of vision cluster state blob from '%s'
VCPClusterer: Failed to read vision cluster state blob from '%s'
VCPClusterer: Failed to open cluster cache file '%s'
cmap
CVMLClusterState
CVMLClusteringAlgorithm_Greedy
VCPClusterer: Failed to restore cluster cache
VCPClusterer: Failed to restore cluster cache std::exception %s
VCPClusterer: Failed to restore cluster cache due to device ran out of memory
VCPClusterer needs a full sync
missing updateHandler
VCPClusterer is not ready
VCPClusterer: Failed to get suggestions from Vision framework %@
v32@?0@"VNCluster"8Q16^B24
v32@?0@"NSSet"8Q16^B24
q24@?0@"NSMutableSet"8@"NSMutableSet"16
VCPClustererBringUpState
clustererState.plist
need full sync
need to compare clusters
need to reset cluster cache
need to reset library clusters
need update
ready
clustering
have unsaved cluster cache
saving cluster cache
have new cluster cache
unknown (error)
AlgoFaceClusterCache.data
temp
Error: failed to processImage
highlightScore
@"VCPMADVIRemoveBackgroundResource"8@?0
VCPMADVIRemoveBackgroundTask
Image loading failed
Failed to obtain image from Vision
Multiple cadence options specified
%@ value must be NSNumber
%@ value must be poisitive
%@ is not supported
v32@?0@"NSString"8@16^B24
v24@?0@"NSDictionary"8@"NSError"16
Full analysis asset processing task cancelled
[%@] Failed to analyze on-demand
VCPFullAnalysisAssetProcessingTask processing failed
AllowOnDemand
InProcess
SceneprintRevision
com.apple.mediaanalysis.service.management
com.apple.mediaanalysis.service.handler
MediaAnalysisService
Error issuing sandbox extension
v16@?0d8
[MediaAnalysis] Error connecting to background analysis service
v16@?0@"NSError"8
Assets from multiple libraries not supported
v24@?0@"NSString"8@"NSError"16
PersonProcessingDeletePersons
PersonProcessingClusterFaces
PersonProcessingIncrementalFaceClustering
PersonProcessingRunBuildPersons
PersonProcessingIncrementalPersonBuilding
PersonProcessingRunPromotePersons
PersonProcessingRebuildFaceIDModel
PersonProcessingClassifyContactPictures
faceCSN
faceIdentifier
personIdentifier
personFaceCount
confirmed
status
requestAdvancedStatus
advancedStatus
PLPhotoAnalysisVisionServiceFaceReclusteringThreshold
PLPhotoAnalysisVisionServiceFaceReclusteringDeletePersons
PLPhotoAnalysisVisionServiceFaceReclusteringShouldRecluster
personLocalIdentifier
v24@?0@"NSArray"8@"NSError"16
v20@?0B8@"NSError"12
model_info.json
net_file
revision
config
loadModel
res_256x160
res_160x256
cnn_human_pose_lite_v2.espresso.net
input
before filter: frame(%d): time_stamp=%f, ave_motion=(%f,%f)
frame(%d): time_stamp=%f, ave_motion=(%f,%f), acc_var=(%f, %f), motion_chg=(%f, %f)
q24@?0@8@16
VCPMADImageSafetyClassificationResource
@"VCPMADImageSafetyClassificationResource"8@?0
[ImageSafety] Before decode
Image pre-processing failed
[ImageSafety] Before inference
CVNLPCommSafetyHandler unavailable
[ImageSafety] After inference
[VCPPhotosFace] Missing faceObservation and humanObservation
@"VNRequest"16@?0#8
@"VNObservation"24@?0@"NSUUID"8@"VNRequest"16
[VCPPhotosFace] Invalid faceprint and torsoprint
[VCPPhotosFace] Unable to serialize faceTorsoprint - %@
[VCPPhotosFace] Unable to determine normalized face bounding { { %f, %f } { %f, %f } }
%@ (%@), %@ (v%d) (%.2f, %.2f, %.2f) (%.2f, %.2f, %.2f, %.2f) quality: %.2f
Human
bounds
cnn_facepose.espresso.net
VCPPoseEspresso
@"VCPCNNModelEspresso"8@?0
quality_head.espresso.net
output
ImageAnalysis
MovieAnalysis
MAComputeRequestClass
q24@?0@"VNClassificationObservation"8@"VNClassificationObservation"16
q24@?0@"VCPClassification"8@"VCPClassification"16
featureBlob
checksum
data
SceneprintHyperplaneLSH, 
NeuralHyperplaneLSH, 
Unknown
com.apple.mediaanalysisd.timer
rawTime
homography
keypoints
v32@?0@"PHFace"8Q16^B24
VNFaceGazeDirectionUnknown
VNFaceGazeDirectionCamera
VNFaceGazeDirectionAnotherFace
VNFaceGazeDirectionCommonLocation
VNFaceGazeDirectionSomewhereElse
VNFaceGazeDirectionDifficultToSay
Error VNFaceGazeDirection: %lu
PHFaceGazeTypeCannotInferGaze
PHFaceGazeTypeLookingAtCamera
PHFaceGazeTypeLookingAtAnotherFace
PHFaceGazeTypeLookingAtCommonLocation
PHFaceGazeTypeOther
Error PHFaceGazeType: %d
sceneprintBlob
absoluteScore
relativeScore
humanScore
faceId
Action
NumOfValidFrames
ActionScore
seg %d: [%d, %d], sceneCut=%d
prev(%d) [%d, %d][%6.1f, %6.1f] qs = %6.2f, curr(%d) [%d, %d] [%6.1f, %6.1f]qs = %6.2f:
dist({%d %d}, {%d %d}) = %6.2f, th = %6.2f
prev: type = %d, fast = %d, gmv_sum {%6.1f, %6.1f}, merge = %d, split = 0
curr: type = %d, fast = %d, gmv_sum {%6.1f, %6.1f}, merge = %d, split = 0
segments
cnn_content.dat
v16@?0^{opaqueCMSampleBuffer=}8
MediaAnalysis
SceneNetV5
eyeExpression
mouthExpression
position
isCloseup
faceQuality
VCPMADVIResource
curationScore
com.apple.MediaAnalysis
com.apple.mediaanalysisd
forceCPU
forceNNGraph
sharedContext
shared 
VCPWallpaperAnalyzer.sharedModelPool
@"VCPObjectPool"8@?0
quantized_9hy8wvx5wz_iteration_47_model.espresso.net
quantized_5c7q2hh2zk_iteration_35_model.espresso.net
height
width
com.apple.mediaanalysis.VCPClientDatabaseManager
/tmp/com.apple.mediaanalysisd/VideoCaptionEncoderTest/
/tmp/com.apple.mediaanalysisd/VideoCaptionDecoderTest/
/tmp/com.apple.mediaanalysisd/ImageCaptionModelTest/
com.apple.MobileAsset.VCPMobileAssets
v16@?0q8
Model
AssetName
Version
VideoCaptionEncoder
v16@?0@"MAProgressNotification"8
v24@?0q8@"NSError"16
ClonedVideoCaptionDecoder
ClonedVideoCaptionEncoder
com.apple.mediaanalysis.VCPVideoTrackSyncDecoder
classification
[VCPVNImageprintWrapper] Invalid imageprint type %lu
Cannot calculate distance - missing the other imageprint
Cannot calculate distance - mismatched imageprint type (%lu vs %lu)
Cannot calculate distance - mismatched versions (%d vs %d)
Cannot calculate distance - unarchive self.data - %@
Cannot calculate distance - unarchive theOtherImageprint.data - %@
torso-only
face-only
Cannot get distance between faceprints. Distance function returns nil
type: %lu, version: %d, and data[length:%lu]: <%p>
v32@?0@"NSNumber"8@"NSArray"16^B24
com.apple.mediaanalysis.VCPSharedInstanceManager
VCPAnalysisProgressQueryScanPhotoLibraryFetch
faceAdjustmentVersion != nil
mediaAnalysisAttributes.characterRecognitionAttributes.algorithmVersion >= %d
mediaAnalysisAttributes.visualSearchAttributes.algorithmVersion >= %d
additionalAttributes.sceneAnalysisVersion >= %d &&  additionalAttributes.sceneAnalysisVersion != %d
VCPAnalysisProgressQueryExpressPathFetchTotalCount
VCPAnalysisProgressQueryExpressPathFetchProcessedCount
VCPAnalysisProgressQueryProgressDetail
VCPAnalysisProgressQueryProgress
VCPAnalysisProgressQueryCachedFaceAnalysisProgress
SalientRegions
bound
plistRepresentation
q24@?0@"VCPSaliencyRegion"8@"VCPSaliencyRegion"16
hand_keypoint_detector_acc.espresso.net
cnn_moflow.espresso.net
landscape_1024x448
square_320x320
input_image_1
input_image_2
zeros
landscape_384x256
landscape_448x320
landscape_640x512
landscape_896x640
portrait_256x384
portrait_320x448
portrait_512x640
portrait_640x896
square_256x256
square_512x512
square_640x640
VCPMoflowEspresso
com.apple.mediaanalysis.VCPVideoProcessorSession
Video processing requests must have completion handler
Specified request already active; cannot add
Failed to create request with specified configuration
Specified request not found; cannot remove
Sample buffer does not contain video frame
Sample buffer must contain uncompressed video
faceSharpness
vnpersonsmodel.bin
vnpetsmodel.bin
Point0
Point1
Radius
Theta
Length
Hand_waving
Hand_clapping
Dancing
Walking
Running
Jumping
cnn_human_action.espresso.net
salientRegion
salientScore
q24@?0@"NSDictionary"8@"NSDictionary"16
/var/mobile/Media/MediaAnalysis
private/com.apple.mediaanalysisd/MediaAnalysis
mediaanalysis.db
kindSubtype != %d
kind == %d
PhotoAnalysisServicePreferences.plist
faceWorkerState.plist
(faceAlgorithmVersion = %d) AND (clusterSequenceNumber = 0) AND (((hidden = 0) AND (manual = 0) AND ((trainingType = %d) OR (trainingType = nil))) OR ((trainingType = %d) OR (trainingType = %d) OR (trainingType = %d)))
SyndPL
Tracking
TrackingScore
AveStats
Failed to parse AVE statistics frame attachment; re-generating statistics
summaryIsTrimmed
livePhoto
movie
AutoplayScore
MotionScore
SubjectScore
ExposureChange
landscape_1024x432
privECMVct
privEMBVct
privDFArray
privET
privImgG
privTZF
privAFS
privAFSt
privFM
relSampleTime
trajectoryHomography
presentingTimestampInNanos
originalPresentingTimestampInNanos
sequenceAdjusterRecipe
sequenceAdjusterDisplacement
interpolatedFrame
LivePhotoMetadataSetupDataVersion
FrameworkVersions
CMCaptureCore
Error: failed to analyze motion flow
mediaAnalysisVersionState.plist
VCPFaceProcessingVersionManager-%@
@"VCPFaceProcessingVersionManager"8@?0
FaceProcessingInternalVersion
Reset none
Reset AnalysisStates
Reset Clustering
shotType
humanPoseResults
version
AutoLoop
Bounce
LongExposure
Stabilize
NormStabilizeInstructions
MinVersion
Params
loopFlavor
loopEnergy
outputFrameDur
stabCropRect
stabilizeResult
Width
Height
frameInstructions
face_model_tensor.dat
face_model_landmark_coordinates.dat
face_model_boundary.dat
com.apple.mediaanalysisd.VCPFaceShapeUpdate
Error detected at line 
Error detected in file 
Submodules/dlib/dlib/optimization/optimization.h
Error detected in function 
double dlib::find_min_box_constrained(search_strategy_type, stop_strategy_type, const funct &, const funct_der &, T &, const matrix_exp<EXP1> &, const matrix_exp<EXP2> &) [search_strategy_type = dlib::lbfgs_search_strategy, stop_strategy_type = dlib::objective_delta_stop_strategy, funct = std::function<double (dlib::matrix<double, 0, 0>)>, funct_der = std::function<dlib::matrix<double, 0, 0> (dlib::matrix<double, 0, 0>)>, T = dlib::matrix<double, 51, 1>, EXP1 = dlib::matrix_op<dlib::op_uniform_matrix_3<double>>, EXP2 = dlib::matrix_op<dlib::op_uniform_matrix_3<double>>]
Failing expression was 
is_col_vector(x) && is_col_vector(x_lower) && is_col_vector(x_upper) && x.size() == x_lower.size() && x.size() == x_upper.size()
double find_min_box_constrained()
 The inputs to this function must be equal length column vectors.
 is_col_vector(x):       
 is_col_vector(x_upper): 
 x.size():               
 x_lower.size():         
 x_upper.size():         
The objective function generated non-finite outputs
 ************************** FATAL ERROR DETECTED ************************** 
 ************************** FATAL ERROR DETECTED ************************** 
 ************************** FATAL ERROR DETECTED ************************** 
Two fatal errors have been detected, the first was inappropriately ignored. 
To prevent further fatal errors from being ignored this application will be 
terminated immediately and you should go fix this buggy program.
The error message from this fatal error was:
**************************** FATAL ERROR DETECTED ****************************
******************************************************************************
EPORT_IN_USE
ETIMEOUT
ECONNECTION
ELISTENER
ERESOLVE
EMONITOR
ECREATE_THREAD
ECREATE_MUTEX
ECREATE_SIGNALER
EUNSPECIFIED
EGENERAL_TYPE1
EGENERAL_TYPE2
EGENERAL_TYPE3
EINVALID_OPTION
ETOO_FEW_ARGS
ETOO_MANY_ARGS
ESOCKET
ETHREAD
EGUI
EFATAL
EBROKEN_ASSERT
EIMAGE_LOAD
EDIR_CREATE
EINCOMPATIBLE_OPTIONS
EMISSING_REQUIRED_OPTION
EINVALID_OPTION_ARG
EMULTIPLE_OCCURANCES
ECONFIG_READER
EIMAGE_SAVE
ECAST_TO_STRING
ESTRING_CAST
EUTF8_TO_UTF32
EOPTION_PARSE
undefined error type
iteration: 
   objective: 
Submodules/dlib/dlib/matrix/matrix.h
const dlib::matrix::literal_assign_helper &dlib::matrix<double, 2, 2>::literal_assign_helper::operator,(const T &) const [T = double, num_rows = 2, num_cols = 2, mem_manager = dlib::memory_manager_stateless_kernel_1<char>, layout = dlib::row_major_layout]
r < m->nr() && c < m->nc()
You have used the matrix comma based assignment incorrectly by attempting to
supply more values than there are elements in the matrix object being assigned to.
Did you forget to call set_size()?
 r: 
 c: 
 m->nr(): 
 m->nc(): 
dlib::matrix<double, 2, 2>::literal_assign_helper::~literal_assign_helper() [T = double, num_rows = 2, num_cols = 2, mem_manager = dlib::memory_manager_stateless_kernel_1<char>, layout = dlib::row_major_layout]
!has_been_used || r == m->nr()
You have used the matrix comma based assignment incorrectly by failing to
supply a full set of values for every element of a matrix object.
const dlib::matrix::literal_assign_helper &dlib::matrix<double, 2, 1>::literal_assign_helper::operator,(const T &) const [T = double, num_rows = 2, num_cols = 1, mem_manager = dlib::memory_manager_stateless_kernel_1<char>, layout = dlib::row_major_layout]
dlib::matrix<double, 2, 1>::literal_assign_helper::~literal_assign_helper() [T = double, num_rows = 2, num_cols = 1, mem_manager = dlib::memory_manager_stateless_kernel_1<char>, layout = dlib::row_major_layout]
You have to supply column vectors to this function
double dlib::find_min_using_approximate_derivatives(search_strategy_type, stop_strategy_type, const funct &, T &, double, double) [search_strategy_type = dlib::lbfgs_search_strategy, stop_strategy_type = dlib::objective_delta_stop_strategy, funct = std::function<double (dlib::matrix<double, 0, 0>)>, T = dlib::matrix<double, 6, 1>]
is_col_vector(x) && derivative_eps > 0
double find_min_using_approximate_derivatives()
x.nc():         
derivative_eps: 
cnn_landmark.espresso.net
VCPFaceLandmarkEspresso
mediaanalysis://asset.mov
VCPMADVITextLookupTask
@"VIImage"8@?0
Failed to create text lookup query context
v24@?0@"VITextLookupResult"8@"NSError"16
VIService_TextLookup
vanishingPoint
dominantLine
v32@?0@"NSString"8@"NSNumber"16^B24
<%@ %p, 
active cost: %d,
inactive cost: %d>
cnn_smile.espresso.net
VCPSmileEspresso
highlight_head.espresso.net
input1
input2
var_165
CVPixelbuffer not IOSurface backed
activityID: %@, 
startTime: %@, 
duration: %f(sec), 
exitStatus: %d>
idx (%tu) is out of range (%tu)
timeValue
homographyParam
timeScale
epoch
errorCode
loopFadeLen
loopPeriod
loopStart
sport
cnn_activitylevel.dat
HighlightMaxDuration
HighlightTargetDuration
HighlightStartRange
HighlightTolerance
HighlightIndex
HighlightBestTrim
HighlightFullResult
v32@?0@"VCPMovieHighlight"8Q16^B24
com.apple.homekitanalysis.session.management
com.apple.homekitanalysis.session.handler
[HomeKit] XPC connection invalidated. Please restart the session.
No result handler registered
No VCPHomeKitAnalysisSession; cannot process message
HMIVideoAnalyzer
com.apple.mediaanalysis.sql
SELECT id, version, dateModified, dateAnalyzed, analysisTypes, flags, quality, masterFingerprint, adjustedFingerprint
, statsFlags
 FROM Assets WHERE localIdentifier=(?);
SELECT resultsType, results FROM Results WHERE assetId=(?);
SELECT resultsType, results FROM Results WHERE assetId=(?
) AND resultsType IN (?
SELECT id, localIdentifier, version, dateModified, dateAnalyzed, analysisTypes, flags, quality, masterFingerprint, adjustedFingerprint
 FROM Assets WHERE localIdentifier IN (?
SELECT assetId, resultsType, results FROM Results WHERE assetId IN (?
SELECT date FROM Blacklist WHERE localIdentifier=(?) AND count>=(?);
i8@?0
SELECT localIdentifier FROM Blacklist WHERE count>=(?) AND localIdentifier IN (?
SELECT localIdentifier FROM Blacklist WHERE count>=(?);
SELECT localIdentifier FROM Assets WHERE dateAnalyzed>=(?) UNION SELECT localIdentifier FROM Blacklist WHERE count>=(?) AND date>=(?);
SELECT localIdentifier, status, attempts, date FROM ProcessingStatus WHERE taskID=(?) AND status!=(?) AND localIdentifier IN (?
SELECT localIdentifier FROM ProcessingStatus WHERE taskID=(?) AND status=(?);
SELECT COUNT(*) FROM ProcessingStatus WHERE taskID=(?) AND status=(?);
SELECT value FROM KeyValueStore WHERE key = (?);
SELECT activityID, startTime, duration, exitStatus FROM BackgroundActivitySchedulingHistory WHERE activityID=(?) AND startTime>=(?);
value
timescale
Orientation
Regions
Home resident maintenance task cancelled
HMITaskService
[VCPMADServiceImageProcessing] Specified identifier not found (%@)
[ImageProcessingTask%d] Identifier %@
Request was canceled
VCPVideoCNNBackboneEspresso
video_backbone.espresso.net
AveragePool_258_out
ReduceMean_264
Add_182_out
Pad_257_out
activityScore
ErrorCode
@"VNSession"8@?0
com.apple/PhotoVision/FaceCrop/
PVFC
PVFC:PVFC
PVFC_VER
PVFC_FB
PVFC_CB
PVFC_GID
tiff:Orientation
Could not set output orientation
Could not register face crop namespace
Could not generate serialized metadata representation
Could not convert metadata representation into serialized format
Could not set face crop metadata
Could not create image source
No meta data exists on image
unexpected nil image source
invalid image source
zero dimensioned face rect submitted
could not create cropped face crop image
could not create face crop metadata
public.jpeg
could not create face crop data
could not write face crop data
VCPFaceCropUtils : newFaceCropFromImageData - %@
image url is nil
Could not create image ref
Could not create face rect
VCPFaceCropUtils:newFaceCropFromImageURL - %@
image data is nil
Could not create image source from data
VCPFaceCropUtils:newFaceCropFromImageData - %@
invalid face crop supplied
VCPFaceCropUtils:faceBoundsFromFaceCrop -- %@
VCPFaceCropUtils:cropBoundsInOriginalImageFromFaceCrop -- %@
the supplied data is not a facecrop
could not create an image source
Could not retrieve image properties
VCPFaceCropUtils:faceCropDimensionsFromFaceCrop -- %@
could not create image ref
Could not create image for rendering
Could not create buffer for rendering
Could not create srgb colorspace
Could not create cropped and subsampled image
Could not create bitmap context
Face
@"VCPMADMachineReadableCodeResource"8@?0
VCPMADVIMachineReadableCodeDetectionTask
flow_estimation_%d
t_38
v16@?0^{?=ii*}8
interestScore
com.apple.mediaanalysisd.realtime
ContentType
faceMetadataArray
realtimeFaceRect
realtimeFaceRoll
realtimeFaceYaw
PriorityScore
v32@?0@8Q16^B24
%@ <%p>:
  person1LocalIdentifier  : %@
  person2LocalIdentifier  : %@
  reason                  : %@
asset.dateCreated
asset.addedDate
asset.filename
centerX
centerY
(verifiedType = %d) OR (verifiedType = %d)
(faceAlgorithmVersion = %d) AND (((hidden = 0) AND (manual = 0) AND ((trainingType = %d) OR (trainingType = nil))) OR ((trainingType = %d) OR (trainingType = %d) OR (trainingType = %d)))
(clusterSequenceNumber > 0)
(manual == 0) AND (faceAlgorithmVersion = %d)
Could not access the library
Canceled operation to get CSNs of faces missing from the library
v40@?0@"NSArray"8{_NSRange=QQ}16^B32
v32@?0@"NSString"8@"PHFetchResult"16^B24
(clusterSequenceNumber in %@)
Canceled operation to ungroup faces
v16@?0^B8
Canceled operation to uncluster faces
(clusterSequenceNumber = 0)
((clusterSequenceNumber > 0) AND (faceGroup = nil))
could not access the library
Canceled operation to cleanup grouped faces with CSN=0
No faceGroups found for person with localIdentifier '%@'
Failed to fetch faces from the faceGroup that contributed the most number of face to person with localIdentifier '%@'
(clusterSequenceNumber in %@) AND (trainingType = %d OR trainingType = %d OR trainingType = %d)
(clusterSequenceNumber in %@) AND (trainingType = %d OR trainingType = %d)
v32@?0@"PHPerson"8Q16^B24
v32@?0@"NSNumber"8@"NSSet"16^B24
photoLibrary is nil
trainingType != %d
VisionFgMapping_LookingAfterNewClusteredFace
VisionFgMapping_LookingForConflictingCluster
VisionFgMapping_ResolveConflictingCluster
v32@?0@"NSNumber"8@"NSDictionary"16^B24
VisionFgMapping_ResolveConflictL0Clusters
VisionFgMapping_Process
clusterSequenceNumber IN %@
@"PHFace"16@?0@"NSNumber"8
Saving clustering results cancelled
Canceled operation to reset library clusters
keyFace == nil
[UpdateKeyFaces] Failed to find persons %@
-[VCPPhotosPersistenceDelegate updateKeyFacesOfPersonsWithLocalIdentifiers:forceUpdate:cancelOrExtendTimeoutBlock:error:]
[UpdateKeyFaces] Operation canceled
Unimplemented %s in VCPPhotosPersistenceDelecate
-[VCPPhotosPersistenceDelegate invalidFaceClusterSequenceNumbersInClusterSequenceNumbers:canceler:error:]
-[VCPPhotosPersistenceDelegate ungroupFaceClusterSequenceNumbers:batchSizeForUnclusteringFaces:canceler:error:]
-[VCPPhotosPersistenceDelegate cleanupUngroupedFacesWithNonZeroClusterSequenceNumbersWithCanceler:error:]
-[VCPPhotosPersistenceDelegate cleanupGroupedFacesWithClusterSequenceNumberSetToZeroWithCanceler:error:]
-[VCPPhotosPersistenceDelegate persistChangesToAlgorithmicFaceGroups:faceCSNByLocalIdentifierForNewlyClusteredFaces:faceCSNsOfUnclusteredFaces:localIdentifiersOfUnclusteredFaces:persistenceCompletionBlock:canceler:error:]
-[VCPPhotosPersistenceDelegate resetLibraryClustersWithCanceler:error:]
-[VCPPhotosPersistenceDelegate updateKeyFacesOfPersonsWithLocalIdentifiers:forceUpdate:canceler:error:]
-[VCPPhotosPersistenceDelegate bestRepresentativeFaceForPerson:qualityMeasureByFace:canceler:]
-[VCPPhotosPersistenceDelegate bestRepresentativeFaceForPerson:qualityMeasureByFace:candidateFaces:canceler:]
-[VCPPhotosPersistenceDelegate associateFace:withFaceCrop:error:]
-[VCPPhotosPersistenceDelegate clearDirtyStateOnFaceCrops:error:]
-[VCPPhotosPersistenceDelegate dirtyFaceCropsWithLimit:]
-[VCPPhotosPersistenceDelegate faceAssociatedWithFaceCrop:]
-[VCPPhotosPersistenceDelegate facesFromAsset:]
-[VCPPhotosPersistenceDelegate persistFaces:deleteFaces:forAsset:persistedFaces:error:]
-[VCPPhotosPersistenceDelegate persistGeneratedFaceCrops:error:]
-[VCPPhotosPersistenceDelegate recordNeedToPersonBuildOnFaceGroupContainingFace:error:]
-[VCPPhotosPersistenceDelegate suggestedPersonLocalIdentifierForPersonLocalIdentifier:faceClusterer:canceler:context:error:]
-[VCPPhotosPersistenceDelegate updateFaceprint:ofPersistedFace:error:]
-[VCPPhotosPersistenceDelegate buildPersonsWithFaceClusterer:keyFaceUpdateBlock:canceler:context:extendTimeoutBlock:]
(personBuilderState = %ld)
Canceled cleaning up merge candidates of verified persons
v24@?0@"PHFetchResult"8@"NSMutableSet"16
v24@?0@"VCPMergeCandidatePair"8^B16
Canceled cleaning up merge candidates
(trainingType = %d) || (trainingType = %d)
v32@?0@"PHPerson"8@"NSString"16^B24
B24@?0@"VCPMergeCandidatePair"8@"NSDictionary"16
(clusterSequenceNumber IN %@)
Person building cancelled
clusterSequenceNumber = %ld
clusterSequenceNumber != %ld
[FaceCropAdjustment][%@-%d]
v32@?0@"NSString"8@"PHFaceCrop"16^B24
v32@?0@"PHFace"8@"PHPerson"16^B24
v24@?0@"NSDictionary"8q16
v32@?0@"NSString"8@"NSMutableArray"16^B24
q24@?0@"PHFaceCrop"8@"PHFaceCrop"16
v32@?0@"PHFaceCrop"8Q16^B24
MADProcessNewlyClusteredFaceCrops
invalid merge candidate pair created from cluster rejections
potential invalid merge candidate pair created from cluster rejections
invalid merge candidate pair from cluster rejection for verified person
potential invalid merge candidate pair from cluster rejection for verified person
B16@?0^@8
no training faces in level1 cluster - create 'unverified person : verified/migrated person' candidate pair
all training faces on single verified person in level1 cluster - create 'unverified person : training person' candidate pair
all training faces on single verified person in level1 cluster - create 'unverified person : verified person' candidate pair
all training faces on single verified person in level1 cluster - create 'training person : verified person' candidate pair
invalid merge candidate pair because we may have a dirty level0 cluster
multiple training persons in level0 cluster - create 'training person : training person' pair
clusterSequenceNumber
single training person in level0 cluster - create 'training person : verified person with confirmed face' pair
single training person in level0 cluster - create 'verified persons with confirmed face : verified persons with confirmed face' pair
invalid merge candidate pair because one person has face rejected for the other
invalid merge candidate pair because we have > 3 verified persons in the face group
single training person in level1 cluster - create 'training person : verified person with confirmed face' pair
single training person in level1 cluster - create 'verified persons with confirmed face : verified persons with confirmed face' pair
level1 cluster - create 'training person : training person' pair
level1 cluster - create 'unverifed person : training person' pair
invalid merge candidate pair: a cluster rejection
v32@?0@"NSMutableSet"8@"NSMapTable"16@"NSSet"24
invalid merge candidate pair:a face on verified person but cluster-rejected on another verified person
-[VCPPhotosPersistenceDelegate buildPersonWithFaceClusterer:keyFaceUpdateBlock:context:cancelOrExtendTimeoutBlock:]
VCPFaceProcessingBuildPersonsCoreAnalyticsCollection
com.apple.mediaanalysisd.photos.personbuilding
BuildingInterval
BuildingSequence
ClusterCount
ClusterFaceCount
FaceGroupCount
FaceGroupCountNeedToBuild
faceLocalIdentifier is nil
fetched %lu faces for %@
clusterSequenceNumber is nil
personLocalIdentifier is nil
fetched %lu persons for %@
Got a 'nil' photoLibrary. Cannot remove auto assigned faces
(manual = 0) AND ((nameSource = %d) OR (nameSource = %d) OR (nameSource = %d)) AND ((trainingType = %d) OR (trainingType = nil))
Operation to remove faces from verified persons has been canceled
Failed to removed faces from person with localIdentifiers '%@'
not known
PGGraphHelper
exposure
underExpose
q24@?0@"PHSceneClassification"8@"PHSceneClassification"16
@"VCPMADVIDocumentRecognitionResource"8@?0
VCPMADVIDocumentRecognitionTask
VCPMADPersonIdentificationTaskResource
@"VCPMADPersonIdentificationTaskResource"8@?0
VCPMADPersonIdentificationTask
[%@] Failed to configuate VNDetectFaceRectanglesRequest
[%@] Failed to configuate VNCreateFaceprintRequest
[%@] Failed to detect faces - %@
q24@?0@"VNFaceObservation"8@"VNFaceObservation"16
[%@] Failed to print faces - %@
{{x:%.*f, y:%.*f}, {width:%.*f, height:%.*f}} 
com.apple.mediaanalysis
com.apple.mediaanalysisd.analysis
com.apple.mediaanalysisd.photos
com.apple.mediaanalysisd.homekit
com.apple.mediaanalysisd.homekitsession
dateModified
dateAnalyzed
masterFingerprint
adjustedFingerprint
performedAnalysisTypes
statsFlags
metadataRanges
SyncPoint
FaceResults
ShotTypeResults
VoiceResults
MLQualityResults
JunkResults
BlurResults
ExposureResults
MLCameraMotionResults
DistanceResults
SaliencyResults
CompositionResults
ClassificationResults
MusicResults
UtteranceResults
ActivityLevelResults
FacePrintResults
PetsResults
PetsFaceResults
PetsKeypointsResults
PetsActionResults
MovieSummaryResults
SettlingEffectsGatingResults
MovieHighlightResults
MovieHighlightScoreResults
MLHighlightScoreResults
KeyFrameResults
KeyFrameBlurResults
KeyFrameStillResults
TrackingResults
LivePhotoEffectsResults
ParallaxResults
WallpaperExportResults
WallpaperPosterConfigDataResults
FaceQualityResults
SceneChangeResults
ApplauseResults
BabbleResults
CheeringResults
LaughterResults
AudioQualityResults
HumanPoseResults
HumanActionResults
HumanPoseInternalResults
HandsResults
LoudnessResults
KeyFrameResourceResults
VideoStabilizationResults
SongResults
HumanActionClassificationResults
InterpolationResults
WPResults
RotationAnalysisResults
ColorNormalizationResults
VideoCaptionResults
ImageCaptionResults
SettlingEffectResults
FaceQualityFlag
energyValues
peakValues
facePosition
faceBounds
facePoseYaw
facePrint
sharpnessFaces
saliencyBounds
saliencyConfidence
songSignature
wallpaperScore
probableRotation
probableRotationConfidence
colorNormalizationData
vanishingPointConfidence
neighbor
neighborDateModified
gyroStabilization
analysisConfidence
stabilizationRecipe
interpolationURL
settlingEffectURL
petsBounds
petsConfidence
petsKeypoints
petsAction
petsAbsoluteScore
petsRelativeScore
keyFrameTime
keyFrameScore
bestPlaybackCrop
maxHighlightStart
maxHighlightDuration
audioQuality
loopSuggestionState
longExposureSuggestionState
livePhotoEffectsRecipe
livePhotoEffectsGatingDescriptions
livePhotoEffectsMatchingScenes
aesthetic
sceneClassification
saliency
saliencyObjectness
duplicateMatchingFeature
duplicateMatchingAlternateFeature
overallScore
allScores
wellFramedSubjectScore
wellChosenBackgroundScore
tastefullyBlurredScore
sharplyFocusedSubjectScore
wellTimedShotScore
pleasantLightingScore
pleasantReflectionsScore
harmoniousColorScore
livelyColorScore
pleasantSymmetryScore
pleasantPatternScore
immersivenessScore
pleasantPerspectiveScore
pleasantPostProcessingScore
noiseScore
failureScore
pleasantCompositionScore
interestingSubjectScore
intrusiveObjectPresenceScore
pleasantCameraTiltScore
lowKeyLightingScore
acceptableCrop
preferredCrop
humanBounds
humanKeypoints
humanConfidence
humanID
humanActions
torsoPrint
handsBounds
handsKeypoints
handsKeypointsConfidents
handsID
videoCaptionText
videoCaptionConfidence
imageCaptionText
imageCaptionConfidence
frameQualityScore
faceQualityScore
sharpnessScore
texture
stillTime
flashFired
QualityOfService
DutyCycling
VCPTaskIDs
ForcePublish
GyroStabilization
PixelStabilization
MaxNumberOfAssetToProcess
ForceFullScan
Full Face, 
Face, 
Voice, 
Full Scene, 
Scene, 
Junk, 
Blur, 
Exposure, 
Distance, 
Feature, 
Saliency, 
Composition, 
Classification, 
ActivityLevel, 
CurationScore, 
Pets, 
PetsPose, 
MovieCuration, 
Effects, 
Parallax, 
Wallpaper Export, 
Face Quality, 
Audio Classification, 
Human pose, 
Loudness Measure, 
Hands, 
Video Stabilization Pixel, 
Video Stabilization Gyro, 
Gyro Analytics, 
ML Video Attributes, 
Song detection, 
Settling effect, 
Human action, 
Iris Recommendation, 
Video Caption, 
Audio Quality, 
v32@?0@"NSString"8@"NSArray"16^B24
mShortInputDecision
mPreGateStillMetadataDecision
mPreGateVideoTrimDecision
mPreGateVideoMLDecision
mPreGateFacesDecision
stabilizeGateDecision
postGateDecision
finalDecision
loopActivityDecision
bounceActivityDecision
longexpActivityDecision
ALGatingResultError
ALGatingResultUnset
ALGatingResultFail
ALGatingResultPass
SceneAnalysis
FaceAnalysis
EffectsAnalysis
Sceneprint
VideoStabilization
MultiWorkerAnalysis
QuickFaceIdentification
EmbeddingAnalysis
OCRAnalysis
MovieHighlightProcessing
VisualSearchAnalysis
FilesystemAnalysis
Unknown(%lu)
autobahn-nature
autobahn-city
autobahn-citynatureish
otgx_csfbtu_gfnbmf
otgx_csfbtu_nbmf
otgx_cvuupdlt
otgx_hfojubmt_gfnbmf
otgx_hfojubmt_nbmf
otgx_opof
otgx_voefsxfbs
otgx_boz
otgx_fyqmjdju
otgx_hfojubmt
meme_document_check_or_checkbook
meme_curation_meme
meme_curation_screenshot
meme_document_boarding_pass
meme_document_currency_or_bill
meme_document_driving_license
meme_document_office_badge
meme_document_passport
meme_document_receipt
meme_document_social_security_number
meme_hier_negative
meme_hier_document
meme_hier_curation
meme_negative
meme_document
meme_screenshot_etc
hier_text_document
hier_tragic_failure
tragic_failure
screenshot
bad_framing
bad_lighting
blurry
food_or_drink
junk_other
medical_reference
negative
receipt_or_document
repair_reference
shopping_reference
utility_reference
junk_negative
hier_negative
junk_non_memorable
hier_non_memorable
junk_poor_quality
hier_poor_quality
No Resource
Download Throttled
Soft Failure
Hard Failure
Duplicate Failure
Upload Failure
PhotoLibraries
ImageTooSmall
UsingBestResource
FacesToDelete
FacesToPersist
VisionClustersMinusLibraryClusters
LibraryClustersMinusVisionClusters
failed
processed
pet-vip-status
person-vip-status
prioritized-processed
prioritized-total-allowed
full-analysis-complete-processed
full-analysis-partial-processed
Confidence
BoundingBox
UserInteractive
UserInitiated
Default
Utility
Background
Unspecified
OptInStatus
FileURL
GroundTruthURL
PersonIdentifier
PersonInformation
UserLabeledGender
UserLabeledAge
UserLabeledEthnicity
ModifyPersonRequest
SubTasks
NumberOfAssetsAllowedForPhotosFaceProcessing
NumberOfAssetsAnalyzedForPhotosFaceProcessing
NumberOfPrioritizedAssetsAnalyzedForPhotosFaceProcessing
NumberOfPrioritizedAssetsAllowedForPhotosFaceProcessing
Success
Canceled
Status Error
Parameter Error
Unknown Error
resident: %@, virtual: %@, phys_footprint: %@, phys_footprint_peak: %@.
resident: N/A, virtual: N/A, phys_footprint: N/A, phys_footprint_peak: N/A.
supportedRevisions
supportedPrivateRevisions
MediaAnalysisVersion
LatestVersionTimeStamp
MediaAnalysisCompleteTimestamp
MediaAnalysisProgressPercentage
SceneAnalysisVersion
LatestSceneAnalysisVersionTimestamp
SceneAnalysisCompleteTimestamp
SceneAnalysisProgressPercentage
FaceAnalysisVersion
LatestFaceAnalysisVersionTimestamp
FaceAnalysisCompleteTimestamp
FaceAnalysisProgressPercentage
PrioritizedFaceAnalysisCompleteTimestamp
PrioritizedFaceAnalysisProgressPercentage
OCRAnalysisVersion
LatestOCRAnalysisVersionTimestamp
OCRAnalysisCompleteTimestamp
OCRAnalysisProgressPercentage
VisualSearchAnalysisVersion
LatestVisualSearchAnalysisVersionTimestamp
VisualSearchAnalysisCompleteTimestamp
VisualSearchAnalysisProgressPercentage
EmbeddingAnalysisVersion
LatestEmbeddingAnalysisVersionTimestamp
EmbeddingAnalysisCompleteTimestamp
EmbeddingAnalysisProgressPercentage
Bytes
%llu %@
Error: failed to processSampleBuffer
cnn_faceblur.dat
feature_extraction
t_19
t_57
t_76
t_95
t_114
types
date
typesWide
assetIdentifier
assetModificationDate
assetMasterFingerprint
assetAdjustedFingerprint
imageBlurResults
imageCompositionResults
imageFaceResults
imageFeatureResults
imageJunkResults
imageSaliencyResults
imageShotTypeResults
imagePetsResults
imagePetsFaceResults
imageSceneprintResults
livePhotoEffectsResults
livePhotoRecommendationResults
livePhotoSharpnessResults
livePhotoKeyFrameResults
livePhotoKeyFrameStillResults
movieActivityLevelResults
movieCameraMotionResults
movieClassificationResults
movieFaceResults
movieFaceprintResults
movieFeatureResults
movieFineSubjectMotionResults
movieInterestingnessResults
movieMovingObjectResults
movieMusicResults
movieObstructionResults
movieOrientationResults
moviePreEncodeResults
movieQualityResults
movieSaliencyResults
movieSceneResults
movieSceneprintResults
movieSubjectMotionResults
movieSubtleMotionResults
movieUtteranceResults
movieVoiceResults
movieSummaryResults
movieHighlightResults
imageExposureResults
imageHumanPoseResults
movieHumanPoseResults
movieApplauseResults
movieBabbleResults
movieCheeringResults
movieLaughterResults
movieHumanActionResults
movieLoudnessResults
moviePetsResults
moviePetsFaceResults
movieStabilizationResults
movieHighlightScoreResults
livePhotoHumanActionClassificationResults
movieAudioQualityResults
OCR/MRC
GlobalXSum
GlobalYSum
Type
cnn_lm.dat
Cannot generate facecrop without originating face
Failed to find originating PHFace %@
Failed to generate facecrop on manual originating face %@
Facecrop is nil
Missing image data from facecrop %@
Invalid facecrop image data %@
Invalid facecrop bounding box %@
Facecrop image size equals to 0
Failed to normalize bound %@ with image (%.0fx%.0f)
Failed to obtain the facecrop image dimensions
Failed to create VNImageRequestHandler
Failed to set VNDetectFaceRectanglesRequest
Failed to set VNCreateFaceprintRequest
Failed to analyze facecrop - %@
Failed to create faceprint - %@
Failed to wrap faceprint/faceTorsoprint
Face has already been persisted with a facecrop
Face does not have a faceprint
Failed to fetch facecrop
Failed to persist face and facecrop
[FaceCropManager] faceLocalIdentifier is nil
[FaceCropManager] Fetched %lu faces with face identifier %@, should be 1
[FaceCropManager] Failed to fetch face %@
yyyyMMdd
en_US_POSIX
FaceIDModelLastGenerationKey
PetIDModelLastGenerationKey
Person
com.apple.mediaanalysis.quickfaceid.management
VCPPersonVIPLoadModel
VCPPetVIPLoadModel
nameSource == %ld
verifiedType = %@
faceCount
nameSource != %ld
VCPPetVIPGenerateModel
isInVIPModel == YES
roll == 0.0
graph
user
VCPPersonVIPGenerateModel
VCPCNNBlurAnalyzerEspresso.sharedModelPool-%lu
cnn_blurV2.espresso.net
cnn_blur.espresso.net
VCPBlurEspresso
res_299x299
res_400x400
res_400x300
res_300x400
yyyy-MM-dd-HH-mm-ss
suggestionLog_
suggestions.html
function addPlaceHolders() {
addPlaceholdersForSet("visionInput", inputFaces);
addPlaceholdersForSet("visionOutput", outputFaces);
addPlaceholdersForSet("visionFiltered", filteredFaces);
function isElementHidden(element) {
var style = window.getComputedStyle(element);
return (style.display === 'none')
function updateVisibility() {
var allDivs = document.getElementsByTagName("div");
for (var i = 0; i < allDivs.length; i++) {
var d = allDivs[i];
if (!d.attributes["img"]) continue;
var rect = d.getBoundingClientRect();
if (
rect.top >= -100 &&
rect.left >= -100 &&
rect.bottom - 100 <= (window.innerHeight || document.documentElement.clientHeight) &&
rect.right - 100 <= (window.innerWidth || document.documentElement.clientWidth)
if (d.childNodes.length == 0) {
d.innerHTML = "<img src='" + d.attributes["img"].value + "' width='100' height='100'>";
else {
if (d.childNodes.length != 0) {
d.innerHTML = "";
function addPlaceholdersForSet(containerId, elements) {
var content = "";
for (var i = 0; i < elements.length; i++) {
content += "<div style='float: left; width: 100px; height: 100px; margin: 3px; background-color: darkgray' img='" + elements[i] + "'></div>"
document.getElementById(containerId).innerHTML = content;
document.onscroll = function (e) {
updateVisibility();
</script>
</head>
<body>
<p>Vision input:</p>
<div id="visionInput">
</div>
<p style="clear: both;">Vision output:</p>
<div id="visionOutput">
</div>
<p style="clear: both;">Vision filtered output:</p>
<div id="visionFiltered">
</div>
</div>
<script>
document.addEventListener("DOMContentLoaded", function (event) {
addPlaceHolders();
</script>
</body>
</html>
could not obtain access to the photo library
photo library could not provide suggestions
_suggestionsForPersonWithLocalIdentifier cancelled
v16@?0Q8
<html>
<head>
<script>
 var inputFaces = [
v32@?0@"NSString"8@"NSArray"16@"NSError"24
var outputFaces = [
var filteredFaces = [
suggestPersonsForPersonWithLocalIdentifier cancelled
Input parameter is empty or nil: '%@'
Failed to find persons with local identifiers: '%@'
VCPClusterer is nil
verifiedType != %d
VCPFaceProcessingDeleteAllVerifiedPersons
succeeded
VCPFaceProcessingReclusterFacesWithThreshold
VCPFaceProcessingBuildPersons
VCPBuildPersons failed %d
VCPFaceProcessingPromotePersons
VCPPromotePersons failed %d
Failed to rebuild persons (error: %d)
Failed to promote persons (error: %d)
B32@?0@"NSDictionary"8Q16^B24
PVPersonPromoter
Memories
iMovie
v48@?0^{CGImage=}8{?=qiIq}16@"NSError"40
IrisObjectsResults
MetaStabilizationResults
MetaStabilizationFrameResults
MetaHomographyDimensionResults
MetaHomographyResults
MetaPresentationTimeResults
MetaMotionBlurResults
MetaPTSInNanosResults
MetaOriginalPTSInNanosResults
MetaItemPTSResultsKey
MetaAdjusterResults
MetaAdjusterRecipeResults
MetaAdjusterDisplacementKey
MetaInterpolatedFrameKey
MetaLensSwitchResults
autoplay_head.espresso.net
var_99
NotImplementedException
[VideoTrackDecoder status] should not be called
[VideoTrackDecoder copyNextSampleBuffer] should not be called
[VideoTrackDecoder getNextCaptureSampleBuffer] should not be called
  state            : %d
  originating face : %@
action_repetition_counter
mlmodelc
VCPMADVIVisualSearchGatingTask
<redacted>
Failed to create visual search query context
VIService_VisualSearchGating
v32@?0@"VIParseResult"8@"NSData"16@"NSError"24
.espresso.net
callback queue
Create Context Error
Create Plan Error
%@ Load Error
Build Model Error
Select Configuration Error
Build Plan Error
Clean Plan Error
B24@?0@"NSString"8@"NSDictionary"16
VCPFaceAnalyzerFillMissingFaceprint
VCPFaceAnalyzerFaceQuality
aggregated
faceID
faceprintBlob
Live Photo
Pano Photo
Screenshot
HDR Photo
SDOF Photo
Photo
Slow-mo Movie
Timelapse Movie
Movie
VCPMADVIVisualSearchTask
v24@?0@"VISearchResult"8@"NSError"16
VIService_ParsedVisualSearch
VIService_VisualSearch
cnn_smile.dat
Failed to load asset
Asset contains no video tracks
Failed to create video track output
Failed to start decoding video track
Video processor cancelled
Failed to complete video decoding
recipeBlob
keyFrame
playbackCrop
colorNormalizationBlob
hasAction
Video stabilization task cancelled
Video stabilization processing failed
VideoCNN
Skeleton
enabled
formatDescriptions
naturalSize
nominalFrameRate
preferredTransform
tracks
res_384x384
q24@?0@"NSNumber"8@"NSNumber"16
res_%dx%d
obstructionScore
VCPMADServiceImageProcessingTask
%@ not currently implemented
q24@?0@"NSObject<VCPMADServiceImageProcessingSubtaskProtocol><VCPMADTaskProtocol>"8@"NSObject<VCPMADServiceImageProcessingSubtaskProtocol><VCPMADTaskProtocol>"16
[MediaAnalysis][%@]Unable to open movie, skip
[MediaAnalysis][%@]Failed to create asset
[%@] Analysis cancelled
[%@] Analysis failed to complete
outputFrameDurValue
cropRectX
cropRectY
cropRectHeight
cropRectWidth
autoloop
bounce
longexposure
stabilize
minVersion
cnn_blink.espresso.net
VCPGazeEspresso
PersonBuilderMergeCandidatesEnabled
PersonBuilderLastMinimumFaceGroupSizeForCreatingMergeCandidates
personBuilderState != %lu
VCPFaceProcessingCleanupMergeCandidates
v16@?0@"NSArray"8
VCPPersonBuilder_UpdateKeyface
statisticsBlob
@"VCPMADVIRectangleDetectionResource"8@?0
VCPMADVIRectangleDetectionTask
com.apple.mediaanalysis.SceneProcessingGroup
MonzaV4_1
@"CVNLPCommSafetyHandler"8@?0
%@%@
classID
size
score
v32@?0@"VNRecognizedObjectObservation"8Q16^B24
v24@?0@"PFSceneTaxonomyNode"8^B16
v32@?0@"NSDictionary"8Q16^B24
meme_
v32@?0@"NSString"8@"NSString"16^B24
cnn_human_pose_single.espresso.net
subjectMotionScore
motionDivScore
objectsMotion
globalMotion
interestingnessScore
trackingScore
sceneChangeScore
browDown_L
browDown_R
browInnerUp
browOuterUp_L
browOuterUp_R
cheekPuff
cheekSquint_L
cheekSquint_R
eyeBlink_L
eyeBlink_R
eyeLookDown_L
eyeLookDown_R
eyeLookIn_L
eyeLookIn_R
eyeLookOut_L
eyeLookOut_R
eyeLookUp_L
eyeLookUp_R
eyeSquint_L
eyeSquint_R
eyeWide_L
eyeWide_R
jawForward
jawLeft
jawOpen
jawRight
mouthClose
mouthDimple_L
mouthDimple_R
mouthFrown_L
mouthFrown_R
mouthFunnel
mouthLeft
mouthLowerDown_L
mouthLowerDown_R
mouthPress_L
mouthPress_R
mouthPucker
mouthRight
mouthRollLower
mouthRollUpper
mouthShrugLower
mouthShrugUpper
mouthSmile_L
mouthSmile_R
mouthStretch_L
mouthStretch_R
mouthUpperUp_L
mouthUpperUp_R
noseSneer_L
noseSneer_R
tongueOut
focalLengthInPixels
objects
faceRollAngles
faceAnchor
vertices
transform
blendshapes
geometry
dispatchQueue
regionsOfInterest
aggSubjectMotionScore
turboMode
frameWidth
frameHeight
VCPCaptureAnalysis
v28@?0f8f12Q16i24
cnn_pets.espresso.net
VCPPetsEspresso
res_0
res_1
res_2
gesture_recognition.espresso.net
cnn_human_pose.espresso.net
AllowOnDemandPixel
AllowOnDemandGyro
AllowStreaming
KeepPrivateResults
MaxHighlightDuration
Standalone
StoreAnalysis
ScaledSlomoTime
com.apple.mediaanalysis.ondemand
com.apple.mediaanalysis.storage
com.apple.mediaanalysis.VCPMediaAnalyzer.sandboxQueue
com.apple.mediaanalysis.VCPMediaAnalyzer.cancelQueue
v16@?0@"NSString"8
VCPMediaAnalyzer
Sceneprint task cancelled
[%@] Thumbnail is not locally available
[%@] Failed to load thumbnail image
[%@] Failed to set revision %lu - %@
[%@] Invalid sceneprint result
45.1
mediaType == %d
kind == %d && kindSubtype != %d
mediaType == %d && !((mediaSubtype & %d) == %d)
kindSubtype == %d
(mediaSubtype & %d) == %d
!((mediaSubtype & %d) == %d)
mediaAnalysisAttributes.mediaAnalysisVersion < %d
kindSubtype != %d && SUBQUERY(additionalAttributes.sceneClassifications, $s, $s.sceneIdentifier = %d AND $s.confidence > %f).@count > 0
kindSubtype != %d && SUBQUERY(additionalAttributes.sceneClassifications, $s, $s.sceneIdentifier = %d AND $s.confidence > %f).@count = 0
SUBQUERY(additionalAttributes.sceneClassifications, $s, $s.sceneIdentifier = %d AND $s.confidence >= %f).@count > 0
SUBQUERY(additionalAttributes.sceneClassifications, $s, $s.sceneIdentifier = %d AND $s.confidence >= %f).@count = 0
additionalAttributes.sceneAnalysisVersion != %d || adjustmentTimestamp != additionalAttributes.sceneAnalysisTimestamp
adjustmentTimestamp != faceAdjustmentVersion
mediaAnalysisAttributes.characterRecognitionAttributes = NULL || mediaAnalysisAttributes.characterRecognitionAttributes.algorithmVersion != %d || adjustmentTimestamp != mediaAnalysisAttributes.characterRecognitionAttributes.adjustmentVersion
mediaAnalysisAttributes.visualSearchAttributes = NULL || mediaAnalysisAttributes.visualSearchAttributes.algorithmVersion != %d || adjustmentTimestamp != mediaAnalysisAttributes.visualSearchAttributes.adjustmentVersion
VCPMADVisionResource
output1
output2
output3
cnn_hand_detector_v2.espresso.net
VCPMAMLModel-%@
@"VCPMAMLModel"8@?0
maxNumberHands
humanActionWindowSize
motionFlowComputationAccuracy
v32@?0@"NSString"8@"NSString"16@"NSError"24
identifier
mediaanalysis://in-memory
com.apple.mediaanalysisd.VCPInMemoryAVAsset
Frame: %u
textureness
hasFlash
supportedImageSizeSet
v24@?0^v8Q16
v16@?0@"NSData"8
Destructive Trim Range: [%.2f - %.2f]
after repare
after consecutive short merge
after sparse short merge
after post processing
=========Segment %s==========
v32@?0@"VCPSegment"8Q16^B24
 [%.2f - %.2f]: %.2f
--[%.2f - %.2f]
com.apple.mediaanalysis.VCPDefaultPhotoLibraryManager
precision
personID
validFaceCount
identitySize
recall
AutoCounterGroundTruth.plist
[AutoCounter] Cannot load ground truth file URL
no_name
AddedDate
unknown
unverified
verifiedType
personName
faceRect
faceGroupID
faceprint
momentIdentifier
[AutoCounter] Failed to fetch person (%@)
FacesPerAsset
OptInDate
OptInDateSinceReferenceDate
OptInMADFaceVersion
OptInDetectionModelVersion
OptInRecognitionModelVersion
FaceCount
AssetCount
AdditionalInformation
AutoCounterClusters_Ver%d_DetectionVer%lu_RecognitionVer%lu.plist
[AutoCounter] Failed to retrive export URL
mergecandidates
faces
assetInformation
[AutoCounter] Failed to process FaceGroups
v32@?0@"NSString"8@"NSDictionary"16^B24
AutoCounterClusterAssetsToFaces_Ver%d_DetectionVer%lu_RecognitionVer%lu.plist
phFaceID
gtFaceID
gtPersonID
v32@?0@"NSString"8@"NSSet"16^B24
com.apple.photos.autocounter
date_optin
detection_version_current
detection_version_optin
mad_version_current
mad_version_optin
person_id
promoter_clusters
promoter_clusters_duplicates
promoter_precision
promoter_recall
promoter_version_current
promoter_version_optin
recognition_version_current
recognition_version_optin
total_assets
total_assets_optin
total_faces
total_faces_optin
type
userLabeledAge
userLabeledEthnicity
userLabeledGender
vision_clusters
vision_clusters_duplicates
vision_precision
vision_recall
nightly
nightly-Ver%d_DetectionVer%lu_RecognitionVer%lu_PersonVer%lu
AutoCounterCoreAnalytics
%@_Ver%d_DetectionVer%lu_RecognitionVer%lu.plist
self.lastPathComponent BEGINSWITH %@
v32@?0@"NSURL"8Q16^B24
visionCluster
weightedAveragePrecision
weightedAverageRecall
numSingletons
numValidSingletons
precisionPerCluster
recallPerPersonToGroundTruth
recallPerPersonExcludeMissDetection
personCluster
identity
PVPersonPromoterVersion
Apple
cnn_saliency.dat
VCPMADVIUserFeedbackTask
VIService_UserFeedback
@"VCPMADVIVisualSearchResource"8@?0
mdta/com.apple.quicktime.live-photo-info
propertyKey %s 
result is nil %s
sum = %6.2f, tracking_score = %6.2f
Target Captured @ [%5.0f, %5.0f, %5.0f, %5.0f]
initial @ [%d %d] s = %6.5f
stop    @ [%d %d] s = %6.5f
lost = %d
[%6.2f, %6.2f, %6.2f, %6.2f]
box0: (x = %2.1f, y = %2.1f, w = %2.1f, h = %2.1f)
box1: (x = %2.1f, y = %2.1f, w = %2.1f, h = %2.1f)
box : (x = %2.1f, y = %2.1f, w = %2.1f, h = %2.1f)
overlap_area = %6.2f, max_area = %6.2f, weight = %6.2f
derr = %6.2f, terr = %6.2f
add new expert with weight %6.2f
expert %d was replaced: voting weight(%6.2f --> %6.2f)!
after voting --> update target
detector and tracker did not match well --> experts vote
detector and tracker matched well --> update experts
VCPImageHumanActionEspresso
cnn_image_human_action.espresso.net
res_192x192
hand_keypoint_detector.espresso.net
regressiontree_landmark.dat
rtree_landmark_tracking.dat
com.apple.mediaanalysisd.VCPVideoFaceValidation
face_validation_warp_tri_list.dat
face_validation_warp
face_validation_warp_params.dat
%@_%d.dat
com.apple.mediaanalysis.VCPImageManager.transcodeQueue
VCPImageManager
@"VCPImageManager"8@?0
MADImageManagerEncode_%.3f_unpadded.jpg
MADImageManagerEncode_%.3f_padded.jpg
/Library/Audio/Tunings/Generic/AU/aufx-epv2-mediaanalysis-appl.plist
cnn_pose.dat
motionType
isFast
sourceSize
inputBounds
VCPVideoCNNActionClassifierEspresso
VCPVideoCNNActionClassifierEspressoStage1
action_recognition_head.espresso.net
action_taxonomy.plist
boxes
action_recognition_head_stage1.espresso.net
q24@?0@"PHFace"8@"PHFace"16
cnn_saliency.espresso.net
VCPSaliencyFullEspresso
energy
peak
%@ canceled
%@ is not yet implemented
frame idx = %d
size = %d, track_target_exist = %d, target_lost = %d, tracking_score = %6.2f
com.apple.homekitanalysis.service.management
com.apple.homekitanalysis.service.handler
Failed to fetch person by local identifier (%@)
HMIAnalysisService
Failed to create VNAlignFaceRectangleRequest
Failed to exercise Vision request - %@
UserOrig
UserAlgo
NoUserAlgo
NoAlgo
cnn_person_detector.espresso.net
PetsRegions
PetsFaceRegions
{CGRect={CGPoint=dd}{CGSize=dd}}
res_256x256
VCPHumanPoseEspresso
res_320x192
res_192x320
clusterer is not available
Face clustering threshold should be in the range: [0.1, 1.0]
VCPFaceProcessingResetFaceClusteringState
VCPFaceProcessingPerformFaceClusteringAndWait
backwarpNonInterleaved
LogLevel
yyyy-MM-dd HH:mm:ss
autoPlayable
Angle
cnn_blur.dat
iChatUsageString
EnableStatsCollect
EnableUserQPForFacetime
EnableUserRefForFacetime
EnableWeightedPrediction
UserFrameType
ReferenceFrameNumDriver
ReferenceL0
UserQpMap
MBStatistics
NotSync
ClonedImageCaptionModel
en-US
Failed to load imageURL: %@
NeuralHash+LSH invalid imageSignatureHash
Invalid NeuralHash+LSH (=)
v20@?0f8^B12
VCPFaceProcessingPromotePersonsCoreAnalyticsCollection
com.apple.mediaanalysisd.photos.personpromoting
GraphVerifiedPersonCount
PromotingInterval
PromotingSequence
TotalFaceCount
UnverifiedPersonCount
UserVerifiedPersonCount
com.apple.Photos
Received action score %f - %f
=========%s==========
[%.2f - %.2f]: %.2f
capturePointSegmentIdx: %d
----[%.2f - %.2f]
startIdx = %d, endIdx = %d, count = %d, [%f, %f] with score %f captureTime=%f
interesting trim: [%f, %f], score = %.2f
 --[%.2f - %.2f]
===========SceneChangeSegments=============
[%f, %f]
Measurement
Min (s)
Max (s)
Avg (s)
Total
Count
Minimum
Maximum
Average
signpost
com.apple.mediaanalysisd.livephotoeffectanalysisresults
com.apple.mediaanalysisd.moviecurationresults
com.apple.mediaanalysisd.livephotokeyframeresults
com.apple.mediaanalysisd.das.dutycycle
com.apple.mediaanalysisd.das.dutycycle.task
com.apple.mediaanalysisd.analysis.pets
com.apple.mediaanalysisd.livePhotoFillingGaps
LivePhotoEffectsShortInputDecision
LivePhotoEffectsPreGateStillMetadataDecision
LivePhotoEffectsPreGateVideoTrimDecision
LivePhotoEffectsPreGateVideoMLDecision
LivePhotoEffectsPreGateFacesDecision
LivePhotoEffectsStabilizeGateDecision
LivePhotoEffectsPostGateDecision
LivePhotoEffectsFinalGateDecision
LivePhotoEffectsLoopActivityDecision
LivePhotoEffectsBounceActivityDecision
LivePhotoEffectsLongexpActivityDecision
LivePhotoEffectsStabilizeResult
MediaType
AutoPlayableScore
SummaryDuration
IsTrimmed
KeyFrameIsSuggested
KeyFrameScoreDifference
KeyFrameTimestampOffset
KeyFrameIsFaceQualityDominant
KeyFrameIsSharpnessDominant
KeyFrameIsSemanticDominant
KeyFrameIsSuggestedEdit
KeyFrameScoreDifferenceEdit
KeyFrameTimestampOffsetEdit
KeyFrameIsFaceQualityDominantEdit
KeyFrameIsSharpnessDominantEdit
KeyFrameIsSemanticDominantEdit
previousQoS
previousQoSDuration
requestedQoS
taskName
taskStatus
DownloadAssetCount
DownloadBytes
Duration
Delay
AvgSpeed
AssetType
NumberOfPetFacesDetected
NumberOfPetsDetected
ResourceType
SceneType
AggregatedBoundingBoxSizeRatio
LargestBoundingBoxSizeRatio
com.apple.mediaanalysis.coreanalytics
VCPMADCoreAnalyticsManager
@"VCPMADCoreAnalyticsManager"8@?0
SHMutableSignature
correlationNonInterleaved
[VCPAsset %@] should not be called
mediaType
mediaSubtypes
pixelWidth
pixelHeight
exif
imageWithPreferredDimension:
imageWithPreferredDimension:orientation
movie:
isMovieResourceLocalAvailable:
originalMovie:
Start
FramesPerSecond
v16@?0@"NSURL"8
VCPDownloadResource
inputBoundsX
inputBoundsY
inputBoundsHeight
inputBoundsWidth
sourceSizeHeight
sourceSizeWidth
homographyParams
cnn_pet_pose.espresso.net
cameramotiontype_head.espresso.net
cameramotionscore_head.espresso.net
VCPMADResourceManager
@"VCPMADResourceManager"8@?0
q24@?0@"VCPMADResourceEntry"8@"VCPMADResourceEntry"16
com.apple.mediaanalysisd.VCPMADResourceManager
DeviceClass
iPad
pLzf7OiX5nWAPUMj7BfI4Q
marketing-name
inputImage
angle
v24@?0@"MLModel"8@"NSError"16
Getting no object IDs when fetching assets on moment %@
Reachability initialization failed; assuming no connection
Reachability flags invalid; assuming no connection
%sonnected to internet via WiFi/Ethernet
Network reachability flag changed to: %@
Human action - no PHFaces found
Failed to lock CVPixelBuffer (%p, %d)
Cannot lock NULL CVPixelBuffer
Lock attempt failed; cannot unlock buffer
Multiple unlock attempts; cannot unlock buffer
Failed to unlock CVPixelBuffer (%p, %d)
Failed to allocate memory
[VCPVideoFullFaceDetector] Detected face %@
[VCPVideoFullFaceDetector] Failed to detect faces - %@
Failed to retrieve faceprint revision from key faces
Failed to create Vision clusterer - %@
Failed to cluster faces - %@
Creating faceprint for face crop
Multiple faces present in face crop; using first
Loading quick identification model
Performing quick identification
Quick identification match found: %@
No quick identification match found
Home face identification task failed (%@)
inferenceHandKeypointCallFromSPI
Failed to allocate textureness or dst buffer for image resolution %dx%d
[MediaAnalysis] Image descriptor - found more than 1 VNImageprintObservations
VNImageprint init error: %@
VCPClusterer: Terminating ...
VCPClusterer: Terminated
VCPClusterer: Cluster triggering set to %lu
VCPClusterer: Scheduling to remove %lu faces and add %lu faces
VCPClusterer: total remove %lu faces and add %lu faces
VCPFaceProcessingClusterFacesCoreAnalyticsCollection
VCPClusterer: Removing %lu faces from cluster cache
VCPClusterer: Failed to cluster(removing) faces - %@
VCPClusterer: Removed %lu faces from cluster cache [time: %f secs]
VCPClusterer: Adding %lu faces to cluster cache
VCPClusterer: Number of orderedFaceIdentifiers (%lu) != number of _faceIdStrsToAdd (%lu)
VCPClusterer: missing localIdentifiers : %@
VCPClusterer: %lu faces to cluster, already took %f seconds
VCPClusterer: %lu faces in current batch, %lu faces remain
VCPClusteringGetFaceObservations
VCPClusterer: Number of faceTorsoprintsToAdd (%lu) !=  number to cluster (%lu)
VCPClusterer: Failed to cluster(adding) faces - %@
VCPClusterer: Added %lu faces to cluster cache
VCPClusteringBatch
VCPClusterer: Added faces to cluster cache [time: %f secs]
VCPClusterer: Start clustering
VCPClusterer: Finished clustering %lu faces, with normalized %.2f millisecond per face
VCPClusterer: Vision failed to cluster - %@
[VisionFgMapping] Preparing Vision Clusters (size: %ld) to Photos FaceGroup
VCPVisionFgMapping_Prepare
VCPClusterer: Failed to save cluster cache - %@
VCPClusterer: Start to update database models
VCPClusterer: Failed to persist FaceGroups; will try next time - %@
VCPClusterer: Updated database models
VCPClusterer: Cannot cluster image print type %lu
VCPClusterer: Failed to get VNFaceTorsoprint from face %@ - %@
VCPClusterer: Missing faceprint data for face %@
VCPClusterer: Failed to remove empty FaceGroup(s) - %@
VCPClusterer: Start quick-syncing cluster cache with library
VCPClusterer: Failed to clean faces with valid CSN but not in any FaceGroup - %@
VCPClusterer: Failed to clean faces with CSN = 0 but found in any FaceGroup - %@
VCPClusterer: Number of clustered faces in the cluster cache (%lu) < number of clustered faces in the library (%lu)
VCPClusterer: Quick-syncing cluster cache with library, found > 10%% (%5.2f) difference in the number of faces that are in the cluster cache versus library
VCPClusterer: Finished quick-syncing cluster cache with library. Elapsed time: %f
VCPClusterer: Start syncing cluster cache with library ...
VCPClusterer: Retrieving clusters from cluster cache ...
VCPClusterer: Retrieved clusters from cluster cache
VCPClusterer: Failed to retrieve clusters from cluster cache - %@
VCPClusterer: Retrieving clusters from library ...
VCPClusterer: Retrieved clusters from library
VCPClusterer: Failed to retrieve clusters from library - %@
VCPClusterer: Syncing cluster cache with library, found %lu non-singleton clusters in the cluster cache that do not match those in the library
VCPClusterer: Syncing cluster cache with library, found %lu clusters in the library cache that do not match those in the cluster cache
VCPClusterer: Syncing cluster cache with library, found > 20%% (%5.2f) difference in the number of faces are in the cluster cache versus library
VCPClusterer: Failed to ungroup faces - %@
VCPClusterer: Successfully reset cluster cache - %@
VCPClusterer: Failed to reset cluster cache - %@ - %@
VCPClusterer: Deleting FaceGroups and reset CSN of all previously clustered faces
VCPClusterer: Canceled syncing cluster cache [point: %d do loop]
VCPClusterer: Retry deleting FaceGroups and reset CSN of all previously clustered faces. Attempt %d of %d.
VCPClusterer: Deleted FaceGroups and reset CSN of all previously clustered faces
VCPClusterer: Failed to delete face groups and reset CSN of all previously clustered faces - %@
VCPClusterer: Syncing cluster cache with library - %@
VCPClusterer: Schedule adding %lu faces to the cluster state
VCPClusterer: Failed to get faces that are no longer present in the library
VCPClusterer: Canceled syncing cluster cache [point: %d]
VCPClusterer: Schedule removing %lu faces from the cluster state
VCPClusterer: Finished syncing cluster cache with library - %@
%@ - %@
Creating VNClustererBuilder with context.processingVersion:%d, type: %@, cachePath: %@, faceprintRequestRevision-%lu threshold-%.2f, torsoprintRequestRevision-%lu threshold-%.2f
VCPClusterer: Started resetting cluster cache ... 
VCPClusterer: Failed to remove all cluster cache files - %@
VCPClusterer: Created a new cluster cache
VCPClusterer: Failed to save a new cluster cache - %@
VCPClusterer: Finished resetting cluster cache
VCPClusterer: Failed to create a new cluster cache - %@
VCPClusterer: Failed to get old vision cluster cache filenames from vision cluster state
VCPClusterer: Failed to remove cluster mmap file at '%@' - %@
VCPClusterer: Failed to restore Vision clustering state - %@
VCPClusterer: Failed to unarchive cluster cache data blob from '%@'
VCPClusterer: Resetting cluster cache files - %@
VCPClusterer: Started restoring cluster cache
VCPClusterer: Failed to restore cluster cache - %@
VCPClusterer: Failed to restore cluster cache
VCPClusterer: Failed to restore cluster cache with std::exception %s
VCPClusterer: Restored cluster cache. Clusterer bring-up state - %@, time to restore: %f secs
[VisionFgMapping] Checking l1-cluster %@ (%ld faces) for conflict
[VisionFgMapping] Resolving conflict l0-cluster %@ in l1-cluster %@
VCPClusterer: Failed to get Vision clusters - %@
VCPClusterer: Retrieving clusters in cluster cache ...
VCPClusterer: Failed to retrieve clusters in cluster cache - %@
VCPClusterer: Retrieving clusters in library ...
VCPClusterer: Failed to retrieve clusters in library - %@
VCPClusterer: Comparing clusters
VCPClusterer: Failed to remove cluster snapshot at '%@': %@
VCPClusterer: Failed to remove cluster mmap file at '%@': %@
VCPClusterer: Bring-up state transition: %@ -> %@
VCPClusterer - _calculateChecksumMD5ForFile: error reading %zu bytes from file
Not implemented, please use initWithOptions
Incompatible request (%@) specified to %@
[RemoveBackground][%@] running (Mask: %d, Crop: %d, In-Place: %d)...
[RemoveBackground][%@] Skipping for ineligible image
[RemoveBackground][%@] Checking for cached image handler...
[RemoveBackground][%@] Matched cached image handler(!)
[RemoveBackground][%@] No cached image handler
[RemoveBackground][%@] Cached image handler does not match
[RemoveBackground][%@] Resetting cached image handler
VCPMADVIRemoveBackgroundTask image loading failed
[RemoveBackground] Image is screenshot - detecting ROI
[RemoveBackground] Failed to detect screenshot ROI (%@)
[RemoveBackground] Screenshot has no ROI (%@)
[RemoveBackground] Screenshot ROI: (%0.2f, %0.2f) %0.2fx%0.2f Confidence: %0.2f [1 of %d]
VNImageRequestHandler_init
[RemoveBackground] Set VNProcessingDevice: %@ (%@)
[RemoveBackground] Perform-in-place requested for ineligible input; ignoring
[%@] In Place: %d Crop: %d  Mask: %d  ROI: (%0.2f, %0.2f) %0.2fx%0.2f
VNImageRequestHandler_performRequests
[RemoveBackground][%@] Caching image handler (resolution %dx%d, orientation %d)
[RemoveBackground] No observations produced for image
[RemoveBackground][%@] complete
Invalid VNRequest configuration (%@)
VNRequest must be non-nil
[MediaAnalysis][%@] Analysis requested for blacklisted asset
[MediaAnalysis][%@] Existing analysis based on old modification
[MediaAnalysis][%@] Existing analysis based on degraded asset
[MediaAnalysis][%@] Existing analysis satisfies request (%@)
[MediaAnalysis][%@] Existing analysis doesn't match asset state
[MediaAnalysis][%@] Existing analysis doesn't satisfy request (%@)
[MediaAnalysis][%@] Generating analysis on-demand: %@
  [%@] Analysis cancelled
  [%@] Analysis failed to complete
Unsupported photo analysis type %@
Unsupported movie analysis type %@
VCPFullAnalysisAssetProcessingTask
VCPFullAnalysisAssetProcessingTask processing failed
Media analysis client XPC connection interrupted
Media analysis client XPC connection invalidated
[MediaAnalysis] [MediaAnalyzer requestAnalysisTypes] call with invalid resourceURLs
Failed to issue sandbox extension on %@
[MediaAnalysis] Error connecting to background analysis service
[MediaAnalysis] Request %d has completed
[MediaAnalysis] Error connecting to Photos background analysis service
[MediaAnalysis] Unsupported task %lu
[MediaAnalysis] Asset processing request %d has completed
In-Process quick face identification not supported
[MediaAnalysis] Error connecting to Photos Quick Face Identification service
[MediaAnalysis] Request %d is %.2f%% complete
[MediaAnalysis] Unknown analysis request %d; dropping cancellation request
[MediaAnalysis] No active analysis requests; dropping cancellation request
[MediaAnalysis] Failed to cancel background analysis: %@
[MediaAnalysis] Background analysis canceled
[MediaAnalysis] Error connecting to background analysis service: %@
[MediaAnalysis] Error connecting to request PersonPromoterStatus service
[MediaAnalysis] Request Person Preference %d has completed
[MediaAnalysis] Request VIP model filepath Preference %d has completed
[MediaAnalysis] Error connecting to request SuggestedPersons service
[MediaAnalysis] Request SuggestedPersons %d has completed
[MediaAnalysis] Error connecting to request UpdateKeyFacesOfPersons service
[MediaAnalysis] Request UpdateKeyFacesOfPersons %d has completed
[MediaAnalysis] Error connecting to request FaceCandidatesforKeyFace service
[MediaAnalysis] Request FaceCandidatesforKeyFace %d has completed
[MediaAnalysis] Error connecting to request ResetFaceClassificationModel service
[MediaAnalysis] Request ResetFaceClassificationModel %d has completed
[MediaAnalysis] Error connecting to request ResetPetClassificationModel service
[MediaAnalysis] Request ResetPetClassificationModel %d has completed
[MediaAnalysis] Error connecting to request SuggestedMePersonIdentifier service
[MediaAnalysis] Request SuggestedMePersonIdentifier %d has completed
[MediaAnalysis] Request PersonPromoterStatus %d has completed
[MediaAnalysis] Error connecting to request Face and Person workflow
[MediaAnalysis] Request Face and Person workflow %d has completed
[MediaAnalysis] Error connecting to request ClusterCacheValidation service
[MediaAnalysis] Request ClusterCacheValidation %d has completed
[MediaAnalysis] Error connecting to request ResetFaceClusteringState service
[MediaAnalysis] Request ResetFaceClusteringState %d has completed
[MediaAnalysis] Error connecting to request ReclusterFaces service
[MediaAnalysis] Request ReclusterFaces %d has completed
[MediaAnalysis] Error connecting to request RebuildPersons service
[MediaAnalysis] Request RebuildPersons %d has completed
[MediaAnalysis] Error connecting to query AutoCounter Opt-In status service
[MediaAnalysis] Query AutoCounter Opt-In status %d has completed
[MediaAnalysis] Error connecting to request Opt-In AutoCounter
[MediaAnalysis] Request Opt-In AutoCounter %d has completed
[MediaAnalysis] Error connecting to request AutoCounter dump
[MediaAnalysis] Request AutoCounter dump %d has completed
[MediaAnalysis] Error connecting to request AutoCounter calculation
[MediaAnalysis] Request AutoCounter calculation %d has completed
[MediaAnalysis] Request AutoCounter SIML validation %d has completed
[MediaAnalysis] Faces must be non-empty and completion block must be non-nil
[MediaAnalysis] Faces must all be from the same Photo Library
[MediaAnalysis] Error connecting to Media Analysis
[MediaAnalysis] nil specified for non-nullable parameter
VCPVideoCaptionEncoder: start loading model at: %@
VCPVideoCaptionEncoder: model to load %@
VCPVideoCaptionEncoder: inputBlob.nframes = %d, inputBlob.height = %d, inputBlob.width = %d, inputBlob.channels = %d
VCPVideoCaptionEncoder: successfully loaded model
 keypointsToObservation - unexpected keypoints count
incompatible input buffer size/format, check requiredInputFormat
CVNLPCommSafetyHandler_init
Failed to create CVNLPCommSafetyHandler: %@
VCPMADImageSafetyClassificationTask running...
VCPMADImageSafetyClassificationTask image loading failed
VCPMADImageSafetyClassificationTask image pre-processing failed
CVNLPCommSafetyHandler_scale
CVNLPCommSafetyHandler unavailable for classifying pixel buffer
CVNLPCommSafetyHandler_classifyPixelBuffer
VCPMADImageSafetyClassificationTask failed (%@)
VCPMADImageSafetyClassificationTask complete
[VCPPhotosFace] faceprint.confidence is too low (%.3f < 0.1) %@ - junkinessIndex: %.3f
[VCPPhotosFace] Accepting faceprint with confidence: %.3f %@ - junkinessIndex: %.3f
[VCPPhotosFace] Missing results for roll information
[VCPPhotosFace] Missing results from VNDetectFaceCaptureQualityRequest
[VCPPhotosFace] Missing results for yaw information
[VCPPhotosFace] Missing results from VNDetectFaceExpressionsRequest
[VCPPhotosFace] Missing results from VNClassifyFaceAttributesRequest
[VCPPhotosFace] Gaze: mask: %s, VNFaceGazeDirection: %@, PHFaceGazeType: %@ at (%.3f, %.3f)
[VCPPhotosFace] Missing results from VNDetectFaceGazeRequest
[PhotosFace] Fail to generate VCPPhotosFace from %@ and %@ - %@
[PhotosFace] Generate VCPPhotosFace %@ from %@ and %@
[PhotosFace] Fail to generate VCPPhotosFace %@ from %@ and %@ - invalid imageprint
[PhotosFace] Fail to generate face only VCPPhotosFace from %@ - %@
[PhotosFace] Generate face only VCPPhotosFace %@ from %@
[PhotosFace] Fail to generate VCPPhotosFace %@ from %@ - invalid imageprint
[PhotosFace] Failed to serialize torsoprint; %@
[PhotosFace] torsoOnlyObservation failed to return a faceprint
[PhotosFace] Ignoring co-locating animalObservation %@
[PhotosFace] Unable to determine normalized bounding box { { %f, %f } { %f, %f } }
[PhotosFace] Failed to serialize animalprintData; %@
[PhotosFace] animalObservation failed to return a faceprint
[PhotosFace] Generate VCPPhotosFace %@ from %@
[PhotosFace] IoU %f %@ %@
[VCPCNNEspressoContext] created CPU context
[VCPCNNEspressoContext] Failed to CPU context
[VCPCNNEspressoContext] created MPSGraph context
[VCPCNNEspressoContext] Failed to create MPSGraph context, fall back to CPU context
[VCPCNNEspressoContext] created preferred context
[VCPCNNEspressoContext] Failed to create ANE context, fall back to MPS context
[VCPCNNEspressoContext] Failed to create MPS context, fall back to CPU context
[VCPCNNEspressoContext] sharing CPU context
[VCPCNNEspressoContext] sharing MPSGraph context
[VCPCNNEspressoContext] sharing preferred context
[VCPCNNEspressoContext] dealloc shared context; keep alive
[VCPCNNEspressoContext] dealloc context;
[VCPCNNEspressoContext] No valid context; skip dealloc
Choosing asset resource from preferred list: %@
Network is available, filtering list to remove the CPL Thumb, new list is: %@
No resources locally available, returning a downloadable hi-res resource: %@
[Face] Failed setting %@ private revision: %@, umbrellaVersion: %d
[FaceConfiguration] No proper vision model revision for %@ with umbrellaVersion: %d
VCPObjectPool failed to allocate object
Failed to get the ideal size of request %@ with revision %lu
Failed to set %@::setRevision %lu: %@
Request %@ (revision %lu) ideal size %@
Ideal size for request %@ not cached
[MediaAnalysis] Junk analayzer - unexpected %d VNObservations
VIService_init
[CNNModelEspresso] Creating %@context for %@
[CNNModelEspresso] Created %scontext (CPU:%d, MPSGraph:%d)), storage type %d
Invalid sceneprint revision: %lu (required %lu)
Failed to open analysis database for Photo Library (%@)
Specified Photo Library has no URL (<%@>); cannot find analysis database
Cloning model: %@
Deleting old clone directory for caption model: %@
Could not delete old clone directory for caption model: %@. error: %@
Creating clone directory for caption model: %@
Could not create clone directory for caption model: %@. error: %@
Cloning caption model: '%@' to: '%@'
Could not clone caption model. clonefile(%@, %@, %o) FAILED with (%d : %s)
Video captioning mode: VCPVideoCaptionMode_Off
Download meta data reply %ld
Queried asset metadata with result: %ld
No video caption encoder query results
Asset %@ not present - downloading
Progress callback: %lld %lld
Downloaded asset with result %li, error? %@
Space not available to download asset %lli
Video caption decoder test model not exist at %@, skip video caption analysis
Unable to obatain video caption decoder model from Accessibility
Video caption encoder test model not exist at %@, skip video caption analysis
Failed to create CVNLPVideoCaptioningModel (%@)
Error to generate video caption with CVNLPVideoCaptioningModel (%@)
Incomparable images: this - %@ vs that - %@
VCPVideoKeyFrameBlurAnalyzer
VCPVideoKeyFrameFaceQualityAnalyzer
Query progress: unsupport taskID %lu - %@
Query progress: output parameter statistics must be non-nil
Query progress: scan library for %lu - %@
VCPAnalysisProgressQueryScanPhotoLibraryFetch
Query progress: unsupported taskID (%lu)
VCPAnalysisProgressQueryExpressPathFetchTotalCount
VCPAnalysisProgressQueryExpressPathFetchProcessedCount
Query progress: unsupported taskID (%@)
VCPAnalysisProgressQueryProgressDetail
VCPAnalysisProgressQueryProgress
Query cached face progress: %lu out of %lu
VCPAnalysisProgressQueryCachedFaceAnalysisProgress
[EmbeddingOnDemand] Incompatible request (%@) specified to %@
[EmbeddingOnDemand] Incompatible imageAsset (%@) specified to %@
VCPMADEmbeddingGenerationTask not supported on this platform
Multiple sampling times (%0.1fs) intersect frame at %lld/%d
%@ skipping sample %lld at %lld/%d
%@ failed for sample at %lld/%d (%@)
QuickFaceID: Failed to create faceprint from data : %@
QuickFaceID: Failed to create animalprint from data : %@
QuickFaceID: Passing classify face confidence: %f
QuickFaceID: Failed passing classify face confidence: %f
QuickFaceID: Failed to predict at all
QuickFaceID Pet: Passing classify pet confidence: %f
QuickFaceID Pet: Failed passing classify pet confidence: %f
QuickFaceID Pet: Failed to predict pet at all
QuickFaceID %@ Model path is nil; skip loading
Failed to load VIP %@ Model
No persistentStorageDirectoryURL for photoLibrary: %@
Unable to serialize library analysis preferences for %@: %@
Unable to write library analysis preferences for %@: %@
Key for setLibraryAnalysisPreferencesValue is nil
Failed to fetch VIP model file path with unknown VCPMAVIPType (%lu)
Failed to fetch VIP model last generation date with unknown VCPMAVIPType (%lu)
Not requiring processing for unknown taskID %lu
Fail in generating motion flow
[FaceModelBump] Failed to update version state - %@
[FaceModelBump] No persistentURL to update version state - %@
[FaceModelBump] Resetting face data ... (%@)
[FaceModelBump] Failed to reset Face Analysis data for PhotoLibrary %@
Face Quality Results mismatch with detected Faces (%lu vs %lu)
Error: FaceQualityScore should not contain results! (size = %lu, timestamp=%.2f)
time=%.2f sharpness=%.2f, faceSharpness=%.2f, cameraM=%.2f, subjectM=%.2f, junk=%.2f, obstr=%.2f, exposure=%.2f, score=%.2f
Error -[VNCreateSceneprintRequest setRevision:error:]
Error -[VNImageRequestHandler requestHandler:error:]
NSKeyedUnarchiver error: %@
 VCPFaceShapeModel - caught exception in find_min_box_constrained()
VCPFaceShapeModel - caught exception in find_min()
 VCPFaceShapeModel - caught exception in find_min_using_approximate_derivatives()
Query context: %@
VCPMADVITextLookupTask running...
VCPMADVITextLookupTask image loading failed
VCPMADVITextLookupTask failed to create text lookup query context (%@)
VIService_TextLookup
VCPMADVITextLookupTask complete (%d)
%@ does not implement purge
Real-time analysis client XPC connection interrupted
Real-time analysis client XPC connection invalidated
Pixel buffer not IOSurface-backed; dropping analysis request
Real-time analysis client XPC connection error
Not all needed analysis are available for video highlights.
[%.2f - %.2f] expressionScore=%.2f, actionScore=%.2f, voiceScore=%.2f, Score=%.2f
[%.2f - %.2f] keyFrameScore=%.2f, expressionScore=%.2f, actionScore=%.2f, voiceScore=%.2f, humanActionScore=%.2f, humanPoseScore=%0.2f, qualityJunkScore = %.2f, mlQualityScore = %.2f, Score=%.2f
[HomeKit] Failed to connect to analysis service (%@)
[HomeKit] VCPHomeKitAnalysisSession initialization fails (%@)
[HomeKit] Client XPC connection interrupted
[HomeKit] Client XPC connection invalidated
[HomeKit] Error connecting to background analysis service
[VCPDatabaseReader] No database file exists
[VCPDatabaseReader] Failed to open database: %d
[VCPDatabaseReader] Failed to set busy handler: %d
[MediaAnalysis] Unknown result key for result type %u
[VCPDatabaseReader] Database already opened, failed to execute query block: %d
[VCPDatabaseReader] Failed to execute query block: %d
[MediaAnalysis] Error querying blacklist status for %@
[MediaAnalysis] Failed to query blacklisted assets
[MediaAnalysis] Failed to query asset %@
[MediaAnalysis] Failed to query analysis properties of asset %@
[MediaAnalysis] queryAnalysesForAssets Failed
[MediaAnalysis] Failed to query assets since %@
[MediaAnalysis] Failed to query failed assets for taskID: %lu
[MediaAnalysis] WARNING: ProcessingStatus entry with nil localIdentifier
Failed to query KeyValueStore (error code: %d)
Failed to query scheduling history for background activity %@
[VCPDatabaseReader] Error SQLITE_BUSY encountered, attempting first retry
[VCPDatabaseReader] busy timeout has passed since first retry, stop retrying
Failed to extract NSArray from column %d (%@)
Orientation value %u invalid, assuming kCGImagePropertyOrientationUp
Running Home Resident Maintenance task
Canceling Home Resident Maintenance task (%d)
HomeAI request submitted (%d)
[VCPMADServiceImageProcessing] Fetching Photos asset with identifier %@
[VCPMADServiceImageProcessing] Fetch returned multiple assets for identifier (%@)
[ImageProcessingTask%d] Build task for asset (%@)
[ImageProcessingTask%d] Failed to fetch asset (%@) - %@
[ImageProcessingTask%d] Failed to process asset (%@) - %@
[ImageProcessingTask%d] Finished processing asset (%@)
Request canceled
%@ returned unexpected status (%d)
VCPMADServiceImageProcessingTaskBatch_Run
Failed to create VNGeneratePhotosAdjustmentsRequest
Failed to set VNGeneratePhotosAdjustmentsRequest::setRevision %lu: %@
VNGeneratePhotosAdjustmentsRequest failed
[FaceCropGeneration] Scaling down from %.0fx%.0f with factor: %.3f
[FaceCropGeneration] Scaling up from %.0fx%.0f with factor: %.3f
Invalid orientation found: %d. Using a default value of 1
 [%@] QuickFaceDetect: failed to persist classification results: %@
   [%@] Ignoring analysis results for Montage asset
 [%@] QuickFaceDetect: analyzing asset (deferType: %d)
 [%@] QuickFaceDetect: processed %lu faces
[SceneNet] Failed to find label for identifier %d
[NSFW] Failed to find label for identifier %d
VCPMADVIMachineReadableCodeDetectionTask running...
[MRC] Custom request configuration; overriding to use cached data
VCPMADVIMachineReadableCodeDetectionTask image loading failed
Failed to configure VNDetectBarcodesRequest
[MRC] Custom request configuration; not persisting result
VCPMADVIMachineReadableCodeDetectionTask complete
Flow decoder: fail to bind inputFeature
Flow decoder: fail to bind correlation
Flow decoder: fail to bind upscaled flow
Flow decoder: fail to bind output flow
Flow decoder: fail to bind buffers
Flow decoder: executing callback
Flow decoder: fail to execute
    Pixel Stabilization confidence doesn't pass the threshold
Found %lu faces with CSN > 0 but not in any face groups
[VisionFgMapping] Vision Cluster with single l0clusters; skip de-conflict
[VisionFgMapping] Vision Cluster contains %lu conflicting people
[VisionFgMapping] Conflicting person %@
[VisionFgMapping] Vision Cluster has conflicting l0cluster %@
[VisionFgMapping] Vision Cluster does not have conflicting l0clusters
[VisionFgMapping] Persisting %ld Vision Clusters to Photos FaceGroup
[VisionFgMapping] Invalid csn (%@) for newly clustered face %@
VisionFgMapping_LookingAfterNewClusteredFace
VisionFgMapping_LookingForConflictingCluster
[VisionFgMapping] Split Cluster %@ with %ld faces with representing face csn %@
[VisionFgMapping] 
 csn: %ld 
[VisionFgMapping] Cannot exclude invalid l0RepresentingCSN %@ in l1Cluster %@
[VisionFgMapping] Output (remaining) Cluster %@ -> %@ with %ld faces
VisionFgMapping_ResolveConflictingCluster
[VisionFgMapping] Output (no-touch) Cluster %@ with %ld faces
VisionFgMapping_ResolveConflictL0Clusters
VisionFgMapping_Process
PersistFaceGroups: Photo library is missing a face with CSN = %@
PersistFaceGroups: Faces with these CSNs will be removed from the cluster cache: %@
PersistFaceGroups: Faces with these localIdentifiers will be re-clustered: %@
PersistFaceGroups: We should not get here! If we did, then we have a previously clustered face without a face group!
PersistFaceGroups: Failed to create a face group change request to add faces!
PersistFaceGroups: Failed to find a faceGroup for face '%@' with CSN: %d
PersistFaceGroups: No faces added to face groups!
PersistFaceGroups: Failed to find face with localIdentier: %@. Could not set its CSN to %@
PersistFaceGroups: Set personBuilderState of faceGroups: %@
PersistFaceGroups: Failed to delete empty face groups with error: %@
PersistFaceGroups: Canceled updating key faces unverified persons after persisting face groups.
PersistFaceGroups: Failed to update key faces unverified persons after persisting face groups. Error: %@
%s: %@
[UpdateKeyFaces] Person %@ already has a keyface; skipping
[UpdateKeyFaces] Failed to find a representing face for Person %@ (verified type %ld)
[UpdateKeyFaces] Updating Person %@ (verified type %ld) with key face %@
[UpdateKeyFaces] Found %lu face groups for unverified person)
[UpdateKeyFaces] Failed to persist key face - %@
Warning: cannot handle representativeness with imageprint type %d; ignoring
Warning: Couldn't get faceprint data for face: %@; ignoring
representativeness selection receives a torso-only print; ignoring
Failed to get VNFaceTorsoprint from faceprint data - %@
Warning: Could not get representativeness for faces, error: %@
PersonBuilder: Deleted duplicate graph-verified persons '%@' from face group %@
PersonBuilder: Failed to delete duplicate graph-verified persons '%@' from face group %@
PersonBuilder: Deduped graph-verified persons '%@' from face group %@
PersonBuilder: Failed to dedupe graph-verified persons '%@' from face group %@
personLocalIdentifier for PHFace %@ is null; skip processing
Found no persons rejected for a rejection training face: %@
PersonBuilder: Did not find merge candidate persons with local identifiers: '%@'
PersonBuilder: Found invalid merge candidate pair ['%@' : '%@']
PersonBuilder: Already found merge candidate pair ['%@' : '%@']
PersonBuilder: persist results for facegroup %@
PersonBuilder: Could not create merge candidate pair '%@' : '%@'
PersonBuilder: Could not create invalid merge candidate pair '%@' : '%@'
PersonBuilder: Cleared personBuilderState of faceGroup: '%@'
Could not find a face with clusterSequenceNumber '%@' in the library
%@ Checking face %@
%@ Failed to find face
%@ No valid person
%@ Found person(s) %@
%@ Person mismatch: face (%@) personLocalIdentifier %@ vs faceCropPerson %@ (%ld)
[FaceCropAdjustment] Correcting %lu training face -> person
[FaceCropAdjustment] Failed to find person for face %@
[FaceCropAdjustment] Correcting face %@ from %@ to %@, with nameSource:%ld
[FaceCropAdjustment] Checking %lu rejected person(s)
[RejectedFaceCrop] To remove face %@ for person %@
[FaceCropAdjustment] Removing %lu faces for person %@
[FaceCropAdjustment] Remove face %@ for person %@
[FaceCropAdjustment] Failed to update person - %@
[PHFaceCrop Dedupe] PHFaceCrop without localIdentifier - %@
[PHFaceCrop Dedupe] PHFace without localIdentifier - %@
[PHFaceCrop Dedupe] Missing PHFaceX[%@]
[PHFaceCrop Dedupe] PHFaceX[%@] without faceprint
[PHFaceCrop Dedupe] Missing PHFaceY[%@]
[PHFaceCrop Dedupe] Unmatched training type PHFaceX[%@](%d) and PHFaceY[%@](%d)
[PHFaceCrop Dedupe] PHFaceY[%@] without faceprint
[PHFaceCrop Dedupe] Duplicated with distance: %f [%@:%d] vs [%@:%d]
[PHFaceCrop Dedupe] Distance: %f [%@] vs [%@] - %@
[PHFaceCrop Dedupe] Processing duplications
[PHFaceCrop Dedupe] %lu duplications - %@
[PHFaceCrop Dedupe] Removing %@ dupe to %@
[FaceCrop] Processing newly clustered face crops in %lu PHFaceGroup; start processing ...
[FaceCrop] Fetched %lu PHFaceCrop in PHFaceGroup (%@); skip
[FaceCrop] Fetched %lu newly clustered PHFaceCrop in PHFaceGroup (%@); skip
[FaceCropAdjustment] Fetched %lu PHFaceCrops in PHFaceGroup (%@); start processing ...
[FaceCropAdjustment] Processing finished
[PHFaceCrop Dedupe] Fetched %lu PHFaceCrop in PHFaceGroup (%@); skip
[PHFaceCrop Dedupe] Fetched %lu PHFaceCrops in PHFaceGroup (%@); start dedupping ...
[FaceCrop] Updated %lu PHFaceCrops
[FaceCrop] Failed to update %lu PHFaceCrops - %@
[FaceCrop] Removed %lu duplicated PHFaceCrops
[FaceCrop] Failed to remove %lu duplicated PHFaceCrops - %@
MADProcessNewlyClusteredFaceCrops
PersonBuilder: Got a 'nil' photoLibrary. Cannot build persons
PersonBuilder: Failed to find unverified person for faceGroups '%@'; These will be fixed up and retried later
PersonBuilder: Failed to fix up face groups without unverified person. Error: '%@'
PersonBuilder: Person Building faceGroup '%@'
PersonBuilder: Failed to find unverified person [unverifiedPerson: %@, unverifiedPersonLocalIdentifier: %@] for faceGroup '%@', skipping this face group
%lu Quick classification face to retain: %@
%lu Quick classification face to reassign: %@
PersonBuilder: Quick classification face: %lu retained, %lu reassigned
[VisionFgMapping] Failed to find conflicting l0cluster (expect csn: %@)
PersonBuilder: We may have a dirty level0 cluster, persons with training faces: %@
PersonBuilder: We may have a dirty level0 cluster, verified persons with confirmed face: %@
PersonBuilder: Unnamed unconfirmed faces in face group, '%@', without a training face: %@
PersonBuilder: Found training rejection, unassigned faces on trainingPersonLocalIdentifier in level0 cluster: %@
PersonBuilder: Skip processing level0 cluster since we have rejected face for training person '%@' in level1 cluster
PersonBuilder: Failed to build persons [Error: '%@']
PersonBuilder: ---> buildPersonWithFaceClusterer, %s
VCPFaceProcessingBuildPersonsCoreAnalyticsCollection
PersonBuilder: Person Building is Disabled!
PersonBuilder: Cleared personBuilderState of faceGroups: %@
PersonBuilder: Failed to clear personBuilderState of faceGroups: %@, error: %@
PersonBuilder: <--- buildPersonWithFaceClusterer
Got a 'nil' photoLibrary. Cannot remove auto assigned faces
Failed to remove auto-assigned faces from person '%@', error: %@
  [%@] No scene classification result fetched from pre analysis
Scene identifier %u has no name; ignoring
[MediaAnalysis][%@] No slow-mo timestamp mapping file URL found
[MediaAnalysis][%@] No slow-mo timestamp mapping file found
[%@] Asset has no small video derivative; cannot download
VCPMADVIDocumentRecognitionTask running...
[DocumentRecognition] Custom request configuration; overriding to use cached data
VCPMADVIDocumentRecognitionTask image loading failed
[DocumentRecognition] Set VNProcessingDevice: %@ (%@)
[DocumentRecognition] Custom request configuration; not persisting result
VCPMADVIDocumentRecognitionTask complete
Cannot load Person Identity Model - %@
Person Identity Model not exist - %@
PersonIdentityModel_init
[%@] running...
[%@] complete
[%@] complete without on-demand process
[%@] image loading failed
VCPMADPersonIdentificationTask_createVisionImageRequest
VCPMADPersonIdentificationTask_detectFace
[%@] No face detected from CVPixelBuffer
[%@] Detected %lu faces, identifying ...
[%@] Detected %lu faces, identifying top %lu faces (by confidence) ...
VCPMADPersonIdentificationTask_generateFaceprint
[%@] No face to identify from CVPixelBuffer
[%@] Failed to classify face (%@) - %@; skipping
[%@] No valid identification to face (%@); skipping
[%@] prediction: %@, confidence: %.3f at %@
[%@] Failed to fetch person with identifier %@; skipping
[%@] Identified %lu faces
VCPMADPersonIdentificationTask_identifyFace
[%@] complete with on-demand analysis
Unknown Media Analysis version specified (%d)
[MediaAnalysis] No slow-mo timerange mapper available, fall back to Scaled Time
[MediaAnalysis] No slow-mo timerange mapper available, fall back to Original Time
Invalid Live Photo Gating result type key [%@]
VCPVersionForTask not implemented for %@ (%d); using MediaAnalysisVersion (%d)
  [%@] Unknown analysis version %d; discarding
Failed to get memory information
Failed to query supported revision; %@ does not support
Unsupported revision (%lu) for %@
Checking revision for %@ is not supporteds
Feature extractor: fail to bind input
Feature extractor: fail to bind output at level %d
Feature extractor: fail to bind buffers
Feature extractor: executing callback
Feature extractor: fail to execute
[OCR][%@] Re-using cached results
[VS][%@] Re-using cached results
VCPMADServiceImageURLAsset_Decode
VCPMADServiceImageDataAsset_Decode
[Faces][%@] Asset not processed or outdated
[Faces][%@] Loading existing results from Photos
[NSFW][%@] Asset not processed or outdated
[NSFW][%@] Loading existing results from Photos
[SceneNet][%@] Asset not processed or outdated
[SceneNet][%@] Loading existing results from Photos
[SceneNet] No scene label name for scene id %d
[%@] Ineligible Confidence: %0.3f
[%@] Ineligible Confidence: -
[%@] Selecting resource for Asset Type: %@ [%d/%d] Resolution: %dx%d
[%@] Evaluating resource (Type: %d Resolution: %dx%d)
[%@] Resource not locally available; skipping resource
[%@] Purging resource cache to load uncommon resource (%@)
[%@] Purging resource cache to load large resource (%dx%d)
[%@] Failed to load orientation
[%@] Loaded resource (Type: %d Actual Resolution: %dx%d, orientation %d)
[%@] Failed to load resource (Type: %d)
VCPMADServiceImageAsset_Decode
[%@] Failed to find/decode high-res image resource
[%@] Evaluating high-resolution resource (Type: %d Resolution: %dx%d)
[%@] Evaluating fall-back resource (Type: %d Resolution: %dx%d)
[%@][%@] Deferring persistence until OCR available
[%@][%@] Deferring persistence until MRC available
[%@][%@] Asset has invalid adjustment version (%@); cannot persist results to Photos
[%@][%@] Persisting results to Photos
VNDocumentObservation_archive
[%@][%@] Failed to archive OCR observation
[%@][%@] No text recognized; skipping archive/persistence
VNBarcodeObservation_archive
[%@][%@] Failed to archive MRC observations
[%@][%@] No MR Codes recognized; skipping archive/persistence
[%@][%@] Successfully persisted results to Photos
[%@][%@] Failed to persist results to Photos
[OCR][%@] Checking for existing results from Photos
[OCR][%@] Loading existing results from Photos
[OCR][%@] Failed to unarchive existing Photos results
[OCR][%@] Photos results exist, but no text was recognized
[OCR][%@] Asset does not have existing results
[OCR][%@] Successfully reused existing results
[MRC][%@] Checking for existing results from Photos
[MRC][%@] Loading existing results from Photos
[MRC][%@] Failed to unarchive existing Photos results
[MRC][%@] Photos results exist, but no text was recognized
[MRC][%@] Asset does not have existing results
[MRC][%@] Successfully reused existing results
[VS][%@] Checking for existing results from Photos
[VS][%@] Loading existing results from Photos
[VS][%@] Photos results exist, but empty
[VS][%@] Asset does not have existing results
[VS][%@] Successfully reused existing results
[VS][%@] Asset has invalid adjustment version (%@); cannot persist results to Photos
[VS][%@] Persisting results to Photos
[VS][%@] Successfully persisted results to Photos
[VS][%@] Failed to persist results to Photos
[FaceCropManager][%@] Publish facecrop for face %@
[FaceCropManager][%@] No face detected; force faceprinting
[FaceCropManager] Failed to create VCPPhotosFace - %@
[FaceCropManager][%@] Failed to faceprint - %@
[FaceCropManager][%@] Failed to associate with face %@ - %@
[FacecropManager][%@] Associated with face %@
[FacecropManager] Updating faceprint for face %@
[FaceCropManager][%@] Failed to generate FaceCrop face - %@
[FaceCropManager][%@] Failed to update faceprint of associated face %@  - %@
[FaceCropManager] Set personBuilderState of faceGroup %@ for face %@
[FaceCropManager][%@] Analyzing facecrop (%.0fx%.0f)
[FaceCropManager][%@] Not in a dirty state (state:%d, expect:%d); skipping process
[FaceCropManager][%@] FaceCrop does not have data
[FaceCropManager][%@] existing face %@
[FaceCropManager][%@] Failed to update associated face %@ - %@
[FaceCropManager][%@] Failed to record needing to Person Building for face %@ - %@
[FaceCropManager][%@] Asset has face; skip facecrop generation
[FaceCropManager][%@] Facecrop will not be generated for the manual face %@
[FaceCropManager][%@] Too small facecrop (%.0fx%.0f) using resource %@ (%@)
[FaceCropManager][%@] Generated %lu facecrop(s)
[FaceCropManager] Library has %lu dirty face crops to analyze
[FaceCropManager] Failed to process dirty facecrop %@ - %@
VCPFaceProcessingDirtyFaceCrops
QuickFaceID Model: persistent storageDirectoryURL is nil
QuickFaceID Model: cannot load Persons Model: %@
VCPPersonVIPLoadModel
QuickFaceID Model: model with VNCreateFaceprintRequest revision %lu (FaceProcessing Version%d)
QuickFaceID Model: system is using VNCreateFaceprintRequest revision %lu (FaceProcessing Version%d)
QuickFaceID: failed to initialize face analyzer
QuickFaceID Pet Model: persistent storageDirectoryURL is nil; skip loading Model
QuickFaceID Pet Model: cannot load Model: %@
VCPPetVIPLoadModel
[%@] QuickFaceID: matching person %@
[%@] QuickFaceID: no matching person at location (%.3f, %.3f) - %@
[%@] QuickFaceID: no matching person at location (%.3f, %.3f)
[%@] Ignoring analysis results for Montage asset
QuickFaceID Persons Model is not ready; skip processing
[%@] QuickFaceID: analyzing asset (deferType: %d)
[%@] QuickFaceID: asset is not image
[%@] QuickFaceID: detecting faces
[%@] QuickFaceID: %lu detected faces
[%@] QuickFaceID: processed %lu faces
VCPPersonVIPAssetProcessing
QuickFaceID Pets Model is not ready; skip classifying
QuickFaceID Pet: pet (PHFace) %@ already has a nameSource %ld for petPerson %@; skip
QuickFaceID Pet: pet (PHFace) %@ is used to train this VIP model with petPerson %@; skip
QuickFaceID Pet: Could not create animalprint for pet (PHFace) %@ - %@
QuickFaceID Pet: Failed to classify %@ - %@; skip
QuickFaceID Pet: did not match %@ (at %.3f, %.3f)
QuickFaceID Pet: classified %@ to petPerson %@
QuickFaceID Pet: no petPerson %@; skipping
QuickFaceID Pet: failed to persist pet classification results: %@
QuickFaceID Pet: classified and persisted %lu Pet PHFace
[PersonIdentification] Unsupported library - %@
[PersonIdentification] No face needs to identify
[PersonIdentification] Identifying %lu faces
[PersonIdentification] VIP Persons Model is not ready
[PersonIdentification][%@] Failed to obtain faceprint; skipping
[PersonIdentification][%@] Failed to obtain face observation; skipping
[PersonIdentification][%@] Face identification process failed (%@); skipping
[PersonIdentification][%@] Face identified as %@ confidence:%.2f
[PersonIdentification][%@] Face not identified, confidence:%@
[PersonIdentification] Identified %lu out of %lu faces
[PersonIdentification] Successfully persisted identification results
[PersonIdentification] Failed to persist identification results - %@
QuickFaceID Model: unknown VIP type (%lu); no entity fetched
QuickFaceID Pets Model: Begin Pets model generation
QuickFaceID Pets Model: Failed to initialize VNAnimalObservation
QuickFaceID Pets Model: Failed to create VNEntityIdentificationModelConfiguration - %@
Failed to create VNMutableEntityIdentificationModel - %@
QuickFaceID Pets Model: Model generation cancelled; quitting
QuickFaceID Pets Model: petPerson: %@, petFaceFetchResult(%lu): %@
QuickFaceID Pets Model: Could not create animalprint for pet (PHFace): %@ - %@
QuickFaceID Pets Model: Could not add animalObservation to model for pet (PHFace): %@.
QuickFaceID Pets Model: animalObservations(%lu): %@
QuickFaceID Pets Model: Could not add animalprint to model - %@
VCPPetVIPGenerateModel
QuickFaceID Pets Model: Finished model generation
QuickFaceID Pets Model: Failed to persist pet model %@
QuickFaceID Pets Model: Could not get animalObservations for pet %@ - %@
QuickFaceID Pets Model: Could not persist isInVIPModel on trained pets - %@
QuickFaceID Pets Model: Finished model generation and persistence
QuickFaceID Model: Begin model generation
QuickFaceID Model: Model generation cancelled. Quitting
QuickFaceID: Building %@-confirmed person %@ (%@)
FaceID Model: fetched %lu faces
FaceID Model: fetched %lu faces without roll predicate
QuickFaceID Model: Could not create faceprint for face: %@. Error: %@
QuickFaceID Model: Could not add faceprint to model for face: %@.
QuickFaceID Model: Could not add faceprints to model. Error: %@
QuickFaceID: Built using %lu faces for person %@ (%@)
VCPPersonVIPGenerateModel
QuickFaceID Model: Finished model generation
QuickFaceID Model: Failed to persist model %@
QuickFaceID Model: Could not get face observations for person %@ - %@
QuickFaceID Model: Could not persist isInVIPModel on trained faces - %@
QuickFaceID Model: Finished model generation and persistence
QuickFaceID %@ Model: Last job generation %.0fs ago, job is due = %@
QuickFaceID [FastMigration]: asset processing progress: total: %ld, processed: %ld, failed: %ld
QuickFaceID [FastMigration]: asset processing rate: processed>90%%: %s, failure>10%%: %s, pass: %s
QuickFaceID [FastMigration]: persistent storageDirectoryURL is nil
QuickFaceID [FastMigration]: cannot load Persons Model: %@
QuickFaceID %@ Model: ignoreLastGenerationTime: %s
QuickFaceID %@ Model: No need to generate model
QuickFaceID Model: unknown VIP type (%lu); no model generated
Restore clusterer error (ClusterState = %ld): %@
Restored clusterer, ClusterState = %ld
UpdateKeyFaces for: '%@'
could not update key faces for suggestions: %@
Loaded clustererState: %ld
Returning no suggestions because the clusterer is working
suggestions first phase query start
suggestions first phase query end
suggestions middle phase query start (includes face groups for person query)
suggestions middle phase query end
suggestions last phase query start
suggestions last phase query end
Querying suggestions for person %@ (Photos: %@ to-be-confirmed, %@ to-be-rejected suggestions)
Returning %lu suggestions for person %@
Input parameter is empty or nil: '%@'
Persons Model: Failed to remove model at %@ - %@
Pets Model: Failed to remove model at %@ - %@
Person Processing: Starting Deleting Persons
VCPFaceProcessingDeleteAllVerifiedPersons
Person Processing: Deleting Persons %@
Person Processing: Starting Face Reclustering
VCPFaceProcessingReclusterFacesWithThreshold
Person Processing: Face Clustering %@
Person Processing: Starting Person Building
VCPFaceProcessingBuildPersons
Person Processing: Person Building %@
Person Processing: Starting Person Promotion
VCPFaceProcessingPromotePersons
Person Processing: Person Promotion %@
AVAsset: Montage asset detected
Failed to decode first frame (%@)
[CGImage->CVPixelBuffer] Failed to create CVPixelBuffer with existing IOSurface
[CGImage->CVPixelBuffer] CGImage not IOSurface backed
[CGImage->CVPixelBuffer] Failed to allocate CVPixelBuffer
[CGImage->CVPixelBuffer] Failed to allocate CGContext
[MediaAnalysis] Sample at %lld/%d is being extended %0.1fx
[MediaAnalysis] Requested post process highlight with NULL input analysis
[MediaAnalysis] Post-process highlights returned NULL
[MediaAnalysisResultsTypesForAnalysisTypes] Unknown result type
VideoPetActionAnalyzer: _scoreAbsoluteMax = %f, _scoreRelativeMax =%f
VCPVideoPetsActionTracker
VideoPetActionAnalyzer: finishAnalysisPass
  Extreme aspect ratio %f; initialization failed
[VideoTrackDecoder] Decoded frame and setting mismatch: actual padding right: %zupx, bottom: %zupx (expected right: %zupx, bottom: %zupx)
[VCPFaceCrop][%@] Failed to generate FaceCrop data - %@
[VCPFaceCrop][%@] Failed to create VCPFaceCrop instance
[%@] VCPCoreMLRequest Failed to open model file at url %@
VCPMADVIVisualSearchGatingTask running...
[VS] Cached parse result empty; returning empty result
VCPMADVIVisualSearchGatingTask failed to create visual search query context (%@)
VCPMADVIVisualSearchGatingTask image loading failed
VIService_VisualSearchGating
VCPMADVIVisualSearchGatingTask complete (%d)
VCPFaceAnalyzerImageRequestHandlerPerformRequest
[FaceAnalyzer] Failed to perform requests - %@
[FaceAnalyzer] Failed to create blur/exposure request
[FaceAnalyzer] Blur score %f out of bound [%f, %f]
[FaceAnalyzer] Failed to perform blur requests - %@
[FaceAnalyzer] Exposure score %f out of bound [%f, %f]
[FaceAnalyzer] Failed to perform exposure requests - %@
VCPFaceAnalyzerBlurExposureAnalysis
VCPFaceAnalyzerVCPFaceCreation
[VCPFaceAnalyzer][%@] Failed to create VCPPhotosFace from PHFace %@
VCPFaceAnalyzerVerifyAndMergeFaces
[FaceAnalyzer][%@] Resource (%d) has invalid dimensions (%dx%d); falling back to asset
[FaceAnalyzer][%@] Invalid dimensions (%dx%d)
VCPFaceProcessingFastPathDecodeAsset
[FaceAnalyzer][%@] Failed to decode image
[FaceAnalyzer][%@] Failed to decode orientation (%d)
VCPFaceAnalyzerLoadImageRequestHandler
[FaceAnalyzer][%@] Failed to create VNImageRequestHandler
[FaceAnalyzer][%@] Loaded local resource (%dx%d orientation:%d)
[FaceAnalyzer][%@] Failed to analyze resource
VCPFaceAnalyzerPerformAnalysis
[FaceAnalyzer][%@] Failed to refine analysis
VCPFaceAnalyzerRefineAnalysis
[FaceAnalyzer][%@] Face refine completed: detected %lu | persist: %lu | delete: %lu
[FaceAnalyzer][%@] Missing local resource %@
[FaceAnalyzer] face (center-x:%.2f, center-y:%.2f, size:%.2f) -> boundingBox (x:%.2f, y:%.2f, width:%.2f, height:%.2f)
[FaceAnalyzer] Failed to generate VNFaceObservation from face %@
[FaceAnalyzer] All faces contain valid faceprint
[FaceAnalyzer] Updating %lu faces with missing faceprint
[FaceAnalyzer] Failed to create VNImageRequestHandler for face quality analysis
[FaceAnalyzer] Faceprint VNImageRequestHandler::performRequests: %@
[FaceAnalyzer] faceprint.confidence is too low (%.3f < 0.1) %@ - junkinessIndex: %.3f
[FaceAnalyzer] Accepting faceprint with confidence: %.3f %@ - junkinessIndex: %.3f
[FaceAnalyzer] Update faceprint for face %@
[FaceAnalyzer] Unable to serialize faceTorsoprint - %@
[FaceAnalyzer] No valid faceprint from observation %@
[FaceAnalyzer] Failed to get faceprint for face %@
VCPFaceAnalyzerFillMissingFaceprint
[FaceAnalyzer][%@] No face detected; skip face quality analysis
[FaceAnalyzer][%@] No valid face observations from %lu faces; skip face quality analysis
[FaceAnalyzer] Analyzing %lu face observations for face quality
[FaceAnalyzer] Failed to set Face Quality revision (%lu) - %@
[FaceAnalyzer] Failed to perform Face Quality request - %@
[FaceAnalyzer][%@][%@] No valid Face Quality score; skipping
VCPFaceAnalyzerFaceQuality
[%@] Asset has no small video derivative; skipping
[%@] File size exceeds streaming threshold; skipping
[%@] Duration exceeds streaming threshold; skipping
Unknown VCPTaskID (%lu); redirect to VCPTaskID_MediaAnalysis
[%@] Processing image at scaled resolution (%dx%d)
[%@] Processing image at subsampled resolution (%dx%d)
[%@] Processing image at full resolution (%dx%d)
[%@] Invalid target resolution (%d)
[%@] Resource (%d) has invalid dimensions (%dx%d); falling back to asset
[%@] Asset has invalid dimensions (%dx%d)
-[PHAsset vcp_needsProcessingForTask] not implemented for %@
[%@] Montage asset detected
[%@] Text Confidence: %0.2f Passed Gating: %d
[%@] Text Confidence: 0.00f Passed Gating: 0 [Absent]
[%@] Asset scene properties unavailable or out-of-date
VCPMADVIVisualSearchTask running...
VCPMADVIVisualSearchTask image loading failed
VCPMADVIVisualSearchTask failed to create visual search query context (%@)
[VisualSearch] Using client provided OCR results
VIService_ParsedVisualSearch
VIService_VisualSearch
VCPMADVIVisualSearchTask complete (%d)
VCPVideoStabilizationAssetProcessingTask
Video Stabilization processing failed
Video caption test mode
Video caption is not enabled by defaults write
Video caption only support live photos
Video captioning model not found or user not turning on Image Descriptions in Accessibility
  [%@] Existing analysis outdated; dropping
VCPLightVideoAnalyzer
Movie analyzer perform VCPPhotosQuickFaceDetection
VCPPhotosQuickFaceDetection
VCPVideoCaptionAnalyzer
VCPVideoStabilizerPixel
VCPVideoFaceDetector
VCPFullVideoAnalyzer
VCPVideoSceneClassifier
VCPVideoActivityAnalyzer
VCPVideoSaliencyAnalyzer
VCPVideoHumanActionAnalyzer
videoCaptionAnalyzer
VCPVideoHumanActionClassifier
VCPVideoPetsAnalyzer
VCPVideoPetActionAnalyzer
VCPMovieCurationAnalyzer
VCPVideoStabilizer
VCPSettlingEffectAnalyzer
VCPVideoCNNAnalyzer
    Analyzing Video Segment - Track ID: %d Start: %lld/%d (%0.3fs) End: %lld/%d (%0.3fs)
VCPAudioAnalyzer
    Video track has invalid full frame dimensions (%.f,%.f)
    Video track has invalid clean aperture rect
VCPVideoStabilizerGyro
  [%@] Asset doesn't have gyro metadata
  [%@] Asset does not have valid video track; all %lu tracks: %@
    Video track has invalid dimensions (%.f,%.f)
VCPMovieAnalyzer
ImageHandAnalyzer: input image aspectRatio = %f
ImageHandAnalyzer: aspectRatio = %@, queryAspectRatioVal = %@
ImageHandAnalyzer: feasibleShapeIndex = %d
ImageHandAnalyzer: detectorHeight = %d, detectorWidth = %d
VCPMADServiceImageProcessingTask_Run
[MotionFlow] Failed to lock/unlock pixelbuffer (errcode: %d)
  [%@] Processing
[MediaAnalysis][%@]Unable to open movie, skip
[MediaAnalysis][%@]Failed to create asset
    Analyzing Audio Track - ID: %d Start: %lld/%d (%0.3fs) End: %lld/%d (%0.3fs)
Error resetting all FaceGroups Person Builder state: %@
Failed to clean up merge candidates. Error: %@
VCPFaceProcessingCleanupMergeCandidates
->->-> Enabling personBuilderMergeCandidates
Failed to update key faces - %@
VCPPersonBuilder_UpdateKeyface
VCPMADVIRectangleDetectionTask running...
VCPMADVIRectangleDetectionTask image loading failed
[RectangleDetection] Set VNProcessingDevice: %@ (%@)
VCPMADVIRectangleDetectionTask complete
[VCPPreAnalyzer] Failed to create VCPPoolBasedPixelBufferCreator for monochrome
 [ProbableRotation] Failed to load %@
[VCPPreAnalyzer] Failed to create VCPPoolBasedPixelBufferCreator for rotation
VCPSceneAnalyzerReleaseCachedResources
Failed to create VNClassifyImageAestheticsRequest
Failed to create VNSceneClassificationRequest
Failed to create VNCreateSceneprintRequest
Failed to create VNClassifyJunkImageRequest
Failed to create VNGenerateAttentionBasedSaliencyImageRequest
Failed to set VNClassifyImageAestheticsRequest::setRevision %lu: %@
Failed to set VNSceneClassificationRequest::setRevision %lu: %@
Failed to set VNCreateSceneprintRequest::setRevision %lu: %@
Failed to set VNGenerateAttentionBasedSaliencyImageRequest::setRevision %lu: %@
Failed to set VNClassifyJunkImageRequest::setRevision %lu: %@
Failed to set VNRecognizeObjectsRequest::setRevision %lu: %@
Failed to set VNGenerateObjectnessBasedSaliencyImageRequest::setRevision %lu: %@
Failed to set VNClassifySignificantEventRequest::setRevision %lu: %@
Failed to set VNClassifySemanticDevelopmentGatingRequest::setRevision %lu: %@
Failed to set VNClassifyCityNatureImageRequest::setRevision %lu: %@
Failed to create %@
Unsupported observation label in VCPSpecialLabelToSceneClassificationID %@
Unsupported observation label %@
[DO] detectedObjects count is 0; skip detectedObjects
[DO] invalid confidenceMax: %f; skip detectedObjects
[DO] Failed to choose the best bounding box c_max: %f, c_threshold (0.8x): %f from %@
[DO] Unsupported observation label in PFSceneTaxonomyNode %@
Unsupported observation label in PFSceneTaxonomyNode: %@
Ignoring SceneNet result for tiny image
Unsupported observation label in VCPSpecialLabelToSceneClassificationID %@ (%@)
Unnormalized saliencyRequest bounding box %@; skip
Unnormalized saliencyRequest narrowed bounding box %@; skip
Unnormalized salientObject narrowed bounding box %@; skip
Error creating VNRequest
Unknown ideal dimension for VNRequests (%@), using image dimension %dx%d
Only one VNRequest (%@) for dimension %dx%d; consider coalescing to common resolution
%dx%d
VCPSceneAnalyzerImageRequestHandlerPerformRequest
Failed to run VNImageRequestHandler::performRequests: %@
CVNLPCommSafetyHandler unavailable for IVS
CVNLPCommSafetyHandler_IVS
Failed to run CVNLPCommSafetyHandler::generateClassificationScoresForPixelBuffer:error: %@
VCPSceneAnalyzerImageBlurAnalysis
VCPSceneAnalyzerExposureAnalysis
VCPSceneAnalyzerRotationAnalysisScaling
[ProbableRotation] invalid coreML results
VCPSceneAnalyzerRotationAnalysisInference
No sceneprint data for WP analysis; return default value
VCPWallpaperAnalysis
VCPSceneAnalyzerLoadImageRequestHandler
Failed to load imageURL: %@
VCPSceneAnalyzerPerformAnalysis
VCPFaceGeometry initWithCoder - vertices data missing
VCPFaceAnchor initWithCoder - unexpected size of transform data
VCPCaptureAnalysis - missing resolution properties for prewarming
CNNFastGestureRecognition: start loading model
CNNFastGestureRecognition: inputBlob.height = %d, inputBlob.width = %d, inputBlob.channels = %d
CNNFastGestureRecognition: successfully loaded model
[MotionFlowSubtleMotionAnalyzer] Failed to request flow from VCPMotionFlowRequest: %@
Motion flow is null
Fail to initialize motionFlowAnalyzer
[VCPMediaAnalyzer] Client XPC connection interrupted
[VCPMediaAnalyzer] Client XPC connection invalidated
[VCPMediaAnalyzer] Acquiring media analysis directory sandbox extension...
[VCPMediaAnalyzer] Failed to establish connection or connection lost to service %@; %@
[VCPMediaAnalyzer] Failed to consume media analysis directory sandbox extension
[VCPMediaAnalyzer] Consumed media analysis directory sandbox extension
[MediaAnalysis] failed to get database sandbox extension
[MediaAnalysis] failed to consume sandbox extension
[MediaAnalysis] Consumed sandbox extension
[MediaAnalysis] Failed to obtain analysis sandbox extension for Photo Library (%@); client may not be able to open analysis database
[MediaAnalysis] Requested max highlight duration longer than %.2fs, fall back to %.2fs
[MediaAnalysis][%@] No valid on-demand analysis; skipping
[MediaAnalysis][%@] Storing on-demand analysis
[MediaAnalysis][%@] Failed to store on-demand analysis - %@
[MediaAnalysis][%@]Unable to open movie
[MediaAnalysis][%@] Received analysis request: %@
[MediaAnalysis][%@] Analysis served: (%@)
[MediaAnalysis] [MediaAnalyzer requestAnalysisForAsset] call from invalid instance
[MediaAnalysis] Failed to obtain database for Photo Library %@
[MediaAnalysis] Cancelling request %d
[MediaAnalysis] Failed to find request %d; cannot cancel
[MediaAnalysis] [MediaAnalyzer assetsAnalyzedSinceDate] call from invalid instance
[MediaAnalysis] Failed to obtain database for Photo Library (%@)
Cannot load %@ for %@, NSData length: %lu, content: %@
Cannot load %@ from PHAsset, NSData length: %lu, content: %@
[MediaAnalysis] [MediaAnalyzer distanceFromAsset] call from invalid instance
[MediaAnalysis] Failed to obtain database for assets
[MediaAnalysis] failed to request analyses
[MediaAnalysis] [requestAnalysesForAssets] call from invalid instance
[MediaAnalysis] [requestAnalysesForAssets] in standalone mode but on-demand not allowed
[MediaAnalysis] call from invalid instance
[MediaAnalysis] on-demand analysis requested in standalone mode
Warning: On demand analysis is not supported.
[MediaAnalysis] Failed to obtain database for collection %@
[MediaAnalysis] [requestLivePhotoEffectsForAssets] call from invalid instance
[MediaAnalysis] [requestLivePhotoEffectsForAssets] in standalone mode but on-demand not allowed
Sceneprint task failed (%@)
Error: MAD tracked taxonomy is not the latest in Photos!
Loading PFSceneTaxonomy identifier %@
Failed to initialize PFSceneTaxonomy w/identifier %@ (%@)
Error: MAD tracked taxonomy identifier %@ does not match the latest in Photos: %@!
[PFSceneTaxonomy(MediaAnalysis)] - Failed find scene name for scene id %d
[PFSceneTaxonomy(MediaAnalysis)] - Failed to find scene id for scene name %@
Video track rotation angle is not multiple of 90
Predicate requested for unsupported task (%@) & priority (%d)
Predicate requested for unsupported task (%@)
VNSession_init
CNNHandsDetector: Loading model %@
CNNHandsDetector: adopting model config: %@
CNNHandsDetectorEspresso: updating model config to %@
copyImageToBGRHandDetectorCallFromSPI
scalerHandDetectorCallFromSPI
inferenceHandDetectorCallFromSPI
CNNHandsDetector: hand class index: %d
[%@][MAMLModel] Failed to open model file at url %@
[%@][MAMLModel] Failed to load compiled model (%@): %@
[MAMLModel] Input feature %@ %ldx%ld %ld
[MAMLModel] Missing inputImage feature description %@
[MAMLModel] Mismatched inputImage width (%ld) and height (%ld)
[MAMLModel] Output feature %@ %@
[MAMLModel] Missing output feature %@
  [%@] Fingerprint requested for asset with no objectID
  [%@] Fingerprinting failed
  Fullfilled content request: %@
  Fullfilled data request: %@
Failed to query ideal dimension for request %@ due to empty supportedImageSizeSet
Failed to query ideal dimension for request %@ because the request does not conform to VNImageIdealImageSizeProviding protocol
Failed to configure %@
[DAS QoS] %@: %@ (%@) download %lu bytes
Requested resource exceeds maximum supported size
Resource already in the buffer. Skip downloading.
requestDownloadOfResource: %@
Download progress: %.2f
    Received %llu bytes (Overall: %llu/%llu)
Data received exceeds maximum supported size
Failed to download asset resource (%@)
Successfully downloaded asset resource
Failed to issue resource request
Download resource timed-out
Cancelling download
queryActionResultForPHFace : no action results
queryActionResultForPHFace : not find the best highlight
queryActionResultForPHFace : no faceprint data for face: %@
queryActionResultForPHFace : failed to get VNFaceTorsoprint %@
queryActionResultForPHFace : failed to decode torsoprintAction
queryActionResultForPHFace : failed to get compute torsoprint distance
queryActionResultForPHFace : torsoprint distance with %@, %f
queryActionResultForPHFace : failed to get torsoprints
Connecting to system photo library...
Opening system photo library...
Opened system photo library
Failed to open system photo library (%@)
Failed to obtain system photo library URL
Closed Photo Library
Photo Library unavailable (%@); closing Photo Library...
  [%@] Failed to decode last frame of video, fall back to thumbnail 
[AutoCounter] feature not supported on this OS variant
[AutoCounter] Failed to find asset for face: %@; skip
[AutoCounter] Asset without cloudIdentifier, use localIdentifier: %@
[AutoCounter] Person without localIdentifier; use face.personLocalidentifier
[AutoCounter] Face without personLocalIdentifier; skip
[AutoCounter] Fetched face/person not matching required person; skip
[AutoCounter] Face in a facegroup without localIdentifier; skip
[AutoCounter] No valid faceprint data; leave as unknown
[AutoCounter] No valid momentLocalIdentifier; leave as 'unknown'
[AutoCounter] Face without localIdentifier; skip
[AutoCounter] Failed to fetch person %@
[AutoCounter] Fail to load groundtruth file
[AutoCounter] Person (%@) already opt-in; skip
[AutoCounter] Cannot write opt-in groundtruth to %@ : %@
[AutoCounter] Export URL: %@
[AutoCounter] Failed to find facegroup for mergeCandidate: %@
[AutoCounter] Reach kVCPMaximumNumberOfMergeCandidatesShown (%lu); skip the rest
[AutoCounter][ClusterDump] FaceGroupCount %lu
[AutoCounter][ClusterDump] FaceCount %lu
[AutoCounter] Saved cluster state to %@
[AutoCounter] Cannot write to %@ : %@
[AutoCounter][P/R][GT] Fail to load groundtruth file: %@
[AutoCounter][P/R][GT] Invalid faceID for face: %@; ignore
[AutoCounter][P/R][GT] Invalid PersonID for faceID: %@; ignore
[AutoCounter][P/R][GT] Load faceID: %@ for PersonID: %@
[AutoCounter] Saved assets-to-faces details to %@
[AutoCounter] Cannot write assets-to-faces to %@ : %@
[AutoCounter][P/R] Fail to load cluster state file: %@
[AutoCounter][P/R] Cluster contains no asset information
[AutoCounter][P/R] Cluster contains no data
[AutoCounter][P/R] Invalid information for asset %@ in cluster; ignore
[AutoCounter][P/R] Invalid ID(s) in cluster: %@; ignore
[AutoCounter][P/R] Invalid face rectangle in cluster state for faceID:%@; ignore
[AutoCounter][P/R] processing cluster state faceID: %@ forPersonID: %@
[AutoCounter][P/R] Invalid ground truth rect for faceID:%@
[AutoCounter][P/R][%@] %.4f library: %@, gt: %@ (fid:%@, pid:%@)
[AutoCounter][P/R] Co-location mapping faceID:faceGroupID %@:%@ -> %@:%@
[AutoCounter][P/R] Cannot find asset for id %@
[AutoCounter][P/R] Precision for FaceGroup (of size %d) for personID %@ (of size %lu) is %f
[AutoCounter][P/R] Valid singleton count = %lu, invalid singleton count = %lu
[AutoCounter][P/R] Valid face count for person %@ is %d
[AutoCounter][P/R] personID %@ Recall (of size %lu) is %f
[AutoCounter][P/R] personID %@ Recall (exclude detection miss) (of size %lu) is %f
[AutoCounter][P/R] Weighted Precision: %f, Weighted Recall: %f (number of best face: %.0f)
[AutoCounter][P/R] Weighted Recall (exclude detection miss): %f (number of best face: %.0f)
[AutoCounter][P/R][PV] Processing person cluster %@ with %lu faces
[AutoCounter][P/R][PV] Invalid faceID in person cluster: %@; ignore
[AutoCounter][P/R][PV] Failed to fetch asset for face %@; ignore
[AutoCounter][P/R][PV] Asset without cloudIdentifier, use localIdentifier: %@
[AutoCounter][P/R][PV] Invalid face rectangle in person cluster state for face: %@; ignore
[AutoCounter][P/R][PV] processing person cluster faceID: %@ for PersonID: %@ and clusterID: %@
[AutoCounter][P/R][PV] Valid faceID mapping faceID:personID %@:%@ -> %@:%@
[AutoCounter][P/R][PV] Invalid faceID mapping faceID:faceGroupID %@:%@ -> %@:%@
[AutoCounter][P/R][PV] Invalid ground truth face rectangle for faceID:%@
[AutoCounter][P/R][PV] Valid co-locate mapping faceID:personID %@:%@ -> %@:%@
[AutoCounter][P/R][PV] Invalid co-location mapping faceID:faceGroupID %@:%@ -> %@:%@
[AutoCounter][P/R][PV] Precision for cluster (of size %d) for personID %@ (of size %lu) is %f
[AutoCounter][P/R][PV] Valid singleton count = %lu, invalid singleton count = %lu
[AutoCounter][P/R][PV] Recall for personID %@ (of size %lu) is %f
[AutoCounter][P/R][PV] Weighted Precision: %f, Weighted Recall: %f
[AutoCounter][CA] Report CoreAnalytics: %@
[AutoCounter][CA] Failed to retrive CoreAnalytics export URL
[AutoCounter][CA] Saved CoreAnalytics to %@
[AutoCounter][CA] Cannot write CoreAnalytics to %@ - %@
[AutoCounter][CA] Cannot retrieve CoreAnalytics files %@
[AutoCounter][CA] Files in folder %@
[AutoCounter][CA] Report CoreAnalytics files: %@
[AutoCounter][CA] Report CoreAnalytics file: %@
[AutoCounter][CA] Finished reporting CoreAnalytics %@
[AutoCounter][P/R] Failed to measure Vision cluster state against ground truth
[AutoCounter][P/R][PV] Failed to measure Person cluster state against ground truth
[AutoCounter][P/R][PV] Failed to report CoreAnalytics
[AutoCounter][P/R][SIMLGT] Failed to load SIML ground truth - %@
[AutoCounter][P/R][SIMLGT] Failed to serialize SIML ground truth - %@
[AutoCounter][P/R][SIMLGT] Load faceID: %@ for PersonID: %@
[AutoCounter][P/R][SIML] Failed to export current clusters states
[AutoCounter][P/R][SIML] Validate cluster state  %@ against ground truth %@
[AutoCounter][P/R][SIML] Failed to measure Vision cluster state against SIML ground truth
VCPMADVIUserFeedbackTask running...
VCPMADVIUserFeedbackTask image loading failed
VIService_UserFeedback
VCPMADVIUserFeedbackTask complete (%d)
[MediaAnalysis] [VCPVideoMetaAnalyzer] Unknown analysis type %@
Image Action classifier - merged actions for face  %@
Image Action classifier - torso or face not detected %@
Image Action classifier - PHFace gated out by age attribute
Image Action classifier - action class %d with confidence %f
VCPPriorityAnalysis - Start initializing
VCPPriorityAnalysis - Finished initializing hand detector
VCPPriorityAnalysis - Finished initializing hand keypoint detector
VCPPriorityAnalysis - Finished initializing gesture recognizer
VCPPriorityAnalysis - Number of hand detected %lu
VCPPriorityAnalysis - dominant hand: %d, hand chirality counter: left: %d, right: %d
VCPPriorityAnalysis - frame interval %f ms
VCPPriorityAnalysis - gestureScoreRightHand %f, gestureScoreLeftHand %f
VCPPriorityAnalysis - gesture score = %f, priority score after thresholding = %f
VCPPriorityAnalysis - Analysis subsampling ratio = %f
VCPPriorityAnalysis - Face yaw: %d
VCPPriorityAnalysis - output priority score = %f
VCPLandmarkValidator failed to validate image (%d)
[ImageManager] kCVPixelFormatType_32BGRA with kCGColorSpaceModelMonochrome, replace with DeviceRGB
[Decode] Downscaling %zux%zu --> %zux%zu
[Decode] %.0fx%.0f --> %zu; subsampling %dx on decode
[Decode] Failed to create CVPixelBuffer from IOSurface; falling back to rendering path
[Decode] Failed to obtain IOSurface; falling back to rendering path
[Decode] Accelerated decode failed; falling back to CGImage
Failed to load url %@ (%@)
[ImageManagerEncode] inputCVPixelBuffer cannot be NULL
[ImageManagerEncode] outputJPEGData cannot be nil
[ImageManagerEncode] targetBitStreamLength cannot be 0
[ImageManagerEncode] Encoding CVPixelBuffer -> JPEG (%lu Bytes)
[ImageManagerEncode] Failed to create compression session
[ImageManagerEncode] Fail to open compression container
[ImageManagerEncode] Fail to image buffer
[ImageManagerEncode] Fail to get transcoded data
[ImageManagerEncode] Oversized data (%luBytes)
[ImageManagerEncode] Padding JPEG with %lu Bytes
[ImageManagerEncode] Exporting reencoded JPEGs
VCPHandPoseImageRequest options: _revision = %d
copyImageToBGRHandKeypointCallFromSPI
preProcessingHandKeypointCallFromSPI
Action classifier - empty torso bound in PHFace %@
Action classifier - found torso bound in PHFace %@
[PreAnalysis] Pre-warmed image unused (%dx%d)
[PreAnalysis] Image not pre-warmed; creating on-demand (%dx%d)
%@ canceled (%@)
%@ failed (%@)
HomeKit analysis client XPC connection interrupted
HomeKit analysis client XPC connection invalidated
[HomeKitAnalysis] Error connecting to background analysis service
[HomeKitAnalysis] Request %d is %.2f%% complete
[HomeKitAnalysis] Unknown analysis request %d; dropping cancellation request
[HomeKitAnalysis] No active analysis requests; dropping cancellation request
[VCPFaceMerger] Failed to align face observation - %@
[VCPFaceMerger] Missing face for observation %@ from mapping
[VCPFaceMerger] Bounding box aligner returned an empty rectange
[VCPFaceMerger] Cannot merge face (v%lu, type-%d) with face %@ (v%lu, type-%d, %s imageprint)
[VCPFaceMerger] Cannot merge face with face %@ - distance %f > threashold %f
[VCPFaceMerger] Cannot merge face with face %@ - distance calculation failed %@
[VCPFaceMerger] Cannot Merge in final stage: [mutableDetectedFaces containsObject:detectedFace] %@ [facesToDelete containsObject:matchedExistingFace] %@ 
invalid buffer size %dx%d or pixel format %u
[VCPFaceClusterer] Failed to restore clusterer (state unknown) - %@
[VCPFaceClusterer] Restored Face Clusterer with ClusterState = %ld
Reset restore clusterer error (ClusterState = %ld): %@
Reset restored clusterer, ClusterState = %ld
Person Processing: Starting Reset Face Clustering
VCPFaceProcessingResetFaceClusteringState
Person Processing: Reset Face Clustering Done
Person Processing: Starting Face Clustering
VCPFaceProcessingPerformFaceClusteringAndWait
Person Processing: Face Clustering Done
---> Start face clustering (%ld) with clustering status: %@
---> Finished face clustering (%ld) with clustering status: %@
VCPFaceProcessingClusterFaces
---> Start face clustering as need (%ld) with clustering status: %@
VCPFaceProcessingClusterFacesIfNecessary
  Analyzing degraded version of Movie
Video caption not enabled by defaults write
Image caption test model not exist at %@, not generating image caption
Image captioning model not found or user not turning on Image Descriptions in Accessibility
  [%@] missing Pre Analysis result
  Analyzing degraded version of Photo
VCPImageFaceDetector
VCPImageFaceExpressionAnalyzer
Failed to create CVNLPCaptionHandlerRef (%@)
VCPImageJunkAnalyzer
VCPImageBlurAnalyzer
VCPLowResImageBlurAnalyzer
VCPImageExposureAnalyzer
VCPImageLivePhotoBlurAnalyzer
VCPImageCompositionAnalyzer
VCPImageDescriptor
VCPImageSaliencyAnalyzer
VCPImagePetsAnalyzer
VCPImagePetKeypointsAnalyzer
VCPImageHumanPoseAnalyzer
Human action on Live Photo requires paired movie, skip analyzing still
VCPImageHumanActionAnalyzer
VCPImageHandsAnalyzer
VCPLivePhotoAnalysis
Live Photo w/o local movie resource and streaming not allowed, skip paired movie analysis
VCPEffectsAnalyzer
[MediaAnalysis] PhotoAnalyzer - Original movie is not available, skip effects analysis
VCPParallaxAnalyzer
VCPFaceQualityAnalysis
VCPLivePhotoKeyFrameAnalyzer
VCPPhotoAnalyzer
VCPEmbeddingAnalyzerLoadImageRequestHandler
VCPNeuralHashprintRequest
NeuralHashprint Vision request failed: %lu - %@
VCPImageHashSignatureRequest
NeuralHash+LSH Vision request failed: %lu - %@
NeuralHash+LSH invalid imageSignatureHash
NeuralHash+LSH failed to encode hash: %@
Invalid NeuralHash+LSH (=)
Cannot create VCPPersonBuilder
---> Canceling VCPBuildPersons
VCPBuildPersons canceled
VCPBuildPersons failed: %@
Cannot create PVPersonPromoter
---> Canceling VCPPromotePersons
Person Processing: Starting Person Promoting
VCPFaceProcessingPromotePersonsCoreAnalyticsCollection
Person Processing: Person Promoting %@
VCPPromotePersons canceled
VCPPromotePersons failed
Cannot create PVPersonPromoter for evaluation
---> Canceling VCPFetchPersonPromoterClusterForEvaluation
Person Processing: Start evaluatePersonPromoterWithUpdateBlock
Person Processing: Retrieved %lu unverified person
Person Processing: evaluatePersonPromoterWithUpdateBlock canceled
Unknown Photos Face Processing umbrella version %d
[Perf] %s: %0.6fs
%-40s  %10s  %10s  %10s  %10s  %10s
  %-38s  %10.6f  %10.6f  %10.6f  %10.6f  %10zu
[CoreAnalyticManager] Session event name is nil; skipping
[CoreAnalyticManager] Session fields name is nil for event %@; skipping
[CoreAnalyticManager] Start session event %@ (total session count %lu)
[CoreAnalyticManager] Ignore 0-accumulation for event %@ field %@
[CoreAnalyticManager] Session event %@ not available
[CoreAnalyticManager] Session event %@ not available; skip sending
[CoreAnalyticManager] flushing analytics ... 
[CoreAnalyticManager] flushSessionAnalytics (total count %lu)
Failed to analyzeDetectedFaces - %@
song analysis failed %@
  [%@] Need Face Processing: no faceAdjustmentVersion
  [%@] Need Face Processing: faceAdjustmentVersion %@ != adjustmentTimestamp %@
Attempt to download resource: %@
[%@] Download progress: %.2f
Download resource timed-out (ID:%d)
Cancelling download (ID:%d)
[FileBasedDownload] Downloaded resource to file url: %@
[FileBasedDownload] Failed to download asset resource (%@)
[FileBasedDownload] Successfully downloaded asset resource
[FileBasedDownload] Failed to issue resource request
[FileBasedDownload][%@] Downloading %@
VCPDownloadResource
[FileBasedDownload][%@] Progress: %.2f
[FileBasedDownload][%@] URL: %@
[FileBasedDownload][%@] Failed on resource %@ - %@
[FileBasedDownload][%@] Success!
[FileBasedDownload][%@] Failed to issue resource request
Wrong outHeight in parseHeatmap2Keypoints
Wrong outWidth in parseHeatmap2Keypoints
[ResourceManager] Invalid cost detected (%ld); clipped to %ld
[ResourceManager] Updating budget (%ld --> %ld)
[ResourceManager] Hit usage timeout; purging resources
[ResourceManager] Request to reserve budget [Budget: %ld][Target: %ld]
[ResourceManager] Pruning inactive resources
[ResourceManager] Purging inactive resource (%@)
[ResourceManager] Failed to reserve budget [Budget: %ld][Target: %ld]
[ResourceManager] Request to activate %@
[ResourceManager] Resource not cached (%@)
[ResourceManager] Resource cached but not active (%@)
[ResourceManager] Activating resource (%@)
[ResourceManager] Resource cached and active (%@)
[ResourceManager] Active resource cost has increased (%@)
[ResourceManager] Active resources exceed budget
[ResourceManager] Active count %d
[ResourceManager] Request to deactivate %@
[ResourceManager] Resource transition active --> inactive (%@)
[ResourceManager] Received request to deactivate un-tracked resource (%@)
[ResourceManager] Request to purge inactive resources
[ResourceManager] Skipping active resource (%@)
[ResourceManager] Purging %@
[ResourceManager] Purging active resource (%@)
[ResourceManager] Request to purge all resources
Requested unavailable frame %d (Frame Count: %d  Buffer Depth: %d)
Unexpected media type (%lu)
[%@] Unexpected media type (%d)
[MotionFlowAnalyzer] Failed to request flow from VCPMotionFlowRequest: %@
Gyro analytics stored via dodML
Could not load MonzaV4_1.mlmodelc in the bundle resource
softlink:r:path:/System/Library/PrivateFrameworks/PhotoVision.framework/PhotoVision
softlink:r:path:/System/Library/PrivateFrameworks/HomeAI.framework/HomeAI
softlink:r:path:/System/Library/PrivateFrameworks/HomeAI.framework/HomeAI
softlink:r:path:/System/Library/PrivateFrameworks/PhotosGraph.framework/PhotosGraph
softlink:r:path:/System/Library/PrivateFrameworks/PhotoVision.framework/PhotoVision
softlink:r:path:/System/Library/PrivateFrameworks/PhotoVision.framework/PhotoVision
softlink:r:path:/System/Library/PrivateFrameworks/HomeAI.framework/HomeAI
softlink:r:path:/System/Library/PrivateFrameworks/PhotoVision.framework/PhotoVision
softlink:r:path:/System/Library/Frameworks/ShazamKit.framework/ShazamKit
VCPProtoMovieLaughterResult
NSCopying
VCPPetsRegion
VCPVideoPetsAnalyzer
VCPSettlingEffectAnalyzer
PVPhotoLibraryProtocol
NSObject
LegacyConversion
VCPProtoResultLegacyConversionProtocol
VCPInternetReachability
VCPVideoCNNAnalyzer
VCPProtoMovieSceneResult
VCPMAMLFeatureProvider
MLFeatureProvider
VCPVoiceDetector
VCPProtoMovieAudioQualityResult
PHAssetResource
VCPFullVideoAnalyzer
VCPProtoMovieFineSubjectMotionResult
BackwardCompatability
VCPVideoFullFaceDetector
CMTimeRange
VCPHomeFaceIdentificationTask
VCPMADTaskProtocol
VCPFingerprint
VCPCNNHandKeypointsDetectorEspresso
VCPImageExposurePreAnalyzer
VCPImageDescriptor
VCPDistanceDescriptorProtocol
VCPProtoLivePhotoKeyFrameResult
VCPCNNDataGPU
VCPVideoMetaFaceAnalyzer
VCPProtoKeypoint
PVFaceProtocol
VCPSuggestionRequest
VCPClusterer
PVFaceClusteringProtocol
VCPHumanPoseImageRequest
VCPVideoCNNTask
VCPProtoMovieHighlightScoreResult
VCPMADVIRemoveBackgroundCachedImageHandler
VCPMADVIRemoveBackgroundResource
VCPMADVIRemoveBackgroundTask
VCPMADServiceImageProcessingSubtaskProtocol
VCPVideoProcessorNode
VCPImageConverter
VCPFullAnalysisAssetProcessingTask
VCPMediaAnalysisServerProtocol
VCPMediaAnalysisClientProtocol
VCPMediaAnalysisService
FaceSuggestions
PersonBuilderAndPromoter
InternalTools
Hubble
VCPVideoCaptionEncoder
VCPHumanPoseEspressoSession
CMTime
VCPCNNPetsDetector
VCPMADImageSafetyClassificationResource
VCPMADImageSafetyClassificationTask
VCPCNNSmileDetector
VCPPhotosFace
PFPhotosFaceRepresentation
VCPCNNEspressoContext
VCPProtoMoviePetsFaceResult
VCPCNNPoseEstimatorEspresso
VCPVideoCNNQuality
VCPSegment
VCPClassification
VCPVideoSceneClassifier
VCPProtoImageFeatureResult
VCPTimer
VCPProtoImageHumanPoseResult
VCPProtoMovieQualityResult
VCPPhotosFaceProcessingContext
VCPFaceUtils
VCPProtoImageSceneprintResult
VCPProtoMovieSubtleMotionResult
VCPProtoMovieHumanActionResult
CGRect
VCPVideoPixelStabilizer
VCPContentAnalysis
VCPLightMotionAnalyzer
VCPLoaned
VCPObjectPool
VCPCNNFullConnectionBlockScalar
VCPProtoMovieSaliencyResult
VCPPreAnalysisRequests
VCPProtoImageFaceResult
VCPJunkAnalyzer
VCPVideoMetaMotionAnalyzer
VCPVideoMetaMotionSegment
VCPMADVIResource
VCPProtoVideoKeyFrame
VCPMediaAnalysis
VCPCNNModelEspresso
VCPWallpaperAnalyzer
MercuryBase64
VCPCNNPoolingBlockGPU
VCPClientDatabaseManager
VCPEdgeDetector
VCPVideoCaptionAnalyzer
VCPVideoTrackSyncDecoder
VCPProtoMovieClassificationResult
VCPVNImageprintWrapper
VCPVideoKeyFrameAnalyzer
VCPMetaSegment
VCPSharedInstanceManager
VCPMetaTrackDecoder
VCPAnalysisProgressQuery
VCPCNNConvBlockVector
VCPSaliencyRegion
VCPVideoSaliencyAnalyzer
VCPHandPoseVideoRequest
VCPMoFlowSingleEspresso
VCPImageQualityAnalyzer
VCPMADEmbeddingGenerationTask
VCPVideoProcessorSession
VCPProtoImageBlurResult
VCPFaceIDModel
VCPVanishingPointDetector
VCPVideoHumanActionClassifier
VCPImageSaliencyAnalyzer
MediaAnalysis
VCPMovieCurationAnalyzer
VCPMovieHighlight
VCPModelR2D2
PVAssetProtocol
VCPProtoMovieUtteranceResult
VCPProtoImageSaliencyResult
VCPMotionFlowRequest
VCPImageCompositionAnalyzer
VCPFaceProcessingVersionManager
VCPLightVideoAnalyzer
VCPVideoKeyFrame
VCPSceneprintDescriptor
VCPProtoImageShotTypeResult
VCPProtoImagePetsFaceResult
VCPImagePetsAnalyzer
VCPVideoFacePoseFilter
VCPCNNFullConnectionBlockGPU
PVPersonProtocol
VCPProtoBounds
VCPFace
VCPFaceDetectionRange
VCPFaceShapeModel
VCPCNNFaceLandmarkDetectorEspresso
VCPMADVITextLookupTask
VCPProtoImageCompositionResult
VCPImageFaceDetector
VCPMADResource
VCPCNNSmileDetectorEspresso
VCPVideoCNNHighlight
VCPRealTimeAnalysisServerProtocol
VCPRealTimeAnalysisClientProtocol
VCPRealTimeAnalysisService
MADActivitySchedulingRecord
CGPoint
VCPVideoPersonDetector
VCPProtoLivePhotoFrameInstruction
VCPFaceTensorModel
VCPProcessingStatusEntry
VCPProtoLivePhotoVariationParams
VCPImagePetsKeypointsAnalyzer
VCPVideoActivityAnalyzer
VCPCompactResult
VCPVideoGlobalAnalyzer
VCPCNNPoolingBlock
VCPProtoMovieHumanPoseResult
VCPExpressionSegment
VCPMovieHighlightAnalyzer
VCPHomeKitAnalysisSessionServerProtocol
VCPHomeKitAnalysisSessionClientProtocol
VCPHomeKitAnalysisSession
VCPHomeKitSessionExportedObject
VCPDatabaseReader
VCPProtoTime
VCPURLAsset
Image
LivePhoto
Movie
VCPExifAnalyzer
VCPHomeResidentMaintenanceTask
VCPMADServiceImageProcessingTaskBatch
VCPVideoCNNBackbone
VCPLoudnessAnalyzer
VCPProtoMovieActivityLevelResult
VCPColorNormalizationAnalyzer
VCPFaceCropUtils
VCPPhotosQuickFaceDetectionManager
VisualSearch
VCPMADMachineReadableCodeResource
VCPMADVIMachineReadableCodeDetectionTask
VCPHuman
VCPFlowDecoder
VCPProtoMovieInterestingnessResult
VCPLandmarkValidator
VCPVideoStabilizer
VCPPhotosPersistenceDelegateAdditions
VCPMergeCandidatePair
VCPPhotosPersistenceDelegate
PVPersonPromoterDelegate
VCPProtoImageExposureResult
VCPProtoMovieFeatureResult
VCPPhotosAsset
VCPMADVIDocumentRecognitionResource
VCPMADVIDocumentRecognitionTask
VCPMADPersonIdentificationTaskResource
VCPMADPersonIdentificationTask
VCPBlurAnalyzer
VCPHumanPoseVideoRequest
VCPImageBlurAnalyzer
VCPFlowFeatureExtractor
VCPImageExposureAnalyzer
VCPProtoAssetAnalysis
VCPMADServiceImagePixelBufferAsset
VCPMADServiceImageURLAsset
VCPMADServiceImageDataAsset
VCPMADServiceImagePhotosAsset
VCPMADServiceImageAsset
VCPCNNFaceLandmarkDetectorMPS
VCPVideoObjectTracker
VCPFaceCropManager
VCPPhotosQuickFaceIdentificationManager
VCPCNNBlurAnalyzerEspresso
VCPVideMetaOrientationAnalyzer
VCPFaceProcessingServiceWorker
VCPVideoTrackSubsamplingDecoder
VCPFrameAnalysisStats
VCPVideoCNNAutoplay
VCPVideoPetsActionAnalyzer
VCPVideoKeyFrameResult
VCPMovieHighlightResult
VCPMovieCurationResults
VCPVideoTrackDecoder
VCPFaceCrop
VCPCoreMLRequest
VCPFrameScoreFilter
VCPProtoMovieBabbleResult
VCPMADVIVisualSearchGatingTask
VCPEspressoModel
VCPFaceAnalyzer
MovieResource
VCPSoundDetector
SNResultsObserving
VCPSoundClassifier
VCPAudioClassifier
VCPProtoMovieFaceprintResult
VCPCNNBlock
MediaAnalysisPhoto
MediaAnalysisMovie
MediaAnalysisSceneProcessing
MediaAnalysisOCRProcessing
MediaAnalysisVisualSearchProcessing
VCPMADVIVisualSearchTask
VCPGeometryUtils
VCPProtoMovieCheeringResult
VCPProtoMovieMusicResult
VCPCNNFaceLandmarkDetector
VCPCNNSmileDetectorMPS
VCPCNNConvBlockGPU
VCPVideoProcessor
VCPProtoMovieStabilizationResult
VCPProtoMovieHighlightResult
VCPCNNFullConnectionBlock
VCPHomeKitMotionAnalyzer
VCPProtoMovieSceneprintResult
CMTimerange
VCPSlowmo
VCPProtoMovieSubjectMotionResult
VCPBoundingBox
VCPCNNPoseEstimator
VCPVideoStabilizationAssetProcessingTask
VCPMovieAnalyzer
VCPImageHandsAnalyzer
VCPProtoMovieObstructionResult
VCPMADServiceImageProcessingTask
VCPProtoLivePhotoEffectsResult
VCPCNNBlurAnalyzer
VCPProtoLivePhotoRecommendationResult
VCPDatabaseBatchIterator
PVFetchResultProtocol
NSFastEnumeration
VCPProtoTimeRange
VCPImageLivePhotoBlurAnalyzer
VCPFullAnalysisURLProcessingTask
PVFaceGroupProtocol
VCPProtoLivePhotoEffectsRecipe
VCPProtoLivePhotoHumanActionClassificationResult
VCPAudioAnalyzer
VCPCNNGazeAnalysis
VCPPersonBuilder
VCPImageHumanPoseAnalyzerTopDown
VCPProtoMoviePreEncodeResult
VCPMADVIRectangleDetectionResource
VCPMADVIRectangleDetectionTask
VCPPreAnalyzer
VCPVideoTrackStandardDecoder
VCPCNNPersonKeypointsDetector
VCPFaceGeometry
NSSecureCoding
NSCoding
VCPFaceAnchor
VCPCaptureAnalysisSession
VCPCNNPetsDetectorEspresso
VCPCNNFastGestureRecognition
VCPMotionFlowSubtleMotionAnalyzer
VCPEffectsAnalyzer
VCPVideoFaceDetector
VCPGaborFilter
VCPCancelToken
VCPStorageServiceProtocol
VCPMediaAnalyzer
VCPPhotosSceneprintAssetProcessingTask
PVMomentProtocol
VCPImageAnalyzer
VCPVideoMetaLensSwitchAnalyzer
VCPVideoMetaLivePhotoMetaAnalyzer
VCPCNNData
VCPHoughTransform
VCPRTLandmarkDetector
VCPCNNConvBlock
VCPCNNConvBlockScalar
VCPProtoImagePetsResult
VCPMADVisionResource
VCPCNNHandsDetector
VCPMAMLModel
VCPCNNPoolingBlockVector
VCPRequest
VCPProtoClassification
VCPInMemoryAVAsset
AVAssetResourceLoaderDelegate
VCPProtoMovieFaceResult
VCPProtoLivePhotoKeyFrameStillResult
VCPDownloadManager
VCPTransforms
VCPActionAnalyzer
MediaAnalysisResults
MediaAnalysisPauseResume
VCPImageMotionFlowAnalyzer
VCPDefaultPhotoLibraryManager
PHPhotoLibraryAvailabilityObserver
VCPInterAssetAnalyzer
VCPClusteringAccuracyMeasures
VCPPhotosAutoCounterWorker
VCPProtoPoint
Exif
VCPImageSaliencyAnalyzerFull
VCPMADVIUserFeedbackTask
VCPMADVIVisualSearchResource
VCPVideoMetaAnalyzer
VCPKeypoint
VCPPersonObservation
VCPHandObservation
VCPMotionFlowObservation
VCPImageHumanActionAnalyzer
VCPProtoMovieApplauseResult
VCPPriorityAnalysis
VCPVideoFaceMeshAnalyzer
bRVA
VCPImageManager
VCPHandPoseImageRequest
VCPCNNHandKeypointsDetector
VCPVoiceDetectorV2
VCPCNNPoseEstimatorMPS
VCPProtoImageJunkResult
VCPProtoMovieCameraMotionResult
VCPVideoCNNActionClassifier
VCPImageSaliencyAnalyzerFullEspresso
VCPCNNFlattenBlock
VCPVideoMetaFocusAnalyzer
VCPVideoMetaFocusSegment
VCPProtoMovieLoudnessResult
VCPPreAnalysisImageEntry
VCPPreAnalysisImage
VCPMABaseTask
VCPHomeKitAnalysisServerProtocol
VCPHomeKitAnalysisClientProtocol
VCPHomeKitAnalysisService
Client
Resident
VCPPhotosFacePair
VCPFaceMerger
VCPLivePhotoKeyFrameAnalyzer
VCPCNNPersonDetector
VCPPoolBasedPixelBufferCreator
VCPParallaxAnalyzer
VCPImageFaceExpressionAnalyzer
VCPTimeMeasurement
VCPImageHumanPoseAnalyzer
VCPFaceClusterer
VCPBackwarp
VCPLogManager
VCPProtoMovieSummaryResult
VCPPreAnalysisImageLoader
VCPProtoMovieVoiceResult
VCPCNNMetalContext
VCPCNNBlurAnalyzerMPS
VCPPhotoAnalyzer
VCPMAEmbeddingAnalyzer
VCPTrimAnalyzer
VCPSceneChangeAnalyzer
VCPSceneChangeSegment
VCPMADCoreAnalyticsManager
VCPProtoMovieOrientationResult
VCPSceneProcessingImageManager
VCPImageFaceQualityAnalyzer
VCPVideoLightFaceDetector
VCPProtoMoviePetsResult
VCPVideoAnalyzer
VCPPnPSolver
VCPSongDetector
VCPProtoLivePhotoKeyFrameFaceResult
VCPCorrelation
VCPVideoHumanActionAnalyzer
VCPAsset
VCPPHFaces
VCPProtoLine
VCPProtoMovieStabilizationRecipe
VCPCNNPetsKeypointsDetector
VCPVideoFacePoseAnalyzer
VCPVideoCNNCameraMotion
VCPVideoActivityDescriptor
VCPCNNModel
VCPMADResourceLock
VCPMADResourceEntry
VCPMADResourceManager
VCPProtoMovieMovingObjectResult
VCPDeviceInformation
VCPCNNPoolingBlockScalar
FullAnalysis
VCPMotionFlowAnalyzer
VCPProtoLivePhotoSharpnessResult
VCPVideoGyroStabilizer
MonzaV4_1Input
MonzaV4_1Output
MonzaV4_1
VCPCtrTracker
VCPBaseTracker
description
dictionaryRepresentation
stringWithFormat:
dictionary
setObject:forKey:
numberWithFloat:
setTimeRange:
allocWithZone:
init
copyWithZone:
isMemberOfClass:
isEqual:
hash
mergeFrom:
readFrom:
writeTo:
copyTo:
timeRange
confidence
setConfidence:
.cxx_destruct
_confidence
_timeRange
T@"VCPProtoTimeRange",&,N,V_timeRange
Tf,N,V_confidence
descriptorWithImage:
serialize
computeDistance:toDescriptor:
initWith:confidence:
bound
setBound:
_bound
T{CGRect={CGPoint=dd}{CGSize=dd}},V_bound
Tf,V_confidence
array
initWithMaxNumRegions:
count
arrayWithArray:
countByEnumeratingWithState:objects:count:
objectForKeyedSubscript:
floatValue
addObject:
dictionaryWithObjects:forKeys:count:
analyzePixelBuffer:flags:results:cancel:
parseResults:toDetections:atTime:fromTime:addActiveRegions:
setPetsDetections:
analyzeFrame:withTimestamp:andDuration:flags:frameStats:
addDetectionToDict:withActiveRegions:forPetsDetections:fromTime:
setValue:forKey:
initWithTransform:
analyzeFrame:withTimestamp:andDuration:flags:
finishAnalysisPass:
results
_petsDetections
_petsFaceDetections
_timeLastProcess
_petsStart
_petsFaceStart
_petsAnalyer
_petsActiveRegions
_petsFaceActiveRegions
initWithTimestamps:andTrack:
finishAnalysisPass:withStillImageBuffer:
processAborted
cancelled
setCancelled:
_processAborted
_cancelled
TB,R,V_processAborted
TB,N,V_cancelled
sortDescriptorWithKey:ascending:
arrayWithObjects:count:
performChangesAndWait:error:
setWantsIncrementalChangeDetails:
setPhotoLibrary:
_defaultFetchOptions
_defaultAssetPropertySets
setFetchPropertySets:
processInfo
processName
isEqualToString:
isSystemPhotoLibrary
urlForApplicationDataFolderIdentifier:
photoLibraryURL
URLByAppendingPathComponent:
URLForDirectory:inDomain:appropriateForURL:create:error:
path
fileExistsAtPath:isDirectory:
createDirectoryAtURL:withIntermediateDirectories:attributes:error:
fileURLWithPath:
setMinimumVerifiedFaceCount:
setMinimumUnverifiedFaceCount:
_phPeopleSortDescriptors
setSortDescriptors:
setIncludeTorsoOnlyPerson:
fetchPersonsWithLocalIdentifiers:options:
predicateWithFormat:
setPredicate:
fetchPersonsWithOptions:
setPersonContext:
fetchedObjects
fetchAssetsForPersons:options:
firstObject
creationDate
lastObject
timeIntervalSinceDate:
predicateWithBlock:
filteredArrayUsingPredicate:
fetchPersonsForAssetCollection:options:
fetchMergeCandidatePersonsForPerson:options:
fetchInvalidMergeCandidatePersonsForPerson:options:
fetchPersonsGroupedByAssetLocalIdentifierForAssets:options:
setIncludeOnlyFacesWithFaceprints:
setShouldPrefetchCount:
setIncludeTorsoOnlyDetectionData:
fetchFacesWithOptions:
_defaultFacePropertySets
_phFaceSortDescriptors
fetchFacesWithLocalIdentifiers:options:
fetchFacesForPerson:options:
localIdentifier
pv_fetchFacesForPersonLocalIdentifiers:inMoment:
fetchAssetsInAssetCollection:options:
fetchedObjectIDs
uuidFromLocalIdentifier:
andPredicateWithSubpredicates:
setInternalPredicate:
fetchFacesInFaceGroup:options:
fetchFacesGroupedByAssetLocalIdentifierForAssets:options:
momentSortDescriptors
fetchMomentsWithOptions:
fetchAssetCollectionsWithLocalIdentifiers:options:
fetchMomentsForAssetsWithLocalIdentifiers:options:
_defaultAssetFetchOptions
fetchAssetsWithLocalIdentifiers:options:
fetchAssetsForFaceGroups:options:
fetchFaceGroupsWithOptions:
fetchFaceGroupsForPerson:options:
unsignedIntegerValue
ratioOfAssetsWithFacesProcessed
fetchAssetCollectionsWithType:subtype:options:
setFetchLimit:
setIncludeAssetSourceTypes:
fetchAssetsWithOptions:
pv_performChangesAndWait:error:
pv_persistentStorageDirectoryURL
pv_fetchPersonsWithLocalIdentifiers:
pv_fetchPersonsWithType:
pv_fetchPersonsInMoment:
pv_fetchCandidatePersonsForPerson:
pv_fetchInvalidCandidatePersonsForPerson:
pv_fetchPersonsGroupedByAssetLocalIdentifierForAssets:
pv_numberOfFacesWithFaceprints
pv_fetchFacesWithLocalIdentifiers:
pv_fetchFacesForPerson:
pv_fetchFacesForPerson:inMoment:
pv_fetchFacesForFaceGroup:
pv_fetchFacesGroupedByAssetLocalIdentifierForAssets:
pv_fetchMoments
pv_fetchMomentsWithLocalIdentifiers:
pv_fetchMomentsForPerson:
pv_fetchMomentsForAssetsWithLocalIdentifiers:
pv_fetchAssetsWithLocalIdentifiers:
pv_fetchAssetsInMoment:
pv_fetchAssetsForPerson:
pv_fetchAssetsForFaceGroup:
pv_fetchFaceGroups
pv_fetchFaceGroupsForPerson:
_progressFromWorkerStatesDictionary:
pv_faceProcessingProgress
pv_fetchInvalidAssetIdentifiersForCommonComparison
pv_lastAssetDate
pv_fetchAssetsForFaceLocalIdentifiers:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
superclass
debugDescription
TQ,R
T#,R
T@"NSString",R,C
boundsWithCGRect:
setFaceBounds:
setFaceQuality:
faceBounds
rectValue
faceQuality
exportToLegacyDictionary
resultFromLegacyDictionary:
setReachabilityForFlags:update:
dealloc
sharedInstance
hasWifiOrEthernetConnection
_callbackQueue
_reachability
_hasWifiOrEthernetConnection
TB,R,N,V_hasWifiOrEthernetConnection
string
length
appendString:
initImageTransform:transformedImageWidth:transformedImageHeight:
forcePersonDetection
initWithPHFaces:
isMLHighlightEnabled
configForAspectRatio:
cropAndScale:regionCrop:
copyImage:withChannels:
persons
runTasks:duration:persons:regionCrop:
clipResults:
addEntriesFromDictionary:
loadAnalysisResults:
loadAnalysisResults:audioResults:
initWithConfig:
inference:
run:withPersons:andRegionCrop:atTime:andDuration:
run:
initWithTimeOfInteret:frameRate:isLivePhoto:phFaces:timeRange:requestedAnalyses:
loadAnalysisResultsFrom:actionAnalyzer:atTime:
isAnalysisResultNeeded:
privateResults
_backbone
_transformImage
_tasks
_postTasks
_privateTasks
_inputData
_inputWidth
_inputHeight
_timeLastDetection
_timeStart
_validFrames
_enoughFrames
_personDetector
_resConfig
_autoplay
_cameraMotion
_quality
_highlight
_regionCrop
_timeEnd
_postInference
setDistanceToPreviousScene:
setHasDistanceToPreviousScene:
hasDistanceToPreviousScene
setFlickerScore:
setHasFlickerScore:
hasFlickerScore
setSceneprintDistanceToPreviousScene:
setHasSceneprintDistanceToPreviousScene:
hasSceneprintDistanceToPreviousScene
qualityScore
setQualityScore:
distanceToPreviousScene
flickerScore
sceneprintDistanceToPreviousScene
_distanceToPreviousScene
_flickerScore
_qualityScore
_sceneprintDistanceToPreviousScene
_has
Tf,N,V_qualityScore
TB,N
Tf,N,V_distanceToPreviousScene
Tf,N,V_flickerScore
Tf,N,V_sceneprintDistanceToPreviousScene
initWithCVPixelBuffer:andFeatureName:
setWithObject:
featureValueWithPixelBuffer:
featureProviderWithCVPixelBuffer:andFeatureName:
featureValueForName:
featureNames
T@"NSSet",R,N
_featureName
_buffer
objectForKey:
loadModel
setupWithAudioStream:
detector
audioFormatRequirements
addDetectionFromTime:toTime:result:
setupWithSample:andSampleBatchSize:
processAudioSamples:timestamp:
finalizeAnalysisAtTime:
voiceDetections
setVoiceDetections:
_model
_audioStream
_sampleBatchSize
_trackStart
_voiceActivity
_voiceStart
_voiceDetections
_utteranceDetections
_musicDetections
T@"NSMutableArray",&,V_voiceDetections
vcp_size
sortUsingComparator:
vcp_sortBySize
type
vcp_originalResource
vcp_isLocallyAvailable
vcp_isDecodable
vcp_isPhotoResourceUsable:
vcp_isMovie
vcp_isVideoResourceUsable:
vcp_isOriginalLocal
vcp_hasLocalMovie:
vcp_hasLocalAdjustments
vcp_resourceWithType:
vcp_smallResourceMeetingCriteria:
vcp_isPhoto
vcp_localMovieResourcesSorted:
reverseObjectEnumerator
vcp_avAsset
vcp_adjustmentsResource
privateFileURL
initWithURL:
hasSlowMotionAdjustments
slowMotionRate
hasAdjustments
photoLibrary
vcp_isSyndicationLibrary
analysisType
vcp_ascendingSizeComparator
vcp_hasLocalPhoto:
vcp_hasLocalSlowmo:
vcp_thumbnailResource
vcp_smallMovieDerivativeResource
vcp_originalVideoResource
vcp_localPhotoResourcesSorted:
vcp_photoResourcesSorted:
vcp_avAsset:
vcp_getFpsRate
vcp_highResImageResourcesForAsset:
timeRangeWithCMTimeRange:
setBounds:
setFlags:
timeRangeValue
mutableCopy
flags
numberWithInt:
setObject:forKeyedSubscript:
bounds
enableMoflow
useSceneprintInSceneAnalysis
initWithFilterTabs:distanceVariance:diffVariance:
vcp_orientation
preferredTransform
initWithFrameWidthInMb:heightInMb:
setVideoActivityDescriptor:
videoActivityDescriptor
containsObject:
analyzeFrame:withTimestamp:andDuration:properties:flags:cancel:
seedAnalyzersWithPixelBuffer:startTime:
intValue
analyzePixelBuffer:withFrame:withTimestamp:andDuration:cancel:
analyzePixelBuffer:withFrame:withTimestamp:andDuration:hasSubtleScene:cancel:
detectedFaces
estimateExpressionScore:encodeStats:frameWidth:frameHeight:
isStableMetaMotion:
frameExpressionScore
setFrameExpressionScore:
salientRegionsFromPixelBuffer:
reviseFrameTrackScore:saliencyRegions:
processAndEstimateQualityScore:
process:
ExtractActivityDescriptorFromStats:
setCameraMotionScore:
setSubjectActionScore:
setInterestingnessScore:
setColorfulnessScore:
setFrameProcessedByVideoAnalyzer:
setSubMbMotionAvailable:
computeExposureScoreOfFrame:
setExposureScore:
setMotionParam:
setMotionParamDiff:
processFrameScore:validScore:
interestingnessScore
addSceneAnalysisResult:to:optional:
estimateQualityScore:
addResult:to:forKey:optional:
addSceneAnalysisResult:to:clipRange:
initWithVideoTrack:withMetaOrientation:withPrivateResults:withFrameStats:isTimelapse:isIris:irisPhotoOffsetSec:irisPhotoExposureSec:slowMoRate:faceDominated:
prepareVideoAnalysisByScenes:
prepareLivePhotoAnalysisByScenes:
analyzeFrame:withTimestamp:andDuration:flags:cancel:
getSceneSwichFrequency
setNextCaptureFrame:
actionScore
setActionScore:
obstructionScore
setObstructionScore:
trackingScore
setTrackingScore:
objectsMotion
globalMotion
.cxx_construct
_encodeAnalysis
_preencodeAnalysis
_obstructionAnalysis
_sceneAnalysis
_motionFilter
_metadataAnalysis
_irisAnalysis
_frameBuffer
_idealHistogram
_isTimelapse
_isIris
_isSlowMo
_orientation
_finalized
_hasInterestingScene
_isCaptureAnalysis
_privateResults
_videoFrameAnalysis
_trackScoreFilter
_metaMotionResults
_faceDominated
_useMoflow
_subtleMotionAnalyzer
_motionFlowAnalyzer
_sceneType
_actionScore
_interestingnessScore
_obstructionScore
_trackingScore
_objectsMotion
_globalMotion
Tf,V_qualityScore
Tf,V_actionScore
Tf,V_interestingnessScore
Tf,V_obstructionScore
Tf,V_trackingScore
T@"NSDictionary",R,N,V_objectsMotion
T@"NSArray",R,N,V_globalMotion
Tf,N,V_actionScore
updateModelByAddingFaces:andRemovingFaces:canceller:error:
updateModelByAddingFaces:error:
vcp_updateModelByAddingFaces:error:
initWithTransform:withExistingFaceprints:frameStats:
estimator
globalSession
releaseCachedResources
initWithCVPixelBuffer:options:
configureVNRequest:withClass:andProcessingVersion:
performRequests:error:
addObjectsFromArray:
boundingBox
detectSmileForFace:inBuffer:smile:
detectPoseForFace:inBuffer:yaw:
setSmile:
setYaw:
setObservation:
setFrameProcessedByFaceDetector:
enumerateKeysAndObjectsUsingBlock:
removeObjectForKey:
trackObjectInFrame:
objectBounds
start
setTrackID:
removeObjectsForKeys:
minProcessTimeIntervalInSecs
detectFaces:faces:
faceBoundsWithTransform:height:transform:
removeAllObjects
trackID
removeObject:
compareFace:withFace:
objectAtIndexedSubscript:
removeObjectAtIndex:
removeSmallestKeyFace
initWithObjectBounds:inFrame:timestamp:
setFaceArea:
detectTrackFacesInFrame:withTimestamp:faces:
flagsForOrientation:width:height:
last
setStart:
setLast:
setPosition:
setFaceID:
position
numberWithUnsignedInteger:
numberWithInteger:
observation
setFaceId:
faceprint
requestRevision
initWithType:cachePath:state:threshold:requestRevision:
clustererBuilderWithOptions:error:
objects
faceID
initForReadingFromData:error:
decodeObjectOfClass:forKey:
computeDistance:withDistanceFunction:error:
integerValue
clusterFaces
updateWithExistingFaces
initRequiringSecureCoding:
encodeObject:forKey:
encodedData
faceRanges
locationChange:relativeTo:landscape:
frameFaceResults
_latestTrackID
_smileDetector
_poseEstimator
_existingFaceprints
_frameStats
_latestFrameArea
_timeLastTracking
_faceTrackers
_keyFaces
_reservedIDs
_facePrints
_allFaces
_faceRanges
_frameFaceResults
timeWithCMTime:
setDuration:
timeValue
duration
initWithFaceCrop:andCompletionHandler:
errorWithDomain:code:userInfo:
setRevision:
setMetalContextPriority:
setPreferBackgroundProcessing:
defaultANEDevice
setProcessingDevice:
configureRequest:withRevision:
initWithData:options:
sharedManager
defaultPhotoLibrary
vcp_vipModelFilepathForVIPType:
defaultManager
fileExistsAtPath:
loadVIPModelAtPath:withVIPType:error:
classifyFaceObservation:withModel:error:
code
taskWithFaceCrop:andCompletionHandler:
resourceRequirement
autoCancellable
cancel
cachesResources
interrupt
resetInterruption
_completionHandler
_faceCropData
_started
_cancel
initWithMaster:adjusted:
master
adjusted
fingerprintWithMaster:adjusted:
isEqualToFingerprint:
_master
_adjusted
T@"NSString",R,V_master
T@"NSString",R,V_adjusted
doubleValue
setTimestamp:
setQualityScoreForLivePhoto:
setVisualPleasingScore:
setOverallFaceQualityScore:
setPenaltyScore:
setTextureScore:
setSharpness:
setExpressionChangeScore:
addFaceResults:
setGlobalQualityScore:
setContentScore:
faceResultsCount
faceResults
objectAtIndex:
timestamp
numberWithDouble:
qualityScoreForLivePhoto
visualPleasingScore
overallFaceQualityScore
exposureScore
penaltyScore
textureScore
sharpness
expressionChangeScore
dictionaryWithDictionary:
hasGlobalQualityScore
globalQualityScore
hasContentScore
contentScore
vcp_mediaAnalysisBundle
resourceURL
URLWithString:relativeToURL:
numberWithBool:
initWithParameters:inputNames:outputNames:properties:
prepareModelWithConfig:
inputBlob
espressoForward:
outputBlob
cvtHeatmaps2Keypoints:outHeight:outWidth:inHeight:inWidth:outChannel:keypoints:keypointConfidence:offset:
init:sharedModel:modelName:
getInputBuffer:srcWidth:cnnInputHeight:cnnInputWidth:offset:
generateHandKeypoints:keypointConfidence:offset:
_forceCPU
_modelEspresso
computeRegionNoise:blockTextureness:average:width:height:stride:
calculateTextureness:height:width:sdof:result:
computeNoiseLevel:width:height:stride:textureness:
_exposureScore
Tf,R,N,V_exposureScore
initWithImage:
initWithData:
imageprint
initWithState:error:
serializeStateAndReturnError:
distanceToImageprint:error:
usePHAssetData
preferredPixelFormat
descriptorWithData:
_imagePrint
initWithCapacity:
clearFaceResults
faceResultsAtIndex:
faceResultsType
setHasGlobalQualityScore:
setHasContentScore:
setFaceResults:
_timestamp
_contentScore
_expressionChangeScore
_faceResults
_globalQualityScore
_overallFaceQualityScore
_penaltyScore
_qualityScoreForLivePhoto
_sharpness
_textureScore
_visualPleasingScore
Td,N,V_timestamp
Tf,N,V_qualityScoreForLivePhoto
Tf,N,V_visualPleasingScore
Tf,N,V_overallFaceQualityScore
Tf,N,V_exposureScore
Tf,N,V_penaltyScore
Tf,N,V_textureScore
Tf,N,V_sharpness
T@"NSMutableArray",&,N,V_faceResults
Tf,N,V_globalQualityScore
Tf,N,V_contentScore
Tf,N,V_expressionChangeScore
allocBuffers:
setEyeExpression:
setMouthExpression:
setIsCloseup:
eyeExpression
mouthExpression
isCloseup
hasFaceQuality
flipTransform:
items
value
time
processMetadataGroup:flags:
finalizeAnalysis
publicResults
_activeFaces
_transform
setX:
setY:
Tf,N,V_x
Tf,N,V_y
fetchPropertySetsIfNeeded
faceClusteringProperties
faceprintData
changeRequestForFace:
setQualityMeasure:
personLocalIdentifier
size
centerX
centerY
poseYaw
clusterSequenceNumber
qualityMeasure
ageType
poseType
T@"NSString",R,N
Td,R,N
Tq,R,N
T@"NSData",R,N
Tq,N
TS,R,N
Tq,D,N
initWithIndexesInRange:
intersectsSet:
minusSet:
removeIndex:
enumerateIndexesUsingBlock:
copy
objectsAtIndexes:
UUID
UUIDString
enumerateObjectsUsingBlock:
initWithFaceClusterIds:clusterFlags:updateHandler:
requestWithFaceClusterIds:clusterFlags:updateHandler:
requestId
clusterFlagByClusterId
csns
cflags
updateHandler
setUpdateHandler:
canceller
_type
_requestId
_clusterFlagByClusterId
_csns
_cflags
_updateHandler
_canceller
TQ,R,V_type
T@"NSString",R,V_requestId
T@"NSMutableDictionary",R,V_clusterFlagByClusterId
T@"NSArray",R,V_csns
T@"NSArray",R,V_cflags
T@?,C,V_updateHandler
T@"VNCanceller",R,V_canceller
faceClusteringDisabled
initWithPhotoLibrary:
vcp_visionCacheStorageDirectoryURL
faceClusteringThreshold
_readPropertyDictionary
_cancelClusteringAndRestoreClusterCache:
cancelAllSuggestionRequests
countOfFaces
minFaceCountToTriggerClustering
maxFaceCountForClustering
_recordIncrementCountOfPendingFacesToAdd:
unionSet:
_processingQueueDetermineNextClusterTriggeringAccumulatedChangesCountIfNecessary
_recordClusteringState:
allClusteredFaceIdsAndReturnError:
allObjects
_faceTorsoprintsFromFaceCSNs:
setClustererBringUpState:
_performAndPersistClustersWithFaceTorsoprintsToAdd:groupingIdentifiersToAdd:faceTorsoprintsToRemove:updatedFaces:cancelOrExtendTimeoutBlock:error:
processingVersion
deterministicallyOrderedFaceIdentifiersWithLocalIdentifiers:faceprintVersion:
setWithArray:
setWithSet:
intersectSet:
subarrayWithRange:
removeObjectsInArray:
dictionaryWithCapacity:
_faceTorsoprintsFromFaceIdentifiers:assignClusterSeqNumberIfNeeded:updatedFaces:groupingIdentifiers:
_recordCountOfPendingFacesToAdd:
vcp_assetCountForTaskID:
sendEvent:withAnalytics:
getAllClustersAndReturnError:
needsFullSync
needsUpdate
_processingQueueSyncClustererWithPhotoLibraryUsingFacesInClusterCache:cancelOrExtendTimeoutBlock:
isReady
_processingQueuePerformForcedFaceClustering:cancelOrExtendTimeoutBlock:
signalCancellation
restoreClusterCacheAndSyncWithLibrary:cancelOrExtendTimeoutBlock:error:
lock
unlock
updateModelByAddingPersons:withGroupingIdentifiers:andRemovingPersons:canceller:error:
clusterId
longValue
level0ClusterAsFaceCSNsByLevel0KeyFaceCSNForClusterIdentifiedByFaceCSN:error:
setWithCapacity:
_processingQueueSaveClusterCache:
persistChangesToAlgorithmicFaceGroups:l1ClustersByFaceCSNRepresentingFaceGroup:l0ClustersByFaceCSNRepresentingFaceGroup:faceCSNByLocalIdentifierForNewlyClusteredFaces:faceCSNsOfUnclusteredFaces:localIdentifiersOfUnclusteredFaces:persistenceCompletionBlock:cancelOrExtendTimeoutBlock:error:
scheduleClusteringAfterRemovingFaceCSNs:addingFaceIdStrs:
allValues
allKeys
arrayWithCapacity:
initWithFaceprint:torsoprint:
setPersonId:
facesForClusteringWithLocalIdentifiers:faceprintVersion:groupingIdentifiers:
_faceTorsoprintsFromFaces:assignClusterSeqNumberIfNeeded:updatedFaces:
imageprintWrapper
data
generateVNImageprintWithType:archiveData:andError:
setClusterSequenceNumber:
deleteEmptyGroupsAndReturnError:
cleanupUngroupedFacesWithNonZeroClusterSequenceNumbers:error:
cleanupGroupedFacesWithClusterSequenceNumberSetToZero:error:
countOfClusteredFaces
date
_bringUpStateDescription:
_processingQueueQuickSyncClustererWithPhotoLibraryUsingFacesInClusterCache:visionClusters:cancelOrExtendTimeoutBlock:
_processingQueueGetVisionClusters:minimumClusterSize:returnClusterAsCountedSet:excludedL0ClustersByL1ClusterId:cancelOrExtendTimeoutBlock:error:
groupedClusterSequenceNumbersOfFacesInFaceGroupsOfMinimumSize:error:
ungroupFaceClusterSequenceNumbers:batchSizeForUnclusteringFaces:cancelOrExtendTimeoutBlock:error:
_removeEmptyGroups
timeIntervalSinceReferenceDate
_setPropertyDictionaryValue:forKey:
_processingQueueResetClusterCache:
resetLibraryClustersWithCancelOrExtendTimeoutBlock:error:
unclusteredClusteringEligibleFaceLocalIdentifiers:
invalidFaceClusterSequenceNumbersInClusterSequenceNumbers:cancelOrExtendTimeoutBlock:error:
countOfClusteringEligibleFaces
_recordCurrentStatus:
clustererBringUpState
saveAndReturnCurrentModelState:
finishEncoding
fileSystemRepresentation
bytes
_removeVisionClusterCacheFilesNotReferencedByVisionClusterState:
_processingQueueGetFaceClusterSequenceNumbersInClusterCache:lastClusterSequenceNumber:error:
clustererModelFileNamesFromState:storedInPath:error:
initWithType:cachePath:state:threshold:torsoThreshold:requestRevision:torsoprintRequestRevision:
cachePath
threshold
torsoprintRequestRevision
torsoThreshold
removeClusteringStateCacheWithURL:error:
_processingQueueRestoreClusteringCacheWithCacheDirectoryURL:clusterState:threshold:error:
dataWithBytesNoCopy:length:freeWhenDone:
_visionClusterMemmapFileInCacheDirectoryURL:clusterState:error:
contentsOfDirectoryAtURL:includingPropertiesForKeys:options:error:
pathExtension
lastPathComponent
removeItemAtURL:error:
_visionClusterStateDataBlobFromClusterSnapshotFileAtURL:error:
finishDecoding
URLByDeletingLastPathComponent
_processingQueueRestoreFromClusterSnapshotFileAtURL:error:
_processingQueueRestoreClusterCacheAndSyncWithLibrary:cancelOrExtendTimeoutBlock:error:
_recordClusterRebuildRequired:
clustererState
facePrimarySuggestionsThreshold
suggestionsForClustersWithFaceIds:affinityThreshold:canceller:error:
wasSignalled
domain
identifyConflictingL0Clusters:csnToRejectedPersonForNewlyClusteredFaces:csnToConfirmedPersonForNewlyClusteredFaces:
l1ClusteredFaceIdsGroupedByL0ClustersForClustersContainingFaceIds:error:
_resolveConflictingL0ClustersFromVNClusters:excludedL0ClustersByL1ClusterId:cancelOrExtendTimeoutBlock:
usesCPUOnly
_propertyDictionaryFileURL
initWithContentsOfURL:
dateWithTimeIntervalSinceReferenceDate:
writeToURL:atomically:
clusteredFaceIdsForClusterContainingFaceId:error:
distanceBetweenClustersWithFaceId:andFaceId:error:
distanceBetweenLevel1Clusters:error:
distanceBetweenLevel0ClusterIdentifiedByFaceCSN:andLevel0ClusterIdentifiedByFaceCSN:error:
distancesFromClustersIdentifiedByFaceCSNs:toClustersIdentifiedByFaceCSNs:error:
initWithPhotoLibrary:andContext:
terminate
numberOfAccumulatedClusterChanges
clusteredFaceCount
clusterCount
clusterIfNecessaryAndWaitWithCancelOrExtendTimeoutBlock:
clusterAndWaitWithCancelOrExtendTimeoutBlock:
cancelClustering
status
suggestedFaceClusterSequenceNumbersForFaceClusterSequenceNumbersRepresentingClusters:error:
requestSuggestionsForFaceClusterSequenceNumbers:withClusteringFlags:updateHandler:error:
cancelSuggestionRequest:
isReadyToReturnSuggestions
differencesBetweenClusterCacheAndLibrary:excludedL0ClustersByL1ClusterId:cancelOrExtendTimeoutBlock:
getClusters:threshold:utilizingGPU:cancelOrExtendTimeoutBlock:error:
_photoLibrary
_persistenceDelegate
_processingQueue
_processingGroup
_canceled
_context
_cacheDirUrl
_cacheFileUrl
_clusteringType
_threshold
_faceCSNsInClusterCache
_nextSeqNum
_faceIdStrsToAdd
_faceCSNsToRemove
_accumulatedChangesCount
_nextClusterTriggeringAccumulatedChangesCount
_visionCanceler
_clusterBuilder
_rebuildClusterer
_outstandingSuggestionRequests
_currentSuggestionRequest
_suggestionLock
_currentStatusSnapshotLock
_currentStatusSnapshot
_currentStatusSnapshotIsValid
_propertyDictionaryLock
_propertyDictionary
_clustererBringUpState
_timestampOfLastClusterComparison
_timebase
TB,R,N
ready
TB,R,N,GisReady
TQ,N,V_clustererBringUpState
TQ,R,N
URLByAppendingPathExtension:
initWithOptions:
initWithKeypointsOption:aspectRatio:lightweight:forceCPU:sharedModel:flushModel:
preferredInputFormat:height:format:
setLocation:
setKeypoints:
parseResults:observations:
updateWithOptions:error:
updateModelForAspectRatio:
processImage:withOptions:error:
preferredInputSizeWithOptions:error:
cleanupWithOptions:error:
_analyzer
_preferredWidth
_preferredHeight
_preferredFormat
highlightScore
setHighlightScore:
_highlightScore
Tf,N,V_highlightScore
identifier
resolution
orientation
isHighResDecoded
initWithImageAsset:requestHandler:regionOfInterest:
matchesImageAsset:
requestHandler
regionOfInterest
_identifier
_resolution
_requestHandler
_regionOfInterest
T@"VNImageRequestHandler",R,N,V_requestHandler
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,V_regionOfInterest
sharedInstanceWithIdentifier:andCreationBlock:
purge
sharedResource
activeCost
inactiveCost
maskOnly
setMaskOnly:
cachedImageHandler
setCachedImageHandler:
_maskOnly
_cachedImageHandler
TB,N,V_maskOnly
T@"VCPMADVIRemoveBackgroundCachedImageHandler",&,N,V_cachedImageHandler
initWithRequest:imageAsset:andSignpostPayload:
returnMask
cropToFit
performInPlace
isSensitive
setResults:
loadPixelBuffer:orientation:
loadHighResPixelBuffer:orientation:
setError:
imageType
isScreenshot
imageWithPixelBuffer:orientation:
initWithImage:regionOfInterest:imageType:preferredMetalDevice:
activateResource:
service
refineRegionsWithRequest:error:
reset
refinedRegions
session
initWithCVPixelBuffer:orientation:options:session:
deviceForMetalDevice:
processingDevice
setPerformInPlace:
setCropResult:
setReturnMask:
setRegionOfInterest:
pixelBuffer
croppedBoundingBox
initWithSurface:cropRect:confidence:
executionNanoseconds
setExecutionNanoseconds:
taskWithRequest:imageAsset:andSignpostPayload:
dependencies
setPreferredMetalDevice:
_request
_imageAsset
_preferredMetalDevice
_signpostPayload
_cancelQueue
_weakRequest
localizedDescription
initWithRequest:andConfiguration:
validateConfiguration:withError:
nodeWithRequest:andConfiguration:
request
timeInterval
frameInterval
_frameInterval
_timeInterval
T@"VNRequest",R,N,V_request
T{?=qiIq},R,N,V_timeInterval
TQ,R,N,V_frameInterval
resize:height:
initWithPixelFormat:
convertImage:yuvFrame:
_pixelFormat
_width
_height
_rgbColorSpace
_cgContext
_rgbFrame
_yuvFrames
_rgbToYuv
databaseForPhotoLibrary:
boolValue
initWithAssets:analysisTypes:options:progressHandler:andCompletionHandler:
queryAnalysisForAsset:withTypes:
isAssetBlacklisted:blacklistDate:
vcp_version
vcp_dateModified
vcp_modificationDate
isEqualToDate:
vcp_degraded
vcp_allAcceptableResourcesForAsset:
mediaType
canAnalyzeUndegraded:withResources:
vcp_types
analyzeOndemand:forAnalysisTypes:withExistingAnalysis:error:
isPhoto
initWithPHAsset:withExistingAnalysis:forAnalysisTypes:
analyzeAsset:withOptions:
isVideo
analyzeAsset:streamed:
requestAnalysis:forAsset:andDatabase:error:
vcp_results
main
taskWithAsset:andAnalysisTypes:andOptions:andProgressHandler:andCompletionHandler:
_assets
_database
_allowOnDemand
_analysisTypes
_options
requestMediaAnalysisDatabaseAccessSandboxExtensionWithPhotoLibraryURL:andReply:
requestImageProcessing:forIOSurface:withOrientation:identifier:requestID:andReply:
requestImageProcessing:forAssetURL:withSandboxToken:identifier:requestID:andReply:
requestImageProcessing:forImageData:withUniformTypeIdentifier:identifier:requestID:andReply:
requestImageProcessing:forAssetWithIdentifier:identifierType:fromPhotoLibraryWithURL:requestID:andReply:
requestImageProcessing:forIOSurface:withOrientation:assetLocalIdentifier:photoLibraryURL:requestID:andReply:
requestImageProcessing:forAssetWithCloudIdentifier:requestID:andReply:
requestImageProcessingWithCloudIdentifierRequests:requestID:andReply:
queryPerformanceMeasurementsWithReply:
resetPerformanceMeasurements
startEntryPointWithQueryID:
cacheHitWithQueryID:cachedResultQueryID:
endEntryPoint
requestURLAssetAnalysis:forAssetWithResourcePaths:withOptions:analysisTypes:sandboxTokens:withReply:
requestAssetAnalysis:forLocalIdentifiers:fromPhotoLibraryWithURL:withOptions:analysisTypes:withReply:
requestAssetAnalysis:forPhotoLibraryURL:withLocalIdentifiers:realTime:withReply:
requestLibraryProcessing:withTaskID:forPhotoLibraryURL:withOptions:andReply:
requestAssetProcessing:withTaskID:forLocalIdentifiers:fromPhotoLibraryWithURL:withOptions:andReply:
requestWallpaperUpgrade:atSourceURL:toDestinationURL:withOptions:sandboxTokens:andReply:
cancelRequest:
cancelAllRequests
cancelBackgroundActivityWithReply:
currentOutstandingTasksWithReply:
notifyLibraryAvailableAtURL:
requestSuggestedPersons:withPersonWithLocalIdentifier:toBeConfirmedPersonSuggestions:toBeRejectedPersonSuggestions:andPhotoLibraryURL:andReply:
requestUpdateKeyFacesOfPersons:withLocalIdentifiers:andForceUpdate:andPhotoLibraryURL:andReply:
requestFaceCandidatesforKeyFace:withPersonsWithLocalIdentifiers:andPhotoLibraryURL:andReply:
requestResetFaceClassificationModel:withPhotoLibraryURL:andReply:
requestResetPetClassificationModel:withPhotoLibraryURL:andReply:
requestSuggestedMePersonIdentifier:withContext:andPhotoLibraryURL:andReply:
requestPersonPromoterStatus:withAdvancedFlag:andPhotoLibraryURL:andReply:
requestClusterCacheValidation:withPhotoLibraryURL:andReply:
requestResetFaceClusteringState:withPhotoLibraryURL:andReply:
requestReclusterFaces:withPhotoLibraryURL:andReply:
requestRebuildPersons:withLocalIdentifiers:andPhotoLibraryURL:andReply:
requestPersonPreferenceForPhotoLibraryURL:andReply:
requestVIPModelStorageFilepathForPhotoLibraryURL:forModelType:andReply:
queryAutoCounterOptInStatus:withPhotoLibraryURL:personLocalIdentifiers:andReply:
requestOptInAutoCounter:withPhotoLibraryURL:persons:andReply:
requestDumpAutoCounter:withPhotoLibraryURL:andReply:
requestAutoCounterAccuracyCalculation:withPhotoLibraryURL:andReply:
requestAutoCounterAccuracyCalculation:withPhotoLibraryURL:clusterStateURL:groundTruthURL:andReply:
requestAutoCounterSIMLValidation:withPhotoLibraryURL:simlGroundTruthURL:andReply:
requestIdentificationOfFacesWithLocalIdentifiers:fromPhotoLibraryWithURL:withRequestID:andReply:
requestProcessingTypes:forAssetsWithLocalIdentifiers:fromPhotoLibraryWithURL:withRequestID:andReply:
interfaceWithProtocol:
setClasses:forSelector:argumentIndex:ofReply:
initWithMachServiceName:options:
setExportedObject:
setRemoteObjectInterface:
reportProgress:forRequest:
setExportedInterface:
setInterruptionHandler:
setInvalidationHandler:
resume
taskForURLAsset:withOptions:analysisTypes:progressHandler:completionHandler:
UTF8String
stringWithUTF8String:
connection
remoteObjectProxyWithErrorHandler:
errorWithDescription:
vcp_defaultURL
requestBackgroundAnalysisForAssets:fromPhotoLibraryWithURL:realTime:progessHandler:completionHandler:
requestProcessingWithTaskID:forPhotoLibrary:withOptions:progessHandler:andCompletionHandler:
requestProcessingWithTaskID:forAssets:withOptions:progressHandler:andCompletionHandler:
taskWithAssets:options:andCompletionHandler:
taskWithAssets:andOptions:andCompletionHandler:
synchronousRemoteObjectProxyWithErrorHandler:
invalidate
queryProgress:forPhotoLibrary:andTaskID:withExtendTimeoutBlock:
queryCachedFaceAnalysisProgress:forPhotoLibrary:withExtendTimeoutBlock:
queryProgressDetail:forPhotoLibrary:andTaskID:withExtendTimeoutBlock:
isMultiLibraryModeEnabled
initWithPhotoLibraryURL:
vcp_defaultPhotoLibrary
sharedAnalysisService
analysisService
queryProgress:forPhotoLibrary:andTaskID:
queryCachedFaceAnalysisProgress:forPhotoLibrary:
queryProgressDetail:forPhotoLibrary:andTaskID:
queryProgressDetail:forPhotoLibraryURL:andTaskID:
queryProgressDetail:forPhotoLibraryURL:andTaskID:withExtendTimeoutBlock:
requestAnalysisTypes:forAssetWithResourceURLs:withOptions:progressHandler:andCompletionHandler:
requestAnalysisTypes:forAssets:withOptions:progressHandler:andCompletionHandler:
requestBackgroundAnalysisForAssets:realTime:progessHandler:completionHandler:
requestBackgroundProcessingWithTaskID:forPhotoLibrary:progessHandler:completionHandler:
requestSceneProcessingForPhotoLibrary:withOptions:progressHandler:andCompletionHandler:
requestFaceProcessingForPhotoLibrary:withOptions:progressHandler:andCompletionHandler:
requestMultiWorkerProcessingForPhotoLibrary:withOptions:progressHandler:andCompletionHandler:
requestFullProcessingForPhotoLibrary:withOptions:progressHandler:andCompletionHandler:
requestLivePhotoEffectsForAssets:withOptions:progressHandler:andCompletionHandler:
requestSceneProcessingForAssets:withOptions:progressHandler:andCompletionHandler:
requestFaceProcessingForAssets:withOptions:progressHandler:andCompletionHandler:
requestQuickFaceIdentificationForPhotoLibraryURL:withOptions:andCompletionHandler:
requestSceneprintProcessingForAssets:withOptions:progressHandler:andCompletionHandler:
requestVideoStabilizationForAssets:withOptions:progressHandler:andCompletionHandler:
cancelBackgroundActivity
requestPersonPreferenceForPhotoLibraryURL:completionHandler:
requestVIPModelFilepathForPhotoLibraryURL:forModelType:completionHandler:
_connection
_managementQueue
_handlerQueue
_progressBlocks
_nextRequestID
requestSuggestedPersonsForPersonWithLocalIdentifier:toBeConfirmedPersonSuggestions:toBeRejectedPersonSuggestions:photoLibraryURL:progessHandler:completionHandler:
requestUpdateKeyFacesOfPersonsWithLocalIdentifiers:forceUpdate:photoLibraryURL:progessHandler:completionHandler:
requestFaceCandidatesforKeyFaceForPersonsWithLocalIdentifiers:photoLibraryURL:progessHandler:completionHandler:
requestResetFaceClassificationModelForPhotoLibraryURL:progressHandler:completionHandler:
requestResetPetClassificationModelForPhotoLibraryURL:progressHandler:completionHandler:
requestSuggestedMePersonIdentifierWithContext:photoLibraryURL:progressHandler:completionHandler:
requestPersonPromoterStatusWithAdvancedFlag:photoLibraryURL:progressHandler:completionHandler:
requestPersonProcessingForPhotoLibraryURL:options:progressHandler:completionHandler:
requestClusterCacheValidationWithPhotoLibraryURL:progressHandler:completionHandler:
requestResetFaceClusteringStateWithPhotoLibraryURL:progressHandler:completionHandler:
requestReclusterFacesWithPhotoLibraryURL:progressHandler:completionHandler:
requestRebuildPersonsWithLocalIdentifiers:photoLibraryURL:progressHandler:completionHandler:
queryAutoCounterOptInStatusForPhotoLibraryURL:withPersonLocalIdentifiers:completionHandler:
requestOptInAutoCounterForPhotoLibraryURL:withPersons:completionHandler:
requestDumpAutoCounterForPhotoLibraryURL:completionHandler:
requestAutoCounterAccuracyCalculationForPhotoLibraryURL:completionHandler:
requestAutoCounterAccuracyCalculationForPhotoLibraryURL:clusterStateURL:groundTruthURL:completionHandler:
requestAutoCounterSIMLValidationForPhotoLibraryURL:simlGroundTruthURL:completionHandler:
requestIdentificationOfFaces:withCompletionHandler:
requestProcessingTypes:forAssetsWithLocalIdentifiers:fromPhotoLibraryWithURL:progressHandler:completionHandler:
dataWithContentsOfURL:
JSONObjectWithData:options:error:
initWithModelPath:
embeddingHeight
embeddingWidth
embeddingChannels
embeddingSequenceLength
videoEmbedding
_outputNames
_forceNNGraph
_embeddingHeight
_embeddingWidth
_embeddingChannels
_embeddingSequenceLength
_videoEmbedding
Ti,R,V_embeddingHeight
Ti,R,V_embeddingWidth
Ti,R,V_embeddingChannels
Ti,R,V_embeddingSequenceLength
T^f,R,V_videoEmbedding
keypointsFromTensor:width:height:channels:withOptions:results:
setObject:atIndexedSubscript:
keypointsToObservation:
keypointsFromTensor:withOptions:results:
requiredInputFormat:height:format:
processFrame:withOptions:results:
_heatmapNms
_revision
_modelOutput16bit
_modelOutputSize
_loadModel
_plan
_ctx
_net
_outputBlob
setValue:
setTimescale:
setEpoch:
timescale
epoch
copyImage:toData:withChannels:
setFlag:
flag
computeIntersectionOverUnion:
initWithCenterAndSize:y:width:height:confidence:
postProcBoxes:maxNumRegions:
nonMaxSuppression:
removeLastObject
createModel:srcWidth:
getInputBuffer:srcWidth:cnnInputHeight:cnnInputWidth:
createInput:withBuffer:cnnInputHeight:cnnInputWidth:
generatePetsBoxes:faceBoxes:cancel:
getCGRectWithClipWidth:height:
detector:
generatePetsRegions:outHeight:outWidth:boxes:faceBoxes:maxNumRegions:
petsDetection:petsRegions:petsFaceRegions:cancel:
initWithOptions:error:
handler
_queue
_handler
processIdentifier
logMemoryWithMessage:
stagedText
conversationIdentifier
classifyPixelBuffer:stagedText:inConversationWithIdentifier:error:
initWithIsSensitive:andAttributes:
getInputBuffer
computeSmileScore:
initWithLocalIdentifier:
faceWithLocalIdentifier:
setSourceWidth:
setSourceHeight:
setManual:
setAlgorithmVersion:
setDetectionType:
uuid
faceJunkinessIndex
torsoprint
wrapperWithImageprintType:version:andData:
setImageprintWrapper:
setBodyWidth:
setBodyHeight:
setBodyCenterX:
setBodyCenterY:
setCenterAndSizeFromNormalizedFaceRect:
roll
setRoll:
faceCaptureQuality
setQuality:
setPoseYaw:
expressionsAndConfidence
setHasSmile:
faceAttributes
ageCategory
label
mad_PHValueFromVNAgeCategoryLabel:
setAgeType:
VN7exwFFmQF0AI9P7FjBljwEFu7QYUGCYE
mad_PHValueFromVNSexCategoryLabel:
setSexType:
eyesCategory
mad_PHValueFromVNEyesCategoryLabel:
setEyesState:
smilingCategory
mad_PHValueFromVNSmilingCategoryLabel:
setSmileType:
faceHairCategory
mad_PHValueFromVNFaceHairCategoryLabel:
setFacialHairType:
hairColorCategory
mad_PHValueFromVNHairColorCategoryLabel:
setHairColorType:
glassesCategory
mad_PHValueFromVNGlassesCategoryLabel:
setGlassesType:
VN4UfLbvVUqMvYV8bbGFQcxg5yRLm8ekI1
mad_PHValueFromVNExpressionCategoryLabel:
setExpressionType:
VN7fiLHgGnvqPqG63cfDUCK4Xm8obUuWoP
mad_PHValueFromVNHeadgearCategoryLabel:
setHeadgearType:
VN2riiZbQrloRhCzYW56f0rk4N3ROe151S
mad_PHValueFromVNFaceHairCategoryV2Label:
setHairType:
VNpLorzxnyAlLcPFNcKhgoNCmy9b5BRWyk
mad_PHValueFromVNPoseCategoryLabel:
setPoseType:
VN3iT1YRjjnIuELobV1olJiO1vvItN6Kdq
mad_PHValueFromVNSkintoneCategoryLabel:
setSkintoneType:
VN1uMyFtnYEWjbrdx3yAuDndKkPeyzNJhB
mad_PHValueFromVNEthnicityCategoryLabel:
setEthnicityType:
eyesState
setIsLeftEyeClosed:
setIsRightEyeClosed:
gaze
gazeMask
setHasFaceMask:
direction
mad_PHValueFromVNFaceGazeDirection:
setGazeType:
location
setGazeCenterX:
setGazeCenterY:
hasFaceMask
mad_VNFaceGazeDirectionDescription:
gazeType
mad_PHFaceGazeTypeDescription:
gazeCenterX
gazeCenterY
_calculateOverlappingBetweenFaceObservation:andHumanObservation:
faceFromFaceObservation:humanObservation:sourceWidth:sourceHeight:visionRequests:processingVersion:force:andError:
setIsTooSmall:
setBlurScore:
qualityMeasureWithCountOfFacesOnAsset:
_isColocatingAnimalObservation:withFaceObservations:orTorsoObservations:
labels
animalprint
setPersonLocalIdentifier:
detectionType
sourceWidth
sourceHeight
setCenterX:
setCenterY:
setSize:
bodyCenterX
bodyCenterY
bodyWidth
bodyHeight
hasSmile
blurScore
isLeftEyeClosed
isRightEyeClosed
faceAlgorithmVersion
quality
isHidden
setHidden:
isInTrash
setIsInTrash:
manual
adjustmentVersion
setAdjustmentVersion:
nameSource
setNameSource:
trainingType
setTrainingType:
faceprintVersion
groupingIdentifier
setGroupingIdentifier:
faceFromPHFace:copyOption:
algorithmVersion
isTooSmall
sexType
smileType
facialHairType
hairColorType
glassesType
expressionType
headgearType
hairType
skintoneType
ethnicityType
version
_calculateIoUBetweenObservation:andObservation:
facesFromFaceObservations:humanObservations:animalObservations:sourceWidth:sourceHeight:visionRequests:blurScorePerFace:exposureScorePerFace:tooSmallFaceObservations:processingVersion:
facesFromPHFetchResult:copyOption:
photosFaceRepresentationSourceWidth
photosFaceRepresentationSourceHeight
photosFaceRepresentationCenterX
photosFaceRepresentationCenterY
photosFaceRepresentationSize
photosFaceRepresentationBlurScore
photosFaceRepresentationHasSmile
photosFaceRepresentationIsLeftEyeClosed
photosFaceRepresentationIsRightEyeClosed
photosFaceRepresentationQualityMeasure
photosFaceRepresentationClusterSequenceNumber
photosFaceRepresentationLocalIdentifier
photosFaceRepresentationRoll
replaceCoordinatesAndFeaturesFromDetectedFace:
normalizedFaceRect
gist
photosFaceRepresentationQuality
hidden
_hidden
_isInTrash
_manual
_isTooSmall
_hasSmile
_isLeftEyeClosed
_isRightEyeClosed
_hasFaceMask
_detectionType
_ageType
_sexType
_eyesState
_smileType
_facialHairType
_hairColorType
_glassesType
_expressionType
_headgearType
_hairType
_poseType
_skintoneType
_ethnicityType
_gazeType
_trainingType
_localIdentifier
_personLocalIdentifier
_sourceWidth
_sourceHeight
_centerX
_centerY
_size
_bodyCenterX
_bodyCenterY
_bodyWidth
_bodyHeight
_blurScore
_adjustmentVersion
_nameSource
_poseYaw
_algorithmVersion
_clusterSequenceNumber
_qualityMeasure
_gazeCenterX
_gazeCenterY
_groupingIdentifier
_imageprintWrapper
_roll
T@"NSString",R,C,N,V_localIdentifier
T@"NSString",C,N,V_personLocalIdentifier
Tq,N,V_sourceWidth
Tq,N,V_sourceHeight
Ts,N,V_detectionType
Td,N,V_centerX
Td,N,V_centerY
Td,N,V_size
Td,N,V_bodyCenterX
Td,N,V_bodyCenterY
Td,N,V_bodyWidth
Td,N,V_bodyHeight
TB,N,V_hidden
TB,N,V_isInTrash
TB,N,V_manual
TB,N,V_isTooSmall
TB,N,V_hasSmile
Td,N,V_blurScore
Td,N,V_exposureScore
TB,N,V_isLeftEyeClosed
TB,N,V_isRightEyeClosed
T@"NSString",C,N,V_adjustmentVersion
Tq,N,V_nameSource
Ti,N,V_trainingType
Td,N,V_poseYaw
TQ,N,V_algorithmVersion
Tq,N,V_clusterSequenceNumber
Tq,N,V_qualityMeasure
TS,N,V_ageType
TS,N,V_sexType
TS,N,V_eyesState
TS,N,V_smileType
TS,N,V_facialHairType
TS,N,V_hairColorType
TS,N,V_glassesType
TS,N,V_expressionType
TS,N,V_headgearType
TS,N,V_hairType
TS,N,V_poseType
TS,N,V_skintoneType
TS,N,V_ethnicityType
TB,N,V_hasFaceMask
TS,N,V_gazeType
Td,N,V_gazeCenterX
Td,N,V_gazeCenterY
T@"NSString",C,N,V_groupingIdentifier
T@"VCPVNImageprintWrapper",&,N,V_imageprintWrapper
Td,N,V_roll
Td,N,V_quality
createContextWithForceCPU
createContextWithMPSGraph
createContextPreferred
sharedContextWithForceCPU:
sharedContextWithMPSGraph:
sharedContextPreferred:
supportGPU
initWithForceCPU:forceNNGraph:shared:
espressoContext
_espressoContext
T^v,R,N,V_espressoContext
_bounds
T@"VCPProtoBounds",&,N,V_bounds
sharedModel:
normalization:
softmax
computePoseScore:
outputBeforeTemporalPooling
_results
numOfFrames
score
numOfValidFrames
sumOfScore
curationScore
initWithTimestamp:score:valid:
updateWithFirstFrame:score:valid:
updateSegment:score:valid:
mergeSegment:
copyFrom:
updateDuration:
trimSegment:fromStart:
isContentTooShort
setCurationScore:
_sumOfScore
_curationScore
_numOfFrames
_numOfValidFrames
T{?={?=qiIq}{?=qiIq}},N,V_timeRange
TQ,R,N,V_numOfFrames
TQ,R,N,V_numOfValidFrames
Tf,N,V_curationScore
initWithSceneId:withDuration:withConfidence:
sceneId
setSceneId:
sumConfidence
setSumConfidence:
_duration
_sumConfidence
_sceneId
T@"NSString",&,V_sceneId
Tf,V_duration
Tf,V_sumConfidence
vcp_sharedTaxonomy
mad_sceneIdFromSceneName:
stringValue
addResult:start:duration:keyIsName:
compareObjectsOfInterest:withScenes:
addAggregatedScenes:timerange:
frameScenes
sceneResults
setSceneResults:
_start
_existingScenes
_internalFrameScenes
_sceneResults
T@"NSDictionary",R
T@"NSArray",&,V_sceneResults
setFeatureBlob:
featureBlob
_featureBlob
T@"NSData",&,N,V_featureBlob
substringToIndex:
handleTimerEvent
initWithIntervalNanoseconds:isOneShot:andBlock:
timerWithInterval:unit:oneShot:andBlock:
destroy
timerWithIntervalSeconds:isOneShot:andBlock:
_source
_active
_isOneShot
_block
setTimeValue:
setTimeScale:
addHomographyParam:
homographyParamsCount
homographyParamAtIndex:
timeScale
addKeypoints:
keypointsCount
clearKeypoints
keypointsAtIndex:
keypointsType
keypoints
_flags
_keypoints
Ti,N,V_flags
T@"NSMutableArray",&,N,V_keypoints
setSceneprintBlob:
sceneprintBlob
_includeTorsoOnlyFaces
sharedManagerForPhotoLibrary:
currentProcessingVersion
contextWithPhotoLibrary:
setFaceClusteringThreshold:
faceClusteringJunkThreshold
setFaceClusteringJunkThreshold:
faceClusteringAgeThreshold
setFaceClusteringAgeThreshold:
faceMergeFaceprintDistanceThreshold
setFaceMergeFaceprintDistanceThreshold:
setFacePrimarySuggestionsThreshold:
minimumSuggestionSize
setMinimumSuggestionSize:
quarantineTwinsOnAssetEnabled
setQuarantineTwinsOnAssetEnabled:
setMinFaceCountToTriggerClustering:
setMaxFaceCountForClustering:
suggestionsLogEnabled
setSuggestionsLogEnabled:
setFaceClusteringDisabled:
minimumFaceGroupSizeForCreatingMergeCandidates
setMinimumFaceGroupSizeForCreatingMergeCandidates:
personBuildingDisabled
setPersonBuildingDisabled:
personBuilderMergeCandidatesDisabled
setPersonBuilderMergeCandidatesDisabled:
advancedStatusMergeCandidateLimit
setAdvancedStatusMergeCandidateLimit:
advancedStatusVerifiedPersonLimit
setAdvancedStatusVerifiedPersonLimit:
clusterIncludeTorsoOnlyFaces
setClusterIncludeTorsoOnlyFaces:
setProcessingVersion:
_quarantineTwinsOnAssetEnabled
_suggestionsLogEnabled
_faceClusteringDisabled
_personBuildingDisabled
_personBuilderMergeCandidatesDisabled
_clusterIncludeTorsoOnlyFaces
_faceClusteringThreshold
_faceClusteringJunkThreshold
_faceClusteringAgeThreshold
_faceMergeFaceprintDistanceThreshold
_facePrimarySuggestionsThreshold
_processingVersion
_minimumSuggestionSize
_minFaceCountToTriggerClustering
_maxFaceCountForClustering
_minimumFaceGroupSizeForCreatingMergeCandidates
_advancedStatusMergeCandidateLimit
_advancedStatusVerifiedPersonLimit
Tf,V_faceClusteringThreshold
Tf,V_faceClusteringJunkThreshold
Tf,V_faceClusteringAgeThreshold
Tf,V_faceMergeFaceprintDistanceThreshold
Tf,V_facePrimarySuggestionsThreshold
TQ,V_minimumSuggestionSize
TB,V_quarantineTwinsOnAssetEnabled
TQ,V_minFaceCountToTriggerClustering
TQ,V_maxFaceCountForClustering
TB,V_suggestionsLogEnabled
TB,V_faceClusteringDisabled
TQ,V_minimumFaceGroupSizeForCreatingMergeCandidates
TB,V_personBuildingDisabled
TB,V_personBuilderMergeCandidatesDisabled
TQ,V_advancedStatusMergeCandidateLimit
TQ,V_advancedStatusVerifiedPersonLimit
TB,V_clusterIncludeTorsoOnlyFaces
Ti,V_processingVersion
_vnFaceAttributeAgeToPHFaceAgeTypeMap
valueForKey:
_vnFaceAttributeSexToPHFaceSexTypeMap
_vnFaceAttributeEyesToPHEyesStateMap
_vnFaceAttributeSmileToPHFaceSmileTypeMap
_vnFaceAttributeFacialHairToPHFacialHairTypeMap
_vnFaceAttributeHairColorToPHFaceHairColorTypeMap
_vnFaceAttributeGlassesToPHFaceGlassesTypeMap
_vnFaceAttributeFacialHairToPHFaceExpressionType
_vnFaceAttributeHeadGearToPHFaceHeadGearType
_vnFaceAttributeHairTypeToPHFaceHairType
_vnFaceAttributePoseToPHFacePoseType
_vnFaceAttributeSkintoneToPHFaceSkintoneType
_vnFaceAttributeEthnicityToPHFaceEthnicityType
_vnFaceGazeDirectionToPHFaceGazeType
setLeftEyeClosed:
setRightEyeClosed:
setFaceAlgorithmVersion:
setFaceExpressionType:
setInTrash:
initWithFaceprintData:faceprintVersion:
setFaceprint:
_firstLocallyAvailableResourceFromResources:
pixelWidth
pixelHeight
vcp_uniformTypeIdentifier
canDecodeAcceleratedUniformTypeIdentifier:
vcp_descendingSizeComparator
preferredResourcesForFaceProcessingWithAsset:
resourceForFaceProcessing:allowStreaming:
setRevision:error:
configureVNRequest:withClass:andVisionRevision:
imageCreationOptions
phFacesFromVCPPhotosFaces:withFetchOptions:
assignPropertiesOfVCPPhotosFace:toPHFaceChangeRequest:
phFaceFromVCPPhotosFace:withFetchOptions:
resourceForFaceProcessingWithAsset:allowStreaming:
faceRectFromNormalizedCenterX:normalizedCenterY:normalizedSize:sourceWidth:sourceHeight:
_sceneprintBlob
T@"NSData",&,N,V_sceneprintBlob
hasFaceId
hasBounds
absoluteScore
setAbsoluteScore:
relativeScore
setRelativeScore:
humanScore
setHumanScore:
faceId
_absoluteScore
_faceId
_humanScore
_relativeScore
Tf,N,V_absoluteScore
Tf,N,V_relativeScore
Tf,N,V_humanScore
T@"NSString",&,N,V_faceId
setX0:
setY0:
setWidth:
setHeight:
width
height
setGyroStabilization:
valueWithCMTime:
setAnalysisResultRef:
analysisResultRef
setAnalysisConfidence:
analysisConfidence
setValidStabilization:
convertAnalysisResult
_analysisSessionRef
supportVectorForward
initWithParameters:useGPU:
convBlockWithFilterSize:filterNum:chunk:reLU:padding:
add:
poolingBlockWithPoolX:poolY:chunk:
initWithParameters:
fcBlockWithNumNeurons:NeuronType:
getGPUContext
cnnDataWithPlane:height:width:context:
prepareNetworkFromURL:withInputSize:
copyBlock:withStride:toBlock:
forward:
output
blockContentDetection:
contentAnalysis
detectPixelBuffer:contentType:
_input
_previousContentType
_argbPixelBuffer
_argbTransferSession
cameraMotionDetection:
computeMotionDivScore:
generateThresholds:withConfidences:
autoLiveMotionScore:
initWithQueue:turbo:
prewarmWithWidth:height:
analyzeFrame:withTimestamp:andDuration:completion:
motionDivScore
_frame
_stats
_cameraMotionParams
_cameraMotionConfidences
_turbo
_motionDivScore
Tf,R,V_actionScore
Tf,R,V_motionDivScore
returnObject:
initWithObject:fromPool:
object
_object
_pool
T@,R,N,V_object
initWithAllocator:
objectPoolWithAllocator:
getObject
_allocator
_objects
readWeightsBias:weights:bias:inputDim:outputDim:quantFactor:
forward
loadWeights:inputDim:outputDim:quantFactor:
setActivityScore:
activityScore
isEqualToValue:
unsignedIntValue
vcp_idealDimension
gatherAvailableRequests
_cachedRequestIdealDimension
revision
includeNSFW
includeLM
includeSE
includeSDG
includeWP
includeDO
includeSO
includeMeme
includeRotation
includeDocument
includeIVS
includePA
includeCN
includeJunk
includeDMF
sharpnessRevision
isDimensionUnknown:
mapAvailableRequestsToResolution
aestheticsRequest
setAestheticsRequest:
classificationRequest
setClassificationRequest:
sceneprintRequest
setSceneprintRequest:
saliencyRequest
setSaliencyRequest:
junkImageRequest
setJunkImageRequest:
objectRequest
setObjectRequest:
saliencyObjectnessRequest
setSaliencyObjectnessRequest:
landmarkRequest
setLandmarkRequest:
nsfwRequest
setNsfwRequest:
tabooRequest
setTabooRequest:
semanticRequest
setSemanticRequest:
sceneprintRawRequest
setSceneprintRawRequest:
memeRequest
setMemeRequest:
adjustmentsRequest
setAdjustmentsRequest:
documentRequest
setDocumentRequest:
cityNatureRequest
setCityNatureRequest:
imagefingerprintsRequest
setImagefingerprintsRequest:
_aestheticsRequest
_classificationRequest
_sceneprintRequest
_saliencyRequest
_junkImageRequest
_objectRequest
_saliencyObjectnessRequest
_landmarkRequest
_nsfwRequest
_tabooRequest
_semanticRequest
_sceneprintRawRequest
_memeRequest
_adjustmentsRequest
_documentRequest
_cityNatureRequest
_imagefingerprintsRequest
T@"VNClassifyImageAestheticsRequest",&,N,V_aestheticsRequest
T@"VNSceneClassificationRequest",&,N,V_classificationRequest
T@"VNCreateSceneprintRequest",&,N,V_sceneprintRequest
T@"VNGenerateAttentionBasedSaliencyImageRequest",&,N,V_saliencyRequest
T@"VNClassifyJunkImageRequest",&,N,V_junkImageRequest
T@"VNRecognizeObjectsRequest",&,N,V_objectRequest
T@"VNGenerateObjectnessBasedSaliencyImageRequest",&,N,V_saliencyObjectnessRequest
T@"VNClassifyPotentialLandmarkRequest",&,N,V_landmarkRequest
T@"VNVYvzEtX1JlUdu8xx5qhDI",&,N,V_nsfwRequest
T@"VN6Mb1ME89lyW3HpahkEygIG",&,N,V_tabooRequest
T@"VN5kJNH3eYuyaLxNpZr5Z7zi",&,N,V_semanticRequest
T@"VNCreateSceneprintRequest",&,N,V_sceneprintRawRequest
T@"VNClassifyMemeImageRequest",&,N,V_memeRequest
T@"VN1JC7R3k4455fKQz0dY1VhQ",&,N,V_adjustmentsRequest
T@"VNRecognizeDocumentElementsRequest",&,N,V_documentRequest
T@"VNClassifyCityNatureImageRequest",&,N,V_cityNatureRequest
T@"VNCreateImageFingerprintsRequest",&,N,V_imagefingerprintsRequest
setHasFaceQuality:
_eyeExpression
_faceQuality
_mouthExpression
_position
_yaw
_isCloseup
Ti,N,V_eyeExpression
Ti,N,V_mouthExpression
Ti,N,V_yaw
Ti,N,V_position
TB,N,V_isCloseup
Tf,N,V_faceQuality
stabilityScore
resetSegment:atTime:
decideSegmentPointBasedOn:
finalizeAtTime:
initWithAbsMotion:atTime:
updateSegment:atTime:
mergeSimilarSegments
absMotion
processFrameMetadata:
_hinkleyDetector
_activeSegment
_mutableResults
_internalResults
_frameTimeRange
T@"NSArray",R,&,N
resetSegment:
updateSegment:
setAbsMotion:
setStabilityScore:
_absMotion
_stabilityScore
Tf,V_absMotion
Tf,V_stabilityScore
_service
T@"VIService",R,N
T@"VCPProtoTime",&,N,V_timestamp
bundleWithIdentifier:
absoluteString
getPlanPhase
prepareModelInput:
prepareModelInputs:
numberWithUnsignedLong:
espressoForwardInputs:
getEspressoContext
inputBlobs
setInputBlobs:
outputBlobs
setOutputBlobs:
setInputBlob:
setOutputBlob:
resConfig
_netFileUrl
_inputNames
_inputBlobs
_outputBlobs
_inputBlob
T{vector<espresso_buffer_t, std::allocator<espresso_buffer_t>>=^{?}^{?}{__compressed_pair<espresso_buffer_t *, std::allocator<espresso_buffer_t>>=^{?}}},N,V_inputBlobs
T{vector<espresso_buffer_t, std::allocator<espresso_buffer_t>>=^{?}^{?}{__compressed_pair<espresso_buffer_t *, std::allocator<espresso_buffer_t>>=^{?}}},N,V_outputBlobs
T{?=^v^v[4Q][4Q]QQQQQQQQQQi},N,V_inputBlob
T{?=^v^v[4Q][4Q]QQQQQQQQQQi},N,V_outputBlob
T@"NSString",R,N,V_resConfig
sharedModelPool
createModel
descriptorData
analyzeWithSceneprint:results:cancel:
_inputsData
vcp_isMercuryBase64
characterSetWithCharactersInString:
rangeOfCharacterFromSet:options:
stringByReplacingOccurrencesOfString:withString:options:range:
stringByAppendingString:
initWithBase64EncodedString:options:
initWithUUIDBytes:
localIdentifierWithUUID:
vcp_mercuryBase64ToLocalIdentifier
sharedDatabaseManager
sharedDatabaseForPhotoLibrary:
_databases
noiseReduction:sigma:imageFiltered:
gradientEstimation:width:height:gradient:gradientMag:
isInImage:width:height:
initWithImage:edgeMap:width:height:widthExtension:heightExtension:
detectWithSigma:lowThreshold:highThreshold:
_widthPadded
_heightPadded
_widthExt
_heightExt
_gradient
_image
_imageFiltered
_nonMaxSuppressed
_gradientX
_gradientY
_gradientMag
_edgeMap
setExposure:
setUnderExpose:
hasUnderExpose
exposure
underExpose
fileURLWithPath:isDirectory:
URLByAppendingPathComponent:isDirectory:
configInputBasedOnDevice
mode
startCatalogDownload:then:
initWithType:
queryMetaDataSync
setAllowsCellularAccess:
setDiscretionary:
setTimeoutIntervalForResource:
attributes
state
assetId
spaceCheck:
totalWritten
totalExpected
attachProgressCallBack:
startDownload:completionWithError:
videoCaptionDecoderTestURL
modelURLForType:timeout:
cloneCaptionModel:to:
videoCaptionEncoderTestURL
getLocalUrl
dataWithBytes:length:
generateCaption:error:
inference:duration:
imageCaptionModelTestURL
initWithFrameRate:timeRange:
downloadVideoCaptionEncoderIfNeeded
_inputNumFrames
_skipNumFramesBothEnds
_frameIndex
_videoCaptionResult
_activeFrameIndices
_videoCaptionDecoder
_videoCaptionEncoder
_downloadGroup
_videoCaptionEncoderAsset
initWithTrack:
asset
assetReaderWithAsset:error:
assetReaderSampleReferenceOutputWithTrack:
addOutput:
startReading
cancelReading
copyNextSampleBuffer
settings
assetReaderTrackOutputWithTrack:outputSettings:
setAppliesPreferredTrackTransform:
canAddOutput:
findNextSample:timerange:
decodeSample:sample:
decodeTask
initWithTrack:timerange:
_assetReader
_trackReader
_timerange
_launchOnce
_group
_inputSemaphore
_outputSemaphore
_cancelDecode
_decodeError
_decodeFinished
_decodedFrames
_outputFrameIdx
_sampleBuffer
addClassification:
classificationsCount
clearClassifications
classificationAtIndex:
classificationType
classifications
setClassifications:
_classifications
T@"NSMutableArray",&,N,V_classifications
initWithImageprintType:version:andData:
isValidTorsoprint
isValidFaceprint
stringWithString:
appendFormat:
calculateDistance:toWrapper:andError:
_version
_data
TQ,R,N,V_type
Ti,R,N,V_version
T@"NSData",R,N,V_data
initWithFaceResults:sdof:
initWithLivePhoto:
setKeyFrameTime:isHeadingFrame:
prepareFrameStats:
statsFlags
computeSharpnessOfFrame:
isLivePhotoKeyFrameEnabled
computeFaceQualityOfFrame:
finalizeKeyFrame
loadKeyFrameResult:timestamp:
adjustScoreByFace
modulateByJunk
modulateByTimeRange
analyzeDetectedFaces:faceResults:cancel:
faceQualityScores
setFaceQualityScores:
setBlurAnalyzerFaceResults:
setFaceSharpness:
setStatsFlags:
computeCurationScore
frameResults
hasGoodSubjectAction
setScore:
setIsHeadingFrame:
resetStatsFlag
loadKeyFrameResults:
frameProcessedByFaceDetector
setFaceStatsFlag:detectedFaces:
frameProcessedByVideoAnalyzer
cameraMotionScore
subjectActionScore
colorfulnessScore
frameProcessedByHumanAnalyzer
humanPoseScore
humanActionScore
subMbMotionAvailable
setMotionStatsFlag:cameraMotion:subjectAction:interestingness:obstruction:colorfulness:exposureScore:humanActionStatsFlag:humanPoseScore:humanActionScore:subMb:
initWithTransform:timeRange:isLivePhoto:frameStats:keyFrameResults:
keyFrameScores
analyzeFrame:withTimestamp:
preparePostProcessingStatsFromFaceRange:junkResults:
postProcess
keyFrames
modulateByExposure
computeMinDistanceBetween:withSet:
_blurAnalyzer
_faceQualityAnalyzer
_junkResults
_keyFrames
_activeKeyFrame
_isLivePhoto
_keyFrameScores
_inputKeyFrameResults
T{?={?=qiIq}{?=qiIq}},R,N,V_timeRange
resetSharedInstanceWithIdentifier:
serialQueue_
sharedInstances_
initWithAsset:error:
assetReaderOutputMetadataAdaptorWithAssetReaderTrackOutput:
nextTimedMetadataGroup
copyNextMetadataGroup
_reader
_readerOutput
_readerOutputAdaptor
queryAnalysisPropertiesForAssets:
vcp_fullAnalysisTypes
faceAdjustmentVersion
vcp_needSceneProcessing
vcp_needsOCRProcessing
vcp_needsVisualSearchProcessing
_countFaceAnalysisWithAssetBatch:
_countSceneAnalysisWithAssetBatch:
_countOCRAnalysisWithAssetBatch:
_countVisualSearchAnalysisWithAssetBatch:
_countEmbeddingAnalysisWithAssetBatch:
blacklistedLocalIdentifiersFromAssets:
queryFailedProcessingStatusFromAssets:forTaskID:
vcp_vipModelLastGenerationDateForVIPType:
vcp_fetchOptionsForLibrary:forTaskID:
_countFailuresWithAssetBatch:andDatabase:andTaskID:
_countMediaAnalysisWithAssetBatch:andDatabase:analyzedCount:completeAnalyzedCount:partialAnalyzedCount:
_countAnalysisWithAssetBatch:andDatabase:andTaskID:
_vipStatusForPhotoLibrary:andType:
_queryProgressDetailExpressEmbeddingAnalysis:forPhotoLibrary:
_processedPredicateForTaskID:
vcp_assetCountWithInternalPredicate:forTaskID:
countForTaskID:withProcessingStatus:
mad_prioritizedAssetsForFaceDetectionInternalPredicate
_screenProgress
_queryProgressDetailExpress:forPhotoLibrary:andTaskID:
_scanPhotoLibrary:withTaskID:statistics:andExtendTimeoutBlock:
reportProgressForPhotoLibrary:taskID:logMessage:withExtendTimeoutBlock:
isFilterSizeSupported:
initWithParameters:filterNum:chunk:reLU:padding:groups:stride:batchNorm:
readFromDisk:quantFactor:
straightForwardForChunkFour
chunkFourForward
CalculateDotProductOfChunk
initWithPlistRepresentation:
attachSalientRegions:toPixelBuffer:
plistRepresentation
analyzerWith:prune:
lostCount
isOutOfBoundary:
objectBoundsInitial
updateConfidence:prevBound:newBound:width:height:
pruneRegions:withOverlapRatio:
boundDistance:relativeTo:landscape:
_detections
_latestRegions
_saliencyAnalyer
_trackers
_confidences
_activeRegions
initWithKeypointsOption:forceCPU:sharedModel:aspectRatio:modelName:revision:
associateHands:withExisingHands:
setHandID:
handDistance:withhandB:
handID
processSampleBuffer:withOptions:error:
_handID
_existingHands
sharedModel:inputNames:
prepareModel
reInitModel
prepareWithLightweightOption:aspectRatio:forceCPU:sharedModel:flushModel:
analyzeImages:secondImage:cancel:
getFlowWithHeight:andWidth:
getFlowToBuffer:
flowScalingTo:scalerX:scalerY:
flowScalingTo:flowBufferY:scalerX:scalerY:
updateModelForAspectRatio:computationAccuracy:
_flow
_sharedModel
_flushModel
vcp_quality
analyzeImageQuality:irisPhotoOffsetSec:cancel:
Tf,R,V_qualityScore
completionHandler
initWithCMSampleBuffer:orientation:options:
shouldProcessSampleWithTimeRange:atSamplingInterval:
processSampleBuffer:withEndTime:error:
addRequest:withConfiguration:error:
removeRequest:error:
processSampleBuffer:error:
flushWithEndTime:error:
setOrientation:
_nodes
_modified
_startTime
_nextSampleBuffer
_frameCount
TI,N,V_orientation
setHasFaceSharpness:
hasFaceSharpness
faceSharpness
_faceSharpness
Tf,N,V_faceSharpness
setFaceTorsoprint:
initWithAnimalprint:confidence:
setMaximumIdentities:
setMaximumTrainingFaceprintsPerIdentity:
initWithConfiguration:
predictPersonFromFaceObservation:limit:canceller:error:
predictedPersonUniqueIdentifier
entityPredictionsForObservation:limit:canceller:error:
petClassificationThreshold
entityUniqueIdentifier
modelFromURL:options:error:
_loadModelAtPath:error:
_loadPetsModelAtPath:error:
setReadOnly:
writeToURL:options:error:
addFaceObservations:toPersonWithUniqueIdentifier:error:
personVIPModelFileName
petVIPModelFileName
faceObservationFromFaceprintData:
animalObservationFromAnimalprintData:
newMutablePersonsModel
classifyAnimalObservation:withModel:error:
persistModel:toPath:error:
persistPetsModel:toPath:error:
addFaceObservations:forPersonIdentifier:toModel:error:
prepareImage:
initWithNumberOfScales:numOfOrientations:width:height:
calculateOrientationResponses
generateOrientationMap
generateLineWeightMap:weightMap:
voteVanishingPoint:
searchVanishingPointandDominantLine:lineGroup:vanishingPoint:vanishingPointConfidence:dominantLine:
processWithFilterScaleIdx:orientIdx:srcImage:outImage:width:height:
extractUsefulAreaFrom:to:withOffset:stridePadded:width:height:
averageOrientationResponses:withCurrentMap:
smoothFiltering:width:height:
calculateConfidence:lineDistance:vaninshingPoint:vanishingPointConfidence:
isVerticalOrHorizontal:
initWithEdgeMap:mapWidth:mapHeight:angleStep:
DetectLinesWithThreshold:output:
detect:withConfidence:dominantLine:
_orientationResponses
_orientionMap
_confidenceMap
_edgeWeightMap
_stride
_stridePadded
_offset
_validDimension
_pixelMean
_pixelVar
_gaborFilter
prepareData:
detect
keypointsFromObservations:
analyzeBodyArray:
_inputChannels
_inputSize
_action
_poseRequest
_bodyArray
_valid
_keyPersonResults
initWithMaxNumRegions:prune:
copyImage:toData:withChunk:
outputScaling
computeScore:width:height:posX:posY:
prepareModelForSourceWidth:andSourceHeight:
scaleImage:toData:withWidth:andHeight:
getSalientRegions:
saliencyDetection:salientRegions:cancel:
analyzePixelBufferInTiles:results:cancel:
pruneRegions:
generateSalientRegion:outHeight:outWidth:
processTile:results:cancel:
aggregateTileResults:tileRect:imageSize:landscape:results:
_chunk
_region
_score
_maxNumRegions
_prune
vcp_mediaAnalysisDatabaseFilepath
stringByAppendingPathComponent:
vcp_mediaAnalysisDirectory
fetchAssetsWithMediaType:options:
internalPredicate
isCloudPhotoLibraryEnabled
cplStatus
lastSuccessfulSyncDate
isExceedingQuota
lastCompletePrefetchDate
vcp_isCPLEnabled
vcp_isCPLDownloadComplete
vcp_supportsInMemoryDownload
vcp_assetCountWithMediaType:forTaskID:
_analysisPreferencesURL
dictionaryWithContentsOfURL:
vcp_analysisPreferences
dataWithPropertyList:format:options:error:
_updateAnalysisPreferencesWithEntries:keysToRemove:
absoluteURL
distantPast
librarySpecificFetchOptions
setIncludeNonvisibleFaces:
mad_unclusteredFacesFetchOptions
wellKnownPhotoLibraryIdentifier
vcp_anyAssetsForTaskID:
vcp_isCPLSyncComplete
vcp_eligibleForStreaming:
vcp_allowInMemoryDownload
vcp_libraryScaleShortDescription
vcp_setAnalysisPreferencesValue:forKey:
vcp_faceAnalysisStateFilepath
mad_countOfUnclusteredFaces
vcp_requiresProcessingForTask:
vcp_requiredFaceLibraryProcessingSubTasks
vcp_description
vcp_requiresDownloadForTask:
vcp_defaultMediaAnalysisDatabaseFilepath
initWithAnalysisType:isLivePhoto:photoOffset:hadFlash:hadZoom:isTimelapse:preferredTimeRange:asset:
setMaxHighlightDuration:
motionParam
motionParamDiff
analyzeMotionStability:motionParamDiff:
postProcessKeyFrames
prepareRequiredQualityResult:junkDetectionResult:descriptorResult:faceResult:petsResult:saliencyResult:actionResult:subtleMotionResult:voiceResult:keyFrameResult:sceneResults:humanActionResults:humanPoseResults:cameraMotionResults:orientationResults:mlHighlightScoreResults:mlQualityResults:frameSize:
generateHighlights
timerange
bestPlaybackCrop
keyFrame
colorNormalization
audioQualityScore:
isTrimmed
isAutoPlayable
reportMovieCurationAnalysisResults:withSummaryAnalytics:
isSettlingOK
autoplayScore
motionScore
subjectScore
exposureChangeScore
addHighlight:to:
highlightScoreResults
movieSummary
addSummary:to:
isSettlingEffectPregatingEnabled
settlingEffects
addSettling:to:
initWithAnalysisTypes:transform:timeRange:isLivePhoto:photoOffset:frameStats:hadFlash:hadZoom:keyFrameResults:isTimelapse:preferredTimeRange:asset:
analyzeKeyFrame:withTimestamp:andDuration:flags:
loadVideoAnalysisResults:audioAnalysisResults:videoCNNResults:andFaceRanges:frameSize:
generateMovieCurations
_keyFrameAnalyzer
_highlightAnalyzer
_descriptorResults
_qualityResuls
_petsResults
_actionResults
_subtleMotionResults
_voiceResults
_audioQualityResults
_humanActionResults
_humanPoseResults
_cameraMotionResults
_saliencyResults
_orientationResults
_mlHighlightScoreResults
_mlQualityResults
_frameSize
_hadFlash
_hadZoom
averageScore
descriptor
junkScore
expressionScore
voiceScore
initWithTimeRange:
isShort
copyScoresFrom:
checkAutoPlayable
setTimerange:
setAverageScore:
setJunkScore:
setExpressionScore:
setVoiceScore:
setHumanActionScore:
setHumanPoseScore:
setBestPlaybackCrop:
setIsAutoPlayable:
setIsTrimmed:
setDescriptor:
setKeyFrame:
setColorNormalization:
setIsSettlingOK:
setAutoplayScore:
setMotionScore:
setSubjectScore:
setExposureChangeScore:
_isAutoPlayable
_isTrimmed
_isSettlingOK
_averageScore
_junkScore
_expressionScore
_voiceScore
_humanActionScore
_humanPoseScore
_autoplayScore
_motionScore
_subjectScore
_exposureChangeScore
_descriptor
_keyFrame
_colorNormalization
_bestPlaybackCrop
T{?={?=qiIq}{?=qiIq}},N,V_timerange
Tf,N,V_score
Tf,N,V_averageScore
Tf,N,V_junkScore
Tf,N,V_expressionScore
Tf,N,V_voiceScore
Tf,N,V_humanActionScore
Tf,N,V_humanPoseScore
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_bestPlaybackCrop
TB,N,V_isAutoPlayable
TB,N,V_isTrimmed
T@"VCPImageDescriptor",&,N,V_descriptor
T@"VCPVideoKeyFrame",&,N,V_keyFrame
T@"NSData",&,N,V_colorNormalization
TB,N,V_isSettlingOK
Tf,N,V_autoplayScore
Tf,N,V_motionScore
Tf,N,V_subjectScore
Tf,N,V_exposureChangeScore
createModules:
allocateInputAndOutputBuffers
initModule:config:cancel:
initWithDevice:
allocateFeatures
allocateStorages
updateModelWithConfig:error:
releaseMemory
setFeatureShape:height:width:level:
extractFeatureFromImage:toFeature:
extractFeatureFromImage:toFeature:callback:
allocateCorreleationBuffer:forLevel:
estimateFlowForLevel:upperFlow:outputFlow:
commandBuffer
encodeToCommandBuffer:input:output:flow:upscaledFlow:
encodeToCommandBuffer:firstInput:secondInput:correlation:
commit
waitUntilCompleted
arrayLength
estimateFlow:correlation:flow:outputFlow:callback:
copyImage:toBuffer:withChannels:
createInput:withImage:modelInputHeight:modelInputWidth:
extractFeaturesFromFirst:andSecond:
estimateMotionFlow:
updateModulesWithConfig:
releaseInputAndOutputBuffers
releaseFeatureBuffers
releaseStorages
prepareWithLightweightOption:aspectRatio:numLevels:startLevel:cancel:
_numLevels
_startLevel
_firstBuffer
_secondBuffer
_outputFlow
_featureExtractor
_flowDecoder
_correlation
_backwarp
_imageFeature
_storage
_flowDecoderSemaphore
distanceIdentity
clsDistanceIdentity
cloudIdentifier
filename
originalFilename
locationCoordinate
T@"NSDate",R,N
T{CLLocationCoordinate2D=dd},R,N
analyzeWithLightweightOption:aspectRatio:computationAccuracy:forceCPU:sharedModel:flushModel:cancel:
createPixelBufferWithWidth:height:pixelFormat:pixelBuffer:
cnnOutputHeight
cnnOutputWidth
setPixelBuffer:
scaleFlowTo:
convertPixelBuffer:toPixelBuffer:withPixelFormat:
guidedUpsampling:inBGRA:
initWithOptions:cancel:
estimateMotionBetweenFirstImage:andSecondImage:error:
estimateMotionBetweenFirstImage:andSecondImage:withUpsample:withGuidedImage:error:
_useSingleEspressoModel
_transferSession
arrayWithObjects:
_versionStateURL
writeToURL:error:
resetFaceAnalysisWithResetLevel:completionHandler:
_updateCurrentProcessingVersion:
resetAnalysisDataWithResetLevel:error:
resetLevelDescription:
_updateVersionStateFileWithError:
defaultProcessingVersion
migrateFaceProcessingToVersion:
_versionState
vcp_firstEnabledTrackWithMediaType:
formatDescriptions
findMetaTrackforType:
analyzerForTrackType:withTransform:requestAnalyses:formatDescription:
vcp_enabledTracksWithMediaType:
processMetaTrackForType:cancel:flags:
checkTimeRangeConsistency
postProcessOrientationResults
initWithAVAsset:forAnalysisTypes:
analyzeAsset:flags:
_requestedAnalyses
_avAsset
_metaTracks
_publicMutableResults
_privateMutableResults
T@"NSDictionary",R,N
semanticScore
isHeadingFrame
computeGlobalQuality
computeScoreFromColorfulness
computeScoreFromExposure
computeExpressionScore
computeScoreFromAction
leftEyeClosed
rightEyeClosed
computeGlobalQualityForLivePhoto
computeVisualPleasingScore
computePenaltyScore
computeContentScore
computeCurationScoreComponents
storeFrameResults
smile
printStats
setSemanticScore:
setDetectedFaces:
setFrameResults:
_subjectAction
_interestingness
_obstruction
_colorfulness
_subMb
_isHeadingFrame
_semanticScore
_statsFlags
_detectedFaces
_faceQualityScores
_frameResults
T{?=qiIq},N,V_timestamp
Tf,N,V_semanticScore
TB,N,V_isHeadingFrame
TQ,N,V_statsFlags
T@"NSMutableArray",&,N,V_detectedFaces
T@"NSMutableArray",&,N,V_faceQualityScores
T@"NSMutableDictionary",&,N,V_frameResults
sceneprints
unarchivedObjectOfClass:fromData:error:
archivedDataWithRootObject:requiringSecureCoding:error:
_sceneprint
shotType
setShotType:
_shotType
Ti,N,V_shotType
convertResultsToDict:results:
_petsDetector
vcp_taskWithImageAsset:andSignpostPayload:
rotationToEulerAngles:angles:
kalmanFiltering:T:
eulerAnglesToRotation:R:
filteringPose:
_previousState
_previousCovar
_previousStateIsValid
name
changeRequestForPerson:
setVerifiedType:
setManualOrder:
fetchKeyFaceForPerson:options:
keyFace
setKeyFace:forCluster:
addMergeCandidatePersons:
anonymizedName
favorite
setIsVerified:
setKeyFace:
pv_addMergeCandidatePersons:
personLocalIdentifiers
faceCount
verifiedType
isVerified
manualOrder
T@"<PVFaceProtocol>",&,N
TB,D,N
dataUsingEncoding:allowLossyConversion:
base64EncodedStringWithOptions:
setAutoPlayable:
setPlaybackCrop:
autoPlayable
playbackCrop
setVersion:
setMinVersion:
setAutoloop:
setBounce:
setLongexposure:
setStabilize:
setCropRectX:
setCropRectY:
setCropRectWidth:
setCropRectHeight:
setStabilizeResult:
setOutputFrameDurValue:
addFrameInstructions:
outputFrameDurValue
cropRectX
cropRectY
cropRectWidth
cropRectHeight
frameInstructionsCount
frameInstructions
exportToLegacyDictionaryFromFrameInstruction:
stabilizeResult
autoloop
exportToLegacyDictionaryFromParam:withLoopFlavor:
bounce
longexposure
stabilize
minVersion
Td,N,V_x0
Td,N,V_y0
Td,N,V_width
Td,N,V_height
faceBounds:height:
_leftEyeClosed
_rightEyeClosed
_smile
_trackID
_observation
T{CGRect={CGPoint=dd}{CGSize=dd}},V_bounds
TB,V_leftEyeClosed
TB,V_rightEyeClosed
TB,V_smile
Tq,V_yaw
Ti,V_trackID
Tf,V_faceQuality
T@"VNFaceObservation",&,V_observation
_faceID
_last
T{?=qiIq},V_start
T{?=qiIq},V_last
TQ,V_flags
TQ,V_position
TQ,V_faceID
setupModel:
initWithFocalLengthInPixels:principalPoint:cameraTowardsPositiveZ:
updateIntrinsic:vc:
updateFocalLengthInPixels:
initWithModelFile:
numVertices
meanBlendshape
getInternal3dLandmarksCoordinates:lm3dPos:
componentsBlendshape
getOneInternalLandmarkCoordinates:lmCoord:lmWeight:lm3dPos:
updateBoundaryLandmarkCoordinates:pts2D:lm2D:lm3dPos:
project3Dto2D:intrinsinc:extrinsic:numVert:out2dpts:
calculateMesh:numVertices:blendshapes:outputMesh:
updateBoundaryLmForShapeOptimization
updateShapeCoeff:extrinsicMatrix:pts2D:exprWeights:outputblendshapes:
moveBoundaryLandmarks:output:isInput:
projectAndUpdateBoundary
optimizeProjectionMatrix:tracking:firstPass:
updateBoundary3dLandmarkBlendshapes:numBlendshapes:pts2D:lm2D:lmBlendshapes:
calculateBlendshapeWeights:prevWeights:lmBlendshapes:maxIter:
updateMeshAndLm3dAfterExpressionChange
calculateIdentityCoefficients:extrinsicMatrix:pts2D:exprWeights:lm3DMeanBlendshapes:lm3DComponents:maxIter:
calculateModelBlendshapes:outputBlendshapes:
tensorCoeff
blendshapeComponentIndex
calculatePosePnpSolver:
reestimateProjectionMatrixPnP
updateIdentityShape:
getPoseParam
estimateExtrinsicsWith:andPoints3D:andNumPoints:
pose
initWithMode:
isIdentityInit
setCameraIntrinsics:uc:vc:
getEulerAngle:
resetIdentityAndExpressions
trackFaceMesh:
fitOneImage:
getPose
blendShapes
updateMeshVertices
processingMode
setProcessingMode:
meshVertices
vertexCount
detectionModeCounterShapeModel
setDetectionModeCounterShapeModel:
_tensorModel
_numVertices
_curMesh
_cur2D
_numInternalLms
_lmCoord
_lmWeight
_numBoundaryLms
_boundaryLmIndices
_numBoundaryVertices
_boundaryVertices
_boundaryLandmarkValidity
_chPts
_chPtSelected
_boundaryLmUpdated
_chCount
_curBlendshapes
_curCoeff
_curExprWeights
_prevExprWeights
_exprWeightDiagMatrix
_transformedCoeff
_blendShapeDelta
_trans
_intrinsicMatrix
_extrinsicMatrix
_eulerAngle
_rotMatrix
_LM2D
_LM3D
_lm3dBlendshapes
_lm3dMeanBlendshapes
_lm3dBlendshapeComponents
_numFrmsSinceLastShapeUpdate
_shapeUpdateInProgress
_poseSolver
_updateShapeGroup
_updateShapeQueue
_asyncBlendshapes
_asyncLmBlendshapes
_asyncExtMat
_asyncLm2d
_asyncWeights
_identityInit
_processingMode
_detectionModeCounterShapeModel
_meshVertices
_vertexCount
Ti,V_processingMode
T^,R,V_meshVertices
TQ,R,V_vertexCount
Ti,V_detectionModeCounterShapeModel
computeLandmarks:
queryID
uiScale
clientBundleID
contextWithDictionary:error:
initWithImageLoader:imageSize:
vcp_annotationWithTypes:
createQueryContextWithError:
surroundingText
normalizedBoundingBoxes
initWithSurroundingText:normalizedBoundingBoxes:
stop
sections
initWithSearchSections:
elapsedTimeSeconds
queryTerm
hintDomain
initWithQueryTerm:hintDomain:textContext:imageContext:annotation:queryContext:
lookupTextWithQuery:completion:
clearCacheWithOption:
_cancellable
setVanishingPoint:
setDominantLine:
vanishingPoint
dominantLine
_dominantLine
_vanishingPoint
T@"VCPProtoPoint",&,N,V_vanishingPoint
T@"VCPProtoLine",&,N,V_dominantLine
longLongValue
setIdentifier:
numberWithUnsignedInt:
setInputFaceObservations:
detectEyeOpennessForFace:inBuffer:eyeOpenness:
faceDetection:faces:cancel:
isDuplicate:withRect:
faceDetector
_analysisInput
requestAnalysis:ofIOSurface:withProperties:withReply:
errorWithStatus:andDescription:
requestAnalysis:ofPixelBuffer:withProperties:withCompletionHandler:
_connectionLock
activityID
startTime
exitStatus
setActivityID:
setStartTime:
setExitStatus:
_exitStatus
_activityID
TQ,N,V_activityID
T@"NSDate",N,V_startTime
Td,N,V_duration
Ti,N,V_exitStatus
pointWithPoint:
setEnd:
pointValue
startPointValue
endPointValue
lineFromPoint:toPoint:
setTorsoprint:
detectPersons:persons:
_persons
exceptionWithName:reason:userInfo:
raise
numberWithLongLong:
clearHomographyParams
homographyParams
setHomographyParams:count:
_homographyParams
_epoch
_timeValue
_timeScale
Tq,N,V_timeValue
T^f,R,N
Ti,N,V_timeScale
Tq,N,V_epoch
_numBlendshapePlusOne
_numComponents
_numIdentities
_meanBlendshape
_tensorCoeff
_componentsBlendshape
_blendshapeComponentIndex
Ti,R,V_numVertices
T^f,R,V_meanBlendshape
T^f,R,V_tensorCoeff
T^f,R,V_componentsBlendshape
T^i,R,V_blendshapeComponentIndex
initWithLocalIdentifier:andTaskID:andStatus:andAttempts:andLastRetryDate:
entryWithLocalIdentifier:andTaskID:andStatus:andAttempts:andLastRetryDate:
taskID
attempts
lastRetryDate
_taskID
_status
_attempts
_lastRetryDate
TQ,R,N,V_taskID
T@"NSString",R,N,V_localIdentifier
TQ,R,N,V_status
TQ,R,N,V_attempts
T@"NSDate",R,N,V_lastRetryDate
setLoopFadeLen:
setHasLoopFadeLen:
hasLoopFadeLen
setLoopPeriod:
setHasLoopPeriod:
hasLoopPeriod
setLoopStart:
setHasLoopStart:
hasLoopStart
errorCode
setErrorCode:
loopFadeLen
loopPeriod
loopStart
_errorCode
_loopFadeLen
_loopPeriod
_loopStart
Ti,N,V_errorCode
Ti,N,V_loopFadeLen
Ti,N,V_loopPeriod
Ti,N,V_loopStart
progressWithTotalUnitCount:parent:pendingUnitCount:
vcp_childWithPendingUnitCount:
initWithForceCPU:sharedModel:
initWithXYAndSize:y:width:height:confidence:
analyzeFrame:withBox:keypoints:
maxX
minX
maxY
minY
analyzePixelBuffer:flags:petsDetections:results:cancel:
initWithMaxNumRegions:forceCPU:sharedModel:
_petsKeypointsDetector
descriptors
normalizeActivityDescriptor
initWithTimerange:andScore:
prepareActivityStats
generateActivityDescriptor
computeActivityScoreAtTime:
resetActivityStatsAtTime:
extractRequiredInfoFrom:toArray:
extractRequiredClassificationInfoFrom:toArray:
extractRequiredFaceInfoFrom:toArray:
validationScoreOfTimeRange:fromResult:startIdx:
actionScoreInTimeRange:
validateActivityScores
scaleBasedOnFaceForTimeRange:
addSceneSwitchFrequencyConstributionToActivityLevel:
addSceneClassificationContributionToActivityLevel:
initWithFrameStats:
preProcessQualityResults:interestingnessResults:obstructionResults:classificationResults:fineActionResults:faceResults:sceneSwitchFrequency:
finishAnalysisPass:fpsRate:
_activityDescriptor
_activityScores
_validActivityScores
_qualityResults
_interestingnessResults
_obstructionResults
_classificationResults
_fineActionResults
_sceneSwitchFrequency
_lastProcessTime
_overallActivityLevel
_sportsSceneId
T{?={?=qiIq}{?=qiIq}},V_timerange
Tf,V_score
hasMeaningfulSceneSegment:withFpsRate:
assetQualityScoreFromAnalysis:withFpsRate:
assetActionScoreFromAnalysis:
assetExpressionScoreFromAnalysis:
assetVoiceScoreFromAnalysis:
assetJunkScoreFromAnalysis:
assetCameraMotionScoreFromAnalysis:
checkCameraZoom:cameraMotionResults:
scaleForTimeRange:basedOnFace:
isJunkTimeRange:basedOnResults:
subjectActivityInTimeRange:fromResults:
cameraActivityfromQuality:
assetActivityLevelFromAnalysisResults:
analyzeOverallQuality:withFpsRate:
generateLivePhotoRecommendationForResults:andPrivateResults:usingFaceAction:
setActivityLevel:
initWithParameters:poolY:chunk:
cnnDataWithGPUContext:
constructBlock:context:
useGPU
getMinimumHighlightInSec
assetImageGeneratorWithAsset:
setMaximumSize:
setRequestedTimeToleranceAfter:
setRequestedTimeToleranceBefore:
computeHighlightScoreResults
postProcessMLHighlightScore
combineMLHighlightScore
selectHighlightsForTimelapse
selectHighlights
evaluateSegment:
computeColorNormalization
loadHighlightScoreResults:
maxTrimMovieHighlight:
targetProcessRange:maxRange:
targetMovieHighlight:mergedRange:maxRange:
isGoodQuality:
targetTrimRange:searchRange:
targetExtendRange:maxRange:
findBestHighlightSegment:targetTrim:
findBestTrim:
highlightScoreForTimeRange:average:
computeQualityTrimFor:withKeyFrame:
computeTrimWithHighlightScoreFor:
pickKeyFramesInRange:
searchFeatureVectorOfSegment:
computeBestPlaybackCrop:
copyCGImageAtTime:actualTime:error:
analyzeCGImage:results:
computeActionFaceTrimFor:
computeSteadyTranslationTrimFor:
checkCameraZoom:
generateExpressionSegments:
analyzeOverallQuality:isSettlingEffect:
settlingMotionScore:
settlingSubjectScore:
settlingExposureChangeScore:
updateCropHeatMap:withResults:timeRange:resultsKey:
computeExpressionScoreInTimerange:
computeActionScoreInTimerange:
computeVoiceScoreInTimeRange:
computeHighlightScoreOfSegment:
addSegment:
qualityScoreForTimerange:
computeMLQualityScoreForTimerange:
junkScoreForTimerange:lengthScale:
computeSubtleMotionScoreInTimerange:
cameraMotionScoreForTimerange:
computeHumanActionScoreInTimerange:
computeHumanPoseScoreInTimerange:
computeMLHighlightScoreForTimerange:
replaceObjectAtIndex:withObject:
actionScoreForTimerange:
subtleMotionScoreForTimerange:
expressionScoreForTimerange:
voiceScoreForTimerange:
visualPleasingScoreForTimerange:
initWithPostProcessOptions:
postProcessMovieHighlight:
computeHighlightScoreOfRange:
SetKeyFramesForSegments:
pickHighlightsFrom:
_featureResults
_keyFrameResults
_expressionSegments
_highlightResults
_internalConstraintResults
_maxDurationInSeconds
_minDurationInSeconds
_targetDurationInSeconds
_toleranceInSeconds
_targetHighlightIndex
_startRange
_isMaxTrim
_requestBestTrim
_requestFullResult
_maxHighlightScore
_minHighlightScore
_photoOffset
_verbose
_preferredTimeRange
_imageGenerator
_numberOfFrames
_prevMotionParamDiff
_sumMotionParam
_diffFlipCount
_colorNormalizationAnalyzer
startSessionWithProperties:andReply:
initWithProperties:withResultsHandler:andInterruptionHandler:
setWeakSession:
processMessageWithOptions:andReply:
processVideoFragmentAssetData:withOptions:andReply:
processResults:withReply:
allowedClasses
sessionWithProperties:andResultsHandler:
sessionWithProperties:withResultsHandler:andInterruptionHandler:
processVideoFragmentAssetData:withOptions:andErrorHandler:
processVideoFragmentAssetData:withOptions:andCompletionHandler:
processMessageWithOptions:andCompletionHandler:
_formatDescription
_resultsHandler
_interruptionHander
weakSession
_weakSession
T@"VCPHomeKitAnalysisSession",W,N,V_weakSession
vcp_setFingerprint:
shouldQueryInternalFields
numberWithUnsignedLongLong:
parseHeader:startColumn:analysis:
parseResults:typeColumn:dataColumn:results:
closeDatabase
openDatabase
executeDatabaseBlock:
queryHeaderForAsset:analysis:assetId:
queryResultsForAssetId:analysis:
queryResultsForAssetId:withTypes:analysis:
queryHeadersForAssets:analyses:idMap:
queryResultsForAssets:withTypes:batchResults:
_queryValue:forKey:
exists
queryBlacklistedLocalIdentifiers
queryAnalysisForAsset:
queryAnalysisPropertiesForAsset:
queryAnalysesForAssets:withTypes:
queryAssetsAnalyzedSince:
queryLocalIdentifiersForTaskID:withStatus:
querySchedulingHistoryRecords:forActivityID:sinceDate:
_sqlSerialQueue
_filepath
propertyListWithData:options:format:error:
_value
_timescale
Tq,N,V_value
Ti,N,V_timescale
TI,N,V_flags
isMovie
getResourceValue:forKey:error:
initWithURL:options:
mediaSubtypes
modificationDate
mainFileURL
scenes
_imageURL
_movie
_mediaType
_mediaSubtypes
_pixelWidth
_pixelHeight
_onceExif
_cachedExif
_onceScenes
_cachedScenes
initWithImageURL:isSDOF:
vcp_exifFromImageURL:
sharedImageManager
pixelBufferWithFormat:andMaxDimension:fromImageURL:
pixelBufferWithFormat:andMaxDimension:fromImageURL:orientation:
exif
imageWithPreferredDimension:
imageWithPreferredDimension:orientation:
imageAssetWithURL:
sdofImageAssetWithURL:
assetWithURL:
initWithImageURL:andMovieURL:
isLivePhoto
vcp_livePhotoStillDisplayTime
photoOffsetSeconds
originalPhotoOffsetSeconds
livePhotoAssetWithImageURL:andMovieURL:
naturalSize
nominalFrameRate
initWithMovieURL:
isSlowmo
slowmoRate
slomoRange
movie
isMovieResourceLocalAvailable
originalMovie
movieAssetWithURL:
transformUprightAboutTopLeft:
addFaceResults:flags:
initWithProperties:forAnalysisTypes:
analyzeAsset:results:
_properties
initWithOptions:andCompletionHandler:
taskService
isCanceled
cancelTask:
submitTaskWithOptions:completionHandler:
taskWithOptions:andCompletionHandler:
cancelBlock
setCancelBlock:
_cancelBlock
T@?,C,N,V_cancelBlock
initWithCompletionHandler:
initWithCloudIdentifierRequests:photoLibrary:clientBundleID:clientTeamID:cancelBlock:andCompletionHandler:
fetchOptionsWithInclusiveDefaultsForPhotoLibrary:
setIncludeHiddenAssets:
setIncludeTrashedAssets:
setIncludeGuestAssets:
addFetchPropertySets:
fetchAssetsWithCloudIdentifiers:options:
assetWithIdentifier:isCloudIdentifier:error:
assetWithPhotosAsset:clientBundleID:clientTeamID:
taskWithRequests:forAsset:cancelBlock:andCompletionHandler:
setSignpostPayload:
taskWithCloudIdentifierRequests:photoLibrary:clientBundleID:clientTeamID:cancelBlock:andCompletionHandler:
signpostPayload
_requests
_photolibrary
_clientBundleID
_clientTeamID
T@"NSString",&,N,V_signpostPayload
sharedModel:outputNames:properties:
outputBeforeFc
outputBeforeSpatiialPooling
outputRes4
_outputBeforeFc
_outputBeforeSpatiialPooling
_outputRes4
_outputBeforeTemporalPooling
T^f,R,V_outputBeforeFc
T^f,R,V_outputBeforeSpatiialPooling
T^f,R,V_outputRes4
T^f,R,V_outputBeforeTemporalPooling
_pcmBuffer
_framePosition
_loudnessAnalyzer
_processFormat
_sampleRate
_peakValues
_momentaryEnergyValues
_loudnessSampleBuffer
_loudnessResults
_samplesFor100ms
_samplesForProcessingBufferList
_activityScore
Tf,N,V_activityScore
initWithCGImage:options:session:
adjustmentKeys
adjustmentValuesForKey:
_sessionPool
dataWithJSONObject:options:error:
initWithData:encoding:
dataUsingEncoding:
newDictionaryRepresentationOfFaceCropDataFromFaceBox:andCropRegion:andGroupingIdentifier:
createOutputMetadataFromDictionary:
reason
newFaceCropFromCGImageSource:withFaceRect:groupingIdentifier:error:
newDictionaryPopulatedWithFaceCropDataFromImageData:
isEqualToNumber:
isValidFaceCrop:
newFaceCropFromImageURL:withNormalizedFaceRect:groupingIdentifier:error:
newFaceCropFromImageData:withFaceRect:groupingIdentifier:error:
faceBoundsFromFaceCrop:error:
cropBoundsInOriginalImageFromFaceCrop:error:
groupingIdentifierFromFaceCrop:error:
faceCropDimensionsFromFaceCrop:error:
initWithContext:
changeRequestForAsset:
creationRequestForFace
placeholderForCreatedFace
addFaces:
quickClassificationFaceAdjustmentVersion
setFaceAdjustmentVersion:
vcp_isMontageWithTaskID:
deferredProcessingNeeded
quickAnalyzeAsset:results:
_persistFaces:forAsset:
processAsset:
_faceAnalyzer
documentObservations
textBlockWithDocumentObservations:
scenenetClassifications
sceneIdentifier
nodeForSceneClassId:
initWithLabel:normalizedBoundingBox:confidence:
initWithAnnotations:revision:
faces
vcp_hasFace
vcp_normalizedFaceBounds
vcp_hasBody
vcp_normalizedBodyBounds
nsfwClassifications
vcp_textAnnotation
vcp_scenenetAnnotation
initWithFaceAnnotations:humanAnnotations:nsfwAnnotations:textBlockAnnotation:scenenetAnnotation:barcodeAnnotation:
symbologies
barcodeObservations
canReuseResultsForRequest
initWithObservations:
setSymbologies:
enableGating
setUseSegmentationPregating:
setBarcodeObservations:
flagsFromKeypoints:withMinConfidence:
_torsoprint
T@"VNTorsoprint",&,V_torsoprint
setStatisticsBlob:
statisticsBlob
initModelWithName:andConfig:
bindWithBuffers:correlation:flow:outputFlow:
_inputBlobNames
_outpuBlobName
interestScore
setInterestScore:
_interestScore
Tf,N,V_interestScore
convBlockWithFilterSize:filterNum:chunk:reLU:padding:groups:stride:batchNorm:
initWithModelFile:paramFile:numTri:triList:angle:
validateOneImage:landmarks:numofLandmarks:score:
_transArray
_meanLandmarkLoc
_triIndexMap
_numTri
_triList
T^f,V_orientation
initWithMetadata:sourceSize:cropRect:
saveStabilizationRecipe
videoStabilizerforAnalysisType:withMetadata:sourceSize:cropRect:
correctionResultRef
setCorrectionResultRef:
cropFraction
setCropFraction:
motionBlurVector
setMotionBlurVector:
gyroStabilization
validStabilization
_gyroStabilization
_validStabilization
_cropFraction
_analysisConfidence
_analysisResultRef
_correctionResultRef
_motionBlurVector
T^v,N,V_analysisResultRef
T^v,N,V_correctionResultRef
T@"NSDictionary",&,N,V_results
Tf,N,V_cropFraction
T@"NSMutableArray",&,N,V_motionBlurVector
TB,N,V_gyroStabilization
Tf,N,V_analysisConfidence
TB,N,V_validStabilization
indexSetWithIndexesInRange:
persistenceDelegate_enumerateInChunksOfSize:withOverageAllowance:usingBlock:
resultsAsArray
resultsAsSet
initWithPerson:andPerson:reason:
person1LocalIdentifier
person2LocalIdentifier
mergeCandidatePairWithPerson:andPerson:reason:
_hash
_person1LocalIdentifier
_person2LocalIdentifier
_reason
T@"NSString",R,V_person1LocalIdentifier
T@"NSString",R,V_person2LocalIdentifier
T@"NSString",R,V_reason
newAllFacesFetchOptionsWithPhotoLibrary:
newFacesDeterministicSortDescriptors
setInternalSortDescriptors:
fetchAssetsGroupedByFaceUUIDForFaces:
fetchMomentUUIDByAssetUUIDForAssets:options:
nonGroupedGroupID
initWithUUIDString:
faceClusterSequenceNumbersOfFacesWithClusterSequenceNumbers:error:
fetchFaceGroupsGroupedByFaceLocalIdentifierForFaces:options:
enumerateFetchResult:withBatchSize:handler:
_ungroupFaceClusterSequenceNumbers:cancelOrExtendTimeoutBlock:error:
strongToStrongObjectsMapTable
_categorizeGroupedFacesInFetchResult:intoFaceLocalIdentifiersByFaceGroup:ungroupedFaceLocalIdentifiers:cancelOrExtendTimeoutBlock:photoLibrary:
_resetFaceClusterSequenceNumberOfFacesInFetchResult:inPhotoLibrary:cancelOrExtendTimeoutBlock:error:
keyEnumerator
changeRequestForFaceGroup:
removeFaces:
performCancellableChangesAndWait:error:
setIncludeOnlyFacesInFaceGroups:
_fetchResultForUngroupedFacesWithNonZeroClusterSequenceNumberInPhotoLibrary:
_fetchResultForGroupedFacesWithClusterSequenceNumberSetToZeroInPhotoLibrary:
newAllPersonsWithAtLeastOneFaceFetchOptionsWithPhotoLibrary:
fetchAssociatedPersonsGroupedByFaceGroupLocalIdentifierForFaceGroups:options:
objectEnumerator
setVerifiedPersonTypes:
fetchRejectedPersonsForFace:options:
anyObject
creationRequestForFaceGroup
placeholderForCreatedFaceGroup
fetchKeyFaceForFaceGroup:options:
setPersonBuilderState:
_localIdentifiersOfUnverifiedPersonsAssociatedWithFaceGroups:cancelOrExtendTimeoutBlock:
updateKeyFacesOfPersonsWithLocalIdentifiers:forceUpdate:cancelOrExtendTimeoutBlock:error:
deleteFaceGroups:
fetchEmptyFaceGroupsWithOptions:
newVisibleFacesFetchOptionsWithPhotoLibrary:
bestRepresentativeFaceForPerson:qualityMeasureByFace:cancelOrExtendTimeoutBlock:
bestRepresentativeFaceForPerson:qualityMeasureByFace:candidateFaces:cancelOrExtendTimeoutBlock:
_facesFromFaceGroupWithMostNumberOfFacesOnPerson:options:error:
_faceToFaceCountMapForFaces:
qualityMeasureForFace:countOfFacesOnAsset:
_representativenessByFaceCSNFromFaces:cancelOrExtendTimeoutBlock:
selectRepresentativeFromFaces:qualityMeasureByLocalIdentifier:representativenessByCSN:candidateFaces:
representativenessForFaces:error:
newAssetFetchOptionsWithPhotoLibrary:
fetchAssetsForFaces:options:
fetchFacesInAsset:options:
removeMergeCandidatePersons:
_cleanupMergeCandidatesForVerifiedPersons:minimumFaceGroupSize:cancelOrExtendTimeoutBlock:error:
minimumVerifiedFaceCount
minimumUnverifiedFaceCount
predicate
evaluateWithObject:
newAllPersonsFetchOptionsWithPhotoLibrary:
_enumeratePersonsWithLocalIdentifiers:fetchOptions:personCache:usingBlock:
deletePersons:
changeRequestForDedupingGraphPersons:
isConfirmedFaceCropGenerationPending
newVerifiedPersonsFetchOptionsWithPhotoLibrary:
_getMergeCandidates:invalidMergeCandidates:forPersonsWithLocalIdentifiers:
fetchRejectedFacesForPerson:options:
progressWithTotalUnitCount:
filterUsingPredicate:
becomeCurrentWithPendingUnitCount:
resignCurrent
addInvalidMergeCandidatePersons:
fetchFacesOnAssetWithFace:options:
otherFacesOnAssetWithFace:options:
_duplicateFaceCSNsOnAssetForPerson:faceCSNsOnPerson:faceByCSNCache:
fetchPersonForFaceCrop:options:
fetchPersonWithFace:options:
compare:
sortedArrayUsingComparator:
fetchFaceCropByFaceLocalIdentifierForFaces:fetchOptions:
_adjustConfirmingAndRejectionWithFaces:faceCrops:cancelOrExtendTimeoutBlock:
_detectDuplicationInExistingFaceCrops:withFetchedFaces:faceCropFaceIdentifiersToEvaluate:duplicationResults:cancelOrExtendTimeoutBlock:
changeRequestForFaceCrop:
setState:
deleteFaceCrops:
_processNewlyClusteredFaceCropsInFaceGroups:cancelOrExtendTimeoutBlock:
dedupeGraphVerifiedPersonsInFaceGroup:personCache:
_getTrainingFacesByPerson:confirmedFaceCSNs:faceCSNsByPerson:faceCSNsByMigratedPerson:faceCSNsByQuickClassificationPerson:mergeCandidates:invalidMergeCandidates:rejectedPersonsByPerson:faceInFaceGroupByCSN:inFaces:personCache:cancelOrExtendTimeoutBlock:
_getRejectedTrainingFaceCSNs:rejectedFaceCSNs:rejectedPersonLocalIdentifiers:forPerson:faceInFaceGroupByCSN:
_completePersonBuildingWithPersonsToUpdate:facesToRemoveByPerson:facesToAddByPerson:updateFaceGroup:newMergeCandidatePairs:newInvalidMergeCandidatePairs:faceInFaceGroupByCSN:personCache:keyFaceUpdateBlock:cancelOrExtendTimeoutBlock:context:error:
nextObject
_level0ClusterIdForFaceCSN:level0Clusters:
_updateFaceCSNsToAddByPerson:faceCSNsToRemoveByPerson:faceInFaceGroupByCSN:faceCSNsByPersonLocalIdentifier:faceCSNsByMigratedPersonLocalIdentifier:personsToUpdate:
_updatedFaceGroupByFGLocalIdentifierFromClusterCSNs:fetchLimit:
_buildPersonsFromUpdatedFaceGroups:faceClusterer:keyFaceUpdateBlock:cancelOrExtendTimeoutBlock:context:
suggestedMeIdentifierWithPersonClusterManager:forPersons:updateBlock:
socialGroupsOverTheYearsWithPersonClusterManager:forPersons:updateBlock:
multiLevelSocialGroupsWithPersonClusterManager:forPersons:updateBlock:
densityClusteringForObjects:maximumDistance:minimumNumberOfObjects:withDistanceBlock:
newVerifiedPersonsWithAtLeastOneFaceFetchOptionsWithPhotoLibrary:
keyFaceForPerson:qualityMeasureByFace:updateBlock:
performSocialGroupsIdentifiersWithPersonClusterManager:forPersons:overTheYearsComputation:updateBlock:
countOfUnclusteredClusteringEligibleFaces
invalidFaceClusterSequenceNumbersInClusterSequenceNumbers:canceler:error:
ungroupFaceClusterSequenceNumbers:batchSizeForUnclusteringFaces:canceler:error:
cleanupUngroupedFacesWithNonZeroClusterSequenceNumbersWithCanceler:error:
cleanupGroupedFacesWithClusterSequenceNumberSetToZeroWithCanceler:error:
persistChangesToAlgorithmicFaceGroups:faceCSNByLocalIdentifierForNewlyClusteredFaces:faceCSNsOfUnclusteredFaces:localIdentifiersOfUnclusteredFaces:persistenceCompletionBlock:canceler:error:
resetLibraryClustersWithCanceler:error:
updateKeyFacesOfPersonsWithLocalIdentifiers:forceUpdate:canceler:error:
bestRepresentativeFaceForPerson:qualityMeasureByFace:canceler:
bestRepresentativeFaceForPerson:qualityMeasureByFace:candidateFaces:canceler:
associateFace:withFaceCrop:error:
clearDirtyStateOnFaceCrops:error:
dirtyFaceCropsWithLimit:
faceAssociatedWithFaceCrop:
facesFromAsset:
persistFaces:deleteFaces:forAsset:persistedFaces:error:
persistGeneratedFaceCrops:error:
recordNeedToPersonBuildOnFaceGroupContainingFace:error:
suggestedPersonLocalIdentifierForPersonLocalIdentifier:faceClusterer:canceler:context:error:
updateFaceprint:ofPersistedFace:error:
buildPersonsWithFaceClusterer:keyFaceUpdateBlock:canceler:context:extendTimeoutBlock:
needsPersonBuilding
cleanupMergeCandidatesWithMinimumFaceGroupSize:cancelOrExtendTimeoutBlock:error:
buildPersonWithFaceClusterer:keyFaceUpdateBlock:context:cancelOrExtendTimeoutBlock:
fetchFaceWithLocalIdentifier:error:
fetchFaceWithClusterSequenceNumber:error:
fetchPersonWithLocalIdentifier:options:error:
removeAutoAssignedFacesFromVerifiedPersonsAndPrepareForPersonBuilding:cancelOrExtendTimeoutBlock:error:
TB,N,V_personBuilderMergeCandidatesDisabled
setHasUnderExpose:
_exposure
_underExpose
Tf,N,V_exposure
Tf,N,V_underExpose
initWithPHAsset:
vcp_fingerprint:
resources
fetchSceneClassificationsGroupedByAssetLocalIdentifierForAssets:
mad_sceneNameFromSceneId:
assetWithPHAsset:
fingerprint
allScenes
_asset
_cachedResources
T@"NSArray",R,N
vcp_fileSize
imageForResource:pixelFormat:maxDimension:orientation:
photoIrisProperties
photoIrisStillDisplayTime
isLocallyAvailable
slowMotionTimeRange
vcp_isVideoSlowmo
vcp_hasAdjustments:
vcp_assetWithoutAdjustments:duration:
requestDownloadOfResource:
assetWithData:
vcp_allResourcesForAsset:
streamedMovie
originalMovieSize
maximumCandidateCount
usesLanguageDetection
mad_defaultRequest
languages
setRecognitionLanguages:
setMaximumCandidateCount:
setUsesLanguageDetection:
setDocumentObservations:
configuration
faceprintRequestRevision
_loadResources
visionSession
personIdentityModel
faceProcessingContext
_faceProcessingContext
_personIdentityModel
taskName
initWithPersonIdentifier:personName:boundingBox:andConfidence:
initWithResultItems:
allowOnDemand
faceDetectorVisionRevision
initWithCVPixelBuffer:options:session:
maximumFaceCount
inputFaceObservations
computeRegionSharpness:width:height:stride:
computeSharpnessScore:forObjects:inImage:
parseFlowCacheVersion
assetResourcesForAsset:
timeRangeMapperForSourceDuration:slowMotionRate:slowMotionTimeRange:forExport:
vcp_timerange
originalTimeForScaledTime:
vcp_setTimerange:
scaledTimeForOriginalTime:
vcp_setResults:
vcp_setTypes:
vcp_flags
vcp_isLivePhoto
vcp_dateAnalyzed
dateByAddingTimeInterval:
supportedRevisions
containsIndex:
supportedPrivateRevisions
setLoopSuggestionState:
setLongExposureSuggestionState:
setRecipeBlob:
loopSuggestionState
longExposureSuggestionState
recipeBlob
associatePersons:withExisingPersons:
personID
insertObject:atIndex:
computeActionScoreForPerson:
normDistance:point2:
computeVarWithID:index1:index2:interVar:intraVar:
setRelativeActionScore:
setAbsoluteActionScore:
setPersonID:
bodyDistance:withBodyB:
_personID
_existingPersons
_existingPersonsArray
analyzerWithRevision:
setSdof:
initWithFaceResults:sdof:revision:
prepareFaceBlurModel:
scaleRegion:ofImage:toData:withWidth:andHeight:
getFaceScoreFromOutput:ratio:
estimateDistance:prevHomography:
analyzePixelBuffer:flags:withPreAnalysisScore:results:cancel:
computeLocalSharpness:
spatialPooling
computeCNNBasedSharpness:sharpnessScore:textureScore:contrast:cancel:
computeCNNFaceSharpness:result:cancel:
computeSharpnessScore:forFacesInImage:
computeGyroSharpness:
setGyroSharpnessParam:homographyResults:livePhotoStillDisplayTime:imageExposureTime:
_sharpnessBlocks
_faces
_framePTSResults
_homographyResults
_faceModel
_faceInput
_livePhotoStillDisplayTime
_imageExposureTime
_useGPU
_sdof
_contrast
Tf,R,V_sharpness
Tf,R,V_textureScore
bindWithBuffers:imgFeature:
_inputBlobName
_featureBlobNames
_featureChannels
addImageBlurResults:
addImageCompositionResults:
addImageFaceResults:
addImageFeatureResults:
addImageJunkResults:
addImageSaliencyResults:
addImageShotTypeResults:
addLivePhotoRecommendationResults:
addLivePhotoSharpnessResults:
addMovieActivityLevelResults:
addMovieCameraMotionResults:
addMovieClassificationResults:
addMovieFaceResults:
addMovieFaceprintResults:
addMovieFeatureResults:
addMovieFineSubjectMotionResults:
addMovieInterestingnessResults:
addMovieMovingObjectResults:
addMovieMusicResults:
addMovieObstructionResults:
addMovieOrientationResults:
addMoviePreEncodeResults:
addMovieQualityResults:
addMovieSaliencyResults:
addMovieSceneResults:
addMovieSubjectMotionResults:
addMovieUtteranceResults:
addMovieVoiceResults:
addImagePetsResults:
addMovieSummaryResults:
addMovieHighlightResults:
addImageExposureResults:
addLivePhotoEffectsResults:
addImagePetsFaceResults:
addImageSceneprintResults:
addMovieSceneprintResults:
addImageHumanPoseResults:
addMovieHumanPoseResults:
addMovieApplauseResults:
addMovieBabbleResults:
addMovieCheeringResults:
addMovieLaughterResults:
addLivePhotoKeyFrameResults:
addLivePhotoKeyFrameStillResults:
addMovieHumanActionResults:
addMovieSubtleMotionResults:
addMovieLoudnessResults:
addMoviePetsResults:
addMoviePetsFaceResults:
addMovieStabilizationResults:
addMovieHighlightScoreResults:
addLivePhotoHumanActionClassificationResults:
addMovieAudioQualityResults:
setAssetIdentifier:
setAssetMasterFingerprint:
setAssetAdjustedFingerprint:
imageBlurResultsCount
clearImageBlurResults
imageBlurResultsAtIndex:
imageCompositionResultsCount
clearImageCompositionResults
imageCompositionResultsAtIndex:
imageFaceResultsCount
clearImageFaceResults
imageFaceResultsAtIndex:
imageFeatureResultsCount
clearImageFeatureResults
imageFeatureResultsAtIndex:
imageJunkResultsCount
clearImageJunkResults
imageJunkResultsAtIndex:
imageSaliencyResultsCount
clearImageSaliencyResults
imageSaliencyResultsAtIndex:
imageShotTypeResultsCount
clearImageShotTypeResults
imageShotTypeResultsAtIndex:
livePhotoRecommendationResultsCount
clearLivePhotoRecommendationResults
livePhotoRecommendationResultsAtIndex:
livePhotoSharpnessResultsCount
clearLivePhotoSharpnessResults
livePhotoSharpnessResultsAtIndex:
movieActivityLevelResultsCount
clearMovieActivityLevelResults
movieActivityLevelResultsAtIndex:
movieCameraMotionResultsCount
clearMovieCameraMotionResults
movieCameraMotionResultsAtIndex:
movieClassificationResultsCount
clearMovieClassificationResults
movieClassificationResultsAtIndex:
movieFaceResultsCount
clearMovieFaceResults
movieFaceResultsAtIndex:
movieFaceprintResultsCount
clearMovieFaceprintResults
movieFaceprintResultsAtIndex:
movieFeatureResultsCount
clearMovieFeatureResults
movieFeatureResultsAtIndex:
movieFineSubjectMotionResultsCount
clearMovieFineSubjectMotionResults
movieFineSubjectMotionResultsAtIndex:
movieInterestingnessResultsCount
clearMovieInterestingnessResults
movieInterestingnessResultsAtIndex:
movieMovingObjectResultsCount
clearMovieMovingObjectResults
movieMovingObjectResultsAtIndex:
movieMusicResultsCount
clearMovieMusicResults
movieMusicResultsAtIndex:
movieObstructionResultsCount
clearMovieObstructionResults
movieObstructionResultsAtIndex:
movieOrientationResultsCount
clearMovieOrientationResults
movieOrientationResultsAtIndex:
moviePreEncodeResultsCount
clearMoviePreEncodeResults
moviePreEncodeResultsAtIndex:
movieQualityResultsCount
clearMovieQualityResults
movieQualityResultsAtIndex:
movieSaliencyResultsCount
clearMovieSaliencyResults
movieSaliencyResultsAtIndex:
movieSceneResultsCount
clearMovieSceneResults
movieSceneResultsAtIndex:
movieSubjectMotionResultsCount
clearMovieSubjectMotionResults
movieSubjectMotionResultsAtIndex:
movieUtteranceResultsCount
clearMovieUtteranceResults
movieUtteranceResultsAtIndex:
movieVoiceResultsCount
clearMovieVoiceResults
movieVoiceResultsAtIndex:
imagePetsResultsCount
clearImagePetsResults
imagePetsResultsAtIndex:
movieSummaryResultsCount
clearMovieSummaryResults
movieSummaryResultsAtIndex:
movieHighlightResultsCount
clearMovieHighlightResults
movieHighlightResultsAtIndex:
imageExposureResultsCount
clearImageExposureResults
imageExposureResultsAtIndex:
livePhotoEffectsResultsCount
clearLivePhotoEffectsResults
livePhotoEffectsResultsAtIndex:
imagePetsFaceResultsCount
clearImagePetsFaceResults
imagePetsFaceResultsAtIndex:
imageSceneprintResultsCount
clearImageSceneprintResults
imageSceneprintResultsAtIndex:
movieSceneprintResultsCount
clearMovieSceneprintResults
movieSceneprintResultsAtIndex:
imageHumanPoseResultsCount
clearImageHumanPoseResults
imageHumanPoseResultsAtIndex:
movieHumanPoseResultsCount
clearMovieHumanPoseResults
movieHumanPoseResultsAtIndex:
movieApplauseResultsCount
clearMovieApplauseResults
movieApplauseResultsAtIndex:
movieBabbleResultsCount
clearMovieBabbleResults
movieBabbleResultsAtIndex:
movieCheeringResultsCount
clearMovieCheeringResults
movieCheeringResultsAtIndex:
movieLaughterResultsCount
clearMovieLaughterResults
movieLaughterResultsAtIndex:
livePhotoKeyFrameResultsCount
clearLivePhotoKeyFrameResults
livePhotoKeyFrameResultsAtIndex:
livePhotoKeyFrameStillResultsCount
clearLivePhotoKeyFrameStillResults
livePhotoKeyFrameStillResultsAtIndex:
movieHumanActionResultsCount
clearMovieHumanActionResults
movieHumanActionResultsAtIndex:
movieSubtleMotionResultsCount
clearMovieSubtleMotionResults
movieSubtleMotionResultsAtIndex:
movieLoudnessResultsCount
clearMovieLoudnessResults
movieLoudnessResultsAtIndex:
moviePetsResultsCount
clearMoviePetsResults
moviePetsResultsAtIndex:
moviePetsFaceResultsCount
clearMoviePetsFaceResults
moviePetsFaceResultsAtIndex:
movieStabilizationResultsCount
clearMovieStabilizationResults
movieStabilizationResultsAtIndex:
movieHighlightScoreResultsCount
clearMovieHighlightScoreResults
movieHighlightScoreResultsAtIndex:
livePhotoHumanActionClassificationResultsCount
clearLivePhotoHumanActionClassificationResults
livePhotoHumanActionClassificationResultsAtIndex:
movieAudioQualityResultsCount
clearMovieAudioQualityResults
movieAudioQualityResultsAtIndex:
imageBlurResultsType
imageCompositionResultsType
imageFaceResultsType
imageFeatureResultsType
imageJunkResultsType
imageSaliencyResultsType
imageShotTypeResultsType
imagePetsResultsType
imagePetsFaceResultsType
imageSceneprintResultsType
livePhotoEffectsResultsType
livePhotoRecommendationResultsType
livePhotoSharpnessResultsType
livePhotoKeyFrameResultsType
livePhotoKeyFrameStillResultsType
movieActivityLevelResultsType
movieCameraMotionResultsType
movieClassificationResultsType
movieFaceResultsType
movieFaceprintResultsType
movieFeatureResultsType
movieFineSubjectMotionResultsType
movieInterestingnessResultsType
movieMovingObjectResultsType
movieMusicResultsType
movieObstructionResultsType
movieOrientationResultsType
moviePreEncodeResultsType
movieQualityResultsType
movieSaliencyResultsType
movieSceneResultsType
movieSceneprintResultsType
movieSubjectMotionResultsType
movieSubtleMotionResultsType
movieUtteranceResultsType
movieVoiceResultsType
movieSummaryResultsType
movieHighlightResultsType
imageExposureResultsType
imageHumanPoseResultsType
movieHumanPoseResultsType
movieApplauseResultsType
movieBabbleResultsType
movieCheeringResultsType
movieLaughterResultsType
movieHumanActionResultsType
movieLoudnessResultsType
moviePetsResultsType
moviePetsFaceResultsType
movieStabilizationResultsType
movieHighlightScoreResultsType
livePhotoHumanActionClassificationResultsType
movieAudioQualityResultsType
setHasQuality:
hasQuality
setHasStatsFlags:
hasStatsFlags
setTypesWide:
setHasTypesWide:
hasTypesWide
hasAssetAdjustedFingerprint
types
setTypes:
setDate:
typesWide
assetIdentifier
assetModificationDate
setAssetModificationDate:
assetMasterFingerprint
assetAdjustedFingerprint
imageBlurResults
setImageBlurResults:
imageCompositionResults
setImageCompositionResults:
imageFaceResults
setImageFaceResults:
imageFeatureResults
setImageFeatureResults:
imageJunkResults
setImageJunkResults:
imageSaliencyResults
setImageSaliencyResults:
imageShotTypeResults
setImageShotTypeResults:
imagePetsResults
setImagePetsResults:
imagePetsFaceResults
setImagePetsFaceResults:
imageSceneprintResults
setImageSceneprintResults:
livePhotoEffectsResults
setLivePhotoEffectsResults:
livePhotoRecommendationResults
setLivePhotoRecommendationResults:
livePhotoSharpnessResults
setLivePhotoSharpnessResults:
livePhotoKeyFrameResults
setLivePhotoKeyFrameResults:
livePhotoKeyFrameStillResults
setLivePhotoKeyFrameStillResults:
movieActivityLevelResults
setMovieActivityLevelResults:
movieCameraMotionResults
setMovieCameraMotionResults:
movieClassificationResults
setMovieClassificationResults:
movieFaceResults
setMovieFaceResults:
movieFaceprintResults
setMovieFaceprintResults:
movieFeatureResults
setMovieFeatureResults:
movieFineSubjectMotionResults
setMovieFineSubjectMotionResults:
movieInterestingnessResults
setMovieInterestingnessResults:
movieMovingObjectResults
setMovieMovingObjectResults:
movieMusicResults
setMovieMusicResults:
movieObstructionResults
setMovieObstructionResults:
movieOrientationResults
setMovieOrientationResults:
moviePreEncodeResults
setMoviePreEncodeResults:
movieQualityResults
setMovieQualityResults:
movieSaliencyResults
setMovieSaliencyResults:
movieSceneResults
setMovieSceneResults:
movieSceneprintResults
setMovieSceneprintResults:
movieSubjectMotionResults
setMovieSubjectMotionResults:
movieSubtleMotionResults
setMovieSubtleMotionResults:
movieUtteranceResults
setMovieUtteranceResults:
movieVoiceResults
setMovieVoiceResults:
movieSummaryResults
setMovieSummaryResults:
movieHighlightResults
setMovieHighlightResults:
imageExposureResults
setImageExposureResults:
imageHumanPoseResults
setImageHumanPoseResults:
movieHumanPoseResults
setMovieHumanPoseResults:
movieApplauseResults
setMovieApplauseResults:
movieBabbleResults
setMovieBabbleResults:
movieCheeringResults
setMovieCheeringResults:
movieLaughterResults
setMovieLaughterResults:
movieHumanActionResults
setMovieHumanActionResults:
movieLoudnessResults
setMovieLoudnessResults:
moviePetsResults
setMoviePetsResults:
moviePetsFaceResults
setMoviePetsFaceResults:
movieStabilizationResults
setMovieStabilizationResults:
movieHighlightScoreResults
setMovieHighlightScoreResults:
livePhotoHumanActionClassificationResults
setLivePhotoHumanActionClassificationResults:
movieAudioQualityResults
setMovieAudioQualityResults:
_assetModificationDate
_date
_typesWide
_assetAdjustedFingerprint
_assetIdentifier
_assetMasterFingerprint
_imageBlurResults
_imageCompositionResults
_imageExposureResults
_imageFaceResults
_imageFeatureResults
_imageHumanPoseResults
_imageJunkResults
_imagePetsFaceResults
_imagePetsResults
_imageSaliencyResults
_imageSceneprintResults
_imageShotTypeResults
_livePhotoEffectsResults
_livePhotoHumanActionClassificationResults
_livePhotoKeyFrameResults
_livePhotoKeyFrameStillResults
_livePhotoRecommendationResults
_livePhotoSharpnessResults
_movieActivityLevelResults
_movieApplauseResults
_movieAudioQualityResults
_movieBabbleResults
_movieCameraMotionResults
_movieCheeringResults
_movieClassificationResults
_movieFaceResults
_movieFaceprintResults
_movieFeatureResults
_movieFineSubjectMotionResults
_movieHighlightResults
_movieHighlightScoreResults
_movieHumanActionResults
_movieHumanPoseResults
_movieInterestingnessResults
_movieLaughterResults
_movieLoudnessResults
_movieMovingObjectResults
_movieMusicResults
_movieObstructionResults
_movieOrientationResults
_moviePetsFaceResults
_moviePetsResults
_moviePreEncodeResults
_movieQualityResults
_movieSaliencyResults
_movieSceneResults
_movieSceneprintResults
_movieStabilizationResults
_movieSubjectMotionResults
_movieSubtleMotionResults
_movieSummaryResults
_movieUtteranceResults
_movieVoiceResults
_types
TI,N,V_version
TI,N,V_types
Td,N,V_date
TQ,N,V_typesWide
T@"NSString",&,N,V_assetIdentifier
Td,N,V_assetModificationDate
T@"NSString",&,N,V_assetMasterFingerprint
T@"NSString",&,N,V_assetAdjustedFingerprint
T@"NSMutableArray",&,N,V_imageBlurResults
T@"NSMutableArray",&,N,V_imageCompositionResults
T@"NSMutableArray",&,N,V_imageFaceResults
T@"NSMutableArray",&,N,V_imageFeatureResults
T@"NSMutableArray",&,N,V_imageJunkResults
T@"NSMutableArray",&,N,V_imageSaliencyResults
T@"NSMutableArray",&,N,V_imageShotTypeResults
T@"NSMutableArray",&,N,V_imagePetsResults
T@"NSMutableArray",&,N,V_imagePetsFaceResults
T@"NSMutableArray",&,N,V_imageSceneprintResults
T@"NSMutableArray",&,N,V_livePhotoEffectsResults
T@"NSMutableArray",&,N,V_livePhotoRecommendationResults
T@"NSMutableArray",&,N,V_livePhotoSharpnessResults
T@"NSMutableArray",&,N,V_livePhotoKeyFrameResults
T@"NSMutableArray",&,N,V_livePhotoKeyFrameStillResults
T@"NSMutableArray",&,N,V_movieActivityLevelResults
T@"NSMutableArray",&,N,V_movieCameraMotionResults
T@"NSMutableArray",&,N,V_movieClassificationResults
T@"NSMutableArray",&,N,V_movieFaceResults
T@"NSMutableArray",&,N,V_movieFaceprintResults
T@"NSMutableArray",&,N,V_movieFeatureResults
T@"NSMutableArray",&,N,V_movieFineSubjectMotionResults
T@"NSMutableArray",&,N,V_movieInterestingnessResults
T@"NSMutableArray",&,N,V_movieMovingObjectResults
T@"NSMutableArray",&,N,V_movieMusicResults
T@"NSMutableArray",&,N,V_movieObstructionResults
T@"NSMutableArray",&,N,V_movieOrientationResults
T@"NSMutableArray",&,N,V_moviePreEncodeResults
T@"NSMutableArray",&,N,V_movieQualityResults
T@"NSMutableArray",&,N,V_movieSaliencyResults
T@"NSMutableArray",&,N,V_movieSceneResults
T@"NSMutableArray",&,N,V_movieSceneprintResults
T@"NSMutableArray",&,N,V_movieSubjectMotionResults
T@"NSMutableArray",&,N,V_movieSubtleMotionResults
T@"NSMutableArray",&,N,V_movieUtteranceResults
T@"NSMutableArray",&,N,V_movieVoiceResults
T@"NSMutableArray",&,N,V_movieSummaryResults
T@"NSMutableArray",&,N,V_movieHighlightResults
T@"NSMutableArray",&,N,V_imageExposureResults
T@"NSMutableArray",&,N,V_imageHumanPoseResults
T@"NSMutableArray",&,N,V_movieHumanPoseResults
T@"NSMutableArray",&,N,V_movieApplauseResults
T@"NSMutableArray",&,N,V_movieBabbleResults
T@"NSMutableArray",&,N,V_movieCheeringResults
T@"NSMutableArray",&,N,V_movieLaughterResults
T@"NSMutableArray",&,N,V_movieHumanActionResults
T@"NSMutableArray",&,N,V_movieLoudnessResults
T@"NSMutableArray",&,N,V_moviePetsResults
T@"NSMutableArray",&,N,V_moviePetsFaceResults
T@"NSMutableArray",&,N,V_movieStabilizationResults
T@"NSMutableArray",&,N,V_movieHighlightScoreResults
T@"NSMutableArray",&,N,V_livePhotoHumanActionClassificationResults
T@"NSMutableArray",&,N,V_movieAudioQualityResults
initWithClientBundleID:andClientTeamID:
initWithPixelBuffer:orientation:andIdentifier:clientBundleID:clientTeamID:
hasCachedParseData
cachedParseData
setCachedParseData:overwriteExisting:
_pixelBuffer
_documentObservations
_hasCachedParseData
_cachedParseData
pixelBufferWithFormat:fromImageURL:flushCache:orientation:
initWithURL:identifier:clientBundleID:clientTeamID:
_url
pixelBufferWithFormat:andMaxDimension:fromData:withUniformTypeIdentifier:flushCache:orientation:
initWithImageData:uniformTypeIdentifier:identifier:clientBundleID:clientTeamID:
_imageData
_uniformTypeIdentifier
vcp_needFaceProcessing
sceneClassifications
vcp_typeDescription
conformsToType:
purgeInactiveResources
vcp_ocrMajorDimensionForResource:
vcp_majorDimensionForResource:withTargetResolution:
getTranscript
setCharacterRecognitionData:machineReadableCodeData:algorithmVersion:adjustmentVersion:
performChanges:completionHandler:
characterRecognitionProperties
persistOCRMRC
machineReadableCodeData
unarchivedObjectOfClasses:fromData:error:
visualSearchProperties
visualSearchData
setVisualSearchData:algorithmVersion:adjustmentVersion:
initWithPhotosAsset:clientBundleID:clientTeamID:
initWithPhotosAsset:pixelBuffer:orientation:clientBundleID:clientTeamID:
thumbnailResource
hasValidSceneProcessing
_resources
_highResPixelBuffer
_highResOrientation
_barcodeObservations
assetWithPixelBuffer:orientation:identifier:clientBundleID:clientTeamID:
assetWithURL:identifier:clientBundleID:clientTeamID:
assetWithImageData:uniformTypeIdentifier:identifier:clientBundleID:clientTeamID:
assetWithPhotosAsset:pixelBuffer:orientation:clientBundleID:clientTeamID:
setCachedParseData:
clientTeamID
_isHighResDecoded
T@"NSString",R,N,V_clientBundleID
T@"NSString",R,N,V_clientTeamID
T@"CLLocation",R,N
T@"NSArray",C,N,V_documentObservations
T@"NSArray",C,N,V_barcodeObservations
TB,R,N,V_hasCachedParseData
T@"NSData",C,N,V_cachedParseData
T{CGSize=dd},R,N,V_resolution
TI,R,N,V_orientation
TB,R,N,V_isHighResDecoded
normalization
_modelLandmarks
setupTrackerWithReferenceFrame:withROI:
trackInFrame:
lostTrackInd
_correlationTracker
_lostCount
_objectBoundsInitial
_objectBounds
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,V_objectBoundsInitial
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,V_objectBounds
Tf,R,N,V_confidence
T{?=qiIq},R,N,V_start
Ti,R,N,V_lostCount
originatingFace
faceCropData
creationRequestsForFaceCropsWithOriginatingFace:resourceData:
fetchFaceCropsWithLocalIdentifiers:options:
fetchFacesForFaceCrop:options:
normalizedRectForRect:inBoundsOfSize:
imageDimensions
initWithData:orientation:options:
_bestFaceForFaceDetectionRequest:withRect:
faceObservationWithRequestRevision:boundingBox:andAlignedBoundingBox:
setForceFaceprintCreation:
setFace:
_faceFromFaceCrop:error:
_clearDirtyStateOnFaceCrop:error:
_associateFace:withFaceCrop:error:
_updateFaceprint:forFace:error:
fetchFaceGroupsWithFace:options:
_faceAssociatedWithFaceCrop:
_generateAndAssociateFaceprintedFaceForFaceCrop:faceCropFaceLocalIdentifier:error:
_updateFace:withFaceCrop:error:
_recordNeedToPersonBuildOnFaceGroupContainingFace:error:
resourceData
initWithLocalIdentifier:faceCropData:
generateFaceCropsForFace:resourceURL:groupingIdentifier:
_persistGeneratedFaceCrops:forAsset:error:
fetchFaceCropsNeedingFaceDetectionWithOptions:
_vcpFaceCropFromPHFaceCrop:
_processDirtyFaceCrop:faceCropFaceLocalIdentifier:error:
_allowANE
generateAndPersistFaceCropsForFaces:withAsset:resource:resourceURL:error:
processDirtyFaceCrops:withCancelBlock:andExtendTimeoutBlock:
setDateFormat:
initWithLocaleIdentifier:
setLocale:
timeZoneForSecondsFromGMT:
setTimeZone:
stringFromDate:
_loadPersonsModelAndInitializeFaceAnalyzer
updateMissingFaceprintForFaces:withAsset:
_classifyFaces:forAsset:detectedPersons:
_loadPetsModel
setIncludedDetectionTypes:
isInVIPModel
associateFaceWithPersonUUID:
orPredicateWithSubpredicates:
_fetchPersonsToFeedVIPModel:allowUnverifiedPerson:
_fetchPetsToFeedVIPModel
fetchEntityForModelType:evaluationMode:allowUnverifiedPerson:
newConfigurationForEntityPrintsGeneratedByRequest:error:
modelWithConfiguration:error:
addObservations:toEntityWithUniqueIdentifier:error:
_persistPetsModel:error:
trainingObservationsForEntityWithUniqueIdentifier:canceller:error:
arrayByAddingObjectsFromArray:
setIsInVIPModel:
_persistPersonsModel:evaluationMode:error:
trainingFaceObservationsForPersonWithUniqueIdentifier:canceller:error:
_fastFaceMigrationEnabled
_faceProcessingPassGoalWithExtendTimeout:
_modelLastGenerationDidExceedTimeIntervalForType:
_keepCurrentPersonsModelWithExtendTimeout:
_needToGenerateModelWithType:ignoreLastGenerationTime:withExtendTimeout:
_generatePersonsModelWithExtendTimeoutBlock:cancel:evaluationMode:allowUnverifiedPerson:
_generatePetsModelWithExtendTimeoutBlock:cancel:
loadPersonsModelAndInitializeFaceAnalyzerWrapper
processAsset:onDemandDetection:detectedFaces:detectedPersons:
classifyVIPPets
personIdentificationForSyndicationPhotoLibrary:withCancelOrExtendTimeoutBlock:
generateVIPModelWithType:ignoreLastGenerationTime:evaluationMode:allowUnverifiedPerson:modelGenerated:extendTimeout:andCancel:
_personsModel
_petsModel
_management
initWithRevision:
sharedModelPoolWithRevision:
getRevision
calculateScoreFromNetworkOutputV2:
calculateScoreFromNetworkOutput:outChannel:outHeight:outWidth:textureness:contrast:imgWidth:
copyBufferFrom:fromStride:toPtr:toStride:toWidth:toHeight:
computeSharpnessScore:textureness:contrast:imgWidth:cancel:
_srcWidth
_srcHeight
numberValue
stringForObjectValue:
copyItemAtURL:toURL:error:
setIncludeAllBurstAssets:
_appendToSuggestionsLog:
suggestionsForPersonLocalIdentifier:clusterSequenceNumbers:excludePersonLocalIdentifiers:minimumSuggestionFaceCount:
updateKeyFacesOfPersonsWithLocalIdentifiers:forceUpdate:context:reply:
_closeSuggestionsLoggingSession
_startAndSyncClusterCacheWithLibrary:reply:
_openSuggestionsLoggingSession
faceClusterSequenceNumbersOfKeyFacesInAlgorithmicFaceGroupsForPerson:verifiedClusterSequenceNumbers:
_logFaceToSuggestionsLog:
_suggestionsForPersonLocalIdentifier:clusterSequenceNumbers:excludePersonLocalIdentifiers:cancel:context:error:
_finalizeSuggestionsLog
_suggestionsForPersonWithLocalIdentifier:toBeConfirmedPersonSuggestions:toBeRejectedPersonSuggestions:cancel:error:
removeItemAtPath:error:
requestSuggestedMePersonIdentifierAtURL:withError:
hasProcessedForLibrary:
initWithPhotoLibrary:andDelegate:
advancedStatus
setProcessed:forLibrary:
_deleteAllVerifiedPersonsWithError:
initWithPhotoLibrary:context:cancelOrExtendTimeoutBlock:
reclusterFacesWithThreshold:shouldRecluster:error:
workerWithPhotoLibrary:andContext:
_copyImageAtURLToSuggestionsLoggingSession:
suggestPersonsForPersonWithLocalIdentifier:toBeConfirmedPersonSuggestions:toBeRejectedPersonSuggestions:context:reply:cancel:
faceCandidatesforKeyFaceForPersonsWithLocalIdentifiers:context:reply:
resetPersonsModelWithReply:
resetPetsModelWithReply:
requestSuggestedMePersonIdentifierWithContext:reply:
personPromoterStatusWithContext:reply:
validateClusterCacheWithContext:cancelOrExtendTimeoutBlock:reply:
resetFaceClusteringStateWithContext:reply:
reclusterFacesWithContext:reply:extendTimeout:cancel:
rebuildPersonsWithContext:reply:extendTimeout:cancel:
_clusterer
_suggestionLoggingDirectory
_suggestionLoggingSessionOpen
_suggestionsLoggingEnabled
indexesOfObjectsPassingTest:
removeObjectsAtIndexes:
tracksWithMediaType:
isEnabled
availableMetadataFormats
metadataForFormat:
metadataItemsFromArray:withKey:keySpace:
initWithSampleBuffer:
metadataItemsFromArray:filteredByIdentifier:
generateCGImageAsynchronouslyForTime:completionHandler:
vcp_isShortMovie
vcp_isMontage
vcp_keyFrameWithMaxDimension:
initWithTrack:timerange:atInterval:
getNextCaptureSampleBuffer
_trackOutput
_decodeEnd
_sampleDuration
_nextSampleTime
_currentSample
_nextSample
faceArea
setFrameProcessedByHumanAnalyzer:
petsDetections
frameProcessedByPetsActionAnalyzer
setFrameProcessedByPetsActionAnalyzer:
petsActionScore
setPetsActionScore:
_frameProcessedByVideoAnalyzer
_subMbMotionAvailable
_frameProcessedByHumanAnalyzer
_frameProcessedByFaceDetector
_frameProcessedByPetsActionAnalyzer
_cameraMotionScore
_subjectActionScore
_colorfulnessScore
_frameExpressionScore
_faceArea
_petsActionScore
_videoActivityDescriptor
_motionParam
_motionParamDiff
TB,N,V_frameProcessedByVideoAnalyzer
Tf,N,V_cameraMotionScore
Tf,N,V_subjectActionScore
Tf,N,V_interestingnessScore
Tf,N,V_obstructionScore
Tf,N,V_colorfulnessScore
TB,N,V_subMbMotionAvailable
Tf,N,V_frameExpressionScore
Tf,N,V_faceArea
T{array<float, 6UL>=[6f]},N,V_motionParam
T{array<float, 6UL>=[6f]},N,V_motionParamDiff
TB,N,V_frameProcessedByHumanAnalyzer
TB,N,V_frameProcessedByFaceDetector
T@"NSMutableArray",&,N,V_petsDetections
TB,N,V_frameProcessedByPetsActionAnalyzer
Tf,N,V_petsActionScore
T@"VCPVideoActivityDescriptor",&,N,V_videoActivityDescriptor
vcp_isVideoTimelapse
vcp_setFlags:
vcp_setQuality:
vcp_setStatsFlags:
_summaryResults
_skip
computeVar:index2:interVar:intraVar:
scaleRect:scaleX:scaleY:
computeActionScore
intersectionOverUnion:rect:
processPets:petsBounds:dominantPetIdx:frame:timestamp:duration:
initWithFrameStats:timeOfInterest:
_poseAnalyzer
_timeLastProcessFullFrame
_maxScore
_endTime
_keyPetResults
_poseResults
_crop
_petRect
_actionScoreAbsolute
_actionScoreRelative
_scoreAbsoluteMax
_scoreRelativeMax
_lastPetTimestamp
_tracker
_tracking
_timeOfInterest
_sampleFlag
initWithTime:andScore:
timeStamp
_timeStamp
T{?=qiIq},R,N,V_timeStamp
Tf,R,N,V_score
initWithTimeRange:score:andKeyFrame:
T{?={?=qiIq}{?=qiIq}},R,N,V_timerange
T@"VCPVideoKeyFrameResult",R,N,V_keyFrame
phAsset
highlights
_phAsset
_highlights
T@"PHAsset",R,N,V_phAsset
T@"NSMutableArray",R,&,N,V_highlights
T@"NSMutableDictionary",&,N,V_results
decodeDimensionsForTrack:
validateDecodedFrame:withSettings:
_track
initWithFaceCropData:originatingFace:
_originatingFace
_cachedImageDimensions
_state
Ts,N,V_state
setEnergy:
setPeak:
energy
peak
URLForResource:withExtension:
modelWithContentsOfURL:error:
initWithModelName:
model
T@"MLModel",R,N,V_model
_numFilterTabs
_scoreArray
_distanceVariance
_diffVariance
_numOfScores
featureIdentifier
imageURL
referralURL
visualUnderstanding
imageRegions
domainInfo
domainKey
labelName
glyphName
hasFocalPoint
focalPoint
displayLabel
displayMessage
initWithDomain:label:glyphName:hasFocalPoint:focalPoint:displayLabel:displayMessage:
initWithNormalizedBoundingBox:andDomains:
payload
initWithResultItems:andPayload:
domains
initWithImage:annotation:normalizedRegionOfInterest:domainsOfInterest:queryContext:
storeResults:
parseWithVisualQuery:cachedResults:completion:
stringByAppendingFormat:
prepareModelWithFile:engine:config:error:
loadModel:
buildModelWithConfig:error:
freeModel
initWithThreshold:
setBlurDeterminationMethod:
setMaximumIntermediateSideLength:
warnings
setPrecisionRecallThreshold:
_faceprintFastMode
setDetectionLevel:
_checkAnalysisRequests:forTooSmallFaceObservations:withAnalysisResults:
_createBlurRequests:andExposureRequests:forFaceObservations:
null
_existingFacesFromAsset:
mergeExistingFaces:andDetectedFaces:withRequestHandler:orientedWidth:orientedHeight:assetWidth:assetHeight:
_downsampleBeforeFaceProcessing
vcp_isPano
vcp_targetMajorDimensionForImageWithWidth:height:andMinPreferredMinorDimension:
pixelBufferWithFormat:andMaxDimension:fromImageURL:flushCache:orientation:
_loadImageRequestHandler:orientation:bufferWidth:bufferHeight:withResource:resourceURL:andAsset:
_performAnalysis:withRequestHandler:quickMode:sourceWidth:sourceHeight:
refineAnalysis:requestHandler:forAsset:orientedWidth:orientedHeight:
analyzeAsset:withResource:resourceURL:quickMode:results:
observationWithRequestRevision:boundingBox:
vcp_quickFaceClassificationDone
analyzeFaceQuality:withAsset:andCancelBlock:
_faceMerger
assetResourcesForAsset:includeDerivatives:
isGuestAsset
uniformTypeIdentifier
typeWithIdentifier:
instancesRespondToSelector:
attributesOfItemAtPath:error:
fileSize
assetLocalIdentifier
vcp_hasExtremeAbnormalDimensionForScene
addDetectionFromTime:toTime:confidence:
request:didProduceResult:
request:didFailWithError:
requestDidComplete:
initWithTrackStart:threshold:resultsKey:
_activeStart
_activeEnd
_length
_activeConfidence
_minDetections
_resultsKey
classificationForIdentifier:
_activeScore
_audioQualityAggregated
initStandardFormatWithSampleRate:channels:
initWithFormat:
initWithPCMFormat:frameCapacity:
setFrameLength:
initWithSoundIdentifier:
addRequest:withObserver:error:
initWithClassifierIdentifier:error:
setWindowDuration:
frameLength
mutableAudioBufferList
analyzeAudioBuffer:atAudioFramePosition:
initWithTypes:
setupWithSample:trackDuration:andSampleBatchSize:
_SNAnalyzer
_detectors
_classifiers
setFaceprintBlob:
faceprintBlob
_faceprintBlob
TI,N,V_faceID
T@"NSData",&,N,V_faceprintBlob
inputSize
setInputSize:
outputSize
setOutputSize:
input
setInput:
setOutput:
context
generateOutput
setGenerateOutput:
_outputSize
_output
_generateOutput
_executedOnGPU
T@"NSMutableArray",W,V_inputSize
T@"NSMutableArray",&,V_outputSize
T@"VCPCNNData",W,V_input
T@"VCPCNNData",&,V_output
T@"VCPCNNMetalContext",R,V_context
TB,V_generateOutput
adjustmentTimestamp
maxSizeBytes
vcp_imagesPredicate:
vcp_nonPanoPredicate:
vcp_fullAnalysisPredatesVersionInternalPredicate:
vcp_livePhotosPredicate:
vcp_moviesPredicate:
vcp_originalSize
vcp_eligibleForVideoDownload:
vcp_needsProcessingForTask:
vcp_isSdofPhoto
setExcludeMontageAssets:
sceneAnalysisProperties
sceneAnalysisVersion
sceneAnalysisTimestamp
vcp_confidenceForSceneIdentifier:
vcp_abnormalImageDimensionForSceneNet
vcp_ocrGatingThreshold
vcp_isDownloadGated
vcp_passedOCRGating
catalogIDs
regionOfInterestResults
resultItems
objectKnowledge
knowledgeProperties
knowledgeGraphID
ontologyNode
thirdPartyObject
objectIdentifier
thumbnailURL
metadata
initWithObjectIdentifier:imageURL:thumbnailURL:metadata:
title
thumbnailAspectRatio
shortDescription
detailedDescription
webURL
initWithDomain:knowledgeGraphID:title:thumbnailURL:thumbnailAspectRatio:shortDescription:detailedDescription:webURL:knowledgeProperties:
setThirdPartyObject:
normalizedBoundingBox
searchSections
initWithNormalizedBoundingBox:regionAttributes:andSearchSections:
userFeedbackPayload
initWithResultItems:andUserFeedbackPayload:
gatingResultItems
initWithRegionOfInterest:domains:
gatingPayload
queryWithPixelBuffer:orientation:imageRegions:textBlockAnnotation:queryContext:payload:
searchWithParsedVisualQuery:completion:
queryWithPixelBuffer:orientation:normalizedRegionOfInterest:annotation:queryContext:
searchWithVisualQuery:completion:
normalizedRectForRect:inBounds:
rectFromMappingNormalizedRect:toBounds:
rectFromMappingNormalizedRect:toBoundsOfSize:
pointFromNormalizedPoint:inBounds:
analyzeFrame:withFaceBounds:
landmarks
_landmarks
setIsFast:
setMotionType:
isFast
motionType
vcp_imageOrientation
progressHandler
_analyzeWithStart:andDuration:error:
analyzeWithStart:andDuration:error:
setProgressHandler:
_session
_progressHandler
T@?,C,V_progressHandler
hasRecipeBlob
_recipeBlob
T@"NSData",&,N,V_recipeBlob
setColorNormalizationBlob:
hasColorNormalizationBlob
colorNormalizationBlob
_colorNormalizationBlob
_playbackCrop
T@"VCPProtoVideoKeyFrame",&,N,V_keyFrame
T@"VCPProtoBounds",&,N,V_playbackCrop
T@"NSData",&,N,V_colorNormalizationBlob
initWithParameters:NeuronType:
_weight
_bias
_numNeurons
_neuronType
calculateFrameDifference:
computeRegionsofInterest
regionsOfInterest
_regions
_diff
_ptrFirst
_ptrLast
_scaler
_frameArray
_frameWidth
_frameHeight
_blockSize
_widthBlockNum
_heightBlockNum
convertToOriginalTimeFromScaledTime:forExport:
vcp_convertToOriginalTimerangeFromScaledTimerange:
scaleTimeRange:toDuration:
vcp_scaleSlowmoTimeRange:withTimeMapping:inComposition:
initWithVideoAsset:videoAdjustments:
composition
insertTimeRange:ofAsset:atTime:error:
rampDown
rampUp
computeRampToTargetRate:forExport:outTimeSteps:outIntermediateRates:
slowMotionRampInRangeForExport:
slowMotionRampOutRangeForExport:
vcp_scaleRampWithIntervals:andRates:inSlowmoTimerange:withTimeMapping:inComposition:
tracks
removeTrack:
hasAction
setHasAction:
_hasAction
TB,N,V_hasAction
setMinX:
setMinY:
setMaxX:
setMaxY:
intersect:
union:
area
classIndex
setClassIndex:
_minX
_maxX
_minY
_maxY
_flag
_classIndex
Tf,V_minX
Tf,V_maxX
Tf,V_minY
Tf,V_maxY
Tf,V_flag
Ti,V_classIndex
initWithAssets:andOptions:andCompletionHandler:
deserializeStabilizationRecipeInAttributes:
_stabilizationType
_onDemandPixel
_onDemandGyro
getMaximumHighlightInSec
vcp_setVersion:
vcp_setDateModified:
initWithVCPAsset:withExistingAnalysis:forAnalysisTypes:
vcp_statsFlags
vcp_addEntriesFromResults:
vcp_syncPoint
vcp_setSyncPoint:
loadValuesAsynchronouslyForKeys:completionHandler:
vcp_addFlags:
vcp_addTypes:
initWithTrack:timerange:withSettings:applyTransform:
isTimelapse
exposureTimeSeconds
processExistingAnalysisForTimeRange:analysisTypes:
createDecoderForTrack:timerange:forAnalysisTypes:
createVideoAnalyzer:withFrameStats:
faceDetectorWithTransform:withExistingFaceprints:frameStats:tracking:faceDominated:cancel:
hadFlash
getEnableMovieHumanAction
getHumanActionClassiferType
initWithFrameStats:timeOfInterest:phFaces:
timelapseRate
vcp_fullFrameSize
postProcessAutoPlayable:
vcp_appendResults:
vcp_endTime
analyzeVideoSegment:timerange:forAnalysisTypes:cancel:
allowStreaming
loadPropertiesForAsset:
vcp_setDateAnalyzed:
initWithAnalysisTypes:forStreaming:
analyzeAsset:cancel:results:
performMetadataAnalysisOnAsset:withCancelBlock:
vcp_cleanApertureRect
storeAnalytics:isLivePhoto:
vcp_startTime
analyzeVideoTrack:start:forAnalysisTypes:cancel:
generateKeyFrameResource:
vcp_removeSyncPoint
vcp_addStatsFlags:
vcp_appendResult:forKey:
analyzerWithVCPAsset:withExistingAnalysis:forAnalysisTypes:
initWithPHAsset:withPausedAnalysis:forAnalysisTypes:
setAllowStreaming:
maxHighlightDuration
faceDominated
setFaceDominated:
_analysis
_supportConditionalAnalysis
_existingAnalysis
_prepareLivePhotoScenes
_generateVideoCaption
_allowStreaming
_maxHighlightDuration
TB,N,V_allowStreaming
Tf,N,V_maxHighlightDuration
TB,N,V_faceDominated
Tq,R,V_status
detector:forceCPU:sharedModel:inputConfig:revision:
detector:sharedModel:modelName:
indexOfObject:inSortedRange:options:usingComparator:
getClosestAspectRatio:
updateModelWithResConfig:
handsDetection:handsRegions:cancel:
handKeypointsDetection:box:keypoints:keypointConfidence:forGFT:
convertSingleResultToDict:keypointConfidence:box:results:
_handsDetector
_handsKeypointsDetector
initWithRequests:forAsset:cancelBlock:andCompletionHandler:
_subtasks
_longExposureSuggestionState
_loopSuggestionState
TQ,N,V_loopSuggestionState
TQ,N,V_longExposureSuggestionState
analyzer
sdof
TB,V_sdof
initWithDatabaseReader:forAssets:resultsTypes:batchSize:
nextBatch
iteratorForAssets:withDatabaseReader:resultTypes:batchSize:
next
analysis
_resultsTypes
_batchSize
_idxLast
_idxCurrent
_batchAnalyses
T@"PHAsset",R,N,V_asset
T@"NSDictionary",R,N,V_analysis
T@"VCPProtoTime",&,N,V_start
T@"VCPProtoTime",&,N,V_duration
initWithMovingObjectsResults:
_movingObjects
newTextureWithDescriptor:
texture2DDescriptorWithPixelFormat:width:height:mipmapped:
setUsage:
newTextureWithDescriptor:iosurface:plane:
newBufferWithIOSurface:
newLinearTextureWithDescriptor:offset:bytesPerRow:bytesPerImage:
getBytes:bytesPerRow:bytesPerImage:fromRegion:mipmapLevel:slice:
setTextureType:
setArrayLength:
replaceRegion:mipmapLevel:slice:withBytes:bytesPerRow:bytesPerImage:
initWithURLAsset:withOptions:analysisTypes:progressHandler:completionHandler:
analyzerWithVCPAsset:forAnalysisTypes:
_noResultStrip
_assetURL
_pairedAssetURL
fetchPersonAssociatedWithFaceGroup:options:
faceCountInFaceGroup
isDirty
clearFrameInstructions
frameInstructionsAtIndex:
frameInstructionsType
setHasEpoch:
hasEpoch
setHasFlags:
hasFlags
setFrameInstructions:
_outputFrameDurValue
_autoloop
_bounce
_cropRectHeight
_cropRectWidth
_cropRectX
_cropRectY
_frameInstructions
_longexposure
_minVersion
_stabilize
_stabilizeResult
Ti,N,V_stabilizeResult
Tq,N,V_outputFrameDurValue
Ti,N,V_cropRectX
Ti,N,V_cropRectY
Ti,N,V_cropRectHeight
Ti,N,V_cropRectWidth
T@"NSMutableArray",&,N,V_frameInstructions
T@"VCPProtoLivePhotoVariationParams",&,N,V_autoloop
T@"VCPProtoLivePhotoVariationParams",&,N,V_bounce
T@"VCPProtoLivePhotoVariationParams",&,N,V_longexposure
T@"VCPProtoLivePhotoVariationParams",&,N,V_stabilize
Ti,N,V_minVersion
Ti,N,V_version
setupWithSample:andTrackDuration:
processSampleBuffer:
analyzeSampleBuffer:
_inputBuffer
_audioTimestamp
_audioBufferList
_voiceDetector
_audioClassifier
_songDetector
_bufferedSamples
_initialized
copyImage:toData:
createInput:withBuffer:cnnInputHeight:cnnInputWidth:faceBounds:
_readFaceAnalysisState
initWithContentsOfFile:
writeToFile:atomically:
_setFaceAnalysisStateValue:forKey:
setChunkSizeForFetch:
setLastMinimumFaceGroupSizeForCreatingMergeCandidate:
_setAllFaceGroupsNeedPersonBuilding
setPersonBuilderMergeCandidatesEnabled:
clusterer
initWithPhotoLibrary:andFaceClusterer:andContext:
performPersonBuildingWithCancelOrExtendTimeoutBlock:error:
_faceClusterer
_lastMinimumFaceGroupSizeForCreatingMergeCandidates
_personBuilderMergeCandidatesEnabled
initWithMaxNumRegions:forceCPU:sharedModel:inputConfig:
personDetection:personRegions:cancel:
_personKeypointsDetector
_statisticsBlob
T@"NSData",&,N,V_statisticsBlob
minimumAspectRatio
setMinimumAspectRatio:
maximumAspectRatio
setMaximumAspectRatio:
quadratureTolerance
setQuadratureTolerance:
minimumSize
setMinimumSize:
minimumConfidence
setMinimumConfidence:
maximumObservations
setMaximumObservations:
valueWithSize:
_includeMeme
_includeDocument
initWithBufferWidth:bufferHeight:andPixelFormat:
initWithMonochromeBufferCreator:
_includeRotation
vcp_sharedModelWithModelName:
_configureRequest:
maximumLeafObservations
setMaximumLeafObservations:
maximumHierarchicalObservations
setMaximumHierarchicalObservations:
_useR14J9
_includeDO
_includeSO
_includeLM
_configureRequest:withRevision:
_includeNSFW
_includeSE
_includeSDG
_includeWP
setReturnAllResults:
defaultMetalDevice
textElements
setRecognize:
machineReadableCodeElements
documentElements
_includePA
_includeCN
_includeDMF
_isMovieWithMediaType:
hasPrefix:
nodeForName:
sceneClassId
_processBoundingBoxFromDetectedObjects:forSceneClassID:
_insertBoundingBox:toSortedBoundingBoxes:
highPrecisionThreshold
highRecallThreshold
searchThreshold
detectors
_extractAndSortBoundingBoxFromDetectedObjects:
_parseClassificationObservations:toClassificationResults:
_parseClassificationObservations:withPrefix:toClassificationResults:
lowercaseString
characterAtIndex:
_generateSceneClassifications:fromRequests:
_obfuscateLabelName:
aestheticScore
wellFramedSubjectScore
wellChosenBackgroundScore
tastefullyBlurredScore
sharplyFocusedSubjectScore
wellTimedShotScore
pleasantLightingScore
pleasantReflectionsScore
harmoniousColorScore
livelyColorScore
pleasantSymmetryScore
pleasantPatternScore
immersivenessScore
pleasantPerspectiveScore
pleasantPostProcessingScore
noiseScore
failureScore
pleasantCompositionScore
interestingSubjectScore
intrusiveObjectPresenceScore
pleasantCameraTiltScore
lowKeyLightingScore
narrowedBoundingBox
salientObjects
elementType
elementCount
fingerprintHashes
hashData
appendData:
_createRequests:withMediaType:
sourcePixelBuffer
_includeIVS
generateClassificationScoresForPixelBuffer:error:
sizeValue
pixelBuffer:width:height:
_performWallpaperAnalysis:withSceneprint:
_collectSceneAnalysisResults:fromRequests:wpResults:ivsResults:abnormalDimension:
createPixelBuffer:
_getSHRevision
_performBlurAnalysis:withPixelBuffer:usingAnalyzer:
inputFeatureName
predictionFromFeatures:error:
outputFeatureName
multiArrayValue
numberWithShort:
_performSceneAnalysis:image:mediaType:mediaSubtypes:abnormalDimension:
_isSDOFWithMediaType:andMediaSubtypes:
_performBlurAnalysis:withLumaPixelBuffer:abnormalDimension:isSDOF:
_performExposureAnalysis:withLumaPixelBuffer:
_performRotationAnalysis:withColorPixelBuffer:
_nonPanoPreWarmDimensions
loadImageURL:abnormalDimension:withNonPanoPreWarmSizes:toColorPixelBuffer:lumaPixelBuffer:andImage:
_enableSceneAssetConcurrency
_performAnalysis:mediaType:mediaSubtypes:abnormalDimension:colorPixelBuffer:andLumaPixelBuffer:image:
_isPanoWithMediaType:andMediaSubtypes:
analyzeWithImageURL:mediaType:mediaSubtypes:abnormalDimension:completionHandler:
_imageLoader
_monochromeBufferCreator
_rotationModel
_rotationBufferCreator
_ivsPool
track
_decoderSettings
createInput:withBuffer:cnnInputHeight:cnnInputWidth:box:
parseKeypoints:
initWithVertices:vertexCount:
supportsSecureCoding
encodeWithCoder:
initWithCoder:
TB,R
vertices
_vertices
TQ,R,N,V_vertexCount
Tr^,R,N
getBytes:length:
initWithTransform:blendShapes:geometry:
transform
geometry
_blendShapes
_geometry
T{?=[4]},R,N,V_transform
T@"NSDictionary",R,N,V_blendShapes
T@"VCPFaceGeometry",R,N,V_geometry
initWithFocalLengthInPixels:offline:isFastMode:
initWithFocalLengthInPixels:
initWithAnalysisTypes:withPreferredTransform:withFocalLengthInPixels:withAnalysisQueue:withTurbo:
transformForAngle:pixelBuffer:
analyzeFrameForPose:withFaceRect:withTimestamp:
rotateTransform:byAngle:
analyzeFrame:withFaceRect:withRotation:withTimestamp:
isTracked
isSegmentPoint
analyzeFrameWithTimeRange:analysisData:
shouldCutAt:stillPTS:withCut:
analyzerForAnalysisTypes:withPreferredTransform:properties:
aggregateAnalysisForTypes:withFramesMeta:properties:
prewarmWithProperties:
updatePreferredTransform:properties:
analyzePixelBuffer:withTimestamp:andDuration:properties:error:
analyzePixelBuffer:withTimestamp:andDuration:properties:completion:
analyzeAudioBuffer:
aggregatedResults
_meshAnalyzer
_videoAnalysis
_audioAnalyzer
_faceDetector
_sceneChangeAnalyzer
_lightMotionAnalyzer
_trimAnalyzer
_homeKitMotionAnalyzer
_rotator
_rotatorForFacePose
_preferredTransform
_focalLengthInPixels
_aggregatedResults
_rotationAngleForFacePose
_preferredAngle
_analysisQueue
_preWarmed
createInput:keypoints:
getDetectionScore:
planDestroy
gestureDetection:score:
enableR2D2
convertFlow:
prepareAnalyzerWithCVPixelBuffer:cancel:
preProcessing:
generateMotionFlow
generateSubleMotionScore:
subtleMotionScore
_scale
_moflowRequest
_downScaleWidth
_downScaleHeight
_flowWidth
_flowHeight
_frameNum
_useR2D2
_subtleMotionScore
Tf,R,V_subtleMotionScore
initWithFlagHasFaceOrPet:
usePHAssetScene
initWithAnalysisResults:
analyzeAsset:onDemand:cancel:statsFlags:results:
_hasFaceOrPet
initWithTransform:frameStats:faceDominated:
_angle
createGaborFilterKernel:sigmaX:sigmaY:lambda:thetaInDegree:phaseInDegree:
_filterBanks
_numScales
_numOrientations
_num
_setupMediaAnalysisServiceConnection
storeAnalysis:forAsset:fromPhotoLibraryURL:withReply:
registerClient:forPhotoLibraryURL:withReply:
_getSandboxExtensionForMediaAnalysisDatabaseWithPhotoLibraryURL:
vcp_setResult:forKey:
vcp_fullAnalysisTypesForResources:
_postProcessMovieHighlights:analysis:withOptions:
_addClassificationResults:analysis:
vcp_fingerprint
_metaAnalysisTypesForAsset:
_analyzeOndemand:forAnalysisTypes:withExistingAnalysis:andOptions:storeAnalysis:cancelBlock:
sharedMediaAnalyzer
_databaseForPhotoLibrary:
_requestAnalysis:forAsset:withExistingAnalysis:andDatabase:andOptions:cancelBlock:
assetsFromPhotoLibrary:analyzedSinceDate:completionHandler:
sceneprintProperties
sceneprint
_getSceneDescriptors:asDescriptorClass:withSceneRange:andAnalysisResults:
_getDistanceDescriptorClass
_checkDuplicate:withAsset:duplicate:
_queryDistanceDescriptor:ofAsset:withExistingAnalysis:andDatabase:timeRange:lastFeature:isDegraded:
computeDistance:fromArray:toArray:
computeDistance:withDescriptorClass:fromAsset:toAsset:
canRenderVariation
canUseLastFrameOfAsset:withResources:
generateDistanceDescriptor:withDescriptorClass:forAsset:withResources:lastFrame:
arrayWithObject:
_typesToRemove:requested:
requestAnalysis:forAssets:withOptions:andProgressHandler:andCompletionHandler:
requestAnalysisTypes:forAssets:withOptions:andProgressHandler:cancelBlock:analyses:
requestAnalysis:forAssets:withOptions:andProgressHandler:andError:
sortedArrayUsingSelector:
personModelFilepathForPhotoLibrary:
loadPersonModelAtPath:error:
faceprintRevisionForPersonModel:
classifyFaceObservation:withPersonsModel:error:
_getDatabaseSandboxExtensionForPhotoLibraryURL:
requestAnalysisTypes:forAssetWithResourceURLs:withOptions:error:
analyzeOndemand:pairedURL:forAnalysisTypes:error:
requestAnalysisForAsset:analysisTypes:progressHandler:completionHandler:
cancelAnalysisWithRequestID:
assetsAnalyzedSinceDate:completionHandler:
distanceFromAsset:toAsset:duplicate:distance:
distanceFromAsset:timeRange:toAsset:timeRange:duplicate:distance:
requestAnalysesForAssets:analysisTypes:allowOndemand:progressHandler:completionHandler:
requestAnalysisTypes:forAssets:allowOndemand:progressHandler:error:
curateMovieAssetsForCollection:withAlreadyCuratedAssets:andDesiredCount:allowOnDemand:
requestMovieHighlightsForAssets:withOptions:
postProcessMovieHighlightDuration:withOptions:
requestLivePhotoEffectsForAssets:allowOnDemand:flags:
completeStorage
_storageQueue
_storageGroup
_standalone
_minHighlightDuration
_mediaAnalysisServiceConnection
_sandboxQueue
_sandboxHandles
_cancelTokens
initWithAssets:options:andCompletionHandler:
imageManager
loadFullPixelBuffer:scaledPixelBuffer299:scaledPixelBuffer360:fromImageURL:abnormalDimension:
_panoVNRequestMethod
approximateLocation
coordinate
gpsHorizontalAccuracy
approximateCoordinate
isCoarse
startDate
endDate
estimatedAssetCount
mad_isExpectedTaxonomy
latestTaxonomyIdentifier
initWithIdentifier:error:
hadZoom
setHadZoom:
minZoom
setMinZoom:
maxZoom
setMaxZoom:
_minZoom
_maxZoom
TB,N,V_hadZoom
Tf,N,V_minZoom
Tf,N,V_maxZoom
readGyroHomographyDimension:
gyroHomographyVersionIsValid:
readSoftwareStackVersion:
referenceSoftwareStackVersion
compareSoftwareStackVersion:withReferenceVersion:
getSetupDataFrom:
getFirstAtomWithFourCharCode:fromSetupData:
compareNumericVersion:withReferenceVersion:
componentsSeparatedByString:
numberFromString:
numberWithChar:
numberWithUnsignedChar:
increaseLengthBy:
resetBytesInRange:
mutableBytes
convertLivePhotoStruct:toDictionary:
dataType
dataValue
convertLivePhotoBinary:toDictionary:
defaultDesiredKeys
initWithRequestAnalyses:formatDescription:
_prevEstimatedCenterMv
_deSerializedMetaBuffer
_metaFocusAnalyzer
_metaMotionAnalyzer
_requestAnalyses
_metadataStabilizationArray
_frameTimestampArray
_originalFrameTimestampArray
_metadataItemTimestampArray
_adjusterArray
_interpolatedFrameArray
_metaLensSwitchAnalzer
_gyroHomographyIsValid
_gyroHomographyDimension
cnnDataClass
initWithGPUContext:
initWithParameters:height:width:context:
bufferAllocCPU
cnnData
randInit
convertCPUData2GPU
convertGPUData2CPU
reallocGPUTemporalBuffers
copyImage:withChunk:
setData:
isInputOutput
setIsInputOutput:
setContext:
_isInputOutput
T@"NSMutableArray",&,V_size
T^f,V_data
TB,V_isInputOutput
T@"VCPCNNMetalContext",W,V_context
Transform
_mapWidth
_mapHeight
_accumulator
_accWidth
_accHeight
_accHalfHeight
_angleStep
_peopleThreshold
mad_nonPrioritizedAssetsForFaceDetectionInternalPredicate
vcp_stillImagesPredicate:
mad_internalPredicateForTaskID:
mad_internalPredicateWithPriority:forTaskID:
mad_internalPredicateNeedsProcessingForTaskID:
initFromConfigFile:numStage:numLandmarks:numTreePerStage:depthOfTree:numFeatures:
detectLandmark:width:height:stride:facerect:prevResult:result:
calculateFaceRectFromPrevLM:result:numOfLandmarks:
_internalLandmarkDetector
_numOfLandmarks
convBlockClass:
_filterSize
_filterNum
_filter
_reLU
_padding
_padSize
_groups
_batchNorm
T@"VNSession",R,N
addBounds:
boundsCount
boundsAtIndex:
initWithMaxNumRegions:forceCPU:sharedModel:inputConfig:revision:
createModelWithResConfig:
generateHandsRegions:boxes:maxNumRegions:
retrieveBoxes:outHeight:outWidth:boxes:anchorBox:
drawLine:width:height:stride:point0:point1:drawPoint:
createInput:withBuffer:
generateHandsBoxes:
drawRectangle:width:height:stride:keypoints:
_cnnInputWidth
_cnnInputHeight
_numClass
modelDescription
inputDescriptionsByName
imageConstraint
pixelsWide
pixelsHigh
pixelFormatType
outputDescriptionsByName
inputPixelFormat
_inputPixelFormat
_inputFeatureName
_outputFeatureName
Tq,R,N,V_inputSize
TI,R,N,V_inputPixelFormat
T@"NSString",R,N,V_inputFeatureName
T@"NSString",R,N,V_outputFeatureName
useCPUOnly
_useCPUOnly
_maxNumHands
_humanActionWindowSize
_motionFlowComputationAccuracy
TB,R,N,V_useCPUOnly
TI,R,N,V_revision
objectID
_computeFingerPrintsOfAsset:completionHandler:
fetchAssetsMatchingAdjustedFingerPrint:photoLibrary:
fetchAssetsMatchingMasterFingerPrint:photoLibrary:
vcp_fetchAssetsMatchingFingerprint:forPhotoLibrary:
TI,N,V_identifier
URLWithString:
resourceLoader
setDelegate:queue:
contentInformationRequest
setContentType:
setContentLength:
setByteRangeAccessSupported:
dataRequest
requestedOffset
requestedLength
respondWithData:
finishLoading
resourceLoader:shouldWaitForLoadingOfRequestedResource:
resourceLoader:shouldWaitForRenewalOfRequestedResource:
resourceLoader:didCancelLoadingRequest:
resourceLoader:shouldWaitForResponseToAuthenticationChallenge:
resourceLoader:didCancelAuthenticationChallenge:
Ti,N,V_faceID
textureness
setTextureness:
hasFlash
setHasFlash:
stillTime
setStillTime:
_stillTime
_textureness
_hasFlash
Tf,N,V_textureness
TB,N,V_hasFlash
Tf,N,V_stillTime
supportedImageSizeSet
pixelsWideRange
idealDimension
pixelsHighRange
T@"NSValue",R,N
_configureRequestWithRevision:
vcp_sceneRequestWithRequestClass:andRevision:
vcp_sceneRequest
vcp_sceneRequestForWallpaper
preferredLanguages
initWithBytesNoCopy:length:deallocator:
dataWithLength:
setNetworkAccessAllowed:
setDownloadIsTransient:
_reportDownload:
requestDataForAssetResource:options:dataReceivedHandler:completionHandler:
cancelDataRequest:
flush
setCancel:
_mutex
_semaphore
_dataTask
T@?,C,N,V_cancel
_minSize
_transformedImageWidth
_transformedImageHeight
isScoreValid:
decideSegmentPointUsingHinkleyDetector:
isActive:
updateActiveThreshold
mergeSameTypeSegments
printSegments:
prepareTrimmingWithTrimStart:andTrimEnd:
mergeConsecutiveShortSegments
mergeSparseShortSegments
analyzeFrameWithTimeRange:andActionScore:
decideSegmentPointBasedOnActionScore:
finalizeWithDestructiveTrimStart:trimEnd:
postProcessSegmentsWithCaptureTime:trimStart:
segments
activeSegment
_activeHinkleyDetector
_activeThreshold
_firstFrame
_postProcessStart
unsignedLongValue
vcp_streamedVideo
vcp_queryActionResultForPHFace:
vcp_mutableResults
vcp_removeResultForKey:
vcp_time
initWithLightweightOption:aspectRatio:computationAccuracy:forceCPU:sharedModel:flushModel:cancel:
newCommandQueue
filterDescriptorWithWidth:height:arrayLength:kernelSpatialDiameter:kernelTemporalDiameter:epsilon:sourceChannels:guideChannels:preallocateIntermediates:
initWithDevice:filterDescriptor:
encodeToCommandBuffer:sourceTexture:destinationTexture:
encodeToCommandBuffer:sourceTextureArray:guidanceTexture:constraintsTextureArray:numberOfIterations:destinationTextureArray:
combineBufferTo:flowX:flowY:
_cnnOutputHeight
_cnnOutputWidth
_computationAccuracy
_device
_commandQueue
_bilinearScale
_guidedFilter
Ti,R,N,V_cnnOutputHeight
Ti,R,N,V_cnnOutputWidth
sharedPhotoLibrary
systemPhotoLibraryURL
openAndWaitWithUpgrade:error:
registerAvailabilityObserver:
unregisterAvailabilityObserver:
close
closedefaultPhotoLibrary
photoLibraryDidBecomeUnavailable:
_defaultPhotoLibraryURL
_defaultPhotoLibrary
thumbnailSizeForAsset:withResources:
imageForResource:pixelFormat:
imageForResource:pixelFormat:maxDimension:
_generateLastFrameDistanceDescriptor:withDescriptorClass:forAsset:
_getThumbnailForAsset:withResouces:andPixelFormat:
addClusterPrecision:forPersonID:personFaceCount:validFaceCount:identitySize:
addIdentityRecallToGroundTruth:forPersonID:personFaceCount:identitySize:
addIdentityRecallExcludeMissDetection:forPersonID:personFaceCount:identitySize:
weightedAveragePrecision
setWeightedAveragePrecision:
weightedAverageRecall
setWeightedAverageRecall:
numSingletons
setNumSingletons:
numValidSingletons
setNumValidSingletons:
precisionPerCluster
setPrecisionPerCluster:
recallPerPersonToGroundTruth
setRecallPerPersonToGroundTruth:
recallPerPersonExcludeMissDetection
setRecallPerPersonExcludeMissDetection:
_weightedAveragePrecision
_weightedAverageRecall
_numSingletons
_numValidSingletons
_precisionPerCluster
_recallPerPersonToGroundTruth
_recallPerPersonExcludeMissDetection
Tf,V_weightedAveragePrecision
Tf,V_weightedAverageRecall
Tf,V_numSingletons
Tf,V_numValidSingletons
T@"NSMutableArray",&,V_precisionPerCluster
T@"NSMutableArray",&,V_recallPerPersonToGroundTruth
T@"NSMutableArray",&,V_recallPerPersonExcludeMissDetection
_groundTruthURL
_loadGroundTruthURL:toGroundTruth:error:
_loadGroundTruth:error:
curationProperties
addedDate
_dumpFaceprint
_processFetchedFaceGroup:forPersonID:facesPerAsset:assetInformation:extendTimeoutBlock:cancelBlock:
_fetchPersonWithIdentifier:facesPerAsset:assetInformation:extendTimeoutBlock:cancelBlock:
localizedStringFromDate:dateStyle:timeStyle:
_fetchPeopleHomePersons
_overlapRatioOf:with:
_dumpAssetsToFaces
_exportAssetsToFacesDetails:
countForObject:
fetchFaces
arrayWithContentsOfURL:
_parseGroundTruthWithURL:faceCountPerPerson:personInformation:faceToPerson:assetToFaces:extendTimeoutBlock:cancelBlock:
_measureClusterWithClusterStateURL:groundTruthFaceCountPerPerson:groundTruthPersonInformation:groundTruthFaceToPerson:groundTruthAssetToFaces:measures:extendTimeoutBlock:cancelBlock:
_measurePVPersonClusters:groundTruthFaceCountPerPerson:groundTruthPersonInformation:groundTruthFaceToPerson:groundTruthAssetToFaces:measures:extendTimeoutBlock:cancelBlock:
_reportCoreAnalyticsWithVisionClusterMeasure:personClusterMeasure:personClusters:andGroundTruthInformation:
calculateAndReportClusterAccuracyWithVisionClusterURL:andPersonClusters:withGroundtruth:results:extendTimeoutBlock:cancelBlock:
dataWithContentsOfURL:options:error:
stringByDeletingPathExtension
_parseSIMLGroundTruthWithURL:faceCountPerPerson:personInformation:faceToPerson:assetToFaces:extendTimeoutBlock:cancelBlock:
exportClustersStates:error:extendTimeoutBlock:cancelBlock:
compare:options:
workerWithPhotoLibrary:
optInPersonCount
_anonymizedName:
optInStatus:error:
optInPerson:error:extendTimeoutBlock:cancelBlock:
calculateAndReportClusterAccuracyWithVisionClusterURL:andPersonClusters:results:extendTimeoutBlock:cancelBlock:
validateClusterAccuracyWithSIMLGroundtruth:results:extendTimeoutBlock:cancelBlock:
_detectionVersion
_recognitionVersion
_personClusterVersion
_clusterDumpFaceFetched
Td,N,V_x
Td,N,V_y
vcp_captureDeviceMake
vcp_scaledExposureTime
vcp_flashFired
vcp_captureDeviceModel
vcp_isAppleCapture
dynamicForward:paramFileUrl:cancel:
_modelURL
reportIdentifier
initWithImage:payload:reportIdentifier:
submitUserFeedback:completion:
T@"NSDictionary",R,&,N
setAttributesFromLegacyDictionary:
setResults:withClass:forPropertyKey:
exportResultsWithPropertyKey:toLegacyDictionary:withKey:
imageAnalysisFromLegacyDictionary:
movieAnalysisFromLegacyDictionary:
_location
T{CGPoint=dd},N,V_location
relativeActionScore
absoluteActionScore
_relativeActionScore
_absoluteActionScore
T@"NSArray",&,N,V_keypoints
Tf,N,V_relativeActionScore
Tf,N,V_absoluteActionScore
Ti,N,V_personID
Ti,N,V_revision
chirality
setChirality:
_chirality
Ti,N,V_chirality
Ti,N,V_handID
T^{__CVBuffer=},N,V_pixelBuffer
rectFromPHFace:
createInput:withBuffer:cnnInputHeight:cnnInputWidth:crop:
aggregateWith:
initWithPHFaces:existingResults:
_existingResults
_phFaces
addKeypointsToNSArray:keypointConfidence:handBox:keypointsArray:
fastSignLanguageDetection:ofPixelBuffer:withMetadata:
priorityAnalysis
calculatePriorityScore:ofPixelBuffer:withMetadata:
_prevComputedScore
_rotationAngle
_frameCounter
_dominantHand
_handChiralityCounter
_handDetectedInPreviousFrame
_fastGestureDetector
_prevFrameHandKeypoint
_prevTimeStampHandDetected
_prevTimeSignLanguageDetected
_frameEndTimeStamp
_frameStartTimeStamp
_classIndexTracker
_handKeypointTracker
_leftHandKeypointTracker
_rightHandKeypointTracker
_singleFrameExecutionTime
_prevHandCenter
makeValidationDecision
updateIntrinsicWhenRotated
setFrame:
checkResolutionChange:withRotation:
validateFace:eulerAngles:
rotateLandmarks:width:height:landmarks:numLandmarks:
mapToCameraNegativeZ
bufferRotated
_faceCount
_faceBounds
_inDetectionMode
_lmDetector
_lmTracker
_prevLM
_curLM
_detectionModeCounter
_trackingModeCounter
_lostTrackCounter
_angleStable
_validationScore
_validateFailedOnce
_validationQueue
_validationGroup
_valBuffer
_valBufferRotated
_valAngle
_valLM
_shapeModel
_faceValidator
_offline
_bufferRotated
_pose
T{?=[4]},R,N,V_pose
Tr^f,R,N
TB,R,N,V_bufferRotated
convertPixelBuffer:toPixelFormat:flushCache:
loggingEnabled
drawImage:pixelFormat:withOrientation:maxDimension:pixelBuffer:
acceleratedDecodeImageData:pixelFormat:maxDimension:pixelBuffer:orientation:flushCache:
decodeImageSource:withUniformTypeIdentifier:pixelFormat:maxDimension:orientation:pixelBuffer:
dataForResource:
_exportReencodedJPEG
allowFastPathDecodeWithUniformType:pixelWidth:andPixelHeight:
pixelBufferWithFormat:fromImageURL:flushCache:
flushCache
compressCVPixelBuffer:toJPEGData:targetBitStreamLength:padding:
_encodeSession
_decodeSession
_transcodeQueue
_std
_mean
_voiceActivityNew
_audioUnit
_motionType
_isFast
Ti,N,V_motionType
TB,N,V_isFast
setInputBoundsX:
setInputBoundsY:
setInputBoundsWidth:
setInputBoundsHeight:
setSourceSizeWidth:
setSourceSizeHeight:
addTimeValue:
addHomographyParams:
timeValuesCount
inputBoundsX
inputBoundsY
inputBoundsWidth
inputBoundsHeight
sourceSizeWidth
sourceSizeHeight
timeValues
sharedModel:inputNames:properties:
sharedModelStage1:inputNames:properties:
_actions
_taxonomy
_modelEspressoStage1
focusStatus
addSegmentToResults
initWithFocusStatus:atTime:
setFocusStatus:
_focusStatus
Tq,V_focusStatus
_energy
_peak
Td,N,V_energy
Td,N,V_peak
initWithPixelBuffer:
setCount:
_count
T^{__CVBuffer=},R,N
TQ,N,V_count
scalePixelBuffer:toPixelBuffer:width:height:
preWarmWidth:andHeight:
_scaledPixelBuffers
_sourcePixelBuffer
T@?,R,N,V_completionHandler
requestAnalysis:ofFragmentData:withRequestID:properties:andReply:
requestAnalysis:ofFragmentSurface:withRequestID:properties:andReply:
requestIdentification:forFaceCrop:withOptions:andReply:
requestResidentMaintenance:withOptions:andReply:
expectedClasses
requestAnalysis:ofAssetData:withProperties:progressHandler:andCompletionHandler:
requestAnalysis:ofAssetSurface:withProperties:progressHandler:andCompletionHandler:
requestIdentificationForFaceCrop:withOptions:andCompletionHandler:
requestResidentMaintenanceWithOptions:andCompletionHandler:
initWithFace:andFace:distance:
pairWithFace:andFace:distance:
face1
face2
distance
_face1
_face2
_distance
T@"VCPPhotosFace",R,N,V_face1
T@"VCPPhotosFace",R,N,V_face2
Td,R,N,V_distance
observationWithBoundingBox:
initWithFaceObservations:
_faceObservationsWithBoundingBoxFromFaces:withFaceHashMapping:
_alignFaceObservations:withRequestHandler:error:
alignedBoundingBoxAsCGRect
_alignBoundingBoxOfFaces:withRequestHandler:orientedWidth:orientedHeight:
_sortedViableFaceMergePairsFromQueryFaces:andCandidateFaces:
sortedViableMergeCandidateFacesFor:from:ignoreSourceAssetDimensions:matchScores:
_mergeDistanceThreshold
createFaceHeatMap:imageFaces:
computeOverallFaceQualityScore:
selectKeyFrameRangeWithMotion:stillTimestamp:isMetaMotion:
fetchAndComputeScoreForKeyFrame:withResult:
computeScoreForPhoto:withRefKeyFrame:
reportLivePhotoKeyFrameAnalysisResults:selectedKeyFrame:originalStillKeyFrame:stillScore:stillFQScore:stillTimestamp:useSemanticOnly:isKeyFrameSuggested:
getFaceHeat:
updateFaceHeatMap:
initWithWidth:height:
analyzeLivePhotoKeyFrame:irisPhotoOffsetSec:originalIrisPhotoOffsetSec:photoTextureScore:hadFlash:cancel:
_photoSharpnessReliable
_photoSharpness
_petsDominant
_ignoreFace
_faceHeatMap
generatePersonRegions:boxes:maxNumRegions:
createInput:withBuffer:inputHeight:inputWidth:
generatePersonBoxes:
_outputsData
_createPixelBufferPool:withBufferWidth:bufferHeight:andPixelFormat:
_bufferWidth
_bufferHeight
valueWithBytes:objCType:
initWithOptions:andExistingResults:
exportWallpaperForAsset:cancel:results:
upgradeWallPaperAtURL:toURL:cancel:results:
initWithFaceResults:
started
_elapsedTimeSeconds
Td,R,V_elapsedTimeSeconds
TB,R,V_started
createModelWithHeight:srcWidth:
parsePersons:width:height:
processPersons:width:height:
createInput:withBuffer:modelInputHeight:modelInputWidth:
generateHumanPose:
saveKeypoints
trackingMode
setTrackingMode:
_saveKeypoints
_trackingMode
TB,V_trackingMode
resetFaceClusteringState:
scheduleClusteringOfFacesWithLocalIdentifiers:
scheduleUnclusteringOfFacesWithClusterSequenceNumbers:
numberOfFacesPendingClustering
getFaceClusters:clusteringThreshold:utilizingGPU:cancelOrExtendTimeoutBlock:error:
clustererIsReadyToReturnSuggestions
_resetFaceClusteringState:
clusterFacesIfNecessary
_cancelOrExtendTimeoutBlock
configureGPU
newDefaultLibraryWithBundle:error:
newFunctionWithName:
newComputePipelineStateWithFunction:error:
computeCommandEncoder
newBufferWithLength:options:
contents
setComputePipelineState:
setTexture:atIndex:
setBuffer:offset:atIndex:
dispatchThreadgroups:threadsPerThreadgroup:
endEncoding
_backwarpKernel
_mtlLibrary
standardUserDefaults
persistentDomainForName:
currentLocale
sharedLogManager
dateFormatter
logLevel
_logLevel
Ti,R,V_logLevel
hasKeyFrame
hasPlaybackCrop
_autoPlayable
TB,N,V_autoPlayable
_createPixelBufferWithWidth:height:pixelFormat:pixelBuffer:
_convertFromBuffer:toLumaPixelBuffer:abnormalDimension:
_imageManager
initNewContext:
execute
device
setDevice:
commandQueue
setCommandQueue:
setCommandBuffer:
_commandBuffer
T@"<MTLDevice>",&,V_device
T@"<MTLCommandQueue>",&,V_commandQueue
T@"<MTLCommandBuffer>",&,V_commandBuffer
resourceForAsset:withResources:
processExistingAnalyses:
mediaAnalysisProperties
blurrinessScore
vcp_usePHFace
vcp_queryPHFaces:results:
dictionaryWithObjectsAndKeys:
updateDegradedFlagForMajorDimension:
downscaleImage:scaledImage:majorDimension:
isPano
vcp_usePHFaceExpression
isSDOF
_reportPetsAnalysisWithResults:
existingAnalysisForMovieAnalyzer
checkFaceDominant
initWithDictionary:
analyzeImage:performedAnalyses:cancel:
_irisAnalyses
_phFaceResults
_phFaceFlags
_imageBlurTextureScore
_preAnalysisSharpnessScore
_requirePHFaceAnalysis
_imageCaptionModel
_loadImageURL:withSession:reencodedImageData:andRequestHandler:
_configureRequest:withRevision:preferANE:
initWithImageSignatureprintType:imageSignatureHashType:
imageNeuralHashprint
setInputSignatureprint:
imageSignatureHash
encodeHashDescriptorWithBase64EncodingAndReturnError:
analyzeWithImageURL:requestTypes:reencode:completionHandler:
promoteUnverifiedPersonsWithUpdateBlock:
evaluatePersonPromoterWithUpdateBlock:
generateCurationSegment
generateInterestingTrimBasedOnCaptureTime:
updateCurationThreshold
calculateCandidateScoreWithRangeAdjust:endIdx:candidateTimeRange:captureTime:
isCurated:
isTimestampSkipable:
checkTrimAt:captureTime:
finalizeWithDestructiveTrimStart:trimEnd:andCaptureTime:
bestTrimTimeRange
_actionAnalyzer
_bestTrimTimeRange
_curationThreshold
_inTrimStart
_inTrimEnd
_captureTime
_ready
ComputeSceneDelta:
decideLensSwitchPoint:
PrintSegments
finalizeAnalysisPass:
_sceneDeltaBuffer
_sceneSegments
_currentStatus
_isSegmentPoint
setValue:forField:andEvent:
accumulateInt64Value:forField:andEvent:
accumulateDoubleValue:forField:andEvent:
valueForField:andEvent:
sendSessionEvent:
_singleAnalyticsSentCount
_sessionAnalyticsSentCount
_sessionAnalytics
Ti,N,V_orientation
_createPixelBuffer:withWidth:andHeight:
_createPixelBuffer:withColorSpace:fromPixelBuffer:
_createPixelBuffer:withMinorDimension:fromFullPixelBuffer:
_pooledPixelBuffer:withDimension:
fullPixelBuffer:toScaledBuffer:
_pixelBufferPools
T@"NSMutableArray",&,V_faceQualityScores
_lastestFaceID
_numFacesLastFrame
_lastVertices
_lastJawOpenness
computeControlPointsCamera:Vt:
computePoints3DCamera
correctSigns
computeRT:T:
computeProjectionError:T:
configureGaussNewton:R6x1:betas:jacobian:residual:
getControlPoints
computeBarycentricCoordinates
computeSVDVt:Vt:
computeL6x10:L6x10:
computeR6x1:
estimateBetasN1:R6x1:betas:
estimateBetasN2:R6x1:betas:
estimateBetasN3:R6x1:betas:
optimizeBetas:R6x1:betas:
estimateRT:betas:R:T:projectionError:
estimatePose:
setPose:
_points2D
_points3D
_numPoints
_controlPointsWorld
_controlPointsCamera
_pointsWorld
_pointsImage
_alphas
_points3DCamera
_cameraOrientation
T{?=[4]},V_pose
initWithCommonFormat:sampleRate:channels:interleaved:
appendBuffer:atTime:error:
_signature
T@"VCPProtoBounds",&,N,V_faceBounds
_correlationKernel
associatePerson:withPHFaces:
addActiveResults:
processPersons:humanBounds:dominantPersonIdx:frame:timestamp:duration:
_activePoseResults
_humanRect
_lastHumanTimestamp
unimplementedExceptionForMethodName:
isImage
typeDescription
T@"VCPFingerprint",R,N
T@"NSURL",R,N
T@"PHFetchResult",R,N
isHDR
Tf,R,N
T{?={?=qiIq}{?=qiIq}},R,N
vcp_faceRectFrom:
vcp_flagsForPHFace:withFaceRect:
vcp_PHFaces:
vcp_reportDownload:withTaskID:
setDownloadPriority:
setDownloadIntent:
setPruneAfterAvailableOnLowDisk:
requestFileURLForAssetResource:options:urlReceivedHandler:completionHandler:
vcp_inMemoryDownload:withTaskID:toData:cancel:
vcp_requestFileURLForAssetResource:withTaskID:toResourceURL:cancel:
vcp_requestFileURLForAssetResource:withTaskID:timeoutHandler:urlHandler:andCompletionHandler:
_end
T@"VCPProtoPoint",&,N,V_start
T@"VCPProtoPoint",&,N,V_end
clearTimeValues
timeValueAtIndex:
homographyParamsAtIndex:
setTimeValues:count:
_timeValues
_inputBoundsHeight
_inputBoundsWidth
_inputBoundsX
_inputBoundsY
_sourceSizeHeight
_sourceSizeWidth
Tf,N,V_cropRectX
Tf,N,V_cropRectY
Tf,N,V_cropRectHeight
Tf,N,V_cropRectWidth
Tf,N,V_inputBoundsX
Tf,N,V_inputBoundsY
Tf,N,V_inputBoundsHeight
Tf,N,V_inputBoundsWidth
Tf,N,V_sourceSizeHeight
Tf,N,V_sourceSizeWidth
T^q,R,N
parseHeatmap2Keypoints:
_landmarkDetector
_lastTimestamp
_motionTypeModel
_motionScoreModel
spatialDescriptorWithMvMagnitudeMean:
_widthInMb
_heightInMb
_motionMagnitudeHistogram
_motionMagnitude
T^f,R
_blocks
_quantFactor
T@"VCPCNNData",R,V_output
deactivateResource:
initWithResourceManager:andResource:
_resourceManager
_resource
initWithResource:
resource
setResource:
activeCount
setActiveCount:
currentCost
setCurrentCost:
_activeCount
_currentCost
T@"VCPMADResource",&,N,V_resource
Tq,N,V_activeCount
Tq,N,V_currentCost
purgeAllResources
_purgeAllResources
_setBudget:
checkTimeout
entryForResource:
validateCost:
_reserveBudget:
currentBudget
reserveBudget:
_budget
_timer
_inactiveDate
_transaction
clearBounds
boundsType
T@"NSMutableArray",&,N,V_bounds
supportsFeatureSet:
isHomePod
marketingName
vcp_fullAnalysisTypesForAssetType:
_analysisDict
_metadata
_cropSize
featureValueWithCGImage:pixelsWide:pixelsHigh:pixelFormatType:options:error:
imageBufferValue
initWithInputImage:
featureValueWithImageAtURL:pixelsWide:pixelsHigh:pixelFormatType:options:error:
inputImage
setInputImage:
initWithInputImageFromCGImage:error:
initWithInputImageAtURL:error:
setInputImageWithCGImage:error:
setInputImageWithURL:error:
_inputImage
T^{__CVBuffer=},N,V_inputImage
angle
featureValueWithMultiArray:
initWithAngle:
setAngle:
T@"MLMultiArray",&,N,V_angle
bundleForClass:
pathForResource:ofType:
URLOfModelInThisBundle
initWithContentsOfURL:error:
initWithContentsOfURL:configuration:error:
initWithMLModel:
modelWithContentsOfURL:configuration:error:
loadContentsOfURL:configuration:completionHandler:
predictionFromFeatures:options:error:
initWithFeatureProviderArray:
predictionsFromBatch:options:error:
featuresAtIndex:
loadWithConfiguration:completionHandler:
initWithConfiguration:error:
predictionFromInputImage:error:
predictionsFromInputs:options:error:
setBox:
stableInd
setStableInd:
setLostTrackInd:
T^{CGPoint=dd}
stable
lostTrack
T^{CGPoint=dd},VP
TB,Vstable
TB,VlostTrack
@24@0:8^{_NSZone=}16
@16@0:8
B24@0:8@16
v24@0:8@16
Q16@0:8
f16@0:8
v20@0:8f16
v16@0:8
@"VCPProtoTimeRange"
@52@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16f48
{CGRect={CGPoint=dd}{CGSize=dd}}16@0:8
v48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
{CGRect="origin"{CGPoint="x"d"y"d}"size"{CGSize="width"d"height"d}}
@64@0:8{CGAffineTransform=dddddd}16
@72@0:8@16@24{?=qiIq}32^{?=qiIq}56@64
i88@0:8^{__CVBuffer=}16{?=qiIq}24{?=qiIq}48^Q72@80
i80@0:8^{__CVBuffer=}16{?=qiIq}24{?=qiIq}48^Q72
v104@0:8{?={?=qiIq}{?=qiIq}}16@64@72{?=qiIq}80
i64@0:8{?={?=qiIq}{?=qiIq}}16
@"NSMutableArray"
{?="value"q"timescale"i"flags"I"epoch"q}
@"VCPImagePetsAnalyzer"
@"NSArray"
@32@0:8@16@24
i72@0:8{?={?=qiIq}{?=qiIq}}16^{__CVBuffer=}64
B16@0:8
v20@0:8B16
B32@0:8@?16^@24
@24@0:8@16
@24@0:8Q16
d24@0:8@16
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
@"NSURL"16@0:8
B32@0:8@?<v@?>16^@24
@"<PVFetchResultProtocol>"24@0:8@"NSArray"16
@"<PVFetchResultProtocol>"24@0:8Q16
@"<PVFetchResultProtocol>"24@0:8@"<PVMomentProtocol>"16
@"<PVFetchResultProtocol>"24@0:8@"<PVPersonProtocol>"16
@"NSDictionary"24@0:8@"<PVFetchResultProtocol>"16
@"<PVFetchResultProtocol>"32@0:8@"<PVPersonProtocol>"16@"<PVMomentProtocol>"24
@"<PVFetchResultProtocol>"32@0:8@"NSArray"16@"<PVMomentProtocol>"24
@"<PVFetchResultProtocol>"24@0:8@"<PVFaceGroupProtocol>"16
@"<PVFetchResultProtocol>"16@0:8
@"<PVFetchResultProtocol>"24@0:8@"<NSFastEnumeration>"16
@"NSDate"16@0:8
@"NSSet"16@0:8
@"NSDictionary"16@0:8
@24@0:8@"NSDictionary"16
v24@0:8I16B20
@"NSObject<OS_dispatch_queue>"
^{__SCNetworkReachability=}
@96@0:8@16f24B28@32{?={?=qiIq}{?=qiIq}}40Q88
i20@0:8f16
i28@0:8^{__CVBuffer=}16i24
i56@0:8@16@24{?=qiIq}32
i32@0:8@16@24
{?=qiIq}40@0:8{?=qiIq}16
i104@0:8{?=qiIq}16{?=qiIq}40@64{CGRect={CGPoint=dd}{CGSize=dd}}72
@"VCPVideoCNNBackbone"
@"VCPTransforms"
@"VCPVideoPersonDetector"
@"NSString"
@"VCPVideoCNNAutoplay"
@"VCPVideoCNNCameraMotion"
@"VCPVideoCNNQuality"
@"VCPVideoCNNHighlight"
{?="distanceToPreviousScene"b1"flickerScore"b1"sceneprintDistanceToPreviousScene"b1}
@32@0:8^{__CVBuffer=}16@24
@"MLFeatureValue"24@0:8@"NSString"16
^{__CVBuffer=}
v40@0:8r^{?=qiIq}16r^{?=qiIq}24@32
i28@0:8^{opaqueCMSampleBuffer=}16i24
i16@0:8
i24@0:8r^{AudioStreamBasicDescription=dIIIIIIII}16
i88@0:8^{AudioBufferList=I[1{AudioBuffer=II^v}]}16{AudioTimeStamp=dQdQ{SMPTETime=ssIIIssss}II}24
i24@0:8r^{?=qiIq}16
@"NSDictionary"
{AudioStreamBasicDescription="mSampleRate"d"mFormatID"I"mFormatFlags"I"mBytesPerPacket"I"mFramesPerPacket"I"mBytesPerFrame"I"mChannelsPerFrame"I"mBitsPerChannel"I"mReserved"I}
B20@0:8B16
@24@0:8@?16
@20@0:8B16
@72@0:8@16@24@32@40B48B52f56f60f64B68
i48@0:8^{__CVBuffer=}16{?=qiIq}24
i88@0:8^{__CVBuffer=}16{?=qiIq}24{?=qiIq}48^Q72@?80
i96@0:8^{__CVBuffer=}16{?=qiIq}24{?=qiIq}48@72^Q80@?88
i40@0:8{?=qiIq}16
f40@0:8@16^{EncodeStats=^^?^B^B^{MotionVector}^{MotionVector}^{MotionVector}^{MotionVector}^S^S^I^S^S^S^S^S^S^S^S^S^S^SIBBBii}24i32i36
i20@0:8i16
v24@0:8^v16
f24@0:8^v16
i36@0:8@16@24B32
i80@0:8@16@24{?={?=qiIq}{?=qiIq}}32
i44@0:8^{__CFArray=}16@24@32B40
v24@0:8^{__CVBuffer=}16
v32@0:8^v16@24
@64@0:8{?={?=qiIq}{?=qiIq}}16
^{MotionFilter=^{FrameBuffer}BB}
^{MetaDataAnalysis=B^{FrameBuffer}{Translation=fff}{Translation=fff}}
^{IrisAnalysis=ffiiB^{__CFArray}}
{FrameBuffer="frame_count_"i"buffer_"[35{Frame="frame_idx_"i"timestamp_"{?="value"q"timescale"i"flags"I"epoch"q}"duration_"{?="value"q"timescale"i"flags"I"epoch"q}"ave_motion_"{Translation="x_"f"y_"f"z_"f}"org_motion_"{Translation="x_"f"y_"f"z_"f}"quality_score_"f"distortion_"Q"distortion_norm_"f"motion_change_"{Translation="x_"f"y_"f"z_"f}"compressed_bytes_"I"blur_"B"acc_var_"{Translation="x_"f"y_"f"z_"f}"texture_"f"motion_result_"{MotionResult="significant_values_"[6f]"confidence_"[6f]"fine_action_score_"f"action_score_"f"track_score_"f"rotation_angle_"f"subtle_motion_score_"f"is_stable_"B"action_blocks_"i"action_motion_"f"valid_mb_"B"valid_submb_"B"support_size_"i"residual_var_"f"gmv_"[2f]"motion_param_"{array<float, 6UL>="__elems_"[6f]}"motion_param_diff_"{array<float, 6UL>="__elems_"[6f]}"duration_"{?="value"q"timescale"i"flags"I"epoch"q}"scene_delta_"f"scene_delta_ratio_"f"objects_"{Vector<ma::Object *>="vector_"^{__CFArray}}"detect_objects_"{Vector<ma::Object *>="vector_"^{__CFArray}}"imported_objects_"{Vector<ma::Object *>="vector_"^{__CFArray}}}"flow_"^f"interestingness_"f"obstruction_"f"colorfulness_score_"f"histogram_"{Histogram="extremities_"f"overexposes_"f"histogram_"[3^i]"moments_hist_"[2^i]}}]}
{Histogram="extremities_"f"overexposes_"f"histogram_"[3^i]"moments_hist_"[2^i]}
@"NSMutableDictionary"
@"VCPFrameAnalysisStats"
@"VCPFrameScoreFilter"
@"VCPMotionFlowSubtleMotionAnalyzer"
@"VCPMotionFlowAnalyzer"
@32@0:8@16^@24
@80@0:8{CGAffineTransform=dddddd}16@64@72
i32@0:8^{__CVBuffer=}16@24
B32@0:8@16@24
B84@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48B80
i56@0:8^{__CVBuffer=}16{?=qiIq}24@48
@"VCPCNNSmileDetector"
@"VCPCNNPoseEstimator"
{?={?=qiIq}{?=qiIq}}16@0:8
@32@0:8@16@?24
v32@0:8@16Q24
B24@0:8^@16
@"NSData"
{atomic<bool>="__a_"{__cxx_atomic_impl<bool, std::__cxx_atomic_base_impl<bool>>="__a_value"AB}}
@32@0:8B16B20@24
^f48@0:8i16i20^i24^i32^f40
i36@0:8^{CGPoint=dd}16^f24f32
@"VCPCNNModelEspresso"
f56@0:8*16*24*32i40i44q48
f48@0:8*16i24i28q32*40
i48@0:8^{__CVBuffer=}16^Q24^@32@?40
@24@0:8^{__CVBuffer=}16
i32@0:8^f16@24
@"NSData"16@0:8
i32@0:8^f16@"<VCPDistanceDescriptorProtocol>"24
@24@0:8@"NSData"16
@"VNImageprint"
d16@0:8
v24@0:8d16
{?="contentScore"b1"globalQualityScore"b1}
i20@0:8B16
{CGAffineTransform=dddddd}64@0:8{CGAffineTransform=dddddd}16
i32@0:8@16^Q24
{CGAffineTransform="a"d"b"d"c"d"d"d"tx"d"ty"d}
v24@0:8q16
q16@0:8
S16@0:8
@40@0:8@16@24@?32
@?16@0:8
v24@0:8@?16
@"VNCanceller"
B32@0:8@16^@24
@32@0:8Q16^@24
@40@0:8Q16Q24^@32
@40@0:8@16@24^@32
@"NSDictionary"32@0:8Q16^@24
@"NSNumber"40@0:8Q16Q24^@32
@"NSDictionary"40@0:8@"NSArray"16@"NSArray"24^@32
v32@0:8@16@24
B28@0:8B16@?20
v24@0:8Q16
v40@0:8{?=QQBB}16
B64@0:8@16@24@32@40@?48^@56
@44@0:8@16B24@28@36
@36@0:8@16B24@28
v40@0:8@16^@24@?32
v32@0:8@16@?24
B40@0:8^@16^Q24^@32
B48@0:8@16@24@32^@40
B36@0:8B16@?20^@28
Q36@0:8B16@?20^@28
@48@0:8@16@24@?32^@40
@40@0:8@16^@24@?32
B60@0:8@16Q24B32^@36@?44^@52
@40@0:8^@16^@24@?32
B56@0:8^@16^d24^B32@?40^@48
@"PHPhotoLibrary"
@"VCPPhotosPersistenceDelegate"
@"NSObject<OS_dispatch_group>"
@"VCPPhotosFaceProcessingContext"
@"NSURL"
@"NSNumber"
@"NSSet"
@"NSMutableSet"
@"VNClustererBuilder"
@"VCPSuggestionRequest"
@"NSLock"
{?="countOfEligibleFaces"Q"countOfFacesPendingToAdd"Q"isClustering"B"rebuildRequired"B}
@"NSDate"
{mach_timebase_info="numer"I"denom"I}
@40@0:8^{__CVBuffer=}16@24^@32
{CGSize=dd}32@0:8@16^@24
I16@0:8
@"VCPImageHumanPoseAnalyzer"
i24@0:8@16
i112@0:8@16@24{CGRect={CGPoint=dd}{CGSize=dd}}32{?=qiIq}64{?=qiIq}88
@64@0:8@16@24{CGRect={CGPoint=dd}{CGSize=dd}}32
{CGSize="width"d"height"d}
@"VNImageRequestHandler"
@"VCPMADVIRemoveBackgroundCachedImageHandler"
@40@0:8@16@24@32
@40@0:8@"MADRequest"16@"VCPMADServiceImageAsset"24@"NSString"32
@"NSArray"16@0:8
v24@0:8@"<MTLDevice>"16
@"MADVIRemoveBackgroundRequest"
@"VCPMADServiceImageAsset"
@"<MTLDevice>"
@"VNImageBasedRequest"
{?=qiIq}16@0:8
@"VNRequest"
@20@0:8i16
i24@0:8i16i20
i32@0:8^{CGImage=}16^^{__CVBuffer}24
^{CGColorSpace=}
^{CGContext=}
^{__CVPixelBufferPool=}
^{OpaqueVTPixelTransferSession=}
@56@0:8@16Q24@32@?40@?48
@48@0:8Q16@24@32^@40
@48@0:8@16Q24@32^@40
@"VCPDatabaseReader"
v56@0:8@16@24I32@36i44@?48
v60@0:8@16@24@32@40i48@?52
v60@0:8@16@24Q32@40i48@?52
v64@0:8@16@24I32@36@44i52@?56
v44@0:8@16@24i32@?36
v36@0:8@16i24@?28
v32@0:8Q16Q24
v60@0:8i16@20@28Q36@44@?52
v60@0:8i16@20@28@36Q44@?52
v48@0:8i16@20@28B36@?40
v52@0:8i16Q20@28@36@?44
v60@0:8i16Q20@28@36@44@?52
v60@0:8i16@20@28@36@44@?52
v20@0:8i16
v48@0:8i16@20B28@32@?40
v44@0:8i16@20@28@?36
v36@0:8i16@20@?28
v40@0:8i16B20@24@?32
v40@0:8@16Q24@?32
v52@0:8i16@20@28@36@?44
v52@0:8Q16@24@32i40@?44
v32@0:8@"NSURL"16@?<v@?@"NSString">24
v56@0:8@"NSArray"16@"IOSurface"24I32@"NSString"36i44@?<v@?@"NSArray"@"NSError">48
v60@0:8@"NSArray"16@"NSURL"24@"NSString"32@"NSString"40i48@?<v@?@"NSArray"@"NSError">52
v60@0:8@"NSArray"16@"NSData"24@"UTType"32@"NSString"40i48@?<v@?@"NSArray"@"NSError">52
v60@0:8@"NSArray"16@"NSString"24Q32@"NSURL"40i48@?<v@?@"NSArray"@"NSError">52
v64@0:8@"NSArray"16@"IOSurface"24I32@"NSString"36@"NSURL"44i52@?<v@?@"NSArray"@"NSError">56
v44@0:8@"NSArray"16@"NSString"24i32@?<v@?@"NSArray"@"NSError">36
v36@0:8@"NSDictionary"16i24@?<v@?@"NSDictionary"@"NSError">28
v24@0:8@?<v@?@"NSDictionary">16
v60@0:8i16@"NSArray"20@"NSDictionary"28Q36@"NSArray"44@?<v@?@"NSDictionary"@"NSError">52
v60@0:8i16@"NSArray"20@"NSURL"28@"NSDictionary"36Q44@?<v@?@"NSDictionary"@"NSError">52
v48@0:8i16@"NSURL"20@"NSArray"28B36@?<v@?@"NSDictionary"@"NSError">40
v52@0:8i16Q20@"NSURL"28@"NSDictionary"36@?<v@?@"NSError">44
v60@0:8i16Q20@"NSArray"28@"NSURL"36@"NSDictionary"44@?<v@?@"NSDictionary"@"NSError">52
v60@0:8i16@"NSURL"20@"NSURL"28@"NSDictionary"36@"NSArray"44@?<v@?@"NSDictionary"@"NSError">52
v24@0:8@?<v@?@"NSError">16
v24@0:8@?<v@?Q>16
v24@0:8@"NSURL"16
v60@0:8i16@"NSString"20@"NSArray"28@"NSArray"36@"NSURL"44@?<v@?@"NSArray"@"NSError">52
v48@0:8i16@"NSArray"20B28@"NSURL"32@?<v@?B@"NSError">40
v44@0:8i16@"NSArray"20@"NSURL"28@?<v@?@"NSArray"@"NSError">36
v36@0:8i16@"NSURL"20@?<v@?B@"NSError">28
v44@0:8i16@"NSDictionary"20@"NSURL"28@?<v@?@"NSString"@"NSError">36
v40@0:8i16B20@"NSURL"24@?<v@?@"NSDictionary"@"NSError">32
v36@0:8i16@"NSURL"20@?<v@?@"NSDictionary"@"NSError">28
v44@0:8i16@"NSArray"20@"NSURL"28@?<v@?B@"NSError">36
v32@0:8@"NSURL"16@?<v@?@"NSDictionary"@"NSError">24
v40@0:8@"NSURL"16Q24@?<v@?@"NSString"@"NSError">32
v44@0:8i16@"NSURL"20@"NSArray"28@?<v@?@"NSDictionary"@"NSError">36
v52@0:8i16@"NSURL"20@"NSURL"28@"NSURL"36@?<v@?@"NSDictionary"@"NSError">44
v44@0:8i16@"NSURL"20@"NSURL"28@?<v@?@"NSDictionary"@"NSError">36
v44@0:8@"NSArray"16@"NSURL"24i32@?<v@?@"NSDictionary"@"NSError">36
v52@0:8Q16@"NSArray"24@"NSURL"32i40@?<v@?@"NSError">44
v28@0:8d16i24
i40@0:8^f16@24Q32
i48@0:8^f16@24Q32@?40
i32@0:8^@16@24
i40@0:8^@16@24@?32
i40@0:8^@16@24Q32
i48@0:8^@16@24Q32@?40
i56@0:8Q16@24@32@?40@?48
i52@0:8@16@24B32@?36@?44
i44@0:8@16B24@?28@?36
i48@0:8Q16@24@?32@?40
i48@0:8@16@24@?32@?40
i40@0:8@16@24@?32
i32@0:8@16@?24
i40@0:8@16Q24@?32
@"NSXPCConnection"
i64@0:8@16@24@32@40@?48@?56
i52@0:8@16B24@28@?36@?44
i40@0:8@16@?24@?32
i44@0:8B16@20@?28@?36
i48@0:8@16@24@32@?40
i24@0:8^f16
^f16@0:8
i40@0:8^{?=^v^v[4Q][4Q]QQQQQQQQQQi}16@24@32
i64@0:8^ 16Q24Q32Q40@48@56
i40@0:8^i16^i24^I32
i40@0:8^{__CVBuffer=}16@24@32
{?="plan"^v"network_index"i}
{?="data"^v"reserved"^v"dim"[4Q]"stride"[4Q]"width"Q"height"Q"channels"Q"batch_number"Q"sequence_length"Q"stride_width"Q"stride_height"Q"stride_channels"Q"stride_batch_number"Q"stride_sequence_length"Q"storage_type"i}
@40@0:8{?=qiIq}16
i36@0:8^{__CVBuffer=}16^f24i32
i40@0:8^f16^{__CVBuffer=}24i32i36
^f40@0:8i16i20^i24^i32
i52@0:8^f16i24i28@32@40i48
i28@0:8@16i24
i48@0:8^{__CVBuffer=}16@24@32@?40
@"CVNLPCommSafetyHandler"
@"MADImageSafetyClassificationRequest"
i64@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16^{__CVBuffer=}48^B56
@72@0:8@16@24Q32Q40@48i56B60^@64
@92@0:8@16@24@32Q40Q48@56@64@72@80i88
@32@0:8@16q24
d32@0:8@16@24
B40@0:8@16@24@32
B48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
q24@0:8Q16
s16@0:8
v20@0:8s16
v20@0:8S16
@"VCPVNImageprintWrapper"
^v16@0:8
^v20@0:8B16
@28@0:8B16B20B24
@"VCPProtoBounds"
@48@0:8{?=qiIq}16f40B44
v72@0:8{?={?=qiIq}{?=qiIq}}16f64B68
v40@0:8{?=qiIq}16
v44@0:8{?=qiIq}16B40
v64@0:8{?={?=qiIq}{?=qiIq}}16
{?="start"{?="value"q"timescale"i"flags"I"epoch"q}"duration"{?="value"q"timescale"i"flags"I"epoch"q}}
@32@0:8@16f24f28
v76@0:8@16{?=qiIq}24{?=qiIq}48B72
v72@0:8@16{?={?=qiIq}{?=qiIq}}24
@44@0:8Q16Q24B32@?36
@36@0:8Q16B24@?28
@"NSObject<OS_dispatch_source>"
S24@0:8@16
@24@0:8q16
@20@0:8S16
S24@0:8q16
@28@0:8@16B24
i40@0:8^@16#24Q32
i36@0:8^@16#24i32
{CGRect={CGPoint=dd}{CGSize=dd}}56@0:8d16d24d32d40d48
@48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
v40@0:8*16Q24^f32
i24@0:8^Q16
i32@0:8^{__CVBuffer=}16^Q24
@"VCPCNNModel"
@"VCPCNNData"
f24@0:8@16
i32@0:8[6f]16[6f]24
i24@0:8^v16
i24@0:8^{EncodeStats=^^?^B^B^{MotionVector}^{MotionVector}^{MotionVector}^{MotionVector}^S^S^I^S^S^S^S^S^S^S^S^S^S^SIBBBii}16
v80@0:8^{__CVBuffer=}16{?=qiIq}24{?=qiIq}48@?72
{Frame="frame_idx_"i"timestamp_"{?="value"q"timescale"i"flags"I"epoch"q}"duration_"{?="value"q"timescale"i"flags"I"epoch"q}"ave_motion_"{Translation="x_"f"y_"f"z_"f}"org_motion_"{Translation="x_"f"y_"f"z_"f}"quality_score_"f"distortion_"Q"distortion_norm_"f"motion_change_"{Translation="x_"f"y_"f"z_"f}"compressed_bytes_"I"blur_"B"acc_var_"{Translation="x_"f"y_"f"z_"f}"texture_"f"motion_result_"{MotionResult="significant_values_"[6f]"confidence_"[6f]"fine_action_score_"f"action_score_"f"track_score_"f"rotation_angle_"f"subtle_motion_score_"f"is_stable_"B"action_blocks_"i"action_motion_"f"valid_mb_"B"valid_submb_"B"support_size_"i"residual_var_"f"gmv_"[2f]"motion_param_"{array<float, 6UL>="__elems_"[6f]}"motion_param_diff_"{array<float, 6UL>="__elems_"[6f]}"duration_"{?="value"q"timescale"i"flags"I"epoch"q}"scene_delta_"f"scene_delta_ratio_"f"objects_"{Vector<ma::Object *>="vector_"^{__CFArray}}"detect_objects_"{Vector<ma::Object *>="vector_"^{__CFArray}}"imported_objects_"{Vector<ma::Object *>="vector_"^{__CFArray}}}"flow_"^f"interestingness_"f"obstruction_"f"colorfulness_score_"f"histogram_"{Histogram="extremities_"f"overexposes_"f"histogram_"[3^i]"moments_hist_"[2^i]}}
^{EncodeStatsHW=^^?^B^B^{MotionVector}^{MotionVector}^{MotionVector}^{MotionVector}^S^S^I^S^S^S^S^S^S^S^S^S^S^SIBBBiii^{OpaqueVTCompressionSession}^{__CFData}{?=qiIq}iiB}
[6[5f]]
@"VCPObjectPool"
i36@0:8^{__sFILE=*iiss{__sbuf=*i}i^v^?^?^?^?{__sbuf=*i}^{__sFILEX}i[3C][1C]{__sbuf=*i}iq}16i24i28i32
@"VNClassifyImageAestheticsRequest"
@"VNSceneClassificationRequest"
@"VNCreateSceneprintRequest"
@"VNGenerateAttentionBasedSaliencyImageRequest"
@"VNClassifyJunkImageRequest"
@"VNRecognizeObjectsRequest"
@"VNGenerateObjectnessBasedSaliencyImageRequest"
@"VNClassifyPotentialLandmarkRequest"
@"VNVYvzEtX1JlUdu8xx5qhDI"
@"VN6Mb1ME89lyW3HpahkEygIG"
@"VN5kJNH3eYuyaLxNpZr5Z7zi"
@"VNClassifyMemeImageRequest"
@"VN1JC7R3k4455fKQz0dY1VhQ"
@"VNRecognizeDocumentElementsRequest"
@"VNClassifyCityNatureImageRequest"
@"VNCreateImageFingerprintsRequest"
{?="faceQuality"b1}
B20@0:8f16
{HinkleyDetector="sensitivity_"f"threshold_"f"min_length_"i"stats_"{HinkleyStats="upper_"f"lower_"f"max_"f"min_"f}}
@"VCPVideoMetaMotionSegment"
@44@0:8f16{?=qiIq}20
v44@0:8f16{?=qiIq}20
@"VIService"
@"VCPProtoTime"
@48@0:8@16@24@32@40
i40@0:8{vector<float *, std::allocator<float *>>=^^f^^f{__compressed_pair<float **, std::allocator<float *>>=^^f}}16
v24@0:8^f16
{vector<espresso_buffer_t, std::allocator<espresso_buffer_t>>=^{?}^{?}{__compressed_pair<espresso_buffer_t *, std::allocator<espresso_buffer_t>>=^{?}}}16@0:8
v40@0:8{vector<espresso_buffer_t, std::allocator<espresso_buffer_t>>=^{?}^{?}{__compressed_pair<espresso_buffer_t *, std::allocator<espresso_buffer_t>>=^{?}}}16
{?=^v^v[4Q][4Q]QQQQQQQQQQi}16@0:8
v184@0:8{?=^v^v[4Q][4Q]QQQQQQQQQQi}16
@"VCPCNNEspressoContext"
{vector<espresso_buffer_t, std::allocator<espresso_buffer_t>>="__begin_"^{?}"__end_"^{?}"__end_cap_"{__compressed_pair<espresso_buffer_t *, std::allocator<espresso_buffer_t>>="__value_"^{?}}}
i40@0:8@16^@24@?32
@"VCPLoaned"
@56@0:8^f16^f24Q32Q40i48i52
i28@0:8f16f20f24
i36@0:8^f16f24^f28
i64@0:8^f16Q24Q32{DSPSplitComplex=^f^f}40^f56
B28@0:8i16i20i24
{DSPSplitComplex="realp"^f"imagp"^f}
@68@0:8f16{?={?=qiIq}{?=qiIq}}20
i64@0:8{?=qiIq}16{?=qiIq}40
@"VCPVideoCaptionEncoder"
@"MAAsset"
@32@0:8@16r^{?={?=qiIq}{?=qiIq}}24
i28@0:8B16^{?={?=qiIq}{?=qiIq}}20
i72@0:8{?={?=qiIq}{?=qiIq}}16^^{opaqueCMSampleBuffer}64
^{opaqueCMSampleBuffer=}16@0:8
@"AVAssetReader"
@"AVAssetReaderSampleReferenceOutput"
@"NSObject<OS_dispatch_semaphore>"
[2^{opaqueCMSampleBuffer}]
@36@0:8Q16i24@28
@40@0:8Q16@24^@32
B40@0:8^f16@24^@32
@132@0:8{CGAffineTransform=dddddd}16{?={?=qiIq}{?=qiIq}}64B112@116@124
i24@0:8^{__CVBuffer=}16
f32@0:8@16@24
@"VCPImageBlurAnalyzer"
@"VCPImageFaceQualityAnalyzer"
@"VCPVideoKeyFrame"
@"AVAssetReaderTrackOutput"
@"AVAssetReaderOutputMetadataAdaptor"
v56@0:8@16@24^Q32^Q40^Q48
Q24@0:8@16
Q40@0:8@16@24Q32
Q32@0:8@16Q24
i48@0:8@16Q24^@32@?40
v48@0:8@16Q24@32@?40
B20@0:8i16
@48@0:8i16i20i24B28B32i36i40B44
i28@0:8^{__sFILE=*iiss{__sbuf=*i}i^v^?^?^?^?{__sbuf=*i}^{__sFILEX}i[3C][1C]{__sbuf=*i}iq}16s24
v32@0:8@16^{__CVBuffer=}24
f92@0:8f16{CGRect={CGPoint=dd}{CGSize=dd}}20{CGRect={CGPoint=dd}{CGSize=dd}}52i84i88
@28@0:8@16f24
f84@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48B80
@"VCPImageSaliencyAnalyzer"
@40@0:8^{opaqueCMSampleBuffer=}16@24^@32
@"VCPImageHandsAnalyzer"
i40@0:8B16@20B28B32B36
i40@0:8^{__CVBuffer=}16^{__CVBuffer=}24@?32
^f32@0:8^i16^i24
i32@0:8^{__CVBuffer=}16f24f28
i40@0:8^{__CVBuffer=}16^{__CVBuffer=}24f32f36
i28@0:8@16I24
{vector<float *, std::allocator<float *>>="__begin_"^^f"__end_"^^f"__end_cap_"{__compressed_pair<float **, std::allocator<float *>>="__value_"^^f}}
i36@0:8@16f24@?28
@"MADEmbeddingGenerationRequest"
B40@0:8@16@24^@32
B88@0:8{?={?=qiIq}{?=qiIq}}16{?=qiIq}64
B56@0:8^{opaqueCMSampleBuffer=}16{?=qiIq}24^@48
B32@0:8^{opaqueCMSampleBuffer=}16^@24
B48@0:8{?=qiIq}16^@40
v20@0:8I16
{CF<opaqueCMSampleBuffer *>="value_"^{opaqueCMSampleBuffer}}
{?="faceSharpness"b1}
@40@0:8@16Q24^@32
i40@0:8^{CGPoint=dd}16^f24^@32
v64@0:8^f16^f24Q32Q40Q48Q56
v28@0:8i16^f20
v40@0:8^f16Q24Q32
i56@0:8^f16@24^{CGPoint=dd}32^f40^@48
i52@0:8@16f24{CGPoint=dd}28^f44
i32@0:8@16^f24
[8^f]
@"VCPGaborFilter"
@"VCPHumanPoseImageRequest"
@24@0:8i16B20
i40@0:8^{__CVBuffer=}16^f24i32i36
f40@0:8^f16i24i28i32i36
i32@0:8^f16i24i28
i24@0:8@?16
i40@0:8^{__CVBuffer=}16@24@?32
i84@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24{CGSize=dd}56B72@76
[5{CGRect="origin"{CGPoint="x"d"y"d}"size"{CGSize="width"d"height"d}}]
[5f]
B24@0:8Q16
Q24@0:8Q16
Q32@0:8q16Q24
@212@0:8Q16{CGAffineTransform=dddddd}24{?={?=qiIq}{?=qiIq}}72B120f124@128B136B140@144B152{?={?=qiIq}{?=qiIq}}156@204
v64@0:8@16@24@32@40{CGSize=dd}48
@"VCPVideoKeyFrameAnalyzer"
@"VCPMovieHighlightAnalyzer"
@"VCPImageDescriptor"
i44@0:8B16@20i28i32@?36
i28@0:8^^{__CVBuffer}16I24
i32@0:8^{__CVBuffer=}16^{__CVBuffer=}24
i32@0:8^{__CVBuffer=}16^{?=[7{?=iii}][7^{__CVBuffer}]}24
i36@0:8i16^{__CVBuffer=}20^{__CVBuffer=}28
i36@0:8^{__CVBuffer=}16^{__CVBuffer=}24i32
i40@0:8^{__CVBuffer=}16^{__CVBuffer=}24i32i36
@"VCPFlowFeatureExtractor"
[7@"VCPFlowDecoder"]
@"VCPCorrelation"
@"VCPBackwarp"
[2{?="featureShape"[7{?="channels"i"height"i"width"i}]"feature"[7^{__CVBuffer}]}]
{?="correlations"[7^{__CVBuffer}]"flows"[7^{__CVBuffer}]"upscaledFlows"[7^{__CVBuffer}]"warpedBuffers"[7^{__CVBuffer}]}
{CLLocationCoordinate2D=dd}16@0:8
i44@0:8Q16Q24i32^^{__CVBuffer}36
i36@0:8^{__CVBuffer=}16^^{__CVBuffer}24i32
@40@0:8^{__CVBuffer=}16^{__CVBuffer=}24^@32
@52@0:8^{__CVBuffer=}16^{__CVBuffer=}24B32^{__CVBuffer=}36^@44
@"VCPImageMotionFlowAnalyzer"
i32@0:8q16^@24
@32@0:8@16Q24
i40@0:8@16@?24^Q32
i32@0:8@?16^Q24
@"AVAsset"
i48@0:8@16{?=qiIq}24
v28@0:8B16@20
v60@0:8B16f20f24f28f32f36f40B44f48f52B56
@"VNSceneprint"
@"VCPCNNPetsDetector"
i32@0:8[3[3f]]16[3f]24
i32@0:8[3f]16[3[3f]]24
i32@0:8[3f]16[3f]24
i24@0:8^{?=[4]}16
{Matrix<float, 12U, 1U, false>="m_data"[12f]}
{Matrix<float, 12U, 12U, false>="m_data"[144f]}
v24@0:8@"<PVFetchResultProtocol>"16
@"<PVFaceProtocol>"16@0:8
v24@0:8@"<PVFaceProtocol>"16
Q36@0:8B16Q20Q28
{CGRect={CGPoint=dd}{CGSize=dd}}32@0:8Q16Q24
{CGRect={CGPoint=dd}{CGSize=dd}}80@0:8Q16Q24{CGAffineTransform=dddddd}32
@"VNFaceObservation"
v24@0:8f16f20
v52@0:8^f16^f24^f32i40^f44
v48@0:8r^f16r^i24r^f32^f40
v48@0:8r^f16r^f24r^f32^f40
v32@0:8r^f16^f24
v52@0:8r^f16i24r^f28r^f36^f44
v36@0:8r^f16^f24B32
B24@0:8^f16
v56@0:8^f16^f24^f32^f40^f48
v44@0:8^f16^f24^f32i40
v68@0:8^f16^f24^f32^f40^f48^f56i64
{matrix<double, 6L, 1L, dlib::memory_manager_stateless_kernel_1<char>, dlib::row_major_layout>={layout<double, 6L, 1L, dlib::memory_manager_stateless_kernel_1<char>, 1>=[6d]}}16@0:8
B28@0:8i16B20B24
{?=[4]}16@0:8
^16@0:8
@"VCPFaceTensorModel"
^{?=ffi}
[8f]
[9f]
[12f]
[3f]
[126f]
[189f]
@"VCPPnPSolver"
[51f]
@24@0:8^@16
@"MADVITextLookupRequest"
@"<VICancellable>"
@"VCPProtoLine"
@"VCPProtoPoint"
B80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48
v48@0:8Q16@24@32@?40
v48@0:8Q16@"IOSurface"24@"NSDictionary"32@?<v@?@"NSDictionary"@"NSError">40
@28@0:8i16@20
v48@0:8Q16^{__CVBuffer=}24@32@?40
{CGPoint=dd}16@0:8
@48@0:8{CGPoint=dd}16{CGPoint=dd}32
f24@0:8Q16
v32@0:8^f16Q24
{?="list"^f"count"Q"size"Q}
@24@0:8^{__sFILE=*iiss{__sbuf=*i}i^v^?^?^?^?{__sbuf=*i}^{__sFILEX}i[3C][1C]{__sbuf=*i}iq}16
v32@0:8^f16^f24
v44@0:8^f16i24^f28^f36
^i16@0:8
@56@0:8@16Q24Q32Q40@48
{?="loopFadeLen"b1"loopPeriod"b1"loopStart"b1}
@28@0:8i16B20B24
i56@0:8^{__CVBuffer=}16^Q24@32^@40@?48
@"VCPCNNPetsKeypointsDetector"
i68@0:8@16@24@32@40@48@56f64
f80@0:8{?={?=qiIq}{?=qiIq}}16@64^i72
f64@0:8{?={?=qiIq}{?=qiIq}}16
i68@0:8{?={?=qiIq}{?=qiIq}}16f64
@"VCPVideoActivityDescriptor"
@68@0:8{?={?=qiIq}{?=qiIq}}16f64
f28@0:8@16f24
B72@0:8{?={?=qiIq}{?=qiIq}}16@64
B28@0:8@16f24
f72@0:8{?={?=qiIq}{?=qiIq}}16@64
f20@0:8f16
@28@0:8i16i20i24
@100@0:8Q16B24f28B32B36B40{?={?=qiIq}{?=qiIq}}44@92
i168@0:8@16@24@32@40@48@56@64@72@80@88@96@104@112@120@128@136@144{CGSize=dd}152
B64@0:8{?={?=qiIq}{?=qiIq}}16
@120@0:8@16{?={?=qiIq}{?=qiIq}}24{?={?=qiIq}{?=qiIq}}72
@112@0:8{?={?=qiIq}{?=qiIq}}16{?={?=qiIq}{?=qiIq}}64
{?={?=qiIq}{?=qiIq}}64@0:8{?={?=qiIq}{?=qiIq}}16
f68@0:8{?={?=qiIq}{?=qiIq}}16B64
@68@0:8{?={?=qiIq}{?=qiIq}}16B64
i64@0:8{array<float, 6UL>=[6f]}16{array<float, 6UL>=[6f]}40
B88@0:8^f16@24{?={?=qiIq}{?=qiIq}}32@80
{CGRect={CGPoint=dd}{CGSize=dd}}64@0:8{?={?=qiIq}{?=qiIq}}16
{?={?=qiIq}{?=qiIq}}68@0:8{?={?=qiIq}{?=qiIq}}16B64
@"AVAssetImageGenerator"
{array<float, 6UL>="__elems_"[6f]}
@"VCPColorNormalizationAnalyzer"
v40@0:8@16@24@?32
v32@0:8@"NSDictionary"16@?<v@?@"NSError">24
v32@0:8@"NSDictionary"16@?<v@?@"NSDictionary"@"NSError">24
v40@0:8@"NSData"16@"NSDictionary"24@?<v@?@"NSDictionary"@"NSError">32
@40@0:8@16@?24@?32
{CF<const opaqueCMFormatDescription *>="value_"^{opaqueCMFormatDescription}}
@"VCPHomeKitAnalysisSession"
i36@0:8^{sqlite3_stmt=}16i24@28
i40@0:8^{sqlite3_stmt=}16i24i28@32
i40@0:8@16^@24^q32
i32@0:8q16@24
i40@0:8q16@24@32
i40@0:8@16@24@32
@32@0:8Q16Q24
Q32@0:8Q16Q24
i32@0:8^q16@24
q24@0:8@16
i40@0:8^@16Q24@32
^{sqlite3=}
@"AVURLAsset"
^{__CVBuffer=}24@0:8Q16
^{__CVBuffer=}32@0:8Q16^I24
{CGAffineTransform=dddddd}20@0:8I16
i32@0:8^Q16^@24
@64@0:8@16@24@32@40@?48@?56
@36@0:8@16B24^@28
@"AVAudioPCMBuffer"
^{LkFsMeasure=IIqBIIddddqqIII[30[6f]]^f^f^f^{DspLibBiquad}^{DspLibBiquad}}
^{CAStreamBasicDescription=dIIIIIIII}
{vector<double, std::allocator<double>>="__begin_"^d"__end_"^d"__end_cap_"{__compressed_pair<double *, std::allocator<double>>="__value_"^d}}
{vector<float, std::allocator<float>>="__begin_"^f"__end_"^f"__end_cap_"{__compressed_pair<float *, std::allocator<float>>="__value_"^f}}
^{AUOutputBL={CAStreamBasicDescription=dIIIIIIII}*^{AudioBufferList}III}
i32@0:8^{CGImage=}16^@24
^{CGImageMetadata=}24@0:8@16
@88@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48@80
@72@0:8r^{CGImageSource=}16{CGRect={CGPoint=dd}{CGSize=dd}}24@56^@64
@72@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24@56^@64
{CGRect={CGPoint=dd}{CGSize=dd}}32@0:8@16^@24
@"VCPFaceAnalyzer"
@"MADVIMachineReadableCodeDetectionRequest"
Q28@0:8@16f24
@"VNTorsoprint"
@36@0:8i16@20@?28
i48@0:8^{__CVBuffer=}16^{__CVBuffer=}24^{__CVBuffer=}32^{__CVBuffer=}40
i56@0:8^{__CVBuffer=}16^{__CVBuffer=}24^{__CVBuffer=}32^{__CVBuffer=}40@?48
@52@0:8@16^{__sFILE=*iiss{__sbuf=*i}i^v^?^?^?^?{__sbuf=*i}^{__sFILEX}i[3C][1C]{__sbuf=*i}iq}24C32*36^f44
i44@0:8^{__CVBuffer=}16^f24i32^f36
@80@0:8Q16@24{CGSize=dd}32{CGRect={CGPoint=dd}{CGSize=dd}}48
v40@0:8Q16Q24@?32
@44@0:8@16@24B32@?36
@48@0:8@16d24Q32@?40
@"<PVFaceProtocol>"40@0:8@"<PVPersonProtocol>"16@"NSMapTable"24@?<v@?f^B>32
@"NSString"40@0:8@"PVPersonClusterManager"16@"NSSet"24@?<v@?f^B>32
@"NSArray"44@0:8@"PVPersonClusterManager"16@"NSSet"24B32@?<v@?f^B>36
@"NSArray"48@0:8@"NSArray"16d24Q32@?<d@?@@>40
@28@0:8@16i24
@36@0:8@16i24@28
@40@0:8@16@?24^@32
v56@0:8@16@24^@32@?40@48
B48@0:8@16Q24@?32^@40
B40@0:8@16@?24^@32
B48@0:8@16@24@?32^@40
B88@0:8@16@24@32@40@48@56@?64@?72^@80
B44@0:8@16B24@?28^@36
@48@0:8@16@24@32@?40
B48@0:8@16Q24@32^@40
B72@0:8@16@24@32@40@?48@56^@64
B44@0:8@16B24@28^@36
B56@0:8@16@24@32^@40^@48
@56@0:8@16@24@32@40^@48
v56@0:8@16@?24@32@40@?48
B40@0:8Q16@?24^@32
@32@0:8@?16Q24
v48@0:8@16@24@32@?40
v40@0:8@16@24@32
v112@0:8^@16^@24^@32^@40^@48^@56^@64^@72^@80@88@96@?104
v56@0:8^@16^@24^@32@40@48
B112@0:8@16@24@32@40@48@56@64@72@?80@?88@96^@104
Q32@0:8Q16@24
v64@0:8@16@24@32@40@48@56
v56@0:8@16@24@32^@40@?48
v56@0:8@16@24@?32@?40@48
v48@0:8@16@?24@32@?40
{?="underExpose"b1}
@"PHAsset"
{CGSize=dd}16@0:8
@"MADVIDocumentRecognitionRequest"
@"VNPersonsModel"
@"MADPersonIdentificationRequest"
f40@0:8*16i24i28q32
i40@0:8^f16@24^{__CVBuffer=}32
v48@0:8@16i24i28^f32^f40
f48@0:8{CGPoint=dd}16{CGPoint=dd}32
@36@0:8@16B24Q28
v40@0:8@16@24f32f36
i40@0:8^{__CVBuffer=}16^f24@?32
i32@0:8^f16^{__CVBuffer=}24
i48@0:8^{CGRect={CGPoint=dd}{CGSize=dd}}16^{__CVBuffer=}24@32i40i44
i52@0:8^{__CVBuffer=}16^Q24f32^@36@?44
[16f]
@"VCPCNNBlurAnalyzer"
i40@0:8^{__CVBuffer=}16^{?=[7{?=iii}][7^{__CVBuffer}]}24@?32
i36@0:8^{?=iii}16i24i28i32
{?="quality"b1"statsFlags"b1"typesWide"b1}
@52@0:8^{__CVBuffer=}16I24@28@36@44
i32@0:8^^{__CVBuffer}16^I24
v28@0:8@16B24
{CF<__CVBuffer *>="value_"^{__CVBuffer}}
@56@0:8@16@24@32@40@48
@"UTType"
@52@0:8@16^{__CVBuffer=}24I32@36@44
@80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16^{__CVBuffer=}48{?=qiIq}56
@"VCPCtrTracker"
@56@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24
B40@0:8@16^@24^@32
B56@0:8@16@24@32@40^@48
i40@0:8^Q16@?24@?32
i40@0:8@16@24^@32
i44@0:8@16B24^@28^@36
B36@0:8@16B24^@28
@24@0:8B16B20
@32@0:8Q16B24B28
i32@0:8@?16@?24
i40@0:8@?16@?24B32B36
B24@0:8@?16
B36@0:8Q16B24@?28
i60@0:8Q16B24B28B32^B36@?44@?52
@"VNEntityIdentificationModel"
f24@0:8^f16
i48@0:8^f16*24f32i36@?40
v56@0:8*16q24^f32q40i48i52
v28@0:8B16@?20
v44@0:8@16B24@28@?36
@64@0:8@16@24@32@?40@48^@56
@56@0:8@16@24@32@?40^@48
v64@0:8@16@24@32@40@?48@?56
v40@0:8@16@?24@?32
v48@0:8@16@?24@?32@?40
@"VCPClusterer"
@40@0:8@16r^{?={?=qiIq}{?=qiIq}}24r^{?=qiIq}32
^{opaqueCMSampleBuffer=}
{array<float, 6UL>=[6f]}16@0:8
v40@0:8{array<float, 6UL>=[6f]}16
v40@0:8i16i20^f24^f32
{CGRect={CGPoint=dd}{CGSize=dd}}56@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16f48f52
f80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48
i92@0:8@16@24i32^{__CVBuffer=}36{?=qiIq}44{?=qiIq}68
@"VCPImagePetsKeypointsAnalyzer"
@"VCPVideoObjectTracker"
@44@0:8{?=qiIq}16f40
@76@0:8{?={?=qiIq}{?=qiIq}}16f64@68
@"VCPVideoKeyFrameResult"
{?=ii}24@0:8@16
B32@0:8^{__CVBuffer=}16@24
@"AVAssetTrack"
@"VCPPhotosFace"
@"MLModel"
@28@0:8i16f20f24
f24@0:8f16B20
@"MADVIVisualSearchGatingRequest"
B44@0:8@16i24@28^@36
i40@0:8^@16^@24@32
i52@0:8^@16@24B32Q36Q44
i56@0:8^@16@24@32Q40Q48
i72@0:8^@16^I24^i32^i40@48@56@64
i52@0:8@16@24@32B40^@44
i32@0:8@16^@24
@"VCPFaceMerger"
v32@0:8@"<SNRequest>"16@"<SNResult>"24
v32@0:8@"<SNRequest>"16@"NSError"24
v24@0:8@"<SNRequest>"16
@52@0:8{?=qiIq}16f40@44
v36@0:8r^{?=qiIq}16r^{?=qiIq}24f32
i52@0:8^{opaqueCMSampleBuffer=}16{?=qiIq}24i48
@"SNAudioStreamAnalyzer"
@"VCPCNNMetalContext"
Q40@0:8Q16Q24Q32
@20@0:8I16
@"MADVIVisualSearchRequest"
{CGRect={CGPoint=dd}{CGSize=dd}}64@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGSize=dd}48
{CGRect={CGPoint=dd}{CGSize=dd}}80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48
{CGPoint=dd}64@0:8{CGPoint=dd}16{CGRect={CGPoint=dd}{CGSize=dd}}32
i56@0:8^{__CVBuffer=}16{CGRect={CGPoint=dd}{CGSize=dd}}24
B72@0:8{?=qiIq}16{?=qiIq}40^@64
@"VCPVideoProcessorSession"
@"VCPProtoVideoKeyFrame"
@24@0:8i16i20
i52@0:8^{__sFILE=*iiss{__sbuf=*i}i^v^?^?^?^?{__sbuf=*i}^{__sFILEX}i[3C][1C]{__sbuf=*i}iq}16^f24^f32i40i44i48
{Scaler="pool_"^{__CVPixelBufferPool}"width_"i"height_"i"crop_rect_"{CGRect="origin"{CGPoint="x"d"y"d}"size"{CGSize="width"d"height"d}}"sw_scaler_"^{OpaqueVTPixelTransferSession}}
{vector<__CVBuffer *, std::allocator<__CVBuffer *>>="__begin_"^^{__CVBuffer}"__end_"^^{__CVBuffer}"__end_cap_"{__compressed_pair<__CVBuffer **, std::allocator<__CVBuffer *>>="__value_"^^{__CVBuffer}}}
v80@0:8{?={?=qiIq}{?=qiIq}}16@64@72
v96@0:8@16@24{?={?=qiIq}{?=qiIq}}32@80@88
@32@0:8@16d24
@36@0:8f16f20f24f28f32
{CGRect={CGPoint=dd}{CGSize=dd}}24@0:8f16f20
i64@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16^{__CVBuffer=}48^q56
@40@0:8@16@24Q32
@72@0:8{?={?=qiIq}{?=qiIq}}16^Q64
@40@0:8@16r^{?={?=qiIq}{?=qiIq}}24Q32
i48@0:8@16r^{?={?=qiIq}{?=qiIq}}24Q32@?40
i64@0:8@16{?=qiIq}24Q48@?56
@32@0:8@?16^B24
@"VCPAsset"
@48@0:8i16B20B24@28@36i44
i48@0:8[21{CGPoint=dd}]16^f24@32@40
@"VCPCNNHandsDetector"
@"VCPCNNHandKeypointsDetector"
@48@0:8@16@24@?32@?40
i48@0:8^{CGRect={CGPoint=dd}{CGSize=dd}}16^{__CVBuffer=}24^f32i40i44
f52@0:8^f16i24i28i32*36f44i48
i52@0:8^{__CVBuffer=}16^f24^f32f40@?44
@44@0:8@16@24@32i40
Q40@0:8^{?=Q^@^Q[5Q]}16^@24Q32
@56@0:8@16@24Q32@?40@?48
@"VCPProtoLivePhotoVariationParams"
{?="epoch"b1"flags"b1}
@28@0:8Q16B24
i48@0:8^{opaqueCMSampleBuffer=}16{?=qiIq}24
i24@0:8^{opaqueCMSampleBuffer=}16
i40@0:8@16@?24^@32
{AudioTimeStamp="mSampleTime"d"mHostTime"Q"mRateScalar"d"mWordClockTime"Q"mSMPTETime"{SMPTETime="mSubframes"s"mSubframeDivisor"s"mCounter"I"mType"I"mFlags"I"mHours"s"mMinutes"s"mSeconds"s"mFrames"s}"mFlags"I"mReserved"I}
{AudioBufferList="mNumberBuffers"I"mBuffers"[1{AudioBuffer="mNumberChannels"I"mDataByteSize"I"mData"^v}]}
@"VCPVoiceDetector"
@"VCPAudioClassifier"
@"VCPLoudnessAnalyzer"
@"VCPSongDetector"
i32@0:8^{__CVBuffer=}16^f24
i72@0:8^f16^{__CVBuffer=}24i32i36{CGRect={CGPoint=dd}{CGSize=dd}}40
@"VCPFaceClusterer"
@36@0:8i16B20B24@28
@"VCPCNNPersonDetector"
@"VCPCNNPersonKeypointsDetector"
@"MADVIRectangleDetectionRequest"
B32@0:8q16Q24
B24@0:8q16
i32@0:8@16q24
i56@0:8^@16@24@32@40Q48
i56@0:8^@16@24q32Q40Q48
i40@0:8^@16^{__CVBuffer=}24@32
i44@0:8^@16^{__CVBuffer=}24Q32B40
i32@0:8^@16^{__CVBuffer=}24
i72@0:8^@16q24Q32Q40^{__CVBuffer=}48^{__CVBuffer=}56@64
v56@0:8@16q24Q32Q40@?48
@"VCPPreAnalysisImageLoader"
@"VCPPoolBasedPixelBufferCreator"
@"VCPMAMLModel"
@44@0:8@16r^{?={?=qiIq}{?=qiIq}}24@32B40
i48@0:8^f16^{__CVBuffer=}24i32i36@40
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
@32@0:8r^16Q24
r^16@0:8
@96@0:8{?=[4]}16@80@88
@"VCPFaceGeometry"
{?="columns"[4]}
@80@0:8Q16{CGAffineTransform=dddddd}24@72
@40@0:8Q16@24@32
@88@0:8Q16{CGAffineTransform=dddddd}24f72@76B84
B32@0:8r^{CGAffineTransform=dddddd}16@24
{CGAffineTransform=dddddd}28@0:8i16^{__CVBuffer=}20
{?=[4]}84@0:8{?=[4]}16i80
@88@0:8^{__CVBuffer=}16{?=qiIq}24{?=qiIq}48@72^@80
i88@0:8^{__CVBuffer=}16{?=qiIq}24{?=qiIq}48@72@?80
i72@0:8{?={?=qiIq}{?=qiIq}}16@64
B68@0:8{?=qiIq}16{?=qiIq}40B64
@"VCPVideoFacePoseAnalyzer"
@"VCPVideoFaceMeshAnalyzer"
@"VCPFullVideoAnalyzer"
@"VCPAudioAnalyzer"
@"VCPVideoFullFaceDetector"
@"VCPSceneChangeAnalyzer"
@"VCPLightMotionAnalyzer"
@"VCPTrimAnalyzer"
@"VCPHomeKitMotionAnalyzer"
^{Rotator=^{__CVPixelBufferPool}iii^{OpaqueVTPixelRotationSession}}
i32@0:8^{__CVBuffer=}16@?24
i92@0:8^{__CVBuffer=}16^v24{?=qiIq}32{?=qiIq}56i80@?84
@"VCPMotionFlowRequest"
i52@0:8@16B24@?28^Q36^@44
@96@0:8{CGAffineTransform=dddddd}16@64@72B80B84@?88
@40@0:8i16i20Q24Q32
i56@0:8i16i20r^f24^f32Q40Q48
i60@0:8{Kernel=^fQQ}16f40f44f48f52f56
^^{Kernel}
v48@0:8@"NSDictionary"16@"NSString"24@"NSURL"32@?<v@?>40
v40@0:8@"NSString"16@"NSURL"24@?<v@?@"NSString">32
@60@0:8@16Q24@32@40B48@?52
@48@0:8@16@24Q32^@40
@64@0:8Q16@24@32@40@48@?56
i48@0:8@16Q24@?32@?40
v40@0:8@16@24^q32
v88@0:8@16#24{?={?=qiIq}{?=qiIq}}32@80
@108@0:8#16@24@32@40{?={?=qiIq}{?=qiIq}}48B96^B100
v48@0:8@16@24^q32^f40
v144@0:8@16{?={?=qiIq}{?=qiIq}}24@72{?={?=qiIq}{?=qiIq}}80^q128^f136
i64@0:8Q16@24@32@?40@?48@56
i52@0:8@16Q24B32@?36@?44
@52@0:8Q16@24B32@?36^@44
@56@0:8Q16@24@32@?40^@48
@44@0:8@16@24Q32B40
{?={?=qiIq}{?=qiIq}}32@0:8@16@24
{atomic<int>="__a_"{__cxx_atomic_impl<int, std::__cxx_atomic_base_impl<int>>="__a_value"Ai}}
i44@0:8^f16i24i28B32*36
@32@0:8Q16^{opaqueCMFormatDescription=}24
B24@0:8^{opaqueCMFormatDescription=}16
{CGSize=dd}24@0:8^{opaqueCMFormatDescription=}16
@24@0:8^{opaqueCMFormatDescription=}16
^{__CFData=}24@0:8^{opaqueCMFormatDescription=}16
^{__CFData=}28@0:8I16^{__CFData=}20
i32@0:8^{FigLivePhotoMetadata=I{FigLivePhotoMetadataV1Struct=fqffffffccSI[0{FigLivePhotoDetectedFaceV1Struct=qffffisS}]}}16@24
{CGVector="dx"d"dy"d}
@"NSMutableData"
@"VCPVideoMetaFocusAnalyzer"
@"VCPVideoMetaMotionAnalyzer"
@"VCPVideoMetaLensSwitchAnalyzer"
@32@0:8{CGPoint=dd}16
@36@0:8i16i20i24@28
@36@0:8^f16i24i28f32
i28@0:8i16@20
@44@0:8@16i24i28i32i36i40
v60@0:8*16i24i28i32^f36^f44^f52
v36@0:8^f16^f24i32
^{LandmarkDetector=iiiiiiiB^f^f^f^i^{ZPoint}^{RegressionTree}^?}
#20@0:8i16
@36@0:8i16i20i24B28B32
@"VNSession"
@40@0:8i16B20B24@28i36
i48@0:8^f16i24i28@32[3[2f]]40
i36@0:8r^v16@24i32
i72@0:8*16i24i28i32{CGPoint=dd}36{CGPoint=dd}52I68
i44@0:8*16i24i28i32^{CGPoint=dd}36
B32@0:8@"AVAssetResourceLoader"16@"AVAssetResourceLoadingRequest"24
B32@0:8@"AVAssetResourceLoader"16@"AVAssetResourceRenewalRequest"24
v32@0:8@"AVAssetResourceLoader"16@"AVAssetResourceLoadingRequest"24
B32@0:8@"AVAssetResourceLoader"16@"NSURLAuthenticationChallenge"24
v32@0:8@"AVAssetResourceLoader"16@"NSURLAuthenticationChallenge"24
@32@0:8#16Q24
@"NSURLSessionDataTask"
^{__CVBuffer=}56@0:8^{__CVBuffer=}16{CGRect={CGPoint=dd}{CGSize=dd}}24
@"VCPSegment"
^{HinkleyDetector=ffi{HinkleyStats=ffff}}
@52@0:8B16@20I28B32B36B40@?44
i40@0:8^{__CVBuffer=}16^{__CVBuffer=}24^{__CVBuffer=}32
@"<MTLDeviceSPI>"
@"<MTLCommandQueue>"
@"MPSImageBilinearScale"
@"MPSImageSpatioTemporalGuidedFilter"
v24@0:8@"PHPhotoLibrary"16
{CGSize=dd}32@0:8@16@24
i40@0:8^@16#24@32
^{__CVBuffer=}36@0:8@16@24i32
i52@0:8^@16#24@32@40B48
i48@0:8^f16@24@32@40
i40@0:8^f16@24@32
v52@0:8f16@20Q28Q36Q44
v44@0:8f16@20Q28Q36
i40@0:8@16^@24^@32
i32@0:8^@16^@24
v56@0:8@16@24@32@?40@?48
B48@0:8@16^@24@?32@?40
i48@0:8^@16^@24@?32@?40
d80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48
i72@0:8@16^@24^@32^@40^@48@?56@?64
i80@0:8@16@24@32@40@48^@56@?64@?72
i48@0:8@16@24@32@40
i64@0:8@16@24@32^@40@?48@?56
i56@0:8@16@24^@32@?40@?48
i48@0:8@16^@24@?32@?40
@"MADVIUserFeedbackRequest"
@88@0:8@16{CGAffineTransform=dddddd}24Q72^{opaqueCMFormatDescription=}80
B40@0:8@16#24@32
v32@0:8{CGPoint=dd}16
{CGPoint="x"d"y"d}
^{__CVBuffer=}16@0:8
{CGRect={CGPoint=dd}{CGSize=dd}}24@0:8@16
@"PHFetchResult"
i48@0:8^{CGPoint=dd}16[21f]24@32@40
i40@0:8^f16^{__CVBuffer=}24@32
{vector<int, std::allocator<int>>="__begin_"^i"__end_"^i"__end_cap_"{__compressed_pair<int *, std::allocator<int>>="__value_"^i}}
@"VCPCNNFastGestureRecognition"
@28@0:8f16B20B24
v40@0:8i16i20i24^f28i36
i84@0:8^{__CVBuffer=}16{CGRect={CGPoint=dd}{CGSize=dd}}24i56{?=qiIq}60
r^f16@0:8
@"VCPRTLandmarkDetector"
@"VCPFaceShapeModel"
[5@"VCPLandmarkValidator"]
B40@0:8@16Q24Q32
i32@0:8^^{__CVBuffer}16i24B28
i56@0:8@16i24Q28^^{__CVBuffer}36^I44B52
i48@0:8^{CGImage=}16i24I28Q32^^{__CVBuffer}40
i60@0:8^{CGImageSource=}16@24i32Q36^I44^^{__CVBuffer}52
^{__CVBuffer=}56@0:8i16Q20@28@36B44^I48
^{__CVBuffer=}28@0:8@16i24
^{__CVBuffer=}36@0:8@16i24Q28
^{__CVBuffer=}44@0:8@16i24Q28^I36
^{__CVBuffer=}32@0:8i16@20B28
^{__CVBuffer=}48@0:8i16Q20@28B36^I40
^{__CVBuffer=}40@0:8i16@20B28^I32
^{__CVBuffer=}36@0:8i16Q20@28
^{__CVBuffer=}44@0:8i16Q20@28^I36
i44@0:8^{__CVBuffer=}16^@24Q32B40
^{CMPhotoCompressionSession=}
^{CMPhotoDecompressionSession=}
i64@0:8^f16i24i28i32i36i40^{CGPoint=dd}44^f52f60
i52@0:8^{__CVBuffer=}16@24[21{CGPoint=dd}]32[21f]40B48
^{OpaqueAudioComponentInstance=}
@"VCPVideoMetaFocusSegment"
@48@0:8q16{?=qiIq}24
v48@0:8q16{?=qiIq}24
i32@0:8Q16Q24
i40@0:8^^{__CVBuffer}16Q24Q32
v52@0:8Q16@24i32@36@?44
v52@0:8Q16@"NSData"24i32@"NSDictionary"36@?<v@?@"NSDictionary"@"NSError">44
v52@0:8Q16@"IOSurface"24i32@"NSDictionary"36@?<v@?@"NSDictionary"@"NSError">44
v44@0:8i16@"NSData"20@"NSDictionary"28@?<v@?@"NSString"@"NSError">36
v36@0:8i16@"NSDictionary"20@?<v@?@"NSDictionary"@"NSError">28
@40@0:8@16@24d32
@24@0:8d16
v48@0:8@16@24Q32Q40
@72@0:8@16@24@32Q40Q48Q56Q64
{?={?=qiIq}{?=qiIq}}32@0:8@16f24B28
i48@0:8@16f24f28f32B36@?40
i56@0:8B16@20@28f36f40f44B48B52
f28@0:8f16@20
f48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
@36@0:8q16q24I32
i44@0:8^^{__CVPixelBufferPool}16q24q32I40
i24@0:8^^{__CVBuffer}16
{CF<__CVPixelBufferPool *>="value_"^{__CVPixelBufferPool}}
i48@0:8@16@24@?32^@40
@44@0:8B16@20B28B32B36B40
i28@0:8f16i20i24
i56@0:8@16@24@32@40@48
@"<MTLComputePipelineState>"
@"<MTLLibrary>"
i40@0:8^{__CVBuffer=}16^^{__CVBuffer}24Q32
i64@0:8@16Q24@32^^{__CVBuffer}40^^{__CVBuffer}48^@56
@"VCPSceneProcessingImageManager"
{CF<OpaqueVTPixelTransferSession *>="value_"^{OpaqueVTPixelTransferSession}}
@"<MTLCommandBuffer>"
i40@0:8^Q16^Q24@?32
@32@0:8@?16@24
v36@0:8@16Q24B32
i48@0:8@16@24^@32^@40
v44@0:8@16Q24B32@?36
i88@0:8{?=qiIq}16{?=qiIq}40{?=qiIq}64
f56@0:8i16i20^{?={?=qiIq}{?=qiIq}}24{?=qiIq}32
B40@0:8{?=qiIq}16
B64@0:8{?=qiIq}16{?=qiIq}40
@"VCPActionAnalyzer"
B24@0:8^v16
[10f]
@"VCPSceneChangeSegment"
v40@0:8q16@24@32
v40@0:8d16@24@32
i40@0:8^^{__CVBuffer}16Q24^{__CVBuffer=}32
i32@0:8^^{__CVBuffer}16Q24
i40@0:8^^{__CVBuffer}16^{CGColorSpace=}24^{__CVBuffer=}32
i56@0:8^^{__CVBuffer}16^^{__CVBuffer}24^^{__CVBuffer}32@40Q48
i48@0:8^{__CVBuffer=}16^^{__CVBuffer}24Q32Q40
@76@0:8{CGAffineTransform=dddddd}16@64B72
@40@0:8f16{CGPoint=dd}20B36
v32@0:8r^f16^v24
i32@0:8^v16^v24
i40@0:8^v16^v24^f32
f32@0:8[3[3f]]16[3f]24
i56@0:8^v16r^f24[3[3f]]32[3f]40^f48
i56@0:8^v16^v24[4f]32^v40^v48
i40@0:8^v16^v24[4f]32
i36@0:8r^f16r^f24i32
v80@0:8{?=[4]}16
[4[3f]]
@"SHMutableSignature"
@56@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48
Q56@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24
i56@0:8@16Q24@?32@?40@?48
^q16@0:8
v32@0:8^q16Q24
{?="list"^q"count"Q"size"Q}
@20@0:8f16
i80@0:8^{__CVBuffer=}16{CGRect={CGPoint=dd}{CGSize=dd}}24{?=qiIq}56
@"VCPCNNFaceLandmarkDetector"
@"VCPVideoFacePoseFilter"
[14f]
[21f]
v24@0:8^{EncodeStats=^^?^B^B^{MotionVector}^{MotionVector}^{MotionVector}^{MotionVector}^S^S^I^S^S^S^S^S^S^S^S^S^S^SIBBBii}16
@24@0:8s16B20
[200@"VCPCNNBlock"]
@"VCPMADResourceManager"
@"VCPMADResource"
q24@0:8q16
@"VCPTimer"
@"NSObject<OS_os_transaction>"
i88@0:8^{__CVBuffer=}16^v24{?=qiIq}32{?=qiIq}56@?80
@72@0:8@16{CGSize=dd}24{CGRect={CGPoint=dd}{CGSize=dd}}40
v68@0:8{CGAffineTransform=dddddd}16B64
@32@0:8^{CGImage=}16^@24
B32@0:8^{CGImage=}16^@24
@"MLMultiArray"
@32@0:8^{__CVBuffer=}16^@24
v32@0:8^{__CVBuffer=}16^{CGPoint=dd}24
^{CGPoint=dd}16@0:8
v24@0:8^{CGPoint=dd}16
^{CGPoint=dd}
^{?=^{?}^{?}^{?}^{tplTracker_resampler_context}^{?}}
mcpl
v024
v024
mcpl
gepj
ARGB
@(#)PROGRAM:MediaAnalysis  PROJECT:MediaAnalysis-1
fff>
mcpl)
333?
#/;GS_k
L>N2ma15EncodeStatsAVE1E
B`e>;
$CV&
C2wACA
?16MAComputeRequest
'3?H
>N2ma19SubtleMotionSegmentE
?33s?22MAImageAnalysisRequest
NSt3__120__shared_ptr_emplaceI25VCPImageHumanPoseAnalyzerNS_9allocatorIS1_EEEE
fff?
#>Yt
N2ma17SlowMotionSegmentE
ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+%
14VCPProtoBounds
@pEff
B>fff?
G!?=
Ga>R
=q=J
ff&?R
Q8?H
?N4dlib7array2dIhNS_33memory_manager_stateless_kernel_1IcEEEE
N4dlib10enumerableIhEE
N4dlib33memory_manager_stateless_kernel_1IhEE
?333?
?333?
>N2ma12TrackSegmentE
N2ma11EncodeStatsE
>N2ma17DescriptorSegmentE
u?ff&?
>fff
'7NSt3__120__shared_ptr_emplaceI21VCPCNNEspressoContextNS_9allocatorIS1_EEEE
20MAImageComputeResult
<0L&=!
<yX(=4
<0L&=!
<yX(=
b=;p
Sc=;p
<5^:
e=X94
Y=X94</n#
=B`e<M
u`=e
w=B`e
N2ma18ObstructionSegmentE
MbP?
?ffffff
N4dlib17sequence_kernel_2INS_21lbfgs_search_strategy11data_helperENS_33memory_manager_stateless_kernel_1IcEEEE
N4dlib10enumerableINS_21lbfgs_search_strategy11data_helperEEE
N4dlib7removerINS_21lbfgs_search_strategy11data_helperEEE
N4dlib33memory_manager_stateless_kernel_1IdEE
NSt3__110__function6__funcINS_6__bindIPFdRKN4dlib6matrixIdLl0ELl0ENS3_33memory_manager_stateless_kernel_1IcEENS3_16row_major_layoutEEEPfSB_SB_SB_bEJRKNS_12placeholders4__phILi1EEERSB_SJ_RA12_fRA126_fbEEENS_9allocatorISO_EEFdS8_EEE
NSt3__110__function6__baseIFdN4dlib6matrixIdLl0ELl0ENS2_33memory_manager_stateless_kernel_1IcEENS2_16row_major_layoutEEEEEE
NSt3__16__bindIPFdRKN4dlib6matrixIdLl0ELl0ENS1_33memory_manager_stateless_kernel_1IcEENS1_16row_major_layoutEEEPfS9_S9_S9_bEJRKNS_12placeholders4__phILi1EEERS9_SH_RA12_fRA126_fbEEE
NSt3__118__weak_result_typeIPFdRKN4dlib6matrixIdLl0ELl0ENS1_33memory_manager_stateless_kernel_1IcEENS1_16row_major_layoutEEEPfS9_S9_S9_bEEE
NSt3__110__function6__funcINS_6__bindIPFN4dlib6matrixIdLl0ELl0ENS3_33memory_manager_stateless_kernel_1IcEENS3_16row_major_layoutEEERKS8_PfSB_SB_SB_bEJRKNS_12placeholders4__phILi1EEERSB_SJ_RA12_fRA126_fbEEENS_9allocatorISO_EEFS8_S8_EEE
NSt3__110__function6__baseIFN4dlib6matrixIdLl0ELl0ENS2_33memory_manager_stateless_kernel_1IcEENS2_16row_major_layoutEEES7_EEE
NSt3__16__bindIPFN4dlib6matrixIdLl0ELl0ENS1_33memory_manager_stateless_kernel_1IcEENS1_16row_major_layoutEEERKS6_PfS9_S9_S9_bEJRKNS_12placeholders4__phILi1EEERS9_SH_RA12_fRA126_fbEEE
NSt3__118__weak_result_typeIPFN4dlib6matrixIdLl0ELl0ENS1_33memory_manager_stateless_kernel_1IcEENS1_16row_major_layoutEEERKS6_PfS9_S9_S9_bEEE
NSt3__117bad_function_callE
N4dlib11fatal_errorE
N4dlib5errorE
NSt3__110__function6__funcINS_6__bindIPFdRKN4dlib6matrixIdLl0ELl0ENS3_33memory_manager_stateless_kernel_1IcEENS3_16row_major_layoutEEEPfSB_SB_SB_SB_SB_SB_PiSB_SB_EJRKNS_12placeholders4__phILi1EEERSB_RA12_fSK_SK_SK_SK_SB_SC_SK_SK_EEENS_9allocatorISN_EEFdS8_EEE
NSt3__16__bindIPFdRKN4dlib6matrixIdLl0ELl0ENS1_33memory_manager_stateless_kernel_1IcEENS1_16row_major_layoutEEEPfS9_S9_S9_S9_S9_S9_PiS9_S9_EJRKNS_12placeholders4__phILi1EEERS9_RA12_fSI_SI_SI_SI_S9_SA_SI_SI_EEE
NSt3__118__weak_result_typeIPFdRKN4dlib6matrixIdLl0ELl0ENS1_33memory_manager_stateless_kernel_1IcEENS1_16row_major_layoutEEEPfS9_S9_S9_S9_S9_S9_PiS9_S9_EEE
NSt3__110__function6__funcINS_6__bindIPFN4dlib6matrixIdLl0ELl0ENS3_33memory_manager_stateless_kernel_1IcEENS3_16row_major_layoutEEERKS8_PfSB_SB_SB_SB_SB_SB_PiSB_SB_SB_EJRKNS_12placeholders4__phILi1EEERSB_RA12_fSK_SK_SK_SK_SB_SC_SK_SK_SK_EEENS_9allocatorISN_EEFS8_S8_EEE
NSt3__16__bindIPFN4dlib6matrixIdLl0ELl0ENS1_33memory_manager_stateless_kernel_1IcEENS1_16row_major_layoutEEERKS6_PfS9_S9_S9_S9_S9_S9_PiS9_S9_S9_EJRKNS_12placeholders4__phILi1EEERS9_RA12_fSI_SI_SI_SI_S9_SA_SI_SI_SI_EEE
NSt3__118__weak_result_typeIPFN4dlib6matrixIdLl0ELl0ENS1_33memory_manager_stateless_kernel_1IcEENS1_16row_major_layoutEEERKS6_PfS9_S9_S9_S9_S9_S9_PiS9_S9_S9_EEE
NSt3__110__function6__funcINS_6__bindIPFdRKN4dlib6matrixIdLl0ELl0ENS3_33memory_manager_stateless_kernel_1IcEENS3_16row_major_layoutEEEPfSB_EJRKNS_12placeholders4__phILi1EEERA126_fRA189_fEEENS_9allocatorISN_EEFdS8_EEE
NSt3__16__bindIPFdRKN4dlib6matrixIdLl0ELl0ENS1_33memory_manager_stateless_kernel_1IcEENS1_16row_major_layoutEEEPfS9_EJRKNS_12placeholders4__phILi1EEERA126_fRA189_fEEE
NSt3__118__weak_result_typeIPFdRKN4dlib6matrixIdLl0ELl0ENS1_33memory_manager_stateless_kernel_1IcEENS1_16row_major_layoutEEEPfS9_EEE
=AB/'
R[DmPJ>
@Z_g@
@333?
>43s?433?
".cc
@333?
?N2ma20SubjectMotionSegmentE
228VCPProtoImageHumanPoseResult
@oDA
ffffff
?333333
N2ma14QualitySegmentE
N2ma19CameraMotionSegmentE
?N2ma19MovingObjectSegmentE
:L=ix
/ L[
AGA)\
N2ma22InterestingnessSegmentE
16VCPProtoKeypoint
22MAMovieAnalysisRequest
xfua2vpe
N2ma12SceneSegmentE
333333
@lwh
N2ma15RotationSegmentE
N2ma15EncodeStatsAVE2E
N2ma13EncodeStatsHWE
BN2ma24FineSubjectMotionSegmentE
333?fff?ff
N2ma7SegmentE
N2ma13EncodeStatsSWE
 ,8DP\ht
Q9RI
Q9RI
7:RI
Q9RI
d*;4
>;_)K;
DX;B`e;
{r;l
k;B`e;
Q;_)K;
#;RI
7:RI
Q9RI
d*;4
7;_)K;
DX;B`e;
{r;o
{r;B`e;
DX;_)K;4
d*;RI
7:RI
Q9RI
7;_)K;
y;KY
3"<U
-<X94<
b<B`e<
4o<E
{r<!
ew<l
{r<E
h<B`e<e
#9<X94<
3"<RI
^;_)K;4
7:RI
Q9RI
k;KY
Q:RI
Q9RI
k:RI
DX;$
d*<4
?F<4
DX;4
Q:RI
>;B`e;'
#<X94<
z<KY
$=yX(=V
7=5^:=[
2D=]mE=
?F=]mE=
2D=\
<=5^:=
-2=2
+=yX(=
D<X94<
;B`e;
>;RI
{r<&
=R' =T
b=B`e=B>h=h
4o= Aq=
{r=F
{r= Aq=
(m=h
j=B>h=B`e=e
WJ=9
E6=|
%=R' =Qk
k:RI
7;B`e;
?$=V
b=B>h=D
s=Gry=
\~=n
\~=Gry=F
m=B>h=e
?$=v
;B`e;4
DX;'
3"<4
=R' =U
(=W[1=Z
B=_)K=a
S=d]\=
d=d]\=a
S=_)K=\
9=W[1=U
(=R' =P
j<<b
ew=I
{r<b
j<<>
ew<M
ew<>
=yX(=
A=;pN=
h=k+v=n
=k+v=
[=;pN=
5=yX(=
ew<b
7:RI
{r<M
7x=J{
/>:#
O/<N
=yX(=Y
U=B`e=
9#>/
$>0L&>
d*>1
'>0L&>/
Yu=B`e=
?F=Y
7=yX(=u
7;KY
=z6+=
/;=:
K=d]\=D
m=I.
V,>i
9>lx:>
<>6<=>
=>6<=>
;>lx:>l
u1>i
V,>
m=d]\=:
/;=z6+=
;_)K;
{r<)\
q,=6<==
Ga=F
s=J{
u >/
!N>`vO>
|P>`vO>
2D>7
~;>~
N=6<==
;_)K;o
<X94<
=z6+=6<==
ew=o
G!>ff&>
+>io0>F%5>
9>[B>>%uB>
qJ>_
QZ>?
+e>x
F>%uB>[B>>
9>F%5>io0>
+>ff&>
P=6<==z6+=u
/]<X94<r
Q9RI
{r<N
=yX(=
x=p_
/>aT
X>RI]>
Ga>f
n>W[q>}
=y>lxz>Zd{>
|>HP|>HP|>
|>Zd{>lxz>
s>W[q>
rh>f
Ga>RI]>P
/>o
/;=yX(=
y;RI
d*;KY
d*<b
ew=p_
2>Gr9>[
sW>v
8g>1
|>n4
3b>v
?>Gr9>
%>d;
Ga=:
d*<o
?F=d]\=F
8V>?
c>gDi>
t>5^z>$
>5^z>
4o>gDi>
s=d]\=
<;p
:_)K;RI
=yX(=
m=J{
P>>yX>
_>>yX>
kI>n
v>=yX(=
;_)K;
T<KY
L=B`e=I.
..>}
6>I.?>
h>iop>~
x>iop>
DX>r
G>I.?>}
c>]
=B`e=
;B`e;X9
c<)\
>B>(>W[1>lx:>
C>lx:>W[1>B>(>-!
;B`e;o
5=;pN=
>R' >z
!=>]
|P>]
g3>z
)>R' >b
xi=;pN=
{r;'
>R' >
m4>m
ZS>-
-r>HP|>
>HP|>
J*>R' >
?F<N
h=J{
H?>:#J>+
U>:#J>
m4>z
)>-!
=R' =
sW=k+v=(
>B>(>
g3>m
>>:#J>=
U>w-a>
l>w-a>=
U>:#J>m
g3>B>(>
=k+v=
:=R' =
#<B`
d*;u
Sc=n
%>W[1>
U>w-a>
\m>~
\m>w-a>+
!=>W[1>
Jj<1
d*;RI
=W[1=
..>lx:>]
ZS>]
F>lx:>
AO=W[1=
5<HP
7;RI
|P>-
:_)K;|
?$=\
Sc=o
/>>y
2>I.?>_
6Z>_
L>I.?>
%>>y
/>n4
Sc=\
;_)K;4
+=_)K=
(m=p
q,>#
q?_
q?h
q,>d;
(m=_)K=V
ew=r
\m>HP|>
c?r
>HP|>
%>>y
ew=a
2=tF
:B`e;
9=d]\=I
=d]\=Z
9=Qk
u`<RI
;B`e;
=R' =
d=&S
:p>7
R&?t
@=R' =
l=q=
~*>Gr9>p
H>>yX>
f%?=
+?-C,?
,?-C,?
h>>yX>p
H>Gr9>
{r<U
:0>[
_>iop>I
;.?{
;.?$
@"?$
>iop>
G!><
;X94<
fU=$
>ff&>
y'?u
c,?r
0?EG2?}
7?^K8?Y
8?^K8?
+5?}
3?EG2?
c,?u
y'?j
8V>9
5>ff&>
fU=|
<X94<B`
?n4 ?
,?I./?
1?I./?D
#?n4 ?
E6=tF
u >io0>
t>J{
$?B>(?
1?X94?
6?X94?
+?B>(?
@>io0>
@=B>h=
$>F%5>
sW>gDi>
V?E
%?gD)?
,?R'0?
S3?0L6?
>?R'@?
8E?a
B?R'@?_
9?0L6?
S3?R'0?
,?gD)?"
V?0
~{>gDi>
F>F%5>/
=B>h=
B<HP
41?4
=?io@?
H?q=J?
~K?(~L?6<M?H
M?6<M?(~L?
~K?q=J?U
B?io@?d
41?h
4o>v
WJ=F
s=Nb
->[B>>r
4!?"
1?]m5?
I<?Di??aTB?
O?2UP?
aQ?2UP?
E?aTB?Di??
8?]m5?
3b>r
O>[B>>V
=yX(=
N=Gry=*
0>%uB>
8g>5^z>
?n4 ?
$?gD)?h
F?GrI?
HN?2UP?
&R?F
V?p_W?
W?p_W?
&R?2UP?
K?GrI?}
-?gD)?
$?n4 ?
>5^z>
T>%uB>|
=Gry=
N=yX(=
Q<KY
S#>4
#?B>(?
41?]m5?c
A?o
X?GrY?
Z??W[?
[?h"\?h"\?
[??W[?
Z?GrY?~
\=?c
9?]m5?
,?B>(?
S#><
ZS=V
Y<RI
sW=n
qJ>RI]>
+?R'0?4
D?yXH?q
Q?tFT?}
Z?HP\?
_?R'`?
h`?R'`?$
]?HP\?h
V?tFT?n
K?yXH?
4?R'0?
p>RI]>
qJ>~
sW=2
<RI
~;>_
|@?o
D?yXH?
UO?A
R?]mU?~
c?=,d?Ttd?Ttd?=,d?
X?]mU?A
K?yXH?o
Ga>_
~;>
y'?D
1?0L6?
:?Di??
UO?X
.^?Nb`?aTb?
d?]me?
eg?+
Dh?+
f?]me?
d?aTb?Nb`?
UO?q
C?Di??
:?0L6?
V,>,
<B`e<
b='1
rh>[
*?I./?X94?
=?aTB?}
U?gDY?
I\?gDY?
F?aTB?d
9?X94?I./?u
rh>O
/>G
<B`e<
=5^:=B`e=q=
k>n4
;?io@?
E?GrI?
Q?]mU?
&b?O
(l?mVm??5n?
n??5n?mVm?
X?]mU?n
M?GrI?
E?io@?
=B`e=5^:=
<=B>h=
q?aT
:P?tFT?~
m?-!o?
Np?-!o?
X?tFT?
a!>r
=B>h=[
4o<z6
9#>X
\>W[q>
f%?
;?R'@?
g?U0j?
n?2Up?N
q?2Up?
l?U0j?
E?R'@?C
>W[q>?
(m=M
G!?=
,?EG2?
K?2UP?O
\?Nb`?}
?t?]mu?KYv?
v?KYv?]mu?
?t?<
c?Nb`?$
T?2UP?
7?EG2?$
G!?Zd
{r<V}
>0L&>l
;.?}
&R?+
^?aTb?
t?KYv?
w?>yx?
y?,ey?,ey?
y?>yx?
w?KYv?
e?aTb?
J9?}
9>0L&>tF
4o=\
B=Qk
2D= Aq=
'>lx:>
!N>x
8E?q=J?
X?HP\?
m?2Up?<
v?'1x?
ky?'1x?
r?2Up?
H`?HP\?~
O?q=J?
+5?{
!N>lx:>
= Aq=
t<RI
=]mE=
;>`vO>x
~K?2UP?
U?GrY?
a?]me?5
(l?-!o?N
?t?KYv?'1x?^
{?(~|?
|?(~|?
y?'1x?KYv?
?t?N
q?-!o?
(l?5
h?]me?
]?GrY?
U?2UP?
=y>x
d>`vO>
{r=]mE=
u<RI
ew<3
?F=F
+e>lxz>B>
eG?(~L?
aQ?4
j?mVm?
Np?S
s?]mu?
/|?q
w?]mu?S
Np?mVm?
aQ?(~L?
>lxz>
^)>=
?F=RI
)>6<=>
e>Zd{>9
R&?-C,?
$H?6<M?
V??W[?$
eg?c
j??5n?
s?KYv?>yx?
Wz?>yx?KYv?
4q??5n?c
_??W[?
&R?6<M?
2?-C,?
A ?:#
>Zd{>
4Q>6<=>
Yu=*
2?^K8?
R?p_W?
[?R'`?=,d?+
z?(~|?H
}?(~|?
g?=,d?R'`?
[?p_W?
=?^K8?\
d*>+
f>HP|>L7
W?h"\?
h`?Ttd?
Dh?6
>w?,ey?
C{?,ey?
Dh?Ttd?
h`?h"\?
!>?Y
>HP|>B
 <X9
f>HP|>L7
W?h"\?
h`?Ttd?
Dh?6
>w?,ey?
C{?,ey?
Dh?Ttd?
h`?h"\?
!>?Y
>HP|>B
 <X9
Yu=*
2?^K8?
R?p_W?
[?R'`?=,d?+
z?(~|?H
}?(~|?
g?=,d?R'`?
[?p_W?
=?^K8?\
d*>+
)>6<=>
e>Zd{>9
R&?-C,?
$H?6<M?
V??W[?$
eg?c
j??5n?
s?KYv?>yx?
Wz?>yx?KYv?
4q??5n?c
_??W[?
&R?6<M?
2?-C,?
A ?:#
>Zd{>
4Q>6<=>
ew<3
?F=F
+e>lxz>B>
eG?(~L?
aQ?4
j?mVm?
Np?S
s?]mu?
/|?q
w?]mu?S
Np?mVm?
aQ?(~L?
>lxz>
^)>=
?F=RI
=]mE=
;>`vO>x
~K?2UP?
U?GrY?
a?]me?5
(l?-!o?N
?t?KYv?'1x?^
{?(~|?
|?(~|?
y?'1x?KYv?
?t?N
q?-!o?
(l?5
h?]me?
]?GrY?
U?2UP?
=y>x
d>`vO>
{r=]mE=
u<RI
2D= Aq=
'>lx:>
!N>x
8E?q=J?
X?HP\?
m?2Up?<
v?'1x?
ky?'1x?
r?2Up?
H`?HP\?~
O?q=J?
+5?{
!N>lx:>
= Aq=
t<RI
{r<V}
>0L&>l
;.?}
&R?+
^?aTb?
t?KYv?
w?>yx?
y?,ey?,ey?
y?>yx?
w?KYv?
e?aTb?
J9?}
9>0L&>tF
4o=\
B=Qk
(m=M
G!?=
,?EG2?
K?2UP?O
\?Nb`?}
?t?]mu?KYv?
v?KYv?]mu?
?t?<
c?Nb`?$
T?2UP?
7?EG2?$
G!?Zd
4o<z6
9#>X
\>W[q>
f%?
;?R'@?
g?U0j?
n?2Up?N
q?2Up?
l?U0j?
E?R'@?C
>W[q>?
<=B>h=
q?aT
:P?tFT?~
m?-!o?
Np?-!o?
X?tFT?
a!>r
=B>h=[
=5^:=B`e=q=
k>n4
;?io@?
E?GrI?
Q?]mU?
&b?O
(l?mVm??5n?
n??5n?mVm?
X?]mU?n
M?GrI?
E?io@?
=B`e=5^:=
<B`e<
b='1
rh>[
*?I./?X94?
=?aTB?}
U?gDY?
I\?gDY?
F?aTB?d
9?X94?I./?u
rh>O
/>G
<B`e<
y'?D
1?0L6?
:?Di??
UO?X
.^?Nb`?aTb?
d?]me?
eg?+
Dh?+
f?]me?
d?aTb?Nb`?
UO?q
C?Di??
:?0L6?
V,>,
~;>_
|@?o
D?yXH?
UO?A
R?]mU?~
c?=,d?Ttd?Ttd?=,d?
X?]mU?A
K?yXH?o
Ga>_
~;>
Y<RI
sW=n
qJ>RI]>
+?R'0?4
D?yXH?q
Q?tFT?}
Z?HP\?
_?R'`?
h`?R'`?$
]?HP\?h
V?tFT?n
K?yXH?
4?R'0?
p>RI]>
qJ>~
sW=2
<RI
S#>4
#?B>(?
41?]m5?c
A?o
X?GrY?
Z??W[?
[?h"\?h"\?
[??W[?
Z?GrY?~
\=?c
9?]m5?
,?B>(?
S#><
ZS=V
=yX(=
N=Gry=*
0>%uB>
8g>5^z>
?n4 ?
$?gD)?h
F?GrI?
HN?2UP?
&R?F
V?p_W?
W?p_W?
&R?2UP?
K?GrI?}
-?gD)?
$?n4 ?
>5^z>
T>%uB>|
=Gry=
N=yX(=
Q<KY
WJ=F
s=Nb
->[B>>r
4!?"
1?]m5?
I<?Di??aTB?
O?2UP?
aQ?2UP?
E?aTB?Di??
8?]m5?
3b>r
O>[B>>V
41?4
=?io@?
H?q=J?
~K?(~L?6<M?H
M?6<M?(~L?
~K?q=J?U
B?io@?d
41?h
4o>v
@=B>h=
$>F%5>
sW>gDi>
V?E
%?gD)?
,?R'0?
S3?0L6?
>?R'@?
8E?a
B?R'@?_
9?0L6?
S3?R'0?
,?gD)?"
V?0
~{>gDi>
F>F%5>/
=B>h=
B<HP
u >io0>
t>J{
$?B>(?
1?X94?
6?X94?
+?B>(?
@>io0>
?n4 ?
,?I./?
1?I./?D
#?n4 ?
E6=tF
;X94<
fU=$
>ff&>
y'?u
c,?r
0?EG2?}
7?^K8?Y
8?^K8?
+5?}
3?EG2?
c,?u
y'?j
8V>9
5>ff&>
fU=|
<X94<B`
:0>[
_>iop>I
;.?{
;.?$
@"?$
>iop>
G!><
l=q=
~*>Gr9>p
H>>yX>
f%?=
+?-C,?
,?-C,?
h>>yX>p
H>Gr9>
{r<U
=R' =
d=&S
:p>7
R&?t
@=R' =
:B`e;
9=d]\=I
=d]\=Z
9=Qk
u`<RI
;B`e;
ew=r
\m>HP|>
c?r
>HP|>
%>>y
ew=a
2=tF
+=_)K=
(m=p
q,>#
q?_
q?h
q,>d;
(m=_)K=V
:_)K;|
?$=\
Sc=o
/>>y
2>I.?>_
6Z>_
L>I.?>
%>>y
/>n4
Sc=\
;_)K;4
|P>-
=W[1=
..>lx:>]
ZS>]
F>lx:>
AO=W[1=
5<HP
7;RI
d*;u
Sc=n
%>W[1>
U>w-a>
\m>~
\m>w-a>+
!=>W[1>
Jj<1
d*;RI
=R' =
sW=k+v=(
>B>(>
g3>m
>>:#J>=
U>w-a>
l>w-a>=
U>:#J>m
g3>B>(>
=k+v=
:=R' =
#<B`
h=J{
H?>:#J>+
U>:#J>
m4>z
)>-!
>R' >
m4>m
ZS>-
-r>HP|>
>HP|>
J*>R' >
?F<N
5=;pN=
>R' >z
!=>]
|P>]
g3>z
)>R' >b
xi=;pN=
{r;'
;B`e;X9
c<)\
>B>(>W[1>lx:>
C>lx:>W[1>B>(>-!
;B`e;o
T<KY
L=B`e=I.
..>}
6>I.?>
h>iop>~
x>iop>
DX>r
G>I.?>}
c>]
=B`e=
:_)K;RI
=yX(=
m=J{
P>>yX>
_>>yX>
kI>n
v>=yX(=
;_)K;
?F=d]\=F
8V>?
c>gDi>
t>5^z>$
>5^z>
4o>gDi>
s=d]\=
<;p
d*;KY
d*<b
ew=p_
2>Gr9>[
sW>v
8g>1
|>n4
3b>v
?>Gr9>
%>d;
Ga=:
d*<o
Q9RI
{r<N
=yX(=
x=p_
/>aT
X>RI]>
Ga>f
n>W[q>}
=y>lxz>Zd{>
|>HP|>HP|>
|>Zd{>lxz>
s>W[q>
rh>f
Ga>RI]>P
/>o
/;=yX(=
y;RI
<X94<
=z6+=6<==
ew=o
G!>ff&>
+>io0>F%5>
9>[B>>%uB>
qJ>_
QZ>?
+e>x
F>%uB>[B>>
9>F%5>io0>
+>ff&>
P=6<==z6+=u
/]<X94<r
;_)K;
{r<)\
q,=6<==
Ga=F
s=J{
u >/
!N>`vO>
|P>`vO>
2D>7
~;>~
N=6<==
;_)K;o
7;KY
=z6+=
/;=:
K=d]\=D
m=I.
V,>i
9>lx:>
<>6<=>
=>6<=>
;>lx:>l
u1>i
V,>
m=d]\=:
/;=z6+=
=yX(=Y
U=B`e=
9#>/
$>0L&>
d*>1
'>0L&>/
Yu=B`e=
?F=Y
7=yX(=u
{r<M
7x=J{
/>:#
O/<N
=yX(=
A=;pN=
h=k+v=n
=k+v=
[=;pN=
5=yX(=
ew<b
7:RI
j<<>
ew<M
ew<>
j<<b
ew=I
{r<b
DX;'
3"<4
=R' =U
(=W[1=Z
B=_)K=a
S=d]\=
d=d]\=a
S=_)K=\
9=W[1=U
(=R' =P
7;B`e;
?$=V
b=B>h=D
s=Gry=
\~=n
\~=Gry=F
m=B>h=e
?$=v
;B`e;4
{r<&
=R' =T
b=B`e=B>h=h
4o= Aq=
{r=F
{r= Aq=
(m=h
j=B>h=B`e=e
WJ=9
E6=|
%=R' =Qk
k:RI
>;B`e;'
#<X94<
z<KY
$=yX(=V
7=5^:=[
2D=]mE=
?F=]mE=
2D=\
<=5^:=
-2=2
+=yX(=
D<X94<
;B`e;
>;RI
DX;$
d*<4
?F<4
DX;4
Q:RI
Q9RI
k:RI
Q9RI
k;KY
Q:RI
Q9RI
7;_)K;
y;KY
3"<U
-<X94<
b<B`e<
4o<E
{r<!
ew<l
{r<E
h<B`e<e
#9<X94<
3"<RI
^;_)K;4
7:RI
Q9RI
d*;4
7;_)K;
DX;B`e;
{r;o
{r;B`e;
DX;_)K;4
d*;RI
7:RI
Q9RI
d*;4
>;_)K;
DX;B`e;
{r;l
k;B`e;
Q;_)K;
#;RI
7:RI
Q9RI
7:RI
Q9RI
_@q=J?\
~|zxvuusqpnmkjiggfecba`_^]]\[ZYXWVUTTSRQQPONNMMLKKJIIHGGGFFEDDCCBBBAA@@??>>===<<;;:::999888776666555444333322211110000////.....----,,,,+++++*****)))))((((('''''''&&&&&&%%%%%%$$$$$$$########""""""!!!!!!!!!        X|E
+>>%I
%@ %@
timeRange
confidence
B8@?0
variation = %6.2f
creationDate
uuid
mediaanalysisd
private/com.apple.mediaanalysisd/caches/vision
verifiedType = %@ OR verifiedType = %@
B24@?0@"PHPerson"8@"NSDictionary"16
asset in (%@)
any person.personUUID in %@
total-allowed
ANY detectedFaces.uuid IN %@
PVPersonClusterManager
Unable to find class %s
v8@?0
com.apple.mediaanalysis.reachability
Not c
None
TransientConnection
Reachable
ConnectionRequired
ConnectionOnTraffic
InterventionRequired
ConnectionOnDemand
IsLocalAddress
IsDirect
IsWWAN
qualityScore
distanceToPreviousScene
flickerScore
sceneprintDistanceToPreviousScene
SceneResults
QualityResults
CameraMotionResults
SubjectMotionResults
FineSubjectMotionResults
SubtleMotionResults
TrackSegments
OrientationResults
IrisRecommendResults
IrisSharpnessResults
PreEncodeResults
MovingObjectsResults
FeatureVectorResults
SceneprintResults
ObstructionResults
InterestingnessResults
flags
quality
attributes
start
duration
distance
sceneprintDistance
featureVector
Data
orientation
objectBounds
slowMoFlicker
sceneprint
index
junk
summaryTimerange
duplicate
MetaFocusResults
MetaMotionResults
MetaMotionProcessedResults
q24@?0@"PHAssetResource"8@"PHAssetResource"16
B16@?0@"PHAssetResource"8
mammal
bird
people
adult
animal
stuffed_animals
fire
fireplace
embers
flame
beach
liquid
ocean
lake
creek
river
snow
jacuzzi
pool
grass
plant
coral_reef
foliage
tree
grill
waterways
shore
waterfall
thunderstorm
manhole
aurora
light
spotlight
smoking_item
flag
flagpole
underwater
candle
kettle
teapot
storm
tornado
lightning
blossom
surfing
pyrotechnics
blizzard
fountain
billboards
curtain
lamp
drinking_glass
fondue
blender
storefront
garden
shrub
firecracker
bubble_soap
watersport
haze
volcano
aquarium
fishtank
flower
seaweed
jellyfish
fish
flashlight
bonfire
smoking
lakeshore
sparkler
sparkling_wine
shower
geyser
actionScore
v32@?0@"NSNumber"8@"VCPFace"16^B24
v32@?0@"NSNumber"8@"VCPVideoObjectTracker"16^B24
q24@?0@"VCPFace"8@"VCPFace"16
/tmp/
v32@?0@"NSNumber"8@"VNFaceprint"16^B24
v32@?0@"NSNumber"8@"NSNumber"16^B24
Home face identification task cancelled
No face present in face crop
Photos identity model not present
%@ | %@
{{%.*g, %.*g}, {%.*g, %.*g}}
timestamp
qualityScoreForLivePhoto
visualPleasingScore
overallFaceQualityScore
exposureScore
penaltyScore
textureScore
sharpness
faceResults
globalQualityScore
contentScore
expressionChangeScore
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
v24@?0Q8^B16
v32@?0@"NSNumber"8Q16^B24
VCPClusteringStatusIsClustering
VCPClusteringStatusClusterRebuildRequired
VCPClusteringStatusEligibleFacesCount
VCPClusteringStatusPendingFacesCount
VCPSuggestionUpdateStarted
VCPSuggestionUpdateFinished
VCPSuggestionUpdateCancelled
com.apple.mediaanalysisd.clusterer.processing
com.apple.mediaanalysis.scheduleclustering
VCPFaceProcessingClusterFacesCoreAnalyticsCollection
v24@?0@"NSString"8^B16
com.apple.mediaanalysisd.photos.faceclustering
ClusteringSequence
FacesAddToClustering
FacesRemoveFromClustering
FacesInClusterBeforeClustering
ClusteringInterval
TotalAssetCount
ProcessingQoS
com.apple.mediaanalysisd.optional_clustering
com.apple.mediaanalysisd.forced_clustering
Operation cancelled
v32@?0@"NSNumber"8@"NSOrderedSet"16^B24
VCPVisionFgMapping_Prepare
v32@?0@"NSCountedSet"8Q16^B24
q24@?0@"NSCountedSet"8@"NSCountedSet"16
v24@?0@"NSNumber"8^B16
VCPClusterCompareTimestamp
VCPClusterer: Failed to get face CSNs from cluster cache, which should not be used
PVErrorInvalidClusterCacheFile - %@
VCPClusterer: Failed to get Vision cluster state - %@
VisionClusterState
clusteringType
threshold
VCPClusterer: Failed to archive cluster snapshot
VCPClusterer: Failed to rename file from '%@' to '%@'. Error = %d
VCPClusterer: Failed to write cluster snapshot to file '%@'
missing parameter clusterState
VCPClusterer: Cluster snapshot file '%s' is too small
VCPClusterer: Invalid magic number found in '%s'
VCPClusterer: Invalid version in '%s', %d != %d
VCPClusterer: Failed to read MD5 from header of '%s'
VCPClusterer: Failed to compute MD5 of '%s'
VCPClusterer: Failed MD5 check for '%s'
VCPClusterer: Failed to read size of vision cluster state blob from '%s'
VCPClusterer: Failed to read vision cluster state blob from '%s'
VCPClusterer: Failed to open cluster cache file '%s'
cmap
CVMLClusterState
CVMLClusteringAlgorithm_Greedy
VCPClusterer: Failed to restore cluster cache
VCPClusterer: Failed to restore cluster cache std::exception %s
VCPClusterer: Failed to restore cluster cache due to device ran out of memory
VCPClusterer needs a full sync
missing updateHandler
VCPClusterer is not ready
VCPClusterer: Failed to get suggestions from Vision framework %@
v32@?0@"VNCluster"8Q16^B24
v32@?0@"NSSet"8Q16^B24
q24@?0@"NSMutableSet"8@"NSMutableSet"16
VCPClustererBringUpState
clustererState.plist
need full sync
need to compare clusters
need to reset cluster cache
need to reset library clusters
need update
ready
clustering
have unsaved cluster cache
saving cluster cache
have new cluster cache
unknown (error)
AlgoFaceClusterCache.data
temp
Error: failed to processImage
highlightScore
@"VCPMADVIRemoveBackgroundResource"8@?0
VCPMADVIRemoveBackgroundTask
Image loading failed
Failed to obtain image from Vision
Multiple cadence options specified
%@ value must be NSNumber
%@ value must be poisitive
%@ is not supported
v32@?0@"NSString"8@16^B24
v24@?0@"NSDictionary"8@"NSError"16
Full analysis asset processing task cancelled
[%@] Failed to analyze on-demand
VCPFullAnalysisAssetProcessingTask processing failed
AllowOnDemand
InProcess
SceneprintRevision
com.apple.mediaanalysis.service.management
com.apple.mediaanalysis.service.handler
MediaAnalysisService
Error issuing sandbox extension
v16@?0d8
[MediaAnalysis] Error connecting to background analysis service
v16@?0@"NSError"8
Assets from multiple libraries not supported
v24@?0@"NSString"8@"NSError"16
PersonProcessingDeletePersons
PersonProcessingClusterFaces
PersonProcessingIncrementalFaceClustering
PersonProcessingRunBuildPersons
PersonProcessingIncrementalPersonBuilding
PersonProcessingRunPromotePersons
PersonProcessingRebuildFaceIDModel
PersonProcessingClassifyContactPictures
faceCSN
faceIdentifier
personIdentifier
personFaceCount
confirmed
status
requestAdvancedStatus
advancedStatus
PLPhotoAnalysisVisionServiceFaceReclusteringThreshold
PLPhotoAnalysisVisionServiceFaceReclusteringDeletePersons
PLPhotoAnalysisVisionServiceFaceReclusteringShouldRecluster
personLocalIdentifier
v24@?0@"NSArray"8@"NSError"16
v20@?0B8@"NSError"12
model_info.json
net_file
revision
config
loadModel
res_256x160
res_160x256
cnn_human_pose_lite_v2.espresso.net
input
before filter: frame(%d): time_stamp=%f, ave_motion=(%f,%f)
frame(%d): time_stamp=%f, ave_motion=(%f,%f), acc_var=(%f, %f), motion_chg=(%f, %f)
q24@?0@8@16
VCPMADImageSafetyClassificationResource
@"VCPMADImageSafetyClassificationResource"8@?0
[ImageSafety] Before decode
Image pre-processing failed
[ImageSafety] Before inference
CVNLPCommSafetyHandler unavailable
[ImageSafety] After inference
[VCPPhotosFace] Missing faceObservation and humanObservation
@"VNRequest"16@?0#8
@"VNObservation"24@?0@"NSUUID"8@"VNRequest"16
[VCPPhotosFace] Invalid faceprint and torsoprint
[VCPPhotosFace] Unable to serialize faceTorsoprint - %@
[VCPPhotosFace] Unable to determine normalized face bounding { { %f, %f } { %f, %f } }
%@ (%@), %@ (v%d) (%.2f, %.2f, %.2f) (%.2f, %.2f, %.2f, %.2f) quality: %.2f
Human
bounds
cnn_facepose.espresso.net
VCPPoseEspresso
@"VCPCNNModelEspresso"8@?0
quality_head.espresso.net
output
ImageAnalysis
MovieAnalysis
MAComputeRequestClass
q24@?0@"VNClassificationObservation"8@"VNClassificationObservation"16
q24@?0@"VCPClassification"8@"VCPClassification"16
featureBlob
checksum
data
SceneprintHyperplaneLSH, 
NeuralHyperplaneLSH, 
Unknown
com.apple.mediaanalysisd.timer
rawTime
homography
keypoints
v32@?0@"PHFace"8Q16^B24
VNFaceGazeDirectionUnknown
VNFaceGazeDirectionCamera
VNFaceGazeDirectionAnotherFace
VNFaceGazeDirectionCommonLocation
VNFaceGazeDirectionSomewhereElse
VNFaceGazeDirectionDifficultToSay
Error VNFaceGazeDirection: %lu
PHFaceGazeTypeCannotInferGaze
PHFaceGazeTypeLookingAtCamera
PHFaceGazeTypeLookingAtAnotherFace
PHFaceGazeTypeLookingAtCommonLocation
PHFaceGazeTypeOther
Error PHFaceGazeType: %d
sceneprintBlob
absoluteScore
relativeScore
humanScore
faceId
Action
NumOfValidFrames
ActionScore
seg %d: [%d, %d], sceneCut=%d
prev(%d) [%d, %d][%6.1f, %6.1f] qs = %6.2f, curr(%d) [%d, %d] [%6.1f, %6.1f]qs = %6.2f:
dist({%d %d}, {%d %d}) = %6.2f, th = %6.2f
prev: type = %d, fast = %d, gmv_sum {%6.1f, %6.1f}, merge = %d, split = 0
curr: type = %d, fast = %d, gmv_sum {%6.1f, %6.1f}, merge = %d, split = 0
segments
cnn_content.dat
v16@?0^{opaqueCMSampleBuffer=}8
MediaAnalysis
SceneNetV5
eyeExpression
mouthExpression
position
isCloseup
faceQuality
VCPMADVIResource
curationScore
com.apple.MediaAnalysis
com.apple.mediaanalysisd
forceCPU
forceNNGraph
sharedContext
shared 
VCPWallpaperAnalyzer.sharedModelPool
@"VCPObjectPool"8@?0
quantized_9hy8wvx5wz_iteration_47_model.espresso.net
quantized_5c7q2hh2zk_iteration_35_model.espresso.net
height
width
com.apple.mediaanalysis.VCPClientDatabaseManager
/tmp/com.apple.mediaanalysisd/VideoCaptionEncoderTest/
/tmp/com.apple.mediaanalysisd/VideoCaptionDecoderTest/
/tmp/com.apple.mediaanalysisd/ImageCaptionModelTest/
com.apple.MobileAsset.VCPMobileAssets
v16@?0q8
Model
AssetName
Version
VideoCaptionEncoder
v16@?0@"MAProgressNotification"8
v24@?0q8@"NSError"16
ClonedVideoCaptionDecoder
ClonedVideoCaptionEncoder
com.apple.mediaanalysis.VCPVideoTrackSyncDecoder
classification
[VCPVNImageprintWrapper] Invalid imageprint type %lu
Cannot calculate distance - missing the other imageprint
Cannot calculate distance - mismatched imageprint type (%lu vs %lu)
Cannot calculate distance - mismatched versions (%d vs %d)
Cannot calculate distance - unarchive self.data - %@
Cannot calculate distance - unarchive theOtherImageprint.data - %@
torso-only
face-only
Cannot get distance between faceprints. Distance function returns nil
type: %lu, version: %d, and data[length:%lu]: <%p>
v32@?0@"NSNumber"8@"NSArray"16^B24
com.apple.mediaanalysis.VCPSharedInstanceManager
VCPAnalysisProgressQueryScanPhotoLibraryFetch
faceAdjustmentVersion != nil
mediaAnalysisAttributes.characterRecognitionAttributes.algorithmVersion >= %d
mediaAnalysisAttributes.visualSearchAttributes.algorithmVersion >= %d
additionalAttributes.sceneAnalysisVersion >= %d &&  additionalAttributes.sceneAnalysisVersion != %d
VCPAnalysisProgressQueryExpressPathFetchTotalCount
VCPAnalysisProgressQueryExpressPathFetchProcessedCount
VCPAnalysisProgressQueryProgressDetail
VCPAnalysisProgressQueryProgress
VCPAnalysisProgressQueryCachedFaceAnalysisProgress
SalientRegions
bound
plistRepresentation
q24@?0@"VCPSaliencyRegion"8@"VCPSaliencyRegion"16
hand_keypoint_detector_acc.espresso.net
cnn_moflow.espresso.net
landscape_1024x448
square_320x320
input_image_1
input_image_2
zeros
landscape_384x256
landscape_448x320
landscape_640x512
landscape_896x640
portrait_256x384
portrait_320x448
portrait_512x640
portrait_640x896
square_256x256
square_512x512
square_640x640
VCPMoflowEspresso
com.apple.mediaanalysis.VCPVideoProcessorSession
Video processing requests must have completion handler
Specified request already active; cannot add
Failed to create request with specified configuration
Specified request not found; cannot remove
Sample buffer does not contain video frame
Sample buffer must contain uncompressed video
faceSharpness
vnpersonsmodel.bin
vnpetsmodel.bin
Point0
Point1
Radius
Theta
Length
Hand_waving
Hand_clapping
Dancing
Walking
Running
Jumping
cnn_human_action.espresso.net
salientRegion
salientScore
q24@?0@"NSDictionary"8@"NSDictionary"16
/var/mobile/Media/MediaAnalysis
private/com.apple.mediaanalysisd/MediaAnalysis
mediaanalysis.db
kindSubtype != %d
kind == %d
PhotoAnalysisServicePreferences.plist
faceWorkerState.plist
(faceAlgorithmVersion = %d) AND (clusterSequenceNumber = 0) AND (((hidden = 0) AND (manual = 0) AND ((trainingType = %d) OR (trainingType = nil))) OR ((trainingType = %d) OR (trainingType = %d) OR (trainingType = %d)))
SyndPL
Tracking
TrackingScore
AveStats
Failed to parse AVE statistics frame attachment; re-generating statistics
summaryIsTrimmed
livePhoto
movie
AutoplayScore
MotionScore
SubjectScore
ExposureChange
landscape_1024x432
privECMVct
privEMBVct
privDFArray
privET
privImgG
privTZF
privAFS
privAFSt
privFM
relSampleTime
trajectoryHomography
presentingTimestampInNanos
originalPresentingTimestampInNanos
sequenceAdjusterRecipe
sequenceAdjusterDisplacement
interpolatedFrame
LivePhotoMetadataSetupDataVersion
FrameworkVersions
CMCaptureCore
Error: failed to analyze motion flow
mediaAnalysisVersionState.plist
VCPFaceProcessingVersionManager-%@
@"VCPFaceProcessingVersionManager"8@?0
FaceProcessingInternalVersion
Reset none
Reset AnalysisStates
Reset Clustering
shotType
humanPoseResults
version
AutoLoop
Bounce
LongExposure
Stabilize
NormStabilizeInstructions
MinVersion
Params
loopFlavor
loopEnergy
outputFrameDur
stabCropRect
stabilizeResult
Width
Height
frameInstructions
face_model_tensor.dat
face_model_landmark_coordinates.dat
face_model_boundary.dat
com.apple.mediaanalysisd.VCPFaceShapeUpdate
Error detected at line 
Error detected in file 
Submodules/dlib/dlib/optimization/optimization.h
Error detected in function 
double dlib::find_min_box_constrained(search_strategy_type, stop_strategy_type, const funct &, const funct_der &, T &, const matrix_exp<EXP1> &, const matrix_exp<EXP2> &) [search_strategy_type = dlib::lbfgs_search_strategy, stop_strategy_type = dlib::objective_delta_stop_strategy, funct = std::function<double (dlib::matrix<double, 0, 0>)>, funct_der = std::function<dlib::matrix<double, 0, 0> (dlib::matrix<double, 0, 0>)>, T = dlib::matrix<double, 51, 1>, EXP1 = dlib::matrix_op<dlib::op_uniform_matrix_3<double>>, EXP2 = dlib::matrix_op<dlib::op_uniform_matrix_3<double>>]
Failing expression was 
is_col_vector(x) && is_col_vector(x_lower) && is_col_vector(x_upper) && x.size() == x_lower.size() && x.size() == x_upper.size()
double find_min_box_constrained()
 The inputs to this function must be equal length column vectors.
 is_col_vector(x):       
 is_col_vector(x_upper): 
 x.size():               
 x_lower.size():         
 x_upper.size():         
The objective function generated non-finite outputs
 ************************** FATAL ERROR DETECTED ************************** 
 ************************** FATAL ERROR DETECTED ************************** 
 ************************** FATAL ERROR DETECTED ************************** 
Two fatal errors have been detected, the first was inappropriately ignored. 
To prevent further fatal errors from being ignored this application will be 
terminated immediately and you should go fix this buggy program.
The error message from this fatal error was:
**************************** FATAL ERROR DETECTED ****************************
******************************************************************************
EPORT_IN_USE
ETIMEOUT
ECONNECTION
ELISTENER
ERESOLVE
EMONITOR
ECREATE_THREAD
ECREATE_MUTEX
ECREATE_SIGNALER
EUNSPECIFIED
EGENERAL_TYPE1
EGENERAL_TYPE2
EGENERAL_TYPE3
EINVALID_OPTION
ETOO_FEW_ARGS
ETOO_MANY_ARGS
ESOCKET
ETHREAD
EGUI
EFATAL
EBROKEN_ASSERT
EIMAGE_LOAD
EDIR_CREATE
EINCOMPATIBLE_OPTIONS
EMISSING_REQUIRED_OPTION
EINVALID_OPTION_ARG
EMULTIPLE_OCCURANCES
ECONFIG_READER
EIMAGE_SAVE
ECAST_TO_STRING
ESTRING_CAST
EUTF8_TO_UTF32
EOPTION_PARSE
undefined error type
iteration: 
   objective: 
Submodules/dlib/dlib/matrix/matrix.h
const dlib::matrix::literal_assign_helper &dlib::matrix<double, 2, 2>::literal_assign_helper::operator,(const T &) const [T = double, num_rows = 2, num_cols = 2, mem_manager = dlib::memory_manager_stateless_kernel_1<char>, layout = dlib::row_major_layout]
r < m->nr() && c < m->nc()
You have used the matrix comma based assignment incorrectly by attempting to
supply more values than there are elements in the matrix object being assigned to.
Did you forget to call set_size()?
 r: 
 c: 
 m->nr(): 
 m->nc(): 
dlib::matrix<double, 2, 2>::literal_assign_helper::~literal_assign_helper() [T = double, num_rows = 2, num_cols = 2, mem_manager = dlib::memory_manager_stateless_kernel_1<char>, layout = dlib::row_major_layout]
!has_been_used || r == m->nr()
You have used the matrix comma based assignment incorrectly by failing to
supply a full set of values for every element of a matrix object.
const dlib::matrix::literal_assign_helper &dlib::matrix<double, 2, 1>::literal_assign_helper::operator,(const T &) const [T = double, num_rows = 2, num_cols = 1, mem_manager = dlib::memory_manager_stateless_kernel_1<char>, layout = dlib::row_major_layout]
dlib::matrix<double, 2, 1>::literal_assign_helper::~literal_assign_helper() [T = double, num_rows = 2, num_cols = 1, mem_manager = dlib::memory_manager_stateless_kernel_1<char>, layout = dlib::row_major_layout]
You have to supply column vectors to this function
double dlib::find_min_using_approximate_derivatives(search_strategy_type, stop_strategy_type, const funct &, T &, double, double) [search_strategy_type = dlib::lbfgs_search_strategy, stop_strategy_type = dlib::objective_delta_stop_strategy, funct = std::function<double (dlib::matrix<double, 0, 0>)>, T = dlib::matrix<double, 6, 1>]
is_col_vector(x) && derivative_eps > 0
double find_min_using_approximate_derivatives()
x.nc():         
derivative_eps: 
cnn_landmark.espresso.net
VCPFaceLandmarkEspresso
mediaanalysis://asset.mov
VCPMADVITextLookupTask
@"VIImage"8@?0
Failed to create text lookup query context
v24@?0@"VITextLookupResult"8@"NSError"16
VIService_TextLookup
vanishingPoint
dominantLine
v32@?0@"NSString"8@"NSNumber"16^B24
<%@ %p, 
active cost: %d,
inactive cost: %d>
cnn_smile.espresso.net
VCPSmileEspresso
highlight_head.espresso.net
input1
input2
var_165
CVPixelbuffer not IOSurface backed
activityID: %@, 
startTime: %@, 
duration: %f(sec), 
exitStatus: %d>
idx (%tu) is out of range (%tu)
timeValue
homographyParam
timeScale
epoch
errorCode
loopFadeLen
loopPeriod
loopStart
sport
cnn_activitylevel.dat
HighlightMaxDuration
HighlightTargetDuration
HighlightStartRange
HighlightTolerance
HighlightIndex
HighlightBestTrim
HighlightFullResult
v32@?0@"VCPMovieHighlight"8Q16^B24
com.apple.homekitanalysis.session.management
com.apple.homekitanalysis.session.handler
[HomeKit] XPC connection invalidated. Please restart the session.
No result handler registered
No VCPHomeKitAnalysisSession; cannot process message
HMIVideoAnalyzer
com.apple.mediaanalysis.sql
SELECT id, version, dateModified, dateAnalyzed, analysisTypes, flags, quality, masterFingerprint, adjustedFingerprint
, statsFlags
 FROM Assets WHERE localIdentifier=(?);
SELECT resultsType, results FROM Results WHERE assetId=(?);
SELECT resultsType, results FROM Results WHERE assetId=(?
) AND resultsType IN (?
SELECT id, localIdentifier, version, dateModified, dateAnalyzed, analysisTypes, flags, quality, masterFingerprint, adjustedFingerprint
 FROM Assets WHERE localIdentifier IN (?
SELECT assetId, resultsType, results FROM Results WHERE assetId IN (?
SELECT date FROM Blacklist WHERE localIdentifier=(?) AND count>=(?);
i8@?0
SELECT localIdentifier FROM Blacklist WHERE count>=(?) AND localIdentifier IN (?
SELECT localIdentifier FROM Blacklist WHERE count>=(?);
SELECT localIdentifier FROM Assets WHERE dateAnalyzed>=(?) UNION SELECT localIdentifier FROM Blacklist WHERE count>=(?) AND date>=(?);
SELECT localIdentifier, status, attempts, date FROM ProcessingStatus WHERE taskID=(?) AND status!=(?) AND localIdentifier IN (?
SELECT localIdentifier FROM ProcessingStatus WHERE taskID=(?) AND status=(?);
SELECT COUNT(*) FROM ProcessingStatus WHERE taskID=(?) AND status=(?);
SELECT value FROM KeyValueStore WHERE key = (?);
SELECT activityID, startTime, duration, exitStatus FROM BackgroundActivitySchedulingHistory WHERE activityID=(?) AND startTime>=(?);
value
timescale
Orientation
Regions
Home resident maintenance task cancelled
HMITaskService
[VCPMADServiceImageProcessing] Specified identifier not found (%@)
[ImageProcessingTask%d] Identifier %@
Request was canceled
VCPVideoCNNBackboneEspresso
video_backbone.espresso.net
AveragePool_258_out
ReduceMean_264
Add_182_out
Pad_257_out
activityScore
ErrorCode
@"VNSession"8@?0
com.apple/PhotoVision/FaceCrop/
PVFC
PVFC:PVFC
PVFC_VER
PVFC_FB
PVFC_CB
PVFC_GID
tiff:Orientation
Could not set output orientation
Could not register face crop namespace
Could not generate serialized metadata representation
Could not convert metadata representation into serialized format
Could not set face crop metadata
Could not create image source
No meta data exists on image
unexpected nil image source
invalid image source
zero dimensioned face rect submitted
could not create cropped face crop image
could not create face crop metadata
public.jpeg
could not create face crop data
could not write face crop data
VCPFaceCropUtils : newFaceCropFromImageData - %@
image url is nil
Could not create image ref
Could not create face rect
VCPFaceCropUtils:newFaceCropFromImageURL - %@
image data is nil
Could not create image source from data
VCPFaceCropUtils:newFaceCropFromImageData - %@
invalid face crop supplied
VCPFaceCropUtils:faceBoundsFromFaceCrop -- %@
VCPFaceCropUtils:cropBoundsInOriginalImageFromFaceCrop -- %@
the supplied data is not a facecrop
could not create an image source
Could not retrieve image properties
VCPFaceCropUtils:faceCropDimensionsFromFaceCrop -- %@
could not create image ref
Could not create image for rendering
Could not create buffer for rendering
Could not create srgb colorspace
Could not create cropped and subsampled image
Could not create bitmap context
Face
@"VCPMADMachineReadableCodeResource"8@?0
VCPMADVIMachineReadableCodeDetectionTask
flow_estimation_%d
t_38
v16@?0^{?=ii*}8
interestScore
com.apple.mediaanalysisd.realtime
ContentType
faceMetadataArray
realtimeFaceRect
realtimeFaceRoll
realtimeFaceYaw
PriorityScore
v32@?0@8Q16^B24
%@ <%p>:
  person1LocalIdentifier  : %@
  person2LocalIdentifier  : %@
  reason                  : %@
asset.dateCreated
asset.addedDate
asset.filename
centerX
centerY
(verifiedType = %d) OR (verifiedType = %d)
(faceAlgorithmVersion = %d) AND (((hidden = 0) AND (manual = 0) AND ((trainingType = %d) OR (trainingType = nil))) OR ((trainingType = %d) OR (trainingType = %d) OR (trainingType = %d)))
(clusterSequenceNumber > 0)
(manual == 0) AND (faceAlgorithmVersion = %d)
Could not access the library
Canceled operation to get CSNs of faces missing from the library
v40@?0@"NSArray"8{_NSRange=QQ}16^B32
v32@?0@"NSString"8@"PHFetchResult"16^B24
(clusterSequenceNumber in %@)
Canceled operation to ungroup faces
v16@?0^B8
Canceled operation to uncluster faces
(clusterSequenceNumber = 0)
((clusterSequenceNumber > 0) AND (faceGroup = nil))
could not access the library
Canceled operation to cleanup grouped faces with CSN=0
No faceGroups found for person with localIdentifier '%@'
Failed to fetch faces from the faceGroup that contributed the most number of face to person with localIdentifier '%@'
(clusterSequenceNumber in %@) AND (trainingType = %d OR trainingType = %d OR trainingType = %d)
(clusterSequenceNumber in %@) AND (trainingType = %d OR trainingType = %d)
v32@?0@"PHPerson"8Q16^B24
v32@?0@"NSNumber"8@"NSSet"16^B24
photoLibrary is nil
trainingType != %d
VisionFgMapping_LookingAfterNewClusteredFace
VisionFgMapping_LookingForConflictingCluster
VisionFgMapping_ResolveConflictingCluster
v32@?0@"NSNumber"8@"NSDictionary"16^B24
VisionFgMapping_ResolveConflictL0Clusters
VisionFgMapping_Process
clusterSequenceNumber IN %@
@"PHFace"16@?0@"NSNumber"8
Saving clustering results cancelled
Canceled operation to reset library clusters
keyFace == nil
[UpdateKeyFaces] Failed to find persons %@
-[VCPPhotosPersistenceDelegate updateKeyFacesOfPersonsWithLocalIdentifiers:forceUpdate:cancelOrExtendTimeoutBlock:error:]
[UpdateKeyFaces] Operation canceled
Unimplemented %s in VCPPhotosPersistenceDelecate
-[VCPPhotosPersistenceDelegate invalidFaceClusterSequenceNumbersInClusterSequenceNumbers:canceler:error:]
-[VCPPhotosPersistenceDelegate ungroupFaceClusterSequenceNumbers:batchSizeForUnclusteringFaces:canceler:error:]
-[VCPPhotosPersistenceDelegate cleanupUngroupedFacesWithNonZeroClusterSequenceNumbersWithCanceler:error:]
-[VCPPhotosPersistenceDelegate cleanupGroupedFacesWithClusterSequenceNumberSetToZeroWithCanceler:error:]
-[VCPPhotosPersistenceDelegate persistChangesToAlgorithmicFaceGroups:faceCSNByLocalIdentifierForNewlyClusteredFaces:faceCSNsOfUnclusteredFaces:localIdentifiersOfUnclusteredFaces:persistenceCompletionBlock:canceler:error:]
-[VCPPhotosPersistenceDelegate resetLibraryClustersWithCanceler:error:]
-[VCPPhotosPersistenceDelegate updateKeyFacesOfPersonsWithLocalIdentifiers:forceUpdate:canceler:error:]
-[VCPPhotosPersistenceDelegate bestRepresentativeFaceForPerson:qualityMeasureByFace:canceler:]
-[VCPPhotosPersistenceDelegate bestRepresentativeFaceForPerson:qualityMeasureByFace:candidateFaces:canceler:]
-[VCPPhotosPersistenceDelegate associateFace:withFaceCrop:error:]
-[VCPPhotosPersistenceDelegate clearDirtyStateOnFaceCrops:error:]
-[VCPPhotosPersistenceDelegate dirtyFaceCropsWithLimit:]
-[VCPPhotosPersistenceDelegate faceAssociatedWithFaceCrop:]
-[VCPPhotosPersistenceDelegate facesFromAsset:]
-[VCPPhotosPersistenceDelegate persistFaces:deleteFaces:forAsset:persistedFaces:error:]
-[VCPPhotosPersistenceDelegate persistGeneratedFaceCrops:error:]
-[VCPPhotosPersistenceDelegate recordNeedToPersonBuildOnFaceGroupContainingFace:error:]
-[VCPPhotosPersistenceDelegate suggestedPersonLocalIdentifierForPersonLocalIdentifier:faceClusterer:canceler:context:error:]
-[VCPPhotosPersistenceDelegate updateFaceprint:ofPersistedFace:error:]
-[VCPPhotosPersistenceDelegate buildPersonsWithFaceClusterer:keyFaceUpdateBlock:canceler:context:extendTimeoutBlock:]
(personBuilderState = %ld)
Canceled cleaning up merge candidates of verified persons
v24@?0@"PHFetchResult"8@"NSMutableSet"16
v24@?0@"VCPMergeCandidatePair"8^B16
Canceled cleaning up merge candidates
(trainingType = %d) || (trainingType = %d)
v32@?0@"PHPerson"8@"NSString"16^B24
B24@?0@"VCPMergeCandidatePair"8@"NSDictionary"16
(clusterSequenceNumber IN %@)
Person building cancelled
clusterSequenceNumber = %ld
clusterSequenceNumber != %ld
[FaceCropAdjustment][%@-%d]
v32@?0@"NSString"8@"PHFaceCrop"16^B24
v32@?0@"PHFace"8@"PHPerson"16^B24
v24@?0@"NSDictionary"8q16
v32@?0@"NSString"8@"NSMutableArray"16^B24
q24@?0@"PHFaceCrop"8@"PHFaceCrop"16
v32@?0@"PHFaceCrop"8Q16^B24
MADProcessNewlyClusteredFaceCrops
invalid merge candidate pair created from cluster rejections
potential invalid merge candidate pair created from cluster rejections
invalid merge candidate pair from cluster rejection for verified person
potential invalid merge candidate pair from cluster rejection for verified person
B16@?0^@8
no training faces in level1 cluster - create 'unverified person : verified/migrated person' candidate pair
all training faces on single verified person in level1 cluster - create 'unverified person : training person' candidate pair
all training faces on single verified person in level1 cluster - create 'unverified person : verified person' candidate pair
all training faces on single verified person in level1 cluster - create 'training person : verified person' candidate pair
invalid merge candidate pair because we may have a dirty level0 cluster
multiple training persons in level0 cluster - create 'training person : training person' pair
clusterSequenceNumber
single training person in level0 cluster - create 'training person : verified person with confirmed face' pair
single training person in level0 cluster - create 'verified persons with confirmed face : verified persons with confirmed face' pair
invalid merge candidate pair because one person has face rejected for the other
invalid merge candidate pair because we have > 3 verified persons in the face group
single training person in level1 cluster - create 'training person : verified person with confirmed face' pair
single training person in level1 cluster - create 'verified persons with confirmed face : verified persons with confirmed face' pair
level1 cluster - create 'training person : training person' pair
level1 cluster - create 'unverifed person : training person' pair
invalid merge candidate pair: a cluster rejection
v32@?0@"NSMutableSet"8@"NSMapTable"16@"NSSet"24
invalid merge candidate pair:a face on verified person but cluster-rejected on another verified person
-[VCPPhotosPersistenceDelegate buildPersonWithFaceClusterer:keyFaceUpdateBlock:context:cancelOrExtendTimeoutBlock:]
VCPFaceProcessingBuildPersonsCoreAnalyticsCollection
com.apple.mediaanalysisd.photos.personbuilding
BuildingInterval
BuildingSequence
ClusterCount
ClusterFaceCount
FaceGroupCount
FaceGroupCountNeedToBuild
faceLocalIdentifier is nil
fetched %lu faces for %@
clusterSequenceNumber is nil
personLocalIdentifier is nil
fetched %lu persons for %@
Got a 'nil' photoLibrary. Cannot remove auto assigned faces
(manual = 0) AND ((nameSource = %d) OR (nameSource = %d) OR (nameSource = %d)) AND ((trainingType = %d) OR (trainingType = nil))
Operation to remove faces from verified persons has been canceled
Failed to removed faces from person with localIdentifiers '%@'
not known
PGGraphHelper
exposure
underExpose
q24@?0@"PHSceneClassification"8@"PHSceneClassification"16
@"VCPMADVIDocumentRecognitionResource"8@?0
VCPMADVIDocumentRecognitionTask
VCPMADPersonIdentificationTaskResource
@"VCPMADPersonIdentificationTaskResource"8@?0
VCPMADPersonIdentificationTask
[%@] Failed to configuate VNDetectFaceRectanglesRequest
[%@] Failed to configuate VNCreateFaceprintRequest
[%@] Failed to detect faces - %@
q24@?0@"VNFaceObservation"8@"VNFaceObservation"16
[%@] Failed to print faces - %@
{{x:%.*f, y:%.*f}, {width:%.*f, height:%.*f}} 
com.apple.mediaanalysis
com.apple.mediaanalysisd.analysis
com.apple.mediaanalysisd.photos
com.apple.mediaanalysisd.homekit
com.apple.mediaanalysisd.homekitsession
dateModified
dateAnalyzed
masterFingerprint
adjustedFingerprint
performedAnalysisTypes
statsFlags
metadataRanges
SyncPoint
FaceResults
ShotTypeResults
VoiceResults
MLQualityResults
JunkResults
BlurResults
ExposureResults
MLCameraMotionResults
DistanceResults
SaliencyResults
CompositionResults
ClassificationResults
MusicResults
UtteranceResults
ActivityLevelResults
FacePrintResults
PetsResults
PetsFaceResults
PetsKeypointsResults
PetsActionResults
MovieSummaryResults
SettlingEffectsGatingResults
MovieHighlightResults
MovieHighlightScoreResults
MLHighlightScoreResults
KeyFrameResults
KeyFrameBlurResults
KeyFrameStillResults
TrackingResults
LivePhotoEffectsResults
ParallaxResults
WallpaperExportResults
WallpaperPosterConfigDataResults
FaceQualityResults
SceneChangeResults
ApplauseResults
BabbleResults
CheeringResults
LaughterResults
AudioQualityResults
HumanPoseResults
HumanActionResults
HumanPoseInternalResults
HandsResults
LoudnessResults
KeyFrameResourceResults
VideoStabilizationResults
SongResults
HumanActionClassificationResults
InterpolationResults
WPResults
RotationAnalysisResults
ColorNormalizationResults
VideoCaptionResults
ImageCaptionResults
SettlingEffectResults
FaceQualityFlag
energyValues
peakValues
facePosition
faceBounds
facePoseYaw
facePrint
sharpnessFaces
saliencyBounds
saliencyConfidence
songSignature
wallpaperScore
probableRotation
probableRotationConfidence
colorNormalizationData
vanishingPointConfidence
neighbor
neighborDateModified
gyroStabilization
analysisConfidence
stabilizationRecipe
interpolationURL
settlingEffectURL
petsBounds
petsConfidence
petsKeypoints
petsAction
petsAbsoluteScore
petsRelativeScore
keyFrameTime
keyFrameScore
bestPlaybackCrop
maxHighlightStart
maxHighlightDuration
audioQuality
loopSuggestionState
longExposureSuggestionState
livePhotoEffectsRecipe
livePhotoEffectsGatingDescriptions
livePhotoEffectsMatchingScenes
aesthetic
sceneClassification
saliency
saliencyObjectness
duplicateMatchingFeature
duplicateMatchingAlternateFeature
overallScore
allScores
wellFramedSubjectScore
wellChosenBackgroundScore
tastefullyBlurredScore
sharplyFocusedSubjectScore
wellTimedShotScore
pleasantLightingScore
pleasantReflectionsScore
harmoniousColorScore
livelyColorScore
pleasantSymmetryScore
pleasantPatternScore
immersivenessScore
pleasantPerspectiveScore
pleasantPostProcessingScore
noiseScore
failureScore
pleasantCompositionScore
interestingSubjectScore
intrusiveObjectPresenceScore
pleasantCameraTiltScore
lowKeyLightingScore
acceptableCrop
preferredCrop
humanBounds
humanKeypoints
humanConfidence
humanID
humanActions
torsoPrint
handsBounds
handsKeypoints
handsKeypointsConfidents
handsID
videoCaptionText
videoCaptionConfidence
imageCaptionText
imageCaptionConfidence
frameQualityScore
faceQualityScore
sharpnessScore
texture
stillTime
flashFired
QualityOfService
DutyCycling
VCPTaskIDs
ForcePublish
GyroStabilization
PixelStabilization
MaxNumberOfAssetToProcess
ForceFullScan
Full Face, 
Face, 
Voice, 
Full Scene, 
Scene, 
Junk, 
Blur, 
Exposure, 
Distance, 
Feature, 
Saliency, 
Composition, 
Classification, 
ActivityLevel, 
CurationScore, 
Pets, 
PetsPose, 
MovieCuration, 
Effects, 
Parallax, 
Wallpaper Export, 
Face Quality, 
Audio Classification, 
Human pose, 
Loudness Measure, 
Hands, 
Video Stabilization Pixel, 
Video Stabilization Gyro, 
Gyro Analytics, 
ML Video Attributes, 
Song detection, 
Settling effect, 
Human action, 
Iris Recommendation, 
Video Caption, 
Audio Quality, 
v32@?0@"NSString"8@"NSArray"16^B24
mShortInputDecision
mPreGateStillMetadataDecision
mPreGateVideoTrimDecision
mPreGateVideoMLDecision
mPreGateFacesDecision
stabilizeGateDecision
postGateDecision
finalDecision
loopActivityDecision
bounceActivityDecision
longexpActivityDecision
ALGatingResultError
ALGatingResultUnset
ALGatingResultFail
ALGatingResultPass
SceneAnalysis
FaceAnalysis
EffectsAnalysis
Sceneprint
VideoStabilization
MultiWorkerAnalysis
QuickFaceIdentification
EmbeddingAnalysis
OCRAnalysis
MovieHighlightProcessing
VisualSearchAnalysis
FilesystemAnalysis
Unknown(%lu)
autobahn-nature
autobahn-city
autobahn-citynatureish
otgx_csfbtu_gfnbmf
otgx_csfbtu_nbmf
otgx_cvuupdlt
otgx_hfojubmt_gfnbmf
otgx_hfojubmt_nbmf
otgx_opof
otgx_voefsxfbs
otgx_boz
otgx_fyqmjdju
otgx_hfojubmt
meme_document_check_or_checkbook
meme_curation_meme
meme_curation_screenshot
meme_document_boarding_pass
meme_document_currency_or_bill
meme_document_driving_license
meme_document_office_badge
meme_document_passport
meme_document_receipt
meme_document_social_security_number
meme_hier_negative
meme_hier_document
meme_hier_curation
meme_negative
meme_document
meme_screenshot_etc
hier_text_document
hier_tragic_failure
tragic_failure
screenshot
bad_framing
bad_lighting
blurry
food_or_drink
junk_other
medical_reference
negative
receipt_or_document
repair_reference
shopping_reference
utility_reference
junk_negative
hier_negative
junk_non_memorable
hier_non_memorable
junk_poor_quality
hier_poor_quality
No Resource
Download Throttled
Soft Failure
Hard Failure
Duplicate Failure
Upload Failure
PhotoLibraries
ImageTooSmall
UsingBestResource
FacesToDelete
FacesToPersist
VisionClustersMinusLibraryClusters
LibraryClustersMinusVisionClusters
failed
processed
pet-vip-status
person-vip-status
prioritized-processed
prioritized-total-allowed
full-analysis-complete-processed
full-analysis-partial-processed
Confidence
BoundingBox
UserInteractive
UserInitiated
Default
Utility
Background
Unspecified
OptInStatus
FileURL
GroundTruthURL
PersonIdentifier
PersonInformation
UserLabeledGender
UserLabeledAge
UserLabeledEthnicity
ModifyPersonRequest
SubTasks
NumberOfAssetsAllowedForPhotosFaceProcessing
NumberOfAssetsAnalyzedForPhotosFaceProcessing
NumberOfPrioritizedAssetsAnalyzedForPhotosFaceProcessing
NumberOfPrioritizedAssetsAllowedForPhotosFaceProcessing
Success
Canceled
Status Error
Parameter Error
Unknown Error
resident: %@, virtual: %@, phys_footprint: %@, phys_footprint_peak: %@.
resident: N/A, virtual: N/A, phys_footprint: N/A, phys_footprint_peak: N/A.
supportedRevisions
supportedPrivateRevisions
MediaAnalysisVersion
LatestVersionTimeStamp
MediaAnalysisCompleteTimestamp
MediaAnalysisProgressPercentage
SceneAnalysisVersion
LatestSceneAnalysisVersionTimestamp
SceneAnalysisCompleteTimestamp
SceneAnalysisProgressPercentage
FaceAnalysisVersion
LatestFaceAnalysisVersionTimestamp
FaceAnalysisCompleteTimestamp
FaceAnalysisProgressPercentage
PrioritizedFaceAnalysisCompleteTimestamp
PrioritizedFaceAnalysisProgressPercentage
OCRAnalysisVersion
LatestOCRAnalysisVersionTimestamp
OCRAnalysisCompleteTimestamp
OCRAnalysisProgressPercentage
VisualSearchAnalysisVersion
LatestVisualSearchAnalysisVersionTimestamp
VisualSearchAnalysisCompleteTimestamp
VisualSearchAnalysisProgressPercentage
EmbeddingAnalysisVersion
LatestEmbeddingAnalysisVersionTimestamp
EmbeddingAnalysisCompleteTimestamp
EmbeddingAnalysisProgressPercentage
Bytes
%llu %@
Error: failed to processSampleBuffer
cnn_faceblur.dat
feature_extraction
t_19
t_57
t_76
t_95
t_114
types
date
typesWide
assetIdentifier
assetModificationDate
assetMasterFingerprint
assetAdjustedFingerprint
imageBlurResults
imageCompositionResults
imageFaceResults
imageFeatureResults
imageJunkResults
imageSaliencyResults
imageShotTypeResults
imagePetsResults
imagePetsFaceResults
imageSceneprintResults
livePhotoEffectsResults
livePhotoRecommendationResults
livePhotoSharpnessResults
livePhotoKeyFrameResults
livePhotoKeyFrameStillResults
movieActivityLevelResults
movieCameraMotionResults
movieClassificationResults
movieFaceResults
movieFaceprintResults
movieFeatureResults
movieFineSubjectMotionResults
movieInterestingnessResults
movieMovingObjectResults
movieMusicResults
movieObstructionResults
movieOrientationResults
moviePreEncodeResults
movieQualityResults
movieSaliencyResults
movieSceneResults
movieSceneprintResults
movieSubjectMotionResults
movieSubtleMotionResults
movieUtteranceResults
movieVoiceResults
movieSummaryResults
movieHighlightResults
imageExposureResults
imageHumanPoseResults
movieHumanPoseResults
movieApplauseResults
movieBabbleResults
movieCheeringResults
movieLaughterResults
movieHumanActionResults
movieLoudnessResults
moviePetsResults
moviePetsFaceResults
movieStabilizationResults
movieHighlightScoreResults
livePhotoHumanActionClassificationResults
movieAudioQualityResults
OCR/MRC
GlobalXSum
GlobalYSum
Type
cnn_lm.dat
Cannot generate facecrop without originating face
Failed to find originating PHFace %@
Failed to generate facecrop on manual originating face %@
Facecrop is nil
Missing image data from facecrop %@
Invalid facecrop image data %@
Invalid facecrop bounding box %@
Facecrop image size equals to 0
Failed to normalize bound %@ with image (%.0fx%.0f)
Failed to obtain the facecrop image dimensions
Failed to create VNImageRequestHandler
Failed to set VNDetectFaceRectanglesRequest
Failed to set VNCreateFaceprintRequest
Failed to analyze facecrop - %@
Failed to create faceprint - %@
Failed to wrap faceprint/faceTorsoprint
Face has already been persisted with a facecrop
Face does not have a faceprint
Failed to fetch facecrop
Failed to persist face and facecrop
[FaceCropManager] faceLocalIdentifier is nil
[FaceCropManager] Fetched %lu faces with face identifier %@, should be 1
[FaceCropManager] Failed to fetch face %@
yyyyMMdd
en_US_POSIX
FaceIDModelLastGenerationKey
PetIDModelLastGenerationKey
Person
com.apple.mediaanalysis.quickfaceid.management
VCPPersonVIPLoadModel
VCPPetVIPLoadModel
nameSource == %ld
verifiedType = %@
faceCount
nameSource != %ld
VCPPetVIPGenerateModel
isInVIPModel == YES
roll == 0.0
graph
user
VCPPersonVIPGenerateModel
VCPCNNBlurAnalyzerEspresso.sharedModelPool-%lu
cnn_blurV2.espresso.net
cnn_blur.espresso.net
VCPBlurEspresso
res_299x299
res_400x400
res_400x300
res_300x400
yyyy-MM-dd-HH-mm-ss
suggestionLog_
suggestions.html
function addPlaceHolders() {
addPlaceholdersForSet("visionInput", inputFaces);
addPlaceholdersForSet("visionOutput", outputFaces);
addPlaceholdersForSet("visionFiltered", filteredFaces);
function isElementHidden(element) {
var style = window.getComputedStyle(element);
return (style.display === 'none')
function updateVisibility() {
var allDivs = document.getElementsByTagName("div");
for (var i = 0; i < allDivs.length; i++) {
var d = allDivs[i];
if (!d.attributes["img"]) continue;
var rect = d.getBoundingClientRect();
if (
rect.top >= -100 &&
rect.left >= -100 &&
rect.bottom - 100 <= (window.innerHeight || document.documentElement.clientHeight) &&
rect.right - 100 <= (window.innerWidth || document.documentElement.clientWidth)
if (d.childNodes.length == 0) {
d.innerHTML = "<img src='" + d.attributes["img"].value + "' width='100' height='100'>";
else {
if (d.childNodes.length != 0) {
d.innerHTML = "";
function addPlaceholdersForSet(containerId, elements) {
var content = "";
for (var i = 0; i < elements.length; i++) {
content += "<div style='float: left; width: 100px; height: 100px; margin: 3px; background-color: darkgray' img='" + elements[i] + "'></div>"
document.getElementById(containerId).innerHTML = content;
document.onscroll = function (e) {
updateVisibility();
</script>
</head>
<body>
<p>Vision input:</p>
<div id="visionInput">
</div>
<p style="clear: both;">Vision output:</p>
<div id="visionOutput">
</div>
<p style="clear: both;">Vision filtered output:</p>
<div id="visionFiltered">
</div>
</div>
<script>
document.addEventListener("DOMContentLoaded", function (event) {
addPlaceHolders();
</script>
</body>
</html>
could not obtain access to the photo library
photo library could not provide suggestions
_suggestionsForPersonWithLocalIdentifier cancelled
v16@?0Q8
<html>
<head>
<script>
 var inputFaces = [
v32@?0@"NSString"8@"NSArray"16@"NSError"24
var outputFaces = [
var filteredFaces = [
suggestPersonsForPersonWithLocalIdentifier cancelled
Input parameter is empty or nil: '%@'
Failed to find persons with local identifiers: '%@'
VCPClusterer is nil
verifiedType != %d
VCPFaceProcessingDeleteAllVerifiedPersons
succeeded
VCPFaceProcessingReclusterFacesWithThreshold
VCPFaceProcessingBuildPersons
VCPBuildPersons failed %d
VCPFaceProcessingPromotePersons
VCPPromotePersons failed %d
Failed to rebuild persons (error: %d)
Failed to promote persons (error: %d)
B32@?0@"NSDictionary"8Q16^B24
PVPersonPromoter
Memories
iMovie
v48@?0^{CGImage=}8{?=qiIq}16@"NSError"40
IrisObjectsResults
MetaStabilizationResults
MetaStabilizationFrameResults
MetaHomographyDimensionResults
MetaHomographyResults
MetaPresentationTimeResults
MetaMotionBlurResults
MetaPTSInNanosResults
MetaOriginalPTSInNanosResults
MetaItemPTSResultsKey
MetaAdjusterResults
MetaAdjusterRecipeResults
MetaAdjusterDisplacementKey
MetaInterpolatedFrameKey
MetaLensSwitchResults
autoplay_head.espresso.net
var_99
NotImplementedException
[VideoTrackDecoder status] should not be called
[VideoTrackDecoder copyNextSampleBuffer] should not be called
[VideoTrackDecoder getNextCaptureSampleBuffer] should not be called
  state            : %d
  originating face : %@
action_repetition_counter
mlmodelc
VCPMADVIVisualSearchGatingTask
<redacted>
Failed to create visual search query context
VIService_VisualSearchGating
v32@?0@"VIParseResult"8@"NSData"16@"NSError"24
.espresso.net
callback queue
Create Context Error
Create Plan Error
%@ Load Error
Build Model Error
Select Configuration Error
Build Plan Error
Clean Plan Error
B24@?0@"NSString"8@"NSDictionary"16
VCPFaceAnalyzerFillMissingFaceprint
VCPFaceAnalyzerFaceQuality
aggregated
faceID
faceprintBlob
Live Photo
Pano Photo
Screenshot
HDR Photo
SDOF Photo
Photo
Slow-mo Movie
Timelapse Movie
Movie
VCPMADVIVisualSearchTask
v24@?0@"VISearchResult"8@"NSError"16
VIService_ParsedVisualSearch
VIService_VisualSearch
cnn_smile.dat
Failed to load asset
Asset contains no video tracks
Failed to create video track output
Failed to start decoding video track
Video processor cancelled
Failed to complete video decoding
recipeBlob
keyFrame
playbackCrop
colorNormalizationBlob
hasAction
Video stabilization task cancelled
Video stabilization processing failed
VideoCNN
Skeleton
enabled
formatDescriptions
naturalSize
nominalFrameRate
preferredTransform
tracks
res_384x384
q24@?0@"NSNumber"8@"NSNumber"16
res_%dx%d
obstructionScore
VCPMADServiceImageProcessingTask
%@ not currently implemented
q24@?0@"NSObject<VCPMADServiceImageProcessingSubtaskProtocol><VCPMADTaskProtocol>"8@"NSObject<VCPMADServiceImageProcessingSubtaskProtocol><VCPMADTaskProtocol>"16
[MediaAnalysis][%@]Unable to open movie, skip
[MediaAnalysis][%@]Failed to create asset
[%@] Analysis cancelled
[%@] Analysis failed to complete
outputFrameDurValue
cropRectX
cropRectY
cropRectHeight
cropRectWidth
autoloop
bounce
longexposure
stabilize
minVersion
cnn_blink.espresso.net
VCPGazeEspresso
PersonBuilderMergeCandidatesEnabled
PersonBuilderLastMinimumFaceGroupSizeForCreatingMergeCandidates
personBuilderState != %lu
VCPFaceProcessingCleanupMergeCandidates
v16@?0@"NSArray"8
VCPPersonBuilder_UpdateKeyface
statisticsBlob
@"VCPMADVIRectangleDetectionResource"8@?0
VCPMADVIRectangleDetectionTask
com.apple.mediaanalysis.SceneProcessingGroup
MonzaV4_1
@"CVNLPCommSafetyHandler"8@?0
%@%@
classID
size
score
v32@?0@"VNRecognizedObjectObservation"8Q16^B24
v24@?0@"PFSceneTaxonomyNode"8^B16
v32@?0@"NSDictionary"8Q16^B24
meme_
v32@?0@"NSString"8@"NSString"16^B24
cnn_human_pose_single.espresso.net
subjectMotionScore
motionDivScore
objectsMotion
globalMotion
interestingnessScore
trackingScore
sceneChangeScore
browDown_L
browDown_R
browInnerUp
browOuterUp_L
browOuterUp_R
cheekPuff
cheekSquint_L
cheekSquint_R
eyeBlink_L
eyeBlink_R
eyeLookDown_L
eyeLookDown_R
eyeLookIn_L
eyeLookIn_R
eyeLookOut_L
eyeLookOut_R
eyeLookUp_L
eyeLookUp_R
eyeSquint_L
eyeSquint_R
eyeWide_L
eyeWide_R
jawForward
jawLeft
jawOpen
jawRight
mouthClose
mouthDimple_L
mouthDimple_R
mouthFrown_L
mouthFrown_R
mouthFunnel
mouthLeft
mouthLowerDown_L
mouthLowerDown_R
mouthPress_L
mouthPress_R
mouthPucker
mouthRight
mouthRollLower
mouthRollUpper
mouthShrugLower
mouthShrugUpper
mouthSmile_L
mouthSmile_R
mouthStretch_L
mouthStretch_R
mouthUpperUp_L
mouthUpperUp_R
noseSneer_L
noseSneer_R
tongueOut
focalLengthInPixels
objects
faceRollAngles
faceAnchor
vertices
transform
blendshapes
geometry
dispatchQueue
regionsOfInterest
aggSubjectMotionScore
turboMode
frameWidth
frameHeight
VCPCaptureAnalysis
v28@?0f8f12Q16i24
cnn_pets.espresso.net
VCPPetsEspresso
res_0
res_1
res_2
gesture_recognition.espresso.net
cnn_human_pose.espresso.net
AllowOnDemandPixel
AllowOnDemandGyro
AllowStreaming
KeepPrivateResults
MaxHighlightDuration
Standalone
StoreAnalysis
ScaledSlomoTime
com.apple.mediaanalysis.ondemand
com.apple.mediaanalysis.storage
com.apple.mediaanalysis.VCPMediaAnalyzer.sandboxQueue
com.apple.mediaanalysis.VCPMediaAnalyzer.cancelQueue
v16@?0@"NSString"8
VCPMediaAnalyzer
Sceneprint task cancelled
[%@] Thumbnail is not locally available
[%@] Failed to load thumbnail image
[%@] Failed to set revision %lu - %@
[%@] Invalid sceneprint result
45.1
mediaType == %d
kind == %d && kindSubtype != %d
mediaType == %d && !((mediaSubtype & %d) == %d)
kindSubtype == %d
(mediaSubtype & %d) == %d
!((mediaSubtype & %d) == %d)
mediaAnalysisAttributes.mediaAnalysisVersion < %d
kindSubtype != %d && SUBQUERY(additionalAttributes.sceneClassifications, $s, $s.sceneIdentifier = %d AND $s.confidence > %f).@count > 0
kindSubtype != %d && SUBQUERY(additionalAttributes.sceneClassifications, $s, $s.sceneIdentifier = %d AND $s.confidence > %f).@count = 0
SUBQUERY(additionalAttributes.sceneClassifications, $s, $s.sceneIdentifier = %d AND $s.confidence >= %f).@count > 0
SUBQUERY(additionalAttributes.sceneClassifications, $s, $s.sceneIdentifier = %d AND $s.confidence >= %f).@count = 0
additionalAttributes.sceneAnalysisVersion != %d || adjustmentTimestamp != additionalAttributes.sceneAnalysisTimestamp
adjustmentTimestamp != faceAdjustmentVersion
mediaAnalysisAttributes.characterRecognitionAttributes = NULL || mediaAnalysisAttributes.characterRecognitionAttributes.algorithmVersion != %d || adjustmentTimestamp != mediaAnalysisAttributes.characterRecognitionAttributes.adjustmentVersion
mediaAnalysisAttributes.visualSearchAttributes = NULL || mediaAnalysisAttributes.visualSearchAttributes.algorithmVersion != %d || adjustmentTimestamp != mediaAnalysisAttributes.visualSearchAttributes.adjustmentVersion
VCPMADVisionResource
output1
output2
output3
cnn_hand_detector_v2.espresso.net
VCPMAMLModel-%@
@"VCPMAMLModel"8@?0
maxNumberHands
humanActionWindowSize
motionFlowComputationAccuracy
v32@?0@"NSString"8@"NSString"16@"NSError"24
identifier
mediaanalysis://in-memory
com.apple.mediaanalysisd.VCPInMemoryAVAsset
Frame: %u
textureness
hasFlash
supportedImageSizeSet
v24@?0^v8Q16
v16@?0@"NSData"8
Destructive Trim Range: [%.2f - %.2f]
after repare
after consecutive short merge
after sparse short merge
after post processing
=========Segment %s==========
v32@?0@"VCPSegment"8Q16^B24
 [%.2f - %.2f]: %.2f
--[%.2f - %.2f]
com.apple.mediaanalysis.VCPDefaultPhotoLibraryManager
precision
personID
validFaceCount
identitySize
recall
AutoCounterGroundTruth.plist
[AutoCounter] Cannot load ground truth file URL
no_name
AddedDate
unknown
unverified
verifiedType
personName
faceRect
faceGroupID
faceprint
momentIdentifier
[AutoCounter] Failed to fetch person (%@)
FacesPerAsset
OptInDate
OptInDateSinceReferenceDate
OptInMADFaceVersion
OptInDetectionModelVersion
OptInRecognitionModelVersion
FaceCount
AssetCount
AdditionalInformation
AutoCounterClusters_Ver%d_DetectionVer%lu_RecognitionVer%lu.plist
[AutoCounter] Failed to retrive export URL
mergecandidates
faces
assetInformation
[AutoCounter] Failed to process FaceGroups
v32@?0@"NSString"8@"NSDictionary"16^B24
AutoCounterClusterAssetsToFaces_Ver%d_DetectionVer%lu_RecognitionVer%lu.plist
phFaceID
gtFaceID
gtPersonID
v32@?0@"NSString"8@"NSSet"16^B24
com.apple.photos.autocounter
date_optin
detection_version_current
detection_version_optin
mad_version_current
mad_version_optin
person_id
promoter_clusters
promoter_clusters_duplicates
promoter_precision
promoter_recall
promoter_version_current
promoter_version_optin
recognition_version_current
recognition_version_optin
total_assets
total_assets_optin
total_faces
total_faces_optin
type
userLabeledAge
userLabeledEthnicity
userLabeledGender
vision_clusters
vision_clusters_duplicates
vision_precision
vision_recall
nightly
nightly-Ver%d_DetectionVer%lu_RecognitionVer%lu_PersonVer%lu
AutoCounterCoreAnalytics
%@_Ver%d_DetectionVer%lu_RecognitionVer%lu.plist
self.lastPathComponent BEGINSWITH %@
v32@?0@"NSURL"8Q16^B24
visionCluster
weightedAveragePrecision
weightedAverageRecall
numSingletons
numValidSingletons
precisionPerCluster
recallPerPersonToGroundTruth
recallPerPersonExcludeMissDetection
personCluster
identity
PVPersonPromoterVersion
Apple
cnn_saliency.dat
VCPMADVIUserFeedbackTask
VIService_UserFeedback
@"VCPMADVIVisualSearchResource"8@?0
mdta/com.apple.quicktime.live-photo-info
propertyKey %s 
result is nil %s
sum = %6.2f, tracking_score = %6.2f
Target Captured @ [%5.0f, %5.0f, %5.0f, %5.0f]
initial @ [%d %d] s = %6.5f
stop    @ [%d %d] s = %6.5f
lost = %d
[%6.2f, %6.2f, %6.2f, %6.2f]
box0: (x = %2.1f, y = %2.1f, w = %2.1f, h = %2.1f)
box1: (x = %2.1f, y = %2.1f, w = %2.1f, h = %2.1f)
box : (x = %2.1f, y = %2.1f, w = %2.1f, h = %2.1f)
overlap_area = %6.2f, max_area = %6.2f, weight = %6.2f
derr = %6.2f, terr = %6.2f
add new expert with weight %6.2f
expert %d was replaced: voting weight(%6.2f --> %6.2f)!
after voting --> update target
detector and tracker did not match well --> experts vote
detector and tracker matched well --> update experts
VCPImageHumanActionEspresso
cnn_image_human_action.espresso.net
compatible
IODeviceTree:/arm-io
res_192x192
hand_keypoint_detector.espresso.net
regressiontree_landmark.dat
rtree_landmark_tracking.dat
com.apple.mediaanalysisd.VCPVideoFaceValidation
face_validation_warp_tri_list.dat
face_validation_warp
face_validation_warp_params.dat
%@_%d.dat
com.apple.mediaanalysis.VCPImageManager.transcodeQueue
VCPImageManager
@"VCPImageManager"8@?0
MADImageManagerEncode_%.3f_unpadded.jpg
MADImageManagerEncode_%.3f_padded.jpg
/Library/Audio/Tunings/Generic/AU/aufx-epv2-mediaanalysis-appl.plist
cnn_pose.dat
motionType
isFast
sourceSize
inputBounds
VCPVideoCNNActionClassifierEspresso
VCPVideoCNNActionClassifierEspressoStage1
action_recognition_head.espresso.net
action_taxonomy.plist
boxes
action_recognition_head_stage1.espresso.net
q24@?0@"PHFace"8@"PHFace"16
cnn_saliency.espresso.net
VCPSaliencyFullEspresso
energy
peak
%@ canceled
%@ is not yet implemented
frame idx = %d
size = %d, track_target_exist = %d, target_lost = %d, tracking_score = %6.2f
com.apple.homekitanalysis.service.management
com.apple.homekitanalysis.service.handler
Failed to fetch person by local identifier (%@)
HMIAnalysisService
Failed to create VNAlignFaceRectangleRequest
Failed to exercise Vision request - %@
UserOrig
UserAlgo
NoUserAlgo
NoAlgo
cnn_person_detector.espresso.net
PetsRegions
PetsFaceRegions
{CGRect={CGPoint=dd}{CGSize=dd}}
res_256x256
VCPHumanPoseEspresso
res_320x192
res_192x320
clusterer is not available
Face clustering threshold should be in the range: [0.1, 1.0]
VCPFaceProcessingResetFaceClusteringState
VCPFaceProcessingPerformFaceClusteringAndWait
backwarpNonInterleaved
LogLevel
yyyy-MM-dd HH:mm:ss
autoPlayable
Angle
cnn_blur.dat
iChatUsageString
EnableStatsCollect
EnableUserQPForFacetime
EnableUserRefForFacetime
EnableWeightedPrediction
UserFrameType
ReferenceFrameNumDriver
ReferenceL0
UserQpMap
MBStatistics
NotSync
ClonedImageCaptionModel
en-US
Failed to load imageURL: %@
NeuralHash+LSH invalid imageSignatureHash
Invalid NeuralHash+LSH (=)
v20@?0f8^B12
VCPFaceProcessingPromotePersonsCoreAnalyticsCollection
com.apple.mediaanalysisd.photos.personpromoting
GraphVerifiedPersonCount
PromotingInterval
PromotingSequence
TotalFaceCount
UnverifiedPersonCount
UserVerifiedPersonCount
com.apple.Photos
Received action score %f - %f
=========%s==========
[%.2f - %.2f]: %.2f
capturePointSegmentIdx: %d
----[%.2f - %.2f]
startIdx = %d, endIdx = %d, count = %d, [%f, %f] with score %f captureTime=%f
interesting trim: [%f, %f], score = %.2f
 --[%.2f - %.2f]
===========SceneChangeSegments=============
[%f, %f]
Measurement
Min (s)
Max (s)
Avg (s)
Total
Count
Minimum
Maximum
Average
signpost
com.apple.mediaanalysisd.livephotoeffectanalysisresults
com.apple.mediaanalysisd.moviecurationresults
com.apple.mediaanalysisd.livephotokeyframeresults
com.apple.mediaanalysisd.das.dutycycle
com.apple.mediaanalysisd.das.dutycycle.task
com.apple.mediaanalysisd.analysis.pets
com.apple.mediaanalysisd.livePhotoFillingGaps
LivePhotoEffectsShortInputDecision
LivePhotoEffectsPreGateStillMetadataDecision
LivePhotoEffectsPreGateVideoTrimDecision
LivePhotoEffectsPreGateVideoMLDecision
LivePhotoEffectsPreGateFacesDecision
LivePhotoEffectsStabilizeGateDecision
LivePhotoEffectsPostGateDecision
LivePhotoEffectsFinalGateDecision
LivePhotoEffectsLoopActivityDecision
LivePhotoEffectsBounceActivityDecision
LivePhotoEffectsLongexpActivityDecision
LivePhotoEffectsStabilizeResult
MediaType
AutoPlayableScore
SummaryDuration
IsTrimmed
KeyFrameIsSuggested
KeyFrameScoreDifference
KeyFrameTimestampOffset
KeyFrameIsFaceQualityDominant
KeyFrameIsSharpnessDominant
KeyFrameIsSemanticDominant
KeyFrameIsSuggestedEdit
KeyFrameScoreDifferenceEdit
KeyFrameTimestampOffsetEdit
KeyFrameIsFaceQualityDominantEdit
KeyFrameIsSharpnessDominantEdit
KeyFrameIsSemanticDominantEdit
previousQoS
previousQoSDuration
requestedQoS
taskName
taskStatus
DownloadAssetCount
DownloadBytes
Duration
Delay
AvgSpeed
AssetType
NumberOfPetFacesDetected
NumberOfPetsDetected
ResourceType
SceneType
AggregatedBoundingBoxSizeRatio
LargestBoundingBoxSizeRatio
com.apple.mediaanalysis.coreanalytics
VCPMADCoreAnalyticsManager
@"VCPMADCoreAnalyticsManager"8@?0
SHMutableSignature
correlationNonInterleaved
[VCPAsset %@] should not be called
mediaType
mediaSubtypes
pixelWidth
pixelHeight
exif
imageWithPreferredDimension:
imageWithPreferredDimension:orientation
movie:
isMovieResourceLocalAvailable:
originalMovie:
Start
FramesPerSecond
v16@?0@"NSURL"8
VCPDownloadResource
inputBoundsX
inputBoundsY
inputBoundsHeight
inputBoundsWidth
sourceSizeHeight
sourceSizeWidth
homographyParams
cnn_pet_pose.espresso.net
cameramotiontype_head.espresso.net
cameramotionscore_head.espresso.net
VCPMADResourceManager
@"VCPMADResourceManager"8@?0
q24@?0@"VCPMADResourceEntry"8@"VCPMADResourceEntry"16
com.apple.mediaanalysisd.VCPMADResourceManager
DeviceClass
iPad
pLzf7OiX5nWAPUMj7BfI4Q
marketing-name
inputImage
angle
v24@?0@"MLModel"8@"NSError"16
Getting no object IDs when fetching assets on moment %@
Reachability initialization failed; assuming no connection
Reachability flags invalid; assuming no connection
%sonnected to internet via WiFi/Ethernet
Network reachability flag changed to: %@
Human action - no PHFaces found
Failed to lock CVPixelBuffer (%p, %d)
Cannot lock NULL CVPixelBuffer
Lock attempt failed; cannot unlock buffer
Multiple unlock attempts; cannot unlock buffer
Failed to unlock CVPixelBuffer (%p, %d)
Failed to allocate memory
[VCPVideoFullFaceDetector] Detected face %@
[VCPVideoFullFaceDetector] Failed to detect faces - %@
Failed to retrieve faceprint revision from key faces
Failed to create Vision clusterer - %@
Failed to cluster faces - %@
Creating faceprint for face crop
Multiple faces present in face crop; using first
Loading quick identification model
Performing quick identification
Quick identification match found: %@
No quick identification match found
Home face identification task failed (%@)
inferenceHandKeypointCallFromSPI
Failed to allocate textureness or dst buffer for image resolution %dx%d
[MediaAnalysis] Image descriptor - found more than 1 VNImageprintObservations
VNImageprint init error: %@
VCPClusterer: Terminating ...
VCPClusterer: Terminated
VCPClusterer: Cluster triggering set to %lu
VCPClusterer: Scheduling to remove %lu faces and add %lu faces
VCPClusterer: total remove %lu faces and add %lu faces
VCPFaceProcessingClusterFacesCoreAnalyticsCollection
VCPClusterer: Removing %lu faces from cluster cache
VCPClusterer: Failed to cluster(removing) faces - %@
VCPClusterer: Removed %lu faces from cluster cache [time: %f secs]
VCPClusterer: Adding %lu faces to cluster cache
VCPClusterer: Number of orderedFaceIdentifiers (%lu) != number of _faceIdStrsToAdd (%lu)
VCPClusterer: missing localIdentifiers : %@
VCPClusterer: %lu faces to cluster, already took %f seconds
VCPClusterer: %lu faces in current batch, %lu faces remain
VCPClusteringGetFaceObservations
VCPClusterer: Number of faceTorsoprintsToAdd (%lu) !=  number to cluster (%lu)
VCPClusterer: Failed to cluster(adding) faces - %@
VCPClusterer: Added %lu faces to cluster cache
VCPClusteringBatch
VCPClusterer: Added faces to cluster cache [time: %f secs]
VCPClusterer: Start clustering
VCPClusterer: Finished clustering %lu faces, with normalized %.2f millisecond per face
VCPClusterer: Vision failed to cluster - %@
[VisionFgMapping] Preparing Vision Clusters (size: %ld) to Photos FaceGroup
VCPVisionFgMapping_Prepare
VCPClusterer: Failed to save cluster cache - %@
VCPClusterer: Start to update database models
VCPClusterer: Failed to persist FaceGroups; will try next time - %@
VCPClusterer: Updated database models
VCPClusterer: Cannot cluster image print type %lu
VCPClusterer: Failed to get VNFaceTorsoprint from face %@ - %@
VCPClusterer: Missing faceprint data for face %@
VCPClusterer: Failed to remove empty FaceGroup(s) - %@
VCPClusterer: Start quick-syncing cluster cache with library
VCPClusterer: Failed to clean faces with valid CSN but not in any FaceGroup - %@
VCPClusterer: Failed to clean faces with CSN = 0 but found in any FaceGroup - %@
VCPClusterer: Number of clustered faces in the cluster cache (%lu) < number of clustered faces in the library (%lu)
VCPClusterer: Quick-syncing cluster cache with library, found > 10%% (%5.2f) difference in the number of faces that are in the cluster cache versus library
VCPClusterer: Finished quick-syncing cluster cache with library. Elapsed time: %f
VCPClusterer: Start syncing cluster cache with library ...
VCPClusterer: Retrieving clusters from cluster cache ...
VCPClusterer: Retrieved clusters from cluster cache
VCPClusterer: Failed to retrieve clusters from cluster cache - %@
VCPClusterer: Retrieving clusters from library ...
VCPClusterer: Retrieved clusters from library
VCPClusterer: Failed to retrieve clusters from library - %@
VCPClusterer: Syncing cluster cache with library, found %lu non-singleton clusters in the cluster cache that do not match those in the library
VCPClusterer: Syncing cluster cache with library, found %lu clusters in the library cache that do not match those in the cluster cache
VCPClusterer: Syncing cluster cache with library, found > 20%% (%5.2f) difference in the number of faces are in the cluster cache versus library
VCPClusterer: Failed to ungroup faces - %@
VCPClusterer: Successfully reset cluster cache - %@
VCPClusterer: Failed to reset cluster cache - %@ - %@
VCPClusterer: Deleting FaceGroups and reset CSN of all previously clustered faces
VCPClusterer: Canceled syncing cluster cache [point: %d do loop]
VCPClusterer: Retry deleting FaceGroups and reset CSN of all previously clustered faces. Attempt %d of %d.
VCPClusterer: Deleted FaceGroups and reset CSN of all previously clustered faces
VCPClusterer: Failed to delete face groups and reset CSN of all previously clustered faces - %@
VCPClusterer: Syncing cluster cache with library - %@
VCPClusterer: Schedule adding %lu faces to the cluster state
VCPClusterer: Failed to get faces that are no longer present in the library
VCPClusterer: Canceled syncing cluster cache [point: %d]
VCPClusterer: Schedule removing %lu faces from the cluster state
VCPClusterer: Finished syncing cluster cache with library - %@
%@ - %@
Creating VNClustererBuilder with context.processingVersion:%d, type: %@, cachePath: %@, faceprintRequestRevision-%lu threshold-%.2f, torsoprintRequestRevision-%lu threshold-%.2f
VCPClusterer: Started resetting cluster cache ... 
VCPClusterer: Failed to remove all cluster cache files - %@
VCPClusterer: Created a new cluster cache
VCPClusterer: Failed to save a new cluster cache - %@
VCPClusterer: Finished resetting cluster cache
VCPClusterer: Failed to create a new cluster cache - %@
VCPClusterer: Failed to get old vision cluster cache filenames from vision cluster state
VCPClusterer: Failed to remove cluster mmap file at '%@' - %@
VCPClusterer: Failed to restore Vision clustering state - %@
VCPClusterer: Failed to unarchive cluster cache data blob from '%@'
VCPClusterer: Resetting cluster cache files - %@
VCPClusterer: Started restoring cluster cache
VCPClusterer: Failed to restore cluster cache - %@
VCPClusterer: Failed to restore cluster cache
VCPClusterer: Failed to restore cluster cache with std::exception %s
VCPClusterer: Restored cluster cache. Clusterer bring-up state - %@, time to restore: %f secs
[VisionFgMapping] Checking l1-cluster %@ (%ld faces) for conflict
[VisionFgMapping] Resolving conflict l0-cluster %@ in l1-cluster %@
VCPClusterer: Failed to get Vision clusters - %@
VCPClusterer: Retrieving clusters in cluster cache ...
VCPClusterer: Failed to retrieve clusters in cluster cache - %@
VCPClusterer: Retrieving clusters in library ...
VCPClusterer: Failed to retrieve clusters in library - %@
VCPClusterer: Comparing clusters
VCPClusterer: Failed to remove cluster snapshot at '%@': %@
VCPClusterer: Failed to remove cluster mmap file at '%@': %@
VCPClusterer: Bring-up state transition: %@ -> %@
VCPClusterer - _calculateChecksumMD5ForFile: error reading %zu bytes from file
Not implemented, please use initWithOptions
Incompatible request (%@) specified to %@
[RemoveBackground][%@] running (Mask: %d, Crop: %d, In-Place: %d)...
[RemoveBackground][%@] Skipping for ineligible image
[RemoveBackground][%@] Checking for cached image handler...
[RemoveBackground][%@] Matched cached image handler(!)
[RemoveBackground][%@] No cached image handler
[RemoveBackground][%@] Cached image handler does not match
[RemoveBackground][%@] Resetting cached image handler
VCPMADVIRemoveBackgroundTask image loading failed
[RemoveBackground] Image is screenshot - detecting ROI
[RemoveBackground] Failed to detect screenshot ROI (%@)
[RemoveBackground] Screenshot has no ROI (%@)
[RemoveBackground] Screenshot ROI: (%0.2f, %0.2f) %0.2fx%0.2f Confidence: %0.2f [1 of %d]
VNImageRequestHandler_init
[RemoveBackground] Set VNProcessingDevice: %@ (%@)
[RemoveBackground] Perform-in-place requested for ineligible input; ignoring
[%@] In Place: %d Crop: %d  Mask: %d  ROI: (%0.2f, %0.2f) %0.2fx%0.2f
VNImageRequestHandler_performRequests
[RemoveBackground][%@] Caching image handler (resolution %dx%d, orientation %d)
[RemoveBackground] No observations produced for image
[RemoveBackground][%@] complete
Invalid VNRequest configuration (%@)
VNRequest must be non-nil
[MediaAnalysis][%@] Analysis requested for blacklisted asset
[MediaAnalysis][%@] Existing analysis based on old modification
[MediaAnalysis][%@] Existing analysis based on degraded asset
[MediaAnalysis][%@] Existing analysis satisfies request (%@)
[MediaAnalysis][%@] Existing analysis doesn't match asset state
[MediaAnalysis][%@] Existing analysis doesn't satisfy request (%@)
[MediaAnalysis][%@] Generating analysis on-demand: %@
  [%@] Analysis cancelled
  [%@] Analysis failed to complete
Unsupported photo analysis type %@
Unsupported movie analysis type %@
VCPFullAnalysisAssetProcessingTask
VCPFullAnalysisAssetProcessingTask processing failed
Media analysis client XPC connection interrupted
Media analysis client XPC connection invalidated
[MediaAnalysis] [MediaAnalyzer requestAnalysisTypes] call with invalid resourceURLs
Failed to issue sandbox extension on %@
[MediaAnalysis] Error connecting to background analysis service
[MediaAnalysis] Request %d has completed
[MediaAnalysis] Error connecting to Photos background analysis service
[MediaAnalysis] Unsupported task %lu
[MediaAnalysis] Asset processing request %d has completed
In-Process quick face identification not supported
[MediaAnalysis] Error connecting to Photos Quick Face Identification service
[MediaAnalysis] Request %d is %.2f%% complete
[MediaAnalysis] Unknown analysis request %d; dropping cancellation request
[MediaAnalysis] No active analysis requests; dropping cancellation request
[MediaAnalysis] Failed to cancel background analysis: %@
[MediaAnalysis] Background analysis canceled
[MediaAnalysis] Error connecting to background analysis service: %@
[MediaAnalysis] Error connecting to request PersonPromoterStatus service
[MediaAnalysis] Request Person Preference %d has completed
[MediaAnalysis] Request VIP model filepath Preference %d has completed
[MediaAnalysis] Error connecting to request SuggestedPersons service
[MediaAnalysis] Request SuggestedPersons %d has completed
[MediaAnalysis] Error connecting to request UpdateKeyFacesOfPersons service
[MediaAnalysis] Request UpdateKeyFacesOfPersons %d has completed
[MediaAnalysis] Error connecting to request FaceCandidatesforKeyFace service
[MediaAnalysis] Request FaceCandidatesforKeyFace %d has completed
[MediaAnalysis] Error connecting to request ResetFaceClassificationModel service
[MediaAnalysis] Request ResetFaceClassificationModel %d has completed
[MediaAnalysis] Error connecting to request ResetPetClassificationModel service
[MediaAnalysis] Request ResetPetClassificationModel %d has completed
[MediaAnalysis] Error connecting to request SuggestedMePersonIdentifier service
[MediaAnalysis] Request SuggestedMePersonIdentifier %d has completed
[MediaAnalysis] Request PersonPromoterStatus %d has completed
[MediaAnalysis] Error connecting to request Face and Person workflow
[MediaAnalysis] Request Face and Person workflow %d has completed
[MediaAnalysis] Error connecting to request ClusterCacheValidation service
[MediaAnalysis] Request ClusterCacheValidation %d has completed
[MediaAnalysis] Error connecting to request ResetFaceClusteringState service
[MediaAnalysis] Request ResetFaceClusteringState %d has completed
[MediaAnalysis] Error connecting to request ReclusterFaces service
[MediaAnalysis] Request ReclusterFaces %d has completed
[MediaAnalysis] Error connecting to request RebuildPersons service
[MediaAnalysis] Request RebuildPersons %d has completed
[MediaAnalysis] Error connecting to query AutoCounter Opt-In status service
[MediaAnalysis] Query AutoCounter Opt-In status %d has completed
[MediaAnalysis] Error connecting to request Opt-In AutoCounter
[MediaAnalysis] Request Opt-In AutoCounter %d has completed
[MediaAnalysis] Error connecting to request AutoCounter dump
[MediaAnalysis] Request AutoCounter dump %d has completed
[MediaAnalysis] Error connecting to request AutoCounter calculation
[MediaAnalysis] Request AutoCounter calculation %d has completed
[MediaAnalysis] Request AutoCounter SIML validation %d has completed
[MediaAnalysis] Faces must be non-empty and completion block must be non-nil
[MediaAnalysis] Faces must all be from the same Photo Library
[MediaAnalysis] Error connecting to Media Analysis
[MediaAnalysis] nil specified for non-nullable parameter
VCPVideoCaptionEncoder: start loading model at: %@
VCPVideoCaptionEncoder: model to load %@
VCPVideoCaptionEncoder: inputBlob.nframes = %d, inputBlob.height = %d, inputBlob.width = %d, inputBlob.channels = %d
VCPVideoCaptionEncoder: successfully loaded model
 keypointsToObservation - unexpected keypoints count
incompatible input buffer size/format, check requiredInputFormat
CVNLPCommSafetyHandler_init
Failed to create CVNLPCommSafetyHandler: %@
VCPMADImageSafetyClassificationTask running...
VCPMADImageSafetyClassificationTask image loading failed
VCPMADImageSafetyClassificationTask image pre-processing failed
CVNLPCommSafetyHandler_scale
CVNLPCommSafetyHandler unavailable for classifying pixel buffer
CVNLPCommSafetyHandler_classifyPixelBuffer
VCPMADImageSafetyClassificationTask failed (%@)
VCPMADImageSafetyClassificationTask complete
[VCPPhotosFace] faceprint.confidence is too low (%.3f < 0.1) %@ - junkinessIndex: %.3f
[VCPPhotosFace] Accepting faceprint with confidence: %.3f %@ - junkinessIndex: %.3f
[VCPPhotosFace] Missing results for roll information
[VCPPhotosFace] Missing results from VNDetectFaceCaptureQualityRequest
[VCPPhotosFace] Missing results for yaw information
[VCPPhotosFace] Missing results from VNDetectFaceExpressionsRequest
[VCPPhotosFace] Missing results from VNClassifyFaceAttributesRequest
[VCPPhotosFace] Gaze: mask: %s, VNFaceGazeDirection: %@, PHFaceGazeType: %@ at (%.3f, %.3f)
[VCPPhotosFace] Missing results from VNDetectFaceGazeRequest
[PhotosFace] Fail to generate VCPPhotosFace from %@ and %@ - %@
[PhotosFace] Generate VCPPhotosFace %@ from %@ and %@
[PhotosFace] Fail to generate VCPPhotosFace %@ from %@ and %@ - invalid imageprint
[PhotosFace] Fail to generate face only VCPPhotosFace from %@ - %@
[PhotosFace] Generate face only VCPPhotosFace %@ from %@
[PhotosFace] Fail to generate VCPPhotosFace %@ from %@ - invalid imageprint
[PhotosFace] Failed to serialize torsoprint; %@
[PhotosFace] torsoOnlyObservation failed to return a faceprint
[PhotosFace] Ignoring co-locating animalObservation %@
[PhotosFace] Unable to determine normalized bounding box { { %f, %f } { %f, %f } }
[PhotosFace] Failed to serialize animalprintData; %@
[PhotosFace] animalObservation failed to return a faceprint
[PhotosFace] Generate VCPPhotosFace %@ from %@
[PhotosFace] IoU %f %@ %@
[VCPCNNEspressoContext] created CPU context
[VCPCNNEspressoContext] Failed to CPU context
[VCPCNNEspressoContext] created MPSGraph context
[VCPCNNEspressoContext] Failed to create MPSGraph context, fall back to CPU context
[VCPCNNEspressoContext] created preferred context
[VCPCNNEspressoContext] Failed to create ANE context, fall back to MPS context
[VCPCNNEspressoContext] Failed to create MPS context, fall back to CPU context
[VCPCNNEspressoContext] sharing CPU context
[VCPCNNEspressoContext] sharing MPSGraph context
[VCPCNNEspressoContext] sharing preferred context
[VCPCNNEspressoContext] dealloc shared context; keep alive
[VCPCNNEspressoContext] dealloc context;
[VCPCNNEspressoContext] No valid context; skip dealloc
Choosing asset resource from preferred list: %@
Network is available, filtering list to remove the CPL Thumb, new list is: %@
No resources locally available, returning a downloadable hi-res resource: %@
[Face] Failed setting %@ private revision: %@, umbrellaVersion: %d
[FaceConfiguration] No proper vision model revision for %@ with umbrellaVersion: %d
VCPObjectPool failed to allocate object
Failed to get the ideal size of request %@ with revision %lu
Failed to set %@::setRevision %lu: %@
Request %@ (revision %lu) ideal size %@
Ideal size for request %@ not cached
[MediaAnalysis] Junk analayzer - unexpected %d VNObservations
VIService_init
[CNNModelEspresso] Creating %@context for %@
[CNNModelEspresso] Created %scontext (CPU:%d, MPSGraph:%d)), storage type %d
Invalid sceneprint revision: %lu (required %lu)
Failed to open analysis database for Photo Library (%@)
Specified Photo Library has no URL (<%@>); cannot find analysis database
Cloning model: %@
Deleting old clone directory for caption model: %@
Could not delete old clone directory for caption model: %@. error: %@
Creating clone directory for caption model: %@
Could not create clone directory for caption model: %@. error: %@
Cloning caption model: '%@' to: '%@'
Could not clone caption model. clonefile(%@, %@, %o) FAILED with (%d : %s)
Video captioning mode: VCPVideoCaptionMode_Off
Download meta data reply %ld
Queried asset metadata with result: %ld
No video caption encoder query results
Asset %@ not present - downloading
Progress callback: %lld %lld
Downloaded asset with result %li, error? %@
Space not available to download asset %lli
Video caption decoder test model not exist at %@, skip video caption analysis
Unable to obatain video caption decoder model from Accessibility
Video caption encoder test model not exist at %@, skip video caption analysis
Failed to create CVNLPVideoCaptioningModel (%@)
Error to generate video caption with CVNLPVideoCaptioningModel (%@)
Incomparable images: this - %@ vs that - %@
VCPVideoKeyFrameBlurAnalyzer
VCPVideoKeyFrameFaceQualityAnalyzer
Query progress: unsupport taskID %lu - %@
Query progress: output parameter statistics must be non-nil
Query progress: scan library for %lu - %@
VCPAnalysisProgressQueryScanPhotoLibraryFetch
Query progress: unsupported taskID (%lu)
VCPAnalysisProgressQueryExpressPathFetchTotalCount
VCPAnalysisProgressQueryExpressPathFetchProcessedCount
Query progress: unsupported taskID (%@)
VCPAnalysisProgressQueryProgressDetail
VCPAnalysisProgressQueryProgress
Query cached face progress: %lu out of %lu
VCPAnalysisProgressQueryCachedFaceAnalysisProgress
[EmbeddingOnDemand] Incompatible request (%@) specified to %@
[EmbeddingOnDemand] Incompatible imageAsset (%@) specified to %@
VCPMADEmbeddingGenerationTask not supported on this platform
Multiple sampling times (%0.1fs) intersect frame at %lld/%d
%@ skipping sample %lld at %lld/%d
%@ failed for sample at %lld/%d (%@)
QuickFaceID: Failed to create faceprint from data : %@
QuickFaceID: Failed to create animalprint from data : %@
QuickFaceID: Passing classify face confidence: %f
QuickFaceID: Failed passing classify face confidence: %f
QuickFaceID: Failed to predict at all
QuickFaceID Pet: Passing classify pet confidence: %f
QuickFaceID Pet: Failed passing classify pet confidence: %f
QuickFaceID Pet: Failed to predict pet at all
QuickFaceID %@ Model path is nil; skip loading
Failed to load VIP %@ Model
No persistentStorageDirectoryURL for photoLibrary: %@
Unable to serialize library analysis preferences for %@: %@
Unable to write library analysis preferences for %@: %@
Key for setLibraryAnalysisPreferencesValue is nil
Failed to fetch VIP model file path with unknown VCPMAVIPType (%lu)
Failed to fetch VIP model last generation date with unknown VCPMAVIPType (%lu)
Not requiring processing for unknown taskID %lu
Fail in generating motion flow
[FaceModelBump] Failed to update version state - %@
[FaceModelBump] No persistentURL to update version state - %@
[FaceModelBump] Resetting face data ... (%@)
[FaceModelBump] Failed to reset Face Analysis data for PhotoLibrary %@
Face Quality Results mismatch with detected Faces (%lu vs %lu)
Error: FaceQualityScore should not contain results! (size = %lu, timestamp=%.2f)
time=%.2f sharpness=%.2f, faceSharpness=%.2f, cameraM=%.2f, subjectM=%.2f, junk=%.2f, obstr=%.2f, exposure=%.2f, score=%.2f
Error -[VNCreateSceneprintRequest setRevision:error:]
Error -[VNImageRequestHandler requestHandler:error:]
NSKeyedUnarchiver error: %@
 VCPFaceShapeModel - caught exception in find_min_box_constrained()
VCPFaceShapeModel - caught exception in find_min()
 VCPFaceShapeModel - caught exception in find_min_using_approximate_derivatives()
Query context: %@
VCPMADVITextLookupTask running...
VCPMADVITextLookupTask image loading failed
VCPMADVITextLookupTask failed to create text lookup query context (%@)
VIService_TextLookup
VCPMADVITextLookupTask complete (%d)
%@ does not implement purge
Real-time analysis client XPC connection interrupted
Real-time analysis client XPC connection invalidated
Pixel buffer not IOSurface-backed; dropping analysis request
Real-time analysis client XPC connection error
Not all needed analysis are available for video highlights.
[%.2f - %.2f] expressionScore=%.2f, actionScore=%.2f, voiceScore=%.2f, Score=%.2f
[%.2f - %.2f] keyFrameScore=%.2f, expressionScore=%.2f, actionScore=%.2f, voiceScore=%.2f, humanActionScore=%.2f, humanPoseScore=%0.2f, qualityJunkScore = %.2f, mlQualityScore = %.2f, Score=%.2f
[HomeKit] Failed to connect to analysis service (%@)
[HomeKit] VCPHomeKitAnalysisSession initialization fails (%@)
[HomeKit] Client XPC connection interrupted
[HomeKit] Client XPC connection invalidated
[HomeKit] Error connecting to background analysis service
[VCPDatabaseReader] No database file exists
[VCPDatabaseReader] Failed to open database: %d
[VCPDatabaseReader] Failed to set busy handler: %d
[MediaAnalysis] Unknown result key for result type %u
[VCPDatabaseReader] Database already opened, failed to execute query block: %d
[VCPDatabaseReader] Failed to execute query block: %d
[MediaAnalysis] Error querying blacklist status for %@
[MediaAnalysis] Failed to query blacklisted assets
[MediaAnalysis] Failed to query asset %@
[MediaAnalysis] Failed to query analysis properties of asset %@
[MediaAnalysis] queryAnalysesForAssets Failed
[MediaAnalysis] Failed to query assets since %@
[MediaAnalysis] Failed to query failed assets for taskID: %lu
[MediaAnalysis] WARNING: ProcessingStatus entry with nil localIdentifier
Failed to query KeyValueStore (error code: %d)
Failed to query scheduling history for background activity %@
[VCPDatabaseReader] Error SQLITE_BUSY encountered, attempting first retry
[VCPDatabaseReader] busy timeout has passed since first retry, stop retrying
Failed to extract NSArray from column %d (%@)
Orientation value %u invalid, assuming kCGImagePropertyOrientationUp
Running Home Resident Maintenance task
Canceling Home Resident Maintenance task (%d)
HomeAI request submitted (%d)
[VCPMADServiceImageProcessing] Fetching Photos asset with identifier %@
[VCPMADServiceImageProcessing] Fetch returned multiple assets for identifier (%@)
[ImageProcessingTask%d] Build task for asset (%@)
[ImageProcessingTask%d] Failed to fetch asset (%@) - %@
[ImageProcessingTask%d] Failed to process asset (%@) - %@
[ImageProcessingTask%d] Finished processing asset (%@)
Request canceled
%@ returned unexpected status (%d)
VCPMADServiceImageProcessingTaskBatch_Run
Failed to create VNGeneratePhotosAdjustmentsRequest
Failed to set VNGeneratePhotosAdjustmentsRequest::setRevision %lu: %@
VNGeneratePhotosAdjustmentsRequest failed
[FaceCropGeneration] Scaling down from %.0fx%.0f with factor: %.3f
[FaceCropGeneration] Scaling up from %.0fx%.0f with factor: %.3f
Invalid orientation found: %d. Using a default value of 1
 [%@] QuickFaceDetect: failed to persist classification results: %@
   [%@] Ignoring analysis results for Montage asset
 [%@] QuickFaceDetect: analyzing asset (deferType: %d)
 [%@] QuickFaceDetect: processed %lu faces
[SceneNet] Failed to find label for identifier %d
[NSFW] Failed to find label for identifier %d
VCPMADVIMachineReadableCodeDetectionTask running...
[MRC] Custom request configuration; overriding to use cached data
VCPMADVIMachineReadableCodeDetectionTask image loading failed
Failed to configure VNDetectBarcodesRequest
[MRC] Custom request configuration; not persisting result
VCPMADVIMachineReadableCodeDetectionTask complete
Flow decoder: fail to bind inputFeature
Flow decoder: fail to bind correlation
Flow decoder: fail to bind upscaled flow
Flow decoder: fail to bind output flow
Flow decoder: fail to bind buffers
Flow decoder: executing callback
Flow decoder: fail to execute
    Pixel Stabilization confidence doesn't pass the threshold
Found %lu faces with CSN > 0 but not in any face groups
[VisionFgMapping] Vision Cluster with single l0clusters; skip de-conflict
[VisionFgMapping] Vision Cluster contains %lu conflicting people
[VisionFgMapping] Conflicting person %@
[VisionFgMapping] Vision Cluster has conflicting l0cluster %@
[VisionFgMapping] Vision Cluster does not have conflicting l0clusters
[VisionFgMapping] Persisting %ld Vision Clusters to Photos FaceGroup
[VisionFgMapping] Invalid csn (%@) for newly clustered face %@
VisionFgMapping_LookingAfterNewClusteredFace
VisionFgMapping_LookingForConflictingCluster
[VisionFgMapping] Split Cluster %@ with %ld faces with representing face csn %@
[VisionFgMapping] 
 csn: %ld 
[VisionFgMapping] Cannot exclude invalid l0RepresentingCSN %@ in l1Cluster %@
[VisionFgMapping] Output (remaining) Cluster %@ -> %@ with %ld faces
VisionFgMapping_ResolveConflictingCluster
[VisionFgMapping] Output (no-touch) Cluster %@ with %ld faces
VisionFgMapping_ResolveConflictL0Clusters
VisionFgMapping_Process
PersistFaceGroups: Photo library is missing a face with CSN = %@
PersistFaceGroups: Faces with these CSNs will be removed from the cluster cache: %@
PersistFaceGroups: Faces with these localIdentifiers will be re-clustered: %@
PersistFaceGroups: We should not get here! If we did, then we have a previously clustered face without a face group!
PersistFaceGroups: Failed to create a face group change request to add faces!
PersistFaceGroups: Failed to find a faceGroup for face '%@' with CSN: %d
PersistFaceGroups: No faces added to face groups!
PersistFaceGroups: Failed to find face with localIdentier: %@. Could not set its CSN to %@
PersistFaceGroups: Set personBuilderState of faceGroups: %@
PersistFaceGroups: Failed to delete empty face groups with error: %@
PersistFaceGroups: Canceled updating key faces unverified persons after persisting face groups.
PersistFaceGroups: Failed to update key faces unverified persons after persisting face groups. Error: %@
%s: %@
[UpdateKeyFaces] Person %@ already has a keyface; skipping
[UpdateKeyFaces] Failed to find a representing face for Person %@ (verified type %ld)
[UpdateKeyFaces] Updating Person %@ (verified type %ld) with key face %@
[UpdateKeyFaces] Found %lu face groups for unverified person)
[UpdateKeyFaces] Failed to persist key face - %@
Warning: cannot handle representativeness with imageprint type %d; ignoring
Warning: Couldn't get faceprint data for face: %@; ignoring
representativeness selection receives a torso-only print; ignoring
Failed to get VNFaceTorsoprint from faceprint data - %@
Warning: Could not get representativeness for faces, error: %@
PersonBuilder: Deleted duplicate graph-verified persons '%@' from face group %@
PersonBuilder: Failed to delete duplicate graph-verified persons '%@' from face group %@
PersonBuilder: Deduped graph-verified persons '%@' from face group %@
PersonBuilder: Failed to dedupe graph-verified persons '%@' from face group %@
personLocalIdentifier for PHFace %@ is null; skip processing
Found no persons rejected for a rejection training face: %@
PersonBuilder: Did not find merge candidate persons with local identifiers: '%@'
PersonBuilder: Found invalid merge candidate pair ['%@' : '%@']
PersonBuilder: Already found merge candidate pair ['%@' : '%@']
PersonBuilder: persist results for facegroup %@
PersonBuilder: Could not create merge candidate pair '%@' : '%@'
PersonBuilder: Could not create invalid merge candidate pair '%@' : '%@'
PersonBuilder: Cleared personBuilderState of faceGroup: '%@'
Could not find a face with clusterSequenceNumber '%@' in the library
%@ Checking face %@
%@ Failed to find face
%@ No valid person
%@ Found person(s) %@
%@ Person mismatch: face (%@) personLocalIdentifier %@ vs faceCropPerson %@ (%ld)
[FaceCropAdjustment] Correcting %lu training face -> person
[FaceCropAdjustment] Failed to find person for face %@
[FaceCropAdjustment] Correcting face %@ from %@ to %@, with nameSource:%ld
[FaceCropAdjustment] Checking %lu rejected person(s)
[RejectedFaceCrop] To remove face %@ for person %@
[FaceCropAdjustment] Removing %lu faces for person %@
[FaceCropAdjustment] Remove face %@ for person %@
[FaceCropAdjustment] Failed to update person - %@
[PHFaceCrop Dedupe] PHFaceCrop without localIdentifier - %@
[PHFaceCrop Dedupe] PHFace without localIdentifier - %@
[PHFaceCrop Dedupe] Missing PHFaceX[%@]
[PHFaceCrop Dedupe] PHFaceX[%@] without faceprint
[PHFaceCrop Dedupe] Missing PHFaceY[%@]
[PHFaceCrop Dedupe] Unmatched training type PHFaceX[%@](%d) and PHFaceY[%@](%d)
[PHFaceCrop Dedupe] PHFaceY[%@] without faceprint
[PHFaceCrop Dedupe] Duplicated with distance: %f [%@:%d] vs [%@:%d]
[PHFaceCrop Dedupe] Distance: %f [%@] vs [%@] - %@
[PHFaceCrop Dedupe] Processing duplications
[PHFaceCrop Dedupe] %lu duplications - %@
[PHFaceCrop Dedupe] Removing %@ dupe to %@
[FaceCrop] Processing newly clustered face crops in %lu PHFaceGroup; start processing ...
[FaceCrop] Fetched %lu PHFaceCrop in PHFaceGroup (%@); skip
[FaceCrop] Fetched %lu newly clustered PHFaceCrop in PHFaceGroup (%@); skip
[FaceCropAdjustment] Fetched %lu PHFaceCrops in PHFaceGroup (%@); start processing ...
[FaceCropAdjustment] Processing finished
[PHFaceCrop Dedupe] Fetched %lu PHFaceCrop in PHFaceGroup (%@); skip
[PHFaceCrop Dedupe] Fetched %lu PHFaceCrops in PHFaceGroup (%@); start dedupping ...
[FaceCrop] Updated %lu PHFaceCrops
[FaceCrop] Failed to update %lu PHFaceCrops - %@
[FaceCrop] Removed %lu duplicated PHFaceCrops
[FaceCrop] Failed to remove %lu duplicated PHFaceCrops - %@
MADProcessNewlyClusteredFaceCrops
PersonBuilder: Got a 'nil' photoLibrary. Cannot build persons
PersonBuilder: Failed to find unverified person for faceGroups '%@'; These will be fixed up and retried later
PersonBuilder: Failed to fix up face groups without unverified person. Error: '%@'
PersonBuilder: Person Building faceGroup '%@'
PersonBuilder: Failed to find unverified person [unverifiedPerson: %@, unverifiedPersonLocalIdentifier: %@] for faceGroup '%@', skipping this face group
%lu Quick classification face to retain: %@
%lu Quick classification face to reassign: %@
PersonBuilder: Quick classification face: %lu retained, %lu reassigned
[VisionFgMapping] Failed to find conflicting l0cluster (expect csn: %@)
PersonBuilder: We may have a dirty level0 cluster, persons with training faces: %@
PersonBuilder: We may have a dirty level0 cluster, verified persons with confirmed face: %@
PersonBuilder: Unnamed unconfirmed faces in face group, '%@', without a training face: %@
PersonBuilder: Found training rejection, unassigned faces on trainingPersonLocalIdentifier in level0 cluster: %@
PersonBuilder: Skip processing level0 cluster since we have rejected face for training person '%@' in level1 cluster
PersonBuilder: Failed to build persons [Error: '%@']
PersonBuilder: ---> buildPersonWithFaceClusterer, %s
VCPFaceProcessingBuildPersonsCoreAnalyticsCollection
PersonBuilder: Person Building is Disabled!
PersonBuilder: Cleared personBuilderState of faceGroups: %@
PersonBuilder: Failed to clear personBuilderState of faceGroups: %@, error: %@
PersonBuilder: <--- buildPersonWithFaceClusterer
Got a 'nil' photoLibrary. Cannot remove auto assigned faces
Failed to remove auto-assigned faces from person '%@', error: %@
  [%@] No scene classification result fetched from pre analysis
Scene identifier %u has no name; ignoring
[MediaAnalysis][%@] No slow-mo timestamp mapping file URL found
[MediaAnalysis][%@] No slow-mo timestamp mapping file found
[%@] Asset has no small video derivative; cannot download
VCPMADVIDocumentRecognitionTask running...
[DocumentRecognition] Custom request configuration; overriding to use cached data
VCPMADVIDocumentRecognitionTask image loading failed
[DocumentRecognition] Set VNProcessingDevice: %@ (%@)
[DocumentRecognition] Custom request configuration; not persisting result
VCPMADVIDocumentRecognitionTask complete
Cannot load Person Identity Model - %@
Person Identity Model not exist - %@
PersonIdentityModel_init
[%@] running...
[%@] complete
[%@] complete without on-demand process
[%@] image loading failed
VCPMADPersonIdentificationTask_createVisionImageRequest
VCPMADPersonIdentificationTask_detectFace
[%@] No face detected from CVPixelBuffer
[%@] Detected %lu faces, identifying ...
[%@] Detected %lu faces, identifying top %lu faces (by confidence) ...
VCPMADPersonIdentificationTask_generateFaceprint
[%@] No face to identify from CVPixelBuffer
[%@] Failed to classify face (%@) - %@; skipping
[%@] No valid identification to face (%@); skipping
[%@] prediction: %@, confidence: %.3f at %@
[%@] Failed to fetch person with identifier %@; skipping
[%@] Identified %lu faces
VCPMADPersonIdentificationTask_identifyFace
[%@] complete with on-demand analysis
Unknown Media Analysis version specified (%d)
[MediaAnalysis] No slow-mo timerange mapper available, fall back to Scaled Time
[MediaAnalysis] No slow-mo timerange mapper available, fall back to Original Time
Invalid Live Photo Gating result type key [%@]
VCPVersionForTask not implemented for %@ (%d); using MediaAnalysisVersion (%d)
  [%@] Unknown analysis version %d; discarding
Failed to get memory information
Failed to query supported revision; %@ does not support
Unsupported revision (%lu) for %@
Checking revision for %@ is not supporteds
Feature extractor: fail to bind input
Feature extractor: fail to bind output at level %d
Feature extractor: fail to bind buffers
Feature extractor: executing callback
Feature extractor: fail to execute
[OCR][%@] Re-using cached results
[VS][%@] Re-using cached results
VCPMADServiceImageURLAsset_Decode
VCPMADServiceImageDataAsset_Decode
[Faces][%@] Asset not processed or outdated
[Faces][%@] Loading existing results from Photos
[NSFW][%@] Asset not processed or outdated
[NSFW][%@] Loading existing results from Photos
[SceneNet][%@] Asset not processed or outdated
[SceneNet][%@] Loading existing results from Photos
[SceneNet] No scene label name for scene id %d
[%@] Ineligible Confidence: %0.3f
[%@] Ineligible Confidence: -
[%@] Selecting resource for Asset Type: %@ [%d/%d] Resolution: %dx%d
[%@] Evaluating resource (Type: %d Resolution: %dx%d)
[%@] Resource not locally available; skipping resource
[%@] Purging resource cache to load uncommon resource (%@)
[%@] Purging resource cache to load large resource (%dx%d)
[%@] Failed to load orientation
[%@] Loaded resource (Type: %d Actual Resolution: %dx%d, orientation %d)
[%@] Failed to load resource (Type: %d)
VCPMADServiceImageAsset_Decode
[%@] Failed to find/decode high-res image resource
[%@] Evaluating high-resolution resource (Type: %d Resolution: %dx%d)
[%@] Evaluating fall-back resource (Type: %d Resolution: %dx%d)
[%@][%@] Deferring persistence until OCR available
[%@][%@] Deferring persistence until MRC available
[%@][%@] Asset has invalid adjustment version (%@); cannot persist results to Photos
[%@][%@] Persisting results to Photos
VNDocumentObservation_archive
[%@][%@] Failed to archive OCR observation
[%@][%@] No text recognized; skipping archive/persistence
VNBarcodeObservation_archive
[%@][%@] Failed to archive MRC observations
[%@][%@] No MR Codes recognized; skipping archive/persistence
[%@][%@] Successfully persisted results to Photos
[%@][%@] Failed to persist results to Photos
[OCR][%@] Checking for existing results from Photos
[OCR][%@] Loading existing results from Photos
[OCR][%@] Failed to unarchive existing Photos results
[OCR][%@] Photos results exist, but no text was recognized
[OCR][%@] Asset does not have existing results
[OCR][%@] Successfully reused existing results
[MRC][%@] Checking for existing results from Photos
[MRC][%@] Loading existing results from Photos
[MRC][%@] Failed to unarchive existing Photos results
[MRC][%@] Photos results exist, but no text was recognized
[MRC][%@] Asset does not have existing results
[MRC][%@] Successfully reused existing results
[VS][%@] Checking for existing results from Photos
[VS][%@] Loading existing results from Photos
[VS][%@] Photos results exist, but empty
[VS][%@] Asset does not have existing results
[VS][%@] Successfully reused existing results
[VS][%@] Asset has invalid adjustment version (%@); cannot persist results to Photos
[VS][%@] Persisting results to Photos
[VS][%@] Successfully persisted results to Photos
[VS][%@] Failed to persist results to Photos
[FaceCropManager][%@] Publish facecrop for face %@
[FaceCropManager][%@] No face detected; force faceprinting
[FaceCropManager] Failed to create VCPPhotosFace - %@
[FaceCropManager][%@] Failed to faceprint - %@
[FaceCropManager][%@] Failed to associate with face %@ - %@
[FacecropManager][%@] Associated with face %@
[FacecropManager] Updating faceprint for face %@
[FaceCropManager][%@] Failed to generate FaceCrop face - %@
[FaceCropManager][%@] Failed to update faceprint of associated face %@  - %@
[FaceCropManager] Set personBuilderState of faceGroup %@ for face %@
[FaceCropManager][%@] Analyzing facecrop (%.0fx%.0f)
[FaceCropManager][%@] Not in a dirty state (state:%d, expect:%d); skipping process
[FaceCropManager][%@] FaceCrop does not have data
[FaceCropManager][%@] existing face %@
[FaceCropManager][%@] Failed to update associated face %@ - %@
[FaceCropManager][%@] Failed to record needing to Person Building for face %@ - %@
[FaceCropManager][%@] Asset has face; skip facecrop generation
[FaceCropManager][%@] Facecrop will not be generated for the manual face %@
[FaceCropManager][%@] Too small facecrop (%.0fx%.0f) using resource %@ (%@)
[FaceCropManager][%@] Generated %lu facecrop(s)
[FaceCropManager] Library has %lu dirty face crops to analyze
[FaceCropManager] Failed to process dirty facecrop %@ - %@
VCPFaceProcessingDirtyFaceCrops
QuickFaceID Model: persistent storageDirectoryURL is nil
QuickFaceID Model: cannot load Persons Model: %@
VCPPersonVIPLoadModel
QuickFaceID Model: model with VNCreateFaceprintRequest revision %lu (FaceProcessing Version%d)
QuickFaceID Model: system is using VNCreateFaceprintRequest revision %lu (FaceProcessing Version%d)
QuickFaceID: failed to initialize face analyzer
QuickFaceID Pet Model: persistent storageDirectoryURL is nil; skip loading Model
QuickFaceID Pet Model: cannot load Model: %@
VCPPetVIPLoadModel
[%@] QuickFaceID: matching person %@
[%@] QuickFaceID: no matching person at location (%.3f, %.3f) - %@
[%@] QuickFaceID: no matching person at location (%.3f, %.3f)
[%@] Ignoring analysis results for Montage asset
QuickFaceID Persons Model is not ready; skip processing
[%@] QuickFaceID: analyzing asset (deferType: %d)
[%@] QuickFaceID: asset is not image
[%@] QuickFaceID: detecting faces
[%@] QuickFaceID: %lu detected faces
[%@] QuickFaceID: processed %lu faces
VCPPersonVIPAssetProcessing
QuickFaceID Pets Model is not ready; skip classifying
QuickFaceID Pet: pet (PHFace) %@ already has a nameSource %ld for petPerson %@; skip
QuickFaceID Pet: pet (PHFace) %@ is used to train this VIP model with petPerson %@; skip
QuickFaceID Pet: Could not create animalprint for pet (PHFace) %@ - %@
QuickFaceID Pet: Failed to classify %@ - %@; skip
QuickFaceID Pet: did not match %@ (at %.3f, %.3f)
QuickFaceID Pet: classified %@ to petPerson %@
QuickFaceID Pet: no petPerson %@; skipping
QuickFaceID Pet: failed to persist pet classification results: %@
QuickFaceID Pet: classified and persisted %lu Pet PHFace
[PersonIdentification] Unsupported library - %@
[PersonIdentification] No face needs to identify
[PersonIdentification] Identifying %lu faces
[PersonIdentification] VIP Persons Model is not ready
[PersonIdentification][%@] Failed to obtain faceprint; skipping
[PersonIdentification][%@] Failed to obtain face observation; skipping
[PersonIdentification][%@] Face identification process failed (%@); skipping
[PersonIdentification][%@] Face identified as %@ confidence:%.2f
[PersonIdentification][%@] Face not identified, confidence:%@
[PersonIdentification] Identified %lu out of %lu faces
[PersonIdentification] Successfully persisted identification results
[PersonIdentification] Failed to persist identification results - %@
QuickFaceID Model: unknown VIP type (%lu); no entity fetched
QuickFaceID Pets Model: Begin Pets model generation
QuickFaceID Pets Model: Failed to initialize VNAnimalObservation
QuickFaceID Pets Model: Failed to create VNEntityIdentificationModelConfiguration - %@
Failed to create VNMutableEntityIdentificationModel - %@
QuickFaceID Pets Model: Model generation cancelled; quitting
QuickFaceID Pets Model: petPerson: %@, petFaceFetchResult(%lu): %@
QuickFaceID Pets Model: Could not create animalprint for pet (PHFace): %@ - %@
QuickFaceID Pets Model: Could not add animalObservation to model for pet (PHFace): %@.
QuickFaceID Pets Model: animalObservations(%lu): %@
QuickFaceID Pets Model: Could not add animalprint to model - %@
VCPPetVIPGenerateModel
QuickFaceID Pets Model: Finished model generation
QuickFaceID Pets Model: Failed to persist pet model %@
QuickFaceID Pets Model: Could not get animalObservations for pet %@ - %@
QuickFaceID Pets Model: Could not persist isInVIPModel on trained pets - %@
QuickFaceID Pets Model: Finished model generation and persistence
QuickFaceID Model: Begin model generation
QuickFaceID Model: Model generation cancelled. Quitting
QuickFaceID: Building %@-confirmed person %@ (%@)
FaceID Model: fetched %lu faces
FaceID Model: fetched %lu faces without roll predicate
QuickFaceID Model: Could not create faceprint for face: %@. Error: %@
QuickFaceID Model: Could not add faceprint to model for face: %@.
QuickFaceID Model: Could not add faceprints to model. Error: %@
QuickFaceID: Built using %lu faces for person %@ (%@)
VCPPersonVIPGenerateModel
QuickFaceID Model: Finished model generation
QuickFaceID Model: Failed to persist model %@
QuickFaceID Model: Could not get face observations for person %@ - %@
QuickFaceID Model: Could not persist isInVIPModel on trained faces - %@
QuickFaceID Model: Finished model generation and persistence
QuickFaceID %@ Model: Last job generation %.0fs ago, job is due = %@
QuickFaceID [FastMigration]: asset processing progress: total: %ld, processed: %ld, failed: %ld
QuickFaceID [FastMigration]: asset processing rate: processed>90%%: %s, failure>10%%: %s, pass: %s
QuickFaceID [FastMigration]: persistent storageDirectoryURL is nil
QuickFaceID [FastMigration]: cannot load Persons Model: %@
QuickFaceID %@ Model: ignoreLastGenerationTime: %s
QuickFaceID %@ Model: No need to generate model
QuickFaceID Model: unknown VIP type (%lu); no model generated
Restore clusterer error (ClusterState = %ld): %@
Restored clusterer, ClusterState = %ld
UpdateKeyFaces for: '%@'
could not update key faces for suggestions: %@
Loaded clustererState: %ld
Returning no suggestions because the clusterer is working
suggestions first phase query start
suggestions first phase query end
suggestions middle phase query start (includes face groups for person query)
suggestions middle phase query end
suggestions last phase query start
suggestions last phase query end
Querying suggestions for person %@ (Photos: %@ to-be-confirmed, %@ to-be-rejected suggestions)
Returning %lu suggestions for person %@
Input parameter is empty or nil: '%@'
Persons Model: Failed to remove model at %@ - %@
Pets Model: Failed to remove model at %@ - %@
Person Processing: Starting Deleting Persons
VCPFaceProcessingDeleteAllVerifiedPersons
Person Processing: Deleting Persons %@
Person Processing: Starting Face Reclustering
VCPFaceProcessingReclusterFacesWithThreshold
Person Processing: Face Clustering %@
Person Processing: Starting Person Building
VCPFaceProcessingBuildPersons
Person Processing: Person Building %@
Person Processing: Starting Person Promotion
VCPFaceProcessingPromotePersons
Person Processing: Person Promotion %@
AVAsset: Montage asset detected
Failed to decode first frame (%@)
[CGImage->CVPixelBuffer] Failed to create CVPixelBuffer with existing IOSurface
[CGImage->CVPixelBuffer] CGImage not IOSurface backed
[CGImage->CVPixelBuffer] Failed to allocate CVPixelBuffer
[CGImage->CVPixelBuffer] Failed to allocate CGContext
[MediaAnalysis] Sample at %lld/%d is being extended %0.1fx
[MediaAnalysis] Requested post process highlight with NULL input analysis
[MediaAnalysis] Post-process highlights returned NULL
[MediaAnalysisResultsTypesForAnalysisTypes] Unknown result type
VideoPetActionAnalyzer: _scoreAbsoluteMax = %f, _scoreRelativeMax =%f
VCPVideoPetsActionTracker
VideoPetActionAnalyzer: finishAnalysisPass
  Extreme aspect ratio %f; initialization failed
[VideoTrackDecoder] Decoded frame and setting mismatch: actual padding right: %zupx, bottom: %zupx (expected right: %zupx, bottom: %zupx)
[VCPFaceCrop][%@] Failed to generate FaceCrop data - %@
[VCPFaceCrop][%@] Failed to create VCPFaceCrop instance
[%@] VCPCoreMLRequest Failed to open model file at url %@
VCPMADVIVisualSearchGatingTask running...
[VS] Cached parse result empty; returning empty result
VCPMADVIVisualSearchGatingTask failed to create visual search query context (%@)
VCPMADVIVisualSearchGatingTask image loading failed
VIService_VisualSearchGating
VCPMADVIVisualSearchGatingTask complete (%d)
VCPFaceAnalyzerImageRequestHandlerPerformRequest
[FaceAnalyzer] Failed to perform requests - %@
[FaceAnalyzer] Failed to create blur/exposure request
[FaceAnalyzer] Blur score %f out of bound [%f, %f]
[FaceAnalyzer] Failed to perform blur requests - %@
[FaceAnalyzer] Exposure score %f out of bound [%f, %f]
[FaceAnalyzer] Failed to perform exposure requests - %@
VCPFaceAnalyzerBlurExposureAnalysis
VCPFaceAnalyzerVCPFaceCreation
[VCPFaceAnalyzer][%@] Failed to create VCPPhotosFace from PHFace %@
VCPFaceAnalyzerVerifyAndMergeFaces
[FaceAnalyzer][%@] Resource (%d) has invalid dimensions (%dx%d); falling back to asset
[FaceAnalyzer][%@] Invalid dimensions (%dx%d)
VCPFaceProcessingFastPathDecodeAsset
[FaceAnalyzer][%@] Failed to decode image
[FaceAnalyzer][%@] Failed to decode orientation (%d)
VCPFaceAnalyzerLoadImageRequestHandler
[FaceAnalyzer][%@] Failed to create VNImageRequestHandler
[FaceAnalyzer][%@] Loaded local resource (%dx%d orientation:%d)
[FaceAnalyzer][%@] Failed to analyze resource
VCPFaceAnalyzerPerformAnalysis
[FaceAnalyzer][%@] Failed to refine analysis
VCPFaceAnalyzerRefineAnalysis
[FaceAnalyzer][%@] Face refine completed: detected %lu | persist: %lu | delete: %lu
[FaceAnalyzer][%@] Missing local resource %@
[FaceAnalyzer] face (center-x:%.2f, center-y:%.2f, size:%.2f) -> boundingBox (x:%.2f, y:%.2f, width:%.2f, height:%.2f)
[FaceAnalyzer] Failed to generate VNFaceObservation from face %@
[FaceAnalyzer] All faces contain valid faceprint
[FaceAnalyzer] Updating %lu faces with missing faceprint
[FaceAnalyzer] Failed to create VNImageRequestHandler for face quality analysis
[FaceAnalyzer] Faceprint VNImageRequestHandler::performRequests: %@
[FaceAnalyzer] faceprint.confidence is too low (%.3f < 0.1) %@ - junkinessIndex: %.3f
[FaceAnalyzer] Accepting faceprint with confidence: %.3f %@ - junkinessIndex: %.3f
[FaceAnalyzer] Update faceprint for face %@
[FaceAnalyzer] Unable to serialize faceTorsoprint - %@
[FaceAnalyzer] No valid faceprint from observation %@
[FaceAnalyzer] Failed to get faceprint for face %@
VCPFaceAnalyzerFillMissingFaceprint
[FaceAnalyzer][%@] No face detected; skip face quality analysis
[FaceAnalyzer][%@] No valid face observations from %lu faces; skip face quality analysis
[FaceAnalyzer] Analyzing %lu face observations for face quality
[FaceAnalyzer] Failed to set Face Quality revision (%lu) - %@
[FaceAnalyzer] Failed to perform Face Quality request - %@
[FaceAnalyzer][%@][%@] No valid Face Quality score; skipping
VCPFaceAnalyzerFaceQuality
[%@] Asset has no small video derivative; skipping
[%@] File size exceeds streaming threshold; skipping
[%@] Duration exceeds streaming threshold; skipping
Unknown VCPTaskID (%lu); redirect to VCPTaskID_MediaAnalysis
[%@] Processing image at scaled resolution (%dx%d)
[%@] Processing image at subsampled resolution (%dx%d)
[%@] Processing image at full resolution (%dx%d)
[%@] Invalid target resolution (%d)
[%@] Resource (%d) has invalid dimensions (%dx%d); falling back to asset
[%@] Asset has invalid dimensions (%dx%d)
-[PHAsset vcp_needsProcessingForTask] not implemented for %@
[%@] Montage asset detected
[%@] Text Confidence: %0.2f Passed Gating: %d
[%@] Text Confidence: 0.00f Passed Gating: 0 [Absent]
[%@] Asset scene properties unavailable or out-of-date
VCPMADVIVisualSearchTask running...
VCPMADVIVisualSearchTask image loading failed
VCPMADVIVisualSearchTask failed to create visual search query context (%@)
[VisualSearch] Using client provided OCR results
VIService_ParsedVisualSearch
VIService_VisualSearch
VCPMADVIVisualSearchTask complete (%d)
VCPVideoStabilizationAssetProcessingTask
Video Stabilization processing failed
Video caption test mode
Video caption is not enabled by defaults write
Video caption only support live photos
Video captioning model not found or user not turning on Image Descriptions in Accessibility
  [%@] Existing analysis outdated; dropping
VCPLightVideoAnalyzer
Movie analyzer perform VCPPhotosQuickFaceDetection
VCPPhotosQuickFaceDetection
VCPVideoCaptionAnalyzer
VCPVideoStabilizerPixel
VCPVideoFaceDetector
VCPFullVideoAnalyzer
VCPVideoSceneClassifier
VCPVideoActivityAnalyzer
VCPVideoSaliencyAnalyzer
VCPVideoHumanActionAnalyzer
videoCaptionAnalyzer
VCPVideoHumanActionClassifier
VCPVideoPetsAnalyzer
VCPVideoPetActionAnalyzer
VCPMovieCurationAnalyzer
VCPVideoStabilizer
VCPSettlingEffectAnalyzer
VCPVideoCNNAnalyzer
    Analyzing Video Segment - Track ID: %d Start: %lld/%d (%0.3fs) End: %lld/%d (%0.3fs)
VCPAudioAnalyzer
    Video track has invalid full frame dimensions (%.f,%.f)
    Video track has invalid clean aperture rect
VCPVideoStabilizerGyro
  [%@] Asset doesn't have gyro metadata
  [%@] Asset does not have valid video track; all %lu tracks: %@
    Video track has invalid dimensions (%.f,%.f)
VCPMovieAnalyzer
ImageHandAnalyzer: input image aspectRatio = %f
ImageHandAnalyzer: aspectRatio = %@, queryAspectRatioVal = %@
ImageHandAnalyzer: feasibleShapeIndex = %d
ImageHandAnalyzer: detectorHeight = %d, detectorWidth = %d
VCPMADServiceImageProcessingTask_Run
[MotionFlow] Failed to lock/unlock pixelbuffer (errcode: %d)
  [%@] Processing
[MediaAnalysis][%@]Unable to open movie, skip
[MediaAnalysis][%@]Failed to create asset
    Analyzing Audio Track - ID: %d Start: %lld/%d (%0.3fs) End: %lld/%d (%0.3fs)
Error resetting all FaceGroups Person Builder state: %@
Failed to clean up merge candidates. Error: %@
VCPFaceProcessingCleanupMergeCandidates
->->-> Enabling personBuilderMergeCandidates
Failed to update key faces - %@
VCPPersonBuilder_UpdateKeyface
VCPMADVIRectangleDetectionTask running...
VCPMADVIRectangleDetectionTask image loading failed
[RectangleDetection] Set VNProcessingDevice: %@ (%@)
VCPMADVIRectangleDetectionTask complete
[VCPPreAnalyzer] Failed to create VCPPoolBasedPixelBufferCreator for monochrome
 [ProbableRotation] Failed to load %@
[VCPPreAnalyzer] Failed to create VCPPoolBasedPixelBufferCreator for rotation
VCPSceneAnalyzerReleaseCachedResources
Failed to create VNClassifyImageAestheticsRequest
Failed to create VNSceneClassificationRequest
Failed to create VNCreateSceneprintRequest
Failed to create VNClassifyJunkImageRequest
Failed to create VNGenerateAttentionBasedSaliencyImageRequest
Failed to set VNClassifyImageAestheticsRequest::setRevision %lu: %@
Failed to set VNSceneClassificationRequest::setRevision %lu: %@
Failed to set VNCreateSceneprintRequest::setRevision %lu: %@
Failed to set VNGenerateAttentionBasedSaliencyImageRequest::setRevision %lu: %@
Failed to set VNClassifyJunkImageRequest::setRevision %lu: %@
Failed to set VNRecognizeObjectsRequest::setRevision %lu: %@
Failed to set VNGenerateObjectnessBasedSaliencyImageRequest::setRevision %lu: %@
Failed to set VNClassifySignificantEventRequest::setRevision %lu: %@
Failed to set VNClassifySemanticDevelopmentGatingRequest::setRevision %lu: %@
Failed to set VNClassifyCityNatureImageRequest::setRevision %lu: %@
Failed to create %@
Unsupported observation label in VCPSpecialLabelToSceneClassificationID %@
Unsupported observation label %@
[DO] detectedObjects count is 0; skip detectedObjects
[DO] invalid confidenceMax: %f; skip detectedObjects
[DO] Failed to choose the best bounding box c_max: %f, c_threshold (0.8x): %f from %@
[DO] Unsupported observation label in PFSceneTaxonomyNode %@
Unsupported observation label in PFSceneTaxonomyNode: %@
Ignoring SceneNet result for tiny image
Unsupported observation label in VCPSpecialLabelToSceneClassificationID %@ (%@)
Unnormalized saliencyRequest bounding box %@; skip
Unnormalized saliencyRequest narrowed bounding box %@; skip
Unnormalized salientObject narrowed bounding box %@; skip
Error creating VNRequest
Unknown ideal dimension for VNRequests (%@), using image dimension %dx%d
Only one VNRequest (%@) for dimension %dx%d; consider coalescing to common resolution
%dx%d
VCPSceneAnalyzerImageRequestHandlerPerformRequest
Failed to run VNImageRequestHandler::performRequests: %@
CVNLPCommSafetyHandler unavailable for IVS
CVNLPCommSafetyHandler_IVS
Failed to run CVNLPCommSafetyHandler::generateClassificationScoresForPixelBuffer:error: %@
VCPSceneAnalyzerImageBlurAnalysis
VCPSceneAnalyzerExposureAnalysis
VCPSceneAnalyzerRotationAnalysisScaling
[ProbableRotation] invalid coreML results
VCPSceneAnalyzerRotationAnalysisInference
No sceneprint data for WP analysis; return default value
VCPWallpaperAnalysis
VCPSceneAnalyzerLoadImageRequestHandler
Failed to load imageURL: %@
VCPSceneAnalyzerPerformAnalysis
VCPFaceGeometry initWithCoder - vertices data missing
VCPFaceAnchor initWithCoder - unexpected size of transform data
VCPCaptureAnalysis - missing resolution properties for prewarming
CNNFastGestureRecognition: start loading model
CNNFastGestureRecognition: inputBlob.height = %d, inputBlob.width = %d, inputBlob.channels = %d
CNNFastGestureRecognition: successfully loaded model
[MotionFlowSubtleMotionAnalyzer] Failed to request flow from VCPMotionFlowRequest: %@
Fail to initialize motionFlowAnalyzer
Motion flow is null
[VCPMediaAnalyzer] Client XPC connection interrupted
[VCPMediaAnalyzer] Client XPC connection invalidated
[VCPMediaAnalyzer] Acquiring media analysis directory sandbox extension...
[VCPMediaAnalyzer] Failed to establish connection or connection lost to service %@; %@
[VCPMediaAnalyzer] Failed to consume media analysis directory sandbox extension
[VCPMediaAnalyzer] Consumed media analysis directory sandbox extension
[MediaAnalysis] failed to get database sandbox extension
[MediaAnalysis] failed to consume sandbox extension
[MediaAnalysis] Consumed sandbox extension
[MediaAnalysis] Failed to obtain analysis sandbox extension for Photo Library (%@); client may not be able to open analysis database
[MediaAnalysis] Requested max highlight duration longer than %.2fs, fall back to %.2fs
[MediaAnalysis][%@] No valid on-demand analysis; skipping
[MediaAnalysis][%@] Storing on-demand analysis
[MediaAnalysis][%@] Failed to store on-demand analysis - %@
[MediaAnalysis][%@]Unable to open movie
[MediaAnalysis][%@] Received analysis request: %@
[MediaAnalysis][%@] Analysis served: (%@)
[MediaAnalysis] [MediaAnalyzer requestAnalysisForAsset] call from invalid instance
[MediaAnalysis] Failed to obtain database for Photo Library %@
[MediaAnalysis] Cancelling request %d
[MediaAnalysis] Failed to find request %d; cannot cancel
[MediaAnalysis] [MediaAnalyzer assetsAnalyzedSinceDate] call from invalid instance
[MediaAnalysis] Failed to obtain database for Photo Library (%@)
Cannot load %@ for %@, NSData length: %lu, content: %@
Cannot load %@ from PHAsset, NSData length: %lu, content: %@
[MediaAnalysis] [MediaAnalyzer distanceFromAsset] call from invalid instance
[MediaAnalysis] Failed to obtain database for assets
[MediaAnalysis] failed to request analyses
[MediaAnalysis] [requestAnalysesForAssets] call from invalid instance
[MediaAnalysis] [requestAnalysesForAssets] in standalone mode but on-demand not allowed
[MediaAnalysis] call from invalid instance
[MediaAnalysis] on-demand analysis requested in standalone mode
Warning: On demand analysis is not supported.
[MediaAnalysis] Failed to obtain database for collection %@
[MediaAnalysis] [requestLivePhotoEffectsForAssets] call from invalid instance
[MediaAnalysis] [requestLivePhotoEffectsForAssets] in standalone mode but on-demand not allowed
Sceneprint task failed (%@)
Error: MAD tracked taxonomy is not the latest in Photos!
Loading PFSceneTaxonomy identifier %@
Failed to initialize PFSceneTaxonomy w/identifier %@ (%@)
Error: MAD tracked taxonomy identifier %@ does not match the latest in Photos: %@!
[PFSceneTaxonomy(MediaAnalysis)] - Failed find scene name for scene id %d
[PFSceneTaxonomy(MediaAnalysis)] - Failed to find scene id for scene name %@
Video track rotation angle is not multiple of 90
Predicate requested for unsupported task (%@) & priority (%d)
Predicate requested for unsupported task (%@)
VNSession_init
CNNHandsDetector: Loading model %@
CNNHandsDetector: adopting model config: %@
CNNHandsDetectorEspresso: updating model config to %@
copyImageToBGRHandDetectorCallFromSPI
scalerHandDetectorCallFromSPI
inferenceHandDetectorCallFromSPI
CNNHandsDetector: hand class index: %d
[%@][MAMLModel] Failed to open model file at url %@
[%@][MAMLModel] Failed to load compiled model (%@): %@
[MAMLModel] Input feature %@ %ldx%ld %ld
[MAMLModel] Missing inputImage feature description %@
[MAMLModel] Mismatched inputImage width (%ld) and height (%ld)
[MAMLModel] Output feature %@ %@
[MAMLModel] Missing output feature %@
  [%@] Fingerprint requested for asset with no objectID
  [%@] Fingerprinting failed
  Fullfilled content request: %@
  Fullfilled data request: %@
Failed to query ideal dimension for request %@ due to empty supportedImageSizeSet
Failed to query ideal dimension for request %@ because the request does not conform to VNImageIdealImageSizeProviding protocol
Failed to configure %@
[DAS QoS] %@: %@ (%@) download %lu bytes
Requested resource exceeds maximum supported size
Resource already in the buffer. Skip downloading.
requestDownloadOfResource: %@
Download progress: %.2f
    Received %llu bytes (Overall: %llu/%llu)
Data received exceeds maximum supported size
Failed to download asset resource (%@)
Successfully downloaded asset resource
Failed to issue resource request
Download resource timed-out
Cancelling download
queryActionResultForPHFace : no action results
queryActionResultForPHFace : not find the best highlight
queryActionResultForPHFace : no faceprint data for face: %@
queryActionResultForPHFace : failed to get VNFaceTorsoprint %@
queryActionResultForPHFace : failed to decode torsoprintAction
queryActionResultForPHFace : failed to get compute torsoprint distance
queryActionResultForPHFace : torsoprint distance with %@, %f
queryActionResultForPHFace : failed to get torsoprints
Connecting to system photo library...
Opening system photo library...
Opened system photo library
Failed to open system photo library (%@)
Failed to obtain system photo library URL
Closed Photo Library
Photo Library unavailable (%@); closing Photo Library...
  [%@] Failed to decode last frame of video, fall back to thumbnail 
[AutoCounter] feature not supported on this OS variant
[AutoCounter] Failed to find asset for face: %@; skip
[AutoCounter] Asset without cloudIdentifier, use localIdentifier: %@
[AutoCounter] Person without localIdentifier; use face.personLocalidentifier
[AutoCounter] Face without personLocalIdentifier; skip
[AutoCounter] Fetched face/person not matching required person; skip
[AutoCounter] Face in a facegroup without localIdentifier; skip
[AutoCounter] No valid faceprint data; leave as unknown
[AutoCounter] No valid momentLocalIdentifier; leave as 'unknown'
[AutoCounter] Face without localIdentifier; skip
[AutoCounter] Failed to fetch person %@
[AutoCounter] Fail to load groundtruth file
[AutoCounter] Person (%@) already opt-in; skip
[AutoCounter] Cannot write opt-in groundtruth to %@ : %@
[AutoCounter] Export URL: %@
[AutoCounter] Failed to find facegroup for mergeCandidate: %@
[AutoCounter] Reach kVCPMaximumNumberOfMergeCandidatesShown (%lu); skip the rest
[AutoCounter][ClusterDump] FaceGroupCount %lu
[AutoCounter][ClusterDump] FaceCount %lu
[AutoCounter] Saved cluster state to %@
[AutoCounter] Cannot write to %@ : %@
[AutoCounter][P/R][GT] Fail to load groundtruth file: %@
[AutoCounter][P/R][GT] Invalid faceID for face: %@; ignore
[AutoCounter][P/R][GT] Invalid PersonID for faceID: %@; ignore
[AutoCounter][P/R][GT] Load faceID: %@ for PersonID: %@
[AutoCounter] Saved assets-to-faces details to %@
[AutoCounter] Cannot write assets-to-faces to %@ : %@
[AutoCounter][P/R] Fail to load cluster state file: %@
[AutoCounter][P/R] Cluster contains no asset information
[AutoCounter][P/R] Cluster contains no data
[AutoCounter][P/R] Invalid information for asset %@ in cluster; ignore
[AutoCounter][P/R] Invalid ID(s) in cluster: %@; ignore
[AutoCounter][P/R] Invalid face rectangle in cluster state for faceID:%@; ignore
[AutoCounter][P/R] processing cluster state faceID: %@ forPersonID: %@
[AutoCounter][P/R] Invalid ground truth rect for faceID:%@
[AutoCounter][P/R][%@] %.4f library: %@, gt: %@ (fid:%@, pid:%@)
[AutoCounter][P/R] Co-location mapping faceID:faceGroupID %@:%@ -> %@:%@
[AutoCounter][P/R] Cannot find asset for id %@
[AutoCounter][P/R] Precision for FaceGroup (of size %d) for personID %@ (of size %lu) is %f
[AutoCounter][P/R] Valid singleton count = %lu, invalid singleton count = %lu
[AutoCounter][P/R] Valid face count for person %@ is %d
[AutoCounter][P/R] personID %@ Recall (of size %lu) is %f
[AutoCounter][P/R] personID %@ Recall (exclude detection miss) (of size %lu) is %f
[AutoCounter][P/R] Weighted Precision: %f, Weighted Recall: %f (number of best face: %.0f)
[AutoCounter][P/R] Weighted Recall (exclude detection miss): %f (number of best face: %.0f)
[AutoCounter][P/R][PV] Processing person cluster %@ with %lu faces
[AutoCounter][P/R][PV] Invalid faceID in person cluster: %@; ignore
[AutoCounter][P/R][PV] Failed to fetch asset for face %@; ignore
[AutoCounter][P/R][PV] Asset without cloudIdentifier, use localIdentifier: %@
[AutoCounter][P/R][PV] Invalid face rectangle in person cluster state for face: %@; ignore
[AutoCounter][P/R][PV] processing person cluster faceID: %@ for PersonID: %@ and clusterID: %@
[AutoCounter][P/R][PV] Valid faceID mapping faceID:personID %@:%@ -> %@:%@
[AutoCounter][P/R][PV] Invalid faceID mapping faceID:faceGroupID %@:%@ -> %@:%@
[AutoCounter][P/R][PV] Invalid ground truth face rectangle for faceID:%@
[AutoCounter][P/R][PV] Valid co-locate mapping faceID:personID %@:%@ -> %@:%@
[AutoCounter][P/R][PV] Invalid co-location mapping faceID:faceGroupID %@:%@ -> %@:%@
[AutoCounter][P/R][PV] Precision for cluster (of size %d) for personID %@ (of size %lu) is %f
[AutoCounter][P/R][PV] Valid singleton count = %lu, invalid singleton count = %lu
[AutoCounter][P/R][PV] Recall for personID %@ (of size %lu) is %f
[AutoCounter][P/R][PV] Weighted Precision: %f, Weighted Recall: %f
[AutoCounter][CA] Report CoreAnalytics: %@
[AutoCounter][CA] Failed to retrive CoreAnalytics export URL
[AutoCounter][CA] Saved CoreAnalytics to %@
[AutoCounter][CA] Cannot write CoreAnalytics to %@ - %@
[AutoCounter][CA] Cannot retrieve CoreAnalytics files %@
[AutoCounter][CA] Files in folder %@
[AutoCounter][CA] Report CoreAnalytics files: %@
[AutoCounter][CA] Report CoreAnalytics file: %@
[AutoCounter][CA] Finished reporting CoreAnalytics %@
[AutoCounter][P/R] Failed to measure Vision cluster state against ground truth
[AutoCounter][P/R][PV] Failed to measure Person cluster state against ground truth
[AutoCounter][P/R][PV] Failed to report CoreAnalytics
[AutoCounter][P/R][SIMLGT] Failed to load SIML ground truth - %@
[AutoCounter][P/R][SIMLGT] Failed to serialize SIML ground truth - %@
[AutoCounter][P/R][SIMLGT] Load faceID: %@ for PersonID: %@
[AutoCounter][P/R][SIML] Failed to export current clusters states
[AutoCounter][P/R][SIML] Validate cluster state  %@ against ground truth %@
[AutoCounter][P/R][SIML] Failed to measure Vision cluster state against SIML ground truth
VCPMADVIUserFeedbackTask running...
VCPMADVIUserFeedbackTask image loading failed
VIService_UserFeedback
VCPMADVIUserFeedbackTask complete (%d)
[MediaAnalysis] [VCPVideoMetaAnalyzer] Unknown analysis type %@
Image Action classifier - merged actions for face  %@
Image Action classifier - torso or face not detected %@
Image Action classifier - PHFace gated out by age attribute
Image Action classifier - action class %d with confidence %f
Unknown device type; this may adversely impact capabilities & performance
VCPPriorityAnalysis - Start initializing
VCPPriorityAnalysis - Finished initializing hand detector
VCPPriorityAnalysis - Finished initializing hand keypoint detector
VCPPriorityAnalysis - Finished initializing gesture recognizer
VCPPriorityAnalysis - Number of hand detected %lu
VCPPriorityAnalysis - dominant hand: %d, hand chirality counter: left: %d, right: %d
VCPPriorityAnalysis - frame interval %f ms
VCPPriorityAnalysis - gestureScoreRightHand %f, gestureScoreLeftHand %f
VCPPriorityAnalysis - gesture score = %f, priority score after thresholding = %f
VCPPriorityAnalysis - Analysis subsampling ratio = %f
VCPPriorityAnalysis - Face yaw: %d
VCPPriorityAnalysis - output priority score = %f
VCPLandmarkValidator failed to validate image (%d)
[ImageManager] kCVPixelFormatType_32BGRA with kCGColorSpaceModelMonochrome, replace with DeviceRGB
[Decode] Downscaling %zux%zu --> %zux%zu
[Decode] %.0fx%.0f --> %zu; subsampling %dx on decode
[Decode] Failed to create CVPixelBuffer from IOSurface; falling back to rendering path
[Decode] Failed to obtain IOSurface; falling back to rendering path
[Decode] Accelerated decode failed; falling back to CGImage
Failed to load url %@ (%@)
[ImageManagerEncode] inputCVPixelBuffer cannot be NULL
[ImageManagerEncode] outputJPEGData cannot be nil
[ImageManagerEncode] targetBitStreamLength cannot be 0
[ImageManagerEncode] Encoding CVPixelBuffer -> JPEG (%lu Bytes)
[ImageManagerEncode] Failed to create compression session
[ImageManagerEncode] Fail to open compression container
[ImageManagerEncode] Fail to image buffer
[ImageManagerEncode] Fail to get transcoded data
[ImageManagerEncode] Oversized data (%luBytes)
[ImageManagerEncode] Padding JPEG with %lu Bytes
[ImageManagerEncode] Exporting reencoded JPEGs
VCPHandPoseImageRequest options: _revision = %d
copyImageToBGRHandKeypointCallFromSPI
preProcessingHandKeypointCallFromSPI
Action classifier - empty torso bound in PHFace %@
Action classifier - found torso bound in PHFace %@
[PreAnalysis] Pre-warmed image unused (%dx%d)
[PreAnalysis] Image not pre-warmed; creating on-demand (%dx%d)
%@ canceled (%@)
%@ failed (%@)
HomeKit analysis client XPC connection interrupted
HomeKit analysis client XPC connection invalidated
[HomeKitAnalysis] Error connecting to background analysis service
[HomeKitAnalysis] Request %d is %.2f%% complete
[HomeKitAnalysis] Unknown analysis request %d; dropping cancellation request
[HomeKitAnalysis] No active analysis requests; dropping cancellation request
[VCPFaceMerger] Failed to align face observation - %@
[VCPFaceMerger] Missing face for observation %@ from mapping
[VCPFaceMerger] Bounding box aligner returned an empty rectange
[VCPFaceMerger] Cannot merge face (v%lu, type-%d) with face %@ (v%lu, type-%d, %s imageprint)
[VCPFaceMerger] Cannot merge face with face %@ - distance %f > threashold %f
[VCPFaceMerger] Cannot merge face with face %@ - distance calculation failed %@
[VCPFaceMerger] Cannot Merge in final stage: [mutableDetectedFaces containsObject:detectedFace] %@ [facesToDelete containsObject:matchedExistingFace] %@ 
invalid buffer size %dx%d or pixel format %u
[VCPFaceClusterer] Failed to restore clusterer (state unknown) - %@
[VCPFaceClusterer] Restored Face Clusterer with ClusterState = %ld
Reset restore clusterer error (ClusterState = %ld): %@
Reset restored clusterer, ClusterState = %ld
Person Processing: Starting Reset Face Clustering
VCPFaceProcessingResetFaceClusteringState
Person Processing: Reset Face Clustering Done
Person Processing: Starting Face Clustering
VCPFaceProcessingPerformFaceClusteringAndWait
Person Processing: Face Clustering Done
---> Start face clustering (%ld) with clustering status: %@
---> Finished face clustering (%ld) with clustering status: %@
VCPFaceProcessingClusterFaces
---> Start face clustering as need (%ld) with clustering status: %@
VCPFaceProcessingClusterFacesIfNecessary
  Analyzing degraded version of Movie
Video caption not enabled by defaults write
Image caption test model not exist at %@, not generating image caption
Image captioning model not found or user not turning on Image Descriptions in Accessibility
  [%@] missing Pre Analysis result
  Analyzing degraded version of Photo
VCPImageFaceDetector
VCPImageFaceExpressionAnalyzer
Failed to create CVNLPCaptionHandlerRef (%@)
VCPImageJunkAnalyzer
VCPImageBlurAnalyzer
VCPLowResImageBlurAnalyzer
VCPImageExposureAnalyzer
VCPImageLivePhotoBlurAnalyzer
VCPImageCompositionAnalyzer
VCPImageDescriptor
VCPImageSaliencyAnalyzer
VCPImagePetsAnalyzer
VCPImagePetKeypointsAnalyzer
VCPImageHumanPoseAnalyzer
Human action on Live Photo requires paired movie, skip analyzing still
VCPImageHumanActionAnalyzer
VCPImageHandsAnalyzer
VCPLivePhotoAnalysis
Live Photo w/o local movie resource and streaming not allowed, skip paired movie analysis
VCPEffectsAnalyzer
[MediaAnalysis] PhotoAnalyzer - Original movie is not available, skip effects analysis
VCPParallaxAnalyzer
VCPFaceQualityAnalysis
VCPLivePhotoKeyFrameAnalyzer
VCPPhotoAnalyzer
VCPEmbeddingAnalyzerLoadImageRequestHandler
VCPNeuralHashprintRequest
NeuralHashprint Vision request failed: %lu - %@
VCPImageHashSignatureRequest
NeuralHash+LSH Vision request failed: %lu - %@
NeuralHash+LSH invalid imageSignatureHash
NeuralHash+LSH failed to encode hash: %@
Invalid NeuralHash+LSH (=)
Cannot create VCPPersonBuilder
---> Canceling VCPBuildPersons
VCPBuildPersons canceled
VCPBuildPersons failed: %@
Cannot create PVPersonPromoter
---> Canceling VCPPromotePersons
Person Processing: Starting Person Promoting
VCPFaceProcessingPromotePersonsCoreAnalyticsCollection
Person Processing: Person Promoting %@
VCPPromotePersons canceled
VCPPromotePersons failed
Cannot create PVPersonPromoter for evaluation
---> Canceling VCPFetchPersonPromoterClusterForEvaluation
Person Processing: Start evaluatePersonPromoterWithUpdateBlock
Person Processing: Retrieved %lu unverified person
Person Processing: evaluatePersonPromoterWithUpdateBlock canceled
Unknown Photos Face Processing umbrella version %d
[Perf] %s: %0.6fs
%-40s  %10s  %10s  %10s  %10s  %10s
  %-38s  %10.6f  %10.6f  %10.6f  %10.6f  %10zu
[CoreAnalyticManager] Session event name is nil; skipping
[CoreAnalyticManager] Session fields name is nil for event %@; skipping
[CoreAnalyticManager] Start session event %@ (total session count %lu)
[CoreAnalyticManager] Ignore 0-accumulation for event %@ field %@
[CoreAnalyticManager] Session event %@ not available
[CoreAnalyticManager] Session event %@ not available; skip sending
[CoreAnalyticManager] flushing analytics ... 
[CoreAnalyticManager] flushSessionAnalytics (total count %lu)
Failed to analyzeDetectedFaces - %@
song analysis failed %@
  [%@] Need Face Processing: no faceAdjustmentVersion
  [%@] Need Face Processing: faceAdjustmentVersion %@ != adjustmentTimestamp %@
Attempt to download resource: %@
[%@] Download progress: %.2f
Download resource timed-out (ID:%d)
Cancelling download (ID:%d)
[FileBasedDownload] Downloaded resource to file url: %@
[FileBasedDownload] Failed to download asset resource (%@)
[FileBasedDownload] Successfully downloaded asset resource
[FileBasedDownload] Failed to issue resource request
[FileBasedDownload][%@] Downloading %@
VCPDownloadResource
[FileBasedDownload][%@] Progress: %.2f
[FileBasedDownload][%@] URL: %@
[FileBasedDownload][%@] Failed on resource %@ - %@
[FileBasedDownload][%@] Success!
[FileBasedDownload][%@] Failed to issue resource request
Wrong outHeight in parseHeatmap2Keypoints
Wrong outWidth in parseHeatmap2Keypoints
[ResourceManager] Invalid cost detected (%ld); clipped to %ld
[ResourceManager] Updating budget (%ld --> %ld)
[ResourceManager] Hit usage timeout; purging resources
[ResourceManager] Request to reserve budget [Budget: %ld][Target: %ld]
[ResourceManager] Pruning inactive resources
[ResourceManager] Purging inactive resource (%@)
[ResourceManager] Failed to reserve budget [Budget: %ld][Target: %ld]
[ResourceManager] Request to activate %@
[ResourceManager] Resource not cached (%@)
[ResourceManager] Resource cached but not active (%@)
[ResourceManager] Activating resource (%@)
[ResourceManager] Resource cached and active (%@)
[ResourceManager] Active resource cost has increased (%@)
[ResourceManager] Active resources exceed budget
[ResourceManager] Active count %d
[ResourceManager] Request to deactivate %@
[ResourceManager] Resource transition active --> inactive (%@)
[ResourceManager] Received request to deactivate un-tracked resource (%@)
[ResourceManager] Request to purge inactive resources
[ResourceManager] Skipping active resource (%@)
[ResourceManager] Purging %@
[ResourceManager] Purging active resource (%@)
[ResourceManager] Request to purge all resources
Requested unavailable frame %d (Frame Count: %d  Buffer Depth: %d)
Unexpected media type (%lu)
[%@] Unexpected media type (%d)
[MotionFlowAnalyzer] Failed to request flow from VCPMotionFlowRequest: %@
Gyro analytics stored via dodML
Could not load MonzaV4_1.mlmodelc in the bundle resource
softlink:r:path:/System/Library/PrivateFrameworks/PhotoVision.framework/PhotoVision
softlink:r:path:/System/Library/PrivateFrameworks/HomeAI.framework/HomeAI
softlink:r:path:/System/Library/PrivateFrameworks/HomeAI.framework/HomeAI
softlink:r:path:/System/Library/PrivateFrameworks/PhotosGraph.framework/PhotosGraph
softlink:r:path:/System/Library/PrivateFrameworks/PhotoVision.framework/PhotoVision
softlink:r:path:/System/Library/PrivateFrameworks/PhotoVision.framework/PhotoVision
softlink:r:path:/System/Library/PrivateFrameworks/HomeAI.framework/HomeAI
softlink:r:path:/System/Library/PrivateFrameworks/PhotoVision.framework/PhotoVision
softlink:r:path:/System/Library/Frameworks/ShazamKit.framework/ShazamKit
VCPProtoMovieLaughterResult
NSCopying
VCPPetsRegion
VCPVideoPetsAnalyzer
VCPSettlingEffectAnalyzer
PVPhotoLibraryProtocol
NSObject
LegacyConversion
VCPProtoResultLegacyConversionProtocol
VCPInternetReachability
VCPVideoCNNAnalyzer
VCPProtoMovieSceneResult
VCPMAMLFeatureProvider
MLFeatureProvider
VCPVoiceDetector
VCPProtoMovieAudioQualityResult
PHAssetResource
VCPFullVideoAnalyzer
VCPProtoMovieFineSubjectMotionResult
BackwardCompatability
VCPVideoFullFaceDetector
CMTimeRange
VCPHomeFaceIdentificationTask
VCPMADTaskProtocol
VCPFingerprint
VCPCNNHandKeypointsDetectorEspresso
VCPImageExposurePreAnalyzer
VCPImageDescriptor
VCPDistanceDescriptorProtocol
VCPProtoLivePhotoKeyFrameResult
VCPCNNDataGPU
VCPVideoMetaFaceAnalyzer
VCPProtoKeypoint
PVFaceProtocol
VCPSuggestionRequest
VCPClusterer
PVFaceClusteringProtocol
VCPHumanPoseImageRequest
VCPVideoCNNTask
VCPProtoMovieHighlightScoreResult
VCPMADVIRemoveBackgroundCachedImageHandler
VCPMADVIRemoveBackgroundResource
VCPMADVIRemoveBackgroundTask
VCPMADServiceImageProcessingSubtaskProtocol
VCPVideoProcessorNode
VCPImageConverter
VCPFullAnalysisAssetProcessingTask
VCPMediaAnalysisServerProtocol
VCPMediaAnalysisClientProtocol
VCPMediaAnalysisService
FaceSuggestions
PersonBuilderAndPromoter
InternalTools
Hubble
VCPVideoCaptionEncoder
VCPHumanPoseEspressoSession
CMTime
VCPCNNPetsDetector
VCPMADImageSafetyClassificationResource
VCPMADImageSafetyClassificationTask
VCPCNNSmileDetector
VCPPhotosFace
PFPhotosFaceRepresentation
VCPCNNEspressoContext
VCPProtoMoviePetsFaceResult
VCPCNNPoseEstimatorEspresso
VCPVideoCNNQuality
VCPSegment
VCPClassification
VCPVideoSceneClassifier
VCPProtoImageFeatureResult
VCPTimer
VCPProtoImageHumanPoseResult
VCPProtoMovieQualityResult
VCPPhotosFaceProcessingContext
VCPFaceUtils
VCPProtoImageSceneprintResult
VCPProtoMovieSubtleMotionResult
VCPProtoMovieHumanActionResult
CGRect
VCPVideoPixelStabilizer
VCPContentAnalysis
VCPLightMotionAnalyzer
VCPLoaned
VCPObjectPool
VCPCNNFullConnectionBlockScalar
VCPProtoMovieSaliencyResult
VCPPreAnalysisRequests
VCPProtoImageFaceResult
VCPJunkAnalyzer
VCPVideoMetaMotionAnalyzer
VCPVideoMetaMotionSegment
VCPMADVIResource
VCPProtoVideoKeyFrame
VCPMediaAnalysis
VCPCNNModelEspresso
VCPWallpaperAnalyzer
MercuryBase64
VCPCNNPoolingBlockGPU
VCPClientDatabaseManager
VCPEdgeDetector
VCPVideoCaptionAnalyzer
VCPVideoTrackSyncDecoder
VCPProtoMovieClassificationResult
VCPVNImageprintWrapper
VCPVideoKeyFrameAnalyzer
VCPMetaSegment
VCPSharedInstanceManager
VCPMetaTrackDecoder
VCPAnalysisProgressQuery
VCPCNNConvBlockVector
VCPSaliencyRegion
VCPVideoSaliencyAnalyzer
VCPHandPoseVideoRequest
VCPMoFlowSingleEspresso
VCPImageQualityAnalyzer
VCPMADEmbeddingGenerationTask
VCPVideoProcessorSession
VCPProtoImageBlurResult
VCPFaceIDModel
VCPVanishingPointDetector
VCPVideoHumanActionClassifier
VCPImageSaliencyAnalyzer
MediaAnalysis
VCPMovieCurationAnalyzer
VCPMovieHighlight
VCPModelR2D2
PVAssetProtocol
VCPProtoMovieUtteranceResult
VCPProtoImageSaliencyResult
VCPMotionFlowRequest
VCPImageCompositionAnalyzer
VCPFaceProcessingVersionManager
VCPLightVideoAnalyzer
VCPVideoKeyFrame
VCPSceneprintDescriptor
VCPProtoImageShotTypeResult
VCPProtoImagePetsFaceResult
VCPImagePetsAnalyzer
VCPVideoFacePoseFilter
VCPCNNFullConnectionBlockGPU
PVPersonProtocol
VCPProtoBounds
VCPFace
VCPFaceDetectionRange
VCPFaceShapeModel
VCPCNNFaceLandmarkDetectorEspresso
VCPMADVITextLookupTask
VCPProtoImageCompositionResult
VCPImageFaceDetector
VCPMADResource
VCPCNNSmileDetectorEspresso
VCPVideoCNNHighlight
VCPRealTimeAnalysisServerProtocol
VCPRealTimeAnalysisClientProtocol
VCPRealTimeAnalysisService
MADActivitySchedulingRecord
CGPoint
VCPVideoPersonDetector
VCPProtoLivePhotoFrameInstruction
VCPFaceTensorModel
VCPProcessingStatusEntry
VCPProtoLivePhotoVariationParams
VCPImagePetsKeypointsAnalyzer
VCPVideoActivityAnalyzer
VCPCompactResult
VCPVideoGlobalAnalyzer
VCPCNNPoolingBlock
VCPProtoMovieHumanPoseResult
VCPExpressionSegment
VCPMovieHighlightAnalyzer
VCPHomeKitAnalysisSessionServerProtocol
VCPHomeKitAnalysisSessionClientProtocol
VCPHomeKitAnalysisSession
VCPHomeKitSessionExportedObject
VCPDatabaseReader
VCPProtoTime
VCPURLAsset
Image
LivePhoto
Movie
VCPExifAnalyzer
VCPHomeResidentMaintenanceTask
VCPMADServiceImageProcessingTaskBatch
VCPVideoCNNBackbone
VCPLoudnessAnalyzer
VCPProtoMovieActivityLevelResult
VCPColorNormalizationAnalyzer
VCPFaceCropUtils
VCPPhotosQuickFaceDetectionManager
VisualSearch
VCPMADMachineReadableCodeResource
VCPMADVIMachineReadableCodeDetectionTask
VCPHuman
VCPFlowDecoder
VCPProtoMovieInterestingnessResult
VCPLandmarkValidator
VCPVideoStabilizer
VCPPhotosPersistenceDelegateAdditions
VCPMergeCandidatePair
VCPPhotosPersistenceDelegate
PVPersonPromoterDelegate
VCPProtoImageExposureResult
VCPProtoMovieFeatureResult
VCPPhotosAsset
VCPMADVIDocumentRecognitionResource
VCPMADVIDocumentRecognitionTask
VCPMADPersonIdentificationTaskResource
VCPMADPersonIdentificationTask
VCPBlurAnalyzer
VCPHumanPoseVideoRequest
VCPImageBlurAnalyzer
VCPFlowFeatureExtractor
VCPImageExposureAnalyzer
VCPProtoAssetAnalysis
VCPMADServiceImagePixelBufferAsset
VCPMADServiceImageURLAsset
VCPMADServiceImageDataAsset
VCPMADServiceImagePhotosAsset
VCPMADServiceImageAsset
VCPCNNFaceLandmarkDetectorMPS
VCPVideoObjectTracker
VCPFaceCropManager
VCPPhotosQuickFaceIdentificationManager
VCPCNNBlurAnalyzerEspresso
VCPVideMetaOrientationAnalyzer
VCPFaceProcessingServiceWorker
VCPVideoTrackSubsamplingDecoder
VCPFrameAnalysisStats
VCPVideoCNNAutoplay
VCPVideoPetsActionAnalyzer
VCPVideoKeyFrameResult
VCPMovieHighlightResult
VCPMovieCurationResults
VCPVideoTrackDecoder
VCPFaceCrop
VCPCoreMLRequest
VCPFrameScoreFilter
VCPProtoMovieBabbleResult
VCPMADVIVisualSearchGatingTask
VCPEspressoModel
VCPFaceAnalyzer
MovieResource
VCPSoundDetector
SNResultsObserving
VCPSoundClassifier
VCPAudioClassifier
VCPProtoMovieFaceprintResult
VCPCNNBlock
MediaAnalysisPhoto
MediaAnalysisMovie
MediaAnalysisSceneProcessing
MediaAnalysisOCRProcessing
MediaAnalysisVisualSearchProcessing
VCPMADVIVisualSearchTask
VCPGeometryUtils
VCPProtoMovieCheeringResult
VCPProtoMovieMusicResult
VCPCNNFaceLandmarkDetector
VCPCNNSmileDetectorMPS
VCPCNNConvBlockGPU
VCPVideoProcessor
VCPProtoMovieStabilizationResult
VCPProtoMovieHighlightResult
VCPCNNFullConnectionBlock
VCPHomeKitMotionAnalyzer
VCPProtoMovieSceneprintResult
CMTimerange
VCPSlowmo
VCPProtoMovieSubjectMotionResult
VCPBoundingBox
VCPCNNPoseEstimator
VCPVideoStabilizationAssetProcessingTask
VCPMovieAnalyzer
VCPImageHandsAnalyzer
VCPProtoMovieObstructionResult
VCPMADServiceImageProcessingTask
VCPProtoLivePhotoEffectsResult
VCPCNNBlurAnalyzer
VCPProtoLivePhotoRecommendationResult
VCPDatabaseBatchIterator
PVFetchResultProtocol
NSFastEnumeration
VCPProtoTimeRange
VCPImageLivePhotoBlurAnalyzer
VCPFullAnalysisURLProcessingTask
PVFaceGroupProtocol
VCPProtoLivePhotoEffectsRecipe
VCPProtoLivePhotoHumanActionClassificationResult
VCPAudioAnalyzer
VCPCNNGazeAnalysis
VCPPersonBuilder
VCPImageHumanPoseAnalyzerTopDown
VCPProtoMoviePreEncodeResult
VCPMADVIRectangleDetectionResource
VCPMADVIRectangleDetectionTask
VCPPreAnalyzer
VCPVideoTrackStandardDecoder
VCPCNNPersonKeypointsDetector
VCPFaceGeometry
NSSecureCoding
NSCoding
VCPFaceAnchor
VCPCaptureAnalysisSession
VCPCNNPetsDetectorEspresso
VCPCNNFastGestureRecognition
VCPMotionFlowSubtleMotionAnalyzer
VCPEffectsAnalyzer
VCPVideoFaceDetector
VCPGaborFilter
VCPCancelToken
VCPStorageServiceProtocol
VCPMediaAnalyzer
VCPPhotosSceneprintAssetProcessingTask
PVMomentProtocol
VCPImageAnalyzer
VCPVideoMetaLensSwitchAnalyzer
VCPVideoMetaLivePhotoMetaAnalyzer
VCPCNNData
VCPHoughTransform
VCPRTLandmarkDetector
VCPCNNConvBlock
VCPCNNConvBlockScalar
VCPProtoImagePetsResult
VCPMADVisionResource
VCPCNNHandsDetector
VCPMAMLModel
VCPCNNPoolingBlockVector
VCPRequest
VCPProtoClassification
VCPInMemoryAVAsset
AVAssetResourceLoaderDelegate
VCPProtoMovieFaceResult
VCPProtoLivePhotoKeyFrameStillResult
VCPDownloadManager
VCPTransforms
VCPActionAnalyzer
MediaAnalysisResults
MediaAnalysisPauseResume
VCPImageMotionFlowAnalyzer
VCPDefaultPhotoLibraryManager
PHPhotoLibraryAvailabilityObserver
VCPInterAssetAnalyzer
VCPClusteringAccuracyMeasures
VCPPhotosAutoCounterWorker
VCPProtoPoint
Exif
VCPImageSaliencyAnalyzerFull
VCPMADVIUserFeedbackTask
VCPMADVIVisualSearchResource
VCPVideoMetaAnalyzer
VCPKeypoint
VCPPersonObservation
VCPHandObservation
VCPMotionFlowObservation
VCPImageHumanActionAnalyzer
VCPProtoMovieApplauseResult
VCPPriorityAnalysis
VCPVideoFaceMeshAnalyzer
bRVA
VCPImageManager
VCPHandPoseImageRequest
VCPCNNHandKeypointsDetector
VCPVoiceDetectorV2
VCPCNNPoseEstimatorMPS
VCPProtoImageJunkResult
VCPProtoMovieCameraMotionResult
VCPVideoCNNActionClassifier
VCPImageSaliencyAnalyzerFullEspresso
VCPCNNFlattenBlock
VCPVideoMetaFocusAnalyzer
VCPVideoMetaFocusSegment
VCPProtoMovieLoudnessResult
VCPPreAnalysisImageEntry
VCPPreAnalysisImage
VCPMABaseTask
VCPHomeKitAnalysisServerProtocol
VCPHomeKitAnalysisClientProtocol
VCPHomeKitAnalysisService
Client
Resident
VCPPhotosFacePair
VCPFaceMerger
VCPLivePhotoKeyFrameAnalyzer
VCPCNNPersonDetector
VCPPoolBasedPixelBufferCreator
VCPParallaxAnalyzer
VCPImageFaceExpressionAnalyzer
VCPTimeMeasurement
VCPImageHumanPoseAnalyzer
VCPFaceClusterer
VCPBackwarp
VCPLogManager
VCPProtoMovieSummaryResult
VCPPreAnalysisImageLoader
VCPProtoMovieVoiceResult
VCPCNNMetalContext
VCPCNNBlurAnalyzerMPS
VCPPhotoAnalyzer
VCPMAEmbeddingAnalyzer
VCPTrimAnalyzer
VCPSceneChangeAnalyzer
VCPSceneChangeSegment
VCPMADCoreAnalyticsManager
VCPProtoMovieOrientationResult
VCPSceneProcessingImageManager
VCPImageFaceQualityAnalyzer
VCPVideoLightFaceDetector
VCPProtoMoviePetsResult
VCPVideoAnalyzer
VCPPnPSolver
VCPSongDetector
VCPProtoLivePhotoKeyFrameFaceResult
VCPCorrelation
VCPVideoHumanActionAnalyzer
VCPAsset
VCPPHFaces
VCPProtoLine
VCPProtoMovieStabilizationRecipe
VCPCNNPetsKeypointsDetector
VCPVideoFacePoseAnalyzer
VCPVideoCNNCameraMotion
VCPVideoActivityDescriptor
VCPCNNModel
VCPMADResourceLock
VCPMADResourceEntry
VCPMADResourceManager
VCPProtoMovieMovingObjectResult
VCPDeviceInformation
VCPCNNPoolingBlockScalar
FullAnalysis
VCPMotionFlowAnalyzer
VCPProtoLivePhotoSharpnessResult
VCPVideoGyroStabilizer
MonzaV4_1Input
MonzaV4_1Output
MonzaV4_1
VCPCtrTracker
VCPBaseTracker
distantPast
parseFlowCacheVersion
documentElements
fetchAssetsForFaceGroups:options:
setExportedInterface:
typeWithIdentifier:
resume
setExportedObject:
fetchAssetsForFaces:options:
initWithBase64EncodedString:options:
sharedPhotoLibrary
fetchAssetsForPersons:options:
getLocalUrl
addInvalidMergeCandidatePersons:
domain
returnMask
quadratureTolerance
assetId
uiScale
fetchAssetsGroupedByFaceUUIDForFaces:
conversationIdentifier
assetImageGeneratorWithAsset:
livelyColorScore
domainInfo
sharplyFocusedSubjectScore
initWithBytesNoCopy:length:deallocator:
fetchAssetsInAssetCollection:options:
unarchivedObjectOfClass:fromData:error:
reverseObjectEnumerator
initWithCGImage:options:session:
domainKey
unarchivedObjectOfClasses:fromData:error:
qualityMeasureForFace:countOfFacesOnAsset:
fetchAssetsMatchingAdjustedFingerPrint:photoLibrary:
initWithCMSampleBuffer:orientation:options:
domains
assetLocalIdentifier
shortDescription
fetchAssetsMatchingMasterFingerPrint:photoLibrary:
setPerformInPlace:
fetchAssetsWithCloudIdentifiers:options:
parseWithVisualQuery:cachedResults:completion:
initWithCVPixelBuffer:options:
doubleValue
path
fetchAssetsWithLocalIdentifiers:options:
initWithCVPixelBuffer:options:session:
pathExtension
fetchAssetsWithMediaType:options:
uniformTypeIdentifier
setPersonBuilderState:
initWithCVPixelBuffer:orientation:options:session:
assetReaderOutputMetadataAdaptorWithAssetReaderTrackOutput:
fetchAssetsWithOptions:
setFace:
setPersonContext:
pathForResource:ofType:
initWithCapacity:
signalCancellation
assetReaderSampleReferenceOutputWithTrack:
setFaceAdjustmentVersion:
fetchAssociatedPersonsGroupedByFaceGroupLocalIdentifierForFaceGroups:options:
payload
addMergeCandidatePersons:
getResourceValue:forKey:error:
assetReaderTrackOutputWithTrack:outputSettings:
unionSet:
setFaceAlgorithmVersion:
initWithType:
fetchEmptyFaceGroupsWithOptions:
setPersonId:
assetReaderWithAsset:error:
initWithClassifierIdentifier:error:
initWithType:cachePath:state:threshold:requestRevision:
unlock
assetResourcesForAsset:
sizeValue
initWithType:cachePath:state:threshold:torsoThreshold:requestRevision:torsoprintRequestRevision:
performCancellableChangesAndWait:error:
fetchFaceCropByFaceLocalIdentifierForFaces:fetchOptions:
unregisterAvailabilityObserver:
assetResourcesForAsset:includeDerivatives:
initWithCommonFormat:sampleRate:channels:interleaved:
unsignedIntValue
performChanges:completionHandler:
fetchFaceCropsNeedingFaceDetectionWithOptions:
VN4UfLbvVUqMvYV8bbGFQcxg5yRLm8ekI1
convertToOriginalTimeFromScaledTime:forExport:
elementCount
performChangesAndWait:error:
unsignedIntegerValue
fetchFaceCropsWithLocalIdentifiers:options:
setPhotoLibrary:
getTranscript
initWithConfiguration:
coordinate
slowMotionRampInRangeForExport:
elementType
fetchFaceGroupsForPerson:options:
performInPlace
setFaceExpressionType:
copy
unsignedLongValue
slowMotionRampOutRangeForExport:
initWithContentsOfFile:
fetchFaceGroupsGroupedByFaceLocalIdentifierForFaces:options:
VNpLorzxnyAlLcPFNcKhgoNCmy9b5BRWyk
glassesCategory
slowMotionRate
initWithContentsOfURL:
fetchFaceGroupsWithFace:options:
loadValuesAsynchronouslyForKeys:completionHandler:
slowMotionTimeRange
salientObjects
fetchFaceGroupsWithOptions:
performRequests:error:
initWithUUIDBytes:
copyCGImageAtTime:actualTime:error:
assetWithURL:
initWithUUIDString:
queryID
saveAndReturnCurrentModelState:
globalSession
queryMetaDataSync
setPrecisionRecallThreshold:
setPredicate:
localIdentifierWithUUID:
fetchFaces
glyphName
smilingCategory
initWithData:encoding:
associateFaceWithPersonUUID:
fetchFacesForFaceCrop:options:
initWithVideoAsset:videoAdjustments:
setPreferBackgroundProcessing:
localizedDescription
initWithData:options:
gpsHorizontalAccuracy
encodeHashDescriptorWithBase64EncodingAndReturnError:
fetchFacesForPerson:options:
setFaceTorsoprint:
setProcessed:forLibrary:
encodeObject:forKey:
socialGroupsOverTheYearsWithPersonClusterManager:forPersons:updateBlock:
localizedStringFromDate:dateStyle:timeStyle:
initWithData:orientation:options:
fetchFacesGroupedByAssetLocalIdentifierForAssets:options:
setFaceprint:
persistentDomainForName:
setProcessingDevice:
fetchFacesInAsset:options:
lock
sortDescriptorWithKey:ascending:
attachProgressCallBack:
copyItemAtURL:toURL:error:
fetchFacesInFaceGroup:options:
JSONObjectWithData:options:error:
queryTerm
sortUsingComparator:
initWithDevice:filterDescriptor:
encodeToCommandBuffer:sourceTexture:destinationTexture:
fetchFacesOnAssetWithFace:options:
queryWithPixelBuffer:orientation:imageRegions:textBlockAnnotation:queryContext:payload:
attributes
sortedArrayUsingComparator:
encodeToCommandBuffer:sourceTextureArray:guidanceTexture:constraintsTextureArray:numberOfIterations:destinationTextureArray:
setPruneAfterAvailableOnLowDisk:
initWithDictionary:
fetchFacesWithLocalIdentifiers:options:
queryWithPixelBuffer:orientation:normalizedRegionOfInterest:annotation:queryContext:
setQuadratureTolerance:
encodedData
attributesOfItemAtPath:error:
initWithDomain:knowledgeGraphID:title:thumbnailURL:thumbnailAspectRatio:shortDescription:detailedDescription:webURL:knowledgeProperties:
sortedArrayUsingSelector:
fetchFacesWithOptions:
setFetchLimit:
initWithDomain:label:glyphName:hasFocalPoint:focalPoint:displayLabel:displayMessage:
scaleTimeRange:toDuration:
sortedViableMergeCandidateFacesFor:from:ignoreSourceAssetDimensions:matchScores:
fetchInvalidMergeCandidatePersonsForPerson:options:
setFetchPropertySets:
hairColorCategory
longLongValue
quickClassificationFaceAdjustmentVersion
scaledTimeForOriginalTime:
endEncoding
fetchKeyFaceForFaceGroup:options:
longValue
raise
sceneAnalysisProperties
fetchKeyFaceForPerson:options:
inputDescriptionsByName
initWithFaceAnnotations:humanAnnotations:nsfwAnnotations:textBlockAnnotation:scenenetAnnotation:barcodeAnnotation:
rampDown
sceneAnalysisTimestamp
fetchMergeCandidatePersonsForPerson:options:
inputFaceObservations
lookupTextWithQuery:completion:
rampUp
entityPredictionsForObservation:limit:canceller:error:
countForObject:
sceneAnalysisVersion
fetchMomentUUIDByAssetUUIDForAssets:options:
setForceFaceprintCreation:
rangeOfCharacterFromSet:options:
setReadOnly:
entityUniqueIdentifier
sceneClassId
fetchMomentsForAssetsWithLocalIdentifiers:options:
ratioOfAssetsWithFacesProcessed
spaceCheck:
sceneClassifications
availableMetadataFormats
fetchMomentsWithOptions:
setRecognitionLanguages:
initWithFaceObservations:
fetchOptionsWithInclusiveDefaultsForPhotoLibrary:
insertObject:atIndex:
setFrameLength:
sceneIdentifier
setRecognize:
updateModelByAddingPersons:withGroupingIdentifiers:andRemovingPersons:canceller:error:
insertTimeRange:ofAsset:atTime:error:
fetchPersonAssociatedWithFaceGroup:options:
setRegionOfInterest:
cplStatus
close
enumerateIndexesUsingBlock:
fetchPersonForFaceCrop:options:
instancesRespondToSelector:
harmoniousColorScore
enumerateKeysAndObjectsUsingBlock:
base64EncodedStringWithOptions:
multiArrayValue
sceneprint
intValue
fetchPersonWithFace:options:
photoIrisProperties
lowKeyLightingScore
enumerateObjectsUsingBlock:
initWithFaceprint:torsoprint:
becomeCurrentWithPendingUnitCount:
multiLevelSocialGroupsWithPersonClusterManager:forPersons:updateBlock:
integerValue
photoIrisStillDisplayTime
hasAdjustments
setRemoteObjectInterface:
stagedText
initWithFaceprintData:faceprintVersion:
lowercaseString
mutableAudioBufferList
fetchPersonsForAssetCollection:options:
setRequestedTimeToleranceAfter:
machineReadableCodeData
sceneprintProperties
mutableBytes
standardUserDefaults
initWithFeatureProviderArray:
photoLibraryURL
fetchPersonsGroupedByAssetLocalIdentifierForAssets:options:
createDirectoryAtURL:withIntermediateDirectories:attributes:error:
setRequestedTimeToleranceBefore:
interestingSubjectScore
machineReadableCodeElements
mutableCopy
fetchPersonsWithLocalIdentifiers:options:
errorWithDomain:code:userInfo:
UTF8String
startCatalogDownload:then:
name
fetchPersonsWithOptions:
interfaceWithProtocol:
addObject:
startDownload:completionWithError:
sceneprints
fetchPropertySetsIfNeeded
clusterId
internalPredicate
addObjectsFromArray:
setReturnAllResults:
narrowedBoundingBox
fetchRejectedFacesForPerson:options:
setReturnMask:
addObservations:toEntityWithUniqueIdentifier:error:
startReading
naturalSize
intersectSet:
fetchRejectedPersonsForFace:options:
addOutput:
fetchSceneClassificationsGroupedByAssetLocalIdentifierForAssets:
setRevision:error:
fetchedObjectIDs
urlForApplicationDataFolderIdentifier:
intersectsSet:
clusteredFaceIdsForClusterContainingFaceId:error:
addRequest:withObserver:error:
searchSections
intrusiveObjectPresenceScore
referralURL
initWithFormat:
searchThreshold
blurrinessScore
fileExistsAtPath:
fileExistsAtPath:isDirectory:
clustererBuilderWithOptions:error:
refineRegionsWithRequest:error:
userFeedbackPayload
UUID
searchWithParsedVisualQuery:completion:
clustererModelFileNamesFromState:storedInPath:error:
usesCPUOnly
fileSize
pixelFormatType
refinedRegions
hasFocalPoint
searchWithVisualQuery:completion:
fileSystemRepresentation
usesLanguageDetection
sections
newBufferWithIOSurface:
fileURLWithPath:
uuid
VN2riiZbQrloRhCzYW56f0rk4N3ROe151S
regionOfInterestResults
newBufferWithLength:options:
uuidFromLocalIdentifier:
fileURLWithPath:isDirectory:
pixelsHigh
boolValue
VN7fiLHgGnvqPqG63cfDUCK4Xm8obUuWoP
newCommandQueue
pixelsHighRange
filterDescriptorWithWidth:height:arrayLength:kernelSpatialDiameter:kernelTemporalDiameter:epsilon:sourceChannels:guideChannels:preallocateIntermediates:
hasPrefix:
registerAvailabilityObserver:
initWithIdentifier:error:
newComputePipelineStateWithFunction:error:
isCloudPhotoLibraryEnabled
filterUsingPredicate:
pixelsWide
hasProcessedForLibrary:
newConfigurationForEntityPrintsGeneratedByRequest:error:
filteredArrayUsingPredicate:
isConfirmedFaceCropGenerationPending
pixelsWideRange
boundingBox
initWithImage:annotation:normalizedRegionOfInterest:domainsOfInterest:queryContext:
newDefaultLibraryWithBundle:error:
placeholderForCreatedFace
releaseCachedResources
selectRepresentativeFromFaces:qualityMeasureByLocalIdentifier:representativenessByCSN:candidateFaces:
code
placeholderForCreatedFaceGroup
addedDate
string
initWithImage:payload:reportIdentifier:
hasSlowMotionAdjustments
initWithImage:regionOfInterest:imageType:preferredMetalDevice:
stringByAppendingFormat:
visualSearchData
stringByAppendingPathComponent:
isEnabled
adjustmentKeys
pleasantCameraTiltScore
visualSearchProperties
stringByAppendingString:
evaluatePersonPromoterWithUpdateBlock:
pleasantCompositionScore
valueWithBytes:objCType:
setShouldPrefetchCount:
remoteObjectProxyWithErrorHandler:
creationRequestForFace
visualUnderstanding
adjustmentTimestamp
serializeStateAndReturnError:
initWithImageLoader:imageSize:
stringByDeletingPathExtension
newFunctionWithName:
isEqualToDate:
valueWithCMTime:
removeAllObjects
pleasantLightingScore
adjustmentValuesForKey:
creationRequestForFaceGroup
stringByReplacingOccurrencesOfString:withString:options:range:
evaluateWithObject:
newLinearTextureWithDescriptor:offset:bytesPerRow:bytesPerImage:
initWithImageSignatureprintType:imageSignatureHashType:
valueWithSize:
pleasantPatternScore
creationRequestsForFaceCropsWithOriginatingFace:resourceData:
exceptionWithName:reason:userInfo:
stringForObjectValue:
commit
isEqualToNumber:
pleasantPerspectiveScore
stringFromDate:
newTextureWithDescriptor:
isEqualToString:
setInTrash:
bundleForClass:
pleasantPostProcessingScore
removeFaces:
stringValue
bundleWithIdentifier:
advancedStatus
isEqualToValue:
setIncludeAllBurstAssets:
newTextureWithDescriptor:iosurface:plane:
pleasantReflectionsScore
removeIndex:
waitUntilCompleted
compare:options:
hashData
aestheticScore
stringWithFormat:
initWithIndexesInRange:
bytes
executionNanoseconds
setIncludeAssetSourceTypes:
isExceedingQuota
fingerprintHashes
setSortDescriptors:
pleasantSymmetryScore
removeItemAtPath:error:
warnings
cachePath
stringWithString:
setIncludeGuestAssets:
removeItemAtURL:error:
wasSignalled
ageCategory
stringWithUTF8String:
setIncludeHiddenAssets:
cropToFit
removeLastObject
initWithIsSensitive:andAttributes:
strongToStrongObjectsMapTable
setIncludeNonvisibleFaces:
croppedBoundingBox
removeMergeCandidatePersons:
webURL
highPrecisionThreshold
expectedClasses
setIncludeOnlyFacesInFaceGroups:
isGuestAsset
removeObject:
highRecallThreshold
curationProperties
subarrayWithRange:
nextObject
setIncludeOnlyFacesWithFaceprints:
finishDecoding
removeObjectAtIndex:
nextTimedMetadataGroup
initWithLabel:normalizedBoundingBox:confidence:
setIncludeTorsoOnlyDetectionData:
finishEncoding
isHidden
componentsSeparatedByString:
removeObjectForKey:
wellChosenBackgroundScore
alignedBoundingBoxAsCGRect
nodeForName:
setIncludeTorsoOnlyPerson:
composition
allClusteredFaceIdsAndReturnError:
VN7exwFFmQF0AI9P7FjBljwEFu7QYUGCYE
finishLoading
removeObjectsAtIndexes:
wellFramedSubjectScore
nodeForSceneClassId:
currentLocale
firstObject
setIncludeTrashedAssets:
_computeFingerPrintsOfAsset:completionHandler:
removeObjectsForKeys:
allKeys
wellKnownPhotoLibraryIdentifier
submitTaskWithOptions:completionHandler:
setIncludedDetectionTypes:
maximumAspectRatio
wellTimedShotScore
hintDomain
URLWithString:relativeToURL:
removeObjectsInArray:
submitUserFeedback:completion:
allValues
maximumCandidateCount
substringToIndex:
noiseScore
URLWithString:
isInVIPModel
maximumFaceCount
setAllowsCellularAccess:
nominalFrameRate
initWithLocaleIdentifier:
allocWithZone:
removeTrack:
writeToFile:atomically:
maximumObservations
dataRequest
nonGroupedGroupID
writeToURL:atomically:
dataType
suggestionsForClustersWithFaceIds:affinityThreshold:canceller:error:
initWithMachServiceName:options:
writeToURL:error:
replaceObjectAtIndex:withObject:
dataUsingEncoding:
setAppliesPreferredTrackTransform:
mediaAnalysisProperties
suggestionsForPersonLocalIdentifier:clusterSequenceNumbers:excludePersonLocalIdentifiers:minimumSuggestionFaceCount:
setInputFaceObservations:
writeToURL:options:error:
dataUsingEncoding:allowLossyConversion:
replaceRegion:mipmapLevel:slice:withBytes:bytesPerRow:bytesPerImage:
floatValue
setArrayLength:
dataValue
reportIdentifier
dataWithBytes:length:
setSymbologies:
setInputSignatureprint:
allowOnDemand
idealDimension
dataWithBytesNoCopy:length:freeWhenDone:
expressionsAndConfidence
normalizedBoundingBox
computeCommandEncoder
dataWithContentsOfURL:
allowedClasses
representativenessForFaces:error:
setTexture:atIndex:
normalizedBoundingBoxes
supportedImageSizeSet
setInternalPredicate:
predicate
dataWithContentsOfURL:options:error:
supportedPrivateRevisions
predicateWithBlock:
isMultiLibraryModeEnabled
setInternalSortDescriptors:
dataWithJSONObject:options:error:
setTextureType:
supportedRevisions
predicateWithFormat:
setInterruptionHandler:
VN3iT1YRjjnIuELobV1olJiO1vvItN6Kdq
dataWithLength:
focalPoint
canAddOutput:
setInvalidationHandler:
predictPersonFromFaceObservation:limit:canceller:error:
supportsFeatureSet:
analysisType
dataWithPropertyList:format:options:error:
setThirdPartyObject:
imageBufferValue
surroundingText
isPhoto
predictedPersonUniqueIdentifier
symbologies
formatDescriptions
synchronousRemoteObjectProxyWithErrorHandler:
URLByAppendingPathComponent:isDirectory:
dateByAddingTimeInterval:
systemPhotoLibraryURL
computeDistance:withDistanceFunction:error:
dateWithTimeIntervalSinceReferenceDate:
setTimeZone:
metadata
predictionsFromBatch:options:error:
imageConstraint
eyesCategory
null
setTimeoutIntervalForResource:
metadataForFormat:
setBlurDeterminationMethod:
setIsInVIPModel:
preferredLanguages
metadataItemsFromArray:filteredByIdentifier:
initWithNormalizedBoundingBox:andDomains:
metadataItemsFromArray:withKey:keySpace:
initWithNormalizedBoundingBox:regionAttributes:andSearchSections:
analyzeAudioBuffer:atAudioFramePosition:
faceAdjustmentVersion
preferredTransform
faceAlgorithmVersion
URLByAppendingPathComponent:
numberFromString:
cancelDataRequest:
frameLength
decodeObjectOfClass:forKey:
faceAttributes
cancelReading
taskService
initWithObjectIdentifier:imageURL:thumbnailURL:metadata:
initWithObservations:
numberValue
requestDataForAssetResource:options:dataReceivedHandler:completionHandler:
numberWithBool:
cancelTask:
isSystemPhotoLibrary
setBuffer:offset:atIndex:
setKeyFace:forCluster:
minimumAspectRatio
numberWithChar:
setByteRangeAccessSupported:
defaultANEDevice
setUsage:
minimumConfidence
numberWithDouble:
catalogIDs
setUseSegmentationPregating:
numberWithFloat:
faceCaptureQuality
defaultManager
setUsesLanguageDetection:
minimumSize
numberWithInt:
initWithOptions:error:
requestFileURLForAssetResource:options:urlReceivedHandler:completionHandler:
faceClusterSequenceNumbersOfFacesWithClusterSequenceNumbers:error:
defaultMetalDevice
numberWithInteger:
changeRequestForAsset:
faceClusterSequenceNumbersOfKeyFacesInAlgorithmicFaceGroupsForPerson:verifiedClusterSequenceNumbers:
initWithPCMFormat:frameCapacity:
tastefullyBlurredScore
gatingPayload
minimumUnverifiedFaceCount
numberWithLongLong:
changeRequestForDedupingGraphPersons:
gatingResultItems
setValue:forKey:
deferredProcessingNeeded
minimumVerifiedFaceCount
faceClusteringProperties
changeRequestForFace:
numberWithShort:
gaze
isValidFaceprint
minusSet:
imageNeuralHashprint
textBlockWithDocumentObservations:
changeRequestForFaceCrop:
numberWithUnsignedChar:
isValidTorsoprint
setLocale:
setVerifiedPersonTypes:
deleteFaceCrops:
numberWithUnsignedInt:
changeRequestForFaceGroup:
textElements
setVerifiedType:
deleteFaceGroups:
numberWithUnsignedInteger:
URLByAppendingPathExtension:
changeRequestForPerson:
setCharacterRecognitionData:machineReadableCodeData:algorithmVersion:adjustmentVersion:
gazeMask
texture2DDescriptorWithPixelFormat:width:height:mipmapped:
deletePersons:
modelDescription
numberWithUnsignedLong:
characterAtIndex:
isVideo
modelFromURL:options:error:
numberWithUnsignedLongLong:
characterRecognitionProperties
setChunkSizeForFetch:
items
modelURLForType:timeout:
imageRegions
characterSetWithCharactersInString:
thirdPartyObject
generateCGImageAsynchronouslyForTime:completionHandler:
setVisualSearchData:algorithmVersion:adjustmentVersion:
modelWithConfiguration:error:
threshold
faceDetectorVisionRevision
generateCaption:error:
modelWithContentsOfURL:configuration:error:
objectAtIndexedSubscript:
setClasses:forSelector:argumentIndex:ofReply:
thumbnailAspectRatio
generateClassificationScoresForPixelBuffer:error:
setWantsIncrementalChangeDetails:
descriptorData
modelWithContentsOfURL:error:
absoluteString
absoluteURL
thumbnailURL
time
faceHairCategory
objectEnumerator
privateFileURL
initWithPersonIdentifier:personName:boundingBox:andConfidence:
keyEnumerator
computeRampToTargetRate:forExport:outTimeSteps:outIntermediateRates:
momentSortDescriptors
imageSignatureHash
objectForKeyedSubscript:
timeIntervalSinceDate:
imageType
setWindowDuration:
timeIntervalSinceReferenceDate
faceJunkinessIndex
initWithPhotoLibrary:andDelegate:
objectID
setWithArray:
imageURL
detailedDescription
objectIdentifier
setComputePipelineState:
requestRevision
setWithCapacity:
imageWithPixelBuffer:orientation:
URLForDirectory:inDomain:appropriateForURL:create:error:
timeRangeMapperForSourceDuration:slowMotionRate:slowMotionTimeRange:forExport:
objectKnowledge
setWithObject:
setMaximumAspectRatio:
initWithPhotoLibraryURL:
faceObservationWithRequestRevision:boundingBox:andAlignedBoundingBox:
setMaximumCandidateCount:
setContentLength:
setWithSet:
requestSuggestedMePersonIdentifierAtURL:withError:
setMaximumHierarchicalObservations:
objects
classificationForIdentifier:
setMaximumIdentities:
setContentType:
imageprint
objectsAtIndexes:
setMaximumIntermediateSideLength:
setMaximumLeafObservations:
immersivenessScore
setMaximumObservations:
processInfo
observationWithBoundingBox:
setMaximumSize:
URLForResource:withExtension:
knowledgeGraphID
increaseLengthBy:
classifyPixelBuffer:stagedText:inConversationWithIdentifier:error:
setMaximumTrainingFaceprintsPerIdentity:
observationWithRequestRevision:boundingBox:
knowledgeProperties
URLByDeletingLastPathComponent
indexOfObject:inSortedRange:options:usingComparator:
setCropResult:
requestedLength
timeZoneForSecondsFromGMT:
l1ClusteredFaceIdsGroupedByL0ClustersForClustersContainingFaceIds:error:
indexSetWithIndexesInRange:
requestedOffset
ontologyNode
setMetalContextPriority:
label
indexesOfObjectsPassingTest:
initWithQueryTerm:hintDomain:textContext:imageContext:annotation:queryContext:
openAndWaitWithUpgrade:error:
processName
labelName
labels
faceprint
clearCacheWithOption:
setDateFormat:
initWithRegionOfInterest:domains:
andPredicateWithSubpredicates:
resetBytesInRange:
addEntriesFromDictionary:
setDelegate:queue:
VN1uMyFtnYEWjbrdx3yAuDndKkPeyzNJhB
resetFaceAnalysisWithResetLevel:completionHandler:
orPredicateWithSubpredicates:
languages
initForReadingFromData:error:
animalprint
setMinimumAspectRatio:
detectors
faceprintRequestRevision
setDetectionLevel:
title
addFaceObservations:toPersonWithUniqueIdentifier:error:
anyObject
setMinimumConfidence:
torsoThreshold
faceprintVersion
lastCompletePrefetchDate
setMinimumSize:
deviceForMetalDevice:
appendBuffer:atTime:error:
lastObject
setMinimumUnverifiedFaceCount:
UUIDString
getAllClustersAndReturnError:
dictionary
appendData:
torsoprintRequestRevision
setDiscretionary:
setMinimumVerifiedFaceCount:
lastPathComponent
addFaces:
getBytes:bytesPerRow:bytesPerImage:fromRegion:mipmapLevel:slice:
appendFormat:
totalExpected
initWithResultItems:
originalTimeForScaledTime:
lastSuccessfulSyncDate
addFetchPropertySets:
configuration
appendString:
initRequiringSecureCoding:
dictionaryWithCapacity:
getBytes:length:
totalWritten
initWithResultItems:andPayload:
latestTaxonomyIdentifier
dictionaryWithContentsOfURL:
resignCurrent
initStandardFormatWithSampleRate:channels:
approximateLocation
initWithResultItems:andUserFeedbackPayload:
failureScore
processingDevice
track
dictionaryWithDictionary:
archivedDataWithRootObject:requiringSecureCoding:error:
length
dictionaryWithObjects:forKeys:count:
initWithSampleBuffer:
setDownloadIntent:
array
dictionaryWithObjectsAndKeys:
librarySpecificFetchOptions
setDownloadIsTransient:
progressWithTotalUnitCount:
resourceData
arrayByAddingObjectsFromArray:
initWithSearchSections:
featureIdentifier
progressWithTotalUnitCount:parent:pendingUnitCount:
conformsToType:
setDownloadPriority:
direction
arrayLength
initWithSoundIdentifier:
setNetworkAccessAllowed:
arrayWithArray:
dispatchThreadgroups:threadsPerThreadgroup:
initWithState:error:
tracks
outputDescriptionsByName
arrayWithCapacity:
displayLabel
initWithSurface:cropRect:confidence:
tracksWithMediaType:
containsIndex:
featureValueWithCGImage:pixelsWide:pixelsHigh:pixelFormatType:options:error:
displayMessage
promoteUnverifiedPersonsWithUpdateBlock:
resourceLoader
arrayWithContentsOfURL:
initWithSurroundingText:normalizedBoundingBoxes:
trainingFaceObservationsForPersonWithUniqueIdentifier:canceller:error:
containsObject:
propertyListWithData:options:format:error:
featureValueWithImageAtURL:pixelsWide:pixelsHigh:pixelFormatType:options:error:
resourceURL
distanceBetweenClustersWithFaceId:andFaceId:error:
arrayWithObject:
setError:
trainingObservationsForEntityWithUniqueIdentifier:canceller:error:
featureValueWithMultiArray:
contentInformationRequest
distanceBetweenLevel1Clusters:error:
arrayWithObjects:
featureValueWithPixelBuffer:
setObject:atIndexedSubscript:
arrayWithObjects:count:
initWithAnimalprint:confidence:
respondWithData:
setObject:forKey:
featuresAtIndex:
distanceToImageprint:error:
contents
initWithAnnotations:revision:
setExcludeMontageAssets:
setObject:forKeyedSubscript:
contentsOfDirectoryAtURL:includingPropertiesForKeys:options:error:
initWithAsset:error:
setExecutionNanoseconds:
fetchAssetCollectionsWithLocalIdentifiers:options:
contextWithDictionary:error:
resultItems
fetchAssetCollectionsWithType:subtype:options:
description
copyWithZone:
dictionaryRepresentation
readFrom:
writeTo:
copyTo:
isEqual:
hash
mergeFrom:
timeRange
setTimeRange:
confidence
setConfidence:
.cxx_destruct
_confidence
_timeRange
T@"VCPProtoTimeRange",&,N,V_timeRange
Tf,N,V_confidence
init
initWith:confidence:
bound
setBound:
_bound
T{CGRect={CGPoint=dd}{CGSize=dd}},V_bound
Tf,V_confidence
initWithTransform:
parseResults:toDetections:atTime:fromTime:addActiveRegions:
analyzeFrame:withTimestamp:andDuration:flags:frameStats:
analyzeFrame:withTimestamp:andDuration:flags:
addDetectionToDict:withActiveRegions:forPetsDetections:fromTime:
finishAnalysisPass:
results
_petsDetections
_petsFaceDetections
_timeLastProcess
_petsStart
_petsFaceStart
_petsAnalyer
_petsActiveRegions
_petsFaceActiveRegions
initWithTimestamps:andTrack:
finishAnalysisPass:withStillImageBuffer:
processAborted
cancelled
setCancelled:
_processAborted
_cancelled
TB,R,V_processAborted
TB,N,V_cancelled
pv_performChangesAndWait:error:
_defaultFetchOptions
_defaultAssetFetchOptions
pv_persistentStorageDirectoryURL
pv_fetchPersonsWithLocalIdentifiers:
pv_fetchPersonsWithType:
pv_fetchPersonsInMoment:
pv_fetchCandidatePersonsForPerson:
pv_fetchInvalidCandidatePersonsForPerson:
pv_fetchPersonsGroupedByAssetLocalIdentifierForAssets:
pv_numberOfFacesWithFaceprints
pv_fetchFacesWithLocalIdentifiers:
pv_fetchFacesForPerson:
pv_fetchFacesForPerson:inMoment:
pv_fetchFacesForPersonLocalIdentifiers:inMoment:
pv_fetchFacesForFaceGroup:
pv_fetchFacesGroupedByAssetLocalIdentifierForAssets:
pv_fetchMoments
pv_fetchMomentsWithLocalIdentifiers:
pv_fetchMomentsForPerson:
pv_fetchMomentsForAssetsWithLocalIdentifiers:
pv_fetchAssetsWithLocalIdentifiers:
pv_fetchAssetsInMoment:
pv_fetchAssetsForPerson:
pv_fetchAssetsForFaceGroup:
pv_fetchFaceGroups
pv_fetchFaceGroupsForPerson:
_progressFromWorkerStatesDictionary:
pv_faceProcessingProgress
pv_fetchInvalidAssetIdentifiersForCommonComparison
pv_lastAssetDate
pv_fetchAssetsForFaceLocalIdentifiers:
_phFaceSortDescriptors
_phPeopleSortDescriptors
_defaultAssetPropertySets
_defaultFacePropertySets
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
superclass
debugDescription
TQ,R
T#,R
T@"NSString",R,C
exportToLegacyDictionary
resultFromLegacyDictionary:
dealloc
sharedInstance
setReachabilityForFlags:update:
hasWifiOrEthernetConnection
_callbackQueue
_reachability
_hasWifiOrEthernetConnection
TB,R,N,V_hasWifiOrEthernetConnection
forcePersonDetection
isMLHighlightEnabled
initWithTimeOfInteret:frameRate:isLivePhoto:phFaces:timeRange:requestedAnalyses:
configForAspectRatio:
copyImage:withChannels:
loadAnalysisResultsFrom:actionAnalyzer:atTime:
loadAnalysisResults:audioResults:
isAnalysisResultNeeded:
runTasks:duration:persons:regionCrop:
privateResults
_backbone
_transformImage
_tasks
_postTasks
_privateTasks
_inputData
_inputWidth
_inputHeight
_timeLastDetection
_timeStart
_validFrames
_enoughFrames
_personDetector
_resConfig
_autoplay
_cameraMotion
_quality
_highlight
_regionCrop
_timeEnd
_postInference
setDistanceToPreviousScene:
setHasDistanceToPreviousScene:
hasDistanceToPreviousScene
setFlickerScore:
setHasFlickerScore:
hasFlickerScore
setSceneprintDistanceToPreviousScene:
setHasSceneprintDistanceToPreviousScene:
hasSceneprintDistanceToPreviousScene
qualityScore
setQualityScore:
distanceToPreviousScene
flickerScore
sceneprintDistanceToPreviousScene
_distanceToPreviousScene
_flickerScore
_qualityScore
_sceneprintDistanceToPreviousScene
_has
Tf,N,V_qualityScore
TB,N
Tf,N,V_distanceToPreviousScene
Tf,N,V_flickerScore
Tf,N,V_sceneprintDistanceToPreviousScene
featureProviderWithCVPixelBuffer:andFeatureName:
featureValueForName:
featureNames
T@"NSSet",R,N
initWithCVPixelBuffer:andFeatureName:
_featureName
_buffer
detector
audioFormatRequirements
addDetectionFromTime:toTime:result:
setupWithSample:andSampleBatchSize:
loadModel
setupWithAudioStream:
processAudioSamples:timestamp:
finalizeAnalysisAtTime:
voiceDetections
setVoiceDetections:
_model
_audioStream
_sampleBatchSize
_trackStart
_voiceActivity
_voiceStart
_voiceDetections
_utteranceDetections
_musicDetections
T@"NSMutableArray",&,V_voiceDetections
vcp_sortBySize
vcp_resourceWithType:
vcp_isOriginalLocal
vcp_hasLocalPhoto:
vcp_hasLocalMovie:
vcp_hasLocalAdjustments
vcp_hasLocalSlowmo:
vcp_thumbnailResource
vcp_smallResourceMeetingCriteria:
vcp_smallMovieDerivativeResource
vcp_originalResource
vcp_originalVideoResource
vcp_adjustmentsResource
vcp_localPhotoResourcesSorted:
vcp_photoResourcesSorted:
vcp_localMovieResourcesSorted:
vcp_avAsset:
vcp_getFpsRate
vcp_highResImageResourcesForAsset:
useSceneprintInSceneAnalysis
enableMoflow
initWithVideoTrack:withMetaOrientation:withPrivateResults:withFrameStats:isTimelapse:isIris:irisPhotoOffsetSec:irisPhotoExposureSec:slowMoRate:faceDominated:
seedAnalyzersWithPixelBuffer:startTime:
prepareVideoAnalysisByScenes:
prepareLivePhotoAnalysisByScenes:
analyzeFrame:withTimestamp:andDuration:flags:cancel:
analyzeFrame:withTimestamp:andDuration:properties:flags:cancel:
isStableMetaMotion:
estimateExpressionScore:encodeStats:frameWidth:frameHeight:
process:
processAndEstimateQualityScore:
estimateQualityScore:
addSceneAnalysisResult:to:optional:
addSceneAnalysisResult:to:clipRange:
addResult:to:forKey:optional:
getSceneSwichFrequency
setNextCaptureFrame:
reviseFrameTrackScore:saliencyRegions:
computeExposureScoreOfFrame:
clipResults:
actionScore
setActionScore:
interestingnessScore
setInterestingnessScore:
obstructionScore
setObstructionScore:
trackingScore
setTrackingScore:
objectsMotion
globalMotion
.cxx_construct
_encodeAnalysis
_preencodeAnalysis
_obstructionAnalysis
_sceneAnalysis
_motionFilter
_metadataAnalysis
_irisAnalysis
_frameBuffer
_idealHistogram
_isTimelapse
_isIris
_isSlowMo
_orientation
_finalized
_hasInterestingScene
_isCaptureAnalysis
_privateResults
_videoFrameAnalysis
_trackScoreFilter
_metaMotionResults
_faceDominated
_useMoflow
_subtleMotionAnalyzer
_motionFlowAnalyzer
_sceneType
_actionScore
_interestingnessScore
_obstructionScore
_trackingScore
_objectsMotion
_globalMotion
Tf,V_qualityScore
Tf,V_actionScore
Tf,V_interestingnessScore
Tf,V_obstructionScore
Tf,V_trackingScore
T@"NSDictionary",R,N,V_objectsMotion
T@"NSArray",R,N,V_globalMotion
Tf,N,V_actionScore
updateModelByAddingFaces:andRemovingFaces:canceller:error:
updateModelByAddingFaces:error:
vcp_updateModelByAddingFaces:error:
faceRanges
initWithTransform:withExistingFaceprints:frameStats:
detectFaces:faces:
minProcessTimeIntervalInSecs
removeSmallestKeyFace
compareFace:withFace:
locationChange:relativeTo:landscape:
detectTrackFacesInFrame:withTimestamp:faces:
frameFaceResults
clusterFaces
updateWithExistingFaces
_latestTrackID
_smileDetector
_poseEstimator
_existingFaceprints
_frameStats
_latestFrameArea
_timeLastTracking
_faceTrackers
_keyFaces
_reservedIDs
_facePrints
_allFaces
_faceRanges
_frameFaceResults
timeRangeValue
timeRangeWithCMTimeRange:
taskWithFaceCrop:andCompletionHandler:
resourceRequirement
autoCancellable
cancel
cachesResources
interrupt
resetInterruption
initWithFaceCrop:andCompletionHandler:
configureRequest:withRevision:
run:
_completionHandler
_faceCropData
_started
_cancel
fingerprintWithMaster:adjusted:
initWithMaster:adjusted:
isEqualToFingerprint:
master
adjusted
_master
_adjusted
T@"NSString",R,V_master
T@"NSString",R,V_adjusted
init:sharedModel:modelName:
getInputBuffer:srcWidth:cnnInputHeight:cnnInputWidth:offset:
generateHandKeypoints:keypointConfidence:offset:
_forceCPU
_modelEspresso
computeRegionNoise:blockTextureness:average:width:height:stride:
computeNoiseLevel:width:height:stride:textureness:
analyzePixelBuffer:flags:results:cancel:
exposureScore
_exposureScore
Tf,R,N,V_exposureScore
usePHAssetData
preferredPixelFormat
descriptorWithImage:
descriptorWithData:
serialize
computeDistance:toDescriptor:
initWithImage:
initWithData:
_imagePrint
faceResultsType
clearFaceResults
addFaceResults:
faceResultsCount
faceResultsAtIndex:
setGlobalQualityScore:
setHasGlobalQualityScore:
hasGlobalQualityScore
setContentScore:
setHasContentScore:
hasContentScore
timestamp
setTimestamp:
qualityScoreForLivePhoto
setQualityScoreForLivePhoto:
visualPleasingScore
setVisualPleasingScore:
overallFaceQualityScore
setOverallFaceQualityScore:
setExposureScore:
penaltyScore
setPenaltyScore:
textureScore
setTextureScore:
sharpness
setSharpness:
faceResults
setFaceResults:
globalQualityScore
contentScore
expressionChangeScore
setExpressionChangeScore:
_timestamp
_contentScore
_expressionChangeScore
_faceResults
_globalQualityScore
_overallFaceQualityScore
_penaltyScore
_qualityScoreForLivePhoto
_sharpness
_textureScore
_visualPleasingScore
Td,N,V_timestamp
Tf,N,V_qualityScoreForLivePhoto
Tf,N,V_visualPleasingScore
Tf,N,V_overallFaceQualityScore
Tf,N,V_exposureScore
Tf,N,V_penaltyScore
Tf,N,V_textureScore
Tf,N,V_sharpness
T@"NSMutableArray",&,N,V_faceResults
Tf,N,V_globalQualityScore
Tf,N,V_contentScore
Tf,N,V_expressionChangeScore
allocBuffers:
flipTransform:
processMetadataGroup:flags:
finalizeAnalysis
publicResults
_activeFaces
_transform
setX:
setY:
Tf,N,V_x
Tf,N,V_y
faceprintData
setQualityMeasure:
localIdentifier
personLocalIdentifier
size
centerX
centerY
poseYaw
clusterSequenceNumber
qualityMeasure
ageType
poseType
T@"NSString",R,N
Td,R,N
Tq,R,N
T@"NSData",R,N
Tq,N
TS,R,N
Tq,D,N
requestWithFaceClusterIds:clusterFlags:updateHandler:
initWithFaceClusterIds:clusterFlags:updateHandler:
type
requestId
clusterFlagByClusterId
csns
cflags
updateHandler
setUpdateHandler:
canceller
_type
_requestId
_clusterFlagByClusterId
_csns
_cflags
_updateHandler
_canceller
TQ,R,V_type
T@"NSString",R,V_requestId
T@"NSMutableDictionary",R,V_clusterFlagByClusterId
T@"NSArray",R,V_csns
T@"NSArray",R,V_cflags
T@?,C,V_updateHandler
T@"VNCanceller",R,V_canceller
removeClusteringStateCacheWithURL:error:
level0ClusterAsFaceCSNsByLevel0KeyFaceCSNForClusterIdentifiedByFaceCSN:error:
distanceBetweenLevel0ClusterIdentifiedByFaceCSN:andLevel0ClusterIdentifiedByFaceCSN:error:
distancesFromClustersIdentifiedByFaceCSNs:toClustersIdentifiedByFaceCSNs:error:
initWithPhotoLibrary:andContext:
terminate
_processingQueueDetermineNextClusterTriggeringAccumulatedChangesCountIfNecessary
scheduleClusteringAfterRemovingFaceCSNs:addingFaceIdStrs:
_processingQueuePerformForcedFaceClustering:cancelOrExtendTimeoutBlock:
numberOfAccumulatedClusterChanges
clusteredFaceCount
clusterCount
clusterIfNecessaryAndWaitWithCancelOrExtendTimeoutBlock:
clusterAndWaitWithCancelOrExtendTimeoutBlock:
_cancelClusteringAndRestoreClusterCache:
cancelClustering
_recordClusteringState:
_recordClusterRebuildRequired:
_recordCountOfPendingFacesToAdd:
_recordIncrementCountOfPendingFacesToAdd:
_recordCurrentStatus:
status
_performAndPersistClustersWithFaceTorsoprintsToAdd:groupingIdentifiersToAdd:faceTorsoprintsToRemove:updatedFaces:cancelOrExtendTimeoutBlock:error:
_faceTorsoprintsFromFaceCSNs:
_faceTorsoprintsFromFaceIdentifiers:assignClusterSeqNumberIfNeeded:updatedFaces:groupingIdentifiers:
_faceTorsoprintsFromFaces:assignClusterSeqNumberIfNeeded:updatedFaces:
_removeEmptyGroups
_processingQueueQuickSyncClustererWithPhotoLibraryUsingFacesInClusterCache:visionClusters:cancelOrExtendTimeoutBlock:
_processingQueueSyncClustererWithPhotoLibraryUsingFacesInClusterCache:cancelOrExtendTimeoutBlock:
_processingQueueGetFaceClusterSequenceNumbersInClusterCache:lastClusterSequenceNumber:error:
_processingQueueSaveClusterCache:
_visionClusterMemmapFileInCacheDirectoryURL:clusterState:error:
_processingQueueRestoreClusteringCacheWithCacheDirectoryURL:clusterState:threshold:error:
_processingQueueResetClusterCache:
_visionClusterStateDataBlobFromClusterSnapshotFileAtURL:error:
_removeVisionClusterCacheFilesNotReferencedByVisionClusterState:
_processingQueueRestoreFromClusterSnapshotFileAtURL:error:
_processingQueueRestoreClusterCacheAndSyncWithLibrary:cancelOrExtendTimeoutBlock:error:
restoreClusterCacheAndSyncWithLibrary:cancelOrExtendTimeoutBlock:error:
suggestedFaceClusterSequenceNumbersForFaceClusterSequenceNumbersRepresentingClusters:error:
requestSuggestionsForFaceClusterSequenceNumbers:withClusteringFlags:updateHandler:error:
cancelSuggestionRequest:
cancelAllSuggestionRequests
isReadyToReturnSuggestions
_resolveConflictingL0ClustersFromVNClusters:excludedL0ClustersByL1ClusterId:cancelOrExtendTimeoutBlock:
_processingQueueGetVisionClusters:minimumClusterSize:returnClusterAsCountedSet:excludedL0ClustersByL1ClusterId:cancelOrExtendTimeoutBlock:error:
differencesBetweenClusterCacheAndLibrary:excludedL0ClustersByL1ClusterId:cancelOrExtendTimeoutBlock:
getClusters:threshold:utilizingGPU:cancelOrExtendTimeoutBlock:error:
_propertyDictionaryFileURL
_readPropertyDictionary
_setPropertyDictionaryValue:forKey:
_bringUpStateDescription:
setClustererBringUpState:
clustererState
isReady
needsFullSync
needsUpdate
clustererBringUpState
_photoLibrary
_persistenceDelegate
_processingQueue
_processingGroup
_canceled
_context
_cacheDirUrl
_cacheFileUrl
_clusteringType
_threshold
_faceCSNsInClusterCache
_nextSeqNum
_faceIdStrsToAdd
_faceCSNsToRemove
_accumulatedChangesCount
_nextClusterTriggeringAccumulatedChangesCount
_visionCanceler
_clusterBuilder
_rebuildClusterer
_outstandingSuggestionRequests
_currentSuggestionRequest
_suggestionLock
_currentStatusSnapshotLock
_currentStatusSnapshot
_currentStatusSnapshotIsValid
_propertyDictionaryLock
_propertyDictionary
_clustererBringUpState
_timestampOfLastClusterComparison
_timebase
TB,R,N
ready
TB,R,N,GisReady
TQ,N,V_clustererBringUpState
TQ,R,N
initWithOptions:
updateWithOptions:error:
parseResults:observations:
processImage:withOptions:error:
preferredInputSizeWithOptions:error:
cleanupWithOptions:error:
_analyzer
_preferredWidth
_preferredHeight
_preferredFormat
run:withPersons:andRegionCrop:atTime:andDuration:
highlightScore
setHighlightScore:
_highlightScore
Tf,N,V_highlightScore
initWithImageAsset:requestHandler:regionOfInterest:
matchesImageAsset:
requestHandler
regionOfInterest
_identifier
_resolution
_requestHandler
_regionOfInterest
T@"VNImageRequestHandler",R,N,V_requestHandler
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,V_regionOfInterest
purge
sharedResource
activeCost
inactiveCost
maskOnly
setMaskOnly:
cachedImageHandler
setCachedImageHandler:
_maskOnly
_cachedImageHandler
TB,N,V_maskOnly
T@"VCPMADVIRemoveBackgroundCachedImageHandler",&,N,V_cachedImageHandler
taskWithRequest:imageAsset:andSignpostPayload:
dependencies
setPreferredMetalDevice:
initWithRequest:imageAsset:andSignpostPayload:
_request
_imageAsset
_preferredMetalDevice
_signpostPayload
_cancelQueue
_weakRequest
validateConfiguration:withError:
nodeWithRequest:andConfiguration:
initWithRequest:andConfiguration:
request
timeInterval
frameInterval
_frameInterval
_timeInterval
T@"VNRequest",R,N,V_request
T{?=qiIq},R,N,V_timeInterval
TQ,R,N,V_frameInterval
initWithPixelFormat:
resize:height:
convertImage:yuvFrame:
_pixelFormat
_width
_height
_rgbColorSpace
_cgContext
_rgbFrame
_yuvFrames
_rgbToYuv
taskWithAsset:andAnalysisTypes:andOptions:andProgressHandler:andCompletionHandler:
initWithAssets:analysisTypes:options:progressHandler:andCompletionHandler:
requestAnalysis:forAsset:andDatabase:error:
analyzeOndemand:forAnalysisTypes:withExistingAnalysis:error:
main
_assets
_database
_allowOnDemand
_analysisTypes
_options
requestMediaAnalysisDatabaseAccessSandboxExtensionWithPhotoLibraryURL:andReply:
requestImageProcessing:forIOSurface:withOrientation:identifier:requestID:andReply:
requestImageProcessing:forAssetURL:withSandboxToken:identifier:requestID:andReply:
requestImageProcessing:forImageData:withUniformTypeIdentifier:identifier:requestID:andReply:
requestImageProcessing:forAssetWithIdentifier:identifierType:fromPhotoLibraryWithURL:requestID:andReply:
requestImageProcessing:forIOSurface:withOrientation:assetLocalIdentifier:photoLibraryURL:requestID:andReply:
requestImageProcessing:forAssetWithCloudIdentifier:requestID:andReply:
requestImageProcessingWithCloudIdentifierRequests:requestID:andReply:
queryPerformanceMeasurementsWithReply:
resetPerformanceMeasurements
startEntryPointWithQueryID:
cacheHitWithQueryID:cachedResultQueryID:
endEntryPoint
requestURLAssetAnalysis:forAssetWithResourcePaths:withOptions:analysisTypes:sandboxTokens:withReply:
requestAssetAnalysis:forLocalIdentifiers:fromPhotoLibraryWithURL:withOptions:analysisTypes:withReply:
requestAssetAnalysis:forPhotoLibraryURL:withLocalIdentifiers:realTime:withReply:
requestLibraryProcessing:withTaskID:forPhotoLibraryURL:withOptions:andReply:
requestAssetProcessing:withTaskID:forLocalIdentifiers:fromPhotoLibraryWithURL:withOptions:andReply:
requestWallpaperUpgrade:atSourceURL:toDestinationURL:withOptions:sandboxTokens:andReply:
cancelRequest:
cancelAllRequests
cancelBackgroundActivityWithReply:
currentOutstandingTasksWithReply:
notifyLibraryAvailableAtURL:
requestSuggestedPersons:withPersonWithLocalIdentifier:toBeConfirmedPersonSuggestions:toBeRejectedPersonSuggestions:andPhotoLibraryURL:andReply:
requestUpdateKeyFacesOfPersons:withLocalIdentifiers:andForceUpdate:andPhotoLibraryURL:andReply:
requestFaceCandidatesforKeyFace:withPersonsWithLocalIdentifiers:andPhotoLibraryURL:andReply:
requestResetFaceClassificationModel:withPhotoLibraryURL:andReply:
requestResetPetClassificationModel:withPhotoLibraryURL:andReply:
requestSuggestedMePersonIdentifier:withContext:andPhotoLibraryURL:andReply:
requestPersonPromoterStatus:withAdvancedFlag:andPhotoLibraryURL:andReply:
requestClusterCacheValidation:withPhotoLibraryURL:andReply:
requestResetFaceClusteringState:withPhotoLibraryURL:andReply:
requestReclusterFaces:withPhotoLibraryURL:andReply:
requestRebuildPersons:withLocalIdentifiers:andPhotoLibraryURL:andReply:
requestPersonPreferenceForPhotoLibraryURL:andReply:
requestVIPModelStorageFilepathForPhotoLibraryURL:forModelType:andReply:
queryAutoCounterOptInStatus:withPhotoLibraryURL:personLocalIdentifiers:andReply:
requestOptInAutoCounter:withPhotoLibraryURL:persons:andReply:
requestDumpAutoCounter:withPhotoLibraryURL:andReply:
requestAutoCounterAccuracyCalculation:withPhotoLibraryURL:andReply:
requestAutoCounterAccuracyCalculation:withPhotoLibraryURL:clusterStateURL:groundTruthURL:andReply:
requestAutoCounterSIMLValidation:withPhotoLibraryURL:simlGroundTruthURL:andReply:
requestIdentificationOfFacesWithLocalIdentifiers:fromPhotoLibraryWithURL:withRequestID:andReply:
requestProcessingTypes:forAssetsWithLocalIdentifiers:fromPhotoLibraryWithURL:withRequestID:andReply:
reportProgress:forRequest:
sharedAnalysisService
analysisService
errorWithDescription:
queryProgress:forPhotoLibrary:andTaskID:
queryProgress:forPhotoLibrary:andTaskID:withExtendTimeoutBlock:
queryCachedFaceAnalysisProgress:forPhotoLibrary:
queryCachedFaceAnalysisProgress:forPhotoLibrary:withExtendTimeoutBlock:
queryProgressDetail:forPhotoLibrary:andTaskID:
queryProgressDetail:forPhotoLibrary:andTaskID:withExtendTimeoutBlock:
queryProgressDetail:forPhotoLibraryURL:andTaskID:
queryProgressDetail:forPhotoLibraryURL:andTaskID:withExtendTimeoutBlock:
connection
requestAnalysisTypes:forAssetWithResourceURLs:withOptions:progressHandler:andCompletionHandler:
requestAnalysisTypes:forAssets:withOptions:progressHandler:andCompletionHandler:
requestBackgroundAnalysisForAssets:fromPhotoLibraryWithURL:realTime:progessHandler:completionHandler:
requestBackgroundAnalysisForAssets:realTime:progessHandler:completionHandler:
requestProcessingWithTaskID:forPhotoLibrary:withOptions:progessHandler:andCompletionHandler:
requestBackgroundProcessingWithTaskID:forPhotoLibrary:progessHandler:completionHandler:
requestSceneProcessingForPhotoLibrary:withOptions:progressHandler:andCompletionHandler:
requestFaceProcessingForPhotoLibrary:withOptions:progressHandler:andCompletionHandler:
requestMultiWorkerProcessingForPhotoLibrary:withOptions:progressHandler:andCompletionHandler:
requestFullProcessingForPhotoLibrary:withOptions:progressHandler:andCompletionHandler:
requestProcessingWithTaskID:forAssets:withOptions:progressHandler:andCompletionHandler:
requestLivePhotoEffectsForAssets:withOptions:progressHandler:andCompletionHandler:
requestSceneProcessingForAssets:withOptions:progressHandler:andCompletionHandler:
requestFaceProcessingForAssets:withOptions:progressHandler:andCompletionHandler:
requestQuickFaceIdentificationForPhotoLibraryURL:withOptions:andCompletionHandler:
requestSceneprintProcessingForAssets:withOptions:progressHandler:andCompletionHandler:
requestVideoStabilizationForAssets:withOptions:progressHandler:andCompletionHandler:
cancelBackgroundActivity
invalidate
requestPersonPreferenceForPhotoLibraryURL:completionHandler:
requestVIPModelFilepathForPhotoLibraryURL:forModelType:completionHandler:
_connection
_managementQueue
_handlerQueue
_progressBlocks
_nextRequestID
requestSuggestedPersonsForPersonWithLocalIdentifier:toBeConfirmedPersonSuggestions:toBeRejectedPersonSuggestions:photoLibraryURL:progessHandler:completionHandler:
requestUpdateKeyFacesOfPersonsWithLocalIdentifiers:forceUpdate:photoLibraryURL:progessHandler:completionHandler:
requestFaceCandidatesforKeyFaceForPersonsWithLocalIdentifiers:photoLibraryURL:progessHandler:completionHandler:
requestResetFaceClassificationModelForPhotoLibraryURL:progressHandler:completionHandler:
requestResetPetClassificationModelForPhotoLibraryURL:progressHandler:completionHandler:
requestSuggestedMePersonIdentifierWithContext:photoLibraryURL:progressHandler:completionHandler:
requestPersonPromoterStatusWithAdvancedFlag:photoLibraryURL:progressHandler:completionHandler:
requestPersonProcessingForPhotoLibraryURL:options:progressHandler:completionHandler:
requestClusterCacheValidationWithPhotoLibraryURL:progressHandler:completionHandler:
requestResetFaceClusteringStateWithPhotoLibraryURL:progressHandler:completionHandler:
requestReclusterFacesWithPhotoLibraryURL:progressHandler:completionHandler:
requestRebuildPersonsWithLocalIdentifiers:photoLibraryURL:progressHandler:completionHandler:
queryAutoCounterOptInStatusForPhotoLibraryURL:withPersonLocalIdentifiers:completionHandler:
requestOptInAutoCounterForPhotoLibraryURL:withPersons:completionHandler:
requestDumpAutoCounterForPhotoLibraryURL:completionHandler:
requestAutoCounterAccuracyCalculationForPhotoLibraryURL:completionHandler:
requestAutoCounterAccuracyCalculationForPhotoLibraryURL:clusterStateURL:groundTruthURL:completionHandler:
requestAutoCounterSIMLValidationForPhotoLibraryURL:simlGroundTruthURL:completionHandler:
requestIdentificationOfFaces:withCompletionHandler:
requestProcessingTypes:forAssetsWithLocalIdentifiers:fromPhotoLibraryWithURL:progressHandler:completionHandler:
initWithModelPath:
inference:
embeddingHeight
embeddingWidth
embeddingChannels
embeddingSequenceLength
videoEmbedding
_outputNames
_forceNNGraph
_embeddingHeight
_embeddingWidth
_embeddingChannels
_embeddingSequenceLength
_videoEmbedding
Ti,R,V_embeddingHeight
Ti,R,V_embeddingWidth
Ti,R,V_embeddingChannels
Ti,R,V_embeddingSequenceLength
T^f,R,V_videoEmbedding
keypointsToObservation:
keypointsFromTensor:withOptions:results:
keypointsFromTensor:width:height:channels:withOptions:results:
requiredInputFormat:height:format:
processFrame:withOptions:results:
_heatmapNms
_revision
_modelOutput16bit
_modelOutputSize
_loadModel
_plan
_ctx
_net
_outputBlob
timeValue
timeWithCMTime:
detector:
copyImage:toData:withChannels:
createInput:withBuffer:cnnInputHeight:cnnInputWidth:
createModel:srcWidth:
getInputBuffer:srcWidth:cnnInputHeight:cnnInputWidth:
generatePetsBoxes:faceBoxes:cancel:
nonMaxSuppression:
generatePetsRegions:outHeight:outWidth:boxes:faceBoxes:maxNumRegions:
postProcBoxes:maxNumRegions:
petsDetection:petsRegions:petsFaceRegions:cancel:
handler
_queue
_handler
logMemoryWithMessage:
getInputBuffer
computeSmileScore:
detectSmileForFace:inBuffer:smile:
faceWithLocalIdentifier:
faceFromFaceObservation:humanObservation:sourceWidth:sourceHeight:visionRequests:processingVersion:force:andError:
facesFromFaceObservations:humanObservations:animalObservations:sourceWidth:sourceHeight:visionRequests:blurScorePerFace:exposureScorePerFace:tooSmallFaceObservations:processingVersion:
faceFromPHFace:copyOption:
facesFromPHFetchResult:copyOption:
_calculateOverlappingBetweenFaceObservation:andHumanObservation:
_calculateIoUBetweenObservation:andObservation:
_isColocatingAnimalObservation:withFaceObservations:orTorsoObservations:
photosFaceRepresentationSourceWidth
photosFaceRepresentationSourceHeight
photosFaceRepresentationCenterX
photosFaceRepresentationCenterY
photosFaceRepresentationSize
photosFaceRepresentationBlurScore
photosFaceRepresentationHasSmile
photosFaceRepresentationIsLeftEyeClosed
photosFaceRepresentationIsRightEyeClosed
photosFaceRepresentationQualityMeasure
photosFaceRepresentationClusterSequenceNumber
photosFaceRepresentationLocalIdentifier
photosFaceRepresentationRoll
initWithLocalIdentifier:
replaceCoordinatesAndFeaturesFromDetectedFace:
setCenterAndSizeFromNormalizedFaceRect:
normalizedFaceRect
gist
qualityMeasureWithCountOfFacesOnAsset:
photosFaceRepresentationQuality
setPersonLocalIdentifier:
sourceWidth
setSourceWidth:
sourceHeight
setSourceHeight:
detectionType
setDetectionType:
setCenterX:
setCenterY:
setSize:
bodyCenterX
setBodyCenterX:
bodyCenterY
setBodyCenterY:
bodyWidth
setBodyWidth:
bodyHeight
setBodyHeight:
hidden
setHidden:
isInTrash
setIsInTrash:
manual
setManual:
isTooSmall
setIsTooSmall:
hasSmile
setHasSmile:
blurScore
setBlurScore:
isLeftEyeClosed
setIsLeftEyeClosed:
isRightEyeClosed
setIsRightEyeClosed:
adjustmentVersion
setAdjustmentVersion:
nameSource
setNameSource:
trainingType
setTrainingType:
setPoseYaw:
algorithmVersion
setAlgorithmVersion:
setClusterSequenceNumber:
setAgeType:
sexType
setSexType:
eyesState
setEyesState:
smileType
setSmileType:
facialHairType
setFacialHairType:
hairColorType
setHairColorType:
glassesType
setGlassesType:
expressionType
setExpressionType:
headgearType
setHeadgearType:
hairType
setHairType:
setPoseType:
skintoneType
setSkintoneType:
ethnicityType
setEthnicityType:
hasFaceMask
setHasFaceMask:
gazeType
setGazeType:
gazeCenterX
setGazeCenterX:
gazeCenterY
setGazeCenterY:
groupingIdentifier
setGroupingIdentifier:
imageprintWrapper
setImageprintWrapper:
roll
setRoll:
quality
setQuality:
_hidden
_isInTrash
_manual
_isTooSmall
_hasSmile
_isLeftEyeClosed
_isRightEyeClosed
_hasFaceMask
_detectionType
_ageType
_sexType
_eyesState
_smileType
_facialHairType
_hairColorType
_glassesType
_expressionType
_headgearType
_hairType
_poseType
_skintoneType
_ethnicityType
_gazeType
_trainingType
_localIdentifier
_personLocalIdentifier
_sourceWidth
_sourceHeight
_centerX
_centerY
_size
_bodyCenterX
_bodyCenterY
_bodyWidth
_bodyHeight
_blurScore
_adjustmentVersion
_nameSource
_poseYaw
_algorithmVersion
_clusterSequenceNumber
_qualityMeasure
_gazeCenterX
_gazeCenterY
_groupingIdentifier
_imageprintWrapper
_roll
T@"NSString",R,C,N,V_localIdentifier
T@"NSString",C,N,V_personLocalIdentifier
Tq,N,V_sourceWidth
Tq,N,V_sourceHeight
Ts,N,V_detectionType
Td,N,V_centerX
Td,N,V_centerY
Td,N,V_size
Td,N,V_bodyCenterX
Td,N,V_bodyCenterY
Td,N,V_bodyWidth
Td,N,V_bodyHeight
TB,N,V_hidden
TB,N,V_isInTrash
TB,N,V_manual
TB,N,V_isTooSmall
TB,N,V_hasSmile
Td,N,V_blurScore
Td,N,V_exposureScore
TB,N,V_isLeftEyeClosed
TB,N,V_isRightEyeClosed
T@"NSString",C,N,V_adjustmentVersion
Tq,N,V_nameSource
Ti,N,V_trainingType
Td,N,V_poseYaw
TQ,N,V_algorithmVersion
Tq,N,V_clusterSequenceNumber
Tq,N,V_qualityMeasure
TS,N,V_ageType
TS,N,V_sexType
TS,N,V_eyesState
TS,N,V_smileType
TS,N,V_facialHairType
TS,N,V_hairColorType
TS,N,V_glassesType
TS,N,V_expressionType
TS,N,V_headgearType
TS,N,V_hairType
TS,N,V_poseType
TS,N,V_skintoneType
TS,N,V_ethnicityType
TB,N,V_hasFaceMask
TS,N,V_gazeType
Td,N,V_gazeCenterX
Td,N,V_gazeCenterY
T@"NSString",C,N,V_groupingIdentifier
T@"VCPVNImageprintWrapper",&,N,V_imageprintWrapper
Td,N,V_roll
Td,N,V_quality
supportGPU
createContextWithForceCPU
createContextWithMPSGraph
createContextPreferred
sharedContextWithForceCPU:
sharedContextWithMPSGraph:
sharedContextPreferred:
initWithForceCPU:forceNNGraph:shared:
espressoContext
_espressoContext
T^v,R,N,V_espressoContext
bounds
setBounds:
_bounds
T@"VCPProtoBounds",&,N,V_bounds
sharedModel:
computePoseScore:
_results
initWithTimestamp:score:valid:
updateWithFirstFrame:score:valid:
updateSegment:score:valid:
mergeSegment:
copyFrom:
updateDuration:
trimSegment:fromStart:
isContentTooShort
score
sumOfScore
numOfFrames
numOfValidFrames
curationScore
setCurationScore:
_sumOfScore
_curationScore
_numOfFrames
_numOfValidFrames
T{?={?=qiIq}{?=qiIq}},N,V_timeRange
TQ,R,N,V_numOfFrames
TQ,R,N,V_numOfValidFrames
Tf,N,V_curationScore
initWithSceneId:withDuration:withConfidence:
sceneId
setSceneId:
duration
setDuration:
sumConfidence
setSumConfidence:
_duration
_sumConfidence
_sceneId
T@"NSString",&,V_sceneId
Tf,V_duration
Tf,V_sumConfidence
compareObjectsOfInterest:withScenes:
addResult:start:duration:keyIsName:
addAggregatedScenes:timerange:
frameScenes
sceneResults
setSceneResults:
_start
_existingScenes
_internalFrameScenes
_sceneResults
T@"NSDictionary",R
T@"NSArray",&,V_sceneResults
featureBlob
setFeatureBlob:
_featureBlob
T@"NSData",&,N,V_featureBlob
timerWithInterval:unit:oneShot:andBlock:
timerWithIntervalSeconds:isOneShot:andBlock:
initWithIntervalNanoseconds:isOneShot:andBlock:
handleTimerEvent
destroy
_source
_active
_isOneShot
_block
keypointsType
clearKeypoints
addKeypoints:
keypointsCount
keypointsAtIndex:
flags
setFlags:
keypoints
setKeypoints:
_flags
_keypoints
Ti,N,V_flags
T@"NSMutableArray",&,N,V_keypoints
_includeTorsoOnlyFaces
contextWithPhotoLibrary:
initWithPhotoLibrary:
faceClusteringThreshold
setFaceClusteringThreshold:
faceClusteringJunkThreshold
setFaceClusteringJunkThreshold:
faceClusteringAgeThreshold
setFaceClusteringAgeThreshold:
faceMergeFaceprintDistanceThreshold
setFaceMergeFaceprintDistanceThreshold:
facePrimarySuggestionsThreshold
setFacePrimarySuggestionsThreshold:
minimumSuggestionSize
setMinimumSuggestionSize:
quarantineTwinsOnAssetEnabled
setQuarantineTwinsOnAssetEnabled:
minFaceCountToTriggerClustering
setMinFaceCountToTriggerClustering:
maxFaceCountForClustering
setMaxFaceCountForClustering:
suggestionsLogEnabled
setSuggestionsLogEnabled:
faceClusteringDisabled
setFaceClusteringDisabled:
minimumFaceGroupSizeForCreatingMergeCandidates
setMinimumFaceGroupSizeForCreatingMergeCandidates:
personBuildingDisabled
setPersonBuildingDisabled:
personBuilderMergeCandidatesDisabled
setPersonBuilderMergeCandidatesDisabled:
advancedStatusMergeCandidateLimit
setAdvancedStatusMergeCandidateLimit:
advancedStatusVerifiedPersonLimit
setAdvancedStatusVerifiedPersonLimit:
clusterIncludeTorsoOnlyFaces
setClusterIncludeTorsoOnlyFaces:
processingVersion
setProcessingVersion:
_quarantineTwinsOnAssetEnabled
_suggestionsLogEnabled
_faceClusteringDisabled
_personBuildingDisabled
_personBuilderMergeCandidatesDisabled
_clusterIncludeTorsoOnlyFaces
_faceClusteringThreshold
_faceClusteringJunkThreshold
_faceClusteringAgeThreshold
_faceMergeFaceprintDistanceThreshold
_facePrimarySuggestionsThreshold
_processingVersion
_minimumSuggestionSize
_minFaceCountToTriggerClustering
_maxFaceCountForClustering
_minimumFaceGroupSizeForCreatingMergeCandidates
_advancedStatusMergeCandidateLimit
_advancedStatusVerifiedPersonLimit
Tf,V_faceClusteringThreshold
Tf,V_faceClusteringJunkThreshold
Tf,V_faceClusteringAgeThreshold
Tf,V_faceMergeFaceprintDistanceThreshold
Tf,V_facePrimarySuggestionsThreshold
TQ,V_minimumSuggestionSize
TB,V_quarantineTwinsOnAssetEnabled
TQ,V_minFaceCountToTriggerClustering
TQ,V_maxFaceCountForClustering
TB,V_suggestionsLogEnabled
TB,V_faceClusteringDisabled
TQ,V_minimumFaceGroupSizeForCreatingMergeCandidates
TB,V_personBuildingDisabled
TB,V_personBuilderMergeCandidatesDisabled
TQ,V_advancedStatusMergeCandidateLimit
TQ,V_advancedStatusVerifiedPersonLimit
TB,V_clusterIncludeTorsoOnlyFaces
Ti,V_processingVersion
imageCreationOptions
phFacesFromVCPPhotosFaces:withFetchOptions:
_vnFaceAttributeAgeToPHFaceAgeTypeMap
mad_PHValueFromVNAgeCategoryLabel:
_vnFaceAttributeSexToPHFaceSexTypeMap
mad_PHValueFromVNSexCategoryLabel:
_vnFaceAttributeEyesToPHEyesStateMap
mad_PHValueFromVNEyesCategoryLabel:
_vnFaceAttributeSmileToPHFaceSmileTypeMap
mad_PHValueFromVNSmilingCategoryLabel:
_vnFaceAttributeFacialHairToPHFacialHairTypeMap
mad_PHValueFromVNFaceHairCategoryLabel:
_vnFaceAttributeHairColorToPHFaceHairColorTypeMap
mad_PHValueFromVNHairColorCategoryLabel:
_vnFaceAttributeGlassesToPHFaceGlassesTypeMap
mad_PHValueFromVNGlassesCategoryLabel:
_vnFaceAttributeFacialHairToPHFaceExpressionType
mad_PHValueFromVNExpressionCategoryLabel:
_vnFaceAttributeHeadGearToPHFaceHeadGearType
mad_PHValueFromVNHeadgearCategoryLabel:
_vnFaceAttributeHairTypeToPHFaceHairType
mad_PHValueFromVNFaceHairCategoryV2Label:
_vnFaceAttributePoseToPHFacePoseType
mad_PHValueFromVNPoseCategoryLabel:
_vnFaceAttributeSkintoneToPHFaceSkintoneType
mad_PHValueFromVNSkintoneCategoryLabel:
_vnFaceAttributeEthnicityToPHFaceEthnicityType
mad_PHValueFromVNEthnicityCategoryLabel:
_vnFaceGazeDirectionToPHFaceGazeType
mad_VNFaceGazeDirectionDescription:
mad_PHFaceGazeTypeDescription:
mad_PHValueFromVNFaceGazeDirection:
assignPropertiesOfVCPPhotosFace:toPHFaceChangeRequest:
phFaceFromVCPPhotosFace:withFetchOptions:
_firstLocallyAvailableResourceFromResources:
resourceForFaceProcessing:allowStreaming:
preferredResourcesForFaceProcessingWithAsset:
resourceForFaceProcessingWithAsset:allowStreaming:
configureVNRequest:withClass:andVisionRevision:
configureVNRequest:withClass:andProcessingVersion:
faceRectFromNormalizedCenterX:normalizedCenterY:normalizedSize:sourceWidth:sourceHeight:
sceneprintBlob
setSceneprintBlob:
_sceneprintBlob
T@"NSData",&,N,V_sceneprintBlob
hasFaceId
hasBounds
absoluteScore
setAbsoluteScore:
relativeScore
setRelativeScore:
humanScore
setHumanScore:
faceId
setFaceId:
_absoluteScore
_faceId
_humanScore
_relativeScore
Tf,N,V_absoluteScore
Tf,N,V_relativeScore
Tf,N,V_humanScore
T@"NSString",&,N,V_faceId
rectValue
boundsWithCGRect:
convertAnalysisResult
_analysisSessionRef
contentAnalysis
copyBlock:withStride:toBlock:
blockContentDetection:
detectPixelBuffer:contentType:
_input
_previousContentType
_argbPixelBuffer
_argbTransferSession
autoLiveMotionScore:
initWithQueue:turbo:
prewarmWithWidth:height:
generateThresholds:withConfidences:
cameraMotionDetection:
computeMotionDivScore:
analyzeFrame:withTimestamp:andDuration:completion:
motionDivScore
_frame
_stats
_cameraMotionParams
_cameraMotionConfidences
_turbo
_motionDivScore
Tf,R,V_actionScore
Tf,R,V_motionDivScore
initWithObject:fromPool:
object
_object
_pool
T@,R,N,V_object
objectPoolWithAllocator:
initWithAllocator:
getObject
returnObject:
_allocator
_objects
forward
loadWeights:inputDim:outputDim:quantFactor:
includeNSFW
includeLM
includeSE
includeSDG
includeWP
includeDO
includeSO
includeMeme
includeRotation
includeDocument
includeIVS
includePA
includeCN
includeJunk
includeDMF
sharpnessRevision
isDimensionUnknown:
_cachedRequestIdealDimension
gatherAvailableRequests
mapAvailableRequestsToResolution
aestheticsRequest
setAestheticsRequest:
classificationRequest
setClassificationRequest:
sceneprintRequest
setSceneprintRequest:
saliencyRequest
setSaliencyRequest:
junkImageRequest
setJunkImageRequest:
objectRequest
setObjectRequest:
saliencyObjectnessRequest
setSaliencyObjectnessRequest:
landmarkRequest
setLandmarkRequest:
nsfwRequest
setNsfwRequest:
tabooRequest
setTabooRequest:
semanticRequest
setSemanticRequest:
sceneprintRawRequest
setSceneprintRawRequest:
memeRequest
setMemeRequest:
adjustmentsRequest
setAdjustmentsRequest:
documentRequest
setDocumentRequest:
cityNatureRequest
setCityNatureRequest:
imagefingerprintsRequest
setImagefingerprintsRequest:
_aestheticsRequest
_classificationRequest
_sceneprintRequest
_saliencyRequest
_junkImageRequest
_objectRequest
_saliencyObjectnessRequest
_landmarkRequest
_nsfwRequest
_tabooRequest
_semanticRequest
_sceneprintRawRequest
_memeRequest
_adjustmentsRequest
_documentRequest
_cityNatureRequest
_imagefingerprintsRequest
T@"VNClassifyImageAestheticsRequest",&,N,V_aestheticsRequest
T@"VNSceneClassificationRequest",&,N,V_classificationRequest
T@"VNCreateSceneprintRequest",&,N,V_sceneprintRequest
T@"VNGenerateAttentionBasedSaliencyImageRequest",&,N,V_saliencyRequest
T@"VNClassifyJunkImageRequest",&,N,V_junkImageRequest
T@"VNRecognizeObjectsRequest",&,N,V_objectRequest
T@"VNGenerateObjectnessBasedSaliencyImageRequest",&,N,V_saliencyObjectnessRequest
T@"VNClassifyPotentialLandmarkRequest",&,N,V_landmarkRequest
T@"VNVYvzEtX1JlUdu8xx5qhDI",&,N,V_nsfwRequest
T@"VN6Mb1ME89lyW3HpahkEygIG",&,N,V_tabooRequest
T@"VN5kJNH3eYuyaLxNpZr5Z7zi",&,N,V_semanticRequest
T@"VNCreateSceneprintRequest",&,N,V_sceneprintRawRequest
T@"VNClassifyMemeImageRequest",&,N,V_memeRequest
T@"VN1JC7R3k4455fKQz0dY1VhQ",&,N,V_adjustmentsRequest
T@"VNRecognizeDocumentElementsRequest",&,N,V_documentRequest
T@"VNClassifyCityNatureImageRequest",&,N,V_cityNatureRequest
T@"VNCreateImageFingerprintsRequest",&,N,V_imagefingerprintsRequest
setFaceQuality:
setHasFaceQuality:
hasFaceQuality
eyeExpression
setEyeExpression:
mouthExpression
setMouthExpression:
setYaw:
position
setPosition:
isCloseup
setIsCloseup:
faceQuality
_eyeExpression
_faceQuality
_mouthExpression
_position
_yaw
_isCloseup
Ti,N,V_eyeExpression
Ti,N,V_mouthExpression
Ti,N,V_yaw
Ti,N,V_position
TB,N,V_isCloseup
Tf,N,V_faceQuality
decideSegmentPointBasedOn:
processFrameMetadata:
mergeSimilarSegments
_hinkleyDetector
_activeSegment
_mutableResults
_internalResults
_frameTimeRange
T@"NSArray",R,&,N
resetSegment:
updateSegment:
finalizeAtTime:
initWithAbsMotion:atTime:
resetSegment:atTime:
updateSegment:atTime:
absMotion
setAbsMotion:
stabilityScore
setStabilityScore:
_absMotion
_stabilityScore
Tf,V_absMotion
Tf,V_stabilityScore
service
_service
T@"VIService",R,N
T@"VCPProtoTime",&,N,V_timestamp
vcp_mediaAnalysisBundle
initWithParameters:inputNames:outputNames:properties:
prepareModelWithConfig:
prepareModelInput:
prepareModelInputs:
espressoForward:
espressoForwardInputs:
normalization:
softmax
getEspressoContext
getPlanPhase
inputBlobs
setInputBlobs:
outputBlobs
setOutputBlobs:
inputBlob
setInputBlob:
outputBlob
setOutputBlob:
resConfig
_netFileUrl
_inputNames
_inputBlobs
_outputBlobs
_inputBlob
T{vector<espresso_buffer_t, std::allocator<espresso_buffer_t>>=^{?}^{?}{__compressed_pair<espresso_buffer_t *, std::allocator<espresso_buffer_t>>=^{?}}},N,V_inputBlobs
T{vector<espresso_buffer_t, std::allocator<espresso_buffer_t>>=^{?}^{?}{__compressed_pair<espresso_buffer_t *, std::allocator<espresso_buffer_t>>=^{?}}},N,V_outputBlobs
T{?=^v^v[4Q][4Q]QQQQQQQQQQi},N,V_inputBlob
T{?=^v^v[4Q][4Q]QQQQQQQQQQi},N,V_outputBlob
T@"NSString",R,N,V_resConfig
sharedModelPool
createModel
analyzeWithSceneprint:results:cancel:
_inputsData
vcp_isMercuryBase64
vcp_mercuryBase64ToLocalIdentifier
sharedDatabaseManager
sharedDatabaseForPhotoLibrary:
_databases
initWithImage:edgeMap:width:height:widthExtension:heightExtension:
detectWithSigma:lowThreshold:highThreshold:
noiseReduction:sigma:imageFiltered:
gradientEstimation:width:height:gradient:gradientMag:
isInImage:width:height:
_widthPadded
_heightPadded
_widthExt
_heightExt
_gradient
_image
_imageFiltered
_nonMaxSuppressed
_gradientX
_gradientY
_gradientMag
_edgeMap
mode
videoCaptionEncoderTestURL
videoCaptionDecoderTestURL
imageCaptionModelTestURL
cloneCaptionModel:to:
initWithFrameRate:timeRange:
downloadVideoCaptionEncoderIfNeeded
configInputBasedOnDevice
inference:duration:
_inputNumFrames
_skipNumFramesBothEnds
_frameIndex
_videoCaptionResult
_activeFrameIndices
_videoCaptionDecoder
_videoCaptionEncoder
_downloadGroup
_videoCaptionEncoderAsset
initWithTrack:
initWithTrack:timerange:
findNextSample:timerange:
decodeSample:sample:
decodeTask
copyNextSampleBuffer
_assetReader
_trackReader
_timerange
_launchOnce
_group
_inputSemaphore
_outputSemaphore
_cancelDecode
_decodeError
_decodeFinished
_decodedFrames
_outputFrameIdx
_sampleBuffer
classificationType
clearClassifications
addClassification:
classificationsCount
classificationAtIndex:
classifications
setClassifications:
_classifications
T@"NSMutableArray",&,N,V_classifications
wrapperWithImageprintType:version:andData:
generateVNImageprintWithType:archiveData:andError:
initWithImageprintType:version:andData:
calculateDistance:toWrapper:andError:
version
data
_version
_data
TQ,R,N,V_type
Ti,R,N,V_version
T@"NSData",R,N,V_data
isLivePhotoKeyFrameEnabled
initWithTransform:timeRange:isLivePhoto:frameStats:keyFrameResults:
keyFrameScores
analyzeFrame:withTimestamp:
loadKeyFrameResults:
preparePostProcessingStatsFromFaceRange:junkResults:
postProcess
keyFrames
setBlurAnalyzerFaceResults:
computeFaceQualityOfFrame:
computeSharpnessOfFrame:
finalizeKeyFrame
adjustScoreByFace
modulateByTimeRange
modulateByExposure
modulateByJunk
setKeyFrameTime:isHeadingFrame:
prepareFrameStats:
computeMinDistanceBetween:withSet:
_blurAnalyzer
_faceQualityAnalyzer
_junkResults
_keyFrames
_activeKeyFrame
_isLivePhoto
_keyFrameScores
_inputKeyFrameResults
T{?={?=qiIq}{?=qiIq}},R,N,V_timeRange
sharedManager
sharedInstanceWithIdentifier:andCreationBlock:
resetSharedInstanceWithIdentifier:
reset
serialQueue_
sharedInstances_
copyNextMetadataGroup
_reader
_readerOutput
_readerOutputAdaptor
_countMediaAnalysisWithAssetBatch:andDatabase:analyzedCount:completeAnalyzedCount:partialAnalyzedCount:
_countFaceAnalysisWithAssetBatch:
_countSceneAnalysisWithAssetBatch:
_countOCRAnalysisWithAssetBatch:
_countVisualSearchAnalysisWithAssetBatch:
_countEmbeddingAnalysisWithAssetBatch:
_countAnalysisWithAssetBatch:andDatabase:andTaskID:
_countFailuresWithAssetBatch:andDatabase:andTaskID:
_vipStatusForPhotoLibrary:andType:
_scanPhotoLibrary:withTaskID:statistics:andExtendTimeoutBlock:
_processedPredicateForTaskID:
_queryProgressDetailExpressEmbeddingAnalysis:forPhotoLibrary:
_queryProgressDetailExpress:forPhotoLibrary:andTaskID:
_screenProgress
reportProgressForPhotoLibrary:taskID:logMessage:withExtendTimeoutBlock:
initWithParameters:filterNum:chunk:reLU:padding:groups:stride:batchNorm:
isFilterSizeSupported:
readFromDisk:quantFactor:
straightForwardForChunkFour
chunkFourForward
CalculateDotProductOfChunk
attachSalientRegions:toPixelBuffer:
salientRegionsFromPixelBuffer:
initWithPlistRepresentation:
plistRepresentation
updateConfidence:prevBound:newBound:width:height:
isOutOfBoundary:
pruneRegions:withOverlapRatio:
boundDistance:relativeTo:landscape:
_detections
_latestRegions
_saliencyAnalyer
_trackers
_confidences
_activeRegions
handDistance:withhandB:
processSampleBuffer:withOptions:error:
associateHands:withExisingHands:
_handID
_existingHands
sharedModel:inputNames:
prepareWithLightweightOption:aspectRatio:forceCPU:sharedModel:flushModel:
prepareModel
reInitModel
analyzeImages:secondImage:cancel:
getFlowWithHeight:andWidth:
getFlowToBuffer:
flowScalingTo:scalerX:scalerY:
flowScalingTo:flowBufferY:scalerX:scalerY:
updateModelForAspectRatio:computationAccuracy:
_flow
_sharedModel
_flushModel
analyzeImageQuality:irisPhotoOffsetSec:cancel:
Tf,R,V_qualityScore
addRequest:withConfiguration:error:
removeRequest:error:
shouldProcessSampleWithTimeRange:atSamplingInterval:
processSampleBuffer:withEndTime:error:
processSampleBuffer:error:
flushWithEndTime:error:
orientation
setOrientation:
_nodes
_modified
_startTime
_nextSampleBuffer
_frameCount
TI,N,V_orientation
setFaceSharpness:
setHasFaceSharpness:
hasFaceSharpness
faceSharpness
_faceSharpness
Tf,N,V_faceSharpness
personVIPModelFileName
petVIPModelFileName
faceObservationFromFaceprintData:
animalObservationFromAnimalprintData:
newMutablePersonsModel
petClassificationThreshold
classifyFaceObservation:withModel:error:
classifyAnimalObservation:withModel:error:
_loadModelAtPath:error:
_loadPetsModelAtPath:error:
loadVIPModelAtPath:withVIPType:error:
persistModel:toPath:error:
persistPetsModel:toPath:error:
addFaceObservations:forPersonIdentifier:toModel:error:
detect:withConfidence:dominantLine:
prepareImage:
calculateOrientationResponses
extractUsefulAreaFrom:to:withOffset:stridePadded:width:height:
averageOrientationResponses:withCurrentMap:
generateOrientationMap
smoothFiltering:width:height:
voteVanishingPoint:
searchVanishingPointandDominantLine:lineGroup:vanishingPoint:vanishingPointConfidence:dominantLine:
calculateConfidence:lineDistance:vaninshingPoint:vanishingPointConfidence:
isVerticalOrHorizontal:
generateLineWeightMap:weightMap:
_orientationResponses
_orientionMap
_confidenceMap
_edgeWeightMap
_stride
_stridePadded
_offset
_validDimension
_pixelMean
_pixelVar
_gaborFilter
detect
prepareData:
analyzeBodyArray:
keypointsFromObservations:
_inputChannels
_inputSize
_action
_poseRequest
_bodyArray
_valid
_keyPersonResults
analyzerWith:prune:
initWithMaxNumRegions:prune:
prepareModelForSourceWidth:andSourceHeight:
copyImage:toData:withChunk:
scaleImage:toData:withWidth:andHeight:
computeScore:width:height:posX:posY:
outputScaling
generateSalientRegion:outHeight:outWidth:
getSalientRegions:
saliencyDetection:salientRegions:cancel:
processTile:results:cancel:
aggregateTileResults:tileRect:imageSize:landscape:results:
pruneRegions:
_chunk
_region
_score
_maxNumRegions
_prune
vcp_mediaAnalysisDirectory
vcp_mediaAnalysisDatabaseFilepath
vcp_anyAssetsForTaskID:
vcp_assetCountForTaskID:
vcp_assetCountWithMediaType:forTaskID:
vcp_assetCountWithInternalPredicate:forTaskID:
vcp_isCPLEnabled
vcp_isCPLSyncComplete
vcp_isCPLDownloadComplete
vcp_eligibleForStreaming:
vcp_supportsInMemoryDownload
vcp_allowInMemoryDownload
vcp_libraryScaleShortDescription
vcp_visionCacheStorageDirectoryURL
_analysisPreferencesURL
vcp_analysisPreferences
_updateAnalysisPreferencesWithEntries:keysToRemove:
vcp_setAnalysisPreferencesValue:forKey:
vcp_vipModelFilepathForVIPType:
vcp_vipModelLastGenerationDateForVIPType:
vcp_faceAnalysisStateFilepath
mad_unclusteredFacesFetchOptions
mad_countOfUnclusteredFaces
vcp_isSyndicationLibrary
vcp_requiresProcessingForTask:
vcp_requiredFaceLibraryProcessingSubTasks
vcp_description
vcp_requiresDownloadForTask:
vcp_defaultPhotoLibrary
vcp_defaultURL
vcp_defaultMediaAnalysisDatabaseFilepath
isSettlingEffectPregatingEnabled
initWithAnalysisTypes:transform:timeRange:isLivePhoto:photoOffset:frameStats:hadFlash:hadZoom:keyFrameResults:isTimelapse:preferredTimeRange:asset:
setMaxHighlightDuration:
analyzeKeyFrame:withTimestamp:andDuration:flags:
loadVideoAnalysisResults:audioAnalysisResults:videoCNNResults:andFaceRanges:frameSize:
postProcessKeyFrames
generateMovieCurations
audioQualityScore:
addHighlight:to:
addSummary:to:
addSettling:to:
reportMovieCurationAnalysisResults:withSummaryAnalytics:
_keyFrameAnalyzer
_highlightAnalyzer
_descriptorResults
_qualityResuls
_petsResults
_actionResults
_subtleMotionResults
_voiceResults
_audioQualityResults
_humanActionResults
_humanPoseResults
_cameraMotionResults
_saliencyResults
_orientationResults
_mlHighlightScoreResults
_mlQualityResults
_frameSize
_hadFlash
_hadZoom
initWithTimeRange:
isShort
copyScoresFrom:
checkAutoPlayable
timerange
setTimerange:
setScore:
averageScore
setAverageScore:
junkScore
setJunkScore:
expressionScore
setExpressionScore:
voiceScore
setVoiceScore:
humanActionScore
setHumanActionScore:
humanPoseScore
setHumanPoseScore:
bestPlaybackCrop
setBestPlaybackCrop:
isAutoPlayable
setIsAutoPlayable:
isTrimmed
setIsTrimmed:
descriptor
setDescriptor:
keyFrame
setKeyFrame:
colorNormalization
setColorNormalization:
isSettlingOK
setIsSettlingOK:
autoplayScore
setAutoplayScore:
motionScore
setMotionScore:
subjectScore
setSubjectScore:
exposureChangeScore
setExposureChangeScore:
_isAutoPlayable
_isTrimmed
_isSettlingOK
_averageScore
_junkScore
_expressionScore
_voiceScore
_humanActionScore
_humanPoseScore
_autoplayScore
_motionScore
_subjectScore
_exposureChangeScore
_descriptor
_keyFrame
_colorNormalization
_bestPlaybackCrop
T{?={?=qiIq}{?=qiIq}},N,V_timerange
Tf,N,V_score
Tf,N,V_averageScore
Tf,N,V_junkScore
Tf,N,V_expressionScore
Tf,N,V_voiceScore
Tf,N,V_humanActionScore
Tf,N,V_humanPoseScore
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_bestPlaybackCrop
TB,N,V_isAutoPlayable
TB,N,V_isTrimmed
T@"VCPImageDescriptor",&,N,V_descriptor
T@"VCPVideoKeyFrame",&,N,V_keyFrame
T@"NSData",&,N,V_colorNormalization
TB,N,V_isSettlingOK
Tf,N,V_autoplayScore
Tf,N,V_motionScore
Tf,N,V_subjectScore
Tf,N,V_exposureChangeScore
prepareWithLightweightOption:aspectRatio:numLevels:startLevel:cancel:
allocateInputAndOutputBuffers
releaseInputAndOutputBuffers
createModules:
updateModulesWithConfig:
allocateStorages
releaseStorages
allocateCorreleationBuffer:forLevel:
allocateFeatures
releaseFeatureBuffers
extractFeaturesFromFirst:andSecond:
extractFeatureFromImage:toFeature:
estimateMotionFlow:
estimateFlowForLevel:upperFlow:outputFlow:
copyImage:toBuffer:withChannels:
createInput:withImage:modelInputHeight:modelInputWidth:
releaseMemory
_numLevels
_startLevel
_firstBuffer
_secondBuffer
_outputFlow
_featureExtractor
_flowDecoder
_correlation
_backwarp
_imageFeature
_storage
_flowDecoderSemaphore
clsDistanceIdentity
cloudIdentifier
filename
originalFilename
pixelWidth
pixelHeight
creationDate
locationCoordinate
distanceIdentity
T@"NSDate",R,N
T{CLLocationCoordinate2D=dd},R,N
initWithOptions:cancel:
createPixelBufferWithWidth:height:pixelFormat:pixelBuffer:
convertPixelBuffer:toPixelBuffer:withPixelFormat:
estimateMotionBetweenFirstImage:andSecondImage:error:
estimateMotionBetweenFirstImage:andSecondImage:withUpsample:withGuidedImage:error:
_useSingleEspressoModel
_transferSession
sharedManagerForPhotoLibrary:
resetLevelDescription:
_versionStateURL
_updateVersionStateFileWithError:
defaultProcessingVersion
currentProcessingVersion
_updateCurrentProcessingVersion:
resetAnalysisDataWithResetLevel:error:
migrateFaceProcessingToVersion:
_versionState
initWithAVAsset:forAnalysisTypes:
findMetaTrackforType:
processMetaTrackForType:cancel:flags:
checkTimeRangeConsistency
postProcessOrientationResults
analyzeAsset:flags:
_requestedAnalyses
_avAsset
_metaTracks
_publicMutableResults
_privateMutableResults
T@"NSDictionary",R,N
initWithLivePhoto:
loadKeyFrameResult:timestamp:
resetStatsFlag
setFaceStatsFlag:detectedFaces:
setMotionStatsFlag:cameraMotion:subjectAction:interestingness:obstruction:colorfulness:exposureScore:humanActionStatsFlag:humanPoseScore:humanActionScore:subMb:
computeGlobalQualityForLivePhoto
computeGlobalQuality
computeVisualPleasingScore
computeContentScore
computePenaltyScore
storeFrameResults
computeCurationScoreComponents
computeCurationScore
computeScoreFromAction
computeExpressionScore
computeScoreFromColorfulness
computeScoreFromExposure
hasGoodSubjectAction
printStats
semanticScore
setSemanticScore:
isHeadingFrame
setIsHeadingFrame:
statsFlags
setStatsFlags:
detectedFaces
setDetectedFaces:
faceQualityScores
setFaceQualityScores:
frameResults
setFrameResults:
_subjectAction
_interestingness
_obstruction
_colorfulness
_subMb
_isHeadingFrame
_semanticScore
_statsFlags
_detectedFaces
_faceQualityScores
_frameResults
T{?=qiIq},N,V_timestamp
Tf,N,V_semanticScore
TB,N,V_isHeadingFrame
TQ,N,V_statsFlags
T@"NSMutableArray",&,N,V_detectedFaces
T@"NSMutableArray",&,N,V_faceQualityScores
T@"NSMutableDictionary",&,N,V_frameResults
_sceneprint
shotType
setShotType:
_shotType
Ti,N,V_shotType
initWithMaxNumRegions:
convertResultsToDict:results:
_petsDetector
vcp_taskWithImageAsset:andSignpostPayload:
rotationToEulerAngles:angles:
eulerAnglesToRotation:R:
kalmanFiltering:T:
filteringPose:
_previousState
_previousCovar
_previousStateIsValid
anonymizedName
favorite
setIsVerified:
setManualOrder:
keyFace
setKeyFace:
pv_addMergeCandidatePersons:
personLocalIdentifiers
faceCount
verifiedType
isVerified
manualOrder
T@"<PVFaceProtocol>",&,N
TB,D,N
exportToLegacyDictionaryFromFrameInstruction:
exportToLegacyDictionaryFromParam:withLoopFlavor:
setX0:
setY0:
width
setWidth:
height
setHeight:
Td,N,V_x0
Td,N,V_y0
Td,N,V_width
Td,N,V_height
flagsForOrientation:width:height:
faceBounds:height:
faceBoundsWithTransform:height:transform:
leftEyeClosed
setLeftEyeClosed:
rightEyeClosed
setRightEyeClosed:
smile
setSmile:
trackID
setTrackID:
observation
setObservation:
_leftEyeClosed
_rightEyeClosed
_smile
_trackID
_observation
T{CGRect={CGPoint=dd}{CGSize=dd}},V_bounds
TB,V_leftEyeClosed
TB,V_rightEyeClosed
TB,V_smile
Tq,V_yaw
Ti,V_trackID
Tf,V_faceQuality
T@"VNFaceObservation",&,V_observation
start
setStart:
last
setLast:
faceID
setFaceID:
_faceID
_last
T{?=qiIq},V_start
T{?=qiIq},V_last
TQ,V_flags
TQ,V_position
TQ,V_faceID
initWithMode:
isIdentityInit
setCameraIntrinsics:uc:vc:
updateIntrinsic:vc:
updateFocalLengthInPixels:
setupModel:
getEulerAngle:
project3Dto2D:intrinsinc:extrinsic:numVert:out2dpts:
getOneInternalLandmarkCoordinates:lmCoord:lmWeight:lm3dPos:
updateBoundaryLandmarkCoordinates:pts2D:lm2D:lm3dPos:
getInternal3dLandmarksCoordinates:lm3dPos:
updateBoundary3dLandmarkBlendshapes:numBlendshapes:pts2D:lm2D:lmBlendshapes:
moveBoundaryLandmarks:output:isInput:
projectAndUpdateBoundary
updateMeshAndLm3dAfterExpressionChange
resetIdentityAndExpressions
updateIdentityShape:
trackFaceMesh:
updateShapeCoeff:extrinsicMatrix:pts2D:exprWeights:outputblendshapes:
updateBoundaryLmForShapeOptimization
reestimateProjectionMatrixPnP
fitOneImage:
calculateBlendshapeWeights:prevWeights:lmBlendshapes:maxIter:
calculateIdentityCoefficients:extrinsicMatrix:pts2D:exprWeights:lm3DMeanBlendshapes:lm3DComponents:maxIter:
getPoseParam
optimizeProjectionMatrix:tracking:firstPass:
calculatePosePnpSolver:
getPose
blendShapes
updateMeshVertices
processingMode
setProcessingMode:
meshVertices
vertexCount
detectionModeCounterShapeModel
setDetectionModeCounterShapeModel:
_tensorModel
_numVertices
_curMesh
_cur2D
_numInternalLms
_lmCoord
_lmWeight
_numBoundaryLms
_boundaryLmIndices
_numBoundaryVertices
_boundaryVertices
_boundaryLandmarkValidity
_chPts
_chPtSelected
_boundaryLmUpdated
_chCount
_curBlendshapes
_curCoeff
_curExprWeights
_prevExprWeights
_exprWeightDiagMatrix
_transformedCoeff
_blendShapeDelta
_trans
_intrinsicMatrix
_extrinsicMatrix
_eulerAngle
_rotMatrix
_LM2D
_LM3D
_lm3dBlendshapes
_lm3dMeanBlendshapes
_lm3dBlendshapeComponents
_numFrmsSinceLastShapeUpdate
_shapeUpdateInProgress
_poseSolver
_updateShapeGroup
_updateShapeQueue
_asyncBlendshapes
_asyncLmBlendshapes
_asyncExtMat
_asyncLm2d
_asyncWeights
_identityInit
_processingMode
_detectionModeCounterShapeModel
_meshVertices
_vertexCount
Ti,V_processingMode
T^,R,V_meshVertices
TQ,R,V_vertexCount
Ti,V_detectionModeCounterShapeModel
computeLandmarks:
createQueryContextWithError:
_cancellable
vanishingPoint
setVanishingPoint:
dominantLine
setDominantLine:
_dominantLine
_vanishingPoint
T@"VCPProtoPoint",&,N,V_vanishingPoint
T@"VCPProtoLine",&,N,V_dominantLine
faceDetector
faceDetection:faces:cancel:
isDuplicate:withRect:
loadAnalysisResults:
_analysisInput
requestAnalysis:ofIOSurface:withProperties:withReply:
errorWithStatus:andDescription:
requestAnalysis:ofPixelBuffer:withProperties:withCompletionHandler:
_connectionLock
activityID
setActivityID:
startTime
setStartTime:
exitStatus
setExitStatus:
_exitStatus
_activityID
TQ,N,V_activityID
T@"NSDate",N,V_startTime
Td,N,V_duration
Ti,N,V_exitStatus
startPointValue
endPointValue
lineFromPoint:toPoint:
detectPersons:persons:
persons
_persons
homographyParamsCount
homographyParams
clearHomographyParams
addHomographyParam:
homographyParamAtIndex:
setHomographyParams:count:
setTimeValue:
timeScale
setTimeScale:
epoch
setEpoch:
_homographyParams
_epoch
_timeValue
_timeScale
Tq,N,V_timeValue
T^f,R,N
Ti,N,V_timeScale
Tq,N,V_epoch
initWithModelFile:
calculateModelBlendshapes:outputBlendshapes:
calculateMesh:numVertices:blendshapes:outputMesh:
numVertices
meanBlendshape
tensorCoeff
componentsBlendshape
blendshapeComponentIndex
_numBlendshapePlusOne
_numComponents
_numIdentities
_meanBlendshape
_tensorCoeff
_componentsBlendshape
_blendshapeComponentIndex
Ti,R,V_numVertices
T^f,R,V_meanBlendshape
T^f,R,V_tensorCoeff
T^f,R,V_componentsBlendshape
T^i,R,V_blendshapeComponentIndex
entryWithLocalIdentifier:andTaskID:andStatus:andAttempts:andLastRetryDate:
initWithLocalIdentifier:andTaskID:andStatus:andAttempts:andLastRetryDate:
taskID
attempts
lastRetryDate
_taskID
_status
_attempts
_lastRetryDate
TQ,R,N,V_taskID
T@"NSString",R,N,V_localIdentifier
TQ,R,N,V_status
TQ,R,N,V_attempts
T@"NSDate",R,N,V_lastRetryDate
setLoopFadeLen:
setHasLoopFadeLen:
hasLoopFadeLen
setLoopPeriod:
setHasLoopPeriod:
hasLoopPeriod
setLoopStart:
setHasLoopStart:
hasLoopStart
errorCode
setErrorCode:
loopFadeLen
loopPeriod
loopStart
_errorCode
_loopFadeLen
_loopPeriod
_loopStart
Ti,N,V_errorCode
Ti,N,V_loopFadeLen
Ti,N,V_loopPeriod
Ti,N,V_loopStart
vcp_childWithPendingUnitCount:
initWithMaxNumRegions:forceCPU:sharedModel:
analyzePixelBuffer:flags:petsDetections:results:cancel:
_petsKeypointsDetector
initWithFrameStats:
prepareActivityStats
generateActivityDescriptor
normalizeActivityDescriptor
resetActivityStatsAtTime:
computeActivityScoreAtTime:
preProcessQualityResults:interestingnessResults:obstructionResults:classificationResults:fineActionResults:faceResults:sceneSwitchFrequency:
extractRequiredInfoFrom:toArray:
extractRequiredFaceInfoFrom:toArray:
extractRequiredClassificationInfoFrom:toArray:
validationScoreOfTimeRange:fromResult:startIdx:
validateActivityScores
scaleBasedOnFaceForTimeRange:
addSceneSwitchFrequencyConstributionToActivityLevel:
actionScoreInTimeRange:
addSceneClassificationContributionToActivityLevel:
finishAnalysisPass:fpsRate:
_activityDescriptor
_activityScores
_validActivityScores
_qualityResults
_interestingnessResults
_obstructionResults
_classificationResults
_fineActionResults
_sceneSwitchFrequency
_lastProcessTime
_overallActivityLevel
_sportsSceneId
initWithTimerange:andScore:
T{?={?=qiIq}{?=qiIq}},V_timerange
Tf,V_score
analyzeOverallQuality:withFpsRate:
checkCameraZoom:cameraMotionResults:
generateLivePhotoRecommendationForResults:andPrivateResults:usingFaceAction:
assetQualityScoreFromAnalysis:withFpsRate:
assetActionScoreFromAnalysis:
assetExpressionScoreFromAnalysis:
assetVoiceScoreFromAnalysis:
assetCameraMotionScoreFromAnalysis:
hasMeaningfulSceneSegment:withFpsRate:
assetJunkScoreFromAnalysis:
scaleForTimeRange:basedOnFace:
subjectActivityInTimeRange:fromResults:
cameraActivityfromQuality:
isJunkTimeRange:basedOnResults:
assetActivityLevelFromAnalysisResults:
setActivityLevel:
poolingBlockWithPoolX:poolY:chunk:
initWithParameters:poolY:chunk:
constructBlock:context:
useGPU
getMinimumHighlightInSec
initWithAnalysisType:isLivePhoto:photoOffset:hadFlash:hadZoom:isTimelapse:preferredTimeRange:asset:
initWithPostProcessOptions:
prepareRequiredQualityResult:junkDetectionResult:descriptorResult:faceResult:petsResult:saliencyResult:actionResult:subtleMotionResult:voiceResult:keyFrameResult:sceneResults:humanActionResults:humanPoseResults:cameraMotionResults:orientationResults:mlHighlightScoreResults:mlQualityResults:frameSize:
generateHighlights
isGoodQuality:
postProcessMovieHighlight:
targetMovieHighlight:mergedRange:maxRange:
targetProcessRange:maxRange:
targetExtendRange:maxRange:
targetTrimRange:searchRange:
maxTrimMovieHighlight:
loadHighlightScoreResults:
selectHighlightsForTimelapse
computeTrimWithHighlightScoreFor:
selectHighlights
computeColorNormalization
highlightScoreForTimeRange:average:
findBestHighlightSegment:targetTrim:
findBestTrim:
movieSummary
settlingMotionScore:
settlingSubjectScore:
settlingExposureChangeScore:
analyzeMotionStability:motionParamDiff:
settlingEffects
updateCropHeatMap:withResults:timeRange:resultsKey:
computeBestPlaybackCrop:
highlightScoreResults
generateExpressionSegments:
computeQualityTrimFor:withKeyFrame:
computeActionFaceTrimFor:
computeSteadyTranslationTrimFor:
checkCameraZoom:
computeHighlightScoreOfRange:
SetKeyFramesForSegments:
pickKeyFramesInRange:
computeHighlightScoreResults
pickHighlightsFrom:
searchFeatureVectorOfSegment:
evaluateSegment:
addSegment:
computeHighlightScoreOfSegment:
computeExpressionScoreInTimerange:
expressionScoreForTimerange:
computeSubtleMotionScoreInTimerange:
computeActionScoreInTimerange:
computeHumanActionScoreInTimerange:
computeHumanPoseScoreInTimerange:
computeVoiceScoreInTimeRange:
postProcessMLHighlightScore
combineMLHighlightScore
computeMLHighlightScoreForTimerange:
computeMLQualityScoreForTimerange:
analyzeOverallQuality:isSettlingEffect:
qualityScoreForTimerange:
actionScoreForTimerange:
voiceScoreForTimerange:
visualPleasingScoreForTimerange:
cameraMotionScoreForTimerange:
subtleMotionScoreForTimerange:
junkScoreForTimerange:lengthScale:
_featureResults
_keyFrameResults
_expressionSegments
_highlightResults
_internalConstraintResults
_maxDurationInSeconds
_minDurationInSeconds
_targetDurationInSeconds
_toleranceInSeconds
_targetHighlightIndex
_startRange
_isMaxTrim
_requestBestTrim
_requestFullResult
_maxHighlightScore
_minHighlightScore
_photoOffset
_verbose
_preferredTimeRange
_imageGenerator
_numberOfFrames
_prevMotionParamDiff
_sumMotionParam
_diffFlipCount
_colorNormalizationAnalyzer
startSessionWithProperties:andReply:
processMessageWithOptions:andReply:
processVideoFragmentAssetData:withOptions:andReply:
processResults:withReply:
sessionWithProperties:andResultsHandler:
sessionWithProperties:withResultsHandler:andInterruptionHandler:
initWithProperties:withResultsHandler:andInterruptionHandler:
processVideoFragmentAssetData:withOptions:andErrorHandler:
processVideoFragmentAssetData:withOptions:andCompletionHandler:
processMessageWithOptions:andCompletionHandler:
_formatDescription
_resultsHandler
_interruptionHander
weakSession
setWeakSession:
_weakSession
T@"VCPHomeKitAnalysisSession",W,N,V_weakSession
shouldQueryInternalFields
databaseForPhotoLibrary:
exists
openDatabase
closeDatabase
parseHeader:startColumn:analysis:
parseResults:typeColumn:dataColumn:results:
queryHeaderForAsset:analysis:assetId:
queryResultsForAssetId:analysis:
queryResultsForAssetId:withTypes:analysis:
queryHeadersForAssets:analyses:idMap:
queryResultsForAssets:withTypes:batchResults:
executeDatabaseBlock:
isAssetBlacklisted:blacklistDate:
blacklistedLocalIdentifiersFromAssets:
queryBlacklistedLocalIdentifiers
queryAnalysisForAsset:
queryAnalysisPropertiesForAsset:
queryAnalysisPropertiesForAssets:
queryAnalysisForAsset:withTypes:
queryAnalysesForAssets:withTypes:
queryAssetsAnalyzedSince:
queryFailedProcessingStatusFromAssets:forTaskID:
queryLocalIdentifiersForTaskID:withStatus:
countForTaskID:withProcessingStatus:
_queryValue:forKey:
valueForKey:
querySchedulingHistoryRecords:forActivityID:sinceDate:
_sqlSerialQueue
_filepath
value
setValue:
timescale
setTimescale:
_value
_timescale
Tq,N,V_value
Ti,N,V_timescale
TI,N,V_flags
mediaType
mediaSubtypes
modificationDate
mainFileURL
scenes
_imageURL
_movie
_mediaType
_mediaSubtypes
_pixelWidth
_pixelHeight
_onceExif
_cachedExif
_onceScenes
_cachedScenes
initWithImageURL:isSDOF:
exif
imageWithPreferredDimension:
imageWithPreferredDimension:orientation:
imageAssetWithURL:
sdofImageAssetWithURL:
photoOffsetSeconds
initWithImageURL:andMovieURL:
originalPhotoOffsetSeconds
livePhotoAssetWithImageURL:andMovieURL:
initWithMovieURL:
slowmoRate
slomoRange
movie
isMovieResourceLocalAvailable
originalMovie
movieAssetWithURL:
initWithProperties:forAnalysisTypes:
transformUprightAboutTopLeft:
addFaceResults:flags:
analyzeAsset:results:
_properties
taskWithOptions:andCompletionHandler:
initWithOptions:andCompletionHandler:
isCanceled
cancelBlock
setCancelBlock:
_cancelBlock
T@?,C,N,V_cancelBlock
initWithCompletionHandler:
taskWithCloudIdentifierRequests:photoLibrary:clientBundleID:clientTeamID:cancelBlock:andCompletionHandler:
initWithCloudIdentifierRequests:photoLibrary:clientBundleID:clientTeamID:cancelBlock:andCompletionHandler:
assetWithIdentifier:isCloudIdentifier:error:
signpostPayload
setSignpostPayload:
_requests
_photolibrary
_clientBundleID
_clientTeamID
T@"NSString",&,N,V_signpostPayload
sharedModel:outputNames:properties:
initWithConfig:
outputBeforeFc
outputBeforeSpatiialPooling
outputRes4
outputBeforeTemporalPooling
_outputBeforeFc
_outputBeforeSpatiialPooling
_outputRes4
_outputBeforeTemporalPooling
T^f,R,V_outputBeforeFc
T^f,R,V_outputBeforeSpatiialPooling
T^f,R,V_outputRes4
T^f,R,V_outputBeforeTemporalPooling
_pcmBuffer
_framePosition
_loudnessAnalyzer
_processFormat
_sampleRate
_peakValues
_momentaryEnergyValues
_loudnessSampleBuffer
_loudnessResults
_samplesFor100ms
_samplesForProcessingBufferList
activityScore
setActivityScore:
_activityScore
Tf,N,V_activityScore
analyzeCGImage:results:
_sessionPool
createOutputMetadataFromDictionary:
newDictionaryPopulatedWithFaceCropDataFromImageData:
newDictionaryRepresentationOfFaceCropDataFromFaceBox:andCropRegion:andGroupingIdentifier:
newFaceCropFromCGImageSource:withFaceRect:groupingIdentifier:error:
newFaceCropFromImageURL:withNormalizedFaceRect:groupingIdentifier:error:
newFaceCropFromImageData:withFaceRect:groupingIdentifier:error:
isValidFaceCrop:
faceBoundsFromFaceCrop:error:
cropBoundsInOriginalImageFromFaceCrop:error:
groupingIdentifierFromFaceCrop:error:
faceCropDimensionsFromFaceCrop:error:
_persistFaces:forAsset:
processAsset:
_faceAnalyzer
vcp_textAnnotation
vcp_scenenetAnnotation
vcp_annotationWithTypes:
enableGating
canReuseResultsForRequest
flagsFromKeypoints:withMinConfidence:
torsoprint
setTorsoprint:
_torsoprint
T@"VNTorsoprint",&,V_torsoprint
initModelWithName:andConfig:
initModule:config:cancel:
bindWithBuffers:correlation:flow:outputFlow:
estimateFlow:correlation:flow:outputFlow:callback:
_inputBlobNames
_outpuBlobName
interestScore
setInterestScore:
_interestScore
Tf,N,V_interestScore
initWithModelFile:paramFile:numTri:triList:angle:
validateOneImage:landmarks:numofLandmarks:score:
_transArray
_meanLandmarkLoc
_triIndexMap
_numTri
_triList
T^f,V_orientation
saveStabilizationRecipe
videoStabilizerforAnalysisType:withMetadata:sourceSize:cropRect:
analysisResultRef
setAnalysisResultRef:
correctionResultRef
setCorrectionResultRef:
setResults:
cropFraction
setCropFraction:
motionBlurVector
setMotionBlurVector:
gyroStabilization
setGyroStabilization:
analysisConfidence
setAnalysisConfidence:
validStabilization
setValidStabilization:
_gyroStabilization
_validStabilization
_cropFraction
_analysisConfidence
_analysisResultRef
_correctionResultRef
_motionBlurVector
T^v,N,V_analysisResultRef
T^v,N,V_correctionResultRef
T@"NSDictionary",&,N,V_results
Tf,N,V_cropFraction
T@"NSMutableArray",&,N,V_motionBlurVector
TB,N,V_gyroStabilization
Tf,N,V_analysisConfidence
TB,N,V_validStabilization
persistenceDelegate_enumerateInChunksOfSize:withOverageAllowance:usingBlock:
resultsAsArray
resultsAsSet
mergeCandidatePairWithPerson:andPerson:reason:
initWithPerson:andPerson:reason:
person1LocalIdentifier
person2LocalIdentifier
reason
_hash
_person1LocalIdentifier
_person2LocalIdentifier
_reason
T@"NSString",R,V_person1LocalIdentifier
T@"NSString",R,V_person2LocalIdentifier
T@"NSString",R,V_reason
newAllPersonsWithAtLeastOneFaceFetchOptionsWithPhotoLibrary:
newAssetFetchOptionsWithPhotoLibrary:
newAllFacesFetchOptionsWithPhotoLibrary:
newVisibleFacesFetchOptionsWithPhotoLibrary:
newFacesDeterministicSortDescriptors
newAllPersonsFetchOptionsWithPhotoLibrary:
newVerifiedPersonsFetchOptionsWithPhotoLibrary:
enumerateFetchResult:withBatchSize:handler:
newVerifiedPersonsWithAtLeastOneFaceFetchOptionsWithPhotoLibrary:
keyFaceForPerson:qualityMeasureByFace:updateBlock:
suggestedMeIdentifierWithPersonClusterManager:forPersons:updateBlock:
performSocialGroupsIdentifiersWithPersonClusterManager:forPersons:overTheYearsComputation:updateBlock:
densityClusteringForObjects:maximumDistance:minimumNumberOfObjects:withDistanceBlock:
countOfFaces
countOfClusteringEligibleFaces
countOfUnclusteredClusteringEligibleFaces
countOfClusteredFaces
unclusteredClusteringEligibleFaceLocalIdentifiers:
deterministicallyOrderedFaceIdentifiersWithLocalIdentifiers:faceprintVersion:
facesForClusteringWithLocalIdentifiers:faceprintVersion:groupingIdentifiers:
invalidFaceClusterSequenceNumbersInClusterSequenceNumbers:cancelOrExtendTimeoutBlock:error:
_categorizeGroupedFacesInFetchResult:intoFaceLocalIdentifiersByFaceGroup:ungroupedFaceLocalIdentifiers:cancelOrExtendTimeoutBlock:photoLibrary:
ungroupFaceClusterSequenceNumbers:batchSizeForUnclusteringFaces:cancelOrExtendTimeoutBlock:error:
_ungroupFaceClusterSequenceNumbers:cancelOrExtendTimeoutBlock:error:
_fetchResultForGroupedFacesWithClusterSequenceNumberSetToZeroInPhotoLibrary:
_fetchResultForUngroupedFacesWithNonZeroClusterSequenceNumberInPhotoLibrary:
_resetFaceClusterSequenceNumberOfFacesInFetchResult:inPhotoLibrary:cancelOrExtendTimeoutBlock:error:
cleanupUngroupedFacesWithNonZeroClusterSequenceNumbers:error:
cleanupGroupedFacesWithClusterSequenceNumberSetToZero:error:
_facesFromFaceGroupWithMostNumberOfFacesOnPerson:options:error:
_localIdentifiersOfUnverifiedPersonsAssociatedWithFaceGroups:cancelOrExtendTimeoutBlock:
identifyConflictingL0Clusters:csnToRejectedPersonForNewlyClusteredFaces:csnToConfirmedPersonForNewlyClusteredFaces:
persistChangesToAlgorithmicFaceGroups:l1ClustersByFaceCSNRepresentingFaceGroup:l0ClustersByFaceCSNRepresentingFaceGroup:faceCSNByLocalIdentifierForNewlyClusteredFaces:faceCSNsOfUnclusteredFaces:localIdentifiersOfUnclusteredFaces:persistenceCompletionBlock:cancelOrExtendTimeoutBlock:error:
resetLibraryClustersWithCancelOrExtendTimeoutBlock:error:
deleteEmptyGroupsAndReturnError:
updateKeyFacesOfPersonsWithLocalIdentifiers:forceUpdate:cancelOrExtendTimeoutBlock:error:
bestRepresentativeFaceForPerson:qualityMeasureByFace:cancelOrExtendTimeoutBlock:
bestRepresentativeFaceForPerson:qualityMeasureByFace:candidateFaces:cancelOrExtendTimeoutBlock:
_representativenessByFaceCSNFromFaces:cancelOrExtendTimeoutBlock:
_faceToFaceCountMapForFaces:
groupedClusterSequenceNumbersOfFacesInFaceGroupsOfMinimumSize:error:
invalidFaceClusterSequenceNumbersInClusterSequenceNumbers:canceler:error:
ungroupFaceClusterSequenceNumbers:batchSizeForUnclusteringFaces:canceler:error:
cleanupUngroupedFacesWithNonZeroClusterSequenceNumbersWithCanceler:error:
cleanupGroupedFacesWithClusterSequenceNumberSetToZeroWithCanceler:error:
persistChangesToAlgorithmicFaceGroups:faceCSNByLocalIdentifierForNewlyClusteredFaces:faceCSNsOfUnclusteredFaces:localIdentifiersOfUnclusteredFaces:persistenceCompletionBlock:canceler:error:
resetLibraryClustersWithCanceler:error:
updateKeyFacesOfPersonsWithLocalIdentifiers:forceUpdate:canceler:error:
bestRepresentativeFaceForPerson:qualityMeasureByFace:canceler:
bestRepresentativeFaceForPerson:qualityMeasureByFace:candidateFaces:canceler:
associateFace:withFaceCrop:error:
clearDirtyStateOnFaceCrops:error:
dirtyFaceCropsWithLimit:
faceAssociatedWithFaceCrop:
facesFromAsset:
persistFaces:deleteFaces:forAsset:persistedFaces:error:
persistGeneratedFaceCrops:error:
recordNeedToPersonBuildOnFaceGroupContainingFace:error:
suggestedPersonLocalIdentifierForPersonLocalIdentifier:faceClusterer:canceler:context:error:
updateFaceprint:ofPersistedFace:error:
buildPersonsWithFaceClusterer:keyFaceUpdateBlock:canceler:context:extendTimeoutBlock:
needsPersonBuilding
_cleanupMergeCandidatesForVerifiedPersons:minimumFaceGroupSize:cancelOrExtendTimeoutBlock:error:
cleanupMergeCandidatesWithMinimumFaceGroupSize:cancelOrExtendTimeoutBlock:error:
_updatedFaceGroupByFGLocalIdentifierFromClusterCSNs:fetchLimit:
_enumeratePersonsWithLocalIdentifiers:fetchOptions:personCache:usingBlock:
dedupeGraphVerifiedPersonsInFaceGroup:personCache:
_getMergeCandidates:invalidMergeCandidates:forPersonsWithLocalIdentifiers:
_getTrainingFacesByPerson:confirmedFaceCSNs:faceCSNsByPerson:faceCSNsByMigratedPerson:faceCSNsByQuickClassificationPerson:mergeCandidates:invalidMergeCandidates:rejectedPersonsByPerson:faceInFaceGroupByCSN:inFaces:personCache:cancelOrExtendTimeoutBlock:
_getRejectedTrainingFaceCSNs:rejectedFaceCSNs:rejectedPersonLocalIdentifiers:forPerson:faceInFaceGroupByCSN:
_completePersonBuildingWithPersonsToUpdate:facesToRemoveByPerson:facesToAddByPerson:updateFaceGroup:newMergeCandidatePairs:newInvalidMergeCandidatePairs:faceInFaceGroupByCSN:personCache:keyFaceUpdateBlock:cancelOrExtendTimeoutBlock:context:error:
_level0ClusterIdForFaceCSN:level0Clusters:
otherFacesOnAssetWithFace:options:
_duplicateFaceCSNsOnAssetForPerson:faceCSNsOnPerson:faceByCSNCache:
_updateFaceCSNsToAddByPerson:faceCSNsToRemoveByPerson:faceInFaceGroupByCSN:faceCSNsByPersonLocalIdentifier:faceCSNsByMigratedPersonLocalIdentifier:personsToUpdate:
_adjustConfirmingAndRejectionWithFaces:faceCrops:cancelOrExtendTimeoutBlock:
_detectDuplicationInExistingFaceCrops:withFetchedFaces:faceCropFaceIdentifiersToEvaluate:duplicationResults:cancelOrExtendTimeoutBlock:
_processNewlyClusteredFaceCropsInFaceGroups:cancelOrExtendTimeoutBlock:
_buildPersonsFromUpdatedFaceGroups:faceClusterer:keyFaceUpdateBlock:cancelOrExtendTimeoutBlock:context:
buildPersonWithFaceClusterer:keyFaceUpdateBlock:context:cancelOrExtendTimeoutBlock:
fetchFaceWithLocalIdentifier:error:
fetchFaceWithClusterSequenceNumber:error:
fetchPersonWithLocalIdentifier:options:error:
removeAutoAssignedFacesFromVerifiedPersonsAndPrepareForPersonBuilding:cancelOrExtendTimeoutBlock:error:
TB,N,V_personBuilderMergeCandidatesDisabled
setUnderExpose:
setHasUnderExpose:
hasUnderExpose
exposure
setExposure:
underExpose
_exposure
_underExpose
Tf,N,V_exposure
Tf,N,V_underExpose
assetWithPHAsset:
initWithPHAsset:
fingerprint
resources
allScenes
faces
_asset
_cachedResources
T@"NSArray",R,N
streamedMovie
originalMovieSize
_loadResources
visionSession
personIdentityModel
faceProcessingContext
photoLibrary
_faceProcessingContext
_personIdentityModel
taskName
computeRegionSharpness:width:height:stride:
computeSharpnessScore:forObjects:inImage:
bodyDistance:withBodyB:
computeActionScoreForPerson:
computeVarWithID:index1:index2:interVar:intraVar:
normDistance:point2:
associatePersons:withExisingPersons:
_personID
_existingPersons
_existingPersonsArray
initWithFaceResults:sdof:revision:
initWithFaceResults:sdof:
setGyroSharpnessParam:homographyResults:livePhotoStillDisplayTime:imageExposureTime:
getFaceScoreFromOutput:ratio:
computeCNNFaceSharpness:result:cancel:
computeSharpnessScore:forFacesInImage:
spatialPooling
computeLocalSharpness:
prepareFaceBlurModel:
scaleRegion:ofImage:toData:withWidth:andHeight:
computeGyroSharpness:
estimateDistance:prevHomography:
analyzePixelBuffer:flags:withPreAnalysisScore:results:cancel:
_sharpnessBlocks
_faces
_framePTSResults
_homographyResults
_faceModel
_faceInput
_livePhotoStillDisplayTime
_imageExposureTime
_useGPU
_sdof
_contrast
Tf,R,V_sharpness
Tf,R,V_textureScore
bindWithBuffers:imgFeature:
extractFeatureFromImage:toFeature:callback:
setFeatureShape:height:width:level:
_inputBlobName
_featureBlobNames
_featureChannels
imageBlurResultsType
imageCompositionResultsType
imageFaceResultsType
imageFeatureResultsType
imageJunkResultsType
imageSaliencyResultsType
imageShotTypeResultsType
imagePetsResultsType
imagePetsFaceResultsType
imageSceneprintResultsType
livePhotoEffectsResultsType
livePhotoRecommendationResultsType
livePhotoSharpnessResultsType
livePhotoKeyFrameResultsType
livePhotoKeyFrameStillResultsType
movieActivityLevelResultsType
movieCameraMotionResultsType
movieClassificationResultsType
movieFaceResultsType
movieFaceprintResultsType
movieFeatureResultsType
movieFineSubjectMotionResultsType
movieInterestingnessResultsType
movieMovingObjectResultsType
movieMusicResultsType
movieObstructionResultsType
movieOrientationResultsType
moviePreEncodeResultsType
movieQualityResultsType
movieSaliencyResultsType
movieSceneResultsType
movieSceneprintResultsType
movieSubjectMotionResultsType
movieSubtleMotionResultsType
movieUtteranceResultsType
movieVoiceResultsType
movieSummaryResultsType
movieHighlightResultsType
imageExposureResultsType
imageHumanPoseResultsType
movieHumanPoseResultsType
movieApplauseResultsType
movieBabbleResultsType
movieCheeringResultsType
movieLaughterResultsType
movieHumanActionResultsType
movieLoudnessResultsType
moviePetsResultsType
moviePetsFaceResultsType
movieStabilizationResultsType
movieHighlightScoreResultsType
livePhotoHumanActionClassificationResultsType
movieAudioQualityResultsType
setHasQuality:
hasQuality
setHasStatsFlags:
hasStatsFlags
setTypesWide:
setHasTypesWide:
hasTypesWide
hasAssetAdjustedFingerprint
clearImageBlurResults
addImageBlurResults:
imageBlurResultsCount
imageBlurResultsAtIndex:
clearImageCompositionResults
addImageCompositionResults:
imageCompositionResultsCount
imageCompositionResultsAtIndex:
clearImageFaceResults
addImageFaceResults:
imageFaceResultsCount
imageFaceResultsAtIndex:
clearImageFeatureResults
addImageFeatureResults:
imageFeatureResultsCount
imageFeatureResultsAtIndex:
clearImageJunkResults
addImageJunkResults:
imageJunkResultsCount
imageJunkResultsAtIndex:
clearImageSaliencyResults
addImageSaliencyResults:
imageSaliencyResultsCount
imageSaliencyResultsAtIndex:
clearImageShotTypeResults
addImageShotTypeResults:
imageShotTypeResultsCount
imageShotTypeResultsAtIndex:
clearImagePetsResults
addImagePetsResults:
imagePetsResultsCount
imagePetsResultsAtIndex:
clearImagePetsFaceResults
addImagePetsFaceResults:
imagePetsFaceResultsCount
imagePetsFaceResultsAtIndex:
clearImageSceneprintResults
addImageSceneprintResults:
imageSceneprintResultsCount
imageSceneprintResultsAtIndex:
clearLivePhotoEffectsResults
addLivePhotoEffectsResults:
livePhotoEffectsResultsCount
livePhotoEffectsResultsAtIndex:
clearLivePhotoRecommendationResults
addLivePhotoRecommendationResults:
livePhotoRecommendationResultsCount
livePhotoRecommendationResultsAtIndex:
clearLivePhotoSharpnessResults
addLivePhotoSharpnessResults:
livePhotoSharpnessResultsCount
livePhotoSharpnessResultsAtIndex:
clearLivePhotoKeyFrameResults
addLivePhotoKeyFrameResults:
livePhotoKeyFrameResultsCount
livePhotoKeyFrameResultsAtIndex:
clearLivePhotoKeyFrameStillResults
addLivePhotoKeyFrameStillResults:
livePhotoKeyFrameStillResultsCount
livePhotoKeyFrameStillResultsAtIndex:
clearMovieActivityLevelResults
addMovieActivityLevelResults:
movieActivityLevelResultsCount
movieActivityLevelResultsAtIndex:
clearMovieCameraMotionResults
addMovieCameraMotionResults:
movieCameraMotionResultsCount
movieCameraMotionResultsAtIndex:
clearMovieClassificationResults
addMovieClassificationResults:
movieClassificationResultsCount
movieClassificationResultsAtIndex:
clearMovieFaceResults
addMovieFaceResults:
movieFaceResultsCount
movieFaceResultsAtIndex:
clearMovieFaceprintResults
addMovieFaceprintResults:
movieFaceprintResultsCount
movieFaceprintResultsAtIndex:
clearMovieFeatureResults
addMovieFeatureResults:
movieFeatureResultsCount
movieFeatureResultsAtIndex:
clearMovieFineSubjectMotionResults
addMovieFineSubjectMotionResults:
movieFineSubjectMotionResultsCount
movieFineSubjectMotionResultsAtIndex:
clearMovieInterestingnessResults
addMovieInterestingnessResults:
movieInterestingnessResultsCount
movieInterestingnessResultsAtIndex:
clearMovieMovingObjectResults
addMovieMovingObjectResults:
movieMovingObjectResultsCount
movieMovingObjectResultsAtIndex:
clearMovieMusicResults
addMovieMusicResults:
movieMusicResultsCount
movieMusicResultsAtIndex:
clearMovieObstructionResults
addMovieObstructionResults:
movieObstructionResultsCount
movieObstructionResultsAtIndex:
clearMovieOrientationResults
addMovieOrientationResults:
movieOrientationResultsCount
movieOrientationResultsAtIndex:
clearMoviePreEncodeResults
addMoviePreEncodeResults:
moviePreEncodeResultsCount
moviePreEncodeResultsAtIndex:
clearMovieQualityResults
addMovieQualityResults:
movieQualityResultsCount
movieQualityResultsAtIndex:
clearMovieSaliencyResults
addMovieSaliencyResults:
movieSaliencyResultsCount
movieSaliencyResultsAtIndex:
clearMovieSceneResults
addMovieSceneResults:
movieSceneResultsCount
movieSceneResultsAtIndex:
clearMovieSceneprintResults
addMovieSceneprintResults:
movieSceneprintResultsCount
movieSceneprintResultsAtIndex:
clearMovieSubjectMotionResults
addMovieSubjectMotionResults:
movieSubjectMotionResultsCount
movieSubjectMotionResultsAtIndex:
clearMovieSubtleMotionResults
addMovieSubtleMotionResults:
movieSubtleMotionResultsCount
movieSubtleMotionResultsAtIndex:
clearMovieUtteranceResults
addMovieUtteranceResults:
movieUtteranceResultsCount
movieUtteranceResultsAtIndex:
clearMovieVoiceResults
addMovieVoiceResults:
movieVoiceResultsCount
movieVoiceResultsAtIndex:
clearMovieSummaryResults
addMovieSummaryResults:
movieSummaryResultsCount
movieSummaryResultsAtIndex:
clearMovieHighlightResults
addMovieHighlightResults:
movieHighlightResultsCount
movieHighlightResultsAtIndex:
clearImageExposureResults
addImageExposureResults:
imageExposureResultsCount
imageExposureResultsAtIndex:
clearImageHumanPoseResults
addImageHumanPoseResults:
imageHumanPoseResultsCount
imageHumanPoseResultsAtIndex:
clearMovieHumanPoseResults
addMovieHumanPoseResults:
movieHumanPoseResultsCount
movieHumanPoseResultsAtIndex:
clearMovieApplauseResults
addMovieApplauseResults:
movieApplauseResultsCount
movieApplauseResultsAtIndex:
clearMovieBabbleResults
addMovieBabbleResults:
movieBabbleResultsCount
movieBabbleResultsAtIndex:
clearMovieCheeringResults
addMovieCheeringResults:
movieCheeringResultsCount
movieCheeringResultsAtIndex:
clearMovieLaughterResults
addMovieLaughterResults:
movieLaughterResultsCount
movieLaughterResultsAtIndex:
clearMovieHumanActionResults
addMovieHumanActionResults:
movieHumanActionResultsCount
movieHumanActionResultsAtIndex:
clearMovieLoudnessResults
addMovieLoudnessResults:
movieLoudnessResultsCount
movieLoudnessResultsAtIndex:
clearMoviePetsResults
addMoviePetsResults:
moviePetsResultsCount
moviePetsResultsAtIndex:
clearMoviePetsFaceResults
addMoviePetsFaceResults:
moviePetsFaceResultsCount
moviePetsFaceResultsAtIndex:
clearMovieStabilizationResults
addMovieStabilizationResults:
movieStabilizationResultsCount
movieStabilizationResultsAtIndex:
clearMovieHighlightScoreResults
addMovieHighlightScoreResults:
movieHighlightScoreResultsCount
movieHighlightScoreResultsAtIndex:
clearLivePhotoHumanActionClassificationResults
addLivePhotoHumanActionClassificationResults:
livePhotoHumanActionClassificationResultsCount
livePhotoHumanActionClassificationResultsAtIndex:
clearMovieAudioQualityResults
addMovieAudioQualityResults:
movieAudioQualityResultsCount
movieAudioQualityResultsAtIndex:
setVersion:
types
setTypes:
date
setDate:
typesWide
assetIdentifier
setAssetIdentifier:
assetModificationDate
setAssetModificationDate:
assetMasterFingerprint
setAssetMasterFingerprint:
assetAdjustedFingerprint
setAssetAdjustedFingerprint:
imageBlurResults
setImageBlurResults:
imageCompositionResults
setImageCompositionResults:
imageFaceResults
setImageFaceResults:
imageFeatureResults
setImageFeatureResults:
imageJunkResults
setImageJunkResults:
imageSaliencyResults
setImageSaliencyResults:
imageShotTypeResults
setImageShotTypeResults:
imagePetsResults
setImagePetsResults:
imagePetsFaceResults
setImagePetsFaceResults:
imageSceneprintResults
setImageSceneprintResults:
livePhotoEffectsResults
setLivePhotoEffectsResults:
livePhotoRecommendationResults
setLivePhotoRecommendationResults:
livePhotoSharpnessResults
setLivePhotoSharpnessResults:
livePhotoKeyFrameResults
setLivePhotoKeyFrameResults:
livePhotoKeyFrameStillResults
setLivePhotoKeyFrameStillResults:
movieActivityLevelResults
setMovieActivityLevelResults:
movieCameraMotionResults
setMovieCameraMotionResults:
movieClassificationResults
setMovieClassificationResults:
movieFaceResults
setMovieFaceResults:
movieFaceprintResults
setMovieFaceprintResults:
movieFeatureResults
setMovieFeatureResults:
movieFineSubjectMotionResults
setMovieFineSubjectMotionResults:
movieInterestingnessResults
setMovieInterestingnessResults:
movieMovingObjectResults
setMovieMovingObjectResults:
movieMusicResults
setMovieMusicResults:
movieObstructionResults
setMovieObstructionResults:
movieOrientationResults
setMovieOrientationResults:
moviePreEncodeResults
setMoviePreEncodeResults:
movieQualityResults
setMovieQualityResults:
movieSaliencyResults
setMovieSaliencyResults:
movieSceneResults
setMovieSceneResults:
movieSceneprintResults
setMovieSceneprintResults:
movieSubjectMotionResults
setMovieSubjectMotionResults:
movieSubtleMotionResults
setMovieSubtleMotionResults:
movieUtteranceResults
setMovieUtteranceResults:
movieVoiceResults
setMovieVoiceResults:
movieSummaryResults
setMovieSummaryResults:
movieHighlightResults
setMovieHighlightResults:
imageExposureResults
setImageExposureResults:
imageHumanPoseResults
setImageHumanPoseResults:
movieHumanPoseResults
setMovieHumanPoseResults:
movieApplauseResults
setMovieApplauseResults:
movieBabbleResults
setMovieBabbleResults:
movieCheeringResults
setMovieCheeringResults:
movieLaughterResults
setMovieLaughterResults:
movieHumanActionResults
setMovieHumanActionResults:
movieLoudnessResults
setMovieLoudnessResults:
moviePetsResults
setMoviePetsResults:
moviePetsFaceResults
setMoviePetsFaceResults:
movieStabilizationResults
setMovieStabilizationResults:
movieHighlightScoreResults
setMovieHighlightScoreResults:
livePhotoHumanActionClassificationResults
setLivePhotoHumanActionClassificationResults:
movieAudioQualityResults
setMovieAudioQualityResults:
_assetModificationDate
_date
_typesWide
_assetAdjustedFingerprint
_assetIdentifier
_assetMasterFingerprint
_imageBlurResults
_imageCompositionResults
_imageExposureResults
_imageFaceResults
_imageFeatureResults
_imageHumanPoseResults
_imageJunkResults
_imagePetsFaceResults
_imagePetsResults
_imageSaliencyResults
_imageSceneprintResults
_imageShotTypeResults
_livePhotoEffectsResults
_livePhotoHumanActionClassificationResults
_livePhotoKeyFrameResults
_livePhotoKeyFrameStillResults
_livePhotoRecommendationResults
_livePhotoSharpnessResults
_movieActivityLevelResults
_movieApplauseResults
_movieAudioQualityResults
_movieBabbleResults
_movieCameraMotionResults
_movieCheeringResults
_movieClassificationResults
_movieFaceResults
_movieFaceprintResults
_movieFeatureResults
_movieFineSubjectMotionResults
_movieHighlightResults
_movieHighlightScoreResults
_movieHumanActionResults
_movieHumanPoseResults
_movieInterestingnessResults
_movieLaughterResults
_movieLoudnessResults
_movieMovingObjectResults
_movieMusicResults
_movieObstructionResults
_movieOrientationResults
_moviePetsFaceResults
_moviePetsResults
_moviePreEncodeResults
_movieQualityResults
_movieSaliencyResults
_movieSceneResults
_movieSceneprintResults
_movieStabilizationResults
_movieSubjectMotionResults
_movieSubtleMotionResults
_movieSummaryResults
_movieUtteranceResults
_movieVoiceResults
_types
TI,N,V_version
TI,N,V_types
Td,N,V_date
TQ,N,V_typesWide
T@"NSString",&,N,V_assetIdentifier
Td,N,V_assetModificationDate
T@"NSString",&,N,V_assetMasterFingerprint
T@"NSString",&,N,V_assetAdjustedFingerprint
T@"NSMutableArray",&,N,V_imageBlurResults
T@"NSMutableArray",&,N,V_imageCompositionResults
T@"NSMutableArray",&,N,V_imageFaceResults
T@"NSMutableArray",&,N,V_imageFeatureResults
T@"NSMutableArray",&,N,V_imageJunkResults
T@"NSMutableArray",&,N,V_imageSaliencyResults
T@"NSMutableArray",&,N,V_imageShotTypeResults
T@"NSMutableArray",&,N,V_imagePetsResults
T@"NSMutableArray",&,N,V_imagePetsFaceResults
T@"NSMutableArray",&,N,V_imageSceneprintResults
T@"NSMutableArray",&,N,V_livePhotoEffectsResults
T@"NSMutableArray",&,N,V_livePhotoRecommendationResults
T@"NSMutableArray",&,N,V_livePhotoSharpnessResults
T@"NSMutableArray",&,N,V_livePhotoKeyFrameResults
T@"NSMutableArray",&,N,V_livePhotoKeyFrameStillResults
T@"NSMutableArray",&,N,V_movieActivityLevelResults
T@"NSMutableArray",&,N,V_movieCameraMotionResults
T@"NSMutableArray",&,N,V_movieClassificationResults
T@"NSMutableArray",&,N,V_movieFaceResults
T@"NSMutableArray",&,N,V_movieFaceprintResults
T@"NSMutableArray",&,N,V_movieFeatureResults
T@"NSMutableArray",&,N,V_movieFineSubjectMotionResults
T@"NSMutableArray",&,N,V_movieInterestingnessResults
T@"NSMutableArray",&,N,V_movieMovingObjectResults
T@"NSMutableArray",&,N,V_movieMusicResults
T@"NSMutableArray",&,N,V_movieObstructionResults
T@"NSMutableArray",&,N,V_movieOrientationResults
T@"NSMutableArray",&,N,V_moviePreEncodeResults
T@"NSMutableArray",&,N,V_movieQualityResults
T@"NSMutableArray",&,N,V_movieSaliencyResults
T@"NSMutableArray",&,N,V_movieSceneResults
T@"NSMutableArray",&,N,V_movieSceneprintResults
T@"NSMutableArray",&,N,V_movieSubjectMotionResults
T@"NSMutableArray",&,N,V_movieSubtleMotionResults
T@"NSMutableArray",&,N,V_movieUtteranceResults
T@"NSMutableArray",&,N,V_movieVoiceResults
T@"NSMutableArray",&,N,V_movieSummaryResults
T@"NSMutableArray",&,N,V_movieHighlightResults
T@"NSMutableArray",&,N,V_imageExposureResults
T@"NSMutableArray",&,N,V_imageHumanPoseResults
T@"NSMutableArray",&,N,V_movieHumanPoseResults
T@"NSMutableArray",&,N,V_movieApplauseResults
T@"NSMutableArray",&,N,V_movieBabbleResults
T@"NSMutableArray",&,N,V_movieCheeringResults
T@"NSMutableArray",&,N,V_movieLaughterResults
T@"NSMutableArray",&,N,V_movieHumanActionResults
T@"NSMutableArray",&,N,V_movieLoudnessResults
T@"NSMutableArray",&,N,V_moviePetsResults
T@"NSMutableArray",&,N,V_moviePetsFaceResults
T@"NSMutableArray",&,N,V_movieStabilizationResults
T@"NSMutableArray",&,N,V_movieHighlightScoreResults
T@"NSMutableArray",&,N,V_livePhotoHumanActionClassificationResults
T@"NSMutableArray",&,N,V_movieAudioQualityResults
initWithClientBundleID:andClientTeamID:
initWithPixelBuffer:orientation:andIdentifier:clientBundleID:clientTeamID:
identifier
resolution
isHighResDecoded
loadPixelBuffer:orientation:
documentObservations
setDocumentObservations:
hasCachedParseData
cachedParseData
setCachedParseData:overwriteExisting:
_pixelBuffer
_documentObservations
_hasCachedParseData
_cachedParseData
initWithURL:identifier:clientBundleID:clientTeamID:
_url
initWithImageData:uniformTypeIdentifier:identifier:clientBundleID:clientTeamID:
_imageData
_uniformTypeIdentifier
initWithPhotosAsset:clientBundleID:clientTeamID:
initWithPhotosAsset:pixelBuffer:orientation:clientBundleID:clientTeamID:
location
isScreenshot
nsfwClassifications
scenenetClassifications
isSensitive
loadHighResPixelBuffer:orientation:
persistOCRMRC
barcodeObservations
setBarcodeObservations:
thumbnailResource
asset
hasValidSceneProcessing
_resources
_highResPixelBuffer
_highResOrientation
_barcodeObservations
assetWithPixelBuffer:orientation:identifier:clientBundleID:clientTeamID:
assetWithURL:identifier:clientBundleID:clientTeamID:
assetWithImageData:uniformTypeIdentifier:identifier:clientBundleID:clientTeamID:
assetWithPhotosAsset:clientBundleID:clientTeamID:
assetWithPhotosAsset:pixelBuffer:orientation:clientBundleID:clientTeamID:
setCachedParseData:
clientBundleID
clientTeamID
_isHighResDecoded
T@"NSString",R,N,V_clientBundleID
T@"NSString",R,N,V_clientTeamID
T@"CLLocation",R,N
T@"NSArray",C,N,V_documentObservations
T@"NSArray",C,N,V_barcodeObservations
TB,R,N,V_hasCachedParseData
T@"NSData",C,N,V_cachedParseData
T{CGSize=dd},R,N,V_resolution
TI,R,N,V_orientation
TB,R,N,V_isHighResDecoded
_modelLandmarks
initWithObjectBounds:inFrame:timestamp:
trackObjectInFrame:
objectBoundsInitial
objectBounds
lostCount
_correlationTracker
_lostCount
_objectBoundsInitial
_objectBounds
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,V_objectBoundsInitial
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,V_objectBounds
Tf,R,N,V_confidence
T{?=qiIq},R,N,V_start
Ti,R,N,V_lostCount
_allowANE
_persistGeneratedFaceCrops:forAsset:error:
_faceAssociatedWithFaceCrop:
_bestFaceForFaceDetectionRequest:withRect:
_faceFromFaceCrop:error:
_associateFace:withFaceCrop:error:
_clearDirtyStateOnFaceCrop:error:
_generateAndAssociateFaceprintedFaceForFaceCrop:faceCropFaceLocalIdentifier:error:
_updateFaceprint:forFace:error:
_updateFace:withFaceCrop:error:
_recordNeedToPersonBuildOnFaceGroupContainingFace:error:
_processDirtyFaceCrop:faceCropFaceLocalIdentifier:error:
_vcpFaceCropFromPHFaceCrop:
generateAndPersistFaceCropsForFaces:withAsset:resource:resourceURL:error:
processDirtyFaceCrops:withCancelBlock:andExtendTimeoutBlock:
_fastFaceMigrationEnabled
loadPersonsModelAndInitializeFaceAnalyzerWrapper
_loadPersonsModelAndInitializeFaceAnalyzer
_loadPetsModel
_classifyFaces:forAsset:detectedPersons:
processAsset:onDemandDetection:detectedFaces:detectedPersons:
classifyVIPPets
personIdentificationForSyndicationPhotoLibrary:withCancelOrExtendTimeoutBlock:
_persistPersonsModel:evaluationMode:error:
_persistPetsModel:error:
_fetchPersonsToFeedVIPModel:allowUnverifiedPerson:
_fetchPetsToFeedVIPModel
fetchEntityForModelType:evaluationMode:allowUnverifiedPerson:
_generatePetsModelWithExtendTimeoutBlock:cancel:
_generatePersonsModelWithExtendTimeoutBlock:cancel:evaluationMode:allowUnverifiedPerson:
_modelLastGenerationDidExceedTimeIntervalForType:
_faceProcessingPassGoalWithExtendTimeout:
_keepCurrentPersonsModelWithExtendTimeout:
_needToGenerateModelWithType:ignoreLastGenerationTime:withExtendTimeout:
generateVIPModelWithType:ignoreLastGenerationTime:evaluationMode:allowUnverifiedPerson:modelGenerated:extendTimeout:andCancel:
_personsModel
_petsModel
_management
initWithRevision:
copyBufferFrom:fromStride:toPtr:toStride:toWidth:toHeight:
sharedModelPoolWithRevision:
calculateScoreFromNetworkOutputV2:
computeSharpnessScore:textureness:contrast:imgWidth:cancel:
_srcWidth
_srcHeight
workerWithPhotoLibrary:andContext:
_openSuggestionsLoggingSession
_closeSuggestionsLoggingSession
_appendToSuggestionsLog:
_copyImageAtURLToSuggestionsLoggingSession:
_logFaceToSuggestionsLog:
_finalizeSuggestionsLog
_startAndSyncClusterCacheWithLibrary:reply:
updateKeyFacesOfPersonsWithLocalIdentifiers:forceUpdate:context:reply:
_suggestionsForPersonLocalIdentifier:clusterSequenceNumbers:excludePersonLocalIdentifiers:cancel:context:error:
_suggestionsForPersonWithLocalIdentifier:toBeConfirmedPersonSuggestions:toBeRejectedPersonSuggestions:cancel:error:
suggestPersonsForPersonWithLocalIdentifier:toBeConfirmedPersonSuggestions:toBeRejectedPersonSuggestions:context:reply:cancel:
faceCandidatesforKeyFaceForPersonsWithLocalIdentifiers:context:reply:
resetPersonsModelWithReply:
resetPetsModelWithReply:
requestSuggestedMePersonIdentifierWithContext:reply:
personPromoterStatusWithContext:reply:
validateClusterCacheWithContext:cancelOrExtendTimeoutBlock:reply:
resetFaceClusteringStateWithContext:reply:
_deleteAllVerifiedPersonsWithError:
reclusterFacesWithContext:reply:extendTimeout:cancel:
rebuildPersonsWithContext:reply:extendTimeout:cancel:
_clusterer
_suggestionLoggingDirectory
_suggestionLoggingSessionOpen
_suggestionsLoggingEnabled
vcp_firstEnabledTrackWithMediaType:
vcp_enabledTracksWithMediaType:
vcp_isShortMovie
vcp_isMontage
vcp_livePhotoStillDisplayTime
vcp_keyFrameWithMaxDimension:
initWithTrack:timerange:atInterval:
getNextCaptureSampleBuffer
_trackOutput
_decodeEnd
_sampleDuration
_nextSampleTime
_currentSample
_nextSample
frameProcessedByVideoAnalyzer
setFrameProcessedByVideoAnalyzer:
cameraMotionScore
setCameraMotionScore:
subjectActionScore
setSubjectActionScore:
colorfulnessScore
setColorfulnessScore:
subMbMotionAvailable
setSubMbMotionAvailable:
frameExpressionScore
setFrameExpressionScore:
faceArea
setFaceArea:
motionParam
setMotionParam:
motionParamDiff
setMotionParamDiff:
frameProcessedByHumanAnalyzer
setFrameProcessedByHumanAnalyzer:
frameProcessedByFaceDetector
setFrameProcessedByFaceDetector:
petsDetections
setPetsDetections:
frameProcessedByPetsActionAnalyzer
setFrameProcessedByPetsActionAnalyzer:
petsActionScore
setPetsActionScore:
videoActivityDescriptor
setVideoActivityDescriptor:
_frameProcessedByVideoAnalyzer
_subMbMotionAvailable
_frameProcessedByHumanAnalyzer
_frameProcessedByFaceDetector
_frameProcessedByPetsActionAnalyzer
_cameraMotionScore
_subjectActionScore
_colorfulnessScore
_frameExpressionScore
_faceArea
_petsActionScore
_videoActivityDescriptor
_motionParam
_motionParamDiff
TB,N,V_frameProcessedByVideoAnalyzer
Tf,N,V_cameraMotionScore
Tf,N,V_subjectActionScore
Tf,N,V_interestingnessScore
Tf,N,V_obstructionScore
Tf,N,V_colorfulnessScore
TB,N,V_subMbMotionAvailable
Tf,N,V_frameExpressionScore
Tf,N,V_faceArea
T{array<float, 6UL>=[6f]},N,V_motionParam
T{array<float, 6UL>=[6f]},N,V_motionParamDiff
TB,N,V_frameProcessedByHumanAnalyzer
TB,N,V_frameProcessedByFaceDetector
T@"NSMutableArray",&,N,V_petsDetections
TB,N,V_frameProcessedByPetsActionAnalyzer
Tf,N,V_petsActionScore
T@"VCPVideoActivityDescriptor",&,N,V_videoActivityDescriptor
_summaryResults
_skip
initWithFrameStats:timeOfInterest:
computeVar:index2:interVar:intraVar:
computeActionScore
scaleRect:scaleX:scaleY:
intersectionOverUnion:rect:
processPets:petsBounds:dominantPetIdx:frame:timestamp:duration:
_poseAnalyzer
_timeLastProcessFullFrame
_maxScore
_endTime
_keyPetResults
_poseResults
_crop
_petRect
_actionScoreAbsolute
_actionScoreRelative
_scoreAbsoluteMax
_scoreRelativeMax
_lastPetTimestamp
_tracker
_tracking
_timeOfInterest
_sampleFlag
initWithTime:andScore:
timeStamp
_timeStamp
T{?=qiIq},R,N,V_timeStamp
Tf,R,N,V_score
initWithTimeRange:score:andKeyFrame:
T{?={?=qiIq}{?=qiIq}},R,N,V_timerange
T@"VCPVideoKeyFrameResult",R,N,V_keyFrame
phAsset
highlights
_phAsset
_highlights
T@"PHAsset",R,N,V_phAsset
T@"NSMutableArray",R,&,N,V_highlights
T@"NSMutableDictionary",&,N,V_results
decodeDimensionsForTrack:
settings
validateDecodedFrame:withSettings:
_track
generateFaceCropsForFace:resourceURL:groupingIdentifier:
initWithLocalIdentifier:faceCropData:
initWithFaceCropData:originatingFace:
faceCropData
originatingFace
imageDimensions
state
setState:
_originatingFace
_cachedImageDimensions
_state
Ts,N,V_state
initWithModelName:
model
T@"MLModel",R,N,V_model
initWithFilterTabs:distanceVariance:diffVariance:
processFrameScore:validScore:
_numFilterTabs
_scoreArray
_distanceVariance
_diffVariance
_numOfScores
storeResults:
loadModel:
prepareModelWithFile:engine:config:error:
buildModelWithConfig:error:
updateModelWithConfig:error:
freeModel
_faceprintFastMode
_downsampleBeforeFaceProcessing
initWithContext:
_createBlurRequests:andExposureRequests:forFaceObservations:
_checkAnalysisRequests:forTooSmallFaceObservations:withAnalysisResults:
_performAnalysis:withRequestHandler:quickMode:sourceWidth:sourceHeight:
_existingFacesFromAsset:
refineAnalysis:requestHandler:forAsset:orientedWidth:orientedHeight:
_loadImageRequestHandler:orientation:bufferWidth:bufferHeight:withResource:resourceURL:andAsset:
analyzeAsset:withResource:resourceURL:quickMode:results:
quickAnalyzeAsset:results:
updateMissingFaceprintForFaces:withAsset:
analyzeFaceQuality:withAsset:andCancelBlock:
_faceMerger
isLocallyAvailable
vcp_uniformTypeIdentifier
vcp_isMovie
vcp_isPhoto
vcp_isVideoResourceUsable:
vcp_isPhotoResourceUsable:
vcp_isDecodable
vcp_isLocallyAvailable
vcp_hasExtremeAbnormalDimensionForScene
vcp_fileSize
vcp_size
vcp_allResourcesForAsset:
vcp_allAcceptableResourcesForAsset:
vcp_ascendingSizeComparator
vcp_descendingSizeComparator
vcp_avAsset
request:didProduceResult:
request:didFailWithError:
requestDidComplete:
initWithTrackStart:threshold:resultsKey:
addDetectionFromTime:toTime:confidence:
_activeStart
_activeEnd
_length
_activeConfidence
_minDetections
_resultsKey
_activeScore
_audioQualityAggregated
initWithTypes:
setupWithSample:trackDuration:andSampleBatchSize:
_SNAnalyzer
_detectors
_classifiers
faceprintBlob
setFaceprintBlob:
_faceprintBlob
TI,N,V_faceID
T@"NSData",&,N,V_faceprintBlob
inputSize
setInputSize:
outputSize
setOutputSize:
input
setInput:
output
setOutput:
context
generateOutput
setGenerateOutput:
_outputSize
_output
_generateOutput
_executedOnGPU
T@"NSMutableArray",W,V_inputSize
T@"NSMutableArray",&,V_outputSize
T@"VCPCNNData",W,V_input
T@"VCPCNNData",&,V_output
T@"VCPCNNMetalContext",R,V_context
TB,V_generateOutput
vcp_typeDescription
vcp_originalSize
vcp_modificationDate
vcp_eligibleForVideoDownload:
vcp_hasAdjustments:
vcp_targetMajorDimensionForImageWithWidth:height:andMinPreferredMinorDimension:
vcp_majorDimensionForResource:withTargetResolution:
vcp_needsProcessingForTask:
vcp_fetchOptionsForLibrary:forTaskID:
vcp_isPano
vcp_isLivePhoto
vcp_isSdofPhoto
vcp_isVideoSlowmo
vcp_isVideoTimelapse
vcp_isMontageWithTaskID:
vcp_needSceneProcessing
vcp_confidenceForSceneIdentifier:
vcp_abnormalImageDimensionForSceneNet
vcp_needsOCRProcessing
vcp_isDownloadGated
vcp_passedOCRGating
vcp_ocrMajorDimensionForResource:
vcp_ocrGatingThreshold
vcp_needsVisualSearchProcessing
normalizedRectForRect:inBoundsOfSize:
normalizedRectForRect:inBounds:
rectFromMappingNormalizedRect:toBoundsOfSize:
rectFromMappingNormalizedRect:toBounds:
pointFromNormalizedPoint:inBounds:
analyzeFrame:withFaceBounds:
landmarks
_landmarks
initWithURL:
_analyzeWithStart:andDuration:error:
analyzeWithStart:andDuration:error:
progressHandler
setProgressHandler:
_session
_progressHandler
T@?,C,V_progressHandler
hasRecipeBlob
recipeBlob
setRecipeBlob:
_recipeBlob
T@"NSData",&,N,V_recipeBlob
hasColorNormalizationBlob
playbackCrop
setPlaybackCrop:
colorNormalizationBlob
setColorNormalizationBlob:
_colorNormalizationBlob
_playbackCrop
T@"VCPProtoVideoKeyFrame",&,N,V_keyFrame
T@"VCPProtoBounds",&,N,V_playbackCrop
T@"NSData",&,N,V_colorNormalizationBlob
fcBlockWithNumNeurons:NeuronType:
initWithParameters:NeuronType:
readWeightsBias:weights:bias:inputDim:outputDim:quantFactor:
_weight
_bias
_numNeurons
_neuronType
setPixelBuffer:
calculateFrameDifference:
computeRegionsofInterest
regionsOfInterest
_regions
_diff
_ptrFirst
_ptrLast
_scaler
_frameArray
_frameWidth
_frameHeight
_blockSize
_widthBlockNum
_heightBlockNum
vcp_convertToOriginalTimerangeFromScaledTimerange:
vcp_scaleSlowmoTimeRange:withTimeMapping:inComposition:
vcp_scaleRampWithIntervals:andRates:inSlowmoTimerange:withTimeMapping:inComposition:
vcp_assetWithoutAdjustments:duration:
hasAction
setHasAction:
_hasAction
TB,N,V_hasAction
initWithXYAndSize:y:width:height:confidence:
initWithCenterAndSize:y:width:height:confidence:
area
intersect:
union:
computeIntersectionOverUnion:
getCGRectWithClipWidth:height:
minX
setMinX:
maxX
setMaxX:
minY
setMinY:
maxY
setMaxY:
flag
setFlag:
classIndex
setClassIndex:
_minX
_maxX
_minY
_maxY
_flag
_classIndex
Tf,V_minX
Tf,V_maxX
Tf,V_minY
Tf,V_maxY
Tf,V_flag
Ti,V_classIndex
estimator
detectPoseForFace:inBuffer:yaw:
taskWithAssets:andOptions:andCompletionHandler:
deserializeStabilizationRecipeInAttributes:
initWithAssets:andOptions:andCompletionHandler:
_stabilizationType
_onDemandPixel
_onDemandGyro
canAnalyzeUndegraded:withResources:
getMaximumHighlightInSec
getHumanActionClassiferType
getEnableMovieHumanAction
analyzerWithVCPAsset:withExistingAnalysis:forAnalysisTypes:
initWithVCPAsset:withExistingAnalysis:forAnalysisTypes:
initWithPHAsset:withPausedAnalysis:forAnalysisTypes:
initWithPHAsset:withExistingAnalysis:forAnalysisTypes:
loadPropertiesForAsset:
processExistingAnalysisForTimeRange:analysisTypes:
performMetadataAnalysisOnAsset:withCancelBlock:
createDecoderForTrack:timerange:forAnalysisTypes:
createVideoAnalyzer:withFrameStats:
analyzeVideoSegment:timerange:forAnalysisTypes:cancel:
postProcessAutoPlayable:
analyzeVideoTrack:start:forAnalysisTypes:cancel:
analyzeAsset:streamed:
generateKeyFrameResource:
allowStreaming
setAllowStreaming:
maxHighlightDuration
faceDominated
setFaceDominated:
_analysis
_supportConditionalAnalysis
_existingAnalysis
_prepareLivePhotoScenes
_generateVideoCaption
_allowStreaming
_maxHighlightDuration
TB,N,V_allowStreaming
Tf,N,V_maxHighlightDuration
TB,N,V_faceDominated
Tq,R,V_status
initWithKeypointsOption:forceCPU:sharedModel:aspectRatio:modelName:revision:
getClosestAspectRatio:
updateModelForAspectRatio:
convertSingleResultToDict:keypointConfidence:box:results:
preferredInputFormat:height:format:
_handsDetector
_handsKeypointsDetector
taskWithRequests:forAsset:cancelBlock:andCompletionHandler:
initWithRequests:forAsset:cancelBlock:andCompletionHandler:
_subtasks
loopSuggestionState
setLoopSuggestionState:
longExposureSuggestionState
setLongExposureSuggestionState:
_longExposureSuggestionState
_loopSuggestionState
TQ,N,V_loopSuggestionState
TQ,N,V_longExposureSuggestionState
analyzerWithRevision:
analyzer
getRevision
calculateScoreFromNetworkOutput:outChannel:outHeight:outWidth:textureness:contrast:imgWidth:
computeCNNBasedSharpness:sharpnessScore:textureScore:contrast:cancel:
sdof
setSdof:
TB,V_sdof
iteratorForAssets:withDatabaseReader:resultTypes:batchSize:
initWithDatabaseReader:forAssets:resultsTypes:batchSize:
next
nextBatch
analysis
_resultsTypes
_batchSize
_idxLast
_idxCurrent
_batchAnalyses
T@"PHAsset",R,N,V_asset
T@"NSDictionary",R,N,V_analysis
allObjects
countByEnumeratingWithState:objects:count:
count
fetchedObjects
T@"VCPProtoTime",&,N,V_start
T@"VCPProtoTime",&,N,V_duration
initWithMovingObjectsResults:
_movingObjects
taskForURLAsset:withOptions:analysisTypes:progressHandler:completionHandler:
initWithURLAsset:withOptions:analysisTypes:progressHandler:completionHandler:
_noResultStrip
_assetURL
_pairedAssetURL
faceCountInFaceGroup
isDirty
frameInstructionsType
setHasEpoch:
hasEpoch
setHasFlags:
hasFlags
clearFrameInstructions
addFrameInstructions:
frameInstructionsCount
frameInstructionsAtIndex:
stabilizeResult
setStabilizeResult:
outputFrameDurValue
setOutputFrameDurValue:
cropRectX
setCropRectX:
cropRectY
setCropRectY:
cropRectHeight
setCropRectHeight:
cropRectWidth
setCropRectWidth:
frameInstructions
setFrameInstructions:
autoloop
setAutoloop:
bounce
setBounce:
longexposure
setLongexposure:
stabilize
setStabilize:
minVersion
setMinVersion:
_outputFrameDurValue
_autoloop
_bounce
_cropRectHeight
_cropRectWidth
_cropRectX
_cropRectY
_frameInstructions
_longexposure
_minVersion
_stabilize
_stabilizeResult
Ti,N,V_stabilizeResult
Tq,N,V_outputFrameDurValue
Ti,N,V_cropRectX
Ti,N,V_cropRectY
Ti,N,V_cropRectHeight
Ti,N,V_cropRectWidth
T@"NSMutableArray",&,N,V_frameInstructions
T@"VCPProtoLivePhotoVariationParams",&,N,V_autoloop
T@"VCPProtoLivePhotoVariationParams",&,N,V_bounce
T@"VCPProtoLivePhotoVariationParams",&,N,V_longexposure
T@"VCPProtoLivePhotoVariationParams",&,N,V_stabilize
Ti,N,V_minVersion
Ti,N,V_version
initWithAnalysisTypes:forStreaming:
setupWithSample:andTrackDuration:
processSampleBuffer:
analyzeAsset:cancel:results:
analyzeSampleBuffer:
_inputBuffer
_audioTimestamp
_audioBufferList
_voiceDetector
_audioClassifier
_songDetector
_bufferedSamples
_initialized
copyImage:toData:
createInput:withBuffer:cnnInputHeight:cnnInputWidth:faceBounds:
detectEyeOpennessForFace:inBuffer:eyeOpenness:
initWithPhotoLibrary:andFaceClusterer:andContext:
_readFaceAnalysisState
_setFaceAnalysisStateValue:forKey:
setPersonBuilderMergeCandidatesEnabled:
setLastMinimumFaceGroupSizeForCreatingMergeCandidate:
_setAllFaceGroupsNeedPersonBuilding
performPersonBuildingWithCancelOrExtendTimeoutBlock:error:
_faceClusterer
_lastMinimumFaceGroupSizeForCreatingMergeCandidates
_personBuilderMergeCandidatesEnabled
initWithMaxNumRegions:forceCPU:sharedModel:inputConfig:
_personKeypointsDetector
statisticsBlob
setStatisticsBlob:
_statisticsBlob
T@"NSData",&,N,V_statisticsBlob
maximumLeafObservations
maximumHierarchicalObservations
_includeNSFW
_includeLM
_includeSE
_includeSDG
_includeWP
_includeDO
_includeSO
_includeMeme
_includeRotation
_includeDocument
_includeIVS
_includePA
_includeCN
_useR14J9
_getSHRevision
_enableSceneAssetConcurrency
_includeDMF
_isPanoWithMediaType:andMediaSubtypes:
_isSDOFWithMediaType:andMediaSubtypes:
_isMovieWithMediaType:
_nonPanoPreWarmDimensions
_configureRequest:
_configureRequest:withRevision:
_createRequests:withMediaType:
_parseClassificationObservations:toClassificationResults:
_parseClassificationObservations:withPrefix:toClassificationResults:
_processBoundingBoxFromDetectedObjects:forSceneClassID:
_insertBoundingBox:toSortedBoundingBoxes:
_extractAndSortBoundingBoxFromDetectedObjects:
_generateSceneClassifications:fromRequests:
_obfuscateLabelName:
_collectSceneAnalysisResults:fromRequests:wpResults:ivsResults:abnormalDimension:
_performSceneAnalysis:image:mediaType:mediaSubtypes:abnormalDimension:
_performBlurAnalysis:withPixelBuffer:usingAnalyzer:
_performBlurAnalysis:withLumaPixelBuffer:abnormalDimension:isSDOF:
_performExposureAnalysis:withLumaPixelBuffer:
_performRotationAnalysis:withColorPixelBuffer:
_performWallpaperAnalysis:withSceneprint:
_performAnalysis:mediaType:mediaSubtypes:abnormalDimension:colorPixelBuffer:andLumaPixelBuffer:image:
analyzeWithImageURL:mediaType:mediaSubtypes:abnormalDimension:completionHandler:
_imageLoader
_monochromeBufferCreator
_rotationModel
_rotationBufferCreator
_ivsPool
initWithTrack:timerange:withSettings:applyTransform:
_decoderSettings
initWithForceCPU:sharedModel:
createInput:withBuffer:cnnInputHeight:cnnInputWidth:box:
analyzeFrame:withBox:keypoints:
parseKeypoints:
supportsSecureCoding
encodeWithCoder:
initWithCoder:
TB,R
initWithVertices:vertexCount:
vertices
_vertices
TQ,R,N,V_vertexCount
Tr^,R,N
initWithTransform:blendShapes:geometry:
transform
geometry
_blendShapes
_geometry
T{?=[4]},R,N,V_transform
T@"NSDictionary",R,N,V_blendShapes
T@"VCPFaceGeometry",R,N,V_geometry
analyzerForAnalysisTypes:withPreferredTransform:properties:
aggregateAnalysisForTypes:withFramesMeta:properties:
initWithAnalysisTypes:withPreferredTransform:withFocalLengthInPixels:withAnalysisQueue:withTurbo:
prewarmWithProperties:
updatePreferredTransform:properties:
transformForAngle:pixelBuffer:
rotateTransform:byAngle:
analyzePixelBuffer:withTimestamp:andDuration:properties:error:
analyzePixelBuffer:withTimestamp:andDuration:properties:completion:
analyzeAudioBuffer:
aggregatedResults
analyzeFrameWithTimeRange:analysisData:
shouldCutAt:stillPTS:withCut:
_meshAnalyzer
_videoAnalysis
_audioAnalyzer
_faceDetector
_sceneChangeAnalyzer
_lightMotionAnalyzer
_trimAnalyzer
_homeKitMotionAnalyzer
_rotator
_rotatorForFacePose
_preferredTransform
_focalLengthInPixels
_aggregatedResults
_rotationAngleForFacePose
_preferredAngle
_analysisQueue
_preWarmed
planDestroy
createInput:keypoints:
getDetectionScore:
gestureDetection:score:
enableR2D2
prepareAnalyzerWithCVPixelBuffer:cancel:
convertFlow:
preProcessing:
generateMotionFlow
generateSubleMotionScore:
analyzePixelBuffer:withFrame:withTimestamp:andDuration:hasSubtleScene:cancel:
subtleMotionScore
_scale
_moflowRequest
_downScaleWidth
_downScaleHeight
_flowWidth
_flowHeight
_frameNum
_useR2D2
_subtleMotionScore
Tf,R,V_subtleMotionScore
usePHAssetScene
initWithAnalysisResults:
initWithFlagHasFaceOrPet:
analyzeAsset:onDemand:cancel:statsFlags:results:
_hasFaceOrPet
faceDetectorWithTransform:withExistingFaceprints:frameStats:tracking:faceDominated:cancel:
_angle
initWithNumberOfScales:numOfOrientations:width:height:
processWithFilterScaleIdx:orientIdx:srcImage:outImage:width:height:
createGaborFilterKernel:sigmaX:sigmaY:lambda:thetaInDegree:phaseInDegree:
_filterBanks
_numScales
_numOrientations
_num
storeAnalysis:forAsset:fromPhotoLibraryURL:withReply:
registerClient:forPhotoLibraryURL:withReply:
compare:
sharedMediaAnalyzer
_getDistanceDescriptorClass
personModelFilepathForPhotoLibrary:
loadPersonModelAtPath:error:
faceprintRevisionForPersonModel:
classifyFaceObservation:withPersonsModel:error:
_setupMediaAnalysisServiceConnection
_getSandboxExtensionForMediaAnalysisDatabaseWithPhotoLibraryURL:
_getDatabaseSandboxExtensionForPhotoLibraryURL:
_databaseForPhotoLibrary:
_addClassificationResults:analysis:
_metaAnalysisTypesForAsset:
_typesToRemove:requested:
_postProcessMovieHighlights:analysis:withOptions:
_analyzeOndemand:forAnalysisTypes:withExistingAnalysis:andOptions:storeAnalysis:cancelBlock:
requestAnalysisTypes:forAssetWithResourceURLs:withOptions:error:
analyzeOndemand:pairedURL:forAnalysisTypes:error:
_requestAnalysis:forAsset:withExistingAnalysis:andDatabase:andOptions:cancelBlock:
requestAnalysisForAsset:analysisTypes:progressHandler:completionHandler:
cancelAnalysisWithRequestID:
assetsFromPhotoLibrary:analyzedSinceDate:completionHandler:
assetsAnalyzedSinceDate:completionHandler:
_checkDuplicate:withAsset:duplicate:
_getSceneDescriptors:asDescriptorClass:withSceneRange:andAnalysisResults:
_queryDistanceDescriptor:ofAsset:withExistingAnalysis:andDatabase:timeRange:lastFeature:isDegraded:
distanceFromAsset:toAsset:duplicate:distance:
distanceFromAsset:timeRange:toAsset:timeRange:duplicate:distance:
requestAnalysisTypes:forAssets:withOptions:andProgressHandler:cancelBlock:analyses:
requestAnalysesForAssets:analysisTypes:allowOndemand:progressHandler:completionHandler:
requestAnalysis:forAssets:withOptions:andProgressHandler:andCompletionHandler:
requestAnalysisTypes:forAssets:allowOndemand:progressHandler:error:
requestAnalysis:forAssets:withOptions:andProgressHandler:andError:
curateMovieAssetsForCollection:withAlreadyCuratedAssets:andDesiredCount:allowOnDemand:
requestMovieHighlightsForAssets:withOptions:
postProcessMovieHighlightDuration:withOptions:
requestLivePhotoEffectsForAssets:allowOnDemand:flags:
completeStorage
_storageQueue
_storageGroup
_standalone
_minHighlightDuration
_mediaAnalysisServiceConnection
_sandboxQueue
_sandboxHandles
_cancelTokens
taskWithAssets:options:andCompletionHandler:
_panoVNRequestMethod
initWithAssets:options:andCompletionHandler:
approximateCoordinate
isCoarse
startDate
endDate
estimatedAssetCount
mad_sceneNameFromSceneId:
mad_sceneIdFromSceneName:
vcp_sharedTaxonomy
mad_isExpectedTaxonomy
analyzePixelBufferInTiles:results:cancel:
calculateTextureness:height:width:sdof:result:
hadZoom
setHadZoom:
minZoom
setMinZoom:
maxZoom
setMaxZoom:
_minZoom
_maxZoom
TB,N,V_hadZoom
Tf,N,V_minZoom
Tf,N,V_maxZoom
defaultDesiredKeys
referenceSoftwareStackVersion
initWithRequestAnalyses:formatDescription:
gyroHomographyVersionIsValid:
readGyroHomographyDimension:
readSoftwareStackVersion:
getSetupDataFrom:
getFirstAtomWithFourCharCode:fromSetupData:
compareSoftwareStackVersion:withReferenceVersion:
compareNumericVersion:withReferenceVersion:
convertLivePhotoStruct:toDictionary:
convertLivePhotoBinary:toDictionary:
_prevEstimatedCenterMv
_deSerializedMetaBuffer
_metaFocusAnalyzer
_metaMotionAnalyzer
_requestAnalyses
_metadataStabilizationArray
_frameTimestampArray
_originalFrameTimestampArray
_metadataItemTimestampArray
_adjusterArray
_interpolatedFrameArray
_metaLensSwitchAnalzer
_gyroHomographyIsValid
_gyroHomographyDimension
pointValue
pointWithPoint:
cnnDataClass
cnnData
cnnDataWithGPUContext:
cnnDataWithPlane:height:width:context:
initWithGPUContext:
initWithParameters:height:width:context:
randInit
bufferAllocCPU
convertCPUData2GPU
convertGPUData2CPU
reallocGPUTemporalBuffers
copyImage:withChunk:
normalization
setData:
isInputOutput
setIsInputOutput:
setContext:
_isInputOutput
T@"NSMutableArray",&,V_size
T^f,V_data
TB,V_isInputOutput
T@"VCPCNNMetalContext",W,V_context
initWithEdgeMap:mapWidth:mapHeight:angleStep:
DetectLinesWithThreshold:output:
Transform
_mapWidth
_mapHeight
_accumulator
_accWidth
_accHeight
_accHalfHeight
_angleStep
vcp_startTime
vcp_endTime
vcp_orientation
vcp_imageOrientation
vcp_fullFrameSize
vcp_cleanApertureRect
vcp_imagesPredicate:
vcp_stillImagesPredicate:
vcp_livePhotosPredicate:
vcp_nonPanoPredicate:
vcp_moviesPredicate:
vcp_fullAnalysisPredatesVersionInternalPredicate:
_peopleThreshold
mad_prioritizedAssetsForFaceDetectionInternalPredicate
mad_nonPrioritizedAssetsForFaceDetectionInternalPredicate
mad_internalPredicateForTaskID:
mad_internalPredicateWithPriority:forTaskID:
mad_internalPredicateNeedsProcessingForTaskID:
initFromConfigFile:numStage:numLandmarks:numTreePerStage:depthOfTree:numFeatures:
detectLandmark:width:height:stride:facerect:prevResult:result:
calculateFaceRectFromPrevLM:result:numOfLandmarks:
_internalLandmarkDetector
_numOfLandmarks
convBlockClass:
convBlockWithFilterSize:filterNum:chunk:reLU:padding:
convBlockWithFilterSize:filterNum:chunk:reLU:padding:groups:stride:batchNorm:
_filterSize
_filterNum
_filter
_reLU
_padding
_padSize
_groups
_batchNorm
session
T@"VNSession",R,N
detector:forceCPU:sharedModel:inputConfig:revision:
initWithMaxNumRegions:forceCPU:sharedModel:inputConfig:revision:
updateModelWithResConfig:
createModelWithResConfig:
createInput:withBuffer:
generateHandsBoxes:
retrieveBoxes:outHeight:outWidth:boxes:anchorBox:
generateHandsRegions:boxes:maxNumRegions:
drawLine:width:height:stride:point0:point1:drawPoint:
drawRectangle:width:height:stride:keypoints:
handsDetection:handsRegions:cancel:
_cnnInputWidth
_cnnInputHeight
_numClass
vcp_sharedModelWithModelName:
inputPixelFormat
inputFeatureName
outputFeatureName
_inputPixelFormat
_inputFeatureName
_outputFeatureName
Tq,R,N,V_inputSize
TI,R,N,V_inputPixelFormat
T@"NSString",R,N,V_inputFeatureName
T@"NSString",R,N,V_outputFeatureName
useCPUOnly
revision
_useCPUOnly
_maxNumHands
_humanActionWindowSize
_motionFlowComputationAccuracy
TB,R,N,V_useCPUOnly
TI,R,N,V_revision
vcp_fingerprint:
vcp_fetchAssetsMatchingFingerprint:forPhotoLibrary:
vcp_hasFace
vcp_normalizedFaceBounds
vcp_hasBody
vcp_normalizedBodyBounds
setIdentifier:
TI,N,V_identifier
initWithURL:options:
assetWithData:
resourceLoader:shouldWaitForLoadingOfRequestedResource:
resourceLoader:shouldWaitForRenewalOfRequestedResource:
resourceLoader:didCancelLoadingRequest:
resourceLoader:shouldWaitForResponseToAuthenticationChallenge:
resourceLoader:didCancelAuthenticationChallenge:
Ti,N,V_faceID
textureness
setTextureness:
hasFlash
setHasFlash:
stillTime
setStillTime:
_stillTime
_textureness
_hasFlash
Tf,N,V_textureness
TB,N,V_hasFlash
Tf,N,V_stillTime
vcp_idealDimension
T@"NSValue",R,N
_configureRequestWithRevision:
vcp_sceneRequestWithRequestClass:andRevision:
vcp_sceneRequest
vcp_sceneRequestForWallpaper
mad_defaultRequest
maxSizeBytes
_reportDownload:
requestDownloadOfResource:
flush
setCancel:
_mutex
_semaphore
_dataTask
T@?,C,N,V_cancel
initImageTransform:transformedImageWidth:transformedImageHeight:
cropAndScale:regionCrop:
_minSize
_transformedImageWidth
_transformedImageHeight
analyzeFrameWithTimeRange:andActionScore:
updateActiveThreshold
isActive:
isScoreValid:
decideSegmentPointBasedOnActionScore:
decideSegmentPointUsingHinkleyDetector:
mergeConsecutiveShortSegments
mergeSameTypeSegments
mergeSparseShortSegments
finalizeWithDestructiveTrimStart:trimEnd:
postProcessSegmentsWithCaptureTime:trimStart:
segments
activeSegment
printSegments:
prepareTrimmingWithTrimStart:andTrimEnd:
_activeHinkleyDetector
_activeThreshold
_firstFrame
_postProcessStart
vcp_version
vcp_dateModified
vcp_dateAnalyzed
vcp_types
vcp_flags
vcp_statsFlags
vcp_quality
vcp_results
vcp_fingerprint
vcp_degraded
vcp_streamedVideo
vcp_queryActionResultForPHFace:
vcp_setVersion:
vcp_setDateModified:
vcp_setDateAnalyzed:
vcp_setTypes:
vcp_setFlags:
vcp_setStatsFlags:
vcp_setQuality:
vcp_setFingerprint:
vcp_addTypes:
vcp_addFlags:
vcp_addStatsFlags:
vcp_mutableResults
vcp_setResult:forKey:
vcp_addEntriesFromResults:
vcp_setResults:
vcp_appendResult:forKey:
vcp_appendResults:
vcp_removeResultForKey:
vcp_time
vcp_timerange
vcp_setTimerange:
vcp_syncPoint
vcp_setSyncPoint:
vcp_removeSyncPoint
analyzeWithLightweightOption:aspectRatio:computationAccuracy:forceCPU:sharedModel:flushModel:cancel:
initWithLightweightOption:aspectRatio:computationAccuracy:forceCPU:sharedModel:flushModel:cancel:
scaleFlowTo:
combineBufferTo:flowX:flowY:
guidedUpsampling:inBGRA:
cnnOutputHeight
cnnOutputWidth
_cnnOutputHeight
_cnnOutputWidth
_computationAccuracy
_device
_commandQueue
_bilinearScale
_guidedFilter
Ti,R,N,V_cnnOutputHeight
Ti,R,N,V_cnnOutputWidth
photoLibraryDidBecomeUnavailable:
defaultPhotoLibrary
closedefaultPhotoLibrary
_defaultPhotoLibraryURL
_defaultPhotoLibrary
canUseLastFrameOfAsset:withResources:
thumbnailSizeForAsset:withResources:
_generateLastFrameDistanceDescriptor:withDescriptorClass:forAsset:
_getThumbnailForAsset:withResouces:andPixelFormat:
generateDistanceDescriptor:withDescriptorClass:forAsset:withResources:lastFrame:
computeDistance:withDescriptorClass:fromAsset:toAsset:
computeDistance:fromArray:toArray:
addClusterPrecision:forPersonID:personFaceCount:validFaceCount:identitySize:
addIdentityRecallToGroundTruth:forPersonID:personFaceCount:identitySize:
addIdentityRecallExcludeMissDetection:forPersonID:personFaceCount:identitySize:
weightedAveragePrecision
setWeightedAveragePrecision:
weightedAverageRecall
setWeightedAverageRecall:
numSingletons
setNumSingletons:
numValidSingletons
setNumValidSingletons:
precisionPerCluster
setPrecisionPerCluster:
recallPerPersonToGroundTruth
setRecallPerPersonToGroundTruth:
recallPerPersonExcludeMissDetection
setRecallPerPersonExcludeMissDetection:
_weightedAveragePrecision
_weightedAverageRecall
_numSingletons
_numValidSingletons
_precisionPerCluster
_recallPerPersonToGroundTruth
_recallPerPersonExcludeMissDetection
Tf,V_weightedAveragePrecision
Tf,V_weightedAverageRecall
Tf,V_numSingletons
Tf,V_numValidSingletons
T@"NSMutableArray",&,V_precisionPerCluster
T@"NSMutableArray",&,V_recallPerPersonToGroundTruth
T@"NSMutableArray",&,V_recallPerPersonExcludeMissDetection
workerWithPhotoLibrary:
_dumpFaceprint
_dumpAssetsToFaces
_groundTruthURL
_loadGroundTruthURL:toGroundTruth:error:
_loadGroundTruth:error:
optInPersonCount
_fetchPeopleHomePersons
_anonymizedName:
_processFetchedFaceGroup:forPersonID:facesPerAsset:assetInformation:extendTimeoutBlock:cancelBlock:
_fetchPersonWithIdentifier:facesPerAsset:assetInformation:extendTimeoutBlock:cancelBlock:
optInStatus:error:
optInPerson:error:extendTimeoutBlock:cancelBlock:
exportClustersStates:error:extendTimeoutBlock:cancelBlock:
_overlapRatioOf:with:
_parseGroundTruthWithURL:faceCountPerPerson:personInformation:faceToPerson:assetToFaces:extendTimeoutBlock:cancelBlock:
_exportAssetsToFacesDetails:
_measureClusterWithClusterStateURL:groundTruthFaceCountPerPerson:groundTruthPersonInformation:groundTruthFaceToPerson:groundTruthAssetToFaces:measures:extendTimeoutBlock:cancelBlock:
_measurePVPersonClusters:groundTruthFaceCountPerPerson:groundTruthPersonInformation:groundTruthFaceToPerson:groundTruthAssetToFaces:measures:extendTimeoutBlock:cancelBlock:
_reportCoreAnalyticsWithVisionClusterMeasure:personClusterMeasure:personClusters:andGroundTruthInformation:
calculateAndReportClusterAccuracyWithVisionClusterURL:andPersonClusters:withGroundtruth:results:extendTimeoutBlock:cancelBlock:
calculateAndReportClusterAccuracyWithVisionClusterURL:andPersonClusters:results:extendTimeoutBlock:cancelBlock:
_parseSIMLGroundTruthWithURL:faceCountPerPerson:personInformation:faceToPerson:assetToFaces:extendTimeoutBlock:cancelBlock:
validateClusterAccuracyWithSIMLGroundtruth:results:extendTimeoutBlock:cancelBlock:
_detectionVersion
_recognitionVersion
_personClusterVersion
_clusterDumpFaceFetched
Td,N,V_x
Td,N,V_y
vcp_scaledExposureTime
vcp_flashFired
vcp_captureDeviceMake
vcp_captureDeviceModel
vcp_isAppleCapture
vcp_exifFromImageURL:
_modelURL
analyzerForTrackType:withTransform:requestAnalyses:formatDescription:
T@"NSDictionary",R,&,N
objectAtIndex:
objectForKey:
setAttributesFromLegacyDictionary:
setResults:withClass:forPropertyKey:
exportResultsWithPropertyKey:toLegacyDictionary:withKey:
imageAnalysisFromLegacyDictionary:
movieAnalysisFromLegacyDictionary:
setLocation:
_location
T{CGPoint=dd},N,V_location
relativeActionScore
setRelativeActionScore:
absoluteActionScore
setAbsoluteActionScore:
personID
setPersonID:
setRevision:
_relativeActionScore
_absoluteActionScore
T@"NSArray",&,N,V_keypoints
Tf,N,V_relativeActionScore
Tf,N,V_absoluteActionScore
Ti,N,V_personID
Ti,N,V_revision
chirality
setChirality:
handID
setHandID:
_chirality
Ti,N,V_chirality
Ti,N,V_handID
pixelBuffer
T^{__CVBuffer=},N,V_pixelBuffer
initWithPHFaces:existingResults:
aggregateWith:
createInput:withBuffer:cnnInputHeight:cnnInputWidth:crop:
rectFromPHFace:
_existingResults
_phFaces
priorityAnalysis
addKeypointsToNSArray:keypointConfidence:handBox:keypointsArray:
fastSignLanguageDetection:ofPixelBuffer:withMetadata:
calculatePriorityScore:ofPixelBuffer:withMetadata:
_prevComputedScore
_rotationAngle
_frameCounter
_dominantHand
_handChiralityCounter
_handDetectedInPreviousFrame
_fastGestureDetector
_prevFrameHandKeypoint
_prevTimeStampHandDetected
_prevTimeSignLanguageDetected
_frameEndTimeStamp
_frameStartTimeStamp
_classIndexTracker
_handKeypointTracker
_leftHandKeypointTracker
_rightHandKeypointTracker
_singleFrameExecutionTime
_prevHandCenter
initWithFocalLengthInPixels:offline:isFastMode:
updateIntrinsicWhenRotated
setFrame:
makeValidationDecision
validateFace:eulerAngles:
checkResolutionChange:withRotation:
isTracked
rotateLandmarks:width:height:landmarks:numLandmarks:
analyzeFrame:withFaceRect:withRotation:withTimestamp:
mapToCameraNegativeZ
pose
bufferRotated
_faceCount
_faceBounds
_inDetectionMode
_lmDetector
_lmTracker
_prevLM
_curLM
_detectionModeCounter
_trackingModeCounter
_lostTrackCounter
_angleStable
_validationScore
_validateFailedOnce
_validationQueue
_validationGroup
_valBuffer
_valBufferRotated
_valAngle
_valLM
_shapeModel
_faceValidator
_offline
_bufferRotated
_pose
T{?=[4]},R,N,V_pose
Tr^f,R,N
TB,R,N,V_bufferRotated
sharedImageManager
canDecodeAcceleratedUniformTypeIdentifier:
allowFastPathDecodeWithUniformType:pixelWidth:andPixelHeight:
loggingEnabled
_exportReencodedJPEG
dataForResource:
convertPixelBuffer:toPixelFormat:flushCache:
acceleratedDecodeImageData:pixelFormat:maxDimension:pixelBuffer:orientation:flushCache:
drawImage:pixelFormat:withOrientation:maxDimension:pixelBuffer:
decodeImageSource:withUniformTypeIdentifier:pixelFormat:maxDimension:orientation:pixelBuffer:
pixelBufferWithFormat:andMaxDimension:fromData:withUniformTypeIdentifier:flushCache:orientation:
imageForResource:pixelFormat:
imageForResource:pixelFormat:maxDimension:
imageForResource:pixelFormat:maxDimension:orientation:
pixelBufferWithFormat:fromImageURL:flushCache:
pixelBufferWithFormat:andMaxDimension:fromImageURL:flushCache:orientation:
pixelBufferWithFormat:fromImageURL:flushCache:orientation:
pixelBufferWithFormat:andMaxDimension:fromImageURL:
pixelBufferWithFormat:andMaxDimension:fromImageURL:orientation:
flushCache
compressCVPixelBuffer:toJPEGData:targetBitStreamLength:padding:
_encodeSession
_decodeSession
_transcodeQueue
detector:sharedModel:modelName:
cvtHeatmaps2Keypoints:outHeight:outWidth:inHeight:inWidth:outChannel:keypoints:keypointConfidence:offset:
handKeypointsDetection:box:keypoints:keypointConfidence:forGFT:
_std
_mean
_voiceActivityNew
_audioUnit
motionType
setMotionType:
isFast
setIsFast:
_motionType
_isFast
Ti,N,V_motionType
TB,N,V_isFast
sharedModel:inputNames:properties:
sharedModelStage1:inputNames:properties:
initWithPHFaces:
_actions
_taxonomy
_modelEspressoStage1
initWithParameters:
addSegmentToResults
initWithFocusStatus:atTime:
focusStatus
setFocusStatus:
_focusStatus
Tq,V_focusStatus
energy
setEnergy:
peak
setPeak:
_energy
_peak
Td,N,V_energy
Td,N,V_peak
initWithPixelBuffer:
setCount:
_count
T^{__CVBuffer=},R,N
TQ,N,V_count
sourcePixelBuffer
preWarmWidth:andHeight:
pixelBuffer:width:height:
_scaledPixelBuffers
_sourcePixelBuffer
completionHandler
T@?,R,N,V_completionHandler
requestAnalysis:ofFragmentData:withRequestID:properties:andReply:
requestAnalysis:ofFragmentSurface:withRequestID:properties:andReply:
requestIdentification:forFaceCrop:withOptions:andReply:
requestResidentMaintenance:withOptions:andReply:
requestAnalysis:ofAssetData:withProperties:progressHandler:andCompletionHandler:
requestAnalysis:ofAssetSurface:withProperties:progressHandler:andCompletionHandler:
requestIdentificationForFaceCrop:withOptions:andCompletionHandler:
requestResidentMaintenanceWithOptions:andCompletionHandler:
pairWithFace:andFace:distance:
initWithFace:andFace:distance:
face1
face2
distance
_face1
_face2
_distance
T@"VCPPhotosFace",R,N,V_face1
T@"VCPPhotosFace",R,N,V_face2
Td,R,N,V_distance
initWithThreshold:
_faceObservationsWithBoundingBoxFromFaces:withFaceHashMapping:
_alignFaceObservations:withRequestHandler:error:
_alignBoundingBoxOfFaces:withRequestHandler:orientedWidth:orientedHeight:
_sortedViableFaceMergePairsFromQueryFaces:andCandidateFaces:
mergeExistingFaces:andDetectedFaces:withRequestHandler:orientedWidth:orientedHeight:assetWidth:assetHeight:
_mergeDistanceThreshold
initWithWidth:height:
selectKeyFrameRangeWithMotion:stillTimestamp:isMetaMotion:
analyzeLivePhotoKeyFrame:irisPhotoOffsetSec:originalIrisPhotoOffsetSec:photoTextureScore:hadFlash:cancel:
reportLivePhotoKeyFrameAnalysisResults:selectedKeyFrame:originalStillKeyFrame:stillScore:stillFQScore:stillTimestamp:useSemanticOnly:isKeyFrameSuggested:
fetchAndComputeScoreForKeyFrame:withResult:
computeScoreForPhoto:withRefKeyFrame:
computeOverallFaceQualityScore:
createFaceHeatMap:imageFaces:
updateFaceHeatMap:
getFaceHeat:
_photoSharpnessReliable
_photoSharpness
_petsDominant
_ignoreFace
_faceHeatMap
createInput:withBuffer:inputHeight:inputWidth:
generatePersonBoxes:
generatePersonRegions:boxes:maxNumRegions:
personDetection:personRegions:cancel:
_outputsData
initWithBufferWidth:bufferHeight:andPixelFormat:
_createPixelBufferPool:withBufferWidth:bufferHeight:andPixelFormat:
createPixelBuffer:
_bufferWidth
_bufferHeight
initWithOptions:andExistingResults:
exportWallpaperForAsset:cancel:results:
upgradeWallPaperAtURL:toURL:cancel:results:
initWithFaceResults:
stop
elapsedTimeSeconds
started
_elapsedTimeSeconds
Td,R,V_elapsedTimeSeconds
TB,R,V_started
saveKeypoints
initWithKeypointsOption:aspectRatio:lightweight:forceCPU:sharedModel:flushModel:
parsePersons:width:height:
processPersons:width:height:
generateHumanPose:
createModelWithHeight:srcWidth:
createInput:withBuffer:modelInputHeight:modelInputWidth:
trackingMode
setTrackingMode:
_saveKeypoints
_trackingMode
TB,V_trackingMode
initWithPhotoLibrary:context:cancelOrExtendTimeoutBlock:
scheduleClusteringOfFacesWithLocalIdentifiers:
scheduleUnclusteringOfFacesWithClusterSequenceNumbers:
numberOfFacesPendingClustering
resetFaceClusteringState:
getFaceClusters:clusteringThreshold:utilizingGPU:cancelOrExtendTimeoutBlock:error:
clustererIsReadyToReturnSuggestions
clusterer
_resetFaceClusteringState:
reclusterFacesWithThreshold:shouldRecluster:error:
clusterFacesIfNecessary
_cancelOrExtendTimeoutBlock
initWithDevice:
configureGPU
encodeToCommandBuffer:input:output:flow:upscaledFlow:
_backwarpKernel
_mtlLibrary
sharedLogManager
dateFormatter
logLevel
_logLevel
Ti,R,V_logLevel
hasKeyFrame
hasPlaybackCrop
autoPlayable
setAutoPlayable:
_autoPlayable
TB,N,V_autoPlayable
initWithMonochromeBufferCreator:
_createPixelBufferWithWidth:height:pixelFormat:pixelBuffer:
_convertFromBuffer:toLumaPixelBuffer:abnormalDimension:
loadImageURL:abnormalDimension:withNonPanoPreWarmSizes:toColorPixelBuffer:lumaPixelBuffer:andImage:
_imageManager
supportVectorForward
initNewContext:
execute
device
setDevice:
commandQueue
setCommandQueue:
commandBuffer
setCommandBuffer:
_commandBuffer
T@"<MTLDevice>",&,V_device
T@"<MTLCommandQueue>",&,V_commandQueue
T@"<MTLCommandBuffer>",&,V_commandBuffer
resourceForAsset:withResources:
analyzerWithVCPAsset:forAnalysisTypes:
processExistingAnalyses:
existingAnalysisForMovieAnalyzer
updateDegradedFlagForMajorDimension:
downscaleImage:scaledImage:majorDimension:
checkFaceDominant
_reportPetsAnalysisWithResults:
analyzeImage:performedAnalyses:cancel:
analyzeAsset:withOptions:
_irisAnalyses
_phFaceResults
_phFaceFlags
_imageBlurTextureScore
_preAnalysisSharpnessScore
_requirePHFaceAnalysis
_imageCaptionModel
_configureRequest:withRevision:preferANE:
_loadImageURL:withSession:reencodedImageData:andRequestHandler:
analyzeWithImageURL:requestTypes:reencode:completionHandler:
updateCurationThreshold
isCurated:
finalizeWithDestructiveTrimStart:trimEnd:andCaptureTime:
generateCurationSegment
generateInterestingTrimBasedOnCaptureTime:
calculateCandidateScoreWithRangeAdjust:endIdx:candidateTimeRange:captureTime:
bestTrimTimeRange
isTimestampSkipable:
checkTrimAt:captureTime:
_actionAnalyzer
_bestTrimTimeRange
_curationThreshold
_inTrimStart
_inTrimEnd
_captureTime
_ready
ComputeSceneDelta:
PrintSegments
decideLensSwitchPoint:
finalizeAnalysisPass:
isSegmentPoint
_sceneDeltaBuffer
_sceneSegments
_currentStatus
_isSegmentPoint
sendEvent:withAnalytics:
setValue:forField:andEvent:
accumulateInt64Value:forField:andEvent:
accumulateDoubleValue:forField:andEvent:
valueForField:andEvent:
sendSessionEvent:
_singleAnalyticsSentCount
_sessionAnalyticsSentCount
_sessionAnalytics
Ti,N,V_orientation
imageManager
_createPixelBuffer:withWidth:andHeight:
_createPixelBuffer:withMinorDimension:fromFullPixelBuffer:
_pooledPixelBuffer:withDimension:
fullPixelBuffer:toScaledBuffer:
_createPixelBuffer:withColorSpace:fromPixelBuffer:
loadFullPixelBuffer:scaledPixelBuffer299:scaledPixelBuffer360:fromImageURL:abnormalDimension:
scalePixelBuffer:toPixelBuffer:width:height:
_pixelBufferPools
analyzeDetectedFaces:faceResults:cancel:
T@"NSMutableArray",&,V_faceQualityScores
initWithTransform:frameStats:faceDominated:
_lastestFaceID
_numFacesLastFrame
_lastVertices
_lastJawOpenness
initWithFocalLengthInPixels:principalPoint:cameraTowardsPositiveZ:
getControlPoints
computeBarycentricCoordinates
computeControlPointsCamera:Vt:
computePoints3DCamera
computeSVDVt:Vt:
computeL6x10:L6x10:
computeR6x1:
estimateBetasN1:R6x1:betas:
estimateBetasN2:R6x1:betas:
estimateBetasN3:R6x1:betas:
correctSigns
computeProjectionError:T:
computeRT:T:
estimateRT:betas:R:T:projectionError:
configureGaussNewton:R6x1:betas:jacobian:residual:
optimizeBetas:R6x1:betas:
estimatePose:
estimateExtrinsicsWith:andPoints3D:andNumPoints:
setPose:
_points2D
_points3D
_numPoints
_controlPointsWorld
_controlPointsCamera
_pointsWorld
_pointsImage
_alphas
_points3DCamera
_cameraOrientation
T{?=[4]},V_pose
_signature
faceBounds
setFaceBounds:
T@"VCPProtoBounds",&,N,V_faceBounds
encodeToCommandBuffer:firstInput:secondInput:correlation:
_correlationKernel
initWithFrameStats:timeOfInterest:phFaces:
associatePerson:withPHFaces:
processPersons:humanBounds:dominantPersonIdx:frame:timestamp:duration:
addActiveResults:
_activePoseResults
_humanRect
_lastHumanTimestamp
unimplementedExceptionForMethodName:
isImage
isMovie
typeDescription
T@"VCPFingerprint",R,N
T@"NSURL",R,N
T@"PHFetchResult",R,N
isPano
isLivePhoto
isHDR
isSDOF
hadFlash
exposureTimeSeconds
Tf,R,N
isSlowmo
isTimelapse
timelapseRate
T{?={?=qiIq}{?=qiIq}},R,N
vcp_flagsForPHFace:withFaceRect:
vcp_faceRectFrom:
vcp_queryPHFaces:results:
vcp_PHFaces:
vcp_quickFaceClassificationDone
vcp_needFaceProcessing
vcp_usePHFace
vcp_usePHFaceExpression
vcp_reportDownload:withTaskID:
vcp_inMemoryDownload:withTaskID:toData:cancel:
vcp_requestFileURLForAssetResource:withTaskID:toResourceURL:cancel:
vcp_requestFileURLForAssetResource:withTaskID:timeoutHandler:urlHandler:andCompletionHandler:
setEnd:
_end
T@"VCPProtoPoint",&,N,V_start
T@"VCPProtoPoint",&,N,V_end
timeValuesCount
timeValues
clearTimeValues
addTimeValue:
timeValueAtIndex:
setTimeValues:count:
addHomographyParams:
homographyParamsAtIndex:
inputBoundsX
setInputBoundsX:
inputBoundsY
setInputBoundsY:
inputBoundsHeight
setInputBoundsHeight:
inputBoundsWidth
setInputBoundsWidth:
sourceSizeHeight
setSourceSizeHeight:
sourceSizeWidth
setSourceSizeWidth:
_timeValues
_inputBoundsHeight
_inputBoundsWidth
_inputBoundsX
_inputBoundsY
_sourceSizeHeight
_sourceSizeWidth
Tf,N,V_cropRectX
Tf,N,V_cropRectY
Tf,N,V_cropRectHeight
Tf,N,V_cropRectWidth
Tf,N,V_inputBoundsX
Tf,N,V_inputBoundsY
Tf,N,V_inputBoundsHeight
Tf,N,V_inputBoundsWidth
Tf,N,V_sourceSizeHeight
Tf,N,V_sourceSizeWidth
T^q,R,N
parseHeatmap2Keypoints:
initWithFocalLengthInPixels:
analyzeFrameForPose:withFaceRect:withTimestamp:
_landmarkDetector
_lastTimestamp
_motionTypeModel
_motionScoreModel
initWithFrameWidthInMb:heightInMb:
ExtractActivityDescriptorFromStats:
spatialDescriptorWithMvMagnitudeMean:
descriptors
_widthInMb
_heightInMb
_motionMagnitudeHistogram
_motionMagnitude
T^f,R
initWithParameters:useGPU:
getGPUContext
add:
prepareNetworkFromURL:withInputSize:
forward:
dynamicForward:paramFileUrl:cancel:
_blocks
_quantFactor
T@"VCPCNNData",R,V_output
initWithResourceManager:andResource:
_resourceManager
_resource
initWithResource:
resource
setResource:
activeCount
setActiveCount:
currentCost
setCurrentCost:
_activeCount
_currentCost
T@"VCPMADResource",&,N,V_resource
Tq,N,V_activeCount
Tq,N,V_currentCost
validateCost:
currentBudget
_setBudget:
checkTimeout
entryForResource:
_reserveBudget:
activateResource:
deactivateResource:
reserveBudget:
purgeInactiveResources
_purgeAllResources
purgeAllResources
_budget
_timer
_inactiveDate
_transaction
boundsType
clearBounds
addBounds:
boundsCount
boundsAtIndex:
T@"NSMutableArray",&,N,V_bounds
canRenderVariation
isHomePod
marketingName
vcp_fullAnalysisTypes
vcp_fullAnalysisTypesForResources:
vcp_fullAnalysisTypesForAssetType:
analyzePixelBuffer:withFrame:withTimestamp:andDuration:cancel:
initWithMetadata:sourceSize:cropRect:
storeAnalytics:isLivePhoto:
_analysisDict
_metadata
_cropSize
initWithInputImage:
initWithInputImageFromCGImage:error:
initWithInputImageAtURL:error:
setInputImageWithCGImage:error:
setInputImageWithURL:error:
inputImage
setInputImage:
_inputImage
T^{__CVBuffer=},N,V_inputImage
initWithAngle:
angle
setAngle:
T@"MLMultiArray",&,N,V_angle
URLOfModelInThisBundle
loadWithConfiguration:completionHandler:
loadContentsOfURL:configuration:completionHandler:
initWithMLModel:
initWithConfiguration:error:
initWithContentsOfURL:error:
initWithContentsOfURL:configuration:error:
predictionFromFeatures:error:
predictionFromFeatures:options:error:
predictionFromInputImage:error:
predictionsFromInputs:options:error:
setupTrackerWithReferenceFrame:withROI:
trackInFrame:
setBox:
stableInd
setStableInd:
lostTrackInd
setLostTrackInd:
T^{CGPoint=dd}
stable
lostTrack
T^{CGPoint=dd},VP
TB,Vstable
TB,VlostTrack
@24@0:8^{_NSZone=}16
@16@0:8
B24@0:8@16
v24@0:8@16
Q16@0:8
f16@0:8
v20@0:8f16
v16@0:8
@"VCPProtoTimeRange"
@52@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16f48
{CGRect={CGPoint=dd}{CGSize=dd}}16@0:8
v48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
{CGRect="origin"{CGPoint="x"d"y"d}"size"{CGSize="width"d"height"d}}
@64@0:8{CGAffineTransform=dddddd}16
@72@0:8@16@24{?=qiIq}32^{?=qiIq}56@64
i88@0:8^{__CVBuffer=}16{?=qiIq}24{?=qiIq}48^Q72@80
i80@0:8^{__CVBuffer=}16{?=qiIq}24{?=qiIq}48^Q72
v104@0:8{?={?=qiIq}{?=qiIq}}16@64@72{?=qiIq}80
i64@0:8{?={?=qiIq}{?=qiIq}}16
@"NSMutableArray"
{?="value"q"timescale"i"flags"I"epoch"q}
@"VCPImagePetsAnalyzer"
@"NSArray"
@32@0:8@16@24
i72@0:8{?={?=qiIq}{?=qiIq}}16^{__CVBuffer=}64
B16@0:8
v20@0:8B16
B32@0:8@?16^@24
@24@0:8@16
@24@0:8Q16
d24@0:8@16
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
@"NSURL"16@0:8
B32@0:8@?<v@?>16^@24
@"<PVFetchResultProtocol>"24@0:8@"NSArray"16
@"<PVFetchResultProtocol>"24@0:8Q16
@"<PVFetchResultProtocol>"24@0:8@"<PVMomentProtocol>"16
@"<PVFetchResultProtocol>"24@0:8@"<PVPersonProtocol>"16
@"NSDictionary"24@0:8@"<PVFetchResultProtocol>"16
@"<PVFetchResultProtocol>"32@0:8@"<PVPersonProtocol>"16@"<PVMomentProtocol>"24
@"<PVFetchResultProtocol>"32@0:8@"NSArray"16@"<PVMomentProtocol>"24
@"<PVFetchResultProtocol>"24@0:8@"<PVFaceGroupProtocol>"16
@"<PVFetchResultProtocol>"16@0:8
@"<PVFetchResultProtocol>"24@0:8@"<NSFastEnumeration>"16
@"NSDate"16@0:8
@"NSSet"16@0:8
@"NSDictionary"16@0:8
@24@0:8@"NSDictionary"16
v24@0:8I16B20
@"NSObject<OS_dispatch_queue>"
^{__SCNetworkReachability=}
@96@0:8@16f24B28@32{?={?=qiIq}{?=qiIq}}40Q88
i20@0:8f16
i28@0:8^{__CVBuffer=}16i24
i56@0:8@16@24{?=qiIq}32
i32@0:8@16@24
{?=qiIq}40@0:8{?=qiIq}16
i104@0:8{?=qiIq}16{?=qiIq}40@64{CGRect={CGPoint=dd}{CGSize=dd}}72
@"VCPVideoCNNBackbone"
@"VCPTransforms"
@"VCPVideoPersonDetector"
@"NSString"
@"VCPVideoCNNAutoplay"
@"VCPVideoCNNCameraMotion"
@"VCPVideoCNNQuality"
@"VCPVideoCNNHighlight"
{?="distanceToPreviousScene"b1"flickerScore"b1"sceneprintDistanceToPreviousScene"b1}
@32@0:8^{__CVBuffer=}16@24
@"MLFeatureValue"24@0:8@"NSString"16
^{__CVBuffer=}
v40@0:8r^{?=qiIq}16r^{?=qiIq}24@32
i28@0:8^{opaqueCMSampleBuffer=}16i24
i16@0:8
i24@0:8r^{AudioStreamBasicDescription=dIIIIIIII}16
i88@0:8^{AudioBufferList=I[1{AudioBuffer=II^v}]}16{AudioTimeStamp=dQdQ{SMPTETime=ssIIIssss}II}24
i24@0:8r^{?=qiIq}16
@"NSDictionary"
{AudioStreamBasicDescription="mSampleRate"d"mFormatID"I"mFormatFlags"I"mBytesPerPacket"I"mFramesPerPacket"I"mBytesPerFrame"I"mChannelsPerFrame"I"mBitsPerChannel"I"mReserved"I}
B20@0:8B16
@24@0:8@?16
@20@0:8B16
@72@0:8@16@24@32@40B48B52f56f60f64B68
i48@0:8^{__CVBuffer=}16{?=qiIq}24
i88@0:8^{__CVBuffer=}16{?=qiIq}24{?=qiIq}48^Q72@?80
i96@0:8^{__CVBuffer=}16{?=qiIq}24{?=qiIq}48@72^Q80@?88
i40@0:8{?=qiIq}16
f40@0:8@16^{EncodeStats=^^?^B^B^{MotionVector}^{MotionVector}^{MotionVector}^{MotionVector}^S^S^I^S^S^S^S^S^S^S^S^S^S^SIBBBii}24i32i36
i20@0:8i16
v24@0:8^v16
f24@0:8^v16
i36@0:8@16@24B32
i80@0:8@16@24{?={?=qiIq}{?=qiIq}}32
i44@0:8^{__CFArray=}16@24@32B40
v24@0:8^{__CVBuffer=}16
v32@0:8^v16@24
@64@0:8{?={?=qiIq}{?=qiIq}}16
^{MotionFilter=^{FrameBuffer}BB}
^{MetaDataAnalysis=B^{FrameBuffer}{Translation=fff}{Translation=fff}}
^{IrisAnalysis=ffiiB^{__CFArray}}
{FrameBuffer="frame_count_"i"buffer_"[35{Frame="frame_idx_"i"timestamp_"{?="value"q"timescale"i"flags"I"epoch"q}"duration_"{?="value"q"timescale"i"flags"I"epoch"q}"ave_motion_"{Translation="x_"f"y_"f"z_"f}"org_motion_"{Translation="x_"f"y_"f"z_"f}"quality_score_"f"distortion_"Q"distortion_norm_"f"motion_change_"{Translation="x_"f"y_"f"z_"f}"compressed_bytes_"I"blur_"B"acc_var_"{Translation="x_"f"y_"f"z_"f}"texture_"f"motion_result_"{MotionResult="significant_values_"[6f]"confidence_"[6f]"fine_action_score_"f"action_score_"f"track_score_"f"rotation_angle_"f"subtle_motion_score_"f"is_stable_"B"action_blocks_"i"action_motion_"f"valid_mb_"B"valid_submb_"B"support_size_"i"residual_var_"f"gmv_"[2f]"motion_param_"{array<float, 6UL>="__elems_"[6f]}"motion_param_diff_"{array<float, 6UL>="__elems_"[6f]}"duration_"{?="value"q"timescale"i"flags"I"epoch"q}"scene_delta_"f"scene_delta_ratio_"f"objects_"{Vector<ma::Object *>="vector_"^{__CFArray}}"detect_objects_"{Vector<ma::Object *>="vector_"^{__CFArray}}"imported_objects_"{Vector<ma::Object *>="vector_"^{__CFArray}}}"flow_"^f"interestingness_"f"obstruction_"f"colorfulness_score_"f"histogram_"{Histogram="extremities_"f"overexposes_"f"histogram_"[3^i]"moments_hist_"[2^i]}}]}
{Histogram="extremities_"f"overexposes_"f"histogram_"[3^i]"moments_hist_"[2^i]}
@"NSMutableDictionary"
@"VCPFrameAnalysisStats"
@"VCPFrameScoreFilter"
@"VCPMotionFlowSubtleMotionAnalyzer"
@"VCPMotionFlowAnalyzer"
@32@0:8@16^@24
@80@0:8{CGAffineTransform=dddddd}16@64@72
i32@0:8^{__CVBuffer=}16@24
B32@0:8@16@24
B84@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48B80
i56@0:8^{__CVBuffer=}16{?=qiIq}24@48
@"VCPCNNSmileDetector"
@"VCPCNNPoseEstimator"
{?={?=qiIq}{?=qiIq}}16@0:8
@32@0:8@16@?24
v32@0:8@16Q24
B24@0:8^@16
@"NSData"
{atomic<bool>="__a_"{__cxx_atomic_impl<bool, std::__cxx_atomic_base_impl<bool>>="__a_value"AB}}
@32@0:8B16B20@24
^f48@0:8i16i20^i24^i32^f40
i36@0:8^{CGPoint=dd}16^f24f32
@"VCPCNNModelEspresso"
f56@0:8*16*24*32i40i44q48
f48@0:8*16i24i28q32*40
i48@0:8^{__CVBuffer=}16^Q24^@32@?40
@24@0:8^{__CVBuffer=}16
i32@0:8^f16@24
@"NSData"16@0:8
i32@0:8^f16@"<VCPDistanceDescriptorProtocol>"24
@24@0:8@"NSData"16
@"VNImageprint"
d16@0:8
v24@0:8d16
{?="contentScore"b1"globalQualityScore"b1}
i20@0:8B16
{CGAffineTransform=dddddd}64@0:8{CGAffineTransform=dddddd}16
i32@0:8@16^Q24
{CGAffineTransform="a"d"b"d"c"d"d"d"tx"d"ty"d}
v24@0:8q16
q16@0:8
S16@0:8
@40@0:8@16@24@?32
@?16@0:8
v24@0:8@?16
@"VNCanceller"
B32@0:8@16^@24
@32@0:8Q16^@24
@40@0:8Q16Q24^@32
@40@0:8@16@24^@32
@"NSDictionary"32@0:8Q16^@24
@"NSNumber"40@0:8Q16Q24^@32
@"NSDictionary"40@0:8@"NSArray"16@"NSArray"24^@32
v32@0:8@16@24
B28@0:8B16@?20
v24@0:8Q16
v40@0:8{?=QQBB}16
B64@0:8@16@24@32@40@?48^@56
@44@0:8@16B24@28@36
@36@0:8@16B24@28
v40@0:8@16^@24@?32
v32@0:8@16@?24
B40@0:8^@16^Q24^@32
B48@0:8@16@24@32^@40
B36@0:8B16@?20^@28
Q36@0:8B16@?20^@28
@48@0:8@16@24@?32^@40
@40@0:8@16^@24@?32
B60@0:8@16Q24B32^@36@?44^@52
@40@0:8^@16^@24@?32
B56@0:8^@16^d24^B32@?40^@48
@"PHPhotoLibrary"
@"VCPPhotosPersistenceDelegate"
@"NSObject<OS_dispatch_group>"
@"VCPPhotosFaceProcessingContext"
@"NSURL"
@"NSNumber"
@"NSSet"
@"NSMutableSet"
@"VNClustererBuilder"
@"VCPSuggestionRequest"
@"NSLock"
{?="countOfEligibleFaces"Q"countOfFacesPendingToAdd"Q"isClustering"B"rebuildRequired"B}
@"NSDate"
{mach_timebase_info="numer"I"denom"I}
@40@0:8^{__CVBuffer=}16@24^@32
{CGSize=dd}32@0:8@16^@24
I16@0:8
@"VCPImageHumanPoseAnalyzer"
i24@0:8@16
i112@0:8@16@24{CGRect={CGPoint=dd}{CGSize=dd}}32{?=qiIq}64{?=qiIq}88
@64@0:8@16@24{CGRect={CGPoint=dd}{CGSize=dd}}32
{CGSize="width"d"height"d}
@"VNImageRequestHandler"
@"VCPMADVIRemoveBackgroundCachedImageHandler"
@40@0:8@16@24@32
@40@0:8@"MADRequest"16@"VCPMADServiceImageAsset"24@"NSString"32
@"NSArray"16@0:8
v24@0:8@"<MTLDevice>"16
@"MADVIRemoveBackgroundRequest"
@"VCPMADServiceImageAsset"
@"<MTLDevice>"
@"VNImageBasedRequest"
{?=qiIq}16@0:8
@"VNRequest"
@20@0:8i16
i24@0:8i16i20
i32@0:8^{CGImage=}16^^{__CVBuffer}24
^{CGColorSpace=}
^{CGContext=}
^{__CVPixelBufferPool=}
^{OpaqueVTPixelTransferSession=}
@56@0:8@16Q24@32@?40@?48
@48@0:8Q16@24@32^@40
@48@0:8@16Q24@32^@40
@"VCPDatabaseReader"
v56@0:8@16@24I32@36i44@?48
v60@0:8@16@24@32@40i48@?52
v60@0:8@16@24Q32@40i48@?52
v64@0:8@16@24I32@36@44i52@?56
v44@0:8@16@24i32@?36
v36@0:8@16i24@?28
v32@0:8Q16Q24
v60@0:8i16@20@28Q36@44@?52
v60@0:8i16@20@28@36Q44@?52
v48@0:8i16@20@28B36@?40
v52@0:8i16Q20@28@36@?44
v60@0:8i16Q20@28@36@44@?52
v60@0:8i16@20@28@36@44@?52
v20@0:8i16
v48@0:8i16@20B28@32@?40
v44@0:8i16@20@28@?36
v36@0:8i16@20@?28
v40@0:8i16B20@24@?32
v40@0:8@16Q24@?32
v52@0:8i16@20@28@36@?44
v52@0:8Q16@24@32i40@?44
v32@0:8@"NSURL"16@?<v@?@"NSString">24
v56@0:8@"NSArray"16@"IOSurface"24I32@"NSString"36i44@?<v@?@"NSArray"@"NSError">48
v60@0:8@"NSArray"16@"NSURL"24@"NSString"32@"NSString"40i48@?<v@?@"NSArray"@"NSError">52
v60@0:8@"NSArray"16@"NSData"24@"UTType"32@"NSString"40i48@?<v@?@"NSArray"@"NSError">52
v60@0:8@"NSArray"16@"NSString"24Q32@"NSURL"40i48@?<v@?@"NSArray"@"NSError">52
v64@0:8@"NSArray"16@"IOSurface"24I32@"NSString"36@"NSURL"44i52@?<v@?@"NSArray"@"NSError">56
v44@0:8@"NSArray"16@"NSString"24i32@?<v@?@"NSArray"@"NSError">36
v36@0:8@"NSDictionary"16i24@?<v@?@"NSDictionary"@"NSError">28
v24@0:8@?<v@?@"NSDictionary">16
v60@0:8i16@"NSArray"20@"NSDictionary"28Q36@"NSArray"44@?<v@?@"NSDictionary"@"NSError">52
v60@0:8i16@"NSArray"20@"NSURL"28@"NSDictionary"36Q44@?<v@?@"NSDictionary"@"NSError">52
v48@0:8i16@"NSURL"20@"NSArray"28B36@?<v@?@"NSDictionary"@"NSError">40
v52@0:8i16Q20@"NSURL"28@"NSDictionary"36@?<v@?@"NSError">44
v60@0:8i16Q20@"NSArray"28@"NSURL"36@"NSDictionary"44@?<v@?@"NSDictionary"@"NSError">52
v60@0:8i16@"NSURL"20@"NSURL"28@"NSDictionary"36@"NSArray"44@?<v@?@"NSDictionary"@"NSError">52
v24@0:8@?<v@?@"NSError">16
v24@0:8@?<v@?Q>16
v24@0:8@"NSURL"16
v60@0:8i16@"NSString"20@"NSArray"28@"NSArray"36@"NSURL"44@?<v@?@"NSArray"@"NSError">52
v48@0:8i16@"NSArray"20B28@"NSURL"32@?<v@?B@"NSError">40
v44@0:8i16@"NSArray"20@"NSURL"28@?<v@?@"NSArray"@"NSError">36
v36@0:8i16@"NSURL"20@?<v@?B@"NSError">28
v44@0:8i16@"NSDictionary"20@"NSURL"28@?<v@?@"NSString"@"NSError">36
v40@0:8i16B20@"NSURL"24@?<v@?@"NSDictionary"@"NSError">32
v36@0:8i16@"NSURL"20@?<v@?@"NSDictionary"@"NSError">28
v44@0:8i16@"NSArray"20@"NSURL"28@?<v@?B@"NSError">36
v32@0:8@"NSURL"16@?<v@?@"NSDictionary"@"NSError">24
v40@0:8@"NSURL"16Q24@?<v@?@"NSString"@"NSError">32
v44@0:8i16@"NSURL"20@"NSArray"28@?<v@?@"NSDictionary"@"NSError">36
v52@0:8i16@"NSURL"20@"NSURL"28@"NSURL"36@?<v@?@"NSDictionary"@"NSError">44
v44@0:8i16@"NSURL"20@"NSURL"28@?<v@?@"NSDictionary"@"NSError">36
v44@0:8@"NSArray"16@"NSURL"24i32@?<v@?@"NSDictionary"@"NSError">36
v52@0:8Q16@"NSArray"24@"NSURL"32i40@?<v@?@"NSError">44
v28@0:8d16i24
i40@0:8^f16@24Q32
i48@0:8^f16@24Q32@?40
i32@0:8^@16@24
i40@0:8^@16@24@?32
i40@0:8^@16@24Q32
i48@0:8^@16@24Q32@?40
i56@0:8Q16@24@32@?40@?48
i52@0:8@16@24B32@?36@?44
i44@0:8@16B24@?28@?36
i48@0:8Q16@24@?32@?40
i48@0:8@16@24@?32@?40
i40@0:8@16@24@?32
i32@0:8@16@?24
i40@0:8@16Q24@?32
@"NSXPCConnection"
i64@0:8@16@24@32@40@?48@?56
i52@0:8@16B24@28@?36@?44
i40@0:8@16@?24@?32
i44@0:8B16@20@?28@?36
i48@0:8@16@24@32@?40
i24@0:8^f16
^f16@0:8
i40@0:8^{?=^v^v[4Q][4Q]QQQQQQQQQQi}16@24@32
i64@0:8^ 16Q24Q32Q40@48@56
i40@0:8^i16^i24^I32
i40@0:8^{__CVBuffer=}16@24@32
{?="plan"^v"network_index"i}
{?="data"^v"reserved"^v"dim"[4Q]"stride"[4Q]"width"Q"height"Q"channels"Q"batch_number"Q"sequence_length"Q"stride_width"Q"stride_height"Q"stride_channels"Q"stride_batch_number"Q"stride_sequence_length"Q"storage_type"i}
@40@0:8{?=qiIq}16
i36@0:8^{__CVBuffer=}16^f24i32
i40@0:8^f16^{__CVBuffer=}24i32i36
^f40@0:8i16i20^i24^i32
i52@0:8^f16i24i28@32@40i48
i28@0:8@16i24
i48@0:8^{__CVBuffer=}16@24@32@?40
@"CVNLPCommSafetyHandler"
@"MADImageSafetyClassificationRequest"
i64@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16^{__CVBuffer=}48^B56
@72@0:8@16@24Q32Q40@48i56B60^@64
@92@0:8@16@24@32Q40Q48@56@64@72@80i88
@32@0:8@16q24
d32@0:8@16@24
B40@0:8@16@24@32
B48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
q24@0:8Q16
s16@0:8
v20@0:8s16
v20@0:8S16
@"VCPVNImageprintWrapper"
^v16@0:8
^v20@0:8B16
@28@0:8B16B20B24
@"VCPProtoBounds"
@48@0:8{?=qiIq}16f40B44
v72@0:8{?={?=qiIq}{?=qiIq}}16f64B68
v40@0:8{?=qiIq}16
v44@0:8{?=qiIq}16B40
v64@0:8{?={?=qiIq}{?=qiIq}}16
{?="start"{?="value"q"timescale"i"flags"I"epoch"q}"duration"{?="value"q"timescale"i"flags"I"epoch"q}}
@32@0:8@16f24f28
v76@0:8@16{?=qiIq}24{?=qiIq}48B72
v72@0:8@16{?={?=qiIq}{?=qiIq}}24
@44@0:8Q16Q24B32@?36
@36@0:8Q16B24@?28
@"NSObject<OS_dispatch_source>"
S24@0:8@16
@24@0:8q16
@20@0:8S16
S24@0:8q16
@28@0:8@16B24
i40@0:8^@16#24Q32
i36@0:8^@16#24i32
{CGRect={CGPoint=dd}{CGSize=dd}}56@0:8d16d24d32d40d48
@48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
v40@0:8*16Q24^f32
i24@0:8^Q16
i32@0:8^{__CVBuffer=}16^Q24
@"VCPCNNModel"
@"VCPCNNData"
f24@0:8@16
i32@0:8[6f]16[6f]24
i24@0:8^v16
i24@0:8^{EncodeStats=^^?^B^B^{MotionVector}^{MotionVector}^{MotionVector}^{MotionVector}^S^S^I^S^S^S^S^S^S^S^S^S^S^SIBBBii}16
v80@0:8^{__CVBuffer=}16{?=qiIq}24{?=qiIq}48@?72
{Frame="frame_idx_"i"timestamp_"{?="value"q"timescale"i"flags"I"epoch"q}"duration_"{?="value"q"timescale"i"flags"I"epoch"q}"ave_motion_"{Translation="x_"f"y_"f"z_"f}"org_motion_"{Translation="x_"f"y_"f"z_"f}"quality_score_"f"distortion_"Q"distortion_norm_"f"motion_change_"{Translation="x_"f"y_"f"z_"f}"compressed_bytes_"I"blur_"B"acc_var_"{Translation="x_"f"y_"f"z_"f}"texture_"f"motion_result_"{MotionResult="significant_values_"[6f]"confidence_"[6f]"fine_action_score_"f"action_score_"f"track_score_"f"rotation_angle_"f"subtle_motion_score_"f"is_stable_"B"action_blocks_"i"action_motion_"f"valid_mb_"B"valid_submb_"B"support_size_"i"residual_var_"f"gmv_"[2f]"motion_param_"{array<float, 6UL>="__elems_"[6f]}"motion_param_diff_"{array<float, 6UL>="__elems_"[6f]}"duration_"{?="value"q"timescale"i"flags"I"epoch"q}"scene_delta_"f"scene_delta_ratio_"f"objects_"{Vector<ma::Object *>="vector_"^{__CFArray}}"detect_objects_"{Vector<ma::Object *>="vector_"^{__CFArray}}"imported_objects_"{Vector<ma::Object *>="vector_"^{__CFArray}}}"flow_"^f"interestingness_"f"obstruction_"f"colorfulness_score_"f"histogram_"{Histogram="extremities_"f"overexposes_"f"histogram_"[3^i]"moments_hist_"[2^i]}}
^{EncodeStatsHW=^^?^B^B^{MotionVector}^{MotionVector}^{MotionVector}^{MotionVector}^S^S^I^S^S^S^S^S^S^S^S^S^S^SIBBBiii^{OpaqueVTCompressionSession}^{__CFData}{?=qiIq}iiB}
[6[5f]]
@"VCPObjectPool"
i36@0:8^{__sFILE=*iiss{__sbuf=*i}i^v^?^?^?^?{__sbuf=*i}^{__sFILEX}i[3C][1C]{__sbuf=*i}iq}16i24i28i32
@"VNClassifyImageAestheticsRequest"
@"VNSceneClassificationRequest"
@"VNCreateSceneprintRequest"
@"VNGenerateAttentionBasedSaliencyImageRequest"
@"VNClassifyJunkImageRequest"
@"VNRecognizeObjectsRequest"
@"VNGenerateObjectnessBasedSaliencyImageRequest"
@"VNClassifyPotentialLandmarkRequest"
@"VNVYvzEtX1JlUdu8xx5qhDI"
@"VN6Mb1ME89lyW3HpahkEygIG"
@"VN5kJNH3eYuyaLxNpZr5Z7zi"
@"VNClassifyMemeImageRequest"
@"VN1JC7R3k4455fKQz0dY1VhQ"
@"VNRecognizeDocumentElementsRequest"
@"VNClassifyCityNatureImageRequest"
@"VNCreateImageFingerprintsRequest"
{?="faceQuality"b1}
B20@0:8f16
{HinkleyDetector="sensitivity_"f"threshold_"f"min_length_"i"stats_"{HinkleyStats="upper_"f"lower_"f"max_"f"min_"f}}
@"VCPVideoMetaMotionSegment"
@44@0:8f16{?=qiIq}20
v44@0:8f16{?=qiIq}20
@"VIService"
@"VCPProtoTime"
@48@0:8@16@24@32@40
i40@0:8{vector<float *, std::allocator<float *>>=^^f^^f{__compressed_pair<float **, std::allocator<float *>>=^^f}}16
v24@0:8^f16
{vector<espresso_buffer_t, std::allocator<espresso_buffer_t>>=^{?}^{?}{__compressed_pair<espresso_buffer_t *, std::allocator<espresso_buffer_t>>=^{?}}}16@0:8
v40@0:8{vector<espresso_buffer_t, std::allocator<espresso_buffer_t>>=^{?}^{?}{__compressed_pair<espresso_buffer_t *, std::allocator<espresso_buffer_t>>=^{?}}}16
{?=^v^v[4Q][4Q]QQQQQQQQQQi}16@0:8
v184@0:8{?=^v^v[4Q][4Q]QQQQQQQQQQi}16
@"VCPCNNEspressoContext"
{vector<espresso_buffer_t, std::allocator<espresso_buffer_t>>="__begin_"^{?}"__end_"^{?}"__end_cap_"{__compressed_pair<espresso_buffer_t *, std::allocator<espresso_buffer_t>>="__value_"^{?}}}
i40@0:8@16^@24@?32
@"VCPLoaned"
@56@0:8^f16^f24Q32Q40i48i52
i28@0:8f16f20f24
i36@0:8^f16f24^f28
i64@0:8^f16Q24Q32{DSPSplitComplex=^f^f}40^f56
B28@0:8i16i20i24
{DSPSplitComplex="realp"^f"imagp"^f}
@68@0:8f16{?={?=qiIq}{?=qiIq}}20
i64@0:8{?=qiIq}16{?=qiIq}40
@"VCPVideoCaptionEncoder"
@"MAAsset"
@32@0:8@16r^{?={?=qiIq}{?=qiIq}}24
i28@0:8B16^{?={?=qiIq}{?=qiIq}}20
i72@0:8{?={?=qiIq}{?=qiIq}}16^^{opaqueCMSampleBuffer}64
^{opaqueCMSampleBuffer=}16@0:8
@"AVAssetReader"
@"AVAssetReaderSampleReferenceOutput"
@"NSObject<OS_dispatch_semaphore>"
[2^{opaqueCMSampleBuffer}]
@36@0:8Q16i24@28
@40@0:8Q16@24^@32
B40@0:8^f16@24^@32
@132@0:8{CGAffineTransform=dddddd}16{?={?=qiIq}{?=qiIq}}64B112@116@124
i24@0:8^{__CVBuffer=}16
f32@0:8@16@24
@"VCPImageBlurAnalyzer"
@"VCPImageFaceQualityAnalyzer"
@"VCPVideoKeyFrame"
@"AVAssetReaderTrackOutput"
@"AVAssetReaderOutputMetadataAdaptor"
v56@0:8@16@24^Q32^Q40^Q48
Q24@0:8@16
Q40@0:8@16@24Q32
Q32@0:8@16Q24
i48@0:8@16Q24^@32@?40
v48@0:8@16Q24@32@?40
B20@0:8i16
@48@0:8i16i20i24B28B32i36i40B44
i28@0:8^{__sFILE=*iiss{__sbuf=*i}i^v^?^?^?^?{__sbuf=*i}^{__sFILEX}i[3C][1C]{__sbuf=*i}iq}16s24
v32@0:8@16^{__CVBuffer=}24
f92@0:8f16{CGRect={CGPoint=dd}{CGSize=dd}}20{CGRect={CGPoint=dd}{CGSize=dd}}52i84i88
@28@0:8@16f24
f84@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48B80
@"VCPImageSaliencyAnalyzer"
@40@0:8^{opaqueCMSampleBuffer=}16@24^@32
@"VCPImageHandsAnalyzer"
i40@0:8B16@20B28B32B36
i40@0:8^{__CVBuffer=}16^{__CVBuffer=}24@?32
^f32@0:8^i16^i24
i32@0:8^{__CVBuffer=}16f24f28
i40@0:8^{__CVBuffer=}16^{__CVBuffer=}24f32f36
i28@0:8@16I24
{vector<float *, std::allocator<float *>>="__begin_"^^f"__end_"^^f"__end_cap_"{__compressed_pair<float **, std::allocator<float *>>="__value_"^^f}}
i36@0:8@16f24@?28
@"MADEmbeddingGenerationRequest"
B40@0:8@16@24^@32
B88@0:8{?={?=qiIq}{?=qiIq}}16{?=qiIq}64
B56@0:8^{opaqueCMSampleBuffer=}16{?=qiIq}24^@48
B32@0:8^{opaqueCMSampleBuffer=}16^@24
B48@0:8{?=qiIq}16^@40
v20@0:8I16
{CF<opaqueCMSampleBuffer *>="value_"^{opaqueCMSampleBuffer}}
{?="faceSharpness"b1}
@40@0:8@16Q24^@32
i40@0:8^{CGPoint=dd}16^f24^@32
v64@0:8^f16^f24Q32Q40Q48Q56
v28@0:8i16^f20
v40@0:8^f16Q24Q32
i56@0:8^f16@24^{CGPoint=dd}32^f40^@48
i52@0:8@16f24{CGPoint=dd}28^f44
i32@0:8@16^f24
[8^f]
@"VCPGaborFilter"
@"VCPHumanPoseImageRequest"
@24@0:8i16B20
i40@0:8^{__CVBuffer=}16^f24i32i36
f40@0:8^f16i24i28i32i36
i32@0:8^f16i24i28
i24@0:8@?16
i40@0:8^{__CVBuffer=}16@24@?32
i84@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24{CGSize=dd}56B72@76
[5{CGRect="origin"{CGPoint="x"d"y"d}"size"{CGSize="width"d"height"d}}]
[5f]
B24@0:8Q16
Q24@0:8Q16
Q32@0:8q16Q24
@212@0:8Q16{CGAffineTransform=dddddd}24{?={?=qiIq}{?=qiIq}}72B120f124@128B136B140@144B152{?={?=qiIq}{?=qiIq}}156@204
v64@0:8@16@24@32@40{CGSize=dd}48
@"VCPVideoKeyFrameAnalyzer"
@"VCPMovieHighlightAnalyzer"
@"VCPImageDescriptor"
i44@0:8B16@20i28i32@?36
i28@0:8^^{__CVBuffer}16I24
i32@0:8^{__CVBuffer=}16^{__CVBuffer=}24
i32@0:8^{__CVBuffer=}16^{?=[7{?=iii}][7^{__CVBuffer}]}24
i36@0:8i16^{__CVBuffer=}20^{__CVBuffer=}28
i36@0:8^{__CVBuffer=}16^{__CVBuffer=}24i32
i40@0:8^{__CVBuffer=}16^{__CVBuffer=}24i32i36
@"VCPFlowFeatureExtractor"
[7@"VCPFlowDecoder"]
@"VCPCorrelation"
@"VCPBackwarp"
[2{?="featureShape"[7{?="channels"i"height"i"width"i}]"feature"[7^{__CVBuffer}]}]
{?="correlations"[7^{__CVBuffer}]"flows"[7^{__CVBuffer}]"upscaledFlows"[7^{__CVBuffer}]"warpedBuffers"[7^{__CVBuffer}]}
{CLLocationCoordinate2D=dd}16@0:8
i44@0:8Q16Q24i32^^{__CVBuffer}36
i36@0:8^{__CVBuffer=}16^^{__CVBuffer}24i32
@40@0:8^{__CVBuffer=}16^{__CVBuffer=}24^@32
@52@0:8^{__CVBuffer=}16^{__CVBuffer=}24B32^{__CVBuffer=}36^@44
@"VCPImageMotionFlowAnalyzer"
i32@0:8q16^@24
@32@0:8@16Q24
i40@0:8@16@?24^Q32
i32@0:8@?16^Q24
@"AVAsset"
i48@0:8@16{?=qiIq}24
v28@0:8B16@20
v60@0:8B16f20f24f28f32f36f40B44f48f52B56
@"VNSceneprint"
@"VCPCNNPetsDetector"
i32@0:8[3[3f]]16[3f]24
i32@0:8[3f]16[3[3f]]24
i32@0:8[3f]16[3f]24
i24@0:8^{?=[4]}16
{Matrix<float, 12U, 1U, false>="m_data"[12f]}
{Matrix<float, 12U, 12U, false>="m_data"[144f]}
v24@0:8@"<PVFetchResultProtocol>"16
@"<PVFaceProtocol>"16@0:8
v24@0:8@"<PVFaceProtocol>"16
Q36@0:8B16Q20Q28
{CGRect={CGPoint=dd}{CGSize=dd}}32@0:8Q16Q24
{CGRect={CGPoint=dd}{CGSize=dd}}80@0:8Q16Q24{CGAffineTransform=dddddd}32
@"VNFaceObservation"
v24@0:8f16f20
v52@0:8^f16^f24^f32i40^f44
v48@0:8r^f16r^i24r^f32^f40
v48@0:8r^f16r^f24r^f32^f40
v32@0:8r^f16^f24
v52@0:8r^f16i24r^f28r^f36^f44
v36@0:8r^f16^f24B32
B24@0:8^f16
v56@0:8^f16^f24^f32^f40^f48
v44@0:8^f16^f24^f32i40
v68@0:8^f16^f24^f32^f40^f48^f56i64
{matrix<double, 6L, 1L, dlib::memory_manager_stateless_kernel_1<char>, dlib::row_major_layout>={layout<double, 6L, 1L, dlib::memory_manager_stateless_kernel_1<char>, 1>=[6d]}}16@0:8
B28@0:8i16B20B24
{?=[4]}16@0:8
^16@0:8
@"VCPFaceTensorModel"
^{?=ffi}
[8f]
[9f]
[12f]
[3f]
[126f]
[189f]
@"VCPPnPSolver"
[51f]
@24@0:8^@16
@"MADVITextLookupRequest"
@"<VICancellable>"
@"VCPProtoLine"
@"VCPProtoPoint"
B80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48
v48@0:8Q16@24@32@?40
v48@0:8Q16@"IOSurface"24@"NSDictionary"32@?<v@?@"NSDictionary"@"NSError">40
@28@0:8i16@20
v48@0:8Q16^{__CVBuffer=}24@32@?40
{CGPoint=dd}16@0:8
@48@0:8{CGPoint=dd}16{CGPoint=dd}32
f24@0:8Q16
v32@0:8^f16Q24
{?="list"^f"count"Q"size"Q}
@24@0:8^{__sFILE=*iiss{__sbuf=*i}i^v^?^?^?^?{__sbuf=*i}^{__sFILEX}i[3C][1C]{__sbuf=*i}iq}16
v32@0:8^f16^f24
v44@0:8^f16i24^f28^f36
^i16@0:8
@56@0:8@16Q24Q32Q40@48
{?="loopFadeLen"b1"loopPeriod"b1"loopStart"b1}
@28@0:8i16B20B24
i56@0:8^{__CVBuffer=}16^Q24@32^@40@?48
@"VCPCNNPetsKeypointsDetector"
i68@0:8@16@24@32@40@48@56f64
f80@0:8{?={?=qiIq}{?=qiIq}}16@64^i72
f64@0:8{?={?=qiIq}{?=qiIq}}16
i68@0:8{?={?=qiIq}{?=qiIq}}16f64
@"VCPVideoActivityDescriptor"
@68@0:8{?={?=qiIq}{?=qiIq}}16f64
f28@0:8@16f24
B72@0:8{?={?=qiIq}{?=qiIq}}16@64
B28@0:8@16f24
f72@0:8{?={?=qiIq}{?=qiIq}}16@64
f20@0:8f16
@28@0:8i16i20i24
@100@0:8Q16B24f28B32B36B40{?={?=qiIq}{?=qiIq}}44@92
i168@0:8@16@24@32@40@48@56@64@72@80@88@96@104@112@120@128@136@144{CGSize=dd}152
B64@0:8{?={?=qiIq}{?=qiIq}}16
@120@0:8@16{?={?=qiIq}{?=qiIq}}24{?={?=qiIq}{?=qiIq}}72
@112@0:8{?={?=qiIq}{?=qiIq}}16{?={?=qiIq}{?=qiIq}}64
{?={?=qiIq}{?=qiIq}}64@0:8{?={?=qiIq}{?=qiIq}}16
f68@0:8{?={?=qiIq}{?=qiIq}}16B64
@68@0:8{?={?=qiIq}{?=qiIq}}16B64
i64@0:8{array<float, 6UL>=[6f]}16{array<float, 6UL>=[6f]}40
B88@0:8^f16@24{?={?=qiIq}{?=qiIq}}32@80
{CGRect={CGPoint=dd}{CGSize=dd}}64@0:8{?={?=qiIq}{?=qiIq}}16
{?={?=qiIq}{?=qiIq}}68@0:8{?={?=qiIq}{?=qiIq}}16B64
@"AVAssetImageGenerator"
{array<float, 6UL>="__elems_"[6f]}
@"VCPColorNormalizationAnalyzer"
v40@0:8@16@24@?32
v32@0:8@"NSDictionary"16@?<v@?@"NSError">24
v32@0:8@"NSDictionary"16@?<v@?@"NSDictionary"@"NSError">24
v40@0:8@"NSData"16@"NSDictionary"24@?<v@?@"NSDictionary"@"NSError">32
@40@0:8@16@?24@?32
{CF<const opaqueCMFormatDescription *>="value_"^{opaqueCMFormatDescription}}
@"VCPHomeKitAnalysisSession"
i36@0:8^{sqlite3_stmt=}16i24@28
i40@0:8^{sqlite3_stmt=}16i24i28@32
i40@0:8@16^@24^q32
i32@0:8q16@24
i40@0:8q16@24@32
i40@0:8@16@24@32
@32@0:8Q16Q24
Q32@0:8Q16Q24
i32@0:8^q16@24
q24@0:8@16
i40@0:8^@16Q24@32
^{sqlite3=}
@"AVURLAsset"
^{__CVBuffer=}24@0:8Q16
^{__CVBuffer=}32@0:8Q16^I24
{CGAffineTransform=dddddd}20@0:8I16
i32@0:8^Q16^@24
@64@0:8@16@24@32@40@?48@?56
@36@0:8@16B24^@28
@"AVAudioPCMBuffer"
^{LkFsMeasure=IIqBIIddddqqIII[30[6f]]^f^f^f^{DspLibBiquad}^{DspLibBiquad}}
^{CAStreamBasicDescription=dIIIIIIII}
{vector<double, std::allocator<double>>="__begin_"^d"__end_"^d"__end_cap_"{__compressed_pair<double *, std::allocator<double>>="__value_"^d}}
{vector<float, std::allocator<float>>="__begin_"^f"__end_"^f"__end_cap_"{__compressed_pair<float *, std::allocator<float>>="__value_"^f}}
^{AUOutputBL={CAStreamBasicDescription=dIIIIIIII}*^{AudioBufferList}III}
i32@0:8^{CGImage=}16^@24
^{CGImageMetadata=}24@0:8@16
@88@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48@80
@72@0:8r^{CGImageSource=}16{CGRect={CGPoint=dd}{CGSize=dd}}24@56^@64
@72@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24@56^@64
{CGRect={CGPoint=dd}{CGSize=dd}}32@0:8@16^@24
@"VCPFaceAnalyzer"
@"MADVIMachineReadableCodeDetectionRequest"
Q28@0:8@16f24
@"VNTorsoprint"
@36@0:8i16@20@?28
i48@0:8^{__CVBuffer=}16^{__CVBuffer=}24^{__CVBuffer=}32^{__CVBuffer=}40
i56@0:8^{__CVBuffer=}16^{__CVBuffer=}24^{__CVBuffer=}32^{__CVBuffer=}40@?48
@52@0:8@16^{__sFILE=*iiss{__sbuf=*i}i^v^?^?^?^?{__sbuf=*i}^{__sFILEX}i[3C][1C]{__sbuf=*i}iq}24C32*36^f44
i44@0:8^{__CVBuffer=}16^f24i32^f36
@80@0:8Q16@24{CGSize=dd}32{CGRect={CGPoint=dd}{CGSize=dd}}48
v40@0:8Q16Q24@?32
@44@0:8@16@24B32@?36
@48@0:8@16d24Q32@?40
@"<PVFaceProtocol>"40@0:8@"<PVPersonProtocol>"16@"NSMapTable"24@?<v@?f^B>32
@"NSString"40@0:8@"PVPersonClusterManager"16@"NSSet"24@?<v@?f^B>32
@"NSArray"44@0:8@"PVPersonClusterManager"16@"NSSet"24B32@?<v@?f^B>36
@"NSArray"48@0:8@"NSArray"16d24Q32@?<d@?@@>40
@28@0:8@16i24
@36@0:8@16i24@28
@40@0:8@16@?24^@32
v56@0:8@16@24^@32@?40@48
B48@0:8@16Q24@?32^@40
B40@0:8@16@?24^@32
B48@0:8@16@24@?32^@40
B88@0:8@16@24@32@40@48@56@?64@?72^@80
B44@0:8@16B24@?28^@36
@48@0:8@16@24@32@?40
B48@0:8@16Q24@32^@40
B72@0:8@16@24@32@40@?48@56^@64
B44@0:8@16B24@28^@36
B56@0:8@16@24@32^@40^@48
@56@0:8@16@24@32@40^@48
v56@0:8@16@?24@32@40@?48
B40@0:8Q16@?24^@32
@32@0:8@?16Q24
v48@0:8@16@24@32@?40
v40@0:8@16@24@32
v112@0:8^@16^@24^@32^@40^@48^@56^@64^@72^@80@88@96@?104
v56@0:8^@16^@24^@32@40@48
B112@0:8@16@24@32@40@48@56@64@72@?80@?88@96^@104
Q32@0:8Q16@24
v64@0:8@16@24@32@40@48@56
v56@0:8@16@24@32^@40@?48
v56@0:8@16@24@?32@?40@48
v48@0:8@16@?24@32@?40
{?="underExpose"b1}
@"PHAsset"
{CGSize=dd}16@0:8
@"MADVIDocumentRecognitionRequest"
@"VNPersonsModel"
@"MADPersonIdentificationRequest"
f40@0:8*16i24i28q32
i40@0:8^f16@24^{__CVBuffer=}32
v48@0:8@16i24i28^f32^f40
f48@0:8{CGPoint=dd}16{CGPoint=dd}32
@36@0:8@16B24Q28
v40@0:8@16@24f32f36
i40@0:8^{__CVBuffer=}16^f24@?32
i32@0:8^f16^{__CVBuffer=}24
i48@0:8^{CGRect={CGPoint=dd}{CGSize=dd}}16^{__CVBuffer=}24@32i40i44
i52@0:8^{__CVBuffer=}16^Q24f32^@36@?44
[16f]
@"VCPCNNBlurAnalyzer"
i40@0:8^{__CVBuffer=}16^{?=[7{?=iii}][7^{__CVBuffer}]}24@?32
i36@0:8^{?=iii}16i24i28i32
{?="quality"b1"statsFlags"b1"typesWide"b1}
@52@0:8^{__CVBuffer=}16I24@28@36@44
i32@0:8^^{__CVBuffer}16^I24
v28@0:8@16B24
{CF<__CVBuffer *>="value_"^{__CVBuffer}}
@56@0:8@16@24@32@40@48
@"UTType"
@52@0:8@16^{__CVBuffer=}24I32@36@44
@80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16^{__CVBuffer=}48{?=qiIq}56
@"VCPCtrTracker"
@56@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24
B40@0:8@16^@24^@32
B56@0:8@16@24@32@40^@48
i40@0:8^Q16@?24@?32
i40@0:8@16@24^@32
i44@0:8@16B24^@28^@36
B36@0:8@16B24^@28
@24@0:8B16B20
@32@0:8Q16B24B28
i32@0:8@?16@?24
i40@0:8@?16@?24B32B36
B24@0:8@?16
B36@0:8Q16B24@?28
i60@0:8Q16B24B28B32^B36@?44@?52
@"VNEntityIdentificationModel"
f24@0:8^f16
i48@0:8^f16*24f32i36@?40
v56@0:8*16q24^f32q40i48i52
v28@0:8B16@?20
v44@0:8@16B24@28@?36
@64@0:8@16@24@32@?40@48^@56
@56@0:8@16@24@32@?40^@48
v64@0:8@16@24@32@40@?48@?56
v40@0:8@16@?24@?32
v48@0:8@16@?24@?32@?40
@"VCPClusterer"
@40@0:8@16r^{?={?=qiIq}{?=qiIq}}24r^{?=qiIq}32
^{opaqueCMSampleBuffer=}
{array<float, 6UL>=[6f]}16@0:8
v40@0:8{array<float, 6UL>=[6f]}16
v40@0:8i16i20^f24^f32
{CGRect={CGPoint=dd}{CGSize=dd}}56@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16f48f52
f80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48
i92@0:8@16@24i32^{__CVBuffer=}36{?=qiIq}44{?=qiIq}68
@"VCPImagePetsKeypointsAnalyzer"
@"VCPVideoObjectTracker"
@44@0:8{?=qiIq}16f40
@76@0:8{?={?=qiIq}{?=qiIq}}16f64@68
@"VCPVideoKeyFrameResult"
{?=ii}24@0:8@16
B32@0:8^{__CVBuffer=}16@24
@"AVAssetTrack"
@"VCPPhotosFace"
@"MLModel"
@28@0:8i16f20f24
f24@0:8f16B20
@"MADVIVisualSearchGatingRequest"
B44@0:8@16i24@28^@36
i40@0:8^@16^@24@32
i52@0:8^@16@24B32Q36Q44
i56@0:8^@16@24@32Q40Q48
i72@0:8^@16^I24^i32^i40@48@56@64
i52@0:8@16@24@32B40^@44
i32@0:8@16^@24
@"VCPFaceMerger"
v32@0:8@"<SNRequest>"16@"<SNResult>"24
v32@0:8@"<SNRequest>"16@"NSError"24
v24@0:8@"<SNRequest>"16
@52@0:8{?=qiIq}16f40@44
v36@0:8r^{?=qiIq}16r^{?=qiIq}24f32
i52@0:8^{opaqueCMSampleBuffer=}16{?=qiIq}24i48
@"SNAudioStreamAnalyzer"
@"VCPCNNMetalContext"
Q40@0:8Q16Q24Q32
@20@0:8I16
@"MADVIVisualSearchRequest"
{CGRect={CGPoint=dd}{CGSize=dd}}64@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGSize=dd}48
{CGRect={CGPoint=dd}{CGSize=dd}}80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48
{CGPoint=dd}64@0:8{CGPoint=dd}16{CGRect={CGPoint=dd}{CGSize=dd}}32
i56@0:8^{__CVBuffer=}16{CGRect={CGPoint=dd}{CGSize=dd}}24
B72@0:8{?=qiIq}16{?=qiIq}40^@64
@"VCPVideoProcessorSession"
@"VCPProtoVideoKeyFrame"
@24@0:8i16i20
i52@0:8^{__sFILE=*iiss{__sbuf=*i}i^v^?^?^?^?{__sbuf=*i}^{__sFILEX}i[3C][1C]{__sbuf=*i}iq}16^f24^f32i40i44i48
{Scaler="pool_"^{__CVPixelBufferPool}"width_"i"height_"i"crop_rect_"{CGRect="origin"{CGPoint="x"d"y"d}"size"{CGSize="width"d"height"d}}"sw_scaler_"^{OpaqueVTPixelTransferSession}}
{vector<__CVBuffer *, std::allocator<__CVBuffer *>>="__begin_"^^{__CVBuffer}"__end_"^^{__CVBuffer}"__end_cap_"{__compressed_pair<__CVBuffer **, std::allocator<__CVBuffer *>>="__value_"^^{__CVBuffer}}}
v80@0:8{?={?=qiIq}{?=qiIq}}16@64@72
v96@0:8@16@24{?={?=qiIq}{?=qiIq}}32@80@88
@32@0:8@16d24
@36@0:8f16f20f24f28f32
{CGRect={CGPoint=dd}{CGSize=dd}}24@0:8f16f20
i64@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16^{__CVBuffer=}48^q56
@40@0:8@16@24Q32
@72@0:8{?={?=qiIq}{?=qiIq}}16^Q64
@40@0:8@16r^{?={?=qiIq}{?=qiIq}}24Q32
i48@0:8@16r^{?={?=qiIq}{?=qiIq}}24Q32@?40
i64@0:8@16{?=qiIq}24Q48@?56
@32@0:8@?16^B24
@"VCPAsset"
@48@0:8i16B20B24@28@36i44
i48@0:8[21{CGPoint=dd}]16^f24@32@40
@"VCPCNNHandsDetector"
@"VCPCNNHandKeypointsDetector"
@48@0:8@16@24@?32@?40
i48@0:8^{CGRect={CGPoint=dd}{CGSize=dd}}16^{__CVBuffer=}24^f32i40i44
f52@0:8^f16i24i28i32*36f44i48
i52@0:8^{__CVBuffer=}16^f24^f32f40@?44
@44@0:8@16@24@32i40
Q40@0:8^{?=Q^@^Q[5Q]}16^@24Q32
@56@0:8@16@24Q32@?40@?48
@"VCPProtoLivePhotoVariationParams"
{?="epoch"b1"flags"b1}
@28@0:8Q16B24
i48@0:8^{opaqueCMSampleBuffer=}16{?=qiIq}24
i24@0:8^{opaqueCMSampleBuffer=}16
i40@0:8@16@?24^@32
{AudioTimeStamp="mSampleTime"d"mHostTime"Q"mRateScalar"d"mWordClockTime"Q"mSMPTETime"{SMPTETime="mSubframes"s"mSubframeDivisor"s"mCounter"I"mType"I"mFlags"I"mHours"s"mMinutes"s"mSeconds"s"mFrames"s}"mFlags"I"mReserved"I}
{AudioBufferList="mNumberBuffers"I"mBuffers"[1{AudioBuffer="mNumberChannels"I"mDataByteSize"I"mData"^v}]}
@"VCPVoiceDetector"
@"VCPAudioClassifier"
@"VCPLoudnessAnalyzer"
@"VCPSongDetector"
i32@0:8^{__CVBuffer=}16^f24
i72@0:8^f16^{__CVBuffer=}24i32i36{CGRect={CGPoint=dd}{CGSize=dd}}40
@"VCPFaceClusterer"
@36@0:8i16B20B24@28
@"VCPCNNPersonDetector"
@"VCPCNNPersonKeypointsDetector"
@"MADVIRectangleDetectionRequest"
B32@0:8q16Q24
B24@0:8q16
i32@0:8@16q24
i56@0:8^@16@24@32@40Q48
i56@0:8^@16@24q32Q40Q48
i40@0:8^@16^{__CVBuffer=}24@32
i44@0:8^@16^{__CVBuffer=}24Q32B40
i32@0:8^@16^{__CVBuffer=}24
i72@0:8^@16q24Q32Q40^{__CVBuffer=}48^{__CVBuffer=}56@64
v56@0:8@16q24Q32Q40@?48
@"VCPPreAnalysisImageLoader"
@"VCPPoolBasedPixelBufferCreator"
@"VCPMAMLModel"
@44@0:8@16r^{?={?=qiIq}{?=qiIq}}24@32B40
i48@0:8^f16^{__CVBuffer=}24i32i36@40
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
@32@0:8r^16Q24
r^16@0:8
@96@0:8{?=[4]}16@80@88
@"VCPFaceGeometry"
{?="columns"[4]}
@80@0:8Q16{CGAffineTransform=dddddd}24@72
@40@0:8Q16@24@32
@88@0:8Q16{CGAffineTransform=dddddd}24f72@76B84
B32@0:8r^{CGAffineTransform=dddddd}16@24
{CGAffineTransform=dddddd}28@0:8i16^{__CVBuffer=}20
{?=[4]}84@0:8{?=[4]}16i80
@88@0:8^{__CVBuffer=}16{?=qiIq}24{?=qiIq}48@72^@80
i88@0:8^{__CVBuffer=}16{?=qiIq}24{?=qiIq}48@72@?80
i72@0:8{?={?=qiIq}{?=qiIq}}16@64
B68@0:8{?=qiIq}16{?=qiIq}40B64
@"VCPVideoFacePoseAnalyzer"
@"VCPVideoFaceMeshAnalyzer"
@"VCPFullVideoAnalyzer"
@"VCPAudioAnalyzer"
@"VCPVideoFullFaceDetector"
@"VCPSceneChangeAnalyzer"
@"VCPLightMotionAnalyzer"
@"VCPTrimAnalyzer"
@"VCPHomeKitMotionAnalyzer"
^{Rotator=^{__CVPixelBufferPool}iii^{OpaqueVTPixelRotationSession}}
i32@0:8^{__CVBuffer=}16@?24
i92@0:8^{__CVBuffer=}16^v24{?=qiIq}32{?=qiIq}56i80@?84
@"VCPMotionFlowRequest"
i52@0:8@16B24@?28^Q36^@44
@96@0:8{CGAffineTransform=dddddd}16@64@72B80B84@?88
@40@0:8i16i20Q24Q32
i56@0:8i16i20r^f24^f32Q40Q48
i60@0:8{Kernel=^fQQ}16f40f44f48f52f56
^^{Kernel}
v48@0:8@"NSDictionary"16@"NSString"24@"NSURL"32@?<v@?>40
v40@0:8@"NSString"16@"NSURL"24@?<v@?@"NSString">32
@60@0:8@16Q24@32@40B48@?52
@48@0:8@16@24Q32^@40
@64@0:8Q16@24@32@40@48@?56
i48@0:8@16Q24@?32@?40
v40@0:8@16@24^q32
v88@0:8@16#24{?={?=qiIq}{?=qiIq}}32@80
@108@0:8#16@24@32@40{?={?=qiIq}{?=qiIq}}48B96^B100
v48@0:8@16@24^q32^f40
v144@0:8@16{?={?=qiIq}{?=qiIq}}24@72{?={?=qiIq}{?=qiIq}}80^q128^f136
i64@0:8Q16@24@32@?40@?48@56
i52@0:8@16Q24B32@?36@?44
@52@0:8Q16@24B32@?36^@44
@56@0:8Q16@24@32@?40^@48
@44@0:8@16@24Q32B40
{?={?=qiIq}{?=qiIq}}32@0:8@16@24
{atomic<int>="__a_"{__cxx_atomic_impl<int, std::__cxx_atomic_base_impl<int>>="__a_value"Ai}}
i44@0:8^f16i24i28B32*36
@32@0:8Q16^{opaqueCMFormatDescription=}24
B24@0:8^{opaqueCMFormatDescription=}16
{CGSize=dd}24@0:8^{opaqueCMFormatDescription=}16
@24@0:8^{opaqueCMFormatDescription=}16
^{__CFData=}24@0:8^{opaqueCMFormatDescription=}16
^{__CFData=}28@0:8I16^{__CFData=}20
i32@0:8^{FigLivePhotoMetadata=I{FigLivePhotoMetadataV1Struct=fqffffffccSI[0{FigLivePhotoDetectedFaceV1Struct=qffffisS}]}}16@24
{CGVector="dx"d"dy"d}
@"NSMutableData"
@"VCPVideoMetaFocusAnalyzer"
@"VCPVideoMetaMotionAnalyzer"
@"VCPVideoMetaLensSwitchAnalyzer"
@32@0:8{CGPoint=dd}16
@36@0:8i16i20i24@28
@36@0:8^f16i24i28f32
i28@0:8i16@20
@44@0:8@16i24i28i32i36i40
v60@0:8*16i24i28i32^f36^f44^f52
v36@0:8^f16^f24i32
^{LandmarkDetector=iiiiiiiB^f^f^f^i^{ZPoint}^{RegressionTree}^?}
#20@0:8i16
@36@0:8i16i20i24B28B32
@"VNSession"
@40@0:8i16B20B24@28i36
i48@0:8^f16i24i28@32[3[2f]]40
i36@0:8r^v16@24i32
i72@0:8*16i24i28i32{CGPoint=dd}36{CGPoint=dd}52i68
i44@0:8*16i24i28i32^{CGPoint=dd}36
B32@0:8@"AVAssetResourceLoader"16@"AVAssetResourceLoadingRequest"24
B32@0:8@"AVAssetResourceLoader"16@"AVAssetResourceRenewalRequest"24
v32@0:8@"AVAssetResourceLoader"16@"AVAssetResourceLoadingRequest"24
B32@0:8@"AVAssetResourceLoader"16@"NSURLAuthenticationChallenge"24
v32@0:8@"AVAssetResourceLoader"16@"NSURLAuthenticationChallenge"24
@32@0:8#16Q24
@"NSURLSessionDataTask"
^{__CVBuffer=}56@0:8^{__CVBuffer=}16{CGRect={CGPoint=dd}{CGSize=dd}}24
@"VCPSegment"
^{HinkleyDetector=ffi{HinkleyStats=ffff}}
@52@0:8B16@20I28B32B36B40@?44
i40@0:8^{__CVBuffer=}16^{__CVBuffer=}24^{__CVBuffer=}32
@"<MTLDeviceSPI>"
@"<MTLCommandQueue>"
@"MPSImageBilinearScale"
@"MPSImageSpatioTemporalGuidedFilter"
v24@0:8@"PHPhotoLibrary"16
{CGSize=dd}32@0:8@16@24
i40@0:8^@16#24@32
^{__CVBuffer=}36@0:8@16@24i32
i52@0:8^@16#24@32@40B48
i48@0:8^f16@24@32@40
i40@0:8^f16@24@32
v52@0:8f16@20Q28Q36Q44
v44@0:8f16@20Q28Q36
i40@0:8@16^@24^@32
i32@0:8^@16^@24
v56@0:8@16@24@32@?40@?48
B48@0:8@16^@24@?32@?40
i48@0:8^@16^@24@?32@?40
d80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48
i72@0:8@16^@24^@32^@40^@48@?56@?64
i80@0:8@16@24@32@40@48^@56@?64@?72
i48@0:8@16@24@32@40
i64@0:8@16@24@32^@40@?48@?56
i56@0:8@16@24^@32@?40@?48
i48@0:8@16^@24@?32@?40
@"MADVIUserFeedbackRequest"
@88@0:8@16{CGAffineTransform=dddddd}24Q72^{opaqueCMFormatDescription=}80
B40@0:8@16#24@32
v32@0:8{CGPoint=dd}16
{CGPoint="x"d"y"d}
^{__CVBuffer=}16@0:8
{CGRect={CGPoint=dd}{CGSize=dd}}24@0:8@16
@"PHFetchResult"
i48@0:8^{CGPoint=dd}16[21f]24@32@40
i40@0:8^f16^{__CVBuffer=}24@32
{vector<int, std::allocator<int>>="__begin_"^i"__end_"^i"__end_cap_"{__compressed_pair<int *, std::allocator<int>>="__value_"^i}}
@"VCPCNNFastGestureRecognition"
@28@0:8f16B20B24
v40@0:8i16i20i24^f28i36
i84@0:8^{__CVBuffer=}16{CGRect={CGPoint=dd}{CGSize=dd}}24i56{?=qiIq}60
r^f16@0:8
@"VCPRTLandmarkDetector"
@"VCPFaceShapeModel"
[5@"VCPLandmarkValidator"]
B40@0:8@16Q24Q32
i32@0:8^^{__CVBuffer}16i24B28
i56@0:8@16i24Q28^^{__CVBuffer}36^I44B52
i48@0:8^{CGImage=}16i24I28Q32^^{__CVBuffer}40
i60@0:8^{CGImageSource=}16@24i32Q36^I44^^{__CVBuffer}52
^{__CVBuffer=}56@0:8i16Q20@28@36B44^I48
^{__CVBuffer=}28@0:8@16i24
^{__CVBuffer=}36@0:8@16i24Q28
^{__CVBuffer=}44@0:8@16i24Q28^I36
^{__CVBuffer=}32@0:8i16@20B28
^{__CVBuffer=}48@0:8i16Q20@28B36^I40
^{__CVBuffer=}40@0:8i16@20B28^I32
^{__CVBuffer=}36@0:8i16Q20@28
^{__CVBuffer=}44@0:8i16Q20@28^I36
i44@0:8^{__CVBuffer=}16^@24Q32B40
^{CMPhotoCompressionSession=}
^{CMPhotoDecompressionSession=}
i64@0:8^f16i24i28i32i36i40^{CGPoint=dd}44^f52f60
i52@0:8^{__CVBuffer=}16@24[21{CGPoint=dd}]32[21f]40B48
^{OpaqueAudioComponentInstance=}
@"VCPVideoMetaFocusSegment"
@48@0:8q16{?=qiIq}24
v48@0:8q16{?=qiIq}24
i32@0:8Q16Q24
i40@0:8^^{__CVBuffer}16Q24Q32
v52@0:8Q16@24i32@36@?44
v52@0:8Q16@"NSData"24i32@"NSDictionary"36@?<v@?@"NSDictionary"@"NSError">44
v52@0:8Q16@"IOSurface"24i32@"NSDictionary"36@?<v@?@"NSDictionary"@"NSError">44
v44@0:8i16@"NSData"20@"NSDictionary"28@?<v@?@"NSString"@"NSError">36
v36@0:8i16@"NSDictionary"20@?<v@?@"NSDictionary"@"NSError">28
@40@0:8@16@24d32
@24@0:8d16
v48@0:8@16@24Q32Q40
@72@0:8@16@24@32Q40Q48Q56Q64
{?={?=qiIq}{?=qiIq}}32@0:8@16f24B28
i48@0:8@16f24f28f32B36@?40
i56@0:8B16@20@28f36f40f44B48B52
f28@0:8f16@20
f48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
@36@0:8q16q24I32
i44@0:8^^{__CVPixelBufferPool}16q24q32I40
i24@0:8^^{__CVBuffer}16
{CF<__CVPixelBufferPool *>="value_"^{__CVPixelBufferPool}}
i48@0:8@16@24@?32^@40
@44@0:8B16@20B28B32B36B40
i28@0:8f16i20i24
i56@0:8@16@24@32@40@48
@"<MTLComputePipelineState>"
@"<MTLLibrary>"
i40@0:8^{__CVBuffer=}16^^{__CVBuffer}24Q32
i64@0:8@16Q24@32^^{__CVBuffer}40^^{__CVBuffer}48^@56
@"VCPSceneProcessingImageManager"
{CF<OpaqueVTPixelTransferSession *>="value_"^{OpaqueVTPixelTransferSession}}
@"<MTLCommandBuffer>"
i40@0:8^Q16^Q24@?32
@32@0:8@?16@24
v36@0:8@16Q24B32
i48@0:8@16@24^@32^@40
v44@0:8@16Q24B32@?36
i88@0:8{?=qiIq}16{?=qiIq}40{?=qiIq}64
f56@0:8i16i20^{?={?=qiIq}{?=qiIq}}24{?=qiIq}32
B40@0:8{?=qiIq}16
B64@0:8{?=qiIq}16{?=qiIq}40
@"VCPActionAnalyzer"
B24@0:8^v16
[10f]
@"VCPSceneChangeSegment"
v40@0:8q16@24@32
v40@0:8d16@24@32
i40@0:8^^{__CVBuffer}16Q24^{__CVBuffer=}32
i32@0:8^^{__CVBuffer}16Q24
i40@0:8^^{__CVBuffer}16^{CGColorSpace=}24^{__CVBuffer=}32
i56@0:8^^{__CVBuffer}16^^{__CVBuffer}24^^{__CVBuffer}32@40Q48
i48@0:8^{__CVBuffer=}16^^{__CVBuffer}24Q32Q40
@76@0:8{CGAffineTransform=dddddd}16@64B72
@40@0:8f16{CGPoint=dd}20B36
v32@0:8r^f16^v24
i32@0:8^v16^v24
i40@0:8^v16^v24^f32
f32@0:8[3[3f]]16[3f]24
i56@0:8^v16r^f24[3[3f]]32[3f]40^f48
i56@0:8^v16^v24[4f]32^v40^v48
i40@0:8^v16^v24[4f]32
i36@0:8r^f16r^f24i32
v80@0:8{?=[4]}16
[4[3f]]
@"SHMutableSignature"
@56@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48
Q56@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24
i56@0:8@16Q24@?32@?40@?48
^q16@0:8
v32@0:8^q16Q24
{?="list"^q"count"Q"size"Q}
@20@0:8f16
i80@0:8^{__CVBuffer=}16{CGRect={CGPoint=dd}{CGSize=dd}}24{?=qiIq}56
@"VCPCNNFaceLandmarkDetector"
@"VCPVideoFacePoseFilter"
[14f]
[21f]
v24@0:8^{EncodeStats=^^?^B^B^{MotionVector}^{MotionVector}^{MotionVector}^{MotionVector}^S^S^I^S^S^S^S^S^S^S^S^S^S^SIBBBii}16
@24@0:8s16B20
[200@"VCPCNNBlock"]
@"VCPMADResourceManager"
@"VCPMADResource"
q24@0:8q16
@"VCPTimer"
@"NSObject<OS_os_transaction>"
i88@0:8^{__CVBuffer=}16^v24{?=qiIq}32{?=qiIq}56@?80
@72@0:8@16{CGSize=dd}24{CGRect={CGPoint=dd}{CGSize=dd}}40
v68@0:8{CGAffineTransform=dddddd}16B64
@32@0:8^{CGImage=}16^@24
B32@0:8^{CGImage=}16^@24
@"MLMultiArray"
@32@0:8^{__CVBuffer=}16^@24
v32@0:8^{__CVBuffer=}16^{CGPoint=dd}24
^{CGPoint=dd}16@0:8
v24@0:8^{CGPoint=dd}16
^{CGPoint=dd}
^{?=^{?}^{?}^{?}^{tplTracker_resampler_context}^{?}}
mcpl
v024
v024
mcpl
gepj
ARGB
