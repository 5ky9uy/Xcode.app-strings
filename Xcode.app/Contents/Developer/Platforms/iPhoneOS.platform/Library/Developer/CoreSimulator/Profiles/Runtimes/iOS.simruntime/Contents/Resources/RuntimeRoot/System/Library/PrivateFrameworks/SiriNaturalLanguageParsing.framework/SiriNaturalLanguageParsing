@(#)PROGRAM:SiriNaturalLanguageParsing  PROJECT:SiriNaturalLanguageParsing-1
N4snlp3ssu5parse18SSUGraphBuilderAppE
N4snlp3ssu5parse15SSUGraphBuilderE
NSt3__120__shared_ptr_emplaceIN4snlp3ssu3app14SSUFileWrapperENS_9allocatorIS4_EEEE
NSt3__111__end_stateIcEE
NSt3__120__shared_ptr_pointerIPNS_13__empty_stateIcEENS_10shared_ptrIS2_E27__shared_ptr_default_deleteIS2_S2_EENS_9allocatorIS2_EEEE
NSt3__116__owns_one_stateIcEE
NSt3__115__has_one_stateIcEE
NSt3__118__match_char_icaseIcNS_12regex_traitsIcEEEE
NSt3__112__match_charIcEE
NSt3__116__back_ref_icaseIcNS_12regex_traitsIcEEEE
NSt3__110__back_refIcEE
NSt3__120__bracket_expressionIcNS_12regex_traitsIcEEEE
NSt3__117__owns_two_statesIcEE
NSt3__111__alternateIcEE
NSt3__111__match_anyIcEE
?N27nlv4_inference_orchestrator16inference_engine24EspressoTransformerModelE
N27nlv4_inference_orchestrator16inference_engine16TransformerModelE
sage
send::common_Mesmon_Announcementsend::common_Ann
N4snlp3ssu5parse24SSUGraphBuilderShortcutsE
<N4siri8ontology12UsoGraphNodeE
N4uaap19DateDurationHandlerE
N4uaap23AbstractDateTimeHandlerE
N5boost10wrapexceptINS_5uuids13entropy_errorEEE
N5boost16exception_detail10clone_baseE
N4snlp6common14text_uso_graph26UsoGraphTextTreeParseErrorE
N4snlp6common14text_uso_graph21UDATextTreeParseErrorE
N4uaap8UPDDSpanE
N4uaap12UPDDTimeSpanE
N4uaap20UPDDDateTimeBaseSpanE
N4uaap11TimeHandlerE
N4snlp6common9exception18SNLPAssetExceptionE
N8nlohmann6detail9exceptionE
false
N8nlohmann6detail12out_of_rangeE
NSt3__117bad_function_callE
N8nlohmann6detail16invalid_iteratorE
N8nlohmann6detail10type_errorE
N8nlohmann6detail11parse_errorE
N4uaap12UPDDDateSpanE
N4uaap20UPDDAbsoluteDateSpanE
N4uaap15DateSpanHandlerE
N4siri8ontology28UsoGraphProtoWriterExceptionE
N4siri8ontology21OntologyBaseExceptionE
N4siri8ontology17OntologyExceptionE
N4uaap11DateHandlerE
N4snlp6common9exception13SNLPExceptionE
N27itfm_inference_orchestrator13orchestration16ITFMOrchestratorE
NSt3__120__shared_ptr_emplaceIN27itfm_inference_orchestrator10vocabulary10VocabularyENS_9allocatorIS3_EEEE
N27snlc_inference_orchestrator13orchestration16SNLCOrchestratorE
NSt3__120__shared_ptr_emplaceINS_4__fs10filesystem16filesystem_error8_StorageENS_9allocatorIS4_EEEE
vH7B
W4vC
9Y>)F$
raB3G
)c=H
]rHa
O8Mr
bnMG
.wN9
[*QmU
mr"iR
R$N(
>S}W
-sSO\
T%L9
hGT.
B}T}
=@[V
!a9X
X5AHx
%4xY
Z~$|7
+\0I
2a\|
\ysK
|M$D
pH_r
(:W"
s\ax}?
pc2g
@BXV
tC7Ddx
EydV
d66
eax~Z
ekhHD
@iZb
k0V(
k*do^
:V!2m
RJqn
bzo=
$qE}
XqkY
quAt
Jugm
~B v
STv/N
_w&2
xg^Jp5|
yMzw
{zel#|67
P/};
[@JO
nQ:B
tedUserDialogActDelegatedUserDiaN4snlp6common14text_uso_graph20ExactMatchComparatorE
N4snlp6common14text_uso_graph18UsoGraphComparatorE
N4snlp6common14text_uso_graph16ActionListParserE
N4snlp6common14text_uso_graph14TextTreeParserE
N27itfm_inference_orchestrator16inference_engine10ITFMModuleE
N4uaap25UPDDTimeSpanWithReferenceE
N4uaap28TimeSpanWithReferenceHandlerE
N4snlp6common14text_uso_graph22UsoGraphTextTreeParserE
N4siri8ontology17IsNameTypeVisitorINS0_16OntologyNodeNameEEE
N4siri8ontology16NoOpONameVisitorE
N4siri8ontology19OntologyNameVisitorE
N4siri8ontology17IsNameTypeVisitorINS0_16OntologyVerbNameEEE
N4siri8ontology17IsNameTypeVisitorINS0_16OntologyEdgeNameEEE
N4snlp3ssu5cache18CacheFileExceptionE
N5boost7archive13text_iarchiveE
N5boost7archive18text_iarchive_implINS0_13text_iarchiveEEE
N5boost7archive21basic_text_iprimitiveINSt3__113basic_istreamIcNS2_11char_traitsIcEEEEEE
N5boost7archive19basic_text_iarchiveINS0_13text_iarchiveEEE
N5boost7archive6detail15common_iarchiveINS0_13text_iarchiveEEE
N5boost7archive6detail18interface_iarchiveINS0_13text_iarchiveEEE
N5boost7archive15binary_iarchiveE
N5boost7archive20binary_iarchive_implINS0_15binary_iarchiveEcNSt3__111char_traitsIcEEEE
N5boost7archive23basic_binary_iprimitiveINS0_15binary_iarchiveEcNSt3__111char_traitsIcEEEE
N5boost7archive21basic_binary_iarchiveINS0_15binary_iarchiveEEE
N5boost7archive6detail15common_iarchiveINS0_15binary_iarchiveEEE
N5boost7archive6detail18interface_iarchiveINS0_15binary_iarchiveEEE
N5boost13serialization6detail17singleton_wrapperINS0_25extended_type_info_typeidIN4snlp3ssu5cache20SSUCacheObjectHeaderEEEEE
N5boost13serialization25extended_type_info_typeidIN4snlp3ssu5cache20SSUCacheObjectHeaderEEE
N5boost13serialization9singletonINS0_25extended_type_info_typeidIN4snlp3ssu5cache20SSUCacheObjectHeaderEEEEE
N4snlp3ssu5cache20SSUCacheObjectHeaderE
N5boost13serialization6detail17singleton_wrapperINS_7archive6detail11iserializerINS3_15binary_iarchiveEN4snlp3ssu5cache20SSUCacheObjectHeaderEEEEE
N5boost7archive6detail11iserializerINS0_15binary_iarchiveEN4snlp3ssu5cache20SSUCacheObjectHeaderEEE
N5boost13serialization6detail17singleton_wrapperINS_7archive6detail11iserializerINS3_13text_iarchiveEN4snlp3ssu5cache20SSUCacheObjectHeaderEEEEE
N5boost7archive6detail11iserializerINS0_13text_iarchiveEN4snlp3ssu5cache20SSUCacheObjectHeaderEEE
N5boost13serialization6detail17singleton_wrapperINS0_25extended_type_info_typeidIN4snlp3ssu5cache25SSUCacheObjectIntentNamesEEEEE
N5boost13serialization25extended_type_info_typeidIN4snlp3ssu5cache25SSUCacheObjectIntentNamesEEE
N5boost13serialization9singletonINS0_25extended_type_info_typeidIN4snlp3ssu5cache25SSUCacheObjectIntentNamesEEEEE
N4snlp3ssu5cache25SSUCacheObjectIntentNamesE
N5boost13serialization6detail17singleton_wrapperINS0_25extended_type_info_typeidINSt3__16vectorINS4_12basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEENS9_ISB_EEEEEEEE
N5boost13serialization25extended_type_info_typeidINSt3__16vectorINS2_12basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEENS7_IS9_EEEEEE
N5boost13serialization9singletonINS0_25extended_type_info_typeidINSt3__16vectorINS3_12basic_stringIcNS3_11char_traitsIcEENS3_9allocatorIcEEEENS8_ISA_EEEEEEEE
NSt3__16vectorINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS4_IS6_EEEE
N5boost13serialization6detail17singleton_wrapperINS_7archive6detail11iserializerINS3_15binary_iarchiveENSt3__16vectorINS7_12basic_stringIcNS7_11char_traitsIcEENS7_9allocatorIcEEEENSC_ISE_EEEEEEEE
N5boost7archive6detail11iserializerINS0_15binary_iarchiveENSt3__16vectorINS4_12basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEENS9_ISB_EEEEEE
N5boost13serialization6detail17singleton_wrapperINS_7archive6detail11iserializerINS3_15binary_iarchiveEN4snlp3ssu5cache25SSUCacheObjectIntentNamesEEEEE
N5boost7archive6detail11iserializerINS0_15binary_iarchiveEN4snlp3ssu5cache25SSUCacheObjectIntentNamesEEE
N5boost13serialization6detail17singleton_wrapperINS_7archive6detail11iserializerINS3_13text_iarchiveENSt3__16vectorINS7_12basic_stringIcNS7_11char_traitsIcEENS7_9allocatorIcEEEENSC_ISE_EEEEEEEE
N5boost7archive6detail11iserializerINS0_13text_iarchiveENSt3__16vectorINS4_12basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEENS9_ISB_EEEEEE
N5boost13serialization6detail17singleton_wrapperINS_7archive6detail11iserializerINS3_13text_iarchiveEN4snlp3ssu5cache25SSUCacheObjectIntentNamesEEEEE
N5boost7archive6detail11iserializerINS0_13text_iarchiveEN4snlp3ssu5cache25SSUCacheObjectIntentNamesEEE
N5boost13serialization6detail17singleton_wrapperINS0_25extended_type_info_typeidIN4snlp3ssu5cache36SSUCacheObjectEncodingsBatchNegativeEEEEE
N5boost13serialization25extended_type_info_typeidIN4snlp3ssu5cache36SSUCacheObjectEncodingsBatchNegativeEEE
N5boost13serialization9singletonINS0_25extended_type_info_typeidIN4snlp3ssu5cache36SSUCacheObjectEncodingsBatchNegativeEEEEE
N4snlp3ssu5cache36SSUCacheObjectEncodingsBatchNegativeE
N5boost13serialization6detail17singleton_wrapperINS0_25extended_type_info_typeidINSt3__16vectorImNS4_9allocatorImEEEEEEEE
N5boost13serialization25extended_type_info_typeidINSt3__16vectorImNS2_9allocatorImEEEEEE
N5boost13serialization9singletonINS0_25extended_type_info_typeidINSt3__16vectorImNS3_9allocatorImEEEEEEEE
NSt3__16vectorImNS_9allocatorImEEEE
N5boost13serialization6detail17singleton_wrapperINS_7archive6detail11iserializerINS3_15binary_iarchiveENSt3__16vectorImNS7_9allocatorImEEEEEEEE
N5boost7archive6detail11iserializerINS0_15binary_iarchiveENSt3__16vectorImNS4_9allocatorImEEEEEE
N5boost13serialization6detail17singleton_wrapperINS0_25extended_type_info_typeidINSt3__16vectorIfNS4_9allocatorIfEEEEEEEE
N5boost13serialization25extended_type_info_typeidINSt3__16vectorIfNS2_9allocatorIfEEEEEE
N5boost13serialization9singletonINS0_25extended_type_info_typeidINSt3__16vectorIfNS3_9allocatorIfEEEEEEEE
NSt3__16vectorIfNS_9allocatorIfEEEE
N5boost13serialization6detail17singleton_wrapperINS_7archive6detail11iserializerINS3_15binary_iarchiveENSt3__16vectorIfNS7_9allocatorIfEEEEEEEE
N5boost7archive6detail11iserializerINS0_15binary_iarchiveENSt3__16vectorIfNS4_9allocatorIfEEEEEE
N5boost13serialization6detail17singleton_wrapperINS_7archive6detail11iserializerINS3_15binary_iarchiveEN4snlp3ssu5cache36SSUCacheObjectEncodingsBatchNegativeEEEEE
N5boost7archive6detail11iserializerINS0_15binary_iarchiveEN4snlp3ssu5cache36SSUCacheObjectEncodingsBatchNegativeEEE
N5boost13serialization6detail17singleton_wrapperINS_7archive6detail11iserializerINS3_13text_iarchiveENSt3__16vectorImNS7_9allocatorImEEEEEEEE
N5boost7archive6detail11iserializerINS0_13text_iarchiveENSt3__16vectorImNS4_9allocatorImEEEEEE
N5boost13serialization6detail17singleton_wrapperINS_7archive6detail11iserializerINS3_13text_iarchiveENSt3__16vectorIfNS7_9allocatorIfEEEEEEEE
N5boost7archive6detail11iserializerINS0_13text_iarchiveENSt3__16vectorIfNS4_9allocatorIfEEEEEE
N5boost13serialization6detail17singleton_wrapperINS_7archive6detail11iserializerINS3_13text_iarchiveEN4snlp3ssu5cache36SSUCacheObjectEncodingsBatchNegativeEEEEE
N5boost7archive6detail11iserializerINS0_13text_iarchiveEN4snlp3ssu5cache36SSUCacheObjectEncodingsBatchNegativeEEE
N5boost13serialization6detail17singleton_wrapperINS0_25extended_type_info_typeidIN4snlp3ssu5cache36SSUCacheObjectEncodingsBatchPositiveEEEEE
N5boost13serialization25extended_type_info_typeidIN4snlp3ssu5cache36SSUCacheObjectEncodingsBatchPositiveEEE
N5boost13serialization9singletonINS0_25extended_type_info_typeidIN4snlp3ssu5cache36SSUCacheObjectEncodingsBatchPositiveEEEEE
N4snlp3ssu5cache36SSUCacheObjectEncodingsBatchPositiveE
N5boost13serialization6detail17singleton_wrapperINS_7archive6detail11iserializerINS3_15binary_iarchiveEN4snlp3ssu5cache36SSUCacheObjectEncodingsBatchPositiveEEEEE
N5boost7archive6detail11iserializerINS0_15binary_iarchiveEN4snlp3ssu5cache36SSUCacheObjectEncodingsBatchPositiveEEE
N5boost13serialization6detail17singleton_wrapperINS_7archive6detail11iserializerINS3_13text_iarchiveEN4snlp3ssu5cache36SSUCacheObjectEncodingsBatchPositiveEEEEE
N5boost7archive6detail11iserializerINS0_13text_iarchiveEN4snlp3ssu5cache36SSUCacheObjectEncodingsBatchPositiveEEE
N4snlp3ssu7trigger16SSUTriggerAlwaysE
N4snlp3ssu7trigger10SSUTriggerE
N4snlp6common18espresso_inference8pre_e5ml14EspressoModuleE
N4snlp3ssu7trigger18SSUTriggerOnScreenE
?N4uaap20UPDDTimeDurationSpanE
N4uaap19TimeDurationHandlerE
N4uaap16UPDDDateTimeSpanE
N4uaap15DateTimeHandlerE
N4uaap25UPDDDateSpanWithReferenceE
N4uaap28DateSpanWithReferenceHandlerE
N4uaap25UPDDSpecialDatePeriodSpanE
N4uaap18UPDDDateOffsetSpanE
UserAcknowledged
N4siri8ontology16OntologyUnitNameE
N5boost5uuids13entropy_errorE
N5boost9exceptionE
NSt3__16__nodeIcEE
NSt3__110shared_ptrINS_13__empty_stateIcEEE27__shared_ptr_default_deleteIS2_S2_EE
NSt3__113__empty_stateIcEE
NSt3__120__l_anchor_multilineIcEE
NSt3__120__r_anchor_multilineIcEE
NSt3__115__word_boundaryIcNS_12regex_traitsIcEEEE
NSt3__111__lookaheadIcNS_12regex_traitsIcEEEE
NSt3__123__match_any_but_newlineIcEE
NSt3__120__match_char_collateIcNS_12regex_traitsIcEEEE
NSt3__118__back_ref_collateIcNS_12regex_traitsIcEEEE
NSt3__128__begin_marked_subexpressionIcEE
NSt3__126__end_marked_subexpressionIcEE
NSt3__16__loopIcEE
NSt3__117__repeat_one_loopIcEE
NSt3__121__empty_non_own_stateIcEE
N27nlv4_inference_orchestrator16inference_engine17BertPreE5MLModuleE
N27nlv4_inference_orchestrator16inference_engine24TransformerEncoderModuleE
N27nlv4_inference_orchestrator16inference_engine24TransformerDecoderModuleE
N27nlv4_inference_orchestrator16inference_engine22BertModuleLoadingErrorE
N27nlv4_inference_orchestrator16inference_engine10BertModuleE
N27nlv4_inference_orchestrator16inference_engine17EspressoBertModelE
N27nlv4_inference_orchestrator13span_matching36RelativeThresholdMatchingSpansFilterE
N27nlv4_inference_orchestrator13span_matching19MatchingSpansFilterE
N4uaap15TimeSpanHandlerE
N27nlv4_inference_orchestrator16inference_engine21BertModelLoadingErrorE
N26psc_inference_orchestrator13orchestration15PSCOrchestratorE
?N5boost7archive13text_oarchiveE
N5boost7archive18text_oarchive_implINS0_13text_oarchiveEEE
N5boost7archive21basic_text_oprimitiveINSt3__113basic_ostreamIcNS2_11char_traitsIcEEEEEE
N5boost7archive19basic_text_oarchiveINS0_13text_oarchiveEEE
N5boost7archive6detail15common_oarchiveINS0_13text_oarchiveEEE
N5boost7archive6detail18interface_oarchiveINS0_13text_oarchiveEEE
N5boost7archive15binary_oarchiveE
N5boost7archive20binary_oarchive_implINS0_15binary_oarchiveEcNSt3__111char_traitsIcEEEE
N5boost7archive23basic_binary_oprimitiveINS0_15binary_oarchiveEcNSt3__111char_traitsIcEEEE
N5boost7archive21basic_binary_oarchiveINS0_15binary_oarchiveEEE
N5boost7archive6detail15common_oarchiveINS0_15binary_oarchiveEEE
N5boost7archive6detail18interface_oarchiveINS0_15binary_oarchiveEEE
N5boost13serialization6detail17singleton_wrapperINS_7archive6detail11oserializerINS3_15binary_oarchiveEN4snlp3ssu5cache20SSUCacheObjectHeaderEEEEE
N5boost7archive6detail11oserializerINS0_15binary_oarchiveEN4snlp3ssu5cache20SSUCacheObjectHeaderEEE
N5boost13serialization6detail17singleton_wrapperINS_7archive6detail11oserializerINS3_13text_oarchiveEN4snlp3ssu5cache20SSUCacheObjectHeaderEEEEE
N5boost7archive6detail11oserializerINS0_13text_oarchiveEN4snlp3ssu5cache20SSUCacheObjectHeaderEEE
N5boost13serialization6detail17singleton_wrapperINS_7archive6detail11oserializerINS3_15binary_oarchiveENSt3__16vectorINS7_12basic_stringIcNS7_11char_traitsIcEENS7_9allocatorIcEEEENSC_ISE_EEEEEEEE
N5boost7archive6detail11oserializerINS0_15binary_oarchiveENSt3__16vectorINS4_12basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEENS9_ISB_EEEEEE
N5boost13serialization6detail17singleton_wrapperINS_7archive6detail11oserializerINS3_15binary_oarchiveEN4snlp3ssu5cache25SSUCacheObjectIntentNamesEEEEE
N5boost7archive6detail11oserializerINS0_15binary_oarchiveEN4snlp3ssu5cache25SSUCacheObjectIntentNamesEEE
N5boost13serialization6detail17singleton_wrapperINS_7archive6detail11oserializerINS3_13text_oarchiveENSt3__16vectorINS7_12basic_stringIcNS7_11char_traitsIcEENS7_9allocatorIcEEEENSC_ISE_EEEEEEEE
N5boost7archive6detail11oserializerINS0_13text_oarchiveENSt3__16vectorINS4_12basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEENS9_ISB_EEEEEE
N5boost13serialization6detail17singleton_wrapperINS_7archive6detail11oserializerINS3_13text_oarchiveEN4snlp3ssu5cache25SSUCacheObjectIntentNamesEEEEE
N5boost7archive6detail11oserializerINS0_13text_oarchiveEN4snlp3ssu5cache25SSUCacheObjectIntentNamesEEE
N5boost13serialization6detail17singleton_wrapperINS_7archive6detail11oserializerINS3_15binary_oarchiveENSt3__16vectorImNS7_9allocatorImEEEEEEEE
N5boost7archive6detail11oserializerINS0_15binary_oarchiveENSt3__16vectorImNS4_9allocatorImEEEEEE
N5boost13serialization6detail17singleton_wrapperINS_7archive6detail11oserializerINS3_15binary_oarchiveENSt3__16vectorIfNS7_9allocatorIfEEEEEEEE
N5boost7archive6detail11oserializerINS0_15binary_oarchiveENSt3__16vectorIfNS4_9allocatorIfEEEEEE
N5boost13serialization6detail17singleton_wrapperINS_7archive6detail11oserializerINS3_15binary_oarchiveEN4snlp3ssu5cache36SSUCacheObjectEncodingsBatchNegativeEEEEE
N5boost7archive6detail11oserializerINS0_15binary_oarchiveEN4snlp3ssu5cache36SSUCacheObjectEncodingsBatchNegativeEEE
N5boost13serialization6detail17singleton_wrapperINS_7archive6detail11oserializerINS3_13text_oarchiveENSt3__16vectorImNS7_9allocatorImEEEEEEEE
N5boost7archive6detail11oserializerINS0_13text_oarchiveENSt3__16vectorImNS4_9allocatorImEEEEEE
N5boost13serialization6detail17singleton_wrapperINS_7archive6detail11oserializerINS3_13text_oarchiveENSt3__16vectorIfNS7_9allocatorIfEEEEEEEE
N5boost7archive6detail11oserializerINS0_13text_oarchiveENSt3__16vectorIfNS4_9allocatorIfEEEEEE
N5boost13serialization6detail17singleton_wrapperINS_7archive6detail11oserializerINS3_13text_oarchiveEN4snlp3ssu5cache36SSUCacheObjectEncodingsBatchNegativeEEEEE
N5boost7archive6detail11oserializerINS0_13text_oarchiveEN4snlp3ssu5cache36SSUCacheObjectEncodingsBatchNegativeEEE
N5boost13serialization6detail17singleton_wrapperINS_7archive6detail11oserializerINS3_15binary_oarchiveEN4snlp3ssu5cache36SSUCacheObjectEncodingsBatchPositiveEEEEE
N5boost7archive6detail11oserializerINS0_15binary_oarchiveEN4snlp3ssu5cache36SSUCacheObjectEncodingsBatchPositiveEEE
N5boost13serialization6detail17singleton_wrapperINS_7archive6detail11oserializerINS3_13text_oarchiveEN4snlp3ssu5cache36SSUCacheObjectEncodingsBatchPositiveEEEEE
N5boost7archive6detail11oserializerINS0_13text_oarchiveEN4snlp3ssu5cache36SSUCacheObjectEncodingsBatchPositiveEEE
N4snlp3ssu7trigger17SSUTriggerAppNameE
N4snlp6common14text_uso_graph19SpacedTextTreeLexerE
N4snlp6common14text_uso_graph13TextTreeLexerE
N4snlp6common14text_uso_graph17UDATextTreeParserE
N13sentencepiece3bpe5ModelE
N13sentencepiece5model8FreeListIZNKS_3bpe5Model12SampleEncodeEN4absl11string_viewEfE10SymbolPairEE
NSt3__110__function6__funcIZNK13sentencepiece3bpe5Model12SampleEncodeEN4absl11string_viewEfE3$_2NS_9allocatorIS7_EEFvS6_PNS_6vectorINS_4pairIS6_iEENS8_ISC_EEEEEEE
NSt3__110__function6__baseIFvN4absl11string_viewEPNS_6vectorINS_4pairIS3_iEENS_9allocatorIS6_EEEEEEE
ZNK13sentencepiece3bpe5Model12SampleEncodeEN4absl11string_viewEfE3$_2
N13sentencepiece31SentencePieceText_SentencePieceE
N13sentencepiece17SentencePieceTextE
N13sentencepiece22NBestSentencePieceTextE
N13sentencepiece11TrainerSpecE
N13sentencepiece14NormalizerSpecE
N13sentencepiece19SelfTestData_SampleE
N13sentencepiece12SelfTestDataE
N13sentencepiece24ModelProto_SentencePieceE
N13sentencepiece10ModelProtoE
N6google8protobuf8internal16InternalMetadata9ContainerINSt3__112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEEEE
N6google8protobuf8internal16InternalMetadata13ContainerBaseE
N13sentencepiece9character5ModelE
N13sentencepiece10filesystem17PosixReadableFileE
N13sentencepiece10filesystem12ReadableFileE
N13sentencepiece14ModelInterfaceE
N13sentencepiece10normalizer10NormalizerE
N5Darts15DoubleArrayImplIvvivEE
N5Darts7Details9ExceptionE
N13sentencepiece22SentencePieceProcessorE
N13sentencepiece7unigram5ModelE
N13sentencepiece7unigram7LatticeE
N13sentencepiece5model8FreeListINS_7unigram7Lattice4NodeEEE
N13sentencepiece5model8FreeListIZNS_7unigram7Lattice5NBestEmE10HypothesisEE
N13sentencepiece4word5ModelE
N6google8protobuf14FatalExceptionE
N6google8protobuf8internal15ExtensionFinderE
N6google8protobuf8internal24GeneratedExtensionFinderE
N6google8protobuf8internal12ExtensionSet8KeyValueE
N6google8protobuf13RepeatedFieldIiEE
N6google8protobuf13RepeatedFieldIxEE
N6google8protobuf13RepeatedFieldIjEE
N6google8protobuf13RepeatedFieldIyEE
N6google8protobuf13RepeatedFieldIfEE
N6google8protobuf13RepeatedFieldIdEE
N6google8protobuf13RepeatedFieldIbEE
N6google8protobuf16RepeatedPtrFieldINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEEE
N6google8protobuf8internal20RepeatedPtrFieldBaseE
N6google8protobuf16RepeatedPtrFieldINS0_11MessageLiteEEE
NSt3__13mapIiN6google8protobuf8internal12ExtensionSet9ExtensionENS_4lessIiEENS_9allocatorINS_4pairIKiS5_EEEEEE
N6google8protobuf11MessageLiteE
NSt3__112basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEE
30SentencepieceModelLoadingError
N5boost7archive17archive_exceptionE
N5boost7archive6detail14basic_iarchiveE
N5boost12noncopyable_11noncopyableE
N5boost12noncopyable_10base_tokenE
N5boost7archive6detail17helper_collectionE
N5boost7archive6detail17basic_iserializerE
N5boost7archive6detail16basic_serializerE
N5boost7archive6detail14basic_oarchiveE
N5boost7archive6detail17basic_oserializerE
N5boost7archive12codecvt_nullIcEE
?456789:;<=
 !"#$%&'()*+,-./0123
N5boost7archive9iterators18dataflow_exceptionE
N5boost13serialization18extended_type_infoE
N5boost13serialization6detail22extended_type_info_argE
N5boost13serialization13typeid_system27extended_type_info_typeid_0E
N5boost13serialization13typeid_system29extended_type_info_typeid_argE
N16nl_featurization14FeaturizerImplE
N16nl_featurization18AbstractFeaturizerE
!h
!h
++Dq
FlatBuffers 2.0.0
item_id
TreeManipulation_OneShotReplyRemodeller
UserAccepted
UserStatedTask
vector
component_name
SNLPLanguageVariantClassifierErrorDomain
LVC/LVC.mlmodelc/model.espresso.net
LVC/spans_pad.txt
LVC/context_pad.txt
LVC/targets.txt
An error occured reading LVC model bundle at: %@
Check that the path contains a valid model bundle: %@
SiriNaturalLanguageParsing
SNLPFeatureStoreEnabled
SNLPMessageContentRuleEnabled
SNLPWireAudioAccessoryMemory
SNLPSalientEntityFeaturizationEnabled
old_prediction
hidden
memory
encodings
num_of_utterance_tokens
attention_index
out_predictions
out_new_hidden
out_new_memory
out_new_attention_index
.nlu.lzfse
.nlu
.version
The request locale does not match the SSUFile locale
Unrecognized asset directory format version: 
Asset directory touch version file not present when expected for: 
Asset directory does not exist or is not a directory: 
-[UPContextualizerStrategyPrompt resultUsingContextualizerInput:]
UPContextualizerStrategyPrompt.m
[dialogAct isKindOfClass:[UPDialogActPrompt class]]
version.yaml
config.json
^VERSION: (\d+)\.(\d+)\.(\d+)
Version file not found at path: 
Version file has no parseable version key: 
%02x
bolt_task_id
NLv4
SNLC
UaaP
UNKNOWN
<UNDEFINED_COMPONENT>
-[UPContextualizerStrategyOffer resultUsingContextualizerInput:]
UPContextualizerStrategyOffer.m
[contextualizerInput.dialogAct isKindOfClass:[UPDialogActOffer class]]
Could not build an SNLPSSUMatcherDirectories object
The given directory is not a file URL: %@.
SNLPITFMErrorDomain
Missing resource: %@
Check that resource is available: %@
target
common_Message
stringContent
primitive_String
common_Announcement
content
[UNK]
[PAD]
[CLS]
[SEP]
Could not open vocabulary data file: 
tokenText argument is empty
Encountered unknown token text and the vocabulary hasno special unknown token
Encountered unknown token ID
[NO_SDAS]
[NO_LEGACY_NL_CONTEXT_LABEL]
DICTATION_PROMPT=
STRICT_PROMPT=
PREVIOUS_NLV3_DOMAIN=
TRUE
FALSE
[insights-snlp-nlv4]: 
[insights-snlp-snlc]: 
[insights-snlp-uaap]: 
[insights-snlp-owl]: 
[insights-snlp-psc]: 
[insights-snlp-lvc]: 
[insights-snlp-ssu]: 
[insights-snlp-<UNDEFINED_COMPONENT>]: 
shape = 
 data = 
Shortcuts
semantic_value
Searching for span with UTF-16 indices (
common_Date
common_Timer
Found matching span with graph:
) vs (
Found a matching insertable span 
Found a new max score, 
, for a non-matching insertable span 
Found a common_Time span with a Jaccard score of 
, overwriting the common_Date span with a Jaccard score of 
UPDialogActPrompt[intent: %@, entityType: %@, entityName: %@, reference: %@]
span_indices
token_embeddings
intent_softmax
app_label_softmax
bio_labels_softmax
group_labels_softmax
Espresso context is nil.
Espresso plan is nil.
Could not create espresso plan.
Failed to build espresso plan.
Failed to execute espresso plan.
Failed to clean up espresso plan.
Failed to reshape espresso blob.
Failed to bind buffer to input 
Failed to bind buffer to output 
SSU only supports a single category at this time.
SSU only supports a single category group in the category at this time.
App shortcut is only supported category type: rdar://101955859
Category at index 
 is out of bounds
Category group at index 
 is out of bounds for category index 
Category Index is out of bounds
Locale not supported by assets directory: 
Unable to open file: 
Unable to gather stats on file
Unable to read the SSU file
/dev/urandom
open /dev/urandom
/AppleInternal/Library/BuildRoots/a1c21190-ba93-11ed-8126-ae4f7fab34c4/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator16.4.Internal.sdk/usr/local/include/boost/uuid/detail/random_provider_posix.ipp
boost::uuids::detail::random_provider_base::random_provider_base()
read
void boost::uuids::detail::random_provider_base::get_random_bytes(void *, std::size_t)
group_name_transform
smsGroupName
personFullName
TreeManipulation_GroupNameTransform
Failed to parse 
^ *"(.*)"
^ *(\d+)
^ *([a-zA-Z0-9:_]+)
^ *:([a-zA-Z0-9:_]+)
^ *\n( *)
^ */ *([a-zA-Z0-9:_]+)
^ *\[(\d+):(\d+)\]
com.apple.uaapcustomluframework
{unique_ptr<itfm_inference_orchestrator::orchestration::ITFMOrchestrator, std::default_delete<itfm_inference_orchestrator::orchestration::ITFMOrchestrator>>={__compressed_pair<itfm_inference_orchestrator::orchestration::ITFMOrchestrator *, std::default_delete<itfm_inference_orchestrator::orchestration::ITFMOrchestrator>>=^{ITFMOrchestrator}}}32@?0@"SNLPITFMModelBundle"8@"SNLPITFMModelInfo"16^@24
%@ Asset Error when creating the %@ (ITFM) inference orchestrator: %s
Hit SNLP exception while calling ITFMOrchestrator::handle for request (high=%llu, low=%llu): %s
ERROR: Could not find the config file 
INFO: The parameter 
 is null.  This is currently expected behaviour.
WARNING: Could not parse the config parameter 
[json.exception.
invalid BOM; must be 0xEF 0xBB 0xBF if given
invalid literal
invalid comment; missing closing '*/'
invalid comment; expecting '/' or '*' after '/'
invalid string: missing closing quote
invalid string: '\u' must be followed by 4 hex digits
invalid string: surrogate U+D800..U+DBFF must be followed by U+DC00..U+DFFF
invalid string: surrogate U+DC00..U+DFFF must follow U+D800..U+DBFF
invalid string: forbidden character after backslash
invalid string: control character U+0000 (NUL) must be escaped to \u0000
invalid string: control character U+0001 (SOH) must be escaped to \u0001
invalid string: control character U+0002 (STX) must be escaped to \u0002
invalid string: control character U+0003 (ETX) must be escaped to \u0003
invalid string: control character U+0004 (EOT) must be escaped to \u0004
invalid string: control character U+0005 (ENQ) must be escaped to \u0005
invalid string: control character U+0006 (ACK) must be escaped to \u0006
invalid string: control character U+0007 (BEL) must be escaped to \u0007
invalid string: control character U+0008 (BS) must be escaped to \u0008 or \b
invalid string: control character U+0009 (HT) must be escaped to \u0009 or \t
invalid string: control character U+000A (LF) must be escaped to \u000A or \n
invalid string: control character U+000B (VT) must be escaped to \u000B
invalid string: control character U+000C (FF) must be escaped to \u000C or \f
invalid string: control character U+000D (CR) must be escaped to \u000D or \r
invalid string: control character U+000E (SO) must be escaped to \u000E
invalid string: control character U+000F (SI) must be escaped to \u000F
invalid string: control character U+0010 (DLE) must be escaped to \u0010
invalid string: control character U+0011 (DC1) must be escaped to \u0011
invalid string: control character U+0012 (DC2) must be escaped to \u0012
invalid string: control character U+0013 (DC3) must be escaped to \u0013
invalid string: control character U+0014 (DC4) must be escaped to \u0014
invalid string: control character U+0015 (NAK) must be escaped to \u0015
invalid string: control character U+0016 (SYN) must be escaped to \u0016
invalid string: control character U+0017 (ETB) must be escaped to \u0017
invalid string: control character U+0018 (CAN) must be escaped to \u0018
invalid string: control character U+0019 (EM) must be escaped to \u0019
invalid string: control character U+001A (SUB) must be escaped to \u001A
invalid string: control character U+001B (ESC) must be escaped to \u001B
invalid string: control character U+001C (FS) must be escaped to \u001C
invalid string: control character U+001D (GS) must be escaped to \u001D
invalid string: control character U+001E (RS) must be escaped to \u001E
invalid string: control character U+001F (US) must be escaped to \u001F
invalid string: ill-formed UTF-8 byte
invalid number; expected digit after '-'
invalid number; expected digit after '.'
invalid number; expected '+', '-', or digit after exponent
invalid number; expected digit after exponent sign
value
object key
object separator
number overflow parsing '
array
object
excessive object size: 
cannot get value
invalid_iterator
iterator does not fit current value
iterator out of range
cannot use erase() with 
type_error
null
string
boolean
binary
discarded
number
excessive array size: 
out_of_range
<U+%.4X>
parse_error
parse error
 at line 
, column 
syntax error 
while parsing 
; last read: '
unexpected 
; expected 
<uninitialized>
true literal
false literal
null literal
string literal
number literal
<parse error>
end of input
'[', '{', or a literal
unknown token
cannot compare iterators of different containers
cannot use key() for non-object iterators
type must be number, but is 
type must be boolean, but is 
type must be string, but is 
Could not convert
semanticValue
unknownCustomEntity
unknownCustomVerb
DataDetectorService
The ITFM asset version (
) is incompatible with inference runtime (compatible versions 
ITFM Orchestrator failed with incompatible major version
Request does not contain a tokenised utterance
Request does not contain a token chain
Request does not contain embeddings
Request embeddings num tokens (
) does not match actual num tokens (
Request embeddings (
) exceeds maximum (
Received null input parser request
SystemGaveOptions
SystemOffered
executed_task
salient_entity
active_task
sdas
executed_tasks
salient_entities
active_tasks
_type=
_full_path=
_verb_entity=
_verb=
_below_verb=
_are_present
_are_absent
contact_type_split
contactType
emailType
TreeManipulation_ContactTypeSplit
nullptr
string_view::substr
cancel
notForMe
selectOrdinal
ordinal
placeholderVerb
((\w+)::common_(\w+)(\.)?(\w+))
::common
SystemPrompted
SystemOffered.offered_act.
SystemGaveOptions.option.
SystemInformed.entity
SystemReportedSuccess
SystemReportedFailure
.primitive_String
SystemOffered.offered_act.UserStatedTask
SystemOffered.offered_act.UserWantedToProceed
UserAcknowledged
UserCancelled
UserRejected
UserWantedToPause
UserWantedToProceed
UserWantedToRepeat
SystemInformed
_verb_entity
contact_address_downcast
emailAddress
phoneNumber
TreeManipulation_ContactAddressDowncaster
map::at:  key not found
min_max_labeller
minimumMaximum
floatSettingState
minimum
maximum
TreeManipulation_MinimumMaximumLabeller
de_DE
en_AU
en_CA
en_GB
en_IN
en_US
fr_FR
Error parsing JSON grammar: row.IsObject() == false [for key: 
resolution-table
 entry
semantic-value
Error parsing JSON grammar: parsedSemanticValue != row.MemberEnd() && parsedSemanticValue->value.IsString() == false [for key: 
synonyms
Error parsing JSON grammar: parsedSynonyms != row.MemberEnd() && parsedSynonyms->value.IsArray() == false [for key: 
Error parsing JSON grammar: parsedSynonym.IsString() == false [for key: 
type
Error parsing JSON grammar: parsedValueType->value.IsString() == false [for key: 
enum-choices
Error parsing JSON grammar: parsedEnumChoices->value.IsArray() == false [for key: 
open-list-choices
Error parsing JSON grammar: parsedOpenListChoices->value.IsArray() == false [for key: 
Error parsing JSON grammar: parsedResolutionTable->value.IsArray() == false [for key: 
left-label
Error parsing JSON grammar: leftLabel != jsonRule.MemberEnd() && leftLabel->value.IsString() == false [for key: 
value-constraints
Error parsing JSON grammar: parsedValueConstraints->value.IsObject() == false [for key: 
right-labels
Error parsing JSON grammar: parsedRightLabels != jsonRule.MemberEnd() && parsedRightLabels->value.IsArray() == false [for key: 
Error parsing JSON grammar: rightLabelObject.IsObject() == false [for key: 
name
Error parsing JSON grammar: parsedName != rightLabelObject.MemberEnd() && parsedName->value.IsString() == false [for key: 
repeated
Error parsing JSON grammar: parsedRepeatedFlag != rightLabelObject.MemberEnd() && parsedRepeatedFlag->value.IsBool() == false [for key: 
Could not open grammar file for reading: 
Grammar file is in error state after reading: 
Label does not exist
Error parsing JSON grammar: jsonGrammar.IsObject() == false [for key: 
(root)
rules
Error parsing JSON grammar: parsedRules != jsonGrammar.MemberEnd() && parsedRules->value.IsArray() == false [for key: 
unordered_map::at: key not found
Error parsing JSON grammar: enumChoice.IsString() == false [for key: 
Error parsing JSON grammar: openListChoice.IsString() == false [for key: 
Error parsing JSON grammar: parsedRule.IsObject() == false [for key: 
Expected:
Actual:
Badly-formed UDA
Expected a UDA of type 
 but got a 
appName
appEntity
Applications
source_tokens_embeddings
matched_spans
context
source_mask
class_probabilities
SNLPServerNLClassifierErrorDomain
SNLC/SNLC.mlmodelc/model.espresso.net
SNLC/spans_pad.txt
SNLC/context_pad.txt
An error occured reading SNLC model bundle at: %@
node=
edge=
stringValue=
integerValue=
indentation=
alias=
textAlignment=
after
approx
before
beginning
earlier
early
every
last
lastlast
late
later
middle
next
nextnext
potentialEvery
restof
same
slidinglast
this
upcoming
week
weekend
weekday
month
quarter
year
summer
winter
autumn
spring
semester
season
businessday
afternoon
bedtime
breakfast
brunch
dinner
evening
happyhour
lunch
midnight
morning
night
noon
SNLPPommesServerClassifierErrorDomain
PSC/PSC.mlmodelc/model.espresso.net
PSC/spans_pad.txt
PSC/context_pad.txt
PSC/targets.txt
confidence_threshold
An error occured reading PSC model bundle at: %@
ROOT
value=
intent=
[next]
[startPayload]
[leaf]
[endPayload]
[newGroup]
task
UserStarted
UserContinued
UserDisambiguated
UserResponded
label
directLeafNodes
validateInferenceTensor failed for tensor 
 because: actualRank (
) != expectedRank (
 because: dimension at index 
 is zero (expected=
) != expectedDimension (
 because: actualDataSize (
) != expectedDataSize (
-[UPContextualizerStrategyOptions resultUsingContextualizerInput:]
UPContextualizerStrategyOptions.m
[contextualizerInput.dialogAct isKindOfClass:[UPDialogActOptions class]]
TreeManipulation_ReplaceFromPersonRecipient
common_Person
common_PersonRelationship
fromPerson
identifyingRelationship
recipients
relationshipType
spiece.model
max_num_utterance_embeddings
utterance_tokens_embedder_emb_dim
max_num_spans_tokens
spans_pad_symbol_index
max_num_context_tokens
batch_size
UNDEFINED_COMPONENT
common_
Node 
 not found in ontology.
Verb 
Last node on the parser stack is null, but it shouldn't
Test alignment parsed but last node on parser stack is not a UsoEntityNode
Empty edge found while attaching: 
Edge not found in ontology: 
Could not attach child 
 to parent 
 with edge 
Check
Control
Convert
Create
Delete
Entity
NoVerb
PlaceholderVerb
RecipientsEventTrigger
RecipientsHiddenPeople
Reference
ReferenceControl
ReferenceDateTimeRangeTrigger
ReferenceDurationTrigger
ReferenceMeasurementTrigger
ReferenceNumberTrigger
ReferencePaymentSortKey
ReferencePhotoCollection
ReferencePhotoCollectionFilter
ReferencePhotoFilter
ReferencePhotoMemoryFilter
ReferencePhotoTag
ReferenceProfile
ReferenceSelect
ReferenceSlideshowFilter
ReferenceStringTrigger
ReferenceTarget
ReferenceTargetSelect
ReferenceTrigger
ReferenceVideoFilter
Request
StockSummarise
Summarise
Target
Update
Token indices out of range: [
Unknown LabelScheme observed
Cannot read SSU cache file with unrecognized version: 
Boost serialization exception: 
I/O stream exception: 
Corrupted SSU cache file: invalid terminator after last negative batch
Corrupted SSU cache file: invalid terminator after last positive batch
Could not deserialise espresso context.
Could not set up espresso network. Got error status: 
not_found
ERROR: Could not find network configuration: 
Note that only parameters of unsigned integer type are currently expected by SiriNaturalLanguageParsing.  This issue will likely cause SiriNaturalLanguageParsing to fail.
Could not build a graph builder for unhandled category: %u
Failed to convert CFString to C++ string
bert_embeddings_requires_subword_embeddings
bert/embeddings/requires_subword_embeddings
feature_pooling_mask
bert_feature_extraction_output
bert/feature_extraction_output
bert_feature_extraction_output_subword
bert/feature_extraction_output_subword
bert_sentence_features
bert/sentence_features
input_ids
input_mask
hello
world
hello world
genericConfirmation
zh_CN
yue_CN
APP_SHORTCUT
USER_SHORTCUT
APP_UI
SOCIAL
DateTime
BeginTime
EndTime
Hours
Meridian
Minutes
MinutesBefore
Seconds
SpecialTimePeriod
Time
TimeDuration
TimeOffset
TimeSpan
TimeSpanReference
TimeSpanWithReference
AbsoluteDate
PartialDate
Date
DateDuration
DateOffset
DateSpan
DateSpanReference
DateSpanWithReference
DateTimeQualifier
DayNumber
DayOfNextWeek
DayOfThisWeek
DayOfWeek
MonthNumber
OccurrenceCount
OrdinalCount
RelativeDay
RelativeDayOfWeek
SpecialDatePeriod
SpecialDatePeriodUnit
SpecialDay
Identifier
YearNumber
B16@?0@"UPResultCandidate"8
+[UPContextualizerUtilities buildPayloadResultFromQuery:modelIdentifier:intent:entityName:serializer:]
UPContextualizerUtilities.m
utterance != nil
batch
candidate
SDA_MessagePayload_Prompt_Override
SDA_IntercomPayload_Prompt_Override
LegacyNLContext_DictationPrompt_Presence_Override
Token overflow; received 
 tokens, expected 
 or fewer tokens.
Could not open file path
FilePath
Given UTF-16 offset is not a Unicode scalar (code point) boundary: 
 000000000000
Input string is not a valid UTF-8 sequence! UTF-8 offset: 
Given UTF-16 offset exceeds the input string: 
Server
Device
Not_Pommes
Pommes
Failed to find the string representation of the SNLC output class: 
Failed to find the string representation of the PSC output class: 
relative_set_number_verb
setNumber
common_Setting
TreeManipulation_SetNumber_VerbReplacement
unknown/
Component: 
Version: SNLPVersionInfo[train=
, majorVersion=
, minorVersion=
Bolt task ID: 
Bolt task ID: <missing>
No assets provided
Combined Hash: 
asset could not be read
protobuf message is missing a start/end index
Invalid span: start token index (%u) >= end token index (%u)
Warning: discarding data detector matching span not aligned with non-whitespace tokens (%u -> %u)
{UPSpan range: %@ ; type: %lu ; category: %@}
TreeManipulation_DefaultValueMediaPlaybackSpeed
context_vocab.txt
multicardinal_vocab.txt
spans_vocab.txt
trg_vocab.txt
span_label_mapping.txt
SystemPrompted_Send_MessageContent
SystemPrompted_Send_MessageContent_With_NLv4_Model_Hypotheses
SDA_Placeholder_Verb_Replacement
SystemPrompted_AnnouncementContent
The NLv4 asset version (
NLv4InferenceOrchestrator setup is broken; erroneous assets were provided
NLv4 request is null
PlaceholderVerb_placeholderVerb
NLv4 request missing request ID
NLv4 request missing valid embeddings
NLv4 request missing valid tokens
NLv4 request missing valid token chain locale
NLv4 request embeddings num tokens (
The NLv4 model config does not contain a setting for the maximum number of matching spans, max_num_spans_tokens.  Inference cannot continue.
SystemPrompted.task.send::common_Message.target.common_Message.stringContent
SystemPrompted.task.send::common_Announcement.target.common_Announcement.content
time
date
common_Time
common_Time12HourClock
common_Time24HourClock
common_Integer
integerValue
denominatorValue
numeratorValue
wholeValue
decoder.mlmodelc/model.espresso.net
encoder.mlmodelc/model.espresso.net
decoder.mlmodelc/model.mil
encoder.mlmodelc/model.mil
encoder.mlmodelc/model.bundle/universal.bundle/universal.e5
decoder.mlmodelc/model.bundle/universal.bundle/universal.e5
encoder.mlmodelc/model.bundle/universal.bundle/main/segment_0__cpu/model.espresso.net
decoder.mlmodelc/model.bundle/universal.bundle/main/segment_0__cpu/model.espresso.net
common_UserEntity.associatedUserEntities
common_Setting.name
common_Timer.attributes
common_UserEntity.names
common_DateTime.time
common_Message.recipients
userEntities
common_PhoneCall.recipients
common_Message.attachments
common_PhoneCall.attributes
common_Message.attributes
common_Person.name
common_Measurement.components
common_RecurringDateTime.recurrenceDateTimes
common_Announcement.recipients
common_Alarm.attributes
common_Message.participants
modified_TranslationSourceLocale
common_Translation
sourceString
common_LocalisedString
locale
common_Locale
modified_TranslationPayload
stringValue
modified_TranslationReferenceType
usoReferenceType
modified_TranslationTargetLocale
targetString
modified_GeographicAreaName
geographicArea
common_GeographicArea
modified_GeographicAreaType
areaType
User dialog act node has multiple children.
common_Message.Target_send
common_Announcement.Target_send
UPEntityWithValue[entityType: %@, entityName: %@, entityValue:%@]
UPDialogActOffer[intent: %@, entityWithValue: %@]
max_seq_length
DataDetector
PlumMatcher
UserVocabMatcher
SingleTrieMatcher
ContextMatcher
OvertonMatcher
MRRDetector
MRRMatcher
RegexSpanMatcher
personRelationship
phoneType
context_pad_symbol_index
start_symbol_index
end_symbol_index
model.espresso.net
model.bundle/universal.bundle/universal.e5
model.bundle/universal.bundle/main/segment_0__cpu/model.espresso.net
Could not find v1 espresso assets for OWL.
Feature mask rank unset for SubOwl model.
coffee
DATE_TIME
Could not create scanner from cache file: "
".  
utterance_tokens_embeddings
padding_mask
span_tokens
position_ids
out_init_decoder_hidden
out_encodings
addresses_
.cache
date_time_
addresses.cache
date_time.cache
flights.cache
currencies.cache
numbers.cache
phone_mobile.cache
[CLS_SPAN]
[SEP_SPAN]
[NO_SPAN]
model_info.plist
info.plist
intent.vocab.txt
bio_labels.vocab.txt
span.vocab.txt
grammar.json
model.mlmodelc
calibration_model.mlmodelc
SDA_Intercom_Payload_Prompt_Override
 => 
cache_directory_format_version.v1.touch
locales
temporary
.ssu_cache_file_in_progress
.ssu_cache_file
([0-9a-f]{32})
app_bundle
false
Subword embeddings enabled: 
bpe.model
vocab_size
Vocab size to pre-allocate: 
hidden_size
BERT:
      pre-process 
      forward: 
      aggregate & post-process: 
      post-process: 
reformulations.txt
bert.mlmodelc
src_vocab.txt
Vocabulary special tokens not properly defined
Could not build an SNLPSSUApplicationInfo object
The given asset directory is not a file URL: %@.
[SNLPSSUApplicationInfo bundleIdentifier='%@' assetURL='%@']
Request has no token chain
Request has no embeddings
v24@?0Q8^B16
Count of nonWhitespaceTokens does not match nonWhitespaceTokenIndexes
(missing)
{Token begin=%@, end=%@, value='%@'}
[%@]
%@ => %@
{UPQuery
  utterance: %@
  tokens: %@
  embeddingsByToken:
  spans:
UPDialogActOptions[intent: %@, entityType: %@, entityName: %@, entityValues: %@]
Invalid tensor name: 
Tensor description: 
Valid options are: [
Invalid feature pooling rank: 
feature extraction output
No embeddings are associated with token "%@"
Span label shape incorrect.
Given coordinates do not match tensor shape
Coordinates exceed bounds of tensor
com.apple.sirinaturallanguageparsing
v8@?0
General
Common
UPDataDetectors
SiriNaturalLanguageParsingSignPosts
text
TreeManipulation_SetIdentityPromoter
common_Person.ReferenceTarget_setIdentity
setIdentity
phone-number
SSUMatcherDirectories[
cacheDirectoryPath=
, modelAssetsPath=
, datasetAssetsPath=
Attempting to re-insert span entity to model graph, beneath 
usoEntityInsertionPoint
SNLPNaturalLanguageParserErrorDomain
NLv4 Asset Error when creating the C++ NLv4 orchestrator: %s
Hit SNLP exception while constructing C++ orchestrator with asset directory %@: %s
Hit SNLP exception while calling NLv4InferenceOrchestrator::pbhandle for request (high=%llu, low=%llu): %s
NLv4InferenceOrchestrator::pbhandle returned nullptrfor request (high=%llu, low=%llu)
embeddingDim field missing from protobuf message
tokenIndex %u is out-of-bounds for an embedding tensor with %llu tokens
Protobuf message contains only %lu values but UPEmbedding for tokenIndex %u is being created (embeddingDim=%llu)
Protobuf message contains %lu embedding values which is not a multiple of %llu embedding dimensions
{UPEmbedding: dimension %lu}
mediaPlaybackSpeed
common_Decimal
common_Number_DefaultValue
common_Number
common_SettingValue
canonicalString
definedValue
numericValue
settings
UNKNOWN-MODEL-TYPE
[Span Token] i=
 id=
 token=
span '
' covers tokens [
common_MixedFraction
common_ListPosition
NLv4SpanResponseAsJSON
NLv4ContextResponseAsJSON
NLv4AssetVersionAsJSON
NLv4ExecutedHandcraftedRulesAsJSON
%@-ITFMSpanResponseAsJSON
%@-ITFMContextResponseAsJSON
%@-ITFMAssetVersionAsJSON
%@-ITFMExecutedHandcraftedRulesAsJSON
TreeNode[
label:'
value:'
parentArgument:'
UTF-8 code unit indices:[
UTF-16 code unit indices:[
Unicode code point indices:[
Expected a node to start at: 
Expected an edge to start at: 
Regex search failed: 
^(accepted|acknowledged|cancelled|delegated|rejected|user_stated_task|wanted_to_pause|wanted_to_proceed|wanted_to_repeat|UserAccepted|UserAcknowledged|UserCancelled|DelegatedUserDialogAct|UserRejected|UserStatedTask|UserWantedToPause|UserWantedToProceed|UserWantedToRepeat)
UDA previously defined as 
 but is being redefined as 
Expecting a valid UDA name but got 
User dialog act not yet specified
UDA not yet specified
accepted
acknowledged
cancelled
UserCanceled
delegated
DelegatedDialogAct
rejected
user_stated_task
wanted_to_pause
wanted_to_proceed
wanted_to_repeat
unknown UDA 
person_name_split
TreeManipulation_PersonNameSplit
GLOBAL
SNLPSSUErrorDomain
Could not execute SNLPSSUMatcher method on Simulator.
SNLPSSUMatcher was built targetting a Simulator.
Skip SSU functionality, or use a real device.
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/src/bpe_model.cc
(index) >= (0)
(index) < (static_cast<int>(symbols.size()))
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/src/builtin_pb/sentencepiece.pb.cc
sentencepiece.SentencePieceText.SentencePiece
sentencepiece.SentencePieceText
sentencepiece.NBestSentencePieceText
<unk>
</s>
<pad>
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/src/builtin_pb/sentencepiece_model.pb.cc
sentencepiece.TrainerSpec
sentencepiece.NormalizerSpec
sentencepiece.SelfTestData.Sample
sentencepiece.SelfTestData
sentencepiece.ModelProto.SentencePiece
sentencepiece.ModelProto
Program terminated with an unrecoverable error.
Cancelled
Unknown
Invalid argument
Deadline exceeded
Not found
Already exists
Permission denied
Unauthenticated
Failed precondition
Aborted
Out of range
Unimplemented
Internal
Unavailable
Data loss
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/src/filesystem.cc
ReadAll is not supported for stdin.
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/src/model_factory.cc
Unknown model_type: 
piece must not be empty.
 is already defined.
unk is already defined.
byte piece 
 is found although `byte_fallback` is false.
 is invalid.
unk is not defined.
there are not 256 byte pieces although `byte_fallback` is true.
<0x%02X>
SiriNaturalLanguageParsing/External_Libraries/sentencepiece/src/model_interface.h
Not implemented.
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/src/normalizer.cc
precompiled_charsmap is empty. use identity normalization.
(length) >= (0)
(norm_to_orig->size()) == (normalized->size() + 1)
Blob for normalization rule is broken.
Trie data size exceeds the input blob size.
(0) == (trie_->build(key.size(), const_cast<char **>(&key[0]), nullptr, nullptr))
SiriNaturalLanguageParsing/External_Libraries/sentencepiece/src/util.h
'result' Must be non NULL
SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/darts_clone/darts.h:703: exception: failed to resize pool: std::bad_alloc
SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/darts_clone/darts.h:1141: exception: failed to insert key: negative value
SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/darts_clone/darts.h:1143: exception: failed to insert key: zero-length key
SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/darts_clone/darts.h:1157: exception: failed to insert key: invalid null character
SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/darts_clone/darts.h:1162: exception: failed to insert key: wrong key order
SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/darts_clone/darts.h:842: exception: failed to build rank index: std::bad_alloc
SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/darts_clone/darts.h:1380: exception: failed to modify unit: too large offset
SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/darts_clone/darts.h:1726: exception: failed to build double-array: invalid null character
SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/darts_clone/darts.h:1728: exception: failed to build double-array: negative value
SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/darts_clone/darts.h:1743: exception: failed to build double-array: wrong key order
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/src/sentencepiece_processor.cc
_status.ok()
model_proto->ParseFromArray(serialized.data(), serialized.size())
LOG(
INFO
 samples did not pass the test.
Self-test failures. See LOG(INFO).
model_
Model is not initialized.
normalizer_
Normalizer is not initialized.
type == TrainerSpec::UNIGRAM || type == TrainerSpec::BPE
Vocabulary constraint is only enabled in subword units.
(v.size()) >= (1)
!v[0].empty()
absl::SimpleAtoi(v[1], &freq)
Could not parse the frequency
pieces
output container is null
detokenized
!w.empty()
Empty piece is not allowed.
(begin) < (norm_to_orig.size())
(end) < (norm_to_orig.size())
(orig_begin) <= (input.size())
(orig_end) <= (input.size())
(orig_begin) <= (orig_end)
(consumed) == (normalized.size())
all normalized characters are not consumed.
output proto is null
nbest_spt
model_->IsNBestEncodeAvailable()
NBestEncode is not available for the current model.
!nbests.empty()
NBestEncode returns empty result.
(nbest_size) <= (512)
nbest_size must be nbest_size <= 512
model_->IsSampleEncodeAvailable()
SampleEncode is not available for the current model.
Invalid id: 
ERROR
Returns default value 
unknown extra_option type.
reverse
it != extra_option_map.end()
option "
" is not available.
!IsUnknown(PieceToId(absl::string_view(model_->bos_piece().data())))
id for `
` is not defined.
!IsUnknown(PieceToId(absl::string_view(model_->eos_piece().data())))
model file path should not be empty.
input->ReadAll(&serialized)
(0) <= (byte)
(consumed) == (1)
(token_index_begin + offset) == (token_index_end)
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/src/unigram_model.cc
Failed to find the best path in Viterbi.
WARNING
nbest_size >= 1. Returns empty result.
Too big agenda. shrinking
(num_nodes) < (trie_results.size())
no pieces are loaded.
cannot build double-array.
no entry is found in the trie.
Two sentence piece sequences are not equivalent! Left: 
, Score: 
. Right: 
 Error #
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/protobuf-lite/arena.cc
CHECK failed: (min_bytes) <= (std::numeric_limits<size_t>::max() - kBlockHeaderSize): 
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/protobuf-lite/common.cc
This program requires version 
 of the Protocol Buffer runtime library, but the installed version is 
.  Please update your library.  If you compiled the program yourself, make sure that your headers are from the same version of Protocol Buffers as your link-time library.  (Version verification failed in "
This program was compiled against version 
 of the Protocol Buffer runtime library, which is not compatible with the installed version (
).  Contact the program author for an update.  If you compiled the program yourself, make sure that your headers are from the same version of Protocol Buffers as your link-time library.  (Version verification failed in "
%d.%d.%d
FATAL
[libprotobuf %s %s:%d] %s
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/protobuf-lite/extension_set.cc
Non-primitive types can't be packed.
can't reach here.
SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/protobuf-lite/google/protobuf/extension_set_inl.h
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/protobuf-lite/generated_message_util.cc
CHECK failed: (scc->visit_status.load(std::memory_order_relaxed)) == (SCCInfoBase::kRunning): 
(cannot determine missing fields for lite message)
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/protobuf-lite/message_lite.cc
parse
 exceeded maximum protobuf size of 2GB: 
Can't 
 message of type "
" because it is missing required fields: 
SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/protobuf-lite/google/protobuf/parse_context.h
Can't happen
Subword model cannot be loaded from: 
true
basic_string
uninitialized exception
unregistered class
invalid signature
unsupported version
pointer conflict
incompatible native format
array size too short
input stream error
class name too long
unregistered void cast 
class version 
<unknown class>
unknown derived exception
code instantiated in more than one module
output stream error
programming error
serialization::archive
unknown exception code
attempt to encode a value > 6 bits
attempt to decode a value not in base64 char set
invalid xml escape_sequence
cannot invoke iterator comparison now
invalid multbyte/wide char conversion
ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/
size of int
size of long
size of float
size of double
endian setting
^(\b\w+\b)(\S+)$
Failed to initialise the regex expression for the subtokens: 
appendMatchedSpan
span_processor.cpp
mInternals.reverseMapping.find(str) != mInternals.reverseMapping.end() && "Unable to find token chain in reverse mapping after a match was found in the pattern " "trie"
Failed to attach the regex expression to the token text: 
Failed to find match in text: 
Encountered invalid substring: 
Encountered empty normalized matching substring for label: 
Begin/inside BIO tags must have a payload component
Only begin/inside BIO tags can have a payload component
Cannot extract payload from non-begin/inside BIO tag
getPayload
bio.cpp
mPayload.has_value()
Well-formed BIO tags must be >=3 characters long, but got: 
BIO tag has no prefix
Unrecognized BIO tag prefix
convertToLabelledSpans
!currentSpan.has_value()
buildAllBioTagsFromEntityLabels
bioTags.size() == expectedFinalSize
Cannot get value for empty optional!
Span labels tensor is of incorrect shape
Span labels tensor shape does not match tokens size
Unable to instantiate a normalizer form the input normalizer choice
Failed to instantiate normalizer - 
Failed to normalize string 
 - due to error: 
Failed to compare strings - due to error: 
Failed to casefold string: 
Invalid substring range. The endIndex
 >= src length 
Invalid substring range. startIndex  (
) >= endIndex (
insertToken
vocabulary.cpp
mIdToText.size() == mTextToId.size()
Token indices out of range.
Number of tokens differs from number of BIO tags
Number of tokens differs from number of group IDs
First dimension of intentEntityTransitions does not equal number of intents
Second dimension of intentEntityTransitions does not equal number of BIO tags
Size of startEntityTransitions does not equal number of BIO tags
First dimension of entityTransitions does not equal number of BIO tags
Second dimension of entityTransitions does not equal number of BIO tags
Out-of-range intent label (key) in uniqueLabels
Out-of-range BIO label (value) in uniqueLabels
Out-of-range intent label (key) in indexableLabels
Out-of-range BIO label (value) in indexableLabels
Empty entitiesScores (implies no tokens)
Size of groupScores (
) does not equal number of tokens (
Invalid beamSize. Should be in the interval (0, 5]
BeamSequence[
  score = 
  intent = 
  entities = 
  groupIds = 
(none)
beamSearch
beam_search.cpp
allCandidates.begin() + beamSize < allCandidates.end()
Beam sequence is empty getIntent
Beam sequence is empty getEntities
Embedding[
 ...
Label vocabulary does not contain pad token
Attempt pruning UserAccepted from a one shot reply UserAccepted + UserStatedTask prediction.
Could not find a UserAccepted dialog act to remove.
Hit filesystem error while reading %s: %s
UPContextualizerStrategyPrompt; %ld domain candidates matched dialog act prompted entity (%@)
UPContextualizerStrategyPrompt: No domain result matched dialog act prompted entity (%@)
UPContextualizerStrategyPrompt: Building verbatim string payload
[%s] Error, file doesn't exist. Hash for file content cannot be calculated: %s
[%s] Error, input stream for file could not be created. Hash for file content cannot be calculated: %s
[%s] Error, input stream for file could not be read. Hash for file content cannot be calculated: %s
[%s] Error while calculating hash of file %s
[%s] Error iterating over directory %s: %s
[%s] Warning: config missing Bolt task ID
[%s] Warning: config Bolt task ID is not a string
[%s] The component %zu is invalid
UPContextualizerStrategyOffer: Detected high-probability yes/no intent in core result
BEGIN "Encoder Inference"
Encoder Inference
END "Encoder Inference"
BEGIN "Decoder Inference"
Decoder Inference
END "Decoder Inference"
[%s] Invalid featurization input provided to the model.  Expected a non-empty utterance length tensor and a context tensor of at least two dimensions.
[%s] The utterance length (%lu) exceeds the maximum utterance length (%lu).
[%s] Padding of the embeddings input is required to execute model inference
[%s] Padding of the context input is required to execute model inference
[%s] Padding of the span input is required to execute model inference
Warning: cannot embed OOV token '%s'.
Featurized the following %lu LegacyNLContext features in ITFMParserRequest: %s
Failed to featurize any labels from legacyNlContext
Warning: Legacy NL context features were supplied, but the asset directory major version (%u) does not support these. These will not be featurized.
Warning: The request's nlContext contains a SDA. Skipping featurization for the legacy context.
No SDA present in nlContext: falling back to legacyNlContext
Failed to extract any labels from nlContext or legacyNlContext
Label '%s' not present in vocabulary. Skipping. (Is this label supported by the provided assets?)
Number of context features (%lu) exceeds maximum limit (%lu): truncating by removing features %s
[%s] %sITFM context: %s
nlu_request_id not found so skipping insertion of context featurized response into FeatureStore
ITFM non-padded context input tensor: %s
Skipping insertion of ITFM context featurizer response into FeatureStore because SNLPFeatureStoreEnabled feature flag is disabled
Successfully inserted context featurizer response into FeatureStore
Unable to insert context featurizer response into FeatureStore
UPQuery from non-proto service: %@
Could not convert query dialog act: %{sensitive}@
Converted dialog act and got: %@
Found no utterance alignments, skipping...
Found no matching insertable span.
SiriOntology indicated an entity node, but failed to cast to UsoEntityNode type.
No utterance alignments found in the entity node; searching the descendant nodes for utterance alignments instead.
Found no entities in the uso graph of matching span, skipping...
There is more than one entity in the USO graph of matching span, skipping...
The first level entity is not of entity node type, skipping...
BEGIN "UaaP UPParserModelInit initWithLoadedModelConfiguration"
UaaP UPParserModelInit initWithLoadedModelConfiguration
END "UaaP UPParserModelInit initWithLoadedModelConfiguration"
BEGIN "UaaP EspressoInference"
UaaP EspressoInference
END "UaaP EspressoInference"
BEGIN "UaaP Post-Processing"
Number of BEAM sequences = %lu
Processing BEAM sequence: %s
Produced candidate: %@
UaaP Post-Processing
END "UaaP Post-Processing"
BEGIN "UaaP Prediction"
Error predicting utterance: %{sensitive}s
UaaP Prediction
END "UaaP Prediction"
Reshaping network to handle current request inputs
Reshaping blob '%s' to w=%d, h=%d, k=%d, n=%d
[%s] %sFeaturizing the following context labels in NLv4ParserRequest.
Skipping insertion of NLv4 context featurizer response into FeatureStore because SNLPFeatureStoreEnabled feature flag is disabled
Loading SSUFile...
SSUFile successfully loaded from: %s
SSUFile relinquished
Temporary decompressed SSUFile removed at location: %s
Finished writing decompressed SSUFile to %s
Error when unmapping the memory for SSU file
[%s] Found an smsGroupName span that matches a common_Person or common_Agent node
[%s] Found a personFullName span that matches a common_Person or common_Agent node, so skipping group_name_transform
[%s] Replacing the node label "%s" with "%s"
[%s] Found %lu smsGroupName matching spans
[%s] Found %lu personFullName matching spans
[%@ Assets] %s
BEGIN "SNLPITFMClassifier responseForRequest"
SNLPITFMClassifier responseForRequest
END "SNLPITFMClassifier responseForRequest"
Warning: failed to parse month number string as an integer: '%s'. Returning nullptr.
Warning: parsed month number not in [1, 12]: %u. Returning nullptr.
Hit unexpected exception while converting USO graph: %s
Hit UsoGraphProtoWriterException while converting USO graph: %s
Attaching shared entity graph: %{sensitive}s
The shared entity graph does not have a single, unique entity below the root: skipping
The shared entity graph does not have an entity node
The entity node could not be dynamically cast to a UsoEntityNode
Failed to attach subtree: %{sensitive}s 
Warning: Creating an LVC (ITFM) Orchestrator without a target vocabulary. This means that string labels in the response will not be populated.
BEGIN "ITFM Span Featurization"
nlu_request_id not found so skipping insertion of asset version into FeatureStore
ITFM Span Featurization
END "ITFM Span Featurization"
BEGIN "ITFM Context Featurization"
ITFM Context Featurization
END "ITFM Context Featurization"
BEGIN "ITFM Inference"
ITFM Inference
END "ITFM Inference"
Could not find output label mapping for component %s
Warning: Invalid model version provided: %u.  Model versions currently supported: %s.
A token could not be reindexed; %{sensitive}s
Unknown error thrown during token index conversion (should be unreachable)
Token indexes could not be converted: %s
[%s] Splitting common_Person nodes in-place
[%s] Iterating through all tree nodes
[%s] Finished iterating through all tree nodes
[%s] Could not split this common_Person node
[%s] Successfully split the common_Person node into name/contact type
[%s] Handling common_Person subtree
[%s] Warning: the common_Person node has more than one child (expecting just `name`). Skipping.
[%s] Warning: the common_Person node child is not `name`. Skipping.
[%s] common_Person.name value: %{sensitive}s
[%s] There exists a person matching span covering this entire common_Person.name node. Skipping.
[%s] Could not find a split for this common_Person. Skipping.
[%s] Warning: Failed to generate a node for matching span (personInput=%{sensitive}s, contactTypeInput=%{sensitive}s)
[%s] Hit out of range exception when looking up token character indices
[%s] newNameNode.startCharIndex (%lu) is less than originalNameStartCharIndex (%lu)
[%s] newNameNode character indices imply an empty or impossible substring (%lu -> %lu)
[%s] contactAddressLabelNode.startCharIndex (%lu) is less than originalNameStartCharIndex (%lu)
[%s] contactAddressLabelNode character indices imply an empty or impossible substring (%lu -> %lu)
[%s] Generated new common_Person.name node with newNameNode.startCharIndex=%lu, newNameNode.endCharIndex=%lu, newNameNode.value=%{sensitive}s
[%s] After filtering, we have %lu contact type matching spans
[%s] After filtering, we have %lu person matching spans
[%s] Warning: could not find start token index corresponding to node.startCharIndex=%lu
[%s] Warning: could not find end token index corresponding to node.endCharIndex=%lu
[%s] Deleting %lu nodes
[%s] Inserting %lu spawned nodes
[%s] Badly formed SystemPrompted dialog act; needs to contain the target UsoGraph.
[%s] Badly formed SystemOffered dialog act; needs to contain a user dialog act.
[%s] Badly formed SystemReportedSuccess dialog act; needs to supply the task UsoGraph.
[%s] Badly formed SystemReportedFailure dialog act; needs to supply the UsoGraphs for the failed task and for the failure reason.
[%s] Warning: Badly formed user dialog act.
[%s] Failed to cast USO task node from SiriOntology. 
[%s] After filtering, we have %lu %s matching spans
[%s] No grounded tokens found under node: %s
No calibration score found for parser result with bundle modelIdentifier: %@
[%s] Both %s and %s semantic values found when using %s spans
[%s] MatchingSpan with label %s, semantic value %s found?: %{BOOL}d
Request validation failed: received nullptr request
Request validation failed: received request with no locale
Request validation failed: received request with a locale (%s) not matching the expected locale (%s)
Request validation failed: received request with no utterance
Successfully validated SSU request
Failed to build app entity from matching span. Skipping.
Matching span has no label. Skipping.
Warning: ON_SCREEN salient entity is missing appBundleId field. Skipping.
Warning: ON_SCREEN salient entity appBundleId field is missing string value. Skipping.
Failed to lookup string node data from matching span USO graph
Unexpected USO graph: app entity node does not contain a valid app bundle ID in its identifiers. Skipping.
Failed to extract UTF-8 indexes from the app entity span graph string node alignment
Matching span has no USO graph. Skipping.
Failed to convert proto USO graph to SiriOntology format. Skipping.
Failed to lookup node Root->entity. Skipping.
Unexpected USO graph: failed to lookup node Entity->name. Skipping.
Unexpected USO graph: node Entity->name is not of type StringNode. Skipping.
Unexpected USO graph: node Entity->name has no string value. Skipping.
Unexpected USO graph: identifier value is empty. Skipping.
Encountered error in deprecated version of inferenceResponseForRequest: %@ (returning SERVER parser response)
Result candidate has uncalibrated probability %f and calibrated probability %@. Using calibrated value.
Result candidate has uncalibrated probability %f and no calibrated probability. Using uncalibrated value.
Loaded config confidence_threshold: %1.2f
[%s] %sPSC %@ probability (%1.2f) is below the 'confidence_threshold: (%1.2f)', setting to -0.0
UPContextualizerStrategyCancel: Detected high-probability cancel intent in core result
UPContextualizerStrategyOptions: Detected high-probability selectOrdinal intent in core result
UPContextualizerStrategyOptions: %ld domain candidates matched dialog act prompted entity (%@)
UPContextualizerStrategyOptions: No domain result matched dialog act prompted entity (%@)
UPContextualizerStrategyOptions: Building verbatim string payload
Building SSUPreprocessor from assets directory: %s
Building preprocessor dependency: SentencePiece model using path: %s
BEGIN "SSUPreprocessor SentencePiece tokenization"
SSUPreprocessor SentencePiece tokenization
END "SSUPreprocessor SentencePiece tokenization"
Warning: truncating SentencePiece tokens for utterance: %{sensitive}s
Encoded utterance as sentence pieces: %{sensitive}s
Client tried to read the next negative cached encodings batch when there are none remaining
Client tried to read a positive cached encodings batch when there are still negative batches to be read
Client tried to read the next positive cached encodings batch when there are none remaining
[%s] [model_task_id=%s]
[%s] %s
Hit unexpected exception while generating USO graph: %s
Hit OntologyException while generating USO graph: %s
Could not compute utterance alignment boundary due to Unicode issue. Not adding alignment.
nlu_request_id not found so skipping insertion of SNLC executed handcrafted rules into FeatureStore
Skipping insertion of SNLC executed handcrafted rules into FeatureStore because SNLPFeatureStoreEnabled feature flag is disabled
Unable to insert executed handcrafted rules into FeatureStore
BEGIN "OWL Embedder Orchestrator Init"
OWL Embedder Orchestrator Init
END "OWL Embedder Orchestrator Init"
The app %s does not already exist in the registry: adding it
Removing app from the registry: %s
[%s] %sNo (app, category) tuples were triggered because the request contained no valid appName spans corresponding to registered SSU-enabled apps
[%s] %sApp '%s' with category '%s' was triggered
Warning: Encountered duplicate bundle ID in appInfos: %s. Using only the first encountered.
SNLC override triggered: falling back on DEVICE based on the turn input SDA content
SNLC override triggered: falling back on SERVER based on the LegacyNLContext dictationPrompt=true
[%s] %sRejecting '%s'.
Warning: Context shape not 2-dim
[NLv4IO Context Tensor] shape=%lu,%lu num_elems=%lu
Warning: Context shape not consistent with data
[NLv4IO Context Token] i=%lu j=%lu id=%lu token=%s
[%s] Could not reshape the input span tensor with %lu dimensions
[%s] Could not reshape the input context tensor with %lu dimensions
[%s] Could not reshape the input embeddings tensor with %lu dimensions
[%s] padEmbeddings input tensor size = %lu (%lu, %lu, %lu)
[%s] padEmbeddings maxNumTokens (defined by network config) = %lu
[%s] Illegal shape for embeddings: (%lu, %lu, %lu). Must be (?, ?, %lu) and hold %lu values
[%s] padEmbeddings For each batch, copying %lu embedding values and adding %lu padding values
[%s] padEmbeddings Padded embedding tensor shape: (%lu, %lu, %lu)
[%s] Found setNumber voc span(s)
Converted protobuf token indexes (%u -> %u) to non-whitespace token indexes (%lu -> %lu)
No matcher names provided - type property will be UPSpanTypeNone
Plum spans are deprecated and not recognized by the span matchers - type property will be UPSpanTypeNone
Span not recognized by the span matchers - type property will be UPSpanTypeNone
Trying to find a media playback subtree to replace default value playback speed.
Found a media playback subtree to replace default value playback speed.
Failed to find a media playback span with speed value.
Creating NLv4InferenceOrchestrator instance with getAssetVersionMajor()=%u
BEGIN "NLv4 Request Validation"
NLv4 Request Validation
END "NLv4 Request Validation"
BEGIN "NLv4 Reindexation"
NLv4 Reindexation
END "NLv4 Reindexation"
BEGIN "NLv4 Matched Span Featurization"
NLv4 Matched Span Featurization
END "NLv4 Matched Span Featurization"
BEGIN "NLv4 Context Featurization"
NLv4 Context Featurization
END "NLv4 Context Featurization"
NLv4 Inference
BEGIN "NLv4 Inference"
[%s] %sNumericalized span input for NLv4 parser model:
[%s] %sNumericalized context input for NLv4 parser model:
Attempt E5-ML inference.
Espresso model assets could not be found.  No NLv4 model was initialised.
END "NLv4 Inference"
BEGIN "NLv4 Denumericalization"
NLv4 Denumericalization
END "NLv4 Denumericalization"
BEGIN "NLv4 Placeholder Fixes"
NLv4 Placeholder Fixes
END "NLv4 Placeholder Fixes"
BEGIN "NLv4 Tree Building"
NLv4 Tree Building
END "NLv4 Tree Building"
BEGIN "NLv4 Post-Inference Tree Manipulation"
Tree after all manipulations:
%{sensitive}s
NLv4 Post-Inference Tree Manipulation
END "NLv4 Post-Inference Tree Manipulation"
BEGIN "NLv4 Protobuf Response Building"
A hypothesis was rejected because it contained only UserAccepted.
Building UDA for hypothesis number %zu
Invalid USO graph, removing parse from output.  This might be due to a grammatical error or an otherwise malformed model tree.
Could not generate a full USO graph for a hypothesis: %s
NLv4 Protobuf Response Building
END "NLv4 Protobuf Response Building"
BEGIN "NLv4 Post-Protobuf Response Corrections"
NLv4 Post-Protobuf Response Corrections
END "NLv4 Post-Protobuf Response Corrections"
BEGIN "NLv4 Handcrafted Rules"
[%s] %sExecuted handcrafted rules:
NLv4 Handcrafted Rules
END "NLv4 Handcrafted Rules"
[%s] %s[NLv4IO Ply tree] hypothesis=%zu:
[NLv4IO Ply tags] hypothesis=%zu:
[SNLPAssetLogger] %s
nlu_request_id not found so skipping insertion of executed handcrafted rules into FeatureStore
Skipping insertion of NLv4 executed handcrafted rules into FeatureStore because SNLPFeatureStoreEnabled feature flag is disabled
Successfully inserted NLv4 executed handcrafted rules into FeatureStore
Unable to insert NLv4 executed handcrafted rules into FeatureStore
Invalid model tree, removing parse from output.
Invalid user dialog act: %s
BEGIN "CalibrationInference"
CalibrationInference
END "CalibrationInference"
Executing OWL espresso v1 inference.
[%s] Warning: encountered unknown span matcher name: %d
[%s] Warning: failed to get namespace for node %{sensitive}s: %{sensitive}s
[%s] Badly formed matching span; start and/or end indices missing from span.
Initialised espresso v1 NLv4 model using original v1 assets.
Initialised espresso v1 NLv4 model using E5-ML v1 assets.  This implies an issue with E5-ML asset generation.  NLv4 inference can proceed, but may not be as performant as expected.
Initializing UPSharedEntityResolution with %lu matching spans
Resolving shared entities for token range (%lu, %lu) with value type: %@
Returning nil since we cannot handle non-date value types
Returning nil since there is no corresponding matching span
Found a corresponding matching span: returning the shared entity graph
Processing matching span with category: %@
Skipping non-DataDetected span
Skipping non-datetime span
Discarding duplicate matching date time span for range (%lu, %lu)
Adding DD datetime span with token range (%lu, %lu)
Missing locale info when init UPDataDetector. Falling back using the system default one.
[%s] A data detector span contained a USO graph with an invalid entity node.  This data detector span was ignored by the span matching featurizer.  Error: %s.
[%s] Span encoding failed; number of buckets (%lu) not matching number of tokens (%lu).
PSC override triggered: falling back on NOT POMMES based on the turn input SDA content
[SSUCacheDirectory] Creating a cache directory instance with root directory: %s
[SSUCacheDirectory] Not a directory: %s
[SSUCacheDirectory] Failed to initialize empty cache directory
[SSUCacheDirectory] Hit filesystem error: %s)
[SSUCacheDirectory] Clearing cache files for all locales
[SSUCacheDirectory] Removing locales directory: %s
[SSUCacheDirectory] Clearing cache files for all locales except %s
[SSUCacheDirectory] Encountered bad cache directory state: the locales directory %s contains a non-directory file: %s. Ignoring.
[SSUCacheDirectory] Removing locale directory: %s
[SSUCacheDirectory] Attempting to removing cache files across all locales for app: %s
[SSUCacheDirectory] Removing app bundle directory: %s
[SSUCacheDirectory] Found no cache files for app: %s. Doing nothing.
[SSUCacheDirectory] Could not find cache file in directory: %s
[SSUCacheDirectory] Encountered bad cache directory state: the app bundle directory %s contains a file with an unexpected filename: %s)
[SSUCacheDirectory] Inserting cache file for locale %s, appBundleId %s and version %s
[SSUCacheDirectory] Atomically renaming temporary file %s to final location %s
[SSUCacheDirectory] Initializing directory with V1 format: %s
[SSUCacheDirectory] Hit file stream error: %s)
[SSUCacheDirectory] Removing existing cache file before inserting new one: %s
[SSUCacheDirectory] Could not extract version from filename: %s
[SSUCacheDirectory] Encountered bad cache directory state: the app bundle directory %s is empty, with no cache files (expected exactly one)
[SSUCacheDirectory] Encountered bad cache directory state: the app bundle directory %s contains multiple cache files (expected exactly one)
[SSUCacheDirectory] Encountered bad cache directory state: the app bundle directory %s contains a non-regular file: %s)
[SSUCacheDirectory] Attempting to heal a corrupted cache by removing all contents under: %s
[SSUCacheDirectory] Error: cannot remove non-existing directory: %s
[SSUCacheDirectory] Successfully removed %lu files/directories under %s
[SSUCacheDirectory] Cannot initialize cache directory with existing file: %s
BEGIN "UPLoadedModelConfigurationInit"
BEGIN "EspressoInitialization"
Exception while initializing model %s
EspressoInitialization
END "EspressoInitialization"
UPLoadedModelConfigurationInit
END "UPLoadedModelConfigurationInit"
BEGIN "OWL Input Preprocess Aggregated"
OWL Input Preprocess Aggregated
END "OWL Input Preprocess Aggregated"
BEGIN "OWL Model Forward Aggregated"
OWL Model Forward Aggregated
END "OWL Model Forward Aggregated"
BEGIN "OWL Output PostProcess Aggregated"
OWL Output PostProcess Aggregated
END "OWL Output PostProcess Aggregated"
BEGIN "OWL Input Preprocess"
OWL Input Preprocess
END "OWL Input Preprocess"
BEGIN "OWL Model Forward"
OWL Model Forward
END "OWL Model Forward"
BEGIN "OWL Output PostProcess"
OWL Output PostProcess
END "OWL Output PostProcess"
[%s] [WARN] MatchingSpan has no USO graph
[%s] [WARN] MatchingSpan has USO graph with no identifiers
[%s] [WARN] probability missing from identifier
[%s] [WARN] probability has no value
[%s] [WARN] Negative relative threshold supplied (%f), span filtering will behave strangely
[%s] Span filtering: %lu out of %lu spans kept
[%s] Span %s [score %f] was kept?: %{BOOL}d
[%s] Span %s [no score] was kept?: %{BOOL}d
OWL assets not identified.  If this is a unit test, have you pulled all git lfs assets?  If this is a user request, have you ensured the assets are available on the device?
Hit error when converting protobuf span to UPSpan: %@
Multiple SystemDialogActs specified in context but UaaP can only handle one - using the first one
BEGIN "UaaP Preprocessing"
Featurized token with text=%s
Token span labels: %s
UaaP Preprocessing
END "UaaP Preprocessing"
Warning: discarding data detector matching span with unknown category %@
Adding matching span (%u -> %u) with label %@
Warning: could not look up ontology name for edge '%s'
Attaching %s edge, binding %s to %s.
Could not insert subtree: %{sensitive}s 
Insertion of subtree was successful.
Replaced the whole reinsertion subtree including the parent.
Replaced only the reinsertion point itself.
 Warning: Could not generate USO graph: %s
[%s] %sBuilt USO graph:
Failed to cast entity node to entity node; SiriOntology reports a non-entity node as an entity node.
Warning: Integer %s out of range for USO integer nodes.
Warning: Failed to convert string %s to integer.
Warning: could not look up ontology name for parent argument '%s'
BEGIN "SNLPNaturalLanguageParser inferenceResponseForRequest"
SNLPNaturalLanguageParser inferenceResponseForRequest
END "SNLPNaturalLanguageParser inferenceResponseForRequest"
Tree after ContactTypeSplit step:
%{sensitive}s
Tree after PersonNameSplitHack step:
%{sensitive}s
Tree after GroupNameTransform step:
%{sensitive}s
Tree after ContactAddressDowncaster step:
%{sensitive}s
Tree after DefaultMediaPlaybackSpeed step:
%{sensitive}s
Tree after SetIdentityPromoter step:
%{sensitive}s
Tree after MinimumMaximumLabeller labelling:
%{sensitive}s
Tree after One Shot Reply check:
%{sensitive}s
Tree after SetNumber verb replacement:
%{sensitive}s
Tree after fromPerson recipient replacement:
%{sensitive}s
[%s] Warning: Failed to extract UTF-8 indexes from the app entity span graph string node alignment: %s
[%s] Span Input
[%s] nlu_request_id not found so skipping insertion of span featurized response into FeatureStore
[%s] Warning: encountered span missing label
[%s] Badly formed matching span; start and/or end indices missing from span. Skipping.
[%s] Mapping span label '%s' to span label '%s'
[%s] Warning: Featurised spans shape not 3-dim
[%s] [Span Tensor] shape=%lu,%lu,%lu num_elems=%lu
[%s] Warning: Span shape not consistent with data
[%s] %s%s
[%s] Spans encoded over the tokens:
[%s] %sRejected OOV Spans: %s
[%s] Skipping insertion of matched spans featurized response into FeatureStore because SNLPFeatureStoreEnabled feature flag is disabled
[%s] Successfully inserted span featurizer response into FeatureStore
[%s] Unable to insert span featurizer response into FeatureStore
Could not find contextualizer strategy for dialog act: %{sensitive}@
Client tried to write the next negative cached encodings batch when there are none remaining to be written
Client tried to write a positive cached encodings batch when there are still negative batches remaining to be written
Client tried to write the next positive cached encodings batch when there are none remaining to be written
Inserting FeatureStore entry with interactionIdentifier=%@, streamIdentifier=%@
[%s] %sThe model has received %lu spans. Truncating this list of spans to %u spans.
[%s] %sThe following spans were kept after truncation:
[%s] %sThe following spans were removed during truncation:
[%s] %s  Span with label %s across indices (%u, %u).
[%s] %s  Span with label %s.
[%s] Since the model itself predicted only %lu common_Person nodes (lower than the threshold of %lu), do not apply the name split hack
[%s] Could not find _any_ partition for this common_Person (including a single-span one). Skipping.
[%s] This common_Person cannot be split into multiple sub-spans. Skipping.
[%s] This common_Person has been partitioned into %lu sub-spans.
[%s] Warning: Failed to generate a node for matching span (input=%{sensitive}s)
[%s] Finding person matching span partitions for range %lu -> %lu
[%s]  - span: %{sensitive}s
[%s] Found %lu possible person partitions:
[%s] Found minimal partition:
[%s]  - component: %{sensitive}s
[%s] Did not find minimal partition
[%s] Generated new common_Person.name node with startCharIndex=%lu, endCharIndex=%lu, value=%{sensitive}s
[%s] Successfully spawned replacement common_Person nodes
Returning app result for intent %s with batchType=%s, batchIndex=%lu, encodingIndexWithinBatch=%lu, similarityScore=%f
Highest matching negative example has score %f (batch type %s, batch index %lu, encoding index %lu). Using max(negativeScoreClipMinimum, score) = %f.
There is no negative example. Using minimum score %f.
BEGIN "Sentence Piece Load"
Sentence Piece Load
END "Sentence Piece Load"
SNLPLanguageVariantClassifier
UPModelIdentifier
NSCopying
UPContextualizerStrategyPrompt
UPContextualizerStrategy
NSObject
UPContextualizerStrategyOffer
SNLPSSUMatcherDirectories
UPDataDetectorSpan
SNLPITFMModelBundle
UPQueryRunner
UPDialogActPrompt
UPDialogAct
UPParserModel
SNLPITFMClassifier
UPUsoSerializer
UPCalibration
SNLPServerNLClassifier
UPResultCandidate
UPModelBundle
SNLPPommesServerClassifier
UPResultRootNode
UPResultNode
UPContextualizerStrategyCancel
UPContextualizerStrategyOptions
UPResultIntermediateNode
UPIntentWithSingleEntity
UPDialogActConverter
UPPreprocessorOutput
SNLPEmbedder
UPContextualizerUtilities
UPUtilities
UPSpan
UPCalibrationModel
UPEntityWithValue
UPDialogActOffer
UPSharedEntityResolution
UPDetectedData
UPDataDetectors
UPContextualizerInput
UPModelConfiguration
SNLPFeatureFlagUtilities
UPLoadedModelConfiguration
SNLPSSUApplicationInfo
UPResult
UPQuery
UPResultCandidateEntity
UPDialogActOptions
UPPreprocessor
UPResultLeafNode
SNLPNaturalLanguageParser
UPEmbedding
SNLPITFMModelInfo
UPContextualizer
SNLPFeatureStoreUtilities
SNLPSSUMatcher
T@"NSArray",R,C,N,V__candidates
.cxx_destruct
T@"UPResult",R,N,V_domainResult
T#,R
__usoSerializer
T@"<UPDialogAct>",R,N,V_dialogAct
_entity
T@"NSArray",R,C,V_entityValues
_locale
T@"NSArray",R,C,V_leafNodes
_tokens
T@"NSArray",R,V_entities
arrayWithArray:
T@"NSDictionary",R,N,V__dataDetectorDateTimeSpansByTokenRange
containsObject:
T@"NSDictionary",R,V_embeddingsByToken
dealloc
T@"NSLocale",R,N,V_locale
directLeafNodes
T@"NSNumber",R,V_groupId
entityWithValue
T@"NSSet",R,N,V_domainModelBundles
hasEmbeddingDim
T@"NSString",R,C
initWithCoreModel:domainModels:
T@"NSString",R,C,V_bioLabelsVocabPath
initWithIntent:entityWithValue:
T@"NSString",R,C,V_category
insertToFeatureStoreWithNLv4SpanResponse:interactionIdentifier:
T@"NSString",R,C,V_entityName
isProxy
T@"NSString",R,C,V_entityValue
numberWithLong:
T@"NSString",R,C,V_grammarPath
read:maxLength:
T@"NSString",R,C,V_intentVocabPath
resultFromResult:withNewIntent:
T@"NSString",R,C,V_parserEspressoModelPath
T@"NSString",R,C,V_spanVocabPath
startTokenIndex
T@"NSString",R,C,V_utterance
valueWithRange:
.cxx_construct
T@"NSURL",R,V_cacheDirectoryURL
JSONObjectWithData:options:error:
__candidateEntitiesByStartIndex
T@"<SIRINLUSystemDialogAct><NSObject>",R,V_dialogAct
_contextualizer
T@"NSArray",R,C,V_directLeafNodes
_intent
T@"NSArray",R,C,V_intermediateNodes
_parseUserDialogActGraph:error:
T@"NSArray",R,C,V_spans
annotatedString
T@"NSArray",R,V_tokens
choices
T@"NSDictionary",R,V__candidateEntitiesByStartIndex
containsString:
T@"NSLocale",R,C,N
deserializeFromSerializedGraph:
T@"NSNumber",R,V_calibratedProbability
T@"NSObject<SIRINLUUserDialogAct>",R,C,V_task
groupId
T@"NSString",R
highInt
T@"NSString",R,C,V_appBundleId
initWithIntent:
T@"NSString",R,C,V_calibrationEspressoModelPath
initWithLength:
T@"NSString",R,C,V_configPath
intentVocabPath
T@"NSString",R,C,V_entityType
modelIdentifier
T@"NSString",R,C,V_espressoModelPath
parserFromAssetDirectory:error:
T@"NSString",R,C,V_intent
release
T@"NSString",R,C,V_label
resultUsingContextualizerInput:
T@"NSString",R,C,V_semanticValue
setProbability:
T@"NSString",R,C,V_text
stringByAppendingPathComponent:
T@"NSString",R,N,V_bioLabelsVocabPath
T@"NSString",R,N,V_bundleId
T@"NSString",R,N,V_errorDomain
T@"NSString",R,N,V_intentVocabPath
T@"NSString",R,N,V_loggingComponentString
T@"NSString",R,V_bundleIdentifier
T@"NSString",R,V_intent
T@"NSString",R,V_label
T@"NSString",R,V_semanticValue
T@"NSString",R,V_text
T@"NSString",R,V_utterance
T@"NSURL",R,N,V_configURL
T@"NSURL",R,N,V_contextVocabularyURL
T@"NSURL",R,N,V_espressoModelURL
T@"NSURL",R,N,V_spanVocabularyURL
T@"NSURL",R,N,V_targetVocabularyURL
T@"NSURL",R,N,V_versionURL
T@"NSURL",R,V_assetURL
T@"NSURL",R,V_datasetAssetsDirectoryURL
T@"NSURL",R,V_modelAssetsDirectoryURL
T@"NSUUID",R,C,V_queryUUID
T@"NSUUID",R,C,V_uuid
T@"SIRINLUEXTERNALUserParse",R,N
T@"SIRINLUEXTERNALUsoGraph",R,N,V_sharedEntityGraph
T@"SIRINLUEXTERNALUsoGraph",R,V_sharedEntityGraph
T@"SIRINLUINTERNALUAAP_PARSERUaaPParserResponse",R
T@"SNLPITFMModelBundle",R,N,V_modelBundle
T@"SNLPITFMModelInfo",R,N,V_modelInfo
T@"UPCalibration",R,N,V__calibration
T@"UPCalibrationModel",R,N,V_calibrationModel
T@"UPContextualizer",R,N,V__contextualizer
T@"UPContextualizerStrategyCancel",R,N,V_cancelContextualizerStrategy
T@"UPContextualizerStrategyOffer",R,N,V_offerContextualizerStrategy
T@"UPContextualizerStrategyOptions",R,N,V_optionsContextualizerStrategy
T@"UPContextualizerStrategyPrompt",R,N,V_promptContextualizerStrategy
T@"UPDialogActConverter",R,N,V__dialogActConverter
T@"UPEntityWithValue",R,V_entity
T@"UPEntityWithValue",R,V_entityWithValue
T@"UPLoadedModelConfiguration",R,N,V__loadedModelConfiguration
T@"UPModelIdentifier",R,N,V_identifier
T@"UPModelIdentifier",R,N,V_modelIdentifier
T@"UPParserModel",R,N,V_coreModel
T@"UPParserModel",R,N,V_parserModel
T@"UPPreprocessor",R
T@"UPPreprocessor",R,N,V_preprocessor
T@"UPQuery",R,N,V_query
T@"UPResult",R,N,V_coreResult
T@"UPResultLeafNode",R
T@"UPResultRootNode",R
T@"UPResultRootNode",R,C
T@"UPUsoSerializer",R,C,V_usoSerializer
T@"UPUsoSerializer",R,N,V_usoSerializer
T@"UPUsoSerializer",R,V__usoSerializer
T@"UPUsoSerializer",R,V_usoSerializer
T@"USOSerializedGraph",R,V_reference
T@"USOSerializedGraph",R,V_usoGraph
TB,R
TQ,R
TQ,R,N,V_type
TQ,R,V_type
T^v,R
T^v,R,N,V_beamMaskInput
T^v,R,N,V_labelToValueType
T^v,R,N,V_resolver
T^v,R,V_ddUsoMapper
T^{EspressoModule=^v^v{?=^vi}},R,N,V_calibrationEspressoModule
T^{EspressoModule=^v^v{?=^vi}},R,N,V_parserEspressoModule
T^{UPDataDetector=q^{__DDScanner}^{__DDScanner}^{__DDScanner}^{__DDScanner}^{__DDScanner}^{__DDScanner}},R,V_dataDetector
T^{__DDResult=},R,V_dataDetectorResult
Td,R
Td,R,N
Td,R,N,V_prebuiltIntentThreshold
Td,R,V_uncalibratedProbability
Tf,N,V_confidenceThreshold
Ti,R,N,V_loggingComponent
Tr^{__CFArray=},R,V_dataDetectorResult
T{_NSRange=QQ},R,V_range
URLByAppendingPathComponent:
URLByDeletingLastPathComponent
UTF8String
UUID
__calibration
__candidates
__contextualizer
__dataDetectorDateTimeSpansByTokenRange
__dialogActConverter
__featurizer
__loadedModelConfiguration
_addPathForLabel:range:text:semanticValue:sharedEntityGraph:toGraphNode:forGraph:
_appBundleId
_assetLogger
_assetURL
_attachSharedEntity:withCustomEntityEdge:toGraphNode:forGraph:
_beamMaskInput
_bioLabelsVocabPath
_buildCandidateEntitiesByStartIndex:
_buildEmbeddingsDictionaryWithNonWhitespaceTokens:nonWhitespaceTokenIndexes:embeddings:error:
_buildTokenListWithTokenChain:nonWhitespaceTokenIndexes:
_bundleId
_bundleIdentifier
_cacheDirectoryURL
_calibratedProbability
_calibration
_calibrationEspressoModelPath
_calibrationEspressoModule
_calibrationModel
_cancelContextualizerStrategy
_candidateEntitiesByStartIndex
_candidateForBeamSequence:utterance:outputTokens:resolver:sharedEntityResolution:
_candidateForUtterance:probability:labelledSpans:intent:sharedEntityResolution:
_candidates
_category
_classifierWithModelURL:configURL:spanVocabularyURL:contextVocabularyURL:versionURL:error:
_confidenceThreshold
_configPath
_configURL
_configurationWithBioLabelsVocabPath:configPath:grammarPath:intentVocabPath:spanVocabPath:parserEspressoModelPath:calibrationEspressoModelPath:error:
_contextVocabularyURL
_contextualizeByDialogActTypeUsingContextualizerInput:
_convertBundleIdToEntity:
_convertFromGaveOptionsDialogAct:error:
_convertFromOfferedDialogAct:error:
_convertFromPromptedDialogAct:error:
_convertITFMResponse:
_convertRequest:
_convertResponse:
_convertSNLCRequest:
_coreModel
_coreResult
_cppOrchestrator
_createDialogActWithProtobufQuery:
_dataDetector
_dataDetectorDateTimeSpansByTokenRange
_dataDetectorResult
_datasetAssetsDirectoryURL
_ddUsoMapper
_dialogAct
_dialogActConverter
_dictionaryRepresentation
_directLeafNodes
_domainModelBundles
_domainResult
_embedding
_embeddingsByToken
_embeddingsTensor
_entities
_entityName
_entityType
_entityValue
_entityValues
_entityWithValue
_errorDomain
_errorForMissingResourceURL:errorDomain:
_espressoModelPath
_espressoModelURL
_existErrorForEspressoModelURL:configURL:contextVocabularyURL:spanVocabularyURL:targetVocabularyURL:versionURL:errorDomain:
_getNonWhitespaceTokenIndexes:
_getSpanTypeFromProtobufSpan:
_grammarPath
_groupHigherLevelEntities:
_groupId
_identifier
_indexedLabelRepresentation
_initWithBioLabelsVocabPath:configPath:grammarPath:intentVocabPath:spanVocabPath:parserEspressoModelPath:calibrationEspressoModelPath:
_initWithCppOrchestrator:
_initWithEspressoModelURL:configURL:contextVocabularyURL:spanVocabularyURL:targetVocabularyURL:versionURL:
_initializationBlock
_insertHigherLevelEntities:intoGraph:underTaskNode:
_insertSimpleEntity:intoGraph:underTaskNode:
_insertToFeatureStoreWithJSONString:interactionIdentifier:streamIdentifier:
_insertToFeatureStoreWithProtobufObject:interactionIdentifier:streamIdentifier:
_intentVocabPath
_intermediateNodeRepresentations:
_intermediateNodes
_jsonStringFromProtobufObject:
_label
_labelToValueType
_leafNodeFromGraphEdge:andGraphNode:
_leafNodeFromLabel:andGraphSemanticValueNode:
_leafNodeFromLabel:andGraphStringNode:
_leafNodes
_loadedModelConfiguration
_loggingComponent
_loggingComponentString
_matchSpansForDetectedDataArray:label:
_modelAssetsDirectoryURL
_modelBundle
_modelIdentifier
_modelInfo
_offerContextualizerStrategy
_optionsContextualizerStrategy
_orchestrator
_outputTokens
_parseUserDialogAct:error:
_parserEspressoModelPath
_parserEspressoModule
_parserModel
_prebuiltIntentThreshold
_preprocessor
_promptContextualizerStrategy
_query
_queryUUID
_range
_reference
_resolver
_resultFromInferenceResult:query:outputTokens:resolver:sharedEntityResolution:
_semanticValue
_setupAssetLogger
_sharedEntityGraph
_spanLabelsTensor
_spanVocabPath
_spanVocabularyURL
_spans
_targetVocabularyURL
_task
_text
_type
_uncalibratedProbability
_usoGraph
_usoSerializer
_usoVocabManager
_utterance
_uuid
_versionURL
addHypotheses:
addIndex:
addObject:
addObjectsFromArray:
allValues
alloc
allocWithZone:
annotatedEntityFragmentString
anyObject
appBundleId
appendFormat:
appendString:
applicationInfoWithBundleIdentifier:assetURL:error:
array
arrayWithCapacity:
arrayWithObject:
arrayWithObjects:count:
assetURL
autorelease
beamMaskInput
begin
bestAvailableProbability
bioLabelsVocabPath
buildDataDetectorDateTimeSpansByTokenRange:
buildMatchedSpanListFromQuerySpans:
buildPayloadResultFromQuery:modelIdentifier:intent:entityName:serializer:
buildSpansListWithProtobufQuery:nonWhitespaceTokenIndexes:error:
bundleId
bundleIdentifier
bundleWithEspressoModelURL:configURL:contextVocabularyURL:spanVocabularyURL:targetVocabularyURL:versionURL:errorDomain:error:
bytes
cacheDirectoryURL
calibrateCandidate:withCalibrationScore:
calibrateParserResults:withCalibrationScores:error:
calibrateResult:withCalibrationScore:
calibratedProbability
calibrationEspressoModelPath
calibrationEspressoModule
calibrationModel
cancelContextualizerStrategy
candidateAtRank:
candidateCount
category
characterAtIndex:
checkFileExistence:error:
class
classificationLabel
classificationProbability
classifierWithModelBundle:modelInfo:error:
classifierWithModelBundle:modelInfo:initializationBlock:error:
classifierWithModelURL:configURL:spanVocabularyURL:contextVocabularyURL:error:
classifierWithPathURL:error:
cleanValue
combinedResultFromResults:
componentsJoinedByString:
confidenceThreshold
configPath
configURL
configurationFromDirectoryUrl:error:
conformsToProtocol:
containsIndex:
contextVocabularyURL
convertCppSubwordTokenChainToObjC:
convertFromDialogAct:error:
convertFromUserDialogAct:
convertNLv4ParserRequestToCpp:
convertNLv4ParserResponseFromCppToObjC:
convertSystemDialogAct:
convertUsoGraphFromObjCToCpp:
copy
copyWithZone:
coreModel
coreResult
count
countByEnumeratingWithState:objects:count:
countOfIndexesInRange:
createConfirmOrRejectedDialogActsFor:reference:
createResultFromExistingResult:truncatedTo:
data
dataDetector
dataDetectorResult
dataWithBytes:length:
dataWithContentsOfURL:
dataWithJSONObject:options:error:
datasetAssetsDirectoryURL
ddUsoMapper
debugDescription
defaultCStringEncoding
defaultManager
deregisterApp:error:
description
dialogAct
dialogActFromQuery:
dictionary
dictionaryRepresentation
dictionaryWithContentsOfFile:
dictionaryWithDictionary:
dictionaryWithObjects:forKeys:count:
directoriesWithCacheDirectoryURL:modelAssetsDirectoryURL:datasetAssetsDirectoryURL:error:
domainModelBundles
domainResult
doubleValue
embeddingDim
embeddings
embeddingsByToken
embeddingsTensor
endTokenIndex
entities
entity
entityLabelsFromCandidate:
entityName
entityType
entityValue
entityValues
enumerateIndexesUsingBlock:
errorDomain
errorWithDomain:code:userInfo:
espressoModelPath
espressoModelURL
fileExistsAtPath:
fileExistsAtPath:isDirectory:
fileSystemRepresentation
filterResult:byEntityName:serializer:
filterResult:serializer:predicate:
firstObject
floatValue
forwardWithSpanLabels:embeddings:utterance:
getBytes:maxLength:usedLength:encoding:options:range:remainingRange:
getCoordinates
getDimension
getEmbeddings:
getEmbeddingsBySentence:
getUsoGraphPrintedForm
getWithStreamId:
grammarPath
hasBegin
hasCalibrationModel
hasEmbeddings
hasEnd
hasEndTokenIndex
hasNlContext
hasNumToken
hasStartTokenIndex
hasTokenChain
hasTopCandidate:excedingProbability:matchingOneOfIntents:
hasTurnContext
hasTurnInput
hasValue
hash
higherLevelChildLabel
higherLevelEntityLabelFromParentLabel:childLabel:
higherLevelParentLabel
hypotheses
identifier
indexSet
inferenceResponseForRequest:
inferenceResponseForRequest:error:
init
initFromAssetDirectoryURL:
initFromSourceVocabPath:bertModelPath:bertConfigPath:reformulatorPath:
initLoadFromDataDetectorsDirectoryPath:forLocale:
initWithAppBundleId:
initWithArray:copyItems:
initWithBundleIdentifier:assetURL:
initWithCacheDirectoryURL:modelAssetsDirectoryURL:datasetAssetsDirectoryURL:
initWithCandidates:queryUUID:
initWithCapacity:
initWithCoordinates:
initWithCoreModel:domainModelBundles:
initWithData:
initWithData:encoding:
initWithDomain:code:userInfo:
initWithDomainResult:coreResult:modelIdentifier:query:dialogAct:
initWithEmbeddingsTensor:spanLabelsTensor:outputTokens:
initWithIndexSet:
initWithIntent:entityType:entityName:entityValues:
initWithIntent:entityType:entityName:reference:
initWithIntent:singleEntity:
initWithJsonStr:interactionId:dataVersion:
initWithKey:ascending:
initWithLabel:
initWithLabel:andLeafNodes:
initWithLabel:andText:andSemanticValue:
initWithLabel:dataDetectorResult:
initWithLabel:intermediateNodes:directLeafNodes:
initWithLoadedModelConfiguration:
initWithLoadedModelConfiguration:parserModel:calibrationModel:
initWithLocale:featurizer:
initWithMatchingSpans:
initWithModelBundle:modelInfo:initializationBlock:error:
initWithModelConfiguration:
initWithPrebuiltIntentThreshold:
initWithPrebuiltIntentThreshold:usoSerializer:
initWithPreprocessor:parserModel:calibrationModel:
initWithProtobufEmbeddings:forTokenAt:error:
initWithProtobufQuery:error:
initWithProtobufSpan:nonWhitespaceTokenIndexes:error:
initWithRange:category:dataDetectorResult:
initWithRange:category:dataDetectorResult:usoGraph:
initWithRange:label:text:groupId:semanticValue:sharedEntityGraph:
initWithRange:type:category:
initWithRange:type:category:sharedEntityGraph:
initWithTask:
initWithType:entityName:entityValue:
initWithType:loggingComponent:errorDomain:
initWithUncalibratedProbability:calibratedProbability:utterance:intent:entities:modelIdentifier:task:
initWithUsoGraph:withError:
initWithUsoSerializer:
initWithUtterance:tokens:embeddingsByToken:spans:dialogAct:
inputStreamWithFileAtPath:
insert:error:
insertToFeatureStoreWithITFMAssertVersion:interactionIdentifier:itfmModelType:
insertToFeatureStoreWithITFMContextResponse:interactionIdentifier:itfmModelType:
insertToFeatureStoreWithITFMExecutedHandcraftedRules:interactionIdentifier:itfmModelType:
insertToFeatureStoreWithITFMSpanResponse:interactionIdentifier:itfmModelType:
insertToFeatureStoreWithNLv4AssertVersion:interactionIdentifier:
insertToFeatureStoreWithNLv4ContextResponse:interactionIdentifier:
insertToFeatureStoreWithNLv4ExecutedHandcraftedRules:interactionIdentifier:
instancesRespondToSelector:
intent
intermediateNodeRepresentations:
intermediateNodes
isEqual:
isEqualToEntityWithValue:
isEqualToIntentWithSingleEntity:
isEqualToString:
isFileURL
isHigherLevelEntity
isKindOfClass:
isMemberOfClass:
isReadableFileAtPath:
isSNLPFeatureStoreEnabled
isWhitespace
itfmModelTypeForSNLPComponent:
label
labelToValueType
languageCode
leafNodeRepresentation
leafNodes
length
lengthOfBytesUsingEncoding:
locale
localeIdentifier
localeWithLocaleIdentifier:
localizedDescription
localizedStringForKey:value:table:
loggingComponent
loggingComponentString
longValue
lowInt
mainBundle
matchSpans:
matchSpansForDetectedData:
matchSpansForUtterance:
matcherNamesAtIndex:
matcherNamesCount
matcherWithDirectories:initialApplicationInfos:initializeModelsPreemptively:error:
matchingSpans
matchingSpansAtIndex:
matchingSpansCount
modelAssetsDirectoryURL
modelBundle
modelInfo
modelWithLoadedModelConfiguration:error:
multiTurnPredictionFromQuery:modelIdentifierToDomainResults:dialogAct:error:
mutableBytes
nSStringToU16String:
nlContext
nluRequestId
null
numToken
numberWithDouble:
numberWithFloat:
numberWithUnsignedInteger:
numberWithUnsignedLong:
objectAtIndex:
objectAtIndexedSubscript:
objectForKey:
objectForKeyedSubscript:
offerContextualizerStrategy
offeredAct
open
optionsContextualizerStrategy
outputTokens
parserEspressoModelPath
parserEspressoModule
parserModel
path
performFullCacheUpdate:
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
prebuiltIntentThreshold
predictionFromProtobufQuery:error:
predictionFromQuery:error:
predictionFromQuery:preprocessorOutput:error:
preprocess:error:
preprocessor
printedForm
probability
promptContextualizerStrategy
protobufRepresentation
query
queryUUID
range
rangeFromStart:end:
rangeOfString:
reference
registerApp:error:
replaceObjectAtIndex:withObject:
requestId
resolveSharedEntityForTokenRange:valueType:
resolver
respondsToSelector:
responseForRequest:error:
resultWithContextualizerInput:
retain
retainCount
rootNode
rootNodeRepresentation
rootNodeRepresentationForIntent:andEntities:
scoreFromQuery:preprocessorOutput:error:
self
semanticValue
serializeFromIntent:andEntities:forBundleId:
setAlgorithm:
setClassificationLabel:
setClassificationProbability:
setConfidenceThreshold:
setEmbedderId:
setEmbeddingDim:
setEmbeddingTensor:
setEmbeddingTensorOutputs:
setEmbeddings:
setLocale:
setMatchingSpans:
setNluRequestId:
setNumLayer:
setNumToken:
setObject:atIndexedSubscript:
setObject:forKey:
setObject:forKeyedSubscript:
setParser:
setParserId:
setReference:
setRequestId:
setSentenceEmbeddingTensor:
setSubwordEmbeddingTensorOutputs:
setSubwordTokenChain:
setTokenChain:
setTokenisedUtterance:
setTurnInput:
setUserDialogActs:
setValues:count:
setWithArray:
sharedEntityGraph
singleTurnPredictionFromDomainResults:
sortedArrayUsingDescriptors:
spanLabelsTensor
spanVocabPath
spanVocabularyURL
spans
stdU16ToNSString:
string
stringByDeletingLastPathComponent
stringByReplacingOccurrencesOfString:withString:
stringForModelType:
stringLabel
stringWithCString:encoding:
stringWithCapacity:
stringWithCharacters:length:
stringWithFormat:
stringWithUTF8String:
subarrayWithRange:
substringFromIndex:
substringToIndex:
superclass
systemDialogActs
systemDialogActsCount
targetVocabularyURL
task
text
toCppUsoGraph:withError:
tokenChain
tokenDescription:
tokenisedUtterance
tokens
tokensAtIndex:
tokensCount
trySetSimulatorError:
turnContext
turnInput
type
uncalibratedProbability
usoGraph
usoSerializer
utterance
uuid
value
valueForKey:
valuesAtIndex:
valuesCount
versionURL
warmup
zone
@32@0:8@16^@24
@24@0:8^{_NSZone=}16
@24@0:8@16
B24@0:8@16
Q16@0:8
@16@0:8
v16@0:8
@"NSUUID"
@"NSString"
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B16@0:8
B24@0:8#16
B24@0:8:16
Vv16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
@"UPResult"24@0:8@"UPContextualizerInput"16
@32@0:8d16@24
d16@0:8
@"UPUsoSerializer"
@24@0:8d16
@48@0:8@16@24@32^@40
@40@0:8@16@24@32
@"NSURL"
@48@0:8{_NSRange=QQ}16@32^{__DDResult=}40
@56@0:8{_NSRange=QQ}16@32^{__DDResult=}40@48
^{__DDResult=}16@0:8
^{__DDResult=}
@"USOSerializedGraph"
@80@0:8@16@24@32@40@48@56@64^@72
@72@0:8@16@24@32@40@48@56@64
@32@0:8@16@24
@64@0:8@16@24@32@40@48@56
@"UPParserModel"
@"NSSet"
@"UPCalibration"
@"UPDialogActConverter"
@"UPContextualizer"
@48@0:8@16@24@32@40
@52@0:8r^v16f24r^v28@36@44
{UPInferenceResult={UPGenericTensor={vector<unsigned long, std::allocator<unsigned long>>=^Q^Q{__compressed_pair<unsigned long *, std::allocator<unsigned long>>=^Q}}{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}}{UPGenericTensor={vector<unsigned long, std::allocator<unsigned long>>=^Q^Q{__compressed_pair<unsigned long *, std::allocator<unsigned long>>=^Q}}{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}}{UPGenericTensor={vector<unsigned long, std::allocator<unsigned long>>=^Q^Q{__compressed_pair<unsigned long *, std::allocator<unsigned long>>=^Q}}{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}}}120@0:8{UPGenericTensor={vector<unsigned long, std::allocator<unsigned long>>=^Q^Q{__compressed_pair<unsigned long *, std::allocator<unsigned long>>=^Q}}{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}}16{UPGenericTensor={vector<unsigned long, std::allocator<unsigned long>>=^Q^Q{__compressed_pair<unsigned long *, std::allocator<unsigned long>>=^Q}}{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}}64@112
@56@0:8r^v16@24r^v32^v40@48
@56@0:8r^v16r^v24r^v32^v40@48
@40@0:8@16@24^@32
@"UPModelIdentifier"
@"UPLoadedModelConfiguration"
@48@0:8@16@24@?32^@40
@?16@0:8
{unique_ptr<const sirinluinternalitfm::ITFMParserRequest, std::default_delete<const sirinluinternalitfm::ITFMParserRequest>>={__compressed_pair<const sirinluinternalitfm::ITFMParserRequest *, std::default_delete<const sirinluinternalitfm::ITFMParserRequest>>=^{ITFMParserRequest}}}24@0:8@16
@72@0:8{ITFMParserResponse=^^?{PtrVector<sirinluinternalitfm::ITFMHypothesis>={vector<std::unique_ptr<sirinluinternalitfm::ITFMHypothesis>, std::allocator<std::unique_ptr<sirinluinternalitfm::ITFMHypothesis>>>=^v^v{__compressed_pair<std::unique_ptr<sirinluinternalitfm::ITFMHypothesis> *, std::allocator<std::unique_ptr<sirinluinternalitfm::ITFMHypothesis>>>=^v}}}{unique_ptr<sirinluexternal::Parser, std::default_delete<sirinluexternal::Parser>>={__compressed_pair<sirinluexternal::Parser *, std::default_delete<sirinluexternal::Parser>>=^{Parser}}}fB{?=b1b1}}16
{unique_ptr<snlp::common::asset_logger::SNLPAssetLogger, std::default_delete<snlp::common::asset_logger::SNLPAssetLogger>>={__compressed_pair<snlp::common::asset_logger::SNLPAssetLogger *, std::default_delete<snlp::common::asset_logger::SNLPAssetLogger>>=^{SNLPAssetLogger}}}16@0:8
{unique_ptr<itfm_inference_orchestrator::orchestration::ITFMOrchestrator, std::default_delete<itfm_inference_orchestrator::orchestration::ITFMOrchestrator>>="__ptr_"{__compressed_pair<itfm_inference_orchestrator::orchestration::ITFMOrchestrator *, std::default_delete<itfm_inference_orchestrator::orchestration::ITFMOrchestrator>>="__value_"^{ITFMOrchestrator}}}
{unique_ptr<snlp::common::asset_logger::SNLPAssetLogger, std::default_delete<snlp::common::asset_logger::SNLPAssetLogger>>="__ptr_"{__compressed_pair<snlp::common::asset_logger::SNLPAssetLogger *, std::default_delete<snlp::common::asset_logger::SNLPAssetLogger>>="__value_"^{SNLPAssetLogger}}}
@"SNLPITFMModelBundle"
@"SNLPITFMModelInfo"
@32@0:8r^v16r^{UsoGraphNode=^^?^{UsoGraph}Q}24
@40@0:8{vector<std::pair<std::reference_wrapper<siri::ontology::UsoGraphNode>, std::reference_wrapper<const siri::ontology::UsoGraphEdge>>, std::allocator<std::pair<std::reference_wrapper<siri::ontology::UsoGraphNode>, std::reference_wrapper<const siri::ontology::UsoGraphEdge>>>>=^v^v{__compressed_pair<std::pair<std::reference_wrapper<siri::ontology::UsoGraphNode>, std::reference_wrapper<const siri::ontology::UsoGraphEdge>> *, std::allocator<std::pair<std::reference_wrapper<siri::ontology::UsoGraphNode>, std::reference_wrapper<const siri::ontology::UsoGraphEdge>>>>=^v}}16
@32@0:8@16r^v24
v40@0:8@16^v24^{UsoGraphNode=^^?^{UsoGraph}Q}32
v80@0:8@16{_NSRange=QQ}24@40@48@56^{UsoGraphNode=^^?^{UsoGraph}Q}64^v72
v48@0:8@16r^v24^{UsoGraphNode=^^?^{UsoGraph}Q}32^v40
{shared_ptr<siri::ontology::UsoVocabManager>="__ptr_"^{UsoVocabManager}"__cntrl_"^{__shared_weak_count}}
@32@0:8@16d24
@56@0:8@16@24@32@40^@48
@64@0:8@16@24@32@40@48^@56
@72@0:8d16@24@32@40@48@56@64
@"NSObject<SIRINLUUserDialogAct>"
@"NSNumber"
@"NSArray"
@"NSDictionary"
@"UPCalibrationModel"
@"UPPreprocessor"
f16@0:8
v20@0:8f16
@"UPEntityWithValue"
@136@0:8{UPGenericTensor={vector<unsigned long, std::allocator<unsigned long>>=^Q^Q{__compressed_pair<unsigned long *, std::allocator<unsigned long>>=^Q}}{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}}16{UPGenericTensor={vector<unsigned long, std::allocator<unsigned long>>=^Q^Q{__compressed_pair<unsigned long *, std::allocator<unsigned long>>=^Q}}{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}}64{vector<nl_featurization::Token, std::allocator<nl_featurization::Token>>=^{Token}^{Token}{__compressed_pair<nl_featurization::Token *, std::allocator<nl_featurization::Token>>=^{Token}}}112
^v16@0:8
{UPGenericTensor="shape"{vector<unsigned long, std::allocator<unsigned long>>="__begin_"^Q"__end_"^Q"__end_cap_"{__compressed_pair<unsigned long *, std::allocator<unsigned long>>="__value_"^Q}}"data"{vector<float, std::allocator<float>>="__begin_"^f"__end_"^f"__end_cap_"{__compressed_pair<float *, std::allocator<float>>="__value_"^f}}}
{vector<nl_featurization::Token, std::allocator<nl_featurization::Token>>="__begin_"^{Token}"__end_"^{Token}"__end_cap_"{__compressed_pair<nl_featurization::Token *, std::allocator<nl_featurization::Token>>="__value_"^{Token}}}
@56@0:8{SubwordTokenChain=^^?{unique_ptr<std::string, std::default_delete<std::string>>={__compressed_pair<std::string *, std::default_delete<std::string>>=^v}}{PtrVector<sirinluinternal::SubwordToken>={vector<std::unique_ptr<sirinluinternal::SubwordToken>, std::allocator<std::unique_ptr<sirinluinternal::SubwordToken>>>=^v^v{__compressed_pair<std::unique_ptr<sirinluinternal::SubwordToken> *, std::allocator<std::unique_ptr<sirinluinternal::SubwordToken>>>=^v}}}}16
{unique_ptr<nlv4_inference_orchestrator::orchestration::EmbedderOrchestrator, std::default_delete<nlv4_inference_orchestrator::orchestration::EmbedderOrchestrator>>="__ptr_"{__compressed_pair<nlv4_inference_orchestrator::orchestration::EmbedderOrchestrator *, std::default_delete<nlv4_inference_orchestrator::orchestration::EmbedderOrchestrator>>="__value_"^{EmbedderOrchestrator}}}
B40@0:8@16d24@32
@56@0:8@16@24@32@40@48
@40@0:8@16@24@?32
B32@0:8@16^@24
{_NSRange=QQ}32@0:8Q16Q24
{basic_string<char16_t, std::char_traits<char16_t>, std::allocator<char16_t>>={__compressed_pair<std::basic_string<char16_t>::__rep, std::allocator<char16_t>>={__rep=(?={__long={?=b1b63}Q^S}{__short={?=b1b7}[1c][11S]}{__raw=[3Q]})}}}24@0:8@16
@24@0:8r^v16
Q24@0:8@16
@56@0:8{_NSRange=QQ}16Q32@40@48
@48@0:8{_NSRange=QQ}16Q32@40
{_NSRange=QQ}16@0:8
@"SIRINLUEXTERNALUsoGraph"
{_NSRange="location"Q"length"Q}
d120@0:8{UPGenericTensor={vector<unsigned long, std::allocator<unsigned long>>=^Q^Q{__compressed_pair<unsigned long *, std::allocator<unsigned long>>=^Q}}{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}}16{UPGenericTensor={vector<unsigned long, std::allocator<unsigned long>>=^Q^Q{__compressed_pair<unsigned long *, std::allocator<unsigned long>>=^Q}}{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}}64@112
@40@0:8{_NSRange=QQ}16@32
@32@0:8@16r^{__CFArray=}24
r^{__CFArray=}16@0:8
r^{__CFArray=}
@32@0:8^{__CFArray=}16@24
^{UPDataDetector=q^{__DDScanner}^{__DDScanner}^{__DDScanner}^{__DDScanner}^{__DDScanner}^{__DDScanner}}16@0:8
^{UPDataDetector=q^{__DDScanner}^{__DDScanner}^{__DDScanner}^{__DDScanner}^{__DDScanner}^{__DDScanner}}
@"UPResult"
@"UPQuery"
@"<UPDialogAct>"
^{EspressoModule=^v^v{?=^vi}}16@0:8
@"NSLocale"
^{EspressoModule=^v^v{?=^vi}}
@32@0:8@16Q24
@24@0:8q16
q16@0:8
@"<SIRINLUSystemDialogAct><NSObject>"
@72@0:8{_NSRange=QQ}16@32@40@48@56@64
{vector<nl_featurization::span_matching::MatchedSpan, std::allocator<nl_featurization::span_matching::MatchedSpan>>=^{MatchedSpan}^{MatchedSpan}{__compressed_pair<nl_featurization::span_matching::MatchedSpan *, std::allocator<nl_featurization::span_matching::MatchedSpan>>=^{MatchedSpan}}}24@0:8@16
@32@0:8@16r^{AbstractFeaturizer=^^?}24
r^{AbstractFeaturizer=^^?}
@24@0:8{unique_ptr<nlv4_inference_orchestrator::orchestration::NLv4InferenceOrchestrator, std::default_delete<nlv4_inference_orchestrator::orchestration::NLv4InferenceOrchestrator>>={__compressed_pair<nlv4_inference_orchestrator::orchestration::NLv4InferenceOrchestrator *, std::default_delete<nlv4_inference_orchestrator::orchestration::NLv4InferenceOrchestrator>>=^{NLv4InferenceOrchestrator}}}16
{unique_ptr<nlv4_inference_orchestrator::orchestration::NLv4InferenceOrchestrator, std::default_delete<nlv4_inference_orchestrator::orchestration::NLv4InferenceOrchestrator>>="__ptr_"{__compressed_pair<nlv4_inference_orchestrator::orchestration::NLv4InferenceOrchestrator *, std::default_delete<nlv4_inference_orchestrator::orchestration::NLv4InferenceOrchestrator>>="__value_"^{NLv4InferenceOrchestrator}}}
@36@0:8@16i24^@28
@24@0:8Q16
@36@0:8Q16i24@28
i16@0:8
@"UPContextualizerStrategyCancel"
@"UPContextualizerStrategyOffer"
@"UPContextualizerStrategyOptions"
@"UPContextualizerStrategyPrompt"
B32@0:8@16@24
B40@0:8@16@24Q32
B40@0:8@16@24@32
Q24@0:8r^i16
@44@0:8@16@24B32^@36
v24@0:8^@16
B24@0:8^@16
@(#)PROGRAM:SiriNaturalLanguageParsing  PROJECT:SiriNaturalLanguageParsing-1
N4snlp3ssu5parse18SSUGraphBuilderAppE
N4snlp3ssu5parse15SSUGraphBuilderE
NSt3__120__shared_ptr_emplaceIN4snlp3ssu3app14SSUFileWrapperENS_9allocatorIS4_EEEE
#lll
#!'#
UNSt3__111__end_stateIcEE
NSt3__120__shared_ptr_pointerIPNS_13__empty_stateIcEENS_10shared_ptrIS2_E27__shared_ptr_default_deleteIS2_S2_EENS_9allocatorIS2_EEEE
NSt3__113__empty_stateIcEE
NSt3__120__l_anchor_multilineIcEE
NSt3__120__r_anchor_multilineIcEE
NSt3__115__word_boundaryIcNS_12regex_traitsIcEEEE
NSt3__111__lookaheadIcNS_12regex_traitsIcEEEE
NSt3__123__match_any_but_newlineIcEE
NSt3__120__match_char_collateIcNS_12regex_traitsIcEEEE
NSt3__118__back_ref_collateIcNS_12regex_traitsIcEEEE
NSt3__128__begin_marked_subexpressionIcEE
NSt3__126__end_marked_subexpressionIcEE
NSt3__16__loopIcEE
NSt3__117__repeat_one_loopIcEE
NSt3__121__empty_non_own_stateIcEE
N27nlv4_inference_orchestrator16inference_engine24EspressoTransformerModelE
N27nlv4_inference_orchestrator16inference_engine16TransformerModelE
048<@E_
048<@
&3ee
N4snlp3ssu5parse24SSUGraphBuilderShortcutsE
N4uaap19DateDurationHandlerE
N4uaap23AbstractDateTimeHandlerE
!4OO
N5boost10wrapexceptINS_5uuids13entropy_errorEEE
N5boost16exception_detail10clone_baseE
N4snlp6common14text_uso_graph26UsoGraphTextTreeParseErrorE
N4snlp6common14text_uso_graph21UDATextTreeParseErrorE
N4uaap8UPDDSpanE
N4uaap12UPDDTimeSpanE
N4uaap20UPDDDateTimeBaseSpanE
N4uaap11TimeHandlerE
E^^^^^^^^^K
*$-
N4snlp6common9exception18SNLPAssetExceptionE
N8nlohmann6detail9exceptionE
false
N8nlohmann6detail12out_of_rangeE
NSt3__117bad_function_callE
N8nlohmann6detail16invalid_iteratorE
N8nlohmann6detail10type_errorE
N8nlohmann6detail11parse_errorE
>IT_ju
 "$&(*,.02468N4uaap12UPDDDateSpanE
N4uaap20UPDDAbsoluteDateSpanE
N4uaap15DateSpanHandlerE
N4siri8ontology28UsoGraphProtoWriterExceptionE
N4siri8ontology21OntologyBaseExceptionE
N4siri8ontology17OntologyExceptionE
N4uaap11DateHandlerE
N4snlp6common9exception13SNLPExceptionE
N27itfm_inference_orchestrator13orchestration16ITFMOrchestratorE
NSt3__120__shared_ptr_emplaceIN27itfm_inference_orchestrator10vocabulary10VocabularyENS_9allocatorIS3_EEEE
N27snlc_inference_orchestrator13orchestration16SNLCOrchestratorE
NSt3__120__shared_ptr_emplaceINS_4__fs10filesystem16filesystem_error8_StorageENS_9allocatorIS4_EEEE
vH7B
W4vC
9Y>)F$
raB3G
)c=H
]rHa
O8Mr
bnMG
.wN9
[*QmU
mr"iR
R$N(
>S}W
-sSO\
T%L9
hGT.
B}T}
=@[V
!a9X
X5AHx
%4xY
Z~$|7
+\0I
2a\|
\ysK
|M$D
pH_r
(:W"
s\ax}?
pc2g
@BXV
tC7Ddx
EydV
d66
eax~Z
ekhHD
@iZb
k0V(
k*do^
:V!2m
RJqn
bzo=
$qE}
XqkY
quAt
Jugm
~B v
STv/N
_w&2
xg^Jp5|
yMzw
{zel#|67
P/};
[@JO
nQ:B
N4snlp6common14text_uso_graph20ExactMatchComparatorE
N4snlp6common14text_uso_graph18UsoGraphComparatorE
N4snlp6common14text_uso_graph16ActionListParserE
N4snlp6common14text_uso_graph14TextTreeParserE
N27itfm_inference_orchestrator16inference_engine10ITFMModuleE
N4uaap25UPDDTimeSpanWithReferenceE
N4uaap28TimeSpanWithReferenceHandlerE
N4snlp6common14text_uso_graph22UsoGraphTextTreeParserE
N4siri8ontology17IsNameTypeVisitorINS0_16OntologyNodeNameEEE
N4siri8ontology16NoOpONameVisitorE
N4siri8ontology19OntologyNameVisitorE
N4siri8ontology17IsNameTypeVisitorINS0_16OntologyVerbNameEEE
N4siri8ontology17IsNameTypeVisitorINS0_16OntologyEdgeNameEEE
N4snlp3ssu5cache18CacheFileExceptionE
N5boost7archive13text_iarchiveE
N5boost7archive21basic_text_iprimitiveINSt3__113basic_istreamIcNS2_11char_traitsIcEEEEEE
N5boost7archive6detail15common_iarchiveINS0_13text_iarchiveEEE
N5boost7archive6detail18interface_iarchiveINS0_13text_iarchiveEEE
N5boost7archive15binary_iarchiveE
N5boost7archive23basic_binary_iprimitiveINS0_15binary_iarchiveEcNSt3__111char_traitsIcEEEE
N5boost7archive6detail15common_iarchiveINS0_15binary_iarchiveEEE
N5boost7archive6detail18interface_iarchiveINS0_15binary_iarchiveEEE
N5boost13serialization6detail17singleton_wrapperINS0_25extended_type_info_typeidIN4snlp3ssu5cache20SSUCacheObjectHeaderEEEEE
N5boost13serialization25extended_type_info_typeidIN4snlp3ssu5cache20SSUCacheObjectHeaderEEE
N5boost13serialization9singletonINS0_25extended_type_info_typeidIN4snlp3ssu5cache20SSUCacheObjectHeaderEEEEE
N4snlp3ssu5cache20SSUCacheObjectHeaderE
N5boost13serialization6detail17singleton_wrapperINS_7archive6detail11iserializerINS3_15binary_iarchiveEN4snlp3ssu5cache20SSUCacheObjectHeaderEEEEE
N5boost7archive6detail11iserializerINS0_15binary_iarchiveEN4snlp3ssu5cache20SSUCacheObjectHeaderEEE
N5boost13serialization6detail17singleton_wrapperINS_7archive6detail11iserializerINS3_13text_iarchiveEN4snlp3ssu5cache20SSUCacheObjectHeaderEEEEE
N5boost7archive6detail11iserializerINS0_13text_iarchiveEN4snlp3ssu5cache20SSUCacheObjectHeaderEEE
N5boost13serialization6detail17singleton_wrapperINS0_25extended_type_info_typeidIN4snlp3ssu5cache25SSUCacheObjectIntentNamesEEEEE
N5boost13serialization25extended_type_info_typeidIN4snlp3ssu5cache25SSUCacheObjectIntentNamesEEE
N5boost13serialization9singletonINS0_25extended_type_info_typeidIN4snlp3ssu5cache25SSUCacheObjectIntentNamesEEEEE
N4snlp3ssu5cache25SSUCacheObjectIntentNamesE
N5boost13serialization6detail17singleton_wrapperINS0_25extended_type_info_typeidINSt3__16vectorINS4_12basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEENS9_ISB_EEEEEEEE
N5boost13serialization25extended_type_info_typeidINSt3__16vectorINS2_12basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEENS7_IS9_EEEEEE
N5boost13serialization9singletonINS0_25extended_type_info_typeidINSt3__16vectorINS3_12basic_stringIcNS3_11char_traitsIcEENS3_9allocatorIcEEEENS8_ISA_EEEEEEEE
NSt3__16vectorINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS4_IS6_EEEE
N5boost13serialization6detail17singleton_wrapperINS_7archive6detail11iserializerINS3_15binary_iarchiveENSt3__16vectorINS7_12basic_stringIcNS7_11char_traitsIcEENS7_9allocatorIcEEEENSC_ISE_EEEEEEEE
N5boost7archive6detail11iserializerINS0_15binary_iarchiveENSt3__16vectorINS4_12basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEENS9_ISB_EEEEEE
N5boost13serialization6detail17singleton_wrapperINS_7archive6detail11iserializerINS3_15binary_iarchiveEN4snlp3ssu5cache25SSUCacheObjectIntentNamesEEEEE
N5boost7archive6detail11iserializerINS0_15binary_iarchiveEN4snlp3ssu5cache25SSUCacheObjectIntentNamesEEE
N5boost13serialization6detail17singleton_wrapperINS_7archive6detail11iserializerINS3_13text_iarchiveENSt3__16vectorINS7_12basic_stringIcNS7_11char_traitsIcEENS7_9allocatorIcEEEENSC_ISE_EEEEEEEE
N5boost7archive6detail11iserializerINS0_13text_iarchiveENSt3__16vectorINS4_12basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEENS9_ISB_EEEEEE
N5boost13serialization6detail17singleton_wrapperINS_7archive6detail11iserializerINS3_13text_iarchiveEN4snlp3ssu5cache25SSUCacheObjectIntentNamesEEEEE
N5boost7archive6detail11iserializerINS0_13text_iarchiveEN4snlp3ssu5cache25SSUCacheObjectIntentNamesEEE
N5boost13serialization6detail17singleton_wrapperINS0_25extended_type_info_typeidIN4snlp3ssu5cache36SSUCacheObjectEncodingsBatchNegativeEEEEE
N5boost13serialization25extended_type_info_typeidIN4snlp3ssu5cache36SSUCacheObjectEncodingsBatchNegativeEEE
N5boost13serialization9singletonINS0_25extended_type_info_typeidIN4snlp3ssu5cache36SSUCacheObjectEncodingsBatchNegativeEEEEE
N4snlp3ssu5cache36SSUCacheObjectEncodingsBatchNegativeE
N5boost13serialization6detail17singleton_wrapperINS0_25extended_type_info_typeidINSt3__16vectorImNS4_9allocatorImEEEEEEEE
N5boost13serialization25extended_type_info_typeidINSt3__16vectorImNS2_9allocatorImEEEEEE
N5boost13serialization9singletonINS0_25extended_type_info_typeidINSt3__16vectorImNS3_9allocatorImEEEEEEEE
NSt3__16vectorImNS_9allocatorImEEEE
N5boost13serialization6detail17singleton_wrapperINS_7archive6detail11iserializerINS3_15binary_iarchiveENSt3__16vectorImNS7_9allocatorImEEEEEEEE
N5boost7archive6detail11iserializerINS0_15binary_iarchiveENSt3__16vectorImNS4_9allocatorImEEEEEE
N5boost13serialization6detail17singleton_wrapperINS0_25extended_type_info_typeidINSt3__16vectorIfNS4_9allocatorIfEEEEEEEE
N5boost13serialization25extended_type_info_typeidINSt3__16vectorIfNS2_9allocatorIfEEEEEE
N5boost13serialization9singletonINS0_25extended_type_info_typeidINSt3__16vectorIfNS3_9allocatorIfEEEEEEEE
NSt3__16vectorIfNS_9allocatorIfEEEE
N5boost13serialization6detail17singleton_wrapperINS_7archive6detail11iserializerINS3_15binary_iarchiveENSt3__16vectorIfNS7_9allocatorIfEEEEEEEE
N5boost7archive6detail11iserializerINS0_15binary_iarchiveENSt3__16vectorIfNS4_9allocatorIfEEEEEE
N5boost13serialization6detail17singleton_wrapperINS_7archive6detail11iserializerINS3_15binary_iarchiveEN4snlp3ssu5cache36SSUCacheObjectEncodingsBatchNegativeEEEEE
N5boost7archive6detail11iserializerINS0_15binary_iarchiveEN4snlp3ssu5cache36SSUCacheObjectEncodingsBatchNegativeEEE
N5boost13serialization6detail17singleton_wrapperINS_7archive6detail11iserializerINS3_13text_iarchiveENSt3__16vectorImNS7_9allocatorImEEEEEEEE
N5boost7archive6detail11iserializerINS0_13text_iarchiveENSt3__16vectorImNS4_9allocatorImEEEEEE
N5boost13serialization6detail17singleton_wrapperINS_7archive6detail11iserializerINS3_13text_iarchiveENSt3__16vectorIfNS7_9allocatorIfEEEEEEEE
N5boost7archive6detail11iserializerINS0_13text_iarchiveENSt3__16vectorIfNS4_9allocatorIfEEEEEE
N5boost13serialization6detail17singleton_wrapperINS_7archive6detail11iserializerINS3_13text_iarchiveEN4snlp3ssu5cache36SSUCacheObjectEncodingsBatchNegativeEEEEE
N5boost7archive6detail11iserializerINS0_13text_iarchiveEN4snlp3ssu5cache36SSUCacheObjectEncodingsBatchNegativeEEE
N5boost13serialization6detail17singleton_wrapperINS0_25extended_type_info_typeidIN4snlp3ssu5cache36SSUCacheObjectEncodingsBatchPositiveEEEEE
N5boost13serialization25extended_type_info_typeidIN4snlp3ssu5cache36SSUCacheObjectEncodingsBatchPositiveEEE
N5boost13serialization9singletonINS0_25extended_type_info_typeidIN4snlp3ssu5cache36SSUCacheObjectEncodingsBatchPositiveEEEEE
N4snlp3ssu5cache36SSUCacheObjectEncodingsBatchPositiveE
N5boost13serialization6detail17singleton_wrapperINS_7archive6detail11iserializerINS3_15binary_iarchiveEN4snlp3ssu5cache36SSUCacheObjectEncodingsBatchPositiveEEEEE
N5boost7archive6detail11iserializerINS0_15binary_iarchiveEN4snlp3ssu5cache36SSUCacheObjectEncodingsBatchPositiveEEE
N5boost13serialization6detail17singleton_wrapperINS_7archive6detail11iserializerINS3_13text_iarchiveEN4snlp3ssu5cache36SSUCacheObjectEncodingsBatchPositiveEEEEE
N5boost7archive6detail11iserializerINS0_13text_iarchiveEN4snlp3ssu5cache36SSUCacheObjectEncodingsBatchPositiveEEE
N4snlp3ssu7trigger16SSUTriggerAlwaysE
N4snlp3ssu7trigger10SSUTriggerE
N4snlp6common18espresso_inference8pre_e5ml14EspressoModuleE
N4snlp3ssu7trigger18SSUTriggerOnScreenE
N4uaap20UPDDTimeDurationSpanE
N4uaap19TimeDurationHandlerE
N4uaap16UPDDDateTimeSpanE
N4uaap15DateTimeHandlerE
N4uaap25UPDDDateSpanWithReferenceE
N4uaap28DateSpanWithReferenceHandlerE
N4uaap25UPDDSpecialDatePeriodSpanE
N4uaap18UPDDDateOffsetSpanE
N4siri8ontology16OntologyUnitNameE
N5boost5uuids13entropy_errorE
N5boost9exceptionE
NSt3__16__nodeIcEE
NSt3__110shared_ptrINS_13__empty_stateIcEEE27__shared_ptr_default_deleteIS2_S2_EE
NSt3__114default_deleteINS_13__empty_stateIcEEEE
NSt3__116__owns_one_stateIcEE
NSt3__115__has_one_stateIcEE
NSt3__118__match_char_icaseIcNS_12regex_traitsIcEEEE
NSt3__112__match_charIcEE
NSt3__116__back_ref_icaseIcNS_12regex_traitsIcEEEE
NSt3__110__back_refIcEE
NSt3__120__bracket_expressionIcNS_12regex_traitsIcEEEE
NSt3__117__owns_two_statesIcEE
NSt3__111__alternateIcEE
NSt3__111__match_anyIcEE
N27nlv4_inference_orchestrator16inference_engine17BertPreE5MLModuleE
N27nlv4_inference_orchestrator16inference_engine24TransformerEncoderModuleE
N27nlv4_inference_orchestrator16inference_engine24TransformerDecoderModuleE
N27nlv4_inference_orchestrator16inference_engine22BertModuleLoadingErrorE
N27nlv4_inference_orchestrator16inference_engine10BertModuleE
N4siri8ontology12UsoGraphNodeE
N27nlv4_inference_orchestrator16inference_engine17EspressoBertModelE
N27nlv4_inference_orchestrator13span_matching36RelativeThresholdMatchingSpansFilterE
N27nlv4_inference_orchestrator13span_matching19MatchingSpansFilterE
N4uaap15TimeSpanHandlerE
N27nlv4_inference_orchestrator16inference_engine21BertModelLoadingErrorE
N26psc_inference_orchestrator13orchestration15PSCOrchestratorE
04<@8E_
04<@8
VZ^bfk
VZ^bf
?N5boost7archive13text_oarchiveE
N5boost7archive21basic_text_oprimitiveINSt3__113basic_ostreamIcNS2_11char_traitsIcEEEEEE
N5boost7archive6detail15common_oarchiveINS0_13text_oarchiveEEE
N5boost7archive6detail18interface_oarchiveINS0_13text_oarchiveEEE
N5boost7archive15binary_oarchiveE
N5boost7archive23basic_binary_oprimitiveINS0_15binary_oarchiveEcNSt3__111char_traitsIcEEEE
N5boost7archive6detail15common_oarchiveINS0_15binary_oarchiveEEE
N5boost7archive6detail18interface_oarchiveINS0_15binary_oarchiveEEE
N5boost13serialization6detail17singleton_wrapperINS_7archive6detail11oserializerINS3_15binary_oarchiveEN4snlp3ssu5cache20SSUCacheObjectHeaderEEEEE
N5boost7archive6detail11oserializerINS0_15binary_oarchiveEN4snlp3ssu5cache20SSUCacheObjectHeaderEEE
N5boost13serialization6detail17singleton_wrapperINS_7archive6detail11oserializerINS3_13text_oarchiveEN4snlp3ssu5cache20SSUCacheObjectHeaderEEEEE
N5boost7archive6detail11oserializerINS0_13text_oarchiveEN4snlp3ssu5cache20SSUCacheObjectHeaderEEE
N5boost13serialization6detail17singleton_wrapperINS_7archive6detail11oserializerINS3_15binary_oarchiveENSt3__16vectorINS7_12basic_stringIcNS7_11char_traitsIcEENS7_9allocatorIcEEEENSC_ISE_EEEEEEEE
N5boost7archive6detail11oserializerINS0_15binary_oarchiveENSt3__16vectorINS4_12basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEENS9_ISB_EEEEEE
N5boost13serialization6detail17singleton_wrapperINS_7archive6detail11oserializerINS3_15binary_oarchiveEN4snlp3ssu5cache25SSUCacheObjectIntentNamesEEEEE
N5boost7archive6detail11oserializerINS0_15binary_oarchiveEN4snlp3ssu5cache25SSUCacheObjectIntentNamesEEE
N5boost13serialization6detail17singleton_wrapperINS_7archive6detail11oserializerINS3_13text_oarchiveENSt3__16vectorINS7_12basic_stringIcNS7_11char_traitsIcEENS7_9allocatorIcEEEENSC_ISE_EEEEEEEE
N5boost7archive6detail11oserializerINS0_13text_oarchiveENSt3__16vectorINS4_12basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEENS9_ISB_EEEEEE
N5boost13serialization6detail17singleton_wrapperINS_7archive6detail11oserializerINS3_13text_oarchiveEN4snlp3ssu5cache25SSUCacheObjectIntentNamesEEEEE
N5boost7archive6detail11oserializerINS0_13text_oarchiveEN4snlp3ssu5cache25SSUCacheObjectIntentNamesEEE
N5boost13serialization6detail17singleton_wrapperINS_7archive6detail11oserializerINS3_15binary_oarchiveENSt3__16vectorImNS7_9allocatorImEEEEEEEE
N5boost7archive6detail11oserializerINS0_15binary_oarchiveENSt3__16vectorImNS4_9allocatorImEEEEEE
N5boost13serialization6detail17singleton_wrapperINS_7archive6detail11oserializerINS3_15binary_oarchiveENSt3__16vectorIfNS7_9allocatorIfEEEEEEEE
N5boost7archive6detail11oserializerINS0_15binary_oarchiveENSt3__16vectorIfNS4_9allocatorIfEEEEEE
N5boost13serialization6detail17singleton_wrapperINS_7archive6detail11oserializerINS3_15binary_oarchiveEN4snlp3ssu5cache36SSUCacheObjectEncodingsBatchNegativeEEEEE
N5boost7archive6detail11oserializerINS0_15binary_oarchiveEN4snlp3ssu5cache36SSUCacheObjectEncodingsBatchNegativeEEE
N5boost13serialization6detail17singleton_wrapperINS_7archive6detail11oserializerINS3_13text_oarchiveENSt3__16vectorImNS7_9allocatorImEEEEEEEE
N5boost7archive6detail11oserializerINS0_13text_oarchiveENSt3__16vectorImNS4_9allocatorImEEEEEE
N5boost13serialization6detail17singleton_wrapperINS_7archive6detail11oserializerINS3_13text_oarchiveENSt3__16vectorIfNS7_9allocatorIfEEEEEEEE
N5boost7archive6detail11oserializerINS0_13text_oarchiveENSt3__16vectorIfNS4_9allocatorIfEEEEEE
N5boost13serialization6detail17singleton_wrapperINS_7archive6detail11oserializerINS3_13text_oarchiveEN4snlp3ssu5cache36SSUCacheObjectEncodingsBatchNegativeEEEEE
N5boost7archive6detail11oserializerINS0_13text_oarchiveEN4snlp3ssu5cache36SSUCacheObjectEncodingsBatchNegativeEEE
N5boost13serialization6detail17singleton_wrapperINS_7archive6detail11oserializerINS3_15binary_oarchiveEN4snlp3ssu5cache36SSUCacheObjectEncodingsBatchPositiveEEEEE
N5boost7archive6detail11oserializerINS0_15binary_oarchiveEN4snlp3ssu5cache36SSUCacheObjectEncodingsBatchPositiveEEE
N5boost13serialization6detail17singleton_wrapperINS_7archive6detail11oserializerINS3_13text_oarchiveEN4snlp3ssu5cache36SSUCacheObjectEncodingsBatchPositiveEEEEE
N5boost7archive6detail11oserializerINS0_13text_oarchiveEN4snlp3ssu5cache36SSUCacheObjectEncodingsBatchPositiveEEE
N4snlp3ssu7trigger17SSUTriggerAppNameE
N4snlp6common14text_uso_graph19SpacedTextTreeLexerE
N4snlp6common14text_uso_graph13TextTreeLexerE
048<@E_
048<@_
048<@E_
048<@_
048<@E_
048<@
ptx|
ptx|
UY]ae
UY]ae
N4snlp6common14text_uso_graph17UDATextTreeParserE
N13sentencepiece3bpe5ModelE
N13sentencepiece5model8FreeListIZNKS_3bpe5Model12SampleEncodeEN4absl11string_viewEfE10SymbolPairEE
NSt3__110__function6__funcIZNK13sentencepiece3bpe5Model12SampleEncodeEN4absl11string_viewEfE3$_2NS_9allocatorIS7_EEFvS6_PNS_6vectorINS_4pairIS6_iEENS8_ISC_EEEEEEE
NSt3__110__function6__baseIFvN4absl11string_viewEPNS_6vectorINS_4pairIS3_iEENS_9allocatorIS6_EEEEEEE
ZNK13sentencepiece3bpe5Model12SampleEncodeEN4absl11string_viewEfE3$_2
)6N13sentencepiece31SentencePieceText_SentencePieceE
N13sentencepiece17SentencePieceTextE
N13sentencepiece22NBestSentencePieceTextE
2DSe
N13sentencepiece11TrainerSpecE
N13sentencepiece14NormalizerSpecE
N13sentencepiece19SelfTestData_SampleE
N13sentencepiece12SelfTestDataE
N13sentencepiece24ModelProto_SentencePieceE
N13sentencepiece10ModelProtoE
N6google8protobuf8internal16InternalMetadata9ContainerINSt3__112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEEEE
N6google8protobuf8internal16InternalMetadata13ContainerBaseE
N13sentencepiece9character5ModelE
N13sentencepiece10filesystem17PosixReadableFileE
N13sentencepiece10filesystem12ReadableFileE
-03N13sentencepiece14ModelInterfaceE
N13sentencepiece10normalizer10NormalizerE
N5Darts15DoubleArrayImplIvvivEE
N5Darts7Details9ExceptionE
N13sentencepiece22SentencePieceProcessorE
$1XX
CQIN13sentencepiece7unigram5ModelE
N13sentencepiece7unigram7LatticeE
N13sentencepiece5model8FreeListINS_7unigram7Lattice4NodeEEE
N13sentencepiece5model8FreeListIZNS_7unigram7Lattice5NBestEmE10HypothesisEE
N13sentencepiece4word5ModelE
N6google8protobuf14FatalExceptionE
+8ER_l
/3N6google8protobuf8internal15ExtensionFinderE
N6google8protobuf8internal24GeneratedExtensionFinderE
N6google8protobuf8internal12ExtensionSet8KeyValueE
N6google8protobuf13RepeatedFieldIiEE
N6google8protobuf13RepeatedFieldIxEE
N6google8protobuf13RepeatedFieldIjEE
N6google8protobuf13RepeatedFieldIyEE
N6google8protobuf13RepeatedFieldIfEE
N6google8protobuf13RepeatedFieldIdEE
N6google8protobuf13RepeatedFieldIbEE
N6google8protobuf16RepeatedPtrFieldINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEEE
N6google8protobuf8internal20RepeatedPtrFieldBaseE
N6google8protobuf16RepeatedPtrFieldINS0_11MessageLiteEEE
NSt3__13mapIiN6google8protobuf8internal12ExtensionSet9ExtensionENS_4lessIiEENS_9allocatorINS_4pairIKiS5_EEEEEE
N6google8protobuf11MessageLiteE
NSt3__112basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEE
30SentencepieceModelLoadingError
$=IUaz
$=IUaz
N5boost7archive17archive_exceptionE
N5boost7archive6detail14basic_iarchiveE
N5boost12noncopyable_11noncopyableE
N5boost12noncopyable_10base_tokenE
N5boost7archive6detail17helper_collectionE
N5boost7archive6detail17basic_iserializerE
N5boost7archive6detail16basic_serializerE
N5boost7archive6detail14basic_oarchiveE
N5boost7archive6detail17basic_oserializerE
?456789:;<=
 !"#$%&'()*+,-./0123
N5boost7archive9iterators18dataflow_exceptionE
N5boost7archive20binary_iarchive_implINS0_15binary_iarchiveEcNSt3__111char_traitsIcEEEE
N5boost7archive21basic_binary_iarchiveINS0_15binary_iarchiveEEE
N5boost7archive12codecvt_nullIcEE
N5boost7archive20binary_oarchive_implINS0_15binary_oarchiveEcNSt3__111char_traitsIcEEEE
N5boost7archive21basic_binary_oarchiveINS0_15binary_oarchiveEEE
N5boost13serialization18extended_type_infoE
N5boost13serialization6detail22extended_type_info_argE
N5boost13serialization13typeid_system27extended_type_info_typeid_0E
N5boost13serialization13typeid_system29extended_type_info_typeid_argE
N5boost7archive19basic_text_iarchiveINS0_13text_iarchiveEEE
N5boost7archive18text_iarchive_implINS0_13text_iarchiveEEE
N5boost7archive19basic_text_oarchiveINS0_13text_oarchiveEEE
N5boost7archive18text_oarchive_implINS0_13text_oarchiveEEE
N16nl_featurization14FeaturizerImplE
N16nl_featurization18AbstractFeaturizerE
:F?G
(x
(x
L\
$`
$`
$`
$`
$`
$`
$`
$`
FlatBuffers 2.0.0
item_id
basic_string
TreeManipulation_OneShotReplyRemodeller
UserAccepted
UserStatedTask
vector
component_name
SNLPLanguageVariantClassifierErrorDomain
LVC/LVC.mlmodelc/model.espresso.net
LVC/spans_pad.txt
LVC/context_pad.txt
LVC/targets.txt
An error occured reading LVC model bundle at: %@
Check that the path contains a valid model bundle: %@
SiriNaturalLanguageParsing
SNLPFeatureStoreEnabled
SNLPMessageContentRuleEnabled
SNLPWireAudioAccessoryMemory
SNLPSalientEntityFeaturizationEnabled
old_prediction
hidden
memory
encodings
num_of_utterance_tokens
attention_index
out_predictions
out_new_hidden
out_new_memory
out_new_attention_index
.nlu.lzfse
.nlu
.version
The request locale does not match the SSUFile locale
Unrecognized asset directory format version: 
Asset directory touch version file not present when expected for: 
Asset directory does not exist or is not a directory: 
-[UPContextualizerStrategyPrompt resultUsingContextualizerInput:]
UPContextualizerStrategyPrompt.m
[dialogAct isKindOfClass:[UPDialogActPrompt class]]
version.yaml
config.json
^VERSION: (\d+)\.(\d+)\.(\d+)
Version file not found at path: 
Version file has no parseable version key: 
%02x
bolt_task_id
NLv4
SNLC
UaaP
UNKNOWN
<UNDEFINED_COMPONENT>
-[UPContextualizerStrategyOffer resultUsingContextualizerInput:]
UPContextualizerStrategyOffer.m
[contextualizerInput.dialogAct isKindOfClass:[UPDialogActOffer class]]
Could not build an SNLPSSUMatcherDirectories object
The given directory is not a file URL: %@.
SNLPITFMErrorDomain
Missing resource: %@
Check that resource is available: %@
target
common_Message
stringContent
primitive_String
common_Announcement
content
[UNK]
[PAD]
[CLS]
[SEP]
Could not open vocabulary data file: 
tokenText argument is empty
Encountered unknown token text and the vocabulary hasno special unknown token
Encountered unknown token ID
[NO_SDAS]
[NO_LEGACY_NL_CONTEXT_LABEL]
DICTATION_PROMPT=
STRICT_PROMPT=
PREVIOUS_NLV3_DOMAIN=
TRUE
FALSE
[insights-snlp-nlv4]: 
[insights-snlp-snlc]: 
[insights-snlp-uaap]: 
[insights-snlp-owl]: 
[insights-snlp-psc]: 
[insights-snlp-lvc]: 
[insights-snlp-ssu]: 
[insights-snlp-<UNDEFINED_COMPONENT>]: 
shape = 
 data = 
Shortcuts
semantic_value
Searching for span with UTF-16 indices (
common_Date
common_Timer
Found matching span with graph:
) vs (
Found a matching insertable span 
Found a new max score, 
, for a non-matching insertable span 
Found a common_Time span with a Jaccard score of 
, overwriting the common_Date span with a Jaccard score of 
UPDialogActPrompt[intent: %@, entityType: %@, entityName: %@, reference: %@]
span_indices
token_embeddings
intent_softmax
app_label_softmax
bio_labels_softmax
group_labels_softmax
Espresso context is nil.
Espresso plan is nil.
Could not create espresso plan.
Failed to build espresso plan.
Failed to execute espresso plan.
Failed to clean up espresso plan.
Failed to reshape espresso blob.
Failed to bind buffer to input 
Failed to bind buffer to output 
SSU only supports a single category at this time.
SSU only supports a single category group in the category at this time.
App shortcut is only supported category type: rdar://101955859
Category at index 
 is out of bounds
Category group at index 
 is out of bounds for category index 
Category Index is out of bounds
Locale not supported by assets directory: 
Unable to open file: 
Unable to gather stats on file
Unable to read the SSU file
/dev/urandom
open /dev/urandom
/AppleInternal/Library/BuildRoots/a1c21190-ba93-11ed-8126-ae4f7fab34c4/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator16.4.Internal.sdk/usr/local/include/boost/uuid/detail/random_provider_posix.ipp
boost::uuids::detail::random_provider_base::random_provider_base()
read
void boost::uuids::detail::random_provider_base::get_random_bytes(void *, std::size_t)
group_name_transform
smsGroupName
personFullName
TreeManipulation_GroupNameTransform
Failed to parse 
^ *"(.*)"
^ *(\d+)
^ *([a-zA-Z0-9:_]+)
^ *:([a-zA-Z0-9:_]+)
^ *\n( *)
^ */ *([a-zA-Z0-9:_]+)
^ *\[(\d+):(\d+)\]
com.apple.uaapcustomluframework
{unique_ptr<itfm_inference_orchestrator::orchestration::ITFMOrchestrator, std::default_delete<itfm_inference_orchestrator::orchestration::ITFMOrchestrator>>={__compressed_pair<itfm_inference_orchestrator::orchestration::ITFMOrchestrator *, std::default_delete<itfm_inference_orchestrator::orchestration::ITFMOrchestrator>>=^{ITFMOrchestrator}}}32@?0@"SNLPITFMModelBundle"8@"SNLPITFMModelInfo"16^@24
%@ Asset Error when creating the %@ (ITFM) inference orchestrator: %s
Hit SNLP exception while calling ITFMOrchestrator::handle for request (high=%llu, low=%llu): %s
ERROR: Could not find the config file 
INFO: The parameter 
 is null.  This is currently expected behaviour.
WARNING: Could not parse the config parameter 
[json.exception.
invalid BOM; must be 0xEF 0xBB 0xBF if given
invalid literal
invalid comment; missing closing '*/'
invalid comment; expecting '/' or '*' after '/'
invalid string: missing closing quote
invalid string: '\u' must be followed by 4 hex digits
invalid string: surrogate U+D800..U+DBFF must be followed by U+DC00..U+DFFF
invalid string: surrogate U+DC00..U+DFFF must follow U+D800..U+DBFF
invalid string: forbidden character after backslash
invalid string: control character U+0000 (NUL) must be escaped to \u0000
invalid string: control character U+0001 (SOH) must be escaped to \u0001
invalid string: control character U+0002 (STX) must be escaped to \u0002
invalid string: control character U+0003 (ETX) must be escaped to \u0003
invalid string: control character U+0004 (EOT) must be escaped to \u0004
invalid string: control character U+0005 (ENQ) must be escaped to \u0005
invalid string: control character U+0006 (ACK) must be escaped to \u0006
invalid string: control character U+0007 (BEL) must be escaped to \u0007
invalid string: control character U+0008 (BS) must be escaped to \u0008 or \b
invalid string: control character U+0009 (HT) must be escaped to \u0009 or \t
invalid string: control character U+000A (LF) must be escaped to \u000A or \n
invalid string: control character U+000B (VT) must be escaped to \u000B
invalid string: control character U+000C (FF) must be escaped to \u000C or \f
invalid string: control character U+000D (CR) must be escaped to \u000D or \r
invalid string: control character U+000E (SO) must be escaped to \u000E
invalid string: control character U+000F (SI) must be escaped to \u000F
invalid string: control character U+0010 (DLE) must be escaped to \u0010
invalid string: control character U+0011 (DC1) must be escaped to \u0011
invalid string: control character U+0012 (DC2) must be escaped to \u0012
invalid string: control character U+0013 (DC3) must be escaped to \u0013
invalid string: control character U+0014 (DC4) must be escaped to \u0014
invalid string: control character U+0015 (NAK) must be escaped to \u0015
invalid string: control character U+0016 (SYN) must be escaped to \u0016
invalid string: control character U+0017 (ETB) must be escaped to \u0017
invalid string: control character U+0018 (CAN) must be escaped to \u0018
invalid string: control character U+0019 (EM) must be escaped to \u0019
invalid string: control character U+001A (SUB) must be escaped to \u001A
invalid string: control character U+001B (ESC) must be escaped to \u001B
invalid string: control character U+001C (FS) must be escaped to \u001C
invalid string: control character U+001D (GS) must be escaped to \u001D
invalid string: control character U+001E (RS) must be escaped to \u001E
invalid string: control character U+001F (US) must be escaped to \u001F
invalid string: ill-formed UTF-8 byte
invalid number; expected digit after '-'
invalid number; expected digit after '.'
invalid number; expected '+', '-', or digit after exponent
invalid number; expected digit after exponent sign
value
object key
object separator
number overflow parsing '
array
object
excessive object size: 
cannot get value
invalid_iterator
iterator does not fit current value
iterator out of range
cannot use erase() with 
type_error
null
string
boolean
binary
discarded
number
excessive array size: 
out_of_range
<U+%.4X>
parse_error
parse error
 at line 
, column 
syntax error 
while parsing 
; last read: '
unexpected 
; expected 
<uninitialized>
true literal
false literal
null literal
string literal
number literal
<parse error>
end of input
'[', '{', or a literal
unknown token
cannot compare iterators of different containers
cannot use key() for non-object iterators
type must be number, but is 
type must be boolean, but is 
type must be string, but is 
Could not convert
semanticValue
unknownCustomEntity
unknownCustomVerb
DataDetectorService
The ITFM asset version (
) is incompatible with inference runtime (compatible versions 
ITFM Orchestrator failed with incompatible major version
Request does not contain a tokenised utterance
Request does not contain a token chain
Request does not contain embeddings
Request embeddings num tokens (
) does not match actual num tokens (
Request embeddings (
) exceeds maximum (
Received null input parser request
SystemGaveOptions
SystemOffered
executed_task
salient_entity
active_task
sdas
executed_tasks
salient_entities
active_tasks
_type=
_full_path=
_verb_entity=
_verb=
_below_verb=
_are_present
_are_absent
contact_type_split
contactType
emailType
TreeManipulation_ContactTypeSplit
nullptr
string_view::substr
cancel
notForMe
selectOrdinal
ordinal
placeholderVerb
((\w+)::common_(\w+)(\.)?(\w+))
::common
SystemPrompted
SystemOffered.offered_act.
SystemGaveOptions.option.
SystemInformed.entity
SystemReportedSuccess
SystemReportedFailure
.primitive_String
SystemOffered.offered_act.UserStatedTask
SystemOffered.offered_act.UserWantedToProceed
UserAcknowledged
UserCancelled
UserRejected
UserWantedToPause
UserWantedToProceed
UserWantedToRepeat
SystemInformed
_verb_entity
contact_address_downcast
emailAddress
phoneNumber
TreeManipulation_ContactAddressDowncaster
map::at:  key not found
min_max_labeller
minimumMaximum
floatSettingState
minimum
maximum
TreeManipulation_MinimumMaximumLabeller
de_DE
en_AU
en_CA
en_GB
en_IN
en_US
fr_FR
Error parsing JSON grammar: row.IsObject() == false [for key: 
resolution-table
 entry
semantic-value
Error parsing JSON grammar: parsedSemanticValue != row.MemberEnd() && parsedSemanticValue->value.IsString() == false [for key: 
synonyms
Error parsing JSON grammar: parsedSynonyms != row.MemberEnd() && parsedSynonyms->value.IsArray() == false [for key: 
Error parsing JSON grammar: parsedSynonym.IsString() == false [for key: 
type
Error parsing JSON grammar: parsedValueType->value.IsString() == false [for key: 
enum-choices
Error parsing JSON grammar: parsedEnumChoices->value.IsArray() == false [for key: 
open-list-choices
Error parsing JSON grammar: parsedOpenListChoices->value.IsArray() == false [for key: 
Error parsing JSON grammar: parsedResolutionTable->value.IsArray() == false [for key: 
left-label
Error parsing JSON grammar: leftLabel != jsonRule.MemberEnd() && leftLabel->value.IsString() == false [for key: 
value-constraints
Error parsing JSON grammar: parsedValueConstraints->value.IsObject() == false [for key: 
right-labels
Error parsing JSON grammar: parsedRightLabels != jsonRule.MemberEnd() && parsedRightLabels->value.IsArray() == false [for key: 
Error parsing JSON grammar: rightLabelObject.IsObject() == false [for key: 
name
Error parsing JSON grammar: parsedName != rightLabelObject.MemberEnd() && parsedName->value.IsString() == false [for key: 
repeated
Error parsing JSON grammar: parsedRepeatedFlag != rightLabelObject.MemberEnd() && parsedRepeatedFlag->value.IsBool() == false [for key: 
Could not open grammar file for reading: 
Grammar file is in error state after reading: 
Label does not exist
Error parsing JSON grammar: jsonGrammar.IsObject() == false [for key: 
(root)
rules
Error parsing JSON grammar: parsedRules != jsonGrammar.MemberEnd() && parsedRules->value.IsArray() == false [for key: 
unordered_map::at: key not found
Error parsing JSON grammar: enumChoice.IsString() == false [for key: 
Error parsing JSON grammar: openListChoice.IsString() == false [for key: 
Error parsing JSON grammar: parsedRule.IsObject() == false [for key: 
Expected:
Actual:
Badly-formed UDA
Expected a UDA of type 
 but got a 
appName
appEntity
Applications
source_tokens_embeddings
matched_spans
context
source_mask
class_probabilities
SNLPServerNLClassifierErrorDomain
SNLC/SNLC.mlmodelc/model.espresso.net
SNLC/spans_pad.txt
SNLC/context_pad.txt
An error occured reading SNLC model bundle at: %@
node=
edge=
stringValue=
integerValue=
indentation=
alias=
textAlignment=
after
approx
before
beginning
earlier
early
every
last
lastlast
late
later
middle
next
nextnext
potentialEvery
restof
same
slidinglast
this
upcoming
week
weekend
weekday
month
quarter
year
summer
winter
autumn
spring
semester
season
businessday
afternoon
bedtime
breakfast
brunch
dinner
evening
happyhour
lunch
midnight
morning
night
noon
SNLPPommesServerClassifierErrorDomain
PSC/PSC.mlmodelc/model.espresso.net
PSC/spans_pad.txt
PSC/context_pad.txt
PSC/targets.txt
confidence_threshold
An error occured reading PSC model bundle at: %@
ROOT
value=
intent=
[next]
[startPayload]
[leaf]
[endPayload]
[newGroup]
task
UserStarted
UserContinued
UserDisambiguated
UserResponded
label
directLeafNodes
validateInferenceTensor failed for tensor 
 because: actualRank (
) != expectedRank (
 because: dimension at index 
 is zero (expected=
) != expectedDimension (
 because: actualDataSize (
) != expectedDataSize (
-[UPContextualizerStrategyOptions resultUsingContextualizerInput:]
UPContextualizerStrategyOptions.m
[contextualizerInput.dialogAct isKindOfClass:[UPDialogActOptions class]]
TreeManipulation_ReplaceFromPersonRecipient
common_Person
common_PersonRelationship
fromPerson
identifyingRelationship
recipients
relationshipType
spiece.model
max_num_utterance_embeddings
utterance_tokens_embedder_emb_dim
max_num_spans_tokens
spans_pad_symbol_index
max_num_context_tokens
batch_size
UNDEFINED_COMPONENT
common_
Node 
 not found in ontology.
Verb 
Last node on the parser stack is null, but it shouldn't
Test alignment parsed but last node on parser stack is not a UsoEntityNode
Empty edge found while attaching: 
Edge not found in ontology: 
Could not attach child 
 to parent 
 with edge 
Check
Control
Convert
Create
Delete
Entity
NoVerb
PlaceholderVerb
RecipientsEventTrigger
RecipientsHiddenPeople
Reference
ReferenceControl
ReferenceDateTimeRangeTrigger
ReferenceDurationTrigger
ReferenceMeasurementTrigger
ReferenceNumberTrigger
ReferencePaymentSortKey
ReferencePhotoCollection
ReferencePhotoCollectionFilter
ReferencePhotoFilter
ReferencePhotoMemoryFilter
ReferencePhotoTag
ReferenceProfile
ReferenceSelect
ReferenceSlideshowFilter
ReferenceStringTrigger
ReferenceTarget
ReferenceTargetSelect
ReferenceTrigger
ReferenceVideoFilter
Request
StockSummarise
Summarise
Target
Update
Token indices out of range: [
Unknown LabelScheme observed
Cannot read SSU cache file with unrecognized version: 
Boost serialization exception: 
I/O stream exception: 
Corrupted SSU cache file: invalid terminator after last negative batch
Corrupted SSU cache file: invalid terminator after last positive batch
Could not deserialise espresso context.
Could not set up espresso network. Got error status: 
not_found
ERROR: Could not find network configuration: 
Note that only parameters of unsigned integer type are currently expected by SiriNaturalLanguageParsing.  This issue will likely cause SiriNaturalLanguageParsing to fail.
Could not build a graph builder for unhandled category: %u
Failed to convert CFString to C++ string
bert_embeddings_requires_subword_embeddings
bert/embeddings/requires_subword_embeddings
feature_pooling_mask
bert_feature_extraction_output
bert/feature_extraction_output
bert_feature_extraction_output_subword
bert/feature_extraction_output_subword
bert_sentence_features
bert/sentence_features
input_ids
input_mask
hello
world
hello world
genericConfirmation
zh_CN
yue_CN
APP_SHORTCUT
USER_SHORTCUT
APP_UI
SOCIAL
DateTime
BeginTime
EndTime
Hours
Meridian
Minutes
MinutesBefore
Seconds
SpecialTimePeriod
Time
TimeDuration
TimeOffset
TimeSpan
TimeSpanReference
TimeSpanWithReference
AbsoluteDate
PartialDate
Date
DateDuration
DateOffset
DateSpan
DateSpanReference
DateSpanWithReference
DateTimeQualifier
DayNumber
DayOfNextWeek
DayOfThisWeek
DayOfWeek
MonthNumber
OccurrenceCount
OrdinalCount
RelativeDay
RelativeDayOfWeek
SpecialDatePeriod
SpecialDatePeriodUnit
SpecialDay
Identifier
YearNumber
B16@?0@"UPResultCandidate"8
+[UPContextualizerUtilities buildPayloadResultFromQuery:modelIdentifier:intent:entityName:serializer:]
UPContextualizerUtilities.m
utterance != nil
batch
candidate
SDA_MessagePayload_Prompt_Override
SDA_IntercomPayload_Prompt_Override
LegacyNLContext_DictationPrompt_Presence_Override
Token overflow; received 
 tokens, expected 
 or fewer tokens.
Could not open file path
FilePath
Given UTF-16 offset is not a Unicode scalar (code point) boundary: 
 000000000000
Input string is not a valid UTF-8 sequence! UTF-8 offset: 
Given UTF-16 offset exceeds the input string: 
Server
Device
Not_Pommes
Pommes
Failed to find the string representation of the SNLC output class: 
Failed to find the string representation of the PSC output class: 
relative_set_number_verb
setNumber
common_Setting
TreeManipulation_SetNumber_VerbReplacement
unknown/
Component: 
Version: SNLPVersionInfo[train=
, majorVersion=
, minorVersion=
Bolt task ID: 
Bolt task ID: <missing>
No assets provided
Combined Hash: 
asset could not be read
protobuf message is missing a start/end index
Invalid span: start token index (%u) >= end token index (%u)
Warning: discarding data detector matching span not aligned with non-whitespace tokens (%u -> %u)
{UPSpan range: %@ ; type: %lu ; category: %@}
TreeManipulation_DefaultValueMediaPlaybackSpeed
context_vocab.txt
multicardinal_vocab.txt
spans_vocab.txt
trg_vocab.txt
span_label_mapping.txt
SystemPrompted_Send_MessageContent
SystemPrompted_Send_MessageContent_With_NLv4_Model_Hypotheses
SDA_Placeholder_Verb_Replacement
SystemPrompted_AnnouncementContent
The NLv4 asset version (
NLv4InferenceOrchestrator setup is broken; erroneous assets were provided
NLv4 request is null
PlaceholderVerb_placeholderVerb
NLv4 request missing request ID
NLv4 request missing valid embeddings
NLv4 request missing valid tokens
NLv4 request missing valid token chain locale
NLv4 request embeddings num tokens (
The NLv4 model config does not contain a setting for the maximum number of matching spans, max_num_spans_tokens.  Inference cannot continue.
SystemPrompted.task.send::common_Message.target.common_Message.stringContent
SystemPrompted.task.send::common_Announcement.target.common_Announcement.content
time
date
common_Time
common_Time12HourClock
common_Time24HourClock
common_Integer
integerValue
denominatorValue
numeratorValue
wholeValue
decoder.mlmodelc/model.espresso.net
encoder.mlmodelc/model.espresso.net
decoder.mlmodelc/model.mil
encoder.mlmodelc/model.mil
encoder.mlmodelc/model.bundle/universal.bundle/universal.e5
decoder.mlmodelc/model.bundle/universal.bundle/universal.e5
encoder.mlmodelc/model.bundle/universal.bundle/main/segment_0__cpu/model.espresso.net
decoder.mlmodelc/model.bundle/universal.bundle/main/segment_0__cpu/model.espresso.net
common_UserEntity.associatedUserEntities
common_Setting.name
common_Timer.attributes
common_UserEntity.names
common_DateTime.time
common_Message.recipients
userEntities
common_PhoneCall.recipients
common_Message.attachments
common_PhoneCall.attributes
common_Message.attributes
common_Person.name
common_Measurement.components
common_RecurringDateTime.recurrenceDateTimes
common_Announcement.recipients
common_Alarm.attributes
common_Message.participants
modified_TranslationSourceLocale
common_Translation
sourceString
common_LocalisedString
locale
common_Locale
modified_TranslationPayload
stringValue
modified_TranslationReferenceType
usoReferenceType
modified_TranslationTargetLocale
targetString
modified_GeographicAreaName
geographicArea
common_GeographicArea
modified_GeographicAreaType
areaType
User dialog act node has multiple children.
common_Message.Target_send
common_Announcement.Target_send
UPEntityWithValue[entityType: %@, entityName: %@, entityValue:%@]
UPDialogActOffer[intent: %@, entityWithValue: %@]
max_seq_length
DataDetector
PlumMatcher
UserVocabMatcher
SingleTrieMatcher
ContextMatcher
OvertonMatcher
MRRDetector
MRRMatcher
RegexSpanMatcher
personRelationship
phoneType
context_pad_symbol_index
start_symbol_index
end_symbol_index
model.espresso.net
model.bundle/universal.bundle/universal.e5
model.bundle/universal.bundle/main/segment_0__cpu/model.espresso.net
Could not find v1 espresso assets for OWL.
Feature mask rank unset for SubOwl model.
coffee
DATE_TIME
Could not create scanner from cache file: "
".  
utterance_tokens_embeddings
padding_mask
span_tokens
position_ids
out_init_decoder_hidden
out_encodings
addresses_
.cache
date_time_
addresses.cache
date_time.cache
flights.cache
currencies.cache
numbers.cache
phone_mobile.cache
[CLS_SPAN]
[SEP_SPAN]
[NO_SPAN]
model_info.plist
info.plist
intent.vocab.txt
bio_labels.vocab.txt
span.vocab.txt
grammar.json
model.mlmodelc
calibration_model.mlmodelc
SDA_Intercom_Payload_Prompt_Override
 => 
cache_directory_format_version.v1.touch
locales
temporary
.ssu_cache_file_in_progress
.ssu_cache_file
([0-9a-f]{32})
app_bundle
true
false
Subword embeddings enabled: 
bpe.model
vocab_size
Vocab size to pre-allocate: 
hidden_size
BERT:
      pre-process 
      forward: 
      aggregate & post-process: 
      post-process: 
reformulations.txt
bert.mlmodelc
src_vocab.txt
Vocabulary special tokens not properly defined
Could not build an SNLPSSUApplicationInfo object
The given asset directory is not a file URL: %@.
[SNLPSSUApplicationInfo bundleIdentifier='%@' assetURL='%@']
Request has no token chain
Request has no embeddings
v24@?0Q8^B16
Count of nonWhitespaceTokens does not match nonWhitespaceTokenIndexes
(missing)
{Token begin=%@, end=%@, value='%@'}
[%@]
%@ => %@
{UPQuery
  utterance: %@
  tokens: %@
  embeddingsByToken:
  spans:
UPDialogActOptions[intent: %@, entityType: %@, entityName: %@, entityValues: %@]
Invalid tensor name: 
Tensor description: 
Valid options are: [
Invalid feature pooling rank: 
feature extraction output
No embeddings are associated with token "%@"
Span label shape incorrect.
Given coordinates do not match tensor shape
Coordinates exceed bounds of tensor
com.apple.sirinaturallanguageparsing
v8@?0
General
Common
UPDataDetectors
SiriNaturalLanguageParsingSignPosts
text
TreeManipulation_SetIdentityPromoter
common_Person.ReferenceTarget_setIdentity
setIdentity
phone-number
SSUMatcherDirectories[
cacheDirectoryPath=
, modelAssetsPath=
, datasetAssetsPath=
Attempting to re-insert span entity to model graph, beneath 
usoEntityInsertionPoint
SNLPNaturalLanguageParserErrorDomain
NLv4 Asset Error when creating the C++ NLv4 orchestrator: %s
Hit SNLP exception while constructing C++ orchestrator with asset directory %@: %s
Hit SNLP exception while calling NLv4InferenceOrchestrator::pbhandle for request (high=%llu, low=%llu): %s
NLv4InferenceOrchestrator::pbhandle returned nullptrfor request (high=%llu, low=%llu)
embeddingDim field missing from protobuf message
tokenIndex %u is out-of-bounds for an embedding tensor with %llu tokens
Protobuf message contains only %lu values but UPEmbedding for tokenIndex %u is being created (embeddingDim=%llu)
Protobuf message contains %lu embedding values which is not a multiple of %llu embedding dimensions
{UPEmbedding: dimension %lu}
mediaPlaybackSpeed
common_Decimal
common_Number_DefaultValue
common_Number
common_SettingValue
canonicalString
definedValue
numericValue
settings
UNKNOWN-MODEL-TYPE
[Span Token] i=
 id=
 token=
span '
' covers tokens [
common_MixedFraction
common_ListPosition
NLv4SpanResponseAsJSON
NLv4ContextResponseAsJSON
NLv4AssetVersionAsJSON
NLv4ExecutedHandcraftedRulesAsJSON
%@-ITFMSpanResponseAsJSON
%@-ITFMContextResponseAsJSON
%@-ITFMAssetVersionAsJSON
%@-ITFMExecutedHandcraftedRulesAsJSON
TreeNode[
label:'
value:'
parentArgument:'
UTF-8 code unit indices:[
UTF-16 code unit indices:[
Unicode code point indices:[
Expected a node to start at: 
Expected an edge to start at: 
Regex search failed: 
^(accepted|acknowledged|cancelled|delegated|rejected|user_stated_task|wanted_to_pause|wanted_to_proceed|wanted_to_repeat|UserAccepted|UserAcknowledged|UserCancelled|DelegatedUserDialogAct|UserRejected|UserStatedTask|UserWantedToPause|UserWantedToProceed|UserWantedToRepeat)
UDA previously defined as 
 but is being redefined as 
Expecting a valid UDA name but got 
User dialog act not yet specified
UDA not yet specified
accepted
acknowledged
cancelled
UserCanceled
delegated
DelegatedDialogAct
rejected
user_stated_task
wanted_to_pause
wanted_to_proceed
wanted_to_repeat
unknown UDA 
person_name_split
TreeManipulation_PersonNameSplit
GLOBAL
SNLPSSUErrorDomain
Could not execute SNLPSSUMatcher method on Simulator.
SNLPSSUMatcher was built targetting a Simulator.
Skip SSU functionality, or use a real device.
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/src/bpe_model.cc
(index) >= (0)
(index) < (static_cast<int>(symbols.size()))
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/src/builtin_pb/sentencepiece.pb.cc
sentencepiece.SentencePieceText.SentencePiece
sentencepiece.SentencePieceText
sentencepiece.NBestSentencePieceText
<unk>
</s>
<pad>
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/src/builtin_pb/sentencepiece_model.pb.cc
sentencepiece.TrainerSpec
sentencepiece.NormalizerSpec
sentencepiece.SelfTestData.Sample
sentencepiece.SelfTestData
sentencepiece.ModelProto.SentencePiece
sentencepiece.ModelProto
Program terminated with an unrecoverable error.
Cancelled
Unknown
Invalid argument
Deadline exceeded
Not found
Already exists
Permission denied
Unauthenticated
Failed precondition
Aborted
Out of range
Unimplemented
Internal
Unavailable
Data loss
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/src/filesystem.cc
ReadAll is not supported for stdin.
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/src/model_factory.cc
Unknown model_type: 
piece must not be empty.
 is already defined.
unk is already defined.
byte piece 
 is found although `byte_fallback` is false.
 is invalid.
unk is not defined.
there are not 256 byte pieces although `byte_fallback` is true.
<0x%02X>
SiriNaturalLanguageParsing/External_Libraries/sentencepiece/src/model_interface.h
Not implemented.
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/src/normalizer.cc
precompiled_charsmap is empty. use identity normalization.
(length) >= (0)
(norm_to_orig->size()) == (normalized->size() + 1)
Blob for normalization rule is broken.
Trie data size exceeds the input blob size.
(0) == (trie_->build(key.size(), const_cast<char **>(&key[0]), nullptr, nullptr))
SiriNaturalLanguageParsing/External_Libraries/sentencepiece/src/util.h
'result' Must be non NULL
SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/darts_clone/darts.h:703: exception: failed to resize pool: std::bad_alloc
SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/darts_clone/darts.h:1141: exception: failed to insert key: negative value
SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/darts_clone/darts.h:1143: exception: failed to insert key: zero-length key
SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/darts_clone/darts.h:1157: exception: failed to insert key: invalid null character
SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/darts_clone/darts.h:1162: exception: failed to insert key: wrong key order
SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/darts_clone/darts.h:842: exception: failed to build rank index: std::bad_alloc
SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/darts_clone/darts.h:1380: exception: failed to modify unit: too large offset
SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/darts_clone/darts.h:1726: exception: failed to build double-array: invalid null character
SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/darts_clone/darts.h:1728: exception: failed to build double-array: negative value
SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/darts_clone/darts.h:1743: exception: failed to build double-array: wrong key order
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/src/sentencepiece_processor.cc
_status.ok()
model_proto->ParseFromArray(serialized.data(), serialized.size())
LOG(
INFO
 samples did not pass the test.
Self-test failures. See LOG(INFO).
model_
Model is not initialized.
normalizer_
Normalizer is not initialized.
type == TrainerSpec::UNIGRAM || type == TrainerSpec::BPE
Vocabulary constraint is only enabled in subword units.
(v.size()) >= (1)
!v[0].empty()
absl::SimpleAtoi(v[1], &freq)
Could not parse the frequency
pieces
output container is null
detokenized
!w.empty()
Empty piece is not allowed.
(begin) < (norm_to_orig.size())
(end) < (norm_to_orig.size())
(orig_begin) <= (input.size())
(orig_end) <= (input.size())
(orig_begin) <= (orig_end)
(consumed) == (normalized.size())
all normalized characters are not consumed.
output proto is null
nbest_spt
model_->IsNBestEncodeAvailable()
NBestEncode is not available for the current model.
!nbests.empty()
NBestEncode returns empty result.
(nbest_size) <= (512)
nbest_size must be nbest_size <= 512
model_->IsSampleEncodeAvailable()
SampleEncode is not available for the current model.
Invalid id: 
ERROR
Returns default value 
unknown extra_option type.
reverse
it != extra_option_map.end()
option "
" is not available.
!IsUnknown(PieceToId(absl::string_view(model_->bos_piece().data())))
id for `
` is not defined.
!IsUnknown(PieceToId(absl::string_view(model_->eos_piece().data())))
model file path should not be empty.
input->ReadAll(&serialized)
(0) <= (byte)
(consumed) == (1)
(token_index_begin + offset) == (token_index_end)
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/src/unigram_model.cc
Failed to find the best path in Viterbi.
WARNING
nbest_size >= 1. Returns empty result.
Too big agenda. shrinking
(num_nodes) < (trie_results.size())
no pieces are loaded.
cannot build double-array.
no entry is found in the trie.
Two sentence piece sequences are not equivalent! Left: 
, Score: 
. Right: 
 Error #
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/protobuf-lite/arena.cc
CHECK failed: (min_bytes) <= (std::numeric_limits<size_t>::max() - kBlockHeaderSize): 
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/protobuf-lite/common.cc
This program requires version 
 of the Protocol Buffer runtime library, but the installed version is 
.  Please update your library.  If you compiled the program yourself, make sure that your headers are from the same version of Protocol Buffers as your link-time library.  (Version verification failed in "
This program was compiled against version 
 of the Protocol Buffer runtime library, which is not compatible with the installed version (
).  Contact the program author for an update.  If you compiled the program yourself, make sure that your headers are from the same version of Protocol Buffers as your link-time library.  (Version verification failed in "
%d.%d.%d
FATAL
[libprotobuf %s %s:%d] %s
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/protobuf-lite/extension_set.cc
Non-primitive types can't be packed.
can't reach here.
SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/protobuf-lite/google/protobuf/extension_set_inl.h
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/protobuf-lite/generated_message_util.cc
CHECK failed: (scc->visit_status.load(std::memory_order_relaxed)) == (SCCInfoBase::kRunning): 
(cannot determine missing fields for lite message)
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/protobuf-lite/message_lite.cc
parse
 exceeded maximum protobuf size of 2GB: 
Can't 
 message of type "
" because it is missing required fields: 
SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/protobuf-lite/google/protobuf/parse_context.h
Can't happen
Subword model cannot be loaded from: 
uninitialized exception
unregistered class
invalid signature
unsupported version
pointer conflict
incompatible native format
array size too short
input stream error
class name too long
unregistered void cast 
class version 
<unknown class>
unknown derived exception
code instantiated in more than one module
output stream error
programming error
serialization::archive
unknown exception code
attempt to encode a value > 6 bits
attempt to decode a value not in base64 char set
invalid xml escape_sequence
cannot invoke iterator comparison now
invalid multbyte/wide char conversion
ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/
size of int
size of long
size of float
size of double
endian setting
^(\b\w+\b)(\S+)$
Failed to initialise the regex expression for the subtokens: 
appendMatchedSpan
span_processor.cpp
mInternals.reverseMapping.find(str) != mInternals.reverseMapping.end() && "Unable to find token chain in reverse mapping after a match was found in the pattern " "trie"
Failed to attach the regex expression to the token text: 
Failed to find match in text: 
Encountered invalid substring: 
Encountered empty normalized matching substring for label: 
Begin/inside BIO tags must have a payload component
Only begin/inside BIO tags can have a payload component
Cannot extract payload from non-begin/inside BIO tag
getPayload
bio.cpp
mPayload.has_value()
Well-formed BIO tags must be >=3 characters long, but got: 
BIO tag has no prefix
Unrecognized BIO tag prefix
convertToLabelledSpans
!currentSpan.has_value()
buildAllBioTagsFromEntityLabels
bioTags.size() == expectedFinalSize
Cannot get value for empty optional!
Span labels tensor is of incorrect shape
Span labels tensor shape does not match tokens size
Unable to instantiate a normalizer form the input normalizer choice
Failed to instantiate normalizer - 
Failed to normalize string 
 - due to error: 
Failed to compare strings - due to error: 
Failed to casefold string: 
Invalid substring range. The endIndex
 >= src length 
Invalid substring range. startIndex  (
) >= endIndex (
insertToken
vocabulary.cpp
mIdToText.size() == mTextToId.size()
Token indices out of range.
Number of tokens differs from number of BIO tags
Number of tokens differs from number of group IDs
First dimension of intentEntityTransitions does not equal number of intents
Second dimension of intentEntityTransitions does not equal number of BIO tags
Size of startEntityTransitions does not equal number of BIO tags
First dimension of entityTransitions does not equal number of BIO tags
Second dimension of entityTransitions does not equal number of BIO tags
Out-of-range intent label (key) in uniqueLabels
Out-of-range BIO label (value) in uniqueLabels
Out-of-range intent label (key) in indexableLabels
Out-of-range BIO label (value) in indexableLabels
Empty entitiesScores (implies no tokens)
Size of groupScores (
) does not equal number of tokens (
Invalid beamSize. Should be in the interval (0, 5]
BeamSequence[
  score = 
  intent = 
  entities = 
  groupIds = 
(none)
beamSearch
beam_search.cpp
allCandidates.begin() + beamSize < allCandidates.end()
Beam sequence is empty getIntent
Beam sequence is empty getEntities
Embedding[
 ...
Label vocabulary does not contain pad token
Attempt pruning UserAccepted from a one shot reply UserAccepted + UserStatedTask prediction.
Could not find a UserAccepted dialog act to remove.
Hit filesystem error while reading %s: %s
UPContextualizerStrategyPrompt; %ld domain candidates matched dialog act prompted entity (%@)
UPContextualizerStrategyPrompt: No domain result matched dialog act prompted entity (%@)
UPContextualizerStrategyPrompt: Building verbatim string payload
[%s] Error, file doesn't exist. Hash for file content cannot be calculated: %s
[%s] Error, input stream for file could not be created. Hash for file content cannot be calculated: %s
[%s] Error, input stream for file could not be read. Hash for file content cannot be calculated: %s
[%s] Error while calculating hash of file %s
[%s] Error iterating over directory %s: %s
[%s] Warning: config missing Bolt task ID
[%s] Warning: config Bolt task ID is not a string
[%s] The component %zu is invalid
UPContextualizerStrategyOffer: Detected high-probability yes/no intent in core result
BEGIN "Encoder Inference"
Encoder Inference
END "Encoder Inference"
BEGIN "Decoder Inference"
Decoder Inference
END "Decoder Inference"
[%s] Invalid featurization input provided to the model.  Expected a non-empty utterance length tensor and a context tensor of at least two dimensions.
[%s] The utterance length (%lu) exceeds the maximum utterance length (%lu).
[%s] Padding of the embeddings input is required to execute model inference
[%s] Padding of the context input is required to execute model inference
[%s] Padding of the span input is required to execute model inference
Warning: cannot embed OOV token '%s'.
Featurized the following %lu LegacyNLContext features in ITFMParserRequest: %s
Failed to featurize any labels from legacyNlContext
Warning: Legacy NL context features were supplied, but the asset directory major version (%u) does not support these. These will not be featurized.
Warning: The request's nlContext contains a SDA. Skipping featurization for the legacy context.
No SDA present in nlContext: falling back to legacyNlContext
Failed to extract any labels from nlContext or legacyNlContext
Label '%s' not present in vocabulary. Skipping. (Is this label supported by the provided assets?)
Number of context features (%lu) exceeds maximum limit (%lu): truncating by removing features %s
[%s] %sITFM context: %s
nlu_request_id not found so skipping insertion of context featurized response into FeatureStore
ITFM non-padded context input tensor: %s
Skipping insertion of ITFM context featurizer response into FeatureStore because SNLPFeatureStoreEnabled feature flag is disabled
Successfully inserted context featurizer response into FeatureStore
Unable to insert context featurizer response into FeatureStore
UPQuery from non-proto service: %@
Could not convert query dialog act: %{sensitive}@
Converted dialog act and got: %@
Found no utterance alignments, skipping...
Found no matching insertable span.
SiriOntology indicated an entity node, but failed to cast to UsoEntityNode type.
No utterance alignments found in the entity node; searching the descendant nodes for utterance alignments instead.
Found no entities in the uso graph of matching span, skipping...
There is more than one entity in the USO graph of matching span, skipping...
The first level entity is not of entity node type, skipping...
BEGIN "UaaP UPParserModelInit initWithLoadedModelConfiguration"
UaaP UPParserModelInit initWithLoadedModelConfiguration
END "UaaP UPParserModelInit initWithLoadedModelConfiguration"
BEGIN "UaaP EspressoInference"
UaaP EspressoInference
END "UaaP EspressoInference"
BEGIN "UaaP Post-Processing"
Number of BEAM sequences = %lu
Processing BEAM sequence: %s
Produced candidate: %@
UaaP Post-Processing
END "UaaP Post-Processing"
BEGIN "UaaP Prediction"
Error predicting utterance: %{sensitive}s
UaaP Prediction
END "UaaP Prediction"
Reshaping network to handle current request inputs
Reshaping blob '%s' to w=%d, h=%d, k=%d, n=%d
[%s] %sFeaturizing the following context labels in NLv4ParserRequest.
[%s] %s%s
Skipping insertion of NLv4 context featurizer response into FeatureStore because SNLPFeatureStoreEnabled feature flag is disabled
Loading SSUFile...
SSUFile successfully loaded from: %s
SSUFile relinquished
Temporary decompressed SSUFile removed at location: %s
Finished writing decompressed SSUFile to %s
Error when unmapping the memory for SSU file
[%s] Found an smsGroupName span that matches a common_Person or common_Agent node
[%s] Found a personFullName span that matches a common_Person or common_Agent node, so skipping group_name_transform
[%s] Replacing the node label "%s" with "%s"
[%s] Found %lu smsGroupName matching spans
[%s] Found %lu personFullName matching spans
[%@ Assets] %s
BEGIN "SNLPITFMClassifier responseForRequest"
SNLPITFMClassifier responseForRequest
END "SNLPITFMClassifier responseForRequest"
[%s] %s
Warning: failed to parse month number string as an integer: '%s'. Returning nullptr.
Warning: parsed month number not in [1, 12]: %u. Returning nullptr.
Hit unexpected exception while converting USO graph: %s
Hit UsoGraphProtoWriterException while converting USO graph: %s
Attaching shared entity graph: %{sensitive}s
The shared entity graph does not have a single, unique entity below the root: skipping
The shared entity graph does not have an entity node
The entity node could not be dynamically cast to a UsoEntityNode
Failed to attach subtree: %{sensitive}s 
Warning: Creating an LVC (ITFM) Orchestrator without a target vocabulary. This means that string labels in the response will not be populated.
BEGIN "ITFM Span Featurization"
nlu_request_id not found so skipping insertion of asset version into FeatureStore
ITFM Span Featurization
END "ITFM Span Featurization"
BEGIN "ITFM Context Featurization"
ITFM Context Featurization
END "ITFM Context Featurization"
BEGIN "ITFM Inference"
ITFM Inference
END "ITFM Inference"
Could not find output label mapping for component %s
Warning: Invalid model version provided: %u.  Model versions currently supported: %s.
A token could not be reindexed; %{sensitive}s
Unknown error thrown during token index conversion (should be unreachable)
Token indexes could not be converted: %s
[%s] Splitting common_Person nodes in-place
[%s] Iterating through all tree nodes
[%s] Finished iterating through all tree nodes
[%s] Could not split this common_Person node
[%s] Successfully split the common_Person node into name/contact type
[%s] Handling common_Person subtree
[%s] Warning: the common_Person node has more than one child (expecting just `name`). Skipping.
[%s] Warning: the common_Person node child is not `name`. Skipping.
[%s] common_Person.name value: %{sensitive}s
[%s] There exists a person matching span covering this entire common_Person.name node. Skipping.
[%s] Could not find a split for this common_Person. Skipping.
[%s] Warning: Failed to generate a node for matching span (personInput=%{sensitive}s, contactTypeInput=%{sensitive}s)
[%s] Hit out of range exception when looking up token character indices
[%s] newNameNode.startCharIndex (%lu) is less than originalNameStartCharIndex (%lu)
[%s] newNameNode character indices imply an empty or impossible substring (%lu -> %lu)
[%s] contactAddressLabelNode.startCharIndex (%lu) is less than originalNameStartCharIndex (%lu)
[%s] contactAddressLabelNode character indices imply an empty or impossible substring (%lu -> %lu)
[%s] Generated new common_Person.name node with newNameNode.startCharIndex=%lu, newNameNode.endCharIndex=%lu, newNameNode.value=%{sensitive}s
[%s] After filtering, we have %lu contact type matching spans
[%s] After filtering, we have %lu person matching spans
[%s] Warning: could not find start token index corresponding to node.startCharIndex=%lu
[%s] Warning: could not find end token index corresponding to node.endCharIndex=%lu
[%s] Deleting %lu nodes
[%s] Inserting %lu spawned nodes
[%s] Badly formed SystemPrompted dialog act; needs to contain the target UsoGraph.
[%s] Badly formed SystemOffered dialog act; needs to contain a user dialog act.
[%s] Badly formed SystemReportedSuccess dialog act; needs to supply the task UsoGraph.
[%s] Badly formed SystemReportedFailure dialog act; needs to supply the UsoGraphs for the failed task and for the failure reason.
[%s] Warning: Badly formed user dialog act.
[%s] Failed to cast USO task node from SiriOntology. 
[%s] After filtering, we have %lu %s matching spans
[%s] No grounded tokens found under node: %s
No calibration score found for parser result with bundle modelIdentifier: %@
[%s] Both %s and %s semantic values found when using %s spans
[%s] MatchingSpan with label %s, semantic value %s found?: %{BOOL}d
Request validation failed: received nullptr request
Request validation failed: received request with no locale
Request validation failed: received request with a locale (%s) not matching the expected locale (%s)
Request validation failed: received request with no utterance
Successfully validated SSU request
Failed to build app entity from matching span. Skipping.
Matching span has no label. Skipping.
Warning: ON_SCREEN salient entity is missing appBundleId field. Skipping.
Warning: ON_SCREEN salient entity appBundleId field is missing string value. Skipping.
Failed to lookup string node data from matching span USO graph
Unexpected USO graph: app entity node does not contain a valid app bundle ID in its identifiers. Skipping.
Failed to extract UTF-8 indexes from the app entity span graph string node alignment
Matching span has no USO graph. Skipping.
Failed to convert proto USO graph to SiriOntology format. Skipping.
Failed to lookup node Root->entity. Skipping.
Unexpected USO graph: failed to lookup node Entity->name. Skipping.
Unexpected USO graph: node Entity->name is not of type StringNode. Skipping.
Unexpected USO graph: node Entity->name has no string value. Skipping.
Unexpected USO graph: identifier value is empty. Skipping.
Encountered error in deprecated version of inferenceResponseForRequest: %@ (returning SERVER parser response)
Result candidate has uncalibrated probability %f and calibrated probability %@. Using calibrated value.
Result candidate has uncalibrated probability %f and no calibrated probability. Using uncalibrated value.
Loaded config confidence_threshold: %1.2f
[%s] %sPSC %@ probability (%1.2f) is below the 'confidence_threshold: (%1.2f)', setting to -0.0
UPContextualizerStrategyCancel: Detected high-probability cancel intent in core result
UPContextualizerStrategyOptions: Detected high-probability selectOrdinal intent in core result
UPContextualizerStrategyOptions: %ld domain candidates matched dialog act prompted entity (%@)
UPContextualizerStrategyOptions: No domain result matched dialog act prompted entity (%@)
UPContextualizerStrategyOptions: Building verbatim string payload
Building SSUPreprocessor from assets directory: %s
Building preprocessor dependency: SentencePiece model using path: %s
BEGIN "SSUPreprocessor SentencePiece tokenization"
SSUPreprocessor SentencePiece tokenization
END "SSUPreprocessor SentencePiece tokenization"
Warning: truncating SentencePiece tokens for utterance: %{sensitive}s
Encoded utterance as sentence pieces: %{sensitive}s
Client tried to read the next negative cached encodings batch when there are none remaining
Client tried to read a positive cached encodings batch when there are still negative batches to be read
Client tried to read the next positive cached encodings batch when there are none remaining
[%s] [model_task_id=%s]
Hit unexpected exception while generating USO graph: %s
Hit OntologyException while generating USO graph: %s
Could not compute utterance alignment boundary due to Unicode issue. Not adding alignment.
nlu_request_id not found so skipping insertion of SNLC executed handcrafted rules into FeatureStore
Skipping insertion of SNLC executed handcrafted rules into FeatureStore because SNLPFeatureStoreEnabled feature flag is disabled
Unable to insert executed handcrafted rules into FeatureStore
BEGIN "OWL Embedder Orchestrator Init"
OWL Embedder Orchestrator Init
END "OWL Embedder Orchestrator Init"
The app %s does not already exist in the registry: adding it
Removing app from the registry: %s
[%s] %sNo (app, category) tuples were triggered because the request contained no valid appName spans corresponding to registered SSU-enabled apps
[%s] %sApp '%s' with category '%s' was triggered
Warning: Encountered duplicate bundle ID in appInfos: %s. Using only the first encountered.
SNLC override triggered: falling back on DEVICE based on the turn input SDA content
SNLC override triggered: falling back on SERVER based on the LegacyNLContext dictationPrompt=true
[%s] %sRejecting '%s'.
Warning: Context shape not 2-dim
[NLv4IO Context Tensor] shape=%lu,%lu num_elems=%lu
Warning: Context shape not consistent with data
[NLv4IO Context Token] i=%lu j=%lu id=%lu token=%s
[%s] Could not reshape the input span tensor with %lu dimensions
[%s] Could not reshape the input context tensor with %lu dimensions
[%s] Could not reshape the input embeddings tensor with %lu dimensions
[%s] padEmbeddings input tensor size = %lu (%lu, %lu, %lu)
[%s] padEmbeddings maxNumTokens (defined by network config) = %lu
[%s] Illegal shape for embeddings: (%lu, %lu, %lu). Must be (?, ?, %lu) and hold %lu values
[%s] padEmbeddings For each batch, copying %lu embedding values and adding %lu padding values
[%s] padEmbeddings Padded embedding tensor shape: (%lu, %lu, %lu)
[%s] Found setNumber voc span(s)
Converted protobuf token indexes (%u -> %u) to non-whitespace token indexes (%lu -> %lu)
No matcher names provided - type property will be UPSpanTypeNone
Plum spans are deprecated and not recognized by the span matchers - type property will be UPSpanTypeNone
Span not recognized by the span matchers - type property will be UPSpanTypeNone
Trying to find a media playback subtree to replace default value playback speed.
Found a media playback subtree to replace default value playback speed.
Failed to find a media playback span with speed value.
Creating NLv4InferenceOrchestrator instance with getAssetVersionMajor()=%u
BEGIN "NLv4 Request Validation"
NLv4 Request Validation
END "NLv4 Request Validation"
BEGIN "NLv4 Reindexation"
NLv4 Reindexation
END "NLv4 Reindexation"
BEGIN "NLv4 Matched Span Featurization"
NLv4 Matched Span Featurization
END "NLv4 Matched Span Featurization"
BEGIN "NLv4 Context Featurization"
NLv4 Context Featurization
END "NLv4 Context Featurization"
BEGIN "NLv4 Inference"
[%s] %sNumericalized span input for NLv4 parser model:
[%s] %sNumericalized context input for NLv4 parser model:
Attempt E5-ML inference.
Espresso model assets could not be found.  No NLv4 model was initialised.
NLv4 Inference
END "NLv4 Inference"
BEGIN "NLv4 Denumericalization"
NLv4 Denumericalization
END "NLv4 Denumericalization"
BEGIN "NLv4 Placeholder Fixes"
NLv4 Placeholder Fixes
END "NLv4 Placeholder Fixes"
BEGIN "NLv4 Tree Building"
NLv4 Tree Building
END "NLv4 Tree Building"
BEGIN "NLv4 Post-Inference Tree Manipulation"
Tree after all manipulations:
%{sensitive}s
NLv4 Post-Inference Tree Manipulation
END "NLv4 Post-Inference Tree Manipulation"
BEGIN "NLv4 Protobuf Response Building"
A hypothesis was rejected because it contained only UserAccepted.
Building UDA for hypothesis number %zu
Invalid USO graph, removing parse from output.  This might be due to a grammatical error or an otherwise malformed model tree.
Could not generate a full USO graph for a hypothesis: %s
NLv4 Protobuf Response Building
END "NLv4 Protobuf Response Building"
BEGIN "NLv4 Post-Protobuf Response Corrections"
NLv4 Post-Protobuf Response Corrections
END "NLv4 Post-Protobuf Response Corrections"
BEGIN "NLv4 Handcrafted Rules"
[%s] %sExecuted handcrafted rules:
NLv4 Handcrafted Rules
END "NLv4 Handcrafted Rules"
[%s] %s[NLv4IO Ply tree] hypothesis=%zu:
[NLv4IO Ply tags] hypothesis=%zu:
[SNLPAssetLogger] %s
nlu_request_id not found so skipping insertion of executed handcrafted rules into FeatureStore
Skipping insertion of NLv4 executed handcrafted rules into FeatureStore because SNLPFeatureStoreEnabled feature flag is disabled
Successfully inserted NLv4 executed handcrafted rules into FeatureStore
Unable to insert NLv4 executed handcrafted rules into FeatureStore
Invalid model tree, removing parse from output.
Invalid user dialog act: %s
BEGIN "CalibrationInference"
CalibrationInference
END "CalibrationInference"
Executing OWL espresso v1 inference.
[%s] Warning: encountered unknown span matcher name: %d
[%s] Warning: failed to get namespace for node %{sensitive}s: %{sensitive}s
[%s] Badly formed matching span; start and/or end indices missing from span.
Initialised espresso v1 NLv4 model using original v1 assets.
Initialised espresso v1 NLv4 model using E5-ML v1 assets.  This implies an issue with E5-ML asset generation.  NLv4 inference can proceed, but may not be as performant as expected.
Initializing UPSharedEntityResolution with %lu matching spans
Resolving shared entities for token range (%lu, %lu) with value type: %@
Returning nil since we cannot handle non-date value types
Returning nil since there is no corresponding matching span
Found a corresponding matching span: returning the shared entity graph
Processing matching span with category: %@
Skipping non-DataDetected span
Skipping non-datetime span
Discarding duplicate matching date time span for range (%lu, %lu)
Adding DD datetime span with token range (%lu, %lu)
Missing locale info when init UPDataDetector. Falling back using the system default one.
[%s] A data detector span contained a USO graph with an invalid entity node.  This data detector span was ignored by the span matching featurizer.  Error: %s.
[%s] Span encoding failed; number of buckets (%lu) not matching number of tokens (%lu).
PSC override triggered: falling back on NOT POMMES based on the turn input SDA content
[SSUCacheDirectory] Creating a cache directory instance with root directory: %s
[SSUCacheDirectory] Not a directory: %s
[SSUCacheDirectory] Failed to initialize empty cache directory
[SSUCacheDirectory] Hit filesystem error: %s)
[SSUCacheDirectory] Clearing cache files for all locales
[SSUCacheDirectory] Removing locales directory: %s
[SSUCacheDirectory] Clearing cache files for all locales except %s
[SSUCacheDirectory] Encountered bad cache directory state: the locales directory %s contains a non-directory file: %s. Ignoring.
[SSUCacheDirectory] Removing locale directory: %s
[SSUCacheDirectory] Attempting to removing cache files across all locales for app: %s
[SSUCacheDirectory] Removing app bundle directory: %s
[SSUCacheDirectory] Found no cache files for app: %s. Doing nothing.
[SSUCacheDirectory] Could not find cache file in directory: %s
[SSUCacheDirectory] Encountered bad cache directory state: the app bundle directory %s contains a file with an unexpected filename: %s)
[SSUCacheDirectory] Inserting cache file for locale %s, appBundleId %s and version %s
[SSUCacheDirectory] Atomically renaming temporary file %s to final location %s
[SSUCacheDirectory] Initializing directory with V1 format: %s
[SSUCacheDirectory] Hit file stream error: %s)
[SSUCacheDirectory] Removing existing cache file before inserting new one: %s
[SSUCacheDirectory] Could not extract version from filename: %s
[SSUCacheDirectory] Encountered bad cache directory state: the app bundle directory %s is empty, with no cache files (expected exactly one)
[SSUCacheDirectory] Encountered bad cache directory state: the app bundle directory %s contains multiple cache files (expected exactly one)
[SSUCacheDirectory] Encountered bad cache directory state: the app bundle directory %s contains a non-regular file: %s)
[SSUCacheDirectory] Attempting to heal a corrupted cache by removing all contents under: %s
[SSUCacheDirectory] Error: cannot remove non-existing directory: %s
[SSUCacheDirectory] Successfully removed %lu files/directories under %s
[SSUCacheDirectory] Cannot initialize cache directory with existing file: %s
BEGIN "UPLoadedModelConfigurationInit"
BEGIN "EspressoInitialization"
Exception while initializing model %s
EspressoInitialization
END "EspressoInitialization"
UPLoadedModelConfigurationInit
END "UPLoadedModelConfigurationInit"
BEGIN "OWL Input Preprocess Aggregated"
OWL Input Preprocess Aggregated
END "OWL Input Preprocess Aggregated"
BEGIN "OWL Model Forward Aggregated"
OWL Model Forward Aggregated
END "OWL Model Forward Aggregated"
BEGIN "OWL Output PostProcess Aggregated"
OWL Output PostProcess Aggregated
END "OWL Output PostProcess Aggregated"
BEGIN "OWL Input Preprocess"
OWL Input Preprocess
END "OWL Input Preprocess"
BEGIN "OWL Model Forward"
OWL Model Forward
END "OWL Model Forward"
BEGIN "OWL Output PostProcess"
OWL Output PostProcess
END "OWL Output PostProcess"
[%s] [WARN] MatchingSpan has no USO graph
[%s] [WARN] MatchingSpan has USO graph with no identifiers
[%s] [WARN] probability missing from identifier
[%s] [WARN] probability has no value
[%s] [WARN] Negative relative threshold supplied (%f), span filtering will behave strangely
[%s] Span filtering: %lu out of %lu spans kept
[%s] Span %s [score %f] was kept?: %{BOOL}d
[%s] Span %s [no score] was kept?: %{BOOL}d
OWL assets not identified.  If this is a unit test, have you pulled all git lfs assets?  If this is a user request, have you ensured the assets are available on the device?
Hit error when converting protobuf span to UPSpan: %@
Multiple SystemDialogActs specified in context but UaaP can only handle one - using the first one
BEGIN "UaaP Preprocessing"
Featurized token with text=%s
Token span labels: %s
UaaP Preprocessing
END "UaaP Preprocessing"
Warning: discarding data detector matching span with unknown category %@
Adding matching span (%u -> %u) with label %@
Warning: could not look up ontology name for edge '%s'
Attaching %s edge, binding %s to %s.
Could not insert subtree: %{sensitive}s 
Insertion of subtree was successful.
Replaced the whole reinsertion subtree including the parent.
Replaced only the reinsertion point itself.
 Warning: Could not generate USO graph: %s
[%s] %sBuilt USO graph:
Failed to cast entity node to entity node; SiriOntology reports a non-entity node as an entity node.
Warning: Integer %s out of range for USO integer nodes.
Warning: Failed to convert string %s to integer.
Warning: could not look up ontology name for parent argument '%s'
BEGIN "SNLPNaturalLanguageParser inferenceResponseForRequest"
SNLPNaturalLanguageParser inferenceResponseForRequest
END "SNLPNaturalLanguageParser inferenceResponseForRequest"
Tree after ContactTypeSplit step:
%{sensitive}s
Tree after PersonNameSplitHack step:
%{sensitive}s
Tree after GroupNameTransform step:
%{sensitive}s
Tree after ContactAddressDowncaster step:
%{sensitive}s
Tree after DefaultMediaPlaybackSpeed step:
%{sensitive}s
Tree after SetIdentityPromoter step:
%{sensitive}s
Tree after MinimumMaximumLabeller labelling:
%{sensitive}s
Tree after One Shot Reply check:
%{sensitive}s
Tree after SetNumber verb replacement:
%{sensitive}s
Tree after fromPerson recipient replacement:
%{sensitive}s
[%s] Warning: Failed to extract UTF-8 indexes from the app entity span graph string node alignment: %s
[%s] Span Input
[%s] nlu_request_id not found so skipping insertion of span featurized response into FeatureStore
[%s] Warning: encountered span missing label
[%s] Badly formed matching span; start and/or end indices missing from span. Skipping.
[%s] Mapping span label '%s' to span label '%s'
[%s] Warning: Featurised spans shape not 3-dim
[%s] [Span Tensor] shape=%lu,%lu,%lu num_elems=%lu
[%s] Warning: Span shape not consistent with data
[%s] Spans encoded over the tokens:
[%s] %sRejected OOV Spans: %s
[%s] Skipping insertion of matched spans featurized response into FeatureStore because SNLPFeatureStoreEnabled feature flag is disabled
[%s] Successfully inserted span featurizer response into FeatureStore
[%s] Unable to insert span featurizer response into FeatureStore
Could not find contextualizer strategy for dialog act: %{sensitive}@
Client tried to write the next negative cached encodings batch when there are none remaining to be written
Client tried to write a positive cached encodings batch when there are still negative batches remaining to be written
Client tried to write the next positive cached encodings batch when there are none remaining to be written
Inserting FeatureStore entry with interactionIdentifier=%@, streamIdentifier=%@
[%s] %sThe model has received %lu spans. Truncating this list of spans to %u spans.
[%s] %sThe following spans were kept after truncation:
[%s] %sThe following spans were removed during truncation:
[%s] %s  Span with label %s across indices (%u, %u).
[%s] %s  Span with label %s.
[%s] Since the model itself predicted only %lu common_Person nodes (lower than the threshold of %lu), do not apply the name split hack
[%s] Could not find _any_ partition for this common_Person (including a single-span one). Skipping.
[%s] This common_Person cannot be split into multiple sub-spans. Skipping.
[%s] This common_Person has been partitioned into %lu sub-spans.
[%s] Warning: Failed to generate a node for matching span (input=%{sensitive}s)
[%s] Finding person matching span partitions for range %lu -> %lu
[%s]  - span: %{sensitive}s
[%s] Found %lu possible person partitions:
[%s] Found minimal partition:
[%s]  - component: %{sensitive}s
[%s] Did not find minimal partition
[%s] Generated new common_Person.name node with startCharIndex=%lu, endCharIndex=%lu, value=%{sensitive}s
[%s] Successfully spawned replacement common_Person nodes
Returning app result for intent %s with batchType=%s, batchIndex=%lu, encodingIndexWithinBatch=%lu, similarityScore=%f
Highest matching negative example has score %f (batch type %s, batch index %lu, encoding index %lu). Using max(negativeScoreClipMinimum, score) = %f.
There is no negative example. Using minimum score %f.
BEGIN "Sentence Piece Load"
Sentence Piece Load
END "Sentence Piece Load"
SNLPLanguageVariantClassifier
UPModelIdentifier
NSCopying
UPContextualizerStrategyPrompt
UPContextualizerStrategy
NSObject
UPContextualizerStrategyOffer
SNLPSSUMatcherDirectories
UPDataDetectorSpan
SNLPITFMModelBundle
UPQueryRunner
UPDialogActPrompt
UPDialogAct
UPParserModel
SNLPITFMClassifier
UPUsoSerializer
UPCalibration
SNLPServerNLClassifier
UPResultCandidate
UPModelBundle
SNLPPommesServerClassifier
UPResultRootNode
UPResultNode
UPContextualizerStrategyCancel
UPContextualizerStrategyOptions
UPResultIntermediateNode
UPIntentWithSingleEntity
UPDialogActConverter
UPPreprocessorOutput
SNLPEmbedder
UPContextualizerUtilities
UPUtilities
UPSpan
UPCalibrationModel
UPEntityWithValue
UPDialogActOffer
UPSharedEntityResolution
UPDetectedData
UPDataDetectors
UPContextualizerInput
UPModelConfiguration
SNLPFeatureFlagUtilities
UPLoadedModelConfiguration
SNLPSSUApplicationInfo
UPResult
UPQuery
UPResultCandidateEntity
UPDialogActOptions
UPPreprocessor
UPResultLeafNode
SNLPNaturalLanguageParser
UPEmbedding
SNLPITFMModelInfo
UPContextualizer
SNLPFeatureStoreUtilities
SNLPSSUMatcher
T@"NSArray",R,C,N,V__candidates
.cxx_destruct
T@"UPResult",R,N,V_domainResult
T#,R
__usoSerializer
T@"<UPDialogAct>",R,N,V_dialogAct
_entity
T@"NSArray",R,C,V_entityValues
_locale
T@"NSArray",R,C,V_leafNodes
_tokens
T@"NSArray",R,V_entities
arrayWithArray:
T@"NSDictionary",R,N,V__dataDetectorDateTimeSpansByTokenRange
containsObject:
T@"NSDictionary",R,V_embeddingsByToken
dealloc
T@"NSLocale",R,N,V_locale
directLeafNodes
T@"NSNumber",R,V_groupId
entityWithValue
T@"NSSet",R,N,V_domainModelBundles
hasEmbeddingDim
T@"NSString",R,C
initWithCoreModel:domainModels:
T@"NSString",R,C,V_bioLabelsVocabPath
initWithIntent:entityWithValue:
T@"NSString",R,C,V_category
insertToFeatureStoreWithNLv4SpanResponse:interactionIdentifier:
T@"NSString",R,C,V_entityName
isProxy
T@"NSString",R,C,V_entityValue
numberWithLong:
T@"NSString",R,C,V_grammarPath
read:maxLength:
T@"NSString",R,C,V_intentVocabPath
resultFromResult:withNewIntent:
T@"NSString",R,C,V_parserEspressoModelPath
T@"NSString",R,C,V_spanVocabPath
startTokenIndex
T@"NSString",R,C,V_utterance
valueWithRange:
.cxx_construct
T@"NSURL",R,V_cacheDirectoryURL
JSONObjectWithData:options:error:
__candidateEntitiesByStartIndex
T@"<SIRINLUSystemDialogAct><NSObject>",R,V_dialogAct
_contextualizer
T@"NSArray",R,C,V_directLeafNodes
_intent
T@"NSArray",R,C,V_intermediateNodes
_parseUserDialogActGraph:error:
T@"NSArray",R,C,V_spans
annotatedString
T@"NSArray",R,V_tokens
choices
T@"NSDictionary",R,V__candidateEntitiesByStartIndex
containsString:
T@"NSLocale",R,C,N
deserializeFromSerializedGraph:
T@"NSNumber",R,V_calibratedProbability
T@"NSObject<SIRINLUUserDialogAct>",R,C,V_task
groupId
T@"NSString",R
highInt
T@"NSString",R,C,V_appBundleId
initWithIntent:
T@"NSString",R,C,V_calibrationEspressoModelPath
initWithLength:
T@"NSString",R,C,V_configPath
intentVocabPath
T@"NSString",R,C,V_entityType
modelIdentifier
T@"NSString",R,C,V_espressoModelPath
parserFromAssetDirectory:error:
T@"NSString",R,C,V_intent
release
T@"NSString",R,C,V_label
resultUsingContextualizerInput:
T@"NSString",R,C,V_semanticValue
setProbability:
T@"NSString",R,C,V_text
stringByAppendingPathComponent:
T@"NSString",R,N,V_bioLabelsVocabPath
T@"NSString",R,N,V_bundleId
T@"NSString",R,N,V_errorDomain
T@"NSString",R,N,V_intentVocabPath
T@"NSString",R,N,V_loggingComponentString
T@"NSString",R,V_bundleIdentifier
T@"NSString",R,V_intent
T@"NSString",R,V_label
T@"NSString",R,V_semanticValue
T@"NSString",R,V_text
T@"NSString",R,V_utterance
T@"NSURL",R,N,V_configURL
T@"NSURL",R,N,V_contextVocabularyURL
T@"NSURL",R,N,V_espressoModelURL
T@"NSURL",R,N,V_spanVocabularyURL
T@"NSURL",R,N,V_targetVocabularyURL
T@"NSURL",R,N,V_versionURL
T@"NSURL",R,V_assetURL
T@"NSURL",R,V_datasetAssetsDirectoryURL
T@"NSURL",R,V_modelAssetsDirectoryURL
T@"NSUUID",R,C,V_queryUUID
T@"NSUUID",R,C,V_uuid
T@"SIRINLUEXTERNALUserParse",R,N
T@"SIRINLUEXTERNALUsoGraph",R,N,V_sharedEntityGraph
T@"SIRINLUEXTERNALUsoGraph",R,V_sharedEntityGraph
T@"SIRINLUINTERNALUAAP_PARSERUaaPParserResponse",R
T@"SNLPITFMModelBundle",R,N,V_modelBundle
T@"SNLPITFMModelInfo",R,N,V_modelInfo
T@"UPCalibration",R,N,V__calibration
T@"UPCalibrationModel",R,N,V_calibrationModel
T@"UPContextualizer",R,N,V__contextualizer
T@"UPContextualizerStrategyCancel",R,N,V_cancelContextualizerStrategy
T@"UPContextualizerStrategyOffer",R,N,V_offerContextualizerStrategy
T@"UPContextualizerStrategyOptions",R,N,V_optionsContextualizerStrategy
T@"UPContextualizerStrategyPrompt",R,N,V_promptContextualizerStrategy
T@"UPDialogActConverter",R,N,V__dialogActConverter
T@"UPEntityWithValue",R,V_entity
T@"UPEntityWithValue",R,V_entityWithValue
T@"UPLoadedModelConfiguration",R,N,V__loadedModelConfiguration
T@"UPModelIdentifier",R,N,V_identifier
T@"UPModelIdentifier",R,N,V_modelIdentifier
T@"UPParserModel",R,N,V_coreModel
T@"UPParserModel",R,N,V_parserModel
T@"UPPreprocessor",R
T@"UPPreprocessor",R,N,V_preprocessor
T@"UPQuery",R,N,V_query
T@"UPResult",R,N,V_coreResult
T@"UPResultLeafNode",R
T@"UPResultRootNode",R
T@"UPResultRootNode",R,C
T@"UPUsoSerializer",R,C,V_usoSerializer
T@"UPUsoSerializer",R,N,V_usoSerializer
T@"UPUsoSerializer",R,V__usoSerializer
T@"UPUsoSerializer",R,V_usoSerializer
T@"USOSerializedGraph",R,V_reference
T@"USOSerializedGraph",R,V_usoGraph
TB,R
TQ,R
TQ,R,N,V_type
TQ,R,V_type
T^v,R
T^v,R,N,V_beamMaskInput
T^v,R,N,V_labelToValueType
T^v,R,N,V_resolver
T^v,R,V_ddUsoMapper
T^{EspressoModule=^v^v{?=^vi}},R,N,V_calibrationEspressoModule
T^{EspressoModule=^v^v{?=^vi}},R,N,V_parserEspressoModule
T^{UPDataDetector=q^{__DDScanner}^{__DDScanner}^{__DDScanner}^{__DDScanner}^{__DDScanner}^{__DDScanner}},R,V_dataDetector
T^{__DDResult=},R,V_dataDetectorResult
Td,R
Td,R,N
Td,R,N,V_prebuiltIntentThreshold
Td,R,V_uncalibratedProbability
Tf,N,V_confidenceThreshold
Ti,R,N,V_loggingComponent
Tr^{__CFArray=},R,V_dataDetectorResult
T{_NSRange=QQ},R,V_range
URLByAppendingPathComponent:
URLByDeletingLastPathComponent
UTF8String
UUID
__calibration
__candidates
__contextualizer
__dataDetectorDateTimeSpansByTokenRange
__dialogActConverter
__featurizer
__loadedModelConfiguration
_addPathForLabel:range:text:semanticValue:sharedEntityGraph:toGraphNode:forGraph:
_appBundleId
_assetLogger
_assetURL
_attachSharedEntity:withCustomEntityEdge:toGraphNode:forGraph:
_beamMaskInput
_bioLabelsVocabPath
_buildCandidateEntitiesByStartIndex:
_buildEmbeddingsDictionaryWithNonWhitespaceTokens:nonWhitespaceTokenIndexes:embeddings:error:
_buildTokenListWithTokenChain:nonWhitespaceTokenIndexes:
_bundleId
_bundleIdentifier
_cacheDirectoryURL
_calibratedProbability
_calibration
_calibrationEspressoModelPath
_calibrationEspressoModule
_calibrationModel
_cancelContextualizerStrategy
_candidateEntitiesByStartIndex
_candidateForBeamSequence:utterance:outputTokens:resolver:sharedEntityResolution:
_candidateForUtterance:probability:labelledSpans:intent:sharedEntityResolution:
_candidates
_category
_classifierWithModelURL:configURL:spanVocabularyURL:contextVocabularyURL:versionURL:error:
_confidenceThreshold
_configPath
_configURL
_configurationWithBioLabelsVocabPath:configPath:grammarPath:intentVocabPath:spanVocabPath:parserEspressoModelPath:calibrationEspressoModelPath:error:
_contextVocabularyURL
_contextualizeByDialogActTypeUsingContextualizerInput:
_convertBundleIdToEntity:
_convertFromGaveOptionsDialogAct:error:
_convertFromOfferedDialogAct:error:
_convertFromPromptedDialogAct:error:
_convertITFMResponse:
_convertRequest:
_convertResponse:
_convertSNLCRequest:
_coreModel
_coreResult
_cppOrchestrator
_createDialogActWithProtobufQuery:
_dataDetector
_dataDetectorDateTimeSpansByTokenRange
_dataDetectorResult
_datasetAssetsDirectoryURL
_ddUsoMapper
_dialogAct
_dialogActConverter
_dictionaryRepresentation
_directLeafNodes
_domainModelBundles
_domainResult
_embedding
_embeddingsByToken
_embeddingsTensor
_entities
_entityName
_entityType
_entityValue
_entityValues
_entityWithValue
_errorDomain
_errorForMissingResourceURL:errorDomain:
_espressoModelPath
_espressoModelURL
_existErrorForEspressoModelURL:configURL:contextVocabularyURL:spanVocabularyURL:targetVocabularyURL:versionURL:errorDomain:
_getNonWhitespaceTokenIndexes:
_getSpanTypeFromProtobufSpan:
_grammarPath
_groupHigherLevelEntities:
_groupId
_identifier
_indexedLabelRepresentation
_initWithBioLabelsVocabPath:configPath:grammarPath:intentVocabPath:spanVocabPath:parserEspressoModelPath:calibrationEspressoModelPath:
_initWithCppOrchestrator:
_initWithEspressoModelURL:configURL:contextVocabularyURL:spanVocabularyURL:targetVocabularyURL:versionURL:
_initializationBlock
_insertHigherLevelEntities:intoGraph:underTaskNode:
_insertSimpleEntity:intoGraph:underTaskNode:
_insertToFeatureStoreWithJSONString:interactionIdentifier:streamIdentifier:
_insertToFeatureStoreWithProtobufObject:interactionIdentifier:streamIdentifier:
_intentVocabPath
_intermediateNodeRepresentations:
_intermediateNodes
_jsonStringFromProtobufObject:
_label
_labelToValueType
_leafNodeFromGraphEdge:andGraphNode:
_leafNodeFromLabel:andGraphSemanticValueNode:
_leafNodeFromLabel:andGraphStringNode:
_leafNodes
_loadedModelConfiguration
_loggingComponent
_loggingComponentString
_matchSpansForDetectedDataArray:label:
_modelAssetsDirectoryURL
_modelBundle
_modelIdentifier
_modelInfo
_offerContextualizerStrategy
_optionsContextualizerStrategy
_orchestrator
_outputTokens
_parseUserDialogAct:error:
_parserEspressoModelPath
_parserEspressoModule
_parserModel
_prebuiltIntentThreshold
_preprocessor
_promptContextualizerStrategy
_query
_queryUUID
_range
_reference
_resolver
_resultFromInferenceResult:query:outputTokens:resolver:sharedEntityResolution:
_semanticValue
_setupAssetLogger
_sharedEntityGraph
_spanLabelsTensor
_spanVocabPath
_spanVocabularyURL
_spans
_targetVocabularyURL
_task
_text
_type
_uncalibratedProbability
_usoGraph
_usoSerializer
_usoVocabManager
_utterance
_uuid
_versionURL
addHypotheses:
addIndex:
addObject:
addObjectsFromArray:
allValues
alloc
allocWithZone:
annotatedEntityFragmentString
anyObject
appBundleId
appendFormat:
appendString:
applicationInfoWithBundleIdentifier:assetURL:error:
array
arrayWithCapacity:
arrayWithObject:
arrayWithObjects:count:
assetURL
autorelease
beamMaskInput
begin
bestAvailableProbability
bioLabelsVocabPath
buildDataDetectorDateTimeSpansByTokenRange:
buildMatchedSpanListFromQuerySpans:
buildPayloadResultFromQuery:modelIdentifier:intent:entityName:serializer:
buildSpansListWithProtobufQuery:nonWhitespaceTokenIndexes:error:
bundleId
bundleIdentifier
bundleWithEspressoModelURL:configURL:contextVocabularyURL:spanVocabularyURL:targetVocabularyURL:versionURL:errorDomain:error:
bytes
cacheDirectoryURL
calibrateCandidate:withCalibrationScore:
calibrateParserResults:withCalibrationScores:error:
calibrateResult:withCalibrationScore:
calibratedProbability
calibrationEspressoModelPath
calibrationEspressoModule
calibrationModel
cancelContextualizerStrategy
candidateAtRank:
candidateCount
category
characterAtIndex:
checkFileExistence:error:
class
classificationLabel
classificationProbability
classifierWithModelBundle:modelInfo:error:
classifierWithModelBundle:modelInfo:initializationBlock:error:
classifierWithModelURL:configURL:spanVocabularyURL:contextVocabularyURL:error:
classifierWithPathURL:error:
cleanValue
combinedResultFromResults:
componentsJoinedByString:
confidenceThreshold
configPath
configURL
configurationFromDirectoryUrl:error:
conformsToProtocol:
containsIndex:
contextVocabularyURL
convertCppSubwordTokenChainToObjC:
convertFromDialogAct:error:
convertFromUserDialogAct:
convertNLv4ParserRequestToCpp:
convertNLv4ParserResponseFromCppToObjC:
convertSystemDialogAct:
convertUsoGraphFromObjCToCpp:
copy
copyWithZone:
coreModel
coreResult
count
countByEnumeratingWithState:objects:count:
countOfIndexesInRange:
createConfirmOrRejectedDialogActsFor:reference:
createResultFromExistingResult:truncatedTo:
data
dataDetector
dataDetectorResult
dataWithBytes:length:
dataWithContentsOfURL:
dataWithJSONObject:options:error:
datasetAssetsDirectoryURL
ddUsoMapper
debugDescription
defaultCStringEncoding
defaultManager
deregisterApp:error:
description
dialogAct
dialogActFromQuery:
dictionary
dictionaryRepresentation
dictionaryWithContentsOfFile:
dictionaryWithDictionary:
dictionaryWithObjects:forKeys:count:
directoriesWithCacheDirectoryURL:modelAssetsDirectoryURL:datasetAssetsDirectoryURL:error:
domainModelBundles
domainResult
doubleValue
embeddingDim
embeddings
embeddingsByToken
embeddingsTensor
endTokenIndex
entities
entity
entityLabelsFromCandidate:
entityName
entityType
entityValue
entityValues
enumerateIndexesUsingBlock:
errorDomain
errorWithDomain:code:userInfo:
espressoModelPath
espressoModelURL
fileExistsAtPath:
fileExistsAtPath:isDirectory:
fileSystemRepresentation
filterResult:byEntityName:serializer:
filterResult:serializer:predicate:
firstObject
floatValue
forwardWithSpanLabels:embeddings:utterance:
getBytes:maxLength:usedLength:encoding:options:range:remainingRange:
getCoordinates
getDimension
getEmbeddings:
getEmbeddingsBySentence:
getUsoGraphPrintedForm
getWithStreamId:
grammarPath
hasBegin
hasCalibrationModel
hasEmbeddings
hasEnd
hasEndTokenIndex
hasNlContext
hasNumToken
hasStartTokenIndex
hasTokenChain
hasTopCandidate:excedingProbability:matchingOneOfIntents:
hasTurnContext
hasTurnInput
hasValue
hash
higherLevelChildLabel
higherLevelEntityLabelFromParentLabel:childLabel:
higherLevelParentLabel
hypotheses
identifier
indexSet
inferenceResponseForRequest:
inferenceResponseForRequest:error:
init
initFromAssetDirectoryURL:
initFromSourceVocabPath:bertModelPath:bertConfigPath:reformulatorPath:
initLoadFromDataDetectorsDirectoryPath:forLocale:
initWithAppBundleId:
initWithArray:copyItems:
initWithBundleIdentifier:assetURL:
initWithCacheDirectoryURL:modelAssetsDirectoryURL:datasetAssetsDirectoryURL:
initWithCandidates:queryUUID:
initWithCapacity:
initWithCoordinates:
initWithCoreModel:domainModelBundles:
initWithData:
initWithData:encoding:
initWithDomain:code:userInfo:
initWithDomainResult:coreResult:modelIdentifier:query:dialogAct:
initWithEmbeddingsTensor:spanLabelsTensor:outputTokens:
initWithIndexSet:
initWithIntent:entityType:entityName:entityValues:
initWithIntent:entityType:entityName:reference:
initWithIntent:singleEntity:
initWithJsonStr:interactionId:dataVersion:
initWithKey:ascending:
initWithLabel:
initWithLabel:andLeafNodes:
initWithLabel:andText:andSemanticValue:
initWithLabel:dataDetectorResult:
initWithLabel:intermediateNodes:directLeafNodes:
initWithLoadedModelConfiguration:
initWithLoadedModelConfiguration:parserModel:calibrationModel:
initWithLocale:featurizer:
initWithMatchingSpans:
initWithModelBundle:modelInfo:initializationBlock:error:
initWithModelConfiguration:
initWithPrebuiltIntentThreshold:
initWithPrebuiltIntentThreshold:usoSerializer:
initWithPreprocessor:parserModel:calibrationModel:
initWithProtobufEmbeddings:forTokenAt:error:
initWithProtobufQuery:error:
initWithProtobufSpan:nonWhitespaceTokenIndexes:error:
initWithRange:category:dataDetectorResult:
initWithRange:category:dataDetectorResult:usoGraph:
initWithRange:label:text:groupId:semanticValue:sharedEntityGraph:
initWithRange:type:category:
initWithRange:type:category:sharedEntityGraph:
initWithTask:
initWithType:entityName:entityValue:
initWithType:loggingComponent:errorDomain:
initWithUncalibratedProbability:calibratedProbability:utterance:intent:entities:modelIdentifier:task:
initWithUsoGraph:withError:
initWithUsoSerializer:
initWithUtterance:tokens:embeddingsByToken:spans:dialogAct:
inputStreamWithFileAtPath:
insert:error:
insertToFeatureStoreWithITFMAssertVersion:interactionIdentifier:itfmModelType:
insertToFeatureStoreWithITFMContextResponse:interactionIdentifier:itfmModelType:
insertToFeatureStoreWithITFMExecutedHandcraftedRules:interactionIdentifier:itfmModelType:
insertToFeatureStoreWithITFMSpanResponse:interactionIdentifier:itfmModelType:
insertToFeatureStoreWithNLv4AssertVersion:interactionIdentifier:
insertToFeatureStoreWithNLv4ContextResponse:interactionIdentifier:
insertToFeatureStoreWithNLv4ExecutedHandcraftedRules:interactionIdentifier:
instancesRespondToSelector:
intent
intermediateNodeRepresentations:
intermediateNodes
isEqual:
isEqualToEntityWithValue:
isEqualToIntentWithSingleEntity:
isEqualToString:
isFileURL
isHigherLevelEntity
isKindOfClass:
isMemberOfClass:
isReadableFileAtPath:
isSNLPFeatureStoreEnabled
isWhitespace
itfmModelTypeForSNLPComponent:
label
labelToValueType
languageCode
leafNodeRepresentation
leafNodes
length
lengthOfBytesUsingEncoding:
locale
localeIdentifier
localeWithLocaleIdentifier:
localizedDescription
localizedStringForKey:value:table:
loggingComponent
loggingComponentString
longValue
lowInt
mainBundle
matchSpans:
matchSpansForDetectedData:
matchSpansForUtterance:
matcherNamesAtIndex:
matcherNamesCount
matcherWithDirectories:initialApplicationInfos:initializeModelsPreemptively:error:
matchingSpans
matchingSpansAtIndex:
matchingSpansCount
modelAssetsDirectoryURL
modelBundle
modelInfo
modelWithLoadedModelConfiguration:error:
multiTurnPredictionFromQuery:modelIdentifierToDomainResults:dialogAct:error:
mutableBytes
nSStringToU16String:
nlContext
nluRequestId
null
numToken
numberWithDouble:
numberWithFloat:
numberWithUnsignedInteger:
numberWithUnsignedLong:
objectAtIndex:
objectAtIndexedSubscript:
objectForKey:
objectForKeyedSubscript:
offerContextualizerStrategy
offeredAct
open
optionsContextualizerStrategy
outputTokens
parserEspressoModelPath
parserEspressoModule
parserModel
path
performFullCacheUpdate:
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
prebuiltIntentThreshold
predictionFromProtobufQuery:error:
predictionFromQuery:error:
predictionFromQuery:preprocessorOutput:error:
preprocess:error:
preprocessor
printedForm
probability
promptContextualizerStrategy
protobufRepresentation
query
queryUUID
range
rangeFromStart:end:
rangeOfString:
reference
registerApp:error:
replaceObjectAtIndex:withObject:
requestId
resolveSharedEntityForTokenRange:valueType:
resolver
respondsToSelector:
responseForRequest:error:
resultWithContextualizerInput:
retain
retainCount
rootNode
rootNodeRepresentation
rootNodeRepresentationForIntent:andEntities:
scoreFromQuery:preprocessorOutput:error:
self
semanticValue
serializeFromIntent:andEntities:forBundleId:
setAlgorithm:
setClassificationLabel:
setClassificationProbability:
setConfidenceThreshold:
setEmbedderId:
setEmbeddingDim:
setEmbeddingTensor:
setEmbeddingTensorOutputs:
setEmbeddings:
setLocale:
setMatchingSpans:
setNluRequestId:
setNumLayer:
setNumToken:
setObject:atIndexedSubscript:
setObject:forKey:
setObject:forKeyedSubscript:
setParser:
setParserId:
setReference:
setRequestId:
setSentenceEmbeddingTensor:
setSubwordEmbeddingTensorOutputs:
setSubwordTokenChain:
setTokenChain:
setTokenisedUtterance:
setTurnInput:
setUserDialogActs:
setValues:count:
setWithArray:
sharedEntityGraph
singleTurnPredictionFromDomainResults:
sortedArrayUsingDescriptors:
spanLabelsTensor
spanVocabPath
spanVocabularyURL
spans
stdU16ToNSString:
string
stringByDeletingLastPathComponent
stringByReplacingOccurrencesOfString:withString:
stringForModelType:
stringLabel
stringWithCString:encoding:
stringWithCapacity:
stringWithCharacters:length:
stringWithFormat:
stringWithUTF8String:
subarrayWithRange:
substringFromIndex:
substringToIndex:
superclass
systemDialogActs
systemDialogActsCount
targetVocabularyURL
task
text
toCppUsoGraph:withError:
tokenChain
tokenDescription:
tokenisedUtterance
tokens
tokensAtIndex:
tokensCount
trySetSimulatorError:
turnContext
turnInput
type
uncalibratedProbability
usoGraph
usoSerializer
utterance
uuid
value
valueForKey:
valuesAtIndex:
valuesCount
versionURL
warmup
zone
@32@0:8@16^@24
@24@0:8^{_NSZone=}16
@24@0:8@16
B24@0:8@16
Q16@0:8
@16@0:8
v16@0:8
@"NSUUID"
@"NSString"
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B16@0:8
B24@0:8#16
B24@0:8:16
Vv16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
@"UPResult"24@0:8@"UPContextualizerInput"16
@32@0:8d16@24
d16@0:8
@"UPUsoSerializer"
@24@0:8d16
@48@0:8@16@24@32^@40
@40@0:8@16@24@32
@"NSURL"
@48@0:8{_NSRange=QQ}16@32^{__DDResult=}40
@56@0:8{_NSRange=QQ}16@32^{__DDResult=}40@48
^{__DDResult=}16@0:8
^{__DDResult=}
@"USOSerializedGraph"
@80@0:8@16@24@32@40@48@56@64^@72
@72@0:8@16@24@32@40@48@56@64
@32@0:8@16@24
@64@0:8@16@24@32@40@48@56
@"UPParserModel"
@"NSSet"
@"UPCalibration"
@"UPDialogActConverter"
@"UPContextualizer"
@48@0:8@16@24@32@40
@52@0:8r^v16f24r^v28@36@44
{UPInferenceResult={UPGenericTensor={vector<unsigned long, std::allocator<unsigned long>>=^Q^Q{__compressed_pair<unsigned long *, std::allocator<unsigned long>>=^Q}}{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}}{UPGenericTensor={vector<unsigned long, std::allocator<unsigned long>>=^Q^Q{__compressed_pair<unsigned long *, std::allocator<unsigned long>>=^Q}}{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}}{UPGenericTensor={vector<unsigned long, std::allocator<unsigned long>>=^Q^Q{__compressed_pair<unsigned long *, std::allocator<unsigned long>>=^Q}}{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}}}120@0:8{UPGenericTensor={vector<unsigned long, std::allocator<unsigned long>>=^Q^Q{__compressed_pair<unsigned long *, std::allocator<unsigned long>>=^Q}}{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}}16{UPGenericTensor={vector<unsigned long, std::allocator<unsigned long>>=^Q^Q{__compressed_pair<unsigned long *, std::allocator<unsigned long>>=^Q}}{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}}64@112
@56@0:8r^v16@24r^v32^v40@48
@56@0:8r^v16r^v24r^v32^v40@48
@40@0:8@16@24^@32
@"UPModelIdentifier"
@"UPLoadedModelConfiguration"
@48@0:8@16@24@?32^@40
@?16@0:8
{unique_ptr<const sirinluinternalitfm::ITFMParserRequest, std::default_delete<const sirinluinternalitfm::ITFMParserRequest>>={__compressed_pair<const sirinluinternalitfm::ITFMParserRequest *, std::default_delete<const sirinluinternalitfm::ITFMParserRequest>>=^{ITFMParserRequest}}}24@0:8@16
@72@0:8{ITFMParserResponse=^^?{PtrVector<sirinluinternalitfm::ITFMHypothesis>={vector<std::unique_ptr<sirinluinternalitfm::ITFMHypothesis>, std::allocator<std::unique_ptr<sirinluinternalitfm::ITFMHypothesis>>>=^v^v{__compressed_pair<std::unique_ptr<sirinluinternalitfm::ITFMHypothesis> *, std::allocator<std::unique_ptr<sirinluinternalitfm::ITFMHypothesis>>>=^v}}}{unique_ptr<sirinluexternal::Parser, std::default_delete<sirinluexternal::Parser>>={__compressed_pair<sirinluexternal::Parser *, std::default_delete<sirinluexternal::Parser>>=^{Parser}}}fB{?=b1b1}}16
{unique_ptr<snlp::common::asset_logger::SNLPAssetLogger, std::default_delete<snlp::common::asset_logger::SNLPAssetLogger>>={__compressed_pair<snlp::common::asset_logger::SNLPAssetLogger *, std::default_delete<snlp::common::asset_logger::SNLPAssetLogger>>=^{SNLPAssetLogger}}}16@0:8
{unique_ptr<itfm_inference_orchestrator::orchestration::ITFMOrchestrator, std::default_delete<itfm_inference_orchestrator::orchestration::ITFMOrchestrator>>="__ptr_"{__compressed_pair<itfm_inference_orchestrator::orchestration::ITFMOrchestrator *, std::default_delete<itfm_inference_orchestrator::orchestration::ITFMOrchestrator>>="__value_"^{ITFMOrchestrator}}}
{unique_ptr<snlp::common::asset_logger::SNLPAssetLogger, std::default_delete<snlp::common::asset_logger::SNLPAssetLogger>>="__ptr_"{__compressed_pair<snlp::common::asset_logger::SNLPAssetLogger *, std::default_delete<snlp::common::asset_logger::SNLPAssetLogger>>="__value_"^{SNLPAssetLogger}}}
@"SNLPITFMModelBundle"
@"SNLPITFMModelInfo"
@32@0:8r^v16r^{UsoGraphNode=^^?^{UsoGraph}Q}24
@40@0:8{vector<std::pair<std::reference_wrapper<siri::ontology::UsoGraphNode>, std::reference_wrapper<const siri::ontology::UsoGraphEdge>>, std::allocator<std::pair<std::reference_wrapper<siri::ontology::UsoGraphNode>, std::reference_wrapper<const siri::ontology::UsoGraphEdge>>>>=^v^v{__compressed_pair<std::pair<std::reference_wrapper<siri::ontology::UsoGraphNode>, std::reference_wrapper<const siri::ontology::UsoGraphEdge>> *, std::allocator<std::pair<std::reference_wrapper<siri::ontology::UsoGraphNode>, std::reference_wrapper<const siri::ontology::UsoGraphEdge>>>>=^v}}16
@32@0:8@16r^v24
v40@0:8@16^v24^{UsoGraphNode=^^?^{UsoGraph}Q}32
v80@0:8@16{_NSRange=QQ}24@40@48@56^{UsoGraphNode=^^?^{UsoGraph}Q}64^v72
v48@0:8@16r^v24^{UsoGraphNode=^^?^{UsoGraph}Q}32^v40
{shared_ptr<siri::ontology::UsoVocabManager>="__ptr_"^{UsoVocabManager}"__cntrl_"^{__shared_weak_count}}
@32@0:8@16d24
@56@0:8@16@24@32@40^@48
@64@0:8@16@24@32@40@48^@56
@72@0:8d16@24@32@40@48@56@64
@"NSObject<SIRINLUUserDialogAct>"
@"NSNumber"
@"NSArray"
@"NSDictionary"
@"UPCalibrationModel"
@"UPPreprocessor"
f16@0:8
v20@0:8f16
@"UPEntityWithValue"
@136@0:8{UPGenericTensor={vector<unsigned long, std::allocator<unsigned long>>=^Q^Q{__compressed_pair<unsigned long *, std::allocator<unsigned long>>=^Q}}{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}}16{UPGenericTensor={vector<unsigned long, std::allocator<unsigned long>>=^Q^Q{__compressed_pair<unsigned long *, std::allocator<unsigned long>>=^Q}}{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}}64{vector<nl_featurization::Token, std::allocator<nl_featurization::Token>>=^{Token}^{Token}{__compressed_pair<nl_featurization::Token *, std::allocator<nl_featurization::Token>>=^{Token}}}112
^v16@0:8
{UPGenericTensor="shape"{vector<unsigned long, std::allocator<unsigned long>>="__begin_"^Q"__end_"^Q"__end_cap_"{__compressed_pair<unsigned long *, std::allocator<unsigned long>>="__value_"^Q}}"data"{vector<float, std::allocator<float>>="__begin_"^f"__end_"^f"__end_cap_"{__compressed_pair<float *, std::allocator<float>>="__value_"^f}}}
{vector<nl_featurization::Token, std::allocator<nl_featurization::Token>>="__begin_"^{Token}"__end_"^{Token}"__end_cap_"{__compressed_pair<nl_featurization::Token *, std::allocator<nl_featurization::Token>>="__value_"^{Token}}}
@56@0:8{SubwordTokenChain=^^?{unique_ptr<std::string, std::default_delete<std::string>>={__compressed_pair<std::string *, std::default_delete<std::string>>=^v}}{PtrVector<sirinluinternal::SubwordToken>={vector<std::unique_ptr<sirinluinternal::SubwordToken>, std::allocator<std::unique_ptr<sirinluinternal::SubwordToken>>>=^v^v{__compressed_pair<std::unique_ptr<sirinluinternal::SubwordToken> *, std::allocator<std::unique_ptr<sirinluinternal::SubwordToken>>>=^v}}}}16
{unique_ptr<nlv4_inference_orchestrator::orchestration::EmbedderOrchestrator, std::default_delete<nlv4_inference_orchestrator::orchestration::EmbedderOrchestrator>>="__ptr_"{__compressed_pair<nlv4_inference_orchestrator::orchestration::EmbedderOrchestrator *, std::default_delete<nlv4_inference_orchestrator::orchestration::EmbedderOrchestrator>>="__value_"^{EmbedderOrchestrator}}}
B40@0:8@16d24@32
@56@0:8@16@24@32@40@48
@40@0:8@16@24@?32
B32@0:8@16^@24
{_NSRange=QQ}32@0:8Q16Q24
{basic_string<char16_t, std::char_traits<char16_t>, std::allocator<char16_t>>={__compressed_pair<std::basic_string<char16_t>::__rep, std::allocator<char16_t>>={__rep=(?={__long=^SQb63b1}{__short=[11S][1C]b7b1}{__raw=[3Q]})}}}24@0:8@16
@24@0:8r^v16
Q24@0:8@16
@56@0:8{_NSRange=QQ}16Q32@40@48
@48@0:8{_NSRange=QQ}16Q32@40
{_NSRange=QQ}16@0:8
@"SIRINLUEXTERNALUsoGraph"
{_NSRange="location"Q"length"Q}
d120@0:8{UPGenericTensor={vector<unsigned long, std::allocator<unsigned long>>=^Q^Q{__compressed_pair<unsigned long *, std::allocator<unsigned long>>=^Q}}{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}}16{UPGenericTensor={vector<unsigned long, std::allocator<unsigned long>>=^Q^Q{__compressed_pair<unsigned long *, std::allocator<unsigned long>>=^Q}}{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}}64@112
@40@0:8{_NSRange=QQ}16@32
@32@0:8@16r^{__CFArray=}24
r^{__CFArray=}16@0:8
r^{__CFArray=}
@32@0:8^{__CFArray=}16@24
^{UPDataDetector=q^{__DDScanner}^{__DDScanner}^{__DDScanner}^{__DDScanner}^{__DDScanner}^{__DDScanner}}16@0:8
^{UPDataDetector=q^{__DDScanner}^{__DDScanner}^{__DDScanner}^{__DDScanner}^{__DDScanner}^{__DDScanner}}
@"UPResult"
@"UPQuery"
@"<UPDialogAct>"
^{EspressoModule=^v^v{?=^vi}}16@0:8
@"NSLocale"
^{EspressoModule=^v^v{?=^vi}}
@32@0:8@16Q24
@24@0:8q16
q16@0:8
@"<SIRINLUSystemDialogAct><NSObject>"
@72@0:8{_NSRange=QQ}16@32@40@48@56@64
{vector<nl_featurization::span_matching::MatchedSpan, std::allocator<nl_featurization::span_matching::MatchedSpan>>=^{MatchedSpan}^{MatchedSpan}{__compressed_pair<nl_featurization::span_matching::MatchedSpan *, std::allocator<nl_featurization::span_matching::MatchedSpan>>=^{MatchedSpan}}}24@0:8@16
@32@0:8@16r^{AbstractFeaturizer=^^?}24
r^{AbstractFeaturizer=^^?}
@24@0:8{unique_ptr<nlv4_inference_orchestrator::orchestration::NLv4InferenceOrchestrator, std::default_delete<nlv4_inference_orchestrator::orchestration::NLv4InferenceOrchestrator>>={__compressed_pair<nlv4_inference_orchestrator::orchestration::NLv4InferenceOrchestrator *, std::default_delete<nlv4_inference_orchestrator::orchestration::NLv4InferenceOrchestrator>>=^{NLv4InferenceOrchestrator}}}16
{unique_ptr<nlv4_inference_orchestrator::orchestration::NLv4InferenceOrchestrator, std::default_delete<nlv4_inference_orchestrator::orchestration::NLv4InferenceOrchestrator>>="__ptr_"{__compressed_pair<nlv4_inference_orchestrator::orchestration::NLv4InferenceOrchestrator *, std::default_delete<nlv4_inference_orchestrator::orchestration::NLv4InferenceOrchestrator>>="__value_"^{NLv4InferenceOrchestrator}}}
@36@0:8@16i24^@28
@24@0:8Q16
@36@0:8Q16i24@28
i16@0:8
@"UPContextualizerStrategyCancel"
@"UPContextualizerStrategyOffer"
@"UPContextualizerStrategyOptions"
@"UPContextualizerStrategyPrompt"
B32@0:8@16@24
B40@0:8@16@24Q32
B40@0:8@16@24@32
Q24@0:8r^i16
@44@0:8@16@24B32^@36
v24@0:8^@16
B24@0:8^@16
