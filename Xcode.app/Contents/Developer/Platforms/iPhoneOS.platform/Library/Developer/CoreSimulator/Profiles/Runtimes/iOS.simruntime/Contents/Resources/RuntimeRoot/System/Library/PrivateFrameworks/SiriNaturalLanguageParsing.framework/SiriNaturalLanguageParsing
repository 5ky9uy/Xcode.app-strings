@(#)PROGRAM:SiriNaturalLanguageParsing  PROJECT:SiriNaturalLanguageParsing-1
NSt3__16__nodeIcEE
NSt3__110shared_ptrINS_13__empty_stateIcEEE27__shared_ptr_default_deleteIS2_S2_EE
NSt3__113__empty_stateIcEE
NSt3__120__l_anchor_multilineIcEE
NSt3__120__r_anchor_multilineIcEE
NSt3__115__word_boundaryIcNS_12regex_traitsIcEEEE
NSt3__111__lookaheadIcNS_12regex_traitsIcEEEE
NSt3__123__match_any_but_newlineIcEE
NSt3__120__match_char_collateIcNS_12regex_traitsIcEEEE
NSt3__118__back_ref_collateIcNS_12regex_traitsIcEEEE
NSt3__128__begin_marked_subexpressionIcEE
NSt3__126__end_marked_subexpressionIcEE
NSt3__16__loopIcEE
NSt3__117__repeat_one_loopIcEE
NSt3__121__empty_non_own_stateIcEE
<N4siri8ontology12UsoGraphNodeE
N4uaap19DateDurationHandlerE
N4uaap23AbstractDateTimeHandlerE
N4snlp6common14text_uso_graph26UsoGraphTextTreeParseErrorE
N4snlp6common14text_uso_graph21UDATextTreeParseErrorE
N4uaap8UPDDSpanE
N4uaap12UPDDTimeSpanE
N4uaap20UPDDDateTimeBaseSpanE
N4uaap11TimeHandlerE
N4uaap12UPDDDateSpanE
N4uaap15DateSpanHandlerE
N4uaap11DateHandlerE
N4snlp6common9exception18SNLPAssetExceptionE
N8nlohmann6detail9exceptionE
false
N8nlohmann6detail12out_of_rangeE
NSt3__117bad_function_callE
N8nlohmann6detail16invalid_iteratorE
N8nlohmann6detail10type_errorE
N8nlohmann6detail11parse_errorE
NSt3__118basic_stringstreamIcNS_11char_traitsIcEENS_9allocatorIcEEEE
NSt3__120__shared_ptr_emplaceIN27snlc_inference_orchestrator10vocabulary10VocabularyENS_9allocatorIS3_EEEE
vH7B
W4vC
9Y>)F$
raB3G
)c=H
]rHa
O8Mr
bnMG
.wN9
[*QmU
mr"iR
R$N(
>S}W
-sSO\
T%L9
hGT.
B}T}
=@[V
!a9X
X5AHx
%4xY
Z~$|7
+\0I
2a\|
\ysK
|M$D
pH_r
(:W"
s\ax}?
pc2g
@BXV
tC7Ddx
EydV
d66
eax~Z
ekhHD
@iZb
k0V(
k*do^
:V!2m
RJqn
bzo=
$qE}
XqkY
quAt
Jugm
~B v
STv/N
_w&2
xg^Jp5|
yMzw
{zel#|67
P/};
[@JO
nQ:B
N4snlp6common14text_uso_graph20ExactMatchComparatorE
N4snlp6common14text_uso_graph18UsoGraphComparatorE
false
N4snlp6common14text_uso_graph16ActionListParserE
N4snlp6common14text_uso_graph14TextTreeParserE
N4siri8ontology17OntologyExceptionE
N4siri8ontology21OntologyBaseExceptionE
N4snlp6common14text_uso_graph22UsoGraphTextTreeParserE
N4siri8ontology17IsNameTypeVisitorINS0_16OntologyNodeNameEEE
N4siri8ontology16NoOpONameVisitorE
N4siri8ontology19OntologyNameVisitorE
N4siri8ontology17IsNameTypeVisitorINS0_16OntologyVerbNameEEE
N4siri8ontology17IsNameTypeVisitorINS0_16OntologyEdgeNameEEE
?primitive_StringN4uaap20UPDDTimeDurationSpanE
N4uaap19TimeDurationHandlerE
N4uaap16UPDDDateTimeSpanE
N4uaap15DateTimeHandlerE
N4uaap25UPDDSpecialDatePeriodSpanE
N4uaap20UPDDAbsoluteDateSpanE
N4uaap18UPDDDateOffsetSpanE
N4snlp6common9exception13SNLPExceptionE
NSt3__114basic_ifstreamIcNS_11char_traitsIcEEEE
NSt3__113basic_filebufIcNS_11char_traitsIcEEEE
false
NSt3__119basic_ostringstreamIcNS_11char_traitsIcEENS_9allocatorIcEEEE
NSt3__115basic_stringbufIcNS_11char_traitsIcEENS_9allocatorIcEEEE
N4siri8ontology16OntologyUnitNameE
N5boost6detail17sp_counted_impl_pINS_6random23mersenne_twister_engineIjLm32ELm624ELm397ELm31ELj2567483615ELm11ELj4294967295ELm7ELj2636928640ELm15ELj4022730752ELm18ELj1812433253EEEEE
N5boost6detail15sp_counted_baseE
N5boost16exception_detail10clone_implINS0_19error_info_injectorISt13runtime_errorEEEE
N5boost16exception_detail19error_info_injectorISt13runtime_errorEE
N5boost9exceptionE
N5boost16exception_detail10clone_baseE
N5boost16exception_detail10clone_implINS0_19error_info_injectorISt16invalid_argumentEEEE
N5boost16exception_detail19error_info_injectorISt16invalid_argumentEE
NSt3__111__end_stateIcEE
NSt3__120__shared_ptr_pointerIPNS_13__empty_stateIcEENS_10shared_ptrIS2_E27__shared_ptr_default_deleteIS2_S2_EENS_9allocatorIS2_EEEE
NSt3__116__owns_one_stateIcEE
NSt3__115__has_one_stateIcEE
NSt3__118__match_char_icaseIcNS_12regex_traitsIcEEEE
NSt3__112__match_charIcEE
NSt3__116__back_ref_icaseIcNS_12regex_traitsIcEEEE
NSt3__110__back_refIcEE
NSt3__120__bracket_expressionIcNS_12regex_traitsIcEEEE
NSt3__117__owns_two_statesIcEE
NSt3__111__alternateIcEE
NSt3__111__match_anyIcEE
N27nlv4_inference_orchestrator13span_matching36RelativeThresholdMatchingSpansFilterE
N27nlv4_inference_orchestrator13span_matching19MatchingSpansFilterE
N4uaap15TimeSpanHandlerE
false
?N4snlp6common14text_uso_graph19SpacedTextTreeLexerE
N4snlp6common14text_uso_graph13TextTreeLexerE
N4snlp6common14text_uso_graph17UDATextTreeParserE
N16nl_featurization14FeaturizerImplE
N16nl_featurization18AbstractFeaturizerE
N10global_ner12post_process20GeographicAreaEntityE
N10global_ner12post_process22PersonalLocationEntityE
N10global_ner12post_process18EmailAddressEntityE
N10global_ner9inference16NerEspressoModelE
N10global_ner9inference13EspressoModelE
N10global_ner12post_process14CurrencyEntityE
N10global_ner12post_process6EntityE
N10global_ner12post_process18BusinessNameEntityE
N10global_ner12post_process13AppNameEntityE
N10global_ner12post_process21MeasurementUnitEntityE
N10global_ner12post_process26MeasurementComponentEntityE
N10global_ner12post_process17PhoneNumberEntityE
N10global_ner12post_process17OtherPersonEntityE
N10global_ner12post_process12NumberEntityE
N10global_ner12post_process17MeasurementEntityE
++Dq
UserAccepted
UserStatedTask
[insights-snlp-snlc]: 
[insights-snlp-nlv4]: 
[insights-snlp-uaap]: 
component_name
old_prediction
hidden
memory
encodings
num_of_utterance_tokens
attention_index
out_predictions
out_new_hidden
out_new_memory
out_new_attention_index
-[UPContextualizerStrategyPrompt resultUsingContextualizerInput:]
UPContextualizerStrategyPrompt.m
[dialogAct isKindOfClass:[UPDialogActPrompt class]]
config.json
version.yaml
^VERSION: (\w+)\.(\d+)\.(\d+)
Version file not found at path: 
Version file has no parseable version key: 
sha256HashForFileContent
SNLPUtilities-cpp.mm
buffer != NULL
bufferSize > 0
%02x
.DS_Store
bolt_task_id
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
-[UPContextualizerStrategyOffer resultUsingContextualizerInput:]
UPContextualizerStrategyOffer.m
[contextualizerInput.dialogAct isKindOfClass:[UPDialogActOffer class]]
label
tokenIndicesIndex
[%lu, %lu)
forward
espresso_transformer_model.cpp
firstDecoderOutput.prediction.data.size() == firstDecoderOutput.prediction.shape[1]
input.maxNumHypotheses >= topIndicesAndScores.size()
input.maxNumHypotheses >= hypotheses.size()
decoderOutput.prediction.data.size() == decoderOutput.prediction.shape[1]
input.maxNumHypotheses >= topIndicesAndScoresInner.size()
Token overflow; received 
 tokens, expected 
 or fewer tokens.
padEmbeddings
paddedDataRowLength >= unpaddedDataRowLength
NLv4
SNLC
UaaP
PLUM
UNKNOWN
getComponentString
SNLPLoggingConstants.mm
(size_t)SNLPComponent::_SNLPComponentCount == componentToLogStringMap.size()
<UNDEFINED_COMPONENT>
unordered_map::at: key not found
insertToken
snlc_vocabulary.cpp
mIdToText.size() == mTextToId.size()
[UNK]
[PAD]
[CLS]
[SEP]
Could not open vocabulary data file: 
tokenText argument is empty
Encountered unknown token text and the vocabulary hasno special unknown token
Encountered unknown token ID
map::at:  key not found
vocabulary.cpp
-[UPQueryRunner combinedResultFromResults:]
UPQueryRunner.mm
[queryUUIDs count] == 1
batch_size
max_num_utterance_embeddings
max_num_context_tokens
max_num_spans_tokens
utterance_tokens_embedder_emb_dim
Unknown
CustomVerb
Searching for span with UTF-16 indices (
common_Date
common_Timer
Found matching span with graph:
) vs (
Found a matching insertable span 
Found a new max score, 
, for a non-matching insertable span 
Found a common_Time span with a Jaccard score of 
, overwriting the common_Date span with a Jaccard score of 
UPDialogActPrompt[intent: %@, entityType: %@, entityName: %@, reference: %@]
span_indices
token_embeddings
intent_softmax
app_label_softmax
bio_labels_softmax
group_labels_softmax
-[UPParserModel _resultFromInferenceResult:query:outputTokens:dataDetectorSpans:resolver:]
UPParserModel.mm
intentSoftmaxTensor.shape.size() == 2
intentSoftmaxTensor.shape[0] == 1
intentSoftmaxTensor.shape[1] == numIntents
bioLabelsSoftmaxTensor.shape.size() == 3
bioLabelsSoftmaxTensor.shape[0] == numTokens
bioLabelsSoftmaxTensor.shape[1] == 1
bioLabelsSoftmaxTensor.shape[2] == numBioTags
Espresso context is nil.
Espresso plan is nil.
Could not create espresso plan.
Failed to build espresso plan.
Failed to execute espresso plan.
Failed to clean up espresso plan.
Failed to reshape espresso blob.
Failed to bind buffer to input 
Failed to bind buffer to output 
findBorderScore
beam_search.cpp
kBeamwidth + 1u == sortedTopScores.size()
getTopKTokenIndicesAndScores
kBeamwidth >= indicesAndScoresOfTopScores.size()
applyLogSoftmax
kDimensionality == scores.size()
type
value
children
group_name_transform
smsGroupName
personFullName
Failed to parse 
^ *"(.*)"
^ *(\d+)
^ *([a-zA-Z0-9:_]+)
^ *:([a-zA-Z0-9:_]+)
^ *\n( *)
^ */ *([a-zA-Z0-9:_]+)
^ *\[(\d+):(\d+)\]
com.apple.uaapcustomluframework
resolveNow
TimeHandler.cpp
timeSpan
resolveTimeAndMeridian
resolveDateTimeRangeValue
resolveSpecialTimePeriod
resolveDateTimeQualifierListValue
dtBaseSpan
resolveOffsetDurationValue
resolveTimeWithOffsetValueAndDirection
resolveTime
The month of year value should range from 1 to 12
resolveDateTimeRangeSpanGraph
DateSpanHandler.cpp
dateSpan
resolveRecurringDateSpan
semanticValue
unknownCustomEntity
-[UPUsoSerializer init]
UPUsoSerializer.mm
self != nil
unknownCustomVerb
-[UPUsoSerializer deserializeFromSerializedGraph:]
rootTaskSuccessors.size() == 1
rootTaskSuccessors.at(0).get().getNodeType() == ontology::type::UsoGraphNodeType::TaskNode
UPStructuredData[
[type = 
, value = 
extractStructuredDataInner
UPDataDetectorStructuredData.cpp
resultTypeRef != NULL
resultStartIndex < resultEndIndex
DateHandler.cpp
resolveOffsetDirection
offsetSpan
resolveOffsetDurationValueAndUnit
resolveDurationValueAndUnit
resolveOffsetReference
DataDetectorService
resolveDateOffset
resolveRelativeDayOfWeek
relativeDayOfWeekSpan
resolveRelativeDay
relativeDaySpan
resolveDate
contact_type_split
contactType
emailType
nullptr
string_view::substr
The SNLC asset version (
) is incompatible with inference runtime (compatible versions 
SNLC Orchestrator failed with incompatible major version
Request does not contain a tokenised utterance
Request does not contain a token chain
Request does not contain embeddings
Request embeddings num tokens (
) does not match actual num tokens (
Request embeddings (
) exceeds maximum (
Received null input parser request
runSNLC
espresso_snlc_orchestrator.cpp
indexedTokens.size() <= requestNumTokens
requestEmbeddingValues.size() <= maxNumEmbeddingValues
truncatedSpans.size() == numMatchingSpans
featurizedContext.data.size() <= maxNumContextTokens
featurizedContext.data.size() <= paddedFeaturizedContext .size()
spanFeaturization.shape.size() == 3
indexedTokens.size() <= mask.size()
ERROR: Could not find the config file 
INFO: The parameter 
 is null.  This is currently expected behaviour.
WARNING: Could not parse the config parameter 
json.hpp
[json.exception.
assert_invariant
m_type != value_t::object || m_value.object != nullptr
m_type != value_t::array || m_value.array != nullptr
m_type != value_t::string || m_value.string != nullptr
m_type != value_t::binary || m_value.binary != nullptr
get_decimal_point
loc != nullptr
invalid BOM; must be 0xEF 0xBB 0xBF if given
invalid literal
unget
!token_string.empty()
invalid comment; missing closing '*/'
invalid comment; expecting '/' or '*' after '/'
scan_literal
std::char_traits<char_type>::to_char_type(current) == literal_text[0]
scan_string
current == '\"'
invalid string: missing closing quote
invalid string: '\u' must be followed by 4 hex digits
invalid string: surrogate U+D800..U+DBFF must be followed by U+DC00..U+DFFF
invalid string: surrogate U+DC00..U+DFFF must follow U+D800..U+DBFF
0x00 <= codepoint && codepoint <= 0x10FFFF
invalid string: forbidden character after backslash
invalid string: control character U+0000 (NUL) must be escaped to \u0000
invalid string: control character U+0001 (SOH) must be escaped to \u0001
invalid string: control character U+0002 (STX) must be escaped to \u0002
invalid string: control character U+0003 (ETX) must be escaped to \u0003
invalid string: control character U+0004 (EOT) must be escaped to \u0004
invalid string: control character U+0005 (ENQ) must be escaped to \u0005
invalid string: control character U+0006 (ACK) must be escaped to \u0006
invalid string: control character U+0007 (BEL) must be escaped to \u0007
invalid string: control character U+0008 (BS) must be escaped to \u0008 or \b
invalid string: control character U+0009 (HT) must be escaped to \u0009 or \t
invalid string: control character U+000A (LF) must be escaped to \u000A or \n
invalid string: control character U+000B (VT) must be escaped to \u000B
invalid string: control character U+000C (FF) must be escaped to \u000C or \f
invalid string: control character U+000D (CR) must be escaped to \u000D or \r
invalid string: control character U+000E (SO) must be escaped to \u000E
invalid string: control character U+000F (SI) must be escaped to \u000F
invalid string: control character U+0010 (DLE) must be escaped to \u0010
invalid string: control character U+0011 (DC1) must be escaped to \u0011
invalid string: control character U+0012 (DC2) must be escaped to \u0012
invalid string: control character U+0013 (DC3) must be escaped to \u0013
invalid string: control character U+0014 (DC4) must be escaped to \u0014
invalid string: control character U+0015 (NAK) must be escaped to \u0015
invalid string: control character U+0016 (SYN) must be escaped to \u0016
invalid string: control character U+0017 (ETB) must be escaped to \u0017
invalid string: control character U+0018 (CAN) must be escaped to \u0018
invalid string: control character U+0019 (EM) must be escaped to \u0019
invalid string: control character U+001A (SUB) must be escaped to \u001A
invalid string: control character U+001B (ESC) must be escaped to \u001B
invalid string: control character U+001C (FS) must be escaped to \u001C
invalid string: control character U+001D (GS) must be escaped to \u001D
invalid string: control character U+001E (RS) must be escaped to \u001E
invalid string: control character U+001F (US) must be escaped to \u001F
invalid string: ill-formed UTF-8 byte
get_codepoint
current == 'u'
0x0000 <= codepoint && codepoint <= 0xFFFF
next_byte_in_range
ranges.size() == 2 || ranges.size() == 4 || ranges.size() == 6
scan_number
false
invalid number; expected digit after '-'
invalid number; expected digit after '.'
invalid number; expected '+', '-', or digit after exponent
invalid number; expected digit after exponent sign
endptr == token_buffer.data() + token_buffer.size()
object key
object separator
number overflow parsing '
sax_parse_internal
!states.empty()
array
object
excessive object size: 
handle_value
!keep_stack.empty()
ref_stack.back()->is_array() || ref_stack.back()->is_object()
!key_keep_stack.empty()
object_element
end_object
!ref_stack.empty()
operator->
m_object != nullptr
m_it.object_iterator != m_object->m_value.object->end()
m_it.array_iterator != m_object->m_value.array->end()
cannot get value
invalid_iterator
iterator does not fit current value
iterator out of range
cannot use erase() with 
type_error
null
string
boolean
binary
discarded
number
excessive array size: 
end_array
out_of_range
<U+%.4X>
parse_error
parse error
 at line 
, column 
syntax error 
while parsing 
; last read: '
unexpected 
; expected 
<uninitialized>
true literal
false literal
null literal
string literal
number literal
<parse error>
end of input
'[', '{', or a literal
unknown token
iter_impl
set_begin
cannot compare iterators of different containers
operator==
set_end
cannot use key() for non-object iterators
operator*
type must be number, but is 
type must be boolean, but is 
type must be string, but is 
operator++
SystemGaveOptions
SystemOffered
executed_task
salient_entity
active_task
sdas
executed_tasks
salient_entities
active_tasks
_type=
_full_path=
_verb_entity=
_verb=
_below_verb=
_are_present
_are_absent
[NO_SDAS]
source_tokens_embeddings
matched_spans
context
source_mask
class_probabilities
cancel
notForMe
selectOrdinal
ordinal
[NO_LEGACY_NL_CONTEXT_LABEL]
DICTATION_PROMPT=
STRICT_PROMPT=
PREVIOUS_NLV3_DOMAIN=
TRUE
FALSE
extractContextLabels
snlc_context_featurizer.cpp
!contextLabelsFromLegacyNlContext.empty()
featurize
featurizedContextStringsSorted.size() == mMaxNumContextTokens + truncatedFeatures.size()
featurizedContext.shape.size() == Embedder::kEmbeddedTensorRank
featurizedContext.shape.at(0) == Embedder::kEmbeddedTensorBatchSize
shape = 
 data = 
placeholderVerb
((\w+)::common_(\w+)(\.)?(\w+))
::common
SystemPrompted
SystemOffered.offered_act.
SystemGaveOptions.option.
SystemInformed.entity
SystemReportedSuccess
SystemReportedFailure
_verb_entity
SystemOffered.offered_act.UserStatedTask
SystemOffered.offered_act.UserWantedToProceed
.primitive_String
UserAcknowledged
UserCancelled
UserRejected
UserWantedToPause
UserWantedToProceed
UserWantedToRepeat
SystemInformed
contact_address_downcast
emailAddress
phoneNumber
min_max_labeller
minimumMaximum
floatSettingState
minimum
maximum
de_DE
en_AU
en_CA
en_GB
en_IN
en_US
fr_FR
enum-choices
left-label
name
open-list-choices
repeated
resolution-table
right-labels
rules
semantic-value
synonyms
value-constraints
Error parsing JSON grammar: row.IsObject() == false [for key: 
 entry
Error parsing JSON grammar: parsedSemanticValue != row.MemberEnd() && parsedSemanticValue->value.IsString() == false [for key: 
Error parsing JSON grammar: parsedSynonyms != row.MemberEnd() && parsedSynonyms->value.IsArray() == false [for key: 
Error parsing JSON grammar: parsedSynonym.IsString() == false [for key: 
Error parsing JSON grammar: parsedValueType->value.IsString() == false [for key: 
Error parsing JSON grammar: parsedEnumChoices->value.IsArray() == false [for key: 
Error parsing JSON grammar: parsedOpenListChoices->value.IsArray() == false [for key: 
Error parsing JSON grammar: parsedResolutionTable->value.IsArray() == false [for key: 
Error parsing JSON grammar: leftLabel != jsonRule.MemberEnd() && leftLabel->value.IsString() == false [for key: 
Error parsing JSON grammar: parsedValueConstraints->value.IsObject() == false [for key: 
Error parsing JSON grammar: parsedRightLabels != jsonRule.MemberEnd() && parsedRightLabels->value.IsArray() == false [for key: 
Error parsing JSON grammar: rightLabelObject.IsObject() == false [for key: 
Error parsing JSON grammar: parsedName != rightLabelObject.MemberEnd() && parsedName->value.IsString() == false [for key: 
Error parsing JSON grammar: parsedRepeatedFlag != rightLabelObject.MemberEnd() && parsedRepeatedFlag->value.IsBool() == false [for key: 
Could not open grammar file for reading: 
Grammar file is in error state after reading: 
Label does not exist
getChildrenPathsInner
grammar.cpp
!currentPath.components.empty()
Error parsing JSON grammar: jsonGrammar.IsObject() == false [for key: 
(root)
Error parsing JSON grammar: parsedRules != jsonGrammar.MemberEnd() && parsedRules->value.IsArray() == false [for key: 
FileReadStream
filereadstream.h
fp_ != 0
bufferSize >= 4
GetString
document.h
IsString()
GetStringLength
GetArray
IsArray()
Begin
MemberEnd
IsObject()
Size
Error parsing JSON grammar: enumChoice.IsString() == false [for key: 
Error parsing JSON grammar: openListChoice.IsString() == false [for key: 
GetBool
IsBool()
ParseStream
stack_.GetSize() == sizeof(ValueType)
GetAllocator
stack.h
allocator_
reader.h
!HasParseError()
ParseNull
is.Peek() == 'n'
PushUnsafe
stackTop_
static_cast<std::ptrdiff_t>(sizeof(T) * count) <= (stackEnd_ - stackTop_)
ParseTrue
is.Peek() == 't'
ParseFalse
is.Peek() == 'f'
ParseString
s.Peek() == '\"'
ParseStringToStream
ParseHex4
Encode
encodings.h
codepoint <= 0x10FFFF
GetSize() >= count * sizeof(T)
GenericStringRef
str != 0 || len == 0u
ParseObject
is.Peek() == '{'
GetSize() >= sizeof(T)
ParseArray
is.Peek() == '['
ParseNumber
expFrac <= 0
Pow10
pow10.h
n >= 0 && n <= 308
NotNullStrLen
str != 0
FindMember
name.IsString()
StringEqual
rhs.IsString()
allocator<const T>::allocate(size_t n) 'n' exceeds maximum supported size
Error parsing JSON grammar: parsedRule.IsObject() == false [for key: 
Expected:
Actual:
Badly-formed UDA
DelegatedUserDialogAct
Expected a UDA of type 
 but got a 
SNLPServerNLClassifierErrorDomain
Missing resource: %@
Check that resource is available: %@
SNLC/SNLC.mlmodelc/model.espresso.net
SNLC/spans_pad.txt
SNLC/context_pad.txt
An error occured reading SNLC model bundle at: %@
Check that the path contains a valid model bundle: %@
SNLC Asset Error when creating the SNLC inference orchestrator: %s
Hit SNLP exception while calling SNLCOrchestrator::runSNLC for request (high=%llu, low=%llu): %s
-[SNLPServerNLClassifier inferenceResponseForRequest:error:]
SNLPServerNLClassifier.mm
parserResponse.has_value()
node=
edge=
stringValue=
integerValue=
indentation=
alias=
textAlignment=
after
approx
before
earlier
every
last
lastlast
later
middle
next
nextnext
potentialEvery
same
slidinglast
this
upcoming
week
weekend
weekday
month
quarter
year
summer
winter
autumn
spring
semester
season
businessday
afternoon
bedtime
breakfast
brunch
dinner
evening
happyhour
lunch
midnight
morning
night
noon
ROOT
value=
intent=
[next]
[startPayload]
[leaf]
[endPayload]
[newGroup]
task
UserStarted
UserContinued
UserDisambiguated
UserResponded
directLeafNodes
Could not create analyzer: locale not supported
locale %@ not supported
-[UPTokenizer tokenizeUtterance:]
UPTokenizer.mm
tokIt.getStartChar() >= 0
tokIt.getEndChar() >= 0
B24@?0@"UPToken"8@"NSDictionary"16
-[UPContextualizerStrategyOptions resultUsingContextualizerInput:]
UPContextualizerStrategyOptions.m
[contextualizerInput.dialogAct isKindOfClass:[UPDialogActOptions class]]
common_
Node 
 not found in ontology.
uso_graph_text_tree_parser.cpp
Verb 
Root
textAlignment
!mNodeStack.empty()
toTreeDebug
mNodeStack.size() >= 1
attachChildInStack
mNodeStack.size() >= 2
Empty edge found while attaching: 
Edge not found in ontology: 
Could not attach child 
 to parent 
 with edge 
Check
Control
Convert
Create
Delete
Entity
NoVerb
PlaceholderVerb
RecipientsEventTrigger
RecipientsHiddenPeople
Reference
ReferenceControl
ReferenceDateTimeRangeTrigger
ReferenceDurationTrigger
ReferenceMeasurementTrigger
ReferenceNumberTrigger
ReferencePaymentSortKey
ReferencePhotoCollection
ReferencePhotoCollectionFilter
ReferencePhotoFilter
ReferencePhotoMemoryFilter
ReferencePhotoTag
ReferenceProfile
ReferenceSelect
ReferenceSlideshowFilter
ReferenceStringTrigger
ReferenceTarget
ReferenceTargetSelect
ReferenceTrigger
ReferenceVideoFilter
Request
StockSummarise
Summarise
Target
Update
Token indices out of range: [
Unknown LabelScheme observed
Could not deserialise espresso context.
Could not set up espresso network.
not_found
ERROR: Could not find network configuration: 
Note that only parameters of unsigned integer type are currently expected by NLv4Parser.  This issue will likely cause NLv4 parser inference to fail.
UNDEFINED_COMPONENT
Failed to convert CFString to C++ string
DateTime
BeginTime
EndTime
Hours
Meridian
Minutes
MinutesBefore
Seconds
SpecialTimePeriod
Time
TimeDuration
TimeOffset
TimeSpan
AbsoluteDate
Date
DateDuration
DateOffset
DateSpan
DateTimeQualifier
DayOfWeek
MonthNumber
OccurrenceCount
RelativeDay
RelativeDayOfWeek
SpecialDatePeriod
SpecialDatePeriodUnit
SpecialDay
Identifier
B16@?0@"UPResultCandidate"8
+[UPContextualizerUtilities buildPayloadResultFromQuery:modelIdentifier:intent:entityName:serializer:]
UPContextualizerUtilities.m
utterance != nil
send::common_Message
target
common_Message
stringContent
generateOverrideResponse
snlc_override_generator.cpp
request.turnInput()->turnContext()->nlContext()->systemDialogActs().size() == 1
resolveDurationGraph
TimeDurationHandler.cpp
timeDurationSpan
Error opening file: 
Number of element should be 2 in line 
MAX_WORD_LENGTH
MAX_UTTERANCE_LENGTH
USE_CHARS
USE_CHAR_LSTM
TestSpan
Could not open file path
FilePath
+[UPUtilities rangeFromStart:end:]
UPUtilities.mm
start <= end
resolveDateTime
DateTimeHandler.cpp
dateTimeSpan
resolveRecurrenceDuration
resolveRecurringDateTime
mapDateTimeToItemizedUsos
Given UTF-16 offset is not a Unicode scalar (code point) boundary: 
 000000000000
getUnicodeScalarAndUtf8Offsets
string_encoding_utils.cpp
preIncrementOffsetUtf8 < iterationOffsetUtf8
Input string is not a valid UTF-8 sequence! UTF-8 offset: 
Given UTF-16 offset exceeds the input string: 
relative_set_number_verb
setNumber
common_Setting
increaseBy
decreaseBy
unknown/
UPDDTimeDurationSpan
UPDDSpan.cpp
CFEqual(DDResultGetType(ddResult), ddspantype::kTimeDuration)
UPDDSpecialDatePeriodSpan
CFEqual(DDResultGetType(ddResult), ddspantype::kSpecialDatePeriod)
UPDDAbsoluteDateSpan
CFEqual(DDResultGetType(ddResult), ddspantype::kAbsoluteDate)
UPDDDateOffsetSpan
CFEqual(DDResultGetType(ddResult), ddspantype::kDateOffset)
UPDDDateSpan
CFEqual(DDResultGetType(ddResult), ddspantype::kDate) || CFEqual(DDResultGetType(ddResult), ddspantype::kDateSpan)
UPDDDateTimeSpan
CFEqual(DDResultGetType(ddResult), ddspantype::kDateTime)
Could not convert
Component: 
Version: SNLPVersionInfo[train=
, majorVersion=
, minorVersion=
Version: <missing>
Bolt task ID: 
Bolt task ID: <missing>
No assets provided
Combined SHA256: 
asset could not be read
chunkPredictions
nerScore
alternativeIndex
context_vocab.txt
multicardinal_vocab.txt
decoder.mlmodelc/model.espresso.net
encoder.mlmodelc/model.espresso.net
spans_vocab.txt
trg_vocab.txt
span_label_mapping.txt
The NLv4 asset version (
NLv4InferenceOrchestrator
nlv4_orchestrator.cpp
!mMulticardinalVocab.has_value()
NLv4InferenceOrchestrator setup is broken; erroneous assets were provided
NLv4 request is null
pbhandle
numTokens == pbRequest->tokenisedUtterance() ->tokenChain() ->tokens() .size()
PlaceholderVerb_placeholderVerb
ja_JP
common_Message.Target_send
NLv4 request missing request ID
NLv4 request missing valid embeddings
NLv4 request missing valid tokens
NLv4 request missing valid token chain locale
NLv4 request embeddings num tokens (
zh_CN
SystemPrompted.task.send::common_Message.target.common_Message.stringContent
spans_pad_symbol_index
context_pad_symbol_index
start_symbol_index
end_symbol_index
common_DateTime.time
common_Message.recipients
common_PhoneCall.recipients
common_Timer.attributes
common_Message.sender
common_Message.attachments
common_RecurringDateTime.recurrenceDateTimes
common_Message.usoQuantifier
common_Message.attributes
common_Message.participants
common_PhoneCall.attributes
modified_TranslationSourceLocale
common_Translation
sourceString
common_LocalisedString
locale
common_Locale
modified_TranslationPayload
stringValue
modified_TranslationReferenceType
usoReferenceType
modified_TranslationTargetLocale
targetString
modified_GeographicAreaName
geographicArea
common_GeographicArea
modified_GeographicAreaType
areaType
User dialog act node has multiple children.
/dev/urandom
sha1 too many bytes
void boost::uuids::detail::sha1::process_byte(unsigned char)
/System/Volumes/Data/SWE/iOS/BuildRoots/BuildRoot900/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator15.2.Internal.sdk/usr/local/include/boost/uuid/sha1.hpp
Not enough elements in call to seed.
shared_ptr.hpp
px != 0
UPEntityWithValue[entityType: %@, entityName: %@, entityValue:%@]
UPDialogActOffer[intent: %@, entityWithValue: %@]
noMatcher
DataDetector
PlumMatcher
UserVocabMatcher
SingleTrieMatcher
ContextMatcher
OvertonMatcher
MRRDetector
MRRMatcher
RegexSpanMatcher
personRelationship
phoneType
values
numTokens
numLayers
embeddingDim
embedderId
input_ids
input_mask
bert/feature_extraction_output
childrenBeginLabelIdsFromPaths
beam_input.cpp
childBeginBioTagId != childVocabulary.getUnknownTokenId()
buildGrammarMask
childBioTagId != childUnknownTokenId
buildUniqueLabels
firstPathComponent.has_value()
buildIndexableLabels
matchSpansInner
UPDataDetector.cpp
detectedSpans.detectedData
Could not create scanner from cache file: "
".  
createScanner
error == NULL
utterance_tokens_embeddings
padding_mask
span_tokens
position_ids
out_init_decoder_hidden
out_encodings
addresses_
.cache
date_time_
addresses.cache
date_time.cache
flights.cache
currencies.cache
numbers.cache
phone_mobile.cache
coarseEntityType
fineGrainedEntityType
charIndicesRange
chunkScore
[CLS_SPAN]
[SEP_SPAN]
[NO_SPAN]
model_info.plist
info.plist
intent.vocab.txt
bio_labels.vocab.txt
span.vocab.txt
grammar.json
model.mlmodelc
calibration_model.mlmodelc
No USO
mention
entityType
score
usoGraph
%@%@%@
Entity type %@ should contain exactly one %@ and the string before %@ should be equal to %@
 => 
PostProcessor
dateTime
tokens
originalUtterance
normalisedUtterance
app_bundle
neu_inputs
model.espresso.net
max_seq_length
espresso_bert_model.cpp
utteranceTokens.size() == maxNumTokens
utteranceTokensMask.size() == maxNumTokens
hidden_size
embeddingDimension > 0
embeddings.size() / embeddingDimension == input.utteranceTokens.tokens.size()
BERT:
      pre-process 
      forward: 
      post-process: 
resolveMinutesBeforeTimeSpanWithUnit
TimeSpanHandler.cpp
resolveTimeSpanWithUnit
resolveTimeSpan
resolveRecurringTimeSpan
addCLSSEPToTokens
sep_cls_utils.hpp
expandedTokens.size() == tokens.size() + 2u
UPDialogActOptions[intent: %@, entityType: %@, entityName: %@, entityValues: %@]
PLUM_%@
v24@?0@"UPSpan"8^B16
Span label shape incorrect.
Given coordinates do not match tensor shape
Coordinates exceed bounds of tensor
mergePathToTree
ply_state_handler.cpp
std::holds_alternative<PayloadStartEnd>(valueInfo)
SNLPOSLoggerForCategory
SNLPLogging.mm
loggingCategory < SNLPCategoryLogMax
v8@?0
General
Common
UPDataDetectors
SiriNaturalLanguageParsingSignPosts
com.apple.sirinaturallanguageparsing
data_detectors
tokenisedUtterance
embeddings
matchedSpans
text
structuredData
phone-number
common_Time
common_Time12HourClock
common_Time24HourClock
date
Attempting to re-insert span entity to model graph, beneath 
time
Re-insertion of span graph was successful.
common_Integer
usoEntityInsertionPoint
token
tokenId
graphemeClusters
isSpecialToken
isWordPiece
isOverflow
encodedLabels
SNLPNaturalLanguageParserErrorDomain
NLv4 Asset Error when creating the C++ NLv4 orchestrator: %s
Hit SNLP exception while constructing C++ orchestrator with asset directory %@: %s
Hit SNLP exception while constructing C++ orchestrator with spans vocab path %@: %s
Hit SNLP exception while calling NLv4InferenceOrchestrator::pbhandle for request (high=%llu, low=%llu): %s
NLv4InferenceOrchestrator::pbhandle returned nullptrfor request (high=%llu, low=%llu)
alternativePredictions
tensoriseTokens
matched_spans_featurizer.cpp
tokenIndex == numEncodedTokens
featureTensor.size() == numEncodedTokens * maxNumLabels
TreeNode[
label:'
value:'
parentArgument:'
UTF-8 code unit indices:[
UTF-16 code unit indices:[
Unicode code point indices:[
Expected a node to start at: 
Expected an edge to start at: 
Regex search failed: 
^(accepted|acknowledged|cancelled|delegated|rejected|user_stated_task|wanted_to_pause|wanted_to_proceed|wanted_to_repeat|UserAccepted|UserAcknowledged|UserCancelled|DelegatedUserDialogAct|UserRejected|UserStatedTask|UserWantedToPause|UserWantedToProceed|UserWantedToRepeat)
UDA previously defined as 
 but is being redefined as 
Expecting a valid UDA name but got 
User dialog act not yet specified
UDA not yet specified
accepted
acknowledged
cancelled
UserCanceled
delegated
DelegatedDialogAct
rejected
user_stated_task
wanted_to_pause
wanted_to_proceed
wanted_to_repeat
unknown UDA 
person_name_split
handleCommonPersonSubtree
person_name_split.cpp
personMatchingSpansPartitionForNode.value().size() >= 2
^(\b\w+\b)(\S+)$
Failed to initialise the regex expression for the subtokens: 
appendMatchedSpan
span_processor.cpp
mInternals.reverseMapping.find(str) != mInternals.reverseMapping.end() && "Unable to find token chain in reverse mapping after a match was found in the pattern " "trie"
Failed to attach the regex expression to the token text: 
Failed to find match in text: 
Encountered invalid substring: 
Encountered empty normalized matching substring for label: 
Begin/inside BIO tags must have a payload component
Only begin/inside BIO tags can have a payload component
Cannot extract payload from non-begin/inside BIO tag
getPayload
bio.cpp
mPayload.has_value()
Well-formed BIO tags must be >=3 characters long, but got: 
BIO tag has no prefix
Unrecognized BIO tag prefix
convertToLabelledSpans
!currentSpan.has_value()
buildAllBioTagsFromEntityLabels
bioTags.size() == expectedFinalSize
Cannot get value for empty optional!
Span labels tensor is of incorrect shape
Span labels tensor shape does not match tokens size
Unable to instantiate a normalizer form the input normalizer choice
Failed to instantiate normalizer - 
Failed to normalize string 
 - due to error: 
Failed to compare strings - due to error: 
Failed to casefold string: 
Invalid substring range. The endIndex
 >= src length 
Invalid substring range. startIndex  (
) >= endIndex (
Token indices out of range.
Number of tokens differs from number of BIO tags
Number of tokens differs from number of group IDs
Empty entitiesScores (implies no tokens)
Size of groupScores does not equal number of tokens
First dimension of intentEntityTransitions does not equal number of intents
Second dimension of intentEntityTransitions does not equal number of BIO tags
Size of startEntityTransitions does not equal number of BIO tags
First dimension of entityTransitions does not equal number of BIO tags
Second dimension of entityTransitions does not equal number of BIO tags
Out-of-range intent label (key) in uniqueLabels
Out-of-range BIO label (value) in uniqueLabels
Out-of-range intent label (key) in indexableLabels
Out-of-range BIO label (value) in indexableLabels
Invalid beamSize. Should be in the interval (0, 5]
BeamSequence[
  score = 
  intent = 
  entities = 
  groupIds = 
(none)
beamSearch
allCandidates.begin() + beamSize < allCandidates.end()
Beam sequence is empty getIntent
Beam sequence is empty getEntities
Embedding[
 ...
Label vocabulary does not contain pad token
Trans params's first and second dimension should have non-zero equal value, while the actual shape is [
Trans params's first and second dimension value: 
 should be equal to tag size: 
Logits tensor's last dimension value: 
 should be equal to the output label's size: 
 and transit parameters's dimension value: 
Invalid input. Can't have WordCharactersTensorEnabled to be false while have WordLengthTensorEnabled to be true.
Word embedding data first dimension: 
 sequence length data first dimension: 
 word character data first dimension: 
 and word length data first dimension: 
 should have equal non-zero values
Word embedding data second dimension: 
 word character data second dimension: 
 and word length second dimension: 
word_embedding_placeholder
sequence_length_placeholder
word_characters_placeholder
word_length_placeholder
proj/logits
Dimension value: 
 should match first value of shape: 
 should match second value of shape: 
 should match third value of shape: 
Begin index of mention boundary: 
 should be smaller than end index (exclusive) of mention boundary: 
End index (exclusive) of mention boundary: 
 should be smaller or equal then predictions labels size: 
Begin index: 
 should be smaller than end index: 
End index: 
Sequence length: 
 should be less than logits length: 
Logits's shape should be [maxTokens (Siri default is 26),
], while the actual shape is [
Output label map contains label: 
 which is not B, I and O label
Output label map file is empty
Output label map file is invalid. Valid output label map should has O tag with 1 label value, I labels comes after B labels, while the actual value is: O tag: 
, first B tag: 
, last B tag: 
, first I tag: 
, last I tag: 
B labels and I labels should have equal size, while the actual value is: first B tag: 
Transition parameters loaded is invalid. Transition parameters's first and second dimension should have non-zero equal value
Vocab indices map file is empty
The given chunkPredictions and usoGraphs don't have equal size
measurement
measurementComponent
otherPerson
appName
personalLocation
businessName
measurementUnit
currency
Entities with type 
 or 
 both exist in char index range [
Can't find entities with type: 
 and entities with type: 
 in char index range [
Entities with type: 
) has more than one
Entity is not with type 
Can't cast to pointer to 
com.apple.siri.nlteam.plum
NerHandler
NerFactory
Espresso
The input nest tag: 
 is empty
Can't get flat tags from: 
The input nest B tag: 
Can't get B tags from: 
Tag 
 is not a B tag
Can't locate I tag
Can't locate 
 in iTagIndicesMap
Tag after split should have size 2
 in output label map
No Number child entities and MeasurementUnit child entity is null
Fail to create espresso context.
Fail to create espresso pan.
Fail to set up espresso network.
Can't find character: 
 in character indices map
Num of tokens in embedding tensor: 
 doesn't match with sequence length: 
Num of layers in embedding tensor: 
 is not 1. Currently NER only support number of layer to be 1.
Number of embedding float values: 
 doesn't match with embedding shape: [
Size of NER alternative prediction from NER factory: 
 is not 1
Find both commonMeasurementComponent node and commonCurrency node. Invalid measurement entity.
Both commonMeasurementComponent node and commonCurrency node don't exist. Invalid measurement entity.
Find more than one commonCurrency node. Invalid measurement entity.
Attempt pruning UserAccepted from a one shot reply UserAccepted + UserStatedTask prediction.
Could not find a UserAccepted dialog act to remove.
UPContextualizerStrategyPrompt; %ld domain candidates matched dialog act prompted entity (%@)
UPContextualizerStrategyPrompt: No domain result matched dialog act prompted entity (%@)
UPContextualizerStrategyPrompt: Building verbatim string payload
[%s] Error, file doesn't exist. Hash for file content cannot be calculated: %s
[%s] Error, input stream for file could not be created. Hash for file content cannot be calculated: %s
[%s] Error, input stream for file could not be read. Hash for file content cannot be calculated: %s
[%s] Error while calculating hash of file %s
[%s] Error iterating over directory %s: %s
[%s] Warning: config missing Bolt task ID
[%s] Warning: config Bolt task ID is not a string
UPContextualizerStrategyOffer: Detected high-probability yes/no intent in core result
BEGIN "Encoder Inference"
Encoder Inference
END "Encoder Inference"
BEGIN "Decoder Inference"
Decoder Inference
END "Decoder Inference"
[%s] Invalid featurization input provided to the model.  Expected a non-empty utterance length tensor and a context tensor of at least two dimensions.
[%s] The utterance length (%lu) exceeds the maximum utterance length (%lu).
[%s] padEmbeddings input tensor size = %lu (%lu, %lu, %lu)
[%s] padEmbeddings maxUtteranceLength (defined by network config) = %lu
[%s] Illegal shape for embeddings: (%lu, %lu, %lu). Must be (?, ?, %lu) and hold %lu values
[%s] padEmbeddings For each batch, copying %lu embedding values and adding %lu padding values
[%s] padEmbeddings Padded embedding tensor shape: (%lu, %lu, %lu)
[%s] The component %zu is invalid
Could not convert query dialog act: %{sensitive}@
Converted dialog act and got: %@
Found no utterance alignments, skipping...
Found no matching insertable span.
SiriOntology indicated an entity node, but failed to cast to UsoEntityNode type.
No utterance alignments found in the entity node; searching the descendant nodes for utterance alignments instead.
Found no entities in the uso graph of matching span, skipping...
There is more than one entity in the USO graph of matching span, skipping...
The first level entity is not of entity node type, skipping...
BEGIN "UaaP UPParserModelInit initWithSystemConfiguration"
UaaP UPParserModelInit initWithSystemConfiguration
END "UaaP UPParserModelInit initWithSystemConfiguration"
BEGIN "UaaP EspressoInference"
UaaP EspressoInference
END "UaaP EspressoInference"
BEGIN "UaaP Post-Processing"
Number of BEAM sequences = %lu
Processing BEAM sequence: %s
Produced candidate: %@
UaaP Post-Processing
END "UaaP Post-Processing"
BEGIN "UaaP Prediction"
Error predicting utterance: %{sensitive}s
UaaP Prediction
END "UaaP Prediction"
Featurizing the following context labels in NLv4ParserRequest.
[%s] Found an smsGroupName span that matches a common_Person or common_Agent node
[%s] Found a personFullName span that matches a common_Person or common_Agent node, so skipping group_name_transform
[%s] Replacing the node label "%s" with "%s"
[%s] Found %lu smsGroupName matching spans
[%s] Found %lu personFullName matching spans
[%s] Splitting common_Person nodes in-place
[%s] Iterating through all tree nodes
[%s] Finished iterating through all tree nodes
[%s] Could not split this common_Person node
[%s] Successfully split the common_Person node into name/contact type
[%s] Handling common_Person subtree
[%s] Warning: the common_Person node has more than one child (expecting just `name`). Skipping.
[%s] Warning: the common_Person node child is not `name`. Skipping.
[%s] common_Person.name value: %{sensitive}s
[%s] There exists a person matching span covering this entire common_Person.name node. Skipping.
[%s] Could not find a split for this common_Person. Skipping.
[%s] Warning: Failed to generate a node for matching span (personInput=%{sensitive}s, contactTypeInput=%{sensitive}s)
[%s] Hit out of range exception when looking up token character indices
[%s] newNameNode.startCharIndex (%lu) is less than originalNameStartCharIndex (%lu)
[%s] newNameNode character indices imply an empty or impossible substring (%lu -> %lu)
[%s] contactAddressLabelNode.startCharIndex (%lu) is less than originalNameStartCharIndex (%lu)
[%s] contactAddressLabelNode character indices imply an empty or impossible substring (%lu -> %lu)
[%s] Generated new common_Person.name node with newNameNode.startCharIndex=%lu, newNameNode.endCharIndex=%lu, newNameNode.value=%{sensitive}s
[%s] After filtering, we have %lu contact type matching spans
[%s] After filtering, we have %lu person matching spans
[%s] Warning: could not find start token index corresponding to node.startCharIndex=%lu
[%s] Warning: could not find end token index corresponding to node.endCharIndex=%lu
[%s] Deleting %lu nodes
[%s] Inserting %lu spawned nodes
BEGIN "SNLC Span Featurization"
SNLC Span Featurization
END "SNLC Span Featurization"
BEGIN "SNLC Context Featurization"
SNLC Context Featurization
END "SNLC Context Featurization"
BEGIN "SNLC Inference"
SNLC Inference
END "SNLC Inference"
Unsupported SNLC classification result. Returning an empty SNLC response.
Warning: Invalid model version provided: %u.  Model versions currently supported: %s.
A token could not be reindexed; %{sensitive}s
Unknown error thrown during token index conversion (should be unreachable)
Token indexes could not be converted: %s
Featurized the following %lu LegacyNLContext features in SNLCParserRequest: %s
Failed to featurize any labels from legacyNlContext
Warning: Legacy NL context features were supplied, but the asset directory major version (%u) does not support these. These will not be featurized.
Warning: The request's nlContext contains a SDA. Skipping featurization for the legacy context.
No SDA present in nlContext: falling back to legacyNlContext
Failed to extract any labels from nlContext or legacyNlContext
Label '%s' not present in vocabulary. Skipping. (Is this label supported by the provided assets?)
Number of context features (%lu) exceeds maximum limit (%lu): truncating by removing features %s
%s SNLC context: %s
SNLC non-padded context input tensor: %s
[%s] Badly formed SystemPrompted dialog act; needs to contain the target UsoGraph.
[%s] Badly formed SystemOffered dialog act; needs to contain a user dialog act.
[%s] Badly formed SystemReportedSuccess dialog act; needs to supply the task UsoGraph.
[%s] Badly formed SystemReportedFailure dialog act; needs to supply the UsoGraphs for the failed task and for the failure reason.
[%s] Warning: Badly formed user dialog act.
[%s] Failed to cast USO task node from SiriOntology. 
[%s] After filtering, we have %lu %s matching spans
[%s] No grounded tokens found under node: %s
No calibration score found for parser result with bundle modelIdentifier: %@
[%s] Both %s and %s semantic values found when using %s spans
[%s] MatchingSpan with label %s, semantic value %s found?: %{BOOL}d
[SNLC Assets] %s
BEGIN "SNLPServerNLClassifier inferenceResponseForRequest"
SNLPServerNLClassifier inferenceResponseForRequest
END "SNLPServerNLClassifier inferenceResponseForRequest"
Encountered error in deprecated version of inferenceResponseForRequest: %@ (returning SERVER parser response)
UPContextualizerStrategyCancel: Detected high-probability cancel intent in core result
UPContextualizerStrategyOptions: Detected high-probability selectOrdinal intent in core result
UPContextualizerStrategyOptions: %ld domain candidates matched dialog act prompted entity (%@)
UPContextualizerStrategyOptions: No domain result matched dialog act prompted entity (%@)
UPContextualizerStrategyOptions: Building verbatim string payload
[%s] [model_task_id=%s]
[%s] %s
SNLC override triggered: falling back on DEVICE based on the turn input SDA content
SNLC override triggered: falling back on SERVER based on the LegacyNLContext dictationPrompt=true
Rejecting '%s'.
Warning: Context shape not 2-dim
[NLv4IO Context Tensor] shape=%lu,%lu num_elems=%lu
Warning: Context shape not consistent with data
[NLv4IO Context Token] i=%lu j=%lu id=%lu token=%s
PrepareGlobalNerRequest
FetchNerPredictions
Utterance: %{sensitive}@
ConvertToUPPLNerResponse
Predictions:
PLUM Span (before post processing):
GeneratePlumSpans
[%s] Found setNumber voc span(s)
Creating NLv4InferenceOrchestrator instance with getAssetVersionMajor()=%u
Creating NLv4InferenceOrchestrator instance via deprecated constructor with major asset version %u
BEGIN "NLv4 Matched Span Featurization"
NLv4 Matched Span Featurization
END "NLv4 Matched Span Featurization"
BEGIN "NLv4 Context Featurization"
NLv4 Context Featurization
END "NLv4 Context Featurization"
NLv4 Inference
BEGIN "NLv4 Inference"
%s Numericalized span input for NLv4 parser model:
%s Numericalized context input for NLv4 parser model:
%s %s
END "NLv4 Inference"
BEGIN "NLv4 Tree Building"
Tree after all manipulations:
%{sensitive}s
A hypothesis was rejected because it contained only UserAccepted.
Building UDA for hypothesis number %zu
Invalid USO graph, removing parse from output.  This might be due to a grammatical error or an otherwise malformed model tree.
Could not generate a full USO graph for a hypothesis: %s
NLv4 Tree Building
END "NLv4 Tree Building"
[NLv4IO Ply tree] hypothesis=%zu:
[NLv4IO Ply tags] hypothesis=%zu:
[SNLPAssetLogger] %s
Invalid model tree, removing parse from output.
Invalid user dialog act: %s
BEGIN "CalibrationInference"
CalibrationInference
END "CalibrationInference"
[%s] Warning: failed to get namespace for node %{sensitive}s: %{sensitive}s
[%s] Badly formed matching span; start and/or end indices missing from span.
[%s] A data detector span contained a USO graph with an invalid entity node.  This data detector span was ignored by the span matching featurizer.  Error: %s.
[%s] Span encoding failed; number of buckets (%lu) not matching number of tokens (%lu).
%s Exception when calling C plus plus post processor code : %{sensitive}s
%s Exception "%{sensitive}s" catched during graph genereation for span:
 %{sensitive}@
%s Error serializing USO graph : %{sensitive}@
%s USO graph genereatd for span:
 %{sensitive}@
%s Use USOGraph from Date Detector Span for PLUM Span:
 %{sensitive}@
%s Data detector span is nil, skip the code to integrate plum spans with data detector spans.
BEGIN "UPLoadedModelConfigurationInit"
BEGIN "EspressoInitialization"
Exception while initializing model %s
EspressoInitialization
END "EspressoInitialization"
UPLoadedModelConfigurationInit
END "UPLoadedModelConfigurationInit"
[%s] [WARN] MatchingSpan has no USO graph
[%s] [WARN] MatchingSpan has USO graph with no identifiers
[%s] [WARN] probability missing from identifier
[%s] [WARN] probability has no value
[%s] [WARN] Negative relative threshold supplied (%f), span filtering will behave strangely
[%s] Span filtering: %lu out of %lu spans kept
[%s] Span %s [score %f] was kept?: %{BOOL}d
[%s] Span %s [no score] was kept?: %{BOOL}d
Warning: cannot embed OOV token '%s'.
BEGIN "UaaP Preprocessing"
Found matched span using data detectors: %lu -> %lu (%s)
Matched span has structured data: %s
Featurized token with text=%s
Token span labels: %s
UaaP Preprocessing
END "UaaP Preprocessing"
Valid insertable span found; re-inserting it into the model graph.
Could not insert subtree: %s 
 Warning: Could not generate USO graph: %s
Built USO graph:
Failed to cast entity node to entity node; SiriOntology reports a non-entity node as an entity node.
Warning: Integer %s out of range for USO integer nodes.
Warning: Failed to convert string %s to integer.
BEGIN "SNLPNaturalLanguageParser inferenceResponseForRequest"
SNLPNaturalLanguageParser inferenceResponseForRequest
END "SNLPNaturalLanguageParser inferenceResponseForRequest"
Tree after ContactTypeSplit step:
%{sensitive}s
Tree after PersonNameSplitHack step:
%{sensitive}s
Tree after GroupNameTransform step:
%{sensitive}s
Tree after ContactAddressDowncaster step:
%{sensitive}s
Tree after MinimumMaximumLabeller labelling:
%{sensitive}s
Tree after One Shot Reply check:
%{sensitive}s
Tree after SetNumber verb replacement:
%{sensitive}s
[%s] Span input
[%s] Span Input
[%s] Warning: encountered span missing label
[%s] Badly formed matching span; start and/or end indices missing from span. Skipping.
[%s] Mapping span label '%s' to span label '%s'
[%s] Warning: Featurised spans shape not 3-dim
[%s] [Span Tensor] shape=%lu,%lu,%lu num_elems=%lu
[%s] Warning: Span shape not consistent with data
[%s] [Span Token] i=%lu j=%lu k=%lu id=%lu token=%s
[%s] span '%s' covers tokens [%u, %u)
[%s] Spans encoded over the tokens:
[%s] %s: %s
[%s] Rejecting OOV Span: %s
Could not find contextualizer strategy for dialog act: %{sensitive}@
[%s] Since the model itself predicted only %lu common_Person nodes (lower than the threshold of %lu), do not apply the name split hack
[%s] Could not find _any_ partition for this common_Person (including a single-span one). Skipping.
[%s] This common_Person cannot be split into multiple sub-spans. Skipping.
[%s] This common_Person has been partitioned into %lu sub-spans.
[%s] Warning: Failed to generate a node for matching span (input=%{sensitive}s)
[%s] Finding person matching span partitions for range %lu -> %lu
[%s]  - span: %{sensitive}s
[%s] Found %lu possible person partitions:
[%s] Found minimal partition:
[%s]  - component: %{sensitive}s
[%s] Did not find minimal partition
[%s] Generated new common_Person.name node with startCharIndex=%lu, endCharIndex=%lu, value=%{sensitive}s
[%s] Successfully spawned replacement common_Person nodes
Espresso
BeamSearch
CrfNormalizer
PrepareTensor
BuildTensor
ExecutePlan
GetTensor
UPModelIdentifier
NSCopying
UPContextualizerStrategyPrompt
UPContextualizerStrategy
NSObject
UPContextualizerStrategyOffer
UPPLMatchedSpan
UPDataDetectorSpan
UPQueryRunner
UPDialogActPrompt
UPDialogAct
UPParserModel
UPResultStructuredDataNode
UPUsoSerializer
UPCalibration
SNLPServerNLClassifier
UPResultCandidate
UPModelBundle
UPResultRootNode
UPTokenizer
UPResultNode
UPContextualizerStrategyCancel
UPContextualizerStrategyOptions
UPResultIntermediateNode
UPIntentWithSingleEntity
UPDialogActConverter
UPPreprocessorOutput
UPToken
UPContextualizerUtilities
UPPLNerHandler
UPUtilities
UPPLAlternativePrediction
UPSpan
UPCalibrationModel
UPEntityWithValue
UPDialogActOffer
UPPLEmbeddingTensor
UPDetectedData
UPDataDetectors
UPContextualizerInput
UPPLChunkPrediction
UPModelConfiguration
UPPlumSpan
UPPLPostProcessor
UPPLTokenization
UPLoadedModelConfiguration
UPResult
UPQuery
UPResultCandidateEntity
UPDialogActOptions
UPPreprocessor
UPSystemConfiguration
UPPLNerRequest
UPResultLeafNode
UPPLToken
SNLPNaturalLanguageParser
UPEmbedding
UPPLNerResponse
UPContextualizer
init
UUID
allocWithZone:
copyWithZone:
uuid
isEqual:
appBundleId
isEqualToString:
hash
initWithAppBundleId:
.cxx_destruct
_uuid
_appBundleId
T@"NSUUID",R,C,V_uuid
T@"NSString",R,C,V_appBundleId
dialogAct
reference
coreResult
createConfirmOrRejectedDialogActsFor:reference:
domainResult
modelIdentifier
query
initWithDomainResult:coreResult:modelIdentifier:query:dialogAct:
entityName
filterResult:byEntityName:serializer:
candidateCount
intent
resultFromResult:withNewIntent:
entityType
buildPayloadResultFromQuery:modelIdentifier:intent:entityName:serializer:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
superclass
description
debugDescription
TQ,R
T#,R
T@"NSString",R,C
resultUsingContextualizerInput:
initWithPrebuiltIntentThreshold:usoSerializer:
prebuiltIntentThreshold
usoSerializer
_prebuiltIntentThreshold
_usoSerializer
Td,R,N,V_prebuiltIntentThreshold
T@"UPUsoSerializer",R,N,V_usoSerializer
stringWithCString:encoding:
defaultManager
fileExistsAtPath:isDirectory:
inputStreamWithFileAtPath:
open
read:maxLength:
stringWithCapacity:
appendFormat:
UTF8String
initWithLength:
mutableBytes
length
dataWithBytes:length:
bytes
arrayWithObjects:count:
hasTopCandidate:excedingProbability:matchingOneOfIntents:
createResultFromExistingResult:truncatedTo:
initWithPrebuiltIntentThreshold:
label
tokenIndicesIndex
stringWithFormat:
dictionaryWithObjects:forKeys:count:
initWithLabel:tokenIndicesIndex:
dictionaryRepresentation
_label
_tokenIndicesIndex
T{_NSRange=QQ},R,N,V_tokenIndicesIndex
T@"NSString",R,N,V_label
initWithRange:type:category:
printedForm
initWithRange:category:dataDetectorResult:
initWithRange:category:dataDetectorResult:usoGraph:
getUsoGraphPrintedForm
dataDetectorResult
usoGraph
_dataDetectorResult
_usoGraph
T^{__DDResult=},R,V_dataDetectorResult
T@"USOSerializedGraph",R,V_usoGraph
initWithUsoSerializer:
countByEnumeratingWithState:objects:count:
preprocessor
initWithPreprocessor:parserModel:calibrationModel:
addObject:
initWithCoreModel:domainModelBundles:
dictionary
parserModel
identifier
preprocess:error:
predictionFromQuery:preprocessorOutput:error:
errorWithDomain:code:userInfo:
setObject:forKey:
calibrationModel
scoreFromQuery:preprocessorOutput:error:
calibrateParserResults:withCalibrationScores:error:
dialogActFromQuery:
allValues
setWithArray:
singleTurnPredictionFromDomainResults:
multiTurnPredictionFromQuery:modelIdentifierToDomainResults:dialogAct:error:
convertFromDialogAct:error:
localizedDescription
queryUUID
valueForKey:
count
anyObject
array
candidateAtRank:
probability
initWithKey:ascending:
sortedArrayUsingDescriptors:
initWithCandidates:queryUUID:
combinedResultFromResults:
predictionFromQuery:error:
objectForKeyedSubscript:
resultWithContextualizerInput:
initWithCoreModel:domainModels:
domainModels
coreModel
domainModelBundles
_calibration
_dialogActConverter
_contextualizer
_coreModel
_domainModelBundles
__calibration
__dialogActConverter
__contextualizer
T@"UPCalibration",R,N,V__calibration
T@"UPDialogActConverter",R,N,V__dialogActConverter
T@"UPContextualizer",R,N,V__contextualizer
T@"UPParserModel",R,N,V_coreModel
T@"NSSet",R,N,V_domainModelBundles
copy
initWithIntent:entityType:entityName:reference:
_intent
_entityType
_entityName
_reference
T@"NSString",R,C,V_entityType
T@"NSString",R,C,V_entityName
T@"USOSerializedGraph",R,V_reference
T@"NSString",R,C,V_intent
initWithCapacity:
initWithType:andValue:andChildren:
initWithSystemConfiguration:loadedModelConfiguration:
initWithModelConfiguration:
modelWithSystemConfiguration:loadedModelConfiguration:error:
bundleId
stdU16ToNSString:
labelToValueType
numberWithUnsignedLong:
rangeFromStart:end:
initWithRange:label:text:groupId:semanticValue:structuredData:
serializeFromIntent:andEntities:forBundleId:
initWithTask:
initWithUncalibratedProbability:calibratedProbability:utterance:intent:entities:modelIdentifier:task:
parserEspressoModule
utterance
nSStringToU16String:
beamMaskInput
arrayWithCapacity:
_candidateForBeamSequence:utterance:outputTokens:resolver:dataDetectorSpans:
annotatedString
intentVocabPath
bioLabelsVocabPath
_candidateForUtterance:probability:labelledSpans:dataDetectorSpans:intent:
spanLabelsTensor
embeddingsTensor
forwardWithSpanLabels:embeddings:utterance:
outputTokens
dataDetectorSpans
resolver
_resultFromInferenceResult:query:outputTokens:dataDetectorSpans:resolver:
locale
isPLUMEnabled
modelWithSystemConfiguration:modelConfiguration:error:
setIsPLUMEnabled:
_systemConfiguration
_loadedModelConfiguration
_isPLUMEnabled
_identifier
__usoSerializer
__systemConfiguration
__loadedModelConfiguration
T@"UPUsoSerializer",R,V__usoSerializer
T@"UPSystemConfiguration",R,N,V__systemConfiguration
T@"UPLoadedModelConfiguration",R,N,V__loadedModelConfiguration
T@"UPModelIdentifier",R,N,V_identifier
T@"NSLocale",R,C,N
TB,N,V_isPLUMEnabled
T@"UPPreprocessor",R
type
value
initWithObjectsAndKeys:
children
initWithArray:copyItems:
objectAtIndexedSubscript:
_dictionaryRepresentation
replaceObjectAtIndex:withObject:
_type
_value
_children
T@"NSString",R,C,V_type
T@"NSString",R,C,V_value
T@"NSArray",R,C,V_children
_convertBundleIdToEntity:
isHigherLevelEntity
_insertSimpleEntity:intoGraph:underTaskNode:
_insertHigherLevelEntities:intoGraph:underTaskNode:
initWithUsoGraph:withError:
defaultCStringEncoding
_leafNodeFromLabel:andGraphStringNode:
_leafNodeFromLabel:andGraphSemanticValueNode:
_leafNodeFromGraphEdge:andGraphNode:
initWithLabel:andLeafNodes:
toCppUsoGraph:withError:
_intermediateNodeRepresentations:
initWithLabel:intermediateNodes:directLeafNodes:
range
text
semanticValue
_addPathForLabel:range:text:semanticValue:toGraphNode:forGraph:
_groupHigherLevelEntities:
objectForKey:
higherLevelChildLabel
higherLevelParentLabel
groupId
numberWithLong:
stringByReplacingOccurrencesOfString:withString:
initWithLabel:andText:andSemanticValue:andStructuredData:
deserializeFromSerializedGraph:
.cxx_construct
_usoVocabManager
doubleValue
calibrateResult:withCalibrationScore:
calibrateCandidate:withCalibrationScore:
uncalibratedProbability
numberWithDouble:
entities
task
mainBundle
localizedStringForKey:value:table:
path
_classifierWithPathURL:shouldExpectVersionInfo:error:
stringWithUTF8String:
URLByAppendingPathComponent:
_classifierWithModelURL:configURL:spanVocabularyURL:contextVocabularyURL:versionURL:error:
_hasVersionInfo
absoluteString
stringByDeletingLastPathComponent
URLWithString:
isReadableFileAtPath:
_errorForMissingResourceURL:
_initWithModelURL:configURL:spanVocabularyURL:contextVocabularyURL:versionURL:error:
_convertRequest:
requestId
highInt
lowInt
_responseForSNLCResponse:
inferenceResponseForRequest:error:
setClassificationLabel:
setClassificationProbability:
data
initWithData:
classifierWithPathURL:error:
classifierWithModelURL:configURL:spanVocabularyURL:contextVocabularyURL:error:
inferenceResponseForRequest:
_snlcOrchestrator
_assetLogger
numberWithUnsignedInteger:
annotatedEntityFragmentString
appendString:
characterAtIndex:
stringWithCharacters:length:
_buildCandidateEntitiesByStartIndex:
structuredData
rootNodeRepresentationForIntent:andEntities:
calibratedProbability
rootNodeRepresentation
_candidateEntitiesByStartIndex
_modelIdentifier
_task
_uncalibratedProbability
_calibratedProbability
_entities
__candidateEntitiesByStartIndex
_utterance
T@"NSDictionary",R,V__candidateEntitiesByStartIndex
T@"NSString",R,V_utterance
T@"NSString",R,V_intent
T@"UPResultRootNode",R
T@"UPUsoSerializer",R,V_usoSerializer
T@"UPModelIdentifier",R,N,V_modelIdentifier
T@"NSObject<SIRINLUUserDialogAct>",R,C,V_task
Td,R,V_uncalibratedProbability
T@"NSNumber",R,V_calibratedProbability
Td,R
T@"NSArray",R,V_entities
initWithLoadedModelConfiguration:parserModel:calibrationModel:
_parserModel
_calibrationModel
_preprocessor
T@"UPPreprocessor",R,N,V_preprocessor
T@"UPParserModel",R,N,V_parserModel
T@"UPCalibrationModel",R,N,V_calibrationModel
initWithLabel:
directLeafNodes
null
intermediateNodes
_intermediateNodes
_directLeafNodes
T@"NSArray",R,C,V_intermediateNodes
T@"NSArray",R,C,V_directLeafNodes
localeIdentifier
raise:format:
whitespaceAndNewlineCharacterSet
stringByTrimmingCharactersInSet:
initWithString:range:isWhitespace:
isWhitespace
predicateWithBlock:
filteredArrayUsingPredicate:
nonWhitespaceTokensForTokens:
initWithLocale:
tokenizeUtterance:
_locale
T@"NSLocale",R,C,V_locale
T@"NSString",R,C,V_label
leafNodes
_leafNodes
T@"NSArray",R,C,V_leafNodes
entity
isEqualToEntityWithValue:
initWithIntent:singleEntity:
isEqualToIntentWithSingleEntity:
_entity
T@"UPEntityWithValue",R,V_entity
_convertFromOfferedDialogAct:error:
_convertFromGaveOptionsDialogAct:error:
_convertFromPromptedDialogAct:error:
offeredAct
_parseUserDialogAct:error:
initWithIntent:entityWithValue:
choices
objectAtIndex:
entityValue
initWithIntent:entityType:entityName:entityValues:
_parseUserDialogActGraph:error:
higherLevelEntityLabelFromParentLabel:childLabel:
initWithType:entityName:entityValue:
T@"UPUsoSerializer",R,C,V_usoSerializer
initWithEmbeddingsTensor:spanLabelsTensor:outputTokens:dataDetectorSpans:
_embeddingsTensor
_spanLabelsTensor
_outputTokens
_dataDetectorSpans
T^v,R
string
isEqualToToken:
initWithString:
_isWhitespace
_string
_range
T@"NSString",R,C,V_string
T{_NSRange=QQ},R,V_range
TB,R,V_isWhitespace
containsObject:
entityLabelsFromCandidate:
filterResult:serializer:predicate:
setReference:
instancesRespondToSelector:
loadConfigs:
integerValue
boolValue
tokenizedUtterance
originalUtterance
tokens
token
charIndicesRange
graphemeClusters
normalizedUtterance
embeddings
numTokens
embeddingDim
values
floatValue
numLayers
embedderId
numberWithFloat:
initWithCoarseEntityType:fineGrainedEntityType:charIndicesRange:tokenIndicesIndex:chunkScore:
initWithChunkPredictions:nerScore:alternativeIndex:
initWithAlternativePredictions:
predictNamedEntitiesForRequest:
alternativePredictions
chunkPredictions
substringWithRange:
fineGrainedEntityType
generateTypeWithPlumPrefix:
chunkScore
initWithRange:originalMention:category:score:usoSerializedGraph:
initWithLocale:modelDir:vocabTagsFile:transParamsFile:charIndicesFile:configFile:
initWithLocale:modelDir:vocabTagsFile:transParamsFile:charIndicesFile:configFile:padCharacter:unkCharacter:
generatePlumSpansForRequest:
maxTokens
maxTokenLength
beamSize
wordCharactersTensorEnabled
wordLengthTensorEnabled
_handler
_postProcessor
_wordCharactersTensorEnabled
_wordLengthTensorEnabled
_maxTokens
_maxTokenLength
_beamSize
TQ,R,N,V_maxTokens
TQ,R,N,V_maxTokenLength
TQ,R,N,V_beamSize
TB,R,N,V_wordCharactersTensorEnabled
TB,R,N,V_wordLengthTensorEnabled
fileExistsAtPath:
lengthOfBytesUsingEncoding:
getBytes:maxLength:usedLength:encoding:options:range:remainingRange:
intermediateNodeRepresentations:
checkFileExistence:error:
nerScore
alternativeIndex
_chunkPredictions
_nerScore
_alternativeIndex
T@"NSArray",R,N,V_chunkPredictions
T@"NSNumber",R,N,V_nerScore
TQ,R,N,V_alternativeIndex
category
_category
TQ,R,V_type
T@"NSString",R,C,V_category
calibrationEspressoModule
_entityValue
T@"NSString",R,C,V_entityValue
initWithIntent:
entityWithValue
_entityWithValue
T@"UPEntityWithValue",R,V_entityWithValue
initWithValues:withNumTokens:withNumLayers:withEmbeddingDim:withEmbedderId:
_values
_numTokens
_numLayers
_embeddingDim
_embedderId
T@"NSArray",R,N,V_values
TQ,R,N,V_numTokens
TQ,R,N,V_numLayers
TQ,R,N,V_embeddingDim
T@"NSString",R,N,V_embedderId
dealloc
initWithLabel:dataDetectorResult:
Tr^{__CFArray=},R,V_dataDetectorResult
localeWithLocaleIdentifier:
initLoadFromDataDetectorsDirectoryPath:forLocale:
dataDetectorsDirectoryPath
languageCode
dataDetector
_matchSpansForDetectedDataArray:label:
addObjectsFromArray:
initLoadFromDataDetectorsDirectoryPath:
initWithSystemConfiguration:forLocale:
matchSpans:
matchSpansForUtterance:
matchSpansForDetectedData:
ddUsoMapper
_dataDetector
_ddUsoMapper
T^{UPDataDetector=q^{__DDScanner}^{__DDScanner}^{__DDScanner}^{__DDScanner}^{__DDScanner}^{__DDScanner}},R,V_dataDetector
T^v,R,V_ddUsoMapper
_domainResult
_coreResult
_query
_dialogAct
T@"UPResult",R,N,V_domainResult
T@"UPResult",R,N,V_coreResult
T@"UPQuery",R,N,V_query
T@"<UPDialogAct>",R,N,V_dialogAct
coarseEntityType
_coarseEntityType
_fineGrainedEntityType
_chunkScore
_charIndicesRange
T@"NSString",R,N,V_coarseEntityType
T@"NSString",R,N,V_fineGrainedEntityType
T{_NSRange=QQ},R,N,V_charIndicesRange
T@"NSNumber",R,N,V_chunkScore
_initWithBioLabelsVocabPath:configPath:grammarPath:intentVocabPath:spanVocabPath:parserEspressoModelPath:calibrationEspressoModelPath:
stringByAppendingPathComponent:
_configurationWithBioLabelsVocabPath:configPath:grammarPath:intentVocabPath:spanVocabPath:parserEspressoModelPath:calibrationEspressoModelPath:error:
configurationFromDirectoryUrl:error:
configPath
grammarPath
spanVocabPath
parserEspressoModelPath
calibrationEspressoModelPath
espressoModelPath
_bioLabelsVocabPath
_configPath
_grammarPath
_intentVocabPath
_spanVocabPath
_parserEspressoModelPath
_calibrationEspressoModelPath
_espressoModelPath
T@"NSString",R,C,V_bioLabelsVocabPath
T@"NSString",R,C,V_configPath
T@"NSString",R,C,V_grammarPath
T@"NSString",R,C,V_intentVocabPath
T@"NSString",R,C,V_spanVocabPath
T@"NSString",R,C,V_parserEspressoModelPath
T@"NSString",R,C,V_calibrationEspressoModelPath
T@"NSString",R,C,V_espressoModelPath
componentsSeparatedByString:
exceptionWithName:reason:userInfo:
getTypeWithtoutPlumPrefix
usoSerializedGraph
setUsoSerializedGraph:
originalMention
score
_usoSerializedGraph
_originalMention
_score
T@"USOSerializedGraph",&,V_usoSerializedGraph
T@"NSString",R,V_originalMention
T@"NSNumber",R,C,V_score
valueWithRange:
process:dataDetectorSpans:
initWithTokens:originalUtterance:normalizedUtterance:
_originalUtterance
_normalizedUtterance
_tokens
T@"NSString",R,N,V_originalUtterance
T@"NSString",R,N,V_normalizedUtterance
T@"NSArray",R,N,V_tokens
dictionaryWithContentsOfFile:
initWithLocale:tokenizer:isPLUMEnabled:featurizer:
hasCalibrationModel
_bundleId
_labelToValueType
_resolver
_beamMaskInput
_parserEspressoModule
_calibrationEspressoModule
T@"NSLocale",R,N,V_locale
TB,R,V_isPLUMEnabled
T@"NSString",R,N,V_bioLabelsVocabPath
T@"NSString",R,N,V_intentVocabPath
T^v,R,N,V_labelToValueType
T^v,R,N,V_resolver
T^v,R,N,V_beamMaskInput
T^{EspressoModule=^v^v{?=^vi}},R,N,V_parserEspressoModule
T^{EspressoModule=^v^v{?=^vi}},R,N,V_calibrationEspressoModule
TB,R
T@"NSString",R,N,V_bundleId
_candidates
subarrayWithRange:
rootNode
_queryUUID
__candidates
T@"NSArray",R,C,N,V__candidates
T@"NSUUID",R,C,V_queryUUID
T@"UPResultRootNode",R,C
initWithTokens:embeddingsByToken:spans:dialogAct:
enumerateSpansWithType:block:
setTokens:
embeddingsByToken
setEmbeddingsByToken:
spans
__utterance
_embeddingsByToken
_spans
T@"NSArray",C,V_tokens
T@"NSDictionary",C,V_embeddingsByToken
T@"NSArray",R,C,V_spans
T@"<SIRINLUSystemDialogAct><NSObject>",R,V_dialogAct
containsString:
rangeOfString:
substringToIndex:
substringFromIndex:
longValue
_indexedLabelRepresentation
leafNodeRepresentation
_text
_groupId
_semanticValue
_structuredData
T@"NSString",R,V_label
T@"NSString",R,V_text
T@"NSNumber",R,V_groupId
T@"NSString",R,V_semanticValue
T@"UPResultStructuredDataNode",R,V_structuredData
T@"UPResultLeafNode",R
T@"NSString",R
entityValues
_entityValues
T@"NSArray",R,C,V_entityValues
getDimension
getCoordinates
tokenizer
__featurizer
_tokenizer
T@"UPTokenizer",R,N,V_tokenizer
_initWithDataDetectorsDirectoryPath:
_configurationWithDataDetectorsDirectoryPath:error:
_dataDetectorsDirectoryPath
T@"NSString",R,C,V_dataDetectorsDirectoryPath
matchedSpans
initWithTokenizedUtterance:embeddings:matchedSpans:
_tokenizedUtterance
_embeddings
_matchedSpans
T@"UPPLTokenization",R,N,V_tokenizedUtterance
T@"UPPLEmbeddingTensor",R,N,V_embeddings
T@"NSArray",R,N,V_matchedSpans
T@"NSString",R,C,V_text
T@"NSString",R,C,V_semanticValue
T@"UPResultStructuredDataNode",R,C,V_structuredData
tokenId
isSpecialToken
numberWithBool:
isWordPiece
isOverflow
encodedLabels
initWithToken:tokenId:charIndicesRange:graphemeClusters:
initWithToken:tokenId:charIndicesRange:graphemeClusters:isSpecialToken:isWordPiece:isOverflow:encodedLabels:
_isSpecialToken
_isWordPiece
_isOverflow
_token
_tokenId
_graphemeClusters
_encodedLabels
T@"NSString",R,N,V_token
TQ,R,N,V_tokenId
T@"NSArray",R,N,V_graphemeClusters
TB,R,N,V_isSpecialToken
TB,R,N,V_isWordPiece
TB,R,N,V_isOverflow
T@"NSArray",R,N,V_encodedLabels
fileSystemRepresentation
_initWithCppOrchestrator:
convertNLv4ParserRequestToCpp:
convertNLv4ParserResponseFromCppToObjC:
parserFromAssetDirectory:error:
parserFromSpansVocab:targetVocab:contextVocab:parserEncoder:parserDecoder:config:error:
_cppOrchestrator
arrayWithArray:
initWithCoordinates:
_embedding
_alternativePredictions
T@"NSArray",R,N,V_alternativePredictions
_contextualizeByDialogActTypeUsingContextualizerInput:
cancelContextualizerStrategy
offerContextualizerStrategy
optionsContextualizerStrategy
promptContextualizerStrategy
_cancelContextualizerStrategy
_offerContextualizerStrategy
_optionsContextualizerStrategy
_promptContextualizerStrategy
T@"UPContextualizerStrategyCancel",R,N,V_cancelContextualizerStrategy
T@"UPContextualizerStrategyOffer",R,N,V_offerContextualizerStrategy
T@"UPContextualizerStrategyOptions",R,N,V_optionsContextualizerStrategy
T@"UPContextualizerStrategyPrompt",R,N,V_promptContextualizerStrategy
@24@0:8^{_NSZone=}16
@24@0:8@16
B24@0:8@16
Q16@0:8
@16@0:8
v16@0:8
@"NSUUID"
@"NSString"
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B16@0:8
B24@0:8#16
B24@0:8:16
Vv16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
@"UPResult"24@0:8@"UPContextualizerInput"16
@32@0:8d16@24
d16@0:8
@"UPUsoSerializer"
@24@0:8d16
@40@0:8@16{_NSRange=QQ}24
{_NSRange=QQ}16@0:8
{_NSRange="location"Q"length"Q}
@48@0:8{_NSRange=QQ}16@32^{__DDResult=}40
@56@0:8{_NSRange=QQ}16@32^{__DDResult=}40@48
^{__DDResult=}16@0:8
^{__DDResult=}
@"USOSerializedGraph"
@32@0:8@16@24
@32@0:8@16^@24
@48@0:8@16@24@32^@40
@"UPParserModel"
@"NSSet"
@"UPCalibration"
@"UPDialogActConverter"
@"UPContextualizer"
@48@0:8@16@24@32@40
@40@0:8@16@24^@32
@52@0:8r^v16f24r^v28r^v36@44
{UPInferenceResult={UPGenericTensor={vector<unsigned long, std::allocator<unsigned long>>=^Q^Q{__compressed_pair<unsigned long *, std::allocator<unsigned long>>=^Q}}{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}}{UPGenericTensor={vector<unsigned long, std::allocator<unsigned long>>=^Q^Q{__compressed_pair<unsigned long *, std::allocator<unsigned long>>=^Q}}{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}}{UPGenericTensor={vector<unsigned long, std::allocator<unsigned long>>=^Q^Q{__compressed_pair<unsigned long *, std::allocator<unsigned long>>=^Q}}{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}}}120@0:8{UPGenericTensor={vector<unsigned long, std::allocator<unsigned long>>=^Q^Q{__compressed_pair<unsigned long *, std::allocator<unsigned long>>=^Q}}{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}}16{UPGenericTensor={vector<unsigned long, std::allocator<unsigned long>>=^Q^Q{__compressed_pair<unsigned long *, std::allocator<unsigned long>>=^Q}}{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}}64@112
@56@0:8r^v16@24r^v32r^v40^v48
@56@0:8r^v16r^v24r^v32^v40r^v48
v20@0:8B16
@"UPModelIdentifier"
@"UPSystemConfiguration"
@"UPLoadedModelConfiguration"
@40@0:8@16@24@32
@"NSArray"
@32@0:8r^v16r^{UsoGraphNode=^^?^{UsoGraph}Q}24
@40@0:8{vector<std::pair<std::reference_wrapper<siri::ontology::UsoGraphNode>, std::reference_wrapper<const siri::ontology::UsoGraphEdge>>, std::allocator<std::pair<std::reference_wrapper<siri::ontology::UsoGraphNode>, std::reference_wrapper<const siri::ontology::UsoGraphEdge>>>>=^v^v{__compressed_pair<std::pair<std::reference_wrapper<siri::ontology::UsoGraphNode>, std::reference_wrapper<const siri::ontology::UsoGraphEdge>> *, std::allocator<std::pair<std::reference_wrapper<siri::ontology::UsoGraphNode>, std::reference_wrapper<const siri::ontology::UsoGraphEdge>>>>=^v}}16
@32@0:8@16r^v24
v40@0:8@16^v24^{UsoGraphNode=^^?^{UsoGraph}Q}32
v72@0:8@16{_NSRange=QQ}24@40@48^{UsoGraphNode=^^?^{UsoGraph}Q}56^v64
{shared_ptr<siri::ontology::UsoVocabManager>="__ptr_"^{UsoVocabManager}"__cntrl_"^{__shared_weak_count}}
@32@0:8@16d24
@36@0:8@16B24^@28
@56@0:8@16@24@32@40^@48
@64@0:8@16@24@32@40@48^@56
{unique_ptr<const sirinluinternalsnlc::SNLCParserRequest, std::default_delete<const sirinluinternalsnlc::SNLCParserRequest>>={__compressed_pair<const sirinluinternalsnlc::SNLCParserRequest *, std::default_delete<const sirinluinternalsnlc::SNLCParserRequest>>=^{SNLCParserRequest}}}24@0:8@16
@40@0:8{SNLCParserResponse=^^?if{?=b1b1}}16
{unique_ptr<snlc_inference_orchestrator::orchestration::SNLCOrchestrator, std::default_delete<snlc_inference_orchestrator::orchestration::SNLCOrchestrator>>="__ptr_"{__compressed_pair<snlc_inference_orchestrator::orchestration::SNLCOrchestrator *, std::default_delete<snlc_inference_orchestrator::orchestration::SNLCOrchestrator>>="__value_"^{SNLCOrchestrator}}}
{unique_ptr<snlp::common::asset_logger::SNLPAssetLogger, std::default_delete<snlp::common::asset_logger::SNLPAssetLogger>>="__ptr_"{__compressed_pair<snlp::common::asset_logger::SNLPAssetLogger *, std::default_delete<snlp::common::asset_logger::SNLPAssetLogger>>="__value_"^{SNLPAssetLogger}}}
@72@0:8d16@24@32@40@48@56@64
@"NSObject<SIRINLUUserDialogAct>"
@"NSNumber"
@"NSDictionary"
@"UPCalibrationModel"
@"UPPreprocessor"
@"NSLocale"
@"UPEntityWithValue"
@160@0:8{UPGenericTensor={vector<unsigned long, std::allocator<unsigned long>>=^Q^Q{__compressed_pair<unsigned long *, std::allocator<unsigned long>>=^Q}}{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}}16{UPGenericTensor={vector<unsigned long, std::allocator<unsigned long>>=^Q^Q{__compressed_pair<unsigned long *, std::allocator<unsigned long>>=^Q}}{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}}64{vector<nl_featurization::Token, std::allocator<nl_featurization::Token>>=^{Token}^{Token}{__compressed_pair<nl_featurization::Token *, std::allocator<nl_featurization::Token>>=^{Token}}}112{vector<uaap::UPDetectedSpan, std::allocator<uaap::UPDetectedSpan>>=^{UPDetectedSpan}^{UPDetectedSpan}{__compressed_pair<uaap::UPDetectedSpan *, std::allocator<uaap::UPDetectedSpan>>=^{UPDetectedSpan}}}136
^v16@0:8
{UPGenericTensor="shape"{vector<unsigned long, std::allocator<unsigned long>>="__begin_"^Q"__end_"^Q"__end_cap_"{__compressed_pair<unsigned long *, std::allocator<unsigned long>>="__value_"^Q}}"data"{vector<float, std::allocator<float>>="__begin_"^f"__end_"^f"__end_cap_"{__compressed_pair<float *, std::allocator<float>>="__value_"^f}}}
{vector<nl_featurization::Token, std::allocator<nl_featurization::Token>>="__begin_"^{Token}"__end_"^{Token}"__end_cap_"{__compressed_pair<nl_featurization::Token *, std::allocator<nl_featurization::Token>>="__value_"^{Token}}}
{vector<uaap::UPDetectedSpan, std::allocator<uaap::UPDetectedSpan>>="__begin_"^{UPDetectedSpan}"__end_"^{UPDetectedSpan}"__end_cap_"{__compressed_pair<uaap::UPDetectedSpan *, std::allocator<uaap::UPDetectedSpan>>="__value_"^{UPDetectedSpan}}}
@44@0:8@16{_NSRange=QQ}24B40
B40@0:8@16d24@32
@56@0:8@16@24@32@40@48
@40@0:8@16@24@?32
@64@0:8@16@24@32@40@48@56
@80@0:8@16@24@32@40@48@56@64@72
v24@0:8@16
{unique_ptr<global_ner::GlobalNerHandler, std::default_delete<global_ner::GlobalNerHandler>>="__ptr_"{__compressed_pair<global_ner::GlobalNerHandler *, std::default_delete<global_ner::GlobalNerHandler>>="__value_"^{GlobalNerHandler}}}
@"UPPLPostProcessor"
B32@0:8@16^@24
{_NSRange=QQ}32@0:8Q16Q24
{basic_string<char16_t, std::char_traits<char16_t>, std::allocator<char16_t>>={__compressed_pair<std::basic_string<char16_t>::__rep, std::allocator<char16_t>>={__rep=(?={__long=QQ^S}{__short=(?=CS)[11S]}{__raw=[3Q]})}}}24@0:8@16
@24@0:8r^v16
@40@0:8@16@24Q32
@48@0:8{_NSRange=QQ}16Q32@40
d120@0:8{UPGenericTensor={vector<unsigned long, std::allocator<unsigned long>>=^Q^Q{__compressed_pair<unsigned long *, std::allocator<unsigned long>>=^Q}}{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}}16{UPGenericTensor={vector<unsigned long, std::allocator<unsigned long>>=^Q^Q{__compressed_pair<unsigned long *, std::allocator<unsigned long>>=^Q}}{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}}64@112
@56@0:8@16Q24Q32Q40@48
@32@0:8@16r^{__CFArray=}24
r^{__CFArray=}16@0:8
r^{__CFArray=}
@32@0:8^{__CFArray=}16@24
^{UPDataDetector=q^{__DDScanner}^{__DDScanner}^{__DDScanner}^{__DDScanner}^{__DDScanner}^{__DDScanner}}16@0:8
^{UPDataDetector=q^{__DDScanner}^{__DDScanner}^{__DDScanner}^{__DDScanner}^{__DDScanner}^{__DDScanner}}
@"UPResult"
@"UPQuery"
@"<UPDialogAct>"
@72@0:8@16@24{_NSRange=QQ}32{_NSRange=QQ}48@64
@80@0:8@16@24@32@40@48@56@64^@72
@72@0:8@16@24@32@40@48@56@64
@64@0:8{_NSRange=QQ}16@32@40@48@56
v32@0:8@16@24
^{EspressoModule=^v^v{?=^vi}}16@0:8
^{EspressoModule=^v^v{?=^vi}}
@32@0:8@16Q24
@24@0:8q16
q16@0:8
v32@0:8Q16@?24
@"<SIRINLUSystemDialogAct><NSObject>"
@72@0:8{_NSRange=QQ}16@32@40@48@56@64
@"UPResultStructuredDataNode"
@44@0:8@16@24B32r^{AbstractFeaturizer=^^?}36
r^{AbstractFeaturizer=^^?}
@"UPTokenizer"
@"UPPLTokenization"
@"UPPLEmbeddingTensor"
@56@0:8@16Q24{_NSRange=QQ}32@48
@76@0:8@16Q24{_NSRange=QQ}32@48B56B60B64@68
@72@0:8@16@24@32@40@48@56^@64
@24@0:8{unique_ptr<nlv4_inference_orchestrator::orchestration::NLv4InferenceOrchestrator, std::default_delete<nlv4_inference_orchestrator::orchestration::NLv4InferenceOrchestrator>>={__compressed_pair<nlv4_inference_orchestrator::orchestration::NLv4InferenceOrchestrator *, std::default_delete<nlv4_inference_orchestrator::orchestration::NLv4InferenceOrchestrator>>=^{NLv4InferenceOrchestrator}}}16
{unique_ptr<nlv4_inference_orchestrator::orchestration::NLv4InferenceOrchestrator, std::default_delete<nlv4_inference_orchestrator::orchestration::NLv4InferenceOrchestrator>>="__ptr_"{__compressed_pair<nlv4_inference_orchestrator::orchestration::NLv4InferenceOrchestrator *, std::default_delete<nlv4_inference_orchestrator::orchestration::NLv4InferenceOrchestrator>>="__value_"^{NLv4InferenceOrchestrator}}}
@"UPContextualizerStrategyCancel"
@"UPContextualizerStrategyOffer"
@"UPContextualizerStrategyOptions"
@"UPContextualizerStrategyPrompt"
@(#)PROGRAM:SiriNaturalLanguageParsing  PROJECT:SiriNaturalLanguageParsing-1
Zvvv:Z
NSt3__16__nodeIcEE
NSt3__110shared_ptrINS_13__empty_stateIcEEE27__shared_ptr_default_deleteIS2_S2_EE
NSt3__114default_deleteINS_13__empty_stateIcEEEE
NSt3__116__owns_one_stateIcEE
NSt3__115__has_one_stateIcEE
NSt3__118__match_char_icaseIcNS_12regex_traitsIcEEEE
NSt3__112__match_charIcEE
NSt3__116__back_ref_icaseIcNS_12regex_traitsIcEEEE
NSt3__110__back_refIcEE
NSt3__120__bracket_expressionIcNS_12regex_traitsIcEEEE
NSt3__117__owns_two_statesIcEE
NSt3__111__alternateIcEE
NSt3__111__match_anyIcEE
9-N4siri8ontology12UsoGraphNodeE
N4uaap19DateDurationHandlerE
N4uaap23AbstractDateTimeHandlerE
,>OO
9N4snlp6common14text_uso_graph26UsoGraphTextTreeParseErrorE
N4snlp6common14text_uso_graph21UDATextTreeParseErrorE
N4uaap8UPDDSpanE
N4uaap12UPDDTimeSpanE
N4uaap20UPDDDateTimeBaseSpanE
N4uaap11TimeHandlerE
N4uaap12UPDDDateSpanE
N4uaap15DateSpanHandlerE
N4uaap11DateHandlerE
.A5bb
####!
;TTTTTTTTTA
58EEEE=
N4snlp6common9exception18SNLPAssetExceptionE
N8nlohmann6detail9exceptionE
false
N8nlohmann6detail12out_of_rangeE
NSt3__117bad_function_callE
N8nlohmann6detail16invalid_iteratorE
N8nlohmann6detail10type_errorE
N8nlohmann6detail11parse_errorE
NSt3__118basic_stringstreamIcNS_11char_traitsIcEENS_9allocatorIcEEEE
NSt3__120__shared_ptr_emplaceIN27snlc_inference_orchestrator10vocabulary10VocabularyENS_9allocatorIS3_EEEE
&3oo
Zvvv:Z
vH7B
W4vC
9Y>)F$
raB3G
)c=H
]rHa
O8Mr
bnMG
.wN9
[*QmU
mr"iR
R$N(
>S}W
-sSO\
T%L9
hGT.
B}T}
=@[V
!a9X
X5AHx
%4xY
Z~$|7
+\0I
2a\|
\ysK
|M$D
pH_r
(:W"
s\ax}?
pc2g
@BXV
tC7Ddx
EydV
d66
eax~Z
ekhHD
@iZb
k0V(
k*do^
:V!2m
RJqn
bzo=
$qE}
XqkY
quAt
Jugm
~B v
STv/N
_w&2
xg^Jp5|
yMzw
{zel#|67
P/};
[@JO
nQ:B
9N4snlp6common14text_uso_graph20ExactMatchComparatorE
N4snlp6common14text_uso_graph18UsoGraphComparatorE
####!
;TTTTTTTTTA
58EEEE=
false
N4snlp6common14text_uso_graph16ActionListParserE
N4snlp6common14text_uso_graph14TextTreeParserE
N4siri8ontology17OntologyExceptionE
N4siri8ontology21OntologyBaseExceptionE
N4snlp6common14text_uso_graph22UsoGraphTextTreeParserE
N4siri8ontology17IsNameTypeVisitorINS0_16OntologyNodeNameEEE
N4siri8ontology16NoOpONameVisitorE
N4siri8ontology19OntologyNameVisitorE
N4siri8ontology17IsNameTypeVisitorINS0_16OntologyVerbNameEEE
N4siri8ontology17IsNameTypeVisitorINS0_16OntologyEdgeNameEEE
N4uaap20UPDDTimeDurationSpanE
N4uaap19TimeDurationHandlerE
9-N4uaap16UPDDDateTimeSpanE
N4uaap15DateTimeHandlerE
N4uaap25UPDDSpecialDatePeriodSpanE
N4uaap20UPDDAbsoluteDateSpanE
N4uaap18UPDDDateOffsetSpanE
####!
;TTTTTTTTTA
58EEEE=
Zvvv:Z
N4snlp6common9exception13SNLPExceptionE
NSt3__114basic_ifstreamIcNS_11char_traitsIcEEEE
NSt3__113basic_filebufIcNS_11char_traitsIcEEEE
false
NSt3__119basic_ostringstreamIcNS_11char_traitsIcEENS_9allocatorIcEEEE
NSt3__115basic_stringbufIcNS_11char_traitsIcEENS_9allocatorIcEEEE
N4siri8ontology16OntologyUnitNameE
N5boost6detail17sp_counted_impl_pINS_6random23mersenne_twister_engineIjLm32ELm624ELm397ELm31ELj2567483615ELm11ELj4294967295ELm7ELj2636928640ELm15ELj4022730752ELm18ELj1812433253EEEEE
N5boost6detail15sp_counted_baseE
N5boost16exception_detail10clone_implINS0_19error_info_injectorISt13runtime_errorEEEE
N5boost16exception_detail19error_info_injectorISt13runtime_errorEE
N5boost9exceptionE
N5boost16exception_detail10clone_baseE
N5boost16exception_detail10clone_implINS0_19error_info_injectorISt16invalid_argumentEEEE
N5boost16exception_detail19error_info_injectorISt16invalid_argumentEE
NSt3__111__end_stateIcEE
NSt3__120__shared_ptr_pointerIPNS_13__empty_stateIcEENS_10shared_ptrIS2_E27__shared_ptr_default_deleteIS2_S2_EENS_9allocatorIS2_EEEE
NSt3__113__empty_stateIcEE
NSt3__120__l_anchor_multilineIcEE
NSt3__120__r_anchor_multilineIcEE
NSt3__115__word_boundaryIcNS_12regex_traitsIcEEEE
NSt3__111__lookaheadIcNS_12regex_traitsIcEEEE
NSt3__123__match_any_but_newlineIcEE
NSt3__120__match_char_collateIcNS_12regex_traitsIcEEEE
NSt3__118__back_ref_collateIcNS_12regex_traitsIcEEEE
NSt3__128__begin_marked_subexpressionIcEE
NSt3__126__end_marked_subexpressionIcEE
NSt3__16__loopIcEE
NSt3__117__repeat_one_loopIcEE
NSt3__121__empty_non_own_stateIcEE
&3oo
Zvvv:Z
9N27nlv4_inference_orchestrator13span_matching36RelativeThresholdMatchingSpansFilterE
N27nlv4_inference_orchestrator13span_matching19MatchingSpansFilterE
N4uaap15TimeSpanHandlerE
####!
;TTTTTTTTTA
58EEEE=
false
Zvvv:Z
N4snlp6common14text_uso_graph19SpacedTextTreeLexerE
N4snlp6common14text_uso_graph13TextTreeLexerE
Zvvv:Z
N4snlp6common14text_uso_graph17UDATextTreeParserE
.A5__
N16nl_featurization14FeaturizerImplE
N16nl_featurization18AbstractFeaturizerE
N10global_ner12post_process20GeographicAreaEntityE
N10global_ner12post_process22PersonalLocationEntityE
N10global_ner12post_process18EmailAddressEntityE
#0ss
^dkN10global_ner9inference16NerEspressoModelE
N10global_ner9inference13EspressoModelE
9-N10global_ner12post_process14CurrencyEntityE
N10global_ner12post_process6EntityE
N10global_ner12post_process18BusinessNameEntityE
N10global_ner12post_process13AppNameEntityE
N10global_ner12post_process21MeasurementUnitEntityE
N10global_ner12post_process26MeasurementComponentEntityE
N10global_ner12post_process17PhoneNumberEntityE
N10global_ner12post_process17OtherPersonEntityE
N10global_ner12post_process12NumberEntityE
N10global_ner12post_process17MeasurementEntityE
(|
(|
UserAccepted
UserStatedTask
[insights-snlp-snlc]: 
[insights-snlp-nlv4]: 
[insights-snlp-uaap]: 
component_name
old_prediction
hidden
memory
encodings
num_of_utterance_tokens
attention_index
out_predictions
out_new_hidden
out_new_memory
out_new_attention_index
-[UPContextualizerStrategyPrompt resultUsingContextualizerInput:]
UPContextualizerStrategyPrompt.m
[dialogAct isKindOfClass:[UPDialogActPrompt class]]
config.json
version.yaml
^VERSION: (\w+)\.(\d+)\.(\d+)
Version file not found at path: 
Version file has no parseable version key: 
sha256HashForFileContent
SNLPUtilities-cpp.mm
buffer != NULL
bufferSize > 0
%02x
.DS_Store
bolt_task_id
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
-[UPContextualizerStrategyOffer resultUsingContextualizerInput:]
UPContextualizerStrategyOffer.m
[contextualizerInput.dialogAct isKindOfClass:[UPDialogActOffer class]]
label
tokenIndicesIndex
[%lu, %lu)
forward
espresso_transformer_model.cpp
firstDecoderOutput.prediction.data.size() == firstDecoderOutput.prediction.shape[1]
input.maxNumHypotheses >= topIndicesAndScores.size()
input.maxNumHypotheses >= hypotheses.size()
decoderOutput.prediction.data.size() == decoderOutput.prediction.shape[1]
input.maxNumHypotheses >= topIndicesAndScoresInner.size()
Token overflow; received 
 tokens, expected 
 or fewer tokens.
padEmbeddings
paddedDataRowLength >= unpaddedDataRowLength
NLv4
SNLC
UaaP
PLUM
UNKNOWN
getComponentString
SNLPLoggingConstants.mm
(size_t)SNLPComponent::_SNLPComponentCount == componentToLogStringMap.size()
<UNDEFINED_COMPONENT>
unordered_map::at: key not found
insertToken
snlc_vocabulary.cpp
mIdToText.size() == mTextToId.size()
[UNK]
[PAD]
[CLS]
[SEP]
Could not open vocabulary data file: 
tokenText argument is empty
Encountered unknown token text and the vocabulary hasno special unknown token
Encountered unknown token ID
map::at:  key not found
vocabulary.cpp
-[UPQueryRunner combinedResultFromResults:]
UPQueryRunner.mm
[queryUUIDs count] == 1
batch_size
max_num_utterance_embeddings
max_num_context_tokens
max_num_spans_tokens
utterance_tokens_embedder_emb_dim
Unknown
CustomVerb
Searching for span with UTF-16 indices (
common_Date
common_Timer
Found matching span with graph:
) vs (
Found a matching insertable span 
Found a new max score, 
, for a non-matching insertable span 
Found a common_Time span with a Jaccard score of 
, overwriting the common_Date span with a Jaccard score of 
UPDialogActPrompt[intent: %@, entityType: %@, entityName: %@, reference: %@]
span_indices
token_embeddings
intent_softmax
app_label_softmax
bio_labels_softmax
group_labels_softmax
-[UPParserModel _resultFromInferenceResult:query:outputTokens:dataDetectorSpans:resolver:]
UPParserModel.mm
intentSoftmaxTensor.shape.size() == 2
intentSoftmaxTensor.shape[0] == 1
intentSoftmaxTensor.shape[1] == numIntents
bioLabelsSoftmaxTensor.shape.size() == 3
bioLabelsSoftmaxTensor.shape[0] == numTokens
bioLabelsSoftmaxTensor.shape[1] == 1
bioLabelsSoftmaxTensor.shape[2] == numBioTags
Espresso context is nil.
Espresso plan is nil.
Could not create espresso plan.
Failed to build espresso plan.
Failed to execute espresso plan.
Failed to clean up espresso plan.
Failed to reshape espresso blob.
Failed to bind buffer to input 
Failed to bind buffer to output 
findBorderScore
beam_search.cpp
kBeamwidth + 1u == sortedTopScores.size()
getTopKTokenIndicesAndScores
kBeamwidth >= indicesAndScoresOfTopScores.size()
applyLogSoftmax
kDimensionality == scores.size()
type
value
children
group_name_transform
smsGroupName
personFullName
Failed to parse 
^ *"(.*)"
^ *(\d+)
^ *([a-zA-Z0-9:_]+)
^ *:([a-zA-Z0-9:_]+)
^ *\n( *)
^ */ *([a-zA-Z0-9:_]+)
^ *\[(\d+):(\d+)\]
com.apple.uaapcustomluframework
resolveNow
TimeHandler.cpp
timeSpan
resolveTimeAndMeridian
resolveDateTimeRangeValue
resolveSpecialTimePeriod
resolveDateTimeQualifierListValue
dtBaseSpan
resolveOffsetDurationValue
resolveTimeWithOffsetValueAndDirection
resolveTime
The month of year value should range from 1 to 12
resolveDateTimeRangeSpanGraph
DateSpanHandler.cpp
dateSpan
resolveRecurringDateSpan
semanticValue
unknownCustomEntity
-[UPUsoSerializer init]
UPUsoSerializer.mm
self != nil
unknownCustomVerb
-[UPUsoSerializer deserializeFromSerializedGraph:]
rootTaskSuccessors.size() == 1
rootTaskSuccessors.at(0).get().getNodeType() == ontology::type::UsoGraphNodeType::TaskNode
UPStructuredData[
[type = 
, value = 
extractStructuredDataInner
UPDataDetectorStructuredData.cpp
resultTypeRef != NULL
resultStartIndex < resultEndIndex
DateHandler.cpp
resolveOffsetDirection
offsetSpan
resolveOffsetDurationValueAndUnit
resolveDurationValueAndUnit
resolveOffsetReference
DataDetectorService
resolveDateOffset
resolveRelativeDayOfWeek
relativeDayOfWeekSpan
resolveRelativeDay
relativeDaySpan
resolveDate
contact_type_split
contactType
emailType
nullptr
string_view::substr
The SNLC asset version (
) is incompatible with inference runtime (compatible versions 
SNLC Orchestrator failed with incompatible major version
Request does not contain a tokenised utterance
Request does not contain a token chain
Request does not contain embeddings
Request embeddings num tokens (
) does not match actual num tokens (
Request embeddings (
) exceeds maximum (
Received null input parser request
runSNLC
espresso_snlc_orchestrator.cpp
indexedTokens.size() <= requestNumTokens
requestEmbeddingValues.size() <= maxNumEmbeddingValues
truncatedSpans.size() == numMatchingSpans
featurizedContext.data.size() <= maxNumContextTokens
featurizedContext.data.size() <= paddedFeaturizedContext .size()
spanFeaturization.shape.size() == 3
indexedTokens.size() <= mask.size()
ERROR: Could not find the config file 
INFO: The parameter 
 is null.  This is currently expected behaviour.
WARNING: Could not parse the config parameter 
json.hpp
[json.exception.
assert_invariant
m_type != value_t::object || m_value.object != nullptr
m_type != value_t::array || m_value.array != nullptr
m_type != value_t::string || m_value.string != nullptr
m_type != value_t::binary || m_value.binary != nullptr
get_decimal_point
loc != nullptr
invalid BOM; must be 0xEF 0xBB 0xBF if given
invalid literal
unget
!token_string.empty()
invalid comment; missing closing '*/'
invalid comment; expecting '/' or '*' after '/'
scan_literal
std::char_traits<char_type>::to_char_type(current) == literal_text[0]
scan_string
current == '\"'
invalid string: missing closing quote
invalid string: '\u' must be followed by 4 hex digits
invalid string: surrogate U+D800..U+DBFF must be followed by U+DC00..U+DFFF
invalid string: surrogate U+DC00..U+DFFF must follow U+D800..U+DBFF
0x00 <= codepoint && codepoint <= 0x10FFFF
invalid string: forbidden character after backslash
invalid string: control character U+0000 (NUL) must be escaped to \u0000
invalid string: control character U+0001 (SOH) must be escaped to \u0001
invalid string: control character U+0002 (STX) must be escaped to \u0002
invalid string: control character U+0003 (ETX) must be escaped to \u0003
invalid string: control character U+0004 (EOT) must be escaped to \u0004
invalid string: control character U+0005 (ENQ) must be escaped to \u0005
invalid string: control character U+0006 (ACK) must be escaped to \u0006
invalid string: control character U+0007 (BEL) must be escaped to \u0007
invalid string: control character U+0008 (BS) must be escaped to \u0008 or \b
invalid string: control character U+0009 (HT) must be escaped to \u0009 or \t
invalid string: control character U+000A (LF) must be escaped to \u000A or \n
invalid string: control character U+000B (VT) must be escaped to \u000B
invalid string: control character U+000C (FF) must be escaped to \u000C or \f
invalid string: control character U+000D (CR) must be escaped to \u000D or \r
invalid string: control character U+000E (SO) must be escaped to \u000E
invalid string: control character U+000F (SI) must be escaped to \u000F
invalid string: control character U+0010 (DLE) must be escaped to \u0010
invalid string: control character U+0011 (DC1) must be escaped to \u0011
invalid string: control character U+0012 (DC2) must be escaped to \u0012
invalid string: control character U+0013 (DC3) must be escaped to \u0013
invalid string: control character U+0014 (DC4) must be escaped to \u0014
invalid string: control character U+0015 (NAK) must be escaped to \u0015
invalid string: control character U+0016 (SYN) must be escaped to \u0016
invalid string: control character U+0017 (ETB) must be escaped to \u0017
invalid string: control character U+0018 (CAN) must be escaped to \u0018
invalid string: control character U+0019 (EM) must be escaped to \u0019
invalid string: control character U+001A (SUB) must be escaped to \u001A
invalid string: control character U+001B (ESC) must be escaped to \u001B
invalid string: control character U+001C (FS) must be escaped to \u001C
invalid string: control character U+001D (GS) must be escaped to \u001D
invalid string: control character U+001E (RS) must be escaped to \u001E
invalid string: control character U+001F (US) must be escaped to \u001F
invalid string: ill-formed UTF-8 byte
get_codepoint
current == 'u'
0x0000 <= codepoint && codepoint <= 0xFFFF
next_byte_in_range
ranges.size() == 2 || ranges.size() == 4 || ranges.size() == 6
scan_number
false
invalid number; expected digit after '-'
invalid number; expected digit after '.'
invalid number; expected '+', '-', or digit after exponent
invalid number; expected digit after exponent sign
endptr == token_buffer.data() + token_buffer.size()
object key
object separator
number overflow parsing '
sax_parse_internal
!states.empty()
array
object
excessive object size: 
handle_value
!keep_stack.empty()
ref_stack.back()->is_array() || ref_stack.back()->is_object()
!key_keep_stack.empty()
object_element
end_object
!ref_stack.empty()
operator->
m_object != nullptr
m_it.object_iterator != m_object->m_value.object->end()
m_it.array_iterator != m_object->m_value.array->end()
cannot get value
invalid_iterator
iterator does not fit current value
iterator out of range
cannot use erase() with 
type_error
null
string
boolean
binary
discarded
number
excessive array size: 
end_array
out_of_range
<U+%.4X>
parse_error
parse error
 at line 
, column 
syntax error 
while parsing 
; last read: '
unexpected 
; expected 
<uninitialized>
true literal
false literal
null literal
string literal
number literal
<parse error>
end of input
'[', '{', or a literal
unknown token
iter_impl
set_begin
cannot compare iterators of different containers
operator==
set_end
cannot use key() for non-object iterators
operator*
type must be number, but is 
type must be boolean, but is 
type must be string, but is 
operator++
SystemGaveOptions
SystemOffered
executed_task
salient_entity
active_task
sdas
executed_tasks
salient_entities
active_tasks
_type=
_full_path=
_verb_entity=
_verb=
_below_verb=
_are_present
_are_absent
[NO_SDAS]
source_tokens_embeddings
matched_spans
context
source_mask
class_probabilities
cancel
notForMe
selectOrdinal
ordinal
[NO_LEGACY_NL_CONTEXT_LABEL]
DICTATION_PROMPT=
STRICT_PROMPT=
PREVIOUS_NLV3_DOMAIN=
TRUE
FALSE
extractContextLabels
snlc_context_featurizer.cpp
!contextLabelsFromLegacyNlContext.empty()
featurize
featurizedContextStringsSorted.size() == mMaxNumContextTokens + truncatedFeatures.size()
featurizedContext.shape.size() == Embedder::kEmbeddedTensorRank
featurizedContext.shape.at(0) == Embedder::kEmbeddedTensorBatchSize
shape = 
 data = 
placeholderVerb
((\w+)::common_(\w+)(\.)?(\w+))
::common
SystemPrompted
SystemOffered.offered_act.
SystemGaveOptions.option.
SystemInformed.entity
SystemReportedSuccess
SystemReportedFailure
_verb_entity
SystemOffered.offered_act.UserStatedTask
SystemOffered.offered_act.UserWantedToProceed
.primitive_String
UserAcknowledged
UserCancelled
UserRejected
UserWantedToPause
UserWantedToProceed
UserWantedToRepeat
SystemInformed
contact_address_downcast
emailAddress
phoneNumber
min_max_labeller
minimumMaximum
floatSettingState
minimum
maximum
de_DE
en_AU
en_CA
en_GB
en_IN
en_US
fr_FR
enum-choices
left-label
name
open-list-choices
repeated
resolution-table
right-labels
rules
semantic-value
synonyms
value-constraints
Error parsing JSON grammar: row.IsObject() == false [for key: 
 entry
Error parsing JSON grammar: parsedSemanticValue != row.MemberEnd() && parsedSemanticValue->value.IsString() == false [for key: 
Error parsing JSON grammar: parsedSynonyms != row.MemberEnd() && parsedSynonyms->value.IsArray() == false [for key: 
Error parsing JSON grammar: parsedSynonym.IsString() == false [for key: 
Error parsing JSON grammar: parsedValueType->value.IsString() == false [for key: 
Error parsing JSON grammar: parsedEnumChoices->value.IsArray() == false [for key: 
Error parsing JSON grammar: parsedOpenListChoices->value.IsArray() == false [for key: 
Error parsing JSON grammar: parsedResolutionTable->value.IsArray() == false [for key: 
Error parsing JSON grammar: leftLabel != jsonRule.MemberEnd() && leftLabel->value.IsString() == false [for key: 
Error parsing JSON grammar: parsedValueConstraints->value.IsObject() == false [for key: 
Error parsing JSON grammar: parsedRightLabels != jsonRule.MemberEnd() && parsedRightLabels->value.IsArray() == false [for key: 
Error parsing JSON grammar: rightLabelObject.IsObject() == false [for key: 
Error parsing JSON grammar: parsedName != rightLabelObject.MemberEnd() && parsedName->value.IsString() == false [for key: 
Error parsing JSON grammar: parsedRepeatedFlag != rightLabelObject.MemberEnd() && parsedRepeatedFlag->value.IsBool() == false [for key: 
Could not open grammar file for reading: 
Grammar file is in error state after reading: 
Label does not exist
getChildrenPathsInner
grammar.cpp
!currentPath.components.empty()
Error parsing JSON grammar: jsonGrammar.IsObject() == false [for key: 
(root)
Error parsing JSON grammar: parsedRules != jsonGrammar.MemberEnd() && parsedRules->value.IsArray() == false [for key: 
FileReadStream
filereadstream.h
fp_ != 0
bufferSize >= 4
GetString
document.h
IsString()
GetStringLength
GetArray
IsArray()
Begin
MemberEnd
IsObject()
Size
Error parsing JSON grammar: enumChoice.IsString() == false [for key: 
Error parsing JSON grammar: openListChoice.IsString() == false [for key: 
GetBool
IsBool()
ParseStream
stack_.GetSize() == sizeof(ValueType)
GetAllocator
stack.h
allocator_
reader.h
!HasParseError()
ParseNull
is.Peek() == 'n'
PushUnsafe
stackTop_
static_cast<std::ptrdiff_t>(sizeof(T) * count) <= (stackEnd_ - stackTop_)
ParseTrue
is.Peek() == 't'
ParseFalse
is.Peek() == 'f'
ParseString
s.Peek() == '\"'
ParseStringToStream
ParseHex4
Encode
encodings.h
codepoint <= 0x10FFFF
GetSize() >= count * sizeof(T)
GenericStringRef
str != 0 || len == 0u
ParseObject
is.Peek() == '{'
GetSize() >= sizeof(T)
ParseArray
is.Peek() == '['
ParseNumber
expFrac <= 0
Pow10
pow10.h
n >= 0 && n <= 308
NotNullStrLen
str != 0
FindMember
name.IsString()
StringEqual
rhs.IsString()
allocator<const T>::allocate(size_t n) 'n' exceeds maximum supported size
Error parsing JSON grammar: parsedRule.IsObject() == false [for key: 
Expected:
Actual:
Badly-formed UDA
DelegatedUserDialogAct
Expected a UDA of type 
 but got a 
SNLPServerNLClassifierErrorDomain
Missing resource: %@
Check that resource is available: %@
SNLC/SNLC.mlmodelc/model.espresso.net
SNLC/spans_pad.txt
SNLC/context_pad.txt
An error occured reading SNLC model bundle at: %@
Check that the path contains a valid model bundle: %@
SNLC Asset Error when creating the SNLC inference orchestrator: %s
Hit SNLP exception while calling SNLCOrchestrator::runSNLC for request (high=%llu, low=%llu): %s
-[SNLPServerNLClassifier inferenceResponseForRequest:error:]
SNLPServerNLClassifier.mm
parserResponse.has_value()
node=
edge=
stringValue=
integerValue=
indentation=
alias=
textAlignment=
after
approx
before
earlier
every
last
lastlast
later
middle
next
nextnext
potentialEvery
same
slidinglast
this
upcoming
week
weekend
weekday
month
quarter
year
summer
winter
autumn
spring
semester
season
businessday
afternoon
bedtime
breakfast
brunch
dinner
evening
happyhour
lunch
midnight
morning
night
noon
ROOT
value=
intent=
[next]
[startPayload]
[leaf]
[endPayload]
[newGroup]
task
UserStarted
UserContinued
UserDisambiguated
UserResponded
directLeafNodes
Could not create analyzer: locale not supported
locale %@ not supported
-[UPTokenizer tokenizeUtterance:]
UPTokenizer.mm
tokIt.getStartChar() >= 0
tokIt.getEndChar() >= 0
B24@?0@"UPToken"8@"NSDictionary"16
-[UPContextualizerStrategyOptions resultUsingContextualizerInput:]
UPContextualizerStrategyOptions.m
[contextualizerInput.dialogAct isKindOfClass:[UPDialogActOptions class]]
common_
Node 
 not found in ontology.
createNodeByName
uso_graph_text_tree_parser.cpp
maybeEntityName.has_value()
Verb 
Root
textAlignment
!mNodeStack.empty()
toTreeDebug
mNodeStack.size() >= 1
attachChildInStack
mNodeStack.size() >= 2
Empty edge found while attaching: 
Edge not found in ontology: 
Could not attach child 
 to parent 
 with edge 
Check
Control
Convert
Create
Delete
Entity
NoVerb
PlaceholderVerb
RecipientsEventTrigger
RecipientsHiddenPeople
Reference
ReferenceControl
ReferenceDateTimeRangeTrigger
ReferenceDurationTrigger
ReferenceMeasurementTrigger
ReferenceNumberTrigger
ReferencePaymentSortKey
ReferencePhotoCollection
ReferencePhotoCollectionFilter
ReferencePhotoFilter
ReferencePhotoMemoryFilter
ReferencePhotoTag
ReferenceProfile
ReferenceSelect
ReferenceSlideshowFilter
ReferenceStringTrigger
ReferenceTarget
ReferenceTargetSelect
ReferenceTrigger
ReferenceVideoFilter
Request
StockSummarise
Summarise
Target
Update
Token indices out of range: [
Unknown LabelScheme observed
Could not deserialise espresso context.
Could not set up espresso network.
not_found
ERROR: Could not find network configuration: 
Note that only parameters of unsigned integer type are currently expected by NLv4Parser.  This issue will likely cause NLv4 parser inference to fail.
UNDEFINED_COMPONENT
Failed to convert CFString to C++ string
DateTime
BeginTime
EndTime
Hours
Meridian
Minutes
MinutesBefore
Seconds
SpecialTimePeriod
Time
TimeDuration
TimeOffset
TimeSpan
AbsoluteDate
Date
DateDuration
DateOffset
DateSpan
DateTimeQualifier
DayOfWeek
MonthNumber
OccurrenceCount
RelativeDay
RelativeDayOfWeek
SpecialDatePeriod
SpecialDatePeriodUnit
SpecialDay
Identifier
B16@?0@"UPResultCandidate"8
+[UPContextualizerUtilities buildPayloadResultFromQuery:modelIdentifier:intent:entityName:serializer:]
UPContextualizerUtilities.m
utterance != nil
send::common_Message
target
common_Message
stringContent
generateOverrideResponse
snlc_override_generator.cpp
request.turnInput()->turnContext()->nlContext()->systemDialogActs().size() == 1
resolveDurationGraph
TimeDurationHandler.cpp
timeDurationSpan
Error opening file: 
Number of element should be 2 in line 
MAX_WORD_LENGTH
MAX_UTTERANCE_LENGTH
USE_CHARS
USE_CHAR_LSTM
TestSpan
Could not open file path
FilePath
+[UPUtilities rangeFromStart:end:]
UPUtilities.mm
start <= end
resolveDateTime
DateTimeHandler.cpp
dateTimeSpan
resolveRecurrenceDuration
resolveRecurringDateTime
mapDateTimeToItemizedUsos
Given UTF-16 offset is not a Unicode scalar (code point) boundary: 
 000000000000
getUnicodeScalarAndUtf8Offsets
string_encoding_utils.cpp
preIncrementOffsetUtf8 < iterationOffsetUtf8
Input string is not a valid UTF-8 sequence! UTF-8 offset: 
Given UTF-16 offset exceeds the input string: 
relative_set_number_verb
setNumber
common_Setting
increaseBy
decreaseBy
unknown/
UPDDTimeDurationSpan
UPDDSpan.cpp
CFEqual(DDResultGetType(ddResult), ddspantype::kTimeDuration)
UPDDSpecialDatePeriodSpan
CFEqual(DDResultGetType(ddResult), ddspantype::kSpecialDatePeriod)
UPDDAbsoluteDateSpan
CFEqual(DDResultGetType(ddResult), ddspantype::kAbsoluteDate)
UPDDDateOffsetSpan
CFEqual(DDResultGetType(ddResult), ddspantype::kDateOffset)
UPDDDateSpan
CFEqual(DDResultGetType(ddResult), ddspantype::kDate) || CFEqual(DDResultGetType(ddResult), ddspantype::kDateSpan)
UPDDDateTimeSpan
CFEqual(DDResultGetType(ddResult), ddspantype::kDateTime)
Could not convert
Component: 
Version: SNLPVersionInfo[train=
, majorVersion=
, minorVersion=
Version: <missing>
Bolt task ID: 
Bolt task ID: <missing>
No assets provided
Combined SHA256: 
asset could not be read
chunkPredictions
nerScore
alternativeIndex
context_vocab.txt
multicardinal_vocab.txt
decoder.mlmodelc/model.espresso.net
encoder.mlmodelc/model.espresso.net
spans_vocab.txt
trg_vocab.txt
span_label_mapping.txt
The NLv4 asset version (
NLv4InferenceOrchestrator
nlv4_orchestrator.cpp
!mMulticardinalVocab.has_value()
NLv4InferenceOrchestrator setup is broken; erroneous assets were provided
NLv4 request is null
pbhandle
numTokens == pbRequest->tokenisedUtterance() ->tokenChain() ->tokens() .size()
PlaceholderVerb_placeholderVerb
ja_JP
common_Message.Target_send
NLv4 request missing request ID
NLv4 request missing valid embeddings
NLv4 request missing valid tokens
NLv4 request missing valid token chain locale
NLv4 request embeddings num tokens (
zh_CN
SystemPrompted.task.send::common_Message.target.common_Message.stringContent
spans_pad_symbol_index
context_pad_symbol_index
start_symbol_index
end_symbol_index
common_DateTime.time
common_Message.recipients
common_PhoneCall.recipients
common_Timer.attributes
common_Message.sender
common_Message.attachments
common_RecurringDateTime.recurrenceDateTimes
common_Message.usoQuantifier
common_Message.attributes
common_Message.participants
common_PhoneCall.attributes
modified_TranslationSourceLocale
common_Translation
sourceString
common_LocalisedString
locale
common_Locale
modified_TranslationPayload
stringValue
modified_TranslationReferenceType
usoReferenceType
modified_TranslationTargetLocale
targetString
modified_GeographicAreaName
geographicArea
common_GeographicArea
modified_GeographicAreaType
areaType
User dialog act node has multiple children.
/dev/urandom
sha1 too many bytes
void boost::uuids::detail::sha1::process_byte(unsigned char)
/System/Volumes/Data/SWE/iOS/BuildRoots/BuildRoot900/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator15.2.Internal.sdk/usr/local/include/boost/uuid/sha1.hpp
Not enough elements in call to seed.
shared_ptr.hpp
px != 0
UPEntityWithValue[entityType: %@, entityName: %@, entityValue:%@]
UPDialogActOffer[intent: %@, entityWithValue: %@]
noMatcher
DataDetector
PlumMatcher
UserVocabMatcher
SingleTrieMatcher
ContextMatcher
OvertonMatcher
MRRDetector
MRRMatcher
RegexSpanMatcher
personRelationship
phoneType
values
numTokens
numLayers
embeddingDim
embedderId
input_ids
input_mask
bert/feature_extraction_output
childrenBeginLabelIdsFromPaths
beam_input.cpp
childBeginBioTagId != childVocabulary.getUnknownTokenId()
buildGrammarMask
childBioTagId != childUnknownTokenId
buildUniqueLabels
firstPathComponent.has_value()
buildIndexableLabels
matchSpansInner
UPDataDetector.cpp
detectedSpans.detectedData
Could not create scanner from cache file: "
".  
createScanner
error == NULL
utterance_tokens_embeddings
padding_mask
span_tokens
position_ids
out_init_decoder_hidden
out_encodings
addresses_
.cache
date_time_
addresses.cache
date_time.cache
flights.cache
currencies.cache
numbers.cache
phone_mobile.cache
coarseEntityType
fineGrainedEntityType
charIndicesRange
chunkScore
[CLS_SPAN]
[SEP_SPAN]
[NO_SPAN]
model_info.plist
info.plist
intent.vocab.txt
bio_labels.vocab.txt
span.vocab.txt
grammar.json
model.mlmodelc
calibration_model.mlmodelc
No USO
mention
entityType
score
usoGraph
%@%@%@
Entity type %@ should contain exactly one %@ and the string before %@ should be equal to %@
 => 
PostProcessor
dateTime
tokens
originalUtterance
normalisedUtterance
app_bundle
neu_inputs
model.espresso.net
max_seq_length
espresso_bert_model.cpp
utteranceTokens.size() == maxNumTokens
utteranceTokensMask.size() == maxNumTokens
hidden_size
embeddingDimension > 0
embeddings.size() / embeddingDimension == input.utteranceTokens.tokens.size()
BERT:
      pre-process 
      forward: 
      post-process: 
resolveMinutesBeforeTimeSpanWithUnit
TimeSpanHandler.cpp
resolveTimeSpanWithUnit
resolveTimeSpan
resolveRecurringTimeSpan
addCLSSEPToTokens
sep_cls_utils.hpp
expandedTokens.size() == tokens.size() + 2u
UPDialogActOptions[intent: %@, entityType: %@, entityName: %@, entityValues: %@]
PLUM_%@
v24@?0@"UPSpan"8^B16
Span label shape incorrect.
Given coordinates do not match tensor shape
Coordinates exceed bounds of tensor
mergePathToTree
ply_state_handler.cpp
std::holds_alternative<PayloadStartEnd>(valueInfo)
SNLPOSLoggerForCategory
SNLPLogging.mm
loggingCategory < SNLPCategoryLogMax
v8@?0
General
Common
UPDataDetectors
SiriNaturalLanguageParsingSignPosts
com.apple.sirinaturallanguageparsing
data_detectors
tokenisedUtterance
embeddings
matchedSpans
text
structuredData
phone-number
common_Time
common_Time12HourClock
common_Time24HourClock
date
Attempting to re-insert span entity to model graph, beneath 
time
Re-insertion of span graph was successful.
common_Integer
usoEntityInsertionPoint
token
tokenId
graphemeClusters
isSpecialToken
isWordPiece
isOverflow
encodedLabels
SNLPNaturalLanguageParserErrorDomain
NLv4 Asset Error when creating the C++ NLv4 orchestrator: %s
Hit SNLP exception while constructing C++ orchestrator with asset directory %@: %s
Hit SNLP exception while constructing C++ orchestrator with spans vocab path %@: %s
Hit SNLP exception while calling NLv4InferenceOrchestrator::pbhandle for request (high=%llu, low=%llu): %s
NLv4InferenceOrchestrator::pbhandle returned nullptrfor request (high=%llu, low=%llu)
alternativePredictions
tensoriseTokens
matched_spans_featurizer.cpp
tokenIndex == numEncodedTokens
featureTensor.size() == numEncodedTokens * maxNumLabels
featureTensor.size() == featureTensorShape[0] * featureTensorShape[1] * featureTensorShape[2]
TreeNode[
label:'
value:'
parentArgument:'
UTF-8 code unit indices:[
UTF-16 code unit indices:[
Unicode code point indices:[
Expected a node to start at: 
Expected an edge to start at: 
Regex search failed: 
^(accepted|acknowledged|cancelled|delegated|rejected|user_stated_task|wanted_to_pause|wanted_to_proceed|wanted_to_repeat|UserAccepted|UserAcknowledged|UserCancelled|DelegatedUserDialogAct|UserRejected|UserStatedTask|UserWantedToPause|UserWantedToProceed|UserWantedToRepeat)
UDA previously defined as 
 but is being redefined as 
Expecting a valid UDA name but got 
User dialog act not yet specified
UDA not yet specified
accepted
acknowledged
cancelled
UserCanceled
delegated
DelegatedDialogAct
rejected
user_stated_task
wanted_to_pause
wanted_to_proceed
wanted_to_repeat
unknown UDA 
person_name_split
handleCommonPersonSubtree
person_name_split.cpp
personMatchingSpansPartitionForNode.value().size() >= 2
^(\b\w+\b)(\S+)$
Failed to initialise the regex expression for the subtokens: 
appendMatchedSpan
span_processor.cpp
mInternals.reverseMapping.find(str) != mInternals.reverseMapping.end() && "Unable to find token chain in reverse mapping after a match was found in the pattern " "trie"
Failed to attach the regex expression to the token text: 
Failed to find match in text: 
Encountered invalid substring: 
Encountered empty normalized matching substring for label: 
Begin/inside BIO tags must have a payload component
Only begin/inside BIO tags can have a payload component
Cannot extract payload from non-begin/inside BIO tag
getPayload
bio.cpp
mPayload.has_value()
Well-formed BIO tags must be >=3 characters long, but got: 
BIO tag has no prefix
Unrecognized BIO tag prefix
convertToLabelledSpans
!currentSpan.has_value()
buildAllBioTagsFromEntityLabels
bioTags.size() == expectedFinalSize
Cannot get value for empty optional!
Span labels tensor is of incorrect shape
Span labels tensor shape does not match tokens size
Unable to instantiate a normalizer form the input normalizer choice
Failed to instantiate normalizer - 
Failed to normalize string 
 - due to error: 
Failed to compare strings - due to error: 
Failed to casefold string: 
Invalid substring range. The endIndex
 >= src length 
Invalid substring range. startIndex  (
) >= endIndex (
Token indices out of range.
Number of tokens differs from number of BIO tags
Number of tokens differs from number of group IDs
Empty entitiesScores (implies no tokens)
Size of groupScores does not equal number of tokens
First dimension of intentEntityTransitions does not equal number of intents
Second dimension of intentEntityTransitions does not equal number of BIO tags
Size of startEntityTransitions does not equal number of BIO tags
First dimension of entityTransitions does not equal number of BIO tags
Second dimension of entityTransitions does not equal number of BIO tags
Out-of-range intent label (key) in uniqueLabels
Out-of-range BIO label (value) in uniqueLabels
Out-of-range intent label (key) in indexableLabels
Out-of-range BIO label (value) in indexableLabels
Invalid beamSize. Should be in the interval (0, 5]
BeamSequence[
  score = 
  intent = 
  entities = 
  groupIds = 
(none)
beamSearch
allCandidates.begin() + beamSize < allCandidates.end()
Beam sequence is empty getIntent
Beam sequence is empty getEntities
Embedding[
 ...
Label vocabulary does not contain pad token
Trans params's first and second dimension should have non-zero equal value, while the actual shape is [
Trans params's first and second dimension value: 
 should be equal to tag size: 
Logits tensor's last dimension value: 
 should be equal to the output label's size: 
 and transit parameters's dimension value: 
Invalid input. Can't have WordCharactersTensorEnabled to be false while have WordLengthTensorEnabled to be true.
Word embedding data first dimension: 
 sequence length data first dimension: 
 word character data first dimension: 
 and word length data first dimension: 
 should have equal non-zero values
Word embedding data second dimension: 
 word character data second dimension: 
 and word length second dimension: 
word_embedding_placeholder
sequence_length_placeholder
word_characters_placeholder
word_length_placeholder
proj/logits
Dimension value: 
 should match first value of shape: 
 should match second value of shape: 
 should match third value of shape: 
Begin index of mention boundary: 
 should be smaller than end index (exclusive) of mention boundary: 
End index (exclusive) of mention boundary: 
 should be smaller or equal then predictions labels size: 
Begin index: 
 should be smaller than end index: 
End index: 
Sequence length: 
 should be less than logits length: 
Logits's shape should be [maxTokens (Siri default is 26),
], while the actual shape is [
Output label map contains label: 
 which is not B, I and O label
Output label map file is empty
Output label map file is invalid. Valid output label map should has O tag with 1 label value, I labels comes after B labels, while the actual value is: O tag: 
, first B tag: 
, last B tag: 
, first I tag: 
, last I tag: 
B labels and I labels should have equal size, while the actual value is: first B tag: 
Transition parameters loaded is invalid. Transition parameters's first and second dimension should have non-zero equal value
Vocab indices map file is empty
The given chunkPredictions and usoGraphs don't have equal size
measurement
measurementComponent
otherPerson
appName
personalLocation
businessName
measurementUnit
currency
Entities with type 
 or 
 both exist in char index range [
Can't find entities with type: 
 and entities with type: 
 in char index range [
Entities with type: 
) has more than one
Entity is not with type 
Can't cast to pointer to 
com.apple.siri.nlteam.plum
NerHandler
NerFactory
Espresso
The input nest tag: 
 is empty
Can't get flat tags from: 
The input nest B tag: 
Can't get B tags from: 
Tag 
 is not a B tag
Can't locate I tag
Can't locate 
 in iTagIndicesMap
Tag after split should have size 2
 in output label map
No Number child entities and MeasurementUnit child entity is null
Fail to create espresso context.
Fail to create espresso pan.
Fail to set up espresso network.
Can't find character: 
 in character indices map
Num of tokens in embedding tensor: 
 doesn't match with sequence length: 
Num of layers in embedding tensor: 
 is not 1. Currently NER only support number of layer to be 1.
Number of embedding float values: 
 doesn't match with embedding shape: [
Size of NER alternative prediction from NER factory: 
 is not 1
Find both commonMeasurementComponent node and commonCurrency node. Invalid measurement entity.
Both commonMeasurementComponent node and commonCurrency node don't exist. Invalid measurement entity.
Find more than one commonCurrency node. Invalid measurement entity.
Attempt pruning UserAccepted from a one shot reply UserAccepted + UserStatedTask prediction.
Could not find a UserAccepted dialog act to remove.
UPContextualizerStrategyPrompt; %ld domain candidates matched dialog act prompted entity (%@)
UPContextualizerStrategyPrompt: No domain result matched dialog act prompted entity (%@)
UPContextualizerStrategyPrompt: Building verbatim string payload
[%s] Error, file doesn't exist. Hash for file content cannot be calculated: %s
[%s] Error, input stream for file could not be created. Hash for file content cannot be calculated: %s
[%s] Error, input stream for file could not be read. Hash for file content cannot be calculated: %s
[%s] Error while calculating hash of file %s
[%s] Error iterating over directory %s: %s
[%s] Warning: config missing Bolt task ID
[%s] Warning: config Bolt task ID is not a string
UPContextualizerStrategyOffer: Detected high-probability yes/no intent in core result
BEGIN "Encoder Inference"
Encoder Inference
END "Encoder Inference"
BEGIN "Decoder Inference"
Decoder Inference
END "Decoder Inference"
[%s] Invalid featurization input provided to the model.  Expected a non-empty utterance length tensor and a context tensor of at least two dimensions.
[%s] The utterance length (%lu) exceeds the maximum utterance length (%lu).
[%s] padEmbeddings input tensor size = %lu (%lu, %lu, %lu)
[%s] padEmbeddings maxUtteranceLength (defined by network config) = %lu
[%s] Illegal shape for embeddings: (%lu, %lu, %lu). Must be (?, ?, %lu) and hold %lu values
[%s] padEmbeddings For each batch, copying %lu embedding values and adding %lu padding values
[%s] padEmbeddings Padded embedding tensor shape: (%lu, %lu, %lu)
[%s] The component %zu is invalid
Could not convert query dialog act: %{sensitive}@
Converted dialog act and got: %@
Found no utterance alignments, skipping...
Found no matching insertable span.
SiriOntology indicated an entity node, but failed to cast to UsoEntityNode type.
No utterance alignments found in the entity node; searching the descendant nodes for utterance alignments instead.
Found no entities in the uso graph of matching span, skipping...
There is more than one entity in the USO graph of matching span, skipping...
The first level entity is not of entity node type, skipping...
BEGIN "UaaP UPParserModelInit initWithSystemConfiguration"
UaaP UPParserModelInit initWithSystemConfiguration
END "UaaP UPParserModelInit initWithSystemConfiguration"
BEGIN "UaaP EspressoInference"
UaaP EspressoInference
END "UaaP EspressoInference"
BEGIN "UaaP Post-Processing"
Number of BEAM sequences = %lu
Processing BEAM sequence: %s
Produced candidate: %@
UaaP Post-Processing
END "UaaP Post-Processing"
BEGIN "UaaP Prediction"
Error predicting utterance: %{sensitive}s
UaaP Prediction
END "UaaP Prediction"
Featurizing the following context labels in NLv4ParserRequest.
[%s] Found an smsGroupName span that matches a common_Person or common_Agent node
[%s] Found a personFullName span that matches a common_Person or common_Agent node, so skipping group_name_transform
[%s] Replacing the node label "%s" with "%s"
[%s] Found %lu smsGroupName matching spans
[%s] Found %lu personFullName matching spans
[%s] Splitting common_Person nodes in-place
[%s] Iterating through all tree nodes
[%s] Finished iterating through all tree nodes
[%s] Could not split this common_Person node
[%s] Successfully split the common_Person node into name/contact type
[%s] Handling common_Person subtree
[%s] Warning: the common_Person node has more than one child (expecting just `name`). Skipping.
[%s] Warning: the common_Person node child is not `name`. Skipping.
[%s] common_Person.name value: %{sensitive}s
[%s] There exists a person matching span covering this entire common_Person.name node. Skipping.
[%s] Could not find a split for this common_Person. Skipping.
[%s] Warning: Failed to generate a node for matching span (personInput=%{sensitive}s, contactTypeInput=%{sensitive}s)
[%s] Hit out of range exception when looking up token character indices
[%s] newNameNode.startCharIndex (%lu) is less than originalNameStartCharIndex (%lu)
[%s] newNameNode character indices imply an empty or impossible substring (%lu -> %lu)
[%s] contactAddressLabelNode.startCharIndex (%lu) is less than originalNameStartCharIndex (%lu)
[%s] contactAddressLabelNode character indices imply an empty or impossible substring (%lu -> %lu)
[%s] Generated new common_Person.name node with newNameNode.startCharIndex=%lu, newNameNode.endCharIndex=%lu, newNameNode.value=%{sensitive}s
[%s] After filtering, we have %lu contact type matching spans
[%s] After filtering, we have %lu person matching spans
[%s] Warning: could not find start token index corresponding to node.startCharIndex=%lu
[%s] Warning: could not find end token index corresponding to node.endCharIndex=%lu
[%s] Deleting %lu nodes
[%s] Inserting %lu spawned nodes
BEGIN "SNLC Span Featurization"
SNLC Span Featurization
END "SNLC Span Featurization"
BEGIN "SNLC Context Featurization"
SNLC Context Featurization
END "SNLC Context Featurization"
BEGIN "SNLC Inference"
SNLC Inference
END "SNLC Inference"
Unsupported SNLC classification result. Returning an empty SNLC response.
Warning: Invalid model version provided: %u.  Model versions currently supported: %s.
[%s] %s
A token could not be reindexed; %{sensitive}s
Unknown error thrown during token index conversion (should be unreachable)
Token indexes could not be converted: %s
Featurized the following %lu LegacyNLContext features in SNLCParserRequest: %s
Failed to featurize any labels from legacyNlContext
Warning: Legacy NL context features were supplied, but the asset directory major version (%u) does not support these. These will not be featurized.
Warning: The request's nlContext contains a SDA. Skipping featurization for the legacy context.
No SDA present in nlContext: falling back to legacyNlContext
Failed to extract any labels from nlContext or legacyNlContext
Label '%s' not present in vocabulary. Skipping. (Is this label supported by the provided assets?)
Number of context features (%lu) exceeds maximum limit (%lu): truncating by removing features %s
%s SNLC context: %s
SNLC non-padded context input tensor: %s
[%s] Badly formed SystemPrompted dialog act; needs to contain the target UsoGraph.
[%s] Badly formed SystemOffered dialog act; needs to contain a user dialog act.
[%s] Badly formed SystemReportedSuccess dialog act; needs to supply the task UsoGraph.
[%s] Badly formed SystemReportedFailure dialog act; needs to supply the UsoGraphs for the failed task and for the failure reason.
[%s] Warning: Badly formed user dialog act.
[%s] Failed to cast USO task node from SiriOntology. 
[%s] After filtering, we have %lu %s matching spans
[%s] No grounded tokens found under node: %s
No calibration score found for parser result with bundle modelIdentifier: %@
[%s] Both %s and %s semantic values found when using %s spans
[%s] MatchingSpan with label %s, semantic value %s found?: %{BOOL}d
[SNLC Assets] %s
BEGIN "SNLPServerNLClassifier inferenceResponseForRequest"
SNLPServerNLClassifier inferenceResponseForRequest
END "SNLPServerNLClassifier inferenceResponseForRequest"
Encountered error in deprecated version of inferenceResponseForRequest: %@ (returning SERVER parser response)
UPContextualizerStrategyCancel: Detected high-probability cancel intent in core result
UPContextualizerStrategyOptions: Detected high-probability selectOrdinal intent in core result
UPContextualizerStrategyOptions: %ld domain candidates matched dialog act prompted entity (%@)
UPContextualizerStrategyOptions: No domain result matched dialog act prompted entity (%@)
UPContextualizerStrategyOptions: Building verbatim string payload
[%s] [model_task_id=%s]
SNLC override triggered: falling back on DEVICE based on the turn input SDA content
SNLC override triggered: falling back on SERVER based on the LegacyNLContext dictationPrompt=true
Rejecting '%s'.
Warning: Context shape not 2-dim
[NLv4IO Context Tensor] shape=%lu,%lu num_elems=%lu
Warning: Context shape not consistent with data
[NLv4IO Context Token] i=%lu j=%lu id=%lu token=%s
PrepareGlobalNerRequest
FetchNerPredictions
Utterance: %{sensitive}@
ConvertToUPPLNerResponse
Predictions:
PLUM Span (before post processing):
GeneratePlumSpans
[%s] Found setNumber voc span(s)
Creating NLv4InferenceOrchestrator instance with getAssetVersionMajor()=%u
Creating NLv4InferenceOrchestrator instance via deprecated constructor with major asset version %u
BEGIN "NLv4 Matched Span Featurization"
NLv4 Matched Span Featurization
END "NLv4 Matched Span Featurization"
BEGIN "NLv4 Context Featurization"
NLv4 Context Featurization
END "NLv4 Context Featurization"
BEGIN "NLv4 Inference"
%s Numericalized span input for NLv4 parser model:
%s Numericalized context input for NLv4 parser model:
%s %s
NLv4 Inference
END "NLv4 Inference"
BEGIN "NLv4 Tree Building"
Tree after all manipulations:
%{sensitive}s
A hypothesis was rejected because it contained only UserAccepted.
Building UDA for hypothesis number %zu
Invalid USO graph, removing parse from output.  This might be due to a grammatical error or an otherwise malformed model tree.
Could not generate a full USO graph for a hypothesis: %s
NLv4 Tree Building
END "NLv4 Tree Building"
[NLv4IO Ply tree] hypothesis=%zu:
[NLv4IO Ply tags] hypothesis=%zu:
[SNLPAssetLogger] %s
Invalid model tree, removing parse from output.
Invalid user dialog act: %s
BEGIN "CalibrationInference"
CalibrationInference
END "CalibrationInference"
[%s] Warning: failed to get namespace for node %{sensitive}s: %{sensitive}s
[%s] Badly formed matching span; start and/or end indices missing from span.
[%s] A data detector span contained a USO graph with an invalid entity node.  This data detector span was ignored by the span matching featurizer.  Error: %s.
[%s] Span encoding failed; number of buckets (%lu) not matching number of tokens (%lu).
%s Exception when calling C plus plus post processor code : %{sensitive}s
%s Exception "%{sensitive}s" catched during graph genereation for span:
 %{sensitive}@
%s Error serializing USO graph : %{sensitive}@
%s USO graph genereatd for span:
 %{sensitive}@
%s Use USOGraph from Date Detector Span for PLUM Span:
 %{sensitive}@
%s Data detector span is nil, skip the code to integrate plum spans with data detector spans.
BEGIN "UPLoadedModelConfigurationInit"
BEGIN "EspressoInitialization"
Exception while initializing model %s
EspressoInitialization
END "EspressoInitialization"
UPLoadedModelConfigurationInit
END "UPLoadedModelConfigurationInit"
[%s] [WARN] MatchingSpan has no USO graph
[%s] [WARN] MatchingSpan has USO graph with no identifiers
[%s] [WARN] probability missing from identifier
[%s] [WARN] probability has no value
[%s] [WARN] Negative relative threshold supplied (%f), span filtering will behave strangely
[%s] Span filtering: %lu out of %lu spans kept
[%s] Span %s [score %f] was kept?: %{BOOL}d
[%s] Span %s [no score] was kept?: %{BOOL}d
Warning: cannot embed OOV token '%s'.
BEGIN "UaaP Preprocessing"
Found matched span using data detectors: %lu -> %lu (%s)
Matched span has structured data: %s
Featurized token with text=%s
Token span labels: %s
UaaP Preprocessing
END "UaaP Preprocessing"
Valid insertable span found; re-inserting it into the model graph.
Could not insert subtree: %s 
 Warning: Could not generate USO graph: %s
Built USO graph:
Failed to cast entity node to entity node; SiriOntology reports a non-entity node as an entity node.
Warning: Integer %s out of range for USO integer nodes.
Warning: Failed to convert string %s to integer.
BEGIN "SNLPNaturalLanguageParser inferenceResponseForRequest"
SNLPNaturalLanguageParser inferenceResponseForRequest
END "SNLPNaturalLanguageParser inferenceResponseForRequest"
Tree after ContactTypeSplit step:
%{sensitive}s
Tree after PersonNameSplitHack step:
%{sensitive}s
Tree after GroupNameTransform step:
%{sensitive}s
Tree after ContactAddressDowncaster step:
%{sensitive}s
Tree after MinimumMaximumLabeller labelling:
%{sensitive}s
Tree after One Shot Reply check:
%{sensitive}s
Tree after SetNumber verb replacement:
%{sensitive}s
[%s] Span input
[%s] Span Input
[%s] Warning: encountered span missing label
[%s] Badly formed matching span; start and/or end indices missing from span. Skipping.
[%s] Mapping span label '%s' to span label '%s'
[%s] Warning: Featurised spans shape not 3-dim
[%s] [Span Tensor] shape=%lu,%lu,%lu num_elems=%lu
[%s] Warning: Span shape not consistent with data
[%s] [Span Token] i=%lu j=%lu k=%lu id=%lu token=%s
[%s] span '%s' covers tokens [%u, %u)
[%s] Spans encoded over the tokens:
[%s] %s: %s
[%s] Rejecting OOV Span: %s
Could not find contextualizer strategy for dialog act: %{sensitive}@
[%s] Since the model itself predicted only %lu common_Person nodes (lower than the threshold of %lu), do not apply the name split hack
[%s] Could not find _any_ partition for this common_Person (including a single-span one). Skipping.
[%s] This common_Person cannot be split into multiple sub-spans. Skipping.
[%s] This common_Person has been partitioned into %lu sub-spans.
[%s] Warning: Failed to generate a node for matching span (input=%{sensitive}s)
[%s] Finding person matching span partitions for range %lu -> %lu
[%s]  - span: %{sensitive}s
[%s] Found %lu possible person partitions:
[%s] Found minimal partition:
[%s]  - component: %{sensitive}s
[%s] Did not find minimal partition
[%s] Generated new common_Person.name node with startCharIndex=%lu, endCharIndex=%lu, value=%{sensitive}s
[%s] Successfully spawned replacement common_Person nodes
Espresso
BeamSearch
CrfNormalizer
PrepareTensor
BuildTensor
ExecutePlan
GetTensor
UPModelIdentifier
NSCopying
UPContextualizerStrategyPrompt
UPContextualizerStrategy
NSObject
UPContextualizerStrategyOffer
UPPLMatchedSpan
UPDataDetectorSpan
UPQueryRunner
UPDialogActPrompt
UPDialogAct
UPParserModel
UPResultStructuredDataNode
UPUsoSerializer
UPCalibration
SNLPServerNLClassifier
UPResultCandidate
UPModelBundle
UPResultRootNode
UPTokenizer
UPResultNode
UPContextualizerStrategyCancel
UPContextualizerStrategyOptions
UPResultIntermediateNode
UPIntentWithSingleEntity
UPDialogActConverter
UPPreprocessorOutput
UPToken
UPContextualizerUtilities
UPPLNerHandler
UPUtilities
UPPLAlternativePrediction
UPSpan
UPCalibrationModel
UPEntityWithValue
UPDialogActOffer
UPPLEmbeddingTensor
UPDetectedData
UPDataDetectors
UPContextualizerInput
UPPLChunkPrediction
UPModelConfiguration
UPPlumSpan
UPPLPostProcessor
UPPLTokenization
UPLoadedModelConfiguration
UPResult
UPQuery
UPResultCandidateEntity
UPDialogActOptions
UPPreprocessor
UPSystemConfiguration
UPPLNerRequest
UPResultLeafNode
UPPLToken
SNLPNaturalLanguageParser
UPEmbedding
UPPLNerResponse
UPContextualizer
init
UUID
allocWithZone:
copyWithZone:
uuid
isEqual:
appBundleId
isEqualToString:
hash
initWithAppBundleId:
.cxx_destruct
_uuid
_appBundleId
T@"NSUUID",R,C,V_uuid
T@"NSString",R,C,V_appBundleId
dialogAct
reference
coreResult
createConfirmOrRejectedDialogActsFor:reference:
domainResult
modelIdentifier
query
initWithDomainResult:coreResult:modelIdentifier:query:dialogAct:
entityName
filterResult:byEntityName:serializer:
candidateCount
intent
resultFromResult:withNewIntent:
entityType
buildPayloadResultFromQuery:modelIdentifier:intent:entityName:serializer:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
superclass
description
debugDescription
TQ,R
T#,R
T@"NSString",R,C
resultUsingContextualizerInput:
initWithPrebuiltIntentThreshold:usoSerializer:
prebuiltIntentThreshold
usoSerializer
_prebuiltIntentThreshold
_usoSerializer
Td,R,N,V_prebuiltIntentThreshold
T@"UPUsoSerializer",R,N,V_usoSerializer
stringWithCString:encoding:
defaultManager
fileExistsAtPath:isDirectory:
inputStreamWithFileAtPath:
open
read:maxLength:
stringWithCapacity:
appendFormat:
UTF8String
initWithLength:
mutableBytes
length
dataWithBytes:length:
bytes
arrayWithObjects:count:
hasTopCandidate:excedingProbability:matchingOneOfIntents:
createResultFromExistingResult:truncatedTo:
initWithPrebuiltIntentThreshold:
label
tokenIndicesIndex
stringWithFormat:
dictionaryWithObjects:forKeys:count:
initWithLabel:tokenIndicesIndex:
dictionaryRepresentation
_label
_tokenIndicesIndex
T{_NSRange=QQ},R,N,V_tokenIndicesIndex
T@"NSString",R,N,V_label
initWithRange:type:category:
printedForm
initWithRange:category:dataDetectorResult:
initWithRange:category:dataDetectorResult:usoGraph:
getUsoGraphPrintedForm
dataDetectorResult
usoGraph
_dataDetectorResult
_usoGraph
T^{__DDResult=},R,V_dataDetectorResult
T@"USOSerializedGraph",R,V_usoGraph
initWithUsoSerializer:
countByEnumeratingWithState:objects:count:
preprocessor
initWithPreprocessor:parserModel:calibrationModel:
addObject:
initWithCoreModel:domainModelBundles:
dictionary
parserModel
identifier
preprocess:error:
predictionFromQuery:preprocessorOutput:error:
errorWithDomain:code:userInfo:
setObject:forKey:
calibrationModel
scoreFromQuery:preprocessorOutput:error:
calibrateParserResults:withCalibrationScores:error:
dialogActFromQuery:
allValues
setWithArray:
singleTurnPredictionFromDomainResults:
multiTurnPredictionFromQuery:modelIdentifierToDomainResults:dialogAct:error:
convertFromDialogAct:error:
localizedDescription
queryUUID
valueForKey:
count
anyObject
array
candidateAtRank:
probability
initWithKey:ascending:
sortedArrayUsingDescriptors:
initWithCandidates:queryUUID:
combinedResultFromResults:
predictionFromQuery:error:
objectForKeyedSubscript:
resultWithContextualizerInput:
initWithCoreModel:domainModels:
domainModels
coreModel
domainModelBundles
_calibration
_dialogActConverter
_contextualizer
_coreModel
_domainModelBundles
__calibration
__dialogActConverter
__contextualizer
T@"UPCalibration",R,N,V__calibration
T@"UPDialogActConverter",R,N,V__dialogActConverter
T@"UPContextualizer",R,N,V__contextualizer
T@"UPParserModel",R,N,V_coreModel
T@"NSSet",R,N,V_domainModelBundles
copy
initWithIntent:entityType:entityName:reference:
_intent
_entityType
_entityName
_reference
T@"NSString",R,C,V_entityType
T@"NSString",R,C,V_entityName
T@"USOSerializedGraph",R,V_reference
T@"NSString",R,C,V_intent
initWithCapacity:
initWithType:andValue:andChildren:
initWithSystemConfiguration:loadedModelConfiguration:
initWithModelConfiguration:
modelWithSystemConfiguration:loadedModelConfiguration:error:
bundleId
stdU16ToNSString:
labelToValueType
numberWithUnsignedLong:
rangeFromStart:end:
initWithRange:label:text:groupId:semanticValue:structuredData:
serializeFromIntent:andEntities:forBundleId:
initWithTask:
initWithUncalibratedProbability:calibratedProbability:utterance:intent:entities:modelIdentifier:task:
parserEspressoModule
utterance
nSStringToU16String:
beamMaskInput
arrayWithCapacity:
_candidateForBeamSequence:utterance:outputTokens:resolver:dataDetectorSpans:
annotatedString
intentVocabPath
bioLabelsVocabPath
_candidateForUtterance:probability:labelledSpans:dataDetectorSpans:intent:
spanLabelsTensor
embeddingsTensor
forwardWithSpanLabels:embeddings:utterance:
outputTokens
dataDetectorSpans
resolver
_resultFromInferenceResult:query:outputTokens:dataDetectorSpans:resolver:
locale
isPLUMEnabled
modelWithSystemConfiguration:modelConfiguration:error:
setIsPLUMEnabled:
_systemConfiguration
_loadedModelConfiguration
_isPLUMEnabled
_identifier
__usoSerializer
__systemConfiguration
__loadedModelConfiguration
T@"UPUsoSerializer",R,V__usoSerializer
T@"UPSystemConfiguration",R,N,V__systemConfiguration
T@"UPLoadedModelConfiguration",R,N,V__loadedModelConfiguration
T@"UPModelIdentifier",R,N,V_identifier
T@"NSLocale",R,C,N
TB,N,V_isPLUMEnabled
T@"UPPreprocessor",R
type
value
initWithObjectsAndKeys:
children
initWithArray:copyItems:
objectAtIndexedSubscript:
_dictionaryRepresentation
replaceObjectAtIndex:withObject:
_type
_value
_children
T@"NSString",R,C,V_type
T@"NSString",R,C,V_value
T@"NSArray",R,C,V_children
_convertBundleIdToEntity:
isHigherLevelEntity
_insertSimpleEntity:intoGraph:underTaskNode:
_insertHigherLevelEntities:intoGraph:underTaskNode:
initWithUsoGraph:withError:
defaultCStringEncoding
_leafNodeFromLabel:andGraphStringNode:
_leafNodeFromLabel:andGraphSemanticValueNode:
_leafNodeFromGraphEdge:andGraphNode:
initWithLabel:andLeafNodes:
toCppUsoGraph:withError:
_intermediateNodeRepresentations:
initWithLabel:intermediateNodes:directLeafNodes:
range
text
semanticValue
_addPathForLabel:range:text:semanticValue:toGraphNode:forGraph:
_groupHigherLevelEntities:
objectForKey:
higherLevelChildLabel
higherLevelParentLabel
groupId
numberWithLong:
stringByReplacingOccurrencesOfString:withString:
initWithLabel:andText:andSemanticValue:andStructuredData:
deserializeFromSerializedGraph:
.cxx_construct
_usoVocabManager
doubleValue
calibrateResult:withCalibrationScore:
calibrateCandidate:withCalibrationScore:
uncalibratedProbability
numberWithDouble:
entities
task
mainBundle
localizedStringForKey:value:table:
path
_classifierWithPathURL:shouldExpectVersionInfo:error:
stringWithUTF8String:
URLByAppendingPathComponent:
_classifierWithModelURL:configURL:spanVocabularyURL:contextVocabularyURL:versionURL:error:
_hasVersionInfo
absoluteString
stringByDeletingLastPathComponent
URLWithString:
isReadableFileAtPath:
_errorForMissingResourceURL:
_initWithModelURL:configURL:spanVocabularyURL:contextVocabularyURL:versionURL:error:
_convertRequest:
requestId
highInt
lowInt
_responseForSNLCResponse:
inferenceResponseForRequest:error:
setClassificationLabel:
setClassificationProbability:
data
initWithData:
classifierWithPathURL:error:
classifierWithModelURL:configURL:spanVocabularyURL:contextVocabularyURL:error:
inferenceResponseForRequest:
_snlcOrchestrator
_assetLogger
numberWithUnsignedInteger:
annotatedEntityFragmentString
appendString:
characterAtIndex:
stringWithCharacters:length:
_buildCandidateEntitiesByStartIndex:
structuredData
rootNodeRepresentationForIntent:andEntities:
calibratedProbability
rootNodeRepresentation
_candidateEntitiesByStartIndex
_modelIdentifier
_task
_uncalibratedProbability
_calibratedProbability
_entities
__candidateEntitiesByStartIndex
_utterance
T@"NSDictionary",R,V__candidateEntitiesByStartIndex
T@"NSString",R,V_utterance
T@"NSString",R,V_intent
T@"UPResultRootNode",R
T@"UPUsoSerializer",R,V_usoSerializer
T@"UPModelIdentifier",R,N,V_modelIdentifier
T@"NSObject<SIRINLUUserDialogAct>",R,C,V_task
Td,R,V_uncalibratedProbability
T@"NSNumber",R,V_calibratedProbability
Td,R
T@"NSArray",R,V_entities
initWithLoadedModelConfiguration:parserModel:calibrationModel:
_parserModel
_calibrationModel
_preprocessor
T@"UPPreprocessor",R,N,V_preprocessor
T@"UPParserModel",R,N,V_parserModel
T@"UPCalibrationModel",R,N,V_calibrationModel
initWithLabel:
directLeafNodes
null
intermediateNodes
_intermediateNodes
_directLeafNodes
T@"NSArray",R,C,V_intermediateNodes
T@"NSArray",R,C,V_directLeafNodes
localeIdentifier
raise:format:
whitespaceAndNewlineCharacterSet
stringByTrimmingCharactersInSet:
initWithString:range:isWhitespace:
isWhitespace
predicateWithBlock:
filteredArrayUsingPredicate:
nonWhitespaceTokensForTokens:
initWithLocale:
tokenizeUtterance:
_locale
T@"NSLocale",R,C,V_locale
T@"NSString",R,C,V_label
leafNodes
_leafNodes
T@"NSArray",R,C,V_leafNodes
entity
isEqualToEntityWithValue:
initWithIntent:singleEntity:
isEqualToIntentWithSingleEntity:
_entity
T@"UPEntityWithValue",R,V_entity
_convertFromOfferedDialogAct:error:
_convertFromGaveOptionsDialogAct:error:
_convertFromPromptedDialogAct:error:
offeredAct
_parseUserDialogAct:error:
initWithIntent:entityWithValue:
choices
objectAtIndex:
entityValue
initWithIntent:entityType:entityName:entityValues:
_parseUserDialogActGraph:error:
higherLevelEntityLabelFromParentLabel:childLabel:
initWithType:entityName:entityValue:
T@"UPUsoSerializer",R,C,V_usoSerializer
initWithEmbeddingsTensor:spanLabelsTensor:outputTokens:dataDetectorSpans:
_embeddingsTensor
_spanLabelsTensor
_outputTokens
_dataDetectorSpans
T^v,R
string
isEqualToToken:
initWithString:
_isWhitespace
_string
_range
T@"NSString",R,C,V_string
T{_NSRange=QQ},R,V_range
TB,R,V_isWhitespace
containsObject:
entityLabelsFromCandidate:
filterResult:serializer:predicate:
setReference:
instancesRespondToSelector:
loadConfigs:
integerValue
boolValue
tokenizedUtterance
originalUtterance
tokens
token
charIndicesRange
graphemeClusters
normalizedUtterance
embeddings
numTokens
embeddingDim
values
floatValue
numLayers
embedderId
numberWithFloat:
initWithCoarseEntityType:fineGrainedEntityType:charIndicesRange:tokenIndicesIndex:chunkScore:
initWithChunkPredictions:nerScore:alternativeIndex:
initWithAlternativePredictions:
predictNamedEntitiesForRequest:
alternativePredictions
chunkPredictions
substringWithRange:
fineGrainedEntityType
generateTypeWithPlumPrefix:
chunkScore
initWithRange:originalMention:category:score:usoSerializedGraph:
initWithLocale:modelDir:vocabTagsFile:transParamsFile:charIndicesFile:configFile:
initWithLocale:modelDir:vocabTagsFile:transParamsFile:charIndicesFile:configFile:padCharacter:unkCharacter:
generatePlumSpansForRequest:
maxTokens
maxTokenLength
beamSize
wordCharactersTensorEnabled
wordLengthTensorEnabled
_handler
_postProcessor
_wordCharactersTensorEnabled
_wordLengthTensorEnabled
_maxTokens
_maxTokenLength
_beamSize
TQ,R,N,V_maxTokens
TQ,R,N,V_maxTokenLength
TQ,R,N,V_beamSize
TB,R,N,V_wordCharactersTensorEnabled
TB,R,N,V_wordLengthTensorEnabled
fileExistsAtPath:
lengthOfBytesUsingEncoding:
getBytes:maxLength:usedLength:encoding:options:range:remainingRange:
intermediateNodeRepresentations:
checkFileExistence:error:
nerScore
alternativeIndex
_chunkPredictions
_nerScore
_alternativeIndex
T@"NSArray",R,N,V_chunkPredictions
T@"NSNumber",R,N,V_nerScore
TQ,R,N,V_alternativeIndex
category
_category
TQ,R,V_type
T@"NSString",R,C,V_category
calibrationEspressoModule
_entityValue
T@"NSString",R,C,V_entityValue
initWithIntent:
entityWithValue
_entityWithValue
T@"UPEntityWithValue",R,V_entityWithValue
initWithValues:withNumTokens:withNumLayers:withEmbeddingDim:withEmbedderId:
_values
_numTokens
_numLayers
_embeddingDim
_embedderId
T@"NSArray",R,N,V_values
TQ,R,N,V_numTokens
TQ,R,N,V_numLayers
TQ,R,N,V_embeddingDim
T@"NSString",R,N,V_embedderId
dealloc
initWithLabel:dataDetectorResult:
Tr^{__CFArray=},R,V_dataDetectorResult
localeWithLocaleIdentifier:
initLoadFromDataDetectorsDirectoryPath:forLocale:
dataDetectorsDirectoryPath
languageCode
dataDetector
_matchSpansForDetectedDataArray:label:
addObjectsFromArray:
initLoadFromDataDetectorsDirectoryPath:
initWithSystemConfiguration:forLocale:
matchSpans:
matchSpansForUtterance:
matchSpansForDetectedData:
ddUsoMapper
_dataDetector
_ddUsoMapper
T^{UPDataDetector=q^{__DDScanner}^{__DDScanner}^{__DDScanner}^{__DDScanner}^{__DDScanner}^{__DDScanner}},R,V_dataDetector
T^v,R,V_ddUsoMapper
_domainResult
_coreResult
_query
_dialogAct
T@"UPResult",R,N,V_domainResult
T@"UPResult",R,N,V_coreResult
T@"UPQuery",R,N,V_query
T@"<UPDialogAct>",R,N,V_dialogAct
coarseEntityType
_coarseEntityType
_fineGrainedEntityType
_chunkScore
_charIndicesRange
T@"NSString",R,N,V_coarseEntityType
T@"NSString",R,N,V_fineGrainedEntityType
T{_NSRange=QQ},R,N,V_charIndicesRange
T@"NSNumber",R,N,V_chunkScore
_initWithBioLabelsVocabPath:configPath:grammarPath:intentVocabPath:spanVocabPath:parserEspressoModelPath:calibrationEspressoModelPath:
stringByAppendingPathComponent:
_configurationWithBioLabelsVocabPath:configPath:grammarPath:intentVocabPath:spanVocabPath:parserEspressoModelPath:calibrationEspressoModelPath:error:
configurationFromDirectoryUrl:error:
configPath
grammarPath
spanVocabPath
parserEspressoModelPath
calibrationEspressoModelPath
espressoModelPath
_bioLabelsVocabPath
_configPath
_grammarPath
_intentVocabPath
_spanVocabPath
_parserEspressoModelPath
_calibrationEspressoModelPath
_espressoModelPath
T@"NSString",R,C,V_bioLabelsVocabPath
T@"NSString",R,C,V_configPath
T@"NSString",R,C,V_grammarPath
T@"NSString",R,C,V_intentVocabPath
T@"NSString",R,C,V_spanVocabPath
T@"NSString",R,C,V_parserEspressoModelPath
T@"NSString",R,C,V_calibrationEspressoModelPath
T@"NSString",R,C,V_espressoModelPath
componentsSeparatedByString:
exceptionWithName:reason:userInfo:
getTypeWithtoutPlumPrefix
usoSerializedGraph
setUsoSerializedGraph:
originalMention
score
_usoSerializedGraph
_originalMention
_score
T@"USOSerializedGraph",&,V_usoSerializedGraph
T@"NSString",R,V_originalMention
T@"NSNumber",R,C,V_score
valueWithRange:
process:dataDetectorSpans:
initWithTokens:originalUtterance:normalizedUtterance:
_originalUtterance
_normalizedUtterance
_tokens
T@"NSString",R,N,V_originalUtterance
T@"NSString",R,N,V_normalizedUtterance
T@"NSArray",R,N,V_tokens
dictionaryWithContentsOfFile:
initWithLocale:tokenizer:isPLUMEnabled:featurizer:
hasCalibrationModel
_bundleId
_labelToValueType
_resolver
_beamMaskInput
_parserEspressoModule
_calibrationEspressoModule
T@"NSLocale",R,N,V_locale
TB,R,V_isPLUMEnabled
T@"NSString",R,N,V_bioLabelsVocabPath
T@"NSString",R,N,V_intentVocabPath
T^v,R,N,V_labelToValueType
T^v,R,N,V_resolver
T^v,R,N,V_beamMaskInput
T^{EspressoModule=^v^v{?=^vi}},R,N,V_parserEspressoModule
T^{EspressoModule=^v^v{?=^vi}},R,N,V_calibrationEspressoModule
TB,R
T@"NSString",R,N,V_bundleId
_candidates
subarrayWithRange:
rootNode
_queryUUID
__candidates
T@"NSArray",R,C,N,V__candidates
T@"NSUUID",R,C,V_queryUUID
T@"UPResultRootNode",R,C
initWithTokens:embeddingsByToken:spans:dialogAct:
enumerateSpansWithType:block:
setTokens:
embeddingsByToken
setEmbeddingsByToken:
spans
__utterance
_embeddingsByToken
_spans
T@"NSArray",C,V_tokens
T@"NSDictionary",C,V_embeddingsByToken
T@"NSArray",R,C,V_spans
T@"<SIRINLUSystemDialogAct><NSObject>",R,V_dialogAct
containsString:
rangeOfString:
substringToIndex:
substringFromIndex:
longValue
_indexedLabelRepresentation
leafNodeRepresentation
_text
_groupId
_semanticValue
_structuredData
T@"NSString",R,V_label
T@"NSString",R,V_text
T@"NSNumber",R,V_groupId
T@"NSString",R,V_semanticValue
T@"UPResultStructuredDataNode",R,V_structuredData
T@"UPResultLeafNode",R
T@"NSString",R
entityValues
_entityValues
T@"NSArray",R,C,V_entityValues
getDimension
getCoordinates
tokenizer
__featurizer
_tokenizer
T@"UPTokenizer",R,N,V_tokenizer
_initWithDataDetectorsDirectoryPath:
_configurationWithDataDetectorsDirectoryPath:error:
_dataDetectorsDirectoryPath
T@"NSString",R,C,V_dataDetectorsDirectoryPath
matchedSpans
initWithTokenizedUtterance:embeddings:matchedSpans:
_tokenizedUtterance
_embeddings
_matchedSpans
T@"UPPLTokenization",R,N,V_tokenizedUtterance
T@"UPPLEmbeddingTensor",R,N,V_embeddings
T@"NSArray",R,N,V_matchedSpans
T@"NSString",R,C,V_text
T@"NSString",R,C,V_semanticValue
T@"UPResultStructuredDataNode",R,C,V_structuredData
tokenId
isSpecialToken
numberWithBool:
isWordPiece
isOverflow
encodedLabels
initWithToken:tokenId:charIndicesRange:graphemeClusters:
initWithToken:tokenId:charIndicesRange:graphemeClusters:isSpecialToken:isWordPiece:isOverflow:encodedLabels:
_isSpecialToken
_isWordPiece
_isOverflow
_token
_tokenId
_graphemeClusters
_encodedLabels
T@"NSString",R,N,V_token
TQ,R,N,V_tokenId
T@"NSArray",R,N,V_graphemeClusters
TB,R,N,V_isSpecialToken
TB,R,N,V_isWordPiece
TB,R,N,V_isOverflow
T@"NSArray",R,N,V_encodedLabels
fileSystemRepresentation
_initWithCppOrchestrator:
convertNLv4ParserRequestToCpp:
convertNLv4ParserResponseFromCppToObjC:
parserFromAssetDirectory:error:
parserFromSpansVocab:targetVocab:contextVocab:parserEncoder:parserDecoder:config:error:
_cppOrchestrator
arrayWithArray:
initWithCoordinates:
_embedding
_alternativePredictions
T@"NSArray",R,N,V_alternativePredictions
_contextualizeByDialogActTypeUsingContextualizerInput:
cancelContextualizerStrategy
offerContextualizerStrategy
optionsContextualizerStrategy
promptContextualizerStrategy
_cancelContextualizerStrategy
_offerContextualizerStrategy
_optionsContextualizerStrategy
_promptContextualizerStrategy
T@"UPContextualizerStrategyCancel",R,N,V_cancelContextualizerStrategy
T@"UPContextualizerStrategyOffer",R,N,V_offerContextualizerStrategy
T@"UPContextualizerStrategyOptions",R,N,V_optionsContextualizerStrategy
T@"UPContextualizerStrategyPrompt",R,N,V_promptContextualizerStrategy
@24@0:8^{_NSZone=}16
@24@0:8@16
B24@0:8@16
Q16@0:8
@16@0:8
v16@0:8
@"NSUUID"
@"NSString"
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B16@0:8
B24@0:8#16
B24@0:8:16
Vv16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
@"UPResult"24@0:8@"UPContextualizerInput"16
@32@0:8d16@24
d16@0:8
@"UPUsoSerializer"
@24@0:8d16
@40@0:8@16{_NSRange=QQ}24
{_NSRange=QQ}16@0:8
{_NSRange="location"Q"length"Q}
@48@0:8{_NSRange=QQ}16@32^{__DDResult=}40
@56@0:8{_NSRange=QQ}16@32^{__DDResult=}40@48
^{__DDResult=}16@0:8
^{__DDResult=}
@"USOSerializedGraph"
@32@0:8@16@24
@32@0:8@16^@24
@48@0:8@16@24@32^@40
@"UPParserModel"
@"NSSet"
@"UPCalibration"
@"UPDialogActConverter"
@"UPContextualizer"
@48@0:8@16@24@32@40
@40@0:8@16@24^@32
@52@0:8r^v16f24r^v28r^v36@44
{UPInferenceResult={UPGenericTensor={vector<unsigned long, std::allocator<unsigned long>>=^Q^Q{__compressed_pair<unsigned long *, std::allocator<unsigned long>>=^Q}}{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}}{UPGenericTensor={vector<unsigned long, std::allocator<unsigned long>>=^Q^Q{__compressed_pair<unsigned long *, std::allocator<unsigned long>>=^Q}}{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}}{UPGenericTensor={vector<unsigned long, std::allocator<unsigned long>>=^Q^Q{__compressed_pair<unsigned long *, std::allocator<unsigned long>>=^Q}}{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}}}120@0:8{UPGenericTensor={vector<unsigned long, std::allocator<unsigned long>>=^Q^Q{__compressed_pair<unsigned long *, std::allocator<unsigned long>>=^Q}}{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}}16{UPGenericTensor={vector<unsigned long, std::allocator<unsigned long>>=^Q^Q{__compressed_pair<unsigned long *, std::allocator<unsigned long>>=^Q}}{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}}64@112
@56@0:8r^v16@24r^v32r^v40^v48
@56@0:8r^v16r^v24r^v32^v40r^v48
v20@0:8B16
@"UPModelIdentifier"
@"UPSystemConfiguration"
@"UPLoadedModelConfiguration"
@40@0:8@16@24@32
@"NSArray"
@32@0:8r^v16r^{UsoGraphNode=^^?^{UsoGraph}Q}24
@40@0:8{vector<std::pair<std::reference_wrapper<siri::ontology::UsoGraphNode>, std::reference_wrapper<const siri::ontology::UsoGraphEdge>>, std::allocator<std::pair<std::reference_wrapper<siri::ontology::UsoGraphNode>, std::reference_wrapper<const siri::ontology::UsoGraphEdge>>>>=^v^v{__compressed_pair<std::pair<std::reference_wrapper<siri::ontology::UsoGraphNode>, std::reference_wrapper<const siri::ontology::UsoGraphEdge>> *, std::allocator<std::pair<std::reference_wrapper<siri::ontology::UsoGraphNode>, std::reference_wrapper<const siri::ontology::UsoGraphEdge>>>>=^v}}16
@32@0:8@16r^v24
v40@0:8@16^v24^{UsoGraphNode=^^?^{UsoGraph}Q}32
v72@0:8@16{_NSRange=QQ}24@40@48^{UsoGraphNode=^^?^{UsoGraph}Q}56^v64
{shared_ptr<siri::ontology::UsoVocabManager>="__ptr_"^{UsoVocabManager}"__cntrl_"^{__shared_weak_count}}
@32@0:8@16d24
@36@0:8@16B24^@28
@56@0:8@16@24@32@40^@48
@64@0:8@16@24@32@40@48^@56
{unique_ptr<const sirinluinternalsnlc::SNLCParserRequest, std::default_delete<const sirinluinternalsnlc::SNLCParserRequest>>={__compressed_pair<const sirinluinternalsnlc::SNLCParserRequest *, std::default_delete<const sirinluinternalsnlc::SNLCParserRequest>>=^{SNLCParserRequest}}}24@0:8@16
@40@0:8{SNLCParserResponse=^^?if{?=b1b1}}16
{unique_ptr<snlc_inference_orchestrator::orchestration::SNLCOrchestrator, std::default_delete<snlc_inference_orchestrator::orchestration::SNLCOrchestrator>>="__ptr_"{__compressed_pair<snlc_inference_orchestrator::orchestration::SNLCOrchestrator *, std::default_delete<snlc_inference_orchestrator::orchestration::SNLCOrchestrator>>="__value_"^{SNLCOrchestrator}}}
{unique_ptr<snlp::common::asset_logger::SNLPAssetLogger, std::default_delete<snlp::common::asset_logger::SNLPAssetLogger>>="__ptr_"{__compressed_pair<snlp::common::asset_logger::SNLPAssetLogger *, std::default_delete<snlp::common::asset_logger::SNLPAssetLogger>>="__value_"^{SNLPAssetLogger}}}
@72@0:8d16@24@32@40@48@56@64
@"NSObject<SIRINLUUserDialogAct>"
@"NSNumber"
@"NSDictionary"
@"UPCalibrationModel"
@"UPPreprocessor"
@"NSLocale"
@"UPEntityWithValue"
@160@0:8{UPGenericTensor={vector<unsigned long, std::allocator<unsigned long>>=^Q^Q{__compressed_pair<unsigned long *, std::allocator<unsigned long>>=^Q}}{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}}16{UPGenericTensor={vector<unsigned long, std::allocator<unsigned long>>=^Q^Q{__compressed_pair<unsigned long *, std::allocator<unsigned long>>=^Q}}{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}}64{vector<nl_featurization::Token, std::allocator<nl_featurization::Token>>=^{Token}^{Token}{__compressed_pair<nl_featurization::Token *, std::allocator<nl_featurization::Token>>=^{Token}}}112{vector<uaap::UPDetectedSpan, std::allocator<uaap::UPDetectedSpan>>=^{UPDetectedSpan}^{UPDetectedSpan}{__compressed_pair<uaap::UPDetectedSpan *, std::allocator<uaap::UPDetectedSpan>>=^{UPDetectedSpan}}}136
^v16@0:8
{UPGenericTensor="shape"{vector<unsigned long, std::allocator<unsigned long>>="__begin_"^Q"__end_"^Q"__end_cap_"{__compressed_pair<unsigned long *, std::allocator<unsigned long>>="__value_"^Q}}"data"{vector<float, std::allocator<float>>="__begin_"^f"__end_"^f"__end_cap_"{__compressed_pair<float *, std::allocator<float>>="__value_"^f}}}
{vector<nl_featurization::Token, std::allocator<nl_featurization::Token>>="__begin_"^{Token}"__end_"^{Token}"__end_cap_"{__compressed_pair<nl_featurization::Token *, std::allocator<nl_featurization::Token>>="__value_"^{Token}}}
{vector<uaap::UPDetectedSpan, std::allocator<uaap::UPDetectedSpan>>="__begin_"^{UPDetectedSpan}"__end_"^{UPDetectedSpan}"__end_cap_"{__compressed_pair<uaap::UPDetectedSpan *, std::allocator<uaap::UPDetectedSpan>>="__value_"^{UPDetectedSpan}}}
@44@0:8@16{_NSRange=QQ}24B40
B40@0:8@16d24@32
@56@0:8@16@24@32@40@48
@40@0:8@16@24@?32
@64@0:8@16@24@32@40@48@56
@80@0:8@16@24@32@40@48@56@64@72
v24@0:8@16
{unique_ptr<global_ner::GlobalNerHandler, std::default_delete<global_ner::GlobalNerHandler>>="__ptr_"{__compressed_pair<global_ner::GlobalNerHandler *, std::default_delete<global_ner::GlobalNerHandler>>="__value_"^{GlobalNerHandler}}}
@"UPPLPostProcessor"
B32@0:8@16^@24
{_NSRange=QQ}32@0:8Q16Q24
{basic_string<char16_t, std::char_traits<char16_t>, std::allocator<char16_t>>={__compressed_pair<std::basic_string<char16_t>::__rep, std::allocator<char16_t>>={__rep=(?={__long=^SQQ}{__short=[11S]{?=[1C]C}}{__raw=[3Q]})}}}24@0:8@16
@24@0:8r^v16
@40@0:8@16@24Q32
@48@0:8{_NSRange=QQ}16Q32@40
d120@0:8{UPGenericTensor={vector<unsigned long, std::allocator<unsigned long>>=^Q^Q{__compressed_pair<unsigned long *, std::allocator<unsigned long>>=^Q}}{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}}16{UPGenericTensor={vector<unsigned long, std::allocator<unsigned long>>=^Q^Q{__compressed_pair<unsigned long *, std::allocator<unsigned long>>=^Q}}{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}}64@112
@56@0:8@16Q24Q32Q40@48
@32@0:8@16r^{__CFArray=}24
r^{__CFArray=}16@0:8
r^{__CFArray=}
@32@0:8^{__CFArray=}16@24
^{UPDataDetector=q^{__DDScanner}^{__DDScanner}^{__DDScanner}^{__DDScanner}^{__DDScanner}^{__DDScanner}}16@0:8
^{UPDataDetector=q^{__DDScanner}^{__DDScanner}^{__DDScanner}^{__DDScanner}^{__DDScanner}^{__DDScanner}}
@"UPResult"
@"UPQuery"
@"<UPDialogAct>"
@72@0:8@16@24{_NSRange=QQ}32{_NSRange=QQ}48@64
@80@0:8@16@24@32@40@48@56@64^@72
@72@0:8@16@24@32@40@48@56@64
@64@0:8{_NSRange=QQ}16@32@40@48@56
v32@0:8@16@24
^{EspressoModule=^v^v{?=^vi}}16@0:8
^{EspressoModule=^v^v{?=^vi}}
@32@0:8@16Q24
@24@0:8q16
q16@0:8
v32@0:8Q16@?24
@"<SIRINLUSystemDialogAct><NSObject>"
@72@0:8{_NSRange=QQ}16@32@40@48@56@64
@"UPResultStructuredDataNode"
@44@0:8@16@24B32r^{AbstractFeaturizer=^^?}36
r^{AbstractFeaturizer=^^?}
@"UPTokenizer"
@"UPPLTokenization"
@"UPPLEmbeddingTensor"
@56@0:8@16Q24{_NSRange=QQ}32@48
@76@0:8@16Q24{_NSRange=QQ}32@48B56B60B64@68
@72@0:8@16@24@32@40@48@56^@64
@24@0:8{unique_ptr<nlv4_inference_orchestrator::orchestration::NLv4InferenceOrchestrator, std::default_delete<nlv4_inference_orchestrator::orchestration::NLv4InferenceOrchestrator>>={__compressed_pair<nlv4_inference_orchestrator::orchestration::NLv4InferenceOrchestrator *, std::default_delete<nlv4_inference_orchestrator::orchestration::NLv4InferenceOrchestrator>>=^{NLv4InferenceOrchestrator}}}16
{unique_ptr<nlv4_inference_orchestrator::orchestration::NLv4InferenceOrchestrator, std::default_delete<nlv4_inference_orchestrator::orchestration::NLv4InferenceOrchestrator>>="__ptr_"{__compressed_pair<nlv4_inference_orchestrator::orchestration::NLv4InferenceOrchestrator *, std::default_delete<nlv4_inference_orchestrator::orchestration::NLv4InferenceOrchestrator>>="__value_"^{NLv4InferenceOrchestrator}}}
@"UPContextualizerStrategyCancel"
@"UPContextualizerStrategyOffer"
@"UPContextualizerStrategyOptions"
@"UPContextualizerStrategyPrompt"
