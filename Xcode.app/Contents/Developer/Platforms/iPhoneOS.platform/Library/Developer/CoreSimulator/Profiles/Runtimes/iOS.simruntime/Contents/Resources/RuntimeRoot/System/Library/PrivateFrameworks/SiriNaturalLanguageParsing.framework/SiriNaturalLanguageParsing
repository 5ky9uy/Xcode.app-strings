@(#)PROGRAM:SiriNaturalLanguageParsing  PROJECT:SiriNaturalLanguageParsing-1
NSt3__111__end_stateIcEE
NSt3__120__shared_ptr_pointerIPNS_13__empty_stateIcEENS_10shared_ptrIS2_E27__shared_ptr_default_deleteIS2_S2_EENS_9allocatorIS2_EEEE
NSt3__116__owns_one_stateIcEE
NSt3__115__has_one_stateIcEE
NSt3__118__match_char_icaseIcNS_12regex_traitsIcEEEE
NSt3__112__match_charIcEE
NSt3__116__back_ref_icaseIcNS_12regex_traitsIcEEEE
NSt3__110__back_refIcEE
NSt3__120__bracket_expressionIcNS_12regex_traitsIcEEEE
NSt3__117__owns_two_statesIcEE
NSt3__111__alternateIcEE
NSt3__111__match_anyIcEE
<N4siri8ontology12UsoGraphNodeE
N4uaap19DateDurationHandlerE
N4uaap23AbstractDateTimeHandlerE
N4snlp6common14text_uso_graph26UsoGraphTextTreeParseErrorE
N4snlp6common14text_uso_graph21UDATextTreeParseErrorE
N4uaap8UPDDSpanE
N4uaap12UPDDTimeSpanE
N4uaap20UPDDDateTimeBaseSpanE
N4uaap11TimeHandlerE
N4snlp6common9exception18SNLPAssetExceptionE
false
N8nlohmann6detail12out_of_rangeE
NSt3__117bad_function_callE
N8nlohmann6detail16invalid_iteratorE
N8nlohmann6detail10type_errorE
N8nlohmann6detail11parse_errorE
N4uaap12UPDDDateSpanE
N4uaap15DateSpanHandlerE
N4uaap11DateHandlerE
N27itfm_inference_orchestrator13orchestration16ITFMOrchestratorE
false
NSt3__120__shared_ptr_emplaceIN27itfm_inference_orchestrator10vocabulary10VocabularyENS_9allocatorIS3_EEEE
N27snlc_inference_orchestrator13orchestration16SNLCOrchestratorE
NSt3__120__shared_ptr_emplaceINS_4__fs10filesystem16filesystem_error8_StorageENS_9allocatorIS4_EEEE
vH7B
W4vC
9Y>)F$
raB3G
)c=H
]rHa
O8Mr
bnMG
.wN9
[*QmU
mr"iR
R$N(
>S}W
-sSO\
T%L9
hGT.
B}T}
=@[V
!a9X
X5AHx
%4xY
Z~$|7
+\0I
2a\|
\ysK
|M$D
pH_r
(:W"
s\ax}?
pc2g
@BXV
tC7Ddx
EydV
d66
eax~Z
ekhHD
@iZb
k0V(
k*do^
:V!2m
RJqn
bzo=
$qE}
XqkY
quAt
Jugm
~B v
STv/N
_w&2
xg^Jp5|
yMzw
{zel#|67
P/};
[@JO
nQ:B
N4snlp6common14text_uso_graph20ExactMatchComparatorE
N4snlp6common14text_uso_graph18UsoGraphComparatorE
N4snlp6common14text_uso_graph16ActionListParserE
N4snlp6common14text_uso_graph14TextTreeParserE
N4uaap25UPDDTimeSpanWithReferenceE
N4uaap28TimeSpanWithReferenceHandlerE
N4siri8ontology17OntologyExceptionE
N4siri8ontology21OntologyBaseExceptionE
N4snlp6common14text_uso_graph22UsoGraphTextTreeParserE
N4siri8ontology17IsNameTypeVisitorINS0_16OntologyNodeNameEEE
N4siri8ontology16NoOpONameVisitorE
N4siri8ontology19OntologyNameVisitorE
N4siri8ontology17IsNameTypeVisitorINS0_16OntologyVerbNameEEE
N4siri8ontology17IsNameTypeVisitorINS0_16OntologyEdgeNameEEE
primitive_StringN4uaap20UPDDTimeDurationSpanE
N4uaap19TimeDurationHandlerE
N4uaap16UPDDDateTimeSpanE
N4uaap15DateTimeHandlerE
N4uaap25UPDDSpecialDatePeriodSpanE
N4uaap20UPDDAbsoluteDateSpanE
N4uaap18UPDDDateOffsetSpanE
N4snlp6common9exception13SNLPExceptionE
N8nlohmann6detail9exceptionE
false
N4siri8ontology16OntologyUnitNameE
N5boost6detail17sp_counted_impl_pINS_6random23mersenne_twister_engineIjLm32ELm624ELm397ELm31ELj2567483615ELm11ELj4294967295ELm7ELj2636928640ELm15ELj4022730752ELm18ELj1812433253EEEEE
N5boost6detail15sp_counted_baseE
N5boost16exception_detail10clone_implINS0_19error_info_injectorISt13runtime_errorEEEE
N5boost16exception_detail19error_info_injectorISt13runtime_errorEE
N5boost9exceptionE
N5boost16exception_detail10clone_baseE
N5boost16exception_detail10clone_implINS0_19error_info_injectorISt16invalid_argumentEEEE
N5boost16exception_detail19error_info_injectorISt16invalid_argumentEE
NSt3__16__nodeIcEE
NSt3__110shared_ptrINS_13__empty_stateIcEEE27__shared_ptr_default_deleteIS2_S2_EE
NSt3__113__empty_stateIcEE
NSt3__120__l_anchor_multilineIcEE
NSt3__120__r_anchor_multilineIcEE
NSt3__115__word_boundaryIcNS_12regex_traitsIcEEEE
NSt3__111__lookaheadIcNS_12regex_traitsIcEEEE
NSt3__123__match_any_but_newlineIcEE
NSt3__120__match_char_collateIcNS_12regex_traitsIcEEEE
NSt3__118__back_ref_collateIcNS_12regex_traitsIcEEEE
NSt3__128__begin_marked_subexpressionIcEE
NSt3__126__end_marked_subexpressionIcEE
NSt3__16__loopIcEE
NSt3__117__repeat_one_loopIcEE
NSt3__121__empty_non_own_stateIcEE
N27nlv4_inference_orchestrator13span_matching36RelativeThresholdMatchingSpansFilterE
N27nlv4_inference_orchestrator13span_matching19MatchingSpansFilterE
N4uaap15TimeSpanHandlerE
N27nlv4_inference_orchestrator16inference_engine21BertModelLoadingErrorE
false
?N4snlp6common14text_uso_graph19SpacedTextTreeLexerE
N4snlp6common14text_uso_graph13TextTreeLexerE
N4snlp6common14text_uso_graph17UDATextTreeParserE
N13sentencepiece3bpe5ModelE
N13sentencepiece5model8FreeListIZNKS_3bpe5Model12SampleEncodeEN4absl11string_viewEfE10SymbolPairEE
NSt3__110__function6__funcIZNK13sentencepiece3bpe5Model12SampleEncodeEN4absl11string_viewEfE3$_2NS_9allocatorIS7_EEFvS6_PNS_6vectorINS_4pairIS6_iEENS8_ISC_EEEEEEE
NSt3__110__function6__baseIFvN4absl11string_viewEPNS_6vectorINS_4pairIS3_iEENS_9allocatorIS6_EEEEEEE
ZNK13sentencepiece3bpe5Model12SampleEncodeEN4absl11string_viewEfE3$_2
N13sentencepiece31SentencePieceText_SentencePieceE
N13sentencepiece17SentencePieceTextE
N13sentencepiece22NBestSentencePieceTextE
BPECHARUNIGRAMWORD
BYTECONTROLNORMALUNKNOWNUNUSEDUSER_DEFINED
N13sentencepiece11TrainerSpecE
N13sentencepiece14NormalizerSpecE
N13sentencepiece19SelfTestData_SampleE
N13sentencepiece12SelfTestDataE
N13sentencepiece24ModelProto_SentencePieceE
N13sentencepiece10ModelProtoE
NSt3__121__basic_string_commonILb1EEE
N6google8protobuf8internal16InternalMetadata9ContainerINSt3__112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEEEE
N6google8protobuf8internal16InternalMetadata13ContainerBaseE
N13sentencepiece9character5ModelE
N13sentencepiece10filesystem17PosixReadableFileE
N13sentencepiece10filesystem12ReadableFileE
N13sentencepiece10filesystem17PosixWritableFileE
N13sentencepiece10filesystem12WritableFileE
N13sentencepiece14ModelInterfaceE
N13sentencepiece10normalizer10NormalizerE
N5Darts15DoubleArrayImplIvvivEE
N5Darts7Details9ExceptionE
N13sentencepiece22SentencePieceProcessorE
N13sentencepiece7unigram5ModelE
N13sentencepiece7unigram7LatticeE
N13sentencepiece5model8FreeListINS_7unigram7Lattice4NodeEEE
N13sentencepiece5model8FreeListIZNS_7unigram7Lattice5NBestEmE10HypothesisEE
N13sentencepiece4word5ModelE
N6google8protobuf8internal21ArenaMetricsCollectorE
N6google8protobuf14FatalExceptionE
N6google8protobuf7ClosureE
N6google8protobuf8internal16FunctionClosure0E
N6google8protobuf8internal15ExtensionFinderE
N6google8protobuf8internal24GeneratedExtensionFinderE
N6google8protobuf8internal12ExtensionSet20LazyMessageExtensionE
N6google8protobuf8internal12ExtensionSet8KeyValueE
N6google8protobuf13RepeatedFieldIiEE
N6google8protobuf13RepeatedFieldIxEE
N6google8protobuf13RepeatedFieldIjEE
N6google8protobuf13RepeatedFieldIyEE
N6google8protobuf13RepeatedFieldIfEE
N6google8protobuf13RepeatedFieldIdEE
N6google8protobuf13RepeatedFieldIbEE
N6google8protobuf16RepeatedPtrFieldINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEEE
N6google8protobuf8internal20RepeatedPtrFieldBaseE
N6google8protobuf16RepeatedPtrFieldINS0_11MessageLiteEEE
NSt3__13mapIiN6google8protobuf8internal12ExtensionSet9ExtensionENS_4lessIiEENS_9allocatorINS_4pairIKiS5_EEEEEE
N6google8protobuf8internal19ImplicitWeakMessageE
N6google8protobuf11MessageLiteE
N6google8protobuf24ZeroCopyCodedInputStreamE
N6google8protobuf2io19ZeroCopyInputStreamE
NSt3__112basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEE
30SentencepieceModelLoadingError
00010203040506070809101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899
456789:;<=
 !"#$%&'()*+,-./0123
?456789:;<=
 !"#$%&'()*+,-./0123
ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/
ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_
N6google8protobuf8internal12FieldSkipperE
N6google8protobuf8internal29CodedOutputStreamFieldSkipperE
N6google8protobuf2io20ZeroCopyOutputStreamE
N6google8protobuf2io18CopyingInputStreamE
N6google8protobuf2io16ArrayInputStreamE
N6google8protobuf2io17ArrayOutputStreamE
N6google8protobuf2io18StringOutputStreamE
N6google8protobuf2io25CopyingInputStreamAdaptorE
N6google8protobuf2io26CopyingOutputStreamAdaptorE
N6google8protobuf2io19LimitingInputStreamE
N6google8protobuf2io15FileInputStreamE
N6google8protobuf2io15FileInputStream22CopyingFileInputStreamE
N6google8protobuf2io16FileOutputStreamE
N6google8protobuf2io16FileOutputStream23CopyingFileOutputStreamE
N6google8protobuf2io19CopyingOutputStreamE
N6google8protobuf2io18IstreamInputStreamE
N6google8protobuf2io18IstreamInputStream25CopyingIstreamInputStreamE
N6google8protobuf2io19OstreamOutputStreamE
N6google8protobuf2io19OstreamOutputStream26CopyingOstreamOutputStreamE
N6google8protobuf2io24ConcatenatingInputStreamE
N16nl_featurization14FeaturizerImplE
N16nl_featurization18AbstractFeaturizerE
N10global_ner12post_process20GeographicAreaEntityE
N10global_ner12post_process22PersonalLocationEntityE
N10global_ner12post_process18EmailAddressEntityE
N10global_ner9inference16NerEspressoModelE
N10global_ner9inference13EspressoModelE
N10global_ner12post_process14CurrencyEntityE
N10global_ner12post_process6EntityE
N10global_ner12post_process18BusinessNameEntityE
N10global_ner12post_process13AppNameEntityE
N10global_ner12post_process21MeasurementUnitEntityE
N10global_ner12post_process26MeasurementComponentEntityE
N10global_ner12post_process17PhoneNumberEntityE
N10global_ner12post_process17OtherPersonEntityE
N10global_ner12post_process12NumberEntityE
N10global_ner12post_process17MeasurementEntityE
++Dq
=K
TreeManipulation_OneShotReplyRemodeller
UserAccepted
UserStatedTask
SiriNL
SNLPFeatureStoreEnabled
[insights-snlp-snlc]: 
[insights-snlp-nlv4]: 
[insights-snlp-uaap]: 
component_name
old_prediction
hidden
memory
encodings
num_of_utterance_tokens
attention_index
out_predictions
out_new_hidden
out_new_memory
out_new_attention_index
-[UPContextualizerStrategyPrompt resultUsingContextualizerInput:]
UPContextualizerStrategyPrompt.m
[dialogAct isKindOfClass:[UPDialogActPrompt class]]
config.json
version.yaml
^VERSION: (\d+)\.(\d+)\.(\d+)
Version file not found at path: 
Version file has no parseable version key: 
%02x
.DS_Store
bolt_task_id
-[UPContextualizerStrategyOffer resultUsingContextualizerInput:]
UPContextualizerStrategyOffer.m
[contextualizerInput.dialogAct isKindOfClass:[UPDialogActOffer class]]
label
tokenIndicesIndex
[%lu, %lu)
Token overflow; received 
 tokens, expected 
 or fewer tokens.
NLv4
SNLC
UaaP
PLUM
UNKNOWN
<UNDEFINED_COMPONENT>
unordered_map::at: key not found
SNLPITFMErrorDomain
Missing resource: %@
Check that resource is available: %@
[UNK]
[PAD]
[CLS]
[SEP]
Could not open vocabulary data file: 
tokenText argument is empty
Encountered unknown token text and the vocabulary hasno special unknown token
Encountered unknown token ID
[NO_SDAS]
[NO_LEGACY_NL_CONTEXT_LABEL]
DICTATION_PROMPT=
STRICT_PROMPT=
PREVIOUS_NLV3_DOMAIN=
TRUE
FALSE
shape = 
 data = 
Searching for span with UTF-16 indices (
common_Date
common_Timer
Found matching span with graph:
) vs (
Found a matching insertable span 
Found a new max score, 
, for a non-matching insertable span 
Found a common_Time span with a Jaccard score of 
, overwriting the common_Date span with a Jaccard score of 
UPDialogActPrompt[intent: %@, entityType: %@, entityName: %@, reference: %@]
span_indices
token_embeddings
intent_softmax
app_label_softmax
bio_labels_softmax
group_labels_softmax
Espresso context is nil.
Espresso plan is nil.
Could not create espresso plan.
Failed to build espresso plan.
Failed to execute espresso plan.
Failed to clean up espresso plan.
Failed to reshape espresso blob.
Failed to bind buffer to input 
Failed to bind buffer to output 
group_name_transform
smsGroupName
personFullName
TreeManipulation_GroupNameTransform
Failed to parse 
^ *"(.*)"
^ *(\d+)
^ *([a-zA-Z0-9:_]+)
^ *:([a-zA-Z0-9:_]+)
^ *\n( *)
^ */ *([a-zA-Z0-9:_]+)
^ *\[(\d+):(\d+)\]
com.apple.uaapcustomluframework
{unique_ptr<itfm_inference_orchestrator::orchestration::ITFMOrchestrator, std::default_delete<itfm_inference_orchestrator::orchestration::ITFMOrchestrator>>={__compressed_pair<itfm_inference_orchestrator::orchestration::ITFMOrchestrator *, std::default_delete<itfm_inference_orchestrator::orchestration::ITFMOrchestrator>>=^{ITFMOrchestrator}}}32@?0@"SNLPITFMModelBundle"8@"SNLPITFMModelInfo"16^@24
%@ Asset Error when creating the %@ (ITFM) inference orchestrator: %s
Hit SNLP exception while calling ITFMOrchestrator::handle for request (high=%llu, low=%llu): %s
ERROR: Could not find the config file 
INFO: The parameter 
 is null.  This is currently expected behaviour.
WARNING: Could not parse the config parameter 
[json.exception.
invalid BOM; must be 0xEF 0xBB 0xBF if given
invalid literal
invalid comment; missing closing '*/'
invalid comment; expecting '/' or '*' after '/'
invalid string: missing closing quote
invalid string: '\u' must be followed by 4 hex digits
invalid string: surrogate U+D800..U+DBFF must be followed by U+DC00..U+DFFF
invalid string: surrogate U+DC00..U+DFFF must follow U+D800..U+DBFF
invalid string: forbidden character after backslash
invalid string: control character U+0000 (NUL) must be escaped to \u0000
invalid string: control character U+0001 (SOH) must be escaped to \u0001
invalid string: control character U+0002 (STX) must be escaped to \u0002
invalid string: control character U+0003 (ETX) must be escaped to \u0003
invalid string: control character U+0004 (EOT) must be escaped to \u0004
invalid string: control character U+0005 (ENQ) must be escaped to \u0005
invalid string: control character U+0006 (ACK) must be escaped to \u0006
invalid string: control character U+0007 (BEL) must be escaped to \u0007
invalid string: control character U+0008 (BS) must be escaped to \u0008 or \b
invalid string: control character U+0009 (HT) must be escaped to \u0009 or \t
invalid string: control character U+000A (LF) must be escaped to \u000A or \n
invalid string: control character U+000B (VT) must be escaped to \u000B
invalid string: control character U+000C (FF) must be escaped to \u000C or \f
invalid string: control character U+000D (CR) must be escaped to \u000D or \r
invalid string: control character U+000E (SO) must be escaped to \u000E
invalid string: control character U+000F (SI) must be escaped to \u000F
invalid string: control character U+0010 (DLE) must be escaped to \u0010
invalid string: control character U+0011 (DC1) must be escaped to \u0011
invalid string: control character U+0012 (DC2) must be escaped to \u0012
invalid string: control character U+0013 (DC3) must be escaped to \u0013
invalid string: control character U+0014 (DC4) must be escaped to \u0014
invalid string: control character U+0015 (NAK) must be escaped to \u0015
invalid string: control character U+0016 (SYN) must be escaped to \u0016
invalid string: control character U+0017 (ETB) must be escaped to \u0017
invalid string: control character U+0018 (CAN) must be escaped to \u0018
invalid string: control character U+0019 (EM) must be escaped to \u0019
invalid string: control character U+001A (SUB) must be escaped to \u001A
invalid string: control character U+001B (ESC) must be escaped to \u001B
invalid string: control character U+001C (FS) must be escaped to \u001C
invalid string: control character U+001D (GS) must be escaped to \u001D
invalid string: control character U+001E (RS) must be escaped to \u001E
invalid string: control character U+001F (US) must be escaped to \u001F
invalid string: ill-formed UTF-8 byte
invalid number; expected digit after '-'
invalid number; expected digit after '.'
invalid number; expected '+', '-', or digit after exponent
invalid number; expected digit after exponent sign
value
object key
object separator
number overflow parsing '
array
object
excessive object size: 
cannot get value
invalid_iterator
iterator does not fit current value
iterator out of range
cannot use erase() with 
type_error
null
string
boolean
binary
discarded
number
excessive array size: 
out_of_range
<U+%.4X>
parse_error
parse error
 at line 
, column 
syntax error 
while parsing 
; last read: '
unexpected 
; expected 
<uninitialized>
true literal
false literal
null literal
string literal
number literal
<parse error>
end of input
'[', '{', or a literal
unknown token
cannot compare iterators of different containers
cannot use key() for non-object iterators
type must be number, but is 
type must be boolean, but is 
type must be string, but is 
The month of year value should range from 1 to 12
semanticValue
unknownCustomEntity
unknownCustomVerb
DataDetectorService
The ITFM asset version (
) is incompatible with inference runtime (compatible versions 
ITFM Orchestrator failed with incompatible major version
Request does not contain a tokenised utterance
Request does not contain a token chain
Request does not contain embeddings
Request embeddings num tokens (
) does not match actual num tokens (
Request embeddings (
) exceeds maximum (
Received null input parser request
SystemGaveOptions
SystemOffered
executed_task
salient_entity
active_task
sdas
executed_tasks
salient_entities
active_tasks
_type=
_full_path=
_verb_entity=
_verb=
_below_verb=
_are_present
_are_absent
contact_type_split
contactType
emailType
TreeManipulation_ContactTypeSplit
nullptr
string_view::substr
cancel
notForMe
selectOrdinal
ordinal
placeholderVerb
((\w+)::common_(\w+)(\.)?(\w+))
::common
SystemPrompted
SystemOffered.offered_act.
SystemGaveOptions.option.
SystemInformed.entity
SystemReportedSuccess
SystemReportedFailure
_verb_entity
SystemOffered.offered_act.UserStatedTask
SystemOffered.offered_act.UserWantedToProceed
.primitive_String
UserAcknowledged
UserCancelled
UserRejected
UserWantedToPause
UserWantedToProceed
UserWantedToRepeat
SystemInformed
contact_address_downcast
emailAddress
phoneNumber
TreeManipulation_ContactAddressDowncaster
map::at:  key not found
min_max_labeller
minimumMaximum
floatSettingState
minimum
maximum
TreeManipulation_MinimumMaximumLabeller
de_DE
en_AU
en_CA
en_GB
en_IN
en_US
fr_FR
Error parsing JSON grammar: row.IsObject() == false [for key: 
resolution-table
 entry
semantic-value
Error parsing JSON grammar: parsedSemanticValue != row.MemberEnd() && parsedSemanticValue->value.IsString() == false [for key: 
synonyms
Error parsing JSON grammar: parsedSynonyms != row.MemberEnd() && parsedSynonyms->value.IsArray() == false [for key: 
Error parsing JSON grammar: parsedSynonym.IsString() == false [for key: 
type
Error parsing JSON grammar: parsedValueType->value.IsString() == false [for key: 
enum-choices
Error parsing JSON grammar: parsedEnumChoices->value.IsArray() == false [for key: 
open-list-choices
Error parsing JSON grammar: parsedOpenListChoices->value.IsArray() == false [for key: 
Error parsing JSON grammar: parsedResolutionTable->value.IsArray() == false [for key: 
left-label
Error parsing JSON grammar: leftLabel != jsonRule.MemberEnd() && leftLabel->value.IsString() == false [for key: 
value-constraints
Error parsing JSON grammar: parsedValueConstraints->value.IsObject() == false [for key: 
right-labels
Error parsing JSON grammar: parsedRightLabels != jsonRule.MemberEnd() && parsedRightLabels->value.IsArray() == false [for key: 
Error parsing JSON grammar: rightLabelObject.IsObject() == false [for key: 
name
Error parsing JSON grammar: parsedName != rightLabelObject.MemberEnd() && parsedName->value.IsString() == false [for key: 
repeated
Error parsing JSON grammar: parsedRepeatedFlag != rightLabelObject.MemberEnd() && parsedRepeatedFlag->value.IsBool() == false [for key: 
Could not open grammar file for reading: 
Grammar file is in error state after reading: 
Label does not exist
Error parsing JSON grammar: jsonGrammar.IsObject() == false [for key: 
(root)
rules
Error parsing JSON grammar: parsedRules != jsonGrammar.MemberEnd() && parsedRules->value.IsArray() == false [for key: 
Error parsing JSON grammar: enumChoice.IsString() == false [for key: 
Error parsing JSON grammar: openListChoice.IsString() == false [for key: 
allocator<const T>::allocate(size_t n) 'n' exceeds maximum supported size
Error parsing JSON grammar: parsedRule.IsObject() == false [for key: 
Expected:
Actual:
Badly-formed UDA
DelegatedUserDialogAct
Expected a UDA of type 
 but got a 
source_tokens_embeddings
matched_spans
context
source_mask
class_probabilities
SNLPServerNLClassifierErrorDomain
SNLC/SNLC.mlmodelc/model.espresso.net
SNLC/spans_pad.txt
SNLC/context_pad.txt
An error occured reading SNLC model bundle at: %@
Check that the path contains a valid model bundle: %@
node=
edge=
stringValue=
integerValue=
indentation=
alias=
textAlignment=
after
approx
before
earlier
every
last
lastlast
later
middle
next
nextnext
potentialEvery
same
slidinglast
this
upcoming
week
weekend
weekday
month
quarter
year
summer
winter
autumn
spring
semester
season
businessday
afternoon
bedtime
breakfast
brunch
dinner
evening
happyhour
lunch
midnight
morning
night
noon
SNLPPommesServerClassifierErrorDomain
PSC/PSC.mlmodelc/model.espresso.net
PSC/spans_pad.txt
PSC/context_pad.txt
confidence_threshold
An error occured reading PSC model bundle at: %@
ROOT
value=
intent=
[next]
[startPayload]
[leaf]
[endPayload]
[newGroup]
task
UserStarted
UserContinued
UserDisambiguated
UserResponded
directLeafNodes
Could not create analyzer: locale not supported
locale %@ not supported
B24@?0@"UPToken"8@"NSDictionary"16
-[UPContextualizerStrategyOptions resultUsingContextualizerInput:]
UPContextualizerStrategyOptions.m
[contextualizerInput.dialogAct isKindOfClass:[UPDialogActOptions class]]
batch_size
max_num_utterance_embeddings
max_num_context_tokens
max_num_spans_tokens
utterance_tokens_embedder_emb_dim
common_
Node 
 not found in ontology.
Verb 
Root
Last node on the parser stack is null, but it shouldn't
Test alignment parsed but last node on parser stack is not a UsoEntityNode
Empty edge found while attaching: 
Edge not found in ontology: 
Could not attach child 
 to parent 
 with edge 
Check
Control
Convert
Create
Delete
Entity
NoVerb
PlaceholderVerb
RecipientsEventTrigger
RecipientsHiddenPeople
Reference
ReferenceControl
ReferenceDateTimeRangeTrigger
ReferenceDurationTrigger
ReferenceMeasurementTrigger
ReferenceNumberTrigger
ReferencePaymentSortKey
ReferencePhotoCollection
ReferencePhotoCollectionFilter
ReferencePhotoFilter
ReferencePhotoMemoryFilter
ReferencePhotoTag
ReferenceProfile
ReferenceSelect
ReferenceSlideshowFilter
ReferenceStringTrigger
ReferenceTarget
ReferenceTargetSelect
ReferenceTrigger
ReferenceVideoFilter
Request
StockSummarise
Summarise
Target
Update
Token indices out of range: [
Unknown LabelScheme observed
Could not deserialise espresso context.
Could not set up espresso network.
not_found
ERROR: Could not find network configuration: 
Note that only parameters of unsigned integer type are currently expected by NLv4Parser.  This issue will likely cause NLv4 parser inference to fail.
UNDEFINED_COMPONENT
{UPToken string: %@ ; range: %@ ; isWhitespace: %@}
proto message is missing one of value, begin or end
Failed to convert CFString to C++ string
hello
world
hello world
DateTime
BeginTime
EndTime
Hours
Meridian
Minutes
MinutesBefore
Seconds
SpecialTimePeriod
Time
TimeDuration
TimeOffset
TimeSpan
TimeSpanReference
TimeSpanWithReference
AbsoluteDate
Date
DateDuration
DateOffset
DateSpan
DateTimeQualifier
DayNumber
DayOfNextWeek
DayOfWeek
MonthNumber
OccurrenceCount
RelativeDay
RelativeDayOfWeek
SpecialDatePeriod
SpecialDatePeriodUnit
SpecialDay
Identifier
YearNumber
B16@?0@"UPResultCandidate"8
+[UPContextualizerUtilities buildPayloadResultFromQuery:modelIdentifier:intent:entityName:serializer:]
UPContextualizerUtilities.m
utterance != nil
send::common_Message
target
common_Message
stringContent
SDA_MessagePayload_Prompt_Override
LegacyNLContext_DictationPrompt_Presence_Override
Error opening file: 
Number of element should be 2 in line 
MAX_WORD_LENGTH
MAX_UTTERANCE_LENGTH
USE_CHARS
USE_CHAR_LSTM
TestSpan
Could not open file path
FilePath
Given UTF-16 offset is not a Unicode scalar (code point) boundary: 
 000000000000
Input string is not a valid UTF-8 sequence! UTF-8 offset: 
Given UTF-16 offset exceeds the input string: 
relative_set_number_verb
setNumber
common_Setting
TreeManipulation_SetNumber_VerbReplacement
increaseBy
decreaseBy
unknown/
Could not convert
Component: 
Version: SNLPVersionInfo[train=
, majorVersion=
, minorVersion=
Bolt task ID: 
Bolt task ID: <missing>
No assets provided
Combined Hash: 
asset could not be read
chunkPredictions
nerScore
alternativeIndex
protobuf message is missing a start/end index
{UPSpan range: %@ ; type: %lu ; category: %@}
context_vocab.txt
multicardinal_vocab.txt
decoder.mlmodelc/model.espresso.net
encoder.mlmodelc/model.espresso.net
spans_vocab.txt
trg_vocab.txt
span_label_mapping.txt
SystemPrompted_Send_MessageContent
SDA_Placeholder_Verb_Replacement
The NLv4 asset version (
NLv4InferenceOrchestrator setup is broken; erroneous assets were provided
NLv4 request is null
PlaceholderVerb_placeholderVerb
ja_JP
common_Message.Target_send
NLv4 request missing request ID
NLv4 request missing valid embeddings
NLv4 request missing valid tokens
NLv4 request missing valid token chain locale
NLv4 request embeddings num tokens (
zh_CN
SystemPrompted.task.send::common_Message.target.common_Message.stringContent
spans_pad_symbol_index
context_pad_symbol_index
start_symbol_index
end_symbol_index
common_DateTime.time
common_Message.recipients
common_PhoneCall.recipients
common_Timer.attributes
common_Message.sender
common_Message.attachments
common_RecurringDateTime.recurrenceDateTimes
common_Message.usoQuantifier
common_Message.attributes
common_Message.participants
common_PhoneCall.attributes
modified_TranslationSourceLocale
common_Translation
sourceString
common_LocalisedString
locale
common_Locale
modified_TranslationPayload
stringValue
modified_TranslationReferenceType
usoReferenceType
modified_TranslationTargetLocale
targetString
modified_GeographicAreaName
geographicArea
common_GeographicArea
modified_GeographicAreaType
areaType
User dialog act node has multiple children.
/dev/urandom
sha1 too many bytes
void boost::uuids::detail::sha1::process_byte(unsigned char)
/System/Volumes/Data/SWE/iOS/BuildRoots/BuildRoot949/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator15.4.Internal.sdk/usr/local/include/boost/uuid/sha1.hpp
Not enough elements in call to seed.
UPEntityWithValue[entityType: %@, entityName: %@, entityValue:%@]
UPDialogActOffer[intent: %@, entityWithValue: %@]
noMatcher
DataDetector
PlumMatcher
UserVocabMatcher
SingleTrieMatcher
ContextMatcher
OvertonMatcher
MRRDetector
MRRMatcher
RegexSpanMatcher
personRelationship
phoneType
values
numTokens
numLayers
embeddingDim
embedderId
bert/embeddings/requires_subword_embeddings
feature_pooling_mask
max_seq_length
input_ids
input_mask
bert/feature_extraction_output
Could not create scanner from cache file: "
".  
utterance_tokens_embeddings
padding_mask
span_tokens
position_ids
out_init_decoder_hidden
out_encodings
addresses_
.cache
date_time_
addresses.cache
date_time.cache
flights.cache
currencies.cache
numbers.cache
phone_mobile.cache
coarseEntityType
fineGrainedEntityType
charIndicesRange
chunkScore
[CLS_SPAN]
[SEP_SPAN]
[NO_SPAN]
model_info.plist
info.plist
intent.vocab.txt
bio_labels.vocab.txt
span.vocab.txt
grammar.json
model.mlmodelc
calibration_model.mlmodelc
No USO
mention
entityType
score
usoGraph
%@%@%@
Entity type %@ should contain exactly one %@ and the string before %@ should be equal to %@
PostProcessor
dateTime
referenceTime
targetTime
tokens
originalUtterance
normalisedUtterance
app_bundle
neu_inputs
model.espresso.net
Subword embeddings enabled: 
bpe.model
hidden_size
BERT:
      pre-process 
      forward: 
      aggregate & post-process: 
      post-process: 
Vocabulary special tokens not properly defined
Query's token chain is nil
Query's embedding tensor is nil
Token with value "%@" doesn't have a nonwhitespace index
{UPQuery
  utterance: %@
  tokens:
  embeddingsByToken:
  spans:
UPDialogActOptions[intent: %@, entityType: %@, entityName: %@, entityValues: %@]
PLUM_%@
v24@?0@"UPSpan"8^B16
No embeddings are associated with token "%@"
Span label shape incorrect.
Given coordinates do not match tensor shape
Coordinates exceed bounds of tensor
v8@?0
General
Common
UPDataDetectors
SiriNaturalLanguageParsingSignPosts
com.apple.sirinaturallanguageparsing
data_detectors
tokenisedUtterance
embeddings
matchedSpans
text
phone-number
common_Time
common_Time12HourClock
common_Time24HourClock
date
Attempting to re-insert span entity to model graph, beneath 
time
common_Integer
usoEntityInsertionPoint
token
tokenId
graphemeClusters
isSpecialToken
isWordPiece
isOverflow
encodedLabels
SNLPNaturalLanguageParserErrorDomain
NLv4 Asset Error when creating the C++ NLv4 orchestrator: %s
Hit SNLP exception while constructing C++ orchestrator with asset directory %@: %s
Hit SNLP exception while calling NLv4InferenceOrchestrator::pbhandle for request (high=%llu, low=%llu): %s
NLv4InferenceOrchestrator::pbhandle returned nullptrfor request (high=%llu, low=%llu)
embeddingDim field missing from protobuf message
tokenIndex %u is out-of-bounds for an embedding tensor with %llu tokens
Protobuf message contains only %lu values but UPEmbedding for tokenIndex %u is being created (embeddingDim=%llu)
Protobuf message contains %lu embedding values which is not a multiple of %llu embedding dimensions
{UPEmbedding: dimension %lu}
UNKNOWN-MODEL-TYPE
alternativePredictions
NLv4SpanResponseAsJSON
NLv4ContextResponseAsJSON
NLv4AssetVersionAsJSON
NLv4ExecutedHandcraftedRulesAsJSON
%@-ITFMSpanResponseAsJSON
%@-ITFMContextResponseAsJSON
%@-ITFMAssetVersionAsJSON
%@-ITFMExecutedHandcraftedRulesAsJSON
TreeNode[
label:'
value:'
parentArgument:'
UTF-8 code unit indices:[
UTF-16 code unit indices:[
Unicode code point indices:[
Expected a node to start at: 
Expected an edge to start at: 
Regex search failed: 
^(accepted|acknowledged|cancelled|delegated|rejected|user_stated_task|wanted_to_pause|wanted_to_proceed|wanted_to_repeat|UserAccepted|UserAcknowledged|UserCancelled|DelegatedUserDialogAct|UserRejected|UserStatedTask|UserWantedToPause|UserWantedToProceed|UserWantedToRepeat)
UDA previously defined as 
 but is being redefined as 
Expecting a valid UDA name but got 
User dialog act not yet specified
UDA not yet specified
accepted
acknowledged
cancelled
UserCanceled
delegated
DelegatedDialogAct
rejected
user_stated_task
wanted_to_pause
wanted_to_proceed
wanted_to_repeat
unknown UDA 
person_name_split
TreeManipulation_PersonNameSplit
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing-3104.68.1/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/src/bpe_model.cc
(index) >= (0)
(index) < (static_cast<int>(symbols.size()))
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing-3104.68.1/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/src/builtin_pb/sentencepiece.pb.cc
sentencepiece.SentencePieceText.SentencePiece
sentencepiece.SentencePieceText
sentencepiece.NBestSentencePieceText
<unk>
</s>
<pad>
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing-3104.68.1/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/src/builtin_pb/sentencepiece_model.pb.cc
sentencepiece.TrainerSpec
sentencepiece.NormalizerSpec
sentencepiece.SelfTestData.Sample
sentencepiece.SelfTestData
sentencepiece.ModelProto.SentencePiece
sentencepiece.ModelProto
size_t to int conversion
Program terminated with an unrecoverable error.
Cancelled
Unknown
Invalid argument
Deadline exceeded
Not found
Already exists
Permission denied
Unauthenticated
Failed precondition
Aborted
Out of range
Unimplemented
Internal
Unavailable
Data loss
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing-3104.68.1/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/src/filesystem.cc
ReadAll is not supported for stdin.
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing-3104.68.1/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/src/model_factory.cc
Unknown model_type: 
piece must not be empty.
 is already defined.
unk is already defined.
byte piece 
 is found although `byte_fallback` is false.
 is invalid.
unk is not defined.
there are not 256 byte pieces although `byte_fallback` is true.
<0x%02X>
SiriNaturalLanguageParsing/External_Libraries/sentencepiece/src/model_interface.h
Not implemented.
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing-3104.68.1/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/src/normalizer.cc
precompiled_charsmap is empty. use identity normalization.
(length) >= (0)
(norm_to_orig->size()) == (normalized->size() + 1)
Blob for normalization rule is broken.
Trie data size exceeds the input blob size.
(0) == (trie_->build(key.size(), const_cast<char **>(&key[0]), nullptr, nullptr))
SiriNaturalLanguageParsing/External_Libraries/sentencepiece/src/util.h
'result' Must be non NULL
SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/darts_clone/darts.h:703: exception: failed to resize pool: std::bad_alloc
SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/darts_clone/darts.h:1141: exception: failed to insert key: negative value
SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/darts_clone/darts.h:1143: exception: failed to insert key: zero-length key
SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/darts_clone/darts.h:1157: exception: failed to insert key: invalid null character
SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/darts_clone/darts.h:1162: exception: failed to insert key: wrong key order
SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/darts_clone/darts.h:842: exception: failed to build rank index: std::bad_alloc
SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/darts_clone/darts.h:1380: exception: failed to modify unit: too large offset
SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/darts_clone/darts.h:1726: exception: failed to build double-array: invalid null character
SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/darts_clone/darts.h:1728: exception: failed to build double-array: negative value
SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/darts_clone/darts.h:1743: exception: failed to build double-array: wrong key order
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing-3104.68.1/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/src/sentencepiece_processor.cc
_status.ok()
model_proto->ParseFromArray(serialized.data(), serialized.size())
LOG(
INFO
 samples did not pass the test.
Self-test failures. See LOG(INFO).
model_
Model is not initialized.
normalizer_
Normalizer is not initialized.
type == TrainerSpec::UNIGRAM || type == TrainerSpec::BPE
Vocabulary constraint is only enabled in subword units.
(v.size()) >= (1)
!v[0].empty()
absl::SimpleAtoi(v[1], &freq)
Could not parse the frequency
pieces
output container is null
detokenized
!w.empty()
Empty piece is not allowed.
(begin) < (norm_to_orig.size())
(end) < (norm_to_orig.size())
(orig_begin) <= (input.size())
(orig_end) <= (input.size())
(orig_begin) <= (orig_end)
(consumed) == (normalized.size())
all normalized characters are not consumed.
output proto is null
nbest_spt
model_->IsNBestEncodeAvailable()
NBestEncode is not available for the current model.
!nbests.empty()
NBestEncode returns empty result.
(nbest_size) <= (512)
nbest_size must be nbest_size <= 512
model_->IsSampleEncodeAvailable()
SampleEncode is not available for the current model.
Invalid id: 
ERROR
Returns default value 
unknown extra_option type.
reverse
it != extra_option_map.end()
option "
" is not available.
!IsUnknown(PieceToId(absl::string_view(model_->bos_piece().data())))
id for `
` is not defined.
!IsUnknown(PieceToId(absl::string_view(model_->eos_piece().data())))
model file path should not be empty.
input->ReadAll(&serialized)
output->Write(model_proto.SerializeAsString())
(0) <= (byte)
(consumed) == (1)
(token_index_begin + offset) == (token_index_end)
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing-3104.68.1/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/src/unigram_model.cc
Failed to find the best path in Viterbi.
WARNING
nbest_size >= 1. Returns empty result.
Too big agenda. shrinking
(num_nodes) < (trie_results.size())
no pieces are loaded.
cannot build double-array.
no entry is found in the trie.
Two sentence piece sequences are not equivalent! Left: 
, Score: 
. Right: 
 Error #
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing-3104.68.1/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/protobuf-lite/arena.cc
CHECK failed: (min_bytes) <= (std::numeric_limits<size_t>::max() - kBlockHeaderSize): 
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing-3104.68.1/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/protobuf-lite/coded_stream.cc
A protocol message was rejected because it was too big (more than 
 bytes).  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in third_party/protobuf/src/google/protobuf/io/coded_stream.h.
CHECK failed: (buffer_size) >= (0): 
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing-3104.68.1/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/protobuf-lite/common.cc
This program requires version 
 of the Protocol Buffer runtime library, but the installed version is 
.  Please update your library.  If you compiled the program yourself, make sure that your headers are from the same version of Protocol Buffers as your link-time library.  (Version verification failed in "
This program was compiled against version 
 of the Protocol Buffer runtime library, which is not compatible with the installed version (
).  Contact the program author for an update.  If you compiled the program yourself, make sure that your headers are from the same version of Protocol Buffers as your link-time library.  (Version verification failed in "
%d.%d.%d
FATAL
[libprotobuf %s %s:%d] %s
%lld
%llu
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing-3104.68.1/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/protobuf-lite/extension_set.cc
CHECK failed: (type) != (WireFormatLite::TYPE_ENUM): 
CHECK failed: (type) != (WireFormatLite::TYPE_MESSAGE): 
CHECK failed: (type) != (WireFormatLite::TYPE_GROUP): 
CHECK failed: (type) == (WireFormatLite::TYPE_ENUM): 
CHECK failed: type == WireFormatLite::TYPE_MESSAGE || type == WireFormatLite::TYPE_GROUP: 
Don't lookup extension types if they aren't present (1). 
Don't lookup extension types if they aren't present (2). 
CHECK failed: extension != NULL: 
Index out-of-bounds (field is empty).
Extension not found.
Non-primitive types can't be packed.
Can't get here.
Invalid message set extension.
Multiple extension registrations for type "
", field number 
can't reach here.
SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/protobuf-lite/google/protobuf/extension_set_inl.h
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing-3104.68.1/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/protobuf-lite/generated_message_util.cc
Not implemented field number 
CHECK failed: (scc->visit_status.load(std::memory_order_relaxed)) == (SCCInfoBase::kRunning): 
 with type 
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing-3104.68.1/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/protobuf-lite/int128.cc
Division or mod by zero: dividend.hi=
, lo=
(cannot determine missing fields for lite message)
MessageLite at 0x
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing-3104.68.1/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/protobuf-lite/message_lite.cc
parse
 exceeded maximum protobuf size of 2GB: 
Can't 
 message of type "
" because it is missing required fields: 
CHECK failed: (byte_size_before_serialization) == (byte_size_after_serialization): 
 was modified concurrently during serialization.
CHECK failed: (bytes_produced_by_serialization) == (byte_size_before_serialization): 
Byte size calculation and serialization were inconsistent.  This may indicate a bug in protocol buffers or it may be caused by concurrent modification of 
This shouldn't be called if all the sizes are equal.
parsing
SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/protobuf-lite/google/protobuf/parse_context.h
Can't happen
SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/protobuf-lite/google/protobuf/repeated_field.h
CHECK failed: (index) >= (0): 
CHECK failed: (index) < (current_size_): 
CANCELLED
INVALID_ARGUMENT
DEADLINE_EXCEEDED
NOT_FOUND
ALREADY_EXISTS
PERMISSION_DENIED
UNAUTHENTICATED
RESOURCE_EXHAUSTED
FAILED_PRECONDITION
ABORTED
OUT_OF_RANGE
UNIMPLEMENTED
INTERNAL
UNAVAILABLE
DATA_LOSS
Subword model cannot be loaded from: 
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing-3104.68.1/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/protobuf-lite/stringpiece.cc
size too big: 
 details: 
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing-3104.68.1/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/protobuf-lite/stringprintf.cc
CHECK failed: (v.size()) <= (kStringPrintfVectorMaxArgs): 
StringPrintfVector currently only supports up to 
 arguments. 
Feel free to add support for more if you need it.
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing-3104.68.1/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/protobuf-lite/strutil.cc
CHECK failed: dest: 
\x%02x
\%03o
CHECK failed: i >= 0: 
FastHexToBuffer() wants non-negative integers, not 
%.*g
CHECK failed: value != nullptr: 
nullptr output boolean given.
true
false
0123456789abcdef
CHECK failed: s != nullptr: 
This can't happen; base64 decoder state = 
Logic problem? szsrc = 
%.1f
CHECK failed: (temp[0]) == ('1'): 
CHECK failed: (temp[size - 1]) == ('5'): 
CHECK failed: (size) <= (6): 
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
CHECK failed: result != nullptr: 
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing-3104.68.1/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/protobuf-lite/wire_format_lite.cc
CHECK failed: (value.size()) <= (kint32max): 
 '%s'
String field
 contains invalid 
UTF-8 data when 
 a protocol 
buffer. Use the 'bytes' type if you intend to send raw 
bytes. 
serializing
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing-3104.68.1/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/protobuf-lite/zero_copy_stream.cc
This ZeroCopyOutputStream doesn't support aliasing. Reaching here usually means a ZeroCopyOutputStream implementation bug.
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing-3104.68.1/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/protobuf-lite/zero_copy_stream_impl_lite.cc
CHECK failed: (last_returned_size_) > (0): 
BackUp() can only be called after a successful Next().
CHECK failed: (count) <= (last_returned_size_): 
CHECK failed: (count) >= (0): 
CHECK failed: target_ != NULL: 
CHECK failed: (count) <= (target_->size()): 
CHECK failed: backup_bytes_ == 0 && buffer_.get() != NULL: 
 BackUp() can only be called after Next().
CHECK failed: (count) <= (buffer_used_): 
 Can't back up over more bytes than were returned by the last call to Next().
 Parameter to BackUp() can't be negative.
CHECK failed: (backup_bytes_) == (0): 
CHECK failed: (buffer_used_) == (buffer_size_): 
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing-3104.68.1/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/protobuf-lite/zero_copy_stream_impl.cc
close() failed: 
CHECK failed: !is_closed_: 
Can't BackUp() after failed Next().
^(\b\w+\b)(\S+)$
Failed to initialise the regex expression for the subtokens: 
appendMatchedSpan
span_processor.cpp
mInternals.reverseMapping.find(str) != mInternals.reverseMapping.end() && "Unable to find token chain in reverse mapping after a match was found in the pattern " "trie"
Failed to attach the regex expression to the token text: 
Failed to find match in text: 
Encountered invalid substring: 
Encountered empty normalized matching substring for label: 
Begin/inside BIO tags must have a payload component
Only begin/inside BIO tags can have a payload component
Cannot extract payload from non-begin/inside BIO tag
getPayload
bio.cpp
mPayload.has_value()
Well-formed BIO tags must be >=3 characters long, but got: 
BIO tag has no prefix
Unrecognized BIO tag prefix
convertToLabelledSpans
!currentSpan.has_value()
buildAllBioTagsFromEntityLabels
bioTags.size() == expectedFinalSize
Cannot get value for empty optional!
Span labels tensor is of incorrect shape
Span labels tensor shape does not match tokens size
Unable to instantiate a normalizer form the input normalizer choice
Failed to instantiate normalizer - 
Failed to normalize string 
 - due to error: 
Failed to compare strings - due to error: 
Failed to casefold string: 
Invalid substring range. The endIndex
 >= src length 
Invalid substring range. startIndex  (
) >= endIndex (
insertToken
vocabulary.cpp
mIdToText.size() == mTextToId.size()
Token indices out of range.
Number of tokens differs from number of BIO tags
Number of tokens differs from number of group IDs
First dimension of intentEntityTransitions does not equal number of intents
Second dimension of intentEntityTransitions does not equal number of BIO tags
Size of startEntityTransitions does not equal number of BIO tags
First dimension of entityTransitions does not equal number of BIO tags
Second dimension of entityTransitions does not equal number of BIO tags
Out-of-range intent label (key) in uniqueLabels
Out-of-range BIO label (value) in uniqueLabels
Out-of-range intent label (key) in indexableLabels
Out-of-range BIO label (value) in indexableLabels
Empty entitiesScores (implies no tokens)
Size of groupScores (
) does not equal number of tokens (
Invalid beamSize. Should be in the interval (0, 5]
BeamSequence[
  score = 
  intent = 
  entities = 
  groupIds = 
(none)
beamSearch
beam_search.cpp
allCandidates.begin() + beamSize < allCandidates.end()
Beam sequence is empty getIntent
Beam sequence is empty getEntities
Embedding[
 ...
Label vocabulary does not contain pad token
Trans params's first and second dimension should have non-zero equal value, while the actual shape is [
Trans params's first and second dimension value: 
 should be equal to tag size: 
Logits tensor's last dimension value: 
 should be equal to the output label's size: 
 and transit parameters's dimension value: 
Invalid input. Can't have WordCharactersTensorEnabled to be false while have WordLengthTensorEnabled to be true.
Word embedding data first dimension: 
 sequence length data first dimension: 
 word character data first dimension: 
 and word length data first dimension: 
 should have equal non-zero values
Word embedding data second dimension: 
 word character data second dimension: 
 and word length second dimension: 
word_embedding_placeholder
sequence_length_placeholder
word_characters_placeholder
word_length_placeholder
dropout_placeholder
proj/logits
Dimension value: 
 should match first value of shape: 
 should match second value of shape: 
 should match third value of shape: 
Begin index of mention boundary: 
 should be smaller than end index (exclusive) of mention boundary: 
End index (exclusive) of mention boundary: 
 should be smaller or equal then predictions labels size: 
Begin index: 
 should be smaller than end index: 
End index: 
Sequence length: 
 should be less than logits length: 
Logits's shape should be [maxTokens (Siri default is 26),
], while the actual shape is [
Output label map contains label: 
 which is not B, I and O label
Output label map file is empty
Output label map file is invalid. Valid output label map should has O tag with 1 label value, I labels comes after B labels, while the actual value is: O tag: 
, first B tag: 
, last B tag: 
, first I tag: 
, last I tag: 
B labels and I labels should have equal size, while the actual value is: first B tag: 
Transition parameters loaded is invalid. Transition parameters's first and second dimension should have non-zero equal value
Vocab indices map file is empty
The given chunkPredictions and usoGraphs don't have equal size
measurement
measurementComponent
otherPerson
appName
personalLocation
businessName
measurementUnit
currency
Entities with type 
 or 
 both exist in char index range [
Can't find entities with type: 
 and entities with type: 
 in char index range [
Entities with type: 
) has more than one
Entity is not with type 
Can't cast to pointer to 
com.apple.siri.nlteam.plum
NerHandler
NerFactory
Espresso
The input nest tag: 
 is empty
Can't get flat tags from: 
The input nest B tag: 
Can't get B tags from: 
Tag 
 is not a B tag
Can't locate I tag
Can't locate 
 in iTagIndicesMap
Tag after split should have size 2
 in output label map
No Number child entities and MeasurementUnit child entity is null
Fail to create espresso context.
Fail to create espresso pan.
Fail to set up espresso network.
Can't find character: 
 in character indices map
Num of tokens in embedding tensor: 
 doesn't match with sequence length: 
Num of layers in embedding tensor: 
 is not 1. Currently NER only support number of layer to be 1.
Number of embedding float values: 
 doesn't match with embedding shape: [
Size of NER alternative prediction from NER factory: 
 is not 1
Find both commonMeasurementComponent node and commonCurrency node. Invalid measurement entity.
Both commonMeasurementComponent node and commonCurrency node don't exist. Invalid measurement entity.
Find more than one commonCurrency node. Invalid measurement entity.
Attempt pruning UserAccepted from a one shot reply UserAccepted + UserStatedTask prediction.
Could not find a UserAccepted dialog act to remove.
UPContextualizerStrategyPrompt; %ld domain candidates matched dialog act prompted entity (%@)
UPContextualizerStrategyPrompt: No domain result matched dialog act prompted entity (%@)
UPContextualizerStrategyPrompt: Building verbatim string payload
[%s] Error, file doesn't exist. Hash for file content cannot be calculated: %s
[%s] Error, input stream for file could not be created. Hash for file content cannot be calculated: %s
[%s] Error, input stream for file could not be read. Hash for file content cannot be calculated: %s
[%s] Error while calculating hash of file %s
[%s] Error iterating over directory %s: %s
[%s] Warning: config missing Bolt task ID
[%s] Warning: config Bolt task ID is not a string
UPContextualizerStrategyOffer: Detected high-probability yes/no intent in core result
BEGIN "Encoder Inference"
Encoder Inference
END "Encoder Inference"
BEGIN "Decoder Inference"
Decoder Inference
END "Decoder Inference"
[%s] Invalid featurization input provided to the model.  Expected a non-empty utterance length tensor and a context tensor of at least two dimensions.
[%s] The utterance length (%lu) exceeds the maximum utterance length (%lu).
[%s] padEmbeddings input tensor size = %lu (%lu, %lu, %lu)
[%s] padEmbeddings maxUtteranceLength (defined by network config) = %lu
[%s] Illegal shape for embeddings: (%lu, %lu, %lu). Must be (?, ?, %lu) and hold %lu values
[%s] padEmbeddings For each batch, copying %lu embedding values and adding %lu padding values
[%s] padEmbeddings Padded embedding tensor shape: (%lu, %lu, %lu)
[%s] The component %zu is invalid
Warning: cannot embed OOV token '%s'.
Featurized the following %lu LegacyNLContext features in ITFMParserRequest: %s
Failed to featurize any labels from legacyNlContext
Warning: Legacy NL context features were supplied, but the asset directory major version (%u) does not support these. These will not be featurized.
Warning: The request's nlContext contains a SDA. Skipping featurization for the legacy context.
No SDA present in nlContext: falling back to legacyNlContext
Failed to extract any labels from nlContext or legacyNlContext
Label '%s' not present in vocabulary. Skipping. (Is this label supported by the provided assets?)
Number of context features (%lu) exceeds maximum limit (%lu): truncating by removing features %s
%s ITFM context: %s
nlu_request_id not found so skipping insertion of context featurized response into FeatureStore
ITFM non-padded context input tensor: %s
Skipping insertion of ITFM context featurizer response into FeatureStore because SNLPFeatureStoreEnabled feature flag is disabled
Successfully inserted context featurizer response into FeatureStore
Unable to insert context featurizer response into FeatureStore
Handling UPQuery converted from proto request: %@
UPQuery from non-proto service: %@
Could not convert query dialog act: %{sensitive}@
Converted dialog act and got: %@
Found no utterance alignments, skipping...
Found no matching insertable span.
SiriOntology indicated an entity node, but failed to cast to UsoEntityNode type.
No utterance alignments found in the entity node; searching the descendant nodes for utterance alignments instead.
Found no entities in the uso graph of matching span, skipping...
There is more than one entity in the USO graph of matching span, skipping...
The first level entity is not of entity node type, skipping...
BEGIN "UaaP UPParserModelInit initWithSystemConfiguration"
UaaP UPParserModelInit initWithSystemConfiguration
END "UaaP UPParserModelInit initWithSystemConfiguration"
BEGIN "UaaP EspressoInference"
UaaP EspressoInference
END "UaaP EspressoInference"
BEGIN "UaaP Post-Processing"
Number of BEAM sequences = %lu
Processing BEAM sequence: %s
Produced candidate: %@
UaaP Post-Processing
END "UaaP Post-Processing"
BEGIN "UaaP Prediction"
Error predicting utterance: %{sensitive}s
UaaP Prediction
END "UaaP Prediction"
Reshaping network to handle current request inputs
Reshaping blob '%s' to w=%d, h=%d, k=%d, n=%d
Featurizing the following context labels in NLv4ParserRequest.
Skipping insertion of NLv4 context featurizer response into FeatureStore because SNLPFeatureStoreEnabled feature flag is disabled
[%s] Found an smsGroupName span that matches a common_Person or common_Agent node
[%s] Found a personFullName span that matches a common_Person or common_Agent node, so skipping group_name_transform
[%s] Replacing the node label "%s" with "%s"
[%s] Found %lu smsGroupName matching spans
[%s] Found %lu personFullName matching spans
[%@ Assets] %s
BEGIN "SNLPITFMClassifier responseForRequest"
SNLPITFMClassifier responseForRequest
END "SNLPITFMClassifier responseForRequest"
BEGIN "ITFM Span Featurization"
nlu_request_id not found so skipping insertion of asset version into FeatureStore
ITFM Span Featurization
END "ITFM Span Featurization"
BEGIN "ITFM Context Featurization"
ITFM Context Featurization
END "ITFM Context Featurization"
BEGIN "ITFM Inference"
ITFM Inference
END "ITFM Inference"
Warning: Invalid model version provided: %u.  Model versions currently supported: %s.
A token could not be reindexed; %{sensitive}s
Unknown error thrown during token index conversion (should be unreachable)
Token indexes could not be converted: %s
[%s] Splitting common_Person nodes in-place
[%s] Iterating through all tree nodes
[%s] Finished iterating through all tree nodes
[%s] Could not split this common_Person node
[%s] Successfully split the common_Person node into name/contact type
[%s] Handling common_Person subtree
[%s] Warning: the common_Person node has more than one child (expecting just `name`). Skipping.
[%s] Warning: the common_Person node child is not `name`. Skipping.
[%s] common_Person.name value: %{sensitive}s
[%s] There exists a person matching span covering this entire common_Person.name node. Skipping.
[%s] Could not find a split for this common_Person. Skipping.
[%s] Warning: Failed to generate a node for matching span (personInput=%{sensitive}s, contactTypeInput=%{sensitive}s)
[%s] Hit out of range exception when looking up token character indices
[%s] newNameNode.startCharIndex (%lu) is less than originalNameStartCharIndex (%lu)
[%s] newNameNode character indices imply an empty or impossible substring (%lu -> %lu)
[%s] contactAddressLabelNode.startCharIndex (%lu) is less than originalNameStartCharIndex (%lu)
[%s] contactAddressLabelNode character indices imply an empty or impossible substring (%lu -> %lu)
[%s] Generated new common_Person.name node with newNameNode.startCharIndex=%lu, newNameNode.endCharIndex=%lu, newNameNode.value=%{sensitive}s
[%s] After filtering, we have %lu contact type matching spans
[%s] After filtering, we have %lu person matching spans
[%s] Warning: could not find start token index corresponding to node.startCharIndex=%lu
[%s] Warning: could not find end token index corresponding to node.endCharIndex=%lu
[%s] Deleting %lu nodes
[%s] Inserting %lu spawned nodes
[%s] Badly formed SystemPrompted dialog act; needs to contain the target UsoGraph.
[%s] Badly formed SystemOffered dialog act; needs to contain a user dialog act.
[%s] Badly formed SystemReportedSuccess dialog act; needs to supply the task UsoGraph.
[%s] Badly formed SystemReportedFailure dialog act; needs to supply the UsoGraphs for the failed task and for the failure reason.
[%s] Warning: Badly formed user dialog act.
[%s] Failed to cast USO task node from SiriOntology. 
[%s] After filtering, we have %lu %s matching spans
[%s] No grounded tokens found under node: %s
No calibration score found for parser result with bundle modelIdentifier: %@
[%s] Both %s and %s semantic values found when using %s spans
[%s] MatchingSpan with label %s, semantic value %s found?: %{BOOL}d
Encountered error in deprecated version of inferenceResponseForRequest: %@ (returning SERVER parser response)
Result candidate has uncalibrated probability %f and calibrated probability %@. Using calibrated value.
Result candidate has uncalibrated probability %f and no calibrated probability. Using uncalibrated value.
Loaded config confidence_threshold: %1.2f
PSC response classificationProbability (%1.2f) is below the threshold (%1.2f), setting to 0.
UPContextualizerStrategyCancel: Detected high-probability cancel intent in core result
UPContextualizerStrategyOptions: Detected high-probability selectOrdinal intent in core result
UPContextualizerStrategyOptions: %ld domain candidates matched dialog act prompted entity (%@)
UPContextualizerStrategyOptions: No domain result matched dialog act prompted entity (%@)
UPContextualizerStrategyOptions: Building verbatim string payload
[%s] [model_task_id=%s]
[%s] %s
SNLC override triggered: falling back on DEVICE based on the turn input SDA content
SNLC override triggered: falling back on SERVER based on the LegacyNLContext dictationPrompt=true
nlu_request_id not found so skipping insertion of SNLC executed handcrafted rules into FeatureStore
Skipping insertion of SNLC executed handcrafted rules into FeatureStore because SNLPFeatureStoreEnabled feature flag is disabled
Successfully inserted executed handcrafted rules into FeatureStore
Unable to insert executed handcrafted rules into FeatureStore
Rejecting '%s'.
Warning: Context shape not 2-dim
[NLv4IO Context Tensor] shape=%lu,%lu num_elems=%lu
Warning: Context shape not consistent with data
[NLv4IO Context Token] i=%lu j=%lu id=%lu token=%s
PrepareGlobalNerRequest
FetchNerPredictions
Utterance: %{sensitive}@
ConvertToUPPLNerResponse
Predictions:
PLUM Span (before post processing):
GeneratePlumSpans
[%s] Found setNumber voc span(s)
No matcher names provided - type property will be UPSpanTypeNone
Span not recognized by the span matchers - type property will be UPSpanTypeNone
Creating NLv4InferenceOrchestrator instance with getAssetVersionMajor()=%u
Creating NLv4InferenceOrchestrator instance via deprecated constructor with major asset version %u
BEGIN "NLv4 Matched Span Featurization"
NLv4 Matched Span Featurization
END "NLv4 Matched Span Featurization"
BEGIN "NLv4 Context Featurization"
NLv4 Context Featurization
END "NLv4 Context Featurization"
NLv4 Inference
BEGIN "NLv4 Inference"
%s Numericalized span input for NLv4 parser model:
%s Numericalized context input for NLv4 parser model:
%s %s
END "NLv4 Inference"
BEGIN "NLv4 Tree Building"
Tree after all manipulations:
%{sensitive}s
A hypothesis was rejected because it contained only UserAccepted.
Building UDA for hypothesis number %zu
Invalid USO graph, removing parse from output.  This might be due to a grammatical error or an otherwise malformed model tree.
Could not generate a full USO graph for a hypothesis: %s
NLv4 Tree Building
END "NLv4 Tree Building"
[NLv4IO Ply tree] hypothesis=%zu:
[NLv4IO Ply tags] hypothesis=%zu:
[SNLPAssetLogger] %s
nlu_request_id not found so skipping insertion of executed handcrafted rules into FeatureStore
Skipping insertion of NLv4 executed handcrafted rules into FeatureStore because SNLPFeatureStoreEnabled feature flag is disabled
Successfully inserted NLv4 executed handcrafted rules into FeatureStore
Unable to insert NLv4 executed handcrafted rules into FeatureStore
Invalid model tree, removing parse from output.
Invalid user dialog act: %s
BEGIN "CalibrationInference"
CalibrationInference
END "CalibrationInference"
[%s] Warning: failed to get namespace for node %{sensitive}s: %{sensitive}s
[%s] Badly formed matching span; start and/or end indices missing from span.
Missing locale info when init UPDataDetector. Falling back using the system default one.
[%s] A data detector span contained a USO graph with an invalid entity node.  This data detector span was ignored by the span matching featurizer.  Error: %s.
[%s] Span encoding failed; number of buckets (%lu) not matching number of tokens (%lu).
%s Exception when calling C plus plus post processor code : %{sensitive}s
%s Exception "%{sensitive}s" catched during graph genereation for span:
 %{sensitive}@
%s Error serializing USO graph : %{sensitive}@
%s USO graph genereatd for span:
 %{sensitive}@
%s Use USOGraph from Date Detector Span for PLUM Span:
 %{sensitive}@
%s Data detector span is nil, skip the code to integrate plum spans with data detector spans.
BEGIN "UPLoadedModelConfigurationInit"
BEGIN "EspressoInitialization"
Exception while initializing model %s
EspressoInitialization
END "EspressoInitialization"
UPLoadedModelConfigurationInit
END "UPLoadedModelConfigurationInit"
[%s] [WARN] MatchingSpan has no USO graph
[%s] [WARN] MatchingSpan has USO graph with no identifiers
[%s] [WARN] probability missing from identifier
[%s] [WARN] probability has no value
[%s] [WARN] Negative relative threshold supplied (%f), span filtering will behave strangely
[%s] Span filtering: %lu out of %lu spans kept
[%s] Span %s [score %f] was kept?: %{BOOL}d
[%s] Span %s [no score] was kept?: %{BOOL}d
Multiple SystemDialogActs specified in context but UaaP can only handle one - using the first one
BEGIN "UaaP Preprocessing"
Found matched span using data detectors: %lu -> %lu (%s)
Featurized token with text=%s
Token span labels: %s
UaaP Preprocessing
END "UaaP Preprocessing"
Valid insertable span found; re-inserting it into the model graph.
Warning: could not look up ontology name for parent argument '%s'
Re-insertion of span graph was successful.
Could not insert subtree: %{sensitive}s 
 Warning: Could not generate USO graph: %s
Built USO graph:
Failed to cast entity node to entity node; SiriOntology reports a non-entity node as an entity node.
Warning: Integer %s out of range for USO integer nodes.
Warning: Failed to convert string %s to integer.
BEGIN "SNLPNaturalLanguageParser inferenceResponseForRequest"
SNLPNaturalLanguageParser inferenceResponseForRequest
END "SNLPNaturalLanguageParser inferenceResponseForRequest"
Tree after ContactTypeSplit step:
%{sensitive}s
Tree after PersonNameSplitHack step:
%{sensitive}s
Tree after GroupNameTransform step:
%{sensitive}s
Tree after ContactAddressDowncaster step:
%{sensitive}s
Tree after MinimumMaximumLabeller labelling:
%{sensitive}s
Tree after One Shot Reply check:
%{sensitive}s
Tree after SetNumber verb replacement:
%{sensitive}s
[%s] Span Input
[%s] nlu_request_id not found so skipping insertion of span featurized response into FeatureStore
[%s] Warning: encountered span missing label
[%s] Badly formed matching span; start and/or end indices missing from span. Skipping.
[%s] Mapping span label '%s' to span label '%s'
[%s] Warning: Featurised spans shape not 3-dim
[%s] [Span Tensor] shape=%lu,%lu,%lu num_elems=%lu
[%s] Warning: Span shape not consistent with data
[%s] [Span Token] i=%lu j=%lu k=%lu id=%lu token=%s
[%s] span '%s' covers tokens [%u, %u)
[%s] Spans encoded over the tokens:
[%s] %s: %s
[%s] Rejecting OOV Span: %s
[%s] Skipping insertion of matched spans featurized response into FeatureStore because SNLPFeatureStoreEnabled feature flag is disabled
[%s] Successfully inserted span featurizer response into FeatureStore
[%s] Unable to insert span featurizer response into FeatureStore
Could not find contextualizer strategy for dialog act: %{sensitive}@
Inserting FeatureStore entry with interactionIdentifier=%@, streamIdentifier=%@
[%s] Since the model itself predicted only %lu common_Person nodes (lower than the threshold of %lu), do not apply the name split hack
[%s] Could not find _any_ partition for this common_Person (including a single-span one). Skipping.
[%s] This common_Person cannot be split into multiple sub-spans. Skipping.
[%s] This common_Person has been partitioned into %lu sub-spans.
[%s] Warning: Failed to generate a node for matching span (input=%{sensitive}s)
[%s] Finding person matching span partitions for range %lu -> %lu
[%s]  - span: %{sensitive}s
[%s] Found %lu possible person partitions:
[%s] Found minimal partition:
[%s]  - component: %{sensitive}s
[%s] Did not find minimal partition
[%s] Generated new common_Person.name node with startCharIndex=%lu, endCharIndex=%lu, value=%{sensitive}s
[%s] Successfully spawned replacement common_Person nodes
Espresso
BeamSearch
CrfNormalizer
PrepareTensor
BuildTensor
ExecutePlan
GetTensor
UPModelIdentifier
NSCopying
UPContextualizerStrategyPrompt
UPContextualizerStrategy
NSObject
UPContextualizerStrategyOffer
UPPLMatchedSpan
UPDataDetectorSpan
SNLPITFMModelBundle
UPQueryRunner
UPDialogActPrompt
UPDialogAct
UPParserModel
SNLPITFMClassifier
UPUsoSerializer
UPCalibration
SNLPServerNLClassifier
UPResultCandidate
UPModelBundle
SNLPPommesServerClassifier
UPResultRootNode
UPTokenizer
UPResultNode
UPContextualizerStrategyCancel
UPContextualizerStrategyOptions
UPResultIntermediateNode
UPIntentWithSingleEntity
UPDialogActConverter
UPPreprocessorOutput
UPToken
SNLPEmbedder
UPContextualizerUtilities
UPPLNerHandler
UPUtilities
UPPLAlternativePrediction
UPSpan
UPCalibrationModel
UPEntityWithValue
UPDialogActOffer
UPPLEmbeddingTensor
UPDetectedData
UPDataDetectors
UPContextualizerInput
UPPLChunkPrediction
UPModelConfiguration
UPPlumSpan
UPPLPostProcessor
UPPLTokenization
SNLPFeatureFlagUtilities
UPLoadedModelConfiguration
UPResult
UPQuery
UPResultCandidateEntity
UPDialogActOptions
UPPreprocessor
UPSystemConfiguration
UPPLNerRequest
UPResultLeafNode
UPPLToken
SNLPNaturalLanguageParser
UPEmbedding
SNLPITFMModelInfo
UPPLNerResponse
UPContextualizer
SNLPFeatureStoreUtilities
init
UUID
allocWithZone:
copyWithZone:
uuid
isEqual:
appBundleId
isEqualToString:
hash
initWithAppBundleId:
.cxx_destruct
_uuid
_appBundleId
T@"NSUUID",R,C,V_uuid
T@"NSString",R,C,V_appBundleId
dialogAct
reference
coreResult
createConfirmOrRejectedDialogActsFor:reference:
domainResult
modelIdentifier
query
initWithDomainResult:coreResult:modelIdentifier:query:dialogAct:
entityName
filterResult:byEntityName:serializer:
candidateCount
intent
resultFromResult:withNewIntent:
entityType
buildPayloadResultFromQuery:modelIdentifier:intent:entityName:serializer:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
superclass
description
debugDescription
TQ,R
T#,R
T@"NSString",R,C
resultUsingContextualizerInput:
initWithPrebuiltIntentThreshold:usoSerializer:
prebuiltIntentThreshold
usoSerializer
_prebuiltIntentThreshold
_usoSerializer
Td,R,N,V_prebuiltIntentThreshold
T@"UPUsoSerializer",R,N,V_usoSerializer
stringWithCString:encoding:
defaultManager
fileExistsAtPath:isDirectory:
inputStreamWithFileAtPath:
open
read:maxLength:
stringWithCapacity:
appendFormat:
UTF8String
initWithLength:
mutableBytes
length
arrayWithObjects:count:
hasTopCandidate:excedingProbability:matchingOneOfIntents:
createResultFromExistingResult:truncatedTo:
initWithPrebuiltIntentThreshold:
label
tokenIndicesIndex
stringWithFormat:
dictionaryWithObjects:forKeys:count:
initWithLabel:tokenIndicesIndex:
dictionaryRepresentation
_label
_tokenIndicesIndex
T{_NSRange=QQ},R,N,V_tokenIndicesIndex
T@"NSString",R,N,V_label
initWithRange:type:category:
printedForm
initWithRange:category:dataDetectorResult:
initWithRange:category:dataDetectorResult:usoGraph:
getUsoGraphPrintedForm
dataDetectorResult
usoGraph
_dataDetectorResult
_usoGraph
T^{__DDResult=},R,V_dataDetectorResult
T@"USOSerializedGraph",R,V_usoGraph
_existErrorForEspressoModelURL:configURL:contextVocabularyURL:spanVocabularyURL:versionURL:errorDomain:
_initWithEspressoModelURL:configURL:contextVocabularyURL:spanVocabularyURL:versionURL:
path
isReadableFileAtPath:
_errorForMissingResourceURL:errorDomain:
mainBundle
localizedStringForKey:value:table:
errorWithDomain:code:userInfo:
bundleWithEspressoModelURL:configURL:contextVocabularyURL:spanVocabularyURL:versionURL:errorDomain:error:
espressoModelURL
configURL
contextVocabularyURL
spanVocabularyURL
versionURL
_espressoModelURL
_configURL
_contextVocabularyURL
_spanVocabularyURL
_versionURL
T@"NSURL",R,N,V_espressoModelURL
T@"NSURL",R,N,V_configURL
T@"NSURL",R,N,V_contextVocabularyURL
T@"NSURL",R,N,V_spanVocabularyURL
T@"NSURL",R,N,V_versionURL
initWithUsoSerializer:
countByEnumeratingWithState:objects:count:
preprocessor
initWithPreprocessor:parserModel:calibrationModel:
addObject:
initWithCoreModel:domainModelBundles:
initWithProtobufQuery:error:
predictionFromQuery:error:
protobufRepresentation
initWithProtobufQueryAndPlumSpans:plumSpans:error:
dictionary
parserModel
identifier
preprocess:error:
predictionFromQuery:preprocessorOutput:error:
setObject:forKey:
calibrationModel
scoreFromQuery:preprocessorOutput:error:
calibrateParserResults:withCalibrationScores:error:
dialogActFromQuery:
allValues
setWithArray:
singleTurnPredictionFromDomainResults:
multiTurnPredictionFromQuery:modelIdentifierToDomainResults:dialogAct:error:
convertFromDialogAct:error:
localizedDescription
queryUUID
valueForKey:
anyObject
array
candidateAtRank:
probability
initWithKey:ascending:
sortedArrayUsingDescriptors:
initWithCandidates:queryUUID:
combinedResultFromResults:
objectForKeyedSubscript:
resultWithContextualizerInput:
initWithCoreModel:domainModels:
predictionFromProtobufQuery:error:
predictionFromProtobufQueryAndPlumSpans:plumSpans:error:
domainModels
coreModel
domainModelBundles
_calibration
_dialogActConverter
_contextualizer
_coreModel
_domainModelBundles
__calibration
__dialogActConverter
__contextualizer
T@"UPCalibration",R,N,V__calibration
T@"UPDialogActConverter",R,N,V__dialogActConverter
T@"UPContextualizer",R,N,V__contextualizer
T@"UPParserModel",R,N,V_coreModel
T@"NSSet",R,N,V_domainModelBundles
copy
initWithIntent:entityType:entityName:reference:
_intent
_entityType
_entityName
_reference
T@"NSString",R,C,V_entityType
T@"NSString",R,C,V_entityName
T@"USOSerializedGraph",R,V_reference
T@"NSString",R,C,V_intent
initWithSystemConfiguration:loadedModelConfiguration:
initWithModelConfiguration:
modelWithSystemConfiguration:loadedModelConfiguration:error:
bundleId
stdU16ToNSString:
numberWithUnsignedLong:
rangeFromStart:end:
initWithRange:label:text:groupId:semanticValue:
serializeFromIntent:andEntities:forBundleId:
initWithTask:
initWithUncalibratedProbability:calibratedProbability:utterance:intent:entities:modelIdentifier:task:
parserEspressoModule
utterance
nSStringToU16String:
beamMaskInput
arrayWithCapacity:
_candidateForBeamSequence:utterance:outputTokens:resolver:
annotatedString
intentVocabPath
bioLabelsVocabPath
_candidateForUtterance:probability:labelledSpans:intent:
spanLabelsTensor
embeddingsTensor
forwardWithSpanLabels:embeddings:utterance:
outputTokens
resolver
_resultFromInferenceResult:query:outputTokens:resolver:
locale
isPLUMEnabled
modelWithSystemConfiguration:modelConfiguration:error:
setIsPLUMEnabled:
_systemConfiguration
_loadedModelConfiguration
_isPLUMEnabled
_identifier
__usoSerializer
__systemConfiguration
__loadedModelConfiguration
T@"UPUsoSerializer",R,V__usoSerializer
T@"UPSystemConfiguration",R,N,V__systemConfiguration
T@"UPLoadedModelConfiguration",R,N,V__loadedModelConfiguration
T@"UPModelIdentifier",R,N,V_identifier
T@"NSLocale",R,C,N
TB,N,V_isPLUMEnabled
T@"UPPreprocessor",R
initWithModelBundle:modelInfo:initializationBlock:error:
_initializationBlock
loggingComponent
loggingComponentString
errorDomain
_setupAssetLogger
stringByDeletingLastPathComponent
_convertRequest:
requestId
highInt
lowInt
_convertResponse:
data
bytes
dataWithBytes:length:
initWithData:
classifierWithModelBundle:modelInfo:initializationBlock:error:
classifierWithModelBundle:modelInfo:error:
responseForRequest:error:
modelBundle
modelInfo
.cxx_construct
_orchestrator
_assetLogger
_modelBundle
_modelInfo
T@"SNLPITFMModelBundle",R,N,V_modelBundle
T@"SNLPITFMModelInfo",R,N,V_modelInfo
_convertBundleIdToEntity:
isHigherLevelEntity
_insertSimpleEntity:intoGraph:underTaskNode:
_insertHigherLevelEntities:intoGraph:underTaskNode:
initWithUsoGraph:withError:
defaultCStringEncoding
_leafNodeFromLabel:andGraphStringNode:
_leafNodeFromLabel:andGraphSemanticValueNode:
_leafNodeFromGraphEdge:andGraphNode:
initWithLabel:andLeafNodes:
toCppUsoGraph:withError:
_intermediateNodeRepresentations:
initWithLabel:intermediateNodes:directLeafNodes:
range
text
semanticValue
_addPathForLabel:range:text:semanticValue:toGraphNode:forGraph:
_groupHigherLevelEntities:
objectForKey:
higherLevelChildLabel
higherLevelParentLabel
groupId
numberWithLong:
stringByReplacingOccurrencesOfString:withString:
initWithLabel:andText:andSemanticValue:
deserializeFromSerializedGraph:
_usoVocabManager
doubleValue
calibrateResult:withCalibrationScore:
calibrateCandidate:withCalibrationScore:
uncalibratedProbability
numberWithDouble:
entities
task
stringWithUTF8String:
URLByAppendingPathComponent:
_classifierWithModelURL:configURL:spanVocabularyURL:contextVocabularyURL:versionURL:error:
URLByDeletingLastPathComponent
initWithType:loggingComponent:errorDomain:
alloc
_convertSNLCRequest:
_convertITFMResponse:
inferenceResponseForRequest:error:
setClassificationLabel:
setClassificationProbability:
embeddings
setEmbeddings:
matchingSpans
setMatchingSpans:
tokenisedUtterance
setTokenisedUtterance:
setRequestId:
turnInput
setTurnInput:
classificationLabel
classificationProbability
classifierWithPathURL:error:
classifierWithModelURL:configURL:spanVocabularyURL:contextVocabularyURL:error:
inferenceResponseForRequest:
numberWithUnsignedInteger:
annotatedEntityFragmentString
appendString:
characterAtIndex:
stringWithCharacters:length:
count
initWithCapacity:
_buildCandidateEntitiesByStartIndex:
rootNodeRepresentationForIntent:andEntities:
calibratedProbability
bestAvailableProbability
setProbability:
convertFromUserDialogAct:
arrayWithObject:
setUserDialogActs:
rootNodeRepresentation
_candidateEntitiesByStartIndex
_modelIdentifier
_task
_uncalibratedProbability
_calibratedProbability
_entities
__candidateEntitiesByStartIndex
_utterance
T@"NSDictionary",R,V__candidateEntitiesByStartIndex
T@"NSString",R,V_utterance
T@"NSString",R,V_intent
T@"UPResultRootNode",R
T@"UPUsoSerializer",R,V_usoSerializer
T@"UPModelIdentifier",R,N,V_modelIdentifier
T@"NSObject<SIRINLUUserDialogAct>",R,C,V_task
Td,R,V_uncalibratedProbability
T@"NSNumber",R,V_calibratedProbability
Td,R
T@"NSArray",R,V_entities
T@"SIRINLUEXTERNALUserParse",R,N
Td,R,N
initWithLoadedModelConfiguration:parserModel:calibrationModel:
_parserModel
_calibrationModel
_preprocessor
T@"UPPreprocessor",R,N,V_preprocessor
T@"UPParserModel",R,N,V_parserModel
T@"UPCalibrationModel",R,N,V_calibrationModel
dataWithContentsOfURL:
JSONObjectWithData:options:error:
floatValue
setConfidenceThreshold:
confidenceThreshold
_confidenceThreshold
Tf,N,V_confidenceThreshold
initWithLabel:
directLeafNodes
initWithArray:copyItems:
objectAtIndexedSubscript:
_dictionaryRepresentation
replaceObjectAtIndex:withObject:
null
intermediateNodes
_intermediateNodes
_directLeafNodes
T@"NSArray",R,C,V_intermediateNodes
T@"NSArray",R,C,V_directLeafNodes
localeIdentifier
raise:format:
whitespaceAndNewlineCharacterSet
stringByTrimmingCharactersInSet:
initWithString:range:isWhitespace:
isWhitespace
predicateWithBlock:
filteredArrayUsingPredicate:
nonWhitespaceTokensForTokens:
initWithLocale:
tokenizeUtterance:
_locale
T@"NSLocale",R,C,V_locale
T@"NSString",R,C,V_label
leafNodes
_leafNodes
T@"NSArray",R,C,V_leafNodes
entity
isEqualToEntityWithValue:
initWithIntent:singleEntity:
isEqualToIntentWithSingleEntity:
_entity
T@"UPEntityWithValue",R,V_entity
_convertFromOfferedDialogAct:error:
_convertFromGaveOptionsDialogAct:error:
_convertFromPromptedDialogAct:error:
offeredAct
_parseUserDialogAct:error:
initWithIntent:entityWithValue:
choices
objectAtIndex:
entityValue
initWithIntent:entityType:entityName:entityValues:
_parseUserDialogActGraph:error:
higherLevelEntityLabelFromParentLabel:childLabel:
initWithType:entityName:entityValue:
T@"UPUsoSerializer",R,C,V_usoSerializer
initWithEmbeddingsTensor:spanLabelsTensor:outputTokens:
dataDetectorSpans
_embeddingsTensor
_spanLabelsTensor
_outputTokens
_dataDetectorSpans
T^v,R
insertToFeatureStoreWithNLv4SpanResponse:interactionIdentifier:
insertToFeatureStoreWithNLv4ContextResponse:interactionIdentifier:
insertToFeatureStoreWithNLv4AssertVersion:interactionIdentifier:
insertToFeatureStoreWithNLv4ExecutedHandcraftedRules:interactionIdentifier:
itfmModelTypeForSNLPComponent:
insertToFeatureStoreWithITFMSpanResponse:interactionIdentifier:itfmModelType:
insertToFeatureStoreWithITFMContextResponse:interactionIdentifier:itfmModelType:
insertToFeatureStoreWithITFMAssertVersion:interactionIdentifier:itfmModelType:
insertToFeatureStoreWithITFMExecutedHandcraftedRules:interactionIdentifier:itfmModelType:
string
isEqualToToken:
hasValue
hasBegin
hasEnd
value
begin
initWithString:
initWithProtobufToken:
_isWhitespace
_string
_range
T@"NSString",R,C,V_string
T{_NSRange=QQ},R,V_range
TB,R,V_isWhitespace
warmup
tokenChain
tokensCount
tokens
cleanValue
setValues:count:
setNumToken:
setNumLayer:
setEmbeddingDim:
setEmbedderId:
setEmbeddingTensor:
setTokenChain:
initFromSourceVocabPath:bertModelPath:bertConfigPath:reformulatorPath:
getEmbeddingsBySentence:
getEmbeddings:
_cppOrchestrator
containsObject:
entityLabelsFromCandidate:
filterResult:serializer:predicate:
setReference:
instancesRespondToSelector:
loadConfigs:
integerValue
boolValue
tokenizedUtterance
originalUtterance
token
charIndicesRange
graphemeClusters
normalizedUtterance
numTokens
embeddingDim
values
numLayers
embedderId
numberWithFloat:
initWithCoarseEntityType:fineGrainedEntityType:charIndicesRange:tokenIndicesIndex:chunkScore:
initWithChunkPredictions:nerScore:alternativeIndex:
initWithAlternativePredictions:
predictNamedEntitiesForRequest:
alternativePredictions
chunkPredictions
substringWithRange:
fineGrainedEntityType
generateTypeWithPlumPrefix:
chunkScore
initWithRange:originalMention:category:score:usoSerializedGraph:
initWithLocale:modelDir:vocabTagsFile:transParamsFile:charIndicesFile:configFile:
initWithLocale:modelDir:vocabTagsFile:transParamsFile:charIndicesFile:configFile:padCharacter:unkCharacter:
generatePlumSpansForRequest:
maxTokens
maxTokenLength
beamSize
wordCharactersTensorEnabled
wordLengthTensorEnabled
useDropOut
_handler
_postProcessor
_wordCharactersTensorEnabled
_wordLengthTensorEnabled
_useDropOut
_maxTokens
_maxTokenLength
_beamSize
TQ,R,N,V_maxTokens
TQ,R,N,V_maxTokenLength
TQ,R,N,V_beamSize
TB,R,N,V_wordCharactersTensorEnabled
TB,R,N,V_wordLengthTensorEnabled
TB,R,N,V_useDropOut
fileExistsAtPath:
lengthOfBytesUsingEncoding:
getBytes:maxLength:usedLength:encoding:options:range:remainingRange:
intermediateNodeRepresentations:
checkFileExistence:error:
nerScore
alternativeIndex
_chunkPredictions
_nerScore
_alternativeIndex
T@"NSArray",R,N,V_chunkPredictions
T@"NSNumber",R,N,V_nerScore
TQ,R,N,V_alternativeIndex
hasStartTokenIndex
hasEndTokenIndex
_getSpanTypeFromProtobufSpan:
startTokenIndex
endTokenIndex
matcherNamesCount
matcherNamesAtIndex:
type
category
initWithProtobufSpan:error:
_type
_category
TQ,R,V_type
T@"NSString",R,C,V_category
calibrationEspressoModule
_entityValue
T@"NSString",R,C,V_entityValue
initWithIntent:
entityWithValue
_entityWithValue
T@"UPEntityWithValue",R,V_entityWithValue
initWithValues:withNumTokens:withNumLayers:withEmbeddingDim:withEmbedderId:
_values
_numTokens
_numLayers
_embeddingDim
_embedderId
T@"NSArray",R,N,V_values
TQ,R,N,V_numTokens
TQ,R,N,V_numLayers
TQ,R,N,V_embeddingDim
T@"NSString",R,N,V_embedderId
dealloc
initWithLabel:dataDetectorResult:
Tr^{__CFArray=},R,V_dataDetectorResult
localeWithLocaleIdentifier:
initLoadFromDataDetectorsDirectoryPath:forLocale:
dataDetectorsDirectoryPath
languageCode
dataDetector
_matchSpansForDetectedDataArray:label:
addObjectsFromArray:
initLoadFromDataDetectorsDirectoryPath:
initWithSystemConfiguration:forLocale:
matchSpans:
matchSpansForUtterance:
matchSpansForDetectedData:
ddUsoMapper
_dataDetector
_ddUsoMapper
T^{UPDataDetector=q^{__DDScanner}^{__DDScanner}^{__DDScanner}^{__DDScanner}^{__DDScanner}^{__DDScanner}},R,V_dataDetector
T^v,R,V_ddUsoMapper
_domainResult
_coreResult
_query
_dialogAct
T@"UPResult",R,N,V_domainResult
T@"UPResult",R,N,V_coreResult
T@"UPQuery",R,N,V_query
T@"<UPDialogAct>",R,N,V_dialogAct
coarseEntityType
_coarseEntityType
_fineGrainedEntityType
_chunkScore
_charIndicesRange
T@"NSString",R,N,V_coarseEntityType
T@"NSString",R,N,V_fineGrainedEntityType
T{_NSRange=QQ},R,N,V_charIndicesRange
T@"NSNumber",R,N,V_chunkScore
_initWithBioLabelsVocabPath:configPath:grammarPath:intentVocabPath:spanVocabPath:parserEspressoModelPath:calibrationEspressoModelPath:
stringByAppendingPathComponent:
_configurationWithBioLabelsVocabPath:configPath:grammarPath:intentVocabPath:spanVocabPath:parserEspressoModelPath:calibrationEspressoModelPath:error:
configurationFromDirectoryUrl:error:
configPath
grammarPath
spanVocabPath
parserEspressoModelPath
calibrationEspressoModelPath
espressoModelPath
_bioLabelsVocabPath
_configPath
_grammarPath
_intentVocabPath
_spanVocabPath
_parserEspressoModelPath
_calibrationEspressoModelPath
_espressoModelPath
T@"NSString",R,C,V_bioLabelsVocabPath
T@"NSString",R,C,V_configPath
T@"NSString",R,C,V_grammarPath
T@"NSString",R,C,V_intentVocabPath
T@"NSString",R,C,V_spanVocabPath
T@"NSString",R,C,V_parserEspressoModelPath
T@"NSString",R,C,V_calibrationEspressoModelPath
T@"NSString",R,C,V_espressoModelPath
componentsSeparatedByString:
exceptionWithName:reason:userInfo:
getTypeWithtoutPlumPrefix
usoSerializedGraph
setUsoSerializedGraph:
originalMention
score
_usoSerializedGraph
_originalMention
_score
T@"USOSerializedGraph",&,V_usoSerializedGraph
T@"NSString",R,V_originalMention
T@"NSNumber",R,C,V_score
valueWithRange:
process:dataDetectorSpans:
initWithTokens:originalUtterance:normalizedUtterance:
_originalUtterance
_normalizedUtterance
_tokens
T@"NSString",R,N,V_originalUtterance
T@"NSString",R,N,V_normalizedUtterance
T@"NSArray",R,N,V_tokens
isSNLPFeatureStoreEnabled
dictionaryWithContentsOfFile:
initWithLocale:tokenizer:isPLUMEnabled:featurizer:
hasCalibrationModel
labelToValueType
_bundleId
_labelToValueType
_resolver
_beamMaskInput
_parserEspressoModule
_calibrationEspressoModule
T@"NSLocale",R,N,V_locale
TB,R,V_isPLUMEnabled
T@"NSString",R,N,V_bioLabelsVocabPath
T@"NSString",R,N,V_intentVocabPath
T^v,R,N,V_labelToValueType
T^v,R,N,V_resolver
T^v,R,N,V_beamMaskInput
T^{EspressoModule=^v^v{?=^vi}},R,N,V_parserEspressoModule
T^{EspressoModule=^v^v{?=^vi}},R,N,V_calibrationEspressoModule
TB,R
T@"NSString",R,N,V_bundleId
_candidates
subarrayWithRange:
addHypotheses:
rootNode
_queryUUID
__candidates
T@"NSArray",R,C,N,V__candidates
T@"NSUUID",R,C,V_queryUUID
T@"UPResultRootNode",R,C
T@"SIRINLUINTERNALUAAP_PARSERUaaPParserResponse",R
hasTokenChain
tokensAtIndex:
hasEmbeddings
hasNonWhitespaceTokenIndex
nonWhitespaceTokenIndex
initWithProtobufEmbeddings:forTokenAt:error:
setObject:forKeyedSubscript:
matchingSpansCount
matchingSpansAtIndex:
hasTurnInput
hasTurnContext
turnContext
hasNlContext
nlContext
systemDialogActs
systemDialogActsCount
firstObject
convertSystemDialogAct:
_createTokenChainWithProtobufQuery:
_createEmbeddingsWithProtobufQuery:error:
_createSpansWithProtobufQuery:plumSpans:error:
_createDialogActWithProtobufQuery:
initWithTokens:embeddingsByToken:spans:dialogAct:
embeddingsByToken
spans
enumerateSpansWithType:block:
setTokens:
setEmbeddingsByToken:
__utterance
_embeddingsByToken
_spans
T@"NSArray",C,V_tokens
T@"NSDictionary",C,V_embeddingsByToken
T@"NSArray",R,C,V_spans
T@"<SIRINLUSystemDialogAct><NSObject>",R,V_dialogAct
containsString:
rangeOfString:
substringToIndex:
substringFromIndex:
longValue
_indexedLabelRepresentation
leafNodeRepresentation
_text
_groupId
_semanticValue
T@"NSString",R,V_label
T@"NSString",R,V_text
T@"NSNumber",R,V_groupId
T@"NSString",R,V_semanticValue
T@"UPResultLeafNode",R
T@"NSString",R
entityValues
_entityValues
T@"NSArray",R,C,V_entityValues
getDimension
getCoordinates
tokenizer
__featurizer
_tokenizer
T@"UPTokenizer",R,N,V_tokenizer
_initWithDataDetectorsDirectoryPath:
_configurationWithDataDetectorsDirectoryPath:error:
_dataDetectorsDirectoryPath
T@"NSString",R,C,V_dataDetectorsDirectoryPath
matchedSpans
initWithTokenizedUtterance:embeddings:matchedSpans:
_tokenizedUtterance
_embeddings
_matchedSpans
T@"UPPLTokenization",R,N,V_tokenizedUtterance
T@"UPPLEmbeddingTensor",R,N,V_embeddings
T@"NSArray",R,N,V_matchedSpans
T@"NSString",R,C,V_text
T@"NSString",R,C,V_semanticValue
tokenId
isSpecialToken
numberWithBool:
isWordPiece
isOverflow
encodedLabels
initWithToken:tokenId:charIndicesRange:graphemeClusters:
initWithToken:tokenId:charIndicesRange:graphemeClusters:isSpecialToken:isWordPiece:isOverflow:encodedLabels:
_isSpecialToken
_isWordPiece
_isOverflow
_token
_tokenId
_graphemeClusters
_encodedLabels
T@"NSString",R,N,V_token
TQ,R,N,V_tokenId
T@"NSArray",R,N,V_graphemeClusters
TB,R,N,V_isSpecialToken
TB,R,N,V_isWordPiece
TB,R,N,V_isOverflow
T@"NSArray",R,N,V_encodedLabels
fileSystemRepresentation
_initWithCppOrchestrator:
convertNLv4ParserRequestToCpp:
convertNLv4ParserResponseFromCppToObjC:
parserFromAssetDirectory:error:
hasEmbeddingDim
hasNumToken
numToken
valuesCount
initWithDomain:code:userInfo:
valuesAtIndex:
setObject:atIndexedSubscript:
initWithCoordinates:
arrayWithArray:
_embedding
stringForModelType:
_loggingComponent
_errorDomain
_loggingComponentString
TQ,R,N,V_type
Ti,R,N,V_loggingComponent
T@"NSString",R,N,V_errorDomain
T@"NSString",R,N,V_loggingComponentString
_alternativePredictions
T@"NSArray",R,N,V_alternativePredictions
_contextualizeByDialogActTypeUsingContextualizerInput:
cancelContextualizerStrategy
offerContextualizerStrategy
optionsContextualizerStrategy
promptContextualizerStrategy
_cancelContextualizerStrategy
_offerContextualizerStrategy
_optionsContextualizerStrategy
_promptContextualizerStrategy
T@"UPContextualizerStrategyCancel",R,N,V_cancelContextualizerStrategy
T@"UPContextualizerStrategyOffer",R,N,V_offerContextualizerStrategy
T@"UPContextualizerStrategyOptions",R,N,V_optionsContextualizerStrategy
T@"UPContextualizerStrategyPrompt",R,N,V_promptContextualizerStrategy
_insertToFeatureStoreWithProtobufObject:interactionIdentifier:streamIdentifier:
dataWithJSONObject:options:error:
initWithData:encoding:
_jsonStringFromProtobufObject:
_insertToFeatureStoreWithJSONString:interactionIdentifier:streamIdentifier:
getWithStreamId:
initWithJsonStr:interactionId:dataVersion:
insert:error:
@24@0:8^{_NSZone=}16
@24@0:8@16
B24@0:8@16
Q16@0:8
@16@0:8
v16@0:8
@"NSUUID"
@"NSString"
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B16@0:8
B24@0:8#16
B24@0:8:16
Vv16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
@"UPResult"24@0:8@"UPContextualizerInput"16
@32@0:8d16@24
d16@0:8
@"UPUsoSerializer"
@24@0:8d16
@40@0:8@16{_NSRange=QQ}24
{_NSRange=QQ}16@0:8
{_NSRange="location"Q"length"Q}
@48@0:8{_NSRange=QQ}16@32^{__DDResult=}40
@56@0:8{_NSRange=QQ}16@32^{__DDResult=}40@48
^{__DDResult=}16@0:8
^{__DDResult=}
@"USOSerializedGraph"
@72@0:8@16@24@32@40@48@56^@64
@64@0:8@16@24@32@40@48@56
@32@0:8@16@24
@56@0:8@16@24@32@40@48
@"NSURL"
@32@0:8@16^@24
@40@0:8@16@24^@32
@48@0:8@16@24@32^@40
@"UPParserModel"
@"NSSet"
@"UPCalibration"
@"UPDialogActConverter"
@"UPContextualizer"
@48@0:8@16@24@32@40
@44@0:8r^v16f24r^v28@36
{UPInferenceResult={UPGenericTensor={vector<unsigned long, std::allocator<unsigned long>>=^Q^Q{__compressed_pair<unsigned long *, std::allocator<unsigned long>>=^Q}}{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}}{UPGenericTensor={vector<unsigned long, std::allocator<unsigned long>>=^Q^Q{__compressed_pair<unsigned long *, std::allocator<unsigned long>>=^Q}}{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}}{UPGenericTensor={vector<unsigned long, std::allocator<unsigned long>>=^Q^Q{__compressed_pair<unsigned long *, std::allocator<unsigned long>>=^Q}}{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}}}120@0:8{UPGenericTensor={vector<unsigned long, std::allocator<unsigned long>>=^Q^Q{__compressed_pair<unsigned long *, std::allocator<unsigned long>>=^Q}}{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}}16{UPGenericTensor={vector<unsigned long, std::allocator<unsigned long>>=^Q^Q{__compressed_pair<unsigned long *, std::allocator<unsigned long>>=^Q}}{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}}64@112
@48@0:8r^v16@24r^v32^v40
@48@0:8r^v16r^v24r^v32^v40
v20@0:8B16
@"UPModelIdentifier"
@"UPSystemConfiguration"
@"UPLoadedModelConfiguration"
@48@0:8@16@24@?32^@40
@?16@0:8
{unique_ptr<const sirinluinternalitfm::ITFMParserRequest, std::default_delete<const sirinluinternalitfm::ITFMParserRequest>>={__compressed_pair<const sirinluinternalitfm::ITFMParserRequest *, std::default_delete<const sirinluinternalitfm::ITFMParserRequest>>=^{ITFMParserRequest}}}24@0:8@16
@48@0:8{ITFMParserResponse=^^?{unique_ptr<sirinluexternal::Parser, std::default_delete<sirinluexternal::Parser>>={__compressed_pair<sirinluexternal::Parser *, std::default_delete<sirinluexternal::Parser>>=^{Parser}}}fB{?=b1b1}}16
{unique_ptr<snlp::common::asset_logger::SNLPAssetLogger, std::default_delete<snlp::common::asset_logger::SNLPAssetLogger>>={__compressed_pair<snlp::common::asset_logger::SNLPAssetLogger *, std::default_delete<snlp::common::asset_logger::SNLPAssetLogger>>=^{SNLPAssetLogger}}}16@0:8
{unique_ptr<itfm_inference_orchestrator::orchestration::ITFMOrchestrator, std::default_delete<itfm_inference_orchestrator::orchestration::ITFMOrchestrator>>="__ptr_"{__compressed_pair<itfm_inference_orchestrator::orchestration::ITFMOrchestrator *, std::default_delete<itfm_inference_orchestrator::orchestration::ITFMOrchestrator>>="__value_"^{ITFMOrchestrator}}}
{unique_ptr<snlp::common::asset_logger::SNLPAssetLogger, std::default_delete<snlp::common::asset_logger::SNLPAssetLogger>>="__ptr_"{__compressed_pair<snlp::common::asset_logger::SNLPAssetLogger *, std::default_delete<snlp::common::asset_logger::SNLPAssetLogger>>="__value_"^{SNLPAssetLogger}}}
@"SNLPITFMModelBundle"
@"SNLPITFMModelInfo"
@32@0:8r^v16r^{UsoGraphNode=^^?^{UsoGraph}Q}24
@40@0:8{vector<std::pair<std::reference_wrapper<siri::ontology::UsoGraphNode>, std::reference_wrapper<const siri::ontology::UsoGraphEdge>>, std::allocator<std::pair<std::reference_wrapper<siri::ontology::UsoGraphNode>, std::reference_wrapper<const siri::ontology::UsoGraphEdge>>>>=^v^v{__compressed_pair<std::pair<std::reference_wrapper<siri::ontology::UsoGraphNode>, std::reference_wrapper<const siri::ontology::UsoGraphEdge>> *, std::allocator<std::pair<std::reference_wrapper<siri::ontology::UsoGraphNode>, std::reference_wrapper<const siri::ontology::UsoGraphEdge>>>>=^v}}16
@32@0:8@16r^v24
@40@0:8@16@24@32
v40@0:8@16^v24^{UsoGraphNode=^^?^{UsoGraph}Q}32
v72@0:8@16{_NSRange=QQ}24@40@48^{UsoGraphNode=^^?^{UsoGraph}Q}56^v64
{shared_ptr<siri::ontology::UsoVocabManager>="__ptr_"^{UsoVocabManager}"__cntrl_"^{__shared_weak_count}}
@32@0:8@16d24
@56@0:8@16@24@32@40^@48
@64@0:8@16@24@32@40@48^@56
@72@0:8d16@24@32@40@48@56@64
@"NSObject<SIRINLUUserDialogAct>"
@"NSNumber"
@"NSArray"
@"NSDictionary"
@"UPCalibrationModel"
@"UPPreprocessor"
f16@0:8
v20@0:8f16
@"NSLocale"
@"UPEntityWithValue"
@136@0:8{UPGenericTensor={vector<unsigned long, std::allocator<unsigned long>>=^Q^Q{__compressed_pair<unsigned long *, std::allocator<unsigned long>>=^Q}}{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}}16{UPGenericTensor={vector<unsigned long, std::allocator<unsigned long>>=^Q^Q{__compressed_pair<unsigned long *, std::allocator<unsigned long>>=^Q}}{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}}64{vector<nl_featurization::Token, std::allocator<nl_featurization::Token>>=^{Token}^{Token}{__compressed_pair<nl_featurization::Token *, std::allocator<nl_featurization::Token>>=^{Token}}}112
^v16@0:8
{UPGenericTensor="shape"{vector<unsigned long, std::allocator<unsigned long>>="__begin_"^Q"__end_"^Q"__end_cap_"{__compressed_pair<unsigned long *, std::allocator<unsigned long>>="__value_"^Q}}"data"{vector<float, std::allocator<float>>="__begin_"^f"__end_"^f"__end_cap_"{__compressed_pair<float *, std::allocator<float>>="__value_"^f}}}
{vector<nl_featurization::Token, std::allocator<nl_featurization::Token>>="__begin_"^{Token}"__end_"^{Token}"__end_cap_"{__compressed_pair<nl_featurization::Token *, std::allocator<nl_featurization::Token>>="__value_"^{Token}}}
{vector<uaap::UPDetectedSpan, std::allocator<uaap::UPDetectedSpan>>="__begin_"^{UPDetectedSpan}"__end_"^{UPDetectedSpan}"__end_cap_"{__compressed_pair<uaap::UPDetectedSpan *, std::allocator<uaap::UPDetectedSpan>>="__value_"^{UPDetectedSpan}}}
@44@0:8@16{_NSRange=QQ}24B40
{unique_ptr<nlv4_inference_orchestrator::orchestration::EmbedderOrchestrator, std::default_delete<nlv4_inference_orchestrator::orchestration::EmbedderOrchestrator>>="__ptr_"{__compressed_pair<nlv4_inference_orchestrator::orchestration::EmbedderOrchestrator *, std::default_delete<nlv4_inference_orchestrator::orchestration::EmbedderOrchestrator>>="__value_"^{EmbedderOrchestrator}}}
B40@0:8@16d24@32
@40@0:8@16@24@?32
@80@0:8@16@24@32@40@48@56@64@72
v24@0:8@16
{unique_ptr<global_ner::GlobalNerHandler, std::default_delete<global_ner::GlobalNerHandler>>="__ptr_"{__compressed_pair<global_ner::GlobalNerHandler *, std::default_delete<global_ner::GlobalNerHandler>>="__value_"^{GlobalNerHandler}}}
@"UPPLPostProcessor"
B32@0:8@16^@24
{_NSRange=QQ}32@0:8Q16Q24
{basic_string<char16_t, std::char_traits<char16_t>, std::allocator<char16_t>>={__compressed_pair<std::basic_string<char16_t>::__rep, std::allocator<char16_t>>={__rep=(?={__long=QQ^S}{__short=(?=CS)[11S]}{__raw=[3Q]})}}}24@0:8@16
@24@0:8r^v16
@40@0:8@16@24Q32
Q24@0:8@16
@48@0:8{_NSRange=QQ}16Q32@40
d120@0:8{UPGenericTensor={vector<unsigned long, std::allocator<unsigned long>>=^Q^Q{__compressed_pair<unsigned long *, std::allocator<unsigned long>>=^Q}}{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}}16{UPGenericTensor={vector<unsigned long, std::allocator<unsigned long>>=^Q^Q{__compressed_pair<unsigned long *, std::allocator<unsigned long>>=^Q}}{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}}64@112
@56@0:8@16Q24Q32Q40@48
@32@0:8@16r^{__CFArray=}24
r^{__CFArray=}16@0:8
r^{__CFArray=}
@32@0:8^{__CFArray=}16@24
^{UPDataDetector=q^{__DDScanner}^{__DDScanner}^{__DDScanner}^{__DDScanner}^{__DDScanner}^{__DDScanner}}16@0:8
^{UPDataDetector=q^{__DDScanner}^{__DDScanner}^{__DDScanner}^{__DDScanner}^{__DDScanner}^{__DDScanner}}
@"UPResult"
@"UPQuery"
@"<UPDialogAct>"
@72@0:8@16@24{_NSRange=QQ}32{_NSRange=QQ}48@64
@80@0:8@16@24@32@40@48@56@64^@72
@72@0:8@16@24@32@40@48@56@64
@64@0:8{_NSRange=QQ}16@32@40@48@56
v32@0:8@16@24
^{EspressoModule=^v^v{?=^vi}}16@0:8
^{EspressoModule=^v^v{?=^vi}}
@32@0:8@16Q24
@24@0:8q16
q16@0:8
v32@0:8Q16@?24
@"<SIRINLUSystemDialogAct><NSObject>"
@44@0:8@16@24B32r^{AbstractFeaturizer=^^?}36
r^{AbstractFeaturizer=^^?}
@"UPTokenizer"
@"UPPLTokenization"
@"UPPLEmbeddingTensor"
@56@0:8@16Q24{_NSRange=QQ}32@48
@76@0:8@16Q24{_NSRange=QQ}32@48B56B60B64@68
@24@0:8{unique_ptr<nlv4_inference_orchestrator::orchestration::NLv4InferenceOrchestrator, std::default_delete<nlv4_inference_orchestrator::orchestration::NLv4InferenceOrchestrator>>={__compressed_pair<nlv4_inference_orchestrator::orchestration::NLv4InferenceOrchestrator *, std::default_delete<nlv4_inference_orchestrator::orchestration::NLv4InferenceOrchestrator>>=^{NLv4InferenceOrchestrator}}}16
{unique_ptr<nlv4_inference_orchestrator::orchestration::NLv4InferenceOrchestrator, std::default_delete<nlv4_inference_orchestrator::orchestration::NLv4InferenceOrchestrator>>="__ptr_"{__compressed_pair<nlv4_inference_orchestrator::orchestration::NLv4InferenceOrchestrator *, std::default_delete<nlv4_inference_orchestrator::orchestration::NLv4InferenceOrchestrator>>="__value_"^{NLv4InferenceOrchestrator}}}
@36@0:8@16i24^@28
@24@0:8Q16
@36@0:8Q16i24@28
i16@0:8
@"UPContextualizerStrategyCancel"
@"UPContextualizerStrategyOffer"
@"UPContextualizerStrategyOptions"
@"UPContextualizerStrategyPrompt"
B32@0:8@16@24
B40@0:8@16@24Q32
B40@0:8@16@24@32
Q24@0:8r^i16
    
@(#)PROGRAM:SiriNaturalLanguageParsing  PROJECT:SiriNaturalLanguageParsing-1
Zvvv:Z
NSt3__111__end_stateIcEE
NSt3__120__shared_ptr_pointerIPNS_13__empty_stateIcEENS_10shared_ptrIS2_E27__shared_ptr_default_deleteIS2_S2_EENS_9allocatorIS2_EEEE
NSt3__113__empty_stateIcEE
NSt3__120__l_anchor_multilineIcEE
NSt3__120__r_anchor_multilineIcEE
NSt3__115__word_boundaryIcNS_12regex_traitsIcEEEE
NSt3__111__lookaheadIcNS_12regex_traitsIcEEEE
NSt3__123__match_any_but_newlineIcEE
NSt3__120__match_char_collateIcNS_12regex_traitsIcEEEE
NSt3__118__back_ref_collateIcNS_12regex_traitsIcEEEE
NSt3__128__begin_marked_subexpressionIcEE
NSt3__126__end_marked_subexpressionIcEE
NSt3__16__loopIcEE
NSt3__117__repeat_one_loopIcEE
NSt3__121__empty_non_own_stateIcEE
&3dd
O]UN4siri8ontology12UsoGraphNodeE
N4uaap19DateDurationHandlerE
N4uaap23AbstractDateTimeHandlerE
,>NN
9N4snlp6common14text_uso_graph26UsoGraphTextTreeParseErrorE
N4snlp6common14text_uso_graph21UDATextTreeParseErrorE
N4uaap8UPDDSpanE
N4uaap12UPDDTimeSpanE
N4uaap20UPDDDateTimeBaseSpanE
N4uaap11TimeHandlerE
E^^^^^^^^^K
*$-
false
N8nlohmann6detail12out_of_rangeE
NSt3__117bad_function_callE
N8nlohmann6detail16invalid_iteratorE
N8nlohmann6detail10type_errorE
N8nlohmann6detail11parse_errorE
!N4uaap12UPDDDateSpanE
N4uaap15DateSpanHandlerE
N4uaap11DateHandlerE
E^^^^^^^^^K
*$-
N4snlp6common9exception18SNLPAssetExceptionE
N27itfm_inference_orchestrator13orchestration16ITFMOrchestratorE
false
NSt3__120__shared_ptr_emplaceIN27itfm_inference_orchestrator10vocabulary10VocabularyENS_9allocatorIS3_EEEE
-@4bb
N27snlc_inference_orchestrator13orchestration16SNLCOrchestratorE
Zvvv:Z
9NSt3__120__shared_ptr_emplaceINS_4__fs10filesystem16filesystem_error8_StorageENS_9allocatorIS4_EEEE
vH7B
W4vC
9Y>)F$
raB3G
)c=H
]rHa
O8Mr
bnMG
.wN9
[*QmU
mr"iR
R$N(
>S}W
-sSO\
T%L9
hGT.
B}T}
=@[V
!a9X
X5AHx
%4xY
Z~$|7
+\0I
2a\|
\ysK
|M$D
pH_r
(:W"
s\ax}?
pc2g
@BXV
tC7Ddx
EydV
d66
eax~Z
ekhHD
@iZb
k0V(
k*do^
:V!2m
RJqn
bzo=
$qE}
XqkY
quAt
Jugm
~B v
STv/N
_w&2
xg^Jp5|
yMzw
{zel#|67
P/};
[@JO
nQ:B
9N4snlp6common14text_uso_graph20ExactMatchComparatorE
N4snlp6common14text_uso_graph18UsoGraphComparatorE
N4snlp6common14text_uso_graph16ActionListParserE
N4snlp6common14text_uso_graph14TextTreeParserE
N4uaap25UPDDTimeSpanWithReferenceE
N4uaap28TimeSpanWithReferenceHandlerE
N4siri8ontology17OntologyExceptionE
N4siri8ontology21OntologyBaseExceptionE
N4snlp6common14text_uso_graph22UsoGraphTextTreeParserE
N4siri8ontology17IsNameTypeVisitorINS0_16OntologyNodeNameEEE
N4siri8ontology16NoOpONameVisitorE
N4siri8ontology19OntologyNameVisitorE
N4siri8ontology17IsNameTypeVisitorINS0_16OntologyVerbNameEEE
N4siri8ontology17IsNameTypeVisitorINS0_16OntologyEdgeNameEEE
N4uaap20UPDDTimeDurationSpanE
N4uaap19TimeDurationHandlerE
N4uaap16UPDDDateTimeSpanE
N4uaap15DateTimeHandlerE
N4uaap25UPDDSpecialDatePeriodSpanE
N4uaap20UPDDAbsoluteDateSpanE
N4uaap18UPDDDateOffsetSpanE
E^^^^^^^^^K
*$-
Zvvv:Z
N4snlp6common9exception13SNLPExceptionE
N8nlohmann6detail9exceptionE
false
N4siri8ontology16OntologyUnitNameE
N5boost6detail17sp_counted_impl_pINS_6random23mersenne_twister_engineIjLm32ELm624ELm397ELm31ELj2567483615ELm11ELj4294967295ELm7ELj2636928640ELm15ELj4022730752ELm18ELj1812433253EEEEE
N5boost6detail15sp_counted_baseE
N5boost16exception_detail10clone_implINS0_19error_info_injectorISt13runtime_errorEEEE
N5boost16exception_detail19error_info_injectorISt13runtime_errorEE
N5boost9exceptionE
N5boost16exception_detail10clone_baseE
N5boost16exception_detail10clone_implINS0_19error_info_injectorISt16invalid_argumentEEEE
N5boost16exception_detail19error_info_injectorISt16invalid_argumentEE
NSt3__16__nodeIcEE
NSt3__110shared_ptrINS_13__empty_stateIcEEE27__shared_ptr_default_deleteIS2_S2_EE
NSt3__114default_deleteINS_13__empty_stateIcEEEE
NSt3__116__owns_one_stateIcEE
NSt3__115__has_one_stateIcEE
NSt3__118__match_char_icaseIcNS_12regex_traitsIcEEEE
NSt3__112__match_charIcEE
NSt3__116__back_ref_icaseIcNS_12regex_traitsIcEEEE
NSt3__110__back_refIcEE
NSt3__120__bracket_expressionIcNS_12regex_traitsIcEEEE
NSt3__117__owns_two_statesIcEE
NSt3__111__alternateIcEE
NSt3__111__match_anyIcEE
&3dd
Zvvv:Z
9N27nlv4_inference_orchestrator13span_matching36RelativeThresholdMatchingSpansFilterE
N27nlv4_inference_orchestrator13span_matching19MatchingSpansFilterE
N4uaap15TimeSpanHandlerE
E^^^^^^^^^K
*$-
N27nlv4_inference_orchestrator16inference_engine21BertModelLoadingErrorE
false
Zvvv:Z
N4snlp6common14text_uso_graph19SpacedTextTreeLexerE
N4snlp6common14text_uso_graph13TextTreeLexerE
Zvvv:Z
N4snlp6common14text_uso_graph17UDATextTreeParserE
-@4N13sentencepiece3bpe5ModelE
N13sentencepiece5model8FreeListIZNKS_3bpe5Model12SampleEncodeEN4absl11string_viewEfE10SymbolPairEE
NSt3__110__function6__funcIZNK13sentencepiece3bpe5Model12SampleEncodeEN4absl11string_viewEfE3$_2NS_9allocatorIS7_EEFvS6_PNS_6vectorINS_4pairIS6_iEENS8_ISC_EEEEEEE
NSt3__110__function6__baseIFvN4absl11string_viewEPNS_6vectorINS_4pairIS3_iEENS_9allocatorIS6_EEEEEEE
ZNK13sentencepiece3bpe5Model12SampleEncodeEN4absl11string_viewEfE3$_2
)6N13sentencepiece31SentencePieceText_SentencePieceE
N13sentencepiece17SentencePieceTextE
N13sentencepiece22NBestSentencePieceTextE
2DSeBPECHARUNIGRAMWORD
BYTECONTROLNORMALUNKNOWNUNUSEDUSER_DEFINED
N13sentencepiece11TrainerSpecE
N13sentencepiece14NormalizerSpecE
N13sentencepiece19SelfTestData_SampleE
N13sentencepiece12SelfTestDataE
N13sentencepiece24ModelProto_SentencePieceE
N13sentencepiece10ModelProtoE
NSt3__121__basic_string_commonILb1EEE
N6google8protobuf8internal16InternalMetadata9ContainerINSt3__112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEEEE
N6google8protobuf8internal16InternalMetadata13ContainerBaseE
N13sentencepiece9character5ModelE
$).38=BGLQN13sentencepiece10filesystem17PosixReadableFileE
N13sentencepiece10filesystem12ReadableFileE
N13sentencepiece10filesystem17PosixWritableFileE
N13sentencepiece10filesystem12WritableFileE
-03N13sentencepiece14ModelInterfaceE
N13sentencepiece10normalizer10NormalizerE
N5Darts15DoubleArrayImplIvvivEE
N5Darts7Details9ExceptionE
N13sentencepiece22SentencePieceProcessorE
$1WW
BPHN13sentencepiece7unigram5ModelE
N13sentencepiece7unigram7LatticeE
N13sentencepiece5model8FreeListINS_7unigram7Lattice4NodeEEE
N13sentencepiece5model8FreeListIZNS_7unigram7Lattice5NBestEmE10HypothesisEE
N13sentencepiece4word5ModelE
N6google8protobuf8internal21ArenaMetricsCollectorE
N6google8protobuf14FatalExceptionE
N6google8protobuf7ClosureE
N6google8protobuf8internal16FunctionClosure0E
+8ER_l
$-6?Qclt}
N6google8protobuf8internal15ExtensionFinderE
N6google8protobuf8internal24GeneratedExtensionFinderE
N6google8protobuf8internal12ExtensionSet20LazyMessageExtensionE
N6google8protobuf8internal12ExtensionSet8KeyValueE
N6google8protobuf13RepeatedFieldIiEE
N6google8protobuf13RepeatedFieldIxEE
N6google8protobuf13RepeatedFieldIjEE
N6google8protobuf13RepeatedFieldIyEE
N6google8protobuf13RepeatedFieldIfEE
N6google8protobuf13RepeatedFieldIdEE
N6google8protobuf13RepeatedFieldIbEE
N6google8protobuf16RepeatedPtrFieldINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEEE
N6google8protobuf8internal20RepeatedPtrFieldBaseE
N6google8protobuf16RepeatedPtrFieldINS0_11MessageLiteEEE
NSt3__13mapIiN6google8protobuf8internal12ExtensionSet9ExtensionENS_4lessIiEENS_9allocatorINS_4pairIKiS5_EEEEEE
N6google8protobuf8internal19ImplicitWeakMessageE
N6google8protobuf11MessageLiteE
N6google8protobuf24ZeroCopyCodedInputStreamE
N6google8protobuf2io19ZeroCopyInputStreamE
NSt3__112basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEE
30SentencepieceModelLoadingError
]]]S]U]W]
"600010203040506070809101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899
456789:;<=
 !"#$%&'()*+,-./0123
?456789:;<=
 !"#$%&'()*+,-./0123
ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/
ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_
N6google8protobuf8internal12FieldSkipperE
N6google8protobuf8internal29CodedOutputStreamFieldSkipperE
N6google8protobuf2io20ZeroCopyOutputStreamE
N6google8protobuf2io18CopyingInputStreamE
N6google8protobuf2io16ArrayInputStreamE
N6google8protobuf2io17ArrayOutputStreamE
N6google8protobuf2io18StringOutputStreamE
N6google8protobuf2io25CopyingInputStreamAdaptorE
N6google8protobuf2io26CopyingOutputStreamAdaptorE
N6google8protobuf2io19LimitingInputStreamE
N6google8protobuf2io15FileInputStreamE
N6google8protobuf2io15FileInputStream22CopyingFileInputStreamE
N6google8protobuf2io16FileOutputStreamE
N6google8protobuf2io16FileOutputStream23CopyingFileOutputStreamE
N6google8protobuf2io19CopyingOutputStreamE
N6google8protobuf2io18IstreamInputStreamE
N6google8protobuf2io18IstreamInputStream25CopyingIstreamInputStreamE
N6google8protobuf2io19OstreamOutputStreamE
N6google8protobuf2io19OstreamOutputStream26CopyingOstreamOutputStreamE
N6google8protobuf2io24ConcatenatingInputStreamE
N16nl_featurization14FeaturizerImplE
N16nl_featurization18AbstractFeaturizerE
N10global_ner12post_process20GeographicAreaEntityE
N10global_ner12post_process22PersonalLocationEntityE
N10global_ner12post_process18EmailAddressEntityE
 ,rr
]cjN10global_ner9inference16NerEspressoModelE
N10global_ner9inference13EspressoModelE
N10global_ner12post_process14CurrencyEntityE
N10global_ner12post_process6EntityE
N10global_ner12post_process18BusinessNameEntityE
N10global_ner12post_process13AppNameEntityE
N10global_ner12post_process21MeasurementUnitEntityE
N10global_ner12post_process26MeasurementComponentEntityE
N10global_ner12post_process17PhoneNumberEntityE
N10global_ner12post_process17OtherPersonEntityE
N10global_ner12post_process12NumberEntityE
N10global_ner12post_process17MeasurementEntityE
(|
(|
L\
$`
$`
$`
$`
$`
$`
$`
$`
TreeManipulation_OneShotReplyRemodeller
UserAccepted
UserStatedTask
SiriNL
SNLPFeatureStoreEnabled
[insights-snlp-snlc]: 
[insights-snlp-nlv4]: 
[insights-snlp-uaap]: 
component_name
old_prediction
hidden
memory
encodings
num_of_utterance_tokens
attention_index
out_predictions
out_new_hidden
out_new_memory
out_new_attention_index
-[UPContextualizerStrategyPrompt resultUsingContextualizerInput:]
UPContextualizerStrategyPrompt.m
[dialogAct isKindOfClass:[UPDialogActPrompt class]]
config.json
version.yaml
^VERSION: (\d+)\.(\d+)\.(\d+)
Version file not found at path: 
Version file has no parseable version key: 
%02x
.DS_Store
bolt_task_id
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
-[UPContextualizerStrategyOffer resultUsingContextualizerInput:]
UPContextualizerStrategyOffer.m
[contextualizerInput.dialogAct isKindOfClass:[UPDialogActOffer class]]
label
tokenIndicesIndex
[%lu, %lu)
Token overflow; received 
 tokens, expected 
 or fewer tokens.
NLv4
SNLC
UaaP
PLUM
UNKNOWN
<UNDEFINED_COMPONENT>
unordered_map::at: key not found
SNLPITFMErrorDomain
Missing resource: %@
Check that resource is available: %@
[UNK]
[PAD]
[CLS]
[SEP]
Could not open vocabulary data file: 
tokenText argument is empty
Encountered unknown token text and the vocabulary hasno special unknown token
Encountered unknown token ID
[NO_SDAS]
[NO_LEGACY_NL_CONTEXT_LABEL]
DICTATION_PROMPT=
STRICT_PROMPT=
PREVIOUS_NLV3_DOMAIN=
TRUE
FALSE
shape = 
 data = 
Searching for span with UTF-16 indices (
common_Date
common_Timer
Found matching span with graph:
) vs (
Found a matching insertable span 
Found a new max score, 
, for a non-matching insertable span 
Found a common_Time span with a Jaccard score of 
, overwriting the common_Date span with a Jaccard score of 
UPDialogActPrompt[intent: %@, entityType: %@, entityName: %@, reference: %@]
span_indices
token_embeddings
intent_softmax
app_label_softmax
bio_labels_softmax
group_labels_softmax
Espresso context is nil.
Espresso plan is nil.
Could not create espresso plan.
Failed to build espresso plan.
Failed to execute espresso plan.
Failed to clean up espresso plan.
Failed to reshape espresso blob.
Failed to bind buffer to input 
Failed to bind buffer to output 
group_name_transform
smsGroupName
personFullName
TreeManipulation_GroupNameTransform
Failed to parse 
^ *"(.*)"
^ *(\d+)
^ *([a-zA-Z0-9:_]+)
^ *:([a-zA-Z0-9:_]+)
^ *\n( *)
^ */ *([a-zA-Z0-9:_]+)
^ *\[(\d+):(\d+)\]
com.apple.uaapcustomluframework
{unique_ptr<itfm_inference_orchestrator::orchestration::ITFMOrchestrator, std::default_delete<itfm_inference_orchestrator::orchestration::ITFMOrchestrator>>={__compressed_pair<itfm_inference_orchestrator::orchestration::ITFMOrchestrator *, std::default_delete<itfm_inference_orchestrator::orchestration::ITFMOrchestrator>>=^{ITFMOrchestrator}}}32@?0@"SNLPITFMModelBundle"8@"SNLPITFMModelInfo"16^@24
%@ Asset Error when creating the %@ (ITFM) inference orchestrator: %s
Hit SNLP exception while calling ITFMOrchestrator::handle for request (high=%llu, low=%llu): %s
ERROR: Could not find the config file 
INFO: The parameter 
 is null.  This is currently expected behaviour.
WARNING: Could not parse the config parameter 
[json.exception.
invalid BOM; must be 0xEF 0xBB 0xBF if given
invalid literal
invalid comment; missing closing '*/'
invalid comment; expecting '/' or '*' after '/'
invalid string: missing closing quote
invalid string: '\u' must be followed by 4 hex digits
invalid string: surrogate U+D800..U+DBFF must be followed by U+DC00..U+DFFF
invalid string: surrogate U+DC00..U+DFFF must follow U+D800..U+DBFF
invalid string: forbidden character after backslash
invalid string: control character U+0000 (NUL) must be escaped to \u0000
invalid string: control character U+0001 (SOH) must be escaped to \u0001
invalid string: control character U+0002 (STX) must be escaped to \u0002
invalid string: control character U+0003 (ETX) must be escaped to \u0003
invalid string: control character U+0004 (EOT) must be escaped to \u0004
invalid string: control character U+0005 (ENQ) must be escaped to \u0005
invalid string: control character U+0006 (ACK) must be escaped to \u0006
invalid string: control character U+0007 (BEL) must be escaped to \u0007
invalid string: control character U+0008 (BS) must be escaped to \u0008 or \b
invalid string: control character U+0009 (HT) must be escaped to \u0009 or \t
invalid string: control character U+000A (LF) must be escaped to \u000A or \n
invalid string: control character U+000B (VT) must be escaped to \u000B
invalid string: control character U+000C (FF) must be escaped to \u000C or \f
invalid string: control character U+000D (CR) must be escaped to \u000D or \r
invalid string: control character U+000E (SO) must be escaped to \u000E
invalid string: control character U+000F (SI) must be escaped to \u000F
invalid string: control character U+0010 (DLE) must be escaped to \u0010
invalid string: control character U+0011 (DC1) must be escaped to \u0011
invalid string: control character U+0012 (DC2) must be escaped to \u0012
invalid string: control character U+0013 (DC3) must be escaped to \u0013
invalid string: control character U+0014 (DC4) must be escaped to \u0014
invalid string: control character U+0015 (NAK) must be escaped to \u0015
invalid string: control character U+0016 (SYN) must be escaped to \u0016
invalid string: control character U+0017 (ETB) must be escaped to \u0017
invalid string: control character U+0018 (CAN) must be escaped to \u0018
invalid string: control character U+0019 (EM) must be escaped to \u0019
invalid string: control character U+001A (SUB) must be escaped to \u001A
invalid string: control character U+001B (ESC) must be escaped to \u001B
invalid string: control character U+001C (FS) must be escaped to \u001C
invalid string: control character U+001D (GS) must be escaped to \u001D
invalid string: control character U+001E (RS) must be escaped to \u001E
invalid string: control character U+001F (US) must be escaped to \u001F
invalid string: ill-formed UTF-8 byte
invalid number; expected digit after '-'
invalid number; expected digit after '.'
invalid number; expected '+', '-', or digit after exponent
invalid number; expected digit after exponent sign
value
object key
object separator
number overflow parsing '
array
object
excessive object size: 
cannot get value
invalid_iterator
iterator does not fit current value
iterator out of range
cannot use erase() with 
type_error
null
string
boolean
binary
discarded
number
excessive array size: 
out_of_range
<U+%.4X>
parse_error
parse error
 at line 
, column 
syntax error 
while parsing 
; last read: '
unexpected 
; expected 
<uninitialized>
true literal
false literal
null literal
string literal
number literal
<parse error>
end of input
'[', '{', or a literal
unknown token
cannot compare iterators of different containers
cannot use key() for non-object iterators
type must be number, but is 
type must be boolean, but is 
type must be string, but is 
The month of year value should range from 1 to 12
semanticValue
unknownCustomEntity
unknownCustomVerb
DataDetectorService
The ITFM asset version (
) is incompatible with inference runtime (compatible versions 
ITFM Orchestrator failed with incompatible major version
Request does not contain a tokenised utterance
Request does not contain a token chain
Request does not contain embeddings
Request embeddings num tokens (
) does not match actual num tokens (
Request embeddings (
) exceeds maximum (
Received null input parser request
SystemGaveOptions
SystemOffered
executed_task
salient_entity
active_task
sdas
executed_tasks
salient_entities
active_tasks
_type=
_full_path=
_verb_entity=
_verb=
_below_verb=
_are_present
_are_absent
contact_type_split
contactType
emailType
TreeManipulation_ContactTypeSplit
nullptr
string_view::substr
cancel
notForMe
selectOrdinal
ordinal
placeholderVerb
((\w+)::common_(\w+)(\.)?(\w+))
::common
SystemPrompted
SystemOffered.offered_act.
SystemGaveOptions.option.
SystemInformed.entity
SystemReportedSuccess
SystemReportedFailure
_verb_entity
SystemOffered.offered_act.UserStatedTask
SystemOffered.offered_act.UserWantedToProceed
.primitive_String
UserAcknowledged
UserCancelled
UserRejected
UserWantedToPause
UserWantedToProceed
UserWantedToRepeat
SystemInformed
contact_address_downcast
emailAddress
phoneNumber
TreeManipulation_ContactAddressDowncaster
map::at:  key not found
min_max_labeller
minimumMaximum
floatSettingState
minimum
maximum
TreeManipulation_MinimumMaximumLabeller
de_DE
en_AU
en_CA
en_GB
en_IN
en_US
fr_FR
Error parsing JSON grammar: row.IsObject() == false [for key: 
resolution-table
 entry
semantic-value
Error parsing JSON grammar: parsedSemanticValue != row.MemberEnd() && parsedSemanticValue->value.IsString() == false [for key: 
synonyms
Error parsing JSON grammar: parsedSynonyms != row.MemberEnd() && parsedSynonyms->value.IsArray() == false [for key: 
Error parsing JSON grammar: parsedSynonym.IsString() == false [for key: 
type
Error parsing JSON grammar: parsedValueType->value.IsString() == false [for key: 
enum-choices
Error parsing JSON grammar: parsedEnumChoices->value.IsArray() == false [for key: 
open-list-choices
Error parsing JSON grammar: parsedOpenListChoices->value.IsArray() == false [for key: 
Error parsing JSON grammar: parsedResolutionTable->value.IsArray() == false [for key: 
left-label
Error parsing JSON grammar: leftLabel != jsonRule.MemberEnd() && leftLabel->value.IsString() == false [for key: 
value-constraints
Error parsing JSON grammar: parsedValueConstraints->value.IsObject() == false [for key: 
right-labels
Error parsing JSON grammar: parsedRightLabels != jsonRule.MemberEnd() && parsedRightLabels->value.IsArray() == false [for key: 
Error parsing JSON grammar: rightLabelObject.IsObject() == false [for key: 
name
Error parsing JSON grammar: parsedName != rightLabelObject.MemberEnd() && parsedName->value.IsString() == false [for key: 
repeated
Error parsing JSON grammar: parsedRepeatedFlag != rightLabelObject.MemberEnd() && parsedRepeatedFlag->value.IsBool() == false [for key: 
Could not open grammar file for reading: 
Grammar file is in error state after reading: 
Label does not exist
Error parsing JSON grammar: jsonGrammar.IsObject() == false [for key: 
(root)
rules
Error parsing JSON grammar: parsedRules != jsonGrammar.MemberEnd() && parsedRules->value.IsArray() == false [for key: 
Error parsing JSON grammar: enumChoice.IsString() == false [for key: 
Error parsing JSON grammar: openListChoice.IsString() == false [for key: 
allocator<const T>::allocate(size_t n) 'n' exceeds maximum supported size
Error parsing JSON grammar: parsedRule.IsObject() == false [for key: 
Expected:
Actual:
Badly-formed UDA
DelegatedUserDialogAct
Expected a UDA of type 
 but got a 
source_tokens_embeddings
matched_spans
context
source_mask
class_probabilities
SNLPServerNLClassifierErrorDomain
SNLC/SNLC.mlmodelc/model.espresso.net
SNLC/spans_pad.txt
SNLC/context_pad.txt
An error occured reading SNLC model bundle at: %@
Check that the path contains a valid model bundle: %@
node=
edge=
stringValue=
integerValue=
indentation=
alias=
textAlignment=
after
approx
before
earlier
every
last
lastlast
later
middle
next
nextnext
potentialEvery
same
slidinglast
this
upcoming
week
weekend
weekday
month
quarter
year
summer
winter
autumn
spring
semester
season
businessday
afternoon
bedtime
breakfast
brunch
dinner
evening
happyhour
lunch
midnight
morning
night
noon
SNLPPommesServerClassifierErrorDomain
PSC/PSC.mlmodelc/model.espresso.net
PSC/spans_pad.txt
PSC/context_pad.txt
confidence_threshold
An error occured reading PSC model bundle at: %@
ROOT
value=
intent=
[next]
[startPayload]
[leaf]
[endPayload]
[newGroup]
task
UserStarted
UserContinued
UserDisambiguated
UserResponded
directLeafNodes
Could not create analyzer: locale not supported
locale %@ not supported
B24@?0@"UPToken"8@"NSDictionary"16
-[UPContextualizerStrategyOptions resultUsingContextualizerInput:]
UPContextualizerStrategyOptions.m
[contextualizerInput.dialogAct isKindOfClass:[UPDialogActOptions class]]
batch_size
max_num_utterance_embeddings
max_num_context_tokens
max_num_spans_tokens
utterance_tokens_embedder_emb_dim
common_
Node 
 not found in ontology.
Verb 
Root
Last node on the parser stack is null, but it shouldn't
Test alignment parsed but last node on parser stack is not a UsoEntityNode
Empty edge found while attaching: 
Edge not found in ontology: 
Could not attach child 
 to parent 
 with edge 
Check
Control
Convert
Create
Delete
Entity
NoVerb
PlaceholderVerb
RecipientsEventTrigger
RecipientsHiddenPeople
Reference
ReferenceControl
ReferenceDateTimeRangeTrigger
ReferenceDurationTrigger
ReferenceMeasurementTrigger
ReferenceNumberTrigger
ReferencePaymentSortKey
ReferencePhotoCollection
ReferencePhotoCollectionFilter
ReferencePhotoFilter
ReferencePhotoMemoryFilter
ReferencePhotoTag
ReferenceProfile
ReferenceSelect
ReferenceSlideshowFilter
ReferenceStringTrigger
ReferenceTarget
ReferenceTargetSelect
ReferenceTrigger
ReferenceVideoFilter
Request
StockSummarise
Summarise
Target
Update
Token indices out of range: [
Unknown LabelScheme observed
Could not deserialise espresso context.
Could not set up espresso network.
not_found
ERROR: Could not find network configuration: 
Note that only parameters of unsigned integer type are currently expected by NLv4Parser.  This issue will likely cause NLv4 parser inference to fail.
UNDEFINED_COMPONENT
{UPToken string: %@ ; range: %@ ; isWhitespace: %@}
proto message is missing one of value, begin or end
Failed to convert CFString to C++ string
hello
world
hello world
DateTime
BeginTime
EndTime
Hours
Meridian
Minutes
MinutesBefore
Seconds
SpecialTimePeriod
Time
TimeDuration
TimeOffset
TimeSpan
TimeSpanReference
TimeSpanWithReference
AbsoluteDate
Date
DateDuration
DateOffset
DateSpan
DateTimeQualifier
DayNumber
DayOfNextWeek
DayOfWeek
MonthNumber
OccurrenceCount
RelativeDay
RelativeDayOfWeek
SpecialDatePeriod
SpecialDatePeriodUnit
SpecialDay
Identifier
YearNumber
B16@?0@"UPResultCandidate"8
+[UPContextualizerUtilities buildPayloadResultFromQuery:modelIdentifier:intent:entityName:serializer:]
UPContextualizerUtilities.m
utterance != nil
send::common_Message
target
common_Message
stringContent
SDA_MessagePayload_Prompt_Override
LegacyNLContext_DictationPrompt_Presence_Override
Error opening file: 
Number of element should be 2 in line 
MAX_WORD_LENGTH
MAX_UTTERANCE_LENGTH
USE_CHARS
USE_CHAR_LSTM
TestSpan
Could not open file path
FilePath
Given UTF-16 offset is not a Unicode scalar (code point) boundary: 
 000000000000
Input string is not a valid UTF-8 sequence! UTF-8 offset: 
Given UTF-16 offset exceeds the input string: 
relative_set_number_verb
setNumber
common_Setting
TreeManipulation_SetNumber_VerbReplacement
increaseBy
decreaseBy
unknown/
Could not convert
Component: 
Version: SNLPVersionInfo[train=
, majorVersion=
, minorVersion=
Bolt task ID: 
Bolt task ID: <missing>
No assets provided
Combined Hash: 
asset could not be read
chunkPredictions
nerScore
alternativeIndex
protobuf message is missing a start/end index
{UPSpan range: %@ ; type: %lu ; category: %@}
context_vocab.txt
multicardinal_vocab.txt
decoder.mlmodelc/model.espresso.net
encoder.mlmodelc/model.espresso.net
spans_vocab.txt
trg_vocab.txt
span_label_mapping.txt
SystemPrompted_Send_MessageContent
SDA_Placeholder_Verb_Replacement
The NLv4 asset version (
NLv4InferenceOrchestrator setup is broken; erroneous assets were provided
NLv4 request is null
PlaceholderVerb_placeholderVerb
ja_JP
common_Message.Target_send
NLv4 request missing request ID
NLv4 request missing valid embeddings
NLv4 request missing valid tokens
NLv4 request missing valid token chain locale
NLv4 request embeddings num tokens (
zh_CN
SystemPrompted.task.send::common_Message.target.common_Message.stringContent
spans_pad_symbol_index
context_pad_symbol_index
start_symbol_index
end_symbol_index
common_DateTime.time
common_Message.recipients
common_PhoneCall.recipients
common_Timer.attributes
common_Message.sender
common_Message.attachments
common_RecurringDateTime.recurrenceDateTimes
common_Message.usoQuantifier
common_Message.attributes
common_Message.participants
common_PhoneCall.attributes
modified_TranslationSourceLocale
common_Translation
sourceString
common_LocalisedString
locale
common_Locale
modified_TranslationPayload
stringValue
modified_TranslationReferenceType
usoReferenceType
modified_TranslationTargetLocale
targetString
modified_GeographicAreaName
geographicArea
common_GeographicArea
modified_GeographicAreaType
areaType
User dialog act node has multiple children.
/dev/urandom
sha1 too many bytes
void boost::uuids::detail::sha1::process_byte(unsigned char)
/System/Volumes/Data/SWE/iOS/BuildRoots/BuildRoot949/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator15.4.Internal.sdk/usr/local/include/boost/uuid/sha1.hpp
Not enough elements in call to seed.
UPEntityWithValue[entityType: %@, entityName: %@, entityValue:%@]
UPDialogActOffer[intent: %@, entityWithValue: %@]
noMatcher
DataDetector
PlumMatcher
UserVocabMatcher
SingleTrieMatcher
ContextMatcher
OvertonMatcher
MRRDetector
MRRMatcher
RegexSpanMatcher
personRelationship
phoneType
values
numTokens
numLayers
embeddingDim
embedderId
bert/embeddings/requires_subword_embeddings
feature_pooling_mask
max_seq_length
input_ids
input_mask
bert/feature_extraction_output
Could not create scanner from cache file: "
".  
utterance_tokens_embeddings
padding_mask
span_tokens
position_ids
out_init_decoder_hidden
out_encodings
addresses_
.cache
date_time_
addresses.cache
date_time.cache
flights.cache
currencies.cache
numbers.cache
phone_mobile.cache
coarseEntityType
fineGrainedEntityType
charIndicesRange
chunkScore
[CLS_SPAN]
[SEP_SPAN]
[NO_SPAN]
model_info.plist
info.plist
intent.vocab.txt
bio_labels.vocab.txt
span.vocab.txt
grammar.json
model.mlmodelc
calibration_model.mlmodelc
No USO
mention
entityType
score
usoGraph
%@%@%@
Entity type %@ should contain exactly one %@ and the string before %@ should be equal to %@
PostProcessor
dateTime
referenceTime
targetTime
tokens
originalUtterance
normalisedUtterance
app_bundle
neu_inputs
model.espresso.net
Subword embeddings enabled: 
bpe.model
hidden_size
BERT:
      pre-process 
      forward: 
      aggregate & post-process: 
      post-process: 
Vocabulary special tokens not properly defined
Query's token chain is nil
Query's embedding tensor is nil
Token with value "%@" doesn't have a nonwhitespace index
{UPQuery
  utterance: %@
  tokens:
  embeddingsByToken:
  spans:
UPDialogActOptions[intent: %@, entityType: %@, entityName: %@, entityValues: %@]
PLUM_%@
v24@?0@"UPSpan"8^B16
No embeddings are associated with token "%@"
Span label shape incorrect.
Given coordinates do not match tensor shape
Coordinates exceed bounds of tensor
v8@?0
General
Common
UPDataDetectors
SiriNaturalLanguageParsingSignPosts
com.apple.sirinaturallanguageparsing
data_detectors
tokenisedUtterance
embeddings
matchedSpans
text
phone-number
common_Time
common_Time12HourClock
common_Time24HourClock
date
Attempting to re-insert span entity to model graph, beneath 
time
common_Integer
usoEntityInsertionPoint
token
tokenId
graphemeClusters
isSpecialToken
isWordPiece
isOverflow
encodedLabels
SNLPNaturalLanguageParserErrorDomain
NLv4 Asset Error when creating the C++ NLv4 orchestrator: %s
Hit SNLP exception while constructing C++ orchestrator with asset directory %@: %s
Hit SNLP exception while calling NLv4InferenceOrchestrator::pbhandle for request (high=%llu, low=%llu): %s
NLv4InferenceOrchestrator::pbhandle returned nullptrfor request (high=%llu, low=%llu)
embeddingDim field missing from protobuf message
tokenIndex %u is out-of-bounds for an embedding tensor with %llu tokens
Protobuf message contains only %lu values but UPEmbedding for tokenIndex %u is being created (embeddingDim=%llu)
Protobuf message contains %lu embedding values which is not a multiple of %llu embedding dimensions
{UPEmbedding: dimension %lu}
UNKNOWN-MODEL-TYPE
alternativePredictions
NLv4SpanResponseAsJSON
NLv4ContextResponseAsJSON
NLv4AssetVersionAsJSON
NLv4ExecutedHandcraftedRulesAsJSON
%@-ITFMSpanResponseAsJSON
%@-ITFMContextResponseAsJSON
%@-ITFMAssetVersionAsJSON
%@-ITFMExecutedHandcraftedRulesAsJSON
TreeNode[
label:'
value:'
parentArgument:'
UTF-8 code unit indices:[
UTF-16 code unit indices:[
Unicode code point indices:[
Expected a node to start at: 
Expected an edge to start at: 
Regex search failed: 
^(accepted|acknowledged|cancelled|delegated|rejected|user_stated_task|wanted_to_pause|wanted_to_proceed|wanted_to_repeat|UserAccepted|UserAcknowledged|UserCancelled|DelegatedUserDialogAct|UserRejected|UserStatedTask|UserWantedToPause|UserWantedToProceed|UserWantedToRepeat)
UDA previously defined as 
 but is being redefined as 
Expecting a valid UDA name but got 
User dialog act not yet specified
UDA not yet specified
accepted
acknowledged
cancelled
UserCanceled
delegated
DelegatedDialogAct
rejected
user_stated_task
wanted_to_pause
wanted_to_proceed
wanted_to_repeat
unknown UDA 
person_name_split
TreeManipulation_PersonNameSplit
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing-3104.68.1/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/src/bpe_model.cc
(index) >= (0)
(index) < (static_cast<int>(symbols.size()))
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing-3104.68.1/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/src/builtin_pb/sentencepiece.pb.cc
sentencepiece.SentencePieceText.SentencePiece
sentencepiece.SentencePieceText
sentencepiece.NBestSentencePieceText
<unk>
</s>
<pad>
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing-3104.68.1/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/src/builtin_pb/sentencepiece_model.pb.cc
sentencepiece.TrainerSpec
sentencepiece.NormalizerSpec
sentencepiece.SelfTestData.Sample
sentencepiece.SelfTestData
sentencepiece.ModelProto.SentencePiece
sentencepiece.ModelProto
size_t to int conversion
Program terminated with an unrecoverable error.
Cancelled
Unknown
Invalid argument
Deadline exceeded
Not found
Already exists
Permission denied
Unauthenticated
Failed precondition
Aborted
Out of range
Unimplemented
Internal
Unavailable
Data loss
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing-3104.68.1/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/src/filesystem.cc
ReadAll is not supported for stdin.
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing-3104.68.1/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/src/model_factory.cc
Unknown model_type: 
piece must not be empty.
 is already defined.
unk is already defined.
byte piece 
 is found although `byte_fallback` is false.
 is invalid.
unk is not defined.
there are not 256 byte pieces although `byte_fallback` is true.
<0x%02X>
SiriNaturalLanguageParsing/External_Libraries/sentencepiece/src/model_interface.h
Not implemented.
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing-3104.68.1/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/src/normalizer.cc
precompiled_charsmap is empty. use identity normalization.
(length) >= (0)
(norm_to_orig->size()) == (normalized->size() + 1)
Blob for normalization rule is broken.
Trie data size exceeds the input blob size.
(0) == (trie_->build(key.size(), const_cast<char **>(&key[0]), nullptr, nullptr))
SiriNaturalLanguageParsing/External_Libraries/sentencepiece/src/util.h
'result' Must be non NULL
SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/darts_clone/darts.h:703: exception: failed to resize pool: std::bad_alloc
SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/darts_clone/darts.h:1141: exception: failed to insert key: negative value
SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/darts_clone/darts.h:1143: exception: failed to insert key: zero-length key
SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/darts_clone/darts.h:1157: exception: failed to insert key: invalid null character
SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/darts_clone/darts.h:1162: exception: failed to insert key: wrong key order
SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/darts_clone/darts.h:842: exception: failed to build rank index: std::bad_alloc
SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/darts_clone/darts.h:1380: exception: failed to modify unit: too large offset
SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/darts_clone/darts.h:1726: exception: failed to build double-array: invalid null character
SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/darts_clone/darts.h:1728: exception: failed to build double-array: negative value
SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/darts_clone/darts.h:1743: exception: failed to build double-array: wrong key order
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing-3104.68.1/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/src/sentencepiece_processor.cc
_status.ok()
model_proto->ParseFromArray(serialized.data(), serialized.size())
LOG(
INFO
 samples did not pass the test.
Self-test failures. See LOG(INFO).
model_
Model is not initialized.
normalizer_
Normalizer is not initialized.
type == TrainerSpec::UNIGRAM || type == TrainerSpec::BPE
Vocabulary constraint is only enabled in subword units.
(v.size()) >= (1)
!v[0].empty()
absl::SimpleAtoi(v[1], &freq)
Could not parse the frequency
pieces
output container is null
detokenized
!w.empty()
Empty piece is not allowed.
(begin) < (norm_to_orig.size())
(end) < (norm_to_orig.size())
(orig_begin) <= (input.size())
(orig_end) <= (input.size())
(orig_begin) <= (orig_end)
(consumed) == (normalized.size())
all normalized characters are not consumed.
output proto is null
nbest_spt
model_->IsNBestEncodeAvailable()
NBestEncode is not available for the current model.
!nbests.empty()
NBestEncode returns empty result.
(nbest_size) <= (512)
nbest_size must be nbest_size <= 512
model_->IsSampleEncodeAvailable()
SampleEncode is not available for the current model.
Invalid id: 
ERROR
Returns default value 
unknown extra_option type.
reverse
it != extra_option_map.end()
option "
" is not available.
!IsUnknown(PieceToId(absl::string_view(model_->bos_piece().data())))
id for `
` is not defined.
!IsUnknown(PieceToId(absl::string_view(model_->eos_piece().data())))
model file path should not be empty.
input->ReadAll(&serialized)
output->Write(model_proto.SerializeAsString())
(0) <= (byte)
(consumed) == (1)
(token_index_begin + offset) == (token_index_end)
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing-3104.68.1/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/src/unigram_model.cc
Failed to find the best path in Viterbi.
WARNING
nbest_size >= 1. Returns empty result.
Too big agenda. shrinking
(num_nodes) < (trie_results.size())
no pieces are loaded.
cannot build double-array.
no entry is found in the trie.
Two sentence piece sequences are not equivalent! Left: 
, Score: 
. Right: 
 Error #
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing-3104.68.1/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/protobuf-lite/arena.cc
CHECK failed: (min_bytes) <= (std::numeric_limits<size_t>::max() - kBlockHeaderSize): 
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing-3104.68.1/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/protobuf-lite/coded_stream.cc
A protocol message was rejected because it was too big (more than 
 bytes).  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in third_party/protobuf/src/google/protobuf/io/coded_stream.h.
CHECK failed: (buffer_size) >= (0): 
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing-3104.68.1/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/protobuf-lite/common.cc
This program requires version 
 of the Protocol Buffer runtime library, but the installed version is 
.  Please update your library.  If you compiled the program yourself, make sure that your headers are from the same version of Protocol Buffers as your link-time library.  (Version verification failed in "
This program was compiled against version 
 of the Protocol Buffer runtime library, which is not compatible with the installed version (
).  Contact the program author for an update.  If you compiled the program yourself, make sure that your headers are from the same version of Protocol Buffers as your link-time library.  (Version verification failed in "
%d.%d.%d
FATAL
[libprotobuf %s %s:%d] %s
%lld
%llu
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing-3104.68.1/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/protobuf-lite/extension_set.cc
CHECK failed: (type) != (WireFormatLite::TYPE_ENUM): 
CHECK failed: (type) != (WireFormatLite::TYPE_MESSAGE): 
CHECK failed: (type) != (WireFormatLite::TYPE_GROUP): 
CHECK failed: (type) == (WireFormatLite::TYPE_ENUM): 
CHECK failed: type == WireFormatLite::TYPE_MESSAGE || type == WireFormatLite::TYPE_GROUP: 
Don't lookup extension types if they aren't present (1). 
Don't lookup extension types if they aren't present (2). 
CHECK failed: extension != NULL: 
Index out-of-bounds (field is empty).
Extension not found.
Non-primitive types can't be packed.
Can't get here.
Invalid message set extension.
Multiple extension registrations for type "
", field number 
can't reach here.
SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/protobuf-lite/google/protobuf/extension_set_inl.h
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing-3104.68.1/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/protobuf-lite/generated_message_util.cc
Not implemented field number 
CHECK failed: (scc->visit_status.load(std::memory_order_relaxed)) == (SCCInfoBase::kRunning): 
 with type 
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing-3104.68.1/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/protobuf-lite/int128.cc
Division or mod by zero: dividend.hi=
, lo=
(cannot determine missing fields for lite message)
MessageLite at 0x
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing-3104.68.1/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/protobuf-lite/message_lite.cc
parse
 exceeded maximum protobuf size of 2GB: 
Can't 
 message of type "
" because it is missing required fields: 
CHECK failed: (byte_size_before_serialization) == (byte_size_after_serialization): 
 was modified concurrently during serialization.
CHECK failed: (bytes_produced_by_serialization) == (byte_size_before_serialization): 
Byte size calculation and serialization were inconsistent.  This may indicate a bug in protocol buffers or it may be caused by concurrent modification of 
This shouldn't be called if all the sizes are equal.
parsing
SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/protobuf-lite/google/protobuf/parse_context.h
Can't happen
SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/protobuf-lite/google/protobuf/repeated_field.h
CHECK failed: (index) >= (0): 
CHECK failed: (index) < (current_size_): 
CANCELLED
INVALID_ARGUMENT
DEADLINE_EXCEEDED
NOT_FOUND
ALREADY_EXISTS
PERMISSION_DENIED
UNAUTHENTICATED
RESOURCE_EXHAUSTED
FAILED_PRECONDITION
ABORTED
OUT_OF_RANGE
UNIMPLEMENTED
INTERNAL
UNAVAILABLE
DATA_LOSS
Subword model cannot be loaded from: 
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing-3104.68.1/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/protobuf-lite/stringpiece.cc
size too big: 
 details: 
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing-3104.68.1/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/protobuf-lite/stringprintf.cc
CHECK failed: (v.size()) <= (kStringPrintfVectorMaxArgs): 
StringPrintfVector currently only supports up to 
 arguments. 
Feel free to add support for more if you need it.
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing-3104.68.1/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/protobuf-lite/strutil.cc
CHECK failed: dest: 
\x%02x
\%03o
CHECK failed: i >= 0: 
FastHexToBuffer() wants non-negative integers, not 
%.*g
CHECK failed: value != nullptr: 
nullptr output boolean given.
true
false
0123456789abcdef
CHECK failed: s != nullptr: 
This can't happen; base64 decoder state = 
Logic problem? szsrc = 
%.1f
CHECK failed: (temp[0]) == ('1'): 
CHECK failed: (temp[size - 1]) == ('5'): 
CHECK failed: (size) <= (6): 
CHECK failed: result != nullptr: 
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing-3104.68.1/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/protobuf-lite/wire_format_lite.cc
CHECK failed: (value.size()) <= (kint32max): 
 '%s'
String field
 contains invalid 
UTF-8 data when 
 a protocol 
buffer. Use the 'bytes' type if you intend to send raw 
bytes. 
serializing
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing-3104.68.1/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/protobuf-lite/zero_copy_stream.cc
This ZeroCopyOutputStream doesn't support aliasing. Reaching here usually means a ZeroCopyOutputStream implementation bug.
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing-3104.68.1/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/protobuf-lite/zero_copy_stream_impl_lite.cc
CHECK failed: (last_returned_size_) > (0): 
BackUp() can only be called after a successful Next().
CHECK failed: (count) <= (last_returned_size_): 
CHECK failed: (count) >= (0): 
CHECK failed: target_ != NULL: 
CHECK failed: (count) <= (target_->size()): 
CHECK failed: backup_bytes_ == 0 && buffer_.get() != NULL: 
 BackUp() can only be called after Next().
CHECK failed: (count) <= (buffer_used_): 
 Can't back up over more bytes than were returned by the last call to Next().
 Parameter to BackUp() can't be negative.
CHECK failed: (backup_bytes_) == (0): 
CHECK failed: (buffer_used_) == (buffer_size_): 
/Library/Caches/com.apple.xbs/Sources/SiriNaturalLanguageParsing_Sim/SiriNaturalLanguageParsing-3104.68.1/SiriNaturalLanguageParsing/External_Libraries/sentencepiece/third_party/protobuf-lite/zero_copy_stream_impl.cc
close() failed: 
CHECK failed: !is_closed_: 
Can't BackUp() after failed Next().
^(\b\w+\b)(\S+)$
Failed to initialise the regex expression for the subtokens: 
appendMatchedSpan
span_processor.cpp
mInternals.reverseMapping.find(str) != mInternals.reverseMapping.end() && "Unable to find token chain in reverse mapping after a match was found in the pattern " "trie"
Failed to attach the regex expression to the token text: 
Failed to find match in text: 
Encountered invalid substring: 
Encountered empty normalized matching substring for label: 
Begin/inside BIO tags must have a payload component
Only begin/inside BIO tags can have a payload component
Cannot extract payload from non-begin/inside BIO tag
getPayload
bio.cpp
mPayload.has_value()
Well-formed BIO tags must be >=3 characters long, but got: 
BIO tag has no prefix
Unrecognized BIO tag prefix
convertToLabelledSpans
!currentSpan.has_value()
buildAllBioTagsFromEntityLabels
bioTags.size() == expectedFinalSize
Cannot get value for empty optional!
Span labels tensor is of incorrect shape
Span labels tensor shape does not match tokens size
Unable to instantiate a normalizer form the input normalizer choice
Failed to instantiate normalizer - 
Failed to normalize string 
 - due to error: 
Failed to compare strings - due to error: 
Failed to casefold string: 
Invalid substring range. The endIndex
 >= src length 
Invalid substring range. startIndex  (
) >= endIndex (
insertToken
vocabulary.cpp
mIdToText.size() == mTextToId.size()
Token indices out of range.
Number of tokens differs from number of BIO tags
Number of tokens differs from number of group IDs
First dimension of intentEntityTransitions does not equal number of intents
Second dimension of intentEntityTransitions does not equal number of BIO tags
Size of startEntityTransitions does not equal number of BIO tags
First dimension of entityTransitions does not equal number of BIO tags
Second dimension of entityTransitions does not equal number of BIO tags
Out-of-range intent label (key) in uniqueLabels
Out-of-range BIO label (value) in uniqueLabels
Out-of-range intent label (key) in indexableLabels
Out-of-range BIO label (value) in indexableLabels
Empty entitiesScores (implies no tokens)
Size of groupScores (
) does not equal number of tokens (
Invalid beamSize. Should be in the interval (0, 5]
BeamSequence[
  score = 
  intent = 
  entities = 
  groupIds = 
(none)
beamSearch
beam_search.cpp
allCandidates.begin() + beamSize < allCandidates.end()
Beam sequence is empty getIntent
Beam sequence is empty getEntities
Embedding[
 ...
Label vocabulary does not contain pad token
Trans params's first and second dimension should have non-zero equal value, while the actual shape is [
Trans params's first and second dimension value: 
 should be equal to tag size: 
Logits tensor's last dimension value: 
 should be equal to the output label's size: 
 and transit parameters's dimension value: 
Invalid input. Can't have WordCharactersTensorEnabled to be false while have WordLengthTensorEnabled to be true.
Word embedding data first dimension: 
 sequence length data first dimension: 
 word character data first dimension: 
 and word length data first dimension: 
 should have equal non-zero values
Word embedding data second dimension: 
 word character data second dimension: 
 and word length second dimension: 
word_embedding_placeholder
sequence_length_placeholder
word_characters_placeholder
word_length_placeholder
dropout_placeholder
proj/logits
Dimension value: 
 should match first value of shape: 
 should match second value of shape: 
 should match third value of shape: 
Begin index of mention boundary: 
 should be smaller than end index (exclusive) of mention boundary: 
End index (exclusive) of mention boundary: 
 should be smaller or equal then predictions labels size: 
Begin index: 
 should be smaller than end index: 
End index: 
Sequence length: 
 should be less than logits length: 
Logits's shape should be [maxTokens (Siri default is 26),
], while the actual shape is [
Output label map contains label: 
 which is not B, I and O label
Output label map file is empty
Output label map file is invalid. Valid output label map should has O tag with 1 label value, I labels comes after B labels, while the actual value is: O tag: 
, first B tag: 
, last B tag: 
, first I tag: 
, last I tag: 
B labels and I labels should have equal size, while the actual value is: first B tag: 
Transition parameters loaded is invalid. Transition parameters's first and second dimension should have non-zero equal value
Vocab indices map file is empty
The given chunkPredictions and usoGraphs don't have equal size
measurement
measurementComponent
otherPerson
appName
personalLocation
businessName
measurementUnit
currency
Entities with type 
 or 
 both exist in char index range [
Can't find entities with type: 
 and entities with type: 
 in char index range [
Entities with type: 
) has more than one
Entity is not with type 
Can't cast to pointer to 
com.apple.siri.nlteam.plum
NerHandler
NerFactory
Espresso
The input nest tag: 
 is empty
Can't get flat tags from: 
The input nest B tag: 
Can't get B tags from: 
Tag 
 is not a B tag
Can't locate I tag
Can't locate 
 in iTagIndicesMap
Tag after split should have size 2
 in output label map
No Number child entities and MeasurementUnit child entity is null
Fail to create espresso context.
Fail to create espresso pan.
Fail to set up espresso network.
Can't find character: 
 in character indices map
Num of tokens in embedding tensor: 
 doesn't match with sequence length: 
Num of layers in embedding tensor: 
 is not 1. Currently NER only support number of layer to be 1.
Number of embedding float values: 
 doesn't match with embedding shape: [
Size of NER alternative prediction from NER factory: 
 is not 1
Find both commonMeasurementComponent node and commonCurrency node. Invalid measurement entity.
Both commonMeasurementComponent node and commonCurrency node don't exist. Invalid measurement entity.
Find more than one commonCurrency node. Invalid measurement entity.
Attempt pruning UserAccepted from a one shot reply UserAccepted + UserStatedTask prediction.
Could not find a UserAccepted dialog act to remove.
UPContextualizerStrategyPrompt; %ld domain candidates matched dialog act prompted entity (%@)
UPContextualizerStrategyPrompt: No domain result matched dialog act prompted entity (%@)
UPContextualizerStrategyPrompt: Building verbatim string payload
[%s] Error, file doesn't exist. Hash for file content cannot be calculated: %s
[%s] Error, input stream for file could not be created. Hash for file content cannot be calculated: %s
[%s] Error, input stream for file could not be read. Hash for file content cannot be calculated: %s
[%s] Error while calculating hash of file %s
[%s] Error iterating over directory %s: %s
[%s] Warning: config missing Bolt task ID
[%s] Warning: config Bolt task ID is not a string
UPContextualizerStrategyOffer: Detected high-probability yes/no intent in core result
BEGIN "Encoder Inference"
Encoder Inference
END "Encoder Inference"
BEGIN "Decoder Inference"
Decoder Inference
END "Decoder Inference"
[%s] Invalid featurization input provided to the model.  Expected a non-empty utterance length tensor and a context tensor of at least two dimensions.
[%s] The utterance length (%lu) exceeds the maximum utterance length (%lu).
[%s] padEmbeddings input tensor size = %lu (%lu, %lu, %lu)
[%s] padEmbeddings maxUtteranceLength (defined by network config) = %lu
[%s] Illegal shape for embeddings: (%lu, %lu, %lu). Must be (?, ?, %lu) and hold %lu values
[%s] padEmbeddings For each batch, copying %lu embedding values and adding %lu padding values
[%s] padEmbeddings Padded embedding tensor shape: (%lu, %lu, %lu)
[%s] The component %zu is invalid
Warning: cannot embed OOV token '%s'.
Featurized the following %lu LegacyNLContext features in ITFMParserRequest: %s
Failed to featurize any labels from legacyNlContext
Warning: Legacy NL context features were supplied, but the asset directory major version (%u) does not support these. These will not be featurized.
Warning: The request's nlContext contains a SDA. Skipping featurization for the legacy context.
No SDA present in nlContext: falling back to legacyNlContext
Failed to extract any labels from nlContext or legacyNlContext
Label '%s' not present in vocabulary. Skipping. (Is this label supported by the provided assets?)
Number of context features (%lu) exceeds maximum limit (%lu): truncating by removing features %s
%s ITFM context: %s
nlu_request_id not found so skipping insertion of context featurized response into FeatureStore
ITFM non-padded context input tensor: %s
Skipping insertion of ITFM context featurizer response into FeatureStore because SNLPFeatureStoreEnabled feature flag is disabled
Successfully inserted context featurizer response into FeatureStore
Unable to insert context featurizer response into FeatureStore
Handling UPQuery converted from proto request: %@
UPQuery from non-proto service: %@
Could not convert query dialog act: %{sensitive}@
Converted dialog act and got: %@
Found no utterance alignments, skipping...
Found no matching insertable span.
SiriOntology indicated an entity node, but failed to cast to UsoEntityNode type.
No utterance alignments found in the entity node; searching the descendant nodes for utterance alignments instead.
Found no entities in the uso graph of matching span, skipping...
There is more than one entity in the USO graph of matching span, skipping...
The first level entity is not of entity node type, skipping...
BEGIN "UaaP UPParserModelInit initWithSystemConfiguration"
UaaP UPParserModelInit initWithSystemConfiguration
END "UaaP UPParserModelInit initWithSystemConfiguration"
BEGIN "UaaP EspressoInference"
UaaP EspressoInference
END "UaaP EspressoInference"
BEGIN "UaaP Post-Processing"
Number of BEAM sequences = %lu
Processing BEAM sequence: %s
Produced candidate: %@
UaaP Post-Processing
END "UaaP Post-Processing"
BEGIN "UaaP Prediction"
Error predicting utterance: %{sensitive}s
UaaP Prediction
END "UaaP Prediction"
Reshaping network to handle current request inputs
Reshaping blob '%s' to w=%d, h=%d, k=%d, n=%d
Featurizing the following context labels in NLv4ParserRequest.
Skipping insertion of NLv4 context featurizer response into FeatureStore because SNLPFeatureStoreEnabled feature flag is disabled
[%s] Found an smsGroupName span that matches a common_Person or common_Agent node
[%s] Found a personFullName span that matches a common_Person or common_Agent node, so skipping group_name_transform
[%s] Replacing the node label "%s" with "%s"
[%s] Found %lu smsGroupName matching spans
[%s] Found %lu personFullName matching spans
[%@ Assets] %s
BEGIN "SNLPITFMClassifier responseForRequest"
SNLPITFMClassifier responseForRequest
END "SNLPITFMClassifier responseForRequest"
[%s] %s
BEGIN "ITFM Span Featurization"
nlu_request_id not found so skipping insertion of asset version into FeatureStore
ITFM Span Featurization
END "ITFM Span Featurization"
BEGIN "ITFM Context Featurization"
ITFM Context Featurization
END "ITFM Context Featurization"
BEGIN "ITFM Inference"
ITFM Inference
END "ITFM Inference"
Warning: Invalid model version provided: %u.  Model versions currently supported: %s.
A token could not be reindexed; %{sensitive}s
Unknown error thrown during token index conversion (should be unreachable)
Token indexes could not be converted: %s
[%s] Splitting common_Person nodes in-place
[%s] Iterating through all tree nodes
[%s] Finished iterating through all tree nodes
[%s] Could not split this common_Person node
[%s] Successfully split the common_Person node into name/contact type
[%s] Handling common_Person subtree
[%s] Warning: the common_Person node has more than one child (expecting just `name`). Skipping.
[%s] Warning: the common_Person node child is not `name`. Skipping.
[%s] common_Person.name value: %{sensitive}s
[%s] There exists a person matching span covering this entire common_Person.name node. Skipping.
[%s] Could not find a split for this common_Person. Skipping.
[%s] Warning: Failed to generate a node for matching span (personInput=%{sensitive}s, contactTypeInput=%{sensitive}s)
[%s] Hit out of range exception when looking up token character indices
[%s] newNameNode.startCharIndex (%lu) is less than originalNameStartCharIndex (%lu)
[%s] newNameNode character indices imply an empty or impossible substring (%lu -> %lu)
[%s] contactAddressLabelNode.startCharIndex (%lu) is less than originalNameStartCharIndex (%lu)
[%s] contactAddressLabelNode character indices imply an empty or impossible substring (%lu -> %lu)
[%s] Generated new common_Person.name node with newNameNode.startCharIndex=%lu, newNameNode.endCharIndex=%lu, newNameNode.value=%{sensitive}s
[%s] After filtering, we have %lu contact type matching spans
[%s] After filtering, we have %lu person matching spans
[%s] Warning: could not find start token index corresponding to node.startCharIndex=%lu
[%s] Warning: could not find end token index corresponding to node.endCharIndex=%lu
[%s] Deleting %lu nodes
[%s] Inserting %lu spawned nodes
[%s] Badly formed SystemPrompted dialog act; needs to contain the target UsoGraph.
[%s] Badly formed SystemOffered dialog act; needs to contain a user dialog act.
[%s] Badly formed SystemReportedSuccess dialog act; needs to supply the task UsoGraph.
[%s] Badly formed SystemReportedFailure dialog act; needs to supply the UsoGraphs for the failed task and for the failure reason.
[%s] Warning: Badly formed user dialog act.
[%s] Failed to cast USO task node from SiriOntology. 
[%s] After filtering, we have %lu %s matching spans
[%s] No grounded tokens found under node: %s
No calibration score found for parser result with bundle modelIdentifier: %@
[%s] Both %s and %s semantic values found when using %s spans
[%s] MatchingSpan with label %s, semantic value %s found?: %{BOOL}d
Encountered error in deprecated version of inferenceResponseForRequest: %@ (returning SERVER parser response)
Result candidate has uncalibrated probability %f and calibrated probability %@. Using calibrated value.
Result candidate has uncalibrated probability %f and no calibrated probability. Using uncalibrated value.
Loaded config confidence_threshold: %1.2f
PSC response classificationProbability (%1.2f) is below the threshold (%1.2f), setting to 0.
UPContextualizerStrategyCancel: Detected high-probability cancel intent in core result
UPContextualizerStrategyOptions: Detected high-probability selectOrdinal intent in core result
UPContextualizerStrategyOptions: %ld domain candidates matched dialog act prompted entity (%@)
UPContextualizerStrategyOptions: No domain result matched dialog act prompted entity (%@)
UPContextualizerStrategyOptions: Building verbatim string payload
[%s] [model_task_id=%s]
SNLC override triggered: falling back on DEVICE based on the turn input SDA content
SNLC override triggered: falling back on SERVER based on the LegacyNLContext dictationPrompt=true
nlu_request_id not found so skipping insertion of SNLC executed handcrafted rules into FeatureStore
Skipping insertion of SNLC executed handcrafted rules into FeatureStore because SNLPFeatureStoreEnabled feature flag is disabled
Successfully inserted executed handcrafted rules into FeatureStore
Unable to insert executed handcrafted rules into FeatureStore
Rejecting '%s'.
Warning: Context shape not 2-dim
[NLv4IO Context Tensor] shape=%lu,%lu num_elems=%lu
Warning: Context shape not consistent with data
[NLv4IO Context Token] i=%lu j=%lu id=%lu token=%s
PrepareGlobalNerRequest
FetchNerPredictions
Utterance: %{sensitive}@
ConvertToUPPLNerResponse
Predictions:
PLUM Span (before post processing):
GeneratePlumSpans
[%s] Found setNumber voc span(s)
No matcher names provided - type property will be UPSpanTypeNone
Span not recognized by the span matchers - type property will be UPSpanTypeNone
Creating NLv4InferenceOrchestrator instance with getAssetVersionMajor()=%u
Creating NLv4InferenceOrchestrator instance via deprecated constructor with major asset version %u
BEGIN "NLv4 Matched Span Featurization"
NLv4 Matched Span Featurization
END "NLv4 Matched Span Featurization"
BEGIN "NLv4 Context Featurization"
NLv4 Context Featurization
END "NLv4 Context Featurization"
BEGIN "NLv4 Inference"
%s Numericalized span input for NLv4 parser model:
%s Numericalized context input for NLv4 parser model:
%s %s
NLv4 Inference
END "NLv4 Inference"
BEGIN "NLv4 Tree Building"
Tree after all manipulations:
%{sensitive}s
A hypothesis was rejected because it contained only UserAccepted.
Building UDA for hypothesis number %zu
Invalid USO graph, removing parse from output.  This might be due to a grammatical error or an otherwise malformed model tree.
Could not generate a full USO graph for a hypothesis: %s
NLv4 Tree Building
END "NLv4 Tree Building"
[NLv4IO Ply tree] hypothesis=%zu:
[NLv4IO Ply tags] hypothesis=%zu:
[SNLPAssetLogger] %s
nlu_request_id not found so skipping insertion of executed handcrafted rules into FeatureStore
Skipping insertion of NLv4 executed handcrafted rules into FeatureStore because SNLPFeatureStoreEnabled feature flag is disabled
Successfully inserted NLv4 executed handcrafted rules into FeatureStore
Unable to insert NLv4 executed handcrafted rules into FeatureStore
Invalid model tree, removing parse from output.
Invalid user dialog act: %s
BEGIN "CalibrationInference"
CalibrationInference
END "CalibrationInference"
[%s] Warning: failed to get namespace for node %{sensitive}s: %{sensitive}s
[%s] Badly formed matching span; start and/or end indices missing from span.
Missing locale info when init UPDataDetector. Falling back using the system default one.
[%s] A data detector span contained a USO graph with an invalid entity node.  This data detector span was ignored by the span matching featurizer.  Error: %s.
[%s] Span encoding failed; number of buckets (%lu) not matching number of tokens (%lu).
%s Exception when calling C plus plus post processor code : %{sensitive}s
%s Exception "%{sensitive}s" catched during graph genereation for span:
 %{sensitive}@
%s Error serializing USO graph : %{sensitive}@
%s USO graph genereatd for span:
 %{sensitive}@
%s Use USOGraph from Date Detector Span for PLUM Span:
 %{sensitive}@
%s Data detector span is nil, skip the code to integrate plum spans with data detector spans.
BEGIN "UPLoadedModelConfigurationInit"
BEGIN "EspressoInitialization"
Exception while initializing model %s
EspressoInitialization
END "EspressoInitialization"
UPLoadedModelConfigurationInit
END "UPLoadedModelConfigurationInit"
[%s] [WARN] MatchingSpan has no USO graph
[%s] [WARN] MatchingSpan has USO graph with no identifiers
[%s] [WARN] probability missing from identifier
[%s] [WARN] probability has no value
[%s] [WARN] Negative relative threshold supplied (%f), span filtering will behave strangely
[%s] Span filtering: %lu out of %lu spans kept
[%s] Span %s [score %f] was kept?: %{BOOL}d
[%s] Span %s [no score] was kept?: %{BOOL}d
Multiple SystemDialogActs specified in context but UaaP can only handle one - using the first one
BEGIN "UaaP Preprocessing"
Found matched span using data detectors: %lu -> %lu (%s)
Featurized token with text=%s
Token span labels: %s
UaaP Preprocessing
END "UaaP Preprocessing"
Valid insertable span found; re-inserting it into the model graph.
Warning: could not look up ontology name for parent argument '%s'
Re-insertion of span graph was successful.
Could not insert subtree: %{sensitive}s 
 Warning: Could not generate USO graph: %s
Built USO graph:
Failed to cast entity node to entity node; SiriOntology reports a non-entity node as an entity node.
Warning: Integer %s out of range for USO integer nodes.
Warning: Failed to convert string %s to integer.
BEGIN "SNLPNaturalLanguageParser inferenceResponseForRequest"
SNLPNaturalLanguageParser inferenceResponseForRequest
END "SNLPNaturalLanguageParser inferenceResponseForRequest"
Tree after ContactTypeSplit step:
%{sensitive}s
Tree after PersonNameSplitHack step:
%{sensitive}s
Tree after GroupNameTransform step:
%{sensitive}s
Tree after ContactAddressDowncaster step:
%{sensitive}s
Tree after MinimumMaximumLabeller labelling:
%{sensitive}s
Tree after One Shot Reply check:
%{sensitive}s
Tree after SetNumber verb replacement:
%{sensitive}s
[%s] Span Input
[%s] nlu_request_id not found so skipping insertion of span featurized response into FeatureStore
[%s] Warning: encountered span missing label
[%s] Badly formed matching span; start and/or end indices missing from span. Skipping.
[%s] Mapping span label '%s' to span label '%s'
[%s] Warning: Featurised spans shape not 3-dim
[%s] [Span Tensor] shape=%lu,%lu,%lu num_elems=%lu
[%s] Warning: Span shape not consistent with data
[%s] [Span Token] i=%lu j=%lu k=%lu id=%lu token=%s
[%s] span '%s' covers tokens [%u, %u)
[%s] Spans encoded over the tokens:
[%s] %s: %s
[%s] Rejecting OOV Span: %s
[%s] Skipping insertion of matched spans featurized response into FeatureStore because SNLPFeatureStoreEnabled feature flag is disabled
[%s] Successfully inserted span featurizer response into FeatureStore
[%s] Unable to insert span featurizer response into FeatureStore
Could not find contextualizer strategy for dialog act: %{sensitive}@
Inserting FeatureStore entry with interactionIdentifier=%@, streamIdentifier=%@
[%s] Since the model itself predicted only %lu common_Person nodes (lower than the threshold of %lu), do not apply the name split hack
[%s] Could not find _any_ partition for this common_Person (including a single-span one). Skipping.
[%s] This common_Person cannot be split into multiple sub-spans. Skipping.
[%s] This common_Person has been partitioned into %lu sub-spans.
[%s] Warning: Failed to generate a node for matching span (input=%{sensitive}s)
[%s] Finding person matching span partitions for range %lu -> %lu
[%s]  - span: %{sensitive}s
[%s] Found %lu possible person partitions:
[%s] Found minimal partition:
[%s]  - component: %{sensitive}s
[%s] Did not find minimal partition
[%s] Generated new common_Person.name node with startCharIndex=%lu, endCharIndex=%lu, value=%{sensitive}s
[%s] Successfully spawned replacement common_Person nodes
Espresso
BeamSearch
CrfNormalizer
PrepareTensor
BuildTensor
ExecutePlan
GetTensor
UPModelIdentifier
NSCopying
UPContextualizerStrategyPrompt
UPContextualizerStrategy
NSObject
UPContextualizerStrategyOffer
UPPLMatchedSpan
UPDataDetectorSpan
SNLPITFMModelBundle
UPQueryRunner
UPDialogActPrompt
UPDialogAct
UPParserModel
SNLPITFMClassifier
UPUsoSerializer
UPCalibration
SNLPServerNLClassifier
UPResultCandidate
UPModelBundle
SNLPPommesServerClassifier
UPResultRootNode
UPTokenizer
UPResultNode
UPContextualizerStrategyCancel
UPContextualizerStrategyOptions
UPResultIntermediateNode
UPIntentWithSingleEntity
UPDialogActConverter
UPPreprocessorOutput
UPToken
SNLPEmbedder
UPContextualizerUtilities
UPPLNerHandler
UPUtilities
UPPLAlternativePrediction
UPSpan
UPCalibrationModel
UPEntityWithValue
UPDialogActOffer
UPPLEmbeddingTensor
UPDetectedData
UPDataDetectors
UPContextualizerInput
UPPLChunkPrediction
UPModelConfiguration
UPPlumSpan
UPPLPostProcessor
UPPLTokenization
SNLPFeatureFlagUtilities
UPLoadedModelConfiguration
UPResult
UPQuery
UPResultCandidateEntity
UPDialogActOptions
UPPreprocessor
UPSystemConfiguration
UPPLNerRequest
UPResultLeafNode
UPPLToken
SNLPNaturalLanguageParser
UPEmbedding
SNLPITFMModelInfo
UPPLNerResponse
UPContextualizer
SNLPFeatureStoreUtilities
init
UUID
allocWithZone:
copyWithZone:
uuid
isEqual:
appBundleId
isEqualToString:
hash
initWithAppBundleId:
.cxx_destruct
_uuid
_appBundleId
T@"NSUUID",R,C,V_uuid
T@"NSString",R,C,V_appBundleId
dialogAct
reference
coreResult
createConfirmOrRejectedDialogActsFor:reference:
domainResult
modelIdentifier
query
initWithDomainResult:coreResult:modelIdentifier:query:dialogAct:
entityName
filterResult:byEntityName:serializer:
candidateCount
intent
resultFromResult:withNewIntent:
entityType
buildPayloadResultFromQuery:modelIdentifier:intent:entityName:serializer:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
superclass
description
debugDescription
TQ,R
T#,R
T@"NSString",R,C
resultUsingContextualizerInput:
initWithPrebuiltIntentThreshold:usoSerializer:
prebuiltIntentThreshold
usoSerializer
_prebuiltIntentThreshold
_usoSerializer
Td,R,N,V_prebuiltIntentThreshold
T@"UPUsoSerializer",R,N,V_usoSerializer
stringWithCString:encoding:
defaultManager
fileExistsAtPath:isDirectory:
inputStreamWithFileAtPath:
open
read:maxLength:
stringWithCapacity:
appendFormat:
UTF8String
initWithLength:
mutableBytes
length
arrayWithObjects:count:
hasTopCandidate:excedingProbability:matchingOneOfIntents:
createResultFromExistingResult:truncatedTo:
initWithPrebuiltIntentThreshold:
label
tokenIndicesIndex
stringWithFormat:
dictionaryWithObjects:forKeys:count:
initWithLabel:tokenIndicesIndex:
dictionaryRepresentation
_label
_tokenIndicesIndex
T{_NSRange=QQ},R,N,V_tokenIndicesIndex
T@"NSString",R,N,V_label
initWithRange:type:category:
printedForm
initWithRange:category:dataDetectorResult:
initWithRange:category:dataDetectorResult:usoGraph:
getUsoGraphPrintedForm
dataDetectorResult
usoGraph
_dataDetectorResult
_usoGraph
T^{__DDResult=},R,V_dataDetectorResult
T@"USOSerializedGraph",R,V_usoGraph
_existErrorForEspressoModelURL:configURL:contextVocabularyURL:spanVocabularyURL:versionURL:errorDomain:
_initWithEspressoModelURL:configURL:contextVocabularyURL:spanVocabularyURL:versionURL:
path
isReadableFileAtPath:
_errorForMissingResourceURL:errorDomain:
mainBundle
localizedStringForKey:value:table:
errorWithDomain:code:userInfo:
bundleWithEspressoModelURL:configURL:contextVocabularyURL:spanVocabularyURL:versionURL:errorDomain:error:
espressoModelURL
configURL
contextVocabularyURL
spanVocabularyURL
versionURL
_espressoModelURL
_configURL
_contextVocabularyURL
_spanVocabularyURL
_versionURL
T@"NSURL",R,N,V_espressoModelURL
T@"NSURL",R,N,V_configURL
T@"NSURL",R,N,V_contextVocabularyURL
T@"NSURL",R,N,V_spanVocabularyURL
T@"NSURL",R,N,V_versionURL
initWithUsoSerializer:
countByEnumeratingWithState:objects:count:
preprocessor
initWithPreprocessor:parserModel:calibrationModel:
addObject:
initWithCoreModel:domainModelBundles:
initWithProtobufQuery:error:
predictionFromQuery:error:
protobufRepresentation
initWithProtobufQueryAndPlumSpans:plumSpans:error:
dictionary
parserModel
identifier
preprocess:error:
predictionFromQuery:preprocessorOutput:error:
setObject:forKey:
calibrationModel
scoreFromQuery:preprocessorOutput:error:
calibrateParserResults:withCalibrationScores:error:
dialogActFromQuery:
allValues
setWithArray:
singleTurnPredictionFromDomainResults:
multiTurnPredictionFromQuery:modelIdentifierToDomainResults:dialogAct:error:
convertFromDialogAct:error:
localizedDescription
queryUUID
valueForKey:
anyObject
array
candidateAtRank:
probability
initWithKey:ascending:
sortedArrayUsingDescriptors:
initWithCandidates:queryUUID:
combinedResultFromResults:
objectForKeyedSubscript:
resultWithContextualizerInput:
initWithCoreModel:domainModels:
predictionFromProtobufQuery:error:
predictionFromProtobufQueryAndPlumSpans:plumSpans:error:
domainModels
coreModel
domainModelBundles
_calibration
_dialogActConverter
_contextualizer
_coreModel
_domainModelBundles
__calibration
__dialogActConverter
__contextualizer
T@"UPCalibration",R,N,V__calibration
T@"UPDialogActConverter",R,N,V__dialogActConverter
T@"UPContextualizer",R,N,V__contextualizer
T@"UPParserModel",R,N,V_coreModel
T@"NSSet",R,N,V_domainModelBundles
copy
initWithIntent:entityType:entityName:reference:
_intent
_entityType
_entityName
_reference
T@"NSString",R,C,V_entityType
T@"NSString",R,C,V_entityName
T@"USOSerializedGraph",R,V_reference
T@"NSString",R,C,V_intent
initWithSystemConfiguration:loadedModelConfiguration:
initWithModelConfiguration:
modelWithSystemConfiguration:loadedModelConfiguration:error:
bundleId
stdU16ToNSString:
numberWithUnsignedLong:
rangeFromStart:end:
initWithRange:label:text:groupId:semanticValue:
serializeFromIntent:andEntities:forBundleId:
initWithTask:
initWithUncalibratedProbability:calibratedProbability:utterance:intent:entities:modelIdentifier:task:
parserEspressoModule
utterance
nSStringToU16String:
beamMaskInput
arrayWithCapacity:
_candidateForBeamSequence:utterance:outputTokens:resolver:
annotatedString
intentVocabPath
bioLabelsVocabPath
_candidateForUtterance:probability:labelledSpans:intent:
spanLabelsTensor
embeddingsTensor
forwardWithSpanLabels:embeddings:utterance:
outputTokens
resolver
_resultFromInferenceResult:query:outputTokens:resolver:
locale
isPLUMEnabled
modelWithSystemConfiguration:modelConfiguration:error:
setIsPLUMEnabled:
_systemConfiguration
_loadedModelConfiguration
_isPLUMEnabled
_identifier
__usoSerializer
__systemConfiguration
__loadedModelConfiguration
T@"UPUsoSerializer",R,V__usoSerializer
T@"UPSystemConfiguration",R,N,V__systemConfiguration
T@"UPLoadedModelConfiguration",R,N,V__loadedModelConfiguration
T@"UPModelIdentifier",R,N,V_identifier
T@"NSLocale",R,C,N
TB,N,V_isPLUMEnabled
T@"UPPreprocessor",R
initWithModelBundle:modelInfo:initializationBlock:error:
_initializationBlock
loggingComponent
loggingComponentString
errorDomain
_setupAssetLogger
stringByDeletingLastPathComponent
_convertRequest:
requestId
highInt
lowInt
_convertResponse:
data
bytes
dataWithBytes:length:
initWithData:
classifierWithModelBundle:modelInfo:initializationBlock:error:
classifierWithModelBundle:modelInfo:error:
responseForRequest:error:
modelBundle
modelInfo
.cxx_construct
_orchestrator
_assetLogger
_modelBundle
_modelInfo
T@"SNLPITFMModelBundle",R,N,V_modelBundle
T@"SNLPITFMModelInfo",R,N,V_modelInfo
_convertBundleIdToEntity:
isHigherLevelEntity
_insertSimpleEntity:intoGraph:underTaskNode:
_insertHigherLevelEntities:intoGraph:underTaskNode:
initWithUsoGraph:withError:
defaultCStringEncoding
_leafNodeFromLabel:andGraphStringNode:
_leafNodeFromLabel:andGraphSemanticValueNode:
_leafNodeFromGraphEdge:andGraphNode:
initWithLabel:andLeafNodes:
toCppUsoGraph:withError:
_intermediateNodeRepresentations:
initWithLabel:intermediateNodes:directLeafNodes:
range
text
semanticValue
_addPathForLabel:range:text:semanticValue:toGraphNode:forGraph:
_groupHigherLevelEntities:
objectForKey:
higherLevelChildLabel
higherLevelParentLabel
groupId
numberWithLong:
stringByReplacingOccurrencesOfString:withString:
initWithLabel:andText:andSemanticValue:
deserializeFromSerializedGraph:
_usoVocabManager
doubleValue
calibrateResult:withCalibrationScore:
calibrateCandidate:withCalibrationScore:
uncalibratedProbability
numberWithDouble:
entities
task
stringWithUTF8String:
URLByAppendingPathComponent:
_classifierWithModelURL:configURL:spanVocabularyURL:contextVocabularyURL:versionURL:error:
URLByDeletingLastPathComponent
initWithType:loggingComponent:errorDomain:
alloc
_convertSNLCRequest:
_convertITFMResponse:
inferenceResponseForRequest:error:
setClassificationLabel:
setClassificationProbability:
embeddings
setEmbeddings:
matchingSpans
setMatchingSpans:
tokenisedUtterance
setTokenisedUtterance:
setRequestId:
turnInput
setTurnInput:
classificationLabel
classificationProbability
classifierWithPathURL:error:
classifierWithModelURL:configURL:spanVocabularyURL:contextVocabularyURL:error:
inferenceResponseForRequest:
numberWithUnsignedInteger:
annotatedEntityFragmentString
appendString:
characterAtIndex:
stringWithCharacters:length:
count
initWithCapacity:
_buildCandidateEntitiesByStartIndex:
rootNodeRepresentationForIntent:andEntities:
calibratedProbability
bestAvailableProbability
setProbability:
convertFromUserDialogAct:
arrayWithObject:
setUserDialogActs:
rootNodeRepresentation
_candidateEntitiesByStartIndex
_modelIdentifier
_task
_uncalibratedProbability
_calibratedProbability
_entities
__candidateEntitiesByStartIndex
_utterance
T@"NSDictionary",R,V__candidateEntitiesByStartIndex
T@"NSString",R,V_utterance
T@"NSString",R,V_intent
T@"UPResultRootNode",R
T@"UPUsoSerializer",R,V_usoSerializer
T@"UPModelIdentifier",R,N,V_modelIdentifier
T@"NSObject<SIRINLUUserDialogAct>",R,C,V_task
Td,R,V_uncalibratedProbability
T@"NSNumber",R,V_calibratedProbability
Td,R
T@"NSArray",R,V_entities
T@"SIRINLUEXTERNALUserParse",R,N
Td,R,N
initWithLoadedModelConfiguration:parserModel:calibrationModel:
_parserModel
_calibrationModel
_preprocessor
T@"UPPreprocessor",R,N,V_preprocessor
T@"UPParserModel",R,N,V_parserModel
T@"UPCalibrationModel",R,N,V_calibrationModel
dataWithContentsOfURL:
JSONObjectWithData:options:error:
floatValue
setConfidenceThreshold:
confidenceThreshold
_confidenceThreshold
Tf,N,V_confidenceThreshold
initWithLabel:
directLeafNodes
initWithArray:copyItems:
objectAtIndexedSubscript:
_dictionaryRepresentation
replaceObjectAtIndex:withObject:
null
intermediateNodes
_intermediateNodes
_directLeafNodes
T@"NSArray",R,C,V_intermediateNodes
T@"NSArray",R,C,V_directLeafNodes
localeIdentifier
raise:format:
whitespaceAndNewlineCharacterSet
stringByTrimmingCharactersInSet:
initWithString:range:isWhitespace:
isWhitespace
predicateWithBlock:
filteredArrayUsingPredicate:
nonWhitespaceTokensForTokens:
initWithLocale:
tokenizeUtterance:
_locale
T@"NSLocale",R,C,V_locale
T@"NSString",R,C,V_label
leafNodes
_leafNodes
T@"NSArray",R,C,V_leafNodes
entity
isEqualToEntityWithValue:
initWithIntent:singleEntity:
isEqualToIntentWithSingleEntity:
_entity
T@"UPEntityWithValue",R,V_entity
_convertFromOfferedDialogAct:error:
_convertFromGaveOptionsDialogAct:error:
_convertFromPromptedDialogAct:error:
offeredAct
_parseUserDialogAct:error:
initWithIntent:entityWithValue:
choices
objectAtIndex:
entityValue
initWithIntent:entityType:entityName:entityValues:
_parseUserDialogActGraph:error:
higherLevelEntityLabelFromParentLabel:childLabel:
initWithType:entityName:entityValue:
T@"UPUsoSerializer",R,C,V_usoSerializer
initWithEmbeddingsTensor:spanLabelsTensor:outputTokens:
dataDetectorSpans
_embeddingsTensor
_spanLabelsTensor
_outputTokens
_dataDetectorSpans
T^v,R
insertToFeatureStoreWithNLv4SpanResponse:interactionIdentifier:
insertToFeatureStoreWithNLv4ContextResponse:interactionIdentifier:
insertToFeatureStoreWithNLv4AssertVersion:interactionIdentifier:
insertToFeatureStoreWithNLv4ExecutedHandcraftedRules:interactionIdentifier:
itfmModelTypeForSNLPComponent:
insertToFeatureStoreWithITFMSpanResponse:interactionIdentifier:itfmModelType:
insertToFeatureStoreWithITFMContextResponse:interactionIdentifier:itfmModelType:
insertToFeatureStoreWithITFMAssertVersion:interactionIdentifier:itfmModelType:
insertToFeatureStoreWithITFMExecutedHandcraftedRules:interactionIdentifier:itfmModelType:
string
isEqualToToken:
hasValue
hasBegin
hasEnd
value
begin
initWithString:
initWithProtobufToken:
_isWhitespace
_string
_range
T@"NSString",R,C,V_string
T{_NSRange=QQ},R,V_range
TB,R,V_isWhitespace
warmup
tokenChain
tokensCount
tokens
cleanValue
setValues:count:
setNumToken:
setNumLayer:
setEmbeddingDim:
setEmbedderId:
setEmbeddingTensor:
setTokenChain:
initFromSourceVocabPath:bertModelPath:bertConfigPath:reformulatorPath:
getEmbeddingsBySentence:
getEmbeddings:
_cppOrchestrator
containsObject:
entityLabelsFromCandidate:
filterResult:serializer:predicate:
setReference:
instancesRespondToSelector:
loadConfigs:
integerValue
boolValue
tokenizedUtterance
originalUtterance
token
charIndicesRange
graphemeClusters
normalizedUtterance
numTokens
embeddingDim
values
numLayers
embedderId
numberWithFloat:
initWithCoarseEntityType:fineGrainedEntityType:charIndicesRange:tokenIndicesIndex:chunkScore:
initWithChunkPredictions:nerScore:alternativeIndex:
initWithAlternativePredictions:
predictNamedEntitiesForRequest:
alternativePredictions
chunkPredictions
substringWithRange:
fineGrainedEntityType
generateTypeWithPlumPrefix:
chunkScore
initWithRange:originalMention:category:score:usoSerializedGraph:
initWithLocale:modelDir:vocabTagsFile:transParamsFile:charIndicesFile:configFile:
initWithLocale:modelDir:vocabTagsFile:transParamsFile:charIndicesFile:configFile:padCharacter:unkCharacter:
generatePlumSpansForRequest:
maxTokens
maxTokenLength
beamSize
wordCharactersTensorEnabled
wordLengthTensorEnabled
useDropOut
_handler
_postProcessor
_wordCharactersTensorEnabled
_wordLengthTensorEnabled
_useDropOut
_maxTokens
_maxTokenLength
_beamSize
TQ,R,N,V_maxTokens
TQ,R,N,V_maxTokenLength
TQ,R,N,V_beamSize
TB,R,N,V_wordCharactersTensorEnabled
TB,R,N,V_wordLengthTensorEnabled
TB,R,N,V_useDropOut
fileExistsAtPath:
lengthOfBytesUsingEncoding:
getBytes:maxLength:usedLength:encoding:options:range:remainingRange:
intermediateNodeRepresentations:
checkFileExistence:error:
nerScore
alternativeIndex
_chunkPredictions
_nerScore
_alternativeIndex
T@"NSArray",R,N,V_chunkPredictions
T@"NSNumber",R,N,V_nerScore
TQ,R,N,V_alternativeIndex
hasStartTokenIndex
hasEndTokenIndex
_getSpanTypeFromProtobufSpan:
startTokenIndex
endTokenIndex
matcherNamesCount
matcherNamesAtIndex:
type
category
initWithProtobufSpan:error:
_type
_category
TQ,R,V_type
T@"NSString",R,C,V_category
calibrationEspressoModule
_entityValue
T@"NSString",R,C,V_entityValue
initWithIntent:
entityWithValue
_entityWithValue
T@"UPEntityWithValue",R,V_entityWithValue
initWithValues:withNumTokens:withNumLayers:withEmbeddingDim:withEmbedderId:
_values
_numTokens
_numLayers
_embeddingDim
_embedderId
T@"NSArray",R,N,V_values
TQ,R,N,V_numTokens
TQ,R,N,V_numLayers
TQ,R,N,V_embeddingDim
T@"NSString",R,N,V_embedderId
dealloc
initWithLabel:dataDetectorResult:
Tr^{__CFArray=},R,V_dataDetectorResult
localeWithLocaleIdentifier:
initLoadFromDataDetectorsDirectoryPath:forLocale:
dataDetectorsDirectoryPath
languageCode
dataDetector
_matchSpansForDetectedDataArray:label:
addObjectsFromArray:
initLoadFromDataDetectorsDirectoryPath:
initWithSystemConfiguration:forLocale:
matchSpans:
matchSpansForUtterance:
matchSpansForDetectedData:
ddUsoMapper
_dataDetector
_ddUsoMapper
T^{UPDataDetector=q^{__DDScanner}^{__DDScanner}^{__DDScanner}^{__DDScanner}^{__DDScanner}^{__DDScanner}},R,V_dataDetector
T^v,R,V_ddUsoMapper
_domainResult
_coreResult
_query
_dialogAct
T@"UPResult",R,N,V_domainResult
T@"UPResult",R,N,V_coreResult
T@"UPQuery",R,N,V_query
T@"<UPDialogAct>",R,N,V_dialogAct
coarseEntityType
_coarseEntityType
_fineGrainedEntityType
_chunkScore
_charIndicesRange
T@"NSString",R,N,V_coarseEntityType
T@"NSString",R,N,V_fineGrainedEntityType
T{_NSRange=QQ},R,N,V_charIndicesRange
T@"NSNumber",R,N,V_chunkScore
_initWithBioLabelsVocabPath:configPath:grammarPath:intentVocabPath:spanVocabPath:parserEspressoModelPath:calibrationEspressoModelPath:
stringByAppendingPathComponent:
_configurationWithBioLabelsVocabPath:configPath:grammarPath:intentVocabPath:spanVocabPath:parserEspressoModelPath:calibrationEspressoModelPath:error:
configurationFromDirectoryUrl:error:
configPath
grammarPath
spanVocabPath
parserEspressoModelPath
calibrationEspressoModelPath
espressoModelPath
_bioLabelsVocabPath
_configPath
_grammarPath
_intentVocabPath
_spanVocabPath
_parserEspressoModelPath
_calibrationEspressoModelPath
_espressoModelPath
T@"NSString",R,C,V_bioLabelsVocabPath
T@"NSString",R,C,V_configPath
T@"NSString",R,C,V_grammarPath
T@"NSString",R,C,V_intentVocabPath
T@"NSString",R,C,V_spanVocabPath
T@"NSString",R,C,V_parserEspressoModelPath
T@"NSString",R,C,V_calibrationEspressoModelPath
T@"NSString",R,C,V_espressoModelPath
componentsSeparatedByString:
exceptionWithName:reason:userInfo:
getTypeWithtoutPlumPrefix
usoSerializedGraph
setUsoSerializedGraph:
originalMention
score
_usoSerializedGraph
_originalMention
_score
T@"USOSerializedGraph",&,V_usoSerializedGraph
T@"NSString",R,V_originalMention
T@"NSNumber",R,C,V_score
valueWithRange:
process:dataDetectorSpans:
initWithTokens:originalUtterance:normalizedUtterance:
_originalUtterance
_normalizedUtterance
_tokens
T@"NSString",R,N,V_originalUtterance
T@"NSString",R,N,V_normalizedUtterance
T@"NSArray",R,N,V_tokens
isSNLPFeatureStoreEnabled
dictionaryWithContentsOfFile:
initWithLocale:tokenizer:isPLUMEnabled:featurizer:
hasCalibrationModel
labelToValueType
_bundleId
_labelToValueType
_resolver
_beamMaskInput
_parserEspressoModule
_calibrationEspressoModule
T@"NSLocale",R,N,V_locale
TB,R,V_isPLUMEnabled
T@"NSString",R,N,V_bioLabelsVocabPath
T@"NSString",R,N,V_intentVocabPath
T^v,R,N,V_labelToValueType
T^v,R,N,V_resolver
T^v,R,N,V_beamMaskInput
T^{EspressoModule=^v^v{?=^vi}},R,N,V_parserEspressoModule
T^{EspressoModule=^v^v{?=^vi}},R,N,V_calibrationEspressoModule
TB,R
T@"NSString",R,N,V_bundleId
_candidates
subarrayWithRange:
addHypotheses:
rootNode
_queryUUID
__candidates
T@"NSArray",R,C,N,V__candidates
T@"NSUUID",R,C,V_queryUUID
T@"UPResultRootNode",R,C
T@"SIRINLUINTERNALUAAP_PARSERUaaPParserResponse",R
hasTokenChain
tokensAtIndex:
hasEmbeddings
hasNonWhitespaceTokenIndex
nonWhitespaceTokenIndex
initWithProtobufEmbeddings:forTokenAt:error:
setObject:forKeyedSubscript:
matchingSpansCount
matchingSpansAtIndex:
hasTurnInput
hasTurnContext
turnContext
hasNlContext
nlContext
systemDialogActs
systemDialogActsCount
firstObject
convertSystemDialogAct:
_createTokenChainWithProtobufQuery:
_createEmbeddingsWithProtobufQuery:error:
_createSpansWithProtobufQuery:plumSpans:error:
_createDialogActWithProtobufQuery:
initWithTokens:embeddingsByToken:spans:dialogAct:
embeddingsByToken
spans
enumerateSpansWithType:block:
setTokens:
setEmbeddingsByToken:
__utterance
_embeddingsByToken
_spans
T@"NSArray",C,V_tokens
T@"NSDictionary",C,V_embeddingsByToken
T@"NSArray",R,C,V_spans
T@"<SIRINLUSystemDialogAct><NSObject>",R,V_dialogAct
containsString:
rangeOfString:
substringToIndex:
substringFromIndex:
longValue
_indexedLabelRepresentation
leafNodeRepresentation
_text
_groupId
_semanticValue
T@"NSString",R,V_label
T@"NSString",R,V_text
T@"NSNumber",R,V_groupId
T@"NSString",R,V_semanticValue
T@"UPResultLeafNode",R
T@"NSString",R
entityValues
_entityValues
T@"NSArray",R,C,V_entityValues
getDimension
getCoordinates
tokenizer
__featurizer
_tokenizer
T@"UPTokenizer",R,N,V_tokenizer
_initWithDataDetectorsDirectoryPath:
_configurationWithDataDetectorsDirectoryPath:error:
_dataDetectorsDirectoryPath
T@"NSString",R,C,V_dataDetectorsDirectoryPath
matchedSpans
initWithTokenizedUtterance:embeddings:matchedSpans:
_tokenizedUtterance
_embeddings
_matchedSpans
T@"UPPLTokenization",R,N,V_tokenizedUtterance
T@"UPPLEmbeddingTensor",R,N,V_embeddings
T@"NSArray",R,N,V_matchedSpans
T@"NSString",R,C,V_text
T@"NSString",R,C,V_semanticValue
tokenId
isSpecialToken
numberWithBool:
isWordPiece
isOverflow
encodedLabels
initWithToken:tokenId:charIndicesRange:graphemeClusters:
initWithToken:tokenId:charIndicesRange:graphemeClusters:isSpecialToken:isWordPiece:isOverflow:encodedLabels:
_isSpecialToken
_isWordPiece
_isOverflow
_token
_tokenId
_graphemeClusters
_encodedLabels
T@"NSString",R,N,V_token
TQ,R,N,V_tokenId
T@"NSArray",R,N,V_graphemeClusters
TB,R,N,V_isSpecialToken
TB,R,N,V_isWordPiece
TB,R,N,V_isOverflow
T@"NSArray",R,N,V_encodedLabels
fileSystemRepresentation
_initWithCppOrchestrator:
convertNLv4ParserRequestToCpp:
convertNLv4ParserResponseFromCppToObjC:
parserFromAssetDirectory:error:
hasEmbeddingDim
hasNumToken
numToken
valuesCount
initWithDomain:code:userInfo:
valuesAtIndex:
setObject:atIndexedSubscript:
initWithCoordinates:
arrayWithArray:
_embedding
stringForModelType:
_loggingComponent
_errorDomain
_loggingComponentString
TQ,R,N,V_type
Ti,R,N,V_loggingComponent
T@"NSString",R,N,V_errorDomain
T@"NSString",R,N,V_loggingComponentString
_alternativePredictions
T@"NSArray",R,N,V_alternativePredictions
_contextualizeByDialogActTypeUsingContextualizerInput:
cancelContextualizerStrategy
offerContextualizerStrategy
optionsContextualizerStrategy
promptContextualizerStrategy
_cancelContextualizerStrategy
_offerContextualizerStrategy
_optionsContextualizerStrategy
_promptContextualizerStrategy
T@"UPContextualizerStrategyCancel",R,N,V_cancelContextualizerStrategy
T@"UPContextualizerStrategyOffer",R,N,V_offerContextualizerStrategy
T@"UPContextualizerStrategyOptions",R,N,V_optionsContextualizerStrategy
T@"UPContextualizerStrategyPrompt",R,N,V_promptContextualizerStrategy
_insertToFeatureStoreWithProtobufObject:interactionIdentifier:streamIdentifier:
dataWithJSONObject:options:error:
initWithData:encoding:
_jsonStringFromProtobufObject:
_insertToFeatureStoreWithJSONString:interactionIdentifier:streamIdentifier:
getWithStreamId:
initWithJsonStr:interactionId:dataVersion:
insert:error:
@24@0:8^{_NSZone=}16
@24@0:8@16
B24@0:8@16
Q16@0:8
@16@0:8
v16@0:8
@"NSUUID"
@"NSString"
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B16@0:8
B24@0:8#16
B24@0:8:16
Vv16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
@"UPResult"24@0:8@"UPContextualizerInput"16
@32@0:8d16@24
d16@0:8
@"UPUsoSerializer"
@24@0:8d16
@40@0:8@16{_NSRange=QQ}24
{_NSRange=QQ}16@0:8
{_NSRange="location"Q"length"Q}
@48@0:8{_NSRange=QQ}16@32^{__DDResult=}40
@56@0:8{_NSRange=QQ}16@32^{__DDResult=}40@48
^{__DDResult=}16@0:8
^{__DDResult=}
@"USOSerializedGraph"
@72@0:8@16@24@32@40@48@56^@64
@64@0:8@16@24@32@40@48@56
@32@0:8@16@24
@56@0:8@16@24@32@40@48
@"NSURL"
@32@0:8@16^@24
@40@0:8@16@24^@32
@48@0:8@16@24@32^@40
@"UPParserModel"
@"NSSet"
@"UPCalibration"
@"UPDialogActConverter"
@"UPContextualizer"
@48@0:8@16@24@32@40
@44@0:8r^v16f24r^v28@36
{UPInferenceResult={UPGenericTensor={vector<unsigned long, std::allocator<unsigned long>>=^Q^Q{__compressed_pair<unsigned long *, std::allocator<unsigned long>>=^Q}}{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}}{UPGenericTensor={vector<unsigned long, std::allocator<unsigned long>>=^Q^Q{__compressed_pair<unsigned long *, std::allocator<unsigned long>>=^Q}}{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}}{UPGenericTensor={vector<unsigned long, std::allocator<unsigned long>>=^Q^Q{__compressed_pair<unsigned long *, std::allocator<unsigned long>>=^Q}}{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}}}120@0:8{UPGenericTensor={vector<unsigned long, std::allocator<unsigned long>>=^Q^Q{__compressed_pair<unsigned long *, std::allocator<unsigned long>>=^Q}}{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}}16{UPGenericTensor={vector<unsigned long, std::allocator<unsigned long>>=^Q^Q{__compressed_pair<unsigned long *, std::allocator<unsigned long>>=^Q}}{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}}64@112
@48@0:8r^v16@24r^v32^v40
@48@0:8r^v16r^v24r^v32^v40
v20@0:8B16
@"UPModelIdentifier"
@"UPSystemConfiguration"
@"UPLoadedModelConfiguration"
@48@0:8@16@24@?32^@40
@?16@0:8
{unique_ptr<const sirinluinternalitfm::ITFMParserRequest, std::default_delete<const sirinluinternalitfm::ITFMParserRequest>>={__compressed_pair<const sirinluinternalitfm::ITFMParserRequest *, std::default_delete<const sirinluinternalitfm::ITFMParserRequest>>=^{ITFMParserRequest}}}24@0:8@16
@48@0:8{ITFMParserResponse=^^?{unique_ptr<sirinluexternal::Parser, std::default_delete<sirinluexternal::Parser>>={__compressed_pair<sirinluexternal::Parser *, std::default_delete<sirinluexternal::Parser>>=^{Parser}}}fB{?=b1b1}}16
{unique_ptr<snlp::common::asset_logger::SNLPAssetLogger, std::default_delete<snlp::common::asset_logger::SNLPAssetLogger>>={__compressed_pair<snlp::common::asset_logger::SNLPAssetLogger *, std::default_delete<snlp::common::asset_logger::SNLPAssetLogger>>=^{SNLPAssetLogger}}}16@0:8
{unique_ptr<itfm_inference_orchestrator::orchestration::ITFMOrchestrator, std::default_delete<itfm_inference_orchestrator::orchestration::ITFMOrchestrator>>="__ptr_"{__compressed_pair<itfm_inference_orchestrator::orchestration::ITFMOrchestrator *, std::default_delete<itfm_inference_orchestrator::orchestration::ITFMOrchestrator>>="__value_"^{ITFMOrchestrator}}}
{unique_ptr<snlp::common::asset_logger::SNLPAssetLogger, std::default_delete<snlp::common::asset_logger::SNLPAssetLogger>>="__ptr_"{__compressed_pair<snlp::common::asset_logger::SNLPAssetLogger *, std::default_delete<snlp::common::asset_logger::SNLPAssetLogger>>="__value_"^{SNLPAssetLogger}}}
@"SNLPITFMModelBundle"
@"SNLPITFMModelInfo"
@32@0:8r^v16r^{UsoGraphNode=^^?^{UsoGraph}Q}24
@40@0:8{vector<std::pair<std::reference_wrapper<siri::ontology::UsoGraphNode>, std::reference_wrapper<const siri::ontology::UsoGraphEdge>>, std::allocator<std::pair<std::reference_wrapper<siri::ontology::UsoGraphNode>, std::reference_wrapper<const siri::ontology::UsoGraphEdge>>>>=^v^v{__compressed_pair<std::pair<std::reference_wrapper<siri::ontology::UsoGraphNode>, std::reference_wrapper<const siri::ontology::UsoGraphEdge>> *, std::allocator<std::pair<std::reference_wrapper<siri::ontology::UsoGraphNode>, std::reference_wrapper<const siri::ontology::UsoGraphEdge>>>>=^v}}16
@32@0:8@16r^v24
@40@0:8@16@24@32
v40@0:8@16^v24^{UsoGraphNode=^^?^{UsoGraph}Q}32
v72@0:8@16{_NSRange=QQ}24@40@48^{UsoGraphNode=^^?^{UsoGraph}Q}56^v64
{shared_ptr<siri::ontology::UsoVocabManager>="__ptr_"^{UsoVocabManager}"__cntrl_"^{__shared_weak_count}}
@32@0:8@16d24
@56@0:8@16@24@32@40^@48
@64@0:8@16@24@32@40@48^@56
@72@0:8d16@24@32@40@48@56@64
@"NSObject<SIRINLUUserDialogAct>"
@"NSNumber"
@"NSArray"
@"NSDictionary"
@"UPCalibrationModel"
@"UPPreprocessor"
f16@0:8
v20@0:8f16
@"NSLocale"
@"UPEntityWithValue"
@136@0:8{UPGenericTensor={vector<unsigned long, std::allocator<unsigned long>>=^Q^Q{__compressed_pair<unsigned long *, std::allocator<unsigned long>>=^Q}}{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}}16{UPGenericTensor={vector<unsigned long, std::allocator<unsigned long>>=^Q^Q{__compressed_pair<unsigned long *, std::allocator<unsigned long>>=^Q}}{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}}64{vector<nl_featurization::Token, std::allocator<nl_featurization::Token>>=^{Token}^{Token}{__compressed_pair<nl_featurization::Token *, std::allocator<nl_featurization::Token>>=^{Token}}}112
^v16@0:8
{UPGenericTensor="shape"{vector<unsigned long, std::allocator<unsigned long>>="__begin_"^Q"__end_"^Q"__end_cap_"{__compressed_pair<unsigned long *, std::allocator<unsigned long>>="__value_"^Q}}"data"{vector<float, std::allocator<float>>="__begin_"^f"__end_"^f"__end_cap_"{__compressed_pair<float *, std::allocator<float>>="__value_"^f}}}
{vector<nl_featurization::Token, std::allocator<nl_featurization::Token>>="__begin_"^{Token}"__end_"^{Token}"__end_cap_"{__compressed_pair<nl_featurization::Token *, std::allocator<nl_featurization::Token>>="__value_"^{Token}}}
{vector<uaap::UPDetectedSpan, std::allocator<uaap::UPDetectedSpan>>="__begin_"^{UPDetectedSpan}"__end_"^{UPDetectedSpan}"__end_cap_"{__compressed_pair<uaap::UPDetectedSpan *, std::allocator<uaap::UPDetectedSpan>>="__value_"^{UPDetectedSpan}}}
@44@0:8@16{_NSRange=QQ}24B40
{unique_ptr<nlv4_inference_orchestrator::orchestration::EmbedderOrchestrator, std::default_delete<nlv4_inference_orchestrator::orchestration::EmbedderOrchestrator>>="__ptr_"{__compressed_pair<nlv4_inference_orchestrator::orchestration::EmbedderOrchestrator *, std::default_delete<nlv4_inference_orchestrator::orchestration::EmbedderOrchestrator>>="__value_"^{EmbedderOrchestrator}}}
B40@0:8@16d24@32
@40@0:8@16@24@?32
@80@0:8@16@24@32@40@48@56@64@72
v24@0:8@16
{unique_ptr<global_ner::GlobalNerHandler, std::default_delete<global_ner::GlobalNerHandler>>="__ptr_"{__compressed_pair<global_ner::GlobalNerHandler *, std::default_delete<global_ner::GlobalNerHandler>>="__value_"^{GlobalNerHandler}}}
@"UPPLPostProcessor"
B32@0:8@16^@24
{_NSRange=QQ}32@0:8Q16Q24
{basic_string<char16_t, std::char_traits<char16_t>, std::allocator<char16_t>>={__compressed_pair<std::basic_string<char16_t>::__rep, std::allocator<char16_t>>={__rep=(?={__long=^SQQ}{__short=[11S]{?=[1C]C}}{__raw=[3Q]})}}}24@0:8@16
@24@0:8r^v16
@40@0:8@16@24Q32
Q24@0:8@16
@48@0:8{_NSRange=QQ}16Q32@40
d120@0:8{UPGenericTensor={vector<unsigned long, std::allocator<unsigned long>>=^Q^Q{__compressed_pair<unsigned long *, std::allocator<unsigned long>>=^Q}}{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}}16{UPGenericTensor={vector<unsigned long, std::allocator<unsigned long>>=^Q^Q{__compressed_pair<unsigned long *, std::allocator<unsigned long>>=^Q}}{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}}64@112
@56@0:8@16Q24Q32Q40@48
@32@0:8@16r^{__CFArray=}24
r^{__CFArray=}16@0:8
r^{__CFArray=}
@32@0:8^{__CFArray=}16@24
^{UPDataDetector=q^{__DDScanner}^{__DDScanner}^{__DDScanner}^{__DDScanner}^{__DDScanner}^{__DDScanner}}16@0:8
^{UPDataDetector=q^{__DDScanner}^{__DDScanner}^{__DDScanner}^{__DDScanner}^{__DDScanner}^{__DDScanner}}
@"UPResult"
@"UPQuery"
@"<UPDialogAct>"
@72@0:8@16@24{_NSRange=QQ}32{_NSRange=QQ}48@64
@80@0:8@16@24@32@40@48@56@64^@72
@72@0:8@16@24@32@40@48@56@64
@64@0:8{_NSRange=QQ}16@32@40@48@56
v32@0:8@16@24
^{EspressoModule=^v^v{?=^vi}}16@0:8
^{EspressoModule=^v^v{?=^vi}}
@32@0:8@16Q24
@24@0:8q16
q16@0:8
v32@0:8Q16@?24
@"<SIRINLUSystemDialogAct><NSObject>"
@44@0:8@16@24B32r^{AbstractFeaturizer=^^?}36
r^{AbstractFeaturizer=^^?}
@"UPTokenizer"
@"UPPLTokenization"
@"UPPLEmbeddingTensor"
@56@0:8@16Q24{_NSRange=QQ}32@48
@76@0:8@16Q24{_NSRange=QQ}32@48B56B60B64@68
@24@0:8{unique_ptr<nlv4_inference_orchestrator::orchestration::NLv4InferenceOrchestrator, std::default_delete<nlv4_inference_orchestrator::orchestration::NLv4InferenceOrchestrator>>={__compressed_pair<nlv4_inference_orchestrator::orchestration::NLv4InferenceOrchestrator *, std::default_delete<nlv4_inference_orchestrator::orchestration::NLv4InferenceOrchestrator>>=^{NLv4InferenceOrchestrator}}}16
{unique_ptr<nlv4_inference_orchestrator::orchestration::NLv4InferenceOrchestrator, std::default_delete<nlv4_inference_orchestrator::orchestration::NLv4InferenceOrchestrator>>="__ptr_"{__compressed_pair<nlv4_inference_orchestrator::orchestration::NLv4InferenceOrchestrator *, std::default_delete<nlv4_inference_orchestrator::orchestration::NLv4InferenceOrchestrator>>="__value_"^{NLv4InferenceOrchestrator}}}
@36@0:8@16i24^@28
@24@0:8Q16
@36@0:8Q16i24@28
i16@0:8
@"UPContextualizerStrategyCancel"
@"UPContextualizerStrategyOffer"
@"UPContextualizerStrategyOptions"
@"UPContextualizerStrategyPrompt"
B32@0:8@16@24
B40@0:8@16@24Q32
B40@0:8@16@24@32
Q24@0:8r^i16
    
