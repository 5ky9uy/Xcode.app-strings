@(#)PROGRAM:RTCV-core-iOS  PROJECT:Vision-6.0.51
@@(#)PROGRAM:RTCV-cvabm-iOS  PROJECT:Vision-6.0.51
@(#)PROGRAM:RTCV-sim-iOS  PROJECT:Vision-6.0.51
@@(#)PROGRAM:RTCV-taptotrack-cyprus-iOS  PROJECT:Vision-6.0.51
@trk
3@(#)PROGRAM:TemporalRegistration-iOS  PROJECT:Vision-6.0.51
=ffffff
?ffffff
?333333
333333
?333333
@mLP
333333
?333333
?333333
o@UUUUUU
@33333
 @333?
Q8>ff
&1>=
L=33s?
IAfff?
<ff&?
u=ff
B>q=J?
 @33
CAffF@
@33
?33XB
 BmQv9
Ga==
anodv3_pet_v1_md2
eIDModel_v1_d18
FaceIDModel_v1_deIDModel_v1_d17
eIDModel_v1_d16
I?33
/@33
eID3Model_v1_d16FaceID3Model_v1_
dv3_torso_v3_md2anodv3_torso_v3_dv3_torso_v3_md3dv3_torso_v3_md4dv3_torso_v4_md2
fff?fff?
@(#)PROGRAM:Vision  PROJECT:Vision-6.0.51
@NSt3__120__shared_ptr_pointerIPhPFvPvENS_9allocatorIhEEEE
N6vision3mod26ImageDescriptorBufferJointE
NSt3__120__shared_ptr_emplaceIN6vision3mod28ConcreteFaceQualityPredictorENS_9allocatorIS3_EEEE
N6vision3mod29ImageDescriptorBufferAbstractE
N6vision3mod24ObjectTrackerCorrelationE
N5apple6vision29GreedyClusteringParamsWrapperE
N5apple6vision38GreedyClusteringParamsWrapperRevision5E
NSt3__120__shared_ptr_emplaceIN5apple6vision46GreedyClusteringParamsWrapperRevision5ConcreteENS_9allocatorIS3_EEEE
N5apple6vision46GreedyClusteringParamsWrapperRevision5ConcreteE
NSt3__120__shared_ptr_emplaceIN6vision3mod33ObjectDetector_DCNFaceDetector_v2ENS_9allocatorIS3_EEEE
N6vision3mod19TorsoprintGeneratorE
NSt3__120__shared_ptr_emplaceIN6vision3mod27TorsoprintGeneratorConcreteENS_9allocatorIS3_EEEE
N6vision3mod27TorsoprintGeneratorConcreteE
>333>
6>%I
N6vision3mod23ImageClassifierEspressoE
NSt3__120__shared_ptr_emplaceIN6vision3mod23ImageClassifierEspresso9private_tENS_9allocatorIS4_EEEE
NSt3__120__shared_ptr_emplaceIN6vision3mod18LandmarkAttributesENS_9allocatorIS3_EEEE
N6vision3mod33ObjectDetector_DCNFaceDetector_v2E
N6vision3mod22ObjectDetectorAbstractE
NSt3__120__shared_ptr_emplaceIN6vision3mod33ObjectDetector_DCNFaceDetector_v24privENS_9allocatorIS4_EEEE
N5apple6vision11OpticalFlow10LKTCPUImplINS1_13LKTCPUComputeEEE
N5apple6vision11OpticalFlow6LKTCPUE
NSt3__120__shared_ptr_emplaceIN6vision3mod28ImageDescriptor_EspressoJunkENS_9allocatorIS3_EEEE
N6vision3mod28ImageDescriptor_EspressoJunkE
NSt3__120__shared_ptr_pointerIPN6vision3mod18LandmarkAttributesENS_10shared_ptrIS3_E27__shared_ptr_default_deleteIS3_S3_EENS_9allocatorIS3_EEEE
NSt3__110shared_ptrIN6vision3mod18LandmarkAttributesEE27__shared_ptr_default_deleteIS3_S3_EE
f024800L
N6vision3mod28ImageDescriptorBufferFloat32E
NSt3__120__shared_ptr_emplaceIN6vision3mod15FaceFrontalizerENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN6vision3mod16FaceSegmenterDNNENS_9allocatorIS3_EEEE
NSt3__110__function6__funcIZZZ152-[VNFaceDetectorPrivateRevisionLegacyFaceCore internalProcessUsingQualityOfServiceClass:options:regionOfInterest:warningRecorder:error:progressHandler:]EUb_ENK3$_0clEP7CGImageEUlvE_NS_9allocatorIS5_EEFvvEEE
NSt3__110__function6__baseIFvvEEE
ZZZ152-[VNFaceDetectorPrivateRevisionLegacyFaceCore internalProcessUsingQualityOfServiceClass:options:regionOfInterest:warningRecorder:error:progressHandler:]EUb_ENK3$_0clEP7CGImageEUlvE_
?n'O
%5>q
f|:>
?T9W=
>tM>9!
v%?-"
=NSt3__120__shared_ptr_emplaceIN6vision3mod24CamGazePredictorConcreteENS_9allocatorIS3_EEEE
N6vision3mod24GreedyClustererWithTorsoE
N6vision3mod29GreedyClustererFacesWithTorsoE
NSt3__120__shared_ptr_emplaceIN6vision3mod29GreedyClustererFacesWithTorsoENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN6vision3mod24GreedyClustererWithTorso9private_tENS_9allocatorIS4_EEEE
NSt3__120__shared_ptr_emplaceINS_6vectorIjNS_9allocatorIjEEEENS2_IS4_EEEE
NSt3__120__shared_ptr_emplaceINS_6vectorINS_5tupleIJjjfEEENS_9allocatorIS3_EEEENS4_IS6_EEEE
N6vision3mod32ImageDescriptorProcessorEspressoE
NSt3__120__shared_ptr_emplaceIN6vision3mod32ImageDescriptorProcessorEspresso9private_tENS_9allocatorIS4_EEEE
NSt3__120__shared_ptr_pointerIPN5apple6vision9libraries9autotrace12EPolygonListEPFvS6_ENS_9allocatorIS5_EEEE
PFvPN5apple6vision9libraries9autotrace12EPolygonListEE
NSt3__120__shared_ptr_emplaceIN6vision3mod13FaceRegionMapENS_9allocatorIS3_EEEE
~|zxvuusqpnmkjiggfecba`_^]]\[ZYXWVUTTSRQQPONNMMLKKJIIHGGGFFEDDCCBBBAA@@??>>===<<;;:::999888776666555444333322211110000////.....----,,,,+++++*****)))))((((('''''''&&&&&&%%%%%%$$$$$$$########""""""!!!!!!!!!        X|E
+>>%I
N6vision3mod15ObjectTrackerExE
yA$H
ITCA
vA,2
q@,2
5mAv<
9Bh6
Df00Lh00L800L
NSt3__120__shared_ptr_emplaceIN6vision3mod22ImageClassifierGlimmerENS_9allocatorIS3_EEEE
NSt3__110__function6__funcIZN6vision3mod14broadcastMinusIdLm16EEEvRKNS3_10CVMLMatrixIT_XT0_EEERKNS3_10CVMLVectorIS6_XT0_EEEiRS7_bEUlddE_NS_9allocatorISF_EEFdddEEE
NSt3__110__function6__baseIFdddEEE
ZN6vision3mod14broadcastMinusIdLm16EEEvRKNS0_10CVMLMatrixIT_XT0_EEERKNS0_10CVMLVectorIS3_XT0_EEEiRS4_bEUlddE_
NSt3__110__function6__funcIZN6vision3mod12broadcastAddIdLm16EEEvRKNS3_10CVMLMatrixIT_XT0_EEERKNS3_10CVMLVectorIS6_XT0_EEEiRS7_bEUlddE_NS_9allocatorISF_EEFdddEEE
ZN6vision3mod12broadcastAddIdLm16EEEvRKNS0_10CVMLMatrixIT_XT0_EEERKNS0_10CVMLVectorIS3_XT0_EEEiRS4_bEUlddE_
N6vision3mod32FeatureSignSparseCoder_bad_allocE
N6vision3mod31ColorGaborImageDescriptorBufferE
N6vision3mod34ColorGaborImageDescriptorProcessorE
NSt3__120__shared_ptr_emplaceIN6vision3mod31ColorGaborImageDescriptorBufferENS_9allocatorIS3_EEEE
NSt3__110__function6__funcINS_6__bindIRFxP7__sFILEPKcRNS_3mapINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_6vectorIfNSB_IfEEEENS_4lessISD_EENSB_INS_4pairIKSD_SG_EEEEEEEJRKNS_12placeholders4__phILi1EEERKNSS_ILi2EEERKNSS_ILi3EEEEEENSB_IS12_EESP_EE
NSt3__110__function6__baseIFxP7__sFILEPKcRNS_3mapINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_6vectorIfNSA_IfEEEENS_4lessISC_EENSA_INS_4pairIKSC_SF_EEEEEEEEE
NSt3__16__bindIRFxP7__sFILEPKcRNS_3mapINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_6vectorIfNS9_IfEEEENS_4lessISB_EENS9_INS_4pairIKSB_SE_EEEEEEEJRKNS_12placeholders4__phILi1EEERKNSQ_ILi2EEERKNSQ_ILi3EEEEEE
NSt3__118__weak_result_typeIPFxP7__sFILEPKcRNS_3mapINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_6vectorIfNS9_IfEEEENS_4lessISB_EENS9_INS_4pairIKSB_SE_EEEEEEEEE
NSt3__110__function6__funcINS_6__bindIRFmmEJRKNS_12placeholders4__phILi1EEEEEENS_9allocatorISA_EES3_EE
NSt3__110__function6__baseIFmmEEE
NSt3__16__bindIRFmmEJRKNS_12placeholders4__phILi1EEEEEE
NSt3__118__weak_result_typeIPFmmEEE
NSt3__114unary_functionImmEE
NSt3__110__function6__funcINS_6__bindIRFxRKNS_3mapINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_6vectorIfNS7_IfEEEENS_4lessIS9_EENS7_INS_4pairIKS9_SC_EEEEEERKSC_RSC_EJRKNS_12placeholders4__phILi1EEERKNSS_ILi2EEERKNSS_ILi3EEEEEENS7_IS12_EESP_EE
NSt3__110__function6__baseIFxRKNS_3mapINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_6vectorIfNS6_IfEEEENS_4lessIS8_EENS6_INS_4pairIKS8_SB_EEEEEERKSB_RSB_EEE
NSt3__16__bindIRFxRKNS_3mapINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_6vectorIfNS5_IfEEEENS_4lessIS7_EENS5_INS_4pairIKS7_SA_EEEEEERKSA_RSA_EJRKNS_12placeholders4__phILi1EEERKNSQ_ILi2EEERKNSQ_ILi3EEEEEE
NSt3__118__weak_result_typeIPFxRKNS_3mapINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_6vectorIfNS5_IfEEEENS_4lessIS7_EENS5_INS_4pairIKS7_SA_EEEEEERKSA_RSA_EEE
NSt3__120__shared_ptr_emplaceIN6vision3mod21ImageAnalyzerConcreteENS_9allocatorIS3_EEEE
NSt3__111__end_stateIcEE
NSt3__16__nodeIcEE
NSt3__120__shared_ptr_pointerIPNS_13__empty_stateIcEENS_10shared_ptrIS2_E27__shared_ptr_default_deleteIS2_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrINS_13__empty_stateIcEEE27__shared_ptr_default_deleteIS2_S2_EE
NSt3__113__empty_stateIcEE
NSt3__116__owns_one_stateIcEE
NSt3__115__has_one_stateIcEE
NSt3__120__l_anchor_multilineIcEE
NSt3__120__r_anchor_multilineIcEE
NSt3__115__word_boundaryIcNS_12regex_traitsIcEEEE
NSt3__111__lookaheadIcNS_12regex_traitsIcEEEE
NSt3__123__match_any_but_newlineIcEE
NSt3__118__match_char_icaseIcNS_12regex_traitsIcEEEE
NSt3__120__match_char_collateIcNS_12regex_traitsIcEEEE
NSt3__112__match_charIcEE
NSt3__116__back_ref_icaseIcNS_12regex_traitsIcEEEE
NSt3__118__back_ref_collateIcNS_12regex_traitsIcEEEE
NSt3__110__back_refIcEE
NSt3__120__bracket_expressionIcNS_12regex_traitsIcEEEE
NSt3__128__begin_marked_subexpressionIcEE
NSt3__126__end_marked_subexpressionIcEE
NSt3__16__loopIcEE
NSt3__117__owns_two_statesIcEE
NSt3__117__repeat_one_loopIcEE
NSt3__111__alternateIcEE
NSt3__121__empty_non_own_stateIcEE
NSt3__111__match_anyIcEE
N5apple6vision11OpticalFlow6LKTCPU19AllocationExceptionE
N5apple6vision11OpticalFlow6LKTCPU27InvalidPixelFormatExceptionE
?2w-!
?O#-
?o/i
?`vO
?+0du
_{fI
tYLl>
?A+0du
++MJ
?S?o*Ra
?G=D
? <
?S\U
|a2U
?G8-x
??5^
?o*Ral!
tYLl
?gDio
?h?RD
?|DL
?pB!
FZ*o
?@M-[
#bJ$Q
?p%;6
FZ*oG
?+5{
?%]3
_{fI
?`vO
h"lx
?%]3
?U0*
?pB!
?Mg'
?a2U0*
o%;6
?,+MJA
?Ral!
?o*Ral!
?8J^
?Dio
?:#J{
?q $
$#ga
?{Ic
?scz
?o*Ral!
?U0*
?S?o*Ra
?Dio
8b->
?o/i
R?o*
?G8-x
?G8-x
?2ZGU
?Z*oG8-
?MJA
R?o*R
?`vO
_{fI
FZ*o
$#gaO
?{fI
?N6vision3mod12_GLOBAL__N_119BoxAlignerExceptionE
NSt3__120__shared_ptr_emplaceIN6vision3mod27GazeFollowPredictorConcreteENS_9allocatorIS3_EEEE
NSt3__110__function6__funcIZN6vision3mod14broadcastMinusIfLm16EEEvRKNS3_10CVMLMatrixIT_XT0_EEERKNS3_10CVMLVectorIS6_XT0_EEEiRS7_bEUlffE_NS_9allocatorISF_EEFfffEEE
NSt3__110__function6__baseIFfffEEE
ZN6vision3mod14broadcastMinusIfLm16EEEvRKNS0_10CVMLMatrixIT_XT0_EEERKNS0_10CVMLVectorIS3_XT0_EEEiRS4_bEUlffE_
NSt3__110__function6__funcIZN6vision3mod12broadcastAddIfLm16EEEvRKNS3_10CVMLMatrixIT_XT0_EEERKNS3_10CVMLVectorIS6_XT0_EEEiRS7_bEUlffE_NS_9allocatorISF_EEFfffEEE
ZN6vision3mod12broadcastAddIfLm16EEEvRKNS0_10CVMLMatrixIT_XT0_EEERKNS0_10CVMLVectorIS3_XT0_EEEiRS4_bEUlffE_
NSt3__110__function6__funcIZ13polynomialFitPKdS3_mmS3_S3_S3_E3$_0NS_9allocatorIS4_EEFNS_6vectorIdNS5_IdEEEEdEEE
NSt3__110__function6__baseIFNS_6vectorIdNS_9allocatorIdEEEEdEEE
Z13polynomialFitPKdS0_mmS0_S0_S0_E3$_0
Q9RI
Q9RI
7:RI
Q9RI
d*;4
>;_)K;
DX;B`e;
{r;l
k;B`e;
Q;_)K;
#;RI
7:RI
Q9RI
d*;4
7;_)K;
DX;B`e;
{r;o
{r;B`e;
DX;_)K;4
d*;RI
7:RI
Q9RI
7;_)K;
y;KY
3"<U
-<X94<
b<B`e<
4o<E
{r<!
ew<l
{r<E
h<B`e<e
#9<X94<
3"<RI
^;_)K;4
7:RI
Q9RI
k;KY
Q:RI
Q9RI
k:RI
DX;$
d*<4
?F<4
DX;4
Q:RI
>;B`e;'
#<X94<
z<KY
$=yX(=V
7=5^:=[
2D=]mE=
?F=]mE=
2D=\
<=5^:=
-2=2
+=yX(=
D<X94<
;B`e;
>;RI
{r<&
=R' =T
b=B`e=B>h=h
4o= Aq=
{r=F
{r= Aq=
(m=h
j=B>h=B`e=e
WJ=9
E6=|
%=R' =Qk
k:RI
7;B`e;
?$=V
b=B>h=D
s=Gry=
\~=n
\~=Gry=F
m=B>h=e
?$=v
;B`e;4
DX;'
3"<4
=R' =U
(=W[1=Z
B=_)K=a
S=d]\=
d=d]\=a
S=_)K=\
9=W[1=U
(=R' =P
j<<b
ew=I
{r<b
j<<>
ew<M
ew<>
=yX(=
A=;pN=
h=k+v=n
=k+v=
[=;pN=
5=yX(=
ew<b
7:RI
{r<M
7x=J{
/>:#
O/<N
=yX(=Y
U=B`e=
9#>/
$>0L&>
d*>1
'>0L&>/
Yu=B`e=
?F=Y
7=yX(=u
7;KY
=z6+=
/;=:
K=d]\=D
m=I.
V,>i
9>lx:>
<>6<=>
=>6<=>
;>lx:>l
u1>i
V,>
m=d]\=:
/;=z6+=
;_)K;
{r<)\
q,=6<==
Ga=F
s=J{
u >/
!N>`vO>
|P>`vO>
2D>7
~;>~
N=6<==
;_)K;o
<X94<
=z6+=6<==
ew=o
G!>ff&>
+>io0>F%5>
9>[B>>%uB>
qJ>_
QZ>?
+e>x
F>%uB>[B>>
9>F%5>io0>
+>ff&>
P=6<==z6+=u
/]<X94<r
Q9RI
{r<N
=yX(=
x=p_
/>aT
X>RI]>
Ga>f
n>W[q>}
=y>lxz>Zd{>
|>HP|>HP|>
|>Zd{>lxz>
s>W[q>
rh>f
Ga>RI]>P
/>o
/;=yX(=
y;RI
d*;KY
d*<b
ew=p_
2>Gr9>[
sW>v
8g>1
|>n4
3b>v
?>Gr9>
%>d;
Ga=:
d*<o
?F=d]\=F
8V>?
c>gDi>
t>5^z>$
>5^z>
4o>gDi>
s=d]\=
<;p
:_)K;RI
=yX(=
m=J{
P>>yX>
_>>yX>
kI>n
v>=yX(=
;_)K;
T<KY
L=B`e=I.
..>}
6>I.?>
h>iop>~
x>iop>
DX>r
G>I.?>}
c>]
=B`e=
;B`e;X9
c<)\
>B>(>W[1>lx:>
C>lx:>W[1>B>(>-!
;B`e;o
5=;pN=
>R' >z
!=>]
|P>]
g3>z
)>R' >b
xi=;pN=
{r;'
>R' >
m4>m
ZS>-
-r>HP|>
>HP|>
J*>R' >
?F<N
h=J{
H?>:#J>+
U>:#J>
m4>z
)>-!
=R' =
sW=k+v=(
>B>(>
g3>m
>>:#J>=
U>w-a>
l>w-a>=
U>:#J>m
g3>B>(>
=k+v=
:=R' =
#<B`
d*;u
Sc=n
%>W[1>
U>w-a>
\m>~
\m>w-a>+
!=>W[1>
Jj<1
d*;RI
=W[1=
..>lx:>]
ZS>]
F>lx:>
AO=W[1=
5<HP
7;RI
|P>-
:_)K;|
?$=\
Sc=o
/>>y
2>I.?>_
6Z>_
L>I.?>
%>>y
/>n4
Sc=\
;_)K;4
+=_)K=
(m=p
q,>#
q?_
q?h
q,>d;
(m=_)K=V
ew=r
\m>HP|>
c?r
>HP|>
%>>y
ew=a
2=tF
:B`e;
9=d]\=I
=d]\=Z
9=Qk
u`<RI
;B`e;
=R' =
d=&S
:p>7
R&?t
@=R' =
l=q=
~*>Gr9>p
H>>yX>
f%?=
+?-C,?
,?-C,?
h>>yX>p
H>Gr9>
{r<U
:0>[
_>iop>I
;.?{
;.?$
@"?$
>iop>
G!><
;X94<
fU=$
>ff&>
y'?u
c,?r
0?EG2?}
7?^K8?Y
8?^K8?
+5?}
3?EG2?
c,?u
y'?j
8V>9
5>ff&>
fU=|
<X94<B`
?n4 ?
,?I./?
1?I./?D
#?n4 ?
E6=tF
u >io0>
t>J{
$?B>(?
1?X94?
6?X94?
+?B>(?
@>io0>
@=B>h=
$>F%5>
sW>gDi>
V?E
%?gD)?
,?R'0?
S3?0L6?
>?R'@?
8E?a
B?R'@?_
9?0L6?
S3?R'0?
,?gD)?"
V?0
~{>gDi>
F>F%5>/
=B>h=
B<HP
41?4
=?io@?
H?q=J?
~K?(~L?6<M?H
M?6<M?(~L?
~K?q=J?U
B?io@?d
41?h
4o>v
WJ=F
s=Nb
->[B>>r
4!?"
1?]m5?
I<?Di??aTB?
O?2UP?
aQ?2UP?
E?aTB?Di??
8?]m5?
3b>r
O>[B>>V
=yX(=
N=Gry=*
0>%uB>
8g>5^z>
?n4 ?
$?gD)?h
F?GrI?
HN?2UP?
&R?F
V?p_W?
W?p_W?
&R?2UP?
K?GrI?}
-?gD)?
$?n4 ?
>5^z>
T>%uB>|
=Gry=
N=yX(=
Q<KY
S#>4
#?B>(?
41?]m5?c
A?o
X?GrY?
Z??W[?
[?h"\?h"\?
[??W[?
Z?GrY?~
\=?c
9?]m5?
,?B>(?
S#><
ZS=V
Y<RI
sW=n
qJ>RI]>
+?R'0?4
D?yXH?q
Q?tFT?}
Z?HP\?
_?R'`?
h`?R'`?$
]?HP\?h
V?tFT?n
K?yXH?
4?R'0?
p>RI]>
qJ>~
sW=2
<RI
~;>_
|@?o
D?yXH?
UO?A
R?]mU?~
c?=,d?Ttd?Ttd?=,d?
X?]mU?A
K?yXH?o
Ga>_
~;>
y'?D
1?0L6?
:?Di??
UO?X
.^?Nb`?aTb?
d?]me?
eg?+
Dh?+
f?]me?
d?aTb?Nb`?
UO?q
C?Di??
:?0L6?
V,>,
<B`e<
b='1
rh>[
*?I./?X94?
=?aTB?}
U?gDY?
I\?gDY?
F?aTB?d
9?X94?I./?u
rh>O
/>G
<B`e<
=5^:=B`e=q=
k>n4
;?io@?
E?GrI?
Q?]mU?
&b?O
(l?mVm??5n?
n??5n?mVm?
X?]mU?n
M?GrI?
E?io@?
=B`e=5^:=
<=B>h=
q?aT
:P?tFT?~
m?-!o?
Np?-!o?
X?tFT?
a!>r
=B>h=[
4o<z6
9#>X
\>W[q>
f%?
;?R'@?
g?U0j?
n?2Up?N
q?2Up?
l?U0j?
E?R'@?C
>W[q>?
(m=M
G!?=
,?EG2?
K?2UP?O
\?Nb`?}
?t?]mu?KYv?
v?KYv?]mu?
?t?<
c?Nb`?$
T?2UP?
7?EG2?$
G!?Zd
{r<V}
>0L&>l
;.?}
&R?+
^?aTb?
t?KYv?
w?>yx?
y?,ey?,ey?
y?>yx?
w?KYv?
e?aTb?
J9?}
9>0L&>tF
4o=\
B=Qk
2D= Aq=
'>lx:>
!N>x
8E?q=J?
X?HP\?
m?2Up?<
v?'1x?
ky?'1x?
r?2Up?
H`?HP\?~
O?q=J?
+5?{
!N>lx:>
= Aq=
t<RI
=]mE=
;>`vO>x
~K?2UP?
U?GrY?
a?]me?5
(l?-!o?N
?t?KYv?'1x?^
{?(~|?
|?(~|?
y?'1x?KYv?
?t?N
q?-!o?
(l?5
h?]me?
]?GrY?
U?2UP?
=y>x
d>`vO>
{r=]mE=
u<RI
ew<3
?F=F
+e>lxz>B>
eG?(~L?
aQ?4
j?mVm?
Np?S
s?]mu?
/|?q
w?]mu?S
Np?mVm?
aQ?(~L?
>lxz>
^)>=
?F=RI
)>6<=>
e>Zd{>9
R&?-C,?
$H?6<M?
V??W[?$
eg?c
j??5n?
s?KYv?>yx?
Wz?>yx?KYv?
4q??5n?c
_??W[?
&R?6<M?
2?-C,?
A ?:#
>Zd{>
4Q>6<=>
Yu=*
2?^K8?
R?p_W?
[?R'`?=,d?+
z?(~|?H
}?(~|?
g?=,d?R'`?
[?p_W?
=?^K8?\
d*>+
f>HP|>L7
W?h"\?
h`?Ttd?
Dh?6
>w?,ey?
C{?,ey?
Dh?Ttd?
h`?h"\?
!>?Y
>HP|>B
 <X9
f>HP|>L7
W?h"\?
h`?Ttd?
Dh?6
>w?,ey?
C{?,ey?
Dh?Ttd?
h`?h"\?
!>?Y
>HP|>B
 <X9
Yu=*
2?^K8?
R?p_W?
[?R'`?=,d?+
z?(~|?H
}?(~|?
g?=,d?R'`?
[?p_W?
=?^K8?\
d*>+
)>6<=>
e>Zd{>9
R&?-C,?
$H?6<M?
V??W[?$
eg?c
j??5n?
s?KYv?>yx?
Wz?>yx?KYv?
4q??5n?c
_??W[?
&R?6<M?
2?-C,?
A ?:#
>Zd{>
4Q>6<=>
ew<3
?F=F
+e>lxz>B>
eG?(~L?
aQ?4
j?mVm?
Np?S
s?]mu?
/|?q
w?]mu?S
Np?mVm?
aQ?(~L?
>lxz>
^)>=
?F=RI
=]mE=
;>`vO>x
~K?2UP?
U?GrY?
a?]me?5
(l?-!o?N
?t?KYv?'1x?^
{?(~|?
|?(~|?
y?'1x?KYv?
?t?N
q?-!o?
(l?5
h?]me?
]?GrY?
U?2UP?
=y>x
d>`vO>
{r=]mE=
u<RI
2D= Aq=
'>lx:>
!N>x
8E?q=J?
X?HP\?
m?2Up?<
v?'1x?
ky?'1x?
r?2Up?
H`?HP\?~
O?q=J?
+5?{
!N>lx:>
= Aq=
t<RI
{r<V}
>0L&>l
;.?}
&R?+
^?aTb?
t?KYv?
w?>yx?
y?,ey?,ey?
y?>yx?
w?KYv?
e?aTb?
J9?}
9>0L&>tF
4o=\
B=Qk
(m=M
G!?=
,?EG2?
K?2UP?O
\?Nb`?}
?t?]mu?KYv?
v?KYv?]mu?
?t?<
c?Nb`?$
T?2UP?
7?EG2?$
G!?Zd
4o<z6
9#>X
\>W[q>
f%?
;?R'@?
g?U0j?
n?2Up?N
q?2Up?
l?U0j?
E?R'@?C
>W[q>?
<=B>h=
q?aT
:P?tFT?~
m?-!o?
Np?-!o?
X?tFT?
a!>r
=B>h=[
=5^:=B`e=q=
k>n4
;?io@?
E?GrI?
Q?]mU?
&b?O
(l?mVm??5n?
n??5n?mVm?
X?]mU?n
M?GrI?
E?io@?
=B`e=5^:=
<B`e<
b='1
rh>[
*?I./?X94?
=?aTB?}
U?gDY?
I\?gDY?
F?aTB?d
9?X94?I./?u
rh>O
/>G
<B`e<
y'?D
1?0L6?
:?Di??
UO?X
.^?Nb`?aTb?
d?]me?
eg?+
Dh?+
f?]me?
d?aTb?Nb`?
UO?q
C?Di??
:?0L6?
V,>,
~;>_
|@?o
D?yXH?
UO?A
R?]mU?~
c?=,d?Ttd?Ttd?=,d?
X?]mU?A
K?yXH?o
Ga>_
~;>
Y<RI
sW=n
qJ>RI]>
+?R'0?4
D?yXH?q
Q?tFT?}
Z?HP\?
_?R'`?
h`?R'`?$
]?HP\?h
V?tFT?n
K?yXH?
4?R'0?
p>RI]>
qJ>~
sW=2
<RI
S#>4
#?B>(?
41?]m5?c
A?o
X?GrY?
Z??W[?
[?h"\?h"\?
[??W[?
Z?GrY?~
\=?c
9?]m5?
,?B>(?
S#><
ZS=V
=yX(=
N=Gry=*
0>%uB>
8g>5^z>
?n4 ?
$?gD)?h
F?GrI?
HN?2UP?
&R?F
V?p_W?
W?p_W?
&R?2UP?
K?GrI?}
-?gD)?
$?n4 ?
>5^z>
T>%uB>|
=Gry=
N=yX(=
Q<KY
WJ=F
s=Nb
->[B>>r
4!?"
1?]m5?
I<?Di??aTB?
O?2UP?
aQ?2UP?
E?aTB?Di??
8?]m5?
3b>r
O>[B>>V
41?4
=?io@?
H?q=J?
~K?(~L?6<M?H
M?6<M?(~L?
~K?q=J?U
B?io@?d
41?h
4o>v
@=B>h=
$>F%5>
sW>gDi>
V?E
%?gD)?
,?R'0?
S3?0L6?
>?R'@?
8E?a
B?R'@?_
9?0L6?
S3?R'0?
,?gD)?"
V?0
~{>gDi>
F>F%5>/
=B>h=
B<HP
u >io0>
t>J{
$?B>(?
1?X94?
6?X94?
+?B>(?
@>io0>
?n4 ?
,?I./?
1?I./?D
#?n4 ?
E6=tF
;X94<
fU=$
>ff&>
y'?u
c,?r
0?EG2?}
7?^K8?Y
8?^K8?
+5?}
3?EG2?
c,?u
y'?j
8V>9
5>ff&>
fU=|
<X94<B`
:0>[
_>iop>I
;.?{
;.?$
@"?$
>iop>
G!><
l=q=
~*>Gr9>p
H>>yX>
f%?=
+?-C,?
,?-C,?
h>>yX>p
H>Gr9>
{r<U
=R' =
d=&S
:p>7
R&?t
@=R' =
:B`e;
9=d]\=I
=d]\=Z
9=Qk
u`<RI
;B`e;
ew=r
\m>HP|>
c?r
>HP|>
%>>y
ew=a
2=tF
+=_)K=
(m=p
q,>#
q?_
q?h
q,>d;
(m=_)K=V
:_)K;|
?$=\
Sc=o
/>>y
2>I.?>_
6Z>_
L>I.?>
%>>y
/>n4
Sc=\
;_)K;4
|P>-
=W[1=
..>lx:>]
ZS>]
F>lx:>
AO=W[1=
5<HP
7;RI
d*;u
Sc=n
%>W[1>
U>w-a>
\m>~
\m>w-a>+
!=>W[1>
Jj<1
d*;RI
=R' =
sW=k+v=(
>B>(>
g3>m
>>:#J>=
U>w-a>
l>w-a>=
U>:#J>m
g3>B>(>
=k+v=
:=R' =
#<B`
h=J{
H?>:#J>+
U>:#J>
m4>z
)>-!
>R' >
m4>m
ZS>-
-r>HP|>
>HP|>
J*>R' >
?F<N
5=;pN=
>R' >z
!=>]
|P>]
g3>z
)>R' >b
xi=;pN=
{r;'
;B`e;X9
c<)\
>B>(>W[1>lx:>
C>lx:>W[1>B>(>-!
;B`e;o
T<KY
L=B`e=I.
..>}
6>I.?>
h>iop>~
x>iop>
DX>r
G>I.?>}
c>]
=B`e=
:_)K;RI
=yX(=
m=J{
P>>yX>
_>>yX>
kI>n
v>=yX(=
;_)K;
?F=d]\=F
8V>?
c>gDi>
t>5^z>$
>5^z>
4o>gDi>
s=d]\=
<;p
d*;KY
d*<b
ew=p_
2>Gr9>[
sW>v
8g>1
|>n4
3b>v
?>Gr9>
%>d;
Ga=:
d*<o
Q9RI
{r<N
=yX(=
x=p_
/>aT
X>RI]>
Ga>f
n>W[q>}
=y>lxz>Zd{>
|>HP|>HP|>
|>Zd{>lxz>
s>W[q>
rh>f
Ga>RI]>P
/>o
/;=yX(=
y;RI
<X94<
=z6+=6<==
ew=o
G!>ff&>
+>io0>F%5>
9>[B>>%uB>
qJ>_
QZ>?
+e>x
F>%uB>[B>>
9>F%5>io0>
+>ff&>
P=6<==z6+=u
/]<X94<r
;_)K;
{r<)\
q,=6<==
Ga=F
s=J{
u >/
!N>`vO>
|P>`vO>
2D>7
~;>~
N=6<==
;_)K;o
7;KY
=z6+=
/;=:
K=d]\=D
m=I.
V,>i
9>lx:>
<>6<=>
=>6<=>
;>lx:>l
u1>i
V,>
m=d]\=:
/;=z6+=
=yX(=Y
U=B`e=
9#>/
$>0L&>
d*>1
'>0L&>/
Yu=B`e=
?F=Y
7=yX(=u
{r<M
7x=J{
/>:#
O/<N
=yX(=
A=;pN=
h=k+v=n
=k+v=
[=;pN=
5=yX(=
ew<b
7:RI
j<<>
ew<M
ew<>
j<<b
ew=I
{r<b
DX;'
3"<4
=R' =U
(=W[1=Z
B=_)K=a
S=d]\=
d=d]\=a
S=_)K=\
9=W[1=U
(=R' =P
7;B`e;
?$=V
b=B>h=D
s=Gry=
\~=n
\~=Gry=F
m=B>h=e
?$=v
;B`e;4
{r<&
=R' =T
b=B`e=B>h=h
4o= Aq=
{r=F
{r= Aq=
(m=h
j=B>h=B`e=e
WJ=9
E6=|
%=R' =Qk
k:RI
>;B`e;'
#<X94<
z<KY
$=yX(=V
7=5^:=[
2D=]mE=
?F=]mE=
2D=\
<=5^:=
-2=2
+=yX(=
D<X94<
;B`e;
>;RI
DX;$
d*<4
?F<4
DX;4
Q:RI
Q9RI
k:RI
Q9RI
k;KY
Q:RI
Q9RI
7;_)K;
y;KY
3"<U
-<X94<
b<B`e<
4o<E
{r<!
ew<l
{r<E
h<B`e<e
#9<X94<
3"<RI
^;_)K;4
7:RI
Q9RI
d*;4
7;_)K;
DX;B`e;
{r;o
{r;B`e;
DX;_)K;4
d*;RI
7:RI
Q9RI
d*;4
>;_)K;
DX;B`e;
{r;l
k;B`e;
Q;_)K;
#;RI
7:RI
Q9RI
7:RI
Q9RI
N6vision3mod22ImageClassifierGlimmerE
N6vision3mod23ImageClassifierAbstractE
NSt3__120__shared_ptr_emplaceIN6vision3mod22ImageClassifierGlimmer9private_tENS_9allocatorIS4_EEEE
N6vision3mod20ObjectTrackerOptionsE
N6vision3mod21ObjectTrackerAbstractE
NSt3__120__shared_ptr_pointerIPN6vision3mod20ObjectTrackerOptionsENS_10shared_ptrIS3_E27__shared_ptr_default_deleteIS3_S3_EENS_9allocatorIS3_EEEE
NSt3__110shared_ptrIN6vision3mod20ObjectTrackerOptionsEE27__shared_ptr_default_deleteIS3_S3_EE
NSt3__120__shared_ptr_emplaceIN4cvml4util23mapped_model_file_fopenENS_9allocatorIS3_EEEE
N4cvml4util23mapped_model_file_fopenE
N4cvml4util17mapped_model_fileE
NSt3__117bad_function_callE
NSt3__120__shared_ptr_emplaceIN4cvml4util22mapped_model_file_openENS_9allocatorIS3_EEEE
N4cvml4util22mapped_model_file_openE
N5apple6vision20CVPixelBufferWrapper13LockExceptionE
Q8@'1
E@q=
4B333?
N6vision3mod20EspressoFloatElemPtrE
N6vision3mod15EspressoElemPtrE
N6vision3mod21EspressoUint16ElemPtrE
N6vision3mod20EspressoUint8ElemPtrE
NSt3__120__shared_ptr_pointerIPN6vision3mod30ImageAnalyzer_CustomClassifierENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIN6vision3mod30ImageAnalyzer_CustomClassifierEEE
NSt3__120__shared_ptr_emplaceINS_6vectorINS_10shared_ptrIN6vision3mod30ImageAnalyzer_CustomClassifierEEENS_9allocatorIS6_EEEENS7_IS9_EEEE
NSt3__120__shared_ptr_emplaceIKNS_6vectorINS_5tupleIJNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEfbEEENS6_IS9_EEEENS6_ISC_EEEE
NSt3__120__shared_ptr_emplaceIN6vision3mod33ImageClassifier_HierarchicalModelENS_9allocatorIS3_EEEE
N6vision3mod37ImageDescriptorProcessorHyperplaneLSHE
NSt3__120__shared_ptr_pointerIPN6vision3mod21ObjectTrackerAbstractENS_10shared_ptrIS3_E27__shared_ptr_default_deleteIS3_S3_EENS_9allocatorIS3_EEEE
NSt3__110shared_ptrIN6vision3mod21ObjectTrackerAbstractEE27__shared_ptr_default_deleteIS3_S3_EE
NSt3__120__shared_ptr_emplaceIN6vision3mod11FaceIDModelENS_9allocatorIS3_EEEE
?N6vision3mod13CVMLCancellerE
NSt3__120__shared_ptr_emplaceIN6vision3mod30ConcreteFaceprintAndAttributesENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_pointerIPN6vision3mod28ImageDescriptorBufferFloat32ENS_10shared_ptrIS3_E27__shared_ptr_default_deleteIS3_S3_EENS_9allocatorIS3_EEEE
NSt3__110shared_ptrIN6vision3mod28ImageDescriptorBufferFloat32EE27__shared_ptr_default_deleteIS3_S3_EE
NSt3__120__shared_ptr_pointerIPfPFvPvENS_9allocatorIfEEEE
PFvPvE
3ForMFor
NSt3__120__shared_ptr_emplaceIN6vision3mod19LandmarkDetectorDNNENS_9allocatorIS3_EEEE
N6vision3mod15GreedyClustererE
N6vision3mod20GreedyClustererFacesE
N6vision3mod14FaceClusteringE
NSt3__120__shared_ptr_pointerIPN4cvml4util12BackedBufferINS2_15RAMBackingStoreEEENS_10shared_ptrIS5_E27__shared_ptr_default_deleteIS5_S5_EENS_9allocatorIS5_EEEE
NSt3__110shared_ptrIN4cvml4util12BackedBufferINS2_15RAMBackingStoreEEEE27__shared_ptr_default_deleteIS5_S5_EE
NSt3__120__shared_ptr_pointerIPN4cvml4util15RAMBackingStoreENS_10shared_ptrIS3_E27__shared_ptr_default_deleteIS3_S3_EENS_9allocatorIS3_EEEE
NSt3__110shared_ptrIN4cvml4util15RAMBackingStoreEE27__shared_ptr_default_deleteIS3_S3_EE
NSt3__120__shared_ptr_pointerIPKN4cvml4util12BackedBufferINS2_15RAMBackingStoreEEENS_10shared_ptrIS6_E27__shared_ptr_default_deleteIS6_S6_EENS_9allocatorIS6_EEEE
NSt3__110shared_ptrIKN4cvml4util12BackedBufferINS2_15RAMBackingStoreEEEE27__shared_ptr_default_deleteIS6_S6_EE
NSt3__120__shared_ptr_emplaceINS_6vectorIhNS_9allocatorIhEEEENS2_IS4_EEEE
NSt3__120__shared_ptr_emplaceIN6vision3mod20GreedyClustererFacesENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN6vision3mod15GreedyClusterer9private_tENS_9allocatorIS4_EEEE
NSt3__120__shared_ptr_emplaceINS_6vectorImNS_9allocatorImEEEENS2_IS4_EEEE
NSt3__120__shared_ptr_emplaceINS_6vectorINS_4pairImmEENS_9allocatorIS3_EEEENS4_IS6_EEEE
17VNNSDataStreambuf
24VNNSMutableDataStreambuf
N6vision3mod19ScreenGazePredictorE
NSt3__120__shared_ptr_emplaceIN6vision3mod27ScreenGazePredictorConcreteENS_9allocatorIS3_EEEE
N6vision3mod27ScreenGazePredictorConcreteE
NSt3__120__shared_ptr_emplaceIN6vision3mod16TapToBoxConcreteENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_pointerIPfZN6vision3mod28readBinSerializedModelValuesEP7__sFILEPKcRKNS3_26BinSerializedModelFileInfoERNS3_11ModelValuesEbE3$_0NS_9allocatorIfEEEE
ZN6vision3mod28readBinSerializedModelValuesEP7__sFILEPKcRKNS0_26BinSerializedModelFileInfoERNS0_11ModelValuesEbE3$_0
NSt3__120__shared_ptr_pointerIPhZN6vision3mod28readBinSerializedModelValuesEP7__sFILEPKcRKNS3_26BinSerializedModelFileInfoERNS3_11ModelValuesEbE3$_1NS_9allocatorIhEEEE
ZN6vision3mod28readBinSerializedModelValuesEP7__sFILEPKcRKNS0_26BinSerializedModelFileInfoERNS0_11ModelValuesEbE3$_1
NSt3__120__shared_ptr_emplaceI17espresso_buffer_tNS_9allocatorIS1_EEEE
NSt3__120__shared_ptr_emplaceIN6vision3mod32ImageDescriptor_EspressoSmartCamENS_9allocatorIS3_EEEE
N6vision3mod32ImageDescriptor_EspressoSmartCamE
NSt3__120__shared_ptr_emplaceIN6vision3mod12FaceID3ModelENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_pointerIPN6vision3mod12FaceID3ModelENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIN6vision3mod12FaceID3ModelEEE
f00Lh00L800L
N6vision3mod17PetprintGeneratorE
NSt3__120__shared_ptr_emplaceIN6vision3mod25PetprintGeneratorConcreteENS_9allocatorIS3_EEEE
N6vision3mod25PetprintGeneratorConcreteE
NSt3__120__shared_ptr_emplaceIN6vision3mod28ImageDescriptorAugmenterNoOpENS_9allocatorIS3_EEEE
N6vision3mod28ImageDescriptorAugmenterNoOpE
N6vision3mod32ImageDescriptorAugmenterAbstractE
NSt3__120__shared_ptr_emplaceIN6vision3mod28ImageDescriptorAugmenterFlipENS_9allocatorIS3_EEEE
N6vision3mod28ImageDescriptorAugmenterFlipE
NSt3__120__shared_ptr_pointerIPN6vision3mod29ImageDescriptorBufferAbstractENS_10shared_ptrIS3_E27__shared_ptr_default_deleteIS3_S3_EENS_9allocatorIS3_EEEE
NSt3__110shared_ptrIN6vision3mod29ImageDescriptorBufferAbstractEE27__shared_ptr_default_deleteIS3_S3_EE
NSt3__120__shared_ptr_pointerIPKhZN4cvml4util31binserialized_table_of_contents9blob_infoC1ES2_RK26_BinSerializer_blobHeader_EUlS2_E_NS_9allocatorIS1_EEEE
ZN4cvml4util31binserialized_table_of_contents9blob_infoC1EPKhRK26_BinSerializer_blobHeader_EUlS4_E_
NSt3__120__shared_ptr_pointerIPfNS_14default_deleteIA_fEENS_9allocatorIfEEEE
NSt3__114default_deleteIA_fEE
NSt3__120__shared_ptr_emplaceIN6vision3mod18FaceBoxPoseAlignerIaEENS_9allocatorIS4_EEEE
NSt3__120__shared_ptr_emplaceIN6vision3mod23ImageClassifierEspressoENS_9allocatorIS3_EEEE
3PIVldmt
N6vision3mod17RPNTrackerOptionsE
N6vision3mod16ObjectTrackerRPNE
N6vision3mod30ImageDescriptorProcessorHasherE
N6vision3mod32ImageDescriptorProcessorAbstractE
NSt3__120__shared_ptr_emplaceIN6vision3mod28ImageDescriptorBufferFloat32ENS_9allocatorIS3_EEEE
333333
?ffffff
/dev/null
< %-8s > 
Emergency
Alert
Critical
Error
Warning
Notice
Info
Verbose
Pixel format (%d) not supported!
Pixel format (%d), model (%d), or stretch (%d) not supported!
Invalid source image!
Invalid instanceResult buffer!
Output buffer size incorrect!
Invalid output buffer rowBytes (%d)!
rtcv::simCropResize failed!
Invalid exemplarResult buffer!
TtResult modelInfo.numModels (%d) out of bounds!
Incorrect trk node state version (%u vs %u)
Numbers of net outputs (%d) more than limit!
Numbers of net outputs (%d) isn't correct!
GeomTransform_constructor: unknown transform model (%d)
GeomTransform_minSupportPoints: unknown transform model (%d), reset to RIGID
GeomTransform_changeCoordinateSystem failed
GeomTransform_setModel: unknown new model (%d) use the old model (%d)
GeomTransform_estimate: unknown transform model (%d) use RIGID
GeomTransform_numTestsToDo: unknown transform model (%d) use RIGID
RigidTransform_estimate: not symmetric positive definite matrix
RigidTransform_estimate: the %ld-th argument is wrong in sposv_ call
AffineTransform_estimate: not symmetric positive definite matrix
AffineTransform_estimate: the %ld-th argument is wrong in sposv_ call
HomographyTransform_estimate:The %ld-th eigenvector failed to converge
HomographyTransform_estimate:The %ld-th eigenvector failed to converge
HomographyTransform_estimate: the %ld-th argument is wrong in ssyevx_ call
HomographyTransform_estimate: the %ld-th argument is wrong in ssyevx_ call
HomographyTransform_estimate: the 9-th parameter is too small pp[8]=%f 
IPDetector_constructor: Cannot allocate mFltImage 
IPDetector_constructor: Cannot allocate box filter
IPDetector_constructor: Cannot allocate mTmpBuffer 
IPDetector_constructor: Cannot allocate mCornerVec 
IPDetector_constructor: Cannot allocate mBX, mBY 
IPDetector_response: box filter failed
v16@?0i8i12
boxFilter_uint8_init: box filter failed when request minimum size err=%d
boxFilter_uint8: box filter failed err=%d
 invMatrix failed INFO1 = %ld
 invMatrix failed INFO2 = %ld
%s : calloc failed
ImageRegistrationCreateContext
%s : CFDictionaryCreateMutable failed
%s : CFArrayCreateMutable failed
%s : RegistrationEngine_constructor failed
imageRegQueue
%s : dispatch_queue_create failed
%s : NULL input parameters
ImageRegister
%s : Need at least one non-reference image
%s : CFArrayGetCount(imageRegCtx->availExtraBuffers) != 0
%s : Could not locate scratch buffers
GeomTransform_estimate failed
Pyramid_loadImage: incompatible size in pyramid (%lu!=%lu) or (%lu!=%lu)
v40@?0^Q8^Q16Q24Q32
WARNING: insufficient number of external corners provided (only %hu corners provided but minumum is %d)
Registration could not detect more that %d inlier corners at the highest resolution.
unexpected keypoint type %@
OrderedKeypoints
ordered keypoints are not available
detectorType
unable to lock base address of pixelBuffer
Model runtime error, Unable to bind output buffer
Model runtime error, Unable to bind input buffer
error occured when running model
error occured when running model, unexpected output received
mask
bbox
saliency_attention_box_head_i4fgq3rswb_fp16.espresso
saliency_objectness_boxes_head_ecvqeduzc7_46800_fp16.espresso
%@ is handled by %@
VNDetectHumanHeadRectanglesRequestPrivateRevisionANODv3
VNDetectHumanHeadRectanglesRequestPrivateRevisionANODv4
VNDetectHumanHeadRectanglesRequestPrivateRevisionANSTModel
 = [
%@:%@
%@ must override %@ with a specific implementation
Failure to create face quality predictor
face quality of %f is out of range
com.apple.cvml.%@
CVML module = %@
VNANFDMultiDetectorProcessingOption_AnimalHeadsRecognitionOriginatingRequestSpecifier
VNANFDMultiDetectorProcessingOption_SportBallsRecognitionOriginatingRequestSpecifier
CVML_debug_enable_cluster_log
en_US_POSIX
yyyy-MM-dd_HH-mm-ss-SSS
VNClusteringLog
%@_%@.log
Level %@ cluster map:
ClusterId: %lld
%@Faces: 
%lld
0 Lookup
1 Lookup
VNSuggestionLog
Input query - face IDs with flags (clusterIdsWithFlags):
faceId: %@
%@can be returned: %@
Suggested face IDs: %@:
ClusterId: %@   
%@Suggestions: 
%@, 
all sugestions for given input query (suggestionLists)
filtered suggestions to include only those that are part of input query (suggestedInputsLists)
Connected groups of suggestions face IDs (connectedSuggestedInputs):
Group %d suggestions: 
Final list of suggestions face IDs (results):
Invalid cache file path: %@
VNClusterOptionClusteringAlgorithm must be set to either VNClusteringAlgorithm_Greedy or VNClusteringAlgorithm_GreedyWithTorso
Creating clustering parameters object failed for following face and torsoprint revisions: %lu and %lu and algorith type: %@
Error initializing cluster state
v32@?0@"VNFaceTorsoprint"8Q16^B24
Internal error querying similar faces
getting clusters failed with error: %lld
getLevel1ClusteredIdsGroupedByLevel0ClustersForFaceId: faceId (%@) is not initialized
getLevel1ClusteredIdsGroupedByLevel0ClustersForFaceId: There is no level-1 cluster that contains faceId = %d
getLevel1ClusteredIdsGroupedByLevel0ClustersForFaceId: Level-1 cluster size is zero for a valid clusterID descriptor (%lld)
B32@?0@"NSNumber"8@"NSMutableOrderedSet"16^@24
Parameter validation failed for getDistanceBetweenLevel1Clusters
B24@?0@"VNFaceObservation"8@"NSDictionary"16
Cache file path is a required parameter
RestoreClusteringState is a required parameter
Clustering request was canceled, error: %llu
Creating clustering parameters object failed for following face and torsoprint revisions: %lu and %lu and algorithm type: %@
Clustering with greedy algorithm
Unexpected type of object for clustering
adding faces (%lu): %s
Faces to add must be accompanied by grouping identifiers when performing clustering in torso mode.
Faces to add array must be the same size as that of the grouping identifiers array.
Clusters:
  %d: prevcount=%d, curcount=%d, shouldUpdateRep = %d
clusters:
  clusterId: %ld, %s
image
person_instances_1:0
person_instances_2:0
person_instances_3:0
person_instances_4:0
HyperDETR-u8-v1.1.espresso
person_instance_confidences:0
VNSegmentationGenerator - internal error in number confidence buffers
VNSegmentationGenerator - internal error calculating confidence index
VNSegmentationGenerator - internal error in number confidence buffer names
VNFaceAnalyzerMultiDetectorObservationGroupsForRequests
VNFaceAnalyzerMultiDetectorProcessingOptionCreateFaceprint
VNFaceAnalyzerMultiDetectorProcessingOptionCreateFaceAnalyzer
VNFaceAnalyzerMultiDetectorProcessingOptionFaceprintOriginatingRequestSpecifier
VNFaceAnalyzerMultiDetectorProcessingOptionFaceAnalyzerOriginatingRequestSpecifier
VNFaceAnalyzerMultiDetectorProcessingOptionFaceObservations
VNFaceAnalyzerMultiDetectorProcessingOptionFaceprintForceFaceprintCreation
VNFaceAnalyzerMultiDetectorProcessingOptionFaceprintConfidence
VNFaceprintGeneratorTypeEspressoCPU
%@:%s
%@ must override %@
Method not implemented
Failure to create face multi-headed classifier.
VNClusterOptionCacheFolderPath
VNClusterOptionClusteringAlgorithm
VNClusterOptionRestoreClusteringState
VNClusterOptionAddObjectsToClustering
VNClusterOptionAddObjectGroupIdsToClustering
VNClusterOptionRemoveObjectsFromClustering
VNClusterOptionFaceprintRevision
VNClusterOptionTorsoprintRevision
VNClusterOptionInputThreshold
VNClusterOptionInputTorsoThreshold
VNClusterOptionVectorMapReadOnlyFlag
Invalid Clusterer cache directory: %@
Invalid Clusterer type: %@
Invalid Faceprint revision: %lu
Failed to create clusterer; Error = %@
Suggestions request has been cancelled
Clustering request has been cancelled
%@ is no longer supported by Vision
%@ is not a registered class code
%@ does not have a registry entry
Request
VNVYvzEtX1JlUdu8xx5qhDI
VN6kBnCOr2mZlSV6yV1dLwB
VN5kJNH3eYuyaLxNpZr5Z7zi
%@ is not a VNRequest subclass
VNAlignFaceRectangleRequest
VNANFDDetectorCompoundRequest
VNAppendBurstSequenceFrameRequest
VNClassifyCityNatureImageRequest
VNClassifyFaceAttributesRequest
VNClassifyImageAestheticsRequest
VNClassifyImageRequest
VNClassifyJunkImageRequest
VNClassifyMemeImageRequest
VNClassifyPotentialLandmarkRequest
VN6Mb1ME89lyW3HpahkEygIG
VNCreateDetectionprintRequest
VNCreateFaceRegionMapRequest
VNCreateFaceprintRequest
VNCreateFaceTorsoprintRequest
VNCreateImageFingerprintsRequest
VNCreateNeuralHashprintRequest
VNCreateSceneprintRequest
VNCreateSmartCamprintRequest
VNCreateTorsoprintRequest
VNDetectContoursRequest
VNDetectDocumentSegmentationRequest
VNDetectFaceCaptureQualityRequest
VNDetectFace3DLandmarksRequest
VNDetectFaceExpressionsRequest
VNDetectFaceGazeRequest
VNDetectFacePoseRequest
VNDetectFaceRectanglesRequest
VNDetectHorizonRequest
VNDetectHumanBodyPoseRequest
VNDetectHumanHandPoseRequest
VNDetectHumanHeadRectanglesRequest
VNDetectHumanRectanglesRequest
VNDetectObjectAtPointRequest
VNDetectRectanglesRequest
VNDetectScreenGazeRequest
VNDetectTextRectanglesRequest
VNDetectTrajectoriesRequest
VNFaceAnalyzerCompoundRequest
VNGenerateAnimalSegmentationRequest
VNGenerateAttentionBasedSaliencyImageRequest
VNGenerateFaceSegmentsRequest
VNGenerateImageFeaturePrintRequest
VNGenerateImageSaliencyRequest
VNGenerateObjectnessBasedSaliencyImageRequest
VN1JC7R3k4455fKQz0dY1VhQ
VNGeneratePersonSegmentationRequest
VNGeneratePersonSemanticsCompoundRequest
VNGenerateSkySegmentationRequest
VNGroupImagesByTimeAndContentRequest
VNHomographicImageRegistrationRequest
VNIdentifyJunkRequest
VNImageBlurScoreRequest
VNImageAnalyzerCompoundRequest
VNRecognizeAnimalsRequest
VNRecognizeAnimalHeadsRequest
VNRecognizeFoodAndDrinkRequest
VNRecognizeSportBallsRequest
VNRecognizeTextRequest
VNRecognizeDocumentElementsRequest
VNRecognizeDocumentsRequest
VNRemoveBackgroundRequest
VNSceneClassificationRequest
VNSmartCam5CompoundRequest
VNTrackHomographyRequest
VNTrackLegacyFaceCoreObjectRequest
VNTrackObjectRequest
VNTrackRectangleRequest
VNTranslationalImageRegistrationRequest
VNANFDMultiDetectorANFDv2
VNANFDMultiDetectorANODv3
VNANFDMultiDetectorANODv4
VNANFDMultiDetectorANSTv1
VNAnimalprintDetectorRevision1
VNAnimalprintDetectorPrivateRevision1MD2
VNBlurDetector
VNBrightnessDetector
VNContoursDetector
VNCoreMLTransformer
VNCRImageReaderDetector
VNCRImageReaderForDocumentsDetector
VNDetectionprintGenerator
VNDocumentSegmentationDetector
VNFaceAnalyzerMultiDetectorFPrev3_1FArev1_3_MD2
VNFaceAnalyzerMultiDetectorFArev2_CameraLightweight
VNFaceAnalyzerMultiDetectorFPrev3_1FArev1_3_MD3
VNFaceBBoxAligner
VNFaceDetectorPrivateRevisionLegacyFaceCore
VNFaceDetectorRevision2
VNFaceExpressionDetector
VNFaceGazeDetector
VNFaceGeometryEstimator
VNFaceLandmarkDetectorRevision2
VNFaceLandmarkDetectorRevision3
VNFaceprintGeneratorRevision1
VNFaceQualityGeneratorRevision1
VNFaceQualityGeneratorRevision2
VNFaceQualityGeneratorPrivateRevisionV3MD4
VNFaceRegionMapGenerator
VNFaceSegmentGenerator
VNGuidedUpsamplingGenerator
VNHomeAppFaceAnalyzerMultiDetectorFPrev3_1FArev1_3_MD3
VNHomographicImageRegistrationDetector
VNHomographyTracker
VNHorizonDetector
VNHumanBodyPoseDetector
VNHumanHandPoseDetector
VNImageAnalyzerMultiDetector
VN4nFZhnOcBOiJmeVWzBWsv
VNImageprintGenerator
VNImageRegistrationDetector
VNImageSignatureDetector
VNJunkIdentifier
VNMemeClassifier
VNMRCDetector
VNObjectAtPointDetectorRevision1
VNOpticalFlowGenerator
VNOpticalFlowGeneratorRevision1
VNOpticalFlowGeneratorRevision2
VNPanopticSegmentationGenerator
VNPersonSegmentationGeneratorInstanceBased4People
VNPersonSegmentationGeneratorSemantics
VNPersonSegmentationGeneratorFast
VNPersonSegmentationGeneratorLearnedMatting
VNPersonSegmentationGeneratorLearnedMattingTiled
VNRectangleDetector
VNRemoveBackgroundProcessor
VNSaliencyAHeatmapBoundingBoxGenerator
VNSaliencyOHeatmapBoundingBoxGenerator
VNSceneClassifier
VNScreenGazeDetector
VNSegmentationGenerator
VNSingleHeadSceneprintGenerator
VNSliderNetDetector
VNSmartCamClassifier
VNSmartCam5GatingDetector
VNSmartCamCombinedAestheticsAndSaliencyDetector
VNTorsoprintGeneratorPrivateRevision3MD2HumanDetectorBased
VNTorsoprintGeneratorPrivateRevision4MD2HomeAIHumanDetectorBased
VNTorsoprintGeneratorRevision1
Scream
Smile
label
Descriptor count = 
Descriptor length = 
 bytes
VNHomographyTrackerProcessOption_State
timeout exceeded
pet_v1_md2_fp16.espresso
Internal error creating sceneprint
Internal error while creating image signature print
%@ %lu %lu
no input buffer
invalid URL
Invalid argument
The image is invalid
could not obtain a supported image size for %@
unable to allocate results array for %@ elements
Invalid requestRevision %d requested
no supported image size available
%@ does not provide classification labels
%@ does not provide a model name
the image processing type is unknown
the image analysis failed
CVML_UNKNOWN_
( %@, %@ )
( %@, [ %@ ] )
%@ #%lu (%p)
attempting to re-assign ordered requests
%@ created
performing %@
performed %@
, failed with %@
%@ cached %@
%@ was already recorded as a cached result
%@ looked up %@
%@ hit %@
VNObjectAtPointDetectorProcessOption_InputPoint
tap_to_box.espresso
Failed to create tap to box converter object
Cannot parse input location point data
com.apple.vis
request %@ was cancelled
request was cancelled
VNRequest
unsupported serialized header version %u
%@ must be overridden
%@ does not support operation
missing option %@
option %@ has an invalid value of %@
 - %@
argument %@ has an invalid value of %@
%@ requires the GPU for processing
processing with %@ is not supported
The current configuration of %@ is not supported
%@ is not a supported request
session no longer available
: %s
%@ (%@)
%s (%@)
%@ - %@
vImage_Error %@
"%@"
DESIGN
BUILT
FAILURE
plan phase %u
VNBarcodeSymbologyAztec
VNBarcodeSymbologyCode39
VNBarcodeSymbologyCode39Checksum
VNBarcodeSymbologyCode39FullASCII
VNBarcodeSymbologyCode39FullASCIIChecksum
VNBarcodeSymbologyCode93
VNBarcodeSymbologyCode93i
VNBarcodeSymbologyCode128
VNBarcodeSymbologyDataMatrix
VNBarcodeSymbologyEAN8
VNBarcodeSymbologyEAN13
VNBarcodeSymbologyI2of5
VNBarcodeSymbologyI2of5Checksum
VNBarcodeSymbologyITF14
VNBarcodeSymbologyPDF417
VNBarcodeSymbologyQR
VNBarcodeSymbologyUPCE
VNBarcodeSymbologyAppClipCode
VNBarcodeSymbologyCodabar
VNBarcodeSymbologyGS1DataBar
VNBarcodeSymbologyGS1DataBarExpanded
VNBarcodeSymbologyGS1DataBarLimited
VNBarcodeSymbologyMicroPDF417
VNBarcodeSymbologyMicroQR
could not locate the face detection model file
Failed to align a detected bounding box
6ziz6uinva_opt.espresso
noMapping
1DAffineMapping
1DLogisticMapping
1DPairwiseAffineMapping
postProcessorType
basic_string
%@ %@
VNClassifyJunkImageRequestPrivateRevisionR14J8Model
VNClassifyJunkImageRequestPrivateRevisionSceneNetV4
VNClassifyJunkImageRequestPrivateRevisionStillCapturePipeline
VNClassifyJunkImageRequestPrivateRevisionSceneNetV4StillCapturePipeline
VNClassifyJunkImageRequestPrivateRevisionR14J9Model
VNClassifyJunkImageRequestPrivateRevisionSceneNetV5
VNClassifyJunkImageRequestPrivateRevisionSceneNetV5StillCapturePipeline
head_joint
left_eye_joint
right_eye_joint
left_ear_joint
right_ear_joint
left_shoulder_1_joint
right_shoulder_1_joint
neck_1_joint
left_forearm_joint
right_forearm_joint
left_hand_joint
right_hand_joint
left_upLeg_joint
right_upLeg_joint
root
left_leg_joint
right_leg_joint
left_foot_joint
right_foot_joint
VNBLKFACE
VNBLKTORSO
VNBLKLARM
VNBLKRARM
VNBLKLLEG
VNBLKRLEG
VNIPOAll
VNCRImageReaderDetectorCreationOption_FastRecognition
VNCRImageReaderDetectorCreationOption_MaximumCandidatesCount
VNCRImageReaderDetectorCreationOption_RecognitionLanguages
VNCRImageReaderDetectorCreationOption_UsesLanguageDetection
VNCRImageReaderDetectorCreationOption_UsesAlternateLineGrouping
VNCRImageReaderDetectorCreationOption_CRImageReaderRevisionKey
VNCRImageReaderDetectorCreationOption_RestrictToCPU
VNCRImageReaderDetectorCreationOption_CustomWords
VNCRImageReaderDetectorCreationOption_DisableLanguageCorrection
VNCRImageReaderDetectorProcessOption_OriginatingRequest
VNCRImageReaderDetectorProcessOption_MinimumTextHeight
VNRecognizeTextRequest produced an internal error
VNRecognizeTextRequest error - invalid orientation
The image is too small in at least one dimension %ld x %ld (each dimension has to be more than 2 pixels)
VNRequestHandlerCleanupOption_AllPipelines
VNRequestHandlerCleanupOption_FacePipeline
VNRequestHandlerCleanupOption_ScenePipeline
VNRequestHandlerCleanupOption_SmartCamPipeline
VNRequestHandlerCleanupOption_JunkPipeline
VNCleanupLevel_Complete
VNCleanupLevel_Partial
VNRequestHandlerCleanupOption_ImageBuffers
VNCleanupPurgeAll
VNTrackObjectPrivateRevisionLegacyFaceCoreProcessOption_MinFaceSize
VNTrackObjectPrivateRevisionLegacyFaceCoreProcessOption_NumberOfDetectionAngles
VNTrackObjectPrivateRevisionLegacyCoreProcessOption_EnhanceEyesAndMouthLocalization
VNTrackObjectPrivateRevisionLegacyFaceCoreProcessOption_ExtractBlink
VNTrackObjectPrivateRevisionLegacyFaceCoreProcessOption_ExtractSmile
VNTrackObjectPrivateRevisionLegacyFaceCoreProcessOption_KalmanFilter
Internal error: Unsupported/unimplemented tracking level by FaceCore
Internal error: Failed to initialize FaceCore detector
Internal error: Tracker is busy with previous tracking requests. It needs to be reset to restart tracking sequence
Internal error: Tracker is not initialized
VN6Ukf2f2QO979ttLvyg0ZAQ
 leaf=%lu hierarchy=%lu
the custom hierarchy is for request revision %lu, not %lu
VNSceneClassificationRequestPrivateRevisionSceneNetV4
VNSceneClassificationRequestPrivateRevisionSceneNetV5
seg_probs__0
0x%08X
tag %@ did not provide any data
failed to write to data stream
unavailable %@, %srevision %lu
private 
code
Cannot register equivalency of %@ %@ <==> %@: %@
nil request class
not a VNRequest subclass
Error while computing blur score: %s
Inconsistent platform
Internal error: internal type conversion failed
Internal error: unexpeted tracked object bounding box size
{?=qiIq}
No valid presentationTimeStamp was available for this image
VNFaceLandmarkDetectorType
VNFaceDetectorType
VNFaceBoxAlignerType
VNFaceGeometryEstimatorType
VNFaceRegionMapGeneratorType
VNFaceExpressionDetectorType
VNFaceSegmentGeneratorType
VNTorsoprintGeneratorDetectorType
VNFaceQualityGeneratorType
VNRectangleDetectorType
VNJunkIdentifierType
VNSingleHeadSceneprintGeneratorType
VNSmartCamClassifierType
VNImageprintGeneratorType
VNSmartCamCombinedAestheticsAndSaliencyDetectorType
VNAttentionBasedSaliencyHeatmapBoundingBoxGeneratorType
VNObjectnessBasedSaliencyHeatmapBoundingBoxGeneratorType
VNSaliencyHeatmapBoundingBoxGeneratorType
VNHorizonDetectorType
VNImageAnalyzerMultiDetectorType
VNFaceAnalyzerMultiDetectorType
VNANFDMultiDetectorType
VNOpticalFlowGeneratorType
VNContoursDetectorType
VNHumanBodyPoseDetectorType
VNHumanHandPoseDetectorType
VNDetectionprintGeneratorDetectorType
VNImageSignatureDetectorType
VN4nFZhnOcBOiJmeVWzBWsvType
VNScreenGazeDetectorType
VNFaceGazeDetectorType
VNCRImageReaderDetectorType
VNCRImageReaderForDocumentsDetectorType
VNAnimalprintDetectorDetectorType
VNImageRegistrationDetectorType
VNHomographicImageRegistrationDetectorType
VNBlurDetectorType
VNBrightnessDetectorType
VNSegmentationGeneratorType
VNObjectDetectorAtPointType
VNMemeClassifierType
VNHomographyTrackerType
VNDocumentSegmentationDetectorType
VNSmartCam5GatingDetectorType
VNPanopticSegmentationGeneratorType
VNSliderNetDetectorType
VNRemoveBackgroundProcessorType
VNMRCDetectorType
VNGuidedUpsamplingGeneratorType
VNDetectorWillLoadNotification
VNDetectorDidLoadNotification
VNDetectorNotificationDetectorClass
VNDetectorNotificationDetector
VNDetectorNotificationConfiguration
%@; resultsIndex=%lu
VNDetectorInitOption_ModelBackingStore
VNDetectorInitOption_MemoryPoolId
VNDetectorOption_OriginatingRequestSpecifier
VNDetectorOption_ProcessingDevice
VNDetectorOption_ExplicitProcessingDevice
VNDetectorOption_MetalContextPriority
VNDetectorOption_PreferBackgroundProcessing
VNDetectorOption_RequestDetectionLevel
VNDetectorProcessOption_InputImageBuffers
VNDetectorProcessOption_InputFaceObservations
VNDetectorProcessOption_ScenePrints
VNDetectorProcessOption_ImageCropAndScaleOption
VNDetectorProcessOption_Canceller
VNDetectorProcessOption_Session
VNDetectorInternalProcessOption_CacheKeys
VNDetectorInternalProcessOption_ImageBuffers
CropCreation
CropProcessing
unknown detector type '%@'
:%@=%@
%@ does not implement %@
Cannot create Metal Context for non-GPU targeting device
primaryInferenceNetworkDescriptorFor%@_%u_%u_%u
%@ does not have an inference network for %@ %@
'%@' is not a valid CGAffineTransform encoding
3x3:|%g %g %g %g %g %g %g %g %g|
3x3:|
'%@' is not a valid matrix_float3x3 encoding
4x4:|%g %g %g %g %g %g %g %g %g %g %g %g %g %g %g %g|
4x4:|
'%@' is not a valid matrix_float4x4 encoding
d3:|%g %g %g|
d3:|
'%@' is not a valid simd_flloat3 encoding
%@.x
%@.y
%@.w
%@.h
%@.or
%@.sz
createBridgeSegment
ContourUtilities.c
mPnts == nPnts
reverseContour
currCPtr != NULL
AnnealContour
sPtrPrev != sPtr
sPtr != sPtrNext
rPtr != NULL
annealSegments
sPrevPtr != sPtr
newCurr != NULL
mergeContourEnd
cPtr2->active
PCOORD_EQUAL(sPtr2->pary[sPtr2->nPnts-1], pc3)
(code == 1) || (code == 2)
mergeEndpointSearch4
code1 != -1
code2 != -1
VNPotentialLandmarkIdentifier
VNClassifyPotentialLandmarkRequestPrivateRevisionStillCapturePipeline
Not supported error
General error
Espresso error
incorrect binserializer key
small sparsity error
feature extraction error
initialization error
no saved state to revert
nominal distance not changed
batch size violation
computation kill request was issued
too few IDs to build VIP model
video error
error with projection computation
missing positional parameter
inconsistent state error
warping error
OpenGL error
invalid format
out of bounds
singular point configuration error
division by zero
LAPACK error
platform endianess not supported
hash already in use
invalid ID
invalid data type
data inconsistency error
I/O error
unknown option
invalid option
missing option
delegate error
vImage related error
memory allocation error
invalid parameter
unexpected null pointer
internal error
not implemented error
CVML_status module %d error %lld
BinSerializer
Face3D
FaceDescriptor
FaceFrontalizer
FaceWarper
Geometry2D
Geometry3D
ImageGrouping
ImageQuality
LandmarkDetector
MomentProcessor
FaceboxAligner
ImageDescriptor
ImageClassifier
ImageProcessing
VIPIdentification
ImageRegistration
SimilarityMatrix
Clustering
HumanDetector
FaceRegionMap
ObjectDetector
ObjectTracker
SRCClassifier
Kmeans
SparseCoding
FaceID
BoostedClassifier
FaceSegmenter
ImageAnalyzer
FaceAttributes
FaceprintAndAttributes
FaceQuality
Torsoprint
ScreenGaze
PetprintGenerator
TapToBox
Generic
ImageTools
VideoTools
ImageWarper
ThirdParty
BinSerializerProcessor
AppleNetParser
FaceProcessorCLI
ImageClassifierCLI
MPCmdlineClientCLI
ClusteringCLI
ImageProcessorCLI
PhotosProcessorCLI
CVMLEngine
CVML Module %lld
[%g,%g,%g,%g]:%@:%u:%u:%c
v32@?0@"NSString"8Q16@"NSString"24
v32@?0Q8@"NSArray"16^B24
cannot process %@ in a single operation
VNFaceRegionMapVersion
userX
userY
userW
userH
alignX
alignY
alignW
alignH
rgnMapData
rgnMapW
rgnMapH
rgnMapRowBytes
pixelToRgnMap
unknown coding version
region map data has length of %lu instead of the expected %lu
Unknown
VNAnimalObservation
anmlPrnt
image:0
person:0
sky:0
personsemantics-u8-v4.espresso
B24@?0#8^B16
The model has reached the maximum entity limit of %lu
entity serial numbers have been exhausted
entity and observation data counts are out-of-sync
VNFaceprintInferenceNetworkHeadIdentifierFaceprint
VNFaceprintInferenceNetworkHeadIdentifierFaceAttributes
NeuralHashv3b_fp16-current.espresso
could not create a image signature print from tensor vector with %lu elements (%lu bytes)
com.apple.VN.createGaborFilterBankGCDQueueName
com.apple.VN.extractGaborDescriptorGCDQueueName
com.apple.VN.gaborReadySyncQueueName
com.apple.VN.gaborDescriptorReadySyncQueueName
VNFaceLandmarkDetectorOption_LoadRefinersModel
VNFaceLandmarkDetectorProcessOption_CalculateLandmarkScore
VNFaceLandmarkDetectorProcessOption_BlinkDetection
Unknown constellation type: %lu
Could not read landmark refiner model data
Invalid parameters passed to landmark score computation
Could not compute landmark score, error code = %lld
Invalid parameters passed to blink score computation
model file is corrupt
void cvml::util::binserialized_table_of_contents::init(const void *const, size_t)
/Library/Caches/com.apple.xbs/Sources/Vision_Sim/VisionKitFramework/VN/algorithm_util/binserialized_mapped_file_contents.h
Model file info populated incorrectly
void cvml::util::binserialized_contents::init_model_values(const cvml::util::binserialized_table_of_contents &, const char *, const vision::mod::BinSerializedModelFileInfo &)
Request object must be of type VNImageBasedRequest
%f,%f,%f,%f:%u:%u:%lu
%@:%u:%u:%lu
B32@?0Q8@"VNCreateFaceprintRequest"16^@24
B32@?0Q8@"VNClassifyFaceAttributesRequest"16^@24
B16@?0@"VNFaceObservation"8
VNImageBufferOption_DownscaleCGInterpolationQuality
VNImageBufferOption_UpscaleCGInterpolationQuality
VNImageBufferOption_FeatureOrientationRelativeToUpRight
VNImageBufferOption_DoNotCacheRepresentations
VNImageBufferOption_CreateFromPixelBufferPool
VNImageBufferAugmentationApplePipeline
VNImageBufferAugmentationBlur
VNImageBufferAugmentationNoise
VNImageBufferAugmentationRotation
VNImageBufferAugmentationFlip
VNImageBufferAugmentationFlipVertical
VNImageBufferAugmentationFlipHorizontal
VNImageBufferAugmentationShear
VNImageBufferAugmentationExposure
VNImageBufferAugmentationRandomCrop
VNImageBufferAugmentationOptionMaxRange
VNImageBufferAugmentationOptionMinRange
VNImageBufferAugmentationOptionNumberOfBuffers
VNImageBufferAugmentationOptionRandomSeed
ERROR while purging caches %s | %@
-[VNImageBufferManager purgeAllCaches]
VNImageBufferContext
subSampleFactor
Cannot obtain image from image source
format=%lu_width=%lu_height=%lu_cropRect=%@
Failed to create image for processing
Missing target buffer for crop operations
VNImageBuffer - Cannot set VTSession property, error: %d
VNImageBuffer - Failed to transfer bufferForTransferSubImage (retain count = %ld, type = %u) to vtSessionDestBuffer (retain count = %ld, type = %u). Error %d
VNImageBuffer - unable to allocate CVPixelBuffer, error: %d
Cannot set VTSession property, error: %d
VNImageBuffer - Failed to transfer inputBufferForRotation (retain count = %ld, type = %u) to vtSessionDestBuffer (retain count = %ld, type = %u). Orientation %d. Crop %@. Rotation %d. Error %d
unable to create the Y plane wrapper buffer
Unable to create CGImage for scaling
Extracting ROI from an image failed
Unable to crop a region of interest from source buffer
Unable to create a CGBitmapContext
Operation failed due to attempt to crop zero or near zero dimensioned area
Could not create buffer with format %@ (%ld)
Failed to create CGImage from CVPixelBuffer
%@;opt=%@
VNImageBuffer - unable to allocate CVPixelBuffer to be rendered from CIImage, error: %d
unable to create the cropped buffer - error: %d
CIDiscBlur
CIExposureAdjust
CIStraightenFilter
CIRandomGenerator
CIColorMonochrome
CIMultiplyBlendMode
RandomCrop produced an invalid crop for width %f height %f
The augmentationOptions do not conatain any of the VNImageBufferAugmentation keys
Cannot transfer image using VTSession, error: %d
orientation
%@ cannot be called with nil options
0x%x
B16@?0@"VNObservation"8
VNCreateTorsoprintRequestPrivateRevision3MD2HumanDetectorBasedTorso
VNCreateTorsoprintRequestPrivateRevisionSydroMD2HomeAIHumanDetectorBasedTorso
VNCRImageReaderForDocumentsDetectorProcessOption_OriginatingRequest
VNCRImageReaderForDocumentsDetectorProcessOption_DetectionOnly
VNCRImageReaderForDocumentsDetectorProcessOption_TextObservationsToRecognize
VNCRImageReaderForDocumentsDetectorProcessOption_MaximumProcessingDimensionOnTheLongSide
v32@?0@"VNWeakSessionWrapper"8Q16^B24
v24@?0@"VNSession"8^B16
%@: %@
VNTrackerOption_RPNEspressoResources
com.apple.Tracker.rpnInitQueue
com.apple.Tracker.rpnTrackQueuee
rpn_template_v5.espresso
rpn_track_v5.espresso
com.apple.VN.serializeRPNInitializationQueue
com.apple.VN.serializeRPNTrackingQueue
com.apple.espresso.mainqueue
Unspecified error
face
 modified on %@
 <dirty>
writeVersion
failed to obtain the data
v32@?0@"VNFaceObservation"8Q16^B24
[%f; %f]
VNRequestWarningImageTooSmall
VNRequestWarningImageTooSmallForFaceObservations
VNRequestWarningImageMinimumLongDimension
VNRequestWarningImageMinimumShortDimension
VNRequestWarningBlinkDetectionFailure
VNRequestWarningTiledAnalysis
Vision
%@-%lu:MTL=%@:Det=%lu:MDm=%lu
Currently executed Request should not be nil
com.apple.%@
cancellation is not currently available
%@ does not support cancellation
imageBuffer
All elements in the %@ array must be of class %@ (%@)
%@ does not support %@
%@ contains an entry for %@ that is dependent on a private revision %@
 preferBackgroundProcessing
 usesCPUOnly
v24@?0@"NSArray"8@"VNAsyncStatus"16
v24@?0d8@"NSError"16
minDimension
maxDimension
idealDimension
idealFormat
wideRange
highRange
aspectHandling
idealOrientation
orientationAgnostic
    %@=%@
The %@ option was expected to be a %@, but was instead a %@ (%@)
landscape_cityscape
VN6OIpeIn2UKbA8EPIFdIs2H
VN1U5ssvGWQjrV1RUm9dL5pR
VN5XQJGcytY6ZCBlwCqdMbq0
VN3HBc5ma46eJPh5drbK827c
VN2bYrp5ZAmkNcYOAHlIZLns
Timed out waiting for dispatch_group_wait completion
Synchronization queue must be initialized
Maximum queue tasks count (%ld) must be a positive number
Controlled Capacity Tasks Queue: %@; %@
Maximum queue tasks count (%ld) is outside of the allowed range [1; %ld]
v32@?0@"NSString"8@"VNControlledCapacityTasksQueue"16^B24
com.apple.VN.VNRequestPerformingPriorityGroup1AsyncTasksQueue.%@
com.apple.VN.VNRequestPerformingPriorityGroup2AsyncTasksQueue.%@
com.apple.VN.requestAsyncTasksQueue
com.apple.VN.detectorAsyncTasksQueue.%@
com.apple.VN.detectorSyncTasksQueue.%@
FTp_data
FTp_elementsCount
FTp_elementsType
FTp_length
FTp_labelsAndConfidence
FTp_VNFaceTorsoprint
FTp_algorithmVersion
FTp_fp
FTp_tp
FTp_rev
FTp_pid
VNNOPRequest
Wrong type of print object
state cannot be nil
Serialized and calculated MD5s don't match
Failed to initialize VNFaceTorsoprint object
VNAnimalprintDetectorProcessOption_InputAnimalObservation
Unable to initialize frontalizer.
could not lock cropped image
Unexpected size of animalprint descriptor
pixelFormatType
-[VNMomentProcessor initWithOptions:error:]
MomentProcessor.mm
-[VNMomentProcessor computeClusteringOfImageDescriptors:intoKGroups:error:]
-[VNMomentProcessor computeNaturalClusteringOfImageDescriptors:error:]
-[VNMomentProcessor computeClusteringTreeForImageDescriptors:assumeDescriptorsAreSorted:error:]
q24@?0@"VNMPImageDescriptor"8@"VNMPImageDescriptor"16
v24@?0#8@"NSIndexSet"16
B32@?0#8Q16^B24
%@ does not provide an entity print that is compatible with a print generated by %@
faceprint
animalprint
%@ does not have a %@
%@ was generated by %@, which is not equivalent to %@
VNGenerateAttentionBasedSaliencyImageRequestPrivateRevisionStillCapturePipeline
VNGenerateAttentionBasedSaliencyImageRequestPrivateRevisionSceneNetV4
VNGenerateAttentionBasedSaliencyImageRequestPrivateRevisionSceneNetV4StillCapturePipeline
VNGenerateAttentionBasedSaliencyImageRequestPrivateRevisionSceneNetV5
VNGenerateAttentionBasedSaliencyImageRequestPrivateRevisionSceneNetV5StillCapturePipeline
results were not already populated by VNImageAnalyzerCompoundRequest
Bounding Box = %@; objectType = %ld; confidence = %f
%@ cannot be created from a read-only model
%@ cannot be created with a data source
%@ cannot open a read-only model
VN62b042cc67e0a7d589ecdb58232fe23d
VN9bdc36cda32be948a5089e37392596ec
VN81aedeb999c79d74e79af7f1c922cf97
VN9f5b8e9dc1b3c824d79372f87b072ee3
VNbe5c67b06e95370f5a7b67b13e73637c
VN220a6626eb3cb51295a4e250ad9da319
VN0af6454e97767772ce64a19ddaf61f0c
VNeeab04670e53ebeb25150a31963a1aa6
VNa0c07362d05e1dafb35b96d20d5ce42d
VN79a8f83d9d55eb4eb2c9695902c47b53
VNacdca02f0900c2cb198193f3eec7b6c9
VNJ4fWm08v8TFm5lmRVji9G
VNBcvG8BSEpHsJWme0UsCjT
Iden
Confid
VNFaceprint
fp_ec
fp_et
fp_l
fp_lac
fp_conf
fp_av
Attempt to deserialize nil
Input data is not a VNFaceprint
CVMLFaceprint
facePrint
Input data is neither VNFaceprint nor CVMLFaceprint. NSKeyedUnarchiver error = %@
Error deserializing VNFaceprint
Serialized state data is an unsupported version (%lu)
Serialized state data length is invalid
Serialized state payload data checksum mismatch
unsupported serialized state version %u
VNSaliencyImageObservation
OISW
OISH
SOBJ
BBOX
BBOY
BBSW
BBSH
NBBOX
NBBOY
NBBSW
NBBSH
VNBrightnessDetectorProcessOption_MaximumIntermediateSideLength
VNScreenGazeDetectorProcessOption_FaceObjectState
VNScreenGazeDetector: Predictor failed to determine gaze
screengazeflow-dw5gmeefrv_535001_quantized.espresso
VNClassifyImageAestheticsRequestPrivateRevisionStillCapturePipeline
VNClassifyImageAestheticsRequestPrivateRevisionSceneNetV4
VNClassifyImageAestheticsRequestPrivateRevisionSceneNetV4StillCapturePipeline
VNClassifyImageAestheticsRequestPrivateRevisionSceneNetV5
VNClassifyImageAestheticsRequestPrivateRevisionSceneNetV5StillCapturePipeline
VNRectangleTracking_BottomLeftTracker
VNRectangleTracking_BottomRightTracker
VNRectangleTracking_TopLeftTracker
VNRectangleTracking_TopRightTracker
No objects to track passed to the tracker
wrong type of a corner tracker allocated
initialization of internal object
Setting input rectangles to one of the rectangle corners failed
v32@?0@"NSString"8@"VNObjectTracker"16^B24
wrong type of a corner tracker object created
tracking of one or more of the rectangle corners failed
v32@?0@8@16^B24
Resetting tracker failed with error: %llu
VNRectangleObservation object is expected to initialize Rectangle Tracker
Tracking of %@ failed: confidence = %f; threshold = %f
Failed to create CVPixelBuffer.
%@ Width = %lu, Height = %lu, Format = %c%c%c%c
Failed to lock pixel buffer
Failed to unlock pixel buffer
Pixel buffer is missing an IOSurface
IOSurface is not valid
symbology
barcodeDescriptor
ACBSBarcodeInfo
MRCDescriptorAttributes
VNDetectBarcodesRequest
 (%@)
BCSDetectedCode
failed to get image from tensor
^{CGImage=}8@?0
failed to create comparison image
unsupported pixel format type
failed to create pixel buffer
docseg_segflow-xde2zmcdh5_64000_4ch_512x288_finalFC.espresso
docseg_segflow-xde2zmcdh5_64000_4ch.segmentation_labels.txt
maximumElementsPerID should be less or equal than INT32_MAX
v32@?0@"<NSObject><NSCopying><NSSecureCoding>"8@"NSNumber"16^B24
invalid face observation at index %lu for person at index %lu
A prediction for an unknown identity with serial number %@ and confidence %f was provided
q24@?0@"VNPersonsModelPrediction"8@"VNPersonsModelPrediction"16
serialNumberToIdentifier
faceprintRequestRevision
v32@?0@"NSNumber"8@"<NSObject><NSCopying><NSSecureCoding>"16^B24
unable to serialize the face ID model (status = %@)
VNSmartCamClassifierProcessOption_ReturnAllResults
smartcam-descriptor
smartcam-classifier
smartcam-classifier-labels
smartcam-classifier-relationships
VN_DEBUG_DUMP_SMARTCAM_INTERMEDIATES
VN_smartcam_classifier_debug_intermediates/
model_junk_12_espresso
VNRecognizeObjectsRequestPrivateRevision26Identifiers
VNRecognizeObjectsRequestPrivateRevision585Identifiers
VNRecognizeObjectsRequestPrivateRevisionSceneNetV4
VNRecognizeObjectsRequestPrivateRevisionSceneNetV5
buffer cannot be nil
data overflow to %lu bytes
tag %@ has a data overflow to %lu bytes
encountered unexpected length of %u, instead of %u
corrupted boolean value: %02X
unexpected end of data stream
landmarkRefinerAndPupil_v2
Could not read expressions model data
Could not create face expression module
VNFaceExpressionDetector face does not have landmark points
Corrupt face mark data
%@ %@ %lu x %lu
name
pixelFormat
elementsCount
length
labelsAndConfidence
VNSceneprint
algorithmVersion
failure with status %lld
 (%s)
encountered an unexpected condition: %s
encountered an unexpected condition: %@
NSException
encountered unknown exception
VNTextRecognitionOptionNone
VNTextRecognitionOptionASCIICharacterSet
VNTextRecognitionOptionEnglishCharacterSet
VNTextRecognitionOptionDanishCharacterSet
VNTextRecognitionOptionDutchCharacterSet
VNTextRecognitionOptionFrenchCharacterSet
VNTextRecognitionOptionGermanCharacterSet
VNTextRecognitionOptionIcelandicCharacterSet
VNTextRecognitionOptionItalianCharacterSet
VNTextRecognitionOptionNorwegianCharacterSet
VNTextRecognitionOptionPortugueseCharacterSet
VNTextRecognitionOptionSpanishCharacterSet
VNTextRecognitionOptionSwedishCharacterSet
ASCII
Text detector object was not created
invalid algorithm value of %lu
%@ is corrupt
@"NSString"8@?0
com.apple.vis.VNPersonsModel
cannot accept model version %lu
unknown person (%@)
operation was cancelled
unsupported algorithm %@
B32@?0@"VNFaceprint"8Q16^B24
the data source is no longer available
configuration has already been resolved to %@ and cannot be set to %@
unknown model kind '%@'
model data cannot be verified due to mismatched checksums
i12@?0I8
com.apple.vis.VNPersonsModelLoader
%@ read as %@
B28@?0I8@"NSObject"12^@20
<%@: %p> %lu identities
cannot create model with version %u
the face observation must not be nil
version
lastModDate
algorithm
readOnly
 single mean
maxIdentities
faceprintsPerIdentity
configuration %@ cannot provide a %@
                              algorithm = %@
                      maximumIdentities = %lu
   maximumTrainingFaceprintsPerIdentity = %lu
               faceprintRequestRevision = %@
personUID
 '%@' confidence %f
readonly
faceprint is not available from the observation
incompatible faceprint revision
VNPersonsModelFaceModel
person identifier data
face observation %lu of %lu for person identifier '%@'
VNClassifyImageRequestPrivateRevisionSceneNetV4
VNClassifyImageRequestPrivateRevisionSceneNetV5
VNClassifyImageRequestPrivateRevisionSmartCamNet5
previous request results
VNFaceAttributeCategoryVersion
facrRev
FAC_label
FAC_LAC
VNFaceAttributesVersion
farRev
age_Cat
gender_Cat
eyes_Cat
smiling_Cat
facehair_Cat
haircolor_Cat
bald_Cat
glasses_Cat
makeup_Cat
makeupEyes_Cat
makeupLips_Cat
unknown01_Cat
unknown02_Cat
unknown03_Cat
unknown04_Cat
unknown05_Cat
unknown06_Cat
unknown07_Cat
facemask_Cat
UNKNOWN_1_unknown0
UNKNOWN_1_unknown1
UNKNOWN_1_unknown2
UNKNOWN_1_unknown3
UNKNOWN_1_unknown4
UNKNOWN_6_unknown0
UNKNOWN_6_unknown1
UNKNOWN_3_unknown0
UNKNOWN_3_unknown1
UNKNOWN_7_unknown0
UNKNOWN_7_unknown1
UNKNOWN_4_unknown0
UNKNOWN_4_unknown1
UNKNOWN_4_unknown2
UNKNOWN_4_unknown3
UNKNOWN_4_unknown4
UNKNOWN_5_unknown0
UNKNOWN_5_unknown1
UNKNOWN_5_unknown2
UNKNOWN_5_unknown3
UNKNOWN_5_unknown4
UNKNOWN_5_unknown5
UNKNOWN_2_unknown0
UNKNOWN_2_unknown1
UNKNOWN_0_unknown0
UNKNOWN_0_unknown1
UNKNOWN_0_unknown2
UNKNOWN_8_unknown0
UNKNOWN_8_unknown1
UNKNOWN_8_unknown2
UNKNOWN_9_unknown0
UNKNOWN_9_unknown1
UNKNOWN_9_unknown2
UNKNOWN_10_unknown0
UNKNOWN_10_unknown1
UNKNOWN_10_unknown2
UNKNOWN_10_unknown3
UNKNOWN_10_unknown4
UNKNOWN_11_unknown0
UNKNOWN_11_unknown1
UNKNOWN_11_unknown2
UNKNOWN_11_unknown3
UNKNOWN_11_unknown4
UNKNOWN_11_unknown5
UNKNOWN_12_unknown0
UNKNOWN_12_unknown1
UNKNOWN_12_unknown2
UNKNOWN_12_unknown3
UNKNOWN_12_unknown4
UNKNOWN_12_unknown5
UNKNOWN_12_unknown6
UNKNOWN_13_unknown0
UNKNOWN_13_unknown1
UNKNOWN_13_unknown2
UNKNOWN_13_unknown3
UNKNOWN_13_unknown4
UNKNOWN_13_unknown5
UNKNOWN_13_unknown6
UNKNOWN_14_unknown0
UNKNOWN_14_unknown1
UNKNOWN_14_unknown2
UNKNOWN_14_unknown3
UNKNOWN_14_unknown4
UNKNOWN_15_unknown0
UNKNOWN_15_unknown1
UNKNOWN_15_unknown2
UNKNOWN_15_unknown3
UNKNOWN_15_unknown4
UNKNOWN_16_unknown0
UNKNOWN_16_unknown1
UNKNOWN_16_unknown2
UNKNOWN_16_unknown3
UNKNOWN_16_unknown4
UNKNOWN_16_unknown5
UNKNOWN_17_unknown0
UNKNOWN_17_unknown1
Wisdom
wisdom parameters are not available for the system
v32@?0@"NSString"8@"NSDictionary"16^B24
wisdom parameters are not available for the device "%@"
Wrong type for warning value - %@, should be %@
detectionprint
VNSegmentationGeneratorProcessOption_PersonSegmentationDetectorOriginatingRequestSpecifier
VNSegmentationGeneratorProcessOption_SkySegmentationDetectorOriginatingRequestSpecifier
VNSegmentationGeneratorProcessOption_QualityLevel
VNSegmentationGeneratorProcessOption_OutputPixelFormat
VNSegmentationGeneratorProcessOption_KeepRawOutputMask
VNSegmentationGeneratorProcessOption_MaskImageObservations
VNSegmentationGeneratorProcessOption_UseTiling
VNSegmentationGeneratorProcessOption_MinimumConfidence
VNSegmentationGeneratorProcessOption_ImageRotated
VNSegmentationGeneratorProcessOption_ImageROI
qualityLevel
B32@?0@"NSString"8^{BufferSize=QQ}16^@24
Unexpected number for masks returned
Missing keepRawOutputMask for %@
Missing resultPixelFormat for %@
Unsupported output pixel format of %x
@"NSArray"24@?0@"VNPixelBufferObservation"8^@16
v32@?0@"NSMutableArray"8Q16^B24
sc_d
sc_ec
sc_et
sc_l
sc_lac
VNSmartCamprint
sc_av
labelsConfidences
%02X
bits
bit data must not be nil
Cannot encode boolean byte data of length %lu because it is not a multiple of 8.
rowProjections
rowSum
rowSumSq
colProjections
colSum
colSumSq
nil buffer passed into initWithImageBuffer
Error while trying to allocate VNImageSignature object
inconsistent row data
inconsistent column data
VNDetectorInternalProcessOption_RecordImageTooSmallWarning
VNDetectorInternalProcessOption_DesiredMinimumFacePrintingLongDimension
Unexpected options parameter passed to face analyzer multi-detector
Could not run network. Error = %s
Error calculating print
Could not get print output. Error = %s
Could not get attributes output. Error = %s
yyyy:MM:dd HH:mm:ss
operation points object must be allocated before calling this method
The %d argument had an illegal value.
The %d-th diagonal element of the triangular factor of A is zero, so that A does not have full rank; the least squares solution could not be computed.
GenericSportBall
VNRecognizeSportBallsRequestPrivateRevisionANSTModel
unknown
VNFaceSegmentGeneratorProcessOption_FaceBoundingBoxExpansionRatio
VNFaceSegmentGeneratorInternalProcessOption_FaceSegmentBBoxNormalized_X
VNFaceSegmentGeneratorInternalProcessOption_FaceSegmentBBoxNormalized_Y
VNFaceSegmentGeneratorInternalProcessOption_FaceSegmentBBoxNormalized_Width
VNFaceSegmentGeneratorInternalProcessOption_FaceSegmentBBoxNormalized_Height
Failed to create Face Segmenter object
Invalid parameter (size)
Unexpected request revision
Invalid parameter (numberOfSupportedFaceSegments)
One of the dimensions of the input face image is zero
Input face aspect ratio > %f cannot be processed
Expected labelConfidence map of %lu x %lu and got %lu x %lu
height
rowBytes
cannot map face segments
faceSemantics_v1_15class_quant.espresso
VNVideoProcessingOptionFrameCadence
VNVideoProcessingOptionTimeInterval
VCPVideoProcessor
PtSpec
VCPPersonObservation
VCPHandObservation
VNHumanPoseDetectorProcessingOption_UseCPUOnly
Human Pose Request is not initialized
Unable to create observation
%@ is not supported
                        algorithm = %@
                  maximumEntities = %lu
   maximumTrainingPrintsPerEntity = %lu
    entityPrintOriginatingRequest = %@
printsPerEntity
printOriginatingRequest
Could not bind output aesthetics scores
Could not bind image to network
Could not run network
Unexpected result
scenenet_sceneprint_r9_opt_int8.espresso
mergesCount
smartDistance
This method should not be invoked directly. Derived classes are responsible for providing correct implementation
B24@?0@"ShotflowDetection"8@"NSDictionary"16
VNANFDMultiDetectorProcessingOption_FoodAndDrinkRecognitionOriginatingRequestSpecifier
Unexpected detector object type
VNOpticalFlowGeneratorProcessOption_PreviousObservation
VNOpticalFlowGeneratorProcessOption_ComputationAccuracy
VNOpticalFlowGeneratorProcessOption_OutputPixelFormat
VNOpticalFlowGeneratorProcessOption_KeepNetworkOutput
VNOpticalFlowGeneratorProcessOption_FromAndToPixelBuffers
VNOpticalFlowGeneratorProcessOption_PortraitMode
VNFaceDetectorPrivateRevisionLegacyFaceCoreProcessOption_Type
VNFaceDetectorPrivateRevisionLegacyFaceCoreProcessOption_ROIs
VNFaceDetectorPrivateRevisionLegacyFaceCoreProcessOption_MinFaceSize
VNFaceDetectorPrivateRevisionLegacyFaceCoreProcessOption_NumberOfDetectionAngles
VNFaceDetectorPrivateRevisionLegacyFaceCoreProcessOption_InitialAngle
VNFaceDetectorPrivateRevisionLegacyFaceCoreProcessOption_EnhanceEyesAndMouthLocalization
VNFaceDetectorPrivateRevisionLegacyFaceCoreProcessOption_ExtractBlink
VNFaceDetectorPrivateRevisionLegacyFaceCoreProcessOption_ExtractSmile
Failed to create detector
Failed to create internal image
origDim
pcaDim
espresso-descriptor
espresso-classifier
espresso-classifier-labels
espresso-classifier-relationships
VNEspressoModelClassifierProcessOption_CenterTileOnly
%@ must implement classifierResourceTypesToNamesForOriginatingRequestSpecifier: for %@
could not locate the resource file "%@"
%@ must implement +classifierResourceTypesToNamesForOriginatingRequestSpecifier: for %@
%@ with a %@ is not supported
Cannot calculate classification image descriptor
Cannot create image print
Cannot create observation object
Could not compute raw labels and confidence for image
resource key "%@" is not available
could not locate %@ in %@
VNDetectBarcodesRequestPrivateRevision2
v32@?0@"NSString"8@"NSString"16^B24
Payload data is missing
QRErrorCorrectionLevel data is missing
QRErrorCorrectionLevel data is invalid
QRSymbolVersion data is missing
QRMaskPattern data is missing
IsCompact data is missing
LayerCount data is missing
CodewordCount data is missing
RowCount data is missing
ColumnCount data is missing
VNDetectBarcodesLocateModeCenterOneVertical
VNDetectBarcodesLocateModeCenterOneVerticalThick
VNDetectBarcodesLocateModeCenterThreeVertical
VNDetectBarcodesLocateModeCenterThreeVerticalCrossed
VNDetectBarcodesLocateModeCenterOneHorizontal
VNDetectBarcodesLocateModeCenterOneHorizontalThick
VNDetectBarcodesLocateModeCenterThreeHorizontal
VNDetectBarcodesLocateModeCenterThreeHorizontalCrossed
VNDetectBarcodesLocateModeCenterOneEachDirection
VNDetectBarcodesLocateModeCenterThreeEachDirection
VNDetectBarcodesLocateModeCenterFiveEachDirection
VNDetectBarcodesLocateModeCenterThreeEachDirectionAndCoverageAndDiagonals
VNDetectBarcodesLocateModeCenterThreeVerticalAndCoverageAndDiagonals
VNDetectBarcodesLocateModeCenterThreeHorizontalAndCoverageAndDiagonals
VNDetectBarcodesLocateModeFastSearch
VNDetectBarcodesLocateModeRegularIntervalHorizontal
VNDetectBarcodesLocateModeRegularIntervalVertical
barcode detection requires at least one element in the symbologies property
%@ is not a supported barcode symbology
barcode type is not available
unknown barcode type of '%@'
_new%@DescriptorForMRCDescriptor:error:
barcode location is not available
invalid barcode location information
Failed to create MRCSample
_new%@DescriptorForACBSBarcodeInfo:
creation of a barcode descriptor for %@ is not supported
unable to create a barcode descriptor for %@
failed to analyze image
camgaze_probs
VNImageNeuralHashprintObservation
nrlHshPrnt
Failed to unarchive %@ object due to coding version mismatch: Currently supported: %u; encoded: %u
VNObjectTrackerRevision1Type
VNObjectTrackerRevision2Type
VNObjectTrackerRevision2Type_RPNTrackerInitModelName
VNObjectTrackerRevision2Type_RPNTrackerTrackModelName
VNObjectTrackerRevisionLegacyFaceCoreType
VNRectangleTrackerType
v32@?0@"NSString"8#16^B24
com.apple.VN.trackersCollectionManagementQueue_%lu
com.apple.VN.trackingProcessingQueue_%lu
A tracker cannot be created without specifying a unique tracker key
Cannot create a Tracker with unknown tracker type: %@
Internal error: Exceeded maximum allowed number of Trackers for a tracker type: %@
GreedyWithTorsoClustering.cpp
VNGuidedUpsamplingGeneratorOption_LowResImages
VNGuidedUpsamplingGeneratorOption_InputPixelFormat
VNGuidedUpsamplingGeneratorOption_OutputPixelFormats
Mismatched lowResObservations and outputPixelFormats count
Pixel format mismatch
VNPixelBufferObservation missing pixel buffer
^{__CVBuffer=}24@?0@"VNPixelBufferObservation"8^@16
observation
entityUID
VNSmartCam5GatingDetectorProcessingOption_ClassificationEnabled
VNSmartCam5GatingDetectorProcessingOption_ClassificationOriginatingRequestSpecifier
VNSmartCam5GatingDetectorProcessingOption_ClassificationObservationsArray
VNSmartCam5GatingDetectorProcessingOption_GatingOriginatingRequestSpecifier
VNSmartCam5GatingDetectorProcessingOption_GatingObservationsArray
VNSmartCam5GatingDetectorProcessingOption_DocumentRegionGatingEnabled
VNSmartCam5GatingDetectorProcessingOption_DocumentRegionGatingGenerateSegmentationMask
VNSmartCam5GatingDetectorProcessingOption_TextRegionGatingEnabled
VNSmartCam5GatingDetectorProcessingOption_TextRegionGatingGenerateSegmentationMask
VNSmartCam5GatingDetectorProcessingOption_MachineReadableCodesGatingEnabled
VNSmartCam5GatingDetectorProcessingOption_MachineReadableCodesGatingGenerateSegmentationMask
appcode
qr_code
unable to create segmentation image for %s
MRC5heads_76f6w2kjaz_61501_ay5mhf87cq_97501_hbnrcg6e5e_89040_8g7zthf4q3_12751_rucb99jtq8_75751_8d9qwisndd_85501_concat_quant.espresso
smartcam_assembly-classification-labels.txt
smartcam_assembly-segmentation-labels.txt
leaf_semdev_text_water
segmentation/MRC_softmax
%@ %@ %@
framework
VNHLKWRI
VNHLKTCMC
VNHLKTMP
VNHLKTIP
VNHLKTTIP
VNHLKIMCP
VNHLKIPIP
VNHLKIDIP
VNHLKITIP
VNHLKMMCP
VNHLKMPIP
VNHLKMDIP
VNHLKMTIP
VNHLKRMCP
VNHLKRPIP
VNHLKRDIP
VNHLKRTIP
VNHLKPMCP
VNHLKPPIP
VNHLKPDIP
VNHLKPTIP
VNHLRKT
VNHLRKI
VNHLRKM
VNHLRKR
VNHLRKP
VNDetectHumanHandPoseRequestPrivateRevisionStarSkyModelDrop1
%@ labelKey = %d; rotationAngle = %f; yawAngle = %f, pitchAngle = %f
-[VNMPImageData initWithVImage:externalImageId:andExifTimestampValue:error:]
MPImageData.m
ERROR: The input image does not seem to be 8888
-[VNMPImageData initWithCVPixelBufferImage:externalImageId:andExifTimestampValue:error:]
%@ must implement %@
unknown classification identifier "%@"
no operation point data is available for "%@"
LKT:waitUntilCompleted
Unhandled metal pixel format
Could not bind pixel buffer to texture
Optical flow estimation invalid state
LKT::Pyramid
LKT:ComputeFlow level %d
lkt_bgra2yuva
lkt_zero_flow
lkt_downscale_2x
lkt_features
lkt_features_derivatives
lkt_solver_prepare_matrices
lkt_solver_box7_y
lkt_solver_box_x_and_Axb
lkt_nlreg_hegbf
Failed to scale the input image
Failed to center square crop the input image
unable to determine preferred image size for detection
VNRequestFaceLandmarksConstellationNotDefined
VNRequestFaceLandmarksConstellation65Points
VNRequestFaceLandmarksConstellation76Points
VNDetectFaceLandmarksRequestPrivateRevisionANSTModel
VNDetectFaceLandmarksRequest revision %lu doesn't support constellation %lu
VNIp
ipType
MPImDesc
ipReqRev
ipOrgReq
otherImageprint cannot be nil
could not compute faceprint distance
Invalid format of VNImageprint serialized state
Failed to deserialize requestRevision
Unexpected size of deserialized state of the object of type %@
Failed to initialize VNImageprint object
Unexpected size of serialized state of the object of type %@
VNFaceGeometryEstimatorInitOption_ImageSize
VNFaceGeometryEstimatorInitOption_CameraFocalLength
VNFaceGeometryEstimatorProcessOption_EstimatePoseOnly
Could not read face geometry estimator model data
Failed to estimate face geometry
_%llu
Cannot create MTLDevice
Unimplemented conversion
Failed to create MTLCommandQueue
pixel buffer does not have an IOSurface
Pixel buffer does not have an IOSurface
IOsurface width is smaller than texture width
IOsurface height is smaller than texture height
Failed to create MTLTextureDescriptor
Failed to create MTLTexture
v32@?0@"<MTLTexture>"8Q16^B24
v32@?0@"<MTLBuffer>"8Q16^B24
Q24@?0Q8^@16
Unimplemented format for guided upsampling
Texture array cannot be empty
Texture sizes do not match
Texture pixel formats do not match
Invalid texture count of 0
Texture count mismatch between input and output textures
Texture size mismatch
ImageFilters
metallib
contrastFromAverage
CIAreaAverage
contrastWithPivot
com.apple.VN
multiplyByFactor
emp_data
emp_elementsCount
emp_elementsType
emp_length
emp_labelsAndConfidence
VNEspressoModelImageprint
VNEspressoModelImageprintRequestRevision
emp_algorithmVersionCodingKey
emp_algorithmVersion
request
descriptorData
f16Desc
descriptorByteLength
elementsType
elementCount
element count must be non-zero
%lu elements of type %@ with length of %lu mismatch to descriptor data length %lu
unable to create float16 descriptor with %lu elements
%@ does not specify a default originating request class
%@ could not resolve originating request class of %@: %@
descriptor data length (%lu) / expected length (%lu) mismatch
The '%@' data is not the expected length of %lu
descriptor data is unavailable
descriptor length is unavailable
unable to create a %@ %@ %@ descriptor with length %@
State cannot be nil
Invalid input data to de-serialize a print object
Invalid format of %@ serialized state
Memory allocation failure
Failed to initialize 'print' object
nil VNEspressoModelImageprint(s) supplied
VNEspressoModelImageprint(s) with different length supplied
Unknown distance funtion requested
cannot compare prints of %@ and %@
Espresso print: version = %@; element count = %lu; element type = %@; length in bytes = %lu; confidence score type = %lu; originating request specifier = %@
invalid element type of %@
float32 data was not a length multiple of 4
float16 data was not a length multiple of 2
facerec_fp3.1_fa1.3.espresso
VNImageAestheticsObservation
OAES
PLHT
PREF
LCOL
PSYM
PPAT
PPERS
PPOST
NOISE
FAIL
PCOMP
INTREST
INTRUSIVE
CTILT
HCOL
LOWKEY
Score
aestheticScore
  %@=%@
VNCntsObs
Points
Size
B16@?0r^{EPolygonList=ii^{EPolygon}i}8
v32@?0^{EPolygonList=ii^{EPolygon}i}8{CGSize=dd}16
Failed to execute bit string to polygon list with error: %@
contourIndex
argument indexPath cannot be empty
indexPath
VNTrajectoryProcessorOption_RequestState
VNTrajectoryProcessorOption_ObjectMinimumNormalizedRadius
VNTrajectoryProcessorOption_ObjectMaximumNormalizedRadius
VNTrajectoryProcessorOption_ProcessingTargetFrameTime
CIColorAbsoluteDifference
CIColorThreshold
inputThreshold
CIMorphologyRectangleMaximum
inputWidth
inputHeight
CIColorControls
inputImage
inputImage2
CIMaximumComponent
Could not create intermediate buffer
cannot perform analysis with minimum object radius of %f and maximum object radius of %f
Too many moving objects or noise detected which prevents trajectory processing.
faceRegionMap-current
Could not read face region map model data
Disgust
Neutral
Surprise
Suspicious
VNObservation
timeRange
 confidence=%f
 timeRange=%@
Data detecor not supported for %@
Could not create DataDetector
VNDetectedObjectObservation
%@ boundingBox=%@
VNFaceObservation
alignedBBX
alignedBBY
alignedBBW
alignedBBH
unalignedBBX
unalignedBBY
unalignedBBW
unalignedBBH
unalignedBBXAsDouble
unalignedBBYAsDouble
unalignedBBWAsDouble
unalignedBBHAsDouble
landmarks65
landmarksConstellation
precisionEstimates
landmarks3D
pose
poseOrigReq
expressions
faceID
faceIDConfidence
torsoprint
faceTorsoprint
hasAlignedBBox
alignedRotAngle
roll
pitch
faceRegionMap
blinking
blinkScore
alignedMeanShape
landmarksScore
faceOrientationIndex
faceJunkinessIndex
faceCaptureQuality
faceAttributes
faceSmntcSegments
faceLMRequestRev
faceLM3DRequestRev
faceLMOReq
faceLM3DOReq
gaze
screengaze
exifOrientation cannot be null
face orientation
Data integrity check failed when un-archiving landmarks constellation. Un-archived constellation is out of range: %lu
invalid pose data
 ID=%lu
 VNFaceLandmarks2D [%@, confidence=%f]
leftEyebrow
leftEye
rightEyebrow
rightEye
noseCrest
nose
medianLine
faceContour
outerLips
innerLips
referenceImageSignature
floatingImageSignature
%@ is not supported by %@
alignmentTransform
warpTransform
exposure
 blurScore=%@
 exposureScore=%@
VNImageprintObservation
descriptor
VNImageprint
nil imageprint supplied
Failed creating a new VNImageprintObservation object
VNCreateImageprintRequest
VNImageExposureScoreRequest
identifier
operationPoints
 "%@"
 (P/R)
%@ cannot provide operation points
VNRecognizeObjectsRequest
%@ labels=[%@]
labels
segmentationMask
featureValue
featureName
%@ "%@" - "%@" (%f)
vnpbo_pbdict
VNCoreMLRequest
CIColorMatrix
inputBVector
transform
angle
vncluster
vncObjects
vncCId
vncTotObjCount
vncRepUpdate
vncRepIds
vncRepnessById
  clusterId = %lu;
  totalObjCount = %lu;
  objects = %@;
  shouldUpdateRep = %d;
  suggestedIdsForRep = %@;
  representativenessById = %@;
clusters
suggestions
clusterState
clusteredFaceIDs
groupedClusteredFaceIDs
level0Distance
distancesByID
The revision of the observations do not match
The observations do not have a feature print that match each others format
One or more of the feature prints are empty
VNSceneObservation
algo
descriptors
Undefined
VNSmartCamObservation
sc_algo
sc_descriptors
textObjects
text
requestUuid
detPts
projPts
eqCoeffs
mvAvgRad
characterBoxes
VNGenerateOpticalFlowRequest
Cannot create VTPixelTransferSessionRef object: session: %lu, error: %d
B16@?0@"VNVTSession"8
@"VNVTSession"16@?0^@8
torso_v4_md2.espresso
anodv3_torso_v4_md2
VNDetectFacePoseRequestPrivateRevisionANSTModel
The region of interest [%g, %g, %g, %g] is not within the normalized bounds of [0 0 1 1]
%@ ROI=%@
uuid
 inputFaceObservations=[%@]
 inputDetectedObjectObservations=[%@]
B32@?0@"VNFaceObservation"8Q16^B24
B32@?0@"VNDetectedObjectObservation"8Q16^B24
No entity for identity serial number %d
q24@?0@"VNEntityIdentificationModelPrediction"8@"VNEntityIdentificationModelPrediction"16
entity unique identifier / print count mismatch
invalid observation at index %lu for entity at index %lu
v32@?0@"<NSObject><NSCopying><NSSecureCoding>"8Q16^B24
entityUniqueIdentifiers
entityPrintCounts
entityPrintOriginatingRequestSpecifier
VNCreateAnimalprintRequestPrivateRevision1MD2
{CGRect={CGPoint=dd}{CGSize=dd}}
pixelBuffer cannot be null
pixelBuffer is not in correct format. (Required format is one component, 32-float)
thresholds not provided
Unable to generate smoothed float-32 image buffer
VNRecognizeAnimalsRequestPrivateRevisionANODv3
VNRecognizeAnimalsRequestPrivateRevisionANSTModel
torso_v3_md2_fp16.espresso
anodv3_torso_v3_md2
%@ not available
Unable to setup request in VNDetectHumanBodyPoseRequest
VCPHumanPoseImageRequest
vnpbo_width
vnpbo_height
vnpbo_bpr
vnpbo_pixelFormat
vnpbo_attribs
vnpbo_attach
vnpbo_bytes
%@_%zu
tplTracker_FFT_3324
tplTrackerFFT.c
(outputIndex >= 0) && (outputIndex < 72)
tplTracker_IFFT_3324
VNContourDetectorProcessOption_ContrastAdjustment
VNContourDetectorProcessOption_ContrastPivot
VNContourDetectorProcessOption_DetectDarkOnLight
VNContourDetectorProcessOption_MaximumImageDimension
VNContourDetectorProcessOption_ForceUseInputCVPixelBufferDirectly
VNContourDetectorProcessOption_InHierarchy
VNContourDetector: Failed to create image filters
VNContourDetector: Original buffer could not be found
VNContourDetector: Failed to adjust contrast
VNContourDetector: Failed to create pixel buffer for adjusted image
VNContourDetector: Error extracting contours
VNClassifyFaceAttributesRequestPrivateRevisionCameraLightweight
VNClassifyFaceAttributesRequestPrivateRevision1_3_MD2
VNClassifyFaceAttributesRequestPrivateRevision1_3_MD3
VNClassifyFaceAttributesRequestPrivateRevision1_3_MD3_HomeApp
Empty observations
portrait
landscape
Accurate
Balanced
Fast
@"NSString"16@?0Q8
%@ qualityLevel=%@
%@ useTiling=%d minimumConfidence=%f
VNGeneratePersonSegmentationRequestPrivateRevisionInstanceBased4People
no image buffer available
pixelBuffer
cgImage
ciImage
AdjacentContourHeal
Contours.c
PCOORD_EQUAL(joinPoint, LAST_PCOORD(cPtrN))
PCOORD_EQUAL(joinPoint, FIRST_PCOORD(cPtrN))
healCenters
ady == 2
heal
(endpoint2 == 4)|| (endpoint2 == 8)
(endpoint2 == 8)|| (endpoint2 == 6)
(endpoint2 == 6)|| (endpoint2 == 2)
(endpoint2 == 2)|| (endpoint2 == 4)
testJoin
(orn >= 0) && (orn <= 8)
orn != 4
VNInferenceNetworkIdentifierSmartCam
VNInferenceNetworkIdentifierSceneNet
VNInferenceNetworkHeadIdentifierSceneprint
VNInferenceNetworkHeadIdentifierSceneClassification
VNInferenceNetworkHeadIdentifierAesthetics
VNInferenceNetworkHeadIdentifierSaliencyA
VNInferenceNetworkHeadIdentifierSaliencyO
VNInferenceNetworkHeadIdentifierFeatureExtractor
VNInferenceNetworkHeadIdentifierFingerprinting
VNInferenceNetworkIdentifierSceneNetObjDetNetSliderNet
VNInferenceNetworkHeadIdentifierObjDetNet
VNInferenceNetworkHeadIdentifierSliderNet
VNInferenceNetworkIdentifierStandaloneSceneprint
VNInferenceNetworkIdentifierFaceprint
%@ %@ --> %@
available%@Versions
v24@?0#8^B16
q24@?0@"VNResourceVersion"8@"VNResourceVersion"16
Network does not have head with identifier "%@"
Network does not have input "%@"
Network does not have output "%@"
no inference network for %@ %@
   (%@ %@)
v32@?0@"NSString"8@"VNResourceVersion"16^B24
   --> %@
       
   <-- %@
networkURL
networkVersion
inputs
outputs
inputImages
networkHeadVersions
confidencesOutput
landmarks
facerec_fp3.1.3b_fa1.3.espresso
data
FaceIDModel_v1_d18
aligned buffer allocation of 
 exceeded calculated size of 
matrix vector size mismatch
vector size too small for output
VNHumanHandPoseDetectorProcessOption_MaximumHandCount
Unable to setup request in VNDetectHumanHandPoseRequest
VCPHandPoseImageRequest
VCPRequestRevisionPropertyKey
VCPRequestMaxNumOfHandsPropertyKey
%@ upperBodyOnly=%@
VNDetectHumanRectanglesRequestPrivateRevisionANODv3
VNDetectHumanRectanglesRequestPrivateRevisionANSTModel
ap_conf
VNCreateAnimalprintRequest
learnedmatting-f16-v2.espresso
learnedMatting_createTileWithScale
learnedMatting_pasteTile
VNSegmentationGenerator - output tiles queue is empty
^{__CVBuffer=}84@?0@"<MTLCommandBuffer>"8{CGRect={CGPoint=dd}{CGSize=dd}}16@"<MTLTexture>"48{BufferSize=QQ}56I72^@76
B96@?0Q8Q16{CGRect={CGPoint=dd}{CGSize=dd}}24{CGRect={CGPoint=dd}{CGSize=dd}}56^@88
pixel format unimplemented
Model name: %@, network: %p, plan: %p: context: %p
VN_ALTERNATE_MODEL_RESOURCE_PATH
resourceDirectory must point to a valid reference
model_opt.espresso
Unable to locate %@
Frameworks/LoopKitGeneratedKernels.framework/
%@/%@
Unable to locate resource bundle
anod_v3_d3
Using alternate resource path = %@
Unable to locate resource "%@" of type "%@" in %@
unable to introspect %@
blob "%@" was not found in %@
Invalid inputs specified to inference plan builder
Could not create inference context
Could not create inference plan
Could not create/add network to inference plan
Could not set network configuration: %@
Could not declare network input buffer: %@
Could not declare network output buffer: %@
Could not build inference plan
Unsupported pixel format %lu
Error allocating %lu x %lu CVPixelBuffer with format %lu
inference buffer image with dimensions %ld x %ld cannot be rendered into a pixel buffer with dimensions %ld x %ld
could not lock pixel buffer
Unsupported inference buffer storage type (%lu)
inference buffer image with row bytes size of %ld cannot be rendered into a pixel buffer with %lu bytes per row
Unknown inference buffer type
inference network cannot be nil
Could not bind output buffer to network
Could not bind input buffer to network
Could not feed-forward buffer data because of compatibility of source and destination buffers
alpha
alpha_refined
learned-matting-1512x2016.espresso
DogHead
CatHead
VNRecognizeAnimalHeadsRequestPrivateRevisionANSTModel
(^\s*|\s*$)
true
unordered_map::at: key not found
VNImageRegistrationDetectorProcessOption_ReferenceImageRegistrationSignature
VNImageRegistrationDetectorProcessOption_FloatingImageRegistrationSignature
VNImageRegistrationDetectorProcessOption_MinimumOverlapPercentage
person
water
foliage
VNPanopticSegmentationGeneratorProcessOption_Categories
VNPanopticSegmentationGeneratorProcessOption_OutputPixelFormat
VNPanopticSegmentationGeneratorProcessOption_Rotated
unsupported output pixel format
VNSegmentationGenerator: failed to create pixel buffer
panopticsegmentation-u8-v1.2.espresso
detection/boxes
detection/confidences
detection/ious
segmentation/masks
CPU optical flow not properly initialized
Input pixel buffer invalid pixel format
Failed to lock input pixel buffer
VNDetectionprintTensorKeyMixed2
VNDetectionprintTensorKeyMixed6
VNDetectionprintTensor '%@' is not available
unable to create originating request specifier: %@
tensors
ERTFaceBox::ERTNumCascadeStages
ERTFaceBox::ERTNumTrees
ERTFaceBox::ERTNumPredictions
ERTFaceBox::ERTNodesThresholds
ERTFaceBox::ERTNodesPredictions
ERTFaceBox::ERTNodesFeatureIDs
ERTFaceBox::ERTNodesLeafFlags
ERTFaceBox::ERTGlobalShift
ERTFaceBox::ERTDefaultPixelValue
ERTFaceBox::ERTDefaultFeatureValue
ERTFaceBox::ERTNumXYPairs
ERTFaceBox::ERTXYPairs
ERROR: ERTDefaultPixelValue failed to load from ERT model file!
ERROR: ERTDefaultFeatureValue failed to load from ERT model file!
Error: 
 failed to load from ERT model file!
 unexpected size of value
%@ "%@" %@ %@
shape
Spans.c
spl != NULL
addSpan
This method must be overriden
groupKey
unable to locate point '%@'
AllPoints
recognized points are not available
junk
junk-descriptor-current
junk-classifier-current
junk-classifier-labels-current
VN_junk_classifier_debug_intermediates
.json
VN_DEBUG_DUMP_JUNK_INTERMEDIATES
VN3FNQUJVIs2puI1uPc9mxh7
VNSY8t4EoTztuqIL02g8uVA0
VN6XNMvaRunPpzWjGa9uUHD6
VN4QuphG8kE4qDaDycivBkX5
VN7gQUejje8mmnE9GSTsVBVV
VNa9xpOJNvRoaW9plFGZ9Eo0
VN2vIWnsZbk4Su55oeWfKDq1
VNmNJnu0xlW8CZXt6hJ7Rpb0
VN35FOB1QhtSfYGRIJvTgtTq
VN6ZsEIQ9ri2eF1vhsxw5COm
VN586xt6lvDeEI7qF1vKQLrD
VN4EVgYIp7c9hqurREgYE3oE
VN5M3z9ICRcyCF1ByLEwd9pZ
input__0
add3__0
VNRectangleDetectorProcessOption_Version
VNRectangleDetectorProcessOption_MaximumNumber
VNRectangleDetectorProcessOption_MinimumConfidence
VNRectangleDetectorProcessOption_MinimumAspectRatio
VNRectangleDetectorProcessOption_MaximumAspectRatio
VNRectangleDetectorProcessOption_QuadratureTolerance
VNRectangleDetectorProcessOption_MinimumSize
VNRectangleDetectorProcessOption_HighAccuracy
VNRectangleDetectorProcessOption_CropRect_X
VNRectangleDetectorProcessOption_CropRect_Y
VNRectangleDetectorProcessOption_CropRect_Width
VNRectangleDetectorProcessOption_CropRect_Hight
VNRectangleDetectorProcessOption_OriginalScaleFactor
VNRectangleDetectorProcessOption_TargetScaleY
invalid region of interest: %@
VNRectangleDetectorProcessOption_MinimumAspectRatio value, %f is greater than VNRectangleDetectorProcessOption_MaximumAspectRatio value, %f
 PixelFocalLength value is out of bounds: %f
faceimage
facelocxy
VNFaceDetectorInitOption_MinFaceSize
VNFaceDetectorInitOption_EnableLowMemoryMode
{CGRect={CGPoint=dd}{CGSize=dd}}16@?0@"VNObservation"8
VN_DEBUG_DUMP_FACE_DETECT_INTERMEDIATES
VN_facedetector_debug_intermediates/
_fd_image.vdump
_fd_image.png
_raw_bboxes.json
%@_face_%d
_raw_bbox_crop.png
imageURL
rect
width
VN Face detector debug intermediates written to: %@
invalid tile size of %ld x %ld
invalid tile increment of %lu x %lu
unexpected ROI origin causing %lui rows of %f x %f
VNFaceLandmarkRegion
FLMReg_BBX
FLMReg_BBY
FLMReg_BBW
FLMReg_BBH
FLMReg_PtCnt
FLMReg_OReq
FLMReg_Rev
VNFaceLandmarkRegion2D
FLMReg2D_PtsData
FLMs_PtsAE
FLMReg2D_PtsClsf
VNFaceLandmarkRegion3D
FLMReg3D_PtsData
VNFaceLandmarks
FLMs_Conf
FLMs_PtsCnt
FLMs_PtsData
FLMs_AlgnBBoxX
FLMs_AlgnBBoxY
FLMs_AlgnBBoxW
FLMs_AlgnBBoxH
FLMs_UsrFacingBBoxX
FLMs_UsrFacingBBoxY
FLMs_UsrFacingBBoxW
FLMs_UsrFacingBBoxH
FLMs_OReq
FLMs_Rev
VNFaceLandmarks2D
FLMs2D_CType
FLMs2D_PtsAE
VNFaceLandmarks3D
Failed to unarchive VNFaceLandmarkRegion object due to coding version mismatch: Currently supported: %u; encoded: %u
could not decode originating request
%@ does not provide a default originating request class
Failed to unarchive VNFaceLandmarkRegion object. Error: %@
%@ faceBoundingBox=%@ pointCount=%lu requestRevision=%lu
VNDetectFaceLandmarksRequest
[VNFaceLandmarkRegion2D -initWithRequestRevision:faceBoundingBox:] is not available, use class designated initializers
Failed to unarchive VNFaceLandmarkRegion2D object due to coding version mismatch: Currently supported: %u; encoded: %u
Failed to unarchive VNFaceLandmarkRegion2D object. Error: points buffer size mismatch (data size: %lu; expected: %lu)
Failed to unarchive VNFaceLandmarkRegion2D object. Error: %@
failed to allocate internal points array
{CGSize=dd}
[VNFaceLandmarkRegion3D -initWithRequestRevision:faceBoundingBox:] is not available, use class designated initializers
Failed to unarchive VNFaceLandmarkRegion3D object due to coding version mismatch: Currently supported: %u; encoded: %u
Failed to unarchive VNFaceLandmarkRegion3D object. Error: points buffer size mismatch (data size: %lu; expected: %lu)
Failed to unarchive VNFaceLandmarkRegion3D object. Error: %@
Failed to unarchive VNFaceLandmarks object due to coding version mismatch: Currently supported: %u; encoded: %u
Failed to unarchive VNFaceLandmarks object. Error: %@
Can't use abstract base class. Must be VNFaceLandmarks2D or VNFaceLandmarks3D
%@ pointCount=%lu requestRevision=%lu
Failed to unarchive VNFaceLandmarks2D object due to coding version mismatch:Currently supported: %u; encoded: %u
Unexpected number of landmark points: %lu; expected: %lu
Failed to unarchive VNFaceLandmarks2D object. Error: %@
pointIndices must not be nullptr
Failed to unarchive VNFaceLandmarks3D object due to coding version mismatch: Currently supported: %u; encoded: %u
Failed to unarchive VNFaceLandmarks3D object. Error: %@
bodynet_v1.0.espresso
torso_print__0
inference output results dimensions are incorrect
zero-dimensioned image (%ld x %ld)
array
%@ is nil
The %@ array has %lu items, which is less than the required count of %lu
The %@ array has %lu items, which is more than the maximum allowed of %lu
expectedAncestoralClass
All elements in the %@ array must be a Class object (%@)
All elements in the %@ array must be a VNRequest subclass (%@)
face observations
detected object observations
cluster IDs
The confidence value %f must be in the range [0..1]
The score value %f must be in the range [-1..1]
Async status object is nil
Async status object reported as completed successfully but with an error
Async status object reported as failed but without an error
Invalid async status state
%@ is %d which is not in the range [%d..%d]
%@ is %f which is not in the range [%f..%f]
default value
%@ was given %@
The %@ required option was not found
The '%@' option specifies %@, not the required %@
landmarksflow-gwkf986dmy_63053_plus_8dtz95rnyx_quantized.espresso
Internal error while processing Face Landmarks
Unexpected landmarks constellation (%d) while processing Face Landmarks
Unknown identifier "%@"
%@ [%@]
adjustments
CVMLObservation_CodingVersionCodingKey
CVMLObservation_ConfidenceCodingKey
CVMLFaceprint_CodingVersionCodingKey
CVMLFaceprint_FaceprintCodingKey
CVMLFaceprint_KeyCodingKey
CVMLFaceprint_ProfileCodingKey
CVMLFaceprint_PlatformCodingKey
CVMLImageprintObservation_ObjectCodingKey
CVMLImageprintObservation_VersionCodingKey
CVMLImageprintObservation_ImageprintTypeCodingKey
CVMLImageprintObservation_ImageprintDescriptorCodingKey
CVMLImageprintObservation_UUIDCodingKey
CVMLImageprintObservation_ImageprintTypeColorGabor
CVMLImageprintObservation_ImageprintDescriptorColorGaborVersion
MPImageDescriptor_externalImageId
MPImageDescriptor_exifTimestamp
MPImageDescriptor_quality
MPImageDescriptor_ColorGaborImageDescriptorBuffer_type
MPImageDescriptor_ColorGaborImageDescriptorBuffer_lengthInBytes
MPImageDescriptor_ColorGaborImageDescriptorBuffer_data
MPImageDescriptor_ColorGaborImageDescriptorBuffer_count
MPImageDescriptor_ColorGaborImageDescriptorBuffer_stride
Exporting of legacy CVMLFaceprints is disabled.  Please convert to VNFaceprint and export
CVMLObservation
MPImageDescriptor
CVMLImageprintObservation
Exporting of CVMLObservation_LegacySupportDoNotChange is not allowed.  Please use VNObservation instead.
Exporting of legacy CVMLImageprintObservation_LegacySupportDoNotChange is disabled.  Please convert to VNImageprintObservation and export
Data integrity check failed when unarchiving an object of type: %@
Exporting of legacy MPImageDescriptor_LegacySupportDoNotChange is disabled.  Please convert to VNImageprintObservation and export
ERROR: state cannot be nil
ERROR: invalid image Id format
Tp_data
Tp_elementsCount
Tp_elementsType
Tp_length
Tp_labelsAndConfidence
Tp_VNTorsoprint
tp_conf
Tp_algorithmVersion
Internal error desrializing torsoprint
Deserialized confidence is outside of the valid range
%@; coinfidence = %f
FaceID3Model_v1_d16
vector length < cols
vector length < rows
matrix size too small for output
broadcast op: dimension mismatch
unknown axis value
dimensions of data points mismatch
output distance matrix too small
matrix size mismatch
row index out of range
col index out of range
empty cumsum vector
output matrix size too small
VNVNCoreMLTransformerProcessOption_NormalizedOriginOffsetX
VNVNCoreMLTransformerProcessOption_NormalizedOriginOffsetY
v16@?0^v8
The model does not have a valid input feature of type image
The requested FeaturePrint.scene is not available. Requested revision: %lu
%@:UUID=%@
No valid VNCoreMLModel found in passed in options
The inputImageFeatureName does not point to a MLFeatureTypeImage input.
q24@?0@"VNClassificationObservation"8@"VNClassificationObservation"16
The outputs of the model are of unexpected types.
The confidence scores don't line up with the labls.
v32@?0@8Q16^B24
could not obtain a feature value for key "%@"
VNImageAnalyzerMultiDetectorSceneNetV3R8
VNImageAnalyzerMultiDetectorSceneNetV5
threshold
precision
recall
operation point map data for "%@" is corrupt
scenenet_op-v8d.plist
SceneNet5_op-v8d.plist
unknown operation points identifier "%@"
could not locate the %@ resource for operation points identifier "%@"
missing threshold for "%@"
missing F2 for "%@"
missing precision table for "%@"
invalid precision table for "%@"
missing recall table for "%@"
invalid recall table for "%@"
unable to open %@
Identifier
plist
no data source available
no %@ is defined at %@
VNFaceLegacyFaceCoreFeature_LeftEyeClosedScore
VNFaceLegacyFaceCoreFeature_RightEyeClosedScore
VNFaceLegacyFaceCoreFeature_SmileScore
VNFaceLegacyFaceCore
fcr_profile
fcr_size
fcr_angle
fcr_center
fcr_bbox
fcr_lefteye
fcr_righteye
fcr_mouth
fcr_trackid
fcr_trackduration
fcr_features
@"VNSmartCam5CompoundRequestGroupingConfiguration"24@?0@"VNRequest"8Q16
VNImageClassifierProcessingOption_ImageProcessingType
VNImageClassifierProcessingOption_AveragedSideLength
VNImageClassifierProcessingOption_ScaleImage
VNImageClassifierProcessingOption_ScaleFactor
VNImageClassifierProcessingOption_DebugIntermediatesDumpPath
VNImageClassifierProcessingOption_DebugInfo
B8@?0
MinConfidenceForClassificationRaw
hierarchicalLabelsAndConfidence
MinConfidenceForHierarchical
_source_scaled.png
_source_scaled.vdump
VN Image Classifier debug intermediates written to: %@
<binary-data>
scalingFactor
augmentationMode
numTiles
imageID
_tile_
.png
.vdump
debugID
Attempt to create an imageprint failed
FAFrameRate
parabolaLength
minXDistanceFromLastPointOnParabola
maxXDistanceFromLastPointOnParabola
minYDistanceFromLastPointOnParabola
maxYDistanceFromLastPointOnParabola
maxFramesSkippedToContinueParabolaDetection
input_data__0
prev_mask__0
PersonSeg__predictions__0
personsegmentation-si-01.espresso
FaceRegionMap::Width
FaceRegionMap::Height
FaceRegionMap::Data
FaceRegionMap::Triangles
FaceRegionMap::NormalizedLandmarks
Lower left cheek
Lower right cheek
Between mouth and nose
Between eyebrows
hashes
VNOpticalFlowGeneratorProcessOption_ROIWidth
VNOpticalFlowGeneratorProcessOption_ROIHeight
Optical flow cannot be performed on images with different dimensions
outputPixelFormat
computationAccuracy
Failed to allocate the vector result buffer
NtCreatePixelBuffer
ntModel.cpp
ret == kCVReturnSuccess
net_exempler_reg
net_exempler_cls
r1_kernel
cls1_kernel
classification_x_corr
regress_adjust
EspressoNetExemplarRun
instance_image
EspressoNetInstanceRun
EspressoNetUnload
status == ESPRESSO_STATUS_SUCCESS
.espresso.net
json
v32@?0@"NSString"8@"NSNumber"16^B24
%@ does not contain the blob "%@"
%@ FAS=%@
VNMRCDetectorProcessOption_MRCDecoderOptions
VNMRCDetectorProcessOption_MRCSample
VNMRCDetectorProcessOption_SegmentationMask
VNMRCDetectorProcessOption_UseMLBasedDetector
unable to generate pyramid data
VNCGAffineTransformAttachment
AffineTransform missing afterCropAndScale
invalid transform data in pixel buffer
image is unavailable
returned buffer from network was not in expected format - outputBoxesEspressoBuffer
returned buffer from network was not in expected format - _outputScoresEspressoBuffer
returned buffer from network was not in expected format - _outputRotationEspressoBuffer
unable to create MRCDecoder
Could not decode sample: %@
mrcdetector.espresso
detections
box_cls
rotation
oreq
VNFaceSegmentsVersion
fsRev
fsWidth
fsHeight
fsData
fsNumOfSgmnts
fsBBoxOrgX
fsBBoxOrgY
fsBBoxSzW
fsBBoxSzH
fsLblToProbMap
Data integrity check failed when un-archiving an object of type: %@
Cannot create CVPixelBuffer object
Cannot create CVPixelBuffer object: faceSegments is out of range
Cannot create CVPixelBuffer object: faceSegment parameter is out of range
Cannot create CVPixelBuffer object: region parameter is out of range
Cannot copy face segment probability map. Error = %d
Cannot create CVPixelBuffer object. Error = %d
facerec_fa1.3_lightweight_fp16.espresso
faceprinting is not supported in camera lightweight mode
VNDetectedObjectObservation object is expected to initialize Object Tracker
Object identifier is not initialized in detected object observation
eigenshape
fopen failed
void cvml::util::mapped_model_file_fopen::open_file(const char *)
/Library/Caches/com.apple.xbs/Sources/Vision_Sim/VisionKitFramework/VN/algorithm_util/mapped_model_file.h
ftell failed
fseek failed
Error %s when executing %s in file %s:%d
syslog_assert_failed
common_defines.h
false
::open failed
void cvml::util::mapped_model_file_open::open_file(const char *, bool)
fstat failed
mmap MAP_FAILED
::madvidse failed
virtual void cvml::util::mapped_model_file_open::advise(int) const
polygonListWithBitString failed
B24@?0@"VNDetector"8^B16
Cannot create framework manager singleton
Processing dispatch queue is unavailable
requests
v24@?0@"VNDetector"8^B16
com.apple.VNSession
Invalid contour passed in
Invalid number of points passed for minimum enclosing circle calculation
Cannot calculate minimum enclosing circle for the given set of points
null points array
Invalid points count %ld
A collection must contain 3 points
Number of points in collection must be greater or equal than %lu
Number of points in collection must be greater than zero
null area pointer
null perimeter pointer
VNMPImageDescriptor_exifTimestamp
VNMPImageDescriptor_quality
VNMPImageDescriptor_ColorGaborImageDescriptorBuffer_type
VNMPImageDescriptor_ColorGaborImageDescriptorBuffer_lengthInBytes
VNMPImageDescriptor_ColorGaborImageDescriptorBuffer_data
VNMPImageDescriptor_ColorGaborImageDescriptorBuffer_count
VNMPImageDescriptor_ColorGaborImageDescriptorBuffer_stride
ERROR: Could not compute the image descriptor
ERROR: Could not compute the convnet-based image descriptor
ERROR: Could not compute image registration features
Integer overflow occured when unarchiving an object of type: %@ stride: %zu count: %zu
unable to allocate descriptor data
MPImageDescriptor cannot be serialized without being created
state parameter cannot be nil
Invalid state format
-[VNMPImageDescriptor computeDescriptorForImageData:context:error:]
MPImageDescriptor.mm
error != nil
%u.%u.%u
Food
Drink
VNRecognizeFoodAndDrinkRequestPrivateRevisionANODv4
VNRecognizeFoodAndDrinkRequestPrivateRevisionANSTModel
VNDetectFaceRectanglesRequestPrivateRevisionANFD2Detector
VNDetectFaceRectanglesRequestPrivateRevisionANOD3Detector
VNDetectFaceRectanglesRequestPrivateRevisionANOD3DetectorNoFBBA
VNDetectFaceRectanglesRequestPrivateRevisionANOD4DetectorNoFBBA
VNDetectFaceRectanglesRequestPrivateRevisionLegacyFaceCore
VNDetectFaceRectanglesRequestPrivateRevisionANSTModel
%@:%@:%p:%ld:%d:%d:%d:%f
unsupported pixel format
v32@?0@"NSNumber"8@"VNCIContextsHandler"16^B24
processingDevice
VNDetectFaceCaptureQualityRequestPrivateRevisionV3MD4
vproj
(x; y) = (%f; %f); (r; theta) = (%f; %f)
facequality_regression-n6vfnwub35_11333-quant-fp16.espresso
v3_drop4
%@%s
##INVALID##
VNImageAnalyzerMultiDetectorInitializationOption_Model
VNImageAnalyzerMultiDetectorInitializationOption_RequireObjDetNet
VNImageAnalyzerMultiDetectorInitializationOption_RequireSliderNet
VNImageAnalyzerMultiDetectorProcessingOption_SkipInputImageScaling
VNImageAnalyzerMultiDetectorProcessingOption_ImageCropAndScale
VNImageAnalyzerMultiDetectorProcessingOption_TilingWarningRecorders
VNImageAnalyzerMultiDetectorProcessingOption_CreateSceneprint
VNImageAnalyzerMultiDetectorProcessingOption_SceneprintOriginatingRequestSpecifier
VNImageAnalyzerMultiDetectorProcessingOption_SceneprintIncludeLabelsAndConfidences
VNImageAnalyzerMultiDetectorProcessingOption_SceneprintObservationsArray
VNImageAnalyzerMultiDetectorProcessingOption_CreateCompressedSceneprint
VNImageAnalyzerMultiDetectorProcessingOption_CompressedSceneprintOriginatingRequestSpecifier
VNImageAnalyzerMultiDetectorProcessingOption_CompressedSceneprintObservationsArray
VNImageAnalyzerMultiDetectorProcessingOption_ClassifyScene
VNImageAnalyzerMultiDetectorProcessingOption_SceneOriginatingRequestSpecifier
VNImageAnalyzerMultiDetectorProcessingOption_SceneBlacklist
VNImageAnalyzerMultiDetectorProcessingOption_SceneMaximumLeafLabels
VNImageAnalyzerMultiDetectorProcessingOption_SceneMaximumHierarchicalLabels
VNImageAnalyzerMultiDetectorProcessingOption_SceneMinimumConfidence
VNImageAnalyzerMultiDetectorProcessingOption_SceneObservationsArray
VNImageAnalyzerMultiDetectorProcessingOption_SceneClassificationCustomHierarchy
VNImageAnalyzerMultiDetectorProcessingOption_ClassifyJunk
VNImageAnalyzerMultiDetectorProcessingOption_JunkOriginatingRequestSpecifier
VNImageAnalyzerMultiDetectorProcessingOption_JunkObservationsArray
VNImageAnalyzerMultiDetectorProcessingOption_ClassifyVNVYvzEtX1JlUdu8xx5qhDI
VNImageAnalyzerMultiDetectorProcessingOption_VNVYvzEtX1JlUdu8xx5qhDIOriginatingRequestSpecifier
VNImageAnalyzerMultiDetectorProcessingOption_VNVYvzEtX1JlUdu8xx5qhDIObservationsArray
VNImageAnalyzerMultiDetectorProcessingOption_ClassifyAesthetics
VNImageAnalyzerMultiDetectorProcessingOption_AestheticsOriginatingRequestSpecifier
VNImageAnalyzerMultiDetectorProcessingOption_AestheticsObservationsArray
VNImageAnalyzerMultiDetectorProcessingOption_GenerateSaliencyAHeatMap
VNImageAnalyzerMultiDetectorProcessingOption_SaliencyAOriginatingRequestSpecifier
VNImageAnalyzerMultiDetectorProcessingOption_SaliencyAObservationsArray
VNImageAnalyzerMultiDetectorProcessingOption_GenerateSaliencyOHeatMap
VNImageAnalyzerMultiDetectorProcessingOption_SaliencyOOriginatingRequestSpecifier
VNImageAnalyzerMultiDetectorProcessingOption_SaliencyOObservationsArray
VNImageAnalyzerMultiDetectorProcessingOption_ClassifyVN5kJNH3eYuyaLxNpZr5Z7zi
VNImageAnalyzerMultiDetectorProcessingOption_VN5kJNH3eYuyaLxNpZr5Z7ziRequestSpecifier
VNImageAnalyzerMultiDetectorProcessingOption_VN5kJNH3eYuyaLxNpZr5Z7ziObservationsArray
VNImageAnalyzerMultiDetectorProcessingOption_ClassifyVNdGg5skzXHSAENO6T3enHE
VNImageAnalyzerMultiDetectorProcessingOption_SignificantEventOriginatingRequestSpecifier
VNImageAnalyzerMultiDetectorProcessingOption_VNdGg5skzXHSAENO6T3enHEObservationsArray
VNImageAnalyzerMultiDetectorProcessingOption_ClassifyCityNature
VNImageAnalyzerMultiDetectorProcessingOption_CityNatureOriginatingRequestSpecifier
VNImageAnalyzerMultiDetectorProcessingOption_CityNatureObservationsArray
VNImageAnalyzerMultiDetectorProcessingOption_RecognizeObjects
VNImageAnalyzerMultiDetectorProcessingOption_RecognizeObjectsOriginatingRequestSpecifier
VNImageAnalyzerMultiDetectorProcessingOption_RecognizeObjectsObservationsArray
VNImageAnalyzerMultiDetectorProcessingOption_RecognizeObjectsBlacklist
VNImageAnalyzerMultiDetectorProcessingOption_RecognizeObjectsModelMinimumDetectionConfidence
VNImageAnalyzerMultiDetectorProcessingOption_RecognizeObjectsModelNonMaximumSuppressionThreshold
VNImageAnalyzerMultiDetectorProcessingOption_ClassifyPotentialLandmark
VNImageAnalyzerMultiDetectorProcessingOption_PotentialLandmarkOriginatingRequestSpecifier
VNImageAnalyzerMultiDetectorProcessingOption_PotentialLandmarkObservationsArray
VNImageAnalyzerMultiDetectorProcessingOption_VN1JC7R3k4455fKQz0dY1VhQ
VNImageAnalyzerMultiDetectorProcessingOption_VN1JC7R3k4455fKQz0dY1VhQOriginatingRequestSpecifier
VNImageAnalyzerMultiDetectorProcessingOption_VN1JC7R3k4455fKQz0dY1VhQObservationsArray
VNImageAnalyzerMultiDetectorProcessingOption_CreateImageFingerprints
VNImageAnalyzerMultiDetectorProcessingOption_ImageFingerprintsOriginatingRequestSpecifier
VNImageAnalyzerMultiDetectorProcessingOption_ImageFingerprintsObservationsArray
VNImageAnalyzerMultiDetectorProcessingOption_TilingIsRequired
SceneNet_v5.10.0_vhh2692239_fe1.3_sc3.3_sa2.4_ae2.4_so2.4_od1.5_fp1.5.espresso
sn3_all_heads_combined_299_no_softmax.espresso
sn3_4heads_combined_299_no_softmax.espresso
unsupported model %@
invalid ROI size of %f x %f
custom hierarchy created for revision %lu cannot be used with a detector for revision %lu
junk_leaf.r14.j9.espresso
junk_leaf.labels_basic-v3b.txt
stem/SpatialSqueeze_COPY254
leaf/probabilities
junk_hierarchical.r14.j9.espresso
junk_hierarchical.labels_higher_order-v3b.txt
hierarchical/probabilities
JunkLeaf_v0.11.0_y8pf7cunms-10000.espresso
JunkLeaf_v0.11.0_y8pf7cunms-10000-v3b.txt
2593
fc_leaf_post_act_1
JunkHierarchical_v0.11.0_y8pf7cunms-10000.espresso
JunkHierarchical_v0.11.0_y8pf7cunms-10000.txt
fc_hier_post_act_1
junk classification not supported for %@
vienna.r14.n4.1.espresso
labels_vienna-v1e.txt
landmarks_gating.r14.l3.espresso
landmarks_gating_labels.txt
labels/probabilities
semdev_23y8pwvx7w_18000.espresso
sg_labels.txt
2590
sg.r14.s4.espresso
stem/SpatialSqueeze_NEW254
EventsLeaf_v0.5.0_89sf2c9ryr-157700.espresso
events_gating_labels_basic-v1c.txt
events_fc_post_act_1
events_gating.r14.e4.espresso
d76p746ctq_50001_split.espresso
d76p746ctq_50001.txt
stem/gap/Mean
UrbanNatureLeaf_v0.1.0_ccinynq7s3-5000.espresso
UrbanNatureLeaf_v0.1.0_ccinynq7s3-5000.txt
scenenet_sc2.4_sa1.4_ae1.4_r9_opt_int8_pca256.pcadata
pca256
could not create a sceneprint from tensor vector with %lu elements (%lu bytes)
subject_framing
background
blur
subject_sharpness
timing
lightning
reflections
color_harmony
color_brightness
symmetry
repetition
immersive_feeling
perspective
post_processing
noise
failure
composition
interestingness
object_intrusion
tilt
low_light
failed to create saliency heat map image
fruit
vegetable
fish
seafood
SceneNet5_aesthetic_labels_basic-v8e
scenenet_aesthetic_labels_basic-v8e
inner/sceneprint
SceneNet5_labels_basic-v8d.csv
classification/labels
scenenet_labels_basic-v8d.csv
objectness/map
SceneNet5_detection_labels-v8d.txt
GXdCvXzGnLp59suJyVSan_labels.txt
fingerprint_144x192x2_seed1.sbin
fingerprint/embedding
failed to create image analyzer
Currently executed Detector should not be nil
Timed out waiting for dependent task execution
boomerang
bubble_soap
cider
doll_house
electronic_toy
equipment
logo
logo_other
pinata
raw_cardboard
raw_other
raw_plastic
shoe_other
skysurfing
slipper
sport_other
swing_dancing
tablet
toy_organizer
ammunition
blackjack
blade
body_part
brassiere
firearm
holiday
magic
menorah
minaret
missile
oktoberfest
pistol
primate
projectile
ramadan_lantern
raw_metal
religion
revolver
rifle
sauna
shotgun
tank_army
temple_exterior
thanksgiving
underwear
underwear_male
weapon
SceneNet5_relationships-v8d.txt
scenenet_relationships-v8d.txt
a hierarchical model for detector model %lu is not supported
vegetables
cannot provide identifiers for %@
ContrastCI
WhiteBalanceTempTintCI
HighlightsCI
VibrancyCI
slidernet/HighKeyCI
slidernet/ContrastCI
slidernet/WhiteBalanceTempTintCI
slidernet/ColorCastCI
slidernet/ExposureAndBlackPointCI
slidernet/HighlightsCI
slidernet/VibrancyCI
aesthetics/attributes
VNImageAnalyzerMultiDetectorModelUndefined
VNImageAnalyzerMultiDetectorModelSceneNetV3
VNImageAnalyzerMultiDetectorModelSceneNetV5
VNImageAnalyzerMultiDetectorModelSceneNetV5StillCapturePipeline
VNImageAnalyzerMultiDetectorModel%lu
detection/scores
detection/coordinates
aircraft
automobile
bicycle
bird
bottle
canine
consumer_electronics
feline
furniture
headgear
kite
computer_monitor
motorcycle
musical_instrument
document
people
food
sign
watersport
train
ungulate
watercraft
flower
appliance
sports_equipment
tool
detection/concat
detection/concat_scale_
contrastPivot property must be in the range [%f..%f]
contrastPivot
maximumImageDimension property must be in the range [%lu..%lu]
maximumImageDimension
VNRecognizeDocumentElementIdentifierDocument
VNRecognizeDocumentElementIdentifierText
VNRecognizeDocumentElementIdentifierQRCode
VNRecognizeDocumentElementIdentifierAppCode
initializeCannyEdgeContext
cannyEdge.c
context->blockAddress
thresholdAndConnectCandidateEdges
context->edgeStackSize <= context->width*context->height
VNTorsoprintGeneratorProcessOption_InputDetectedObjectObservation
Could not create torso print generator
unable to lock base address of pixel buffer
Unexpected size of torsoprint descriptor
torso__0
smartcam_onlyfc
HighKeyCI
ColorCastCI
ExposureAndBlackPointCI
HighlightsCI_V2
VibrancyCI_V2
sliderflow-s6xrskinrc_29001.espresso
AEEnhancerNet/
/final_output:0
hash_size
feat_size
projection_matrix
num_hashes
CCTextDetector_EnableDebug
CCTextDetector_DebugPathname
creditCardSubsampleImage.png
votingImage.png
inverseVotingImage.png
/var/mobile/Media/DCIM/ccOutDebug/
textOutFirstPassImage.png
textOutSecondPassImage.png
color profile context must not be NULL
adaptiveOutImage.png
selectedTextOutImageArray.png
uOutImage.png
textBoxRevised
textBoxRevisedNormalized
stubBox
stubBoxNormalized
{{%i,%i},{%i,%i}}
{{%2.4f,%2.4f},{%2.4f,%2.4f}}
textBox
textBoxMM
charBox
charBoxMM
charConfidence
{{1,1},{1,1}}
connectedComponents.png
stubBoxMM
CCTextDetector internal error
q24@?0@"VNTextObservation"8@"VNTextObservation"16
map::at:  key not found
acceptableVersions
entity index %lu, observation index %lu was generated by %@, which is not compatible with the model requirement of %@
maximumElementsPerID
faceIDModel
entity unique identifier counts (%lu) do not agree with the print counts (%lu)
face_quality_v1.0_fp16.espresso
VNEspressoModelFileBasedDetectorOption_InputBlobNames
VNEspressoModelFileBasedDetectorOption_OutputBlobNames
VNEspressoModelFileBasedDetectorOption_NetworkConfiguration
%@ did not provide a valid model file name
%@ did not provide a valid model input image dimensions blob name
Unexpected network input image size
%@:%@:%@
could not obtain the dimensions of "%@"
failed to bind buffer to network
failed to bind pixel buffer to network
inference plan failed to execute
en_US
%@:%@:%p:%ld:%d:%d:%f
crOutput
 "%@" - (%f) revision: %ld
[%@]
childIndex
The contour is too small for polygon approximation
The value for epsilon is invalid. It needs to be bigger than zero but it is %f
3.1.3
softmax_
_output
v4.1
UNKNOWN_0
UNKNOWN_1
UNKNOWN_2
UNKNOWN_3
UNKNOWN_4
UNKNOWN_6
UNKNOWN_7
UNKNOWN_5
UNKNOWN_8
UNKNOWN_9
UNKNOWN_10
UNKNOWN_11
UNKNOWN_12
UNKNOWN_13
UNKNOWN_14
UNKNOWN_15
UNKNOWN_16
UNKNOWN_17
flatten_output
confidence
[%g, %g, %g, %g]
(%g, %g)
box = %@; default box = %@; confidence = %f; rotationAngle = %f; yawAngle = %f label = %d; boxCenter = %@
face model data is unavailable
face observations are not available
VNCreateSceneprintPrivateRevision64DimensionPCA
VNCreateSceneprintPrivateRevision128DimensionPCA
VNCreateSceneprintRequestPrivateRevisionSceneNetV4
VNCreateSceneprintRequestPrivateRevisionSceneNetV4StillCapturePipeline
VNCreateSceneprintPrivateRevision256DimensionPCAStillCapturePipeline
VNCreateSceneprintRequestPrivateRevisionStillCapturePipeline
VNCreateSceneprintPrivateRevision256DimensionPCA
VNCreateSceneprintRequestPrivateRevisionSceneNetV5
VNCreateSceneprintRequestPrivateRevisionSceneNetV5StillCapturePipeline
 useCenterTileOnly
 returnAllResults
.espresso
.espresso.hwx
B32@?0@"NSString"8Q16^B24
merged/probabilities
SCL_v0.3.1_9c7zcipfrc_558001-labels-v3.txt
SCL_v0.3.1_9c7zcipfrc_558001.espresso
Chirality
%@ has an invalid value of %@
VNFaceLandmarkDetectorDNNProcessOption_Constellation
Unsupported constellation type.
Could not compute Landmarks using Landmark Detector due to internal error
Unexpected number of Landmark points (%lu) while processing Face Landmarks request. Expected: %lu
Unexpected number of error estimates for Landmark points (%lu) while processing Face Landmarks request. Expected: %lu
Unexpected number of occlusion entries for Landmark points (%lu) while processing Face Landmarks request. Expected: %lu
Could not run Landmark Detector. Error = %s
VNRequestPerformer_SameOrdinalityRequestsPriorityGroup1Key
VNRequestPerformer_SameOrdinalityRequestsPriorityGroup2Key
v56@?0@"NSArray"8@"NSMutableDictionary"16@"NSMutableDictionary"24@"NSMutableArray"32@"NSMutableArray"40q48
Q16@?0@"NSArray"8
Internal error while sorting requests
v32@?0@"NSString"8@"NSMutableArray"16^B24
q24@?0@"NSNumber"8@"NSNumber"16
v44@?0@"NSArray"8@"VNRequestPerformingContext"16@"VNControlledCapacityTasksQueue"24@"NSObject<OS_dispatch_group>"32B40
Unexpected internal error
q24@?0@"VNRequest"8@"VNRequest"16
VNHomographicImageRegistrationDetectorProcessOption_ReferenceImageBuffer
VNHomographicImageRegistrationDetectorProcessOption_ReferenceImageRegistrationSignature
VNHomographicImageRegistrationDetectorProcessOption_FloatingImageBuffer
VNHomographicImageRegistrationDetectorProcessOption_FloatingImageRegistrationSignature
VNHomographicImageRegistrationDetectorProcessOption_ReferenceImagePixelBufferRef
failed to create a %lu x %lu pixel buffer of type '%c%c%c%c'
failed to warp image
registration of region of interest %@ (%@) cannot be performed on reference image of size %@
failed to create image registration context
VNANFDMultiDetectorProcessingOption_HumanFaceDetectorOriginatingRequestSpecifier
VNANFDMultiDetectorProcessingOption_HumanHeadDetectorOriginatingRequestSpecifier
VNANFDMultiDetectorProcessingOption_HumanDetectorOriginatingRequestSpecifier
VNANFDMultiDetectorProcessingOption_AnimalRecognitionOriginatingRequestSpecifier
VNANFDMultiDetectorProcessingOption_HumanDetectorUpperBody
VNANFDMultiDetectorProcessingOption_HumanDetectorFullBody
VNANFDMultiDetectorProcessingOption_PrecisionRecallThreshold
q24@?0@"VNDetectedObjectObservation"8@"VNDetectedObjectObservation"16
%@%@%@
Failure to create multi-headed object detector.
B48@?0{CGRect={CGPoint=dd}{CGSize=dd}}8^@40
v16@?0@"NSMutableArray"8
The request info is not found for request class %@
Not supported object type: %d
Unexpected number of aligned faces: %lu, should be 1
Unexpected label key for detected object: %d
addDescriptors
GreedyClustering.cpp
elementSize == ELEMENT_SIZE
getMergeableClusters
ci == clusterID
computeInitialMergingList
L0 > mergingTo
.cmap
Unable to determine classification hierarchy for a given request revision: %lu
%@ must provide an implementation for %@
v32@?0@"NSString"8@"NSArray"16^B24
additional relationships must have at least one child identifier
%@: %@, %@
SCRDL
could not decode additional relationships
The classification identifier '%@' does not exist in the hierarchy
VNFaceGazeDirectionUnknown
VNFaceGazeDirectionDifficultToSay
VNFaceGazeDirectionSomewhereElse
VNFaceGazeDirectionCamera
VNFaceGazeDirectionCommonLocation
VNFaceGazeDirectionAnotherFace
VNFaceGazeDirection%@
%@ %@ face %@ %@
, looking at %@
direction
locX
locY
lookFace
gazeMask
Invalid async state - %@
completed: %d: error: %@
facecrop
righteyecrop
facelocmat
lefteyecrop
Input faces not provided to face rectangle aligner
VNImageHashSignatureObservation
Tap coordinates are out of bounds.
Failed to fill image.
output1
Failed to compute image histogram.
Size mismatch during image copy.
VNClusteringAlgorithm_Greedy
VNClusteringAlgorithm_GreedyWithTorso
options parameter cannot be nil
type
unsupported cluster algorithm type
splitIntoMonotonicSpans
SegmentUtilities.c
cPtr->nPnts > 1
!closedP
idx <= monoLength
mergeSegment
sPtr2 != NULL
self isKindOfClass: %@
B24@?0@"VNBarcodeObservation"8@"NSDictionary"16
B24@?0@"CROutputRegion"8@"NSDictionary"16
topLevelRegion
crOutputRegion
requestRevision
v32@?0@"CROutputRegion"8Q16^B24
 transcript="%@"
 shortDescription="%@", type=%ld
%@ %@ model=%@
%@:imageCropAndScaleOption=%lu:Model=%@
Failed to initialize VNCoreMLTransformer
sceneprint could not be generated
no sceneprints defined in observation
The VNCoreMLTransform request failed
Failed to create motion flow estimator
Failed to properly create motion flow estimator
Optical flow incorrect number of images to compare
Unexpected number of buffers for optical flow processing
B24@?0@"VNCIContext"8^@16
B32@?0^{__CVBuffer=}8^{__CVBuffer=}16^@24
Invalid pixel format combinations
VCPRequestFrameWidthPropertyKey
VCPRequestFrameHeightPropertyKey
VCPRequestMotionFlowComputationAccuracyPropertyKey
VCPRequestForceCPUPropertyKey
VCPMotionFlowRequest
Unable to find class %s
@"VNEspressoResources"24@?0@"NSString"8^@16
Option value for option key %@ is a mandatory parameter
Tracker resources
Failed to allocate espresso resources
sgnPrnt
sgnHash
Error deserializing object of type %@
Cannot calculate encoding for hash type: %lu
Cannot encode null-print object 
v32@?0@"VNRectangleObservation"8Q16^B24
Accurate observations count mismatch
VNRemoveBackgroundProcessorOption_PerformInPlace
VNRemoveBackgroundProcessorOption_CropResult
VNRemoveBackgroundProcessorOption_ReturnMask
VNRemoveBackgroundProcessorOption_MaskObservation
VNRemoveBackgroundProcessorOption_LowResInput
subject_lifting_gen1_rev5_gv8dsz6vxu_int8.espresso
input_image
saliency
gating_confidence
removebkgnd_assembleConstraints
removebkgnd_maskimage
removebkgnd_copyCrop
failed to create semaphore
performInPlace
Conditions for in-place execution not met
@"<MTLTexture>"32@?0{BufferSize=QQ}8Q24
v16@?0@"<MTLComputeCommandEncoder>"8
v16@?0@"<MTLCommandBuffer>"8
No pixels meet or exceed alpha threshold
convertYUV420ToRGBA8888: invalid dst size of %lu x %lu
convertYUV420ToRGBA8888: failed to allocate %lu bytes
public.png
convertYUV420ToRGBA8888: src must be YUV420 format!
com.apple.vis.VNEntityIdentificationModel
unknown entity (%@)
unknown model kind %@
readObjectForVersion%uTag:fromInputStream:intoObjectDictionary:md5Context:error:
cannot read model version %u
model data fails checksum validation
model data object %@ is a %@, not the expected %@
%@%lu%@
writeReadOnlyVersion
ToOutputStream:options:md5Context:error:
v24@?0Q8^B16
%@ does not support writing version %@
no entity print originating request specifier is defined
maximumEntities
maximumTrainingPrintsPerEntity
an entity print originating request specifier must be configured
%@ cannot be created from a %@
%@ is generated by %@ instead of %@
q24@?0@"VNRequestSpecifier"8@"VNRequestSpecifier"16
B32@?0@"<VNEntityIdentificationModelPrint>"8Q16^B24
B32@?0@"VNObservation<VNEntityIdentificationModelObservation>"8Q16^B24
VNEntityIdentificationModelTrainedModel
could not decode object of class %@
unable to decode entity unique identifier for tag %@
unable to decode observations for tag %@
v40@?0@"NSArray"8{_NSRange=QQ}16^B32
VNHumanObservation
trsPrnt
upBdyOnly
logits_pos_%ld
logits_neg_%ld
logits_%ld
offsets_%ld
f8@?0
logits_roll_%ld
logits_yaw_%ld
shotflow-8k6zuzd9wy_46860_opt_quantized.espresso
rcnn_output
rcnn_output_scores
rcnn_output_cls
rcnn_output_selected_indices
roll_output
yaw_output
anodv4_drop6_fp16.espresso
face_pose_topk
anst_v1.5.espresso
VNGeneratePersonSemanticsCompoundRequest unimplemented revision/options for %@
v32@?0@"NSNumber"8@"NSMutableArray"16^B24
The request class %@ shall have it's results populated in the results array
smartcam
scorPdiffParameters
exprParameters
blinkParametersApp
smileBlinkParametersGeo
lmarkQuality
exprParamsv1
pupilMeanStd
pupil
Internal error: input specifications are invalid for executing this request
Could not analyze face. Error = %s
Could not get output. Error = %s
Could not get confidence output. Error = %s
Error classifying attributes
Not implemented in abstract class
Input image has invalid pixel format
Input image has invalid width/height
Output image has invalid pixel format
Output image has invalid width/height
Cannot create a face-torso print object
solo_landmarks_s9min6ugm8_opt.espresso
%d_%d
unable to create new pixel buffer
Revision %lu of %@ is deprected and not supported anymore
B24@?0Q8^@16
VNCreateFaceprintRequestPrivateRevision3_1MD2
VNCreateFaceprintRequestPrivateRevision3_1MD3_HomeApp
VNCreateFaceprintRequestPrivateRevision3_1MD3
VNImageSignatureDetectorProcessOption_ImageSignatureprintInput
VNImageSignatureDetectorInitOption_ImageSignatureprintType
VNImageSignatureDetectorInitOption_ImageSignatureHashType
Unknown signature hash type: %lu
B24@?0@"NSString"8^@16
neuralhash_128x96_seed1
Unknown signature print type: %lu
Unknown error creating VNObservation object
Mismatch in signature print type
Unknown signature print type
Mismatch in signature hash type
mismatched faceprint request revision for observation at index %lu, person at index %lu
Face ID model data deserialization failed with code %@
Balanced quality level is handled by compound request
anodv3_pet_v1_md2
output
input
VNFaceBBoxAlignerProcessOption_FaceRawBoxInImageCoordinates_X
VNFaceBBoxAlignerProcessOption_FaceRawBoxInImageCoordinates_Y
VNFaceBBoxAlignerProcessOption_FaceRawBoxInImageCoordinates_Width
VNFaceBBoxAlignerProcessOption_FaceRawBoxInImageCoordinates_Height
VNFaceBBoxAlignerProcessOption_FaceRawBoxInImageCoordinatesMagnified_X
VNFaceBBoxAlignerProcessOption_FaceRawBoxInImageCoordinatesMagnified_Y
VNFaceBBoxAlignerProcessOption_FaceRawBoxInImageCoordinatesMagnified_Width
VNFaceBBoxAlignerProcessOption_FaceRawBoxInImageCoordinatesMagnified_Height
faceBoxPoseAligner-current
Could not map face box aligner model
Failed to allocate memory for face bounding box aligner model data
VNTrackingOption_ProcessingQueue
VNTrackingOption_TrackerKey
VNTrackingOption_TrackerType
VNTrackingOption_TrackingLevel
VNTrackingOption_InputBBox
VNTrackingOption_CVPixelBufferFormat
VNTrackingOption_InputImageMaxWidth
VNTrackingOption_InputImageMaxHeight
VNTrackingOption_TrackingLevelFast
VNTrackingOption_TrackingLevelAccurate
VNTrackingOption_TrackingLevelRPN
Tracker is not initialized
Tracker is busy with previous tracking requests. It needs to be reset to restart tracking sequence
Setting objects to track failed
No frame to track objects was passed to the tracker
Tracking objects failed with error: %llu
no tracker results
failed to initialize object IDs to rectangles dictionary
Conversion to Tracker coordinate system failed
face_quality_v2.0_fp16.espresso
VNSmartCamCombinedAestheticsAndSaliencyDetectorOptionClassifyAesthetics
VNSmartCamCombinedAestheticsAndSaliencyDetectorOptionGenerateSaliencyHeatMap
aesthetics/scores
Could not bind output aesthetics attributes
saliency/map
Could not bind input image buffer
combined_classification_smartCamfanet_0-0011_saliency_bhutc68tnd_aesthetics_3eqm2xn28k.espresso
No aesthetic score data returned
Unexpected aesthetic score input types provided
No attribute data returned
Unexpected attribute scores input types provided
Error allocating VNImageAestheticsObservation
Failed to create observation
+N9mZUAHooNvMiQnjeTJ8g
v32@?0@"NSString"8@16^B24
v32@?0@"VNRequest"8Q16^B24
   +-- %@
Unexpected number of unique observation classes
%@ does not override %@
Cannot generate optical flow
trained model data is not available
trained model entity print originating request is not defined
observations are not available in a read-only model
VNFaceGazeDetectorProcessOption_GazeHeatMapThreshold
VNFaceGazeDetectorProcessOption_CommonGazeLocationRadius
VNFaceGazeDetectorProcessOption_MinimumFaceDimension
unexpected gaze label of %d
Error allocating %lu x %lu CVPixelBuffer with format %@
B24@?0^{__CVBuffer=}8^@16
camgaze_classification_3class_light-nxbrsq87z6_23998_BGR_opt.espresso
gazefollow_3dmaps_cat4-jsk53qcqtz_157500_BGR_quant_fp16.espresso
vector
no request performer available
no image is available
v20@?0@"<NSObject><NSCopying>"8B16
detector type has not been configured for %@
Internal error processing request of class %@
VNGenerateObjectnessBasedSaliencyImageRequestPrivateRevision544x544Input128x128Output
VNGenerateObjectnessBasedSaliencyImageRequestPrivateRevisionSceneNetV4
VNGenerateObjectnessBasedSaliencyImageRequestPrivateRevisionSceneNetV5
The model has reached the maximum identity limit of %lu
identity serial numbers have been exhausted
available person serial numbers is corrupt
VNBlurDetectorProcessOption_MaximumIntermediateSideLength
VNBlurDetectorProcessOption_ImageBlurDeterminationMethod
blurDeterminationMethod
v8@?0
VNImageprintGeneratorProcessOption_Timestamp
no valid initial image buffer was provided
%@:Trk=%@
VNDetectorInternalProcessOption_TorsoBBox_X
VNDetectorInternalProcessOption_TorsoBBox_Y
VNDetectorInternalProcessOption_TorsoBBox_Width
VNDetectorInternalProcessOption_TorsoBBox_Height
Memory for torso bouding box is not allocated
faceOrientationRelativeToUpright
Error in calculating torso bounding box dimensions
Unexpected espresso result
could not create tensor
Could not bind classification/mixed_2/concat_channels
classification/mixed_6/concat_channels
Could not bind classification/mixed_6/concat_channels
classification/mixed_2/concat_channels
detector_print_mixed26.espresso
ConnectedComponents
ConnectedComponents.c
pneighbor(*(Pcoord *)dequeFirst(dbLookup[mnid]), pix)
pneighbor(*(Pcoord *)dequeFirst(dbLookup[nid]), pix)
pneighbor(*(Pcoord *)dequeFirst(dbLookup[mid]), pix)
pneighbor(*(Pcoord *)dequeFirst(dbLookup[pid]), pix)
loc != -1
cidcnt < MAX_CONTOURS
eraseContourPixels
deque != NULL
v16@?0Q8
allocSegments
Segments.c
sdb->nSegments <= sdb->maxSegments
center = %@; radius = %f (diameter = %f)
ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/
VNTensorDataTypeUnknown
VNTensorDataTypeFloat64
VNTensorDataTypeFloat32
VNTensorDataTypeFloat16
VNTensorDataTypeInt32
VNTensorDataTypeInt8
VNTensorDataTypeUInt32
VNTensorDataTypeUInt8
VNTensorDataTypePlanar8Image
VNTensorDataTypePlanarFloat32Image
VNTensorDataType_(%lX)
sizes
Illegal sizes data length of %@
Corrupted sizes data count expected %@, actual %@
VNImageOptionImageOrientation
VNImageOptionProperties
VNImageOptionCameraPixelFocalLength
VNImageOptionCameraIntrinsics
VNImageOptionCIContext
'%c%c%c%c'
%c[%@ %@]
VNElementTypeUnknown
VNElementTypeFloat
VNElementTypeDouble
VNElementType(%lu)
VNImageCropAndScaleOptionCenterCrop
VNImageCropAndScaleOptionScaleFit
VNImageCropAndScaleOptionScaleFill
VNImageCropAndScaleOptionScaleFitRotate90CCW
VNImageCropAndScaleOption(%lu)
%g x %g
[%@ %@]
[%g %g %g %g %g %g]
Face crop orientation is a mandatory parameter
image orientation
feature orientation
options
q24@?0@"VNObservation"8@"VNObservation"16
q24@?0@"VNRecognizedObjectObservation"8@"VNRecognizedObjectObservation"16
%@Revision%lu
Model file %@.bin is missing
Loading Resource Error
Model file %@.dat is missing
B16@?0^@8
NSColor
colorWithCGColor:
One of the output parameters is null
UIImage
imageWithCGImage:
UIBezierPath
bezierPathWithCGPath:
UIGraphicsBeginImageContext
UIGraphicsGetCurrentContext
UIGraphicsGetImageFromCurrentImageContext
UIGraphicsEndImageContext
Could not render path on image %@
/System/Library/Frameworks/UIKit.framework/UIKit
 K-means
indexType
softlink:r:path:/System/Library/PrivateFrameworks/BarcodeSupport.framework/BarcodeSupport
softlink:r:path:/System/Library/PrivateFrameworks/VideoProcessing.framework/VideoProcessing
softlink:r:path:/System/Library/PrivateFrameworks/VideoProcessing.framework/VideoProcessing
softlink:r:path:/System/Library/PrivateFrameworks/VideoProcessing.framework/VideoProcessing
softlink:r:path:/System/Library/PrivateFrameworks/VideoProcessing.framework/VideoProcessing
softlink:r:path:/System/Library/PrivateFrameworks/VideoProcessing.framework/VideoProcessing
softlink:r:path:/System/Library/PrivateFrameworks/VideoProcessing.framework/VideoProcessing
softlink:r:path:/System/Library/PrivateFrameworks/MediaAnalysis.framework/MediaAnalysis
VNRecognizedBodyPointsSpecifier
VNSaliencyHeatmapBoundingBoxGenerator
VNSaliencyAHeatmapBoundingBoxGenerator
VNSaliencyOHeatmapBoundingBoxGenerator
VNCreateNeuralHashprintRequestConfiguration
VNCreateNeuralHashprintRequest
Revisioning
VNDetectHumanHeadRectanglesRequest
VNFaceQualityGenerator
VNDetectScreenGazeRequestConfiguration
VNDetectScreenGazeRequest
VNFaceObservationAccepting
NSObject
CVML_Error
VNANFDMultiDetectorANODv4
VNClusteringLogger
VNSuggestionsLogger
VNGreedyClusteringReadOnly
VNClusteringReadOnly
VNClusteringCancelling
VNGreedyClusteringReadWrite
VNClusteringWritable
VNPersonSegmentationGeneratorInstanceBased4People
VNFaceAnalyzerMultiDetectorBase
VNClustererContextBase
VNClustererReadOnlyContext
VNClustererModelQuerying
VNClustererReadWriteContext
VNClustererModelBuilding
VNClassRegistrar
BehaviorIntrospection
VNHomographyTrackerState
ICFlowControl
ICResultDelegate
VNHomographyTracker
VNAnimalprintDetectorRevision1
VN5xRo0q9Wz9Io02mmbtoLsConfiguration
VN6kBnCOr2mZlSV6yV1dLwB
VNImageAnalyzerBasedDetector
_VNRequestForensicsRequestAndErrorTuple
_VNRequestForensicsRequestAndObservationsCacheKeyTuple
_VNRequestForensicsParentChildRequests
VNRequestForensics
VNObjectAtPointDetectorRevision1
VNError
VNFaceDetectorRevision2
VNClassifyJunkImageRequestConfiguration
VNClassifyJunkImageRequest
VNHumanBodyPoseObservation
VNCRImageReaderDetector
VNObjectTrackerLegacyFaceCore
VN1JC7R3k4455fKQz0dY1VhQ
VNHomographicImageRegistrationRequest
VNSceneClassificationRequestConfiguration
VNSceneClassificationRequest
VNClassifyMemeImageRequest
VNRequestSpecifier
NSCopying
NSSecureCoding
NSCoding
VNRequestSpecifying
VNRequestRevisionProviding
VNRequestClassProviding
Compatibility
VNBlurSignature
VNBlurMeasure
VNTrackingRequest
VNDetectTrajectoriesRequestConfiguration
VNDetectTrajectoriesRequest
VNMultiDetectorOriginalRequestInfo
VNDetector
VNClassCodeProviding
VNDetectorKeyProviding
Vision
VNClassifyPotentialLandmarkRequestConfiguration
VNClassifyPotentialLandmarkRequest
VNImageAnalyzerCompoundRequestGroupingConfiguration
VNImageAnalyzerCompoundRequestGroupingConfigurations
VNImageAnalyzerCompoundRequestConfiguration
VNImageAnalyzerCompoundRequest
VNFaceRegionMap
VNAnimalObservation
VNPersonSegmentationGeneratorSemantics
VNANEProcessingDevice
VNRuntimeUtilities
VNEntityIdentificationModelTrainingData
VNEntityIdentificationModelDataSource
VNEntityIdentificationModelTrainedModelDataProvider
VNFaceprintInferenceNetworkDescriptor
VN4nFZhnOcBOiJmeVWzBWsv
VNCanceller
VNFaceLandmarkDetector
VNFaceAnalyzerCompoundRequestConfiguration
VNFaceAnalyzerCompoundRequestConfigurationGroups
VNFaceAnalyzerFaceObservationGrouping
VNFaceObservationAcceptingInternal
VNFaceAnalyzerCompoundRequest
VNImageBufferManager
VNImageSourceManager
VNImageBufferCache
VNImageBuffer
VNSequencedRequestSupporting
VNCreateTorsoprintRequestConfiguration
VNCreateTorsoprintRequest
VNDetectedObjectObservationAccepting
VNCRImageReaderForDocumentsDetector
_VNWeakSessionsCollection
VNFrameworkManager
VNLegacyForcedCleanupImplementing
VNMTLDeviceWisdomParametersProviding
VNObjectTrackerRevision2
VNMutablePersonsModel
VNPersonsModelDataDelegate
VNPoint
VNRequestProgressProviding
VNRequest
VNWarningRecorder
VNAsyncStatusProviding
VNSizeRange
VNSupportedImageSize
VNRequestConfiguration
VN5kJNH3eYuyaLxNpZr5Z7ziConfiguration
VN5kJNH3eYuyaLxNpZr5Z7zi
VNControlledCapacityTasksQueue
VNControlledCapacityAsyncTasksQueue
VNControlledCapacitySyncTasksQueue
VNTasksQueueCache
VNAsyncTasksQueueCache
VNSyncTasksQueueCache
VNRequestPerformingPriorityGroup1AsyncTasksQueueCache
VNRequestPerformingPriorityGroup2AsyncTasksQueueCache
VNRequestAsyncTasksQueueCache
VNDetectorAsyncTasksQueueCache
VNDetectorSyncTasksQueueCache
VNFaceTorsoprint
VNAnimalprintDetectorBase
VNScreenGazeFaceObjectState
VNScreenGazeState
VNMomentProcessor
VNMPClusteringTreeNodeWrapper
NSFastEnumeration
VNEntityIdentificationModelPrint
VNEntityIdentificationModelObservation
VNGenerateAttentionBasedSaliencyImageRequestConfiguration
VNGenerateAttentionBasedSaliencyImageRequest
VNEspressoDetectedObject
VNMutableEntityIdentificationModel
VNEntityIdentificationModelTrainingDataDelegate
VNVYvzEtX1JlUdu8xx5qhDIConfiguration
VNVYvzEtX1JlUdu8xx5qhDI
VNDetectedPoint
VNRecognizedPoint
VNFaceprint
VNSerializingInternal
SaliencyExtrema
VNSaliencyImageObservation
VNImageSaliencyObservation
VNBrightnessDetector
VNScreenGazeDetector
VNClassifyImageAestheticsRequestConfiguration
VNClassifyImageAestheticsRequest
VNRectangleTracker
VNCVPixelBufferHelper
VNBarcodeObservation
VNDataDetectorSupporting
VNDocumentSegmentationDetector
VNDetectFaceGazeRequestConfiguration
VNDetectFaceGazeRequest
VNPersonsModelFaceID2ModelAdditions
VNPersonsModelFaceModelVIPv2
VNSmartCamClassifier
VNRecognizeObjectsRequestConfiguration
VNRecognizeObjectsRequest
VNFaceExpressionDetector
VNImageTensorDescriptor
VNSceneprint
VNSceneFeaturePrint
VNDetectTextRectanglesRequestConfiguration
VNDetectTextRectanglesRequest
VNPersonsModelAdditions
_VNPersonsModelDataSourceBasedDataProvider
VNPersonsModelFaceModelDataProvider
VNPersonsModel
VNPersonsModelInformation
VNPersonsModelAlgorithm
VNPersonsModelAlgorithmVIPv2
VNPersonsModelAlgorithmVIPv3
VNPersonsModelConfiguration
VNPersonsModelPrediction
VNPersonsModelReadOptions
VNPersonsModelWriteOptions
VNClassifyImageRequestConfiguration
VNClassifyImageRequest
VNImageRegistrationRequest
VNFaceAttributeCategory
VNObjectCloning
VNFaceAttributes
VNMTLDeviceWisdomParameters
VNCreateDetectionprintRequestConfiguration
VNCreateDetectionprintRequest
VNDetectionprintObservation
VNSegmentationGenerator
VNSmartCamprint
VNFingerprintHash
VNImageSignature
VNFaceAnalyzerMultiDetector
VNEntityIdentificationModelWriteOptions
VNMPUtils
VNOperationPointsProvider
VNOperationPointsProviding
VNRecognizeSportBallsRequest
VNFaceSegmentGenerator
VNVideoProcessorCadence
VNVideoProcessorRequestConfigurationPopulating
VNVideoProcessorFrameRateCadence
VNVideoProcessorTimeIntervalCadence
VNVideoProcessorRequestProcessingOptions
VNVideoProcessor
VNRecognizedPointsObservation
VNHumanPoseDetector
VNEntityIdentificationModelConfiguration
VNSingleHeadSceneprintGenerator
ShotflowDetector
ShotflowDetectorANFDv1
ShotflowDetectorANODBase
ShotflowDetectorANFDv2
ShotflowDetectorANODv3
ShotflowDetectorANODv4
ShotflowDetectorANSTv1
VNANFDMultiDetectorANODv3
VNOpticalFlowGenerator
VNFaceDetectorPrivateRevisionLegacyFaceCore
VNEspressoModelClassifier
VNDetectBarcodesRequest
VNDetectBarcodesRequestConfiguration
VNImageNeuralHashprintObservation
VNTrackerManager
VNGuidedUpsamplingGenerator
VNFaceAnalyzerMultiDetectorFPrev3_1FArev1_3_MD3
VNEntityIdentificationModelPrediction
VNGenerateImageFeaturePrintRequestConfiguration
VNGenerateImageFeaturePrintRequest
VNSmartCam5GatingDetector
VNFrameworkDescriptor
VNDetectHumanHandPoseRequestConfiguration
VNDetectHumanHandPoseRequest
VNHumanHandPoseObservation
ANFDDetectedObject
VNMPImageData
VNOperationPoints
_VNUnspecifiedOperationPoints
LKTOpticalFlowGPU
VNNOPRequestConfiguration
VNNOPRequest
VNDetectFaceLandmarksRequestConfiguration
VNDetectFaceLandmarksRequest
VNImageprint
VNOriginatingRequestSpecifierProviding
VNSerializing
VNFaceGeometryEstimator
VNMetalProcessingDevice
VNMetalContext
VNCIFilter
VNCIContrastFromAverageColorFilter
VNCIContrastWithPivotColorFilter
VNCIMultiplicationFilter
VNEspressoModelImageprint
VNFaceAnalyzerMultiDetectorFPrev3_1FArev1_3_MD2
VNImageAestheticsObservation
VNContoursObservation
VNTrajectoryRequestState
VNTrajectoryProcessor
VNFaceRegionMapGenerator
VNObservation
VNDetectedObjectObservation
VNObservationAdditions
VNFaceObservation
VNImageAlignmentObservation
VNImageTranslationAlignmentObservation
VNImageHomographicAlignmentObservation
VNImageScoreObservation
VNImageprintObservation
VNImageBlurObservation
VNImageBrightnessObservation
VNClassificationObservation
VNRecognizedObjectObservation
VNCoreMLFeatureValueObservation
VNPixelBufferObservation
VNRectangleObservation
VNHorizonObservation
VNCluster
VNClusterObservation
VNFeaturePrintObservation
VNSceneObservation
VNSmartCamObservation
VNRecognizedTextObservation
VNTrajectoryObservation
_VNTextObservationCharacterBox
VNTextObservation
VNOpticalFlowObservation
VNHorizonDetector
VNVTSession
VNVTPixelTransferSession
VNVTImageRotationSession
VNVTSessionManager
VNTorsoprintGeneratorPrivateRevision4MD2HomeAIHumanDetectorBased
VNDetectFacePoseRequest
VNImageBasedRequestConfiguration
VNImageBasedRequest
VNDetectedObjectObservationAcceptingInternal
VNImageIdealImageSizeProviding
VNEntityIdentificationModelTrainedModelVIPv3Additions
VNEntityIdentificationModelTrainedModelVIPv3
VNVersionParser
VNCreateAnimalprintRequest
VNHeatMapExtrema
VNHeatMapUtilities
VNGenerateImageSaliencyRequestConfiguration
VNGenerateImageSaliencyRequest
VNRecognizeAnimalsRequest
VNANERuntimeDirectProcessingDevice
VNCVPixelBufferPoolManager
VNTorsoprintGeneratorPrivateRevision3MD2HumanDetectorBased
VNDetectorCache
VNDetectorProviding
VNDetectorReleasing
VNHumanBodyPoseDetector
VNEntityIdentificationModelTrainedModelAdditions
VNEntityIdentificationModelTrainedModel
VNCVPixelBufferConversionHelpers
VNContoursDetector
VNClassifyFaceAttributesRequest
VNGeneratePersonSegmentationRequestConfiguration
VNGeneratePersonSegmentationRequest
VNSequenceRequestHandler
VNPersonsModelFaceModel
_VNDetectorDescriptorIdentifierVersionTuple
_VNInferenceNetworkDescriptorInfo
VNInferenceNetworkDescriptor
VNHomeAppFaceAnalyzerMultiDetectorFPrev3_1FArev1_3_MD3
VNEntityIdentificationModelInformation
VNHumanHandPoseDetector
VNDetectHumanRectanglesRequestConfiguration
VNDetectHumanRectanglesRequest
VNAnimalprint
VNPersonSegmentationGeneratorLearnedMattingTiled
VNMPImageGrouping
VNEspressoResources
VNEspressoHelpers
VNPersonSegmentationGeneratorLearnedMatting
VNRecognizeAnimalHeadsRequest
VNImageRegistrationDetector
VNPanopticSegmentationGenerator
VNDetectObjectAtPointRequestConfiguration
VNDetectObjectAtPointRequest
LKTOpticalFlowCPU
VNDetectionprintTensor
VNDetectionprint
VNDetectFace3DLandmarksRequest
VNTensorDescriptor
VNRecognizedPointsSpecifier
VNJunkIdentifier
VNdGg5skzXHSAENO6T3enHEConfiguration
VN6Mb1ME89lyW3HpahkEygIG
VNRectangleDetector
VNCPUProcessingDevice
VNTorsoprintGeneratorBase
VNClassifyCityNatureImageRequestConfiguration
VNClassifyCityNatureImageRequest
VNDetectDocumentSegmentationRequest
VNImageBlurScoreRequestConfiguration
VNImageBlurScoreRequest
VNFaceDetector
VNFaceLandmarkRegion
VNFaceLandmarkRegion2D
VNFaceLandmarkRegion3D
VNFaceLandmarks
VNFaceLandmarks2D
VNFaceLandmarks3D
VNTorsoprintGeneratorRevision1
VNValidationUtilities
VNFaceLandmarkDetectorRevision3
VNProcessingDescriptor
VN1vLyVSh30UQ26TGBoV8MHv
VNBlacklist
CVMLFaceprint_LegacySupportDoNotChange
CVMLObservation_LegacySupportDoNotChange
CVMLImageprintObservation_LegacySupportDoNotChange
MPImageDescriptor_LegacySupportDoNotChange
VNTrackLegacyFaceCoreObjectRequest
VNTorsoprint
VNMLFeatureProvider
MLFeatureProvider
VNCoreMLModel
VNCoreMLTransformer
VNSceneTaxonomyOperationPoints
VNFaceLegacyFaceCore
VNSmartCam5CompoundRequestGroupingConfiguration
VNSmartCam5CompoundRequest
VNImageClassifier
VNCreateImageprintRequestConfiguration
VNCreateImageprintRequest
ParabolaDetection
VNPersonSegmentationGeneratorFast
VNDetectHumanBodyPoseRequestConfiguration
VNDetectHumanBodyPoseRequest
VNImageFingerprintsObservation
VNOpticalFlowGeneratorRevision1
VNCoreEspressoUtils
VNStatefulRequestConfiguration
VNStatefulRequest
VNMRCDetector
VNFaceScreenGaze
VNFaceSegments
VNFaceAnalyzerMultiDetectorFArev2_CameraLightweight
VNObjectTracker
VNModelFileImpl
VNModelFile
VNModelFilesCache
_VNGlobalSession
VNSession
VNDetectorCacheDelegate
VNTrackerProviding
VNRPNTrackerResourcesProviding
VNRequestWarming
VNWeakSessionWrapper
VNGeometryUtils
VNBoundingCircleAlgorithm
VNContourAreaCalculationAlgorithm
VNContourPerimeterAlgorithm
VNMPImageDescriptor
VNANFDMultiDetectorANFDv2
VNResourceVersion
VNGenerateFaceSegmentsRequestConfiguration
VNGenerateFaceSegmentsRequest
VNRecognizeFoodAndDrinkRequest
VNDetectFaceRectanglesRequestConfiguration
VNDetectFaceRectanglesRequest
VNRecognizeDocumentsRequestConfiguration
VNRecognizeDocumentsRequest
VNDocumentObservationsAccepting
VNCIContextsHandler
VNCIContext
VNCIContextManager
VNDetectFaceCaptureQualityRequestConfiguration
VNDetectFaceCaptureQualityRequest
VNVector
VNTranslationalImageRegistrationRequest
VNFaceQualityGeneratorPrivateRevisionV3MD4
VNCreateSmartCamprintRequestConfiguration
VNCreateSmartCamprintRequest
VNImageAnalyzerMultiDetector
_VNImageAnalyzerMultiDetectorSceneOperationPointsCache
_VNImageAnalyzerMultiDetectorSceneOperationPointsProvider
VNDetectContoursRequestConfiguration
VNDetectContoursRequest
VNRecognizeDocumentElementsRequestElementConfiguration
VNRecognizeDocumentElementsRequestConfiguration
VNRecognizeDocumentElementsRequest
VNTorsoprintGeneratorHumanDetectorBased
VNCreateImageFingerprintsRequestConfiguration
VNCreateImageFingerprintsRequest
VNSliderNetDetector
VNCreateFaceRegionMapRequest
VNPersonsModelMigration
CCCharBoxContext
CCTextDetector
VNEntityIdentificationModelReadOptions
VNObjectTrackerRevision1
VNEntityIdentificationModelTrainedModelVIPv2Additions
VNEntityIdentificationModelTrainedModelVIPv2
VNFaceQualityGeneratorRevision1
VNObservationsCache
VNEspressoModelFileBasedDetector
VNRecognizeTextRequestConfiguration
VNRecognizeTextRequest
VNRecognizedText
VNContour
ShotflowDetection
VNRemoveBackgroundRequestConfiguration
VNRemoveBackgroundRequest
VNDetectRectanglesRequestConfiguration
VNDetectRectanglesRequest
VNReadOnlyPersonsModel
VNPersonsModelDataSource
VNCreateSceneprintRequestConfiguration
VNCreateSceneprintRequest
VNANFDMultiDetectorANSTv1
VNMemeClassifier
VNRecognizedHandPointsSpecifier
VNFaceLandmarkDetectorDNN
VNRequestPerformer
VNRequestCancelling
VNIdentifyJunkRequest
VNHomographicImageRegistrationDetector
VNANFDMultiDetectorOriginalRequestInfo
6 `%`
VNANFDMultiDetector
VNClassificationCustomHierarchy
_VNImageAnalyzerMultiDetectorClassificationCustomHierarchy
VNFaceGaze
VNAsyncStatus
VNProcessingDevice
VNAlignFaceRectangleRequestConfiguration
VNAlignFaceRectangleRequest
VN3XKGTKNBvy6h4RFtpxLyW
VNClustererOptions
VNClustererQueryOptions
VNClustererBuilderOptions
VNClustererQuery
VNClustererBuilder
VNDocumentObservation
VNRecognizedTextBlock
VNRecognizedTextBlockObservation
VNDataDetectorResult
VNCoreMLRequestConfiguration
VNCoreMLRequest
VNOpticalFlowGeneratorRevision2
VNMPContext
VNRPNTrackerEspressoResources
VNRPNTrackerEspressoResourcesCache
VN6Ac6Cyl5O5oK19HboyMBR
VN6B8mkraBUpwUqskMYPtS3
VNGenerateAnimalSegmentationRequestConfiguration
VNGenerateAnimalSegmentationRequest
VNRemoveBackgroundProcessor
_VNEntityIdentificationModelDataSourceBasedTrainedModelDataProvider
VNEntityIdentificationModel
VNHumanObservation
ShotflowNetwork
ShotflowNetworkANFDv1
ShotflowNetworkANODBase
ShotflowNetworkANFDv2
ShotflowNetworkANODv3
ShotflowNetworkANODv4
ShotflowNetworkANSTv1
VNDetectFaceExpressionsRequest
VNGeneratePersonSemanticsCompoundRequest
VNBrightnessMeasure
VNHomeAppFaceAnalyzerMultiDetectorBase
VNEntityIdentificationModelAdditions
VNTrackRectangleRequest
LKTOpticalFlow
VNCreateFaceTorsoprintRequestConfiguration
VNCreateFaceTorsoprintRequest
VNFaceLandmarkDetectorRevision2
OrientationAdditions
VNCreateFaceprintRequestConfiguration
VNCreateFaceprintRequest
VNImageSignatureDetector
VNPersonsModelFaceID3ModelAdditions
VNPersonsModelFaceModelVIPv3
VNGenerateSkySegmentationRequestConfiguration
VNGenerateSkySegmentationRequest
VNTrackObjectRequest
VNFaceBBoxAligner
VNTracker
VNImageExposureScoreRequest
VNFaceQualityGeneratorRevision2
VNSmartCamCombinedAestheticsAndSaliencyDetector
VNCompoundRequest
VNUniqueObservationClassCompoundRequest
VNHomologousObservationClassCompoundRequest
VNGenerateOpticalFlowRequestConfiguration
VNGenerateOpticalFlowRequest
VNReadOnlyEntityIdentificationModel
VNFaceGazeDetector
VNANERuntimeProcessingDevice
VNRequestPerformingContext
VNImageBufferProviding
VNTrackHomographyRequestConfiguration
VNTrackHomographyRequest
VNANFDDetectorCompoundRequestConfiguration
VNANFDDetectorCompoundRequestConfigurationGroups
VNANFDDetectorCompoundRequest
VNGenerateObjectnessBasedSaliencyImageRequestConfiguration
VNGenerateObjectnessBasedSaliencyImageRequest
VNImageRegistrationSignature
VNImageRegistration
VNPersonsModelData
VNBlurDetector
VNImageprintGenerator
VNTargetedImageRequest
VNTorsoprintGeneratorFaceBased
VNDetectionprintGenerator
VNCircle
VNTensorDataTypeAdditions
VNTensorShape
VNEspressoTensorShape
VNImageRequestHandler
VNEntityIdentificationModelAlgorithm
VNEntityIdentificationModelAlgorithmVIPv2
VNEntityIdentificationModelAlgorithmVIPv3
VNDetectHorizonRequest
CGImage
.cxx_destruct
T@"<VNDetectorCacheDelegate>",&
ICReportFrameAnalysis:forPresentationTime:withStats:
T@"NSArray",R,C
ICShouldBeCanceled
T@"NSArray",R,N
T#,R
T@"NSDictionary",R,N,V_features
T#,R,N,V_requestClass
T@"NSNumber",C,N,V_inputFactor2
T*,VpulseVectorHeightCharBoxAdaptive
T@"NSNumber",C,N,V_inputFactor4
T@"<MLFeatureProvider>",&,N,V_featureProvider
T@"NSString",R,C,N,V_identifier
T@"<NSLocking>",R
T@"NSUUID",&,N,SsetUUID:,V_uuid
T@"<NSObject><NSCopying>",R,N,V_observationsCacheKey
T@"VNFaceprint",&,N,V_faceprint
T@"<NSObject><NSCopying><NSSecureCoding>",R,C,V_entityUniqueIdentifier
T@"VNImageTensorDescriptor",R,N
T@"<VNEntityIdentificationModelTrainingDataDelegate>",W,V_delegate
T@?,C,N
T@"BCSDetectedCode",&,N,V_detectedBarcodeSupportCode
TB,N,V_readOnly
T@"CIBarcodeDescriptor",R,N,V_barcodeDescriptor
TB,R,N,GisValid
T@"CRImageReaderOutput",R,C,V_crOutput
TC,V_ii
T@"LKTOpticalFlow",&,N,V_opticalFlow
TQ,N,V_faceprintRequestRevision
T@"MLModel",&,V_model
TQ,N,V_revision
T@"NSArray",&,N,V_clusters
T^v,R,V_context
T@"NSArray",&,N,V_groupedClusteredFaceIdsForCluster
Tf,N,V_precisionRecallThreshold
T@"NSArray",&,N,V_objects
Tf,R,N,V_tastefullyBlurredScore
T@"NSArray",&,N,V_suggestionsForCluster
Tf,V_confidence
T@"NSArray",C,N,V_allLabelsWithConfidences
Tf,V_pitchAngle
T@"NSArray",C,N,V_inputDetectedObjectObservations
Tq,V_nextLeafId
T@"NSArray",C,N,V_originalRequestConfigurations
T{?={?=qiIq}{?=qiIq}{?=qiIq}},R
T@"NSArray",C,N,V_smartCamprints
T{CGPoint=dd},R
T@"NSArray",C,N,V_textObjects
_C0_tex
T@"NSArray",C,V_precisionEstimatesPerPoint
_G0_tex
T@"NSArray",R
_aestheticScore
T@"NSArray",R,C,N
_barcodeRequest
T@"NSArray",R,C,N,V_detectedPoints
_bounds
T@"NSArray",R,C,N,V_labels
_cachedAppClipCodeMetadataValue
T@"NSArray",R,C,N,V_originalRequests
_charBoxContext
T@"NSArray",R,C,N,V_results
_computeZCVectorHighProbability
T@"NSArray",R,D,N
_crOutputRegion
T@"NSArray",R,N,GgetChildren
_descriptorData
T@"NSArray",R,N,GgetRecognizedLanguages
_detectionLevel
T@"NSArray",R,V_precisionEstimatesPerPoint
_detectorMultiSessionAccessLock
T@"NSBundle",R,N,V_frameworkBundle
_explicitlySetMaximumIdentities
T@"NSData",&,N,V_clusterState
_faceAttributes
T@"NSData",&,V_faceprint
_faceObservationsForRegionOfInterestContainingFaceObservations:
T@"NSData",R,C
_faceTorsoprint
T@"NSData",R,C,V_pointsData
_idealDimension
T@"NSData",R,N,V_landmarkPoints3d
_imageprintType
T@"NSData",R,N,V_outputBufferData
_kernel
T@"NSData",R,V_descriptorData
_landmarkPoints
T@"NSDate",R,C,N,V_lastModificationDate
_legacyFaceCore
T@"NSDate",R,N,V_lastModificationDate
_makeupCategory
T@"NSDictionary",&,N,V_representativenessById
_medianLineLock
T@"NSDictionary",C,N,V_detectorConfigurationOptions
_networkFileURL
T@"NSDictionary",R,C,D
_networkVersion
T@"NSDictionary",R,C,V_configurationOptions
_observationGroupConfigurations
T@"NSDictionary",R,D
_olmcsThreshold
T@"NSError",R,N,V_error
_originatingRequestSpecifierKey
T@"NSIndexSet",C,N,V_acceptableVersions
_performInPlace
T@"NSIndexSet",R,C
_points
T@"NSMutableArray",R,N,V_originalRequests
_previousLeafDescriptorDistance
T@"NSNumber",&,N
_radius
T@"NSNumber",&,N,V_cascadeStepCount
_removeExistingFaceObservations:fromPersonWithUniqueIdentifier:
T@"NSNumber",&,N,V_distance
_rightPupilLock
T@"NSNumber",&,N,V_faceCoreInitialAngle
_smartCamprints
T@"NSNumber",&,N,V_faceCoreNumberOfDetectionAngles
_stopSensitized
T@"NSNumber",&,N,V_roll
_torsoThreshold
T@"NSNumber",C,N,V_inputContrast
_userFacingBBox
T@"NSNumber",C,N,V_timeStamp
_videoProcessor
T@"NSNumber",R,C,N
advise:
T@"NSObject<OS_dispatch_queue_attr>",R,D
analysisTypesForProcessOptions:
T@"NSPointerArray",&,N,V_requestImageBuffers
applyTransform:
T@"NSSet",&,N,V_clusteredFaceIds
bBottom
T@"NSSet",R,C
boundingCircleForContour:error:
T@"NSString",&,N
bufferTableLock
T@"NSString",&,N,V_value
bundleWithPath:
T@"NSString",&,V_inputImageKey
compoundResults
T@"NSString",&,V_predictedFeatureKey
computeNumCropCols:width:start:
T@"NSString",C,N,V_additionalCharacters
containsString:
T@"NSString",C,N,V_locateMode
copyFlagValue:toTarget:atIndex:
T@"NSString",C,N,V_type
cornersForCharacterRange:error:
T@"NSString",C,V_faceprintInputPath
T@"NSString",R
currentRevision
T@"NSString",R,C,N
dataWithLength:
T@"NSString",R,C,N,V_imageprintVersion
dealloc
T@"NSString",R,C,N,V_sceneprintVersion
defaultRevision
T@"NSString",R,C,N,V_symbology
detectedObjectClassToRequestKey
T@"NSString",R,C,V_identifier
detectorCache:didEvictDetector:
T@"NSString",R,D,N
dictionaryValue
T@"NSString",R,V_externalImageId
dropTrainedModelAndReturnError:
T@"NSString",R,V_imageFilePath
encodeArrayOfObjCType:count:at:
T@"NSString",R,V_modelName
errorForMemoryAllocationFailure
T@"NSString",R,V_predictedProbabilitiesKey
externalImageId
T@"NSURL",R,N,V_networkFileURL
faceCoreNumberOfDetectionAngles
T@"NSURL",R,V_logFolderURL
faceObservation
T@"NSUUID",R
featureProvider
T@"NSUUID",R,N,V_lookedAtFaceObservationUUID
filterDescriptorWithWidth:height:arrayLength:kernelSpatialDiameter:kernelTemporalDiameter:epsilon:sourceChannels:guideChannels:
T@"NSUUID",R,V_requestUUID
frameworkBundle
T@"VN6Ac6Cyl5O5oK19HboyMBR",C,N,V_inputSignatureprint
getFloatValue:forKey:inOptions:minimumValue:maximumValue:error:
T@"VN6Ac6Cyl5O5oK19HboyMBR",R,V_imageSignatureprint
getRegionLabels
T@"VNAnimalprint",R,N
groupIdentifier
T@"VNAsyncStatus",R,C,V_asyncStatus
identifierCount
T@"VNClassificationCustomHierarchy",&,N,V_customHierarchy
imageProperties
T@"VNClassificationObservation",C,N,V_mostLikelyLabel
imageWithCVImageBuffer:options:
T@"VNControlledCapacityTasksQueue",R
imageprintValid
T@"VNCoreMLModel",R,N,V_model
initWithBox:defaultBox:confidence:scale:rotationAngle:yawAngle:
T@"VNDetectBarcodesRequest",&,N,V_barcodeRequest
initWithCoder:forCodingVersion:
T@"VNDetectionprint",R,C,V_detectionprint
initWithFormat:
T@"VNEntityIdentificationModelAlgorithm",R,C
initWithNode:freeNodeOnDealloc:
T@"VNEntityIdentificationModelConfiguration",R,C
initWithOriginatingRequestSpecifier:faceBoundingBox:pointCount:
T@"VNEspressoResources",R,N,V_espressoResources
initWithState:byteOffset:error:
T@"VNFaceAttributeCategory",R,V_VN1uMyFtnYEWjbrdx3yAuDndKkPeyzNJhB
initWithTargetedImageURL:orientation:options:completionHandler:
T@"VNFaceAttributeCategory",R,V_VN3iT1YRjjnIuELobV1olJiO1vvItN6Kdq
inputDetectedObjectObservations
T@"VNFaceAttributeCategory",R,V_VN7CbCeAogPS2iHE6VQwu6H96xanljtMqk
inputTextBlocks
T@"VNFaceAttributeCategory",R,V_VN7fiLHgGnvqPqG63cfDUCK4Xm8obUuWoP
isAtEnd
T@"VNFaceAttributeCategory",R,V_ageCategory
isProxy
T@"VNFaceAttributeCategory",R,V_eyesCategory
isValid
T@"VNFaceAttributeCategory",R,V_facemaskCategory
keyUsedToCacheResultsOfRequest:
T@"VNFaceAttributeCategory",R,V_hairColorCategory
leftEye
T@"VNFaceAttributeCategory",R,V_makeupEyesCategory
linkTimeOrRunTimeBeforeVersion:
T@"VNFaceAttributeCategory",R,V_smilingCategory
loadedDetectors
T@"VNFaceGaze",R,N,V_gaze
mBottom
T@"VNFaceLandmarkRegion2D",R,V_faceContour
maximumEntities
T@"VNFaceLandmarkRegion2D",R,V_leftEye
medianHeightTop
T@"VNFaceLandmarkRegion2D",R,V_leftPupil
multiArrayValue
T@"VNFaceLandmarkRegion2D",R,V_nose
networkRequiredInputImageHeight
T@"VNFaceLandmarkRegion2D",R,V_outerLips
newCommandQueue
T@"VNFaceLandmarkRegion2D",R,V_rightEyebrow
numberWithBool:
T@"VNFaceLandmarkRegion3D",R,V_allPoints
objects
T@"VNFaceLandmarkRegion3D",R,V_innerLips
orderedRequests
T@"VNFaceLandmarkRegion3D",R,V_leftEyebrow
outputBlobNames
T@"VNFaceLandmarkRegion3D",R,V_nose
pixelFormatType
T@"VNFaceLandmarkRegion3D",R,V_outerLips
pixelsHighRange
T@"VNFaceLandmarkRegion3D",R,V_rightEyebrow
pointerAtIndex:
T@"VNFaceLandmarks2D",R,N
predictedPersonUniqueIdentifier
T@"VNFaceLegacyFaceCore",R,N,V_legacyFaceCore
profile
T@"VNFaceRegionMap",R,N,V_faceRegionMap
projectedPoints
T@"VNFaceSegments",R,N,V_faceSegments
ptrFile
T@"VNImageRegistrationSignature",&,N,V_floatingImageSignature
T@"VNImageSignature",&,N,V_targetImageSignature
recordImageCropQuickLookInfoToOptionsSafe:cacheKey:imageBuffer:
T@"VNMPContext",&,N,V_context
release
T@"VNMetalContext",R,N,V_metalContext
releaseTracker:
T@"VNObservation<VNEntityIdentificationModelObservation>",R,V_observation
requestClassNameFromRequestKey:
T@"VNPersonsModelAlgorithm",R,C,N
requestRevision
T@"VNPersonsModelConfiguration",R,C,N
requiredVersion
T@"VNPixelBufferObservation",R,N,V_globalSegmentationMask
revision:supportsConstellation:
T@"VNPixelBufferObservation",R,V_segmentationMask
seekToEndOfFile
T@"VNPoint",R,V_center
session
T@"VNProcessingDevice",C,N
setAgeCategory:
T@"VNProcessingDevice",R,C,N
setBoundingBox:
T@"VNRecognizeDocumentElementsRequestElementConfiguration",R,V_documentElements
setCharboxROIFullVectorHeight2:
T@"VNRecognizeDocumentElementsRequestElementConfiguration",R,V_textElements
setDebugMatlab:
T@"VNRecognizedTextBlockObservation",R,N,GgetTitle
setKey:
T@"VNRequest",R,N,V_request
setMergesCount:
T@"VNRequestSpecifier",R,C
setMinimumCharacterPixelHeight:
T@"VNRequestSpecifier",R,N,V_landmarks3DOriginatingRequestSpecifier
setMmWidthCard:
T@"VNRequestSpecifier",R,N,V_poseOriginatingRequestSpecifier
setNumberOfKeypointsToConsider:
T@"VNResourceVersion",R,N
setOpticalFlow:
T@"VNSceneObservation",&,N,V_sceneObservation
setStopMaxFind:
T@"VNSizeRange",R,N,V_pixelsHighRange
setTemporalSmoothingFrameCount:
T@"VNSupportedImageSize",&,N,V_detectorPreferredImageSize
setUsesCPUOnly:
T@"VNTasksQueueCache",R,D
setYaw:
T@"VNTensorDescriptor",R,N,V_faceprintOutput
sortBoxes:filterThresholdIndex:
T@"VNTorsoprint",&,N
startSensitized
T@"VNVector",R
stringByAppendingPathComponent:
T@?,C,N,VprogressHandler
stringFromDate:
targetFrameTime
TB,N
topLeft
TB,N,V_automaticallyDetectsLanguage
trackedFrameCVPixelBufferFormat
TB,N,V_detectDiacritics
validTorsoprint
TB,N,V_detectorWantsAnisotropicScaling
validateRequestClassName:error:
TB,N,V_faceCoreEnhanceEyesAndMouthLocalization
versionForStringRepresentation:
TB,N,V_faceCoreExtractSmile
TB,N,V_forceUseInputCVPixelBufferDirectly
.cxx_construct
T@"<NSObject><NSCopying>",R,C,N
ACBSBarcodeTypeForBarcodeSymbology:
T@"NSArray",C,N
ICReportProgress:
T@"NSArray",R,D
MRCSymbologyForBarcodeSymbology:
T@"NSData",R,N,V_landmarkPoints
T#,R,D
T@"NSNumber",C,N,V_inputFactor1
T*,VpulseVectorHeightCharBox
T@"NSNumber",C,N,V_inputFactor3
T,R,N,V_equationCoefficients
T@"NSString",C,N,V_detectorType
T@"<MTLDevice>",&,N
T@"NSString",R,N,GgetTranscript
T@"<NSObject><NSCopying>",C,N,V_modelCachingIdentifier
T@"VN6Ac6Cyl5O5oK19HboyMBR",C,N
T@"<NSObject><NSCopying><NSSecureCoding>",R,C,N,V_predictedPersonUniqueIdentifier
T@"VNFaceprint",R,N,V_faceprint
T@"<VNEntityIdentificationModelDelegate>",&
T@"VNSession",R
T@"<VNPersonsModelDataDelegate>",W,N,V_delegate
TB,N,V_hasLabel
T@"CCCharBoxContext",&,V_charBoxContext
TB,N,V_useSegmentationPregating
T@"CIImage",&,N,V_inputImage
TB,V_performSceneClassification
T@"DDScannerResult",&,N,V_scannerResult
TI,V_stopNormal
T@"MLFeatureValue",R,C,N,V_featureValue
TQ,N,V_personId
T@"MLObjectBoundingBoxOutputDescription",R,V_boundingBoxOutputDescription
TQ,R,N,V_imageSignatureHashType
T@"NSArray",&,N,V_filterThresholds
Tf,N,V_commonGazeLocationRadius
T@"NSArray",&,N,V_landmarkPrecisionEstimatesPerPoint
Tf,N,V_yawAngle
T@"NSArray",&,N,V_suggestedIdsForRepresentative
Tf,R,N,V_wellFramedSubjectScore
T@"NSArray",&,V_qualityCriteriaList
Tf,V_nextLeafDescriptorDistance
T@"NSArray",C,N,V_customWords
Ti,R,N,V_height
T@"NSArray",C,N,V_inputFaceObservations
Tq,V_objectType
T@"NSArray",C,N,V_recognitionLanguages
T{CGPoint=dd},N
T@"NSArray",C,N,V_symbologies
T{CGPoint=dd},R,N,V_bottomRight
T@"NSArray",C,N,VinputTextBlocks
_C1_tex
T@"NSArray",C,V_regionLabels
_G1_tex
T@"NSArray",R,C,D
_analysisPreRollFramesRemaining
T@"NSArray",R,C,N,V_baselines
_blocks
T@"NSArray",R,C,N,V_inputFaceObservations
_buffer
T@"NSArray",R,C,N,V_orderedChildRequests
_center
T@"NSArray",R,C,N,V_projectedPoints
_characterBoxes
T@"NSArray",R,C,V_fingerprintHashes
_contrastFilter
T@"NSArray",R,N,GgetBlocks
_createPixelBufferOfWidth:height:fromImageBuffer:options:error:
T@"NSArray",R,N,GgetLines
_detectedPoints
T@"NSArray",R,N,V_sceneprints
_detectionprint
T@"NSAttributedString",R,C,N,V_attributedString
_device
T@"NSData",&,N,V_alignedMeanShape
_extractOptions
T@"NSData",&,N,V_state
_faceId
T@"NSData",R
_faceScreenGaze
T@"NSData",R,C,N
_height
T@"NSData",R,N
T@"NSData",R,N,V_landmarkPoints65
_inputs
T@"NSData",R,N,V_poseData
_labels
T@"NSData",R,V_rawColorGaborDescriptor
_ledger
T@"NSDate",R,C,V_lastModificationDate
_mSalientRegion
T@"NSDictionary",&,N,V_distancesById
_maximumTrainingPrintsPerEntity
T@"NSDictionary",C,N,SsetACBSBarcodeInfo:,V_acbsBarcodeInfo
_midRow
T@"NSDictionary",R
_networkRequiredInputImageWidth
T@"NSDictionary",R,C,N
_normalizedPath
T@"NSDictionary",R,C,V_labelsAndConfidence
_offsetsOutputs
T@"NSDictionary",R,N,V_faceSegmentLabelToProbabilityMap
_origImageWidth
T@"NSIndexPath",R,V_indexPath
_outputConfidenceEspressoBuffer
T@"NSIndexSet",C,V_acceptableVersions
_pixelWidthCard
T@"NSIndexSet",R,C,N
_preScaleFactor
T@"NSNotificationCenter",R
_previousLeafId
T@"NSNumber",&,N,V_blurScore
_regionOfInterestConfigurations
T@"NSNumber",&,N,V_contrastPivot
_requestToHumanReadableLabelMap
T@"NSNumber",&,N,V_exposureScore
_scenePrintMLMultiArrayDataType
T@"NSNumber",&,N,V_faceCoreMinFaceSize
_smartThreshold
T@"NSNumber",&,N,V_pitch
_topLevelRegion
T@"NSNumber",&,N,V_yaw
_trackerManager
T@"NSNumber",C,N,V_inputPivot
_uv_tex
T@"NSNumber",R
acbsBarcodeInfo
T@"NSNumber",R,N,V_faceCaptureQuality
allKeys
T@"NSObject<OS_dispatch_semaphore>",&,V_cancellationSemaphore
applicableDetectorAndOptions:forRevision:loadedInSession:error:
T@"NSPointerArray",&,N,V_requestImageBuffersCacheKeys
arrayWithArray:
T@"NSSet",R
boundingBoxIsCalculatedProperty
T@"NSSet",R,N
T@"NSString",&,N,V_shortDescription
bundleForClass:
T@"NSString",&,V_imageFilePath
cadence
T@"NSString",&,V_inputScenePrintKey
computeBlurScore:usingBlurSignature:insetFactor:imageROI:error:
T@"NSString",C,N
containsObject:
T@"NSString",C,N,V_cachePath
context
T@"NSString",C,N,V_textRecognition
corners
T@"NSString",C,V_debugFilename
createErrorWithCode:andMessage:
T@"NSString",C,V_key
currentDateTime
T@"NSString",R,C
customHierarchy
T@"NSString",R,C,N,V_featureName
dateFromString:
T@"NSString",R,C,N,V_name
decodeArrayOfObjCType:count:at:
T@"NSString",R,C,N,V_smartCamprintVersion
descriptorsForIdentifier:error:
T@"NSString",R,C,N,V_text
detectorCache:didCacheDetector:
T@"NSString",R,D
detectorWantsAnisotropicScaling
T@"NSString",R,N,V_originatingRequestSpecifierKey
directANEDevice
T@"NSString",R,V_fileNameBase
emptyTorsoprintDataForRevision:
T@"NSString",R,V_level
entityIdentificationModel:numberOfObservationsForEntityAtIndex:
T@"NSString",R,V_networkConfigurationName
expansionRatioWithinValidRange:
T@"NSString",R,V_version
faceBoundingBox
T@"NSURL",R,V_logFileURL
faceIDModelMaximumElementsPerID
T@"NSUUID",C,V_identifier
faceprintOutput
T@"NSUUID",R,N,V_faceObservationUUID
fileURL
T@"NSUUID",R,V_key
filterWithName:
T@"ShotflowDetector",R,N,V_mMultiHeadedANFDDetector
getComputedRectifyingTransform:
T@"VN6Ac6Cyl5O5oK19HboyMBR",R,V_imageNeuralHashprint
getPixelFocalLengthIfAvailable:
T@"VN6B8mkraBUpwUqskMYPtS3",R,V_imageSignatureHash
glassesCategory
T@"VNAsyncStatus",R,C
hasPose
T@"VNCircle",R
imageConstraint
T@"VNClassificationCustomHierarchy",R,C,N
imageTransformForCGOrientation:
T@"VNControlledCapacityTasksQueue",&,N,V_synchronizationQueue
imageWithContentsOfURL:options:
T@"VNControlledCapacityTasksQueue",R,C,N
initWithAnimalprint:confidence:
T@"VNCoreMLModel",R,V_model
initWithCMSampleBuffer:options:
T@"VNDetectedObjectObservation",&,N,V_inputObservation
initWithDevice:andWisdomParams:
T@"VNEntityIdentificationModelAlgorithm",C,N,V_algorithm
initWithLength:
T@"VNEntityIdentificationModelAlgorithm",R,C,V_algorithm
initWithOriginatingRequestSpecifier:compressedPoints:imageSize:
T@"VNEntityIdentificationModelInformation",R,C
initWithPayload:symbolVersion:maskPattern:errorCorrectionLevel:
T@"VNFaceAttributeCategory",R
initWithString:
T@"VNFaceAttributeCategory",R,V_VN2riiZbQrloRhCzYW56f0rk4N3ROe151S
initWithWidth:height:numScales:
T@"VNFaceAttributeCategory",R,V_VN4UfLbvVUqMvYV8bbGFQcxg5yRLm8ekI1
inputImageWidth
T@"VNFaceAttributeCategory",R,V_VN7exwFFmQF0AI9P7FjBljwEFu7QYUGCYE
isAllowedPixelsWide:pixelsHigh:
T@"VNFaceAttributeCategory",R,V_VNpLorzxnyAlLcPFNcKhgoNCmy9b5BRWyk
isEqualToArray:
T@"VNFaceAttributeCategory",R,V_baldCategory
isTitle
T@"VNFaceAttributeCategory",R,V_faceHairCategory
T@"VNFaceAttributeCategory",R,V_glassesCategory
lastTrackedBBox
T@"VNFaceAttributeCategory",R,V_makeupCategory
legacyForcedCleanupWithOptions:
T@"VNFaceAttributeCategory",R,V_makeupLipsCategory
linkTimeVersion
T@"VNFaceAttributes",R,N,V_faceAttributes
lowPriorityCIContextMetalDevice
T@"VNFaceLandmarkRegion2D",R,V_allPoints
manager
T@"VNFaceLandmarkRegion2D",R,V_innerLips
maximumHierarchicalObservations
T@"VNFaceLandmarkRegion2D",R,V_leftEyebrow
modelMinimumDetectionConfidence
T@"VNFaceLandmarkRegion2D",R,V_medianLine
network
T@"VNFaceLandmarkRegion2D",R,V_noseCrest
T@"VNFaceLandmarkRegion2D",R,V_rightEye
normalizedFaceBBoxForLandmarks:
T@"VNFaceLandmarkRegion2D",R,V_rightPupil
numberWithLong:
T@"VNFaceLandmarkRegion3D",R,V_faceContour
observationCountsForAllEntities
T@"VNFaceLandmarkRegion3D",R,V_leftEye
originalCGImage
T@"VNFaceLandmarkRegion3D",R,V_medianLine
performRequests:onImageURL:orientation:gatheredForensics:error:
T@"VNFaceLandmarkRegion3D",R,V_noseCrest
pixelHeightCard
T@"VNFaceLandmarkRegion3D",R,V_rightEye
pixelsWideRange
T@"VNFaceLandmarks2D",&,N,V_landmarks
poseOriginatingRequestSpecifier
T@"VNFaceLandmarks3D",R,N
processImage:withOptions:error:
T@"VNFaceObservation",R,N,V_faceObservation
progressHandler
T@"VNFaceScreenGaze",R,N,V_faceScreenGaze
propertyForKey:
T@"VNFaceTorsoprint",&,N
quality
T@"VNImageRegistrationSignature",&,N,V_referenceImageSignature
read:maxLength:
T@"VNImageprint",&,N,V_imageprint
recordWarnings:
T@"VNMPImageDescriptor",&,N,V_descriptor
releaseQueueWithUniqueAppendix:
T@"VNObservation",&,N,V_originalObservation
request
T@"VNPersonsModelAlgorithm",C,N,V_algorithm
requestPerformerAndReturnError:
T@"VNPersonsModelAlgorithm",R,C,N,V_algorithm
requiredSessionInOptions:error:
T@"VNPixelBufferObservation",R,N,V_gazeMask
results
T@"VNPixelBufferObservation",R,N,V_instanceSegmentationMask
saveAndReturnCurrentModelState:
T@"VNPoint",R
serializeRPNInitializationQueue
T@"VNProcessingDevice",&,N,V_processingDevice
T@"VNProcessingDevice",R
setAnimalprint:
T@"VNRecognizeDocumentElementsRequestElementConfiguration",R
setBox:
T@"VNRecognizeDocumentElementsRequestElementConfiguration",R,V_machineReadableCodeElements
setCustomWords:
T@"VNRecognizedPointsSpecifier",R
setInHierarchy:
T@"VNRequest",R,N,V_parentRequest
setMaxBoxWidth:
T@"VNRequestSpecifier",R
setMinBoxWidth:
T@"VNRequestSpecifier",R,C,V_entityPrintOriginatingRequestSpecifier
setMinimumSize:
T@"VNRequestSpecifier",R,N,V_landmarksOriginatingRequestSpecifier
setNumWarpings:
T@"VNRequestSpecifier",R,V_originatingRequestSpecifier
setNumberStyle:
T@"VNResourceVersion",R,N,V_networkVersion
setStartNormal:
T@"VNSceneObservation",R,&,N
setSymbologies:
T@"VNSizeRange",R,N,V_pixelsWideRange
setTextObjects:
T@"VNSupportedImageSize",C,N
setWithObjects:
T@"VNTensorDescriptor",R,N,V_confidencesOutput
smilingCategory
T@"VNTensorShape",R,N,V_shape
specifiesRequestClass:revision:
T@"VNTorsoprint",R,N,V_torsoprint
strides
T@"VNVideoProcessorCadence",C,V_cadence
stringByAppendingPathExtension:
T@?,R,C,N,V_completionHandler
supportedSymbologiesRev2Private
TB,D,N
textRecognition
TB,N,GisLastFrame,V_lastFrame
trackID
TB,N,V_cropResult
unload:
TB,N,V_detectionOnly
validateAsyncStatusState:error:
TB,N,V_detectsDarkOnLight
version
TB,N,V_faceCoreExtractBlink
vn_encodeValidatedScore:forKey:
TB,N,V_forceFaceprintCreation
TB,N,V_inHierarchy
TB,N,V_isTitle
TB,N,V_isValid
TB,N,V_keepRawOutputMask
TB,N,V_minimizeFalseDetections
TB,N,V_performBlinkDetection
TB,N,V_performInPlace
TB,N,V_preferBackgroundProcessing
TB,N,V_refineLeftEyeRegion
TB,N,V_refineMouthRegion
TB,N,V_refineRightEyeRegion
TB,N,V_reportCharacterBoxes
TB,N,V_returnAllResults
TB,N,V_returnMask
TB,N,V_shouldUpdateRepresentative
TB,N,V_stopAtFirstPyramidWith2DCode
TB,N,V_upperBodyOnly
TB,N,V_useCenterTileOnly
TB,N,V_useMLDetector
TB,N,V_useNonLocalRegularization
TB,N,V_useTiling
TB,N,V_usesAlternateLineGrouping
TB,N,V_usesLanguageCorrection
TB,R
TB,R,D
TB,R,D,N
TB,R,GisReadOnly,V_readOnly
TB,R,N
TB,R,N,GisBoundingBoxAligned,V_boundingBoxAligned
TB,R,N,GisOrientationAgnostic,V_orientationAgnostic
TB,R,N,GisReadOnly,V_readOnly
TB,R,N,GisValidFaceprint
TB,R,N,GisValidTorsoprint
TB,R,N,V_completed
TB,R,N,V_imageprintValid
TB,R,N,V_upperBodyOnly
TB,R,V_logEnabled
TB,R,Vindeterminate
TB,V_computeZCVectorHighProbability
TB,V_debugMatlab
TB,V_debugOut
TB,V_forceFaceprintCreation
TB,V_freeImageInDealloc
TB,V_freeNodeOnDealloc
TB,V_generateSegmentationMask
TB,V_performClustersPostprocessing
TB,V_readOnly
TB,V_recognize
TB,V_useImageAnalyzerScaling
TB,V_useTimestampAdjustedDistances
TC,R,D,N
TC,V_profileNormal
TI,N
TI,N,V_outputPixelFormat
TI,R
TI,R,D
TI,R,N,V_idealImageFormat
TI,R,N,V_idealOrientation
TI,R,N,V_major
TI,R,N,V_micro
TI,R,N,V_minor
TI,R,N,V_pixelFormatType
TI,R,V_inputImageFormat
TI,V_maxBoxWidth
TI,V_maxHeight
TI,V_minBoxWidth
TI,V_minHeight
TI,V_pixelHeightCard
TI,V_pixelWidthCard
TI,V_platform
TI,V_profile
TI,V_startMaxFind
TI,V_startNormal
TI,V_startSensitized
TI,V_stopMaxFind
TI,V_stopSensitized
TI,V_trackedFrameCVPixelBufferFormat
TI,VallocationSize
TQ,N
TQ,N,V_algorithm
TQ,N,V_blurDeterminationMethod
TQ,N,V_clusterId
TQ,N,V_constellation
TQ,N,V_detectionLevel
TQ,N,V_faceCoreType
TQ,N,V_faceId
TQ,N,V_imageCropAndScaleOption
TQ,N,V_imageSignatureHashType
TQ,N,V_imageSignatureprintType
TQ,N,V_landmarksConstellation
TQ,N,V_maximumCandidateCount
TQ,N,V_maximumHierarchicalObservations
TQ,N,V_maximumImageDimension
TQ,N,V_maximumIntermediateSideLength
TQ,N,V_maximumLeafObservations
TQ,N,V_maximumObservations
TQ,N,V_maximumProcessingDimensionOnTheLongSide
TQ,N,V_memoryPoolId
TQ,N,V_metalContextPriority
TQ,N,V_minimumCharacterPixelHeight
TQ,N,V_modelFileBackingStore
TQ,N,V_qualityLevel
TQ,N,V_requestRevision
TQ,N,V_requiredVersion
TQ,N,V_resolvedRevision
TQ,N,V_torsoprintRequestRevision
TQ,N,V_totalObjectCount
TQ,N,V_trackingLevel
TQ,N,V_type
TQ,N,V_version
TQ,R
TQ,R,D
TQ,R,N
TQ,R,N,V_aspectRatioHandling
TQ,R,N,V_backingStore
TQ,R,N,V_bytesPerRow
TQ,R,N,V_confidenceScoreType
TQ,R,N,V_dataType
TQ,R,N,V_faceprintRequestRevision
TQ,R,N,V_idealDimension
TQ,R,N,V_imageSignatureprintType
TQ,R,N,V_inputImageAspectRatioHandling
TQ,R,N,V_maximumDimension
TQ,R,N,V_minimumDimension
TQ,R,N,V_networkRequiredInputImageHeight
TQ,R,N,V_networkRequiredInputImageWidth
TQ,R,N,V_numberOfFaceSegments
TQ,R,N,V_originalRequestResultsIndex
TQ,R,N,V_outputBufferHeight
TQ,R,N,V_outputBufferWidth
TQ,R,N,V_pixelHeight
TQ,R,N,V_pixelWidth
TQ,R,N,V_preferredSmallSide
TQ,R,N,V_profile
TQ,R,N,V_requestRevision
TQ,R,N,V_trackDuration
TQ,R,N,V_version
TQ,R,V_constellation
TQ,R,V_elementCount
TQ,R,V_imageSignatureHashType
TQ,R,V_imageSignatureprintType
TQ,R,V_inputImageHeight
TQ,R,V_inputImageWidth
TQ,R,V_pointCount
TQ,R,V_scenePrintRevision
TQ,R,V_topLevelIndex
TQ,R,V_version
TQ,V_imageCropAndScaleOption
TQ,V_maximumHandCount
TQ,V_version
TS,VfilterWalkUpDownCount
TS,VmedianHeightBottom
TS,VmedianHeightTop
T^Q,VcharBoxFlags
T^S,VcharboxROIFullVectorHeight2
T^S,VcharboxROIFullVectorRowStart
T^f,VfloatVectorSumProd
T^v,R
T^v,R,V_colorGaborDescriptor
T^v,R,V_imageRegistrationDescriptor
T^v,R,V_plan
T^v,R,V_sceneClassifierDescriptor
T^v,V_node
T^{__CVBuffer=},R,N,V_pixelBuffer
T^{__CVBuffer=},R,V_imageCVPixelBuffer
T^{__sFILE=*iiss{__sbuf=*i}i^v^?^?^?^?{__sbuf=*i}^{__sFILEX}i[3C][1C]{__sbuf=*i}iq},R,N
T^{vImage_Buffer=^vQQQ},R,V_image
Td,N
Td,N,V_angle
Td,N,V_detectorExecutionTimeInterval
Td,R
Td,R,N,V_faceAngle
Td,R,N,V_faceSize
Td,R,N,V_movingAverageRadius
Td,R,V_radius
Td,R,V_timeInterval
Td,R,V_x
Td,R,V_y
Tf,N
Tf,N,V_alignedRotationAngle
Tf,N,V_confidence
Tf,N,V_contrastAdjustment
Tf,N,V_faceCoreKalmanFilter
Tf,N,V_faceIdConfidence
Tf,N,V_gazeHeatMapThreshold
Tf,N,V_maximumAspectRatio
Tf,N,V_minimumAspectRatio
Tf,N,V_minimumConfidence
Tf,N,V_minimumFaceDimension
Tf,N,V_minimumSize
Tf,N,V_minimumTextHeight
Tf,N,V_nlreg_sigma_c
Tf,N,V_nlreg_sigma_l
Tf,N,V_nlreg_sigma_w
Tf,N,V_nmsThreshold
Tf,N,V_objectMaximumNormalizedRadius
Tf,N,V_objectMinimumNormalizedRadius
Tf,N,V_olmcsThreshold
Tf,N,V_osfsSizeRatio
Tf,N,V_osfsThreshold
Tf,N,V_pitchAngle
Tf,N,V_quadratureTolerance
Tf,N,V_rotationAngle
Tf,N,V_smartDistanceFactor
Tf,N,V_smartThreshold
Tf,N,V_threshold
Tf,N,V_torsoThreshold
Tf,R
Tf,R,D
Tf,R,N
Tf,R,N,GfaceJunkinessIndex
Tf,R,N,GfaceOrientationIndex
Tf,R,N,V_aestheticScore
Tf,R,N,V_confidence
Tf,R,N,V_failureScore
Tf,R,N,V_harmoniousColorScore
Tf,R,N,V_immersivenessScore
Tf,R,N,V_interestingSubjectScore
Tf,R,N,V_intrusiveObjectPresenceScore
Tf,R,N,V_livelyColorScore
Tf,R,N,V_lowKeyLightingScore
Tf,R,N,V_noiseScore
Tf,R,N,V_pleasantCameraTiltScore
Tf,R,N,V_pleasantCompositionScore
Tf,R,N,V_pleasantLightingScore
Tf,R,N,V_pleasantPatternScore
Tf,R,N,V_pleasantPerspectiveScore
Tf,R,N,V_pleasantPostProcessingScore
Tf,R,N,V_pleasantReflectionsScore
Tf,R,N,V_pleasantSymmetryScore
Tf,R,N,V_sharplyFocusedSubjectScore
Tf,R,N,V_wellChosenBackgroundScore
Tf,R,N,V_wellTimedShotScore
Tf,R,V_aspectRatio
Tf,R,V_confidence
Tf,R,V_quality
Tf,V_inliersRatioThreshold
Tf,V_mmHeightCard
Tf,V_mmWidthCard
Tf,V_modelMinimumDetectionConfidence
Tf,V_modelNonMaximumSuppressionThreshold
Tf,V_naturalClusteringDistanceThreshold
Tf,V_nextLeafTotalDistance
Tf,V_previousLeafDescriptorDistance
Tf,V_previousLeafTotalDistance
Tf,V_roiAreaThreshold
Tf,V_rotationAngle
Tf,V_yawAngle
Tf,VbBottom
Tf,VbTop
Tf,VmBottom
Tf,VmTop
Tf,VposLL
Tf,VposLR
Tf,VposUL
Tf,VposUR
Ti,N,V_label
Ti,N,V_mergesCount
Ti,N,V_nlreg_padding
Ti,N,V_nlreg_radius
Ti,N,V_numWarpings
Ti,N,V_olmcsMergeCountDelta
Ti,N,V_scale
Ti,R,N,V_levelCount
Ti,R,N,V_numScales
Ti,R,N,V_width
Ti,V_clusterSplitDistanceType
Ti,V_debugMode
Ti,V_labelKey
Ti,V_midRow
Ti,V_modelType
Ti,V_numberOfKeypointsToConsider
Ti,V_timerMode
Tq,N
Tq,N,V_qualityLevel
Tq,N,V_recognitionLevel
Tq,N,V_temporalSmoothingFrameCount
Tq,N,V_trajectoryLength
Tq,R
Tq,R,D
Tq,R,N,V_direction
Tq,R,N,V_pointsClassification
Tq,R,N,V_trackID
Tq,R,V_descriptorId
Tq,R,V_exifTimestamp
Tq,R,V_frameRate
Tq,R,V_inputScenePrintMLMultiArrayDataType
Tq,R,V_internalNonSerializedDescriptorId
Tq,V_indexType
Tq,V_nextLeafTimestampDistance
Tq,V_previousLeafId
Tq,V_previousLeafTimestampDistance
Tq,V_trackedFrameNumber
Tr^,R
Tr^,R,V_points
Tr^,V_points
Tr^Q,R,N
Tr^v,R
Tr^v,R,D
Tr^v,R,N
Tr^v,R,V_espressoMaskOutputBufferSizes
Tr^v,R,V_espressoMaskOutputBuffers
Tr^{BufferSize=QQ},R
Tr^{CGPath=},R
Tr^{CGPoint=dd},R
Tr^{FastRegistration_Signatures=^fQ{Projections_meanStdTable=^f^f}^fQ{Projections_meanStdTable=^f^f}*},R
Tr^{__MRCDescriptor=},N,SsetMRCDescriptor:,V_mrcDescriptor
Ts,VloopBigBox
Ts,VloopBigBoxPrev
T{?=[3]},N,V_warpTransform
T{?=[4]},R,N
T{?=^vi},R,V_network
T{?=qiIq},N
T{?=qiIq},N,V_targetFrameTime
T{?=qiIq},R
T{?=qiIq},V_frameAnalysisSpacing
T{?={?=qiIq}{?=qiIq}},N,V_timeRange
T{?=},R,N
T{BufferSize=QQ},R,N
T{CGAffineTransform=dddddd},N
T{CGAffineTransform=dddddd},N,V_alignmentTransform
T{CGAffineTransform=dddddd},N,V_transform
T{CGPoint=dd},N,V_inputPoint
T{CGPoint=dd},R,N
T{CGPoint=dd},R,N,V_bottomLeft
T{CGPoint=dd},R,N,V_faceCenter
T{CGPoint=dd},R,N,V_leftEye
T{CGPoint=dd},R,N,V_location
T{CGPoint=dd},R,N,V_mouth
T{CGPoint=dd},R,N,V_rightEye
T{CGPoint=dd},R,N,V_topLeft
T{CGPoint=dd},R,N,V_topRight
T{CGRect={CGPoint=dd}{CGSize=dd}},N
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_boundingBox
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_box
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_defaultBox
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_regionOfInterest
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,V_boundingBox
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,V_croppedBoundingBox
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,V_faceBoundingBox
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,V_unalignedBoundingBox
T{CGRect={CGPoint=dd}{CGSize=dd}},R,V_faceBoundingBox
T{CGRect={CGPoint=dd}{CGSize=dd}},R,V_userFacingBBox
T{CGRect={CGPoint=dd}{CGSize=dd}},V_bounds
T{CGRect={CGPoint=dd}{CGSize=dd}},V_lastTrackedBBox
T{CGSize=dd},N,V_trackingFrameSizeInPixels
T{CGSize=dd},R
T{CGSize=dd},R,D
T{_Geometry2D_rect2D_={_Geometry2D_point2D_=ff}{_Geometry2D_size2D_=ff}},N,V_alignedBoundingBox
T{_Geometry2D_rect2D_={_Geometry2D_point2D_=ff}{_Geometry2D_size2D_=ff}},R,V_alignedBBox
T{tuple<float, float, float>={__tuple_impl<std::__tuple_indices<0, 1, 2>, float, float, float>=fff}},R
UID_counter
URLByAppendingPathComponent:
URLForIdentifier:error:
URLForResource:withExtension:
UTF8String
UUID
UUIDString
VN1uMyFtnYEWjbrdx3yAuDndKkPeyzNJhB
VN2riiZbQrloRhCzYW56f0rk4N3ROe151S
VN3iT1YRjjnIuELobV1olJiO1vvItN6Kdq
VN4UfLbvVUqMvYV8bbGFQcxg5yRLm8ekI1
VN7CbCeAogPS2iHE6VQwu6H96xanljtMqk
VN7exwFFmQF0AI9P7FjBljwEFu7QYUGCYE
VN7fiLHgGnvqPqG63cfDUCK4Xm8obUuWoP
VNAssert:log:
VNClassCode
VNEntityIdentificationModelPrintByteLength
VNEntityIdentificationModelPrintData
VNEntityIdentificationModelPrintElementCount
VNEntityIdentificationModelPrintElementType
VNEntityIdentificationModelPrintOriginatingRequestSpecifier
VNEntityIdentificationModelPrintWithOriginatingRequestSpecifier:error:
VNObservationsWithOriginatingRequestSpecifier:
VNPersonsModelFaceprintWithRequestRevision:error:
VNPersonsModelSubdataWithRange:rangeDescription:error:
VNPersonsModelSubdataWithRange:rangeDescriptionProvidingBlock:error:
VNTrackerOptionToTrackerType:
VNpLorzxnyAlLcPFNcKhgoNCmy9b5BRWyk
_ACBarcodeRecognizerLocateMode
_Adiagb_buf
_C0_pxbuf
_C1_pxbuf
_G0_pxbuf
_G1_pxbuf
_I_tex
_I_u32_alias_tex
_Ixy_buf
_MRCLocateMode
_VN1uMyFtnYEWjbrdx3yAuDndKkPeyzNJhB
_VN2riiZbQrloRhCzYW56f0rk4N3ROe151S
_VN3iT1YRjjnIuELobV1olJiO1vvItN6Kdq
_VN4UfLbvVUqMvYV8bbGFQcxg5yRLm8ekI1
_VN5kJNH3eYuyaLxNpZr5Z7ziCustomClassifiers
_VN7CbCeAogPS2iHE6VQwu6H96xanljtMqk
_VN7exwFFmQF0AI9P7FjBljwEFu7QYUGCYE
_VN7fiLHgGnvqPqG63cfDUCK4Xm8obUuWoP
_VNEspressoModelImageprintSerializedLength
_VNPointsFromCGPoints:
_VNVYvzEtX1JlUdu8xx5qhDICustomClassifiers
_VNpLorzxnyAlLcPFNcKhgoNCmy9b5BRWyk
_absoluteDiffFilter
_acbsBarcodeInfo
_acceptableVersions
_accessToMutableFaceObservationsForPersonAtIndex:
_actualSizeForDesiredSize:ofSourceImageWidth:height:
_addFaceAnalysisResultsFromMap:toFaceAttributeObject:forOriginatingRequestSpecifier:
_addPointsOfNamedRegion:inLandmarks:toPath:applyingAffineTransform:
_addRelationships:error:
_addUniqueFaceObservations:toPersonWithUniqueIdentifier:error:
_additionalCharacters
_additionalRelationships
_adjustments
_ageCategory
_ageClassifierBabyThreshold
_ageClassifierFilePath
_ageClassifierKidThreshold
_algorithm
_algorithmType
_alignFace:imageBuffer:qosClass:warningRecorder:error:
_alignFacesInContext:faces:qosClass:options:error:
_alignedBBox
_alignedBoundingBox
_alignedMeanShape
_alignedRotationAngle
_alignmentTransform
_allBarcodeSymbologiesRev1
_allBarcodeSymbologiesRev2
_allBarcodeSymbologiesRev2Private
_allClassificationIdentifiers
_allLabelsWithConfidences
_allPoints
_allPointsLock
_allPropertyNames
_allRecognizedPoints
_allocateCRCharBoxContext:
_allocateSumDerivVectors:size:
_allocateVImageWithWidth:height:rowBytes:imageOut:
_alternatePathForEspressoResource:ofType:error:
_analysisSemaphore
_analysisSession
_analyzePixelBuffer:options:error:
_angle
_animalprint
_applyMaskComputeState
_area
_aspectRatio
_aspectRatioHandling
_assembleConstraintsState
_asyncStatus
_asyncStatusLock
_attributedString
_automaticallyDetectsLanguage
_availablePersonSerialNumbers
_availableSerialNumbers
_backingStore
_baldCategory
_barcodeDescriptor
_barcodesDetectedInImageBuffer:usingACBSConfig:originatingRequestSpecifier:error:
_baselines
_bindBuffer:toNetworkBlobName:bindMode:error:
_bindPixelBufferToTexture:error:
_blacklistedIdentifiers
_blinkScore
_blurDeterminationMethod
_blurScore
_booleanBytesData_DO_NOT_DIRECTLY_ACCESS
_bottomLeft
_bottomRight
_boundingBox
_boundingBoxAligned
_boundingBoxGenerator
_boundingBoxOutputDescription
_box
_boxesBuffer
_buildCalibrationMatrix:calibrationMatrix:error:
_bytesPerRow
_cacheDirectoryPath
_cacheFolderPath
_cachePath
_cachedAllSceneClassificationsFromLastAnalysis
_cachedAllSceneClassificationsFromLastAnalysisAccessLock
_cachedCalculatedHash
_cachedDependencyProcessingOrdinality
_cachedDetectorOfClass:configuredWithOptions:
_cachedFloatingImageBuffer
_cachedFloatingImageSignature
_cachedHashValue
_cachedLandmarks
_cachedLandmarks3d
_cachedLandmarks3dLock
_cachedLandmarks65
_cachedLandmarks65Lock
_cachedLandmarksLock
_cachedMetalDeviceWisdomParametersAndReturnError:
_cachedPayloadDataValue
_cachedPayloadStringValue
_cachedPersonUniqueIdentifierToFaceprintCountMapping
_cachedRequestClass
_cachedRequestClassName
_cachedRequestResults
_cachedSaliencyHeatmapBoundingBoxGenerators
_cachedSupportedClassificationIdentifiers
_cachedTrackerResourcesConfiguredWithOptions:
_cadence
_calculateHomographicWarpTransform:ofFloatingImagePixelBuffer:ontoReferenceImagePixelBuffer:usingImageRegistrationContext:seededWithPreviousWarpTransform:error:
_calculateImageSignatureHashDescriptorFrom:options:error:
_calculateImageSignatureprintDescriptorFromOptions:error:
_calculateNumberOfTilesForNetworkInputImageSize:networkInputMaskSize:networkOutputMaskSize:rotated:
_calculateProbabilityNormalSumsForRect:
_calculateTorsoBBoxFromFaceBBox:insideImageWithSize:faceOrientationRelativeToUpright:torsoBBox:error:
_calculatedStorageByteCount
_cancellableUpdate:facesToMove:requestRevision:
_cancellationQueue
_cancellationResourcesLock
_cancellationSemaphore
_cancellationTriggered
_canceller
_cascadeStepCount
_checkInitInputs:cachePath:checkType:requestRevision:error:
_checkedCachedResultsOnBehalfOfRequest
_childRequestsImplicitlyPerformedOnBehalfOfParentRequest:
_chirality
_ciContext
_ciContextManager
_ciContrastFromAvgFilter
_ciContrastWithPivotFilter
_cityNatureGatingCustomClassifiers
_classifyAesthetics:generateSaliencyHeatMap:for32BGRAImageInPixelBuffer:withOptions:modelInputImageSize:originalImageSize:regionOfInterest:warningRecorder:error:
_clusterId
_clusterSplitDistanceType
_clusterState
_clusteredFaceIds
_clusterer
_clusteringLogger
_clusters
_colorGaborDescriptor
_commandQueue
_commonGazeLocationRadius
_completed
_completionHandler
_compressedPoints
_computationAccuracy
_computeBoundingBoxes
_computeColumnSumsOverRange:sampleImageAddress:rowSumOut:rowDerivOut:
_computeFeaturesDerivativesWithCommandBuffer:in_tex:out_tex:
_computeFeaturesWithCommandBuffer:in_tex:out_tex:
_computeLabel
_computeOpticalFlow
_computePipelines
_computeProdBoostNormalizedResult:size:binOverride:
_concatenateFaceprintImageDescriptorBuffer:withFaceprints:forIdentityWithSerialNumber:faceprintLabels:
_confidence
_confidenceScoreType
_confidencesBuffer
_confidencesOutput
_configuration
_configurationOptions
_configureVNProcessingDescriptorIdentifierSceneNetV3DetectorConfigurationOptions:
_configureVNProcessingDescriptorIdentifierSceneNetV3_ObjDetNet_SliderNetDetectorConfigurationOptions:
_constellation
_context
_contextsLock
_contourChildrenIndices
_contourPoints
_contrastAdjustment
_contrastPivot
_convertCornerObservationsToRectangleObservation:error:
_convertOptionsToFaceCoreDetectOptions:
_convertOptionsToFaceCoreExtractOptions:
_convertOptionsToFaceCoreSetupOptions:
_convertVNOptionsToFaceCoreDetectOptions:
_convertVNOptionsToFaceCoreExtractOptions:
_convertVNOptionsToFaceCoreOptions:optionsMap:
_convertVNOptionsToFaceCoreSetupOptions:
_copyCropComputeState
_cornerTrackersImpl
_cpuContextsHandler
_crOutput
_createACBSConfigAndReturnError:
_createCroppedAndScaledBufferFromVNImageBuffer:regionOfInterest:withOptions:error:
_createFaceLandmarks2DRegionOfPoints:fromPointIndexes:andPointCount:
_createFaceSegmentProabilityDataPixelBufferWithSize:error:
_createGeneratorOptionsForRequestRevision:session:images:previousTargetImageIsCurrentRefImage:previousObservation:
_createGreedyClusterer:state:error:
_createHomographicPixelBufferFromImageBuffer:cropRect:options:error:
_createImagePyramidWithCommandBuffer:in_pixelbuf:I_idx:error:
_createMRCDecoderOptionsForRevision:error:
_createN:CVPixelBuffers:withPixelFormat:width:height:error:
_createNSArrayFrom:withPointIndices:andPointCount:
_createPixelBufferFromImageBuffer:regionOfInterest:maximumIntermediateSideLength:options:error:
_createPointArray:count:
_createScaledImagePixelBufferFromCropRect:ofImageBuffer:inPixelFormat:forDetectorInputImageSize:usingAnisotropicScaling:error:
_createScaledImagePixelBufferFromImageBuffer:inPixelFormat:forDetectorInputImageSize:usingAnisotropicScaling:error:
_createTileWithScaleComputePipelineState
_createTracker:type:options:error:
_createTrackerWithLevel:options:error:
_createVCPVideoProcessorRequestConfiguration
_cropCIImage:outBuffer:width:height:format:cropRect:performCrop:options:rotate90CCW:error:
_cropCVPixelBuffer:outBuffer:width:height:format:cropRect:performCrop:options:rotate90CCW:error:
_cropImageSourceManager:outBuffer:width:height:format:cropRect:performCrop:options:rotate90CCW:error:
_cropResult
_croppedBoundingBox
_currentFrame
_currentImageHeight
_currentImageWidth
_currentNetworkHeight
_currentNetworkWidth
_current_frame_index
_customHierarchy
_customWords
_cvPixelBufferPoolManager
_dataSource
_dataSource_DO_NOT_ACCESS_DIRECTLY
_dataType
_deallocateBuffer
_debugFilename
_debugMatlab
_debugMode
_debugOut
_defaultBox
_defaultBoxSizes
_defaultProcessingDevice
_defaultRevisionForBuildVersion:
_defaultSceneClassificationHierarchicalModel
_delegate
_delegateFlags
_delegate_DO_NOT_ACCESS_DIRECTLY
_descriptor
_descriptorId
_descriptorIdentifier
_descriptorIdentifierToVersionsArray
_descriptorVersion
_detectContoursRequest
_detectCreditCardTextWithRequestPerformingContext:requestRevision:error:
_detectDiacritics
_detectFacesInImage:error:
_detectOptions
_detectTextWithRequestPerformingContext:requestRevision:error:
_detectedBarcodeSupportCode
_detectedObjectObservationsForRegionOfInterestContainingDetectedObjectObservations:relationWithRegionOfInterest:
_detectionOnly
_detectionprintTensorForOutputBuffer:originatingRequestSpecifier:error:
_detector
_detectorAccessingLock
_detectorCache_onlyAccessWithDetectorAccessingLock
_detectorClass
_detectorConfigurationOptions
_detectorDescriptorIdentifierVersionTuples
_detectorExecutionTimeInterval
_detectorModel
_detectorPreferredImageSize
_detectorType
_detectorTypesForIdentifier:
_detectorWantsAnisotropicScaling
_detectors
_detectsDarkOnLight
_determineAnimalsToProcessFrom:outputAnimalsThatNeedNoProcessing:outputAnimalsThatNeedAnimalprints:
_dilateFilter
_dilateRadius
_direction
_distance
_distancesById
_doNLRegularizationWithCommandBuffer:in_uv_tex:join_tex:w_tex:out_uv_tex:
_doSolverWithCommandBuffer:scale:scale_xy_inv:coeff:in_uv_tex:out_uv_tex:out_w_tex:
_documentElements
_documentIdentifierToSceneLabels
_downscale2XWithCommandBuffer:in_u32_alias_tex:out_u32_alias_tex:
_dumpIntermediatesFullImage:imageURL:requiredImageSource:imageProcessingType:error:
_dumpIntermediatesTiles:imageURL:requiredImageSource:imageProcessingType:allocatedTileCount:imageTiles:bytesPerPixel:numTiles:scaleFactor:augmentationMode:scalingImage:error:
_elementCount
_elementType
_entityIdentificationModel
_entityPrintCounts
_entityPrintOriginatingRequestSpecifier
_entityUniqueIdentifier
_entityUniqueIdentifiers
_equationCoefficients
_error
_espressoConfidencesOutputBuffer
_espressoContext
_espressoInputImageSize
_espressoInputMaskSize
_espressoMaskInputBufferSize
_espressoMaskOutputBufferSizes
_espressoMaskOutputBuffers
_espressoNetwork
_espressoPlan
_espressoResources
_executionNanoseconds
_exifOrientationFromFaceRollAngle:exifOrientation:error:
_exifTimestamp
_explicitlySetMaximumTrainingFaceprintsPerIdentity
_exposureScore
_expressionsAndScores
_externalImageId
_extractCharBoxCuts:heightConstraint:medianHeightTopVector:medianHeightBottomVector:isAdaptive:
_extrema
_extremeValues
_eyesCategory
_faceAngle
_faceAttributesPupilRefiner
_faceBBoxAligner
_faceBoundingBox
_faceBoundingBoxExpansionRatio
_faceCaptureQuality
_faceCenter
_faceContour
_faceContourLock
_faceCoreEnhanceEyesAndMouthLocalization
_faceCoreExtractBlink
_faceCoreExtractSmile
_faceCoreInitialAngle
_faceCoreKalmanFilter
_faceCoreMinFaceSize
_faceCoreNumberOfDetectionAngles
_faceCoreType
_faceDetector
_faceHairCategory
_faceIDModel
_faceIdConfidence
_faceJunkinessIndex
_faceModel_DO_NOT_ACCESS_DIRECTLY
_faceObjectStates
_faceObservation
_faceObservationUUID
_faceOrientationIndex
_faceRegionMap
_faceSegmentLabelToProbabilityMap
_faceSegmenterDNN
_faceSegmenterMaximumInputImageAspectRatio
_faceSegments
_faceSize
_facemaskCategory
_faceprint
_faceprintInputPath
_faceprintOutput
_faceprintRequestRevision
_faceprintRevision
_failureScore
_featureName
_featureProvider
_featureValue
_features
_fileNameBase
_fillFaceSegmentLabelToProbabilityMap:error:
_filterThresholds
_fingerprintHashes
_floatingImageSignature
_flushMetalDeviceWisdomParametersCache
_forceFaceprintCreation
_forceUseInputCVPixelBufferDirectly
_forestAlgoParams
_frameAnalysisSpacing
_frameIndex
_frameRate
_frameworkBundle
_frameworkManager
_frameworkOperationPointsIdentifier
_freeCRCharBoxContext
_freeContexts
_freeImageInDealloc
_freeNodeOnDealloc
_freeSumDerivVectors:
_freeVImage:
_futharkRecognitionLanguage
_gaze
_gazeFollowPredictor
_gazeHeatMapThreshold
_gazeMask
_gazePredictor
_generalConfigurations
_generateAdaptiveBinarization:adaptImage:useLowLightEnhancement:
_generateAndApplyColorProfileForImage:votingImage:textOut:minMaxRGB:lowHighRGB:numCropRows:rowStartLocation:rowStopLocation:sumTextOutFirstPass:useLowLightEnhancement:
_generateBinarizationForImage:textOut:firstOrSecondPassIndicator:minMaxRGB:
_generateBoxes:pulseVector:uImage:countBigBoxOut:bigBoxes:bigBoxesA:useLowLightEnhancement:
_generateCC:ccBigBoxes:textOut:countBigBox:bufferHeight:
_generateCRCharBoxInformation:inputImage:singleVotingImageAddressRef:bigBoxes:bigBoxesAdapt:textOut:adaptOut:lowHighRGB:countBigBox:useLowLightEnhancement:
_generateCRCharBoxInformation_TrackBox:finalCharBoxCoordCount:
_generateCRCharBoxInformation_extendTextBoxes:countBigBox:rowStartLocation2:finalCharBoxCoordCount:finalCoordinatesForStubRevised:width:height:bigBoxIndicator:
_generateCRCharBoxInformation_spaceBoxRemovalHistogram:zcStartLeft:zcStopRight:rowStartLocation2:lowHighRGB:histCompliancePercent:varSpaceBox:
_generateCRCharBoxInformation_spaceBoxRemovalMagicThresh:magicMinHeight:magicMaxHeight:rowStartLocation2:magicThresh:magicThreshPrev:useLowLightEnhancement:
_generateCRCharBoxInformation_spaceBoxRemovalTightenBox:singleVotingImageAddressRef:adaptOut:textOut:zcStartLeft:zcStopRight:finalCoordinatesForStub:finalCoordinatesForStubRevised:finalCharBoxCoordCount:useLowLightEnhancement:
_generateCRCharBoxInformation_spaceBoxRemovalTruthFilter:magicThresh:zcStartLeft:zcStopRight:isSpaceBoxAccepted:histCompliancePercent:useLowLightEnhancement:
_generateCRCharBoxInformation_zcFinalVectorFillIn:
_generateCRCharBoxInformation_zcFinalVectorHighProbability:zcFinalRange:
_generateCRCharBoxInformation_zcFinalVectorOriginate:textOut:adaptOut:bigBoxes:bigBoxesAdapt:ccCharBoxesAggr:ccCharBoxesFiltered:height:rowStartLocation2:rowStopLocation2:singleVotingImageAddressRef:countBigBox:filterWalkUpDownCount:useLowLightEnhancement:
_generateFilteredPulseVector:target:height:
_generatePulseAggregate:pulseVectorMain:pulseVectorResult:metricSelection:bufferHeight:bufferWidth:
_generatePulseAggregateSmallStubs:pulseVectorResult:bufferHeight:bufferWidth:
_generatePulseVectorOutputs:votingImage:rowLocationsRef:
_generateSegmentationMask
_generateSmoothedImage:uImage:
_generateVotingImage:votingImage:useLowLightEnhancement:
_generateZeroCrossingVector:zcVectorFlag:width:
_getAnalyzerName:version:forModel:configuredWithOptions:error:
_getCornerPointsFromCodeLocationPoints:bottomLeft:topLeft:topRight:bottomRight:
_getFaceSegmenterInputImageSize:forRequestRevision:error:
_getFilterResultOut:defaultRows:bufferHeight:minHeight:maxHeight:startRange:stopRange:startMaxFind:stopMaxFind:bytesPerRow:thresholdSet:sampleImageAddressRef:sampleImageFloatAddressRef:pulseVectorFlag:
_getFilterResultOutBothSumDeriv:floatVectorResult:bufferHeight:minHeight:maxHeight:config:bytesPerRow:thresholdSet:sampleImageAddressRef:
_getFilter_callCount
_getModelWritingImplementation:selector:version:forOptions:
_getNumberOfSupportedFaceSegments:forRequestRevision:error:
_getOrientationLock
_getSerialNumber:forPersonUniqueIdentifier:error:
_getTracker:
_glassesCategory
_globalSegmentationMask
_gpuContextsHandlers
_gpuHandlersLock
_groupOrderedRequests:ordinality:ordinalityAndPriorityGroups:
_groupedClusteredFaceIdsForCluster
_groupingConfiguration
_groupingConfigurations
_groupsRequestsWithTheSameOrdinality:priorityGroup1:priorityGroup2:
_guidedFilter
_hairColorCategory
_handler
_harmoniousColorScore
_hasLabel
_hashData_DO_NOT_DIRECTLY_ACCESS
_hasherInitialized
_helpReadOrientationFromOptionsDictionary:
_hierarchicalModel_DO_NOT_ACCESS_DIRECTLY
_humanPoseDetector
_humanReadableLabelForRequest:
_hyperplaneLSHProcessor
_idealImageFormat
_idealOrientation
_identifier
_identifiers
_image
_imageAnalyzer
_imageAnalyzerJunkCustomClassifiers
_imageAnalyzerPCA256
_imageBuffer
_imageBuffer_DO_NOT_DIRECTLY_ACCESS
_imageCVPixelBuffer
_imageCropAndScaleOption
_imageData
_imageFilePath
_imageHeight
_imageInputKey
_imageNeuralHashprint
_imageReader
_imageReaderInitializationOptionsForCreationOptions:error:
_imageRegistrationDescriptor
_imageRotationSession
_imageRotationSessionsHandler
_imageSignatureHash
_imageSignatureHashType
_imageSignatureprint
_imageSignatureprintType
_imageSize
_imageSourceManager
_imageSourceSubsample1
_imageSourceSubsample2
_imageSourceSubsample4
_imageSourceSubsample8
_imageURL
_imageWidth
_imageprint
_imageprintDescriptor
_imageprintValid
_imageprintVersion
_immersivenessScore
_implicitRequests
_inHierarchy
_inUseContexts
_indexPath
_indexType
_initLocks
_initMemory:height:numScales:
_initWithClassKeyMappedCoder:
_initializeGreedyClustererOptions:
_initializePolygonContainers
_inliersRatioThreshold
_innerLips
_innerLipsLock
_inputContrast
_inputDetectedObjectObservations
_inputFaceObservations
_inputFactor1
_inputFactor2
_inputFactor3
_inputFactor4
_inputImage
_inputImageAspectRatioHandling
_inputImageBlobNameForModel:configuredWithOptions:
_inputImageFormat
_inputImageHeight
_inputImageKey
_inputImageWidth
_inputImages
_inputObservation
_inputPivot
_inputPixelFormat
_inputPoint
_inputScenePrintKey
_inputScenePrintMLMultiArrayDataType
_inputSignatureprint
_instanceSegmentationMask
_interestingSubjectScore
_internalAlignedBBox
_internalNonSerializedDescriptorId
_internalPerformRevision:inContext:previousObservation:error:
_introspectionBuiltSupportedRevisions
_intrusiveObjectPresenceScore
_iousBuffer
_isBlinking
_isFaceprintJunk:
_isSeparatedString:equalToString:atIndex:usingSeparator:
_isTitle
_isValid
_junkObservationsForLastAnalysisWithOptions:error:
_keepNetworkOutput
_keepRawOutputMask
_key
_kindToOriginalRequestsMapping
_label
_labelKey
_labelToOperationPointsDataIndexMap
_labelsAndConfidence
_landmarkDetector
_landmarkPoints3d
_landmarkPoints65
_landmarkPrecisionEstimatesPerPoint
_landmarkScore
_landmarks
_landmarks3DOriginatingRequestSpecifier
_landmarksConstellation
_landmarksOriginatingRequestSpecifier
_lastAnalyzedFramePTS
_lastDataChangeSequenceNumber
_lastFrame
_lastModificationDate
_lastTrackedBBox
_leftEye
_leftEyeLock
_leftEyebrow
_leftEyebrowLock
_leftPupil
_leftPupilLock
_level
_levelCount
_library
_liveTrackerCounter
_liveTrackerCounterLimit
_livelyColorScore
_loadEspressoModelWithConfigurationOptions:error:
_loadSubSample1Lock
_loadSubSample2Lock
_loadSubSample4Lock
_loadSubSample8Lock
_locateDetectorOfClass:configuredWithOptions:inSessions:excludingSession:
_locateFrameworkBundleForResourceWithName:resourceDirectory:error:
_locateMode
_locateTrackerResourcesConfiguredWithOptions:inSessions:excludingSession:
_locatedCachedResultsOnBehalfOfRequest
_location
_lock
_lockStaticObjectsAccessLock
_logEnabled
_logFileURL
_logFolderURL
_logitsNegOutputs
_logitsPosOutputs
_lookedAtFaceObservationUUID
_lowKeyLightingScore
_mComputeBoundingBoxesLock
_mFaceFrontalizerImpl
_mFaceQualityPredictor
_mHighlySalientRegion
_mMultiHeadedANFDDetector
_mMultiHeadedFaceClassifier
_mOriginalImageSize
_mSalientObjects
_machineReadableCodeElements
_machineReadableCodesDetectedInImageBuffer:originatingRequestSpecifier:inContext:mrcDetector:error:
_major
_makeFaceSegmentProbabilityDataImageBuffer:rect:
_makeupEyesCategory
_makeupLipsCategory
_masksBuffer
_maxBoxWidth
_maxContextsCount
_maxHeight
_maxSessionsCount
_maxThreadExecutionWidth
_maximumAspectRatio
_maximumCandidateCount
_maximumDimension
_maximumElementsPerID
_maximumEntities
_maximumHandCount
_maximumHierarchicalObservations
_maximumIdentities
_maximumImageDimension
_maximumIntermediateSideLength
_maximumLeafObservations
_maximumObservations
_maximumProcessingDimensionOnTheLongSide
_maximumTasksCount
_maximumTrackersOfType:
_medianLine
_memoryPoolId
_mergesCount
_metalContext
_metalContextPriority
_metalDevice
_micro
_minBoxWidth
_minHeight
_minimizeFalseDetections
_minimumAspectRatio
_minimumCharacterPixelHeight
_minimumConfidence
_minimumDimension
_minimumFaceDimension
_minimumSize
_minimumTextHeight
_minor
_mmHeightCard
_mmWidthCard
_model
_modelCachingIdentifier
_modelData
_modelDrop
_modelFileBackingStore
_modelFilesWereMemmapped
_modelMinimumDetectionConfidence
_modelName
_modelNonMaximumSuppressionThreshold
_modelType
_modelWasModified
_mostLikelyLabel
_motionFlowRequest
_mouth
_movingAverageRadius
_mrcContext
_mrcDescriptor
_mtlContext
_name
_naturalClusteringDistanceThreshold
_network
_networkConfigurationName
_networkHeadVersions
_networkHeight
_networkInputImageHeight
_networkInputImageWidth
_networkRequiredInputImageHeight
_networkRequiredInputImageSize
_networkUsesAnisotropicScaling
_networkWidth
_newVNBarcodeSymbologyAztecDescriptorForACBSBarcodeInfo:
_newVNBarcodeSymbologyAztecDescriptorForMRCDescriptor:error:
_newVNBarcodeSymbologyPDF417DescriptorForACBSBarcodeInfo:
_newVNBarcodeSymbologyPDF417DescriptorForMRCDescriptor:error:
_newVNBarcodeSymbologyQRDescriptorForACBSBarcodeInfo:
_newVNBarcodeSymbologyQRDescriptorForMRCDescriptor:error:
_nextFrameToBeAnalyzedPTS
_nextLeafDescriptorDistance
_nextLeafId
_nextLeafTimestampDistance
_nextLeafTotalDistance
_nlreg_padding
_nlreg_radius
_nlreg_sigma_c
_nlreg_sigma_l
_nlreg_sigma_w
_nmsThreshold
_node
_noiseScore
_nonframeworkDataURL
_normalizeRegion:
_nose
_noseCrest
_noseCrestLock
_noseLock
_notificationCenter
_numScales
_numWarpings
_numberOfFaceSegments
_numberOfKeypointsToConsider
_objectMaximumNormalizedRadius
_objectMinimumNormalizedRadius
_objectType
_objects
_observation
_observationGroupsToRequestMapping
_observationsCache
_observationsCacheKey
_observationsCacheKeyForRequest:
_observationsCacheLock
_observationsForImageReaderOutput:requestRevision:error:
_observationsForOneComponent32FloatPixelBuffer:options:regionOfInterest:error:
_observationsForSerialNumber
_observedParabolas
_obtainCreatedCGImageSourceRefAtAddress:forSubSampleFactor:protectedWithUnfairLock:operatingInLowPriority:
_olmcsMergeCountDelta
_operationPoints
_operationPointsCache
_operationPointsDataArray
_operationPointsDataForClassificationIdentifier:error:
_operationPointsProvider
_opticalFlow
_options
_orderedChildRequests
_orderedHandKeypoints
_orderedPersonKeypoints
_orderedRequests
_orientation
_orientationAgnostic
_origCIImage
_origImageHeight
_origPixelBuffer
_origSampleBuffer
_originalObservation
_originalRequestConfigurations
_originalRequestResultsIndex
_originalRequests
_originatingRequestDetectionLevel
_originatingRequestSpecifier
_originatingRequestSpecifierToOperationPoints
_osfsSizeRatio
_osfsThreshold
_outerLips
_outerLipsLock
_outputBufferData
_outputBufferHeight
_outputBufferWidth
_outputMaskEspressoBuffer
_outputPixelFormat
_outputs
_parabolaDetector
_parentRequest
_parseInputObservations:imageBuffer:error:
_parseOptions:error:
_passedInCIContext
_pasteTileComputePipelineState
_pathLock
_perMeshPtr
_performBlinkDetection
_performClustersPostprocessing
_performNOPForRevision:inContext:detectorCompletionSemaphore:error:
_performOrderedRequests:inContext:error:
_performRequests:onBehalfOfRequest:inContext:error:
_performRequests:onImageBuffer:gatheredForensics:error:
_performSceneClassification
_performedRequests
_personId
_personPredictionsForFace:withDescriptor:limit:faceIDCanceller:error:
_personUniqueIdentifierToSerialNumberMapping
_personUniqueIdentifiers
_personsModel
_petprintGenerator
_pitch
_pitchAngle
_pixelBuffer
_pixelBufferReps
_pixelBufferRepsCache
_pixelBufferRepsLock
_pixelFormatType
_pixelHeight
_pixelHeightCard
_pixelTransferSession
_pixelTransferSessionsHandler
_pixelValueToRegionLabelMap
_pixelWidth
_pixelsHighRange
_pixelsWideRange
_plan
_platform
_pleasantCameraTiltScore
_pleasantCompositionScore
_pleasantLightingScore
_pleasantPatternScore
_pleasantPerspectiveScore
_pleasantPostProcessingScore
_pleasantReflectionsScore
_pleasantSymmetryScore
_pointCount
_pointsCalculatorLock
_pointsClassification
_pointsData
_polygonList
_pools
_poolsLock
_poseData
_poseOriginatingRequestSpecifier
_postProcessTrackingResults:trackerResults:error:
_potentialLandmarkCustomClassifiers
_precisionEstimatesPerPoint
_precisionRecallThreshold
_predictedFeatureKey
_predictedPersonUniqueIdentifier
_predictedProbabilitiesKey
_predictor
_preferBackgroundProcessing
_preferredBufferSizeFormat
_preferredSmallSide
_previousFrameBuffer
_previousFrameImage
_previousImageHeight
_previousImageWidth
_previousLeafTimestampDistance
_previousLeafTotalDistance
_previousObservations
_printDebugInfo:detectedObjectsRaw:faceDetectorBGRAImage:tempImage:
_probabilityNormSums
_processAllFrames
_processFaceBasedInputInContext:revision:torsosThatNeedNoProcessing:torsosThatNeedTorsoprints:error:
_processFullImagePixelBuffer:options:regionOfInterest:warningRecorder:error:progressHandler:
_processHumanBodyBasedInputInContext:revision:torsosThatNeedNoProcessing:torsosThatNeedTorsoprints:error:
_processHumanBodyObservations:revision:regionOfInterest:context:error:
_processTiledImageBuffer:inputMaskObservation:options:error:
_processingDevice
_profile
_profileNormal
_projectedPoints
_propertyListRepresentation
_pyramid_size
_qosClass
_quadratureTolerance
_quality
_qualityCriteriaList
_qualityLevel
_queue
_queueNameToTasksQueueDictionary
_queueNameToTasksQueueDictionaryLock
_queueWithUniqueAppendix:queueClass:
_rawColorGaborDescriptor
_readOnly
_recognitionLanguages
_recognitionLevel
_recognize
_rectangleTrackingProcessingQueue
_referenceImageSignature
_refineLeftEyeRegion
_refineMouthRegion
_refineRightEyeRegion
_regionLabels
_regionMap
_regionOfInterest
_releaseDetectorsThatCanBeReplacedByDetectorOfClass:withConfiguration:
_releaseEspressoContext
_releaseEspressoPlan
_releaseSignallingBlock
_releaseTracker_NO_LOCK_DO_NOT_EXECUTE_DIRECTLY:
_removeAllFaceObservationsFromIdentityWithSerialNumber:
_removeBackgroundSemaphore
_removeExistingFaceObservations:fromIdentityWithSerialNumber:
_removePersonWithUniqueIdentifier:
_renderCIImage:toBuffer:width:height:rowBytes:format:error:
_renderCIImage:width:height:format:error:
_reportCharacterBoxes
_representativenessById
_repsCacheKeyToProcessingQueueDictionary
_repsCacheKeyToProcessingQueueDictionaryLock
_request
_requestClass
_requestClassCode
_requestConstellationToDetectorConstellationMap
_requestForensics
_requestImageBuffers
_requestImageBuffersCacheKeys
_requestLock
_requestNewIdentitySerialNumberAndReturnError:
_requestPerformer
_requestPerformingQueuePriorityGroup1
_requestPerformingQueuePriorityGroup2
_requestRevision
_requestToObservationClassMap
_requestToObservationsCacheKeyMap
_requestUUID
_requestsClassMapping
_requestsInFlight
_requestsPending
_requireFaceAttributesPupilRefiner
_requiredVersion
_resetTrackerIfNeeded:session:options:error:
_resolvedRevision
_results
_resultsLock
_returnAllResults
_returnMask
_revision
_rightEye
_rightEyeLock
_rightEyebrow
_rightEyebrowLock
_rightPupil
_roiAreaThreshold
_roll
_rollOutputs
_rotation
_rotationAngle
_rpnEspressoResourcesKeyToEspressoResourcesCache
_rpnEspressoResourcesKeyToEspressoResourcesCacheLock
_rpnInitEspressoResources
_rpnTrackEspressoResources
_sRGB
_saveFaceAttributes:toFaceObservation:options:error:
_saveFaceprint:toFaceObservation:options:error:
_scale
_scannerResult
_sceneClassifierDescriptor
_sceneObservation
_scenePrint
_scenePrintRevision
_sceneprintVersion
_sceneprints
_scoresDictionary
_screenGaze
_screenGazeState
_segmentationMask
_semaphore
_sequencedRequestObservations
_serialNumber
_serialNumberForEntityUniqueIdentifier
_serialNumberToFaceObservationsMapping
_serialNumberToPersonUniqueIdentifierMapTable
_serializationOptions
_session
_sessions
_sessionsAccessLock
_setCustomHierarchy:
_setFaceExpressionFeatureScoreIfDetected:features:detectionKey:scoreKey:featureKey:
_setResolvedRevision:
_setupBufferAndReturnError:
_setupPipelinesReturnError:
_shape
_sharplyFocusedSubjectScore
_shortDescription
_shouldUpdateRepresentative
_signalled
_signallingBlock
_signature
_signatureData
_signaturePrintTypeSupported:
_significantEventCustomClassifiers
_sizedPointsCache
_sizes
_smartCamCombinedModelImageAestheticsClassificationsForRevision:performedInContext:error:
_smartCamCombinedModelImageSaliencyObservationsForRevision:performedInContext:error:
_smartCamprintVersion
_smartDistanceFactor
_smilingCategory
_specifier
_startMaxFind
_startNormal
_startSensitized
_state
_stopAtFirstPyramidWith2DCode
_stopMaxFind
_stopNormal
_suggestedIdsForRepresentative
_suggestionsForCluster
_suggestionsLogger
_symbologies
_symbology
_synchronizationQueue
_tapToBox
_targetFrameTime
_targetImageDimensionForContourDetection
_targetImageSignature
_targetedImageBuffer
_tastefullyBlurredScore
_temporalSmoothingFrameCount
_tensorsDictionary
_text
_textBlockObservationsFromRegion:requestRevision:
_textElements
_textObjects
_textRecognition
_threshold
_thresholdFilter
_timeInterval
_timeRange
_timeStamp
_timerMode
_topLeft
_topLevelContoursIndices
_topLevelIndex
_topRight
_torsoprint
_torsoprintGenerator
_torsoprintRequestRevision
_torsoprintRevision
_totalObjectCount
_trackDuration
_trackID
_trackedFrameCVPixelBufferFormat
_trackedFrameNumber
_trackerClassToNameMapTable
_trackerResourceCache
_trackerResourcesAccessingLock
_trackerTypeToClassDictionary
_trackers
_trackersCollectionManagementQueue
_trackingFrameSizeInPixels
_trackingLevel
_trackingLevelOptionFromTrackingLevelEnum
_trackingProcessingQueue
_trackingRectAroundPoint:trackingRectSize:
_trainedModel
_trainedModel_DO_NOT_ACCESS_DIRECTLY
_trainingData
_trajectoryLength
_trajectoryProcessor
_transform
_transformsAndConfidences
_type
_unalignedBoundingBox
_unalignedFaceBoundingBox
_uniqueFaceObservationsWithRegistrationState:forFaceObservations:withExpectedFaceprintRequestRevision:ofPersonWithUniqueIdentifier:error:
_unlockStaticObjectsAccessLock
_updateClustererWithOptions:canceller:error:
_updateModelWithFlexibleImageConstraintUsingWidth:height:
_updateTrackerWithModifiedBBoxForImageBuffer:error:
_upperBodyOnly
_useCenterTileOnly
_useImageAnalyzerScaling
_useMLDetector
_useNonLocalRegularization
_useSegmentationPregating
_useTiling
_useTimestampAdjustedDistances
_userBBox
_usesAlternateLineGrouping
_usesLanguageCorrection
_uuid
_uuidStringForCacheIdentifier
_uv_pxbuf
_uv_tex_user_ref
_uv_u32_alias_tex
_uv_user_ref
_validateAndPrepareRequests:error:
_validateDetectedObjectObservations:forObservationClass:withMinimumCount:forOptionalRequest:error:
_validateFaceObservations:withMinimumCount:forOptionalRequest:error:
_validateInputImage:error:
_validateOutputImage:error:
_validatedImageBufferForKey:inOptions:error:
_value
_vectorMapReadOnlyFlag
_vectorProjections
_version
_version1ModelWithObjects:error:
_visionBBoxToTrackerBBox:trackedObjects:imageSize:results:error:
_vtSessionManager
_w_pxbuf
_w_tex
_warningRecorder
_warnings
_warpTransform
_weakRequestPerformer
_weakSession
_weakSessionWrappers
_wellChosenBackgroundScore
_wellFramedSubjectScore
_wellTimedShotScore
_width
_wisdomParameters
_wisdomParametersLock
_wisdomParams
_wisdomResourcesPath
_yaw
_yawAngle
_yawOutputs
_zeroFlowWithCommandBuffer:uv_tex:
acceptableEntityPrintOriginatingRequestSpecifiers
acceptableVersions
activeImageBuffers
activeProcessorCount
addAllJointsToPath:imageSize:
addAllPersonsFromPersonsModel:error:
addCompletedHandler:
addEntriesFromDictionary:
addFaceObservations:toFaceDescriptorBuffer:
addFaceObservations:toPersonWithUniqueIdentifier:error:
addFaceObservations:withGroupingIdentifiers:toFaceDescriptorBuffer:
addIndex:
addIndexes:
addObject:
addObjectsFromArray:
addObservations:toEntityWithUniqueIdentifier:error:
addOriginalRequest:
addPersonData:withGroupingIdentifiers:toFaceDescriptorBuffer:
addPersonWithUniqueIdentifier:fromPersonsModel:error:
addPointer:
addRPNTrackerResourcesConfiguredForOptions:resources:error:
addRequest:processingOptions:error:
addRequest:withConfiguration:error:
addRequest:withProcessingOptions:error:
addSession:droppingWeakZeroedObjects:
addTilingWarningRecorder:
addToGroupingsRequest:withFaceObservations:
additionalCharacters
adjustmentKeys
adjustmentValuesForKey:
aestheticScore
ageCategory
algorithm
algorithmOfClass:error:
alignedBBox
alignedBoundingBox
alignedBoundingBoxAsCGRect
alignedMeanShape
alignedRotationAngle
alignmentTransform
alignmentTransformInTopLeftOrigin:orientation:
allCityNatureIdentifiersWithOptions:error:
allClusteredFaceIdsAndReturnError:
allConfigurations
allDevices
allIdentifiers
allInputImages
allInputs
allJunkIdentifiersForOptions:error:
allLabelsWithConfidences
allLandmarksPointsIndexes
allLandmarksPointsIndexesForConstellation:
allModelEquivalents
allObjects
allOutputs
allPhotosAdjustmentKeysForOptions:error:
allPoints
allRecognizedObjectsIdentifiersWithOptions:error:
allSceneIdentifiersWithOptions:error:
allScorePropertyNames
allSessions
allSessionsDroppingWeakZeroedObjects:
allSignificantEventIdentifiersWithOptions:error:
allSubclassesOfClass:excludingRootClass:overridingClassSelector:
allSupportedRevisions
allVN5kJNH3eYuyaLxNpZr5Z7ziIdentifiersWithOptions:error:
allValues
allocWithZone:
allocateColorProfileContext:width:height:rowBytes:
allocationSize
allowedImageSizeClosestToPixelsWide:pixelsHigh:preferDownScaling:preferInputAspectRatio:
allowsCachingOfResults
analysisPixelFormatTypeForConfiguration:
analyzeTimeRange:error:
analyzeWithStart:andDuration:error:
analyzeWithTimeRange:error:
anfdMultiDetectorClassToProcessRequest:
angle
angleInTopLeftOrigin:orientation:
animalprint
anyObject
appClipCodeMetadataValue
appendBytes:length:
appendData:
appendFormat:
appendPath:
appendString:
appendString:toLogFile:
applicableDetectorClassForRevision:error:
applicableDetectorTypeForRevision:error:
applicableRevisionForDependentRequest:
applicableRevisionForDependentRequestOfClass:beingPerformedByRevision:
applyConfigurationOfRequest:
applyWithExtent:arguments:
archivedDataWithRootObject:requiringSecureCoding:error:
array
arrayByAddingObjectsFromArray:
arrayWithCapacity:
arrayWithObject:
arrayWithObjects:count:
asVNTensorDataType
aspectRatio
aspectRatioHandling
aspectRatioInOrientation:
assignOriginalRequestsResultsFromObservations:obtainedInPerformingContext:
asyncStatus
attributedString
augmentedBuffersWithWidth:height:format:options:augmentationOptions:error:
augmentedCroppedBuffersWithWidth:height:format:cropRect:options:augmentationOptions:error:
automaticallyDetectsLanguage
autorelease
availableGroupKeys
availableIdentifiers
availableJointNames
availableJointsGroupNames
availableKeys
availableLocateModes
availableLocateModesAndReturnError:
availableLocateModesRev1
availableLocateModesRev2
availableVNInferenceNetworkIdentifierFaceprintVersions
availableVNInferenceNetworkIdentifierSceneNetObjDetNetSliderNetVersions
availableVNInferenceNetworkIdentifierSceneNetVersions
availableVNInferenceNetworkIdentifierSmartCamVersions
availableVNInferenceNetworkIdentifierStandaloneSceneprintVersions
availableVersionsForIdentifier:error:
avgDistance
bTop
backingStore
baldCategory
barcodeDescriptor
barcodeRequest
barcodeSymbologyForACBSBarcodeType:
barcodeSymbologyForMRCSymbology:
baseAddress
baselines
batchNumber
beginRangeFaceBoundingBoxExpansionRatio
bindBuffer:toNetworkInputBlobName:error:
bindBuffer:toNetworkOutputBlobName:error:
bindLockedPixelBuffer:toNetworkInputBlobName:error:
bindOutputConfidenceBuffersAndReturnError:
bindPixelBuffer:toNetworkBlobName:error:
blacklistForModel:
blacklistFromUTF8StringArray:
blacklistedIdentifiers
blinkScore
blocks
blocksWithTypes:inRegion:
blurDeterminationMethod
blurMeasure
blurScore
boolForKey:
boolValue
booleanBytesData
bottomLeft
bottomRight
boundingBox
boundingBoxAligned
boundingBoxForRange:error:
boundingBoxForTextRange:error:
boundingBoxInTopLeftOrigin:orientation:
boundingBoxOutputDescription
boundingBoxesFromFloat32ImageBuffer:thresholds:error:
boundingBoxesFromFloat32ImageBuffer:thresholds:relativeToMaximum:applySmoothing:originalImageSize:sigmaX:sigmaY:nStd:error:
boundingBoxesFromFloat32PixelBuffer:thresholds:relativeToMaximum:applySmoothing:originalImageSize:sigmaX:sigmaY:nStd:error:
boundingCircleForPoints:error:
boundingCircleForSIMDPoints:pointCount:error:
boundingQuad
bounds
boxCenter
brightness
bufferWithWidth:height:format:options:error:
bufferWithWidth:height:format:options:error:pixelBufferRepsCacheKey:
bundleIdentifier
bundlePath
bundleWithIdentifier:
bytes
bytesPerRow
cStringUsingEncoding:
cacheBuffer:forCacheKey:
cacheDetector:
cacheKeyFromOptions:error:
cacheKeyWithBufferFormat:width:height:
cacheKeyWithBufferFormat:width:height:cropRect:
cacheObservationsOfRequest:
cacheOptionsKeys
cachePath
cachedBufferWithKey:
cachedFloatingImageBufferReturningError:
cachedFloatingImageRegistrationSignatureReturningError:
cachedImageReader
cachedObservationsAcceptedByRequest:
cachedObservationsWithKey:wereCheckedOnBehalfOfRequest:
cachedObservationsWithKey:wereLocatedOnBehalfOfRequest:
cachedPixelBufferRepresentationForKey:
cachingIdentifier
calculateArea:forContour:orientedArea:error:
calculateDistanceFromImageprintObservation:
calculateImageDescriptors:regionOfInterest:warningRecorder:canceller:error:
calculatePerimeter:forContour:error:
calculatePupilLocationAndUpdateLandmarkPoints:
calculateSaliencyBoundingBoxesForDetectorType:pixelBuffer:configurationOptions:originatingRequestSpecifier:regionOfInterest:warningRecorder:error:
calculateSumProd:prodROIRef:prodROIRotateRef:rowStartLocation2:height:
calculateSumProdAlternative:prodROIRef:prodROIRotateRef:rowStartLocation2:height:
calculateTilesForRegionOfInterest:imageWidth:imageHeight:tileSizeInPixels:overlapFraction:aspectRatioThreshold:columns:rows:tiles:error:
canBehaveAsDetectorOfClass:withConfiguration:
canCreateModelOfClass:withObjects:error:
cancel
cancelAllRequests
cancelClustering:
cancellationSemaphore
cancellationTriggered
cancellationTriggeredAndReturnError:
cancellerAndReturnError:
candidates
cascadeStepCount
categorizeFaceObservations:shouldRunDetectorBlock:facesThatNeedNoProcessing:facesThatNeedProcessing:facesThatNeed2DLandmarks:
category
cellStartsX
cellStartsY
center
channels
charBoxContext
charBoxFlags
charBoxesFromTextBoxes:bigBoxes:ccYTopLocationsForSort:ccYBottomLocationsForSort:
characterBoxes
charboxROIFullVectorHeight2
charboxROIFullVectorRowStart
checkFlag:atIndex:
childContourAtIndex:error:
childContourCount
childContourIndicesAtIndex:
childContours
children
chirality
ciContextLock
class
class:overridesClassSelector:
classForClassCode:error:
classNameForClassCode:error:
classifierResourceTypesToNamesForOriginatingRequestSpecifier:
classifyImageHierarchicallyWithDescriptors:usingImageClassifier:hierarchicalClassifier:minimumClassificationConfidence:minimumClassificationConfidenceRatio:maximumLeafLabels:maximumHierarchicalLabels:options:metalContext:error:
classifyImageWithDescriptors:usingImageClassifier:andMinConfidenceForClassification:options:metalContext:error:
clearFlag:atIndex:
clearImage
close
closeFile
closestContentRegionOfType:toNormalizedPoint:maxPixelDistance:
closestTextBlockOfTypes:toPoint:maximumPixelDistance:
clusterId
clusterSplitDistanceType
clusterState
clusteredFaceIds
clusteredFaceIdsForClusterContainingFaceId:error:
clustererBuilderWithOptions:error:
clustererModelFileNamesFromState:storedInPath:error:
clustererQueryWithOptions:error:
clusters
code
codingTypesToCodingKeys
colorGaborDescriptor
colorWithRed:green:blue:alpha:
commandBuffer
commit
commonGazeLocationRadius
compare:
compare:options:
completeInitializationForSession:error:
completed
completionHandler
componentsJoinedByString:
componentsSeparatedByString:
compoundRequestProcessingDeviceFromOriginalRequestsProcessingDevice:
compoundRequestRevisionForRequest:
compoundRequestsForOriginalRequests:withPerformingContext:error:
computationAccuracy
computeApproximateBlurScore:onGrayscaleImage:sampledPixelsCount:insetFactor:error:
computeApproximateBlurScore:onRGBAImage:sampledPixelsCount:insetFactor:error:
computeBlurScore:onGrayscaleImage:andWithRegionOfInterestInImageCoordinates:andRegionOfInterestInsetFactor:error:
computeBlurScore:onGrayscaleImage:insetFactor:error:
computeBlurSignatureForGrayscaleImage:error:
computeBrightnessScore:onImage:error:
computeCenterCropRectFromCropRect:inImageSize:calculatedScaleX:calculatedScaleY:
computeCentroidUsingPoints:indicies:numberOfIndicies:
computeClusteringForClusteringTree:intoKGroups:error:
computeClusteringForClusteringTree:usingThreshold:error:
computeClusteringIntoKGroups:forHierarchicalTree:context:
computeClusteringIntoKGroups:orUsingDistanceThreshold:forHierarchicalTree:context:
computeClusteringOfImageDescriptors:intoKGroups:error:
computeClusteringTreeForImageDescriptors:assumeDescriptorsAreSorted:error:
computeClusteringTreeForImageDescriptors:error:
computeClusteringUsingDistanceThreshold:forHierarchicalTree:context:
computeCommandEncoder
computeConvnetDescriptorForImageData:context:error:
computeDependentTopAndBottomComponents:finalCharBoxCoordCount:
computeDescriptorForImageData:context:error:
computeDistance:toFeaturePrintObservation:error:
computeDistance:withDistanceFunction:error:
computeDistanceToFeaturePrintObservation:error:
computeEdgeWidthBlurScore:onGrayscaleImage:error:
computeFinalDescriptorBasedDistanceForColorDistance:andSceneClassifierDistance:
computeHashForCVPixelBuffer:
computeHierarchicalClusteringOfImageDescriptors:results:context:
computeImageCropWithImage:regionOfInterest:usingDescriptorProcessor:scalingImage:options:pixelBuffer:error:
computeImageDescriptorsWithImage:pixelBuffer:regionOfInterest:usingDescriptorProcessor:tileCount:augmentationMode:resultantDescriptorBuffer:options:metalContext:canceller:tileColumns:tileRows:error:
computeIndependentTopAndBottomComponents:finalCharBoxCoordCount:
computeLabelsAndConfidence:usingDescriptorBuffer:populateLabelsAndConfidence:options:metalContext:error:
computeLandmarksScoreOnImage:withFaceBoundingBox:andLandmarks:error:
computeMainStub:numCropRows:numCropColsOut:maxY:start:
computeNaturalClusteringForClusteringTree:error:
computeNaturalClusteringForHierarchicalTree:context:
computeNaturalClusteringOfImageDescriptors:error:
computePulseVectorSum:start:stop:imageHeight:imageWidth:bottomHeight:topHeight:
computeRectFromExtremaUsingThreshold:vImage:
computeRegistrationFeaturesForImageData:context:error:
computeTimestampAdjustedDistanceForBaseDistance:andTimestampDiff:
computeTotalDistanceForDescriptorDistance:timestampDiff:useTimestampAdjustment:
computeTransform:forRegisteringImageSignature:withSignature:minimumOverlap:error:
computeYawPitchRollFromPoseMatrix:outputYaw:outputPitch:outputRoll:
computeZCVectorHighProbability
confidence
confidenceFeatureName
confidenceScoreType
confidenceTypeForOriginatingRequestSpecifier:
confidenceTypeForRevision:
confidencesOutput
configuration
configurationClass
configurationForRequest:
configurationForRequest:withObservationGroup:compoundRequestRevision:
configurationFromLoadedObjects:error:
configurationOptionKeysForDetectorKey
configurationOptions
configureImageAnalyzerOptions:error:
conformsToProtocol:
constellation
containsIdentifier:
containsIndex:
containsPoint:
containsPoint:inCircumferentialRingOfWidth:
containsValueForKey:
contentRegionOfType:containingTextAtIndex:
contentsWithTypes:
contextWithMTLDevice:options:
contextWithOptions:
contourAtIndex:error:
contourAtIndexPath:error:
contourCount
contrastAdjustment
contrastPivot
convertClusterNodesListToDescriptorsList:
convertRelationships:toStdRelationships:
convertToAlgorithm:error:
convertUpdatePairsToClusters:
coordinatesFeatureName
copy
copyColorspaceForFormat:bitmapInfo:
copyItemAtPath:toPath:error:
copyStateOfRequest:
copyWithZone:
count
countByEnumeratingWithState:objects:count:
crOutput
createBufferWithMaxSideLengthOf:andPixelFormat:andOptions:error:
createCGImage:fromRect:
createCVPixelBufferRefFromDictionaryRepresentation:
createCVPixelBufferWithPixelFormat:fromImageInEspressoBuffer:error:
createClassifierWithDescriptor:classifierAbsolutePath:computePlatform:computePath:labelsFilename:options:
createCompoundConfigurationHashKeyForRequest:compoundRequestRevision:
createCroppedBufferWithMaxSideLengthOf:andCropBounds:andPixelFormat:andOptions:error:
createDescriprorProcessorWithModelPath:nBatch:computePlatform:computePath:options:
createDictionaryRepresentationOfCVPixelBuffer:
createDirectoryAtPath:withIntermediateDirectories:attributes:error:
createDirectoryAtURL:withIntermediateDirectories:attributes:error:
createExpressionAndConfidencesDictionaryFromScores:
createExpressionDetectionDictionaryFromScores:
createHierarchicalModelForMultiDetectorModel:error:
createHierarchicalModelForOriginatingRequestSpecifier:error:
createLumaImage:lumaImage:numCropRows:rowStartLocation:
createLumaImageAlternative:lumaImageAlternative:numCropRows:rowStartLocation:
createMaskImageOfFaceSegments:error:
createNSErrorWithStatus:andMessage:
createNSExceptionWithStatus:andMessage:
createObservationWithDescriptors:forOriginatingRequestSpecifier:
createPixelBufferInOrientation:error:
createProbabilityImageOfFaceSegment:error:
createProbabilityImageOfFaceSegment:region:normalize:error:
createRPNTrackerResourcesConfiguredWithOptions:error:
createRegionOfInterestCrop:options:warningRecorder:pixelBuffer:error:progressHandler:
createSaliencyImageAndReturnError:
createSingleNetworkPlanFromResourceName:usingProcessingDevice:lowPriorityMode:inputBlobNames:outputBlobNames:networkConfiguration:explicitNetworkLayersStorageType:memoryPoolId:espressoResources:error:
createSingleNetworkPlanFromResourceName:usingProcessingDevice:lowPriorityMode:inputBlobNames:outputBlobNames:networkConfiguration:memoryPoolId:espressoResources:error:
createVNEntityIdentificationModelEntryPrintForRevision:fromDescriptorData:length:elementCount:error:
cropAndScaleBufferWithWidth:height:cropRect:format:imageCropAndScaleOption:options:error:calculatedNormalizedOriginOffset:calculatedScaleX:calculatedScaleY:
cropAndScaleBufferWithWidth:height:cropRect:format:imageCropAndScaleOption:options:error:calculatedNormalizedOriginOffset:calculatedScaleX:calculatedScaleY:pixelBufferRepsCacheKey:
cropResult
croppedBoundingBox
croppedBufferWithWidth:height:format:cropRect:options:error:
croppedBufferWithWidth:height:format:cropRect:options:error:pixelBufferRepsCacheKey:
currentCodingVersion
currentQueueIsSynchronizationQueue
currentSerializationVersion
currentVersion
customHierarchyForRequest:error:
customHierarchyWithAdditionalParent:children:error:
customHierarchyWithAdditionalRelationships:error:
customWords
data
dataPointer
dataType
dataUsingEncoding:
dataUsingEncoding:allowLossyConversion:
dataWithBytes:length:
dataWithBytesNoCopy:length:freeWhenDone:
dataWithJSONObject:options:error:
dataWithOptions:error:
date
ddResult
debugDescription
debugFilename
debugMatlab
debugMode
debugOut
debugQuickLookObject
decodeArrayOfObjectsOfClass:forKey:
decodeArrayOfObjectsOfClasses:forKey:
decodeBoolForKey:
decodeDoubleForKey:
decodeFloatForKey:
decodeInt32ForKey:
decodeIntForKey:
decodeIntegerForKey:
decodeObjectOfClass:forKey:
decodeObjectOfClasses:forKey:
decodeTopLevelObjectOfClasses:forKey:error:
defaultANEDevice
defaultBox
defaultBoxesSides
defaultCPUDevice
defaultCStringEncoding
defaultDevice
defaultFaceBoundingBoxExpansionRatio
defaultFaceDetectionPrecisionRecallThreshold
defaultImageCropAndScaleOption
defaultManager
defaultMetalDevice
defaultOriginatingRequestClassNameForRequestRevision:
defaultOriginatingRequestSpecifierForRevision:
defaultProcessingDeviceForRevision:
defineCustomHierarchy:error:
defineCustomHierarchyWithRelationships:error:
delegate
deleteCharactersInRange:
dependencyAnalyzedRequestsForRequests:withPerformingContext:error:
dependencyProcessingOrdinality
dependentRequestCompatibility
dependentRequestMappingTable
description
descriptionForPrivateRevision:
descriptor
descriptorData
descriptorForEspressoBlobDimensions:dataType:
descriptorForIdentifier:version:error:
descriptorId
detect:inputIsBGR:
detectAndProcessObjects:inputIsBGR:
detectBlinkOnFaceImage:faceObservation:lumaRec2DInImageCoordinates:landmarks:warningRecorder:error:
detectDarkOnLight
detectDiacritics
detectFaceLandmarksInContext:faces:error:
detectFacesInContext:error:
detectFacesInImage:options:error:
detectFeaturesInBuffer:withRegionOfInterest:error:
detectHumanBodiesInContext:error:
detectedBarcodeSupportCode
detectedCodeWithBarcodeObservation:
detectedObjectRequestKeyToRequestInfo
detectedPoints
detectedPointsInTopLeftOrigin:orientation:
detectionLevel
detectionOnly
detectionprint
detectorAccessingLock
detectorClass
detectorClassForConfigurationOptions:error:
detectorClassForDescriptorIdentifier:version:
detectorClassForDetectorType:configuredWithOptions:error:
detectorClassForDetectorType:error:
detectorConfigurationOptions
detectorCropCreationAsyncTasksQueue
detectorCropProcessingAsyncTasksQueue
detectorExecutionTimeInterval
detectorKeyComponentForDetectorConfigurationOptionKey:value:
detectorName
detectorOfClass:configuredWithOptions:error:
detectorOfClass:configuredWithOptions:forSession:error:
detectorOfType:configuredWithOptions:error:
detectorPreferredImageSize
detectorProgressHandler
detectorType
detectorWithConfigurationOptions:forSession:error:
detectsDarkOnLight
determineColorProfileType:
deviceForMetalDevice:
diameter
dictionary
dictionaryRepresentation
dictionaryRepresentationClassesSet
dictionaryWithCapacity:
dictionaryWithContentsOfFile:
dictionaryWithObjects:forKeys:count:
dictionaryWithObjectsAndKeys:
didTrainEntityIdentificationModel:
direction
dispatchGroupAsyncByPreservingQueueCapacity:block:
dispatchGroupWait:error:
dispatchQueueAttribute
dispatchReportBlockCompletion
dispatchSyncByPreservingQueueCapacity:
dispatchThreadgroups:threadsPerThreadgroup:
distance
distanceBetweenClustersWithFaceId:andFaceId:error:
distanceBetweenFacesWithFaceObservation:andFaceObservation:error:
distanceBetweenFacesWithFaceprint:andFaceprint:error:
distanceBetweenLevel1Clusters:error:
distanceBetweenPoint:point:
distanceFromDescriptor:
distanceToDefaultBox
distanceToImageprint:error:
distanceToPoint:
distancesById
distantPast
documentElements
documentOutputRegionForImage:options:roi:error:withProgressHandler:
documentWithRegions:title:confidence:imageSize:
domain
dotProductOfVector:vector:
doubleValue
drawAtPoint:
dropCurrentFaceModelAndReturnError:
elementCount
elementType
emptyFaceprintDataForRevision:
encodeBool:forKey:
encodeDouble:forKey:
encodeFloat:forKey:
encodeHashDescriptorWithBase64EncodingAndReturnError:
encodeInt32:forKey:
encodeInt:forKey:
encodeInteger:forKey:
encodeObject:forKey:
encodeToCommandBuffer:sourceTexture:destinationTexture:
encodeToCommandBuffer:sourceTextureArray:guidanceTexture:constraintsTextureArray:numberOfIterations:destinationTextureArray:
encodeWithCoder:
encodedData
endEncoding
endRangeFaceBoundingBoxExpansionRatio
enforceSquareFaces:withHeight:andWidth:
entityCount
entityIdentificationModel:indexOfEntityWithUniqueIdentifier:
entityIdentificationModel:observationAtIndex:forEntityAtIndex:
entityIdentificationModel:trainingFailedWithError:
entityIdentificationModel:uniqueIdentifierOfEntityAtIndex:
entityIdentificationModelDidDropTrainingData:
entityIdentificationModelTrainingDataWasModified:
entityIdentificationModelWillDropTrainingData:
entityPredictionsForObservation:limit:canceller:error:
entityPrintOriginatingRequestSpecifier
entityUniqueIdentifier
entityUniqueIdentifiers
enumerateIndexesUsingBlock:
enumerateIndexesWithOptions:usingBlock:
enumerateKeysAndObjectsUsingBlock:
enumerateObjectsAtIndexes:options:usingBlock:
enumerateObjectsUsingBlock:
enumerateSubclassesOfClass:excludingRootClass:usingBlock:
environment
equationCoefficients
error
errorForCVReturnCode:localizedDescription:
errorForCancellationOfRequest:
errorForDataUnavailableWithLocalizedDescription:
errorForDataUnavailableWithLocalizedDescription:underlyingError:
errorForEspressoErrorInfo:localizedDescription:
errorForEspressoReturnStatus:localizedDescription:
errorForExecutionTimeoutWithLocalizedDescription:
errorForExecutionTimeoutWithLocalizedDescription:underlyingError:
errorForFailedEspressoPlan:localizedDescription:
errorForGPURequiredByRequest:
errorForInternalErrorWithLocalizedDescription:
errorForInternalErrorWithLocalizedDescription:underlyingError:
errorForInvalidArgument:named:
errorForInvalidArgumentWithLocalizedDescription:
errorForInvalidFormatErrorWithLocalizedDescription:
errorForInvalidImageFailure
errorForInvalidImageFailureWithLocalizedDescription:
errorForInvalidModelWithLocalizedDescription:
errorForInvalidModelWithLocalizedDescription:underlyingError:
errorForInvalidOperationForRequestClass:revision:
errorForInvalidOperationForRequestSpecifier:
errorForInvalidOperationWithLocalizedDescription:
errorForInvalidOption:named:
errorForInvalidOption:named:localizedDescription:
errorForInvalidOptionWithLocalizedDescription:
errorForMemoryAllocationFailureWithLocalizedDescription:
errorForMissingOptionNamed:
errorForOSStatus:localizedDescription:
errorForOperationFailedErrorWithLocalizedDescription:
errorForOutOfBoundsErrorWithLocalizedDescription:
errorForUnavailableSession
errorForUnimplementedFunctionWithLocalizedDescription:
errorForUnimplementedMethod:
errorForUnimplementedMethod:ofObject:
errorForUnknownClassificationIdentifier:
errorForUnknownErrorWithLocalizedDescription:
errorForUnsupportedConfigurationOfRequest:
errorForUnsupportedProcessingDevice:
errorForUnsupportedRequestClassName:
errorForUnsupportedRequestSpecifier:
errorForUnsupportedRevision:ofRequest:
errorForUnsupportedRevision:ofRequestClass:
errorForUnsupportedSerializingHeaderVersion:
errorForVImageError:localizedDescription:
errorWithCode:message:
errorWithCode:message:underlyingError:
errorWithDomain:code:userInfo:
espressoDeviceID
espressoEngine
espressoInputImageSize
espressoInputMaskSize
espressoMaskOutputBufferSizes
espressoMaskOutputBuffers
espressoModelFileNameForConfigurationOptions:
espressoModelImageprintClass
espressoModelInputImageDimensionsBlobNameForConfigurationOptions:
espressoModelNetworkLayersStorageTypeForConfigurationOptions:
espressoResources
espressoStorageType
estimateFlowFromReference:target:error:
estimateFlowStream:error:
estimateMotionBetweenFirstImage:andSecondImage:withUpsample:withGuidedImage:error:
evictAllDetectors
evictDetectorsPassingTest:
examinePulseWindow:prodBoostNormalized:pwContext:minHeight:maxHeight:thresholdSet:
exceptionWithName:reason:userInfo:
executePlanAndReturnError:
executionNanoseconds
executionTimeInternal
exifTimestamp
explicitlyConfiguredProcessingDevice
exposureScore
expressionFeatures
expressionTypeFromString:
expressionsAndConfidence
expressionsAndDetections
expressionsAndScores
extent
extractBoxesForStub:bigBoxesAdapt:countBigBox:rowStartLocation2:rowStopLocation2:heightConstraint:imageWidth:height:ccCharBoxesAggr:ccCharBoxesFiltered:useLowLightEnhancement:
extractCharBoxHeightInfo:ccCharBoxesFiltered:ccYTopLocationsForSort:ccYBottomLocationsForSort:aggregateGreenBoxesForStubCount:imageWidth:
extractDetailsForFaces:inImage:options:error:
eyesCategory
face
faceAngle
faceAttributes
faceBoundingBoxExpansionRatio
faceBoundingBoxScalingFactorForFaceObservation:
faceCaptureQuality
faceCenter
faceContour
faceCoreEnhanceEyesAndMouthLocalization
faceCoreExtractBlink
faceCoreExtractSmile
faceCoreInitialAngle
faceCoreKalmanFilter
faceCoreMinFaceSize
faceCoreType
faceCountForPersonWithUniqueIdentifier:
faceCountsForAllPersons
faceCountsForPersonsWithUniqueIdentifiers:
faceDetectionPrecisionRecallThreshold
faceHairCategory
faceID2ModelMaximumElementsPerID
faceID3IndexMode
faceID3ModelMaximumElementsPerID
faceID3ModelMaximumIDs
faceID3ModelSeed
faceId
faceIdConfidence
faceJunkinessIndex
faceModelClass
faceModelFaceObservationAtIndex:forPersonAtIndex:
faceModelIndexOfPersonWithUniqueIdentifier:
faceModelNumberOfFaceObservationsForPersonAtIndex:
faceModelPersonsCount
faceModelUniqueIdentifierOfPersonAtIndex:
faceObservationUUID
faceObservationWithRequestRevision:boundingBox:alignedBoundingBox:roll:yaw:
faceObservationWithRequestRevision:boundingBox:alignedBoundingBox:roll:yaw:pitch:
faceObservationWithRequestRevision:boundingBox:andAlignedBoundingBox:
faceObservationWithRequestRevision:boundingBox:faceprint:
faceObservationWithRequestRevision:boundingBox:roll:yaw:
faceObservationWithRequestRevision:boundingBox:roll:yaw:pitch:
faceObservationWithRequestRevision:unalignedBoundingBox:alignedBoundingBox:
faceObservationsForPersonWithUniqueIdentifier:error:
faceObservationsInOptions:withOptionName:error:
faceOrientationIndex
faceRegionMap
faceScreenGaze
faceSegmentIndexToFlagMap
faceSegmentLabelToProbabilityMap
faceSegmentToSegmentMaskGrayLevelDictionary
faceSegments
faceSegmentsPixelSizeInBytes
faceSize
faceTorsoprint
faceType
facemaskCategory
faceprint
faceprintInputPath
faceprintRequestRevision
faceprintRequestRevisionForFaceTorsoRequestRevision:error:
failWithError:
failureScore
featureExtractorParameters
featureName
featureNames
featureValue
featureValueForName:
featureValueFromScenePrint:dataType:
featureValueWithMultiArray:
featureValueWithPixelBuffer:
features
feedForwardEspressoBufferForNetwork:fromBufferWithName:toBufferWithName:firstFrame:error:
fileExistsAtPath:
fileExistsAtPath:isDirectory:
fileHandleForUpdatingAtPath:
fileNameBase
fileURLWithPath:
fileURLWithPath:isDirectory:
fillInOneVector:checkFlag:checkHeight:
filterBoxes:
filterThresholds
filterWalkUpDownCount
filterWithName:keysAndValues:
filteredArrayUsingPredicate:
fingerprintHashes
finishDecoding
finishEncoding
firstIndex
firstObject
firstObjectCommonWithArray:
firstSupportedRevisionInOrderedRevisionList:
floatValue
floatVectorSumProd
floatingImageSignature
forceFaceprintCreation
forceUseInputCVPixelBufferDirectly
forcedCleanup
forcedCleanupWithOptions:
frameAnalysisSpacing
frameCVPixelBufferFormatForRequestRevision:
frameRate
frameworkClass
frameworkVersion
free
freeColorProfileContext:
freeImageInDealloc
freeNodeOnDealloc
freeVImageBuffer:
fullyPopulateConfigurationOptions:
fullyPopulatedConfigurationOptionsWithOverridingOptions:
gaze
gazeHeatMapThreshold
gazeMask
genderCategory
generateDominantPulse:rowLocationsRef:debugOut:bufferHeight:bufferWidth:
generateHistogramBounds:rgbVector2Ref:numPixels1:numPixels2:minMaxRGB:lowHighRGB:
generatePulses:minHeight:maxHeight:thresholdSet:prodBoostNormalized:pulseVectorFlag:
generateSegmentationMask
getAllClustersAndReturnError:
getAllClustersFromStateAndReturnError:
getArray:forKey:inOptions:withElementsOfClass:requiredMinimumCount:allowedMaximumCount:error:
getBOOLValue:forKey:inOptions:error:
getBOOLValue:forKey:inOptions:withDefaultValue:error:
getBlocks
getCRDocumentOutputRegion
getCROutputRegion
getCameraIntrinsicsAvailable:
getCameraOpticalCenterIfAvailable:
getChildren
getClassCode:forClass:error:
getClassCode:forClassName:error:
getClusterState:
getClusteredIds:
getClustersForClusterIds:options:error:
getClustersWithOptions:error:
getConfidence:forClassificationIdentifier:withPrecision:error:
getConfidence:forClassificationIdentifier:withRecall:error:
getConstellation:cvmlConstellation:fromOptions:error:
getDataDetectorResults:
getDataDetectorResultsForString:error:
getDefaultConfidence:forClassificationIdentifier:error:
getDistanceBetweenLevel0ClustersWithFaceId:andFaceId:error:
getDistanceBetweenLevel1Clusters:error:
getDistanceForClusterNode:splitDistanceType:
getDistances:to:error:
getDoubleValue:forKey:inOptions:error:
getDoubleValue:forKey:inOptions:withDefaultValue:error:
getFaceEXIFOrientation:error:
getFloatValue:forKey:inOptions:error:
getFloatValue:forKey:inOptions:withDefaultValue:error:
getHostTime
getHostTimeInNanos
getIndexBoxes:filterThresholdIndex:
getInputImageTensorDescriptor:forBlobName:pixelFormatType:outputTensorDescriptors:forBlobNamesWithTypes:fromNetworkModelFileWithPath:error:
getIntValue:forKey:inOptions:error:
getIntValue:forKey:inOptions:minimumValue:maximumValue:error:
getIntValue:forKey:inOptions:withDefaultValue:error:
getKey:fromDictionary:withDefault:
getLabels
getLandmarkErrorEstimates:forConstellation:error:
getLandmarkOcclusionFlags:forConstellation:error:
getLandmarkPoints:forConstellation:error:
getLeafNodes
getLevel0ClusteredIdsForFaceId:error:
getLevel1ClusteredIdsGroupedByLevel0ClustersForFaceId:error:
getLines
getLumaHistogram:startCC:colorProfileContext:
getMTLGPUPriority:forKey:inOptions:withDefaultValue:error:
getNSIntegerValue:forKey:inOptions:withDefaultValue:error:
getNSUIntegerValue:forKey:inOptions:error:
getNSUIntegerValue:forKey:inOptions:withDefaultValue:error:
getOSTypeValue:forKey:inOptions:error:
getOSTypeValue:forKey:inOptions:withDefaultValue:error:
getOptionalArray:forKey:inOptions:withElementsOfClass:error:
getOptionalCanceller:inOptions:error:
getOptionalExplicitProcessingDevice:inOptions:error:
getOptionalObject:ofClass:forKey:inOptions:error:
getOptionalOriginatingRequestSpecifier:forKey:inOptions:specifyingSupportedRevisionsForRequestClass:error:
getOptionalValidatedInputDetectedObjectObservations:forObservationClass:relationWithRegionOfInterest:error:
getOptionalValidatedInputFaceObservations:clippedToRegionOfInterest:error:
getPercentageValue:forKey:inOptions:withDefaultValue:error:
getPrecision:forClassificationIdentifier:confidence:error:
getRecall:forClassificationIdentifier:confidence:error:
getRecognizedLanguages
getReferenceImageBuffer:registrationSignature:forRequestPerformingContext:error:
getRepresentativenessForFaces:error:
getRequiredObject:ofClass:forKey:inOptions:error:
getSignatureData
getStoredRepresentationTag:forModelVersion:error:
getSuggestedImageSize:
getTitle
getTopLeftPoint:topRightPoint:bottomRightPoint:bottomLeftPoint:inTopLeftOrigin:orientation:
getTranscript
getUUIDBytes:
getValue:size:
getVotingHistogram:colorProfileContext:startCC:rowStartLocation:
getWidth:height:ofBlobNamed:forNetworkModelFileWithName:error:
getWidth:height:ofBlobNamed:forNetworkModelFileWithPath:error:
getWidth:height:ofEspressoModelNetworkBlobNamed:error:
globalSegmentationMask
globalSession
groupEndpoints:finalCharBoxCoordCount:
groupedClusteredFaceIdsForCluster
hairColorCategory
harmoniousColorScore
hasAdjustmentForKey:
hasCancellationHook
hasEquivalentDescriptorToImageprint:
hasLabel
hasLocation
hasMinimumPrecision:forRecall:
hasMinimumRecall:forPrecision:
hasModelEquivalencyToRequestSpecifier:
hasObjDetNet
hasPrecisionRecallCurve
hasPrefix:
hasSliderNet
hasSuffix:
hasWarnings
hash
hashData
hashString
height
hierarchicalModelAndReturnError:
idealDimension
idealImageFormat
idealOrientation
identifier
image
imageBufferAndReturnError:
imageBufferValue
imageByApplyingCGOrientation:
imageByApplyingFilter:withInputParameters:
imageByApplyingOrientation:
imageByApplyingTransform:
imageByApplyingTransform:highQualityDownsample:
imageByClampingToExtent
imageByColorMatchingColorSpaceToWorkingSpace:
imageByCompositingOverImage:
imageByCroppingToRect:
imageByPremultiplyingAlpha
imageByUnpremultiplyingAlpha
imageCVPixelBuffer
imageCropAndScaleOption
imageFilePath
imageNeuralHashprint
imageReaderRecognitionOptionsForProcessOptions:
imageRegistrationDescriptor
imageSignatureHash
imageSignatureHashType
imageSignatureprint
imageSignatureprintType
imageSignaturnprintByRunningNeuralHashprintRequest:error:
imageWithCVImageBuffer:
imageWithCVPixelBuffer:
imageWithContentsOfURL:
imageWithData:
imageWithData:options:
imageprint
imageprintVersion
immersivenessScore
importantClasses
inHierarchy
indeterminate
indexAtPosition:
indexOfEntityWithUniqueIdentifier:
indexOfObject:
indexOfObject:inSortedRange:options:usingComparator:
indexOfObjectPassingTest:
indexPath
indexPathByAddingIndex:
indexPathWithIndex:
indexSet
indexSetWithIndexesInRange:
indexType
indexesOfObjectsPassingTest:
inferenceNetworkIdentifiers
information
informationForModelWithData:error:
informationForModelWithURL:error:
init
initDumpDebugIntermediates:debugInfo:
initForReadingFromData:error:
initRequiringSecureCoding:
initToMemory
initWithArray:
initWithArray:copyItems:
initWithBCSDetectedCode:description:observation:
initWithBatchNumber:channels:width:height:
initWithBooleanBytes:length:
initWithBooleanBytesData:
initWithBoundingBox:
initWithBox:defaultBox:confidence:scale:rotationAngle:yawAngle:hasLabel:label:
initWithBox:defaultBox:confidence:scale:rotationAngle:yawAngle:mergesCount:
initWithBox:defaultBox:confidence:scale:rotationAngle:yawAngle:mergesCount:hasLabel:label:
initWithBox:defaultBox:confidence:scale:rotationAngle:yawAngle:pitchAngle:hasLabel:label:
initWithBox:defaultBox:confidence:scale:rotationAngle:yawAngle:pitchAngle:mergesCount:hasLabel:label:
initWithBuffer:forKey:originalFeatureProvider:
initWithBytes:length:
initWithBytes:objCType:
initWithBytesNoCopy:length:
initWithBytesNoCopy:length:freeWhenDone:
initWithCGImage:
initWithCGImage:options:
initWithCGImage:options:session:
initWithCGImage:orientation:options:
initWithCGImage:orientation:options:session:
initWithCIImage:options:
initWithCIImage:options:session:
initWithCIImage:orientation:options:
initWithCIImage:orientation:options:session:
initWithCMSampleBuffer:options:session:
initWithCMSampleBuffer:orientation:options:
initWithCMSampleBuffer:orientation:options:session:
initWithCVPixelBuffer:
initWithCVPixelBuffer:options:
initWithCVPixelBuffer:options:session:
initWithCVPixelBuffer:orientation:options:
initWithCVPixelBuffer:orientation:options:session:
initWithCVPixelBufferImage:externalImageId:andExifTimestampString:error:
initWithCVPixelBufferImage:externalImageId:andExifTimestampValue:error:
initWithCachingBehavior:
initWithCapacity:
initWithCenter:diameter:
initWithCenter:radius:
initWithCoder:
initWithCompletionHandler:
initWithConfiguration:
initWithConfiguration:dataSource:
initWithConfiguration:faceModel:
initWithConfiguration:trainedModel:
initWithConfigurationOptions:
initWithContentsOfURL:
initWithDDScannerResult:observation:
initWithData:
initWithData:elementCount:elementType:lengthInBytes:confidence:originatingRequestSpecifier:
initWithData:elementCount:elementType:lengthInBytes:confidence:requestRevision:
initWithData:elementCount:elementType:lengthInBytes:faceprintConfidence:torsoprintConfidence:
initWithData:elementCount:elementType:lengthInBytes:faceprintConfidence:torsoprintConfidence:originatingRequestSpecifier:
initWithData:elementCount:elementType:lengthInBytes:imageSignatureHashType:requestRevision:
initWithData:elementCount:elementType:lengthInBytes:imageSignatureprintType:originatingRequestSpecifier:
initWithData:elementCount:elementType:lengthInBytes:imageSignatureprintType:requestRevision:
initWithData:elementCount:elementType:lengthInBytes:labelsAndConfidence:originatingRequestSpecifier:
initWithData:elementCount:elementType:lengthInBytes:labelsAndConfidence:requestRevision:
initWithData:elementCount:elementType:lengthInBytes:requestRevision:
initWithData:encoding:
initWithData:forKey:
initWithData:options:
initWithData:options:session:
initWithData:orientation:options:
initWithData:orientation:options:session:
initWithDataPointer:shape:dataType:strides:deallocator:error:
initWithDescriptorData:elementType:elementCount:originatingRequestSpecifier:
initWithDetectedObjectObservation:
initWithDetectedObjectObservation:completionHandler:
initWithDetectorDescriptorIdentifierVersionTuples:descriptorIdentifierToVersionsArray:
initWithDetectorModel:
initWithDetectorType:configuration:
initWithDetectorType:groupingConfiguration:
initWithDevice:filterDescriptor:
initWithDevice:kernelWidth:kernelHeight:
initWithDevice:thresholdValue:maximumValue:linearGrayColorTransform:
initWithDictionary:
initWithDictionary:copyItems:
initWithDimensions:
initWithDispatchQueueLabel:maximumTasksCount:
initWithDomain:code:userInfo:
initWithEntityIdentificationModel:dataSource:
initWithEntityPrintOriginatingRequestSpecifier:
initWithEspressoNetwork:espressoPlan:threshold:
initWithFace:
initWithFaceIDModel:entityPrintOriginatingRequestSpecifier:entityUniqueIdentifiers:entityPrintCounts:
initWithFaceIDModel:entityPrintOriginatingRequestSpecifier:maximumElementsPerID:entityUniqueIdentifiers:entityPrintCounts:
initWithFaceIDModel:faceprintRequestRevision:maximumElementsPerID:personUniqueIdentifierToSerialNumberMapping:
initWithFaceIDModel:faceprintRequestRevision:personUniqueIdentifierToSerialNumberMapping:
initWithFaceObservation:predictedPersonUniqueIdentifier:confidence:
initWithFaceObservations:
initWithFaceObservations:completionHandler:
initWithFaceprint:torsoPrint:originatingRequestSpecifier:
initWithFaceprint:torsoPrint:requestRevision:
initWithFaceprint:torsoprint:
initWithFrameAnalysisSpacing:completionHandler:
initWithFrameAnalysisSpacing:trajectoryLength:
initWithFrameAnalysisSpacing:trajectoryLength:completionHandler:
initWithFrameRate:
initWithFrameworkBundleIdentifier:
initWithHashData:
initWithIdealFormat:pixelsWideRange:pixelsHighRange:aspectRatioHandling:idealOrientation:orientationAgnostic:
initWithIdealFormat:width:height:orientation:aspectRatioHandling:orientationAgnostic:
initWithIdentifiers:
initWithImageBuffer:regionOfInterest:error:
initWithImageChannels:width:height:
initWithImageCropAndScaleOption:
initWithImageData:andCustomQualityScore:context:error:
initWithImageData:context:error:
initWithImageDescriptor:type:originatingRequestSpecifier:
initWithImageSignatureprintType:imageSignatureHashType:
initWithImageSignatureprintType:imageSignatureHashType:completionHandler:
initWithIndex:
initWithIndexes:length:
initWithIndexesInRange:
initWithInputParameters:
initWithJSFile:binSerializerId:context:computePath:
initWithJSFile:context:computePath:
initWithKernelName:
initWithKernelName:inputParameters:
initWithKeyOptions:valueOptions:capacity:
initWithLabelToOperationPointsDataIndexMap:operationPointsDataArray:
initWithLocation:
initWithLocation:confidence:
initWithLocation:confidence:identifier:
initWithMLModel:error:
initWithMajor:
initWithMajor:minor:
initWithMajor:minor:micro:
initWithMappedModel:
initWithMetalContext:width:height:numScales:error:
initWithMetalDevice:
initWithMinimumDimension:maximumDimension:idealDimension:
initWithModel:
initWithModel:completionHandler:
initWithModelConfiguration:
initWithModelName:networkConfigurationName:network:plan:context:
initWithModelPath:espressoEngineID:espressoDeviceID:espressoStorageType:threshold:
initWithName:dataType:shape:
initWithName:pixelFormatType:pixelWidth:pixelHeight:
initWithNetwork:
initWithNetwork:filterThresholds:
initWithNetworkContext:
initWithNetworkFileURL:version:networkHeadVersions:inputImage:faceprintOutput:confidencesOutput:
initWithNetworkFileURL:version:networkHeadVersions:inputImage:outputs:confidencesOutput:
initWithNetworkFileURL:version:networkHeadVersions:inputs:outputs:inputImages:confidencesOutput:
initWithObjectType:boundingBox:confidence:
initWithObjectType:boundingBox:confidence:rotationAngle:yawAngle:pitchAngle:labelKey:
initWithObjects:
initWithObjects:count:
initWithObjectsAndKeys:
initWithObservation:entityUniqueIdentifier:confidence:
initWithOperationPoints:
initWithOperationPointsCache:originatingRequestSpecifier:
initWithOptions:
initWithOptions:error:
initWithOptions:logEnabled:
initWithOptions:logEnabled:logFileNameBase:
initWithOptions:model:error:
initWithOriginalRequests:
initWithOriginalRequests:requestToObservationClassMap:
initWithOriginatingRequestSpecifier:
initWithOriginatingRequestSpecifier:adjustments:
initWithOriginatingRequestSpecifier:allRecognizedPoints:
initWithOriginatingRequestSpecifier:boundingBox:
initWithOriginatingRequestSpecifier:boundingBox:confidence:labels:animalprint:
initWithOriginatingRequestSpecifier:boundingBox:confidence:labels:segmentationMask:
initWithOriginatingRequestSpecifier:boundingBox:upperBodyOnly:confidence:
initWithOriginatingRequestSpecifier:detectionLevel:
initWithOriginatingRequestSpecifier:detectionprint:
initWithOriginatingRequestSpecifier:faceBoundingBox:
initWithOriginatingRequestSpecifier:faceBoundingBox:points:pointCount:
initWithOriginatingRequestSpecifier:faceBoundingBox:pointsClassification:points:pointCount:precisionEstimatesPerPoint:
initWithOriginatingRequestSpecifier:featureName:CVPixelBuffer:
initWithOriginatingRequestSpecifier:featureName:featureValue:
initWithOriginatingRequestSpecifier:fingerprintHashes:
initWithOriginatingRequestSpecifier:identifier:confidence:
initWithOriginatingRequestSpecifier:identifier:confidence:operationPointsProvider:
initWithOriginatingRequestSpecifier:imageNeuralHashprint:
initWithOriginatingRequestSpecifier:imageSignatureprint:imageSignatureHash:
initWithOriginatingRequestSpecifier:keypointReturningObservation:
initWithOriginatingRequestSpecifier:overallAestheticScore:wellFramedSubjectScore:wellChosenBackgroundScore:tastefullyBlurredScore:sharplyFocusedSubjectScore:wellTimedShotScore:pleasantLightingScore:pleasantReflectionsScore:harmoniousColorScore:livelyColorScore:pleasantSymmetryScore:pleasantPatternScore:immersivenessScore:pleasantPerspectiveScore:pleasantPostProcessingScore:noiseScore:failureScore:pleasantCompositionScore:interestingSubjectScore:intrusiveObjectPresenceScore:pleasantCameraTiltScore:lowKeyLightingScore:
initWithOriginatingRequestSpecifier:pointsData:pointCount:constellation:precisionEstimatesPerPoint:userFacingBBox:alignedBBox:landmarkScore:
initWithOriginatingRequestSpecifier:pointsData:pointCount:userFacingBBox:alignedBBox:landmarkScore:
initWithOriginatingRequestSpecifier:rawSaliencyImage:originalImageSize:salientObjectBoundingBoxes:
initWithOriginatingRequestSpecifier:sceneprints:
initWithOriginatingRequestSpecifier:smartCamprints:
initWithOriginatingRequestSpecifier:symbology:descriptor:boundingBox:
initWithOriginatingRequestSpecifier:symbology:descriptor:topLeft:bottomLeft:bottomRight:topRight:
initWithOriginatingRequestSpecifier:topLeft:bottomLeft:bottomRight:topRight:
initWithOriginatingRequestSpecifier:topLeft:bottomLeft:bottomRight:topRight:boundingBox:
initWithOriginatingRequestSpecifierProcessingOptionKey:originalRequestResultsIndex:
initWithParentRequest:orderedChildRequests:
initWithPayload:isCompact:layerCount:dataCodewordCount:
initWithPayload:isCompact:rowCount:columnCount:
initWithPersonsModel:dataSource:
initWithPixelFormatType:width:height:
initWithPlatform:
initWithPoint:
initWithPoint:completionHandler:
initWithPoints:topLevelIndex:indexPath:aspectRatio:
initWithR:theta:
initWithRawColorGaborDescriptor:
initWithRawData:confidence:requestRevision:
initWithRawImageprintDescriptor:
initWithRectangleObservation:
initWithRectangleObservation:completionHandler:
initWithRequest:error:
initWithRequest:observationsCacheKey:
initWithRequestClass:
initWithRequestClass:name:code:revision:
initWithRequestRevision:
initWithRequestRevision:CRImageReaderOutput:
initWithRequestRevision:boundingBox:
initWithRequestRevision:boundingBox:confidence:labels:
initWithRequestRevision:crOutputRegion:
initWithRequestRevision:identifier:confidence:
initWithRequestRevision:identifier:confidence:operationPointsProvider:
initWithRequestRevision:outputBufferWidth:outputBufferHeight:outputBufferData:numberOfFaceSegments:faceSegmentBBox:faceSegmentLabelToProbabilityMap:
initWithRequestRevision:regionMap:deallocateBuffer:userBBox:alignedBBox:valueToLabelMap:
initWithRequestRevision:sceneprints:
initWithRequestRevision:smartCamprints:
initWithRequestRevision:topLeft:bottomLeft:bottomRight:topRight:
initWithSceneObservation:
initWithSceneObservation:completionHandler:
initWithScenePrint:dataType:forKey:originalFeatureProvider:
initWithSession:
initWithSession:imageBuffer:
initWithSession:requestPerformer:imageBuffer:forensics:observationsCache:
initWithSession:requestPerformer:imageBuffer:forensics:observationsCache:qosClass:
initWithShape:dataType:error:
initWithSignatureData:
initWithSizes:count:
initWithState:error:
initWithStatus:error:
initWithSubrequests:
initWithSubrequests:uniqueObservationClasses:
initWithTargetedCGImage:options:
initWithTargetedCGImage:options:completionHandler:
initWithTargetedCGImage:orientation:options:
initWithTargetedCGImage:orientation:options:completionHandler:
initWithTargetedCIImage:options:
initWithTargetedCIImage:options:completionHandler:
initWithTargetedCIImage:orientation:options:
initWithTargetedCIImage:orientation:options:completionHandler:
initWithTargetedCMSampleBuffer:options:
initWithTargetedCMSampleBuffer:options:completionHandler:
initWithTargetedCMSampleBuffer:orientation:options:
initWithTargetedCMSampleBuffer:orientation:options:completionHandler:
initWithTargetedCVPixelBuffer:options:
initWithTargetedCVPixelBuffer:options:completionHandler:
initWithTargetedCVPixelBuffer:orientation:options:
initWithTargetedCVPixelBuffer:orientation:options:completionHandler:
initWithTargetedImageBuffer:completionHandler:
initWithTargetedImageData:options:
initWithTargetedImageData:options:completionHandler:
initWithTargetedImageData:orientation:options:
initWithTargetedImageData:orientation:options:completionHandler:
initWithTargetedImageURL:options:
initWithTargetedImageURL:options:completionHandler:
initWithTargetedImageURL:orientation:options:
initWithTensorsDictionary:originatingRequestSpecifier:
initWithTensorsDictionary:requestRevision:
initWithTimeInterval:
initWithTopLeft:bottomLeft:bottomRight:topRight:
initWithTopLevelRegion:requestRevision:
initWithType:cachePath:state:readOnly:threshold:requestRevision:error:
initWithType:cachePath:state:readOnly:threshold:requestRevision:torsoprintRequestRevision:error:
initWithType:cachePath:state:readOnly:threshold:torsoThreshold:requestRevision:error:
initWithType:cachePath:state:readOnly:threshold:torsoThreshold:requestRevision:torsoprintRequestRevision:error:
initWithType:cachePath:state:threshold:
initWithType:cachePath:state:threshold:requestRevision:
initWithType:cachePath:state:threshold:requestRevision:error:
initWithType:cachePath:state:threshold:requestRevision:torsoprintRequestRevision:error:
initWithType:cachePath:state:threshold:torsoThreshold:
initWithType:cachePath:state:threshold:torsoThreshold:requestRevision:
initWithType:cachePath:state:threshold:torsoThreshold:requestRevision:error:
initWithType:cachePath:state:threshold:torsoThreshold:requestRevision:torsoprintRequestRevision:
initWithType:cachePath:state:threshold:torsoThreshold:requestRevision:torsoprintRequestRevision:error:
initWithURL:
initWithURL:append:
initWithURL:options:
initWithURL:options:session:
initWithURL:orientation:options:
initWithURL:orientation:options:session:
initWithUTF8String:
initWithUUIDBytes:
initWithUUIDString:
initWithVCPHandObservation:originatingRequestSpecifier:
initWithVCPPersonObservation:originatingRequestSpecifier:
initWithVImage:externalImageId:andExifTimestampString:error:
initWithVImage:externalImageId:andExifTimestampValue:error:
initWithVectorHead:tail:
initWithVersion:algorithm:lastModificationDate:readOnly:
initWithVersion:lastModificationDate:algorithm:readOnly:
initWithX:y:
initWithXComponent:yComponent:
initialize
initializeBuffers
initializeEspressoResourcesWithModelPath:espressoEngineID:espressoDeviceID:espressoStorageType:
initializeForImage:
initializeLogging
initializeOutputConfidenceBuffers:
inliersRatioThreshold
innerLips
inputBGR
inputBiasRGB
inputBlobNames
inputContrast
inputDescriptionsByName
inputFaceObservations
inputFactor1
inputFactor2
inputFactor3
inputFactor4
inputImage
inputImageAspectRatio
inputImageAspectRatioHandling
inputImageAspectRatioHandlingForConfigurationOptions:
inputImageBlobName
inputImageBlobNameForConfiguration:
inputImageFeatureName
inputImageFormat
inputImageHeight
inputImageKey
inputImageMaxDimension
inputImageMinDimension
inputImageSize
inputLayerName
inputMaskBlobName
inputMaskRequired
inputNamed:error:
inputObservation
inputPivot
inputPoint
inputScale
inputScenePrintKey
inputScenePrintMLMultiArrayDataType
inputSignatureprint
inputStreamWithURL:
insertObject:atIndex:
insertString:atIndex:
instanceMethodForSelector:
instanceSegmentationMask
instancesRespondToSelector:
intValue
integerValue
interestingSubjectScore
internalCancelInContext:error:
internalParabolas
internalParams
internalPerformRevision:inContext:error:
internalProcessUsingQualityOfServiceClass:options:regionOfInterest:warningRecorder:error:progressHandler:
intersectSet:
intersectionOverArea:
intersectionOverMinArea:
intrusiveObjectPresenceScore
invalidVersion
ioSurfaceBackedPixelBufferAttributes
ioSurfaceMemoryPoolId
isAllowedDimension:
isAnchorSquare
isBlinking
isBoundingBoxAligned
isCRImageReaderViableAfterError:
isCVPixelBuffer:equalToCVPixelBuffer:
isCompatibleWithConfiguration:
isDetectedObject:ofAGivenObjectSubClass:
isEqual:
isEqualToDate:
isEqualToDictionary:
isEqualToResourceVersion:
isEqualToSet:
isEqualToString:
isEquivalentToVNEntityIdentificationModelPrint:
isFullCoverageRegionOfInterest
isImageprintValid
isKindOfClass:
isLastFrame
isLogEnabled
isMajorVersion:equalToMajorVersion:
isMemberOfClass:
isMinorVersion:equalToMinorVersion:
isOrientationAgnostic
isOverlappingLowMergeDet:withOverlapThreshold:withMergeCountDelta:
isOverlappingSmallFace:withOverlapThreshold:withSizeRatio:
isPrint:compatibleWithOtherPrint:error:
isReadOnly
isReadableFileAtPath:
isReentrant
isResettable
isRevision1DetectedRectanglesCompatible
isSubclassOfClass:
isSubsetOfSet:
isTracking
isUserFacingBBoxEquivalentToAlignedBBox
isValidFaceprint
isValidTorsoprint
keepNetworkOutput
keepRawOutputMask
kernelWithFunctionName:fromMetalLibraryData:error:
keyEnumerator
keyForDetectorWithConfigurationOptions:
keypoints
keypointsMultiArrayAndReturnError:
knownAnimalHeadIdentifiers
knownAnimalIdentifiers
knownAnimalIdentifiersForRevision:error:
knownClassificationsForRevision:error:
knownFoodAndDrinkIdentifiers
knownObjectIdentifiersRecognizedByRequestRevision:error:
knownSceneClassifications
knownSceneClassificationsForRevision:error:
knownSportBallIdentifiers
knownTensorKeysForRequestRevision:error:
l1ClusteredFaceIdsGroupedByL0ClustersForClustersContainingFaceIds:error:
label
labelKey
labelNames
labels
labelsAndConfidence
landmarkDetectorDNNVersion
landmarkPointSizeInBytes
landmarkPoints
landmarkPoints3d
landmarkPoints65
landmarkPrecisionEstimatesPerPoint
landmarkScore
landmarks
landmarks3DOriginatingRequestSpecifier
landmarks3d
landmarks65
landmarksConstellation
landmarksMeshPartsForConstellation:
landmarksOriginatingRequestSpecifier
lastDataChangeSequenceNumberForEntityIdentificationModel:
lastDataChangeSequenceNumberForPersonsModel:
lastFrame
lastIndex
lastModificationDate
lastModificationDateForEntityIdentificationModel:
lastObject
lastPathComponent
layers_size
leafSubclassesOfClass:excludingRootClass:overridingClassSelector:
leafsCount
left
leftEyebrow
leftPupil
legacyFaceCore
legacyForcedCleanupOfFacePipelineWithLevel:
legacyForcedCleanupOfJunkPipelineWithLevel:
legacyForcedCleanupOfScenePipelineWithLevel:
legacyForcedCleanupOfSmartCamPipelineWithLevel:
length
lengthInBytes
level
levelCount
lines
linkTimeOrRunTimeAtLeastVersion:
livelyColorScore
load:
loadFromIdentifier:error:
loadFromPropertyList:error:
loadFromURL:error:
loadRefinersAndReturnError:
localeWithLocaleIdentifier:
localizedDescription
localizedFailureReason
localizedStringForKey:value:table:
localizedStringFromDate:dateStyle:timeStyle:
locateMode
locateRPNTrackerResourcesConfiguredForOptions:error:
location
locationInTopLeftOrigin:orientation:
lock
logAllSuggestons:
logClusterLookupMapL0:
logClusterLookupMapL1:
logClusterMap:level:
logClusterMapL0:
logClusterMapL1:
logConnectedGroups:
logEnabled
logFileURL
logFilteredByInputQuerySuggestons:
logFinalSuggestionsList:
logFolderURL
logInputFaceIdsWithFlags:
logInternalError:
logString:
logSuggestons:description:
longLongValue
longValue
lookedAtFaceObservationUUID
loopBigBox
loopBigBoxPrev
lowKeyLightingScore
lowPriorityCIContext
mClassifier
mDescriptorProcessor
mFaceBoxAlignerModelFileHandle
mFaceBoxPoseAlignerImpl
mFaceRegionMapAlgorithmImpl
mJunkClassifierImpl
mJunkDescriptorImpl
mTop
mTrackerImpl
m_ClusteringImpl
m_ClusteringImpl_const
m_FaceAttributesImpl
m_impl
machineReadableCodeElements
magnifiedBBoxScaleFactor
mainBundle
mainCIContext
mainCIContextMetalDevice
major
makeAllocationsForWidth:
makeClippedRectAgainstImageExtentUsingOriginalRect:
makeupCategory
makeupEyesCategory
makeupLipsCategory
maskConfidenceForOutputMaskBlobName:
matchedString
maxBoxWidth
maxHeight
maxTotalThreadsPerThreadgroup
maximumAllowableEntities
maximumAllowableFaceprintsPerIdentity
maximumAllowableIdentities
maximumAllowedTasksInTheQueue
maximumAspectRatio
maximumCandidateCount
maximumDimension
maximumFaceIdInModelAndReturnError:
maximumHandCount
maximumIdentities
maximumImageDimension
maximumIntermediateSideLength
maximumLeafObservations
maximumObjectSize
maximumObservations
maximumProcessingDimensionOnTheLongSide
maximumTasksCount
maximumTrainingFaceprintsPerIdentity
maximumTrainingPrintsPerEntity
maximumValueFromFloat32ImageBuffer:
medianHeightBottom
medianLine
memoryPoolId
mergeBoxes:
mergeHeadsBoxes:
mergesCount
metalContext
metalContextPriority
metalDevice
methodForSelector:
micro
midRow
minBoxWidth
minHeight
minimizeFalseDetections
minimumAspectRatio
minimumCharacterPixelHeight
minimumConfidence
minimumDimension
minimumFaceDimension
minimumLatencyFrameCount
minimumObjectSize
minimumSize
minimumTextHeight
minimumTorsoInsideInputImageThreshold
minor
minusOrderedSet:
minusSet:
mmHeightCard
mmWidthCard
model
modelBuiltFromConfiguration:dataProvider:canceller:error:
modelCachingIdentifier
modelConfigurationForVersion:modelObjects:error:
modelDescription
modelFileBackingStore
modelForMLModel:error:
modelForRequestClass:revision:
modelFromData:options:error:
modelFromPersonsModel:error:
modelFromStream:options:error:
modelFromURL:options:error:
modelName
modelNameForConfiguration:
modelNonMaximumSuppressionThreshold
modelType
modelVersionForOptions:
modelVersionIDForConfigurationOptions:
modelWithConfiguration:dataSource:error:
modelWithConfiguration:error:
modifySmallFaceThrehold:withHeight:andWidth:
mouth
moveItemAtPath:toPath:error:
movingAverageRadius
mrcDescriptor
multiArrayConstraint
mumberBinsNegativeMaxout
mumberPosClasses
mutableBytes
mutableCopy
name
nameConfidence
narrowedBoundingBox
naturalClusteringDistanceThreshold
needsMetalContext
networkConfigurationName
networkFileURL
networkRequiredInputImagePixelFormatForConfigurationOptions:
networkRequiredInputImageWidth
networkThreshold
networkVersion
newBarcodeObservationForACBSBarcodeInfo:imageWidth:imageHeight:roiCroppingPixelRect:originatingRequestSpecifier:error:
newBarcodeObservationForMRCDescriptor:roiCroppingPixelRect:originatingRequestSpecifier:error:
newBufferWithLength:options:
newComputePipelineStateWithFunction:error:
newConfiguration
newConfigurationForEntityPrintsGeneratedByRequest:error:
newConfigurationInstance
newDefaultDetectorOptionsForRequestRevision:session:
newDefaultDetectorOptionsForSession:
newDefaultLibraryWithBundle:error:
newDefaultRequestInstance
newFunctionWithName:
newHierarchicalModelAndReturnError:
newImageReaderAndReturnError:
newMetalContextForConfigurationOptions:error:
newModelForVersion:modelObjects:error:
newModelFromVersion:objects:error:
newTextureViewWithPixelFormat:
newTextureWithDescriptor:
newTextureWithDescriptor:iosurface:plane:
nextLeafDescriptorDistance
nextLeafId
nextLeafTimestampDistance
nextLeafTotalDistance
nextObject
nlreg_padding
nlreg_radius
nlreg_sigma_c
nlreg_sigma_l
nlreg_sigma_w
nmsBoxes:
nmsThreshold
node
nodeId
noiseScore
nonGroupedGroupID
nonSquareRollDefault
nonSquareYawDefault
normalizedPath
normalizedPathInTopLeftOrigin:orientation:
normalizedPoints
normalizedPointsInTopLeftOrigin:orientation:
nose
noseCrest
notificationCenter
null
numScales
numWarpings
numberBinsRoll
numberBinsYaw
numberFromString:
numberMaxoutLayers
numberOfEntitiesInEntityIdentificationModel:
numberOfFaceSegments
numberOfImageChannels
numberOfKeypointsToConsider
numberOfPersonsInPersonsModel:
numberWithDouble:
numberWithFloat:
numberWithInt:
numberWithInteger:
numberWithLongLong:
numberWithShort:
numberWithUnsignedChar:
numberWithUnsignedInt:
numberWithUnsignedInteger:
numberWithUnsignedLong:
numberWithUnsignedLongLong:
object:overridesSelector:
objectAtIndex:
objectAtIndexedSubscript:
objectBoundingBoxOutputDescription
objectEnumerator
objectForKey:
objectForKeyedSubscript:
objectMaximumNormalizedRadius
objectMinimumNormalizedRadius
objectType
objectsAtIndexes:
observation
observationAtIndex:forEntityAtIndex:
observationBoundsAreNormalizedToROIForRequestClassCode:revision:
observationCountForEntityAtIndex:
observationCountForEntityWithUniqueIdentifier:
observationCountsForEntitiesWithUniqueIdentifiers:
observationProvidesBoundsNormalizedToROI
observationWithBoundingBox:
observationWithImageprint:error:
observationWithOriginatingRequestSpecifier:
observationWithRequestRevision:boundingBox:
observationWithSceneprints:
observationWithSmartCamprints:
observationsAcceptedByRequest:testedKeyHandler:
observationsCacheKey
observationsForEntityWithUniqueIdentifier:error:
observationsForKey:
observationsForLastAnalysisOfImageAnalyzer:processOptions:originatingRequestSpecifier:qosClass:error:
observationsForSceneLabelsFromLastAnalysisOfImageAnalyzer:identifierAcceptingBlock:operationPointsProvider:originatingRequestSpecifier:qosClass:error:
obtainImageSourceRefWithSubSampleFactor:andLowPriorityHint:error:
olmcsMergeCountDelta
olmcsThreshold
onlyInputImage
open
operationPointsAndReturnError:
opticalFlow
orderedChildRequests
orderedRequestsForRequests:
orderedSetWithCapacity:
orientation
orientationAgnostic
originalObservation
originalPixelBuffer
originalRequestConfigurations
originalRequestResultsIndex
originalRequests
originalRequestsOfClass:
originatingRequestSpecifier
originatingRequestSpecifierForKey:inOptions:error:
originatingRequestSpecifierForKey:inOptions:specifyingSupportedRevisionsForRequestClass:error:
originatingRequestSpecifierForRequestRevision:error:
originatingRequestSpecifierInOptions:error:
originatingRequestSpecifierInOptions:specifyingSupportedRevisionsForRequestClass:error:
originatingRequestSpecifierKey
originatingRequestSpecifierToDetectorClassMap
osfsSizeRatio
osfsThreshold
outerLips
outputBufferData
outputBufferHeight
outputBufferWidth
outputConfidenceBlobNames
outputDescriptionsByName
outputImage
outputMaskBlobNameToRequestKey
outputMaskBlobNames
outputMaskSize
outputNamed:error:
outputPixelFormat
outputRegionWithContentsOfCharacterRange:
overlap:
overlappingLowMergeCountSuppression:
overlappingSmallFacesSuppression:
padStringWithSpaces:toSize:
parabolaSearchBuffer
parentRequest
parseExifTimestamp:
path
pathExtension
pathForEspressoNetworkModelFileWithName:error:
pathForEspressoResource:ofType:error:
pathForEspressoResourceWithFilename:error:
pathForResource:ofType:
pathForResource:ofType:inDirectory:
pathsForResourcesOfType:inDirectory:
payloadDataValue
payloadStringValue
performBlinkDetection
performClustersPostprocessing
performClustersPostprocessing:error:
performDependentRequests:onBehalfOfRequest:inContext:error:
performInContext:error:
performInContextAsync:asyncDispatchQueue:asyncDispatchGroup:
performInPlace
performRequests:error:
performRequests:gatheredForensics:error:
performRequests:inContext:error:
performRequests:onCGImage:error:
performRequests:onCGImage:gatheredForensics:error:
performRequests:onCGImage:orientation:error:
performRequests:onCGImage:orientation:gatheredForensics:error:
performRequests:onCIImage:error:
performRequests:onCIImage:gatheredForensics:error:
performRequests:onCIImage:orientation:error:
performRequests:onCIImage:orientation:gatheredForensics:error:
performRequests:onCMSampleBuffer:error:
performRequests:onCMSampleBuffer:gatheredForensics:error:
performRequests:onCMSampleBuffer:orientation:error:
performRequests:onCMSampleBuffer:orientation:gatheredForensics:error:
performRequests:onCVPixelBuffer:error:
performRequests:onCVPixelBuffer:gatheredForensics:error:
performRequests:onCVPixelBuffer:orientation:error:
performRequests:onCVPixelBuffer:orientation:gatheredForensics:error:
performRequests:onImageData:error:
performRequests:onImageData:gatheredForensics:error:
performRequests:onImageData:orientation:error:
performRequests:onImageData:orientation:gatheredForensics:error:
performRequests:onImageURL:error:
performRequests:onImageURL:gatheredForensics:error:
performRequests:onImageURL:orientation:error:
performSceneClassification
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
performedRequest:withError:
performedRequests
performingOrderedDependentRequests:onBehalfOfRequest:
performingRequest:
personCount
personId
personPredictionsForFace:withDescriptor:limit:canceller:error:
personUniqueIdentifiers
personsModel:faceObservationAtIndex:forPersonAtIndex:
personsModel:indexOfPersonWithUniqueIdentifier:
personsModel:numberOfFaceObservationsForPersonAtIndex:
personsModel:uniqueIdentifierOfPersonAtIndex:
personsModelDataWasModified:
pitch
pitchAngle
pixelBuffer
pixelFormat
pixelHeight
pixelValueSizeInBytesForBuffer:error:
pixelWidth
pixelWidthCard
pixelsHigh
pixelsWide
plan
platform
pleasantCameraTiltScore
pleasantCompositionScore
pleasantLightingScore
pleasantPatternScore
pleasantPerspectiveScore
pleasantPostProcessingScore
pleasantReflectionsScore
pleasantSymmetryScore
pointAtIndex:
pointByApplyingVector:toPoint:
pointCount
pointKeyGroupLabelsMapping
pointValue
points
pointsClassification
pointsData
pointsInImageOfSize:
polygonApproximationWithEpsilon:error:
polygonList
populateDetectorProcessingOptions:session:
populateVCPVideoProcessorRequestConfiguration:
populatedMLMultiArrayAndReturnError:
posLL
posLR
posUL
posUR
pose
poseData
poseQuaternion
poseSquare
postNotificationName:object:userInfo:
postVisionFeaturePrintModel
postprocessLandmarkResultsForLandmarks:imageBuffer:outputFace:options:warningRecorder:error:
precisionEstimatesPerPoint
precisionRecallThreshold
predicateWithBlock:
predicateWithFormat:
predictPersonFromFaceObservation:limit:canceller:error:
predictWithCVPixelBuffer:options:error:
predictWithScenePrint:options:error:
predictedFeatureKey
predictedFeatureName
predictedProbabilitiesKey
predictedProbabilitiesName
predictionFromFeatures:options:error:
predictionsForObservation:limit:canceller:error:
preferBackgroundProcessing
preferredInputSizeWithOptions:error:
preferredMetalContext
preferredPixelFormat
preferredSmallSide
preheatModelsForOptions:revision:error:
prepareForPerformingRequests:error:
previousLeafDescriptorDistance
previousLeafId
previousLeafTimestampDistance
previousLeafTotalDistance
previousSequencedObservationsAcceptedByRequest:
previousSequencedObservationsForRequest:
primaryInferenceNetworkDescriptorForIdentifier:version:error:
primaryInferenceNetworkDescriptorForVNInferenceNetworkIdentifierFaceprint_3_1_0
primaryInferenceNetworkDescriptorForVNInferenceNetworkIdentifierSceneNetObjDetNetSliderNet_3_0_0
primaryInferenceNetworkDescriptorForVNInferenceNetworkIdentifierSceneNet_3_0_0
primaryInferenceNetworkDescriptorForVNInferenceNetworkIdentifierSceneNet_5_10_0
primaryInferenceNetworkDescriptorForVNInferenceNetworkIdentifierSmartCam_5_0_0
primaryInferenceNetworkDescriptorForVNInferenceNetworkIdentifierStandaloneSceneprint_3_0_0
printCountForEntityWithUniqueIdentifier:
printCountsForAllEntities
printCountsForEntitiesWithUniqueIdentifiers:
printDebugInfo:facesDataRaw:faceDetectorBGRAImage:tempImage:
printWithDescriptorData:elementType:elementCount:originatingRequestSpecifier:error:
printWithFloat16PrecisionFloat32Data:originatingRequestSpecifier:error:
printWithFloat16PrecisionFloat32Values:elementCount:originatingRequestSpecifier:error:
processBoxes:withHeight:andWidth:
processDetectedObject:originatingRequestSpecifier:objectBoundingBox:imageBuffer:qosClass:warningRecorder:detectedObjectResults:error:
processFaceObservations:revision:regionOfInterest:detectorType:detectorOptions:shouldAlignFaceBBox:shouldRunDetectorBlock:context:error:
processInfo
processLockedImageBuffer:inputMaskObservation:options:error:
processRecognizedObjectWithIdentifier:originatingRequestSpecifier:objectBoundingBox:objectConfidence:detectedObjectResults:
processRegionOfInterest:croppedPixelBuffer:options:qosClass:warningRecorder:error:progressHandler:
processUsingQualityOfServiceClass:options:regionOfInterest:warningRecorder:error:progressHandler:
processVImage:inputIsBGR:
processVNImageBuffer:regionOfInterest:withOptions:warningRecorder:requestUUID:error:
processingDevice
processingDeviceDetectorWithEspressoNetwork:espressoPlan:
processingDeviceDetectorWithEspressoNetwork:espressoPlan:networkThreshold:filterThresholds:
processingDeviceDetectorWithEspressoNetwork:espressoPlan:threshold:
processingDeviceDetectorWithModelPath:networkThreshold:filterThresholds:preferredDeviceID:engineID:storageType:
processingDeviceDetectorWithModelPath:preferredDeviceID:engineID:storageType:
processingDeviceNetworkWithModelPath:threshold:preferredDeviceID:engineID:storageType:
profileNormal
projectedPointsInTopLeftOrigin:orientation:
propertyListWithStream:options:format:error:
providesBoundsNormalizedToROI
providesSceneLabels
providesSegmentationLabels
pulseVectorHeightCharBox
pulseVectorHeightCharBoxAdaptive
purgeAll
purgeAllCaches
purgeCacheRepresentationsForOriginalBuffer:
purgeCachedRepresentations
purgeIntermediates
qosClass
quadForTextInCharacterRange:
quadratureTolerance
qualityCriteriaList
qualityLevel
queueLabelWithUniqueAppendix:
queueWithUniqueAppendix:
radius
raise:format:
rangeOfContentRegion:
rangeOfString:options:
rangeOfTextBlock:
rangeOfTextBlockObservation:
rank
ratios
rawColorGaborDescriptor
rawConfidence
rawImageprintDescriptor
readObjectForModelVersion:tag:fromInputStream:intoObjectDictionary:md5Context:error:
readObjectForVersion1Tag:fromInputStream:intoObjectDictionary:md5Context:error:
readOnly
reason
recognitionLanguages
recognitionLevel
recognize
recognizeDetectedBlocks:inImage:error:withProgressHandler:
recognizedAnimalHeadObjectClassToAnimalHeadCategoryName
recognizedAnimalObjectClassToAnimalName
recognizedFoodAndDrinkObjectClassToFoodAndDrinkCategoryName
recognizedLanguages
recognizedLocale
recognizedPointForJointName:error:
recognizedPointForKey:error:
recognizedPointsForGroupKey:error:
recognizedPointsForJointsGroupName:error:
recognizedPointsObservationClass
recognizedPointsSpecifier
recognizedSportBallObjectClassToSportBallCategoryName
recordDefaultConfigurationOptionsInDictionary:
recordImageCropQuickLookInfoFromOptions:toObservation:
recordImageCropQuickLookInfoFromOptionsSafe:toObservation:
recordImageCropQuickLookInfoToOptions:cacheKey:imageBuffer:
recordSequencedObservationsForRequest:
recordSequencedObservationsOfRequest:
recordWarning:value:
recordWarningsInOriginalRequests
rectangleObservationWithRequestRevision:topLeft:bottomLeft:bottomRight:topRight:
referenceImageSignature
refineLeftEyeRegion
refineMouthRegion
refineRightEyeRegion
regionLabels
regionNameAtImageCoordinate:imageSize:
regionNameAtNormalizedAlignedFaceCoordinate:
regionNameAtNormalizedFaceCoordinate:
regionOfInterest
regionOfInterestNonIntegralPixelRectForWidth:height:
regionOfInterestPixelRectForWidth:height:
registerModelEquivalencyOf:to:
registerRequestClass:revision:modelEquivalencyToRevision:
registerRequestClassName:revision:modelEquivalencyToRevision:
registerSession:
registryID
relationships
releaseAllQueues
releaseAllocations
releaseCachedResources
releaseCachedResourcesWithCompletionBlock:
releaseDetectorsThatCanBeReplacedByDetectorOfClass:withConfiguration:
releaseMetalDeviceWisdomParameters
releaseResources
removeAllFaceObservationsFromPersonWithUniqueIdentifier:error:
removeAllObjects
removeAllObservationsFromEntityWithUniqueIdentifier:error:
removeCachedBufferWithKey:
removeEntityWithUniqueIdentifier:error:
removeFaceObservations:fromPersonWithUniqueIdentifier:error:
removeIndex:
removeItemAtPath:error:
removeLastObject
removeObject:
removeObjectAtIndex:
removeObjectForKey:
removeObjectIdenticalTo:
removeObjectsAtIndexes:
removeObjectsInArray:
removeObjectsInRange:
removeObservations:fromEntityWithUniqueIdentifier:error:
removePersonWithUniqueIdentifier:error:
removeRequest:error:
render:toBitmap:rowBytes:bounds:format:colorSpace:
render:toCVPixelBuffer:
render:toCVPixelBuffer:bounds:colorSpace:
renderCIImage:width:height:format:processingDevice:error:
renderEspressoBufferImage:intoCVPixelBuffer:error:
replaceCharactersInRange:withString:
reportCharacterBoxes
representativenessById
representativenessForFaces:error:
request:cachedResultsWithObservationsCacheKey:
requestClass
requestClassAndReturnError:
requestClassCode
requestClassName
requestDetectionLevel
requestForcedCleanup
requestForcedCleanupWithOptions:
requestForcedCleanupWithOptions:completion:
requestForensics
requestFrameAnalysisSpacing
requestImageBuffers
requestImageBuffersCacheKeys
requestInfoForRequest:
requestKeyFromRequest:
requestKeyToRequestInfo
requestPropertiesFromRequestKey:
requestTasksQueue
requestThatProvidedObservationsForRequest:
requestUUID
requestsImplicitlyPerformedOnBehalfOfRequest:
requestsThatLookedUpCachedResultsKey:
requiredArrayForKey:inOptions:withElementsOfClass:error:
requiredCancellerInOptions:error:
requiredDetectedObjectObservationInOptions:withOptionName:forObservationClass:error:
requiredFaceObservationInOptions:withOptionName:error:
requiredObjectOfClass:forKey:inOptions:error:
requiredProcessingDeviceInOptions:error:
requiredTargetedImageBufferReturningError:
reset
reset:
resetAsyncStatus
resetBoxBounds
resetFileNameURLWithCurentDateTime
resetModelState:error:
resizeAndProcessVImage:inputIsBGR:
resolvedAlgorithmAndReturnError:
resolvedProcessingDevice
resolvedRevision
resolvedRevisionDidChangeFromRevision:
resolvedRevisionForRevision:
resourcePath
respondsToSelector:
resultsAreAssignedWithOriginatingRequestSpecifier
resultsForPixelBuffer:options:error:
resultsForPixelBuffer:roi:options:error:withProgressHandler:
resultsFromCoreResults:
resultsObtainedFromObservationsCacheForRequest:
retain
retainCount
returnAllResults
returnAllResultsOptionKey
returnMask
revision
revisionAvailability
revisionSupportsFullBodyDetection:
right
rightEye
rightEyebrow
rightPupil
roiAreaThreshold
roll
rotateImageToMatchNetworkOrientation
rotationAngle
rpnInitQueue
rpnTrackQueue
rpnTrackerInitModelName
rpnTrackerInitProcessingQueueName
rpnTrackerTrackModelName
rpnTrackerTrackProcessingQueueName
runNetwork:inputIsBGR:
runSuccessReportingBlockSynchronously:detector:qosClass:error:
runTimeVersion
salientObjects
salientObjectsAndReturnError:
scale
scanCharactersFromSet:intoString:
scanDouble:
scanFloat:
scanInteger:
scanString:intoString:
scanUpToCharactersFromSet:intoString:
scannerResult
scannerWithString:
sceneClassifierDescriptor
sceneLabelOperationPointsForOriginatingRequestSpecifier:error:
sceneLabelsFileName
sceneObservation
scenePrintRevision
sceneprintCurrentVersion
sceneprintVersion
sceneprints
screenGazeRawOutputInCentimeters
segmentationLabelsFileName
segmentationMask
self
sequencedRequestPreviousObservationsKey
serialNumber
serializationMagicNumber
serializeAsVNImageprintStateAndReturnError:
serializeRPNTrackingQueue
serializeStateAndReturnError:
serializeStateIntoData:startingAtByteOffset:error:
serializedLength
sessionAndReturnError:
setACBSBarcodeInfo:
setAcceptableVersions:
setAdditionalCharacters:
setAlgorithm:
setAlignedBoundingBox:
setAlignedMeanShape:
setAlignedRotationAngle:
setAlignmentTransform:
setAllLabelsWithConfidences:
setAllocationSize:
setAngle:
setArray:
setAsyncStatus:error:
setAutomaticallyDetectsLanguage:
setBBottom:
setBTop:
setBackgroundGPUPriority:
setBarcodeRequest:
setBlinkScore:
setBlurDeterminationMethod:
setBlurScore:
setBoundingBoxAligned:
setBoundingBoxFromQuadrilateralPointsAtTopLeft:topRight:bottomRight:bottomLeft:
setBounds:
setBuffer:offset:atIndex:
setBytes:length:atIndex:
setCachePath:
setCachedImageReader:
setCadence:
setCancellationSemaphore:
setCascadeStepCount:
setCharBoxContext:
setCharBoxFlags:
setCharacterBoxes:
setCharboxROIFullVectorRowStart:
setClass:forClassName:
setClusterId:
setClusterSplitDistanceType:
setClusterState:
setClusteredFaceIds:
setClusters:
setCommonGazeLocationRadius:
setComputationAccuracy:
setComputePipelineState:
setComputeZCVectorHighProbability:
setConfidence:
setConstellation:
setContext:
setContrastAdjustment:
setContrastPivot:
setCropResult:
setCustomHierarchy:
setDateFormat:
setDebugFilename:
setDebugMode:
setDebugOut:
setDecodingFailurePolicy:
setDefaultBox:
setDefaultSymbologiesForRevision:
setDelegate:
setDescriptor:
setDetectDarkOnLight:
setDetectDiacritics:
setDetectedBarcodeSupportCode:
setDetectionLevel:
setDetectionOnly:
setDetectorConfigurationOption:value:
setDetectorConfigurationOptions:
setDetectorExecutionTimeInterval:
setDetectorPreferredImageSize:
setDetectorType:
setDetectorWantsAnisotropicScaling:
setDetectsDarkOnLight:
setDistance:
setDistancesById:
setExposureScore:
setExpressionsAndScores:
setFaceAttributes:
setFaceBoundingBoxExpansionRatio:
setFaceCaptureQuality:
setFaceCoreEnhanceEyesAndMouthLocalization:
setFaceCoreExtractBlink:
setFaceCoreExtractSmile:
setFaceCoreInitialAngle:
setFaceCoreKalmanFilter:
setFaceCoreMinFaceSize:
setFaceCoreNumberOfDetectionAngles:
setFaceCoreType:
setFaceDetectionPrecisionRecallThreshold:
setFaceId:
setFaceIdConfidence:
setFaceJunkinessIndex:
setFaceOrientationIndex:
setFaceRegionMap:
setFaceScreenGaze:
setFaceSegments:
setFaceTorsoprint:
setFaceprint:
setFaceprintInputPath:
setFaceprintRequestRevision:
setFeatureProvider:
setFilterThresholds:
setFilterWalkUpDownCount:
setFlag:atIndex:
setFloatVectorSumProd:
setFloatingImageSignature:
setForceFaceprintCreation:
setForceUseInputCVPixelBufferDirectly:
setFrameAnalysisSpacing:
setFreeImageInDealloc:
setFreeNodeOnDealloc:
setGaze:
setGazeHeatMapThreshold:
setGenerateSegmentationMask:
setGreedyClustererFaces_const:
setGroupedClusteredFaceIdsForCluster:
setHasLabel:
setIdentifier:
setIi:
setImageCropAndScaleOption:
setImageFilePath:
setImageSignatureHashType:
setImageSignatureprintType:
setImageprint:
setIndexType:
setInliersRatioThreshold:
setInputContrast:
setInputDetectedObjectObservations:
setInputFaceObservations:
setInputFactor1:
setInputFactor2:
setInputFactor3:
setInputFactor4:
setInputImage:
setInputImageFeatureName:
setInputImageKey:
setInputObservation:
setInputPivot:
setInputPoint:
setInputScenePrintKey:
setInputShape:height:
setInputSignatureprint:
setInputTextBlocks:
setIoSurfaceMemoryPoolId:
setIsBlinking:
setIsTitle:
setIsValid:
setKeepNetworkOutput:
setKeepRawOutputMask:
setLabel:
setLabelKey:
setLandmark3DPointsData:originatingRequestSpecifier:
setLandmarkPoints65Data:originatingRequestSpecifier:
setLandmarkPointsData:originatingRequestSpecifier:
setLandmarkPrecisionEstimatesPerPoint:
setLandmarkScore:
setLandmarks:
setLandmarksConstellation:
setLastFrame:
setLastTrackedBBox:
setLegacyFaceCore:
setLength:
setLineWidth:
setLocale:
setLocateMode:
setLoopBigBox:
setLoopBigBoxPrev:
setMBottom:
setMRCDescriptor:
setMTop:
setMaxHeight:
setMaximumAspectRatio:
setMaximumCandidateCount:
setMaximumEntities:
setMaximumHandCount:
setMaximumHierarchicalObservations:
setMaximumIdentities:
setMaximumImageDimension:
setMaximumIntermediateSideLength:
setMaximumLeafObservations:
setMaximumObjectSize:
setMaximumObservations:
setMaximumProcessingDimensionOnTheLongSide:
setMaximumTasksCount:
setMaximumTrainingFaceprintsPerIdentity:
setMaximumTrainingPrintsPerEntity:
setMedianHeightBottom:
setMedianHeightTop:
setMemoryPoolId:
setMetalContextPriority:
setMidRow:
setMinHeight:
setMinimizeFalseDetections:
setMinimumAspectRatio:
setMinimumCharacterHeight:
setMinimumConfidence:
setMinimumFaceDimension:
setMinimumObjectSize:
setMinimumTextHeight:
setMmHeightCard:
setModel:
setModelCachingIdentifier:
setModelFileBackingStore:
setModelMinimumDetectionConfidence:
setModelNonMaximumSuppressionThreshold:
setModelType:
setMrcDescriptor:
setNaturalClusteringDistanceThreshold:
setNextLeafDescriptorDistance:
setNextLeafId:
setNextLeafTimestampDistance:
setNextLeafTotalDistance:
setNlreg_padding:
setNlreg_radius:
setNlreg_sigma_c:
setNlreg_sigma_l:
setNlreg_sigma_w:
setNmsThreshold:
setNode:
setObject:atIndexedSubscript:
setObject:forKey:
setObject:forKeyedSubscript:
setObjectMaximumNormalizedRadius:
setObjectMinimumNormalizedRadius:
setObjectType:
setObjects:
setObservations:forKey:
setOlmcsMergeCountDelta:
setOlmcsThreshold:
setOrderedRequests:
setOriginalObservation:
setOriginalRequestConfigurations:
setOsfsSizeRatio:
setOsfsThreshold:
setOutputFormat:
setOutputObjectTypes:
setOutputPixelFormat:
setOutputUV:error:
setPerformBlinkDetection:
setPerformClustersPostprocessing:
setPerformInPlace:
setPerformSceneClassification:
setPersonId:
setPitch:
setPitchAngle:
setPixelHeightCard:
setPixelWidthCard:
setPlatform:
setPoints:
setPosLL:
setPosLR:
setPosUL:
setPosUR:
setPoseData:originatingRequestSpecifier:
setPrecisionEstimatesPerPoint:
setPrecisionRecallThreshold:
setPredictedFeatureKey:
setPreferBackgroundProcessing:
setPreferredMetalContext:
setPreviousLeafDescriptorDistance:
setPreviousLeafId:
setPreviousLeafTimestampDistance:
setPreviousLeafTotalDistance:
setProcessedResults:
setProcessingDevice:
setProfile:
setProfileNormal:
setProgressHandler:
setPulseVectorHeightCharBox:
setPulseVectorHeightCharBoxAdaptive:
setQuadratureTolerance:
setQualityCriteriaList:
setQualityLevel:
setReadOnly:
setRecognitionLanguage:
setRecognitionLanguages:
setRecognitionLevel:
setRecognize:
setReferenceImageSignature:
setRefineLeftEyeRegion:
setRefineMouthRegion:
setRefineRightEyeRegion:
setRegionLabels:
setRegionOfInterest:
setReportCharacterBoxes:
setRepresentativenessById:
setRequestImageBuffers:
setRequestImageBuffersCacheKeys:
setRequestRevision:
setRequiredVersion:
setRequiresSecureCoding:
setResolvedRevision:
setResourcePath:
setResults:
setResults:assignedWithOriginatingSpecifier:
setReturnAllResults:
setReturnMask:
setReturnSubFeatures:
setRevision:
setRevision:error:
setRoiAreaThreshold:
setRoll:
setRotationAngle:
setScale:
setScanLocation:
setScannerResult:
setSceneObservation:
setShortDescription:
setShouldUpdateRepresentative:
setSignatureData:
setSmartCamprints:
setSmartDistanceFactor:
setSmartThreshold:
setStartMaxFind:
setStartSensitized:
setState:
setStopAtFirstPyramidWith2DCode:
setStopNormal:
setStopSensitized:
setStroke
setSuggestedIdsForRepresentative:
setSuggestionsForCluster:
setSynchronizationQueue:
setTargetFrameTime:
setTargetImageSignature:
setTasksTimeout:
setText:
setTextRecognition:
setTexture:atIndex:
setThreshold:
setTimeRange:
setTimeStamp:
setTimerMode:
setTorsoThreshold:
setTorsoprint:
setTorsoprintRequestRevision:
setTotalObjectCount:
setTrackedFrameCVPixelBufferFormat:
setTrackedFrameNumber:
setTrackedObjects:inFrame:error:
setTrackingFrameSizeInPixels:
setTrackingLevel:
setTrajectoryLength:
setTransform:
setType:
setUUID:
setUnalignedBoundingBox:
setUpperBodyOnly:
setUsage:
setUseCenterTileOnly:
setUseImageAnalyzerScaling:
setUseMLDetector:
setUseNonLocalRegularization:
setUseSegmentationPregating:
setUseTiling:
setUseTimestampAdjustedDistances:
setUsesAlternateLineGrouping:
setUsesLanguageCorrection:
setUsesLanguageDetection:
setVN5ui9WkMeVvCBruHiQE1q2r6E9kO1AyrP:
setValue:
setValue:forKey:
setValue:forKeyPath:
setVersion:
setWarnings:
setWarpTransform:
setWithArray:
setWithCapacity:
setWithObject:
setYawAngle:
set_priority:low_priority_max_ms_per_command_buffer:gpu_priority:
setobjectMaximumNormalizedRadius:
setsTimeRangeOnResults
setupInputImageFromModelDescription:
shape
shapeForBlobDimensions:
sharedCIContextWithOptions:
sharedCache
sharedInstance
sharplyFocusedSubjectScore
shortDescription
shortValue
shotflowDetector
shotflowNetworkClass
shouldAlignFacesForRequestWithSpecifier:
shouldAssumeOriginatingRequestClassForHeaderSerializationVersion:
shouldBeReplacedByDetectorOfClass:withConfiguration:
shouldBeWrappedWithNextLine
shouldDumpDebugIntermediates
shouldIgnoreLagecyLabelsAndConfidenceForHeaderSerializationVersion:
shouldReprocessDocument
shouldUpdateRepresentative
shouldWrapToNextLine
signPostAdditionalParameter
signalCancellation
signature
significantRegionsFromFloat32ImageBuffer:threshold:
significantRegionsFromFloat32ImageBuffer:threshold:relativeToMaximum:
significantRegionsFromFloat32PixelBuffer:threshold:relativeToMaximum:error:
size
sizeConstraint
sizes
smallestImageSizeForTextWithRelativeHeight:originalImageSize:
smartCamprintCurrentVersion
smartCamprintVersion
smartCamprints
smartDistance
smartDistanceFactor
smartMergeBoxes:
smartThreshold
smoothedFloat32ImageBuffer:fromImageBuffer:originalImageSize:sigmaX:sigmaY:nStd:
sortDescriptorWithKey:ascending:
sortImageDescriptorsChronologically:
sortUsingComparator:
sortUsingSelector:
sortWithOptions:usingComparator:
sortedArrayUsingComparator:
sortedArrayUsingDescriptors:
sortedArrayUsingSelector:
sortedArrayWithOptions:usingComparator:
specifier
specifierForRequest:
specifierForRequestClass:revision:error:
specifierForRequestClassCode:revision:error:
specifierForRequestClassName:revision:error:
specifiesAnyRequestClass:
specifiesAnyRequestClassName:
specifiesRequestClass:
specifiesRequestClass:withAnyRevision:
specifiesRequestClassName:
specifiesRequestClassName:revision:
specifiesRequestClassName:withAnyRevision:
splitDetectedClassResultsIntoSubclasses:
squaredLength
standardUserDefaults
startMaxFind
startNormal
state
stopAtFirstPyramidWith2DCode
stopMaxFind
stopNormal
stopSensitized
storageByteCount
streamError
string
stringByAppendingFormat:
stringByAppendingString:
stringByDeletingLastPathComponent
stringByDeletingPathExtension
stringRepresentation
stringValue
stringWithCString:encoding:
stringWithCapacity:
stringWithFormat:
stringWithString:
stringWithUTF8String:
stroke
strongToStrongObjectsMapTable
subFeatures
subarrayWithRange:
subclassesOfClass:excludingRootClass:passingTest:
subdataWithRange:
substringFromIndex:
substringWithRange:
suggestedIdsForRepresentative
suggestionsForCluster
suggestionsForClusterIdsWithFlags:affinityThreshold:error:
suggestionsForClustersWithFaceIds:affinityThreshold:canceller:error:
superclass
supportedAdjustmentKeysAndReturnError:
supportedAdjustmentKeysForConfiguration:error:
supportedClassificationIdentifiersAcceptedByBlock:error:
supportedClassificationIdentifiersWithOptions:error:
supportedDocumentElementIdentifiers
supportedIdentifiersAndReturnError:
supportedIdentifiersWithOptions:error:
supportedImageSizeSet
supportedImageSizeSetForEspressoModelWithName:inputImageBlobName:analysisPixelFormatType:error:
supportedImageSizeSetForOptions:error:
supportedJointNamesForRevision:error:
supportedJointsGroupNamesForRevision:error:
supportedLabelKeys
supportedLanguagesForOptions:revision:error:
supportedLanguagesForProcessOptions:error:
supportedPrivateRevisions
supportedReadVersions
supportedRecognitionLanguagesAndReturnError:
supportedRecognitionLanguagesForTextRecognitionLevel:revision:error:
supportedRequestSpecifiers
supportedRevisions
supportedSymbologies
supportedSymbologiesAndReturnError:
supportedSymbologiesRev1
supportedSymbologiesRev2
supportedWriteVersions
supportsAnyRevision:
supportsExecution
supportsPrivateRevision:
supportsProcessingDevice:
supportsRevision:
supportsSecureCoding
supportsTiling
symbologies
symbology
synchronizationQueue
targetImageSignature
targetedImageBuffer
targetsANE
targetsCPU
targetsGPU
tasksTimeout
tastefullyBlurredScore
temporalSmoothingFrameCount
tensorForKey:error:
tensorShapesForBlobNames:ofNetworkModelFileWithPath:error:
text
textBlockOfTypes:containingTextAtIndex:
textBlockWithCharacterRange:
textBoxesForBuffer:error:
textBoxesForImage:originatingRequestSpecifier:error:
textElements
textObjects
texture2DDescriptorWithPixelFormat:width:height:mipmapped:
theta
threadExecutionWidth
threshold
tightenBox:startTop:startBottom:startPosition:stopPosition:imageHeight:halfWalk:
timeInterval
timeIntervalSince1970
timeRange
timeStamp
timerMode
timingInfo
title
topCandidates:
topLevelContourCount
topLevelContours
topLevelIndex
topRight
torsoThreshold
torsoprint
torsoprintDescriptorSize
torsoprintForImageBuffer:requestRevision:error:
torsoprintInputImageSizeForFaceOrientation:
torsoprintRequestRevision
torsoprintRequestRevisionForFaceTorsoRequestRevision:error:
totalObjectCount
trackDuration
trackInFrame:error:
trackedCorners
trackedFrameNumber
trackerObservationClass
trackerResourcesAccessingLock
trackerResourcesConfiguredWithOptions:error:
trackerResourcesConfiguredWithOptions:forSession:error:
trackerTypeForRequestRevision:error:
trackerWithOptions:error:
trackingFrameSizeInPixels
trackingLevel
trainedModelBuiltFromConfiguration:dataProvider:canceller:error:
trainedModelClass
trainedModelEntityCount
trainedModelIndexOfEntityWithUniqueIdentifier:
trainedModelNumberOfObservationsForEntityAtIndex:
trainedModelObservationAtIndex:forEntityAtIndex:
trainedModelUniqueIdentifierOfEntityAtIndex:
trainedModelWithCanceller:error:
trainingEntityPrintsForEntityWithUniqueIdentifier:error:
trainingFaceObservationsForPersonWithUniqueIdentifier:canceller:error:
trainingFaceprintsForPersonWithUniqueIdentifier:canceller:error:
trainingFaceprintsForPersonWithUniqueIdentifier:error:
trainingObservationsForEntityWithUniqueIdentifier:canceller:error:
trainingPrintsForEntityWithUniqueIdentifier:canceller:error:
trajectoryLength
transcript
transform
transformForImageWidth:height:
transformedWith:
translateAndNormalizeLandmarkPointsWrtLLCofAlignedFaceBBox:imageBuffer:outputFace:error:
tryToPerformBlock:usingSignallingBlock:
type
unalignedBoundingBox
unarchivedObjectOfClass:fromData:error:
unarchivedObjectOfClasses:fromData:error:
unionSet:
uniqueIdentifierForEntityAtIndex:
uniqueIdentifierOfEntityAtIndex:
unitVectorForVector:
unlock
unsignedCharValue
unsignedIntValue
unsignedIntegerValue
unsignedLongLongValue
unsignedLongValue
unspecifiedOperationPoints
upToDateFaceModelWithCanceller:error:
updateExtrema:x:y:
updateInternalConfigurationWithModelFaceprintRequestRevision:error:
updateModelByAddingFaces:andRemovingFaces:canceller:error:
updateModelByAddingFaces:canceller:error:
updateModelByAddingFaces:withGroupingIdentifiers:andRemovingFaces:canceller:error:
updateModelByAddingFaces:withGroupingIdentifiers:canceller:error:
updateModelByAddingPersons:withGroupingIdentifiers:andRemovingPersons:canceller:error:
updateModelByRemovingFaces:canceller:error:
updateRuntimeParametersFromOptions:error:
updateWithOptions:error:
updateWithPropertiesOfModel:
upperBodyOnly
uppercaseLetterCharacterSet
useCenterTileOnly
useFOpenForModelWithPath:
useGPU
useImageAnalyzerScaling
useMLDetector
useNonLocalRegularization
useSegmentationPregating
useTiling
useTimestampAdjustedDistances
userFacingBBox
usesAlternateLineGrouping
usesCPUOnly
usesLanguageCorrection
usesLanguageDetection
uuid
vNpLorzxnyAlLcPFNcKhgoNCmy9b5BRWyk
valid
validFaceprint
validateAceptableObservation:forEntityPrintOriginatingRequestSpecifier:error:
validateArray:named:hasElementsOfClass:requiredMinimumCount:allowedMaximumCount:error:
validateAsyncStatusResult:error:
validateAsyncStatusResults:error:
validateClassArray:named:hasElementsAncestoredFromClass:requiredMinimumCount:allowedMaximumCount:error:
validateConfiguration:error:
validateConfigurationAndReturnError:
validateDescriptorData:elementType:elementCount:error:
validateImageBuffer:error:
validateImageBuffer:ofNonZeroWidth:andHeight:error:
validateNonZeroImageWidth:height:componentNameProvidingBlock:error:
validateOptionalDetectedObjectObservations:forObservationClass:error:
validateOptionalDetectedObjectObservations:forObservationClass:forRequest:error:
validateOptionalFaceObservations:error:
validateOptionalFaceObservations:forRequest:error:
validateRequiredClusterIDs:error:
validateRequiredDetectedObjectObservations:forObservationClass:error:
validateRequiredDetectedObjectObservations:forObservationClass:forRequest:error:
validateRequiredFaceObservations:error:
validateRequiredFaceObservations:forRequest:error:
validateScoreRange:error:
validateVNConfidenceRange:error:
validateWithCanceller:error:
validatedImageBufferFromOptions:error:
validatedProcessingDeviceInOptions:error:
value
value:withObjCType:
valueForKey:
valueForWarning:
valueWithBytes:objCType:
vcpPoseRequestRuntimeOptionsForDetectorOptions:error:
vcpPoseRequestSetupOptionsForDetectorOptions:error:
vectorByAddingVector:toVector:
vectorByMultiplyingVector:byScalar:
vectorBySubtractingVector:fromVector:
vectorWithCGRect:
vectorWithX:Y:Z:W:
versionNumbersEncodedInClass:withMethodNamePrefix:suffix:
versionOfNetworkHead:error:
visionFeaturePrintInfo
vn1uMyFtnYEWjbrdx3yAuDndKkPeyzNJhB
vn2riiZbQrloRhCzYW56f0rk4N3ROe151S
vn3iT1YRjjnIuELobV1olJiO1vvItN6Kdq
vn4UfLbvVUqMvYV8bbGFQcxg5yRLm8ekI1
vn7CbCeAogPS2iHE6VQwu6H96xanljtMqk
vn7exwFFmQF0AI9P7FjBljwEFu7QYUGCYE
vn7fiLHgGnvqPqG63cfDUCK4Xm8obUuWoP
vn_cloneObject
vn_decode3x3MatrixForKey:
vn_decode4x4MatrixForKey:
vn_decodeCGAffineTransformForKey:
vn_decodeCodingVersionForKey:
vn_decodeEntityUniqueIdentifierArrayForKey:
vn_decodeEntityUniqueIdentifierForKey:
vn_decodePersonUniqueIdentifierForKey:
vn_decodePixelBufferForKey:
vn_decodePointForKey:
vn_decodeRectForKey:
vn_decodeSimdFloat3ForKey:
vn_decodeSizeForKey:
vn_decodeTimeRangeForKey:
vn_decodeValidatedConfidenceForKey:
vn_decodeValidatedScoreForKey:
vn_encode3x3Matrix:forKey:
vn_encode4x4Matrix:forKey:
vn_encodeCGAffineTransform:forKey:
vn_encodeCodingVersion:forKey:
vn_encodeEntityUniqueIdentifier:forKey:
vn_encodeEntityUniqueIdentifierArray:forKey:
vn_encodePersonUniqueIdentifier:forKey:
vn_encodePixelBuffer:forKey:
vn_encodePoint:forKey:
vn_encodeRect:forKey:
vn_encodeSimdFloat3:forKey:
vn_encodeSize:forKey:
vn_encodeTimeRange:forKey:
vn_encodeValidatedConfidence:forKey:
vn_enumerateObjectsAsSubarraysOfCount:usingBlock:
waitUntilCompleted
wantsSequencedRequestObservationsRecording
warmUpApplicableDetectorInSession:error:
warmUpSession:error:
warmUpSession:withOptions:error:
warnings
warpTransform
wasSignalled
weakObjectsHashTable
weakObjectsPointerArray
wellChosenBackgroundScore
wellFramedSubjectScore
wellTimedShotScore
whiteImage
width
willAcceptCachedResultsFromRequestWithConfiguration:
willTrainEntityIdentificationModel:withCanceller:
wipe_layers_blobs
wisdomParameterForMTLDevice:error:
wisdomParameterForMTLDeviceWithName:error:
write:maxLength:
writeData:
writeReadOnlyVersion1ToOutputStream:options:md5Context:error:
writeToFile:atomically:
writeToFile:atomically:encoding:error:
writeToStream:options:error:
writeToURL:options:error:
writeVersion1ToOutputStream:options:md5Context:error:
yawAngle
zeroCircle
zeroPoint
zeroVector
zone
B16@0:8
@32@0:8@16@24
Q16@0:8
B24@0:8@16
@16@0:8
@24@0:8^@16
v24@0:8@16
@24@0:8@16
v16@0:8
@"NSArray"
@96@0:8@16^{__CVBuffer=}24@32@40{CGRect={CGPoint=dd}{CGSize=dd}}48@80^@88
I24@0:8@16
Q24@0:8@16
@72@0:8^{__CVBuffer=}16@24{CGRect={CGPoint=dd}{CGSize=dd}}32^@64
^{__CVBuffer=}56@0:8Q16Q24@32@40^@48
B40@0:8@16@24^@32
B88@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48@56^^{__CVBuffer}64^@72@?80
@92@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16r^{__CVBuffer=}48@56I64@68^@76@?84
@24@0:8Q16
#16@0:8
B32@0:8@16^@24
@32@0:8Q16^@24
B40@0:8Q16@24^@32
r^{?=Q{?=ii}{?=ii}{?=ii}}16@0:8
q16@0:8
#32@0:8@16^@24
{basic_string_view<char, std::char_traits<char>>=*Q}24@0:8@16
{shared_ptr<vision::mod::FaceQualityPredictor>="__ptr_"^{FaceQualityPredictor}"__cntrl_"^{__shared_weak_count}}
@24@0:8#16
@24@0:8^{_NSZone=}16
v24@0:8q16
r^{?=Q#Q}16@0:8
Q32@0:8#16Q24
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
@"NSArray"16@0:8
v24@0:8@"NSArray"16
@24@0:8@?16
@"VNScreenGazeState"
@32@0:8q16@24
B100@0:8@16@24{CGRect={CGPoint=dd}{CGSize=dd}}32@64I72@76@84^@92
v32@0:8@16@24
@32@0:8@16q24
@36@0:8@16B24@28
@28@0:8@16B24
v32@0:8r^v16@24
v24@0:8r^v16
@"NSURL"
@"NSString"
v32@0:8@16^v24
v40@0:8@16@24^v32
@32@0:8@16^@24
@40@0:8@16@24^@32
@36@0:8@16f24^@28
@"NSArray"36@0:8@"NSDictionary"16f24^@28
@"NSData"24@0:8^@16
@"NSSet"24@0:8^@16
@"NSArray"32@0:8@"NSNumber"16^@24
@"NSNumber"40@0:8@"NSNumber"16@"NSNumber"24^@32
@"NSDictionary"32@0:8@"NSArray"16^@24
@"NSArray"24@0:8^@16
@"NSArray"40@0:8@"NSArray"16@"NSDictionary"24^@32
@"NSDictionary"40@0:8@"NSArray"16@"NSArray"24^@32
@"NSNumber"24@0:8^@16
@"NSArray"40@0:8@"NSData"16@"NSString"24^@32
@"NSUUID"16@0:8
B24@0:8^@16
v32@0:8{shared_ptr<const vision::mod::FaceClustering>=^{FaceClustering}^{__shared_weak_count}}16
@24@0:8^v16
@"VNClusteringLogger"
@"VNSuggestionsLogger"
@"NSData"
{shared_ptr<const vision::mod::FaceClustering>="__ptr_"^{FaceClustering}"__cntrl_"^{__shared_weak_count}}
@"NSArray"32@0:8@"NSDictionary"16^@24
q40@0:8^v16^v24Q32
{shared_ptr<vision::mod::FaceClustering>="__ptr_"^{FaceClustering}"__cntrl_"^{__shared_weak_count}}
f24@0:8@16
v24@0:8^v16
{unordered_map<NSString *, espresso_buffer_t, std::hash<NSString *>, std::equal_to<NSString *>, std::allocator<std::pair<NSString *const, espresso_buffer_t>>>="__table_"{__hash_table<std::__hash_value_type<NSString *, espresso_buffer_t>, std::__unordered_map_hasher<NSString *, std::__hash_value_type<NSString *, espresso_buffer_t>, std::hash<NSString *>, std::equal_to<NSString *>, true>, std::__unordered_map_equal<NSString *, std::__hash_value_type<NSString *, espresso_buffer_t>, std::equal_to<NSString *>, std::hash<NSString *>, true>, std::allocator<std::__hash_value_type<NSString *, espresso_buffer_t>>>="__bucket_list_"{unique_ptr<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, espresso_buffer_t>, void *> *> *[], std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, espresso_buffer_t>, void *> *> *>>>="__ptr_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, espresso_buffer_t>, void *> *> **, std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, espresso_buffer_t>, void *> *> *>>>="__value_"^^v"__value_"{__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, espresso_buffer_t>, void *> *> *>>="__data_"{__compressed_pair<unsigned long, std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, espresso_buffer_t>, void *> *> *>>="__value_"Q}}}}"__p1_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, espresso_buffer_t>, void *> *>, std::allocator<std::__hash_node<std::__hash_value_type<NSString *, espresso_buffer_t>, void *>>>="__value_"{__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, espresso_buffer_t>, void *> *>="__next_"^v}}"__p2_"{__compressed_pair<unsigned long, std::__unordered_map_hasher<NSString *, std::__hash_value_type<NSString *, espresso_buffer_t>, std::hash<NSString *>, std::equal_to<NSString *>, true>>="__value_"Q}"__p3_"{__compressed_pair<float, std::__unordered_map_equal<NSString *, std::__hash_value_type<NSString *, espresso_buffer_t>, std::equal_to<NSString *>, std::hash<NSString *>, true>>="__value_"f}}}
r^v24@0:8@16
@84@0:8I16@20{CGRect={CGPoint=dd}{CGSize=dd}}28@60^@68@?76
v40@0:8^v16@24@32
B56@0:8{shared_ptr<vision::mod::ImageDescriptorBufferAbstract>=^{ImageDescriptorBufferAbstract}^{__shared_weak_count}}16@32@40^@48
B32@0:8{shared_ptr<vision::mod::ImageDescriptorBufferAbstract>=^{ImageDescriptorBufferAbstract}^{__shared_weak_count}}16
B48@0:8^v16@24@32^@40
{shared_ptr<vision::mod::FaceprintAndAttributes>="__ptr_"^{FaceprintAndAttributes}"__cntrl_"^{__shared_weak_count}}
B56@0:8@16@24@32Q40^@48
@64@0:8@16@24@32B40f44Q48^@56
@72@0:8@16@24@32B40f44Q48Q56^@64
@68@0:8@16@24@32B40f44f48Q52^@60
@76@0:8@16@24@32B40f44f48Q52Q60^@68
@40@0:8#16@24^@32
@"NSNumber"
@44@0:8@16f24@28^@36
@"NSArray"32@0:8@"NSArray"16^@24
@"NSArray"44@0:8@"NSDictionary"16f24@"VNCanceller"28^@36
@"NSNumber"40@0:8@"VNFaceprint"16@"VNFaceprint"24^@32
@"NSNumber"40@0:8@"VNFaceObservation"16@"VNFaceObservation"24^@32
@60@0:8@16@24@32f40Q44^@52
@68@0:8@16@24@32f40Q44Q52^@60
@64@0:8@16@24@32f40f44Q48^@56
@72@0:8@16@24@32f40f44Q48Q56^@64
@"<VNClusteringReadOnly><VNClusteringCancelling>"
@48@0:8@16@24@32^@40
@56@0:8@16@24@32@40^@48
B32@0:8@"NSData"16^@24
@"NSArray"48@0:8@"NSArray"16@"NSArray"24@"VNCanceller"32^@40
@"NSArray"56@0:8@"NSArray"16@"NSArray"24@"NSArray"32@"VNCanceller"40^@48
@"NSArray"40@0:8@"NSArray"16@"VNCanceller"24^@32
@"<VNClusteringReadOnly><VNClusteringWritable><VNClusteringCancelling>"
#28@0:8I16^@20
@28@0:8I16^@20
B40@0:8^I16#24^@32
B40@0:8^I16@24^@32
B28@0:8I16Q20
v20@0:8f16
v56@0:8@16{?=qiIq}24@48
v56@0:8@"NSArray"16{?=qiIq}24@"NSDictionary"48
@"NSObject<OS_dispatch_semaphore>"
{os_unfair_lock_s="_os_unfair_lock_opaque"I}
{vector<std::tuple<simd_float3x3, float>, std::allocator<std::tuple<simd_float3x3, float>>>="__begin_"^v"__end_"^v"__end_cap_"{__compressed_pair<std::tuple<simd_float3x3, float> *, std::allocator<std::tuple<simd_float3x3, float>>>="__value_"^v}}
v24@0:8Q16
@"VN6Ac6Cyl5O5oK19HboyMBR"
@32@0:8Q16@24
@32@0:8Q16Q24
@40@0:8Q16Q24@?32
{CGSize=dd}16@0:8
B32@0:8^v16^@24
@52@0:8^v16@24@32I40^@44
@32@0:8@?16^@24
@60@0:8^v16@?24@32@40I48^@52
{shared_ptr<vision::mod::ImageAnalyzer>="__ptr_"^{ImageAnalyzer}"__cntrl_"^{__shared_weak_count}}
{_Geometry2D_size2D_="height"f"width"f}
@"VNRequest"
@"NSError"
@"<NSObject><NSCopying>"
@"NSMutableArray"
@"NSMapTable"
{shared_ptr<vision::mod::TapToBox>="__ptr_"^{TapToBox}"__cntrl_"^{__shared_weak_count}}
@40@0:8q16@24@32
@20@0:8I16
@32@0:8#16Q24
@40@0:8@16@24@32
@32@0:8Q16#24
@28@0:8i16@20
@40@0:8{?=ii*}16@32
@32@0:8^v16@24
v28@0:8B16@20
{shared_ptr<vision::mod::ObjectDetector_DCNFaceDetector_v2>="__ptr_"^{ObjectDetector_DCNFaceDetector_v2}"__cntrl_"^{__shared_weak_count}}
@"VNFaceBBoxAligner"
@40@0:8@16Q24^@32
@"CRImageReader"
@"FaceCoreDetector"
@"NSDictionary"
@"VNSceneObservation"
@"VNClassificationCustomHierarchy"
@32@0:8@16@?24
@40@0:8^I16Q24^@32
@40@0:8#16Q24^@32
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
#24@0:8^@16
@44@0:8#16@24I32Q36
I16@0:8
B32@0:8#16Q24
B32@0:8@16Q24
v40@0:8#16Q24Q32
v40@0:8@16Q24Q32
@32@0:8^{__CVBuffer=}16^@24
^v16@0:8
B76@0:8^f16^{__CVBuffer=}24{CGRect={CGPoint=dd}{CGSize=dd}}32f64^@68
B44@0:8^f16^{__CVBuffer=}24f32^@36
B76@0:8^f16@24f32{CGRect={CGPoint=dd}{CGSize=dd}}36^@68
B40@0:8^f16^{__CVBuffer=}24^@32
B48@0:8^f16^{__CVBuffer=}24i32f36^@40
I24@0:8Q16
v20@0:8B16
@"VNDetectedObjectObservation"
f16@0:8
{?=qiIq}16@0:8
v40@0:8{?=qiIq}16
{?="value"q"timescale"i"flags"I"epoch"q}
@56@0:8{?=qiIq}16q40@?48
@"VNTrajectoryProcessor"
@"VNTrajectoryRequestState"
@32@0:8@16Q24
#40@0:8@16@24^@32
@44@0:8@16@24I32^@36
v44@0:8@?16@24I32^@36
@"<NSObject><NSCopying>"24@0:8@"NSDictionary"16
B32@0:8#16@24
B40@0:8^@16@24^@32
v40@0:8@16@24@32
@"VNMetalContext"
@"VNControlledCapacityTasksQueue"
v28@0:8I16@20
v72@0:8{CGAffineTransform=dddddd}16@64
{CGAffineTransform=dddddd}24@0:8@16
v72@0:8{?=[3]}16@64
{?=[3]}24@0:8@16
v88@0:8{?=[4]}16@80
{?=[4]}24@0:8@16
v40@0:816@32
24@0:8@16
v72@0:8{?={?=qiIq}{?=qiIq}}16@64
{?={?=qiIq}{?=qiIq}}24@0:8@16
v40@0:8{CGPoint=dd}16@32
{CGPoint=dd}24@0:8@16
v40@0:8{CGSize=dd}16@32
{CGSize=dd}24@0:8@16
v56@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48
{CGRect={CGPoint=dd}{CGSize=dd}}24@0:8@16
v32@0:8^{__CVBuffer=}16@24
^{__CVBuffer=}24@0:8@16
v28@0:8f16@20
@"NSMutableDictionary"
@"VNImageAnalyzerCompoundRequestGroupingConfiguration"
@92@0:8Q16^{vImage_Buffer=^vQQQ}24B32{CGRect={CGPoint=dd}{CGSize=dd}}36{_Geometry2D_rect2D_={_Geometry2D_point2D_=ff}{_Geometry2D_size2D_=ff}}68@84
@32@0:8{CGPoint=dd}16
@48@0:8{CGPoint=dd}16{CGSize=dd}32
{vImage_Buffer="data"^v"height"Q"width"Q"rowBytes"Q}
{CGRect="origin"{CGPoint="x"d"y"d}"size"{CGSize="width"d"height"d}}
{_Geometry2D_rect2D_="origin"{_Geometry2D_point2D_="x"f"y"f}"size"{_Geometry2D_size2D_="height"f"width"f}}
@28@0:8@16f24
@76@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24f56@60@68
@"VNAnimalprint"
i16@0:8
B20@0:8i16
B32@0:8@16:24
B32@0:8#16:24
v36@0:8#16B24@?28
@36@0:8#16B24@?28
@36@0:8#16B24:28
Q32@0:8@16@24
Q32@0:8@16Q24
@40@0:8@16Q24Q32
Q24@0:8@"VNEntityIdentificationModel"16
@"<NSObject><NSCopying><NSSecureCoding>"32@0:8@"VNEntityIdentificationModel"16Q24
Q32@0:8@"VNEntityIdentificationModel"16@"<NSObject><NSCopying><NSSecureCoding>"24
Q32@0:8@"VNEntityIdentificationModel"16Q24
@"VNObservation<VNEntityIdentificationModelObservation>"40@0:8@"VNEntityIdentificationModel"16Q24Q32
@"NSDate"24@0:8@"VNEntityIdentificationModel"16
Q24@0:8Q16
@"<NSObject><NSCopying><NSSecureCoding>"24@0:8Q16
Q24@0:8@"<NSObject><NSCopying><NSSecureCoding>"16
@"VNObservation<VNEntityIdentificationModelObservation>"32@0:8Q16Q24
@"<VNEntityIdentificationModelTrainingDataDelegate>"
@"VNRequestSpecifier"
@"NSMutableIndexSet"
@"NSDate"
@64@0:8@16@24@32@40@48@56
@"VNTensorDescriptor"
B32@0:8@?16@?24
r^{_LandmarkDetector_faceMeshParts_=ii[23i]i[23i]i[23i]i[23i]i[23i]i[23i]i[23i]i[23i]i[23i]i[23i]i[23i]i[23i]i[23i]i[23i]i[23i]i[23i]i[23i]}24@0:8Q16
r^v24@0:8Q16
{_Geometry2D_point2D_=ff}36@0:8r^{_Geometry2D_point2D_=ff}16r^i24i32
@48@0:8r^{vImage_Buffer=^vQQQ}16r^{_Geometry2D_rect2D_={_Geometry2D_point2D_=ff}{_Geometry2D_size2D_=ff}}24r^v32^@40
B64@0:8r^v16@24@32@40@48^@56
B64@0:8r^{vImage_Buffer=^vQQQ}16@24^{_Geometry2D_rect2D_={_Geometry2D_point2D_=ff}{_Geometry2D_size2D_=ff}}32r^v40@48^@56
{shared_ptr<vision::mod::LandmarkAttributes>="__ptr_"^{LandmarkAttributes}"__cntrl_"^{__shared_weak_count}}
@40@0:8@16@24Q32
B36@0:8^@16B24^@28
v32@0:8Q16@?24
@"CIContext"
@"<MTLDevice>"
@"NSLock"
@"NSHashTable"
^{CGImageSource=}40@0:8^^{CGImageSource}16I24^{os_unfair_lock_s=I}28B36
^{CGImageSource=}32@0:8I16B20^@24
^{CGImageSource=}
@68@0:8I16Q20Q28{CGRect={CGPoint=dd}{CGSize=dd}}36
@36@0:8I16Q20Q28
v24@0:8^{__CVBuffer=}16
^{__CFDictionary=}
r^{__CFDictionary=}16@0:8
i24@0:8@16
{CGRect={CGPoint=dd}{CGSize=dd}}80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGSize=dd}48^d64^d72
^{CGColorSpace=}28@0:8I16^I20
@"<NSObject><NSCopying>"16@0:8
@32@0:8^{__CVBuffer=}16@24
@36@0:8^{__CVBuffer=}16I24@28
@32@0:8^{CGImage=}16@24
@36@0:8^{CGImage=}16I24@28
@36@0:8@16I24@28
@32@0:8^{opaqueCMSampleBuffer=}16@24
@36@0:8^{opaqueCMSampleBuffer=}16I24@28
^{__CVBuffer=}16@0:8
^{CGImage=}16@0:8
^{__CVBuffer=}52@0:8Q16Q24I32@36^@44
^{__CVBuffer=}60@0:8Q16Q24I32@36^@44^@52
^{__CVBuffer=}84@0:8Q16Q24I32{CGRect={CGPoint=dd}{CGSize=dd}}36@68^@76
^{__CVBuffer=}92@0:8Q16Q24I32{CGRect={CGPoint=dd}{CGSize=dd}}36@68^@76^@84
^{__CVBuffer=}116@0:8Q16Q24{CGRect={CGPoint=dd}{CGSize=dd}}32I64Q68@76^@84^{CGPoint=dd}92^d100^d108
^{__CVBuffer=}124@0:8Q16Q24{CGRect={CGPoint=dd}{CGSize=dd}}32I64Q68@76^@84^{CGPoint=dd}92^d100^d108^@116
{?={?=qiIq}{?=qiIq}{?=qiIq}}16@0:8
B24@0:8^f16
B24@0:8^{CGPoint=dd}16
B24@0:8^{?=[3]}16
{CGRect={CGPoint=dd}{CGSize=dd}}48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
^{__CVBuffer=}44@0:8Q16I24@28^@36
^{__CVBuffer=}76@0:8Q16{CGRect={CGPoint=dd}{CGSize=dd}}24I56@60^@68
@60@0:8Q16Q24I32@36@44^@52
@92@0:8Q16Q24I32{CGRect={CGPoint=dd}{CGSize=dd}}36@68@76^@84
^{__CVBuffer=}
@"CIImage"
^{opaqueCMSampleBuffer=}
@"VNImageSourceManager"
@"VNImageBufferCache"
B56@0:8@16Q24@32@40^@48
@80@0:8@16Q24{CGRect={CGPoint=dd}{CGSize=dd}}32@64^@72
v28@0:8@16B24
@20@0:8B16
v24@0:8@"NSDictionary"16
v24@0:8@"NSString"16
@"NSDictionary"32@0:8@"<MTLDevice>"16^@24
@"NSDictionary"32@0:8@"NSString"16^@24
@48@0:8#16@24@32@40
@48@0:8#16@24@32^@40
@"NSNotificationCenter"
@"NSRecursiveLock"
@"_VNWeakSessionsCollection"
@"VNMTLDeviceWisdomParameters"
@40@0:8Q16@24^@32
v24@0:8@"VNPersonsModelData"16
B48@0:8@16@24^{CC_MD5state_st=IIIIII[16I]i}32^@40
B48@0:8^^?16^:24^Q32@40
@"VNPersonsModelData"
d32@0:8@16@24
d24@0:8@16
@32@0:8d16d24
{CGPoint=dd}16@0:8
@64@0:8{CGAffineTransform=dddddd}16
d16@0:8
@?16@0:8
v24@0:8@?16
@?<v@?@"VNRequest"d@"NSError">16@0:8
v24@0:8@?<v@?@"VNRequest"d@"NSError">16
B56@0:8^@16#24@32@40^@48
B48@0:8^d16@24@32^@40
B56@0:8^d16@24@32d40^@48
B48@0:8^f16@24@32^@40
B52@0:8^f16@24@32f40^@44
B56@0:8^@16@24@32#40^@48
Q20@0:8i16
B24@0:8Q16
v32@0:8@"NSString"16@24
@24@0:8@"NSString"16
v28@0:8B16@"NSError"20
@"VNAsyncStatus"16@0:8
#32@0:8Q16^@24
@48@0:8^@16Q24@32^@40
B48@0:8@16^Q24^Q32^@40
B32@0:8Q16^@24
@112@0:8@16Q24{CGRect={CGPoint=dd}{CGSize=dd}}32@64@72@?80@?88@96^@104
@52@0:8@16@24I32@36^@44
v56@0:8@16@?24@32@40@48
@"VNRequestConfiguration"
@"VNWarningRecorder"
@"VNAsyncStatus"
@"VNCanceller"
@"NSObject<OS_dispatch_queue>"
@40@0:8Q16Q24Q32
@52@0:8I16@20@28Q36I44B48
@52@0:8I16Q20Q28I36Q40B48
B32@0:8Q16Q24
@"VNSizeRange"
@"VNProcessingDevice"
v32@0:8@16@?24
@32@0:8@16#24
B20@0:8I16
@56@0:8r^v16Q24Q32Q40f48f52
@64@0:8r^v16Q24Q32Q40f48f52@56
@40@0:8@16^Q24^@32
Q40@0:8@16Q24^@32
@"VNFaceprint"
@"VNTorsoprint"
{shared_ptr<vision::mod::PetprintGenerator>="__ptr_"^{PetprintGenerator}"__cntrl_"^{__shared_weak_count}}
@"VNFaceObservation"
@"NSUUID"
{_Geometry2D_point2D_="x"f"y"f}
@36@0:8@16i24^@28
@36@0:8@16B24^@28
@40@0:8{vector<MPClusteringTreeNode *, std::allocator<MPClusteringTreeNode *>>=^^{MPClusteringTreeNode}^^{MPClusteringTreeNode}{__compressed_pair<MPClusteringTreeNode **, std::allocator<MPClusteringTreeNode *>>=^^{MPClusteringTreeNode}}}16
@"VNMPContext"
@28@0:8^v16B24
Q40@0:8^{?=Q^@^Q[5Q]}16^@24Q32
B24@0:8@"<VNEntityIdentificationModelPrint>"16
@"VNRequestSpecifier"16@0:8
@"NSData"16@0:8
@"<VNEntityIdentificationModelPrint>"32@0:8@"VNRequestSpecifier"16^@24
@60@0:8q16{CGRect={CGPoint=dd}{CGSize=dd}}24f56
{CGRect={CGPoint=dd}{CGSize=dd}}16@0:8
v48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
B40@0:8#16@24^@32
v24@0:8@"VNEntityIdentificationModelTrainingData"16
@"VNEntityIdentificationModelTrainingData"
@36@0:8{CGPoint=dd}16f32
@44@0:8{CGPoint=dd}16f32@36
Q40@0:8@"NSMutableData"16Q24^@32
@40@0:8@"NSData"16^Q24^@32
@56@0:8r^v16Q24Q32Q40Q48
@60@0:8r^v16Q24Q32Q40f48Q52
@60@0:8r^v16Q24Q32Q40f48@52
@36@0:8r^v16f24Q28
v28@0:8f16i20i24
{CGRect={CGPoint=dd}{CGSize=dd}}52@0:8f16{vImage_Buffer=^vQQQ}20
[4{CGPoint="x"d"y"d}]
[4f]
@56@0:8@16^{__CVBuffer=}24{CGSize=dd}32@48
^{__CVBuffer=}24@0:8^@16
{CGSize="width"d"height"d}
^{__CVBuffer=}80@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24Q56@64^@72
{shared_ptr<vision::mod::ScreenGazePredictor>="__ptr_"^{ScreenGazePredictor}"__cntrl_"^{__shared_weak_count}}
@104@0:8@16@24@32{CGPoint=dd}40{CGPoint=dd}56{CGPoint=dd}72{CGPoint=dd}88
@72@0:8@16@24@32{CGRect={CGPoint=dd}{CGSize=dd}}40
v24@0:8^{__MRCDescriptor=}16
r^{__MRCDescriptor=}16@0:8
v24@0:8r^{__MRCDescriptor=}16
@"CIBarcodeDescriptor"
r^{__MRCDescriptor=}
{shared_ptr<vision::mod::ImageDescriptorBufferFloat32>=^{ImageDescriptorBufferFloat32}^{__shared_weak_count}}52@0:8{shared_ptr<vision::mod::ImageDescriptorBufferFloat32>=^{ImageDescriptorBufferFloat32}^{__shared_weak_count}}16@32i40^v44
B40@0:8^I16Q24^@32
@56@0:8{shared_ptr<vision::mod::FaceIDModel>=^{FaceIDModel}^{__shared_weak_count}}16Q32Q40@48
B40@0:8^i16@24^@32
@56@0:8@16r^v24Q32^{CVMLCanceller=^^?Bi}40^@48
@56@0:8@16r^v24Q32@40^@48
{shared_ptr<vision::mod::FaceIDModel>="__ptr_"^{FaceIDModel}"__cntrl_"^{__shared_weak_count}}
{shared_ptr<vision::mod::ImageClassifierAbstract>=^{ImageClassifierAbstract}^{__shared_weak_count}}88@0:8{shared_ptr<vision::mod::ImageDescriptorProcessorAbstract>=^{ImageDescriptorProcessorAbstract}^{__shared_weak_count}}16r*32i40i44r*48{Options=BQ@@}56
{shared_ptr<vision::mod::ImageDescriptorProcessorAbstract>=^{ImageDescriptorProcessorAbstract}^{__shared_weak_count}}68@0:8r*16i24i28i32{Options=BQ@@}36
v32@0:8^@16^@24
@44@0:8@16I24Q28Q36
@64@0:8r^v16Q24Q32Q40@48Q56
B40@0:8@16Q24^@32
@48@0:8{_NSRange=QQ}16@?32^@40
@48@0:8{_NSRange=QQ}16@32^@40
@"VNFaceObservation"32@0:8Q16Q24
@"VNPersonsModel"
@"<VNPersonsModelDataSource>"
@40@0:8#16@24@32
B60@0:8Q16I24@28@36^{CC_MD5state_st=IIIIII[16I]i}44^@52
@48@0:8@16Q24@32^@40
@"VNPersonsModelFaceModel"
@"VNPersonsModelConfiguration"
@44@0:8Q16@24@32B40
@"VNPersonsModelAlgorithm"
@32@0:8#16^@24
@36@0:8@16@24f32
@"<NSObject><NSCopying><NSSecureCoding>"
@"NSIndexSet"
B48@0:8^@16^@24@32^@40
@"VNImageBuffer"
@"VNImageRegistrationSignature"
@"VNClassificationObservation"
@"VNFaceAttributeCategory"
@"VNDetectionprint"
r^{BufferSize=QQ}16@0:8
{BufferSize=QQ}16@0:8
{optional<std::tuple<std::unordered_map<NSString *, __CVBuffer *>, std::unordered_map<NSString *, espresso_buffer_t>>>=(?=c{tuple<std::unordered_map<NSString *, __CVBuffer *>, std::unordered_map<NSString *, espresso_buffer_t>>={__tuple_impl<std::__tuple_indices<0, 1>, std::unordered_map<NSString *, __CVBuffer *>, std::unordered_map<NSString *, espresso_buffer_t>>={unordered_map<NSString *, __CVBuffer *, std::hash<NSString *>, std::equal_to<NSString *>, std::allocator<std::pair<NSString *const, __CVBuffer *>>>={__hash_table<std::__hash_value_type<NSString *, __CVBuffer *>, std::__unordered_map_hasher<NSString *, std::__hash_value_type<NSString *, __CVBuffer *>, std::hash<NSString *>, std::equal_to<NSString *>, true>, std::__unordered_map_equal<NSString *, std::__hash_value_type<NSString *, __CVBuffer *>, std::equal_to<NSString *>, std::hash<NSString *>, true>, std::allocator<std::__hash_value_type<NSString *, __CVBuffer *>>>={unique_ptr<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, __CVBuffer *>, void *> *> *[], std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, __CVBuffer *>, void *> *> *>>>={__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, __CVBuffer *>, void *> *> **, std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, __CVBuffer *>, void *> *> *>>>=^^v{__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, __CVBuffer *>, void *> *> *>>={__compressed_pair<unsigned long, std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, __CVBuffer *>, void *> *> *>>=Q}}}}{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, __CVBuffer *>, void *> *>, std::allocator<std::__hash_node<std::__hash_value_type<NSString *, __CVBuffer *>, void *>>>={__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, __CVBuffer *>, void *> *>=^v}}{__compressed_pair<unsigned long, std::__unordered_map_hasher<NSString *, std::__hash_value_type<NSString *, __CVBuffer *>, std::hash<NSString *>, std::equal_to<NSString *>, true>>=Q}{__compressed_pair<float, std::__unordered_map_equal<NSString *, std::__hash_value_type<NSString *, __CVBuffer *>, std::equal_to<NSString *>, std::hash<NSString *>, true>>=f}}}{unordered_map<NSString *, espresso_buffer_t, std::hash<NSString *>, std::equal_to<NSString *>, std::allocator<std::pair<NSString *const, espresso_buffer_t>>>={__hash_table<std::__hash_value_type<NSString *, espresso_buffer_t>, std::__unordered_map_hasher<NSString *, std::__hash_value_type<NSString *, espresso_buffer_t>, std::hash<NSString *>, std::equal_to<NSString *>, true>, std::__unordered_map_equal<NSString *, std::__hash_value_type<NSString *, espresso_buffer_t>, std::equal_to<NSString *>, std::hash<NSString *>, true>, std::allocator<std::__hash_value_type<NSString *, espresso_buffer_t>>>={unique_ptr<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, espresso_buffer_t>, void *> *> *[], std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, espresso_buffer_t>, void *> *> *>>>={__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, espresso_buffer_t>, void *> *> **, std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, espresso_buffer_t>, void *> *> *>>>=^^v{__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, espresso_buffer_t>, void *> *> *>>={__compressed_pair<unsigned long, std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, espresso_buffer_t>, void *> *> *>>=Q}}}}{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, espresso_buffer_t>, void *> *>, std::allocator<std::__hash_node<std::__hash_value_type<NSString *, espresso_buffer_t>, void *>>>={__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, espresso_buffer_t>, void *> *>=^v}}{__compressed_pair<unsigned long, std::__unordered_map_hasher<NSString *, std::__hash_value_type<NSString *, espresso_buffer_t>, std::hash<NSString *>, std::equal_to<NSString *>, true>>=Q}{__compressed_pair<float, std::__unordered_map_equal<NSString *, std::__hash_value_type<NSString *, espresso_buffer_t>, std::equal_to<NSString *>, std::hash<NSString *>, true>>=f}}}}})B}48@0:8^{__CVBuffer=}16@24@32^@40
^{__CVBuffer=}60@0:8@16Q24Q32I40@44^@52
r^v16@0:8
{BufferSize="width"Q"height"Q}
{unordered_map<NSString *, apple::vision::BufferSize, std::hash<NSString *>, std::equal_to<NSString *>, std::allocator<std::pair<NSString *const, apple::vision::BufferSize>>>="__table_"{__hash_table<std::__hash_value_type<NSString *, apple::vision::BufferSize>, std::__unordered_map_hasher<NSString *, std::__hash_value_type<NSString *, apple::vision::BufferSize>, std::hash<NSString *>, std::equal_to<NSString *>, true>, std::__unordered_map_equal<NSString *, std::__hash_value_type<NSString *, apple::vision::BufferSize>, std::equal_to<NSString *>, std::hash<NSString *>, true>, std::allocator<std::__hash_value_type<NSString *, apple::vision::BufferSize>>>="__bucket_list_"{unique_ptr<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, apple::vision::BufferSize>, void *> *> *[], std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, apple::vision::BufferSize>, void *> *> *>>>="__ptr_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, apple::vision::BufferSize>, void *> *> **, std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, apple::vision::BufferSize>, void *> *> *>>>="__value_"^^v"__value_"{__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, apple::vision::BufferSize>, void *> *> *>>="__data_"{__compressed_pair<unsigned long, std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, apple::vision::BufferSize>, void *> *> *>>="__value_"Q}}}}"__p1_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, apple::vision::BufferSize>, void *> *>, std::allocator<std::__hash_node<std::__hash_value_type<NSString *, apple::vision::BufferSize>, void *>>>="__value_"{__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, apple::vision::BufferSize>, void *> *>="__next_"^v}}"__p2_"{__compressed_pair<unsigned long, std::__unordered_map_hasher<NSString *, std::__hash_value_type<NSString *, apple::vision::BufferSize>, std::hash<NSString *>, std::equal_to<NSString *>, true>>="__value_"Q}"__p3_"{__compressed_pair<float, std::__unordered_map_equal<NSString *, std::__hash_value_type<NSString *, apple::vision::BufferSize>, std::equal_to<NSString *>, std::hash<NSString *>, true>>="__value_"f}}}
@64@0:8r^v16Q24Q32Q40@48@56
@32@0:8r*16Q24
@64@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24^@56
r^{FastRegistration_Signatures=^fQ{Projections_meanStdTable=^f^f}^fQ{Projections_meanStdTable=^f^f}*}16@0:8
{FastRegistration_Signatures="piRow"^f"nPiRow"Q"piRowTable"{Projections_meanStdTable="sumTable"^f"sumSqTable"^f}"piCol"^f"nPiCol"Q"piColTable"{Projections_meanStdTable="sumTable"^f"sumSqTable"^f}"_memoryContainer"*}
f24@0:8Q16
{shared_ptr<vision::mod::FaceFrontalizer>="__ptr_"^{FaceFrontalizer}"__cntrl_"^{__shared_weak_count}}
v24@0:8^{vImage_Buffer=^vQQQ}16
q24@0:8@16
@"VNOperationPoints"24@0:8^@16
@"VNOperationPoints"
B40@0:8^{CGSize=dd}16Q24^@32
B40@0:8^Q16Q24^@32
{shared_ptr<vision::mod::FaceSegmenterDNN>="__ptr_"^{FaceSegmenterDNN}"__cntrl_"^{__shared_weak_count}}
v24@0:8@"NSMutableDictionary"16
@24@0:8q16
@24@0:8d16
@"VNVideoProcessorCadence"
B72@0:8{?={?=qiIq}{?=qiIq}}16^@64
@"VCPVideoProcessor"
v40@0:8^{CGPath=}16{CGSize=dd}24
@"VNRecognizedPointsSpecifier"
@"VCPRequest"
@"VNEntityIdentificationModelAlgorithm"
@48@0:8@16f24@28i36i40i44
@36@0:8@16i24i28i32
@52@0:8{?=^vi}16^v32f40@44
@40@0:8{?=^vi}16^v32
{CGSize=dd}32@0:8{CGSize=dd}16
@28@0:8r^{vImage_Buffer=^vQQQ}16B24
@32@0:8@16f24f28
v20@0:8i16
@"ShotflowNetwork"
{shared_ptr<vision::mod::ImageClassifier_HierarchicalModel>=^{ImageClassifier_HierarchicalModel}^{__shared_weak_count}}32@0:8@16^@24
@80@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24@56@64^@72
{shared_ptr<vision::mod::ImageDescriptorProcessorAbstract>="__ptr_"^{ImageDescriptorProcessorAbstract}"__cntrl_"^{__shared_weak_count}}
{shared_ptr<vision::mod::ImageClassifierAbstract>="__ptr_"^{ImageClassifierAbstract}"__cntrl_"^{__shared_weak_count}}
@"NSSet"
^{__CFString=}24@0:8@16
@24@0:8^{__CFString=}16
@32@0:8^{__MRCDescriptor=}16^@24
^{ACBSConfig=}24@0:8^@16
@72@0:8^{__MRCDescriptor=}16{CGRect={CGPoint=dd}{CGSize=dd}}24@56^@64
B56@0:8@16^{CGPoint=dd}24^{CGPoint=dd}32^{CGPoint=dd}40^{CGPoint=dd}48
@88@0:8@16Q24Q32{CGRect={CGPoint=dd}{CGSize=dd}}40@72^@80
@48@0:8@16^{ACBSConfig=}24@32^@40
@"VNRPNTrackerEspressoResourcesCache"
B68@0:8@16^v24Q32Q40Q48I56^@60
^{__CVBuffer=}52@0:8@16Q24Q32I40^@44
@"MPSImageSpatioTemporalGuidedFilter"
@"VNObservation<VNEntityIdentificationModelObservation>"
@"VNSaliencyOHeatmapBoundingBoxGenerator"
@"NSBundle"
@76@0:8q16{CGRect={CGPoint=dd}{CGSize=dd}}24f56f60f64f68i72
@48@0:8^{vImage_Buffer=^vQQQ}16@24@32^@40
@48@0:8^{vImage_Buffer=^vQQQ}16@24q32^@40
@48@0:8^{__CVBuffer=}16@24@32^@40
@48@0:8^{__CVBuffer=}16@24q32^@40
^{vImage_Buffer=^vQQQ}16@0:8
^{vImage_Buffer=^vQQQ}
B40@0:8^f16@24^@32
B44@0:8^f16@24f32^@36
@44@0:8@16i24i28i32^@36
B32@0:8^{__CVBuffer=}16^@24
B40@0:8^{__CVBuffer=}16^{__CVBuffer=}24^@32
v28@0:8i16i20i24
B44@0:8@16^{__CVBuffer=}24i32^@36
v68@0:8@16i242836@44@52@60
v56@0:8@16@24@32@40@48
@"<MTLCommandQueue>"
[9@"<MTLComputePipelineState>"]
[10{CGSize="width"d"height"d}]
[2[10@"<MTLTexture>"]]
[10@"<MTLTexture>"]
[2@"<MTLBuffer>"]
[2^{__CVBuffer}]
@"<MTLTexture>"
v24@0:8d16
@"VNSupportedImageSize"
{CGSize=dd}40@0:8@16Q24Q32
^{__CVBuffer=}88@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48I56{CGSize=dd}60B76^@80
^{__CVBuffer=}56@0:8@16I24{CGSize=dd}28B44^@48
B48@0:8Q16@24@32^@40
@32@0:8@"NSData"16^@24
@40@0:8@16Q24@32
@"VNMPImageDescriptor"
B40@0:8@16^f24^@32
@"<MTLLibrary>"
@"CIColorKernel"
B48@0:8@16Q24Q32^@40
@56@0:8@16Q24Q32@40^@48
@48@0:8r^f16Q24@32^@40
@48@0:8@16Q24Q32@40
@28@0:8@16I24
@112@0:8@16f24f28f32f36f40f44f48f52f56f60f64f68f72f76f80f84f88f92f96f100f104f108
@48@0:8@16@24{CGSize=dd}32
@32@0:8q16^@24
r^{CGPath=}16@0:8
r^{EPolygonList=ii^{EPolygon}i}16@0:8
r^v24@0:8q16
^{CGPath=}
{shared_ptr<apple::vision::libraries::autotrace::EPolygonList>="__ptr_"^{EPolygonList}"__cntrl_"^{__shared_weak_count}}
{vector<unsigned int, std::allocator<unsigned int>>="__begin_"^I"__end_"^I"__end_cap_"{__compressed_pair<unsigned int *, std::allocator<unsigned int>>="__value_"^I}}
{vector<std::vector<unsigned int>, std::allocator<std::vector<unsigned int>>>="__begin_"^v"__end_"^v"__end_cap_"{__compressed_pair<std::vector<unsigned int> *, std::allocator<std::vector<unsigned int>>>="__value_"^v}}
@48@0:8{?=qiIq}16q40
^{__CVBuffer=}72@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24@56^@64
@24@0:8r^v16
@88@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24@56@64@72^@80
@"CIFilter"
@"VNDetectContoursRequest"
^{CGColorSpace=}
@"ParabolaDetection"
{shared_ptr<vision::mod::FaceRegionMap>="__ptr_"^{FaceRegionMap}"__cntrl_"^{__shared_weak_count}}
{?={?=qiIq}{?=qiIq}}16@0:8
v64@0:8{?={?=qiIq}{?=qiIq}}16
@"NSPointerArray"
{?="start"{?="value"q"timescale"i"flags"I"epoch"q}"duration"{?="value"q"timescale"i"flags"I"epoch"q}}
@48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
@56@0:8Q16{CGRect={CGPoint=dd}{CGSize=dd}}24
@56@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24
v80@0:8{CGPoint=dd}16{CGPoint=dd}32{CGPoint=dd}48{CGPoint=dd}64
@"VNPixelBufferObservation"
B36@0:8f16^i20^@28
@88@0:8Q16{CGRect={CGPoint=dd}{CGSize=dd}}24{CGRect={CGPoint=dd}{CGSize=dd}}56
@64@0:8Q16{CGRect={CGPoint=dd}{CGSize=dd}}24@56
@80@0:8Q16{CGRect={CGPoint=dd}{CGSize=dd}}24@56@64@72
@72@0:8Q16{CGRect={CGPoint=dd}{CGSize=dd}}24@56@64
@112@0:8Q16{CGRect={CGPoint=dd}{CGSize=dd}}24{CGRect={CGPoint=dd}{CGSize=dd}}56@88@96@104
@104@0:8Q16{CGRect={CGPoint=dd}{CGSize=dd}}24{CGRect={CGPoint=dd}{CGSize=dd}}56@88@96
B104@0:8{?=[4]}16^f80^f88^f96
{?=[4]}16@0:8
{?=}16@0:8
B24@0:8^{CGAffineTransform=dddddd}16
v88@0:8@16@24^{CGPath=}32{CGAffineTransform=dddddd}40
B32@0:8^i16^@24
{_Geometry2D_rect2D_={_Geometry2D_point2D_=ff}{_Geometry2D_size2D_=ff}}16@0:8
v32@0:8{_Geometry2D_rect2D_={_Geometry2D_point2D_=ff}{_Geometry2D_size2D_=ff}}16
@"VNFaceLandmarks2D"
@"VNFaceLandmarks3D"
@"VNFaceRegionMap"
@"VNFaceAttributes"
@"VNFaceTorsoprint"
@"VNFaceSegments"
@"VNFaceLegacyFaceCore"
@"VNFaceGaze"
@"VNFaceScreenGaze"
{CGAffineTransform=dddddd}16@0:8
v64@0:8{CGAffineTransform=dddddd}16
{CGAffineTransform="a"d"b"d"c"d"d"d"tx"d"ty"d}
{?=[3]}16@0:8
v64@0:8{?=[3]}16
{?="columns"[3]}
@"VNImageprint"
@36@0:8Q16@24f32
@44@0:8Q16@24f32@36
@44@0:8@16@24f32@36
B24@0:8f16f20
@"<VNOperationPointsProviding>"
@68@0:8Q16{CGRect={CGPoint=dd}{CGSize=dd}}24f56@60
@"MLFeatureValue"
@40@0:8@16@24^{__CVBuffer=}32
@88@0:8Q16{CGPoint=dd}24{CGPoint=dd}40{CGPoint=dd}56{CGPoint=dd}72
@80@0:8{CGPoint=dd}16{CGPoint=dd}32{CGPoint=dd}48{CGPoint=dd}64
@88@0:8@16{CGPoint=dd}24{CGPoint=dd}40{CGPoint=dd}56{CGPoint=dd}72
@120@0:8@16{CGPoint=dd}24{CGPoint=dd}40{CGPoint=dd}56{CGPoint=dd}72{CGRect={CGPoint=dd}{CGSize=dd}}88
{CGPoint="x"d"y"d}
{CGAffineTransform=dddddd}32@0:8Q16Q24
f32@0:8@16^@24
16@0:8
@"VNImageSignature"
@"LKTOpticalFlow"
^{OpaqueVTPixelTransferSession=}
^{OpaqueVTPixelRotationSession=}
{unique_ptr<SessionsHandler<VNVTPixelTransferSession>, std::default_delete<SessionsHandler<VNVTPixelTransferSession>>>="__ptr_"{__compressed_pair<SessionsHandler<VNVTPixelTransferSession> *, std::default_delete<SessionsHandler<VNVTPixelTransferSession>>>="__value_"^v}}
{unique_ptr<SessionsHandler<VNVTImageRotationSession>, std::default_delete<SessionsHandler<VNVTImageRotationSession>>>="__ptr_"{__compressed_pair<SessionsHandler<VNVTImageRotationSession> *, std::default_delete<SessionsHandler<VNVTImageRotationSession>>>="__value_"^v}}
B48@0:8^@16#24Q32^@40
{CGRect={CGPoint=dd}{CGSize=dd}}32@0:8Q16Q24
@56@0:8{shared_ptr<vision::mod::FaceID3Model>=^{FaceID3Model}^{__shared_weak_count}}16@32@40@48
{shared_ptr<vision::mod::FaceID3Model>="__ptr_"^{FaceID3Model}"__cntrl_"^{__shared_weak_count}}
B48@0:8@16@24Q32@40
B32@0:8@16@24
B108@0:8{vImage_Buffer=^vQQQ}16{vImage_Buffer=^vQQQ}48{CGSize=dd}80f96f100f104
f48@0:8{vImage_Buffer=^vQQQ}16
@52@0:8{vImage_Buffer=^vQQQ}16f48
@56@0:8{vImage_Buffer=^vQQQ}16f48B52
@40@0:8^{__CVBuffer=}16f24B28^@32
@64@0:8{vImage_Buffer=^vQQQ}16@48^@56
@100@0:8{vImage_Buffer=^vQQQ}16@48B56B60{CGSize=dd}64f80f84f88^@92
@76@0:8^{__CVBuffer=}16@24B32B36{CGSize=dd}40f56f60f64^@68
{unordered_map<apple::vision::BufferSizeFormat, __CVPixelBufferPool *, std::hash<apple::vision::BufferSizeFormat>, std::equal_to<apple::vision::BufferSizeFormat>, std::allocator<std::pair<const apple::vision::BufferSizeFormat, __CVPixelBufferPool *>>>="__table_"{__hash_table<std::__hash_value_type<apple::vision::BufferSizeFormat, __CVPixelBufferPool *>, std::__unordered_map_hasher<apple::vision::BufferSizeFormat, std::__hash_value_type<apple::vision::BufferSizeFormat, __CVPixelBufferPool *>, std::hash<apple::vision::BufferSizeFormat>, std::equal_to<apple::vision::BufferSizeFormat>, true>, std::__unordered_map_equal<apple::vision::BufferSizeFormat, std::__hash_value_type<apple::vision::BufferSizeFormat, __CVPixelBufferPool *>, std::equal_to<apple::vision::BufferSizeFormat>, std::hash<apple::vision::BufferSizeFormat>, true>, std::allocator<std::__hash_value_type<apple::vision::BufferSizeFormat, __CVPixelBufferPool *>>>="__bucket_list_"{unique_ptr<std::__hash_node_base<std::__hash_node<std::__hash_value_type<apple::vision::BufferSizeFormat, __CVPixelBufferPool *>, void *> *> *[], std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<apple::vision::BufferSizeFormat, __CVPixelBufferPool *>, void *> *> *>>>="__ptr_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<apple::vision::BufferSizeFormat, __CVPixelBufferPool *>, void *> *> **, std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<apple::vision::BufferSizeFormat, __CVPixelBufferPool *>, void *> *> *>>>="__value_"^^v"__value_"{__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<apple::vision::BufferSizeFormat, __CVPixelBufferPool *>, void *> *> *>>="__data_"{__compressed_pair<unsigned long, std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<apple::vision::BufferSizeFormat, __CVPixelBufferPool *>, void *> *> *>>="__value_"Q}}}}"__p1_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<apple::vision::BufferSizeFormat, __CVPixelBufferPool *>, void *> *>, std::allocator<std::__hash_node<std::__hash_value_type<apple::vision::BufferSizeFormat, __CVPixelBufferPool *>, void *>>>="__value_"{__hash_node_base<std::__hash_node<std::__hash_value_type<apple::vision::BufferSizeFormat, __CVPixelBufferPool *>, void *> *>="__next_"^v}}"__p2_"{__compressed_pair<unsigned long, std::__unordered_map_hasher<apple::vision::BufferSizeFormat, std::__hash_value_type<apple::vision::BufferSizeFormat, __CVPixelBufferPool *>, std::hash<apple::vision::BufferSizeFormat>, std::equal_to<apple::vision::BufferSizeFormat>, true>>="__value_"Q}"__p3_"{__compressed_pair<float, std::__unordered_map_equal<apple::vision::BufferSizeFormat, std::__hash_value_type<apple::vision::BufferSizeFormat, __CVPixelBufferPool *>, std::equal_to<apple::vision::BufferSizeFormat>, std::hash<apple::vision::BufferSizeFormat>, true>>="__value_"f}}}
@"VNDetector"40@0:8@"NSString"16@"NSDictionary"24^@32
@"VNDetector"40@0:8#16@"NSDictionary"24^@32
v32@0:8#16@24
v32@0:8#16@"NSDictionary"24
@"<VNDetectorCacheDelegate>"
{?="reportDidCacheDetector"b1"reportDidEvictDetector"b1}
@"NSMutableSet"
@56@0:8Q16r^v24Q32Q40^@48
@24@0:8^{__CVBuffer=}16
B32@0:8^{__CVBuffer=}16^{__CVBuffer=}24
Q24@0:8^{__CVBuffer=}16
@"VNCIContrastFromAverageColorFilter"
@"VNCIContrastWithPivotColorFilter"
v20@0:8I16
B48@0:8@16@24^@32^@40
B40@0:8@16^{__CVBuffer=}24^@32
B48@0:8@16^{__CVBuffer=}24^@32^@40
B44@0:8@16^{__CVBuffer=}24I32^@36
B52@0:8@16^{__CVBuffer=}24I32^@36^@44
B40@0:8@16^{CGImage=}24^@32
B48@0:8@16^{CGImage=}24^@32^@40
B44@0:8@16^{CGImage=}24I32^@36
B52@0:8@16^{CGImage=}24I32^@36^@44
B44@0:8@16@24I32^@36
B52@0:8@16@24I32^@36^@44
B40@0:8@16^{opaqueCMSampleBuffer=}24^@32
B48@0:8@16^{opaqueCMSampleBuffer=}24^@32^@40
B44@0:8@16^{opaqueCMSampleBuffer=}24I32^@36
B52@0:8@16^{opaqueCMSampleBuffer=}24I32^@36^@44
@"VNSession"
@"VNRequestPerformer"
@"VNResourceVersion"
#32@0:8@16@24
@72@0:8@16@24@32@40@48@56@64
{BufferSize=QQ}68@0:8{BufferSize=QQ}16{BufferSize=QQ}32{BufferSize=QQ}48B64
{optional<std::tuple<std::unordered_map<NSString *, __CVBuffer *>, std::unordered_map<NSString *, espresso_buffer_t>>>=(?=c{tuple<std::unordered_map<NSString *, __CVBuffer *>, std::unordered_map<NSString *, espresso_buffer_t>>={__tuple_impl<std::__tuple_indices<0, 1>, std::unordered_map<NSString *, __CVBuffer *>, std::unordered_map<NSString *, espresso_buffer_t>>={unordered_map<NSString *, __CVBuffer *, std::hash<NSString *>, std::equal_to<NSString *>, std::allocator<std::pair<NSString *const, __CVBuffer *>>>={__hash_table<std::__hash_value_type<NSString *, __CVBuffer *>, std::__unordered_map_hasher<NSString *, std::__hash_value_type<NSString *, __CVBuffer *>, std::hash<NSString *>, std::equal_to<NSString *>, true>, std::__unordered_map_equal<NSString *, std::__hash_value_type<NSString *, __CVBuffer *>, std::equal_to<NSString *>, std::hash<NSString *>, true>, std::allocator<std::__hash_value_type<NSString *, __CVBuffer *>>>={unique_ptr<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, __CVBuffer *>, void *> *> *[], std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, __CVBuffer *>, void *> *> *>>>={__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, __CVBuffer *>, void *> *> **, std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, __CVBuffer *>, void *> *> *>>>=^^v{__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, __CVBuffer *>, void *> *> *>>={__compressed_pair<unsigned long, std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, __CVBuffer *>, void *> *> *>>=Q}}}}{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, __CVBuffer *>, void *> *>, std::allocator<std::__hash_node<std::__hash_value_type<NSString *, __CVBuffer *>, void *>>>={__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, __CVBuffer *>, void *> *>=^v}}{__compressed_pair<unsigned long, std::__unordered_map_hasher<NSString *, std::__hash_value_type<NSString *, __CVBuffer *>, std::hash<NSString *>, std::equal_to<NSString *>, true>>=Q}{__compressed_pair<float, std::__unordered_map_equal<NSString *, std::__hash_value_type<NSString *, __CVBuffer *>, std::equal_to<NSString *>, std::hash<NSString *>, true>>=f}}}{unordered_map<NSString *, espresso_buffer_t, std::hash<NSString *>, std::equal_to<NSString *>, std::allocator<std::pair<NSString *const, espresso_buffer_t>>>={__hash_table<std::__hash_value_type<NSString *, espresso_buffer_t>, std::__unordered_map_hasher<NSString *, std::__hash_value_type<NSString *, espresso_buffer_t>, std::hash<NSString *>, std::equal_to<NSString *>, true>, std::__unordered_map_equal<NSString *, std::__hash_value_type<NSString *, espresso_buffer_t>, std::equal_to<NSString *>, std::hash<NSString *>, true>, std::allocator<std::__hash_value_type<NSString *, espresso_buffer_t>>>={unique_ptr<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, espresso_buffer_t>, void *> *> *[], std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, espresso_buffer_t>, void *> *> *>>>={__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, espresso_buffer_t>, void *> *> **, std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, espresso_buffer_t>, void *> *> *>>>=^^v{__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, espresso_buffer_t>, void *> *> *>>={__compressed_pair<unsigned long, std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, espresso_buffer_t>, void *> *> *>>=Q}}}}{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, espresso_buffer_t>, void *> *>, std::allocator<std::__hash_node<std::__hash_value_type<NSString *, espresso_buffer_t>, void *>>>={__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, espresso_buffer_t>, void *> *>=^v}}{__compressed_pair<unsigned long, std::__unordered_map_hasher<NSString *, std::__hash_value_type<NSString *, espresso_buffer_t>, std::hash<NSString *>, std::equal_to<NSString *>, true>>=Q}{__compressed_pair<float, std::__unordered_map_equal<NSString *, std::__hash_value_type<NSString *, espresso_buffer_t>, std::equal_to<NSString *>, std::hash<NSString *>, true>>=f}}}}})B}48@0:8@16@24@32^@40
@"<MTLComputePipelineState>"
q40@0:8@16^^{MPClusteringTreeNode}24@32
f28@0:8^{MPClusteringTreeNode=@iffi^{MPClusteringTreeNode}^{MPClusteringTreeNode}^{MPClusteringTreeNode}^{MPClusteringTreeNode}}16i24
{vector<MPClusteringTreeNode *, std::allocator<MPClusteringTreeNode *>>=^^{MPClusteringTreeNode}^^{MPClusteringTreeNode}{__compressed_pair<MPClusteringTreeNode **, std::allocator<MPClusteringTreeNode *>>=^^{MPClusteringTreeNode}}}40@0:8i16f20^{MPClusteringTreeNode=@iffi^{MPClusteringTreeNode}^{MPClusteringTreeNode}^{MPClusteringTreeNode}^{MPClusteringTreeNode}}24@32
{vector<MPClusteringTreeNode *, std::allocator<MPClusteringTreeNode *>>=^^{MPClusteringTreeNode}^^{MPClusteringTreeNode}{__compressed_pair<MPClusteringTreeNode **, std::allocator<MPClusteringTreeNode *>>=^^{MPClusteringTreeNode}}}36@0:8i16^{MPClusteringTreeNode=@iffi^{MPClusteringTreeNode}^{MPClusteringTreeNode}^{MPClusteringTreeNode}^{MPClusteringTreeNode}}20@28
{vector<MPClusteringTreeNode *, std::allocator<MPClusteringTreeNode *>>=^^{MPClusteringTreeNode}^^{MPClusteringTreeNode}{__compressed_pair<MPClusteringTreeNode **, std::allocator<MPClusteringTreeNode *>>=^^{MPClusteringTreeNode}}}36@0:8f16^{MPClusteringTreeNode=@iffi^{MPClusteringTreeNode}^{MPClusteringTreeNode}^{MPClusteringTreeNode}^{MPClusteringTreeNode}}20@28
{vector<MPClusteringTreeNode *, std::allocator<MPClusteringTreeNode *>>=^^{MPClusteringTreeNode}^^{MPClusteringTreeNode}{__compressed_pair<MPClusteringTreeNode **, std::allocator<MPClusteringTreeNode *>>=^^{MPClusteringTreeNode}}}32@0:8^{MPClusteringTreeNode=@iffi^{MPClusteringTreeNode}^{MPClusteringTreeNode}^{MPClusteringTreeNode}^{MPClusteringTreeNode}}16@24
f28@0:8f16q20
f32@0:8f16q20B28
@64@0:8@16@24{?=^vi}32^v48^v56
{?=^vi}16@0:8
{?="plan"^v"network_index"i}
@40@0:8@16^@24^@32
B56@0:8^Q16^Q24@32@40^@48
B84@0:8@16@24B32@36@44@52Q60^@68^@76
B88@0:8@16@24B32@36@44@52i60Q64^@72^@80
^{__CVBuffer=}36@0:8I16r^{?=^v^v[4Q][4Q]QQQQQQQQQQi}20^@28
B40@0:8r^{?=^v^v[4Q][4Q]QQQQQQQQQQi}16^{__CVBuffer=}24^@32
Q32@0:8r^{?=^v^v[4Q][4Q]QQQQQQQQQQi}16^@24
B52@0:8^{?=^vi}16@24@32B40^@44
{?="data"^v"reserved"^v"dim"[4Q]"stride"[4Q]"width"Q"height"Q"channels"Q"batch_number"Q"sequence_length"Q"stride_width"Q"stride_height"Q"stride_channels"Q"stride_batch_number"Q"stride_sequence_length"Q"storage_type"i}
v32@0:8{CGPoint=dd}16
@40@0:8{CGPoint=dd}16@?32
@28@0:8i16i20i24
{unique_ptr<apple::vision::OpticalFlow::LKTCPU, std::default_delete<apple::vision::OpticalFlow::LKTCPU>>="__ptr_"{__compressed_pair<apple::vision::OpticalFlow::LKTCPU *, std::default_delete<apple::vision::OpticalFlow::LKTCPU>>="__value_"^{LKTCPU}}}
@32@0:8r^{?=*QQQQ}16Q24
@"VNTensorShape"
{CGSize=dd}20@0:8i16
v72@0:8@16^v24^{__CVBuffer=}32{vImage_Buffer=^vQQQ}40
B112@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16Q48Q56Q64f72f76^Q80^Q88^v96^@104
@64@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24Q56
24@0:8Q16
r^{CGPoint=dd}16@0:8
r^{CGPoint=dd}32@0:8{CGSize=dd}16
@88@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24q56^64Q72@80
r^16@0:8
@72@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24^56Q64
v24@0:8r^16
^v32@0:8r^i16Q24
@92@0:8@16@24Q32{CGRect={CGPoint=dd}{CGSize=dd}}40{_Geometry2D_rect2D_={_Geometry2D_point2D_=ff}{_Geometry2D_size2D_=ff}}72f88
@40@0:8@16r^i24Q32
@108@0:8@16@24Q32Q40@48{CGRect={CGPoint=dd}{CGSize=dd}}56{_Geometry2D_rect2D_={_Geometry2D_point2D_=ff}{_Geometry2D_size2D_=ff}}88f104
@40@0:8q16r^i24Q32
@"VNFaceLandmarkRegion2D"
@"VNFaceLandmarkRegion3D"
@40@0:8^{__CVBuffer=}16Q24^@32
B48@0:8Q16Q24@?32^@40
B64@0:8@16@24#32Q40Q48^@56
B48@0:8@16Q24@32^@40
B56@0:8@16#24Q32@40^@48
B40@0:8@16#24^@32
B48@0:8@16#24@32^@40
B28@0:8f16^@20
B48@0:8^B16@24@32^@40
B52@0:8^B16@24@32B40^@44
B48@0:8^Q16@24@32^@40
B56@0:8^q16@24@32q40^@48
B56@0:8^Q16@24@32Q40^@48
B48@0:8^i16@24@32^@40
B56@0:8^i16@24@32i40i44^@48
B52@0:8^i16@24@32i40^@44
B56@0:8^f16@24@32f40f44^@48
B48@0:8^I16@24@32^@40
B52@0:8^I16@24@32I40^@44
B72@0:8^@16@24@32#40Q48Q56^@64
@48@0:8@16@24#32^@40
@40@0:8@16#24^@32
C16@0:8
@24@0:8r^*16
@"MPImageDescriptor_LegacySupportDoNotChange"
@"MLFeatureValue"24@0:8@"NSString"16
@"NSSet"16@0:8
@40@0:8^{__CVBuffer=}16@24@32
@48@0:8@16q24@32@40
@"VNSceneprint"
@"<MLFeatureProvider>"
v32@0:8q16q24
@40@0:8^{__CVBuffer=}16@24^@32
@"MLModel"
@"MLObjectBoundingBoxOutputDescription"
@"VNCoreMLModel"
@32@0:8@16^{?=ff[9{?=ff}][9{?=ff}]}24
r^{?=ff[9{?=ff}][9{?=ff}]}32@0:8@16^@24
^{?=ff[9{?=ff}][9{?=ff}]}
@"VNSmartCam5CompoundRequestGroupingConfiguration"
B92@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24^{ImageDescriptorProcessorAbstract=^^?}56B64@68^^{__CVBuffer}76^@84
B136@0:8@16^^{__CVBuffer}24{CGRect={CGPoint=dd}{CGSize=dd}}32^{ImageDescriptorProcessorAbstract=^^?}64i72I76^v80@88@96@104^Q112^Q120^@128
B64@0:8^v16^v24^v32@40@48^@56
@60@0:8r^v16^v24f32@36@44^@52
@88@0:8r^v16^v24^{ImageClassifier_HierarchicalModel=^{ImageClassfier_Graph}}32f40f44Q48Q56@64@72^@80
B52@0:8@16@24r^{__CVBuffer=}32i40^@44
B84@0:8@16@24r^{__CVBuffer=}32i40I44r^v48i56I60f64I68B72^@76
{map<int, InternalObservedParabola, std::less<int>, std::allocator<std::pair<const int, InternalObservedParabola>>>="__tree_"{__tree<std::__value_type<int, InternalObservedParabola>, std::__map_value_compare<int, std::__value_type<int, InternalObservedParabola>, std::less<int>, true>, std::allocator<std::__value_type<int, InternalObservedParabola>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<int, InternalObservedParabola>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<int, std::__value_type<int, InternalObservedParabola>, std::less<int>, true>>="__value_"Q}}}
{ParabolaSearchBuffer="maxFramesSkippedForDetection"i"minRegionSizeX"i"minRegionSizeY"i"contourPointsQ"{deque<std::vector<CGPointWithPts>, std::allocator<std::vector<CGPointWithPts>>>="__map_"{__split_buffer<std::vector<CGPointWithPts> *, std::allocator<std::vector<CGPointWithPts> *>>="__first_"^^v"__begin_"^^v"__end_"^^v"__end_cap_"{__compressed_pair<std::vector<CGPointWithPts> **, std::allocator<std::vector<CGPointWithPts> *>>="__value_"^^v}}"__start_"Q"__size_"{__compressed_pair<unsigned long, std::allocator<std::vector<CGPointWithPts>>>="__value_"Q}}}
{InternalParameters="minRegionSizeX"i"minRegionSizeY"i"initialYDiffLimit"f"startingMinDiffDeviation"f"maxDistanceForSolution"f"frameWidth"i"frameHeight"i"xScaleFactor"f"yScaleFactor"f"runningMinDiffDeviation"i"maxFrameSkipScaleFactor"f"majorAxisScaler"f"minorAxisScalar"f"contourSizeUpperBound"f"contourSizeLowerBound"f"maxRadiusToCompensate"f"maxRadiusBasedDeviation"f"xConsistencyDeviation"f"rejectionScaler"f}
{map<int, ObservedParabola, std::less<int>, std::allocator<std::pair<const int, ObservedParabola>>>="__tree_"{__tree<std::__value_type<int, ObservedParabola>, std::__map_value_compare<int, std::__value_type<int, ObservedParabola>, std::less<int>, true>, std::allocator<std::__value_type<int, ObservedParabola>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<int, ObservedParabola>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<int, std::__value_type<int, ObservedParabola>, std::less<int>, true>>="__value_"Q}}}
{ForestAlgoParams="FAFrameRate"f"parabolaLength"i"minXDistanceFromLastPointOnParabola"i"maxXDistanceFromLastPointOnParabola"i"minYDistanceFromLastPointOnParabola"i"maxYDistanceFromLastPointOnParabola"i"maxFramesSkippedToContinueParabolaDetection"i"minObjectSize"i}
B68@0:8^@16@24I32^@36@44@52^@60
@48@0:8{?=qiIq}16@?40
^{__MRCContext=}
@96@0:8Q16Q24Q32@40Q48{CGRect={CGPoint=dd}{CGSize=dd}}56@88
^{__CVBuffer=}32@0:8Q16^@24
^{__CVBuffer=}68@0:8Q16{CGRect={CGPoint=dd}{CGSize=dd}}24B56^@60
{vImage_Buffer=^vQQQ}56@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24
^{__CVBuffer=}40@0:8{CGSize=dd}16^@32
{vector<float, std::allocator<float>>="__begin_"^f"__end_"^f"__end_cap_"{__compressed_pair<float *, std::allocator<float>>="__value_"^f}}
^{__sFILE=*iiss{__sbuf=*i}i^v^?^?^?^?{__sbuf=*i}^{__sFILEX}i[3C][1C]{__sbuf=*i}iq}16@0:8
@24@0:8r^{mapped_model_file=^^?Q}16
r^{mapped_model_file=^^?Q}
{unique_ptr<cvml::util::model_file_cache, std::default_delete<cvml::util::model_file_cache>>="__ptr_"{__compressed_pair<cvml::util::model_file_cache *, std::default_delete<cvml::util::model_file_cache>>="__value_"^{model_file_cache}}}
v32@0:8@"VNDetectorCache"16@"VNDetector"24
@"VNTracker"32@0:8@"NSDictionary"16^@24
v24@0:8@"VNTracker"16
@"VNRPNTrackerEspressoResources"32@0:8@"NSDictionary"16^@24
B32@0:8@"NSArray"16^@24
@32@0:8#16@24
@"VNFrameworkManager"
@"VNDetectorCache"
@"VNVTSessionManager"
@"VNCIContextManager"
@"VNTrackerManager"
@"VNCVPixelBufferPoolManager"
@40@0:8r^16q24^@32
B44@0:8^d16@24B32^@36
B40@0:8^d16@24^@32
f24@0:8f16f20
@24@0:8I16I20
@28@0:8I16I20I24
B20@0:8f16
@40@0:8q16Q24^@32
@"VNDetectBarcodesRequest"
@"VNCIContextsHandler"
@32@0:8@16d24
@"VNPoint"
B56@0:8^@16^@24Q32@40^@48
{shared_ptr<vision::mod::ImageClassifier_HierarchicalModel>=^{ImageClassifier_HierarchicalModel}^{__shared_weak_count}}32@0:8Q16^@24
@88@0:8r^{__CVBuffer=}16@24{CGRect={CGPoint=dd}{CGSize=dd}}32@64^@72@?80
{shared_ptr<vision::mod::ImageClassifier_HierarchicalModel>="__ptr_"^{ImageClassifier_HierarchicalModel}"__cntrl_"^{__shared_weak_count}}
{map<unsigned long, std::shared_ptr<std::vector<std::shared_ptr<vision::mod::ImageAnalyzer_CustomClassifier>>>, std::less<unsigned long>, std::allocator<std::pair<const unsigned long, std::shared_ptr<std::vector<std::shared_ptr<vision::mod::ImageAnalyzer_CustomClassifier>>>>>>="__tree_"{__tree<std::__value_type<unsigned long, std::shared_ptr<std::vector<std::shared_ptr<vision::mod::ImageAnalyzer_CustomClassifier>>>>, std::__map_value_compare<unsigned long, std::__value_type<unsigned long, std::shared_ptr<std::vector<std::shared_ptr<vision::mod::ImageAnalyzer_CustomClassifier>>>>, std::less<unsigned long>, true>, std::allocator<std::__value_type<unsigned long, std::shared_ptr<std::vector<std::shared_ptr<vision::mod::ImageAnalyzer_CustomClassifier>>>>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<unsigned long, std::shared_ptr<std::vector<std::shared_ptr<vision::mod::ImageAnalyzer_CustomClassifier>>>>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<unsigned long, std::__value_type<unsigned long, std::shared_ptr<std::vector<std::shared_ptr<vision::mod::ImageAnalyzer_CustomClassifier>>>>, std::less<unsigned long>, true>>="__value_"Q}}}
{unique_ptr<vision::mod::ImageAnalyzer_PCA, std::default_delete<vision::mod::ImageAnalyzer_PCA>>="__ptr_"{__compressed_pair<vision::mod::ImageAnalyzer_PCA *, std::default_delete<vision::mod::ImageAnalyzer_PCA>>="__value_"^{ImageAnalyzer_PCA}}}
@"_VNImageAnalyzerMultiDetectorSceneOperationPointsCache"
{map<unsigned long, std::shared_ptr<vision::mod::ImageAnalyzer_CustomClassifier>, std::less<unsigned long>, std::allocator<std::pair<const unsigned long, std::shared_ptr<vision::mod::ImageAnalyzer_CustomClassifier>>>>="__tree_"{__tree<std::__value_type<unsigned long, std::shared_ptr<vision::mod::ImageAnalyzer_CustomClassifier>>, std::__map_value_compare<unsigned long, std::__value_type<unsigned long, std::shared_ptr<vision::mod::ImageAnalyzer_CustomClassifier>>, std::less<unsigned long>, true>, std::allocator<std::__value_type<unsigned long, std::shared_ptr<vision::mod::ImageAnalyzer_CustomClassifier>>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<unsigned long, std::shared_ptr<vision::mod::ImageAnalyzer_CustomClassifier>>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<unsigned long, std::__value_type<unsigned long, std::shared_ptr<vision::mod::ImageAnalyzer_CustomClassifier>>, std::less<unsigned long>, true>>="__value_"Q}}}
{shared_ptr<const std::vector<std::tuple<std::string, float, bool>>>="__ptr_"^v"__cntrl_"^{__shared_weak_count}}
@"VNRecognizeDocumentElementsRequestElementConfiguration"
{shared_ptr<vision::mod::TorsoprintGenerator>="__ptr_"^{TorsoprintGenerator}"__cntrl_"^{__shared_weak_count}}
v28@0:8Q16I24
I28@0:8Q16I24
v36@0:8Q16Q24I32
^f16@0:8
v24@0:8^f16
*16@0:8
v24@0:8*16
^Q16@0:8
v24@0:8^Q16
^S16@0:8
v24@0:8^S16
S16@0:8
v20@0:8S16
s16@0:8
v20@0:8s16
v48@0:8{vImage_Buffer=^vQQQ}16
i48@0:8Q16Q24Q32^{vImage_Buffer=^vQQQ}40
i88@0:8{vImage_Buffer=^vQQQ}16{vImage_Buffer=^vQQQ}48*80
v56@0:8S16^f20^{__CCPulseWindowContext=^{__CCRange}SSsB}28C36C40{ThresholdSet_t=fff}44
i56@0:8S16C20C24{ThresholdSet_t=fff}28^f40Q48
v48@0:8^{__CCRange=SS}16*24^i32^i40
i28@0:8^{__CCSumDerivVectors=^f^f^f^f^fffii}16i24
v24@0:8^{__CCSumDerivVectors=^f^f^f^f^fffii}16
v32@0:8^{__CCSumDerivVectors=^f^f^f^f^fffii}16i24C28
i72@0:8C16^f20S28C32C36^{__CCFilterSumDerivConfig={__CCRange=SS}{__CCRange=SS}BBQQ}40S48{ThresholdSet_t=fff}52*64
i96@0:8^f16S24S28C32C36S40S44I48I52S56{ThresholdSet_t=fff}60*72^f80Q88
v52@0:8Q16Q24Q32C40S44S48
v40@0:8Q16Q24S32S36
v44@0:8Q16^S24C32S36S40
i56@0:8^{__rgbaColor=CCCC}16^{__rgbaColor=CCCC}24I32I36^{__rgbMinMaxU8=CCCCCC}40^{__rgbMinMaxFloat=ffffff}48
I92@0:8{vImage_Buffer=^vQQQ}16{vImage_Buffer=^vQQQ}48C80^{__rgbMinMaxFloat=ffffff}84
f88@0:8{vImage_Buffer=^vQQQ}16{vImage_Buffer=^vQQQ}48S80S84
v64@0:8{vImage_Buffer=^vQQQ}16^{__CCColorProfileContext={vImage_Buffer=^vQQQ}{vImage_Buffer=^vQQQ}{vImage_Buffer=^vQQQ}{vImage_Buffer=^vQQQ}iiSS}48S56S60
v60@0:8{vImage_Buffer=^vQQQ}16S48^{__CCColorProfileContext={vImage_Buffer=^vQQQ}{vImage_Buffer=^vQQQ}{vImage_Buffer=^vQQQ}{vImage_Buffer=^vQQQ}iiSS}52
S40@0:8^f16Q24^S32
i72@0:8{vImage_Buffer=^vQQQ}16S48^S52f60^S64
v24@0:8^{__CCColorProfileContext={vImage_Buffer=^vQQQ}{vImage_Buffer=^vQQQ}{vImage_Buffer=^vQQQ}{vImage_Buffer=^vQQQ}iiSS}16
i40@0:8^{__CCColorProfileContext={vImage_Buffer=^vQQQ}{vImage_Buffer=^vQQQ}{vImage_Buffer=^vQQQ}{vImage_Buffer=^vQQQ}iiSS}16S24S28Q32
i152@0:8{vImage_Buffer=^vQQQ}16{vImage_Buffer=^vQQQ}48{vImage_Buffer=^vQQQ}80^{__rgbMinMaxU8=CCCCCC}112^{__rgbMinMaxFloat=ffffff}120S128S132S136^I140C148
i84@0:8{vImage_Buffer=^vQQQ}16{vImage_Buffer=^vQQQ}48C80
i80@0:8{vImage_Buffer=^vQQQ}16{vImage_Buffer=^vQQQ}48
i92@0:8@16Q24{vImage_Buffer=^vQQQ}32^Q64^{__CCBigBox=SSSS[50{__CCCharBox=SSSSS}]}72^{__CCBigBox=SSSS[50{__CCCharBox=SSSSS}]}80C88
v72@0:8@16^{__CCBigBox=SSSS[50{__CCCharBox=SSSSS}]}24{vImage_Buffer=^vQQQ}32C64S68
v32@0:8^{__CCBox=SSSS}16^Q24
i32@0:8^{__CCBox=SSSS}16^Q24
i56@0:8*16S24S28Q32Q40S48S52
{__CCRange=SS}76@0:8{vImage_Buffer=^vQQQ}16S48S52S56S60Q64S72
v156@0:8{vImage_Buffer=^vQQQ}16*48{vImage_Buffer=^vQQQ}56{vImage_Buffer=^vQQQ}88S120S124^{__CCBox=SSSS}128^{__CCBox=SSSS}136^Q144C152
v60@0:8^f16^f24S32S36^B40^f48C56
v84@0:8{vImage_Buffer=^vQQQ}16S48S52S56^{__rgbMinMaxFloat=ffffff}60^f68^f76
i80@0:8{vImage_Buffer=^vQQQ}16f48f52S56^f60^f68C76
I48@0:8^{__CCBigBox=SSSS[50{__CCCharBox=SSSSS}]}16C24^S28^S36B44
v40@0:8Q16Q24Q32
v72@0:8{vImage_Buffer=^vQQQ}16^f48^f56S64S68
v56@0:8^{__CCCharBox=SSSSS}16^{__CCCharBox=SSSSS}24^S32^S40S48S52
S48@0:8^{__CCCharBox=SSSSS}16^{__CCBigBox=SSSS[50{__CCCharBox=SSSSS}]}24^S32^S40
i76@0:8^{__CCBigBox=SSSS[50{__CCCharBox=SSSSS}]}16^{__CCBigBox=SSSS[50{__CCCharBox=SSSSS}]}24C32S36S40C44S48S52^{__CCCharBox=SSSSS}56^{__CCCharBox=SSSSS}64C72
i180@0:8{vImage_Buffer=^vQQQ}16{vImage_Buffer=^vQQQ}48{vImage_Buffer=^vQQQ}80^{__CCBigBox=SSSS[50{__CCCharBox=SSSSS}]}112^{__CCBigBox=SSSS[50{__CCCharBox=SSSSS}]}120^{__CCCharBox=SSSSS}128^{__CCCharBox=SSSSS}136S144S148S152*156C164^S168C176
i52@0:8{vImage_Buffer=^vQQQ}16S48
v60@0:8{vImage_Buffer=^vQQQ}16Q48B56
i24@0:8Q16
i68@0:8^{__CCBigBox=SSSS[50{__CCCharBox=SSSSS}]}16C24S28Q32^{__CCBox=SSSS}40Q48S56*60
i160@0:8@16{vImage_Buffer=^vQQQ}24*56^{__CCBigBox=SSSS[50{__CCCharBox=SSSSS}]}64^{__CCBigBox=SSSS[50{__CCCharBox=SSSSS}]}72{vImage_Buffer=^vQQQ}80{vImage_Buffer=^vQQQ}112^{__rgbMinMaxFloat=ffffff}144C152C156
i88@0:8{vImage_Buffer=^vQQQ}16{vImage_Buffer=^vQQQ}48^S80
@56@0:8{vImage_Buffer=^vQQQ}16^@48
v20@0:8C16
@"CCCharBoxContext"
@64@0:8{shared_ptr<vision::mod::FaceIDModel>=^{FaceIDModel}^{__shared_weak_count}}16@32Q40@48@56
B48@0:8^Q16^Q24@32^@40
B40@0:8^{?=^v^v[4Q][4Q]QQQQQQQQQQi}16@24^@32
B44@0:8^{?=^v^v[4Q][4Q]QQQQQQQQQQi}16@24i32^@36
B40@0:8^{__CVBuffer=}16@24^@32
@"VNEspressoResources"
@40@0:8{_NSRange=QQ}16^@32
@"CRImageReaderOutput"
@44@0:8r^v16Q24@32f40
@28@0:8f16^@20
@"VNContoursObservation"
{vector<float __attribute__((ext_vector_type(2))), std::allocator<float __attribute__((ext_vector_type(2)))>>="__begin_"^"__end_"^"__end_cap_"{__compressed_pair<float * __attribute__((ext_vector_type(2))), std::allocator<float __attribute__((ext_vector_type(2)))>>="__value_"^}}
@"NSIndexPath"
@96@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48f80i84f88f92
@100@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48f80i84f88f92i96
@104@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48f80i84f88f92B96i100
@108@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48f80i84f88f92f96B100i104
@108@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48f80i84f88f92i96B100i104
@112@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48f80i84f88f92f96i100B104i108
B32@0:8@16f24f28
B32@0:8@16f24i28
Q24@0:8@"VNPersonsModel"16
@"<NSObject><NSCopying><NSSecureCoding>"32@0:8@"VNPersonsModel"16Q24
Q32@0:8@"VNPersonsModel"16@"<NSObject><NSCopying><NSSecureCoding>"24
Q32@0:8@"VNPersonsModel"16Q24
@"VNFaceObservation"40@0:8@"VNPersonsModel"16Q24Q32
B48@0:8^Q16^i24@32^@40
B36@0:8^v16i24^@28
{shared_ptr<vision::mod::LandmarkDetectorDNN>="__ptr_"^{LandmarkDetectorDNN}"__cntrl_"^{__shared_weak_count}}
{vector<_Geometry2D_point2D_, std::allocator<_Geometry2D_point2D_>>="__begin_"^{_Geometry2D_point2D_}"__end_"^{_Geometry2D_point2D_}"__end_cap_"{__compressed_pair<_Geometry2D_point2D_ *, std::allocator<_Geometry2D_point2D_>>="__value_"^{_Geometry2D_point2D_}}}
B48@0:8@16@24@32^@40
B60@0:8Q16^^{__CVBuffer}24I32Q36Q44^@52
B64@0:8^{?=[3]}16^{__CVBuffer=}24^{__CVBuffer=}32^{ImageRegistrationCtx_s=}40r^{?=[3]}48^@56
#24@0:8@16
v72@0:8@16@24^{__CVBuffer=}32{vImage_Buffer=^vQQQ}40
v76@0:8@16@24{CGRect={CGPoint=dd}{CGSize=dd}}32f64@68
@"ShotflowDetector"
{shared_ptr<vision::mod::ImageClassifier_HierarchicalModel>=^{ImageClassifier_HierarchicalModel}^{__shared_weak_count}}24@0:8^@16
@28@0:8B16@20
@"VN6B8mkraBUpwUqskMYPtS3"
@56@0:8@16@24@32f40f44Q48
@52@0:8@16@24@32f40Q44
@64@0:8@16@24@32f40f44Q48Q56
@44@0:8@16@24@32f40
@48@0:8@16@24@32f40f44
@"<VNClustererModelQuerying>"
@"<VNClustererModelQuerying><VNClustererModelBuilding>"
{_NSRange=QQ}24@0:8@16
@32@0:8Q16q24
@32@0:8{_NSRange=QQ}16
@48@0:8Q16{CGPoint=dd}24q40
@"CRDocumentOutputRegion"
@"CROutputRegion"
@"NSAttributedString"
@"DDScannerResult"
@"VNObservation"
@"BCSDetectedCode"
@"VCPMotionFlowRequest"
{BufferSizeFormat="width"Q"height"Q"format"I}
@64@0:8r^v16Q24Q32Q40Q48@56
@64@0:8r^v16Q24Q32Q40Q48Q56
@"VNEntityIdentificationModel"
@"<VNEntityIdentificationModelDataSource>"
B52@0:8I16@20@28^{CC_MD5state_st=IIIIII[16I]i}36^@44
@"<VNEntityIdentificationModelDelegate>"
{?="willTrain"b1"didTrain"b1"failedTraining"b1"willDropTrainingData"b1"didDropTrainingData"b1}
@"VNEntityIdentificationModelConfiguration"
@"VNEntityIdentificationModelTrainedModel"
@64@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24B56f60
{tuple<float, float, float>={__tuple_impl<std::__tuple_indices<0, 1, 2>, float, float, float>=fff}}16@0:8
@40@0:8@16f24i28i32i36
@44@0:8{?=^vi}16^v32f40
@40@0:8@16i24i28i32f36
v36@0:8@16i24i28i32
i32@0:8Q16Q24
v52@0:8{vImage_Buffer=^vQQQ}16B48
@52@0:8{vImage_Buffer=^vQQQ}16B48
{vector<std::shared_ptr<espresso_buffer_t>, std::allocator<std::shared_ptr<espresso_buffer_t>>>="__begin_"^v"__end_"^v"__end_cap_"{__compressed_pair<std::shared_ptr<espresso_buffer_t> *, std::allocator<std::shared_ptr<espresso_buffer_t>>>="__value_"^v}}
[10B]
[6[10[2f]]]
Q32@0:8Q16^@24
{CGRect={CGPoint=dd}{CGSize=dd}}24@0:8B16I20
r^{CGPoint=dd}24@0:8B16I20
{CGPoint=dd}24@0:8B16I20
^{__CVBuffer=}28@0:8I16^@20
v56@0:8^{CGPoint=dd}16^{CGPoint=dd}24^{CGPoint=dd}32^{CGPoint=dd}40B48I52
@24@0:8B16I20
d24@0:8B16I20
{CGAffineTransform=dddddd}24@0:8B16I20
r^{CGPath=}24@0:8B16I20
r^24@0:8B16I20
f20@0:8I16
{shared_ptr<vision::mod::ImageDescriptorBufferAbstract>=^{ImageDescriptorBufferAbstract}^{__shared_weak_count}}32@0:8@16^@24
{shared_ptr<vision::mod::ImageDescriptorBufferAbstract>=^{ImageDescriptorBufferAbstract}^{__shared_weak_count}}40@0:8r^v16@24^@32
{unique_ptr<vision::mod::ImageDescriptorProcessorHyperplaneLSH, std::default_delete<vision::mod::ImageDescriptorProcessorHyperplaneLSH>>="__ptr_"{__compressed_pair<vision::mod::ImageDescriptorProcessorHyperplaneLSH *, std::default_delete<vision::mod::ImageDescriptorProcessorHyperplaneLSH>>="__value_"^{ImageDescriptorProcessorHyperplaneLSH}}}
@48@0:8{shared_ptr<vision::mod::FaceID3Model>=^{FaceID3Model}^{__shared_weak_count}}16Q32@40
v32@0:8{CGSize=dd}16
{shared_ptr<vision::mod::FaceBoxPoseAligner<signed char>>="__ptr_"^v"__cntrl_"^{__shared_weak_count}}
@"<VNModelFile>"
^v40@0:8@16^{ObjectTrackerOptions=^^?@i}24^@32
B64@0:8@16^v24{CGSize=dd}32@48^@56
{shared_ptr<vision::mod::ObjectTrackerAbstract>="__ptr_"^{ObjectTrackerAbstract}"__cntrl_"^{__shared_weak_count}}
@120@0:8B16B20^{__CVBuffer=}24@32{CGSize=dd}40{CGSize=dd}56{CGRect={CGPoint=dd}{CGSize=dd}}72@104^@112
@52@0:8Q16@24@32B40@44
{shared_ptr<vision::mod::CamGazePredictor>="__ptr_"^{CamGazePredictor}"__cntrl_"^{__shared_weak_count}}
{shared_ptr<vision::mod::GazeFollowPredictor>="__ptr_"^{GazeFollowPredictor}"__cntrl_"^{__shared_weak_count}}
@"VNImageBuffer"24@0:8^@16
@56@0:8@16@24@32@40@48
@60@0:8@16@24@32@40@48I56
@"VNObservationsCache"
@"VNRequestForensics"
@"VNHomographyTrackerState"
B52@0:8^{CGAffineTransform=dddddd}16@24@32f40^@44
@52@0:8B16@20Q28@36^@44
@"<VNPersonsModelDataDelegate>"
@40@0:8^{__CVBuffer=}16@24@?32
@44@0:8^{__CVBuffer=}16I24@28@?36
@40@0:8^{CGImage=}16@24@?32
@44@0:8^{CGImage=}16I24@28@?36
@40@0:8@16@24@?32
@44@0:8@16I24@28@?36
@40@0:8^{opaqueCMSampleBuffer=}16@24@?32
@44@0:8^{opaqueCMSampleBuffer=}16I24@28@?36
B84@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGSize=dd}48i64^{CGRect={CGPoint=dd}{CGSize=dd}}68^@76
@40@0:8r^{?=^v^v[4Q][4Q]QQQQQQQQQQi}16@24^@32
B32@0:8@16d24
r^Q16@0:8
@32@0:8r^Q16Q24
@48@0:8Q16Q24Q32Q40
{vector<unsigned long, std::allocator<unsigned long>>="__begin_"^Q"__end_"^Q"__end_cap_"{__compressed_pair<unsigned long *, std::allocator<unsigned long>>="__value_"^Q}}
@24@0:8r^{?=*QQQQ}16
B40@0:8@16^@24^@32
@44@0:8^{__CVBuffer=}16I24@28@36
@40@0:8^{CGImage=}16@24@32
@44@0:8^{CGImage=}16I24@28@36
@44@0:8@16I24@28@36
@40@0:8^{opaqueCMSampleBuffer=}16@24@32
@44@0:8^{opaqueCMSampleBuffer=}16I24@28@36
fgla
FNA*
fsba
ytcC
tAFC
eAIC
gmIC
knJC
meMC
10NV
mLPC
20NV
30NV
LMoc
pmna
pted
MRFC
pcaf
pt+f
40NV
rgfi
pgmi
plrn
pncs
pcms
psrt
raBD
tnCD
gSDD
QCFD
mLFD
L3FD
xEFD
zGFD
oPFD
caFD
roHD
PBHD
PHHD
HuHD
RuHD
tPOD
ceRD
zGSD
txTD
jrTD
nAF*
gSAG
StAG
gSFG
PFIG
SmIG
SbOG
FpOG
50NV
gSPG
CSPG
gSSG
iprg
gerh
knuj
rlbi
AmI*
pxei
 pon
inAR
hnAR
D&FR
jbOR
bsOR
txTR
lEDR
coDR
kBmR
necs
5mS*
gmHT
CFLT
jbOT
ceRT
gert
2NA>
3NA>
4NA>
1SA>
1pA>
2pA>
rlB>
trB>
noC>
LMC>
RmI>
DmI>
PeD>
gSD>
3MF>
4MF>
5MF>
ABF>
CFL>
2aF>
xEF>
zGF>
eGF>
2LF>
3LF>
1PF>
1QF>
2QF>
CQF>
MRF>
gSF>
GUG>
1AH>
RIH>
TgH>
zrH>
PBH>
PHH>
AmI>
1NV>
pmI>
gRI>
SmI>
knJ>
meM>
crM>
1pO>
FpO>
1FO>
2FO>
GSP>
4SP>
SSP>
FSP>
LSP>
TSP>
ceR>
kBR>
BAS>
BOS>
ncS>
zGS>
GgS>
pcS>
dlS>
CmS>
5mS>
S+A>
4rT>
7rT>
1rT>
*F+I
 O/R
 O+E
Ixam
I/Em
ogla
*F+I
hgih
f00L
ARGB
doml
ogla
qere
f00L
ARGB
)\O?
333333
Me!>
`Y?*
K/>n
4?Rc
As?@
[?>Y
5?+3A?&S
>;9W?@1
^y>?
>3PI>
j?}Y
?}wG?X
&>CVK?
q'?ep0?
xj>t
>: i?
6:>0
>=`Z?
=aR<>=
aK=e
>A*q?C
t=+jp>B
->g,&?"R;?
>?k}A>}
G?c%
O?Ig
>obp?
$X?7pG>
>h@=>H
\'?`
7?BZg?
{>?q
g?> 
=6rQ?
8?6v
y?F$&?~
L?6X
GS?R
>FA?6Wq?
{?OX
>9{3?1
*?<h6>
?X:/>
XQ?$~
>S\%>o
v#?Y
@#?o+u?
{v>U
*X?S]
>c~j?'
>5)E?
>:u)?w1E?
>}y)?
W?:U?<L
B%?-|
?sc~?
>}>2?
=?!"
6=JCA?
.?m<4?
I>O\R?
Dc?#I
D?R(
LA?:
>R`U?
\?@h}?:
?=`b?
L>h\
??yYS?
>WCB>mq
>k,a=T
a?V)}?
?]m}?
>$%M?
Oi>-
d?6x{?
>|HX?DnV>
>W!E>w
>~t*>+
OU=0cn?
E\?+5o?
)?kb
}?C<
uQ?1A
=Nd6>
Ch=R
Nx>(-\=c)
`I>K9
"~=p
=8hS?.
\)<]pF=
$?OZ
>9`'?
r=?}vp>5&<?-yx? 
R>x~
rj>?V$?
>L?;
E?oI2?
>b1*>
>?pB
>:X'?
C?AcB?
=?Vb>?
>BAY>T
~'> ~*?
d?%=
t?`w
@?5(j>yt
^$?v
-Z?mq
ms?@O
333?
@(#)PROGRAM:RTCV-core-iOS  PROJECT:Vision-6.0.51
@@(#)PROGRAM:RTCV-cvabm-iOS  PROJECT:Vision-6.0.51
@(#)PROGRAM:RTCV-sim-iOS  PROJECT:Vision-6.0.51
@@(#)PROGRAM:RTCV-taptotrack-cyprus-iOS  PROJECT:Vision-6.0.51
@trk
@(#)PROGRAM:TemporalRegistration-iOS  PROJECT:Vision-6.0.51
=ffffff
ffffff
_@ff
(>ff
&1>=
?333333
333333
?333333
?%~E
@mLP
?33s?H
~;>4
9C?f
as?q=
v?vO
333333
?333333
?333333
zd?{
o@UUUUUU
?fff?
33333
 "$&zz
!$'*-0369<?BEHKNQTWZ]`cfilorux{~
 #&),/258;>ADGJMPSVY\_behknqtwz}
,1:AIP
SX^v
:H&M4X
&&&?&F&M
>%iii
%||ii@
%(#+/5;
]cj0
")02
#^#^^^#
.@(#)PROGRAM:Vision  PROJECT:Vision-6.0.51
@NSt3__120__shared_ptr_pointerIPhPFvPvENS_9allocatorIhEEEE
N6vision3mod26ImageDescriptorBufferJointE
NSt3__120__shared_ptr_emplaceIN6vision3mod28ConcreteFaceQualityPredictorENS_9allocatorIS3_EEEE
N6vision3mod29ImageDescriptorBufferAbstractE
N6vision3mod24ObjectTrackerCorrelationE
N5apple6vision29GreedyClusteringParamsWrapperE
N5apple6vision38GreedyClusteringParamsWrapperRevision5E
NSt3__120__shared_ptr_emplaceIN5apple6vision46GreedyClusteringParamsWrapperRevision5ConcreteENS_9allocatorIS3_EEEE
N5apple6vision46GreedyClusteringParamsWrapperRevision5ConcreteE
NSt3__120__shared_ptr_emplaceIN6vision3mod33ObjectDetector_DCNFaceDetector_v2ENS_9allocatorIS3_EEEE
N6vision3mod19TorsoprintGeneratorE
NSt3__120__shared_ptr_emplaceIN6vision3mod27TorsoprintGeneratorConcreteENS_9allocatorIS3_EEEE
N6vision3mod27TorsoprintGeneratorConcreteE
>333>
6>%I
N6vision3mod23ImageClassifierEspressoE
NSt3__120__shared_ptr_emplaceIN6vision3mod23ImageClassifierEspresso9private_tENS_9allocatorIS4_EEEE
NSt3__120__shared_ptr_emplaceIN6vision3mod18LandmarkAttributesENS_9allocatorIS3_EEEE
N6vision3mod33ObjectDetector_DCNFaceDetector_v2E
N6vision3mod22ObjectDetectorAbstractE
NSt3__120__shared_ptr_emplaceIN6vision3mod33ObjectDetector_DCNFaceDetector_v24privENS_9allocatorIS4_EEEE
N5apple6vision11OpticalFlow10LKTCPUImplINS1_13LKTCPUComputeEEE
N5apple6vision11OpticalFlow6LKTCPUE
NSt3__120__shared_ptr_emplaceIN6vision3mod28ImageDescriptor_EspressoJunkENS_9allocatorIS3_EEEE
N6vision3mod28ImageDescriptor_EspressoJunkE
NSt3__120__shared_ptr_pointerIPN6vision3mod18LandmarkAttributesENS_10shared_ptrIS3_E27__shared_ptr_default_deleteIS3_S3_EENS_9allocatorIS3_EEEE
NSt3__110shared_ptrIN6vision3mod18LandmarkAttributesEE27__shared_ptr_default_deleteIS3_S3_EE
NSt3__114default_deleteIN6vision3mod18LandmarkAttributesEEE
f024800L
N6vision3mod28ImageDescriptorBufferFloat32E
NSt3__120__shared_ptr_emplaceIN6vision3mod15FaceFrontalizerENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN6vision3mod16FaceSegmenterDNNENS_9allocatorIS3_EEEE
NSt3__110__function6__funcIZZZ152-[VNFaceDetectorPrivateRevisionLegacyFaceCore internalProcessUsingQualityOfServiceClass:options:regionOfInterest:warningRecorder:error:progressHandler:]EUb_ENK3$_0clEP7CGImageEUlvE_NS_9allocatorIS5_EEFvvEEE
NSt3__110__function6__baseIFvvEEE
ZZZ152-[VNFaceDetectorPrivateRevisionLegacyFaceCore internalProcessUsingQualityOfServiceClass:options:regionOfInterest:warningRecorder:error:progressHandler:]EUb_ENK3$_0clEP7CGImageEUlvE_
?n'O
%5>q
f|:>
?T9W=
>tM>9!
v%?-"
=NSt3__120__shared_ptr_emplaceIN6vision3mod24CamGazePredictorConcreteENS_9allocatorIS3_EEEE
N6vision3mod24GreedyClustererWithTorsoE
N6vision3mod29GreedyClustererFacesWithTorsoE
NSt3__120__shared_ptr_emplaceIN6vision3mod29GreedyClustererFacesWithTorsoENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN6vision3mod24GreedyClustererWithTorso9private_tENS_9allocatorIS4_EEEE
NSt3__120__shared_ptr_emplaceINS_6vectorIjNS_9allocatorIjEEEENS2_IS4_EEEE
NSt3__120__shared_ptr_emplaceINS_6vectorINS_5tupleIJjjfEEENS_9allocatorIS3_EEEENS4_IS6_EEEE
N6vision3mod32ImageDescriptorProcessorEspressoE
NSt3__120__shared_ptr_emplaceIN6vision3mod32ImageDescriptorProcessorEspresso9private_tENS_9allocatorIS4_EEEE
NSt3__120__shared_ptr_pointerIPN5apple6vision9libraries9autotrace12EPolygonListEPFvS6_ENS_9allocatorIS5_EEEE
PFvPN5apple6vision9libraries9autotrace12EPolygonListEE
FvPN5apple6vision9libraries9autotrace12EPolygonListEE
NSt3__120__shared_ptr_emplaceIN6vision3mod13FaceRegionMapENS_9allocatorIS3_EEEE
~|zxvuusqpnmkjiggfecba`_^]]\[ZYXWVUTTSRQQPONNMMLKKJIIHGGGFFEDDCCBBBAA@@??>>===<<;;:::999888776666555444333322211110000////.....----,,,,+++++*****)))))((((('''''''&&&&&&%%%%%%$$$$$$$########""""""!!!!!!!!!        
+>>%I
N6vision3mod15ObjectTrackerExE
yA$H
ITCA
vA,2
q@,2
5mAv<
9Bh6
Df00Lh00L800L
NSt3__120__shared_ptr_emplaceIN6vision3mod22ImageClassifierGlimmerENS_9allocatorIS3_EEEE
NSt3__110__function6__funcIZN6vision3mod14broadcastMinusIdLm16EEEvRKNS3_10CVMLMatrixIT_XT0_EEERKNS3_10CVMLVectorIS6_XT0_EEEiRS7_bEUlddE_NS_9allocatorISF_EEFdddEEE
NSt3__110__function6__baseIFdddEEE
ZN6vision3mod14broadcastMinusIdLm16EEEvRKNS0_10CVMLMatrixIT_XT0_EEERKNS0_10CVMLVectorIS3_XT0_EEEiRS4_bEUlddE_
NSt3__110__function6__funcIZN6vision3mod12broadcastAddIdLm16EEEvRKNS3_10CVMLMatrixIT_XT0_EEERKNS3_10CVMLVectorIS6_XT0_EEEiRS7_bEUlddE_NS_9allocatorISF_EEFdddEEE
ZN6vision3mod12broadcastAddIdLm16EEEvRKNS0_10CVMLMatrixIT_XT0_EEERKNS0_10CVMLVectorIS3_XT0_EEEiRS4_bEUlddE_
N6vision3mod32FeatureSignSparseCoder_bad_allocE
N6vision3mod31ColorGaborImageDescriptorBufferE
N6vision3mod34ColorGaborImageDescriptorProcessorE
NSt3__120__shared_ptr_emplaceIN6vision3mod31ColorGaborImageDescriptorBufferENS_9allocatorIS3_EEEE
NSt3__110__function6__funcINS_6__bindIRFxP7__sFILEPKcRNS_3mapINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_6vectorIfNSB_IfEEEENS_4lessISD_EENSB_INS_4pairIKSD_SG_EEEEEEEJRKNS_12placeholders4__phILi1EEERKNSS_ILi2EEERKNSS_ILi3EEEEEENSB_IS12_EESP_EE
NSt3__110__function6__baseIFxP7__sFILEPKcRNS_3mapINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_6vectorIfNSA_IfEEEENS_4lessISC_EENSA_INS_4pairIKSC_SF_EEEEEEEEE
NSt3__16__bindIRFxP7__sFILEPKcRNS_3mapINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_6vectorIfNS9_IfEEEENS_4lessISB_EENS9_INS_4pairIKSB_SE_EEEEEEEJRKNS_12placeholders4__phILi1EEERKNSQ_ILi2EEERKNSQ_ILi3EEEEEE
NSt3__118__weak_result_typeIPFxP7__sFILEPKcRNS_3mapINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_6vectorIfNS9_IfEEEENS_4lessISB_EENS9_INS_4pairIKSB_SE_EEEEEEEEE
NSt3__110__function6__funcINS_6__bindIRFmmEJRKNS_12placeholders4__phILi1EEEEEENS_9allocatorISA_EES3_EE
NSt3__110__function6__baseIFmmEEE
NSt3__16__bindIRFmmEJRKNS_12placeholders4__phILi1EEEEEE
NSt3__118__weak_result_typeIPFmmEEE
NSt3__114unary_functionImmEE
NSt3__110__function6__funcINS_6__bindIRFxRKNS_3mapINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_6vectorIfNS7_IfEEEENS_4lessIS9_EENS7_INS_4pairIKS9_SC_EEEEEERKSC_RSC_EJRKNS_12placeholders4__phILi1EEERKNSS_ILi2EEERKNSS_ILi3EEEEEENS7_IS12_EESP_EE
NSt3__110__function6__baseIFxRKNS_3mapINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_6vectorIfNS6_IfEEEENS_4lessIS8_EENS6_INS_4pairIKS8_SB_EEEEEERKSB_RSB_EEE
NSt3__16__bindIRFxRKNS_3mapINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_6vectorIfNS5_IfEEEENS_4lessIS7_EENS5_INS_4pairIKS7_SA_EEEEEERKSA_RSA_EJRKNS_12placeholders4__phILi1EEERKNSQ_ILi2EEERKNSQ_ILi3EEEEEE
NSt3__118__weak_result_typeIPFxRKNS_3mapINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_6vectorIfNS5_IfEEEENS_4lessIS7_EENS5_INS_4pairIKS7_SA_EEEEEERKSA_RSA_EEE
NSt3__120__shared_ptr_emplaceIN6vision3mod21ImageAnalyzerConcreteENS_9allocatorIS3_EEEE
NSt3__111__end_stateIcEE
NSt3__16__nodeIcEE
NSt3__120__shared_ptr_pointerIPNS_13__empty_stateIcEENS_10shared_ptrIS2_E27__shared_ptr_default_deleteIS2_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrINS_13__empty_stateIcEEE27__shared_ptr_default_deleteIS2_S2_EE
NSt3__114default_deleteINS_13__empty_stateIcEEEE
NSt3__113__empty_stateIcEE
NSt3__116__owns_one_stateIcEE
NSt3__115__has_one_stateIcEE
NSt3__120__l_anchor_multilineIcEE
NSt3__120__r_anchor_multilineIcEE
NSt3__115__word_boundaryIcNS_12regex_traitsIcEEEE
NSt3__111__lookaheadIcNS_12regex_traitsIcEEEE
NSt3__123__match_any_but_newlineIcEE
NSt3__118__match_char_icaseIcNS_12regex_traitsIcEEEE
NSt3__120__match_char_collateIcNS_12regex_traitsIcEEEE
NSt3__112__match_charIcEE
NSt3__116__back_ref_icaseIcNS_12regex_traitsIcEEEE
NSt3__118__back_ref_collateIcNS_12regex_traitsIcEEEE
NSt3__110__back_refIcEE
NSt3__120__bracket_expressionIcNS_12regex_traitsIcEEEE
NSt3__128__begin_marked_subexpressionIcEE
NSt3__126__end_marked_subexpressionIcEE
NSt3__16__loopIcEE
NSt3__117__owns_two_statesIcEE
NSt3__117__repeat_one_loopIcEE
NSt3__111__alternateIcEE
NSt3__121__empty_non_own_stateIcEE
NSt3__111__match_anyIcEE
N5apple6vision11OpticalFlow6LKTCPU19AllocationExceptionE
N5apple6vision11OpticalFlow6LKTCPU27InvalidPixelFormatExceptionE
?2w-!
?O#-
?o/i
?`vO
?+0du
_{fI
tYLl>
?A+0du
++MJ
?S?o*Ra
?G=D
? <
?S\U
|a2U
?G8-x
??5^
?o*Ral!
tYLl
?gDio
?h?RD
?|DL
?pB!
FZ*o
?@M-[
#bJ$Q
?p%;6
FZ*oG
?+5{
?%]3
_{fI
?`vO
h"lx
?%]3
?U0*
?pB!
?Mg'
?a2U0*
o%;6
?,+MJA
?Ral!
?o*Ral!
?8J^
?Dio
?:#J{
?q $
$#ga
?{Ic
?scz
?o*Ral!
?U0*
?S?o*Ra
?Dio
8b->
?o/i
R?o*
?G8-x
?G8-x
?2ZGU
?Z*oG8-
?MJA
R?o*R
?`vO
_{fI
FZ*o
$#gaO
?{fI
?N6vision3mod12_GLOBAL__N_119BoxAlignerExceptionE
NSt3__120__shared_ptr_emplaceIN6vision3mod27GazeFollowPredictorConcreteENS_9allocatorIS3_EEEE
NSt3__110__function6__funcIZN6vision3mod14broadcastMinusIfLm16EEEvRKNS3_10CVMLMatrixIT_XT0_EEERKNS3_10CVMLVectorIS6_XT0_EEEiRS7_bEUlffE_NS_9allocatorISF_EEFfffEEE
NSt3__110__function6__baseIFfffEEE
ZN6vision3mod14broadcastMinusIfLm16EEEvRKNS0_10CVMLMatrixIT_XT0_EEERKNS0_10CVMLVectorIS3_XT0_EEEiRS4_bEUlffE_
NSt3__110__function6__funcIZN6vision3mod12broadcastAddIfLm16EEEvRKNS3_10CVMLMatrixIT_XT0_EEERKNS3_10CVMLVectorIS6_XT0_EEEiRS7_bEUlffE_NS_9allocatorISF_EEFfffEEE
ZN6vision3mod12broadcastAddIfLm16EEEvRKNS0_10CVMLMatrixIT_XT0_EEERKNS0_10CVMLVectorIS3_XT0_EEEiRS4_bEUlffE_
NSt3__110__function6__funcIZ13polynomialFitPKdS3_mmS3_S3_S3_E3$_0NS_9allocatorIS4_EEFNS_6vectorIdNS5_IdEEEEdEEE
NSt3__110__function6__baseIFNS_6vectorIdNS_9allocatorIdEEEEdEEE
Z13polynomialFitPKdS0_mmS0_S0_S0_E3$_0
Q9RI
Q9RI
7:RI
Q9RI
d*;4
>;_)K;
DX;B`e;
{r;l
k;B`e;
Q;_)K;
#;RI
7:RI
Q9RI
d*;4
7;_)K;
DX;B`e;
{r;o
{r;B`e;
DX;_)K;4
d*;RI
7:RI
Q9RI
7;_)K;
y;KY
3"<U
-<X94<
b<B`e<
4o<E
{r<!
ew<l
{r<E
h<B`e<e
#9<X94<
3"<RI
^;_)K;4
7:RI
Q9RI
k;KY
Q:RI
Q9RI
k:RI
DX;$
d*<4
?F<4
DX;4
Q:RI
>;B`e;'
#<X94<
z<KY
$=yX(=V
7=5^:=[
2D=]mE=
?F=]mE=
2D=\
<=5^:=
-2=2
+=yX(=
D<X94<
;B`e;
>;RI
{r<&
=R' =T
b=B`e=B>h=h
4o= Aq=
{r=F
{r= Aq=
(m=h
j=B>h=B`e=e
WJ=9
E6=|
%=R' =Qk
k:RI
7;B`e;
?$=V
b=B>h=D
s=Gry=
\~=n
\~=Gry=F
m=B>h=e
?$=v
;B`e;4
DX;'
3"<4
=R' =U
(=W[1=Z
B=_)K=a
S=d]\=
d=d]\=a
S=_)K=\
9=W[1=U
(=R' =P
j<<b
ew=I
{r<b
j<<>
ew<M
ew<>
=yX(=
A=;pN=
h=k+v=n
=k+v=
[=;pN=
5=yX(=
ew<b
7:RI
{r<M
7x=J{
/>:#
O/<N
=yX(=Y
U=B`e=
9#>/
$>0L&>
d*>1
'>0L&>/
Yu=B`e=
?F=Y
7=yX(=u
7;KY
=z6+=
/;=:
K=d]\=D
m=I.
V,>i
9>lx:>
<>6<=>
=>6<=>
;>lx:>l
u1>i
V,>
m=d]\=:
/;=z6+=
;_)K;
{r<)\
q,=6<==
Ga=F
s=J{
u >/
!N>`vO>
|P>`vO>
2D>7
~;>~
N=6<==
;_)K;o
<X94<
=z6+=6<==
ew=o
G!>ff&>
+>io0>F%5>
9>[B>>%uB>
qJ>_
QZ>?
+e>x
F>%uB>[B>>
9>F%5>io0>
+>ff&>
P=6<==z6+=u
/]<X94<r
Q9RI
{r<N
=yX(=
x=p_
/>aT
X>RI]>
Ga>f
n>W[q>}
=y>lxz>Zd{>
|>HP|>HP|>
|>Zd{>lxz>
s>W[q>
rh>f
Ga>RI]>P
/>o
/;=yX(=
y;RI
d*;KY
d*<b
ew=p_
2>Gr9>[
sW>v
8g>1
|>n4
3b>v
?>Gr9>
%>d;
Ga=:
d*<o
?F=d]\=F
8V>?
c>gDi>
t>5^z>$
>5^z>
4o>gDi>
s=d]\=
<;p
:_)K;RI
=yX(=
m=J{
P>>yX>
_>>yX>
kI>n
v>=yX(=
;_)K;
T<KY
L=B`e=I.
..>}
6>I.?>
h>iop>~
x>iop>
DX>r
G>I.?>}
c>]
=B`e=
;B`e;X9
c<)\
>B>(>W[1>lx:>
C>lx:>W[1>B>(>-!
;B`e;o
5=;pN=
>R' >z
!=>]
|P>]
g3>z
)>R' >b
xi=;pN=
{r;'
>R' >
m4>m
ZS>-
-r>HP|>
>HP|>
J*>R' >
?F<N
h=J{
H?>:#J>+
U>:#J>
m4>z
)>-!
=R' =
sW=k+v=(
>B>(>
g3>m
>>:#J>=
U>w-a>
l>w-a>=
U>:#J>m
g3>B>(>
=k+v=
:=R' =
#<B`
d*;u
Sc=n
%>W[1>
U>w-a>
\m>~
\m>w-a>+
!=>W[1>
Jj<1
d*;RI
=W[1=
..>lx:>]
ZS>]
F>lx:>
AO=W[1=
5<HP
7;RI
|P>-
:_)K;|
?$=\
Sc=o
/>>y
2>I.?>_
6Z>_
L>I.?>
%>>y
/>n4
Sc=\
;_)K;4
+=_)K=
(m=p
q,>#
q?_
q?h
q,>d;
(m=_)K=V
ew=r
\m>HP|>
c?r
>HP|>
%>>y
ew=a
2=tF
:B`e;
9=d]\=I
=d]\=Z
9=Qk
u`<RI
;B`e;
=R' =
d=&S
:p>7
R&?t
@=R' =
l=q=
~*>Gr9>p
H>>yX>
f%?=
+?-C,?
,?-C,?
h>>yX>p
H>Gr9>
{r<U
:0>[
_>iop>I
;.?{
;.?$
@"?$
>iop>
G!><
;X94<
fU=$
>ff&>
y'?u
c,?r
0?EG2?}
7?^K8?Y
8?^K8?
+5?}
3?EG2?
c,?u
y'?j
8V>9
5>ff&>
fU=|
<X94<B`
?n4 ?
,?I./?
1?I./?D
#?n4 ?
E6=tF
u >io0>
t>J{
$?B>(?
1?X94?
6?X94?
+?B>(?
@>io0>
@=B>h=
$>F%5>
sW>gDi>
V?E
%?gD)?
,?R'0?
S3?0L6?
>?R'@?
8E?a
B?R'@?_
9?0L6?
S3?R'0?
,?gD)?"
V?0
~{>gDi>
F>F%5>/
=B>h=
B<HP
41?4
=?io@?
H?q=J?
~K?(~L?6<M?H
M?6<M?(~L?
~K?q=J?U
B?io@?d
41?h
4o>v
WJ=F
s=Nb
->[B>>r
4!?"
1?]m5?
I<?Di??aTB?
O?2UP?
aQ?2UP?
E?aTB?Di??
8?]m5?
3b>r
O>[B>>V
=yX(=
N=Gry=*
0>%uB>
8g>5^z>
?n4 ?
$?gD)?h
F?GrI?
HN?2UP?
&R?F
V?p_W?
W?p_W?
&R?2UP?
K?GrI?}
-?gD)?
$?n4 ?
>5^z>
T>%uB>|
=Gry=
N=yX(=
Q<KY
S#>4
#?B>(?
41?]m5?c
A?o
X?GrY?
Z??W[?
[?h"\?h"\?
[??W[?
Z?GrY?~
\=?c
9?]m5?
,?B>(?
S#><
ZS=V
Y<RI
sW=n
qJ>RI]>
+?R'0?4
D?yXH?q
Q?tFT?}
Z?HP\?
_?R'`?
h`?R'`?$
]?HP\?h
V?tFT?n
K?yXH?
4?R'0?
p>RI]>
qJ>~
sW=2
<RI
~;>_
|@?o
D?yXH?
UO?A
R?]mU?~
c?=,d?Ttd?Ttd?=,d?
X?]mU?A
K?yXH?o
Ga>_
~;>
y'?D
1?0L6?
:?Di??
UO?X
.^?Nb`?aTb?
d?]me?
eg?+
Dh?+
f?]me?
d?aTb?Nb`?
UO?q
C?Di??
:?0L6?
V,>,
<B`e<
b='1
rh>[
*?I./?X94?
=?aTB?}
U?gDY?
I\?gDY?
F?aTB?d
9?X94?I./?u
rh>O
/>G
<B`e<
=5^:=B`e=q=
k>n4
;?io@?
E?GrI?
Q?]mU?
&b?O
(l?mVm??5n?
n??5n?mVm?
X?]mU?n
M?GrI?
E?io@?
=B`e=5^:=
<=B>h=
q?aT
:P?tFT?~
m?-!o?
Np?-!o?
X?tFT?
a!>r
=B>h=[
4o<z6
9#>X
\>W[q>
f%?
;?R'@?
g?U0j?
n?2Up?N
q?2Up?
l?U0j?
E?R'@?C
>W[q>?
(m=M
G!?=
,?EG2?
K?2UP?O
\?Nb`?}
?t?]mu?KYv?
v?KYv?]mu?
?t?<
c?Nb`?$
T?2UP?
7?EG2?$
G!?Zd
{r<V}
>0L&>l
;.?}
&R?+
^?aTb?
t?KYv?
w?>yx?
y?,ey?,ey?
y?>yx?
w?KYv?
e?aTb?
J9?}
9>0L&>tF
4o=\
B=Qk
2D= Aq=
'>lx:>
!N>x
8E?q=J?
X?HP\?
m?2Up?<
v?'1x?
ky?'1x?
r?2Up?
H`?HP\?~
O?q=J?
+5?{
!N>lx:>
= Aq=
t<RI
=]mE=
;>`vO>x
~K?2UP?
U?GrY?
a?]me?5
(l?-!o?N
?t?KYv?'1x?^
{?(~|?
|?(~|?
y?'1x?KYv?
?t?N
q?-!o?
(l?5
h?]me?
]?GrY?
U?2UP?
=y>x
d>`vO>
{r=]mE=
u<RI
ew<3
?F=F
+e>lxz>B>
eG?(~L?
aQ?4
j?mVm?
Np?S
s?]mu?
/|?q
w?]mu?S
Np?mVm?
aQ?(~L?
>lxz>
^)>=
?F=RI
)>6<=>
e>Zd{>9
R&?-C,?
$H?6<M?
V??W[?$
eg?c
j??5n?
s?KYv?>yx?
Wz?>yx?KYv?
4q??5n?c
_??W[?
&R?6<M?
2?-C,?
A ?:#
>Zd{>
4Q>6<=>
Yu=*
2?^K8?
R?p_W?
[?R'`?=,d?+
z?(~|?H
}?(~|?
g?=,d?R'`?
[?p_W?
=?^K8?\
d*>+
f>HP|>L7
W?h"\?
h`?Ttd?
Dh?6
>w?,ey?
C{?,ey?
Dh?Ttd?
h`?h"\?
!>?Y
>HP|>B
 <X9
f>HP|>L7
W?h"\?
h`?Ttd?
Dh?6
>w?,ey?
C{?,ey?
Dh?Ttd?
h`?h"\?
!>?Y
>HP|>B
 <X9
Yu=*
2?^K8?
R?p_W?
[?R'`?=,d?+
z?(~|?H
}?(~|?
g?=,d?R'`?
[?p_W?
=?^K8?\
d*>+
)>6<=>
e>Zd{>9
R&?-C,?
$H?6<M?
V??W[?$
eg?c
j??5n?
s?KYv?>yx?
Wz?>yx?KYv?
4q??5n?c
_??W[?
&R?6<M?
2?-C,?
A ?:#
>Zd{>
4Q>6<=>
ew<3
?F=F
+e>lxz>B>
eG?(~L?
aQ?4
j?mVm?
Np?S
s?]mu?
/|?q
w?]mu?S
Np?mVm?
aQ?(~L?
>lxz>
^)>=
?F=RI
=]mE=
;>`vO>x
~K?2UP?
U?GrY?
a?]me?5
(l?-!o?N
?t?KYv?'1x?^
{?(~|?
|?(~|?
y?'1x?KYv?
?t?N
q?-!o?
(l?5
h?]me?
]?GrY?
U?2UP?
=y>x
d>`vO>
{r=]mE=
u<RI
2D= Aq=
'>lx:>
!N>x
8E?q=J?
X?HP\?
m?2Up?<
v?'1x?
ky?'1x?
r?2Up?
H`?HP\?~
O?q=J?
+5?{
!N>lx:>
= Aq=
t<RI
{r<V}
>0L&>l
;.?}
&R?+
^?aTb?
t?KYv?
w?>yx?
y?,ey?,ey?
y?>yx?
w?KYv?
e?aTb?
J9?}
9>0L&>tF
4o=\
B=Qk
(m=M
G!?=
,?EG2?
K?2UP?O
\?Nb`?}
?t?]mu?KYv?
v?KYv?]mu?
?t?<
c?Nb`?$
T?2UP?
7?EG2?$
G!?Zd
4o<z6
9#>X
\>W[q>
f%?
;?R'@?
g?U0j?
n?2Up?N
q?2Up?
l?U0j?
E?R'@?C
>W[q>?
<=B>h=
q?aT
:P?tFT?~
m?-!o?
Np?-!o?
X?tFT?
a!>r
=B>h=[
=5^:=B`e=q=
k>n4
;?io@?
E?GrI?
Q?]mU?
&b?O
(l?mVm??5n?
n??5n?mVm?
X?]mU?n
M?GrI?
E?io@?
=B`e=5^:=
<B`e<
b='1
rh>[
*?I./?X94?
=?aTB?}
U?gDY?
I\?gDY?
F?aTB?d
9?X94?I./?u
rh>O
/>G
<B`e<
y'?D
1?0L6?
:?Di??
UO?X
.^?Nb`?aTb?
d?]me?
eg?+
Dh?+
f?]me?
d?aTb?Nb`?
UO?q
C?Di??
:?0L6?
V,>,
~;>_
|@?o
D?yXH?
UO?A
R?]mU?~
c?=,d?Ttd?Ttd?=,d?
X?]mU?A
K?yXH?o
Ga>_
~;>
Y<RI
sW=n
qJ>RI]>
+?R'0?4
D?yXH?q
Q?tFT?}
Z?HP\?
_?R'`?
h`?R'`?$
]?HP\?h
V?tFT?n
K?yXH?
4?R'0?
p>RI]>
qJ>~
sW=2
<RI
S#>4
#?B>(?
41?]m5?c
A?o
X?GrY?
Z??W[?
[?h"\?h"\?
[??W[?
Z?GrY?~
\=?c
9?]m5?
,?B>(?
S#><
ZS=V
=yX(=
N=Gry=*
0>%uB>
8g>5^z>
?n4 ?
$?gD)?h
F?GrI?
HN?2UP?
&R?F
V?p_W?
W?p_W?
&R?2UP?
K?GrI?}
-?gD)?
$?n4 ?
>5^z>
T>%uB>|
=Gry=
N=yX(=
Q<KY
WJ=F
s=Nb
->[B>>r
4!?"
1?]m5?
I<?Di??aTB?
O?2UP?
aQ?2UP?
E?aTB?Di??
8?]m5?
3b>r
O>[B>>V
41?4
=?io@?
H?q=J?
~K?(~L?6<M?H
M?6<M?(~L?
~K?q=J?U
B?io@?d
41?h
4o>v
@=B>h=
$>F%5>
sW>gDi>
V?E
%?gD)?
,?R'0?
S3?0L6?
>?R'@?
8E?a
B?R'@?_
9?0L6?
S3?R'0?
,?gD)?"
V?0
~{>gDi>
F>F%5>/
=B>h=
B<HP
u >io0>
t>J{
$?B>(?
1?X94?
6?X94?
+?B>(?
@>io0>
?n4 ?
,?I./?
1?I./?D
#?n4 ?
E6=tF
;X94<
fU=$
>ff&>
y'?u
c,?r
0?EG2?}
7?^K8?Y
8?^K8?
+5?}
3?EG2?
c,?u
y'?j
8V>9
5>ff&>
fU=|
<X94<B`
:0>[
_>iop>I
;.?{
;.?$
@"?$
>iop>
G!><
l=q=
~*>Gr9>p
H>>yX>
f%?=
+?-C,?
,?-C,?
h>>yX>p
H>Gr9>
{r<U
=R' =
d=&S
:p>7
R&?t
@=R' =
:B`e;
9=d]\=I
=d]\=Z
9=Qk
u`<RI
;B`e;
ew=r
\m>HP|>
c?r
>HP|>
%>>y
ew=a
2=tF
+=_)K=
(m=p
q,>#
q?_
q?h
q,>d;
(m=_)K=V
:_)K;|
?$=\
Sc=o
/>>y
2>I.?>_
6Z>_
L>I.?>
%>>y
/>n4
Sc=\
;_)K;4
|P>-
=W[1=
..>lx:>]
ZS>]
F>lx:>
AO=W[1=
5<HP
7;RI
d*;u
Sc=n
%>W[1>
U>w-a>
\m>~
\m>w-a>+
!=>W[1>
Jj<1
d*;RI
=R' =
sW=k+v=(
>B>(>
g3>m
>>:#J>=
U>w-a>
l>w-a>=
U>:#J>m
g3>B>(>
=k+v=
:=R' =
#<B`
h=J{
H?>:#J>+
U>:#J>
m4>z
)>-!
>R' >
m4>m
ZS>-
-r>HP|>
>HP|>
J*>R' >
?F<N
5=;pN=
>R' >z
!=>]
|P>]
g3>z
)>R' >b
xi=;pN=
{r;'
;B`e;X9
c<)\
>B>(>W[1>lx:>
C>lx:>W[1>B>(>-!
;B`e;o
T<KY
L=B`e=I.
..>}
6>I.?>
h>iop>~
x>iop>
DX>r
G>I.?>}
c>]
=B`e=
:_)K;RI
=yX(=
m=J{
P>>yX>
_>>yX>
kI>n
v>=yX(=
;_)K;
?F=d]\=F
8V>?
c>gDi>
t>5^z>$
>5^z>
4o>gDi>
s=d]\=
<;p
d*;KY
d*<b
ew=p_
2>Gr9>[
sW>v
8g>1
|>n4
3b>v
?>Gr9>
%>d;
Ga=:
d*<o
Q9RI
{r<N
=yX(=
x=p_
/>aT
X>RI]>
Ga>f
n>W[q>}
=y>lxz>Zd{>
|>HP|>HP|>
|>Zd{>lxz>
s>W[q>
rh>f
Ga>RI]>P
/>o
/;=yX(=
y;RI
<X94<
=z6+=6<==
ew=o
G!>ff&>
+>io0>F%5>
9>[B>>%uB>
qJ>_
QZ>?
+e>x
F>%uB>[B>>
9>F%5>io0>
+>ff&>
P=6<==z6+=u
/]<X94<r
;_)K;
{r<)\
q,=6<==
Ga=F
s=J{
u >/
!N>`vO>
|P>`vO>
2D>7
~;>~
N=6<==
;_)K;o
7;KY
=z6+=
/;=:
K=d]\=D
m=I.
V,>i
9>lx:>
<>6<=>
=>6<=>
;>lx:>l
u1>i
V,>
m=d]\=:
/;=z6+=
=yX(=Y
U=B`e=
9#>/
$>0L&>
d*>1
'>0L&>/
Yu=B`e=
?F=Y
7=yX(=u
{r<M
7x=J{
/>:#
O/<N
=yX(=
A=;pN=
h=k+v=n
=k+v=
[=;pN=
5=yX(=
ew<b
7:RI
j<<>
ew<M
ew<>
j<<b
ew=I
{r<b
DX;'
3"<4
=R' =U
(=W[1=Z
B=_)K=a
S=d]\=
d=d]\=a
S=_)K=\
9=W[1=U
(=R' =P
7;B`e;
?$=V
b=B>h=D
s=Gry=
\~=n
\~=Gry=F
m=B>h=e
?$=v
;B`e;4
{r<&
=R' =T
b=B`e=B>h=h
4o= Aq=
{r=F
{r= Aq=
(m=h
j=B>h=B`e=e
WJ=9
E6=|
%=R' =Qk
k:RI
>;B`e;'
#<X94<
z<KY
$=yX(=V
7=5^:=[
2D=]mE=
?F=]mE=
2D=\
<=5^:=
-2=2
+=yX(=
D<X94<
;B`e;
>;RI
DX;$
d*<4
?F<4
DX;4
Q:RI
Q9RI
k:RI
Q9RI
k;KY
Q:RI
Q9RI
7;_)K;
y;KY
3"<U
-<X94<
b<B`e<
4o<E
{r<!
ew<l
{r<E
h<B`e<e
#9<X94<
3"<RI
^;_)K;4
7:RI
Q9RI
d*;4
7;_)K;
DX;B`e;
{r;o
{r;B`e;
DX;_)K;4
d*;RI
7:RI
Q9RI
d*;4
>;_)K;
DX;B`e;
{r;l
k;B`e;
Q;_)K;
#;RI
7:RI
Q9RI
7:RI
Q9RI
N6vision3mod22ImageClassifierGlimmerE
N6vision3mod23ImageClassifierAbstractE
NSt3__120__shared_ptr_emplaceIN6vision3mod22ImageClassifierGlimmer9private_tENS_9allocatorIS4_EEEE
N6vision3mod20ObjectTrackerOptionsE
N6vision3mod21ObjectTrackerAbstractE
NSt3__120__shared_ptr_pointerIPN6vision3mod20ObjectTrackerOptionsENS_10shared_ptrIS3_E27__shared_ptr_default_deleteIS3_S3_EENS_9allocatorIS3_EEEE
NSt3__110shared_ptrIN6vision3mod20ObjectTrackerOptionsEE27__shared_ptr_default_deleteIS3_S3_EE
NSt3__114default_deleteIN6vision3mod20ObjectTrackerOptionsEEE
NSt3__120__shared_ptr_emplaceIN4cvml4util23mapped_model_file_fopenENS_9allocatorIS3_EEEE
N4cvml4util23mapped_model_file_fopenE
N4cvml4util17mapped_model_fileE
NSt3__117bad_function_callE
NSt3__120__shared_ptr_emplaceIN4cvml4util22mapped_model_file_openENS_9allocatorIS3_EEEE
N4cvml4util22mapped_model_file_openE
N5apple6vision20CVPixelBufferWrapper13LockExceptionE
PN6vision3mod31ColorGaborImageDescriptorBufferE
Q8@'1
E@q=
4B333?
N6vision3mod20EspressoFloatElemPtrE
N6vision3mod15EspressoElemPtrE
N6vision3mod21EspressoUint16ElemPtrE
N6vision3mod20EspressoUint8ElemPtrE
NSt3__120__shared_ptr_pointerIPN6vision3mod30ImageAnalyzer_CustomClassifierENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIN6vision3mod30ImageAnalyzer_CustomClassifierEEE
NSt3__120__shared_ptr_emplaceINS_6vectorINS_10shared_ptrIN6vision3mod30ImageAnalyzer_CustomClassifierEEENS_9allocatorIS6_EEEENS7_IS9_EEEE
NSt3__120__shared_ptr_emplaceIKNS_6vectorINS_5tupleIJNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEfbEEENS6_IS9_EEEENS6_ISC_EEEE
NSt3__120__shared_ptr_emplaceIN6vision3mod33ImageClassifier_HierarchicalModelENS_9allocatorIS3_EEEE
N6vision3mod37ImageDescriptorProcessorHyperplaneLSHE
NSt3__120__shared_ptr_pointerIPN6vision3mod21ObjectTrackerAbstractENS_10shared_ptrIS3_E27__shared_ptr_default_deleteIS3_S3_EENS_9allocatorIS3_EEEE
NSt3__110shared_ptrIN6vision3mod21ObjectTrackerAbstractEE27__shared_ptr_default_deleteIS3_S3_EE
NSt3__114default_deleteIN6vision3mod21ObjectTrackerAbstractEEE
NSt3__120__shared_ptr_emplaceIN6vision3mod11FaceIDModelENS_9allocatorIS3_EEEE
?N6vision3mod13CVMLCancellerE
NSt3__120__shared_ptr_emplaceIN6vision3mod30ConcreteFaceprintAndAttributesENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_pointerIPN6vision3mod28ImageDescriptorBufferFloat32ENS_10shared_ptrIS3_E27__shared_ptr_default_deleteIS3_S3_EENS_9allocatorIS3_EEEE
NSt3__110shared_ptrIN6vision3mod28ImageDescriptorBufferFloat32EE27__shared_ptr_default_deleteIS3_S3_EE
NSt3__114default_deleteIN6vision3mod28ImageDescriptorBufferFloat32EEE
NSt3__120__shared_ptr_pointerIPfPFvPvENS_9allocatorIfEEEE
PFvPvE
FvPvE
3ForMFor
NSt3__120__shared_ptr_emplaceIN6vision3mod19LandmarkDetectorDNNENS_9allocatorIS3_EEEE
N6vision3mod15GreedyClustererE
N6vision3mod20GreedyClustererFacesE
N6vision3mod14FaceClusteringE
NSt3__120__shared_ptr_pointerIPN4cvml4util12BackedBufferINS2_15RAMBackingStoreEEENS_10shared_ptrIS5_E27__shared_ptr_default_deleteIS5_S5_EENS_9allocatorIS5_EEEE
NSt3__110shared_ptrIN4cvml4util12BackedBufferINS2_15RAMBackingStoreEEEE27__shared_ptr_default_deleteIS5_S5_EE
NSt3__114default_deleteIN4cvml4util12BackedBufferINS2_15RAMBackingStoreEEEEE
NSt3__120__shared_ptr_pointerIPN4cvml4util15RAMBackingStoreENS_10shared_ptrIS3_E27__shared_ptr_default_deleteIS3_S3_EENS_9allocatorIS3_EEEE
NSt3__110shared_ptrIN4cvml4util15RAMBackingStoreEE27__shared_ptr_default_deleteIS3_S3_EE
NSt3__114default_deleteIN4cvml4util15RAMBackingStoreEEE
NSt3__120__shared_ptr_pointerIPKN4cvml4util12BackedBufferINS2_15RAMBackingStoreEEENS_10shared_ptrIS6_E27__shared_ptr_default_deleteIS6_S6_EENS_9allocatorIS6_EEEE
NSt3__110shared_ptrIKN4cvml4util12BackedBufferINS2_15RAMBackingStoreEEEE27__shared_ptr_default_deleteIS6_S6_EE
NSt3__114default_deleteIKN4cvml4util12BackedBufferINS2_15RAMBackingStoreEEEEE
NSt3__120__shared_ptr_emplaceINS_6vectorIhNS_9allocatorIhEEEENS2_IS4_EEEE
NSt3__120__shared_ptr_emplaceIN6vision3mod20GreedyClustererFacesENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN6vision3mod15GreedyClusterer9private_tENS_9allocatorIS4_EEEE
NSt3__120__shared_ptr_emplaceINS_6vectorImNS_9allocatorImEEEENS2_IS4_EEEE
NSt3__120__shared_ptr_emplaceINS_6vectorINS_4pairImmEENS_9allocatorIS3_EEEENS4_IS6_EEEE
17VNNSDataStreambuf
24VNNSMutableDataStreambuf
N6vision3mod19ScreenGazePredictorE
NSt3__120__shared_ptr_emplaceIN6vision3mod27ScreenGazePredictorConcreteENS_9allocatorIS3_EEEE
N6vision3mod27ScreenGazePredictorConcreteE
NSt3__120__shared_ptr_emplaceIN6vision3mod16TapToBoxConcreteENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_pointerIPfZN6vision3mod28readBinSerializedModelValuesEP7__sFILEPKcRKNS3_26BinSerializedModelFileInfoERNS3_11ModelValuesEbE3$_0NS_9allocatorIfEEEE
ZN6vision3mod28readBinSerializedModelValuesEP7__sFILEPKcRKNS0_26BinSerializedModelFileInfoERNS0_11ModelValuesEbE3$_0
NSt3__120__shared_ptr_pointerIPhZN6vision3mod28readBinSerializedModelValuesEP7__sFILEPKcRKNS3_26BinSerializedModelFileInfoERNS3_11ModelValuesEbE3$_1NS_9allocatorIhEEEE
ZN6vision3mod28readBinSerializedModelValuesEP7__sFILEPKcRKNS0_26BinSerializedModelFileInfoERNS0_11ModelValuesEbE3$_1
NSt3__120__shared_ptr_emplaceI17espresso_buffer_tNS_9allocatorIS1_EEEE
NSt3__120__shared_ptr_emplaceIN6vision3mod32ImageDescriptor_EspressoSmartCamENS_9allocatorIS3_EEEE
N6vision3mod32ImageDescriptor_EspressoSmartCamE
NSt3__120__shared_ptr_emplaceIN6vision3mod12FaceID3ModelENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_pointerIPN6vision3mod12FaceID3ModelENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIN6vision3mod12FaceID3ModelEEE
f00Lh00L800L
N6vision3mod17PetprintGeneratorE
NSt3__120__shared_ptr_emplaceIN6vision3mod25PetprintGeneratorConcreteENS_9allocatorIS3_EEEE
N6vision3mod25PetprintGeneratorConcreteE
NSt3__120__shared_ptr_emplaceIN6vision3mod28ImageDescriptorAugmenterNoOpENS_9allocatorIS3_EEEE
N6vision3mod28ImageDescriptorAugmenterNoOpE
N6vision3mod32ImageDescriptorAugmenterAbstractE
NSt3__120__shared_ptr_emplaceIN6vision3mod28ImageDescriptorAugmenterFlipENS_9allocatorIS3_EEEE
N6vision3mod28ImageDescriptorAugmenterFlipE
NSt3__120__shared_ptr_pointerIPN6vision3mod29ImageDescriptorBufferAbstractENS_10shared_ptrIS3_E27__shared_ptr_default_deleteIS3_S3_EENS_9allocatorIS3_EEEE
NSt3__110shared_ptrIN6vision3mod29ImageDescriptorBufferAbstractEE27__shared_ptr_default_deleteIS3_S3_EE
NSt3__114default_deleteIN6vision3mod29ImageDescriptorBufferAbstractEEE
NSt3__120__shared_ptr_pointerIPKhZN4cvml4util31binserialized_table_of_contents9blob_infoC1ES2_RK26_BinSerializer_blobHeader_EUlS2_E_NS_9allocatorIS1_EEEE
ZN4cvml4util31binserialized_table_of_contents9blob_infoC1EPKhRK26_BinSerializer_blobHeader_EUlS4_E_
NSt3__120__shared_ptr_pointerIPfNS_14default_deleteIA_fEENS_9allocatorIfEEEE
NSt3__114default_deleteIA_fEE
NSt3__120__shared_ptr_emplaceIN6vision3mod18FaceBoxPoseAlignerIaEENS_9allocatorIS4_EEEE
NSt3__120__shared_ptr_emplaceIN6vision3mod23ImageClassifierEspressoENS_9allocatorIS3_EEEE
3PIVldmt
N6vision3mod17RPNTrackerOptionsE
N6vision3mod16ObjectTrackerRPNE
N6vision3mod30ImageDescriptorProcessorHasherE
N6vision3mod32ImageDescriptorProcessorAbstractE
NSt3__120__shared_ptr_emplaceIN6vision3mod28ImageDescriptorBufferFloat32ENS_9allocatorIS3_EEEE
333333
?ffffff
333?
L=33s?
<ff&?
B>q=J?
:fff?
CAffF@
@33
B33XBmQv9
Ga==
/dev/null
< %-8s > 
Emergency
Alert
Critical
Error
Warning
Notice
Info
Verbose
Pixel format (%d) not supported!
Pixel format (%d), model (%d), or stretch (%d) not supported!
Invalid source image!
Invalid instanceResult buffer!
Output buffer size incorrect!
Invalid output buffer rowBytes (%d)!
rtcv::simCropResize failed!
Invalid exemplarResult buffer!
TtResult modelInfo.numModels (%d) out of bounds!
Incorrect trk node state version (%u vs %u)
Numbers of net outputs (%d) more than limit!
Numbers of net outputs (%d) isn't correct!
GeomTransform_constructor: unknown transform model (%d)
GeomTransform_minSupportPoints: unknown transform model (%d), reset to RIGID
GeomTransform_changeCoordinateSystem failed
GeomTransform_setModel: unknown new model (%d) use the old model (%d)
GeomTransform_estimate: unknown transform model (%d) use RIGID
GeomTransform_numTestsToDo: unknown transform model (%d) use RIGID
RigidTransform_estimate: not symmetric positive definite matrix
RigidTransform_estimate: the %ld-th argument is wrong in sposv_ call
AffineTransform_estimate: not symmetric positive definite matrix
AffineTransform_estimate: the %ld-th argument is wrong in sposv_ call
HomographyTransform_estimate:The %ld-th eigenvector failed to converge
HomographyTransform_estimate:The %ld-th eigenvector failed to converge
HomographyTransform_estimate: the %ld-th argument is wrong in ssyevx_ call
HomographyTransform_estimate: the %ld-th argument is wrong in ssyevx_ call
HomographyTransform_estimate: the 9-th parameter is too small pp[8]=%f 
IPDetector_constructor: Cannot allocate mFltImage 
IPDetector_constructor: Cannot allocate box filter
IPDetector_constructor: Cannot allocate mTmpBuffer 
IPDetector_constructor: Cannot allocate mCornerVec 
IPDetector_constructor: Cannot allocate mBX, mBY 
IPDetector_response: box filter failed
v16@?0i8i12
v8@?0
boxFilter_uint8_init: box filter failed when request minimum size err=%d
boxFilter_uint8: box filter failed err=%d
 invMatrix failed INFO1 = %ld
 invMatrix failed INFO2 = %ld
%s : calloc failed
ImageRegistrationCreateContext
%s : CFDictionaryCreateMutable failed
%s : CFArrayCreateMutable failed
%s : RegistrationEngine_constructor failed
imageRegQueue
%s : dispatch_queue_create failed
%s : NULL input parameters
ImageRegister
%s : Need at least one non-reference image
%s : CFArrayGetCount(imageRegCtx->availExtraBuffers) != 0
%s : Could not locate scratch buffers
GeomTransform_estimate failed
Pyramid_loadImage: incompatible size in pyramid (%lu!=%lu) or (%lu!=%lu)
v40@?0^Q8^Q16Q24Q32
WARNING: insufficient number of external corners provided (only %hu corners provided but minumum is %d)
Registration could not detect more that %d inlier corners at the highest resolution.
unexpected keypoint type %@
OrderedKeypoints
ordered keypoints are not available
detectorType
unable to lock base address of pixelBuffer
bbox
Model runtime error, Unable to bind output buffer
Model runtime error, Unable to bind input buffer
error occured when running model
error occured when running model, unexpected output received
mask
saliency_attention_box_head_i4fgq3rswb_fp16.espresso
saliency_objectness_boxes_head_ecvqeduzc7_46800_fp16.espresso
%@ is handled by %@
VNDetectHumanHeadRectanglesRequestPrivateRevisionANODv3
VNDetectHumanHeadRectanglesRequestPrivateRevisionANODv4
VNDetectHumanHeadRectanglesRequestPrivateRevisionANSTModel
 = [
%@:%@
%@ must override %@ with a specific implementation
Failure to create face quality predictor
Could not run network
face quality of %f is out of range
com.apple.cvml.%@
CVML module = %@
VNANFDMultiDetectorProcessingOption_AnimalHeadsRecognitionOriginatingRequestSpecifier
VNANFDMultiDetectorProcessingOption_SportBallsRecognitionOriginatingRequestSpecifier
%@%@%@
CVML_debug_enable_cluster_log
en_US_POSIX
yyyy-MM-dd_HH-mm-ss-SSS
VNClusteringLog
%@_%@.log
Level %@ cluster map:
ClusterId: %lld
%@Faces: 
%lld
0 Lookup
1 Lookup
VNSuggestionLog
Input query - face IDs with flags (clusterIdsWithFlags):
faceId: %@
%@can be returned: %@
Suggested face IDs: %@:
ClusterId: %@   
%@Suggestions: 
%@, 
all sugestions for given input query (suggestionLists)
filtered suggestions to include only those that are part of input query (suggestedInputsLists)
Connected groups of suggestions face IDs (connectedSuggestedInputs):
Group %d suggestions: 
Final list of suggestions face IDs (results):
Invalid cache file path: %@
VNClusterOptionClusteringAlgorithm must be set to either VNClusteringAlgorithm_Greedy or VNClusteringAlgorithm_GreedyWithTorso
Creating clustering parameters object failed for following face and torsoprint revisions: %lu and %lu and algorith type: %@
Error initializing cluster state
v32@?0@"VNFaceTorsoprint"8Q16^B24
Internal error querying similar faces
getting clusters failed with error: %lld
getLevel1ClusteredIdsGroupedByLevel0ClustersForFaceId: faceId (%@) is not initialized
getLevel1ClusteredIdsGroupedByLevel0ClustersForFaceId: There is no level-1 cluster that contains faceId = %d
getLevel1ClusteredIdsGroupedByLevel0ClustersForFaceId: Level-1 cluster size is zero for a valid clusterID descriptor (%lld)
B32@?0@"NSNumber"8@"NSMutableOrderedSet"16^@24
Parameter validation failed for getDistanceBetweenLevel1Clusters
B24@?0@"VNFaceObservation"8@"NSDictionary"16
Cache file path is a required parameter
RestoreClusteringState is a required parameter
Clustering request was canceled, error: %llu
Creating clustering parameters object failed for following face and torsoprint revisions: %lu and %lu and algorithm type: %@
Clustering with greedy algorithm
Unexpected type of object for clustering
adding faces (%lu): %s
Faces to add must be accompanied by grouping identifiers when performing clustering in torso mode.
Faces to add array must be the same size as that of the grouping identifiers array.
Clusters:
  %d: prevcount=%d, curcount=%d, shouldUpdateRep = %d
clusters:
  clusterId: %ld, %s
person_instances_1:0
person_instances_2:0
person_instances_3:0
person_instances_4:0
HyperDETR-u8-v1.1.espresso
person_instance_confidences:0
VNSegmentationGenerator - internal error in number confidence buffers
VNSegmentationGenerator - internal error calculating confidence index
VNSegmentationGenerator - internal error in number confidence buffer names
VNFaceAnalyzerMultiDetectorObservationGroupsForRequests
VNFaceAnalyzerMultiDetectorProcessingOptionCreateFaceprint
VNFaceAnalyzerMultiDetectorProcessingOptionCreateFaceAnalyzer
VNFaceAnalyzerMultiDetectorProcessingOptionFaceprintOriginatingRequestSpecifier
VNFaceAnalyzerMultiDetectorProcessingOptionFaceAnalyzerOriginatingRequestSpecifier
VNFaceAnalyzerMultiDetectorProcessingOptionFaceObservations
VNFaceAnalyzerMultiDetectorProcessingOptionFaceprintForceFaceprintCreation
VNFaceAnalyzerMultiDetectorProcessingOptionFaceprintConfidence
VNFaceprintGeneratorTypeEspressoCPU
%@:%s
%@ must override %@
Method not implemented
Failure to create face multi-headed classifier.
Unexpected options parameter passed to face analyzer multi-detector
VNClusterOptionCacheFolderPath
VNClusterOptionClusteringAlgorithm
VNClusterOptionRestoreClusteringState
VNClusterOptionAddObjectsToClustering
VNClusterOptionAddObjectGroupIdsToClustering
VNClusterOptionRemoveObjectsFromClustering
VNClusterOptionFaceprintRevision
VNClusterOptionTorsoprintRevision
VNClusterOptionInputThreshold
VNClusterOptionInputTorsoThreshold
VNClusterOptionVectorMapReadOnlyFlag
Invalid Clusterer cache directory: %@
Invalid Clusterer type: %@
Invalid Faceprint revision: %lu
Failed to create clusterer; Error = %@
Suggestions request has been cancelled
Clustering request has been cancelled
%@ is no longer supported by Vision
%@ is not a registered class code
%@ does not have a registry entry
Request
%@ is not a VNRequest subclass
VNAlignFaceRectangleRequest
VNANFDDetectorCompoundRequest
VNAppendBurstSequenceFrameRequest
VNClassifyCityNatureImageRequest
VNClassifyFaceAttributesRequest
VNClassifyImageAestheticsRequest
VNClassifyImageRequest
VNClassifyJunkImageRequest
VNClassifyMemeImageRequest
VNVYvzEtX1JlUdu8xx5qhDI
VNClassifyPotentialLandmarkRequest
VN5kJNH3eYuyaLxNpZr5Z7zi
VN6Mb1ME89lyW3HpahkEygIG
VNCoreMLRequest
VNCreateAnimalprintRequest
VNCreateDetectionprintRequest
VNCreateFaceRegionMapRequest
VNCreateFaceprintRequest
VNCreateFaceTorsoprintRequest
VN6kBnCOr2mZlSV6yV1dLwB
VNCreateImageFingerprintsRequest
VNCreateImageprintRequest
VNCreateNeuralHashprintRequest
VNCreateSceneprintRequest
VNCreateSmartCamprintRequest
VNCreateTorsoprintRequest
VNDetectBarcodesRequest
VNDetectContoursRequest
VNDetectDocumentSegmentationRequest
VNDetectFaceCaptureQualityRequest
VNDetectFaceLandmarksRequest
VNDetectFace3DLandmarksRequest
VNDetectFaceExpressionsRequest
VNDetectFaceGazeRequest
VNDetectFacePoseRequest
VNDetectFaceRectanglesRequest
VNDetectHorizonRequest
VNDetectHumanBodyPoseRequest
VNDetectHumanHandPoseRequest
VNDetectHumanHeadRectanglesRequest
VNDetectHumanRectanglesRequest
VNDetectObjectAtPointRequest
VNDetectRectanglesRequest
VNDetectScreenGazeRequest
VNDetectTextRectanglesRequest
VNDetectTrajectoriesRequest
VNFaceAnalyzerCompoundRequest
VNGenerateAnimalSegmentationRequest
VNGenerateAttentionBasedSaliencyImageRequest
VNGenerateFaceSegmentsRequest
VNGenerateImageFeaturePrintRequest
VNGenerateImageSaliencyRequest
VNGenerateObjectnessBasedSaliencyImageRequest
VNGenerateOpticalFlowRequest
VN1JC7R3k4455fKQz0dY1VhQ
VNGeneratePersonSegmentationRequest
VNGeneratePersonSemanticsCompoundRequest
VNGenerateSkySegmentationRequest
VNGroupImagesByTimeAndContentRequest
VNHomographicImageRegistrationRequest
VNIdentifyJunkRequest
VNImageBlurScoreRequest
VNImageAnalyzerCompoundRequest
VNImageExposureScoreRequest
VNNOPRequest
VNRecognizeAnimalsRequest
VNRecognizeAnimalHeadsRequest
VNRecognizeFoodAndDrinkRequest
VNRecognizeObjectsRequest
VNRecognizeSportBallsRequest
VNRecognizeTextRequest
VNRecognizeDocumentElementsRequest
VNRecognizeDocumentsRequest
VNRemoveBackgroundRequest
VNSceneClassificationRequest
VNSmartCam5CompoundRequest
VNTrackHomographyRequest
VNTrackLegacyFaceCoreObjectRequest
VNTrackObjectRequest
VNTrackRectangleRequest
VNTranslationalImageRegistrationRequest
VNANFDMultiDetectorANFDv2
VNANFDMultiDetectorANODv3
VNANFDMultiDetectorANODv4
VNANFDMultiDetectorANSTv1
VNAnimalprintDetectorRevision1
VNAnimalprintDetectorPrivateRevision1MD2
VNBlurDetector
VNBrightnessDetector
VNContoursDetector
VNCoreMLTransformer
VNCRImageReaderDetector
VNCRImageReaderForDocumentsDetector
VNDetectionprintGenerator
VNDocumentSegmentationDetector
VNFaceAnalyzerMultiDetectorFPrev3_1FArev1_3_MD2
VNFaceAnalyzerMultiDetectorFArev2_CameraLightweight
VNFaceAnalyzerMultiDetectorFPrev3_1FArev1_3_MD3
VNFaceBBoxAligner
VNFaceDetectorPrivateRevisionLegacyFaceCore
VNFaceDetectorRevision2
VNFaceExpressionDetector
VNFaceGazeDetector
VNFaceGeometryEstimator
VNFaceLandmarkDetectorRevision2
VNFaceLandmarkDetectorRevision3
VNFaceprintGeneratorRevision1
VNFaceQualityGeneratorRevision1
VNFaceQualityGeneratorRevision2
VNFaceQualityGeneratorPrivateRevisionV3MD4
VNFaceRegionMapGenerator
VNFaceSegmentGenerator
VNGuidedUpsamplingGenerator
VNHomeAppFaceAnalyzerMultiDetectorFPrev3_1FArev1_3_MD3
VNHomographicImageRegistrationDetector
VNHomographyTracker
VNHorizonDetector
VNHumanBodyPoseDetector
VNHumanHandPoseDetector
VNImageAnalyzerMultiDetector
VN4nFZhnOcBOiJmeVWzBWsv
VNImageprintGenerator
VNImageRegistrationDetector
VNImageSignatureDetector
VNJunkIdentifier
VNMemeClassifier
VNMRCDetector
VNObjectAtPointDetectorRevision1
VNOpticalFlowGenerator
VNOpticalFlowGeneratorRevision1
VNOpticalFlowGeneratorRevision2
VNPanopticSegmentationGenerator
VNPersonSegmentationGeneratorInstanceBased4People
VNPersonSegmentationGeneratorSemantics
VNPersonSegmentationGeneratorFast
VNPersonSegmentationGeneratorLearnedMatting
VNPersonSegmentationGeneratorLearnedMattingTiled
VNRectangleDetector
VNRemoveBackgroundProcessor
VNSaliencyAHeatmapBoundingBoxGenerator
VNSaliencyOHeatmapBoundingBoxGenerator
VNSceneClassifier
VNScreenGazeDetector
VNSegmentationGenerator
VNSingleHeadSceneprintGenerator
VNSliderNetDetector
VNSmartCamClassifier
VNSmartCam5GatingDetector
VNSmartCamCombinedAestheticsAndSaliencyDetector
VNTorsoprintGeneratorPrivateRevision3MD2HumanDetectorBased
VNTorsoprintGeneratorPrivateRevision4MD2HomeAIHumanDetectorBased
VNTorsoprintGeneratorRevision1
Disgust
Neutral
Scream
Smile
Surprise
Suspicious
label
v3_drop2
v3_drop3
Descriptor count = 
Descriptor length = 
 bytes
VNHomographyTrackerProcessOption_State
timeout exceeded
pet_v1_md2_fp16.espresso
Mismatch in signature print type
Internal error creating sceneprint
Internal error while creating image signature print
%@ %lu %lu
no input buffer
invalid URL
Invalid argument
The image is invalid
could not obtain a supported image size for %@
unable to allocate results array for %@ elements
Invalid requestRevision %d requested
no supported image size available
%@ does not provide classification labels
%@ does not provide a model name
failed to create image analyzer
the image processing type is unknown
the image analysis failed
CVML_UNKNOWN_
( %@, %@ )
( %@, [ %@ ] )
%@ #%lu (%p)
attempting to re-assign ordered requests
%@ created
performing %@
performed %@
, failed with %@
%@ cached %@
%@ was already recorded as a cached result
%@ looked up %@
%@ hit %@
VNObjectAtPointDetectorProcessOption_InputPoint
tap_to_box.espresso
Failed to create tap to box converter object
Cannot parse input location point data
com.apple.vis
request %@ was cancelled
request was cancelled
VNRequest
unsupported serialized header version %u
%@ must be overridden
%@ does not support operation
missing option %@
option %@ has an invalid value of %@
 - %@
argument %@ has an invalid value of %@
%@ requires the GPU for processing
processing with %@ is not supported
The current configuration of %@ is not supported
%@ does not support %@
%@ is not a supported request
session no longer available
: %s
%@ (%@)
%s (%@)
%@ - %@
vImage_Error %@
"%@"
DESIGN
BUILT
FAILURE
plan phase %u
VNBarcodeSymbologyAztec
VNBarcodeSymbologyCode39
VNBarcodeSymbologyCode39Checksum
VNBarcodeSymbologyCode39FullASCII
VNBarcodeSymbologyCode39FullASCIIChecksum
VNBarcodeSymbologyCode93
VNBarcodeSymbologyCode93i
VNBarcodeSymbologyCode128
VNBarcodeSymbologyDataMatrix
VNBarcodeSymbologyEAN8
VNBarcodeSymbologyEAN13
VNBarcodeSymbologyI2of5
VNBarcodeSymbologyI2of5Checksum
VNBarcodeSymbologyITF14
VNBarcodeSymbologyPDF417
VNBarcodeSymbologyQR
VNBarcodeSymbologyUPCE
VNBarcodeSymbologyAppClipCode
VNBarcodeSymbologyCodabar
VNBarcodeSymbologyGS1DataBar
VNBarcodeSymbologyGS1DataBarExpanded
VNBarcodeSymbologyGS1DataBarLimited
VNBarcodeSymbologyMicroPDF417
VNBarcodeSymbologyMicroQR
could not locate the face detection model file
Failed to align a detected bounding box
6ziz6uinva_opt.espresso
noMapping
1DAffineMapping
1DLogisticMapping
1DPairwiseAffineMapping
postProcessorType
basic_string
%@ %@
VNClassifyJunkImageRequestPrivateRevisionR14J8Model
VNClassifyJunkImageRequestPrivateRevisionSceneNetV4
VNClassifyJunkImageRequestPrivateRevisionStillCapturePipeline
VNClassifyJunkImageRequestPrivateRevisionSceneNetV4StillCapturePipeline
VNClassifyJunkImageRequestPrivateRevisionR14J9Model
VNClassifyJunkImageRequestPrivateRevisionSceneNetV5
VNClassifyJunkImageRequestPrivateRevisionSceneNetV5StillCapturePipeline
head_joint
left_eye_joint
right_eye_joint
left_ear_joint
right_ear_joint
left_shoulder_1_joint
right_shoulder_1_joint
neck_1_joint
left_forearm_joint
right_forearm_joint
left_hand_joint
right_hand_joint
left_upLeg_joint
right_upLeg_joint
root
left_leg_joint
right_leg_joint
left_foot_joint
right_foot_joint
VNBLKFACE
VNBLKTORSO
VNBLKLARM
VNBLKRARM
VNBLKLLEG
VNBLKRLEG
VNIPOAll
VNCRImageReaderDetectorCreationOption_FastRecognition
VNCRImageReaderDetectorCreationOption_MaximumCandidatesCount
VNCRImageReaderDetectorCreationOption_RecognitionLanguages
VNCRImageReaderDetectorCreationOption_UsesLanguageDetection
VNCRImageReaderDetectorCreationOption_UsesAlternateLineGrouping
VNCRImageReaderDetectorCreationOption_CRImageReaderRevisionKey
VNCRImageReaderDetectorCreationOption_RestrictToCPU
VNCRImageReaderDetectorCreationOption_CustomWords
VNCRImageReaderDetectorCreationOption_DisableLanguageCorrection
VNCRImageReaderDetectorProcessOption_OriginatingRequest
VNCRImageReaderDetectorProcessOption_MinimumTextHeight
VNRecognizeTextRequest produced an internal error
VNRecognizeTextRequest error - invalid orientation
The image is too small in at least one dimension %ld x %ld (each dimension has to be more than 2 pixels)
VNRequestHandlerCleanupOption_AllPipelines
VNRequestHandlerCleanupOption_FacePipeline
VNRequestHandlerCleanupOption_ScenePipeline
VNRequestHandlerCleanupOption_SmartCamPipeline
VNRequestHandlerCleanupOption_JunkPipeline
VNCleanupLevel_Complete
VNCleanupLevel_Partial
VNRequestHandlerCleanupOption_ImageBuffers
VNCleanupPurgeAll
VNTrackObjectPrivateRevisionLegacyFaceCoreProcessOption_MinFaceSize
VNTrackObjectPrivateRevisionLegacyFaceCoreProcessOption_NumberOfDetectionAngles
VNTrackObjectPrivateRevisionLegacyCoreProcessOption_EnhanceEyesAndMouthLocalization
VNTrackObjectPrivateRevisionLegacyFaceCoreProcessOption_ExtractBlink
VNTrackObjectPrivateRevisionLegacyFaceCoreProcessOption_ExtractSmile
VNTrackObjectPrivateRevisionLegacyFaceCoreProcessOption_KalmanFilter
Internal error: Unsupported/unimplemented tracking level by FaceCore
Internal error: Failed to initialize FaceCore detector
Internal error: Tracker is busy with previous tracking requests. It needs to be reset to restart tracking sequence
Internal error: Tracker is not initialized
VN6Ukf2f2QO979ttLvyg0ZAQ
 leaf=%lu hierarchy=%lu
the custom hierarchy is for request revision %lu, not %lu
VNSceneClassificationRequestPrivateRevisionSceneNetV4
VNSceneClassificationRequestPrivateRevisionSceneNetV5
v2.2
v2.2_small
v3.0
anodv3_torso_v3_md3
anodv3_torso_v3_md4
anodv3_torso_v4_md1
seg_probs__0
'%c%c%c%c'
0x%08X
tag %@ did not provide any data
tag %@ has a data overflow to %lu bytes
encountered unexpected length of %u, instead of %u
failed to write to data stream
unexpected end of data stream
unavailable %@, %srevision %lu
private 
code
Cannot register equivalency of %@ %@ <==> %@: %@
nil request class
not a VNRequest subclass
Error while computing blur score: %s
Inconsistent platform
This method should not be invoked directly. Derived classes are responsible for providing correct implementation
%@:Trk=%@
Internal error: internal type conversion failed
Internal error: unexpeted tracked object bounding box size
{?=qiIq}
No valid presentationTimeStamp was available for this image
VNFaceLandmarkDetectorType
VNFaceDetectorType
VNFaceBoxAlignerType
VNFaceGeometryEstimatorType
VNFaceRegionMapGeneratorType
VNFaceExpressionDetectorType
VNFaceSegmentGeneratorType
VNTorsoprintGeneratorDetectorType
VNFaceQualityGeneratorType
VNRectangleDetectorType
VNJunkIdentifierType
VNSingleHeadSceneprintGeneratorType
VNSmartCamClassifierType
VNImageprintGeneratorType
VNSmartCamCombinedAestheticsAndSaliencyDetectorType
VNAttentionBasedSaliencyHeatmapBoundingBoxGeneratorType
VNObjectnessBasedSaliencyHeatmapBoundingBoxGeneratorType
VNSaliencyHeatmapBoundingBoxGeneratorType
VNHorizonDetectorType
VNImageAnalyzerMultiDetectorType
VNFaceAnalyzerMultiDetectorType
VNANFDMultiDetectorType
VNOpticalFlowGeneratorType
VNContoursDetectorType
VNHumanBodyPoseDetectorType
VNHumanHandPoseDetectorType
VNDetectionprintGeneratorDetectorType
VNImageSignatureDetectorType
VN4nFZhnOcBOiJmeVWzBWsvType
VNScreenGazeDetectorType
VNFaceGazeDetectorType
VNCRImageReaderDetectorType
VNCRImageReaderForDocumentsDetectorType
VNAnimalprintDetectorDetectorType
VNImageRegistrationDetectorType
VNHomographicImageRegistrationDetectorType
VNBlurDetectorType
VNBrightnessDetectorType
VNSegmentationGeneratorType
VNObjectDetectorAtPointType
VNMemeClassifierType
VNHomographyTrackerType
VNDocumentSegmentationDetectorType
VNSmartCam5GatingDetectorType
VNPanopticSegmentationGeneratorType
VNSliderNetDetectorType
VNRemoveBackgroundProcessorType
VNMRCDetectorType
VNGuidedUpsamplingGeneratorType
VNDetectorWillLoadNotification
VNDetectorDidLoadNotification
VNDetectorNotificationDetectorClass
VNDetectorNotificationDetector
VNDetectorNotificationConfiguration
%@; resultsIndex=%lu
VNDetectorInitOption_ModelBackingStore
VNDetectorInitOption_MemoryPoolId
VNDetectorOption_OriginatingRequestSpecifier
VNDetectorOption_ProcessingDevice
VNDetectorOption_ExplicitProcessingDevice
VNDetectorOption_MetalContextPriority
VNDetectorOption_PreferBackgroundProcessing
VNDetectorOption_RequestDetectionLevel
VNDetectorProcessOption_InputImageBuffers
VNDetectorProcessOption_InputFaceObservations
VNDetectorProcessOption_ScenePrints
VNDetectorProcessOption_ImageCropAndScaleOption
VNDetectorProcessOption_Canceller
VNDetectorProcessOption_Session
VNDetectorInternalProcessOption_CacheKeys
VNDetectorInternalProcessOption_ImageBuffers
CropCreation
CropProcessing
unknown detector type '%@'
:%@=%@
Currently executed Detector should not be nil
%@ does not implement %@
Cannot create Metal Context for non-GPU targeting device
primaryInferenceNetworkDescriptorFor%@_%u_%u_%u
%@ does not have an inference network for %@ %@
[%g %g %g %g %g %g]
'%@' is not a valid CGAffineTransform encoding
3x3:|%g %g %g %g %g %g %g %g %g|
3x3:|
'%@' is not a valid matrix_float3x3 encoding
4x4:|%g %g %g %g %g %g %g %g %g %g %g %g %g %g %g %g|
4x4:|
'%@' is not a valid matrix_float4x4 encoding
d3:|%g %g %g|
d3:|
'%@' is not a valid simd_flloat3 encoding
%@.x
%@.y
%@.w
%@.h
%@.or
%@.sz
createBridgeSegment
ContourUtilities.c
mPnts == nPnts
reverseContour
currCPtr != NULL
AnnealContour
sPtrPrev != sPtr
sPtr != sPtrNext
rPtr != NULL
annealSegments
sPrevPtr != sPtr
newCurr != NULL
mergeContourEnd
cPtr2->active
PCOORD_EQUAL(sPtr2->pary[sPtr2->nPnts-1], pc3)
(code == 1) || (code == 2)
mergeEndpointSearch4
code1 != -1
code2 != -1
VNPotentialLandmarkIdentifier
VNClassifyPotentialLandmarkRequestPrivateRevisionStillCapturePipeline
Not supported error
General error
Espresso error
incorrect binserializer key
small sparsity error
feature extraction error
initialization error
no saved state to revert
nominal distance not changed
batch size violation
computation kill request was issued
too few IDs to build VIP model
video error
error with projection computation
missing positional parameter
inconsistent state error
warping error
OpenGL error
invalid format
out of bounds
singular point configuration error
division by zero
LAPACK error
platform endianess not supported
hash already in use
invalid ID
invalid data type
data inconsistency error
I/O error
unknown option
invalid option
missing option
delegate error
vImage related error
memory allocation error
invalid parameter
unexpected null pointer
internal error
not implemented error
CVML_status module %d error %lld
BinSerializer
Face3D
FaceDescriptor
FaceFrontalizer
FaceWarper
Geometry2D
Geometry3D
ImageGrouping
ImageQuality
LandmarkDetector
MomentProcessor
FaceboxAligner
ImageDescriptor
ImageClassifier
ImageProcessing
VIPIdentification
ImageRegistration
SimilarityMatrix
Clustering
HumanDetector
FaceRegionMap
ObjectDetector
ObjectTracker
SRCClassifier
Kmeans
SparseCoding
FaceID
BoostedClassifier
FaceSegmenter
ImageAnalyzer
FaceAttributes
FaceprintAndAttributes
FaceQuality
Torsoprint
ScreenGaze
PetprintGenerator
TapToBox
Generic
ImageTools
VideoTools
ImageWarper
ThirdParty
BinSerializerProcessor
AppleNetParser
FaceProcessorCLI
ImageClassifierCLI
MPCmdlineClientCLI
ClusteringCLI
ImageProcessorCLI
PhotosProcessorCLI
CVMLEngine
CVML Module %lld
[%g,%g,%g,%g]:%@:%u:%u:%c
v32@?0@"NSString"8Q16@"NSString"24
v32@?0Q8@"NSArray"16^B24
cannot process %@ in a single operation
VNFaceRegionMapVersion
requestRevision
userX
userY
userW
userH
alignX
alignY
alignW
alignH
rgnMapData
rgnMapW
rgnMapH
rgnMapRowBytes
pixelToRgnMap
unknown coding version
region map data has length of %lu instead of the expected %lu
Unknown
VNAnimalObservation
anmlPrnt
Failed to unarchive %@ object due to coding version mismatch: Currently supported: %u; encoded: %u
image:0
person:0
sky:0
personsemantics-u8-v4.espresso
B24@?0#8^B16
The model has reached the maximum entity limit of %lu
entity serial numbers have been exhausted
entity and observation data counts are out-of-sync
VNFaceprintInferenceNetworkHeadIdentifierFaceprint
VNFaceprintInferenceNetworkHeadIdentifierFaceAttributes
NeuralHashv3b_fp16-current.espresso
leaf/logits
could not create a image signature print from tensor vector with %lu elements (%lu bytes)
com.apple.VN.createGaborFilterBankGCDQueueName
com.apple.VN.extractGaborDescriptorGCDQueueName
com.apple.VN.gaborReadySyncQueueName
com.apple.VN.gaborDescriptorReadySyncQueueName
VNFaceLandmarkDetectorOption_LoadRefinersModel
VNFaceLandmarkDetectorProcessOption_CalculateLandmarkScore
VNFaceLandmarkDetectorProcessOption_BlinkDetection
Unknown constellation type: %lu
landmarkRefinerAndPupil_v2
Could not read landmark refiner model data
Invalid parameters passed to landmark score computation
Could not compute landmark score, error code = %lld
Invalid parameters passed to blink score computation
model file is corrupt
void cvml::util::binserialized_table_of_contents::init(const void *const, size_t)
/Library/Caches/com.apple.xbs/Sources/Vision_Sim/VisionKitFramework/VN/algorithm_util/binserialized_mapped_file_contents.h
Model file info populated incorrectly
void cvml::util::binserialized_contents::init_model_values(const cvml::util::binserialized_table_of_contents &, const char *, const vision::mod::BinSerializedModelFileInfo &)
Request object must be of type VNImageBasedRequest
%f,%f,%f,%f:%u:%u:%lu
%@:%u:%u:%lu
B32@?0Q8@"VNCreateFaceprintRequest"16^@24
B32@?0Q8@"VNClassifyFaceAttributesRequest"16^@24
B16@?0@"VNFaceObservation"8
VNImageBufferOption_DownscaleCGInterpolationQuality
VNImageBufferOption_UpscaleCGInterpolationQuality
VNImageBufferOption_FeatureOrientationRelativeToUpRight
VNImageBufferOption_DoNotCacheRepresentations
VNImageBufferOption_CreateFromPixelBufferPool
VNImageBufferAugmentationApplePipeline
VNImageBufferAugmentationBlur
VNImageBufferAugmentationNoise
VNImageBufferAugmentationRotation
VNImageBufferAugmentationFlip
VNImageBufferAugmentationFlipVertical
VNImageBufferAugmentationFlipHorizontal
VNImageBufferAugmentationShear
VNImageBufferAugmentationExposure
VNImageBufferAugmentationRandomCrop
VNImageBufferAugmentationOptionMaxRange
VNImageBufferAugmentationOptionMinRange
VNImageBufferAugmentationOptionNumberOfBuffers
VNImageBufferAugmentationOptionRandomSeed
ERROR while purging caches %s | %@
-[VNImageBufferManager purgeAllCaches]
VNImageBufferContext
subSampleFactor
Cannot obtain image from image source
format=%lu_width=%lu_height=%lu_cropRect=%@
Failed to create image for processing
Missing target buffer for crop operations
VNImageBuffer - Cannot set VTSession property, error: %d
VNImageBuffer - Failed to transfer bufferForTransferSubImage (retain count = %ld, type = %u) to vtSessionDestBuffer (retain count = %ld, type = %u). Error %d
VNImageBuffer - unable to allocate CVPixelBuffer, error: %d
Cannot set VTSession property, error: %d
VNImageBuffer - Failed to transfer inputBufferForRotation (retain count = %ld, type = %u) to vtSessionDestBuffer (retain count = %ld, type = %u). Orientation %d. Crop %@. Rotation %d. Error %d
unable to create the Y plane wrapper buffer
Unable to create CGImage for scaling
Extracting ROI from an image failed
Unable to crop a region of interest from source buffer
Unable to create a CGBitmapContext
Operation failed due to attempt to crop zero or near zero dimensioned area
Could not create buffer with format %@ (%ld)
Failed to create CGImage from CVPixelBuffer
%@;opt=%@
VNImageBuffer - unable to allocate CVPixelBuffer to be rendered from CIImage, error: %d
unable to create the cropped buffer - error: %d
CIDiscBlur
CIExposureAdjust
CIStraightenFilter
CIRandomGenerator
CIColorMonochrome
CIMultiplyBlendMode
RandomCrop produced an invalid crop for width %f height %f
The augmentationOptions do not conatain any of the VNImageBufferAugmentation keys
Cannot transfer image using VTSession, error: %d
orientation
%@ cannot be called with nil options
0x%x
B16@?0@"VNObservation"8
VNCreateTorsoprintRequestPrivateRevision3MD2HumanDetectorBasedTorso
VNCreateTorsoprintRequestPrivateRevisionSydroMD2HomeAIHumanDetectorBasedTorso
VNCRImageReaderForDocumentsDetectorProcessOption_OriginatingRequest
VNCRImageReaderForDocumentsDetectorProcessOption_DetectionOnly
VNCRImageReaderForDocumentsDetectorProcessOption_TextObservationsToRecognize
VNCRImageReaderForDocumentsDetectorProcessOption_MaximumProcessingDimensionOnTheLongSide
v32@?0@"VNWeakSessionWrapper"8Q16^B24
v24@?0@"VNSession"8^B16
%@: %@
VNTrackerOption_RPNEspressoResources
com.apple.Tracker.rpnInitQueue
com.apple.Tracker.rpnTrackQueuee
rpn_template_v5.espresso
rpn_track_v5.espresso
com.apple.VN.serializeRPNInitializationQueue
com.apple.VN.serializeRPNTrackingQueue
com.apple.espresso.mainqueue
Unspecified error
face
 modified on %@
 <dirty>
writeVersion
ToOutputStream:options:md5Context:error:
%@%lu%@
writeReadOnlyVersion
failed to obtain the data
v32@?0@"VNFaceObservation"8Q16^B24
[%f; %f]
VNRequestWarningImageTooSmall
VNRequestWarningImageTooSmallForFaceObservations
VNRequestWarningImageMinimumLongDimension
VNRequestWarningImageMinimumShortDimension
VNRequestWarningBlinkDetectionFailure
VNRequestWarningTiledAnalysis
Vision
%@-%lu:MTL=%@:Det=%lu:MDm=%lu
Currently executed Request should not be nil
com.apple.%@
cancellation is not currently available
%@ does not support cancellation
imageBuffer
All elements in the %@ array must be of class %@ (%@)
%@ contains an entry for %@ that is dependent on a private revision %@
 preferBackgroundProcessing
 usesCPUOnly
v24@?0@"NSArray"8@"VNAsyncStatus"16
Timed out waiting for dependent task execution
v24@?0d8@"NSError"16
minDimension
maxDimension
idealDimension
idealFormat
wideRange
highRange
aspectHandling
idealOrientation
orientationAgnostic
    %@=%@
The %@ required option was not found
The %@ option was expected to be a %@, but was instead a %@ (%@)
landscape_cityscape
VN6OIpeIn2UKbA8EPIFdIs2H
VN1U5ssvGWQjrV1RUm9dL5pR
VN5XQJGcytY6ZCBlwCqdMbq0
VN3HBc5ma46eJPh5drbK827c
VN2bYrp5ZAmkNcYOAHlIZLns
Timed out waiting for dispatch_group_wait completion
Synchronization queue must be initialized
Maximum queue tasks count (%ld) must be a positive number
Controlled Capacity Tasks Queue: %@; %@
Maximum queue tasks count (%ld) is outside of the allowed range [1; %ld]
v32@?0@"NSString"8@"VNControlledCapacityTasksQueue"16^B24
com.apple.VN.VNRequestPerformingPriorityGroup1AsyncTasksQueue.%@
com.apple.VN.VNRequestPerformingPriorityGroup2AsyncTasksQueue.%@
com.apple.VN.requestAsyncTasksQueue
com.apple.VN.detectorAsyncTasksQueue.%@
com.apple.VN.detectorSyncTasksQueue.%@
FTp_data
FTp_elementsCount
FTp_elementsType
FTp_length
FTp_labelsAndConfidence
FTp_VNFaceTorsoprint
FTp_algorithmVersion
FTp_fp
FTp_tp
FTp_rev
FTp_pid
Wrong type of print object
state cannot be nil
Serialized and calculated MD5s don't match
Unexpected size of deserialized state of the object of type %@
Failed to initialize VNFaceTorsoprint object
Unexpected size of serialized state of the object of type %@
VNAnimalprintDetectorProcessOption_InputAnimalObservation
Unable to initialize frontalizer.
could not lock cropped image
Unexpected size of animalprint descriptor
pixelFormatType
-[VNMomentProcessor initWithOptions:error:]
MomentProcessor.mm
-[VNMomentProcessor computeClusteringOfImageDescriptors:intoKGroups:error:]
-[VNMomentProcessor computeNaturalClusteringOfImageDescriptors:error:]
-[VNMomentProcessor computeClusteringTreeForImageDescriptors:assumeDescriptorsAreSorted:error:]
q24@?0@"VNMPImageDescriptor"8@"VNMPImageDescriptor"16
v24@?0#8@"NSIndexSet"16
B32@?0#8Q16^B24
%@ does not provide an entity print that is compatible with a print generated by %@
faceprint
torsoprint
animalprint
%@ does not have a %@
%@ was generated by %@, which is not equivalent to %@
VNGenerateAttentionBasedSaliencyImageRequestPrivateRevisionStillCapturePipeline
VNGenerateAttentionBasedSaliencyImageRequestPrivateRevisionSceneNetV4
VNGenerateAttentionBasedSaliencyImageRequestPrivateRevisionSceneNetV4StillCapturePipeline
VNGenerateAttentionBasedSaliencyImageRequestPrivateRevisionSceneNetV5
VNGenerateAttentionBasedSaliencyImageRequestPrivateRevisionSceneNetV5StillCapturePipeline
results were not already populated by VNImageAnalyzerCompoundRequest
Bounding Box = %@; objectType = %ld; confidence = %f
%@ cannot be created from a read-only model
%@ cannot be created with a data source
%@ cannot open a read-only model
VN62b042cc67e0a7d589ecdb58232fe23d
VN9bdc36cda32be948a5089e37392596ec
VN81aedeb999c79d74e79af7f1c922cf97
VN9f5b8e9dc1b3c824d79372f87b072ee3
VNbe5c67b06e95370f5a7b67b13e73637c
VN220a6626eb3cb51295a4e250ad9da319
VN0af6454e97767772ce64a19ddaf61f0c
VNeeab04670e53ebeb25150a31963a1aa6
VNa0c07362d05e1dafb35b96d20d5ce42d
VN79a8f83d9d55eb4eb2c9695902c47b53
VNacdca02f0900c2cb198193f3eec7b6c9
VNJ4fWm08v8TFm5lmRVji9G
VNBcvG8BSEpHsJWme0UsCjT
Iden
Confid
VNFaceprint
type
fp_ec
fp_et
fp_l
fp_lac
fp_conf
fp_av
Attempt to deserialize nil
Input data is not a VNFaceprint
CVMLFaceprint
facePrint
Input data is neither VNFaceprint nor CVMLFaceprint. NSKeyedUnarchiver error = %@
Error deserializing VNFaceprint
Serialized state data is an unsupported version (%lu)
Serialized state data length is invalid
Serialized state payload data checksum mismatch
unsupported serialized state version %u
VNSaliencyImageObservation
OISW
OISH
SOBJ
BBOX
BBOY
BBSW
BBSH
NBBOX
NBBOY
NBBSW
NBBSH
VNBrightnessDetectorProcessOption_MaximumIntermediateSideLength
VNScreenGazeDetectorProcessOption_FaceObjectState
VNScreenGazeDetector: Predictor failed to determine gaze
screengazeflow-dw5gmeefrv_535001_quantized.espresso
VNClassifyImageAestheticsRequestPrivateRevisionStillCapturePipeline
VNClassifyImageAestheticsRequestPrivateRevisionSceneNetV4
VNClassifyImageAestheticsRequestPrivateRevisionSceneNetV4StillCapturePipeline
VNClassifyImageAestheticsRequestPrivateRevisionSceneNetV5
VNClassifyImageAestheticsRequestPrivateRevisionSceneNetV5StillCapturePipeline
VNRectangleTracking_BottomLeftTracker
VNRectangleTracking_BottomRightTracker
VNRectangleTracking_TopLeftTracker
VNRectangleTracking_TopRightTracker
No objects to track passed to the tracker
wrong type of a corner tracker allocated
initialization of internal object
Setting input rectangles to one of the rectangle corners failed
v32@?0@"NSString"8@"VNObjectTracker"16^B24
Tracker is not initialized
wrong type of a corner tracker object created
tracking of one or more of the rectangle corners failed
v32@?0@8@16^B24
Resetting tracker failed with error: %llu
VNRectangleObservation object is expected to initialize Rectangle Tracker
Tracking of %@ failed: confidence = %f; threshold = %f
Failed to create CVPixelBuffer.
Failed to create CVPixelBufferPool.
Failed to create CVPixelBuffer from pool.
%@ Width = %lu, Height = %lu, Format = %c%c%c%c
Failed to lock pixel buffer
Failed to unlock pixel buffer
Pixel buffer is null
Pixel buffer is missing an IOSurface
IOSurface is not valid
symbology
barcodeDescriptor
ACBSBarcodeInfo
MRCDescriptorAttributes
 (%@)
BCSDetectedCode
failed to get image from tensor
^{CGImage=}8@?0
failed to create comparison image
unsupported pixel format type
failed to create pixel buffer
docseg_segflow-xde2zmcdh5_64000_4ch_512x288_finalFC.espresso
BL_BR_TR_TL
docseg_segflow-xde2zmcdh5_64000_4ch.segmentation_labels.txt
maximumElementsPerID should be less or equal than INT32_MAX
v32@?0@"<NSObject><NSCopying><NSSecureCoding>"8@"NSNumber"16^B24
invalid face observation at index %lu for person at index %lu
mismatched faceprint request revision for observation at index %lu, person at index %lu
A prediction for an unknown identity with serial number %@ and confidence %f was provided
q24@?0@"VNPersonsModelPrediction"8@"VNPersonsModelPrediction"16
serialNumberToIdentifier
maximumElementsPerID
faceprintRequestRevision
faceIDModel
v32@?0@"NSNumber"8@"<NSObject><NSCopying><NSSecureCoding>"16^B24
Face ID model data deserialization failed with code %@
unable to serialize the face ID model (status = %@)
VNSmartCamClassifierProcessOption_ReturnAllResults
smartcam-descriptor
smartcam-classifier
smartcam-classifier-labels
smartcam-classifier-relationships
VN_DEBUG_DUMP_SMARTCAM_INTERMEDIATES
VN_smartcam_classifier_debug_intermediates/
model_junk_12_espresso
VNRecognizeObjectsRequestPrivateRevision26Identifiers
VNRecognizeObjectsRequestPrivateRevision585Identifiers
VNRecognizeObjectsRequestPrivateRevisionSceneNetV4
VNRecognizeObjectsRequestPrivateRevisionSceneNetV5
buffer cannot be nil
data overflow to %lu bytes
corrupted boolean value: %02X
Could not read expressions model data
Could not create face expression module
VNFaceExpressionDetector face does not have landmark points
Corrupt face mark data
%@ %@ %lu x %lu
name
pixelFormat
elementsCount
elementsType
length
labelsAndConfidence
VNSceneprint
algorithmVersion
labelsConfidences
failure with status %lld
 (%s)
encountered an unexpected condition: %s
encountered an unexpected condition: %@
NSException
encountered unknown exception
VNTextRecognitionOptionNone
VNTextRecognitionOptionASCIICharacterSet
VNTextRecognitionOptionEnglishCharacterSet
VNTextRecognitionOptionDanishCharacterSet
VNTextRecognitionOptionDutchCharacterSet
VNTextRecognitionOptionFrenchCharacterSet
VNTextRecognitionOptionGermanCharacterSet
VNTextRecognitionOptionIcelandicCharacterSet
VNTextRecognitionOptionItalianCharacterSet
VNTextRecognitionOptionNorwegianCharacterSet
VNTextRecognitionOptionPortugueseCharacterSet
VNTextRecognitionOptionSpanishCharacterSet
VNTextRecognitionOptionSwedishCharacterSet
ASCII
Text detector object was not created
invalid algorithm value of %lu
%@ is corrupt
@"NSString"8@?0
com.apple.vis.VNPersonsModel
cannot accept model version %lu
unknown person (%@)
operation was cancelled
unsupported algorithm %@
B32@?0@"VNFaceprint"8Q16^B24
the data source is no longer available
configuration has already been resolved to %@ and cannot be set to %@
unknown model kind '%@'
model data cannot be verified due to mismatched checksums
i12@?0I8
com.apple.vis.VNPersonsModelLoader
%@ read as %@
B28@?0I8@"NSObject"12^@20
<%@: %p> %lu identities
cannot create model with version %u
the face observation must not be nil
version
lastModDate
algorithm
readOnly
 K-means
 single mean
indexType
maxIdentities
faceprintsPerIdentity
configuration %@ cannot provide a %@
                              algorithm = %@
                      maximumIdentities = %lu
   maximumTrainingFaceprintsPerIdentity = %lu
               faceprintRequestRevision = %@
personUID
 '%@' confidence %f
acceptableVersions
readonly
faceprint is not available from the observation
incompatible faceprint revision
VNPersonsModelFaceModel
could not decode object of class %@
person identifier data
face observation %lu of %lu for person identifier '%@'
VNClassifyImageRequestPrivateRevisionSceneNetV4
VNClassifyImageRequestPrivateRevisionSceneNetV5
VNClassifyImageRequestPrivateRevisionSmartCamNet5
previous request results
VNFaceAttributeCategoryVersion
facrRev
FAC_label
FAC_LAC
VNFaceAttributesVersion
farRev
age_Cat
gender_Cat
eyes_Cat
smiling_Cat
facehair_Cat
haircolor_Cat
bald_Cat
glasses_Cat
makeup_Cat
makeupEyes_Cat
makeupLips_Cat
unknown01_Cat
unknown02_Cat
unknown03_Cat
unknown04_Cat
unknown05_Cat
unknown06_Cat
unknown07_Cat
facemask_Cat
UNKNOWN_1_unknown0
UNKNOWN_1_unknown1
UNKNOWN_1_unknown2
UNKNOWN_1_unknown3
UNKNOWN_1_unknown4
UNKNOWN_6_unknown0
UNKNOWN_6_unknown1
UNKNOWN_3_unknown0
UNKNOWN_3_unknown1
UNKNOWN_7_unknown0
UNKNOWN_7_unknown1
UNKNOWN_4_unknown0
UNKNOWN_4_unknown1
UNKNOWN_4_unknown2
UNKNOWN_4_unknown3
UNKNOWN_4_unknown4
UNKNOWN_5_unknown0
UNKNOWN_5_unknown1
UNKNOWN_5_unknown2
UNKNOWN_5_unknown3
UNKNOWN_5_unknown4
UNKNOWN_5_unknown5
UNKNOWN_2_unknown0
UNKNOWN_2_unknown1
UNKNOWN_0_unknown0
UNKNOWN_0_unknown1
UNKNOWN_0_unknown2
UNKNOWN_8_unknown0
UNKNOWN_8_unknown1
UNKNOWN_8_unknown2
UNKNOWN_9_unknown0
UNKNOWN_9_unknown1
UNKNOWN_9_unknown2
UNKNOWN_10_unknown0
UNKNOWN_10_unknown1
UNKNOWN_10_unknown2
UNKNOWN_10_unknown3
UNKNOWN_10_unknown4
UNKNOWN_11_unknown0
UNKNOWN_11_unknown1
UNKNOWN_11_unknown2
UNKNOWN_11_unknown3
UNKNOWN_11_unknown4
UNKNOWN_11_unknown5
UNKNOWN_12_unknown0
UNKNOWN_12_unknown1
UNKNOWN_12_unknown2
UNKNOWN_12_unknown3
UNKNOWN_12_unknown4
UNKNOWN_12_unknown5
UNKNOWN_12_unknown6
UNKNOWN_13_unknown0
UNKNOWN_13_unknown1
UNKNOWN_13_unknown2
UNKNOWN_13_unknown3
UNKNOWN_13_unknown4
UNKNOWN_13_unknown5
UNKNOWN_13_unknown6
UNKNOWN_14_unknown0
UNKNOWN_14_unknown1
UNKNOWN_14_unknown2
UNKNOWN_14_unknown3
UNKNOWN_14_unknown4
UNKNOWN_15_unknown0
UNKNOWN_15_unknown1
UNKNOWN_15_unknown2
UNKNOWN_15_unknown3
UNKNOWN_15_unknown4
UNKNOWN_16_unknown0
UNKNOWN_16_unknown1
UNKNOWN_16_unknown2
UNKNOWN_16_unknown3
UNKNOWN_16_unknown4
UNKNOWN_16_unknown5
UNKNOWN_17_unknown0
UNKNOWN_17_unknown1
Wisdom
wisdom parameters are not available for the system
v32@?0@"NSString"8@"NSDictionary"16^B24
wisdom parameters are not available for the device "%@"
Wrong type for warning value - %@, should be %@
detectionprint
VNSegmentationGeneratorProcessOption_PersonSegmentationDetectorOriginatingRequestSpecifier
VNSegmentationGeneratorProcessOption_SkySegmentationDetectorOriginatingRequestSpecifier
VNSegmentationGeneratorProcessOption_QualityLevel
VNSegmentationGeneratorProcessOption_OutputPixelFormat
VNSegmentationGeneratorProcessOption_KeepRawOutputMask
VNSegmentationGeneratorProcessOption_MaskImageObservations
VNSegmentationGeneratorProcessOption_UseTiling
VNSegmentationGeneratorProcessOption_MinimumConfidence
VNSegmentationGeneratorProcessOption_ImageRotated
VNSegmentationGeneratorProcessOption_ImageROI
qualityLevel
B32@?0@"NSString"8^{BufferSize=QQ}16^@24
Unexpected number for masks returned
Missing keepRawOutputMask for %@
Missing resultPixelFormat for %@
Unsupported output pixel format of %x
@"NSArray"24@?0@"VNPixelBufferObservation"8^@16
v32@?0@"NSMutableArray"8Q16^B24
sc_d
sc_ec
sc_et
sc_l
sc_lac
VNSmartCamprint
sc_av
%02X
bits
bit data must not be nil
Cannot encode boolean byte data of length %lu because it is not a multiple of 8.
rowProjections
rowSum
rowSumSq
colProjections
colSum
colSumSq
nil buffer passed into initWithImageBuffer
Error while trying to allocate VNImageSignature object
inconsistent row data
inconsistent column data
VNDetectorInternalProcessOption_RecordImageTooSmallWarning
VNDetectorInternalProcessOption_DesiredMinimumFacePrintingLongDimension
Could not run network. Error = %s
Error calculating print
Could not get print output. Error = %s
Could not get confidence output. Error = %s
Error classifying attributes
Could not get attributes output. Error = %s
yyyy:MM:dd HH:mm:ss
operation points object must be allocated before calling this method
The %d argument had an illegal value.
The %d-th diagonal element of the triangular factor of A is zero, so that A does not have full rank; the least squares solution could not be computed.
GenericSportBall
VNRecognizeSportBallsRequestPrivateRevisionANSTModel
unknown
VNFaceSegmentGeneratorProcessOption_FaceBoundingBoxExpansionRatio
VNFaceSegmentGeneratorInternalProcessOption_FaceSegmentBBoxNormalized_X
VNFaceSegmentGeneratorInternalProcessOption_FaceSegmentBBoxNormalized_Y
VNFaceSegmentGeneratorInternalProcessOption_FaceSegmentBBoxNormalized_Width
VNFaceSegmentGeneratorInternalProcessOption_FaceSegmentBBoxNormalized_Height
Failed to create Face Segmenter object
Invalid parameter (size)
Unexpected request revision
Invalid parameter (numberOfSupportedFaceSegments)
One of the dimensions of the input face image is zero
Input face aspect ratio > %f cannot be processed
Expected labelConfidence map of %lu x %lu and got %lu x %lu
width
height
rowBytes
cannot map face segments
faceSemantics_v1_15class_quant.espresso
VNVideoProcessingOptionFrameCadence
VNVideoProcessingOptionTimeInterval
VCPVideoProcessor
PtSpec
VCPPersonObservation
VCPHandObservation
VNHumanPoseDetectorProcessingOption_UseCPUOnly
Human Pose Request is not initialized
Unable to create observation
%@ is not supported
                        algorithm = %@
                  maximumEntities = %lu
   maximumTrainingPrintsPerEntity = %lu
    entityPrintOriginatingRequest = %@
maximumEntities
printsPerEntity
printOriginatingRequest
Could not bind output aesthetics scores
Could not bind image to network
Unexpected result
scenenet_sceneprint_r9_opt_int8.espresso
mergesCount
smartDistance
B24@?0@"ShotflowDetection"8@"NSDictionary"16
VNANFDMultiDetectorProcessingOption_FoodAndDrinkRecognitionOriginatingRequestSpecifier
Unexpected detector object type
VNOpticalFlowGeneratorProcessOption_PreviousObservation
VNOpticalFlowGeneratorProcessOption_ComputationAccuracy
VNOpticalFlowGeneratorProcessOption_OutputPixelFormat
VNOpticalFlowGeneratorProcessOption_KeepNetworkOutput
VNOpticalFlowGeneratorProcessOption_FromAndToPixelBuffers
VNOpticalFlowGeneratorProcessOption_PortraitMode
VNFaceDetectorPrivateRevisionLegacyFaceCoreProcessOption_Type
VNFaceDetectorPrivateRevisionLegacyFaceCoreProcessOption_ROIs
VNFaceDetectorPrivateRevisionLegacyFaceCoreProcessOption_MinFaceSize
VNFaceDetectorPrivateRevisionLegacyFaceCoreProcessOption_NumberOfDetectionAngles
VNFaceDetectorPrivateRevisionLegacyFaceCoreProcessOption_InitialAngle
VNFaceDetectorPrivateRevisionLegacyFaceCoreProcessOption_EnhanceEyesAndMouthLocalization
VNFaceDetectorPrivateRevisionLegacyFaceCoreProcessOption_ExtractBlink
VNFaceDetectorPrivateRevisionLegacyFaceCoreProcessOption_ExtractSmile
Failed to create detector
Failed to create internal image
origDim
pcaDim
espresso-descriptor
espresso-classifier
espresso-classifier-labels
espresso-classifier-relationships
VNEspressoModelClassifierProcessOption_CenterTileOnly
%@ must implement classifierResourceTypesToNamesForOriginatingRequestSpecifier: for %@
could not locate the resource file "%@"
%@ must implement +classifierResourceTypesToNamesForOriginatingRequestSpecifier: for %@
%@ with a %@ is not supported
Cannot calculate classification image descriptor
Cannot create image print
Cannot create observation object
Could not compute raw labels and confidence for image
resource key "%@" is not available
could not locate %@ in %@
VNDetectBarcodesRequestPrivateRevision2
v32@?0@"NSString"8@"NSString"16^B24
Payload data is missing
QRErrorCorrectionLevel data is missing
QRErrorCorrectionLevel data is invalid
QRSymbolVersion data is missing
QRMaskPattern data is missing
IsCompact data is missing
LayerCount data is missing
CodewordCount data is missing
RowCount data is missing
ColumnCount data is missing
VNDetectBarcodesLocateModeCenterOneVertical
VNDetectBarcodesLocateModeCenterOneVerticalThick
VNDetectBarcodesLocateModeCenterThreeVertical
VNDetectBarcodesLocateModeCenterThreeVerticalCrossed
VNDetectBarcodesLocateModeCenterOneHorizontal
VNDetectBarcodesLocateModeCenterOneHorizontalThick
VNDetectBarcodesLocateModeCenterThreeHorizontal
VNDetectBarcodesLocateModeCenterThreeHorizontalCrossed
VNDetectBarcodesLocateModeCenterOneEachDirection
VNDetectBarcodesLocateModeCenterThreeEachDirection
VNDetectBarcodesLocateModeCenterFiveEachDirection
VNDetectBarcodesLocateModeCenterThreeEachDirectionAndCoverageAndDiagonals
VNDetectBarcodesLocateModeCenterThreeVerticalAndCoverageAndDiagonals
VNDetectBarcodesLocateModeCenterThreeHorizontalAndCoverageAndDiagonals
VNDetectBarcodesLocateModeFastSearch
VNDetectBarcodesLocateModeRegularIntervalHorizontal
VNDetectBarcodesLocateModeRegularIntervalVertical
barcode detection requires at least one element in the symbologies property
%@ is not a supported barcode symbology
barcode type is not available
unknown barcode type of '%@'
_new%@DescriptorForMRCDescriptor:error:
barcode location is not available
invalid barcode location information
Failed to create MRCSample
_new%@DescriptorForACBSBarcodeInfo:
creation of a barcode descriptor for %@ is not supported
unable to create a barcode descriptor for %@
failed to analyze image
camgaze_probs
VNImageNeuralHashprintObservation
nrlHshPrnt
VNObjectTrackerRevision1Type
VNObjectTrackerRevision2Type
VNObjectTrackerRevision2Type_RPNTrackerInitModelName
VNObjectTrackerRevision2Type_RPNTrackerTrackModelName
VNObjectTrackerRevisionLegacyFaceCoreType
VNRectangleTrackerType
v32@?0@"NSString"8#16^B24
com.apple.VN.trackersCollectionManagementQueue_%lu
com.apple.VN.trackingProcessingQueue_%lu
A tracker cannot be created without specifying a unique tracker key
Cannot create a Tracker with unknown tracker type: %@
Internal error: Exceeded maximum allowed number of Trackers for a tracker type: %@
GreedyWithTorsoClustering.cpp
VNGuidedUpsamplingGeneratorOption_LowResImages
VNGuidedUpsamplingGeneratorOption_InputPixelFormat
VNGuidedUpsamplingGeneratorOption_OutputPixelFormats
Mismatched lowResObservations and outputPixelFormats count
Pixel format mismatch
unsupported output pixel format
VNPixelBufferObservation missing pixel buffer
^{__CVBuffer=}24@?0@"VNPixelBufferObservation"8^@16
facerec_fp3.1.3b_fa1.3.espresso
observation
entityUID
VNSmartCam5GatingDetectorProcessingOption_ClassificationEnabled
VNSmartCam5GatingDetectorProcessingOption_ClassificationOriginatingRequestSpecifier
VNSmartCam5GatingDetectorProcessingOption_ClassificationObservationsArray
VNSmartCam5GatingDetectorProcessingOption_GatingOriginatingRequestSpecifier
VNSmartCam5GatingDetectorProcessingOption_GatingObservationsArray
VNSmartCam5GatingDetectorProcessingOption_DocumentRegionGatingEnabled
VNSmartCam5GatingDetectorProcessingOption_DocumentRegionGatingGenerateSegmentationMask
VNSmartCam5GatingDetectorProcessingOption_TextRegionGatingEnabled
VNSmartCam5GatingDetectorProcessingOption_TextRegionGatingGenerateSegmentationMask
VNSmartCam5GatingDetectorProcessingOption_MachineReadableCodesGatingEnabled
VNSmartCam5GatingDetectorProcessingOption_MachineReadableCodesGatingGenerateSegmentationMask
appcode
qr_code
unable to create segmentation image for %s
MRC5heads_76f6w2kjaz_61501_ay5mhf87cq_97501_hbnrcg6e5e_89040_8g7zthf4q3_12751_rucb99jtq8_75751_8d9qwisndd_85501_concat_quant.espresso
text
smartcam_assembly-classification-labels.txt
smartcam_assembly-segmentation-labels.txt
leaf_semdev_text_water
segmentation/MRC_softmax
%@ %@ %@
framework
VNHLKWRI
VNHLKTCMC
VNHLKTMP
VNHLKTIP
VNHLKTTIP
VNHLKIMCP
VNHLKIPIP
VNHLKIDIP
VNHLKITIP
VNHLKMMCP
VNHLKMPIP
VNHLKMDIP
VNHLKMTIP
VNHLKRMCP
VNHLKRPIP
VNHLKRDIP
VNHLKRTIP
VNHLKPMCP
VNHLKPPIP
VNHLKPDIP
VNHLKPTIP
VNHLRKT
VNHLRKI
VNHLRKM
VNHLRKR
VNHLRKP
VNDetectHumanHandPoseRequestPrivateRevisionStarSkyModelDrop1
%@ labelKey = %d; rotationAngle = %f; yawAngle = %f, pitchAngle = %f
-[VNMPImageData initWithVImage:externalImageId:andExifTimestampValue:error:]
MPImageData.m
ERROR: The input image does not seem to be 8888
-[VNMPImageData initWithCVPixelBufferImage:externalImageId:andExifTimestampValue:error:]
%@ must implement %@
unknown classification identifier "%@"
no operation point data is available for "%@"
LKT:waitUntilCompleted
Unhandled metal pixel format
Could not bind pixel buffer to texture
Optical flow estimation invalid state
LKT::Pyramid
LKT:ComputeFlow level %d
lkt_bgra2yuva
lkt_zero_flow
lkt_downscale_2x
lkt_features
lkt_features_derivatives
lkt_solver_prepare_matrices
lkt_solver_box7_y
lkt_solver_box_x_and_Axb
lkt_nlreg_hegbf
Failed to scale the input image
Failed to center square crop the input image
unable to determine preferred image size for detection
VNRequestFaceLandmarksConstellationNotDefined
VNRequestFaceLandmarksConstellation65Points
VNRequestFaceLandmarksConstellation76Points
VNDetectFaceLandmarksRequestPrivateRevisionANSTModel
VNDetectFaceLandmarksRequest revision %lu doesn't support constellation %lu
VNIp
ipType
MPImDesc
ipReqRev
ipOrgReq
otherImageprint cannot be nil
could not compute faceprint distance
Invalid format of VNImageprint serialized state
Failed to deserialize requestRevision
Failed to initialize VNImageprint object
VNFaceGeometryEstimatorInitOption_ImageSize
VNFaceGeometryEstimatorInitOption_CameraFocalLength
VNFaceGeometryEstimatorProcessOption_EstimatePoseOnly
eigenshape
Could not read face geometry estimator model data
Failed to estimate face geometry
_%llu
Cannot create MTLDevice
Unimplemented conversion
Failed to create MTLCommandQueue
pixel buffer does not have an IOSurface
Pixel buffer does not have an IOSurface
IOsurface width is smaller than texture width
IOsurface height is smaller than texture height
Failed to create MTLTextureDescriptor
Failed to create MTLTexture
v32@?0@"<MTLTexture>"8Q16^B24
v32@?0@"<MTLBuffer>"8Q16^B24
Q24@?0Q8^@16
Unimplemented format for guided upsampling
Texture array cannot be empty
Texture sizes do not match
Texture pixel formats do not match
Invalid texture count of 0
Texture count mismatch between input and output textures
Texture size mismatch
ImageFilters
metallib
contrastFromAverage
CIAreaAverage
contrastWithPivot
com.apple.VN
multiplyByFactor
emp_data
emp_elementsCount
emp_elementsType
emp_length
emp_labelsAndConfidence
VNEspressoModelImageprint
VNEspressoModelImageprintRequestRevision
emp_algorithmVersionCodingKey
emp_algorithmVersion
request
descriptorData
f16Desc
descriptorByteLength
elementCount
element count must be non-zero
%lu elements of type %@ with length of %lu mismatch to descriptor data length %lu
unable to create float16 descriptor with %lu elements
%@ does not specify a default originating request class
%@ could not resolve originating request class of %@: %@
descriptor data length (%lu) / expected length (%lu) mismatch
The '%@' data is not the expected length of %lu
descriptor data is unavailable
descriptor length is unavailable
unable to create a %@ %@ %@ descriptor with length %@
State cannot be nil
Invalid input data to de-serialize a print object
Invalid format of %@ serialized state
Memory allocation failure
Failed to initialize 'print' object
nil VNEspressoModelImageprint(s) supplied
VNEspressoModelImageprint(s) with different length supplied
Unknown distance funtion requested
cannot compare prints of %@ and %@
Espresso print: version = %@; element count = %lu; element type = %@; length in bytes = %lu; confidence score type = %lu; originating request specifier = %@
invalid element type of %@
float32 data was not a length multiple of 4
float16 data was not a length multiple of 2
facerec_fp3.1_fa1.3.espresso
VNImageAestheticsObservation
OAES
PLHT
PREF
LCOL
PSYM
PPAT
PPERS
PPOST
NOISE
FAIL
PCOMP
INTREST
INTRUSIVE
CTILT
HCOL
LOWKEY
Score
aestheticScore
  %@=%@
VNCntsObs
Points
Size
B16@?0r^{EPolygonList=ii^{EPolygon}i}8
v32@?0^{EPolygonList=ii^{EPolygon}i}8{CGSize=dd}16
Failed to execute bit string to polygon list with error: %@
contourIndex
argument indexPath cannot be empty
indexPath
VNTrajectoryProcessorOption_RequestState
VNTrajectoryProcessorOption_ObjectMinimumNormalizedRadius
VNTrajectoryProcessorOption_ObjectMaximumNormalizedRadius
VNTrajectoryProcessorOption_ProcessingTargetFrameTime
CIColorAbsoluteDifference
CIColorThreshold
inputThreshold
CIMorphologyRectangleMaximum
inputWidth
inputHeight
CIColorControls
inputImage
inputImage2
CIMaximumComponent
Could not create intermediate buffer
cannot perform analysis with minimum object radius of %f and maximum object radius of %f
Too many moving objects or noise detected which prevents trajectory processing.
faceRegionMap-current
Could not read face region map model data
VNObservation
uuid
timeRange
 confidence=%f
 timeRange=%@
Data detecor not supported for %@
Could not create DataDetector
VNDetectedObjectObservation
%@ boundingBox=%@
VNFaceObservation
alignedBBX
alignedBBY
alignedBBW
alignedBBH
unalignedBBX
unalignedBBY
unalignedBBW
unalignedBBH
unalignedBBXAsDouble
unalignedBBYAsDouble
unalignedBBWAsDouble
unalignedBBHAsDouble
landmarks65
landmarksConstellation
precisionEstimates
landmarks3D
pose
poseOrigReq
expressions
faceID
faceIDConfidence
faceTorsoprint
hasAlignedBBox
alignedRotAngle
roll
pitch
faceRegionMap
blinking
blinkScore
alignedMeanShape
landmarksScore
faceOrientationIndex
faceJunkinessIndex
faceCaptureQuality
faceAttributes
faceSmntcSegments
faceLMRequestRev
faceLM3DRequestRev
faceLMOReq
faceLM3DOReq
gaze
screengaze
exifOrientation cannot be null
face orientation
Data integrity check failed when un-archiving landmarks constellation. Un-archived constellation is out of range: %lu
invalid pose data
 ID=%lu
 VNFaceLandmarks2D [%@, confidence=%f]
leftEyebrow
leftEye
rightEyebrow
rightEye
noseCrest
nose
medianLine
faceContour
outerLips
innerLips
referenceImageSignature
floatingImageSignature
%@ is not supported by %@
alignmentTransform
warpTransform
exposure
 blurScore=%@
 exposureScore=%@
VNImageprintObservation
descriptor
VNImageprint
nil imageprint supplied
Failed creating a new VNImageprintObservation object
identifier
operationPoints
 "%@"
 (P/R)
%@ cannot provide operation points
%@ labels=[%@]
labels
segmentationMask
featureValue
featureName
%@ "%@" - "%@" (%f)
vnpbo_pbdict
CIColorMatrix
inputBVector
transform
angle
vncluster
vncObjects
vncCId
vncTotObjCount
vncRepUpdate
vncRepIds
vncRepnessById
  clusterId = %lu;
  totalObjCount = %lu;
  objects = %@;
  shouldUpdateRep = %d;
  suggestedIdsForRep = %@;
  representativenessById = %@;
Data integrity check failed when unarchiving an object of type: %@
clusters
suggestions
clusterState
clusteredFaceIDs
groupedClusteredFaceIDs
level0Distance
distancesByID
The revision of the observations do not match
The observations do not have a feature print that match each others format
One or more of the feature prints are empty
VNSceneObservation
algo
descriptors
Undefined
VNSmartCamObservation
sc_algo
sc_descriptors
textObjects
requestUuid
detPts
projPts
eqCoeffs
mvAvgRad
characterBoxes
Cannot create VTPixelTransferSessionRef object: session: %lu, error: %d
B16@?0@"VNVTSession"8
@"VNVTSession"16@?0^@8
torso_v4_md2.espresso
anodv3_torso_v4_md2
VNDetectFacePoseRequestPrivateRevisionANSTModel
The region of interest [%g, %g, %g, %g] is not within the normalized bounds of [0 0 1 1]
%@ ROI=%@
 inputFaceObservations=[%@]
 inputDetectedObjectObservations=[%@]
B32@?0@"VNFaceObservation"8Q16^B24
B32@?0@"VNDetectedObjectObservation"8Q16^B24
No entity for identity serial number %d
q24@?0@"VNEntityIdentificationModelPrediction"8@"VNEntityIdentificationModelPrediction"16
entity unique identifier / print count mismatch
invalid observation at index %lu for entity at index %lu
entity index %lu, observation index %lu was generated by %@, which is not compatible with the model requirement of %@
v32@?0@"<NSObject><NSCopying><NSSecureCoding>"8Q16^B24
entityUniqueIdentifiers
entityPrintCounts
entityPrintOriginatingRequestSpecifier
entity unique identifier counts (%lu) do not agree with the print counts (%lu)
VNCreateAnimalprintRequestPrivateRevision1MD2
{CGRect={CGPoint=dd}{CGSize=dd}}
pixelBuffer cannot be null
pixelBuffer is not in correct format. (Required format is one component, 32-float)
thresholds not provided
Unable to generate smoothed float-32 image buffer
VNRecognizeAnimalsRequestPrivateRevisionANODv3
VNRecognizeAnimalsRequestPrivateRevisionANSTModel
torso_v3_md2_fp16.espresso
anodv3_torso_v3_md2
%@ not available
Unable to setup request in VNDetectHumanBodyPoseRequest
VCPHumanPoseImageRequest
vnpbo_width
vnpbo_height
vnpbo_bpr
vnpbo_pixelFormat
vnpbo_attribs
vnpbo_attach
vnpbo_bytes
%@_%zu
tplTracker_FFT_3324
tplTrackerFFT.c
(outputIndex >= 0) && (outputIndex < 72)
tplTracker_IFFT_3324
VNContourDetectorProcessOption_ContrastAdjustment
VNContourDetectorProcessOption_ContrastPivot
VNContourDetectorProcessOption_DetectDarkOnLight
VNContourDetectorProcessOption_MaximumImageDimension
VNContourDetectorProcessOption_ForceUseInputCVPixelBufferDirectly
VNContourDetectorProcessOption_InHierarchy
VNContourDetector: Failed to create image filters
VNContourDetector: Original buffer could not be found
VNContourDetector: Failed to adjust contrast
VNContourDetector: Failed to create pixel buffer for adjusted image
VNContourDetector: Error extracting contours
VNClassifyFaceAttributesRequestPrivateRevisionCameraLightweight
VNClassifyFaceAttributesRequestPrivateRevision1_3_MD2
VNClassifyFaceAttributesRequestPrivateRevision1_3_MD3
VNClassifyFaceAttributesRequestPrivateRevision1_3_MD3_HomeApp
Balanced quality level is handled by compound request
Empty observations
portrait
landscape
Accurate
Balanced
Fast
@"NSString"16@?0Q8
%@ qualityLevel=%@
%@ useTiling=%d minimumConfidence=%f
VNGeneratePersonSegmentationRequestPrivateRevisionInstanceBased4People
no image buffer available
pixelBuffer
cgImage
ciImage
AdjacentContourHeal
Contours.c
PCOORD_EQUAL(joinPoint, LAST_PCOORD(cPtrN))
PCOORD_EQUAL(joinPoint, FIRST_PCOORD(cPtrN))
healCenters
ady == 2
heal
(endpoint2 == 4)|| (endpoint2 == 8)
(endpoint2 == 8)|| (endpoint2 == 6)
(endpoint2 == 6)|| (endpoint2 == 2)
(endpoint2 == 2)|| (endpoint2 == 4)
testJoin
(orn >= 0) && (orn <= 8)
orn != 4
VNInferenceNetworkIdentifierSmartCam
VNInferenceNetworkIdentifierSceneNet
VNInferenceNetworkHeadIdentifierSceneprint
VNInferenceNetworkHeadIdentifierSceneClassification
VNInferenceNetworkHeadIdentifierAesthetics
VNInferenceNetworkHeadIdentifierSaliencyA
VNInferenceNetworkHeadIdentifierSaliencyO
VNInferenceNetworkHeadIdentifierFeatureExtractor
VNInferenceNetworkHeadIdentifierFingerprinting
VNInferenceNetworkIdentifierSceneNetObjDetNetSliderNet
VNInferenceNetworkHeadIdentifierObjDetNet
VNInferenceNetworkHeadIdentifierSliderNet
VNInferenceNetworkIdentifierStandaloneSceneprint
VNInferenceNetworkIdentifierFaceprint
%@ %@ --> %@
available%@Versions
v24@?0#8^B16
q24@?0@"VNResourceVersion"8@"VNResourceVersion"16
Network does not have head with identifier "%@"
Network does not have input "%@"
Network does not have output "%@"
no inference network for %@ %@
   (%@ %@)
v32@?0@"NSString"8@"VNResourceVersion"16^B24
   --> %@
       
   <-- %@
networkURL
networkVersion
inputs
outputs
inputImages
networkHeadVersions
confidencesOutput
landmarks
landmarks_63
landmarks_76
occlusion
FaceIDModel_v1_d18
aligned buffer allocation of 
 exceeded calculated size of 
matrix vector size mismatch
vector size too small for output
VNHumanHandPoseDetectorProcessOption_MaximumHandCount
Unable to setup request in VNDetectHumanHandPoseRequest
VCPHandPoseImageRequest
VCPRequestRevisionPropertyKey
VCPRequestMaxNumOfHandsPropertyKey
%@ upperBodyOnly=%@
VNDetectHumanRectanglesRequestPrivateRevisionANODv3
VNDetectHumanRectanglesRequestPrivateRevisionANSTModel
ap_conf
Error deserializing object of type %@
learnedmatting-f16-v2.espresso
learnedMatting_createTileWithScale
learnedMatting_pasteTile
VNSegmentationGenerator - output tiles queue is empty
^{__CVBuffer=}84@?0@"<MTLCommandBuffer>"8{CGRect={CGPoint=dd}{CGSize=dd}}16@"<MTLTexture>"48{BufferSize=QQ}56I72^@76
B96@?0Q8Q16{CGRect={CGPoint=dd}{CGSize=dd}}24{CGRect={CGPoint=dd}{CGSize=dd}}56^@88
pixel format unimplemented
Model name: %@, network: %p, plan: %p: context: %p
VN_ALTERNATE_MODEL_RESOURCE_PATH
resourceDirectory must point to a valid reference
model_opt.espresso
Unable to locate %@
Frameworks/LoopKitGeneratedKernels.framework/
%@/%@
Unable to locate resource bundle
anod_v3_d3
Using alternate resource path = %@
Unable to locate resource "%@" of type "%@" in %@
unable to introspect %@
blob "%@" was not found in %@
Invalid inputs specified to inference plan builder
Could not create inference context
Could not create inference plan
Could not create/add network to inference plan
Could not set network configuration: %@
Could not declare network input buffer: %@
Could not declare network output buffer: %@
Could not build inference plan
Unsupported pixel format %lu
Error allocating %lu x %lu CVPixelBuffer with format %lu
inference buffer image with dimensions %ld x %ld cannot be rendered into a pixel buffer with dimensions %ld x %ld
could not lock pixel buffer
Unsupported inference buffer storage type (%lu)
inference buffer image with row bytes size of %ld cannot be rendered into a pixel buffer with %lu bytes per row
Unknown inference buffer type
inference network cannot be nil
Could not bind output buffer to network
Could not bind input buffer to network
Could not feed-forward buffer data because of compatibility of source and destination buffers
alpha
alpha_refined
learned-matting-1512x2016.espresso
DogHead
CatHead
VNRecognizeAnimalHeadsRequestPrivateRevisionANSTModel
(^\s*|\s*$)
true
unordered_map::at: key not found
VNImageRegistrationDetectorProcessOption_ReferenceImageRegistrationSignature
VNImageRegistrationDetectorProcessOption_FloatingImageRegistrationSignature
VNImageRegistrationDetectorProcessOption_MinimumOverlapPercentage
person
water
foliage
VNPanopticSegmentationGeneratorProcessOption_Categories
VNPanopticSegmentationGeneratorProcessOption_OutputPixelFormat
VNPanopticSegmentationGeneratorProcessOption_Rotated
VNSegmentationGenerator: failed to create pixel buffer
panopticsegmentation-u8-v1.2.espresso
detection/boxes
detection/confidences
detection/ious
segmentation/masks
CPU optical flow not properly initialized
Input pixel buffer invalid pixel format
Failed to lock input pixel buffer
VNDetectionprintTensorKeyMixed2
VNDetectionprintTensorKeyMixed6
VNDetectionprintTensor '%@' is not available
unable to create originating request specifier: %@
tensors
ERTFaceBox::ERTNumCascadeStages
ERTFaceBox::ERTNumTrees
ERTFaceBox::ERTNumPredictions
ERTFaceBox::ERTNodesThresholds
ERTFaceBox::ERTNodesPredictions
ERTFaceBox::ERTNodesFeatureIDs
ERTFaceBox::ERTNodesLeafFlags
ERTFaceBox::ERTGlobalShift
ERTFaceBox::ERTDefaultPixelValue
ERTFaceBox::ERTDefaultFeatureValue
ERTFaceBox::ERTNumXYPairs
ERTFaceBox::ERTXYPairs
ERROR: ERTDefaultPixelValue failed to load from ERT model file!
ERROR: ERTDefaultFeatureValue failed to load from ERT model file!
Error: 
 failed to load from ERT model file!
 unexpected size of value
%@ "%@" %@ %@
Spans.c
spl != NULL
addSpan
This method must be overriden
groupKey
unable to locate point '%@'
AllPoints
recognized points are not available
junk
junk-descriptor-current
junk-classifier-current
junk-classifier-labels-current
VN_junk_classifier_debug_intermediates
.json
VN_DEBUG_DUMP_JUNK_INTERMEDIATES
VN3FNQUJVIs2puI1uPc9mxh7
VNSY8t4EoTztuqIL02g8uVA0
VN6XNMvaRunPpzWjGa9uUHD6
VN4QuphG8kE4qDaDycivBkX5
VN7gQUejje8mmnE9GSTsVBVV
VNa9xpOJNvRoaW9plFGZ9Eo0
VN2vIWnsZbk4Su55oeWfKDq1
VNmNJnu0xlW8CZXt6hJ7Rpb0
VN35FOB1QhtSfYGRIJvTgtTq
VN6ZsEIQ9ri2eF1vhsxw5COm
VN586xt6lvDeEI7qF1vKQLrD
VN4EVgYIp7c9hqurREgYE3oE
VN5M3z9ICRcyCF1ByLEwd9pZ
input__0
add3__0
VNRectangleDetectorProcessOption_Version
VNRectangleDetectorProcessOption_MaximumNumber
VNRectangleDetectorProcessOption_MinimumConfidence
VNRectangleDetectorProcessOption_MinimumAspectRatio
VNRectangleDetectorProcessOption_MaximumAspectRatio
VNRectangleDetectorProcessOption_QuadratureTolerance
VNRectangleDetectorProcessOption_MinimumSize
VNRectangleDetectorProcessOption_HighAccuracy
VNRectangleDetectorProcessOption_CropRect_X
VNRectangleDetectorProcessOption_CropRect_Y
VNRectangleDetectorProcessOption_CropRect_Width
VNRectangleDetectorProcessOption_CropRect_Hight
VNRectangleDetectorProcessOption_OriginalScaleFactor
VNRectangleDetectorProcessOption_TargetScaleY
invalid region of interest: %@
VNRectangleDetectorProcessOption_MinimumAspectRatio value, %f is greater than VNRectangleDetectorProcessOption_MaximumAspectRatio value, %f
 PixelFocalLength value is out of bounds: %f
faceimage
facelocxy
VNFaceDetectorInitOption_MinFaceSize
VNFaceDetectorInitOption_EnableLowMemoryMode
{CGRect={CGPoint=dd}{CGSize=dd}}16@?0@"VNObservation"8
VN_DEBUG_DUMP_FACE_DETECT_INTERMEDIATES
VN_facedetector_debug_intermediates/
_fd_image.vdump
_fd_image.png
_raw_bboxes.json
%@_face_%d
_raw_bbox_crop.png
imageURL
<binary-data>
rect
VN Face detector debug intermediates written to: %@
invalid ROI size of %f x %f
invalid tile size of %ld x %ld
invalid tile increment of %lu x %lu
unexpected ROI origin causing %lui rows of %f x %f
VNFaceLandmarkRegion
FLMReg_BBX
FLMReg_BBY
FLMReg_BBW
FLMReg_BBH
FLMReg_PtCnt
FLMReg_OReq
FLMReg_Rev
VNFaceLandmarkRegion2D
FLMReg2D_PtsData
FLMs_PtsAE
FLMReg2D_PtsClsf
VNFaceLandmarkRegion3D
FLMReg3D_PtsData
VNFaceLandmarks
FLMs_Conf
FLMs_PtsCnt
FLMs_PtsData
FLMs_AlgnBBoxX
FLMs_AlgnBBoxY
FLMs_AlgnBBoxW
FLMs_AlgnBBoxH
FLMs_UsrFacingBBoxX
FLMs_UsrFacingBBoxY
FLMs_UsrFacingBBoxW
FLMs_UsrFacingBBoxH
FLMs_OReq
FLMs_Rev
VNFaceLandmarks2D
FLMs2D_CType
FLMs2D_PtsAE
VNFaceLandmarks3D
Failed to unarchive VNFaceLandmarkRegion object due to coding version mismatch: Currently supported: %u; encoded: %u
could not decode originating request
%@ does not provide a default originating request class
Failed to unarchive VNFaceLandmarkRegion object. Error: %@
%@ faceBoundingBox=%@ pointCount=%lu requestRevision=%lu
[VNFaceLandmarkRegion2D -initWithRequestRevision:faceBoundingBox:] is not available, use class designated initializers
Failed to unarchive VNFaceLandmarkRegion2D object due to coding version mismatch: Currently supported: %u; encoded: %u
Failed to unarchive VNFaceLandmarkRegion2D object. Error: points buffer size mismatch (data size: %lu; expected: %lu)
Failed to unarchive VNFaceLandmarkRegion2D object. Error: %@
failed to allocate internal points array
{CGSize=dd}
[VNFaceLandmarkRegion3D -initWithRequestRevision:faceBoundingBox:] is not available, use class designated initializers
Failed to unarchive VNFaceLandmarkRegion3D object due to coding version mismatch: Currently supported: %u; encoded: %u
Failed to unarchive VNFaceLandmarkRegion3D object. Error: points buffer size mismatch (data size: %lu; expected: %lu)
Failed to unarchive VNFaceLandmarkRegion3D object. Error: %@
Failed to unarchive VNFaceLandmarks object due to coding version mismatch: Currently supported: %u; encoded: %u
Failed to unarchive VNFaceLandmarks object. Error: %@
Can't use abstract base class. Must be VNFaceLandmarks2D or VNFaceLandmarks3D
%@ pointCount=%lu requestRevision=%lu
Failed to unarchive VNFaceLandmarks2D object due to coding version mismatch:Currently supported: %u; encoded: %u
Unexpected number of landmark points: %lu; expected: %lu
Failed to unarchive VNFaceLandmarks2D object. Error: %@
pointIndices must not be nullptr
Failed to unarchive VNFaceLandmarks3D object due to coding version mismatch: Currently supported: %u; encoded: %u
Failed to unarchive VNFaceLandmarks3D object. Error: %@
bodynet_v1.0.espresso
torso_print__0
inference output results dimensions are incorrect
zero-dimensioned image (%ld x %ld)
array
%@ is nil
The %@ array has %lu items, which is less than the required count of %lu
The %@ array has %lu items, which is more than the maximum allowed of %lu
expectedAncestoralClass
All elements in the %@ array must be a Class object (%@)
All elements in the %@ array must be a VNRequest subclass (%@)
face observations
detected object observations
cluster IDs
The confidence value %f must be in the range [0..1]
The score value %f must be in the range [-1..1]
Async status object is nil
Async status object reported as completed successfully but with an error
Async status object reported as failed but without an error
Invalid async status state
%@ is %d which is not in the range [%d..%d]
%@ is %f which is not in the range [%f..%f]
default value
%@ was given %@
The '%@' option specifies %@, not the required %@
landmarksflow-gwkf986dmy_63053_plus_8dtz95rnyx_quantized.espresso
Internal error while processing Face Landmarks
Unexpected landmarks constellation (%d) while processing Face Landmarks
Unknown identifier "%@"
%@ [%@]
adjustments
CVMLObservation_CodingVersionCodingKey
CVMLObservation_ConfidenceCodingKey
CVMLFaceprint_CodingVersionCodingKey
CVMLFaceprint_FaceprintCodingKey
CVMLFaceprint_KeyCodingKey
CVMLFaceprint_ProfileCodingKey
CVMLFaceprint_PlatformCodingKey
CVMLImageprintObservation_ObjectCodingKey
CVMLImageprintObservation_VersionCodingKey
CVMLImageprintObservation_ImageprintTypeCodingKey
CVMLImageprintObservation_ImageprintDescriptorCodingKey
CVMLImageprintObservation_UUIDCodingKey
CVMLImageprintObservation_ImageprintTypeColorGabor
CVMLImageprintObservation_ImageprintDescriptorColorGaborVersion
MPImageDescriptor_externalImageId
MPImageDescriptor_exifTimestamp
MPImageDescriptor_quality
MPImageDescriptor_ColorGaborImageDescriptorBuffer_type
MPImageDescriptor_ColorGaborImageDescriptorBuffer_lengthInBytes
MPImageDescriptor_ColorGaborImageDescriptorBuffer_data
MPImageDescriptor_ColorGaborImageDescriptorBuffer_count
MPImageDescriptor_ColorGaborImageDescriptorBuffer_stride
Exporting of legacy CVMLFaceprints is disabled.  Please convert to VNFaceprint and export
CVMLObservation
MPImageDescriptor
CVMLImageprintObservation
Exporting of CVMLObservation_LegacySupportDoNotChange is not allowed.  Please use VNObservation instead.
Exporting of legacy CVMLImageprintObservation_LegacySupportDoNotChange is disabled.  Please convert to VNImageprintObservation and export
Exporting of legacy MPImageDescriptor_LegacySupportDoNotChange is disabled.  Please convert to VNImageprintObservation and export
ERROR: state cannot be nil
ERROR: invalid image Id format
Tp_data
Tp_elementsCount
Tp_elementsType
Tp_length
Tp_labelsAndConfidence
Tp_VNTorsoprint
tp_conf
Tp_algorithmVersion
Internal error desrializing torsoprint
Deserialized confidence is outside of the valid range
%@; coinfidence = %f
FaceID3Model_v1_d16
vector length < cols
vector length < rows
matrix size too small for output
broadcast op: dimension mismatch
unknown axis value
dimensions of data points mismatch
output distance matrix too small
matrix size mismatch
row index out of range
col index out of range
empty cumsum vector
output matrix size too small
VNVNCoreMLTransformerProcessOption_NormalizedOriginOffsetX
VNVNCoreMLTransformerProcessOption_NormalizedOriginOffsetY
v16@?0^v8
The model does not have a valid input feature of type image
The requested FeaturePrint.scene is not available. Requested revision: %lu
%@:UUID=%@
No valid VNCoreMLModel found in passed in options
The inputImageFeatureName does not point to a MLFeatureTypeImage input.
q24@?0@"VNClassificationObservation"8@"VNClassificationObservation"16
The outputs of the model are of unexpected types.
The confidence scores don't line up with the labls.
v32@?0@8Q16^B24
could not obtain a feature value for key "%@"
VNImageAnalyzerMultiDetectorSceneNetV3R8
VNImageAnalyzerMultiDetectorSceneNetV5
threshold
precision
recall
operation point map data for "%@" is corrupt
scenenet_op-v8d.plist
SceneNet5_op-v8d.plist
unknown operation points identifier "%@"
could not locate the %@ resource for operation points identifier "%@"
missing threshold for "%@"
missing F2 for "%@"
missing precision table for "%@"
invalid precision table for "%@"
missing recall table for "%@"
invalid recall table for "%@"
unable to open %@
Identifier
plist
no data source available
no %@ is defined at %@
VNFaceLegacyFaceCoreFeature_LeftEyeClosedScore
VNFaceLegacyFaceCoreFeature_RightEyeClosedScore
VNFaceLegacyFaceCoreFeature_SmileScore
VNFaceLegacyFaceCore
fcr_profile
fcr_size
fcr_angle
fcr_center
fcr_bbox
fcr_lefteye
fcr_righteye
fcr_mouth
fcr_trackid
fcr_trackduration
fcr_features
@"VNSmartCam5CompoundRequestGroupingConfiguration"24@?0@"VNRequest"8Q16
VNImageClassifierProcessingOption_ImageProcessingType
VNImageClassifierProcessingOption_AveragedSideLength
VNImageClassifierProcessingOption_ScaleImage
VNImageClassifierProcessingOption_ScaleFactor
VNImageClassifierProcessingOption_DebugIntermediatesDumpPath
VNImageClassifierProcessingOption_DebugInfo
B8@?0
MinConfidenceForClassificationRaw
hierarchicalLabelsAndConfidence
MinConfidenceForHierarchical
_source_scaled.png
_source_scaled.vdump
VN Image Classifier debug intermediates written to: %@
scalingFactor
augmentationMode
numTiles
imageID
_tile_
.png
.vdump
debugID
Attempt to create an imageprint failed
FAFrameRate
parabolaLength
minXDistanceFromLastPointOnParabola
maxXDistanceFromLastPointOnParabola
minYDistanceFromLastPointOnParabola
maxYDistanceFromLastPointOnParabola
maxFramesSkippedToContinueParabolaDetection
input_data__0
prev_mask__0
PersonSeg__predictions__0
personsegmentation-si-01.espresso
FaceRegionMap::Width
FaceRegionMap::Height
FaceRegionMap::Data
FaceRegionMap::Triangles
FaceRegionMap::NormalizedLandmarks
Background
Right eye
Left eyebrow
Right eyebrow
Root of nose
Lower left cheek
Lower right cheek
Between mouth and nose
Left cheek
Right cheek
Left temple
Right temple
Between eyebrows
Above left eye
Above right eye
Upper lip
Lower lip
Between lips
Tip of nose
hashes
VNOpticalFlowGeneratorProcessOption_ROIWidth
VNOpticalFlowGeneratorProcessOption_ROIHeight
Optical flow cannot be performed on images with different dimensions
Unexpected number of buffers for optical flow processing
outputPixelFormat
computationAccuracy
Failed to allocate the vector result buffer
NtCreatePixelBuffer
ntModel.cpp
ret == kCVReturnSuccess
net_exempler_reg
net_exempler_cls
r1_kernel
cls1_kernel
classification_x_corr
regress_adjust
EspressoNetExemplarRun
instance_image
EspressoNetInstanceRun
EspressoNetUnload
status == ESPRESSO_STATUS_SUCCESS
.espresso.net
shape
json
v32@?0@"NSString"8@"NSNumber"16^B24
%@ does not contain the blob "%@"
%@ FAS=%@
VNMRCDetectorProcessOption_MRCDecoderOptions
VNMRCDetectorProcessOption_MRCSample
VNMRCDetectorProcessOption_SegmentationMask
VNMRCDetectorProcessOption_UseMLBasedDetector
unable to generate pyramid data
VNCGAffineTransformAttachment
AffineTransform missing afterCropAndScale
invalid transform data in pixel buffer
image is unavailable
returned buffer from network was not in expected format - outputBoxesEspressoBuffer
returned buffer from network was not in expected format - _outputScoresEspressoBuffer
returned buffer from network was not in expected format - _outputRotationEspressoBuffer
unable to create MRCDecoder
Could not decode sample: %@
mrcdetector.espresso
detections
box_cls
rotation
oreq
VNFaceSegmentsVersion
fsRev
fsWidth
fsHeight
fsData
fsNumOfSgmnts
fsBBoxOrgX
fsBBoxOrgY
fsBBoxSzW
fsBBoxSzH
fsLblToProbMap
Data integrity check failed when un-archiving an object of type: %@
Cannot create CVPixelBuffer object
Cannot create CVPixelBuffer object: faceSegments is out of range
Cannot create CVPixelBuffer object: faceSegment parameter is out of range
Cannot create CVPixelBuffer object: region parameter is out of range
Cannot copy face segment probability map. Error = %d
Cannot create CVPixelBuffer object. Error = %d
facerec_fa1.3_lightweight_fp16.espresso
faceprinting is not supported in camera lightweight mode
VNDetectedObjectObservation object is expected to initialize Object Tracker
Object identifier is not initialized in detected object observation
fopen failed
void cvml::util::mapped_model_file_fopen::open_file(const char *)
/Library/Caches/com.apple.xbs/Sources/Vision_Sim/VisionKitFramework/VN/algorithm_util/mapped_model_file.h
ftell failed
fseek failed
Error %s when executing %s in file %s:%d
syslog_assert_failed
common_defines.h
false
::open failed
void cvml::util::mapped_model_file_open::open_file(const char *, bool)
fstat failed
mmap MAP_FAILED
::madvidse failed
virtual void cvml::util::mapped_model_file_open::advise(int) const
polygonListWithBitString failed
B24@?0@"VNDetector"8^B16
Cannot create framework manager singleton
Processing dispatch queue is unavailable
requests
v24@?0@"VNDetector"8^B16
com.apple.VNSession
Invalid contour passed in
Invalid number of points passed for minimum enclosing circle calculation
Cannot calculate minimum enclosing circle for the given set of points
null points array
Invalid points count %ld
A collection must contain 3 points
Number of points in collection must be greater or equal than %lu
Number of points in collection must be greater than zero
null area pointer
null perimeter pointer
VNMPImageDescriptor_exifTimestamp
VNMPImageDescriptor_quality
VNMPImageDescriptor_ColorGaborImageDescriptorBuffer_type
VNMPImageDescriptor_ColorGaborImageDescriptorBuffer_lengthInBytes
VNMPImageDescriptor_ColorGaborImageDescriptorBuffer_data
VNMPImageDescriptor_ColorGaborImageDescriptorBuffer_count
VNMPImageDescriptor_ColorGaborImageDescriptorBuffer_stride
ERROR: Could not compute the image descriptor
ERROR: Could not compute the convnet-based image descriptor
ERROR: Could not compute image registration features
Integer overflow occured when unarchiving an object of type: %@ stride: %zu count: %zu
unable to allocate descriptor data
MPImageDescriptor cannot be serialized without being created
state parameter cannot be nil
Invalid state format
-[VNMPImageDescriptor computeDescriptorForImageData:context:error:]
MPImageDescriptor.mm
error != nil
%u.%u.%u
Food
Drink
VNRecognizeFoodAndDrinkRequestPrivateRevisionANODv4
VNRecognizeFoodAndDrinkRequestPrivateRevisionANSTModel
VNDetectFaceRectanglesRequestPrivateRevisionANFD2Detector
VNDetectFaceRectanglesRequestPrivateRevisionANOD3Detector
VNDetectFaceRectanglesRequestPrivateRevisionANOD3DetectorNoFBBA
VNDetectFaceRectanglesRequestPrivateRevisionANOD4DetectorNoFBBA
VNDetectFaceRectanglesRequestPrivateRevisionLegacyFaceCore
VNDetectFaceRectanglesRequestPrivateRevisionANSTModel
%@:%@:%p:%ld:%d:%d:%d:%f
[%@]
unsupported pixel format
v32@?0@"NSNumber"8@"VNCIContextsHandler"16^B24
processingDevice
VNDetectFaceCaptureQualityRequestPrivateRevisionV3MD4
vproj
(x; y) = (%f; %f); (r; theta) = (%f; %f)
facequality_regression-n6vfnwub35_11333-quant-fp16.espresso
v3_drop4
%@%s
##INVALID##
VNImageAnalyzerMultiDetectorInitializationOption_Model
VNImageAnalyzerMultiDetectorInitializationOption_RequireObjDetNet
VNImageAnalyzerMultiDetectorInitializationOption_RequireSliderNet
VNImageAnalyzerMultiDetectorProcessingOption_SkipInputImageScaling
VNImageAnalyzerMultiDetectorProcessingOption_ImageCropAndScale
VNImageAnalyzerMultiDetectorProcessingOption_TilingWarningRecorders
VNImageAnalyzerMultiDetectorProcessingOption_CreateSceneprint
VNImageAnalyzerMultiDetectorProcessingOption_SceneprintOriginatingRequestSpecifier
VNImageAnalyzerMultiDetectorProcessingOption_SceneprintIncludeLabelsAndConfidences
VNImageAnalyzerMultiDetectorProcessingOption_SceneprintObservationsArray
VNImageAnalyzerMultiDetectorProcessingOption_CreateCompressedSceneprint
VNImageAnalyzerMultiDetectorProcessingOption_CompressedSceneprintOriginatingRequestSpecifier
VNImageAnalyzerMultiDetectorProcessingOption_CompressedSceneprintObservationsArray
VNImageAnalyzerMultiDetectorProcessingOption_ClassifyScene
VNImageAnalyzerMultiDetectorProcessingOption_SceneOriginatingRequestSpecifier
VNImageAnalyzerMultiDetectorProcessingOption_SceneBlacklist
VNImageAnalyzerMultiDetectorProcessingOption_SceneMaximumLeafLabels
VNImageAnalyzerMultiDetectorProcessingOption_SceneMaximumHierarchicalLabels
VNImageAnalyzerMultiDetectorProcessingOption_SceneMinimumConfidence
VNImageAnalyzerMultiDetectorProcessingOption_SceneObservationsArray
VNImageAnalyzerMultiDetectorProcessingOption_SceneClassificationCustomHierarchy
VNImageAnalyzerMultiDetectorProcessingOption_ClassifyJunk
VNImageAnalyzerMultiDetectorProcessingOption_JunkOriginatingRequestSpecifier
VNImageAnalyzerMultiDetectorProcessingOption_JunkObservationsArray
VNImageAnalyzerMultiDetectorProcessingOption_ClassifyVNVYvzEtX1JlUdu8xx5qhDI
VNImageAnalyzerMultiDetectorProcessingOption_VNVYvzEtX1JlUdu8xx5qhDIOriginatingRequestSpecifier
VNImageAnalyzerMultiDetectorProcessingOption_VNVYvzEtX1JlUdu8xx5qhDIObservationsArray
VNImageAnalyzerMultiDetectorProcessingOption_ClassifyAesthetics
VNImageAnalyzerMultiDetectorProcessingOption_AestheticsOriginatingRequestSpecifier
VNImageAnalyzerMultiDetectorProcessingOption_AestheticsObservationsArray
VNImageAnalyzerMultiDetectorProcessingOption_GenerateSaliencyAHeatMap
VNImageAnalyzerMultiDetectorProcessingOption_SaliencyAOriginatingRequestSpecifier
VNImageAnalyzerMultiDetectorProcessingOption_SaliencyAObservationsArray
VNImageAnalyzerMultiDetectorProcessingOption_GenerateSaliencyOHeatMap
VNImageAnalyzerMultiDetectorProcessingOption_SaliencyOOriginatingRequestSpecifier
VNImageAnalyzerMultiDetectorProcessingOption_SaliencyOObservationsArray
VNImageAnalyzerMultiDetectorProcessingOption_ClassifyVN5kJNH3eYuyaLxNpZr5Z7zi
VNImageAnalyzerMultiDetectorProcessingOption_VN5kJNH3eYuyaLxNpZr5Z7ziRequestSpecifier
VNImageAnalyzerMultiDetectorProcessingOption_VN5kJNH3eYuyaLxNpZr5Z7ziObservationsArray
VNImageAnalyzerMultiDetectorProcessingOption_ClassifyVNdGg5skzXHSAENO6T3enHE
VNImageAnalyzerMultiDetectorProcessingOption_SignificantEventOriginatingRequestSpecifier
VNImageAnalyzerMultiDetectorProcessingOption_VNdGg5skzXHSAENO6T3enHEObservationsArray
VNImageAnalyzerMultiDetectorProcessingOption_ClassifyCityNature
VNImageAnalyzerMultiDetectorProcessingOption_CityNatureOriginatingRequestSpecifier
VNImageAnalyzerMultiDetectorProcessingOption_CityNatureObservationsArray
VNImageAnalyzerMultiDetectorProcessingOption_RecognizeObjects
VNImageAnalyzerMultiDetectorProcessingOption_RecognizeObjectsOriginatingRequestSpecifier
VNImageAnalyzerMultiDetectorProcessingOption_RecognizeObjectsObservationsArray
VNImageAnalyzerMultiDetectorProcessingOption_RecognizeObjectsBlacklist
VNImageAnalyzerMultiDetectorProcessingOption_RecognizeObjectsModelMinimumDetectionConfidence
VNImageAnalyzerMultiDetectorProcessingOption_RecognizeObjectsModelNonMaximumSuppressionThreshold
VNImageAnalyzerMultiDetectorProcessingOption_ClassifyPotentialLandmark
VNImageAnalyzerMultiDetectorProcessingOption_PotentialLandmarkOriginatingRequestSpecifier
VNImageAnalyzerMultiDetectorProcessingOption_PotentialLandmarkObservationsArray
VNImageAnalyzerMultiDetectorProcessingOption_VN1JC7R3k4455fKQz0dY1VhQ
VNImageAnalyzerMultiDetectorProcessingOption_VN1JC7R3k4455fKQz0dY1VhQOriginatingRequestSpecifier
VNImageAnalyzerMultiDetectorProcessingOption_VN1JC7R3k4455fKQz0dY1VhQObservationsArray
VNImageAnalyzerMultiDetectorProcessingOption_CreateImageFingerprints
VNImageAnalyzerMultiDetectorProcessingOption_ImageFingerprintsOriginatingRequestSpecifier
VNImageAnalyzerMultiDetectorProcessingOption_ImageFingerprintsObservationsArray
VNImageAnalyzerMultiDetectorProcessingOption_TilingIsRequired
SceneNet_v5.10.0_vhh2692239_fe1.3_sc3.3_sa2.4_ae2.4_so2.4_od1.5_fp1.5.espresso
sn3_all_heads_combined_299_no_softmax.espresso
sn3_4heads_combined_299_no_softmax.espresso
unsupported model %@
custom hierarchy created for revision %lu cannot be used with a detector for revision %lu
junk_leaf.r14.j9.espresso
junk_leaf.labels_basic-v3b.txt
stem/SpatialSqueeze_COPY254
leaf/probabilities
junk_hierarchical.r14.j9.espresso
junk_hierarchical.labels_higher_order-v3b.txt
hierarchical/probabilities
JunkLeaf_v0.11.0_y8pf7cunms-10000.espresso
JunkLeaf_v0.11.0_y8pf7cunms-10000-v3b.txt
2593
fc_leaf_post_act_1
JunkHierarchical_v0.11.0_y8pf7cunms-10000.espresso
JunkHierarchical_v0.11.0_y8pf7cunms-10000.txt
fc_hier_post_act_1
junk classification not supported for %@
vienna.r14.n4.1.espresso
labels_vienna-v1e.txt
landmarks_gating.r14.l3.espresso
landmarks_gating_labels.txt
labels/probabilities
semdev_23y8pwvx7w_18000.espresso
sg_labels.txt
2590
sg.r14.s4.espresso
stem/SpatialSqueeze_NEW254
EventsLeaf_v0.5.0_89sf2c9ryr-157700.espresso
events_gating_labels_basic-v1c.txt
events_fc_post_act_1
events_gating.r14.e4.espresso
d76p746ctq_50001_split.espresso
d76p746ctq_50001.txt
stem/gap/Mean
UrbanNatureLeaf_v0.1.0_ccinynq7s3-5000.espresso
UrbanNatureLeaf_v0.1.0_ccinynq7s3-5000.txt
slidernet/
scenenet_sc2.4_sa1.4_ae1.4_r9_opt_int8_pca256.pcadata
pca256
could not create a sceneprint from tensor vector with %lu elements (%lu bytes)
subject_framing
background
blur
subject_sharpness
timing
lightning
reflections
color_harmony
color_brightness
symmetry
repetition
immersive_feeling
perspective
post_processing
noise
failure
composition
interestingness
object_intrusion
tilt
low_light
failed to create saliency heat map image
fruit
vegetable
fish
seafood
SceneNet5_aesthetic_labels_basic-v8e
scenenet_aesthetic_labels_basic-v8e
inner/sceneprint
SceneNet5_labels_basic-v8d.csv
classification/labels
scenenet_labels_basic-v8d.csv
objectness/map
SceneNet5_detection_labels-v8d.txt
GXdCvXzGnLp59suJyVSan_labels.txt
fingerprint_144x192x2_seed1.sbin
fingerprint/embedding
boomerang
bubble_soap
cider
doll_house
electronic_toy
equipment
logo
logo_other
pinata
raw_cardboard
raw_other
raw_plastic
shoe_other
skysurfing
slipper
sport_other
swing_dancing
tablet
toy_organizer
ammunition
blackjack
blade
body_part
brassiere
firearm
holiday
magic
menorah
minaret
missile
oktoberfest
pistol
primate
projectile
ramadan_lantern
raw_metal
religion
revolver
rifle
sauna
shotgun
tank_army
temple_exterior
thanksgiving
underwear
underwear_male
weapon
SceneNet5_relationships-v8d.txt
scenenet_relationships-v8d.txt
a hierarchical model for detector model %lu is not supported
vegetables
cannot provide identifiers for %@
HighKeyCI
ContrastCI
WhiteBalanceTempTintCI
ColorCastCI
ExposureAndBlackPointCI
HighlightsCI
VibrancyCI
slidernet/HighKeyCI
slidernet/ContrastCI
slidernet/WhiteBalanceTempTintCI
slidernet/ColorCastCI
slidernet/ExposureAndBlackPointCI
slidernet/HighlightsCI
slidernet/VibrancyCI
VNImageAnalyzerMultiDetectorModelUndefined
VNImageAnalyzerMultiDetectorModelSceneNetV3
VNImageAnalyzerMultiDetectorModelSceneNetV5
VNImageAnalyzerMultiDetectorModelSceneNetV5StillCapturePipeline
VNImageAnalyzerMultiDetectorModel%lu
detection/scores
detection/coordinates
aircraft
automobile
bicycle
bird
bottle
canine
consumer_electronics
feline
furniture
headgear
kite
computer_monitor
motorcycle
musical_instrument
document
people
food
sign
watersport
train
ungulate
watercraft
flower
appliance
sports_equipment
tool
detection/concat
detection/concat_scale_
contrastPivot property must be in the range [%f..%f]
contrastPivot
maximumImageDimension property must be in the range [%lu..%lu]
maximumImageDimension
VNRecognizeDocumentElementIdentifierDocument
VNRecognizeDocumentElementIdentifierText
VNRecognizeDocumentElementIdentifierQRCode
VNRecognizeDocumentElementIdentifierAppCode
initializeCannyEdgeContext
cannyEdge.c
context->blockAddress
thresholdAndConnectCandidateEdges
context->edgeStackSize <= context->width*context->height
VNTorsoprintGeneratorProcessOption_InputDetectedObjectObservation
Could not create torso print generator
unable to lock base address of pixel buffer
Unexpected size of torsoprint descriptor
torso__0
smartcam_onlyfc
HighlightsCI_V2
VibrancyCI_V2
sliderflow-s6xrskinrc_29001.espresso
AEEnhancerNet/
/final_output:0
hash_size
feat_size
projection_matrix
num_hashes
CCTextDetector_EnableDebug
CCTextDetector_DebugPathname
creditCardSubsampleImage.png
votingImage.png
inverseVotingImage.png
/var/mobile/Media/DCIM/ccOutDebug/
textOutFirstPassImage.png
textOutSecondPassImage.png
color profile context must not be NULL
adaptiveOutImage.png
selectedTextOutImageArray.png
uOutImage.png
textBoxRevised
textBoxRevisedNormalized
stubBox
stubBoxNormalized
{{%i,%i},{%i,%i}}
{{%2.4f,%2.4f},{%2.4f,%2.4f}}
textBox
textBoxMM
charBox
charBoxMM
charConfidence
{{1,1},{1,1}}
connectedComponents.png
stubBoxMM
CCTextDetector internal error
q24@?0@"VNTextObservation"8@"VNTextObservation"16
map::at:  key not found
face_quality_v1.0_fp16.espresso
VNEspressoModelFileBasedDetectorOption_InputBlobNames
VNEspressoModelFileBasedDetectorOption_OutputBlobNames
VNEspressoModelFileBasedDetectorOption_NetworkConfiguration
%@ did not provide a valid model file name
%@ did not provide a valid model input image dimensions blob name
Unexpected network input image size
%@:%@:%@
could not obtain the dimensions of "%@"
failed to bind buffer to network
failed to bind pixel buffer to network
inference plan failed to execute
en_US
%@:%@:%p:%ld:%d:%d:%f
crOutput
 "%@" - (%f) revision: %ld
childIndex
The contour is too small for polygon approximation
The value for epsilon is invalid. It needs to be bigger than zero but it is %f
1.3_lightweight
3.1.3
softmax_
_output
_embedding
v4.1
UNKNOWN_0
UNKNOWN_1
UNKNOWN_2
UNKNOWN_3
UNKNOWN_4
UNKNOWN_6
UNKNOWN_7
UNKNOWN_5
UNKNOWN_8
UNKNOWN_9
UNKNOWN_10
UNKNOWN_11
UNKNOWN_12
UNKNOWN_13
UNKNOWN_14
UNKNOWN_15
UNKNOWN_16
UNKNOWN_17
flatten_output
confidence
[%g, %g, %g, %g]
(%g, %g)
box = %@; default box = %@; confidence = %f; rotationAngle = %f; yawAngle = %f label = %d; boxCenter = %@
face model data is unavailable
face observations are not available
VNCreateSceneprintPrivateRevision64DimensionPCA
VNCreateSceneprintPrivateRevision128DimensionPCA
VNCreateSceneprintRequestPrivateRevisionSceneNetV4
VNCreateSceneprintRequestPrivateRevisionSceneNetV4StillCapturePipeline
VNCreateSceneprintPrivateRevision256DimensionPCAStillCapturePipeline
VNCreateSceneprintRequestPrivateRevisionStillCapturePipeline
VNCreateSceneprintPrivateRevision256DimensionPCA
VNCreateSceneprintRequestPrivateRevisionSceneNetV5
VNCreateSceneprintRequestPrivateRevisionSceneNetV5StillCapturePipeline
 useCenterTileOnly
 returnAllResults
.espresso
.espresso.hwx
B32@?0@"NSString"8Q16^B24
merged/probabilities
SCL_v0.3.1_9c7zcipfrc_558001-labels-v3.txt
SCL_v0.3.1_9c7zcipfrc_558001.espresso
Chirality
%@ has an invalid value of %@
VNFaceLandmarkDetectorDNNProcessOption_Constellation
Unsupported constellation type.
Could not compute Landmarks using Landmark Detector due to internal error
Unexpected number of Landmark points (%lu) while processing Face Landmarks request. Expected: %lu
Unexpected number of error estimates for Landmark points (%lu) while processing Face Landmarks request. Expected: %lu
Unexpected number of occlusion entries for Landmark points (%lu) while processing Face Landmarks request. Expected: %lu
Could not run Landmark Detector. Error = %s
VNRequestPerformer_SameOrdinalityRequestsPriorityGroup1Key
VNRequestPerformer_SameOrdinalityRequestsPriorityGroup2Key
v56@?0@"NSArray"8@"NSMutableDictionary"16@"NSMutableDictionary"24@"NSMutableArray"32@"NSMutableArray"40q48
Q16@?0@"NSArray"8
Internal error while sorting requests
v32@?0@"NSString"8@"NSMutableArray"16^B24
q24@?0@"NSNumber"8@"NSNumber"16
v44@?0@"NSArray"8@"VNRequestPerformingContext"16@"VNControlledCapacityTasksQueue"24@"NSObject<OS_dispatch_group>"32B40
Unexpected internal error
q24@?0@"VNRequest"8@"VNRequest"16
VNHomographicImageRegistrationDetectorProcessOption_ReferenceImageBuffer
VNHomographicImageRegistrationDetectorProcessOption_ReferenceImageRegistrationSignature
VNHomographicImageRegistrationDetectorProcessOption_FloatingImageBuffer
VNHomographicImageRegistrationDetectorProcessOption_FloatingImageRegistrationSignature
VNHomographicImageRegistrationDetectorProcessOption_ReferenceImagePixelBufferRef
failed to create a %lu x %lu pixel buffer of type '%c%c%c%c'
failed to warp image
registration of region of interest %@ (%@) cannot be performed on reference image of size %@
failed to create image registration context
VNANFDMultiDetectorProcessingOption_HumanFaceDetectorOriginatingRequestSpecifier
VNANFDMultiDetectorProcessingOption_HumanHeadDetectorOriginatingRequestSpecifier
VNANFDMultiDetectorProcessingOption_HumanDetectorOriginatingRequestSpecifier
VNANFDMultiDetectorProcessingOption_AnimalRecognitionOriginatingRequestSpecifier
VNANFDMultiDetectorProcessingOption_HumanDetectorUpperBody
VNANFDMultiDetectorProcessingOption_HumanDetectorFullBody
VNANFDMultiDetectorProcessingOption_PrecisionRecallThreshold
q24@?0@"VNDetectedObjectObservation"8@"VNDetectedObjectObservation"16
Failure to create multi-headed object detector.
B48@?0{CGRect={CGPoint=dd}{CGSize=dd}}8^@40
v16@?0@"NSMutableArray"8
The request info is not found for request class %@
Not supported object type: %d
Unexpected number of aligned faces: %lu, should be 1
Unexpected label key for detected object: %d
addDescriptors
GreedyClustering.cpp
elementSize == ELEMENT_SIZE
getMergeableClusters
ci == clusterID
computeInitialMergingList
L0 > mergingTo
.cmap
Unable to determine classification hierarchy for a given request revision: %lu
%@ must provide an implementation for %@
v32@?0@"NSString"8@"NSArray"16^B24
additional relationships must have at least one child identifier
%@: %@, %@
SCRDL
could not decode additional relationships
The classification identifier '%@' does not exist in the hierarchy
VNFaceGazeDirectionUnknown
VNFaceGazeDirectionDifficultToSay
VNFaceGazeDirectionSomewhereElse
VNFaceGazeDirectionCamera
VNFaceGazeDirectionCommonLocation
VNFaceGazeDirectionAnotherFace
VNFaceGazeDirection%@
%@ %@ face %@ %@
, looking at %@
direction
locX
locY
lookFace
gazeMask
Invalid async state - %@
completed: %d: error: %@
facecrop
righteyecrop
facelocmat
lefteyecrop
Input faces not provided to face rectangle aligner
VNImageHashSignatureObservation
sgnPrnt
sgnHash
Tap coordinates are out of bounds.
Failed to fill image.
output1
Failed to compute image histogram.
Size mismatch during image copy.
VNClusteringAlgorithm_Greedy
VNClusteringAlgorithm_GreedyWithTorso
options parameter cannot be nil
unsupported cluster algorithm type
splitIntoMonotonicSpans
SegmentUtilities.c
cPtr->nPnts > 1
!closedP
idx <= monoLength
mergeSegment
sPtr2 != NULL
self isKindOfClass: %@
B24@?0@"VNBarcodeObservation"8@"NSDictionary"16
B24@?0@"CROutputRegion"8@"NSDictionary"16
topLevelRegion
crOutputRegion
v32@?0@"CROutputRegion"8Q16^B24
 transcript="%@"
 shortDescription="%@", type=%ld
%@ %@ model=%@
%@:imageCropAndScaleOption=%lu:Model=%@
Failed to initialize VNCoreMLTransformer
sceneprint could not be generated
no sceneprints defined in observation
The VNCoreMLTransform request failed
Failed to create motion flow estimator
Failed to properly create motion flow estimator
Optical flow incorrect number of images to compare
B24@?0@"VNCIContext"8^@16
B32@?0^{__CVBuffer=}8^{__CVBuffer=}16^@24
Invalid pixel format combinations
VCPRequestFrameWidthPropertyKey
VCPRequestFrameHeightPropertyKey
VCPRequestMotionFlowComputationAccuracyPropertyKey
VCPRequestForceCPUPropertyKey
VCPMotionFlowRequest
Unable to find class %s
@"VNEspressoResources"24@?0@"NSString"8^@16
Option value for option key %@ is a mandatory parameter
Tracker resources
Failed to allocate espresso resources
Cannot calculate encoding for hash type: %lu
Cannot encode null-print object 
v32@?0@"VNRectangleObservation"8Q16^B24
Accurate observations count mismatch
VNRemoveBackgroundProcessorOption_PerformInPlace
VNRemoveBackgroundProcessorOption_CropResult
VNRemoveBackgroundProcessorOption_ReturnMask
VNRemoveBackgroundProcessorOption_MaskObservation
VNRemoveBackgroundProcessorOption_LowResInput
subject_lifting_gen1_rev5_gv8dsz6vxu_int8.espresso
input_image
saliency
gating_confidence
removebkgnd_assembleConstraints
removebkgnd_maskimage
removebkgnd_copyCrop
failed to create semaphore
performInPlace
Conditions for in-place execution not met
@"<MTLTexture>"32@?0{BufferSize=QQ}8Q24
v16@?0@"<MTLComputeCommandEncoder>"8
v16@?0@"<MTLCommandBuffer>"8
No pixels meet or exceed alpha threshold
convertYUV420ToRGBA8888: invalid dst size of %lu x %lu
convertYUV420ToRGBA8888: failed to allocate %lu bytes
public.png
convertYUV420ToRGBA8888: src must be YUV420 format!
com.apple.vis.VNEntityIdentificationModel
unknown entity (%@)
unknown model kind %@
readObjectForVersion%uTag:fromInputStream:intoObjectDictionary:md5Context:error:
cannot read model version %u
model data fails checksum validation
model data object %@ is a %@, not the expected %@
v24@?0Q8^B16
%@ does not support writing version %@
no entity print originating request specifier is defined
maximumTrainingPrintsPerEntity
an entity print originating request specifier must be configured
%@ cannot be created from a %@
%@ is generated by %@ instead of %@
q24@?0@"VNRequestSpecifier"8@"VNRequestSpecifier"16
B32@?0@"<VNEntityIdentificationModelPrint>"8Q16^B24
B32@?0@"VNObservation<VNEntityIdentificationModelObservation>"8Q16^B24
VNEntityIdentificationModelTrainedModel
unable to decode entity unique identifier for tag %@
unable to decode observations for tag %@
v40@?0@"NSArray"8{_NSRange=QQ}16^B32
VNHumanObservation
trsPrnt
upBdyOnly
logits_pos_%ld
logits_neg_%ld
logits_%ld
offsets_%ld
f8@?0
logits_roll_%ld
logits_yaw_%ld
shotflow-8k6zuzd9wy_46860_opt_quantized.espresso
rcnn_output
rcnn_output_scores
rcnn_output_cls
rcnn_output_selected_indices
roll_output
yaw_output
anodv4_drop6_fp16.espresso
face_pose_topk
anst_v1.5.espresso
VNGeneratePersonSemanticsCompoundRequest unimplemented revision/options for %@
v32@?0@"NSNumber"8@"NSMutableArray"16^B24
The request class %@ shall have it's results populated in the results array
smartcam
scorPdiffParameters
exprParameters
blinkParametersApp
smileBlinkParametersGeo
lmarkQuality
exprParamsv1
pupilMeanStd
pupil
Internal error: input specifications are invalid for executing this request
Could not analyze face. Error = %s
Could not get output. Error = %s
Not implemented in abstract class
Input image has invalid pixel format
Input image has invalid width/height
Output image has invalid pixel format
Output image has invalid width/height
Cannot create a face-torso print object
solo_landmarks_s9min6ugm8_opt.espresso
%d_%d
unable to create new pixel buffer
Revision %lu of %@ is deprected and not supported anymore
B24@?0Q8^@16
VNCreateFaceprintRequestPrivateRevision3_1MD2
VNCreateFaceprintRequestPrivateRevision3_1MD3_HomeApp
VNCreateFaceprintRequestPrivateRevision3_1MD3
VNImageSignatureDetectorProcessOption_ImageSignatureprintInput
VNImageSignatureDetectorInitOption_ImageSignatureprintType
VNImageSignatureDetectorInitOption_ImageSignatureHashType
Unknown signature hash type: %lu
B24@?0@"NSString"8^@16
neuralhash_128x96_seed1
Unknown signature print type: %lu
Unknown error creating VNObservation object
Unknown signature print type
Mismatch in signature hash type
anodv3_pet_v1_md2
output
input
VNFaceBBoxAlignerProcessOption_FaceRawBoxInImageCoordinates_X
VNFaceBBoxAlignerProcessOption_FaceRawBoxInImageCoordinates_Y
VNFaceBBoxAlignerProcessOption_FaceRawBoxInImageCoordinates_Width
VNFaceBBoxAlignerProcessOption_FaceRawBoxInImageCoordinates_Height
VNFaceBBoxAlignerProcessOption_FaceRawBoxInImageCoordinatesMagnified_X
VNFaceBBoxAlignerProcessOption_FaceRawBoxInImageCoordinatesMagnified_Y
VNFaceBBoxAlignerProcessOption_FaceRawBoxInImageCoordinatesMagnified_Width
VNFaceBBoxAlignerProcessOption_FaceRawBoxInImageCoordinatesMagnified_Height
faceBoxPoseAligner-current
Could not map face box aligner model
Failed to allocate memory for face bounding box aligner model data
VNTrackingOption_ProcessingQueue
VNTrackingOption_TrackerKey
VNTrackingOption_TrackerType
VNTrackingOption_TrackingLevel
VNTrackingOption_InputBBox
VNTrackingOption_CVPixelBufferFormat
VNTrackingOption_InputImageMaxWidth
VNTrackingOption_InputImageMaxHeight
VNTrackingOption_TrackingLevelFast
VNTrackingOption_TrackingLevelAccurate
VNTrackingOption_TrackingLevelRPN
Tracker is busy with previous tracking requests. It needs to be reset to restart tracking sequence
Setting objects to track failed
No frame to track objects was passed to the tracker
Tracking objects failed with error: %llu
no tracker results
failed to initialize object IDs to rectangles dictionary
Conversion to Tracker coordinate system failed
face_quality_v2.0_fp16.espresso
VNSmartCamCombinedAestheticsAndSaliencyDetectorOptionClassifyAesthetics
VNSmartCamCombinedAestheticsAndSaliencyDetectorOptionGenerateSaliencyHeatMap
aesthetics/scores
aesthetics/attributes
Could not bind output aesthetics attributes
saliency/map
Could not bind input image buffer
combined_classification_smartCamfanet_0-0011_saliency_bhutc68tnd_aesthetics_3eqm2xn28k.espresso
No aesthetic score data returned
Unexpected aesthetic score input types provided
No attribute data returned
Unexpected attribute scores input types provided
Error allocating VNImageAestheticsObservation
Failed to create observation
+N9mZUAHooNvMiQnjeTJ8g
v32@?0@"NSString"8@16^B24
v32@?0@"VNRequest"8Q16^B24
   +-- %@
Unexpected number of unique observation classes
%@ does not override %@
Cannot generate optical flow
trained model data is not available
trained model entity print originating request is not defined
observations are not available in a read-only model
VNFaceGazeDetectorProcessOption_GazeHeatMapThreshold
VNFaceGazeDetectorProcessOption_CommonGazeLocationRadius
VNFaceGazeDetectorProcessOption_MinimumFaceDimension
unexpected gaze label of %d
Error allocating %lu x %lu CVPixelBuffer with format %@
B24@?0^{__CVBuffer=}8^@16
camgaze_classification_3class_light-nxbrsq87z6_23998_BGR_opt.espresso
gazefollow_3dmaps_cat4-jsk53qcqtz_157500_BGR_quant_fp16.espresso
image
vector
no request performer available
no image is available
v20@?0@"<NSObject><NSCopying>"8B16
detector type has not been configured for %@
Internal error processing request of class %@
VNGenerateObjectnessBasedSaliencyImageRequestPrivateRevision544x544Input128x128Output
VNGenerateObjectnessBasedSaliencyImageRequestPrivateRevisionSceneNetV4
VNGenerateObjectnessBasedSaliencyImageRequestPrivateRevisionSceneNetV5
The model has reached the maximum identity limit of %lu
identity serial numbers have been exhausted
available person serial numbers is corrupt
VNBlurDetectorProcessOption_MaximumIntermediateSideLength
VNBlurDetectorProcessOption_ImageBlurDeterminationMethod
blurDeterminationMethod
VNImageprintGeneratorProcessOption_Timestamp
no valid initial image buffer was provided
VNDetectorInternalProcessOption_TorsoBBox_X
VNDetectorInternalProcessOption_TorsoBBox_Y
VNDetectorInternalProcessOption_TorsoBBox_Width
VNDetectorInternalProcessOption_TorsoBBox_Height
Memory for torso bouding box is not allocated
faceOrientationRelativeToUpright
Error in calculating torso bounding box dimensions
Unexpected espresso result
could not create tensor
classification/mixed_2/concat_channels
Could not bind classification/mixed_2/concat_channels
classification/mixed_6/concat_channels
Could not bind classification/mixed_6/concat_channels
data
detector_print_mixed26.espresso
ConnectedComponents
ConnectedComponents.c
pneighbor(*(Pcoord *)dequeFirst(dbLookup[mnid]), pix)
pneighbor(*(Pcoord *)dequeFirst(dbLookup[nid]), pix)
pneighbor(*(Pcoord *)dequeFirst(dbLookup[mid]), pix)
pneighbor(*(Pcoord *)dequeFirst(dbLookup[pid]), pix)
loc != -1
cidcnt < MAX_CONTOURS
eraseContourPixels
deque != NULL
v16@?0Q8
allocSegments
Segments.c
sdb->nSegments <= sdb->maxSegments
center = %@; radius = %f (diameter = %f)
ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/
VNTensorDataTypeUnknown
VNTensorDataTypeFloat64
VNTensorDataTypeFloat32
VNTensorDataTypeFloat16
VNTensorDataTypeInt32
VNTensorDataTypeInt8
VNTensorDataTypeUInt32
VNTensorDataTypeUInt8
VNTensorDataTypePlanar8Image
VNTensorDataTypePlanarFloat32Image
VNTensorDataType_(%lX)
sizes
Illegal sizes data length of %@
Corrupted sizes data count expected %@, actual %@
VNImageOptionImageOrientation
VNImageOptionProperties
VNImageOptionCameraPixelFocalLength
VNImageOptionCameraIntrinsics
VNImageOptionCIContext
%c[%@ %@]
VNElementTypeUnknown
VNElementTypeFloat
VNElementTypeDouble
VNElementType(%lu)
VNImageCropAndScaleOptionCenterCrop
VNImageCropAndScaleOptionScaleFit
VNImageCropAndScaleOptionScaleFill
VNImageCropAndScaleOptionScaleFitRotate90CCW
VNImageCropAndScaleOption(%lu)
%g x %g
[%@ %@]
Face crop orientation is a mandatory parameter
image orientation
feature orientation
options
q24@?0@"VNObservation"8@"VNObservation"16
q24@?0@"VNRecognizedObjectObservation"8@"VNRecognizedObjectObservation"16
%@Revision%lu
Model file %@.bin is missing
Loading Resource Error
Model file %@.dat is missing
B16@?0^@8
NSColor
colorWithCGColor:
One of the output parameters is null
UIImage
imageWithCGImage:
UIBezierPath
bezierPathWithCGPath:
UIGraphicsBeginImageContext
UIGraphicsGetCurrentContext
UIGraphicsGetImageFromCurrentImageContext
UIGraphicsEndImageContext
Could not render path on image %@
/System/Library/Frameworks/UIKit.framework/UIKit
softlink:r:path:/System/Library/PrivateFrameworks/BarcodeSupport.framework/BarcodeSupport
softlink:r:path:/System/Library/PrivateFrameworks/VideoProcessing.framework/VideoProcessing
softlink:r:path:/System/Library/PrivateFrameworks/VideoProcessing.framework/VideoProcessing
softlink:r:path:/System/Library/PrivateFrameworks/VideoProcessing.framework/VideoProcessing
softlink:r:path:/System/Library/PrivateFrameworks/VideoProcessing.framework/VideoProcessing
softlink:r:path:/System/Library/PrivateFrameworks/VideoProcessing.framework/VideoProcessing
softlink:r:path:/System/Library/PrivateFrameworks/VideoProcessing.framework/VideoProcessing
softlink:r:path:/System/Library/PrivateFrameworks/MediaAnalysis.framework/MediaAnalysis
dPO/
VNRecognizedBodyPointsSpecifier
VNSaliencyHeatmapBoundingBoxGenerator
VNSaliencyAHeatmapBoundingBoxGenerator
VNSaliencyOHeatmapBoundingBoxGenerator
VNCreateNeuralHashprintRequestConfiguration
VNCreateNeuralHashprintRequest
Revisioning
VNDetectHumanHeadRectanglesRequest
VNFaceQualityGenerator
VNDetectScreenGazeRequestConfiguration
VNDetectScreenGazeRequest
VNFaceObservationAccepting
NSObject
CVML_Error
VNANFDMultiDetectorANODv4
VNClusteringLogger
VNSuggestionsLogger
VNGreedyClusteringReadOnly
VNClusteringReadOnly
VNClusteringCancelling
VNGreedyClusteringReadWrite
VNClusteringWritable
VNPersonSegmentationGeneratorInstanceBased4People
VNFaceAnalyzerMultiDetectorBase
VNClustererContextBase
VNClustererReadOnlyContext
VNClustererModelQuerying
VNClustererReadWriteContext
VNClustererModelBuilding
VNClassRegistrar
BehaviorIntrospection
VNHomographyTrackerState
ICFlowControl
ICResultDelegate
VNHomographyTracker
VNAnimalprintDetectorRevision1
VN5xRo0q9Wz9Io02mmbtoLsConfiguration
VN6kBnCOr2mZlSV6yV1dLwB
VNImageAnalyzerBasedDetector
_VNRequestForensicsRequestAndErrorTuple
_VNRequestForensicsRequestAndObservationsCacheKeyTuple
_VNRequestForensicsParentChildRequests
VNRequestForensics
VNObjectAtPointDetectorRevision1
VNError
VNFaceDetectorRevision2
VNClassifyJunkImageRequestConfiguration
VNClassifyJunkImageRequest
VNHumanBodyPoseObservation
VNCRImageReaderDetector
VNObjectTrackerLegacyFaceCore
VN1JC7R3k4455fKQz0dY1VhQ
VNHomographicImageRegistrationRequest
VNSceneClassificationRequestConfiguration
VNSceneClassificationRequest
VNClassifyMemeImageRequest
VNRequestSpecifier
NSCopying
NSSecureCoding
NSCoding
VNRequestSpecifying
VNRequestRevisionProviding
VNRequestClassProviding
Compatibility
VNBlurSignature
VNBlurMeasure
VNTrackingRequest
VNDetectTrajectoriesRequestConfiguration
VNDetectTrajectoriesRequest
VNMultiDetectorOriginalRequestInfo
VNDetector
VNClassCodeProviding
VNDetectorKeyProviding
Vision
VNClassifyPotentialLandmarkRequestConfiguration
VNClassifyPotentialLandmarkRequest
VNImageAnalyzerCompoundRequestGroupingConfiguration
VNImageAnalyzerCompoundRequestGroupingConfigurations
VNImageAnalyzerCompoundRequestConfiguration
VNImageAnalyzerCompoundRequest
VNFaceRegionMap
VNAnimalObservation
VNPersonSegmentationGeneratorSemantics
VNANEProcessingDevice
VNRuntimeUtilities
VNEntityIdentificationModelTrainingData
VNEntityIdentificationModelDataSource
VNEntityIdentificationModelTrainedModelDataProvider
VNFaceprintInferenceNetworkDescriptor
VN4nFZhnOcBOiJmeVWzBWsv
VNCanceller
VNFaceLandmarkDetector
VNFaceAnalyzerCompoundRequestConfiguration
VNFaceAnalyzerCompoundRequestConfigurationGroups
VNFaceAnalyzerFaceObservationGrouping
VNFaceObservationAcceptingInternal
VNFaceAnalyzerCompoundRequest
VNImageBufferManager
VNImageSourceManager
VNImageBufferCache
VNImageBuffer
VNSequencedRequestSupporting
VNCreateTorsoprintRequestConfiguration
VNCreateTorsoprintRequest
VNDetectedObjectObservationAccepting
VNCRImageReaderForDocumentsDetector
_VNWeakSessionsCollection
VNFrameworkManager
VNLegacyForcedCleanupImplementing
VNMTLDeviceWisdomParametersProviding
VNObjectTrackerRevision2
VNMutablePersonsModel
VNPersonsModelDataDelegate
VNPoint
VNRequestProgressProviding
VNRequest
VNWarningRecorder
VNAsyncStatusProviding
VNSizeRange
VNSupportedImageSize
VNRequestConfiguration
VN5kJNH3eYuyaLxNpZr5Z7ziConfiguration
VN5kJNH3eYuyaLxNpZr5Z7zi
VNControlledCapacityTasksQueue
VNControlledCapacityAsyncTasksQueue
VNControlledCapacitySyncTasksQueue
VNTasksQueueCache
VNAsyncTasksQueueCache
VNSyncTasksQueueCache
VNRequestPerformingPriorityGroup1AsyncTasksQueueCache
VNRequestPerformingPriorityGroup2AsyncTasksQueueCache
VNRequestAsyncTasksQueueCache
VNDetectorAsyncTasksQueueCache
VNDetectorSyncTasksQueueCache
VNFaceTorsoprint
VNAnimalprintDetectorBase
VNScreenGazeFaceObjectState
VNScreenGazeState
VNMomentProcessor
VNMPClusteringTreeNodeWrapper
NSFastEnumeration
VNEntityIdentificationModelPrint
VNEntityIdentificationModelObservation
VNGenerateAttentionBasedSaliencyImageRequestConfiguration
VNGenerateAttentionBasedSaliencyImageRequest
VNEspressoDetectedObject
VNMutableEntityIdentificationModel
VNEntityIdentificationModelTrainingDataDelegate
VNVYvzEtX1JlUdu8xx5qhDIConfiguration
VNVYvzEtX1JlUdu8xx5qhDI
VNDetectedPoint
VNRecognizedPoint
VNFaceprint
VNSerializingInternal
SaliencyExtrema
VNSaliencyImageObservation
VNImageSaliencyObservation
VNBrightnessDetector
VNScreenGazeDetector
VNClassifyImageAestheticsRequestConfiguration
VNClassifyImageAestheticsRequest
VNRectangleTracker
VNCVPixelBufferHelper
VNBarcodeObservation
VNDataDetectorSupporting
VNDocumentSegmentationDetector
VNDetectFaceGazeRequestConfiguration
VNDetectFaceGazeRequest
VNPersonsModelFaceID2ModelAdditions
VNPersonsModelFaceModelVIPv2
VNSmartCamClassifier
VNRecognizeObjectsRequestConfiguration
VNRecognizeObjectsRequest
VNFaceExpressionDetector
VNImageTensorDescriptor
VNSceneprint
VNSceneFeaturePrint
VNDetectTextRectanglesRequestConfiguration
VNDetectTextRectanglesRequest
VNPersonsModelAdditions
_VNPersonsModelDataSourceBasedDataProvider
VNPersonsModelFaceModelDataProvider
VNPersonsModel
VNPersonsModelInformation
VNPersonsModelAlgorithm
VNPersonsModelAlgorithmVIPv2
VNPersonsModelAlgorithmVIPv3
VNPersonsModelConfiguration
VNPersonsModelPrediction
VNPersonsModelReadOptions
VNPersonsModelWriteOptions
VNClassifyImageRequestConfiguration
VNClassifyImageRequest
VNImageRegistrationRequest
VNFaceAttributeCategory
VNObjectCloning
VNFaceAttributes
VNMTLDeviceWisdomParameters
VNCreateDetectionprintRequestConfiguration
VNCreateDetectionprintRequest
VNDetectionprintObservation
VNSegmentationGenerator
VNSmartCamprint
VNFingerprintHash
VNImageSignature
VNFaceAnalyzerMultiDetector
VNEntityIdentificationModelWriteOptions
VNMPUtils
VNOperationPointsProvider
VNOperationPointsProviding
VNRecognizeSportBallsRequest
VNFaceSegmentGenerator
VNVideoProcessorCadence
VNVideoProcessorRequestConfigurationPopulating
VNVideoProcessorFrameRateCadence
VNVideoProcessorTimeIntervalCadence
VNVideoProcessorRequestProcessingOptions
VNVideoProcessor
VNRecognizedPointsObservation
VNHumanPoseDetector
VNEntityIdentificationModelConfiguration
VNSingleHeadSceneprintGenerator
ShotflowDetector
ShotflowDetectorANFDv1
ShotflowDetectorANODBase
ShotflowDetectorANFDv2
ShotflowDetectorANODv3
ShotflowDetectorANODv4
ShotflowDetectorANSTv1
VNANFDMultiDetectorANODv3
VNOpticalFlowGenerator
VNFaceDetectorPrivateRevisionLegacyFaceCore
VNEspressoModelClassifier
VNDetectBarcodesRequest
VNDetectBarcodesRequestConfiguration
VNImageNeuralHashprintObservation
VNTrackerManager
VNGuidedUpsamplingGenerator
VNFaceAnalyzerMultiDetectorFPrev3_1FArev1_3_MD3
VNEntityIdentificationModelPrediction
VNGenerateImageFeaturePrintRequestConfiguration
VNGenerateImageFeaturePrintRequest
VNSmartCam5GatingDetector
VNFrameworkDescriptor
VNDetectHumanHandPoseRequestConfiguration
VNDetectHumanHandPoseRequest
VNHumanHandPoseObservation
ANFDDetectedObject
VNMPImageData
VNOperationPoints
_VNUnspecifiedOperationPoints
LKTOpticalFlowGPU
VNNOPRequestConfiguration
VNNOPRequest
VNDetectFaceLandmarksRequestConfiguration
VNDetectFaceLandmarksRequest
VNImageprint
VNOriginatingRequestSpecifierProviding
VNSerializing
VNFaceGeometryEstimator
VNMetalProcessingDevice
VNMetalContext
VNCIFilter
VNCIContrastFromAverageColorFilter
VNCIContrastWithPivotColorFilter
VNCIMultiplicationFilter
VNEspressoModelImageprint
VNFaceAnalyzerMultiDetectorFPrev3_1FArev1_3_MD2
VNImageAestheticsObservation
VNContoursObservation
VNTrajectoryRequestState
VNTrajectoryProcessor
VNFaceRegionMapGenerator
VNObservation
VNDetectedObjectObservation
VNObservationAdditions
VNFaceObservation
VNImageAlignmentObservation
VNImageTranslationAlignmentObservation
VNImageHomographicAlignmentObservation
VNImageScoreObservation
VNImageprintObservation
VNImageBlurObservation
VNImageBrightnessObservation
VNClassificationObservation
VNRecognizedObjectObservation
VNCoreMLFeatureValueObservation
VNPixelBufferObservation
VNRectangleObservation
VNHorizonObservation
VNCluster
VNClusterObservation
VNFeaturePrintObservation
VNSceneObservation
VNSmartCamObservation
VNRecognizedTextObservation
VNTrajectoryObservation
_VNTextObservationCharacterBox
VNTextObservation
VNOpticalFlowObservation
VNHorizonDetector
VNVTSession
VNVTPixelTransferSession
VNVTImageRotationSession
VNVTSessionManager
VNTorsoprintGeneratorPrivateRevision4MD2HomeAIHumanDetectorBased
VNDetectFacePoseRequest
VNImageBasedRequestConfiguration
VNImageBasedRequest
VNDetectedObjectObservationAcceptingInternal
VNImageIdealImageSizeProviding
VNEntityIdentificationModelTrainedModelVIPv3Additions
VNEntityIdentificationModelTrainedModelVIPv3
VNVersionParser
VNCreateAnimalprintRequest
VNHeatMapExtrema
VNHeatMapUtilities
VNGenerateImageSaliencyRequestConfiguration
VNGenerateImageSaliencyRequest
VNRecognizeAnimalsRequest
VNANERuntimeDirectProcessingDevice
VNCVPixelBufferPoolManager
VNTorsoprintGeneratorPrivateRevision3MD2HumanDetectorBased
VNDetectorCache
VNDetectorProviding
VNDetectorReleasing
VNHumanBodyPoseDetector
VNEntityIdentificationModelTrainedModelAdditions
VNEntityIdentificationModelTrainedModel
VNCVPixelBufferConversionHelpers
VNContoursDetector
VNClassifyFaceAttributesRequest
VNGeneratePersonSegmentationRequestConfiguration
VNGeneratePersonSegmentationRequest
VNSequenceRequestHandler
VNPersonsModelFaceModel
_VNDetectorDescriptorIdentifierVersionTuple
_VNInferenceNetworkDescriptorInfo
VNInferenceNetworkDescriptor
VNHomeAppFaceAnalyzerMultiDetectorFPrev3_1FArev1_3_MD3
VNEntityIdentificationModelInformation
VNHumanHandPoseDetector
VNDetectHumanRectanglesRequestConfiguration
VNDetectHumanRectanglesRequest
VNAnimalprint
VNPersonSegmentationGeneratorLearnedMattingTiled
VNMPImageGrouping
VNEspressoResources
VNEspressoHelpers
VNPersonSegmentationGeneratorLearnedMatting
VNRecognizeAnimalHeadsRequest
VNImageRegistrationDetector
VNPanopticSegmentationGenerator
VNDetectObjectAtPointRequestConfiguration
VNDetectObjectAtPointRequest
LKTOpticalFlowCPU
VNDetectionprintTensor
VNDetectionprint
VNDetectFace3DLandmarksRequest
VNTensorDescriptor
VNRecognizedPointsSpecifier
VNJunkIdentifier
VNdGg5skzXHSAENO6T3enHEConfiguration
VN6Mb1ME89lyW3HpahkEygIG
VNRectangleDetector
VNCPUProcessingDevice
VNTorsoprintGeneratorBase
VNClassifyCityNatureImageRequestConfiguration
VNClassifyCityNatureImageRequest
VNDetectDocumentSegmentationRequest
VNImageBlurScoreRequestConfiguration
VNImageBlurScoreRequest
VNFaceDetector
VNFaceLandmarkRegion
VNFaceLandmarkRegion2D
VNFaceLandmarkRegion3D
VNFaceLandmarks
VNFaceLandmarks2D
VNFaceLandmarks3D
VNTorsoprintGeneratorRevision1
VNValidationUtilities
VNFaceLandmarkDetectorRevision3
VNProcessingDescriptor
VN1vLyVSh30UQ26TGBoV8MHv
VNBlacklist
CVMLFaceprint_LegacySupportDoNotChange
CVMLObservation_LegacySupportDoNotChange
CVMLImageprintObservation_LegacySupportDoNotChange
MPImageDescriptor_LegacySupportDoNotChange
VNTrackLegacyFaceCoreObjectRequest
VNTorsoprint
VNMLFeatureProvider
MLFeatureProvider
VNCoreMLModel
VNCoreMLTransformer
VNSceneTaxonomyOperationPoints
VNFaceLegacyFaceCore
VNSmartCam5CompoundRequestGroupingConfiguration
VNSmartCam5CompoundRequest
VNImageClassifier
VNCreateImageprintRequestConfiguration
VNCreateImageprintRequest
ParabolaDetection
VNPersonSegmentationGeneratorFast
VNDetectHumanBodyPoseRequestConfiguration
VNDetectHumanBodyPoseRequest
VNImageFingerprintsObservation
VNOpticalFlowGeneratorRevision1
VNCoreEspressoUtils
VNStatefulRequestConfiguration
VNStatefulRequest
VNMRCDetector
VNFaceScreenGaze
VNFaceSegments
VNFaceAnalyzerMultiDetectorFArev2_CameraLightweight
VNObjectTracker
VNModelFileImpl
VNModelFile
VNModelFilesCache
_VNGlobalSession
VNSession
VNDetectorCacheDelegate
VNTrackerProviding
VNRPNTrackerResourcesProviding
VNRequestWarming
VNWeakSessionWrapper
VNGeometryUtils
VNBoundingCircleAlgorithm
VNContourAreaCalculationAlgorithm
VNContourPerimeterAlgorithm
VNMPImageDescriptor
VNANFDMultiDetectorANFDv2
VNResourceVersion
VNGenerateFaceSegmentsRequestConfiguration
VNGenerateFaceSegmentsRequest
VNRecognizeFoodAndDrinkRequest
VNDetectFaceRectanglesRequestConfiguration
VNDetectFaceRectanglesRequest
VNRecognizeDocumentsRequestConfiguration
VNRecognizeDocumentsRequest
VNDocumentObservationsAccepting
VNCIContextsHandler
VNCIContext
VNCIContextManager
VNDetectFaceCaptureQualityRequestConfiguration
VNDetectFaceCaptureQualityRequest
VNVector
VNTranslationalImageRegistrationRequest
VNFaceQualityGeneratorPrivateRevisionV3MD4
VNCreateSmartCamprintRequestConfiguration
VNCreateSmartCamprintRequest
VNImageAnalyzerMultiDetector
_VNImageAnalyzerMultiDetectorSceneOperationPointsCache
_VNImageAnalyzerMultiDetectorSceneOperationPointsProvider
VNDetectContoursRequestConfiguration
VNDetectContoursRequest
VNRecognizeDocumentElementsRequestElementConfiguration
VNRecognizeDocumentElementsRequestConfiguration
VNRecognizeDocumentElementsRequest
VNTorsoprintGeneratorHumanDetectorBased
VNCreateImageFingerprintsRequestConfiguration
VNCreateImageFingerprintsRequest
VNSliderNetDetector
VNCreateFaceRegionMapRequest
VNPersonsModelMigration
CCCharBoxContext
CCTextDetector
VNEntityIdentificationModelReadOptions
VNObjectTrackerRevision1
VNEntityIdentificationModelTrainedModelVIPv2Additions
VNEntityIdentificationModelTrainedModelVIPv2
VNFaceQualityGeneratorRevision1
VNObservationsCache
VNEspressoModelFileBasedDetector
VNRecognizeTextRequestConfiguration
VNRecognizeTextRequest
VNRecognizedText
VNContour
ShotflowDetection
VNRemoveBackgroundRequestConfiguration
VNRemoveBackgroundRequest
VNDetectRectanglesRequestConfiguration
VNDetectRectanglesRequest
VNReadOnlyPersonsModel
VNPersonsModelDataSource
VNCreateSceneprintRequestConfiguration
VNCreateSceneprintRequest
VNANFDMultiDetectorANSTv1
VNMemeClassifier
VNRecognizedHandPointsSpecifier
VNFaceLandmarkDetectorDNN
VNRequestPerformer
VNRequestCancelling
VNIdentifyJunkRequest
VNHomographicImageRegistrationDetector
VNANFDMultiDetectorOriginalRequestInfo
6 `%`
VNANFDMultiDetector
VNClassificationCustomHierarchy
_VNImageAnalyzerMultiDetectorClassificationCustomHierarchy
VNFaceGaze
VNAsyncStatus
VNProcessingDevice
VNAlignFaceRectangleRequestConfiguration
VNAlignFaceRectangleRequest
VN3XKGTKNBvy6h4RFtpxLyW
VNClustererOptions
VNClustererQueryOptions
VNClustererBuilderOptions
VNClustererQuery
VNClustererBuilder
VNDocumentObservation
VNRecognizedTextBlock
VNRecognizedTextBlockObservation
VNDataDetectorResult
VNCoreMLRequestConfiguration
VNCoreMLRequest
VNOpticalFlowGeneratorRevision2
VNMPContext
VNRPNTrackerEspressoResources
VNRPNTrackerEspressoResourcesCache
VN6Ac6Cyl5O5oK19HboyMBR
VN6B8mkraBUpwUqskMYPtS3
VNGenerateAnimalSegmentationRequestConfiguration
VNGenerateAnimalSegmentationRequest
VNRemoveBackgroundProcessor
_VNEntityIdentificationModelDataSourceBasedTrainedModelDataProvider
VNEntityIdentificationModel
VNHumanObservation
ShotflowNetwork
ShotflowNetworkANFDv1
ShotflowNetworkANODBase
ShotflowNetworkANFDv2
ShotflowNetworkANODv3
ShotflowNetworkANODv4
ShotflowNetworkANSTv1
VNDetectFaceExpressionsRequest
VNGeneratePersonSemanticsCompoundRequest
VNBrightnessMeasure
VNHomeAppFaceAnalyzerMultiDetectorBase
VNEntityIdentificationModelAdditions
VNTrackRectangleRequest
LKTOpticalFlow
VNCreateFaceTorsoprintRequestConfiguration
VNCreateFaceTorsoprintRequest
VNFaceLandmarkDetectorRevision2
OrientationAdditions
VNCreateFaceprintRequestConfiguration
VNCreateFaceprintRequest
VNImageSignatureDetector
VNPersonsModelFaceID3ModelAdditions
VNPersonsModelFaceModelVIPv3
VNGenerateSkySegmentationRequestConfiguration
VNGenerateSkySegmentationRequest
VNTrackObjectRequest
VNFaceBBoxAligner
VNTracker
VNImageExposureScoreRequest
VNFaceQualityGeneratorRevision2
VNSmartCamCombinedAestheticsAndSaliencyDetector
VNCompoundRequest
VNUniqueObservationClassCompoundRequest
VNHomologousObservationClassCompoundRequest
VNGenerateOpticalFlowRequestConfiguration
VNGenerateOpticalFlowRequest
VNReadOnlyEntityIdentificationModel
VNFaceGazeDetector
VNANERuntimeProcessingDevice
VNRequestPerformingContext
VNImageBufferProviding
VNTrackHomographyRequestConfiguration
VNTrackHomographyRequest
VNANFDDetectorCompoundRequestConfiguration
VNANFDDetectorCompoundRequestConfigurationGroups
VNANFDDetectorCompoundRequest
VNGenerateObjectnessBasedSaliencyImageRequestConfiguration
VNGenerateObjectnessBasedSaliencyImageRequest
VNImageRegistrationSignature
VNImageRegistration
VNPersonsModelData
VNBlurDetector
VNImageprintGenerator
VNTargetedImageRequest
VNTorsoprintGeneratorFaceBased
VNDetectionprintGenerator
VNCircle
VNTensorDataTypeAdditions
VNTensorShape
VNEspressoTensorShape
VNImageRequestHandler
VNEntityIdentificationModelAlgorithm
VNEntityIdentificationModelAlgorithmVIPv2
VNEntityIdentificationModelAlgorithmVIPv3
VNDetectHorizonRequest
CGImage
.cxx_destruct
T@"<VNDetectorCacheDelegate>",&
ICReportFrameAnalysis:forPresentationTime:withStats:
T@"NSArray",R,C
ICShouldBeCanceled
T@"NSArray",R,N
T#,R
T@"NSDictionary",R,N,V_features
T#,R,N,V_requestClass
T@"NSNumber",C,N,V_inputFactor2
T*,VpulseVectorHeightCharBoxAdaptive
T@"NSNumber",C,N,V_inputFactor4
T@"<MLFeatureProvider>",&,N,V_featureProvider
T@"NSString",R,C,N,V_identifier
T@"<NSLocking>",R
T@"NSUUID",&,N,SsetUUID:,V_uuid
T@"<NSObject><NSCopying>",R,N,V_observationsCacheKey
T@"VNFaceprint",&,N,V_faceprint
T@"<NSObject><NSCopying><NSSecureCoding>",R,C,V_entityUniqueIdentifier
T@"VNImageTensorDescriptor",R,N
T@"<VNEntityIdentificationModelTrainingDataDelegate>",W,V_delegate
T@?,C,N
T@"BCSDetectedCode",&,N,V_detectedBarcodeSupportCode
TB,N,V_readOnly
T@"CIBarcodeDescriptor",R,N,V_barcodeDescriptor
TB,R,N,GisValid
T@"CRImageReaderOutput",R,C,V_crOutput
TC,V_ii
T@"LKTOpticalFlow",&,N,V_opticalFlow
TQ,N,V_faceprintRequestRevision
T@"MLModel",&,V_model
TQ,N,V_revision
T@"NSArray",&,N,V_clusters
T^v,R,V_context
T@"NSArray",&,N,V_groupedClusteredFaceIdsForCluster
Tf,N,V_precisionRecallThreshold
T@"NSArray",&,N,V_objects
Tf,R,N,V_tastefullyBlurredScore
T@"NSArray",&,N,V_suggestionsForCluster
Tf,V_confidence
T@"NSArray",C,N,V_allLabelsWithConfidences
Tf,V_pitchAngle
T@"NSArray",C,N,V_inputDetectedObjectObservations
Tq,V_nextLeafId
T@"NSArray",C,N,V_originalRequestConfigurations
T{?={?=qiIq}{?=qiIq}{?=qiIq}},R
T@"NSArray",C,N,V_smartCamprints
T{CGPoint=dd},R
T@"NSArray",C,N,V_textObjects
_C0_tex
T@"NSArray",C,V_precisionEstimatesPerPoint
_G0_tex
T@"NSArray",R
_aestheticScore
T@"NSArray",R,C,N
_barcodeRequest
T@"NSArray",R,C,N,V_detectedPoints
_bounds
T@"NSArray",R,C,N,V_labels
_cachedAppClipCodeMetadataValue
T@"NSArray",R,C,N,V_originalRequests
_charBoxContext
T@"NSArray",R,C,N,V_results
_computeZCVectorHighProbability
T@"NSArray",R,D,N
_crOutputRegion
T@"NSArray",R,N,GgetChildren
_descriptorData
T@"NSArray",R,N,GgetRecognizedLanguages
_detectionLevel
T@"NSArray",R,V_precisionEstimatesPerPoint
_detectorMultiSessionAccessLock
T@"NSBundle",R,N,V_frameworkBundle
_explicitlySetMaximumIdentities
T@"NSData",&,N,V_clusterState
_faceAttributes
T@"NSData",&,V_faceprint
_faceObservationsForRegionOfInterestContainingFaceObservations:
T@"NSData",R,C
_faceTorsoprint
T@"NSData",R,C,V_pointsData
_idealDimension
T@"NSData",R,N,V_landmarkPoints3d
_imageprintType
T@"NSData",R,N,V_outputBufferData
_kernel
T@"NSData",R,V_descriptorData
_landmarkPoints
T@"NSDate",R,C,N,V_lastModificationDate
_legacyFaceCore
T@"NSDate",R,N,V_lastModificationDate
_makeupCategory
T@"NSDictionary",&,N,V_representativenessById
_medianLineLock
T@"NSDictionary",C,N,V_detectorConfigurationOptions
_networkFileURL
T@"NSDictionary",R,C,D
_networkVersion
T@"NSDictionary",R,C,V_configurationOptions
_observationGroupConfigurations
T@"NSDictionary",R,D
_olmcsThreshold
T@"NSError",R,N,V_error
_originatingRequestSpecifierKey
T@"NSIndexSet",C,N,V_acceptableVersions
_performInPlace
T@"NSIndexSet",R,C
_points
T@"NSMutableArray",R,N,V_originalRequests
_previousLeafDescriptorDistance
T@"NSNumber",&,N
_radius
T@"NSNumber",&,N,V_cascadeStepCount
_removeExistingFaceObservations:fromPersonWithUniqueIdentifier:
T@"NSNumber",&,N,V_distance
_rightPupilLock
T@"NSNumber",&,N,V_faceCoreInitialAngle
_smartCamprints
T@"NSNumber",&,N,V_faceCoreNumberOfDetectionAngles
_stopSensitized
T@"NSNumber",&,N,V_roll
_torsoThreshold
T@"NSNumber",C,N,V_inputContrast
_userFacingBBox
T@"NSNumber",C,N,V_timeStamp
_videoProcessor
T@"NSNumber",R,C,N
advise:
T@"NSObject<OS_dispatch_queue_attr>",R,D
analysisTypesForProcessOptions:
T@"NSPointerArray",&,N,V_requestImageBuffers
applyTransform:
T@"NSSet",&,N,V_clusteredFaceIds
bBottom
T@"NSSet",R,C
boundingCircleForContour:error:
T@"NSString",&,N
bufferTableLock
T@"NSString",&,N,V_value
bundleWithPath:
T@"NSString",&,V_inputImageKey
compoundResults
T@"NSString",&,V_predictedFeatureKey
computeNumCropCols:width:start:
T@"NSString",C,N,V_additionalCharacters
containsString:
T@"NSString",C,N,V_locateMode
copyFlagValue:toTarget:atIndex:
T@"NSString",C,N,V_type
cornersForCharacterRange:error:
T@"NSString",C,V_faceprintInputPath
T@"NSString",R
currentRevision
T@"NSString",R,C,N
dataWithLength:
T@"NSString",R,C,N,V_imageprintVersion
dealloc
T@"NSString",R,C,N,V_sceneprintVersion
defaultRevision
T@"NSString",R,C,N,V_symbology
detectedObjectClassToRequestKey
T@"NSString",R,C,V_identifier
detectorCache:didEvictDetector:
T@"NSString",R,D,N
dictionaryValue
T@"NSString",R,V_externalImageId
dropTrainedModelAndReturnError:
T@"NSString",R,V_imageFilePath
encodeArrayOfObjCType:count:at:
T@"NSString",R,V_modelName
errorForMemoryAllocationFailure
T@"NSString",R,V_predictedProbabilitiesKey
externalImageId
T@"NSURL",R,N,V_networkFileURL
faceCoreNumberOfDetectionAngles
T@"NSURL",R,V_logFolderURL
faceObservation
T@"NSUUID",R
featureProvider
T@"NSUUID",R,N,V_lookedAtFaceObservationUUID
filterDescriptorWithWidth:height:arrayLength:kernelSpatialDiameter:kernelTemporalDiameter:epsilon:sourceChannels:guideChannels:
T@"NSUUID",R,V_requestUUID
frameworkBundle
T@"VN6Ac6Cyl5O5oK19HboyMBR",C,N,V_inputSignatureprint
getFloatValue:forKey:inOptions:minimumValue:maximumValue:error:
T@"VN6Ac6Cyl5O5oK19HboyMBR",R,V_imageSignatureprint
getRegionLabels
T@"VNAnimalprint",R,N
groupIdentifier
T@"VNAsyncStatus",R,C,V_asyncStatus
identifierCount
T@"VNClassificationCustomHierarchy",&,N,V_customHierarchy
imageProperties
T@"VNClassificationObservation",C,N,V_mostLikelyLabel
imageWithCVImageBuffer:options:
T@"VNControlledCapacityTasksQueue",R
imageprintValid
T@"VNCoreMLModel",R,N,V_model
initWithBox:defaultBox:confidence:scale:rotationAngle:yawAngle:
T@"VNDetectBarcodesRequest",&,N,V_barcodeRequest
initWithCoder:forCodingVersion:
T@"VNDetectionprint",R,C,V_detectionprint
initWithFormat:
T@"VNEntityIdentificationModelAlgorithm",R,C
initWithNode:freeNodeOnDealloc:
T@"VNEntityIdentificationModelConfiguration",R,C
initWithOriginatingRequestSpecifier:faceBoundingBox:pointCount:
T@"VNEspressoResources",R,N,V_espressoResources
initWithState:byteOffset:error:
T@"VNFaceAttributeCategory",R,V_VN1uMyFtnYEWjbrdx3yAuDndKkPeyzNJhB
initWithTargetedImageURL:orientation:options:completionHandler:
T@"VNFaceAttributeCategory",R,V_VN3iT1YRjjnIuELobV1olJiO1vvItN6Kdq
inputDetectedObjectObservations
T@"VNFaceAttributeCategory",R,V_VN7CbCeAogPS2iHE6VQwu6H96xanljtMqk
inputTextBlocks
T@"VNFaceAttributeCategory",R,V_VN7fiLHgGnvqPqG63cfDUCK4Xm8obUuWoP
isAtEnd
T@"VNFaceAttributeCategory",R,V_ageCategory
isProxy
T@"VNFaceAttributeCategory",R,V_eyesCategory
isValid
T@"VNFaceAttributeCategory",R,V_facemaskCategory
keyUsedToCacheResultsOfRequest:
T@"VNFaceAttributeCategory",R,V_hairColorCategory
leftEye
T@"VNFaceAttributeCategory",R,V_makeupEyesCategory
linkTimeOrRunTimeBeforeVersion:
T@"VNFaceAttributeCategory",R,V_smilingCategory
loadedDetectors
T@"VNFaceGaze",R,N,V_gaze
mBottom
T@"VNFaceLandmarkRegion2D",R,V_faceContour
maximumEntities
T@"VNFaceLandmarkRegion2D",R,V_leftEye
medianHeightTop
T@"VNFaceLandmarkRegion2D",R,V_leftPupil
multiArrayValue
T@"VNFaceLandmarkRegion2D",R,V_nose
networkRequiredInputImageHeight
T@"VNFaceLandmarkRegion2D",R,V_outerLips
newCommandQueue
T@"VNFaceLandmarkRegion2D",R,V_rightEyebrow
numberWithBool:
T@"VNFaceLandmarkRegion3D",R,V_allPoints
objects
T@"VNFaceLandmarkRegion3D",R,V_innerLips
orderedRequests
T@"VNFaceLandmarkRegion3D",R,V_leftEyebrow
outputBlobNames
T@"VNFaceLandmarkRegion3D",R,V_nose
pixelFormatType
T@"VNFaceLandmarkRegion3D",R,V_outerLips
pixelsHighRange
T@"VNFaceLandmarkRegion3D",R,V_rightEyebrow
pointerAtIndex:
T@"VNFaceLandmarks2D",R,N
predictedPersonUniqueIdentifier
T@"VNFaceLegacyFaceCore",R,N,V_legacyFaceCore
profile
T@"VNFaceRegionMap",R,N,V_faceRegionMap
projectedPoints
T@"VNFaceSegments",R,N,V_faceSegments
ptrFile
T@"VNImageRegistrationSignature",&,N,V_floatingImageSignature
T@"VNImageSignature",&,N,V_targetImageSignature
recordImageCropQuickLookInfoToOptionsSafe:cacheKey:imageBuffer:
T@"VNMPContext",&,N,V_context
release
T@"VNMetalContext",R,N,V_metalContext
releaseTracker:
T@"VNObservation<VNEntityIdentificationModelObservation>",R,V_observation
requestClassNameFromRequestKey:
T@"VNPersonsModelAlgorithm",R,C,N
requestRevision
T@"VNPersonsModelConfiguration",R,C,N
requiredVersion
T@"VNPixelBufferObservation",R,N,V_globalSegmentationMask
revision:supportsConstellation:
T@"VNPixelBufferObservation",R,V_segmentationMask
seekToEndOfFile
T@"VNPoint",R,V_center
session
T@"VNProcessingDevice",C,N
setAgeCategory:
T@"VNProcessingDevice",R,C,N
setBoundingBox:
T@"VNRecognizeDocumentElementsRequestElementConfiguration",R,V_documentElements
setCharboxROIFullVectorHeight2:
T@"VNRecognizeDocumentElementsRequestElementConfiguration",R,V_textElements
setDebugMatlab:
T@"VNRecognizedTextBlockObservation",R,N,GgetTitle
setKey:
T@"VNRequest",R,N,V_request
setMergesCount:
T@"VNRequestSpecifier",R,C
setMinimumCharacterPixelHeight:
T@"VNRequestSpecifier",R,N,V_landmarks3DOriginatingRequestSpecifier
setMmWidthCard:
T@"VNRequestSpecifier",R,N,V_poseOriginatingRequestSpecifier
setNumberOfKeypointsToConsider:
T@"VNResourceVersion",R,N
setOpticalFlow:
T@"VNSceneObservation",&,N,V_sceneObservation
setStopMaxFind:
T@"VNSizeRange",R,N,V_pixelsHighRange
setTemporalSmoothingFrameCount:
T@"VNSupportedImageSize",&,N,V_detectorPreferredImageSize
setUsesCPUOnly:
T@"VNTasksQueueCache",R,D
setYaw:
T@"VNTensorDescriptor",R,N,V_faceprintOutput
sortBoxes:filterThresholdIndex:
T@"VNTorsoprint",&,N
startSensitized
T@"VNVector",R
stringByAppendingPathComponent:
T@?,C,N,VprogressHandler
stringFromDate:
targetFrameTime
TB,N
topLeft
TB,N,V_automaticallyDetectsLanguage
trackedFrameCVPixelBufferFormat
TB,N,V_detectDiacritics
validTorsoprint
TB,N,V_detectorWantsAnisotropicScaling
validateRequestClassName:error:
TB,N,V_faceCoreEnhanceEyesAndMouthLocalization
versionForStringRepresentation:
TB,N,V_faceCoreExtractSmile
TB,N,V_forceUseInputCVPixelBufferDirectly
.cxx_construct
T@"<NSObject><NSCopying>",R,C,N
ACBSBarcodeTypeForBarcodeSymbology:
T@"NSArray",C,N
ICReportProgress:
T@"NSArray",R,D
MRCSymbologyForBarcodeSymbology:
T@"NSData",R,N,V_landmarkPoints
T#,R,D
T@"NSNumber",C,N,V_inputFactor1
T*,VpulseVectorHeightCharBox
T@"NSNumber",C,N,V_inputFactor3
T,R,N,V_equationCoefficients
T@"NSString",C,N,V_detectorType
T@"<MTLDevice>",&,N
T@"NSString",R,N,GgetTranscript
T@"<NSObject><NSCopying>",C,N,V_modelCachingIdentifier
T@"VN6Ac6Cyl5O5oK19HboyMBR",C,N
T@"<NSObject><NSCopying><NSSecureCoding>",R,C,N,V_predictedPersonUniqueIdentifier
T@"VNFaceprint",R,N,V_faceprint
T@"<VNEntityIdentificationModelDelegate>",&
T@"VNSession",R
T@"<VNPersonsModelDataDelegate>",W,N,V_delegate
TB,N,V_hasLabel
T@"CCCharBoxContext",&,V_charBoxContext
TB,N,V_useSegmentationPregating
T@"CIImage",&,N,V_inputImage
TB,V_performSceneClassification
T@"DDScannerResult",&,N,V_scannerResult
TI,V_stopNormal
T@"MLFeatureValue",R,C,N,V_featureValue
TQ,N,V_personId
T@"MLObjectBoundingBoxOutputDescription",R,V_boundingBoxOutputDescription
TQ,R,N,V_imageSignatureHashType
T@"NSArray",&,N,V_filterThresholds
Tf,N,V_commonGazeLocationRadius
T@"NSArray",&,N,V_landmarkPrecisionEstimatesPerPoint
Tf,N,V_yawAngle
T@"NSArray",&,N,V_suggestedIdsForRepresentative
Tf,R,N,V_wellFramedSubjectScore
T@"NSArray",&,V_qualityCriteriaList
Tf,V_nextLeafDescriptorDistance
T@"NSArray",C,N,V_customWords
Ti,R,N,V_height
T@"NSArray",C,N,V_inputFaceObservations
Tq,V_objectType
T@"NSArray",C,N,V_recognitionLanguages
T{CGPoint=dd},N
T@"NSArray",C,N,V_symbologies
T{CGPoint=dd},R,N,V_bottomRight
T@"NSArray",C,N,VinputTextBlocks
_C1_tex
T@"NSArray",C,V_regionLabels
_G1_tex
T@"NSArray",R,C,D
_analysisPreRollFramesRemaining
T@"NSArray",R,C,N,V_baselines
_blocks
T@"NSArray",R,C,N,V_inputFaceObservations
_buffer
T@"NSArray",R,C,N,V_orderedChildRequests
_center
T@"NSArray",R,C,N,V_projectedPoints
_characterBoxes
T@"NSArray",R,C,V_fingerprintHashes
_contrastFilter
T@"NSArray",R,N,GgetBlocks
_createPixelBufferOfWidth:height:fromImageBuffer:options:error:
T@"NSArray",R,N,GgetLines
_detectedPoints
T@"NSArray",R,N,V_sceneprints
_detectionprint
T@"NSAttributedString",R,C,N,V_attributedString
_device
T@"NSData",&,N,V_alignedMeanShape
_extractOptions
T@"NSData",&,N,V_state
_faceId
T@"NSData",R
_faceScreenGaze
T@"NSData",R,C,N
_height
T@"NSData",R,N
T@"NSData",R,N,V_landmarkPoints65
_inputs
T@"NSData",R,N,V_poseData
_labels
T@"NSData",R,V_rawColorGaborDescriptor
_ledger
T@"NSDate",R,C,V_lastModificationDate
_mSalientRegion
T@"NSDictionary",&,N,V_distancesById
_maximumTrainingPrintsPerEntity
T@"NSDictionary",C,N,SsetACBSBarcodeInfo:,V_acbsBarcodeInfo
_midRow
T@"NSDictionary",R
_networkRequiredInputImageWidth
T@"NSDictionary",R,C,N
_normalizedPath
T@"NSDictionary",R,C,V_labelsAndConfidence
_offsetsOutputs
T@"NSDictionary",R,N,V_faceSegmentLabelToProbabilityMap
_origImageWidth
T@"NSIndexPath",R,V_indexPath
_outputConfidenceEspressoBuffer
T@"NSIndexSet",C,V_acceptableVersions
_pixelWidthCard
T@"NSIndexSet",R,C,N
_preScaleFactor
T@"NSNotificationCenter",R
_previousLeafId
T@"NSNumber",&,N,V_blurScore
_regionOfInterestConfigurations
T@"NSNumber",&,N,V_contrastPivot
_requestToHumanReadableLabelMap
T@"NSNumber",&,N,V_exposureScore
_scenePrintMLMultiArrayDataType
T@"NSNumber",&,N,V_faceCoreMinFaceSize
_smartThreshold
T@"NSNumber",&,N,V_pitch
_topLevelRegion
T@"NSNumber",&,N,V_yaw
_trackerManager
T@"NSNumber",C,N,V_inputPivot
_uv_tex
T@"NSNumber",R
acbsBarcodeInfo
T@"NSNumber",R,N,V_faceCaptureQuality
allKeys
T@"NSObject<OS_dispatch_semaphore>",&,V_cancellationSemaphore
applicableDetectorAndOptions:forRevision:loadedInSession:error:
T@"NSPointerArray",&,N,V_requestImageBuffersCacheKeys
arrayWithArray:
T@"NSSet",R
boundingBoxIsCalculatedProperty
T@"NSSet",R,N
T@"NSString",&,N,V_shortDescription
bundleForClass:
T@"NSString",&,V_imageFilePath
cadence
T@"NSString",&,V_inputScenePrintKey
computeBlurScore:usingBlurSignature:insetFactor:imageROI:error:
T@"NSString",C,N
containsObject:
T@"NSString",C,N,V_cachePath
context
T@"NSString",C,N,V_textRecognition
corners
T@"NSString",C,V_debugFilename
createErrorWithCode:andMessage:
T@"NSString",C,V_key
currentDateTime
T@"NSString",R,C
customHierarchy
T@"NSString",R,C,N,V_featureName
dateFromString:
T@"NSString",R,C,N,V_name
decodeArrayOfObjCType:count:at:
T@"NSString",R,C,N,V_smartCamprintVersion
descriptorsForIdentifier:error:
T@"NSString",R,C,N,V_text
detectorCache:didCacheDetector:
T@"NSString",R,D
detectorWantsAnisotropicScaling
T@"NSString",R,N,V_originatingRequestSpecifierKey
directANEDevice
T@"NSString",R,V_fileNameBase
emptyTorsoprintDataForRevision:
T@"NSString",R,V_level
entityIdentificationModel:numberOfObservationsForEntityAtIndex:
T@"NSString",R,V_networkConfigurationName
expansionRatioWithinValidRange:
T@"NSString",R,V_version
faceBoundingBox
T@"NSURL",R,V_logFileURL
faceIDModelMaximumElementsPerID
T@"NSUUID",C,V_identifier
faceprintOutput
T@"NSUUID",R,N,V_faceObservationUUID
fileURL
T@"NSUUID",R,V_key
filterWithName:
T@"ShotflowDetector",R,N,V_mMultiHeadedANFDDetector
getComputedRectifyingTransform:
T@"VN6Ac6Cyl5O5oK19HboyMBR",R,V_imageNeuralHashprint
getPixelFocalLengthIfAvailable:
T@"VN6B8mkraBUpwUqskMYPtS3",R,V_imageSignatureHash
glassesCategory
T@"VNAsyncStatus",R,C
hasPose
T@"VNCircle",R
imageConstraint
T@"VNClassificationCustomHierarchy",R,C,N
imageTransformForCGOrientation:
T@"VNControlledCapacityTasksQueue",&,N,V_synchronizationQueue
imageWithContentsOfURL:options:
T@"VNControlledCapacityTasksQueue",R,C,N
initWithAnimalprint:confidence:
T@"VNCoreMLModel",R,V_model
initWithCMSampleBuffer:options:
T@"VNDetectedObjectObservation",&,N,V_inputObservation
initWithDevice:andWisdomParams:
T@"VNEntityIdentificationModelAlgorithm",C,N,V_algorithm
initWithLength:
T@"VNEntityIdentificationModelAlgorithm",R,C,V_algorithm
initWithOriginatingRequestSpecifier:compressedPoints:imageSize:
T@"VNEntityIdentificationModelInformation",R,C
initWithPayload:symbolVersion:maskPattern:errorCorrectionLevel:
T@"VNFaceAttributeCategory",R
initWithString:
T@"VNFaceAttributeCategory",R,V_VN2riiZbQrloRhCzYW56f0rk4N3ROe151S
initWithWidth:height:numScales:
T@"VNFaceAttributeCategory",R,V_VN4UfLbvVUqMvYV8bbGFQcxg5yRLm8ekI1
inputImageWidth
T@"VNFaceAttributeCategory",R,V_VN7exwFFmQF0AI9P7FjBljwEFu7QYUGCYE
isAllowedPixelsWide:pixelsHigh:
T@"VNFaceAttributeCategory",R,V_VNpLorzxnyAlLcPFNcKhgoNCmy9b5BRWyk
isEqualToArray:
T@"VNFaceAttributeCategory",R,V_baldCategory
isTitle
T@"VNFaceAttributeCategory",R,V_faceHairCategory
T@"VNFaceAttributeCategory",R,V_glassesCategory
lastTrackedBBox
T@"VNFaceAttributeCategory",R,V_makeupCategory
legacyForcedCleanupWithOptions:
T@"VNFaceAttributeCategory",R,V_makeupLipsCategory
linkTimeVersion
T@"VNFaceAttributes",R,N,V_faceAttributes
lowPriorityCIContextMetalDevice
T@"VNFaceLandmarkRegion2D",R,V_allPoints
manager
T@"VNFaceLandmarkRegion2D",R,V_innerLips
maximumHierarchicalObservations
T@"VNFaceLandmarkRegion2D",R,V_leftEyebrow
modelMinimumDetectionConfidence
T@"VNFaceLandmarkRegion2D",R,V_medianLine
network
T@"VNFaceLandmarkRegion2D",R,V_noseCrest
T@"VNFaceLandmarkRegion2D",R,V_rightEye
normalizedFaceBBoxForLandmarks:
T@"VNFaceLandmarkRegion2D",R,V_rightPupil
numberWithLong:
T@"VNFaceLandmarkRegion3D",R,V_faceContour
observationCountsForAllEntities
T@"VNFaceLandmarkRegion3D",R,V_leftEye
originalCGImage
T@"VNFaceLandmarkRegion3D",R,V_medianLine
performRequests:onImageURL:orientation:gatheredForensics:error:
T@"VNFaceLandmarkRegion3D",R,V_noseCrest
pixelHeightCard
T@"VNFaceLandmarkRegion3D",R,V_rightEye
pixelsWideRange
T@"VNFaceLandmarks2D",&,N,V_landmarks
poseOriginatingRequestSpecifier
T@"VNFaceLandmarks3D",R,N
processImage:withOptions:error:
T@"VNFaceObservation",R,N,V_faceObservation
progressHandler
T@"VNFaceScreenGaze",R,N,V_faceScreenGaze
propertyForKey:
T@"VNFaceTorsoprint",&,N
quality
T@"VNImageRegistrationSignature",&,N,V_referenceImageSignature
read:maxLength:
T@"VNImageprint",&,N,V_imageprint
recordWarnings:
T@"VNMPImageDescriptor",&,N,V_descriptor
releaseQueueWithUniqueAppendix:
T@"VNObservation",&,N,V_originalObservation
request
T@"VNPersonsModelAlgorithm",C,N,V_algorithm
requestPerformerAndReturnError:
T@"VNPersonsModelAlgorithm",R,C,N,V_algorithm
requiredSessionInOptions:error:
T@"VNPixelBufferObservation",R,N,V_gazeMask
results
T@"VNPixelBufferObservation",R,N,V_instanceSegmentationMask
saveAndReturnCurrentModelState:
T@"VNPoint",R
serializeRPNInitializationQueue
T@"VNProcessingDevice",&,N,V_processingDevice
T@"VNProcessingDevice",R
setAnimalprint:
T@"VNRecognizeDocumentElementsRequestElementConfiguration",R
setBox:
T@"VNRecognizeDocumentElementsRequestElementConfiguration",R,V_machineReadableCodeElements
setCustomWords:
T@"VNRecognizedPointsSpecifier",R
setInHierarchy:
T@"VNRequest",R,N,V_parentRequest
setMaxBoxWidth:
T@"VNRequestSpecifier",R
setMinBoxWidth:
T@"VNRequestSpecifier",R,C,V_entityPrintOriginatingRequestSpecifier
setMinimumSize:
T@"VNRequestSpecifier",R,N,V_landmarksOriginatingRequestSpecifier
setNumWarpings:
T@"VNRequestSpecifier",R,V_originatingRequestSpecifier
setNumberStyle:
T@"VNResourceVersion",R,N,V_networkVersion
setStartNormal:
T@"VNSceneObservation",R,&,N
setSymbologies:
T@"VNSizeRange",R,N,V_pixelsWideRange
setTextObjects:
T@"VNSupportedImageSize",C,N
setWithObjects:
T@"VNTensorDescriptor",R,N,V_confidencesOutput
smilingCategory
T@"VNTensorShape",R,N,V_shape
specifiesRequestClass:revision:
T@"VNTorsoprint",R,N,V_torsoprint
strides
T@"VNVideoProcessorCadence",C,V_cadence
stringByAppendingPathExtension:
T@?,R,C,N,V_completionHandler
supportedSymbologiesRev2Private
TB,D,N
textRecognition
TB,N,GisLastFrame,V_lastFrame
trackID
TB,N,V_cropResult
unload:
TB,N,V_detectionOnly
validateAsyncStatusState:error:
TB,N,V_detectsDarkOnLight
version
TB,N,V_faceCoreExtractBlink
vn_encodeValidatedScore:forKey:
TB,N,V_forceFaceprintCreation
TB,N,V_inHierarchy
TB,N,V_isTitle
TB,N,V_isValid
TB,N,V_keepRawOutputMask
TB,N,V_minimizeFalseDetections
TB,N,V_performBlinkDetection
TB,N,V_performInPlace
TB,N,V_preferBackgroundProcessing
TB,N,V_refineLeftEyeRegion
TB,N,V_refineMouthRegion
TB,N,V_refineRightEyeRegion
TB,N,V_reportCharacterBoxes
TB,N,V_returnAllResults
TB,N,V_returnMask
TB,N,V_shouldUpdateRepresentative
TB,N,V_stopAtFirstPyramidWith2DCode
TB,N,V_upperBodyOnly
TB,N,V_useCenterTileOnly
TB,N,V_useMLDetector
TB,N,V_useNonLocalRegularization
TB,N,V_useTiling
TB,N,V_usesAlternateLineGrouping
TB,N,V_usesLanguageCorrection
TB,R
TB,R,D
TB,R,D,N
TB,R,GisReadOnly,V_readOnly
TB,R,N
TB,R,N,GisBoundingBoxAligned,V_boundingBoxAligned
TB,R,N,GisOrientationAgnostic,V_orientationAgnostic
TB,R,N,GisReadOnly,V_readOnly
TB,R,N,GisValidFaceprint
TB,R,N,GisValidTorsoprint
TB,R,N,V_completed
TB,R,N,V_imageprintValid
TB,R,N,V_upperBodyOnly
TB,R,V_logEnabled
TB,R,Vindeterminate
TB,V_computeZCVectorHighProbability
TB,V_debugMatlab
TB,V_debugOut
TB,V_forceFaceprintCreation
TB,V_freeImageInDealloc
TB,V_freeNodeOnDealloc
TB,V_generateSegmentationMask
TB,V_performClustersPostprocessing
TB,V_readOnly
TB,V_recognize
TB,V_useImageAnalyzerScaling
TB,V_useTimestampAdjustedDistances
TC,R,D,N
TC,V_profileNormal
TI,N
TI,N,V_outputPixelFormat
TI,R
TI,R,D
TI,R,N,V_idealImageFormat
TI,R,N,V_idealOrientation
TI,R,N,V_major
TI,R,N,V_micro
TI,R,N,V_minor
TI,R,N,V_pixelFormatType
TI,R,V_inputImageFormat
TI,V_maxBoxWidth
TI,V_maxHeight
TI,V_minBoxWidth
TI,V_minHeight
TI,V_pixelHeightCard
TI,V_pixelWidthCard
TI,V_platform
TI,V_profile
TI,V_startMaxFind
TI,V_startNormal
TI,V_startSensitized
TI,V_stopMaxFind
TI,V_stopSensitized
TI,V_trackedFrameCVPixelBufferFormat
TI,VallocationSize
TQ,N
TQ,N,V_algorithm
TQ,N,V_blurDeterminationMethod
TQ,N,V_clusterId
TQ,N,V_constellation
TQ,N,V_detectionLevel
TQ,N,V_faceCoreType
TQ,N,V_faceId
TQ,N,V_imageCropAndScaleOption
TQ,N,V_imageSignatureHashType
TQ,N,V_imageSignatureprintType
TQ,N,V_landmarksConstellation
TQ,N,V_maximumCandidateCount
TQ,N,V_maximumHierarchicalObservations
TQ,N,V_maximumImageDimension
TQ,N,V_maximumIntermediateSideLength
TQ,N,V_maximumLeafObservations
TQ,N,V_maximumObservations
TQ,N,V_maximumProcessingDimensionOnTheLongSide
TQ,N,V_memoryPoolId
TQ,N,V_metalContextPriority
TQ,N,V_minimumCharacterPixelHeight
TQ,N,V_modelFileBackingStore
TQ,N,V_qualityLevel
TQ,N,V_requestRevision
TQ,N,V_requiredVersion
TQ,N,V_resolvedRevision
TQ,N,V_torsoprintRequestRevision
TQ,N,V_totalObjectCount
TQ,N,V_trackingLevel
TQ,N,V_type
TQ,N,V_version
TQ,R
TQ,R,D
TQ,R,N
TQ,R,N,V_aspectRatioHandling
TQ,R,N,V_backingStore
TQ,R,N,V_bytesPerRow
TQ,R,N,V_confidenceScoreType
TQ,R,N,V_dataType
TQ,R,N,V_faceprintRequestRevision
TQ,R,N,V_idealDimension
TQ,R,N,V_imageSignatureprintType
TQ,R,N,V_inputImageAspectRatioHandling
TQ,R,N,V_maximumDimension
TQ,R,N,V_minimumDimension
TQ,R,N,V_networkRequiredInputImageHeight
TQ,R,N,V_networkRequiredInputImageWidth
TQ,R,N,V_numberOfFaceSegments
TQ,R,N,V_originalRequestResultsIndex
TQ,R,N,V_outputBufferHeight
TQ,R,N,V_outputBufferWidth
TQ,R,N,V_pixelHeight
TQ,R,N,V_pixelWidth
TQ,R,N,V_preferredSmallSide
TQ,R,N,V_profile
TQ,R,N,V_requestRevision
TQ,R,N,V_trackDuration
TQ,R,N,V_version
TQ,R,V_constellation
TQ,R,V_elementCount
TQ,R,V_imageSignatureHashType
TQ,R,V_imageSignatureprintType
TQ,R,V_inputImageHeight
TQ,R,V_inputImageWidth
TQ,R,V_pointCount
TQ,R,V_scenePrintRevision
TQ,R,V_topLevelIndex
TQ,R,V_version
TQ,V_imageCropAndScaleOption
TQ,V_maximumHandCount
TQ,V_version
TS,VfilterWalkUpDownCount
TS,VmedianHeightBottom
TS,VmedianHeightTop
T^Q,VcharBoxFlags
T^S,VcharboxROIFullVectorHeight2
T^S,VcharboxROIFullVectorRowStart
T^f,VfloatVectorSumProd
T^v,R
T^v,R,V_colorGaborDescriptor
T^v,R,V_imageRegistrationDescriptor
T^v,R,V_plan
T^v,R,V_sceneClassifierDescriptor
T^v,V_node
T^{__CVBuffer=},R,N,V_pixelBuffer
T^{__CVBuffer=},R,V_imageCVPixelBuffer
T^{__sFILE=*iiss{__sbuf=*i}i^v^?^?^?^?{__sbuf=*i}^{__sFILEX}i[3C][1C]{__sbuf=*i}iq},R,N
T^{vImage_Buffer=^vQQQ},R,V_image
Td,N
Td,N,V_angle
Td,N,V_detectorExecutionTimeInterval
Td,R
Td,R,N,V_faceAngle
Td,R,N,V_faceSize
Td,R,N,V_movingAverageRadius
Td,R,V_radius
Td,R,V_timeInterval
Td,R,V_x
Td,R,V_y
Tf,N
Tf,N,V_alignedRotationAngle
Tf,N,V_confidence
Tf,N,V_contrastAdjustment
Tf,N,V_faceCoreKalmanFilter
Tf,N,V_faceIdConfidence
Tf,N,V_gazeHeatMapThreshold
Tf,N,V_maximumAspectRatio
Tf,N,V_minimumAspectRatio
Tf,N,V_minimumConfidence
Tf,N,V_minimumFaceDimension
Tf,N,V_minimumSize
Tf,N,V_minimumTextHeight
Tf,N,V_nlreg_sigma_c
Tf,N,V_nlreg_sigma_l
Tf,N,V_nlreg_sigma_w
Tf,N,V_nmsThreshold
Tf,N,V_objectMaximumNormalizedRadius
Tf,N,V_objectMinimumNormalizedRadius
Tf,N,V_olmcsThreshold
Tf,N,V_osfsSizeRatio
Tf,N,V_osfsThreshold
Tf,N,V_pitchAngle
Tf,N,V_quadratureTolerance
Tf,N,V_rotationAngle
Tf,N,V_smartDistanceFactor
Tf,N,V_smartThreshold
Tf,N,V_threshold
Tf,N,V_torsoThreshold
Tf,R
Tf,R,D
Tf,R,N
Tf,R,N,GfaceJunkinessIndex
Tf,R,N,GfaceOrientationIndex
Tf,R,N,V_aestheticScore
Tf,R,N,V_confidence
Tf,R,N,V_failureScore
Tf,R,N,V_harmoniousColorScore
Tf,R,N,V_immersivenessScore
Tf,R,N,V_interestingSubjectScore
Tf,R,N,V_intrusiveObjectPresenceScore
Tf,R,N,V_livelyColorScore
Tf,R,N,V_lowKeyLightingScore
Tf,R,N,V_noiseScore
Tf,R,N,V_pleasantCameraTiltScore
Tf,R,N,V_pleasantCompositionScore
Tf,R,N,V_pleasantLightingScore
Tf,R,N,V_pleasantPatternScore
Tf,R,N,V_pleasantPerspectiveScore
Tf,R,N,V_pleasantPostProcessingScore
Tf,R,N,V_pleasantReflectionsScore
Tf,R,N,V_pleasantSymmetryScore
Tf,R,N,V_sharplyFocusedSubjectScore
Tf,R,N,V_wellChosenBackgroundScore
Tf,R,N,V_wellTimedShotScore
Tf,R,V_aspectRatio
Tf,R,V_confidence
Tf,R,V_quality
Tf,V_inliersRatioThreshold
Tf,V_mmHeightCard
Tf,V_mmWidthCard
Tf,V_modelMinimumDetectionConfidence
Tf,V_modelNonMaximumSuppressionThreshold
Tf,V_naturalClusteringDistanceThreshold
Tf,V_nextLeafTotalDistance
Tf,V_previousLeafDescriptorDistance
Tf,V_previousLeafTotalDistance
Tf,V_roiAreaThreshold
Tf,V_rotationAngle
Tf,V_yawAngle
Tf,VbBottom
Tf,VbTop
Tf,VmBottom
Tf,VmTop
Tf,VposLL
Tf,VposLR
Tf,VposUL
Tf,VposUR
Ti,N,V_label
Ti,N,V_mergesCount
Ti,N,V_nlreg_padding
Ti,N,V_nlreg_radius
Ti,N,V_numWarpings
Ti,N,V_olmcsMergeCountDelta
Ti,N,V_scale
Ti,R,N,V_levelCount
Ti,R,N,V_numScales
Ti,R,N,V_width
Ti,V_clusterSplitDistanceType
Ti,V_debugMode
Ti,V_labelKey
Ti,V_midRow
Ti,V_modelType
Ti,V_numberOfKeypointsToConsider
Ti,V_timerMode
Tq,N
Tq,N,V_qualityLevel
Tq,N,V_recognitionLevel
Tq,N,V_temporalSmoothingFrameCount
Tq,N,V_trajectoryLength
Tq,R
Tq,R,D
Tq,R,N,V_direction
Tq,R,N,V_pointsClassification
Tq,R,N,V_trackID
Tq,R,V_descriptorId
Tq,R,V_exifTimestamp
Tq,R,V_frameRate
Tq,R,V_inputScenePrintMLMultiArrayDataType
Tq,R,V_internalNonSerializedDescriptorId
Tq,V_indexType
Tq,V_nextLeafTimestampDistance
Tq,V_previousLeafId
Tq,V_previousLeafTimestampDistance
Tq,V_trackedFrameNumber
Tr^,R
Tr^,R,V_points
Tr^,V_points
Tr^Q,R,N
Tr^v,R
Tr^v,R,D
Tr^v,R,N
Tr^v,R,V_espressoMaskOutputBufferSizes
Tr^v,R,V_espressoMaskOutputBuffers
Tr^{BufferSize=QQ},R
Tr^{CGPath=},R
Tr^{CGPoint=dd},R
Tr^{FastRegistration_Signatures=^fQ{Projections_meanStdTable=^f^f}^fQ{Projections_meanStdTable=^f^f}*},R
Tr^{__MRCDescriptor=},N,SsetMRCDescriptor:,V_mrcDescriptor
Ts,VloopBigBox
Ts,VloopBigBoxPrev
T{?=[3]},N,V_warpTransform
T{?=[4]},R,N
T{?=^vi},R,V_network
T{?=qiIq},N
T{?=qiIq},N,V_targetFrameTime
T{?=qiIq},R
T{?=qiIq},V_frameAnalysisSpacing
T{?={?=qiIq}{?=qiIq}},N,V_timeRange
T{?=},R,N
T{BufferSize=QQ},R,N
T{CGAffineTransform=dddddd},N
T{CGAffineTransform=dddddd},N,V_alignmentTransform
T{CGAffineTransform=dddddd},N,V_transform
T{CGPoint=dd},N,V_inputPoint
T{CGPoint=dd},R,N
T{CGPoint=dd},R,N,V_bottomLeft
T{CGPoint=dd},R,N,V_faceCenter
T{CGPoint=dd},R,N,V_leftEye
T{CGPoint=dd},R,N,V_location
T{CGPoint=dd},R,N,V_mouth
T{CGPoint=dd},R,N,V_rightEye
T{CGPoint=dd},R,N,V_topLeft
T{CGPoint=dd},R,N,V_topRight
T{CGRect={CGPoint=dd}{CGSize=dd}},N
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_boundingBox
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_box
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_defaultBox
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_regionOfInterest
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,V_boundingBox
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,V_croppedBoundingBox
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,V_faceBoundingBox
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,V_unalignedBoundingBox
T{CGRect={CGPoint=dd}{CGSize=dd}},R,V_faceBoundingBox
T{CGRect={CGPoint=dd}{CGSize=dd}},R,V_userFacingBBox
T{CGRect={CGPoint=dd}{CGSize=dd}},V_bounds
T{CGRect={CGPoint=dd}{CGSize=dd}},V_lastTrackedBBox
T{CGSize=dd},N,V_trackingFrameSizeInPixels
T{CGSize=dd},R
T{CGSize=dd},R,D
T{_Geometry2D_rect2D_={_Geometry2D_point2D_=ff}{_Geometry2D_size2D_=ff}},N,V_alignedBoundingBox
T{_Geometry2D_rect2D_={_Geometry2D_point2D_=ff}{_Geometry2D_size2D_=ff}},R,V_alignedBBox
T{tuple<float, float, float>={__tuple_impl<std::__tuple_indices<0, 1, 2>, float, float, float>=fff}},R
UID_counter
URLByAppendingPathComponent:
URLForIdentifier:error:
URLForResource:withExtension:
UTF8String
UUID
UUIDString
VN1uMyFtnYEWjbrdx3yAuDndKkPeyzNJhB
VN2riiZbQrloRhCzYW56f0rk4N3ROe151S
VN3iT1YRjjnIuELobV1olJiO1vvItN6Kdq
VN4UfLbvVUqMvYV8bbGFQcxg5yRLm8ekI1
VN7CbCeAogPS2iHE6VQwu6H96xanljtMqk
VN7exwFFmQF0AI9P7FjBljwEFu7QYUGCYE
VN7fiLHgGnvqPqG63cfDUCK4Xm8obUuWoP
VNAssert:log:
VNClassCode
VNEntityIdentificationModelPrintByteLength
VNEntityIdentificationModelPrintData
VNEntityIdentificationModelPrintElementCount
VNEntityIdentificationModelPrintElementType
VNEntityIdentificationModelPrintOriginatingRequestSpecifier
VNEntityIdentificationModelPrintWithOriginatingRequestSpecifier:error:
VNObservationsWithOriginatingRequestSpecifier:
VNPersonsModelFaceprintWithRequestRevision:error:
VNPersonsModelSubdataWithRange:rangeDescription:error:
VNPersonsModelSubdataWithRange:rangeDescriptionProvidingBlock:error:
VNTrackerOptionToTrackerType:
VNpLorzxnyAlLcPFNcKhgoNCmy9b5BRWyk
_ACBarcodeRecognizerLocateMode
_Adiagb_buf
_C0_pxbuf
_C1_pxbuf
_G0_pxbuf
_G1_pxbuf
_I_tex
_I_u32_alias_tex
_Ixy_buf
_MRCLocateMode
_VN1uMyFtnYEWjbrdx3yAuDndKkPeyzNJhB
_VN2riiZbQrloRhCzYW56f0rk4N3ROe151S
_VN3iT1YRjjnIuELobV1olJiO1vvItN6Kdq
_VN4UfLbvVUqMvYV8bbGFQcxg5yRLm8ekI1
_VN5kJNH3eYuyaLxNpZr5Z7ziCustomClassifiers
_VN7CbCeAogPS2iHE6VQwu6H96xanljtMqk
_VN7exwFFmQF0AI9P7FjBljwEFu7QYUGCYE
_VN7fiLHgGnvqPqG63cfDUCK4Xm8obUuWoP
_VNEspressoModelImageprintSerializedLength
_VNPointsFromCGPoints:
_VNVYvzEtX1JlUdu8xx5qhDICustomClassifiers
_VNpLorzxnyAlLcPFNcKhgoNCmy9b5BRWyk
_absoluteDiffFilter
_acbsBarcodeInfo
_acceptableVersions
_accessToMutableFaceObservationsForPersonAtIndex:
_actualSizeForDesiredSize:ofSourceImageWidth:height:
_addFaceAnalysisResultsFromMap:toFaceAttributeObject:forOriginatingRequestSpecifier:
_addPointsOfNamedRegion:inLandmarks:toPath:applyingAffineTransform:
_addRelationships:error:
_addUniqueFaceObservations:toPersonWithUniqueIdentifier:error:
_additionalCharacters
_additionalRelationships
_adjustments
_ageCategory
_ageClassifierBabyThreshold
_ageClassifierFilePath
_ageClassifierKidThreshold
_algorithm
_algorithmType
_alignFace:imageBuffer:qosClass:warningRecorder:error:
_alignFacesInContext:faces:qosClass:options:error:
_alignedBBox
_alignedBoundingBox
_alignedMeanShape
_alignedRotationAngle
_alignmentTransform
_allBarcodeSymbologiesRev1
_allBarcodeSymbologiesRev2
_allBarcodeSymbologiesRev2Private
_allClassificationIdentifiers
_allLabelsWithConfidences
_allPoints
_allPointsLock
_allPropertyNames
_allRecognizedPoints
_allocateCRCharBoxContext:
_allocateSumDerivVectors:size:
_allocateVImageWithWidth:height:rowBytes:imageOut:
_alternatePathForEspressoResource:ofType:error:
_analysisSemaphore
_analysisSession
_analyzePixelBuffer:options:error:
_angle
_animalprint
_applyMaskComputeState
_area
_aspectRatio
_aspectRatioHandling
_assembleConstraintsState
_asyncStatus
_asyncStatusLock
_attributedString
_automaticallyDetectsLanguage
_availablePersonSerialNumbers
_availableSerialNumbers
_backingStore
_baldCategory
_barcodeDescriptor
_barcodesDetectedInImageBuffer:usingACBSConfig:originatingRequestSpecifier:error:
_baselines
_bindBuffer:toNetworkBlobName:bindMode:error:
_bindPixelBufferToTexture:error:
_blacklistedIdentifiers
_blinkScore
_blurDeterminationMethod
_blurScore
_booleanBytesData_DO_NOT_DIRECTLY_ACCESS
_bottomLeft
_bottomRight
_boundingBox
_boundingBoxAligned
_boundingBoxGenerator
_boundingBoxOutputDescription
_box
_boxesBuffer
_buildCalibrationMatrix:calibrationMatrix:error:
_bytesPerRow
_cacheDirectoryPath
_cacheFolderPath
_cachePath
_cachedAllSceneClassificationsFromLastAnalysis
_cachedAllSceneClassificationsFromLastAnalysisAccessLock
_cachedCalculatedHash
_cachedDependencyProcessingOrdinality
_cachedDetectorOfClass:configuredWithOptions:
_cachedFloatingImageBuffer
_cachedFloatingImageSignature
_cachedHashValue
_cachedLandmarks
_cachedLandmarks3d
_cachedLandmarks3dLock
_cachedLandmarks65
_cachedLandmarks65Lock
_cachedLandmarksLock
_cachedMetalDeviceWisdomParametersAndReturnError:
_cachedPayloadDataValue
_cachedPayloadStringValue
_cachedPersonUniqueIdentifierToFaceprintCountMapping
_cachedRequestClass
_cachedRequestClassName
_cachedRequestResults
_cachedSaliencyHeatmapBoundingBoxGenerators
_cachedSupportedClassificationIdentifiers
_cachedTrackerResourcesConfiguredWithOptions:
_cadence
_calculateHomographicWarpTransform:ofFloatingImagePixelBuffer:ontoReferenceImagePixelBuffer:usingImageRegistrationContext:seededWithPreviousWarpTransform:error:
_calculateImageSignatureHashDescriptorFrom:options:error:
_calculateImageSignatureprintDescriptorFromOptions:error:
_calculateNumberOfTilesForNetworkInputImageSize:networkInputMaskSize:networkOutputMaskSize:rotated:
_calculateProbabilityNormalSumsForRect:
_calculateTorsoBBoxFromFaceBBox:insideImageWithSize:faceOrientationRelativeToUpright:torsoBBox:error:
_calculatedStorageByteCount
_cancellableUpdate:facesToMove:requestRevision:
_cancellationQueue
_cancellationResourcesLock
_cancellationSemaphore
_cancellationTriggered
_canceller
_cascadeStepCount
_checkInitInputs:cachePath:checkType:requestRevision:error:
_checkedCachedResultsOnBehalfOfRequest
_childRequestsImplicitlyPerformedOnBehalfOfParentRequest:
_chirality
_ciContext
_ciContextManager
_ciContrastFromAvgFilter
_ciContrastWithPivotFilter
_cityNatureGatingCustomClassifiers
_classifyAesthetics:generateSaliencyHeatMap:for32BGRAImageInPixelBuffer:withOptions:modelInputImageSize:originalImageSize:regionOfInterest:warningRecorder:error:
_clusterId
_clusterSplitDistanceType
_clusterState
_clusteredFaceIds
_clusterer
_clusteringLogger
_clusters
_colorGaborDescriptor
_commandQueue
_commonGazeLocationRadius
_completed
_completionHandler
_compressedPoints
_computationAccuracy
_computeBoundingBoxes
_computeColumnSumsOverRange:sampleImageAddress:rowSumOut:rowDerivOut:
_computeFeaturesDerivativesWithCommandBuffer:in_tex:out_tex:
_computeFeaturesWithCommandBuffer:in_tex:out_tex:
_computeLabel
_computeOpticalFlow
_computePipelines
_computeProdBoostNormalizedResult:size:binOverride:
_concatenateFaceprintImageDescriptorBuffer:withFaceprints:forIdentityWithSerialNumber:faceprintLabels:
_confidence
_confidenceScoreType
_confidencesBuffer
_confidencesOutput
_configuration
_configurationOptions
_configureVNProcessingDescriptorIdentifierSceneNetV3DetectorConfigurationOptions:
_configureVNProcessingDescriptorIdentifierSceneNetV3_ObjDetNet_SliderNetDetectorConfigurationOptions:
_constellation
_context
_contextsLock
_contourChildrenIndices
_contourPoints
_contrastAdjustment
_contrastPivot
_convertCornerObservationsToRectangleObservation:error:
_convertOptionsToFaceCoreDetectOptions:
_convertOptionsToFaceCoreExtractOptions:
_convertOptionsToFaceCoreSetupOptions:
_convertVNOptionsToFaceCoreDetectOptions:
_convertVNOptionsToFaceCoreExtractOptions:
_convertVNOptionsToFaceCoreOptions:optionsMap:
_convertVNOptionsToFaceCoreSetupOptions:
_copyCropComputeState
_cornerTrackersImpl
_cpuContextsHandler
_crOutput
_createACBSConfigAndReturnError:
_createCroppedAndScaledBufferFromVNImageBuffer:regionOfInterest:withOptions:error:
_createFaceLandmarks2DRegionOfPoints:fromPointIndexes:andPointCount:
_createFaceSegmentProabilityDataPixelBufferWithSize:error:
_createGeneratorOptionsForRequestRevision:session:images:previousTargetImageIsCurrentRefImage:previousObservation:
_createGreedyClusterer:state:error:
_createHomographicPixelBufferFromImageBuffer:cropRect:options:error:
_createImagePyramidWithCommandBuffer:in_pixelbuf:I_idx:error:
_createMRCDecoderOptionsForRevision:error:
_createN:CVPixelBuffers:withPixelFormat:width:height:error:
_createNSArrayFrom:withPointIndices:andPointCount:
_createPixelBufferFromImageBuffer:regionOfInterest:maximumIntermediateSideLength:options:error:
_createPointArray:count:
_createScaledImagePixelBufferFromCropRect:ofImageBuffer:inPixelFormat:forDetectorInputImageSize:usingAnisotropicScaling:error:
_createScaledImagePixelBufferFromImageBuffer:inPixelFormat:forDetectorInputImageSize:usingAnisotropicScaling:error:
_createTileWithScaleComputePipelineState
_createTracker:type:options:error:
_createTrackerWithLevel:options:error:
_createVCPVideoProcessorRequestConfiguration
_cropCIImage:outBuffer:width:height:format:cropRect:performCrop:options:rotate90CCW:error:
_cropCVPixelBuffer:outBuffer:width:height:format:cropRect:performCrop:options:rotate90CCW:error:
_cropImageSourceManager:outBuffer:width:height:format:cropRect:performCrop:options:rotate90CCW:error:
_cropResult
_croppedBoundingBox
_currentFrame
_currentImageHeight
_currentImageWidth
_currentNetworkHeight
_currentNetworkWidth
_current_frame_index
_customHierarchy
_customWords
_cvPixelBufferPoolManager
_dataSource
_dataSource_DO_NOT_ACCESS_DIRECTLY
_dataType
_deallocateBuffer
_debugFilename
_debugMatlab
_debugMode
_debugOut
_defaultBox
_defaultBoxSizes
_defaultProcessingDevice
_defaultRevisionForBuildVersion:
_defaultSceneClassificationHierarchicalModel
_delegate
_delegateFlags
_delegate_DO_NOT_ACCESS_DIRECTLY
_descriptor
_descriptorId
_descriptorIdentifier
_descriptorIdentifierToVersionsArray
_descriptorVersion
_detectContoursRequest
_detectCreditCardTextWithRequestPerformingContext:requestRevision:error:
_detectDiacritics
_detectFacesInImage:error:
_detectOptions
_detectTextWithRequestPerformingContext:requestRevision:error:
_detectedBarcodeSupportCode
_detectedObjectObservationsForRegionOfInterestContainingDetectedObjectObservations:relationWithRegionOfInterest:
_detectionOnly
_detectionprintTensorForOutputBuffer:originatingRequestSpecifier:error:
_detector
_detectorAccessingLock
_detectorCache_onlyAccessWithDetectorAccessingLock
_detectorClass
_detectorConfigurationOptions
_detectorDescriptorIdentifierVersionTuples
_detectorExecutionTimeInterval
_detectorModel
_detectorPreferredImageSize
_detectorType
_detectorTypesForIdentifier:
_detectorWantsAnisotropicScaling
_detectors
_detectsDarkOnLight
_determineAnimalsToProcessFrom:outputAnimalsThatNeedNoProcessing:outputAnimalsThatNeedAnimalprints:
_dilateFilter
_dilateRadius
_direction
_distance
_distancesById
_doNLRegularizationWithCommandBuffer:in_uv_tex:join_tex:w_tex:out_uv_tex:
_doSolverWithCommandBuffer:scale:scale_xy_inv:coeff:in_uv_tex:out_uv_tex:out_w_tex:
_documentElements
_documentIdentifierToSceneLabels
_downscale2XWithCommandBuffer:in_u32_alias_tex:out_u32_alias_tex:
_dumpIntermediatesFullImage:imageURL:requiredImageSource:imageProcessingType:error:
_dumpIntermediatesTiles:imageURL:requiredImageSource:imageProcessingType:allocatedTileCount:imageTiles:bytesPerPixel:numTiles:scaleFactor:augmentationMode:scalingImage:error:
_elementCount
_elementType
_entityIdentificationModel
_entityPrintCounts
_entityPrintOriginatingRequestSpecifier
_entityUniqueIdentifier
_entityUniqueIdentifiers
_equationCoefficients
_error
_espressoConfidencesOutputBuffer
_espressoContext
_espressoInputImageSize
_espressoInputMaskSize
_espressoMaskInputBufferSize
_espressoMaskOutputBufferSizes
_espressoMaskOutputBuffers
_espressoNetwork
_espressoPlan
_espressoResources
_executionNanoseconds
_exifOrientationFromFaceRollAngle:exifOrientation:error:
_exifTimestamp
_explicitlySetMaximumTrainingFaceprintsPerIdentity
_exposureScore
_expressionsAndScores
_externalImageId
_extractCharBoxCuts:heightConstraint:medianHeightTopVector:medianHeightBottomVector:isAdaptive:
_extrema
_extremeValues
_eyesCategory
_faceAngle
_faceAttributesPupilRefiner
_faceBBoxAligner
_faceBoundingBox
_faceBoundingBoxExpansionRatio
_faceCaptureQuality
_faceCenter
_faceContour
_faceContourLock
_faceCoreEnhanceEyesAndMouthLocalization
_faceCoreExtractBlink
_faceCoreExtractSmile
_faceCoreInitialAngle
_faceCoreKalmanFilter
_faceCoreMinFaceSize
_faceCoreNumberOfDetectionAngles
_faceCoreType
_faceDetector
_faceHairCategory
_faceIDModel
_faceIdConfidence
_faceJunkinessIndex
_faceModel_DO_NOT_ACCESS_DIRECTLY
_faceObjectStates
_faceObservation
_faceObservationUUID
_faceOrientationIndex
_faceRegionMap
_faceSegmentLabelToProbabilityMap
_faceSegmenterDNN
_faceSegmenterMaximumInputImageAspectRatio
_faceSegments
_faceSize
_facemaskCategory
_faceprint
_faceprintInputPath
_faceprintOutput
_faceprintRequestRevision
_faceprintRevision
_failureScore
_featureName
_featureProvider
_featureValue
_features
_fileNameBase
_fillFaceSegmentLabelToProbabilityMap:error:
_filterThresholds
_fingerprintHashes
_floatingImageSignature
_flushMetalDeviceWisdomParametersCache
_forceFaceprintCreation
_forceUseInputCVPixelBufferDirectly
_forestAlgoParams
_frameAnalysisSpacing
_frameIndex
_frameRate
_frameworkBundle
_frameworkManager
_frameworkOperationPointsIdentifier
_freeCRCharBoxContext
_freeContexts
_freeImageInDealloc
_freeNodeOnDealloc
_freeSumDerivVectors:
_freeVImage:
_futharkRecognitionLanguage
_gaze
_gazeFollowPredictor
_gazeHeatMapThreshold
_gazeMask
_gazePredictor
_generalConfigurations
_generateAdaptiveBinarization:adaptImage:useLowLightEnhancement:
_generateAndApplyColorProfileForImage:votingImage:textOut:minMaxRGB:lowHighRGB:numCropRows:rowStartLocation:rowStopLocation:sumTextOutFirstPass:useLowLightEnhancement:
_generateBinarizationForImage:textOut:firstOrSecondPassIndicator:minMaxRGB:
_generateBoxes:pulseVector:uImage:countBigBoxOut:bigBoxes:bigBoxesA:useLowLightEnhancement:
_generateCC:ccBigBoxes:textOut:countBigBox:bufferHeight:
_generateCRCharBoxInformation:inputImage:singleVotingImageAddressRef:bigBoxes:bigBoxesAdapt:textOut:adaptOut:lowHighRGB:countBigBox:useLowLightEnhancement:
_generateCRCharBoxInformation_TrackBox:finalCharBoxCoordCount:
_generateCRCharBoxInformation_extendTextBoxes:countBigBox:rowStartLocation2:finalCharBoxCoordCount:finalCoordinatesForStubRevised:width:height:bigBoxIndicator:
_generateCRCharBoxInformation_spaceBoxRemovalHistogram:zcStartLeft:zcStopRight:rowStartLocation2:lowHighRGB:histCompliancePercent:varSpaceBox:
_generateCRCharBoxInformation_spaceBoxRemovalMagicThresh:magicMinHeight:magicMaxHeight:rowStartLocation2:magicThresh:magicThreshPrev:useLowLightEnhancement:
_generateCRCharBoxInformation_spaceBoxRemovalTightenBox:singleVotingImageAddressRef:adaptOut:textOut:zcStartLeft:zcStopRight:finalCoordinatesForStub:finalCoordinatesForStubRevised:finalCharBoxCoordCount:useLowLightEnhancement:
_generateCRCharBoxInformation_spaceBoxRemovalTruthFilter:magicThresh:zcStartLeft:zcStopRight:isSpaceBoxAccepted:histCompliancePercent:useLowLightEnhancement:
_generateCRCharBoxInformation_zcFinalVectorFillIn:
_generateCRCharBoxInformation_zcFinalVectorHighProbability:zcFinalRange:
_generateCRCharBoxInformation_zcFinalVectorOriginate:textOut:adaptOut:bigBoxes:bigBoxesAdapt:ccCharBoxesAggr:ccCharBoxesFiltered:height:rowStartLocation2:rowStopLocation2:singleVotingImageAddressRef:countBigBox:filterWalkUpDownCount:useLowLightEnhancement:
_generateFilteredPulseVector:target:height:
_generatePulseAggregate:pulseVectorMain:pulseVectorResult:metricSelection:bufferHeight:bufferWidth:
_generatePulseAggregateSmallStubs:pulseVectorResult:bufferHeight:bufferWidth:
_generatePulseVectorOutputs:votingImage:rowLocationsRef:
_generateSegmentationMask
_generateSmoothedImage:uImage:
_generateVotingImage:votingImage:useLowLightEnhancement:
_generateZeroCrossingVector:zcVectorFlag:width:
_getAnalyzerName:version:forModel:configuredWithOptions:error:
_getCornerPointsFromCodeLocationPoints:bottomLeft:topLeft:topRight:bottomRight:
_getFaceSegmenterInputImageSize:forRequestRevision:error:
_getFilterResultOut:defaultRows:bufferHeight:minHeight:maxHeight:startRange:stopRange:startMaxFind:stopMaxFind:bytesPerRow:thresholdSet:sampleImageAddressRef:sampleImageFloatAddressRef:pulseVectorFlag:
_getFilterResultOutBothSumDeriv:floatVectorResult:bufferHeight:minHeight:maxHeight:config:bytesPerRow:thresholdSet:sampleImageAddressRef:
_getFilter_callCount
_getModelWritingImplementation:selector:version:forOptions:
_getNumberOfSupportedFaceSegments:forRequestRevision:error:
_getOrientationLock
_getSerialNumber:forPersonUniqueIdentifier:error:
_getTracker:
_glassesCategory
_globalSegmentationMask
_gpuContextsHandlers
_gpuHandlersLock
_groupOrderedRequests:ordinality:ordinalityAndPriorityGroups:
_groupedClusteredFaceIdsForCluster
_groupingConfiguration
_groupingConfigurations
_groupsRequestsWithTheSameOrdinality:priorityGroup1:priorityGroup2:
_guidedFilter
_hairColorCategory
_handler
_harmoniousColorScore
_hasLabel
_hashData_DO_NOT_DIRECTLY_ACCESS
_hasherInitialized
_helpReadOrientationFromOptionsDictionary:
_hierarchicalModel_DO_NOT_ACCESS_DIRECTLY
_humanPoseDetector
_humanReadableLabelForRequest:
_hyperplaneLSHProcessor
_idealImageFormat
_idealOrientation
_identifier
_identifiers
_image
_imageAnalyzer
_imageAnalyzerJunkCustomClassifiers
_imageAnalyzerPCA256
_imageBuffer
_imageBuffer_DO_NOT_DIRECTLY_ACCESS
_imageCVPixelBuffer
_imageCropAndScaleOption
_imageData
_imageFilePath
_imageHeight
_imageInputKey
_imageNeuralHashprint
_imageReader
_imageReaderInitializationOptionsForCreationOptions:error:
_imageRegistrationDescriptor
_imageRotationSession
_imageRotationSessionsHandler
_imageSignatureHash
_imageSignatureHashType
_imageSignatureprint
_imageSignatureprintType
_imageSize
_imageSourceManager
_imageSourceSubsample1
_imageSourceSubsample2
_imageSourceSubsample4
_imageSourceSubsample8
_imageURL
_imageWidth
_imageprint
_imageprintDescriptor
_imageprintValid
_imageprintVersion
_immersivenessScore
_implicitRequests
_inHierarchy
_inUseContexts
_indexPath
_indexType
_initLocks
_initMemory:height:numScales:
_initWithClassKeyMappedCoder:
_initializeGreedyClustererOptions:
_initializePolygonContainers
_inliersRatioThreshold
_innerLips
_innerLipsLock
_inputContrast
_inputDetectedObjectObservations
_inputFaceObservations
_inputFactor1
_inputFactor2
_inputFactor3
_inputFactor4
_inputImage
_inputImageAspectRatioHandling
_inputImageBlobNameForModel:configuredWithOptions:
_inputImageFormat
_inputImageHeight
_inputImageKey
_inputImageWidth
_inputImages
_inputObservation
_inputPivot
_inputPixelFormat
_inputPoint
_inputScenePrintKey
_inputScenePrintMLMultiArrayDataType
_inputSignatureprint
_instanceSegmentationMask
_interestingSubjectScore
_internalAlignedBBox
_internalNonSerializedDescriptorId
_internalPerformRevision:inContext:previousObservation:error:
_introspectionBuiltSupportedRevisions
_intrusiveObjectPresenceScore
_iousBuffer
_isBlinking
_isFaceprintJunk:
_isSeparatedString:equalToString:atIndex:usingSeparator:
_isTitle
_isValid
_junkObservationsForLastAnalysisWithOptions:error:
_keepNetworkOutput
_keepRawOutputMask
_key
_kindToOriginalRequestsMapping
_label
_labelKey
_labelToOperationPointsDataIndexMap
_labelsAndConfidence
_landmarkDetector
_landmarkPoints3d
_landmarkPoints65
_landmarkPrecisionEstimatesPerPoint
_landmarkScore
_landmarks
_landmarks3DOriginatingRequestSpecifier
_landmarksConstellation
_landmarksOriginatingRequestSpecifier
_lastAnalyzedFramePTS
_lastDataChangeSequenceNumber
_lastFrame
_lastModificationDate
_lastTrackedBBox
_leftEye
_leftEyeLock
_leftEyebrow
_leftEyebrowLock
_leftPupil
_leftPupilLock
_level
_levelCount
_library
_liveTrackerCounter
_liveTrackerCounterLimit
_livelyColorScore
_loadEspressoModelWithConfigurationOptions:error:
_loadSubSample1Lock
_loadSubSample2Lock
_loadSubSample4Lock
_loadSubSample8Lock
_locateDetectorOfClass:configuredWithOptions:inSessions:excludingSession:
_locateFrameworkBundleForResourceWithName:resourceDirectory:error:
_locateMode
_locateTrackerResourcesConfiguredWithOptions:inSessions:excludingSession:
_locatedCachedResultsOnBehalfOfRequest
_location
_lock
_lockStaticObjectsAccessLock
_logEnabled
_logFileURL
_logFolderURL
_logitsNegOutputs
_logitsPosOutputs
_lookedAtFaceObservationUUID
_lowKeyLightingScore
_mComputeBoundingBoxesLock
_mFaceFrontalizerImpl
_mFaceQualityPredictor
_mHighlySalientRegion
_mMultiHeadedANFDDetector
_mMultiHeadedFaceClassifier
_mOriginalImageSize
_mSalientObjects
_machineReadableCodeElements
_machineReadableCodesDetectedInImageBuffer:originatingRequestSpecifier:inContext:mrcDetector:error:
_major
_makeFaceSegmentProbabilityDataImageBuffer:rect:
_makeupEyesCategory
_makeupLipsCategory
_masksBuffer
_maxBoxWidth
_maxContextsCount
_maxHeight
_maxSessionsCount
_maxThreadExecutionWidth
_maximumAspectRatio
_maximumCandidateCount
_maximumDimension
_maximumElementsPerID
_maximumEntities
_maximumHandCount
_maximumHierarchicalObservations
_maximumIdentities
_maximumImageDimension
_maximumIntermediateSideLength
_maximumLeafObservations
_maximumObservations
_maximumProcessingDimensionOnTheLongSide
_maximumTasksCount
_maximumTrackersOfType:
_medianLine
_memoryPoolId
_mergesCount
_metalContext
_metalContextPriority
_metalDevice
_micro
_minBoxWidth
_minHeight
_minimizeFalseDetections
_minimumAspectRatio
_minimumCharacterPixelHeight
_minimumConfidence
_minimumDimension
_minimumFaceDimension
_minimumSize
_minimumTextHeight
_minor
_mmHeightCard
_mmWidthCard
_model
_modelCachingIdentifier
_modelData
_modelDrop
_modelFileBackingStore
_modelFilesWereMemmapped
_modelMinimumDetectionConfidence
_modelName
_modelNonMaximumSuppressionThreshold
_modelType
_modelWasModified
_mostLikelyLabel
_motionFlowRequest
_mouth
_movingAverageRadius
_mrcContext
_mrcDescriptor
_mtlContext
_name
_naturalClusteringDistanceThreshold
_network
_networkConfigurationName
_networkHeadVersions
_networkHeight
_networkInputImageHeight
_networkInputImageWidth
_networkRequiredInputImageHeight
_networkRequiredInputImageSize
_networkUsesAnisotropicScaling
_networkWidth
_newVNBarcodeSymbologyAztecDescriptorForACBSBarcodeInfo:
_newVNBarcodeSymbologyAztecDescriptorForMRCDescriptor:error:
_newVNBarcodeSymbologyPDF417DescriptorForACBSBarcodeInfo:
_newVNBarcodeSymbologyPDF417DescriptorForMRCDescriptor:error:
_newVNBarcodeSymbologyQRDescriptorForACBSBarcodeInfo:
_newVNBarcodeSymbologyQRDescriptorForMRCDescriptor:error:
_nextFrameToBeAnalyzedPTS
_nextLeafDescriptorDistance
_nextLeafId
_nextLeafTimestampDistance
_nextLeafTotalDistance
_nlreg_padding
_nlreg_radius
_nlreg_sigma_c
_nlreg_sigma_l
_nlreg_sigma_w
_nmsThreshold
_node
_noiseScore
_nonframeworkDataURL
_normalizeRegion:
_nose
_noseCrest
_noseCrestLock
_noseLock
_notificationCenter
_numScales
_numWarpings
_numberOfFaceSegments
_numberOfKeypointsToConsider
_objectMaximumNormalizedRadius
_objectMinimumNormalizedRadius
_objectType
_objects
_observation
_observationGroupsToRequestMapping
_observationsCache
_observationsCacheKey
_observationsCacheKeyForRequest:
_observationsCacheLock
_observationsForImageReaderOutput:requestRevision:error:
_observationsForOneComponent32FloatPixelBuffer:options:regionOfInterest:error:
_observationsForSerialNumber
_observedParabolas
_obtainCreatedCGImageSourceRefAtAddress:forSubSampleFactor:protectedWithUnfairLock:operatingInLowPriority:
_olmcsMergeCountDelta
_operationPoints
_operationPointsCache
_operationPointsDataArray
_operationPointsDataForClassificationIdentifier:error:
_operationPointsProvider
_opticalFlow
_options
_orderedChildRequests
_orderedHandKeypoints
_orderedPersonKeypoints
_orderedRequests
_orientation
_orientationAgnostic
_origCIImage
_origImageHeight
_origPixelBuffer
_origSampleBuffer
_originalObservation
_originalRequestConfigurations
_originalRequestResultsIndex
_originalRequests
_originatingRequestDetectionLevel
_originatingRequestSpecifier
_originatingRequestSpecifierToOperationPoints
_osfsSizeRatio
_osfsThreshold
_outerLips
_outerLipsLock
_outputBufferData
_outputBufferHeight
_outputBufferWidth
_outputMaskEspressoBuffer
_outputPixelFormat
_outputs
_parabolaDetector
_parentRequest
_parseInputObservations:imageBuffer:error:
_parseOptions:error:
_passedInCIContext
_pasteTileComputePipelineState
_pathLock
_perMeshPtr
_performBlinkDetection
_performClustersPostprocessing
_performNOPForRevision:inContext:detectorCompletionSemaphore:error:
_performOrderedRequests:inContext:error:
_performRequests:onBehalfOfRequest:inContext:error:
_performRequests:onImageBuffer:gatheredForensics:error:
_performSceneClassification
_performedRequests
_personId
_personPredictionsForFace:withDescriptor:limit:faceIDCanceller:error:
_personUniqueIdentifierToSerialNumberMapping
_personUniqueIdentifiers
_personsModel
_petprintGenerator
_pitch
_pitchAngle
_pixelBuffer
_pixelBufferReps
_pixelBufferRepsCache
_pixelBufferRepsLock
_pixelFormatType
_pixelHeight
_pixelHeightCard
_pixelTransferSession
_pixelTransferSessionsHandler
_pixelValueToRegionLabelMap
_pixelWidth
_pixelsHighRange
_pixelsWideRange
_plan
_platform
_pleasantCameraTiltScore
_pleasantCompositionScore
_pleasantLightingScore
_pleasantPatternScore
_pleasantPerspectiveScore
_pleasantPostProcessingScore
_pleasantReflectionsScore
_pleasantSymmetryScore
_pointCount
_pointsCalculatorLock
_pointsClassification
_pointsData
_polygonList
_pools
_poolsLock
_poseData
_poseOriginatingRequestSpecifier
_postProcessTrackingResults:trackerResults:error:
_potentialLandmarkCustomClassifiers
_precisionEstimatesPerPoint
_precisionRecallThreshold
_predictedFeatureKey
_predictedPersonUniqueIdentifier
_predictedProbabilitiesKey
_predictor
_preferBackgroundProcessing
_preferredBufferSizeFormat
_preferredSmallSide
_previousFrameBuffer
_previousFrameImage
_previousImageHeight
_previousImageWidth
_previousLeafTimestampDistance
_previousLeafTotalDistance
_previousObservations
_printDebugInfo:detectedObjectsRaw:faceDetectorBGRAImage:tempImage:
_probabilityNormSums
_processAllFrames
_processFaceBasedInputInContext:revision:torsosThatNeedNoProcessing:torsosThatNeedTorsoprints:error:
_processFullImagePixelBuffer:options:regionOfInterest:warningRecorder:error:progressHandler:
_processHumanBodyBasedInputInContext:revision:torsosThatNeedNoProcessing:torsosThatNeedTorsoprints:error:
_processHumanBodyObservations:revision:regionOfInterest:context:error:
_processTiledImageBuffer:inputMaskObservation:options:error:
_processingDevice
_profile
_profileNormal
_projectedPoints
_propertyListRepresentation
_pyramid_size
_qosClass
_quadratureTolerance
_quality
_qualityCriteriaList
_qualityLevel
_queue
_queueNameToTasksQueueDictionary
_queueNameToTasksQueueDictionaryLock
_queueWithUniqueAppendix:queueClass:
_rawColorGaborDescriptor
_readOnly
_recognitionLanguages
_recognitionLevel
_recognize
_rectangleTrackingProcessingQueue
_referenceImageSignature
_refineLeftEyeRegion
_refineMouthRegion
_refineRightEyeRegion
_regionLabels
_regionMap
_regionOfInterest
_releaseDetectorsThatCanBeReplacedByDetectorOfClass:withConfiguration:
_releaseEspressoContext
_releaseEspressoPlan
_releaseSignallingBlock
_releaseTracker_NO_LOCK_DO_NOT_EXECUTE_DIRECTLY:
_removeAllFaceObservationsFromIdentityWithSerialNumber:
_removeBackgroundSemaphore
_removeExistingFaceObservations:fromIdentityWithSerialNumber:
_removePersonWithUniqueIdentifier:
_renderCIImage:toBuffer:width:height:rowBytes:format:error:
_renderCIImage:width:height:format:error:
_reportCharacterBoxes
_representativenessById
_repsCacheKeyToProcessingQueueDictionary
_repsCacheKeyToProcessingQueueDictionaryLock
_request
_requestClass
_requestClassCode
_requestConstellationToDetectorConstellationMap
_requestForensics
_requestImageBuffers
_requestImageBuffersCacheKeys
_requestLock
_requestNewIdentitySerialNumberAndReturnError:
_requestPerformer
_requestPerformingQueuePriorityGroup1
_requestPerformingQueuePriorityGroup2
_requestRevision
_requestToObservationClassMap
_requestToObservationsCacheKeyMap
_requestUUID
_requestsClassMapping
_requestsInFlight
_requestsPending
_requireFaceAttributesPupilRefiner
_requiredVersion
_resetTrackerIfNeeded:session:options:error:
_resolvedRevision
_results
_resultsLock
_returnAllResults
_returnMask
_revision
_rightEye
_rightEyeLock
_rightEyebrow
_rightEyebrowLock
_rightPupil
_roiAreaThreshold
_roll
_rollOutputs
_rotation
_rotationAngle
_rpnEspressoResourcesKeyToEspressoResourcesCache
_rpnEspressoResourcesKeyToEspressoResourcesCacheLock
_rpnInitEspressoResources
_rpnTrackEspressoResources
_sRGB
_saveFaceAttributes:toFaceObservation:options:error:
_saveFaceprint:toFaceObservation:options:error:
_scale
_scannerResult
_sceneClassifierDescriptor
_sceneObservation
_scenePrint
_scenePrintRevision
_sceneprintVersion
_sceneprints
_scoresDictionary
_screenGaze
_screenGazeState
_segmentationMask
_semaphore
_sequencedRequestObservations
_serialNumber
_serialNumberForEntityUniqueIdentifier
_serialNumberToFaceObservationsMapping
_serialNumberToPersonUniqueIdentifierMapTable
_serializationOptions
_session
_sessions
_sessionsAccessLock
_setCustomHierarchy:
_setFaceExpressionFeatureScoreIfDetected:features:detectionKey:scoreKey:featureKey:
_setResolvedRevision:
_setupBufferAndReturnError:
_setupPipelinesReturnError:
_shape
_sharplyFocusedSubjectScore
_shortDescription
_shouldUpdateRepresentative
_signalled
_signallingBlock
_signature
_signatureData
_signaturePrintTypeSupported:
_significantEventCustomClassifiers
_sizedPointsCache
_sizes
_smartCamCombinedModelImageAestheticsClassificationsForRevision:performedInContext:error:
_smartCamCombinedModelImageSaliencyObservationsForRevision:performedInContext:error:
_smartCamprintVersion
_smartDistanceFactor
_smilingCategory
_specifier
_startMaxFind
_startNormal
_startSensitized
_state
_stopAtFirstPyramidWith2DCode
_stopMaxFind
_stopNormal
_suggestedIdsForRepresentative
_suggestionsForCluster
_suggestionsLogger
_symbologies
_symbology
_synchronizationQueue
_tapToBox
_targetFrameTime
_targetImageDimensionForContourDetection
_targetImageSignature
_targetedImageBuffer
_tastefullyBlurredScore
_temporalSmoothingFrameCount
_tensorsDictionary
_text
_textBlockObservationsFromRegion:requestRevision:
_textElements
_textObjects
_textRecognition
_threshold
_thresholdFilter
_timeInterval
_timeRange
_timeStamp
_timerMode
_topLeft
_topLevelContoursIndices
_topLevelIndex
_topRight
_torsoprint
_torsoprintGenerator
_torsoprintRequestRevision
_torsoprintRevision
_totalObjectCount
_trackDuration
_trackID
_trackedFrameCVPixelBufferFormat
_trackedFrameNumber
_trackerClassToNameMapTable
_trackerResourceCache
_trackerResourcesAccessingLock
_trackerTypeToClassDictionary
_trackers
_trackersCollectionManagementQueue
_trackingFrameSizeInPixels
_trackingLevel
_trackingLevelOptionFromTrackingLevelEnum
_trackingProcessingQueue
_trackingRectAroundPoint:trackingRectSize:
_trainedModel
_trainedModel_DO_NOT_ACCESS_DIRECTLY
_trainingData
_trajectoryLength
_trajectoryProcessor
_transform
_transformsAndConfidences
_type
_unalignedBoundingBox
_unalignedFaceBoundingBox
_uniqueFaceObservationsWithRegistrationState:forFaceObservations:withExpectedFaceprintRequestRevision:ofPersonWithUniqueIdentifier:error:
_unlockStaticObjectsAccessLock
_updateClustererWithOptions:canceller:error:
_updateModelWithFlexibleImageConstraintUsingWidth:height:
_updateTrackerWithModifiedBBoxForImageBuffer:error:
_upperBodyOnly
_useCenterTileOnly
_useImageAnalyzerScaling
_useMLDetector
_useNonLocalRegularization
_useSegmentationPregating
_useTiling
_useTimestampAdjustedDistances
_userBBox
_usesAlternateLineGrouping
_usesLanguageCorrection
_uuid
_uuidStringForCacheIdentifier
_uv_pxbuf
_uv_tex_user_ref
_uv_u32_alias_tex
_uv_user_ref
_validateAndPrepareRequests:error:
_validateDetectedObjectObservations:forObservationClass:withMinimumCount:forOptionalRequest:error:
_validateFaceObservations:withMinimumCount:forOptionalRequest:error:
_validateInputImage:error:
_validateOutputImage:error:
_validatedImageBufferForKey:inOptions:error:
_value
_vectorMapReadOnlyFlag
_vectorProjections
_version
_version1ModelWithObjects:error:
_visionBBoxToTrackerBBox:trackedObjects:imageSize:results:error:
_vtSessionManager
_w_pxbuf
_w_tex
_warningRecorder
_warnings
_warpTransform
_weakRequestPerformer
_weakSession
_weakSessionWrappers
_wellChosenBackgroundScore
_wellFramedSubjectScore
_wellTimedShotScore
_width
_wisdomParameters
_wisdomParametersLock
_wisdomParams
_wisdomResourcesPath
_yaw
_yawAngle
_yawOutputs
_zeroFlowWithCommandBuffer:uv_tex:
acceptableEntityPrintOriginatingRequestSpecifiers
acceptableVersions
activeImageBuffers
activeProcessorCount
addAllJointsToPath:imageSize:
addAllPersonsFromPersonsModel:error:
addCompletedHandler:
addEntriesFromDictionary:
addFaceObservations:toFaceDescriptorBuffer:
addFaceObservations:toPersonWithUniqueIdentifier:error:
addFaceObservations:withGroupingIdentifiers:toFaceDescriptorBuffer:
addIndex:
addIndexes:
addObject:
addObjectsFromArray:
addObservations:toEntityWithUniqueIdentifier:error:
addOriginalRequest:
addPersonData:withGroupingIdentifiers:toFaceDescriptorBuffer:
addPersonWithUniqueIdentifier:fromPersonsModel:error:
addPointer:
addRPNTrackerResourcesConfiguredForOptions:resources:error:
addRequest:processingOptions:error:
addRequest:withConfiguration:error:
addRequest:withProcessingOptions:error:
addSession:droppingWeakZeroedObjects:
addTilingWarningRecorder:
addToGroupingsRequest:withFaceObservations:
additionalCharacters
adjustmentKeys
adjustmentValuesForKey:
aestheticScore
ageCategory
algorithm
algorithmOfClass:error:
alignedBBox
alignedBoundingBox
alignedBoundingBoxAsCGRect
alignedMeanShape
alignedRotationAngle
alignmentTransform
alignmentTransformInTopLeftOrigin:orientation:
allCityNatureIdentifiersWithOptions:error:
allClusteredFaceIdsAndReturnError:
allConfigurations
allDevices
allIdentifiers
allInputImages
allInputs
allJunkIdentifiersForOptions:error:
allLabelsWithConfidences
allLandmarksPointsIndexes
allLandmarksPointsIndexesForConstellation:
allModelEquivalents
allObjects
allOutputs
allPhotosAdjustmentKeysForOptions:error:
allPoints
allRecognizedObjectsIdentifiersWithOptions:error:
allSceneIdentifiersWithOptions:error:
allScorePropertyNames
allSessions
allSessionsDroppingWeakZeroedObjects:
allSignificantEventIdentifiersWithOptions:error:
allSubclassesOfClass:excludingRootClass:overridingClassSelector:
allSupportedRevisions
allVN5kJNH3eYuyaLxNpZr5Z7ziIdentifiersWithOptions:error:
allValues
allocWithZone:
allocateColorProfileContext:width:height:rowBytes:
allocationSize
allowedImageSizeClosestToPixelsWide:pixelsHigh:preferDownScaling:preferInputAspectRatio:
allowsCachingOfResults
analysisPixelFormatTypeForConfiguration:
analyzeTimeRange:error:
analyzeWithStart:andDuration:error:
analyzeWithTimeRange:error:
anfdMultiDetectorClassToProcessRequest:
angle
angleInTopLeftOrigin:orientation:
animalprint
anyObject
appClipCodeMetadataValue
appendBytes:length:
appendData:
appendFormat:
appendPath:
appendString:
appendString:toLogFile:
applicableDetectorClassForRevision:error:
applicableDetectorTypeForRevision:error:
applicableRevisionForDependentRequest:
applicableRevisionForDependentRequestOfClass:beingPerformedByRevision:
applyConfigurationOfRequest:
applyWithExtent:arguments:
archivedDataWithRootObject:requiringSecureCoding:error:
array
arrayByAddingObjectsFromArray:
arrayWithCapacity:
arrayWithObject:
arrayWithObjects:count:
asVNTensorDataType
aspectRatio
aspectRatioHandling
aspectRatioInOrientation:
assignOriginalRequestsResultsFromObservations:obtainedInPerformingContext:
asyncStatus
attributedString
augmentedBuffersWithWidth:height:format:options:augmentationOptions:error:
augmentedCroppedBuffersWithWidth:height:format:cropRect:options:augmentationOptions:error:
automaticallyDetectsLanguage
autorelease
availableGroupKeys
availableIdentifiers
availableJointNames
availableJointsGroupNames
availableKeys
availableLocateModes
availableLocateModesAndReturnError:
availableLocateModesRev1
availableLocateModesRev2
availableVNInferenceNetworkIdentifierFaceprintVersions
availableVNInferenceNetworkIdentifierSceneNetObjDetNetSliderNetVersions
availableVNInferenceNetworkIdentifierSceneNetVersions
availableVNInferenceNetworkIdentifierSmartCamVersions
availableVNInferenceNetworkIdentifierStandaloneSceneprintVersions
availableVersionsForIdentifier:error:
avgDistance
bTop
backingStore
baldCategory
barcodeDescriptor
barcodeRequest
barcodeSymbologyForACBSBarcodeType:
barcodeSymbologyForMRCSymbology:
baseAddress
baselines
batchNumber
beginRangeFaceBoundingBoxExpansionRatio
bindBuffer:toNetworkInputBlobName:error:
bindBuffer:toNetworkOutputBlobName:error:
bindLockedPixelBuffer:toNetworkInputBlobName:error:
bindOutputConfidenceBuffersAndReturnError:
bindPixelBuffer:toNetworkBlobName:error:
blacklistForModel:
blacklistFromUTF8StringArray:
blacklistedIdentifiers
blinkScore
blocks
blocksWithTypes:inRegion:
blurDeterminationMethod
blurMeasure
blurScore
boolForKey:
boolValue
booleanBytesData
bottomLeft
bottomRight
boundingBox
boundingBoxAligned
boundingBoxForRange:error:
boundingBoxForTextRange:error:
boundingBoxInTopLeftOrigin:orientation:
boundingBoxOutputDescription
boundingBoxesFromFloat32ImageBuffer:thresholds:error:
boundingBoxesFromFloat32ImageBuffer:thresholds:relativeToMaximum:applySmoothing:originalImageSize:sigmaX:sigmaY:nStd:error:
boundingBoxesFromFloat32PixelBuffer:thresholds:relativeToMaximum:applySmoothing:originalImageSize:sigmaX:sigmaY:nStd:error:
boundingCircleForPoints:error:
boundingCircleForSIMDPoints:pointCount:error:
boundingQuad
bounds
boxCenter
brightness
bufferWithWidth:height:format:options:error:
bufferWithWidth:height:format:options:error:pixelBufferRepsCacheKey:
bundleIdentifier
bundlePath
bundleWithIdentifier:
bytes
bytesPerRow
cStringUsingEncoding:
cacheBuffer:forCacheKey:
cacheDetector:
cacheKeyFromOptions:error:
cacheKeyWithBufferFormat:width:height:
cacheKeyWithBufferFormat:width:height:cropRect:
cacheObservationsOfRequest:
cacheOptionsKeys
cachePath
cachedBufferWithKey:
cachedFloatingImageBufferReturningError:
cachedFloatingImageRegistrationSignatureReturningError:
cachedImageReader
cachedObservationsAcceptedByRequest:
cachedObservationsWithKey:wereCheckedOnBehalfOfRequest:
cachedObservationsWithKey:wereLocatedOnBehalfOfRequest:
cachedPixelBufferRepresentationForKey:
cachingIdentifier
calculateArea:forContour:orientedArea:error:
calculateDistanceFromImageprintObservation:
calculateImageDescriptors:regionOfInterest:warningRecorder:canceller:error:
calculatePerimeter:forContour:error:
calculatePupilLocationAndUpdateLandmarkPoints:
calculateSaliencyBoundingBoxesForDetectorType:pixelBuffer:configurationOptions:originatingRequestSpecifier:regionOfInterest:warningRecorder:error:
calculateSumProd:prodROIRef:prodROIRotateRef:rowStartLocation2:height:
calculateSumProdAlternative:prodROIRef:prodROIRotateRef:rowStartLocation2:height:
calculateTilesForRegionOfInterest:imageWidth:imageHeight:tileSizeInPixels:overlapFraction:aspectRatioThreshold:columns:rows:tiles:error:
canBehaveAsDetectorOfClass:withConfiguration:
canCreateModelOfClass:withObjects:error:
cancel
cancelAllRequests
cancelClustering:
cancellationSemaphore
cancellationTriggered
cancellationTriggeredAndReturnError:
cancellerAndReturnError:
candidates
cascadeStepCount
categorizeFaceObservations:shouldRunDetectorBlock:facesThatNeedNoProcessing:facesThatNeedProcessing:facesThatNeed2DLandmarks:
category
cellStartsX
cellStartsY
center
channels
charBoxContext
charBoxFlags
charBoxesFromTextBoxes:bigBoxes:ccYTopLocationsForSort:ccYBottomLocationsForSort:
characterBoxes
charboxROIFullVectorHeight2
charboxROIFullVectorRowStart
checkFlag:atIndex:
childContourAtIndex:error:
childContourCount
childContourIndicesAtIndex:
childContours
children
chirality
ciContextLock
class
class:overridesClassSelector:
classForClassCode:error:
classNameForClassCode:error:
classifierResourceTypesToNamesForOriginatingRequestSpecifier:
classifyImageHierarchicallyWithDescriptors:usingImageClassifier:hierarchicalClassifier:minimumClassificationConfidence:minimumClassificationConfidenceRatio:maximumLeafLabels:maximumHierarchicalLabels:options:metalContext:error:
classifyImageWithDescriptors:usingImageClassifier:andMinConfidenceForClassification:options:metalContext:error:
clearFlag:atIndex:
clearImage
close
closeFile
closestContentRegionOfType:toNormalizedPoint:maxPixelDistance:
closestTextBlockOfTypes:toPoint:maximumPixelDistance:
clusterId
clusterSplitDistanceType
clusterState
clusteredFaceIds
clusteredFaceIdsForClusterContainingFaceId:error:
clustererBuilderWithOptions:error:
clustererModelFileNamesFromState:storedInPath:error:
clustererQueryWithOptions:error:
clusters
code
codingTypesToCodingKeys
colorGaborDescriptor
colorWithRed:green:blue:alpha:
commandBuffer
commit
commonGazeLocationRadius
compare:
compare:options:
completeInitializationForSession:error:
completed
completionHandler
componentsJoinedByString:
componentsSeparatedByString:
compoundRequestProcessingDeviceFromOriginalRequestsProcessingDevice:
compoundRequestRevisionForRequest:
compoundRequestsForOriginalRequests:withPerformingContext:error:
computationAccuracy
computeApproximateBlurScore:onGrayscaleImage:sampledPixelsCount:insetFactor:error:
computeApproximateBlurScore:onRGBAImage:sampledPixelsCount:insetFactor:error:
computeBlurScore:onGrayscaleImage:andWithRegionOfInterestInImageCoordinates:andRegionOfInterestInsetFactor:error:
computeBlurScore:onGrayscaleImage:insetFactor:error:
computeBlurSignatureForGrayscaleImage:error:
computeBrightnessScore:onImage:error:
computeCenterCropRectFromCropRect:inImageSize:calculatedScaleX:calculatedScaleY:
computeCentroidUsingPoints:indicies:numberOfIndicies:
computeClusteringForClusteringTree:intoKGroups:error:
computeClusteringForClusteringTree:usingThreshold:error:
computeClusteringIntoKGroups:forHierarchicalTree:context:
computeClusteringIntoKGroups:orUsingDistanceThreshold:forHierarchicalTree:context:
computeClusteringOfImageDescriptors:intoKGroups:error:
computeClusteringTreeForImageDescriptors:assumeDescriptorsAreSorted:error:
computeClusteringTreeForImageDescriptors:error:
computeClusteringUsingDistanceThreshold:forHierarchicalTree:context:
computeCommandEncoder
computeConvnetDescriptorForImageData:context:error:
computeDependentTopAndBottomComponents:finalCharBoxCoordCount:
computeDescriptorForImageData:context:error:
computeDistance:toFeaturePrintObservation:error:
computeDistance:withDistanceFunction:error:
computeDistanceToFeaturePrintObservation:error:
computeEdgeWidthBlurScore:onGrayscaleImage:error:
computeFinalDescriptorBasedDistanceForColorDistance:andSceneClassifierDistance:
computeHashForCVPixelBuffer:
computeHierarchicalClusteringOfImageDescriptors:results:context:
computeImageCropWithImage:regionOfInterest:usingDescriptorProcessor:scalingImage:options:pixelBuffer:error:
computeImageDescriptorsWithImage:pixelBuffer:regionOfInterest:usingDescriptorProcessor:tileCount:augmentationMode:resultantDescriptorBuffer:options:metalContext:canceller:tileColumns:tileRows:error:
computeIndependentTopAndBottomComponents:finalCharBoxCoordCount:
computeLabelsAndConfidence:usingDescriptorBuffer:populateLabelsAndConfidence:options:metalContext:error:
computeLandmarksScoreOnImage:withFaceBoundingBox:andLandmarks:error:
computeMainStub:numCropRows:numCropColsOut:maxY:start:
computeNaturalClusteringForClusteringTree:error:
computeNaturalClusteringForHierarchicalTree:context:
computeNaturalClusteringOfImageDescriptors:error:
computePulseVectorSum:start:stop:imageHeight:imageWidth:bottomHeight:topHeight:
computeRectFromExtremaUsingThreshold:vImage:
computeRegistrationFeaturesForImageData:context:error:
computeTimestampAdjustedDistanceForBaseDistance:andTimestampDiff:
computeTotalDistanceForDescriptorDistance:timestampDiff:useTimestampAdjustment:
computeTransform:forRegisteringImageSignature:withSignature:minimumOverlap:error:
computeYawPitchRollFromPoseMatrix:outputYaw:outputPitch:outputRoll:
computeZCVectorHighProbability
confidence
confidenceFeatureName
confidenceScoreType
confidenceTypeForOriginatingRequestSpecifier:
confidenceTypeForRevision:
confidencesOutput
configuration
configurationClass
configurationForRequest:
configurationForRequest:withObservationGroup:compoundRequestRevision:
configurationFromLoadedObjects:error:
configurationOptionKeysForDetectorKey
configurationOptions
configureImageAnalyzerOptions:error:
conformsToProtocol:
constellation
containsIdentifier:
containsIndex:
containsPoint:
containsPoint:inCircumferentialRingOfWidth:
containsValueForKey:
contentRegionOfType:containingTextAtIndex:
contentsWithTypes:
contextWithMTLDevice:options:
contextWithOptions:
contourAtIndex:error:
contourAtIndexPath:error:
contourCount
contrastAdjustment
contrastPivot
convertClusterNodesListToDescriptorsList:
convertRelationships:toStdRelationships:
convertToAlgorithm:error:
convertUpdatePairsToClusters:
coordinatesFeatureName
copy
copyColorspaceForFormat:bitmapInfo:
copyStateOfRequest:
copyWithZone:
count
countByEnumeratingWithState:objects:count:
crOutput
createBufferWithMaxSideLengthOf:andPixelFormat:andOptions:error:
createCGImage:fromRect:
createCVPixelBufferRefFromDictionaryRepresentation:
createCVPixelBufferWithPixelFormat:fromImageInEspressoBuffer:error:
createClassifierWithDescriptor:classifierAbsolutePath:computePlatform:computePath:labelsFilename:options:
createCompoundConfigurationHashKeyForRequest:compoundRequestRevision:
createCroppedBufferWithMaxSideLengthOf:andCropBounds:andPixelFormat:andOptions:error:
createDescriprorProcessorWithModelPath:nBatch:computePlatform:computePath:options:
createDictionaryRepresentationOfCVPixelBuffer:
createDirectoryAtPath:withIntermediateDirectories:attributes:error:
createDirectoryAtURL:withIntermediateDirectories:attributes:error:
createExpressionAndConfidencesDictionaryFromScores:
createExpressionDetectionDictionaryFromScores:
createHierarchicalModelForMultiDetectorModel:error:
createHierarchicalModelForOriginatingRequestSpecifier:error:
createLumaImage:lumaImage:numCropRows:rowStartLocation:
createLumaImageAlternative:lumaImageAlternative:numCropRows:rowStartLocation:
createMaskImageOfFaceSegments:error:
createNSErrorWithStatus:andMessage:
createNSExceptionWithStatus:andMessage:
createObservationWithDescriptors:forOriginatingRequestSpecifier:
createPixelBufferInOrientation:error:
createProbabilityImageOfFaceSegment:error:
createProbabilityImageOfFaceSegment:region:normalize:error:
createRPNTrackerResourcesConfiguredWithOptions:error:
createRegionOfInterestCrop:options:warningRecorder:pixelBuffer:error:progressHandler:
createSaliencyImageAndReturnError:
createSingleNetworkPlanFromResourceName:usingProcessingDevice:lowPriorityMode:inputBlobNames:outputBlobNames:networkConfiguration:explicitNetworkLayersStorageType:memoryPoolId:espressoResources:error:
createSingleNetworkPlanFromResourceName:usingProcessingDevice:lowPriorityMode:inputBlobNames:outputBlobNames:networkConfiguration:memoryPoolId:espressoResources:error:
createVNEntityIdentificationModelEntryPrintForRevision:fromDescriptorData:length:elementCount:error:
cropAndScaleBufferWithWidth:height:cropRect:format:imageCropAndScaleOption:options:error:calculatedNormalizedOriginOffset:calculatedScaleX:calculatedScaleY:
cropAndScaleBufferWithWidth:height:cropRect:format:imageCropAndScaleOption:options:error:calculatedNormalizedOriginOffset:calculatedScaleX:calculatedScaleY:pixelBufferRepsCacheKey:
cropResult
croppedBoundingBox
croppedBufferWithWidth:height:format:cropRect:options:error:
croppedBufferWithWidth:height:format:cropRect:options:error:pixelBufferRepsCacheKey:
currentCodingVersion
currentQueueIsSynchronizationQueue
currentSerializationVersion
currentVersion
customHierarchyForRequest:error:
customHierarchyWithAdditionalParent:children:error:
customHierarchyWithAdditionalRelationships:error:
customWords
data
dataPointer
dataType
dataUsingEncoding:
dataWithBytes:length:
dataWithBytesNoCopy:length:freeWhenDone:
dataWithJSONObject:options:error:
dataWithOptions:error:
date
ddResult
debugDescription
debugFilename
debugMatlab
debugMode
debugOut
debugQuickLookObject
decodeArrayOfObjectsOfClass:forKey:
decodeArrayOfObjectsOfClasses:forKey:
decodeBoolForKey:
decodeDoubleForKey:
decodeFloatForKey:
decodeInt32ForKey:
decodeIntForKey:
decodeIntegerForKey:
decodeObjectOfClass:forKey:
decodeObjectOfClasses:forKey:
decodeTopLevelObjectOfClasses:forKey:error:
defaultANEDevice
defaultBox
defaultBoxesSides
defaultCPUDevice
defaultCStringEncoding
defaultDevice
defaultFaceBoundingBoxExpansionRatio
defaultFaceDetectionPrecisionRecallThreshold
defaultImageCropAndScaleOption
defaultManager
defaultMetalDevice
defaultOriginatingRequestClassNameForRequestRevision:
defaultOriginatingRequestSpecifierForRevision:
defaultProcessingDeviceForRevision:
defineCustomHierarchy:error:
defineCustomHierarchyWithRelationships:error:
delegate
deleteCharactersInRange:
dependencyAnalyzedRequestsForRequests:withPerformingContext:error:
dependencyProcessingOrdinality
dependentRequestCompatibility
dependentRequestMappingTable
description
descriptionForPrivateRevision:
descriptor
descriptorData
descriptorForEspressoBlobDimensions:dataType:
descriptorForIdentifier:version:error:
descriptorId
detect:inputIsBGR:
detectAndProcessObjects:inputIsBGR:
detectBlinkOnFaceImage:faceObservation:lumaRec2DInImageCoordinates:landmarks:warningRecorder:error:
detectDarkOnLight
detectDiacritics
detectFaceLandmarksInContext:faces:error:
detectFacesInContext:error:
detectFacesInImage:options:error:
detectFeaturesInBuffer:withRegionOfInterest:error:
detectHumanBodiesInContext:error:
detectedBarcodeSupportCode
detectedCodeWithBarcodeObservation:
detectedObjectRequestKeyToRequestInfo
detectedPoints
detectedPointsInTopLeftOrigin:orientation:
detectionLevel
detectionOnly
detectionprint
detectorAccessingLock
detectorClass
detectorClassForConfigurationOptions:error:
detectorClassForDescriptorIdentifier:version:
detectorClassForDetectorType:configuredWithOptions:error:
detectorClassForDetectorType:error:
detectorConfigurationOptions
detectorCropCreationAsyncTasksQueue
detectorCropProcessingAsyncTasksQueue
detectorExecutionTimeInterval
detectorKeyComponentForDetectorConfigurationOptionKey:value:
detectorName
detectorOfClass:configuredWithOptions:error:
detectorOfClass:configuredWithOptions:forSession:error:
detectorOfType:configuredWithOptions:error:
detectorPreferredImageSize
detectorProgressHandler
detectorType
detectorWithConfigurationOptions:forSession:error:
detectsDarkOnLight
determineColorProfileType:
deviceForMetalDevice:
diameter
dictionary
dictionaryRepresentation
dictionaryRepresentationClassesSet
dictionaryWithCapacity:
dictionaryWithObjects:forKeys:count:
dictionaryWithObjectsAndKeys:
didTrainEntityIdentificationModel:
direction
dispatchGroupAsyncByPreservingQueueCapacity:block:
dispatchGroupWait:error:
dispatchQueueAttribute
dispatchReportBlockCompletion
dispatchSyncByPreservingQueueCapacity:
dispatchThreadgroups:threadsPerThreadgroup:
distance
distanceBetweenClustersWithFaceId:andFaceId:error:
distanceBetweenFacesWithFaceObservation:andFaceObservation:error:
distanceBetweenFacesWithFaceprint:andFaceprint:error:
distanceBetweenLevel1Clusters:error:
distanceBetweenPoint:point:
distanceFromDescriptor:
distanceToDefaultBox
distanceToImageprint:error:
distanceToPoint:
distancesById
distantPast
documentElements
documentOutputRegionForImage:options:roi:error:withProgressHandler:
documentWithRegions:title:confidence:imageSize:
domain
dotProductOfVector:vector:
doubleValue
drawAtPoint:
dropCurrentFaceModelAndReturnError:
elementCount
elementType
emptyFaceprintDataForRevision:
encodeBool:forKey:
encodeDouble:forKey:
encodeFloat:forKey:
encodeHashDescriptorWithBase64EncodingAndReturnError:
encodeInt32:forKey:
encodeInt:forKey:
encodeInteger:forKey:
encodeObject:forKey:
encodeToCommandBuffer:sourceTexture:destinationTexture:
encodeToCommandBuffer:sourceTextureArray:guidanceTexture:constraintsTextureArray:numberOfIterations:destinationTextureArray:
encodeWithCoder:
encodedData
endEncoding
endRangeFaceBoundingBoxExpansionRatio
enforceSquareFaces:withHeight:andWidth:
entityCount
entityIdentificationModel:indexOfEntityWithUniqueIdentifier:
entityIdentificationModel:observationAtIndex:forEntityAtIndex:
entityIdentificationModel:trainingFailedWithError:
entityIdentificationModel:uniqueIdentifierOfEntityAtIndex:
entityIdentificationModelDidDropTrainingData:
entityIdentificationModelTrainingDataWasModified:
entityIdentificationModelWillDropTrainingData:
entityPredictionsForObservation:limit:canceller:error:
entityPrintOriginatingRequestSpecifier
entityUniqueIdentifier
entityUniqueIdentifiers
enumerateIndexesUsingBlock:
enumerateIndexesWithOptions:usingBlock:
enumerateKeysAndObjectsUsingBlock:
enumerateObjectsAtIndexes:options:usingBlock:
enumerateObjectsUsingBlock:
enumerateSubclassesOfClass:excludingRootClass:usingBlock:
environment
equationCoefficients
error
errorForCVReturnCode:localizedDescription:
errorForCancellationOfRequest:
errorForDataUnavailableWithLocalizedDescription:
errorForDataUnavailableWithLocalizedDescription:underlyingError:
errorForEspressoErrorInfo:localizedDescription:
errorForEspressoReturnStatus:localizedDescription:
errorForExecutionTimeoutWithLocalizedDescription:
errorForExecutionTimeoutWithLocalizedDescription:underlyingError:
errorForFailedEspressoPlan:localizedDescription:
errorForGPURequiredByRequest:
errorForInternalErrorWithLocalizedDescription:
errorForInternalErrorWithLocalizedDescription:underlyingError:
errorForInvalidArgument:named:
errorForInvalidArgumentWithLocalizedDescription:
errorForInvalidFormatErrorWithLocalizedDescription:
errorForInvalidImageFailure
errorForInvalidImageFailureWithLocalizedDescription:
errorForInvalidModelWithLocalizedDescription:
errorForInvalidModelWithLocalizedDescription:underlyingError:
errorForInvalidOperationForRequestClass:revision:
errorForInvalidOperationForRequestSpecifier:
errorForInvalidOperationWithLocalizedDescription:
errorForInvalidOption:named:
errorForInvalidOption:named:localizedDescription:
errorForInvalidOptionWithLocalizedDescription:
errorForMemoryAllocationFailureWithLocalizedDescription:
errorForMissingOptionNamed:
errorForOSStatus:localizedDescription:
errorForOperationFailedErrorWithLocalizedDescription:
errorForOutOfBoundsErrorWithLocalizedDescription:
errorForUnavailableSession
errorForUnimplementedFunctionWithLocalizedDescription:
errorForUnimplementedMethod:
errorForUnimplementedMethod:ofObject:
errorForUnknownClassificationIdentifier:
errorForUnknownErrorWithLocalizedDescription:
errorForUnsupportedConfigurationOfRequest:
errorForUnsupportedProcessingDevice:
errorForUnsupportedRequestClassName:
errorForUnsupportedRequestSpecifier:
errorForUnsupportedRevision:ofRequest:
errorForUnsupportedRevision:ofRequestClass:
errorForUnsupportedSerializingHeaderVersion:
errorForVImageError:localizedDescription:
errorWithCode:message:
errorWithCode:message:underlyingError:
errorWithDomain:code:userInfo:
espressoDeviceID
espressoEngine
espressoInputImageSize
espressoInputMaskSize
espressoMaskOutputBufferSizes
espressoMaskOutputBuffers
espressoModelFileNameForConfigurationOptions:
espressoModelImageprintClass
espressoModelInputImageDimensionsBlobNameForConfigurationOptions:
espressoModelNetworkLayersStorageTypeForConfigurationOptions:
espressoResources
espressoStorageType
estimateFlowFromReference:target:error:
estimateFlowStream:error:
estimateMotionBetweenFirstImage:andSecondImage:withUpsample:withGuidedImage:error:
evictAllDetectors
evictDetectorsPassingTest:
examinePulseWindow:prodBoostNormalized:pwContext:minHeight:maxHeight:thresholdSet:
exceptionWithName:reason:userInfo:
executePlanAndReturnError:
executionNanoseconds
executionTimeInternal
exifTimestamp
explicitlyConfiguredProcessingDevice
exposureScore
expressionFeatures
expressionTypeFromString:
expressionsAndConfidence
expressionsAndDetections
expressionsAndScores
extent
extractBoxesForStub:bigBoxesAdapt:countBigBox:rowStartLocation2:rowStopLocation2:heightConstraint:imageWidth:height:ccCharBoxesAggr:ccCharBoxesFiltered:useLowLightEnhancement:
extractCharBoxHeightInfo:ccCharBoxesFiltered:ccYTopLocationsForSort:ccYBottomLocationsForSort:aggregateGreenBoxesForStubCount:imageWidth:
extractDetailsForFaces:inImage:options:error:
eyesCategory
face
faceAngle
faceAttributes
faceBoundingBoxExpansionRatio
faceBoundingBoxScalingFactorForFaceObservation:
faceCaptureQuality
faceCenter
faceContour
faceCoreEnhanceEyesAndMouthLocalization
faceCoreExtractBlink
faceCoreExtractSmile
faceCoreInitialAngle
faceCoreKalmanFilter
faceCoreMinFaceSize
faceCoreType
faceCountForPersonWithUniqueIdentifier:
faceCountsForAllPersons
faceCountsForPersonsWithUniqueIdentifiers:
faceDetectionPrecisionRecallThreshold
faceHairCategory
faceID2ModelMaximumElementsPerID
faceID3IndexMode
faceID3ModelMaximumElementsPerID
faceID3ModelMaximumIDs
faceID3ModelSeed
faceId
faceIdConfidence
faceJunkinessIndex
faceModelClass
faceModelFaceObservationAtIndex:forPersonAtIndex:
faceModelIndexOfPersonWithUniqueIdentifier:
faceModelNumberOfFaceObservationsForPersonAtIndex:
faceModelPersonsCount
faceModelUniqueIdentifierOfPersonAtIndex:
faceObservationUUID
faceObservationWithRequestRevision:boundingBox:alignedBoundingBox:roll:yaw:
faceObservationWithRequestRevision:boundingBox:alignedBoundingBox:roll:yaw:pitch:
faceObservationWithRequestRevision:boundingBox:andAlignedBoundingBox:
faceObservationWithRequestRevision:boundingBox:faceprint:
faceObservationWithRequestRevision:boundingBox:roll:yaw:
faceObservationWithRequestRevision:boundingBox:roll:yaw:pitch:
faceObservationWithRequestRevision:unalignedBoundingBox:alignedBoundingBox:
faceObservationsForPersonWithUniqueIdentifier:error:
faceObservationsInOptions:withOptionName:error:
faceOrientationIndex
faceRegionMap
faceScreenGaze
faceSegmentIndexToFlagMap
faceSegmentLabelToProbabilityMap
faceSegmentToSegmentMaskGrayLevelDictionary
faceSegments
faceSegmentsPixelSizeInBytes
faceSize
faceTorsoprint
faceType
facemaskCategory
faceprint
faceprintInputPath
faceprintRequestRevision
faceprintRequestRevisionForFaceTorsoRequestRevision:error:
failWithError:
failureScore
featureExtractorParameters
featureName
featureNames
featureValue
featureValueForName:
featureValueFromScenePrint:dataType:
featureValueWithMultiArray:
featureValueWithPixelBuffer:
features
feedForwardEspressoBufferForNetwork:fromBufferWithName:toBufferWithName:firstFrame:error:
fileExistsAtPath:
fileExistsAtPath:isDirectory:
fileHandleForUpdatingAtPath:
fileNameBase
fileURLWithPath:
fileURLWithPath:isDirectory:
fillInOneVector:checkFlag:checkHeight:
filterBoxes:
filterThresholds
filterWalkUpDownCount
filterWithName:keysAndValues:
filteredArrayUsingPredicate:
fingerprintHashes
finishDecoding
finishEncoding
firstIndex
firstObject
firstObjectCommonWithArray:
firstSupportedRevisionInOrderedRevisionList:
floatValue
floatVectorSumProd
floatingImageSignature
forceFaceprintCreation
forceUseInputCVPixelBufferDirectly
forcedCleanup
forcedCleanupWithOptions:
frameAnalysisSpacing
frameCVPixelBufferFormatForRequestRevision:
frameRate
frameworkClass
frameworkVersion
free
freeColorProfileContext:
freeImageInDealloc
freeNodeOnDealloc
freeVImageBuffer:
fullyPopulateConfigurationOptions:
fullyPopulatedConfigurationOptionsWithOverridingOptions:
gaze
gazeHeatMapThreshold
gazeMask
genderCategory
generateDominantPulse:rowLocationsRef:debugOut:bufferHeight:bufferWidth:
generateHistogramBounds:rgbVector2Ref:numPixels1:numPixels2:minMaxRGB:lowHighRGB:
generatePulses:minHeight:maxHeight:thresholdSet:prodBoostNormalized:pulseVectorFlag:
generateSegmentationMask
getAllClustersAndReturnError:
getAllClustersFromStateAndReturnError:
getArray:forKey:inOptions:withElementsOfClass:requiredMinimumCount:allowedMaximumCount:error:
getBOOLValue:forKey:inOptions:error:
getBOOLValue:forKey:inOptions:withDefaultValue:error:
getBlocks
getCRDocumentOutputRegion
getCROutputRegion
getCameraIntrinsicsAvailable:
getCameraOpticalCenterIfAvailable:
getChildren
getClassCode:forClass:error:
getClassCode:forClassName:error:
getClusterState:
getClusteredIds:
getClustersForClusterIds:options:error:
getClustersWithOptions:error:
getConfidence:forClassificationIdentifier:withPrecision:error:
getConfidence:forClassificationIdentifier:withRecall:error:
getConstellation:cvmlConstellation:fromOptions:error:
getDataDetectorResults:
getDataDetectorResultsForString:error:
getDefaultConfidence:forClassificationIdentifier:error:
getDistanceBetweenLevel0ClustersWithFaceId:andFaceId:error:
getDistanceBetweenLevel1Clusters:error:
getDistanceForClusterNode:splitDistanceType:
getDistances:to:error:
getDoubleValue:forKey:inOptions:error:
getDoubleValue:forKey:inOptions:withDefaultValue:error:
getFaceEXIFOrientation:error:
getFloatValue:forKey:inOptions:error:
getFloatValue:forKey:inOptions:withDefaultValue:error:
getHostTime
getHostTimeInNanos
getIndexBoxes:filterThresholdIndex:
getInputImageTensorDescriptor:forBlobName:pixelFormatType:outputTensorDescriptors:forBlobNamesWithTypes:fromNetworkModelFileWithPath:error:
getIntValue:forKey:inOptions:error:
getIntValue:forKey:inOptions:minimumValue:maximumValue:error:
getIntValue:forKey:inOptions:withDefaultValue:error:
getKey:fromDictionary:withDefault:
getLabels
getLandmarkErrorEstimates:forConstellation:error:
getLandmarkOcclusionFlags:forConstellation:error:
getLandmarkPoints:forConstellation:error:
getLeafNodes
getLevel0ClusteredIdsForFaceId:error:
getLevel1ClusteredIdsGroupedByLevel0ClustersForFaceId:error:
getLines
getLumaHistogram:startCC:colorProfileContext:
getMTLGPUPriority:forKey:inOptions:withDefaultValue:error:
getNSIntegerValue:forKey:inOptions:withDefaultValue:error:
getNSUIntegerValue:forKey:inOptions:error:
getNSUIntegerValue:forKey:inOptions:withDefaultValue:error:
getOSTypeValue:forKey:inOptions:error:
getOSTypeValue:forKey:inOptions:withDefaultValue:error:
getOptionalArray:forKey:inOptions:withElementsOfClass:error:
getOptionalCanceller:inOptions:error:
getOptionalExplicitProcessingDevice:inOptions:error:
getOptionalObject:ofClass:forKey:inOptions:error:
getOptionalOriginatingRequestSpecifier:forKey:inOptions:specifyingSupportedRevisionsForRequestClass:error:
getOptionalValidatedInputDetectedObjectObservations:forObservationClass:relationWithRegionOfInterest:error:
getOptionalValidatedInputFaceObservations:clippedToRegionOfInterest:error:
getPercentageValue:forKey:inOptions:withDefaultValue:error:
getPrecision:forClassificationIdentifier:confidence:error:
getRecall:forClassificationIdentifier:confidence:error:
getRecognizedLanguages
getReferenceImageBuffer:registrationSignature:forRequestPerformingContext:error:
getRepresentativenessForFaces:error:
getRequiredObject:ofClass:forKey:inOptions:error:
getSignatureData
getStoredRepresentationTag:forModelVersion:error:
getSuggestedImageSize:
getTitle
getTopLeftPoint:topRightPoint:bottomRightPoint:bottomLeftPoint:inTopLeftOrigin:orientation:
getTranscript
getUUIDBytes:
getValue:size:
getVotingHistogram:colorProfileContext:startCC:rowStartLocation:
getWidth:height:ofBlobNamed:forNetworkModelFileWithName:error:
getWidth:height:ofBlobNamed:forNetworkModelFileWithPath:error:
getWidth:height:ofEspressoModelNetworkBlobNamed:error:
globalSegmentationMask
globalSession
groupEndpoints:finalCharBoxCoordCount:
groupedClusteredFaceIdsForCluster
hairColorCategory
harmoniousColorScore
hasAdjustmentForKey:
hasCancellationHook
hasEquivalentDescriptorToImageprint:
hasLabel
hasLocation
hasMinimumPrecision:forRecall:
hasMinimumRecall:forPrecision:
hasModelEquivalencyToRequestSpecifier:
hasObjDetNet
hasPrecisionRecallCurve
hasPrefix:
hasSliderNet
hasSuffix:
hasWarnings
hash
hashData
hashString
height
hierarchicalModelAndReturnError:
idealDimension
idealImageFormat
idealOrientation
identifier
image
imageBufferAndReturnError:
imageBufferValue
imageByApplyingCGOrientation:
imageByApplyingFilter:withInputParameters:
imageByApplyingOrientation:
imageByApplyingTransform:
imageByApplyingTransform:highQualityDownsample:
imageByClampingToExtent
imageByColorMatchingColorSpaceToWorkingSpace:
imageByCompositingOverImage:
imageByCroppingToRect:
imageByPremultiplyingAlpha
imageByUnpremultiplyingAlpha
imageCVPixelBuffer
imageCropAndScaleOption
imageFilePath
imageNeuralHashprint
imageReaderRecognitionOptionsForProcessOptions:
imageRegistrationDescriptor
imageSignatureHash
imageSignatureHashType
imageSignatureprint
imageSignatureprintType
imageSignaturnprintByRunningNeuralHashprintRequest:error:
imageWithCVImageBuffer:
imageWithCVPixelBuffer:
imageWithContentsOfURL:
imageWithData:options:
imageprint
imageprintVersion
immersivenessScore
importantClasses
inHierarchy
indeterminate
indexAtPosition:
indexOfEntityWithUniqueIdentifier:
indexOfObject:
indexOfObject:inSortedRange:options:usingComparator:
indexOfObjectPassingTest:
indexPath
indexPathByAddingIndex:
indexPathWithIndex:
indexSet
indexSetWithIndexesInRange:
indexType
indexesOfObjectsPassingTest:
inferenceNetworkIdentifiers
information
informationForModelWithData:error:
informationForModelWithURL:error:
init
initDumpDebugIntermediates:debugInfo:
initForReadingFromData:error:
initRequiringSecureCoding:
initToMemory
initWithArray:
initWithArray:copyItems:
initWithBCSDetectedCode:description:observation:
initWithBatchNumber:channels:width:height:
initWithBooleanBytes:length:
initWithBooleanBytesData:
initWithBoundingBox:
initWithBox:defaultBox:confidence:scale:rotationAngle:yawAngle:hasLabel:label:
initWithBox:defaultBox:confidence:scale:rotationAngle:yawAngle:mergesCount:
initWithBox:defaultBox:confidence:scale:rotationAngle:yawAngle:mergesCount:hasLabel:label:
initWithBox:defaultBox:confidence:scale:rotationAngle:yawAngle:pitchAngle:hasLabel:label:
initWithBox:defaultBox:confidence:scale:rotationAngle:yawAngle:pitchAngle:mergesCount:hasLabel:label:
initWithBuffer:forKey:originalFeatureProvider:
initWithBytes:length:
initWithBytes:objCType:
initWithBytesNoCopy:length:
initWithBytesNoCopy:length:freeWhenDone:
initWithCGImage:
initWithCGImage:options:
initWithCGImage:options:session:
initWithCGImage:orientation:options:
initWithCGImage:orientation:options:session:
initWithCIImage:options:
initWithCIImage:options:session:
initWithCIImage:orientation:options:
initWithCIImage:orientation:options:session:
initWithCMSampleBuffer:options:session:
initWithCMSampleBuffer:orientation:options:
initWithCMSampleBuffer:orientation:options:session:
initWithCVPixelBuffer:
initWithCVPixelBuffer:options:
initWithCVPixelBuffer:options:session:
initWithCVPixelBuffer:orientation:options:
initWithCVPixelBuffer:orientation:options:session:
initWithCVPixelBufferImage:externalImageId:andExifTimestampString:error:
initWithCVPixelBufferImage:externalImageId:andExifTimestampValue:error:
initWithCachingBehavior:
initWithCapacity:
initWithCenter:diameter:
initWithCenter:radius:
initWithCoder:
initWithCompletionHandler:
initWithConfiguration:
initWithConfiguration:dataSource:
initWithConfiguration:faceModel:
initWithConfiguration:trainedModel:
initWithConfigurationOptions:
initWithContentsOfURL:
initWithDDScannerResult:observation:
initWithData:
initWithData:elementCount:elementType:lengthInBytes:confidence:originatingRequestSpecifier:
initWithData:elementCount:elementType:lengthInBytes:confidence:requestRevision:
initWithData:elementCount:elementType:lengthInBytes:faceprintConfidence:torsoprintConfidence:
initWithData:elementCount:elementType:lengthInBytes:faceprintConfidence:torsoprintConfidence:originatingRequestSpecifier:
initWithData:elementCount:elementType:lengthInBytes:imageSignatureHashType:requestRevision:
initWithData:elementCount:elementType:lengthInBytes:imageSignatureprintType:originatingRequestSpecifier:
initWithData:elementCount:elementType:lengthInBytes:imageSignatureprintType:requestRevision:
initWithData:elementCount:elementType:lengthInBytes:labelsAndConfidence:originatingRequestSpecifier:
initWithData:elementCount:elementType:lengthInBytes:labelsAndConfidence:requestRevision:
initWithData:elementCount:elementType:lengthInBytes:requestRevision:
initWithData:forKey:
initWithData:options:
initWithData:options:session:
initWithData:orientation:options:
initWithData:orientation:options:session:
initWithDataPointer:shape:dataType:strides:deallocator:error:
initWithDescriptorData:elementType:elementCount:originatingRequestSpecifier:
initWithDetectedObjectObservation:
initWithDetectedObjectObservation:completionHandler:
initWithDetectorDescriptorIdentifierVersionTuples:descriptorIdentifierToVersionsArray:
initWithDetectorModel:
initWithDetectorType:configuration:
initWithDetectorType:groupingConfiguration:
initWithDevice:filterDescriptor:
initWithDevice:kernelWidth:kernelHeight:
initWithDevice:thresholdValue:maximumValue:linearGrayColorTransform:
initWithDictionary:
initWithDictionary:copyItems:
initWithDimensions:
initWithDispatchQueueLabel:maximumTasksCount:
initWithDomain:code:userInfo:
initWithEntityIdentificationModel:dataSource:
initWithEntityPrintOriginatingRequestSpecifier:
initWithEspressoNetwork:espressoPlan:threshold:
initWithFace:
initWithFaceIDModel:entityPrintOriginatingRequestSpecifier:entityUniqueIdentifiers:entityPrintCounts:
initWithFaceIDModel:entityPrintOriginatingRequestSpecifier:maximumElementsPerID:entityUniqueIdentifiers:entityPrintCounts:
initWithFaceIDModel:faceprintRequestRevision:maximumElementsPerID:personUniqueIdentifierToSerialNumberMapping:
initWithFaceIDModel:faceprintRequestRevision:personUniqueIdentifierToSerialNumberMapping:
initWithFaceObservation:predictedPersonUniqueIdentifier:confidence:
initWithFaceObservations:
initWithFaceObservations:completionHandler:
initWithFaceprint:torsoPrint:originatingRequestSpecifier:
initWithFaceprint:torsoPrint:requestRevision:
initWithFaceprint:torsoprint:
initWithFrameAnalysisSpacing:completionHandler:
initWithFrameAnalysisSpacing:trajectoryLength:
initWithFrameAnalysisSpacing:trajectoryLength:completionHandler:
initWithFrameRate:
initWithFrameworkBundleIdentifier:
initWithHashData:
initWithIdealFormat:pixelsWideRange:pixelsHighRange:aspectRatioHandling:idealOrientation:orientationAgnostic:
initWithIdealFormat:width:height:orientation:aspectRatioHandling:orientationAgnostic:
initWithIdentifiers:
initWithImageBuffer:regionOfInterest:error:
initWithImageChannels:width:height:
initWithImageCropAndScaleOption:
initWithImageData:andCustomQualityScore:context:error:
initWithImageData:context:error:
initWithImageDescriptor:type:originatingRequestSpecifier:
initWithImageSignatureprintType:imageSignatureHashType:
initWithImageSignatureprintType:imageSignatureHashType:completionHandler:
initWithIndex:
initWithIndexes:length:
initWithIndexesInRange:
initWithInputParameters:
initWithJSFile:binSerializerId:context:computePath:
initWithJSFile:context:computePath:
initWithKernelName:
initWithKernelName:inputParameters:
initWithKeyOptions:valueOptions:capacity:
initWithLabelToOperationPointsDataIndexMap:operationPointsDataArray:
initWithLocation:
initWithLocation:confidence:
initWithLocation:confidence:identifier:
initWithMLModel:error:
initWithMajor:
initWithMajor:minor:
initWithMajor:minor:micro:
initWithMappedModel:
initWithMetalContext:width:height:numScales:error:
initWithMetalDevice:
initWithMinimumDimension:maximumDimension:idealDimension:
initWithModel:
initWithModel:completionHandler:
initWithModelConfiguration:
initWithModelName:networkConfigurationName:network:plan:context:
initWithModelPath:espressoEngineID:espressoDeviceID:espressoStorageType:threshold:
initWithName:dataType:shape:
initWithName:pixelFormatType:pixelWidth:pixelHeight:
initWithNetwork:
initWithNetwork:filterThresholds:
initWithNetworkFileURL:version:networkHeadVersions:inputImage:faceprintOutput:confidencesOutput:
initWithNetworkFileURL:version:networkHeadVersions:inputImage:outputs:confidencesOutput:
initWithNetworkFileURL:version:networkHeadVersions:inputs:outputs:inputImages:confidencesOutput:
initWithObjectType:boundingBox:confidence:
initWithObjectType:boundingBox:confidence:rotationAngle:yawAngle:pitchAngle:labelKey:
initWithObjects:
initWithObjects:count:
initWithObjectsAndKeys:
initWithObservation:entityUniqueIdentifier:confidence:
initWithOperationPoints:
initWithOperationPointsCache:originatingRequestSpecifier:
initWithOptions:
initWithOptions:error:
initWithOptions:logEnabled:
initWithOptions:logEnabled:logFileNameBase:
initWithOptions:model:error:
initWithOriginalRequests:
initWithOriginalRequests:requestToObservationClassMap:
initWithOriginatingRequestSpecifier:
initWithOriginatingRequestSpecifier:adjustments:
initWithOriginatingRequestSpecifier:allRecognizedPoints:
initWithOriginatingRequestSpecifier:boundingBox:
initWithOriginatingRequestSpecifier:boundingBox:confidence:labels:animalprint:
initWithOriginatingRequestSpecifier:boundingBox:confidence:labels:segmentationMask:
initWithOriginatingRequestSpecifier:boundingBox:upperBodyOnly:confidence:
initWithOriginatingRequestSpecifier:detectionLevel:
initWithOriginatingRequestSpecifier:detectionprint:
initWithOriginatingRequestSpecifier:faceBoundingBox:
initWithOriginatingRequestSpecifier:faceBoundingBox:points:pointCount:
initWithOriginatingRequestSpecifier:faceBoundingBox:pointsClassification:points:pointCount:precisionEstimatesPerPoint:
initWithOriginatingRequestSpecifier:featureName:CVPixelBuffer:
initWithOriginatingRequestSpecifier:featureName:featureValue:
initWithOriginatingRequestSpecifier:fingerprintHashes:
initWithOriginatingRequestSpecifier:identifier:confidence:
initWithOriginatingRequestSpecifier:identifier:confidence:operationPointsProvider:
initWithOriginatingRequestSpecifier:imageNeuralHashprint:
initWithOriginatingRequestSpecifier:imageSignatureprint:imageSignatureHash:
initWithOriginatingRequestSpecifier:keypointReturningObservation:
initWithOriginatingRequestSpecifier:overallAestheticScore:wellFramedSubjectScore:wellChosenBackgroundScore:tastefullyBlurredScore:sharplyFocusedSubjectScore:wellTimedShotScore:pleasantLightingScore:pleasantReflectionsScore:harmoniousColorScore:livelyColorScore:pleasantSymmetryScore:pleasantPatternScore:immersivenessScore:pleasantPerspectiveScore:pleasantPostProcessingScore:noiseScore:failureScore:pleasantCompositionScore:interestingSubjectScore:intrusiveObjectPresenceScore:pleasantCameraTiltScore:lowKeyLightingScore:
initWithOriginatingRequestSpecifier:pointsData:pointCount:constellation:precisionEstimatesPerPoint:userFacingBBox:alignedBBox:landmarkScore:
initWithOriginatingRequestSpecifier:pointsData:pointCount:userFacingBBox:alignedBBox:landmarkScore:
initWithOriginatingRequestSpecifier:rawSaliencyImage:originalImageSize:salientObjectBoundingBoxes:
initWithOriginatingRequestSpecifier:sceneprints:
initWithOriginatingRequestSpecifier:smartCamprints:
initWithOriginatingRequestSpecifier:symbology:descriptor:boundingBox:
initWithOriginatingRequestSpecifier:symbology:descriptor:topLeft:bottomLeft:bottomRight:topRight:
initWithOriginatingRequestSpecifier:topLeft:bottomLeft:bottomRight:topRight:
initWithOriginatingRequestSpecifier:topLeft:bottomLeft:bottomRight:topRight:boundingBox:
initWithOriginatingRequestSpecifierProcessingOptionKey:originalRequestResultsIndex:
initWithParentRequest:orderedChildRequests:
initWithPayload:isCompact:layerCount:dataCodewordCount:
initWithPayload:isCompact:rowCount:columnCount:
initWithPersonsModel:dataSource:
initWithPixelFormatType:width:height:
initWithPlatform:
initWithPoint:
initWithPoint:completionHandler:
initWithPoints:topLevelIndex:indexPath:aspectRatio:
initWithR:theta:
initWithRawColorGaborDescriptor:
initWithRawData:confidence:requestRevision:
initWithRawImageprintDescriptor:
initWithRectangleObservation:
initWithRectangleObservation:completionHandler:
initWithRequest:error:
initWithRequest:observationsCacheKey:
initWithRequestClass:
initWithRequestClass:name:code:revision:
initWithRequestRevision:
initWithRequestRevision:CRImageReaderOutput:
initWithRequestRevision:boundingBox:
initWithRequestRevision:boundingBox:confidence:labels:
initWithRequestRevision:crOutputRegion:
initWithRequestRevision:identifier:confidence:
initWithRequestRevision:identifier:confidence:operationPointsProvider:
initWithRequestRevision:outputBufferWidth:outputBufferHeight:outputBufferData:numberOfFaceSegments:faceSegmentBBox:faceSegmentLabelToProbabilityMap:
initWithRequestRevision:regionMap:deallocateBuffer:userBBox:alignedBBox:valueToLabelMap:
initWithRequestRevision:sceneprints:
initWithRequestRevision:smartCamprints:
initWithRequestRevision:topLeft:bottomLeft:bottomRight:topRight:
initWithSceneObservation:
initWithSceneObservation:completionHandler:
initWithScenePrint:dataType:forKey:originalFeatureProvider:
initWithSession:
initWithSession:imageBuffer:
initWithSession:requestPerformer:imageBuffer:forensics:observationsCache:
initWithSession:requestPerformer:imageBuffer:forensics:observationsCache:qosClass:
initWithShape:dataType:error:
initWithSignatureData:
initWithSizes:count:
initWithState:error:
initWithStatus:error:
initWithSubrequests:
initWithSubrequests:uniqueObservationClasses:
initWithTargetedCGImage:options:
initWithTargetedCGImage:options:completionHandler:
initWithTargetedCGImage:orientation:options:
initWithTargetedCGImage:orientation:options:completionHandler:
initWithTargetedCIImage:options:
initWithTargetedCIImage:options:completionHandler:
initWithTargetedCIImage:orientation:options:
initWithTargetedCIImage:orientation:options:completionHandler:
initWithTargetedCMSampleBuffer:options:
initWithTargetedCMSampleBuffer:options:completionHandler:
initWithTargetedCMSampleBuffer:orientation:options:
initWithTargetedCMSampleBuffer:orientation:options:completionHandler:
initWithTargetedCVPixelBuffer:options:
initWithTargetedCVPixelBuffer:options:completionHandler:
initWithTargetedCVPixelBuffer:orientation:options:
initWithTargetedCVPixelBuffer:orientation:options:completionHandler:
initWithTargetedImageBuffer:completionHandler:
initWithTargetedImageData:options:
initWithTargetedImageData:options:completionHandler:
initWithTargetedImageData:orientation:options:
initWithTargetedImageData:orientation:options:completionHandler:
initWithTargetedImageURL:options:
initWithTargetedImageURL:options:completionHandler:
initWithTargetedImageURL:orientation:options:
initWithTensorsDictionary:originatingRequestSpecifier:
initWithTensorsDictionary:requestRevision:
initWithTimeInterval:
initWithTopLeft:bottomLeft:bottomRight:topRight:
initWithTopLevelRegion:requestRevision:
initWithType:cachePath:state:readOnly:threshold:requestRevision:error:
initWithType:cachePath:state:readOnly:threshold:requestRevision:torsoprintRequestRevision:error:
initWithType:cachePath:state:readOnly:threshold:torsoThreshold:requestRevision:error:
initWithType:cachePath:state:readOnly:threshold:torsoThreshold:requestRevision:torsoprintRequestRevision:error:
initWithType:cachePath:state:threshold:
initWithType:cachePath:state:threshold:requestRevision:
initWithType:cachePath:state:threshold:requestRevision:error:
initWithType:cachePath:state:threshold:requestRevision:torsoprintRequestRevision:error:
initWithType:cachePath:state:threshold:torsoThreshold:
initWithType:cachePath:state:threshold:torsoThreshold:requestRevision:
initWithType:cachePath:state:threshold:torsoThreshold:requestRevision:error:
initWithType:cachePath:state:threshold:torsoThreshold:requestRevision:torsoprintRequestRevision:
initWithType:cachePath:state:threshold:torsoThreshold:requestRevision:torsoprintRequestRevision:error:
initWithURL:
initWithURL:append:
initWithURL:options:
initWithURL:options:session:
initWithURL:orientation:options:
initWithURL:orientation:options:session:
initWithUTF8String:
initWithUUIDBytes:
initWithUUIDString:
initWithVCPHandObservation:originatingRequestSpecifier:
initWithVCPPersonObservation:originatingRequestSpecifier:
initWithVImage:externalImageId:andExifTimestampString:error:
initWithVImage:externalImageId:andExifTimestampValue:error:
initWithVectorHead:tail:
initWithVersion:algorithm:lastModificationDate:readOnly:
initWithVersion:lastModificationDate:algorithm:readOnly:
initWithX:y:
initWithXComponent:yComponent:
initialize
initializeBuffers
initializeEspressoResourcesWithModelPath:espressoEngineID:espressoDeviceID:espressoStorageType:
initializeForImage:
initializeLogging
initializeOutputConfidenceBuffers:
inliersRatioThreshold
innerLips
inputBGR
inputBiasRGB
inputBlobNames
inputContrast
inputDescriptionsByName
inputFaceObservations
inputFactor1
inputFactor2
inputFactor3
inputFactor4
inputImage
inputImageAspectRatio
inputImageAspectRatioHandling
inputImageAspectRatioHandlingForConfigurationOptions:
inputImageBlobName
inputImageBlobNameForConfiguration:
inputImageFeatureName
inputImageFormat
inputImageHeight
inputImageKey
inputImageMaxDimension
inputImageMinDimension
inputImageSize
inputLayerName
inputMaskBlobName
inputMaskRequired
inputNamed:error:
inputObservation
inputPivot
inputPoint
inputScale
inputScenePrintKey
inputScenePrintMLMultiArrayDataType
inputSignatureprint
inputStreamWithURL:
insertObject:atIndex:
insertString:atIndex:
instanceMethodForSelector:
instanceSegmentationMask
instancesRespondToSelector:
intValue
integerValue
interestingSubjectScore
internalCancelInContext:error:
internalParabolas
internalParams
internalPerformRevision:inContext:error:
internalProcessUsingQualityOfServiceClass:options:regionOfInterest:warningRecorder:error:progressHandler:
intersectSet:
intersectionOverArea:
intersectionOverMinArea:
intrusiveObjectPresenceScore
invalidVersion
ioSurfaceBackedPixelBufferAttributes
ioSurfaceMemoryPoolId
isAllowedDimension:
isAnchorSquare
isBlinking
isBoundingBoxAligned
isCRImageReaderViableAfterError:
isCVPixelBuffer:equalToCVPixelBuffer:
isCompatibleWithConfiguration:
isDetectedObject:ofAGivenObjectSubClass:
isEqual:
isEqualToDate:
isEqualToDictionary:
isEqualToResourceVersion:
isEqualToSet:
isEqualToString:
isEquivalentToVNEntityIdentificationModelPrint:
isFullCoverageRegionOfInterest
isImageprintValid
isKindOfClass:
isLastFrame
isLogEnabled
isMajorVersion:equalToMajorVersion:
isMemberOfClass:
isMinorVersion:equalToMinorVersion:
isOrientationAgnostic
isOverlappingLowMergeDet:withOverlapThreshold:withMergeCountDelta:
isOverlappingSmallFace:withOverlapThreshold:withSizeRatio:
isPrint:compatibleWithOtherPrint:error:
isReadOnly
isReadableFileAtPath:
isReentrant
isResettable
isRevision1DetectedRectanglesCompatible
isSubclassOfClass:
isSubsetOfSet:
isTracking
isUserFacingBBoxEquivalentToAlignedBBox
isValidFaceprint
isValidTorsoprint
keepNetworkOutput
keepRawOutputMask
kernelWithFunctionName:fromMetalLibraryData:error:
keyEnumerator
keyForDetectorWithConfigurationOptions:
keypoints
keypointsMultiArrayAndReturnError:
knownAnimalHeadIdentifiers
knownAnimalIdentifiers
knownAnimalIdentifiersForRevision:error:
knownClassificationsForRevision:error:
knownFoodAndDrinkIdentifiers
knownObjectIdentifiersRecognizedByRequestRevision:error:
knownSceneClassifications
knownSceneClassificationsForRevision:error:
knownSportBallIdentifiers
knownTensorKeysForRequestRevision:error:
l1ClusteredFaceIdsGroupedByL0ClustersForClustersContainingFaceIds:error:
label
labelKey
labelNames
labels
labelsAndConfidence
landmarkDetectorDNNVersion
landmarkPointSizeInBytes
landmarkPoints
landmarkPoints3d
landmarkPoints65
landmarkPrecisionEstimatesPerPoint
landmarkScore
landmarks
landmarks3DOriginatingRequestSpecifier
landmarks3d
landmarks65
landmarksConstellation
landmarksMeshPartsForConstellation:
landmarksOriginatingRequestSpecifier
lastDataChangeSequenceNumberForEntityIdentificationModel:
lastDataChangeSequenceNumberForPersonsModel:
lastFrame
lastIndex
lastModificationDate
lastModificationDateForEntityIdentificationModel:
lastObject
lastPathComponent
layers_size
leafSubclassesOfClass:excludingRootClass:overridingClassSelector:
leafsCount
left
leftEyebrow
leftPupil
legacyFaceCore
legacyForcedCleanupOfFacePipelineWithLevel:
legacyForcedCleanupOfJunkPipelineWithLevel:
legacyForcedCleanupOfScenePipelineWithLevel:
legacyForcedCleanupOfSmartCamPipelineWithLevel:
length
lengthInBytes
level
levelCount
lines
linkTimeOrRunTimeAtLeastVersion:
livelyColorScore
load:
loadFromIdentifier:error:
loadFromPropertyList:error:
loadFromURL:error:
loadRefinersAndReturnError:
localeWithLocaleIdentifier:
localizedDescription
localizedFailureReason
localizedStringForKey:value:table:
localizedStringFromDate:dateStyle:timeStyle:
locateMode
locateRPNTrackerResourcesConfiguredForOptions:error:
location
locationInTopLeftOrigin:orientation:
lock
logAllSuggestons:
logClusterLookupMapL0:
logClusterLookupMapL1:
logClusterMap:level:
logClusterMapL0:
logClusterMapL1:
logConnectedGroups:
logEnabled
logFileURL
logFilteredByInputQuerySuggestons:
logFinalSuggestionsList:
logFolderURL
logInputFaceIdsWithFlags:
logInternalError:
logString:
logSuggestons:description:
longLongValue
longValue
lookedAtFaceObservationUUID
loopBigBox
loopBigBoxPrev
lowKeyLightingScore
lowPriorityCIContext
mClassifier
mDescriptorProcessor
mFaceBoxAlignerModelFileHandle
mFaceBoxPoseAlignerImpl
mFaceRegionMapAlgorithmImpl
mJunkClassifierImpl
mJunkDescriptorImpl
mTop
mTrackerImpl
m_ClusteringImpl
m_ClusteringImpl_const
m_FaceAttributesImpl
m_impl
machineReadableCodeElements
magnifiedBBoxScaleFactor
mainBundle
mainCIContext
mainCIContextMetalDevice
major
makeAllocationsForWidth:
makeClippedRectAgainstImageExtentUsingOriginalRect:
makeupCategory
makeupEyesCategory
makeupLipsCategory
maskConfidenceForOutputMaskBlobName:
matchedString
maxBoxWidth
maxHeight
maxTotalThreadsPerThreadgroup
maximumAllowableEntities
maximumAllowableFaceprintsPerIdentity
maximumAllowableIdentities
maximumAllowedTasksInTheQueue
maximumAspectRatio
maximumCandidateCount
maximumDimension
maximumFaceIdInModelAndReturnError:
maximumHandCount
maximumIdentities
maximumImageDimension
maximumIntermediateSideLength
maximumLeafObservations
maximumObjectSize
maximumObservations
maximumProcessingDimensionOnTheLongSide
maximumTasksCount
maximumTrainingFaceprintsPerIdentity
maximumTrainingPrintsPerEntity
maximumValueFromFloat32ImageBuffer:
medianHeightBottom
medianLine
memoryPoolId
mergeBoxes:
mergeHeadsBoxes:
mergesCount
metalContext
metalContextPriority
metalDevice
methodForSelector:
micro
midRow
minBoxWidth
minHeight
minimizeFalseDetections
minimumAspectRatio
minimumCharacterPixelHeight
minimumConfidence
minimumDimension
minimumFaceDimension
minimumLatencyFrameCount
minimumObjectSize
minimumSize
minimumTextHeight
minimumTorsoInsideInputImageThreshold
minor
minusOrderedSet:
minusSet:
mmHeightCard
mmWidthCard
model
modelBuiltFromConfiguration:dataProvider:canceller:error:
modelCachingIdentifier
modelConfigurationForVersion:modelObjects:error:
modelDescription
modelFileBackingStore
modelForMLModel:error:
modelForRequestClass:revision:
modelFromData:options:error:
modelFromPersonsModel:error:
modelFromStream:options:error:
modelFromURL:options:error:
modelName
modelNameForConfiguration:
modelNonMaximumSuppressionThreshold
modelType
modelVersionForOptions:
modelVersionIDForConfigurationOptions:
modelWithConfiguration:dataSource:error:
modelWithConfiguration:error:
modifySmallFaceThrehold:withHeight:andWidth:
mouth
moveItemAtPath:toPath:error:
movingAverageRadius
mrcDescriptor
multiArrayConstraint
mumberBinsNegativeMaxout
mumberPosClasses
mutableBytes
mutableCopy
name
nameConfidence
narrowedBoundingBox
naturalClusteringDistanceThreshold
needsMetalContext
networkConfigurationName
networkFileURL
networkRequiredInputImagePixelFormatForConfigurationOptions:
networkRequiredInputImageWidth
networkThreshold
networkVersion
newBarcodeObservationForACBSBarcodeInfo:imageWidth:imageHeight:roiCroppingPixelRect:originatingRequestSpecifier:error:
newBarcodeObservationForMRCDescriptor:roiCroppingPixelRect:originatingRequestSpecifier:error:
newBufferWithLength:options:
newComputePipelineStateWithFunction:error:
newConfiguration
newConfigurationForEntityPrintsGeneratedByRequest:error:
newConfigurationInstance
newDefaultDetectorOptionsForRequestRevision:session:
newDefaultDetectorOptionsForSession:
newDefaultLibraryWithBundle:error:
newDefaultRequestInstance
newFunctionWithName:
newHierarchicalModelAndReturnError:
newImageReaderAndReturnError:
newMetalContextForConfigurationOptions:error:
newModelForVersion:modelObjects:error:
newModelFromVersion:objects:error:
newTextureViewWithPixelFormat:
newTextureWithDescriptor:
newTextureWithDescriptor:iosurface:plane:
nextLeafDescriptorDistance
nextLeafId
nextLeafTimestampDistance
nextLeafTotalDistance
nextObject
nlreg_padding
nlreg_radius
nlreg_sigma_c
nlreg_sigma_l
nlreg_sigma_w
nmsBoxes:
nmsThreshold
node
nodeId
noiseScore
nonGroupedGroupID
nonSquareRollDefault
nonSquareYawDefault
normalizedPath
normalizedPathInTopLeftOrigin:orientation:
normalizedPoints
normalizedPointsInTopLeftOrigin:orientation:
nose
noseCrest
notificationCenter
null
numScales
numWarpings
numberBinsRoll
numberBinsYaw
numberFromString:
numberMaxoutLayers
numberOfEntitiesInEntityIdentificationModel:
numberOfFaceSegments
numberOfImageChannels
numberOfKeypointsToConsider
numberOfPersonsInPersonsModel:
numberWithDouble:
numberWithFloat:
numberWithInt:
numberWithInteger:
numberWithLongLong:
numberWithShort:
numberWithUnsignedChar:
numberWithUnsignedInt:
numberWithUnsignedInteger:
numberWithUnsignedLong:
numberWithUnsignedLongLong:
object:overridesSelector:
objectAtIndex:
objectAtIndexedSubscript:
objectBoundingBoxOutputDescription
objectEnumerator
objectForKey:
objectForKeyedSubscript:
objectMaximumNormalizedRadius
objectMinimumNormalizedRadius
objectType
objectsAtIndexes:
observation
observationAtIndex:forEntityAtIndex:
observationBoundsAreNormalizedToROIForRequestClassCode:revision:
observationCountForEntityAtIndex:
observationCountForEntityWithUniqueIdentifier:
observationCountsForEntitiesWithUniqueIdentifiers:
observationProvidesBoundsNormalizedToROI
observationWithBoundingBox:
observationWithImageprint:error:
observationWithOriginatingRequestSpecifier:
observationWithRequestRevision:boundingBox:
observationWithSceneprints:
observationWithSmartCamprints:
observationsAcceptedByRequest:testedKeyHandler:
observationsCacheKey
observationsForEntityWithUniqueIdentifier:error:
observationsForKey:
observationsForLastAnalysisOfImageAnalyzer:processOptions:originatingRequestSpecifier:qosClass:error:
observationsForSceneLabelsFromLastAnalysisOfImageAnalyzer:identifierAcceptingBlock:operationPointsProvider:originatingRequestSpecifier:qosClass:error:
obtainImageSourceRefWithSubSampleFactor:andLowPriorityHint:error:
olmcsMergeCountDelta
olmcsThreshold
onlyInputImage
open
operationPointsAndReturnError:
opticalFlow
orderedChildRequests
orderedRequestsForRequests:
orderedSetWithCapacity:
orientation
orientationAgnostic
originalObservation
originalPixelBuffer
originalRequestConfigurations
originalRequestResultsIndex
originalRequests
originalRequestsOfClass:
originatingRequestSpecifier
originatingRequestSpecifierForKey:inOptions:error:
originatingRequestSpecifierForKey:inOptions:specifyingSupportedRevisionsForRequestClass:error:
originatingRequestSpecifierForRequestRevision:error:
originatingRequestSpecifierInOptions:error:
originatingRequestSpecifierInOptions:specifyingSupportedRevisionsForRequestClass:error:
originatingRequestSpecifierKey
originatingRequestSpecifierToDetectorClassMap
osfsSizeRatio
osfsThreshold
outerLips
outputBufferData
outputBufferHeight
outputBufferWidth
outputConfidenceBlobNames
outputDescriptionsByName
outputImage
outputMaskBlobNameToRequestKey
outputMaskBlobNames
outputMaskSize
outputNamed:error:
outputPixelFormat
outputRegionWithContentsOfCharacterRange:
overlap:
overlappingLowMergeCountSuppression:
overlappingSmallFacesSuppression:
padStringWithSpaces:toSize:
parabolaSearchBuffer
parentRequest
parseExifTimestamp:
path
pathExtension
pathForEspressoNetworkModelFileWithName:error:
pathForEspressoResource:ofType:error:
pathForEspressoResourceWithFilename:error:
pathForResource:ofType:
pathForResource:ofType:inDirectory:
pathsForResourcesOfType:inDirectory:
payloadDataValue
payloadStringValue
performBlinkDetection
performClustersPostprocessing
performClustersPostprocessing:error:
performDependentRequests:onBehalfOfRequest:inContext:error:
performInContext:error:
performInContextAsync:asyncDispatchQueue:asyncDispatchGroup:
performInPlace
performRequests:error:
performRequests:gatheredForensics:error:
performRequests:inContext:error:
performRequests:onCGImage:error:
performRequests:onCGImage:gatheredForensics:error:
performRequests:onCGImage:orientation:error:
performRequests:onCGImage:orientation:gatheredForensics:error:
performRequests:onCIImage:error:
performRequests:onCIImage:gatheredForensics:error:
performRequests:onCIImage:orientation:error:
performRequests:onCIImage:orientation:gatheredForensics:error:
performRequests:onCMSampleBuffer:error:
performRequests:onCMSampleBuffer:gatheredForensics:error:
performRequests:onCMSampleBuffer:orientation:error:
performRequests:onCMSampleBuffer:orientation:gatheredForensics:error:
performRequests:onCVPixelBuffer:error:
performRequests:onCVPixelBuffer:gatheredForensics:error:
performRequests:onCVPixelBuffer:orientation:error:
performRequests:onCVPixelBuffer:orientation:gatheredForensics:error:
performRequests:onImageData:error:
performRequests:onImageData:gatheredForensics:error:
performRequests:onImageData:orientation:error:
performRequests:onImageData:orientation:gatheredForensics:error:
performRequests:onImageURL:error:
performRequests:onImageURL:gatheredForensics:error:
performRequests:onImageURL:orientation:error:
performSceneClassification
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
performedRequest:withError:
performedRequests
performingOrderedDependentRequests:onBehalfOfRequest:
performingRequest:
personCount
personId
personPredictionsForFace:withDescriptor:limit:canceller:error:
personUniqueIdentifiers
personsModel:faceObservationAtIndex:forPersonAtIndex:
personsModel:indexOfPersonWithUniqueIdentifier:
personsModel:numberOfFaceObservationsForPersonAtIndex:
personsModel:uniqueIdentifierOfPersonAtIndex:
personsModelDataWasModified:
pitch
pitchAngle
pixelBuffer
pixelFormat
pixelHeight
pixelValueSizeInBytesForBuffer:error:
pixelWidth
pixelWidthCard
pixelsHigh
pixelsWide
plan
platform
pleasantCameraTiltScore
pleasantCompositionScore
pleasantLightingScore
pleasantPatternScore
pleasantPerspectiveScore
pleasantPostProcessingScore
pleasantReflectionsScore
pleasantSymmetryScore
pointAtIndex:
pointByApplyingVector:toPoint:
pointCount
pointKeyGroupLabelsMapping
pointValue
points
pointsClassification
pointsData
pointsInImageOfSize:
polygonApproximationWithEpsilon:error:
polygonList
populateDetectorProcessingOptions:session:
populateVCPVideoProcessorRequestConfiguration:
populatedMLMultiArrayAndReturnError:
posLL
posLR
posUL
posUR
pose
poseData
poseQuaternion
poseSquare
postNotificationName:object:userInfo:
postVisionFeaturePrintModel
postprocessLandmarkResultsForLandmarks:imageBuffer:outputFace:options:warningRecorder:error:
precisionEstimatesPerPoint
precisionRecallThreshold
predicateWithBlock:
predicateWithFormat:
predictPersonFromFaceObservation:limit:canceller:error:
predictWithCVPixelBuffer:options:error:
predictWithScenePrint:options:error:
predictedFeatureKey
predictedFeatureName
predictedProbabilitiesKey
predictedProbabilitiesName
predictionFromFeatures:options:error:
predictionsForObservation:limit:canceller:error:
preferBackgroundProcessing
preferredInputSizeWithOptions:error:
preferredMetalContext
preferredPixelFormat
preferredSmallSide
preheatModelsForOptions:revision:error:
prepareForPerformingRequests:error:
previousLeafDescriptorDistance
previousLeafId
previousLeafTimestampDistance
previousLeafTotalDistance
previousSequencedObservationsAcceptedByRequest:
previousSequencedObservationsForRequest:
primaryInferenceNetworkDescriptorForIdentifier:version:error:
primaryInferenceNetworkDescriptorForVNInferenceNetworkIdentifierFaceprint_3_1_0
primaryInferenceNetworkDescriptorForVNInferenceNetworkIdentifierSceneNetObjDetNetSliderNet_3_0_0
primaryInferenceNetworkDescriptorForVNInferenceNetworkIdentifierSceneNet_3_0_0
primaryInferenceNetworkDescriptorForVNInferenceNetworkIdentifierSceneNet_5_10_0
primaryInferenceNetworkDescriptorForVNInferenceNetworkIdentifierSmartCam_5_0_0
primaryInferenceNetworkDescriptorForVNInferenceNetworkIdentifierStandaloneSceneprint_3_0_0
printCountForEntityWithUniqueIdentifier:
printCountsForAllEntities
printCountsForEntitiesWithUniqueIdentifiers:
printDebugInfo:facesDataRaw:faceDetectorBGRAImage:tempImage:
printWithDescriptorData:elementType:elementCount:originatingRequestSpecifier:error:
printWithFloat16PrecisionFloat32Data:originatingRequestSpecifier:error:
printWithFloat16PrecisionFloat32Values:elementCount:originatingRequestSpecifier:error:
processBoxes:withHeight:andWidth:
processDetectedObject:originatingRequestSpecifier:objectBoundingBox:imageBuffer:qosClass:warningRecorder:detectedObjectResults:error:
processFaceObservations:revision:regionOfInterest:detectorType:detectorOptions:shouldAlignFaceBBox:shouldRunDetectorBlock:context:error:
processInfo
processLockedImageBuffer:inputMaskObservation:options:error:
processRecognizedObjectWithIdentifier:originatingRequestSpecifier:objectBoundingBox:objectConfidence:detectedObjectResults:
processRegionOfInterest:croppedPixelBuffer:options:qosClass:warningRecorder:error:progressHandler:
processUsingQualityOfServiceClass:options:regionOfInterest:warningRecorder:error:progressHandler:
processVImage:inputIsBGR:
processVNImageBuffer:regionOfInterest:withOptions:warningRecorder:requestUUID:error:
processingDevice
processingDeviceDetectorWithEspressoNetwork:espressoPlan:
processingDeviceDetectorWithEspressoNetwork:espressoPlan:networkThreshold:filterThresholds:
processingDeviceDetectorWithEspressoNetwork:espressoPlan:threshold:
processingDeviceDetectorWithModelPath:networkThreshold:filterThresholds:preferredDeviceID:engineID:storageType:
processingDeviceDetectorWithModelPath:preferredDeviceID:engineID:storageType:
processingDeviceNetworkWithModelPath:threshold:preferredDeviceID:engineID:storageType:
profileNormal
projectedPointsInTopLeftOrigin:orientation:
propertyListWithStream:options:format:error:
providesBoundsNormalizedToROI
providesSceneLabels
providesSegmentationLabels
pulseVectorHeightCharBox
pulseVectorHeightCharBoxAdaptive
purgeAll
purgeAllCaches
purgeCacheRepresentationsForOriginalBuffer:
purgeCachedRepresentations
purgeIntermediates
qosClass
quadForTextInCharacterRange:
quadratureTolerance
qualityCriteriaList
qualityLevel
queueLabelWithUniqueAppendix:
queueWithUniqueAppendix:
radius
raise:format:
rangeOfContentRegion:
rangeOfTextBlock:
rangeOfTextBlockObservation:
rank
ratios
rawColorGaborDescriptor
rawConfidence
rawImageprintDescriptor
readObjectForModelVersion:tag:fromInputStream:intoObjectDictionary:md5Context:error:
readObjectForVersion1Tag:fromInputStream:intoObjectDictionary:md5Context:error:
readOnly
reason
recognitionLanguages
recognitionLevel
recognize
recognizeDetectedBlocks:inImage:error:withProgressHandler:
recognizedAnimalHeadObjectClassToAnimalHeadCategoryName
recognizedAnimalObjectClassToAnimalName
recognizedFoodAndDrinkObjectClassToFoodAndDrinkCategoryName
recognizedLanguages
recognizedLocale
recognizedPointForJointName:error:
recognizedPointForKey:error:
recognizedPointsForGroupKey:error:
recognizedPointsForJointsGroupName:error:
recognizedPointsObservationClass
recognizedPointsSpecifier
recognizedSportBallObjectClassToSportBallCategoryName
recordDefaultConfigurationOptionsInDictionary:
recordImageCropQuickLookInfoFromOptions:toObservation:
recordImageCropQuickLookInfoFromOptionsSafe:toObservation:
recordImageCropQuickLookInfoToOptions:cacheKey:imageBuffer:
recordSequencedObservationsForRequest:
recordSequencedObservationsOfRequest:
recordWarning:value:
recordWarningsInOriginalRequests
rectangleObservationWithRequestRevision:topLeft:bottomLeft:bottomRight:topRight:
referenceImageSignature
refineLeftEyeRegion
refineMouthRegion
refineRightEyeRegion
regionLabels
regionNameAtImageCoordinate:imageSize:
regionNameAtNormalizedAlignedFaceCoordinate:
regionNameAtNormalizedFaceCoordinate:
regionOfInterest
regionOfInterestNonIntegralPixelRectForWidth:height:
regionOfInterestPixelRectForWidth:height:
registerModelEquivalencyOf:to:
registerRequestClass:revision:modelEquivalencyToRevision:
registerRequestClassName:revision:modelEquivalencyToRevision:
registerSession:
registryID
relationships
releaseAllQueues
releaseAllocations
releaseCachedResources
releaseCachedResourcesWithCompletionBlock:
releaseDetectorsThatCanBeReplacedByDetectorOfClass:withConfiguration:
releaseMetalDeviceWisdomParameters
releaseResources
removeAllFaceObservationsFromPersonWithUniqueIdentifier:error:
removeAllObjects
removeAllObservationsFromEntityWithUniqueIdentifier:error:
removeCachedBufferWithKey:
removeEntityWithUniqueIdentifier:error:
removeFaceObservations:fromPersonWithUniqueIdentifier:error:
removeIndex:
removeItemAtPath:error:
removeLastObject
removeObject:
removeObjectAtIndex:
removeObjectForKey:
removeObjectIdenticalTo:
removeObjectsAtIndexes:
removeObjectsInArray:
removeObjectsInRange:
removeObservations:fromEntityWithUniqueIdentifier:error:
removePersonWithUniqueIdentifier:error:
removeRequest:error:
render:toBitmap:rowBytes:bounds:format:colorSpace:
render:toCVPixelBuffer:
render:toCVPixelBuffer:bounds:colorSpace:
renderCIImage:width:height:format:processingDevice:error:
renderEspressoBufferImage:intoCVPixelBuffer:error:
replaceCharactersInRange:withString:
reportCharacterBoxes
representativenessById
representativenessForFaces:error:
request:cachedResultsWithObservationsCacheKey:
requestClass
requestClassAndReturnError:
requestClassCode
requestClassName
requestDetectionLevel
requestForcedCleanup
requestForcedCleanupWithOptions:
requestForcedCleanupWithOptions:completion:
requestForensics
requestFrameAnalysisSpacing
requestImageBuffers
requestImageBuffersCacheKeys
requestInfoForRequest:
requestKeyFromRequest:
requestKeyToRequestInfo
requestPropertiesFromRequestKey:
requestTasksQueue
requestThatProvidedObservationsForRequest:
requestUUID
requestsImplicitlyPerformedOnBehalfOfRequest:
requestsThatLookedUpCachedResultsKey:
requiredArrayForKey:inOptions:withElementsOfClass:error:
requiredCancellerInOptions:error:
requiredDetectedObjectObservationInOptions:withOptionName:forObservationClass:error:
requiredFaceObservationInOptions:withOptionName:error:
requiredObjectOfClass:forKey:inOptions:error:
requiredProcessingDeviceInOptions:error:
requiredTargetedImageBufferReturningError:
reset
reset:
resetAsyncStatus
resetBoxBounds
resetFileNameURLWithCurentDateTime
resetModelState:error:
resizeAndProcessVImage:inputIsBGR:
resolvedAlgorithmAndReturnError:
resolvedProcessingDevice
resolvedRevision
resolvedRevisionDidChangeFromRevision:
resolvedRevisionForRevision:
resourcePath
respondsToSelector:
resultsAreAssignedWithOriginatingRequestSpecifier
resultsForPixelBuffer:options:error:
resultsForPixelBuffer:roi:options:error:withProgressHandler:
resultsFromCoreResults:
resultsObtainedFromObservationsCacheForRequest:
retain
retainCount
returnAllResults
returnAllResultsOptionKey
returnMask
revision
revisionAvailability
revisionSupportsFullBodyDetection:
right
rightEye
rightEyebrow
rightPupil
roiAreaThreshold
roll
rotateImageToMatchNetworkOrientation
rotationAngle
rpnInitQueue
rpnTrackQueue
rpnTrackerInitModelName
rpnTrackerInitProcessingQueueName
rpnTrackerTrackModelName
rpnTrackerTrackProcessingQueueName
runNetwork:inputIsBGR:
runSuccessReportingBlockSynchronously:detector:qosClass:error:
runTimeVersion
salientObjects
salientObjectsAndReturnError:
scale
scanCharactersFromSet:intoString:
scanDouble:
scanFloat:
scanInteger:
scanString:intoString:
scanUpToCharactersFromSet:intoString:
scannerResult
scannerWithString:
sceneClassifierDescriptor
sceneLabelOperationPointsForOriginatingRequestSpecifier:error:
sceneLabelsFileName
sceneObservation
scenePrintRevision
sceneprintCurrentVersion
sceneprintVersion
sceneprints
screenGazeRawOutputInCentimeters
segmentationLabelsFileName
segmentationMask
self
sequencedRequestPreviousObservationsKey
serialNumber
serializationMagicNumber
serializeAsVNImageprintStateAndReturnError:
serializeRPNTrackingQueue
serializeStateAndReturnError:
serializeStateIntoData:startingAtByteOffset:error:
serializedLength
sessionAndReturnError:
setACBSBarcodeInfo:
setAcceptableVersions:
setAdditionalCharacters:
setAlgorithm:
setAlignedBoundingBox:
setAlignedMeanShape:
setAlignedRotationAngle:
setAlignmentTransform:
setAllLabelsWithConfidences:
setAllocationSize:
setAngle:
setArray:
setAsyncStatus:error:
setAutomaticallyDetectsLanguage:
setBBottom:
setBTop:
setBackgroundGPUPriority:
setBarcodeRequest:
setBlinkScore:
setBlurDeterminationMethod:
setBlurScore:
setBoundingBoxAligned:
setBoundingBoxFromQuadrilateralPointsAtTopLeft:topRight:bottomRight:bottomLeft:
setBounds:
setBuffer:offset:atIndex:
setBytes:length:atIndex:
setCachePath:
setCachedImageReader:
setCadence:
setCancellationSemaphore:
setCascadeStepCount:
setCharBoxContext:
setCharBoxFlags:
setCharacterBoxes:
setCharboxROIFullVectorRowStart:
setClass:forClassName:
setClusterId:
setClusterSplitDistanceType:
setClusterState:
setClusteredFaceIds:
setClusters:
setCommonGazeLocationRadius:
setComputationAccuracy:
setComputePipelineState:
setComputeZCVectorHighProbability:
setConfidence:
setConstellation:
setContext:
setContrastAdjustment:
setContrastPivot:
setCropResult:
setCustomHierarchy:
setDateFormat:
setDebugFilename:
setDebugMode:
setDebugOut:
setDecodingFailurePolicy:
setDefaultBox:
setDefaultSymbologiesForRevision:
setDelegate:
setDescriptor:
setDetectDarkOnLight:
setDetectDiacritics:
setDetectedBarcodeSupportCode:
setDetectionLevel:
setDetectionOnly:
setDetectorConfigurationOption:value:
setDetectorConfigurationOptions:
setDetectorExecutionTimeInterval:
setDetectorPreferredImageSize:
setDetectorType:
setDetectorWantsAnisotropicScaling:
setDetectsDarkOnLight:
setDistance:
setDistancesById:
setExposureScore:
setExpressionsAndScores:
setFaceAttributes:
setFaceBoundingBoxExpansionRatio:
setFaceCaptureQuality:
setFaceCoreEnhanceEyesAndMouthLocalization:
setFaceCoreExtractBlink:
setFaceCoreExtractSmile:
setFaceCoreInitialAngle:
setFaceCoreKalmanFilter:
setFaceCoreMinFaceSize:
setFaceCoreNumberOfDetectionAngles:
setFaceCoreType:
setFaceDetectionPrecisionRecallThreshold:
setFaceId:
setFaceIdConfidence:
setFaceJunkinessIndex:
setFaceOrientationIndex:
setFaceRegionMap:
setFaceScreenGaze:
setFaceSegments:
setFaceTorsoprint:
setFaceprint:
setFaceprintInputPath:
setFaceprintRequestRevision:
setFeatureProvider:
setFilterThresholds:
setFilterWalkUpDownCount:
setFlag:atIndex:
setFloatVectorSumProd:
setFloatingImageSignature:
setForceFaceprintCreation:
setForceUseInputCVPixelBufferDirectly:
setFrameAnalysisSpacing:
setFreeImageInDealloc:
setFreeNodeOnDealloc:
setGaze:
setGazeHeatMapThreshold:
setGenerateSegmentationMask:
setGreedyClustererFaces_const:
setGroupedClusteredFaceIdsForCluster:
setHasLabel:
setIdentifier:
setIi:
setImageCropAndScaleOption:
setImageFilePath:
setImageSignatureHashType:
setImageSignatureprintType:
setImageprint:
setIndexType:
setInliersRatioThreshold:
setInputContrast:
setInputDetectedObjectObservations:
setInputFaceObservations:
setInputFactor1:
setInputFactor2:
setInputFactor3:
setInputFactor4:
setInputImage:
setInputImageFeatureName:
setInputImageKey:
setInputObservation:
setInputPivot:
setInputPoint:
setInputScenePrintKey:
setInputShape:height:
setInputSignatureprint:
setInputTextBlocks:
setIoSurfaceMemoryPoolId:
setIsBlinking:
setIsTitle:
setIsValid:
setKeepNetworkOutput:
setKeepRawOutputMask:
setLabel:
setLabelKey:
setLandmark3DPointsData:originatingRequestSpecifier:
setLandmarkPoints65Data:originatingRequestSpecifier:
setLandmarkPointsData:originatingRequestSpecifier:
setLandmarkPrecisionEstimatesPerPoint:
setLandmarkScore:
setLandmarks:
setLandmarksConstellation:
setLastFrame:
setLastTrackedBBox:
setLegacyFaceCore:
setLength:
setLineWidth:
setLocale:
setLocateMode:
setLoopBigBox:
setLoopBigBoxPrev:
setMBottom:
setMRCDescriptor:
setMTop:
setMaxHeight:
setMaximumAspectRatio:
setMaximumCandidateCount:
setMaximumEntities:
setMaximumHandCount:
setMaximumHierarchicalObservations:
setMaximumIdentities:
setMaximumImageDimension:
setMaximumIntermediateSideLength:
setMaximumLeafObservations:
setMaximumObjectSize:
setMaximumObservations:
setMaximumProcessingDimensionOnTheLongSide:
setMaximumTasksCount:
setMaximumTrainingFaceprintsPerIdentity:
setMaximumTrainingPrintsPerEntity:
setMedianHeightBottom:
setMedianHeightTop:
setMemoryPoolId:
setMetalContextPriority:
setMidRow:
setMinHeight:
setMinimizeFalseDetections:
setMinimumAspectRatio:
setMinimumCharacterHeight:
setMinimumConfidence:
setMinimumFaceDimension:
setMinimumObjectSize:
setMinimumTextHeight:
setMmHeightCard:
setModel:
setModelCachingIdentifier:
setModelFileBackingStore:
setModelMinimumDetectionConfidence:
setModelNonMaximumSuppressionThreshold:
setModelType:
setMrcDescriptor:
setNaturalClusteringDistanceThreshold:
setNextLeafDescriptorDistance:
setNextLeafId:
setNextLeafTimestampDistance:
setNextLeafTotalDistance:
setNlreg_padding:
setNlreg_radius:
setNlreg_sigma_c:
setNlreg_sigma_l:
setNlreg_sigma_w:
setNmsThreshold:
setNode:
setObject:atIndexedSubscript:
setObject:forKey:
setObject:forKeyedSubscript:
setObjectMaximumNormalizedRadius:
setObjectMinimumNormalizedRadius:
setObjectType:
setObjects:
setObservations:forKey:
setOlmcsMergeCountDelta:
setOlmcsThreshold:
setOrderedRequests:
setOriginalObservation:
setOriginalRequestConfigurations:
setOsfsSizeRatio:
setOsfsThreshold:
setOutputFormat:
setOutputObjectTypes:
setOutputPixelFormat:
setOutputUV:error:
setPerformBlinkDetection:
setPerformClustersPostprocessing:
setPerformInPlace:
setPerformSceneClassification:
setPersonId:
setPitch:
setPitchAngle:
setPixelHeightCard:
setPixelWidthCard:
setPlatform:
setPoints:
setPosLL:
setPosLR:
setPosUL:
setPosUR:
setPoseData:originatingRequestSpecifier:
setPrecisionEstimatesPerPoint:
setPrecisionRecallThreshold:
setPredictedFeatureKey:
setPreferBackgroundProcessing:
setPreferredMetalContext:
setPreviousLeafDescriptorDistance:
setPreviousLeafId:
setPreviousLeafTimestampDistance:
setPreviousLeafTotalDistance:
setProcessedResults:
setProcessingDevice:
setProfile:
setProfileNormal:
setProgressHandler:
setPulseVectorHeightCharBox:
setPulseVectorHeightCharBoxAdaptive:
setQuadratureTolerance:
setQualityCriteriaList:
setQualityLevel:
setReadOnly:
setRecognitionLanguage:
setRecognitionLanguages:
setRecognitionLevel:
setRecognize:
setReferenceImageSignature:
setRefineLeftEyeRegion:
setRefineMouthRegion:
setRefineRightEyeRegion:
setRegionLabels:
setRegionOfInterest:
setReportCharacterBoxes:
setRepresentativenessById:
setRequestImageBuffers:
setRequestImageBuffersCacheKeys:
setRequestRevision:
setRequiredVersion:
setRequiresSecureCoding:
setResolvedRevision:
setResourcePath:
setResults:
setResults:assignedWithOriginatingSpecifier:
setReturnAllResults:
setReturnMask:
setReturnSubFeatures:
setRevision:
setRevision:error:
setRoiAreaThreshold:
setRoll:
setRotationAngle:
setScale:
setScannerResult:
setSceneObservation:
setShortDescription:
setShouldUpdateRepresentative:
setSignatureData:
setSmartCamprints:
setSmartDistanceFactor:
setSmartThreshold:
setStartMaxFind:
setStartSensitized:
setState:
setStopAtFirstPyramidWith2DCode:
setStopNormal:
setStopSensitized:
setStroke
setSuggestedIdsForRepresentative:
setSuggestionsForCluster:
setSynchronizationQueue:
setTargetFrameTime:
setTargetImageSignature:
setTasksTimeout:
setText:
setTextRecognition:
setTexture:atIndex:
setThreshold:
setTimeRange:
setTimeStamp:
setTimerMode:
setTorsoThreshold:
setTorsoprint:
setTorsoprintRequestRevision:
setTotalObjectCount:
setTrackedFrameCVPixelBufferFormat:
setTrackedFrameNumber:
setTrackedObjects:inFrame:error:
setTrackingFrameSizeInPixels:
setTrackingLevel:
setTrajectoryLength:
setTransform:
setType:
setUUID:
setUnalignedBoundingBox:
setUpperBodyOnly:
setUsage:
setUseCenterTileOnly:
setUseImageAnalyzerScaling:
setUseMLDetector:
setUseNonLocalRegularization:
setUseSegmentationPregating:
setUseTiling:
setUseTimestampAdjustedDistances:
setUsesAlternateLineGrouping:
setUsesLanguageCorrection:
setUsesLanguageDetection:
setVN5ui9WkMeVvCBruHiQE1q2r6E9kO1AyrP:
setValue:
setValue:forKey:
setValue:forKeyPath:
setVersion:
setWarnings:
setWarpTransform:
setWithCapacity:
setWithObject:
setYawAngle:
set_priority:low_priority_max_ms_per_command_buffer:gpu_priority:
setobjectMaximumNormalizedRadius:
setsTimeRangeOnResults
setupInputImageFromModelDescription:
shape
shapeForBlobDimensions:
sharedCIContextWithOptions:
sharedCache
sharedInstance
sharplyFocusedSubjectScore
shortDescription
shortValue
shotflowDetector
shotflowNetworkClass
shouldAlignFacesForRequestWithSpecifier:
shouldAssumeOriginatingRequestClassForHeaderSerializationVersion:
shouldBeReplacedByDetectorOfClass:withConfiguration:
shouldBeWrappedWithNextLine
shouldDumpDebugIntermediates
shouldIgnoreLagecyLabelsAndConfidenceForHeaderSerializationVersion:
shouldReprocessDocument
shouldUpdateRepresentative
shouldWrapToNextLine
signPostAdditionalParameter
signalCancellation
signature
significantRegionsFromFloat32ImageBuffer:threshold:
significantRegionsFromFloat32ImageBuffer:threshold:relativeToMaximum:
significantRegionsFromFloat32PixelBuffer:threshold:relativeToMaximum:error:
size
sizeConstraint
sizes
smallestImageSizeForTextWithRelativeHeight:originalImageSize:
smartCamprintCurrentVersion
smartCamprintVersion
smartCamprints
smartDistance
smartDistanceFactor
smartMergeBoxes:
smartThreshold
smoothedFloat32ImageBuffer:fromImageBuffer:originalImageSize:sigmaX:sigmaY:nStd:
sortDescriptorWithKey:ascending:
sortImageDescriptorsChronologically:
sortUsingComparator:
sortUsingSelector:
sortWithOptions:usingComparator:
sortedArrayUsingComparator:
sortedArrayUsingDescriptors:
sortedArrayUsingSelector:
sortedArrayWithOptions:usingComparator:
specifier
specifierForRequest:
specifierForRequestClass:revision:error:
specifierForRequestClassCode:revision:error:
specifierForRequestClassName:revision:error:
specifiesAnyRequestClass:
specifiesAnyRequestClassName:
specifiesRequestClass:
specifiesRequestClass:withAnyRevision:
specifiesRequestClassName:
specifiesRequestClassName:revision:
specifiesRequestClassName:withAnyRevision:
splitDetectedClassResultsIntoSubclasses:
squaredLength
standardUserDefaults
startMaxFind
startNormal
state
stopAtFirstPyramidWith2DCode
stopMaxFind
stopNormal
stopSensitized
storageByteCount
streamError
string
stringByAppendingFormat:
stringByAppendingString:
stringByDeletingLastPathComponent
stringByDeletingPathExtension
stringRepresentation
stringValue
stringWithCString:encoding:
stringWithCapacity:
stringWithFormat:
stringWithString:
stringWithUTF8String:
stroke
strongToStrongObjectsMapTable
subFeatures
subarrayWithRange:
subclassesOfClass:excludingRootClass:passingTest:
subdataWithRange:
substringFromIndex:
substringWithRange:
suggestedIdsForRepresentative
suggestionsForCluster
suggestionsForClusterIdsWithFlags:affinityThreshold:error:
suggestionsForClustersWithFaceIds:affinityThreshold:canceller:error:
superclass
supportedAdjustmentKeysAndReturnError:
supportedAdjustmentKeysForConfiguration:error:
supportedClassificationIdentifiersAcceptedByBlock:error:
supportedClassificationIdentifiersWithOptions:error:
supportedDocumentElementIdentifiers
supportedIdentifiersAndReturnError:
supportedIdentifiersWithOptions:error:
supportedImageSizeSet
supportedImageSizeSetForEspressoModelWithName:inputImageBlobName:analysisPixelFormatType:error:
supportedImageSizeSetForOptions:error:
supportedJointNamesForRevision:error:
supportedJointsGroupNamesForRevision:error:
supportedLabelKeys
supportedLanguagesForOptions:revision:error:
supportedLanguagesForProcessOptions:error:
supportedPrivateRevisions
supportedReadVersions
supportedRecognitionLanguagesAndReturnError:
supportedRecognitionLanguagesForTextRecognitionLevel:revision:error:
supportedRequestSpecifiers
supportedRevisions
supportedSymbologies
supportedSymbologiesAndReturnError:
supportedSymbologiesRev1
supportedSymbologiesRev2
supportedWriteVersions
supportsAnyRevision:
supportsExecution
supportsPrivateRevision:
supportsProcessingDevice:
supportsRevision:
supportsSecureCoding
supportsTiling
symbologies
symbology
synchronizationQueue
targetImageSignature
targetedImageBuffer
targetsANE
targetsCPU
targetsGPU
tasksTimeout
tastefullyBlurredScore
temporalSmoothingFrameCount
tensorForKey:error:
tensorShapesForBlobNames:ofNetworkModelFileWithPath:error:
text
textBlockOfTypes:containingTextAtIndex:
textBlockWithCharacterRange:
textBoxesForBuffer:error:
textBoxesForImage:originatingRequestSpecifier:error:
textElements
textObjects
texture2DDescriptorWithPixelFormat:width:height:mipmapped:
theta
threadExecutionWidth
threshold
tightenBox:startTop:startBottom:startPosition:stopPosition:imageHeight:halfWalk:
timeInterval
timeIntervalSince1970
timeRange
timeStamp
timerMode
timingInfo
title
topCandidates:
topLevelContourCount
topLevelContours
topLevelIndex
topRight
torsoThreshold
torsoprint
torsoprintDescriptorSize
torsoprintForImageBuffer:requestRevision:error:
torsoprintInputImageSizeForFaceOrientation:
torsoprintRequestRevision
torsoprintRequestRevisionForFaceTorsoRequestRevision:error:
totalObjectCount
trackDuration
trackInFrame:error:
trackedCorners
trackedFrameNumber
trackerObservationClass
trackerResourcesAccessingLock
trackerResourcesConfiguredWithOptions:error:
trackerResourcesConfiguredWithOptions:forSession:error:
trackerTypeForRequestRevision:error:
trackerWithOptions:error:
trackingFrameSizeInPixels
trackingLevel
trainedModelBuiltFromConfiguration:dataProvider:canceller:error:
trainedModelClass
trainedModelEntityCount
trainedModelIndexOfEntityWithUniqueIdentifier:
trainedModelNumberOfObservationsForEntityAtIndex:
trainedModelObservationAtIndex:forEntityAtIndex:
trainedModelUniqueIdentifierOfEntityAtIndex:
trainedModelWithCanceller:error:
trainingEntityPrintsForEntityWithUniqueIdentifier:error:
trainingFaceObservationsForPersonWithUniqueIdentifier:canceller:error:
trainingFaceprintsForPersonWithUniqueIdentifier:canceller:error:
trainingFaceprintsForPersonWithUniqueIdentifier:error:
trainingObservationsForEntityWithUniqueIdentifier:canceller:error:
trainingPrintsForEntityWithUniqueIdentifier:canceller:error:
trajectoryLength
transcript
transform
transformForImageWidth:height:
transformedWith:
translateAndNormalizeLandmarkPointsWrtLLCofAlignedFaceBBox:imageBuffer:outputFace:error:
tryToPerformBlock:usingSignallingBlock:
type
unalignedBoundingBox
unarchivedObjectOfClass:fromData:error:
unarchivedObjectOfClasses:fromData:error:
unionSet:
uniqueIdentifierForEntityAtIndex:
uniqueIdentifierOfEntityAtIndex:
unitVectorForVector:
unlock
unsignedCharValue
unsignedIntValue
unsignedIntegerValue
unsignedLongLongValue
unsignedLongValue
unspecifiedOperationPoints
upToDateFaceModelWithCanceller:error:
updateExtrema:x:y:
updateInternalConfigurationWithModelFaceprintRequestRevision:error:
updateModelByAddingFaces:andRemovingFaces:canceller:error:
updateModelByAddingFaces:canceller:error:
updateModelByAddingFaces:withGroupingIdentifiers:andRemovingFaces:canceller:error:
updateModelByAddingFaces:withGroupingIdentifiers:canceller:error:
updateModelByAddingPersons:withGroupingIdentifiers:andRemovingPersons:canceller:error:
updateModelByRemovingFaces:canceller:error:
updateRuntimeParametersFromOptions:error:
updateWithOptions:error:
updateWithPropertiesOfModel:
upperBodyOnly
uppercaseLetterCharacterSet
useCenterTileOnly
useFOpenForModelWithPath:
useGPU
useImageAnalyzerScaling
useMLDetector
useNonLocalRegularization
useSegmentationPregating
useTiling
useTimestampAdjustedDistances
userFacingBBox
usesAlternateLineGrouping
usesCPUOnly
usesLanguageCorrection
usesLanguageDetection
uuid
vNpLorzxnyAlLcPFNcKhgoNCmy9b5BRWyk
valid
validFaceprint
validateAceptableObservation:forEntityPrintOriginatingRequestSpecifier:error:
validateArray:named:hasElementsOfClass:requiredMinimumCount:allowedMaximumCount:error:
validateAsyncStatusResult:error:
validateAsyncStatusResults:error:
validateClassArray:named:hasElementsAncestoredFromClass:requiredMinimumCount:allowedMaximumCount:error:
validateConfiguration:error:
validateConfigurationAndReturnError:
validateDescriptorData:elementType:elementCount:error:
validateImageBuffer:error:
validateImageBuffer:ofNonZeroWidth:andHeight:error:
validateNonZeroImageWidth:height:componentNameProvidingBlock:error:
validateOptionalDetectedObjectObservations:forObservationClass:error:
validateOptionalDetectedObjectObservations:forObservationClass:forRequest:error:
validateOptionalFaceObservations:error:
validateOptionalFaceObservations:forRequest:error:
validateRequiredClusterIDs:error:
validateRequiredDetectedObjectObservations:forObservationClass:error:
validateRequiredDetectedObjectObservations:forObservationClass:forRequest:error:
validateRequiredFaceObservations:error:
validateRequiredFaceObservations:forRequest:error:
validateScoreRange:error:
validateVNConfidenceRange:error:
validateWithCanceller:error:
validatedImageBufferFromOptions:error:
validatedProcessingDeviceInOptions:error:
value
value:withObjCType:
valueForKey:
valueForWarning:
valueWithBytes:objCType:
vcpPoseRequestRuntimeOptionsForDetectorOptions:error:
vcpPoseRequestSetupOptionsForDetectorOptions:error:
vectorByAddingVector:toVector:
vectorByMultiplyingVector:byScalar:
vectorBySubtractingVector:fromVector:
vectorWithCGRect:
vectorWithX:Y:Z:W:
versionNumbersEncodedInClass:withMethodNamePrefix:suffix:
versionOfNetworkHead:error:
visionFeaturePrintInfo
vn1uMyFtnYEWjbrdx3yAuDndKkPeyzNJhB
vn2riiZbQrloRhCzYW56f0rk4N3ROe151S
vn3iT1YRjjnIuELobV1olJiO1vvItN6Kdq
vn4UfLbvVUqMvYV8bbGFQcxg5yRLm8ekI1
vn7CbCeAogPS2iHE6VQwu6H96xanljtMqk
vn7exwFFmQF0AI9P7FjBljwEFu7QYUGCYE
vn7fiLHgGnvqPqG63cfDUCK4Xm8obUuWoP
vn_cloneObject
vn_decode3x3MatrixForKey:
vn_decode4x4MatrixForKey:
vn_decodeCGAffineTransformForKey:
vn_decodeCodingVersionForKey:
vn_decodeEntityUniqueIdentifierArrayForKey:
vn_decodeEntityUniqueIdentifierForKey:
vn_decodePersonUniqueIdentifierForKey:
vn_decodePixelBufferForKey:
vn_decodePointForKey:
vn_decodeRectForKey:
vn_decodeSimdFloat3ForKey:
vn_decodeSizeForKey:
vn_decodeTimeRangeForKey:
vn_decodeValidatedConfidenceForKey:
vn_decodeValidatedScoreForKey:
vn_encode3x3Matrix:forKey:
vn_encode4x4Matrix:forKey:
vn_encodeCGAffineTransform:forKey:
vn_encodeCodingVersion:forKey:
vn_encodeEntityUniqueIdentifier:forKey:
vn_encodeEntityUniqueIdentifierArray:forKey:
vn_encodePersonUniqueIdentifier:forKey:
vn_encodePixelBuffer:forKey:
vn_encodePoint:forKey:
vn_encodeRect:forKey:
vn_encodeSimdFloat3:forKey:
vn_encodeSize:forKey:
vn_encodeTimeRange:forKey:
vn_encodeValidatedConfidence:forKey:
vn_enumerateObjectsAsSubarraysOfCount:usingBlock:
waitUntilCompleted
wantsSequencedRequestObservationsRecording
warmUpApplicableDetectorInSession:error:
warmUpSession:error:
warmUpSession:withOptions:error:
warnings
warpTransform
wasSignalled
weakObjectsHashTable
weakObjectsPointerArray
wellChosenBackgroundScore
wellFramedSubjectScore
wellTimedShotScore
whiteImage
width
willAcceptCachedResultsFromRequestWithConfiguration:
willTrainEntityIdentificationModel:withCanceller:
wipe_layers_blobs
wisdomParameterForMTLDevice:error:
wisdomParameterForMTLDeviceWithName:error:
write:maxLength:
writeData:
writeReadOnlyVersion1ToOutputStream:options:md5Context:error:
writeToFile:atomically:
writeToFile:atomically:encoding:error:
writeToStream:options:error:
writeToURL:options:error:
writeVersion1ToOutputStream:options:md5Context:error:
yawAngle
zeroCircle
zeroPoint
zeroVector
zone
B16@0:8
@32@0:8@16@24
Q16@0:8
B24@0:8@16
@16@0:8
@24@0:8^@16
v24@0:8@16
@24@0:8@16
v16@0:8
@"NSArray"
@96@0:8@16^{__CVBuffer=}24@32@40{CGRect={CGPoint=dd}{CGSize=dd}}48@80^@88
I24@0:8@16
Q24@0:8@16
@72@0:8^{__CVBuffer=}16@24{CGRect={CGPoint=dd}{CGSize=dd}}32^@64
^{__CVBuffer=}56@0:8Q16Q24@32@40^@48
B40@0:8@16@24^@32
B88@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48@56^^{__CVBuffer}64^@72@?80
@92@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16r^{__CVBuffer=}48@56I64@68^@76@?84
@24@0:8Q16
#16@0:8
B32@0:8@16^@24
@32@0:8Q16^@24
B40@0:8Q16@24^@32
r^{?=Q{?=ii}{?=ii}{?=ii}}16@0:8
q16@0:8
#32@0:8@16^@24
{basic_string_view<char, std::char_traits<char>>=*Q}24@0:8@16
{shared_ptr<vision::mod::FaceQualityPredictor>="__ptr_"^{FaceQualityPredictor}"__cntrl_"^{__shared_weak_count}}
@24@0:8#16
@24@0:8^{_NSZone=}16
v24@0:8q16
r^{?=Q#Q}16@0:8
Q32@0:8#16Q24
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
@"NSArray"16@0:8
v24@0:8@"NSArray"16
@24@0:8@?16
@"VNScreenGazeState"
@32@0:8q16@24
B100@0:8@16@24{CGRect={CGPoint=dd}{CGSize=dd}}32@64I72@76@84^@92
v32@0:8@16@24
@32@0:8@16q24
@36@0:8@16B24@28
@28@0:8@16B24
v32@0:8r^v16@24
v24@0:8r^v16
@"NSURL"
@"NSString"
v32@0:8@16^v24
v40@0:8@16@24^v32
@32@0:8@16^@24
@40@0:8@16@24^@32
@36@0:8@16f24^@28
@"NSArray"36@0:8@"NSDictionary"16f24^@28
@"NSData"24@0:8^@16
@"NSSet"24@0:8^@16
@"NSArray"32@0:8@"NSNumber"16^@24
@"NSNumber"40@0:8@"NSNumber"16@"NSNumber"24^@32
@"NSDictionary"32@0:8@"NSArray"16^@24
@"NSArray"24@0:8^@16
@"NSArray"40@0:8@"NSArray"16@"NSDictionary"24^@32
@"NSDictionary"40@0:8@"NSArray"16@"NSArray"24^@32
@"NSNumber"24@0:8^@16
@"NSArray"40@0:8@"NSData"16@"NSString"24^@32
@"NSUUID"16@0:8
B24@0:8^@16
v32@0:8{shared_ptr<const vision::mod::FaceClustering>=^{FaceClustering}^{__shared_weak_count}}16
@24@0:8^v16
@"VNClusteringLogger"
@"VNSuggestionsLogger"
@"NSData"
{shared_ptr<const vision::mod::FaceClustering>="__ptr_"^{FaceClustering}"__cntrl_"^{__shared_weak_count}}
@"NSArray"32@0:8@"NSDictionary"16^@24
q40@0:8^v16^v24Q32
{shared_ptr<vision::mod::FaceClustering>="__ptr_"^{FaceClustering}"__cntrl_"^{__shared_weak_count}}
f24@0:8@16
v24@0:8^v16
{unordered_map<NSString *, espresso_buffer_t, std::hash<NSString *>, std::equal_to<NSString *>, std::allocator<std::pair<NSString *const, espresso_buffer_t>>>="__table_"{__hash_table<std::__hash_value_type<NSString *, espresso_buffer_t>, std::__unordered_map_hasher<NSString *, std::__hash_value_type<NSString *, espresso_buffer_t>, std::hash<NSString *>, std::equal_to<NSString *>, true>, std::__unordered_map_equal<NSString *, std::__hash_value_type<NSString *, espresso_buffer_t>, std::equal_to<NSString *>, std::hash<NSString *>, true>, std::allocator<std::__hash_value_type<NSString *, espresso_buffer_t>>>="__bucket_list_"{unique_ptr<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, espresso_buffer_t>, void *> *> *[], std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, espresso_buffer_t>, void *> *> *>>>="__ptr_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, espresso_buffer_t>, void *> *> **, std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, espresso_buffer_t>, void *> *> *>>>="__value_"^^v"__value_"{__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, espresso_buffer_t>, void *> *> *>>="__data_"{__compressed_pair<unsigned long, std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, espresso_buffer_t>, void *> *> *>>="__value_"Q}}}}"__p1_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, espresso_buffer_t>, void *> *>, std::allocator<std::__hash_node<std::__hash_value_type<NSString *, espresso_buffer_t>, void *>>>="__value_"{__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, espresso_buffer_t>, void *> *>="__next_"^v}}"__p2_"{__compressed_pair<unsigned long, std::__unordered_map_hasher<NSString *, std::__hash_value_type<NSString *, espresso_buffer_t>, std::hash<NSString *>, std::equal_to<NSString *>, true>>="__value_"Q}"__p3_"{__compressed_pair<float, std::__unordered_map_equal<NSString *, std::__hash_value_type<NSString *, espresso_buffer_t>, std::equal_to<NSString *>, std::hash<NSString *>, true>>="__value_"f}}}
r^v24@0:8@16
@84@0:8I16@20{CGRect={CGPoint=dd}{CGSize=dd}}28@60^@68@?76
v40@0:8^v16@24@32
B56@0:8{shared_ptr<vision::mod::ImageDescriptorBufferAbstract>=^{ImageDescriptorBufferAbstract}^{__shared_weak_count}}16@32@40^@48
B32@0:8{shared_ptr<vision::mod::ImageDescriptorBufferAbstract>=^{ImageDescriptorBufferAbstract}^{__shared_weak_count}}16
B48@0:8^v16@24@32^@40
{shared_ptr<vision::mod::FaceprintAndAttributes>="__ptr_"^{FaceprintAndAttributes}"__cntrl_"^{__shared_weak_count}}
B56@0:8@16@24@32Q40^@48
@64@0:8@16@24@32B40f44Q48^@56
@72@0:8@16@24@32B40f44Q48Q56^@64
@68@0:8@16@24@32B40f44f48Q52^@60
@76@0:8@16@24@32B40f44f48Q52Q60^@68
@40@0:8#16@24^@32
@"NSNumber"
@44@0:8@16f24@28^@36
@"NSArray"32@0:8@"NSArray"16^@24
@"NSArray"44@0:8@"NSDictionary"16f24@"VNCanceller"28^@36
@"NSNumber"40@0:8@"VNFaceprint"16@"VNFaceprint"24^@32
@"NSNumber"40@0:8@"VNFaceObservation"16@"VNFaceObservation"24^@32
@60@0:8@16@24@32f40Q44^@52
@68@0:8@16@24@32f40Q44Q52^@60
@64@0:8@16@24@32f40f44Q48^@56
@72@0:8@16@24@32f40f44Q48Q56^@64
@"<VNClusteringReadOnly><VNClusteringCancelling>"
@48@0:8@16@24@32^@40
@56@0:8@16@24@32@40^@48
B32@0:8@"NSData"16^@24
@"NSArray"48@0:8@"NSArray"16@"NSArray"24@"VNCanceller"32^@40
@"NSArray"56@0:8@"NSArray"16@"NSArray"24@"NSArray"32@"VNCanceller"40^@48
@"NSArray"40@0:8@"NSArray"16@"VNCanceller"24^@32
@"<VNClusteringReadOnly><VNClusteringWritable><VNClusteringCancelling>"
#28@0:8I16^@20
@28@0:8I16^@20
B40@0:8^I16#24^@32
B40@0:8^I16@24^@32
B28@0:8I16Q20
v20@0:8f16
v56@0:8@16{?=qiIq}24@48
v56@0:8@"NSArray"16{?=qiIq}24@"NSDictionary"48
@"NSObject<OS_dispatch_semaphore>"
{os_unfair_lock_s="_os_unfair_lock_opaque"I}
{vector<std::tuple<simd_float3x3, float>, std::allocator<std::tuple<simd_float3x3, float>>>="__begin_"^v"__end_"^v"__end_cap_"{__compressed_pair<std::tuple<simd_float3x3, float> *, std::allocator<std::tuple<simd_float3x3, float>>>="__value_"^v}}
v24@0:8Q16
@"VN6Ac6Cyl5O5oK19HboyMBR"
@32@0:8Q16@24
@32@0:8Q16Q24
@40@0:8Q16Q24@?32
{CGSize=dd}16@0:8
B32@0:8^v16^@24
@52@0:8^v16@24@32I40^@44
@32@0:8@?16^@24
@60@0:8^v16@?24@32@40I48^@52
{shared_ptr<vision::mod::ImageAnalyzer>="__ptr_"^{ImageAnalyzer}"__cntrl_"^{__shared_weak_count}}
{_Geometry2D_size2D_="height"f"width"f}
@"VNRequest"
@"NSError"
@"<NSObject><NSCopying>"
@"NSMutableArray"
@"NSMapTable"
{shared_ptr<vision::mod::TapToBox>="__ptr_"^{TapToBox}"__cntrl_"^{__shared_weak_count}}
@40@0:8q16@24@32
@20@0:8I16
@32@0:8#16Q24
@40@0:8@16@24@32
@32@0:8Q16#24
@28@0:8i16@20
@40@0:8{?=ii*}16@32
@32@0:8^v16@24
v28@0:8B16@20
{shared_ptr<vision::mod::ObjectDetector_DCNFaceDetector_v2>="__ptr_"^{ObjectDetector_DCNFaceDetector_v2}"__cntrl_"^{__shared_weak_count}}
@"VNFaceBBoxAligner"
@40@0:8@16Q24^@32
@"CRImageReader"
@"FaceCoreDetector"
@"NSDictionary"
@"VNSceneObservation"
@"VNClassificationCustomHierarchy"
@32@0:8@16@?24
@40@0:8^I16Q24^@32
@40@0:8#16Q24^@32
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
#24@0:8^@16
@44@0:8#16@24I32Q36
I16@0:8
B32@0:8#16Q24
B32@0:8@16Q24
v40@0:8#16Q24Q32
v40@0:8@16Q24Q32
@32@0:8^{__CVBuffer=}16^@24
^v16@0:8
B76@0:8^f16^{__CVBuffer=}24{CGRect={CGPoint=dd}{CGSize=dd}}32f64^@68
B44@0:8^f16^{__CVBuffer=}24f32^@36
B76@0:8^f16@24f32{CGRect={CGPoint=dd}{CGSize=dd}}36^@68
B40@0:8^f16^{__CVBuffer=}24^@32
B48@0:8^f16^{__CVBuffer=}24i32f36^@40
I24@0:8Q16
v20@0:8B16
@"VNDetectedObjectObservation"
f16@0:8
{?=qiIq}16@0:8
v40@0:8{?=qiIq}16
{?="value"q"timescale"i"flags"I"epoch"q}
@56@0:8{?=qiIq}16q40@?48
@"VNTrajectoryProcessor"
@"VNTrajectoryRequestState"
@32@0:8@16Q24
#40@0:8@16@24^@32
@44@0:8@16@24I32^@36
v44@0:8@?16@24I32^@36
@"<NSObject><NSCopying>"24@0:8@"NSDictionary"16
B32@0:8#16@24
B40@0:8^@16@24^@32
v40@0:8@16@24@32
@"VNMetalContext"
@"VNControlledCapacityTasksQueue"
v28@0:8I16@20
v72@0:8{CGAffineTransform=dddddd}16@64
{CGAffineTransform=dddddd}24@0:8@16
v72@0:8{?=[3]}16@64
{?=[3]}24@0:8@16
v88@0:8{?=[4]}16@80
{?=[4]}24@0:8@16
v40@0:816@32
24@0:8@16
v72@0:8{?={?=qiIq}{?=qiIq}}16@64
{?={?=qiIq}{?=qiIq}}24@0:8@16
v40@0:8{CGPoint=dd}16@32
{CGPoint=dd}24@0:8@16
v40@0:8{CGSize=dd}16@32
{CGSize=dd}24@0:8@16
v56@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48
{CGRect={CGPoint=dd}{CGSize=dd}}24@0:8@16
v32@0:8^{__CVBuffer=}16@24
^{__CVBuffer=}24@0:8@16
v28@0:8f16@20
@"NSMutableDictionary"
@"VNImageAnalyzerCompoundRequestGroupingConfiguration"
@92@0:8Q16^{vImage_Buffer=^vQQQ}24B32{CGRect={CGPoint=dd}{CGSize=dd}}36{_Geometry2D_rect2D_={_Geometry2D_point2D_=ff}{_Geometry2D_size2D_=ff}}68@84
@32@0:8{CGPoint=dd}16
@48@0:8{CGPoint=dd}16{CGSize=dd}32
{vImage_Buffer="data"^v"height"Q"width"Q"rowBytes"Q}
{CGRect="origin"{CGPoint="x"d"y"d}"size"{CGSize="width"d"height"d}}
{_Geometry2D_rect2D_="origin"{_Geometry2D_point2D_="x"f"y"f}"size"{_Geometry2D_size2D_="height"f"width"f}}
@28@0:8@16f24
@76@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24f56@60@68
@"VNAnimalprint"
i16@0:8
B20@0:8i16
B32@0:8@16:24
B32@0:8#16:24
v36@0:8#16B24@?28
@36@0:8#16B24@?28
@36@0:8#16B24:28
Q32@0:8@16@24
Q32@0:8@16Q24
@40@0:8@16Q24Q32
Q24@0:8@"VNEntityIdentificationModel"16
@"<NSObject><NSCopying><NSSecureCoding>"32@0:8@"VNEntityIdentificationModel"16Q24
Q32@0:8@"VNEntityIdentificationModel"16@"<NSObject><NSCopying><NSSecureCoding>"24
Q32@0:8@"VNEntityIdentificationModel"16Q24
@"VNObservation<VNEntityIdentificationModelObservation>"40@0:8@"VNEntityIdentificationModel"16Q24Q32
@"NSDate"24@0:8@"VNEntityIdentificationModel"16
Q24@0:8Q16
@"<NSObject><NSCopying><NSSecureCoding>"24@0:8Q16
Q24@0:8@"<NSObject><NSCopying><NSSecureCoding>"16
@"VNObservation<VNEntityIdentificationModelObservation>"32@0:8Q16Q24
@"<VNEntityIdentificationModelTrainingDataDelegate>"
@"VNRequestSpecifier"
@"NSMutableIndexSet"
@"NSDate"
@64@0:8@16@24@32@40@48@56
@"VNTensorDescriptor"
B32@0:8@?16@?24
r^{_LandmarkDetector_faceMeshParts_=ii[23i]i[23i]i[23i]i[23i]i[23i]i[23i]i[23i]i[23i]i[23i]i[23i]i[23i]i[23i]i[23i]i[23i]i[23i]i[23i]i[23i]}24@0:8Q16
r^v24@0:8Q16
{_Geometry2D_point2D_=ff}36@0:8r^{_Geometry2D_point2D_=ff}16r^i24i32
@48@0:8r^{vImage_Buffer=^vQQQ}16r^{_Geometry2D_rect2D_={_Geometry2D_point2D_=ff}{_Geometry2D_size2D_=ff}}24r^v32^@40
B64@0:8r^v16@24@32@40@48^@56
B64@0:8r^{vImage_Buffer=^vQQQ}16@24^{_Geometry2D_rect2D_={_Geometry2D_point2D_=ff}{_Geometry2D_size2D_=ff}}32r^v40@48^@56
{shared_ptr<vision::mod::LandmarkAttributes>="__ptr_"^{LandmarkAttributes}"__cntrl_"^{__shared_weak_count}}
@40@0:8@16@24Q32
B36@0:8^@16B24^@28
v32@0:8Q16@?24
@"CIContext"
@"<MTLDevice>"
@"NSLock"
@"NSHashTable"
^{CGImageSource=}40@0:8^^{CGImageSource}16I24^{os_unfair_lock_s=I}28B36
^{CGImageSource=}32@0:8I16B20^@24
^{CGImageSource=}
@68@0:8I16Q20Q28{CGRect={CGPoint=dd}{CGSize=dd}}36
@36@0:8I16Q20Q28
v24@0:8^{__CVBuffer=}16
^{__CFDictionary=}
r^{__CFDictionary=}16@0:8
i24@0:8@16
{CGRect={CGPoint=dd}{CGSize=dd}}80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGSize=dd}48^d64^d72
^{CGColorSpace=}28@0:8I16^I20
@"<NSObject><NSCopying>"16@0:8
@32@0:8^{__CVBuffer=}16@24
@36@0:8^{__CVBuffer=}16I24@28
@32@0:8^{CGImage=}16@24
@36@0:8^{CGImage=}16I24@28
@36@0:8@16I24@28
@32@0:8^{opaqueCMSampleBuffer=}16@24
@36@0:8^{opaqueCMSampleBuffer=}16I24@28
^{__CVBuffer=}16@0:8
^{CGImage=}16@0:8
^{__CVBuffer=}52@0:8Q16Q24I32@36^@44
^{__CVBuffer=}60@0:8Q16Q24I32@36^@44^@52
^{__CVBuffer=}84@0:8Q16Q24I32{CGRect={CGPoint=dd}{CGSize=dd}}36@68^@76
^{__CVBuffer=}92@0:8Q16Q24I32{CGRect={CGPoint=dd}{CGSize=dd}}36@68^@76^@84
^{__CVBuffer=}116@0:8Q16Q24{CGRect={CGPoint=dd}{CGSize=dd}}32I64Q68@76^@84^{CGPoint=dd}92^d100^d108
^{__CVBuffer=}124@0:8Q16Q24{CGRect={CGPoint=dd}{CGSize=dd}}32I64Q68@76^@84^{CGPoint=dd}92^d100^d108^@116
{?={?=qiIq}{?=qiIq}{?=qiIq}}16@0:8
B24@0:8^f16
B24@0:8^{CGPoint=dd}16
B24@0:8^{?=[3]}16
{CGRect={CGPoint=dd}{CGSize=dd}}48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
^{__CVBuffer=}44@0:8Q16I24@28^@36
^{__CVBuffer=}76@0:8Q16{CGRect={CGPoint=dd}{CGSize=dd}}24I56@60^@68
@60@0:8Q16Q24I32@36@44^@52
@92@0:8Q16Q24I32{CGRect={CGPoint=dd}{CGSize=dd}}36@68@76^@84
^{__CVBuffer=}
@"CIImage"
^{opaqueCMSampleBuffer=}
@"VNImageSourceManager"
@"VNImageBufferCache"
B56@0:8@16Q24@32@40^@48
@80@0:8@16Q24{CGRect={CGPoint=dd}{CGSize=dd}}32@64^@72
v28@0:8@16B24
@20@0:8B16
v24@0:8@"NSDictionary"16
v24@0:8@"NSString"16
@"NSDictionary"32@0:8@"<MTLDevice>"16^@24
@"NSDictionary"32@0:8@"NSString"16^@24
@48@0:8#16@24@32@40
@48@0:8#16@24@32^@40
@"NSNotificationCenter"
@"NSRecursiveLock"
@"_VNWeakSessionsCollection"
@"VNMTLDeviceWisdomParameters"
@40@0:8Q16@24^@32
v24@0:8@"VNPersonsModelData"16
B48@0:8@16@24^{CC_MD5state_st=IIIIII[16I]i}32^@40
B48@0:8^^?16^:24^Q32@40
@"VNPersonsModelData"
d32@0:8@16@24
d24@0:8@16
@32@0:8d16d24
{CGPoint=dd}16@0:8
@64@0:8{CGAffineTransform=dddddd}16
d16@0:8
@?16@0:8
v24@0:8@?16
@?<v@?@"VNRequest"d@"NSError">16@0:8
v24@0:8@?<v@?@"VNRequest"d@"NSError">16
B56@0:8^@16#24@32@40^@48
B48@0:8^d16@24@32^@40
B56@0:8^d16@24@32d40^@48
B48@0:8^f16@24@32^@40
B52@0:8^f16@24@32f40^@44
B56@0:8^@16@24@32#40^@48
Q20@0:8i16
B24@0:8Q16
v32@0:8@"NSString"16@24
@24@0:8@"NSString"16
v28@0:8B16@"NSError"20
@"VNAsyncStatus"16@0:8
#32@0:8Q16^@24
@48@0:8^@16Q24@32^@40
B48@0:8@16^Q24^Q32^@40
B32@0:8Q16^@24
@112@0:8@16Q24{CGRect={CGPoint=dd}{CGSize=dd}}32@64@72@?80@?88@96^@104
@52@0:8@16@24I32@36^@44
v56@0:8@16@?24@32@40@48
@"VNRequestConfiguration"
@"VNWarningRecorder"
@"VNAsyncStatus"
@"VNCanceller"
@"NSObject<OS_dispatch_queue>"
@40@0:8Q16Q24Q32
@52@0:8I16@20@28Q36I44B48
@52@0:8I16Q20Q28I36Q40B48
B32@0:8Q16Q24
@"VNSizeRange"
@"VNProcessingDevice"
v32@0:8@16@?24
@32@0:8@16#24
B20@0:8I16
@56@0:8r^v16Q24Q32Q40f48f52
@64@0:8r^v16Q24Q32Q40f48f52@56
@40@0:8@16^Q24^@32
Q40@0:8@16Q24^@32
@"VNFaceprint"
@"VNTorsoprint"
{shared_ptr<vision::mod::PetprintGenerator>="__ptr_"^{PetprintGenerator}"__cntrl_"^{__shared_weak_count}}
@"VNFaceObservation"
@"NSUUID"
{_Geometry2D_point2D_="x"f"y"f}
@36@0:8@16i24^@28
@36@0:8@16B24^@28
@40@0:8{vector<MPClusteringTreeNode *, std::allocator<MPClusteringTreeNode *>>=^^{MPClusteringTreeNode}^^{MPClusteringTreeNode}{__compressed_pair<MPClusteringTreeNode **, std::allocator<MPClusteringTreeNode *>>=^^{MPClusteringTreeNode}}}16
@"VNMPContext"
@28@0:8^v16B24
Q40@0:8^{?=Q^@^Q[5Q]}16^@24Q32
B24@0:8@"<VNEntityIdentificationModelPrint>"16
@"VNRequestSpecifier"16@0:8
@"NSData"16@0:8
@"<VNEntityIdentificationModelPrint>"32@0:8@"VNRequestSpecifier"16^@24
@60@0:8q16{CGRect={CGPoint=dd}{CGSize=dd}}24f56
{CGRect={CGPoint=dd}{CGSize=dd}}16@0:8
v48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
B40@0:8#16@24^@32
v24@0:8@"VNEntityIdentificationModelTrainingData"16
@"VNEntityIdentificationModelTrainingData"
@36@0:8{CGPoint=dd}16f32
@44@0:8{CGPoint=dd}16f32@36
Q40@0:8@"NSMutableData"16Q24^@32
@40@0:8@"NSData"16^Q24^@32
@56@0:8r^v16Q24Q32Q40Q48
@60@0:8r^v16Q24Q32Q40f48Q52
@60@0:8r^v16Q24Q32Q40f48@52
@36@0:8r^v16f24Q28
v28@0:8f16i20i24
{CGRect={CGPoint=dd}{CGSize=dd}}52@0:8f16{vImage_Buffer=^vQQQ}20
[4{CGPoint="x"d"y"d}]
[4f]
@56@0:8@16^{__CVBuffer=}24{CGSize=dd}32@48
^{__CVBuffer=}24@0:8^@16
{CGSize="width"d"height"d}
^{__CVBuffer=}80@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24Q56@64^@72
{shared_ptr<vision::mod::ScreenGazePredictor>="__ptr_"^{ScreenGazePredictor}"__cntrl_"^{__shared_weak_count}}
@104@0:8@16@24@32{CGPoint=dd}40{CGPoint=dd}56{CGPoint=dd}72{CGPoint=dd}88
@72@0:8@16@24@32{CGRect={CGPoint=dd}{CGSize=dd}}40
v24@0:8^{__MRCDescriptor=}16
r^{__MRCDescriptor=}16@0:8
v24@0:8r^{__MRCDescriptor=}16
@"CIBarcodeDescriptor"
r^{__MRCDescriptor=}
{shared_ptr<vision::mod::ImageDescriptorBufferFloat32>=^{ImageDescriptorBufferFloat32}^{__shared_weak_count}}52@0:8{shared_ptr<vision::mod::ImageDescriptorBufferFloat32>=^{ImageDescriptorBufferFloat32}^{__shared_weak_count}}16@32i40^v44
B40@0:8^I16Q24^@32
@56@0:8{shared_ptr<vision::mod::FaceIDModel>=^{FaceIDModel}^{__shared_weak_count}}16Q32Q40@48
B40@0:8^i16@24^@32
@56@0:8@16r^v24Q32^{CVMLCanceller=^^?Bi}40^@48
@56@0:8@16r^v24Q32@40^@48
{shared_ptr<vision::mod::FaceIDModel>="__ptr_"^{FaceIDModel}"__cntrl_"^{__shared_weak_count}}
{shared_ptr<vision::mod::ImageClassifierAbstract>=^{ImageClassifierAbstract}^{__shared_weak_count}}88@0:8{shared_ptr<vision::mod::ImageDescriptorProcessorAbstract>=^{ImageDescriptorProcessorAbstract}^{__shared_weak_count}}16r*32i40i44r*48{Options=BQ@@}56
{shared_ptr<vision::mod::ImageDescriptorProcessorAbstract>=^{ImageDescriptorProcessorAbstract}^{__shared_weak_count}}68@0:8r*16i24i28i32{Options=BQ@@}36
v32@0:8^@16^@24
@44@0:8@16I24Q28Q36
@64@0:8r^v16Q24Q32Q40@48Q56
B40@0:8@16Q24^@32
@48@0:8{_NSRange=QQ}16@?32^@40
@48@0:8{_NSRange=QQ}16@32^@40
@"VNFaceObservation"32@0:8Q16Q24
@"VNPersonsModel"
@"<VNPersonsModelDataSource>"
@40@0:8#16@24@32
B60@0:8Q16I24@28@36^{CC_MD5state_st=IIIIII[16I]i}44^@52
@48@0:8@16Q24@32^@40
@"VNPersonsModelFaceModel"
@"VNPersonsModelConfiguration"
@44@0:8Q16@24@32B40
@"VNPersonsModelAlgorithm"
@32@0:8#16^@24
@36@0:8@16@24f32
@"<NSObject><NSCopying><NSSecureCoding>"
@"NSIndexSet"
B48@0:8^@16^@24@32^@40
@"VNImageBuffer"
@"VNImageRegistrationSignature"
@"VNClassificationObservation"
@"VNFaceAttributeCategory"
@"VNDetectionprint"
r^{BufferSize=QQ}16@0:8
{BufferSize=QQ}16@0:8
{optional<std::tuple<std::unordered_map<NSString *, __CVBuffer *>, std::unordered_map<NSString *, espresso_buffer_t>>>=(?=c{tuple<std::unordered_map<NSString *, __CVBuffer *>, std::unordered_map<NSString *, espresso_buffer_t>>={__tuple_impl<std::__tuple_indices<0, 1>, std::unordered_map<NSString *, __CVBuffer *>, std::unordered_map<NSString *, espresso_buffer_t>>={unordered_map<NSString *, __CVBuffer *, std::hash<NSString *>, std::equal_to<NSString *>, std::allocator<std::pair<NSString *const, __CVBuffer *>>>={__hash_table<std::__hash_value_type<NSString *, __CVBuffer *>, std::__unordered_map_hasher<NSString *, std::__hash_value_type<NSString *, __CVBuffer *>, std::hash<NSString *>, std::equal_to<NSString *>, true>, std::__unordered_map_equal<NSString *, std::__hash_value_type<NSString *, __CVBuffer *>, std::equal_to<NSString *>, std::hash<NSString *>, true>, std::allocator<std::__hash_value_type<NSString *, __CVBuffer *>>>={unique_ptr<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, __CVBuffer *>, void *> *> *[], std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, __CVBuffer *>, void *> *> *>>>={__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, __CVBuffer *>, void *> *> **, std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, __CVBuffer *>, void *> *> *>>>=^^v{__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, __CVBuffer *>, void *> *> *>>={__compressed_pair<unsigned long, std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, __CVBuffer *>, void *> *> *>>=Q}}}}{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, __CVBuffer *>, void *> *>, std::allocator<std::__hash_node<std::__hash_value_type<NSString *, __CVBuffer *>, void *>>>={__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, __CVBuffer *>, void *> *>=^v}}{__compressed_pair<unsigned long, std::__unordered_map_hasher<NSString *, std::__hash_value_type<NSString *, __CVBuffer *>, std::hash<NSString *>, std::equal_to<NSString *>, true>>=Q}{__compressed_pair<float, std::__unordered_map_equal<NSString *, std::__hash_value_type<NSString *, __CVBuffer *>, std::equal_to<NSString *>, std::hash<NSString *>, true>>=f}}}{unordered_map<NSString *, espresso_buffer_t, std::hash<NSString *>, std::equal_to<NSString *>, std::allocator<std::pair<NSString *const, espresso_buffer_t>>>={__hash_table<std::__hash_value_type<NSString *, espresso_buffer_t>, std::__unordered_map_hasher<NSString *, std::__hash_value_type<NSString *, espresso_buffer_t>, std::hash<NSString *>, std::equal_to<NSString *>, true>, std::__unordered_map_equal<NSString *, std::__hash_value_type<NSString *, espresso_buffer_t>, std::equal_to<NSString *>, std::hash<NSString *>, true>, std::allocator<std::__hash_value_type<NSString *, espresso_buffer_t>>>={unique_ptr<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, espresso_buffer_t>, void *> *> *[], std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, espresso_buffer_t>, void *> *> *>>>={__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, espresso_buffer_t>, void *> *> **, std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, espresso_buffer_t>, void *> *> *>>>=^^v{__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, espresso_buffer_t>, void *> *> *>>={__compressed_pair<unsigned long, std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, espresso_buffer_t>, void *> *> *>>=Q}}}}{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, espresso_buffer_t>, void *> *>, std::allocator<std::__hash_node<std::__hash_value_type<NSString *, espresso_buffer_t>, void *>>>={__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, espresso_buffer_t>, void *> *>=^v}}{__compressed_pair<unsigned long, std::__unordered_map_hasher<NSString *, std::__hash_value_type<NSString *, espresso_buffer_t>, std::hash<NSString *>, std::equal_to<NSString *>, true>>=Q}{__compressed_pair<float, std::__unordered_map_equal<NSString *, std::__hash_value_type<NSString *, espresso_buffer_t>, std::equal_to<NSString *>, std::hash<NSString *>, true>>=f}}}}})B}48@0:8^{__CVBuffer=}16@24@32^@40
^{__CVBuffer=}60@0:8@16Q24Q32I40@44^@52
r^v16@0:8
{BufferSize="width"Q"height"Q}
{unordered_map<NSString *, apple::vision::BufferSize, std::hash<NSString *>, std::equal_to<NSString *>, std::allocator<std::pair<NSString *const, apple::vision::BufferSize>>>="__table_"{__hash_table<std::__hash_value_type<NSString *, apple::vision::BufferSize>, std::__unordered_map_hasher<NSString *, std::__hash_value_type<NSString *, apple::vision::BufferSize>, std::hash<NSString *>, std::equal_to<NSString *>, true>, std::__unordered_map_equal<NSString *, std::__hash_value_type<NSString *, apple::vision::BufferSize>, std::equal_to<NSString *>, std::hash<NSString *>, true>, std::allocator<std::__hash_value_type<NSString *, apple::vision::BufferSize>>>="__bucket_list_"{unique_ptr<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, apple::vision::BufferSize>, void *> *> *[], std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, apple::vision::BufferSize>, void *> *> *>>>="__ptr_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, apple::vision::BufferSize>, void *> *> **, std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, apple::vision::BufferSize>, void *> *> *>>>="__value_"^^v"__value_"{__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, apple::vision::BufferSize>, void *> *> *>>="__data_"{__compressed_pair<unsigned long, std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, apple::vision::BufferSize>, void *> *> *>>="__value_"Q}}}}"__p1_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, apple::vision::BufferSize>, void *> *>, std::allocator<std::__hash_node<std::__hash_value_type<NSString *, apple::vision::BufferSize>, void *>>>="__value_"{__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, apple::vision::BufferSize>, void *> *>="__next_"^v}}"__p2_"{__compressed_pair<unsigned long, std::__unordered_map_hasher<NSString *, std::__hash_value_type<NSString *, apple::vision::BufferSize>, std::hash<NSString *>, std::equal_to<NSString *>, true>>="__value_"Q}"__p3_"{__compressed_pair<float, std::__unordered_map_equal<NSString *, std::__hash_value_type<NSString *, apple::vision::BufferSize>, std::equal_to<NSString *>, std::hash<NSString *>, true>>="__value_"f}}}
@64@0:8r^v16Q24Q32Q40@48@56
@32@0:8r*16Q24
@64@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24^@56
r^{FastRegistration_Signatures=^fQ{Projections_meanStdTable=^f^f}^fQ{Projections_meanStdTable=^f^f}*}16@0:8
{FastRegistration_Signatures="piRow"^f"nPiRow"Q"piRowTable"{Projections_meanStdTable="sumTable"^f"sumSqTable"^f}"piCol"^f"nPiCol"Q"piColTable"{Projections_meanStdTable="sumTable"^f"sumSqTable"^f}"_memoryContainer"*}
f24@0:8Q16
{shared_ptr<vision::mod::FaceFrontalizer>="__ptr_"^{FaceFrontalizer}"__cntrl_"^{__shared_weak_count}}
v24@0:8^{vImage_Buffer=^vQQQ}16
q24@0:8@16
@"VNOperationPoints"24@0:8^@16
@"VNOperationPoints"
B40@0:8^{CGSize=dd}16Q24^@32
B40@0:8^Q16Q24^@32
{shared_ptr<vision::mod::FaceSegmenterDNN>="__ptr_"^{FaceSegmenterDNN}"__cntrl_"^{__shared_weak_count}}
v24@0:8@"NSMutableDictionary"16
@24@0:8q16
@24@0:8d16
@"VNVideoProcessorCadence"
B72@0:8{?={?=qiIq}{?=qiIq}}16^@64
@"VCPVideoProcessor"
v40@0:8^{CGPath=}16{CGSize=dd}24
@"VNRecognizedPointsSpecifier"
@"VCPRequest"
@"VNEntityIdentificationModelAlgorithm"
@48@0:8@16f24@28i36i40i44
@36@0:8@16i24i28i32
@52@0:8{?=^vi}16^v32f40@44
@40@0:8{?=^vi}16^v32
{CGSize=dd}32@0:8{CGSize=dd}16
@28@0:8r^{vImage_Buffer=^vQQQ}16B24
@32@0:8@16f24f28
v20@0:8i16
@"ShotflowNetwork"
{shared_ptr<vision::mod::ImageClassifier_HierarchicalModel>=^{ImageClassifier_HierarchicalModel}^{__shared_weak_count}}32@0:8@16^@24
@80@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24@56@64^@72
{shared_ptr<vision::mod::ImageDescriptorProcessorAbstract>="__ptr_"^{ImageDescriptorProcessorAbstract}"__cntrl_"^{__shared_weak_count}}
{shared_ptr<vision::mod::ImageClassifierAbstract>="__ptr_"^{ImageClassifierAbstract}"__cntrl_"^{__shared_weak_count}}
@"NSSet"
^{__CFString=}24@0:8@16
@24@0:8^{__CFString=}16
@32@0:8^{__MRCDescriptor=}16^@24
^{ACBSConfig=}24@0:8^@16
@72@0:8^{__MRCDescriptor=}16{CGRect={CGPoint=dd}{CGSize=dd}}24@56^@64
B56@0:8@16^{CGPoint=dd}24^{CGPoint=dd}32^{CGPoint=dd}40^{CGPoint=dd}48
@88@0:8@16Q24Q32{CGRect={CGPoint=dd}{CGSize=dd}}40@72^@80
@48@0:8@16^{ACBSConfig=}24@32^@40
@"VNRPNTrackerEspressoResourcesCache"
B68@0:8@16^v24Q32Q40Q48I56^@60
^{__CVBuffer=}52@0:8@16Q24Q32I40^@44
@"MPSImageSpatioTemporalGuidedFilter"
@"VNObservation<VNEntityIdentificationModelObservation>"
@"VNSaliencyOHeatmapBoundingBoxGenerator"
@"NSBundle"
@76@0:8q16{CGRect={CGPoint=dd}{CGSize=dd}}24f56f60f64f68i72
@48@0:8^{vImage_Buffer=^vQQQ}16@24@32^@40
@48@0:8^{vImage_Buffer=^vQQQ}16@24q32^@40
@48@0:8^{__CVBuffer=}16@24@32^@40
@48@0:8^{__CVBuffer=}16@24q32^@40
^{vImage_Buffer=^vQQQ}16@0:8
^{vImage_Buffer=^vQQQ}
B40@0:8^f16@24^@32
B44@0:8^f16@24f32^@36
@44@0:8@16i24i28i32^@36
B32@0:8^{__CVBuffer=}16^@24
B40@0:8^{__CVBuffer=}16^{__CVBuffer=}24^@32
v28@0:8i16i20i24
B44@0:8@16^{__CVBuffer=}24i32^@36
v68@0:8@16i242836@44@52@60
v56@0:8@16@24@32@40@48
@"<MTLCommandQueue>"
[9@"<MTLComputePipelineState>"]
[10{CGSize="width"d"height"d}]
[2[10@"<MTLTexture>"]]
[10@"<MTLTexture>"]
[2@"<MTLBuffer>"]
[2^{__CVBuffer}]
@"<MTLTexture>"
v24@0:8d16
@"VNSupportedImageSize"
{CGSize=dd}40@0:8@16Q24Q32
^{__CVBuffer=}88@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48I56{CGSize=dd}60B76^@80
^{__CVBuffer=}56@0:8@16I24{CGSize=dd}28B44^@48
B48@0:8Q16@24@32^@40
@32@0:8@"NSData"16^@24
@40@0:8@16Q24@32
@"VNMPImageDescriptor"
B40@0:8@16^f24^@32
@"<MTLLibrary>"
@"CIColorKernel"
B48@0:8@16Q24Q32^@40
@56@0:8@16Q24Q32@40^@48
@48@0:8r^f16Q24@32^@40
@48@0:8@16Q24Q32@40
@28@0:8@16I24
@112@0:8@16f24f28f32f36f40f44f48f52f56f60f64f68f72f76f80f84f88f92f96f100f104f108
@48@0:8@16@24{CGSize=dd}32
@32@0:8q16^@24
r^{CGPath=}16@0:8
r^{EPolygonList=ii^{EPolygon}i}16@0:8
r^v24@0:8q16
^{CGPath=}
{shared_ptr<apple::vision::libraries::autotrace::EPolygonList>="__ptr_"^{EPolygonList}"__cntrl_"^{__shared_weak_count}}
{vector<unsigned int, std::allocator<unsigned int>>="__begin_"^I"__end_"^I"__end_cap_"{__compressed_pair<unsigned int *, std::allocator<unsigned int>>="__value_"^I}}
{vector<std::vector<unsigned int>, std::allocator<std::vector<unsigned int>>>="__begin_"^v"__end_"^v"__end_cap_"{__compressed_pair<std::vector<unsigned int> *, std::allocator<std::vector<unsigned int>>>="__value_"^v}}
@48@0:8{?=qiIq}16q40
^{__CVBuffer=}72@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24@56^@64
@24@0:8r^v16
@88@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24@56@64@72^@80
@"CIFilter"
@"VNDetectContoursRequest"
^{CGColorSpace=}
@"ParabolaDetection"
{shared_ptr<vision::mod::FaceRegionMap>="__ptr_"^{FaceRegionMap}"__cntrl_"^{__shared_weak_count}}
{?={?=qiIq}{?=qiIq}}16@0:8
v64@0:8{?={?=qiIq}{?=qiIq}}16
@"NSPointerArray"
{?="start"{?="value"q"timescale"i"flags"I"epoch"q}"duration"{?="value"q"timescale"i"flags"I"epoch"q}}
@48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
@56@0:8Q16{CGRect={CGPoint=dd}{CGSize=dd}}24
@56@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24
v80@0:8{CGPoint=dd}16{CGPoint=dd}32{CGPoint=dd}48{CGPoint=dd}64
@"VNPixelBufferObservation"
B36@0:8f16^i20^@28
@88@0:8Q16{CGRect={CGPoint=dd}{CGSize=dd}}24{CGRect={CGPoint=dd}{CGSize=dd}}56
@64@0:8Q16{CGRect={CGPoint=dd}{CGSize=dd}}24@56
@80@0:8Q16{CGRect={CGPoint=dd}{CGSize=dd}}24@56@64@72
@72@0:8Q16{CGRect={CGPoint=dd}{CGSize=dd}}24@56@64
@112@0:8Q16{CGRect={CGPoint=dd}{CGSize=dd}}24{CGRect={CGPoint=dd}{CGSize=dd}}56@88@96@104
@104@0:8Q16{CGRect={CGPoint=dd}{CGSize=dd}}24{CGRect={CGPoint=dd}{CGSize=dd}}56@88@96
B104@0:8{?=[4]}16^f80^f88^f96
{?=[4]}16@0:8
{?=}16@0:8
B24@0:8^{CGAffineTransform=dddddd}16
v88@0:8@16@24^{CGPath=}32{CGAffineTransform=dddddd}40
B32@0:8^i16^@24
{_Geometry2D_rect2D_={_Geometry2D_point2D_=ff}{_Geometry2D_size2D_=ff}}16@0:8
v32@0:8{_Geometry2D_rect2D_={_Geometry2D_point2D_=ff}{_Geometry2D_size2D_=ff}}16
@"VNFaceLandmarks2D"
@"VNFaceLandmarks3D"
@"VNFaceRegionMap"
@"VNFaceAttributes"
@"VNFaceTorsoprint"
@"VNFaceSegments"
@"VNFaceLegacyFaceCore"
@"VNFaceGaze"
@"VNFaceScreenGaze"
{CGAffineTransform=dddddd}16@0:8
v64@0:8{CGAffineTransform=dddddd}16
{CGAffineTransform="a"d"b"d"c"d"d"d"tx"d"ty"d}
{?=[3]}16@0:8
v64@0:8{?=[3]}16
{?="columns"[3]}
@"VNImageprint"
@36@0:8Q16@24f32
@44@0:8Q16@24f32@36
@44@0:8@16@24f32@36
B24@0:8f16f20
@"<VNOperationPointsProviding>"
@68@0:8Q16{CGRect={CGPoint=dd}{CGSize=dd}}24f56@60
@"MLFeatureValue"
@40@0:8@16@24^{__CVBuffer=}32
@88@0:8Q16{CGPoint=dd}24{CGPoint=dd}40{CGPoint=dd}56{CGPoint=dd}72
@80@0:8{CGPoint=dd}16{CGPoint=dd}32{CGPoint=dd}48{CGPoint=dd}64
@88@0:8@16{CGPoint=dd}24{CGPoint=dd}40{CGPoint=dd}56{CGPoint=dd}72
@120@0:8@16{CGPoint=dd}24{CGPoint=dd}40{CGPoint=dd}56{CGPoint=dd}72{CGRect={CGPoint=dd}{CGSize=dd}}88
{CGPoint="x"d"y"d}
{CGAffineTransform=dddddd}32@0:8Q16Q24
f32@0:8@16^@24
16@0:8
@"VNImageSignature"
@"LKTOpticalFlow"
^{OpaqueVTPixelTransferSession=}
^{OpaqueVTPixelRotationSession=}
{unique_ptr<SessionsHandler<VNVTPixelTransferSession>, std::default_delete<SessionsHandler<VNVTPixelTransferSession>>>="__ptr_"{__compressed_pair<SessionsHandler<VNVTPixelTransferSession> *, std::default_delete<SessionsHandler<VNVTPixelTransferSession>>>="__value_"^v}}
{unique_ptr<SessionsHandler<VNVTImageRotationSession>, std::default_delete<SessionsHandler<VNVTImageRotationSession>>>="__ptr_"{__compressed_pair<SessionsHandler<VNVTImageRotationSession> *, std::default_delete<SessionsHandler<VNVTImageRotationSession>>>="__value_"^v}}
B48@0:8^@16#24Q32^@40
{CGRect={CGPoint=dd}{CGSize=dd}}32@0:8Q16Q24
@56@0:8{shared_ptr<vision::mod::FaceID3Model>=^{FaceID3Model}^{__shared_weak_count}}16@32@40@48
{shared_ptr<vision::mod::FaceID3Model>="__ptr_"^{FaceID3Model}"__cntrl_"^{__shared_weak_count}}
B48@0:8@16@24Q32@40
B32@0:8@16@24
B108@0:8{vImage_Buffer=^vQQQ}16{vImage_Buffer=^vQQQ}48{CGSize=dd}80f96f100f104
f48@0:8{vImage_Buffer=^vQQQ}16
@52@0:8{vImage_Buffer=^vQQQ}16f48
@56@0:8{vImage_Buffer=^vQQQ}16f48B52
@40@0:8^{__CVBuffer=}16f24B28^@32
@64@0:8{vImage_Buffer=^vQQQ}16@48^@56
@100@0:8{vImage_Buffer=^vQQQ}16@48B56B60{CGSize=dd}64f80f84f88^@92
@76@0:8^{__CVBuffer=}16@24B32B36{CGSize=dd}40f56f60f64^@68
{unordered_map<apple::vision::BufferSizeFormat, __CVPixelBufferPool *, std::hash<apple::vision::BufferSizeFormat>, std::equal_to<apple::vision::BufferSizeFormat>, std::allocator<std::pair<const apple::vision::BufferSizeFormat, __CVPixelBufferPool *>>>="__table_"{__hash_table<std::__hash_value_type<apple::vision::BufferSizeFormat, __CVPixelBufferPool *>, std::__unordered_map_hasher<apple::vision::BufferSizeFormat, std::__hash_value_type<apple::vision::BufferSizeFormat, __CVPixelBufferPool *>, std::hash<apple::vision::BufferSizeFormat>, std::equal_to<apple::vision::BufferSizeFormat>, true>, std::__unordered_map_equal<apple::vision::BufferSizeFormat, std::__hash_value_type<apple::vision::BufferSizeFormat, __CVPixelBufferPool *>, std::equal_to<apple::vision::BufferSizeFormat>, std::hash<apple::vision::BufferSizeFormat>, true>, std::allocator<std::__hash_value_type<apple::vision::BufferSizeFormat, __CVPixelBufferPool *>>>="__bucket_list_"{unique_ptr<std::__hash_node_base<std::__hash_node<std::__hash_value_type<apple::vision::BufferSizeFormat, __CVPixelBufferPool *>, void *> *> *[], std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<apple::vision::BufferSizeFormat, __CVPixelBufferPool *>, void *> *> *>>>="__ptr_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<apple::vision::BufferSizeFormat, __CVPixelBufferPool *>, void *> *> **, std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<apple::vision::BufferSizeFormat, __CVPixelBufferPool *>, void *> *> *>>>="__value_"^^v"__value_"{__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<apple::vision::BufferSizeFormat, __CVPixelBufferPool *>, void *> *> *>>="__data_"{__compressed_pair<unsigned long, std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<apple::vision::BufferSizeFormat, __CVPixelBufferPool *>, void *> *> *>>="__value_"Q}}}}"__p1_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<apple::vision::BufferSizeFormat, __CVPixelBufferPool *>, void *> *>, std::allocator<std::__hash_node<std::__hash_value_type<apple::vision::BufferSizeFormat, __CVPixelBufferPool *>, void *>>>="__value_"{__hash_node_base<std::__hash_node<std::__hash_value_type<apple::vision::BufferSizeFormat, __CVPixelBufferPool *>, void *> *>="__next_"^v}}"__p2_"{__compressed_pair<unsigned long, std::__unordered_map_hasher<apple::vision::BufferSizeFormat, std::__hash_value_type<apple::vision::BufferSizeFormat, __CVPixelBufferPool *>, std::hash<apple::vision::BufferSizeFormat>, std::equal_to<apple::vision::BufferSizeFormat>, true>>="__value_"Q}"__p3_"{__compressed_pair<float, std::__unordered_map_equal<apple::vision::BufferSizeFormat, std::__hash_value_type<apple::vision::BufferSizeFormat, __CVPixelBufferPool *>, std::equal_to<apple::vision::BufferSizeFormat>, std::hash<apple::vision::BufferSizeFormat>, true>>="__value_"f}}}
@"VNDetector"40@0:8@"NSString"16@"NSDictionary"24^@32
@"VNDetector"40@0:8#16@"NSDictionary"24^@32
v32@0:8#16@24
v32@0:8#16@"NSDictionary"24
@"<VNDetectorCacheDelegate>"
{?="reportDidCacheDetector"b1"reportDidEvictDetector"b1}
@"NSMutableSet"
@56@0:8Q16r^v24Q32Q40^@48
@24@0:8^{__CVBuffer=}16
B32@0:8^{__CVBuffer=}16^{__CVBuffer=}24
Q24@0:8^{__CVBuffer=}16
@"VNCIContrastFromAverageColorFilter"
@"VNCIContrastWithPivotColorFilter"
v20@0:8I16
B48@0:8@16@24^@32^@40
B40@0:8@16^{__CVBuffer=}24^@32
B48@0:8@16^{__CVBuffer=}24^@32^@40
B44@0:8@16^{__CVBuffer=}24I32^@36
B52@0:8@16^{__CVBuffer=}24I32^@36^@44
B40@0:8@16^{CGImage=}24^@32
B48@0:8@16^{CGImage=}24^@32^@40
B44@0:8@16^{CGImage=}24I32^@36
B52@0:8@16^{CGImage=}24I32^@36^@44
B44@0:8@16@24I32^@36
B52@0:8@16@24I32^@36^@44
B40@0:8@16^{opaqueCMSampleBuffer=}24^@32
B48@0:8@16^{opaqueCMSampleBuffer=}24^@32^@40
B44@0:8@16^{opaqueCMSampleBuffer=}24I32^@36
B52@0:8@16^{opaqueCMSampleBuffer=}24I32^@36^@44
@"VNSession"
@"VNRequestPerformer"
@"VNResourceVersion"
#32@0:8@16@24
@72@0:8@16@24@32@40@48@56@64
{BufferSize=QQ}68@0:8{BufferSize=QQ}16{BufferSize=QQ}32{BufferSize=QQ}48B64
{optional<std::tuple<std::unordered_map<NSString *, __CVBuffer *>, std::unordered_map<NSString *, espresso_buffer_t>>>=(?=c{tuple<std::unordered_map<NSString *, __CVBuffer *>, std::unordered_map<NSString *, espresso_buffer_t>>={__tuple_impl<std::__tuple_indices<0, 1>, std::unordered_map<NSString *, __CVBuffer *>, std::unordered_map<NSString *, espresso_buffer_t>>={unordered_map<NSString *, __CVBuffer *, std::hash<NSString *>, std::equal_to<NSString *>, std::allocator<std::pair<NSString *const, __CVBuffer *>>>={__hash_table<std::__hash_value_type<NSString *, __CVBuffer *>, std::__unordered_map_hasher<NSString *, std::__hash_value_type<NSString *, __CVBuffer *>, std::hash<NSString *>, std::equal_to<NSString *>, true>, std::__unordered_map_equal<NSString *, std::__hash_value_type<NSString *, __CVBuffer *>, std::equal_to<NSString *>, std::hash<NSString *>, true>, std::allocator<std::__hash_value_type<NSString *, __CVBuffer *>>>={unique_ptr<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, __CVBuffer *>, void *> *> *[], std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, __CVBuffer *>, void *> *> *>>>={__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, __CVBuffer *>, void *> *> **, std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, __CVBuffer *>, void *> *> *>>>=^^v{__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, __CVBuffer *>, void *> *> *>>={__compressed_pair<unsigned long, std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, __CVBuffer *>, void *> *> *>>=Q}}}}{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, __CVBuffer *>, void *> *>, std::allocator<std::__hash_node<std::__hash_value_type<NSString *, __CVBuffer *>, void *>>>={__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, __CVBuffer *>, void *> *>=^v}}{__compressed_pair<unsigned long, std::__unordered_map_hasher<NSString *, std::__hash_value_type<NSString *, __CVBuffer *>, std::hash<NSString *>, std::equal_to<NSString *>, true>>=Q}{__compressed_pair<float, std::__unordered_map_equal<NSString *, std::__hash_value_type<NSString *, __CVBuffer *>, std::equal_to<NSString *>, std::hash<NSString *>, true>>=f}}}{unordered_map<NSString *, espresso_buffer_t, std::hash<NSString *>, std::equal_to<NSString *>, std::allocator<std::pair<NSString *const, espresso_buffer_t>>>={__hash_table<std::__hash_value_type<NSString *, espresso_buffer_t>, std::__unordered_map_hasher<NSString *, std::__hash_value_type<NSString *, espresso_buffer_t>, std::hash<NSString *>, std::equal_to<NSString *>, true>, std::__unordered_map_equal<NSString *, std::__hash_value_type<NSString *, espresso_buffer_t>, std::equal_to<NSString *>, std::hash<NSString *>, true>, std::allocator<std::__hash_value_type<NSString *, espresso_buffer_t>>>={unique_ptr<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, espresso_buffer_t>, void *> *> *[], std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, espresso_buffer_t>, void *> *> *>>>={__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, espresso_buffer_t>, void *> *> **, std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, espresso_buffer_t>, void *> *> *>>>=^^v{__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, espresso_buffer_t>, void *> *> *>>={__compressed_pair<unsigned long, std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, espresso_buffer_t>, void *> *> *>>=Q}}}}{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, espresso_buffer_t>, void *> *>, std::allocator<std::__hash_node<std::__hash_value_type<NSString *, espresso_buffer_t>, void *>>>={__hash_node_base<std::__hash_node<std::__hash_value_type<NSString *, espresso_buffer_t>, void *> *>=^v}}{__compressed_pair<unsigned long, std::__unordered_map_hasher<NSString *, std::__hash_value_type<NSString *, espresso_buffer_t>, std::hash<NSString *>, std::equal_to<NSString *>, true>>=Q}{__compressed_pair<float, std::__unordered_map_equal<NSString *, std::__hash_value_type<NSString *, espresso_buffer_t>, std::equal_to<NSString *>, std::hash<NSString *>, true>>=f}}}}})B}48@0:8@16@24@32^@40
@"<MTLComputePipelineState>"
q40@0:8@16^^{MPClusteringTreeNode}24@32
f28@0:8^{MPClusteringTreeNode=@iffi^{MPClusteringTreeNode}^{MPClusteringTreeNode}^{MPClusteringTreeNode}^{MPClusteringTreeNode}}16i24
{vector<MPClusteringTreeNode *, std::allocator<MPClusteringTreeNode *>>=^^{MPClusteringTreeNode}^^{MPClusteringTreeNode}{__compressed_pair<MPClusteringTreeNode **, std::allocator<MPClusteringTreeNode *>>=^^{MPClusteringTreeNode}}}40@0:8i16f20^{MPClusteringTreeNode=@iffi^{MPClusteringTreeNode}^{MPClusteringTreeNode}^{MPClusteringTreeNode}^{MPClusteringTreeNode}}24@32
{vector<MPClusteringTreeNode *, std::allocator<MPClusteringTreeNode *>>=^^{MPClusteringTreeNode}^^{MPClusteringTreeNode}{__compressed_pair<MPClusteringTreeNode **, std::allocator<MPClusteringTreeNode *>>=^^{MPClusteringTreeNode}}}36@0:8i16^{MPClusteringTreeNode=@iffi^{MPClusteringTreeNode}^{MPClusteringTreeNode}^{MPClusteringTreeNode}^{MPClusteringTreeNode}}20@28
{vector<MPClusteringTreeNode *, std::allocator<MPClusteringTreeNode *>>=^^{MPClusteringTreeNode}^^{MPClusteringTreeNode}{__compressed_pair<MPClusteringTreeNode **, std::allocator<MPClusteringTreeNode *>>=^^{MPClusteringTreeNode}}}36@0:8f16^{MPClusteringTreeNode=@iffi^{MPClusteringTreeNode}^{MPClusteringTreeNode}^{MPClusteringTreeNode}^{MPClusteringTreeNode}}20@28
{vector<MPClusteringTreeNode *, std::allocator<MPClusteringTreeNode *>>=^^{MPClusteringTreeNode}^^{MPClusteringTreeNode}{__compressed_pair<MPClusteringTreeNode **, std::allocator<MPClusteringTreeNode *>>=^^{MPClusteringTreeNode}}}32@0:8^{MPClusteringTreeNode=@iffi^{MPClusteringTreeNode}^{MPClusteringTreeNode}^{MPClusteringTreeNode}^{MPClusteringTreeNode}}16@24
f28@0:8f16q20
f32@0:8f16q20B28
@64@0:8@16@24{?=^vi}32^v48^v56
{?=^vi}16@0:8
{?="plan"^v"network_index"i}
@40@0:8@16^@24^@32
B56@0:8^Q16^Q24@32@40^@48
B84@0:8@16@24B32@36@44@52Q60^@68^@76
B88@0:8@16@24B32@36@44@52i60Q64^@72^@80
^{__CVBuffer=}36@0:8I16r^{?=^v^v[4Q][4Q]QQQQQQQQQQi}20^@28
B40@0:8r^{?=^v^v[4Q][4Q]QQQQQQQQQQi}16^{__CVBuffer=}24^@32
Q32@0:8r^{?=^v^v[4Q][4Q]QQQQQQQQQQi}16^@24
B52@0:8^{?=^vi}16@24@32B40^@44
{?="data"^v"reserved"^v"dim"[4Q]"stride"[4Q]"width"Q"height"Q"channels"Q"batch_number"Q"sequence_length"Q"stride_width"Q"stride_height"Q"stride_channels"Q"stride_batch_number"Q"stride_sequence_length"Q"storage_type"i}
v32@0:8{CGPoint=dd}16
@40@0:8{CGPoint=dd}16@?32
@28@0:8i16i20i24
{unique_ptr<apple::vision::OpticalFlow::LKTCPU, std::default_delete<apple::vision::OpticalFlow::LKTCPU>>="__ptr_"{__compressed_pair<apple::vision::OpticalFlow::LKTCPU *, std::default_delete<apple::vision::OpticalFlow::LKTCPU>>="__value_"^{LKTCPU}}}
@32@0:8r^{?=*QQQQ}16Q24
@"VNTensorShape"
{CGSize=dd}20@0:8i16
v72@0:8@16^v24^{__CVBuffer=}32{vImage_Buffer=^vQQQ}40
B112@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16Q48Q56Q64f72f76^Q80^Q88^v96^@104
@64@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24Q56
24@0:8Q16
r^{CGPoint=dd}16@0:8
r^{CGPoint=dd}32@0:8{CGSize=dd}16
@88@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24q56^64Q72@80
r^16@0:8
@72@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24^56Q64
v24@0:8r^16
^v32@0:8r^i16Q24
@92@0:8@16@24Q32{CGRect={CGPoint=dd}{CGSize=dd}}40{_Geometry2D_rect2D_={_Geometry2D_point2D_=ff}{_Geometry2D_size2D_=ff}}72f88
@40@0:8@16r^i24Q32
@108@0:8@16@24Q32Q40@48{CGRect={CGPoint=dd}{CGSize=dd}}56{_Geometry2D_rect2D_={_Geometry2D_point2D_=ff}{_Geometry2D_size2D_=ff}}88f104
@40@0:8q16r^i24Q32
@"VNFaceLandmarkRegion2D"
@"VNFaceLandmarkRegion3D"
@40@0:8^{__CVBuffer=}16Q24^@32
B48@0:8Q16Q24@?32^@40
B64@0:8@16@24#32Q40Q48^@56
B48@0:8@16Q24@32^@40
B56@0:8@16#24Q32@40^@48
B40@0:8@16#24^@32
B48@0:8@16#24@32^@40
B28@0:8f16^@20
B48@0:8^B16@24@32^@40
B52@0:8^B16@24@32B40^@44
B48@0:8^Q16@24@32^@40
B56@0:8^q16@24@32q40^@48
B56@0:8^Q16@24@32Q40^@48
B48@0:8^i16@24@32^@40
B56@0:8^i16@24@32i40i44^@48
B52@0:8^i16@24@32i40^@44
B56@0:8^f16@24@32f40f44^@48
B48@0:8^I16@24@32^@40
B52@0:8^I16@24@32I40^@44
B72@0:8^@16@24@32#40Q48Q56^@64
@48@0:8@16@24#32^@40
@40@0:8@16#24^@32
C16@0:8
@24@0:8r^*16
@"MPImageDescriptor_LegacySupportDoNotChange"
@"MLFeatureValue"24@0:8@"NSString"16
@"NSSet"16@0:8
@40@0:8^{__CVBuffer=}16@24@32
@48@0:8@16q24@32@40
@"VNSceneprint"
@"<MLFeatureProvider>"
v32@0:8q16q24
@40@0:8^{__CVBuffer=}16@24^@32
@"MLModel"
@"MLObjectBoundingBoxOutputDescription"
@"VNCoreMLModel"
@32@0:8@16^{?=ff[9{?=ff}][9{?=ff}]}24
r^{?=ff[9{?=ff}][9{?=ff}]}32@0:8@16^@24
^{?=ff[9{?=ff}][9{?=ff}]}
@"VNSmartCam5CompoundRequestGroupingConfiguration"
B92@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24^{ImageDescriptorProcessorAbstract=^^?}56B64@68^^{__CVBuffer}76^@84
B136@0:8@16^^{__CVBuffer}24{CGRect={CGPoint=dd}{CGSize=dd}}32^{ImageDescriptorProcessorAbstract=^^?}64i72I76^v80@88@96@104^Q112^Q120^@128
B64@0:8^v16^v24^v32@40@48^@56
@60@0:8r^v16^v24f32@36@44^@52
@88@0:8r^v16^v24^{ImageClassifier_HierarchicalModel=^{ImageClassfier_Graph}}32f40f44Q48Q56@64@72^@80
B52@0:8@16@24r^{__CVBuffer=}32i40^@44
B84@0:8@16@24r^{__CVBuffer=}32i40I44r^v48i56I60f64I68B72^@76
{map<int, InternalObservedParabola, std::less<int>, std::allocator<std::pair<const int, InternalObservedParabola>>>="__tree_"{__tree<std::__value_type<int, InternalObservedParabola>, std::__map_value_compare<int, std::__value_type<int, InternalObservedParabola>, std::less<int>, true>, std::allocator<std::__value_type<int, InternalObservedParabola>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<int, InternalObservedParabola>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<int, std::__value_type<int, InternalObservedParabola>, std::less<int>, true>>="__value_"Q}}}
{ParabolaSearchBuffer="maxFramesSkippedForDetection"i"minRegionSizeX"i"minRegionSizeY"i"contourPointsQ"{deque<std::vector<CGPointWithPts>, std::allocator<std::vector<CGPointWithPts>>>="__map_"{__split_buffer<std::vector<CGPointWithPts> *, std::allocator<std::vector<CGPointWithPts> *>>="__first_"^^v"__begin_"^^v"__end_"^^v"__end_cap_"{__compressed_pair<std::vector<CGPointWithPts> **, std::allocator<std::vector<CGPointWithPts> *>>="__value_"^^v}}"__start_"Q"__size_"{__compressed_pair<unsigned long, std::allocator<std::vector<CGPointWithPts>>>="__value_"Q}}}
{InternalParameters="minRegionSizeX"i"minRegionSizeY"i"initialYDiffLimit"f"startingMinDiffDeviation"f"maxDistanceForSolution"f"frameWidth"i"frameHeight"i"xScaleFactor"f"yScaleFactor"f"runningMinDiffDeviation"i"maxFrameSkipScaleFactor"f"majorAxisScaler"f"minorAxisScalar"f"contourSizeUpperBound"f"contourSizeLowerBound"f"maxRadiusToCompensate"f"maxRadiusBasedDeviation"f"xConsistencyDeviation"f"rejectionScaler"f}
{map<int, ObservedParabola, std::less<int>, std::allocator<std::pair<const int, ObservedParabola>>>="__tree_"{__tree<std::__value_type<int, ObservedParabola>, std::__map_value_compare<int, std::__value_type<int, ObservedParabola>, std::less<int>, true>, std::allocator<std::__value_type<int, ObservedParabola>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<int, ObservedParabola>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<int, std::__value_type<int, ObservedParabola>, std::less<int>, true>>="__value_"Q}}}
{ForestAlgoParams="FAFrameRate"f"parabolaLength"i"minXDistanceFromLastPointOnParabola"i"maxXDistanceFromLastPointOnParabola"i"minYDistanceFromLastPointOnParabola"i"maxYDistanceFromLastPointOnParabola"i"maxFramesSkippedToContinueParabolaDetection"i"minObjectSize"i}
B68@0:8^@16@24I32^@36@44@52^@60
@48@0:8{?=qiIq}16@?40
^{__MRCContext=}
@96@0:8Q16Q24Q32@40Q48{CGRect={CGPoint=dd}{CGSize=dd}}56@88
^{__CVBuffer=}32@0:8Q16^@24
^{__CVBuffer=}68@0:8Q16{CGRect={CGPoint=dd}{CGSize=dd}}24B56^@60
{vImage_Buffer=^vQQQ}56@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24
^{__CVBuffer=}40@0:8{CGSize=dd}16^@32
{vector<float, std::allocator<float>>="__begin_"^f"__end_"^f"__end_cap_"{__compressed_pair<float *, std::allocator<float>>="__value_"^f}}
^{__sFILE=*iiss{__sbuf=*i}i^v^?^?^?^?{__sbuf=*i}^{__sFILEX}i[3C][1C]{__sbuf=*i}iq}16@0:8
@24@0:8r^{mapped_model_file=^^?Q}16
r^{mapped_model_file=^^?Q}
{unique_ptr<cvml::util::model_file_cache, std::default_delete<cvml::util::model_file_cache>>="__ptr_"{__compressed_pair<cvml::util::model_file_cache *, std::default_delete<cvml::util::model_file_cache>>="__value_"^{model_file_cache}}}
v32@0:8@"VNDetectorCache"16@"VNDetector"24
@"VNTracker"32@0:8@"NSDictionary"16^@24
v24@0:8@"VNTracker"16
@"VNRPNTrackerEspressoResources"32@0:8@"NSDictionary"16^@24
B32@0:8@"NSArray"16^@24
@32@0:8#16@24
@"VNFrameworkManager"
@"VNDetectorCache"
@"VNVTSessionManager"
@"VNCIContextManager"
@"VNTrackerManager"
@"VNCVPixelBufferPoolManager"
@40@0:8r^16q24^@32
B44@0:8^d16@24B32^@36
B40@0:8^d16@24^@32
f24@0:8f16f20
@24@0:8I16I20
@28@0:8I16I20I24
B20@0:8f16
@40@0:8q16Q24^@32
@"VNDetectBarcodesRequest"
@"VNCIContextsHandler"
@32@0:8@16d24
@"VNPoint"
B56@0:8^@16^@24Q32@40^@48
{shared_ptr<vision::mod::ImageClassifier_HierarchicalModel>=^{ImageClassifier_HierarchicalModel}^{__shared_weak_count}}32@0:8Q16^@24
@88@0:8r^{__CVBuffer=}16@24{CGRect={CGPoint=dd}{CGSize=dd}}32@64^@72@?80
{shared_ptr<vision::mod::ImageClassifier_HierarchicalModel>="__ptr_"^{ImageClassifier_HierarchicalModel}"__cntrl_"^{__shared_weak_count}}
{map<unsigned long, std::shared_ptr<std::vector<std::shared_ptr<vision::mod::ImageAnalyzer_CustomClassifier>>>, std::less<unsigned long>, std::allocator<std::pair<const unsigned long, std::shared_ptr<std::vector<std::shared_ptr<vision::mod::ImageAnalyzer_CustomClassifier>>>>>>="__tree_"{__tree<std::__value_type<unsigned long, std::shared_ptr<std::vector<std::shared_ptr<vision::mod::ImageAnalyzer_CustomClassifier>>>>, std::__map_value_compare<unsigned long, std::__value_type<unsigned long, std::shared_ptr<std::vector<std::shared_ptr<vision::mod::ImageAnalyzer_CustomClassifier>>>>, std::less<unsigned long>, true>, std::allocator<std::__value_type<unsigned long, std::shared_ptr<std::vector<std::shared_ptr<vision::mod::ImageAnalyzer_CustomClassifier>>>>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<unsigned long, std::shared_ptr<std::vector<std::shared_ptr<vision::mod::ImageAnalyzer_CustomClassifier>>>>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<unsigned long, std::__value_type<unsigned long, std::shared_ptr<std::vector<std::shared_ptr<vision::mod::ImageAnalyzer_CustomClassifier>>>>, std::less<unsigned long>, true>>="__value_"Q}}}
{unique_ptr<vision::mod::ImageAnalyzer_PCA, std::default_delete<vision::mod::ImageAnalyzer_PCA>>="__ptr_"{__compressed_pair<vision::mod::ImageAnalyzer_PCA *, std::default_delete<vision::mod::ImageAnalyzer_PCA>>="__value_"^{ImageAnalyzer_PCA}}}
@"_VNImageAnalyzerMultiDetectorSceneOperationPointsCache"
{map<unsigned long, std::shared_ptr<vision::mod::ImageAnalyzer_CustomClassifier>, std::less<unsigned long>, std::allocator<std::pair<const unsigned long, std::shared_ptr<vision::mod::ImageAnalyzer_CustomClassifier>>>>="__tree_"{__tree<std::__value_type<unsigned long, std::shared_ptr<vision::mod::ImageAnalyzer_CustomClassifier>>, std::__map_value_compare<unsigned long, std::__value_type<unsigned long, std::shared_ptr<vision::mod::ImageAnalyzer_CustomClassifier>>, std::less<unsigned long>, true>, std::allocator<std::__value_type<unsigned long, std::shared_ptr<vision::mod::ImageAnalyzer_CustomClassifier>>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<unsigned long, std::shared_ptr<vision::mod::ImageAnalyzer_CustomClassifier>>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<unsigned long, std::__value_type<unsigned long, std::shared_ptr<vision::mod::ImageAnalyzer_CustomClassifier>>, std::less<unsigned long>, true>>="__value_"Q}}}
{shared_ptr<const std::vector<std::tuple<std::string, float, bool>>>="__ptr_"^v"__cntrl_"^{__shared_weak_count}}
@"VNRecognizeDocumentElementsRequestElementConfiguration"
{shared_ptr<vision::mod::TorsoprintGenerator>="__ptr_"^{TorsoprintGenerator}"__cntrl_"^{__shared_weak_count}}
v28@0:8Q16I24
I28@0:8Q16I24
v36@0:8Q16Q24I32
^f16@0:8
v24@0:8^f16
*16@0:8
v24@0:8*16
^Q16@0:8
v24@0:8^Q16
^S16@0:8
v24@0:8^S16
S16@0:8
v20@0:8S16
s16@0:8
v20@0:8s16
v48@0:8{vImage_Buffer=^vQQQ}16
i48@0:8Q16Q24Q32^{vImage_Buffer=^vQQQ}40
i88@0:8{vImage_Buffer=^vQQQ}16{vImage_Buffer=^vQQQ}48*80
v56@0:8S16^f20^{__CCPulseWindowContext=^{__CCRange}SSsB}28C36C40{ThresholdSet_t=fff}44
i56@0:8S16C20C24{ThresholdSet_t=fff}28^f40Q48
v48@0:8^{__CCRange=SS}16*24^i32^i40
i28@0:8^{__CCSumDerivVectors=^f^f^f^f^fffii}16i24
v24@0:8^{__CCSumDerivVectors=^f^f^f^f^fffii}16
v32@0:8^{__CCSumDerivVectors=^f^f^f^f^fffii}16i24C28
i72@0:8C16^f20S28C32C36^{__CCFilterSumDerivConfig={__CCRange=SS}{__CCRange=SS}BBQQ}40S48{ThresholdSet_t=fff}52*64
i96@0:8^f16S24S28C32C36S40S44I48I52S56{ThresholdSet_t=fff}60*72^f80Q88
v52@0:8Q16Q24Q32C40S44S48
v40@0:8Q16Q24S32S36
v44@0:8Q16^S24C32S36S40
i56@0:8^{__rgbaColor=CCCC}16^{__rgbaColor=CCCC}24I32I36^{__rgbMinMaxU8=CCCCCC}40^{__rgbMinMaxFloat=ffffff}48
I92@0:8{vImage_Buffer=^vQQQ}16{vImage_Buffer=^vQQQ}48C80^{__rgbMinMaxFloat=ffffff}84
f88@0:8{vImage_Buffer=^vQQQ}16{vImage_Buffer=^vQQQ}48S80S84
v64@0:8{vImage_Buffer=^vQQQ}16^{__CCColorProfileContext={vImage_Buffer=^vQQQ}{vImage_Buffer=^vQQQ}{vImage_Buffer=^vQQQ}{vImage_Buffer=^vQQQ}iiSS}48S56S60
v60@0:8{vImage_Buffer=^vQQQ}16S48^{__CCColorProfileContext={vImage_Buffer=^vQQQ}{vImage_Buffer=^vQQQ}{vImage_Buffer=^vQQQ}{vImage_Buffer=^vQQQ}iiSS}52
S40@0:8^f16Q24^S32
i72@0:8{vImage_Buffer=^vQQQ}16S48^S52f60^S64
v24@0:8^{__CCColorProfileContext={vImage_Buffer=^vQQQ}{vImage_Buffer=^vQQQ}{vImage_Buffer=^vQQQ}{vImage_Buffer=^vQQQ}iiSS}16
i40@0:8^{__CCColorProfileContext={vImage_Buffer=^vQQQ}{vImage_Buffer=^vQQQ}{vImage_Buffer=^vQQQ}{vImage_Buffer=^vQQQ}iiSS}16S24S28Q32
i152@0:8{vImage_Buffer=^vQQQ}16{vImage_Buffer=^vQQQ}48{vImage_Buffer=^vQQQ}80^{__rgbMinMaxU8=CCCCCC}112^{__rgbMinMaxFloat=ffffff}120S128S132S136^I140C148
i84@0:8{vImage_Buffer=^vQQQ}16{vImage_Buffer=^vQQQ}48C80
i80@0:8{vImage_Buffer=^vQQQ}16{vImage_Buffer=^vQQQ}48
i92@0:8@16Q24{vImage_Buffer=^vQQQ}32^Q64^{__CCBigBox=SSSS[50{__CCCharBox=SSSSS}]}72^{__CCBigBox=SSSS[50{__CCCharBox=SSSSS}]}80C88
v72@0:8@16^{__CCBigBox=SSSS[50{__CCCharBox=SSSSS}]}24{vImage_Buffer=^vQQQ}32C64S68
v32@0:8^{__CCBox=SSSS}16^Q24
i32@0:8^{__CCBox=SSSS}16^Q24
i56@0:8*16S24S28Q32Q40S48S52
{__CCRange=SS}76@0:8{vImage_Buffer=^vQQQ}16S48S52S56S60Q64S72
v156@0:8{vImage_Buffer=^vQQQ}16*48{vImage_Buffer=^vQQQ}56{vImage_Buffer=^vQQQ}88S120S124^{__CCBox=SSSS}128^{__CCBox=SSSS}136^Q144C152
v60@0:8^f16^f24S32S36^B40^f48C56
v84@0:8{vImage_Buffer=^vQQQ}16S48S52S56^{__rgbMinMaxFloat=ffffff}60^f68^f76
i80@0:8{vImage_Buffer=^vQQQ}16f48f52S56^f60^f68C76
I48@0:8^{__CCBigBox=SSSS[50{__CCCharBox=SSSSS}]}16C24^S28^S36B44
v40@0:8Q16Q24Q32
v72@0:8{vImage_Buffer=^vQQQ}16^f48^f56S64S68
v56@0:8^{__CCCharBox=SSSSS}16^{__CCCharBox=SSSSS}24^S32^S40S48S52
S48@0:8^{__CCCharBox=SSSSS}16^{__CCBigBox=SSSS[50{__CCCharBox=SSSSS}]}24^S32^S40
i76@0:8^{__CCBigBox=SSSS[50{__CCCharBox=SSSSS}]}16^{__CCBigBox=SSSS[50{__CCCharBox=SSSSS}]}24C32S36S40C44S48S52^{__CCCharBox=SSSSS}56^{__CCCharBox=SSSSS}64C72
i180@0:8{vImage_Buffer=^vQQQ}16{vImage_Buffer=^vQQQ}48{vImage_Buffer=^vQQQ}80^{__CCBigBox=SSSS[50{__CCCharBox=SSSSS}]}112^{__CCBigBox=SSSS[50{__CCCharBox=SSSSS}]}120^{__CCCharBox=SSSSS}128^{__CCCharBox=SSSSS}136S144S148S152*156C164^S168C176
i52@0:8{vImage_Buffer=^vQQQ}16S48
v60@0:8{vImage_Buffer=^vQQQ}16Q48B56
i24@0:8Q16
i68@0:8^{__CCBigBox=SSSS[50{__CCCharBox=SSSSS}]}16C24S28Q32^{__CCBox=SSSS}40Q48S56*60
i160@0:8@16{vImage_Buffer=^vQQQ}24*56^{__CCBigBox=SSSS[50{__CCCharBox=SSSSS}]}64^{__CCBigBox=SSSS[50{__CCCharBox=SSSSS}]}72{vImage_Buffer=^vQQQ}80{vImage_Buffer=^vQQQ}112^{__rgbMinMaxFloat=ffffff}144C152C156
i88@0:8{vImage_Buffer=^vQQQ}16{vImage_Buffer=^vQQQ}48^S80
@56@0:8{vImage_Buffer=^vQQQ}16^@48
v20@0:8C16
@"CCCharBoxContext"
@64@0:8{shared_ptr<vision::mod::FaceIDModel>=^{FaceIDModel}^{__shared_weak_count}}16@32Q40@48@56
B48@0:8^Q16^Q24@32^@40
B40@0:8^{?=^v^v[4Q][4Q]QQQQQQQQQQi}16@24^@32
B44@0:8^{?=^v^v[4Q][4Q]QQQQQQQQQQi}16@24i32^@36
B40@0:8^{__CVBuffer=}16@24^@32
@"VNEspressoResources"
@40@0:8{_NSRange=QQ}16^@32
@"CRImageReaderOutput"
@44@0:8r^v16Q24@32f40
@28@0:8f16^@20
@"VNContoursObservation"
{vector<float __attribute__((ext_vector_type(2))), std::allocator<float __attribute__((ext_vector_type(2)))>>="__begin_"^"__end_"^"__end_cap_"{__compressed_pair<float * __attribute__((ext_vector_type(2))), std::allocator<float __attribute__((ext_vector_type(2)))>>="__value_"^}}
@"NSIndexPath"
@96@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48f80i84f88f92
@100@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48f80i84f88f92i96
@104@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48f80i84f88f92B96i100
@108@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48f80i84f88f92f96B100i104
@108@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48f80i84f88f92i96B100i104
@112@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48f80i84f88f92f96i100B104i108
B32@0:8@16f24f28
B32@0:8@16f24i28
Q24@0:8@"VNPersonsModel"16
@"<NSObject><NSCopying><NSSecureCoding>"32@0:8@"VNPersonsModel"16Q24
Q32@0:8@"VNPersonsModel"16@"<NSObject><NSCopying><NSSecureCoding>"24
Q32@0:8@"VNPersonsModel"16Q24
@"VNFaceObservation"40@0:8@"VNPersonsModel"16Q24Q32
B48@0:8^Q16^i24@32^@40
B36@0:8^v16i24^@28
{shared_ptr<vision::mod::LandmarkDetectorDNN>="__ptr_"^{LandmarkDetectorDNN}"__cntrl_"^{__shared_weak_count}}
{vector<_Geometry2D_point2D_, std::allocator<_Geometry2D_point2D_>>="__begin_"^{_Geometry2D_point2D_}"__end_"^{_Geometry2D_point2D_}"__end_cap_"{__compressed_pair<_Geometry2D_point2D_ *, std::allocator<_Geometry2D_point2D_>>="__value_"^{_Geometry2D_point2D_}}}
B48@0:8@16@24@32^@40
B60@0:8Q16^^{__CVBuffer}24I32Q36Q44^@52
B64@0:8^{?=[3]}16^{__CVBuffer=}24^{__CVBuffer=}32^{ImageRegistrationCtx_s=}40r^{?=[3]}48^@56
#24@0:8@16
v72@0:8@16@24^{__CVBuffer=}32{vImage_Buffer=^vQQQ}40
v76@0:8@16@24{CGRect={CGPoint=dd}{CGSize=dd}}32f64@68
@"ShotflowDetector"
{shared_ptr<vision::mod::ImageClassifier_HierarchicalModel>=^{ImageClassifier_HierarchicalModel}^{__shared_weak_count}}24@0:8^@16
@28@0:8B16@20
@"VN6B8mkraBUpwUqskMYPtS3"
@56@0:8@16@24@32f40f44Q48
@52@0:8@16@24@32f40Q44
@64@0:8@16@24@32f40f44Q48Q56
@44@0:8@16@24@32f40
@48@0:8@16@24@32f40f44
@"<VNClustererModelQuerying>"
@"<VNClustererModelQuerying><VNClustererModelBuilding>"
{_NSRange=QQ}24@0:8@16
@32@0:8Q16q24
@32@0:8{_NSRange=QQ}16
@48@0:8Q16{CGPoint=dd}24q40
@"CRDocumentOutputRegion"
@"CROutputRegion"
@"NSAttributedString"
@"DDScannerResult"
@"VNObservation"
@"BCSDetectedCode"
@"VCPMotionFlowRequest"
{BufferSizeFormat="width"Q"height"Q"format"I}
@64@0:8r^v16Q24Q32Q40Q48@56
@64@0:8r^v16Q24Q32Q40Q48Q56
@"VNEntityIdentificationModel"
@"<VNEntityIdentificationModelDataSource>"
B52@0:8I16@20@28^{CC_MD5state_st=IIIIII[16I]i}36^@44
@"<VNEntityIdentificationModelDelegate>"
{?="willTrain"b1"didTrain"b1"failedTraining"b1"willDropTrainingData"b1"didDropTrainingData"b1}
@"VNEntityIdentificationModelConfiguration"
@"VNEntityIdentificationModelTrainedModel"
@64@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24B56f60
{tuple<float, float, float>={__tuple_impl<std::__tuple_indices<0, 1, 2>, float, float, float>=fff}}16@0:8
@40@0:8@16f24i28i32i36
@44@0:8{?=^vi}16^v32f40
@40@0:8@16i24i28i32f36
v36@0:8@16i24i28i32
i32@0:8Q16Q24
v52@0:8{vImage_Buffer=^vQQQ}16B48
@52@0:8{vImage_Buffer=^vQQQ}16B48
{vector<std::shared_ptr<espresso_buffer_t>, std::allocator<std::shared_ptr<espresso_buffer_t>>>="__begin_"^v"__end_"^v"__end_cap_"{__compressed_pair<std::shared_ptr<espresso_buffer_t> *, std::allocator<std::shared_ptr<espresso_buffer_t>>>="__value_"^v}}
[10B]
[6[10[2f]]]
Q32@0:8Q16^@24
{CGRect={CGPoint=dd}{CGSize=dd}}24@0:8B16I20
r^{CGPoint=dd}24@0:8B16I20
{CGPoint=dd}24@0:8B16I20
^{__CVBuffer=}28@0:8I16^@20
v56@0:8^{CGPoint=dd}16^{CGPoint=dd}24^{CGPoint=dd}32^{CGPoint=dd}40B48I52
@24@0:8B16I20
d24@0:8B16I20
{CGAffineTransform=dddddd}24@0:8B16I20
r^{CGPath=}24@0:8B16I20
r^24@0:8B16I20
f20@0:8I16
{shared_ptr<vision::mod::ImageDescriptorBufferAbstract>=^{ImageDescriptorBufferAbstract}^{__shared_weak_count}}32@0:8@16^@24
{shared_ptr<vision::mod::ImageDescriptorBufferAbstract>=^{ImageDescriptorBufferAbstract}^{__shared_weak_count}}40@0:8r^v16@24^@32
{unique_ptr<vision::mod::ImageDescriptorProcessorHyperplaneLSH, std::default_delete<vision::mod::ImageDescriptorProcessorHyperplaneLSH>>="__ptr_"{__compressed_pair<vision::mod::ImageDescriptorProcessorHyperplaneLSH *, std::default_delete<vision::mod::ImageDescriptorProcessorHyperplaneLSH>>="__value_"^{ImageDescriptorProcessorHyperplaneLSH}}}
@48@0:8{shared_ptr<vision::mod::FaceID3Model>=^{FaceID3Model}^{__shared_weak_count}}16Q32@40
v32@0:8{CGSize=dd}16
{shared_ptr<vision::mod::FaceBoxPoseAligner<signed char>>="__ptr_"^v"__cntrl_"^{__shared_weak_count}}
@"<VNModelFile>"
^v40@0:8@16^{ObjectTrackerOptions=^^?@i}24^@32
B64@0:8@16^v24{CGSize=dd}32@48^@56
{shared_ptr<vision::mod::ObjectTrackerAbstract>="__ptr_"^{ObjectTrackerAbstract}"__cntrl_"^{__shared_weak_count}}
@120@0:8B16B20^{__CVBuffer=}24@32{CGSize=dd}40{CGSize=dd}56{CGRect={CGPoint=dd}{CGSize=dd}}72@104^@112
@52@0:8Q16@24@32B40@44
{shared_ptr<vision::mod::CamGazePredictor>="__ptr_"^{CamGazePredictor}"__cntrl_"^{__shared_weak_count}}
{shared_ptr<vision::mod::GazeFollowPredictor>="__ptr_"^{GazeFollowPredictor}"__cntrl_"^{__shared_weak_count}}
@"VNImageBuffer"24@0:8^@16
@56@0:8@16@24@32@40@48
@60@0:8@16@24@32@40@48I56
@"VNObservationsCache"
@"VNRequestForensics"
@"VNHomographyTrackerState"
B52@0:8^{CGAffineTransform=dddddd}16@24@32f40^@44
@52@0:8B16@20Q28@36^@44
@"<VNPersonsModelDataDelegate>"
@40@0:8^{__CVBuffer=}16@24@?32
@44@0:8^{__CVBuffer=}16I24@28@?36
@40@0:8^{CGImage=}16@24@?32
@44@0:8^{CGImage=}16I24@28@?36
@40@0:8@16@24@?32
@44@0:8@16I24@28@?36
@40@0:8^{opaqueCMSampleBuffer=}16@24@?32
@44@0:8^{opaqueCMSampleBuffer=}16I24@28@?36
B84@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGSize=dd}48i64^{CGRect={CGPoint=dd}{CGSize=dd}}68^@76
@40@0:8r^{?=^v^v[4Q][4Q]QQQQQQQQQQi}16@24^@32
B32@0:8@16d24
r^Q16@0:8
@32@0:8r^Q16Q24
@48@0:8Q16Q24Q32Q40
{vector<unsigned long, std::allocator<unsigned long>>="__begin_"^Q"__end_"^Q"__end_cap_"{__compressed_pair<unsigned long *, std::allocator<unsigned long>>="__value_"^Q}}
@24@0:8r^{?=*QQQQ}16
B40@0:8@16^@24^@32
@44@0:8^{__CVBuffer=}16I24@28@36
@40@0:8^{CGImage=}16@24@32
@44@0:8^{CGImage=}16I24@28@36
@44@0:8@16I24@28@36
@40@0:8^{opaqueCMSampleBuffer=}16@24@32
@44@0:8^{opaqueCMSampleBuffer=}16I24@28@36
fgla
FNA*
fsba
ytcC
tAFC
eAIC
gmIC
knJC
meMC
10NV
mLPC
20NV
30NV
LMoc
pmna
pted
MRFC
pcaf
pt+f
40NV
rgfi
pgmi
plrn
pncs
pcms
psrt
raBD
tnCD
gSDD
QCFD
mLFD
L3FD
xEFD
zGFD
oPFD
caFD
roHD
PBHD
PHHD
HuHD
RuHD
tPOD
ceRD
zGSD
txTD
jrTD
nAF*
gSAG
StAG
gSFG
PFIG
SmIG
SbOG
FpOG
50NV
gSPG
CSPG
gSSG
iprg
gerh
knuj
rlbi
AmI*
pxei
 pon
inAR
hnAR
D&FR
jbOR
bsOR
txTR
lEDR
coDR
kBmR
necs
5mS*
gmHT
CFLT
jbOT
ceRT
gert
2NA>
3NA>
4NA>
1SA>
1pA>
2pA>
rlB>
trB>
noC>
LMC>
RmI>
DmI>
PeD>
gSD>
3MF>
4MF>
5MF>
ABF>
CFL>
2aF>
xEF>
zGF>
eGF>
2LF>
3LF>
1PF>
1QF>
2QF>
CQF>
MRF>
gSF>
GUG>
1AH>
RIH>
TgH>
zrH>
PBH>
PHH>
AmI>
1NV>
pmI>
gRI>
SmI>
knJ>
meM>
crM>
1pO>
FpO>
1FO>
2FO>
GSP>
4SP>
SSP>
FSP>
LSP>
TSP>
ceR>
kBR>
BAS>
BOS>
ncS>
zGS>
GgS>
pcS>
dlS>
CmS>
5mS>
S+A>
4rT>
7rT>
1rT>
*F+I
 O/R
 O+E
Ixam
I/Em
ogla
*F+I
hgih
f00L
ARGB
doml
ogla
qere
f00L
ARGB
)\O?
333333
Me!>
`Y?*
K/>n
4?Rc
As?@
[?>Y
5?+3A?&S
>;9W?@1
^y>?
>3PI>
j?}Y
?}wG?X
&>CVK?
q'?ep0?
xj>t
>: i?
6:>0
>=`Z?
=aR<>=
aK=e
>A*q?C
t=+jp>B
->g,&?"R;?
>?k}A>}
G?c%
O?Ig
>obp?
$X?7pG>
>h@=>H
\'?`
7?BZg?
{>?q
g?> 
=6rQ?
8?6v
y?F$&?~
L?6X
GS?R
>FA?6Wq?
{?OX
>9{3?1
*?<h6>
?X:/>
XQ?$~
>S\%>o
v#?Y
@#?o+u?
{v>U
*X?S]
>c~j?'
>5)E?
>:u)?w1E?
>}y)?
W?:U?<L
B%?-|
?sc~?
>}>2?
=?!"
6=JCA?
.?m<4?
I>O\R?
Dc?#I
D?R(
LA?:
>R`U?
\?@h}?:
?=`b?
L>h\
??yYS?
>WCB>mq
>k,a=T
a?V)}?
?]m}?
>$%M?
Oi>-
d?6x{?
>|HX?DnV>
>W!E>w
>~t*>+
OU=0cn?
E\?+5o?
)?kb
}?C<
uQ?1A
=Nd6>
Ch=R
Nx>(-\=c)
`I>K9
"~=p
=8hS?.
\)<]pF=
$?OZ
>9`'?
r=?}vp>5&<?-yx? 
R>x~
rj>?V$?
>L?;
E?oI2?
>b1*>
>?pB
>:X'?
C?AcB?
=?Vb>?
>BAY>T
~'> ~*?
d?%=
t?`w
@?5(j>yt
^$?v
-Z?mq
ms?@O
333?
