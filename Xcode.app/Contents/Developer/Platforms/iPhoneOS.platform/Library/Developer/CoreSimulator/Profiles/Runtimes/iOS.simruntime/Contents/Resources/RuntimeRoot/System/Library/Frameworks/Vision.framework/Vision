@(#)PROGRAM:RTCV-core-iOS  PROJECT:Vision-5.0.70
@@(#)PROGRAM:RTCV-cvabm-iOS  PROJECT:Vision-5.0.70
@(#)PROGRAM:RTCV-sim-iOS  PROJECT:Vision-5.0.70
@@(#)PROGRAM:RTCV-taptotrack-cyprus-iOS  PROJECT:Vision-5.0.70
@trk
Ga==
3@(#)PROGRAM:TemporalRegistration-iOS  PROJECT:Vision-5.0.70
=ffffff
?ffffff
&1>=
333333
333333
?333333
I@xwwwww
?xwwwww
333333
?333333
o@UUUUUU
@33333
@333?
Cq=J?\
=33s?
IAfff?
<ff&?
u=ff
 @33
CAffF@
@33
D?33XB
 BmQv9
Ga==
B>q=J?
eIDModel_v1_d16
FaceIDModel_v1_deIDModel_v1_d17
@(#)PROGRAM:Vision  PROJECT:Vision-5.0.70
@PFvPvE
NSt3__120__shared_ptr_pointerIPhPFvPvENS_9allocatorIhEEEE
NSt3__120__shared_ptr_pointerIPfPFvPvENS_9allocatorIfEEEE
N6vision3mod26ImageDescriptorBufferJointE
NSt3__115basic_stringbufIcNS_11char_traitsIcEENS_9allocatorIcEEEE
NSt3__120__shared_ptr_emplaceIN6vision3mod28ConcreteFaceQualityPredictorENS_9allocatorIS3_EEEE
N6vision3mod29ImageDescriptorBufferAbstractE
N6vision3mod24ObjectTrackerCorrelationE
N5apple6vision38GreedyClusteringParamsWrapperRevision1E
N5apple6vision29GreedyClusteringParamsWrapperE
N5apple6vision38GreedyClusteringParamsWrapperRevision2E
N5apple6vision38GreedyClusteringParamsWrapperRevision5E
N5apple6vision46GreedyClusteringParamsWrapperRevision5ConcreteE
NSt3__120__shared_ptr_emplaceIN5apple6vision46GreedyClusteringParamsWrapperRevision5ConcreteENS_9allocatorIS3_EEEE
N5apple6vision46GreedyClusteringParamsWrapperRevision2ConcreteE
NSt3__120__shared_ptr_emplaceIN5apple6vision46GreedyClusteringParamsWrapperRevision2ConcreteENS_9allocatorIS3_EEEE
N5apple6vision46GreedyClusteringParamsWrapperRevision1ConcreteE
NSt3__120__shared_ptr_emplaceIN6vision3mod25GreedyClustererHacks_rev1ENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN5apple6vision46GreedyClusteringParamsWrapperRevision1ConcreteENS_9allocatorIS3_EEEE
N6vision3mod5ERT2DIfEE
NSt3__114default_deleteIA_fEE
NSt3__120__shared_ptr_pointerIPfNS_14default_deleteIA_fEENS_9allocatorIfEEEE
N6vision3mod23Transformation2DPrivateI16_Geometry2D_RST_EE
N6vision3mod23Transformation2DPrivateI19_Geometry2D_Affine_EE
N6vision3mod16Transformation2DE
NSt3__120__shared_ptr_emplaceIN6vision3mod33ObjectDetector_DCNFaceDetector_v2ENS_9allocatorIS3_EEEE
N6vision3mod23Transformation2DPrivateIA9_fEE
N6vision3mod19TorsoprintGeneratorE
N6vision3mod32ImageDescriptorAugmenterAbstractE
N6vision3mod40ImageDescriptorAugmenterFlipAndNormalizeE
N6vision3mod28ImageDescriptorAugmenterFlipE
NSt3__120__shared_ptr_emplaceIN6vision3mod40ImageDescriptorAugmenterFlipAndNormalizeENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN6vision3mod28ImageDescriptorAugmenterFlipENS_9allocatorIS3_EEEE
N6vision3mod28ImageDescriptorAugmenterNoOpE
NSt3__120__shared_ptr_emplaceIN6vision3mod28ImageDescriptorAugmenterNoOpENS_9allocatorIS3_EEEE
N6vision3mod27TorsoprintGeneratorConcreteE
NSt3__120__shared_ptr_emplaceIN6vision3mod27TorsoprintGeneratorConcreteENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN6vision3mod28ImageDescriptorBufferFloat32ENS_9allocatorIS3_EEEE
NSt3__110shared_ptrIN6vision3mod29ImageDescriptorBufferAbstractEE27__shared_ptr_default_deleteIS3_S3_EE
NSt3__120__shared_ptr_pointerIPN6vision3mod29ImageDescriptorBufferAbstractENS_10shared_ptrIS3_E27__shared_ptr_default_deleteIS3_S3_EENS_9allocatorIS3_EEEE
>333>
6>%I
N6vision3mod32ImageDescriptorProcessorAbstractE
N6vision3mod23ImageClassifierAbstractE
N6vision3mod23ImageClassifierEspressoE
NSt3__120__shared_ptr_emplaceIN6vision3mod23ImageClassifierEspresso9private_tENS_9allocatorIS4_EEEE
NSt3__120__shared_ptr_emplaceIN6vision3mod18LandmarkAttributesENS_9allocatorIS3_EEEE
ZN4cvml4util31binserialized_table_of_contents9blob_infoC1EPKhRK26_BinSerializer_blobHeader_EUlS4_E_
NSt3__120__shared_ptr_pointerIPKhZN4cvml4util31binserialized_table_of_contents9blob_infoC1ES2_RK26_BinSerializer_blobHeader_EUlS2_E_NS_9allocatorIS1_EEEE
NSt3__110shared_ptrIN6vision3mod21ObjectTrackerAbstractEE27__shared_ptr_default_deleteIS3_S3_EE
NSt3__120__shared_ptr_pointerIPN6vision3mod21ObjectTrackerAbstractENS_10shared_ptrIS3_E27__shared_ptr_default_deleteIS3_S3_EENS_9allocatorIS3_EEEE
N6vision3mod33ObjectDetector_DCNFaceDetector_v2E
N6vision3mod22ObjectDetectorAbstractE
NSt3__120__shared_ptr_emplaceIN6vision3mod33ObjectDetector_DCNFaceDetector_v24privENS_9allocatorIS4_EEEE
NSt3__120__shared_ptr_emplaceIN6vision3mod30ObjectDetector_DCNFaceDetectorENS_9allocatorIS3_EEEE
N5apple6vision11OpticalFlow6LKTCPU19AllocationExceptionE
N5apple6vision11OpticalFlow6LKTCPU27InvalidPixelFormatExceptionE
N5apple6vision20CVPixelBufferWrapper13LockExceptionE
N5apple6vision11OpticalFlow10LKTCPUImplINS1_13LKTCPUComputeEEE
N5apple6vision11OpticalFlow6LKTCPUE
NSt3__117bad_function_callE
ZZ98-[VNScreenGazeDetector processWithOptions:regionOfInterest:warningRecorder:error:progressHandler:]EUb_E3$_0
NSt3__110__function6__funcIZZ98-[VNScreenGazeDetector processWithOptions:regionOfInterest:warningRecorder:error:progressHandler:]EUb_E3$_0NS_9allocatorIS2_EEFvvEEE
NSt3__110__function6__baseIFvvEEE
N6vision3mod28ImageDescriptor_EspressoJunkE
NSt3__120__shared_ptr_emplaceIN6vision3mod28ImageDescriptor_EspressoJunkENS_9allocatorIS3_EEEE
NSt3__110shared_ptrIN6vision3mod18LandmarkAttributesEE27__shared_ptr_default_deleteIS3_S3_EE
NSt3__120__shared_ptr_pointerIPN6vision3mod18LandmarkAttributesENS_10shared_ptrIS3_E27__shared_ptr_default_deleteIS3_S3_EENS_9allocatorIS3_EEEE
f024800L
N6vision3mod28ImageDescriptorBufferFloat32E
NSt3__110shared_ptrIN6vision3mod28ImageDescriptorBufferFloat32EE27__shared_ptr_default_deleteIS3_S3_EE
NSt3__120__shared_ptr_pointerIPN6vision3mod28ImageDescriptorBufferFloat32ENS_10shared_ptrIS3_E27__shared_ptr_default_deleteIS3_S3_EENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN6vision3mod15FaceFrontalizerENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN6vision3mod16FaceSegmenterDNNENS_9allocatorIS3_EEEE
ZZZ121-[VNFaceDetectorPrivateRevisionLegacyFaceCore processWithOptions:regionOfInterest:warningRecorder:error:progressHandler:]EUb_ENK3$_0clEP7CGImageEUlvE_
NSt3__110__function6__funcIZZZ121-[VNFaceDetectorPrivateRevisionLegacyFaceCore processWithOptions:regionOfInterest:warningRecorder:error:progressHandler:]EUb_ENK3$_0clEP7CGImageEUlvE_NS_9allocatorIS5_EEFvvEEE
NSt3__120__shared_ptr_emplaceIN6vision3mod33ImageClassifier_HierarchicalModelENS_9allocatorIS3_EEEE
?n'O
%5>q
f|:>
?T9W=
>tM>9!
v%?-"
=NSt3__110shared_ptrIN6vision3mod20GreedyClustererHacksEE27__shared_ptr_default_deleteIS3_S3_EE
NSt3__120__shared_ptr_pointerIPN6vision3mod20GreedyClustererHacksENS_10shared_ptrIS3_E27__shared_ptr_default_deleteIS3_S3_EENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN6vision3mod24CamGazePredictorConcreteENS_9allocatorIS3_EEEE
NSt3__110shared_ptrIN4cvml4util12BackedBufferINS2_15RAMBackingStoreEEEE27__shared_ptr_default_deleteIS5_S5_EE
NSt3__120__shared_ptr_pointerIPN4cvml4util12BackedBufferINS2_15RAMBackingStoreEEENS_10shared_ptrIS5_E27__shared_ptr_default_deleteIS5_S5_EENS_9allocatorIS5_EEEE
NSt3__110shared_ptrIN4cvml4util15RAMBackingStoreEE27__shared_ptr_default_deleteIS3_S3_EE
NSt3__120__shared_ptr_pointerIPN4cvml4util15RAMBackingStoreENS_10shared_ptrIS3_E27__shared_ptr_default_deleteIS3_S3_EENS_9allocatorIS3_EEEE
NSt3__110shared_ptrIKN4cvml4util12BackedBufferINS2_15RAMBackingStoreEEEE27__shared_ptr_default_deleteIS6_S6_EE
NSt3__120__shared_ptr_pointerIPKN4cvml4util12BackedBufferINS2_15RAMBackingStoreEEENS_10shared_ptrIS6_E27__shared_ptr_default_deleteIS6_S6_EENS_9allocatorIS6_EEEE
N6vision3mod24GreedyClustererWithTorsoE
NSt3__120__shared_ptr_emplaceINS_6vectorINS_5tupleIJjjfEEENS_9allocatorIS3_EEEENS4_IS6_EEEE
NSt3__120__shared_ptr_emplaceINS_6vectorIhNS_9allocatorIhEEEENS2_IS4_EEEE
NSt3__120__shared_ptr_emplaceINS_6vectorIjNS_9allocatorIjEEEENS2_IS4_EEEE
N6vision3mod29GreedyClustererFacesWithTorsoE
N6vision3mod14FaceClusteringE
NSt3__120__shared_ptr_emplaceIN6vision3mod24GreedyClustererWithTorso9private_tENS_9allocatorIS4_EEEE
NSt3__120__shared_ptr_emplaceIN6vision3mod29GreedyClustererFacesWithTorsoENS_9allocatorIS3_EEEE
N6vision3mod32ImageDescriptorProcessorEspressoE
NSt3__120__shared_ptr_emplaceIN6vision3mod32ImageDescriptorProcessorEspresso9private_tENS_9allocatorIS4_EEEE
PFvPN5apple6vision9libraries9autotrace12EPolygonListEE
NSt3__120__shared_ptr_pointerIPN5apple6vision9libraries9autotrace12EPolygonListEPFvS6_ENS_9allocatorIS5_EEEE
NSt3__120__shared_ptr_emplaceIN6vision3mod13FaceRegionMapENS_9allocatorIS3_EEEE
~|zxvuusqpnmkjiggfecba`_^]]\[ZYXWVUTTSRQQPONNMMLKKJIIHGGGFFEDDCCBBBAA@@??>>===<<;;:::999888776666555444333322211110000////.....----,,,,+++++*****)))))((((('''''''&&&&&&%%%%%%$$$$$$$########""""""!!!!!!!!!        X|E
+>>%I
N6vision3mod30ObjectDetector_DCNFaceDetectorE
NSt3__120__shared_ptr_emplaceIN6vision3mod30ObjectDetector_DCNFaceDetector4privENS_9allocatorIS4_EEEE
NSt3__120__shared_ptr_emplaceIN6vision3mod11FaceIDModelENS_9allocatorIS3_EEEE
N6vision3mod15ObjectTrackerExE
yA$H
ITCA
vA,2
q@,2
5mAv<
9Bh6
NSt3__120__shared_ptr_emplaceIN6vision3mod22ImageClassifierGlimmerENS_9allocatorIS3_EEEE
ZN6vision3mod12broadcastAddIdLm16EEEvRKNS0_10CVMLMatrixIT_XT0_EEERKNS0_10CVMLVectorIS3_XT0_EEEiRS4_bEUlddE_
NSt3__110__function6__funcIZN6vision3mod12broadcastAddIdLm16EEEvRKNS3_10CVMLMatrixIT_XT0_EEERKNS3_10CVMLVectorIS6_XT0_EEEiRS7_bEUlddE_NS_9allocatorISF_EEFdddEEE
NSt3__110__function6__baseIFdddEEE
ZN6vision3mod14broadcastMinusIdLm16EEEvRKNS0_10CVMLMatrixIT_XT0_EEERKNS0_10CVMLVectorIS3_XT0_EEEiRS4_bEUlddE_
NSt3__110__function6__funcIZN6vision3mod14broadcastMinusIdLm16EEEvRKNS3_10CVMLMatrixIT_XT0_EEERKNS3_10CVMLVectorIS6_XT0_EEEiRS7_bEUlddE_NS_9allocatorISF_EEFdddEEE
N6vision3mod32FeatureSignSparseCoder_bad_allocE
N6vision3mod31ColorGaborImageDescriptorBufferE
NSt3__120__shared_ptr_emplaceIN6vision3mod31ColorGaborImageDescriptorBufferENS_9allocatorIS3_EEEE
N6vision3mod34ColorGaborImageDescriptorProcessorE
NSt3__121__empty_non_own_stateIcEE
NSt3__115__has_one_stateIcEE
NSt3__16__nodeIcEE
NSt3__117__owns_two_statesIcEE
NSt3__116__owns_one_stateIcEE
NSt3__111__alternateIcEE
NSt3__117__repeat_one_loopIcEE
NSt3__16__loopIcEE
NSt3__120__l_anchor_multilineIcEE
NSt3__120__r_anchor_multilineIcEE
NSt3__126__end_marked_subexpressionIcEE
NSt3__128__begin_marked_subexpressionIcEE
NSt3__112__match_charIcEE
NSt3__120__match_char_collateIcNS_12regex_traitsIcEEEE
NSt3__118__match_char_icaseIcNS_12regex_traitsIcEEEE
NSt3__120__bracket_expressionIcNS_12regex_traitsIcEEEE
NSt3__111__match_anyIcEE
NSt3__110__back_refIcEE
NSt3__118__back_ref_collateIcNS_12regex_traitsIcEEEE
NSt3__116__back_ref_icaseIcNS_12regex_traitsIcEEEE
NSt3__123__match_any_but_newlineIcEE
NSt3__111__lookaheadIcNS_12regex_traitsIcEEEE
NSt3__115__word_boundaryIcNS_12regex_traitsIcEEEE
NSt3__110shared_ptrINS_13__empty_stateIcEEE27__shared_ptr_default_deleteIS2_S2_EE
NSt3__120__shared_ptr_pointerIPNS_13__empty_stateIcEENS_10shared_ptrIS2_E27__shared_ptr_default_deleteIS2_S2_EENS_9allocatorIS2_EEEE
NSt3__113__empty_stateIcEE
NSt3__111__end_stateIcEE
NSt3__16__bindIRFxRKNS_3mapINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_6vectorIfNS5_IfEEEENS_4lessIS7_EENS5_INS_4pairIKS7_SA_EEEEEERKSA_RSA_EJRKNS_12placeholders4__phILi1EEERKNSQ_ILi2EEERKNSQ_ILi3EEEEEE
NSt3__118__weak_result_typeIPFxRKNS_3mapINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_6vectorIfNS5_IfEEEENS_4lessIS7_EENS5_INS_4pairIKS7_SA_EEEEEERKSA_RSA_EEE
NSt3__110__function6__funcINS_6__bindIRFxRKNS_3mapINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_6vectorIfNS7_IfEEEENS_4lessIS9_EENS7_INS_4pairIKS9_SC_EEEEEERKSC_RSC_EJRKNS_12placeholders4__phILi1EEERKNSS_ILi2EEERKNSS_ILi3EEEEEENS7_IS12_EESP_EE
NSt3__110__function6__baseIFxRKNS_3mapINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_6vectorIfNS6_IfEEEENS_4lessIS8_EENS6_INS_4pairIKS8_SB_EEEEEERKSB_RSB_EEE
NSt3__16__bindIRFmmEJRKNS_12placeholders4__phILi1EEEEEE
NSt3__118__weak_result_typeIPFmmEEE
NSt3__114unary_functionImmEE
NSt3__110__function6__funcINS_6__bindIRFmmEJRKNS_12placeholders4__phILi1EEEEEENS_9allocatorISA_EES3_EE
NSt3__110__function6__baseIFmmEEE
NSt3__16__bindIRFxP7__sFILEPKcRNS_3mapINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_6vectorIfNS9_IfEEEENS_4lessISB_EENS9_INS_4pairIKSB_SE_EEEEEEEJRKNS_12placeholders4__phILi1EEERKNSQ_ILi2EEERKNSQ_ILi3EEEEEE
NSt3__118__weak_result_typeIPFxP7__sFILEPKcRNS_3mapINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_6vectorIfNS9_IfEEEENS_4lessISB_EENS9_INS_4pairIKSB_SE_EEEEEEEEE
NSt3__110__function6__funcINS_6__bindIRFxP7__sFILEPKcRNS_3mapINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_6vectorIfNSB_IfEEEENS_4lessISD_EENSB_INS_4pairIKSD_SG_EEEEEEEJRKNS_12placeholders4__phILi1EEERKNSS_ILi2EEERKNSS_ILi3EEEEEENSB_IS12_EESP_EE
NSt3__110__function6__baseIFxP7__sFILEPKcRNS_3mapINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_6vectorIfNSA_IfEEEENS_4lessISC_EENSA_INS_4pairIKSC_SF_EEEEEEEEE
NSt3__119basic_ostringstreamIcNS_11char_traitsIcEENS_9allocatorIcEEEE
N6vision3mod12_GLOBAL__N_119BoxAlignerExceptionE
?2w-!
?O#-
?o/i
?`vO
?+0du
_{fI
tYLl>
?A+0du
++MJ
?S?o*Ra
?G=D
? <
?S\U
|a2U
?G8-x
??5^
?o*Ral!
tYLl
?gDio
?h?RD
?|DL
?pB!
FZ*o
?@M-[
#bJ$Q
?p%;6
FZ*oG
?+5{
?%]3
_{fI
?`vO
h"lx
?%]3
?U0*
?pB!
?Mg'
?a2U0*
o%;6
?,+MJA
?Ral!
?o*Ral!
?8J^
?Dio
?:#J{
?q $
$#ga
?{Ic
?scz
?o*Ral!
?U0*
?S?o*Ra
?Dio
8b->
?o/i
R?o*
?G8-x
?G8-x
?2ZGU
?Z*oG8-
?MJA
R?o*R
?`vO
_{fI
FZ*o
$#gaO
?{fI
?N6vision3mod19LandmarkDetectorERTE
NSt3__120__shared_ptr_emplaceIN6vision3mod19LandmarkDetectorERTENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN4cvml4util31binserialized_table_of_contentsENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN6vision3mod27GazeFollowPredictorConcreteENS_9allocatorIS3_EEEE
Z13polynomialFitPKdS0_mmS0_S0_S0_E3$_0
NSt3__110__function6__funcIZ13polynomialFitPKdS3_mmS3_S3_S3_E3$_0NS_9allocatorIS4_EEFNS_6vectorIdNS5_IdEEEEdEEE
NSt3__110__function6__baseIFNS_6vectorIdNS_9allocatorIdEEEEdEEE
Q9RI
Q9RI
7:RI
Q9RI
d*;4
>;_)K;
DX;B`e;
{r;l
k;B`e;
Q;_)K;
#;RI
7:RI
Q9RI
d*;4
7;_)K;
DX;B`e;
{r;o
{r;B`e;
DX;_)K;4
d*;RI
7:RI
Q9RI
7;_)K;
y;KY
3"<U
-<X94<
b<B`e<
4o<E
{r<!
ew<l
{r<E
h<B`e<e
#9<X94<
3"<RI
^;_)K;4
7:RI
Q9RI
k;KY
Q:RI
Q9RI
k:RI
DX;$
d*<4
?F<4
DX;4
Q:RI
>;B`e;'
#<X94<
z<KY
$=yX(=V
7=5^:=[
2D=]mE=
?F=]mE=
2D=\
<=5^:=
-2=2
+=yX(=
D<X94<
;B`e;
>;RI
{r<&
=R' =T
b=B`e=B>h=h
4o= Aq=
{r=F
{r= Aq=
(m=h
j=B>h=B`e=e
WJ=9
E6=|
%=R' =Qk
k:RI
7;B`e;
?$=V
b=B>h=D
s=Gry=
\~=n
\~=Gry=F
m=B>h=e
?$=v
;B`e;4
DX;'
3"<4
=R' =U
(=W[1=Z
B=_)K=a
S=d]\=
d=d]\=a
S=_)K=\
9=W[1=U
(=R' =P
j<<b
ew=I
{r<b
j<<>
ew<M
ew<>
=yX(=
A=;pN=
h=k+v=n
=k+v=
[=;pN=
5=yX(=
ew<b
7:RI
{r<M
7x=J{
/>:#
O/<N
=yX(=Y
U=B`e=
9#>/
$>0L&>
d*>1
'>0L&>/
Yu=B`e=
?F=Y
7=yX(=u
7;KY
=z6+=
/;=:
K=d]\=D
m=I.
V,>i
9>lx:>
<>6<=>
=>6<=>
;>lx:>l
u1>i
V,>
m=d]\=:
/;=z6+=
;_)K;
{r<)\
q,=6<==
Ga=F
s=J{
u >/
!N>`vO>
|P>`vO>
2D>7
~;>~
N=6<==
;_)K;o
<X94<
=z6+=6<==
ew=o
G!>ff&>
+>io0>F%5>
9>[B>>%uB>
qJ>_
QZ>?
+e>x
F>%uB>[B>>
9>F%5>io0>
+>ff&>
P=6<==z6+=u
/]<X94<r
Q9RI
{r<N
=yX(=
x=p_
/>aT
X>RI]>
Ga>f
n>W[q>}
=y>lxz>Zd{>
|>HP|>HP|>
|>Zd{>lxz>
s>W[q>
rh>f
Ga>RI]>P
/>o
/;=yX(=
y;RI
d*;KY
d*<b
ew=p_
2>Gr9>[
sW>v
8g>1
|>n4
3b>v
?>Gr9>
%>d;
Ga=:
d*<o
?F=d]\=F
8V>?
c>gDi>
t>5^z>$
>5^z>
4o>gDi>
s=d]\=
<;p
:_)K;RI
=yX(=
m=J{
P>>yX>
_>>yX>
kI>n
v>=yX(=
;_)K;
T<KY
L=B`e=I.
..>}
6>I.?>
h>iop>~
x>iop>
DX>r
G>I.?>}
c>]
=B`e=
;B`e;X9
c<)\
>B>(>W[1>lx:>
C>lx:>W[1>B>(>-!
;B`e;o
5=;pN=
>R' >z
!=>]
|P>]
g3>z
)>R' >b
xi=;pN=
{r;'
>R' >
m4>m
ZS>-
-r>HP|>
>HP|>
J*>R' >
?F<N
h=J{
H?>:#J>+
U>:#J>
m4>z
)>-!
=R' =
sW=k+v=(
>B>(>
g3>m
>>:#J>=
U>w-a>
l>w-a>=
U>:#J>m
g3>B>(>
=k+v=
:=R' =
#<B`
d*;u
Sc=n
%>W[1>
U>w-a>
\m>~
\m>w-a>+
!=>W[1>
Jj<1
d*;RI
=W[1=
..>lx:>]
ZS>]
F>lx:>
AO=W[1=
5<HP
7;RI
|P>-
:_)K;|
?$=\
Sc=o
/>>y
2>I.?>_
6Z>_
L>I.?>
%>>y
/>n4
Sc=\
;_)K;4
+=_)K=
(m=p
q,>#
q?_
q?h
q,>d;
(m=_)K=V
ew=r
\m>HP|>
c?r
>HP|>
%>>y
ew=a
2=tF
:B`e;
9=d]\=I
=d]\=Z
9=Qk
u`<RI
;B`e;
=R' =
d=&S
:p>7
R&?t
@=R' =
l=q=
~*>Gr9>p
H>>yX>
f%?=
+?-C,?
,?-C,?
h>>yX>p
H>Gr9>
{r<U
:0>[
_>iop>I
;.?{
;.?$
@"?$
>iop>
G!><
;X94<
fU=$
>ff&>
y'?u
c,?r
0?EG2?}
7?^K8?Y
8?^K8?
+5?}
3?EG2?
c,?u
y'?j
8V>9
5>ff&>
fU=|
<X94<B`
?n4 ?
,?I./?
1?I./?D
#?n4 ?
E6=tF
u >io0>
t>J{
$?B>(?
1?X94?
6?X94?
+?B>(?
@>io0>
@=B>h=
$>F%5>
sW>gDi>
V?E
%?gD)?
,?R'0?
S3?0L6?
>?R'@?
8E?a
B?R'@?_
9?0L6?
S3?R'0?
,?gD)?"
V?0
~{>gDi>
F>F%5>/
=B>h=
B<HP
41?4
=?io@?
H?q=J?
~K?(~L?6<M?H
M?6<M?(~L?
~K?q=J?U
B?io@?d
41?h
4o>v
WJ=F
s=Nb
->[B>>r
4!?"
1?]m5?
I<?Di??aTB?
O?2UP?
aQ?2UP?
E?aTB?Di??
8?]m5?
3b>r
O>[B>>V
=yX(=
N=Gry=*
0>%uB>
8g>5^z>
?n4 ?
$?gD)?h
F?GrI?
HN?2UP?
&R?F
V?p_W?
W?p_W?
&R?2UP?
K?GrI?}
-?gD)?
$?n4 ?
>5^z>
T>%uB>|
=Gry=
N=yX(=
Q<KY
S#>4
#?B>(?
41?]m5?c
A?o
X?GrY?
Z??W[?
[?h"\?h"\?
[??W[?
Z?GrY?~
\=?c
9?]m5?
,?B>(?
S#><
ZS=V
Y<RI
sW=n
qJ>RI]>
+?R'0?4
D?yXH?q
Q?tFT?}
Z?HP\?
_?R'`?
h`?R'`?$
]?HP\?h
V?tFT?n
K?yXH?
4?R'0?
p>RI]>
qJ>~
sW=2
<RI
~;>_
|@?o
D?yXH?
UO?A
R?]mU?~
c?=,d?Ttd?Ttd?=,d?
X?]mU?A
K?yXH?o
Ga>_
~;>
y'?D
1?0L6?
:?Di??
UO?X
.^?Nb`?aTb?
d?]me?
eg?+
Dh?+
f?]me?
d?aTb?Nb`?
UO?q
C?Di??
:?0L6?
V,>,
<B`e<
b='1
rh>[
*?I./?X94?
=?aTB?}
U?gDY?
I\?gDY?
F?aTB?d
9?X94?I./?u
rh>O
/>G
<B`e<
=5^:=B`e=q=
k>n4
;?io@?
E?GrI?
Q?]mU?
&b?O
(l?mVm??5n?
n??5n?mVm?
X?]mU?n
M?GrI?
E?io@?
=B`e=5^:=
<=B>h=
q?aT
:P?tFT?~
m?-!o?
Np?-!o?
X?tFT?
a!>r
=B>h=[
4o<z6
9#>X
\>W[q>
f%?
;?R'@?
g?U0j?
n?2Up?N
q?2Up?
l?U0j?
E?R'@?C
>W[q>?
(m=M
G!?=
,?EG2?
K?2UP?O
\?Nb`?}
?t?]mu?KYv?
v?KYv?]mu?
?t?<
c?Nb`?$
T?2UP?
7?EG2?$
G!?Zd
{r<V}
>0L&>l
;.?}
&R?+
^?aTb?
t?KYv?
w?>yx?
y?,ey?,ey?
y?>yx?
w?KYv?
e?aTb?
J9?}
9>0L&>tF
4o=\
B=Qk
2D= Aq=
'>lx:>
!N>x
8E?q=J?
X?HP\?
m?2Up?<
v?'1x?
ky?'1x?
r?2Up?
H`?HP\?~
O?q=J?
+5?{
!N>lx:>
= Aq=
t<RI
=]mE=
;>`vO>x
~K?2UP?
U?GrY?
a?]me?5
(l?-!o?N
?t?KYv?'1x?^
{?(~|?
|?(~|?
y?'1x?KYv?
?t?N
q?-!o?
(l?5
h?]me?
]?GrY?
U?2UP?
=y>x
d>`vO>
{r=]mE=
u<RI
ew<3
?F=F
+e>lxz>B>
eG?(~L?
aQ?4
j?mVm?
Np?S
s?]mu?
/|?q
w?]mu?S
Np?mVm?
aQ?(~L?
>lxz>
^)>=
?F=RI
)>6<=>
e>Zd{>9
R&?-C,?
$H?6<M?
V??W[?$
eg?c
j??5n?
s?KYv?>yx?
Wz?>yx?KYv?
4q??5n?c
_??W[?
&R?6<M?
2?-C,?
A ?:#
>Zd{>
4Q>6<=>
Yu=*
2?^K8?
R?p_W?
[?R'`?=,d?+
z?(~|?H
}?(~|?
g?=,d?R'`?
[?p_W?
=?^K8?\
d*>+
f>HP|>L7
W?h"\?
h`?Ttd?
Dh?6
>w?,ey?
C{?,ey?
Dh?Ttd?
h`?h"\?
!>?Y
>HP|>B
 <X9
f>HP|>L7
W?h"\?
h`?Ttd?
Dh?6
>w?,ey?
C{?,ey?
Dh?Ttd?
h`?h"\?
!>?Y
>HP|>B
 <X9
Yu=*
2?^K8?
R?p_W?
[?R'`?=,d?+
z?(~|?H
}?(~|?
g?=,d?R'`?
[?p_W?
=?^K8?\
d*>+
)>6<=>
e>Zd{>9
R&?-C,?
$H?6<M?
V??W[?$
eg?c
j??5n?
s?KYv?>yx?
Wz?>yx?KYv?
4q??5n?c
_??W[?
&R?6<M?
2?-C,?
A ?:#
>Zd{>
4Q>6<=>
ew<3
?F=F
+e>lxz>B>
eG?(~L?
aQ?4
j?mVm?
Np?S
s?]mu?
/|?q
w?]mu?S
Np?mVm?
aQ?(~L?
>lxz>
^)>=
?F=RI
=]mE=
;>`vO>x
~K?2UP?
U?GrY?
a?]me?5
(l?-!o?N
?t?KYv?'1x?^
{?(~|?
|?(~|?
y?'1x?KYv?
?t?N
q?-!o?
(l?5
h?]me?
]?GrY?
U?2UP?
=y>x
d>`vO>
{r=]mE=
u<RI
2D= Aq=
'>lx:>
!N>x
8E?q=J?
X?HP\?
m?2Up?<
v?'1x?
ky?'1x?
r?2Up?
H`?HP\?~
O?q=J?
+5?{
!N>lx:>
= Aq=
t<RI
{r<V}
>0L&>l
;.?}
&R?+
^?aTb?
t?KYv?
w?>yx?
y?,ey?,ey?
y?>yx?
w?KYv?
e?aTb?
J9?}
9>0L&>tF
4o=\
B=Qk
(m=M
G!?=
,?EG2?
K?2UP?O
\?Nb`?}
?t?]mu?KYv?
v?KYv?]mu?
?t?<
c?Nb`?$
T?2UP?
7?EG2?$
G!?Zd
4o<z6
9#>X
\>W[q>
f%?
;?R'@?
g?U0j?
n?2Up?N
q?2Up?
l?U0j?
E?R'@?C
>W[q>?
<=B>h=
q?aT
:P?tFT?~
m?-!o?
Np?-!o?
X?tFT?
a!>r
=B>h=[
=5^:=B`e=q=
k>n4
;?io@?
E?GrI?
Q?]mU?
&b?O
(l?mVm??5n?
n??5n?mVm?
X?]mU?n
M?GrI?
E?io@?
=B`e=5^:=
<B`e<
b='1
rh>[
*?I./?X94?
=?aTB?}
U?gDY?
I\?gDY?
F?aTB?d
9?X94?I./?u
rh>O
/>G
<B`e<
y'?D
1?0L6?
:?Di??
UO?X
.^?Nb`?aTb?
d?]me?
eg?+
Dh?+
f?]me?
d?aTb?Nb`?
UO?q
C?Di??
:?0L6?
V,>,
~;>_
|@?o
D?yXH?
UO?A
R?]mU?~
c?=,d?Ttd?Ttd?=,d?
X?]mU?A
K?yXH?o
Ga>_
~;>
Y<RI
sW=n
qJ>RI]>
+?R'0?4
D?yXH?q
Q?tFT?}
Z?HP\?
_?R'`?
h`?R'`?$
]?HP\?h
V?tFT?n
K?yXH?
4?R'0?
p>RI]>
qJ>~
sW=2
<RI
S#>4
#?B>(?
41?]m5?c
A?o
X?GrY?
Z??W[?
[?h"\?h"\?
[??W[?
Z?GrY?~
\=?c
9?]m5?
,?B>(?
S#><
ZS=V
=yX(=
N=Gry=*
0>%uB>
8g>5^z>
?n4 ?
$?gD)?h
F?GrI?
HN?2UP?
&R?F
V?p_W?
W?p_W?
&R?2UP?
K?GrI?}
-?gD)?
$?n4 ?
>5^z>
T>%uB>|
=Gry=
N=yX(=
Q<KY
WJ=F
s=Nb
->[B>>r
4!?"
1?]m5?
I<?Di??aTB?
O?2UP?
aQ?2UP?
E?aTB?Di??
8?]m5?
3b>r
O>[B>>V
41?4
=?io@?
H?q=J?
~K?(~L?6<M?H
M?6<M?(~L?
~K?q=J?U
B?io@?d
41?h
4o>v
@=B>h=
$>F%5>
sW>gDi>
V?E
%?gD)?
,?R'0?
S3?0L6?
>?R'@?
8E?a
B?R'@?_
9?0L6?
S3?R'0?
,?gD)?"
V?0
~{>gDi>
F>F%5>/
=B>h=
B<HP
u >io0>
t>J{
$?B>(?
1?X94?
6?X94?
+?B>(?
@>io0>
?n4 ?
,?I./?
1?I./?D
#?n4 ?
E6=tF
;X94<
fU=$
>ff&>
y'?u
c,?r
0?EG2?}
7?^K8?Y
8?^K8?
+5?}
3?EG2?
c,?u
y'?j
8V>9
5>ff&>
fU=|
<X94<B`
:0>[
_>iop>I
;.?{
;.?$
@"?$
>iop>
G!><
l=q=
~*>Gr9>p
H>>yX>
f%?=
+?-C,?
,?-C,?
h>>yX>p
H>Gr9>
{r<U
=R' =
d=&S
:p>7
R&?t
@=R' =
:B`e;
9=d]\=I
=d]\=Z
9=Qk
u`<RI
;B`e;
ew=r
\m>HP|>
c?r
>HP|>
%>>y
ew=a
2=tF
+=_)K=
(m=p
q,>#
q?_
q?h
q,>d;
(m=_)K=V
:_)K;|
?$=\
Sc=o
/>>y
2>I.?>_
6Z>_
L>I.?>
%>>y
/>n4
Sc=\
;_)K;4
|P>-
=W[1=
..>lx:>]
ZS>]
F>lx:>
AO=W[1=
5<HP
7;RI
d*;u
Sc=n
%>W[1>
U>w-a>
\m>~
\m>w-a>+
!=>W[1>
Jj<1
d*;RI
=R' =
sW=k+v=(
>B>(>
g3>m
>>:#J>=
U>w-a>
l>w-a>=
U>:#J>m
g3>B>(>
=k+v=
:=R' =
#<B`
h=J{
H?>:#J>+
U>:#J>
m4>z
)>-!
>R' >
m4>m
ZS>-
-r>HP|>
>HP|>
J*>R' >
?F<N
5=;pN=
>R' >z
!=>]
|P>]
g3>z
)>R' >b
xi=;pN=
{r;'
;B`e;X9
c<)\
>B>(>W[1>lx:>
C>lx:>W[1>B>(>-!
;B`e;o
T<KY
L=B`e=I.
..>}
6>I.?>
h>iop>~
x>iop>
DX>r
G>I.?>}
c>]
=B`e=
:_)K;RI
=yX(=
m=J{
P>>yX>
_>>yX>
kI>n
v>=yX(=
;_)K;
?F=d]\=F
8V>?
c>gDi>
t>5^z>$
>5^z>
4o>gDi>
s=d]\=
<;p
d*;KY
d*<b
ew=p_
2>Gr9>[
sW>v
8g>1
|>n4
3b>v
?>Gr9>
%>d;
Ga=:
d*<o
Q9RI
{r<N
=yX(=
x=p_
/>aT
X>RI]>
Ga>f
n>W[q>}
=y>lxz>Zd{>
|>HP|>HP|>
|>Zd{>lxz>
s>W[q>
rh>f
Ga>RI]>P
/>o
/;=yX(=
y;RI
<X94<
=z6+=6<==
ew=o
G!>ff&>
+>io0>F%5>
9>[B>>%uB>
qJ>_
QZ>?
+e>x
F>%uB>[B>>
9>F%5>io0>
+>ff&>
P=6<==z6+=u
/]<X94<r
;_)K;
{r<)\
q,=6<==
Ga=F
s=J{
u >/
!N>`vO>
|P>`vO>
2D>7
~;>~
N=6<==
;_)K;o
7;KY
=z6+=
/;=:
K=d]\=D
m=I.
V,>i
9>lx:>
<>6<=>
=>6<=>
;>lx:>l
u1>i
V,>
m=d]\=:
/;=z6+=
=yX(=Y
U=B`e=
9#>/
$>0L&>
d*>1
'>0L&>/
Yu=B`e=
?F=Y
7=yX(=u
{r<M
7x=J{
/>:#
O/<N
=yX(=
A=;pN=
h=k+v=n
=k+v=
[=;pN=
5=yX(=
ew<b
7:RI
j<<>
ew<M
ew<>
j<<b
ew=I
{r<b
DX;'
3"<4
=R' =U
(=W[1=Z
B=_)K=a
S=d]\=
d=d]\=a
S=_)K=\
9=W[1=U
(=R' =P
7;B`e;
?$=V
b=B>h=D
s=Gry=
\~=n
\~=Gry=F
m=B>h=e
?$=v
;B`e;4
{r<&
=R' =T
b=B`e=B>h=h
4o= Aq=
{r=F
{r= Aq=
(m=h
j=B>h=B`e=e
WJ=9
E6=|
%=R' =Qk
k:RI
>;B`e;'
#<X94<
z<KY
$=yX(=V
7=5^:=[
2D=]mE=
?F=]mE=
2D=\
<=5^:=
-2=2
+=yX(=
D<X94<
;B`e;
>;RI
DX;$
d*<4
?F<4
DX;4
Q:RI
Q9RI
k:RI
Q9RI
k;KY
Q:RI
Q9RI
7;_)K;
y;KY
3"<U
-<X94<
b<B`e<
4o<E
{r<!
ew<l
{r<E
h<B`e<e
#9<X94<
3"<RI
^;_)K;4
7:RI
Q9RI
d*;4
7;_)K;
DX;B`e;
{r;o
{r;B`e;
DX;_)K;4
d*;RI
7:RI
Q9RI
d*;4
>;_)K;
DX;B`e;
{r;l
k;B`e;
Q;_)K;
#;RI
7:RI
Q9RI
7:RI
Q9RI
N6vision3mod22ImageClassifierGlimmerE
NSt3__120__shared_ptr_emplaceIN6vision3mod22ImageClassifierGlimmer9private_tENS_9allocatorIS4_EEEE
N6vision3mod20ObjectTrackerOptionsE
N6vision3mod21ObjectTrackerAbstractE
NSt3__110shared_ptrIN6vision3mod20ObjectTrackerOptionsEE27__shared_ptr_default_deleteIS3_S3_EE
NSt3__120__shared_ptr_pointerIPN6vision3mod20ObjectTrackerOptionsENS_10shared_ptrIS3_E27__shared_ptr_default_deleteIS3_S3_EENS_9allocatorIS3_EEEE
N4cvml4util17mapped_model_fileE
N4cvml4util22mapped_model_file_openE
NSt3__120__shared_ptr_emplaceIN4cvml4util22mapped_model_file_openENS_9allocatorIS3_EEEE
N4cvml4util23mapped_model_file_fopenE
NSt3__120__shared_ptr_emplaceIN4cvml4util23mapped_model_file_fopenENS_9allocatorIS3_EEEE
Q8@'1
E@q=
4B333?
NSt3__114default_deleteIN6vision3mod30ImageAnalyzer_CustomClassifierEEE
NSt3__120__shared_ptr_pointerIPN6vision3mod30ImageAnalyzer_CustomClassifierENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceINS_6vectorINS_10shared_ptrIN6vision3mod30ImageAnalyzer_CustomClassifierEEENS_9allocatorIS6_EEEENS7_IS9_EEEE
x<NSt3__120__shared_ptr_emplaceIN6vision3mod23ImageClassifierEspressoENS_9allocatorIS3_EEEE
N6vision3mod13CVMLCancellerE
NSt3__120__shared_ptr_emplaceIN6vision3mod30ConcreteFaceprintAndAttributesENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN6vision3mod19LandmarkDetectorDNNENS_9allocatorIS3_EEEE
N6vision3mod15GreedyClustererE
NSt3__120__shared_ptr_emplaceINS_6vectorINS_4pairImmEENS_9allocatorIS3_EEEENS4_IS6_EEEE
NSt3__120__shared_ptr_emplaceINS_6vectorImNS_9allocatorImEEEENS2_IS4_EEEE
N6vision3mod20GreedyClustererFacesE
NSt3__120__shared_ptr_emplaceIN6vision3mod15GreedyClusterer9private_tENS_9allocatorIS4_EEEE
NSt3__120__shared_ptr_emplaceIN6vision3mod20GreedyClustererFacesENS_9allocatorIS3_EEEE
17VNNSDataStreambuf
24VNNSMutableDataStreambuf
N6vision3mod19ScreenGazePredictorE
N6vision3mod27ScreenGazePredictorConcreteE
NSt3__120__shared_ptr_emplaceIN6vision3mod27ScreenGazePredictorConcreteENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN6vision3mod16TapToBoxConcreteENS_9allocatorIS3_EEEE
+/l?
rTD?
9FI?
W@+/l?
,A?P
?+/l?
+/l?@
q@4J?
9Q>`^
w=?k+K
F?]"!@R
?bD&>xzr?
uw?-
Fs?)
'I^?`
l?6a
>xq%
$@t=
;?`1S>
>M;{?
?;+n?
{f=~C
G]Z?
_=E3
wi@^ 
?k+H
7kV@
ZN6vision3mod28readBinSerializedModelValuesEP7__sFILEPKcRKNS0_26BinSerializedModelFileInfoERNS0_11ModelValuesEbE3$_1
NSt3__120__shared_ptr_pointerIPhZN6vision3mod28readBinSerializedModelValuesEP7__sFILEPKcRKNS3_26BinSerializedModelFileInfoERNS3_11ModelValuesEbE3$_1NS_9allocatorIhEEEE
ZN6vision3mod28readBinSerializedModelValuesEP7__sFILEPKcRKNS0_26BinSerializedModelFileInfoERNS0_11ModelValuesEbE3$_0
NSt3__120__shared_ptr_pointerIPfZN6vision3mod28readBinSerializedModelValuesEP7__sFILEPKcRKNS3_26BinSerializedModelFileInfoERNS3_11ModelValuesEbE3$_0NS_9allocatorIfEEEE
ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/
NSt3__120__shared_ptr_emplaceI17espresso_buffer_tNS_9allocatorIS1_EEEE
N6vision3mod32ImageDescriptor_EspressoSmartCamE
NSt3__120__shared_ptr_emplaceIN6vision3mod32ImageDescriptor_EspressoSmartCamENS_9allocatorIS3_EEEE
N6vision3mod37ImageDescriptorProcessorHyperplaneLSHIfEE
N6vision3mod30ImageDescriptorProcessorHasherIfEE
N6vision3mod17PetprintGeneratorE
N6vision3mod25PetprintGeneratorConcreteE
NSt3__120__shared_ptr_emplaceIN6vision3mod25PetprintGeneratorConcreteENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN6vision3mod18FaceBoxPoseAlignerIaEENS_9allocatorIS4_EEEE
N6vision3mod17RPNTrackerOptionsE
N6vision3mod16ObjectTrackerRPNE
/dev/null
< %-8s > 
Emergency
Alert
Critical
Error
Warning
Notice
Info
Verbose
Pixel format (%d) not supported!
Pixel format (%d), model (%d), or stretch (%d) not supported!
Invalid source image!
Invalid instanceResult buffer!
Output buffer size incorrect!
Invalid output buffer rowBytes (%d)!
rtcv::simCropResize failed!
Invalid exemplarResult buffer!
TtResult modelInfo.numModels (%d) out of bounds!
Incorrect trk node state version (%u vs %u)
Numbers of net outputs (%d) more than limit!
Numbers of net outputs (%d) isn't correct!
GeomTransform_constructor: unknown transform model (%d)
GeomTransform_minSupportPoints: unknown transform model (%d), reset to RIGID
GeomTransform_changeCoordinateSystem failed
GeomTransform_setModel: unknown new model (%d) use the old model (%d)
GeomTransform_estimate: unknown transform model (%d) use RIGID
GeomTransform_numTestsToDo: unknown transform model (%d) use RIGID
RigidTransform_estimate: not symmetric positive definite matrix
RigidTransform_estimate: the %ld-th argument is wrong in sposv_ call
AffineTransform_estimate: not symmetric positive definite matrix
AffineTransform_estimate: the %ld-th argument is wrong in sposv_ call
HomographyTransform_estimate:The %ld-th eigenvector failed to converge
HomographyTransform_estimate:The %ld-th eigenvector failed to converge
HomographyTransform_estimate: the %ld-th argument is wrong in ssyevx_ call
HomographyTransform_estimate: the %ld-th argument is wrong in ssyevx_ call
HomographyTransform_estimate: the 9-th parameter is too small pp[8]=%f 
IPDetector_constructor: Cannot allocate mFltImage 
IPDetector_constructor: Cannot allocate box filter
IPDetector_constructor: Cannot allocate mTmpBuffer 
IPDetector_constructor: Cannot allocate mCornerVec 
IPDetector_constructor: Cannot allocate mBX, mBY 
IPDetector_response: box filter failed
v16@?0i8i12
v8@?0
histogram equalization queue
v16@?0Q8
boxFilter_uint8_init: box filter failed when request minimum size err=%d
boxFilter_uint8: box filter failed err=%d
 invMatrix failed INFO1 = %ld
 invMatrix failed INFO2 = %ld
%s : -[EAGLContext setParameter:...] failed with error %d
gl_UtilsCreateContext
%s : calloc failed
ImageRegistrationCreateContext
%s : CFDictionaryCreateMutable failed
%s : CFArrayCreateMutable failed
%s : HistEqCreateContext failed
%s : RegistrationEngine_constructor failed
imageRegQueue
%s : dispatch_queue_create failed
%s : NULL input parameters
ImageRegistrationUnregisterOneImage
ImageRegister
%s : Need at least one non-reference image
%s : CFArrayGetCount(imageRegCtx->availExtraBuffers) != 0
%s : Could not locate scratch buffers
%s : CPU histogram equalization failed
HistogramEqualization
%s : invalid histogram equalization method
HistEqualizeCPU
%s : Unsupported image width,height
%s : Couldn't lock output buffer
%s : Couldn't lock input buffer
%s : CFArrayGetCount(imageRegCtx->availExtraBuffers) returned %d
GetUnusedExtraBuffer
GeomTransform_estimate failed
Pyramid_loadImage: incompatible size in pyramid (%lu!=%lu) or (%lu!=%lu)
v40@?0^Q8^Q16Q24Q32
WARNING: insufficient number of external corners provided (only %hu corners provided but minumum is %d)
Registration could not detect more that %d inlier corners at the highest resolution.
position
%s SHADER COMPILATION FAILED
VERTEX
FRAGMENT
Shader compile log:
<OOM with failed shader compile log>
PROGRAM LINK FAILED
Program link log:
<OOM with failed program link log>
%s : GL program failed to compile/link
HistEqCreateContext
source
textureScale
textureBias
attribute vec2 position;
varying vec2 texcoord;
void main()
  texcoord = 0.5 * (position + 1.0);
  gl_Position = vec4(position.x, position.y, 0.0, 1.0);
precision mediump float;
uniform sampler2D source;
uniform sampler2D lut;
uniform float textureScale;
uniform float textureBias;
varying highp vec2 texcoord;
void main()
  vec4 texColor = texture2D(source, texcoord);
  texColor = textureScale * texColor + textureBias;
  gl_FragColor.xyzw = vec4(texture2D(lut, vec2(texColor.x, 0.0)).x,
                           texture2D(lut, vec2(texColor.y, 0.0)).x,
                           texture2D(lut, vec2(texColor.z, 0.0)).x,
                           texture2D(lut, vec2(texColor.w, 0.0)).x);
libcompiler_rt abort
_availability_version_check
kCFAllocatorNull
CFDataCreateWithBytesNoCopy
CFPropertyListCreateWithData
CFPropertyListCreateFromXMLData
CFStringCreateWithCStringNoCopy
CFDictionaryGetValue
CFGetTypeID
CFStringGetTypeID
CFStringGetCString
CFRelease
/System/Library/CoreServices/SystemVersion.plist
IPHONE_SIMULATOR_ROOT
ProductVersion
%d.%d.%d
__cpu_indicator_init
cpu_model.c
__cpu_model.__cpu_type < CPU_TYPE_MAX
__cpu_model.__cpu_subtype < CPU_SUBTYPE_MAX
ordered keypoints are not available
OrderedKeypoints
unexpected keypoint type %@
detectorType
bbox
error occured when running model, unexpected output received
error occured when running model
Model runtime error, Unable to bind input buffer
Model runtime error, Unable to bind output buffer
unable to lock base address of pixelBuffer
saliency_attention_box_head_i4fgq3rswb_fp16.espresso
saliency_objectness_boxes_head_ecvqeduzc7_46800_fp16.espresso
Internal error:  detection of Human Heads should be handled by ANFD Detector Compound Request
VNDetectHumanHeadRectanglesRequestPrivateRevisionANODv3
VNDetectHumanHeadRectanglesRequestPrivateRevisionANODv4
 = [
VNFaceQualityGeneratorProcessingOptionInputFaceObservation
%@:%@
face_quality_v2.0.espresso
face_quality_v1.0.espresso
face quality of %f is out of range
Could not run network
Failed to scale and crop face rectangle.
Failure to create face quality predictor.
CVML module = %@
com.apple.cvml.%@
VNANFDMultiDetectorProcessingOption_AnimalHeadsRecognitionOriginatingRequestSpecifier
VNANFDMultiDetectorProcessingOption_SportBallsRecognitionOriginatingRequestSpecifier
%@%@%@
1 Lookup
0 Lookup
%lld
%@Faces: 
ClusterId: %lld
Level %@ cluster map:
%@_%@.log
VNClusteringLog
yyyy-MM-dd_HH-mm-ss-SSS
en_US_POSIX
CVML_debug_enable_cluster_log
%@, 
Final list of suggestions face IDs (results):
Group %d suggestions: 
Connected groups of suggestions face IDs (connectedSuggestedInputs):
filtered suggestions to include only those that are part of input query (suggestedInputsLists)
all sugestions for given input query (suggestionLists)
%@Suggestions: 
ClusterId: %@   
Suggested face IDs: %@:
%@can be returned: %@
faceId: %@
Input query - face IDs with flags (clusterIdsWithFlags):
VNSuggestionLog
Clustering request was canceled, error: %llu
Parameter validation failed for getDistanceBetweenLevel1Clusters
B32@?0@"NSNumber"8@"NSMutableOrderedSet"16^@24
getLevel1ClusteredIdsGroupedByLevel0ClustersForFaceId: Level-1 cluster size is zero for a valid clusterID descriptor (%lld)
getLevel1ClusteredIdsGroupedByLevel0ClustersForFaceId: There is no level-1 cluster that contains faceId = %d
getLevel1ClusteredIdsGroupedByLevel0ClustersForFaceId: faceId (%@) is not initialized
getting clusters failed with error: %lld
Internal error querying similar faces
Error initializing cluster state
Creating clustering parameters object failed for following face and torsoprint revisions: %lu and %lu and algorith type: %@
VNClusterOptionClusteringAlgorithm must be set to either VNClusteringAlgorithm_Greedy or VNClusteringAlgorithm_GreedyWithTorso
Invalid cache file path: %@
RestoreClusteringState is a required parameter
Cache file path is a required parameter
B24@?0@"VNFaceObservation"8@"NSDictionary"16
v32@?0@"VNFaceTorsoprint"8Q16^B24
  clusterId: %ld, %s
clusters:
  %d: prevcount=%d, curcount=%d, shouldUpdateRep = %d
Clusters:
Faces to add array must be the same size as that of the grouping identifiers array.
Faces to add must be accompanied by grouping identifiers when performing clustering in torso mode.
adding faces (%lu): %s
Unexpected type of object for clustering
Clustering with greedy algorithm
Creating clustering parameters object failed for following face and torsoprint revisions: %lu and %lu and algorithm type: %@
VNFaceAnalyzerMultiDetectorObservationGroupsForRequests
VNFaceAnalyzerMultiDetectorProcessingOptionCreateFaceprint
VNFaceAnalyzerMultiDetectorProcessingOptionCreateFaceAnalyzer
VNFaceAnalyzerMultiDetectorProcessingOptionFaceprintOriginatingRequestSpecifier
VNFaceAnalyzerMultiDetectorProcessingOptionFaceAnalyzerOriginatingRequestSpecifier
VNFaceAnalyzerMultiDetectorProcessingOptionFaceObservations
VNFaceAnalyzerMultiDetectorProcessingOptionInputFaceObservation
VNFaceAnalyzerMultiDetectorProcessingOptionFaceprintForceFaceprintCreation
VNFaceAnalyzerMultiDetectorProcessingOptionFaceprintConfidence
VNFaceprintGeneratorTypeEspressoCPU
Method not implemented
%@ must override %@
%@:%s
Failure to create face multi-headed classifier.
VNClusterOptionCacheFolderPath
VNClusterOptionClusteringAlgorithm
VNClusterOptionRestoreClusteringState
VNClusterOptionAddObjectsToClustering
VNClusterOptionAddObjectGroupIdsToClustering
VNClusterOptionRemoveObjectsFromClustering
VNClusterOptionFaceprintRevision
VNClusterOptionTorsoprintRevision
VNClusterOptionInputThreshold
VNClusterOptionInputTorsoThreshold
VNClusterOptionVectorMapReadOnlyFlag
Failed to create clusterer; Error = %@
Invalid Faceprint revision: %lu
Invalid Clusterer type: %@
Invalid Clusterer cache directory: %@
Suggestions request has been cancelled
Clustering request has been cancelled
%@ is not a VNRequest subclass
VN6Mb1ME89lyW3HpahkEygIG
VN5kJNH3eYuyaLxNpZr5Z7zi
VN6kBnCOr2mZlSV6yV1dLwB
VNVYvzEtX1JlUdu8xx5qhDI
Request
%@ does not have a registry entry
VNAlignFaceRectangleRequest
VNANFDDetectorCompoundRequest
VNAppendBurstSequenceFrameRequest
VNClassifyFaceAttributesRequest
VNClassifyJunkImageRequest
VNClassifyMemeImageRequest
VNClassifyPotentialLandmarkRequest
VNCreateFaceRegionMapRequest
VNCreateNeuralHashprintRequest
VNDetectContoursRequest
VNDetectDocumentSegmentationRequest
VNDetectFaceCaptureQualityRequest
VNDetectFaceExpressionsRequest
VNDetectFaceGazeRequest
VNDetectFacePoseRequest
VNDetectHumanBodyPoseRequest
VNDetectHumanHandPoseRequest
VNDetectHumanHeadRectanglesRequest
VNDetectObjectAtPointRequest
VNDetectTextRectanglesRequest
VNDetectTrajectoriesRequest
VNFaceAnalyzerCompoundRequest
VNGenerateAttentionBasedSaliencyImageRequest
VNGenerateFaceSegmentsRequest
VNGenerateImageSaliencyRequest
VNGenerateObjectnessBasedSaliencyImageRequest
VN1JC7R3k4455fKQz0dY1VhQ
VNGeneratePersonSegmentationRequest
VNGroupImagesByTimeAndContentRequest
VNIdentifyJunkRequest
VNImageAnalyzerCompoundRequest
VNRecognizeAnimalHeadsRequest
VNRecognizeFoodAndDrinkRequest
VNRecognizeSportBallsRequest
VNRecognizeDocumentElementsRequest
VNRecognizeDocumentsRequest
VNSceneClassificationRequest
VNSmartCam5CompoundRequest
VNTrackHomographyRequest
VNTrackLegacyFaceCoreObjectRequest
VNTrackObjectRequest
VNTrackRectangleRequest
VNANFDMultiDetectorANFDv2
VNANFDMultiDetectorANODv3
VNANFDMultiDetectorANODv4
VNAnimalprintDetectorRevision1
VNAnimalprintDetectorPrivateRevision1MD2
VNBlurDetector
VNBrightnessDetector
VNContoursDetector
VNCoreMLTransformer
VNCRImageReaderDetector
VNCRImageReaderForDocumentsDetector
VNDetectionprintGenerator
VNDocumentSegmentationDetector
VNFaceAnalyzerMultiDetectorFPrev2FArev1
VNFaceAnalyzerMultiDetectorFPrev3FArev2
VNFaceAnalyzerMultiDetectorFPrev3_1FArev1_3_MD2
VNFaceAnalyzerMultiDetectorFArev2_CameraLightweight
VNFaceAnalyzerMultiDetectorFPrev3_1FArev1_3_MD3
VNFaceBBoxAligner
VNFaceDetectorPrivateRevisionLegacyFaceCore
VNFaceDetectorRevision1
VNFaceDetectorRevision2
VNFaceExpressionDetector
VNFaceGazeDetector
VNFaceGeometryEstimator
VNFaceLandmarkDetectorRevision1
VNFaceLandmarkDetectorRevision2
VNFaceLandmarkDetectorRevision3
VNFaceprintGeneratorRevision1
VNFaceQualityGenerator
VNFaceRegionMapGenerator
VNFaceSegmentGenerator
VNObjectBasedSaliencyGenerator
VNGenerateObjectnessBasedSaliency544x544Detector
VNHomeAppFaceAnalyzerMultiDetector
VNHomeAppFaceAnalyzerMultiDetectorFPrev3_1FArev1_3_MD3
VNHomographicImageRegistrationDetector
VNHomographyTracker
VNHorizonDetector
VNHumanBodyPoseDetector
VNHumanHandPoseDetector
VNImageAnalyzerMultiDetector
VN4nFZhnOcBOiJmeVWzBWsv
VNImageprintGenerator
VNImageRegistrationDetector
VNImageSignatureDetector
VNJunkIdentifier
VNMemeClassifier
VNObjectAtPointDetectorRevision1
VNOpticalFlowGenerator
VNPersonSegmentationGenerator
VNPersonSegmentationGeneratorSemantics
VNPersonSegmentationGeneratorFast
VNPersonSegmentationGeneratorLearnedMatting
VNRectangleDetector
VNSaliencyAHeatmapBoundingBoxGenerator
VNSaliencyOHeatmapBoundingBoxGenerator
VNSceneClassifier
VNScreenGazeDetector
VNSingleHeadSceneprintGenerator
VNSmartCamClassifier
VNSmartCam5GatingDetector
VNSmartCamCombinedAestheticsAndSaliencyDetector
VNTorsoprintGeneratorPrivateRevisionMD1
VNTorsoprintGeneratorPrivateRevision3MD1HumanDetectorBased
VNTorsoprintGeneratorPrivateRevision3MD2HumanDetectorBased
VNTorsoprintGeneratorPrivateRevision3MD4HumanDetectorBased
VNTorsoprintGeneratorRevision1
%@ is not a registered class code
%@ is no longer supported by Vision
label
Descriptor count = 
Descriptor length = 
 bytes
VNHomographyTrackerProcessOption_State
timeout exceeded
facerec-v2.2-bgr-att-308_chk-0050__0__faceBoxPoseAligner-current__faceDetectorV2-current__ageClassifier
pet_v1_md2.espresso
Internal error while creating image signature print
Internal error creating sceneprint
Mismatch in signature print type
%@ %lu %lu
The image is invalid
Invalid argument
unable to allocate results array for %@ elements
could not obtain a supported image size for %@
Invalid requestRevision %d requested
no input buffer
invalid URL
no supported image size available
unable to access image
the image processing type is unknown
failed to create image analyzer
%@ does not provide a model name
CVML_UNKNOWN_
%@ does not provide classification labels
( %@, %@ )
( %@, [ %@ ] )
%@ hit %@
%@ looked up %@
%@ was already recorded as a cached result
%@ cached %@
, failed with %@
performed %@
performing %@
%@ created
attempting to re-assign ordered requests
%@ #%lu (%p)
Failed to create MTLTexture
Failed to create MTLTextureDescriptor
IOsurface height is smaller than texture height
IOsurface width is smaller than texture width
pixelBuffer does not contain an IOSurface
pixel buffer does not have an IOSurface
Cannot create an MTLCommandQueue
Cannot create an MTLLibrary
Cannot create an MTLDevice
VNObjectAtPointDetectorProcessOption_InputPoint
Unable to lock pixel buffer
Cannot parse input location point data
Failed to create tap to box converter object
tap_to_box.espresso
algParam
nodeParam
leafParam
regLookup
ERT - p : %d
testFeature
ERT2D.cpp
p.n > 0
ERT - node params are unavailable
ERT - reg lookup is unavailable
ERT - maxCacheSize: %d
ERT - cacheIndexL : %d
ERT - cacheIndexR : %d
ERT - anchorIndex : %d
com.apple.vis
%@ - %@
%s (%@)
DESIGN
BUILT
FAILURE
plan phase %ul
%@ (%@)
: %s
session no longer available
%@ is not a supported request
%@ does not support %@
The current configuration of %@ is not supported
processing with %@ is not supported
%@ requires the GPU for processing
argument %@ has an invalid value of %@
"%@"
 - %@
option %@ has an invalid value of %@
missing option %@
%@ does not support operation
%@ must be overridden
unsupported serialized header version %u
VNRequest
request was cancelled
request %@ was cancelled
VNBarcodeSymbologyAztec
VNBarcodeSymbologyCode39
VNBarcodeSymbologyCode39Checksum
VNBarcodeSymbologyCode39FullASCII
VNBarcodeSymbologyCode39FullASCIIChecksum
VNBarcodeSymbologyCode93
VNBarcodeSymbologyCode93i
VNBarcodeSymbologyCode128
VNBarcodeSymbologyDataMatrix
VNBarcodeSymbologyEAN8
VNBarcodeSymbologyEAN13
VNBarcodeSymbologyI2of5
VNBarcodeSymbologyI2of5Checksum
VNBarcodeSymbologyITF14
VNBarcodeSymbologyPDF417
VNBarcodeSymbologyQR
VNBarcodeSymbologyUPCE
VNBarcodeSymbologyAppClipCode
VNBarcodeSymbologyCodabar
VNBarcodeSymbologyGS1DataBar
VNBarcodeSymbologyGS1DataBarExpanded
VNBarcodeSymbologyGS1DataBarLimited
VNBarcodeSymbologyMicroPDF417
VNBarcodeSymbologyMicroQR
Failed to align a detected bounding box
6ziz6uinva_opt.espresso
could not locate the face detection model file
noMapping
1DAffineMapping
1DLogisticMapping
1DPairwiseAffineMapping
postProcessorType
%@ %@
VNClassifyJunkImageRequestPrivateRevisionStillCapturePipeline
VNClassifyJunkImageRequestPrivateRevisionR14J8Model
VNClassifyJunkImageRequestPrivateRevisionR14J9Model
VNClassifyJunkImageRequestPrivateRevisionSceneNetV4
VNClassifyJunkImageRequestPrivateRevisionSceneNetV4StillCapturePipeline
head_joint
left_eye_joint
right_eye_joint
left_ear_joint
right_ear_joint
left_shoulder_1_joint
right_shoulder_1_joint
neck_1_joint
left_forearm_joint
right_forearm_joint
left_hand_joint
right_hand_joint
left_upLeg_joint
right_upLeg_joint
root
left_leg_joint
right_leg_joint
left_foot_joint
right_foot_joint
VNBLKFACE
VNBLKTORSO
VNBLKLARM
VNBLKRARM
VNBLKLLEG
VNBLKRLEG
VNIPOAll
ERROR: unknown transformation
VNCRImageReaderDetectorCreationOption_FastRecognition
VNCRImageReaderDetectorCreationOption_MaximumCandidatesCount
VNCRImageReaderDetectorCreationOption_RecognitionLanguages
VNCRImageReaderDetectorCreationOption_UsesLanguageDetection
VNCRImageReaderDetectorCreationOption_UsesAlternateLineGrouping
VNCRImageReaderDetectorCreationOption_CRImageReaderRevisionKey
VNCRImageReaderDetectorCreationOption_RestrictToCPU
VNCRImageReaderDetectorCreationOption_CustomWords
VNCRImageReaderDetectorCreationOption_DisableLanguageCorrection
VNCRImageReaderDetectorProcessOption_OriginatingRequest
VNCRImageReaderDetectorProcessOption_MinimumTextHeight
VNRecognizeTextRequest error - invalid orientation
VNRecognizeTextRequest produced an internal error
VNRequestHandlerCleanupOption_AllPipelines
VNRequestHandlerCleanupOption_FacePipeline
VNRequestHandlerCleanupOption_ScenePipeline
VNRequestHandlerCleanupOption_SmartCamPipeline
VNRequestHandlerCleanupOption_JunkPipeline
VNCleanupLevel_Complete
VNCleanupLevel_Partial
VNRequestHandlerCleanupOption_ImageBuffers
VNCleanupPurgeAll
VNTrackObjectPrivateRevisionLegacyFaceCoreProcessOption_MinFaceSize
VNTrackObjectPrivateRevisionLegacyFaceCoreProcessOption_NumberOfDetectionAngles
VNTrackObjectPrivateRevisionLegacyCoreProcessOption_EnhanceEyesAndMouthLocalization
VNTrackObjectPrivateRevisionLegacyFaceCoreProcessOption_ExtractBlink
VNTrackObjectPrivateRevisionLegacyFaceCoreProcessOption_ExtractSmile
VNTrackObjectPrivateRevisionLegacyFaceCoreProcessOption_KalmanFilter
Internal error: Tracker is not initialized
Internal error: Tracker is busy with previous tracking requests. It needs to be reset to restart tracking sequence
Internal error: Failed to initialize FaceCore detector
Internal error: Unsupported/unimplemented tracking level by FaceCore
VN741QpzmIdpMgb2GHtZi5nL
 leaf=%lu hierarchy=%lu
the custom hierarchy is for request revision %lu, not %lu
%@ is not supported for %@
VNSceneClassificationRequestPrivateRevisionSceneNetV4
seg_probs__0
v2.2
v2.2_small
anodv3_torso_v3_md3
0x%08X
'%c%c%c%c'
failed to write to data stream
tag %@ did not provide any data
tag %@ has a data overflow to %lu bytes
unexpected end of data stream
encountered unexpected length of %u, instead of %u
could not decode object of class %@
code
private 
unavailable %@, %srevision %lu
not a VNRequest subclass
nil request class
Error while computing blur score: %s
Inconsistent platform
Internal error: unexpeted tracked object bounding box size
Internal error: internal type conversion failed
%@:Trk=%@
This method should not be invoked directly. Derived classes are responsible for providing correct implementation
No valid presentationTimeStamp was available for this image
{?=qiIq}
VNFaceLandmarkDetectorType
VNFaceDetectorType
VNFaceBoxAlignerType
VNFaceGeometryEstimatorType
VNFaceRegionMapGeneratorType
VNFaceExpressionDetectorType
VNFaceprintGeneratorDetectorType
VNFaceSegmentGeneratorType
VNTorsoprintGeneratorDetectorType
VNFaceQualityGeneratorType
VNRectangleDetectorType
VNJunkIdentifierType
VNSingleHeadSceneprintGeneratorType
VNSmartCamClassifierType
VNImageprintGeneratorType
VNSmartCamCombinedAestheticsAndSaliencyDetectorType
VNAttentionBasedSaliencyHeatmapBoundingBoxGeneratorType
VNObjectnessBasedSaliencyHeatmapBoundingBoxGeneratorType
VNHorizonDetectorType
VNImageAnalyzerMultiDetectorType
VNFaceAnalyzerMultiDetectorType
VNANFDMultiDetectorType
VNOpticalFlowGeneratorType
VNContoursDetectorType
VNHumanBodyPoseDetectorType
VNHumanHandPoseDetectorType
VNDetectionprintGeneratorDetectorType
VNImageSignatureDetectorType
VN4nFZhnOcBOiJmeVWzBWsvType
VNScreenGazeDetectorType
VNFaceGazeDetectorType
VNCRImageReaderDetectorType
VNCRImageReaderForDocumentsDetectorType
VNAnimalprintDetectorDetectorType
VNImageRegistrationDetectorType
VNHomographicImageRegistrationDetectorType
VNBlurDetectorType
VNBrightnessDetectorType
VNPersonSegmentationGeneratorType
VNObjectDetectorAtPointType
VNMemeClassifierType
VNHomographyTrackerType
VNDocumentSegmentationDetectorType
VNSmartCam5GatingDetectorType
VNDetectorWillLoadNotification
VNDetectorDidLoadNotification
VNDetectorNotificationDetectorClass
VNDetectorNotificationDetector
VNDetectorNotificationConfiguration
Requested Metal Device is not supported: %@
VNDetectorInitOption_ModelBackingStore
VNDetectorOption_OriginatingRequestSpecifier
VNDetectorOption_ProcessingDevice
VNDetectorOption_ExplicitProcessingDevice
VNDetectorOption_MetalContextPriority
VNDetectorOption_PreferBackgroundProcessing
VNDetectorOption_RequestDetectionLevel
VNDetectorProcessOption_InputImageBuffers
VNDetectorProcessOption_ScenePrints
VNDetectorProcessOption_ImageCropAndScaleOption
VNDetectorProcessOption_Canceller
VNDetectorProcessOption_Session
Cannot initialize Metal Context
Cannot create Metal Context for non-GPU targeting device
%@ does not implement %@
Synchronization queue must be initialized
unable to create processing queue
com.apple.VN.processingQueue.%@
com.apple.VN.%@_%@
:%@=%@
unknown detector type '%@'
VNFaceAnalyzerMultiDetectorHomeAppType
VNSaliencyHeatmapBoundingBoxGeneratorType
VNObjectnessBasedSaliencyDetectorType
%@.sz
%@.or
%@.h
%@.w
%@.y
%@.x
'%@' is not a valid simd_flloat3 encoding
d3:|
d3:|%g %g %g|
'%@' is not a valid matrix_float4x4 encoding
4x4:|
4x4:|%g %g %g %g %g %g %g %g %g %g %g %g %g %g %g %g|
'%@' is not a valid matrix_float3x3 encoding
3x3:|
3x3:|%g %g %g %g %g %g %g %g %g|
'%@' is not a valid CGAffineTransform encoding
[%g %g %g %g %g %g]
AnnealContour
ContourUtilities.c
sPtrPrev != sPtr
sPtr != sPtrNext
rPtr != NULL
annealSegments
sPrevPtr != sPtr
newCurr != NULL
createBridgeSegment
mPnts == nPnts
reverseContour
currCPtr != NULL
mergeEndpointSearch4
code1 != -1
code2 != -1
mergeContourEnd
cPtr2->active
PCOORD_EQUAL(sPtr2->pary[sPtr2->nPnts-1], pc3)
(code == 1) || (code == 2)
VNPotentialLandmarkIdentifier
VNClassifyPotentialLandmarkRequestPrivateRevisionStillCapturePipeline
VNClassifyPotentialLandmarkRequestPrivateRevisionSceneNetV4
VNClassifyPotentialLandmarkRequestPrivateRevisionSceneNetV4StillCapturePipeline
CVML_status module %d error %lld
not implemented error
internal error
unexpected null pointer
invalid parameter
memory allocation error
vImage related error
delegate error
missing option
invalid option
unknown option
I/O error
data inconsistency error
invalid data type
invalid ID
hash already in use
platform endianess not supported
LAPACK error
division by zero
singular point configuration error
out of bounds
invalid format
OpenGL error
warping error
inconsistent state error
missing positional parameter
error with projection computation
video error
too few IDs to build VIP model
computation kill request was issued
batch size violation
nominal distance not changed
no saved state to revert
initialization error
feature extraction error
small sparsity error
incorrect binserializer key
Espresso error
General error
Not supported error
CVML Module %lld
CVMLEngine
PhotosProcessorCLI
ImageProcessorCLI
ClusteringCLI
MPCmdlineClientCLI
ImageClassifierCLI
FaceProcessorCLI
AppleNetParser
BinSerializerProcessor
ThirdParty
ImageWarper
VideoTools
ImageTools
Generic
TapToBox
PetprintGenerator
ScreenGaze
Torsoprint
FaceQuality
FaceprintAndAttributes
FaceAttributes
ImageAnalyzer
FaceSegmenter
BoostedClassifier
FaceID
SparseCoding
Kmeans
SRCClassifier
ObjectTracker
ObjectDetector
FaceRegionMap
HumanDetector
Clustering
SimilarityMatrix
ImageRegistration
VIPIdentification
ImageProcessing
ImageClassifier
ImageDescriptor
FaceboxAligner
MomentProcessor
LandmarkDetector
ImageQuality
ImageGrouping
Geometry3D
Geometry2D
FaceWarper
FaceFrontalizer
FaceDescriptor
Face3D
BinSerializer
v32@?0@"NSNumber"8@"NSMutableArray"16^B24
v32@?0Q8@"NSArray"16^B24
v32@?0@"NSString"8Q16@"NSString"24
[%g,%g,%g,%g]:%@:%u:%u:%c:%c
cannot process %@ in a single operation
Unknown
pixelToRgnMap
rgnMapRowBytes
rgnMapH
rgnMapW
rgnMapData
alignH
alignW
alignY
alignX
userH
userW
userY
userX
requestRevision
VNFaceRegionMapVersion
region map data has length of %lu instead of the expected %lu
unknown coding version
anmlPrnt
VNAnimalObservation
Failed to unarchive %@ object due to coding version mismatch: Currently supported: %u; encoded: %u
VNRecognizeAnimalsRequest
person:0
image:0
personsemantics-u8-v4.espresso
entity and observation data counts are out-of-sync
entity serial numbers have been exhausted
The model has reached the maximum entity limit of %lu
could not create a image signature print from tensor vector with %lu elements (%lu bytes)
leaf/logits
NeuralHashv3b-current.espresso
com.apple.VN.createGaborFilterBankGCDQueueName
com.apple.VN.extractGaborDescriptorGCDQueueName
com.apple.VN.gaborReadySyncQueueName
com.apple.VN.gaborDescriptorReadySyncQueueName
VNFaceLandmarkDetectorOption_LoadRefinersModel
VNFaceLandmarkDetectorProcessOption_InputFaceObservations
VNFaceLandmarkDetectorProcessOption_CalculateLandmarkScore
Unknown constellation type: %lu
Invalid parameters passed to blink score computation
Could not compute landmark score, error code = %lld
Invalid parameters passed to landmark score computation
landmarkRefinerAndPupil_v2
Model file info populated incorrectly
void cvml::util::binserialized_contents::init_model_values(const cvml::util::binserialized_table_of_contents &, const char *, const vision::mod::BinSerializedModelFileInfo &)
/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-5.0.70.1/VisionKitFramework/VN/algorithm_util/binserialized_mapped_file_contents.h
model file is corrupt
void cvml::util::binserialized_table_of_contents::init(const void *const, size_t)
Could not read landmark refiner model data
%@:%u:%u:%lu
B32@?0Q8@"VNClassifyFaceAttributesRequest"16^@24
B32@?0Q8@"VNCreateFaceprintRequest"16^@24
%f,%f,%f,%f:%u:%u:%lu
Request object must be of type VNImageBasedRequest
VNImageBufferOption_DownscaleCGInterpolationQuality
VNImageBufferOption_UpscaleCGInterpolationQuality
VNImageBufferOption_FeatureOrientationRelativeToUpRight
VNImageBufferOption_DoNotCacheRepresentations
VNImageBufferAugmentationApplePipeline
VNImageBufferAugmentationBlur
VNImageBufferAugmentationNoise
VNImageBufferAugmentationRotation
VNImageBufferAugmentationFlip
VNImageBufferAugmentationFlipVertical
VNImageBufferAugmentationFlipHorizontal
VNImageBufferAugmentationShear
VNImageBufferAugmentationExposure
VNImageBufferAugmentationRandomCrop
VNImageBufferAugmentationOptionMaxRange
VNImageBufferAugmentationOptionMinRange
VNImageBufferAugmentationOptionNumberOfBuffers
VNImageBufferAugmentationOptionRandomSeed
VNImageBufferContext
-[VNImageBufferManager purgeAllCaches]
ERROR while purging caches %s | %@
The augmentationOptions do not conatain any of the VNImageBufferAugmentation keys
RandomCrop produced an invalid crop for width %f height %f
CIMultiplyBlendMode
CIColorMonochrome
CIRandomGenerator
CIStraightenFilter
CIExposureAdjust
CIDiscBlur
Unable to create a CGBitmapContext
Unable to create CGImage for scaling
Unable to crop image from source buffer
cannot crop outside of image
Missing target buffer for crop operations
%@ cannot be called with nil options
Extracting ROI from an image failed
unable to create the Y plane wrapper buffer
this release call should not be used with anything but a referencing pixelbuffer %s
void CVPixelBufferReleaseReferencingPixelBufferCallback(void * _Nullable, const void * _Nullable)
Failed to transfer inBuffer to inputBufferForRotation. Error %d
unable to create %@ x %@ pixel buffer with format %@
Failed to transfer inBuffer to croppedBuffer. Error %d
unable to create the interim YUV buffer
unable to create the cropped buffer - error: %d
%@;opt=%@
invalid chunk increment of %lu x %lu
invalid chunk size of %ld x %ld
invalid ROI size of %f x %f
Could not create buffer with format %@ (%ld)
0x%x
Operation failed due to attempt to crop zero or near zero dimensioned area
Failed to create image for processing
orientation
VNCreateTorsoprintRequestPrivateRevisionMD1Torso
VNCreateTorsoprintRequestPrivateRevision3MD1HumanDetectorBasedTorso
VNCreateTorsoprintRequestPrivateRevision3MD2HumanDetectorBasedTorso
VNCreateTorsoprintRequestPrivateRevision3MD4HumanDetectorBasedTorso
VNCRImageReaderForDocumentsDetectorProcessOption_OriginatingRequest
VNCRImageReaderForDocumentsDetectorProcessOption_DetectionOnly
VNCRImageReaderForDocumentsDetectorProcessOption_TextObservationsToRecognize
VNCRImageReaderForDocumentsDetectorProcessOption_MaximumProcessingDimensionOnTheLongSide
%@: %@
v32@?0@"VNWeakSessionWrapper"8Q16^B24
v24@?0@"VNSession"8^B16
com.apple.VN.serializeRPNTrackingQueue
com.apple.VN.serializeRPNInitializationQueue
rpn_track_v4.espresso
rpn_template_v4.espresso
com.apple.Tracker.rpnTrackQueuee
com.apple.Tracker.rpnInitQueue
failed to obtain the data
ToOutputStream:options:md5Context:error:
%@%lu%@
writeVersion
writeReadOnlyVersion
v32@?0@"VNFaceObservation"8Q16^B24
 <dirty>
 modified on %@
[%f; %f]
VNRequestWarningImageTooSmall
VNRequestWarningImageTooSmallForFaceObservations
VNRequestWarningImageMinimumLongDimension
VNRequestWarningImageMinimumShortDimension
VNRequestWarningBlinkDetectionFailure
 usesCPUOnly
 preferBackgroundProcessing
%@ is not a private revision for %@
imageBuffer
cancellation is not currently available
%@ does not support cancellation
com.apple.%@
%@-%lu:MTL=%@:Det=%lu:MDm=%lu
%@ contains an entry for %@ that is dependent on a private revision %@
Vision
All elements in the %@ array must be of class %@ (%@)
The %@ option was expected to be a %@, but was instead a %@ (%@)
The %@ required option was not found
    %@=%@
idealDimension
maxDimension
minDimension
orientationAgnostic
idealOrientation
aspectHandling
highRange
wideRange
idealFormat
landscape_cityscape
VN6OIpeIn2UKbA8EPIFdIs2H
VN1U5ssvGWQjrV1RUm9dL5pR
VN5XQJGcytY6ZCBlwCqdMbq0
VN1AQGhMkQFbwnqJ5zpkkekl
VN1CvVY8bX4JHKrNK7S2KcGZ
Unexpected size of serialized state of the object of type %@
state cannot be nil
Failed to initialize VNFaceTorsoprint object
Unexpected size of deserialized state of the object of type %@
Serialized and calculated MD5s don't match
Wrong type of print object
FTp_pid
FTp_tp
FTp_fp
FTp_rev
FTp_algorithmVersion
FTp_VNFaceTorsoprint
FTp_labelsAndConfidence
FTp_length
FTp_elementsType
FTp_elementsCount
FTp_data
VNCreateFaceTorsoprintRequest
VNNOPRequest
VNAnimalprintDetectorProcessOption_InputAnimalObservation
Unexpected size of animalprint descriptor
could not lock cropped image
Unable to initialize frontalizer.
%@:%c
Wiping layers for face detector unsuccessful
VNFaceDetector error aligning a detected bounding box
VN Face detector debug intermediates written to: %@
error
rect
imageURL
height
width
_raw_bbox_crop.png
%@_face_%ld
<binary-data>
_raw_bboxes.json
_fd_image.png
_fd_image.vdump
VN_facedetector_debug_intermediates/
failed to lock face pixel buffer
model8c_.espresso.net
model8c_.espresso
pixelFormatType
-[VNMomentProcessor computeClusteringTreeForImageDescriptors:assumeDescriptorsAreSorted:error:]
MomentProcessor.mm
-[VNMomentProcessor computeNaturalClusteringOfImageDescriptors:error:]
-[VNMomentProcessor computeClusteringOfImageDescriptors:intoKGroups:error:]
-[VNMomentProcessor initWithOptions:error:]
q24@?0@"VNMPImageDescriptor"8@"VNMPImageDescriptor"16
%@ does not provide an entity print that is compatible with a print generated by %@
%@ was generated by a %@ instead of a %@
%@ does not have a %@
faceprint
animalprint
v24@?0#8@"NSIndexSet"16
B32@?0#8Q16^B24
VNGenerateAttentionBasedSaliencyImageRequestPrivateRevisionStillCapturePipeline
VNGenerateAttentionBasedSaliencyImageRequestPrivateRevisionSceneNetV4
VNGenerateAttentionBasedSaliencyImageRequestPrivateRevisionSceneNetV4StillCapturePipeline
results were not already populated by VNImageAnalyzerCompoundRequest
Bounding Box = %@; objectType = %ld; confidence = %f
%@ cannot open a read-only model
%@ cannot be created with a data source
%@ cannot be created from a read-only model
VN62b042cc67e0a7d589ecdb58232fe23d
VN9bdc36cda32be948a5089e37392596ec
VN81aedeb999c79d74e79af7f1c922cf97
VN9f5b8e9dc1b3c824d79372f87b072ee3
VNbe5c67b06e95370f5a7b67b13e73637c
VN220a6626eb3cb51295a4e250ad9da319
VN0af6454e97767772ce64a19ddaf61f0c
VNeeab04670e53ebeb25150a31963a1aa6
VNa0c07362d05e1dafb35b96d20d5ce42d
VN79a8f83d9d55eb4eb2c9695902c47b53
VNacdca02f0900c2cb198193f3eec7b6c9
VNJ4fWm08v8TFm5lmRVji9G
VNBcvG8BSEpHsJWme0UsCjT
VNsHEZqjFIQQpXGSrwHkafy
Confid
Iden
unsupported serialized state version %u
Serialized state payload data checksum mismatch
Serialized state data length is invalid
Serialized state data is an unsupported version (%lu)
Error deserializing VNFaceprint
Input data is neither VNFaceprint nor CVMLFaceprint. NSKeyedUnarchiver error = %@
facePrint
CVMLFaceprint
Input data is not a VNFaceprint
Attempt to deserialize nil
fp_conf
type
VNFaceprint
fp_av
fp_lac
fp_l
fp_et
fp_ec
VNCreateFaceprintRequest
NBBSH
NBBSW
NBBOY
NBBOX
BBSH
BBSW
BBOY
BBOX
SOBJ
OISH
OISW
VNSaliencyImageObservation
VNBrightnessDetectorProcessOption_MaximumIntermediateSideLength
VNScreenGazeDetectorProcessOption_FaceObjectState
VNScreenGazeDetector: Predictor failed to determine gaze
screengazeflow-dw5gmeefrv_535001_quantized.espresso
VNClassifyImageAestheticsRequestPrivateRevisionStillCapturePipeline
VNClassifyImageAestheticsRequestPrivateRevisionSceneNetV4
VNClassifyImageAestheticsRequestPrivateRevisionSceneNetV4StillCapturePipeline
VNRectangleTracking_BottomLeftTracker
VNRectangleTracking_BottomRightTracker
VNRectangleTracking_TopLeftTracker
VNRectangleTracking_TopRightTracker
v32@?0@8@16^B24
Tracking of %@ failed: confidence = %f; threshold = %f
VNRectangleObservation object is expected to initialize Rectangle Tracker
Resetting tracker failed with error: %llu
Tracker is not initialized
tracking of one or more of the rectangle corners failed
wrong type of a corner tracker object created
v32@?0@"NSString"8@"VNObjectTracker"16^B24
Setting input rectangles to one of the rectangle corners failed
initialization of internal object
wrong type of a corner tracker allocated
No objects to track passed to the tracker
/System/Library/PrivateFrameworks/BarcodeSupport.framework/BarcodeSupport
/System/Library/PrivateFrameworks/BarcodeSupport.framework/Contents/MacOS/BarcodeSupport
BCSDetectedCode
 (%@)
MRCDescriptorAttributes
ACBSBarcodeInfo
barcodeDescriptor
symbology
VNDetectBarcodesRequest
failed to create pixel buffer
unsupported pixel format type
failed to create comparison image
^{CGImage=}8@?0
docseg_segflow-xde2zmcdh5_64000_4ch.segmentation_labels.txt
sigmoid
finalFC
BL_BR_TR_TL
docseg_segflow-xde2zmcdh5_64000_4ch_512x288_finalFC.espresso
VNSmartCamClassifierProcessOption_ReturnAllResults
VN_smartcam_classifier_debug_intermediates/
VN_DEBUG_DUMP_SMARTCAM_INTERMEDIATES
smartcam-classifier-relationships
smartcam-classifier-labels
smartcam-classifier
smartcam-descriptor
model_junk_12_espresso
VNRecognizeObjectsRequestPrivateRevision26Identifiers
VNRecognizeObjectsRequestPrivateRevision585Identifiers
VNRecognizeObjectsRequestPrivateRevisionSceneNetV4
buffer cannot be nil
data overflow to %lu bytes
corrupted boolean value: %02X
VNFaceExpressionDetectorProcessOption_InputFaceObservations
Corrupt face mark data
VNFaceExpressionDetector face does not have landmark points
Could not create face expression module
Could not read expressions model data
labelsConfidences
algorithmVersion
VNSceneprint
labelsAndConfidence
length
elementsType
elementsCount
VNCreateSceneprintRequest
VNDetectorProcessingQueueOption
 (%s)
failure with status %lld
encountered unknown exception
NSException
encountered an unexpected condition: %@
encountered an unexpected condition: %s
VNTextRecognitionOptionNone
VNTextRecognitionOptionASCIICharacterSet
VNTextRecognitionOptionEnglishCharacterSet
VNTextRecognitionOptionDanishCharacterSet
VNTextRecognitionOptionDutchCharacterSet
VNTextRecognitionOptionFrenchCharacterSet
VNTextRecognitionOptionGermanCharacterSet
VNTextRecognitionOptionIcelandicCharacterSet
VNTextRecognitionOptionItalianCharacterSet
VNTextRecognitionOptionNorwegianCharacterSet
VNTextRecognitionOptionPortugueseCharacterSet
VNTextRecognitionOptionSpanishCharacterSet
VNTextRecognitionOptionSwedishCharacterSet
invalid algorithm value of %lu
Text detector object was not created
ASCII
com.apple.vis.VNPersonsModel
v32@?0@"VNFaceprint"8Q16^B24
unknown person (%@)
<%@: %p> %lu identities
configuration has already been resolved to %@ and cannot be set to %@
the data source is no longer available
face observation %lu of %lu for person identifier '%@'
person identifier data
cannot create model with version %u
lastModDate
version
acceptableVersions
B28@?0I8@"NSObject"12^@20
%@ read as %@
com.apple.vis.VNPersonsModelLoader
i12@?0I8
model data cannot be verified due to mismatched checksums
cannot read model version %u
readObjectForVersion%uTag:fromInputStream:intoObjectDictionary:md5Context:error:
cannot accept model version %lu
Tag:fromInputStream:intoObjectDictionary:md5Context:error:
readObjectForVersion
faceprintRequestRevision
faceprintsPerIdentity
maxIdentities
               faceprintRequestRevision = %@
   maximumTrainingFaceprintsPerIdentity = %lu
                      maximumIdentities = %lu
unknown model kind '%@'
 '%@' confidence %f
personUID
readonly
incompatible faceprint revision
faceprint is not available from the observation
%@ is corrupt
operation was cancelled
VNClassifyImageRequestPrivateRevisionSceneNetV4
VNClassifyImageRequestPrivateRevisionSmartCamNet5
previous request results
UNKNOWN_1_unknown0
UNKNOWN_1_unknown1
UNKNOWN_1_unknown2
UNKNOWN_1_unknown3
UNKNOWN_1_unknown4
UNKNOWN_6_unknown0
UNKNOWN_6_unknown1
UNKNOWN_3_unknown0
UNKNOWN_3_unknown1
UNKNOWN_7_unknown0
UNKNOWN_7_unknown1
UNKNOWN_4_unknown0
UNKNOWN_4_unknown1
UNKNOWN_4_unknown2
UNKNOWN_4_unknown3
UNKNOWN_4_unknown4
UNKNOWN_5_unknown0
UNKNOWN_5_unknown1
UNKNOWN_5_unknown2
UNKNOWN_5_unknown3
UNKNOWN_5_unknown4
UNKNOWN_5_unknown5
UNKNOWN_2_unknown0
UNKNOWN_2_unknown1
UNKNOWN_0_unknown0
UNKNOWN_0_unknown1
UNKNOWN_0_unknown2
UNKNOWN_8_unknown0
UNKNOWN_8_unknown1
UNKNOWN_8_unknown2
UNKNOWN_9_unknown0
UNKNOWN_9_unknown1
UNKNOWN_9_unknown2
UNKNOWN_10_unknown0
UNKNOWN_10_unknown1
UNKNOWN_10_unknown2
UNKNOWN_10_unknown3
UNKNOWN_10_unknown4
UNKNOWN_11_unknown0
UNKNOWN_11_unknown1
UNKNOWN_11_unknown2
UNKNOWN_11_unknown3
UNKNOWN_11_unknown4
UNKNOWN_11_unknown5
UNKNOWN_12_unknown0
UNKNOWN_12_unknown1
UNKNOWN_12_unknown2
UNKNOWN_12_unknown3
UNKNOWN_12_unknown4
UNKNOWN_12_unknown5
UNKNOWN_12_unknown6
UNKNOWN_13_unknown0
UNKNOWN_13_unknown1
UNKNOWN_13_unknown2
UNKNOWN_13_unknown3
UNKNOWN_13_unknown4
UNKNOWN_13_unknown5
UNKNOWN_13_unknown6
UNKNOWN_14_unknown0
UNKNOWN_14_unknown1
UNKNOWN_14_unknown2
UNKNOWN_14_unknown3
UNKNOWN_14_unknown4
UNKNOWN_15_unknown0
UNKNOWN_15_unknown1
UNKNOWN_15_unknown2
UNKNOWN_15_unknown3
UNKNOWN_15_unknown4
UNKNOWN_16_unknown0
UNKNOWN_16_unknown1
UNKNOWN_16_unknown2
UNKNOWN_16_unknown3
UNKNOWN_16_unknown4
UNKNOWN_16_unknown5
UNKNOWN_17_unknown0
UNKNOWN_17_unknown1
FAC_LAC
FAC_label
facrRev
VNFaceAttributeCategoryVersion
unknown07_Cat
unknown06_Cat
unknown05_Cat
unknown04_Cat
unknown03_Cat
unknown02_Cat
unknown01_Cat
facemask_Cat
makeupLips_Cat
makeupEyes_Cat
glasses_Cat
bald_Cat
haircolor_Cat
facehair_Cat
smiling_Cat
eyes_Cat
gender_Cat
age_Cat
farRev
VNFaceAttributesVersion
makeup_Cat
wisdom parameters are not available for the device "%@"
v32@?0@"NSString"8@"NSDictionary"16^B24
wisdom parameters are not available for the system
Wisdom
Wrong type for warning value - %@, should be %@
detectionprint
VNPersonSegmentationGeneratorProcessOption_QualityLevel
VNPersonSegmentationGeneratorProcessOption_OutputPixelFormat
VNPersonSegmentationGeneratorProcessOption_KeepRawOutputMask
VNPersonSegmentationGeneratorProcessOption_MaskImageObservation
qualityLevel
VNPersonSegmentationGenerator: failed to create pixel buffer
unsupported pixel format
unsupported output pixel format
failed to create a CIContext
sc_av
VNSmartCamprint
sc_lac
sc_l
sc_et
sc_ec
sc_d
VNCreateSmartCamprintRequest
colSumSq
colSum
colProjections
rowSumSq
rowSum
rowProjections
inconsistent column data
inconsistent row data
Error while trying to allocate VNImageSignature object
nil buffer passed into initWithImageBuffer
Could not get attributes output. Error = %s
Error classifying attributes
Could not get confidence output. Error = %s
Could not get print output. Error = %s
Error calculating print
Could not run network. Error = %s
Unexpected options parameter passed to face analyzer multi-detector
yyyy:MM:dd HH:mm:ss
operation points object must be allocated before calling this method
The %d argument had an illegal value.
The %d-th diagonal element of the triangular factor of A is zero, so that A does not have full rank; the least squares solution could not be computed.
GenericSportBall
Internal error:  detection of sport balls should be handled by ANFD Detector Compound Request
unknown
VNFaceSegmentGeneratorProcessOption_InputFaceObservations
VNFaceSegmentGeneratorProcessOption_FaceBoundingBoxExpansionRatio
cannot map face segments
rowBytes
Expected labelConfidence map of %lu x %lu and got %lu x %lu
Input face aspect ratio > %f cannot be processed
One of the dimensions of the input face image is zero
Unexpected request revision
Invalid parameter (numberOfSupportedFaceSegments)
Invalid parameter (size)
Failed to create Face Segmenter object
faceSemantics_v1.1.espresso
VNVideoProcessingOptionFrameCadence
VNVideoProcessingOptionTimeInterval
VCPVideoProcessor
PtSpec
VCPHandObservation
VCPPersonObservation
VNHumanPoseDetectorProcessingOption_UseCPUOnly
Unable to create observation
Human Pose Request is not initialized
VCPRequestFrameHeightPropertyKey
VCPRequestFrameWidthPropertyKey
VCPRequestForceCPUPropertyKey
printOriginatingRequest
printsPerEntity
maximumEntities
    entityPrintOriginatingRequest = %@
   maximumTrainingPrintsPerEntity = %lu
                  maximumEntities = %lu
%@ is not supported
scenenet_sceneprint_r9_opt_int8.espresso
Unexpected result
Could not bind image to network
Could not bind output aesthetics scores
B24@?0@"ShotflowDetection"8@"NSDictionary"16
smartDistance
mergesCount
VNANFDMultiDetectorProcessingOption_FoodAndDrinkRecognitionOriginatingRequestSpecifier
Unexpected detector object type
VNFaceDetectorPrivateRevisionLegacyFaceCoreProcessOption_Type
VNFaceDetectorPrivateRevisionLegacyFaceCoreProcessOption_ROIs
VNFaceDetectorPrivateRevisionLegacyFaceCoreProcessOption_MinFaceSize
VNFaceDetectorPrivateRevisionLegacyFaceCoreProcessOption_NumberOfDetectionAngles
VNFaceDetectorPrivateRevisionLegacyFaceCoreProcessOption_EnhanceEyesAndMouthLocalization
VNFaceDetectorPrivateRevisionLegacyFaceCoreProcessOption_ExtractBlink
VNFaceDetectorPrivateRevisionLegacyFaceCoreProcessOption_ExtractSmile
Failed to create internal image
Failed to create detector
origDim
pcaDim
espresso-descriptor
espresso-classifier
espresso-classifier-labels
espresso-classifier-relationships
VNEspressoModelClassifierProcessOption_CenterTileOnly
could not locate the resource file "%@"
%@ must implement classifierResourceTypesToNamesForOriginatingRequestSpecifier: for %@
%@ must override %@ with a specific implementation
Could not compute image descriptor for image
Could not compute image descriptor for image. Error: %s
Image buffer is not initialized
Cannot create observation object
Cannot create image print
Cannot calculate classification image descriptor
Could not compute raw labels and confidence for image
%@ with a %@ is not supported
could not locate %@ in %@
resource key "%@" is not available
%@ must implement +classifierResourceTypesToNamesForOriginatingRequestSpecifier: for %@
failed to analyze image
@"NSString"8@?0
barcode location is not available
unable to create a barcode descriptor for %@
creation of a barcode descriptor for %@ is not supported
_new%@DescriptorForACBSBarcodeInfo:
unknown barcode type of '%@'
barcode type is not available
Could not decode sample
invalid barcode location information
_new%@DescriptorForMRCDescriptor:error:
%@ is not a supported barcode symbology
barcode detection requires at least one element in the symbologies property
VNDetectBarcodesLocateModeRegularIntervalVertical
VNDetectBarcodesLocateModeRegularIntervalHorizontal
VNDetectBarcodesLocateModeCenterThreeHorizontalAndCoverageAndDiagonals
VNDetectBarcodesLocateModeCenterThreeVerticalAndCoverageAndDiagonals
VNDetectBarcodesLocateModeCenterFiveEachDirection
VNDetectBarcodesLocateModeCenterOneEachDirection
VNDetectBarcodesLocateModeCenterThreeHorizontalCrossed
VNDetectBarcodesLocateModeCenterThreeHorizontal
VNDetectBarcodesLocateModeCenterOneHorizontalThick
VNDetectBarcodesLocateModeCenterOneHorizontal
VNDetectBarcodesLocateModeCenterThreeVerticalCrossed
VNDetectBarcodesLocateModeCenterThreeVertical
VNDetectBarcodesLocateModeCenterOneVerticalThick
VNDetectBarcodesLocateModeCenterOneVertical
VNDetectBarcodesLocateModeCenterThreeEachDirectionAndCoverageAndDiagonals
VNDetectBarcodesLocateModeCenterThreeEachDirection
VNDetectBarcodesLocateModeFastSearch
ColumnCount data is missing
RowCount data is missing
IsCompact data is missing
Payload data is missing
CodewordCount data is missing
LayerCount data is missing
QRMaskPattern data is missing
QRSymbolVersion data is missing
QRErrorCorrectionLevel data is invalid
QRErrorCorrectionLevel data is missing
v32@?0@"NSString"8@"NSString"16^B24
VNDetectBarcodesRequestPrivateRevision2
ageClassifier_W
ageClassifier_b
camgaze_probs
nrlHshPrnt
VNImageNeuralHashprintObservation
VNObjectTrackerRevision1Type
VNObjectTrackerRevision2Type
VNObjectTrackerRevisionLegacyFaceCoreType
VNRectangleTrackerType
Internal error: Exceeded maximum allowed number of Trackers for a tracker type: %@
Cannot create a Tracker with unknown tracker type: %@
A tracker cannot be created without specifying a unique tracker key
com.apple.VN.trackersCollectionManagementQueue
com.apple.VN.trackingProcessingQueue
v32@?0@"NSString"8#16^B24
GreedyWithTorsoClustering.cpp
facerec_fp3.1.3b_fa1.3.espresso
entityUID
observation
VNSmartCam5GatingDetectorProcessingOption_ClassificationEnabled
VNSmartCam5GatingDetectorProcessingOption_ClassificationOriginatingRequestSpecifier
VNSmartCam5GatingDetectorProcessingOption_ClassificationObservationsArray
VNSmartCam5GatingDetectorProcessingOption_GatingOriginatingRequestSpecifier
VNSmartCam5GatingDetectorProcessingOption_GatingObservationsArray
VNSmartCam5GatingDetectorProcessingOption_DocumentRegionGatingEnabled
VNSmartCam5GatingDetectorProcessingOption_DocumentRegionGatingGenerateSegmentationMask
VNSmartCam5GatingDetectorProcessingOption_TextRegionGatingEnabled
VNSmartCam5GatingDetectorProcessingOption_TextRegionGatingGenerateSegmentationMask
VNSmartCam5GatingDetectorProcessingOption_MachineReadableCodesGatingEnabled
VNSmartCam5GatingDetectorProcessingOption_MachineReadableCodesGatingGenerateSegmentationMask
unable to create segmentation image for %s
appcode
qr_code
leaf_semdev_text_water
segmentation/MRC_softmax
smartcam_assembly-segmentation-labels.txt
smartcam_assembly-classification-labels.txt
text
MRC5heads_76f6w2kjaz_61501_ay5mhf87cq_97501_hbnrcg6e5e_89040_8g7zthf4q3_12751_rucb99jtq8_75751_8d9qwisndd_85501_concat_quant.espresso
VNHLKWRI
VNHLKTCMC
VNHLKTMP
VNHLKTIP
VNHLKTTIP
VNHLKIMCP
VNHLKIPIP
VNHLKIDIP
VNHLKITIP
VNHLKMMCP
VNHLKMPIP
VNHLKMDIP
VNHLKMTIP
VNHLKRMCP
VNHLKRPIP
VNHLKRDIP
VNHLKRTIP
VNHLKPMCP
VNHLKPPIP
VNHLKPDIP
VNHLKPTIP
VNHLRKT
VNHLRKI
VNHLRKM
VNHLRKR
VNHLRKP
VNDetectHumanHandPoseRequestPrivateRevisionStarSkyModelDrop1
%@ labelKey = %d; rotationAngle = %f; yawAngle = %f, pitchAngle = %f
-[VNMPImageData initWithCVPixelBufferImage:externalImageId:andExifTimestampValue:error:]
MPImageData.m
-[VNMPImageData initWithVImage:externalImageId:andExifTimestampValue:error:]
ERROR: The input image does not seem to be 8888
no operation point data is available for "%@"
unknown classification identifier "%@"
%@ must implement %@
LKT:ComputeFlow level %d
lkt_bgra2yuva
lkt_zero_flow
lkt_downscale_2x
lkt_features
lkt_features_derivatives
lkt_solver_prepare_matrices
lkt_solver_box7_y
lkt_solver_box_x_and_Axb
lkt_nlreg_hegbf
LKT::Pyramid
Optical flow estimation invalid state
Could not bind pixel buffer to texture
Unhandled metal pixel format
LKT:waitUntilCompleted
unable to determine preferred image size for detection
Failed to center square crop the input image
Failed to scale the input image
VNDetectFaceLandmarksRequest revision %lu doesn't support constellation %lu
VNRequestFaceLandmarksConstellationNotDefined
VNRequestFaceLandmarksConstellation65Points
VNRequestFaceLandmarksConstellation76Points
Failed to initialize VNImageprint object
Failed to deserialize requestRevision
Invalid format of VNImageprint serialized state
ipOrgReq
ipType
MPImDesc
VNIp
ipReqRev
could not compute faceprint distance
otherImageprint cannot be nil
VNFaceGeometryEstimatorInitOption_ImageSize
VNFaceGeometryEstimatorInitOption_CameraFocalLength
VNFaceGeometryEstimatorProcessOption_EstimatePoseOnly
VNFaceGeometryEstimatorProcessOption_InputFaceObservation
Failed to estimate face geometry
Could not read face geometry estimator model data
eigenshape
_%llu
v32@?0@"NSString"8@16^B24
metallib
ImageFilters
com.apple.VN
CIAreaAverage
contrastFromAverage
contrastWithPivot
emp_data
emp_elementsCount
emp_elementsType
emp_length
emp_labelsAndConfidence
VNEspressoModelImageprint
emp_algorithmVersionCodingKey
emp_algorithmVersion
Unknown distance funtion requested
cannot compare prints of %@ and %@
VNEspressoModelImageprint(s) with different length supplied
nil VNEspressoModelImageprint(s) supplied
Failed to initialize 'print' object
Memory allocation failure
Invalid format of %@ serialized state
Invalid input data to de-serialize a print object
State cannot be nil
Inconsistent intenal state
elementCount
descriptorByteLength
descriptorData
request
unable to create a %@ %@ %@ descriptor with length %@
expected descriptor length of %@ does not match the encoded length of %@
invalid element type of %@
descriptor length is unavailable
descriptor data is unavailable
VNEspressoModelImageprintRequestRevision
%@ could not resolve originating request class of %@: %@
%@ does not specify a default originating request class
facerec_fp3.1_fa1.3.espresso
  %@=%@
LOWKEY
HCOL
CTILT
INTRUSIVE
INTREST
PCOMP
FAIL
NOISE
PPOST
PPERS
PPAT
PSYM
LCOL
PREF
PLHT
OAES
VNImageAestheticsObservation
VNClassifyImageAestheticsRequest
Score
aestheticScore
wellChosenSubjectScore
Size
Points
VNCntsObs
indexPath
argument indexPath cannot be empty
contourIndex
Failed to execute bit string to polygon list with error: %@
B16@?0r^{EPolygonList=ii^{EPolygon}i}8
VNTrajectoryProcessorOption_RequestState
VNTrajectoryProcessorOption_ObjectMinimumNormalizedRadius
VNTrajectoryProcessorOption_ObjectMaximumNormalizedRadius
VNTrajectoryProcessorOption_ProcessingTargetFrameTime
Too many moving objects or noise detected which prevents trajectory processing.
cannot perform analysis with minimum object radius of %f and maximum object radius of %f
Could not create intermediate buffer
inputHeight
inputWidth
CIMaximumComponent
inputImage2
inputImage
CIColorControls
CIMorphologyRectangleMaximum
inputThreshold
CIColorThreshold
CIColorAbsoluteDifference
VNFaceRegionMapGeneratorProcessOption_InputFaceObservations
faceRegionMap-current
Could not read face region map model data
Smile
Disgust
Neutral
Surprise
Scream
Suspicious
Could not create DataDetector
Data detecor not supported for %@
 timeRange=%@
 confidence=%f
timeRange
uuid
VNObservation
%@ boundingBox=%@
VNDetectedObjectObservation
VNDetectRectanglesRequest
 VNFaceLandmarks2D [%@, confidence=%f]
 ID=%lu
screengaze
gaze
faceLM3DOReq
faceLMOReq
faceOrientationIndex
faceJunkinessIndex
faceCaptureQuality
landmarksScore
blinkScore
alignedMeanShape
blinking
faceSmntcSegments
faceAttributes
faceRegionMap
pitch
roll
alignedRotAngle
hasAlignedBBox
faceTorsoprint
torsoprint
faceID
faceIDConfidence
expressions
pose
landmarks3D
landmarksConstellation
precisionEstimates
landmarks65
unalignedBBHAsDouble
unalignedBBWAsDouble
unalignedBBYAsDouble
unalignedBBXAsDouble
alignedBBH
alignedBBW
alignedBBY
alignedBBX
VNFaceObservation
faceLM3DRequestRev
faceLMRequestRev
invalid pose data
Data integrity check failed when un-archiving landmarks constellation. Un-archived constellation is out of range: %lu
unalignedBBH
unalignedBBW
unalignedBBY
unalignedBBX
VNDetectFaceRectanglesRequest
face orientation
exifOrientation cannot be null
%@ is not supported by %@
floatingImageSignature
referenceImageSignature
alignmentTransform
VNTranslationalImageRegistrationRequest
warpTransform
VNHomographicImageRegistrationRequest
 exposureScore=%@
 blurScore=%@
exposure
VNImageprint
VNImageprintObservation
descriptor
VNCreateImageprintRequest
Failed creating a new VNImageprintObservation object
nil imageprint supplied
VNImageBlurScoreRequest
VNImageExposureScoreRequest
%@ cannot provide operation points
 (P/R)
 "%@"
operationPoints
identifier
VNClassifyImageRequest
segmentationMask
labels
featureName
vnpbo_pbdict
VNCoreMLRequest
%@ labels=[%@]
VNRecognizeObjectsRequest
%@ "%@" - "%@" (%f)
featureValue
transform
angle
VNDetectHorizonRequest
vncRepnessById
vncRepIds
vncRepUpdate
Data integrity check failed when unarchiving an object of type: %@
vncTotObjCount
vncCId
vncObjects
vncluster
  representativenessById = %@;
  suggestedIdsForRep = %@;
  shouldUpdateRep = %d;
  objects = %@;
  totalObjCount = %lu;
  clusterId = %lu;
distancesByID
level0Distance
groupedClusteredFaceIDs
clusteredFaceIDs
clusterState
suggestions
clusters
One or more of the feature prints are empty
The observations do not have a feature print that match each others format
The revision of the observations do not match
descriptors
algo
VNSceneObservation
Undefined
VNGenerateImageFeaturePrintRequest
sc_descriptors
sc_algo
VNSmartCamObservation
textObjects
VNRecognizeTextRequest
mvAvgRad
projPts
detPts
eqCoeffs
requestUuid
characterBoxes
VNGenerateOpticalFlowRequest
B32@?0@"VNDetectedObjectObservation"8Q16^B24
B32@?0@"VNFaceObservation"8Q16^B24
 inputDetectedObjectObservations=[%@]
 inputFaceObservations=[%@]
%@ ROI=%@
The region of interest [%g, %g, %g, %g] is not within the normalized bounds of [0 0 1 1]
VNCreateAnimalprintRequestPrivateRevision1MD2
Unspecified error
face
com.apple.espresso.mainqueue
pixelBuffer is not in correct format. (Required format is one component, 32-float)
pixelBuffer cannot be null
Unable to generate smoothed float-32 image buffer
{CGRect={CGPoint=dd}{CGSize=dd}}
VNRecognizeAnimalsRequestPrivateRevisionANODv3
facerec_fp3.0_fa1.3_d7.espresso
torso_v3_md2.espresso
anodv3_torso_v3_md2
%@ not available
Unable to setup request in VNDetectHumanBodyPoseRequest
VCPHumanPoseImageRequest
faceIDModel
maximumElementsPerID
entityPrintOriginatingRequestSpecifier
entityPrintCounts
entityUniqueIdentifiers
Face ID model data deserialization failed with code %@
FaceID model could not be created
unexpected exception
entity unique identifier counts (%lu) do not agree with the print counts (%lu)
v32@?0@"<NSObject><NSCopying><NSSecureCoding>"8Q16^B24
q24@?0@"VNEntityIdentificationModelPrediction"8@"VNEntityIdentificationModelPrediction"16
No entity for identity serial number %d
entity unique identifier / print count mismatch
entity index %lu, observation index %lu was generated by %@, which is not compatible with the model requirement of %@
invalid observation at index %lu for entity at index %lu
vnpbo_bpr
vnpbo_bytes
%@_%zu
vnpbo_attach
vnpbo_attribs
vnpbo_pixelFormat
vnpbo_height
vnpbo_width
tplTracker_FFT_3324
tplTrackerFFT.c
(outputIndex >= 0) && (outputIndex < 72)
tplTracker_IFFT_3324
VNContourDetectorProcessOption_ContrastAdjustment
VNContourDetectorProcessOption_ContrastPivot
VNContourDetectorProcessOption_DetectDarkOnLight
VNContourDetectorProcessOption_MaximumImageDimension
VNContourDetectorProcessOption_ForceUseInputCVPixelBufferDirectly
VNContourDetectorProcessOption_InHierarchy
VNContourDetector: Error extracting contours
VNContourDetector: Failed to create pixel buffer for adjusted image
VNContourDetector: Failed to adjust contrast
VNContourDetector: Original buffer could not be found
VNContourDetector: Failed to create image filters
VNContourDetector: Failed to create a CIContext
VNClassifyFaceAttributesRequestPrivateRevisionCameraLightweight
VNClassifyFaceAttributesRequestPrivateRevision1_3_MD2
VNClassifyFaceAttributesRequestPrivateRevision1_3_MD3
portrait
landscape
ciImage
cgImage
pixelBuffer
no image buffer available
unable to serialize the face ID model (status = %@)
serialNumberToIdentifier
v32@?0@"NSNumber"8@"<NSObject><NSCopying><NSSecureCoding>"16^B24
q24@?0@"VNPersonsModelPrediction"8@"VNPersonsModelPrediction"16
A prediction for an unknown identity with serial number %@ and confidence %f was provided
v32@?0@"<NSObject><NSCopying><NSSecureCoding>"8@"NSNumber"16^B24
maximumElementsPerID should be less or equal than INT32_MAX
mismatched faceprint request revision for observation at index %lu, person at index %lu
invalid face observation at index %lu for person at index %lu
heal
Contours.c
(endpoint2 == 4)|| (endpoint2 == 8)
(endpoint2 == 8)|| (endpoint2 == 6)
(endpoint2 == 6)|| (endpoint2 == 2)
(endpoint2 == 2)|| (endpoint2 == 4)
healCenters
ady == 2
AdjacentContourHeal
PCOORD_EQUAL(joinPoint, LAST_PCOORD(cPtrN))
PCOORD_EQUAL(joinPoint, FIRST_PCOORD(cPtrN))
testJoin
(orn >= 0) && (orn <= 8)
orn != 4
landmarks
landmarks_63
landmarks_76
occlusion
output matrix size too small
matrix size too small for output
broadcast op: dimension mismatch
unknown axis value
dimensions of data points mismatch
output distance matrix too small
matrix size mismatch
empty cumsum vector
vector length < rows
vector length < cols
row index out of range
col index out of range
aligned buffer allocation of 
 exceeded calculated size of 
matrix vector size mismatch
vector size too small for output
FaceIDModel_v1_d17
readOnly
VNHumanHandPoseDetectorProcessOption_MaximumHandCount
VCPRequestMaxNumOfHandsPropertyKey
/System/Library/PrivateFrameworks/VideoProcessing.framework/VideoProcessing
/System/Library/PrivateFrameworks/VideoProcessing.framework/Contents/MacOS/VideoProcessing
VCPRequestRevisionPropertyKey
Unable to setup request in VNDetectHumanHandPoseRequest
VCPHandPoseImageRequest
Unable to find class %s
Internal error:  detection of Human Torsos should be handled by ANFD Detector Compound Request
%@ upperBodyOnly=%@
VNDetectHumanRectanglesRequestPrivateRevisionANODv3
Error deserializing object of type %@
ap_conf
VNCreateAnimalprintRequest
Model name: %@, network: %p, plan: %p: context: %p
Could not feed-forward buffer data becuase of compatibility of source and destination buffers
Could not bind input buffer to network
Could not bind output buffer to network
inference network cannot be nil
Unknown inference buffer type
inference buffer image with row bytes size of %ld cannot be rendered into a pixel buffer with %lu bytes per row
Unsupported inference buffer storage type (%lu)
could not lock pixel buffer
inference buffer image with dimensions %ld x %ld cannot be rendered into a pixel buffer with dimensions %ld x %ld
Error allocating %lu x %lu CVPixelBuffer with format %lu
Unsupported pixel format %lu
Could not build inference plan
Could not declare network output buffer: %@
Could not declare network input buffer: %@
Could not set network configuration: %@
Could not create/add network to inference plan
Could not create inference plan
Could not create inference context
Invalid inputs specified to inference plan builder
blob "%@" was not found in %@
unable to introspect %@
.espresso.net
shape
json
Unable to locate resource "%@" of type "%@" in %@
anod_v3_d3
Unable to locate resource bundle
%@/%@
Frameworks/LoopKitGeneratedKernels.framework/
Unable to locate %@
model_opt.espresso
resourceDirectory must point to a valid reference
alpha_refined
alpha
learned-matting-1512x2016.espresso
torso_v3_md4.espresso
anodv3_torso_v3_md4
DogHead
CatHead
Internal error:  detection of animal heads should be handled by ANFD Detector Compound Request
^ +| +$
true
unordered_map::at: key not found
VNImageRegistrationDetectorProcessOption_ReferenceImageRegistrationSignature
VNImageRegistrationDetectorProcessOption_FloatingImageRegistrationSignature
VNImageRegistrationDetectorProcessOption_MinimumOverlapPercentage
Input pixel buffer invalid pixel format
Failed to lock input pixel buffer
CPU optical flow not properly initialized
VNDetectionprintTensorKeyMixed2
VNDetectionprintTensorKeyMixed6
VNCreateDetectionprintRequest
tensors
unable to create originating request specifier: %@
VNDetectionprintTensor '%@' is not available
ERTFaceBox::ERTDefaultFeatureValue
Error: 
 failed to load from ERT model file!
ERROR: ERTDefaultFeatureValue failed to load from ERT model file!
ERTFaceBox::ERTDefaultPixelValue
ERROR: ERTDefaultPixelValue failed to load from ERT model file!
ERTFaceBox::ERTNumXYPairs
ERTFaceBox::ERTXYPairs
 unexpected size of value
ERTFaceBox::ERTGlobalShift
ERTFaceBox::ERTNumCascadeStages
ERTFaceBox::ERTNumTrees
ERTFaceBox::ERTNumPredictions
ERTFaceBox::ERTNodesThresholds
ERTFaceBox::ERTNodesPredictions
ERTFaceBox::ERTNodesFeatureIDs
ERTFaceBox::ERTNodesLeafFlags
Spans.c
spl != NULL
addSpan
recognized points are not available
AllPoints
unable to locate point '%@'
groupKey
This method must be overriden
VNFaceLandmarkDetectorProcessOption_RefineLeftEye
VNFaceLandmarkDetectorProcessOption_RefineRightEye
VNFaceLandmarkDetectorProcessOption_RefineMouth
VNFaceLandmarkDetectorProcessOption_BlinkDetection
VNFaceLandmarkDetectorProcessOption_CascadeStepCount
VN facelandmark2d debug intermediates written to: %@
outputLandmarks
inputMeanShape
aligned
_info.json
_output_intermediate_landmarks.png
_input_intermediate_meanShape.png
_input_intermediate_image.png
_input_intermediate_image.vdump
VN_facelandmark2d_debug_intermediates/
Landmark Detector did not provide any data
landmarks_v2
mouth
lefteye
righteye
Landmark algorithm is not initialized
Could not read landmark model data
VN_DEBUG_DUMP_JUNK_INTERMEDIATES
.json
VN_junk_classifier_debug_intermediates
Trying to run junk classifier when the classifier failed to initialize
junk
junk-classifier-labels-current
junk-classifier-current
junk-descriptor-current
VN3FNQUJVIs2puI1uPc9mxh7
VNSY8t4EoTztuqIL02g8uVA0
VN6XNMvaRunPpzWjGa9uUHD6
VN4QuphG8kE4qDaDycivBkX5
VN7gQUejje8mmnE9GSTsVBVV
VNa9xpOJNvRoaW9plFGZ9Eo0
VN2vIWnsZbk4Su55oeWfKDq1
VNmNJnu0xlW8CZXt6hJ7Rpb0
VN35FOB1QhtSfYGRIJvTgtTq
VN6ZsEIQ9ri2eF1vhsxw5COm
VN4EVgYIp7c9hqurREgYE3oE
VN586xt6lvDeEI7qF1vKQLrD
VN5M3z9ICRcyCF1ByLEwd9pZ
VN7LwTOQRUVgWYGTpBWmEuHR
VN7cyr9XFDn4gd6NHo6Gtid5
input__0
add3__0
VNRectangleDetectorProcessOption_Version
VNRectangleDetectorProcessOption_MaximumNumber
VNRectangleDetectorProcessOption_MinimumConfidence
VNRectangleDetectorProcessOption_MinimumAspectRatio
VNRectangleDetectorProcessOption_MaximumAspectRatio
VNRectangleDetectorProcessOption_QuadratureTolerance
VNRectangleDetectorProcessOption_MinimumSize
VNRectangleDetectorProcessOption_HighAccuracy
VNRectangleDetectorProcessOption_MinimumAspectRatio value, %f is greater than VNRectangleDetectorProcessOption_MaximumAspectRatio value, %f
 PixelFocalLength value is out of bounds: %f
invalid region of interest: %@
faceimage
facelocxy
VNFaceDetectorInitOption_MinFaceSize
VNFaceDetectorInitOption_EnableLowMemoryMode
%@_face_%d
VN_DEBUG_DUMP_FACE_DETECT_INTERMEDIATES
%@ faceBoundingBox=%@ pointCount=%lu requestRevision=%lu
FLMReg_OReq
FLMReg_PtCnt
FLMReg_BBH
FLMReg_BBW
FLMReg_BBY
FLMReg_BBX
VNFaceLandmarkRegion
Failed to unarchive VNFaceLandmarkRegion object. Error: %@
%@ does not provide a default originating request class
could not decode originating request
FLMReg_Rev
Failed to unarchive VNFaceLandmarkRegion object due to coding version mismatch: Currently supported: %u; encoded: %u
{CGSize=dd}
failed to allocate internal points array
FLMs_PtsAE
FLMReg2D_PtsData
VNFaceLandmarkRegion2D
Failed to unarchive VNFaceLandmarkRegion2D object. Error: %@
Failed to unarchive VNFaceLandmarkRegion2D object. Error: points buffer size mismatch (data size: %lu; expected: %lu)
Failed to unarchive VNFaceLandmarkRegion2D object due to coding version mismatch: Currently supported: %u; encoded: %u
[VNFaceLandmarkRegion2D -initWithRequestRevision:faceBoundingBox:] is not available, use class designated initializers
VNDetectFaceLandmarksRequest
FLMReg3D_PtsData
VNFaceLandmarkRegion3D
Failed to unarchive VNFaceLandmarkRegion3D object. Error: %@
Failed to unarchive VNFaceLandmarkRegion3D object. Error: points buffer size mismatch (data size: %lu; expected: %lu)
Failed to unarchive VNFaceLandmarkRegion3D object due to coding version mismatch: Currently supported: %u; encoded: %u
[VNFaceLandmarkRegion3D -initWithRequestRevision:faceBoundingBox:] is not available, use class designated initializers
VNDetectFace3DLandmarksRequest
%@ pointCount=%lu requestRevision=%lu
Can't use abstract base class. Must be VNFaceLandmarks2D or VNFaceLandmarks3D
FLMs_OReq
FLMs_UsrFacingBBoxH
FLMs_UsrFacingBBoxW
FLMs_UsrFacingBBoxY
FLMs_UsrFacingBBoxX
FLMs_AlgnBBoxH
FLMs_AlgnBBoxW
FLMs_AlgnBBoxY
FLMs_AlgnBBoxX
FLMs_PtsData
FLMs_PtsCnt
FLMs_Conf
VNFaceLandmarks
Failed to unarchive VNFaceLandmarks object. Error: %@
FLMs_Rev
Failed to unarchive VNFaceLandmarks object due to coding version mismatch: Currently supported: %u; encoded: %u
pointIndices must not be nullptr
FLMs2D_PtsAE
FLMs2D_CType
VNFaceLandmarks2D
Failed to unarchive VNFaceLandmarks2D object. Error: %@
Unexpected number of landmark points: %lu; expected: %lu
Failed to unarchive VNFaceLandmarks2D object due to coding version mismatch:Currently supported: %u; encoded: %u
VNFaceLandmarks3D
Failed to unarchive VNFaceLandmarks3D object. Error: %@
Failed to unarchive VNFaceLandmarks3D object due to coding version mismatch: Currently supported: %u; encoded: %u
bodynet_v1.0.espresso
torso_print__0
inference output results dimensions are incorrect
The '%@' option specifies %@, not the required %@
default value
%@ is %f which is not in the range [%f..%f]
%@ is %d which is not in the range [%d..%d]
The score value %f must be in the range [-1..1]
The confidence value %f must be in the range [0..1]
cluster IDs
detected object observations
face observations
All elements in the %@ array must be a VNRequest subclass (%@)
All elements in the %@ array must be a Class object (%@)
The %@ array has %lu items, which is more than the maximum allowed of %lu
The %@ array has %lu items, which is less than the required count of %lu
%@ is nil
array
expectedAncestoralClass
%@ was given %@
zero-dimensioned image (%ld x %ld)
landmarksflow-gwkf986dmy_63053_plus_8dtz95rnyx_quantized.espresso
Unexpected landmarks constellation (%d) while processing Face Landmarks
Internal error while processing Face Landmarks
adjustments
%@ [%@]
Exporting of legacy CVMLFaceprints is disabled.  Please convert to VNFaceprint and export
CVMLFaceprint_ProfileCodingKey
CVMLFaceprint_PlatformCodingKey
CVMLFaceprint_KeyCodingKey
CVMLFaceprint_FaceprintCodingKey
CVMLFaceprint_CodingVersionCodingKey
Exporting of CVMLObservation_LegacySupportDoNotChange is not allowed.  Please use VNObservation instead.
CVMLImageprintObservation
Exporting of legacy CVMLImageprintObservation_LegacySupportDoNotChange is disabled.  Please convert to VNImageprintObservation and export
CVMLImageprintObservation_ImageprintDescriptorColorGaborVersion
CVMLImageprintObservation_ImageprintTypeCodingKey
CVMLImageprintObservation_UUIDCodingKey
CVMLImageprintObservation_ImageprintDescriptorCodingKey
CVMLImageprintObservation_VersionCodingKey
CVMLImageprintObservation_ObjectCodingKey
CVMLImageprintObservation_ImageprintTypeColorGabor
MPImageDescriptor
ERROR: invalid image Id format
ERROR: state cannot be nil
Exporting of legacy MPImageDescriptor_LegacySupportDoNotChange is disabled.  Please convert to VNImageprintObservation and export
MPImageDescriptor_ColorGaborImageDescriptorBuffer_stride
MPImageDescriptor_ColorGaborImageDescriptorBuffer_count
MPImageDescriptor_ColorGaborImageDescriptorBuffer_data
MPImageDescriptor_ColorGaborImageDescriptorBuffer_lengthInBytes
MPImageDescriptor_ColorGaborImageDescriptorBuffer_type
MPImageDescriptor_quality
MPImageDescriptor_exifTimestamp
MPImageDescriptor_externalImageId
CVMLObservation
CVMLObservation_ConfidenceCodingKey
CVMLObservation_CodingVersionCodingKey
Deserialized confidence is outside of the valid range
Internal error desrializing torsoprint
tp_conf
Tp_algorithmVersion
Tp_VNTorsoprint
Tp_labelsAndConfidence
Tp_length
Tp_elementsType
Tp_elementsCount
Tp_data
VNCreateTorsoprintRequest
v16@?0^v8
%@:UUID=%@
The requested FeaturePrint.scene is not available. Requested revision: %lu
The model does not have a valid input feature of type image
could not obtain a feature value for key "%@"
q24@?0@"VNClassificationObservation"8@"VNClassificationObservation"16
v32@?0@8Q16^B24
The confidence scores don't line up with the labls.
The outputs of the model are of unexpected types.
The inputImageFeatureName does not point to a MLFeatureTypeImage input.
No valid VNCoreMLModel found in passed in options
VNImageAnalyzerMultiDetectorSceneNetV3R8
VNImageAnalyzerMultiDetectorSceneNetV4
no data source available
plist
Identifier
no %@ is defined at %@
recall
precision
threshold
operation point map data for "%@" is corrupt
unable to open %@
invalid recall table for "%@"
missing recall table for "%@"
invalid precision table for "%@"
missing precision table for "%@"
missing F2 for "%@"
missing threshold for "%@"
could not locate the %@ resource for operation points identifier "%@"
unknown operation points identifier "%@"
scenenet4_op.plist
scenenet_op-v8d.plist
VNFaceLegacyFaceCoreFeature_LeftEyeClosedScore
VNFaceLegacyFaceCoreFeature_RightEyeClosedScore
VNFaceLegacyFaceCoreFeature_SmileScore
fcr_features
fcr_trackduration
fcr_trackid
fcr_mouth
fcr_righteye
fcr_lefteye
fcr_bbox
fcr_center
fcr_angle
fcr_size
fcr_profile
VNFaceLegacyFaceCore
@"VNSmartCam5CompoundRequestGroupingConfiguration"24@?0@"VNRequest"8Q16
MinConfidenceForHierarchical
hierarchicalLabelsAndConfidence
MinConfidenceForClassificationRaw
debugID
.vdump
.png
_tile_
imageID
numTiles
augmentationMode
scalingFactor
VN Image Classifier debug intermediates written to: %@
_source_scaled.vdump
_source_scaled.png
B8@?0
Attempt to create an imageprint failed
FAFrameRate
parabolaLength
minXDistanceFromLastPointOnParabola
maxXDistanceFromLastPointOnParabola
minYDistanceFromLastPointOnParabola
maxYDistanceFromLastPointOnParabola
maxFramesSkippedToContinueParabolaDetection
PersonSeg__predictions__0
prev_mask__0
input_data__0
personsegmentation-si-01.espresso
FaceRegionMap::Width
FaceRegionMap::Height
FaceRegionMap::Data
FaceRegionMap::Triangles
FaceRegionMap::NormalizedLandmarks
Background
Left eye
Right eye
Left eyebrow
Right eyebrow
Root of nose
Nose
Chin
Lower left cheek
Lower right cheek
Between mouth and nose
Left cheek
Right cheek
Left temple
Right temple
Between eyebrows
Above left eye
Above right eye
Upper lip
Lower lip
Between lips
Forehead
Tip of nose
VNOpticalFlowGeneratorProcessOption_PreviousObservation
VNOpticalFlowGeneratorProcessOption_OutputPixelFormat
VNOpticalFlowGeneratorProcessOption_LevelCount
VNOpticalFlowGeneratorProcessOption_WarpCount
VNOpticalFlowGeneratorProcessOption_EnableFiltering
VNOpticalFlowGeneratorProcessOption_FilterSize
VNOpticalFlowGeneratorProcessOption_FilterSamplingDensity
VNOpticalFlowGeneratorProcessOption_FilterLumaWeight
VNOpticalFlowGeneratorProcessOption_FilterChromaWeight
VNOpticalFlowGeneratorProcessOption_FilterOcclusionWeight
Failed to initialize optical flow
Failed to allocate the vector result buffer
filterSamplingDensity
filterSize
levelCount
outputPixelFormat
Optical flow cannot be performed on images with different dimensions
NtCreatePixelBuffer
ntModel.cpp
ret == kCVReturnSuccess
net_exempler_reg
net_exempler_cls
r1_kernel
cls1_kernel
classification_x_corr
regress_adjust
EspressoNetUnload
status == ESPRESSO_STATUS_SUCCESS
EspressoNetExemplarRun
instance_image
EspressoNetInstanceRun
%@ FAS=%@
VNDetectScreenGazeRequest
oreq
Cannot create CVPixelBuffer object. Error = %d
Cannot copy face segment probability map. Error = %d
Cannot create CVPixelBuffer object: region parameter is out of range
Cannot create CVPixelBuffer object: faceSegment parameter is out of range
Cannot create CVPixelBuffer object: faceSegments is out of range
Cannot create CVPixelBuffer object
fsLblToProbMap
fsBBoxSzH
fsBBoxSzW
fsBBoxOrgY
fsBBoxOrgX
fsNumOfSgmnts
fsData
fsHeight
fsWidth
fsRev
VNFaceSegmentsVersion
Data integrity check failed when un-archiving an object of type: %@
facerec_fa1.3_lightweight.espresso
faceprinting is not supported in camera lightweight mode
Object identifier is not initialized in detected object observation
VNDetectedObjectObservation object is expected to initialize Object Tracker
::open failed
void cvml::util::mapped_model_file_open::open_file(const char *, bool)
fstat failed
mmap MAP_FAILED
/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-5.0.70.1/VisionKitFramework/VN/algorithm_util/mapped_model_file.h
Error %s when executing %s in file %s:%d
syslog_assert_failed
common_defines.h
false
::madvidse failed
virtual void cvml::util::mapped_model_file_open::advise(int) const
fopen failed
void cvml::util::mapped_model_file_fopen::open_file(const char *)
ftell failed
fseek failed
polygonListWithBitString failed
B24@?0@"VNDetector"8^B16
v24@?0@"VNDetector"8^B16
request classes
requests
Processing dispatch queue is unavailable
com.apple.VNSession
Cannot create framework manager singleton
Invalid points count %ld
null points array
null perimeter pointer
Invalid contour passed in
null area pointer
Cannot calculate minimum enclosing circle for the given set of points
A collection must contain 3 points
Number of points in collection must be greater or equal than %lu
Number of points in collection must be greater than zero
Invalid number of points passed for minimum enclosing circle calculation
-[VNMPImageDescriptor computeDescriptorForImageData:context:error:]
MPImageDescriptor.mm
error != nil
Invalid state format
state parameter cannot be nil
MPImageDescriptor cannot be serialized without being created
VNMPImageDescriptor_ColorGaborImageDescriptorBuffer_stride
VNMPImageDescriptor_ColorGaborImageDescriptorBuffer_count
VNMPImageDescriptor_ColorGaborImageDescriptorBuffer_data
VNMPImageDescriptor_ColorGaborImageDescriptorBuffer_lengthInBytes
VNMPImageDescriptor_ColorGaborImageDescriptorBuffer_type
VNMPImageDescriptor_quality
VNMPImageDescriptor_exifTimestamp
unable to allocate descriptor data
Integer overflow occured when unarchiving an object of type: %@ stride: %zu count: %zu
ERROR: Could not compute image registration features
ERROR: Could not compute the convnet-based image descriptor
ERROR: Could not compute the image descriptor
Cannot generate face segments
Food
Drink
VNRecognizeFoodAndDrinkRequestPrivateRevisionANODv4
VNDetectFaceRectanglesRequestPrivateRevisionANFD2Detector
VNDetectFaceRectanglesRequestPrivateRevisionANOD3Detector
VNDetectFaceRectanglesRequestPrivateRevisionLegacyFaceCore
v24@?0d8@"NSError"16
%@:%@:%p:%ld:%d:%d:%d:%f
[%@]
(x; y) = (%f; %f); (r; theta) = (%f; %f)
vproj
%@%s
##INVALID##
VNImageAnalyzerMultiDetectorInitializationOption_Model
VNImageAnalyzerMultiDetectorInitializationOption_RequireObjDetNet
VNImageAnalyzerMultiDetectorInitializationOption_RequireSliderNet
VNImageAnalyzerMultiDetectorInitializationOption_PreferLowerGPUMemoryUtilization
VNImageAnalyzerMultiDetectorProcessingOption_SkipInputImageScaling
VNImageAnalyzerMultiDetectorProcessingOption_ImageCropAndScale
VNImageAnalyzerMultiDetectorProcessingOption_CreateSceneprint
VNImageAnalyzerMultiDetectorProcessingOption_SceneprintOriginatingRequestSpecifier
VNImageAnalyzerMultiDetectorProcessingOption_SceneprintIncludeLabelsAndConfidences
VNImageAnalyzerMultiDetectorProcessingOption_SceneprintObservationsArray
VNImageAnalyzerMultiDetectorProcessingOption_CreateCompressedSceneprint
VNImageAnalyzerMultiDetectorProcessingOption_CompressedSceneprintOriginatingRequestSpecifier
VNImageAnalyzerMultiDetectorProcessingOption_CompressedSceneprintObservationsArray
VNImageAnalyzerMultiDetectorProcessingOption_ClassifyScene
VNImageAnalyzerMultiDetectorProcessingOption_SceneOriginatingRequestSpecifier
VNImageAnalyzerMultiDetectorProcessingOption_SceneBlacklist
VNImageAnalyzerMultiDetectorProcessingOption_SceneMaximumLeafLabels
VNImageAnalyzerMultiDetectorProcessingOption_SceneMaximumHierarchicalLabels
VNImageAnalyzerMultiDetectorProcessingOption_SceneMinimumConfidence
VNImageAnalyzerMultiDetectorProcessingOption_SceneObservationsArray
VNImageAnalyzerMultiDetectorProcessingOption_SceneClassificationCustomHierarchy
VNImageAnalyzerMultiDetectorProcessingOption_ClassifyJunk
VNImageAnalyzerMultiDetectorProcessingOption_JunkOriginatingRequestSpecifier
VNImageAnalyzerMultiDetectorProcessingOption_JunkObservationsArray
VNImageAnalyzerMultiDetectorProcessingOption_ClassifyVNVYvzEtX1JlUdu8xx5qhDI
VNImageAnalyzerMultiDetectorProcessingOption_VNVYvzEtX1JlUdu8xx5qhDIOriginatingRequestSpecifier
VNImageAnalyzerMultiDetectorProcessingOption_VNVYvzEtX1JlUdu8xx5qhDIObservationsArray
VNImageAnalyzerMultiDetectorProcessingOption_ClassifyAesthetics
VNImageAnalyzerMultiDetectorProcessingOption_AestheticsOriginatingRequestSpecifier
VNImageAnalyzerMultiDetectorProcessingOption_AestheticsObservationsArray
VNImageAnalyzerMultiDetectorProcessingOption_GenerateSaliencyAHeatMap
VNImageAnalyzerMultiDetectorProcessingOption_SaliencyAOriginatingRequestSpecifier
VNImageAnalyzerMultiDetectorProcessingOption_SaliencyAObservationsArray
VNImageAnalyzerMultiDetectorProcessingOption_GenerateSaliencyOHeatMap
VNImageAnalyzerMultiDetectorProcessingOption_SaliencyOOriginatingRequestSpecifier
VNImageAnalyzerMultiDetectorProcessingOption_SaliencyOObservationsArray
VNImageAnalyzerMultiDetectorProcessingOption_ClassifyVN5kJNH3eYuyaLxNpZr5Z7zi
VNImageAnalyzerMultiDetectorProcessingOption_VN5kJNH3eYuyaLxNpZr5Z7ziRequestSpecifier
VNImageAnalyzerMultiDetectorProcessingOption_VN5kJNH3eYuyaLxNpZr5Z7ziObservationsArray
VNImageAnalyzerMultiDetectorProcessingOption_ClassifyVNdGg5skzXHSAENO6T3enHE
VNImageAnalyzerMultiDetectorProcessingOption_SignificantEventOriginatingRequestSpecifier
VNImageAnalyzerMultiDetectorProcessingOption_VNdGg5skzXHSAENO6T3enHEObservationsArray
VNImageAnalyzerMultiDetectorProcessingOption_RecognizeObjects
VNImageAnalyzerMultiDetectorProcessingOption_RecognizeObjectsOriginatingRequestSpecifier
VNImageAnalyzerMultiDetectorProcessingOption_RecognizeObjectsObservationsArray
VNImageAnalyzerMultiDetectorProcessingOption_RecognizeObjectsBlacklist
VNImageAnalyzerMultiDetectorProcessingOption_RecognizeObjectsModelMinimumDetectionConfidence
VNImageAnalyzerMultiDetectorProcessingOption_RecognizeObjectsModelNonMaximumSuppressionThreshold
VNImageAnalyzerMultiDetectorProcessingOption_ClassifyPotentialLandmark
VNImageAnalyzerMultiDetectorProcessingOption_PotentialLandmarkOriginatingRequestSpecifier
VNImageAnalyzerMultiDetectorProcessingOption_PotentialLandmarkObservationsArray
VNImageAnalyzerMultiDetectorProcessingOption_VN1JC7R3k4455fKQz0dY1VhQ
VNImageAnalyzerMultiDetectorProcessingOption_VN1JC7R3k4455fKQz0dY1VhQOriginatingRequestSpecifier
VNImageAnalyzerMultiDetectorProcessingOption_VN1JC7R3k4455fKQz0dY1VhQObservationsArray
leaf/probabilities
stem/SpatialSqueeze_COPY254
events_gating_labels_basic-v1c.txt
events_gating.r14.e4.espresso
hierarchical/probabilities
stem/SpatialSqueeze_NEW254
sg_labels.txt
sg.r14.s4.espresso
fruit
vegetables
fish
seafood
cannot provide identifiers for %@
junk classification not supported for %@
VNImageAnalyzerMultiDetectorModelUndefined
VNImageAnalyzerMultiDetectorModelSceneNetV3
VNImageAnalyzerMultiDetectorModelSceneNetV3StillCapturePipeline
VNImageAnalyzerMultiDetectorModel%lu
junk_hierarchical_SceneNetSky_v0.0.x_62sm8dw77a_130001_j1.0.0.espresso
stem/MobilenetV3/SpatialSqueeze_NEW138
junk_leaf_SceneNetSky_v0.0.x_62sm8dw77a_130001_j1.0.0.espresso
junk_hierarchical.labels_higher_order-v3b.txt
junk_hierarchical.r14.j9.espresso
junk_leaf.labels_basic-v3b.txt
junk_leaf.r14.j9.espresso
Exclusive tiling condition in horizontal or vertical directions is not satisfied
v64@?0{CGRect={CGPoint=dd}{CGSize=dd}}8Q40Q48^B56
custom hierarchy created for revision %lu cannot be used with a detector for revision %lu
^{__CVBuffer=}16@?0^@8
vegetable
failed to create saliency heat map image
subject_framing
background
blur
subject_sharpness
timing
lightning
reflections
color_harmony
color_brightness
symmetry
repetition
immersive_feeling
perspective
post_processing
noise
failure
composition
interestingness
object_intrusion
tilt
low_light
positive
labels/probabilities
landmarks_gating_labels.txt
landmarks_gating.r14.l3.espresso
labels_vienna-v1e.txt
vienna.r14.n4.1.espresso
could not create a compressed sceneprint from tensor vector with %lu elements (%lu bytes)
pca256
scenenet_sc2.4_sa1.4_ae1.4_r9_opt_int8_pca256.pcadata
could not create a sceneprint from tensor vector with %lu elements (%lu bytes)
inner/sceneprint
classification/labels
objectness/map
detection/concat
detection/concat_scale_
offsets
scores
aircraft
automobile
bicycle
bird
bottle
canine
consumer_electronics
feline
furniture
headgear
kite
computer_monitor
motorcycle
musical_instrument
document
people
food
sign
watersport
train
ungulate
watercraft
flower
appliance
sports_equipment
tool
slidernet/HighKeyCI
slidernet/ContrastCI
slidernet/WhiteBalanceTempTintCI
slidernet/ColorCastCI
slidernet/ExposureAndBlackPointCI
slidernet/HighlightsCI
slidernet/VibrancyCI
GXdCvXzGnLp59suJyVSan_labels.txt
scenenet_labels_basic-v8d.csv
scenenet_aesthetic_labels_basic-v8e
a hierarchical model for detector model %lu is not supported
scenenet_relationships-v8d.txt
boomerang
bubble_soap
cider
doll_house
electronic_toy
equipment
logo
logo_other
pinata
raw_cardboard
raw_other
raw_plastic
shoe_other
skysurfing
slipper
sport_other
swing_dancing
tablet
toy_organizer
ammunition
blackjack
blade
body_part
brassiere
firearm
holiday
magic
menorah
minaret
missile
oktoberfest
pistol
primate
projectile
ramadan_lantern
raw_metal
religion
revolver
rifle
sauna
shotgun
tank_army
temple_exterior
thanksgiving
underwear
underwear_male
weapon
scenenet_sc2.4_sa1.4_ae1.7_r14.2-c_opt_int8_fp16-sp_ae_sa_only.espresso
sn3_4heads_combined_299_no_softmax.espresso
sn3_all_heads_combined_299_no_softmax.espresso
maximumImageDimension
maximumImageDimension property must be in the range [%lu..%lu]
contrastPivot
contrastPivot property must be in the range [%f..%f]
VNRecognizeDocumentElementIdentifierDocument
VNRecognizeDocumentElementIdentifierText
VNRecognizeDocumentElementIdentifierQRCode
VNRecognizeDocumentElementIdentifierAppCode
initializeCannyEdgeContext
cannyEdge.c
context->blockAddress
thresholdAndConnectCandidateEdges
context->edgeStackSize <= context->width*context->height
VNTorsoprintGeneratorProcessOption_InputDetectedObjectObservation
Unexpected size of torsoprint descriptor
unable to lock base address of pixel buffer
Could not create torso print generator
smartcam_onlyfc
CCTextDetector_EnableDebug
CCTextDetector_DebugPathname
q24@?0@"VNTextObservation"8@"VNTextObservation"16
textBoxRevisedNormalized
stubBoxNormalized
CCTextDetector internal error
textBoxRevised
stubBoxMM
{{%2.4f,%2.4f},{%2.4f,%2.4f}}
{{%i,%i},{%i,%i}}
stubBox
connectedComponents.png
{{1,1},{1,1}}
charConfidence
charBoxMM
charBox
textBoxMM
textBox
uOutImage.png
selectedTextOutImageArray.png
adaptiveOutImage.png
color profile context must not be NULL
textOutSecondPassImage.png
textOutFirstPassImage.png
/var/mobile/Media/DCIM/ccOutDebug/
inverseVotingImage.png
votingImage.png
creditCardSubsampleImage.png
map::at:  key not found
VNEspressoModelFileBasedDetectorOption_InputBlobNames
VNEspressoModelFileBasedDetectorOption_OutputBlobNames
VNEspressoModelFileBasedDetectorOption_NetworkConfiguration
%@:%@:%@
inference plan failed to execute
failed to bind pixel buffer to network
failed to bind buffer to network
could not obtain the dimensions of "%@"
Unexpected network input image size
%@ did not provide a valid model input image dimensions blob name
%@ did not provide a valid model file name
en_US
%@:%@:%p:%ld:%d:%f
 "%@" - (%f) revision: %ld
crOutput
The value for epsilon is invalid. It needs to be bigger than zero but it is %f
The contour is too small for polygon approximation
childIndex
flatten_output
softmax_
_output
_fc/Relu
_embedding
confidence
v4.1
1.3_lightweight
3.1.3
UNKNOWN_0
UNKNOWN_1
UNKNOWN_2
UNKNOWN_3
UNKNOWN_4
UNKNOWN_6
UNKNOWN_7
UNKNOWN_5
UNKNOWN_8
UNKNOWN_9
UNKNOWN_10
UNKNOWN_11
UNKNOWN_12
UNKNOWN_13
UNKNOWN_14
UNKNOWN_15
UNKNOWN_16
UNKNOWN_17
_unknown
box = %@; default box = %@; confidence = %f; rotationAngle = %f; yawAngle = %f label = %d; boxCenter = %@
(%g, %g)
[%g, %g, %g, %g]
face observations are not available
face model data is unavailable
VNCreateSceneprintPrivateRevision64DimensionPCA
VNCreateSceneprintPrivateRevision128DimensionPCA
VNCreateSceneprintPrivateRevision256DimensionPCA
VNCreateSceneprintPrivateRevision256DimensionPCAStillCapturePipeline
VNCreateSceneprintRequestPrivateRevisionStillCapturePipeline
VNCreateSceneprintRequestPrivateRevisionSceneNetV4
VNCreateSceneprintRequestPrivateRevisionSceneNetV4StillCapturePipeline
 returnAllResults
 useCenterTileOnly
SCL_v0.3.1_9c7zcipfrc_558001.espresso
SCL_v0.3.1_9c7zcipfrc_558001-labels-v3.txt
merged/probabilities
trv3_0.espresso
v3.0
%@ has an invalid value of %@
Chirality
VNFaceLandmarkDetectorDNNProcessOption_Constellation
Could not run Landmark Detector. Error = %s
Unexpected number of occlusion entries for Landmark points (%lu) while processing Face Landmarks request. Expected: %lu
Unexpected number of error estimates for Landmark points (%lu) while processing Face Landmarks request. Expected: %lu
Unexpected number of Landmark points (%lu) while processing Face Landmarks request. Expected: %lu
Could not compute Landmarks using Landmark Detector due to internal error
Unsupported constellation type.
q24@?0@"VNRequest"8@"VNRequest"16
VNHomographicImageRegistrationDetectorProcessOption_ReferenceImageBuffer
VNHomographicImageRegistrationDetectorProcessOption_ReferenceImageRegistrationSignature
VNHomographicImageRegistrationDetectorProcessOption_FloatingImageBuffer
VNHomographicImageRegistrationDetectorProcessOption_FloatingImageRegistrationSignature
failed to create image registration context
registration of region of interest %@ (%@) cannot be performed on reference image of size %@
failed to create GL context
failed to warp image
failed to create a %lu x %lu pixel buffer of type '%c%c%c%c'
VNANFDMultiDetectorProcessingOption_HumanFaceDetectorOriginatingRequestSpecifier
VNANFDMultiDetectorProcessingOption_HumanHeadDetectorOriginatingRequestSpecifier
VNANFDMultiDetectorProcessingOption_HumanDetectorOriginatingRequestSpecifier
VNANFDMultiDetectorProcessingOption_AnimalRecognitionOriginatingRequestSpecifier
VNANFDMultiDetectorProcessingOption_HumanDetectorUpperBody
VNANFDMultiDetectorProcessingOption_HumanDetectorFullBody
VNANFDMultiDetectorProcessingOption_PrecisionRecallThreshold
%@; resultsIndex=%lu
Unexpected label key for detected object: %d
Unexpected number of aligned faces: %lu, should be 1
v16@?0@"NSMutableArray"8
B56@?0@"VNImageBuffer"8{CGRect={CGPoint=dd}{CGSize=dd}}16^@48
Not supported object type: %d
Unexpected zero dimension for image crop
The request info is not found for request class %@
Failure to create multi-headed object detector.
.cmap
getMergeableClusters
GreedyClustering.cpp
ci == clusterID
computeInitialMergingList
L0 > mergingTo
addDescriptors
elementSize == ELEMENT_SIZE
could not decode additional relationships
SCRDL
%@: %@, %@
additional relationships must have at least one child identifier
v32@?0@"NSString"8@"NSArray"16^B24
The classification identifier '%@' does not exist in the hierarchy
%@ must provide an implementation for %@
Unable to determine classification hierarchy for a given request revision: %lu
gazeMask
lookFace
locY
locX
direction
, looking at %@
%@ %@ face %@ %@
VNFaceGazeDirectionUnknown
VNFaceGazeDirectionDifficultToSay
VNFaceGazeDirectionSomewhereElse
VNFaceGazeDirectionCamera
VNFaceGazeDirectionCommonLocation
VNFaceGazeDirectionAnotherFace
VNFaceGazeDirection%@
facecrop
righteyecrop
facelocmat
lefteyecrop
Input faces not provided to face rectangle aligner
sgnHash
sgnPrnt
VNImageHashSignatureObservation
output1
Tap coordinates are out of bounds.
Failed to fill image.
Size mismatch during image copy.
Failed to compute image histogram.
VNClusteringAlgorithm_Greedy
VNClusteringAlgorithm_GreedyWithTorso
options parameter cannot be nil
unsupported cluster algorithm type
splitIntoMonotonicSpans
SegmentUtilities.c
cPtr->nPnts > 1
!closedP
idx <= monoLength
mergeSegment
sPtr2 != NULL
topLevelRegion
 shortDescription="%@", type=%ld
 transcript="%@"
v32@?0@"CROutputRegion"8Q16^B24
crOutputRegion
B24@?0@"CROutputRegion"8@"NSDictionary"16
B24@?0@"VNBarcodeObservation"8@"NSDictionary"16
self isKindOfClass: %@
The VNCoreMLTransform request failed
no sceneprints defined in observation
sceneprint could not be generated
Failed to initialize VNCoreMLTransformer
%@:imageCropAndScaleOption=%lu:Model=%@
%@ %@ model=%@
Option value for option key %@ is a mandatory parameter
Cannot encode null-print object 
Cannot calculate encoding for hash type: %lu
facerec_fp2.2_fa1.1_r2_optimize_rename.espresso
meanShape
convertYUV420ToRGBA8888: src must be YUV420 format!
convertYUV420ToRGBA8888: invalid dst size of %lu x %lu
convertYUV420ToRGBA8888: failed to allocate %lu bytes
public.png
com.apple.vis.VNEntityIdentificationModel
B32@?0@"VNObservation<VNEntityIdentificationModelObservation>"8Q16^B24
B32@?0@"<VNEntityIdentificationModelPrint>"8Q16^B24
unknown entity (%@)
%@ does not support writing version %@
v24@?0Q8^B16
v40@?0@"NSArray"8{_NSRange=QQ}16^B32
model data fails checksum validation
unknown model kind %@
q24@?0@"VNRequestSpecifier"8@"VNRequestSpecifier"16
%@ is generated by %@ instead of %@
%@ cannot be created from a %@
an entity print originating request specifier must be configured
maximumTrainingPrintsPerEntity
model data object %@ is a %@, not the expected %@
no entity print originating request specifier is defined
unable to decode observations for tag %@
unable to decode entity unique identifier for tag %@
upBdyOnly
trsPrnt
VNHumanObservation
VNDetectHumanRectanglesRequest
f8@?0
offsets_%ld
logits_%ld
logits_neg_%ld
logits_pos_%ld
logits_yaw_%ld
logits_roll_%ld
shotflow-8k6zuzd9wy_46860_opt_quantized.espresso
yaw_output
roll_output
rcnn_output_selected_indices
rcnn_output_cls
rcnn_output_scores
rcnn_output
input_image
anodv4_drop6.espresso
face_pose_topk
smartcam
scorPdiffParameters
exprParameters
blinkParametersApp
smileBlinkParametersGeo
exprParamsv1
lmarkQuality
pupilMeanStd
pupil
Could not get output. Error = %s
Could not analyze face. Error = %s
Internal error: input specifications are invalid for executing this request
Unexpected options for HomeApp faceprint generator
Output image has invalid width/height
Output image has invalid pixel format
Input image has invalid width/height
Input image has invalid pixel format
Not implemented in abstract class
Cannot create a face-torso print object
VNCreateFaceTorsoprintRequestPrivateRevisionMD1Torso
solo_landmarks_s9min6ugm8_opt.espresso
VNCreateFaceprintRequestPrivateRevisionHomeApp
VNCreateFaceprintRequestPrivateRevision3_1MD2
VNCreateFaceprintRequestPrivateRevision3_1MD3_HomeApp
VNCreateFaceprintRequestPrivateRevision3_1MD3
Revision %lu of %@ is deprected and not supported anymore
B24@?0Q8^@16
VNImageSignatureDetectorProcessOption_ImageSignatureprintInput
VNImageSignatureDetectorInitOption_ImageSignatureprintType
VNImageSignatureDetectorInitOption_ImageSignatureHashType
Mismatch in signature hash type
Unknown signature print type
Unknown error creating VNObservation object
Unknown signature print type: %lu
neuralhash_128x96_seed1
B24@?0@"NSString"8^@16
Unknown signature hash type: %lu
hash_size
feat_size
projection_matrix
output
input
anodv3_pet_v1_md2
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
VNFaceBBoxAlignerProcessOption_InputFaceObservations
faceBoxPoseAligner-current
Failed to allocate memory for face bounding box aligner model data
Could not map face box aligner model
VNTrackingOption_ProcessingQueue
VNTrackingOption_TrackerKey
VNTrackingOption_TrackerType
VNTrackingOption_TrackingLevel
VNTrackingOption_InputBBox
VNTrackingOption_CVPixelBufferFormat
VNTrackingOption_InputImageMaxWidth
VNTrackingOption_InputImageMaxHeight
VNTrackingOption_TrackingLevelFast
VNTrackingOption_TrackingLevelAccurate
VNTrackingOption_TrackingLevelRPN
Tracking objects failed with error: %llu
No frame to track objects was passed to the tracker
Conversion to Tracker coordinate system failed
failed to initialize object IDs to rectangles dictionary
no tracker results
Setting objects to track failed
Tracker is busy with previous tracking requests. It needs to be reset to restart tracking sequence
VNSmartCamCombinedAestheticsAndSaliencyDetectorOptionClassifyAesthetics
VNSmartCamCombinedAestheticsAndSaliencyDetectorOptionGenerateSaliencyHeatMap
aesthetics/scores
aesthetics/attributes
saliency/map
Failed to create observation
Error allocating VNImageAestheticsObservation
Unexpected attribute scores input types provided
No attribute data returned
Unexpected aesthetic score input types provided
No aesthetic score data returned
Could not bind input image buffer
Could not bind output aesthetics attributes
combined_classification_smartCamfanet_0-0011_saliency_bhutc68tnd_aesthetics_3eqm2xn28k.espresso
+N9mZUAHooNvMiQnjeTJ8g
   +-- %@
Unexpected number of unique observation classes
%@ does not override %@
Cannot generate optical flow
observations are not available in a read-only model
trained model entity print originating request is not defined
trained model data is not available
VNFaceGazeDetectorProcessOption_InputFaceObservations
VNFaceGazeDetectorProcessOption_GazeHeatMapThreshold
VNFaceGazeDetectorProcessOption_CommonGazeLocationRadius
VNFaceGazeDetectorProcessOption_MinimumFaceDimension
B24@?0^{__CVBuffer=}8^@16
Error allocating %lu x %lu CVPixelBuffer with format %@
unexpected gaze label of %d
camgaze_classification_3class_light-nxbrsq87z6_23998_BGR_opt.espresso
gazefollow_3dmaps_cat4-jsk53qcqtz_157500_BGR.espresso
image
v20@?0@"<NSObject><NSCopying>"8B16
no image is available
no request performer available
mask
network input blob name is not available
Could not bind objectness heat map
Unexpected Error: Pixel buffer is NULL
The request class %@ shall have it's results populated in the results array
Internal error processing request of class %@
VNGenerateObjectnessBasedSaliencyImageRequestPrivateRevision544x544Input128x128Output
available person serial numbers is corrupt
identity serial numbers have been exhausted
The model has reached the maximum identity limit of %lu
VNBlurDetectorProcessOption_MaximumIntermediateSideLength
VNBlurDetectorProcessOption_ImageBlurDeterminationMethod
blurDeterminationMethod
VNImageprintGeneratorProcessOption_Timestamp
no valid initial image buffer was provided
VNTorsoprintGeneratorProcessOption_InputFaceObservation
Error in calculating torso bounding box dimensions
faceOrientationRelativeToUpright
Memory for torso bouding box is not allocated
detector_print_mixed26.espresso
classification/mixed_2/concat_channels
classification/mixed_6/concat_channels
data
Could not bind classification/mixed_6/concat_channels
Could not bind classification/mixed_2/concat_channels
could not create tensor
Unexpected espresso result
ConnectedComponents
ConnectedComponents.c
pneighbor(*(Pcoord *)dequeFirst(dbLookup[mnid]), pix)
pneighbor(*(Pcoord *)dequeFirst(dbLookup[nid]), pix)
pneighbor(*(Pcoord *)dequeFirst(dbLookup[mid]), pix)
pneighbor(*(Pcoord *)dequeFirst(dbLookup[pid]), pix)
loc != -1
cidcnt < MAX_CONTOURS
eraseContourPixels
deque != NULL
torso__0
allocSegments
Segments.c
sdb->nSegments <= sdb->maxSegments
center = %@; radius = %f (diameter = %f)
VNImageOptionImageOrientation
VNImageOptionProperties
VNImageOptionCameraPixelFocalLength
VNImageOptionCameraIntrinsics
VNImageOptionCIContext
%c[%@ %@]
VNElementTypeUnknown
VNElementTypeFloat
VNElementTypeDouble
VNElementType(%lu)
VNImageCropAndScaleOptionCenterCrop
VNImageCropAndScaleOptionScaleFit
VNImageCropAndScaleOptionScaleFill
VNImageCropAndScaleOption(%lu)
%g x %g
[%@ %@]
feature orientation
image orientation
Face crop orientation is a mandatory parameter
options
q24@?0@"VNObservation"8@"VNObservation"16
q24@?0@"VNRecognizedObjectObservation"8@"VNRecognizedObjectObservation"16
%@Revision%lu
Loading Resource Error
Model file %@.bin is missing
Model file %@.dat is missing
B16@?0^@8
unable to lock pixel buffer
imageWithCGImage:
UIImage
/System/Library/Frameworks/UIKit.framework/UIKit
bezierPathWithCGPath:
UIBezierPath
UIGraphicsBeginImageContext
UIGraphicsGetCurrentContext
UIGraphicsGetImageFromCurrentImageContext
UIGraphicsEndImageContext
Could not render path on image %@
softlink:r:path:/System/Library/PrivateFrameworks/VideoProcessing.framework/VideoProcessing
softlink:r:path:/System/Library/PrivateFrameworks/BarcodeSupport.framework/BarcodeSupport
softlink:r:path:/System/Library/PrivateFrameworks/VideoProcessing.framework/VideoProcessing
softlink:r:path:/System/Library/PrivateFrameworks/VideoProcessing.framework/VideoProcessing
softlink:r:path:/System/Library/PrivateFrameworks/VideoProcessing.framework/VideoProcessing
softlink:r:path:/System/Library/PrivateFrameworks/BarcodeSupport.framework/BarcodeSupport
softlink:r:path:/System/Library/PrivateFrameworks/VideoProcessing.framework/VideoProcessing
softlink:r:path:/System/Library/PrivateFrameworks/VideoProcessing.framework/VideoProcessing
softlink:r:path:/System/Library/PrivateFrameworks/VideoProcessing.framework/VideoProcessing
VNRecognizedBodyPointsSpecifier
VNSaliencyHeatmapBoundingBoxGenerator
VNSaliencyAHeatmapBoundingBoxGenerator
VNSaliencyOHeatmapBoundingBoxGenerator
VNCreateNeuralHashprintRequestConfiguration
VNCreateNeuralHashprintRequest
VNImageIdealImageSizeProviding
NSObject
Revisioning
VNDetectHumanHeadRectanglesRequest
VNFaceQualityGenerator
VNDetectScreenGazeRequestConfiguration
VNDetectScreenGazeRequest
VNFaceObservationAccepting
CVML_Error
VNANFDMultiDetectorANODv4
VNClusteringLogger
VNSuggestionsLogger
VNGreedyClusteringReadOnly
VNClusteringCancelling
VNClusteringReadOnly
VNGreedyClusteringReadWrite
VNClusteringWritable
VNFaceAnalyzerMultiDetectorBase
VNClustererContextBase
VNClustererReadOnlyContext
VNClustererModelQuerying
VNClustererReadWriteContext
VNClustererModelBuilding
VNClassRegistrar
VNHomographyTrackerState
ICResultDelegate
ICFlowControl
VNHomographyTracker
VNAnimalprintDetectorRevision1
VN5xRo0q9Wz9Io02mmbtoLsConfiguration
VN6kBnCOr2mZlSV6yV1dLwB
VNImageAnalyzerBasedDetector
_VNRequestForensicsRequestAndErrorTuple
_VNRequestForensicsRequestAndObservationsCacheKeyTuple
_VNRequestForensicsParentChildRequests
VNRequestForensics
LKTMetalContext
VNObjectAtPointDetectorRevision1
VNError
VNFaceDetectorRevision2
VNClassifyJunkImageRequestConfiguration
VNClassifyJunkImageRequest
VNHumanBodyPoseObservation
VNCRImageReaderDetector
VNObjectTrackerLegacyFaceCore
VN1JC7R3k4455fKQz0dY1VhQ
VNHomographicImageRegistrationRequest
VNSceneClassificationRequestConfiguration
VNSceneClassificationRequest
VNClassifyMemeImageRequest
VNRequestSpecifier
VNRequestSpecifying
VNRequestClassProviding
VNRequestRevisionProviding
NSSecureCoding
NSCoding
NSCopying
VNBlurSignature
VNBlurMeasure
VNTrackingRequest
VNDetectTrajectoriesRequestConfiguration
VNDetectTrajectoriesRequest
VNMetalContext
VNDetector
VNDetectorKeyProviding
VNClassCodeProviding
Vision
VNClassifyPotentialLandmarkRequestConfiguration
VNClassifyPotentialLandmarkRequest
VNImageAnalyzerCompoundRequestGroupingConfiguration
VNImageAnalyzerCompoundRequestGroupingConfigurations
VNImageAnalyzerCompoundRequestConfiguration
VNImageAnalyzerCompoundRequest
VNFaceRegionMap
VNAnimalObservation
VNPersonSegmentationGeneratorSemantics
VNANEProcessingDevice
VNRuntimeUtilities
VNEntityIdentificationModelTrainingData
VNEntityIdentificationModelTrainedModelDataProvider
VNEntityIdentificationModelDataSource
VN4nFZhnOcBOiJmeVWzBWsv
VNCanceller
VNFaceLandmarkDetector
VNFaceAnalyzerCompoundRequestConfiguration
VNFaceAnalyzerCompoundRequestConfigurationGroups
VNFaceAnalyzerCompoundRequest
VNFaceObservationAcceptingInternal
VNFaceAnalyzerFaceObservationGrouping
VNImageBufferManager
VNImageSourceManager
VNImageBuffer
VNSequencedRequestSupporting
VNCreateTorsoprintRequestConfiguration
VNCreateTorsoprintRequest
VNDetectedObjectObservationAccepting
VNCRImageReaderForDocumentsDetector
_VNWeakSessionsCollection
VNFrameworkManager
VNMTLDeviceWisdomParametersProviding
VNLegacyForcedCleanupImplementing
VNObjectTrackerRevision2
VNMutablePersonsModel
VNPersonsModelDataDelegate
VNPoint
VNRequest
VNRequestConfiguration
VNSizeRange
VNSupportedImageSize
VN5kJNH3eYuyaLxNpZr5Z7ziConfiguration
VN5kJNH3eYuyaLxNpZr5Z7zi
VNFaceTorsoprint
VNAnimalprintDetectorBase
VNFaceDetectorRevision1
 0$1
VNScreenGazeFaceObjectState
VNScreenGazeState
VNMomentProcessor
VNMPClusteringTreeNodeWrapper
NSFastEnumeration
VNEntityIdentificationModelPrint
VNEntityIdentificationModelObservation
VNGenerateAttentionBasedSaliencyImageRequestConfiguration
VNGenerateAttentionBasedSaliencyImageRequest
VNEspressoDetectedObject
VNMutableEntityIdentificationModel
VNEntityIdentificationModelTrainingDataDelegate
VNVYvzEtX1JlUdu8xx5qhDIConfiguration
VNVYvzEtX1JlUdu8xx5qhDI
VNDetectedPoint
VNRecognizedPoint
VNFaceprint
VNSerializingInternal
SaliencyExtrema
VNSaliencyImageObservation
VNImageSaliencyObservation
VNBrightnessDetector
VNScreenGazeDetector
VNClassifyImageAestheticsRequestConfiguration
VNClassifyImageAestheticsRequest
VNRectangleTracker
VNBarcodeObservation
VNDataDetectorSupporting
VNDocumentSegmentationDetector
VNDetectFaceGazeRequestConfiguration
VNDetectFaceGazeRequest
VNSmartCamClassifier
VNRecognizeObjectsRequestConfiguration
VNRecognizeObjectsRequest
VNFaceExpressionDetector
VNSceneprint
VNSceneFeaturePrint
VNDetectTextRectanglesRequestConfiguration
VNDetectTextRectanglesRequest
_VNPersonsModelDataSourceBasedDataProvider
VNPersonsModelFaceModelDataProvider
VNPersonsModel
VNPersonsModelInformation
VNPersonsModelReadOptions
VNPersonsModelConfiguration
VNPersonsModelPrediction
VNPersonsModelWriteOptions
VNPersonsModelAdditions
VNClassifyImageRequestConfiguration
VNClassifyImageRequest
VNImageRegistrationRequest
VNFaceAttributeCategory
VNObjectCloning
VNFaceAttributes
VNMTLDeviceWisdomParameters
VNCreateDetectionprintRequestConfiguration
VNCreateDetectionprintRequest
VNWarningRecorder
VNDetectionprintObservation
VNPersonSegmentationGenerator
VNSmartCamprint
VNImageSignature
VNFaceAnalyzerMultiDetector
VNEntityIdentificationModelWriteOptions
VNMPUtils
VNOperationPointsProvider
VNOperationPointsProviding
VNRecognizeSportBallsRequest
VNFaceSegmentGenerator
VNVideoProcessorRequestConfigurationPopulating
VNVideoProcessorCadence
VNVideoProcessorFrameRateCadence
VNVideoProcessorTimeIntervalCadence
VNVideoProcessorRequestProcessingOptions
VNVideoProcessor
VNRecognizedPointsObservation
VNHumanPoseDetector
VNEntityIdentificationModelConfiguration
VNSingleHeadSceneprintGenerator
ShotflowDetector
ShotflowDetectorANFDv1
ShotflowDetectorANODBase
ShotflowDetectorANFDv2
ShotflowDetectorANODv3
ShotflowDetectorANODv4
VNANFDMultiDetectorANODv3
VNFaceDetectorPrivateRevisionLegacyFaceCore
VNEspressoModelClassifier
VNDetectBarcodesRequest
VNDetectBarcodesRequestConfiguration
VNImageNeuralHashprintObservation
VNTrackerManager
VNFaceAnalyzerMultiDetectorFPrev3_1FArev1_3_MD3
VNEntityIdentificationModelPrediction
VNGenerateImageFeaturePrintRequestConfiguration
VNGenerateImageFeaturePrintRequest
VNSmartCam5GatingDetector
VNDetectHumanHandPoseRequestConfiguration
VNDetectHumanHandPoseRequest
VNHumanHandPoseObservation
ANFDDetectedObject
VNMPImageData
_VNUnspecifiedOperationPoints
VNOperationPoints
LKTOpticalFlowGPU
VNNOPRequestConfiguration
VNNOPRequest
VNDetectFaceLandmarksRequestConfiguration
VNDetectFaceLandmarksRequest
VNImageprint
VNSerializing
VNOriginatingRequestSpecifierProviding
VNFaceGeometryEstimator
VNMetalProcessingDevice
VNCIFilter
VNCIContrastFromAverageColorFilter
VNCIContrastWithPivotColorFilter
VNEspressoModelImageprint
VNFaceAnalyzerMultiDetectorFPrev3_1FArev1_3_MD2
VNImageAestheticsObservation
VNContoursObservation
VNTrajectoryRequestState
VNTrajectoryProcessor
VNFaceRegionMapGenerator
VNObservation
VNDetectedObjectObservation
VNFaceObservation
VNImageAlignmentObservation
VNImageTranslationAlignmentObservation
VNImageHomographicAlignmentObservation
VNImageScoreObservation
VNImageprintObservation
VNImageBlurObservation
VNImageBrightnessObservation
VNClassificationObservation
VNRecognizedObjectObservation
VNPixelBufferObservation
VNCoreMLFeatureValueObservation
VNRectangleObservation
VNHorizonObservation
VNCluster
VNClusterObservation
VNFeaturePrintObservation
VNSceneObservation
VNSmartCamObservation
VNRecognizedTextObservation
VNTrajectoryObservation
_VNTextObservationCharacterBox
VNTextObservation
VNOpticalFlowObservation
VNObservationAdditions
VNHorizonDetector
VNDetectFacePoseRequest
VNImageBasedRequestConfiguration
VNImageBasedRequest
VNDetectedObjectObservationAcceptingInternal
VNVersionParser
VNCreateAnimalprintRequest
VNHeatMapExtrema
VNHeatMapUtilities
VNGenerateImageSaliencyRequestConfiguration
VNGenerateImageSaliencyRequest
VNRecognizeAnimalsRequest
VNANERuntimeDirectProcessingDevice
VNHomeAppFaceAnalyzerMultiDetector
VNTorsoprintGeneratorPrivateRevision3MD2HumanDetectorBased
VNDetectorCache
VNDetectorReleasing
VNDetectorProviding
VNHumanBodyPoseDetector
VNEntityIdentificationModelTrainedModel
VNEntityIdentificationModelTrainedModelAdditions
VNCVPixelBufferConversionHelpers
VNContoursDetector
VNClassifyFaceAttributesRequest
VNGeneratePersonSegmentationRequestConfiguration
VNGeneratePersonSegmentationRequest
VNSequenceRequestHandler
VNPersonsModelFaceModel
VNPersonsModelFaceModelAdditions
VNHomeAppFaceAnalyzerMultiDetectorFPrev3_1FArev1_3_MD3
VNEntityIdentificationModelInformation
VNHumanHandPoseDetector
VNDetectHumanRectanglesRequestConfiguration
VNDetectHumanRectanglesRequest
VNAnimalprint
VNMPImageGrouping
VNEspressoResources
VNEspressoHelpers
VNPersonSegmentationGeneratorLearnedMatting
VNTorsoprintGeneratorPrivateRevision3MD4HumanDetectorBased
VNRecognizeAnimalHeadsRequest
VNImageRegistrationDetector
VNDetectObjectAtPointRequestConfiguration
VNDetectObjectAtPointRequest
LKTOpticalFlowCPU
VNDetectionprintTensor
VNDetectionprint
VNDetectFace3DLandmarksRequest
VNRecognizedPointsSpecifier
VNFaceLandmarkDetectorRevision1
VNFaceAnalyzerMultiDetectorFPrev3FArev2
VNJunkIdentifier
VNdGg5skzXHSAENO6T3enHEConfiguration
VN6Mb1ME89lyW3HpahkEygIG
VNRectangleDetector
VNCPUProcessingDevice
VNTorsoprintGeneratorBase
VNDetectDocumentSegmentationRequest
VNImageBlurScoreRequestConfiguration
VNImageBlurScoreRequest
VNFaceDetector
VNFaceLandmarkRegion
VNFaceLandmarkRegion2D
VNFaceLandmarkRegion3D
VNFaceLandmarks
VNFaceLandmarks2D
VNFaceLandmarks3D
VNTorsoprintGeneratorRevision1
VNValidationUtilities
VNFaceLandmarkDetectorRevision3
VN1vLyVSh30UQ26TGBoV8MHv
VNBlacklist
CVMLFaceprint_LegacySupportDoNotChange
CVMLObservation_LegacySupportDoNotChange
CVMLImageprintObservation_LegacySupportDoNotChange
MPImageDescriptor_LegacySupportDoNotChange
VNTrackLegacyFaceCoreObjectRequest
VNTorsoprint
VNMLFeatureProvider
MLFeatureProvider
VNCoreMLModel
VNCoreMLTransformer
VNSceneTaxonomyOperationPoints
VNFaceLegacyFaceCore
VNSmartCam5CompoundRequestGroupingConfiguration
VNSmartCam5CompoundRequest
VNImageClassifier
VNCreateImageprintRequestConfiguration
VNCreateImageprintRequest
ParabolaDetection
VNPersonSegmentationGeneratorFast
VNDetectHumanBodyPoseRequestConfiguration
VNDetectHumanBodyPoseRequest
VNOpticalFlowGenerator
VNStatefulRequestConfiguration
VNStatefulRequest
VNFaceScreenGaze
VNFaceSegments
VNFaceAnalyzerMultiDetectorFArev2_CameraLightweight
VNObjectTracker
VNModelFileImpl
VNModelFile
VNModelFilesCache
VNSession
VNRequestWarming
VNTrackerProviding
VNDetectorCacheDelegate
_VNGlobalSession
VNWeakSessionWrapper
VNBoundingCircleAlgorithm
VNContourAreaCalculationAlgorithm
VNContourPerimeterAlgorithm
VNGeometryUtils
VNMPImageDescriptor
VNANFDMultiDetectorANFDv2
VNGenerateFaceSegmentsRequestConfiguration
VNGenerateFaceSegmentsRequest
VNRecognizeFoodAndDrinkRequest
VNDetectFaceRectanglesRequestConfiguration
VNDetectFaceRectanglesRequest
VNRecognizeDocumentsRequestConfiguration
VNRecognizeDocumentsRequest
VNDocumentObservationsAccepting
VNRequestProgressProviding
VNDetectFaceCaptureQualityRequestConfiguration
VNDetectFaceCaptureQualityRequest
VNVector
VNTranslationalImageRegistrationRequest
VNCreateSmartCamprintRequestConfiguration
VNCreateSmartCamprintRequest
_VNImageAnalyzerMultiDetectorSceneOperationPointsProvider
VNImageAnalyzerMultiDetector
_VNImageAnalyzerMultiDetectorSceneOperationPointsCache
VNDetectContoursRequestConfiguration
VNDetectContoursRequest
VNRecognizeDocumentElementsRequestElementConfiguration
VNRecognizeDocumentElementsRequestConfiguration
VNRecognizeDocumentElementsRequest
VNTorsoprintGeneratorHumanDetectorBased
VNCreateFaceRegionMapRequest
VNPersonsModelMigration
CCCharBoxContext
CCTextDetector
VNEntityIdentificationModelReadOptions
VNObjectTrackerRevision1
VNObservationsCache
VNEspressoModelFileBasedDetector
VNRecognizeTextRequestConfiguration
VNRecognizeTextRequest
VNRecognizedText
VNContour
ShotflowDetection
VNDetectRectanglesRequestConfiguration
VNDetectRectanglesRequest
VNReadOnlyPersonsModel
VNPersonsModelDataSource
VNCreateSceneprintRequestConfiguration
VNCreateSceneprintRequest
VNMemeClassifier
VNTorsoprintGeneratorPrivateRevision3MD1HumanDetectorBased
VNRecognizedHandPointsSpecifier
VNFaceLandmarkDetectorDNN
VNRequestPerformer
VNRequestCancelling
VNIdentifyJunkRequest
VNHomographicImageRegistrationDetector
VNANFDMultiDetectorOriginalRequestInfo
VNANFDMultiDetector
6`!`
VNClassificationCustomHierarchy
_VNImageAnalyzerMultiDetectorClassificationCustomHierarchy
VNFaceGaze
VNProcessingDevice
VNAlignFaceRectangleRequestConfiguration
VNAlignFaceRectangleRequest
VN3XKGTKNBvy6h4RFtpxLyW
VNClustererOptions
VNClustererQueryOptions
VNClustererBuilderOptions
VNClustererQuery
VNClustererBuilder
VNDocumentObservation
VNDataDetectorResult
VNRecognizedTextBlockObservation
VNRecognizedTextBlock
VNCoreMLRequestConfiguration
VNCoreMLRequest
VNMPContext
VNRPNTrackerEspressoModelCacheManager
VN6Ac6Cyl5O5oK19HboyMBR
VN6B8mkraBUpwUqskMYPtS3
VNFaceAnalyzerMultiDetectorFPrev2FArev1
_VNEntityIdentificationModelDataSourceBasedTrainedModelDataProvider
VNEntityIdentificationModel
VNHumanObservation
ShotflowNetwork
ShotflowNetworkANFDv1
ShotflowNetworkANODBase
ShotflowNetworkANFDv2
ShotflowNetworkANODv3
ShotflowNetworkANODv4
VNDetectFaceExpressionsRequest
VNBrightnessMeasure
VNHomeAppFaceAnalyzerMultiDetectorBase
VNEntityIdentificationModelAdditions
VNTrackRectangleRequest
LKTOpticalFlow
VNCreateFaceTorsoprintRequestConfiguration
VNCreateFaceTorsoprintRequest
VNFaceLandmarkDetectorRevision2
VNCreateFaceprintRequestConfiguration
VNCreateFaceprintRequest
VNImageSignatureDetector
VNTrackObjectRequest
VNFaceBBoxAligner
VNTracker
VNImageExposureScoreRequest
VNSmartCamCombinedAestheticsAndSaliencyDetector
VNCompoundRequest
VNUniqueObservationClassCompoundRequest
VNHomologousObservationClassCompoundRequest
VNGenerateOpticalFlowRequest
VNReadOnlyEntityIdentificationModel
VNFaceGazeDetector
VNANERuntimeProcessingDevice
VNRequestPerformingContext
VNImageBufferProviding
VNObjectBasedSaliencyGenerator
VNTrackHomographyRequestConfiguration
VNTrackHomographyRequest
VNANFDDetectorCompoundRequestConfiguration
VNANFDDetectorCompoundRequestConfigurationGroups
VNANFDDetectorCompoundRequest
VNGenerateObjectnessBasedSaliencyImageRequestConfiguration
VNGenerateObjectnessBasedSaliencyImageRequest
VNImageRegistrationSignature
VNImageRegistration
VNPersonsModelData
VNBlurDetector
VNImageprintGenerator
VNTargetedImageRequest
VNTorsoprintGeneratorFaceBased
VNDetectionprintGenerator
VNTorsoprintGeneratorPrivateRevisionMD1
VNCircle
VNImageRequestHandler
VNDetectHorizonRequest
objectForKey:
count
objectAtIndex:
cStringUsingEncoding:
stringWithUTF8String:
dictionaryWithContentsOfFile:
setObject:forKey:
initWithAPI:properties:
setParameter:to:
setCurrentContext:
_orderedPersonKeypoints
initWithVCPPersonObservation:originatingRequestSpecifier:
hash
isEqual:
availableGroupKeys
pointKeyGroupLabelsMapping
populatedMLMultiArrayAndReturnError:
encodeWithCoder:
initWithCoder:
.cxx_destruct
failWithError:
decodeObjectOfClasses:forKey:
initWithObjects:
encodeObject:forKey:
stringWithFormat:
numberWithInt:
intValue
objectAtIndexedSubscript:
dataPointer
initWithShape:dataType:error:
arrayWithObjects:count:
numberWithUnsignedInteger:
dictionaryWithObjects:forKeys:count:
isEqualToArray:
copy
addObject:
isEqualToString:
initWithCapacity:
keypoints
supportsSecureCoding
calculateSaliencyBoundingBoxesForDetectorType:pixelBuffer:configurationOptions:originatingRequestSpecifier:regionOfInterest:warningRecorder:error:
recordDefaultConfigurationOptionsInDictionary:
configurationOptionKeysForDetectorKey
espressoModelInputImageDimensionsBlobNameForConfigurationOptions:
networkRequiredInputImagePixelFormatForConfigurationOptions:
inputImageAspectRatioHandlingForConfigurationOptions:
removeObject:
mutableCopy
setObject:forKeyedSubscript:
_observationsForOneComponent32FloatPixelBuffer:options:regionOfInterest:error:
_createScaledOneComponent32FloatPixelBufferFromImageBuffer:options:error:
processWithOptions:regionOfInterest:warningRecorder:error:progressHandler:
imageWithCVPixelBuffer:
UTF8String
espressoModelFileNameForConfigurationOptions:
T@"NSArray",R
supportedImageSizeSet
TQ,R
T#,R
T@"NSString",R,C
debugDescription
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
superclass
description
defaultProcessingDeviceForRevision:
configurationClass
warmUpSession:error:
results
T@"NSArray",R,C,D
internalPerformRevision:inContext:error:
_detectorAndOptions:loadedInSession:error:
revisionAvailability
dependencyProcessingOrdinality
descriptionForPrivateRevision:
supportedPrivateRevisions
keyForDetectorWithConfigurationOptions:
_mFaceQualityPredictor
completeInitializationForSession:error:
.cxx_construct
numberWithFloat:
Tq,N,V_temporalSmoothingFrameCount
_temporalSmoothingFrameCount
initWithRequestClass:
copyWithZone:
temporalSmoothingFrameCount
setTemporalSmoothingFrameCount:
Tq,N
inputFaceObservations
T@"NSArray",C,N
_state
setInputFaceObservations:
init
initWithCompletionHandler:
applyConfigurationOfRequest:
resultsAreAssignedWithOriginatingRequestSpecifier
willAcceptCachedResultsFromRequestWithConfiguration:
addObjectsFromArray:
dependentRequestCompatibility
compatibleRevisionForDependentRequestOfClass:beingPerformedByRevision:
createNSErrorWithStatus:andMessage:
createNSExceptionWithStatus:andMessage:
exceptionWithName:reason:userInfo:
localizedStringForKey:value:table:
mainBundle
errorWithDomain:code:userInfo:
T@"NSDictionary",R
detectorClass
detectedObjectClassToRequestKey
detectedObjectRequestKeyToRequestInfo
recognizedAnimalHeadObjectClassToAnimalHeadCategoryName
knownAnimalHeadIdentifiers
recognizedSportBallObjectClassToSportBallCategoryName
knownSportBallIdentifiers
allValues
initWithFormat:
updateRuntimeParametersFromOptions:error:
processDetectedObject:originatingRequestSpecifier:objectBoundingBox:imageBuffer:warningRecorder:detectedObjectResults:error:
T@"NSURL",R,V_logFolderURL
T@"NSURL",R,V_logFileURL
TB,R,V_logEnabled
T@"NSString",R,V_fileNameBase
_logEnabled
_logFolderURL
_logFileURL
_fileNameBase
initWithOptions:logEnabled:logFileNameBase:
initWithOptions:logEnabled:
resetFileNameURLWithCurentDateTime
logString:
logClusterMap:level:
logClusterMapL0:
logClusterLookupMapL0:
logClusterMapL1:
logClusterLookupMapL1:
logFolderURL
logFileURL
logEnabled
fileNameBase
appendFormat:
padStringWithSpaces:toSize:
appendString:toLogFile:
path
URLByAppendingPathComponent:
currentDateTime
isLogEnabled
stringFromDate:
date
setDateFormat:
setLocale:
localeWithLocaleIdentifier:
replaceCharactersInRange:withString:
insertString:atIndex:
stringWithCapacity:
stringWithString:
closeFile
writeData:
dataUsingEncoding:
stringByAppendingString:
seekToEndOfFile
writeToFile:atomically:encoding:error:
fileHandleForUpdatingAtPath:
fileExistsAtPath:isDirectory:
stringByDeletingLastPathComponent
defaultManager
boolForKey:
standardUserDefaults
logInputFaceIdsWithFlags:
logSuggestons:description:
logAllSuggestons:
logFilteredByInputQuerySuggestons:
logConnectedGroups:
logFinalSuggestionsList:
appendString:
deleteCharactersInRange:
objectForKeyedSubscript:
allKeys
_clusteringLogger
_suggestionsLogger
_cacheFolderPath
_algorithmType
_vectorMapReadOnlyFlag
_faceprintRevision
_torsoprintRevision
_ageClassifierFilePath
_ageClassifierBabyThreshold
_ageClassifierKidThreshold
m_ClusteringImpl_const
cancelClustering:
getRepresentativenessForFaces:error:
clustererModelFileNamesFromState:storedInPath:error:
nonGroupedGroupID
suggestionsForClusterIdsWithFlags:affinityThreshold:error:
getClusterState:
getClusteredIds:
getLevel1ClusteredIdsGroupedByLevel0ClustersForFaceId:error:
getDistanceBetweenLevel0ClustersWithFaceId:andFaceId:error:
getDistanceBetweenLevel1Clusters:error:
getAllClustersFromStateAndReturnError:
getClustersForClusterIds:options:error:
getDistances:to:error:
maximumFaceIdInModelAndReturnError:
_parseOptions:error:
initializeLogging
initWithOptions:error:
setGreedyClustererFaces_const:
convertUpdatePairsToClusters:
getLevel0ClusteredIdsForFaceId:error:
numberWithLongLong:
unsignedIntegerValue
addFaceObservations:toFaceDescriptorBuffer:
dictionary
enumerateObjectsUsingBlock:
unsignedLongValue
firstObject
minusOrderedSet:
orderedSetWithCapacity:
longLongValue
unsignedIntValue
dataWithBytes:length:
isEqualToSet:
allObjects
minusSet:
unionSet:
setWithObject:
containsObject:
dictionaryWithCapacity:
arrayWithObject:
bytes
localizedDescription
fileURLWithPath:
boolValue
addFaceObservations:withGroupingIdentifiers:toFaceDescriptorBuffer:
addPersonData:withGroupingIdentifiers:toFaceDescriptorBuffer:
lastPathComponent
filteredArrayUsingPredicate:
predicateWithBlock:
getUUIDBytes:
initWithUUIDBytes:
m_ClusteringImpl
getClustersWithOptions:error:
_cancellableUpdate:facesToMove:requestRevision:
numberOfImageChannels
modelVersionForOptions:
detectorClassForConfigurationOptions:error:
_mMultiHeadedFaceClassifier
_addFaceAnalysisResultsFromMap:toFaceAttributeObject:forOriginatingRequestSpecifier:
_saveFaceprint:toFaceObservation:options:error:
_isFaceprintJunk:
_saveFaceAttributes:toFaceObservation:options:error:
_type
_threshold
_torsoThreshold
_cacheDirectoryPath
_readOnly
_faceprintRequestRevision
_torsoprintRequestRevision
_checkInitInputs:cachePath:checkType:requestRevision:error:
initWithType:cachePath:state:readOnly:threshold:requestRevision:error:
initWithType:cachePath:state:readOnly:threshold:requestRevision:torsoprintRequestRevision:error:
initWithType:cachePath:state:readOnly:threshold:torsoThreshold:requestRevision:error:
initWithType:cachePath:state:readOnly:threshold:torsoThreshold:requestRevision:torsoprintRequestRevision:error:
_createGreedyClusterer:state:error:
_initializeGreedyClustererOptions:
numberWithBool:
_clusterer
representativenessForFaces:error:
distanceBetweenFacesWithFaceprint:andFaceprint:error:
distanceBetweenFacesWithFaceObservation:andFaceObservation:error:
allClusteredFaceIdsAndReturnError:
clusteredFaceIdsForClusterContainingFaceId:error:
getAllClustersAndReturnError:
l1ClusteredFaceIdsGroupedByL0ClustersForClustersContainingFaceIds:error:
distanceBetweenClustersWithFaceId:andFaceId:error:
distanceBetweenLevel1Clusters:error:
suggestionsForClustersWithFaceIds:affinityThreshold:canceller:error:
initWithType:cachePath:state:threshold:requestRevision:error:
initWithType:cachePath:state:threshold:requestRevision:torsoprintRequestRevision:error:
initWithType:cachePath:state:threshold:torsoThreshold:requestRevision:error:
initWithType:cachePath:state:threshold:torsoThreshold:requestRevision:torsoprintRequestRevision:error:
updateModelByAddingFaces:canceller:error:
updateModelByAddingFaces:withGroupingIdentifiers:canceller:error:
updateModelByRemovingFaces:canceller:error:
resetModelState:error:
saveAndReturnCurrentModelState:
updateModelByAddingFaces:andRemovingFaces:canceller:error:
updateModelByAddingFaces:withGroupingIdentifiers:andRemovingFaces:canceller:error:
updateModelByAddingPersons:withGroupingIdentifiers:andRemovingPersons:canceller:error:
_updateClustererWithOptions:canceller:error:
classForClassCode:error:
classNameForClassCode:error:
getClassCode:forClass:error:
getClassCode:forClassName:error:
validateRequestClassName:error:
hasSuffix:
hasPrefix:
numberWithUnsignedInt:
initWithUTF8String:
_analysisSession
_analysisSemaphore
_analysisPreRollFramesRemaining
_resultsLock
_transformsAndConfidences
ICReportFrameAnalysis:forPresentationTime:withStats:
ICShouldBeCanceled
ICReportProgress:
dealloc
floatValue
pathForResource:ofType:
TQ,N,V_imageSignatureprintType
TQ,N,V_imageSignatureHashType
T@"VN6Ac6Cyl5O5oK19HboyMBR",C,N,V_inputSignatureprint
inputSignatureprint
_imageSignatureprintType
_imageSignatureHashType
_inputSignatureprint
imageSignatureprintType
setImageSignatureprintType:
setInputSignatureprint:
imageSignatureHashType
setImageSignatureHashType:
T@"VN6Ac6Cyl5O5oK19HboyMBR",C,N
TQ,R,N
newDefaultDetectorOptionsForRequestRevision:session:
initWithImageSignatureprintType:imageSignatureHashType:
initWithImageSignatureprintType:imageSignatureHashType:completionHandler:
resultsSortingComparator
imageSignaturnprintByRunningNeuralHashprintRequest:error:
enumerateIndexesUsingBlock:
modelNameForConfiguration:
inputImageBlobNameForConfiguration:
analysisPixelFormatTypeForConfiguration:
supportedImageSizeSetForOptions:error:
_imageAnalyzer
_networkRequiredInputImageSize
_networkUsesAnisotropicScaling
_cachedSupportedClassificationIdentifiers
inputImageSize
defaultImageCropAndScaleOption
configureImageAnalyzerOptions:error:
analysisTypesForProcessOptions:
observationsForLastAnalysisOfImageAnalyzer:processOptions:originatingRequestSpecifier:error:
providesSceneLabels
sceneLabelsFileName
supportedClassificationIdentifiersAcceptedByBlock:error:
observationsForSceneLabelsFromLastAnalysisOfImageAnalyzer:identifierAcceptingBlock:operationPointsProvider:originatingRequestSpecifier:error:
providesSegmentationLabels
segmentationLabelsFileName
supportsProcessingDevice:
sortUsingSelector:
compare:
T@"VNRequest",R,N,V_request
T@"NSError",R,N,V_error
_request
_error
initWithRequest:error:
request
error
T@"<NSObject><NSCopying>",R,N,V_observationsCacheKey
_observationsCacheKey
initWithRequest:observationsCacheKey:
observationsCacheKey
T@"VNRequest",R,N,V_parentRequest
T@"NSArray",R,C,N,V_orderedChildRequests
_parentRequest
_orderedChildRequests
initWithParentRequest:orderedChildRequests:
parentRequest
orderedChildRequests
componentsJoinedByString:
T@"NSArray",R,C,N
_originalRequests
_orderedRequests
_implicitRequests
_performedRequests
_cachedRequestResults
_checkedCachedResultsOnBehalfOfRequest
_locatedCachedResultsOnBehalfOfRequest
_ledger
_requestToHumanReadableLabelMap
_humanReadableLabelForRequest:
initWithOriginalRequests:
setOrderedRequests:
performingOrderedDependentRequests:onBehalfOfRequest:
performingRequest:
performedRequest:withError:
request:cachedResultsWithObservationsCacheKey:
cachedObservationsWithKey:wereCheckedOnBehalfOfRequest:
cachedObservationsWithKey:wereLocatedOnBehalfOfRequest:
originalRequests
orderedRequests
performedRequests
keyUsedToCacheResultsOfRequest:
requestsThatLookedUpCachedResultsKey:
_childRequestsImplicitlyPerformedOnBehalfOfParentRequest:
requestsImplicitlyPerformedOnBehalfOfRequest:
requestThatProvidedObservationsForRequest:
resultsObtainedFromObservationsCacheForRequest:
strongToStrongObjectsMapTable
T@"<MTLDevice>",R,N,V_device
T@"<MTLCommandQueue>",R,N,V_commandQueue
T@"<MTLLibrary>",R,N,V_library
_device
_commandQueue
_library
initWithDevice:error:
bindPixelBufferToMTL2DTexture:pixelFormat:plane:error:
bindPixelBufferToMTL2DTexture:pixelFormat:textureSize:plane:error:
bindIOSurfaceToMTL2DTexture:pixelFormat:width:height:plane:error:
device
commandQueue
library
newTextureWithDescriptor:iosurface:plane:
setUsage:
texture2DDescriptorWithPixelFormat:width:height:mipmapped:
setBackgroundGPUPriority:
newCommandQueue
newDefaultLibraryWithBundle:error:
metalContextForDevice:error:
makeResourceCoherent:resource:
_tapToBox
errorWithCode:message:
errorWithCode:message:underlyingError:
errorForCancellationOfRequest:
errorForMemoryAllocationFailure
errorForMemoryAllocationFailureWithLocalizedDescription:
errorForInternalErrorWithLocalizedDescription:
errorForInternalErrorWithLocalizedDescription:underlyingError:
errorForInvalidFormatErrorWithLocalizedDescription:
errorForUnsupportedSerializingHeaderVersion:
errorForUnimplementedFunctionWithLocalizedDescription:
errorForUnimplementedMethod:ofObject:
errorForOutOfBoundsErrorWithLocalizedDescription:
errorForInvalidOperationWithLocalizedDescription:
errorForInvalidOperationForRequestClass:revision:
errorForInvalidOperationForRequestSpecifier:
errorForMissingOptionNamed:
errorForInvalidOption:named:
errorForInvalidOption:named:localizedDescription:
errorForInvalidOptionWithLocalizedDescription:
errorForInvalidArgumentWithLocalizedDescription:
errorForInvalidArgument:named:
errorForInvalidModelWithLocalizedDescription:
errorForInvalidModelWithLocalizedDescription:underlyingError:
errorForOperationFailedErrorWithLocalizedDescription:
errorForUnknownErrorWithLocalizedDescription:
errorForGPURequiredByRequest:
errorForUnsupportedProcessingDevice:
errorForUnsupportedConfigurationOfRequest:
errorForUnsupportedRevision:ofRequest:
errorForUnsupportedRevision:ofRequestClass:
errorForUnsupportedRequestClassName:
errorForUnsupportedRequestSpecifier:
errorForDataUnavailableWithLocalizedDescription:
errorForDataUnavailableWithLocalizedDescription:underlyingError:
errorForUnavailableSession
errorForEspressoReturnStatus:localizedDescription:
errorForEspressoErrorInfo:localizedDescription:
errorForFailedEspressoPlan:localizedDescription:
errorForCVReturnCode:localizedDescription:
errorForOSStatus:localizedDescription:
logInternalError:
VNAssert:log:
localizedFailureReason
code
dictionaryWithObjectsAndKeys:
stringByAppendingFormat:
_faceDetector
_faceBBoxAligner
_preferBackgroundProcessing
purgeIntermediates
removeObjectAtIndex:
setObject:atIndexedSubscript:
initWithObjectsAndKeys:
TQ,N,V_imageCropAndScaleOption
_imageCropAndScaleOption
imageCropAndScaleOption
setImageCropAndScaleOption:
TQ,N
_applicableDetectorAndOptions:loadedInSession:error:
supportedIdentifiersAndReturnError:
knownClassificationsForRevision:error:
T@"NSArray",R,C
availableJointNames
availableJointsGroupNames
recognizedPointForJointName:error:
recognizedPointsForJointsGroupName:error:
_imageReaderInitializationOptionsForCreationOptions:error:
imageReaderRecognitionOptionsForProcessOptions:
supportedLanguagesForProcessOptions:error:
supportedLanguagesForOptions:revision:error:
addEntriesFromDictionary:
_imageReader
cachedImageReader
setCachedImageReader:
isCRImageReaderViableAfterError:
newImageReaderAndReturnError:
_observationsForImageReaderOutput:requestRevision:error:
domain
resultsForPixelBuffer:options:error:
resultsForPixelBuffer:roi:options:error:withProgressHandler:
smallestImageSizeForTextWithRelativeHeight:originalImageSize:
doubleValue
candidates
stringValue
arrayWithCapacity:
setOutputObjectTypes:
_detector
_detectOptions
_extractOptions
isResettable
setTrackedObjects:inFrame:error:
trackInFrame:error:
reset:
_detectFacesInImage:error:
extractDetailsForFaces:inImage:options:error:
detectFacesInImage:options:error:
initWithCVPixelBuffer:
initWithCGImage:
_convertOptionsToFaceCoreExtractOptions:
_convertOptionsToFaceCoreDetectOptions:
_convertOptionsToFaceCoreSetupOptions:
trackerObservationClass
setValue:forKey:
allowsCachingOfResults
wantsSequencedRequestObservationsRecording
T@"VNSceneObservation",&,N,V_sceneObservation
T@"VNClassificationCustomHierarchy",&,N,V_customHierarchy
TQ,N,V_maximumLeafObservations
TQ,N,V_maximumHierarchicalObservations
_sceneObservation
_customHierarchy
_maximumLeafObservations
_maximumHierarchicalObservations
sceneObservation
setSceneObservation:
customHierarchy
setCustomHierarchy:
maximumLeafObservations
setMaximumLeafObservations:
maximumHierarchicalObservations
setMaximumHierarchicalObservations:
T@"VNSceneObservation",R,&,N
T@"VNClassificationCustomHierarchy",R,C,N
initWithSceneObservation:
initWithSceneObservation:completionHandler:
_errorForUnimplementedSelector:forRevision:
_setCustomHierarchy:
resolvedRevisionDidChangeFromRevision:
defineCustomHierarchy:error:
defineCustomHierarchyWithRelationships:error:
_knownVNImageAnalyzerMultiDetectorSceneLabelsForRevision:requestBackingStore:error:
_imageAnalyzerMultiDetectorLoadedInSession:forRevision:processingDevice:requestBackingStore:appliedDetectorOptions:error:
T@"NSArray",R,N
knownSceneClassifications
knownSceneClassificationsForRevision:error:
archivedDataWithRootObject:requiringSecureCoding:error:
read:maxLength:
initWithLength:
mutableBytes
write:maxLength:
unarchivedObjectOfClass:fromData:error:
streamError
TI,R
_requestClassCode
_requestRevision
_cachedRequestClassName
_cachedRequestClass
requestClassAndReturnError:
requestClassName
requestRevision
TB,R
initWithRequestClass:name:code:revision:
requestClassCode
specifiesRequestClass:revision:
specifiesRequestClassName:revision:
specifiesRequestClass:withAnyRevision:
specifiesRequestClassName:withAnyRevision:
specifiesRequestClass:
specifiesAnyRequestClass:
specifiesRequestClassName:
specifiesAnyRequestClassName:
decodeIntegerForKey:
decodeInt32ForKey:
encodeInteger:forKey:
encodeInt32:forKey:
specifierForRequestClassCode:revision:error:
specifierForRequest:
specifierForRequestClass:revision:error:
specifierForRequestClassName:revision:error:
isSubclassOfClass:
_signatureData
initWithSignatureData:
setSignatureData:
getSignatureData
computeBlurSignatureForGrayscaleImage:error:
computeBlurScore:onGrayscaleImage:andWithRegionOfInterestInImageCoordinates:andRegionOfInterestInsetFactor:error:
computeBlurScore:onGrayscaleImage:insetFactor:error:
computeBlurScore:usingBlurSignature:insetFactor:imageROI:error:
computeEdgeWidthBlurScore:onGrayscaleImage:error:
computeApproximateBlurScore:onGrayscaleImage:sampledPixelsCount:insetFactor:error:
computeApproximateBlurScore:onRGBAImage:sampledPixelsCount:insetFactor:error:
dataWithBytesNoCopy:length:freeWhenDone:
wipe_layers_blobs
initWithPlatform:
set_priority:low_priority_max_ms_per_command_buffer:gpu_priority:
initWithJSFile:context:computePath:
initWithJSFile:binSerializerId:context:computePath:
T@"VNDetectedObjectObservation",&,N,V_inputObservation
TQ,N,V_trackingLevel
lastFrame
TB,N,GisLastFrame,V_lastFrame
_inputObservation
_trackingLevel
_lastFrame
_trackingLevelOptionFromTrackingLevelEnum
setTrackingLevel:
sequencedRequestPreviousObservationsKey
initWithDetectedObjectObservation:
initWithDetectedObjectObservation:completionHandler:
newDefaultRequestInstance
setInputObservation:
inputObservation
populateDetectorProcessingOptions:session:
_resetTrackerIfNeeded:trackerProvider:options:error:
trackingLevel
isLastFrame
setLastFrame:
UUIDString
numberWithUnsignedLong:
frameCVPixelBufferFormatForRequestRevision:
trackerTypeForRequestRevision:error:
raise:format:
Tq,N,V_trajectoryLength
Tf,N,V_objectMinimumNormalizedRadius
Tf,N,V_objectMaximumNormalizedRadius
T{?=qiIq},N,V_targetFrameTime
_objectMinimumNormalizedRadius
_objectMaximumNormalizedRadius
_trajectoryLength
_targetFrameTime
trajectoryLength
setTrajectoryLength:
objectMinimumNormalizedRadius
setObjectMinimumNormalizedRadius:
objectMaximumNormalizedRadius
setObjectMaximumNormalizedRadius:
targetFrameTime
setTargetFrameTime:
Tq,R
Tf,N
T{?=qiIq},N
_trajectoryProcessor
initWithFrameAnalysisSpacing:trajectoryLength:completionHandler:
setobjectMaximumNormalizedRadius:
minimumObjectSize
setMinimumObjectSize:
maximumObjectSize
setMaximumObjectSize:
initWithBytes:objCType:
setsTimeRangeOnResults
T@"<MTLDevice>",R,V_metalDevice
T@"NSDictionary",R,V_wisdomParams
TB,R,V_useGPU
_useGPU
_metalDevice
_wisdomParams
initWithMetalDevice:
metalDevice
wisdomParams
useGPU
name
T@"NSObject<OS_dispatch_queue>",&,N,V_synchronizationQueue
T@"NSDictionary",R,C,V_configurationOptions
T@"VNMetalContext",R,N,V_metalContext
T@"NSObject<OS_dispatch_queue>",R,N,V_processingQueue
TQ,R,N,V_backingStore
_configurationOptions
_processingQueue
_metalContext
_backingStore
_synchronizationQueue
VNClassCode
initWithConfigurationOptions:
canBehaveAsDetectorOfClass:withConfiguration:
shouldBeReplacedByDetectorOfClass:withConfiguration:
warmUpSession:withOptions:error:
processInSynchronizationQueueUsingQualityOfServiceClass:options:regionOfInterest:warningRecorder:error:progressHandler:
currentQueueIsSynchronizationQueue
tracedProcessWithOptions:regionOfInterest:warningRecorder:error:progressHandler:
validateImageBuffer:error:
validatedImageBufferFromOptions:error:
needsMetalContext
newMetalContextForConfigurationOptions:error:
getOptionalCanceller:inOptions:error:
requiredCancellerInOptions:error:
validatedProcessingDeviceInOptions:error:
configurationOptions
processingQueue
metalContext
backingStore
synchronizationQueue
setSynchronizationQueue:
detectorName
isReentrant
detectorClassForDetectorType:error:
detectorClassForDetectorType:configuredWithOptions:error:
fullyPopulateConfigurationOptions:
fullyPopulatedConfigurationOptionsWithOverridingOptions:
detectorWithConfigurationOptions:forSession:error:
detectorKeyComponentForDetectorConfigurationOptionKey:value:
supportedImageSizeSetForEspressoModelWithName:inputImageBlobName:analysisPixelFormatType:error:
initWithArray:
removeObjectForKey:
scanCharactersFromSet:intoString:
scanUpToCharactersFromSet:intoString:
isAtEnd
scannerWithString:
uppercaseLetterCharacterSet
substringFromIndex:
vn_decodeSizeForKey:
encodeFloat:forKey:
decodeFloatForKey:
vn_encodeCodingVersion:forKey:
vn_decodeCodingVersionForKey:
vn_encodeCGAffineTransform:forKey:
vn_decodeCGAffineTransformForKey:
vn_encode3x3Matrix:forKey:
vn_decode3x3MatrixForKey:
vn_encode4x4Matrix:forKey:
vn_decode4x4MatrixForKey:
vn_encodeSimdFloat3:forKey:
vn_decodeSimdFloat3ForKey:
vn_encodeTimeRange:forKey:
vn_decodeTimeRangeForKey:
vn_encodeRect:forKey:
vn_decodeRectForKey:
vn_encodePixelBuffer:forKey:
vn_decodePixelBufferForKey:
vn_encodeValidatedConfidence:forKey:
vn_decodeValidatedConfidenceForKey:
vn_encodeValidatedScore:forKey:
vn_decodeValidatedScoreForKey:
scanFloat:
decodeObjectOfClass:forKey:
scanString:intoString:
scanDouble:
encodeDouble:forKey:
decodeDoubleForKey:
vn_encodePoint:forKey:
vn_encodeSize:forKey:
vn_decodePointForKey:
TQ,V_imageCropAndScaleOption
_kindToOriginalRequestsMapping
_detectorConfigurationOptions
_groupingConfigurations
T@"NSString",C,N,V_detectorType
T@"NSDictionary",C,N,V_detectorConfigurationOptions
T@"NSArray",C,N,V_originalRequestConfigurations
_detectorType
_originalRequestConfigurations
detectorType
setDetectorType:
detectorConfigurationOptions
setDetectorConfigurationOptions:
originalRequestConfigurations
setOriginalRequestConfigurations:
_groupingConfiguration
initWithDetectorType:groupingConfiguration:
enumerateKeysAndObjectsUsingBlock:
isEqualToDictionary:
compoundRequestsForOriginalRequests:withPerformingContext:error:
methodForSelector:
T@"NSArray",C,V_regionLabels
_regionMap
_userBBox
_internalAlignedBBox
_deallocateBuffer
_pixelValueToRegionLabelMap
_regionLabels
initWithRequestRevision:regionMap:deallocateBuffer:userBBox:alignedBBox:valueToLabelMap:
getRegionLabels
regionNameAtNormalizedAlignedFaceCoordinate:
regionNameAtImageCoordinate:imageSize:
regionNameAtNormalizedFaceCoordinate:
regionLabels
setRegionLabels:
numberWithUnsignedChar:
numberWithDouble:
unsignedLongLongValue
T@"VNAnimalprint",R,N
_animalprint
animalprint
setAnimalprint:
initWithAnimalprint:confidence:
initWithOriginatingRequestSpecifier:boundingBox:confidence:labels:animalprint:
vn_cloneObject
defaultOriginatingRequestClassNameForRequestRevision:
inputImageBlobName
inputMaskBlobName
outputMaskBlobName
rotateImageToMatchNetworkOrientation
inputMaskRequired
targetsANE
espressoStorageType
object:overridesSelector:
instanceMethodForSelector:
instancesRespondToSelector:
T@"VNRequestSpecifier",R,C,V_entityPrintOriginatingRequestSpecifier
T@"<VNEntityIdentificationModelTrainingDataDelegate>",W,V_delegate
T@"NSDate",R,C,V_lastModificationDate
_maximumEntities
_delegate
_entityPrintOriginatingRequestSpecifier
_entityUniqueIdentifiers
_serialNumberForEntityUniqueIdentifier
_observationsForSerialNumber
_availableSerialNumbers
_lastModificationDate
_lastDataChangeSequenceNumber
trainedModelEntityCount
trainedModelUniqueIdentifierOfEntityAtIndex:
trainedModelIndexOfEntityWithUniqueIdentifier:
trainedModelNumberOfObservationsForEntityAtIndex:
trainedModelObservationAtIndex:forEntityAtIndex:
lastDataChangeSequenceNumberForEntityIdentificationModel:
lastModificationDateForEntityIdentificationModel:
numberOfEntitiesInEntityIdentificationModel:
entityIdentificationModel:uniqueIdentifierOfEntityAtIndex:
entityIdentificationModel:indexOfEntityWithUniqueIdentifier:
entityIdentificationModel:numberOfObservationsForEntityAtIndex:
entityIdentificationModel:observationAtIndex:forEntityAtIndex:
initWithModelConfiguration:
entityCount
uniqueIdentifierOfEntityAtIndex:
indexOfEntityWithUniqueIdentifier:
observationCountForEntityAtIndex:
observationAtIndex:forEntityAtIndex:
addObservations:toEntityWithUniqueIdentifier:error:
removeObservations:fromEntityWithUniqueIdentifier:error:
removeAllObservationsFromEntityWithUniqueIdentifier:error:
removeEntityWithUniqueIdentifier:error:
validateWithCanceller:error:
entityPrintOriginatingRequestSpecifier
delegate
setDelegate:
lastModificationDate
addIndex:
removeAllObjects
removeObjectsInArray:
intersectSet:
removeIndex:
firstIndex
indexOfObject:
initWithIndexesInRange:
_signallingBlock
_lock
_signalled
_releaseSignallingBlock
tryToPerformBlock:usingSignallingBlock:
reset
signalCancellation
wasSignalled
landmarksMeshPartsForConstellation:
allLandmarksPointsIndexesForConstellation:
computeCentroidUsingPoints:indicies:numberOfIndicies:
_faceAttributesPupilRefiner
_requireFaceAttributesPupilRefiner
_modelFilesWereMemmapped
loadRefinersAndReturnError:
calculatePupilLocationAndUpdateLandmarkPoints:
computeLandmarksScoreOnImage:withFaceBoundingBox:andLandmarks:error:
postprocessLandmarkResultsForLandmarks:imageBuffer:outputFace:options:warningRecorder:error:
normalizedFaceBBoxForLandmarks:
detectBlinkOnFaceImage:faceObservation:lumaRec2DInImageCoordinates:landmarks:warningRecorder:error:
T@"NSMutableArray",R,N,V_originalRequests
setDetectorConfigurationOption:value:
setResolvedRevision:
_generalConfigurations
_observationGroupConfigurations
configurationForRequest:withObservationGroup:compoundRequestRevision:
allConfigurations
initWithDetectorType:configuration:
_determineFacesToProcessFrom:outputFacesThatNeedNoProcessing:outputfacesThatNeedAttributes:isFaceprintRequest:isAttributeRequest:
detectionLevel
assignOriginalRequestsResultsFromObservations:obtainedInPerformingContext:
addToGroupingsRequest:withFaceObservations:
getOptionalValidatedInputFaceObservations:clippedToRegionOfInterest:error:
_observationGroupsToRequestMapping
subarrayWithRange:
vn_enumerateObjectsAsSubarraysOfCount:usingBlock:
mainCIContext
mainCIContextMetalDevice
lowPriorityCIContext
lowPriorityCIContextMetalDevice
activeImageBuffers
bufferTableLock
purgeAllCaches
sharedCIContextWithOptions:
unlock
contextWithOptions:
contextWithMTLDevice:options:
lock
purgeCachedRepresentations
nextObject
objectEnumerator
weakObjectsHashTable
manager
_getOrientationLock
_loadSubSample1Lock
_loadSubSample2Lock
_loadSubSample4Lock
_loadSubSample8Lock
_imageSourceSubsample1
_imageSourceSubsample2
_imageSourceSubsample4
_imageSourceSubsample8
_imageURL
_imageData
_orientation
_obtainCreatedCGImageSourceRefAtAddress:forSubSampleFactor:protectedWithUnfairLock:operatingInLowPriority:
T{?={?=qiIq}{?=qiIq}{?=qiIq}},R
_origPixelBuffer
_origCGImage
_pixelBufferReps
_pixelBufferRepsLock
_origCIImage
_passedInCIContext
_origSampleBuffer
_imageSourceManager
_origImageWidth
_origImageHeight
_options
initWithCVPixelBuffer:options:
initWithCVPixelBuffer:orientation:options:
initWithCGImage:options:
initWithCGImage:orientation:options:
initWithCIImage:options:
initWithCIImage:orientation:options:
initWithData:options:
initWithData:orientation:options:
initWithURL:options:
initWithURL:orientation:options:
initWithCMSampleBuffer:options:
initWithCMSampleBuffer:orientation:options:
originalPixelBuffer
originalCGImage
bufferWithWidth:height:format:options:error:
bufferWithWidth:height:format:options:error:pixelBufferRepsCacheKey:
cachedPixelBufferRepresentationForKey:
croppedBufferWithWidth:height:format:cropRect:options:error:
croppedBufferWithWidth:height:format:cropRect:options:error:pixelBufferRepsCacheKey:
cropAndScaleBufferWithWidth:height:cropRect:format:imageCropAndScaleOption:options:error:calculatedNormalizedOriginOffset:calculatedScaleX:calculatedScaleY:
cropAndScaleBufferWithWidth:height:cropRect:format:imageCropAndScaleOption:options:error:calculatedNormalizedOriginOffset:calculatedScaleX:calculatedScaleY:pixelBufferRepsCacheKey:
orientation
timingInfo
width
height
getPixelFocalLengthIfAvailable:
getCameraOpticalCenterIfAvailable:
getCameraIntrinsicsAvailable:
imageProperties
fileURL
processInChunksOfSize:overlapFraction:options:roi:handler:error:
makeClippedRectAgainstImageExtentUsingOriginalRect:
createBufferWithMaxSideLengthOf:andPixelFormat:andOptions:error:
createCroppedBufferWithMaxSideLengthOf:andCropBounds:andPixelFormat:andOptions:error:
augmentedBuffersWithWidth:height:format:options:augmentationOptions:error:
augmentedCroppedBuffersWithWidth:height:format:cropRect:options:augmentationOptions:error:
imageByApplyingCGOrientation:
imageByCroppingToRect:
colorWithRed:green:blue:alpha:
imageByApplyingTransform:
imageByClampingToExtent
filterWithName:
copyColorspaceForFormat:bitmapInfo:
imageWithData:options:
imageWithContentsOfURL:options:
integerValue
_cropImageSourceManager:outBuffer:width:height:format:cropRect:performCrop:options:error:
render:toCVPixelBuffer:bounds:colorSpace:
imageByCompositingOverImage:
imageByClampingToRect:
clearImage
imageByApplyingOrientation:
imageByApplyingTransform:highQualityDownsample:
extent
imageTransformForCGOrientation:
_cropCIImage:outBuffer:width:height:format:cropRect:performCrop:options:error:
imageWithContentsOfURL:
imageWithCGImage:
imageWithCVImageBuffer:
ioSurfaceBackedPixelBufferAttributes
_cropCVPixelBuffer:outBuffer:width:height:format:cropRect:performCrop:options:error:
render:toCVPixelBuffer:
firstObjectCommonWithArray:
createPixelBufferRepsCacheKeyForCropRect:format:width:height:
computeCenterCropRectFromCropRect:inImageSize:calculatedScaleX:calculatedScaleY:
_helpReadOrientationFromOptionsDictionary:
imageWithData:
createDirectoryAtPath:withIntermediateDirectories:attributes:error:
stringByAppendingPathComponent:
callStackSymbols
rangeOfString:options:
rangeOfString:options:range:
substringWithRange:
inputDetectedObjectObservations
setInputDetectedObjectObservations:
_processFaceBasedInputInContext:torsosThatNeedNoProcessing:torsosThatNeedTorsoprints:error:
_determineFacesToProcessFrom:outputFacesThatNeedNoProcessing:outputFacesThatNeedAlignment:outputFacesThatNeedTorsoprints:
_processHumanBodyBasedInputInContext:torsosThatNeedNoProcessing:torsosThatNeedTorsoprints:error:
_determineHumanBodiesToProcessFrom:outputHumanBodiesThatNeedNoProcessing:tputHumanBodiesThatNeedTorsoprints:
arrayWithArray:
documentOutputRegionForImage:options:roi:error:withProgressHandler:
documentWithRegions:title:confidence:imageSize:
recognizeDetectedBlocks:inImage:error:withProgressHandler:
preheatModelsForOptions:revision:error:
_weakSessionWrappers
addSession:droppingWeakZeroedObjects:
allSessionsDroppingWeakZeroedObjects:
removeObjectsAtIndexes:
T@"<NSLocking>",R
T@"NSNotificationCenter",R
_notificationCenter
_detectorAccessingLock
_sessionsAccessLock
_sessions
_wisdomParametersLock
_wisdomParameters
wisdomParameterForMTLDevice:error:
wisdomParameterForMTLDeviceWithName:error:
legacyForcedCleanupWithOptions:
legacyForcedCleanupOfFacePipelineWithLevel:
legacyForcedCleanupOfScenePipelineWithLevel:
legacyForcedCleanupOfSmartCamPipelineWithLevel:
legacyForcedCleanupOfJunkPipelineWithLevel:
_locateDetectorOfClass:configuredWithOptions:inSessions:excludingSession:
notificationCenter
registerSession:
allSessions
detectorAccessingLock
detectorOfClass:configuredWithOptions:forSession:error:
loadedDetectors
releaseMetalDeviceWisdomParameters
postNotificationName:object:userInfo:
serializeRPNTrackingQueue
serializeRPNInitializationQueue
rpnTrackQueue
rpnInitQueue
rpnTrackerInitProcessingQueueName
rpnTrackerTrackProcessingQueueName
rpnTrackerInitModelName
rpnTrackerTrackModelName
_modelData
_faceModel_DO_NOT_ACCESS_DIRECTLY
personsModelDataWasModified:
initWithConfiguration:
_modelWasModified
upToDateFaceModelWithCanceller:error:
_writeVersion1InformationToOutputStream:md5Context:error:
_writeVersion1ConfigurationToOutputStream:md5Context:error:
writeVersion1ToOutputStream:options:md5Context:error:
_writeReadOnlyVersion:toOutputStream:options:md5Context:error:
writeReadOnlyVersion1ToOutputStream:options:md5Context:error:
_getModelWritingImplementation:selector:forVersion:readOnly:
_getModelWritingImplementation:selector:version:forOptions:
writeToStream:options:error:
_writeToUnopenedStream:options:error:
dataWithOptions:error:
writeToURL:options:error:
addFaceObservations:toPersonWithUniqueIdentifier:error:
removeFaceObservations:fromPersonWithUniqueIdentifier:error:
removeAllFaceObservationsFromPersonWithUniqueIdentifier:error:
removePersonWithUniqueIdentifier:error:
initWithURL:append:
propertyForKey:
initToMemory
close
reason
open
enumerateIndexesWithOptions:usingBlock:
initWithIndex:
supportedWriteVersions
enumerateObjectsAtIndexes:options:usingBlock:
setLength:
appendData:
appendBytes:length:
localizedStringFromDate:dateStyle:timeStyle:
configurationFromLoadedObjects:error:
_version1ModelWithObjects:error:
newModelFromVersion:objects:error:
addIndexes:
keyEnumerator
T{CGPoint=dd},R
Td,R,V_x
Td,R,V_y
distanceToPoint:
initWithLocation:
initWithX:y:
location
T@"VNPoint",R
zeroPoint
pointByApplyingVector:toPoint:
distanceBetweenPoint:point:
T@"NSObject<OS_dispatch_semaphore>",&,V_cancellationSemaphore
T@"VNProcessingDevice",R
Td,R
T@"<MTLDevice>",&,N
T@"VNProcessingDevice",C,N
T@"VNRequestSpecifier",R
TB,N
T@"NSArray",R,C,N,V_results
T@?,R,C,N,V_completionHandler
TQ,N,V_revision
_completionHandler
_configuration
_warningRecorder
_canceller
_cancellationTriggered
_cancellationResourcesLock
_cancellationSemaphore
_cancellationQueue
_revision
_serialNumber
_executionNanoseconds
_results
recordWarning:value:
valueForWarning:
_defaultProcessingDevice
serialNumber
configuration
hasCancellationHook
specifier
newDefaultDetectorOptionsForSession:
explicitlyConfiguredProcessingDevice
copyStateOfRequest:
performInContext:error:
validateConfigurationAndReturnError:
internalCancelInContext:error:
setResults:
setResults:assignedWithOriginatingSpecifier:
setSortedResults:
warnings
cancel
cancellerAndReturnError:
cancellationTriggered
cancellationTriggeredAndReturnError:
preferBackgroundProcessing
setPreferBackgroundProcessing:
modelFileBackingStore
setModelFileBackingStore:
preferredMetalContext
setPreferredMetalContext:
usesCPUOnly
setUsesCPUOnly:
metalContextPriority
setMetalContextPriority:
processingDevice
setProcessingDevice:
setDetectionLevel:
maximumProcessingDimensionOnTheLongSide
setMaximumProcessingDimensionOnTheLongSide:
validateImageBuffer:ofNonZeroWidth:andHeight:error:
_setResolvedRevision:
setPrivateRevision:error:
setRevision:error:
setRevision:
revision
resolvedRevision
compatibleRevisionForDependentRequest:
supportedImageSizeSetForDetectorType:
executionNanoseconds
executionTimeInternal
completionHandler
cancellationSemaphore
setCancellationSemaphore:
resolvedRevisionForRevision:
supportsPrivateRevision:
supportsRevision:
resolvedProcessingDevice
null
sortedArrayWithOptions:usingComparator:
defaultRevision
newConfigurationInstance
requestClass
T@"NSIndexSet",R,C
T@"NSIndexSet",R,C,N
initialize
defaultRequestInstanceWarmUpSession:error:
getOptionalObject:ofClass:forKey:inOptions:error:
getRequiredObject:ofClass:forKey:inOptions:error:
getDoubleValue:forKey:inOptions:error:
getDoubleValue:forKey:inOptions:withDefaultValue:error:
getFloatValue:forKey:inOptions:error:
getFloatValue:forKey:inOptions:withDefaultValue:error:
getOptionalArray:forKey:inOptions:withElementsOfClass:error:
_defaultRevisionForBuildVersion:
_introspectionBuiltSupportedRevisions
supportedRevisions
currentRevision
firstSupportedRevisionInOrderedRevisionList:
lastIndex
indexSet
containsIndex:
T#,R,N,V_requestClass
TQ,N,V_resolvedRevision
TQ,N,V_detectionLevel
T@"VNProcessingDevice",&,N,V_processingDevice
T@"VNProcessingDevice",R,C,N
TQ,N,V_metalContextPriority
TB,N,V_preferBackgroundProcessing
TQ,N,V_modelFileBackingStore
TQ,N,V_maximumProcessingDimensionOnTheLongSide
_requestClass
_resolvedRevision
_detectionLevel
_processingDevice
_metalContextPriority
_modelFileBackingStore
_maximumProcessingDimensionOnTheLongSide
_allPropertyNames
allocWithZone:
valueForKey:
TQ,R,N,V_minimumDimension
TQ,R,N,V_maximumDimension
TQ,R,N,V_idealDimension
_minimumDimension
_maximumDimension
_idealDimension
initWithMinimumDimension:maximumDimension:idealDimension:
isAllowedDimension:
minimumDimension
maximumDimension
idealDimension
T@"VNSizeRange",R,N,V_pixelsWideRange
T@"VNSizeRange",R,N,V_pixelsHighRange
TQ,R,N,V_aspectRatioHandling
TI,R,N,V_idealImageFormat
TI,R,N,V_idealOrientation
orientationAgnostic
TB,R,N,GisOrientationAgnostic,V_orientationAgnostic
_cachedCalculatedHash
_orientationAgnostic
_idealImageFormat
_idealOrientation
_pixelsWideRange
_pixelsHighRange
_aspectRatioHandling
initWithIdealFormat:pixelsWideRange:pixelsHighRange:aspectRatioHandling:idealOrientation:orientationAgnostic:
initWithIdealFormat:width:height:orientation:aspectRatioHandling:orientationAgnostic:
isAllowedPixelsWide:pixelsHigh:
pixelsWideRange
pixelsHighRange
aspectRatioHandling
idealImageFormat
idealOrientation
isOrientationAgnostic
decodeBoolForKey:
encodeBool:forKey:
_applicableDetectorLoadedInSession:appliedConfigurationOptions:error:
TQ,N,V_personId
T@"VNFaceprint",R,N,V_faceprint
T@"VNTorsoprint",R,N,V_torsoprint
validFaceprint
TB,R,N,GisValidFaceprint
validTorsoprint
TB,R,N,GisValidTorsoprint
_faceprint
_torsoprint
_personId
initWithData:elementCount:elementType:lengthInBytes:faceprintConfidence:torsoprintConfidence:
initWithData:elementCount:elementType:lengthInBytes:faceprintConfidence:torsoprintConfidence:originatingRequestSpecifier:
initWithFaceprint:torsoprint:
initWithFaceprint:torsoPrint:requestRevision:
initWithFaceprint:torsoPrint:originatingRequestSpecifier:
computeDistance:withDistanceFunction:error:
isValidFaceprint
isValidTorsoprint
initWithState:byteOffset:error:
serializeStateIntoData:startingAtByteOffset:error:
serializeStateAndReturnError:
serializedLength
faceprint
torsoprint
personId
setPersonId:
dataWithLength:
shouldAssumeOriginatingRequestClassForHeaderSerializationVersion:
containsValueForKey:
currentVersion
currentCodingVersion
codingTypesToCodingKeys
currentSerializationVersion
shouldIgnoreLagecyLabelsAndConfidenceForHeaderSerializationVersion:
_petprintGenerator
_useLowPriorityMode
writeToFile:atomically:
dataWithJSONObject:options:error:
numberWithUnsignedLongLong:
stringByDeletingPathExtension
createDirectoryAtURL:withIntermediateDirectories:attributes:error:
array
initWithDevice:andWisdomParams:
_faceObservation
_imageWidth
_imageHeight
_frameIndex
_uuid
_leftPupil
_rightPupil
_screenGazeState
_unalignedFaceBoundingBox
_currentFrame
_faceObjectStates
processInfo
activeProcessorCount
T@"VNMPContext",&,N,V_context
_context
computeClusteringOfImageDescriptors:intoKGroups:error:
computeNaturalClusteringOfImageDescriptors:error:
computeClusteringTreeForImageDescriptors:error:
computeClusteringTreeForImageDescriptors:assumeDescriptorsAreSorted:error:
convertClusterNodesListToDescriptorsList:
performClustersPostprocessing:error:
computeClusteringForClusteringTree:intoKGroups:error:
computeClusteringForClusteringTree:usingThreshold:error:
computeNaturalClusteringForClusteringTree:error:
getKey:fromDictionary:withDefault:
context
setContext:
node
initWithNode:freeNodeOnDealloc:
T^v,V_node
TB,V_freeNodeOnDealloc
_freeNodeOnDealloc
_node
nodeId
descriptor
left
right
distance
avgDistance
leafsCount
getLeafNodes
setNode:
freeNodeOnDealloc
setFreeNodeOnDealloc:
sortImageDescriptorsChronologically:
sortedArrayUsingComparator:
countByEnumeratingWithState:objects:count:
T@"VNRequestSpecifier",R,C
T@"NSData",R
isEquivalentToVNEntityIdentificationModelPrint:
VNEntityIdentificationModelPrintOriginatingRequestSpecifier
VNEntityIdentificationModelPrintElementCount
VNEntityIdentificationModelPrintElementType
VNEntityIdentificationModelPrintByteLength
VNEntityIdentificationModelPrintData
VNEntityIdentificationModelPrintWithOriginatingRequestSpecifier:error:
indexesOfObjectsPassingTest:
objectsAtIndexes:
_detectorLoadedInSession:forRevision:getAppliedDetectorOptions:error:
_smartCamCombinedModelImageSaliencyObservationsForRevision:performedInContext:error:
Tq,V_objectType
T{CGRect={CGPoint=dd}{CGSize=dd}},V_bounds
Tf,V_confidence
_bounds
_confidence
_objectType
initWithObjectType:boundingBox:confidence:
center
objectType
setObjectType:
bounds
setBounds:
confidence
setConfidence:
entityIdentificationModelTrainingDataWasModified:
canCreateModelOfClass:withObjects:error:
modelWithConfiguration:dataSource:error:
newModelForVersion:modelObjects:error:
modelWithConfiguration:error:
_trainingData
Tf,R
initWithLocation:confidence:
T@"NSString",R,C,V_identifier
_identifier
initWithLocation:confidence:identifier:
identifier
Tf,R,N,V_confidence
initWithData:elementCount:elementType:lengthInBytes:requestRevision:
initWithData:elementCount:elementType:lengthInBytes:confidence:requestRevision:
initWithData:elementCount:elementType:lengthInBytes:confidence:originatingRequestSpecifier:
finishDecoding
setClass:forClassName:
initForReadingFromData:error:
serializationMagicNumber
confidenceTypeForOriginatingRequestSpecifier:
emptyFaceprintDataForRevision:
_extrema
_extremeValues
updateExtrema:x:y:
computeRectFromExtremaUsingThreshold:vImage:
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N
_mOriginalImageSize
_mSalientRegion
_mHighlySalientRegion
_mComputeBoundingBoxesLock
_mSalientObjects
initWithOriginatingRequestSpecifier:rawSaliencyImage:originalImageSize:salientObjectBoundingBoxes:
createSaliencyImageAndReturnError:
salientObjectsAndReturnError:
_computeBoundingBoxes
salientObjects
boundingBox
narrowedBoundingBox
getValue:size:
setWithObjects:
_createPixelBufferFromImageBuffer:regionOfInterest:maximumIntermediateSideLength:options:error:
_predictor
_smartCamCombinedModelImageAestheticsClassificationsForRevision:performedInContext:error:
_cornerTrackersImpl
_rectangleTrackingProcessingQueue
isTracking
_parseInputObservations:imageBuffer:error:
_convertCornerObservationsToRectangleObservation:error:
_trackingRectAroundPoint:trackingRectSize:
trackedCorners
T@"NSDictionary",C,N,SsetACBSBarcodeInfo:,V_acbsBarcodeInfo
Tr^{__MRCDescriptor=},N,SsetMRCDescriptor:,V_mrcDescriptor
T@"NSData",R,C,N
T@"NSNumber",R,C,N
T@"NSString",R,C,N,V_symbology
T@"CIBarcodeDescriptor",R,N,V_barcodeDescriptor
T@"NSString",R,C,N
_cachedPayloadStringValue
_cachedPayloadDataValue
_cachedAppClipCodeMetadataValue
_symbology
_barcodeDescriptor
_acbsBarcodeInfo
_mrcDescriptor
getDataDetectorResults:
initWithOriginatingRequestSpecifier:symbology:descriptor:topLeft:bottomLeft:bottomRight:topRight:
initWithOriginatingRequestSpecifier:symbology:descriptor:boundingBox:
setMrcDescriptor:
payloadStringValue
payloadDataValue
appClipCodeMetadataValue
symbology
barcodeDescriptor
acbsBarcodeInfo
setACBSBarcodeInfo:
mrcDescriptor
setMRCDescriptor:
detectedCodeWithBarcodeObservation:
Tf,N,V_gazeHeatMapThreshold
Tf,N,V_minimumFaceDimension
Tf,N,V_commonGazeLocationRadius
_gazeHeatMapThreshold
_minimumFaceDimension
_commonGazeLocationRadius
gazeHeatMapThreshold
setGazeHeatMapThreshold:
minimumFaceDimension
setMinimumFaceDimension:
commonGazeLocationRadius
setCommonGazeLocationRadius:
T@"NSString",R
createClassifierWithDescriptor:classifierAbsolutePath:computePlatform:computePath:labelsFilename:options:
createDescriprorProcessorWithModelPath:nBatch:computePlatform:computePath:options:
classifierResourceTypesToNamesForOriginatingRequestSpecifier:
espressoModelImageprintClass
returnAllResultsOptionKey
createObservationWithDescriptors:forOriginatingRequestSpecifier:
initDumpDebugIntermediates:debugInfo:
TB,V_useImageAnalyzerScaling
Tf,V_modelMinimumDetectionConfidence
Tf,V_modelNonMaximumSuppressionThreshold
_useImageAnalyzerScaling
_modelMinimumDetectionConfidence
_modelNonMaximumSuppressionThreshold
useImageAnalyzerScaling
setUseImageAnalyzerScaling:
modelMinimumDetectionConfidence
setModelMinimumDetectionConfidence:
modelNonMaximumSuppressionThreshold
setModelNonMaximumSuppressionThreshold:
_applicableDetectorAndGetConfigurationOptions:loadedInSession:error:
knownObjectIdentifiersRecognizedByRequestRevision:error:
expressionTypeFromString:
createExpressionAndConfidencesDictionaryFromScores:
createExpressionDetectionDictionaryFromScores:
m_FaceAttributesImpl
T@"NSDictionary",R,C,V_labelsAndConfidence
_labelsAndConfidence
initWithData:elementCount:elementType:lengthInBytes:labelsAndConfidence:requestRevision:
labelsAndConfidence
bundleForClass:
TB,N,V_reportCharacterBoxes
TQ,N,V_algorithm
TQ,N,V_minimumCharacterPixelHeight
TB,N,V_detectDiacritics
TB,N,V_minimizeFalseDetections
T@"NSString",C,N,V_textRecognition
T@"NSString",C,N,V_additionalCharacters
_reportCharacterBoxes
_detectDiacritics
_minimizeFalseDetections
_algorithm
_minimumCharacterPixelHeight
_textRecognition
_additionalCharacters
reportCharacterBoxes
setReportCharacterBoxes:
algorithm
setAlgorithm:
minimumCharacterPixelHeight
setMinimumCharacterPixelHeight:
detectDiacritics
setDetectDiacritics:
minimizeFalseDetections
setMinimizeFalseDetections:
textRecognition
setTextRecognition:
additionalCharacters
setAdditionalCharacters:
T@"NSString",C,N
_detectCreditCardTextWithRequestPerformingContext:requestRevision:error:
_futharkRecognitionLanguage
_detectTextWithRequestPerformingContext:requestRevision:error:
subFeatures
corners
detectFeaturesInBuffer:withRegionOfInterest:error:
setReturnSubFeatures:
setRecognitionLanguage:
setMinimumCharacterHeight:
initWithDimensions:
_personsModel
_dataSource
faceModelPersonsCount
faceModelUniqueIdentifierOfPersonAtIndex:
faceModelIndexOfPersonWithUniqueIdentifier:
faceModelNumberOfFaceObservationsForPersonAtIndex:
faceModelFaceObservationAtIndex:forPersonAtIndex:
initWithPersonsModel:dataSource:
T@"VNPersonsModelConfiguration",R,C,N
_dataSourceAndReturnError:
initWithConfiguration:dataSource:
updateInternalConfigurationWithModelFaceprintRequestRevision:error:
predictPersonFromFaceObservation:limit:canceller:error:
personCount
personUniqueIdentifiers
faceCountForPersonWithUniqueIdentifier:
faceObservationsForPersonWithUniqueIdentifier:error:
trainingFaceObservationsForPersonWithUniqueIdentifier:canceller:error:
indexOfFaceprintObjectFrom:withEquivalentDescriptorTo:
faceCountsForPersonsWithUniqueIdentifiers:
faceCountsForAllPersons
VNPersonsModelFaceprintWithRequestRevision:error:
faceprintRequestRevision
initWithDomain:code:userInfo:
setFaceprintRequestRevision:
_modelClassForKind:error:
versionNumbersEncodedInClass:withMethodNamePrefix:suffix:
supportedReadVersions
_readModelObjectsFromStream:options:actionBlock:progressBlock:modelClass:version:error:
_modelFromStream:options:error:
modelFromStream:options:error:
_modelFromUnopenedStream:options:error:
modelFromData:options:error:
modelFromURL:options:error:
_modelInformationFromUnopenedStream:error:
informationForModelWithData:error:
informationForModelWithURL:error:
readObjectForVersion1Tag:fromInputStream:intoObjectDictionary:md5Context:error:
VNPersonsModelSubdataWithRange:rangeDescriptionProvidingBlock:error:
VNPersonsModelSubdataWithRange:rangeDescription:error:
initWithVersion:lastModificationDate:
TQ,R,N,V_version
T@"NSDate",R,C,N,V_lastModificationDate
_version
version
isEqualToDate:
distantPast
T@"NSIndexSet",C,N,V_acceptableVersions
_acceptableVersions
acceptableVersions
setAcceptableVersions:
setMaximumTrainingFaceprintsPerIdentity:
setMaximumIdentities:
TQ,N,V_maximumIdentities
TQ,N,V_maximumTrainingFaceprintsPerIdentity
TQ,N,V_faceprintRequestRevision
_maximumIdentities
_maximumTrainingFaceprintsPerIdentity
maximumTrainingFaceprintsPerIdentity
maximumIdentities
maximumAllowableFaceprintsPerIdentity
maximumAllowableIdentities
T@"VNFaceObservation",R,N,V_faceObservation
T@"<NSObject><NSCopying><NSSecureCoding>",R,C,N,V_predictedPersonUniqueIdentifier
_predictedPersonUniqueIdentifier
initWithFaceObservation:predictedPersonUniqueIdentifier:confidence:
faceObservation
predictedPersonUniqueIdentifier
TQ,N,V_version
TB,N,V_readOnly
setVersion:
readOnly
setReadOnly:
subdataWithRange:
_applicableDetectorTypeForRevision:error:
_cachedFloatingImageBuffer
_cachedFloatingImageSignature
cachedFloatingImageBufferReturningError:
cachedFloatingImageRegistrationSignatureReturningError:
getReferenceImageBuffer:registrationSignature:forRequestPerformingContext:error:
T@"VNClassificationObservation",C,N,V_mostLikelyLabel
T@"NSArray",C,N,V_allLabelsWithConfidences
TQ,R,N,V_requestRevision
_mostLikelyLabel
_allLabelsWithConfidences
_computeLabel
setAllLabelsWithConfidences:
initWithRequestRevision:
label
setLabel:
allLabelsWithConfidences
T@"VNFaceAttributeCategory",R,V_VN1uMyFtnYEWjbrdx3yAuDndKkPeyzNJhB
T@"VNFaceAttributeCategory",R,V_VN4UfLbvVUqMvYV8bbGFQcxg5yRLm8ekI1
T@"VNFaceAttributeCategory",R,V_VN7CbCeAogPS2iHE6VQwu6H96xanljtMqk
T@"VNFaceAttributeCategory",R,V_VN7fiLHgGnvqPqG63cfDUCK4Xm8obUuWoP
T@"VNFaceAttributeCategory",R,V_VN2riiZbQrloRhCzYW56f0rk4N3ROe151S
T@"VNFaceAttributeCategory",R,V_VNpLorzxnyAlLcPFNcKhgoNCmy9b5BRWyk
T@"VNFaceAttributeCategory",R,V_VN3iT1YRjjnIuELobV1olJiO1vvItN6Kdq
T@"VNFaceAttributeCategory",R
T@"VNFaceAttributeCategory",R,V_ageCategory
T@"VNFaceAttributeCategory",R,V_VN7exwFFmQF0AI9P7FjBljwEFu7QYUGCYE
T@"VNFaceAttributeCategory",R,V_eyesCategory
T@"VNFaceAttributeCategory",R,V_smilingCategory
T@"VNFaceAttributeCategory",R,V_faceHairCategory
T@"VNFaceAttributeCategory",R,V_hairColorCategory
T@"VNFaceAttributeCategory",R,V_baldCategory
T@"VNFaceAttributeCategory",R,V_glassesCategory
T@"VNFaceAttributeCategory",R,V_makeupEyesCategory
T@"VNFaceAttributeCategory",R,V_makeupLipsCategory
T@"VNFaceAttributeCategory",R,V_makeupCategory
T@"VNFaceAttributeCategory",R,V_facemaskCategory
_ageCategory
_VN7exwFFmQF0AI9P7FjBljwEFu7QYUGCYE
_eyesCategory
_smilingCategory
_faceHairCategory
_hairColorCategory
_baldCategory
_glassesCategory
_makeupCategory
_makeupEyesCategory
_makeupLipsCategory
_VN1uMyFtnYEWjbrdx3yAuDndKkPeyzNJhB
_VN4UfLbvVUqMvYV8bbGFQcxg5yRLm8ekI1
_VN7CbCeAogPS2iHE6VQwu6H96xanljtMqk
_VN7fiLHgGnvqPqG63cfDUCK4Xm8obUuWoP
_VN2riiZbQrloRhCzYW56f0rk4N3ROe151S
_VNpLorzxnyAlLcPFNcKhgoNCmy9b5BRWyk
_VN3iT1YRjjnIuELobV1olJiO1vvItN6Kdq
_facemaskCategory
ageCategory
setAgeCategory:
VN7exwFFmQF0AI9P7FjBljwEFu7QYUGCYE
eyesCategory
smilingCategory
faceHairCategory
hairColorCategory
baldCategory
glassesCategory
makeupCategory
makeupEyesCategory
makeupLipsCategory
VN1uMyFtnYEWjbrdx3yAuDndKkPeyzNJhB
VN4UfLbvVUqMvYV8bbGFQcxg5yRLm8ekI1
VN7CbCeAogPS2iHE6VQwu6H96xanljtMqk
VN7fiLHgGnvqPqG63cfDUCK4Xm8obUuWoP
VN2riiZbQrloRhCzYW56f0rk4N3ROe151S
VNpLorzxnyAlLcPFNcKhgoNCmy9b5BRWyk
VN3iT1YRjjnIuELobV1olJiO1vvItN6Kdq
facemaskCategory
setVN5ui9WkMeVvCBruHiQE1q2r6E9kO1AyrP:
genderCategory
vn7exwFFmQF0AI9P7FjBljwEFu7QYUGCYE
vn1uMyFtnYEWjbrdx3yAuDndKkPeyzNJhB
vn4UfLbvVUqMvYV8bbGFQcxg5yRLm8ekI1
vn7CbCeAogPS2iHE6VQwu6H96xanljtMqk
vn7fiLHgGnvqPqG63cfDUCK4Xm8obUuWoP
vn2riiZbQrloRhCzYW56f0rk4N3ROe151S
vNpLorzxnyAlLcPFNcKhgoNCmy9b5BRWyk
vn3iT1YRjjnIuELobV1olJiO1vvItN6Kdq
_wisdomResourcesPath
_cachedMetalDeviceWisdomParametersAndReturnError:
_flushMetalDeviceWisdomParametersCache
containsString:
_warnings
hasWarnings
setWarnings:
recordWarnings:
T@"VNDetectionprint",R,C,V_detectionprint
_detectionprint
initWithOriginatingRequestSpecifier:detectionprint:
detectionprint
T@"NSString",R,D,N
TB,R,D,N
_ciContext
_espressoMaskInputBuffer
_espressoMaskOutputBuffer
render:toBitmap:rowBytes:bounds:format:colorSpace:
initWithData:elementCount:elementType:lengthInBytes:labelsAndConfidence:originatingRequestSpecifier:
Tr^{FastRegistration_Signatures=^fQ{Projections_meanStdTable=^f^f}^fQ{Projections_meanStdTable=^f^f}*},R
_signature
initWithImageBuffer:regionOfInterest:error:
signature
_mFaceFrontalizerImpl
_faceVImageBuffer
_mFaceFrontalizerWorkingBuffer
faceBoundingBoxScalingFactorForFaceObservation:
TQ,V_version
TB,V_readOnly
getHostTime
getHostTimeInNanos
createErrorWithCode:andMessage:
freeVImageBuffer:
parseExifTimestamp:
timeIntervalSince1970
dateFromString:
_operationPoints
operationPointsAndReturnError:
initWithOperationPoints:
_faceSegmenterDNN
_getFaceSegmenterInputImageSize:forRequestRevision:error:
_getNumberOfSupportedFaceSegments:forRequestRevision:error:
_fillFaceSegmentLabelToProbabilityMap:error:
initWithBytesNoCopy:length:freeWhenDone:
initWithBytesNoCopy:length:
_faceSegmenterMaximumInputImageAspectRatio
populateVCPVideoProcessorRequestConfiguration:
Tq,R,V_frameRate
_frameRate
initWithFrameRate:
frameRate
numberWithInteger:
Td,R,V_timeInterval
_timeInterval
initWithTimeInterval:
timeInterval
T@"VNVideoProcessorCadence",C,V_cadence
_cadence
_createVCPVideoProcessorRequestConfiguration
cadence
setCadence:
_videoProcessor
initWithURL:
addRequest:processingOptions:error:
addRequest:withProcessingOptions:error:
removeRequest:error:
analyzeWithTimeRange:error:
analyzeTimeRange:error:
analyzeWithStart:andDuration:error:
addRequest:withConfiguration:error:
T@"VNRecognizedPointsSpecifier",R
T@"NSNumber",R
_specifier
initWithOriginatingRequestSpecifier:keypointReturningObservation:
recognizedPointsSpecifier
availableKeys
groupIdentifier
recognizedPointsForGroupKey:error:
recognizedPointForKey:error:
keypointsMultiArrayAndReturnError:
recognizedPointsObservationClass
_humanPoseDetector
vcpPoseRequestSetupOptionsForDetectorOptions:error:
vcpPoseRequestRuntimeOptionsForDetectorOptions:error:
processImage:withOptions:error:
preferredPixelFormat
preferredInputSizeWithOptions:error:
updateWithOptions:error:
_maximumTrainingPrintsPerEntity
initWithEntityPrintOriginatingRequestSpecifier:
maximumEntities
setMaximumEntities:
maximumTrainingPrintsPerEntity
setMaximumTrainingPrintsPerEntity:
maximumAllowableEntities
newConfigurationForEntityPrintsGeneratedByRequest:error:
_analyzePixelBuffer:sceneprintOutputBuffer:options:error:
_analyzeRegionOfInterest:sceneprintOutputBuffer:options:warningRecorder:error:
_observationsForSceneprintOutput:originatingRequestSpecifier:error:
T@"NSArray",&,N,V_filterThresholds
Tf,N,V_nmsThreshold
Tf,N,V_osfsThreshold
Tf,N,V_osfsSizeRatio
Tf,N,V_olmcsThreshold
Ti,N,V_olmcsMergeCountDelta
Tf,N,V_smartThreshold
Tf,N,V_smartDistanceFactor
_nmsThreshold
_network
_osfsThreshold
_osfsSizeRatio
_olmcsThreshold
_olmcsMergeCountDelta
_smartThreshold
_smartDistanceFactor
_filterThresholds
initWithNetwork:filterThresholds:
initWithNetwork:
threshold
setThreshold:
overlappingSmallFacesSuppression:
overlappingLowMergeCountSuppression:
mergeBoxes:
smartMergeBoxes:
nmsBoxes:
sortBoxes:filterThresholdIndex:
filterBoxes:
detect:inputIsBGR:
processBoxes:withHeight:andWidth:
detectAndProcessObjects:inputIsBGR:
enforceSquareFaces:withHeight:andWidth:
nmsThreshold
setNmsThreshold:
filterThresholds
setFilterThresholds:
osfsThreshold
setOsfsThreshold:
osfsSizeRatio
setOsfsSizeRatio:
olmcsThreshold
setOlmcsThreshold:
olmcsMergeCountDelta
setOlmcsMergeCountDelta:
smartThreshold
setSmartThreshold:
smartDistanceFactor
setSmartDistanceFactor:
sortedArrayUsingDescriptors:
sortDescriptorWithKey:ascending:
shotflowNetworkClass
T#,R,D
T@"NSArray",R,D
T@"NSString",R,D
T{CGSize=dd},R
T@"NSSet",R
inputLayerName
modelName
inputImageMinDimension
inputImageMaxDimension
inputImageAspectRatio
supportedLabelKeys
processingDeviceDetectorWithModelPath:networkThreshold:filterThresholds:preferredDeviceID:engineID:storageType:
processingDeviceDetectorWithModelPath:preferredDeviceID:engineID:storageType:
processingDeviceDetectorWithEspressoNetwork:espressoPlan:networkThreshold:filterThresholds:
processingDeviceDetectorWithEspressoNetwork:espressoPlan:
networkThreshold
getSuggestedImageSize:
mergeHeadsBoxes:
defaultFaceDetectionPrecisionRecallThreshold
faceDetectionPrecisionRecallThreshold
setFaceDetectionPrecisionRecallThreshold:
getIndexBoxes:filterThresholdIndex:
recognizedFoodAndDrinkObjectClassToFoodAndDrinkCategoryName
knownFoodAndDrinkIdentifiers
_convertVNOptionsToFaceCoreSetupOptions:
_convertVNOptionsToFaceCoreDetectOptions:
_convertVNOptionsToFaceCoreExtractOptions:
_convertVNOptionsToFaceCoreOptions:optionsMap:
createHierarchicalModelForOriginatingRequestSpecifier:error:
convertRelationships:toStdRelationships:
defaultCStringEncoding
stringByAppendingPathExtension:
mDescriptorProcessor
mClassifier
_blacklistedIdentifiers
calculateImageDescriptors:regionOfInterest:warningRecorder:canceller:error:
_calculateImageDescriptors:regionOfInterest:warningRecorder:canceller:descriptorBuffer:debugIntermediatesDumpPath:outputDebugDictionary:error:
getLabels
blacklistedIdentifiers
setWithCapacity:
TB,N,V_useSegmentationPregating
_useSegmentationPregating
supportedSymbologiesAndReturnError:
_newVNBarcodeSymbologyQRDescriptorForACBSBarcodeInfo:
_newVNBarcodeSymbologyAztecDescriptorForACBSBarcodeInfo:
_newVNBarcodeSymbologyPDF417DescriptorForACBSBarcodeInfo:
_newVNBarcodeSymbologyQRDescriptorForMRCDescriptor:error:
_newVNBarcodeSymbologyAztecDescriptorForMRCDescriptor:error:
_newVNBarcodeSymbologyPDF417DescriptorForMRCDescriptor:error:
_ACBarcodeRecognizerLocateMode
_createACBSConfigAndReturnError:
_MRCLocateMode
_createMRCDecoderOptionsAndReturnError:
newBarcodeObservationForMRCDescriptor:roiCroppingPixelRect:originatingRequestSpecifier:error:
_machineReadableCodesDetectedInImageBuffer:originatingRequestSpecifier:error:
_getCornerPointsFromCodeLocationPoints:bottomLeft:topLeft:topRight:bottomRight:
newBarcodeObservationForACBSBarcodeInfo:imageWidth:imageHeight:roiCroppingPixelRect:originatingRequestSpecifier:error:
_barcodesDetectedInImageBuffer:usingACBSConfig:originatingRequestSpecifier:error:
availableLocateModesAndReturnError:
symbologies
setSymbologies:
locateMode
setLocateMode:
stopAtFirstPyramidWith2DCode
setStopAtFirstPyramidWith2DCode:
useSegmentationPregating
setUseSegmentationPregating:
setDefaultSymbologiesForRevision:
availableLocateModesRev2
availableLocateModesRev1
barcodeSymbologyForACBSBarcodeType:
barcodeSymbologyForMRCSymbology:
initWithKeyOptions:valueOptions:capacity:
initWithPayload:isCompact:rowCount:columnCount:
initWithPayload:isCompact:layerCount:dataCodewordCount:
initWithPayload:symbolVersion:maskPattern:errorCorrectionLevel:
unsignedCharValue
supportedSymbologiesRev2Private
supportedSymbologiesRev2
supportedSymbologiesRev1
ACBSBarcodeTypeForBarcodeSymbology:
MRCSymbologyForBarcodeSymbology:
_allBarcodeSymbologiesRev1
_allBarcodeSymbologiesRev2
_allBarcodeSymbologiesRev2Private
supportedSymbologies
availableLocateModes
sortedArrayUsingSelector:
T@"NSArray",C,N,V_symbologies
T@"NSString",C,N,V_locateMode
TB,N,V_stopAtFirstPyramidWith2DCode
_stopAtFirstPyramidWith2DCode
_symbologies
_locateMode
T@"VN6Ac6Cyl5O5oK19HboyMBR",R,V_imageNeuralHashprint
_imageNeuralHashprint
initWithOriginatingRequestSpecifier:imageNeuralHashprint:
imageNeuralHashprint
_trackerTypeToClassDictionary
_trackerClassToNameMapTable
_liveTrackerCounter
_trackingProcessingQueue
_trackersCollectionManagementQueue
_liveTrackerCounterLimit
_trackers
trackerWithOptions:error:
_maximumTrackersOfType:
_getTracker:
_createTracker:type:options:error:
releaseTracker:
releaseManager
releaseAllTrackers
T@"VNObservation<VNEntityIdentificationModelObservation>",R,V_observation
T@"<NSObject><NSCopying><NSSecureCoding>",R,C,V_entityUniqueIdentifier
Tf,R,V_confidence
_observation
_entityUniqueIdentifier
initWithObservation:entityUniqueIdentifier:confidence:
observation
entityUniqueIdentifier
_documentIdentifierToSceneLabels
_boundingBoxGenerator
supportedClassificationIdentifiersWithOptions:error:
supportedDocumentElementIdentifiers
TQ,V_maximumHandCount
_maximumHandCount
maximumHandCount
setMaximumHandCount:
indexSetWithIndexesInRange:
supportedJointNamesForRevision:error:
supportedJointsGroupNamesForRevision:error:
chirality
Tf,V_rotationAngle
Tf,V_yawAngle
Tf,V_pitchAngle
Ti,V_labelKey
_rotationAngle
_yawAngle
_pitchAngle
_labelKey
initWithObjectType:boundingBox:confidence:rotationAngle:yawAngle:pitchAngle:labelKey:
rotationAngle
setRotationAngle:
yawAngle
setYawAngle:
pitchAngle
setPitchAngle:
labelKey
setLabelKey:
T^{vImage_Buffer=^vQQQ},R,V_image
T^{__CVBuffer=},R,V_imageCVPixelBuffer
T@"NSString",&,V_imageFilePath
TB,V_freeImageInDealloc
T@"NSString",R,V_externalImageId
Tq,R,V_exifTimestamp
_freeImageInDealloc
_image
_imageCVPixelBuffer
_imageFilePath
_externalImageId
_exifTimestamp
initWithVImage:externalImageId:andExifTimestampString:error:
initWithVImage:externalImageId:andExifTimestampValue:error:
initWithCVPixelBufferImage:externalImageId:andExifTimestampString:error:
initWithCVPixelBufferImage:externalImageId:andExifTimestampValue:error:
image
imageCVPixelBuffer
imageFilePath
setImageFilePath:
freeImageInDealloc
setFreeImageInDealloc:
externalImageId
exifTimestamp
getDefaultConfidence:forClassificationIdentifier:error:
getConfidence:forClassificationIdentifier:withPrecision:error:
getPrecision:forClassificationIdentifier:confidence:error:
getConfidence:forClassificationIdentifier:withRecall:error:
getRecall:forClassificationIdentifier:confidence:error:
errorForUnknownClassificationIdentifier:
errorForUnimplementedMethod:
unspecifiedOperationPoints
loadFromURL:error:
_mtlContext
_computePipelines
_maxThreadExecutionWidth
_pyramid_size
_I_tex
_I_u32_alias_tex
_G0_pxbuf
_G1_pxbuf
_G0_tex
_G1_tex
_C0_pxbuf
_C1_pxbuf
_C0_tex
_C1_tex
_Adiagb_buf
_Ixy_buf
_w_pxbuf
_w_tex
_uv_pxbuf
_uv_tex
_uv_u32_alias_tex
_current_frame_index
_uv_tex_user_ref
initWithMetalContext:width:height:numScales:
waitUntilCompleted
setOutputUV:error:
estimateFlowFromReference:target:error:
estimateFlowStream:error:
_initMemory:height:numScales:
_setupPipelines
_setupBufferAndReturnError:
_computeOpticalFlow
_createImagePyramidWithCommandBuffer:in_pixelbuf:I_idx:error:
_zeroFlowWithCommandBuffer:uv_tex:
_downscale2XWithCommandBuffer:in_u32_alias_tex:out_u32_alias_tex:
_computeFeaturesWithCommandBuffer:in_tex:out_tex:
_computeFeaturesDerivativesWithCommandBuffer:in_tex:out_tex:
_doSolverWithCommandBuffer:scale:scale_xy_inv:coeff:in_uv_tex:out_uv_tex:out_w_tex:
_doNLRegularizationWithCommandBuffer:in_uv_tex:join_tex:w_tex:out_uv_tex:
endEncoding
dispatchThreadgroups:threadsPerThreadgroup:
maxTotalThreadsPerThreadgroup
threadExecutionWidth
setBytes:length:atIndex:
setTexture:atIndex:
setComputePipelineState:
computeCommandEncoder
setBuffer:offset:atIndex:
commit
commandBuffer
newTextureViewWithPixelFormat:
newTextureWithDescriptor:
newBufferWithLength:options:
newComputePipelineStateWithFunction:error:
newFunctionWithName:
T@"VNSupportedImageSize",&,N,V_detectorPreferredImageSize
TB,N,V_detectorWantsAnisotropicScaling
Td,N,V_detectorExecutionTimeInterval
_detectorWantsAnisotropicScaling
_detectorPreferredImageSize
_detectorExecutionTimeInterval
detectorPreferredImageSize
setDetectorPreferredImageSize:
detectorWantsAnisotropicScaling
setDetectorWantsAnisotropicScaling:
detectorExecutionTimeInterval
setDetectorExecutionTimeInterval:
T@"VNSupportedImageSize",C,N
Td,N
_actualSizeForDesiredSize:ofSourceImageWidth:height:
_createScaledImagePixelBufferFromCropRect:ofImageBuffer:inPixelFormat:forDetectorInputImageSize:usingAnisotropicScaling:error:
_createScaledImagePixelBufferFromImageBuffer:inPixelFormat:forDetectorInputImageSize:usingAnisotropicScaling:error:
_performNOPForRevision:inContext:detectorCompletionSemaphore:error:
TB,N,V_refineMouthRegion
TB,N,V_refineLeftEyeRegion
TB,N,V_refineRightEyeRegion
TB,N,V_performBlinkDetection
T@"NSNumber",&,N,V_cascadeStepCount
TQ,N,V_constellation
_refineMouthRegion
_refineLeftEyeRegion
_refineRightEyeRegion
_performBlinkDetection
_cascadeStepCount
_constellation
refineMouthRegion
setRefineMouthRegion:
refineLeftEyeRegion
setRefineLeftEyeRegion:
refineRightEyeRegion
setRefineRightEyeRegion:
performBlinkDetection
setPerformBlinkDetection:
cascadeStepCount
setCascadeStepCount:
constellation
setConstellation:
revision:supportsConstellation:
T@"NSNumber",&,N
_determineFacesToProcessFrom:outputFacesThatNeedNoProcessing:outputFacesThatNeedAlignment:outputFacesThatNeedLandmarks:
T@"VNMPImageDescriptor",&,N,V_descriptor
TQ,N,V_type
_originatingRequestSpecifier
_descriptor
initWithState:error:
originatingRequestSpecifier
distanceToImageprint:error:
initWithImageDescriptor:type:originatingRequestSpecifier:
setDescriptor:
type
setType:
layers_size
initWithNetworkContext:
allLandmarksPointsIndexes
_buildCalibrationMatrix:calibrationMatrix:error:
initWithBytes:length:
targetsGPU
espressoDeviceID
espressoEngine
registryID
allDevices
T@"CIImage",&,N,V_inputImage
_kernel
_inputImage
initWithKernelName:
initWithKernelName:inputParameters:
inputImage
setInputImage:
kernelWithFunctionName:fromMetalLibraryData:error:
initWithContentsOfURL:
URLForResource:withExtension:
bundleWithIdentifier:
T@"NSNumber",C,N,V_inputContrast
_inputContrast
initWithInputParameters:
outputImage
inputContrast
setInputContrast:
imageByPremultiplyingAlpha
applyWithExtent:arguments:
imageByUnpremultiplyingAlpha
imageByApplyingFilter:withInputParameters:
vectorWithCGRect:
T@"NSNumber",C,N,V_inputPivot
_inputPivot
setInputPivot:
inputPivot
T@"NSData",R,V_descriptorData
TQ,R,V_elementCount
TQ,R,V_lengthInBytes
T@"NSDictionary",R,C
TQ,R,N,V_confidenceScoreType
T@"NSString",R,V_version
_elementType
_descriptorData
_elementCount
_lengthInBytes
_confidenceScoreType
initWithData:elementCount:elementType:lengthInBytes:originatingRequestSpecifier:
elementType
_initWithClassKeyMappedCoder:
initWithCoder:forCodingVersion:
_VNEspressoModelImageprintSerializedLength
hasEquivalentDescriptorToImageprint:
descriptorData
elementCount
lengthInBytes
confidenceScoreType
originatingRequestSpecifierForRequestRevision:error:
TI,R,D
T@"NSDictionary",R,C,D
TQ,R,D
Tf,R,N,V_aestheticScore
Tf,R,N,V_wellFramedSubjectScore
Tf,R,N
Tf,R,N,V_wellChosenBackgroundScore
Tf,R,N,V_tastefullyBlurredScore
Tf,R,N,V_sharplyFocusedSubjectScore
Tf,R,N,V_wellTimedShotScore
Tf,R,N,V_pleasantLightingScore
Tf,R,N,V_pleasantReflectionsScore
Tf,R,N,V_harmoniousColorScore
Tf,R,N,V_livelyColorScore
Tf,R,N,V_pleasantSymmetryScore
Tf,R,N,V_pleasantPatternScore
Tf,R,N,V_immersivenessScore
Tf,R,N,V_pleasantPerspectiveScore
Tf,R,N,V_pleasantPostProcessingScore
Tf,R,N,V_noiseScore
Tf,R,N,V_failureScore
Tf,R,N,V_pleasantCompositionScore
Tf,R,N,V_interestingSubjectScore
Tf,R,N,V_intrusiveObjectPresenceScore
Tf,R,N,V_pleasantCameraTiltScore
Tf,R,N,V_lowKeyLightingScore
_aestheticScore
_wellFramedSubjectScore
_wellChosenBackgroundScore
_tastefullyBlurredScore
_sharplyFocusedSubjectScore
_wellTimedShotScore
_pleasantLightingScore
_pleasantReflectionsScore
_harmoniousColorScore
_livelyColorScore
_pleasantSymmetryScore
_pleasantPatternScore
_immersivenessScore
_pleasantPerspectiveScore
_pleasantPostProcessingScore
_noiseScore
_failureScore
_pleasantCompositionScore
_interestingSubjectScore
_intrusiveObjectPresenceScore
_pleasantCameraTiltScore
_lowKeyLightingScore
initWithOriginatingRequestSpecifier:overallAestheticScore:wellFramedSubjectScore:wellChosenBackgroundScore:tastefullyBlurredScore:sharplyFocusedSubjectScore:wellTimedShotScore:pleasantLightingScore:pleasantReflectionsScore:harmoniousColorScore:livelyColorScore:pleasantSymmetryScore:pleasantPatternScore:immersivenessScore:pleasantPerspectiveScore:pleasantPostProcessingScore:noiseScore:failureScore:pleasantCompositionScore:interestingSubjectScore:intrusiveObjectPresenceScore:pleasantCameraTiltScore:lowKeyLightingScore:
wellChosenSubjectScore
_scoresDictionary
aestheticScore
wellFramedSubjectScore
wellChosenBackgroundScore
tastefullyBlurredScore
sharplyFocusedSubjectScore
wellTimedShotScore
pleasantLightingScore
pleasantReflectionsScore
harmoniousColorScore
livelyColorScore
pleasantSymmetryScore
pleasantPatternScore
immersivenessScore
pleasantPerspectiveScore
pleasantPostProcessingScore
noiseScore
failureScore
pleasantCompositionScore
interestingSubjectScore
intrusiveObjectPresenceScore
pleasantCameraTiltScore
lowKeyLightingScore
allScorePropertyNames
insertObject:atIndex:
Tr^{CGPath=},R
_compressedPoints
_imageSize
_pathLock
_normalizedPath
_polygonList
_topLevelContoursIndices
_contourChildrenIndices
initWithOriginatingRequestSpecifier:compressedPoints:imageSize:
_initializePolygonContainers
contourCount
topLevelContourCount
topLevelContours
contourAtIndex:error:
contourAtIndexPath:error:
normalizedPath
polygonList
childContourIndicesAtIndex:
indexAtPosition:
initWithIndexes:length:
_targetImageDimensionForContourDetection
_absoluteDiffFilter
_thresholdFilter
_dilateFilter
_contrastFilter
_detectContoursRequest
_previousFrameBuffer
_previousFrameImage
_maximumImageDimension
_preScaleFactor
_dilateRadius
_frameAnalysisSpacing
_lastAnalyzedFramePTS
_nextFrameToBeAnalyzedPTS
_processAllFrames
_sRGB
_parabolaDetector
_currentImageWidth
_currentImageHeight
initWithFrameAnalysisSpacing:trajectoryLength:
_createCroppedAndScaledBufferFromVNImageBuffer:regionOfInterest:withOptions:error:
_VNPointsFromCGPoints:
processVNImageBuffer:regionOfInterest:withOptions:warningRecorder:requestUUID:error:
imageByColorMatchingColorSpaceToWorkingSpace:
imageWithCVImageBuffer:options:
filterWithName:keysAndValues:
mFaceRegionMapAlgorithmImpl
T@"NSUUID",&,N,SsetUUID:,V_uuid
Tf,N,V_confidence
T{?={?=qiIq}{?=qiIq}},N,V_timeRange
T@"VNRequestSpecifier",R,V_originatingRequestSpecifier
_timeRange
observationWithOriginatingRequestSpecifier:
initWithOriginatingRequestSpecifier:
getDataDetectorResultsForString:error:
uuid
setUUID:
timeRange
setTimeRange:
resultsFromCoreResults:
UUID
defaultOriginatingRequestSpecifierForRevision:
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_boundingBox
T@"NSUUID",C,V_identifier
T@"VNPixelBufferObservation",R,N,V_globalSegmentationMask
_boundingBox
_globalSegmentationMask
initWithOriginatingRequestSpecifier:boundingBox:
setBoundingBoxFromQuadrilateralPointsAtTopLeft:topRight:bottomRight:bottomLeft:
setBoundingBox:
globalSegmentationMask
setIdentifier:
boundingBoxIsCalculatedProperty
observationWithBoundingBox:
observationWithRequestRevision:boundingBox:
T@"VNFaceLandmarks2D",&,N,V_landmarks
TB,N,V_hasBBoxBeenAligned
T{_Geometry2D_rect2D_={_Geometry2D_point2D_=ff}{_Geometry2D_size2D_=ff}},N,V_alignedBoundingBox
Tf,N,V_alignedRotationAngle
T@"NSData",R,N,V_landmarkPoints
T@"NSData",R,N,V_landmarkPoints65
TQ,N,V_landmarksConstellation
T@"NSArray",&,N,V_landmarkPrecisionEstimatesPerPoint
T@"NSData",R,N,V_landmarkPoints3d
T@"NSData",&,N,V_poseData
Tf,N,V_faceIdConfidence
T@"NSData",&,N,V_alignedMeanShape
T@"NSNumber",&,N,V_roll
T@"NSNumber",&,N,V_yaw
T@"NSNumber",&,N,V_pitch
T@"VNRequestSpecifier",R,N,V_landmarksOriginatingRequestSpecifier
T@"VNRequestSpecifier",R,N,V_landmarks3DOriginatingRequestSpecifier
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,V_unalignedBoundingBox
T@"VNFaceLandmarks3D",R,N
T@"VNFaceLandmarks2D",R,N
T@"VNFaceRegionMap",R,N,V_faceRegionMap
T@"VNFaceAttributes",R,N,V_faceAttributes
T@"NSDictionary",R,C,N
T@"VNFaceLegacyFaceCore",R,N,V_legacyFaceCore
T{?=[4]},R,N
T{?=},R,N
TQ,N,V_faceId
T@"VNFaceprint",&,N,V_faceprint
T@"VNTorsoprint",&,N
T@"VNFaceTorsoprint",&,N
T@"VNFaceSegments",R,N,V_faceSegments
Tf,R,N,GfaceJunkinessIndex
Tf,R,N,GfaceOrientationIndex
T@"VNFaceGaze",R,N,V_gaze
T@"VNFaceScreenGaze",R,N,V_faceScreenGaze
T@"NSNumber",R,N,V_faceCaptureQuality
_cachedLandmarks
_cachedLandmarksLock
_cachedLandmarks65
_cachedLandmarks65Lock
_cachedLandmarks3d
_cachedLandmarks3dLock
_faceRegionMap
_faceAttributes
_faceTorsoprint
_faceSegments
_landmarkScore
_isBlinking
_blinkScore
_expressionsAndScores
_faceJunkinessIndex
_faceOrientationIndex
_alignedBoundingBox
_unalignedBoundingBox
_landmarkPoints
_landmarkPoints65
_landmarksConstellation
_landmarkPrecisionEstimatesPerPoint
_landmarkPoints3d
_poseData
_faceIdConfidence
_faceId
_hasBBoxBeenAligned
_alignedRotationAngle
_roll
_yaw
_pitch
_alignedMeanShape
_faceCaptureQuality
_landmarksOriginatingRequestSpecifier
_landmarks3DOriginatingRequestSpecifier
_legacyFaceCore
_gaze
_faceScreenGaze
_landmarks
_initLocks
expressionsAndConfidence
nameConfidence
landmarks
landmarks65
landmarks3d
pose
poseQuaternion
getComputedRectifyingTransform:
setIsBlinking:
setBlinkScore:
isBlinking
blinkScore
alignedBoundingBoxAsCGRect
setExpressionsAndScores:
expressionsAndScores
expressionsAndDetections
setLandmarkPointsData:originatingRequestSpecifier:
setLandmarkPoints65Data:originatingRequestSpecifier:
setLandmark3DPointsData:originatingRequestSpecifier:
setLandmarkScore:
landmarkScore
setFaceRegionMap:
setFaceAttributes:
setFaceSegments:
setFaceCaptureQuality:
faceOrientationIndex
faceJunkinessIndex
setFaceJunkinessIndex:
setFaceOrientationIndex:
setTorsoprint:
faceTorsoprint
setFaceTorsoprint:
setUnalignedBoundingBox:
setRoll:
setYaw:
setPitch:
setLegacyFaceCore:
setFaceScreenGaze:
setGaze:
getFaceEXIFOrientation:error:
faceCaptureQuality
roll
pitch
setLandmarks:
hasBBoxBeenAligned
setHasBBoxBeenAligned:
alignedBoundingBox
setAlignedBoundingBox:
alignedRotationAngle
setAlignedRotationAngle:
landmarkPoints
landmarkPoints65
landmarksConstellation
setLandmarksConstellation:
landmarkPrecisionEstimatesPerPoint
setLandmarkPrecisionEstimatesPerPoint:
landmarkPoints3d
poseData
setPoseData:
faceIdConfidence
setFaceIdConfidence:
alignedMeanShape
setAlignedMeanShape:
landmarksOriginatingRequestSpecifier
landmarks3DOriginatingRequestSpecifier
unalignedBoundingBox
faceRegionMap
faceAttributes
legacyFaceCore
faceId
setFaceId:
setFaceprint:
faceSegments
gaze
faceScreenGaze
_exifOrientationFromFaceRollAngle:exifOrientation:error:
decodeArrayOfObjectsOfClass:forKey:
faceObservationWithRequestRevision:boundingBox:andAlignedBoundingBox:
faceObservationWithRequestRevision:unalignedBoundingBox:alignedBoundingBox:
faceObservationWithRequestRevision:boundingBox:faceprint:
faceObservationWithRequestRevision:boundingBox:roll:yaw:pitch:
faceObservationWithRequestRevision:boundingBox:roll:yaw:
faceObservationWithRequestRevision:boundingBox:alignedBoundingBox:roll:yaw:pitch:
faceObservationWithRequestRevision:boundingBox:alignedBoundingBox:roll:yaw:
computeYawPitchRollFromPoseMatrix:outputYaw:outputPitch:outputRoll:
T@"VNImageRegistrationSignature",&,N,V_referenceImageSignature
T@"VNImageRegistrationSignature",&,N,V_floatingImageSignature
T{CGAffineTransform=dddddd},N
_referenceImageSignature
_floatingImageSignature
alignmentTransform
setAlignmentTransform:
referenceImageSignature
setReferenceImageSignature:
floatingImageSignature
setFloatingImageSignature:
T{CGAffineTransform=dddddd},N,V_alignmentTransform
_alignmentTransform
T{?=[3]},N,V_warpTransform
_warpTransform
warpTransform
setWarpTransform:
T@"NSNumber",&,N,V_blurScore
T@"NSNumber",&,N,V_exposureScore
_blurScore
_exposureScore
blurScore
setBlurScore:
exposureScore
setExposureScore:
T@"VNImageprint",&,N,V_imageprint
TB,R,N,V_imageprintValid
T@"NSString",R,C,N,V_imageprintVersion
T@"NSData",R,N
_imageprintValid
_imageprint
_imageprintVersion
calculateDistanceFromImageprintObservation:
isImageprintValid
initWithRawImageprintDescriptor:
rawImageprintDescriptor
imageprint
setImageprint:
imageprintValid
imageprintVersion
observationWithImageprint:error:
initWithUUIDString:
blurMeasure
brightness
T@"NSString",R,C,N,V_identifier
_operationPointsProvider
initWithRequestRevision:identifier:confidence:
initWithRequestRevision:identifier:confidence:operationPointsProvider:
initWithOriginatingRequestSpecifier:identifier:confidence:
initWithOriginatingRequestSpecifier:identifier:confidence:operationPointsProvider:
hasPrecisionRecallCurve
hasMinimumRecall:forPrecision:
hasMinimumPrecision:forRecall:
T@"VNPixelBufferObservation",R,V_segmentationMask
T@"NSArray",R,C,N,V_labels
_labels
_segmentationMask
initWithRequestRevision:boundingBox:confidence:labels:
initWithOriginatingRequestSpecifier:boundingBox:confidence:labels:segmentationMask:
segmentationMask
labels
T^{__CVBuffer=},R,N,V_pixelBuffer
T@"NSString",R,C,N,V_featureName
_pixelBuffer
_featureName
initWithOriginatingRequestSpecifier:featureName:CVPixelBuffer:
pixelBuffer
featureName
T@"MLFeatureValue",R,C,N,V_featureValue
_featureValue
initWithOriginatingRequestSpecifier:featureName:featureValue:
featureValue
T{CGPoint=dd},R,N,V_topLeft
T{CGPoint=dd},R,N,V_topRight
T{CGPoint=dd},R,N,V_bottomLeft
T{CGPoint=dd},R,N,V_bottomRight
_topLeft
_bottomLeft
_bottomRight
_topRight
initWithTopLeft:bottomLeft:bottomRight:topRight:
initWithRequestRevision:topLeft:bottomLeft:bottomRight:topRight:
initWithOriginatingRequestSpecifier:topLeft:bottomLeft:bottomRight:topRight:
initWithBoundingBox:
initWithRequestRevision:boundingBox:
topLeft
bottomLeft
bottomRight
topRight
rectangleObservationWithRequestRevision:topLeft:bottomLeft:bottomRight:topRight:
T{CGAffineTransform=dddddd},N,V_transform
Td,N,V_angle
_transform
_angle
transform
setTransform:
angle
setAngle:
T@"NSArray",&,N,V_objects
TQ,N,V_clusterId
TQ,N,V_totalObjectCount
TB,N,V_shouldUpdateRepresentative
T@"NSArray",&,N,V_suggestedIdsForRepresentative
T@"NSDictionary",&,N,V_representativenessById
_shouldUpdateRepresentative
_objects
_clusterId
_totalObjectCount
_suggestedIdsForRepresentative
_representativenessById
objects
setObjects:
clusterId
setClusterId:
totalObjectCount
setTotalObjectCount:
shouldUpdateRepresentative
setShouldUpdateRepresentative:
suggestedIdsForRepresentative
setSuggestedIdsForRepresentative:
representativenessById
setRepresentativenessById:
T@"NSArray",&,N,V_clusters
T@"NSArray",&,N,V_suggestionsForCluster
T@"NSData",&,N,V_clusterState
T@"NSSet",&,N,V_clusteredFaceIds
T@"NSArray",&,N,V_groupedClusteredFaceIdsForCluster
T@"NSNumber",&,N,V_distance
T@"NSDictionary",&,N,V_distancesById
_clusters
_suggestionsForCluster
_clusterState
_clusteredFaceIds
_groupedClusteredFaceIdsForCluster
_distance
_distancesById
clusters
setClusters:
suggestionsForCluster
setSuggestionsForCluster:
clusterState
setClusterState:
clusteredFaceIds
setClusteredFaceIds:
groupedClusteredFaceIdsForCluster
setGroupedClusteredFaceIdsForCluster:
setDistance:
distancesById
setDistancesById:
data
computeDistance:toFeaturePrintObservation:error:
computeDistanceToFeaturePrintObservation:error:
T@"NSArray",R,N,V_sceneprints
T@"NSString",R,C,N,V_sceneprintVersion
_sceneprints
_sceneprintVersion
initWithRequestRevision:sceneprints:
initWithOriginatingRequestSpecifier:sceneprints:
sceneprints
sceneprintVersion
sceneprintCurrentVersion
observationWithSceneprints:
T@"NSArray",C,N,V_smartCamprints
T@"NSString",R,C,N,V_smartCamprintVersion
_smartCamprints
_smartCamprintVersion
initWithRequestRevision:smartCamprints:
initWithOriginatingRequestSpecifier:smartCamprints:
smartCamprints
setSmartCamprints:
smartCamprintVersion
smartCamprintCurrentVersion
observationWithSmartCamprints:
T@"NSArray",C,N,V_textObjects
TB,N,V_isTitle
T@"NSString",R,C,N,V_text
_isTitle
_textObjects
_text
topCandidates:
setText:
textObjects
setTextObjects:
isTitle
setIsTitle:
text
T@"NSArray",R,C,N,V_detectedPoints
T@"NSArray",R,C,N,V_projectedPoints
T,R,N,V_equationCoefficients
Td,R,N,V_movingAverageRadius
_detectedPoints
_projectedPoints
_movingAverageRadius
_requestUUID
_equationCoefficients
detectedPoints
projectedPoints
equationCoefficients
movingAverageRadius
_characterBoxes
characterBoxes
setCharacterBoxes:
T@"VNImageSignature",&,N,V_targetImageSignature
T@"LKTOpticalFlow",&,N,V_opticalFlow
_targetImageSignature
_opticalFlow
targetImageSignature
setTargetImageSignature:
opticalFlow
setOpticalFlow:
VNObservationsWithOriginatingRequestSpecifier:
_determineFacesToProcessFrom:outputFacesThatNeedNoProcessing:outputFacesThatNeedProcessing:outputFacesThatNeed2DLandmarks:
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_regionOfInterest
T@"NSArray",C,N,V_inputFaceObservations
T@"NSArray",C,N,V_inputDetectedObjectObservations
_inputFaceObservations
_inputDetectedObjectObservations
_regionOfInterest
regionOfInterest
setRegionOfInterest:
T{CGRect={CGPoint=dd}{CGSize=dd}},N
getOptionalValidatedInputDetectedObjectObservations:forObservationClass:relationWithRegionOfInterest:error:
isFullCoverageRegionOfInterest
regionOfInterestNonIntegralPixelRectForWidth:height:
regionOfInterestPixelRectForWidth:height:
_faceObservationsForRegionOfInterestContainingFaceObservations:
_detectedObjectObservationsForRegionOfInterestContainingDetectedObjectObservations:relationWithRegionOfInterest:
_isSeparatedString:equalToString:atIndex:usingSeparator:
isMajorVersion:equalToMajorVersion:
isMinorVersion:equalToMinorVersion:
componentsSeparatedByString:
_determineAnimalsToProcessFrom:outputAnimalsThatNeedNoProcessing:outputAnimalsThatNeedAnimalprints:
getFacesFromNetworkResultOriginalWidth:originalHeight:
processVimageNoRotation:tex:doBGRA2RGBA:
autoResizeForAspectRatio:useLowPriorityMode:gpuPriority:
is_memory_tight
shared
setIs_memory_tight:
setContextMetal:
setContextCpu:
autoSetupNetBaseName:weights:scaleConfig:setupMode:computePath:autoAspectRatio:forceReset:useLowPriorityMode:gpuPriority:
smoothedFloat32ImageBuffer:fromImageBuffer:originalImageSize:sigmaX:sigmaY:nStd:
maximumValueFromFloat32ImageBuffer:
significantRegionsFromFloat32ImageBuffer:threshold:
significantRegionsFromFloat32ImageBuffer:threshold:relativeToMaximum:
significantRegionsFromFloat32PixelBuffer:threshold:relativeToMaximum:error:
boundingBoxesFromFloat32ImageBuffer:thresholds:error:
boundingBoxesFromFloat32ImageBuffer:thresholds:relativeToMaximum:applySmoothing:originalImageSize:sigmaX:sigmaY:nStd:error:
boundingBoxesFromFloat32PixelBuffer:thresholds:relativeToMaximum:applySmoothing:originalImageSize:sigmaX:sigmaY:nStd:error:
value:withObjCType:
knownAnimalIdentifiersForRevision:error:
_shouldProcessRequestRevision:error:
T@"<VNDetectorCacheDelegate>",&
_delegateFlags
_detectors
releaseDetectorsThatCanBeReplacedByDetectorOfClass:withConfiguration:
detectorOfType:configuredWithOptions:error:
detectorOfClass:configuredWithOptions:error:
cacheDetector:
evictDetectorsPassingTest:
evictAllDetectors
_faceIDModel
_maximumElementsPerID
_entityPrintCounts
initWithFaceIDModel:entityPrintOriginatingRequestSpecifier:maximumElementsPerID:entityUniqueIdentifiers:entityPrintCounts:
trainingEntityPrintsForEntityWithUniqueIdentifier:error:
predictionsForObservation:limit:canceller:error:
entityUniqueIdentifiers
printCountForEntityWithUniqueIdentifier:
printCountsForEntitiesWithUniqueIdentifiers:
printCountsForAllEntities
encodeInt:forKey:
decodeIntForKey:
removeObjectsInRange:
sortUsingComparator:
createVNEntityIdentificationModelEntryPrintForRevision:fromDescriptorData:length:elementCount:error:
trainedModelBuiltFromConfiguration:dataProvider:canceller:error:
faceIDModelMaximumElementsPerID
dictionaryRepresentationClassesSet
createDictionaryRepresentationOfCVPixelBuffer:
createCVPixelBufferRefFromDictionaryRepresentation:
isCVPixelBuffer:equalToCVPixelBuffer:
computeHashForCVPixelBuffer:
_ciContrastFromAvgFilter
_ciContrastWithPivotFilter
whiteImage
TQ,N,V_qualityLevel
TI,N,V_outputPixelFormat
_outputPixelFormat
_qualityLevel
qualityLevel
setQualityLevel:
outputPixelFormat
setOutputPixelFormat:
TI,N
_previousObservation
_previousImageWidth
_previousImageHeight
initWithDictionary:
_session
_requestPerformer
_performRequests:onImageBuffer:gatheredForensics:error:
initWithSession:
performRequests:onCVPixelBuffer:error:
performRequests:onCVPixelBuffer:gatheredForensics:error:
performRequests:onCVPixelBuffer:orientation:error:
performRequests:onCVPixelBuffer:orientation:gatheredForensics:error:
performRequests:onCGImage:error:
performRequests:onCGImage:gatheredForensics:error:
performRequests:onCGImage:orientation:error:
performRequests:onCGImage:orientation:gatheredForensics:error:
performRequests:onCIImage:error:
performRequests:onCIImage:gatheredForensics:error:
performRequests:onCIImage:orientation:error:
performRequests:onCIImage:orientation:gatheredForensics:error:
performRequests:onImageURL:error:
performRequests:onImageURL:gatheredForensics:error:
performRequests:onImageURL:orientation:error:
performRequests:onImageURL:orientation:gatheredForensics:error:
performRequests:onImageData:error:
performRequests:onImageData:gatheredForensics:error:
performRequests:onImageData:orientation:error:
performRequests:onImageData:orientation:gatheredForensics:error:
performRequests:onCMSampleBuffer:error:
performRequests:onCMSampleBuffer:gatheredForensics:error:
performRequests:onCMSampleBuffer:orientation:error:
performRequests:onCMSampleBuffer:orientation:gatheredForensics:error:
prepareForPerformingRequestsOfClass:error:
prepareForPerformingRequests:error:
requestForcedCleanup
forcedCleanup
requestForcedCleanupWithOptions:
requestForcedCleanupWithOptions:completion:
forcedCleanupWithOptions:
_serialNumberToPersonUniqueIdentifierMapTable
initWithFaceIDModel:faceprintRequestRevision:maximumElementsPerID:personUniqueIdentifierToSerialNumberMapping:
_getSerialNumber:forPersonUniqueIdentifier:error:
_personPredictionsForFace:withDescriptor:limit:faceIDCanceller:error:
personPredictionsForFace:withDescriptor:limit:canceller:error:
trainingFaceprintsForPersonWithUniqueIdentifier:error:
dictionaryRepresentation
_concatenateFaceprintImageDescriptorBuffer:withFaceprints:forIdentityWithSerialNumber:faceprintLabels:
modelBuiltFromConfiguration:dataProvider:canceller:error:
TQ,R,V_version
TB,R,GisReadOnly,V_readOnly
initWithVersion:lastModificationDate:readOnly:
isReadOnly
TB,N,V_upperBodyOnly
_upperBodyOnly
upperBodyOnly
setUpperBodyOnly:
revisionSupportsFullBodyDetection:
confidenceTypeForRevision:
computeHierarchicalClusteringOfImageDescriptors:results:context:
getDistanceForClusterNode:splitDistanceType:
computeClusteringIntoKGroups:orUsingDistanceThreshold:forHierarchicalTree:context:
computeClusteringIntoKGroups:forHierarchicalTree:context:
computeClusteringUsingDistanceThreshold:forHierarchicalTree:context:
computeNaturalClusteringForHierarchicalTree:context:
computeTimestampAdjustedDistanceForBaseDistance:andTimestampDiff:
computeTotalDistanceForDescriptorDistance:timestampDiff:useTimestampAdjustment:
T{?=^vi},R,V_network
T^v,R,V_plan
T^v,R,V_context
T@"NSString",R,V_modelName
T@"NSString",R,V_networkConfigurationName
_plan
_modelName
_networkConfigurationName
initWithModelName:networkConfigurationName:network:plan:context:
free
network
plan
networkConfigurationName
_locateFrameworkBundleForResourceWithName:resourceDirectory:error:
pathForEspressoResource:ofType:error:
pathForEspressoResourceWithFilename:error:
pathForEspressoNetworkModelFileWithName:error:
getWidth:height:ofBlobNamed:forNetworkModelFileWithName:error:
createSingleNetworkPlanFromResourceName:usingProcessingDevice:lowPriorityMode:inputBlobNames:outputBlobNames:networkConfiguration:espressoResources:error:
createSingleNetworkPlanFromResourceName:usingProcessingDevice:lowPriorityMode:inputBlobNames:outputBlobNames:networkConfiguration:explicitNetworkLayersStorageType:espressoResources:error:
createCVPixelBufferWithPixelFormat:fromImageInEspressoBuffer:error:
renderEspressoBufferImage:intoCVPixelBuffer:error:
pixelValueSizeInBytesForBuffer:error:
feedForwardEspressoBufferForNetwork:fromBufferWithName:toBufferWithName:firstFrame:error:
pathExtension
pathForResource:ofType:inDirectory:
bundleWithPath:
bundlePath
T{CGPoint=dd},N,V_inputPoint
_inputPoint
inputPoint
setInputPoint:
T{CGPoint=dd},N
initWithPoint:
initWithPoint:completionHandler:
_uv_user_ref
initWithWidth:height:numScales:
_tensorsDictionary
tensorForKey:error:
initWithTensorsDictionary:originatingRequestSpecifier:
initWithTensorsDictionary:requestRevision:
knownTensorKeysForRequestRevision:error:
_allRecognizedPoints
initWithOriginatingRequestSpecifier:allRecognizedPoints:
dumpDebugIntermediatesWithImageBuffer:lumaIntermediate:alignedBBoxInLumaIntermediateCoordinates:meanShapeInLumaIntermediate:landmarkPointsInLumaIntermediate:
mFaceLandmarkAlgorithmImpl
mFaceLandmarkMouthRefinerImpl
mFaceLandmarkRightEyeRefinerImpl
mFaceLandmarkLeftEyeRefinerImpl
_loadEspressoModelWithConfigurationOptions:error:
cascadeStepCountInOriginalModel
cascadeStepCountLoaded
shouldDumpDebugIntermediates
mJunkDescriptorImpl
mJunkClassifierImpl
fileURLWithPath:isDirectory:
_perMeshPtr
targetsCPU
torsoprintDescriptorSize
T{CGSize=dd},R,D
minimumTorsoInsideInputImageThreshold
Tf,R,D
magnifiedBBoxScaleFactor
torsoprintInputImageSizeForFaceOrientation:
TQ,N,V_maximumIntermediateSideLength
TQ,N,V_blurDeterminationMethod
_maximumIntermediateSideLength
_blurDeterminationMethod
maximumIntermediateSideLength
setMaximumIntermediateSideLength:
blurDeterminationMethod
setBlurDeterminationMethod:
printDebugInfo:facesDataRaw:faceDetectorBGRAImage:tempImage:
T{CGRect={CGPoint=dd}{CGSize=dd}},R,V_faceBoundingBox
TQ,R,V_pointCount
_faceBoundingBox
_pointCount
initWithOriginatingRequestSpecifier:faceBoundingBox:pointCount:
faceBoundingBox
pointCount
Tr^,R,V_points
Tr^{CGPoint=dd},R
T@"NSArray",R,V_precisionEstimatesPerPoint
_sizedPointsCache
_pointsCalculatorLock
_points
_precisionEstimatesPerPoint
pointAtIndex:
normalizedPoints
pointsInImageOfSize:
initWithOriginatingRequestSpecifier:faceBoundingBox:points:pointCount:precisionEstimatesPerPoint:
points
precisionEstimatesPerPoint
Tr^,V_points
initWithOriginatingRequestSpecifier:faceBoundingBox:
initWithOriginatingRequestSpecifier:faceBoundingBox:points:pointCount:
setPoints:
T@"NSData",R,C,V_pointsData
T{_Geometry2D_rect2D_={_Geometry2D_point2D_=ff}{_Geometry2D_size2D_=ff}},R,V_alignedBBox
T{CGRect={CGPoint=dd}{CGSize=dd}},R,V_userFacingBBox
_pointsData
_alignedBBox
_userFacingBBox
_createPointArray:count:
isUserFacingBBoxEquivalentToAlignedBBox
initWithOriginatingRequestSpecifier:pointsData:pointCount:userFacingBBox:alignedBBox:landmarkScore:
pointsData
alignedBBox
userFacingBBox
landmarkPointSizeInBytes
TQ,R,V_constellation
T@"NSArray",C,V_precisionEstimatesPerPoint
T@"VNFaceLandmarkRegion2D",R,V_allPoints
T@"VNFaceLandmarkRegion2D",R,V_faceContour
T@"VNFaceLandmarkRegion2D",R,V_leftEye
T@"VNFaceLandmarkRegion2D",R,V_rightEye
T@"VNFaceLandmarkRegion2D",R,V_leftEyebrow
T@"VNFaceLandmarkRegion2D",R,V_rightEyebrow
T@"VNFaceLandmarkRegion2D",R,V_nose
T@"VNFaceLandmarkRegion2D",R,V_noseCrest
T@"VNFaceLandmarkRegion2D",R,V_medianLine
T@"VNFaceLandmarkRegion2D",R,V_outerLips
T@"VNFaceLandmarkRegion2D",R,V_innerLips
T@"VNFaceLandmarkRegion2D",R,V_leftPupil
T@"VNFaceLandmarkRegion2D",R,V_rightPupil
_allPoints
_allPointsLock
_faceContour
_faceContourLock
_leftEye
_leftEyeLock
_rightEye
_rightEyeLock
_leftEyebrow
_leftEyebrowLock
_rightEyebrow
_rightEyebrowLock
_nose
_noseLock
_noseCrest
_noseCrestLock
_medianLine
_medianLineLock
_outerLips
_outerLipsLock
_innerLips
_innerLipsLock
_leftPupilLock
_rightPupilLock
initWithOriginatingRequestSpecifier:pointsData:pointCount:constellation:precisionEstimatesPerPoint:userFacingBBox:alignedBBox:landmarkScore:
allPoints
faceContour
_createFaceLandmarks2DRegionFromPointIndexes:andPointCount:
leftEye
rightEye
leftEyebrow
rightEyebrow
nose
noseCrest
medianLine
outerLips
innerLips
leftPupil
rightPupil
setPrecisionEstimatesPerPoint:
_createNSArrayFrom:withPointIndices:andPointCount:
T@"VNFaceLandmarkRegion3D",R,V_allPoints
T@"VNFaceLandmarkRegion3D",R,V_faceContour
T@"VNFaceLandmarkRegion3D",R,V_leftEye
T@"VNFaceLandmarkRegion3D",R,V_rightEye
T@"VNFaceLandmarkRegion3D",R,V_leftEyebrow
T@"VNFaceLandmarkRegion3D",R,V_rightEyebrow
T@"VNFaceLandmarkRegion3D",R,V_nose
T@"VNFaceLandmarkRegion3D",R,V_noseCrest
T@"VNFaceLandmarkRegion3D",R,V_medianLine
T@"VNFaceLandmarkRegion3D",R,V_outerLips
T@"VNFaceLandmarkRegion3D",R,V_innerLips
torsoprintForImageBuffer:requestRevision:error:
validateNonZeroImageWidth:height:componentNameProvidingBlock:error:
validateArray:named:hasElementsOfClass:requiredMinimumCount:allowedMaximumCount:error:
validateClassArray:named:hasElementsAncestoredFromClass:requiredMinimumCount:allowedMaximumCount:error:
_validateFaceObservations:withMinimumCount:forOptionalRequest:error:
_validateDetectedObjectObservations:forObservationClass:withMinimumCount:forOptionalRequest:error:
validateRequiredFaceObservations:error:
validateRequiredFaceObservations:forRequest:error:
validateOptionalFaceObservations:error:
validateOptionalFaceObservations:forRequest:error:
validateRequiredDetectedObjectObservations:forObservationClass:error:
validateRequiredDetectedObjectObservations:forObservationClass:forRequest:error:
validateOptionalDetectedObjectObservations:forObservationClass:error:
validateOptionalDetectedObjectObservations:forObservationClass:forRequest:error:
validateRequiredClusterIDs:error:
validateVNConfidenceRange:error:
validateScoreRange:error:
requiredObjectOfClass:forKey:inOptions:error:
getBOOLValue:forKey:inOptions:error:
getBOOLValue:forKey:inOptions:withDefaultValue:error:
getNSUIntegerValue:forKey:inOptions:error:
getNSIntegerValue:forKey:inOptions:withDefaultValue:error:
getNSUIntegerValue:forKey:inOptions:withDefaultValue:error:
getIntValue:forKey:inOptions:error:
getIntValue:forKey:inOptions:minimumValue:maximumValue:error:
getIntValue:forKey:inOptions:withDefaultValue:error:
getFloatValue:forKey:inOptions:minimumValue:maximumValue:error:
getPercentageValue:forKey:inOptions:withDefaultValue:error:
getOSTypeValue:forKey:inOptions:error:
getOSTypeValue:forKey:inOptions:withDefaultValue:error:
getMTLGPUPriority:forKey:inOptions:withDefaultValue:error:
getArray:forKey:inOptions:withElementsOfClass:requiredMinimumCount:allowedMaximumCount:error:
requiredArrayForKey:inOptions:withElementsOfClass:error:
requiredFaceObservationInOptions:withOptionName:error:
faceObservationsInOptions:withOptionName:error:
requiredDetectedObjectObservationInOptions:withOptionName:forObservationClass:error:
requiredSessionInOptions:error:
originatingRequestSpecifierInOptions:error:
originatingRequestSpecifierForKey:inOptions:error:
originatingRequestSpecifierInOptions:specifyingSupportedRevisionsForRequestClass:error:
originatingRequestSpecifierForKey:inOptions:specifyingSupportedRevisionsForRequestClass:error:
getOptionalOriginatingRequestSpecifier:forKey:inOptions:specifyingSupportedRevisionsForRequestClass:error:
requiredProcessingDeviceInOptions:error:
getOptionalExplicitProcessingDevice:inOptions:error:
landmarkDetectorDNNVersion
_adjustments
initWithOriginatingRequestSpecifier:adjustments:
adjustmentKeys
hasAdjustmentForKey:
adjustmentValuesForKey:
initWithDictionary:copyItems:
T@"NSSet",R,C
_identifiers
initWithIdentifiers:
identifierCount
allIdentifiers
containsIdentifier:
blacklistFromUTF8StringArray:
T@"NSData",&,V_faceprint
T@"NSString",C,V_key
TI,V_platform
TI,V_profile
T@"NSString",C,V_faceprintInputPath
_platform
_profile
_key
_faceprintInputPath
setKey:
platform
setPlatform:
profile
setProfile:
faceprintInputPath
setFaceprintInputPath:
initWithData:forKey:
_imageprintDescriptor
_imageprintType
initWithData:
serializeAsVNImageprintStateAndReturnError:
Tq,R,V_descriptorId
Tf,R,V_quality
T^v,R,V_colorGaborDescriptor
T^v,R,V_sceneClassifierDescriptor
T^v,R,V_imageRegistrationDescriptor
Tq,V_previousLeafId
Tq,V_nextLeafId
Tf,V_nextLeafDescriptorDistance
Tf,V_previousLeafDescriptorDistance
Tq,V_nextLeafTimestampDistance
Tq,V_previousLeafTimestampDistance
Tf,V_nextLeafTotalDistance
Tf,V_previousLeafTotalDistance
T@"NSData",R,V_rawColorGaborDescriptor
T@"NSString",R,V_imageFilePath
_quality
_nextLeafDescriptorDistance
_previousLeafDescriptorDistance
_nextLeafTotalDistance
_previousLeafTotalDistance
_descriptorId
_colorGaborDescriptor
_sceneClassifierDescriptor
_imageRegistrationDescriptor
_previousLeafId
_nextLeafId
_nextLeafTimestampDistance
_previousLeafTimestampDistance
_rawColorGaborDescriptor
descriptorId
quality
colorGaborDescriptor
sceneClassifierDescriptor
imageRegistrationDescriptor
previousLeafId
setPreviousLeafId:
nextLeafId
setNextLeafId:
nextLeafDescriptorDistance
setNextLeafDescriptorDistance:
previousLeafDescriptorDistance
setPreviousLeafDescriptorDistance:
nextLeafTimestampDistance
setNextLeafTimestampDistance:
previousLeafTimestampDistance
setPreviousLeafTimestampDistance:
nextLeafTotalDistance
setNextLeafTotalDistance:
previousLeafTotalDistance
setPreviousLeafTotalDistance:
rawColorGaborDescriptor
shortValue
longValue
T@"NSNumber",&,N,V_faceCoreMinFaceSize
T@"NSNumber",&,N,V_faceCoreNumberOfDetectionAngles
TB,N,V_faceCoreEnhanceEyesAndMouthLocalization
TB,N,V_faceCoreExtractBlink
TB,N,V_faceCoreExtractSmile
Tf,N,V_faceCoreKalmanFilter
_faceCoreEnhanceEyesAndMouthLocalization
_faceCoreExtractBlink
_faceCoreExtractSmile
_faceCoreKalmanFilter
_faceCoreMinFaceSize
_faceCoreNumberOfDetectionAngles
faceCoreMinFaceSize
setFaceCoreMinFaceSize:
faceCoreNumberOfDetectionAngles
setFaceCoreNumberOfDetectionAngles:
faceCoreEnhanceEyesAndMouthLocalization
setFaceCoreEnhanceEyesAndMouthLocalization:
faceCoreExtractBlink
setFaceCoreExtractBlink:
faceCoreExtractSmile
setFaceCoreExtractSmile:
faceCoreKalmanFilter
setFaceCoreKalmanFilter:
dataUsingEncoding:allowLossyConversion:
initWithData:encoding:
emptyTorsoprintDataForRevision:
T@"NSSet",R,N
_imageInputKey
_buffer
_scenePrint
_scenePrintMLMultiArrayDataType
_featureProvider
featureValueForName:
featureNames
initWithBuffer:forKey:originalFeatureProvider:
initWithScenePrint:dataType:forKey:originalFeatureProvider:
featureValueFromScenePrint:dataType:
featureValueWithPixelBuffer:
featureValueWithMultiArray:
initWithDataPointer:shape:dataType:strides:deallocator:error:
T@"<NSObject><NSCopying>",R,C,N
T@"MLModel",&,V_model
Ti,V_modelType
T@"NSString",&,V_inputImageKey
T@"NSString",&,V_predictedFeatureKey
T@"NSString",R,V_predictedProbabilitiesKey
T@"MLObjectBoundingBoxOutputDescription",R,V_boundingBoxOutputDescription
TQ,R,V_inputImageWidth
TQ,R,V_inputImageHeight
TI,R,V_inputImageFormat
TQ,R,V_scenePrintRevision
T@"NSString",&,V_inputScenePrintKey
Tq,R,V_inputScenePrintMLMultiArrayDataType
T@"<MLFeatureProvider>",&,N,V_featureProvider
_uuidStringForCacheIdentifier
_modelType
_inputImageFormat
_model
_inputImageKey
_predictedFeatureKey
_predictedProbabilitiesKey
_boundingBoxOutputDescription
_inputImageWidth
_inputImageHeight
_scenePrintRevision
_inputScenePrintKey
_inputScenePrintMLMultiArrayDataType
initWithMLModel:error:
setInputImageFeatureName:
inputImageFeatureName
setupInputImageFromModelDescription:
_updateModelWithFlexibleImageConstraintUsingWidth:height:
predictWithCVPixelBuffer:options:error:
predictWithScenePrint:options:error:
cachingIdentifier
featureProvider
setFeatureProvider:
model
setModel:
modelType
setModelType:
inputImageKey
setInputImageKey:
predictedFeatureKey
setPredictedFeatureKey:
predictedProbabilitiesKey
boundingBoxOutputDescription
inputImageWidth
inputImageHeight
inputImageFormat
scenePrintRevision
inputScenePrintKey
setInputScenePrintKey:
inputScenePrintMLMultiArrayDataType
predictionFromFeatures:options:error:
pixelsHigh
pixelsWide
allowedImageSizeClosestToPixelsWide:pixelsHigh:preferDownScaling:preferInputAspectRatio:
sizeConstraint
imageConstraint
inputDescriptionsByName
modelDescription
pixelFormatType
dataType
multiArrayConstraint
postVisionFeaturePrintModel
featureExtractorParameters
visionFeaturePrintInfo
predictedProbabilitiesName
outputDescriptionsByName
objectBoundingBoxOutputDescription
predictedFeatureName
modelForMLModel:error:
T@"VNCoreMLModel",R,V_model
initWithOptions:model:error:
imageBufferValue
labelNames
shape
multiArrayValue
confidenceFeatureName
coordinatesFeatureName
dictionaryValue
_frameworkOperationPointsIdentifier
_nonframeworkDataURL
_labelToOperationPointsDataIndexMap
_operationPointsDataArray
_cachedHashValue
initWithLabelToOperationPointsDataIndexMap:operationPointsDataArray:
_operationPointsDataForClassificationIdentifier:error:
_allClassificationIdentifiers
_propertyListRepresentation
loadFromPropertyList:error:
loadFromIdentifier:error:
URLForIdentifier:error:
propertyListWithStream:options:format:error:
inputStreamWithURL:
TQ,R,N,V_profile
Td,R,N,V_faceSize
Td,R,N,V_faceAngle
T{CGPoint=dd},R,N,V_faceCenter
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,V_faceBoundingBox
T{CGPoint=dd},R,N,V_leftEye
T{CGPoint=dd},R,N,V_rightEye
T{CGPoint=dd},R,N,V_mouth
Tq,R,N,V_trackID
TQ,R,N,V_trackDuration
T@"NSDictionary",R,N,V_features
_faceSize
_faceAngle
_trackID
_trackDuration
_features
_faceCenter
_mouth
initWithFace:
faceSize
faceAngle
faceCenter
mouth
trackID
trackDuration
features
_setFaceExpressionFeatureScoreIfDetected:features:detectionKey:scoreKey:featureKey:
expressionFeatures
face
faceType
initWithImageCropAndScaleOption:
addOriginalRequest:
anyObject
computeImageDescriptorsWithImage:regionOfInterest:usingDescriptorProcessor:tileCount:augmentationMode:scalingImage:resultantDescriptorBuffer:debugIntermediatesDumpPath:outputDebugDictionary:options:metalContext:canceller:error:
computeLabelsAndConfidence:usingDescriptorBuffer:populateLabelsAndConfidence:options:metalContext:error:
classifyImageWithDescriptors:usingImageClassifier:andMinConfidenceForClassification:outputDebugDictionary:options:metalContext:error:
classifyImageHierarchicallyWithDescriptors:usingImageClassifier:hierarchicalClassifier:minimumClassificationConfidence:minimumClassificationConfidenceRatio:maximumLeafLabels:maximumHierarchicalLabels:outputDebugDictionary:options:metalContext:error:
T@"NSNumber",C,N,V_timeStamp
_timeStamp
timeStamp
setTimeStamp:
UID_counter
internalParabolas
parabolaSearchBuffer
internalParams
_observedParabolas
_forestAlgoParams
_validatedImageBuffersFromOptions:error:
_validatedOpticalFlowOptions:width:height:error:
_createVectorResultPixelBufferWidth:height:pixelFormat:error:
_calculateLKTVectorResult:fromPixelBuffer:toPixelBuffer:opticalFlowOptions:error:
_createOpticalFlowForPixelBuffer:opticalFlowOptions:error:
_initializedLKTMetalContextAndReturnError:
T{?=qiIq},V_frameAnalysisSpacing
T@"NSUUID",R,V_requestUUID
frameAnalysisSpacing
setFrameAnalysisSpacing:
requestUUID
T@"NSUUID",R
T{?=qiIq},R
initWithFrameAnalysisSpacing:completionHandler:
minimumLatencyFrameCount
requestFrameAnalysisSpacing
_screenGaze
screenGazeRawOutputInCentimeters
TQ,R,N,V_outputBufferWidth
TQ,R,N,V_outputBufferHeight
T@"NSData",R,N,V_outputBufferData
TQ,R,N,V_numberOfFaceSegments
T@"NSDictionary",R,N,V_faceSegmentLabelToProbabilityMap
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,V_boundingBox
_outputBufferWidth
_outputBufferHeight
_outputBufferData
_numberOfFaceSegments
_faceSegmentLabelToProbabilityMap
_probabilityNormSums
initWithRequestRevision:outputBufferWidth:outputBufferHeight:outputBufferData:numberOfFaceSegments:faceSegmentBBox:faceSegmentLabelToProbabilityMap:
createMaskImageOfFaceSegments:error:
createProbabilityImageOfFaceSegment:error:
createProbabilityImageOfFaceSegment:region:normalize:error:
_normalizeRegion:
_makeFaceSegmentProbabilityDataImageBuffer:rect:
_createFaceSegmentProabilityDataPixelBufferWithSize:error:
_calculateProbabilityNormalSumsForRect:
outputBufferWidth
outputBufferHeight
outputBufferData
numberOfFaceSegments
faceSegmentLabelToProbabilityMap
faceSegmentToSegmentMaskGrayLevelDictionary
faceSegmentIndexToFlagMap
faceSegmentsPixelSizeInBytes
Tr^v,R,N
resourcePath
T@"NSString",&,N
T^{__sFILE=*iiss{__sbuf=*i}i^v^?^?^?^?{__sbuf=*i}^{__sFILEX}i[3C][1C]{__sbuf=*i}iq},R,N
m_impl
setResourcePath:
ptrFile
advise:
baseAddress
length
initWithMappedModel:
load:
unload:
purgeAll
useFOpenForModelWithPath:
sharedInstance
detectorCache:didCacheDetector:
detectorCache:didEvictDetector:
globalSession
_frameworkManager
_detectorCache_onlyAccessWithDetectorAccessingLock
_requestedTrackerUUIDsAccessLock
_requestedTrackerUUIDs
releaseCachedResources
releaseCachedResourcesWithCompletionBlock:
_cachedDetectorOfClass:configuredWithOptions:
_releaseDetectorsThatCanBeReplacedByDetectorOfClass:withConfiguration:
_weakSession
sessionAndReturnError:
boundingCircleForContour:error:
boundingCircleForPoints:error:
boundingCircleForSIMDPoints:pointCount:error:
calculateArea:forContour:orientedArea:error:
calculatePerimeter:forContour:error:
Tq,R,V_internalNonSerializedDescriptorId
_internalNonSerializedDescriptorId
initWithImageData:context:error:
initWithImageData:andCustomQualityScore:context:error:
computeConvnetDescriptorForImageData:context:error:
computeDescriptorForImageData:context:error:
computeRegistrationFeaturesForImageData:context:error:
distanceFromDescriptor:
computeFinalDescriptorBasedDistanceForColorDistance:andSceneClassifierDistance:
initWithRawColorGaborDescriptor:
numberWithShort:
numberWithLong:
_faceBoundingBoxExpansionRatio
setFaceBoundingBoxExpansionRatio:
faceBoundingBoxExpansionRatio
expansionRatioWithinValidRange:
defaultFaceBoundingBoxExpansionRatio
beginRangeFaceBoundingBoxExpansionRatio
endRangeFaceBoundingBoxExpansionRatio
_determineFacesToProcessFrom:outputFacesThatNeedNoProcessing:outputFacesThatNeedAlignment:outputfacesThatNeedSegments:
TQ,N,V_faceCoreType
Tf,N,V_precisionRecallThreshold
_precisionRecallThreshold
_faceCoreType
setPrecisionRecallThreshold:
precisionRecallThreshold
faceCoreType
setFaceCoreType:
_detectorTypeForRevision:error:
TB,N,V_detectionOnly
TB,N,V_usesLanguageDetection
TB,N,V_usesAlternateLineGrouping
TQ,N,V_maximumCandidateCount
_detectionOnly
_usesLanguageDetection
_usesAlternateLineGrouping
_maximumCandidateCount
detectionOnly
setDetectionOnly:
usesLanguageDetection
setUsesLanguageDetection:
usesAlternateLineGrouping
setUsesAlternateLineGrouping:
maximumCandidateCount
setMaximumCandidateCount:
T@"VNDetectBarcodesRequest",&,N,V_barcodeRequest
T@?,C,N,VprogressHandler
TB,R,Vindeterminate
T@"NSArray",C,N,VinputTextBlocks
indeterminate
progressHandler
inputTextBlocks
_barcodeRequest
setInputTextBlocks:
T@?,C,N
setProgressHandler:
setRecognitionLanguages:
recognitionLanguages
setCustomWords:
customWords
setRecognitionLevel:
recognitionLevel
setUsesLanguageCorrection:
usesLanguageCorrection
setMinimumTextHeight:
minimumTextHeight
supportedRecognitionLanguagesAndReturnError:
barcodeRequest
setBarcodeRequest:
supportedRecognitionLanguagesForTextRecognitionLevel:revision:error:
_determineFacesToProcessFrom:outputFacesThatNeedNoProcessing:outputFacesThatNeedFaceQuality:
_vectorProjections
initWithXComponent:yComponent:
initWithR:theta:
initWithVectorHead:tail:
theta
squaredLength
T@"VNVector",R
zeroVector
unitVectorForVector:
vectorByMultiplyingVector:byScalar:
vectorByAddingVector:toVector:
vectorBySubtractingVector:fromVector:
dotProductOfVector:vector:
fileExistsAtPath:
removeItemAtPath:error:
copyItemAtPath:toPath:error:
moveItemAtPath:toPath:error:
TB,N,V_returnAllResults
_returnAllResults
returnAllResults
setReturnAllResults:
_operationPointsCache
initWithOperationPointsCache:originatingRequestSpecifier:
sceneLabelOperationPointsForOriginatingRequestSpecifier:error:
_defaultSceneClassificationHierarchicalModel
_imageAnalyzerJunkCustomClassifiers
_imageAnalyzerPCA256
_VNVYvzEtX1JlUdu8xx5qhDICustomClassifiers
_potentialLandmarkCustomClassifiers
_VN5kJNH3eYuyaLxNpZr5Z7ziCustomClassifiers
_significantEventCustomClassifiers
_cachedAllSceneClassificationsFromLastAnalysis
_cachedSaliencyHeatmapBoundingBoxGenerators
_junkObservationsForLastAnalysisWithOptions:error:
hasObjDetNet
hasSliderNet
allSceneIdentifiersWithOptions:error:
allJunkIdentifiersForOptions:error:
allRecognizedObjectsIdentifiersWithOptions:error:
allVN5kJNH3eYuyaLxNpZr5Z7ziIdentifiersWithOptions:error:
allSignificantEventIdentifiersWithOptions:error:
arrayByAddingObjectsFromArray:
indexOfObject:inSortedRange:options:usingComparator:
createHierarchicalModelForMultiDetectorModel:error:
_inputImageBlobNameForModel:configuredWithOptions:
_analyzerNameForModel:configuredWithOptions:
initWithDetectorModel:
_detectorModel
_originatingRequestSpecifierToOperationPoints
modelForRequestClass:revision:
blacklistForModel:
isSubsetOfSet:
Tf,N,V_contrastAdjustment
T@"NSNumber",&,N,V_contrastPivot
TB,N,V_detectsDarkOnLight
TQ,N,V_maximumImageDimension
TB,N,V_inHierarchy
TB,N,V_forceUseInputCVPixelBufferDirectly
_detectsDarkOnLight
_inHierarchy
_forceUseInputCVPixelBufferDirectly
_contrastAdjustment
_contrastPivot
contrastAdjustment
setContrastAdjustment:
contrastPivot
setContrastPivot:
detectsDarkOnLight
setDetectsDarkOnLight:
maximumImageDimension
setMaximumImageDimension:
inHierarchy
setInHierarchy:
forceUseInputCVPixelBufferDirectly
setForceUseInputCVPixelBufferDirectly:
detectDarkOnLight
setDetectDarkOnLight:
TB,V_recognize
TB,V_generateSegmentationMask
_recognize
_generateSegmentationMask
recognize
setRecognize:
generateSegmentationMask
setGenerateSegmentationMask:
newConfiguration
T@"VNRecognizeDocumentElementsRequestElementConfiguration",R,V_documentElements
T@"VNRecognizeDocumentElementsRequestElementConfiguration",R,V_textElements
T@"VNRecognizeDocumentElementsRequestElementConfiguration",R,V_machineReadableCodeElements
_documentElements
_textElements
_machineReadableCodeElements
documentElements
textElements
machineReadableCodeElements
T@"VNRecognizeDocumentElementsRequestElementConfiguration",R
_torsoprintGenerator
addAllPersonsFromPersonsModel:error:
addPersonWithUniqueIdentifier:fromPersonsModel:error:
modelFromPersonsModel:error:
T^f,VfloatVectorSumProd
T*,VpulseVectorHeightCharBox
T*,VpulseVectorHeightCharBoxAdaptive
T^Q,VcharBoxFlags
T^S,VcharboxROIFullVectorRowStart
T^S,VcharboxROIFullVectorHeight2
TI,VallocationSize
Tf,VmTop
Tf,VmBottom
Tf,VbTop
Tf,VbBottom
Tf,VposUL
Tf,VposLL
Tf,VposUR
Tf,VposLR
TS,VmedianHeightTop
TS,VmedianHeightBottom
Ts,VloopBigBox
Ts,VloopBigBoxPrev
TS,VfilterWalkUpDownCount
medianHeightTop
medianHeightBottom
loopBigBox
loopBigBoxPrev
filterWalkUpDownCount
allocationSize
mTop
mBottom
bTop
bBottom
posUL
posLL
posUR
posLR
floatVectorSumProd
pulseVectorHeightCharBox
pulseVectorHeightCharBoxAdaptive
charBoxFlags
charboxROIFullVectorRowStart
charboxROIFullVectorHeight2
setFlag:atIndex:
clearFlag:atIndex:
checkFlag:atIndex:
copyFlagValue:toTarget:atIndex:
resetBoxBounds
makeAllocationsForWidth:
releaseAllocations
setFloatVectorSumProd:
setPulseVectorHeightCharBox:
setPulseVectorHeightCharBoxAdaptive:
setCharBoxFlags:
setCharboxROIFullVectorRowStart:
setCharboxROIFullVectorHeight2:
setAllocationSize:
setMTop:
setMBottom:
setBTop:
setBBottom:
setPosUL:
setPosLL:
setPosUR:
setPosLR:
setMedianHeightTop:
setMedianHeightBottom:
setLoopBigBox:
setLoopBigBoxPrev:
setFilterWalkUpDownCount:
TB,V_computeZCVectorHighProbability
Ti,V_midRow
TI,V_minHeight
TI,V_maxHeight
TI,V_startMaxFind
TI,V_stopMaxFind
Tf,V_mmHeightCard
Tf,V_mmWidthCard
TI,V_pixelHeightCard
TI,V_pixelWidthCard
TI,V_minBoxWidth
TI,V_maxBoxWidth
TI,V_startNormal
TI,V_stopNormal
TI,V_startSensitized
TI,V_stopSensitized
T@"CCCharBoxContext",&,V_charBoxContext
TC,V_ii
TC,V_profileNormal
TB,V_debugMatlab
TB,V_debugOut
T@"NSString",C,V_debugFilename
_getFilter_callCount
_computeZCVectorHighProbability
_profileNormal
_debugMatlab
_debugOut
_midRow
_minHeight
_maxHeight
_startMaxFind
_stopMaxFind
_mmHeightCard
_mmWidthCard
_pixelHeightCard
_pixelWidthCard
_minBoxWidth
_maxBoxWidth
_startNormal
_stopNormal
_startSensitized
_stopSensitized
_charBoxContext
_debugFilename
initWithOptions:
initializeForImage:
_allocateVImageWithWidth:height:rowBytes:imageOut:
_freeVImage:
_generateVotingImage:votingImage:useLowLightEnhancement:
examinePulseWindow:prodBoostNormalized:pwContext:minHeight:maxHeight:thresholdSet:
generatePulses:minHeight:maxHeight:thresholdSet:prodBoostNormalized:pulseVectorFlag:
_computeColumnSumsOverRange:sampleImageAddress:rowSumOut:rowDerivOut:
_allocateSumDerivVectors:size:
_freeSumDerivVectors:
_computeProdBoostNormalizedResult:size:binOverride:
_getFilterResultOutBothSumDeriv:floatVectorResult:bufferHeight:minHeight:maxHeight:config:bytesPerRow:thresholdSet:sampleImageAddressRef:
_getFilterResultOut:defaultRows:bufferHeight:minHeight:maxHeight:startRange:stopRange:startMaxFind:stopMaxFind:bytesPerRow:thresholdSet:sampleImageAddressRef:sampleImageFloatAddressRef:pulseVectorFlag:
_generatePulseAggregate:pulseVectorMain:pulseVectorResult:metricSelection:bufferHeight:bufferWidth:
_generatePulseAggregateSmallStubs:pulseVectorResult:bufferHeight:bufferWidth:
generateDominantPulse:rowLocationsRef:debugOut:bufferHeight:bufferWidth:
generateHistogramBounds:rgbVector2Ref:numPixels1:numPixels2:minMaxRGB:lowHighRGB:
_generateBinarizationForImage:textOut:firstOrSecondPassIndicator:minMaxRGB:
createLumaImage:lumaImage:numCropRows:rowStartLocation:
createLumaImageAlternative:lumaImageAlternative:numCropRows:rowStartLocation:
getVotingHistogram:colorProfileContext:startCC:rowStartLocation:
getLumaHistogram:startCC:colorProfileContext:
computeNumCropCols:width:start:
computeMainStub:numCropRows:numCropColsOut:maxY:start:
determineColorProfileType:
allocateColorProfileContext:width:height:rowBytes:
freeColorProfileContext:
_generateAndApplyColorProfileForImage:votingImage:textOut:minMaxRGB:lowHighRGB:numCropRows:rowStartLocation:rowStopLocation:sumTextOutFirstPass:useLowLightEnhancement:
_generateAdaptiveBinarization:adaptImage:useLowLightEnhancement:
_generateSmoothedImage:uImage:
_generateBoxes:pulseVector:uImage:countBigBoxOut:bigBoxes:bigBoxesA:useLowLightEnhancement:
_generateCC:ccBigBoxes:textOut:countBigBox:bufferHeight:
groupEndpoints:finalCharBoxCoordCount:
computeIndependentTopAndBottomComponents:finalCharBoxCoordCount:
computeDependentTopAndBottomComponents:finalCharBoxCoordCount:
_generateCRCharBoxInformation_TrackBox:finalCharBoxCoordCount:
computePulseVectorSum:start:stop:imageHeight:imageWidth:bottomHeight:topHeight:
tightenBox:startTop:startBottom:startPosition:stopPosition:imageHeight:halfWalk:
_generateCRCharBoxInformation_spaceBoxRemovalTightenBox:singleVotingImageAddressRef:adaptOut:textOut:zcStartLeft:zcStopRight:finalCoordinatesForStub:finalCoordinatesForStubRevised:finalCharBoxCoordCount:useLowLightEnhancement:
_generateCRCharBoxInformation_spaceBoxRemovalTruthFilter:magicThresh:zcStartLeft:zcStopRight:isSpaceBoxAccepted:histCompliancePercent:useLowLightEnhancement:
_generateCRCharBoxInformation_spaceBoxRemovalHistogram:zcStartLeft:zcStopRight:rowStartLocation2:lowHighRGB:histCompliancePercent:varSpaceBox:
_generateCRCharBoxInformation_spaceBoxRemovalMagicThresh:magicMinHeight:magicMaxHeight:rowStartLocation2:magicThresh:magicThreshPrev:useLowLightEnhancement:
_extractCharBoxCuts:heightConstraint:medianHeightTopVector:medianHeightBottomVector:isAdaptive:
_generateFilteredPulseVector:target:height:
_generateZeroCrossingVector:zcVectorFlag:width:
calculateSumProd:prodROIRef:prodROIRotateRef:rowStartLocation2:height:
calculateSumProdAlternative:prodROIRef:prodROIRotateRef:rowStartLocation2:height:
extractCharBoxHeightInfo:ccCharBoxesFiltered:ccYTopLocationsForSort:ccYBottomLocationsForSort:aggregateGreenBoxesForStubCount:imageWidth:
charBoxesFromTextBoxes:bigBoxes:ccYTopLocationsForSort:ccYBottomLocationsForSort:
extractBoxesForStub:bigBoxesAdapt:countBigBox:rowStartLocation2:rowStopLocation2:heightConstraint:imageWidth:height:ccCharBoxesAggr:ccCharBoxesFiltered:useLowLightEnhancement:
_generateCRCharBoxInformation_zcFinalVectorOriginate:textOut:adaptOut:bigBoxes:bigBoxesAdapt:ccCharBoxesAggr:ccCharBoxesFiltered:height:rowStartLocation2:rowStopLocation2:singleVotingImageAddressRef:countBigBox:filterWalkUpDownCount:useLowLightEnhancement:
_generateCRCharBoxInformation_zcFinalVectorHighProbability:zcFinalRange:
fillInOneVector:checkFlag:checkHeight:
_generateCRCharBoxInformation_zcFinalVectorFillIn:
_allocateCRCharBoxContext:
_freeCRCharBoxContext
_generateCRCharBoxInformation_extendTextBoxes:countBigBox:rowStartLocation2:finalCharBoxCoordCount:finalCoordinatesForStubRevised:width:height:bigBoxIndicator:
_generateCRCharBoxInformation:inputImage:singleVotingImageAddressRef:bigBoxes:bigBoxesAdapt:textOut:adaptOut:lowHighRGB:countBigBox:useLowLightEnhancement:
_generatePulseVectorOutputs:votingImage:rowLocationsRef:
textBoxesForBuffer:error:
textBoxesForImage:originatingRequestSpecifier:error:
charBoxContext
setCharBoxContext:
computeZCVectorHighProbability
setComputeZCVectorHighProbability:
midRow
setMidRow:
minHeight
setMinHeight:
maxHeight
setMaxHeight:
startMaxFind
setStartMaxFind:
stopMaxFind
setStopMaxFind:
mmHeightCard
setMmHeightCard:
mmWidthCard
setMmWidthCard:
pixelHeightCard
setPixelHeightCard:
pixelWidthCard
setPixelWidthCard:
minBoxWidth
setMinBoxWidth:
maxBoxWidth
setMaxBoxWidth:
startNormal
setStartNormal:
stopNormal
setStopNormal:
startSensitized
setStartSensitized:
stopSensitized
setStopSensitized:
setIi:
profileNormal
setProfileNormal:
debugMatlab
setDebugMatlab:
debugOut
setDebugOut:
debugFilename
setDebugFilename:
T@"NSIndexSet",C,V_acceptableVersions
_observationsCache
observationsForKey:
setObservations:forKey:
observationsAcceptedByRequest:testedKeyHandler:
T@"VNEspressoResources",R,N,V_espressoResources
TQ,R,N,V_networkRequiredInputImageWidth
TQ,R,N,V_networkRequiredInputImageHeight
TQ,R,N,V_inputImageAspectRatioHandling
_espressoResources
_networkRequiredInputImageWidth
_networkRequiredInputImageHeight
_inputImageAspectRatioHandling
espressoModelNetworkLayersStorageTypeForConfigurationOptions:
getWidth:height:ofEspressoModelNetworkBlobNamed:error:
bindBuffer:toNetworkInputBlobName:error:
bindBuffer:toNetworkOutputBlobName:error:
_bindBuffer:toNetworkBlobName:bindMode:error:
bindLockedPixelBuffer:toNetworkInputBlobName:error:
executePlanAndReturnError:
espressoResources
networkRequiredInputImageWidth
networkRequiredInputImageHeight
inputImageAspectRatioHandling
T@"NSArray",C,N,V_recognitionLanguages
T@"NSArray",C,N,V_customWords
Tq,N,V_recognitionLevel
TB,N,V_usesLanguageCorrection
Tf,N,V_minimumTextHeight
_usesLanguageCorrection
_minimumTextHeight
_recognitionLanguages
_customWords
_recognitionLevel
TQ,N,V_requestRevision
T@"CRImageReaderOutput",R,C,V_crOutput
_crOutput
initWithRequestRevision:CRImageReaderOutput:
string
boundingBoxForRange:error:
setRequestRevision:
crOutput
pointValue
cornersForCharacterRange:error:
TQ,R,V_topLevelIndex
T@"NSIndexPath",R,V_indexPath
Tr^,R
Tf,R,V_aspectRatio
_contourPoints
_topLevelIndex
_aspectRatio
_indexPath
initWithPoints:topLevelIndex:indexPath:aspectRatio:
indexPath
childContourCount
childContours
childContourAtIndex:error:
polygonApproximationWithEpsilon:error:
topLevelIndex
aspectRatio
indexPathWithIndex:
indexPathByAddingIndex:
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_box
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_defaultBox
Ti,N,V_scale
Ti,N,V_mergesCount
Tf,N,V_rotationAngle
Tf,N,V_yawAngle
Tf,N,V_pitchAngle
TB,N,V_hasLabel
Ti,N,V_label
T{CGPoint=dd},R,N
_area
_hasLabel
_mergesCount
_scale
_label
_box
_defaultBox
initWithBox:defaultBox:confidence:scale:rotationAngle:yawAngle:
initWithBox:defaultBox:confidence:scale:rotationAngle:yawAngle:mergesCount:
initWithBox:defaultBox:confidence:scale:rotationAngle:yawAngle:hasLabel:label:
initWithBox:defaultBox:confidence:scale:rotationAngle:yawAngle:pitchAngle:hasLabel:label:
initWithBox:defaultBox:confidence:scale:rotationAngle:yawAngle:mergesCount:hasLabel:label:
initWithBox:defaultBox:confidence:scale:rotationAngle:yawAngle:pitchAngle:mergesCount:hasLabel:label:
boxCenter
distanceToDefaultBox
smartDistance
overlap:
intersectionOverArea:
intersectionOverMinArea:
isOverlappingSmallFace:withOverlapThreshold:withSizeRatio:
isOverlappingLowMergeDet:withOverlapThreshold:withMergeCountDelta:
setBox:
defaultBox
setDefaultBox:
mergesCount
setMergesCount:
scale
setScale:
hasLabel
setHasLabel:
TQ,N,V_requiredVersion
Tf,N,V_minimumAspectRatio
Tf,N,V_maximumAspectRatio
Tf,N,V_quadratureTolerance
Tf,N,V_minimumSize
Tf,N,V_minimumConfidence
TQ,N,V_maximumObservations
_minimumAspectRatio
_maximumAspectRatio
_quadratureTolerance
_minimumSize
_minimumConfidence
_requiredVersion
_maximumObservations
requiredVersion
setRequiredVersion:
minimumAspectRatio
setMinimumAspectRatio:
maximumAspectRatio
setMaximumAspectRatio:
quadratureTolerance
setQuadratureTolerance:
minimumSize
setMinimumSize:
minimumConfidence
setMinimumConfidence:
maximumObservations
setMaximumObservations:
lastDataChangeSequenceNumberForPersonsModel:
numberOfPersonsInPersonsModel:
personsModel:uniqueIdentifierOfPersonAtIndex:
personsModel:indexOfPersonWithUniqueIdentifier:
personsModel:numberOfFaceObservationsForPersonAtIndex:
personsModel:faceObservationAtIndex:forPersonAtIndex:
initWithConfiguration:faceModel:
TB,N,V_useCenterTileOnly
_useCenterTileOnly
useCenterTileOnly
setUseCenterTileOnly:
_detectorTypeForRequestRevision:options:error:
_applicableDetectorForRequestRevision:applicableDetectorOptions:loadedInSession:error:
_applicableDetectorLoadedInSession:error:
_modelDrop
supportedIdentifiersWithOptions:error:
_orderedHandKeypoints
_chirality
initWithVCPHandObservation:originatingRequestSpecifier:
TC,R,D,N
inputBlobNames
outputBlobNames
_requestConstellationToDetectorConstellationMap
T^v,R
_landmarkDetector
getConstellation:cvmlConstellation:fromOptions:error:
getLandmarkPoints:forConstellation:error:
getLandmarkErrorEstimates:forConstellation:error:
getLandmarkOcclusionFlags:forConstellation:error:
translateAndNormalizeLandmarkPointsWrtLLCofAlignedFaceBBox:imageBuffer:outputFace:error:
releaseResources
_requestLock
_requestsInFlight
_requestsPending
_sequencedRequestObservations
_trackerKeys
cancelAllRequests
_validateAndPrepareRequests:error:
_performRequests:onBehalfOfRequest:inContext:error:
_performOrderedRequests:inContext:error:
dependencyAnalyzedRequestsForRequests:withPerformingContext:error:
orderedRequestsForRequests:
performRequests:inContext:error:
performDependentRequests:onBehalfOfRequest:inContext:error:
recordSequencedObservationsForRequest:
previousSequencedObservationsForRequest:
removeObjectIdenticalTo:
_glContext
_validatedImageBufferForKey:inOptions:error:
_createN:CVPixelBuffers:withPixelFormat:width:height:error:
_createHomographicPixelBufferFromImageBuffer:cropRect:options:error:
_calculateHomographicWarpTransform:ofFloatingImagePixelBuffer:ontoReferenceImagePixelBuffer:usingImageRegistrationContext:glContext:seededWithPreviousWarpTransform:error:
T@"NSString",R,N,V_originatingRequestSpecifierKey
TQ,R,N,V_originalRequestResultsIndex
_originatingRequestSpecifierKey
_originalRequestResultsIndex
initWithOriginatingRequestSpecifierProcessingOptionKey:originalRequestResultsIndex:
originatingRequestSpecifierKey
originalRequestResultsIndex
requestKeyFromRequest:
requestClassNameFromRequestKey:
requestPropertiesFromRequestKey:
originatingRequestSpecifierToDetectorClassMap
anfdMultiDetectorClassToProcessRequest:
requestInfoForRequest:
faceDetectorChunkAspectRatio
recognizedAnimalObjectClassToAnimalName
knownAnimalIdentifiers
_printDebugInfo:detectedObjectsRaw:faceDetectorBGRAImage:tempImage:
T@"ShotflowDetector",R,N,V_mMultiHeadedANFDDetector
_mMultiHeadedANFDDetector
_alignFace:imageBuffer:warningRecorder:error:
processRecognizedObjectWithIdentifier:originatingRequestSpecifier:objectBoundingBox:objectConfidence:detectedObjectResults:
shotflowDetector
setArray:
_hierarchicalModel_DO_NOT_ACCESS_DIRECTLY
_additionalRelationships
_originatingRequestDetectionLevel
initWithOriginatingRequestSpecifier:detectionLevel:
hierarchicalModelAndReturnError:
newHierarchicalModelAndReturnError:
_addRelationships:error:
relationships
customHierarchyWithAdditionalParent:children:error:
customHierarchyWithAdditionalRelationships:error:
requestDetectionLevel
initWithArray:copyItems:
stringWithCString:encoding:
customHierarchyForRequest:error:
T@"NSUUID",R,N,V_faceObservationUUID
Tq,R,N,V_direction
TB,R,N
T{CGPoint=dd},R,N,V_location
T@"VNPixelBufferObservation",R,N,V_gazeMask
T@"NSUUID",R,N,V_lookedAtFaceObservationUUID
_faceObservationUUID
_direction
_location
_lookedAtFaceObservationUUID
_gazeMask
hasLocation
faceObservationUUID
direction
lookedAtFaceObservationUUID
gazeMask
_lockStaticObjectsAccessLock
_unlockStaticObjectsAccessLock
defaultDevice
defaultCPUDevice
defaultMetalDevice
deviceForMetalDevice:
defaultANEDevice
directANEDevice
T@"NSArray",R,C,N,V_inputFaceObservations
initWithFaceObservations:
initWithFaceObservations:completionHandler:
_determineFacesToProcessFrom:outputFacesThatNeedNoProcessing:outputFacesThatNeedProcessing:
T@"VN6Ac6Cyl5O5oK19HboyMBR",R,V_imageSignatureprint
T@"VN6B8mkraBUpwUqskMYPtS3",R,V_imageSignatureHash
_imageSignatureprint
_imageSignatureHash
initWithOriginatingRequestSpecifier:imageSignatureprint:imageSignatureHash:
imageSignatureprint
imageSignatureHash
T@"NSString",C,N,V_type
T@"NSString",C,N,V_cachePath
T@"NSData",&,N,V_state
Tf,N,V_threshold
Tf,N,V_torsoThreshold
TQ,N,V_torsoprintRequestRevision
_cachePath
initWithType:cachePath:state:threshold:torsoThreshold:requestRevision:
initWithType:cachePath:state:threshold:requestRevision:
initWithType:cachePath:state:threshold:torsoThreshold:requestRevision:torsoprintRequestRevision:
initWithType:cachePath:state:threshold:
initWithType:cachePath:state:threshold:torsoThreshold:
cachePath
setCachePath:
state
setState:
torsoThreshold
setTorsoThreshold:
torsoprintRequestRevision
setTorsoprintRequestRevision:
clustererQueryWithOptions:error:
clustererBuilderWithOptions:error:
blocks
T@"NSArray",R,N,GgetBlocks
title
T@"VNRecognizedTextBlockObservation",R,N,GgetTitle
transcript
T@"NSString",R,N,GgetTranscript
_topLevelRegion
_blocks
initWithTopLevelRegion:requestRevision:
_textBlockObservationsFromRegion:requestRevision:
getTranscript
getTitle
blocksWithTypes:inRegion:
boundingBoxForTextRange:error:
rangeOfTextBlock:
textBlockOfTypes:containingTextAtIndex:
getBlocks
textBlockWithCharacterRange:
closestTextBlockOfTypes:toPoint:maximumPixelDistance:
getCRDocumentOutputRegion
shouldReprocessDocument
T@"DDScannerResult",&,N,V_scannerResult
T@"NSString",&,N,V_shortDescription
T@"NSString",&,N,V_value
T@"VNObservation",&,N,V_originalObservation
T@"BCSDetectedCode",&,N,V_detectedBarcodeSupportCode
_scannerResult
_shortDescription
_value
_originalObservation
_detectedBarcodeSupportCode
initWithDDScannerResult:observation:
initWithBCSDetectedCode:description:observation:
scannerResult
setScannerResult:
shortDescription
setShortDescription:
value
setValue:
originalObservation
setOriginalObservation:
detectedBarcodeSupportCode
setDetectedBarcodeSupportCode:
category
matchedString
ddResult
contentsWithTypes:
initWithRequestRevision:crOutputRegion:
children
T@"NSArray",R,N,GgetChildren
lines
T@"NSArray",R,N,GgetLines
_crOutputRegion
getChildren
getLines
getCROutputRegion
quadForTextInCharacterRange:
T@"NSAttributedString",R,C,N,V_attributedString
T@"NSArray",R,C,N,V_baselines
_attributedString
_baselines
attributedString
baselines
rawConfidence
boundingQuad
closestContentRegionOfType:toNormalizedPoint:maxPixelDistance:
outputRegionWithContentsOfCharacterRange:
contentRegionOfType:containingTextAtIndex:
rangeOfContentRegion:
predicateWithFormat:
T@"<NSObject><NSCopying>",C,N,V_modelCachingIdentifier
_modelCachingIdentifier
updateWithPropertiesOfModel:
modelCachingIdentifier
setModelCachingIdentifier:
T@"VNCoreMLModel",R,N,V_model
initWithModel:
initWithModel:completionHandler:
Ti,V_debugMode
Ti,V_timerMode
Ti,V_clusterSplitDistanceType
T@"NSArray",&,V_qualityCriteriaList
TB,V_useTimestampAdjustedDistances
TB,V_performClustersPostprocessing
TB,V_performSceneClassification
Tf,V_roiAreaThreshold
Tf,V_inliersRatioThreshold
Ti,V_numberOfKeypointsToConsider
Tf,V_naturalClusteringDistanceThreshold
_useTimestampAdjustedDistances
_performClustersPostprocessing
_performSceneClassification
_debugMode
_timerMode
_clusterSplitDistanceType
_roiAreaThreshold
_inliersRatioThreshold
_numberOfKeypointsToConsider
_naturalClusteringDistanceThreshold
_qualityCriteriaList
debugMode
setDebugMode:
timerMode
setTimerMode:
clusterSplitDistanceType
setClusterSplitDistanceType:
qualityCriteriaList
setQualityCriteriaList:
useTimestampAdjustedDistances
setUseTimestampAdjustedDistances:
performClustersPostprocessing
setPerformClustersPostprocessing:
performSceneClassification
setPerformSceneClassification:
roiAreaThreshold
setRoiAreaThreshold:
inliersRatioThreshold
setInliersRatioThreshold:
numberOfKeypointsToConsider
setNumberOfKeypointsToConsider:
naturalClusteringDistanceThreshold
setNaturalClusteringDistanceThreshold:
T@"NSString",R,V_espressoModelName
_rpnEspressoResourcesKeyToEspressoResourcesCache
_rpnEspressoResourcesKeyToEspressoResourcesCacheLock
_espressoModelName
initWithRPNEspressoModelName:
espressoResourcesFromOptions:error:
espressoModelName
cacheKeyFromOptions:error:
T@"VNRPNTrackerEspressoModelCacheManager",R,C
rpnInitEspressoResourcesCacheManager
rpnTrackEspressoResourcesCacheManager
cacheOptionsKeys
TQ,R,V_imageSignatureprintType
initWithData:elementCount:elementType:lengthInBytes:imageSignatureprintType:originatingRequestSpecifier:
initWithData:elementCount:elementType:lengthInBytes:imageSignatureprintType:requestRevision:
_signaturePrintTypeSupported:
TQ,R,V_imageSignatureHashType
initWithData:elementCount:elementType:lengthInBytes:imageSignatureHashType:requestRevision:
encodeHashDescriptorWithBase64EncodingAndReturnError:
_entityIdentificationModel
initWithEntityIdentificationModel:dataSource:
T@"<VNEntityIdentificationModelDelegate>",&
T@"VNEntityIdentificationModelConfiguration",R,C
T@"VNEntityIdentificationModelInformation",R,C
_delegate_DO_NOT_ACCESS_DIRECTLY
_dataSource_DO_NOT_ACCESS_DIRECTLY
_trainedModel_DO_NOT_ACCESS_DIRECTLY
trainedModelWithCanceller:error:
dropTrainedModel
information
uniqueIdentifierForEntityAtIndex:
observationCountForEntityWithUniqueIdentifier:
observationsForEntityWithUniqueIdentifier:error:
observationCountsForEntitiesWithUniqueIdentifiers:
observationCountsForAllEntities
trainingObservationsForEntityWithUniqueIdentifier:canceller:error:
entityPredictionsForObservation:limit:canceller:error:
indexOfObjectPassingTest:
entityIdentificationModelDidDropTrainingData:
entityIdentificationModelWillDropTrainingData:
entityIdentificationModel:trainingFailedWithError:
didTrainEntityIdentificationModel:
willTrainEntityIdentificationModel:withCanceller:
encodedData
finishEncoding
initRequiringSecureCoding:
modelConfigurationForVersion:modelObjects:error:
validateConfiguration:error:
validateAceptableObservation:forEntityPrintOriginatingRequestSpecifier:error:
supportedRequestSpecifiers
setValue:forKeyPath:
TB,R,N,V_upperBodyOnly
initWithOriginatingRequestSpecifier:boundingBox:upperBodyOnly:confidence:
TQ,R,N,V_preferredSmallSide
_espressoNetwork
_espressoPlan
_espressoContext
_logitsPosOutputs
_logitsNegOutputs
_offsetsOutputs
_rollOutputs
_yawOutputs
_currentNetworkWidth
_currentNetworkHeight
_releaseEspressoContext
_releaseEspressoPlan
isAnchorSquare
_defaultBoxSizes
_preferredSmallSide
initWithModelPath:espressoEngineID:espressoDeviceID:espressoStorageType:threshold:
initWithEspressoNetwork:espressoPlan:threshold:
initializeEspressoResourcesWithModelPath:espressoEngineID:espressoDeviceID:espressoStorageType:
initializeBuffers
setInputShape:height:
runNetwork:inputIsBGR:
processVImage:inputIsBGR:
resizeAndProcessVImage:inputIsBGR:
preferredSmallSide
hasPose
nonSquareYawDefault
nonSquareRollDefault
numberBinsYaw
numberBinsRoll
strides
inputBGR
inputScale
inputBiasRGB
defaultBoxesSides
numberMaxoutLayers
ratios
Tr^v,R,D
cellStartsX
cellStartsY
mumberBinsNegativeMaxout
mumberPosClasses
Tr^v,R
T{tuple<float, float, float>={__tuple_impl<std::__tuple_indices<0, 1, 2>, float, float, float>=fff}},R
poseSquare
TB,R,D
importantClasses
processingDeviceNetworkWithModelPath:threshold:preferredDeviceID:engineID:storageType:
processingDeviceDetectorWithEspressoNetwork:espressoPlan:threshold:
computeBrightnessScore:onImage:error:
decodeArrayOfObjectsOfClasses:forKey:
vn_encodeEntityUniqueIdentifier:forKey:
vn_encodeEntityUniqueIdentifierArray:forKey:
vn_decodeEntityUniqueIdentifierForKey:
vn_decodeEntityUniqueIdentifierArrayForKey:
initWithRectangleObservation:
initWithRectangleObservation:completionHandler:
TB,N,V_isValid
Ti,R,N,V_width
Ti,R,N,V_height
Ti,R,N,V_levelCount
Ti,R,N,V_numScales
Ti,N,V_numWarpings
TB,N,V_useNonLocalRegularization
Ti,N,V_nlreg_radius
Ti,N,V_nlreg_padding
Tf,N,V_nlreg_sigma_l
Tf,N,V_nlreg_sigma_c
Tf,N,V_nlreg_sigma_w
_isValid
_useNonLocalRegularization
_width
_height
_levelCount
_numScales
_numWarpings
_nlreg_radius
_nlreg_padding
_nlreg_sigma_l
_nlreg_sigma_c
_nlreg_sigma_w
_validateInputImage:error:
_validateOutputImage:error:
isValid
setIsValid:
levelCount
numScales
numWarpings
setNumWarpings:
useNonLocalRegularization
setUseNonLocalRegularization:
nlreg_radius
setNlreg_radius:
nlreg_padding
setNlreg_padding:
nlreg_sigma_l
setNlreg_sigma_l:
nlreg_sigma_c
setNlreg_sigma_c:
nlreg_sigma_w
setNlreg_sigma_w:
faceprintRequestRevisionForFaceTorsoRequestRevision:error:
torsoprintRequestRevisionForFaceTorsoRequestRevision:error:
TB,N,V_forceFaceprintCreation
_forceFaceprintCreation
setForceFaceprintCreation:
forceFaceprintCreation
TB,V_forceFaceprintCreation
_determineFacesToProcessFrom:outputFacesThatNeedNoProcessing:outputFacesThatNeedAlignment:outputFacesThatNeedFaceprints:
TQ,R,N,V_imageSignatureprintType
TQ,R,N,V_imageSignatureHashType
_hyperplaneLSHProcessor
_calculateImageSignatureprintDescriptorFromOptions:error:
_calculateImageSignatureHashDescriptorFrom:options:error:
T{CGSize=dd},N,V_trackingFrameSizeInPixels
_trackingFrameSizeInPixels
setTrackingFrameSizeInPixels:
trackingFrameSizeInPixels
mFaceBoxPoseAlignerImpl
mFaceBoxAlignerModelFileHandle
processWithOptions:warningRecorder:error:
Tq,V_trackedFrameNumber
T{CGRect={CGPoint=dd}{CGSize=dd}},V_lastTrackedBBox
T@"NSUUID",R,V_key
T@"NSString",R,V_level
TI,V_trackedFrameCVPixelBufferFormat
mTrackerImpl
_trackedFrameCVPixelBufferFormat
_level
_trackedFrameNumber
_lastTrackedBBox
_createTrackerWithLevel:options:error:
_postProcessTrackingResults:trackerResults:error:
_visionBBoxToTrackerBBox:trackedObjects:imageSize:results:error:
_updateTrackerWithModifiedBBoxForImageBuffer:error:
trackedFrameCVPixelBufferFormat
setTrackedFrameCVPixelBufferFormat:
level
trackedFrameNumber
setTrackedFrameNumber:
lastTrackedBBox
setLastTrackedBBox:
VNTrackerOptionToTrackerType:
_classifyAesthetics:generateSaliencyHeatMap:for32BGRAImageInPixelBuffer:withOptions:modelInputImageSize:originalImageSize:regionOfInterest:warningRecorder:error:
vn_encodePersonUniqueIdentifier:forKey:
vn_decodePersonUniqueIdentifierForKey:
T@"NSArray",R,C,N,V_originalRequests
_cachedDependencyProcessingOrdinality
compoundResults
recordWarningsInOriginalRequests
compoundRequestProcessingDeviceFromOriginalRequestsProcessingDevice:
_requestToObservationClassMap
initWithSubrequests:uniqueObservationClasses:
initWithOriginalRequests:requestToObservationClassMap:
_requestsClassMapping
initWithSubrequests:
originalRequestsOfClass:
TQ,N,V_levelCount
TQ,N,V_warpCount
TB,N,V_enableFiltering
TQ,N,V_filterSize
TQ,N,V_filterSamplingDensity
Tf,N,V_filterLumaWeight
Tf,N,V_filterChromaWeight
Tf,N,V_filterOcclusionWeight
_computationAccuracy
_enableFiltering
_filterLumaWeight
_filterChromaWeight
_filterOcclusionWeight
_warpCount
_filterSize
_filterSamplingDensity
initWithTargetedImageBuffer:completionHandler:
_internalPerformRevision:inContext:previousObservation:error:
_createGeneratorOptionsForRequestRevision:session:images:previousTargetImageIsCurrentRefImage:previousObservation:
generateLevel
setGenerateLevel:
computationAccuracy
setComputationAccuracy:
warpCount
setWarpCount:
enableFiltering
setEnableFiltering:
filterSize
setFilterSize:
filterSamplingDensity
setFilterSamplingDensity:
filterLumaWeight
setFilterLumaWeight:
filterChromaWeight
setFilterChromaWeight:
filterOcclusionWeight
setFilterOcclusionWeight:
setLevelCount:
_trainedModel
initWithConfiguration:trainedModel:
_gazePredictor
_gazeFollowPredictor
T@"VNSession",R
_qosClass
_weakRequestPerformer
_imageBuffer_DO_NOT_DIRECTLY_ACCESS
_requestToObservationsCacheKeyMap
_requestForensics
imageBufferAndReturnError:
initWithSession:requestPerformer:imageBuffer:forensics:observationsCache:
initWithSession:requestPerformer:imageBuffer:forensics:observationsCache:qosClass:
_observationsCacheKeyForRequest:
session
requestPerformerAndReturnError:
requestForensics
qosClass
cacheObservationsOfRequest:
cachedObservationsAcceptedByRequest:
recordSequencedObservationsOfRequest:
previousSequencedObservationsAcceptedByRequest:
_runAnalysisOnImage:espressoResources:inputBlobName:error:
_observationsForImageIn32BGRAPixelBuffer:withOptions:originalImageSize:regionOfInterest:warningRecorder:error:
_regionOfInterestConfigurations
configurationForRequest:
createCompoundConfigurationHashKeyForRequest:compoundRequestRevision:
compoundRequestRevisionForRequest:
_objectnessObservationsForRevision:performedInContext:error:
computeTransform:forRegisteringImageSignature:withSignature:minimumOverlap:error:
T@"<VNPersonsModelDataDelegate>",W,N,V_delegate
T@"NSDate",R,N,V_lastModificationDate
TQ,R,N,V_faceprintRequestRevision
_personUniqueIdentifiers
_personUniqueIdentifierToSerialNumberMapping
_serialNumberToFaceObservationsMapping
_availablePersonSerialNumbers
_requestNewIdentitySerialNumberAndReturnError:
_uniqueFaceObservationsWithRegistrationState:forFaceObservations:withExpectedFaceprintRequestRevision:ofPersonWithUniqueIdentifier:error:
_addUniqueFaceObservations:toPersonWithUniqueIdentifier:error:
_removeAllFaceObservationsFromIdentityWithSerialNumber:
_removePersonWithUniqueIdentifier:
_removeExistingFaceObservations:fromIdentityWithSerialNumber:
_removeExistingFaceObservations:fromPersonWithUniqueIdentifier:
_accessToMutableFaceObservationsForPersonAtIndex:
_targetedImageBuffer
initWithTargetedCVPixelBuffer:options:
initWithTargetedCVPixelBuffer:options:completionHandler:
initWithTargetedCVPixelBuffer:orientation:options:
initWithTargetedCVPixelBuffer:orientation:options:completionHandler:
initWithTargetedCGImage:options:
initWithTargetedCGImage:options:completionHandler:
initWithTargetedCGImage:orientation:options:
initWithTargetedCGImage:orientation:options:completionHandler:
initWithTargetedCIImage:options:
initWithTargetedCIImage:options:completionHandler:
initWithTargetedCIImage:orientation:options:
initWithTargetedCIImage:orientation:options:completionHandler:
initWithTargetedImageURL:options:
initWithTargetedImageURL:options:completionHandler:
initWithTargetedImageURL:orientation:options:
initWithTargetedImageURL:orientation:options:completionHandler:
initWithTargetedImageData:options:
initWithTargetedImageData:options:completionHandler:
initWithTargetedImageData:orientation:options:
initWithTargetedImageData:orientation:options:completionHandler:
initWithTargetedCMSampleBuffer:options:
initWithTargetedCMSampleBuffer:options:completionHandler:
initWithTargetedCMSampleBuffer:orientation:options:
initWithTargetedCMSampleBuffer:orientation:options:completionHandler:
targetedImageBuffer
requiredTargetedImageBufferReturningError:
_calculateTorsoBBoxFromFaceBBox:insideImageWithSize:faceOrientationRelativeToUpright:torsoBBox:error:
_detectionprintTensorForOutputBuffer:originatingRequestSpecifier:error:
_analyzePixelBuffer:options:error:
T@"VNPoint",R,V_center
Td,R,V_radius
_center
_radius
initWithCenter:radius:
initWithCenter:diameter:
diameter
containsPoint:
containsPoint:inCircumferentialRingOfWidth:
radius
T@"VNCircle",R
zeroCircle
_imageBuffer
initWithSession:imageBuffer:
performRequests:error:
performRequests:gatheredForensics:error:
initWithCVPixelBuffer:options:session:
initWithCVPixelBuffer:orientation:options:session:
initWithCGImage:options:session:
initWithCGImage:orientation:options:session:
initWithCIImage:options:session:
initWithCIImage:orientation:options:session:
initWithURL:options:session:
initWithURL:orientation:options:session:
initWithData:options:session:
initWithData:orientation:options:session:
initWithCMSampleBuffer:options:session:
initWithCMSampleBuffer:orientation:options:session:
setWithArray:
initWithString:
setScanLocation:
scanInteger:
size
drawAtPoint:
compare:options:
@"NSArray"
@32@0:8@16@24
Q16@0:8
B24@0:8@16
@16@0:8
@24@0:8^@16
v24@0:8@16
@24@0:8@16
v16@0:8
B16@0:8
@96@0:8@16^{__CVBuffer=}24@32@40{CGRect={CGPoint=dd}{CGSize=dd}}48@80^@88
I24@0:8@16
Q24@0:8@16
@72@0:8^{__CVBuffer=}16@24{CGRect={CGPoint=dd}{CGSize=dd}}32^@64
^{__CVBuffer=}40@0:8@16@24^@32
@80@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24@56^@64@?72
@"NSArray"16@0:8
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8@"Protocol"16
B24@0:8:16
Vv16@0:8
^{_NSZone=}16@0:8
@"NSString"16@0:8
@24@0:8Q16
B32@0:8@16^@24
B40@0:8Q16@24^@32
@40@0:8^@16@24^@32
r^{?=Q{?=ii}{?=ii}{?=ii}}16@0:8
q16@0:8
{shared_ptr<vision::mod::FaceQualityPredictor>="__ptr_"^{FaceQualityPredictor}"__cntrl_"^{__shared_weak_count}}
@24@0:8#16
@24@0:8^{_NSZone=}16
v24@0:8q16
@"VNScreenGazeState"
v24@0:8@"NSArray"16
@24@0:8@?16
r^{?=Q#Q}16@0:8
Q32@0:8#16Q24
@32@0:8q16@24
B96@0:8@16@24{CGRect={CGPoint=dd}{CGSize=dd}}32@64@72@80^@88
@"NSURL"
@"NSString"
@36@0:8@16B24@28
@28@0:8@16B24
v32@0:8r^v16@24
v24@0:8r^v16
v32@0:8@16@24
@32@0:8@16q24
@"VNClusteringLogger"
@"VNSuggestionsLogger"
@"NSData"
{shared_ptr<const vision::mod::FaceClustering>="__ptr_"^{FaceClustering}"__cntrl_"^{__shared_weak_count}}
B24@0:8^@16
@"NSArray"36@0:8@"NSDictionary"16f24^@28
@"NSData"24@0:8^@16
@"NSSet"24@0:8^@16
@"NSArray"32@0:8@"NSNumber"16^@24
@"NSNumber"40@0:8@"NSNumber"16@"NSNumber"24^@32
@"NSDictionary"32@0:8@"NSArray"16^@24
@"NSArray"24@0:8^@16
@"NSArray"40@0:8@"NSArray"16@"NSDictionary"24^@32
@"NSDictionary"40@0:8@"NSArray"16@"NSArray"24^@32
@"NSNumber"24@0:8^@16
@"NSArray"40@0:8@"NSData"16@"NSString"24^@32
@"NSUUID"16@0:8
@32@0:8@16^@24
@40@0:8@16@24^@32
@36@0:8@16f24^@28
v32@0:8{shared_ptr<const vision::mod::FaceClustering>=^{FaceClustering}^{__shared_weak_count}}16
@24@0:8^v16
v32@0:8@16^v24
v40@0:8@16@24^v32
{shared_ptr<vision::mod::FaceClustering>="__ptr_"^{FaceClustering}"__cntrl_"^{__shared_weak_count}}
@"NSArray"32@0:8@"NSDictionary"16^@24
q40@0:8^v16^v24Q32
r^v24@0:8@16
#32@0:8@16^@24
{shared_ptr<vision::mod::FaceprintAndAttributes>="__ptr_"^{FaceprintAndAttributes}"__cntrl_"^{__shared_weak_count}}
v40@0:8^v16@24@32
B56@0:8{shared_ptr<vision::mod::ImageDescriptorBufferAbstract>=^{ImageDescriptorBufferAbstract}^{__shared_weak_count}}16@32@40^@48
B32@0:8{shared_ptr<vision::mod::ImageDescriptorBufferAbstract>=^{ImageDescriptorBufferAbstract}^{__shared_weak_count}}16
B48@0:8^v16@24@32^@40
@"NSNumber"
B56@0:8@16@24@32Q40^@48
@64@0:8@16@24@32B40f44Q48^@56
@72@0:8@16@24@32B40f44Q48Q56^@64
@68@0:8@16@24@32B40f44f48Q52^@60
@76@0:8@16@24@32B40f44f48Q52Q60^@68
@40@0:8#16@24^@32
@"<VNClusteringReadOnly><VNClusteringCancelling>"
@"NSArray"32@0:8@"NSArray"16^@24
@"NSArray"44@0:8@"NSDictionary"16f24@"VNCanceller"28^@36
@"NSNumber"40@0:8@"VNFaceprint"16@"VNFaceprint"24^@32
@"NSNumber"40@0:8@"VNFaceObservation"16@"VNFaceObservation"24^@32
@44@0:8@16f24@28^@36
@60@0:8@16@24@32f40Q44^@52
@68@0:8@16@24@32f40Q44Q52^@60
@64@0:8@16@24@32f40f44Q48^@56
@72@0:8@16@24@32f40f44Q48Q56^@64
@"<VNClusteringReadOnly><VNClusteringWritable><VNClusteringCancelling>"
B32@0:8@"NSData"16^@24
@"NSArray"48@0:8@"NSArray"16@"NSArray"24@"VNCanceller"32^@40
@"NSArray"56@0:8@"NSArray"16@"NSArray"24@"NSArray"32@"VNCanceller"40^@48
@"NSArray"40@0:8@"NSArray"16@"VNCanceller"24^@32
@48@0:8@16@24@32^@40
@56@0:8@16@24@32@40^@48
#28@0:8I16^@20
@28@0:8I16^@20
B40@0:8^I16#24^@32
B40@0:8^I16@24^@32
@"NSObject<OS_dispatch_semaphore>"
{os_unfair_lock_s="_os_unfair_lock_opaque"I}
{vector<std::tuple<simd_float3x3, float>, std::allocator<std::tuple<simd_float3x3, float>>>="__begin_"^v"__end_"^v"__end_cap_"{__compressed_pair<std::tuple<simd_float3x3, float> *, std::allocator<std::tuple<simd_float3x3, float>>>="__value_"^v}}
v56@0:8@"NSArray"16{?=qiIq}24@"NSDictionary"48
v56@0:8@16{?=qiIq}24@48
v20@0:8f16
@"VN6Ac6Cyl5O5oK19HboyMBR"
v24@0:8Q16
@32@0:8Q16@24
@32@0:8Q16Q24
@40@0:8Q16Q24@?32
@?16@0:8
{unique_ptr<vision::mod::ImageAnalyzer, std::default_delete<vision::mod::ImageAnalyzer>>="__ptr_"{__compressed_pair<vision::mod::ImageAnalyzer *, std::default_delete<vision::mod::ImageAnalyzer>>="__value_"^{ImageAnalyzer}}}
{_Geometry2D_size2D_="height"f"width"f}
{CGSize=dd}16@0:8
B32@0:8^v16^@24
@48@0:8^v16@24@32^@40
@32@0:8@?16^@24
@56@0:8^v16@?24@32@40^@48
@"VNRequest"
@"NSError"
@"<NSObject><NSCopying>"
@"NSMutableArray"
@"NSMapTable"
@"<MTLDevice>"
@"<MTLCommandQueue>"
@"<MTLLibrary>"
@48@0:8^{__CVBuffer=}16Q24Q32^@40
@64@0:8^{__CVBuffer=}16Q24{CGSize=dd}32Q48^@56
@64@0:8^{__IOSurface=}16Q24Q32Q40Q48^@56
{shared_ptr<vision::mod::TapToBox>="__ptr_"^{TapToBox}"__cntrl_"^{__shared_weak_count}}
@40@0:8q16@24@32
@20@0:8I16
@32@0:8#16Q24
@40@0:8@16@24@32
@32@0:8Q16#24
@28@0:8i16@20
@40@0:8{?=ii*}16@32
@32@0:8^v16@24
v28@0:8B16@20
{shared_ptr<vision::mod::ObjectDetector_DCNFaceDetector_v2>="__ptr_"^{ObjectDetector_DCNFaceDetector_v2}"__cntrl_"^{__shared_weak_count}}
@"VNFaceBBoxAligner"
@32@0:8Q16^@24
@"CRImageReader"
@40@0:8@16Q24^@32
@"FaceCoreDetector"
@"NSDictionary"
@"VNSceneObservation"
@"VNClassificationCustomHierarchy"
@32@0:8@16@?24
@32@0:8:16Q24
@64@0:8@16Q24@32Q40^@48^@56
@40@0:8Q16Q24^@32
#24@0:8^@16
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
@44@0:8#16@24I32Q36
I16@0:8
B32@0:8#16Q24
B32@0:8@16Q24
@40@0:8^I16Q24^@32
@40@0:8#16Q24^@32
v24@0:8^v16
^v16@0:8
@32@0:8^{__CVBuffer=}16^@24
B76@0:8^f16^{__CVBuffer=}24{CGRect={CGPoint=dd}{CGSize=dd}}32f64^@68
B44@0:8^f16^{__CVBuffer=}24f32^@36
B76@0:8^f16@24f32{CGRect={CGPoint=dd}{CGSize=dd}}36^@68
B40@0:8^f16^{__CVBuffer=}24^@32
B48@0:8^f16^{__CVBuffer=}24i32f36^@40
@"VNDetectedObjectObservation"
v20@0:8B16
I24@0:8Q16
{?="value"q"timescale"i"flags"I"epoch"q}
f16@0:8
{?=qiIq}16@0:8
v40@0:8{?=qiIq}16
@"VNTrajectoryProcessor"
@"VNTrajectoryRequestState"
@56@0:8{?=qiIq}16q40@?48
@"NSObject<OS_dispatch_queue>"
@"VNMetalContext"
@"<NSObject><NSCopying>"24@0:8@"NSDictionary"16
B32@0:8#16@24
B40@0:8@16@24^@32
@84@0:8I16@20{CGRect={CGPoint=dd}{CGSize=dd}}28@60^@68@?76
B40@0:8^@16@24^@32
#40@0:8@16@24^@32
@44@0:8@16@24I32^@36
v28@0:8I16@20
v72@0:8{CGAffineTransform=dddddd}16@64
{CGAffineTransform=dddddd}24@0:8@16
v72@0:8{?=[3]}16@64
{?=[3]}24@0:8@16
v88@0:8{?=[4]}16@80
{?=[4]}24@0:8@16
v40@0:816@32
24@0:8@16
v72@0:8{?={?=qiIq}{?=qiIq}}16@64
{?={?=qiIq}{?=qiIq}}24@0:8@16
v40@0:8{CGPoint=dd}16@32
{CGPoint=dd}24@0:8@16
v40@0:8{CGSize=dd}16@32
{CGSize=dd}24@0:8@16
v56@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48
{CGRect={CGPoint=dd}{CGSize=dd}}24@0:8@16
v32@0:8^{__CVBuffer=}16@24
^{__CVBuffer=}24@0:8@16
v28@0:8f16@20
f24@0:8@16
@"NSMutableDictionary"
@"VNImageAnalyzerCompoundRequestGroupingConfiguration"
{vImage_Buffer="data"^v"height"Q"width"Q"rowBytes"Q}
{CGRect="origin"{CGPoint="x"d"y"d}"size"{CGSize="width"d"height"d}}
{_Geometry2D_rect2D_="origin"{_Geometry2D_point2D_="x"f"y"f}"size"{_Geometry2D_size2D_="height"f"width"f}}
@92@0:8Q16^{vImage_Buffer=^vQQQ}24B32{CGRect={CGPoint=dd}{CGSize=dd}}36{_Geometry2D_rect2D_={_Geometry2D_point2D_=ff}{_Geometry2D_size2D_=ff}}68@84
@32@0:8{CGPoint=dd}16
@48@0:8{CGPoint=dd}16{CGSize=dd}32
@"VNAnimalprint"
@28@0:8@16f24
@76@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24f56@60@68
i16@0:8
B32@0:8@16:24
@"<VNEntityIdentificationModelTrainingDataDelegate>"
@"VNRequestSpecifier"
@"NSMutableIndexSet"
@"NSDate"
@"<NSObject><NSCopying><NSSecureCoding>"24@0:8Q16
Q24@0:8@"<NSObject><NSCopying><NSSecureCoding>"16
Q24@0:8Q16
@"VNObservation<VNEntityIdentificationModelObservation>"32@0:8Q16Q24
Q24@0:8@"VNEntityIdentificationModel"16
@"<NSObject><NSCopying><NSSecureCoding>"32@0:8@"VNEntityIdentificationModel"16Q24
Q32@0:8@"VNEntityIdentificationModel"16@"<NSObject><NSCopying><NSSecureCoding>"24
Q32@0:8@"VNEntityIdentificationModel"16Q24
@"VNObservation<VNEntityIdentificationModelObservation>"40@0:8@"VNEntityIdentificationModel"16Q24Q32
@"NSDate"24@0:8@"VNEntityIdentificationModel"16
@32@0:8@16Q24
Q32@0:8@16@24
Q32@0:8@16Q24
@40@0:8@16Q24Q32
B32@0:8@?16@?24
r^{_LandmarkDetector_faceMeshParts_=ii[23i]i[23i]i[23i]i[23i]i[23i]i[23i]i[23i]i[23i]i[23i]i[23i]i[23i]i[23i]i[23i]i[23i]i[23i]i[23i]i[23i]}24@0:8Q16
r^v24@0:8Q16
{_Geometry2D_point2D_=ff}36@0:8r^{_Geometry2D_point2D_=ff}16r^i24i32
{shared_ptr<vision::mod::LandmarkAttributes>="__ptr_"^{LandmarkAttributes}"__cntrl_"^{__shared_weak_count}}
@48@0:8r^{vImage_Buffer=^vQQQ}16r^{_Geometry2D_rect2D_={_Geometry2D_point2D_=ff}{_Geometry2D_size2D_=ff}}24r^v32^@40
B64@0:8r^v16@24@32@40@48^@56
B64@0:8r^{vImage_Buffer=^vQQQ}16@24^{_Geometry2D_rect2D_={_Geometry2D_point2D_=ff}{_Geometry2D_size2D_=ff}}32r^v40@48^@56
@40@0:8@16@24Q32
v48@0:8@16@24@32B40B44
B36@0:8^@16B24^@28
v32@0:8Q16@?24
@"CIContext"
@"NSHashTable"
@"NSLock"
^{CGImageSource=}
^{CGImageSource=}40@0:8^^{CGImageSource}16I24^{os_unfair_lock_s=I}28B36
^{__CVBuffer=}
^{CGImage=}
^{__CFDictionary=}
@"CIImage"
^{opaqueCMSampleBuffer=}
@"VNImageSourceManager"
@"<NSObject><NSCopying>"16@0:8
@32@0:8^{__CVBuffer=}16@24
@36@0:8^{__CVBuffer=}16I24@28
@32@0:8^{CGImage=}16@24
@36@0:8^{CGImage=}16I24@28
@36@0:8@16I24@28
@32@0:8^{opaqueCMSampleBuffer=}16@24
@36@0:8^{opaqueCMSampleBuffer=}16I24@28
^{__CVBuffer=}16@0:8
^{CGImage=}16@0:8
^{__CVBuffer=}52@0:8Q16Q24I32@36^@44
^{__CVBuffer=}60@0:8Q16Q24I32@36^@44^@52
^{__CVBuffer=}84@0:8Q16Q24I32{CGRect={CGPoint=dd}{CGSize=dd}}36@68^@76
^{__CVBuffer=}92@0:8Q16Q24I32{CGRect={CGPoint=dd}{CGSize=dd}}36@68^@76^@84
^{__CVBuffer=}116@0:8Q16Q24{CGRect={CGPoint=dd}{CGSize=dd}}32I64Q68@76^@84^{CGPoint=dd}92^d100^d108
^{__CVBuffer=}124@0:8Q16Q24{CGRect={CGPoint=dd}{CGSize=dd}}32I64Q68@76^@84^{CGPoint=dd}92^d100^d108^@116
{?={?=qiIq}{?=qiIq}{?=qiIq}}16@0:8
B24@0:8^f16
B24@0:8^{CGPoint=dd}16
B24@0:8^{?=[3]}16
B84@0:8Q16f24@28{CGRect={CGPoint=dd}{CGSize=dd}}36@?68^@76
{CGRect={CGPoint=dd}{CGSize=dd}}48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
^{__CVBuffer=}44@0:8Q16I24@28^@36
^{__CVBuffer=}76@0:8Q16{CGRect={CGPoint=dd}{CGSize=dd}}24I56@60^@68
@60@0:8Q16Q24I32@36@44^@52
@92@0:8Q16Q24I32{CGRect={CGPoint=dd}{CGSize=dd}}36@68@76^@84
@68@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16I48Q52Q60
r^{__CFDictionary=}16@0:8
i24@0:8@16
{CGRect={CGPoint=dd}{CGSize=dd}}80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGSize=dd}48^d64^d72
^{CGColorSpace=}28@0:8I16^I20
B48@0:8@16@24@32^@40
v48@0:8@16@24@32@40
v40@0:8@16@24@32
v28@0:8@16B24
@20@0:8B16
@"NSNotificationCenter"
@"NSRecursiveLock"
@"_VNWeakSessionsCollection"
@"VNMTLDeviceWisdomParameters"
@"NSDictionary"32@0:8@"<MTLDevice>"16^@24
@"NSDictionary"32@0:8@"NSString"16^@24
v24@0:8@"NSDictionary"16
v24@0:8@"NSString"16
@48@0:8#16@24@32@40
@48@0:8#16@24@32^@40
@"VNPersonsModelData"
@"VNPersonsModelFaceModel"
v24@0:8@"VNPersonsModelData"16
B40@0:8@16^{CC_MD5state_st=IIIIII[16I]i}24^@32
B48@0:8@16@24^{CC_MD5state_st=IIIIII[16I]i}32^@40
B56@0:8Q16@24@32^{CC_MD5state_st=IIIIII[16I]i}40^@48
B44@0:8^^?16^:24Q32B40
B48@0:8^^?16^:24^Q32@40
@40@0:8Q16@24^@32
d24@0:8@16
@32@0:8d16d24
{CGPoint=dd}16@0:8
d16@0:8
d32@0:8@16@24
@"VNRequestConfiguration"
@"VNWarningRecorder"
@"VNCanceller"
v32@0:8@"NSString"16@24
@24@0:8@"NSString"16
B48@0:8@16^Q24^Q32^@40
B32@0:8Q16^@24
B56@0:8^@16#24@32@40^@48
B48@0:8^d16@24@32^@40
B56@0:8^d16@24@32d40^@48
B48@0:8^f16@24@32^@40
B52@0:8^f16@24@32f40^@44
B56@0:8^@16@24@32#40^@48
Q20@0:8i16
B24@0:8Q16
@"VNProcessingDevice"
@40@0:8Q16Q24Q32
@"VNSizeRange"
@52@0:8I16@20@28Q36I44B48
@52@0:8I16Q20Q28I36Q40B48
B32@0:8Q16Q24
@40@0:8@16^@24^@32
@"VNFaceprint"
@"VNTorsoprint"
@56@0:8r^v16Q24Q32Q40f48f52
@64@0:8r^v16Q24Q32Q40f48f52@56
@40@0:8@16^Q24^@32
Q40@0:8@16Q24^@32
B20@0:8I16
{shared_ptr<vision::mod::PetprintGenerator>="__ptr_"^{PetprintGenerator}"__cntrl_"^{__shared_weak_count}}
{shared_ptr<vision::mod::ObjectDetector_DCNFaceDetector>="__ptr_"^{ObjectDetector_DCNFaceDetector}"__cntrl_"^{__shared_weak_count}}
@"VNFaceObservation"
@"NSUUID"
{_Geometry2D_point2D_="x"f"y"f}
@"VNMPContext"
@36@0:8@16i24^@28
@36@0:8@16B24^@28
@40@0:8{vector<MPClusteringTreeNode *, std::allocator<MPClusteringTreeNode *>>=^^{MPClusteringTreeNode}^^{MPClusteringTreeNode}{__compressed_pair<MPClusteringTreeNode **, std::allocator<MPClusteringTreeNode *>>=^^{MPClusteringTreeNode}}}16
@28@0:8^v16B24
Q40@0:8^{?=Q^@^Q[5Q]}16^@24Q32
B24@0:8@"<VNEntityIdentificationModelPrint>"16
@"VNRequestSpecifier"16@0:8
@"NSData"16@0:8
@"<VNEntityIdentificationModelPrint>"32@0:8@"VNRequestSpecifier"16^@24
@48@0:8@16Q24^@32^@40
@60@0:8q16{CGRect={CGPoint=dd}{CGSize=dd}}24f56
{CGRect={CGPoint=dd}{CGSize=dd}}16@0:8
v48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
v24@0:8@"VNEntityIdentificationModelTrainingData"16
B40@0:8#16@24^@32
@"VNEntityIdentificationModelTrainingData"
@36@0:8{CGPoint=dd}16f32
@44@0:8{CGPoint=dd}16f32@36
Q40@0:8@"NSMutableData"16Q24^@32
@40@0:8@"NSData"16^Q24^@32
@56@0:8r^v16Q24Q32Q40Q48
@60@0:8r^v16Q24Q32Q40f48Q52
@60@0:8r^v16Q24Q32Q40f48@52
[4{CGPoint="x"d"y"d}]
[4f]
v28@0:8f16i20i24
{CGRect={CGPoint=dd}{CGSize=dd}}52@0:8f16{vImage_Buffer=^vQQQ}20
{CGSize="width"d"height"d}
@56@0:8@16^{__CVBuffer=}24{CGSize=dd}32@48
^{__CVBuffer=}24@0:8^@16
^{__CVBuffer=}80@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24Q56@64^@72
{shared_ptr<vision::mod::ScreenGazePredictor>="__ptr_"^{ScreenGazePredictor}"__cntrl_"^{__shared_weak_count}}
@"CIBarcodeDescriptor"
r^{__MRCDescriptor=}
@104@0:8@16@24@32{CGPoint=dd}40{CGPoint=dd}56{CGPoint=dd}72{CGPoint=dd}88
@72@0:8@16@24@32{CGRect={CGPoint=dd}{CGSize=dd}}40
v24@0:8^{__MRCDescriptor=}16
r^{__MRCDescriptor=}16@0:8
v24@0:8r^{__MRCDescriptor=}16
{shared_ptr<vision::mod::ImageClassifierAbstract>=^{ImageClassifierAbstract}^{__shared_weak_count}}88@0:8{shared_ptr<vision::mod::ImageDescriptorProcessorAbstract>=^{ImageDescriptorProcessorAbstract}^{__shared_weak_count}}16r*32i40i44r*48{Options=BQ@@}56
{shared_ptr<vision::mod::ImageDescriptorProcessorAbstract>=^{ImageDescriptorProcessorAbstract}^{__shared_weak_count}}68@0:8r*16i24i28i32{Options=BQ@@}36
v32@0:8^@16^@24
@64@0:8r^v16Q24Q32Q40@48Q56
B40@0:8@16Q24^@32
@"VNPersonsModel"
@"<VNPersonsModelDataSource>"
@"VNFaceObservation"32@0:8Q16Q24
@"VNPersonsModelConfiguration"
@48@0:8@16Q24@32^@40
@40@0:8#16@24@32
@72@0:8@16@24@?32@?40^#48^Q56^@64
B52@0:8I16@20@28^{CC_MD5state_st=IIIIII[16I]i}36^@44
@"NSIndexSet"
@"<NSObject><NSCopying><NSSecureCoding>"
@36@0:8@16@24f32
@48@0:8{_NSRange=QQ}16@?32^@40
@48@0:8{_NSRange=QQ}16@32^@40
@"VNImageBuffer"
@"VNImageRegistrationSignature"
B48@0:8^@16^@24@32^@40
@"VNClassificationObservation"
@"VNFaceAttributeCategory"
@"VNDetectionprint"
{?="data"^v"reserved"^v"dim"[4Q]"stride"[4Q]"width"Q"height"Q"channels"Q"batch_number"Q"sequence_length"Q"stride_width"Q"stride_height"Q"stride_channels"Q"stride_batch_number"Q"stride_sequence_length"Q"storage_type"i}
@64@0:8r^v16Q24Q32Q40@48@56
{FastRegistration_Signatures="piRow"^f"nPiRow"Q"piRowTable"{Projections_meanStdTable="sumTable"^f"sumSqTable"^f}"piCol"^f"nPiCol"Q"piColTable"{Projections_meanStdTable="sumTable"^f"sumSqTable"^f}"_memoryContainer"*}
@64@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24^@56
r^{FastRegistration_Signatures=^fQ{Projections_meanStdTable=^f^f}^fQ{Projections_meanStdTable=^f^f}*}16@0:8
{shared_ptr<vision::mod::FaceFrontalizer>="__ptr_"^{FaceFrontalizer}"__cntrl_"^{__shared_weak_count}}
@"NSMutableData"
f24@0:8Q16
v24@0:8^{vImage_Buffer=^vQQQ}16
q24@0:8@16
@"VNOperationPoints"
@"VNOperationPoints"24@0:8^@16
{shared_ptr<vision::mod::FaceSegmenterDNN>="__ptr_"^{FaceSegmenterDNN}"__cntrl_"^{__shared_weak_count}}
B40@0:8^{CGSize=dd}16Q24^@32
B40@0:8^Q16Q24^@32
v24@0:8@"NSMutableDictionary"16
@24@0:8q16
@24@0:8d16
@"VNVideoProcessorCadence"
@"VCPVideoProcessor"
B72@0:8{?={?=qiIq}{?=qiIq}}16^@64
@"VNRecognizedPointsSpecifier"
@"VCPRequest"
B48@0:8^{__CVBuffer=}16^{?=^v^v[4Q][4Q]QQQQQQQQQQi}24@32^@40
B80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16^{?=^v^v[4Q][4Q]QQQQQQQQQQi}48@56@64^@72
@40@0:8r^{?=^v^v[4Q][4Q]QQQQQQQQQQi}16@24^@32
@"ShotflowNetwork"
@28@0:8r^{vImage_Buffer=^vQQQ}16B24
@32@0:8@16f24f28
v20@0:8i16
@48@0:8@16f24@28i36i40i44
@36@0:8@16i24i28i32
@52@0:8{?=^vi}16^v32f40@44
@40@0:8{?=^vi}16^v32
{CGSize=dd}32@0:8{CGSize=dd}16
{shared_ptr<vision::mod::ImageClassifier_HierarchicalModel>=^{ImageClassifier_HierarchicalModel}^{__shared_weak_count}}32@0:8@16^@24
{shared_ptr<vision::mod::ImageDescriptorProcessorAbstract>="__ptr_"^{ImageDescriptorProcessorAbstract}"__cntrl_"^{__shared_weak_count}}
{shared_ptr<vision::mod::ImageClassifierAbstract>="__ptr_"^{ImageClassifierAbstract}"__cntrl_"^{__shared_weak_count}}
@"NSSet"
@80@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24@56@64^@72
B104@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24@56@64^v72@80@88^@96
@32@0:8^{__MRCDescriptor=}16^@24
^{ACBSConfig=}24@0:8^@16
^{__CFDictionary=}24@0:8^@16
@72@0:8^{__MRCDescriptor=}16{CGRect={CGPoint=dd}{CGSize=dd}}24@56^@64
B56@0:8@16^{CGPoint=dd}24^{CGPoint=dd}32^{CGPoint=dd}40^{CGPoint=dd}48
@88@0:8@16Q24Q32{CGRect={CGPoint=dd}{CGSize=dd}}40@72^@80
@48@0:8@16^{ACBSConfig=}24@32^@40
^{__CFString=}24@0:8@16
@24@0:8^{__CFString=}16
@"VNObservation<VNEntityIdentificationModelObservation>"
@"VNSaliencyOHeatmapBoundingBoxGenerator"
@76@0:8q16{CGRect={CGPoint=dd}{CGSize=dd}}24f56f60f64f68i72
^{vImage_Buffer=^vQQQ}
@48@0:8^{vImage_Buffer=^vQQQ}16@24@32^@40
@48@0:8^{vImage_Buffer=^vQQQ}16@24q32^@40
@48@0:8^{__CVBuffer=}16@24@32^@40
@48@0:8^{__CVBuffer=}16@24q32^@40
^{vImage_Buffer=^vQQQ}16@0:8
B40@0:8^f16@24^@32
B44@0:8^f16@24f32^@36
@"LKTMetalContext"
[9@"<MTLComputePipelineState>"]
[10{CGSize="width"d"height"d}]
[2[10@"<MTLTexture>"]]
[10@"<MTLTexture>"]
[2@"<MTLBuffer>"]
[2^{__CVBuffer}]
@"<MTLTexture>"
B32@0:8^{__CVBuffer=}16^@24
B40@0:8^{__CVBuffer=}16^{__CVBuffer=}24^@32
v28@0:8i16i20i24
B44@0:8@16^{__CVBuffer=}24i32^@36
v68@0:8@16i242836@44@52@60
v56@0:8@16@24@32@40@48
@"VNSupportedImageSize"
v24@0:8d16
{CGSize=dd}40@0:8@16Q24Q32
^{__CVBuffer=}88@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48I56{CGSize=dd}60B76^@80
^{__CVBuffer=}56@0:8@16I24{CGSize=dd}28B44^@48
B48@0:8Q16@24@32^@40
@"VNMPImageDescriptor"
@32@0:8@"NSData"16^@24
@40@0:8@16Q24@32
r^v16@0:8
B40@0:8@16^f24^@32
@"CIColorKernel"
@56@0:8r^v16Q24Q32Q40@48
@28@0:8@16I24
@112@0:8@16f24f28f32f36f40f44f48f52f56f60f64f68f72f76f80f84f88f92f96f100f104f108
^{CGPath=}
{shared_ptr<apple::vision::libraries::autotrace::EPolygonList>="__ptr_"^{EPolygonList}"__cntrl_"^{__shared_weak_count}}
{vector<unsigned int, std::allocator<unsigned int>>="__begin_"^I"__end_"^I"__end_cap_"{__compressed_pair<unsigned int *, std::allocator<unsigned int>>="__value_"^I}}
{vector<std::vector<unsigned int>, std::allocator<std::vector<unsigned int>>>="__begin_"^v"__end_"^v"__end_cap_"{__compressed_pair<std::vector<unsigned int> *, std::allocator<std::vector<unsigned int>>>="__value_"^v}}
@48@0:8@16@24{CGSize=dd}32
@32@0:8q16^@24
r^{CGPath=}16@0:8
r^{EPolygonList=ii^{EPolygon}i}16@0:8
r^v24@0:8q16
@"CIFilter"
@"VNDetectContoursRequest"
^{CGColorSpace=}
@"ParabolaDetection"
@48@0:8{?=qiIq}16q40
^{__CVBuffer=}72@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24@56^@64
@24@0:8r^v16
@88@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24@56@64@72^@80
{shared_ptr<vision::mod::FaceRegionMap>="__ptr_"^{FaceRegionMap}"__cntrl_"^{__shared_weak_count}}
{?="start"{?="value"q"timescale"i"flags"I"epoch"q}"duration"{?="value"q"timescale"i"flags"I"epoch"q}}
{?={?=qiIq}{?=qiIq}}16@0:8
v64@0:8{?={?=qiIq}{?=qiIq}}16
@"VNPixelBufferObservation"
@56@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24
v80@0:8{CGPoint=dd}16{CGPoint=dd}32{CGPoint=dd}48{CGPoint=dd}64
@48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
@56@0:8Q16{CGRect={CGPoint=dd}{CGSize=dd}}24
@"VNFaceLandmarks2D"
@"VNFaceLandmarks3D"
@"VNFaceRegionMap"
@"VNFaceAttributes"
@"VNFaceTorsoprint"
@"VNFaceSegments"
@"VNFaceLegacyFaceCore"
@"VNFaceGaze"
@"VNFaceScreenGaze"
{?=[4]}16@0:8
{?=}16@0:8
B24@0:8^{CGAffineTransform=dddddd}16
B32@0:8^i16^@24
{_Geometry2D_rect2D_={_Geometry2D_point2D_=ff}{_Geometry2D_size2D_=ff}}16@0:8
v32@0:8{_Geometry2D_rect2D_={_Geometry2D_point2D_=ff}{_Geometry2D_size2D_=ff}}16
B36@0:8f16^i20^@28
@88@0:8Q16{CGRect={CGPoint=dd}{CGSize=dd}}24{CGRect={CGPoint=dd}{CGSize=dd}}56
@64@0:8Q16{CGRect={CGPoint=dd}{CGSize=dd}}24@56
@80@0:8Q16{CGRect={CGPoint=dd}{CGSize=dd}}24@56@64@72
@72@0:8Q16{CGRect={CGPoint=dd}{CGSize=dd}}24@56@64
@112@0:8Q16{CGRect={CGPoint=dd}{CGSize=dd}}24{CGRect={CGPoint=dd}{CGSize=dd}}56@88@96@104
@104@0:8Q16{CGRect={CGPoint=dd}{CGSize=dd}}24{CGRect={CGPoint=dd}{CGSize=dd}}56@88@96
B104@0:8{?=[4]}16^f80^f88^f96
{CGAffineTransform=dddddd}16@0:8
v64@0:8{CGAffineTransform=dddddd}16
{CGAffineTransform="a"d"b"d"c"d"d"d"tx"d"ty"d}
{?="columns"[3]}
{?=[3]}16@0:8
v64@0:8{?=[3]}16
@"VNImageprint"
@"<VNOperationPointsProviding>"
@36@0:8Q16@24f32
@44@0:8Q16@24f32@36
@44@0:8@16@24f32@36
B24@0:8f16f20
@68@0:8Q16{CGRect={CGPoint=dd}{CGSize=dd}}24f56@60
@40@0:8@16@24^{__CVBuffer=}32
@"MLFeatureValue"
{CGPoint="x"d"y"d}
@80@0:8{CGPoint=dd}16{CGPoint=dd}32{CGPoint=dd}48{CGPoint=dd}64
@88@0:8Q16{CGPoint=dd}24{CGPoint=dd}40{CGPoint=dd}56{CGPoint=dd}72
@88@0:8@16{CGPoint=dd}24{CGPoint=dd}40{CGPoint=dd}56{CGPoint=dd}72
f32@0:8@16^@24
16@0:8
@"VNImageSignature"
@"LKTOpticalFlow"
B48@0:8^@16#24Q32^@40
{CGRect={CGPoint=dd}{CGSize=dd}}32@0:8Q16Q24
B48@0:8@16@24Q32@40
B32@0:8@16@24
B108@0:8{vImage_Buffer=^vQQQ}16{vImage_Buffer=^vQQQ}48{CGSize=dd}80f96f100f104
f48@0:8{vImage_Buffer=^vQQQ}16
@52@0:8{vImage_Buffer=^vQQQ}16f48
@56@0:8{vImage_Buffer=^vQQQ}16f48B52
@40@0:8^{__CVBuffer=}16f24B28^@32
@64@0:8{vImage_Buffer=^vQQQ}16@48^@56
@100@0:8{vImage_Buffer=^vQQQ}16@48B56B60{CGSize=dd}64f80f84f88^@92
@76@0:8^{__CVBuffer=}16@24B32B36{CGSize=dd}40f56f60f64^@68
@"<VNDetectorCacheDelegate>"
{?="reportDidCacheDetector"b1"reportDidEvictDetector"b1}
@"NSMutableSet"
v32@0:8#16@"NSDictionary"24
v32@0:8#16@24
@"VNDetector"40@0:8@"NSString"16@"NSDictionary"24^@32
@"VNDetector"40@0:8#16@"NSDictionary"24^@32
v24@0:8@?16
{shared_ptr<vision::mod::FaceIDModel>="__ptr_"^{FaceIDModel}"__cntrl_"^{__shared_weak_count}}
@64@0:8{shared_ptr<vision::mod::FaceIDModel>=^{FaceIDModel}^{__shared_weak_count}}16@32Q40@48@56
@56@0:8Q16r^v24Q32Q40^@48
@24@0:8^{__CVBuffer=}16
B32@0:8^{__CVBuffer=}16^{__CVBuffer=}24
Q24@0:8^{__CVBuffer=}16
@"VNCIContrastFromAverageColorFilter"
@"VNCIContrastWithPivotColorFilter"
v20@0:8I16
@"VNSession"
@"VNRequestPerformer"
B48@0:8@16@24^@32^@40
B40@0:8@16^{__CVBuffer=}24^@32
B48@0:8@16^{__CVBuffer=}24^@32^@40
B44@0:8@16^{__CVBuffer=}24I32^@36
B52@0:8@16^{__CVBuffer=}24I32^@36^@44
B40@0:8@16^{CGImage=}24^@32
B48@0:8@16^{CGImage=}24^@32^@40
B44@0:8@16^{CGImage=}24I32^@36
B52@0:8@16^{CGImage=}24I32^@36^@44
B44@0:8@16@24I32^@36
B52@0:8@16@24I32^@36^@44
B40@0:8@16^{opaqueCMSampleBuffer=}24^@32
B48@0:8@16^{opaqueCMSampleBuffer=}24^@32^@40
B44@0:8@16^{opaqueCMSampleBuffer=}24I32^@36
B52@0:8@16^{opaqueCMSampleBuffer=}24I32^@36^@44
v32@0:8@16@?24
@56@0:8{shared_ptr<vision::mod::FaceIDModel>=^{FaceIDModel}^{__shared_weak_count}}16Q32Q40@48
B40@0:8^i16@24^@32
@56@0:8@16r^v24Q32^{CVMLCanceller=^^?Bi}40^@48
@56@0:8@16r^v24Q32@40^@48
{shared_ptr<vision::mod::ImageDescriptorBufferFloat32>=^{ImageDescriptorBufferFloat32}^{__shared_weak_count}}52@0:8{shared_ptr<vision::mod::ImageDescriptorBufferFloat32>=^{ImageDescriptorBufferFloat32}^{__shared_weak_count}}16@32i40^v44
@36@0:8Q16@24B32
q40@0:8@16^^{MPClusteringTreeNode}24@32
f28@0:8^{MPClusteringTreeNode=@iffi^{MPClusteringTreeNode}^{MPClusteringTreeNode}^{MPClusteringTreeNode}^{MPClusteringTreeNode}}16i24
{vector<MPClusteringTreeNode *, std::allocator<MPClusteringTreeNode *>>=^^{MPClusteringTreeNode}^^{MPClusteringTreeNode}{__compressed_pair<MPClusteringTreeNode **, std::allocator<MPClusteringTreeNode *>>=^^{MPClusteringTreeNode}}}40@0:8i16f20^{MPClusteringTreeNode=@iffi^{MPClusteringTreeNode}^{MPClusteringTreeNode}^{MPClusteringTreeNode}^{MPClusteringTreeNode}}24@32
{vector<MPClusteringTreeNode *, std::allocator<MPClusteringTreeNode *>>=^^{MPClusteringTreeNode}^^{MPClusteringTreeNode}{__compressed_pair<MPClusteringTreeNode **, std::allocator<MPClusteringTreeNode *>>=^^{MPClusteringTreeNode}}}36@0:8i16^{MPClusteringTreeNode=@iffi^{MPClusteringTreeNode}^{MPClusteringTreeNode}^{MPClusteringTreeNode}^{MPClusteringTreeNode}}20@28
{vector<MPClusteringTreeNode *, std::allocator<MPClusteringTreeNode *>>=^^{MPClusteringTreeNode}^^{MPClusteringTreeNode}{__compressed_pair<MPClusteringTreeNode **, std::allocator<MPClusteringTreeNode *>>=^^{MPClusteringTreeNode}}}36@0:8f16^{MPClusteringTreeNode=@iffi^{MPClusteringTreeNode}^{MPClusteringTreeNode}^{MPClusteringTreeNode}^{MPClusteringTreeNode}}20@28
{vector<MPClusteringTreeNode *, std::allocator<MPClusteringTreeNode *>>=^^{MPClusteringTreeNode}^^{MPClusteringTreeNode}{__compressed_pair<MPClusteringTreeNode **, std::allocator<MPClusteringTreeNode *>>=^^{MPClusteringTreeNode}}}32@0:8^{MPClusteringTreeNode=@iffi^{MPClusteringTreeNode}^{MPClusteringTreeNode}^{MPClusteringTreeNode}^{MPClusteringTreeNode}}16@24
f28@0:8f16q20
f32@0:8f16q20B28
{?="plan"^v"network_index"i}
@64@0:8@16@24{?=^vi}32^v48^v56
{?=^vi}16@0:8
B56@0:8^Q16^Q24@32@40^@48
B76@0:8@16@24B32@36@44@52^@60^@68
B80@0:8@16@24B32@36@44@52i60^@64^@72
^{__CVBuffer=}36@0:8I16r^{?=^v^v[4Q][4Q]QQQQQQQQQQi}20^@28
B40@0:8r^{?=^v^v[4Q][4Q]QQQQQQQQQQi}16^{__CVBuffer=}24^@32
Q32@0:8r^{?=^v^v[4Q][4Q]QQQQQQQQQQi}16^@24
B52@0:8^{?=^vi}16@24@32B40^@44
v32@0:8{CGPoint=dd}16
@40@0:8{CGPoint=dd}16@?32
{unique_ptr<apple::vision::OpticalFlow::LKTCPU, std::default_delete<apple::vision::OpticalFlow::LKTCPU>>="__ptr_"{__compressed_pair<apple::vision::OpticalFlow::LKTCPU *, std::default_delete<apple::vision::OpticalFlow::LKTCPU>>="__value_"^{LKTCPU}}}
@28@0:8i16i20i24
v64@0:8@16^{__CVBuffer=}24{_Geometry2D_rect2D_={_Geometry2D_point2D_=ff}{_Geometry2D_size2D_=ff}}32r^v48r^v56
{shared_ptr<vision::mod::LandmarkDetectorERT>="__ptr_"^{LandmarkDetectorERT}"__cntrl_"^{__shared_weak_count}}
{CGSize=dd}20@0:8i16
v72@0:8@16^v24^{__CVBuffer=}32{vImage_Buffer=^vQQQ}40
@64@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24Q56
24@0:8Q16
r^{CGPoint=dd}16@0:8
r^{CGPoint=dd}32@0:8{CGSize=dd}16
@80@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24^56Q64@72
r^16@0:8
@72@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24^56Q64
v24@0:8r^16
^v32@0:8r^i16Q24
@92@0:8@16@24Q32{CGRect={CGPoint=dd}{CGSize=dd}}40{_Geometry2D_rect2D_={_Geometry2D_point2D_=ff}{_Geometry2D_size2D_=ff}}72f88
@"VNFaceLandmarkRegion2D"
@108@0:8@16@24Q32Q40@48{CGRect={CGPoint=dd}{CGSize=dd}}56{_Geometry2D_rect2D_={_Geometry2D_point2D_=ff}{_Geometry2D_size2D_=ff}}88f104
@32@0:8r^i16Q24
@40@0:8@16r^i24Q32
@"VNFaceLandmarkRegion3D"
@40@0:8^{__CVBuffer=}16Q24^@32
B48@0:8Q16Q24@?32^@40
B64@0:8@16@24#32Q40Q48^@56
B48@0:8@16Q24@32^@40
B56@0:8@16#24Q32@40^@48
B40@0:8@16#24^@32
B48@0:8@16#24@32^@40
B28@0:8f16^@20
B48@0:8^B16@24@32^@40
B52@0:8^B16@24@32B40^@44
B48@0:8^Q16@24@32^@40
B56@0:8^q16@24@32q40^@48
B56@0:8^Q16@24@32Q40^@48
B48@0:8^i16@24@32^@40
B56@0:8^i16@24@32i40i44^@48
B52@0:8^i16@24@32i40^@44
B56@0:8^f16@24@32f40f44^@48
B48@0:8^I16@24@32^@40
B52@0:8^I16@24@32I40^@44
B72@0:8^@16@24@32#40Q48Q56^@64
@48@0:8@16@24#32^@40
@40@0:8@16#24^@32
C16@0:8
@24@0:8r^*16
@"MPImageDescriptor_LegacySupportDoNotChange"
@"VNSceneprint"
@"<MLFeatureProvider>"
@"MLFeatureValue"24@0:8@"NSString"16
@"NSSet"16@0:8
@40@0:8^{__CVBuffer=}16@24@32
@48@0:8@16^q24@32@40
@"MLModel"
@"MLObjectBoundingBoxOutputDescription"
v32@0:8q16q24
@40@0:8^{__CVBuffer=}16@24^@32
@"VNCoreMLModel"
^{?=ff[9{?=ff}][9{?=ff}]}
@32@0:8@16^{?=ff[9{?=ff}][9{?=ff}]}24
r^{?=ff[9{?=ff}][9{?=ff}]}32@0:8@16^@24
@"VNSmartCam5CompoundRequestGroupingConfiguration"
B132@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24^{ImageDescriptorProcessorAbstract=^^?}56i64I68B72^v76@84@92@100@108@116^@124
B64@0:8^v16^v24^v32@40@48^@56
@68@0:8r^v16^v24f32@36@44@52^@60
@96@0:8r^v16^v24^{ImageClassifier_HierarchicalModel=^{ImageClassfier_Graph}}32f40f44Q48Q56@64@72@80^@88
{map<int, InternalObservedParabola, std::less<int>, std::allocator<std::pair<const int, InternalObservedParabola>>>="__tree_"{__tree<std::__value_type<int, InternalObservedParabola>, std::__map_value_compare<int, std::__value_type<int, InternalObservedParabola>, std::less<int>, true>, std::allocator<std::__value_type<int, InternalObservedParabola>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<int, InternalObservedParabola>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<int, std::__value_type<int, InternalObservedParabola>, std::less<int>, true>>="__value_"Q}}}
{ParabolaSearchBuffer="maxFramesSkippedForDetection"i"minRegionSizeX"i"minRegionSizeY"i"contourPointsQ"{deque<std::vector<CGPointWithPts>, std::allocator<std::vector<CGPointWithPts>>>="__map_"{__split_buffer<std::vector<CGPointWithPts> *, std::allocator<std::vector<CGPointWithPts> *>>="__first_"^^v"__begin_"^^v"__end_"^^v"__end_cap_"{__compressed_pair<std::vector<CGPointWithPts> **, std::allocator<std::vector<CGPointWithPts> *>>="__value_"^^v}}"__start_"Q"__size_"{__compressed_pair<unsigned long, std::allocator<std::vector<CGPointWithPts>>>="__value_"Q}}}
{InternalParameters="minRegionSizeX"i"minRegionSizeY"i"initialYDiffLimit"f"startingMinDiffDeviation"f"maxDistanceForSolution"f"frameWidth"i"frameHeight"i"xScaleFactor"f"yScaleFactor"f"runningMinDiffDeviation"i"maxFrameSkipScaleFactor"f"majorAxisScaler"f"minorAxisScalar"f"contourSizeUpperBound"f"contourSizeLowerBound"f"maxRadiusToCompensate"f"maxRadiusBasedDeviation"f"xConsistencyDeviation"f"rejectionScaler"f}
{map<int, ObservedParabola, std::less<int>, std::allocator<std::pair<const int, ObservedParabola>>>="__tree_"{__tree<std::__value_type<int, ObservedParabola>, std::__map_value_compare<int, std::__value_type<int, ObservedParabola>, std::less<int>, true>, std::allocator<std::__value_type<int, ObservedParabola>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<int, ObservedParabola>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<int, std::__value_type<int, ObservedParabola>, std::less<int>, true>>="__value_"Q}}}
{ForestAlgoParams="FAFrameRate"f"parabolaLength"i"minXDistanceFromLastPointOnParabola"i"maxXDistanceFromLastPointOnParabola"i"minYDistanceFromLastPointOnParabola"i"maxYDistanceFromLastPointOnParabola"i"maxFramesSkippedToContinueParabolaDetection"i"minObjectSize"i}
{optional<OpticalFlowOptions>=(?=c{OpticalFlowOptions=@IQQBQQfff})B}48@0:8@16Q24Q32^@40
{CVPixelBufferWrapper=^{__CVBuffer}}44@0:8Q16Q24I32^@36
@56@0:8{CVPixelBufferWrapper=^{__CVBuffer}}16{CVPixelBufferWrapper=^{__CVBuffer}}24{CVPixelBufferWrapper=^{__CVBuffer}}32r^{OpticalFlowOptions=@IQQBQQfff}40^@48
@40@0:8{CVPixelBufferWrapper=^{__CVBuffer}}16r^{OpticalFlowOptions=@IQQBQQfff}24^@32
@48@0:8{?=qiIq}16@?40
{vector<float, std::allocator<float>>="__begin_"^f"__end_"^f"__end_cap_"{__compressed_pair<float *, std::allocator<float>>="__value_"^f}}
@96@0:8Q16Q24Q32@40Q48{CGRect={CGPoint=dd}{CGSize=dd}}56@88
^{__CVBuffer=}32@0:8Q16^@24
^{__CVBuffer=}68@0:8Q16{CGRect={CGPoint=dd}{CGSize=dd}}24B56^@60
{vImage_Buffer=^vQQQ}56@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24
^{__CVBuffer=}40@0:8{CGSize=dd}16^@32
r^{mapped_model_file=^^?Q}
^{__sFILE=*iiss{__sbuf=*i}i^v^?^?^?^?{__sbuf=*i}^{__sFILEX}i[3C][1C]{__sbuf=*i}iq}16@0:8
@24@0:8r^{mapped_model_file=^^?Q}16
{unique_ptr<cvml::util::model_file_cache, std::default_delete<cvml::util::model_file_cache>>="__ptr_"{__compressed_pair<cvml::util::model_file_cache *, std::default_delete<cvml::util::model_file_cache>>="__value_"^{model_file_cache}}}
B32@0:8@"NSArray"16^@24
@"VNTracker"32@0:8@"NSDictionary"16^@24
v24@0:8@"VNTracker"16
v32@0:8@"VNDetectorCache"16@"VNDetector"24
@"VNFrameworkManager"
@"VNDetectorCache"
@32@0:8#16@24
@40@0:8r^16q24^@32
B44@0:8^d16@24B32^@36
B40@0:8^d16@24^@32
f24@0:8f16f20
B20@0:8f16
@"VNDetectBarcodesRequest"
@?<v@?@"VNRequest"d@"NSError">16@0:8
v24@0:8@?<v@?@"VNRequest"d@"NSError">16
@40@0:8q16Q24^@32
@"VNPoint"
@32@0:8@16d24
@"_VNImageAnalyzerMultiDetectorSceneOperationPointsCache"
{shared_ptr<vision::mod::ImageClassifier_HierarchicalModel>="__ptr_"^{ImageClassifier_HierarchicalModel}"__cntrl_"^{__shared_weak_count}}
{map<unsigned long, std::shared_ptr<std::vector<std::shared_ptr<vision::mod::ImageAnalyzer_CustomClassifier>>>, std::less<unsigned long>, std::allocator<std::pair<const unsigned long, std::shared_ptr<std::vector<std::shared_ptr<vision::mod::ImageAnalyzer_CustomClassifier>>>>>>="__tree_"{__tree<std::__value_type<unsigned long, std::shared_ptr<std::vector<std::shared_ptr<vision::mod::ImageAnalyzer_CustomClassifier>>>>, std::__map_value_compare<unsigned long, std::__value_type<unsigned long, std::shared_ptr<std::vector<std::shared_ptr<vision::mod::ImageAnalyzer_CustomClassifier>>>>, std::less<unsigned long>, true>, std::allocator<std::__value_type<unsigned long, std::shared_ptr<std::vector<std::shared_ptr<vision::mod::ImageAnalyzer_CustomClassifier>>>>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<unsigned long, std::shared_ptr<std::vector<std::shared_ptr<vision::mod::ImageAnalyzer_CustomClassifier>>>>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<unsigned long, std::__value_type<unsigned long, std::shared_ptr<std::vector<std::shared_ptr<vision::mod::ImageAnalyzer_CustomClassifier>>>>, std::less<unsigned long>, true>>="__value_"Q}}}
{unique_ptr<vision::mod::ImageAnalyzer_PCA, std::default_delete<vision::mod::ImageAnalyzer_PCA>>="__ptr_"{__compressed_pair<vision::mod::ImageAnalyzer_PCA *, std::default_delete<vision::mod::ImageAnalyzer_PCA>>="__value_"^{ImageAnalyzer_PCA}}}
{map<unsigned long, std::shared_ptr<vision::mod::ImageAnalyzer_CustomClassifier>, std::less<unsigned long>, std::allocator<std::pair<const unsigned long, std::shared_ptr<vision::mod::ImageAnalyzer_CustomClassifier>>>>="__tree_"{__tree<std::__value_type<unsigned long, std::shared_ptr<vision::mod::ImageAnalyzer_CustomClassifier>>, std::__map_value_compare<unsigned long, std::__value_type<unsigned long, std::shared_ptr<vision::mod::ImageAnalyzer_CustomClassifier>>, std::less<unsigned long>, true>, std::allocator<std::__value_type<unsigned long, std::shared_ptr<vision::mod::ImageAnalyzer_CustomClassifier>>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<unsigned long, std::shared_ptr<vision::mod::ImageAnalyzer_CustomClassifier>>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<unsigned long, std::__value_type<unsigned long, std::shared_ptr<vision::mod::ImageAnalyzer_CustomClassifier>>, std::less<unsigned long>, true>>="__value_"Q}}}
{vector<std::tuple<std::string, float, bool>, std::allocator<std::tuple<std::string, float, bool>>>="__begin_"^v"__end_"^v"__end_cap_"{__compressed_pair<std::tuple<std::string, float, bool> *, std::allocator<std::tuple<std::string, float, bool>>>="__value_"^v}}
{shared_ptr<vision::mod::ImageClassifier_HierarchicalModel>=^{ImageClassifier_HierarchicalModel}^{__shared_weak_count}}32@0:8Q16^@24
@"VNRecognizeDocumentElementsRequestElementConfiguration"
{shared_ptr<vision::mod::TorsoprintGenerator>="__ptr_"^{TorsoprintGenerator}"__cntrl_"^{__shared_weak_count}}
v28@0:8Q16I24
I28@0:8Q16I24
v36@0:8Q16Q24I32
^f16@0:8
v24@0:8^f16
*16@0:8
v24@0:8*16
^Q16@0:8
v24@0:8^Q16
^S16@0:8
v24@0:8^S16
S16@0:8
v20@0:8S16
s16@0:8
v20@0:8s16
@"CCCharBoxContext"
v48@0:8{vImage_Buffer=^vQQQ}16
i48@0:8Q16Q24Q32^{vImage_Buffer=^vQQQ}40
i88@0:8{vImage_Buffer=^vQQQ}16{vImage_Buffer=^vQQQ}48*80
v56@0:8S16^f20^{__CCPulseWindowContext=^{__CCRange}SSsB}28C36C40{ThresholdSet_t=fff}44
i56@0:8S16C20C24{ThresholdSet_t=fff}28^f40Q48
v48@0:8^{__CCRange=SS}16*24^i32^i40
i28@0:8^{__CCSumDerivVectors=^f^f^f^f^fffii}16i24
v24@0:8^{__CCSumDerivVectors=^f^f^f^f^fffii}16
v32@0:8^{__CCSumDerivVectors=^f^f^f^f^fffii}16i24C28
i72@0:8C16^f20S28C32C36^{__CCFilterSumDerivConfig={__CCRange=SS}{__CCRange=SS}BBQQ}40S48{ThresholdSet_t=fff}52*64
i96@0:8^f16S24S28C32C36S40S44I48I52S56{ThresholdSet_t=fff}60*72^f80Q88
v52@0:8Q16Q24Q32C40S44S48
v40@0:8Q16Q24S32S36
v44@0:8Q16^S24C32S36S40
i56@0:8^{__rgbaColor=CCCC}16^{__rgbaColor=CCCC}24I32I36^{__rgbMinMaxU8=CCCCCC}40^{__rgbMinMaxFloat=ffffff}48
I92@0:8{vImage_Buffer=^vQQQ}16{vImage_Buffer=^vQQQ}48C80^{__rgbMinMaxFloat=ffffff}84
f88@0:8{vImage_Buffer=^vQQQ}16{vImage_Buffer=^vQQQ}48S80S84
v64@0:8{vImage_Buffer=^vQQQ}16^{__CCColorProfileContext={vImage_Buffer=^vQQQ}{vImage_Buffer=^vQQQ}{vImage_Buffer=^vQQQ}{vImage_Buffer=^vQQQ}iiSS}48S56S60
v60@0:8{vImage_Buffer=^vQQQ}16S48^{__CCColorProfileContext={vImage_Buffer=^vQQQ}{vImage_Buffer=^vQQQ}{vImage_Buffer=^vQQQ}{vImage_Buffer=^vQQQ}iiSS}52
S40@0:8^f16Q24^S32
i72@0:8{vImage_Buffer=^vQQQ}16S48^S52f60^S64
v24@0:8^{__CCColorProfileContext={vImage_Buffer=^vQQQ}{vImage_Buffer=^vQQQ}{vImage_Buffer=^vQQQ}{vImage_Buffer=^vQQQ}iiSS}16
i40@0:8^{__CCColorProfileContext={vImage_Buffer=^vQQQ}{vImage_Buffer=^vQQQ}{vImage_Buffer=^vQQQ}{vImage_Buffer=^vQQQ}iiSS}16S24S28Q32
i152@0:8{vImage_Buffer=^vQQQ}16{vImage_Buffer=^vQQQ}48{vImage_Buffer=^vQQQ}80^{__rgbMinMaxU8=CCCCCC}112^{__rgbMinMaxFloat=ffffff}120S128S132S136^I140C148
i84@0:8{vImage_Buffer=^vQQQ}16{vImage_Buffer=^vQQQ}48C80
i80@0:8{vImage_Buffer=^vQQQ}16{vImage_Buffer=^vQQQ}48
i92@0:8@16Q24{vImage_Buffer=^vQQQ}32^Q64^{__CCBigBox=SSSS[50{__CCCharBox=SSSSS}]}72^{__CCBigBox=SSSS[50{__CCCharBox=SSSSS}]}80C88
v72@0:8@16^{__CCBigBox=SSSS[50{__CCCharBox=SSSSS}]}24{vImage_Buffer=^vQQQ}32C64S68
v32@0:8^{__CCBox=SSSS}16^Q24
i32@0:8^{__CCBox=SSSS}16^Q24
i56@0:8*16S24S28Q32Q40S48S52
{__CCRange=SS}76@0:8{vImage_Buffer=^vQQQ}16S48S52S56S60Q64S72
v156@0:8{vImage_Buffer=^vQQQ}16*48{vImage_Buffer=^vQQQ}56{vImage_Buffer=^vQQQ}88S120S124^{__CCBox=SSSS}128^{__CCBox=SSSS}136^Q144C152
v60@0:8^f16^f24S32S36^B40^f48C56
v84@0:8{vImage_Buffer=^vQQQ}16S48S52S56^{__rgbMinMaxFloat=ffffff}60^f68^f76
i80@0:8{vImage_Buffer=^vQQQ}16f48f52S56^f60^f68C76
I48@0:8^{__CCBigBox=SSSS[50{__CCCharBox=SSSSS}]}16C24^S28^S36B44
v40@0:8Q16Q24Q32
v72@0:8{vImage_Buffer=^vQQQ}16^f48^f56S64S68
v56@0:8^{__CCCharBox=SSSSS}16^{__CCCharBox=SSSSS}24^S32^S40S48S52
S48@0:8^{__CCCharBox=SSSSS}16^{__CCBigBox=SSSS[50{__CCCharBox=SSSSS}]}24^S32^S40
i76@0:8^{__CCBigBox=SSSS[50{__CCCharBox=SSSSS}]}16^{__CCBigBox=SSSS[50{__CCCharBox=SSSSS}]}24C32S36S40C44S48S52^{__CCCharBox=SSSSS}56^{__CCCharBox=SSSSS}64C72
i180@0:8{vImage_Buffer=^vQQQ}16{vImage_Buffer=^vQQQ}48{vImage_Buffer=^vQQQ}80^{__CCBigBox=SSSS[50{__CCCharBox=SSSSS}]}112^{__CCBigBox=SSSS[50{__CCCharBox=SSSSS}]}120^{__CCCharBox=SSSSS}128^{__CCCharBox=SSSSS}136S144S148S152*156C164^S168C176
i52@0:8{vImage_Buffer=^vQQQ}16S48
v60@0:8{vImage_Buffer=^vQQQ}16Q48B56
i24@0:8Q16
i68@0:8^{__CCBigBox=SSSS[50{__CCCharBox=SSSSS}]}16C24S28Q32^{__CCBox=SSSS}40Q48S56*60
i160@0:8@16{vImage_Buffer=^vQQQ}24*56^{__CCBigBox=SSSS[50{__CCCharBox=SSSSS}]}64^{__CCBigBox=SSSS[50{__CCCharBox=SSSSS}]}72{vImage_Buffer=^vQQQ}80{vImage_Buffer=^vQQQ}112^{__rgbMinMaxFloat=ffffff}144C152C156
i88@0:8{vImage_Buffer=^vQQQ}16{vImage_Buffer=^vQQQ}48^S80
@56@0:8{vImage_Buffer=^vQQQ}16^@48
v20@0:8C16
@"VNEspressoResources"
B48@0:8^Q16^Q24@32^@40
B40@0:8^{?=^v^v[4Q][4Q]QQQQQQQQQQi}16@24^@32
B44@0:8^{?=^v^v[4Q][4Q]QQQQQQQQQQi}16@24i32^@36
B40@0:8^{__CVBuffer=}16@24^@32
@"CRImageReaderOutput"
@40@0:8{_NSRange=QQ}16^@32
@"VNContoursObservation"
{vector<float __attribute__((ext_vector_type(2))), std::allocator<float __attribute__((ext_vector_type(2)))>>="__begin_"^"__end_"^"__end_cap_"{__compressed_pair<float * __attribute__((ext_vector_type(2))), std::allocator<float __attribute__((ext_vector_type(2)))>>="__value_"^}}
@"NSIndexPath"
@44@0:8r^v16Q24@32f40
@28@0:8f16^@20
@96@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48f80i84f88f92
@100@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48f80i84f88f92i96
@104@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48f80i84f88f92B96i100
@108@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48f80i84f88f92f96B100i104
@108@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48f80i84f88f92i96B100i104
@112@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48f80i84f88f92f96i100B104i108
B32@0:8@16f24f28
B32@0:8@16f24i28
Q24@0:8@"VNPersonsModel"16
@"<NSObject><NSCopying><NSSecureCoding>"32@0:8@"VNPersonsModel"16Q24
Q32@0:8@"VNPersonsModel"16@"<NSObject><NSCopying><NSSecureCoding>"24
Q32@0:8@"VNPersonsModel"16Q24
@"VNFaceObservation"40@0:8@"VNPersonsModel"16Q24Q32
@48@0:8Q16^@24@32^@40
{shared_ptr<vision::mod::LandmarkDetectorDNN>="__ptr_"^{LandmarkDetectorDNN}"__cntrl_"^{__shared_weak_count}}
{vector<_Geometry2D_point2D_, std::allocator<_Geometry2D_point2D_>>="__begin_"^{_Geometry2D_point2D_}"__end_"^{_Geometry2D_point2D_}"__end_cap_"{__compressed_pair<_Geometry2D_point2D_ *, std::allocator<_Geometry2D_point2D_>>="__value_"^{_Geometry2D_point2D_}}}
B48@0:8^Q16^i24@32^@40
B36@0:8^v16i24^@28
B60@0:8Q16^^{__CVBuffer}24I32Q36Q44^@52
B72@0:8^{?=[3]}16^{__CVBuffer=}24^{__CVBuffer=}32^{ImageRegistrationCtx_s=}40^v48r^{?=[3]}56^@64
#24@0:8@16
v72@0:8@16@24^{__CVBuffer=}32{vImage_Buffer=^vQQQ}40
@"ShotflowDetector"
v76@0:8@16@24{CGRect={CGPoint=dd}{CGSize=dd}}32f64@68
{shared_ptr<vision::mod::ImageClassifier_HierarchicalModel>=^{ImageClassifier_HierarchicalModel}^{__shared_weak_count}}24@0:8^@16
@"VN6B8mkraBUpwUqskMYPtS3"
@56@0:8@16@24@32f40f44Q48
@52@0:8@16@24@32f40Q44
@64@0:8@16@24@32f40f44Q48Q56
@44@0:8@16@24@32f40
@48@0:8@16@24@32f40f44
@"<VNClustererModelQuerying>"
@"<VNClustererModelQuerying><VNClustererModelBuilding>"
@"CRDocumentOutputRegion"
{_NSRange=QQ}24@0:8@16
@32@0:8Q16q24
@32@0:8{_NSRange=QQ}16
@48@0:8Q16{CGPoint=dd}24q40
@"DDScannerResult"
@"VNObservation"
@"BCSDetectedCode"
@"CROutputRegion"
@"NSAttributedString"
@64@0:8r^v16Q24Q32Q40Q48@56
@64@0:8r^v16Q24Q32Q40Q48Q56
@"VNEntityIdentificationModel"
@"<VNEntityIdentificationModelDataSource>"
@"<VNEntityIdentificationModelDelegate>"
{?="willTrain"b1"didTrain"b1"failedTraining"b1"willDropTrainingData"b1"didDropTrainingData"b1}
@"VNEntityIdentificationModelConfiguration"
@"VNEntityIdentificationModelTrainedModel"
@64@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24B56f60
{vector<std::shared_ptr<espresso_buffer_t>, std::allocator<std::shared_ptr<espresso_buffer_t>>>="__begin_"^v"__end_"^v"__end_cap_"{__compressed_pair<std::shared_ptr<espresso_buffer_t> *, std::allocator<std::shared_ptr<espresso_buffer_t>>>="__value_"^v}}
[10B]
[6[10[2f]]]
@40@0:8@16i24i28i32f36
@44@0:8{?=^vi}16^v32f40
v36@0:8@16i24i28i32
i32@0:8Q16Q24
v52@0:8{vImage_Buffer=^vQQQ}16B48
@52@0:8{vImage_Buffer=^vQQQ}16B48
{tuple<float, float, float>={__tuple_impl<std::__tuple_indices<0, 1, 2>, float, float, float>=fff}}16@0:8
@40@0:8@16f24i28i32i36
Q32@0:8Q16^@24
{unique_ptr<vision::mod::ImageDescriptorProcessorHyperplaneLSH<float>, std::default_delete<vision::mod::ImageDescriptorProcessorHyperplaneLSH<float>>>="__ptr_"{__compressed_pair<vision::mod::ImageDescriptorProcessorHyperplaneLSH<float> *, std::default_delete<vision::mod::ImageDescriptorProcessorHyperplaneLSH<float>>>="__value_"^v}}
{shared_ptr<vision::mod::ImageDescriptorBufferAbstract>=^{ImageDescriptorBufferAbstract}^{__shared_weak_count}}32@0:8@16^@24
{shared_ptr<vision::mod::ImageDescriptorBufferAbstract>=^{ImageDescriptorBufferAbstract}^{__shared_weak_count}}40@0:8r^v16@24^@32
v32@0:8{CGSize=dd}16
{shared_ptr<vision::mod::FaceBoxPoseAligner<signed char>>="__ptr_"^v"__cntrl_"^{__shared_weak_count}}
@"<VNModelFile>"
{shared_ptr<vision::mod::ObjectTrackerAbstract>="__ptr_"^{ObjectTrackerAbstract}"__cntrl_"^{__shared_weak_count}}
^v40@0:8@16^{ObjectTrackerOptions=^^?@i}24^@32
B64@0:8@16^v24{CGSize=dd}32@48^@56
@120@0:8B16B20^{__CVBuffer=}24@32{CGSize=dd}40{CGSize=dd}56{CGRect={CGPoint=dd}{CGSize=dd}}72@104^@112
@52@0:8Q16@24@32B40@44
{shared_ptr<vision::mod::CamGazePredictor>="__ptr_"^{CamGazePredictor}"__cntrl_"^{__shared_weak_count}}
{shared_ptr<vision::mod::GazeFollowPredictor>="__ptr_"^{GazeFollowPredictor}"__cntrl_"^{__shared_weak_count}}
@"VNObservationsCache"
@"VNRequestForensics"
@"VNImageBuffer"24@0:8^@16
@56@0:8@16@24@32@40@48
@60@0:8@16@24@32@40@48I56
B48@0:8^{__CVBuffer=}16@24@32^@40
@96@0:8^{__CVBuffer=}16@24{CGSize=dd}32{CGRect={CGPoint=dd}{CGSize=dd}}48@80^@88
@"VNHomographyTrackerState"
B52@0:8^{CGAffineTransform=dddddd}16@24@32f40^@44
@"<VNPersonsModelDataDelegate>"
@52@0:8B16@20Q28@36^@44
@40@0:8^{__CVBuffer=}16@24@?32
@44@0:8^{__CVBuffer=}16I24@28@?36
@40@0:8^{CGImage=}16@24@?32
@44@0:8^{CGImage=}16I24@28@?36
@40@0:8@16@24@?32
@44@0:8@16I24@28@?36
@40@0:8^{opaqueCMSampleBuffer=}16@24@?32
@44@0:8^{opaqueCMSampleBuffer=}16I24@28@?36
B84@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGSize=dd}48i64^{CGRect={CGPoint=dd}{CGSize=dd}}68^@76
B32@0:8@16d24
B40@0:8@16^@24^@32
@44@0:8^{__CVBuffer=}16I24@28@36
@40@0:8^{CGImage=}16@24@32
@44@0:8^{CGImage=}16I24@28@36
@44@0:8@16I24@28@36
@40@0:8^{opaqueCMSampleBuffer=}16@24@32
@44@0:8^{opaqueCMSampleBuffer=}16I24@28@36
fgla
FNA*
fsba
tAFC
eAIC
gmIC
knJC
meMC
10NV
mLPC
20NV
30NV
LMoc
pmna
pted
MRFC
pcaf
pt+f
40NV
pgmi
plrn
pncs
pcms
psrt
raBD
tnCD
gSDD
QCFD
mLFD
L3FD
xEFD
zGFD
oPFD
caFD
roHD
PBHD
PHHD
HuHD
RuHD
tPOD
ceRD
zGSD
txTD
jrTD
nAF*
StAG
gSFG
PFIG
SmIG
SbOG
FpOG
50NV
gSPG
iprg
gerh
knuj
rlbi
AmI*
pxei
 pon
inAR
hnAR
D&FR
jbOR
bsOR
txTR
lEDR
coDR
necs
5mS*
gmHT
CFLT
jbOT
ceRT
gert
2NA>
3NA>
4NA>
1pA>
2pA>
rlB>
trB>
noC>
LMC>
RmI>
DmI>
PeD>
gSD>
1MF>
2MF>
3MF>
4MF>
5MF>
ABF>
CFL>
1aF>
2aF>
xEF>
zGF>
eGF>
1LF>
2LF>
3LF>
1PF>
 QF>
MRF>
gSF>
SbO>
!OS>
FAH>
1AH>
RIH>
TgH>
zrH>
PBH>
PHH>
AmI>
1NV>
pmI>
gRI>
SmI>
knJ>
meM>
1pO>
FpO>
gSP>
SSP>
FSP>
LSP>
ceR>
BAS>
BOS>
ncS>
zGS>
pcS>
CmS>
5mS>
S+A>
2rT>
3rT>
4rT>
5rT>
1rT>
Me!>
`Y?*
K/>n
4?Rc
As?@
[?>Y
5?+3A?&S
>;9W?@1
^y>?
>3PI>
j?}Y
?}wG?X
&>CVK?
q'?ep0?
xj>t
>: i?
6:>0
>=`Z?
=aR<>=
aK=e
>A*q?C
t=+jp>B
->g,&?"R;?
>?k}A>}
G?c%
O?Ig
>obp?
$X?7pG>
>h@=>H
\'?`
7?BZg?
{>?q
g?> 
=6rQ?
8?6v
y?F$&?~
L?6X
GS?R
>FA?6Wq?
{?OX
>9{3?1
*?<h6>
?X:/>
XQ?$~
>S\%>o
v#?Y
@#?o+u?
{v>U
*X?S]
>c~j?'
>5)E?
>:u)?w1E?
>}y)?
W?:U?<L
B%?-|
?sc~?
>}>2?
=?!"
6=JCA?
.?m<4?
I>O\R?
Dc?#I
D?R(
LA?:
>R`U?
\?@h}?:
?=`b?
L>h\
??yYS?
>WCB>mq
>k,a=T
a?V)}?
?]m}?
>$%M?
Oi>-
d?6x{?
>|HX?DnV>
>W!E>w
>~t*>+
OU=0cn?
E\?+5o?
)?kb
}?C<
uQ?1A
=Nd6>
Ch=R
Nx>(-\=c)
`I>K9
"~=p
=8hS?.
\)<]pF=
$?OZ
>9`'?
r=?}vp>5&<?-yx? 
R>x~
rj>?V$?
>L?;
E?oI2?
>b1*>
>?pB
>:X'?
C?AcB?
=?Vb>?
>BAY>T
~'> ~*?
d?%=
t?`w
@?5(j>yt
^$?v
-Z?mq
ms?@O
333?
*F+I
Ixam
I/Em
 O/R
 O+E
*F+I
Ixam
I/Em
MFor
doml
qere
ldmt
)\O?
333333
