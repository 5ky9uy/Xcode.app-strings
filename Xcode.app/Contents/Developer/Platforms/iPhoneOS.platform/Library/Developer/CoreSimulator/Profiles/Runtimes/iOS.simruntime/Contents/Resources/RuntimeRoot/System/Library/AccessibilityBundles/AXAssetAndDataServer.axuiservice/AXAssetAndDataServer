v8@?0
refresh-voices
AXCustomPronunciations
AXVoiceOverActivities
Reconciled iCloud pronunciations: adding: %{private}@
Did not find a change, not updating
CustomPronunciationSubstitutions
NPS: Publishing data to nano domain
ICLOUD[%p]: Waiting 5s to publish, deleting %@
Created an empty length archive, not synching
ICLOUD[%p]: Publishing data to iCloud %{private}@
Custom pronunciations settings updated
@16@?0@"TTSAXResource"8
/Library/Caches/com.apple.xbs/Sources/AccessibilityFrameworks_Sim/Source/AXAssetAndDataServer/AXAssetAndDataServer.m
-[AXAssetAndDataServer _updateCachedTTSVoices]_block_invoke
We just refreshed voices, why are they missing?
-[AXAssetAndDataServer _handleExtantVoices]
Why is name nil for %@ %@
VoiceId
Language
Name
en-US
@"NSArray"8@?0
@"NSString"40@?0@"TTSVoiceAsset"8@"NSString"16q24@"NSString"32
@"NSString"32@?0@"TTSVoiceAsset"8@"NSString"16q24
B24@?0@"TTSVoiceAsset"8Q16
LastSpeechAssetUpdateCheck
com.apple.accessibility.api
com.apple.private.kernel.jetsam
com.apple.CoreRoutine.preferences
com.apple.TVServices.DisplayManager
com.apple.accessibility.voiceover
com.apple.appletv.pbs.display-manager-service-access
com.apple.accessibility.axctl
delete
options
audioLevel
v16@?0Q8
v20@?0B8@"NSError"12
com.apple.accessibility.controlcenter.sounddetection
got transcription results: %@
AXSpeechPronunciationClient
results
v24@?0@"NSDictionary"8@"NSError"16
Fail: %@, %d
Error
error
Starting pronunciation dictation: %@, %@, %@
q24@?0@"TTSVoiceAsset"8@"TTSVoiceAsset"16
v28@?0d8B16@"NSError"20
v16@?0@"MAProgressNotification"8
v16@?0q8
CCSControlCenterService
Unable to find class %s
AXHearingAidControlCenterBundleID
AXAssetAndDataServer
AXUIService
NSObject
AFAssistantUIService
AFSpeechDelegate
AFDictationDelegate
init
sharedInstance
mobileAssetWorkQueue
initWithTargetSerialQueue:
setAutomaticallyCancelPendingBlockUponSchedulingNewBlock:
_monitoriCloudVoiceOverData
_icloudDataChanged:
afterDelay:processBlock:
sharedDatabase
setCloudKitSync:
setCloudKitPushInSameProcess:
defaultStore
dataForKey:
initForReadingFromData:error:
arrayWithObjects:count:
setWithArray:
decodeObjectOfClasses:forKey:
count
_iCloudReconcileDataStore:
_iCloudReconcileActivitiesStore:
synchronize
syncPronunciationsWithCloudKit
_reconcilePronunciations
_reconcileActivities
voiceOverActivities
countByEnumeratingWithState:objects:count:
indexOfObject:
objectAtIndexedSubscript:
isIdenticalTo:
setVoiceOverActivities:
ignoreLogging
identifier
customPronunciationSubstitutions
containsObject:
_syncToWatch
setCustomPronunciationSubstitutions:
setWithObject:
synchronizeUserDefaultsDomain:keys:
copy
archivedDataWithRootObject:requiringSecureCoding:error:
length
setData:forKey:
_saveCustomPronunciationsToExternalsAndDelete:
_customPronunciationsSettingsChanged
registerUpdateBlock:forRetrieveSelector:withListener:
_saveActivitiesToExternalsAndDelete:
defaultCenter
addObserver:selector:name:object:
currentLocale
languageCode
letterFeedbackEnabled
phoneticFeedbackEnabled
wordFeedbackEnabled
quickTypeWordFeedbackEnabled
speakCorrectionsEnabled
isEqualToString:
userDidSelectVoiceForLanguage:source:
resourcesWithLanguage:type:
speechVoice
ax_flatMappedArrayUsingBlock:
isDefault
speechVoiceIdentifierForLanguage:source:exists:
voiceForIdentifier:
footprint
isNeuralSiriVoiceIdentifier:
setSpeechVoiceIdentifier:forLanguage:source:
language
informSiriAboutVoiceUsageForIdentifier:forLanguage:add:
voiceRefreshQueue
dictionary
numberWithBool:
setObject:forKeyedSubscript:
setCurrentVoices:
availableVoices:
currentVoices
_handleExtantVoices
objectForKeyedSubscript:
_updateDefaultVoiceIfNecessaryForLanguage:source:
mobileAssetDownloadQueue
_downloadAssetsForSelectedVoices
attributes
firstObject
stringByReplacingOccurrencesOfString:withString:
_combinedVocalizerAssets:
boolValue
intValue
_languageForAsset:
setIsCombinedVoice:
setNonCombinedVoiceId:
objectForKey:
allInstalledAssetsForVoiceId:
setIdentifier:
setLanguage:
setNonLocalizedNameWithoutQuality:
setQuality:
setGender:
setIsInstalled:
unsignedIntegerValue
setAssetSize:
setCanBeDownloaded:
addObject:
_vocalizerAssets
gender
languages
name
fileSize
numberWithLongLong:
isInstalled
state
supportsAlex
nameForVoiceIdentifier:
array
neural
_normalizedSiriName:
axSafelyAddObject:
_handleSiriStyleVoices:assetRetrieval:voiceIdentifier:voiceName:
axFilterObjectsUsingBlock:
setExtantVoices:
lowercaseString
migratePrefToNeuralVoiceIfNecessaryForVoice:
isSiriVoiceIdentifier:
startDownloadingVoice:
standardUserDefaults
date
dateByAddingTimeInterval:
setObject:forKey:
timeIntervalSinceReferenceDate
extantVoices
_checkForMacinTalkAssetUpdates
_checkForVocalizerAssetUpdates
_updateCachedTTSVoices
setWithObjects:
_checkForAssets:
valueForKey:
secureUnarchiveData:withExpectedClass:otherAllowedClasses:
_startPronunciationSession:
_cancelPronunciationSession
_stopPronunciationSession
_pronunciationAudioLevel
numberWithFloat:
dictionaryWithObjects:forKeys:count:
selectedSpeechVoiceIdentifiers
installedAssetsForLanguage:voiceType:
axSafelyAddObjectsFromArray:
setAutoDownloadedVoiceAssets:
setSiriAutoUpdateListInitialized:
requestEnableModuleWithIdentifier:completionHandler:
getEnabledStateOfModuleWithIdentifier:completionHandler:
systemLanguageID
isVocalizerVoiceIdentifier:
informSiriVoiceSubscriptionsWithVoiceId:addition:
_handleFailureForSpeechPronunciation:
averagePower
stopSpeechWithOptions:
cancelSpeech
phonemeSuggestions
clientMessengerWithIdentifier:
backgroundAccessQueue
sendAsynchronousMessage:withIdentifier:targetAccessQueue:completion:
endSession
description
setDelegate:
setTranscriptionMode:
orthography
setOrthography:
initWithActivationEvent:
setIsEyesFree:
setEndpointerOperationMode:
startDictationWithLanguageCode:options:speechOptions:
initWithType:
setDoNotBlockBeforeFirstUnlock:
returnTypes:
queryMetaDataSync
results
assetsForLanguage:voiceType:
masteredVersion
sortedArrayUsingComparator:
setAllowsCellularAccess:
totalWritten
totalExpected
_alexAssets
_beginDownloadIfNecessaryForAssets:
_vocalizerAssetsForLanguage:
_beginDownloadIfNecessaryForSiriAssets:
voiceAssetForVoiceId:
downloadAsset:progressHandler:
selectedIdsForTesting
isCompactVocalizerVoiceIdentifier:
isAssetManagedBySiriForVoiceId:
_handleSiriAssetDownload:
_handleMobileAssetDownload:
mobileAssetForVoiceId:
hasPrefix:
_voiceFromInternalVoiceListWithIdentifier:
isCombinedVocalizerVoiceIdentifier:
compare:options:
cleanUpExtraInstalledAssetsIfNecessary:
inUnitTestMode
replaceTestAsset:withAsset:
spaceCheck:
_handleAssetProgress:asset:installedAsset:
attachProgressCallBack:
_mobileAssetDownloadOptions
_updateAsset:existingAsset:
startDownload:then:
assetType
assetIsDownloading:
purgeAsset:
alexLocalAssetURL
getLocalFileUrl
isEqual:
_addToDownloadQueue:
purge:
_purgeExistingAsset:inFavorOfAsset:
setAlexLocalAssetURL:
defaultManager
path
setAttributes:ofItemAtPath:error:
possibleRequiredEntitlementsForProcessingMessageWithIdentifier:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
debugDescription
TQ,R
T#,R
T@"NSString",R,C
processMessage:withIdentifier:fromClientWithIdentifier:error:
messageWithIdentifierShouldBeProcessedAsynchronously:
processMessageAsynchronously:withIdentifier:fromClientWithIdentifier:completion:
accessQueueForProcessingMessageWithIdentifier:
messageWithIdentifierRequiresWritingBlock:
processInitializationMessage:
serviceWasFullyInitialized
connectionWillBeInterruptedForClientWithIdentifier:
requiredEntitlementForProcessingMessageWithIdentifier:
assistantConnectionRequestWillStart:
assistantConnectionDismissAssistant:
assistantConnection:dismissAssistantWithReason:
assistantConnectionRequestFinished:
assistantConnection:receivedCommand:completion:
assistantConnection:requestFailedWithError:requestClass:
assistantConnection:openURL:completion:
assistantConnection:openApplicationWithBundleID:URL:completion:
assistantConnection:shouldSpeak:
assistantConnection:didChangeAudioSessionID:
assistantConnectionAudioSessionDidBeginInterruption:
assistantConnectionAudioSessionDidBeginInterruption:userInfo:
assistantConnectionAudioSessionDidEndInterruption:shouldResume:
assistantConnectionAudioSessionDidEndInterruption:shouldResume:userInfo:
assistantConnectionWillStartAcousticIDRequest:
assistantConnectionDidDetectMusic:
assistantConnection:didFinishAcousticIDRequestWithSuccess:
assistantConnection:setUserActivtiyInfoAndMakeCurrent:webpageURL:
assistantConnectionInvalidateCurrentUserActivity:
assistantConnection:wantsToCacheImage:
assistantConnection:extensionRequestWillStartForApplication:
assistantConnection:extensionRequestFinishedForApplication:error:
assistantConnection:startUIRequestWithText:completion:
assistantConnection:startUIRequestWithInfo:completion:
assistantConnection:willStartAudioPlaybackRequest:
assistantConnection:didStartAudioPlaybackRequest:
assistantConnection:didStopAudioPlaybackRequest:error:
assistantConnection:didHandleQuickStopWithAction:
assistantConnection:willProcessStartPlayback:intent:completion:
assistantConnection:willProcessStartPlayback:
assistantConnection:startPlaybackDidFail:
assistantConnection:audioSessionWillBecomeActive:
assistantConnection:audioSessionDidBecomeActive:
assistantConnection:willProcessAppLaunchWithBundleIdentifier:
assistantConnection:appLaunchFailedWithBundleIdentifier:
assistantConnectionSpeechRecordingWillBegin:
assistantConnection:speechRecordingWillBeginWithInputAudioPowerXPCWrapper:
assistantConnection:speechRecordingDidBeginOnAVRecordRoute:
assistantConnection:speechRecordingDidBeginOnAVRecordRoute:audioSessionID:
assistantConnection:speechRecordingDidChangeAVRecordRoute:
assistantConnectionSpeechRecordingDidDetectStartpoint:
assistantConnection:speechRecordingPerformTwoShotPromptWithType:completion:
assistantConnectionSpeechRecordingDidEnd:
assistantConnectionSpeechRecordingDidCancel:
assistantConnection:speechRecordingDidFail:
assistantConnectionDidChangeAudioRecordingPower:
assistantConnection:speechRecognitionDidFail:
assistantConnection:speechRecognized:
assistantConnection:speechRecognizedPartialResult:
assistantConnection:recognizedAdditionalSpeechInterpretation:refId:
assistantConnection:recognitionUpdateWithPhrases:utterances:refId:
assistantConnection:recognitionUpdateWillBeginForTask:
dictationConnectionSpeechRecordingWillBegin:
dictationConnectionSpeechRecordingDidBegin:
dictationConnection:speechRecordingDidBeginWithOptions:
dictationConnection:didBeginLocalRecognitionWithModelInfo:
dictationConnectionSpeechRecordingDidEnd:
dictationConnectionSpeechRecordingDidCancel:
dictationConnection:speechRecordingDidFail:
dictationConnection:speechRecognitionDidFail:
dictationConnection:didDetectLanguage:confidenceScores:
dictationConnection:didDetectLanguage:confidenceScores:isConfident:
dictationConnection:didRecognizeMultilingualSpeech:
dictationConnection:languageDetectorFailedWithError:
dictationConnection:didRecognizePhrases:languageModel:correctionIdentifier:
dictationConnection:didRecognizePhrases:languageModel:correctionIdentifier:replacingPreviousPhrasesCount:
dictationConnection:didRecognizeTokens:languageModel:
dictationConnection:didRecognizeTokens:nluResult:languageModel:
dictationConnection:didRecognizePartialResult:
dictationConnection:didProcessAudioDuration:
dictationConnectionSpeechRecognitionDidSucceed:
dictationConnection:didRecognizeTranscriptionObjects:languageModel:
dictationConnnectionDidChangeAvailability:
dictationConnection:didFinishWritingAudioFile:error:
dictationConnection:didReceiveSearchResults:recognizedText:stable:final:
dictationConnection:didRecognizePackage:
dictationConnection:didRecognizePackage:nluResult:
dictationConnectionDidPauseRecognition:
_isVocalizerAsset:
_purgeExistingSiriAsset:inFavorOfAsset:
setVoiceRefreshQueue:
.cxx_destruct
_lastTTSVoiceAssetUpdate
_pronunciationPusher
_lastActivitiesICloudRetrieval
_activitiesPusher
_isUpdatingCachedTTSVoices
_dictationConnection
_isRecording
_assetService
_voiceRefreshQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_voiceRefreshQueue
Checking pronunciations
Got pronunciations: %{private}@, count: %d
Exception decoding data: %@
Checking activities
Got activities: count: %d
did not find %@ in %@
%@ not identical to %@
Reconciled iCloud activities: adding: %{private}@
Did not find a change, not updating
%{public}@
Skipping publishing to iCloud because we just retrieved this data
Created an empty length archive, not synching
ICLOUD[%p]: Publishing data to iCloud %{private}@
Not updating default spoken content voice because no speech features are enabled.
Not updating default spoken content voice because switch control is not enabled.
Not updating default voice because the voice doesn't match our system language.
Switching voice from %@ to %@ for source %ld because default voice has changed, and the user hasn't selected one for language %@
Vocalizer assets example[0]: %{public}@
Victoria macinTalkAsset: %{public}@
local macinTalkAsset: %{public}@
remote macinTalkAsset: %{public}@
New siri names %@
Original old siri assets %@
Filtered out old siri assets so we're left with %@
Siri voices not supported
Set extant voices: %{public}@
Retrieved siri-style assets: %{public}@
Siri style: skipping non premium: %@
Siri style: skipping neural: %@
Processed Siri-style assets: %{public}@
made siri voice %@ with asset %@
Updating spoken content settings because the selected voice was a Siri voice, but a neural voice matching the same name and language: %@ was available
Downloading %@ because a non-neural variant was previously selected, but a neural variant is now available
Removing %@ from active siri list, because neural voice was available and non-neural version wasn't in use outside of Speech Features
Force checking speech assets: %d date: %{public}@
No previous LastSpeechAssetUpdateCheck was found. Setting date earlier: %{public}@.
Has speech asset data: %d
Not checking voice assets because it's too soon: %{public}@ - only %f seconds 
Checking on assets now
Asset is installed and is in selected voices: %@
Hearing aid control status: %d
Added hearing to control center: %@ success: %d
Sound detection control status: %d
Added sound detection to control center: %@ success: %d
Inform siri about %@
MAAssetQuery error fetching results %{public}@ %{public}@ %{public}@
Asset progress: %{public}@ - %f
Checking assets: %{public}@
checking assets[%{public}@] %{public}@
Handling download for %@ %@
Finished downloading asset: %@, %@
Updating siri voice list usage after downloading a selected voice ID that was missing
could not parse voice identifier %{public}@
could not find asset for voice identifier %{public}@ but the voice was installed. This is expected if it is a built-in voice.
could not find asset for voice identifier %{public}@
selected voice %{public}@ is already downloading.
selected voice %{public}@ is required by the OS.
selected voice %{public}@ is installed but not in the catalog.
selected voice %{public}@ has unknown state.
selected voice %{public}@ is already installed.
selected voice %{public}@ %@ is not present. Beginning download.
Asset not present, but no space to download voice %{public}@: %{public}@
asset installed with os
Adding asset to queue: %{public}@
No siri asset installed
Installed asset %{public}@, latest asset: %{public}@
Detected new Asset, downloading: %{public}@
Enough disk space available - start %{public}@
Updating Installed Asset: %{public}@
Error: %{public}@
Asset state: %@
Error: Not enough disk space
No newer asset than %{public}@ - [installed asset %{public}@]
Purging old asset: %{public}@
No macintalk or siri asset installed
No newer asset than %{public}@ - %@ [installed asset %{public}@]
Purged old asset: %{public}@, %{public}@
Trying to update unknown asset (expecting Macintalk, Combined, or Siri): %{public}@
Could not remove file protection from: %{public}@
Could not purge old asset: %{public}@
@16@0:8
@24@0:8Q16
B24@0:8@16
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B16@0:8
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
@48@0:8@16Q24@32^@40
B24@0:8Q16
v48@0:8@16Q24@32@?40
v24@0:8@16
v16@0:8
@"NSDictionary"48@0:8@"NSDictionary"16Q24@"NSString"32^@40
v48@0:8@"NSDictionary"16Q24@"NSString"32@?<v@?@"NSDictionary"@"NSError">40
@"AXAccessQueue"24@0:8Q16
v24@0:8@"NSDictionary"16
v24@0:8@"NSString"16
@"NSString"24@0:8Q16
@"NSSet"24@0:8Q16
v32@0:8@16q24
v40@0:8@16@24@?32
v40@0:8@16@24@32
v48@0:8@16@24@32@?40
v28@0:8@16B24
v28@0:8@16I24
v32@0:8@16@24
v36@0:8@16B24@28
v32@0:8@16Q24
v48@0:8@16q24@32@?40
v24@0:8@"AFConnection"16
v32@0:8@"AFConnection"16q24
v40@0:8@"AFConnection"16@"AceObject<SAAceCommand>"24@?<v@?@"AceObject<SAAceCommand>">32
v40@0:8@"AFConnection"16@"NSError"24@"NSString"32
v40@0:8@"AFConnection"16@"NSURL"24@?<v@?B>32
v48@0:8@"AFConnection"16@"NSString"24@"NSURL"32@?<v@?B>40
v28@0:8@"AFConnection"16B24
v28@0:8@"AFConnection"16I24
v32@0:8@"AFConnection"16@"NSDictionary"24
v36@0:8@"AFConnection"16B24@"NSDictionary"28
v40@0:8@"AFConnection"16@"NSDictionary"24@"NSURL"32
v32@0:8@"AFConnection"16@"INImage"24
v32@0:8@"AFConnection"16@"NSString"24
v40@0:8@"AFConnection"16@"NSString"24@"NSError"32
v40@0:8@"AFConnection"16@"NSString"24@?<v@?B>32
v40@0:8@"AFConnection"16@"AFRequestInfo"24@?<v@?B>32
v32@0:8@"AFConnection"16@"AFAudioPlaybackRequest"24
v40@0:8@"AFConnection"16@"AFAudioPlaybackRequest"24@"NSError"32
v32@0:8@"AFConnection"16Q24
v48@0:8@"AFConnection"16q24@"INIntent"32@?<v@?BB>40
v36@0:8@16@24I32
v40@0:8@16q24@?32
v48@0:8@16@24@32@40
v32@0:8@"AFConnection"16@"AFXPCWrapper"24
v36@0:8@"AFConnection"16@"NSString"24I32
v40@0:8@"AFConnection"16q24@?<v@?dd@"NSError">32
v32@0:8@"AFConnection"16@"NSError"24
v32@0:8@"AFConnection"16@"SASSpeechRecognized"24
v32@0:8@"AFConnection"16@"SASSpeechPartialResult"24
v40@0:8@"AFConnection"16@"AFSpeechInterpretation"24@"NSString"32
v48@0:8@"AFConnection"16@"NSArray"24@"NSArray"32@"NSString"40
v44@0:8@16@24@32B40
v56@0:8@16@24@32@40Q48
v32@0:8@16d24
v48@0:8@16@24@32B40B44
v24@0:8@"AFDictationConnection"16
v32@0:8@"AFDictationConnection"16@"AFDictationOptions"24
v32@0:8@"AFDictationConnection"16@"NSString"24
v32@0:8@"AFDictationConnection"16@"NSError"24
v40@0:8@"AFDictationConnection"16@"NSString"24@"NSDictionary"32
v44@0:8@"AFDictationConnection"16@"NSString"24@"NSDictionary"32B40
v32@0:8@"AFDictationConnection"16@"SASMultilingualSpeechRecognized"24
v48@0:8@"AFDictationConnection"16@"NSArray"24@"NSString"32@40
v56@0:8@"AFDictationConnection"16@"NSArray"24@"NSString"32@40Q48
v40@0:8@"AFDictationConnection"16@"NSArray"24@"NSString"32
v48@0:8@"AFDictationConnection"16@"NSArray"24@"AFDictationNLUResult"32@"NSString"40
v32@0:8@"AFDictationConnection"16@"SASSpeechPartialResult"24
v32@0:8@"AFDictationConnection"16d24
v40@0:8@"AFDictationConnection"16@"NSFileHandle"24@"NSError"32
v48@0:8@"AFDictationConnection"16@"NSArray"24@"NSString"32B40B44
v32@0:8@"AFDictationConnection"16@"AFSpeechPackage"24
v40@0:8@"AFDictationConnection"16@"AFSpeechPackage"24@"AFDictationNLUResult"32
@24@0:8@16
v48@0:8@16@?24@?32@?40
v20@0:8B16
v36@0:8@16@24B32
f16@0:8
@20@0:8B16
@"AXDispatchTimer"
@"AFDictationConnection"
@"AXAssetsService"
@"NSObject<OS_dispatch_queue>"
softlink:r:path:/System/Library/PrivateFrameworks/ControlCenterServices.framework/ControlCenterServices
softlink:r:path:/System/Library/PrivateFrameworks/HearingUtilities.framework/HearingUtilities
AWos}
v8@?0
refresh-voices
AXCustomPronunciations
AXVoiceOverActivities
Reconciled iCloud pronunciations: adding: %{private}@
Did not find a change, not updating
CustomPronunciationSubstitutions
NPS: Publishing data to nano domain
ICLOUD[%p]: Waiting 5s to publish, deleting %@
Created an empty length archive, not synching
ICLOUD[%p]: Publishing data to iCloud %{private}@
Custom pronunciations settings updated
@16@?0@"TTSAXResource"8
/Library/Caches/com.apple.xbs/Sources/AccessibilityFrameworks_Sim/Source/AXAssetAndDataServer/AXAssetAndDataServer.m
-[AXAssetAndDataServer _updateCachedTTSVoices]_block_invoke
We just refreshed voices, why are they missing?
-[AXAssetAndDataServer _handleExtantVoices]
Why is name nil for %@ %@
VoiceId
Language
Name
en-US
@"NSArray"8@?0
@"NSString"40@?0@"TTSVoiceAsset"8@"NSString"16q24@"NSString"32
@"NSString"32@?0@"TTSVoiceAsset"8@"NSString"16q24
B24@?0@"TTSVoiceAsset"8Q16
LastSpeechAssetUpdateCheck
com.apple.accessibility.api
com.apple.private.kernel.jetsam
com.apple.CoreRoutine.preferences
com.apple.TVServices.DisplayManager
com.apple.accessibility.voiceover
com.apple.appletv.pbs.display-manager-service-access
com.apple.accessibility.axctl
delete
options
audioLevel
v16@?0Q8
v20@?0B8@"NSError"12
com.apple.accessibility.controlcenter.sounddetection
got transcription results: %@
AXSpeechPronunciationClient
results
v24@?0@"NSDictionary"8@"NSError"16
Fail: %@, %d
Error
error
Starting pronunciation dictation: %@, %@, %@
q24@?0@"TTSVoiceAsset"8@"TTSVoiceAsset"16
v28@?0d8B16@"NSError"20
v16@?0@"MAProgressNotification"8
v16@?0q8
CCSControlCenterService
Unable to find class %s
AXHearingAidControlCenterBundleID
AXAssetAndDataServer
AXUIService
NSObject
AFAssistantUIService
AFSpeechDelegate
AFDictationDelegate
_voiceFromInternalVoiceListWithIdentifier:
voiceForIdentifier:
voiceAssetForVoiceId:
valueForKey:
userDidSelectVoiceForLanguage:source:
unsignedIntegerValue
totalWritten
totalExpected
timeIntervalSinceReferenceDate
systemLanguageID
synchronizeUserDefaultsDomain:keys:
synchronize
syncPronunciationsWithCloudKit
supportsAlex
stringByReplacingOccurrencesOfString:withString:
stopSpeechWithOptions:
state
startDownloadingVoice:
startDownload:then:
startDictationWithLanguageCode:options:speechOptions:
standardUserDefaults
speechVoiceIdentifierForLanguage:source:exists:
speechVoice
speakCorrectionsEnabled
spaceCheck:
sortedArrayUsingComparator:
sharedDatabase
setWithObjects:
setWithObject:
setWithArray:
setVoiceOverActivities:
setTranscriptionMode:
setSpeechVoiceIdentifier:forLanguage:source:
setSiriAutoUpdateListInitialized:
setQuality:
setOrthography:
setObject:forKeyedSubscript:
setObject:forKey:
setNonLocalizedNameWithoutQuality:
setNonCombinedVoiceId:
setLanguage:
setIsInstalled:
setIsEyesFree:
setIsCombinedVoice:
setIdentifier:
setGender:
setExtantVoices:
setEndpointerOperationMode:
setDoNotBlockBeforeFirstUnlock:
setDelegate:
setData:forKey:
setCustomPronunciationSubstitutions:
setCurrentVoices:
setCloudKitSync:
setCloudKitPushInSameProcess:
setCanBeDownloaded:
setAutomaticallyCancelPendingBlockUponSchedulingNewBlock:
setAutoDownloadedVoiceAssets:
setAttributes:ofItemAtPath:error:
setAssetSize:
setAllowsCellularAccess:
setAlexLocalAssetURL:
sendAsynchronousMessage:withIdentifier:targetAccessQueue:completion:
selectedSpeechVoiceIdentifiers
selectedIdsForTesting
secureUnarchiveData:withExpectedClass:otherAllowedClasses:
returnTypes:
results
resourcesWithLanguage:type:
requestEnableModuleWithIdentifier:completionHandler:
replaceTestAsset:withAsset:
registerUpdateBlock:forRetrieveSelector:withListener:
quickTypeWordFeedbackEnabled
queryMetaDataSync
purgeAsset:
purge:
phoneticFeedbackEnabled
phonemeSuggestions
path
orthography
objectForKeyedSubscript:
objectForKey:
objectAtIndexedSubscript:
numberWithLongLong:
numberWithFloat:
numberWithBool:
neural
nameForVoiceIdentifier:
name
mobileAssetWorkQueue
mobileAssetForVoiceId:
mobileAssetDownloadQueue
masteredVersion
lowercaseString
letterFeedbackEnabled
length
languages
languageCode
language
isVocalizerVoiceIdentifier:
isSiriVoiceIdentifier:
isNeuralSiriVoiceIdentifier:
isInstalled
isIdenticalTo:
isEqualToString:
isDefault
isCompactVocalizerVoiceIdentifier:
isCombinedVocalizerVoiceIdentifier:
isAssetManagedBySiriForVoiceId:
intValue
installedAssetsForLanguage:voiceType:
initWithType:
initWithTargetSerialQueue:
initWithActivationEvent:
initForReadingFromData:error:
informSiriVoiceSubscriptionsWithVoiceId:addition:
indexOfObject:
inUnitTestMode
ignoreLogging
identifier
hasPrefix:
getLocalFileUrl
getEnabledStateOfModuleWithIdentifier:completionHandler:
gender
footprint
firstObject
fileSize
extantVoices
endSession
downloadAsset:progressHandler:
dictionaryWithObjects:forKeys:count:
dictionary
defaultStore
defaultManager
defaultCenter
decodeObjectOfClasses:forKey:
dateByAddingTimeInterval:
date
dataForKey:
currentVoices
currentLocale
countByEnumeratingWithState:objects:count:
count
copy
containsObject:
compare:options:
clientMessengerWithIdentifier:
cleanUpExtraInstalledAssetsIfNecessary:
cancelSpeech
boolValue
backgroundAccessQueue
ax_flatMappedArrayUsingBlock:
axSafelyAddObjectsFromArray:
axSafelyAddObject:
axFilterObjectsUsingBlock:
averagePower
availableVoices:
attributes
attachProgressCallBack:
assetsForLanguage:voiceType:
assetType
assetIsDownloading:
arrayWithObjects:count:
array
archivedDataWithRootObject:requiringSecureCoding:error:
allInstalledAssetsForVoiceId:
alexLocalAssetURL
afterDelay:processBlock:
addObserver:selector:name:object:
addObject:
wordFeedbackEnabled
init
customPronunciationSubstitutions
voiceOverActivities
_icloudDataChanged:
sharedInstance
possibleRequiredEntitlementsForProcessingMessageWithIdentifier:
isEqual:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
description
debugDescription
TQ,R
T#,R
T@"NSString",R,C
processMessage:withIdentifier:fromClientWithIdentifier:error:
messageWithIdentifierShouldBeProcessedAsynchronously:
processMessageAsynchronously:withIdentifier:fromClientWithIdentifier:completion:
accessQueueForProcessingMessageWithIdentifier:
messageWithIdentifierRequiresWritingBlock:
processInitializationMessage:
serviceWasFullyInitialized
connectionWillBeInterruptedForClientWithIdentifier:
requiredEntitlementForProcessingMessageWithIdentifier:
assistantConnectionRequestWillStart:
assistantConnectionDismissAssistant:
assistantConnection:dismissAssistantWithReason:
assistantConnectionRequestFinished:
assistantConnection:receivedCommand:completion:
assistantConnection:requestFailedWithError:requestClass:
assistantConnection:openURL:completion:
assistantConnection:openApplicationWithBundleID:URL:completion:
assistantConnection:shouldSpeak:
assistantConnection:didChangeAudioSessionID:
assistantConnectionAudioSessionDidBeginInterruption:
assistantConnectionAudioSessionDidBeginInterruption:userInfo:
assistantConnectionAudioSessionDidEndInterruption:shouldResume:
assistantConnectionAudioSessionDidEndInterruption:shouldResume:userInfo:
assistantConnectionWillStartAcousticIDRequest:
assistantConnectionDidDetectMusic:
assistantConnection:didFinishAcousticIDRequestWithSuccess:
assistantConnection:setUserActivtiyInfoAndMakeCurrent:webpageURL:
assistantConnectionInvalidateCurrentUserActivity:
assistantConnection:wantsToCacheImage:
assistantConnection:extensionRequestWillStartForApplication:
assistantConnection:extensionRequestFinishedForApplication:error:
assistantConnection:startUIRequestWithText:completion:
assistantConnection:startUIRequestWithInfo:completion:
assistantConnection:willStartAudioPlaybackRequest:
assistantConnection:didStartAudioPlaybackRequest:
assistantConnection:didStopAudioPlaybackRequest:error:
assistantConnection:didHandleQuickStopWithAction:
assistantConnection:willProcessStartPlayback:intent:completion:
assistantConnection:willProcessStartPlayback:
assistantConnection:startPlaybackDidFail:
assistantConnection:audioSessionWillBecomeActive:
assistantConnection:audioSessionDidBecomeActive:
assistantConnection:willProcessAppLaunchWithBundleIdentifier:
assistantConnection:appLaunchFailedWithBundleIdentifier:
assistantConnectionSpeechRecordingWillBegin:
assistantConnection:speechRecordingWillBeginWithInputAudioPowerXPCWrapper:
assistantConnection:speechRecordingDidBeginOnAVRecordRoute:
assistantConnection:speechRecordingDidBeginOnAVRecordRoute:audioSessionID:
assistantConnection:speechRecordingDidChangeAVRecordRoute:
assistantConnectionSpeechRecordingDidDetectStartpoint:
assistantConnection:speechRecordingPerformTwoShotPromptWithType:completion:
assistantConnectionSpeechRecordingDidEnd:
assistantConnectionSpeechRecordingDidCancel:
assistantConnection:speechRecordingDidFail:
assistantConnectionDidChangeAudioRecordingPower:
assistantConnection:speechRecognitionDidFail:
assistantConnection:speechRecognized:
assistantConnection:speechRecognizedPartialResult:
assistantConnection:recognizedAdditionalSpeechInterpretation:refId:
assistantConnection:recognitionUpdateWithPhrases:utterances:refId:
assistantConnection:recognitionUpdateWillBeginForTask:
dictationConnectionSpeechRecordingWillBegin:
dictationConnectionSpeechRecordingDidBegin:
dictationConnection:speechRecordingDidBeginWithOptions:
dictationConnection:didBeginLocalRecognitionWithModelInfo:
dictationConnectionSpeechRecordingDidEnd:
dictationConnectionSpeechRecordingDidCancel:
dictationConnection:speechRecordingDidFail:
dictationConnection:speechRecognitionDidFail:
dictationConnection:didDetectLanguage:confidenceScores:
dictationConnection:didDetectLanguage:confidenceScores:isConfident:
dictationConnection:didRecognizeMultilingualSpeech:
dictationConnection:languageDetectorFailedWithError:
dictationConnection:didRecognizePhrases:languageModel:correctionIdentifier:
dictationConnection:didRecognizePhrases:languageModel:correctionIdentifier:replacingPreviousPhrasesCount:
dictationConnection:didRecognizeTokens:languageModel:
dictationConnection:didRecognizeTokens:nluResult:languageModel:
dictationConnection:didRecognizePartialResult:
dictationConnection:didProcessAudioDuration:
dictationConnectionSpeechRecognitionDidSucceed:
dictationConnection:didRecognizeTranscriptionObjects:languageModel:
dictationConnnectionDidChangeAvailability:
dictationConnection:didFinishWritingAudioFile:error:
dictationConnection:didReceiveSearchResults:recognizedText:stable:final:
dictationConnection:didRecognizePackage:
dictationConnection:didRecognizePackage:nluResult:
dictationConnectionDidPauseRecognition:
_reconcilePronunciations
_reconcileActivities
_iCloudReconcileActivitiesStore:
_iCloudReconcileDataStore:
_syncToWatch
_saveActivitiesToExternalsAndDelete:
_saveCustomPronunciationsToExternalsAndDelete:
_customPronunciationsSettingsChanged
_monitoriCloudVoiceOverData
_updateDefaultVoiceIfNecessaryForLanguage:source:
_updateCachedTTSVoices
_languageForAsset:
_handleExtantVoices
_normalizedSiriName:
_handleSiriStyleVoices:assetRetrieval:voiceIdentifier:voiceName:
migratePrefToNeuralVoiceIfNecessaryForVoice:
_checkForAssets:
informSiriAboutVoiceUsageForIdentifier:forLanguage:add:
_pronunciationAudioLevel
_stopPronunciationSession
_cancelPronunciationSession
_handleFailureForSpeechPronunciation:
_startPronunciationSession:
_combinedVocalizerAssets:
_vocalizerAssets
_vocalizerAssetsForLanguage:
_alexAssets
_mobileAssetDownloadOptions
_handleAssetProgress:asset:installedAsset:
_checkForMacinTalkAssetUpdates
_checkForVocalizerAssetUpdates
_handleSiriAssetDownload:
_downloadAssetsForSelectedVoices
_handleMobileAssetDownload:
_addToDownloadQueue:
_isVocalizerAsset:
_beginDownloadIfNecessaryForSiriAssets:
_beginDownloadIfNecessaryForAssets:
_updateAsset:existingAsset:
_purgeExistingSiriAsset:inFavorOfAsset:
_purgeExistingAsset:inFavorOfAsset:
voiceRefreshQueue
setVoiceRefreshQueue:
.cxx_destruct
_lastTTSVoiceAssetUpdate
_pronunciationPusher
_lastActivitiesICloudRetrieval
_activitiesPusher
_isUpdatingCachedTTSVoices
_dictationConnection
_isRecording
_assetService
_voiceRefreshQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_voiceRefreshQueue
Checking pronunciations
Got pronunciations: %{private}@, count: %d
Exception decoding data: %@
Checking activities
Got activities: count: %d
did not find %@ in %@
%@ not identical to %@
Reconciled iCloud activities: adding: %{private}@
Did not find a change, not updating
%{public}@
Skipping publishing to iCloud because we just retrieved this data
Created an empty length archive, not synching
ICLOUD[%p]: Publishing data to iCloud %{private}@
Not updating default spoken content voice because no speech features are enabled.
Not updating default spoken content voice because switch control is not enabled.
Not updating default voice because the voice doesn't match our system language.
Switching voice from %@ to %@ for source %ld because default voice has changed, and the user hasn't selected one for language %@
Vocalizer assets example[0]: %{public}@
Victoria macinTalkAsset: %{public}@
local macinTalkAsset: %{public}@
remote macinTalkAsset: %{public}@
New siri names %@
Original old siri assets %@
Filtered out old siri assets so we're left with %@
Siri voices not supported
Set extant voices: %{public}@
Retrieved siri-style assets: %{public}@
Siri style: skipping non premium: %@
Siri style: skipping neural: %@
Processed Siri-style assets: %{public}@
made siri voice %@ with asset %@
Updating spoken content settings because the selected voice was a Siri voice, but a neural voice matching the same name and language: %@ was available
Downloading %@ because a non-neural variant was previously selected, but a neural variant is now available
Removing %@ from active siri list, because neural voice was available and non-neural version wasn't in use outside of Speech Features
Force checking speech assets: %d date: %{public}@
No previous LastSpeechAssetUpdateCheck was found. Setting date earlier: %{public}@.
Has speech asset data: %d
Not checking voice assets because it's too soon: %{public}@ - only %f seconds 
Checking on assets now
Asset is installed and is in selected voices: %@
Hearing aid control status: %d
Added hearing to control center: %@ success: %d
Sound detection control status: %d
Added sound detection to control center: %@ success: %d
Inform siri about %@
MAAssetQuery error fetching results %{public}@ %{public}@ %{public}@
Asset progress: %{public}@ - %f
Checking assets: %{public}@
checking assets[%{public}@] %{public}@
Handling download for %@ %@
Finished downloading asset: %@, %@
Updating siri voice list usage after downloading a selected voice ID that was missing
could not parse voice identifier %{public}@
could not find asset for voice identifier %{public}@ but the voice was installed. This is expected if it is a built-in voice.
could not find asset for voice identifier %{public}@
selected voice %{public}@ is already downloading.
selected voice %{public}@ is required by the OS.
selected voice %{public}@ is installed but not in the catalog.
selected voice %{public}@ has unknown state.
selected voice %{public}@ is already installed.
selected voice %{public}@ %@ is not present. Beginning download.
Asset not present, but no space to download voice %{public}@: %{public}@
asset installed with os
Adding asset to queue: %{public}@
No siri asset installed
Installed asset %{public}@, latest asset: %{public}@
Detected new Asset, downloading: %{public}@
Enough disk space available - start %{public}@
Updating Installed Asset: %{public}@
Error: %{public}@
Asset state: %@
Error: Not enough disk space
No newer asset than %{public}@ - [installed asset %{public}@]
Purging old asset: %{public}@
No macintalk or siri asset installed
No newer asset than %{public}@ - %@ [installed asset %{public}@]
Purged old asset: %{public}@, %{public}@
Trying to update unknown asset (expecting Macintalk, Combined, or Siri): %{public}@
Could not remove file protection from: %{public}@
Could not purge old asset: %{public}@
@16@0:8
@24@0:8Q16
B24@0:8@16
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B16@0:8
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
@48@0:8@16Q24@32^@40
B24@0:8Q16
v48@0:8@16Q24@32@?40
v24@0:8@16
v16@0:8
@"NSDictionary"48@0:8@"NSDictionary"16Q24@"NSString"32^@40
v48@0:8@"NSDictionary"16Q24@"NSString"32@?<v@?@"NSDictionary"@"NSError">40
@"AXAccessQueue"24@0:8Q16
v24@0:8@"NSDictionary"16
v24@0:8@"NSString"16
@"NSString"24@0:8Q16
@"NSSet"24@0:8Q16
v32@0:8@16q24
v40@0:8@16@24@?32
v40@0:8@16@24@32
v48@0:8@16@24@32@?40
v28@0:8@16B24
v28@0:8@16I24
v32@0:8@16@24
v36@0:8@16B24@28
v32@0:8@16Q24
v48@0:8@16q24@32@?40
v24@0:8@"AFConnection"16
v32@0:8@"AFConnection"16q24
v40@0:8@"AFConnection"16@"AceObject<SAAceCommand>"24@?<v@?@"AceObject<SAAceCommand>">32
v40@0:8@"AFConnection"16@"NSError"24@"NSString"32
v40@0:8@"AFConnection"16@"NSURL"24@?<v@?B>32
v48@0:8@"AFConnection"16@"NSString"24@"NSURL"32@?<v@?B>40
v28@0:8@"AFConnection"16B24
v28@0:8@"AFConnection"16I24
v32@0:8@"AFConnection"16@"NSDictionary"24
v36@0:8@"AFConnection"16B24@"NSDictionary"28
v40@0:8@"AFConnection"16@"NSDictionary"24@"NSURL"32
v32@0:8@"AFConnection"16@"INImage"24
v32@0:8@"AFConnection"16@"NSString"24
v40@0:8@"AFConnection"16@"NSString"24@"NSError"32
v40@0:8@"AFConnection"16@"NSString"24@?<v@?B>32
v40@0:8@"AFConnection"16@"AFRequestInfo"24@?<v@?B>32
v32@0:8@"AFConnection"16@"AFAudioPlaybackRequest"24
v40@0:8@"AFConnection"16@"AFAudioPlaybackRequest"24@"NSError"32
v32@0:8@"AFConnection"16Q24
v48@0:8@"AFConnection"16q24@"INIntent"32@?<v@?BB>40
v36@0:8@16@24I32
v40@0:8@16q24@?32
v48@0:8@16@24@32@40
v32@0:8@"AFConnection"16@"AFXPCWrapper"24
v36@0:8@"AFConnection"16@"NSString"24I32
v40@0:8@"AFConnection"16q24@?<v@?dd@"NSError">32
v32@0:8@"AFConnection"16@"NSError"24
v32@0:8@"AFConnection"16@"SASSpeechRecognized"24
v32@0:8@"AFConnection"16@"SASSpeechPartialResult"24
v40@0:8@"AFConnection"16@"AFSpeechInterpretation"24@"NSString"32
v48@0:8@"AFConnection"16@"NSArray"24@"NSArray"32@"NSString"40
v44@0:8@16@24@32B40
v56@0:8@16@24@32@40Q48
v32@0:8@16d24
v48@0:8@16@24@32B40B44
v24@0:8@"AFDictationConnection"16
v32@0:8@"AFDictationConnection"16@"AFDictationOptions"24
v32@0:8@"AFDictationConnection"16@"NSString"24
v32@0:8@"AFDictationConnection"16@"NSError"24
v40@0:8@"AFDictationConnection"16@"NSString"24@"NSDictionary"32
v44@0:8@"AFDictationConnection"16@"NSString"24@"NSDictionary"32B40
v32@0:8@"AFDictationConnection"16@"SASMultilingualSpeechRecognized"24
v48@0:8@"AFDictationConnection"16@"NSArray"24@"NSString"32@40
v56@0:8@"AFDictationConnection"16@"NSArray"24@"NSString"32@40Q48
v40@0:8@"AFDictationConnection"16@"NSArray"24@"NSString"32
v48@0:8@"AFDictationConnection"16@"NSArray"24@"AFDictationNLUResult"32@"NSString"40
v32@0:8@"AFDictationConnection"16@"SASSpeechPartialResult"24
v32@0:8@"AFDictationConnection"16d24
v40@0:8@"AFDictationConnection"16@"NSFileHandle"24@"NSError"32
v48@0:8@"AFDictationConnection"16@"NSArray"24@"NSString"32B40B44
v32@0:8@"AFDictationConnection"16@"AFSpeechPackage"24
v40@0:8@"AFDictationConnection"16@"AFSpeechPackage"24@"AFDictationNLUResult"32
@24@0:8@16
v48@0:8@16@?24@?32@?40
v20@0:8B16
v36@0:8@16@24B32
f16@0:8
@20@0:8B16
@"AXDispatchTimer"
@"AFDictationConnection"
@"AXAssetsService"
@"NSObject<OS_dispatch_queue>"
softlink:r:path:/System/Library/PrivateFrameworks/ControlCenterServices.framework/ControlCenterServices
softlink:r:path:/System/Library/PrivateFrameworks/HearingUtilities.framework/HearingUtilities
