v8@?0
refresh-voices
AXCustomPronunciations
AXVoiceOverActivities
Reconciled iCloud pronunciations: adding: %{private}@
Did not find a change, not updating
CustomPronunciationSubstitutions
NPS: Publishing data to nano domain
ICLOUD[%p]: Waiting 5s to publish, deleting %@
Created an empty length archive, not synching
ICLOUD[%p]: Publishing data to iCloud %{private}@
Custom pronunciations settings updated
@16@?0@"TTSAXResource"8
/Library/Caches/com.apple.xbs/Sources/AccessibilityFrameworks_Sim/Source/AXAssetAndDataServer/AXAssetAndDataServer.m
-[AXAssetAndDataServer _handleExtantVoices]
Why is name nil for %@ %@
VoiceId
Language
Name
en-US
@"NSArray"8@?0
@"NSString"40@?0@"TTSVoiceAsset"8@"NSString"16q24@"NSString"32
@"NSString"32@?0@"TTSVoiceAsset"8@"NSString"16q24
B24@?0@"TTSVoiceAsset"8Q16
LastSpeechAssetUpdateCheck
com.apple.accessibility.api
com.apple.private.kernel.jetsam
com.apple.CoreRoutine.preferences
com.apple.TVServices.DisplayManager
com.apple.accessibility.voiceover
com.apple.appletv.pbs.display-manager-service-access
com.apple.accessibility.axctl
delete
options
audioLevel
v16@?0Q8
v20@?0B8@"NSError"12
com.apple.accessibility.controlcenter.sounddetection
got transcription results: %@
AXSpeechPronunciationClient
results
v24@?0@"NSDictionary"8@"NSError"16
Fail: %@, %d
Error
error
Starting pronunciation dictation: %@, %@, %@
q24@?0@"TTSVoiceAsset"8@"TTSVoiceAsset"16
v28@?0d8B16@"NSError"20
v16@?0@"MAProgressNotification"8
v16@?0q8
CCSControlCenterService
Unable to find class %s
AXHearingAidControlCenterBundleID
AXAssetAndDataServer
AXUIService
NSObject
AFAssistantUIService
AFSpeechDelegate
AFDictationDelegate
init
sharedInstance
mobileAssetWorkQueue
initWithTargetSerialQueue:
setAutomaticallyCancelPendingBlockUponSchedulingNewBlock:
_monitoriCloudVoiceOverData
_icloudDataChanged:
afterDelay:processBlock:
sharedDatabase
setCloudKitSync:
setCloudKitPushInSameProcess:
defaultStore
dataForKey:
initForReadingFromData:error:
arrayWithObjects:count:
setWithArray:
decodeObjectOfClasses:forKey:
count
_iCloudReconcileDataStore:
_iCloudReconcileActivitiesStore:
synchronize
syncPronunciationsWithCloudKit
_reconcilePronunciations
_reconcileActivities
voiceOverActivities
countByEnumeratingWithState:objects:count:
indexOfObject:
objectAtIndexedSubscript:
isIdenticalTo:
setVoiceOverActivities:
ignoreLogging
identifier
customPronunciationSubstitutions
containsObject:
_syncToWatch
setCustomPronunciationSubstitutions:
setWithObject:
synchronizeUserDefaultsDomain:keys:
copy
archivedDataWithRootObject:requiringSecureCoding:error:
length
setData:forKey:
_saveCustomPronunciationsToExternalsAndDelete:
_customPronunciationsSettingsChanged
registerUpdateBlock:forRetrieveSelector:withListener:
_saveActivitiesToExternalsAndDelete:
defaultCenter
addObserver:selector:name:object:
currentLocale
languageCode
letterFeedbackEnabled
phoneticFeedbackEnabled
wordFeedbackEnabled
quickTypeWordFeedbackEnabled
speakCorrectionsEnabled
isEqualToString:
userDidSelectVoiceForLanguage:source:
resourcesWithLanguage:type:
speechVoice
ax_flatMappedArrayUsingBlock:
isDefault
speechVoiceIdentifierForLanguage:source:exists:
voiceForIdentifier:
footprint
isNeuralSiriVoiceIdentifier:
setSpeechVoiceIdentifier:forLanguage:source:
language
informSiriAboutVoiceUsageForIdentifier:forLanguage:add:
attributes
objectForKeyedSubscript:
firstObject
stringByReplacingOccurrencesOfString:withString:
_combinedVocalizerAssets:
boolValue
intValue
_languageForAsset:
setIsCombinedVoice:
setNonCombinedVoiceId:
objectForKey:
allInstalledAssetsForVoiceId:
setIdentifier:
setLanguage:
setNonLocalizedNameWithoutQuality:
setQuality:
setGender:
setIsInstalled:
unsignedIntegerValue
setAssetSize:
setCanBeDownloaded:
addObject:
_vocalizerAssets
gender
languages
name
fileSize
numberWithLongLong:
isInstalled
state
supportsAlex
nameForVoiceIdentifier:
array
neural
_normalizedSiriName:
axSafelyAddObject:
_handleSiriStyleVoices:assetRetrieval:voiceIdentifier:voiceName:
axFilterObjectsUsingBlock:
setExtantVoices:
lowercaseString
migratePrefToNeuralVoiceIfNecessaryForVoice:
isSiriVoiceIdentifier:
startDownloadingVoice:
standardUserDefaults
date
dateByAddingTimeInterval:
setObject:forKey:
timeIntervalSinceReferenceDate
currentVoices
extantVoices
_checkForMacinTalkAssetUpdates
_checkForVocalizerAssetUpdates
_updateCachedTTSVoices
setWithObjects:
_checkForAssets:
valueForKey:
secureUnarchiveData:withExpectedClass:otherAllowedClasses:
_startPronunciationSession:
_cancelPronunciationSession
_stopPronunciationSession
_pronunciationAudioLevel
numberWithFloat:
dictionaryWithObjects:forKeys:count:
selectedSpeechVoiceIdentifiers
mobileAssetDownloadQueue
installedAssetsForLanguage:voiceType:
axSafelyAddObjectsFromArray:
setAutoDownloadedVoiceAssets:
setSiriAutoUpdateListInitialized:
requestEnableModuleWithIdentifier:completionHandler:
getEnabledStateOfModuleWithIdentifier:completionHandler:
systemLanguageID
_updateDefaultVoiceIfNecessaryForLanguage:source:
isVocalizerVoiceIdentifier:
informSiriVoiceSubscriptionsWithVoiceId:addition:
_handleFailureForSpeechPronunciation:
averagePower
stopSpeechWithOptions:
cancelSpeech
phonemeSuggestions
clientMessengerWithIdentifier:
backgroundAccessQueue
sendAsynchronousMessage:withIdentifier:targetAccessQueue:completion:
endSession
description
setDelegate:
setTranscriptionMode:
orthography
setOrthography:
initWithActivationEvent:
setIsEyesFree:
setEndpointerOperationMode:
startDictationWithLanguageCode:options:speechOptions:
initWithType:
setDoNotBlockBeforeFirstUnlock:
returnTypes:
queryMetaDataSync
results
assetsForLanguage:voiceType:
masteredVersion
sortedArrayUsingComparator:
setAllowsCellularAccess:
totalWritten
totalExpected
_alexAssets
_beginDownloadIfNecessaryForAssets:
_vocalizerAssetsForLanguage:
_beginDownloadIfNecessaryForSiriAssets:
voiceAssetForVoiceId:
downloadAsset:progressHandler:
selectedIdsForTesting
isCompactVocalizerVoiceIdentifier:
isAssetManagedBySiriForVoiceId:
_handleSiriAssetDownload:
mobileAssetForVoiceId:
hasPrefix:
_voiceFromInternalVoiceListWithIdentifier:
isCombinedVocalizerVoiceIdentifier:
compare:options:
cleanUpExtraInstalledAssetsIfNecessary:
inUnitTestMode
replaceTestAsset:withAsset:
spaceCheck:
_handleAssetProgress:asset:installedAsset:
attachProgressCallBack:
_mobileAssetDownloadOptions
_updateAsset:existingAsset:
startDownload:then:
assetType
assetIsDownloading:
purgeAsset:
alexLocalAssetURL
getLocalFileUrl
isEqual:
_addToDownloadQueue:
purge:
_purgeExistingAsset:inFavorOfAsset:
setAlexLocalAssetURL:
defaultManager
path
setAttributes:ofItemAtPath:error:
possibleRequiredEntitlementsForProcessingMessageWithIdentifier:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
debugDescription
TQ,R
T#,R
T@"NSString",R,C
processMessage:withIdentifier:fromClientWithIdentifier:error:
messageWithIdentifierShouldBeProcessedAsynchronously:
processMessageAsynchronously:withIdentifier:fromClientWithIdentifier:completion:
accessQueueForProcessingMessageWithIdentifier:
messageWithIdentifierRequiresWritingBlock:
processInitializationMessage:
serviceWasFullyInitialized
connectionWillBeInterruptedForClientWithIdentifier:
requiredEntitlementForProcessingMessageWithIdentifier:
assistantConnectionRequestWillStart:
assistantConnectionDismissAssistant:
assistantConnection:dismissAssistantWithReason:
assistantConnectionRequestFinished:
assistantConnection:receivedCommand:completion:
assistantConnection:requestFailedWithError:requestClass:
assistantConnection:openURL:completion:
assistantConnection:openApplicationWithBundleID:URL:completion:
assistantConnection:shouldSpeak:
assistantConnection:didChangeAudioSessionID:
assistantConnectionAudioSessionDidBeginInterruption:
assistantConnectionAudioSessionDidBeginInterruption:userInfo:
assistantConnectionAudioSessionDidEndInterruption:shouldResume:
assistantConnectionAudioSessionDidEndInterruption:shouldResume:userInfo:
assistantConnectionWillStartAcousticIDRequest:
assistantConnectionDidDetectMusic:
assistantConnection:didFinishAcousticIDRequestWithSuccess:
assistantConnection:setUserActivtiyInfoAndMakeCurrent:webpageURL:
assistantConnectionInvalidateCurrentUserActivity:
assistantConnection:wantsToCacheImage:
assistantConnection:extensionRequestWillStartForApplication:
assistantConnection:extensionRequestFinishedForApplication:error:
assistantConnection:startUIRequestWithText:completion:
assistantConnection:startUIRequestWithInfo:completion:
assistantConnection:willStartAudioPlaybackRequest:
assistantConnection:didStartAudioPlaybackRequest:
assistantConnection:didStopAudioPlaybackRequest:error:
assistantConnection:didHandleQuickStopWithAction:
assistantConnection:willProcessStartPlayback:intent:completion:
assistantConnection:willProcessStartPlayback:
assistantConnection:startPlaybackDidFail:
assistantConnection:audioSessionWillBecomeActive:
assistantConnection:audioSessionDidBecomeActive:
assistantConnection:willProcessAppLaunchWithBundleIdentifier:
assistantConnection:appLaunchFailedWithBundleIdentifier:
assistantConnectionSpeechRecordingWillBegin:
assistantConnection:speechRecordingWillBeginWithInputAudioPowerXPCWrapper:
assistantConnection:speechRecordingDidBeginOnAVRecordRoute:
assistantConnection:speechRecordingDidBeginOnAVRecordRoute:audioSessionID:
assistantConnection:speechRecordingDidChangeAVRecordRoute:
assistantConnectionSpeechRecordingDidDetectStartpoint:
assistantConnection:speechRecordingPerformTwoShotPromptWithType:completion:
assistantConnectionSpeechRecordingDidEnd:
assistantConnectionSpeechRecordingDidCancel:
assistantConnection:speechRecordingDidFail:
assistantConnectionDidChangeAudioRecordingPower:
assistantConnection:speechRecognitionDidFail:
assistantConnection:speechRecognized:
assistantConnection:speechRecognizedPartialResult:
assistantConnection:recognizedAdditionalSpeechInterpretation:refId:
assistantConnection:recognitionUpdateWithPhrases:utterances:refId:
assistantConnection:recognitionUpdateWillBeginForTask:
dictationConnectionSpeechRecordingWillBegin:
dictationConnectionSpeechRecordingDidBegin:
dictationConnection:speechRecordingDidBeginWithOptions:
dictationConnection:didBeginLocalRecognitionWithModelInfo:
dictationConnectionSpeechRecordingDidEnd:
dictationConnectionSpeechRecordingDidCancel:
dictationConnection:speechRecordingDidFail:
dictationConnection:speechRecognitionDidFail:
dictationConnection:didDetectLanguage:confidenceScores:
dictationConnection:didDetectLanguage:confidenceScores:isConfident:
dictationConnection:didRecognizeMultilingualSpeech:
dictationConnection:languageDetectorFailedWithError:
dictationConnection:didRecognizePhrases:languageModel:correctionIdentifier:
dictationConnection:didRecognizePhrases:languageModel:correctionIdentifier:replacingPreviousPhrasesCount:
dictationConnection:didRecognizeTokens:languageModel:
dictationConnection:didRecognizeTokens:nluResult:languageModel:
dictationConnection:didRecognizePartialResult:
dictationConnection:didProcessAudioDuration:
dictationConnectionSpeechRecognitionDidSucceed:
dictationConnection:didRecognizeTranscriptionObjects:languageModel:
dictationConnnectionDidChangeAvailability:
dictationConnection:didFinishWritingAudioFile:error:
dictationConnection:didReceiveSearchResults:recognizedText:stable:final:
dictationConnection:didRecognizePackage:
dictationConnection:didRecognizePackage:nluResult:
dictationConnectionDidPauseRecognition:
dictationConnection:didRecognizeFinalResultCandidatePackage:
_handleExtantVoices
_downloadAssetsForSelectedVoices
_handleMobileAssetDownload:
_isVocalizerAsset:
_purgeExistingSiriAsset:inFavorOfAsset:
voiceRefreshQueue
setVoiceRefreshQueue:
.cxx_destruct
_lastTTSVoiceAssetUpdate
_pronunciationPusher
_lastActivitiesICloudRetrieval
_activitiesPusher
_isUpdatingCachedTTSVoices
_dictationConnection
_isRecording
_assetService
_voiceRefreshQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_voiceRefreshQueue
Checking pronunciations
Got pronunciations: %{private}@, count: %d
Exception decoding data: %@
Checking activities
Got activities: count: %d
did not find %@ in %@
%@ not identical to %@
Reconciled iCloud activities: adding: %{private}@
Did not find a change, not updating
%{public}@
Skipping publishing to iCloud because we just retrieved this data
Created an empty length archive, not synching
ICLOUD[%p]: Publishing data to iCloud %{private}@
Not updating default spoken content voice because no speech features are enabled.
Not updating default spoken content voice because switch control is not enabled.
Not updating default voice because the voice doesn't match our system language.
Switching voice from %@ to %@ for source %ld because default voice has changed, and the user hasn't selected one for language %@
Vocalizer assets example[0]: %{public}@
Victoria macinTalkAsset: %{public}@
local macinTalkAsset: %{public}@
remote macinTalkAsset: %{public}@
New siri names %@
Original old siri assets %@
Filtered out old siri assets so we're left with %@
Siri voices not supported
Set extant voices: %{public}@
Retrieved siri-style assets: %{public}@
Siri style: skipping non premium: %@
Siri style: skipping neural: %@
Processed Siri-style assets: %{public}@
made siri voice %@ with asset %@
Updating spoken content settings because the selected voice was a Siri voice, but a neural voice matching the same name and language: %@ was available
Downloading %@ because a non-neural variant was previously selected, but a neural variant is now available
Removing %@ from active siri list, because neural voice was available and non-neural version wasn't in use outside of Speech Features
Force checking speech assets: %d date: %{public}@
No previous LastSpeechAssetUpdateCheck was found. Setting date earlier: %{public}@.
Has speech asset data: %d
Not checking voice assets because it's too soon: %{public}@ - only %f seconds 
Checking on assets now
Asset is installed and is in selected voices: %@
Hearing aid control status: %d
Added hearing to control center: %@ success: %d
Sound detection control status: %d
Added sound detection to control center: %@ success: %d
Inform siri about %@
MAAssetQuery error fetching results %{public}@ %{public}@ %{public}@
Asset progress: %{public}@ - %f
Checking assets: %{public}@
checking assets[%{public}@] %{public}@
Handling download for %@ %@
Finished downloading asset: %@, %@
Updating siri voice list usage after downloading a selected voice ID that was missing
could not parse voice identifier %{public}@
could not find asset for voice identifier %{public}@ but the voice was installed. This is expected if it is a built-in voice.
could not find asset for voice identifier %{public}@
selected voice %{public}@ is already downloading.
selected voice %{public}@ is required by the OS.
selected voice %{public}@ is installed but not in the catalog.
selected voice %{public}@ has unknown state.
selected voice %{public}@ is already installed.
selected voice %{public}@ %@ is not present. Beginning download.
Asset not present, but no space to download voice %{public}@: %{public}@
asset installed with os
Adding asset to queue: %{public}@
No siri asset installed
Installed asset %{public}@, latest asset: %{public}@
Detected new Asset, downloading: %{public}@
Enough disk space available - start %{public}@
Updating Installed Asset: %{public}@
Error: %{public}@
Asset state: %@
Error: Not enough disk space
No newer asset than %{public}@ - [installed asset %{public}@]
Purging old asset: %{public}@
No macintalk or siri asset installed
No newer asset than %{public}@ - %@ [installed asset %{public}@]
Purged old asset: %{public}@, %{public}@
Trying to update unknown asset (expecting Macintalk, Combined, or Siri): %{public}@
Could not remove file protection from: %{public}@
Could not purge old asset: %{public}@
@16@0:8
@24@0:8Q16
B24@0:8@16
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B16@0:8
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
@48@0:8@16Q24@32^@40
B24@0:8Q16
v48@0:8@16Q24@32@?40
v24@0:8@16
v16@0:8
@"NSDictionary"48@0:8@"NSDictionary"16Q24@"NSString"32^@40
v48@0:8@"NSDictionary"16Q24@"NSString"32@?<v@?@"NSDictionary"@"NSError">40
@"AXAccessQueue"24@0:8Q16
v24@0:8@"NSDictionary"16
v24@0:8@"NSString"16
@"NSString"24@0:8Q16
@"NSSet"24@0:8Q16
v32@0:8@16q24
v40@0:8@16@24@?32
v40@0:8@16@24@32
v48@0:8@16@24@32@?40
v28@0:8@16B24
v28@0:8@16I24
v32@0:8@16@24
v36@0:8@16B24@28
v32@0:8@16Q24
v48@0:8@16q24@32@?40
v24@0:8@"AFConnection"16
v32@0:8@"AFConnection"16q24
v40@0:8@"AFConnection"16@"AceObject<SAAceCommand>"24@?<v@?@"AceObject<SAAceCommand>">32
v40@0:8@"AFConnection"16@"NSError"24@"NSString"32
v40@0:8@"AFConnection"16@"NSURL"24@?<v@?B>32
v48@0:8@"AFConnection"16@"NSString"24@"NSURL"32@?<v@?B>40
v28@0:8@"AFConnection"16B24
v28@0:8@"AFConnection"16I24
v32@0:8@"AFConnection"16@"NSDictionary"24
v36@0:8@"AFConnection"16B24@"NSDictionary"28
v40@0:8@"AFConnection"16@"NSDictionary"24@"NSURL"32
v32@0:8@"AFConnection"16@"INImage"24
v32@0:8@"AFConnection"16@"NSString"24
v40@0:8@"AFConnection"16@"NSString"24@"NSError"32
v40@0:8@"AFConnection"16@"NSString"24@?<v@?B>32
v40@0:8@"AFConnection"16@"AFRequestInfo"24@?<v@?B>32
v32@0:8@"AFConnection"16@"AFAudioPlaybackRequest"24
v40@0:8@"AFConnection"16@"AFAudioPlaybackRequest"24@"NSError"32
v32@0:8@"AFConnection"16Q24
v48@0:8@"AFConnection"16q24@"INIntent"32@?<v@?BB>40
v36@0:8@16@24I32
v40@0:8@16q24@?32
v48@0:8@16@24@32@40
v32@0:8@"AFConnection"16@"AFXPCWrapper"24
v36@0:8@"AFConnection"16@"NSString"24I32
v40@0:8@"AFConnection"16q24@?<v@?dd@"NSError">32
v32@0:8@"AFConnection"16@"NSError"24
v32@0:8@"AFConnection"16@"SASSpeechRecognized"24
v32@0:8@"AFConnection"16@"SASSpeechPartialResult"24
v40@0:8@"AFConnection"16@"AFSpeechInterpretation"24@"NSString"32
v48@0:8@"AFConnection"16@"NSArray"24@"NSArray"32@"NSString"40
v44@0:8@16@24@32B40
v56@0:8@16@24@32@40Q48
v32@0:8@16d24
v48@0:8@16@24@32B40B44
v24@0:8@"AFDictationConnection"16
v32@0:8@"AFDictationConnection"16@"AFDictationOptions"24
v32@0:8@"AFDictationConnection"16@"NSString"24
v32@0:8@"AFDictationConnection"16@"NSError"24
v40@0:8@"AFDictationConnection"16@"NSString"24@"NSDictionary"32
v44@0:8@"AFDictationConnection"16@"NSString"24@"NSDictionary"32B40
v32@0:8@"AFDictationConnection"16@"SASMultilingualSpeechRecognized"24
v48@0:8@"AFDictationConnection"16@"NSArray"24@"NSString"32@40
v56@0:8@"AFDictationConnection"16@"NSArray"24@"NSString"32@40Q48
v40@0:8@"AFDictationConnection"16@"NSArray"24@"NSString"32
v48@0:8@"AFDictationConnection"16@"NSArray"24@"AFDictationNLUResult"32@"NSString"40
v32@0:8@"AFDictationConnection"16@"SASSpeechPartialResult"24
v32@0:8@"AFDictationConnection"16d24
v40@0:8@"AFDictationConnection"16@"NSFileHandle"24@"NSError"32
v48@0:8@"AFDictationConnection"16@"NSArray"24@"NSString"32B40B44
v32@0:8@"AFDictationConnection"16@"AFSpeechPackage"24
v40@0:8@"AFDictationConnection"16@"AFSpeechPackage"24@"AFDictationNLUResult"32
@24@0:8@16
v48@0:8@16@?24@?32@?40
v20@0:8B16
v36@0:8@16@24B32
f16@0:8
@20@0:8B16
@"AXDispatchTimer"
@"AFDictationConnection"
@"AXAssetsService"
@"NSObject<OS_dispatch_queue>"
softlink:r:path:/System/Library/PrivateFrameworks/ControlCenterServices.framework/ControlCenterServices
softlink:r:path:/System/Library/PrivateFrameworks/HearingUtilities.framework/HearingUtilities
v8@?0
refresh-voices
AXCustomPronunciations
AXVoiceOverActivities
Reconciled iCloud pronunciations: adding: %{private}@
Did not find a change, not updating
CustomPronunciationSubstitutions
NPS: Publishing data to nano domain
ICLOUD[%p]: Waiting 5s to publish, deleting %@
Created an empty length archive, not synching
ICLOUD[%p]: Publishing data to iCloud %{private}@
Custom pronunciations settings updated
@16@?0@"TTSAXResource"8
/Library/Caches/com.apple.xbs/Sources/AccessibilityFrameworks_Sim/Source/AXAssetAndDataServer/AXAssetAndDataServer.m
-[AXAssetAndDataServer _handleExtantVoices]
Why is name nil for %@ %@
VoiceId
Language
Name
en-US
@"NSArray"8@?0
@"NSString"40@?0@"TTSVoiceAsset"8@"NSString"16q24@"NSString"32
@"NSString"32@?0@"TTSVoiceAsset"8@"NSString"16q24
B24@?0@"TTSVoiceAsset"8Q16
LastSpeechAssetUpdateCheck
com.apple.accessibility.api
com.apple.private.kernel.jetsam
com.apple.CoreRoutine.preferences
com.apple.TVServices.DisplayManager
com.apple.accessibility.voiceover
com.apple.appletv.pbs.display-manager-service-access
com.apple.accessibility.axctl
delete
options
audioLevel
v16@?0Q8
v20@?0B8@"NSError"12
com.apple.accessibility.controlcenter.sounddetection
got transcription results: %@
AXSpeechPronunciationClient
results
v24@?0@"NSDictionary"8@"NSError"16
Fail: %@, %d
Error
error
Starting pronunciation dictation: %@, %@, %@
q24@?0@"TTSVoiceAsset"8@"TTSVoiceAsset"16
v28@?0d8B16@"NSError"20
v16@?0@"MAProgressNotification"8
v16@?0q8
CCSControlCenterService
Unable to find class %s
AXHearingAidControlCenterBundleID
AXAssetAndDataServer
AXUIService
NSObject
AFAssistantUIService
AFSpeechDelegate
AFDictationDelegate
setCloudKitSync:
clientMessengerWithIdentifier:
standardUserDefaults
neural
setVoiceOverActivities:
languages
fileSize
wordFeedbackEnabled
attachProgressCallBack:
selectedIdsForTesting
purge:
isCompactVocalizerVoiceIdentifier:
setIsEyesFree:
date
addObject:
synchronizeUserDefaultsDomain:keys:
speechVoiceIdentifierForLanguage:source:exists:
assetsForLanguage:voiceType:
indexOfObject:
setTranscriptionMode:
setCloudKitPushInSameProcess:
nameForVoiceIdentifier:
cleanUpExtraInstalledAssetsIfNecessary:
secureUnarchiveData:withExpectedClass:otherAllowedClasses:
extantVoices
languageCode
_voiceFromInternalVoiceListWithIdentifier:
isCombinedVocalizerVoiceIdentifier:
setIsCombinedVoice:
phoneticFeedbackEnabled
synchronize
dataForKey:
inUnitTestMode
assetType
cancelSpeech
name
returnTypes:
setCanBeDownloaded:
speechVoice
endSession
voiceForIdentifier:
setSpeechVoiceIdentifier:forLanguage:source:
language
isAssetManagedBySiriForVoiceId:
phonemeSuggestions
syncPronunciationsWithCloudKit
setIdentifier:
boolValue
setAutomaticallyCancelPendingBlockUponSchedulingNewBlock:
assetIsDownloading:
mobileAssetWorkQueue
ignoreLogging
speakCorrectionsEnabled
voiceAssetForVoiceId:
downloadAsset:progressHandler:
results
isVocalizerVoiceIdentifier:
setSiriAutoUpdateListInitialized:
path
currentVoices
intValue
setGender:
supportsAlex
mobileAssetForVoiceId:
spaceCheck:
backgroundAccessQueue
setAutoDownloadedVoiceAssets:
identifier
valueForKey:
dictionaryWithObjects:forKeys:count:
isSiriVoiceIdentifier:
setQuality:
resourcesWithLanguage:type:
arrayWithObjects:count:
orthography
installedAssetsForLanguage:voiceType:
setExtantVoices:
stringByReplacingOccurrencesOfString:withString:
currentLocale
setAttributes:ofItemAtPath:error:
hasPrefix:
sortedArrayUsingComparator:
isNeuralSiriVoiceIdentifier:
mobileAssetDownloadQueue
ax_flatMappedArrayUsingBlock:
array
userDidSelectVoiceForLanguage:source:
setOrthography:
requestEnableModuleWithIdentifier:completionHandler:
countByEnumeratingWithState:objects:count:
objectForKeyedSubscript:
getLocalFileUrl
initWithType:
setEndpointerOperationMode:
stopSpeechWithOptions:
axSafelyAddObjectsFromArray:
setAssetSize:
replaceTestAsset:withAsset:
setObject:forKey:
unsignedIntegerValue
archivedDataWithRootObject:requiringSecureCoding:error:
defaultStore
isInstalled
setDoNotBlockBeforeFirstUnlock:
objectForKey:
setAllowsCellularAccess:
state
initWithTargetSerialQueue:
count
masteredVersion
getEnabledStateOfModuleWithIdentifier:completionHandler:
axSafelyAddObject:
sharedDatabase
defaultManager
totalWritten
allInstalledAssetsForVoiceId:
setDelegate:
setNonLocalizedNameWithoutQuality:
isIdenticalTo:
registerUpdateBlock:forRetrieveSelector:withListener:
initWithActivationEvent:
startDownloadingVoice:
copy
objectAtIndexedSubscript:
setAlexLocalAssetURL:
setWithObjects:
lowercaseString
axFilterObjectsUsingBlock:
gender
alexLocalAssetURL
totalExpected
setNonCombinedVoiceId:
startDownload:then:
defaultCenter
quickTypeWordFeedbackEnabled
isEqualToString:
numberWithLongLong:
setData:forKey:
containsObject:
initForReadingFromData:error:
sendAsynchronousMessage:withIdentifier:targetAccessQueue:completion:
averagePower
letterFeedbackEnabled
footprint
setWithObject:
queryMetaDataSync
timeIntervalSinceReferenceDate
setLanguage:
afterDelay:processBlock:
decodeObjectOfClasses:forKey:
compare:options:
startDictationWithLanguageCode:options:speechOptions:
informSiriVoiceSubscriptionsWithVoiceId:addition:
numberWithFloat:
setCustomPronunciationSubstitutions:
selectedSpeechVoiceIdentifiers
attributes
firstObject
length
setWithArray:
purgeAsset:
systemLanguageID
dateByAddingTimeInterval:
setIsInstalled:
isDefault
addObserver:selector:name:object:
init
customPronunciationSubstitutions
voiceOverActivities
_icloudDataChanged:
sharedInstance
possibleRequiredEntitlementsForProcessingMessageWithIdentifier:
isEqual:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
description
debugDescription
TQ,R
T#,R
T@"NSString",R,C
processMessage:withIdentifier:fromClientWithIdentifier:error:
messageWithIdentifierShouldBeProcessedAsynchronously:
processMessageAsynchronously:withIdentifier:fromClientWithIdentifier:completion:
accessQueueForProcessingMessageWithIdentifier:
messageWithIdentifierRequiresWritingBlock:
processInitializationMessage:
serviceWasFullyInitialized
connectionWillBeInterruptedForClientWithIdentifier:
requiredEntitlementForProcessingMessageWithIdentifier:
assistantConnectionRequestWillStart:
assistantConnectionDismissAssistant:
assistantConnection:dismissAssistantWithReason:
assistantConnectionRequestFinished:
assistantConnection:receivedCommand:completion:
assistantConnection:requestFailedWithError:requestClass:
assistantConnection:openURL:completion:
assistantConnection:openApplicationWithBundleID:URL:completion:
assistantConnection:shouldSpeak:
assistantConnection:didChangeAudioSessionID:
assistantConnectionAudioSessionDidBeginInterruption:
assistantConnectionAudioSessionDidBeginInterruption:userInfo:
assistantConnectionAudioSessionDidEndInterruption:shouldResume:
assistantConnectionAudioSessionDidEndInterruption:shouldResume:userInfo:
assistantConnectionWillStartAcousticIDRequest:
assistantConnectionDidDetectMusic:
assistantConnection:didFinishAcousticIDRequestWithSuccess:
assistantConnection:setUserActivtiyInfoAndMakeCurrent:webpageURL:
assistantConnectionInvalidateCurrentUserActivity:
assistantConnection:wantsToCacheImage:
assistantConnection:extensionRequestWillStartForApplication:
assistantConnection:extensionRequestFinishedForApplication:error:
assistantConnection:startUIRequestWithText:completion:
assistantConnection:startUIRequestWithInfo:completion:
assistantConnection:willStartAudioPlaybackRequest:
assistantConnection:didStartAudioPlaybackRequest:
assistantConnection:didStopAudioPlaybackRequest:error:
assistantConnection:didHandleQuickStopWithAction:
assistantConnection:willProcessStartPlayback:intent:completion:
assistantConnection:willProcessStartPlayback:
assistantConnection:startPlaybackDidFail:
assistantConnection:audioSessionWillBecomeActive:
assistantConnection:audioSessionDidBecomeActive:
assistantConnection:willProcessAppLaunchWithBundleIdentifier:
assistantConnection:appLaunchFailedWithBundleIdentifier:
assistantConnectionSpeechRecordingWillBegin:
assistantConnection:speechRecordingWillBeginWithInputAudioPowerXPCWrapper:
assistantConnection:speechRecordingDidBeginOnAVRecordRoute:
assistantConnection:speechRecordingDidBeginOnAVRecordRoute:audioSessionID:
assistantConnection:speechRecordingDidChangeAVRecordRoute:
assistantConnectionSpeechRecordingDidDetectStartpoint:
assistantConnection:speechRecordingPerformTwoShotPromptWithType:completion:
assistantConnectionSpeechRecordingDidEnd:
assistantConnectionSpeechRecordingDidCancel:
assistantConnection:speechRecordingDidFail:
assistantConnectionDidChangeAudioRecordingPower:
assistantConnection:speechRecognitionDidFail:
assistantConnection:speechRecognized:
assistantConnection:speechRecognizedPartialResult:
assistantConnection:recognizedAdditionalSpeechInterpretation:refId:
assistantConnection:recognitionUpdateWithPhrases:utterances:refId:
assistantConnection:recognitionUpdateWillBeginForTask:
dictationConnectionSpeechRecordingWillBegin:
dictationConnectionSpeechRecordingDidBegin:
dictationConnection:speechRecordingDidBeginWithOptions:
dictationConnection:didBeginLocalRecognitionWithModelInfo:
dictationConnectionSpeechRecordingDidEnd:
dictationConnectionSpeechRecordingDidCancel:
dictationConnection:speechRecordingDidFail:
dictationConnection:speechRecognitionDidFail:
dictationConnection:didDetectLanguage:confidenceScores:
dictationConnection:didDetectLanguage:confidenceScores:isConfident:
dictationConnection:didRecognizeMultilingualSpeech:
dictationConnection:languageDetectorFailedWithError:
dictationConnection:didRecognizePhrases:languageModel:correctionIdentifier:
dictationConnection:didRecognizePhrases:languageModel:correctionIdentifier:replacingPreviousPhrasesCount:
dictationConnection:didRecognizeTokens:languageModel:
dictationConnection:didRecognizeTokens:nluResult:languageModel:
dictationConnection:didRecognizePartialResult:
dictationConnection:didProcessAudioDuration:
dictationConnectionSpeechRecognitionDidSucceed:
dictationConnection:didRecognizeTranscriptionObjects:languageModel:
dictationConnnectionDidChangeAvailability:
dictationConnection:didFinishWritingAudioFile:error:
dictationConnection:didReceiveSearchResults:recognizedText:stable:final:
dictationConnection:didRecognizePackage:
dictationConnection:didRecognizePackage:nluResult:
dictationConnectionDidPauseRecognition:
dictationConnection:didRecognizeFinalResultCandidatePackage:
_reconcilePronunciations
_reconcileActivities
_iCloudReconcileActivitiesStore:
_iCloudReconcileDataStore:
_syncToWatch
_saveActivitiesToExternalsAndDelete:
_saveCustomPronunciationsToExternalsAndDelete:
_customPronunciationsSettingsChanged
_monitoriCloudVoiceOverData
_updateDefaultVoiceIfNecessaryForLanguage:source:
_updateCachedTTSVoices
_languageForAsset:
_handleExtantVoices
_normalizedSiriName:
_handleSiriStyleVoices:assetRetrieval:voiceIdentifier:voiceName:
migratePrefToNeuralVoiceIfNecessaryForVoice:
_checkForAssets:
informSiriAboutVoiceUsageForIdentifier:forLanguage:add:
_pronunciationAudioLevel
_stopPronunciationSession
_cancelPronunciationSession
_handleFailureForSpeechPronunciation:
_startPronunciationSession:
_combinedVocalizerAssets:
_vocalizerAssets
_vocalizerAssetsForLanguage:
_alexAssets
_mobileAssetDownloadOptions
_handleAssetProgress:asset:installedAsset:
_checkForMacinTalkAssetUpdates
_checkForVocalizerAssetUpdates
_handleSiriAssetDownload:
_downloadAssetsForSelectedVoices
_handleMobileAssetDownload:
_addToDownloadQueue:
_isVocalizerAsset:
_beginDownloadIfNecessaryForSiriAssets:
_beginDownloadIfNecessaryForAssets:
_updateAsset:existingAsset:
_purgeExistingSiriAsset:inFavorOfAsset:
_purgeExistingAsset:inFavorOfAsset:
voiceRefreshQueue
setVoiceRefreshQueue:
.cxx_destruct
_lastTTSVoiceAssetUpdate
_pronunciationPusher
_lastActivitiesICloudRetrieval
_activitiesPusher
_isUpdatingCachedTTSVoices
_dictationConnection
_isRecording
_assetService
_voiceRefreshQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_voiceRefreshQueue
Checking pronunciations
%{public}@
Got pronunciations: %{private}@, count: %d
Exception decoding data: %@
Checking activities
Got activities: count: %d
did not find %@ in %@
%@ not identical to %@
Reconciled iCloud activities: adding: %{private}@
Did not find a change, not updating
Skipping publishing to iCloud because we just retrieved this data
Created an empty length archive, not synching
ICLOUD[%p]: Publishing data to iCloud %{private}@
Not updating default spoken content voice because no speech features are enabled.
Not updating default spoken content voice because switch control is not enabled.
Not updating default voice because the voice doesn't match our system language.
Switching voice from %@ to %@ for source %ld because default voice has changed, and the user hasn't selected one for language %@
Vocalizer assets example[0]: %{public}@
Victoria macinTalkAsset: %{public}@
local macinTalkAsset: %{public}@
remote macinTalkAsset: %{public}@
New siri names %@
Original old siri assets %@
Filtered out old siri assets so we're left with %@
Siri voices not supported
Set extant voices: %{public}@
Retrieved siri-style assets: %{public}@
Siri style: skipping non premium: %@
Siri style: skipping neural: %@
Processed Siri-style assets: %{public}@
made siri voice %@ with asset %@
Updating spoken content settings because the selected voice was a Siri voice, but a neural voice matching the same name and language: %@ was available
Downloading %@ because a non-neural variant was previously selected, but a neural variant is now available
Removing %@ from active siri list, because neural voice was available and non-neural version wasn't in use outside of Speech Features
Force checking speech assets: %d date: %{public}@
No previous LastSpeechAssetUpdateCheck was found. Setting date earlier: %{public}@.
Has speech asset data: %d
Not checking voice assets because it's too soon: %{public}@ - only %f seconds 
Checking on assets now
Asset is installed and is in selected voices: %@
Hearing aid control status: %d
Added hearing to control center: %@ success: %d
Sound detection control status: %d
Added sound detection to control center: %@ success: %d
Inform siri about %@
MAAssetQuery error fetching results %{public}@ %{public}@ %{public}@
Asset progress: %{public}@ - %f
Checking assets: %{public}@
checking assets[%{public}@] %{public}@
Handling download for %@ %@
Finished downloading asset: %@, %@
Updating siri voice list usage after downloading a selected voice ID that was missing
could not parse voice identifier %{public}@
could not find asset for voice identifier %{public}@ but the voice was installed. This is expected if it is a built-in voice.
could not find asset for voice identifier %{public}@
selected voice %{public}@ is already downloading.
selected voice %{public}@ is required by the OS.
selected voice %{public}@ is installed but not in the catalog.
selected voice %{public}@ has unknown state.
selected voice %{public}@ is already installed.
selected voice %{public}@ %@ is not present. Beginning download.
Asset not present, but no space to download voice %{public}@: %{public}@
asset installed with os
Adding asset to queue: %{public}@
No siri asset installed
Installed asset %{public}@, latest asset: %{public}@
Detected new Asset, downloading: %{public}@
Enough disk space available - start %{public}@
Updating Installed Asset: %{public}@
Error: %{public}@
Asset state: %@
Error: Not enough disk space
No newer asset than %{public}@ - [installed asset %{public}@]
Purging old asset: %{public}@
No macintalk or siri asset installed
No newer asset than %{public}@ - %@ [installed asset %{public}@]
Purged old asset: %{public}@, %{public}@
Trying to update unknown asset (expecting Macintalk, Combined, or Siri): %{public}@
Could not remove file protection from: %{public}@
Could not purge old asset: %{public}@
@16@0:8
@24@0:8Q16
B24@0:8@16
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B16@0:8
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
@48@0:8@16Q24@32^@40
B24@0:8Q16
v48@0:8@16Q24@32@?40
v24@0:8@16
v16@0:8
@"NSDictionary"48@0:8@"NSDictionary"16Q24@"NSString"32^@40
v48@0:8@"NSDictionary"16Q24@"NSString"32@?<v@?@"NSDictionary"@"NSError">40
@"AXAccessQueue"24@0:8Q16
v24@0:8@"NSDictionary"16
v24@0:8@"NSString"16
@"NSString"24@0:8Q16
@"NSSet"24@0:8Q16
v32@0:8@16q24
v40@0:8@16@24@?32
v40@0:8@16@24@32
v48@0:8@16@24@32@?40
v28@0:8@16B24
v28@0:8@16I24
v32@0:8@16@24
v36@0:8@16B24@28
v32@0:8@16Q24
v48@0:8@16q24@32@?40
v24@0:8@"AFConnection"16
v32@0:8@"AFConnection"16q24
v40@0:8@"AFConnection"16@"AceObject<SAAceCommand>"24@?<v@?@"AceObject<SAAceCommand>">32
v40@0:8@"AFConnection"16@"NSError"24@"NSString"32
v40@0:8@"AFConnection"16@"NSURL"24@?<v@?B>32
v48@0:8@"AFConnection"16@"NSString"24@"NSURL"32@?<v@?B>40
v28@0:8@"AFConnection"16B24
v28@0:8@"AFConnection"16I24
v32@0:8@"AFConnection"16@"NSDictionary"24
v36@0:8@"AFConnection"16B24@"NSDictionary"28
v40@0:8@"AFConnection"16@"NSDictionary"24@"NSURL"32
v32@0:8@"AFConnection"16@"INImage"24
v32@0:8@"AFConnection"16@"NSString"24
v40@0:8@"AFConnection"16@"NSString"24@"NSError"32
v40@0:8@"AFConnection"16@"NSString"24@?<v@?B>32
v40@0:8@"AFConnection"16@"AFRequestInfo"24@?<v@?B>32
v32@0:8@"AFConnection"16@"AFAudioPlaybackRequest"24
v40@0:8@"AFConnection"16@"AFAudioPlaybackRequest"24@"NSError"32
v32@0:8@"AFConnection"16Q24
v48@0:8@"AFConnection"16q24@"INIntent"32@?<v@?BB>40
v36@0:8@16@24I32
v40@0:8@16q24@?32
v48@0:8@16@24@32@40
v32@0:8@"AFConnection"16@"AFXPCWrapper"24
v36@0:8@"AFConnection"16@"NSString"24I32
v40@0:8@"AFConnection"16q24@?<v@?dd@"NSError">32
v32@0:8@"AFConnection"16@"NSError"24
v32@0:8@"AFConnection"16@"SASSpeechRecognized"24
v32@0:8@"AFConnection"16@"SASSpeechPartialResult"24
v40@0:8@"AFConnection"16@"AFSpeechInterpretation"24@"NSString"32
v48@0:8@"AFConnection"16@"NSArray"24@"NSArray"32@"NSString"40
v44@0:8@16@24@32B40
v56@0:8@16@24@32@40Q48
v32@0:8@16d24
v48@0:8@16@24@32B40B44
v24@0:8@"AFDictationConnection"16
v32@0:8@"AFDictationConnection"16@"AFDictationOptions"24
v32@0:8@"AFDictationConnection"16@"NSString"24
v32@0:8@"AFDictationConnection"16@"NSError"24
v40@0:8@"AFDictationConnection"16@"NSString"24@"NSDictionary"32
v44@0:8@"AFDictationConnection"16@"NSString"24@"NSDictionary"32B40
v32@0:8@"AFDictationConnection"16@"SASMultilingualSpeechRecognized"24
v48@0:8@"AFDictationConnection"16@"NSArray"24@"NSString"32@40
v56@0:8@"AFDictationConnection"16@"NSArray"24@"NSString"32@40Q48
v40@0:8@"AFDictationConnection"16@"NSArray"24@"NSString"32
v48@0:8@"AFDictationConnection"16@"NSArray"24@"AFDictationNLUResult"32@"NSString"40
v32@0:8@"AFDictationConnection"16@"SASSpeechPartialResult"24
v32@0:8@"AFDictationConnection"16d24
v40@0:8@"AFDictationConnection"16@"NSFileHandle"24@"NSError"32
v48@0:8@"AFDictationConnection"16@"NSArray"24@"NSString"32B40B44
v32@0:8@"AFDictationConnection"16@"AFSpeechPackage"24
v40@0:8@"AFDictationConnection"16@"AFSpeechPackage"24@"AFDictationNLUResult"32
@24@0:8@16
v48@0:8@16@?24@?32@?40
v20@0:8B16
v36@0:8@16@24B32
f16@0:8
@20@0:8B16
@"AXDispatchTimer"
@"AFDictationConnection"
@"AXAssetsService"
@"NSObject<OS_dispatch_queue>"
softlink:r:path:/System/Library/PrivateFrameworks/ControlCenterServices.framework/ControlCenterServices
softlink:r:path:/System/Library/PrivateFrameworks/HearingUtilities.framework/HearingUtilities
