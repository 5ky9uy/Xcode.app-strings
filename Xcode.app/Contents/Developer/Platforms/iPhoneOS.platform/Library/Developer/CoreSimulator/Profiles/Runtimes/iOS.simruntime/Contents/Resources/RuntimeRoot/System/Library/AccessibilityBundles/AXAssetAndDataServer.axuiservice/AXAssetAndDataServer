v8@?0
refresh-voices
AXCustomPronunciations
AXVoiceOverActivities
Reconciled iCloud pronunciations: adding: %{private}@
Did not find a change, not updating
CustomPronunciationSubstitutions
NPS: Publishing data to nano domain
ICLOUD[%p]: Waiting 5s to publish, deleting %@
Created an empty length archive, not synching
ICLOUD[%p]: Publishing data to iCloud %{private}@
Custom pronunciations settings updated
@16@?0@"TTSAXResource"8
com.apple.private.kernel.jetsam
com.apple.CoreRoutine.preferences
com.apple.TVServices.DisplayManager
com.apple.accessibility.voiceover
com.apple.appletv.pbs.display-manager-service-access
com.apple.accessibility.axctl
delete
options
audioLevel
v16@?0Q8
v20@?0B8@"NSError"12
com.apple.accessibility.controlcenter.sounddetection
got transcription results: %@
AXSpeechPronunciationClient
results
v24@?0@"NSDictionary"8@"NSError"16
Fail: %@, %d
Error
error
Starting pronunciation dictation: %@, %@, %@
CCSControlCenterService
Unable to find class %s
AXHearingAidControlCenterBundleID
AXAssetAndDataServer
AXUIService
NSObject
AFAssistantUIService
AFSpeechDelegate
AFDictationDelegate
init
sharedInstance
mobileAssetWorkQueue
initWithTargetSerialQueue:
setAutomaticallyCancelPendingBlockUponSchedulingNewBlock:
_monitoriCloudVoiceOverData
_icloudDataChanged:
afterDelay:processBlock:
sharedDatabase
setCloudKitSync:
setCloudKitPushInSameProcess:
defaultStore
dataForKey:
initForReadingFromData:error:
arrayWithObjects:count:
setWithArray:
decodeObjectOfClasses:forKey:
count
_iCloudReconcileDataStore:
_iCloudReconcileActivitiesStore:
synchronize
syncPronunciationsWithCloudKit
_reconcilePronunciations
_reconcileActivities
voiceOverActivities
countByEnumeratingWithState:objects:count:
indexOfObject:
objectAtIndexedSubscript:
isIdenticalTo:
setVoiceOverActivities:
ignoreLogging
identifier
customPronunciationSubstitutions
containsObject:
_syncToWatch
setCustomPronunciationSubstitutions:
setWithObject:
synchronizeUserDefaultsDomain:keys:
copy
archivedDataWithRootObject:requiringSecureCoding:error:
length
setData:forKey:
_saveCustomPronunciationsToExternalsAndDelete:
_customPronunciationsSettingsChanged
registerUpdateBlock:forRetrieveSelector:withListener:
_saveActivitiesToExternalsAndDelete:
defaultCenter
addObserver:selector:name:object:
currentLocale
languageCode
letterFeedbackEnabled
phoneticFeedbackEnabled
wordFeedbackEnabled
quickTypeWordFeedbackEnabled
speakCorrectionsEnabled
isEqualToString:
userDidSelectVoiceForLanguage:source:
resourcesWithLanguage:type:
speechVoice
ax_flatMappedArrayUsingBlock:
isDefault
speechVoiceIdentifierForLanguage:source:exists:
voiceForIdentifier:
footprint
isNeuralSiriVoiceIdentifier:
setSpeechVoiceIdentifier:forLanguage:source:
language
informSiriAboutVoiceUsageForIdentifier:forLanguage:add:
lowercaseString
stringByReplacingOccurrencesOfString:withString:
array
neural
addObject:
languages
firstObject
name
gender
fileSize
numberWithLongLong:
setNonLocalizedNameWithoutQuality:
setIdentifier:
setLanguage:
setGender:
isInstalled
setIsInstalled:
unsignedIntegerValue
setAssetSize:
setCanBeDownloaded:
setQuality:
migratePrefToNeuralVoiceIfNecessaryForVoice:
isSiriVoiceIdentifier:
setWithObjects:
valueForKey:
objectForKeyedSubscript:
secureUnarchiveData:withExpectedClass:otherAllowedClasses:
_startPronunciationSession:
_cancelPronunciationSession
_stopPronunciationSession
_pronunciationAudioLevel
numberWithFloat:
dictionaryWithObjects:forKeys:count:
selectedSpeechVoiceIdentifiers
mobileAssetDownloadQueue
installedAssetsForLanguage:voiceType:
axSafelyAddObjectsFromArray:
setAutoDownloadedVoiceAssets:
setSiriAutoUpdateListInitialized:
requestEnableModuleWithIdentifier:completionHandler:
getEnabledStateOfModuleWithIdentifier:completionHandler:
systemLanguageID
_updateDefaultVoiceIfNecessaryForLanguage:source:
isVocalizerVoiceIdentifier:
informSiriVoiceSubscriptionsWithVoiceId:addition:
_handleFailureForSpeechPronunciation:
averagePower
stopSpeechWithOptions:
cancelSpeech
phonemeSuggestions
clientMessengerWithIdentifier:
backgroundAccessQueue
sendAsynchronousMessage:withIdentifier:targetAccessQueue:completion:
endSession
description
setDelegate:
setTranscriptionMode:
orthography
setOrthography:
initWithActivationEvent:
setIsEyesFree:
setEndpointerOperationMode:
startDictationWithLanguageCode:options:speechOptions:
possibleRequiredEntitlementsForProcessingMessageWithIdentifier:
isEqual:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
debugDescription
TQ,R
T#,R
T@"NSString",R,C
processMessage:withIdentifier:fromClientWithIdentifier:error:
messageWithIdentifierShouldBeProcessedAsynchronously:
processMessageAsynchronously:withIdentifier:fromClientWithIdentifier:completion:
accessQueueForProcessingMessageWithIdentifier:
messageWithIdentifierRequiresWritingBlock:
processInitializationMessage:
serviceWasFullyInitialized
connectionWillBeInterruptedForClientWithIdentifier:
requiredEntitlementForProcessingMessageWithIdentifier:
assistantConnectionRequestWillStart:
assistantConnectionDismissAssistant:
assistantConnection:dismissAssistantWithReason:
assistantConnectionRequestFinished:
assistantConnection:receivedCommand:completion:
assistantConnection:requestFailedWithError:requestClass:
assistantConnection:openURL:completion:
assistantConnection:openApplicationWithBundleID:URL:completion:
assistantConnection:shouldSpeak:
assistantConnection:didChangeAudioSessionID:
assistantConnectionAudioSessionDidBeginInterruption:
assistantConnectionAudioSessionDidBeginInterruption:userInfo:
assistantConnectionAudioSessionDidEndInterruption:shouldResume:
assistantConnectionAudioSessionDidEndInterruption:shouldResume:userInfo:
assistantConnectionWillStartAcousticIDRequest:
assistantConnectionDidDetectMusic:
assistantConnection:didFinishAcousticIDRequestWithSuccess:
assistantConnection:setUserActivtiyInfoAndMakeCurrent:webpageURL:
assistantConnectionInvalidateCurrentUserActivity:
assistantConnection:wantsToCacheImage:
assistantConnection:extensionRequestWillStartForApplication:
assistantConnection:extensionRequestFinishedForApplication:error:
assistantConnection:startUIRequestWithText:completion:
assistantConnection:startUIRequestWithInfo:completion:
assistantConnection:willStartAudioPlaybackRequest:
assistantConnection:didStartAudioPlaybackRequest:
assistantConnection:didStopAudioPlaybackRequest:error:
assistantConnection:didHandleQuickStopWithAction:
assistantConnection:willProcessStartPlayback:intent:completion:
assistantConnection:willProcessStartPlayback:
assistantConnection:startPlaybackDidFail:
assistantConnection:audioSessionWillBecomeActive:
assistantConnection:audioSessionDidBecomeActive:
assistantConnection:willProcessAppLaunchWithBundleIdentifier:
assistantConnection:appLaunchFailedWithBundleIdentifier:
assistantConnectionSpeechRecordingWillBegin:
assistantConnection:speechRecordingWillBeginWithInputAudioPowerXPCWrapper:
assistantConnection:speechRecordingDidBeginOnAVRecordRoute:
assistantConnection:speechRecordingDidBeginOnAVRecordRoute:audioSessionID:
assistantConnection:speechRecordingDidChangeAVRecordRoute:
assistantConnectionSpeechRecordingDidDetectStartpoint:
assistantConnection:speechRecordingPerformTwoShotPromptWithType:completion:
assistantConnectionSpeechRecordingDidEnd:
assistantConnectionSpeechRecordingDidCancel:
assistantConnection:speechRecordingDidFail:
assistantConnectionDidChangeAudioRecordingPower:
assistantConnection:speechRecognitionDidFail:
assistantConnection:speechRecognized:
assistantConnection:speechRecognizedPartialResult:
assistantConnection:recognizedAdditionalSpeechInterpretation:refId:
assistantConnection:recognitionUpdateWithPhrases:utterances:refId:
assistantConnection:recognitionUpdateWillBeginForTask:
dictationConnectionSpeechRecordingWillBegin:
dictationConnectionSpeechRecordingDidBegin:
dictationConnection:speechRecordingDidBeginWithOptions:
dictationConnection:didBeginLocalRecognitionWithModelInfo:
dictationConnectionSpeechRecordingDidEnd:
dictationConnectionSpeechRecordingDidCancel:
dictationConnection:speechRecordingDidFail:
dictationConnection:speechRecognitionDidFail:
dictationConnection:didDetectLanguage:confidenceScores:
dictationConnection:didDetectLanguage:confidenceScores:isConfident:
dictationConnection:didRecognizeMultilingualSpeech:
dictationConnection:languageDetectorFailedWithError:
dictationConnection:didRecognizePhrases:languageModel:correctionIdentifier:
dictationConnection:didRecognizePhrases:languageModel:correctionIdentifier:replacingPreviousPhrasesCount:
dictationConnection:didRecognizeTokens:languageModel:
dictationConnection:didRecognizeTokens:nluResult:languageModel:
dictationConnection:didRecognizePartialResult:
dictationConnection:didProcessAudioDuration:
dictationConnectionSpeechRecognitionDidSucceed:
dictationConnection:didRecognizeTranscriptionObjects:languageModel:
dictationConnnectionDidChangeAvailability:
dictationConnection:didFinishWritingAudioFile:error:
dictationConnection:didReceiveSearchResults:recognizedText:stable:final:
dictationConnection:didRecognizePackage:
dictationConnection:didRecognizePackage:nluResult:
dictationConnectionDidPauseRecognition:
dictationConnection:didRecognizeFinalResultCandidatePackage:
_normalizedSiriName:
_handleSiriStyleVoices:assetRetrieval:voiceIdentifier:voiceName:
voiceRefreshQueue
setVoiceRefreshQueue:
.cxx_destruct
_lastTTSVoiceAssetUpdate
_pronunciationPusher
_lastActivitiesICloudRetrieval
_activitiesPusher
_isUpdatingCachedTTSVoices
_dictationConnection
_isRecording
_assetService
_voiceRefreshQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_voiceRefreshQueue
Checking pronunciations
Got pronunciations: %{private}@, count: %d
Exception decoding data: %@
Checking activities
Got activities: count: %d
did not find %@ in %@
%@ not identical to %@
Reconciled iCloud activities: adding: %{private}@
Did not find a change, not updating
%{public}@
Skipping publishing to iCloud because we just retrieved this data
Created an empty length archive, not synching
ICLOUD[%p]: Publishing data to iCloud %{private}@
Not updating default spoken content voice because no speech features are enabled.
Not updating default spoken content voice because switch control is not enabled.
Not updating default voice because the voice doesn't match our system language.
Switching voice from %@ to %@ for source %ld because default voice has changed, and the user hasn't selected one for language %@
Retrieved siri-style assets: %{public}@
Siri style: skipping non premium: %@
Siri style: skipping neural: %@
Processed Siri-style assets: %{public}@
made siri voice %@ with asset %@
Updating spoken content settings because the selected voice was a Siri voice, but a neural voice matching the same name and language: %@ was available
Downloading %@ because a non-neural variant was previously selected, but a neural variant is now available
Removing %@ from active siri list, because neural voice was available and non-neural version wasn't in use outside of Speech Features
Asset is installed and is in selected voices: %@
Hearing aid control status: %d
Added hearing to control center: %@ success: %d
Sound detection control status: %d
Added sound detection to control center: %@ success: %d
Inform siri about %@
@16@0:8
@24@0:8Q16
B24@0:8@16
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B16@0:8
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
@48@0:8@16Q24@32^@40
B24@0:8Q16
v48@0:8@16Q24@32@?40
v24@0:8@16
v16@0:8
@"NSDictionary"48@0:8@"NSDictionary"16Q24@"NSString"32^@40
v48@0:8@"NSDictionary"16Q24@"NSString"32@?<v@?@"NSDictionary"@"NSError">40
@"AXAccessQueue"24@0:8Q16
v24@0:8@"NSDictionary"16
v24@0:8@"NSString"16
@"NSString"24@0:8Q16
@"NSSet"24@0:8Q16
v32@0:8@16q24
v40@0:8@16@24@?32
v40@0:8@16@24@32
v48@0:8@16@24@32@?40
v28@0:8@16B24
v28@0:8@16I24
v32@0:8@16@24
v36@0:8@16B24@28
v32@0:8@16Q24
v48@0:8@16q24@32@?40
v24@0:8@"AFConnection"16
v32@0:8@"AFConnection"16q24
v40@0:8@"AFConnection"16@"AceObject<SAAceCommand>"24@?<v@?@"AceObject<SAAceCommand>">32
v40@0:8@"AFConnection"16@"NSError"24@"NSString"32
v40@0:8@"AFConnection"16@"NSURL"24@?<v@?B>32
v48@0:8@"AFConnection"16@"NSString"24@"NSURL"32@?<v@?B>40
v28@0:8@"AFConnection"16B24
v28@0:8@"AFConnection"16I24
v32@0:8@"AFConnection"16@"NSDictionary"24
v36@0:8@"AFConnection"16B24@"NSDictionary"28
v40@0:8@"AFConnection"16@"NSDictionary"24@"NSURL"32
v32@0:8@"AFConnection"16@"INImage"24
v32@0:8@"AFConnection"16@"NSString"24
v40@0:8@"AFConnection"16@"NSString"24@"NSError"32
v40@0:8@"AFConnection"16@"NSString"24@?<v@?B>32
v40@0:8@"AFConnection"16@"AFRequestInfo"24@?<v@?B>32
v32@0:8@"AFConnection"16@"AFAudioPlaybackRequest"24
v40@0:8@"AFConnection"16@"AFAudioPlaybackRequest"24@"NSError"32
v32@0:8@"AFConnection"16Q24
v48@0:8@"AFConnection"16q24@"INIntent"32@?<v@?BB>40
v36@0:8@16@24I32
v40@0:8@16q24@?32
v48@0:8@16@24@32@40
v32@0:8@"AFConnection"16@"AFXPCWrapper"24
v36@0:8@"AFConnection"16@"NSString"24I32
v40@0:8@"AFConnection"16q24@?<v@?dd@"NSError">32
v32@0:8@"AFConnection"16@"NSError"24
v32@0:8@"AFConnection"16@"SASSpeechRecognized"24
v32@0:8@"AFConnection"16@"SASSpeechPartialResult"24
v40@0:8@"AFConnection"16@"AFSpeechInterpretation"24@"NSString"32
v48@0:8@"AFConnection"16@"NSArray"24@"NSArray"32@"NSString"40
v44@0:8@16@24@32B40
v56@0:8@16@24@32@40Q48
v32@0:8@16d24
v48@0:8@16@24@32B40B44
v24@0:8@"AFDictationConnection"16
v32@0:8@"AFDictationConnection"16@"AFDictationOptions"24
v32@0:8@"AFDictationConnection"16@"NSString"24
v32@0:8@"AFDictationConnection"16@"NSError"24
v40@0:8@"AFDictationConnection"16@"NSString"24@"NSDictionary"32
v44@0:8@"AFDictationConnection"16@"NSString"24@"NSDictionary"32B40
v32@0:8@"AFDictationConnection"16@"SASMultilingualSpeechRecognized"24
v48@0:8@"AFDictationConnection"16@"NSArray"24@"NSString"32@40
v56@0:8@"AFDictationConnection"16@"NSArray"24@"NSString"32@40Q48
v40@0:8@"AFDictationConnection"16@"NSArray"24@"NSString"32
v48@0:8@"AFDictationConnection"16@"NSArray"24@"AFDictationNLUResult"32@"NSString"40
v32@0:8@"AFDictationConnection"16@"SASSpeechPartialResult"24
v32@0:8@"AFDictationConnection"16d24
v40@0:8@"AFDictationConnection"16@"NSFileHandle"24@"NSError"32
v48@0:8@"AFDictationConnection"16@"NSArray"24@"NSString"32B40B44
v32@0:8@"AFDictationConnection"16@"AFSpeechPackage"24
v40@0:8@"AFDictationConnection"16@"AFSpeechPackage"24@"AFDictationNLUResult"32
@24@0:8@16
v48@0:8@16@?24@?32@?40
v36@0:8@16@24B32
f16@0:8
@"AXDispatchTimer"
@"AFDictationConnection"
@"AXAssetsService"
@"NSObject<OS_dispatch_queue>"
softlink:r:path:/System/Library/PrivateFrameworks/ControlCenterServices.framework/ControlCenterServices
softlink:r:path:/System/Library/PrivateFrameworks/HearingUtilities.framework/HearingUtilities
v8@?0
refresh-voices
AXCustomPronunciations
AXVoiceOverActivities
Reconciled iCloud pronunciations: adding: %{private}@
Did not find a change, not updating
CustomPronunciationSubstitutions
NPS: Publishing data to nano domain
ICLOUD[%p]: Waiting 5s to publish, deleting %@
Created an empty length archive, not synching
ICLOUD[%p]: Publishing data to iCloud %{private}@
Custom pronunciations settings updated
@16@?0@"TTSAXResource"8
com.apple.private.kernel.jetsam
com.apple.CoreRoutine.preferences
com.apple.TVServices.DisplayManager
com.apple.accessibility.voiceover
com.apple.appletv.pbs.display-manager-service-access
com.apple.accessibility.axctl
delete
options
audioLevel
v16@?0Q8
v20@?0B8@"NSError"12
com.apple.accessibility.controlcenter.sounddetection
got transcription results: %@
AXSpeechPronunciationClient
results
v24@?0@"NSDictionary"8@"NSError"16
Fail: %@, %d
Error
error
Starting pronunciation dictation: %@, %@, %@
CCSControlCenterService
Unable to find class %s
AXHearingAidControlCenterBundleID
AXAssetAndDataServer
AXUIService
NSObject
AFAssistantUIService
AFSpeechDelegate
AFDictationDelegate
setCloudKitSync:
length
containsObject:
setVoiceOverActivities:
isSiriVoiceIdentifier:
gender
unsignedIntegerValue
registerUpdateBlock:forRetrieveSelector:withListener:
addObserver:selector:name:object:
sendAsynchronousMessage:withIdentifier:targetAccessQueue:completion:
setTranscriptionMode:
setGender:
wordFeedbackEnabled
stopSpeechWithOptions:
clientMessengerWithIdentifier:
averagePower
installedAssetsForLanguage:voiceType:
setNonLocalizedNameWithoutQuality:
mobileAssetWorkQueue
footprint
setEndpointerOperationMode:
isNeuralSiriVoiceIdentifier:
languages
objectAtIndexedSubscript:
setCloudKitPushInSameProcess:
systemLanguageID
addObject:
startDictationWithLanguageCode:options:speechOptions:
currentLocale
quickTypeWordFeedbackEnabled
selectedSpeechVoiceIdentifiers
cancelSpeech
sharedDatabase
indexOfObject:
mobileAssetDownloadQueue
firstObject
setLanguage:
defaultStore
numberWithLongLong:
initWithTargetSerialQueue:
arrayWithObjects:count:
isInstalled
setDelegate:
setCanBeDownloaded:
setSpeechVoiceIdentifier:forLanguage:source:
initWithActivationEvent:
synchronizeUserDefaultsDomain:keys:
setWithObjects:
secureUnarchiveData:withExpectedClass:otherAllowedClasses:
languageCode
phoneticFeedbackEnabled
voiceForIdentifier:
ignoreLogging
countByEnumeratingWithState:objects:count:
backgroundAccessQueue
defaultCenter
array
setSiriAutoUpdateListInitialized:
setIsInstalled:
speechVoiceIdentifierForLanguage:source:exists:
numberWithFloat:
phonemeSuggestions
setAutomaticallyCancelPendingBlockUponSchedulingNewBlock:
synchronize
valueForKey:
isIdenticalTo:
fileSize
language
setData:forKey:
setWithObject:
setIsEyesFree:
identifier
count
lowercaseString
endSession
speechVoice
resourcesWithLanguage:type:
setAutoDownloadedVoiceAssets:
archivedDataWithRootObject:requiringSecureCoding:error:
decodeObjectOfClasses:forKey:
initForReadingFromData:error:
neural
orthography
setQuality:
ax_flatMappedArrayUsingBlock:
isVocalizerVoiceIdentifier:
isEqualToString:
syncPronunciationsWithCloudKit
getEnabledStateOfModuleWithIdentifier:completionHandler:
userDidSelectVoiceForLanguage:source:
informSiriVoiceSubscriptionsWithVoiceId:addition:
copy
setWithArray:
setCustomPronunciationSubstitutions:
requestEnableModuleWithIdentifier:completionHandler:
setOrthography:
setIdentifier:
letterFeedbackEnabled
axSafelyAddObjectsFromArray:
objectForKeyedSubscript:
speakCorrectionsEnabled
afterDelay:processBlock:
dataForKey:
dictionaryWithObjects:forKeys:count:
name
setAssetSize:
stringByReplacingOccurrencesOfString:withString:
isDefault
init
customPronunciationSubstitutions
voiceOverActivities
_icloudDataChanged:
sharedInstance
possibleRequiredEntitlementsForProcessingMessageWithIdentifier:
isEqual:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
description
debugDescription
TQ,R
T#,R
T@"NSString",R,C
processMessage:withIdentifier:fromClientWithIdentifier:error:
messageWithIdentifierShouldBeProcessedAsynchronously:
processMessageAsynchronously:withIdentifier:fromClientWithIdentifier:completion:
accessQueueForProcessingMessageWithIdentifier:
messageWithIdentifierRequiresWritingBlock:
processInitializationMessage:
serviceWasFullyInitialized
connectionWillBeInterruptedForClientWithIdentifier:
requiredEntitlementForProcessingMessageWithIdentifier:
assistantConnectionRequestWillStart:
assistantConnectionDismissAssistant:
assistantConnection:dismissAssistantWithReason:
assistantConnectionRequestFinished:
assistantConnection:receivedCommand:completion:
assistantConnection:requestFailedWithError:requestClass:
assistantConnection:openURL:completion:
assistantConnection:openApplicationWithBundleID:URL:completion:
assistantConnection:shouldSpeak:
assistantConnection:didChangeAudioSessionID:
assistantConnectionAudioSessionDidBeginInterruption:
assistantConnectionAudioSessionDidBeginInterruption:userInfo:
assistantConnectionAudioSessionDidEndInterruption:shouldResume:
assistantConnectionAudioSessionDidEndInterruption:shouldResume:userInfo:
assistantConnectionWillStartAcousticIDRequest:
assistantConnectionDidDetectMusic:
assistantConnection:didFinishAcousticIDRequestWithSuccess:
assistantConnection:setUserActivtiyInfoAndMakeCurrent:webpageURL:
assistantConnectionInvalidateCurrentUserActivity:
assistantConnection:wantsToCacheImage:
assistantConnection:extensionRequestWillStartForApplication:
assistantConnection:extensionRequestFinishedForApplication:error:
assistantConnection:startUIRequestWithText:completion:
assistantConnection:startUIRequestWithInfo:completion:
assistantConnection:willStartAudioPlaybackRequest:
assistantConnection:didStartAudioPlaybackRequest:
assistantConnection:didStopAudioPlaybackRequest:error:
assistantConnection:didHandleQuickStopWithAction:
assistantConnection:willProcessStartPlayback:intent:completion:
assistantConnection:willProcessStartPlayback:
assistantConnection:startPlaybackDidFail:
assistantConnection:audioSessionWillBecomeActive:
assistantConnection:audioSessionDidBecomeActive:
assistantConnection:willProcessAppLaunchWithBundleIdentifier:
assistantConnection:appLaunchFailedWithBundleIdentifier:
assistantConnectionSpeechRecordingWillBegin:
assistantConnection:speechRecordingWillBeginWithInputAudioPowerXPCWrapper:
assistantConnection:speechRecordingDidBeginOnAVRecordRoute:
assistantConnection:speechRecordingDidBeginOnAVRecordRoute:audioSessionID:
assistantConnection:speechRecordingDidChangeAVRecordRoute:
assistantConnectionSpeechRecordingDidDetectStartpoint:
assistantConnection:speechRecordingPerformTwoShotPromptWithType:completion:
assistantConnectionSpeechRecordingDidEnd:
assistantConnectionSpeechRecordingDidCancel:
assistantConnection:speechRecordingDidFail:
assistantConnectionDidChangeAudioRecordingPower:
assistantConnection:speechRecognitionDidFail:
assistantConnection:speechRecognized:
assistantConnection:speechRecognizedPartialResult:
assistantConnection:recognizedAdditionalSpeechInterpretation:refId:
assistantConnection:recognitionUpdateWithPhrases:utterances:refId:
assistantConnection:recognitionUpdateWillBeginForTask:
dictationConnectionSpeechRecordingWillBegin:
dictationConnectionSpeechRecordingDidBegin:
dictationConnection:speechRecordingDidBeginWithOptions:
dictationConnection:didBeginLocalRecognitionWithModelInfo:
dictationConnectionSpeechRecordingDidEnd:
dictationConnectionSpeechRecordingDidCancel:
dictationConnection:speechRecordingDidFail:
dictationConnection:speechRecognitionDidFail:
dictationConnection:didDetectLanguage:confidenceScores:
dictationConnection:didDetectLanguage:confidenceScores:isConfident:
dictationConnection:didRecognizeMultilingualSpeech:
dictationConnection:languageDetectorFailedWithError:
dictationConnection:didRecognizePhrases:languageModel:correctionIdentifier:
dictationConnection:didRecognizePhrases:languageModel:correctionIdentifier:replacingPreviousPhrasesCount:
dictationConnection:didRecognizeTokens:languageModel:
dictationConnection:didRecognizeTokens:nluResult:languageModel:
dictationConnection:didRecognizePartialResult:
dictationConnection:didProcessAudioDuration:
dictationConnectionSpeechRecognitionDidSucceed:
dictationConnection:didRecognizeTranscriptionObjects:languageModel:
dictationConnnectionDidChangeAvailability:
dictationConnection:didFinishWritingAudioFile:error:
dictationConnection:didReceiveSearchResults:recognizedText:stable:final:
dictationConnection:didRecognizePackage:
dictationConnection:didRecognizePackage:nluResult:
dictationConnectionDidPauseRecognition:
dictationConnection:didRecognizeFinalResultCandidatePackage:
_reconcilePronunciations
_reconcileActivities
_iCloudReconcileActivitiesStore:
_iCloudReconcileDataStore:
_syncToWatch
_saveActivitiesToExternalsAndDelete:
_saveCustomPronunciationsToExternalsAndDelete:
_customPronunciationsSettingsChanged
_monitoriCloudVoiceOverData
_updateDefaultVoiceIfNecessaryForLanguage:source:
_normalizedSiriName:
_handleSiriStyleVoices:assetRetrieval:voiceIdentifier:voiceName:
migratePrefToNeuralVoiceIfNecessaryForVoice:
informSiriAboutVoiceUsageForIdentifier:forLanguage:add:
_pronunciationAudioLevel
_stopPronunciationSession
_cancelPronunciationSession
_handleFailureForSpeechPronunciation:
_startPronunciationSession:
voiceRefreshQueue
setVoiceRefreshQueue:
.cxx_destruct
_lastTTSVoiceAssetUpdate
_pronunciationPusher
_lastActivitiesICloudRetrieval
_activitiesPusher
_isUpdatingCachedTTSVoices
_dictationConnection
_isRecording
_assetService
_voiceRefreshQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_voiceRefreshQueue
Checking pronunciations
%{public}@
Got pronunciations: %{private}@, count: %d
Exception decoding data: %@
Checking activities
Got activities: count: %d
did not find %@ in %@
%@ not identical to %@
Reconciled iCloud activities: adding: %{private}@
Did not find a change, not updating
Skipping publishing to iCloud because we just retrieved this data
Created an empty length archive, not synching
ICLOUD[%p]: Publishing data to iCloud %{private}@
Not updating default spoken content voice because no speech features are enabled.
Not updating default spoken content voice because switch control is not enabled.
Not updating default voice because the voice doesn't match our system language.
Switching voice from %@ to %@ for source %ld because default voice has changed, and the user hasn't selected one for language %@
Retrieved siri-style assets: %{public}@
Siri style: skipping non premium: %@
Siri style: skipping neural: %@
Processed Siri-style assets: %{public}@
made siri voice %@ with asset %@
Updating spoken content settings because the selected voice was a Siri voice, but a neural voice matching the same name and language: %@ was available
Downloading %@ because a non-neural variant was previously selected, but a neural variant is now available
Removing %@ from active siri list, because neural voice was available and non-neural version wasn't in use outside of Speech Features
Asset is installed and is in selected voices: %@
Hearing aid control status: %d
Added hearing to control center: %@ success: %d
Sound detection control status: %d
Added sound detection to control center: %@ success: %d
Inform siri about %@
@16@0:8
@24@0:8Q16
B24@0:8@16
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B16@0:8
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
@48@0:8@16Q24@32^@40
B24@0:8Q16
v48@0:8@16Q24@32@?40
v24@0:8@16
v16@0:8
@"NSDictionary"48@0:8@"NSDictionary"16Q24@"NSString"32^@40
v48@0:8@"NSDictionary"16Q24@"NSString"32@?<v@?@"NSDictionary"@"NSError">40
@"AXAccessQueue"24@0:8Q16
v24@0:8@"NSDictionary"16
v24@0:8@"NSString"16
@"NSString"24@0:8Q16
@"NSSet"24@0:8Q16
v32@0:8@16q24
v40@0:8@16@24@?32
v40@0:8@16@24@32
v48@0:8@16@24@32@?40
v28@0:8@16B24
v28@0:8@16I24
v32@0:8@16@24
v36@0:8@16B24@28
v32@0:8@16Q24
v48@0:8@16q24@32@?40
v24@0:8@"AFConnection"16
v32@0:8@"AFConnection"16q24
v40@0:8@"AFConnection"16@"AceObject<SAAceCommand>"24@?<v@?@"AceObject<SAAceCommand>">32
v40@0:8@"AFConnection"16@"NSError"24@"NSString"32
v40@0:8@"AFConnection"16@"NSURL"24@?<v@?B>32
v48@0:8@"AFConnection"16@"NSString"24@"NSURL"32@?<v@?B>40
v28@0:8@"AFConnection"16B24
v28@0:8@"AFConnection"16I24
v32@0:8@"AFConnection"16@"NSDictionary"24
v36@0:8@"AFConnection"16B24@"NSDictionary"28
v40@0:8@"AFConnection"16@"NSDictionary"24@"NSURL"32
v32@0:8@"AFConnection"16@"INImage"24
v32@0:8@"AFConnection"16@"NSString"24
v40@0:8@"AFConnection"16@"NSString"24@"NSError"32
v40@0:8@"AFConnection"16@"NSString"24@?<v@?B>32
v40@0:8@"AFConnection"16@"AFRequestInfo"24@?<v@?B>32
v32@0:8@"AFConnection"16@"AFAudioPlaybackRequest"24
v40@0:8@"AFConnection"16@"AFAudioPlaybackRequest"24@"NSError"32
v32@0:8@"AFConnection"16Q24
v48@0:8@"AFConnection"16q24@"INIntent"32@?<v@?BB>40
v36@0:8@16@24I32
v40@0:8@16q24@?32
v48@0:8@16@24@32@40
v32@0:8@"AFConnection"16@"AFXPCWrapper"24
v36@0:8@"AFConnection"16@"NSString"24I32
v40@0:8@"AFConnection"16q24@?<v@?dd@"NSError">32
v32@0:8@"AFConnection"16@"NSError"24
v32@0:8@"AFConnection"16@"SASSpeechRecognized"24
v32@0:8@"AFConnection"16@"SASSpeechPartialResult"24
v40@0:8@"AFConnection"16@"AFSpeechInterpretation"24@"NSString"32
v48@0:8@"AFConnection"16@"NSArray"24@"NSArray"32@"NSString"40
v44@0:8@16@24@32B40
v56@0:8@16@24@32@40Q48
v32@0:8@16d24
v48@0:8@16@24@32B40B44
v24@0:8@"AFDictationConnection"16
v32@0:8@"AFDictationConnection"16@"AFDictationOptions"24
v32@0:8@"AFDictationConnection"16@"NSString"24
v32@0:8@"AFDictationConnection"16@"NSError"24
v40@0:8@"AFDictationConnection"16@"NSString"24@"NSDictionary"32
v44@0:8@"AFDictationConnection"16@"NSString"24@"NSDictionary"32B40
v32@0:8@"AFDictationConnection"16@"SASMultilingualSpeechRecognized"24
v48@0:8@"AFDictationConnection"16@"NSArray"24@"NSString"32@40
v56@0:8@"AFDictationConnection"16@"NSArray"24@"NSString"32@40Q48
v40@0:8@"AFDictationConnection"16@"NSArray"24@"NSString"32
v48@0:8@"AFDictationConnection"16@"NSArray"24@"AFDictationNLUResult"32@"NSString"40
v32@0:8@"AFDictationConnection"16@"SASSpeechPartialResult"24
v32@0:8@"AFDictationConnection"16d24
v40@0:8@"AFDictationConnection"16@"NSFileHandle"24@"NSError"32
v48@0:8@"AFDictationConnection"16@"NSArray"24@"NSString"32B40B44
v32@0:8@"AFDictationConnection"16@"AFSpeechPackage"24
v40@0:8@"AFDictationConnection"16@"AFSpeechPackage"24@"AFDictationNLUResult"32
@24@0:8@16
v48@0:8@16@?24@?32@?40
v36@0:8@16@24B32
f16@0:8
@"AXDispatchTimer"
@"AFDictationConnection"
@"AXAssetsService"
@"NSObject<OS_dispatch_queue>"
softlink:r:path:/System/Library/PrivateFrameworks/ControlCenterServices.framework/ControlCenterServices
softlink:r:path:/System/Library/PrivateFrameworks/HearingUtilities.framework/HearingUtilities
