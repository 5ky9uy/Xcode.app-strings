v8@?0
refresh-voices
AXCustomPronunciations
AXVoiceOverActivities
Reconciled iCloud pronunciations: adding: %{private}@
Did not find a change, not updating
CustomPronunciationSubstitutions
NPS: Publishing data to nano domain
ICLOUD[%p]: Waiting 5s to publish, deleting %@
Created an empty length archive, not synching
ICLOUD[%p]: Publishing data to iCloud %{private}@
Custom pronunciations settings updated
@16@?0@"TTSAXResource"8
com.apple.private.kernel.jetsam
com.apple.CoreRoutine.preferences
com.apple.TVServices.DisplayManager
com.apple.accessibility.voiceover
com.apple.appletv.pbs.display-manager-service-access
com.apple.accessibility.axctl
delete
options
audioLevel
v16@?0Q8
v20@?0B8@"NSError"12
com.apple.accessibility.controlcenter.sounddetection
got transcription results: %@
AXSpeechPronunciationClient
results
v24@?0@"NSDictionary"8@"NSError"16
Fail: %@, %d
Error
error
Starting pronunciation dictation: %@, %@, %@
CCSControlCenterService
Unable to find class %s
AXHearingAidControlCenterBundleID
AXAssetAndDataServer
AXUIService
NSObject
AFAssistantUIService
AFSpeechDelegate
AFDictationDelegate
assistantConnection:openApplicationWithBundleID:URL:completion:
T#,R
assistantConnectionAudioSessionDidEndInterruption:shouldResume:
T@"NSString",R,C
dictationConnection:didRecognizeTokens:nluResult:languageModel:
_activitiesPusher
lowercaseString
_cancelPronunciationSession
release
_dictationConnection
setIsInstalled:
_handleSiriStyleVoices:assetRetrieval:voiceIdentifier:voiceName:
setWithObjects:
.cxx_destruct
assistantConnection:willProcessStartPlayback:intent:completion:
T@"NSObject<OS_dispatch_queue>",&,N,V_voiceRefreshQueue
containsObject:
TQ,R
isProxy
_assetService
possibleRequiredEntitlementsForProcessingMessageWithIdentifier:
_customPronunciationsSettingsChanged
setData:forKey:
_handleFailureForSpeechPronunciation:
setOrthography:
_iCloudReconcileActivitiesStore:
_iCloudReconcileDataStore:
_icloudDataChanged:
_isRecording
_isUpdatingCachedTTSVoices
_lastActivitiesICloudRetrieval
_lastTTSVoiceAssetUpdate
_monitoriCloudVoiceOverData
_normalizedSiriName:
_pronunciationAudioLevel
_pronunciationPusher
_reconcileActivities
_reconcilePronunciations
_saveActivitiesToExternalsAndDelete:
_saveCustomPronunciationsToExternalsAndDelete:
_startPronunciationSession:
_stopPronunciationSession
_syncToWatch
_updateDefaultVoiceIfNecessaryForLanguage:source:
_voiceRefreshQueue
accessQueueForProcessingMessageWithIdentifier:
addObject:
addObserver:selector:name:object:
afterDelay:processBlock:
archivedDataWithRootObject:requiringSecureCoding:error:
array
arrayWithObjects:count:
assistantConnection:appLaunchFailedWithBundleIdentifier:
assistantConnection:audioSessionDidBecomeActive:
assistantConnection:audioSessionWillBecomeActive:
assistantConnection:didChangeAudioSessionID:
assistantConnection:didFinishAcousticIDRequestWithSuccess:
assistantConnection:didHandleQuickStopWithAction:
assistantConnection:didStartAudioPlaybackRequest:
assistantConnection:didStopAudioPlaybackRequest:error:
assistantConnection:dismissAssistantWithReason:
assistantConnection:extensionRequestFinishedForApplication:error:
assistantConnection:extensionRequestWillStartForApplication:
assistantConnection:openURL:completion:
assistantConnection:receivedCommand:completion:
assistantConnection:recognitionUpdateWillBeginForTask:
assistantConnection:recognitionUpdateWithPhrases:utterances:refId:
assistantConnection:recognizedAdditionalSpeechInterpretation:refId:
assistantConnection:requestFailedWithError:requestClass:
assistantConnection:setUserActivtiyInfoAndMakeCurrent:webpageURL:
assistantConnection:shouldSpeak:
assistantConnection:speechRecognitionDidFail:
assistantConnection:speechRecognized:
assistantConnection:speechRecognizedPartialResult:
assistantConnection:speechRecordingDidBeginOnAVRecordRoute:
assistantConnection:speechRecordingDidBeginOnAVRecordRoute:audioSessionID:
assistantConnection:speechRecordingDidChangeAVRecordRoute:
assistantConnection:speechRecordingDidFail:
assistantConnection:speechRecordingPerformTwoShotPromptWithType:completion:
assistantConnection:speechRecordingWillBeginWithInputAudioPowerXPCWrapper:
assistantConnection:startPlaybackDidFail:
assistantConnection:startUIRequestWithInfo:completion:
assistantConnection:startUIRequestWithText:completion:
assistantConnection:wantsToCacheImage:
assistantConnection:willProcessAppLaunchWithBundleIdentifier:
assistantConnection:willProcessStartPlayback:
assistantConnection:willStartAudioPlaybackRequest:
assistantConnectionAudioSessionDidBeginInterruption:
assistantConnectionAudioSessionDidBeginInterruption:userInfo:
assistantConnectionAudioSessionDidEndInterruption:shouldResume:userInfo:
assistantConnectionDidChangeAudioRecordingPower:
assistantConnectionDidDetectMusic:
assistantConnectionDismissAssistant:
assistantConnectionInvalidateCurrentUserActivity:
assistantConnectionRequestFinished:
assistantConnectionRequestWillStart:
assistantConnectionSpeechRecordingDidCancel:
assistantConnectionSpeechRecordingDidDetectStartpoint:
assistantConnectionSpeechRecordingDidEnd:
assistantConnectionSpeechRecordingWillBegin:
assistantConnectionWillStartAcousticIDRequest:
autorelease
averagePower
axSafelyAddObjectsFromArray:
ax_flatMappedArrayUsingBlock:
backgroundAccessQueue
cancelSpeech
class
clientMessengerWithIdentifier:
conformsToProtocol:
connectionWillBeInterruptedForClientWithIdentifier:
copy
count
countByEnumeratingWithState:objects:count:
currentLocale
customPronunciationSubstitutions
dataForKey:
debugDescription
decodeObjectOfClasses:forKey:
defaultCenter
defaultStore
description
dictationConnection:didBeginLocalRecognitionWithModelInfo:
dictationConnection:didDetectLanguage:confidenceScores:
dictationConnection:didDetectLanguage:confidenceScores:isConfident:
dictationConnection:didFinishWritingAudioFile:error:
dictationConnection:didProcessAudioDuration:
dictationConnection:didReceiveSearchResults:recognizedText:stable:final:
dictationConnection:didRecognizeFinalResultCandidatePackage:
dictationConnection:didRecognizeMultilingualSpeech:
dictationConnection:didRecognizePackage:
dictationConnection:didRecognizePackage:nluResult:
dictationConnection:didRecognizePartialResult:
dictationConnection:didRecognizePhrases:languageModel:correctionIdentifier:
dictationConnection:didRecognizePhrases:languageModel:correctionIdentifier:replacingPreviousPhrasesCount:
dictationConnection:didRecognizeTokens:languageModel:
dictationConnection:didRecognizeTranscriptionObjects:languageModel:
dictationConnection:languageDetectorFailedWithError:
dictationConnection:speechRecognitionDidFail:
dictationConnection:speechRecordingDidBeginWithOptions:
dictationConnection:speechRecordingDidFail:
dictationConnectionDidPauseRecognition:
dictationConnectionSpeechRecognitionDidSucceed:
dictationConnectionSpeechRecordingDidBegin:
dictationConnectionSpeechRecordingDidCancel:
dictationConnectionSpeechRecordingDidEnd:
dictationConnectionSpeechRecordingWillBegin:
dictationConnnectionDidChangeAvailability:
dictionaryWithObjects:forKeys:count:
endSession
fileSize
firstObject
footprint
gender
getEnabledStateOfModuleWithIdentifier:completionHandler:
hash
identifier
ignoreLogging
indexOfObject:
informSiriAboutVoiceUsageForIdentifier:forLanguage:add:
informSiriVoiceSubscriptionsWithVoiceId:addition:
init
initForReadingFromData:error:
initWithActivationEvent:
initWithTargetSerialQueue:
installedAssetsForLanguage:voiceType:
isDefault
isEqual:
isEqualToString:
isIdenticalTo:
isInstalled
isKindOfClass:
isMemberOfClass:
isNeuralSiriVoiceIdentifier:
isSiriVoiceIdentifier:
isVocalizerVoiceIdentifier:
language
languageCode
languages
length
letterFeedbackEnabled
messageWithIdentifierRequiresWritingBlock:
messageWithIdentifierShouldBeProcessedAsynchronously:
migratePrefToNeuralVoiceIfNecessaryForVoice:
mobileAssetDownloadQueue
mobileAssetWorkQueue
name
neural
numberWithFloat:
numberWithLongLong:
objectAtIndexedSubscript:
objectForKeyedSubscript:
orthography
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
phonemeSuggestions
phoneticFeedbackEnabled
processInitializationMessage:
processMessage:withIdentifier:fromClientWithIdentifier:error:
processMessageAsynchronously:withIdentifier:fromClientWithIdentifier:completion:
quickTypeWordFeedbackEnabled
registerUpdateBlock:forRetrieveSelector:withListener:
requestEnableModuleWithIdentifier:completionHandler:
requiredEntitlementForProcessingMessageWithIdentifier:
resourcesWithLanguage:type:
respondsToSelector:
retain
retainCount
secureUnarchiveData:withExpectedClass:otherAllowedClasses:
selectedSpeechVoiceIdentifiers
self
sendAsynchronousMessage:withIdentifier:targetAccessQueue:completion:
serviceWasFullyInitialized
setAssetSize:
setAutoDownloadedVoiceAssets:
setAutomaticallyCancelPendingBlockUponSchedulingNewBlock:
setCanBeDownloaded:
setCloudKitPushInSameProcess:
setCloudKitSync:
setCustomPronunciationSubstitutions:
setDelegate:
setEndpointerOperationMode:
setGender:
setIdentifier:
setIsEyesFree:
setLanguage:
setNonLocalizedNameWithoutQuality:
setQuality:
setSiriAutoUpdateListInitialized:
setSpeechVoiceIdentifier:forLanguage:source:
setTranscriptionMode:
setVoiceOverActivities:
setVoiceRefreshQueue:
setWithArray:
setWithObject:
sharedDatabase
sharedInstance
speakCorrectionsEnabled
speechVoice
speechVoiceIdentifierForLanguage:source:exists:
startDictationWithLanguageCode:options:speechOptions:
stopSpeechWithOptions:
stringByReplacingOccurrencesOfString:withString:
superclass
syncPronunciationsWithCloudKit
synchronize
synchronizeUserDefaultsDomain:keys:
systemLanguageID
unsignedIntegerValue
userDidSelectVoiceForLanguage:source:
valueForKey:
voiceForIdentifier:
voiceOverActivities
voiceRefreshQueue
wordFeedbackEnabled
zone
Checking pronunciations
Got pronunciations: %{private}@, count: %d
Exception decoding data: %@
Checking activities
Got activities: count: %d
did not find %@ in %@
%@ not identical to %@
Reconciled iCloud activities: adding: %{private}@
Did not find a change, not updating
%{public}@
Skipping publishing to iCloud because we just retrieved this data
Created an empty length archive, not synching
ICLOUD[%p]: Publishing data to iCloud %{private}@
Not updating default spoken content voice because no speech features are enabled.
Not updating default spoken content voice because switch control is not enabled.
Not updating default voice because the voice doesn't match our system language.
Switching voice from %@ to %@ for source %ld because default voice has changed, and the user hasn't selected one for language %@
Retrieved siri-style assets: %{public}@
Siri style: skipping non premium: %@
Siri style: skipping neural: %@
Processed Siri-style assets: %{public}@
made siri voice %@ with asset %@
Updating spoken content settings because the selected voice was a Siri voice, but a neural voice matching the same name and language: %@ was available
Downloading %@ because a non-neural variant was previously selected, but a neural variant is now available
Removing %@ from active siri list, because neural voice was available and non-neural version wasn't in use outside of Speech Features
Asset is installed and is in selected voices: %@
Hearing aid control status: %d
Added hearing to control center: %@ success: %d
Sound detection control status: %d
Added sound detection to control center: %@ success: %d
Inform siri about %@
@16@0:8
@24@0:8Q16
B24@0:8@16
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B16@0:8
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
@48@0:8@16Q24@32^@40
B24@0:8Q16
v48@0:8@16Q24@32@?40
v24@0:8@16
v16@0:8
@"NSDictionary"48@0:8@"NSDictionary"16Q24@"NSString"32^@40
v48@0:8@"NSDictionary"16Q24@"NSString"32@?<v@?@"NSDictionary"@"NSError">40
@"AXAccessQueue"24@0:8Q16
v24@0:8@"NSDictionary"16
v24@0:8@"NSString"16
@"NSString"24@0:8Q16
@"NSSet"24@0:8Q16
v32@0:8@16q24
v40@0:8@16@24@?32
v40@0:8@16@24@32
v48@0:8@16@24@32@?40
v28@0:8@16B24
v28@0:8@16I24
v32@0:8@16@24
v36@0:8@16B24@28
v32@0:8@16Q24
v48@0:8@16q24@32@?40
v24@0:8@"AFConnection"16
v32@0:8@"AFConnection"16q24
v40@0:8@"AFConnection"16@"AceObject<SAAceCommand>"24@?<v@?@"AceObject<SAAceCommand>">32
v40@0:8@"AFConnection"16@"NSError"24@"NSString"32
v40@0:8@"AFConnection"16@"NSURL"24@?<v@?B>32
v48@0:8@"AFConnection"16@"NSString"24@"NSURL"32@?<v@?B>40
v28@0:8@"AFConnection"16B24
v28@0:8@"AFConnection"16I24
v32@0:8@"AFConnection"16@"NSDictionary"24
v36@0:8@"AFConnection"16B24@"NSDictionary"28
v40@0:8@"AFConnection"16@"NSDictionary"24@"NSURL"32
v32@0:8@"AFConnection"16@"INImage"24
v32@0:8@"AFConnection"16@"NSString"24
v40@0:8@"AFConnection"16@"NSString"24@"NSError"32
v40@0:8@"AFConnection"16@"NSString"24@?<v@?B>32
v40@0:8@"AFConnection"16@"AFRequestInfo"24@?<v@?B>32
v32@0:8@"AFConnection"16@"AFAudioPlaybackRequest"24
v40@0:8@"AFConnection"16@"AFAudioPlaybackRequest"24@"NSError"32
v32@0:8@"AFConnection"16Q24
v48@0:8@"AFConnection"16q24@"INIntent"32@?<v@?BB>40
v36@0:8@16@24I32
v40@0:8@16q24@?32
v48@0:8@16@24@32@40
v32@0:8@"AFConnection"16@"AFXPCWrapper"24
v36@0:8@"AFConnection"16@"NSString"24I32
v40@0:8@"AFConnection"16q24@?<v@?dd@"NSError">32
v32@0:8@"AFConnection"16@"NSError"24
v32@0:8@"AFConnection"16@"SASSpeechRecognized"24
v32@0:8@"AFConnection"16@"SASSpeechPartialResult"24
v40@0:8@"AFConnection"16@"AFSpeechInterpretation"24@"NSString"32
v48@0:8@"AFConnection"16@"NSArray"24@"NSArray"32@"NSString"40
v44@0:8@16@24@32B40
v56@0:8@16@24@32@40Q48
v32@0:8@16d24
v48@0:8@16@24@32B40B44
v24@0:8@"AFDictationConnection"16
v32@0:8@"AFDictationConnection"16@"AFDictationOptions"24
v32@0:8@"AFDictationConnection"16@"NSString"24
v32@0:8@"AFDictationConnection"16@"NSError"24
v40@0:8@"AFDictationConnection"16@"NSString"24@"NSDictionary"32
v44@0:8@"AFDictationConnection"16@"NSString"24@"NSDictionary"32B40
v32@0:8@"AFDictationConnection"16@"SASMultilingualSpeechRecognized"24
v48@0:8@"AFDictationConnection"16@"NSArray"24@"NSString"32@40
v56@0:8@"AFDictationConnection"16@"NSArray"24@"NSString"32@40Q48
v40@0:8@"AFDictationConnection"16@"NSArray"24@"NSString"32
v48@0:8@"AFDictationConnection"16@"NSArray"24@"AFDictationNLUResult"32@"NSString"40
v32@0:8@"AFDictationConnection"16@"SASSpeechPartialResult"24
v32@0:8@"AFDictationConnection"16d24
v40@0:8@"AFDictationConnection"16@"NSFileHandle"24@"NSError"32
v48@0:8@"AFDictationConnection"16@"NSArray"24@"NSString"32B40B44
v32@0:8@"AFDictationConnection"16@"AFSpeechPackage"24
v40@0:8@"AFDictationConnection"16@"AFSpeechPackage"24@"AFDictationNLUResult"32
@24@0:8@16
v48@0:8@16@?24@?32@?40
v36@0:8@16@24B32
f16@0:8
@"AXDispatchTimer"
@"AFDictationConnection"
@"AXAssetsService"
@"NSObject<OS_dispatch_queue>"
softlink:r:path:/System/Library/PrivateFrameworks/ControlCenterServices.framework/ControlCenterServices
softlink:r:path:/System/Library/PrivateFrameworks/HearingUtilities.framework/HearingUtilities
v8@?0
refresh-voices
AXCustomPronunciations
AXVoiceOverActivities
Reconciled iCloud pronunciations: adding: %{private}@
Did not find a change, not updating
CustomPronunciationSubstitutions
NPS: Publishing data to nano domain
ICLOUD[%p]: Waiting 5s to publish, deleting %@
Created an empty length archive, not synching
ICLOUD[%p]: Publishing data to iCloud %{private}@
Custom pronunciations settings updated
@16@?0@"TTSAXResource"8
com.apple.private.kernel.jetsam
com.apple.CoreRoutine.preferences
com.apple.TVServices.DisplayManager
com.apple.accessibility.voiceover
com.apple.appletv.pbs.display-manager-service-access
com.apple.accessibility.axctl
delete
options
audioLevel
v16@?0Q8
v20@?0B8@"NSError"12
com.apple.accessibility.controlcenter.sounddetection
got transcription results: %@
AXSpeechPronunciationClient
results
v24@?0@"NSDictionary"8@"NSError"16
Fail: %@, %d
Error
error
Starting pronunciation dictation: %@, %@, %@
CCSControlCenterService
Unable to find class %s
AXHearingAidControlCenterBundleID
AXAssetAndDataServer
AXUIService
NSObject
AFAssistantUIService
AFSpeechDelegate
AFDictationDelegate
assistantConnection:openApplicationWithBundleID:URL:completion:
T#,R
assistantConnectionAudioSessionDidEndInterruption:shouldResume:
T@"NSString",R,C
dictationConnection:didRecognizeTokens:nluResult:languageModel:
_activitiesPusher
lowercaseString
_cancelPronunciationSession
release
_dictationConnection
setIsInstalled:
_handleSiriStyleVoices:assetRetrieval:voiceIdentifier:voiceName:
setWithObjects:
.cxx_destruct
assistantConnection:willProcessStartPlayback:intent:completion:
T@"NSObject<OS_dispatch_queue>",&,N,V_voiceRefreshQueue
containsObject:
TQ,R
isProxy
_assetService
possibleRequiredEntitlementsForProcessingMessageWithIdentifier:
_customPronunciationsSettingsChanged
setData:forKey:
_handleFailureForSpeechPronunciation:
setOrthography:
_iCloudReconcileActivitiesStore:
_iCloudReconcileDataStore:
_icloudDataChanged:
_isRecording
_isUpdatingCachedTTSVoices
_lastActivitiesICloudRetrieval
_lastTTSVoiceAssetUpdate
_monitoriCloudVoiceOverData
_normalizedSiriName:
_pronunciationAudioLevel
_pronunciationPusher
_reconcileActivities
_reconcilePronunciations
_saveActivitiesToExternalsAndDelete:
_saveCustomPronunciationsToExternalsAndDelete:
_startPronunciationSession:
_stopPronunciationSession
_syncToWatch
_updateDefaultVoiceIfNecessaryForLanguage:source:
_voiceRefreshQueue
accessQueueForProcessingMessageWithIdentifier:
addObject:
addObserver:selector:name:object:
afterDelay:processBlock:
archivedDataWithRootObject:requiringSecureCoding:error:
array
arrayWithObjects:count:
assistantConnection:appLaunchFailedWithBundleIdentifier:
assistantConnection:audioSessionDidBecomeActive:
assistantConnection:audioSessionWillBecomeActive:
assistantConnection:didChangeAudioSessionID:
assistantConnection:didFinishAcousticIDRequestWithSuccess:
assistantConnection:didHandleQuickStopWithAction:
assistantConnection:didStartAudioPlaybackRequest:
assistantConnection:didStopAudioPlaybackRequest:error:
assistantConnection:dismissAssistantWithReason:
assistantConnection:extensionRequestFinishedForApplication:error:
assistantConnection:extensionRequestWillStartForApplication:
assistantConnection:openURL:completion:
assistantConnection:receivedCommand:completion:
assistantConnection:recognitionUpdateWillBeginForTask:
assistantConnection:recognitionUpdateWithPhrases:utterances:refId:
assistantConnection:recognizedAdditionalSpeechInterpretation:refId:
assistantConnection:requestFailedWithError:requestClass:
assistantConnection:setUserActivtiyInfoAndMakeCurrent:webpageURL:
assistantConnection:shouldSpeak:
assistantConnection:speechRecognitionDidFail:
assistantConnection:speechRecognized:
assistantConnection:speechRecognizedPartialResult:
assistantConnection:speechRecordingDidBeginOnAVRecordRoute:
assistantConnection:speechRecordingDidBeginOnAVRecordRoute:audioSessionID:
assistantConnection:speechRecordingDidChangeAVRecordRoute:
assistantConnection:speechRecordingDidFail:
assistantConnection:speechRecordingPerformTwoShotPromptWithType:completion:
assistantConnection:speechRecordingWillBeginWithInputAudioPowerXPCWrapper:
assistantConnection:startPlaybackDidFail:
assistantConnection:startUIRequestWithInfo:completion:
assistantConnection:startUIRequestWithText:completion:
assistantConnection:wantsToCacheImage:
assistantConnection:willProcessAppLaunchWithBundleIdentifier:
assistantConnection:willProcessStartPlayback:
assistantConnection:willStartAudioPlaybackRequest:
assistantConnectionAudioSessionDidBeginInterruption:
assistantConnectionAudioSessionDidBeginInterruption:userInfo:
assistantConnectionAudioSessionDidEndInterruption:shouldResume:userInfo:
assistantConnectionDidChangeAudioRecordingPower:
assistantConnectionDidDetectMusic:
assistantConnectionDismissAssistant:
assistantConnectionInvalidateCurrentUserActivity:
assistantConnectionRequestFinished:
assistantConnectionRequestWillStart:
assistantConnectionSpeechRecordingDidCancel:
assistantConnectionSpeechRecordingDidDetectStartpoint:
assistantConnectionSpeechRecordingDidEnd:
assistantConnectionSpeechRecordingWillBegin:
assistantConnectionWillStartAcousticIDRequest:
autorelease
averagePower
axSafelyAddObjectsFromArray:
ax_flatMappedArrayUsingBlock:
backgroundAccessQueue
cancelSpeech
class
clientMessengerWithIdentifier:
conformsToProtocol:
connectionWillBeInterruptedForClientWithIdentifier:
copy
count
countByEnumeratingWithState:objects:count:
currentLocale
customPronunciationSubstitutions
dataForKey:
debugDescription
decodeObjectOfClasses:forKey:
defaultCenter
defaultStore
description
dictationConnection:didBeginLocalRecognitionWithModelInfo:
dictationConnection:didDetectLanguage:confidenceScores:
dictationConnection:didDetectLanguage:confidenceScores:isConfident:
dictationConnection:didFinishWritingAudioFile:error:
dictationConnection:didProcessAudioDuration:
dictationConnection:didReceiveSearchResults:recognizedText:stable:final:
dictationConnection:didRecognizeFinalResultCandidatePackage:
dictationConnection:didRecognizeMultilingualSpeech:
dictationConnection:didRecognizePackage:
dictationConnection:didRecognizePackage:nluResult:
dictationConnection:didRecognizePartialResult:
dictationConnection:didRecognizePhrases:languageModel:correctionIdentifier:
dictationConnection:didRecognizePhrases:languageModel:correctionIdentifier:replacingPreviousPhrasesCount:
dictationConnection:didRecognizeTokens:languageModel:
dictationConnection:didRecognizeTranscriptionObjects:languageModel:
dictationConnection:languageDetectorFailedWithError:
dictationConnection:speechRecognitionDidFail:
dictationConnection:speechRecordingDidBeginWithOptions:
dictationConnection:speechRecordingDidFail:
dictationConnectionDidPauseRecognition:
dictationConnectionSpeechRecognitionDidSucceed:
dictationConnectionSpeechRecordingDidBegin:
dictationConnectionSpeechRecordingDidCancel:
dictationConnectionSpeechRecordingDidEnd:
dictationConnectionSpeechRecordingWillBegin:
dictationConnnectionDidChangeAvailability:
dictionaryWithObjects:forKeys:count:
endSession
fileSize
firstObject
footprint
gender
getEnabledStateOfModuleWithIdentifier:completionHandler:
hash
identifier
ignoreLogging
indexOfObject:
informSiriAboutVoiceUsageForIdentifier:forLanguage:add:
informSiriVoiceSubscriptionsWithVoiceId:addition:
init
initForReadingFromData:error:
initWithActivationEvent:
initWithTargetSerialQueue:
installedAssetsForLanguage:voiceType:
isDefault
isEqual:
isEqualToString:
isIdenticalTo:
isInstalled
isKindOfClass:
isMemberOfClass:
isNeuralSiriVoiceIdentifier:
isSiriVoiceIdentifier:
isVocalizerVoiceIdentifier:
language
languageCode
languages
length
letterFeedbackEnabled
messageWithIdentifierRequiresWritingBlock:
messageWithIdentifierShouldBeProcessedAsynchronously:
migratePrefToNeuralVoiceIfNecessaryForVoice:
mobileAssetDownloadQueue
mobileAssetWorkQueue
name
neural
numberWithFloat:
numberWithLongLong:
objectAtIndexedSubscript:
objectForKeyedSubscript:
orthography
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
phonemeSuggestions
phoneticFeedbackEnabled
processInitializationMessage:
processMessage:withIdentifier:fromClientWithIdentifier:error:
processMessageAsynchronously:withIdentifier:fromClientWithIdentifier:completion:
quickTypeWordFeedbackEnabled
registerUpdateBlock:forRetrieveSelector:withListener:
requestEnableModuleWithIdentifier:completionHandler:
requiredEntitlementForProcessingMessageWithIdentifier:
resourcesWithLanguage:type:
respondsToSelector:
retain
retainCount
secureUnarchiveData:withExpectedClass:otherAllowedClasses:
selectedSpeechVoiceIdentifiers
self
sendAsynchronousMessage:withIdentifier:targetAccessQueue:completion:
serviceWasFullyInitialized
setAssetSize:
setAutoDownloadedVoiceAssets:
setAutomaticallyCancelPendingBlockUponSchedulingNewBlock:
setCanBeDownloaded:
setCloudKitPushInSameProcess:
setCloudKitSync:
setCustomPronunciationSubstitutions:
setDelegate:
setEndpointerOperationMode:
setGender:
setIdentifier:
setIsEyesFree:
setLanguage:
setNonLocalizedNameWithoutQuality:
setQuality:
setSiriAutoUpdateListInitialized:
setSpeechVoiceIdentifier:forLanguage:source:
setTranscriptionMode:
setVoiceOverActivities:
setVoiceRefreshQueue:
setWithArray:
setWithObject:
sharedDatabase
sharedInstance
speakCorrectionsEnabled
speechVoice
speechVoiceIdentifierForLanguage:source:exists:
startDictationWithLanguageCode:options:speechOptions:
stopSpeechWithOptions:
stringByReplacingOccurrencesOfString:withString:
superclass
syncPronunciationsWithCloudKit
synchronize
synchronizeUserDefaultsDomain:keys:
systemLanguageID
unsignedIntegerValue
userDidSelectVoiceForLanguage:source:
valueForKey:
voiceForIdentifier:
voiceOverActivities
voiceRefreshQueue
wordFeedbackEnabled
zone
Checking pronunciations
%{public}@
Got pronunciations: %{private}@, count: %d
Exception decoding data: %@
Checking activities
Got activities: count: %d
did not find %@ in %@
%@ not identical to %@
Reconciled iCloud activities: adding: %{private}@
Did not find a change, not updating
Skipping publishing to iCloud because we just retrieved this data
Created an empty length archive, not synching
ICLOUD[%p]: Publishing data to iCloud %{private}@
Not updating default spoken content voice because no speech features are enabled.
Not updating default spoken content voice because switch control is not enabled.
Not updating default voice because the voice doesn't match our system language.
Switching voice from %@ to %@ for source %ld because default voice has changed, and the user hasn't selected one for language %@
Retrieved siri-style assets: %{public}@
Siri style: skipping non premium: %@
Siri style: skipping neural: %@
Processed Siri-style assets: %{public}@
made siri voice %@ with asset %@
Updating spoken content settings because the selected voice was a Siri voice, but a neural voice matching the same name and language: %@ was available
Downloading %@ because a non-neural variant was previously selected, but a neural variant is now available
Removing %@ from active siri list, because neural voice was available and non-neural version wasn't in use outside of Speech Features
Asset is installed and is in selected voices: %@
Hearing aid control status: %d
Added hearing to control center: %@ success: %d
Sound detection control status: %d
Added sound detection to control center: %@ success: %d
Inform siri about %@
@16@0:8
@24@0:8Q16
B24@0:8@16
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B16@0:8
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
@48@0:8@16Q24@32^@40
B24@0:8Q16
v48@0:8@16Q24@32@?40
v24@0:8@16
v16@0:8
@"NSDictionary"48@0:8@"NSDictionary"16Q24@"NSString"32^@40
v48@0:8@"NSDictionary"16Q24@"NSString"32@?<v@?@"NSDictionary"@"NSError">40
@"AXAccessQueue"24@0:8Q16
v24@0:8@"NSDictionary"16
v24@0:8@"NSString"16
@"NSString"24@0:8Q16
@"NSSet"24@0:8Q16
v32@0:8@16q24
v40@0:8@16@24@?32
v40@0:8@16@24@32
v48@0:8@16@24@32@?40
v28@0:8@16B24
v28@0:8@16I24
v32@0:8@16@24
v36@0:8@16B24@28
v32@0:8@16Q24
v48@0:8@16q24@32@?40
v24@0:8@"AFConnection"16
v32@0:8@"AFConnection"16q24
v40@0:8@"AFConnection"16@"AceObject<SAAceCommand>"24@?<v@?@"AceObject<SAAceCommand>">32
v40@0:8@"AFConnection"16@"NSError"24@"NSString"32
v40@0:8@"AFConnection"16@"NSURL"24@?<v@?B>32
v48@0:8@"AFConnection"16@"NSString"24@"NSURL"32@?<v@?B>40
v28@0:8@"AFConnection"16B24
v28@0:8@"AFConnection"16I24
v32@0:8@"AFConnection"16@"NSDictionary"24
v36@0:8@"AFConnection"16B24@"NSDictionary"28
v40@0:8@"AFConnection"16@"NSDictionary"24@"NSURL"32
v32@0:8@"AFConnection"16@"INImage"24
v32@0:8@"AFConnection"16@"NSString"24
v40@0:8@"AFConnection"16@"NSString"24@"NSError"32
v40@0:8@"AFConnection"16@"NSString"24@?<v@?B>32
v40@0:8@"AFConnection"16@"AFRequestInfo"24@?<v@?B>32
v32@0:8@"AFConnection"16@"AFAudioPlaybackRequest"24
v40@0:8@"AFConnection"16@"AFAudioPlaybackRequest"24@"NSError"32
v32@0:8@"AFConnection"16Q24
v48@0:8@"AFConnection"16q24@"INIntent"32@?<v@?BB>40
v36@0:8@16@24I32
v40@0:8@16q24@?32
v48@0:8@16@24@32@40
v32@0:8@"AFConnection"16@"AFXPCWrapper"24
v36@0:8@"AFConnection"16@"NSString"24I32
v40@0:8@"AFConnection"16q24@?<v@?dd@"NSError">32
v32@0:8@"AFConnection"16@"NSError"24
v32@0:8@"AFConnection"16@"SASSpeechRecognized"24
v32@0:8@"AFConnection"16@"SASSpeechPartialResult"24
v40@0:8@"AFConnection"16@"AFSpeechInterpretation"24@"NSString"32
v48@0:8@"AFConnection"16@"NSArray"24@"NSArray"32@"NSString"40
v44@0:8@16@24@32B40
v56@0:8@16@24@32@40Q48
v32@0:8@16d24
v48@0:8@16@24@32B40B44
v24@0:8@"AFDictationConnection"16
v32@0:8@"AFDictationConnection"16@"AFDictationOptions"24
v32@0:8@"AFDictationConnection"16@"NSString"24
v32@0:8@"AFDictationConnection"16@"NSError"24
v40@0:8@"AFDictationConnection"16@"NSString"24@"NSDictionary"32
v44@0:8@"AFDictationConnection"16@"NSString"24@"NSDictionary"32B40
v32@0:8@"AFDictationConnection"16@"SASMultilingualSpeechRecognized"24
v48@0:8@"AFDictationConnection"16@"NSArray"24@"NSString"32@40
v56@0:8@"AFDictationConnection"16@"NSArray"24@"NSString"32@40Q48
v40@0:8@"AFDictationConnection"16@"NSArray"24@"NSString"32
v48@0:8@"AFDictationConnection"16@"NSArray"24@"AFDictationNLUResult"32@"NSString"40
v32@0:8@"AFDictationConnection"16@"SASSpeechPartialResult"24
v32@0:8@"AFDictationConnection"16d24
v40@0:8@"AFDictationConnection"16@"NSFileHandle"24@"NSError"32
v48@0:8@"AFDictationConnection"16@"NSArray"24@"NSString"32B40B44
v32@0:8@"AFDictationConnection"16@"AFSpeechPackage"24
v40@0:8@"AFDictationConnection"16@"AFSpeechPackage"24@"AFDictationNLUResult"32
@24@0:8@16
v48@0:8@16@?24@?32@?40
v36@0:8@16@24B32
f16@0:8
@"AXDispatchTimer"
@"AFDictationConnection"
@"AXAssetsService"
@"NSObject<OS_dispatch_queue>"
softlink:r:path:/System/Library/PrivateFrameworks/ControlCenterServices.framework/ControlCenterServices
softlink:r:path:/System/Library/PrivateFrameworks/HearingUtilities.framework/HearingUtilities
