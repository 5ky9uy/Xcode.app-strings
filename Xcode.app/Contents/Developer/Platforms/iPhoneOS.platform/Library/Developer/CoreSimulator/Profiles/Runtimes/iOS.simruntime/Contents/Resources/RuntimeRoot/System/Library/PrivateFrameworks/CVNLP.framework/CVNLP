allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
v8@?0
General
TextDecoder
CTCTextDecoder
CVNLPLanguageModel
CVNLPCLIPModel
CVNLPVideoCaptioningModel
com.apple.cvnlp
bolt_id
net_file
vocab_file
vocab_name
output_name
encoder
num_layers
max_seq_len
Expected model_spec.json to contain key: 
seq_len
embed_dim
filterTokens
runtime_parameters.json file exists but does not contain filterTokens: 
encoder_embed
caption_ids
caption_ids_mask
caption_causal_mask
runtime_parameters.json
Filename specified by model_spec.json for video captioning espresso network not found: 
Incorrect data type requested.
[json.exception.
invalid BOM; must be 0xEF 0xBB 0xBF if given
null
invalid literal
invalid string: missing closing quote
invalid string: '\u' must be followed by 4 hex digits
invalid string: surrogate U+DC00..U+DFFF must be followed by U+DC00..U+DFFF
invalid string: surrogate U+DC00..U+DFFF must follow U+D800..U+DBFF
invalid string: forbidden character after backslash
invalid string: control character U+0000 (NUL) must be escaped to \u0000
invalid string: control character U+0001 (SOH) must be escaped to \u0001
invalid string: control character U+0002 (STX) must be escaped to \u0002
invalid string: control character U+0003 (ETX) must be escaped to \u0003
invalid string: control character U+0004 (EOT) must be escaped to \u0004
invalid string: control character U+0005 (ENQ) must be escaped to \u0005
invalid string: control character U+0006 (ACK) must be escaped to \u0006
invalid string: control character U+0007 (BEL) must be escaped to \u0007
invalid string: control character U+0008 (BS) must be escaped to \u0008 or \b
invalid string: control character U+0009 (HT) must be escaped to \u0009 or \t
invalid string: control character U+000A (LF) must be escaped to \u000A or \n
invalid string: control character U+000B (VT) must be escaped to \u000B
invalid string: control character U+000C (FF) must be escaped to \u000C or \f
invalid string: control character U+000D (CR) must be escaped to \u000D or \r
invalid string: control character U+000E (SO) must be escaped to \u000E
invalid string: control character U+000F (SI) must be escaped to \u000F
invalid string: control character U+0010 (DLE) must be escaped to \u0010
invalid string: control character U+0011 (DC1) must be escaped to \u0011
invalid string: control character U+0012 (DC2) must be escaped to \u0012
invalid string: control character U+0013 (DC3) must be escaped to \u0013
invalid string: control character U+0014 (DC4) must be escaped to \u0014
invalid string: control character U+0015 (NAK) must be escaped to \u0015
invalid string: control character U+0016 (SYN) must be escaped to \u0016
invalid string: control character U+0017 (ETB) must be escaped to \u0017
invalid string: control character U+0018 (CAN) must be escaped to \u0018
invalid string: control character U+0019 (EM) must be escaped to \u0019
invalid string: control character U+001A (SUB) must be escaped to \u001A
invalid string: control character U+001B (ESC) must be escaped to \u001B
invalid string: control character U+001C (FS) must be escaped to \u001C
invalid string: control character U+001D (GS) must be escaped to \u001D
invalid string: control character U+001E (RS) must be escaped to \u001E
invalid string: control character U+001F (US) must be escaped to \u001F
invalid string: ill-formed UTF-8 byte
invalid number; expected digit after '-'
invalid number; expected digit after '.'
invalid number; expected '+', '-', or digit after exponent
invalid number; expected digit after exponent sign
object separator
array
object
excessive object size: 
cannot compare iterators of different containers
invalid_iterator
cannot get value
iterator does not fit current value
iterator out of range
cannot use erase() with 
string
boolean
discarded
number
excessive array size: 
<U+%.4X>
parse error
 at line 
, column 
while parsing 
; last read: '
unexpected 
; expected 
<uninitialized>
true literal
false literal
null literal
string literal
number literal
<parse error>
end of input
'[', '{', or a literal
unknown token
[KeyError] 
cannot use operator[] with a string argument with 
type must be string, but is 
type must be number, but is 
type must be array, but is 
[FileNotFoundError] 
%@%@
Error during scaling.
Error code %zd
/System/Library/PrivateFrameworks/CVNLP.framework/lm_vocabulary.plist
/tmp/lm_vocabulary.plist
CVNLPBeamSearch
Could not construct
CVNLPCommSafetyImageSensitivity
CVNLPCommSafetyImageSensitivityScore
CVNLPCommSafetyHandlerImageClassificationScores
CVNLPCaptionScaleMethod
CVNLPCaptionScaleMethodCGInterpolationNone
CVNLPCaptionScaleMethodCGInterpolationLow
CVNLPCaptionScaleMethodCGInterpolationMedium
CVNLPCaptionScaleMethodCGInterpolationHigh
CVNLPCaptionScaleMethodvImage
CVNLPCommSafetyUseCPU
CVNLPCommSafetyUseGPU
CVNLPCommSafetyUseANE
CVNLPCommSafetyUseAnyAvailableDevice
CVNLPCommSafetyUseMTLDevice
CVNLPCommSafetyEnableAllClasses
CVNLPCommSafetyUseImageAnalyzer
CVNLPCommSafetyUseTextAnalyzer
encoder_opt.espresso.net
image
mean_feats
att_feats
p_att_feats
CVNLPVideoCaptioningModelName
CVNLPVideoCaptioningModelEspressoEngine
CVNLPVideoCaptioningModelBeamSearchMaxSteps
CVNLPVideoCaptioningModelBeamSearchBeamWidth
CVNLPVideoCaptioningModelBeamSearchTopK
CVNLPVideoCaptioningModelBeamSearchLengthPenalty
CLIP
Invalid model directory: 
Could not convert
Unrecognized value for engine=
[InvalidArgument] 
+N9mZUAHooNvMiQnjeTJ8g
VNCreateSceneprintRequest
Unable to find class %s
VNImageRequestHandler
CVNLPCaptionError
CVNLPVideoCaptioningModelError
You must override %@ in a subclass
from
%@(%@ <%@> at <%@>: <%@>)
CVNLPCommSafetyTextItem requires keyed coding
CVNLPConversationIdentifier
CVNLPDate
CVNLPDirection
CVNLPText
INSendMessageIntent
com.apple.MobileSMS
CVNLPCommSafetyCDTextProvider event query creation failed: %@
CVNLPCommSafetyCDTextProvider event query execution error: %@
chat
urn:biz:
CVNLPCommSafetyCDTextProvider event query execution failed: %@
_DKKnowledgeStore
_DKEventQuery
_DKSystemEventStreams
_DKQuery
_DKSource
_DKIntentMetadataKey
CVNLPCommSafetyCDTextProvider class initialization failed: %p %p %p %p %p %p
CVNLPCommSafetyCDTextProvider class initialization failed: %@
] Avg vocab subset size over 
 samples: 
; numRetries: 
position
] sampleText: 
/dev/urandom
temperature
InputDimension
SequenceLength
ModelURL
ModelData
InputNames
OutputNames
ModelName
ModelVersion
QuantizationParams
QuantizationSchemeName
QuantizationSchemeLinearInt8RangeMin
QuantizationSchemeLinearInt8RangeMax
Unexpected mrlkey: 
Activation Matrix with %ld timesteps, %ld observations 
 t%ld, <B>:%.2f [%ld], sym=%@:%.2f [%ld]
CVNLPCLIPModelName
v3.1
c_network_get_input_names returned null for encoder
Failed to load encoder network
Encode
EncodePx
q24@?0@"NSString"8@"NSString"16
com.apple.CVNLPCLIPModel
Could not find item
com.apple.CVNLP
Default
captionModel
minimumConfidence
lengthNormalizationFactor
excludeGenderStrategy
classifiers
revisions
blockingTokens
categories
replacements
excludeGenderReplacements
excludeGenderTriggers
gender
blacklistTokens
blockingTokensAnnex
replaceKey
replaceWith
replaceProb
genderOption
v44@?0^{__CFURL=}8i16^{__CFLocale=}20^{__CFString=}28^B36
v28@?0r*8q16I24
0123456789
<PS>
v56@?0@"NSString"8{_NSRange=QQ}16{_NSRange=QQ}32^B48
Missing or incorrect bos or eos or unk token in vocabulary file
Unexpected format in Special Map file
Special token shall not appear in vocabulary file
Missing special token class in vocabulary file
Unknown TokenID: 
Special token 
 not found in vocab!
Unknown Token: 
Input text should not contain BOS token!
OutOfVocabularyError: 
bimap<>: invalid key
[%@: Peak-Delta: %lf, CPU-Time: %lf, Interval: %lf]
maxpeak
peakdelta
recentpeak
current
timeInterval
CVNLPExceptionError
caption_queue
classify_queue
Create
Total
Scale
ScalePx
TotalPx
comm_safety_handler
CSModels/ImageModel
CVNLPCommSafetyError
["%@"], modelLogProb=%.8f, logProbTotalNorm=%.8f, logProbBlank=%.8f, logProbNonBlank=%.8f, %lu tokens
["%@"], logProbTotal=%.8f, logProbNormTotal=%.8f, logProbWordLM=%.8f, logProbHistoryLex=%.8f, logProbActiveLex=%.8f, logProbCharacterLM=%.8f, %lu tokens
v24@?0^{_LXCursor=}8^B16
'.-/
com.apple.cvnlp.languagemodeling
d16@?0@"CVNLPTextDecodingPath"8
CVNLPCLIPModelURL
CVNLPCLIPModelEspressoEngine
MRLNeuralNetworkCreate returned nullptr
DictionaryRef_iterator iterator out of range.
decoder_queue
DecodeBlockExecute:%tu
DecodeBlockCopy:%tu
decoder_block%tu_opt.espresso.net
att_feats_placeholder
block_input
block_output
decoder_opt.espresso.net
vanilla_attention
_out
in_word_ids
word_probs
in_word_ids_mask
scale
Failed to load decoder network
self_attention
_k_s_in
_v_s_in
Failed to execute decoder network
60dc96fd80c33771139d6cf90639a776
1.5.0
self ENDSWITH '%@_quantized.espresso.net'
self ENDSWITH '%@_quantized_sqdev.espresso.net'
Could not create espresso context for engine: 
 and device id: 
self ENDSWITH 'operating_thresholds.json'
d61a476a2e70af249c2b1695097eeea9
d9ad80f7b43abb16a607e4361c87bca3
e156d20cabbf6d6cbca2f1f437738097
64c53be656ce81ef8aad95a16847f9ce
c9cc54544693ed5ad6386336207971dd
85a5e1ae11b0353df314fe3763da2c56
58484718d77c0af68837b49bde584d48
63f9d5d4ca6958521ae9de3dcaa6fef6
Name could not be encoded: 
Name could not be decoded: 
class_thresholds
class
index
default
thresholds
59744aeff8
Inference
precision_recall_data
CVNLPBeamSearchSize
CVNLPBeamSearchLengthNormalizationFactor
CVNLPBeamSearchOutputVocabSize
CVNLPBeamSearchOutputVocabPath
CVNLPBeamSearchOutputVocabMap
CVNLPBeamSearchOutputVocabFilterList
CVNLPBeamSearchBlacklistRules
CVNLPBeamEndToken
CVNLPBeamSearchIncludeLanguageModel
CVNLPBeamSearchBeamID
CVNLPBeamSearchNextTokenID
CVNLPBeamSearchNextTokenSoftmaxValues
CVNLPBeamSearchNextTokenMetaData
CVNLPBeamTokens
CVNLPBeamScore
sentencepiece.model
Unable to find vocab file.
d24@?0d8d16
%@ : %.2f
v32@?0@"NSString"8@"CVNLPCTCTextDecodingPath"16^B24
FPS is : %f 
Invalid model URL: 
Received lengthPenalty=
, which is outside the allowed range of [0.0, 10.0]. Please set to a floating point number between 0 and 10.
Unknown error encountered during initWithOptions.
Unknown error encountered during generateCaption.
VNImageBuffer
Key not found in dictionary: 
CVNLPCaption
[UnknownError] 
 %@ 
triggerTokens
@"NSError"16@?0@"VNImageBasedRequest"8
Failed to create s-classifier
Failed to create n-classifier
VisionRequestCreation
VisionPerformRequest
VN6Mb1ME89lyW3HpahkEygIG
VNVYvzEtX1JlUdu8xx5qhDI
CVNLPModelURLKey
CVNLPTokenTypeKey
CVNLPLocaleKey
CVNLPLanguageModelArchitectureKey
CVNLPSamplingBeamSizeKey
CVNLPSamplingMaxLengthKey
CVNLPSamplingMethodKey
CVNLPSamplingNucleusThresholdKey
CVNLPSamplingNumberKey
CVNLPSamplingTopKKey
Missing required key:
LSTM
model.espresso.bin
_gpt
Received null token.
Received empty token.
Method
GREEDY
BEAM
TOP_K
NUCLEUS
TopK
Number
NucleusThreshold
MaxLength
Locale
TokenType
Architecture
BeamSize
Unexpected CVNLP key: 
CVNLPLanguageModelWithState
InvalidProbabilityError: expected 
to be in the interval [0, 1].
output_dim
image_encoder
image_size
text_encoder
embed_net_file
main_net_file
embed_output_names
main_input_ids_name
main_input_ids_mask_name
main_output_name
lowercase
bos:eos
text_ids
text_ids_mask
type must be boolean, but is 
CVNLPCaptionTrackPerformance
CVNLPCaptionModelPath
CVNLPCaptionLanguage
CVNLPCaptions
CVNLPGeneratedCaption
CVNLPGeneratedCaptionScore
CVNLPGeneratedCaptionConfidenceLow
CVNLPImageClassificationIdentifiers
CVNLPCaptionModelType
CVNLPCaptionModelLSTM
CVNLPCaptionModelTransformer
CVNLPCaptionEnableGenderedCaptions
CVNLPCaptionFilterTokens
v32@?0@"NSString"8d16^B24
Mismatching vocab file and output vocab sizes
vocab_reverse.json
Decode
DecodeBlock
OneStep
q24@?0@"CVNLPDecodingLexicon"8@"CVNLPDecodingLexicon"16
priority == %lu
v24@?0@"CVNLPDecodingLexicon"8^B16
%@(<%@> from <%@>-<%@> %@)
sensitive
non-sensitive
CVNLPCommSafetyTextClassification requires keyed coding
CVNLPStartDate
CVNLPEndDate
CVNLPResult
%@(%@ %@ > %.2g)
operating_thresholds.json
model_thresholds
threshold
TextClassifier%@.mlmodelc
CVNLPCommSafetyTextAnalyzer item provider error: %@
v32@?0@"NSArray"8@"NSError"16^B24
decoder_opt_pro.espresso.net
mean_feats_placeholder
p_att_feats_placeholder
in_word_id
lstm/att_state_feed
lstm/lang_state_feed
word_id
lang_prob
new_att_state
new_lang_state
lstmAttnStateData
lstmLangStateData
Failed to create espresso context.
Failed to create espresso plan.
Setting plan priorty
Loading espresso Network
Sharing intermediate buffer
Declaring network output
Setting preprocessing params
Building espresso plan
Executing plan
Model has no pre-declared outputs.
Model must have exactly one pre-declared output.
Binding output buffer
Error encountered during: 
 [espresso error: 
unordered_map::at: key not found
PixelBufferTransfer operation [
] failed. Status = 
Image Transfer
Session Creation
PixelBufferTransfer internal inconsistency: null session.
Unsupported espresso type encountered.
Unpacking tensor shape
Failed to allocate aligned memory.
Unknown data type
Unknown data type.
Binding buffer
Unsupported tensor rank: 
Encountered an error during: %s
 -> Espresso Error: %s
Invalid dimensions requested for CVPixelBuffer creation.
Failed to create CVPixelBuffer. Status = 
Failed to lock pixel buffer.
Failed to unlock pixel buffer.
Unsupported CVPixelBuffer type: 
Null CVPixelBuffer encountered.
Binding CVPixelBuffer
Failed to get CVPixelBuffer's data. Ensure the buffer was locked.
precompiled_charsmap is empty.
Normalizer model is not available.
length < 0
norm_to_org and normalized are inconsistent
Trie blob is broken.
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/src/util.h
'result' Must be non NULL
Cannot open 
input ifstream is null
Model file is broken
Model is not initialized.
Normalizer is not initialized.
output container is null
Empty piece is not allowed.
consumed index is out-of-range.
original index is out-of-range.
all normalized characters are not consumed.
output proto is null
NBestEncode returns empty result
nbest_size must be 0 < nbest_size <= 512 or nbest_size < 0.
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/src/sentencepiece_processor.cc
LOG(
ERROR
Returns default value 
</s>
Unknown extra_option type
reverse
option 
 is not available.
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/arenastring.h
CHECK failed: initial_value != NULL: 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/repeated_field.h
CHECK failed: (index) >= (0): 
CHECK failed: (index) < (current_size_): 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/src/model_factory.cc
Unknown model_type: 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/src/char_model.cc
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/src/unigram_model.cc
best_node
nbest_size >= 1. Returns empty result.
Too big agenda. shrinking
(num_nodes) < (trie_results.size())
model file is already precompiled.
No pieces are loaded.
Cannot build double-array.
No entry is found in the trie.
precompiled_trie is empty.
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/third_party/darts_clone/darts.h:776: exception: failed to resize pool: std::bad_alloc
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/third_party/darts_clone/darts.h:1214: exception: failed to insert key: negative value
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/third_party/darts_clone/darts.h:1216: exception: failed to insert key: zero-length key
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/third_party/darts_clone/darts.h:1230: exception: failed to insert key: invalid null character
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/third_party/darts_clone/darts.h:1235: exception: failed to insert key: wrong key order
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/third_party/darts_clone/darts.h:915: exception: failed to build rank index: std::bad_alloc
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/third_party/darts_clone/darts.h:1453: exception: failed to modify unit: too large offset
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/third_party/darts_clone/darts.h:1799: exception: failed to build double-array: invalid null character
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/third_party/darts_clone/darts.h:1801: exception: failed to build double-array: negative value
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/third_party/darts_clone/darts.h:1816: exception: failed to build double-array: wrong key order
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/src/sentencepiece_model.pb.cc
CHECK failed: !model_prefix_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
CHECK failed: !input_format_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
CHECK failed: (&from) != (this): 
sentencepiece.TrainerSpec
CHECK failed: !name_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
CHECK failed: !precompiled_charsmap_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
sentencepiece.NormalizerSpec
CHECK failed: !piece_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
sentencepiece.ModelProto.SentencePiece
CHECK failed: !precompiled_trie_.IsDefault( &::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
CHECK failed: trainer_spec_ != NULL: 
CHECK failed: normalizer_spec_ != NULL: 
sentencepiece.ModelProto
CHECK failed: (n) >= (0): 
down_cast
casts.h
f == NULL || dynamic_cast<To>(f) != NULL
CHECK failed: (&other) != (this): 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/src/model_interface.cc
User defined symbol is not supported.
 is already defined.
!result.empty()
Cancelled
Unknown
Invalid argument
Deadline exceeded
Not found
Already exists
Permission denied
Unauthenticated
Resource exhausted
Failed precondition
Aborted
Out of range
Unimplemented
Internal
Unavailable
Data loss
Unkown code:
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/src/sentencepiece.pb.cc
CHECK failed: !surface_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
sentencepiece.SentencePieceText.SentencePiece
CHECK failed: !text_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
sentencepiece.SentencePieceText
sentencepiece.NBestSentencePieceText
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/src/bpe_model.cc
Invalid character length.
(index) >= (0)
(index) < (static_cast<int>(symbols.size()))
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/src/model_interface.h
Not implemented.
(cannot determine missing fields for lite message)
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/message_lite.cc
CHECK failed: !coded_out.HadError(): 
parse
Can't 
 message of type "
" because it is missing required fields: 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/wire_format_lite.cc
CHECK failed: (value.size()) <= (kint32max): 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/io/coded_stream.cc
A protocol message was rejected because it was too big (more than 
 bytes).  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
CHECK failed: (buffer_size) >= (0): 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/generated_message_util.cc
Not implemented field number 
 with type 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/stubs/common.cc
This program requires version 
 of the Protocol Buffer runtime library, but the installed version is 
.  Please update your library.  If you compiled the program yourself, make sure that your headers are from the same version of Protocol Buffers as your link-time library.  (Version verification failed in "
This program was compiled against version 
 of the Protocol Buffer runtime library, which is not compatible with the installed version (
).  Contact the program author for an update.  If you compiled the program yourself, make sure that your headers are from the same version of Protocol Buffers as your link-time library.  (Version verification failed in "
%d.%d.%d
INFO
WARNING
FATAL
[libprotobuf %s %s:%d] %s
pthread_mutex_lock: 
pthread_mutex_unlock: 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/io/zero_copy_stream.cc
This ZeroCopyOutputStream doesn't support aliasing. Reaching here usually means a ZeroCopyOutputStream implementation bug.
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/io/zero_copy_stream_impl_lite.cc
CHECK failed: (last_returned_size_) > (0): 
BackUp() can only be called after a successful Next().
CHECK failed: (count) <= (last_returned_size_): 
CHECK failed: (count) >= (0): 
CHECK failed: target_ != NULL: 
Cannot allocate buffer larger than kint32max for 
StringOutputStream.
CHECK failed: (count) <= (target_->size()): 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/extension_set.cc
Non-primitive types can't be packed.
can't reach here.
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/arena.cc
CHECK failed: (min_bytes) <= (std::numeric_limits<size_t>::max() - kHeaderSize): 
N5cvnlp4util6InFileE
N5cvnlp4util4PathE
NSt3__110__function6__funcIZN5cvnlp4util6MatrixIfE3rowEmEUlmmE_NS_9allocatorIS6_EEFmmmEEE
NSt3__110__function6__baseIFmmmEEE
_N5cvnlp4util8KeyErrorE
N5cvnlp4util20ExceptionWithMessageE
N5cvnlp4util17FileNotFoundErrorE
NSt3__14__fs10filesystem4pathE
N2ik6TensorE
N5cvnlp6vidcap27ExcludeTokenIDsLogitsWarperE
N5cvnlp6vidcap12LogitsWarperE
N8nlohmann6detail11other_errorE
N8nlohmann6detail9exceptionE
N8nlohmann6detail22input_adapter_protocolE
NSt3__117bad_function_callE
N8nlohmann6detail16invalid_iteratorE
NSt3__120__shared_ptr_emplaceIN5cvnlp23SentencePieceVocabularyENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_pointerIPN5cvnlp6vidcap17BeamSearchOptionsENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIN5cvnlp6vidcap17BeamSearchOptionsEEE
ZN5cvnlp4util6MatrixIfE3rowEmEUlmmE_
NSt3__111__end_stateIcEE
NSt3__16__nodeIcEE
NSt3__120__shared_ptr_pointerIPNS_13__empty_stateIcEENS_10shared_ptrIS2_E27__shared_ptr_default_deleteIS2_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrINS_13__empty_stateIcEEE27__shared_ptr_default_deleteIS2_S2_EE
NSt3__113__empty_stateIcEE
NSt3__116__owns_one_stateIcEE
NSt3__115__has_one_stateIcEE
NSt3__120__l_anchor_multilineIcEE
NSt3__120__r_anchor_multilineIcEE
NSt3__115__word_boundaryIcNS_12regex_traitsIcEEEE
NSt3__111__lookaheadIcNS_12regex_traitsIcEEEE
NSt3__123__match_any_but_newlineIcEE
NSt3__118__match_char_icaseIcNS_12regex_traitsIcEEEE
NSt3__120__match_char_collateIcNS_12regex_traitsIcEEEE
NSt3__112__match_charIcEE
NSt3__116__back_ref_icaseIcNS_12regex_traitsIcEEEE
NSt3__118__back_ref_collateIcNS_12regex_traitsIcEEEE
NSt3__110__back_refIcEE
NSt3__120__bracket_expressionIcNS_12regex_traitsIcEEEE
NSt3__128__begin_marked_subexpressionIcEE
NSt3__126__end_marked_subexpressionIcEE
NSt3__16__loopIcEE
NSt3__117__owns_two_statesIcEE
NSt3__117__repeat_one_loopIcEE
NSt3__111__alternateIcEE
NSt3__121__empty_non_own_stateIcEE
NSt3__111__match_anyIcEE
<N5cvnlp4util15InvalidArgumentE
N5cvnlp4util12RuntimeErrorE
NSt3__120__shared_ptr_emplaceIN5cvnlp4clip9CLIPModelENS_9allocatorIS3_EEEE
;N5cvnlp13GreedySamplerE
N5cvnlp20LanguageModelSamplerE
N5cvnlp11TopKSamplerE
N5cvnlp11BeamSamplerE
N5cvnlp14NucleusSamplerE
N5cvnlp20OutOfVocabularyErrorE
N5cvnlp19TokenListVocabularyE
N5cvnlp18AbstractVocabularyE
N5cvnlp23SentencePieceVocabularyE
N5boost16exception_detail10clone_implINS0_19error_info_injectorISt12out_of_rangeEEEE
N5boost16exception_detail19error_info_injectorISt12out_of_rangeEE
N5boost9exceptionE
N5boost16exception_detail10clone_baseE
N5cvnlp18CharacterTokenizerE
N5cvnlp17AbstractTokenizerE
N5cvnlp19WhitespaceTokenizerE
vanilla_attention
 ANSt3__120__shared_ptr_emplaceIN5cvnlp6vidcap20VideoCaptioningModelENS_9allocatorIS3_EEEE
N5cvnlp4util12UnknownErrorE
CN5cvnlp23InvalidProbabilityErrorE
N5cvnlp4util4FileE
NSt3__113basic_fstreamIcNS_11char_traitsIcEEEE
NSt3__120__shared_ptr_emplaceIN8nlohmann6detail20input_stream_adapterENS_9allocatorIS3_EEEE
N8nlohmann6detail20input_stream_adapterE
N8nlohmann6detail12out_of_rangeE
N8nlohmann6detail10type_errorE
N8nlohmann6detail11parse_errorE
N5cvnlp4util9DirectoryE
N2ik14InferenceErrorE
N2ik11EspressoNetE
N2ik14EspressoTensorE
NSt3__120__shared_ptr_pointerIPhNS_10shared_ptrIA_hE27__shared_ptr_default_deleteIS3_hEENS_9allocatorIhEEEE
NSt3__110shared_ptrIA_hE27__shared_ptr_default_deleteIS1_hEE
NSt3__120__shared_ptr_emplaceIN2ik21EspressoBufferStorageENS_9allocatorIS2_EEEE
N2ik21EspressoBufferStorageE
N2ik13TensorStorageE
N2ik17PixelBufferTensorE
NSt3__120__shared_ptr_emplaceIN2ik18PixelBufferStorageENS_9allocatorIS2_EEEE
N2ik18PixelBufferStorageE
N13sentencepiece10normalizer10NormalizerE
N5Darts15DoubleArrayImplIvvivEE
N13sentencepiece22SentencePieceProcessorE
N13sentencepiece4word5ModelE
N13sentencepiece9character5ModelE
N13sentencepiece7unigram7LatticeE
N13sentencepiece7unigram9ModelBaseE
N13sentencepiece7unigram5ModelE
N5Darts7Details9ExceptionE
@?N13sentencepiece11TrainerSpecE
N13sentencepiece14NormalizerSpecE
N13sentencepiece24ModelProto_SentencePieceE
N13sentencepiece10ModelProtoE
NSt3__112basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEE
NSt3__121__basic_string_commonILb1EEE
N13sentencepiece14ModelInterfaceE
N13sentencepiece31SentencePieceText_SentencePieceE
N13sentencepiece17SentencePieceTextE
N13sentencepiece22NBestSentencePieceTextE
N6google8protobuf8internal29InternalMetadataWithArenaBaseINSt3__112basic_stringIcNS3_11char_traitsIcEENS3_9allocatorIcEEEENS1_29InternalMetadataWithArenaLiteEE9ContainerE
N13sentencepiece3bpe5ModelE
N6google8protobuf11MessageLiteE
N6google8protobuf8internal12FieldSkipperE
N6google8protobuf8internal29CodedOutputStreamFieldSkipperE
N6google8protobuf14FatalExceptionE
N6google8protobuf7ClosureE
N6google8protobuf8internal16FunctionClosure0E
N6google8protobuf2io20ZeroCopyOutputStreamE
N6google8protobuf2io17ArrayOutputStreamE
N6google8protobuf2io18StringOutputStreamE
N6google8protobuf8internal15ExtensionFinderE
N6google8protobuf8internal24GeneratedExtensionFinderE
N6google8protobuf13RepeatedFieldIiEE
N6google8protobuf13RepeatedFieldIxEE
N6google8protobuf13RepeatedFieldIjEE
N6google8protobuf13RepeatedFieldIyEE
N6google8protobuf13RepeatedFieldIfEE
N6google8protobuf13RepeatedFieldIdEE
N6google8protobuf13RepeatedFieldIbEE
N6google8protobuf16RepeatedPtrFieldINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEEE
N6google8protobuf8internal20RepeatedPtrFieldBaseE
N6google8protobuf16RepeatedPtrFieldINS0_11MessageLiteEEE
Attempting to parse ModelSpec from JSON path: %s
Performing greedy search, since requested topKPerStep is 1.
Setting Espresso storage type to FLOAT32 since CPU runtime requested.
Setting Espresso storage type to FLOAT16.
sampleTokenIDs(%s, %zu)
EOS encountered in greedySample. Terminating early.
No context provided. Pushing bosID as first tokenID for beam search.
Skipping generation on sample that ends with EOS: %s
All beams contain finished sequences. Exiting beam search loop early after %lu steps
Setting Espresso engine to CPU since ANE is not available and we are investigating issues when running on pre-ANE devices with MPS.
Unknown error encountered during initWithOptions.
Using user-provided CLIP model to encode image instead of Vision.
Unknown error encountered during encodeImage.
Unknown Error encountered during encodeText.
Could not load the contents of file at %@
Could not load the contents of file at %@ as dictionary
Error adding caption rules-file line: %@. Error: %@
Expected token=%s to get converted into single TokenID, but got %zu tokenIDs: %s. Returning UNK TokenID as fallback.
[CVNLPTokenIDConverter] Failed to load token id resources: %s
Input buffer and pixel buffer are both nil
Video Pixel Buffers are empty
Unexpected tokenNormalizedScore issue? got %.8f from tokenScore = %.2f, characterCount = %ld
Default ivs model files not found.
ANE-specific ivs model files not found. Falling back to the default model.
Failed to load encoder network for engine: %d, espresso error: %s
Error during espresso execution: %s
Error during operating point retrieval: %s
Unknown error encountered during initWithOptions. See NSError object for more details.
Received unsupported CFType for locale.
Received unsupported model format. Could be either Montreal or Espresso
Creation options does not contain all required keys.
Unable to determine model locale from options=%@
Locale not supported: %s
Model directory does not exist: %s
Expected output sequence to have dimensions (vocab=%ld, time=%ld), but got (vocab=%ld, time=%ld)
Invalid sampling method: "%s"
Tokenized query=%s into %zu tokens.
CLIP image encoder model file not found!
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:o:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:o:path:/System/Library/Frameworks/Vision.framework/Vision
CVNLPTextDecodingToken
CVNLPCaptionSensitiveImageParameters
CVNLPInformationStream
CVNLPLanguageResourceBundle
CVNLPCaptionEncoderLSTM
CVNLPCLIPEmbedding
CVNLPCLIPModel
CVNLPCaptionEncoder
CVNLPCommSafetyTextItem
NSCopying
NSSecureCoding
NSCoding
CVNLPCommSafetyTextProvider
CVNLPCommSafetyCDTextProvider
CVNLPActivationMatrix
CVNLPLexiconCursors
CVNLPCaptionEncoderTransformer
CVNLPCaptionPostProcessingHandler
CVNLPCaptionModelBase
BundleHelper
CVNLPTextDecodingConfiguration
CVNLPTextDecodingBeamSearchConfiguration
CVNLPTextDecoder
CVNLPCaptionRuntimeParameters
CVNLPTextDecodingResultCandidate
CVNLPTextDecodingResult
CVNLPDecodingLanguageModel
CVNLPTokenIDConverter
CVNLPModelBase
CVNLPPerformanceResult
CVNLPPerformance
CVNLPCommSafetyHandler
CVNLPCTCTextDecodingPath
CVNLPCaptionDecoder
CVNLPTextDecodingPath
CVNLPCaptionDecoderBlock
CVNLPCommSafetyImageAnalyzer
CVNLPCTCBeamState
CVNLPVideoCaptioningModel
CVNLPCaption
CVNLPCaptionRuntimeExcludeGenderTrigger
CVNLPVisionRequestHandler
CVNLPCTCTextDecoder
CVNLPTextDecoding
NSObject
CVNLPCaptionRuntimeReplacements
3@!2
CVNLPCaptionDecoderTransformer
CVNLPDecodingLexicon
CVNLPDecodingLexicons
CVNLPCommSafetyTextClassification
CVNLPCommSafetyTextAnalyzerModel
CVNLPCommSafetyTextAnalyzer
CVNLPCaptionDecoderLSTM
CVNLPTextDecodingContext
init
initWithString:score:alignmentScore:activationRange:terminatingCharacter:
stringWithFormat:
initWithString:score:activationRange:terminatingCharacter:
initWithString:score:activationRange:hasPrecedingSpace:
fullString
string
hasPrecedingSpace
terminatingCharacter
score
alignmentScore
activationRange
.cxx_destruct
_hasPrecedingSpace
_string
_terminatingCharacter
_score
_alignmentScore
_activationRange
T@"NSString",R,C,N,V_string
TB,R,N,V_hasPrecedingSpace
T@"NSString",R,C,N,V_terminatingCharacter
T@"NSNumber",R,C,N,V_score
T@"NSNumber",R,C,N,V_alignmentScore
T{_NSRange=QQ},R,N,V_activationRange
T@"NSString",R,C,N
raise:format:
dictionaryWithObjects:forKeys:count:
isEqualToString:
objectForKeyedSubscript:
errorWithDomain:code:userInfo:
boolValue
defaultManager
fileExistsAtPath:
unsignedIntegerValue
floatValue
path
bytes
dictionary
numberWithUnsignedLong:
setObject:forKeyedSubscript:
array
numberWithFloat:
addObject:
copy
addObjectsFromArray:
initWithVisionIdentifier:minConfidence:commonBlockingTokens:categoryBlockingTokens:categoryBlockingTokensAnnex:
visionIdentifier
minConfidence
blockingTokens
_visionIdentifier
_minConfidence
_blockingTokens
T@"NSString",R,N,V_visionIdentifier
Td,R,N,V_minConfidence
T@"NSArray",R,N,V_blockingTokens
defaultLowerBoundLogProbability
initWithDecodingWeight:lowerBoundLogProbability:
doubleValue
numberWithDouble:
defaultDecodingWeight
initWithDecodingWeight:
decodingWeightValue
lowerBoundLogProbabilityValue
decodingWeight
lowerBoundLogProbability
_decodingWeightValue
_lowerBoundLogProbabilityValue
_decodingWeight
_lowerBoundLogProbability
T@"NSNumber",R,N,V_decodingWeight
T@"NSNumber",R,N,V_lowerBoundLogProbability
packagedLexiconCursorsUsingTextDecodingContext:
packagedLexiconRootCursors
initWithLexicons:characterLanguageModel:wordLanguageModel:
packagedLexiconCursorsUsingContext:
lexicons
characterLanguageModel
wordLanguageModel
_lexicons
_characterLanguageModel
_wordLanguageModel
T@"CVNLPDecodingLexicons",R,N,V_lexicons
T@"CVNLPDecodingLanguageModel",R,N,V_characterLanguageModel
T@"CVNLPDecodingLanguageModel",R,N,V_wordLanguageModel
initWithOptions:runTimeParams:
URLByAppendingPathComponent:
UTF8String
dealloc
_run:meanFeatures:attnFeatures:projectedAttnFeatures:
arrayWithObjects:count:
_copy_data_from_blob:to:
dataWithBytes:length:
data
computeCaptionForImage:outputs:
encoderPlan
encoderCtx
encoderNet
meanFeatsBlob
attFeatsBlob
pAttFeatsBlob
meanFeaturesPresent
initWithData:
_data
T@"NSData",R,N,V_data
options
model
setRevision:error:
initWithCVPixelBuffer:options:
performRequests:error:
results
firstObject
sceneprints
descriptorData
initWithOptions:error:
encodeImage:error:
encodeText:error:
encodeTextAverage:error:
modelName
.cxx_construct
_modelName
_options
_model
T{shared_ptr<cvnlp::clip::CLIPModel>=^{CLIPModel}^{__shared_weak_count}},R,N,V_model
T@"NSString",R,N,V_modelName
T@"NSDictionary",R,N,V_options
pathForResource:ofType:
createBundle
countByEnumeratingWithState:objects:count:
exceptionWithName:reason:userInfo:
_blob_size:
computeCaptionForPixelBuffer:outputs:
_fill_blob_data:with:
data_dim
direction
description
conversationIdentifier
date
text
hash
isEqual:
allowsKeyedCoding
encodeObject:forKey:
encodeInteger:forKey:
decodeObjectOfClass:forKey:
decodeIntegerForKey:
initWithConversationIdentifier:date:direction:text:
supportsSecureCoding
copyWithZone:
encodeWithCoder:
initWithCoder:
TB,R
_conversationIdentifier
_date
_text
_direction
T@"NSString",R,C,N,V_conversationIdentifier
T@"NSDate",R,C,N,V_date
Tq,R,N,V_direction
T@"NSString",R,C,N,V_text
defaultTextProvider
setDefaultTextProvider:
T@"CVNLPCommSafetyTextProvider",&
provideTextItemsWithConversationIdentifier:startDate:endDate:progressHandler:
appIntentsStream
arrayWithObjects:
setEventStreams:
startDateSortDescriptorAscending:
setSortDescriptors:
setExecuteConcurrently:
intentClass
predicateForObjectsWithMetadataKey:andStringValue:
intentsSourceID
predicateForEventsWithSourceID:bundleID:groupIDs:
predicateForEventsWithSourceID:bundleID:
distantPast
distantFuture
predicateForEventsWithEndInDateRangeFrom:to:
andPredicateWithSubpredicates:
setPredicate:
knowledgeStoreWithDirectReadOnlyAccess
queryForConversationIdentifier:startDate:endDate:
setLimit:
setOffset:
executeQuery:error:
interaction
intent
content
containsString:
endDate
count
initWithBuffer:domainType:characterObservations:blankIndex:pruningPolicy:
shape
objectAtIndexedSubscript:
integerValue
strides
dataType
initWithMultiArray:domainType:characterObservations:blankIndex:pruningPolicy:
_cachedTimesample
set_cachedTimesample:
_valueForObservationIndex:timestep:
dataPointer
characterIndexForObservationIndex:timestep:
blankIndexForTimestep:
probabilityForObservationIndex:timestep:
logProbabilityForObservationIndex:timestep:
_sortNonBlankCandidatesForTimestep:
_enumerateNonBlankCandidatesInTimestep:block:
_candidateSymbolAtIndex:forTimestep:outputScore:
topCandidateForTimestep:outputLogProbability:outputIndex:
logProbabilityForBlankAtTimestep:
observationCount
appendFormat:
initWithBuffer:indexBuffer:domainType:characterObservations:blankIndex:pruningPolicy:
initWithMultiArray:characterObservations:blankIndex:pruningPolicy:
initWithMultiArray:indexArray:domainType:characterObservations:blankIndex:pruningPolicy:
timestepCount
probabilityForBlankAtTimestep:
enumerateNonBlankCandidatesInTimestep:block:
topCandidateForTimestep:outputLogProbability:
topCandidateForTimestep:outputProbability:outputIndex:
debugDescription
characterObservations
setCharacterObservations:
blankIndex
setBlankIndex:
domainType
_espressoBuffer
set_espressoBuffer:
_indexBuffer
set_indexBuffer:
_doubleScoreMatrix
set_doubleScoreMatrix:
_multiArray
set_multiArray:
_indexArray
set_indexArray:
_timestepCount
set_timestepCount:
_observationCount
set_observationCount:
_timeStride
set_timeStride:
_observationStride
set_observationStride:
_type
set_type:
_pruningPolicy
set_pruningPolicy:
_cachedPriorityQueueTimestep
set_cachedPriorityQueueTimestep:
_isDoubleDataType
set_isDoubleDataType:
_usingIndexes
set_usingIndexes:
_cachedBlankIndexTimestep
_cachedBlankIndex
__isDoubleDataType
__usingIndexes
_characterObservations
_blankIndex
_domainType
__doubleScoreMatrix
__multiArray
__indexArray
__timestepCount
__observationCount
__timeStride
__observationStride
__type
__cachedPriorityQueueTimestep
__cachedTimesample
__cachedBlankIndexTimestep
__cachedBlankIndex
__pruningPolicy
__espressoBuffer
__indexBuffer
T{?=^v^v[4Q][4Q]QQQQQQQQQQi},N,V__espressoBuffer
T{?=^v^v[4Q][4Q]QQQQQQQQQQi},N,V__indexBuffer
T^d,N,V__doubleScoreMatrix
T@"MLMultiArray",&,N,V__multiArray
T@"MLMultiArray",&,N,V__indexArray
Tq,N,V__timestepCount
Tq,N,V__observationCount
Tq,N,V__timeStride
Tq,N,V__observationStride
Tq,N,V__type
T{CVNLPTextDecodingPruningPolicy=qBfI},N,V__pruningPolicy
Tq,V__cachedPriorityQueueTimestep
T^v,V__cachedTimesample
TB,N,V__isDoubleDataType
TB,N,V__usingIndexes
Tq,R,N,V__cachedBlankIndexTimestep
Tq,R,N,V__cachedBlankIndex
T@"NSOrderedSet",&,N,V_characterObservations
Tq,N,V_blankIndex
Tq,R,N,V_domainType
initWithSortedCursors:
enumerateLexiconCursorsSortedByPriorityWithBlock:
_sortedCursors
perfResults
computeCaptionForImageImpl:outputs:
run:block:
dataWithBytesNoCopy:length:freeWhenDone:
computeCaptionForPixelBufferImpl:outputs:
computeCaptionForVideoPixelBufferImpl:outputs:
computeCaptionForVideoPixelBuffer:outputs:
encoderInputNames
characterSetWithCharactersInString:
_excludeGenderReplacements:genderOption:error:
_excludeGenderTriggers:genderOption:error:
_replacements:genderOption:
_checkForBlockingTokens:visionObservations:
_filterVisionObservations:
runtimeParameters
genderOption
stringWithSpaceAtEnds
excludeGenderReplacements
mutableCopy
replacementKey
replacementValue
length
replaceOccurrencesOfString:withString:options:range:
trimSet
stringByTrimmingCharactersInSet:
whitespaceCharacterSet
componentsSeparatedByCharactersInSet:
genderedTokens
indexOfObject:
excludeGenderTriggers
triggerTokens
strongToStrongObjectsMapTable
replacements
rangeOfString:
objectForKey:
replacementProb
setObject:forKey:
sensitiveImageParameters
identifier
confidence
_checkAboveThreshold:observationConfidence:difference:
_checkForBlockingTokens:blockingTokens:
initWithOptions:runtimeParameters:
postProcessCaptions:genderOption:error:
postProcessCaptions:visionObservations:
_trimSet
_runtimeParameters
T@"NSCharacterSet",R,V_trimSet
T@"CVNLPCaptionRuntimeParameters",R,W,V_runtimeParameters
initWithOptions:
runTimeParams
_runTimeParams
T@"CVNLPCaptionRuntimeParameters",R,N,V_runTimeParams
bundleForClass:
languageCode
defaultWhitespaceCommitActionBehavior
defaultCommitActionBehaviorForLocale:
defaultCharacterCommitActionBehavior
initWithCommitActionBehavior:
commitActionBlock
setCommitActionBlock:
_commitActionBlock
T@?,N,V_commitActionBlock
initWithCommitActionBehavior:scoringFunction:beamWidth:pathCount:shouldOptimizeAlignment:pruneProblematicMixedScriptWordPaths:shouldApplyWordLMToLastWord:
initWithCommitActionBehavior:scoringFunction:beamWidth:pathCount:shouldOptimizeAlignment:pruneProblematicMixedScriptWordPaths:
initWithCommitActionBehavior:scoringFunction:beamWidth:pathCount:shouldOptimizeAlignment:
initWithCommitActionBehavior:scoringFunction:beamWidth:pathCount:
initWithCommitActionBehavior:beamWidth:pathCount:shouldOptimizeAlignment:
initWithCommitActionBehavior:beamWidth:pathCount:shouldOptimizeAlignment:pruneProblematicMixedScriptWordPaths:
beamWidth
setBeamWidth:
pathCount
setPathCount:
shouldOptimizeAlignment
setShouldOptimizeAlignment:
pruneProblematicMixedScriptWordPaths
setPruneProblematicMixedScriptWordPaths:
shouldApplyWordLMToLastWord
setShouldApplyWordLMToLastWord:
scoringFunction
_shouldOptimizeAlignment
_pruneProblematicMixedScriptWordPaths
_shouldApplyWordLMToLastWord
_beamWidth
_pathCount
_scoringFunction
TQ,N,V_beamWidth
TQ,N,V_pathCount
TB,N,V_shouldOptimizeAlignment
TB,N,V_pruneProblematicMixedScriptWordPaths
TB,N,V_shouldApplyWordLMToLastWord
T@?,R,N,V_scoringFunction
fileURLWithPath:
dataWithContentsOfFile:
JSONObjectWithData:options:error:
initWithContentsOfURL:error:
stringWithUTF8String:
rangeOfFirstMatchInString:options:range:
numberWithInteger:
initWithLanguageResourceBundle:
languageResourceBundle
_languageResourceBundle
T@"CVNLPLanguageResourceBundle",R,N,V_languageResourceBundle
_loadRuntimeParameters:
allKeys
initWithDictionary:
whitespaceAndNewlineCharacterSet
regularExpressionWithPattern:options:error:
captionModelMinimumConfidence
setCaptionModelMinimumConfidence:
captionModelLengthNormalizationFactor
setCaptionModelLengthNormalizationFactor:
excludeGenderStrategy
setExcludeGenderStrategy:
classifierRevisions
setClassifierRevisions:
setSensitiveImageParameters:
setReplacements:
setGenderedTokens:
blackListRules
setBlackListRules:
setExcludeGenderReplacements:
setExcludeGenderTriggers:
setGenderOption:
_excludeGenderStrategy
_genderOption
_captionModelMinimumConfidence
_captionModelLengthNormalizationFactor
_classifierRevisions
_sensitiveImageParameters
_replacements
_genderedTokens
_blackListRules
_excludeGenderReplacements
_excludeGenderTriggers
Td,N,V_captionModelMinimumConfidence
Td,N,V_captionModelLengthNormalizationFactor
Ti,N,V_excludeGenderStrategy
T@"NSDictionary",&,N,V_classifierRevisions
T@"NSDictionary",&,N,V_sensitiveImageParameters
T@"NSArray",&,N,V_replacements
T@"NSArray",&,N,V_genderedTokens
T@"NSArray",&,N,V_blackListRules
T@"NSArray",&,N,V_excludeGenderReplacements
T@"NSArray",&,N,V_excludeGenderTriggers
Ti,N,V_genderOption
initWithKey:value:prob:genderOption:
appendString:
initWithTokens:score:activationScore:
tokens
setScore:
activationScore
setActivationScore:
_tokens
_activationScore
T@"NSArray",R,N,V_tokens
Td,V_score
Td,V_activationScore
candidates
initWithCandidates:
_candidates
T@"NSArray",R,N,V_candidates
_initWithLanguageModel:locale:decodingWeight:lowerBoundLogProbability:type:
initWithLanguageModel:locale:
localeIdentifier
lastPathComponent
stringByDeletingPathExtension
stringByDeletingLastPathComponent
numberWithInt:
_decodingLanguageModelForLocale:modelType:decodingWeight:lowerBoundLogProbability:type:
requiredContextLengthForStringLength:
stringByAppendingString:
objectAtIndex:
rangeValue
maximumLengthOfBytesUsingEncoding:
getBytes:maxLength:usedLength:encoding:options:range:remainingRange:
initWithBytes:length:encoding:
_normalizedLMTokenIDForWord:withTokenID:sourceLanguageModel:outScore:
rangeOfString:options:range:
valueWithRange:
languageModel
lowercaseString
decodingLMLanguageModelForLocale:modelType:decodingWeight:
decodingCVNLPLanguageModelForLocale:modelType:decodingWeight:
initWithLMLanguageModel:locale:decodingWeight:
initWithLMLanguageModel:locale:decodingWeight:lowerBoundLogProbability:
initWithCVNLPLanguageModel:locale:decodingWeight:
initWithCVNLPLanguageModel:locale:decodingWeight:lowerBoundLogProbability:
initWithLanguageModel:
lmSPIType
characterTokenIDsForString:
wordTokenIDsForString:outTokenRanges:
locale
_lmSPIType
_tokenizer
_locale
_languageModel
T@"NSLocale",R,N,V_locale
T^v,R,N,V_languageModel
rangeOfCharacterFromSet:
lowercaseLetterCharacterSet
uppercaseLetterCharacterSet
lengthOfBytesUsingEncoding:
characterAtIndex:
punctuationCharacterSet
enumerateSubstringsInRange:options:usingBlock:
dataUsingEncoding:
stringWithCharacters:length:
initWithResource:andTokenType:
enumerateTokenIDsForText:withBlock:
bosTokenID
eosTokenID
unkTokenID
_vocabTokenizer
_bosTokenID
_eosTokenID
_unkTokenID
TI,R,V_bosTokenID
TI,R,V_eosTokenID
TI,R,V_unkTokenID
_copy_data_from_blob:toPtr:
_copy_data_to_blob:to:
_copy_data_to_blob:toBuffer:
_copy_data_to_blob_repeated:to:
performanceResults
_perfResults
T@"CVNLPPerformance",R,N,V_perfResults
name
initWithName:
dict
maxpeak
peakdelta
recentpeak
current
cpuTime
cpuInstructions
timeInterval
_name
T@"NSString",R,N,V_name
computePerf
processInfo
processIdentifier
timeIntervalSinceDate:
_computePerf
_results
TB,R,N,V_computePerf
T@"NSMutableDictionary",R,N,V_results
computeCaptionForImageWithInputs:genderOption:
code
classifyImage:
addEntriesFromDictionary:
resourcePath
fileURLWithPathComponents:
initWithModelURL:options:error:
clientQueue
imageAnalyzer
classifyImage:error:
generateClassificationScoresForImage:error:
classifyPixelBuffer:error:
generateClassificationScoresForPixelBuffer:error:
getOperatingPointDataForClassName:modelURL:error:
textAnalyzer
processText:inConversationWithIdentifier:date:error:
processConversationsWithStartDate:endDate:previousClassifications:progressHandler:completionHandler:
classifyPixelBuffer:startDate:endDate:stagedText:inConversationWithIdentifier:error:
getOperatingPointDataForClassName:error:
classifyPixelBuffer:stagedText:inConversationWithIdentifier:error:
performanceStatistics
_clientQueue
_imageAnalyzer
_textAnalyzer
T@"NSObject<OS_dispatch_queue>",R,V_clientQueue
T@"CVNLPCommSafetyImageAnalyzer",R,V_imageAnalyzer
T@"CVNLPCommSafetyTextAnalyzer",R,V_textAnalyzer
T@"NSDictionary",R,V_options
modelLogProbability
characterCount
substringWithRange:
_currentTokenStringLength
lastTokenBoundaryLogProbability
updateLastTokenWithMaxActivation:totalLogProbability:tokenBoundaryLogProbability:
commitTokenAtTimestep:currentSymbolLogProbability:commitAction:string:stemmingFromPath:
arrayWithCapacity:
scoreForTokenIndex:
arrayWithArray:
normalizedTotalLogProbability
blankLogProbability
nonBlankLogProbability
wordLanguageModelLogProbability
historyLexiconLogProbability
activeWordLexiconLogProbability
characterLanguageModelLogProbability
setLastTokenBoundaryLogProbability:
initWithLanguageResourceBundle:scoringFunction:initialCharacterLMState:characterTokenIDs:wordTokenIDs:optimizingAlignment:hasContext:
setBlankLogProbability:
setCharacterLanguageModelLogProbability:
setHistoryLexiconLogProbability:
setActiveWordLexiconLogProbability:
setWordLanguageModelLogProbability:
setCharacterCount:
setPseudoSpaceCount:
cursors
setCursors:
applyWordLanguageModelProbabilityToPath:stemmedFromPath:isCommittingToken:
_updateCharacterLanguageModelLogProbabilityForString:stemmingFromPath:normalizedCodepoint:
_updateLexiconLogProbabilityForString:stemmingFromPath:
inputNormalizationFunction
_getQueue
_wordLanguageModelLogProbabilityForString:originalWordRanges:originalWordIDs:wordRanges:wordIDs:
letterCharacterSet
formUnionWithCharacterSet:
invertedSet
rangeOfCharacterFromSet:options:range:
setCharacterLMState:
pseudoSpaceCount
tokenCount
lexiconScore
hasProblematicMixedScriptWords
normalizedActivationLogProbability
latestExpandedSymbolIncludingPseudospace
latestExpandedSymbol
hasExpanded
tokensWithTimestep:isFinalTimestep:
compare:
merge:logProbCumulator:
childPathWithBlankLogProb:
pathByExtendingWithString:extendedPathString:blankLogProb:nonBlankLogProb:timestep:commitAction:symbolLogProb:
setNonBlankLogProbability:
languageResourceLogProbability
optimizingAlignment
characterLMState
_tokenString
_histWordTokenIDs
_beginningCurrentWord
_cumulativeTokenLogProbabilities
_tokenBoundaryLogProbabilities
_tokenStringSegmentationPositions
_tokenMaxActivations
_tokenCommitCharacterLengths
_hasContext
_normalizedTotalLogProbability
_latestExpandedSymbolIncludingPseudospace
_hasExpanded
_hasProblematicMixedScriptWords
_hasCalculatedHasProblematicMixedScriptWords
_lastCodeUnitType
_optimizingAlignment
_blankLogProbability
_nonBlankLogProbability
_historyLexiconLogProbability
_activeWordLexiconLogProbability
_languageResourceLogProbability
_cursors
_characterLMState
Td,V_blankLogProbability
Td,V_nonBlankLogProbability
Td,V_historyLexiconLogProbability
Td,V_activeWordLexiconLogProbability
Td,R
Td,R,V_languageResourceLogProbability
TB,R,V_optimizingAlignment
T@"CVNLPLexiconCursors",&,N,V_cursors
T^{CVNLPLanguageModelWithState=},N,V_characterLMState
T@"CVNLPLanguageResourceBundle",R,&,N,V_languageResourceBundle
T@"NSString",R,N
TB,R,N
defaultPathScoringFunctionForLanguageResourceBundle:pruneProblematicMixedScriptWordPaths:
defaultPathScoringFunctionPruneProblematicMixedScriptWordPaths:
defaultPathScoringFunctionForLanguageResourceBundle:
defaultPathScoringFunction
initWithCharacterLanguageModelLogProbability:wordLanguageModelLogProbability:lexiconScore:hasProblematicMixedScriptWords:string:
_modelLogProbability
_characterLanguageModelLogProbability
_wordLanguageModelLogProbability
_lexiconScore
_characterCount
_pseudoSpaceCount
_tokenCount
Td,R,N,V_modelLogProbability
Td,R,N,V_characterLanguageModelLogProbability
Td,R,N,V_wordLanguageModelLogProbability
Td,R,N,V_lexiconScore
TB,R,N,V_hasProblematicMixedScriptWords
Tq,R,N,V_characterCount
Tq,R,N,V_pseudoSpaceCount
Tq,R,N,V_tokenCount
T@"NSString",R,N,V_string
_loadNetwork:modelIndex:
decoderQueue
_runBlockWithCopyOutputBlock:
blockInput
metricString
decoderPlan
nextBlock
blockOutput
runBlockWithCopyInput:copyOutputBlock:
initWithOptions:modelIndex:runTimeParams:
buildNetworkForSequenceLength:imageFeatures:
copyInputState:
copyOutputState:
runBlockWithCopyInputBlock:copyOutputBlock:
modelIndex
setModelIndex:
setDecoderPlan:
decoderCtx
setDecoderCtx:
decoderNet
setDecoderNet:
attFeatsPlaceholderBlob
setAttFeatsPlaceholderBlob:
scaleInput
setScaleInput:
positionInput
setPositionInput:
maskInput
setMaskInput:
setBlockInput:
setBlockOutput:
stateOutputEspressoBuffers
setStateOutputEspressoBuffers:
stateInputEspressoBuffers
setStateInputEspressoBuffers:
stateInputEspressoBuffersShape
setStateInputEspressoBuffersShape:
setDecoderQueue:
setNextBlock:
setMetricString:
metricCopyString
setMetricCopyString:
decoderInputNames
setDecoderInputNames:
_modelIndex
_decoderPlan
_decoderCtx
_decoderQueue
_nextBlock
_metricString
_metricCopyString
_decoderNet
_stateOutputEspressoBuffers
_stateInputEspressoBuffers
_stateInputEspressoBuffersShape
_decoderInputNames
_attFeatsPlaceholderBlob
_scaleInput
_positionInput
_maskInput
_blockInput
_blockOutput
TQ,N,V_modelIndex
T^v,N,V_decoderPlan
T^v,N,V_decoderCtx
T{?=^vi},N,V_decoderNet
T{?=^v^v[4Q][4Q]QQQQQQQQQQi},N,V_attFeatsPlaceholderBlob
T{?=^v^v[4Q][4Q]QQQQQQQQQQi},N,V_scaleInput
T{?=^v^v[4Q][4Q]QQQQQQQQQQi},N,V_positionInput
T{?=^v^v[4Q][4Q]QQQQQQQQQQi},N,V_maskInput
T{?=^v^v[4Q][4Q]QQQQQQQQQQi},N,V_blockInput
T{?=^v^v[4Q][4Q]QQQQQQQQQQi},N,V_blockOutput
T{map<std::string, std::vector<float>, std::less<std::string>, std::allocator<std::pair<const std::string, std::vector<float>>>>={__tree<std::__value_type<std::string, std::vector<float>>, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<float>>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::vector<float>>>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::vector<float>>, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<float>>, std::less<std::string>, true>>=Q}}},N,V_stateOutputEspressoBuffers
T{map<std::string, std::vector<float>, std::less<std::string>, std::allocator<std::pair<const std::string, std::vector<float>>>>={__tree<std::__value_type<std::string, std::vector<float>>, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<float>>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::vector<float>>>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::vector<float>>, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<float>>, std::less<std::string>, true>>=Q}}},N,V_stateInputEspressoBuffers
T{map<std::string, std::vector<unsigned long>, std::less<std::string>, std::allocator<std::pair<const std::string, std::vector<unsigned long>>>>={__tree<std::__value_type<std::string, std::vector<unsigned long>>, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<unsigned long>>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::vector<unsigned long>>>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::vector<unsigned long>>, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<unsigned long>>, std::less<std::string>, true>>=Q}}},N,V_stateInputEspressoBuffersShape
T@"NSObject<OS_dispatch_queue>",&,N,V_decoderQueue
T@"CVNLPCaptionDecoderBlock",&,N,V_nextBlock
T@"NSString",&,N,V_metricString
T@"NSString",&,N,V_metricCopyString
T{vector<std::string, std::allocator<std::string>>=^v^v{__compressed_pair<std::string *, std::allocator<std::string>>=^v}},N,V_decoderInputNames
_checkIfOnANEDevice
contentsOfDirectoryAtPath:error:
predicateWithFormat:
filteredArrayUsingPredicate:
_readOperatingThresholdsDataUsingModelURL:error:
_extractThresholdForOTGXMain:
loadNetworkForURL:espressoEngine:storageType:deviceId:
_nameFromRevParts:
_createNameEncodingDict
valueForKey:
_createNameDecodingDict
_decodeName:
otgxMainThreshold
computeOutputForImage:error:
_processNetworkOutput:
_computeOutputForPixelBuffer:error:
acceptedOutputIndices
_encodeName:
otgxMainIndex
otgxRetrieveAllClasses
modelUrl
_espressoEngine
_espressoDeviceId
_espressoStorageType
leafProbabilities
_otgxRetrieveAllClasses
__espressoEngine
__espressoDeviceId
__espressoStorageType
_acceptedOutputIndices
_otgxMainThreshold
_otgxMainIndex
_modelUrl
T@"NSDictionary",R,V_acceptedOutputIndices
T@"NSNumber",R,V_otgxMainThreshold
TQ,R,V_otgxMainIndex
TB,R,V_otgxRetrieveAllClasses
T@"NSURL",R,V_modelUrl
Ti,R,V__espressoEngine
Ti,R,V__espressoDeviceId
Ti,R,V__espressoStorageType
enumeratePathsWithBlock:
dictionaryWithDictionary:
enumerateKeysAndObjectsUsingBlock:
keysSortedByValueUsingSelector:
addPath:
removeObjectForKey:
pathForString:
paths
sortedKeys
kBest:discarded:k:shouldUpdateLMState:
mergePathsWithTrailingWhitespaces
applyWordLanguageModelProbabilityToPaths
mutablePaths
setMutablePaths:
_mutablePaths
T@"NSMutableDictionary",&,N,V_mutablePaths
userInfo
initWithURL:options:
tracksWithMediaType:
nominalFrameRate
initWithAsset:
setRequestedTimeToleranceAfter:
setRequestedTimeToleranceBefore:
duration
copyCGImageAtTime:actualTime:error:
initWithCGImage:options:
bufferWithWidth:height:format:options:error:
initWithUTF8String:
generateCaption:error:
T{shared_ptr<cvnlp::vidcap::VideoCaptioningModel>=^{VideoCaptioningModel}^{__shared_weak_count}},R,N,V_model
intValue
_triggerTokens
T@"NSArray",R,V_triggerTokens
_nsfwRequest
_significantRequest
decodingResultWithConfiguration:withContext:
history
inactiveSubstring
subarrayWithRange:
greedyDecodingResultWithConfiguration:
initWithString:
removeLastObject
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
superclass
TQ,R
T#,R
T@"NSString",R,C
decodingResultForKBestPaths:withBeamWidth:
decodingResultForKBestPaths:withBeamWidth:context:
greedyDecodingResult
decodingResultForKBestPaths:withBeamWidth:context:optimizeAlignment:
activationMatrix
setActivationMatrix:
_activationMatrix
T@"CVNLPActivationMatrix",&,N,V_activationMatrix
_replacementKey
_replacementValue
_replacementProb
T@"NSString",R,N,V_replacementKey
T@"NSString",R,N,V_replacementValue
Td,R,N,V_replacementProb
T@"NSNumber",R,N,V_genderOption
_loadVocabFile:
_loadNetwork:options:runTimeParams:
_createBeamSearch:runTimeParams:
decoderBlocks
lastObject
numberWithUnsignedInteger:
computeCaptionForImageWithInputsImpl:genderOption:
maxCaptionLen
startID
decoderBatchSize
vocabSize
endID
vocab
componentsJoinedByString:
numberWithBool:
setStartID:
setEndID:
setDecoderBatchSize:
setMaxCaptionLen:
setVocabSize:
outputVocabSize
setOutputVocabSize:
setVocab:
setDecoderBlocks:
beamSize
setBeamSize:
beamSearch
setBeamSearch:
filterBeamSearch
setFilterBeamSearch:
_startID
_endID
_decoderBatchSize
_maxCaptionLen
_vocabSize
_outputVocabSize
_vocab
_decoderBlocks
_beamSize
_beamSearch
_filterBeamSearch
TQ,N,V_startID
TQ,N,V_endID
TQ,N,V_decoderBatchSize
TQ,N,V_maxCaptionLen
TQ,N,V_vocabSize
TQ,N,V_outputVocabSize
T@"NSDictionary",&,N,V_vocab
T@"NSArray",&,N,V_decoderBlocks
TQ,N,V_beamSize
T^{CVNLPBeamSearch=},N,V_beamSearch
T^{CVNLPBeamSearch=},N,V_filterBeamSearch
initWithLexicon:priority:
_createLexiconForLocale:
initWithLexicon:
decodingLexiconForLocale:
decodingLexiconForLocale:priority:
lexicon
priority
_rootCursor
_lexicon
_priority
__rootCursor
T^{_LXCursor=},R,N,V__rootCursor
Tr^{_LXLexicon=},R,N,V_lexicon
TQ,R,N,V_priority
initWithLexicons:decodingWeight:lowerBoundLogProbability:
initWithLexicons:decodingWeight:lowerBoundLogProbability:inputNormalizationFunction:
allObjects
sortedArrayUsingComparator:
setWithArray:
filteredSetUsingPredicate:
initWithLexicons:decodingWeight:
activeSubstring
enumerateLexiconsSortedByPriorityWithBlock:
initWithLexicons:
lexiconsForPriority:
_sortedLexicons
_inputNormalizationFunction
T^?,R,N,V_inputNormalizationFunction
startDate
result
initWithConversationIdentifier:startDate:endDate:result:
_startDate
_endDate
_result
T@"NSDate",R,C,N,V_startDate
T@"NSDate",R,C,N,V_endDate
Tq,R,N,V_result
predictedLabelHypothesesForString:maximumCount:
initWithModel:className:threshold:
detectSensitivityForString:
_className
_threshold
dataWithContentsOfURL:
modelWithContentsOfURL:error:
_classifyString:
processText:inConversationWithIdentifier:startDate:endDate:error:
classifyString:
dateByAddingTimeInterval:
arrayWithObject:
_classificationForTextItems:conversationIdentifier:
_classificationsForTextItems:previousClassifications:
initWithModelURL:options:
_models
packBeamID:tokenID:lstmAttnState:lstmLangState:softmax:
extractBeamID:tokenID:lstmAttnState:lstmLangState:fromFollowup:
meanFeatsPlaceholderBlob
pAttFeatsPlaceholderBlob
lstmAttStateFeedBlob
lstmLangStateFeedBlob
inWordIDBlob
wordIDBlob
langProbBlob
newAttStateBlob
newLangStateBlob
initWithHistory:activeRange:
initWithHistory:
activeRange
_history
_activeRange
T@"NSString",R,N,V_history
T{_NSRange=QQ},R,N,V_activeRange
@64@0:8@16@24@32{_NSRange=QQ}40@56
@56@0:8@16@24{_NSRange=QQ}32@48
@52@0:8@16@24{_NSRange=QQ}32B48
@16@0:8
B16@0:8
{_NSRange=QQ}16@0:8
v16@0:8
@"NSString"
@"NSNumber"
{_NSRange="location"Q"length"Q}
@56@0:8@16d24@32@40@48
d16@0:8
@"NSArray"
@24@0:8@16
@32@0:8@16@24
@40@0:8@16@24@32
@"CVNLPDecodingLexicons"
@"CVNLPDecodingLanguageModel"
v32@0:8^{vImage_Buffer=^vQQQ}16^@24
v48@0:8^{vImage_Buffer=^vQQQ}16^@24^@32^@40
{?="plan"^v"network_index"i}
{?="data"^v"reserved"^v"dim"[4Q]"stride"[4Q]"width"Q"height"Q"channels"Q"batch_number"Q"sequence_length"Q"stride_width"Q"stride_height"Q"stride_channels"Q"stride_batch_number"Q"stride_sequence_length"Q"storage_type"i}
@"NSData"
@32@0:8@16^@24
@32@0:8^{__CVBuffer=}16^@24
{shared_ptr<cvnlp::clip::CLIPModel>=^{CLIPModel}^{__shared_weak_count}}16@0:8
@"NSDictionary"
{shared_ptr<cvnlp::clip::CLIPModel>="__ptr_"^{CLIPModel}"__cntrl_"^{__shared_weak_count}}
v32@0:8^{__CVBuffer=}16^@24
Q184@0:8{?=^v^v[4Q][4Q]QQQQQQQQQQi}16
v188@0:8{?=^v^v[4Q][4Q]QQQQQQQQQQi}16f184
[4Q]
@24@0:8^{_NSZone=}16
v24@0:8@16
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
@48@0:8@16@24q32@40
Q16@0:8
B24@0:8@16
q16@0:8
@"NSDate"
v48@0:8@16@24@32@?40
@232@0:8{?=^v^v[4Q][4Q]QQQQQQQQQQi}16q184@192q200{CVNLPTextDecodingPruningPolicy=qBfI}208
@400@0:8{?=^v^v[4Q][4Q]QQQQQQQQQQi}16{?=^v^v[4Q][4Q]QQQQQQQQQQi}184q352@360q368{CVNLPTextDecodingPruningPolicy=qBfI}376
@72@0:8@16q24@32q40{CVNLPTextDecodingPruningPolicy=qBfI}48
@64@0:8@16@24q32{CVNLPTextDecodingPruningPolicy=qBfI}40
@80@0:8@16@24q32@40q48{CVNLPTextDecodingPruningPolicy=qBfI}56
d32@0:8q16q24
q24@0:8q16
d24@0:8q16
q32@0:8q16q24
v32@0:8q16@?24
@40@0:8q16q24^d32
v24@0:8q16
@32@0:8q16^d24
@40@0:8q16^d24^q32
{?=^v^v[4Q][4Q]QQQQQQQQQQi}16@0:8
v184@0:8{?=^v^v[4Q][4Q]QQQQQQQQQQi}16
^d16@0:8
v24@0:8^d16
{CVNLPTextDecodingPruningPolicy=qBfI}16@0:8
v40@0:8{CVNLPTextDecodingPruningPolicy=qBfI}16
^v16@0:8
v24@0:8^v16
v20@0:8B16
@"NSOrderedSet"
@"MLMultiArray"
{CVNLPTextDecodingPruningPolicy="strategy"q"shouldSort"B"threshold"f"maxNumberOfCandidates"I}
@24@0:8^v16
v24@0:8@?16
{vector<const _LXCursor *, std::allocator<const _LXCursor *>>="__begin_"^^{_LXCursor}"__end_"^^{_LXCursor}"__end_cap_"{__compressed_pair<const _LXCursor **, std::allocator<const _LXCursor *>>="__value_"^^{_LXCursor}}}
v32@0:8^v16^@24
{vector<std::string, std::allocator<std::string>>="__begin_"^v"__end_"^v"__end_cap_"{__compressed_pair<std::string *, std::allocator<std::string>>="__value_"^v}}
@36@0:8@16i24^@28
@28@0:8@16i24
B40@0:8@16d24^@32
@"NSCharacterSet"
@"CVNLPCaptionRuntimeParameters"
@?24@0:8@16
@?16@0:8
@24@0:8@?16
@60@0:8@?16@?24Q32Q40B48B52B56
@56@0:8@?16@?24Q32Q40B48B52
@52@0:8@?16@?24Q32Q40B48
@48@0:8@?16@?24Q32Q40
@44@0:8@?16Q24Q32B40
@48@0:8@?16Q24Q32B40B44
v24@0:8Q16
@"CVNLPLanguageResourceBundle"
v24@0:8d16
i16@0:8
v20@0:8i16
@40@0:8@16d24d32
@48@0:8@16i24@28@36i44
@36@0:8@16i24@28
I44@0:8@16I24@28^d36
@52@0:8^v16@24@32@40i48
@40@0:8^v16@24@32
@48@0:8^v16@24@32@40
@40@0:8^{CVNLPLanguageModel=}16@24@32
@48@0:8^{CVNLPLanguageModel=}16@24@32@40
@32@0:8^v16@24
{vector<unsigned int, std::allocator<unsigned int>>=^I^I{__compressed_pair<unsigned int *, std::allocator<unsigned int>>=^I}}24@0:8@16
{vector<unsigned int, std::allocator<unsigned int>>=^I^I{__compressed_pair<unsigned int *, std::allocator<unsigned int>>=^I}}32@0:8@16^@24
@"NSLocale"
v32@0:8@16@?24
I16@0:8
{unique_ptr<cvnlp::AbstractVocabulary, std::default_delete<cvnlp::AbstractVocabulary>>="__ptr_"{__compressed_pair<cvnlp::AbstractVocabulary *, std::default_delete<cvnlp::AbstractVocabulary>>="__value_"^{AbstractVocabulary}}}
v192@0:8{?=^v^v[4Q][4Q]QQQQQQQQQQi}16^v184
v192@0:8{?=^v^v[4Q][4Q]QQQQQQQQQQi}16^f184
v192@0:8^f16{?=^v^v[4Q][4Q]QQQQQQQQQQi}24
v192@0:8@16{?=^v^v[4Q][4Q]QQQQQQQQQQi}24
@"CVNLPPerformance"
@"NSMutableDictionary"
q32@0:8^{CGImage=}16^@24
@32@0:8^{CGImage=}16^@24
q32@0:8^{__CVBuffer=}16^@24
@48@0:8@16@24@32^@40
v56@0:8@16@24@32@?40@?48
@48@0:8^{__CVBuffer=}16@24@32^@40
@64@0:8^{__CVBuffer=}16@24@32@40@48^@56
@"NSObject<OS_dispatch_queue>"
@"CVNLPCommSafetyImageAnalyzer"
@"CVNLPCommSafetyTextAnalyzer"
v36@0:8@16@24B32
@96@0:8@16@?24^{CVNLPLanguageModelWithState=}32{vector<unsigned int, std::allocator<unsigned int>>=^I^I{__compressed_pair<unsigned int *, std::allocator<unsigned int>>=^I}}40{vector<unsigned int, std::allocator<unsigned int>>=^I^I{__compressed_pair<unsigned int *, std::allocator<unsigned int>>=^I}}64B88B92
v24@0:8^{CVNLPLanguageModelWithState=}16
v56@0:8q16d24q32@40@48
@28@0:8q16B24
q24@0:8@16
v40@0:8q16d24d32
@24@0:8d16
@72@0:8@16@24d32d40q48q56d64
v36@0:8@16@24I32
v32@0:8@16@24
f88@0:8@16@24{vector<unsigned int, std::allocator<unsigned int>>=^I^I{__compressed_pair<unsigned int *, std::allocator<unsigned int>>=^I}}32@56{vector<unsigned int, std::allocator<unsigned int>>=^I^I{__compressed_pair<unsigned int *, std::allocator<unsigned int>>=^I}}64
^{CVNLPLanguageModelWithState=}16@0:8
{vector<unsigned int, std::allocator<unsigned int>>="__begin_"^I"__end_"^I"__end_cap_"{__compressed_pair<unsigned int *, std::allocator<unsigned int>>="__value_"^I}}
{vector<double, std::allocator<double>>="__begin_"^d"__end_"^d"__end_cap_"{__compressed_pair<double *, std::allocator<double>>="__value_"^d}}
{vector<unsigned long, std::allocator<unsigned long>>="__begin_"^Q"__end_"^Q"__end_cap_"{__compressed_pair<unsigned long *, std::allocator<unsigned long>>="__value_"^Q}}
@"CVNLPLexiconCursors"
^{CVNLPLanguageModelWithState=}
@?28@0:8@16B24
@?20@0:8B16
@52@0:8d16d24d32B40@44
@40@0:8@16Q24@32
B32@0:8@16Q24
v32@0:8Q16@24
v32@0:8@?16@?24
v32@0:8^f16@?24
{?=^vi}16@0:8
v32@0:8{?=^vi}16
{map<std::string, std::vector<float>, std::less<std::string>, std::allocator<std::pair<const std::string, std::vector<float>>>>={__tree<std::__value_type<std::string, std::vector<float>>, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<float>>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::vector<float>>>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::vector<float>>, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<float>>, std::less<std::string>, true>>=Q}}}16@0:8
v40@0:8{map<std::string, std::vector<float>, std::less<std::string>, std::allocator<std::pair<const std::string, std::vector<float>>>>={__tree<std::__value_type<std::string, std::vector<float>>, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<float>>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::vector<float>>>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::vector<float>>, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<float>>, std::less<std::string>, true>>=Q}}}16
{map<std::string, std::vector<unsigned long>, std::less<std::string>, std::allocator<std::pair<const std::string, std::vector<unsigned long>>>>={__tree<std::__value_type<std::string, std::vector<unsigned long>>, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<unsigned long>>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::vector<unsigned long>>>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::vector<unsigned long>>, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<unsigned long>>, std::less<std::string>, true>>=Q}}}16@0:8
v40@0:8{map<std::string, std::vector<unsigned long>, std::less<std::string>, std::allocator<std::pair<const std::string, std::vector<unsigned long>>>>={__tree<std::__value_type<std::string, std::vector<unsigned long>>, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<unsigned long>>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::vector<unsigned long>>>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::vector<unsigned long>>, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<unsigned long>>, std::less<std::string>, true>>=Q}}}16
{vector<std::string, std::allocator<std::string>>=^v^v{__compressed_pair<std::string *, std::allocator<std::string>>=^v}}16@0:8
v40@0:8{vector<std::string, std::allocator<std::string>>=^v^v{__compressed_pair<std::string *, std::allocator<std::string>>=^v}}16
@"CVNLPCaptionDecoderBlock"
{map<std::string, std::vector<float>, std::less<std::string>, std::allocator<std::pair<const std::string, std::vector<float>>>>="__tree_"{__tree<std::__value_type<std::string, std::vector<float>>, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<float>>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::vector<float>>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::vector<float>>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<float>>, std::less<std::string>, true>>="__value_"Q}}}
{map<std::string, std::vector<unsigned long>, std::less<std::string>, std::allocator<std::pair<const std::string, std::vector<unsigned long>>>>="__tree_"{__tree<std::__value_type<std::string, std::vector<unsigned long>>, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<unsigned long>>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::vector<unsigned long>>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::vector<unsigned long>>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<unsigned long>>, std::less<std::string>, true>>="__value_"Q}}}
@40@0:8@16@24^@32
B36@0:8@16i24i28i32
@32@0:8^{vImage_Buffer=^vQQQ}16^@24
@"NSURL"
v44@0:8^@16^@24Q32B40
{shared_ptr<cvnlp::vidcap::VideoCaptioningModel>=^{VideoCaptioningModel}^{__shared_weak_count}}16@0:8
{shared_ptr<cvnlp::vidcap::VideoCaptioningModel>="__ptr_"^{VideoCaptioningModel}"__cntrl_"^{__shared_weak_count}}
@24@0:8^{__CVBuffer=}16
@"VNVYvzEtX1JlUdu8xx5qhDI"
@"VN6Mb1ME89lyW3HpahkEygIG"
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
@32@0:8Q16Q24
@40@0:8Q16Q24@32
@"CVNLPTextDecodingResult"32@0:8Q16Q24
@"CVNLPTextDecodingResult"40@0:8Q16Q24@"CVNLPTextDecodingContext"32
@"CVNLPTextDecodingResult"32@0:8@"CVNLPTextDecodingBeamSearchConfiguration"16@"CVNLPTextDecodingContext"24
@"CVNLPTextDecodingResult"16@0:8
@"CVNLPTextDecodingResult"24@0:8@"CVNLPTextDecodingConfiguration"16
@44@0:8Q16Q24@32B40
@"CVNLPActivationMatrix"
@48@0:8@16@24d32@40
v40@0:8@16@24@32
^{CVNLPBeamSearch=}16@0:8
v24@0:8^{CVNLPBeamSearch=}16
^{CVNLPBeamSearch=}
r^{_LXLexicon=}24@0:8@16
@32@0:8@16Q24
@32@0:8^{_LXLexicon=}16Q24
@24@0:8^{_LXLexicon=}16
r^{_LXLexicon=}16@0:8
^{_LXCursor=}16@0:8
r^{_LXLexicon=}
^{_LXCursor=}
@48@0:8@16@24@32^?40
@24@0:8Q16
^?16@0:8
@48@0:8@16@24@32q40
@40@0:8@16@24d32
@"NLModel"
@56@0:8@16@24@32@40^@48
@56@0:8@16@24^{?=^v^v[4Q][4Q]QQQQQQQQQQi}32^{?=^v^v[4Q][4Q]QQQQQQQQQQi}40^{?=^v^v[4Q][4Q]QQQQQQQQQQi}48
v56@0:8^@16^@24^{?=^v^v[4Q][4Q]QQQQQQQQQQi}32^{?=^v^v[4Q][4Q]QQQQQQQQQQi}40@48
@40@0:8@16{_NSRange=QQ}24
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
v8@?0
General
TextDecoder
CTCTextDecoder
CVNLPLanguageModel
CVNLPCLIPModel
CVNLPVideoCaptioningModel
com.apple.cvnlp
bolt_id
net_file
vocab_file
vocab_name
output_name
encoder
num_layers
max_seq_len
Expected model_spec.json to contain key: 
seq_len
embed_dim
filterTokens
runtime_parameters.json file exists but does not contain filterTokens: 
encoder_embed
caption_ids
caption_ids_mask
caption_causal_mask
model_spec.json
runtime_parameters.json
Filename specified by model_spec.json for video captioning espresso network not found: 
Incorrect data type requested.
[json.exception.
invalid BOM; must be 0xEF 0xBB 0xBF if given
null
invalid literal
invalid string: missing closing quote
invalid string: '\u' must be followed by 4 hex digits
invalid string: surrogate U+DC00..U+DFFF must be followed by U+DC00..U+DFFF
invalid string: surrogate U+DC00..U+DFFF must follow U+D800..U+DBFF
invalid string: forbidden character after backslash
invalid string: control character U+0000 (NUL) must be escaped to \u0000
invalid string: control character U+0001 (SOH) must be escaped to \u0001
invalid string: control character U+0002 (STX) must be escaped to \u0002
invalid string: control character U+0003 (ETX) must be escaped to \u0003
invalid string: control character U+0004 (EOT) must be escaped to \u0004
invalid string: control character U+0005 (ENQ) must be escaped to \u0005
invalid string: control character U+0006 (ACK) must be escaped to \u0006
invalid string: control character U+0007 (BEL) must be escaped to \u0007
invalid string: control character U+0008 (BS) must be escaped to \u0008 or \b
invalid string: control character U+0009 (HT) must be escaped to \u0009 or \t
invalid string: control character U+000A (LF) must be escaped to \u000A or \n
invalid string: control character U+000B (VT) must be escaped to \u000B
invalid string: control character U+000C (FF) must be escaped to \u000C or \f
invalid string: control character U+000D (CR) must be escaped to \u000D or \r
invalid string: control character U+000E (SO) must be escaped to \u000E
invalid string: control character U+000F (SI) must be escaped to \u000F
invalid string: control character U+0010 (DLE) must be escaped to \u0010
invalid string: control character U+0011 (DC1) must be escaped to \u0011
invalid string: control character U+0012 (DC2) must be escaped to \u0012
invalid string: control character U+0013 (DC3) must be escaped to \u0013
invalid string: control character U+0014 (DC4) must be escaped to \u0014
invalid string: control character U+0015 (NAK) must be escaped to \u0015
invalid string: control character U+0016 (SYN) must be escaped to \u0016
invalid string: control character U+0017 (ETB) must be escaped to \u0017
invalid string: control character U+0018 (CAN) must be escaped to \u0018
invalid string: control character U+0019 (EM) must be escaped to \u0019
invalid string: control character U+001A (SUB) must be escaped to \u001A
invalid string: control character U+001B (ESC) must be escaped to \u001B
invalid string: control character U+001C (FS) must be escaped to \u001C
invalid string: control character U+001D (GS) must be escaped to \u001D
invalid string: control character U+001E (RS) must be escaped to \u001E
invalid string: control character U+001F (US) must be escaped to \u001F
invalid string: ill-formed UTF-8 byte
invalid number; expected digit after '-'
invalid number; expected digit after '.'
invalid number; expected '+', '-', or digit after exponent
invalid number; expected digit after exponent sign
object key
object separator
array
object
excessive object size: 
cannot compare iterators of different containers
invalid_iterator
cannot get value
iterator does not fit current value
iterator out of range
cannot use erase() with 
type_error
string
boolean
discarded
number
excessive array size: 
out_of_range
<U+%.4X>
parse_error
parse error
 at line 
, column 
syntax error 
while parsing 
; last read: '
unexpected 
; expected 
<uninitialized>
true literal
false literal
null literal
string literal
number literal
<parse error>
end of input
'[', '{', or a literal
unknown token
[KeyError] 
cannot use operator[] with a string argument with 
type must be string, but is 
type must be number, but is 
type must be array, but is 
[FileNotFoundError] 
%@%@
Error during scaling.
Error code %zd
/System/Library/PrivateFrameworks/CVNLP.framework/lm_vocabulary.plist
/tmp/lm_vocabulary.plist
CVNLPBeamSearch
Could not construct
CVNLPCommSafetyImageSensitivity
CVNLPCommSafetyImageSensitivityScore
CVNLPCommSafetyHandlerImageClassificationScores
CVNLPCaptionScaleMethod
CVNLPCaptionScaleMethodCGInterpolationNone
CVNLPCaptionScaleMethodCGInterpolationLow
CVNLPCaptionScaleMethodCGInterpolationMedium
CVNLPCaptionScaleMethodCGInterpolationHigh
CVNLPCaptionScaleMethodvImage
CVNLPCommSafetyUseCPU
CVNLPCommSafetyUseGPU
CVNLPCommSafetyUseANE
CVNLPCommSafetyUseAnyAvailableDevice
CVNLPCommSafetyUseMTLDevice
CVNLPCommSafetyEnableAllClasses
CVNLPCommSafetyUseImageAnalyzer
CVNLPCommSafetyUseTextAnalyzer
encoder_opt.espresso.net
image
mean_feats
att_feats
p_att_feats
CVNLPVideoCaptioningModelName
CVNLPVideoCaptioningModelEspressoEngine
CVNLPVideoCaptioningModelBeamSearchMaxSteps
CVNLPVideoCaptioningModelBeamSearchBeamWidth
CVNLPVideoCaptioningModelBeamSearchTopK
CVNLPVideoCaptioningModelBeamSearchLengthPenalty
CLIP
Invalid model directory: 
Could not convert
Unrecognized value for engine=
[InvalidArgument] 
+N9mZUAHooNvMiQnjeTJ8g
VNCreateSceneprintRequest
Unable to find class %s
VNImageRequestHandler
CVNLPCaptionError
CVNLPVideoCaptioningModelError
You must override %@ in a subclass
from
%@(%@ <%@> at <%@>: <%@>)
CVNLPCommSafetyTextItem requires keyed coding
CVNLPConversationIdentifier
CVNLPDate
CVNLPDirection
CVNLPText
INSendMessageIntent
com.apple.MobileSMS
CVNLPCommSafetyCDTextProvider event query creation failed: %@
CVNLPCommSafetyCDTextProvider event query execution error: %@
chat
urn:biz:
CVNLPCommSafetyCDTextProvider event query execution failed: %@
_DKKnowledgeStore
_DKEventQuery
_DKSystemEventStreams
_DKQuery
_DKSource
_DKIntentMetadataKey
CVNLPCommSafetyCDTextProvider class initialization failed: %p %p %p %p %p %p
CVNLPCommSafetyCDTextProvider class initialization failed: %@
] Avg vocab subset size over 
 samples: 
; numRetries: 
position
] sampleText: 
/dev/urandom
temperature
InputDimension
SequenceLength
ModelURL
ModelData
InputNames
OutputNames
ModelName
ModelVersion
QuantizationParams
QuantizationSchemeName
QuantizationSchemeLinearInt8RangeMin
QuantizationSchemeLinearInt8RangeMax
Unexpected mrlkey: 
Activation Matrix with %ld timesteps, %ld observations 
 t%ld, <B>:%.2f [%ld], sym=%@:%.2f [%ld]
CVNLPCLIPModelName
v3.1
c_network_get_input_names returned null for encoder
Failed to load encoder network
Encode
EncodePx
q24@?0@"NSString"8@"NSString"16
com.apple.CVNLPCLIPModel
Could not find item
com.apple.CVNLP
Default
captionModel
minimumConfidence
lengthNormalizationFactor
excludeGenderStrategy
classifiers
revisions
blockingTokens
categories
replacements
excludeGenderReplacements
excludeGenderTriggers
gender
blacklistTokens
blockingTokensAnnex
replaceKey
replaceWith
replaceProb
genderOption
v44@?0^{__CFURL=}8i16^{__CFLocale=}20^{__CFString=}28^B36
v28@?0r*8q16I24
0123456789
<PS>
v56@?0@"NSString"8{_NSRange=QQ}16{_NSRange=QQ}32^B48
Missing or incorrect bos or eos or unk token in vocabulary file
Unexpected format in Special Map file
Special token shall not appear in vocabulary file
Missing special token class in vocabulary file
Unknown TokenID: 
Special token 
 not found in vocab!
Unknown Token: 
Input text should not contain BOS token!
OutOfVocabularyError: 
bimap<>: invalid key
[%@: Peak-Delta: %lf, CPU-Time: %lf, Interval: %lf]
maxpeak
peakdelta
recentpeak
current
timeInterval
CVNLPExceptionError
caption_queue
classify_queue
Create
Total
Scale
ScalePx
TotalPx
comm_safety_handler
CSModels/ImageModel
CVNLPCommSafetyError
["%@"], modelLogProb=%.8f, logProbTotalNorm=%.8f, logProbBlank=%.8f, logProbNonBlank=%.8f, %lu tokens
["%@"], logProbTotal=%.8f, logProbNormTotal=%.8f, logProbWordLM=%.8f, logProbHistoryLex=%.8f, logProbActiveLex=%.8f, logProbCharacterLM=%.8f, %lu tokens
v24@?0^{_LXCursor=}8^B16
'.-/
com.apple.cvnlp.languagemodeling
d16@?0@"CVNLPTextDecodingPath"8
CVNLPCLIPModelURL
CVNLPCLIPModelEspressoEngine
MRLNeuralNetworkCreate returned nullptr
DictionaryRef_iterator iterator out of range.
decoder_queue
DecodeBlockExecute:%tu
DecodeBlockCopy:%tu
decoder_block%tu_opt.espresso.net
att_feats_placeholder
block_input
block_output
decoder_opt.espresso.net
vanilla_attention
_out
in_word_ids
word_probs
in_word_ids_mask
scale
Failed to load decoder network
self_attention
_k_s_in
_v_s_in
Failed to execute decoder network
60dc96fd80c33771139d6cf90639a776
1.5.0
self ENDSWITH '%@_quantized.espresso.net'
self ENDSWITH '%@_quantized_sqdev.espresso.net'
Could not create espresso context for engine: 
 and device id: 
self ENDSWITH 'operating_thresholds.json'
d61a476a2e70af249c2b1695097eeea9
d9ad80f7b43abb16a607e4361c87bca3
e156d20cabbf6d6cbca2f1f437738097
64c53be656ce81ef8aad95a16847f9ce
c9cc54544693ed5ad6386336207971dd
85a5e1ae11b0353df314fe3763da2c56
58484718d77c0af68837b49bde584d48
63f9d5d4ca6958521ae9de3dcaa6fef6
Name could not be encoded: 
Name could not be decoded: 
class_thresholds
class
index
default
thresholds
59744aeff8
Inference
precision_recall_data
CVNLPBeamSearchSize
CVNLPBeamSearchLengthNormalizationFactor
CVNLPBeamSearchOutputVocabSize
CVNLPBeamSearchOutputVocabPath
CVNLPBeamSearchOutputVocabMap
CVNLPBeamSearchOutputVocabFilterList
CVNLPBeamSearchBlacklistRules
CVNLPBeamEndToken
CVNLPBeamSearchIncludeLanguageModel
CVNLPBeamSearchBeamID
CVNLPBeamSearchNextTokenID
CVNLPBeamSearchNextTokenSoftmaxValues
CVNLPBeamSearchNextTokenMetaData
CVNLPBeamTokens
CVNLPBeamScore
vocab.txt
special_map.txt
sentencepiece.model
Unable to find vocab file.
d24@?0d8d16
%@ : %.2f
v32@?0@"NSString"8@"CVNLPCTCTextDecodingPath"16^B24
FPS is : %f 
Invalid model URL: 
Received lengthPenalty=
, which is outside the allowed range of [0.0, 10.0]. Please set to a floating point number between 0 and 10.
Unknown error encountered during initWithOptions.
Unknown error encountered during generateCaption.
VNImageBuffer
Key not found in dictionary: 
CVNLPCaption
[UnknownError] 
 %@ 
triggerTokens
@"NSError"16@?0@"VNImageBasedRequest"8
Failed to create s-classifier
Failed to create n-classifier
VisionRequestCreation
VisionPerformRequest
VN6Mb1ME89lyW3HpahkEygIG
VNVYvzEtX1JlUdu8xx5qhDI
CVNLPModelURLKey
CVNLPTokenTypeKey
CVNLPLocaleKey
CVNLPLanguageModelArchitectureKey
CVNLPSamplingBeamSizeKey
CVNLPSamplingMaxLengthKey
CVNLPSamplingMethodKey
CVNLPSamplingNucleusThresholdKey
CVNLPSamplingNumberKey
CVNLPSamplingTopKKey
Missing required key:
model.dat
LSTM
model.espresso.bin
_gpt
Received null token.
Received empty token.
Method
GREEDY
BEAM
TOP_K
NUCLEUS
TopK
Number
NucleusThreshold
MaxLength
Locale
TokenType
Architecture
BeamSize
Unexpected CVNLP key: 
CVNLPLanguageModelWithState
InvalidProbabilityError: expected 
to be in the interval [0, 1].
output_dim
image_encoder
image_size
text_encoder
embed_net_file
main_net_file
embed_output_names
main_input_ids_name
main_input_ids_mask_name
main_output_name
lowercase
bos:eos
text_ids_mask
type must be boolean, but is 
CVNLPCaptionTrackPerformance
CVNLPCaptionModelPath
CVNLPCaptionLanguage
CVNLPCaptions
CVNLPGeneratedCaption
CVNLPGeneratedCaptionScore
CVNLPGeneratedCaptionConfidenceLow
CVNLPImageClassificationIdentifiers
CVNLPCaptionModelType
CVNLPCaptionModelLSTM
CVNLPCaptionModelTransformer
CVNLPCaptionEnableGenderedCaptions
CVNLPCaptionFilterTokens
v32@?0@"NSString"8d16^B24
Mismatching vocab file and output vocab sizes
vocab_reverse.json
Decode
DecodeBlock
OneStep
q24@?0@"CVNLPDecodingLexicon"8@"CVNLPDecodingLexicon"16
priority == %lu
v24@?0@"CVNLPDecodingLexicon"8^B16
%@(<%@> from <%@>-<%@> %@)
sensitive
non-sensitive
CVNLPCommSafetyTextClassification requires keyed coding
CVNLPStartDate
CVNLPEndDate
CVNLPResult
%@(%@ %@ > %.2g)
operating_thresholds.json
model_thresholds
threshold
TextClassifier%@.mlmodelc
CVNLPCommSafetyTextAnalyzer item provider error: %@
v32@?0@"NSArray"8@"NSError"16^B24
decoder_opt_pro.espresso.net
mean_feats_placeholder
p_att_feats_placeholder
in_word_id
lstm/att_state_feed
lstm/lang_state_feed
word_id
lang_prob
new_att_state
new_lang_state
lstmAttnStateData
lstmLangStateData
Failed to create espresso context.
Failed to create espresso plan.
Setting plan priorty
Loading espresso Network
Sharing intermediate buffer
Declaring network output
Setting preprocessing params
Building espresso plan
Executing plan
Model has no pre-declared outputs.
Model must have exactly one pre-declared output.
Binding output buffer
Error encountered during: 
 [espresso error: 
unordered_map::at: key not found
PixelBufferTransfer operation [
] failed. Status = 
Image Transfer
Session Creation
PixelBufferTransfer internal inconsistency: null session.
Unsupported espresso type encountered.
Unpacking tensor shape
Failed to allocate aligned memory.
Unknown data type
Unknown data type.
Binding buffer
Unsupported tensor rank: 
Encountered an error during: %s
 -> Espresso Error: %s
Invalid dimensions requested for CVPixelBuffer creation.
Failed to create CVPixelBuffer. Status = 
Failed to lock pixel buffer.
Failed to unlock pixel buffer.
Unsupported CVPixelBuffer type: 
Null CVPixelBuffer encountered.
Binding CVPixelBuffer
Failed to get CVPixelBuffer's data. Ensure the buffer was locked.
precompiled_charsmap is empty.
Normalizer model is not available.
length < 0
norm_to_org and normalized are inconsistent
Trie blob is broken.
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/src/util.h
'result' Must be non NULL
Cannot open 
input ifstream is null
Model file is broken
Model is not initialized.
Normalizer is not initialized.
output container is null
Empty piece is not allowed.
consumed index is out-of-range.
original index is out-of-range.
all normalized characters are not consumed.
output proto is null
NBestEncode returns empty result
nbest_size must be 0 < nbest_size <= 512 or nbest_size < 0.
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/src/sentencepiece_processor.cc
LOG(
ERROR
Returns default value 
</s>
Unknown extra_option type
reverse
option 
 is not available.
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/arenastring.h
CHECK failed: initial_value != NULL: 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/repeated_field.h
CHECK failed: (index) >= (0): 
CHECK failed: (index) < (current_size_): 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/src/model_factory.cc
Unknown model_type: 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/src/char_model.cc
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/src/unigram_model.cc
best_node
nbest_size >= 1. Returns empty result.
Too big agenda. shrinking
(num_nodes) < (trie_results.size())
model file is already precompiled.
No pieces are loaded.
Cannot build double-array.
No entry is found in the trie.
precompiled_trie is empty.
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/third_party/darts_clone/darts.h:776: exception: failed to resize pool: std::bad_alloc
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/third_party/darts_clone/darts.h:1214: exception: failed to insert key: negative value
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/third_party/darts_clone/darts.h:1216: exception: failed to insert key: zero-length key
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/third_party/darts_clone/darts.h:1230: exception: failed to insert key: invalid null character
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/third_party/darts_clone/darts.h:1235: exception: failed to insert key: wrong key order
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/third_party/darts_clone/darts.h:915: exception: failed to build rank index: std::bad_alloc
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/third_party/darts_clone/darts.h:1453: exception: failed to modify unit: too large offset
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/third_party/darts_clone/darts.h:1799: exception: failed to build double-array: invalid null character
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/third_party/darts_clone/darts.h:1801: exception: failed to build double-array: negative value
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/third_party/darts_clone/darts.h:1816: exception: failed to build double-array: wrong key order
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/src/sentencepiece_model.pb.cc
CHECK failed: !model_prefix_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
CHECK failed: !input_format_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
CHECK failed: (&from) != (this): 
sentencepiece.TrainerSpec
CHECK failed: !name_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
CHECK failed: !precompiled_charsmap_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
sentencepiece.NormalizerSpec
CHECK failed: !piece_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
sentencepiece.ModelProto.SentencePiece
CHECK failed: !precompiled_trie_.IsDefault( &::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
CHECK failed: trainer_spec_ != NULL: 
CHECK failed: normalizer_spec_ != NULL: 
sentencepiece.ModelProto
CHECK failed: (n) >= (0): 
down_cast
casts.h
f == NULL || dynamic_cast<To>(f) != NULL
CHECK failed: (&other) != (this): 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/src/model_interface.cc
User defined symbol is not supported.
 is already defined.
!result.empty()
Cancelled
Unknown
Invalid argument
Deadline exceeded
Not found
Already exists
Permission denied
Unauthenticated
Resource exhausted
Failed precondition
Aborted
Out of range
Unimplemented
Internal
Unavailable
Data loss
Unkown code:
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/src/sentencepiece.pb.cc
CHECK failed: !surface_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
sentencepiece.SentencePieceText.SentencePiece
CHECK failed: !text_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
sentencepiece.SentencePieceText
sentencepiece.NBestSentencePieceText
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/src/bpe_model.cc
Invalid character length.
(index) >= (0)
(index) < (static_cast<int>(symbols.size()))
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/src/model_interface.h
Not implemented.
(cannot determine missing fields for lite message)
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/message_lite.cc
CHECK failed: !coded_out.HadError(): 
parse
Can't 
 message of type "
" because it is missing required fields: 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/wire_format_lite.cc
CHECK failed: (value.size()) <= (kint32max): 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/io/coded_stream.cc
A protocol message was rejected because it was too big (more than 
 bytes).  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
CHECK failed: (buffer_size) >= (0): 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/generated_message_util.cc
Not implemented field number 
 with type 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/stubs/common.cc
This program requires version 
 of the Protocol Buffer runtime library, but the installed version is 
.  Please update your library.  If you compiled the program yourself, make sure that your headers are from the same version of Protocol Buffers as your link-time library.  (Version verification failed in "
This program was compiled against version 
 of the Protocol Buffer runtime library, which is not compatible with the installed version (
).  Contact the program author for an update.  If you compiled the program yourself, make sure that your headers are from the same version of Protocol Buffers as your link-time library.  (Version verification failed in "
%d.%d.%d
INFO
WARNING
FATAL
[libprotobuf %s %s:%d] %s
pthread_mutex_lock: 
pthread_mutex_unlock: 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/io/zero_copy_stream.cc
This ZeroCopyOutputStream doesn't support aliasing. Reaching here usually means a ZeroCopyOutputStream implementation bug.
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/io/zero_copy_stream_impl_lite.cc
CHECK failed: (last_returned_size_) > (0): 
BackUp() can only be called after a successful Next().
CHECK failed: (count) <= (last_returned_size_): 
CHECK failed: (count) >= (0): 
CHECK failed: target_ != NULL: 
Cannot allocate buffer larger than kint32max for 
StringOutputStream.
CHECK failed: (count) <= (target_->size()): 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/extension_set.cc
Non-primitive types can't be packed.
can't reach here.
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/arena.cc
CHECK failed: (min_bytes) <= (std::numeric_limits<size_t>::max() - kHeaderSize): 
N5cvnlp4util6InFileE
N5cvnlp4util9DirectoryE
NSt3__110__function6__funcIZN5cvnlp4util6MatrixIfE3rowEmEUlmmE_NS_9allocatorIS6_EEFmmmEEE
NSt3__110__function6__baseIFmmmEEE
bbbbbbbb
bbbbbbbbbbbbbbbbbb
bbbbbbbbb
bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb
b"bbbbbbbb&bbbbbbb:bbbbbJbbbbbbZb^
2-DN'H
Xbh`
3;CA
9AGM
+39?
TT"TTTTTTTTTTTTTTTT
TTTTTTTTTTTTTTTTTTTTTTTTTTT5:
]]]]]]]]]]]]]]]]]
]]]]]]]]]]]]$]]]]]]]]]]]]]]K]]]5
N5cvnlp4util8KeyErrorE
N5cvnlp4util20ExceptionWithMessageE
N5cvnlp4util17FileNotFoundErrorE
N5cvnlp4util4FileE
NSt3__14__fs10filesystem4pathE
N5cvnlp6vidcap27ExcludeTokenIDsLogitsWarperE
N5cvnlp6vidcap12LogitsWarperE
NSt3__113basic_fstreamIcNS_11char_traitsIcEEEE
N8nlohmann6detail11other_errorE
N8nlohmann6detail9exceptionE
NSt3__120__shared_ptr_emplaceIN8nlohmann6detail20input_stream_adapterENS_9allocatorIS3_EEEE
N8nlohmann6detail20input_stream_adapterE
N8nlohmann6detail22input_adapter_protocolE
N8nlohmann6detail12out_of_rangeE
NSt3__117bad_function_callE
N8nlohmann6detail16invalid_iteratorE
N8nlohmann6detail10type_errorE
N8nlohmann6detail11parse_errorE
NSt3__120__shared_ptr_emplaceIN5cvnlp23SentencePieceVocabularyENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_pointerIPN5cvnlp6vidcap17BeamSearchOptionsENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIN5cvnlp6vidcap17BeamSearchOptionsEEE
ZN5cvnlp4util6MatrixIfE3rowEmEUlmmE_
NSt3__111__end_stateIcEE
NSt3__16__nodeIcEE
NSt3__120__shared_ptr_pointerIPNS_13__empty_stateIcEENS_10shared_ptrIS2_E27__shared_ptr_default_deleteIS2_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrINS_13__empty_stateIcEEE27__shared_ptr_default_deleteIS2_S2_EE
NSt3__113__empty_stateIcEE
NSt3__116__owns_one_stateIcEE
NSt3__115__has_one_stateIcEE
NSt3__120__l_anchor_multilineIcEE
NSt3__120__r_anchor_multilineIcEE
NSt3__115__word_boundaryIcNS_12regex_traitsIcEEEE
NSt3__111__lookaheadIcNS_12regex_traitsIcEEEE
NSt3__123__match_any_but_newlineIcEE
NSt3__118__match_char_icaseIcNS_12regex_traitsIcEEEE
NSt3__120__match_char_collateIcNS_12regex_traitsIcEEEE
NSt3__112__match_charIcEE
NSt3__116__back_ref_icaseIcNS_12regex_traitsIcEEEE
NSt3__118__back_ref_collateIcNS_12regex_traitsIcEEEE
NSt3__110__back_refIcEE
NSt3__120__bracket_expressionIcNS_12regex_traitsIcEEEE
NSt3__128__begin_marked_subexpressionIcEE
NSt3__126__end_marked_subexpressionIcEE
NSt3__16__loopIcEE
NSt3__117__owns_two_statesIcEE
NSt3__117__repeat_one_loopIcEE
NSt3__111__alternateIcEE
NSt3__121__empty_non_own_stateIcEE
NSt3__111__match_anyIcEE
N5cvnlp4util15InvalidArgumentE
N5cvnlp4util12RuntimeErrorE
NSt3__120__shared_ptr_emplaceIN5cvnlp4clip9CLIPModelENS_9allocatorIS3_EEEE
N5cvnlp13GreedySamplerE
N5cvnlp20LanguageModelSamplerE
N5cvnlp11TopKSamplerE
N5cvnlp11BeamSamplerE
N5cvnlp14NucleusSamplerE
%+N5cvnlp20OutOfVocabularyErrorE
N5cvnlp19TokenListVocabularyE
N5cvnlp18AbstractVocabularyE
N5cvnlp23SentencePieceVocabularyE
N5boost16exception_detail10clone_implINS0_19error_info_injectorISt12out_of_rangeEEEE
N5boost16exception_detail19error_info_injectorISt12out_of_rangeEE
N5boost9exceptionE
N5boost16exception_detail10clone_baseE
N5cvnlp18CharacterTokenizerE
N5cvnlp17AbstractTokenizerE
N5cvnlp19WhitespaceTokenizerE
"(9DJPV^djq
NSt3__120__shared_ptr_emplaceIN5cvnlp6vidcap20VideoCaptioningModelENS_9allocatorIS3_EEEE
N5cvnlp4util12UnknownErrorE
"(9DJPV^djq
"(2;CIOV\bj
"(7AMSYcioxN5cvnlp23InvalidProbabilityErrorE
N5cvnlp4util4PathE
N2ik6TensorE
N2ik14InferenceErrorE
N2ik11EspressoNetE
N2ik14EspressoTensorE
NSt3__120__shared_ptr_pointerIPhNS_10shared_ptrIA_hE27__shared_ptr_default_deleteIS3_hEENS_9allocatorIhEEEE
NSt3__110shared_ptrIA_hE27__shared_ptr_default_deleteIS1_hEE
NSt3__114default_deleteIA_hEE
NSt3__120__shared_ptr_emplaceIN2ik21EspressoBufferStorageENS_9allocatorIS2_EEEE
N2ik21EspressoBufferStorageE
N2ik13TensorStorageE
N2ik17PixelBufferTensorE
NSt3__120__shared_ptr_emplaceIN2ik18PixelBufferStorageENS_9allocatorIS2_EEEE
N2ik18PixelBufferStorageE
N13sentencepiece10normalizer10NormalizerE
N5Darts15DoubleArrayImplIvvivEE
N13sentencepiece22SentencePieceProcessorE
N13sentencepiece4word5ModelE
*-0N13sentencepiece9character5ModelE
$1WW
BPHN13sentencepiece7unigram7LatticeE
N13sentencepiece7unigram9ModelBaseE
N13sentencepiece7unigram5ModelE
N5Darts7Details9ExceptionE
$5FW
N13sentencepiece11TrainerSpecE
N13sentencepiece14NormalizerSpecE
N13sentencepiece24ModelProto_SentencePieceE
N13sentencepiece10ModelProtoE
NSt3__112basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEE
N13sentencepiece14ModelInterfaceE
$).38=BGLQV
N13sentencepiece31SentencePieceText_SentencePieceE
N13sentencepiece17SentencePieceTextE
N13sentencepiece22NBestSentencePieceTextE
N6google8protobuf8internal29InternalMetadataWithArenaBaseINSt3__112basic_stringIcNS3_11char_traitsIcEENS3_9allocatorIcEEEENS1_29InternalMetadataWithArenaLiteEE9ContainerE
N13sentencepiece3bpe5ModelE
N6google8protobuf11MessageLiteE
N6google8protobuf8internal12FieldSkipperE
N6google8protobuf8internal29CodedOutputStreamFieldSkipperE
N6google8protobuf14FatalExceptionE
N6google8protobuf7ClosureE
N6google8protobuf8internal16FunctionClosure0E
N6google8protobuf2io20ZeroCopyOutputStreamE
N6google8protobuf2io17ArrayOutputStreamE
N6google8protobuf2io18StringOutputStreamE
-BWl
"+4=Oajr{
N6google8protobuf8internal15ExtensionFinderE
N6google8protobuf8internal24GeneratedExtensionFinderE
NSt3__121__basic_string_commonILb1EEE
N6google8protobuf13RepeatedFieldIiEE
N6google8protobuf13RepeatedFieldIxEE
N6google8protobuf13RepeatedFieldIjEE
N6google8protobuf13RepeatedFieldIyEE
N6google8protobuf13RepeatedFieldIfEE
N6google8protobuf13RepeatedFieldIdEE
N6google8protobuf13RepeatedFieldIbEE
N6google8protobuf16RepeatedPtrFieldINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEEE
N6google8protobuf8internal20RepeatedPtrFieldBaseE
N6google8protobuf16RepeatedPtrFieldINS0_11MessageLiteEEE
Attempting to parse ModelSpec from JSON path: %s
Performing greedy search, since requested topKPerStep is 1.
Setting Espresso storage type to FLOAT32 since CPU runtime requested.
Setting Espresso storage type to FLOAT16.
sampleTokenIDs(%s, %zu)
EOS encountered in greedySample. Terminating early.
No context provided. Pushing bosID as first tokenID for beam search.
Skipping generation on sample that ends with EOS: %s
All beams contain finished sequences. Exiting beam search loop early after %lu steps
Setting Espresso engine to CPU since ANE is not available and we are investigating issues when running on pre-ANE devices with MPS.
Unknown error encountered during initWithOptions.
Using user-provided CLIP model to encode image instead of Vision.
Unknown error encountered during encodeImage.
Unknown Error encountered during encodeText.
Could not load the contents of file at %@
Could not load the contents of file at %@ as dictionary
Error adding caption rules-file line: %@. Error: %@
Expected token=%s to get converted into single TokenID, but got %zu tokenIDs: %s. Returning UNK TokenID as fallback.
[CVNLPTokenIDConverter] Failed to load token id resources: %s
Input buffer and pixel buffer are both nil
Video Pixel Buffers are empty
Unexpected tokenNormalizedScore issue? got %.8f from tokenScore = %.2f, characterCount = %ld
Default ivs model files not found.
ANE-specific ivs model files not found. Falling back to the default model.
Failed to load encoder network for engine: %d, espresso error: %s
Error during espresso execution: %s
Error during operating point retrieval: %s
Unknown error encountered during initWithOptions. See NSError object for more details.
Received unsupported CFType for locale.
Received unsupported model format. Could be either Montreal or Espresso
Creation options does not contain all required keys.
Unable to determine model locale from options=%@
Locale not supported: %s
Model directory does not exist: %s
Expected output sequence to have dimensions (vocab=%ld, time=%ld), but got (vocab=%ld, time=%ld)
Invalid sampling method: "%s"
Tokenized query=%s into %zu tokens.
CLIP image encoder model file not found!
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:o:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:o:path:/System/Library/Frameworks/Vision.framework/Vision
CVNLPTextDecodingToken
CVNLPCaptionSensitiveImageParameters
CVNLPInformationStream
CVNLPLanguageResourceBundle
CVNLPCaptionEncoderLSTM
CVNLPCLIPEmbedding
CVNLPCLIPModel
CVNLPCaptionEncoder
CVNLPCommSafetyTextItem
NSCopying
NSSecureCoding
NSCoding
CVNLPCommSafetyTextProvider
CVNLPCommSafetyCDTextProvider
CVNLPActivationMatrix
CVNLPLexiconCursors
CVNLPCaptionEncoderTransformer
CVNLPCaptionPostProcessingHandler
CVNLPCaptionModelBase
BundleHelper
CVNLPTextDecodingConfiguration
CVNLPTextDecodingBeamSearchConfiguration
CVNLPTextDecoder
CVNLPCaptionRuntimeParameters
CVNLPTextDecodingResultCandidate
CVNLPTextDecodingResult
CVNLPDecodingLanguageModel
CVNLPTokenIDConverter
CVNLPModelBase
CVNLPPerformanceResult
CVNLPPerformance
CVNLPCommSafetyHandler
CVNLPCTCTextDecodingPath
CVNLPCaptionDecoder
CVNLPTextDecodingPath
CVNLPCaptionDecoderBlock
CVNLPCommSafetyImageAnalyzer
CVNLPCTCBeamState
CVNLPVideoCaptioningModel
CVNLPCaption
CVNLPCaptionRuntimeExcludeGenderTrigger
CVNLPVisionRequestHandler
CVNLPCTCTextDecoder
CVNLPTextDecoding
NSObject
CVNLPCaptionRuntimeReplacements
3@!2
CVNLPCaptionDecoderTransformer
CVNLPDecodingLexicon
CVNLPDecodingLexicons
CVNLPCommSafetyTextClassification
CVNLPCommSafetyTextAnalyzerModel
CVNLPCommSafetyTextAnalyzer
CVNLPCaptionDecoderLSTM
CVNLPTextDecodingContext
dataUsingEncoding:
startDateSortDescriptorAscending:
dataWithBytes:length:
setLimit:
numberWithFloat:
addEntriesFromDictionary:
tracksWithMediaType:
characterSetWithCharactersInString:
lowercaseLetterCharacterSet
punctuationCharacterSet
performRequests:error:
dataWithBytesNoCopy:length:freeWhenDone:
keysSortedByValueUsingSelector:
addObject:
numberWithInt:
strides
lowercaseString
knowledgeStoreWithDirectReadOnlyAccess
dataWithContentsOfFile:
getBytes:maxLength:usedLength:encoding:options:range:remainingRange:
addObjectsFromArray:
numberWithInteger:
enumerateSubstringsInRange:options:usingBlock:
descriptorData
raise:format:
initWithContentsOfURL:error:
setObject:forKey:
languageCode
errorWithDomain:code:userInfo:
unsignedIntegerValue
dataWithContentsOfURL:
numberWithUnsignedInteger:
stringByAppendingString:
rangeOfCharacterFromSet:
setObject:forKeyedSubscript:
exceptionWithName:reason:userInfo:
confidence
allKeys
numberWithUnsignedLong:
stringByDeletingLastPathComponent
maximumLengthOfBytesUsingEncoding:
rangeOfCharacterFromSet:options:range:
setOffset:
containsString:
objectAtIndex:
dateByAddingTimeInterval:
uppercaseLetterCharacterSet
initWithString:
dictionary
rangeOfFirstMatchInString:options:range:
allObjects
stringByDeletingPathExtension
decodeIntegerForKey:
setPredicate:
predicateForEventsWithEndInDateRangeFrom:to:
objectAtIndexedSubscript:
sceneprints
lastObject
allowsKeyedCoding
content
stringByTrimmingCharactersInSet:
rangeOfString:
userInfo
dictionaryWithDictionary:
decodeObjectOfClass:forKey:
predicateForEventsWithSourceID:bundleID:
boolValue
lastPathComponent
andPredicateWithSubpredicates:
objectForKey:
contentsOfDirectoryAtPath:error:
valueForKey:
dictionaryWithObjects:forKeys:count:
rangeOfString:options:range:
stringWithCharacters:length:
predicateForEventsWithSourceID:bundleID:groupIDs:
bufferWithWidth:height:format:options:error:
setRequestedTimeToleranceAfter:
objectForKeyedSubscript:
appIntentsStream
executeQuery:error:
valueWithRange:
rangeValue
stringWithFormat:
initWithURL:options:
predicateForObjectsWithMetadataKey:andStringValue:
setRequestedTimeToleranceBefore:
initWithUTF8String:
appendFormat:
copy
regularExpressionWithPattern:options:error:
distantFuture
setRevision:error:
identifier
bundleForClass:
predicateWithFormat:
fileExistsAtPath:
appendString:
copyCGImageAtTime:actualTime:error:
distantPast
JSONObjectWithData:options:error:
stringWithUTF8String:
bytes
setSortDescriptors:
length
code
fileURLWithPath:
whitespaceAndNewlineCharacterSet
removeLastObject
predictedLabelHypothesesForString:maximumCount:
strongToStrongObjectsMapTable
removeObjectForKey:
lengthOfBytesUsingEncoding:
modelWithContentsOfURL:error:
whitespaceCharacterSet
fileURLWithPathComponents:
setWithArray:
intValue
doubleValue
mutableCopy
replaceOccurrencesOfString:withString:options:range:
subarrayWithRange:
indexOfObject:
letterCharacterSet
array
integerValue
filteredArrayUsingPredicate:
substringWithRange:
duration
componentsJoinedByString:
initWithAsset:
intent
countByEnumeratingWithState:objects:count:
arrayWithArray:
componentsSeparatedByCharactersInSet:
filteredSetUsingPredicate:
encodeInteger:forKey:
shape
characterAtIndex:
processIdentifier
firstObject
URLByAppendingPathComponent:
intentClass
arrayWithCapacity:
encodeObject:forKey:
nominalFrameRate
initWithBytes:length:encoding:
processInfo
floatValue
path
intentsSourceID
arrayWithObject:
timeIntervalSinceDate:
initWithCGImage:options:
arrayWithObjects:
setEventStreams:
interaction
formUnionWithCharacterSet:
defaultManager
initWithCVPixelBuffer:options:
localeIdentifier
sortedArrayUsingComparator:
arrayWithObjects:count:
setExecuteConcurrently:
dataPointer
invertedSet
resourcePath
enumerateKeysAndObjectsUsingBlock:
UTF8String
pathForResource:ofType:
dataType
numberWithBool:
isEqualToString:
numberWithDouble:
init
initWithString:score:alignmentScore:activationRange:terminatingCharacter:
initWithString:score:activationRange:terminatingCharacter:
initWithString:score:activationRange:hasPrecedingSpace:
fullString
string
hasPrecedingSpace
terminatingCharacter
score
alignmentScore
activationRange
.cxx_destruct
_hasPrecedingSpace
_string
_terminatingCharacter
_score
_alignmentScore
_activationRange
T@"NSString",R,C,N,V_string
TB,R,N,V_hasPrecedingSpace
T@"NSString",R,C,N,V_terminatingCharacter
T@"NSNumber",R,C,N,V_score
T@"NSNumber",R,C,N,V_alignmentScore
T{_NSRange=QQ},R,N,V_activationRange
T@"NSString",R,C,N
initWithVisionIdentifier:minConfidence:commonBlockingTokens:categoryBlockingTokens:categoryBlockingTokensAnnex:
visionIdentifier
minConfidence
blockingTokens
_visionIdentifier
_minConfidence
_blockingTokens
T@"NSString",R,N,V_visionIdentifier
Td,R,N,V_minConfidence
T@"NSArray",R,N,V_blockingTokens
defaultDecodingWeight
defaultLowerBoundLogProbability
initWithDecodingWeight:
initWithDecodingWeight:lowerBoundLogProbability:
decodingWeightValue
lowerBoundLogProbabilityValue
decodingWeight
lowerBoundLogProbability
_decodingWeightValue
_lowerBoundLogProbabilityValue
_decodingWeight
_lowerBoundLogProbability
T@"NSNumber",R,N,V_decodingWeight
T@"NSNumber",R,N,V_lowerBoundLogProbability
initWithLexicons:characterLanguageModel:wordLanguageModel:
packagedLexiconCursorsUsingContext:
packagedLexiconRootCursors
lexicons
characterLanguageModel
wordLanguageModel
_lexicons
_characterLanguageModel
_wordLanguageModel
T@"CVNLPDecodingLexicons",R,N,V_lexicons
T@"CVNLPDecodingLanguageModel",R,N,V_characterLanguageModel
T@"CVNLPDecodingLanguageModel",R,N,V_wordLanguageModel
initWithOptions:runTimeParams:
dealloc
computeCaptionForImage:outputs:
_run:meanFeatures:attnFeatures:projectedAttnFeatures:
encoderPlan
encoderCtx
encoderNet
meanFeatsBlob
attFeatsBlob
pAttFeatsBlob
meanFeaturesPresent
initWithData:
data
_data
T@"NSData",R,N,V_data
initWithOptions:error:
encodeImage:error:
encodeText:error:
encodeTextAverage:error:
model
modelName
options
.cxx_construct
_modelName
_options
_model
T{shared_ptr<cvnlp::clip::CLIPModel>=^{CLIPModel}^{__shared_weak_count}},R,N,V_model
T@"NSString",R,N,V_modelName
T@"NSDictionary",R,N,V_options
computeCaptionForPixelBuffer:outputs:
_blob_size:
_fill_blob_data:with:
data_dim
description
supportsSecureCoding
copyWithZone:
encodeWithCoder:
initWithCoder:
TB,R
initWithConversationIdentifier:date:direction:text:
hash
isEqual:
conversationIdentifier
date
direction
text
_conversationIdentifier
_date
_text
_direction
T@"NSString",R,C,N,V_conversationIdentifier
T@"NSDate",R,C,N,V_date
Tq,R,N,V_direction
T@"NSString",R,C,N,V_text
defaultTextProvider
setDefaultTextProvider:
T@"CVNLPCommSafetyTextProvider",&
provideTextItemsWithConversationIdentifier:startDate:endDate:progressHandler:
queryForConversationIdentifier:startDate:endDate:
initWithBuffer:domainType:characterObservations:blankIndex:pruningPolicy:
initWithBuffer:indexBuffer:domainType:characterObservations:blankIndex:pruningPolicy:
initWithMultiArray:domainType:characterObservations:blankIndex:pruningPolicy:
initWithMultiArray:characterObservations:blankIndex:pruningPolicy:
initWithMultiArray:indexArray:domainType:characterObservations:blankIndex:pruningPolicy:
timestepCount
observationCount
probabilityForObservationIndex:timestep:
logProbabilityForObservationIndex:timestep:
_valueForObservationIndex:timestep:
blankIndexForTimestep:
probabilityForBlankAtTimestep:
logProbabilityForBlankAtTimestep:
characterIndexForObservationIndex:timestep:
enumerateNonBlankCandidatesInTimestep:block:
_candidateSymbolAtIndex:forTimestep:outputScore:
_enumerateNonBlankCandidatesInTimestep:block:
_sortNonBlankCandidatesForTimestep:
topCandidateForTimestep:outputLogProbability:
topCandidateForTimestep:outputLogProbability:outputIndex:
topCandidateForTimestep:outputProbability:outputIndex:
debugDescription
characterObservations
setCharacterObservations:
blankIndex
setBlankIndex:
domainType
_espressoBuffer
set_espressoBuffer:
_indexBuffer
set_indexBuffer:
_doubleScoreMatrix
set_doubleScoreMatrix:
_multiArray
set_multiArray:
_indexArray
set_indexArray:
_timestepCount
set_timestepCount:
_observationCount
set_observationCount:
_timeStride
set_timeStride:
_observationStride
set_observationStride:
_type
set_type:
_pruningPolicy
set_pruningPolicy:
_cachedPriorityQueueTimestep
set_cachedPriorityQueueTimestep:
_cachedTimesample
set_cachedTimesample:
_isDoubleDataType
set_isDoubleDataType:
_usingIndexes
set_usingIndexes:
_cachedBlankIndexTimestep
_cachedBlankIndex
__isDoubleDataType
__usingIndexes
_characterObservations
_blankIndex
_domainType
__doubleScoreMatrix
__multiArray
__indexArray
__timestepCount
__observationCount
__timeStride
__observationStride
__type
__cachedPriorityQueueTimestep
__cachedTimesample
__cachedBlankIndexTimestep
__cachedBlankIndex
__pruningPolicy
__espressoBuffer
__indexBuffer
T{?=^v^v[4Q][4Q]QQQQQQQQQQi},N,V__espressoBuffer
T{?=^v^v[4Q][4Q]QQQQQQQQQQi},N,V__indexBuffer
T^d,N,V__doubleScoreMatrix
T@"MLMultiArray",&,N,V__multiArray
T@"MLMultiArray",&,N,V__indexArray
Tq,N,V__timestepCount
Tq,N,V__observationCount
Tq,N,V__timeStride
Tq,N,V__observationStride
Tq,N,V__type
T{CVNLPTextDecodingPruningPolicy=qBfI},N,V__pruningPolicy
Tq,V__cachedPriorityQueueTimestep
T^v,V__cachedTimesample
TB,N,V__isDoubleDataType
TB,N,V__usingIndexes
Tq,R,N,V__cachedBlankIndexTimestep
Tq,R,N,V__cachedBlankIndex
T@"NSOrderedSet",&,N,V_characterObservations
Tq,N,V_blankIndex
Tq,R,N,V_domainType
initWithSortedCursors:
enumerateLexiconCursorsSortedByPriorityWithBlock:
count
_sortedCursors
computeCaptionForImageImpl:outputs:
computeCaptionForPixelBufferImpl:outputs:
computeCaptionForVideoPixelBuffer:outputs:
computeCaptionForVideoPixelBufferImpl:outputs:
encoderInputNames
initWithOptions:runtimeParameters:
postProcessCaptions:genderOption:error:
postProcessCaptions:visionObservations:
_excludeGenderReplacements:genderOption:error:
_excludeGenderTriggers:genderOption:error:
_replacements:genderOption:
_checkAboveThreshold:observationConfidence:difference:
_checkForBlockingTokens:blockingTokens:
_checkForBlockingTokens:visionObservations:
_filterVisionObservations:
trimSet
runtimeParameters
_trimSet
_runtimeParameters
T@"NSCharacterSet",R,V_trimSet
T@"CVNLPCaptionRuntimeParameters",R,W,V_runtimeParameters
initWithOptions:
runTimeParams
_runTimeParams
T@"CVNLPCaptionRuntimeParameters",R,N,V_runTimeParams
createBundle
defaultCommitActionBehaviorForLocale:
defaultWhitespaceCommitActionBehavior
defaultCharacterCommitActionBehavior
initWithCommitActionBehavior:
commitActionBlock
setCommitActionBlock:
_commitActionBlock
T@?,N,V_commitActionBlock
initWithCommitActionBehavior:scoringFunction:beamWidth:pathCount:shouldOptimizeAlignment:pruneProblematicMixedScriptWordPaths:shouldApplyWordLMToLastWord:
initWithCommitActionBehavior:scoringFunction:beamWidth:pathCount:shouldOptimizeAlignment:pruneProblematicMixedScriptWordPaths:
initWithCommitActionBehavior:scoringFunction:beamWidth:pathCount:shouldOptimizeAlignment:
initWithCommitActionBehavior:scoringFunction:beamWidth:pathCount:
initWithCommitActionBehavior:beamWidth:pathCount:shouldOptimizeAlignment:
initWithCommitActionBehavior:beamWidth:pathCount:shouldOptimizeAlignment:pruneProblematicMixedScriptWordPaths:
beamWidth
setBeamWidth:
pathCount
setPathCount:
shouldOptimizeAlignment
setShouldOptimizeAlignment:
pruneProblematicMixedScriptWordPaths
setPruneProblematicMixedScriptWordPaths:
shouldApplyWordLMToLastWord
setShouldApplyWordLMToLastWord:
scoringFunction
_shouldOptimizeAlignment
_pruneProblematicMixedScriptWordPaths
_shouldApplyWordLMToLastWord
_beamWidth
_pathCount
_scoringFunction
TQ,N,V_beamWidth
TQ,N,V_pathCount
TB,N,V_shouldOptimizeAlignment
TB,N,V_pruneProblematicMixedScriptWordPaths
TB,N,V_shouldApplyWordLMToLastWord
T@?,R,N,V_scoringFunction
initWithLanguageResourceBundle:
languageResourceBundle
_languageResourceBundle
T@"CVNLPLanguageResourceBundle",R,N,V_languageResourceBundle
_loadRuntimeParameters:
captionModelMinimumConfidence
setCaptionModelMinimumConfidence:
captionModelLengthNormalizationFactor
setCaptionModelLengthNormalizationFactor:
excludeGenderStrategy
setExcludeGenderStrategy:
classifierRevisions
setClassifierRevisions:
sensitiveImageParameters
setSensitiveImageParameters:
replacements
setReplacements:
genderedTokens
setGenderedTokens:
blackListRules
setBlackListRules:
excludeGenderReplacements
setExcludeGenderReplacements:
excludeGenderTriggers
setExcludeGenderTriggers:
genderOption
setGenderOption:
_excludeGenderStrategy
_genderOption
_captionModelMinimumConfidence
_captionModelLengthNormalizationFactor
_classifierRevisions
_sensitiveImageParameters
_replacements
_genderedTokens
_blackListRules
_excludeGenderReplacements
_excludeGenderTriggers
Td,N,V_captionModelMinimumConfidence
Td,N,V_captionModelLengthNormalizationFactor
Ti,N,V_excludeGenderStrategy
T@"NSDictionary",&,N,V_classifierRevisions
T@"NSDictionary",&,N,V_sensitiveImageParameters
T@"NSArray",&,N,V_replacements
T@"NSArray",&,N,V_genderedTokens
T@"NSArray",&,N,V_blackListRules
T@"NSArray",&,N,V_excludeGenderReplacements
T@"NSArray",&,N,V_excludeGenderTriggers
Ti,N,V_genderOption
initWithTokens:score:activationScore:
tokens
setScore:
activationScore
setActivationScore:
_tokens
_activationScore
T@"NSArray",R,N,V_tokens
Td,V_score
Td,V_activationScore
initWithCandidates:
candidates
_candidates
T@"NSArray",R,N,V_candidates
_decodingLanguageModelForLocale:modelType:decodingWeight:lowerBoundLogProbability:type:
decodingLMLanguageModelForLocale:modelType:decodingWeight:
decodingCVNLPLanguageModelForLocale:modelType:decodingWeight:
_normalizedLMTokenIDForWord:withTokenID:sourceLanguageModel:outScore:
_initWithLanguageModel:locale:decodingWeight:lowerBoundLogProbability:type:
initWithLMLanguageModel:locale:decodingWeight:
initWithLMLanguageModel:locale:decodingWeight:lowerBoundLogProbability:
initWithCVNLPLanguageModel:locale:decodingWeight:
initWithCVNLPLanguageModel:locale:decodingWeight:lowerBoundLogProbability:
initWithLanguageModel:locale:
initWithLanguageModel:
lmSPIType
requiredContextLengthForStringLength:
characterTokenIDsForString:
wordTokenIDsForString:outTokenRanges:
locale
languageModel
_lmSPIType
_tokenizer
_locale
_languageModel
T@"NSLocale",R,N,V_locale
T^v,R,N,V_languageModel
initWithResource:andTokenType:
enumerateTokenIDsForText:withBlock:
bosTokenID
eosTokenID
unkTokenID
_vocabTokenizer
_bosTokenID
_eosTokenID
_unkTokenID
TI,R,V_bosTokenID
TI,R,V_eosTokenID
TI,R,V_unkTokenID
_copy_data_from_blob:to:
_copy_data_from_blob:toPtr:
_copy_data_to_blob:to:
_copy_data_to_blob:toBuffer:
_copy_data_to_blob_repeated:to:
performanceResults
perfResults
_perfResults
T@"CVNLPPerformance",R,N,V_perfResults
initWithName:
dict
name
maxpeak
peakdelta
recentpeak
current
cpuTime
cpuInstructions
timeInterval
_name
T@"NSString",R,N,V_name
run:block:
computePerf
results
_computePerf
_results
TB,R,N,V_computePerf
T@"NSMutableDictionary",R,N,V_results
classifyImage:error:
generateClassificationScoresForImage:error:
classifyPixelBuffer:error:
generateClassificationScoresForPixelBuffer:error:
getOperatingPointDataForClassName:error:
processText:inConversationWithIdentifier:date:error:
processConversationsWithStartDate:endDate:previousClassifications:progressHandler:completionHandler:
classifyPixelBuffer:stagedText:inConversationWithIdentifier:error:
classifyPixelBuffer:startDate:endDate:stagedText:inConversationWithIdentifier:error:
performanceStatistics
clientQueue
imageAnalyzer
textAnalyzer
_clientQueue
_imageAnalyzer
_textAnalyzer
T@"NSObject<OS_dispatch_queue>",R,V_clientQueue
T@"CVNLPCommSafetyImageAnalyzer",R,V_imageAnalyzer
T@"CVNLPCommSafetyTextAnalyzer",R,V_textAnalyzer
T@"NSDictionary",R,V_options
applyWordLanguageModelProbabilityToPath:stemmedFromPath:isCommittingToken:
_getQueue
initWithLanguageResourceBundle:scoringFunction:initialCharacterLMState:characterTokenIDs:wordTokenIDs:optimizingAlignment:hasContext:
setCharacterLanguageModelLogProbability:
setWordLanguageModelLogProbability:
setCharacterCount:
setPseudoSpaceCount:
setCharacterLMState:
setLastTokenBoundaryLogProbability:
characterCount
pseudoSpaceCount
tokenCount
modelLogProbability
normalizedTotalLogProbability
lexiconScore
hasProblematicMixedScriptWords
lastTokenBoundaryLogProbability
scoreForTokenIndex:
normalizedActivationLogProbability
latestExpandedSymbolIncludingPseudospace
latestExpandedSymbol
hasExpanded
_currentTokenStringLength
commitTokenAtTimestep:currentSymbolLogProbability:commitAction:string:stemmingFromPath:
tokensWithTimestep:isFinalTimestep:
compare:
merge:logProbCumulator:
updateLastTokenWithMaxActivation:totalLogProbability:tokenBoundaryLogProbability:
childPathWithBlankLogProb:
pathByExtendingWithString:extendedPathString:blankLogProb:nonBlankLogProb:timestep:commitAction:symbolLogProb:
_updateCharacterLanguageModelLogProbabilityForString:stemmingFromPath:normalizedCodepoint:
_updateLexiconLogProbabilityForString:stemmingFromPath:
_wordLanguageModelLogProbabilityForString:originalWordRanges:originalWordIDs:wordRanges:wordIDs:
blankLogProbability
setBlankLogProbability:
nonBlankLogProbability
setNonBlankLogProbability:
historyLexiconLogProbability
setHistoryLexiconLogProbability:
activeWordLexiconLogProbability
setActiveWordLexiconLogProbability:
languageResourceLogProbability
optimizingAlignment
cursors
setCursors:
characterLMState
_tokenString
_histWordTokenIDs
_beginningCurrentWord
_cumulativeTokenLogProbabilities
_tokenBoundaryLogProbabilities
_tokenStringSegmentationPositions
_tokenMaxActivations
_tokenCommitCharacterLengths
_hasContext
_normalizedTotalLogProbability
_latestExpandedSymbolIncludingPseudospace
_hasExpanded
_hasProblematicMixedScriptWords
_hasCalculatedHasProblematicMixedScriptWords
_lastCodeUnitType
_optimizingAlignment
_blankLogProbability
_nonBlankLogProbability
_historyLexiconLogProbability
_activeWordLexiconLogProbability
_languageResourceLogProbability
_cursors
_characterLMState
Td,V_blankLogProbability
Td,V_nonBlankLogProbability
Td,V_historyLexiconLogProbability
Td,V_activeWordLexiconLogProbability
Td,R
Td,R,V_languageResourceLogProbability
TB,R,V_optimizingAlignment
T@"CVNLPLexiconCursors",&,N,V_cursors
T^{CVNLPLanguageModelWithState=},N,V_characterLMState
T@"CVNLPLanguageResourceBundle",R,&,N,V_languageResourceBundle
T@"NSString",R,N
TB,R,N
computeCaptionForImageWithInputs:genderOption:
defaultPathScoringFunctionForLanguageResourceBundle:
defaultPathScoringFunctionForLanguageResourceBundle:pruneProblematicMixedScriptWordPaths:
defaultPathScoringFunction
defaultPathScoringFunctionPruneProblematicMixedScriptWordPaths:
initWithCharacterLanguageModelLogProbability:wordLanguageModelLogProbability:lexiconScore:hasProblematicMixedScriptWords:string:
characterLanguageModelLogProbability
wordLanguageModelLogProbability
_modelLogProbability
_characterLanguageModelLogProbability
_wordLanguageModelLogProbability
_lexiconScore
_characterCount
_pseudoSpaceCount
_tokenCount
Td,R,N,V_modelLogProbability
Td,R,N,V_characterLanguageModelLogProbability
Td,R,N,V_wordLanguageModelLogProbability
Td,R,N,V_lexiconScore
TB,R,N,V_hasProblematicMixedScriptWords
Tq,R,N,V_characterCount
Tq,R,N,V_pseudoSpaceCount
Tq,R,N,V_tokenCount
T@"NSString",R,N,V_string
initWithOptions:modelIndex:runTimeParams:
_loadNetwork:modelIndex:
buildNetworkForSequenceLength:imageFeatures:
copyInputState:
copyOutputState:
runBlockWithCopyInputBlock:copyOutputBlock:
runBlockWithCopyInput:copyOutputBlock:
_runBlockWithCopyOutputBlock:
modelIndex
setModelIndex:
decoderPlan
setDecoderPlan:
decoderCtx
setDecoderCtx:
decoderNet
setDecoderNet:
attFeatsPlaceholderBlob
setAttFeatsPlaceholderBlob:
scaleInput
setScaleInput:
positionInput
setPositionInput:
maskInput
setMaskInput:
blockInput
setBlockInput:
blockOutput
setBlockOutput:
stateOutputEspressoBuffers
setStateOutputEspressoBuffers:
stateInputEspressoBuffers
setStateInputEspressoBuffers:
stateInputEspressoBuffersShape
setStateInputEspressoBuffersShape:
decoderQueue
setDecoderQueue:
nextBlock
setNextBlock:
metricString
setMetricString:
metricCopyString
setMetricCopyString:
decoderInputNames
setDecoderInputNames:
_modelIndex
_decoderPlan
_decoderCtx
_decoderQueue
_nextBlock
_metricString
_metricCopyString
_decoderNet
_stateOutputEspressoBuffers
_stateInputEspressoBuffers
_stateInputEspressoBuffersShape
_decoderInputNames
_attFeatsPlaceholderBlob
_scaleInput
_positionInput
_maskInput
_blockInput
_blockOutput
TQ,N,V_modelIndex
T^v,N,V_decoderPlan
T^v,N,V_decoderCtx
T{?=^vi},N,V_decoderNet
T{?=^v^v[4Q][4Q]QQQQQQQQQQi},N,V_attFeatsPlaceholderBlob
T{?=^v^v[4Q][4Q]QQQQQQQQQQi},N,V_scaleInput
T{?=^v^v[4Q][4Q]QQQQQQQQQQi},N,V_positionInput
T{?=^v^v[4Q][4Q]QQQQQQQQQQi},N,V_maskInput
T{?=^v^v[4Q][4Q]QQQQQQQQQQi},N,V_blockInput
T{?=^v^v[4Q][4Q]QQQQQQQQQQi},N,V_blockOutput
T{map<std::string, std::vector<float>, std::less<std::string>, std::allocator<std::pair<const std::string, std::vector<float>>>>={__tree<std::__value_type<std::string, std::vector<float>>, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<float>>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::vector<float>>>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::vector<float>>, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<float>>, std::less<std::string>, true>>=Q}}},N,V_stateOutputEspressoBuffers
T{map<std::string, std::vector<float>, std::less<std::string>, std::allocator<std::pair<const std::string, std::vector<float>>>>={__tree<std::__value_type<std::string, std::vector<float>>, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<float>>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::vector<float>>>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::vector<float>>, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<float>>, std::less<std::string>, true>>=Q}}},N,V_stateInputEspressoBuffers
T{map<std::string, std::vector<unsigned long>, std::less<std::string>, std::allocator<std::pair<const std::string, std::vector<unsigned long>>>>={__tree<std::__value_type<std::string, std::vector<unsigned long>>, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<unsigned long>>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::vector<unsigned long>>>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::vector<unsigned long>>, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<unsigned long>>, std::less<std::string>, true>>=Q}}},N,V_stateInputEspressoBuffersShape
T@"NSObject<OS_dispatch_queue>",&,N,V_decoderQueue
T@"CVNLPCaptionDecoderBlock",&,N,V_nextBlock
T@"NSString",&,N,V_metricString
T@"NSString",&,N,V_metricCopyString
T{vector<std::string, std::allocator<std::string>>=^v^v{__compressed_pair<std::string *, std::allocator<std::string>>=^v}},N,V_decoderInputNames
_checkIfOnANEDevice
_readOperatingThresholdsDataUsingModelURL:error:
_nameFromRevParts:
_createNameEncodingDict
_createNameDecodingDict
_encodeName:
_decodeName:
getOperatingPointDataForClassName:modelURL:error:
initWithModelURL:options:error:
loadNetworkForURL:espressoEngine:storageType:deviceId:
_extractThresholdForOTGXMain:
computeOutputForImage:error:
_computeOutputForPixelBuffer:error:
_processNetworkOutput:
acceptedOutputIndices
otgxMainThreshold
otgxMainIndex
otgxRetrieveAllClasses
modelUrl
_espressoEngine
_espressoDeviceId
_espressoStorageType
leafProbabilities
_otgxRetrieveAllClasses
__espressoEngine
__espressoDeviceId
__espressoStorageType
_acceptedOutputIndices
_otgxMainThreshold
_otgxMainIndex
_modelUrl
T@"NSDictionary",R,V_acceptedOutputIndices
T@"NSNumber",R,V_otgxMainThreshold
TQ,R,V_otgxMainIndex
TB,R,V_otgxRetrieveAllClasses
T@"NSURL",R,V_modelUrl
Ti,R,V__espressoEngine
Ti,R,V__espressoDeviceId
Ti,R,V__espressoStorageType
addPath:
pathForString:
paths
enumeratePathsWithBlock:
sortedKeys
kBest:discarded:k:shouldUpdateLMState:
mergePathsWithTrailingWhitespaces
applyWordLanguageModelProbabilityToPaths
mutablePaths
setMutablePaths:
_mutablePaths
T@"NSMutableDictionary",&,N,V_mutablePaths
generateCaption:error:
T{shared_ptr<cvnlp::vidcap::VideoCaptioningModel>=^{VideoCaptioningModel}^{__shared_weak_count}},R,N,V_model
stringWithSpaceAtEnds
initWithDictionary:
triggerTokens
_triggerTokens
T@"NSArray",R,V_triggerTokens
classifyImage:
_nsfwRequest
_significantRequest
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
superclass
TQ,R
T#,R
T@"NSString",R,C
decodingResultForKBestPaths:withBeamWidth:
decodingResultForKBestPaths:withBeamWidth:context:
decodingResultWithConfiguration:withContext:
greedyDecodingResult
greedyDecodingResultWithConfiguration:
decodingResultForKBestPaths:withBeamWidth:context:optimizeAlignment:
activationMatrix
setActivationMatrix:
_activationMatrix
T@"CVNLPActivationMatrix",&,N,V_activationMatrix
initWithKey:value:prob:genderOption:
replacementKey
replacementValue
replacementProb
_replacementKey
_replacementValue
_replacementProb
T@"NSString",R,N,V_replacementKey
T@"NSString",R,N,V_replacementValue
Td,R,N,V_replacementProb
T@"NSNumber",R,N,V_genderOption
_loadVocabFile:
_loadNetwork:options:runTimeParams:
_createBeamSearch:runTimeParams:
computeCaptionForImageWithInputsImpl:genderOption:
startID
setStartID:
endID
setEndID:
decoderBatchSize
setDecoderBatchSize:
maxCaptionLen
setMaxCaptionLen:
vocabSize
setVocabSize:
outputVocabSize
setOutputVocabSize:
vocab
setVocab:
decoderBlocks
setDecoderBlocks:
beamSize
setBeamSize:
beamSearch
setBeamSearch:
filterBeamSearch
setFilterBeamSearch:
_startID
_endID
_decoderBatchSize
_maxCaptionLen
_vocabSize
_outputVocabSize
_vocab
_decoderBlocks
_beamSize
_beamSearch
_filterBeamSearch
TQ,N,V_startID
TQ,N,V_endID
TQ,N,V_decoderBatchSize
TQ,N,V_maxCaptionLen
TQ,N,V_vocabSize
TQ,N,V_outputVocabSize
T@"NSDictionary",&,N,V_vocab
T@"NSArray",&,N,V_decoderBlocks
TQ,N,V_beamSize
T^{CVNLPBeamSearch=},N,V_beamSearch
T^{CVNLPBeamSearch=},N,V_filterBeamSearch
_createLexiconForLocale:
decodingLexiconForLocale:
decodingLexiconForLocale:priority:
initWithLexicon:priority:
initWithLexicon:
lexicon
priority
_rootCursor
_lexicon
_priority
__rootCursor
T^{_LXCursor=},R,N,V__rootCursor
Tr^{_LXLexicon=},R,N,V_lexicon
TQ,R,N,V_priority
initWithLexicons:
initWithLexicons:decodingWeight:
initWithLexicons:decodingWeight:lowerBoundLogProbability:
initWithLexicons:decodingWeight:lowerBoundLogProbability:inputNormalizationFunction:
enumerateLexiconsSortedByPriorityWithBlock:
lexiconsForPriority:
packagedLexiconCursorsUsingTextDecodingContext:
inputNormalizationFunction
_sortedLexicons
_inputNormalizationFunction
T^?,R,N,V_inputNormalizationFunction
initWithConversationIdentifier:startDate:endDate:result:
startDate
endDate
result
_startDate
_endDate
_result
T@"NSDate",R,C,N,V_startDate
T@"NSDate",R,C,N,V_endDate
Tq,R,N,V_result
initWithModel:className:threshold:
detectSensitivityForString:
_className
_threshold
initWithModelURL:options:
_classifyString:
classifyString:
processText:inConversationWithIdentifier:startDate:endDate:error:
_classificationForTextItems:conversationIdentifier:
_classificationsForTextItems:previousClassifications:
_models
packBeamID:tokenID:lstmAttnState:lstmLangState:softmax:
extractBeamID:tokenID:lstmAttnState:lstmLangState:fromFollowup:
meanFeatsPlaceholderBlob
pAttFeatsPlaceholderBlob
lstmAttStateFeedBlob
lstmLangStateFeedBlob
inWordIDBlob
wordIDBlob
langProbBlob
newAttStateBlob
newLangStateBlob
initWithHistory:activeRange:
initWithHistory:
activeSubstring
inactiveSubstring
history
activeRange
_history
_activeRange
T@"NSString",R,N,V_history
T{_NSRange=QQ},R,N,V_activeRange
@64@0:8@16@24@32{_NSRange=QQ}40@56
@56@0:8@16@24{_NSRange=QQ}32@48
@52@0:8@16@24{_NSRange=QQ}32B48
@16@0:8
B16@0:8
{_NSRange=QQ}16@0:8
v16@0:8
@"NSString"
@"NSNumber"
{_NSRange="location"Q"length"Q}
@56@0:8@16d24@32@40@48
d16@0:8
@"NSArray"
@24@0:8@16
@32@0:8@16@24
@40@0:8@16@24@32
@"CVNLPDecodingLexicons"
@"CVNLPDecodingLanguageModel"
v32@0:8^{vImage_Buffer=^vQQQ}16^@24
v48@0:8^{vImage_Buffer=^vQQQ}16^@24^@32^@40
{?="plan"^v"network_index"i}
{?="data"^v"reserved"^v"dim"[4Q]"stride"[4Q]"width"Q"height"Q"channels"Q"batch_number"Q"sequence_length"Q"stride_width"Q"stride_height"Q"stride_channels"Q"stride_batch_number"Q"stride_sequence_length"Q"storage_type"i}
@"NSData"
@32@0:8@16^@24
@32@0:8^{__CVBuffer=}16^@24
{shared_ptr<cvnlp::clip::CLIPModel>=^{CLIPModel}^{__shared_weak_count}}16@0:8
@"NSDictionary"
{shared_ptr<cvnlp::clip::CLIPModel>="__ptr_"^{CLIPModel}"__cntrl_"^{__shared_weak_count}}
v32@0:8^{__CVBuffer=}16^@24
Q184@0:8{?=^v^v[4Q][4Q]QQQQQQQQQQi}16
v188@0:8{?=^v^v[4Q][4Q]QQQQQQQQQQi}16f184
[4Q]
@24@0:8^{_NSZone=}16
v24@0:8@16
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
@48@0:8@16@24q32@40
Q16@0:8
B24@0:8@16
q16@0:8
@"NSDate"
v48@0:8@16@24@32@?40
@232@0:8{?=^v^v[4Q][4Q]QQQQQQQQQQi}16q184@192q200{CVNLPTextDecodingPruningPolicy=qBfI}208
@400@0:8{?=^v^v[4Q][4Q]QQQQQQQQQQi}16{?=^v^v[4Q][4Q]QQQQQQQQQQi}184q352@360q368{CVNLPTextDecodingPruningPolicy=qBfI}376
@72@0:8@16q24@32q40{CVNLPTextDecodingPruningPolicy=qBfI}48
@64@0:8@16@24q32{CVNLPTextDecodingPruningPolicy=qBfI}40
@80@0:8@16@24q32@40q48{CVNLPTextDecodingPruningPolicy=qBfI}56
d32@0:8q16q24
q24@0:8q16
d24@0:8q16
q32@0:8q16q24
v32@0:8q16@?24
@40@0:8q16q24^d32
v24@0:8q16
@32@0:8q16^d24
@40@0:8q16^d24^q32
{?=^v^v[4Q][4Q]QQQQQQQQQQi}16@0:8
v184@0:8{?=^v^v[4Q][4Q]QQQQQQQQQQi}16
^d16@0:8
v24@0:8^d16
{CVNLPTextDecodingPruningPolicy=qBfI}16@0:8
v40@0:8{CVNLPTextDecodingPruningPolicy=qBfI}16
^v16@0:8
v24@0:8^v16
v20@0:8B16
@"NSOrderedSet"
@"MLMultiArray"
{CVNLPTextDecodingPruningPolicy="strategy"q"shouldSort"B"threshold"f"maxNumberOfCandidates"I}
@24@0:8^v16
v24@0:8@?16
{vector<const _LXCursor *, std::allocator<const _LXCursor *>>="__begin_"^^{_LXCursor}"__end_"^^{_LXCursor}"__end_cap_"{__compressed_pair<const _LXCursor **, std::allocator<const _LXCursor *>>="__value_"^^{_LXCursor}}}
v32@0:8^v16^@24
{vector<std::string, std::allocator<std::string>>="__begin_"^v"__end_"^v"__end_cap_"{__compressed_pair<std::string *, std::allocator<std::string>>="__value_"^v}}
@36@0:8@16i24^@28
@28@0:8@16i24
B40@0:8@16d24^@32
@"NSCharacterSet"
@"CVNLPCaptionRuntimeParameters"
@?24@0:8@16
@?16@0:8
@24@0:8@?16
@60@0:8@?16@?24Q32Q40B48B52B56
@56@0:8@?16@?24Q32Q40B48B52
@52@0:8@?16@?24Q32Q40B48
@48@0:8@?16@?24Q32Q40
@44@0:8@?16Q24Q32B40
@48@0:8@?16Q24Q32B40B44
v24@0:8Q16
@"CVNLPLanguageResourceBundle"
v24@0:8d16
i16@0:8
v20@0:8i16
@40@0:8@16d24d32
@48@0:8@16i24@28@36i44
@36@0:8@16i24@28
I44@0:8@16I24@28^d36
@52@0:8^v16@24@32@40i48
@40@0:8^v16@24@32
@48@0:8^v16@24@32@40
@40@0:8^{CVNLPLanguageModel=}16@24@32
@48@0:8^{CVNLPLanguageModel=}16@24@32@40
@32@0:8^v16@24
{vector<unsigned int, std::allocator<unsigned int>>=^I^I{__compressed_pair<unsigned int *, std::allocator<unsigned int>>=^I}}24@0:8@16
{vector<unsigned int, std::allocator<unsigned int>>=^I^I{__compressed_pair<unsigned int *, std::allocator<unsigned int>>=^I}}32@0:8@16^@24
@"NSLocale"
v32@0:8@16@?24
I16@0:8
{unique_ptr<cvnlp::AbstractVocabulary, std::default_delete<cvnlp::AbstractVocabulary>>="__ptr_"{__compressed_pair<cvnlp::AbstractVocabulary *, std::default_delete<cvnlp::AbstractVocabulary>>="__value_"^{AbstractVocabulary}}}
v192@0:8{?=^v^v[4Q][4Q]QQQQQQQQQQi}16^v184
v192@0:8{?=^v^v[4Q][4Q]QQQQQQQQQQi}16^f184
v192@0:8^f16{?=^v^v[4Q][4Q]QQQQQQQQQQi}24
v192@0:8@16{?=^v^v[4Q][4Q]QQQQQQQQQQi}24
@"CVNLPPerformance"
@"NSMutableDictionary"
q32@0:8^{CGImage=}16^@24
@32@0:8^{CGImage=}16^@24
q32@0:8^{__CVBuffer=}16^@24
@48@0:8@16@24@32^@40
v56@0:8@16@24@32@?40@?48
@48@0:8^{__CVBuffer=}16@24@32^@40
@64@0:8^{__CVBuffer=}16@24@32@40@48^@56
@"NSObject<OS_dispatch_queue>"
@"CVNLPCommSafetyImageAnalyzer"
@"CVNLPCommSafetyTextAnalyzer"
v36@0:8@16@24B32
@96@0:8@16@?24^{CVNLPLanguageModelWithState=}32{vector<unsigned int, std::allocator<unsigned int>>=^I^I{__compressed_pair<unsigned int *, std::allocator<unsigned int>>=^I}}40{vector<unsigned int, std::allocator<unsigned int>>=^I^I{__compressed_pair<unsigned int *, std::allocator<unsigned int>>=^I}}64B88B92
v24@0:8^{CVNLPLanguageModelWithState=}16
v56@0:8q16d24q32@40@48
@28@0:8q16B24
q24@0:8@16
v40@0:8q16d24d32
@24@0:8d16
@72@0:8@16@24d32d40q48q56d64
v36@0:8@16@24I32
v32@0:8@16@24
f88@0:8@16@24{vector<unsigned int, std::allocator<unsigned int>>=^I^I{__compressed_pair<unsigned int *, std::allocator<unsigned int>>=^I}}32@56{vector<unsigned int, std::allocator<unsigned int>>=^I^I{__compressed_pair<unsigned int *, std::allocator<unsigned int>>=^I}}64
^{CVNLPLanguageModelWithState=}16@0:8
{vector<unsigned int, std::allocator<unsigned int>>="__begin_"^I"__end_"^I"__end_cap_"{__compressed_pair<unsigned int *, std::allocator<unsigned int>>="__value_"^I}}
{vector<double, std::allocator<double>>="__begin_"^d"__end_"^d"__end_cap_"{__compressed_pair<double *, std::allocator<double>>="__value_"^d}}
{vector<unsigned long, std::allocator<unsigned long>>="__begin_"^Q"__end_"^Q"__end_cap_"{__compressed_pair<unsigned long *, std::allocator<unsigned long>>="__value_"^Q}}
@"CVNLPLexiconCursors"
^{CVNLPLanguageModelWithState=}
@?28@0:8@16B24
@?20@0:8B16
@52@0:8d16d24d32B40@44
@40@0:8@16Q24@32
B32@0:8@16Q24
v32@0:8Q16@24
v32@0:8@?16@?24
v32@0:8^f16@?24
{?=^vi}16@0:8
v32@0:8{?=^vi}16
{map<std::string, std::vector<float>, std::less<std::string>, std::allocator<std::pair<const std::string, std::vector<float>>>>={__tree<std::__value_type<std::string, std::vector<float>>, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<float>>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::vector<float>>>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::vector<float>>, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<float>>, std::less<std::string>, true>>=Q}}}16@0:8
v40@0:8{map<std::string, std::vector<float>, std::less<std::string>, std::allocator<std::pair<const std::string, std::vector<float>>>>={__tree<std::__value_type<std::string, std::vector<float>>, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<float>>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::vector<float>>>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::vector<float>>, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<float>>, std::less<std::string>, true>>=Q}}}16
{map<std::string, std::vector<unsigned long>, std::less<std::string>, std::allocator<std::pair<const std::string, std::vector<unsigned long>>>>={__tree<std::__value_type<std::string, std::vector<unsigned long>>, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<unsigned long>>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::vector<unsigned long>>>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::vector<unsigned long>>, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<unsigned long>>, std::less<std::string>, true>>=Q}}}16@0:8
v40@0:8{map<std::string, std::vector<unsigned long>, std::less<std::string>, std::allocator<std::pair<const std::string, std::vector<unsigned long>>>>={__tree<std::__value_type<std::string, std::vector<unsigned long>>, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<unsigned long>>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::vector<unsigned long>>>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::vector<unsigned long>>, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<unsigned long>>, std::less<std::string>, true>>=Q}}}16
{vector<std::string, std::allocator<std::string>>=^v^v{__compressed_pair<std::string *, std::allocator<std::string>>=^v}}16@0:8
v40@0:8{vector<std::string, std::allocator<std::string>>=^v^v{__compressed_pair<std::string *, std::allocator<std::string>>=^v}}16
@"CVNLPCaptionDecoderBlock"
{map<std::string, std::vector<float>, std::less<std::string>, std::allocator<std::pair<const std::string, std::vector<float>>>>="__tree_"{__tree<std::__value_type<std::string, std::vector<float>>, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<float>>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::vector<float>>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::vector<float>>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<float>>, std::less<std::string>, true>>="__value_"Q}}}
{map<std::string, std::vector<unsigned long>, std::less<std::string>, std::allocator<std::pair<const std::string, std::vector<unsigned long>>>>="__tree_"{__tree<std::__value_type<std::string, std::vector<unsigned long>>, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<unsigned long>>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::vector<unsigned long>>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::vector<unsigned long>>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<unsigned long>>, std::less<std::string>, true>>="__value_"Q}}}
@40@0:8@16@24^@32
B36@0:8@16i24i28i32
@32@0:8^{vImage_Buffer=^vQQQ}16^@24
@"NSURL"
v44@0:8^@16^@24Q32B40
{shared_ptr<cvnlp::vidcap::VideoCaptioningModel>=^{VideoCaptioningModel}^{__shared_weak_count}}16@0:8
{shared_ptr<cvnlp::vidcap::VideoCaptioningModel>="__ptr_"^{VideoCaptioningModel}"__cntrl_"^{__shared_weak_count}}
@24@0:8^{__CVBuffer=}16
@"VNVYvzEtX1JlUdu8xx5qhDI"
@"VN6Mb1ME89lyW3HpahkEygIG"
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
@32@0:8Q16Q24
@40@0:8Q16Q24@32
@"CVNLPTextDecodingResult"32@0:8Q16Q24
@"CVNLPTextDecodingResult"40@0:8Q16Q24@"CVNLPTextDecodingContext"32
@"CVNLPTextDecodingResult"32@0:8@"CVNLPTextDecodingBeamSearchConfiguration"16@"CVNLPTextDecodingContext"24
@"CVNLPTextDecodingResult"16@0:8
@"CVNLPTextDecodingResult"24@0:8@"CVNLPTextDecodingConfiguration"16
@44@0:8Q16Q24@32B40
@"CVNLPActivationMatrix"
@48@0:8@16@24d32@40
v40@0:8@16@24@32
^{CVNLPBeamSearch=}16@0:8
v24@0:8^{CVNLPBeamSearch=}16
^{CVNLPBeamSearch=}
r^{_LXLexicon=}24@0:8@16
@32@0:8@16Q24
@32@0:8^{_LXLexicon=}16Q24
@24@0:8^{_LXLexicon=}16
r^{_LXLexicon=}16@0:8
^{_LXCursor=}16@0:8
r^{_LXLexicon=}
^{_LXCursor=}
@48@0:8@16@24@32^?40
@24@0:8Q16
^?16@0:8
@48@0:8@16@24@32q40
@40@0:8@16@24d32
@"NLModel"
@56@0:8@16@24@32@40^@48
@56@0:8@16@24^{?=^v^v[4Q][4Q]QQQQQQQQQQi}32^{?=^v^v[4Q][4Q]QQQQQQQQQQi}40^{?=^v^v[4Q][4Q]QQQQQQQQQQi}48
v56@0:8^@16^@24^{?=^v^v[4Q][4Q]QQQQQQQQQQi}32^{?=^v^v[4Q][4Q]QQQQQQQQQQi}40@48
@40@0:8@16{_NSRange=QQ}24
