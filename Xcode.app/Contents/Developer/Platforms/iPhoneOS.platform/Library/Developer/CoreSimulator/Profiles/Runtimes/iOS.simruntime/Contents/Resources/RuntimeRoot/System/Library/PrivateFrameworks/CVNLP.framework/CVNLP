vector
basic_string
v8@?0
General
TextDecoder
CTCTextDecoder
CVNLPLanguageModel
CVNLPCLIPModel
CVNLPVideoCaptioningModel
com.apple.cvnlp
bolt_id
net_file
vocab_file
vocab_name
output_name
encoder
num_layers
max_seq_len
Expected model_spec.json to contain key: 
seq_len
embed_dim
filterTokens
runtime_parameters.json file exists but does not contain filterTokens: 
encoder_embed
caption_ids
caption_ids_mask
caption_causal_mask
runtime_parameters.json
Filename specified by model_spec.json for video captioning espresso network not found: 
Incorrect data type requested.
[json.exception.
invalid BOM; must be 0xEF 0xBB 0xBF if given
null
invalid literal
invalid string: missing closing quote
invalid string: '\u' must be followed by 4 hex digits
invalid string: surrogate U+DC00..U+DFFF must be followed by U+DC00..U+DFFF
invalid string: surrogate U+DC00..U+DFFF must follow U+D800..U+DBFF
invalid string: forbidden character after backslash
invalid string: control character U+0000 (NUL) must be escaped to \u0000
invalid string: control character U+0001 (SOH) must be escaped to \u0001
invalid string: control character U+0002 (STX) must be escaped to \u0002
invalid string: control character U+0003 (ETX) must be escaped to \u0003
invalid string: control character U+0004 (EOT) must be escaped to \u0004
invalid string: control character U+0005 (ENQ) must be escaped to \u0005
invalid string: control character U+0006 (ACK) must be escaped to \u0006
invalid string: control character U+0007 (BEL) must be escaped to \u0007
invalid string: control character U+0008 (BS) must be escaped to \u0008 or \b
invalid string: control character U+0009 (HT) must be escaped to \u0009 or \t
invalid string: control character U+000A (LF) must be escaped to \u000A or \n
invalid string: control character U+000B (VT) must be escaped to \u000B
invalid string: control character U+000C (FF) must be escaped to \u000C or \f
invalid string: control character U+000D (CR) must be escaped to \u000D or \r
invalid string: control character U+000E (SO) must be escaped to \u000E
invalid string: control character U+000F (SI) must be escaped to \u000F
invalid string: control character U+0010 (DLE) must be escaped to \u0010
invalid string: control character U+0011 (DC1) must be escaped to \u0011
invalid string: control character U+0012 (DC2) must be escaped to \u0012
invalid string: control character U+0013 (DC3) must be escaped to \u0013
invalid string: control character U+0014 (DC4) must be escaped to \u0014
invalid string: control character U+0015 (NAK) must be escaped to \u0015
invalid string: control character U+0016 (SYN) must be escaped to \u0016
invalid string: control character U+0017 (ETB) must be escaped to \u0017
invalid string: control character U+0018 (CAN) must be escaped to \u0018
invalid string: control character U+0019 (EM) must be escaped to \u0019
invalid string: control character U+001A (SUB) must be escaped to \u001A
invalid string: control character U+001B (ESC) must be escaped to \u001B
invalid string: control character U+001C (FS) must be escaped to \u001C
invalid string: control character U+001D (GS) must be escaped to \u001D
invalid string: control character U+001E (RS) must be escaped to \u001E
invalid string: control character U+001F (US) must be escaped to \u001F
invalid string: ill-formed UTF-8 byte
invalid number; expected digit after '-'
invalid number; expected digit after '.'
invalid number; expected '+', '-', or digit after exponent
invalid number; expected digit after exponent sign
object key
object separator
array
object
excessive object size: 
cannot compare iterators of different containers
invalid_iterator
cannot get value
iterator does not fit current value
iterator out of range
cannot use erase() with 
string
boolean
discarded
number
excessive array size: 
<U+%.4X>
parse error
 at line 
, column 
while parsing 
; last read: '
unexpected 
; expected 
<uninitialized>
true literal
false literal
null literal
string literal
number literal
<parse error>
end of input
'[', '{', or a literal
unknown token
[KeyError] 
cannot use operator[] with a string argument with 
type must be string, but is 
type must be number, but is 
type must be array, but is 
[FileNotFoundError] 
%@%@
Error during scaling.
Error code %zd
/System/Library/PrivateFrameworks/CVNLP.framework/lm_vocabulary.plist
/tmp/lm_vocabulary.plist
CVNLPBeamSearch
Could not construct
CVNLPCommSafetyImageSensitivity
CVNLPCommSafetyImageSensitivityScore
CVNLPCommSafetyHandlerImageClassificationScores
CVNLPCaptionScaleMethod
CVNLPCaptionScaleMethodCGInterpolationNone
CVNLPCaptionScaleMethodCGInterpolationLow
CVNLPCaptionScaleMethodCGInterpolationMedium
CVNLPCaptionScaleMethodCGInterpolationHigh
CVNLPCaptionScaleMethodvImage
CVNLPCommSafetyUseCPU
CVNLPCommSafetyUseGPU
CVNLPCommSafetyUseANE
CVNLPCommSafetyUseAnyAvailableDevice
CVNLPCommSafetyUseMTLDevice
CVNLPCommSafetyEnableAllClasses
CVNLPCommSafetyUseImageAnalyzer
CVNLPCommSafetyUseTextAnalyzer
encoder_opt.espresso.net
image
mean_feats
att_feats
p_att_feats
CVNLPVideoCaptioningModelName
CVNLPVideoCaptioningModelEspressoEngine
CVNLPVideoCaptioningModelBeamSearchMaxSteps
CVNLPVideoCaptioningModelBeamSearchBeamWidth
CVNLPVideoCaptioningModelBeamSearchTopK
CVNLPVideoCaptioningModelBeamSearchLengthPenalty
CLIP
Invalid model directory: 
Could not convert
Unrecognized value for engine=
[InvalidArgument] 
+N9mZUAHooNvMiQnjeTJ8g
VNCreateSceneprintRequest
Unable to find class %s
VNImageRequestHandler
CVNLPCaptionError
CVNLPVideoCaptioningModelError
You must override %@ in a subclass
from
%@(%@ <%@> at <%@>: <%@>)
CVNLPCommSafetyTextItem requires keyed coding
CVNLPConversationIdentifier
CVNLPDate
CVNLPDirection
CVNLPText
INSendMessageIntent
com.apple.MobileSMS
CVNLPCommSafetyCDTextProvider event query creation failed: %@
CVNLPCommSafetyCDTextProvider event query execution error: %@
chat
urn:biz:
CVNLPCommSafetyCDTextProvider event query execution failed: %@
_DKKnowledgeStore
_DKEventQuery
_DKSystemEventStreams
_DKQuery
_DKSource
_DKIntentMetadataKey
CVNLPCommSafetyCDTextProvider class initialization failed: %p %p %p %p %p %p
CVNLPCommSafetyCDTextProvider class initialization failed: %@
] Avg vocab subset size over 
 samples: 
; numRetries: 
position
] sampleText: 
/dev/urandom
temperature
InputDimension
SequenceLength
ModelURL
QuantizationParams
QuantizationSchemeName
QuantizationSchemeLinearInt8RangeMin
QuantizationSchemeLinearInt8RangeMax
Unexpected mrlkey: 
Activation Matrix with %ld timesteps, %ld observations 
 t%ld, <B>:%.2f [%ld], sym=%@:%.2f [%ld]
CVNLPCLIPModelName
v3.1
c_network_get_input_names returned null for encoder
Failed to load encoder network
Encode
EncodePx
q24@?0@"NSString"8@"NSString"16
com.apple.CVNLPCLIPModel
Could not find item
com.apple.CVNLP
Default
captionModel
minimumConfidence
lengthNormalizationFactor
excludeGenderStrategy
classifiers
revisions
blockingTokens
categories
replacements
excludeGenderReplacements
excludeGenderTriggers
gender
blacklistTokens
blockingTokensAnnex
replaceKey
replaceWith
replaceProb
genderOption
v44@?0^{__CFURL=}8i16^{__CFLocale=}20^{__CFString=}28^B36
v28@?0r*8q16I24
0123456789
<PS>
v56@?0@"NSString"8{_NSRange=QQ}16{_NSRange=QQ}32^B48
Missing or incorrect bos or eos or unk token in vocabulary file
Unexpected format in Special Map file
Special token shall not appear in vocabulary file
Missing special token class in vocabulary file
Unknown TokenID: 
Special token 
 not found in vocab!
Unknown Token: 
Input text should not contain BOS token!
OutOfVocabularyError: 
bimap<>: invalid key
[%@: Peak-Delta: %lf, CPU-Time: %lf, Interval: %lf]
maxpeak
peakdelta
recentpeak
current
timeInterval
CVNLPExceptionError
caption_queue
classify_queue
Create
Total
Scale
ScalePx
TotalPx
comm_safety_handler
CSModels/ImageModel
CVNLPCommSafetyError
["%@"], modelLogProb=%.8f, logProbTotalNorm=%.8f, logProbBlank=%.8f, logProbNonBlank=%.8f, %lu tokens
["%@"], logProbTotal=%.8f, logProbNormTotal=%.8f, logProbWordLM=%.8f, logProbHistoryLex=%.8f, logProbActiveLex=%.8f, logProbCharacterLM=%.8f, %lu tokens
v24@?0^{_LXCursor=}8^B16
'.-/
com.apple.cvnlp.languagemodeling
d16@?0@"CVNLPTextDecodingPath"8
CVNLPCLIPModelURL
CVNLPCLIPModelEspressoEngine
MRLNeuralNetworkCreate returned nullptr
DictionaryRef_iterator iterator out of range.
decoder_queue
DecodeBlockExecute:%tu
DecodeBlockCopy:%tu
decoder_block%tu_opt.espresso.net
att_feats_placeholder
block_input
block_output
decoder_opt.espresso.net
vanilla_attention
in_word_ids
word_probs
in_word_ids_mask
scale
Failed to load decoder network
self_attention
_k_s_in
_v_s_in
Failed to execute decoder network
60dc96fd80c33771139d6cf90639a776
1.5.0
self ENDSWITH '%@_quantized.espresso.net'
self ENDSWITH '%@_quantized_sqdev.espresso.net'
Could not create espresso context for engine: 
 and device id: 
self ENDSWITH 'operating_thresholds.json'
d61a476a2e70af249c2b1695097eeea9
d9ad80f7b43abb16a607e4361c87bca3
e156d20cabbf6d6cbca2f1f437738097
64c53be656ce81ef8aad95a16847f9ce
c9cc54544693ed5ad6386336207971dd
85a5e1ae11b0353df314fe3763da2c56
58484718d77c0af68837b49bde584d48
63f9d5d4ca6958521ae9de3dcaa6fef6
Name could not be encoded: 
Name could not be decoded: 
class_thresholds
class
index
default
thresholds
59744aeff8
Inference
precision_recall_data
CVNLPBeamSearchSize
CVNLPBeamSearchLengthNormalizationFactor
CVNLPBeamSearchOutputVocabSize
CVNLPBeamSearchOutputVocabPath
CVNLPBeamSearchOutputVocabMap
CVNLPBeamSearchOutputVocabFilterList
CVNLPBeamSearchBlacklistRules
CVNLPBeamEndToken
CVNLPBeamSearchIncludeLanguageModel
CVNLPBeamSearchBeamID
CVNLPBeamSearchNextTokenID
CVNLPBeamSearchNextTokenSoftmaxValues
CVNLPBeamSearchNextTokenMetaData
CVNLPBeamTokens
CVNLPBeamScore
sentencepiece.model
Unable to find vocab file.
d24@?0d8d16
%@ : %.2f
v32@?0@"NSString"8@"CVNLPCTCTextDecodingPath"16^B24
FPS is : %f 
Invalid model URL: 
Received lengthPenalty=
, which is outside the allowed range of [0.0, 10.0]. Please set to a floating point number between 0 and 10.
Unknown error encountered during initWithOptions.
Unknown error encountered during generateCaption.
VNImageBuffer
Key not found in dictionary: 
CVNLPCaption
[UnknownError] 
 %@ 
triggerTokens
@"NSError"16@?0@"VNImageBasedRequest"8
Failed to create s-classifier
Failed to create n-classifier
VisionRequestCreation
VisionPerformRequest
VN6Mb1ME89lyW3HpahkEygIG
VNVYvzEtX1JlUdu8xx5qhDI
CVNLPModelURLKey
CVNLPTokenTypeKey
CVNLPLocaleKey
CVNLPLanguageModelArchitectureKey
CVNLPSamplingBeamSizeKey
CVNLPSamplingMaxLengthKey
CVNLPSamplingMethodKey
CVNLPSamplingNucleusThresholdKey
CVNLPSamplingNumberKey
CVNLPSamplingTopKKey
Missing required key:
model.espresso.bin
Received null token.
Received empty token.
Method
TopK
Number
NucleusThreshold
MaxLength
BeamSize
Unexpected CVNLP key: 
CVNLPLanguageModelWithState
InvalidProbabilityError: expected 
to be in the interval [0, 1].
output_dim
image_encoder
image_size
text_encoder
embed_net_file
main_net_file
embed_output_names
main_input_ids_name
main_input_ids_mask_name
main_output_name
lowercase
bos:eos
text_ids
text_ids_mask
type must be boolean, but is 
CVNLPCaptionTrackPerformance
CVNLPCaptionModelPath
CVNLPCaptionLanguage
CVNLPCaptions
CVNLPGeneratedCaption
CVNLPGeneratedCaptionScore
CVNLPGeneratedCaptionConfidenceLow
CVNLPImageClassificationIdentifiers
CVNLPCaptionModelType
CVNLPCaptionModelLSTM
CVNLPCaptionModelTransformer
CVNLPCaptionEnableGenderedCaptions
CVNLPCaptionFilterTokens
v32@?0@"NSString"8d16^B24
Mismatching vocab file and output vocab sizes
vocab_reverse.json
Decode
DecodeBlock
OneStep
q24@?0@"CVNLPDecodingLexicon"8@"CVNLPDecodingLexicon"16
priority == %lu
v24@?0@"CVNLPDecodingLexicon"8^B16
%@(<%@> from <%@>-<%@> %@)
sensitive
non-sensitive
CVNLPCommSafetyTextClassification requires keyed coding
CVNLPStartDate
CVNLPEndDate
CVNLPResult
%@(%@ %@ > %.2g)
operating_thresholds.json
model_thresholds
threshold
TextClassifier%@.mlmodelc
CVNLPCommSafetyTextAnalyzer item provider error: %@
v32@?0@"NSArray"8@"NSError"16^B24
decoder_opt_pro.espresso.net
mean_feats_placeholder
p_att_feats_placeholder
in_word_id
lstm/att_state_feed
lstm/lang_state_feed
word_id
lang_prob
new_att_state
new_lang_state
lstmAttnStateData
lstmLangStateData
Failed to create espresso context.
Failed to create espresso plan.
Setting plan priorty
Loading espresso Network
Sharing intermediate buffer
Declaring network output
Setting preprocessing params
Building espresso plan
Executing plan
Model has no pre-declared outputs.
Model must have exactly one pre-declared output.
Binding output buffer
Error encountered during: 
 [espresso error: 
unordered_map::at: key not found
PixelBufferTransfer operation [
] failed. Status = 
Image Transfer
Session Creation
PixelBufferTransfer internal inconsistency: null session.
Unsupported espresso type encountered.
Unpacking tensor shape
Failed to allocate aligned memory.
Unknown data type
Unknown data type.
Binding buffer
Unsupported tensor rank: 
Encountered an error during: %s
 -> Espresso Error: %s
Invalid dimensions requested for CVPixelBuffer creation.
Failed to create CVPixelBuffer. Status = 
Failed to lock pixel buffer.
Failed to unlock pixel buffer.
Unsupported CVPixelBuffer type: 
Null CVPixelBuffer encountered.
Binding CVPixelBuffer
Failed to get CVPixelBuffer's data. Ensure the buffer was locked.
precompiled_charsmap is empty.
Normalizer model is not available.
length < 0
norm_to_org and normalized are inconsistent
Trie blob is broken.
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/src/util.h
'result' Must be non NULL
Cannot open 
input ifstream is null
Model file is broken
Model is not initialized.
Normalizer is not initialized.
output container is null
Empty piece is not allowed.
consumed index is out-of-range.
original index is out-of-range.
all normalized characters are not consumed.
output proto is null
NBestEncode returns empty result
nbest_size must be 0 < nbest_size <= 512 or nbest_size < 0.
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/src/sentencepiece_processor.cc
LOG(
ERROR
Returns default value 
</s>
Unknown extra_option type
reverse
option 
 is not available.
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/arenastring.h
CHECK failed: initial_value != NULL: 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/repeated_field.h
CHECK failed: (index) >= (0): 
CHECK failed: (index) < (current_size_): 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/src/model_factory.cc
Unknown model_type: 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/src/char_model.cc
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/src/unigram_model.cc
best_node
nbest_size >= 1. Returns empty result.
Too big agenda. shrinking
(num_nodes) < (trie_results.size())
model file is already precompiled.
No pieces are loaded.
Cannot build double-array.
No entry is found in the trie.
precompiled_trie is empty.
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/third_party/darts_clone/darts.h:776: exception: failed to resize pool: std::bad_alloc
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/third_party/darts_clone/darts.h:1214: exception: failed to insert key: negative value
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/third_party/darts_clone/darts.h:1216: exception: failed to insert key: zero-length key
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/third_party/darts_clone/darts.h:1230: exception: failed to insert key: invalid null character
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/third_party/darts_clone/darts.h:1235: exception: failed to insert key: wrong key order
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/third_party/darts_clone/darts.h:915: exception: failed to build rank index: std::bad_alloc
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/third_party/darts_clone/darts.h:1453: exception: failed to modify unit: too large offset
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/third_party/darts_clone/darts.h:1799: exception: failed to build double-array: invalid null character
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/third_party/darts_clone/darts.h:1801: exception: failed to build double-array: negative value
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/third_party/darts_clone/darts.h:1816: exception: failed to build double-array: wrong key order
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/src/sentencepiece_model.pb.cc
CHECK failed: !model_prefix_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
CHECK failed: !input_format_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
CHECK failed: (&from) != (this): 
sentencepiece.TrainerSpec
CHECK failed: !name_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
CHECK failed: !precompiled_charsmap_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
sentencepiece.NormalizerSpec
CHECK failed: !piece_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
sentencepiece.ModelProto.SentencePiece
CHECK failed: !precompiled_trie_.IsDefault( &::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
CHECK failed: trainer_spec_ != NULL: 
CHECK failed: normalizer_spec_ != NULL: 
sentencepiece.ModelProto
CHECK failed: (n) >= (0): 
down_cast
casts.h
f == NULL || dynamic_cast<To>(f) != NULL
CHECK failed: (&other) != (this): 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/src/model_interface.cc
User defined symbol is not supported.
 is already defined.
!result.empty()
Cancelled
Unknown
Invalid argument
Deadline exceeded
Not found
Already exists
Permission denied
Unauthenticated
Resource exhausted
Failed precondition
Aborted
Out of range
Unimplemented
Internal
Unavailable
Data loss
Unkown code:
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/src/sentencepiece.pb.cc
CHECK failed: !surface_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
sentencepiece.SentencePieceText.SentencePiece
CHECK failed: !text_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
sentencepiece.SentencePieceText
sentencepiece.NBestSentencePieceText
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/src/bpe_model.cc
Invalid character length.
(index) >= (0)
(index) < (static_cast<int>(symbols.size()))
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/src/model_interface.h
Not implemented.
(cannot determine missing fields for lite message)
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/message_lite.cc
CHECK failed: !coded_out.HadError(): 
parse
Can't 
 message of type "
" because it is missing required fields: 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/wire_format_lite.cc
CHECK failed: (value.size()) <= (kint32max): 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/io/coded_stream.cc
A protocol message was rejected because it was too big (more than 
 bytes).  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
CHECK failed: (buffer_size) >= (0): 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/generated_message_util.cc
Not implemented field number 
 with type 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/stubs/common.cc
This program requires version 
 of the Protocol Buffer runtime library, but the installed version is 
.  Please update your library.  If you compiled the program yourself, make sure that your headers are from the same version of Protocol Buffers as your link-time library.  (Version verification failed in "
This program was compiled against version 
 of the Protocol Buffer runtime library, which is not compatible with the installed version (
).  Contact the program author for an update.  If you compiled the program yourself, make sure that your headers are from the same version of Protocol Buffers as your link-time library.  (Version verification failed in "
%d.%d.%d
INFO
WARNING
FATAL
[libprotobuf %s %s:%d] %s
pthread_mutex_lock: 
pthread_mutex_unlock: 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/io/zero_copy_stream.cc
This ZeroCopyOutputStream doesn't support aliasing. Reaching here usually means a ZeroCopyOutputStream implementation bug.
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/io/zero_copy_stream_impl_lite.cc
CHECK failed: (last_returned_size_) > (0): 
BackUp() can only be called after a successful Next().
CHECK failed: (count) <= (last_returned_size_): 
CHECK failed: (count) >= (0): 
CHECK failed: target_ != NULL: 
Cannot allocate buffer larger than kint32max for 
StringOutputStream.
CHECK failed: (count) <= (target_->size()): 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/extension_set.cc
Non-primitive types can't be packed.
can't reach here.
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/arena.cc
CHECK failed: (min_bytes) <= (std::numeric_limits<size_t>::max() - kHeaderSize): 
N5cvnlp4util6InFileE
N5cvnlp4util4PathE
NSt3__110__function6__funcIZN5cvnlp4util6MatrixIfE3rowEmEUlmmE_NS_9allocatorIS6_EEFmmmEEE
NSt3__110__function6__baseIFmmmEEE
N5cvnlp4util8KeyErrorE
N5cvnlp4util20ExceptionWithMessageE
N5cvnlp4util17FileNotFoundErrorE
NSt3__14__fs10filesystem4pathE
N2ik6TensorE
N5cvnlp6vidcap27ExcludeTokenIDsLogitsWarperE
N5cvnlp6vidcap12LogitsWarperE
N8nlohmann6detail11other_errorE
N8nlohmann6detail9exceptionE
N8nlohmann6detail22input_adapter_protocolE
NSt3__117bad_function_callE
N8nlohmann6detail16invalid_iteratorE
NSt3__120__shared_ptr_emplaceIN5cvnlp23SentencePieceVocabularyENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_pointerIPN5cvnlp6vidcap17BeamSearchOptionsENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIN5cvnlp6vidcap17BeamSearchOptionsEEE
ZN5cvnlp4util6MatrixIfE3rowEmEUlmmE_
NSt3__111__end_stateIcEE
NSt3__16__nodeIcEE
NSt3__120__shared_ptr_pointerIPNS_13__empty_stateIcEENS_10shared_ptrIS2_E27__shared_ptr_default_deleteIS2_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrINS_13__empty_stateIcEEE27__shared_ptr_default_deleteIS2_S2_EE
NSt3__113__empty_stateIcEE
NSt3__116__owns_one_stateIcEE
NSt3__115__has_one_stateIcEE
NSt3__120__l_anchor_multilineIcEE
NSt3__120__r_anchor_multilineIcEE
NSt3__115__word_boundaryIcNS_12regex_traitsIcEEEE
NSt3__111__lookaheadIcNS_12regex_traitsIcEEEE
NSt3__123__match_any_but_newlineIcEE
NSt3__118__match_char_icaseIcNS_12regex_traitsIcEEEE
NSt3__120__match_char_collateIcNS_12regex_traitsIcEEEE
NSt3__112__match_charIcEE
NSt3__116__back_ref_icaseIcNS_12regex_traitsIcEEEE
NSt3__118__back_ref_collateIcNS_12regex_traitsIcEEEE
NSt3__110__back_refIcEE
NSt3__120__bracket_expressionIcNS_12regex_traitsIcEEEE
NSt3__128__begin_marked_subexpressionIcEE
NSt3__126__end_marked_subexpressionIcEE
NSt3__16__loopIcEE
NSt3__117__owns_two_statesIcEE
NSt3__117__repeat_one_loopIcEE
NSt3__111__alternateIcEE
NSt3__121__empty_non_own_stateIcEE
NSt3__111__match_anyIcEE
<N5cvnlp4util15InvalidArgumentE
N5cvnlp4util12RuntimeErrorE
NSt3__120__shared_ptr_emplaceIN5cvnlp4clip9CLIPModelENS_9allocatorIS3_EEEE
;N5cvnlp13GreedySamplerE
N5cvnlp20LanguageModelSamplerE
N5cvnlp11TopKSamplerE
N5cvnlp11BeamSamplerE
N5cvnlp14NucleusSamplerE
N5cvnlp20OutOfVocabularyErrorE
N5cvnlp19TokenListVocabularyE
N5cvnlp18AbstractVocabularyE
N5cvnlp23SentencePieceVocabularyE
N5boost10wrapexceptISt12out_of_rangeEE
N5boost16exception_detail10clone_baseE
N5boost9exceptionE
N5cvnlp18CharacterTokenizerE
N5cvnlp17AbstractTokenizerE
N5cvnlp19WhitespaceTokenizerE
vanilla_attention
 ANSt3__120__shared_ptr_emplaceIN5cvnlp6vidcap20VideoCaptioningModelENS_9allocatorIS3_EEEE
N5cvnlp4util12UnknownErrorE
CN5cvnlp23InvalidProbabilityErrorE
N5cvnlp4util4FileE
NSt3__113basic_fstreamIcNS_11char_traitsIcEEEE
NSt3__120__shared_ptr_emplaceIN8nlohmann6detail20input_stream_adapterENS_9allocatorIS3_EEEE
N8nlohmann6detail20input_stream_adapterE
N8nlohmann6detail12out_of_rangeE
N8nlohmann6detail10type_errorE
N8nlohmann6detail11parse_errorE
N5cvnlp4util9DirectoryE
N2ik14InferenceErrorE
N2ik11EspressoNetE
N2ik14EspressoTensorE
NSt3__120__shared_ptr_pointerIPhNS_10shared_ptrIA_hE27__shared_ptr_default_deleteIS3_hEENS_9allocatorIhEEEE
NSt3__110shared_ptrIA_hE27__shared_ptr_default_deleteIS1_hEE
NSt3__120__shared_ptr_emplaceIN2ik21EspressoBufferStorageENS_9allocatorIS2_EEEE
N2ik21EspressoBufferStorageE
N2ik13TensorStorageE
N2ik17PixelBufferTensorE
NSt3__120__shared_ptr_emplaceIN2ik18PixelBufferStorageENS_9allocatorIS2_EEEE
N2ik18PixelBufferStorageE
N13sentencepiece10normalizer10NormalizerE
N5Darts15DoubleArrayImplIvvivEE
N13sentencepiece22SentencePieceProcessorE
N13sentencepiece4word5ModelE
N13sentencepiece9character5ModelE
N13sentencepiece7unigram7LatticeE
N13sentencepiece7unigram9ModelBaseE
N13sentencepiece7unigram5ModelE
N5Darts7Details9ExceptionE
N13sentencepiece11TrainerSpecE
N13sentencepiece14NormalizerSpecE
N13sentencepiece24ModelProto_SentencePieceE
N13sentencepiece10ModelProtoE
NSt3__112basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEE
N13sentencepiece14ModelInterfaceE
N13sentencepiece31SentencePieceText_SentencePieceE
N13sentencepiece17SentencePieceTextE
N13sentencepiece22NBestSentencePieceTextE
N6google8protobuf8internal29InternalMetadataWithArenaBaseINSt3__112basic_stringIcNS3_11char_traitsIcEENS3_9allocatorIcEEEENS1_29InternalMetadataWithArenaLiteEE9ContainerE
N13sentencepiece3bpe5ModelE
N6google8protobuf11MessageLiteE
N6google8protobuf8internal12FieldSkipperE
N6google8protobuf8internal29CodedOutputStreamFieldSkipperE
N6google8protobuf14FatalExceptionE
N6google8protobuf7ClosureE
N6google8protobuf8internal16FunctionClosure0E
N6google8protobuf2io20ZeroCopyOutputStreamE
N6google8protobuf2io17ArrayOutputStreamE
N6google8protobuf2io18StringOutputStreamE
N6google8protobuf8internal15ExtensionFinderE
N6google8protobuf8internal24GeneratedExtensionFinderE
N6google8protobuf13RepeatedFieldIiEE
N6google8protobuf13RepeatedFieldIxEE
N6google8protobuf13RepeatedFieldIjEE
N6google8protobuf13RepeatedFieldIyEE
N6google8protobuf13RepeatedFieldIfEE
N6google8protobuf13RepeatedFieldIdEE
N6google8protobuf13RepeatedFieldIbEE
N6google8protobuf16RepeatedPtrFieldINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEEE
N6google8protobuf8internal20RepeatedPtrFieldBaseE
N6google8protobuf16RepeatedPtrFieldINS0_11MessageLiteEEE
Attempting to parse ModelSpec from JSON path: %s
Performing greedy search, since requested topKPerStep is 1.
Setting Espresso storage type to FLOAT32 since CPU runtime requested.
Setting Espresso storage type to FLOAT16.
sampleTokenIDs(%s, %zu)
EOS encountered in greedySample. Terminating early.
No context provided. Pushing bosID as first tokenID for beam search.
Skipping generation on sample that ends with EOS: %s
All beams contain finished sequences. Exiting beam search loop early after %lu steps
Setting Espresso engine to CPU since ANE is not available and we are investigating issues when running on pre-ANE devices with MPS.
Unknown error encountered during initWithOptions.
Using user-provided CLIP model to encode image instead of Vision.
Unknown error encountered during encodeImage.
Unknown Error encountered during encodeText.
Could not load the contents of file at %@
Could not load the contents of file at %@ as dictionary
Error adding caption rules-file line: %@. Error: %@
Expected token=%s to get converted into single TokenID, but got %zu tokenIDs: %s. Returning UNK TokenID as fallback.
[CVNLPTokenIDConverter] Failed to load token id resources: %s
Input buffer and pixel buffer are both nil
Video Pixel Buffers are empty
Unexpected tokenNormalizedScore issue? got %.8f from tokenScore = %.2f, characterCount = %ld
Default ivs model files not found.
ANE-specific ivs model files not found. Falling back to the default model.
Failed to load encoder network for engine: %d, espresso error: %s
Error during espresso execution: %s
Error during operating point retrieval: %s
Unknown error encountered during initWithOptions. See NSError object for more details.
Received unsupported CFType for locale.
Received unsupported model format. Could be either Montreal or Espresso
Creation options does not contain all required keys.
Unable to determine model locale from options=%@
Locale not supported: %s
Model directory does not exist: %s
Expected output sequence to have dimensions (vocab=%ld, time=%ld), but got (vocab=%ld, time=%ld)
Invalid sampling method: "%s"
Tokenized query=%s into %zu tokens.
CLIP image encoder model file not found!
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:o:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:o:path:/System/Library/Frameworks/Vision.framework/Vision
CVNLPTextDecodingToken
CVNLPCaptionSensitiveImageParameters
CVNLPInformationStream
CVNLPLanguageResourceBundle
CVNLPCaptionEncoderLSTM
CVNLPCLIPEmbedding
CVNLPCLIPModel
CVNLPCaptionEncoder
CVNLPCommSafetyTextItem
NSCopying
NSSecureCoding
NSCoding
CVNLPCommSafetyTextProvider
CVNLPCommSafetyCDTextProvider
CVNLPActivationMatrix
CVNLPLexiconCursors
CVNLPCaptionEncoderTransformer
CVNLPCaptionPostProcessingHandler
CVNLPCaptionModelBase
BundleHelper
CVNLPTextDecodingConfiguration
CVNLPTextDecodingBeamSearchConfiguration
CVNLPTextDecoder
CVNLPCaptionRuntimeParameters
CVNLPTextDecodingResultCandidate
CVNLPTextDecodingResult
CVNLPDecodingLanguageModel
CVNLPTokenIDConverter
CVNLPModelBase
CVNLPPerformanceResult
CVNLPPerformance
CVNLPCommSafetyHandler
CVNLPCTCTextDecodingPath
CVNLPCaptionDecoder
CVNLPTextDecodingPath
CVNLPCaptionDecoderBlock
CVNLPCommSafetyImageAnalyzer
CVNLPCTCBeamState
CVNLPVideoCaptioningModel
CVNLPCaption
CVNLPCaptionRuntimeExcludeGenderTrigger
CVNLPVisionRequestHandler
CVNLPCTCTextDecoder
CVNLPTextDecoding
NSObject
CVNLPCaptionRuntimeReplacements
3@!2
CVNLPCaptionDecoderTransformer
CVNLPDecodingLexicon
CVNLPDecodingLexicons
CVNLPCommSafetyTextClassification
CVNLPCommSafetyTextAnalyzerModel
CVNLPCommSafetyTextAnalyzer
CVNLPCaptionDecoderLSTM
CVNLPTextDecodingContext
T@"NSArray",&,N,V_decoderBlocks
.cxx_destruct
T@"NSString",&,N,V_metricString
T#,R
Tq,R,N,V_result
T@"CVNLPCaptionDecoderBlock",&,N,V_nextBlock
__timestepCount
T@"CVNLPCaptionRuntimeParameters",R,W,V_runtimeParameters
_blackListRules
T@"CVNLPCommSafetyTextAnalyzer",R,V_textAnalyzer
_characterCount
T@"CVNLPDecodingLanguageModel",R,N,V_characterLanguageModel
_decodingWeight
T@"CVNLPDecodingLexicons",R,N,V_lexicons
_espressoEngine
T@"CVNLPLanguageResourceBundle",R,N,V_languageResourceBundle
_hasProblematicMixedScriptWords
T@"CVNLPPerformance",R,N,V_perfResults
_loadVocabFile:
T@"MLMultiArray",&,N,V__multiArray
_models
T@"NSArray",&,N,V_excludeGenderReplacements
_result
T@"NSArray",&,N,V_genderedTokens
_stateInputEspressoBuffersShape
T@"NSArray",R,N,V_blockingTokens
_tokens
T@"NSArray",R,N,V_tokens
activationRange
T@"NSCharacterSet",R,V_trimSet
activeSubstring
T@"NSDate",R,C,N,V_date
allKeys
T@"NSDate",R,C,N,V_startDate
bundleForClass:
T@"NSDictionary",&,N,V_sensitiveImageParameters
computeCaptionForImage:outputs:
T@"NSDictionary",R,N,V_options
content
T@"NSDictionary",R,V_options
cpuInstructions
T@"NSMutableDictionary",&,N,V_mutablePaths
current
T@"NSNumber",R,C,N,V_alignmentScore
dealloc
T@"NSNumber",R,N,V_decodingWeight
defaultPathScoringFunctionPruneProblematicMixedScriptWordPaths:
T@"NSNumber",R,V_otgxMainThreshold
extractBeamID:tokenID:lstmAttnState:lstmLangState:fromFollowup:
T@"NSObject<OS_dispatch_queue>",R,V_clientQueue
initWithLanguageResourceBundle:
T@"NSString",&,N,V_metricCopyString
initWithString:
T@"NSString",R,C,N
isProxy
T@"NSString",R,C,N,V_string
lastTokenBoundaryLogProbability
T@"NSString",R,C,N,V_text
lowercaseString
T@"NSString",R,N,V_history
newAttStateBlob
T@"NSString",R,N,V_name
options
T@"NSString",R,N,V_replacementValue
release
T@"NSString",R,N,V_visionIdentifier
results
T@?,N,V_commitActionBlock
setBlockOutput:
TB,N,V__isDoubleDataType
setRequestedTimeToleranceAfter:
TB,N,V_pruneProblematicMixedScriptWordPaths
set_indexArray:
TB,N,V_shouldOptimizeAlignment
set_timeStride:
TB,R,N
strides
TB,R,N,V_hasPrecedingSpace
valueWithRange:
TB,R,V_optimizingAlignment
.cxx_construct
T@"NSNumber",R,N,V_genderOption
JSONObjectWithData:options:error:
TQ,N,V_beamSize
T@"CVNLPActivationMatrix",&,N,V_activationMatrix
__pruningPolicy
T@"CVNLPCaptionRuntimeParameters",R,N,V_runTimeParams
_alignmentScore
T@"CVNLPCommSafetyImageAnalyzer",R,V_imageAnalyzer
_blockingTokens
T@"CVNLPCommSafetyTextProvider",&
_copy_data_to_blob_repeated:to:
T@"CVNLPDecodingLanguageModel",R,N,V_wordLanguageModel
_espressoBuffer
T@"CVNLPLanguageResourceBundle",R,&,N,V_languageResourceBundle
_genderedTokens
T@"CVNLPLexiconCursors",&,N,V_cursors
_languageResourceLogProbability
T@"MLMultiArray",&,N,V__indexArray
_locale
T@"NSArray",&,N,V_blackListRules
_replacementKey
T@"NSArray",&,N,V_excludeGenderTriggers
_sortedLexicons
T@"NSArray",&,N,V_replacements
_string
T@"NSArray",R,N,V_candidates
_vocabTokenizer
T@"NSArray",R,V_triggerTokens
activationScore
T@"NSData",R,N,V_data
activeWordLexiconLogProbability
T@"NSDate",R,C,N,V_endDate
arrayWithArray:
T@"NSDictionary",&,N,V_classifierRevisions
classifyString:
T@"NSDictionary",&,N,V_vocab
containsString:
T@"NSDictionary",R,V_acceptedOutputIndices
copyInputState:
T@"NSLocale",R,N,V_locale
cpuTime
T@"NSMutableDictionary",R,N,V_results
cursors
T@"NSNumber",R,C,N,V_score
defaultLowerBoundLogProbability
T@"NSNumber",R,N,V_lowerBoundLogProbability
endDate
T@"NSObject<OS_dispatch_queue>",&,N,V_decoderQueue
history
T@"NSOrderedSet",&,N,V_characterObservations
initWithModelURL:options:error:
T@"NSString",R,C
intentsSourceID
T@"NSString",R,C,N,V_conversationIdentifier
keysSortedByValueUsingSelector:
T@"NSString",R,C,N,V_terminatingCharacter
lexicon
T@"NSString",R,N
maxpeak
T@"NSString",R,N,V_modelName
numberWithBool:
T@"NSString",R,N,V_replacementKey
outputVocabSize
T@"NSString",R,N,V_string
replacementProb
T@"NSURL",R,V_modelUrl
scoringFunction
T@?,R,N,V_scoringFunction
setDecoderPlan:
TB,N,V__usingIndexes
setShouldApplyWordLMToLastWord:
TB,N,V_shouldApplyWordLMToLastWord
set_multiArray:
TB,R
startID
TB,R,N,V_computePerf
trimSet
TB,R,N,V_hasProblematicMixedScriptWords
wordLanguageModelLogProbability
TB,R,V_otgxRetrieveAllClasses
TI,R,V_bosTokenID
TI,R,V_eosTokenID
TI,R,V_unkTokenID
TQ,N,V_beamWidth
TQ,N,V_decoderBatchSize
TQ,N,V_endID
TQ,N,V_maxCaptionLen
TQ,N,V_modelIndex
TQ,N,V_outputVocabSize
TQ,N,V_pathCount
TQ,N,V_startID
TQ,N,V_vocabSize
TQ,R
TQ,R,N,V_priority
TQ,R,V_otgxMainIndex
T^?,R,N,V_inputNormalizationFunction
T^d,N,V__doubleScoreMatrix
T^v,N,V_decoderCtx
T^v,N,V_decoderPlan
T^v,R,N,V_languageModel
T^v,V__cachedTimesample
T^{CVNLPBeamSearch=},N,V_beamSearch
T^{CVNLPBeamSearch=},N,V_filterBeamSearch
T^{CVNLPLanguageModelWithState=},N,V_characterLMState
T^{_LXCursor=},R,N,V__rootCursor
Td,N,V_captionModelLengthNormalizationFactor
Td,N,V_captionModelMinimumConfidence
Td,R
Td,R,N,V_characterLanguageModelLogProbability
Td,R,N,V_lexiconScore
Td,R,N,V_minConfidence
Td,R,N,V_modelLogProbability
Td,R,N,V_replacementProb
Td,R,N,V_wordLanguageModelLogProbability
Td,R,V_languageResourceLogProbability
Td,V_activationScore
Td,V_activeWordLexiconLogProbability
Td,V_blankLogProbability
Td,V_historyLexiconLogProbability
Td,V_nonBlankLogProbability
Td,V_score
Ti,N,V_excludeGenderStrategy
Ti,N,V_genderOption
Ti,R,V__espressoDeviceId
Ti,R,V__espressoEngine
Ti,R,V__espressoStorageType
Tq,N,V__observationCount
Tq,N,V__observationStride
Tq,N,V__timeStride
Tq,N,V__timestepCount
Tq,N,V__type
Tq,N,V_blankIndex
Tq,R,N,V__cachedBlankIndex
Tq,R,N,V__cachedBlankIndexTimestep
Tq,R,N,V_characterCount
Tq,R,N,V_direction
Tq,R,N,V_domainType
Tq,R,N,V_pseudoSpaceCount
Tq,R,N,V_tokenCount
Tq,V__cachedPriorityQueueTimestep
Tr^{_LXLexicon=},R,N,V_lexicon
T{?=^v^v[4Q][4Q]QQQQQQQQQQi},N,V__espressoBuffer
T{?=^v^v[4Q][4Q]QQQQQQQQQQi},N,V__indexBuffer
T{?=^v^v[4Q][4Q]QQQQQQQQQQi},N,V_attFeatsPlaceholderBlob
T{?=^v^v[4Q][4Q]QQQQQQQQQQi},N,V_blockInput
T{?=^v^v[4Q][4Q]QQQQQQQQQQi},N,V_blockOutput
T{?=^v^v[4Q][4Q]QQQQQQQQQQi},N,V_maskInput
T{?=^v^v[4Q][4Q]QQQQQQQQQQi},N,V_positionInput
T{?=^v^v[4Q][4Q]QQQQQQQQQQi},N,V_scaleInput
T{?=^vi},N,V_decoderNet
T{CVNLPTextDecodingPruningPolicy=qBfI},N,V__pruningPolicy
T{_NSRange=QQ},R,N,V_activationRange
T{_NSRange=QQ},R,N,V_activeRange
T{map<std::string, std::vector<float>, std::less<std::string>, std::allocator<std::pair<const std::string, std::vector<float>>>>={__tree<std::__value_type<std::string, std::vector<float>>, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<float>>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::vector<float>>>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::vector<float>>, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<float>>, std::less<std::string>, true>>=Q}}},N,V_stateInputEspressoBuffers
T{map<std::string, std::vector<float>, std::less<std::string>, std::allocator<std::pair<const std::string, std::vector<float>>>>={__tree<std::__value_type<std::string, std::vector<float>>, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<float>>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::vector<float>>>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::vector<float>>, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<float>>, std::less<std::string>, true>>=Q}}},N,V_stateOutputEspressoBuffers
T{map<std::string, std::vector<unsigned long>, std::less<std::string>, std::allocator<std::pair<const std::string, std::vector<unsigned long>>>>={__tree<std::__value_type<std::string, std::vector<unsigned long>>, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<unsigned long>>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::vector<unsigned long>>>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::vector<unsigned long>>, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<unsigned long>>, std::less<std::string>, true>>=Q}}},N,V_stateInputEspressoBuffersShape
T{shared_ptr<cvnlp::clip::CLIPModel>=^{CLIPModel}^{__shared_weak_count}},R,N,V_model
T{shared_ptr<cvnlp::vidcap::VideoCaptioningModel>=^{VideoCaptioningModel}^{__shared_weak_count}},R,N,V_model
T{vector<std::string, std::allocator<std::string>>=^v^v{__compressed_pair<std::string *, std::allocator<std::string>>=^v}},N,V_decoderInputNames
URLByAppendingPathComponent:
UTF8String
__cachedBlankIndex
__cachedBlankIndexTimestep
__cachedPriorityQueueTimestep
__cachedTimesample
__doubleScoreMatrix
__espressoBuffer
__espressoDeviceId
__espressoEngine
__espressoStorageType
__indexArray
__indexBuffer
__isDoubleDataType
__multiArray
__observationCount
__observationStride
__rootCursor
__timeStride
__type
__usingIndexes
_acceptedOutputIndices
_activationMatrix
_activationRange
_activationScore
_activeRange
_activeWordLexiconLogProbability
_attFeatsPlaceholderBlob
_beamSearch
_beamSize
_beamWidth
_beginningCurrentWord
_blankIndex
_blankLogProbability
_blob_size:
_blockInput
_blockOutput
_bosTokenID
_cachedBlankIndex
_cachedBlankIndexTimestep
_cachedPriorityQueueTimestep
_cachedTimesample
_candidateSymbolAtIndex:forTimestep:outputScore:
_candidates
_captionModelLengthNormalizationFactor
_captionModelMinimumConfidence
_characterLMState
_characterLanguageModel
_characterLanguageModelLogProbability
_characterObservations
_checkAboveThreshold:observationConfidence:difference:
_checkForBlockingTokens:blockingTokens:
_checkForBlockingTokens:visionObservations:
_checkIfOnANEDevice
_className
_classificationForTextItems:conversationIdentifier:
_classificationsForTextItems:previousClassifications:
_classifierRevisions
_classifyString:
_clientQueue
_commitActionBlock
_computeOutputForPixelBuffer:error:
_computePerf
_conversationIdentifier
_copy_data_from_blob:to:
_copy_data_from_blob:toPtr:
_copy_data_to_blob:to:
_copy_data_to_blob:toBuffer:
_createBeamSearch:runTimeParams:
_createLexiconForLocale:
_createNameDecodingDict
_createNameEncodingDict
_cumulativeTokenLogProbabilities
_currentTokenStringLength
_cursors
_data
_date
_decodeName:
_decoderBatchSize
_decoderBlocks
_decoderCtx
_decoderInputNames
_decoderNet
_decoderPlan
_decoderQueue
_decodingLanguageModelForLocale:modelType:decodingWeight:lowerBoundLogProbability:type:
_decodingWeightValue
_direction
_domainType
_doubleScoreMatrix
_encodeName:
_endDate
_endID
_enumerateNonBlankCandidatesInTimestep:block:
_eosTokenID
_espressoDeviceId
_espressoStorageType
_excludeGenderReplacements
_excludeGenderReplacements:genderOption:error:
_excludeGenderStrategy
_excludeGenderTriggers
_excludeGenderTriggers:genderOption:error:
_extractThresholdForOTGXMain:
_fill_blob_data:with:
_filterBeamSearch
_filterVisionObservations:
_genderOption
_getQueue
_hasCalculatedHasProblematicMixedScriptWords
_hasContext
_hasExpanded
_hasPrecedingSpace
_histWordTokenIDs
_history
_historyLexiconLogProbability
_imageAnalyzer
_indexArray
_indexBuffer
_initWithLanguageModel:locale:decodingWeight:lowerBoundLogProbability:type:
_inputNormalizationFunction
_isDoubleDataType
_languageModel
_languageResourceBundle
_lastCodeUnitType
_latestExpandedSymbolIncludingPseudospace
_lexicon
_lexiconScore
_lexicons
_lmSPIType
_loadNetwork:modelIndex:
_loadNetwork:options:runTimeParams:
_loadRuntimeParameters:
_lowerBoundLogProbability
_lowerBoundLogProbabilityValue
_maskInput
_maxCaptionLen
_metricCopyString
_metricString
_minConfidence
_model
_modelIndex
_modelLogProbability
_modelName
_modelUrl
_multiArray
_mutablePaths
_name
_nameFromRevParts:
_nextBlock
_nonBlankLogProbability
_normalizedLMTokenIDForWord:withTokenID:sourceLanguageModel:outScore:
_normalizedTotalLogProbability
_nsfwRequest
_observationCount
_observationStride
_optimizingAlignment
_options
_otgxMainIndex
_otgxMainThreshold
_otgxRetrieveAllClasses
_outputVocabSize
_pathCount
_perfResults
_positionInput
_priority
_processNetworkOutput:
_pruneProblematicMixedScriptWordPaths
_pruningPolicy
_pseudoSpaceCount
_readOperatingThresholdsDataUsingModelURL:error:
_replacementProb
_replacementValue
_replacements
_replacements:genderOption:
_results
_rootCursor
_run:meanFeatures:attnFeatures:projectedAttnFeatures:
_runBlockWithCopyOutputBlock:
_runTimeParams
_runtimeParameters
_scaleInput
_score
_scoringFunction
_sensitiveImageParameters
_shouldApplyWordLMToLastWord
_shouldOptimizeAlignment
_significantRequest
_sortNonBlankCandidatesForTimestep:
_sortedCursors
_startDate
_startID
_stateInputEspressoBuffers
_stateOutputEspressoBuffers
_terminatingCharacter
_text
_textAnalyzer
_threshold
_timeStride
_timestepCount
_tokenBoundaryLogProbabilities
_tokenCommitCharacterLengths
_tokenCount
_tokenMaxActivations
_tokenString
_tokenStringSegmentationPositions
_tokenizer
_triggerTokens
_trimSet
_type
_unkTokenID
_updateCharacterLanguageModelLogProbabilityForString:stemmingFromPath:normalizedCodepoint:
_updateLexiconLogProbabilityForString:stemmingFromPath:
_usingIndexes
_valueForObservationIndex:timestep:
_visionIdentifier
_vocab
_vocabSize
_wordLanguageModel
_wordLanguageModelLogProbability
_wordLanguageModelLogProbabilityForString:originalWordRanges:originalWordIDs:wordRanges:wordIDs:
acceptedOutputIndices
activationMatrix
activeRange
addEntriesFromDictionary:
addObject:
addObjectsFromArray:
addPath:
alignmentScore
allObjects
allowsKeyedCoding
andPredicateWithSubpredicates:
appIntentsStream
appendFormat:
appendString:
applyWordLanguageModelProbabilityToPath:stemmedFromPath:isCommittingToken:
applyWordLanguageModelProbabilityToPaths
array
arrayWithCapacity:
arrayWithObject:
arrayWithObjects:
arrayWithObjects:count:
attFeatsBlob
attFeatsPlaceholderBlob
autorelease
beamSearch
beamSize
beamWidth
blackListRules
blankIndex
blankIndexForTimestep:
blankLogProbability
blockInput
blockOutput
blockingTokens
boolValue
bosTokenID
bufferWithWidth:height:format:options:error:
buildNetworkForSequenceLength:imageFeatures:
bytes
candidates
captionModelLengthNormalizationFactor
captionModelMinimumConfidence
characterAtIndex:
characterCount
characterIndexForObservationIndex:timestep:
characterLMState
characterLanguageModel
characterLanguageModelLogProbability
characterObservations
characterSetWithCharactersInString:
characterTokenIDsForString:
childPathWithBlankLogProb:
class
classifierRevisions
classifyImage:
classifyImage:error:
classifyPixelBuffer:error:
classifyPixelBuffer:stagedText:inConversationWithIdentifier:error:
classifyPixelBuffer:startDate:endDate:stagedText:inConversationWithIdentifier:error:
clientQueue
code
commitActionBlock
commitTokenAtTimestep:currentSymbolLogProbability:commitAction:string:stemmingFromPath:
compare:
componentsJoinedByString:
componentsSeparatedByCharactersInSet:
computeCaptionForImageImpl:outputs:
computeCaptionForImageWithInputs:genderOption:
computeCaptionForImageWithInputsImpl:genderOption:
computeCaptionForPixelBuffer:outputs:
computeCaptionForPixelBufferImpl:outputs:
computeCaptionForVideoPixelBuffer:outputs:
computeCaptionForVideoPixelBufferImpl:outputs:
computeOutputForImage:error:
computePerf
confidence
conformsToProtocol:
contentsOfDirectoryAtPath:error:
conversationIdentifier
copy
copyCGImageAtTime:actualTime:error:
copyOutputState:
copyWithZone:
count
countByEnumeratingWithState:objects:count:
createBundle
data
dataPointer
dataType
dataUsingEncoding:
dataWithBytes:length:
dataWithBytesNoCopy:length:freeWhenDone:
dataWithContentsOfFile:
dataWithContentsOfURL:
data_dim
date
dateByAddingTimeInterval:
debugDescription
decodeIntegerForKey:
decodeObjectOfClass:forKey:
decoderBatchSize
decoderBlocks
decoderCtx
decoderInputNames
decoderNet
decoderPlan
decoderQueue
decodingCVNLPLanguageModelForLocale:modelType:decodingWeight:
decodingLMLanguageModelForLocale:modelType:decodingWeight:
decodingLexiconForLocale:
decodingLexiconForLocale:priority:
decodingResultForKBestPaths:withBeamWidth:
decodingResultForKBestPaths:withBeamWidth:context:
decodingResultForKBestPaths:withBeamWidth:context:optimizeAlignment:
decodingResultWithConfiguration:withContext:
decodingWeight
decodingWeightValue
defaultCharacterCommitActionBehavior
defaultCommitActionBehaviorForLocale:
defaultDecodingWeight
defaultManager
defaultPathScoringFunction
defaultPathScoringFunctionForLanguageResourceBundle:
defaultPathScoringFunctionForLanguageResourceBundle:pruneProblematicMixedScriptWordPaths:
defaultTextProvider
defaultWhitespaceCommitActionBehavior
description
descriptorData
detectSensitivityForString:
dict
dictionary
dictionaryWithDictionary:
dictionaryWithObjects:forKeys:count:
direction
distantFuture
distantPast
domainType
doubleValue
duration
encodeImage:error:
encodeInteger:forKey:
encodeObject:forKey:
encodeText:error:
encodeTextAverage:error:
encodeWithCoder:
encoderCtx
encoderInputNames
encoderNet
encoderPlan
endID
enumerateKeysAndObjectsUsingBlock:
enumerateLexiconCursorsSortedByPriorityWithBlock:
enumerateLexiconsSortedByPriorityWithBlock:
enumerateNonBlankCandidatesInTimestep:block:
enumeratePathsWithBlock:
enumerateSubstringsInRange:options:usingBlock:
enumerateTokenIDsForText:withBlock:
eosTokenID
errorWithDomain:code:userInfo:
exceptionWithName:reason:userInfo:
excludeGenderReplacements
excludeGenderStrategy
excludeGenderTriggers
executeQuery:error:
fileExistsAtPath:
fileURLWithPath:
fileURLWithPathComponents:
filterBeamSearch
filteredArrayUsingPredicate:
filteredSetUsingPredicate:
firstObject
floatValue
formUnionWithCharacterSet:
fullString
genderOption
genderedTokens
generateCaption:error:
generateClassificationScoresForImage:error:
generateClassificationScoresForPixelBuffer:error:
getBytes:maxLength:usedLength:encoding:options:range:remainingRange:
getOperatingPointDataForClassName:error:
getOperatingPointDataForClassName:modelURL:error:
greedyDecodingResult
greedyDecodingResultWithConfiguration:
hasExpanded
hasPrecedingSpace
hasProblematicMixedScriptWords
hash
historyLexiconLogProbability
identifier
imageAnalyzer
inWordIDBlob
inactiveSubstring
indexOfObject:
init
initWithAsset:
initWithBuffer:domainType:characterObservations:blankIndex:pruningPolicy:
initWithBuffer:indexBuffer:domainType:characterObservations:blankIndex:pruningPolicy:
initWithBytes:length:encoding:
initWithCGImage:options:
initWithCVNLPLanguageModel:locale:decodingWeight:
initWithCVNLPLanguageModel:locale:decodingWeight:lowerBoundLogProbability:
initWithCVPixelBuffer:options:
initWithCandidates:
initWithCharacterLanguageModelLogProbability:wordLanguageModelLogProbability:lexiconScore:hasProblematicMixedScriptWords:string:
initWithCoder:
initWithCommitActionBehavior:
initWithCommitActionBehavior:beamWidth:pathCount:shouldOptimizeAlignment:
initWithCommitActionBehavior:beamWidth:pathCount:shouldOptimizeAlignment:pruneProblematicMixedScriptWordPaths:
initWithCommitActionBehavior:scoringFunction:beamWidth:pathCount:
initWithCommitActionBehavior:scoringFunction:beamWidth:pathCount:shouldOptimizeAlignment:
initWithCommitActionBehavior:scoringFunction:beamWidth:pathCount:shouldOptimizeAlignment:pruneProblematicMixedScriptWordPaths:
initWithCommitActionBehavior:scoringFunction:beamWidth:pathCount:shouldOptimizeAlignment:pruneProblematicMixedScriptWordPaths:shouldApplyWordLMToLastWord:
initWithContentsOfURL:error:
initWithConversationIdentifier:date:direction:text:
initWithConversationIdentifier:startDate:endDate:result:
initWithData:
initWithDecodingWeight:
initWithDecodingWeight:lowerBoundLogProbability:
initWithDictionary:
initWithHistory:
initWithHistory:activeRange:
initWithKey:value:prob:genderOption:
initWithLMLanguageModel:locale:decodingWeight:
initWithLMLanguageModel:locale:decodingWeight:lowerBoundLogProbability:
initWithLanguageModel:
initWithLanguageModel:locale:
initWithLanguageResourceBundle:scoringFunction:initialCharacterLMState:characterTokenIDs:wordTokenIDs:optimizingAlignment:hasContext:
initWithLexicon:
initWithLexicon:priority:
initWithLexicons:
initWithLexicons:characterLanguageModel:wordLanguageModel:
initWithLexicons:decodingWeight:
initWithLexicons:decodingWeight:lowerBoundLogProbability:
initWithLexicons:decodingWeight:lowerBoundLogProbability:inputNormalizationFunction:
initWithModel:className:threshold:
initWithModelURL:options:
initWithMultiArray:characterObservations:blankIndex:pruningPolicy:
initWithMultiArray:domainType:characterObservations:blankIndex:pruningPolicy:
initWithMultiArray:indexArray:domainType:characterObservations:blankIndex:pruningPolicy:
initWithName:
initWithOptions:
initWithOptions:error:
initWithOptions:modelIndex:runTimeParams:
initWithOptions:runTimeParams:
initWithOptions:runtimeParameters:
initWithResource:andTokenType:
initWithSortedCursors:
initWithString:score:activationRange:hasPrecedingSpace:
initWithString:score:activationRange:terminatingCharacter:
initWithString:score:alignmentScore:activationRange:terminatingCharacter:
initWithTokens:score:activationScore:
initWithURL:options:
initWithUTF8String:
initWithVisionIdentifier:minConfidence:commonBlockingTokens:categoryBlockingTokens:categoryBlockingTokensAnnex:
inputNormalizationFunction
intValue
integerValue
intent
intentClass
interaction
invertedSet
isEqual:
isEqualToString:
isKindOfClass:
isMemberOfClass:
kBest:discarded:k:shouldUpdateLMState:
knowledgeStoreWithDirectReadOnlyAccess
langProbBlob
languageCode
languageModel
languageResourceBundle
languageResourceLogProbability
lastObject
lastPathComponent
latestExpandedSymbol
latestExpandedSymbolIncludingPseudospace
leafProbabilities
length
lengthOfBytesUsingEncoding:
letterCharacterSet
lexiconScore
lexicons
lexiconsForPriority:
lmSPIType
loadNetworkForURL:espressoEngine:storageType:deviceId:
locale
localeIdentifier
logProbabilityForBlankAtTimestep:
logProbabilityForObservationIndex:timestep:
lowerBoundLogProbability
lowerBoundLogProbabilityValue
lowercaseLetterCharacterSet
lstmAttStateFeedBlob
lstmLangStateFeedBlob
maskInput
maxCaptionLen
maximumLengthOfBytesUsingEncoding:
meanFeatsBlob
meanFeatsPlaceholderBlob
meanFeaturesPresent
merge:logProbCumulator:
mergePathsWithTrailingWhitespaces
metricCopyString
metricString
minConfidence
model
modelIndex
modelLogProbability
modelName
modelUrl
modelWithContentsOfURL:error:
mutableCopy
mutablePaths
name
newLangStateBlob
nextBlock
nominalFrameRate
nonBlankLogProbability
normalizedActivationLogProbability
normalizedTotalLogProbability
numberWithDouble:
numberWithFloat:
numberWithInt:
numberWithInteger:
numberWithUnsignedInteger:
numberWithUnsignedLong:
objectAtIndex:
objectAtIndexedSubscript:
objectForKey:
objectForKeyedSubscript:
observationCount
optimizingAlignment
otgxMainIndex
otgxMainThreshold
otgxRetrieveAllClasses
pAttFeatsBlob
pAttFeatsPlaceholderBlob
packBeamID:tokenID:lstmAttnState:lstmLangState:softmax:
packagedLexiconCursorsUsingContext:
packagedLexiconCursorsUsingTextDecodingContext:
packagedLexiconRootCursors
path
pathByExtendingWithString:extendedPathString:blankLogProb:nonBlankLogProb:timestep:commitAction:symbolLogProb:
pathCount
pathForResource:ofType:
pathForString:
paths
peakdelta
perfResults
performRequests:error:
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
performanceResults
performanceStatistics
positionInput
postProcessCaptions:genderOption:error:
postProcessCaptions:visionObservations:
predicateForEventsWithEndInDateRangeFrom:to:
predicateForEventsWithSourceID:bundleID:
predicateForEventsWithSourceID:bundleID:groupIDs:
predicateForObjectsWithMetadataKey:andStringValue:
predicateWithFormat:
predictedLabelHypothesesForString:maximumCount:
priority
probabilityForBlankAtTimestep:
probabilityForObservationIndex:timestep:
processConversationsWithStartDate:endDate:previousClassifications:progressHandler:completionHandler:
processIdentifier
processInfo
processText:inConversationWithIdentifier:date:error:
processText:inConversationWithIdentifier:startDate:endDate:error:
provideTextItemsWithConversationIdentifier:startDate:endDate:progressHandler:
pruneProblematicMixedScriptWordPaths
pseudoSpaceCount
punctuationCharacterSet
queryForConversationIdentifier:startDate:endDate:
raise:format:
rangeOfCharacterFromSet:
rangeOfCharacterFromSet:options:range:
rangeOfFirstMatchInString:options:range:
rangeOfString:
rangeOfString:options:range:
rangeValue
recentpeak
regularExpressionWithPattern:options:error:
removeLastObject
removeObjectForKey:
replaceOccurrencesOfString:withString:options:range:
replacementKey
replacementValue
replacements
requiredContextLengthForStringLength:
resourcePath
respondsToSelector:
result
retain
retainCount
run:block:
runBlockWithCopyInput:copyOutputBlock:
runBlockWithCopyInputBlock:copyOutputBlock:
runTimeParams
runtimeParameters
scaleInput
sceneprints
score
scoreForTokenIndex:
self
sensitiveImageParameters
setActivationMatrix:
setActivationScore:
setActiveWordLexiconLogProbability:
setAttFeatsPlaceholderBlob:
setBeamSearch:
setBeamSize:
setBeamWidth:
setBlackListRules:
setBlankIndex:
setBlankLogProbability:
setBlockInput:
setCaptionModelLengthNormalizationFactor:
setCaptionModelMinimumConfidence:
setCharacterCount:
setCharacterLMState:
setCharacterLanguageModelLogProbability:
setCharacterObservations:
setClassifierRevisions:
setCommitActionBlock:
setCursors:
setDecoderBatchSize:
setDecoderBlocks:
setDecoderCtx:
setDecoderInputNames:
setDecoderNet:
setDecoderQueue:
setDefaultTextProvider:
setEndID:
setEventStreams:
setExcludeGenderReplacements:
setExcludeGenderStrategy:
setExcludeGenderTriggers:
setExecuteConcurrently:
setFilterBeamSearch:
setGenderOption:
setGenderedTokens:
setHistoryLexiconLogProbability:
setLastTokenBoundaryLogProbability:
setLimit:
setMaskInput:
setMaxCaptionLen:
setMetricCopyString:
setMetricString:
setModelIndex:
setMutablePaths:
setNextBlock:
setNonBlankLogProbability:
setObject:forKey:
setObject:forKeyedSubscript:
setOffset:
setOutputVocabSize:
setPathCount:
setPositionInput:
setPredicate:
setPruneProblematicMixedScriptWordPaths:
setPseudoSpaceCount:
setReplacements:
setRequestedTimeToleranceBefore:
setRevision:error:
setScaleInput:
setScore:
setSensitiveImageParameters:
setShouldOptimizeAlignment:
setSortDescriptors:
setStartID:
setStateInputEspressoBuffers:
setStateInputEspressoBuffersShape:
setStateOutputEspressoBuffers:
setVocab:
setVocabSize:
setWithArray:
setWordLanguageModelLogProbability:
set_cachedPriorityQueueTimestep:
set_cachedTimesample:
set_doubleScoreMatrix:
set_espressoBuffer:
set_indexBuffer:
set_isDoubleDataType:
set_observationCount:
set_observationStride:
set_pruningPolicy:
set_timestepCount:
set_type:
set_usingIndexes:
shape
shouldApplyWordLMToLastWord
shouldOptimizeAlignment
sortedArrayUsingComparator:
sortedKeys
startDate
startDateSortDescriptorAscending:
stateInputEspressoBuffers
stateInputEspressoBuffersShape
stateOutputEspressoBuffers
string
stringByAppendingString:
stringByDeletingLastPathComponent
stringByDeletingPathExtension
stringByTrimmingCharactersInSet:
stringWithCharacters:length:
stringWithFormat:
stringWithSpaceAtEnds
stringWithUTF8String:
strongToStrongObjectsMapTable
subarrayWithRange:
substringWithRange:
superclass
supportsSecureCoding
terminatingCharacter
text
textAnalyzer
timeInterval
timeIntervalSinceDate:
timestepCount
tokenCount
tokens
tokensWithTimestep:isFinalTimestep:
topCandidateForTimestep:outputLogProbability:
topCandidateForTimestep:outputLogProbability:outputIndex:
topCandidateForTimestep:outputProbability:outputIndex:
tracksWithMediaType:
triggerTokens
unkTokenID
unsignedIntegerValue
updateLastTokenWithMaxActivation:totalLogProbability:tokenBoundaryLogProbability:
uppercaseLetterCharacterSet
userInfo
valueForKey:
visionIdentifier
vocab
vocabSize
whitespaceAndNewlineCharacterSet
whitespaceCharacterSet
wordIDBlob
wordLanguageModel
wordTokenIDsForString:outTokenRanges:
zone
@64@0:8@16@24@32{_NSRange=QQ}40@56
@56@0:8@16@24{_NSRange=QQ}32@48
@52@0:8@16@24{_NSRange=QQ}32B48
@16@0:8
B16@0:8
{_NSRange=QQ}16@0:8
v16@0:8
@"NSString"
@"NSNumber"
{_NSRange="location"Q"length"Q}
@56@0:8@16d24@32@40@48
d16@0:8
@"NSArray"
@24@0:8@16
@32@0:8@16@24
@40@0:8@16@24@32
@"CVNLPDecodingLexicons"
@"CVNLPDecodingLanguageModel"
v32@0:8^{vImage_Buffer=^vQQQ}16^@24
v48@0:8^{vImage_Buffer=^vQQQ}16^@24^@32^@40
{?="plan"^v"network_index"i}
{?="data"^v"reserved"^v"dim"[4Q]"stride"[4Q]"width"Q"height"Q"channels"Q"batch_number"Q"sequence_length"Q"stride_width"Q"stride_height"Q"stride_channels"Q"stride_batch_number"Q"stride_sequence_length"Q"storage_type"i}
@"NSData"
@32@0:8@16^@24
@32@0:8^{__CVBuffer=}16^@24
{shared_ptr<cvnlp::clip::CLIPModel>=^{CLIPModel}^{__shared_weak_count}}16@0:8
@"NSDictionary"
{shared_ptr<cvnlp::clip::CLIPModel>="__ptr_"^{CLIPModel}"__cntrl_"^{__shared_weak_count}}
v32@0:8^{__CVBuffer=}16^@24
Q184@0:8{?=^v^v[4Q][4Q]QQQQQQQQQQi}16
v188@0:8{?=^v^v[4Q][4Q]QQQQQQQQQQi}16f184
[4Q]
@24@0:8^{_NSZone=}16
v24@0:8@16
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
@48@0:8@16@24q32@40
Q16@0:8
B24@0:8@16
q16@0:8
@"NSDate"
v48@0:8@16@24@32@?40
@232@0:8{?=^v^v[4Q][4Q]QQQQQQQQQQi}16q184@192q200{CVNLPTextDecodingPruningPolicy=qBfI}208
@400@0:8{?=^v^v[4Q][4Q]QQQQQQQQQQi}16{?=^v^v[4Q][4Q]QQQQQQQQQQi}184q352@360q368{CVNLPTextDecodingPruningPolicy=qBfI}376
@72@0:8@16q24@32q40{CVNLPTextDecodingPruningPolicy=qBfI}48
@64@0:8@16@24q32{CVNLPTextDecodingPruningPolicy=qBfI}40
@80@0:8@16@24q32@40q48{CVNLPTextDecodingPruningPolicy=qBfI}56
d32@0:8q16q24
q24@0:8q16
d24@0:8q16
q32@0:8q16q24
v32@0:8q16@?24
@40@0:8q16q24^d32
v24@0:8q16
@32@0:8q16^d24
@40@0:8q16^d24^q32
{?=^v^v[4Q][4Q]QQQQQQQQQQi}16@0:8
v184@0:8{?=^v^v[4Q][4Q]QQQQQQQQQQi}16
^d16@0:8
v24@0:8^d16
{CVNLPTextDecodingPruningPolicy=qBfI}16@0:8
v40@0:8{CVNLPTextDecodingPruningPolicy=qBfI}16
^v16@0:8
v24@0:8^v16
v20@0:8B16
@"NSOrderedSet"
@"MLMultiArray"
{CVNLPTextDecodingPruningPolicy="strategy"q"shouldSort"B"threshold"f"maxNumberOfCandidates"I}
@24@0:8^v16
v24@0:8@?16
{vector<const _LXCursor *, std::allocator<const _LXCursor *>>="__begin_"^^{_LXCursor}"__end_"^^{_LXCursor}"__end_cap_"{__compressed_pair<const _LXCursor **, std::allocator<const _LXCursor *>>="__value_"^^{_LXCursor}}}
v32@0:8^v16^@24
{vector<std::string, std::allocator<std::string>>="__begin_"^v"__end_"^v"__end_cap_"{__compressed_pair<std::string *, std::allocator<std::string>>="__value_"^v}}
@36@0:8@16i24^@28
@28@0:8@16i24
B40@0:8@16d24^@32
@"NSCharacterSet"
@"CVNLPCaptionRuntimeParameters"
@?24@0:8@16
@?16@0:8
@24@0:8@?16
@60@0:8@?16@?24Q32Q40B48B52B56
@56@0:8@?16@?24Q32Q40B48B52
@52@0:8@?16@?24Q32Q40B48
@48@0:8@?16@?24Q32Q40
@44@0:8@?16Q24Q32B40
@48@0:8@?16Q24Q32B40B44
v24@0:8Q16
@"CVNLPLanguageResourceBundle"
v24@0:8d16
i16@0:8
v20@0:8i16
@40@0:8@16d24d32
@48@0:8@16i24@28@36i44
@36@0:8@16i24@28
I44@0:8@16I24@28^d36
@52@0:8^v16@24@32@40i48
@40@0:8^v16@24@32
@48@0:8^v16@24@32@40
@40@0:8^{CVNLPLanguageModel=}16@24@32
@48@0:8^{CVNLPLanguageModel=}16@24@32@40
@32@0:8^v16@24
{vector<unsigned int, std::allocator<unsigned int>>=^I^I{__compressed_pair<unsigned int *, std::allocator<unsigned int>>=^I}}24@0:8@16
{vector<unsigned int, std::allocator<unsigned int>>=^I^I{__compressed_pair<unsigned int *, std::allocator<unsigned int>>=^I}}32@0:8@16^@24
@"NSLocale"
v32@0:8@16@?24
I16@0:8
{unique_ptr<cvnlp::AbstractVocabulary, std::default_delete<cvnlp::AbstractVocabulary>>="__ptr_"{__compressed_pair<cvnlp::AbstractVocabulary *, std::default_delete<cvnlp::AbstractVocabulary>>="__value_"^{AbstractVocabulary}}}
v192@0:8{?=^v^v[4Q][4Q]QQQQQQQQQQi}16^v184
v192@0:8{?=^v^v[4Q][4Q]QQQQQQQQQQi}16^f184
v192@0:8^f16{?=^v^v[4Q][4Q]QQQQQQQQQQi}24
v192@0:8@16{?=^v^v[4Q][4Q]QQQQQQQQQQi}24
@"CVNLPPerformance"
@"NSMutableDictionary"
q32@0:8^{CGImage=}16^@24
@32@0:8^{CGImage=}16^@24
q32@0:8^{__CVBuffer=}16^@24
@48@0:8@16@24@32^@40
v56@0:8@16@24@32@?40@?48
@48@0:8^{__CVBuffer=}16@24@32^@40
@64@0:8^{__CVBuffer=}16@24@32@40@48^@56
@"NSObject<OS_dispatch_queue>"
@"CVNLPCommSafetyImageAnalyzer"
@"CVNLPCommSafetyTextAnalyzer"
v36@0:8@16@24B32
@96@0:8@16@?24^{CVNLPLanguageModelWithState=}32{vector<unsigned int, std::allocator<unsigned int>>=^I^I{__compressed_pair<unsigned int *, std::allocator<unsigned int>>=^I}}40{vector<unsigned int, std::allocator<unsigned int>>=^I^I{__compressed_pair<unsigned int *, std::allocator<unsigned int>>=^I}}64B88B92
v24@0:8^{CVNLPLanguageModelWithState=}16
v56@0:8q16d24q32@40@48
@28@0:8q16B24
q24@0:8@16
v40@0:8q16d24d32
@24@0:8d16
@72@0:8@16@24d32d40q48q56d64
v36@0:8@16@24I32
v32@0:8@16@24
f88@0:8@16@24{vector<unsigned int, std::allocator<unsigned int>>=^I^I{__compressed_pair<unsigned int *, std::allocator<unsigned int>>=^I}}32@56{vector<unsigned int, std::allocator<unsigned int>>=^I^I{__compressed_pair<unsigned int *, std::allocator<unsigned int>>=^I}}64
^{CVNLPLanguageModelWithState=}16@0:8
{vector<unsigned int, std::allocator<unsigned int>>="__begin_"^I"__end_"^I"__end_cap_"{__compressed_pair<unsigned int *, std::allocator<unsigned int>>="__value_"^I}}
{vector<double, std::allocator<double>>="__begin_"^d"__end_"^d"__end_cap_"{__compressed_pair<double *, std::allocator<double>>="__value_"^d}}
{vector<unsigned long, std::allocator<unsigned long>>="__begin_"^Q"__end_"^Q"__end_cap_"{__compressed_pair<unsigned long *, std::allocator<unsigned long>>="__value_"^Q}}
@"CVNLPLexiconCursors"
^{CVNLPLanguageModelWithState=}
@?28@0:8@16B24
@?20@0:8B16
@52@0:8d16d24d32B40@44
@40@0:8@16Q24@32
B32@0:8@16Q24
v32@0:8Q16@24
v32@0:8@?16@?24
v32@0:8^f16@?24
{?=^vi}16@0:8
v32@0:8{?=^vi}16
{map<std::string, std::vector<float>, std::less<std::string>, std::allocator<std::pair<const std::string, std::vector<float>>>>={__tree<std::__value_type<std::string, std::vector<float>>, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<float>>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::vector<float>>>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::vector<float>>, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<float>>, std::less<std::string>, true>>=Q}}}16@0:8
v40@0:8{map<std::string, std::vector<float>, std::less<std::string>, std::allocator<std::pair<const std::string, std::vector<float>>>>={__tree<std::__value_type<std::string, std::vector<float>>, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<float>>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::vector<float>>>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::vector<float>>, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<float>>, std::less<std::string>, true>>=Q}}}16
{map<std::string, std::vector<unsigned long>, std::less<std::string>, std::allocator<std::pair<const std::string, std::vector<unsigned long>>>>={__tree<std::__value_type<std::string, std::vector<unsigned long>>, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<unsigned long>>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::vector<unsigned long>>>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::vector<unsigned long>>, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<unsigned long>>, std::less<std::string>, true>>=Q}}}16@0:8
v40@0:8{map<std::string, std::vector<unsigned long>, std::less<std::string>, std::allocator<std::pair<const std::string, std::vector<unsigned long>>>>={__tree<std::__value_type<std::string, std::vector<unsigned long>>, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<unsigned long>>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::vector<unsigned long>>>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::vector<unsigned long>>, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<unsigned long>>, std::less<std::string>, true>>=Q}}}16
{vector<std::string, std::allocator<std::string>>=^v^v{__compressed_pair<std::string *, std::allocator<std::string>>=^v}}16@0:8
v40@0:8{vector<std::string, std::allocator<std::string>>=^v^v{__compressed_pair<std::string *, std::allocator<std::string>>=^v}}16
@"CVNLPCaptionDecoderBlock"
{map<std::string, std::vector<float>, std::less<std::string>, std::allocator<std::pair<const std::string, std::vector<float>>>>="__tree_"{__tree<std::__value_type<std::string, std::vector<float>>, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<float>>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::vector<float>>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::vector<float>>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<float>>, std::less<std::string>, true>>="__value_"Q}}}
{map<std::string, std::vector<unsigned long>, std::less<std::string>, std::allocator<std::pair<const std::string, std::vector<unsigned long>>>>="__tree_"{__tree<std::__value_type<std::string, std::vector<unsigned long>>, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<unsigned long>>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::vector<unsigned long>>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::vector<unsigned long>>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<unsigned long>>, std::less<std::string>, true>>="__value_"Q}}}
@40@0:8@16@24^@32
B36@0:8@16i24i28i32
@32@0:8^{vImage_Buffer=^vQQQ}16^@24
@"NSURL"
v44@0:8^@16^@24Q32B40
{shared_ptr<cvnlp::vidcap::VideoCaptioningModel>=^{VideoCaptioningModel}^{__shared_weak_count}}16@0:8
{shared_ptr<cvnlp::vidcap::VideoCaptioningModel>="__ptr_"^{VideoCaptioningModel}"__cntrl_"^{__shared_weak_count}}
@24@0:8^{__CVBuffer=}16
@"VNVYvzEtX1JlUdu8xx5qhDI"
@"VN6Mb1ME89lyW3HpahkEygIG"
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
@32@0:8Q16Q24
@40@0:8Q16Q24@32
@"CVNLPTextDecodingResult"32@0:8Q16Q24
@"CVNLPTextDecodingResult"40@0:8Q16Q24@"CVNLPTextDecodingContext"32
@"CVNLPTextDecodingResult"32@0:8@"CVNLPTextDecodingBeamSearchConfiguration"16@"CVNLPTextDecodingContext"24
@"CVNLPTextDecodingResult"16@0:8
@"CVNLPTextDecodingResult"24@0:8@"CVNLPTextDecodingConfiguration"16
@44@0:8Q16Q24@32B40
@"CVNLPActivationMatrix"
@48@0:8@16@24d32@40
v40@0:8@16@24@32
^{CVNLPBeamSearch=}16@0:8
v24@0:8^{CVNLPBeamSearch=}16
^{CVNLPBeamSearch=}
r^{_LXLexicon=}24@0:8@16
@32@0:8@16Q24
@32@0:8^{_LXLexicon=}16Q24
@24@0:8^{_LXLexicon=}16
r^{_LXLexicon=}16@0:8
^{_LXCursor=}16@0:8
r^{_LXLexicon=}
^{_LXCursor=}
@48@0:8@16@24@32^?40
@24@0:8Q16
^?16@0:8
@48@0:8@16@24@32q40
@40@0:8@16@24d32
@"NLModel"
@56@0:8@16@24@32@40^@48
@56@0:8@16@24^{?=^v^v[4Q][4Q]QQQQQQQQQQi}32^{?=^v^v[4Q][4Q]QQQQQQQQQQi}40^{?=^v^v[4Q][4Q]QQQQQQQQQQi}48
v56@0:8^@16^@24^{?=^v^v[4Q][4Q]QQQQQQQQQQi}32^{?=^v^v[4Q][4Q]QQQQQQQQQQi}40@48
@40@0:8@16{_NSRange=QQ}24
vector
basic_string
v8@?0
General
TextDecoder
CTCTextDecoder
CVNLPLanguageModel
CVNLPCLIPModel
CVNLPVideoCaptioningModel
com.apple.cvnlp
bolt_id
net_file
vocab_file
vocab_name
output_name
encoder
num_layers
max_seq_len
Expected model_spec.json to contain key: 
seq_len
embed_dim
filterTokens
runtime_parameters.json file exists but does not contain filterTokens: 
encoder_embed
caption_ids
caption_ids_mask
caption_causal_mask
model_spec.json
runtime_parameters.json
Filename specified by model_spec.json for video captioning espresso network not found: 
Incorrect data type requested.
[json.exception.
invalid BOM; must be 0xEF 0xBB 0xBF if given
null
invalid literal
invalid string: missing closing quote
invalid string: '\u' must be followed by 4 hex digits
invalid string: surrogate U+DC00..U+DFFF must be followed by U+DC00..U+DFFF
invalid string: surrogate U+DC00..U+DFFF must follow U+D800..U+DBFF
invalid string: forbidden character after backslash
invalid string: control character U+0000 (NUL) must be escaped to \u0000
invalid string: control character U+0001 (SOH) must be escaped to \u0001
invalid string: control character U+0002 (STX) must be escaped to \u0002
invalid string: control character U+0003 (ETX) must be escaped to \u0003
invalid string: control character U+0004 (EOT) must be escaped to \u0004
invalid string: control character U+0005 (ENQ) must be escaped to \u0005
invalid string: control character U+0006 (ACK) must be escaped to \u0006
invalid string: control character U+0007 (BEL) must be escaped to \u0007
invalid string: control character U+0008 (BS) must be escaped to \u0008 or \b
invalid string: control character U+0009 (HT) must be escaped to \u0009 or \t
invalid string: control character U+000A (LF) must be escaped to \u000A or \n
invalid string: control character U+000B (VT) must be escaped to \u000B
invalid string: control character U+000C (FF) must be escaped to \u000C or \f
invalid string: control character U+000D (CR) must be escaped to \u000D or \r
invalid string: control character U+000E (SO) must be escaped to \u000E
invalid string: control character U+000F (SI) must be escaped to \u000F
invalid string: control character U+0010 (DLE) must be escaped to \u0010
invalid string: control character U+0011 (DC1) must be escaped to \u0011
invalid string: control character U+0012 (DC2) must be escaped to \u0012
invalid string: control character U+0013 (DC3) must be escaped to \u0013
invalid string: control character U+0014 (DC4) must be escaped to \u0014
invalid string: control character U+0015 (NAK) must be escaped to \u0015
invalid string: control character U+0016 (SYN) must be escaped to \u0016
invalid string: control character U+0017 (ETB) must be escaped to \u0017
invalid string: control character U+0018 (CAN) must be escaped to \u0018
invalid string: control character U+0019 (EM) must be escaped to \u0019
invalid string: control character U+001A (SUB) must be escaped to \u001A
invalid string: control character U+001B (ESC) must be escaped to \u001B
invalid string: control character U+001C (FS) must be escaped to \u001C
invalid string: control character U+001D (GS) must be escaped to \u001D
invalid string: control character U+001E (RS) must be escaped to \u001E
invalid string: control character U+001F (US) must be escaped to \u001F
invalid string: ill-formed UTF-8 byte
invalid number; expected digit after '-'
invalid number; expected digit after '.'
invalid number; expected '+', '-', or digit after exponent
invalid number; expected digit after exponent sign
object key
object separator
array
object
excessive object size: 
cannot compare iterators of different containers
invalid_iterator
cannot get value
iterator does not fit current value
iterator out of range
cannot use erase() with 
type_error
string
boolean
discarded
number
excessive array size: 
out_of_range
<U+%.4X>
parse_error
parse error
 at line 
, column 
syntax error 
while parsing 
; last read: '
unexpected 
; expected 
<uninitialized>
true literal
false literal
null literal
string literal
number literal
<parse error>
end of input
'[', '{', or a literal
unknown token
[KeyError] 
cannot use operator[] with a string argument with 
type must be string, but is 
type must be number, but is 
type must be array, but is 
[FileNotFoundError] 
%@%@
Error during scaling.
Error code %zd
/System/Library/PrivateFrameworks/CVNLP.framework/lm_vocabulary.plist
/tmp/lm_vocabulary.plist
CVNLPBeamSearch
Could not construct
CVNLPCommSafetyImageSensitivity
CVNLPCommSafetyImageSensitivityScore
CVNLPCommSafetyHandlerImageClassificationScores
CVNLPCaptionScaleMethod
CVNLPCaptionScaleMethodCGInterpolationNone
CVNLPCaptionScaleMethodCGInterpolationLow
CVNLPCaptionScaleMethodCGInterpolationMedium
CVNLPCaptionScaleMethodCGInterpolationHigh
CVNLPCaptionScaleMethodvImage
CVNLPCommSafetyUseCPU
CVNLPCommSafetyUseGPU
CVNLPCommSafetyUseANE
CVNLPCommSafetyUseAnyAvailableDevice
CVNLPCommSafetyUseMTLDevice
CVNLPCommSafetyEnableAllClasses
CVNLPCommSafetyUseImageAnalyzer
CVNLPCommSafetyUseTextAnalyzer
encoder_opt.espresso.net
image
mean_feats
att_feats
p_att_feats
CVNLPVideoCaptioningModelName
CVNLPVideoCaptioningModelEspressoEngine
CVNLPVideoCaptioningModelBeamSearchMaxSteps
CVNLPVideoCaptioningModelBeamSearchBeamWidth
CVNLPVideoCaptioningModelBeamSearchTopK
CVNLPVideoCaptioningModelBeamSearchLengthPenalty
CLIP
Invalid model directory: 
Could not convert
Unrecognized value for engine=
[InvalidArgument] 
+N9mZUAHooNvMiQnjeTJ8g
VNCreateSceneprintRequest
Unable to find class %s
VNImageRequestHandler
CVNLPCaptionError
CVNLPVideoCaptioningModelError
You must override %@ in a subclass
from
%@(%@ <%@> at <%@>: <%@>)
CVNLPCommSafetyTextItem requires keyed coding
CVNLPConversationIdentifier
CVNLPDate
CVNLPDirection
CVNLPText
INSendMessageIntent
com.apple.MobileSMS
CVNLPCommSafetyCDTextProvider event query creation failed: %@
CVNLPCommSafetyCDTextProvider event query execution error: %@
chat
urn:biz:
CVNLPCommSafetyCDTextProvider event query execution failed: %@
_DKKnowledgeStore
_DKEventQuery
_DKSystemEventStreams
_DKQuery
_DKSource
_DKIntentMetadataKey
CVNLPCommSafetyCDTextProvider class initialization failed: %p %p %p %p %p %p
CVNLPCommSafetyCDTextProvider class initialization failed: %@
] Avg vocab subset size over 
 samples: 
; numRetries: 
position
] sampleText: 
/dev/urandom
temperature
InputDimension
SequenceLength
ModelURL
QuantizationParams
QuantizationSchemeName
QuantizationSchemeLinearInt8RangeMin
QuantizationSchemeLinearInt8RangeMax
Unexpected mrlkey: 
Activation Matrix with %ld timesteps, %ld observations 
 t%ld, <B>:%.2f [%ld], sym=%@:%.2f [%ld]
CVNLPCLIPModelName
v3.1
c_network_get_input_names returned null for encoder
Failed to load encoder network
Encode
EncodePx
q24@?0@"NSString"8@"NSString"16
com.apple.CVNLPCLIPModel
Could not find item
com.apple.CVNLP
Default
captionModel
minimumConfidence
lengthNormalizationFactor
excludeGenderStrategy
classifiers
revisions
blockingTokens
categories
replacements
excludeGenderReplacements
excludeGenderTriggers
gender
blacklistTokens
blockingTokensAnnex
replaceKey
replaceWith
replaceProb
genderOption
v44@?0^{__CFURL=}8i16^{__CFLocale=}20^{__CFString=}28^B36
v28@?0r*8q16I24
0123456789
<PS>
v56@?0@"NSString"8{_NSRange=QQ}16{_NSRange=QQ}32^B48
Missing or incorrect bos or eos or unk token in vocabulary file
Unexpected format in Special Map file
Special token shall not appear in vocabulary file
Missing special token class in vocabulary file
Unknown TokenID: 
Special token 
 not found in vocab!
Unknown Token: 
Input text should not contain BOS token!
OutOfVocabularyError: 
bimap<>: invalid key
[%@: Peak-Delta: %lf, CPU-Time: %lf, Interval: %lf]
maxpeak
peakdelta
recentpeak
current
timeInterval
CVNLPExceptionError
caption_queue
classify_queue
Create
Total
Scale
ScalePx
TotalPx
comm_safety_handler
CSModels/ImageModel
CVNLPCommSafetyError
["%@"], modelLogProb=%.8f, logProbTotalNorm=%.8f, logProbBlank=%.8f, logProbNonBlank=%.8f, %lu tokens
["%@"], logProbTotal=%.8f, logProbNormTotal=%.8f, logProbWordLM=%.8f, logProbHistoryLex=%.8f, logProbActiveLex=%.8f, logProbCharacterLM=%.8f, %lu tokens
v24@?0^{_LXCursor=}8^B16
'.-/
com.apple.cvnlp.languagemodeling
d16@?0@"CVNLPTextDecodingPath"8
CVNLPCLIPModelURL
CVNLPCLIPModelEspressoEngine
MRLNeuralNetworkCreate returned nullptr
DictionaryRef_iterator iterator out of range.
decoder_queue
DecodeBlockExecute:%tu
DecodeBlockCopy:%tu
decoder_block%tu_opt.espresso.net
att_feats_placeholder
block_input
block_output
decoder_opt.espresso.net
vanilla_attention
in_word_ids
word_probs
in_word_ids_mask
scale
Failed to load decoder network
self_attention
_k_s_in
_v_s_in
Failed to execute decoder network
60dc96fd80c33771139d6cf90639a776
1.5.0
self ENDSWITH '%@_quantized.espresso.net'
self ENDSWITH '%@_quantized_sqdev.espresso.net'
Could not create espresso context for engine: 
 and device id: 
self ENDSWITH 'operating_thresholds.json'
d61a476a2e70af249c2b1695097eeea9
d9ad80f7b43abb16a607e4361c87bca3
e156d20cabbf6d6cbca2f1f437738097
64c53be656ce81ef8aad95a16847f9ce
c9cc54544693ed5ad6386336207971dd
85a5e1ae11b0353df314fe3763da2c56
58484718d77c0af68837b49bde584d48
63f9d5d4ca6958521ae9de3dcaa6fef6
Name could not be encoded: 
Name could not be decoded: 
class_thresholds
class
index
default
thresholds
59744aeff8
Inference
precision_recall_data
CVNLPBeamSearchSize
CVNLPBeamSearchLengthNormalizationFactor
CVNLPBeamSearchOutputVocabSize
CVNLPBeamSearchOutputVocabPath
CVNLPBeamSearchOutputVocabMap
CVNLPBeamSearchOutputVocabFilterList
CVNLPBeamSearchBlacklistRules
CVNLPBeamEndToken
CVNLPBeamSearchIncludeLanguageModel
CVNLPBeamSearchBeamID
CVNLPBeamSearchNextTokenID
CVNLPBeamSearchNextTokenSoftmaxValues
CVNLPBeamSearchNextTokenMetaData
CVNLPBeamTokens
CVNLPBeamScore
vocab.txt
special_map.txt
sentencepiece.model
Unable to find vocab file.
d24@?0d8d16
%@ : %.2f
v32@?0@"NSString"8@"CVNLPCTCTextDecodingPath"16^B24
FPS is : %f 
Invalid model URL: 
Received lengthPenalty=
, which is outside the allowed range of [0.0, 10.0]. Please set to a floating point number between 0 and 10.
Unknown error encountered during initWithOptions.
Unknown error encountered during generateCaption.
VNImageBuffer
Key not found in dictionary: 
CVNLPCaption
[UnknownError] 
 %@ 
triggerTokens
@"NSError"16@?0@"VNImageBasedRequest"8
Failed to create s-classifier
Failed to create n-classifier
VisionRequestCreation
VisionPerformRequest
VN6Mb1ME89lyW3HpahkEygIG
VNVYvzEtX1JlUdu8xx5qhDI
CVNLPModelURLKey
CVNLPTokenTypeKey
CVNLPLocaleKey
CVNLPLanguageModelArchitectureKey
CVNLPSamplingBeamSizeKey
CVNLPSamplingMaxLengthKey
CVNLPSamplingMethodKey
CVNLPSamplingNucleusThresholdKey
CVNLPSamplingNumberKey
CVNLPSamplingTopKKey
Missing required key:
model.dat
model.espresso.bin
Received null token.
Received empty token.
Method
TopK
Number
NucleusThreshold
MaxLength
BeamSize
Unexpected CVNLP key: 
CVNLPLanguageModelWithState
InvalidProbabilityError: expected 
to be in the interval [0, 1].
output_dim
image_encoder
image_size
text_encoder
embed_net_file
main_net_file
embed_output_names
main_input_ids_name
main_input_ids_mask_name
main_output_name
lowercase
bos:eos
text_ids
text_ids_mask
type must be boolean, but is 
CVNLPCaptionTrackPerformance
CVNLPCaptionModelPath
CVNLPCaptionLanguage
CVNLPCaptions
CVNLPGeneratedCaption
CVNLPGeneratedCaptionScore
CVNLPGeneratedCaptionConfidenceLow
CVNLPImageClassificationIdentifiers
CVNLPCaptionModelType
CVNLPCaptionModelLSTM
CVNLPCaptionModelTransformer
CVNLPCaptionEnableGenderedCaptions
CVNLPCaptionFilterTokens
v32@?0@"NSString"8d16^B24
Mismatching vocab file and output vocab sizes
vocab_reverse.json
Decode
DecodeBlock
OneStep
q24@?0@"CVNLPDecodingLexicon"8@"CVNLPDecodingLexicon"16
priority == %lu
v24@?0@"CVNLPDecodingLexicon"8^B16
%@(<%@> from <%@>-<%@> %@)
sensitive
non-sensitive
CVNLPCommSafetyTextClassification requires keyed coding
CVNLPStartDate
CVNLPEndDate
CVNLPResult
%@(%@ %@ > %.2g)
operating_thresholds.json
model_thresholds
threshold
TextClassifier%@.mlmodelc
CVNLPCommSafetyTextAnalyzer item provider error: %@
v32@?0@"NSArray"8@"NSError"16^B24
decoder_opt_pro.espresso.net
mean_feats_placeholder
p_att_feats_placeholder
in_word_id
lstm/att_state_feed
lstm/lang_state_feed
word_id
lang_prob
new_att_state
new_lang_state
lstmAttnStateData
lstmLangStateData
Failed to create espresso context.
Failed to create espresso plan.
Setting plan priorty
Loading espresso Network
Sharing intermediate buffer
Declaring network output
Setting preprocessing params
Building espresso plan
Executing plan
Model has no pre-declared outputs.
Model must have exactly one pre-declared output.
Binding output buffer
Error encountered during: 
 [espresso error: 
unordered_map::at: key not found
PixelBufferTransfer operation [
] failed. Status = 
Image Transfer
Session Creation
PixelBufferTransfer internal inconsistency: null session.
Unsupported espresso type encountered.
Unpacking tensor shape
Failed to allocate aligned memory.
Unknown data type
Unknown data type.
Binding buffer
Unsupported tensor rank: 
Encountered an error during: %s
 -> Espresso Error: %s
Invalid dimensions requested for CVPixelBuffer creation.
Failed to create CVPixelBuffer. Status = 
Failed to lock pixel buffer.
Failed to unlock pixel buffer.
Unsupported CVPixelBuffer type: 
Null CVPixelBuffer encountered.
Binding CVPixelBuffer
Failed to get CVPixelBuffer's data. Ensure the buffer was locked.
precompiled_charsmap is empty.
Normalizer model is not available.
length < 0
norm_to_org and normalized are inconsistent
Trie blob is broken.
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/src/util.h
'result' Must be non NULL
Cannot open 
input ifstream is null
Model file is broken
Model is not initialized.
Normalizer is not initialized.
output container is null
Empty piece is not allowed.
consumed index is out-of-range.
original index is out-of-range.
all normalized characters are not consumed.
output proto is null
NBestEncode returns empty result
nbest_size must be 0 < nbest_size <= 512 or nbest_size < 0.
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/src/sentencepiece_processor.cc
LOG(
ERROR
Returns default value 
</s>
Unknown extra_option type
reverse
option 
 is not available.
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/arenastring.h
CHECK failed: initial_value != NULL: 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/repeated_field.h
CHECK failed: (index) >= (0): 
CHECK failed: (index) < (current_size_): 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/src/model_factory.cc
Unknown model_type: 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/src/char_model.cc
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/src/unigram_model.cc
best_node
nbest_size >= 1. Returns empty result.
Too big agenda. shrinking
(num_nodes) < (trie_results.size())
model file is already precompiled.
No pieces are loaded.
Cannot build double-array.
No entry is found in the trie.
precompiled_trie is empty.
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/third_party/darts_clone/darts.h:776: exception: failed to resize pool: std::bad_alloc
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/third_party/darts_clone/darts.h:1214: exception: failed to insert key: negative value
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/third_party/darts_clone/darts.h:1216: exception: failed to insert key: zero-length key
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/third_party/darts_clone/darts.h:1230: exception: failed to insert key: invalid null character
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/third_party/darts_clone/darts.h:1235: exception: failed to insert key: wrong key order
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/third_party/darts_clone/darts.h:915: exception: failed to build rank index: std::bad_alloc
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/third_party/darts_clone/darts.h:1453: exception: failed to modify unit: too large offset
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/third_party/darts_clone/darts.h:1799: exception: failed to build double-array: invalid null character
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/third_party/darts_clone/darts.h:1801: exception: failed to build double-array: negative value
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/third_party/darts_clone/darts.h:1816: exception: failed to build double-array: wrong key order
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/src/sentencepiece_model.pb.cc
CHECK failed: !model_prefix_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
CHECK failed: !input_format_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
CHECK failed: (&from) != (this): 
sentencepiece.TrainerSpec
CHECK failed: !name_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
CHECK failed: !precompiled_charsmap_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
sentencepiece.NormalizerSpec
CHECK failed: !piece_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
sentencepiece.ModelProto.SentencePiece
CHECK failed: !precompiled_trie_.IsDefault( &::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
CHECK failed: trainer_spec_ != NULL: 
CHECK failed: normalizer_spec_ != NULL: 
sentencepiece.ModelProto
CHECK failed: (n) >= (0): 
down_cast
casts.h
f == NULL || dynamic_cast<To>(f) != NULL
CHECK failed: (&other) != (this): 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/src/model_interface.cc
User defined symbol is not supported.
 is already defined.
!result.empty()
Cancelled
Unknown
Invalid argument
Deadline exceeded
Not found
Already exists
Permission denied
Unauthenticated
Resource exhausted
Failed precondition
Aborted
Out of range
Unimplemented
Internal
Unavailable
Data loss
Unkown code:
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/src/sentencepiece.pb.cc
CHECK failed: !surface_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
sentencepiece.SentencePieceText.SentencePiece
CHECK failed: !text_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
sentencepiece.SentencePieceText
sentencepiece.NBestSentencePieceText
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/src/bpe_model.cc
Invalid character length.
(index) >= (0)
(index) < (static_cast<int>(symbols.size()))
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/src/model_interface.h
Not implemented.
(cannot determine missing fields for lite message)
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/message_lite.cc
CHECK failed: !coded_out.HadError(): 
parse
Can't 
 message of type "
" because it is missing required fields: 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/wire_format_lite.cc
CHECK failed: (value.size()) <= (kint32max): 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/io/coded_stream.cc
A protocol message was rejected because it was too big (more than 
 bytes).  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
CHECK failed: (buffer_size) >= (0): 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/generated_message_util.cc
Not implemented field number 
 with type 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/stubs/common.cc
This program requires version 
 of the Protocol Buffer runtime library, but the installed version is 
.  Please update your library.  If you compiled the program yourself, make sure that your headers are from the same version of Protocol Buffers as your link-time library.  (Version verification failed in "
This program was compiled against version 
 of the Protocol Buffer runtime library, which is not compatible with the installed version (
).  Contact the program author for an update.  If you compiled the program yourself, make sure that your headers are from the same version of Protocol Buffers as your link-time library.  (Version verification failed in "
%d.%d.%d
INFO
WARNING
FATAL
[libprotobuf %s %s:%d] %s
pthread_mutex_lock: 
pthread_mutex_unlock: 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/io/zero_copy_stream.cc
This ZeroCopyOutputStream doesn't support aliasing. Reaching here usually means a ZeroCopyOutputStream implementation bug.
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/io/zero_copy_stream_impl_lite.cc
CHECK failed: (last_returned_size_) > (0): 
BackUp() can only be called after a successful Next().
CHECK failed: (count) <= (last_returned_size_): 
CHECK failed: (count) >= (0): 
CHECK failed: target_ != NULL: 
Cannot allocate buffer larger than kint32max for 
StringOutputStream.
CHECK failed: (count) <= (target_->size()): 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/extension_set.cc
Non-primitive types can't be packed.
can't reach here.
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/arena.cc
CHECK failed: (min_bytes) <= (std::numeric_limits<size_t>::max() - kHeaderSize): 
N5cvnlp4util6InFileE
N5cvnlp4util9DirectoryE
NSt3__110__function6__funcIZN5cvnlp4util6MatrixIfE3rowEmEUlmmE_NS_9allocatorIS6_EEFmmmEEE
NSt3__110__function6__baseIFmmmEEE
bbbbbbbb
bbbbbbbbbbbbbbbbbb
bbbbbbbbb
bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb
b"bbbbbbbb&bbbbbbb:bbbbbJbbbbbbZb^
2-DN'H
Xbh`
3;CA
9AGM
08>D
TT"TTTTTTTTTTTTTTTT
TTTTTTTTTTTTTTTTTTTTTTTTTTT5:
]]]]]]]]]]]]]]]]]
]]]]]]]]]]]]$]]]]]]]]]]]]]]K]]]5
N5cvnlp4util8KeyErrorE
N5cvnlp4util20ExceptionWithMessageE
N5cvnlp4util17FileNotFoundErrorE
N5cvnlp4util4FileE
NSt3__14__fs10filesystem4pathE
N5cvnlp6vidcap27ExcludeTokenIDsLogitsWarperE
N5cvnlp6vidcap12LogitsWarperE
NSt3__113basic_fstreamIcNS_11char_traitsIcEEEE
N8nlohmann6detail11other_errorE
N8nlohmann6detail9exceptionE
NSt3__120__shared_ptr_emplaceIN8nlohmann6detail20input_stream_adapterENS_9allocatorIS3_EEEE
N8nlohmann6detail20input_stream_adapterE
N8nlohmann6detail22input_adapter_protocolE
N8nlohmann6detail12out_of_rangeE
NSt3__117bad_function_callE
N8nlohmann6detail16invalid_iteratorE
N8nlohmann6detail10type_errorE
N8nlohmann6detail11parse_errorE
NSt3__120__shared_ptr_emplaceIN5cvnlp23SentencePieceVocabularyENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_pointerIPN5cvnlp6vidcap17BeamSearchOptionsENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIN5cvnlp6vidcap17BeamSearchOptionsEEE
ZN5cvnlp4util6MatrixIfE3rowEmEUlmmE_
NSt3__111__end_stateIcEE
NSt3__16__nodeIcEE
NSt3__120__shared_ptr_pointerIPNS_13__empty_stateIcEENS_10shared_ptrIS2_E27__shared_ptr_default_deleteIS2_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrINS_13__empty_stateIcEEE27__shared_ptr_default_deleteIS2_S2_EE
NSt3__113__empty_stateIcEE
NSt3__116__owns_one_stateIcEE
NSt3__115__has_one_stateIcEE
NSt3__120__l_anchor_multilineIcEE
NSt3__120__r_anchor_multilineIcEE
NSt3__115__word_boundaryIcNS_12regex_traitsIcEEEE
NSt3__111__lookaheadIcNS_12regex_traitsIcEEEE
NSt3__123__match_any_but_newlineIcEE
NSt3__118__match_char_icaseIcNS_12regex_traitsIcEEEE
NSt3__120__match_char_collateIcNS_12regex_traitsIcEEEE
NSt3__112__match_charIcEE
NSt3__116__back_ref_icaseIcNS_12regex_traitsIcEEEE
NSt3__118__back_ref_collateIcNS_12regex_traitsIcEEEE
NSt3__110__back_refIcEE
NSt3__120__bracket_expressionIcNS_12regex_traitsIcEEEE
NSt3__128__begin_marked_subexpressionIcEE
NSt3__126__end_marked_subexpressionIcEE
NSt3__16__loopIcEE
NSt3__117__owns_two_statesIcEE
NSt3__117__repeat_one_loopIcEE
NSt3__111__alternateIcEE
NSt3__121__empty_non_own_stateIcEE
NSt3__111__match_anyIcEE
N5cvnlp4util15InvalidArgumentE
N5cvnlp4util12RuntimeErrorE
NSt3__120__shared_ptr_emplaceIN5cvnlp4clip9CLIPModelENS_9allocatorIS3_EEEE
sdN5cvnlp13GreedySamplerE
N5cvnlp20LanguageModelSamplerE
N5cvnlp11TopKSamplerE
N5cvnlp11BeamSamplerE
N5cvnlp14NucleusSamplerE
%+N5cvnlp20OutOfVocabularyErrorE
N5cvnlp19TokenListVocabularyE
N5cvnlp18AbstractVocabularyE
N5cvnlp23SentencePieceVocabularyE
N5boost10wrapexceptISt12out_of_rangeEE
N5boost16exception_detail10clone_baseE
N5boost9exceptionE
N5cvnlp18CharacterTokenizerE
N5cvnlp17AbstractTokenizerE
N5cvnlp19WhitespaceTokenizerE
#)-4:@FOU[c
NSt3__120__shared_ptr_emplaceIN5cvnlp6vidcap20VideoCaptioningModelENS_9allocatorIS3_EEEE
N5cvnlp4util12UnknownErrorE
#)-4:@FOU[c
"(2;CIOV\bj
!%)-159=AEN5cvnlp23InvalidProbabilityErrorE
N5cvnlp4util4PathE
N2ik6TensorE
N2ik14InferenceErrorE
N2ik11EspressoNetE
N2ik14EspressoTensorE
NSt3__120__shared_ptr_pointerIPhNS_10shared_ptrIA_hE27__shared_ptr_default_deleteIS3_hEENS_9allocatorIhEEEE
NSt3__110shared_ptrIA_hE27__shared_ptr_default_deleteIS1_hEE
NSt3__114default_deleteIA_hEE
NSt3__120__shared_ptr_emplaceIN2ik21EspressoBufferStorageENS_9allocatorIS2_EEEE
N2ik21EspressoBufferStorageE
N2ik13TensorStorageE
N2ik17PixelBufferTensorE
NSt3__120__shared_ptr_emplaceIN2ik18PixelBufferStorageENS_9allocatorIS2_EEEE
N2ik18PixelBufferStorageE
N13sentencepiece10normalizer10NormalizerE
N5Darts15DoubleArrayImplIvvivEE
N13sentencepiece22SentencePieceProcessorE
N13sentencepiece4word5ModelE
*-0N13sentencepiece9character5ModelE
$1XX
CQIN13sentencepiece7unigram7LatticeE
N13sentencepiece7unigram9ModelBaseE
N13sentencepiece7unigram5ModelE
N5Darts7Details9ExceptionE
$5FW
N13sentencepiece11TrainerSpecE
N13sentencepiece14NormalizerSpecE
N13sentencepiece24ModelProto_SentencePieceE
N13sentencepiece10ModelProtoE
NSt3__112basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEE
N13sentencepiece14ModelInterfaceE
N13sentencepiece31SentencePieceText_SentencePieceE
N13sentencepiece17SentencePieceTextE
N13sentencepiece22NBestSentencePieceTextE
N6google8protobuf8internal29InternalMetadataWithArenaBaseINSt3__112basic_stringIcNS3_11char_traitsIcEENS3_9allocatorIcEEEENS1_29InternalMetadataWithArenaLiteEE9ContainerE
N13sentencepiece3bpe5ModelE
N6google8protobuf11MessageLiteE
N6google8protobuf8internal12FieldSkipperE
N6google8protobuf8internal29CodedOutputStreamFieldSkipperE
N6google8protobuf14FatalExceptionE
N6google8protobuf7ClosureE
N6google8protobuf8internal16FunctionClosure0E
N6google8protobuf2io20ZeroCopyOutputStreamE
N6google8protobuf2io17ArrayOutputStreamE
N6google8protobuf2io18StringOutputStreamE
'6ETcr
"+4=Oajr{
N6google8protobuf8internal15ExtensionFinderE
N6google8protobuf8internal24GeneratedExtensionFinderE
N6google8protobuf13RepeatedFieldIiEE
N6google8protobuf13RepeatedFieldIxEE
N6google8protobuf13RepeatedFieldIjEE
N6google8protobuf13RepeatedFieldIyEE
N6google8protobuf13RepeatedFieldIfEE
N6google8protobuf13RepeatedFieldIdEE
N6google8protobuf13RepeatedFieldIbEE
N6google8protobuf16RepeatedPtrFieldINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEEE
N6google8protobuf8internal20RepeatedPtrFieldBaseE
N6google8protobuf16RepeatedPtrFieldINS0_11MessageLiteEEE
Attempting to parse ModelSpec from JSON path: %s
Performing greedy search, since requested topKPerStep is 1.
Setting Espresso storage type to FLOAT32 since CPU runtime requested.
Setting Espresso storage type to FLOAT16.
sampleTokenIDs(%s, %zu)
EOS encountered in greedySample. Terminating early.
No context provided. Pushing bosID as first tokenID for beam search.
Skipping generation on sample that ends with EOS: %s
All beams contain finished sequences. Exiting beam search loop early after %lu steps
Setting Espresso engine to CPU since ANE is not available and we are investigating issues when running on pre-ANE devices with MPS.
Unknown error encountered during initWithOptions.
Using user-provided CLIP model to encode image instead of Vision.
Unknown error encountered during encodeImage.
Unknown Error encountered during encodeText.
Could not load the contents of file at %@
Could not load the contents of file at %@ as dictionary
Error adding caption rules-file line: %@. Error: %@
Expected token=%s to get converted into single TokenID, but got %zu tokenIDs: %s. Returning UNK TokenID as fallback.
[CVNLPTokenIDConverter] Failed to load token id resources: %s
Input buffer and pixel buffer are both nil
Video Pixel Buffers are empty
Unexpected tokenNormalizedScore issue? got %.8f from tokenScore = %.2f, characterCount = %ld
Default ivs model files not found.
ANE-specific ivs model files not found. Falling back to the default model.
Failed to load encoder network for engine: %d, espresso error: %s
Error during espresso execution: %s
Error during operating point retrieval: %s
Unknown error encountered during initWithOptions. See NSError object for more details.
Received unsupported CFType for locale.
Received unsupported model format. Could be either Montreal or Espresso
Creation options does not contain all required keys.
Unable to determine model locale from options=%@
Locale not supported: %s
Model directory does not exist: %s
Expected output sequence to have dimensions (vocab=%ld, time=%ld), but got (vocab=%ld, time=%ld)
Invalid sampling method: "%s"
Tokenized query=%s into %zu tokens.
CLIP image encoder model file not found!
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:o:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:o:path:/System/Library/Frameworks/Vision.framework/Vision
CVNLPTextDecodingToken
CVNLPCaptionSensitiveImageParameters
CVNLPInformationStream
CVNLPLanguageResourceBundle
CVNLPCaptionEncoderLSTM
CVNLPCLIPEmbedding
CVNLPCLIPModel
CVNLPCaptionEncoder
CVNLPCommSafetyTextItem
NSCopying
NSSecureCoding
NSCoding
CVNLPCommSafetyTextProvider
CVNLPCommSafetyCDTextProvider
CVNLPActivationMatrix
CVNLPLexiconCursors
CVNLPCaptionEncoderTransformer
CVNLPCaptionPostProcessingHandler
CVNLPCaptionModelBase
BundleHelper
CVNLPTextDecodingConfiguration
CVNLPTextDecodingBeamSearchConfiguration
CVNLPTextDecoder
CVNLPCaptionRuntimeParameters
CVNLPTextDecodingResultCandidate
CVNLPTextDecodingResult
CVNLPDecodingLanguageModel
CVNLPTokenIDConverter
CVNLPModelBase
CVNLPPerformanceResult
CVNLPPerformance
CVNLPCommSafetyHandler
CVNLPCTCTextDecodingPath
CVNLPCaptionDecoder
CVNLPTextDecodingPath
CVNLPCaptionDecoderBlock
CVNLPCommSafetyImageAnalyzer
CVNLPCTCBeamState
CVNLPVideoCaptioningModel
CVNLPCaption
CVNLPCaptionRuntimeExcludeGenderTrigger
CVNLPVisionRequestHandler
CVNLPCTCTextDecoder
CVNLPTextDecoding
NSObject
CVNLPCaptionRuntimeReplacements
3@!2
CVNLPCaptionDecoderTransformer
CVNLPDecodingLexicon
CVNLPDecodingLexicons
CVNLPCommSafetyTextClassification
CVNLPCommSafetyTextAnalyzerModel
CVNLPCommSafetyTextAnalyzer
CVNLPCaptionDecoderLSTM
CVNLPTextDecodingContext
T@"NSArray",&,N,V_decoderBlocks
.cxx_destruct
T@"NSString",&,N,V_metricString
T#,R
Tq,R,N,V_result
T@"CVNLPCaptionDecoderBlock",&,N,V_nextBlock
__timestepCount
T@"CVNLPCaptionRuntimeParameters",R,W,V_runtimeParameters
_blackListRules
T@"CVNLPCommSafetyTextAnalyzer",R,V_textAnalyzer
_characterCount
T@"CVNLPDecodingLanguageModel",R,N,V_characterLanguageModel
_decodingWeight
T@"CVNLPDecodingLexicons",R,N,V_lexicons
_espressoEngine
T@"CVNLPLanguageResourceBundle",R,N,V_languageResourceBundle
_hasProblematicMixedScriptWords
T@"CVNLPPerformance",R,N,V_perfResults
_loadVocabFile:
T@"MLMultiArray",&,N,V__multiArray
_models
T@"NSArray",&,N,V_excludeGenderReplacements
_result
T@"NSArray",&,N,V_genderedTokens
_stateInputEspressoBuffersShape
T@"NSArray",R,N,V_blockingTokens
_tokens
T@"NSArray",R,N,V_tokens
activationRange
T@"NSCharacterSet",R,V_trimSet
activeSubstring
T@"NSDate",R,C,N,V_date
allKeys
T@"NSDate",R,C,N,V_startDate
bundleForClass:
T@"NSDictionary",&,N,V_sensitiveImageParameters
computeCaptionForImage:outputs:
T@"NSDictionary",R,N,V_options
content
T@"NSDictionary",R,V_options
cpuInstructions
T@"NSMutableDictionary",&,N,V_mutablePaths
current
T@"NSNumber",R,C,N,V_alignmentScore
dealloc
T@"NSNumber",R,N,V_decodingWeight
defaultPathScoringFunctionPruneProblematicMixedScriptWordPaths:
T@"NSNumber",R,V_otgxMainThreshold
extractBeamID:tokenID:lstmAttnState:lstmLangState:fromFollowup:
T@"NSObject<OS_dispatch_queue>",R,V_clientQueue
initWithLanguageResourceBundle:
T@"NSString",&,N,V_metricCopyString
initWithString:
T@"NSString",R,C,N
isProxy
T@"NSString",R,C,N,V_string
lastTokenBoundaryLogProbability
T@"NSString",R,C,N,V_text
lowercaseString
T@"NSString",R,N,V_history
newAttStateBlob
T@"NSString",R,N,V_name
options
T@"NSString",R,N,V_replacementValue
release
T@"NSString",R,N,V_visionIdentifier
results
T@?,N,V_commitActionBlock
setBlockOutput:
TB,N,V__isDoubleDataType
setRequestedTimeToleranceAfter:
TB,N,V_pruneProblematicMixedScriptWordPaths
set_indexArray:
TB,N,V_shouldOptimizeAlignment
set_timeStride:
TB,R,N
strides
TB,R,N,V_hasPrecedingSpace
valueWithRange:
TB,R,V_optimizingAlignment
.cxx_construct
T@"NSNumber",R,N,V_genderOption
JSONObjectWithData:options:error:
TQ,N,V_beamSize
T@"CVNLPActivationMatrix",&,N,V_activationMatrix
__pruningPolicy
T@"CVNLPCaptionRuntimeParameters",R,N,V_runTimeParams
_alignmentScore
T@"CVNLPCommSafetyImageAnalyzer",R,V_imageAnalyzer
_blockingTokens
T@"CVNLPCommSafetyTextProvider",&
_copy_data_to_blob_repeated:to:
T@"CVNLPDecodingLanguageModel",R,N,V_wordLanguageModel
_espressoBuffer
T@"CVNLPLanguageResourceBundle",R,&,N,V_languageResourceBundle
_genderedTokens
T@"CVNLPLexiconCursors",&,N,V_cursors
_languageResourceLogProbability
T@"MLMultiArray",&,N,V__indexArray
_locale
T@"NSArray",&,N,V_blackListRules
_replacementKey
T@"NSArray",&,N,V_excludeGenderTriggers
_sortedLexicons
T@"NSArray",&,N,V_replacements
_string
T@"NSArray",R,N,V_candidates
_vocabTokenizer
T@"NSArray",R,V_triggerTokens
activationScore
T@"NSData",R,N,V_data
activeWordLexiconLogProbability
T@"NSDate",R,C,N,V_endDate
arrayWithArray:
T@"NSDictionary",&,N,V_classifierRevisions
classifyString:
T@"NSDictionary",&,N,V_vocab
containsString:
T@"NSDictionary",R,V_acceptedOutputIndices
copyInputState:
T@"NSLocale",R,N,V_locale
cpuTime
T@"NSMutableDictionary",R,N,V_results
cursors
T@"NSNumber",R,C,N,V_score
defaultLowerBoundLogProbability
T@"NSNumber",R,N,V_lowerBoundLogProbability
endDate
T@"NSObject<OS_dispatch_queue>",&,N,V_decoderQueue
history
T@"NSOrderedSet",&,N,V_characterObservations
initWithModelURL:options:error:
T@"NSString",R,C
intentsSourceID
T@"NSString",R,C,N,V_conversationIdentifier
keysSortedByValueUsingSelector:
T@"NSString",R,C,N,V_terminatingCharacter
lexicon
T@"NSString",R,N
maxpeak
T@"NSString",R,N,V_modelName
numberWithBool:
T@"NSString",R,N,V_replacementKey
outputVocabSize
T@"NSString",R,N,V_string
replacementProb
T@"NSURL",R,V_modelUrl
scoringFunction
T@?,R,N,V_scoringFunction
setDecoderPlan:
TB,N,V__usingIndexes
setShouldApplyWordLMToLastWord:
TB,N,V_shouldApplyWordLMToLastWord
set_multiArray:
TB,R
startID
TB,R,N,V_computePerf
trimSet
TB,R,N,V_hasProblematicMixedScriptWords
wordLanguageModelLogProbability
TB,R,V_otgxRetrieveAllClasses
TI,R,V_bosTokenID
TI,R,V_eosTokenID
TI,R,V_unkTokenID
TQ,N,V_beamWidth
TQ,N,V_decoderBatchSize
TQ,N,V_endID
TQ,N,V_maxCaptionLen
TQ,N,V_modelIndex
TQ,N,V_outputVocabSize
TQ,N,V_pathCount
TQ,N,V_startID
TQ,N,V_vocabSize
TQ,R
TQ,R,N,V_priority
TQ,R,V_otgxMainIndex
T^?,R,N,V_inputNormalizationFunction
T^d,N,V__doubleScoreMatrix
T^v,N,V_decoderCtx
T^v,N,V_decoderPlan
T^v,R,N,V_languageModel
T^v,V__cachedTimesample
T^{CVNLPBeamSearch=},N,V_beamSearch
T^{CVNLPBeamSearch=},N,V_filterBeamSearch
T^{CVNLPLanguageModelWithState=},N,V_characterLMState
T^{_LXCursor=},R,N,V__rootCursor
Td,N,V_captionModelLengthNormalizationFactor
Td,N,V_captionModelMinimumConfidence
Td,R
Td,R,N,V_characterLanguageModelLogProbability
Td,R,N,V_lexiconScore
Td,R,N,V_minConfidence
Td,R,N,V_modelLogProbability
Td,R,N,V_replacementProb
Td,R,N,V_wordLanguageModelLogProbability
Td,R,V_languageResourceLogProbability
Td,V_activationScore
Td,V_activeWordLexiconLogProbability
Td,V_blankLogProbability
Td,V_historyLexiconLogProbability
Td,V_nonBlankLogProbability
Td,V_score
Ti,N,V_excludeGenderStrategy
Ti,N,V_genderOption
Ti,R,V__espressoDeviceId
Ti,R,V__espressoEngine
Ti,R,V__espressoStorageType
Tq,N,V__observationCount
Tq,N,V__observationStride
Tq,N,V__timeStride
Tq,N,V__timestepCount
Tq,N,V__type
Tq,N,V_blankIndex
Tq,R,N,V__cachedBlankIndex
Tq,R,N,V__cachedBlankIndexTimestep
Tq,R,N,V_characterCount
Tq,R,N,V_direction
Tq,R,N,V_domainType
Tq,R,N,V_pseudoSpaceCount
Tq,R,N,V_tokenCount
Tq,V__cachedPriorityQueueTimestep
Tr^{_LXLexicon=},R,N,V_lexicon
T{?=^v^v[4Q][4Q]QQQQQQQQQQi},N,V__espressoBuffer
T{?=^v^v[4Q][4Q]QQQQQQQQQQi},N,V__indexBuffer
T{?=^v^v[4Q][4Q]QQQQQQQQQQi},N,V_attFeatsPlaceholderBlob
T{?=^v^v[4Q][4Q]QQQQQQQQQQi},N,V_blockInput
T{?=^v^v[4Q][4Q]QQQQQQQQQQi},N,V_blockOutput
T{?=^v^v[4Q][4Q]QQQQQQQQQQi},N,V_maskInput
T{?=^v^v[4Q][4Q]QQQQQQQQQQi},N,V_positionInput
T{?=^v^v[4Q][4Q]QQQQQQQQQQi},N,V_scaleInput
T{?=^vi},N,V_decoderNet
T{CVNLPTextDecodingPruningPolicy=qBfI},N,V__pruningPolicy
T{_NSRange=QQ},R,N,V_activationRange
T{_NSRange=QQ},R,N,V_activeRange
T{map<std::string, std::vector<float>, std::less<std::string>, std::allocator<std::pair<const std::string, std::vector<float>>>>={__tree<std::__value_type<std::string, std::vector<float>>, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<float>>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::vector<float>>>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::vector<float>>, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<float>>, std::less<std::string>, true>>=Q}}},N,V_stateInputEspressoBuffers
T{map<std::string, std::vector<float>, std::less<std::string>, std::allocator<std::pair<const std::string, std::vector<float>>>>={__tree<std::__value_type<std::string, std::vector<float>>, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<float>>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::vector<float>>>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::vector<float>>, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<float>>, std::less<std::string>, true>>=Q}}},N,V_stateOutputEspressoBuffers
T{map<std::string, std::vector<unsigned long>, std::less<std::string>, std::allocator<std::pair<const std::string, std::vector<unsigned long>>>>={__tree<std::__value_type<std::string, std::vector<unsigned long>>, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<unsigned long>>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::vector<unsigned long>>>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::vector<unsigned long>>, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<unsigned long>>, std::less<std::string>, true>>=Q}}},N,V_stateInputEspressoBuffersShape
T{shared_ptr<cvnlp::clip::CLIPModel>=^{CLIPModel}^{__shared_weak_count}},R,N,V_model
T{shared_ptr<cvnlp::vidcap::VideoCaptioningModel>=^{VideoCaptioningModel}^{__shared_weak_count}},R,N,V_model
T{vector<std::string, std::allocator<std::string>>=^v^v{__compressed_pair<std::string *, std::allocator<std::string>>=^v}},N,V_decoderInputNames
URLByAppendingPathComponent:
UTF8String
__cachedBlankIndex
__cachedBlankIndexTimestep
__cachedPriorityQueueTimestep
__cachedTimesample
__doubleScoreMatrix
__espressoBuffer
__espressoDeviceId
__espressoEngine
__espressoStorageType
__indexArray
__indexBuffer
__isDoubleDataType
__multiArray
__observationCount
__observationStride
__rootCursor
__timeStride
__type
__usingIndexes
_acceptedOutputIndices
_activationMatrix
_activationRange
_activationScore
_activeRange
_activeWordLexiconLogProbability
_attFeatsPlaceholderBlob
_beamSearch
_beamSize
_beamWidth
_beginningCurrentWord
_blankIndex
_blankLogProbability
_blob_size:
_blockInput
_blockOutput
_bosTokenID
_cachedBlankIndex
_cachedBlankIndexTimestep
_cachedPriorityQueueTimestep
_cachedTimesample
_candidateSymbolAtIndex:forTimestep:outputScore:
_candidates
_captionModelLengthNormalizationFactor
_captionModelMinimumConfidence
_characterLMState
_characterLanguageModel
_characterLanguageModelLogProbability
_characterObservations
_checkAboveThreshold:observationConfidence:difference:
_checkForBlockingTokens:blockingTokens:
_checkForBlockingTokens:visionObservations:
_checkIfOnANEDevice
_className
_classificationForTextItems:conversationIdentifier:
_classificationsForTextItems:previousClassifications:
_classifierRevisions
_classifyString:
_clientQueue
_commitActionBlock
_computeOutputForPixelBuffer:error:
_computePerf
_conversationIdentifier
_copy_data_from_blob:to:
_copy_data_from_blob:toPtr:
_copy_data_to_blob:to:
_copy_data_to_blob:toBuffer:
_createBeamSearch:runTimeParams:
_createLexiconForLocale:
_createNameDecodingDict
_createNameEncodingDict
_cumulativeTokenLogProbabilities
_currentTokenStringLength
_cursors
_data
_date
_decodeName:
_decoderBatchSize
_decoderBlocks
_decoderCtx
_decoderInputNames
_decoderNet
_decoderPlan
_decoderQueue
_decodingLanguageModelForLocale:modelType:decodingWeight:lowerBoundLogProbability:type:
_decodingWeightValue
_direction
_domainType
_doubleScoreMatrix
_encodeName:
_endDate
_endID
_enumerateNonBlankCandidatesInTimestep:block:
_eosTokenID
_espressoDeviceId
_espressoStorageType
_excludeGenderReplacements
_excludeGenderReplacements:genderOption:error:
_excludeGenderStrategy
_excludeGenderTriggers
_excludeGenderTriggers:genderOption:error:
_extractThresholdForOTGXMain:
_fill_blob_data:with:
_filterBeamSearch
_filterVisionObservations:
_genderOption
_getQueue
_hasCalculatedHasProblematicMixedScriptWords
_hasContext
_hasExpanded
_hasPrecedingSpace
_histWordTokenIDs
_history
_historyLexiconLogProbability
_imageAnalyzer
_indexArray
_indexBuffer
_initWithLanguageModel:locale:decodingWeight:lowerBoundLogProbability:type:
_inputNormalizationFunction
_isDoubleDataType
_languageModel
_languageResourceBundle
_lastCodeUnitType
_latestExpandedSymbolIncludingPseudospace
_lexicon
_lexiconScore
_lexicons
_lmSPIType
_loadNetwork:modelIndex:
_loadNetwork:options:runTimeParams:
_loadRuntimeParameters:
_lowerBoundLogProbability
_lowerBoundLogProbabilityValue
_maskInput
_maxCaptionLen
_metricCopyString
_metricString
_minConfidence
_model
_modelIndex
_modelLogProbability
_modelName
_modelUrl
_multiArray
_mutablePaths
_name
_nameFromRevParts:
_nextBlock
_nonBlankLogProbability
_normalizedLMTokenIDForWord:withTokenID:sourceLanguageModel:outScore:
_normalizedTotalLogProbability
_nsfwRequest
_observationCount
_observationStride
_optimizingAlignment
_options
_otgxMainIndex
_otgxMainThreshold
_otgxRetrieveAllClasses
_outputVocabSize
_pathCount
_perfResults
_positionInput
_priority
_processNetworkOutput:
_pruneProblematicMixedScriptWordPaths
_pruningPolicy
_pseudoSpaceCount
_readOperatingThresholdsDataUsingModelURL:error:
_replacementProb
_replacementValue
_replacements
_replacements:genderOption:
_results
_rootCursor
_run:meanFeatures:attnFeatures:projectedAttnFeatures:
_runBlockWithCopyOutputBlock:
_runTimeParams
_runtimeParameters
_scaleInput
_score
_scoringFunction
_sensitiveImageParameters
_shouldApplyWordLMToLastWord
_shouldOptimizeAlignment
_significantRequest
_sortNonBlankCandidatesForTimestep:
_sortedCursors
_startDate
_startID
_stateInputEspressoBuffers
_stateOutputEspressoBuffers
_terminatingCharacter
_text
_textAnalyzer
_threshold
_timeStride
_timestepCount
_tokenBoundaryLogProbabilities
_tokenCommitCharacterLengths
_tokenCount
_tokenMaxActivations
_tokenString
_tokenStringSegmentationPositions
_tokenizer
_triggerTokens
_trimSet
_type
_unkTokenID
_updateCharacterLanguageModelLogProbabilityForString:stemmingFromPath:normalizedCodepoint:
_updateLexiconLogProbabilityForString:stemmingFromPath:
_usingIndexes
_valueForObservationIndex:timestep:
_visionIdentifier
_vocab
_vocabSize
_wordLanguageModel
_wordLanguageModelLogProbability
_wordLanguageModelLogProbabilityForString:originalWordRanges:originalWordIDs:wordRanges:wordIDs:
acceptedOutputIndices
activationMatrix
activeRange
addEntriesFromDictionary:
addObject:
addObjectsFromArray:
addPath:
alignmentScore
allObjects
allowsKeyedCoding
andPredicateWithSubpredicates:
appIntentsStream
appendFormat:
appendString:
applyWordLanguageModelProbabilityToPath:stemmedFromPath:isCommittingToken:
applyWordLanguageModelProbabilityToPaths
array
arrayWithCapacity:
arrayWithObject:
arrayWithObjects:
arrayWithObjects:count:
attFeatsBlob
attFeatsPlaceholderBlob
autorelease
beamSearch
beamSize
beamWidth
blackListRules
blankIndex
blankIndexForTimestep:
blankLogProbability
blockInput
blockOutput
blockingTokens
boolValue
bosTokenID
bufferWithWidth:height:format:options:error:
buildNetworkForSequenceLength:imageFeatures:
bytes
candidates
captionModelLengthNormalizationFactor
captionModelMinimumConfidence
characterAtIndex:
characterCount
characterIndexForObservationIndex:timestep:
characterLMState
characterLanguageModel
characterLanguageModelLogProbability
characterObservations
characterSetWithCharactersInString:
characterTokenIDsForString:
childPathWithBlankLogProb:
class
classifierRevisions
classifyImage:
classifyImage:error:
classifyPixelBuffer:error:
classifyPixelBuffer:stagedText:inConversationWithIdentifier:error:
classifyPixelBuffer:startDate:endDate:stagedText:inConversationWithIdentifier:error:
clientQueue
code
commitActionBlock
commitTokenAtTimestep:currentSymbolLogProbability:commitAction:string:stemmingFromPath:
compare:
componentsJoinedByString:
componentsSeparatedByCharactersInSet:
computeCaptionForImageImpl:outputs:
computeCaptionForImageWithInputs:genderOption:
computeCaptionForImageWithInputsImpl:genderOption:
computeCaptionForPixelBuffer:outputs:
computeCaptionForPixelBufferImpl:outputs:
computeCaptionForVideoPixelBuffer:outputs:
computeCaptionForVideoPixelBufferImpl:outputs:
computeOutputForImage:error:
computePerf
confidence
conformsToProtocol:
contentsOfDirectoryAtPath:error:
conversationIdentifier
copy
copyCGImageAtTime:actualTime:error:
copyOutputState:
copyWithZone:
count
countByEnumeratingWithState:objects:count:
createBundle
data
dataPointer
dataType
dataUsingEncoding:
dataWithBytes:length:
dataWithBytesNoCopy:length:freeWhenDone:
dataWithContentsOfFile:
dataWithContentsOfURL:
data_dim
date
dateByAddingTimeInterval:
debugDescription
decodeIntegerForKey:
decodeObjectOfClass:forKey:
decoderBatchSize
decoderBlocks
decoderCtx
decoderInputNames
decoderNet
decoderPlan
decoderQueue
decodingCVNLPLanguageModelForLocale:modelType:decodingWeight:
decodingLMLanguageModelForLocale:modelType:decodingWeight:
decodingLexiconForLocale:
decodingLexiconForLocale:priority:
decodingResultForKBestPaths:withBeamWidth:
decodingResultForKBestPaths:withBeamWidth:context:
decodingResultForKBestPaths:withBeamWidth:context:optimizeAlignment:
decodingResultWithConfiguration:withContext:
decodingWeight
decodingWeightValue
defaultCharacterCommitActionBehavior
defaultCommitActionBehaviorForLocale:
defaultDecodingWeight
defaultManager
defaultPathScoringFunction
defaultPathScoringFunctionForLanguageResourceBundle:
defaultPathScoringFunctionForLanguageResourceBundle:pruneProblematicMixedScriptWordPaths:
defaultTextProvider
defaultWhitespaceCommitActionBehavior
description
descriptorData
detectSensitivityForString:
dict
dictionary
dictionaryWithDictionary:
dictionaryWithObjects:forKeys:count:
direction
distantFuture
distantPast
domainType
doubleValue
duration
encodeImage:error:
encodeInteger:forKey:
encodeObject:forKey:
encodeText:error:
encodeTextAverage:error:
encodeWithCoder:
encoderCtx
encoderInputNames
encoderNet
encoderPlan
endID
enumerateKeysAndObjectsUsingBlock:
enumerateLexiconCursorsSortedByPriorityWithBlock:
enumerateLexiconsSortedByPriorityWithBlock:
enumerateNonBlankCandidatesInTimestep:block:
enumeratePathsWithBlock:
enumerateSubstringsInRange:options:usingBlock:
enumerateTokenIDsForText:withBlock:
eosTokenID
errorWithDomain:code:userInfo:
exceptionWithName:reason:userInfo:
excludeGenderReplacements
excludeGenderStrategy
excludeGenderTriggers
executeQuery:error:
fileExistsAtPath:
fileURLWithPath:
fileURLWithPathComponents:
filterBeamSearch
filteredArrayUsingPredicate:
filteredSetUsingPredicate:
firstObject
floatValue
formUnionWithCharacterSet:
fullString
genderOption
genderedTokens
generateCaption:error:
generateClassificationScoresForImage:error:
generateClassificationScoresForPixelBuffer:error:
getBytes:maxLength:usedLength:encoding:options:range:remainingRange:
getOperatingPointDataForClassName:error:
getOperatingPointDataForClassName:modelURL:error:
greedyDecodingResult
greedyDecodingResultWithConfiguration:
hasExpanded
hasPrecedingSpace
hasProblematicMixedScriptWords
hash
historyLexiconLogProbability
identifier
imageAnalyzer
inWordIDBlob
inactiveSubstring
indexOfObject:
init
initWithAsset:
initWithBuffer:domainType:characterObservations:blankIndex:pruningPolicy:
initWithBuffer:indexBuffer:domainType:characterObservations:blankIndex:pruningPolicy:
initWithBytes:length:encoding:
initWithCGImage:options:
initWithCVNLPLanguageModel:locale:decodingWeight:
initWithCVNLPLanguageModel:locale:decodingWeight:lowerBoundLogProbability:
initWithCVPixelBuffer:options:
initWithCandidates:
initWithCharacterLanguageModelLogProbability:wordLanguageModelLogProbability:lexiconScore:hasProblematicMixedScriptWords:string:
initWithCoder:
initWithCommitActionBehavior:
initWithCommitActionBehavior:beamWidth:pathCount:shouldOptimizeAlignment:
initWithCommitActionBehavior:beamWidth:pathCount:shouldOptimizeAlignment:pruneProblematicMixedScriptWordPaths:
initWithCommitActionBehavior:scoringFunction:beamWidth:pathCount:
initWithCommitActionBehavior:scoringFunction:beamWidth:pathCount:shouldOptimizeAlignment:
initWithCommitActionBehavior:scoringFunction:beamWidth:pathCount:shouldOptimizeAlignment:pruneProblematicMixedScriptWordPaths:
initWithCommitActionBehavior:scoringFunction:beamWidth:pathCount:shouldOptimizeAlignment:pruneProblematicMixedScriptWordPaths:shouldApplyWordLMToLastWord:
initWithContentsOfURL:error:
initWithConversationIdentifier:date:direction:text:
initWithConversationIdentifier:startDate:endDate:result:
initWithData:
initWithDecodingWeight:
initWithDecodingWeight:lowerBoundLogProbability:
initWithDictionary:
initWithHistory:
initWithHistory:activeRange:
initWithKey:value:prob:genderOption:
initWithLMLanguageModel:locale:decodingWeight:
initWithLMLanguageModel:locale:decodingWeight:lowerBoundLogProbability:
initWithLanguageModel:
initWithLanguageModel:locale:
initWithLanguageResourceBundle:scoringFunction:initialCharacterLMState:characterTokenIDs:wordTokenIDs:optimizingAlignment:hasContext:
initWithLexicon:
initWithLexicon:priority:
initWithLexicons:
initWithLexicons:characterLanguageModel:wordLanguageModel:
initWithLexicons:decodingWeight:
initWithLexicons:decodingWeight:lowerBoundLogProbability:
initWithLexicons:decodingWeight:lowerBoundLogProbability:inputNormalizationFunction:
initWithModel:className:threshold:
initWithModelURL:options:
initWithMultiArray:characterObservations:blankIndex:pruningPolicy:
initWithMultiArray:domainType:characterObservations:blankIndex:pruningPolicy:
initWithMultiArray:indexArray:domainType:characterObservations:blankIndex:pruningPolicy:
initWithName:
initWithOptions:
initWithOptions:error:
initWithOptions:modelIndex:runTimeParams:
initWithOptions:runTimeParams:
initWithOptions:runtimeParameters:
initWithResource:andTokenType:
initWithSortedCursors:
initWithString:score:activationRange:hasPrecedingSpace:
initWithString:score:activationRange:terminatingCharacter:
initWithString:score:alignmentScore:activationRange:terminatingCharacter:
initWithTokens:score:activationScore:
initWithURL:options:
initWithUTF8String:
initWithVisionIdentifier:minConfidence:commonBlockingTokens:categoryBlockingTokens:categoryBlockingTokensAnnex:
inputNormalizationFunction
intValue
integerValue
intent
intentClass
interaction
invertedSet
isEqual:
isEqualToString:
isKindOfClass:
isMemberOfClass:
kBest:discarded:k:shouldUpdateLMState:
knowledgeStoreWithDirectReadOnlyAccess
langProbBlob
languageCode
languageModel
languageResourceBundle
languageResourceLogProbability
lastObject
lastPathComponent
latestExpandedSymbol
latestExpandedSymbolIncludingPseudospace
leafProbabilities
length
lengthOfBytesUsingEncoding:
letterCharacterSet
lexiconScore
lexicons
lexiconsForPriority:
lmSPIType
loadNetworkForURL:espressoEngine:storageType:deviceId:
locale
localeIdentifier
logProbabilityForBlankAtTimestep:
logProbabilityForObservationIndex:timestep:
lowerBoundLogProbability
lowerBoundLogProbabilityValue
lowercaseLetterCharacterSet
lstmAttStateFeedBlob
lstmLangStateFeedBlob
maskInput
maxCaptionLen
maximumLengthOfBytesUsingEncoding:
meanFeatsBlob
meanFeatsPlaceholderBlob
meanFeaturesPresent
merge:logProbCumulator:
mergePathsWithTrailingWhitespaces
metricCopyString
metricString
minConfidence
model
modelIndex
modelLogProbability
modelName
modelUrl
modelWithContentsOfURL:error:
mutableCopy
mutablePaths
name
newLangStateBlob
nextBlock
nominalFrameRate
nonBlankLogProbability
normalizedActivationLogProbability
normalizedTotalLogProbability
numberWithDouble:
numberWithFloat:
numberWithInt:
numberWithInteger:
numberWithUnsignedInteger:
numberWithUnsignedLong:
objectAtIndex:
objectAtIndexedSubscript:
objectForKey:
objectForKeyedSubscript:
observationCount
optimizingAlignment
otgxMainIndex
otgxMainThreshold
otgxRetrieveAllClasses
pAttFeatsBlob
pAttFeatsPlaceholderBlob
packBeamID:tokenID:lstmAttnState:lstmLangState:softmax:
packagedLexiconCursorsUsingContext:
packagedLexiconCursorsUsingTextDecodingContext:
packagedLexiconRootCursors
path
pathByExtendingWithString:extendedPathString:blankLogProb:nonBlankLogProb:timestep:commitAction:symbolLogProb:
pathCount
pathForResource:ofType:
pathForString:
paths
peakdelta
perfResults
performRequests:error:
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
performanceResults
performanceStatistics
positionInput
postProcessCaptions:genderOption:error:
postProcessCaptions:visionObservations:
predicateForEventsWithEndInDateRangeFrom:to:
predicateForEventsWithSourceID:bundleID:
predicateForEventsWithSourceID:bundleID:groupIDs:
predicateForObjectsWithMetadataKey:andStringValue:
predicateWithFormat:
predictedLabelHypothesesForString:maximumCount:
priority
probabilityForBlankAtTimestep:
probabilityForObservationIndex:timestep:
processConversationsWithStartDate:endDate:previousClassifications:progressHandler:completionHandler:
processIdentifier
processInfo
processText:inConversationWithIdentifier:date:error:
processText:inConversationWithIdentifier:startDate:endDate:error:
provideTextItemsWithConversationIdentifier:startDate:endDate:progressHandler:
pruneProblematicMixedScriptWordPaths
pseudoSpaceCount
punctuationCharacterSet
queryForConversationIdentifier:startDate:endDate:
raise:format:
rangeOfCharacterFromSet:
rangeOfCharacterFromSet:options:range:
rangeOfFirstMatchInString:options:range:
rangeOfString:
rangeOfString:options:range:
rangeValue
recentpeak
regularExpressionWithPattern:options:error:
removeLastObject
removeObjectForKey:
replaceOccurrencesOfString:withString:options:range:
replacementKey
replacementValue
replacements
requiredContextLengthForStringLength:
resourcePath
respondsToSelector:
result
retain
retainCount
run:block:
runBlockWithCopyInput:copyOutputBlock:
runBlockWithCopyInputBlock:copyOutputBlock:
runTimeParams
runtimeParameters
scaleInput
sceneprints
score
scoreForTokenIndex:
self
sensitiveImageParameters
setActivationMatrix:
setActivationScore:
setActiveWordLexiconLogProbability:
setAttFeatsPlaceholderBlob:
setBeamSearch:
setBeamSize:
setBeamWidth:
setBlackListRules:
setBlankIndex:
setBlankLogProbability:
setBlockInput:
setCaptionModelLengthNormalizationFactor:
setCaptionModelMinimumConfidence:
setCharacterCount:
setCharacterLMState:
setCharacterLanguageModelLogProbability:
setCharacterObservations:
setClassifierRevisions:
setCommitActionBlock:
setCursors:
setDecoderBatchSize:
setDecoderBlocks:
setDecoderCtx:
setDecoderInputNames:
setDecoderNet:
setDecoderQueue:
setDefaultTextProvider:
setEndID:
setEventStreams:
setExcludeGenderReplacements:
setExcludeGenderStrategy:
setExcludeGenderTriggers:
setExecuteConcurrently:
setFilterBeamSearch:
setGenderOption:
setGenderedTokens:
setHistoryLexiconLogProbability:
setLastTokenBoundaryLogProbability:
setLimit:
setMaskInput:
setMaxCaptionLen:
setMetricCopyString:
setMetricString:
setModelIndex:
setMutablePaths:
setNextBlock:
setNonBlankLogProbability:
setObject:forKey:
setObject:forKeyedSubscript:
setOffset:
setOutputVocabSize:
setPathCount:
setPositionInput:
setPredicate:
setPruneProblematicMixedScriptWordPaths:
setPseudoSpaceCount:
setReplacements:
setRequestedTimeToleranceBefore:
setRevision:error:
setScaleInput:
setScore:
setSensitiveImageParameters:
setShouldOptimizeAlignment:
setSortDescriptors:
setStartID:
setStateInputEspressoBuffers:
setStateInputEspressoBuffersShape:
setStateOutputEspressoBuffers:
setVocab:
setVocabSize:
setWithArray:
setWordLanguageModelLogProbability:
set_cachedPriorityQueueTimestep:
set_cachedTimesample:
set_doubleScoreMatrix:
set_espressoBuffer:
set_indexBuffer:
set_isDoubleDataType:
set_observationCount:
set_observationStride:
set_pruningPolicy:
set_timestepCount:
set_type:
set_usingIndexes:
shape
shouldApplyWordLMToLastWord
shouldOptimizeAlignment
sortedArrayUsingComparator:
sortedKeys
startDate
startDateSortDescriptorAscending:
stateInputEspressoBuffers
stateInputEspressoBuffersShape
stateOutputEspressoBuffers
string
stringByAppendingString:
stringByDeletingLastPathComponent
stringByDeletingPathExtension
stringByTrimmingCharactersInSet:
stringWithCharacters:length:
stringWithFormat:
stringWithSpaceAtEnds
stringWithUTF8String:
strongToStrongObjectsMapTable
subarrayWithRange:
substringWithRange:
superclass
supportsSecureCoding
terminatingCharacter
text
textAnalyzer
timeInterval
timeIntervalSinceDate:
timestepCount
tokenCount
tokens
tokensWithTimestep:isFinalTimestep:
topCandidateForTimestep:outputLogProbability:
topCandidateForTimestep:outputLogProbability:outputIndex:
topCandidateForTimestep:outputProbability:outputIndex:
tracksWithMediaType:
triggerTokens
unkTokenID
unsignedIntegerValue
updateLastTokenWithMaxActivation:totalLogProbability:tokenBoundaryLogProbability:
uppercaseLetterCharacterSet
userInfo
valueForKey:
visionIdentifier
vocab
vocabSize
whitespaceAndNewlineCharacterSet
whitespaceCharacterSet
wordIDBlob
wordLanguageModel
wordTokenIDsForString:outTokenRanges:
zone
@64@0:8@16@24@32{_NSRange=QQ}40@56
@56@0:8@16@24{_NSRange=QQ}32@48
@52@0:8@16@24{_NSRange=QQ}32B48
@16@0:8
B16@0:8
{_NSRange=QQ}16@0:8
v16@0:8
@"NSString"
@"NSNumber"
{_NSRange="location"Q"length"Q}
@56@0:8@16d24@32@40@48
d16@0:8
@"NSArray"
@24@0:8@16
@32@0:8@16@24
@40@0:8@16@24@32
@"CVNLPDecodingLexicons"
@"CVNLPDecodingLanguageModel"
v32@0:8^{vImage_Buffer=^vQQQ}16^@24
v48@0:8^{vImage_Buffer=^vQQQ}16^@24^@32^@40
{?="plan"^v"network_index"i}
{?="data"^v"reserved"^v"dim"[4Q]"stride"[4Q]"width"Q"height"Q"channels"Q"batch_number"Q"sequence_length"Q"stride_width"Q"stride_height"Q"stride_channels"Q"stride_batch_number"Q"stride_sequence_length"Q"storage_type"i}
@"NSData"
@32@0:8@16^@24
@32@0:8^{__CVBuffer=}16^@24
{shared_ptr<cvnlp::clip::CLIPModel>=^{CLIPModel}^{__shared_weak_count}}16@0:8
@"NSDictionary"
{shared_ptr<cvnlp::clip::CLIPModel>="__ptr_"^{CLIPModel}"__cntrl_"^{__shared_weak_count}}
v32@0:8^{__CVBuffer=}16^@24
Q184@0:8{?=^v^v[4Q][4Q]QQQQQQQQQQi}16
v188@0:8{?=^v^v[4Q][4Q]QQQQQQQQQQi}16f184
[4Q]
@24@0:8^{_NSZone=}16
v24@0:8@16
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
@48@0:8@16@24q32@40
Q16@0:8
B24@0:8@16
q16@0:8
@"NSDate"
v48@0:8@16@24@32@?40
@232@0:8{?=^v^v[4Q][4Q]QQQQQQQQQQi}16q184@192q200{CVNLPTextDecodingPruningPolicy=qBfI}208
@400@0:8{?=^v^v[4Q][4Q]QQQQQQQQQQi}16{?=^v^v[4Q][4Q]QQQQQQQQQQi}184q352@360q368{CVNLPTextDecodingPruningPolicy=qBfI}376
@72@0:8@16q24@32q40{CVNLPTextDecodingPruningPolicy=qBfI}48
@64@0:8@16@24q32{CVNLPTextDecodingPruningPolicy=qBfI}40
@80@0:8@16@24q32@40q48{CVNLPTextDecodingPruningPolicy=qBfI}56
d32@0:8q16q24
q24@0:8q16
d24@0:8q16
q32@0:8q16q24
v32@0:8q16@?24
@40@0:8q16q24^d32
v24@0:8q16
@32@0:8q16^d24
@40@0:8q16^d24^q32
{?=^v^v[4Q][4Q]QQQQQQQQQQi}16@0:8
v184@0:8{?=^v^v[4Q][4Q]QQQQQQQQQQi}16
^d16@0:8
v24@0:8^d16
{CVNLPTextDecodingPruningPolicy=qBfI}16@0:8
v40@0:8{CVNLPTextDecodingPruningPolicy=qBfI}16
^v16@0:8
v24@0:8^v16
v20@0:8B16
@"NSOrderedSet"
@"MLMultiArray"
{CVNLPTextDecodingPruningPolicy="strategy"q"shouldSort"B"threshold"f"maxNumberOfCandidates"I}
@24@0:8^v16
v24@0:8@?16
{vector<const _LXCursor *, std::allocator<const _LXCursor *>>="__begin_"^^{_LXCursor}"__end_"^^{_LXCursor}"__end_cap_"{__compressed_pair<const _LXCursor **, std::allocator<const _LXCursor *>>="__value_"^^{_LXCursor}}}
v32@0:8^v16^@24
{vector<std::string, std::allocator<std::string>>="__begin_"^v"__end_"^v"__end_cap_"{__compressed_pair<std::string *, std::allocator<std::string>>="__value_"^v}}
@36@0:8@16i24^@28
@28@0:8@16i24
B40@0:8@16d24^@32
@"NSCharacterSet"
@"CVNLPCaptionRuntimeParameters"
@?24@0:8@16
@?16@0:8
@24@0:8@?16
@60@0:8@?16@?24Q32Q40B48B52B56
@56@0:8@?16@?24Q32Q40B48B52
@52@0:8@?16@?24Q32Q40B48
@48@0:8@?16@?24Q32Q40
@44@0:8@?16Q24Q32B40
@48@0:8@?16Q24Q32B40B44
v24@0:8Q16
@"CVNLPLanguageResourceBundle"
v24@0:8d16
i16@0:8
v20@0:8i16
@40@0:8@16d24d32
@48@0:8@16i24@28@36i44
@36@0:8@16i24@28
I44@0:8@16I24@28^d36
@52@0:8^v16@24@32@40i48
@40@0:8^v16@24@32
@48@0:8^v16@24@32@40
@40@0:8^{CVNLPLanguageModel=}16@24@32
@48@0:8^{CVNLPLanguageModel=}16@24@32@40
@32@0:8^v16@24
{vector<unsigned int, std::allocator<unsigned int>>=^I^I{__compressed_pair<unsigned int *, std::allocator<unsigned int>>=^I}}24@0:8@16
{vector<unsigned int, std::allocator<unsigned int>>=^I^I{__compressed_pair<unsigned int *, std::allocator<unsigned int>>=^I}}32@0:8@16^@24
@"NSLocale"
v32@0:8@16@?24
I16@0:8
{unique_ptr<cvnlp::AbstractVocabulary, std::default_delete<cvnlp::AbstractVocabulary>>="__ptr_"{__compressed_pair<cvnlp::AbstractVocabulary *, std::default_delete<cvnlp::AbstractVocabulary>>="__value_"^{AbstractVocabulary}}}
v192@0:8{?=^v^v[4Q][4Q]QQQQQQQQQQi}16^v184
v192@0:8{?=^v^v[4Q][4Q]QQQQQQQQQQi}16^f184
v192@0:8^f16{?=^v^v[4Q][4Q]QQQQQQQQQQi}24
v192@0:8@16{?=^v^v[4Q][4Q]QQQQQQQQQQi}24
@"CVNLPPerformance"
@"NSMutableDictionary"
q32@0:8^{CGImage=}16^@24
@32@0:8^{CGImage=}16^@24
q32@0:8^{__CVBuffer=}16^@24
@48@0:8@16@24@32^@40
v56@0:8@16@24@32@?40@?48
@48@0:8^{__CVBuffer=}16@24@32^@40
@64@0:8^{__CVBuffer=}16@24@32@40@48^@56
@"NSObject<OS_dispatch_queue>"
@"CVNLPCommSafetyImageAnalyzer"
@"CVNLPCommSafetyTextAnalyzer"
v36@0:8@16@24B32
@96@0:8@16@?24^{CVNLPLanguageModelWithState=}32{vector<unsigned int, std::allocator<unsigned int>>=^I^I{__compressed_pair<unsigned int *, std::allocator<unsigned int>>=^I}}40{vector<unsigned int, std::allocator<unsigned int>>=^I^I{__compressed_pair<unsigned int *, std::allocator<unsigned int>>=^I}}64B88B92
v24@0:8^{CVNLPLanguageModelWithState=}16
v56@0:8q16d24q32@40@48
@28@0:8q16B24
q24@0:8@16
v40@0:8q16d24d32
@24@0:8d16
@72@0:8@16@24d32d40q48q56d64
v36@0:8@16@24I32
v32@0:8@16@24
f88@0:8@16@24{vector<unsigned int, std::allocator<unsigned int>>=^I^I{__compressed_pair<unsigned int *, std::allocator<unsigned int>>=^I}}32@56{vector<unsigned int, std::allocator<unsigned int>>=^I^I{__compressed_pair<unsigned int *, std::allocator<unsigned int>>=^I}}64
^{CVNLPLanguageModelWithState=}16@0:8
{vector<unsigned int, std::allocator<unsigned int>>="__begin_"^I"__end_"^I"__end_cap_"{__compressed_pair<unsigned int *, std::allocator<unsigned int>>="__value_"^I}}
{vector<double, std::allocator<double>>="__begin_"^d"__end_"^d"__end_cap_"{__compressed_pair<double *, std::allocator<double>>="__value_"^d}}
{vector<unsigned long, std::allocator<unsigned long>>="__begin_"^Q"__end_"^Q"__end_cap_"{__compressed_pair<unsigned long *, std::allocator<unsigned long>>="__value_"^Q}}
@"CVNLPLexiconCursors"
^{CVNLPLanguageModelWithState=}
@?28@0:8@16B24
@?20@0:8B16
@52@0:8d16d24d32B40@44
@40@0:8@16Q24@32
B32@0:8@16Q24
v32@0:8Q16@24
v32@0:8@?16@?24
v32@0:8^f16@?24
{?=^vi}16@0:8
v32@0:8{?=^vi}16
{map<std::string, std::vector<float>, std::less<std::string>, std::allocator<std::pair<const std::string, std::vector<float>>>>={__tree<std::__value_type<std::string, std::vector<float>>, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<float>>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::vector<float>>>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::vector<float>>, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<float>>, std::less<std::string>, true>>=Q}}}16@0:8
v40@0:8{map<std::string, std::vector<float>, std::less<std::string>, std::allocator<std::pair<const std::string, std::vector<float>>>>={__tree<std::__value_type<std::string, std::vector<float>>, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<float>>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::vector<float>>>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::vector<float>>, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<float>>, std::less<std::string>, true>>=Q}}}16
{map<std::string, std::vector<unsigned long>, std::less<std::string>, std::allocator<std::pair<const std::string, std::vector<unsigned long>>>>={__tree<std::__value_type<std::string, std::vector<unsigned long>>, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<unsigned long>>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::vector<unsigned long>>>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::vector<unsigned long>>, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<unsigned long>>, std::less<std::string>, true>>=Q}}}16@0:8
v40@0:8{map<std::string, std::vector<unsigned long>, std::less<std::string>, std::allocator<std::pair<const std::string, std::vector<unsigned long>>>>={__tree<std::__value_type<std::string, std::vector<unsigned long>>, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<unsigned long>>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::vector<unsigned long>>>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::vector<unsigned long>>, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<unsigned long>>, std::less<std::string>, true>>=Q}}}16
{vector<std::string, std::allocator<std::string>>=^v^v{__compressed_pair<std::string *, std::allocator<std::string>>=^v}}16@0:8
v40@0:8{vector<std::string, std::allocator<std::string>>=^v^v{__compressed_pair<std::string *, std::allocator<std::string>>=^v}}16
@"CVNLPCaptionDecoderBlock"
{map<std::string, std::vector<float>, std::less<std::string>, std::allocator<std::pair<const std::string, std::vector<float>>>>="__tree_"{__tree<std::__value_type<std::string, std::vector<float>>, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<float>>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::vector<float>>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::vector<float>>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<float>>, std::less<std::string>, true>>="__value_"Q}}}
{map<std::string, std::vector<unsigned long>, std::less<std::string>, std::allocator<std::pair<const std::string, std::vector<unsigned long>>>>="__tree_"{__tree<std::__value_type<std::string, std::vector<unsigned long>>, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<unsigned long>>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::vector<unsigned long>>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::vector<unsigned long>>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<unsigned long>>, std::less<std::string>, true>>="__value_"Q}}}
@40@0:8@16@24^@32
B36@0:8@16i24i28i32
@32@0:8^{vImage_Buffer=^vQQQ}16^@24
@"NSURL"
v44@0:8^@16^@24Q32B40
{shared_ptr<cvnlp::vidcap::VideoCaptioningModel>=^{VideoCaptioningModel}^{__shared_weak_count}}16@0:8
{shared_ptr<cvnlp::vidcap::VideoCaptioningModel>="__ptr_"^{VideoCaptioningModel}"__cntrl_"^{__shared_weak_count}}
@24@0:8^{__CVBuffer=}16
@"VNVYvzEtX1JlUdu8xx5qhDI"
@"VN6Mb1ME89lyW3HpahkEygIG"
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
@32@0:8Q16Q24
@40@0:8Q16Q24@32
@"CVNLPTextDecodingResult"32@0:8Q16Q24
@"CVNLPTextDecodingResult"40@0:8Q16Q24@"CVNLPTextDecodingContext"32
@"CVNLPTextDecodingResult"32@0:8@"CVNLPTextDecodingBeamSearchConfiguration"16@"CVNLPTextDecodingContext"24
@"CVNLPTextDecodingResult"16@0:8
@"CVNLPTextDecodingResult"24@0:8@"CVNLPTextDecodingConfiguration"16
@44@0:8Q16Q24@32B40
@"CVNLPActivationMatrix"
@48@0:8@16@24d32@40
v40@0:8@16@24@32
^{CVNLPBeamSearch=}16@0:8
v24@0:8^{CVNLPBeamSearch=}16
^{CVNLPBeamSearch=}
r^{_LXLexicon=}24@0:8@16
@32@0:8@16Q24
@32@0:8^{_LXLexicon=}16Q24
@24@0:8^{_LXLexicon=}16
r^{_LXLexicon=}16@0:8
^{_LXCursor=}16@0:8
r^{_LXLexicon=}
^{_LXCursor=}
@48@0:8@16@24@32^?40
@24@0:8Q16
^?16@0:8
@48@0:8@16@24@32q40
@40@0:8@16@24d32
@"NLModel"
@56@0:8@16@24@32@40^@48
@56@0:8@16@24^{?=^v^v[4Q][4Q]QQQQQQQQQQi}32^{?=^v^v[4Q][4Q]QQQQQQQQQQi}40^{?=^v^v[4Q][4Q]QQQQQQQQQQi}48
v56@0:8^@16^@24^{?=^v^v[4Q][4Q]QQQQQQQQQQi}32^{?=^v^v[4Q][4Q]QQQQQQQQQQi}40@48
@40@0:8@16{_NSRange=QQ}24
