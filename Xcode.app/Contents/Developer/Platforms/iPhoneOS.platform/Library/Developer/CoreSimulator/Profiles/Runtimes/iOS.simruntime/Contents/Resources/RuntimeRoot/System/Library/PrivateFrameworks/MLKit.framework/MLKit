@(#)PROGRAM:MLKit  PROJECT:MLUI-1
?__C
URLResourceKey
NNSURLResourceKey
Foundation
FileAttributeKey
NNSFileAttributeKey
AVAuthorizationStatus
UIDeviceOrientation
MLPreviewType
MLKit
MLPreviewEnvironment
PreviewScreenMode
MLKit
CameraViewController
SomeClass
OSAvailability
MLKit
CameraMonitorObject
CameraMonitor
AuthorizationSetupResult
CameraMonitorResult
CameraMonitorError
CameraView
FileErrors
ModelHeuristics
>DiskSize
imageClassifier
textClassifier
activityClassifier
objectDetector
wordTagger
tabularClassifier
tabularRegressor
recommender
soundClassifier
styleTransfer
actionClassifier
handActionClassifier
handPoseClassifier
imageSegmenter
poseEstimation
bertQA
depthEstimation
unknown
itemSimilarityRecommender
Fatal error
Down-casted Array element failed to match the target type
Expected 
NSArray element failed to match the Swift Array Element type
Expected 
pipelineRegressor
featureVectorizer
treeEnsembleRegressor
pipelineClassifier
soundAnalysisPreprocessing
neuralNetworkClassifier
nonMaximumSuppression
labelProbability
supportVectorClassifier
treeEnsembleClassifier
kNearestNeighborsClassifier
visionFeaturePrint
_TtC5MLKit20MLPreviewEnvironment
_screenMode
_dismissPreview
_presentShareSheet
_TtC5MLKit20CameraViewController
@24@0:8@16
v16@0:8
@32@0:8@16@24
cameraMonitor
currentPreviewLayer
MLKit.CameraViewController
init(nibName:bundle:)
Error during camera access: 
MLKit/CameraViewController.swift
init(coder:) has not been implemented
_TtC5MLKitP33_B2618D8A38BB367B729892787F41CE5A9SomeClass
_TtC5MLKit19CameraMonitorObject
_cameraOutout
_TtC5MLKit13CameraMonitor
@16@0:8
captureSession
camera
cameraInput
videoOutput
photoOutput
sessionQueue
liveVideoFeedQueue
authSetupResult
monitorObject
v40@0:8@16@24@32
MLKit1
v40@0:8@16^{opaqueCMSampleBuffer=}24@32
v8@?0
Camera photo output is invalid
No camera device is available
MLKit/CameraMonitor.swift
mlmodel.preview.session.queue
mlmodel.preview.live.video.feed.queue
Camera output is unknown
v12@?0B8
_TtC5MLKit10CameraView
viewController
So8NSStringC
$sSY
$ss21_ObjectiveCBridgeableP
yyXlG
$ss12CaseIterableP
ySbG
$s7Combine16ObservableObjectP
So16UIViewControllerC
So26AVCaptureVideoPreviewLayerCSg
yypG
ySS_SSSgtG
SS_SSSgt
SaySSG
SSSg
ySS_SStG
SS_SSt
ySSG
_pGG
So8NSObjectC
So16AVCaptureSessionC
So15AVCaptureDeviceCSg
So20AVCaptureDeviceInputCSg
So24AVCaptureVideoDataOutputC
So20AVCapturePhotoOutputC
So17OS_dispatch_queueC
So7UIImageC
_pSgIegg_
SS7message_t
$s7SwiftUI4ViewP
$s7SwiftUI29UIViewControllerRepresentableP
So8MIOModelC
3key_yp5valuetSg
3key_yp5valuet
ypSgSg
ypSg
_rawValue
RawValue
_ObjectiveCType
AllCases
RawValue
imageClassifier
textClassifier
activityClassifier
objectDetector
wordTagger
tabularClassifier
tabularRegressor
recommender
soundClassifier
styleTransfer
actionClassifier
handActionClassifier
handPoseClassifier
imageSegmenter
poseEstimation
bertQA
depthEstimation
unknown
_screenMode
_dismissPreview
_presentShareSheet
standard
fullscreen
ObjectWillChangePublisher
cameraMonitor
currentPreviewLayer
macOS
watchOS
tvOS
_cameraOutout
captureSession
camera
cameraInput
videoOutput
photoOutput
sessionQueue
liveVideoFeedQueue
authSetupResult
monitorObject
image
success
notAuthorized
configurationFailed
ObjectWillChangePublisher
captureSessionAlreadyRunning
captureSessionIsMissing
invalidVideoDataOutput
invalidPhotoOutput
invalidOperation
noCamerasAvailable
unknown
viewController
Body
UIViewControllerType
Coordinator
badEnumeration
badResource
model
specificationVersion
AVCapturePhotoCaptureDelegate
AVCaptureVideoDataOutputSampleBufferDelegate
NSObject
dealloc
T#,R
keyType
TQ,R
setContentMode:
.cxx_destruct
isProxy
T@"NSString",R,C
release
addInput:
addOutput:
addSubview:
attributesOfItemAtPath:error:
authorizationStatusForMediaType:
autorelease
bounds
canAddOutput:
captureOutput:didCapturePhotoForResolvedSettings:
captureOutput:didDropSampleBuffer:fromConnection:
captureOutput:didFinishCaptureForResolvedSettings:error:
captureOutput:didFinishProcessingLivePhotoToMovieFileAtURL:duration:photoDisplayTime:resolvedSettings:error:
captureOutput:didFinishProcessingPhoto:error:
captureOutput:didFinishProcessingPhotoSampleBuffer:previewPhotoSampleBuffer:resolvedSettings:bracketSettings:error:
captureOutput:didFinishProcessingRawPhotoSampleBuffer:previewPhotoSampleBuffer:resolvedSettings:bracketSettings:error:
captureOutput:didFinishRecordingLivePhotoMovieForEventualFileAtURL:resolvedSettings:
captureOutput:didOutputSampleBuffer:fromConnection:
captureOutput:willBeginCaptureForResolvedSettings:
captureOutput:willCapturePhotoForResolvedSettings:
class
conformsToProtocol:
connection
constraint
currentDevice
debugDescription
defaultDeviceWithDeviceType:mediaType:position:
defaultManager
description
fileDataRepresentation
getResourceValue:forKey:error:
hash
init
initWithCIImage:
initWithCVPixelBuffer:
initWithCoder:
initWithData:
initWithDevice:error:
initWithFrame:
initWithNibName:bundle:
initWithSession:
inputDescriptions
insertSublayer:atIndex:
isEqual:
isKindOfClass:
isLivePhotoCaptureSupported
isMemberOfClass:
isVideoOrientationSupported
layer
longLongValue
mainBundle
modelDescription
modelTypeName
name
orientation
outputDescriptions
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
predictedFeatureName
requestAccessForMediaType:completionHandler:
respondsToSelector:
retain
retainCount
self
setAllowedUnits:
setCountStyle:
setFrame:
setHighResolutionCaptureEnabled:
setLivePhotoCaptureEnabled:
setSessionPreset:
setVideoGravity:
setVideoOrientation:
shape
startRunning
stringFromByteCount:
subModels
superclass
type
view
viewDidLayoutSubviews
viewDidLoad
zone
v32@0:8@16@24
v40@0:8@16@24@32
v64@0:8@16^{opaqueCMSampleBuffer=}24^{opaqueCMSampleBuffer=}32@40@48@56
v96@0:8@16@24{?=qiIq}32{?=qiIq}56@80@88
v32@0:8@"AVCapturePhotoOutput"16@"AVCaptureResolvedPhotoSettings"24
v40@0:8@"AVCapturePhotoOutput"16@"AVCapturePhoto"24@"NSError"32
v64@0:8@"AVCapturePhotoOutput"16^{opaqueCMSampleBuffer=}24^{opaqueCMSampleBuffer=}32@"AVCaptureResolvedPhotoSettings"40@"AVCaptureBracketedStillImageSettings"48@"NSError"56
v40@0:8@"AVCapturePhotoOutput"16@"NSURL"24@"AVCaptureResolvedPhotoSettings"32
v96@0:8@"AVCapturePhotoOutput"16@"NSURL"24{?=qiIq}32{?=qiIq}56@"AVCaptureResolvedPhotoSettings"80@"NSError"88
v40@0:8@"AVCapturePhotoOutput"16@"AVCaptureResolvedPhotoSettings"24@"NSError"32
v40@0:8@16^{opaqueCMSampleBuffer=}24@32
v40@0:8@"AVCaptureOutput"16^{opaqueCMSampleBuffer=}24@"AVCaptureConnection"32
B24@0:8@16
#16@0:8
@16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B16@0:8
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
@(#)PROGRAM:MLKit  PROJECT:MLUI-1
?__C
URLResourceKey
NNSURLResourceKey
Foundation
FileAttributeKey
NNSFileAttributeKey
AVAuthorizationStatus
UIDeviceOrientation
%(05>EKS\ejs
MLPreviewType
MLKit
MLPreviewEnvironment
PreviewScreenMode
MLKit
CameraViewController
SomeClass
OSAvailability
MLKit
CameraMonitorObject
CameraMonitor
AuthorizationSetupResult
CameraMonitorResult
CameraMonitorError
CameraView
FileErrors
ModelHeuristics
DiskSize
imageClassifier
textClassifier
activityClassifier
objectDetector
wordTagger
tabularClassifier
tabularRegressor
recommender
soundClassifier
styleTransfer
actionClassifier
handActionClassifier
handPoseClassifier
imageSegmenter
poseEstimation
bertQA
depthEstimation
unknown
itemSimilarityRecommender
Fatal error
Down-casted Array element failed to match the target type
Expected 
NSArray element failed to match the Swift Array Element type
Expected 
pipelineRegressor
featureVectorizer
treeEnsembleRegressor
pipelineClassifier
soundAnalysisPreprocessing
neuralNetworkClassifier
nonMaximumSuppression
labelProbability
supportVectorClassifier
treeEnsembleClassifier
kNearestNeighborsClassifier
visionFeaturePrint
_TtC5MLKit20MLPreviewEnvironment
_screenMode
_dismissPreview
_presentShareSheet
_TtC5MLKit20CameraViewController
@24@0:8@16
v16@0:8
@32@0:8@16@24
cameraMonitor
currentPreviewLayer
MLKit.CameraViewController
init(nibName:bundle:)
Error during camera access: 
MLKit/CameraViewController.swift
init(coder:) has not been implemented
_TtC5MLKitP33_B2618D8A38BB367B729892787F41CE5A9SomeClass
_TtC5MLKit19CameraMonitorObject
_cameraOutout
_TtC5MLKit13CameraMonitor
@16@0:8
captureSession
camera
cameraInput
videoOutput
photoOutput
sessionQueue
liveVideoFeedQueue
authSetupResult
monitorObject
v40@0:8@16@24@32
MLKit1
v40@0:8@16^{opaqueCMSampleBuffer=}24@32
v8@?0
Camera photo output is invalid
No camera device is available
MLKit/CameraMonitor.swift
mlmodel.preview.session.queue
mlmodel.preview.live.video.feed.queue
Camera output is unknown
v12@?0B8
_TtC5MLKit10CameraView
viewController
So8NSStringC
$sSY
$ss21_ObjectiveCBridgeableP
yyXlG
$ss12CaseIterableP
ySbG
$s7Combine16ObservableObjectP
So16UIViewControllerC
So26AVCaptureVideoPreviewLayerCSg
yypG
ySS_SSSgtG
SS_SSSgt
SaySSG
SSSg
ySS_SStG
SS_SSt
ySSG
_pGG
So8NSObjectC
So16AVCaptureSessionC
So15AVCaptureDeviceCSg
So20AVCaptureDeviceInputCSg
So24AVCaptureVideoDataOutputC
So20AVCapturePhotoOutputC
So17OS_dispatch_queueC
So7UIImageC
_pSgIegg_
SS7message_t
$s7SwiftUI4ViewP
$s7SwiftUI29UIViewControllerRepresentableP
So8MIOModelC
3key_yp5valuetSg
3key_yp5valuet
ypSgSg
ypSg
_rawValue
RawValue
_ObjectiveCType
AllCases
RawValue
imageClassifier
textClassifier
activityClassifier
objectDetector
wordTagger
tabularClassifier
tabularRegressor
recommender
soundClassifier
styleTransfer
actionClassifier
handActionClassifier
handPoseClassifier
imageSegmenter
poseEstimation
bertQA
depthEstimation
unknown
_screenMode
_dismissPreview
_presentShareSheet
standard
fullscreen
ObjectWillChangePublisher
cameraMonitor
currentPreviewLayer
macOS
watchOS
tvOS
_cameraOutout
captureSession
camera
cameraInput
videoOutput
photoOutput
sessionQueue
liveVideoFeedQueue
authSetupResult
monitorObject
image
success
notAuthorized
configurationFailed
ObjectWillChangePublisher
captureSessionAlreadyRunning
captureSessionIsMissing
invalidVideoDataOutput
invalidPhotoOutput
invalidOperation
noCamerasAvailable
unknown
viewController
Body
UIViewControllerType
Coordinator
badEnumeration
badResource
model
specificationVersion
AVCapturePhotoCaptureDelegate
AVCaptureVideoDataOutputSampleBufferDelegate
NSObject
dealloc
T#,R
keyType
TQ,R
setContentMode:
.cxx_destruct
isProxy
T@"NSString",R,C
release
addInput:
addOutput:
addSubview:
attributesOfItemAtPath:error:
authorizationStatusForMediaType:
autorelease
bounds
canAddOutput:
captureOutput:didCapturePhotoForResolvedSettings:
captureOutput:didDropSampleBuffer:fromConnection:
captureOutput:didFinishCaptureForResolvedSettings:error:
captureOutput:didFinishProcessingLivePhotoToMovieFileAtURL:duration:photoDisplayTime:resolvedSettings:error:
captureOutput:didFinishProcessingPhoto:error:
captureOutput:didFinishProcessingPhotoSampleBuffer:previewPhotoSampleBuffer:resolvedSettings:bracketSettings:error:
captureOutput:didFinishProcessingRawPhotoSampleBuffer:previewPhotoSampleBuffer:resolvedSettings:bracketSettings:error:
captureOutput:didFinishRecordingLivePhotoMovieForEventualFileAtURL:resolvedSettings:
captureOutput:didOutputSampleBuffer:fromConnection:
captureOutput:willBeginCaptureForResolvedSettings:
captureOutput:willCapturePhotoForResolvedSettings:
class
conformsToProtocol:
connection
constraint
currentDevice
debugDescription
defaultDeviceWithDeviceType:mediaType:position:
defaultManager
description
fileDataRepresentation
getResourceValue:forKey:error:
hash
init
initWithCIImage:
initWithCVPixelBuffer:
initWithCoder:
initWithData:
initWithDevice:error:
initWithFrame:
initWithNibName:bundle:
initWithSession:
inputDescriptions
insertSublayer:atIndex:
isEqual:
isKindOfClass:
isLivePhotoCaptureSupported
isMemberOfClass:
isVideoOrientationSupported
layer
longLongValue
mainBundle
modelDescription
modelTypeName
name
orientation
outputDescriptions
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
predictedFeatureName
requestAccessForMediaType:completionHandler:
respondsToSelector:
retain
retainCount
self
setAllowedUnits:
setCountStyle:
setFrame:
setHighResolutionCaptureEnabled:
setLivePhotoCaptureEnabled:
setSessionPreset:
setVideoGravity:
setVideoOrientation:
shape
startRunning
stringFromByteCount:
subModels
superclass
type
view
viewDidLayoutSubviews
viewDidLoad
zone
v32@0:8@16@24
v40@0:8@16@24@32
v64@0:8@16^{opaqueCMSampleBuffer=}24^{opaqueCMSampleBuffer=}32@40@48@56
v96@0:8@16@24{?=qiIq}32{?=qiIq}56@80@88
v32@0:8@"AVCapturePhotoOutput"16@"AVCaptureResolvedPhotoSettings"24
v40@0:8@"AVCapturePhotoOutput"16@"AVCapturePhoto"24@"NSError"32
v64@0:8@"AVCapturePhotoOutput"16^{opaqueCMSampleBuffer=}24^{opaqueCMSampleBuffer=}32@"AVCaptureResolvedPhotoSettings"40@"AVCaptureBracketedStillImageSettings"48@"NSError"56
v40@0:8@"AVCapturePhotoOutput"16@"NSURL"24@"AVCaptureResolvedPhotoSettings"32
v96@0:8@"AVCapturePhotoOutput"16@"NSURL"24{?=qiIq}32{?=qiIq}56@"AVCaptureResolvedPhotoSettings"80@"NSError"88
v40@0:8@"AVCapturePhotoOutput"16@"AVCaptureResolvedPhotoSettings"24@"NSError"32
v40@0:8@16^{opaqueCMSampleBuffer=}24@32
v40@0:8@"AVCaptureOutput"16^{opaqueCMSampleBuffer=}24@"AVCaptureConnection"32
B24@0:8@16
#16@0:8
@16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B16@0:8
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
