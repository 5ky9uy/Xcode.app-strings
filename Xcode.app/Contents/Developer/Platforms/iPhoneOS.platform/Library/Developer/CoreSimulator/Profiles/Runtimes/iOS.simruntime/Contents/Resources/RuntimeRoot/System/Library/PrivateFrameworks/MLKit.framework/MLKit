@(#)PROGRAM:MLKit  PROJECT:MLUI-1
?__C
URLResourceKey
NNSURLResourceKey
Foundation
FileAttributeKey
NNSFileAttributeKey
AVAuthorizationStatus
UIDeviceOrientation
MLPreviewType
MLKit
MLPreviewEnvironment
PreviewScreenMode
MLKit
CameraViewController
SomeClass
OSAvailability
10.13
10.13.2
10.14
10.15
11.0
12.0
11.0
11.2
12.0
13.0
14.0
15.0
MLKit
CameraMonitorObject
CameraMonitor
AuthorizationSetupResult
CameraMonitorResult
CameraMonitorError
CameraView
FileErrors
ModelHeuristics
>DiskSize
imageClassifier
textClassifier
activityClassifier
objectDetector
wordTagger
tabularClassifier
tabularRegressor
recommender
soundClassifier
styleTransfer
actionClassifier
handActionClassifier
handPoseClassifier
imageSegmenter
poseEstimation
bertQA
depthEstimation
unknown
itemSimilarityRecommender
Fatal error
Down-casted Array element failed to match the target type
Expected 
NSArray element failed to match the Swift Array Element type
Expected 
pipelineRegressor
featureVectorizer
treeEnsembleRegressor
pipelineClassifier
soundAnalysisPreprocessing
neuralNetworkClassifier
nonMaximumSuppression
labelProbability
supportVectorClassifier
treeEnsembleClassifier
kNearestNeighborsClassifier
visionFeaturePrint
_TtC5MLKit20MLPreviewEnvironment
_screenMode
_dismissPreview
_presentShareSheet
_TtC5MLKit20CameraViewController
@24@0:8@16
v16@0:8
@32@0:8@16@24
cameraMonitor
currentPreviewLayer
MLKit.CameraViewController
init(nibName:bundle:)
Error during camera access: 
MLKit/CameraViewController.swift
init(coder:) has not been implemented
_TtC5MLKitP33_B2618D8A38BB367B729892787F41CE5A9SomeClass
_TtC5MLKit19CameraMonitorObject
_cameraOutout
_TtC5MLKit13CameraMonitor
@16@0:8
captureSession
camera
cameraInput
videoOutput
photoOutput
sessionQueue
liveVideoFeedQueue
authSetupResult
monitorObject
v40@0:8@16@24@32
MLKit1
v40@0:8@16^{opaqueCMSampleBuffer=}24@32
v8@?0
Camera photo output is invalid
No camera device is available
MLKit/CameraMonitor.swift
mlmodel.preview.session.queue
mlmodel.preview.live.video.feed.queue
Camera output is unknown
v12@?0B8
AVCapturePhotoCaptureDelegate
v32@0:8@16@24
v64@0:8@16^{opaqueCMSampleBuffer=}24^{opaqueCMSampleBuffer=}32@40@48@56
v96@0:8@16@24{?=qiIq}32{?=qiIq}56@80@88
v32@0:8@"AVCapturePhotoOutput"16@"AVCaptureResolvedPhotoSettings"24
v40@0:8@"AVCapturePhotoOutput"16@"AVCapturePhoto"24@"NSError"32
v64@0:8@"AVCapturePhotoOutput"16^{opaqueCMSampleBuffer=}24^{opaqueCMSampleBuffer=}32@"AVCaptureResolvedPhotoSettings"40@"AVCaptureBracketedStillImageSettings"48@"NSError"56
v40@0:8@"AVCapturePhotoOutput"16@"NSURL"24@"AVCaptureResolvedPhotoSettings"32
v96@0:8@"AVCapturePhotoOutput"16@"NSURL"24{?=qiIq}32{?=qiIq}56@"AVCaptureResolvedPhotoSettings"80@"NSError"88
v40@0:8@"AVCapturePhotoOutput"16@"AVCaptureResolvedPhotoSettings"24@"NSError"32
AVCaptureVideoDataOutputSampleBufferDelegate
v40@0:8@"AVCaptureOutput"16^{opaqueCMSampleBuffer=}24@"AVCaptureConnection"32
NSObject
B24@0:8@16
q16@0:8
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B16@0:8
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
hash
Tq,N,R
superclass
T#,N,R
description
T@"NSString",N,R
debugDescription
B24@0:8@"Protocol"16
@"NSString"16@0:8
_TtC5MLKit10CameraView
viewController
So8NSStringC
$sSY
$ss21_ObjectiveCBridgeableP
yyXlG
$ss12CaseIterableP
ySbG
$s7Combine16ObservableObjectP
So16UIViewControllerC
So26AVCaptureVideoPreviewLayerCSg
yypG
ySS_SSSgtG
SaySSG
SSSg
SS_SSt
ySS_SStG
ySSG
_pGG
So8NSObjectC
So16AVCaptureSessionC
So15AVCaptureDeviceCSg
So20AVCaptureDeviceInputCSg
So24AVCaptureVideoDataOutputC
So20AVCapturePhotoOutputC
So17OS_dispatch_queueC
So7UIImageC
_pSgIegg_
SS7message_t
$s7SwiftUI4ViewP
$s7SwiftUI29UIViewControllerRepresentableP
So8MIOModelC
3key_yp5valuetSg
ypSg
3key_yp5valuet
ypSgSg
_rawValue
RawValue
_ObjectiveCType
AllCases
RawValue
imageClassifier
textClassifier
activityClassifier
objectDetector
wordTagger
tabularClassifier
tabularRegressor
recommender
soundClassifier
styleTransfer
actionClassifier
handActionClassifier
handPoseClassifier
imageSegmenter
poseEstimation
bertQA
depthEstimation
unknown
_screenMode
_dismissPreview
_presentShareSheet
standard
fullscreen
ObjectWillChangePublisher
cameraMonitor
currentPreviewLayer
macOS
watchOS
tvOS
_cameraOutout
captureSession
camera
cameraInput
videoOutput
photoOutput
sessionQueue
liveVideoFeedQueue
authSetupResult
monitorObject
image
success
notAuthorized
configurationFailed
ObjectWillChangePublisher
captureSessionAlreadyRunning
captureSessionIsMissing
invalidVideoDataOutput
invalidPhotoOutput
invalidOperation
noCamerasAvailable
unknown
viewController
Body
UIViewControllerType
Coordinator
badEnumeration
badResource
model
specificationVersion
modelTypeName
modelDescription
inputDescriptions
type
constraint
shape
outputDescriptions
keyType
subModels
name
predictedFeatureName
initWithCoder:
viewDidLoad
initWithNibName:bundle:
.cxx_destruct
viewDidLayoutSubviews
connection
isVideoOrientationSupported
setVideoOrientation:
view
bounds
setFrame:
currentDevice
orientation
initWithFrame:
setContentMode:
addSubview:
initWithSession:
setVideoGravity:
layer
insertSublayer:atIndex:
startRunning
dealloc
init
captureOutput:didFinishProcessingPhoto:error:
captureOutput:didOutputSampleBuffer:fromConnection:
initWithCVPixelBuffer:
initWithCIImage:
fileDataRepresentation
initWithData:
canAddOutput:
setSessionPreset:
addOutput:
setHighResolutionCaptureEnabled:
isLivePhotoCaptureSupported
setLivePhotoCaptureEnabled:
defaultDeviceWithDeviceType:mediaType:position:
initWithDevice:error:
addInput:
authorizationStatusForMediaType:
requestAccessForMediaType:completionHandler:
mainBundle
captureOutput:willBeginCaptureForResolvedSettings:
captureOutput:willCapturePhotoForResolvedSettings:
captureOutput:didCapturePhotoForResolvedSettings:
captureOutput:didFinishProcessingPhotoSampleBuffer:previewPhotoSampleBuffer:resolvedSettings:bracketSettings:error:
captureOutput:didFinishProcessingRawPhotoSampleBuffer:previewPhotoSampleBuffer:resolvedSettings:bracketSettings:error:
captureOutput:didFinishRecordingLivePhotoMovieForEventualFileAtURL:resolvedSettings:
captureOutput:didFinishProcessingLivePhotoToMovieFileAtURL:duration:photoDisplayTime:resolvedSettings:error:
captureOutput:didFinishCaptureForResolvedSettings:error:
captureOutput:didDropSampleBuffer:fromConnection:
isEqual:
hash
superclass
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
description
debugDescription
setCountStyle:
setAllowedUnits:
stringFromByteCount:
defaultManager
getResourceValue:forKey:error:
longLongValue
attributesOfItemAtPath:error:
@(#)PROGRAM:MLKit  PROJECT:MLUI-1
?__C
URLResourceKey
NNSURLResourceKey
Foundation
FileAttributeKey
NNSFileAttributeKey
AVAuthorizationStatus
UIDeviceOrientation
#&.7@GMU^glu~
$'18CLR\dov
%(05>EKS\ejs
MLPreviewType
MLKit
MLPreviewEnvironment
PreviewScreenMode
MLKit
CameraViewController
SomeClass
OSAvailability
10.13
10.13.2
10.14
10.15
11.0
12.0
11.0
11.2
12.0
13.0
14.0
15.0
MLKit
CameraMonitorObject
CameraMonitor
AuthorizationSetupResult
CameraMonitorResult
CameraMonitorError
CameraView
FileErrors
ModelHeuristics
DiskSize
imageClassifier
textClassifier
activityClassifier
objectDetector
wordTagger
tabularClassifier
tabularRegressor
recommender
soundClassifier
styleTransfer
actionClassifier
handActionClassifier
handPoseClassifier
imageSegmenter
poseEstimation
bertQA
depthEstimation
unknown
itemSimilarityRecommender
Fatal error
Down-casted Array element failed to match the target type
Expected 
NSArray element failed to match the Swift Array Element type
Expected 
pipelineRegressor
featureVectorizer
treeEnsembleRegressor
pipelineClassifier
soundAnalysisPreprocessing
neuralNetworkClassifier
nonMaximumSuppression
labelProbability
supportVectorClassifier
treeEnsembleClassifier
kNearestNeighborsClassifier
visionFeaturePrint
_TtC5MLKit20MLPreviewEnvironment
_screenMode
_dismissPreview
_presentShareSheet
_TtC5MLKit20CameraViewController
@24@0:8@16
v16@0:8
@32@0:8@16@24
cameraMonitor
currentPreviewLayer
MLKit.CameraViewController
init(nibName:bundle:)
Error during camera access: 
MLKit/CameraViewController.swift
init(coder:) has not been implemented
_TtC5MLKitP33_B2618D8A38BB367B729892787F41CE5A9SomeClass
_TtC5MLKit19CameraMonitorObject
_cameraOutout
_TtC5MLKit13CameraMonitor
@16@0:8
captureSession
camera
cameraInput
videoOutput
photoOutput
sessionQueue
liveVideoFeedQueue
authSetupResult
monitorObject
v40@0:8@16@24@32
MLKit1
v40@0:8@16^{opaqueCMSampleBuffer=}24@32
v8@?0
Camera photo output is invalid
No camera device is available
MLKit/CameraMonitor.swift
mlmodel.preview.session.queue
mlmodel.preview.live.video.feed.queue
Camera output is unknown
v12@?0B8
AVCapturePhotoCaptureDelegate
v32@0:8@16@24
v64@0:8@16^{opaqueCMSampleBuffer=}24^{opaqueCMSampleBuffer=}32@40@48@56
v96@0:8@16@24{?=qiIq}32{?=qiIq}56@80@88
v32@0:8@"AVCapturePhotoOutput"16@"AVCaptureResolvedPhotoSettings"24
v40@0:8@"AVCapturePhotoOutput"16@"AVCapturePhoto"24@"NSError"32
v64@0:8@"AVCapturePhotoOutput"16^{opaqueCMSampleBuffer=}24^{opaqueCMSampleBuffer=}32@"AVCaptureResolvedPhotoSettings"40@"AVCaptureBracketedStillImageSettings"48@"NSError"56
v40@0:8@"AVCapturePhotoOutput"16@"NSURL"24@"AVCaptureResolvedPhotoSettings"32
v96@0:8@"AVCapturePhotoOutput"16@"NSURL"24{?=qiIq}32{?=qiIq}56@"AVCaptureResolvedPhotoSettings"80@"NSError"88
v40@0:8@"AVCapturePhotoOutput"16@"AVCaptureResolvedPhotoSettings"24@"NSError"32
AVCaptureVideoDataOutputSampleBufferDelegate
v40@0:8@"AVCaptureOutput"16^{opaqueCMSampleBuffer=}24@"AVCaptureConnection"32
NSObject
B24@0:8@16
q16@0:8
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B16@0:8
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
hash
Tq,N,R
superclass
T#,N,R
description
T@"NSString",N,R
debugDescription
B24@0:8@"Protocol"16
@"NSString"16@0:8
_TtC5MLKit10CameraView
viewController
So8NSStringC
$sSY
$ss21_ObjectiveCBridgeableP
yyXlG
$ss12CaseIterableP
ySbG
$s7Combine16ObservableObjectP
So16UIViewControllerC
So26AVCaptureVideoPreviewLayerCSg
yypG
ySS_SSSgtG
SaySSG
SSSg
SS_SSt
ySS_SStG
ySSG
_pGG
So8NSObjectC
So16AVCaptureSessionC
So15AVCaptureDeviceCSg
So20AVCaptureDeviceInputCSg
So24AVCaptureVideoDataOutputC
So20AVCapturePhotoOutputC
So17OS_dispatch_queueC
So7UIImageC
_pSgIegg_
SS7message_t
$s7SwiftUI4ViewP
$s7SwiftUI29UIViewControllerRepresentableP
So8MIOModelC
3key_yp5valuetSg
ypSg
3key_yp5valuet
ypSgSg
_rawValue
RawValue
_ObjectiveCType
AllCases
RawValue
imageClassifier
textClassifier
activityClassifier
objectDetector
wordTagger
tabularClassifier
tabularRegressor
recommender
soundClassifier
styleTransfer
actionClassifier
handActionClassifier
handPoseClassifier
imageSegmenter
poseEstimation
bertQA
depthEstimation
unknown
_screenMode
_dismissPreview
_presentShareSheet
standard
fullscreen
ObjectWillChangePublisher
cameraMonitor
currentPreviewLayer
macOS
watchOS
tvOS
_cameraOutout
captureSession
camera
cameraInput
videoOutput
photoOutput
sessionQueue
liveVideoFeedQueue
authSetupResult
monitorObject
image
success
notAuthorized
configurationFailed
ObjectWillChangePublisher
captureSessionAlreadyRunning
captureSessionIsMissing
invalidVideoDataOutput
invalidPhotoOutput
invalidOperation
noCamerasAvailable
unknown
viewController
Body
UIViewControllerType
Coordinator
badEnumeration
badResource
model
specificationVersion
modelTypeName
modelDescription
inputDescriptions
type
constraint
shape
outputDescriptions
keyType
subModels
name
predictedFeatureName
initWithCoder:
viewDidLoad
initWithNibName:bundle:
.cxx_destruct
viewDidLayoutSubviews
connection
isVideoOrientationSupported
setVideoOrientation:
view
bounds
setFrame:
currentDevice
orientation
initWithFrame:
setContentMode:
addSubview:
initWithSession:
setVideoGravity:
layer
insertSublayer:atIndex:
startRunning
dealloc
init
captureOutput:didFinishProcessingPhoto:error:
captureOutput:didOutputSampleBuffer:fromConnection:
initWithCVPixelBuffer:
initWithCIImage:
fileDataRepresentation
initWithData:
canAddOutput:
setSessionPreset:
addOutput:
setHighResolutionCaptureEnabled:
isLivePhotoCaptureSupported
setLivePhotoCaptureEnabled:
defaultDeviceWithDeviceType:mediaType:position:
initWithDevice:error:
addInput:
authorizationStatusForMediaType:
requestAccessForMediaType:completionHandler:
mainBundle
captureOutput:willBeginCaptureForResolvedSettings:
captureOutput:willCapturePhotoForResolvedSettings:
captureOutput:didCapturePhotoForResolvedSettings:
captureOutput:didFinishProcessingPhotoSampleBuffer:previewPhotoSampleBuffer:resolvedSettings:bracketSettings:error:
captureOutput:didFinishProcessingRawPhotoSampleBuffer:previewPhotoSampleBuffer:resolvedSettings:bracketSettings:error:
captureOutput:didFinishRecordingLivePhotoMovieForEventualFileAtURL:resolvedSettings:
captureOutput:didFinishProcessingLivePhotoToMovieFileAtURL:duration:photoDisplayTime:resolvedSettings:error:
captureOutput:didFinishCaptureForResolvedSettings:error:
captureOutput:didDropSampleBuffer:fromConnection:
isEqual:
hash
superclass
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
description
debugDescription
setCountStyle:
setAllowedUnits:
stringFromByteCount:
defaultManager
getResourceValue:forKey:error:
longLongValue
attributesOfItemAtPath:error:
