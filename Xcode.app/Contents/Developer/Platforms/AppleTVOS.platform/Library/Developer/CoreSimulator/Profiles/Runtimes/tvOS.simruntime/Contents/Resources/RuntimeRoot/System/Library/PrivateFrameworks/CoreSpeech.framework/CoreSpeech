?ffffff
 A33s@ff
pB!<
?fff?
zT?\
?(knN
$@frmaEVAWffac
@fff?
@mcpl
mcpl
@xeps
@mcpl
@supo
mcplsupoxeps
Median
+[CSUtils(Statistics) distributionDictionary:]
average:
stddev:
q24@?0@8@16
com.apple.corespeech.cat.xpc
[SplitterEnabled(%d)]
[Device%d(%@) DoAP(%d)]
[SplitterState:%d]
CSAudioInjectionBuiltInEngine
v8@?0
-[CSAudioInjectionBuiltInEngine dealloc]
SampleCount
HostTime
-[CSAudioInjectionBuiltInEngine getBestSampleCountWithOption:]
trigger-time
-[NviDataLogger logData:]
-[NviDataLogger stream:handleEvent:]
CSMicUsageReporter
CSVoiceTriggerAssetHandler
-[CSVoiceTriggerAssetHandler getVoiceTriggerAssetWithEndpointId:completion:]
CSVoiceTriggerAssetHandler.m
CSAudioSessionController Queue
-[CSAudioSessionController dealloc]
-[CSAudioSessionController audioSessionInfoProvider:didReceiveAudioSessionInterruptionNotificationWithUserInfo:]_block_invoke
-[CSAudioSessionController audioSessionInfoProvider:didReceiveAudioSessionRouteChangeNotificationWithUserInfo:]_block_invoke
-[CSAudioSessionController audioSessionInfoProvider:didReceiveAudioSessionMediaServicesWereLostNotificationWithUserInfo:]_block_invoke
-[CSAudioSessionController audioSessionInfoProvider:didReceiveAudioSessionMediaServicesWereResetNotificationWithUserInfo:]_block_invoke
-[CSAudioSessionController _createXPCClientConnectionIfNeeded]
-[CSAudioSessionController _startMonitoring]
-[CSAudioSessionController _stopMonitoring]
-[CSAudioSessionController _registerInterruptionNotification]
-[CSAudioSessionController _registerAudioRouteChangeNotification]
-[CSAudioSessionController _handleInterruption:]_block_invoke
-[CSAudioSessionController _mediaServicesWereLost:]_block_invoke
-[CSAudioSessionController _mediaServicesWereReset:]_block_invoke
-[CSAudioSessionController _audioRouteChanged:]_block_invoke
-[CSAudioSessionController _teardownXPCClientIfNeeded]
-[CSAudioSessionController CSXPCClient:didDisconnect:]_block_invoke
-[CSAudioSessionController coreSpeechDaemonStateMonitor:didReceiveStateChanged:]_block_invoke
com.apple.siri.SiriDebug.SpeakerVoiceGradingTrigger
com.apple.siri.SiriDebug.RemoteNearMissGradingTrigger
com.apple.siri.SiriDebug.VoiceProfileAddedTrigger
com.apple.siri.SiriDebug.VoiceProfileSyncTrigger
com.apple.siri.SiriDebug
+[CSSiriDebugConnection launchSiriDebugAppWithMessage:]_block_invoke
v24@?0@"AFSiriResponse"8@"NSError"16
CSMediaPlayingMonitor queue
-[CSMediaPlayingMonitor initializeMediaPlayingState]_block_invoke_2
v16@?0@8
v12@?0I8
-[CSMediaPlayingMonitor _startMonitoringWithQueue:]
-[CSMediaPlayingMonitor _stopMonitoring]
-[CSMediaPlayingMonitor _notePossiblePlayPausedStateChange:]
PLAYING
NOT PLAYING
audioURL : %@, numberOfChannels : %lu, scaleFactor: %f
announcemessage
Audio/Video
Alarm
CSVolumeMonitor queue
-[CSVolumeMonitor _startMonitoringWithQueue:]
-[CSVolumeMonitor fetchVolumeFromAVSystemControllerForAudioCategory:]_block_invoke
-[CSVolumeMonitor systemControllerDied:]
-[CSVolumeMonitor startObservingSystemVolumes]
-[CSVolumeMonitor _startObservingSystemControllerLifecycle]
CSTimerMonitor queue
-[CSTimerMonitor _startMonitoringWithQueue:]
-[CSTimerMonitor _stopMonitoring]
CSAlarmMonitor queue
-[CSAlarmMonitor _startMonitoringWithQueue:]
-[CSAlarmMonitor _stopMonitoring]
-[CSAudioStreamHolding dealloc]
+[CSUserIdentityClassifier pickTopScoringProfileIdFromScores:]
+[CSUserIdentityClassifier classifyUserIdentityFor:withScores:withAsset:]
Confident
Known
Unknown
Unsure1
UnsureN
+[CSUserIdentityClassifier stringFromClassificationCategory:]
v16@?0@"NSError"8
-[CSAttSiriServiceClient init]_block_invoke
-[CSAttSiriServiceClient init]
com.apple.corespeech.corespeechd.attsiri.service
-[CSAttSiriServiceClient _setupAttSiriSvcXpcConnection]_block_invoke
firstPassTriggerSource
ApplicationProcessor
Remora
CSPreMyriadCoordinator Queue
-[CSPreMyriadCoordinator _clearPendingRemoraVoiceTrigger]
-[CSPreMyriadCoordinator handlePendingRemoraVoiceTriggerIfNeeded]
-[CSPreMyriadCoordinator handlePendingRemoraVoiceTriggerIfNeeded]_block_invoke
-[CSPreMyriadCoordinator _clearPendingBuiltInVoiceTrigger]
-[CSPreMyriadCoordinator handlePendingBuiltInVoiceTriggerIfNeeded]
-[CSPreMyriadCoordinator handlePendingBuiltInVoiceTriggerIfNeeded]_block_invoke
v32@?0@"NSString"8@"CSPreMyriadVoiceTriggerMetaData"16^B24
-[CSPreMyriadCoordinator secondPassDidStopForClient:deviceId:]
-[CSPreMyriadCoordinator secondPassDidStartForClient:deviceId:withFirstPassEstimate:]
CSAudioInjectionHearstEngine
-[CSAudioInjectionHearstEngine dealloc]
v20@?0B8@"NSError"12
-[CSAudioRecordContext(AVVC) avvcContextSettings]
-[CSAudioZeroCounter getZeroStatisticsFromBuffer:entireSamples:]
-[CSAudioZeroCounter stopReportZeroStatistics]
voiceTriggerInfo
route
source
Adaptive Siri Volume Disabled
/Library/Audio/Tunings/B238/SoundAnalysis/b238_distance_classifier.mlmodelc
/Library/Audio/Tunings/B520/SoundAnalysis/b520_distance_classifier.mlmodelc
near
medium
siriVolume.json
smartSiriVolume
noiseLevelChannelBitset
LKFSChannelBitset
DistanceChannelBitset
energyBufferSize
noiseLowerPercentile
noiseUpperPercentile
LKFSLowerPercentile
LKFSUpperPercentile
noiseTimeConstant
noiseMicSensitivityOffset
noiseMicSensitivityOffsetDeviceSimple
LKFSTimeConstant
LKFSMicSensitivityOffset
noiseTTSMappingInputRangeLow
noiseTTSMappingInputRangeHigh
noiseTTSMappingOutputRangeLow
noiseTTSMappingOutputRangeHigh
LKFSTTSMappingInputRangeLow
LKFSTTSMappingInputRangeHigh
LKFSTTSMappingOutputRangeLow
LKFSTTSMappingOutputRangeHigh
userOffsetInputRangeLow
userOffsetInputRangeHigh
userOffsetOutputRangeLow
userOffsetOutputRangeHigh
TTSVolumeLowerLimitDB
TTSVolumeUpperLimitDB
noiseWeight
SSVCAMaxFrameSize
SSVCAVoiceTriggerBasedTTSValidForSeconds
SSVCASmartSiriVolumeUnsyncedMetricLogsToRetain
SSVCASmartSiriVolumeSyncedMetricLogsToRetain
SSVCAVoiceTriggerInitialSilenceDurationSeconds
SSVCADistanceInputBufferDurationSeconds
SSVCAListenPollingIntervalAtStartInSeconds
SSVCADefaultZeroFloatingPointValue
SSVCAAnnouncementStatusFetchTimeoutMs
SSVCADefaultOutputTTSVolume
SSVCANoiseActivityCountThreshold
SSVCASpeakerDistanceFarBoostFactor
SSVCASpeakerDistanceMidBoostFactor
SSVCASpeakerDistanceNearBoostFactor
SSVCADistanceModelConfidenceThreshold
SSVCAMinimumLinearSoundLevel
SSVCAMaximumLinearSoundLevel
SSVCALinearToDecibelConstantMultiplier
SSVCADecibelToLinearLogBase
SSVCASignalToSigmoidNoiseDilationFactor
SSVCASignalToSigmoidMusicDilationFactorDeviceDefault
SSVCASignalToSigmoidMusicDilationFactorDeviceSimple
SSVCASignalToSigmoidSpeechDilationFactor
SSVCASignalToSigmoidNoiseVSpread
SSVCASignalToSigmoidMusicVSpreadDeviceDefault
SSVCASignalToSigmoidMusicVSpreadDeviceSimple
SSVCASignalToSigmoidSpeechVSpread
SSVCASignalToSigmoidNoiseVOffset
SSVCASignalToSigmoidMusicVOffsetDeviceDefault
SSVCASignalToSigmoidMusicVOffsetDeviceSimple
SSVCASignalToSigmoidSpeechVOffset
SSVCASignalToSigmoidNoiseHOffset
SSVCASignalToSigmoidMusicHOffsetDeviceDefault
SSVCASignalToSigmoidMusicHOffsetDeviceSimple
SSVCASignalToSigmoidSpeechHOffset
SSVCASignalToSigmoidMusicSteepnessDeviceDefault
SSVCASignalToSigmoidMusicSteepnessDeviceSimple
SSVCASignalToSigmoidNoiseSteepness
SSVCASignalToSigmoidSpeechSteepness
SSVCADBToTTSMinimumOutput
SSVCADBToTTSMaximumOutput
SSVCADBToTTSTransitionPoint
SSVCADBToTTSPreTransitionOffset
SSVCADBToTTSPreTransitionMultiplier
SSVCADBToTTSPostTransitionOffset
SSVCADBToTTSPostTransitionDC
SSVCADBToTTSPostTransitionMultiplier
SSVCAMinimumDistanceUpdateWaitPeriodSeconds
SSVCANoiseActivityThreshold
SSVCANoiseResultsBufferSize
SSVCAMusicResultsBufferSize
SSVCADefaultSpeechStrength
SSVCADefaultMusicStrength
SSVCANoiseActivityHistoricalSampleCount
SSVCADspCoefsCount
SSVCADspNumStages
SSVCADistanceResultsBufferSize
SSVCAExponentialDistanceHistoryDegradationFactor
SSVCADistanceResultSampleCountTolerance
SSVCAMusicHistoricalSamplesInSeconds
SSVCADeviceSimpleOutputMinTargetDB
SSVCADeviceSimpleOutputMaxTargetDB
SSVCADeviceSimpleOutputSlope
SSVCADeviceSimpleMinTargetDB
SSVCADeviceSimpleMaxTargetDB
SSVCADeviceSimpleDBToSystemVolSlope
SSVCADeviceSimpleMicSensitivityOffset
SSVCADeviceSimplePreTriggerSilenceSampleCount
SSVCAMinTTSSystemVolume
SSVCAMaxTTSSystemVolume
SSVCAUserIntentValidForSeconds
SSVCAUserIntentVolumeIncreaseFactor
SSVCAUserIntentVolumeDecreaseFactor
SSVCAUserIntentPermanentOffsetFactorDelta
SSVCAUserIntentPermanentOffsetFactorLowerBound
SSVCAUserIntentPermanentOffsetFactorUpperBound
SSVCADeviceSimpleMinTTSVolume
SSVCADeviceSimpleMaxTTSVolume
SSVCADeviceDefaultMinTTSVolume
SSVCADeviceDefaultMaxTTSVolume
SSVCADeviceDefaultASVOffMinTTSVolume
SSVCADeviceSimpleASVOffMinTTSVolume
SSVCADeviceDefaultMicSensitivityOffset
SSVCAVolumeHalfLifeSeconds
SSVCAHistoricalVolumeBufferSize
SSVCAMaximumCompensatedSpeechLevelNearField
-[CSAsset(SmartSiriVolume) _getNumberFromASVDictionaryForKey:category:default:]
recordDeviceInfo
playbackRoute
playbackDeviceTypeList
%@ {recordDeviceInfo = %@, playbackRoute = %@, playbackDevices = %@
-[CSSpeakerRecognitionProxy initWithDelegate:]
CSVoiceTriggerXPCService Queue
-[CSVoiceTriggerXPCService enableVoiceTrigger:withAssertion:xpcClient:]_block_invoke
-[CSVoiceTriggerXPCService setPhraseSpotterBypassing:timeout:xpcClient:]_block_invoke
-[CSVoiceTriggerXPCService setRaiseToSpeakBypassing:timeout:xpcClient:]_block_invoke
-[CSVoiceTriggerXPCService notifyVoiceTriggeredSiriSessionCancelledWithXpcClient:]_block_invoke
-[CSVoiceTriggerXPCService fetchVoiceTriggerDailyStats]_block_invoke
-[CSVoiceTriggerXPCService _createXPCClientConnectionIfNeeded:]
-[CSVoiceTriggerXPCService voiceTriggerXPCClient:didDisconnect:]_block_invoke
-[CSVoiceTriggerXPCService _teardownXPCClientIfNeeded]
v12@?0i8
-[CSVoiceTriggerAssetDownloadMonitor _startMonitoringWithQueue:]
-[CSVoiceTriggerAssetDownloadMonitor _stopMonitoring]
-[CSVoiceTriggerAssetDownloadMonitor _didInstalledNewVoiceTriggerAsset]
com.apple.MobileAsset.VoiceTriggerAssets.ma.new-asset-installed
com.apple.MobileAsset.VoiceTriggerAssetsIPad.ma.new-asset-installed
com.apple.MobileAsset.VoiceTriggerAssetsWatch.ma.new-asset-installed
com.apple.MobileAsset.VoiceTriggerAssetsMarsh.ma.new-asset-installed
com.apple.MobileAsset.VoiceTriggerAssetsMac.ma.new-asset-installed
com.apple.MobileAsset.VoiceTriggerAssetsTV.ma.new-asset-installed
Dispose Log Queue
+[CSUtils(Directory) removeLogFilesInDirectory:matchingPattern:beforeDays:]_block_invoke
v24@?0@"NSArray"8^@16
+[CSUtils(Directory) clearLogFilesInDirectory:matchingPattern:exceedNumber:]_block_invoke_2
+[CSUtils(Directory) clearLogFilesInDirectory:matchingPattern:exceedNumber:]_block_invoke
Unable to get %@ for file at %@: %@
q24@?0@"NSURL"8@"NSURL"16
B24@?0@"NSURL"8@"NSDictionary"16
+[CSUtils(Directory) _contentsOfDirectoryAtURL:matchingPattern:includingPropertiesForKeys:error:]
Languages
Footprint
Premium
-[CSAudioPreprocessor resetWithSampleRate:containsVoiceTrigger:voiceTriggerInfo:]
-[CSAudioPreprocessor flush]
ZeroFilterMetrics
-[CSAudioPreprocessor _fetchCurrentMetrics]
BeepCancellerMetrics
set option : allowVoiceTriggerAssetsDownload ? %@;           allowEndpointAssetDownload ? %@;           allowLanguageDetectorAssetDownload ? %@;           allowAdBlockerAssetDownload ? %@;           allowSpeakerRecognitionAssetDownload ? %@
com.apple.assistant
Siri Global
 - %@
CSKeychainValueForAccountAndKey
CSBluetoothManager Queue
-[CSBluetoothManager getBTLocalDeviceWithCompletion:]
-[CSBluetoothManager getBTLocalDeviceWithCompletion:]_block_invoke
v16@?0^{BTLocalDeviceImpl=}8
-[CSBluetoothManager _getWirelessSplitterInfoFromLocalDevice:]
-[CSBluetoothManager _detachBluetoothSession]
-[CSBluetoothManager _attachBluetoothSession]
CSBluetoothManager
-[CSBluetoothManager _sessionAttached:result:]
-[CSBluetoothManager _sessionDetached:]
-[CSBluetoothManager _sessionTerminated:]
-[CSBluetoothManager _setUpLocalDevice]
CSSiriAssertionMonitor queue
-[CSSiriAssertionMonitor init]
-[CSSiriAssertionMonitor _stopMonitoring]
-[CSSiriAssertionMonitor enableAssertionReceived]_block_invoke
-[CSSiriAssertionMonitor disableAssertionReceived]_block_invoke
com.apple.corespeech.CSAccessorySiriClientBehaviourMonitor
-[CSAccessorySiriClientBehaviorMonitor notifyWillStartStreamWithContext:option:forAccessory:]_block_invoke
-[CSAccessorySiriClientBehaviorMonitor notifyDidStartStreamWithContext:successfully:option:withEventUUID:forAccessory:]_block_invoke
-[CSAccessorySiriClientBehaviorMonitor notifyWillStopStream:reason:forAccessory:]_block_invoke
-[CSAccessorySiriClientBehaviorMonitor notifyDidStopStream:reason:withEventUUID:forAccessory:]_block_invoke
-[CSSpeakerRecognitionAssetDownloadMonitor _startMonitoringWithQueue:]
-[CSSpeakerRecognitionAssetDownloadMonitor _stopMonitoring]
-[CSSpeakerRecognitionAssetDownloadMonitor _didInstalledNewAsset]
-[CSSpeakerRecognitionAssetDownloadMonitor trialAssetDownloadMonitorDelegate:didInstallNewAsset:assetType:]
com.apple.MobileAsset.SpeakerRecognitionAssets.ma.new-asset-installed
CSAudioFileReader Queue
-[CSAudioFileReader initWithURL:]
-[CSAudioFileReader prepareRecording:]
-[CSAudioFileReader startRecording]
-[CSAudioFileReader _readAudioBufferAndFeed]
-[CSAudioFileReader stopRecording]
-[CSAdBlockerAssetDownloadMonitor _startMonitoringWithQueue:]
-[CSAdBlockerAssetDownloadMonitor _stopMonitoring]
-[CSAdBlockerAssetDownloadMonitor _didInstalledNewAdBlockerAsset]
-[CSAdBlockerAssetDownloadMonitor trialAssetDownloadMonitorDelegate:didInstallNewAsset:assetType:]
com.apple.MobileAsset.AdBlockerAssets.ma.new-asset-installed
CSAudioRouteChangeMonitorImplWatch queue
-[CSAudioRouteChangeMonitorImplWatch activeAudioRouteDidChange:]_block_invoke
-[CSAudioRouteChangeMonitorImplWatch _startMonitoringWithQueue:]
-[CSAudioRouteChangeMonitorImplWatch _stopMonitoring]
-[CSAudioRouteChangeMonitorImplWatch _notifyHearstConnectionState:]
-[CSAudioRouteChangeMonitorImplWatch _systemControllerDied:]
-[CSAudioSampleRateConverter _createSampleRateConverterWithInASBD:outASBD:]
CSAudioSampleRateConverter.m
Too many buffers
i32@?0^I8^{AudioBufferList=I[1{AudioBuffer=II^v}]}16^^{AudioStreamPacketDescription}24
-[CSAudioSampleRateConverter convertSampleRateOfBuffer:]
CSLanguageDetectorAssetMonitor
v24@?0@"NSArray"8@"NSError"16
-[CSLanguageDetectorAssetMonitor startMonitor]_block_invoke
en-US
-[CSLanguageDetectorAssetMonitor _supportedLocale:]_block_invoke
v24@?0@"CSAsset"8@"NSError"16
com.apple.MobileAsset.LanguageDetectorAssets.ma.new-asset-installed
-[CSSiriSpeechRecordingContext dealloc]
v24@?0@"NSURL"8@"NSError"16
%@ (sessionUUID = %@)
-[CSSiriSpeechRecordingContext initWithSessionUUID:turnIdentifier:]
com.apple.assistant.request.speech-context
-[CSSiriSpeechRecordingContext becomeCurrent]
-[CSSiriSpeechRecordingContext resignCurrent]
-[CSSiriSpeechRecordingContext updateStartSpeechId:]
-[CSSiriSpeechRecordingContext updateSelectedResultCandidateId:]
-[CSSiriSpeechRecordingContext updateAccessToRecordedAudioForVoiceIdentificationTraining:forResultCandidateId:sharedUserId:]
-[CSSiriSpeechRecordingContext getAudioRecordRouteAndDeviceIdentificationWithCompletion:]_block_invoke
-[CSSiriSpeechRecordingContext acquireRecordedAudioWithHandler:]
-[CSSiriSpeechRecordingContext acquireRecordedAudioWithHandler:]_block_invoke
v16@?0q8
-[CSSiriSpeechRecordingContext updateAudioRecordContext:]
-[CSSiriSpeechRecordingContext updateAudioRecordDeviceInfo:]
-[CSSiriSpeechRecordingContext updateVoiceTriggerInfo:]
-[CSSiriSpeechRecordingContext updateRecordingInfo:]
-[CSSiriSpeechRecordingContext updateRecordingSettings:]
-[CSSiriSpeechRecordingContext willPrepareAndStartRecordingWithAudioActivationInfo:]
Start Recording
sessionUUID
v16@?0@"<AFAssertionContextMutating>"8
-[CSSiriSpeechRecordingContext willPrepareAndStartRecordingWithAudioActivationInfo:]_block_invoke
v24@?0@"AFAssertionContext"8@"NSError"16
-[CSSiriSpeechRecordingContext didDetectTwoShotWithAudioActivationInfo:atTime:]
Two Shot Detection
-[CSSiriSpeechRecordingContext didDetectTwoShotWithAudioActivationInfo:atTime:]_block_invoke_2
-[CSSiriSpeechRecordingContext didDetectTwoShotWithAudioActivationInfo:atTime:]_block_invoke
-[CSSiriSpeechRecordingContext willStopRecordingAtHostTime:]
Stop Recording
-[CSSiriSpeechRecordingContext didStopRecordingWithError:]
-[CSSiriSpeechRecordingContext relinquishAudioSessionAssertionsWithContext:]
-[CSSiriSpeechRecordingContext relinquishAudioSessionAssertionsWithError:]
-[CSSiriSpeechRecordingContext beginRecordingAudioWithAudioStreamBasicDescription:]
-[CSSiriSpeechRecordingContext endRecordingAudio]
-[CSSiriSpeechRecordingContext endRecordingAudio]_block_invoke_2
-[CSSiriSpeechRecordingContext endRecordingAudio]_block_invoke
%@.wav
@"NSString"8@?0
-[CSSiriSpeechRecordingContext _finalizeAudioFileWriterWithCompletion:]
v32@?0@"NSFileHandle"8@"NSURL"16@"NSError"24
-[CSSiriSpeechRecordingContext instrumentSiriCueForAlertType:]_block_invoke
-[CSSiriSpeechRecordingContext emitRequestLinkEventForMHUUID:]
-[CSSiriSpeechRecordingContext _didBecomeCurrent]
-[CSSiriSpeechRecordingContext _didResignCurrent]
-[CSSiriSpeechRecordingContext _donateRecordedAudioForVoiceIdentificationTrainingWithCompletion:]_block_invoke
ALLOWED
DENIED
-[CSSiriSpeechRecordingContext _donateRecordedAudioForVoiceIdentificationTrainingWithCompletion:]_block_invoke_2
-[CSSiriSpeechRecordingContext _removeRecordedAudio]
com.apple.CoreSpeech.Connection.Listener
-[CSSmartSiriVolumeClient init]
-[CSSmartSiriVolumeClient getVolumeForTTSType:withContext:]_block_invoke
v24@?0@"NSError"8@"CSSmartSiriVolumeEstimate"16
-[CSSmartSiriVolumeClient setSmartSiriVolumePercentage:]_block_invoke
-[CSSmartSiriVolumeClient setSmartSiriVolumeDirection:]_block_invoke
-[CSSmartSiriVolumeClient setPermanentVolumeOffsetWithDirection:]_block_invoke
-[CSSmartSiriVolumeClient didTTSVolumeChangeForReason:]_block_invoke
-[CSSmartSiriVolumeClient _getRemoteServiceProxyObject]_block_invoke
-[CSSmartSiriVolumeClient _getRemoteServiceProxyObject]
com.apple.corespeech.corespeechd.ssv.service
-[CSSmartSiriVolumeClient _createClientConnection]_block_invoke
CSAudioInjectionProvider
ATVRemoteInput
BuiltInMic
-[CSAudioInjectionProvider dealloc]
-[CSAudioInjectionProvider stop]
-[CSAudioInjectionProvider startAudioStreamWithOption:recordDeviceIndicator:error:]
-[CSAudioInjectionProvider stopAudioStreamWithRecordDeviceIndicator:error:]
BuiltInSpeaker
-[NSString(XPCObject) _cs_initWithXPCObject:]
RemoteVAD Align Queue
-[CSOpportuneSpeakListener startListenWithOption:completion:]
-[CSOpportuneSpeakListener _startRequestWithCompletion:]_block_invoke
-[CSOpportuneSpeakListener _startRequestWithCompletion:]
-[CSOpportuneSpeakListener stopListenWithStateReset:completion:]_block_invoke
-[CSOpportuneSpeakListener stopListenWithStateReset:completion:]
-[CSOpportuneSpeakListener audioStreamProvider:audioBufferAvailable:]
-[CSOpportuneSpeakListener spgEndpointAnalyzer:hasSilenceScoreEstimate:clientProcessedAudioTimeMS:]
com.apple.corespeech.corespeechd.voiceid.xpc
v16@?0@"NSObject<OS_xpc_object>"8
-[CSVoiceIdXPCClient _handleListenerEvent:]
-[CSVoiceIdXPCClient _handleListenerError:]
utterencePath
audioDevice
audioRecord
voiceTriggerEventInfo
otherCtxt
type
body
result
resultErrorDomain
resultErrorCode
NviError
-[CSNNVADEndpointAnalyzer init]
-[CSNNVADEndpointAnalyzer preheat]
-[CSNNVADEndpointAnalyzer reset]
-[CSNNVADEndpointAnalyzer processAudioSamplesAsynchronously:]
-[CSNNVADEndpointAnalyzer recordingStoppedForReason:]
-[CSNNVADEndpointAnalyzer stopEndpointer]
-[CSNNVADEndpointAnalyzer resetForNewRequestWithSampleRate:recordContext:]
com.apple.corespeech.corespeechd.activation.xpc
-[CSActivationXPCClient dealloc]
-[CSActivationXPCClient _handleListenerEvent:]
-[CSActivationXPCClient _handleListenerError:]
-[CSActivationXPCClient notifyActivationEvent:completion:]
event
+[CSUtils(LanguageCode) getSiriLanguageWithFallback:]
+[CSUtils(LanguageCode) getSiriLanguageWithEndpointId:fallbackLanguage:]
CSStopRecordingReasonDefault
CSStopRecordingForClientEndpoint
CSStopRecordingForServerEndpoint
CSStopRecordingForReleaseAudioSession
CSStopRecordingForRequestCancellation
, %llu}
triggerEndMachTime
-[CSMyriadSelfTriggerCoordinator selfTriggerDetector:didDetectSelfTrigger:]
com.apple.siri.corespeech.selftrigger
FirstPktLatency
TrailingPktLatency
TrailingPktSpeechLatency
-[CSEndpointLatencyInfo addPktInfoWithTimestamp:arrivalTimestamp:currentMachTime:]
-[CSEndpointLatencyInfo reportWithRequestMHUUID:]
-[CSCommandControlStreamEventMonitor isStreaming]
CSSiriAudioFileWriterErrorDomain
CSSiriAudioFileWriterExtAudioFileErrorDomain
SavedAudioFile
CSSiriAudioFileWriter.m
Invalid parameter not satisfying: %@
type != AFAudioFileTypeNone
CSSiriAudioFileWriterQueue
-[CSSiriAudioFileWriter _initWithType:pathGenerator:xorFileHandle:priority:]_block_invoke
path
-[CSSiriAudioFileWriter _close]
-[CSSiriAudioFileWriter _delete]
-[CSSiriAudioFileWriter configureWithAudioStreamBasicDescription:]
AudioFile Already configured
-[CSSiriAudioFileWriter configureWithAudioStreamBasicDescription:]_block_invoke
-[CSSiriAudioFileWriter appendAudioData:]_block_invoke
-[CSSiriAudioFileWriter flushWithCompletion:]_block_invoke
_AudioStreamBasicDescriptionForAFAudioFileType
com.apple.corespeech.corespeechservices
com.apple.corespeech.xpc
+[CSCoreSpeechServices installedVoiceTriggerAssetForLanguageCode:completion:]_block_invoke
reason
CoreSpeechXPC service invalidated
+[CSCoreSpeechServices fetchRemoteVoiceTriggerAssetForLanguageCode:completion:]_block_invoke
v24@?0@"NSString"8@"NSError"16
+[CSCoreSpeechServices getCurrentVoiceTriggerLocaleWithEndpointId:completion:]
+[CSCoreSpeechServices getCurrentVoiceTriggerLocaleWithEndpointId:completion:]_block_invoke
v16@?0@"NSString"8
+[CSCoreSpeechServices voiceTriggerRTModelForVersion:minorVersion:accessoryRTModelType:endpointId:downloadedModels:preinstalledModels:completion:]_block_invoke
+[CSCoreSpeechServices voiceTriggerRTModelForVersion:minorVersion:downloadedModels:preinstalledModels:completion:]
+[CSCoreSpeechServices voiceTriggerRTModelForVersion:minorVersion:downloadedModels:preinstalledModels:completion:]_block_invoke
+[CSCoreSpeechServices voiceTriggerJarvisLanguageList:jarvisSelectedLanguage:completion:]_block_invoke
+[CSCoreSpeechServices voiceTriggerJarvisLanguageList:jarvisSelectedLanguage:completion:]
+[CSCoreSpeechServices requestUpdatedSATAudio]_block_invoke
v12@?0B8
+[CSCoreSpeechServices getFirstPassRunningMode]_block_invoke
+[CSAudioStreamRequest defaultRequestWithContext:]
+[CSAudioStreamRequest requestForLpcmRecordSettingsWithContext:]
+[CSAudioStreamRequest requestForOpusRecordSettingsWithContext:]
+[CSAudioStreamRequest requestForSpeexRecordSettingsWithContext:]
[requiresHistoricalBuffer = %@]
[useCustomizedRecordSettings = %@]
[lpcmIsFloat = %@]
[isSiri = %@]
[sampleRate = %lf]
[numberOfChannels = %lu]
requiresHistoricalBuffer
useCustomizedRecordSettings
audioFormat
sampleRate
lpcmBitDepth
lpcmIsFloat
NumberOfChannels
encoderBitRate
isSiri
recordContext
v20@?0B8Q12
-[CSSelfTriggerDetectorEnabledPolicyMac _addSelfTriggerDetectorEnabledConditions]_block_invoke
B8@?0
CSSpeechManager Asset Query Queue
-[CSSpeechManager startManager]
-[CSSpeechManager registerSpeechController:]
-[CSSpeechManager registerSiriClientProxy:]
v32@?0@"NSNumber"8@"CSAudioProvider"16^B24
-[CSSpeechManager audioProviderWithContext:error:]
-[CSSpeechManager audioProviderWithContext:error:]_block_invoke
v32@?0Q8q16@"NSError"24
-[CSSpeechManager audioProviderWithStreamID:]_block_invoke
-[CSSpeechManager _getAudioRecorderWithError:]
-[CSSpeechManager audioProviderInvalidated:streamHandleId:]_block_invoke
-[CSSpeechManager audioRecorderWillBeDestroyed:]_block_invoke
-[CSSpeechManager voiceTriggerAssetHandler:endpointId:didChangeCachedAsset:]
-[CSSpeechManager _handleClearLoggingFileTimer]
-[CSSpeechManager _createClearLoggingFileTimer]
-[CSSpeechManager _startClearLoggingFilesTimer]
-[CSSpeechEndHostTimeEstimator notifyTrailingSilenceDurationAtEndpoint:]
-[CSSpeechEndHostTimeEstimator estimatedSpeechEndHostTime]
CSCommandControlListener
-[CSCommandControlListener startListenWithOption:completion:]
-[CSCommandControlListener _startRequestWithCompletion:]_block_invoke
-[CSCommandControlListener _startRequestWithCompletion:]
-[CSCommandControlListener stopListenWithCompletion:]
-[CSCommandControlListener stopListenWithCompletion:]_block_invoke
-[CSCommandControlListener audioStreamProvider:didStopStreamUnexpectly:]_block_invoke
-[CSCommandControlListener CSXPCClient:didDisconnect:]_block_invoke
FlexKwdSpotter
recognizer_flexKwd.json
flexKwdConfigFile
flexKwd.Thresholds
flexKwdThresholdsFile
Serial CSAssetManager queue
-[CSAssetManager initWithDownloadOption:]
-[CSAssetManager initWithDownloadOption:]_block_invoke
ENABLED
DISABLED
-[CSAssetManager setAssetDownloadingOption:]_block_invoke
-[CSAssetManager _fetchRemoteMetaData]
-[CSAssetManager _canFetchRemoteAsset:]
-[CSAssetManager CSLanguageCodeUpdateMonitor:didReceiveLanguageCodeChanged:]
-[CSAssetManager _createPeriodicalDownloadTimer]
-[CSAssetManager _createPeriodicalDownloadTimer]_block_invoke
-[CSAssetManager _startPeriodicalDownload]
-[CSAssetManager _stopPeriodicalDownload]
RecordedAudio
TrimmedAudio
com.apple.corespeech.endpointer.xpc.client
com.apple.corespeech.endpointer.xpc.connection
-[CSEndpointerXPCClient endpointerModelVersion]_block_invoke_2
v24@?0@"NSError"8@"NSString"16
-[CSEndpointerXPCClient endpointerModelVersion]_block_invoke
-[CSEndpointerXPCClient endpointerModelVersion]
-[CSEndpointerXPCClient elapsedTimeWithNoSpeech]_block_invoke_2
v24@?0@"NSError"8d16
-[CSEndpointerXPCClient elapsedTimeWithNoSpeech]_block_invoke
-[CSEndpointerXPCClient elapsedTimeWithNoSpeech]
-[CSEndpointerXPCClient trailingSilenceDurationAtEndpoint]_block_invoke_2
-[CSEndpointerXPCClient trailingSilenceDurationAtEndpoint]_block_invoke
-[CSEndpointerXPCClient trailingSilenceDurationAtEndpoint]
-[CSEndpointerXPCClient endPointAnalyzerType]_block_invoke_2
v24@?0@"NSError"8Q16
-[CSEndpointerXPCClient endPointAnalyzerType]_block_invoke
-[CSEndpointerXPCClient endPointAnalyzerType]
-[CSEndpointerXPCClient _getRemoteServiceProxyObject]
-[CSEndpointerXPCClient _getRemoteServiceProxyObject]_block_invoke
com.apple.corespeech.corespeechd.endpointer.service
-[CSEndpointerXPCClient _createClientConnection]_block_invoke
-[CSEndpointerXPCClient didDetectHardEndpointAtTime:withTotalAudioRecorded:endpointBufferHostTime:featuresAtEndpoint:endpointerType:serverFeatureLatencyDistribution:additionalMetrics:]
-[CSEndpointerXPCClient didDetectHardEndpointAtTime:withMetrics:]
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
deque
-[NviDirectionalitySignalProvider initWithDataSource:assetsProvider:]
-[NviDirectionalitySignalProvider addDelegate:]
-[NviDirectionalitySignalProvider removeDelegate:]
-[NviDirectionalitySignalProvider startWithNviContext:didStartHandler:]
-[NviDirectionalitySignalProvider reset]
-[NviDirectionalitySignalProvider stopWithDidStopHandler:]
-[CSConnectionListener initWithMachService:withServiceInterface:withServiceObject:withDelegateInterface:]
-[CSConnectionListener dealloc]
-[CSConnectionListener listener:shouldAcceptNewConnection:]
corespeech.corespeechd.xpc
-[CSConnectionListener listener:shouldAcceptNewConnection:]_block_invoke
-[CSConnectionListener listener:shouldAcceptNewConnection:]_block_invoke_2
-[CSConnectionListener notifyClientsWithBlock:]_block_invoke
+[CSAudioRecorderFactory audioRecorderWithQueue:error:]
samples_fed
best_start
best_end
best_score
is_secondchance
isEarlyDetect
triggerStartSampleCount
clientStartSampleCount
triggerFireMachTime
activeChannel
twoShotAudibleFeedbackDelay
musicVolume
mediaPlayState
CSSpeechRecordSettingsKey_AudioSessionActiveDelay
CSSpeechRecordSettingsKey_AudioSessionActiveReason
CSSpeechRecordSettingsKey_LanguageDetectorLocales
CSSpeechRecordSettingsKey_LanguageDetectorDictationLanguages
CSSpeechRecordSettingsKey_LanguageDetectorCurrentKeyboard
CSSpeechRecordSettingsKey_LanguageDetectorWasLanguageToggled
CSSpeechRecordSettingsKey_LanguageDetectorMultilingualKeyboardLanguages
CSSpeechRecordSettingsKey_LanguageDetectorKeyboardConvoLanguagePriors
CSSpeechRecordSettingsKey_LanguageDetectorKeyboardGlobalLanguagePriors
CSSpeechRecordSettingsKey_LanguageDetectorPreviousMessageLanguage
CSSpeechRecordSettingsKey_LanguageDetectorGlobalLastKeyboardUsed
CSSpeechRecordSettingsKey_LanguageDetectorDictationLanguagePriors
CSSpeechRecordSettingsKey_LanguageDetectorConversationalMessages
CSSpeechRecordSettingsKey_disableEndpointer
CSSpeechRecordSettingsKey_DictationRequestAppName
CSSpeechRecordSettingsKey_DictationRequestAppBundleID
CSSpeechRecordSettingsKey_DictationStartSampleId
CSSpeechRecordSettingsKey_isDucking
CSSpeechRecordSettingsKey_disableLocalSpeechRecognizer
CSSpeechRecordSettingsKey_triggerEventInfo
CSSpeechRecordSettingsKey_requestMHUUID
CSSpeechRecordSettingsKey_siriSessionUUID
spIdAudioProcessedDuration
spIdUnknownUserScore
spIdKnownUserScores
spIdKnownUserRawScores
spIdUserScoresVersion
spIdKnownUserProfileVersions
spIdScoreThresholdingType
spIdVTInvocationScoreThresholdingType
spIdNonVTInvocationScoreThresholdingType
SpIdScoreThreshold
spIdAssetVersion
spIdDirectionSigsArr
shouldRecordUserAudio
shouldRecordPayload
userIdentityClassification
userClassified
CSSpeechController ContextReset
com.apple.corespeech.twoShotAudibleFeedback
MediaPlayingObserverQueue
v16@?0@"NSOrderedSet"8
-[CSSpeechController initializeRecordSessionWithRecordContext:]
-[CSSpeechController startController]
-[CSSpeechController prepareRecordWithSettings:error:]
-[CSSpeechController _fetchLastTriggerInfo]
-[CSSpeechController _fetchLastTriggerInfo]_block_invoke_2
v24@?0@"NSDictionary"8@"NSDictionary"16
-[CSSpeechController _addAcousticSLInfo]
v16@?0@"NSDictionary"8
-[CSSpeechController _activateAudioSessionWithReason:delay:delayRequested:error:]_block_invoke
-[CSSpeechController _activateAudioSessionWithReason:delay:delayRequested:error:]
com.apple.corespeech.ducking
-[CSSpeechController _scheduleActivateAudioSessionWithDelay:sessionActivateReason:scheduleReason:validator:completion:]_block_invoke
-[CSSpeechController _scheduleActivateAudioSessionWithDelay:sessionActivateReason:scheduleReason:validator:completion:]
-[CSSpeechController _cancelPendingAudioSessionActivateForReason:]
-[CSSpeechController _performPendingAudioSessionActivateForReason:]
-[CSSpeechController _lazyActivateAudioSessionWithReason:error:]
-[CSSpeechController _lazyActivateAudioSessionWithReason:error:]_block_invoke
-[CSSpeechController _activateAudioSessionWithReason:error:]
-[CSSpeechController _doActivateAudioSessionWithReason:error:]
-[CSSpeechController _updateRecordContextIfNeeded:]
-[CSSpeechController setCurrentRecordContext:error:]
-[CSSpeechController preheat]
-[CSSpeechController prewarmAudioSession]
-[CSSpeechController resetAudioSession]
-[CSSpeechController reset]
-[CSSpeechController releaseAudioSession]
-[CSSpeechController releaseAudioSession:]
v32@?0@8#16@?<v@?>24
-[CSSpeechController startRecordingWithSettings:error:]
-[CSSpeechController startRecordingWithSettings:error:]_block_invoke
-[CSSpeechController startRecordingWithSettings:error:]_block_invoke_2
-[CSSpeechController _startPhaticDecision]
-[CSSpeechController _startPhaticDecision]_block_invoke
not 
-[CSSpeechController stopRecording]
-[CSSpeechController stopRecordingWithOptions:]
-[CSSpeechController recordRoute]
-[CSSpeechController recordDeviceInfo]
-[CSSpeechController audioDeviceInfo]
-[CSSpeechController playbackRoute]
-[CSSpeechController _didStopForReason:]
-[CSSpeechController audioStreamProvider:didStopStreamUnexpectly:]
-[CSSpeechController _audioStreamProvdider:audioBufferAvailable:]
-[CSSpeechController audioStreamProvider:audioChunkForTVAvailable:]_block_invoke
-[CSSpeechController audioStreamProvider:didHardwareConfigurationChange:]
-[CSSpeechController audioStreamProvider:didHardwareConfigurationChange:]_block_invoke
-[CSSpeechController audioSessionProvider:providerInvalidated:]_block_invoke_2
-[CSSpeechController audioSessionProvider:didChangeContext:]
-[CSSpeechController audioSessionController:didReceiveAudioSessionMediaServicesWereResetNotificationWithUserInfo:]
-[CSSpeechController audioAlertProvidingDidFinishAlertPlayback:ofType:error:]
-[CSSpeechController audioAlertProvidingDidFinishAlertPlayback:ofType:error:]_block_invoke
-[CSSpeechController audioSessionProviderBeginInterruption:]
-[CSSpeechController audioSessionProviderBeginInterruption:]_block_invoke
-[CSSpeechController audioSessionProviderBeginInterruption:withContext:]
-[CSSpeechController audioSessionProviderBeginInterruption:withContext:]_block_invoke
-[CSSpeechController audioSessionProviderEndInterruption:]
-[CSSpeechController audioSessionProviderEndInterruption:]_block_invoke
-[CSSpeechController audioSessionProvider:willSetAudioSessionActive:]
-[CSSpeechController audioSessionProvider:willSetAudioSessionActive:]_block_invoke
-[CSSpeechController audioSessionProvider:didSetAudioSessionActive:]
-[CSSpeechController audioSessionProvider:didSetAudioSessionActive:]_block_invoke
-[CSSpeechController didTTSVolumeChange:forReason:]
-[CSSpeechController didTTSVolumeChange:forReason:]_block_invoke
-[CSSpeechController audioConverterDidConvertPackets:packets:durationInSec:timestamp:arrivalTimestampToAudioRecorder:]
-[CSSpeechController setAlertSoundFromURL:forType:]
-[CSSpeechController playAlertSoundForType:]
-[CSSpeechController playRecordStartingAlertAndResetEndpointer]
-[CSSpeechController stopEndpointer]
-[CSSpeechController setMeteringEnabled:]
-[CSSpeechController _createAudioPowerMeterIfNeeded]
-[CSSpeechController outputReferenceChannel]
-[CSSpeechController voiceTriggerInfo]
-[CSSpeechController endpointer:detectedTwoShotAtTime:]
-[CSSpeechController keywordDetectorDidDetectKeyword]_block_invoke
-[CSSpeechController _fetchAudioDecoderForTV:]
-[CSSpeechController _createAudioProviderFromXPCWithContext:]
-[CSSpeechController _setupAudioProviderFromXPC:context:]
Accounts
Speech Identifier
%c%c%c%c
none
-[CSSpeechController endpointerModelVersion]
-[CSSpeechController cancelCurrentLanguageDetectorRequest]_block_invoke
-[CSSpeechController beginWaitingForMyriad]
-[CSSpeechController endWaitingForMyriadWithDecision:]
-[CSSpeechController _setSoundPlayingState]
 NOT
-[CSSpeechController CSXPCClient:didDisconnect:]_block_invoke
-[CSSpeechController _teardownAudioProviderIfNeeded]
-[CSSpeechController _setMediaPlaybackState:isInterrupted:]
-[CSSpeechController _setAlarmIsPlaying:]
-[CSSpeechController _setTimerIsPlaying:]
-[CSSpeechController nowPlayingObserver:playbackStateDidChangeFrom:to:lastPlayingDate:]_block_invoke
-[CSSpeechController clockAlarmObserver:alarmDidFire:]_block_invoke
-[CSSpeechController clockAlarmObserver:alarmDidDismiss:]_block_invoke
-[CSSpeechController clockTimerObserver:timerDidFire:]_block_invoke
-[CSSpeechController clockTimerObserver:timerDidDismiss:]_block_invoke
com.apple.CoreSpeech.Connection.SSR.Listener
-[CSSSRXPCClient init]
-[CSSSRXPCClient _getRemoteServiceProxyObject]
-[CSSSRXPCClient _getRemoteServiceProxyObject]_block_invoke
com.apple.corespeech.corespeechd.ssr.service
-[CSSSRXPCClient _createClientConnection]_block_invoke
-[CSSSRXPCClient didReceiveSpeakerRecognitionScoreCard:]
RequestContext
DetectedToken
TriggerMachTime
TriggerAbsStartSampleId
{attendingCtx: %@, detctedToken: %@, triggerMachTime=%llu, triggerStartSampleId=%llu}
rtblobs
adkblobs
blob
majorVersion
minorVersion
signature
cert
rtlocalemap
jarvislocalemap
adklocalemap
-[CSAsset(RTModel) createRTModelWithLocale:]
-[CSAsset(RTModel) latestHearstRTModelForLocale:]
-[CSAsset(RTModel) rtModelWithAccessoryRTModelType:majorVersion:minorVersion:locale:]
-[CSAsset(RTModel) localeMapWithName:]
%02x
%@ {request = %@, options = %@, player = %@, playerItem = %@}
-[CSSiriAudioPlaybackSessionImplAVPlayerBased _prepareWithOptions:audioSession:completion:]
-[CSSiriAudioPlaybackSessionImplAVPlayerBased _prepareWithOptions:audioSession:completion:]_block_invoke
Unable to create player item.
Unable to replace current item of player.
Timed out when waiting for player item status to change to ready to play.
status
Failed to change player item status to ready to play.
v24@?0@8@16
-[CSSiriAudioPlaybackSessionImplAVPlayerBased _startWithOptions:audioSession:preparationHandler:executionHandler:finalizationHandler:]
Attempted to start audio playback session when it is already active.
-[CSSiriAudioPlaybackSessionImplAVPlayerBased _startWithOptions:audioSession:preparationHandler:executionHandler:finalizationHandler:]_block_invoke
Audio playback session is already inactive after preparation.
-[CSSiriAudioPlaybackSessionImplAVPlayerBased _startWithOptions:audioSession:preparationHandler:executionHandler:finalizationHandler:]_block_invoke_2
Audio playback session is already inactive after player seek to begin.
Player failed to seek to begin.
Stopped playback.
-[CSSiriAudioPlaybackSessionImplAVPlayerBased _finalizeWithError:]
-[CSSiriAudioPlaybackSessionImplAVPlayerBased _resetPlayerItem]
-[CSSiriAudioPlaybackSessionImplAVPlayerBased playerItemDidPlayToEndTime:]
-[CSSiriAudioPlaybackSessionImplAVPlayerBased playerItemFailedToPlayToEndTime:]
Player item failed to play to end time.
com.apple.siri.speechmodeltraining
com.apple.corespeech.speechmodeltraining.xpc
com.apple.speech.speechmodeltraining
SpeechModelTrainingClient
v24@?0@"NSDictionary"8@"NSError"16
Assistant/SpeechPersonalizedLM
Assistant/SpeechPersonalizedLM_Fides
Received Error %@
Input directory path(%@) does not match expected path
-[CSAudioStartStreamOption(AVVC) avvcStartRecordSettingsWithAudioStreamHandleId:]
-[NviSignalProvidersController initWithAssetsProvider:dataSourceMap:signalProviderToDataSourceMap:]
-[NviSignalProvidersController dealloc]
NviSignalProvidersController.m
No DataSource found for SignalType: %@
-[NviSignalProvidersController _setupSignalProviders:]
-[NviSignalProvidersController _startDataSourcesWithContext:]
-[NviSignalProvidersController _startDataSourcesWithContext:]_block_invoke
-[NviSignalProvidersController _startSignalProvidersWithContext:]
-[NviSignalProvidersController _startSignalProvidersWithContext:]_block_invoke
-[NviSignalProvidersController _stopDataSources]_block_invoke
-[NviSignalProvidersController _stopDataSources]
-[NviSignalProvidersController _stopCurrentlyRunningSignalProviders]_block_invoke
-[NviSignalProvidersController _stopCurrentlyRunningSignalProviders]
-[NviSignalProvidersController _iterateSignalMask:withHandler:]
v16@?0@"<NviSignalProvider>"8
CSXPCClient Reply Queue
com.apple.corespeech.corespeechd.xpc
-[CSXPCClient sendXPCClientType]
xpcClientType
-[CSXPCClient prepareAudioProviderWithContext:clientType:error:]
context
clientType
activateReason
dynamicAttribute
dictationRequestBundleId
deactivateOption
setDuckOthersOption
enableSmartRoutingConsideration
enableMiniDucking
alertType
soundPath
alertStartTime
-[CSXPCClient alertStartTime]
alertBehavior
setMeterEnable
channelNumber
power
-[CSXPCClient peakPowerForChannel:]
-[CSXPCClient averagePowerForChannel:]
-[CSXPCClient audioMetric]
audioMetric
audioStreamRequest
-[CSXPCClient audioStreamWithRequest:streamName:error:]
v24@?0@"CSAudioStream"8@"NSError"16
-[CSXPCClient audioStreamWithRequest:streamName:completion:]
-[CSXPCClient prepareAudioStreamSync:request:error:]
-[CSXPCClient prepareAudioStream:request:completion:]
startAudioStreamOption
-[CSXPCClient acousticSLResultForContext:completion:]
-[CSXPCClient acousticSLResultForContext:completion:]_block_invoke
acousticSLResult
-[CSXPCClient triggerInfoForContext:completion:]
rtsTriggerInfo
recordRoute
audioDeviceInfo
recordSettings
-[CSXPCClient audioChunkFrom:to:]
-[CSXPCClient audioChunkFrom:to:channelIdx:]
-[CSXPCClient audioChunkToEndFrom:]
-[CSXPCClient audioChunkToEndFrom:channelIdx:]
-[CSXPCClient saveRecordingBufferFrom:to:toURL:]
-[CSXPCClient saveRecordingBufferToEndFrom:toURL:]
-[CSXPCClient holdAudioStreamWithDescription:timeout:]
-[CSXPCClient cancelAudioStreamHold:]
-[CSXPCClient isRecording]
-[CSXPCClient setAnnounceCallsEnabled:withStreamHandleID:]
deviceID
sessionID
-[CSXPCClient audioSessionIdForDeviceId:]
sampleCount
replyHostTime
-[CSXPCClient hostTimeFromSampleCount:]
hostTime
replySampleCount
-[CSXPCClient sampleCountFromHostTime:]
option
-[CSXPCClient _handleListenerEvent:]
-[CSXPCClient _handleListenerMessage:]
-[CSXPCClient _handleListenerError:]
-[CSXPCClient _handleAlertProvidingDelegateMessageBody:]
didFinishAlertPlayback
errorDomain
errorCode
-[CSXPCClient _handleSessionProvidingDelegateMessageBody:]
interruptionContext
-[CSXPCClient _handleSessionProvidingDelegateBeginInterruptionWithContext:]
willSetAudioSessionActive
didSetAudioSessionActive
streamHandleIdInvalidationflag
didChangeContextFlag
-[CSXPCClient _handleSessionInfoProvidingDelegateMessageBody:]
notificationInfo
-[CSXPCClient _handleSessionInfoProvidingDelegateInterruptionNotification:]
-[CSXPCClient _handleSessionInfoProvidingDelegateRouteChangeNotification:]
-[CSXPCClient _handleSessionInfoProvidingDelegateMediaServicesWereLostNotification:]
-[CSXPCClient _handleSessionInfoProvidingDelegateMediaServicesWereResetNotification:]
-[CSXPCClient _handleStreamProvidingDelegateMessageBody:]
stopReason
chunk
hardwareConfig
Serial CSEventMonitor queue
-[CSEventMonitor _startMonitoringWithQueue:]
CSEventMonitor.m
-[CSEventMonitor _stopMonitoring]
-[CSSmartSiriVolumeManager initWithSamplingRate:withAsset:]
-[CSSmartSiriVolumeManager CSAlarmMonitor:didReceiveAlarmChanged:]
-[CSSmartSiriVolumeManager CSTimerMonitor:didReceiveTimerChanged:]
-[CSSmartSiriVolumeManager CSVolumeMonitor:didReceiveMusicVolumeChanged:]
-[CSSmartSiriVolumeManager CSVolumeMonitor:didReceiveAlarmVolumeChanged:]
-[CSSmartSiriVolumeManager CSAutomaticVolumeEnabledMonitor:didReceiveEnabled:]
numImplicitUtt
numExplicitUtt
numFirstPassTriggersPerDay
-[CSAudioFileLog _closeAudioFile]
-[CSAudioFileLog startRecording]_block_invoke
-input.wav
-[CSAudioFileLog appendAudioData:]_block_invoke
-[CSAudioFileLog stopRecording]_block_invoke
Logs/CrashReporter/CoreSpeech/audio/
-[CSAudioFileLog _getOrCreateAudioLogDirectory]
/tmp
en_US_POSIX
yyyyMMdd-HHmmss
%@/%@%@%@
firstPassEndSampleCount
firstPassStartSampleCount
firstPassGoodness
totalSampleCount
triggerScore
vtEndTime
numSamplesFromHistoricalBuffer
[%@]
[%llu]
[%f]
BuiltInAOPVoiceTrigger
RemoteMicVoiceTrigger
RemoteMicVAD
JarvisVoiceTrigger
mediaserverdLaunched
RemoraVoiceTrigger
uuid
deviceId
activationInfo
vadScore
hosttime
com.apple.corespeech.fakeasset.rolling
-[CoreSpeechXPCFakeModelMonitor _registerForFakeAssetRollNotification]_block_invoke
-[CoreSpeechXPCFakeModelMonitor _registerForFakeAssetRollNotification]
-[CSSmartSiriVolumeUserIntent applyLowerAndUpperBoundsToVolume:]
-[CSSmartSiriVolumeUserIntent applyLowerAndUpperBoundsToVolumeOffset:]
com.apple.MobileAsset.VoiceTriggerAssetsMac
-[CSAssetController init]
Serial CSAssetController queue
V1 Assets Clean-up queue
-[CSAssetController _cleanUpMobileAssetV1Directory]
-[CSAssetController assetOfType:language:]
-[CSAssetController allInstalledAssetsOfType:language:]
q24@?0@"MAAsset"8@"MAAsset"16
v32@?0@"MAAsset"8Q16^B24
-[CSAssetController assetOfType:language:completion:]
-[CSAssetController assetOfType:language:compatibilityVersion:completion:]
v24@?0@"MAAsset"8@"NSError"16
-[CSAssetController installedAssetOfType:language:]
-[CSAssetController installedAssetOfType:language:completion:]
-[CSAssetController _installedAssetOfType:withLanguage:]
-[CSAssetController _installedAssetOfType:query:withLanguage:completion:]_block_invoke
-[CSAssetController _findLatestInstalledAsset:]
-[CSAssetController _assetQueryForAssetType:]
-[CSAssetController _runAssetQuery:completion:]
-[CSAssetController _runAssetQuery:completion:]_block_invoke
-[CSAssetController fetchRemoteMetaOfType:allowRetry:]
-[CSAssetController fetchRemoteMetaOfType:allowRetry:]_block_invoke
v20@?0@"NSError"8B16
-[CSAssetController _fetchRemoteAssetOfType:withLanguage:completion:]
-[CSAssetController _fetchRemoteAssetOfType:withLanguage:query:completion:]_block_invoke_2
-[CSAssetController _fetchRemoteAssetOfType:withLanguage:query:completion:]_block_invoke
-[CSAssetController _downloadAssetCatalogForAssetType:complete:]_block_invoke
-[CSAssetController _updateFromRemoteToLocalAssets:forAssetType:completion:]
-[CSAssetController _downloadAsset:withComplete:]
v16@?0d8
-[CSAssetController _downloadAsset:withComplete:]_block_invoke
-[CSAssetController _startDownloadingAsset:progress:completion:]
v16@?0@"MAProgressNotification"8
+[CSAssetController(Utils) addKeyValuePairForQuery:assetType:]
com.apple.MobileAsset.VoiceTriggerAssets
com.apple.MobileAsset.VoiceTriggerAssetsIPad
com.apple.MobileAsset.VoiceTriggerAssetsWatch
com.apple.MobileAsset.VoiceTriggerAssetsMarsh
com.apple.MobileAsset.VoiceTriggerAssetsTV
com.apple.MobileAsset.SpeechEndpointAssets
com.apple.MobileAsset.LanguageDetectorAssets
com.apple.MobileAsset.AdBlockerAssets
com.apple.MobileAsset.SpeakerRecognitionAssets
Dictation
-[CSSyncKeywordAnalyzerQuasar initWithConfigPath:triggerTokens:useKeywordSpotting:preventDuplicatedReset:]
-[CSSyncKeywordAnalyzerQuasar resetWithLanguage:withFarField:withAudioSource:]
-[CSSyncKeywordAnalyzerQuasar flushAudio]
-[CSSyncKeywordAnalyzerQuasar processAudioChunk:]
-[CSSyncKeywordAnalyzerQuasar phraseIdScores]
+[CSSyncKeywordAnalyzerQuasar dumpEARSpeechRecognitionResults:]
v32@?0@"_EARSpeechRecognitionToken"8Q16^B24
CSAudioInjectionTvRemoteEngine
ApplicationProcessorWithCall
v16@?0@"AFSiriActivationResult"8
-[CSSiriLauncher notifyBuiltInVoiceTrigger:myriadPHash:completion:]_block_invoke
Trigger was during phone call
v16@?0@"<AFMyriadContextMutating>"8
-[CSSiriLauncher notifyWakeKeywordSpokenInBuiltInMic:]_block_invoke
-[CSSiriLauncher notifyCarPlayVoiceTriggerPrewarm:deviceId:completion:]_block_invoke
-[CSSiriLauncher notifyCarPlayVoiceTrigger:deviceId:myriadPHash:completion:]_block_invoke
-[CSSiriLauncher notifyWakeKeywordSpokenCarPlay:deviceId:]_block_invoke
-[CSSiriLauncher notifyBluetoothDeviceVoiceTrigger:deviceId:completion:]_block_invoke
-[CSSiriLauncher notifyWakeKeywordSpokenBluetoothDevice:deviceId:]_block_invoke
-[CSSiriLauncher deactivateSiriActivationConnectionWithReason:withOptions:]_block_invoke
-[CSAudioRouteChangeMonitor _startMonitoringWithQueue:]
CSAudioRouteChangeMonitor.m
-[CSAudioRouteChangeMonitor _stopMonitoring]
-[CSAudioRouteChangeMonitor getHearstConnected:]
-[CSAudioRouteChangeMonitor hearstConnected]
-[CSAudioRouteChangeMonitor getJarvisConnected:]
-[CSAudioRouteChangeMonitor jarvisConnected]
CSSmartSiriVolumeEnablePolicy queue
-[CSSmartSiriVolumeEnablePolicy _addSmartSiriVolumeEnabledConditions]_block_invoke
CSAudioInjectionRemoraEngine
-[CSAudioInjectionRemoraEngine dealloc]
CSAudioInjectionEngine
-[CSAudioInjectionEngine _createDeInterleaverIfNeeded]
-[CSAudioInjectionEngine stop]_block_invoke
-[CSAudioInjectionEngine _readAudioBufferAndFeed]
v16@?0Q8
-[CSAudioInjectionEngine injectAudio:withScaleFactor:outASBD:playbackStarted:completion:]
-[CSAudioInjectionEngine stopAudioStream]_block_invoke
-[CSAudioInjectionEngine _deinterleaveBufferIfNeeded:]
-[CSAudioInjectionEngine _compensateChannelDataIfNeeded:receivedNumChannels:]
VoiceTrigger Asset Change Monitor
com.apple.corespeech.voicetriggerassetchange
CSAttSiriRequestSourceKey
SiriFollowupforIdleAndQuiet
LockScreenNotification
-[NviAudioFileWriter initWithURL:inputFormat:outputFormat:]
-[NviAudioFileWriter addSamples:numSamples:]
AcousticSLTaskTypeVoiceTrigger
AcousticSLTaskTypeContConv
AcousticSL
-[CSAcousticSLProxy setAsset:forTask:]_block_invoke
-[CSAcousticSLProxy _setAsset:forTask:]
-[CSAcousticSLProxy _startRequestWithContext:withVtei:completion:]
-[CSAcousticSLProxy _addAudio:]
-[CSAcousticSLProxy _reset]
-[CSAcousticSLProxy _handleUnintededRequests:]
-[CSAcousticSLProxy _logResultToVTDirectory:]
-SL.json
SLAssetVersion
SLScore
SLAnalyzedSamples
SLCheckerType
SLThreshold
SLInputOriginType
SLTaskName
-[CSAcousticSLProxy _reportResultToAnalytics]
-[CSAcousticSLProxy analyzer:hasFinalResult:]_block_invoke
-[CSAcousticSLProxy analyzer:hasPartialResult:]_block_invoke
-[CSVoiceTriggerEnabledPolicyNonAOP _addVoiceTriggerEnabledConditions]_block_invoke
CSSiriClientBehaviorMonitor
-[CSSiriClientBehaviorMonitor notifyFetchedAudioStreamWithRequest:audioProviderUUID:successfully:]_block_invoke
-[CSSiriClientBehaviorMonitor notifyPreparedAudioStreamWithRequest:audioProviderUUID:successfully:]_block_invoke
-[CSSiriClientBehaviorMonitor notifyWillStartStreamWithContext:option:]_block_invoke
-[CSSiriClientBehaviorMonitor notifyDidStartStreamWithContext:successfully:option:withEventUUID:]_block_invoke
-[CSSiriClientBehaviorMonitor notifyWillStopStream:reason:]_block_invoke
-[CSSiriClientBehaviorMonitor notifyDidStopStream:withEventUUID:]_block_invoke
-[CSSiriClientBehaviorMonitor notifyReleaseAudioSession]_block_invoke
-[CSSpeechEndpointAssetMetaUpdateMonitor _startMonitoringWithQueue:]
-[CSSpeechEndpointAssetMetaUpdateMonitor _stopMonitoring]
-[CSSpeechEndpointAssetMetaUpdateMonitor _didReceiveNewSpeechEndpointAssetMetaData]
com.apple.MobileAsset.SpeechEndpointAssets.ma.cached-metadata-updated
estimatedTTSVolume
debugLogPath
-[CSVoiceTriggerAssetHandlerMac _getVoiceTriggerAssetFromAssetManager:]_block_invoke
-[CSVoiceTriggerAssetHandlerMac _getVoiceTriggerAssetFromAssetManagerWithLocale:completion:]_block_invoke
-[CSVoiceTriggerAssetHandlerMac _checkNewAssetAvailablity]_block_invoke
-[CSVoiceTriggerAssetHandlerMac _checkNewAssetAvailablityForEndpoint]_block_invoke
-[CSVoiceTriggerAssetHandlerMac CSVoiceTriggerAssetDownloadMonitor:didInstallNewAsset:]
-[CSVoiceTriggerAssetHandlerMac CSLanguageCodeUpdateMonitor:didReceiveLanguageCodeChanged:]
-[CSVoiceTriggerAssetHandlerMac CSFirstUnlockMonitor:didReceiveFirstUnlock:]
CSVoiceTriggerAOPModeEnabledPolicyIOS RecordState queue
-[CSVoiceTriggerAOPModeEnabledPolicyIOS _addConditionsForIOSBargeIn]_block_invoke
BTDetails_IsHFPRoute
-[CSVoiceTriggerAOPModeEnabledPolicyIOS _addConditionsForIOSAOP]_block_invoke
-[CSVoiceTriggerAOPModeEnabledPolicyIOS _isSpeechDetectionDevicePresent]
-[CSVoiceTriggerAOPModeEnabledPolicyIOS siriClientBehaviorMonitor:didChangedRecordState:withEventUUID:withContext:]_block_invoke
configVersion
languageCode
com.apple.corespeech.aopFirstPassTriggerWakeupLatency
latency
device
@"NSDictionary"8@?0
com.apple.corespeech.SecondPassWakeUp
unknown
modelVersion
firstPassSource
triggerAPWakeup
-[CSVoiceTriggerStatAggregator logFalseWakeUp:]
-[CSVoiceTriggerStatAggregator logTriggerLengthSampleCountStatistics:withFirstPassDeterministicTriggerLengthSampleCount:]
com.apple.exprAOPSecondPass
newTriggerLengthSampleCount
oldTriggerLengthSampleCount
sampleCountDelta
com.apple.corespeech.AudioZeroRun
duration
CSOpportuneSpeakBehaviorMonitor
-[CSOpportuneSpeakBehaviorMonitor notifyWillStartStreamWithContext:audioProviderUUID:option:]_block_invoke
-[CSOpportuneSpeakBehaviorMonitor notifyDidStartStreamWithContext:audioProviderUUID:successfully:option:]_block_invoke
-[CSOpportuneSpeakBehaviorMonitor notifyWillStopStream:]_block_invoke
-[CSOpportuneSpeakBehaviorMonitor notifyDidStopStream:]_block_invoke
Library/nvi
%@ {activationMode = %.4s, deviceIdentifier = %@, activated = %d}
-[CSSiriAudioActivationInfo initWithSpeechRecordingMode:clientConfiguration:experimentContext:]
-[CSSiriAudioActivationInfo setSpeechRequestOptions:currentActivationInfo:]
-[CSSiriAudioActivationInfo setClientConfiguration:]
-[CSSiriAudioActivationInfo startRecordingSettingsWithRecordRoute:playbackRoute:]
-[CSSiriAudioActivationInfo _alertBehaviorForRecordRoute:playbackRoute:attemptsToUsePastDataBufferFrames:]
-[CSSiriAudioActivationInfo audioAlertStyleForRecordRoute:playbackRoute:]
-[CSSiriAudioActivationInfo twoShotPromptTypeForRecordRoute:playbackRoute:]
-[CSSiriAudioActivationInfo audioSessionActivationTargetDate]
-[CSSiriAudioActivationInfo dateByAddingTimeIntervalSinceActivation:]
-[CSSiriAudioActivationInfo _audioAlertStyleForListenAfterSpeakingWithRecordRoute:playbackRoute:echoCancellation:useDeviceSpeakerForTTS:]_block_invoke
q8@?0
-[CSSiriAudioActivationInfo _audioAlertStyleForListenAfterSpeakingWithRecordRoute:playbackRoute:echoCancellation:useDeviceSpeakerForTTS:]
-[CSSiriAudioActivationInfo _audioSessionActiveDelayCoreSpeechWithType:]
@"NSNumber"16@?0@"NSNumber"8
-[CSSiriAudioActivationInfo _audioSessionActiveDelayUserPerceptionWithType:]
-[CSSiriAudioActivationInfo _audioSessionActiveDelayOverride]
-[CSSiriAudioActivationInfo _audioSessionActiveDelayServerConfiguration]
_ActivationModeForSpeechEvent
triggerEndSampleCount
triggerEndSeconds
com.apple.voicetrigger
com.apple.nvi
IsNviEnabled
InternalBuild
NviVADSignalType
NviKwdSignalType
NviDirectionalitySignalType
NviAsdAnchorSignalType
NviAsdPayloadSignalType
+[NviUtils strRepForNviSignalType:]
NviUtils.m
Unknown NviSignalTypeString: <%@>
NviAudioDataSrcType
+[NviUtils strRepForNviDataSourceType:]
NviDataSource_END_MARKER
+[NviUtils nviDataSourceTypeForStr:]
+[NviUtils _createDirAtPath:]
yyyyMMdd_HHmmss.SSS
Unexpected!! Received dir for NviConfig: %@
+[NviUtils readJsonDictionaryAt:]
+[NviUtils getValueFromDictionaryOfDictionaries:keypath:]
+[NviUtils createDirAtPath:]
SilenceFramesCountMs
SilenceProbability
SilenceDurationMs
ProcessedAudioMs
[requestHistoricalAudioDataWithHostTime = %@]
[requestHistoricalAudioDataSampleCount = %@]
[useOpportunisticZLL = %@]
[startRecordingHostTime = %llu]
[startRecordingSampleCount = %llu]
[alertBehavior = %llu %llu %llu]
[skipAlertBehavior = %@]
[requireSingleChannelLookup = %@]
[selectedChannel = %u]
[estimatedStartHostTime = %llu
[disableEndpointer = %d]
[disableLocalSpeechRecognizer = %d]
[requestMHUUID] = %@]
[siriSessionUUID] = %@]
requestHistoricalAudioDataWithHostTime
requestHistoricalAudioDataSampleCount
startRecordingHostTime
startRecordingSampleCount
useOpportunisticZLL
startAlertBehavior
stopAlertBehavior
errorAlertBehavior
skipAlertBehavior
requireSingleChannelLookup
selectedChannel
estimatedStartHostTime
disableEndpointer
disableLocalSpeechRecognizer
requestMHUUID
siriSessionUUID
+[CSUtils(AudioDevice) isHFPWithRecordRoute:]
+[CSUtils(AudioDevice) isHeadphoneDeviceWithRecordRoute:playbackRoute:]
%@ {request = %@, options = %@, player = %@}
-[CSSiriAudioPlaybackSessionImplAVAudioPlayerBased _prepareWithOptions:audioSession:error:]
Failed to initialize AVAudioPlayer.
Failed to prepare to play AVAudioPlayer.
-[CSSiriAudioPlaybackSessionImplAVAudioPlayerBased _startWithOptions:audioSession:preparationHandler:executionHandler:finalizationHandler:]
Attempted to start audio playback session when AVAudioPlayer is already playing.
Failed to play AVAudioPlayer.
-[CSSiriAudioPlaybackSessionImplAVAudioPlayerBased _stop:]
Stopped playback of AVAudioPlayer.
-[CSSiriAudioPlaybackSessionImplAVAudioPlayerBased _stop:]_block_invoke
-[CSSiriAudioPlaybackSessionImplAVAudioPlayerBased _handleBeginInterruption]
-[CSSiriAudioPlaybackSessionImplAVAudioPlayerBased _handleEndInterruption:]
-[CSSiriAudioPlaybackSessionImplAVAudioPlayerBased _didNotStartWithError:]
-[CSSiriAudioPlaybackSessionImplAVAudioPlayerBased _didStopWithError:]
-[CSSiriAudioPlaybackSessionImplAVAudioPlayerBased _finalizeWithError:]
-[CSSiriAudioPlaybackSessionImplAVAudioPlayerBased audioPlayerDidFinishPlaying:successfully:]
-[CSSiriAudioPlaybackSessionImplAVAudioPlayerBased audioPlayerDecodeErrorDidOccur:error:]
-[CSVoiceTriggerXPCServiceProxy enableVoiceTrigger:withAssertion:timestamp:]
voicetrigger assertion queue
-[CSVoiceTriggerXPCServiceProxy enableVoiceTrigger:withAssertion:timestamp:]_block_invoke
Enabled
Disabled
phrasespotter assertion queue
-[CSVoiceTriggerXPCServiceProxy setPhraseSpotterBypassing:timeout:]_block_invoke_2
bypassed
NOT bypassed
-[CSVoiceTriggerXPCServiceProxy setPhraseSpotterBypassing:timeout:]_block_invoke
raise-to-speak assertion queue
-[CSVoiceTriggerXPCServiceProxy setRaiseToSpeakBypassing:timeout:]_block_invoke_2
-[CSVoiceTriggerXPCServiceProxy setRaiseToSpeakBypassing:timeout:]_block_invoke
-[CSVoiceTriggerXPCServiceProxy notifyVoiceTriggeredSiriSessionCancelled]
-[CSVoiceTriggerXPCServiceProxy notifyServiceConnectionLost]
smartSiriVolumeOverrideMediaVolume
com.apple.ssv.clientq
-[CSSmartSiriVolumeController getVolumeForTTSType:withContext:]_block_invoke
-[CSSmartSiriVolumeController _createSSVClientConnectionIfNeeded]
-[CSSmartSiriVolumeController didSmartSiriVolumeChangeForReason:]
speakerRecognition
satThreshold
combinationWeight
implicitProfileThreshold
implicitProfileDeltaThreshold
implicitVTThreshold
pruningExplicitSATThreshold
pruningExplicitPSRThreshold
pruningSATThreshold
pruningPSRThreshold
numPruningRetentionUtt
maxEnrollmentUtterances
pruningCookie
configFileRecognizer
configFileNDAPI
voiceTriggerSecondPassAOP
implicit_training_enabled
multiUserHighScoreThreshold
multiUserLowScoreThreshold
multiUserConfidentScoreThreshold
multiUserDeltaScoreThreshold
recognizer.json
config.txt
meta_version.json
enrollment_version.json
CSP2P_CommandType_Key
CSP2P_CommandDict_Key
corespeech
com.apple.siridebug.request.generic
com.apple.siridebug.command.remote.heysiri
com.apple.siridebug.command.parallel.recording
com.apple.siridebug.command.transfer.voiceprofile
com.apple.siridebug.command.query.voiceprofile
com.apple.siridebug.command.reverse.transfer.voiceprofile
com.apple.siridebug.command.fetch.voiceprofile
com.apple.siridebug.command.voiceprofile.update.trigger
com.apple.siridebug.command.fetch.parallelrecording
com.apple.siridebug.command.transfer.parallelrecording
com.apple.siridebug.command.fetch.voicegradingdata
com.apple.siridebug.command.transfer.voicegradingdata
com.apple.siridebug.command.delete.voiceprofile
CSP2P_RemoteHeySiriEnable_Key
CSP2P_RemoteHeySiriStatus_Key
CSP2P_RemoteRecordingStart_Key
CSP2P_RemoteRecordingStatus_Key
CSP2P_VoiceProfileData_Key
CSP2P_VoiceProfileFileName_Key
CSP2P_VoiceProfileSpeakerName_Key
CSP2P_VoiceProfileLocale_Key
CSP2P_VoiceProfileDataType_Key
CSP2P_VoiceProfileSegment_Key
CSP2P_VoiceProfileTotalSegments_Key
CSP2P_VoiceProfileStatus_Key
CSP2P_VoiceProfileProfileId_Key
CSP2P_VoiceProfileHomeUserId_Key
CSP2P_VoiceProfileRelativeFilePath_Key
CSP2P_VoiceProfileSiriProfileId_Key
CSP2P_VoiceProfileAppDomain_Key
CSP2P_VoiceProfileOnboardTimeStamp_Key
CSP2P_VoiceProfileTransferCompleted_Key
CSP2P_VoiceProfileRecordedData_Key
CSP2P_VoiceProfileRemoteFileName_Key
CSP2P_VoiceDataToBeGraded_Key
CSP2P_VoiceFileNameToBeGraded_Key
CSP2P_GradingDataTransferStatus_Key
CSP2P_PeerIdentifier_Key
CSP2P_VoiceProfilePeerName_Key
CSP2P_IsDataCompressed_Key
CSP2P_UncompressedDataSize_Key
CSP2P_GradingBatchTransferID_Key
CSP2P_VoiceProfileiTunesUserID_Key
CSP2P_VoiceProfileiTunesPassword_Key
remote
-triggered
-almost
-rejected
-activation
ssrmeta
ssvmeta
vtei
multiuser
acousticSLmeta
com.apple.corespeech.p2psvc
-[CSP2PService processRemoteCommandWithPayload:fromPeer:withReply:]_block_invoke
CoreSpeech
-[CSP2PService sendCoreSpeechGradingDataToNearbyPeer]_block_invoke
-[CSP2PService sendVTNearMissGradingDataToCompanion]_block_invoke
-[CSP2PService sendVoiceProfileUpdatedMessageToNearbyPeerForLocale:]_block_invoke
-[CSP2PService sendAcousticGradingDataToNearbyPeer]_block_invoke
-[CSP2PService _processRemoteHeySiriCommandWithRequest:fromSenderID:withReply:]
-[CSP2PService _compressFilesInDirectory:matchingPredicate:compressedFileAvailable:]
json
-[CSP2PService _sendVoiceTriggerGradingDataToPeerId:]_block_invoke
v52@?0@"NSString"8@"NSData"16Q24Q32B40@"NSError"44
.wav
.json
-[CSP2PService _sendCoreSpeechGradingDataToPeerId:]_block_invoke_2
-[CSP2PService _sendCoreSpeechGradingDataToPeerId:]_block_invoke
-[CSP2PService _sendGradingData:withFileName:toPeerId:withCompressedFlag:withUncompressedDataSize:withBatchId:withRetainFileFlag:]
fileData
fileName
peerId
-[CSP2PService _sendGradingData:withFileName:toPeerId:withCompressedFlag:withUncompressedDataSize:withBatchId:withRetainFileFlag:]_block_invoke
-[CSP2PService _receiveParallelRecordingFromPeerId:recordingInfo:withReply:]
%@_%@
-[CSP2PService _receiveVoiceGradingDataFromPeerId:requestInfo:withReply:]
%@.%@.%@
suppressnotification
%@.%@
-[CSP2PService _receiveVoiceProfileFromPeerId:voiceProfileInfo:withReply:]
CoreSpeechCache
audio
tdti
com.apple.siri.corespeech.voiceprofilelist.change
-[CSP2PService _processVoiceProfileDeleteCommandWithRequest:fromSenderID:withReply:]_block_invoke
CSP2PService.m
-[CSP2PService _processGradingDataFetchCommandWithRequest:fromSenderID:withReply:]
-[CSP2PService _processVoiceProfileListQueryCommandFromPeerId:requestInfo:withReply:]
yyyyMMddHHmmss
voiceprofiles
-[CSP2PService _getHomeUserIdForSharedSiriId:withCompletion:]
-[CSP2PService _getHomeUserIdForSharedSiriId:withCompletion:]_block_invoke
homeUserId query for siriProfileId %@ timedout !
-[CSP2PService _processFetchVoiceProfileCommandFromPeerId:requestInfo:withReply:]
Caches/VoiceTrigger/SATUpdate
_%d_%d_%@
-[CSP2PService _sendVoiceProfile:toPeerId:]
td/audio
tdti/audio
ti/audio
-[CSP2PService _sendVoiceProfile:toPeerId:]_block_invoke
-[CSP2PService _processReverseTransferVoiceProfileCommandFromPeerId:requestInfo:withReply:]
-[CSP2PService _processVoiceProfileUpdateTriggerFromPeerId:requestInfo:withReply:]
-[CSP2PService _sendVoiceProfileUpdateTriggerToPeerId:forLocale:]_block_invoke
-synced.wav
-[CSP2PService _sendAcousticGradingDataToPeerId:]_block_invoke_2
-[CSP2PService _sendAcousticGradingDataToPeerId:]_block_invoke
Logs/CoreSpeech/spid/grading
-[CSP2PService _createDirectoryIfDoesNotExist:]
RemoteGradingData
VoiceProfileStore
trained_users.json
Caches
-[CSP2PService _getContentsOfDirectory:]
com.apple.corespeech
-[CSVoiceTriggerAwareZeroFilter resetWithSampleRate:containsVoiceTrigger:voiceTriggerInfo:]
-[CSPostBuildInstallService registerPostBuildInstallService]
-[CSPostBuildInstallService registerPostBuildInstallService]_block_invoke
com.apple.cs.postinstall
CSContinuousAudioFingerprintProvider
-[CSContinuousAudioFingerprintProvider startWithUUID:withMaximumBufferSize:]
-[CSContinuousAudioFingerprintProvider startWithUUID:withMaximumBufferSize:]_block_invoke
-[CSContinuousAudioFingerprintProvider stopWithUUID:]
-[CSContinuousAudioFingerprintProvider stopWithUUID:]_block_invoke
-[CSContinuousAudioFingerprintProvider _startListenPollingWithInterval:completion:]
-[CSContinuousAudioFingerprintProvider _startListenPollingWithInterval:completion:]_block_invoke
-[CSContinuousAudioFingerprintProvider _startListenWithCompletion:]_block_invoke_2
-[CSContinuousAudioFingerprintProvider _startListenWithCompletion:]_block_invoke
-[CSContinuousAudioFingerprintProvider _startListenWithCompletion:]
-[CSContinuousAudioFingerprintProvider _startListenPolling]
-[CSContinuousAudioFingerprintProvider _stopListening]
-[CSContinuousAudioFingerprintProvider _stopListening]_block_invoke
-[CSContinuousAudioFingerprintProvider CSSiriEnabledMonitor:didReceiveEnabled:]
-[CSContinuousAudioFingerprintProvider audioStreamProvider:didStopStreamUnexpectly:]
-[CSContinuousAudioFingerprintProvider CSAudioServerCrashMonitorDidReceiveServerRestart:]
best_phrase
early_warning
is_rescoring
samples_at_fire
start_sample_count
-[CSKeywordAnalyzerNDAPI initWithConfigPath:resourcePath:]
-[CSKeywordAnalyzerNDAPI _setStartAnalyzeTime:]
threshold_normal
-[CSKeywordAnalyzerNDAPI getThreshold]
threshold_logging
-[CSKeywordAnalyzerNDAPI getLoggingThreshold]
threshold_reject_logging
-[CSKeywordAnalyzerNDAPI getRejectLoggingThreshold]
SignalTs, ProcessedAudioMs, StartSample, EndSample, Azimuth, EmaAzimuth, Confidence, SpatialSpreadSpectrum
%llu,%f,%lu,%lu,%f,%f,%f,
{%@, {start=%lu, end=%lu, conf=%f, az=%f, estAz=%fdist=%@}
,%d, 
%f, 
isMediaPlaying
noiseLevelDB
musicLevelDB
musicPlaybackVolumeDB
alarmVolume
finalTTSVolume
isAlarmPlaying
isTimerPlaying
isLKFSProcessPaused
removeVoiceTriggerSamples
-[CSSmartSiriVolume initWithSamplingRate:asset:]
-[CSSmartSiriVolume startSmartSiriVolume]_block_invoke
RUNNING
PAUSED
-[CSSmartSiriVolume _startListenPolling]
-[CSSmartSiriVolume _startListenPollingWithInterval:completion:]
-[CSSmartSiriVolume _startListenPollingWithInterval:completion:]_block_invoke
-[CSSmartSiriVolume _startListenWithCompletion:]_block_invoke_2
-[CSSmartSiriVolume _startListenWithCompletion:]_block_invoke
-[CSSmartSiriVolume _startListenWithCompletion:]
-[CSSmartSiriVolume _stopListening]
-[CSSmartSiriVolume _stopListening]_block_invoke
-[CSSmartSiriVolume initializeMediaPlayingState]_block_invoke
playing
NOT playing
-[CSSmartSiriVolume initializeMediaPlayingState]
-[CSSmartSiriVolume initializeAlarmState]_block_invoke
firing
NOT firing
-[CSSmartSiriVolume initializeTimerState]_block_invoke
-[CSSmartSiriVolume _setAsset:]
-[CSSmartSiriVolume _processAudioChunk:soundType:]
-[CSSmartSiriVolume estimateSoundLevelbySoundType:]_block_invoke
-[CSSmartSiriVolume _pauseSSVProcessing]_block_invoke
-[CSSmartSiriVolume _resumeSSVProcessing]_block_invoke
-[CSSmartSiriVolume audioStreamProvider:audioBufferAvailable:]_block_invoke
-[CSSmartSiriVolume audioStreamProvider:didStopStreamUnexpectly:]
-[CSSmartSiriVolume didDetectKeywordWithResult:]
-[CSSmartSiriVolume didDetectKeywordWithResult:]_block_invoke
-[CSSmartSiriVolume estimatedTTSVolumeForNoiseLevelAndLKFS:LKFS:]_block_invoke
-[CSSmartSiriVolume _combineResultsWithOptimalFromNoise:andOptimalFromLkfs:withUserOffset:]
-[CSSmartSiriVolume CSMediaPlayingMonitor:didReceiveMediaPlayingChanged:]_block_invoke
-[CSSmartSiriVolume didReceiveAlarmChanged:]_block_invoke
-[CSSmartSiriVolume didReceiveTimerChanged:]_block_invoke
-[CSSmartSiriVolume CSSiriEnabledMonitor:didReceiveEnabled:]
-[CSSmartSiriVolume CSAudioServerCrashMonitorDidReceiveServerRestart:]
-[CSSmartSiriVolume siriClientBehaviorMonitor:didStartStreamWithContext:successfully:option:withEventUUID:]_block_invoke
-[CSSmartSiriVolume _setStartAnalyzeTime:]
-[CSSmartSiriVolume getVolumeForTTSType:withOverrideMediaVolume:WithRequestTime:]
CSSACInfoMonitor queue
-[CSSACInfoMonitor _startMonitoringWithQueue:]
-[CSSACInfoMonitor _stopMonitoring]
-[CSSACInfoMonitor isDeviceRoleStereo]
RTModelData
RTModelHash
RTModelLocale
RTModelDigest
RTModelSignature
RTModelCertificate
RT Model for 
 from asset 
CorealisRTModel
CorealisRTModelVersion
dataSize(%d), hash(%@), locale(%@), digest(%@), cert(%@), signature(%@)
com.apple.assistant.vibration-manager
com.apple.springboard.ring-vibrate.changed
com.apple.springboard.silent-vibrate.changed
-[CSSiriVibrationManager _fetchRingVibrationValue]
ring-vibrate
-[CSSiriVibrationManager _fetchSilentVibrationValue]
silent-vibrate
-[CSSiriVibrationManager handleRingVibrationValueChange]
-[CSSiriVibrationManager handleSilentVibrationValueChange]
com.apple.springboard
mobile
_fetchVibrationState
::: Initializing NVI logging...
Framework
InitNviLogging_block_invoke
CSAudioRouteChangeMonitorImpl queue
-[CSAudioRouteChangeMonitorImpl preferredExternalRouteDidChange:]_block_invoke
-[CSAudioRouteChangeMonitorImpl carPlayAuxStreamSupportDidChange:]_block_invoke
-[CSAudioRouteChangeMonitorImpl carPlayIsConnectedDidChange:]
-[CSAudioRouteChangeMonitorImpl _startMonitoringWithQueue:]
-[CSAudioRouteChangeMonitorImpl _stopMonitoring]
-[CSAudioRouteChangeMonitorImpl _notifyHearstConnectionState:]
-[CSAudioRouteChangeMonitorImpl _notifyJarvisConnectionState:]
-[CSAudioRouteChangeMonitorImpl _systemControllerDied:]
-[CSAutomaticVolumeEnabledMonitor observeValueForKeyPath:ofObject:change:context:]_block_invoke
-[CSSiriRecordingInfo initWithDictation:fingerprintOnly:secureOfflineOnly:audioAlertStyle:recordSettings:endpointerModelVersion:recordRoute:recordDeviceInfo:playbackRoute:audioDeviceID:audioSessionID:voiceTriggerEventInfo:activationAlertStartTimestamp:startRecordingTimestamp:firstBufferTimestamp:firstBufferHostTime:estimatedSpeechEndHostTime:deviceIdentifier:includeBTInfo:speechEvent:]
forceSiriPCMAudio
-[CSSpeakerRecognitionAssetMetaUpdateMonitor _startMonitoringWithQueue:]
-[CSSpeakerRecognitionAssetMetaUpdateMonitor _stopMonitoring]
-[CSSpeakerRecognitionAssetMetaUpdateMonitor _didReceiveSpeakerRecognitionAssetMetaData]
com.apple.MobileAsset.SpeakerRecognitionAssets.ma.cached-metadata-updated
com.apple.coreaudio.BorealisToggled
-[CSVoiceTriggerEnabledMonitor _startMonitoringWithQueue:]_block_invoke
-[CSVoiceTriggerEnabledMonitor _startMonitoringWithQueue:]
-[CSVoiceTriggerEnabledMonitor _stopMonitoring]
-[CSVoiceTriggerEnabledMonitor _checkVoiceTriggerEnabled]
Warmup
SearchOrMessaging
ExtraDelayMs
EndpointerDecisionLagMs
ClientLagThresholdMsKey
ClampedSFLatencyMsForClientLag
UseDefaultServerFeaturesOnClientLag
extra-delay-frequency
endpoint-threshold
com.apple.cs.%@.stateserialqueue
com.apple.cs.%@.sepfQueue
com.apple.cs.%@.hybridClassifierfQueue
-[CSHybridEndpointer endpointerModelVersion]_block_invoke
-[CSHybridEndpointer updateEndpointerThreshold:]
-[CSHybridEndpointer updateEndpointerDelayedTrigger:]
-[CSHybridEndpointer setEndpointerOperationMode:]_block_invoke
-[CSHybridEndpointer fetchCurrentEndpointerOperationMode]_block_invoke
-[CSHybridEndpointer processTaskString:]_block_invoke
-[CSHybridEndpointer processServerEndpointFeatures:]
-[CSHybridEndpointer shouldAcceptEagerResultForDuration:resultsCompletionHandler:]_block_invoke_2
-[CSHybridEndpointer shouldAcceptEagerResultForDuration:resultsCompletionHandler:]_block_invoke
-[CSHybridEndpointer processFirstAudioPacketTimestamp:firstAudioSampleSensorTimestamp:]_block_invoke
-[CSHybridEndpointer processOSDFeatures:withFrameDurationMs:]
-[CSHybridEndpointer processOSDFeatures:withFrameDurationMs:]_block_invoke_2
-[CSHybridEndpointer processOSDFeatures:withFrameDurationMs:]_block_invoke
locale
endpointerModelVersion
wordCount
eosLikelihood
trailingSilenceDuration
serverFeaturesLatency
clientSilenceProbability
clientSilenceFramesCountMs
endpointResult
-[CSHybridEndpointer logFeaturesWithEvent:locale:]_block_invoke
extraSamplesAtStart
-[CSHybridEndpointer handleVoiceTriggerWithActivationInfo:]_block_invoke
-[CSHybridEndpointer recordingStoppedForReason:]
-[CSHybridEndpointer stopEndpointer]
-[CSHybridEndpointer resetForNewRequestWithSampleRate:recordContext:]
-[CSHybridEndpointer resetForNewRequestWithSampleRate:recordContext:]_block_invoke
-[CSHybridEndpointer _readParametersFromHEPAsset:]_block_invoke
CSHybirdEndpointer.m
CSHybridEndpointer reset called
-[CSHybridEndpointer endpointerAssetManagerDidUpdateAsset:]_block_invoke
cs_hep_marsh.json
cs_hep.json
-[CSHybridEndpointer _getCSHybridEndpointerConfigForAsset:]
-[CSSiriEnabledMonitor _startMonitoringWithQueue:]
-[CSSiriEnabledMonitor _stopMonitoring]
_AssistantPrefsChangedNotification
com.apple.nvi.csaudiosrc
-[NviCSAudioDataSource startWithNviContext:didStartHandler:]_block_invoke_2
-[NviCSAudioDataSource stopWithDidStopHandler:]_block_invoke_2
-[NviCSAudioDataSource _createAudioStreamWithCurrentNviContext]
-[NviCSAudioDataSource audioStreamProvider:avBufferAvailable:]
-[NviCSAudioDataSource audioStreamProvider:didStopStreamUnexpectly:]
-[NviCSAudioDataSource audioStreamProvider:audioChunkForTVAvailable:]
SPG.nnet
version
CSEndpointerAssetManager queue
-[CSEndpointerAssetManager init]
-[CSEndpointerAssetManager checkFirstUnlocked]
-[CSEndpointerAssetManager CSLanguageCodeUpdateMonitor:didReceiveLanguageCodeChanged:]_block_invoke
-[CSEndpointerAssetManager CSAssetManagerDidDownloadNewAsset:]_block_invoke
-[CSEndpointerAssetManager CSFirstUnlockMonitor:didReceiveFirstUnlock:]_block_invoke
-[CSEndpointerAssetManager _getCurrentHEPAsset]
-[CSEndpointerAssetManager _updateOEPAssetsWithLanguage:]
-[CSEndpointerAssetManager _notifyAssetsUpdate]
ModelInfo=
-[CSEndpointerAssetManager _getOEPVersionFromPath:]
-[CSShadowMicScoreCreator calculateShadowMicScore]
-[CSEndpointDelayReporter initWithRequestMHUUID:turnIdentifier:]
-[CSEndpointDelayReporter reset]
leadingSilence
trailingSilence
endTime
-[CSEndpointDelayReporter setSpeechRecognizedContext:withEndpointerMetrics:]
CSActivationEventNotifier
-[CSActivationEventNotifier notifyActivationEventSynchronously:completion:]
-[CSActivationEventNotifier notifyActivationEvent:completion:]_block_invoke
-[CSActivationEventNotifier notifyActivationEvent:deviceId:activationInfo:completion:]_block_invoke
-[CSActivationEventNotifier _createXPCClientConnection]
-[CSLanguageCodeUpdateMonitorImpl _startMonitoringWithQueue:]
-[CSLanguageCodeUpdateMonitorImpl _stopMonitoring]
-[CSLanguageCodeUpdateMonitorImpl _didReceiveLanguageCodeUpdate]
+[CSUtils(AudioFile) readAudioChunksFrom:block:]
-[CSSoftwareUpdateCheckingMonitor _startMonitoringWithQueue:]
-[CSSoftwareUpdateCheckingMonitor _stopMonitoring]
-[CSSoftwareUpdateCheckingMonitor _checkSoftwareUpdateCheckingState]
com.apple.duetscheduler.restartCheckNotification
-[CSAssetManagerEnablePolicy _addAssetManagerEnabledConditions]_block_invoke
Liminal
progChecker.json
progressiveCheckerConfigFile
contionusConversationConfigFile
checkerConfig
validInputOrigins
thresholds
shadowMode
Unspecified
VoiceTrigger
ButtonPress
B32@?0@8@16^B24
v24@?0@8^B16
-[CSVoiceTriggerAssetMetaUpdateMonitor _startMonitoringWithQueue:]
-[CSVoiceTriggerAssetMetaUpdateMonitor _stopMonitoring]
-[CSVoiceTriggerAssetMetaUpdateMonitor _didReceiveNewVoiceTriggerAssetMetaData]
com.apple.MobileAsset.VoiceTriggerAssets.ma.cached-metadata-updated
com.apple.MobileAsset.VoiceTriggerAssetsIPad.ma.cached-metadata-updated
com.apple.MobileAsset.VoiceTriggerAssetsWatch.ma.cached-metadata-updated
com.apple.MobileAsset.VoiceTriggerAssetsMarsh.ma.cached-metadata-updated
com.apple.MobileAsset.VoiceTriggerAssetsMac.ma.cached-metadata-updated
com.apple.MobileAsset.VoiceTriggerAssetsTV.ma.cached-metadata-updated
-[CSAudioRecordDeviceIndicator updateWithLatestRecordContext:]
com.apple.assistant.queue-monitor
-[CSSiriQueueMonitor beginMonitoring]
-[CSSiriQueueMonitor endMonitoring]
-[CSSiriQueueMonitor _addQueue:heartBeatInterval:timeoutInterval:timeoutHandler:]
-[CSSiriQueueMonitor _beginMonitoring]
-[CSSiriQueueMonitor _endMonitoring]
-[_CSSiriQueueObserver startWithQueue:]
com.apple.assistant.queue-observer.%s
-[_CSSiriQueueObserver stop]
-[_CSSiriQueueObserver timeoutDetected]
-[CSRemoteVADCircularBuffer copySamplesFrom:to:]
copySamples
-[CSAdBlockerAssetMetaUpdateMonitor _startMonitoringWithQueue:]
-[CSAdBlockerAssetMetaUpdateMonitor _stopMonitoring]
-[CSAdBlockerAssetMetaUpdateMonitor _didReceiveNewAdBlockerAssetMetaData]
com.apple.MobileAsset.AdBlockerAssets.ma.cached-metadata-updated
-[CSAudioStream initWithAudioStreamProvider:streamName:streamRequest:]
-[CSAudioStream dealloc]
-[CSAudioStream startAudioStreamWithOption:completion:]
-[CSAudioStream isStreaming]
-[CSAudioStream audioStreamProvider:didStopStreamUnexpectly:]
-[CSAudioStream audioStreamProvider:didHardwareConfigurationChange:]
BluetoothA2DPOutput
BluetoothHFP
BluetoothLE
MicrophoneBuiltIn
Speaker
Headphones
MicrophoneWired
HDMIOutput
LineIn
USBAudio
ADAudioSessionPortOther
-[CSSiriAudioSession currentInputRoute]_block_invoke
v24@?0^v8Q16
-[CSSiriAudioSession currentOutputRoute]_block_invoke_3
_AudioObjectGetScalarArray
v20@?0I8r^{AudioObjectPropertyAddress=III}12
_AudioDeviceRegisterForChangedNotification
v16@?0^v8
_AudioObjectGetCFTypeRef
_AudioObjectGetIntValue
{wordCount: %ld, trailingSilDuration: %ld, eosLikelihood: %f, pauseCounts: (%@), silencePosterior: %f, taskName: %@, processedAudioDurationInMilliseconds: %ld}
WordCount
TrailingSilDuration
EOSLikelihood
PauseCounts
SilencePosterior
ProcessedAudioDurationInMilliseconds
CSActivationEventNotificationHandler Queue
-[CSActivationEventNotificationHandler setDelegate:forType:]_block_invoke
-[CSActivationEventNotificationHandler notifyActivationEvent:completion:]_block_invoke
-[CSActivationEventNotificationHandler _notifyActivationEvent:completion:]
-[CSActivationEventNotificationHandler _notifyActivationEvent:completion:]_block_invoke
-[CSActivationEventNotificationHandler _startMonitoring]
-[CSActivationEventNotificationHandler _stopMonitoring]
-[CoreSpeechXPC installedVoiceTriggerAssetForLanguageCode:completion:]
-[CoreSpeechXPC fetchRemoteVoiceTriggerAssetForLanguageCode:completion:]
-[CoreSpeechXPC _handleFakeHearstModelRequest:majorVersion:minorVersion:downloadedModels:preinstalledModels:completion:]
fakeModel.json
fakeModel
-[CoreSpeechXPC voiceTriggerRTModelForVersion:minorVersion:accessoryRTModelType:locale:endpointId:downloadedModels:preinstalledModels:completion:]
v40@?0@"CSVoiceTriggerRTModel"8@"CSVoiceTriggerRTModel"16@"NSString"24@"NSError"32
-[CoreSpeechXPC voiceTriggerRTModelForVersion:minorVersion:accessoryRTModelType:locale:endpointId:downloadedModels:preinstalledModels:completion:]_block_invoke
-[CoreSpeechXPC voiceTriggerJarvisLanguageList:jarvisSelectedLanguage:completion:]_block_invoke
-[CoreSpeechXPC voiceTriggerJarvisLanguageList:jarvisSelectedLanguage:completion:]
de-AT
de-DE
de-CH
en-AU
en-CA
en-GB
en-SG
en-IE
en-IN
en-ZA
en-NZ
it-IT
it-CH
ja-JP
zh-CN
zh-TW
nb-NO
nl-BE
nl-NL
sv-SE
tr-TR
fi-FI
he-IL
es-ES
es-US
es-CL
es-MX
fr-FR
fr-BE
fr-CA
fr-CH
ko-KR
zh-HK
yue-CN
da-DK
ms-MY
pt-BR
ru-RU
th-TH
ar-AE
ar-SA
default
Hearst
-[CSSiriRestrictionOnLockScreenMonitor _startMonitoringWithQueue:]
-[CSSiriRestrictionOnLockScreenMonitor _stopMonitoring]
-[CSSiriRestrictionOnLockScreenMonitor _checkSiriRestrictedOnLockScreen]
-[CSRawAudioInjectionProvider init]
CSRawAudioInjectionProvider
-[CSRawAudioInjectionProvider dealloc]
-[CSRawAudioInjectionProvider setContext:completion:]
-[CSRawAudioInjectionProvider setCurrentContext:streamHandleId:error:]
-[CSRawAudioInjectionProvider prepareAudioStreamRecord:recordDeviceIndicator:error:]
-[CSRawAudioInjectionProvider startAudioStreamWithOption:recordDeviceIndicator:error:]
/var/mobile/darwin_test.wav
-[CSRawAudioInjectionProvider stopAudioStreamWithRecordDeviceIndicator:error:]
-[CSRawAudioInjectionProvider isRecordingWithRecordDeviceIndicator:]
RawAudioInjection
-[CSRawAudioInjectionProvider prewarmAudioSessionWithStreamHandleId:error:]
-[CSRawAudioInjectionProvider activateAudioSessionWithReason:streamHandleId:error:]
-[CSSpringboardStartMonitor _startMonitoringWithQueue:]
-[CSSpringboardStartMonitor _stopMonitoring]
-[CSSpringboardStartMonitor _checkSpringBoardStarted]
com.apple.springboard.finishedstartup
CSAudioProvider
CSAudioProvider logging
-[CSAudioProvider dealloc]
-[CSAudioProvider setStreamState:]
-[CSAudioProvider setAudioRecorder:]_block_invoke
-[CSAudioProvider setCurrentContext:error:]
-[CSAudioProvider setCurrentContext:error:]_block_invoke
-[CSAudioProvider _audioStreamWithRequest:streamName:error:]
-[CSAudioProvider _prepareAudioStreamSync:request:error:]
-[CSAudioProvider _createCircularBufferIfNeeded]
-[CSAudioProvider _tearDownCircularBufferIfNeeded]
-[CSAudioProvider startAudioStream:option:completion:]
-[CSAudioProvider startAudioStream:option:completion:]_block_invoke
-[CSAudioProvider prepareAudioStreamSync:request:error:]
-[CSAudioProvider prepareAudioStream:request:completion:]
-[CSAudioProvider _startAudioStream:option:completion:]
-[CSAudioProvider _handleDidStartAudioStreamWithResult:error:]
-[CSAudioProvider _handleDidStopAudioStreamWithReason:]
-[CSAudioProvider _stopAudioStream:option:completion:]
-[CSAudioProvider _stopAudioStream:option:completion:]_block_invoke
-[CSAudioProvider _stopAudioStream:option:completion:]_block_invoke_2
CSAudioProvider.m
-[CSAudioProvider _saveRecordingBufferFrom:to:toURL:]_block_invoke
-[CSAudioProvider holdAudioStreamWithDescription:timeout:]
-[CSAudioProvider holdAudioStreamWithDescription:timeout:]_block_invoke_2
-[CSAudioProvider holdAudioStreamWithDescription:timeout:]_block_invoke
-[CSAudioProvider cancelAudioStreamHold:]
-[CSAudioProvider cancelAudioStreamHold:]_block_invoke
-[CSAudioProvider prewarmAudioSessionWithError:]
-[CSAudioProvider activateAudioSessionWithReason:dynamicAttribute:bundleID:error:]
-[CSAudioProvider _activateAudioSessionWithReason:error:]
-[CSAudioProvider deactivateAudioSession:error:]
-[CSAudioProvider _deactivateAudioSession:error:]
-[CSAudioProvider setAlertSoundFromURL:forType:]
-[CSAudioProvider playAlertSoundForType:]
-[CSAudioProvider playRecordStartingAlertAndResetEndpointer]
-[CSAudioProvider alertStartTime]
-[CSAudioProvider triggerInfoForContext:completion:]_block_invoke
-[CSAudioProvider _shouldStopRecording]
-[CSAudioProvider audioRecorderStreamHandleIdInvalidated:]
-[CSAudioProvider audioRecorderWillBeDestroyed:]_block_invoke
-[CSAudioProvider _fetchHistoricalAudioAndForwardToStream:remoteVAD:]
-[CSAudioProvider _scheduleAlertFinishTimeout:]
-[CSAudioProvider _scheduleAlertFinishTimeout:]_block_invoke
-[CSAudioProvider _didReceiveFinishStartAlertPlaybackAt:]
-[CSAudioProvider audioRecorderBuiltInAudioStreamInvalidated:error:]_block_invoke
-[CSAudioProvider audioRecorderDisconnected:]
-[CSAudioProvider CSAudioServerCrashMonitorDidReceiveServerCrash:]
-[CSAudioProvider CSAudioServerCrashMonitorDidReceiveServerRestart:]
-[CSAudioProvider _handleAudioSystemFailure]
StreamInit
StreamPrepared
StreamStarting
StreamSteaming
StreamStopping
StreamStoppingWithScheduledStart
unknown(%tu)
com.apple.corespeech.recording
Recording transaction
-[CSAudioProvider _releaseRecordingTransactionIfNeeded]
%@-%@
-[CSAudioProvider _onAudioPacketWatchdogFire]
-[CSAudioProvider _scheduleDidStartRecordingDelegateWatchDog]
-[CSAudioProvider _schduleDidStartRecordingDelegateWatchDogWithToken:]
-[CSAudioProvider _clearDidStartRecordingDelegateWatchDog]
-[CSAudioProvider _scheduleDidStopRecordingDelegateWatchDog]
-[CSAudioProvider _scheduleDidStopRecordingDelegateWatchDog:]
-[CSAudioProvider _clearDidStopRecordingDelegateWatchDog]
-[CSListeningEnabledPolicyWatch _addListeningEnabledConditions]_block_invoke
-[NSArray(XPCObject) _cs_initWithXPCObject:]
-[NSArray(XPCObject) _cs_initWithXPCObject:]_block_invoke
B24@?0Q8@"NSObject<OS_xpc_object>"16
-[NSArray(XPCObject) _cs_xpcObject]_block_invoke
v32@?0@8Q16^B24
-[CSAlwaysOnProcessorStateMonitor _didReceiveAOPListeningStateChange:]
+[CSAdBlockerAssetDecoderFactory adBlockerAssetDecoderWithVersion:]
com.apple.siri.myriad.in.ear
+[CSMyriadNotifier notifyInEarMyriadTrigger]
+[CSRemoteDeviceProtocolInfo localDeviceProtocolInfo]
protocolVersion=%lu, deviceCategory=%lu, buildVersion=%@, deviceProductVersion=%@, deviceProductType=%@
protocolVersion
deviceCategory
buildVersion
deviceProductVersion
deviceProductType
-[CSHybridEndpointAnalyzer init]
com.apple.cs.%@.apQueue
com.apple.cs.%@.osdQueue
-[CSHybridEndpointAnalyzer _loadAndSetupEndpointerAssetIfNecessary]
-[CSHybridEndpointAnalyzer processAudioSamplesAsynchronously:]
-[CSHybridEndpointAnalyzer processAudioSamplesAsynchronously:]_block_invoke
-[CSHybridEndpointAnalyzer updateEndpointerThreshold:]
-[CSHybridEndpointAnalyzer updateEndpointerDelayedTrigger:]
-[CSHybridEndpointAnalyzer processServerEndpointFeatures:]
-[CSHybridEndpointAnalyzer shouldAcceptEagerResultForDuration:resultsCompletionHandler:]_block_invoke_2
-[CSHybridEndpointAnalyzer shouldAcceptEagerResultForDuration:resultsCompletionHandler:]_block_invoke
-[CSHybridEndpointAnalyzer osdAnalyzer:didUpdateOSDFeatures:]
-[CSHybridEndpointAnalyzer osdAnalyzer:didUpdateOSDFeatures:]_block_invoke_2
-[CSHybridEndpointAnalyzer osdAnalyzer:didUpdateOSDFeatures:]_block_invoke
-[CSHybridEndpointAnalyzer logFeaturesWithEvent:locale:]_block_invoke
-[CSHybridEndpointAnalyzer handleVoiceTriggerWithActivationInfo:]_block_invoke
-[CSHybridEndpointAnalyzer recordingStoppedForReason:]
-[CSHybridEndpointAnalyzer stopEndpointer]
-[CSHybridEndpointAnalyzer resetForNewRequestWithSampleRate:recordContext:]
-[CSHybridEndpointAnalyzer resetForNewRequestWithSampleRate:recordContext:]_block_invoke
-[CSHybridEndpointAnalyzer _readParametersFromHEPAsset:]_block_invoke
CSHybridEndpointAnalyzer.m
CSHybridEndpointAnalyzer reset called
-[CSHybridEndpointAnalyzer CSLanguageCodeUpdateMonitor:didReceiveLanguageCodeChanged:]
-[CSHybridEndpointAnalyzer CSAssetManagerDidDownloadNewAsset:]
-[CSHybridEndpointAnalyzer CSFirstUnlockMonitor:didReceiveFirstUnlock:]
-[CSHybridEndpointAnalyzer _updateAssetWithLanguage:]_block_invoke
-[CSHybridEndpointAnalyzer _getCSHybridEndpointerConfigForAsset:]
com.apple.da
ExperimentGroup
walkabout
carry
CSAudioSessionInfoProvider
-[CSAudioSessionInfoProvider audioSessionIdForDeviceId:]
-[CSAudioSessionInfoProvider CSAudioServerCrashMonitorDidReceiveServerCrash:]_block_invoke
-[CSAudioSessionInfoProvider CSAudioServerCrashMonitorDidReceiveServerRestart:]_block_invoke
-[CSAudioSessionInfoProvider _registerInterruptionNotification]
-[CSAudioSessionInfoProvider _registerAudioRouteChangeNotification]
-[CSAudioSessionInfoProvider _handleInterruption:]_block_invoke
-[CSAudioSessionInfoProvider _audioRouteChanged:]_block_invoke
RouteChangeNotificationInfo
-[CSAudioSessionInfoProvider _deregisterAudioSessionNotifications]
-[CSEndpointerProxy resetForNewRequestWithSampleRate:recordContext:recordOption:voiceTriggerInfo:]
-[CSEndpointerProxy resetForVoiceTriggerTwoShotWithSampleRate:]
-[CSEndpointerProxy preheat]
-[CSEndpointerProxy endpointer:didDetectStartpointAtTime:]
-[CSEndpointerProxy endpointer:didDetectHardEndpointAtTime:withMetrics:]
-[CSEndpointerProxy endpointer:detectedTwoShotAtTime:]
-[CSEndpointerProxy endpointerModelVersion]
-[CSEndpointerProxy logHybridEndpointFeaturesWithEvent:locale:]
CSSiriMobileBluetoothDeviceDataSource
Queue %s did not respond to watchdog and is likely blocked.
-[CSSiriMobileBluetoothDeviceDataSource init]_block_invoke
-[CSSiriMobileBluetoothDeviceDataSource _cleanUpDeviceProxies]
-[CSSiriMobileBluetoothDeviceDataSource _detachFromSession]
-[CSSiriMobileBluetoothDeviceDataSource _attachToSession]
-[CSSiriMobileBluetoothDeviceDataSource _sessionAttached:result:]
-[CSSiriMobileBluetoothDeviceDataSource _sessionDetached:]
-[CSSiriMobileBluetoothDeviceDataSource _sessionTerminated:]
-[CSSiriMobileBluetoothDeviceDataSource _setUpLocalDevice]
-[CSSiriMobileBluetoothDeviceDataSource localDevice:event:result:]
-[CSSiriMobileBluetoothDeviceDataSource _setUpAccessoryManager]
-[CSSiriMobileBluetoothDeviceDataSource accessoryManager:event:device:state:]
v16@?0@"AFBluetoothDeviceInfo"8
-[CSSiriMobileBluetoothDeviceDataSource getBTDeviceWithAddress:completion:]_block_invoke
-[CSSiriMobileBluetoothDeviceDataSource getBTDeviceWithDeviceUID:completion:]_block_invoke
-[CSSiriMobileBluetoothDeviceDataSource getBTLocalDeviceWithCompletion:]_block_invoke
%@ {deviceUID = %@}
%@ {address = %@}
-[CSSiriMobileBluetoothDeviceProxy dealloc]
-[CSSiriMobileBluetoothDeviceProxy initWithAddress:dataSource:queue:]
-[CSSiriMobileBluetoothDeviceProxy initWithAddress:dataSource:queue:]_block_invoke
-[CSSiriMobileBluetoothDeviceProxy initWithDeviceUID:dataSource:queue:]
-[CSSiriMobileBluetoothDeviceProxy initWithDeviceUID:dataSource:queue:]_block_invoke
-[CSSiriMobileBluetoothDeviceProxy deviceInfo]_block_invoke
-[CSSiriMobileBluetoothDeviceProxy deviceInfo]
-[CSSiriMobileBluetoothDeviceProxy getHeadphoneInEarDetectionState:]
-[CSSiriMobileBluetoothDeviceProxy getHeadphoneListeningMode:]
-[CSSiriMobileBluetoothDeviceProxy setHeadphoneListeningMode:completion:]
v24@?0^{BTDeviceImpl=}8^{BTAccessoryManagerImpl=}16
-[CSSiriMobileBluetoothDeviceProxy _reload:]
-[CSSiriMobileBluetoothDeviceProxy _reload:]_block_invoke
-[CSSiriMobileBluetoothDeviceProxy _updateDeviceInfo:]
v16@?0@"<AFBluetoothDeviceObserver>"8
-[CSSiriMobileBluetoothDeviceProxy _fetchDeviceInfoWithCompletion:]
v16@?0@"<AFBluetoothDeviceInfoMutating>"8
-[CSSiriMobileBluetoothDeviceProxy _fetchDeviceInfoWithCompletion:]_block_invoke
-[CSSiriMobileBluetoothDeviceProxy _accessBTDeviceAndAccessoryManagerUsingBlock:]
-[CSSiriMobileBluetoothDeviceProxy _accessBTDeviceAndAccessoryManagerUsingBlock:]_block_invoke
-[CSSiriMobileBluetoothDeviceProxy _invalidate]
v24@?0@"<AFBluetoothDeviceObserver>"8^B16
ADBTResult
_CSSiriBTDeviceGetAddress
_CSSiriBTDeviceGetDeviceInfo
Serial CSCATAssetManager queue
-[CSCATAssetManager downloadForManifest:withAssetName:]_block_invoke_2
v32@?0@"NSString"8@"NSString"16@"NSError"24
-[CSCATAssetManager fetchRemoteCATAssetForResource:withNameOfFile:completion:]_block_invoke
CATXPC service invalidated
-[NSNumber(XPCObject) _cs_initWithXPCObject:]
-[NSNumber(XPCObject) _cs_xpcObject]
-[CSFirstUnlockMonitor _stopMonitoring]
kVTPreferencesPhraseSpotterEnabledDidChangeDarwinNotification
-[CSPhraseSpotterEnabledMonitor _checkPhraseSpotterEnabled]
-[CSPhraseSpotterEnabledMonitor _phraseSpotterEnabledDidChange]
corespeechd speaker xpc connection client queue
-[CSVoiceIdXPCConnection _handleClientEvent:]
-[CSVoiceIdXPCConnection _handleClientMessage:client:]
-[CSVoiceIdXPCConnection _handleClientError:client:]
com.apple.
com.apple.private.
com.apple.assistant.audio-service-workloop
Internal User Classification
kAFPreferencesDidChangeDarwinNotification
Audio Session Active Delay
Server Media Playback Volume Threshold for Audio Session Activation Delay
Server Audio Session Activation Delay Above Media Playback Volume Threshold
Server Audio Session Activation Delay
com.apple.corespeech.mockremoteplugin.xpc
CSFallbackAudioSessionReleaseProvider
-[CSFallbackAudioSessionReleaseProvider fallbackDeactivateAudioSession:error:]_block_invoke
-[CSFallbackAudioSessionReleaseProvider fallbackDeactivateAudioSession:error:]
com.apple.siri.acousticsignature
ADAcousticFingerprinter
-[CSSiriAcousticFingerprinter _connectionInterrupted]
-[CSSiriAcousticFingerprinter _connectionInvalidated]
-[CSSiriAcousticFingerprinter _configureWithCurrentASBD]
-[CSSiriAcousticFingerprinter _convertPCMDataForFingerprinting:]
-[CSSiriAcousticFingerprinter appendPCMData:]_block_invoke
v16@?0@"NSData"8
-[CSSiriAcousticFingerprinter flush]_block_invoke_2
ASXSampleRateFromInt
satScore
CSSiriSpeechRecorder.m
speechController != nil
audioSessionController != nil
audioPlaybackService != nil
-[CSSiriSpeechRecorder initWithQueue:speechController:audioSessionController:audioPlaybackService:experimentContext:]
-[CSSiriSpeechRecorder _currentMHUUID:]
-[CSSiriSpeechRecorder _setSpeechCapturingMode:]
-[CSSiriSpeechRecorder _setEndpointerOperationMode:forceUpdate:]
-[CSSiriSpeechRecorder _setAlertsIfNeeded]
siri-begin-improved
v32@?0@"NSNumber"8@"NSNumber"16^B24
-[CSSiriSpeechRecorder _updateRecordBufferDuration]
Speech controller should not be nil.
-[CSSiriSpeechRecorder _speechControllerWithError:]
-[CSSiriSpeechRecorder _resetSpeechController]
-[CSSiriSpeechRecorder _prepareSpeechControllerWithOptions:error:]
requestDuringActiveCall
since we have no Voice Controller!
-[CSSiriSpeechRecorder _stopRecordingWithReason:hostTime:]
%d.%d
 Forcing two shot mode to NO
-[CSSiriSpeechRecorder _disableEndpointer]
-[CSSiriSpeechRecorder _playAudioAlert:]
-[CSSiriSpeechRecorder _checkAudioLoggingLimits:]
-[CSSiriSpeechRecorder _setupAudioFileWritingForSpeechController:info:context:]
yyyy_MM_dd-HHmmss.SSS
%@/PCM-%@-%@.wav
-[CSSiriSpeechRecorder _setEndpointStyle:]
-[CSSiriSpeechRecorder _stopRecordingForEndpointReason:]
-[CSSiriSpeechRecorder eagerlyInitializeAudioRecording]
-[CSSiriSpeechRecorder preheat]
-[CSSiriSpeechRecorder preheat]_block_invoke
-[CSSiriSpeechRecorder recordingInfoForPreheatWithEvent:]
-[CSSiriSpeechRecorder currentVTSatScore]
-[CSSiriSpeechRecorder prepareForMode:]
-[CSSiriSpeechRecorder startSpeechCaptureWithContext:willStartHandler:error:]
kAudioSessionProperty_ActiveSessionDisplayIDs
, playing error alert
-[CSSiriSpeechRecorder updateSpeechSynthesisRecord:]
-[CSSiriSpeechRecorder _audioSessionID]
state
v16@?0@?<v@?@"NSDictionary">8
-[CSSiriSpeechRecorder setSpeechRequestOptions:]
-[CSSiriSpeechRecorder _updateAudioContextWithInfo:reason:]
-[CSSiriSpeechRecorder _setAudioContextWithInfo:forReason:]
-[CSSiriSpeechRecorder _updateAudioContextToPostVoiceForReason:]
-[CSSiriSpeechRecorder _updateAudioContextWithPendingInfoForReason:]
-[CSSiriSpeechRecorder releaseAudioSession]
notify
suppress (keep others interrupted forever)
-[CSSiriSpeechRecorder setSpeechWasRecognizedForElapsedTime:isFinal:]
-[CSSiriSpeechRecorder setFingerprintWasRecognized]
-[CSSiriSpeechRecorder stopSpeechCaptureForEvent:suppressAlert:hostTime:]
-[CSSiriSpeechRecorder cancelSpeechCaptureSuppressingAlert:]
-[CSSiriSpeechRecorder forceSuccessAudioAlertOnStop]
-[CSSiriSpeechRecorder _speechRecordingEventListener]_block_invoke
-[CSSiriSpeechRecorder setClientConfiguration:]
-[CSSiriSpeechRecorder playRecordingStartAlert]_block_invoke
-[CSSiriSpeechRecorder _updateRecordDeviceInfoAndPlaybackRouteForReason:audioDeviceInfo:forcesUpdate:]
Unavailable
playbackDeviceTypes
-[CSSiriSpeechRecorder _recordingInfoForEvent:audioAlertStyle:includeBTInfo:includeRecordDeviceInfo:]
-[CSSiriSpeechRecorder speechControllerDidStartRecording:audioDeviceInfo:successfully:error:]
-[CSSiriSpeechRecorder speechControllerDidStartRecording:audioDeviceInfo:successfully:error:]_block_invoke
-[CSSiriSpeechRecorder _speechControllerDidStartRecording:successfully:error:]
Opus
Speex
-[CSSiriSpeechRecorder speechControllerDidDeliverLastBuffer:forReason:estimatedSpeechEndHostTime:]
-[CSSiriSpeechRecorder speechControllerDidStopRecording:audioDeviceInfo:forReason:estimatedSpeechEndHostTime:]
-[CSSiriSpeechRecorder speechControllerDidStopRecording:audioDeviceInfo:forReason:estimatedSpeechEndHostTime:]_block_invoke
-[CSSiriSpeechRecorder _speechControllerDidStopRecording:audioDeviceInfo:forReason:estimatedSpeechEndHostTime:errorCodeOverride:underlyingError:]
-[CSSiriSpeechRecorder _speechControllerDidStopRecording:audioDeviceInfo:forReason:estimatedSpeechEndHostTime:errorCodeOverride:underlyingError:]_block_invoke_2
-[CSSiriSpeechRecorder _speexDecoder]
-[CSSiriSpeechRecorder _opusDecoder]
-[CSSiriSpeechRecorder _decodeRecordBufferForSecureOfflineOnly:isOpus:]_block_invoke
-[CSSiriSpeechRecorder _decodeRecordBufferForSecureOfflineOnly:isOpus:]
-[CSSiriSpeechRecorder speechControllerRecordBufferAvailable:buffers:durationInSec:recordedAt:audioDeviceInfo:]
-[CSSiriSpeechRecorder speechControllerRecordBufferAvailable:buffers:durationInSec:recordedAt:audioDeviceInfo:]_block_invoke
-[CSSiriSpeechRecorder _speechControllerDidReceiveFirstAudioRecordBufferWithHostTime:atHostTime:mhUUID:]
-[CSSiriSpeechRecorder getAudioRouteInstrumentationWithRecordingInfo:]
-[CSSiriSpeechRecorder speechControllerLPCMRecordBufferAvailable:buffer:]
audio_recording
empty_lpcm_record_buffer
-[CSSiriSpeechRecorder _speechControllerDidReceiveLastAudioRecordBuffer:forReason:estimatedSpeechEndHostTime:isRecordingStopped:]
-[CSSiriSpeechRecorder speechControllerBeginRecordInterruption:withContext:]
-[CSSiriSpeechRecorder speechControllerEndRecordInterruption:]
-[CSSiriSpeechRecorder speechControllerRecordHardwareConfigurationDidChange:toConfiguration:]
-[CSSiriSpeechRecorder speechController:willSetAudioSessionActive:]
-[CSSiriSpeechRecorder speechController:didSetAudioSessionActive:]
-[CSSiriSpeechRecorder speechControllerDidFinishAlertPlayback:ofType:error:]
-[CSSiriSpeechRecorder speechControllerDidFinishAlertPlayback:ofType:error:]_block_invoke
-[CSSiriSpeechRecorder _playStopAlertIfNecessaryForReason:endpointMode:error:]
AVVoice_RecordStoppedWithError
AVVoice_RecordStopped
-[CSSiriSpeechRecorder languageDetectorDidDetectLanguageWithConfidence:confidence:isConfident:]
-[CSSiriSpeechRecorder speechControllerDidDetectVoiceTriggerTwoShot:atTime:wantsAudibleFeedback:]
-[CSSiriSpeechRecorder speechControllerDidDetectVoiceTriggerTwoShot:atTime:wantsAudibleFeedback:]_block_invoke
Two shot feedback
-[CSSiriSpeechRecorder suppressUtteranceGradingIfRequired]
Utterance Grading
-[CSSiriSpeechRecorder suppressUtteranceGradingIfRequired]_block_invoke
-[CSSiriSpeechRecorder speechControllerRequestsOperation:forReason:]
-[CSSiriSpeechRecorder speechControllerRequestsOperation:forReason:completion:]
-[CSSiriSpeechRecorder _speechControllerRequestsOperation:forReason:completion:]
v32@?0d8d16@"NSError"24
-[CSSiriSpeechRecorder speechControllerDidUpdateSmartSiriVolume:forReason:]
-[CSSiriSpeechRecorder endpointer:didDetectStartpointAtTime:]
-[CSSiriSpeechRecorder endpointer:didDetectStartpointAtTime:]_block_invoke
-[CSSiriSpeechRecorder endpointer:didDetectHardEndpointAtTime:withMetrics:]
time
additionalMetrics
@"NSMutableDictionary"8@?0
-[CSSiriSpeechRecorder endpointer:didDetectHardEndpointAtTime:withMetrics:]_block_invoke
-[CSSiriSpeechRecorder _hardEndpointWasDetectedWithMetrics:atTime:]
-[CSSiriSpeechRecorder _performTwoShotPromptForType:atTime:]
suppressedAlert
timedOut
-[CSSiriSpeechRecorder _playPhaticWithCompletion:]
-[CSSiriSpeechRecorder _playPhaticWithCompletion:]_block_invoke
delegate is nil
-[CSSiriSpeechRecorder _handleFakeTwoShotPromptTimeoutWithUUID:]
-[CSSiriSpeechRecorder _handleFakeTwoShotPromptCallbackWithUUID:timestamp:duration:error:]
-[CSSiriSpeechRecorder updateEndpointHintForDuration:completion:]
-[CSSiriSpeechRecorder _checkIfLastEndpointHintShouldBeAccepted]
-[CSSiriSpeechRecorder _checkIfLastEndpointHintShouldBeAccepted]_block_invoke_2
v20@?0B8@"NSArray"12
-[CSSiriSpeechRecorder _enforceEndpointHint]
-[CSSiriSpeechRecorder performBlockAfterAlerts:timeout:]
-[CSSiriSpeechRecorder performBlockAfterAlerts:timeout:]_block_invoke
-[CSSiriSpeechRecorder acousticFingerprinter:hasFingerprint:duration:]
-[CSSiriSpeechRecorder _startAudioPlaybackRequest:options:completion:]
-[CSSiriSpeechRecorder _startAudioPlaybackRequest:options:completion:]_block_invoke
-[CSSiriSpeechRecorder speakerIdentificationDidDetectSpeakerWithScores:]
-[CSSiriSpeechRecorder audioSessionController:didReceiveAudioSessionInterruptionNotificationWithUserInfo:]
-[CSSiriSpeechRecorder audioSessionController:didReceiveAudioSessionRouteChangeNotificationWithUserInfo:]
-[CSSiriSpeechRecorder audioSessionController:didReceiveAudioSessionMediaServicesWereLostNotificationWithUserInfo:]
-[CSSiriSpeechRecorder audioSessionController:didReceiveAudioSessionMediaServicesWereResetNotificationWithUserInfo:]
-[CSSiriSpeechRecorder audioSessionController:didReceiveAudioSessionOwnerLostNotification:]
-[CSSiriSpeechRecorder audioSessionController:didReceiveAudioSessionOwnerResetNotification:]
Siri
DictationSecureOfflineOnly
FingerprintOnly
SiriSecureOfflineOnly
SiriCoreSymptomsReporter
Class getSiriCoreSymptomsReporterClass(void)_block_invoke
Unable to find class %s
void *SiriCoreLibrary(void)
/System/Library/PrivateFrameworks/SiriCore.framework/SiriCore
/System/Library/PrivateFrameworks/SiriCore.framework/Contents/MacOS/SiriCore
com.apple.assistant.audio-playback-service
-[CSSiriAudioPlaybackService _prewarmRequest:completion:]
-[CSSiriAudioPlaybackService _startRequest:options:preparationHandler:executionHandler:finalizationHandler:]
-[CSSiriAudioPlaybackService _handlePreparationForSession:]
v16@?0@"<CSSiriAudioPlaybackServiceListening>"8
-[CSSiriAudioPlaybackService _handleExecutionForSession:]
-[CSSiriAudioPlaybackService _handleFinalizationForSession:error:]
v32@?0@"AFAudioPlaybackRequest"8@"<CSSiriAudioPlaybackSession>"16^B24
v24@?0@"<CSSiriAudioPlaybackServiceListening>"8^B16
-[CSSiriAudioPlaybackService _evictAllReusableSessionsForReason:]
-[CSSiriAudioPlaybackService audioSessionController:didReceiveAudioSessionInterruptionNotificationWithUserInfo:]
-[CSSiriAudioPlaybackService audioSessionController:didReceiveAudioSessionMediaServicesWereLostNotificationWithUserInfo:]
-[CSSiriAudioPlaybackService audioSessionController:didReceiveAudioSessionMediaServicesWereResetNotificationWithUserInfo:]
-[CSSiriAudioPlaybackService audioSessionController:didReceiveAudioSessionOwnerLostNotification:]
-[CSSiriAudioPlaybackService audioSessionController:didReceiveAudioSessionOwnerResetNotification:]
-[CSStartOfSpeechDetector initWithConfig:samplingRate:minSpeechFrames:numLeadingFrames:delegate:]
-[CSAudioServerCrashMonitor _startMonitoringWithQueue:]
com.apple.corespeech.voicetriggerservice
-[CSVoiceTriggerXPCClient dealloc]
-[CSVoiceTriggerXPCClient _handleListenerEvent:]
-[CSVoiceTriggerXPCClient _handleListenerError:]
enable
assertion
timestamp
phraseSpotterBypass
bypassTimeout
raiseToSpeakBypass
triggerStats
-[CSVoiceTriggerXPCClient fetchVoiceTriggerStats]
-[CSCoreSpeechDaemonStateMonitor notifyDaemonStateChanged:]
com.apple.corespeech.corespeechd.launch
-[CSCoreSpeechDaemonStateMonitor _startMonitoringWithQueue:]
-[CSCoreSpeechDaemonStateMonitor _stopMonitoring]
-[CSCoreSpeechDaemonStateMonitor _didReceiveDaemonStateChanged:]
com.apple.transcribe.Transcriber
-[CSKeywordAnalyzerQuasar initWithConfigPath:triggerTokens:useKeywordSpotting:]
-[CSKeywordAnalyzerQuasar initWithConfigPath:triggerTokens:useKeywordSpotting:]_block_invoke
-[CSKeywordAnalyzerQuasar reset]
-[CSKeywordAnalyzerQuasar dealloc]
-[CSKeywordAnalyzerQuasar runRecognition]
-[CSKeywordAnalyzerQuasar runRecognition]_block_invoke
-[CSKeywordAnalyzerQuasar endAudio]
-[CSKeywordAnalyzerQuasar endAudio]_block_invoke
-[CSKeywordAnalyzerQuasar _recognizeWavData:length:]
-[CSKeywordAnalyzerQuasar speechRecognizer:didRecognizePartialResult:]_block_invoke
-[CSKeywordAnalyzerQuasar speechRecognizer:didRecognizeFinalResults:]_block_invoke
-[CSKeywordAnalyzerQuasar _phraseIdToCtcScoreMap]
-[CSKeywordAnalyzerQuasar speechRecognizer:didFinishRecognitionWithError:]_block_invoke
-[CSKeywordAnalyzerQuasar _getConfidence:]_block_invoke
-[CSNetworkAvailabilityMonitor _startMonitoringWithQueue:]
-[CSNetworkAvailabilityMonitor _stopMonitoring]
-[CSNetworkAvailabilityMonitor _availabilityChanged]
-[CSSpeechDetectionDevicePresentMonitor handleSpeechDetectionVADPresentChange:]
-[CSSpeechDetectionDevicePresentMonitor _systemControllerDied:]
isRemoteDevice
remoteDeviceUID
remoteDeviceProductIdentifier
remoteDeviceUIDString
%@ {route = %@, isRemoteDevice = %d, remoteDeviceUID = %@, remoteDeviceProductIdentifier = %@, remoteDeviceUIDString = %@}
CSOpportuneSpeakListnerTestService
com.apple.corespeech.opportunelistner.start
com.apple.corespeech.opportunelistner.stop
A945B95D-69F6-FC77-4FAE-91F50A039CD8
-[CSOpportuneSpeakListnerTestService receiveOpportuneSpeakListenerStart]_block_invoke
-[CSOpportuneSpeakListnerTestService receiveOpportuneSpeakListenerStop]_block_invoke
-[CSOpportuneSpeakListnerTestService opportuneSpeakListener:hasRemoteVADAvailable:]
-[CSOpportuneSpeakListnerTestService opportuneSpeakListener:hasVADAvailable:]
-[CSOpportuneSpeakListnerTestService opportuneSpeakListener:didStopUnexpectly:]
-[CSAudioConverter _convertBufferedLPCM:allowPartial:timestamp:arrivalTimestampToAudioRecorder:]
-[CSAudioConverter _convertBufferedLPCM:allowPartial:timestamp:arrivalTimestampToAudioRecorder:]_block_invoke
CSAudioConverter.m
Cannot produce ASPD for PCM
-[CSAudioConverter reset]
-[CSAudioConverter _configureAudioConverter:]
CreateAudioConverter
-[CSLanguageCodeUpdateMonitor _startMonitoringWithQueue:]
CSLanguageCodeUpdateMonitor.m
-[CSLanguageCodeUpdateMonitor _stopMonitoring]
-[CSLanguageCodeUpdateMonitor notifySiriLanguageCodeChanged:]
-[NSData(Nvi) splitAudioDataToReachSampleCount:currSampleCount:numBytesPerSample:completionHandler:]
com.apple.corespeech.audioinjection.xpc
+[CSAudioInjectionServices setAudioInjectionMode:]
+[CSAudioInjectionServices audioInjectionEnabled]
+[CSAudioInjectionServices pingpong:completion:]_block_invoke
TEST
+[CSAudioInjectionServices pingpong:completion:]
v28@?0B8@"NSError"12@"NSUUID"20
+[CSAudioInjectionServices createAudioInjectionDeviceWithType:deviceName:deviceID:productID:completion:]_block_invoke
+[CSAudioInjectionServices createAudioInjectionDeviceWithType:deviceName:deviceID:productID:completion:]
v36@?0B8@"NSError"12Q20Q28
+[CSAudioInjectionServices injectAudio:toDeviceWithUUID:withfadingTimeWindowLength:completion:]_block_invoke
+[CSAudioInjectionServices injectAudio:toDeviceWithUUID:withfadingTimeWindowLength:completion:]
+[CSAudioInjectionServices connectDeviceWithUUID:completion:]_block_invoke
+[CSAudioInjectionServices connectDeviceWithUUID:completion:]
+[CSAudioInjectionServices disconnectDeviceWithUUID:completion:]_block_invoke_2
+[CSAudioInjectionServices disconnectDeviceWithUUID:completion:]_block_invoke
+[CSAudioInjectionServices disconnectDeviceWithUUID:completion:]
+[CSAudioInjectionServices primaryInputDeviceUUIDWithCompletion:]_block_invoke_2
+[CSAudioInjectionServices primaryInputDeviceUUIDWithCompletion:]_block_invoke
+[CSAudioInjectionServices primaryInputDeviceUUIDWithCompletion:]
Dpg:%.3f Dpd:%.3f T:%.3f
droppingPrediction
droppedPrediction
voic
carplay
hearst
raisetospeak
auto
-[NSDictionary(XPCObject) _cs_initWithXPCObject:]
-[NSDictionary(XPCObject) _cs_initWithXPCObject:]_block_invoke
B24@?0r*8@"NSObject<OS_xpc_object>"16
-[NSDictionary(XPCObject) _cs_xpcObject]_block_invoke
v32@?0@8@16^B24
effectiveThreshold
recognizerScore
recognizerThresholdOffset
threshold
isSecondChance
supportedPhrases
mpvt2ndPassTriggeredPhraseId
phraseId
phraseStr
ndapiScore
2ndChanceThreshold
loggingThreshold
recognizerScoreScaleFactor
tdsrSatCombinedSATThreshold
%lu:%@:ndapi=%f:ctc=%f:comb=%f:thr=%f:maxd=%d:
%lu:%@:ndapi=%f:ctc=%f:comb=%f:thr=%f:maxd=%d:res=%@
-[CSVTSecondPassScorer initWithAsset:firstPassSource:]
-[CSVTSecondPassScorer updateWithCtcCheckerResults:]
-[CSVTSecondPassScorer getTriggeredPhraseWithSecondChanceEnabled:]
%@, 
detector-config
supported-locales
detector.json
sos-options.json
SPG.json
Builtin Microphone
[Context = %ld]
[DeviceId = %@]
[Announced = %d]
[streamHandleId = %d]
[startHostTime = %llu]
[startAlert = %d]
[stopAlert = %d]
[stopOnErrorAlert = %d]
[skipAlert = %@]
-[CSAudioRecorder initWithQueue:error:]
-[CSAudioRecorder willDestroy]
-[CSAudioRecorder dealloc]
-[CSAudioRecorder _destroyVoiceController]
-[CSAudioRecorder _voiceControllerWithError:]_block_invoke
-[CSAudioRecorder _voiceControllerWithError:]
-[CSAudioRecorder setAnnounceCallsEnabled:withStreamHandleID:]
-[CSAudioRecorder setContext:completion:]
-[CSAudioRecorder setCurrentContext:streamHandleId:error:]
-[CSAudioRecorder prepareAudioStreamRecord:recordDeviceIndicator:error:]
-[CSAudioRecorder _startAudioStreamForAudioInjectionWithAVVCContext:]
-[CSAudioRecorder startAudioStreamWithOption:recordDeviceIndicator:error:]
-[CSAudioRecorder stopAudioStreamWithRecordDeviceIndicator:error:]
-[CSAudioRecorder isSessionCurrentlyActivated]
-[CSAudioRecorder recordDeviceInfoWithStreamHandleId:recordDeviceIndicator:]
%llu
-[CSAudioRecorder audioDeviceInfoWithStreamHandleId:recordDeviceIndicator:]
-[CSAudioRecorder recordingSampleRateWithStreamHandleId:]
-[CSAudioRecorder isNarrowBandWithStreamHandleId:]
-[CSAudioRecorder prewarmAudioSessionWithStreamHandleId:error:]
-[CSAudioRecorder setRecordMode:streamHandleId:error:]
-[CSAudioRecorder activateAudioSessionWithReason:streamHandleId:error:]
-[CSAudioRecorder deactivateAudioSession:error:]
-[CSAudioRecorder deactivateAudioSession:streamHandleId:error:]
+[CSAudioRecorder createSharedAudioSession]
-[CSAudioRecorder enableSmartRoutingConsiderationForStream:enable:]
-[CSAudioRecorder setDuckOthersForStream:]
-[CSAudioRecorder setMixWithOthersForStream:]
-[CSAudioRecorder setDuckOthersOption:]
-[CSAudioRecorder enableMiniDucking:]
-[CSAudioRecorder configureAlertBehavior:audioStreamHandleId:]
-[CSAudioRecorder voiceTriggerInfoWithRecordDeviceIndicator:]
-[CSAudioRecorder _updateLanguageCodeForRemoteVTEIResult:]
useRemoteBuiltInMic
-[CSAudioRecorder _processAudioBuffer:audioStreamHandleId:arrivalTimestampToAudioRecorder:]
-[CSAudioRecorder _compensateChannelDataIfNeeded:receivedNumChannels:]
-[CSAudioRecorder playRecordStartingAlertAndResetEndpointerFromStream:]
-[CSAudioRecorder playAlertSoundForType:recordDevideIndicator:]
-[CSAudioRecorder voiceControllerDidStartRecording:forStream:successfully:error:]
-[CSAudioRecorder voiceControllerAudioCallback:forStream:buffer:]
-[CSAudioRecorder voiceControllerDidStopRecording:forStream:forReason:]
-[CSAudioRecorder voiceControllerStreamInvalidated:forStream:]
-[CSAudioRecorder voiceControllerRecordHardwareConfigurationDidChange:toConfiguration:]
-[CSAudioRecorder voiceControllerDidFinishAlertPlayback:ofType:error:]
-[CSAudioRecorder voiceControllerEncoderErrorDidOccur:error:]
-[CSAudioRecorder voiceControllerBeginRecordInterruption:]
-[CSAudioRecorder voiceControllerBeginRecordInterruption:withContext:]
-[CSAudioRecorder voiceControllerEndRecordInterruption:]
-[CSAudioRecorder voiceControllerWillSetAudioSessionActive:willActivate:]
-[CSAudioRecorder voiceControllerDidSetAudioSessionActive:isActivated:]
-[CSAudioRecorder voiceControllerMediaServicesWereLost:]
-[CSAudioRecorder voiceControllerMediaServicesWereReset:]
-[CSAudioRecorder _hasLocalPendingTwoShot]_block_invoke
-[CSAudioRecorder _getRecordSettingsWithRequest:]
-[CSAudioRecorder _fetchRemoteRecordClientWithDeviceId:streamHandleId:]
CSCommandControlBehaviorMonitor
-[CSCommandControlBehaviorMonitor notifyWillStartStreamWithContext:option:]_block_invoke
-[CSCommandControlBehaviorMonitor notifyDidStartStreamWithContext:successfully:option:]_block_invoke
-[CSCommandControlBehaviorMonitor notifyWillStopStream:]_block_invoke
-[CSCommandControlBehaviorMonitor notifyDidStopStream:]_block_invoke
[profileId: %@, language: %@, product: %@, version: %@, homeId: %@, name: %@]
{isVT=%d, requestHistoricalAudio=%d, reqStartAudioSampleId=%lu, reqStartMachAbsTime=%llu}
-[NSData(XPCObject) _cs_initWithXPCObject:]
+[CSEndpointerFactory endpointerProxy]
CSOpportuneSpeakEventMonitor
-[CSOpportuneSpeakEventMonitor isStreaming]
+[NviSignalData headerString]
-[NviSignalData stringForLogging]
{%@:ts=%lld}
%s input dictionary is nil
%s Dealloc CSAudioInjectionEngine : %@
%s Looking up audio diff:%llu sampleCount:%llu %@
%s Unable to write to o/p stream ! 
%s Got event! %lu
%s Got unhandled evt code %lu 
%s %{public}@ deallocated
%s audioProvider not exist
%s Start Monitoring : AudioSession notification from corespeechd
%s Stop Monitoring : AudioSession notification from corespeechd
%s reset sessionInfoProvider since xpcClient disconnected
%s CoreSpeech Daemon reset notification
%s %@ task delivered.
%s %@ completed with response %@ and error %@.
%s Get initial state from MediaRemote: media is on playing state %{public}ld.
%s Start monitoring MediaRemote: media playback
%s Stop monitoring MediaRemote: media playback
%s MediaRemote reported the now playing app playback state changed to %s (state %d)
%s Celestial is not available on this platform.
%s notification = %{public}@
%s MobileTimer is not available on this platform.
%s Dealloc audioStreamHolding : %{public}@
%s ERR: topScoringUser is nil from %{public}@
%s ERR: invalid arguments passed %{public}@ %{public}@
%s ERR: Incorrect category %{public}d passed
%s ERR: Failed to get remote proxy object for AttSiriXPC: %@
%s _remoteSvcProxy is nil!
%s Client Interruption Handler: %{public}@, client PID: %{public}d)
%s Client Invalidation Handler: %{public}@, client PID: %{public}d exited
%s Clearing pending homekit accessory voice trigger %{private}@
%s Handling Pending Remora VoiceTrigger Event
%s Time since last pending remora voice trigger %f. Ignoring.
%s Clearing pending built-in voice trigger %{private}@
%s Handling Pending BuiltInVoiceTrigger Event
%s Time since last pending builtin voice trigger %f. Ignoring.
%s client: %lu, deviceId: %{private}@
%s Setting mixable to yes as we are in an active call
%s In %@: Continuous digital zero detected, lasting %{public}u samples per channel
%s In %@: Continuous digital zero in this audio chunk detected, lasting %{public}u samples per channel
%s Cannot access to %{public}@ %{public}@ using default value=%{public}@
%s ERR: Failed to establish XPC connection!
%s Requesting RTS %{public}@ bypass for %{public}lf seconds
%s voiceTriggerXPC client not exist
%s reset xpcClient since it disconnected
%s Start monitoring : VoiceTrigger Asset Download
%s Stop monitoring : VoiceTrigger Asset Download
%s New VoiceTrigger is now installed
%s CS logging files under %{public}@ created before %{public}@ will be removed.
%s Couldn't get creation date: %{public}@
%s Could not remove %{public}@: %{public}@
%s CS logging files number %{public}lu with pattern %{public}@ under %{public}@ exceeding limit, only keep the latest %{public}lu ones
%s Regular expression is nil!
%s Resetting audio preprocessor : %{public}f, containsVoiceTrigger:%{public}d
%s Flushing audio preprocessor
%s Zero Filter Metrics: %{public}@
%s Beep Canceller Metrics : %{public}@
%s Couldn't find keychain value %@ for account %@ %{public}d
%s Trying to access BTLocalDevice
%s Accessing BTLocalDevice
%s BTLocalDevice %{public}p
%s Failed to get sharing enable flag : %d
%s Failed getting sharing device addresses %d
%s Failed converting address from BTDeviceAddress (result = %d).
%s Device is temporary paired and not in contacts
%s Detaching bluetooth session : %{public}p
%s Already Attaching Bluetooth Session
%s Start attaching bluetooth session
%s session = %{public}p, result = %{public}d
%s session = %p
%s detached session is different from currently attached session, ignore
%s terminated session is different from currently attached session, ignore
%s Bluetooth Session is NULL
%s Failed to get default local device from session %{public}p, (result = %{public}d)
%s Failed to add local device callback from session %{public}p, (result = %{public}d
%s Start monitoring: siri assertion enable/disable
%s Stop monitoring: siri assertion enable/disable
%s did receive enable assertion
%s did receive disable assertion
%s accessoryId %{private}@
%s Start monitoring : SpeakerRecognition Asset Download
%s Stop monitoring : SpeakerRecognition Assets Download
%s New SpeakerRecognition Assets is now installed
%s ERR: Delegate received for invalid Trial assetType:%lu
%s ::: Error reading file %@, err: %d
%s CSAudioFileReader requires prepare recording settings to feed audio
%s CSAudioFileReader only support LinearPCM to feed
%s Setting ExtAudioFileSetProperty failed : %d
%s Starting audio file feed timer, bufferDuration = %f sampleRate = %f, bytesPerFrame = %d, channelsPerFrame = %d
%s ::: Error reading data from audio file : %d
%s Reach to EOF, chunkSize = %d
%s Stopping audio file feed timer
%s Start monitoring : AdBlocker Asset Download
%s Stop monitoring : AdBlocker Asset Download
%s New AdBlockerAsset is now installed
%s Received active route change notification
%s Start monitoring : AudioRouteChangeMonitor
%s Stop monitoring : AudioRouteChangeMonitor
%s Notifying Hearst Connection State : %{public}d
%s Cannot create SampleRateConverter using AudioConverterNew : %{public}d
%s Cannot set Quality property to audioConverter
%s Cannot set Complexity property to audioConverter
%s Audio resampling done : %lu
%s AudioConverter is sad: 0x%{public}xd
%s Cannot start monitoring language detector asset, since we already registered
%s LanguageDetector supported locale is nil : %{public}@
%s %p (sessionUUID = %@)
%s %p (sessionUUID = %@
%s %p
%s %p (startSpeechId = %@)
%s %p (selectedResultCandidateId = %@)
%s %p (allows = %d, resultCandidateId = %@)
%s route = %@, deviceIdentifier = %@, deviceUID = %@
%s %p (recordedAudioFileURL = %@)
%s %p (audioRecordContext = %@)
%s %p (audioRecordDeviceInfo = %@)
%s %p (voiceTriggerInfo = %@)
%s %p (recordingInfo = %@)
%s %p (recordingSettings = %@)
%s %p audioActivationInfo = %@
%s %p effectiveDate = %@ (%f)
%s %p (error = %@)
%s %p (relinquishmentContext = %@)
%s %p startRecordingAudioSessionAssertion = %@
%s %p audioActivationInfo = %@, time = %f
%s %p twoShotDetectionAudioSessionAssertion = %@
%s %p hostTime = %llu
%s %p context = %@
%s %p error = %@
%s %p (_recordedAudioFileURL = %@)
%s %p (_audioFileWriter = %@)
%s recordingSettings was nil
%s No alert behavior in recordingSettings
%s No alert style specified for record starting
%s %p No recorded audio.
%s %p Access to payload audio at %@ is %@, setting payload recording flag for CoreSpeech.
%s %p Donating recorded audio at %@...
%s %p Failed to donate recorded audio at %@ for  VoiceID training (error = %@).
%s %p Donated recorded audio at %@ for  Voice VoiceID training.
%s %p Removing recorded audio at %@...
%s %p Removed recorded audio at %@.
%s %p Failed to remove recorded audio at %@ (error = %@).
%s Creating SmartSiriVolume connection
%s SmartSiriVolume Remote Object Proxy is nil
%s SmartSiriVolume Failed to get estimate with %{public}@
%s SmartSiriVolume didChangeForReason: %{public}d
%s ERR: SmartSiriVolume Remote Object Proxy returned error : %{public}ld (%{public}@)
%s ERR: SmartSiriVolume ssvConnection is nil
%s Dealloc CSAudioInjectionProvider : %@
%s Stopping Audio Injection Provider : %@
%s Calling start audio stream : %@ %@
%s Calling stop audio stream : %@
%s xpc object string return nil
%s xpc object should be XPC_TYPE_STRING
%s Start Listening request with deviceId : %{public}@
%s CSOpportuneSpeakListener received didStart : %{public}d, %{public}@
%s remoteVADDuration = %{public}d, spgDuration = %{public}d, _remoteVADSPGRatio = %{public}d
%s AudioStreamRequest has failed : %{public}@
%s CSOpportuneSpeakListener received didStop : %{public}d, %{public}@
%s Request stop CSOpportuneSpeakListener
%s Audio coming from DoAP should contains RemoteVAD
%s boronScore : %{public}d, reportBoron : %{public}d, slienceScore : %{public}lf
%s cannot handle nil event 
%s ignore unknown types of message: %{public}@
%s cannot handle nil error
%s Listener connection disconnected
%s connection error: %{public}s
%s Not supported on this platform
%s disconnect activationXPCClient
%s cannot handle event : event = %{public}p
%s ignore unknown types of message 
%s cannot handle error : error = %{public}p
%s Siri language is nil, falling back to %@
%s endpointUUID not provided, fallback to legacy query
%s Failed to query language code with endpointId %@, trying legacy query
%s Advert data: %{public}@
%s advert data write failed
%s %{public}.2f ms after firstBufferStart
%s Invalid timestamp (currentMachTime: %{public}llu timestamp: %{public}llu)
%s Invalid timestamp (currentMachTime: %{public}llu arrivalTimestamp: %{public}llu)
%s numOfAudioPackets: %{public}lu, numOfValidTrailingPackets: %{public}lu, numOfValidTrailingSpeechPackets: %{public}lu, 
trailingPktLatencies: %{public}@ 
trailingPktSpeechLatencies: %{public}@
%s Fetching CommandControl Listening State: %d
%s Error getting file path from provided file handle; will create our own path and handle
%s Failure disposing audio file %{public}d
%s Error removing item at URL %{public}@
%s Configuring with asbd %.4s
%s Creating audio file at URL %@
%s Failed creating audio file at url %{public}@ %{public}d
%s Error setting input format %{public}d
%s No audio file to append data
%s Failed writing audio file %{public}d
%s No file url on flush
%s Failed opening fd for flushed audio file %{public}s
%s inASBD->mChannelsPerFrame = %lu
%s Error getting format info for type %{public}.4s %{public}.4s
%s getCoreSpeechXPCConnection Invalidated
%s making connection to corespeechd with (%{public}d)
%s Asking VoiceTrigger locale to corespeechd
%s Current VoiceTrigger Locale = %{public}@
%s Cannot get Current VoiceTrigger Locale, falling back to en-US : %{public}@
%s Asking current VoiceTrigger aset for %{public}d.%{public}d
%s Asking keyword language given Jarvis language list %{public}@, jarvis-selected language: %{public}@
%s CSCoreSpeechServices Invalidated
%s Request updated SAT audio succeed.
%s Request updated SAT audio failed.
%s SelfTriggerDetector cannot be turned on since VoiceTrigger is disabled
%s SelfTriggerDetector cannot be turned on since builtInSpeaker is inactive
%s SelfTriggerDetector cannot be turned on since deviceIsInSleep
%s speechController = %{public}p
%s xpcListener = %{public}p
%s context = %{public}@
%s Failed to create audio recorder : %{public}@
%s For Context : %{public}@, audioStreamId(%llu) has allocated
%s Failed to get audio stream handle ID : %{publid}@
%s has match with audio stream handle id : %llu
%s does not match with audio stream handle id(%llu), creating new audio provider
%s No audioRecorder available, return nil for audioProvider
%s have matched audioProvider with stream handle id : %llu
%s don't have matched audioProvider with stream handle id : %llu, need to create one later
%s audioProvider[%{public}@] invalidated with streamHandleId : %{public}llu
%s No matched audioProvider found for streamHandleId : %{public}llu
%s Received VoiceTrigger cached asset change notification, let's reinitialize VoiceTrigger
%s Trying to start clear logging files
%s Clear logging file timer is already started, ignore startClearLoggingFilesTimer request.
%s SpeechEndEstimation: trailingSilenceDuration = %{public}f
%s SpeechEndEstimation: TrailingSilenceDuration at endpointer(%{public}f) is longer than threshold(%{public}f), force to make 0
%s SpeechEndEstimation: _lastAudioChunkHostTime = %{public}llu, estimatedSpeechEndHostTime = %{public}llu
%s Start Listening for Command Control
%s Calling didStart of CSCommandControlListener
%s Stopping stopListenWithCompletion
%s Calling didStop of CSCommandControlListener
%s Calling didStopUnexpectly
%s Received xpc disconnection, audioStream is streaming = %{public}d
%s init-_currentLanguageCode: %{public}@
%s Asset Manager Policy has been %{public}@
%s Asset Manager Policy has been enabled, start fetching meta data now
%s Need to fetch remote meta now, since we have new asset need to be downloaded
%s Does not need to fetch remote meta now
%s Cannot fetch VoiceTrigger asset meta data
%s Undefined assetType : %{public}u
%s _currentLanguageCode changed: %{public}@
%s Trying to start download meta data
%s Periodical downloading is already scheduled, ignore request.
%s No periodical downloading is scheduled, ignore request.
%s Endpointer Failed to get epVersion
%s Endpointer Remote Object Proxy is nil
%s xpcWaitingGroup timed out for fetching endpointerModelVersion
%s elapsed time = %{public}lf
%s Endpointer Failed to get elapsedTimeWithNoSpeech
%s xpcWaitingGroup timed out for fetching elapsedTimeWithNoSpeech
%s Endpointer Failed to get trailingSilenceDurationAtEndpoint
%s xpcWaitingGroup timed out for fetching trailingSilenceDurationAtEndpoint
%s Endpointer Failed to get endPointAnalyzerType
%s xpcWaitingGroup timed out for fetching endPointAnalyzerType
%s Creating RemoteServiceProxy
%s ERR: Endpointer Remote Object Proxy returned error : %{public}ld (%{public}@)
%s ERR: Endpointer endpointerConnection is nil
%s Endpointer didDetectHardEndpointAtTime time withMetrics
%s Not supported on this platform.
%s ERR: Mach Service Name is nil - Bailing out
%s ERR: Proxy Object is nil - Bailing out
%s ERR: Exported interface is nil - Bailing out
%s Started listening for %{public}@
%s Service %{public}@ dealloced - %{public}@
%s Got connection on service %{public}@
%s Invalid listener - %{public}@
%s Rejecting connection to %{public}@ due to entitlement
%s Interruption Handler: %{public}@, client PID: %{public}d)
%s Invalidation Handler: %{public}@, client PID: %{public}d exited
%s Adding connection for client PID (%{public}d)
%s Client connections dump:
For client PID (%d): %@
%s Sending message for client PID (%{public}d)
%s RemoteObjectProxy is nil for client PID (%{public}d)
%s Using audioInjectionProvider as recorder
%s Record Context: %{public}@
%s Calling startController
%s Ignore request since it is already started
%s settings : %{public}@
%s Session Provider does not exist
%s Received special error code that corespeech needs to setContext and activate audio session again
%s CSSpeechController is already streaming audio.., we don't need to create another audio stream here
%s Prepare audio stream succeeded ? %{public}@, error - %{public}@
%s audioStreamWithRequest succeeded ? %{public}@, error - %{public}@
%s Failed to get audioStream : %{public}@
%s AudioStreamProvider is not existing?
%s We need to apply 12dB post gain for this Siri audio session
%s We don't need to apply post gain
%s Done prepareRecord with result: %{public}@.
%s xpcClient not existing
%s received lastVoiceTriggerInfo %{public}@, lastRTSTriggerInfo %{public}@
%s Activating Audio Session Now Sync.
%s Activating Audio Session Now Async.
%s StreamProvider is already recording
%s duckingDelayedTime = %{public}f, timeIntervalSinceLastTriggerEnd = %{public}lf
%s Failed activate audio session with %{public}f seconds delay from prepareRecordWithSettings due to error %{public}@.
%s Finished activate audio session with %{public}f seconds delay from prepareRecordWithSettings.
%s Cancelled activate audio session with %{public}f seconds delay from prepareRecordWithSettings.
%s Scheduled activateAudioSession with %{public}f seconds delay in prepareRecordWithSettings.
%s Delayed active audio session: Consumed token %{public}@ with %{public}f seconds delay for reason %{public}@.
%s Delayed active audio session: Activating audio session for reason %{public}@.
%s Delayed active audio session: Failed to activate audio session for reason %{public}@ due to error %@.
%s Delayed active audio session: Successfully activate audio session for reason %{public}@.
%s Delayed active audio session: Ignored activating audio session for reason %{public}@ because the validator rejected.
%s Delayed active audio session: Ignored activate audio session for reason %{public}@ because the scheduled token %{public}@ does not match the current token %{public}@.
%s Delayed active audio session: Scheduled new token %{public}@ with %{public}f seconds delay for reason %{public}@.
%s Delayed audio session activate: Cancelled token %{public}@ for reason %{public}@.
%s Delayed audio session activate: Consumed token %{public}@ in advance for reason %{public}@.
%s Delayed audio session activate: Activating audio session for reason %{public}@.
%s Delayed audio session activate: Failed to activate audio session for reason %{public}@ due to error %@.
%s Delayed audio session activate: Successfully activate audio session for reason %{public}@.
%s Creating fake session activation notification for session activation now
%s Scheduling Lazy Audio Session activation with %f timeout
%s Lazy session activate success
%s Lazy Audio Session is not configured.
%s Creating fake session activation notification for session activation failure : %{public}@
%s Activating audio session now
%s AudioSession activated successfully ? %{public}@
%s AudioSession Provider not available
%s Falling back to button record type for context whose record type previously is set to unspecified for accessory %{private}@.
%s recordContext : %{public}@
%s Will skip setting current record context because we were in active call and context was post or auto
%s Resetting CoreSpeech frameworks
%s Ask start recording with requestMHUUID: %{public}@
%s TriggerlessDictation: Ask start recording from: %{public}tu
%s Ask start recording from: %{public}tu
%s Voice trigger to use the current voice triggered channel: %{public}tu
%s Auto prompt to use the last voice triggered channel: %{public}tu
%s SpeechController to receive data from default channel
%s SpeechController to receive data from channel %{public}tu
%s Ask delay audio session active by %{public}f seconds
%s Postpone calling audio session activation til we receive didStart
%s Sending client speechControllerDidStartRecording successfully? %{pubic}@, audioDeviceInfo = %{public}@
%s Sending client speechControllerDidStartRecording successfully? %{pubic}@
%s Report unexpectedly long launch latency %{publlic}.3f
%s audioStream not existing
%s _activateAudoiSessionWithDelay has failed. startRecordWithSettings has failed
%s Start recording invoked too late (%{public}.3f seconds), override scheduledCheckTime: %{public}llu to currentTime: %{public}llu
%s Scheduled audible feedback decision after %{public}.3fseconds (vtEndMachTime: %{public}llu currentMachTime: %{public}llu)
%s Two shot audible feedback decision not needed since we already stopped recording
%s Two shot audible feedback decision (%{public}.3fs later than the scheduled time), elapsedTimeWithNoSpeech: %{public}.3f
%s Two shot audible feedback is %{public}@needed. (isMediaPlaying = %{public}d, canPlayPhaticDuringMediaPlayback = %{public}d)
%s Two shot audible feedback should notify? [%{public}@]
%s Two shot audible feedback is prevented by Myriad decision.
%s Two shot audible feedback decision timed out while waiting for Myriad decision
%s Phatic not needed since we already stopped recording
%s Phatic decision elapsedTimeWithNoSpeech: %{public}.3f
%s Notifying scheduled phatic playback...
%s Failed to playback phatic, error: %{public}@
%s Asking stopRecording when audio stream is not existing
%s Options: %{public}@ at: %{public}llu
%s Reporting didDeliverLastPacket at: %{public}llu
%s SpeechEndEstimation: %{public}llu
%s Scheduling StopRecording After HostTime=%{public}llu
%s Reason : %{public}ld
%s SpeechEndEstimation: Should Estimate SpeechEndHostTime
%s SpeechEndEstimation: Reporting didStop with estimated speech end : %{public}llu, at: %{public}llu, audioDeviceInfo: %{public}@
%s SpeechEndEstimation: Reporting didStop with estimated speech end : %{public}llu, at: %{public}llu
%s _didDeliverLastPacket=%d. Dropping Audio packets of size=%lu
%s chunk.hostTime=%{public}llu, chunkSz=%{public}lu, stopOptions=%{public}@, _numTrailingSamplesAfterSchedulingStop=%{public}lu, maxAllowedSamples=%{public}lu
%s STOPRECORDING: Reached MAX allowed trailing samples AFTER stopRecording was scheduled!
%s STOPRECORDING: chunk.hostTime=%{public}llu >= stopOptions=%{public}@
%s SpeechManager still forwarding audio after didStopForwarding, we shouldn't have this
%s STOPRECORDING: chunk.endHostTime=%{public}llu >= stopOptions=%{public}@
%s AudioProvider is invalidated, teardown connection to audioprovider
%s Ignore session active notification
%s SmartSiriVolume update reason: %lu
%s SpeechController is trying to forward encoded audio after didStopForwarding, we shouldn't have this
%s %{public}.2f ms after vtEnd
%s Setting Alert Sounds From : %{public}@ for AlertType : %{public}d
%s Creating Audio Power Meter with record route %{public}@
%s We don't need Audio Power Meter with record route %{public}@
%s Not available
%s Reported 2-shot at: %{public}f secs
%s _delegate doesnt respond to speechControllerDidDetectVoiceTriggerTwoShot
%s Requesting QuickStop operation upon detecting keyword
%s Unexpected audioFormat for ATV : %{public}u
%s Create audioDecoder for audioFormat %{public}u
%s Unable to prepareAudioProvider in _xpcClient, teardown XPC connection again
%s Queried endpointerModelVersion: %{public}@
%s Cancelling current language detector request !
%s Received Myriad started
%s Received Myriad finished with decision: %tu
%s Detected sound is%{public}@ playing: media(%d) alarm(%d) timer(%d)
%s XPCConnection disconnected
%s reset audioProvider since xpcClient disconnected
%s Playback is active: %{public}d on accessory: %{private}@
%s Alarm is playing: %{public}d on accessory: %{private}@
%s Timer is playing: %{public}d on accessory: %{private}@
%s Now Playing State has changed %d
%s Alarm firing
%s Alarm dismissed
%s Timer firing
%s Timer dismissed
%s SSR Remote Object Proxy is nil
%s Successfully created SSR connection
%s ERR: SSR Remote Object Proxy returned error : %{public}ld (%{public}@)
%s ERR: SSR ssrConnection is nil
%s scoreCard is nil!
%s CS doesn't have ndblobbuilder!
%s latestMajorVersion = %d, LatestMinorVersion = %d
%s corespeech.json doesn't contains rtblobs
%s blob file name is not exists
%s blob file is not exists at %{public}@
%s Reading blob from : %{public}@
%s Blob is nil : %{public}@
%s Locale map for %{public}@ is not available on asset
%s request = %@, options = %@
%s error = %@
%s prepared
%s Player item %@ status is failed with error %@.
%s Created player item %@ from URL %@.
%s Created player item %@ from WAVE asset with %tu bytes of data .
%s Unable to create player item.
%s Created player %@.
%s Unable to replace current item of player %@. Expected current item is %@, actual current item is %@.
%s Player item %@ status is ready to play.
%s Timed out when waiting for player item %@ status to change to ready to play.
%s Successfully changed player item %@ status to ready to play.
%s Failed to change player item %@ status to ready to play due to error %@.
%s Attempted to start %@ when it is already active.
%s Failed to prepare %@ due to error %@.
%s Failed to start %@ because it is already inactive after preparation.
%s Failed to start %@ because it is already inactive after player seek to begin.
%s Failed to start %@ because player failed to seek to begin.
%s started
%s Reset player item %@.
%@ Interrupted
%@ Invalidated
Dealloc-ing
personalizedLMPath=%@ fidesPersonalizedLMPath=%@
Client is 24-hour job
Client is DictationPersonalizationFidesPlugin
Client is PersonalizedLmFidesPlugin
Received an error while accessing %@ service: %@
Invalidating
%s Start Recording Host Time = %{public}llu
%s %p created
%s %p dealloced
%s sp=%p
%s %@ not supported yet.
%s Failed to create: %@
%s SigPrvdrs: %@
%s Starting datasrc: %@
%s Failed to start %@. Err=%@
%s >>> All DataSources Started within timeout of 2secs: timeTaken=%f ms
%s WARN: DataSources Start timedout. timeout=2secs
%s Starting signal provider: %@
%s Failed to start %@: Err=%@
%s >>> All SignalProviders didStart within timeout of 2secs: timeTaken=%f ms
%s WARN: SignalProviders timedout didStart. timeout=2secs
%s >>> All DataSources Stopped within timeout of 2secs: timeTaken=%f ms
%s WARN: DataSources timedout stopping. timeout=2secs
%s Failed to stop %@: Err=%@
%s >>> All SignalProviders didStop within timeout of 2secs: timeTaken=%f ms
%s WARN: SignalProviders timedout didStop. timeout=2secs
%s WARN: Cannot find SignalProvider for %@. Skipping
%s Sending XPCClientType : %{public}d
%s Prepare Audio Provider with Context : %{public}@
%s Failed to get reply result correctly
%s Received alertStartTime = %{public}llu
%s Received peakPower = %{public}f
%s Received averagePower = %{public}f
%s Sending audioMetric request
%s Failed to get audioMetric reply
%s audioMetric : %{public}@
%s Received invalid audioMetric
%s Error creating message
%s audioStreamWithRequest for stream %{public}@
%s Invalid message: stream is nil or request is nil
%s PrepareAudioStream %{public}@
%s Sending AcousticSLResult request
%s Failed to get AcousticSLResult reply
%s Received AcousticSLResult %{public}@
%s Failed to parse AcousticSLResult from raw data
%s Message not valid
%s Sending VoiceTriggerInfo request
%s Failed to get VoiceTriggerInfo request
%s Received VoiceTriggerInfo %{public}@
%s Failed to parse VoiceTriggerInfo from raw data
%s Received rtsTriggerInfo %{public}@
%s Failed to parse rtsTriggerInfo from raw data
%s Not implemented
%s NO reply!!!
%s No message!!
%s No reply for hostTimeFromSampleCount request with sampleCount %{public}llu
%s No message for hostTimeFromSampleCount request with sampleCount %{public}llu
%s No reply for sampleCountFromHostTime request with hostTime %{public}llu
%s No message for sampleCountFromHostTime request with hostTime %{public}llu
%s Cannot handle nil message
%s Unexpected message type : %{public}lld
%s AlertProvidingDelegate messageType : %{public}lld
%s Unexpected type : %{public}lld
%s SessionProvidingDelegate messageType : %{public}lld
%s context : %{public}@
%s invalid context
%s SessionInfoProvidingDelegate messageType : %{public}lld
%s Received notificationInfo %{public}@
%s Failed to parse notificationInfo from raw data
%s Smart Siri Volume not supported on this platform - Bailing out
%s ERR: Failed to initialize Smart Siri Volume with sampling %{public}f and %{public}@
%s AlarmState changed to %{public}d
%s TimerState changed to %{public}d
%s MusicVolume changed to %{public}f
%s AlarmVolume changed to %{public}f
%s Automatic Volume State changed to %{public}d
%s Audio file already configured, closing first
%s Creating audio file at URL %{public}@
%s Closing file at URL %{public}@, audio size: %{public}u
%s Couldn't create CoreSpeech log directory at path %{public}@ %{public}@
%s Received notification %@
%s Failed to register for notification %@ (status=%d)
%s SmartSiriVolumeContextAware TTS volume post lower and upper bounds is: %f
%s TTS volume offset post lower and upper bounds is: %{public}f
%s _csAssetsDictionary = %{public}@
%s CSAssetController cannot query for nil language
%s ::: found %{public}lu installed assets for assetType=%{public}lu, matching query: %{public}@
%s Error running asset-query for assetType:%{public}lu, query: %{public}@, error: %{public}lu
%s ::: found %{public}lu assets for assetType=%{public}lu, matching query: %{public}@
%s Asset state : %{public}ld
%s ::: %{public}s
%s ::: %{public}s; query: %{public}@
%s Found %{public}lu assets
%s Error running asset query: error %{public}lu, or result is empty
%s ::: Request Fetching RemoteMetaData : assetType : %{public}d
%s Fetching remote meta data failed, scheduled retry after %{public}f seconds
%s ::: Request fetching remote asset
%s ::: found %{public}lu assets for assetType %{public}lu
%s Failed to finish query for assetType %{public}lu with error %{public}lu
%s Meta data downloaded successfully for assetType %{public}lu
%s Failed to download meta data for assetType %{public}lu with error %{public}lu
%s ::: Fetching remote asset
%s ::: Purging installed asset : %{public}@
%s ::: Request downloading remote asset for assetType %{public}lu
%s ::: Start downloading asset
%s ::: download progress: %{public}3.0f%%
%s ::: Error downloading from %{public}@ with error %{public}@
%s ::: download completed successfully from %{public}@.
%s Attempting to download asset %{public}@, asset state : %{public}ld
%s ERR: Unknown AssetType: %{public}lu
%s Transcriber trigger token list: %{public}@
%s Initializing Quasar with config: %{public}@
%s Failed initialization in _EARSyncSpeechRecognizer initWithConfiguration
%s ERR: Exception initializing _EARSyncSpeechRecognizer: %{public}s
%s Speech model loading took %{public}.3fms
%s endAudio failed
%s processAudioChunk failed
%s MpVT: phId=%{public}@, tok=%{public}@
%s Res-%lu: 
%s tok=%@
%s Overriding Myriad state as request was made during a phone call
%s Invoked Siri client
%s Cannot invoke Siri client : %{public}@
%s Cannot notify wake keyword spoken event : %{public}@
%s AFSiriActivationCarPlayDeviceVoiceTriggerPrewarm success
%s AFSiriActivationCarPlayDeviceVoiceTriggerPrewarm failed : %{public}@
%s Invoked Siri client for voice trigger from Jarvis
%s Cannot invoke Siri client for voice trigger from Jarvis : %{public}@
%s SiriActivationConnection deactivated due to %ld
%s SmartSiriVolume cannot be resumed since Siri is speaking
%s Dealloc CSAudioInjectionEngineRemoraEngine : %@
%s Cannot create de-interleaver using AudioConverterNew: %{public}d
%s Created de-interleaver
%s Stopping AudioInjectionEngine : %@
%s Failed to open audio file %@, error : %d
%s Streaming from %@
%s Cannot speak nil Audio URL
%s Cannot speak since audio file does not exists : %@
%s Calling stopAudioStream
%s Failed to deinterleave the data: %{public}d
%s Compensating %{public}u channel(s), heartbeat = %{public}lld
%s ::: Error creating output file %{public}@, err: %{public}d
%s ::: Error writing to output wave file. : %{public}ld
%s Invalid FTM config read from configFile %{public}@ for task %{public}@
%s Reading config from: %{public}@ for task %{public}@
%s Configured recording types: %{public}lu
%s Thresholds read: %{public}@
%s Shadow Mode: %{public}d
%s Received start request for record type: %{public}@, supportedRecordTypes: %{public}lx taskName %{public}@
%s Sending previous result request now !
%s Unable to create progressive checker with error:%{public}@
%s Unable to create progressive checker context with error:%{public}@
%s Created SLProgressiveCheckerAnalyzer %{public}@ with context %{public}@
%s Session not in progress, ignoring audio
%s CSAcousticProxy has received %{public}d samples, heartbeat = %{public}lld
%s Siri session ended, stoping acoustic checker
%s Cancelling Siri request, score: %{public}.3f, threshold: %{public}.3f
%s Assistant audio log not available
%s Error writing out AcousticSL info meta: %{public}@
%s Saving AcousticSL results at %{public}@
%s Submitting AcousticFTM analytics: %@
%s Invalid Analyzer: %{public}@
%s FINAL: Analyzed samples: %lu, score: %f didMitigate: %d
%s PARTIAL: Analyzed samples: %lu, score: %f didMitigate: %d
%s VoiceTrigger cannot be turned on since SpeechDetectionVAD is not present
%s VoiceTrigger cannot be turned on since voiceTriggerInCoreSpeech is NO
%s VoiceTrigger cannot be turned on since VoiceTrigger is disabled
%s VoiceTrigger cannot be turned on since Siri is disabled
%s VoiceTrigger cannot be turned on since SpringBoard is not started yet
%s VoiceTrigger cannot be turned on since device is not unlocked after restart
%s VoiceTrigger cannot be turned on since device is on battery
%s VoiceTrigger cannot be turned on since Siri is restricted on lock screen
%s VoiceTrigger cannot be turned on since Software Update Checking is running
%s VoiceTrigger cannot be turned on since we are in a connected or outgoing call
%s Successfully ? %{public}@
%s Notify release of audio session
%s Start monitoring : speech endpoint asset meta update
%s Stop monitoring : speech endpoint asset meta update
%s New speech endpoint asset is available
%s Cannot get a VoiceTrigger asset : %{public}@
%s CSVoiceTriggerAsset found: %{public}@
%s Asset Query failed : %{public}@
%s cached asset:%{public}@, new asset:%{public}@
%s New asset is same as cached asset, ignore notification
%s New asset is different from cached one. Updating cached asset
%s new VoiceTrigger asset downloaded
%s Language Code Changed : %{public}@
%s First unlock notification received : %{public}d
%s Turn on AP mode since device is hands free state
%s CommandControl Streaming = %{public}d
%s Turn on AP mode since command control is streaming
%s VoiceTrigger AOP mode cannot be turned on since builtIn speaker is active
%s AudioRecordContext = %{public}@, recordState = RECORDING
%s CarPlay is connected, we will still run AOP mode
%s hypotheticalRoute = %{public}@
%s Audio route changing to HFP is expected
%s VoiceTrigger AOP mode cannot be turned on since Siri client is recording
%s AOP Listening is disabled
%s Turn on AP mode since siri is in attending state
%s Turn on AP mode since device is on the ringtone state
%s Speech Detection VAD is not available, we will still running in AOP mode
%s Will notify Siri Client record state change to STOPPED in %{public}f seconds, eventUUID = %{public}@
%s Notifying Siri Client record state change to STOPPED, eventUUID = %{public}@
%s There is no pending event to timeout : pendingRecordingStopUUID = %{public}@, timeoutTargetUUID = %{public}@
%s ::: incrementing false wakeup to %{public}llu
%s PowerLog : HeySiriFalseTrigger numFalseWakeUp:%{public}d, secondsSinceLastReport:%{public}lf
%s ::: accumulated false wakeup count is %{public}llu so far, not reporting yet because it has been only %{public}.2f seconds since last report
%s Sending event with non determenistic triggerLengthSampleCount %llu, triggerLengthSampleCountDetermenisticFromFirstPass %llu, and delta of %lld samples
%s %p speechRecordingMode = %zd, clientConfiguration = %@
%s %p speechRequestOptions = %@, currentActivationInfo = %@
%s activeMediaPlaybackVolume = %f
%s clientConfiguration = %@
%s recordRoute = %@, playbackRoute = %@
%s Requesting historical buffer of duration %lf seconds
%s recordRoute = %@, playbackRoute = %@, attemptsToUsePastDataBufferFrames = %d
%s alertBehavior = %@
%s AppleTV (isVoiceOverTouchEnabledInAccessibility = %d)
%s HomePod
%s BT Voice trigger during incoming/active phone call
%s Built-in Voice
%s Triggerless
%s CarPlay Button Press (recordRoute = %@)
%s Bluetooth Voice Trigger
%s Bluetooth Direct Trigger
%s Car DoNotDisturb
%s VoiceOver Enabled (activationMode = %.4s, speechEvent = %ld (%@), recordRoute = %@)
%s Accessibility Vibration Disabled (activationMode = %.4s, speechEvent = %ld (%@), recordRoute = %@)
%s Overriding default behavior, playing beep because of custom sound ID
%s Playback Route is Hands-Free (activationMode = %.4s, speechEvent = %ld (%@), recordRoute = %@)
%s No Vibration Support
%s Others (activationMode = %.4s, speechEvent = %ld (%@), recordRoute = %@)
%s Others (deviceRingerSwitchState = %ld (%@))
%s alertStyle = %ld
%s targetDate = %@ (%f)
%s timeInterval = %f
%s voiceTriggerEndHostTime = %llu
%s buttonDownHostTime = %llu
%s activationHostTime = %llu
%s activationSystemUptime = %f
%s date = %@ (%f)
%s Overriding default behavior to play beep because of custom sound ID
%s Voice Feedback -> PresentationModeVoice
%s Voice Feedback -> PresentationModeSilent
%s Voice Feedback -> Control with Ring Switch (deviceRingerSwitchState = %ld (%@))
%s Voice Feedback -> Always On
%s Voice Feedback -> Hands-Free Only
%s Voice Feedback -> Unknown
%s audioSessionActiveDelay = %@ (Triggerless Listening)
%s audioSessionActiveDelay = %@ (Audio Session Coordination)
%s audioSessionActiveDelay = %@ (User Perception)
%s isOnPhoneCall = %d
%s audioSessionActiveDelay = %@ (Horseman Voice)
%s audioSessionActiveDelay = %@ (ATV Remote)
%s audioSessionActiveDelay = %@ (Hearst Voice)
%s audioSessionActiveDelay = %@ (Others)
%s audioSessionActiveDelay = %@
%s mediaPlaybackVolumeThreshold = %@
%s audioSessionActiveDelay = %@ (Above Media Playback Volume Threshold)
%s audioSessionActiveDelay = %@ (Default)
%s Overriding mode to %ld. This should only be used for testing.
%s WARN: Invalid sigType: %lu
%s Unknown DataSrc Type: %{public}lu
%s Unknown DataSrcTypeStr(%{public}@)
%s Failed to create dir at: %{public}@
%s Json file doesnt exist at: %{public}@
%s Could not read Json file at: %{public}@, err: %{public}@
%s Failed to parse json at: %{public}@, err: %{public}@
%s Could not find <%{public}@> in Keypath=%{public}@
%s Record route to verify = %{public}@
%s Record route = %{public}@, playback route = %{public}@
%s Device endpointType = %{public}lu
%s Creating audio player...
%s Failed to create audio player due to error %@.
%s Created audio player %@ with audio session %@.
%s Reused audio player %@ with audio session %@.
%s Audio player %@ is already prepared to play.
%s Preparing audio player %@ to play...
%s Failed to prepare audio player %@ to play.
%s Prepared audio player %@ to play.
%s request = %@
%s Ignored because the session is already active.
%s Ignored because the audio player is already playing.
%s Asking audio player %@ to play...
%s Failed to play audio player %@.
%s Started playing audio player %@.
%s request = %@, immediately = %d
%s Stopping audio player...
%s Ignored because there's no audio player to stop.
%s _request = %@
%s Ignored because there's no audio player to pause.
%s _request = %@, shouldResume = %d
%s Ignored because there's no audio player to resume playing.
%s request = %@, error = %@
%s Ignored because there's no audio player to destroy.
%s request = %@, player = %@, success = %d
%s request = %@, player = %@, error = %@
%s ::: %{public}s enable: %{public}d reason: %{public}@ timestamp : %{public}lf
%s Ignoring request to enable/disable voice trigger with nil reason.
%s ::: Asserting that VoiceTrigger should be %{public}@ with reason: %{public}@. Existing assertions (%{public}lu): %{public}@; times: %{public}@ vs %{public}f
%s Ignoring request to enable/disable voice trigger - time order violation.
%s ::: Ignore request as phraseSpotter already %{public}@
%s ::: Asserting that PhraseSpotter should be %{public}@, timeout: %{public}f
%s ::: Timeout!! PhraseSpotter should be NOT bypassed
%s ::: Ignore request as raiseToSpeak already %{public}@
%s ::: Asserting that raiseToSpeak should be %{public}@, timeout: %{public}f
%s ::: Timeout!! raiseToSpeak should be NOT bypassed
%s HandleDisconnect
%s ERR: Failed to get TTS Volume
%s Estimated TTS volume : %{public}f
%s SmartSiriVolume not available
%s Notifying SSV Client on Volume change for reason - %{public}d
%s Dropped SSV Client notification for Volume change with reason - %{public}d
%s Non internal build, Ignoring command %@ from peerId %@ - Bailing out!
%s Received Malformed command %@ from peerId %@ - Bailing out!
%s Command %@ received from peerId %@
%s Unknown Command: (%@) - Ignoring
%s Triggering sync with peer - %@
%s Triggering nearmiss sync with peer - %@
%s Triggering voice profile sync with peer - %@
%s Triggering acoustic data sync with peer - %@
%s CSP2P_RemoteHeySiriCmd: ENABLE HeySiri: Not Implemented Yet: 
%s CSP2P_RemoteHeySiriCmd: DISABLE HeySiri: Not Implemented Yet: 
%s Cannot read contents of directory: %@, err: %@
%s Could not determine if [%@] is a directory or not. Err=%@
%s Found dir: %@. Skipping compression
%s _compressFilesInDirectory: Malloc failed for file %@ (%lu) - Discarding
%s _compressFilesInDirectory: Compression failed for file %@ (%lu) - Sending Uncompressed
%s _compressFilesInDirectory: File %@ compressed from %ld to %ld 
%s Failed in compressing %{public}@ with errror %{public}@ - Bailing out
%s Transfering NearMiss file %@ withCompression %{public}@ and size %ld in batch %{public}@
%s Transfering grading file %@ withCompression %{public}@ and size %ld in batch %{public}@
%s %@ is nil - Bailing out
%s Failed in transporting Voice file %@ with reponse: %@, error %@
%s Failed to remove the file %@ with error %@
%s Failed to move the file %@ to %@ with error %@
%s CSP2P_VoiceProfileParallelRecordingTransferCmd: received malformed command - %@ %@ %@
%s CSP2P_VoiceProfileParallelRecordingTransferCmd: unknown IDS peer with passed Identifier %@, %@ %@
%s CSP2P_VoiceProfileParallelRecordingTransferCmd: received malformed command - %@
%s CSP2P_VoiceProfileParallelRecordingTransferCmd: Creating directory failed with error %@
%s Ignoring sync of existing file %@ from %@
%s Syncing parallel recorded audio file - %@ from %@
%s Uncompressed file %@ sent by peer %@
%s ERR: Failed to allocate buffer of size %zu, bailing out
%s Writing to file(%@) failed!. Err=%@
%s received malformed command - %@ %@ %@
%s unknown IDS peer with passed Identifier %@, %@ %@
%s received malformed command - %@
%s Syncing audio file - %@ from %@
%s CSP2P_VoiceProfileTransferCmd: received malformed command - %@ %@ %@
%s CSP2P_VoiceProfileTransferCmd: received malformed command: CSP2P_VoiceProfileData_Key: %@CSP2P_VoiceProfileFileName_Key: %@CSP2P_VoiceProfileSpeakerName_Key: %@CSP2P_VoiceProfileLocale_Key: %@CSP2P_VoiceProfileDataType_Key: %@CSP2P_VoiceProfileTotalSegments_Key: %@CSP2P_VoiceProfileSegment_Key: %@
%s CSP2P_VoiceProfileTransferCmd: Received VoiceProfile Segment (%@/%@) from peerId %@
%s CSP2P_VoiceProfileTransferCmd: Failed to delete the directory %@ with error %@
%s CSP2P_VoiceProfileTransferCmd: received VoiceProfileSegment %@, expected %d
%s CSP2P_VoiceProfileTransferCmd: Creating directory failed with error %@
%s CSP2P_VoiceProfileTransferCmd: Writing to file failed!!!
%s Received request to delete VoiceProfile %@ from peerId %@
%s Cannot send data across when _adCompanionServiceProvider is nil - returning
%s ERR: Rejecting command %@ sent to non Horseman device
%s ERR: received malformed command - %@ %@
%s ERR: unknown IDS peer with passed Identifier %@, %@ %@
%s ERR: received malformed command with locale nil - %@
%s Fetching homeUserId for siriProfileId %{public}@
%s siriProfileId %{public}@ maps to homeUserId %{public}@
%s ERR: Home User Id erred %{public}@ for Siri Profile Id %{private}@
%s ERR: %@
%s ERR: received malformed command with profileId nil - %@
%s ERR: Failed to find voice profile with identifier - %@
%s CSP2P_VoiceProfileFetchCmd: Transferring voice profile %{public}@
%s CSP2P_VoiceProfileFetchCmd: File %@ isCompressed: %d, compressedSize: %ld, err: %@
%s CSP2P_VoiceProfileReverseTransferCmd: Failed VoiceProfileTransfer: %@, error %@
%s CSP2P_VoiceProfileReverseTransferCmd: Successfully transferred %@
%s CSP2P_VoiceProfileReverseTransferCmd: Failed transferring voice profile %@ with error %@
%s CSP2P_VoiceProfileReverseTransferCmd: Successfully transferred voice profile %@
%s ERR: Rejecting command %@ sent to Horseman device
%s ERR: received malformed command with relative path nil - %@
%s Failed in sending trigger for Voice profile update to peer %@ with error %@
%s SpkrId:: path is nil - Bailing out
%s SpkrId:: Direntry with same name exists, this will be removed: %@
%s SpkrId:: Creating Directory : %@
%s SpkrId:: Creating Directory failed : %@
%s Error reading directory at %@: err: %@
%s %@ is empty
%s zeroFilterWinSz: %{public}tu, numHostTicksPerAudioSample: %{public}f
%s _vtEndInSampleCount:%{public}ld, _numSamplesProcessed: %{public}ld, voiceTriggerInfo: %{public}@
%s Registering for post build install/first unlock activity - %s
%s Received event for XPC activity: %@ in state: %ld
%s XPC activity: %@ deferred: %@ firstUnlock: %@
%s Registered XPC activity got triggered...
%s VT is disabled, skipping post build activity !
%s Post build install/first unlock tasks got completed with error - %{public}@
%s Registered XPC activity complete. State: %@.
%s UUID was nil will not start fingerprint provider
%s Updated in use services for fingerprintProvider. %lu services in use
%s Starting continuousFingerprintProvider
%s UUID was nil will not stop fingerprint provider
%s Updated in use services for fingerprintProvider. %lu services remaining
%s Stopping continuousFingerprintProvider
%s listen polling has failed : %{public}@
%s Skip listen polling since audio is streaming / Siri disabled
%s Start audio stream successfully ? %{public}@, error : %{public}@
%s Received didStartRecording when Siri is off
%s Failed in requesting audio stream : %{public}@
%s Already started listen polling, skip
%s Failed to stop audio stream : %{public}@
%s No audio stream to stop, we shouldn't hit this
%s Siri enabled : %{public}d
%s stream stopped unexpectedly : %{public}ld
%s Mediaserverd/bridgeaudiod recovered from crash
%s NDAPI initialization failed
%s set StartAnalyzeSampleCount = %{public}lld
%s NDAPI config doesn't contain threshold_normal
%s NDAPI config doesn't contain threshold_logging
%s NDAPI config doesn't contain threshold_reject_logging
%s SmartSiriVolume: deleted %{public}u elements in energy buffer.
%s SmartSiriVolume: number of elements to delete exceeds energy buffer size, ignore.
%s SmartSiriVolume init value for noise estimation %{public}f
%s SmartSiriVolume init value for LKFS estimation %{public}f
%s SmartSiriVolume enable policy changed : %{public}@
%s SmartSiriVolume received MediaRemote initial state as %{public}@
%s SmartSiriVolume haven't got MediaRemote callback yet, let's assume media is playing.
%s SmartSiriVolume received alarm initial state as %{public}@
%s SmartSiriVolume received timer initial state as %{public}@
%s asset is nil, use default parameters(this should not happen).
%s SmartSiriVolume configure: %{public}@
%s SmartSiriVolume heartbeat = %{public}lld
%s SmartSiriVolume: estimated noise level %{public}f
%s SmartSiriVolume: estimated LKFS %{public}f
%s SmartSiriVolume: pause SSV calculation.
%s SmartSiriVolume: resume SSV calculation.
%s Siri is disabled, we shouldn't receive audio here, heartbeat = %{public}lld
%s SmartSiriVolume received VT event!
%s SmartSiriVolume remove samples from VT utterances by %{public}llu, with startAnalyzeSampleCount = %{public}llu, samplesFed = %{public}llu, triggerStartSampleCount = %{public}llu
%s SmartSiriVolume trying to delete too many VT samples, set triggerDurationToDelete to be limited max: %{public}llu
%s SmartSiriVolume got empty VT event!
%s SmartSiriVolume dismiss alarm firing as VoiceTrigger detected.
%s SmartSiriVolume dismiss timer firing as VoiceTrigger detected.
%s SmartSiriVolume: final estimated TTS volume in dB %{public}f
%s SmartSiriVolume: adjust TTS volume since alarm/timer is firing.
%s SmartSiriVolume: TTS volume in dB from noise %{public}f, from LKFS %{public}f, with user offset %{public}f
%s SmartSiriVolume: soft volume algorithm in use
%s SmartSiriVolume: pause LKFS calculation according to MediaRemote notification.
%s SmartSiriVolume: resume LKFS calculation according to MediaRemote notification.
%s SmartSiriVolume received unknown media playing state, let's assume media is playing.
%s SmartSiriVolume received unknown alarm state, let's reset alarm state.
%s SmartSiriVolume: alarm firing status = %@ according to MobileTimer notification.
%s SmartSiriVolume received unknown timer state, let's reset timer state.
%s SmartSiriVolume: timer firing status = %@ according to MobileTimer notification.
%s SmartSiriVolume dismiss alarm firing as Siri client is recording.
%s SmartSiriVolume dismiss timer firing as Siri client is recording.
%s SmartSiriVolume: set StartAnalyzeSampleCount = %{public}lld
%s SmartSiriVolume: final estimated TTS volume %{public}f with music volume %{public}f
%s Start monitoring : SACInfo
%s Stop monitoring : SACInfo
%s Device is in stereo mode : %{public}@
%s vibration state fetched from CFPreferences is NULL, using On as default value
%s ::: NVI logging initialized
%s Received external route change notification
%s Received CarPlay AuxStream support change notification
%s Received CarPlay connection change notification
%s Notifying Jarvis Connection State : %{public}d
%s Automatic Volume Toggled. Automatic Volume Enabled: %{public}d
%s No SACodec for settings %{public}@
%s Start monitoring : SpeakerRecognition Asset meta update
%s Stop monitoring : SpeakerRecognition Asset meta update
%s New Speaker Recognition asset metadata is available
%s VoiceTrigger is already %{public}@, received duplicated notification!
%s Start monitring : VoiceTrigger setting switch
%s Cannot start monitoring VoiceTrigger setting switch because it was already started
%s Stop monitring : VoiceTrigger setting switch
%s VoiceTrigger enabled = %{public}@
%s endpointerModelVersion is still nil after fetching it from EAREndpointer
%s Updated endpointer threshold: %{public}f
%s Updated endpointer delayed trigger: %{public}d
%s setEndpointerOperationMode : %{public}d
%s current EndpointerOperationMode : %{public}d
%s update endpointer threshold to %{public}f for task %{public}@
%s EARSPG: CSServerEndpointFeatures: %{public}@
%s Accepting RC: RCTime < 0: Server's processedAudioDuration(%{public}f) > _lastReportedEndpointTimeMs(%{public}f): sfLatency: %{public}f, rcTimeMs: %{public}f
%s Rejecting RC: SFLatency < 0: Server's processedAudioDuration(%{public}f): _lastReportedEndpointTimeMs(%{public}f): sfLatency: %{public}f, rcTimeMs: %{public}f
%s rcEpFeatures: %{public}@ shouldAccept: %{public}d
%s first audio buffer host time: %{public}llu
%s HEP::RecordingDidStop: Ignoring silenceScoreEstimateAvailable, Not queuing
%s Detected speech start at %{public}f of effectiveClientProcessedAudioMs
%s HEP::RecordingDidStop: Ignoring silenceScoreEstimateAvailable
%s Already communicated end-pt: Not Invoking hybridClassifier for silposnf=%{public}f
%s ClientLag: serverProcessedAudioMs(%{public}ld) > effectiveClientProcessedAudioMs(%{public}f)
%s ClientLag: Not invoking HybridClassifier: sfLatency > clientLagThreshold: %{public}f > %{public}f
%s ClientLag: Using DefaultServerFeatures with disconnected-state sfLatency: %{public}f
%s ClientLag: Using ServerFeatures with ClampedSFLatency: %{public}f
%s Using ServerFeatures with ClampedSFLatency
%s ClientLag: Not Invoking HybridClassifier as serverProcessedAudioMs > effectiveClientProcessedAudioMs
%s HEP.feats: [%{public}ld,%{public}f,%{public}f,%{public}ld,%{public}f,%{public}f] & [(%{public}@),%{public}f] @ %{public}lu [%{public}f, %{public}d]
%s HEP.posterior=%{public}f, result=1, endpointedBuffer.hostTime=%{public}llu isAnchorTimeBuffered=%{public}d
%s request timeout with features %{public}@
%s ServerFeaturesLatencyDistribution: %{public}@ additionalMetrics: %{public}@
%s MMEP:: HEP detected at %{public}f but will continue running for MMEP.
%s Already communicated end-pt: Not scheduling work for hybridClassifierQueue for silposnf=%{public}f
%s Log hybrid endpointer features for event: %{public}@, and locale: %{public}@
%s triggerEndSeconds: %{public}f, _vtEndInSampleCount: %{public}lu, _vtExtraAudioAtStartInMs: %{public}lu,  _hepAudioOriginInMs: %{public}f, voiceTriggerInfo: %{public}@,
%s CSHybridEndpointer recordingStoppedForReason: %{public}ld
%s sampleRate=%{public}lu, recordContext=%{public}@
%s CSEndpointAsset exists: %{public}@
%s No asset for CSHybridEndpointer for currentLanguage: %{public}@. Fallback to VAD2
%s Created HybridClassifier(%{public}@); canProcessCurrentRequest after reset: %{public}d,for sampleRate: %{public}lu, lang=%{public}@, version=%{public}@
%s HEP.logs.hdr: [ServerASR_trailingSilenceDuration,ClientSPG_SilenceFramesCountMs,ServerASR_endOfSentenceLikelihood,ServerASR_wordCount,ServerFeaturesLatency,ClientSPG_SilenceProbabilityHMMFiltered] & [ServerASR_pauseCounts,ServerASR_silencePosterior,ClientSPG_silenceProbailitySPGRaw] @ effectiveClientProcessedAudioMs : [HEPPosteriorOut,HEPDecision]
%s csHepConfig: %{public}@
%s _clientHepConfig: %{public}f, _clampedSFLatencyForClientLag: %{public}f, _useDefaultServerFeaturesOnClientLag: %{public}d, _extraDelayFrequency: %{public}lu, _taskThresholdMap: %{public}@
%s update assets to: %@
%s %{public}@ doesnt exist
%s Could not read: %{public}@
%s Could not decode contents of: %{public}@: err: %{public}@
%s Start monitoring : Siri setting switch, Siri is %{public}@
%s Stop monitoring : Siri setting switch
%s Siri Enabled = %{public}@
%s Start audio stream successfully ? %{public}@, error : %{public}@, startRecordingSampleCount=%lu
%s Stopped audioStream with result=%d, err=%@
%s audioProvider == nil, error : %{public}@
%s provider: %{public}@, unexpectedStop: %{public}ld
%s Device is firstUnlocked. Fetching HEP assets
%s Device is NOT firstUnlocked. Will fetch assets after firstUnlock
%s Language changed to: %{public}@
%s New hybrid endpoint asset downloaded
%s FirstUnlock notification received: %{public}d
%s elapsed time to get HEP assets: %{public}lf
%s Failed to get HEP asset
%s HEP Asset: %{public}@, path: %{public}@
%s installationString: %@, for language: %@
%s File not exist: %{public}@
%s endpointAsset: %{public}@, osdAsset: %{public}@
%s _bestStartDetectSample %lu was greater than _bestEarlyDetectSample %lu or _bestEndDetectSample %lu
%s _bestEarlyDetectSample %lu was greater than _bestEndDetectSample %lu
%s _speechVoiceLevel %lu is 0
%s _numberOfTotalFramesETFT %lu is 0
%s _requestMHUUID: %{public}@, _turnIdentifier: %{public}@
%s _userSpeakingStartedTimeInMs %{public}f, _userSpeakingEndedTimeInMs: %{public}f, _userSpeakingStartedHostTime: %{public}llu, _userSpeakingEndedHostTime: %{public}llu, _stopRecordingHostTime: %{public}llu, _endpointBufferHostTime: %{public}llu
%s Received Activation Event : %{public}@
%s Cannot handle activation event : %{public}@
%s activation client not exist
%s Start monitoring : Siri language code
%s Stop monitoring : Siri language code
%s Siri language changed to : %{public}@
%s Ignore notifying change of language code, since it is nil
%s Error reading audio file: %{public}d, skipping...
%s Start monitoring : Software update checking state
%s Cannot start monitoring software update checking state because it was already started
%s Stop monitoring : Software update checking state
%s Software update checking running : %{public}@
%s AssetManager cannot be turned on since isFirstUnlocked is NO
%s AssetManager cannot be turned on since network is not available
%s Start monitoring : VoiceTrigger Asset meta update
%s Stop monitoring : VoiceTrigger Asset meta update
%s New VoiceTrigger asset metadata is available
%s Replace deviceId(%{public}@) to nil for VoiceTrigger from Gibraltar.
%s Queue %@ is already being observed.
%s queue = %@
%s queue = %@, numberOfOccurrences = %tu
%s Could NOT copyFrom: %{public}lu to: %{public}lu, retSampleCount: %{public}lu
%s Invalid request: reqStartSample=%{public}lu, reqEndSample=%{public}lu, oldestSampleInBuffer: %{public}lu, latestSampleInBuffer=%{public}lu
%s Start monitoring : AdBlocker Asset meta update
%s Stop monitoring : AdBlocker Asset meta update
%s New AdBlocker asset metadata is available
%s stream %{public}@ initialized
%s stream %{public}@ is deallocated
%s Creating UUID for start audio stream request : %{public}@
%s AudioStream<%{public}@> is streaming : %{public}d
%s AudioStream<%{public}@> has received didStopStreamUnexpectly
%s AudioStream<%{public}@> has received didHardwareConfigurationChange
%s Input route changed
%s Output route changed
%s Failed getting audio property %{public}.4s %{public}d
%s Failed getting audio property size %{public}.4s %d{public}
%s Failed registering for property listener %{public}.4s %{public}d
%s Found pending activation : %{public}@, handle pending activation immediately
%s Received Activation Event in CoreSpeechDaemon: %{public}@
%s Returning error for already existing pending activation event : %{public}@
%s No delegate registered : Postpone activation event handling until we have delegate registered
%s Pending Timeout fired for %{public}@ returning error for timeout
%s There is no pending activation event to timeout
%s corespeechd received mediaserverd launched event
%s Start monitoring : AOP First Pass trigger
%s Stop monitoring : AOP First Pass trigger
%s Received a request for VoiceTrigger Asset for language code : %{public}@
%s Fake Model Path does not exist : %{public}@
%s fake model meta json does not exist : %{public}@
%s Unable to read fake model meta json : %{public}@
%s Unable to parse fake model meta json : %{public}@
%s Loading FakeModel : %{public}@
%s Cannot create RTModel from %{public}@
%s fake model number(%{public}d) is less than minimum fake model number((%{public}d)
%s Using fake model for the first time : %{public}@
%s Using fake model : %{public}@
%s %{public}@ fake model is selected for download
%s %{public}@ model is selected for fallback
%s Received a request for VoiceTriggerRTModel %{public}@ Firmware Version : %{public}d.%{public}d
%s Asking mobile asset with currentLanguageCode = %{public}@
%s DownloadModel : 
%s preinstalledModels : 
%s Hearst Fake Model request switch turned on, executing stress test mode with fakeModelPath : %{public}@
%s VoiceTriggerAsset is not available : %{public}@
%s rtLocaleMap is nil fallback to embedded locale map
%s accessoryRTBlobs are not available for the version(%{public}d.%{public}d) and locale:%{public}@, returning fallback model : %{public}@
%s Hash matched with downloadedModel : %{public}@, accessory will select this model
%s Hash matched with preinstalledModel : %{public}@, accessory will select this model
%s Ask for download : %{public}@, and use %{public}@ as fallback
%s Select keyword language as %{public}@, error : %{public}@
%s Language list and jarvis language not provided
%s current Siri language code : %{public}@
%s Jarvis locale map is nil, fallback to embedded locale map
%s Start monitoring : Setting preference change
%s Stop monitoring : Setting preference change
%s Siri restricted on lock screen : %{public}@
%s Initializing CSRawAudioInjectionProvider
%s Done initializing CSRawAudioInjectionProvider
%s Dealloc CSRawAudioInjectionProvider
%s Calling StreamId for : %@
%s Calling prepare
%s Calling start audio stream : %@
%s Calling stop audio stream
%s Calling isRecording
%s Calling prewarm
%s Calling activate audio session
%s Start monitoring : Springboard start
%s Cannot start monitoring Springboard start because it was already started
%s Stop monitoring : Springboard start
%s SpringBoard started = %{public}@
%s CSAudioProvider is deallocated
%s CSAudioProvider[%{public}@]:StreamState changed from : %{public}@ to : %{public}@
%s CSAudioProvider[%{public}@]:Setting audioRecorder : %{public}p
%s CSAudioProvider[%{public}@]:setCurrentContext : %{public}@
%s CSAudioProvider[%{public}@]:Cannot change context since audio recorder is currently recording
%s CSAudioProvider[%{public}@]:audioStreamWithRequest for stream <%{public}@>
%s Failed to _prepareAudioStreamSync : %{public}@
%s CSAudioProvider[%{public}@]:Prepare audio stream reuqested while state is %{public}@
%s CSAudioProvider[%{public}@]:Cannot prepare, audio system is recovering
%s CSAudioProvider[%{public}@]:Asking AudioRecorder prepareAudioStreamRecord
%s CSAudioProvider[%{public}@]:prepareAudioStreamRecord failed : %{public}@
%s CSAudioProvider[%{public}@]:Create circular buffer
%s CSAudioProvider[%{public}@]:Tear down circular buffer
%s CSAudioProvider[%{public}@]:startAudioStream with stream : %{public}@ with stream state : %{public}@, option : %{public}@, streamId : %{public}llu
%s CSAudioProvider[%{public}@]:state was %{public}@, prepareAudioStream first
%s CSAudioProvider[%{public}@]:prepareAudioStreamSync with stream : %{public}@ with stream state : %{public}@, request : %{public}@
%s CSAudioProvider[%{public}@]:prepareAudioStream with stream : %{public}@ with stream state : %{public}@
%s CSAudioProvider[%{public}@]:Cannot handle start audio stream on : %{public}@
%s CSAudioProvider[%{public}@]:Cannot startAudioStream, audio system is recovering
%s CSAudioProvider[%{public}@]:Requested startHostTime = %{public}llu, _clientStartSampleCount = %{public}tu
%s CSAudioProvider[%{public}@]:%{public}@ is requesting earlier audio than asked, we can't deliver earlier audio
%s CSAudioProvider[%{public}@]:Set circularBufferStartHostTime = %{public}llu, circularBufferStartSampleCount = %{public}lu
%s CSAudioProvider[%{public}@]:Entering dispatch group for recordingWillStartGroup
%s CSAudioProvider[%{public}@]:Failed to fetch historical audio since _clientStartSampleCount is newer than audioBuffer sample count(%{public}llu)
%s CSAudioProvider[%{public}@]:Leaving dispatch group for recordingWillStartGroup
%s CSAudioProvider[%{public}@]:Received didStartRecording while %{public}@
%s CSAudioProvider[%{public}@]:Received didStopRecording reason : %{public}d, streamState : %{public}@
%s Calling unexpected didStop for all weak streams
%s CSAudioProvider[%{public}@]:Received didStopRecording while %{public}@
%s CSAudioProvider[%{public}@]:Waiting for recordingWillStartGroup before scheduling stopAudioStream
%s CSAudioProvider[%{public}@]:Scheduled stopAudioStream after waiting for recordingWillStartGroup - stopAudioStream %{public}@ with streamState : %{public}@
%s CSAudioProvider[%{public}@]:requested stop audio stream while stoppingWithScheduledStart, take out audio stream from schedule
%s CSAudioProvider[%{public}@]:Stream %{public}@ is not streaming on stream state : %{public}@, ignore the stopAudioStream request
%s CSAudioProvider[%{public}@]:Cannot handle stop audio stream on : %{public}@
%s CSAudioProvider[%{public}@]:requested stop audio stream while stopping, adding audio stream into stop pending
%s CSAudioProvider[%{public}@]:Stop all recordings, moving stream state to %{public}@
%s CSAudioProvider[%{public}@]:Failed to stop audioStream : %{public}@
%s Saving circular buffer from %{public}lu to %{public}lu
%s CSAudioProvider[%{public}@]:%{public}@ ask for audio hold stream for %{public}f
%s CSAudioProvider[%{public}@]:Timeout for %{public}@ has fired
%s CSAudioProvider[%{public}@]:Removing %{public}@ from stream holders
%s CSAudioProvider[%{public}@]:%{public}@ stream holder was already removed from stream holders
%s CSAudioProvider[%{public}@]:%{public}@ ask for cancel hold stream
%s Failed to prewarmAudioSessionWithError : %{public}@
%s Failed to activateAudioSessionWithReason: %{public}@
%s CSAudioProvider[%{public}@]:Activating Audio Session under : %{public}@
%s Failed to activateAudioSession : %{public}@
%s Failed to deactivate audio session : %{public}@
%s CSAudioProvider[%{public}@]:Deactivating Audio Session under : %{public}@
%s Failed to deactivateAudioSession : %{public}@
%s CSAudioProvider[%{public}@]:AVVC is recovering, ignore command...
%s Fetching voiceTriggerInfo locally for context type : %{public}lld
%s Fetching voiceTriggerInfo from audioRecorder
%s CSAudioProvider[%{public}@]:Cannot stopRecording as there are %{public}tu streamHolders
%s CSAudioProvider[%{public}@]:Shouldn't stop AVVC recording as there are %{public}tu streams
%s CSAudioProvider[%{public}@]:
%s CSAudioProvider[%{public}@]:Buffer underrun!!!!, lastForwardedSampleTime:%{public}lu, oldestSampleTimeInBuffer:%{public}lu, stream:%{public}@
%s CSAudioProvider[%{public}@]:Ignore forwarding stream %{public}@                                        the audio packets until sampleCount == %{public}lu (theMostRecentSampleCount:%{public}lu)
%s CSAudioProvider[%{public}@]:Buffer overrun!!! lastForwardedSampleTime:%{public}lu,                                    theMostRecentSampleCount:%{public}lu, stream:%{public}@
%s ScheduleAlertFinishTimeout : %{public}@
%s ScheduleAlertFinishTimeout will be ignored : %{public}@, %{public}@
%s Received finishStartAlertPlaybackAt:%{public}llu streamState : %{public}@
%s CSAudioProvider[%{public}@]:Requested alertFinishHostTime = %{public}llu, _clientStartSampleCount = %{public}tu, circularBufferSampleCount = %{public}tu
%s Audio Streaming already stopped
%s Will invalidate current builtIn audio stream : %{public}@
%s failed to stopAudioStream : %{public}@
%s CSAudioProvider[%{public}@]:Audio Recorder Disconnected
%s CSAudioProvider[%{public}@]:Mediaserverd/bridgeaudiod crashed
%s CSAudioProvider[%{public}@]:Mediaserverd/bridgeaudiod recovered from crash
%s CSAudioProvider[%{public}@]:AudioRecorder will be destroyed
%s CSAudioProvider[%{public}@]:recordingTransaction already released
%s CSAudioProvider[%{public}@]:Release recording transaction at streamState : %{public}@
%s Audio Packet Delivery WatchDog fired, trying to recover
%s Schedule didStart WDT %{public}@ for %{public}lf seconds
%s startRecordingWatchDogDidFire : %{public}@, currentToken : %{public}@
%s startRecordingWatchDogToken doesn't match. Ignore this WDT fire
%s Clearing didStartRecordingDelegate WatchDogTimer : %{public}@
%s Schedule didStop WDT %{public}@ for %{public}lf seconds
%s stopRecordingWatchDogDidFire : %{public}@, currentToken : %{public}@
%s stopRecordingWatchDogToken doesn't match. Ignore this WDT fire
%s Clearing didStopRecordingDelegate WatchDogTimer : %{public}@
%s Listening on watch cannot be turned on since speech detection VAD is disabled
%s Listening on watch cannot be turned on since Siri is disabled
%s Listening on watch cannot be turned on since SpringBoard is not started
%s Listening on watch cannot be turned on since device is not unlocked after restart
%s Hey Siri is enabled. Checking if we are in a call.
%s Hey Siri is disabled. Not checking if we are in a call.
%s Listening on watch cannot be turned on since Siri assertion is disabled and or its not in a ringtone state
%s Listening on watch cannot be turned on since audioInjection is enabled
%s Listening on watch cant be turned on because we are in a connected or outgoing call
%s xpc object should be XPC_TYPE_ARRAY
%s xpcObject value is NULL
%s Cannot decode non-plist types of XPC object
%s Cannot encode non-plist types into XPC object : %{public}@
%s Received AOP Listening state change notification : %{public}d
%s Error reading file
%s Version of AdBlockerAsset: %d
%s Send a In-Ear Myriad notification
%s Unsupported protocol for this device
%s HEP::RecordingDidStop: Ignoring processAudioSamplesAsynchronously: Not queueing
%s HEP::RecordingDidStop: Ignoring processAudioSamplesAsynchronously
%s addAudio first sample offset: %{public}lu
%s HEP.posterior=%{public}f, result=1, endpointedBuffer.hostTime=%{public}llu, isAnchorTimeBuffered=%{public}d
%s CSHybridEndpointAnalyzer recordingStoppedForReason: %{public}ld
%s Created OSDAnalyzer: %{public}@
%s _clientHepConfig: %{public}f, _clampedSFLatencyForClientLag: %{public}f, _useDefaultServerFeaturesOnClientLag: %{public}d
%s _currentAsset changed to : %{public}@
%s Session Query Failed : %{public}@
%s Mediaserverd/bridgeaudiod crashed
%s Start monitoring : AudioSessionInterruption
%s Start monitoring : AudioSessionRouteChangeNotification
%s Stop monitoring AudioSession activities
%s Endpointer is disabled in recordOption: %@
%s CSHybridEndpointer canProcessCurrentRequest
%s CSHybridEndpointer can-NOT-ProcessCurrentRequest, fallback  to NNVAD
%s _activeEndpointer=%{public}@
%s shouldUseCVT2ShotDecision: %{public}d, isWatchRTSTriggered=%{public}d
%s preheat
%s endpointer: %{public}@: didDetectStartpointAtTime: %{public}f
%s EP_PROXY::RecordingDidStop: Ignoring startPoint-reporting
%s EP_PROXY::RecordingDidStop: Ignoring didDetectHardpoint-reporting
%s %{public}@: Endpointer didDetectHardEndpointAtTime:withMetrics: %{public}f, CallingDelegate: %{public}@
%s WARN: endpointerModelVersion called when CSHybridEndpointer is not available
%s WARN: logEndpointFeatures called when CSHybridEndpointer is not available
%s %@
%s Detaching from session %p
%s Already attaching to session!
%s Attaching to session
%s Failed attaching to bt session %d
%s session = %p, result = %d
%s Session is NULL.
%s Failed getting default local device from session %p (result = %d).
%s Failed adding callbacks to local device %p from session %p (result = %d).
%s localDevice = %p, event = %d, result = %d
%s Failed getting default accessory manager from session %p (result = %d).
%s Failed adding callbacks to accessory manager %p from session %p (result = %d).
%s accessoryManager = %p, accessoryEvent = %d, device = %p, state = %d
%s Failed getting device address from string %d
%s Failed getting device from address %d
%s BTDevice %p for address %@
%s BTAccessoryManager %p
%s Failed getting device from deviceUID %d
%s BTDevice %p for deviceUID %@
%s BTLocalDevice %p
%s Loading device info for %@...
%s Loaded device info %@ for %@.
%s Using slow path...
%s Slow path took %f seconds.
%s Slow path timed out after 4 seconds.
%s Method not supported
%s Reloading device info for %@...
%s Reloaded device info %@ for %@.
%s deviceInfo = %@
%s deviceInfo changed from %@ to %@
%s Fetching device info for %@...
%s Fetched device info %@ for %@.
%s Getting BTDevice and BTAccessoryManager for %@...
%s Got BTDevice %p and BTAccessoryManager %p for %@.
%s Device UID and address of %@ are nil.
%s Data source of %@ is nil.
%s Failed getting BTDevice and BTAccessoryManager for %@.
%s Failed getting address from BTDevice %p (result = %d).
%s Failed getting vendor id and product id from BTDevice %p (result = %d).
%s Failed getting InEar capability from BTDevice %p via BTAccessoryManager %p (result = %d).
%s Failed getting DoAP capability from BTDevice %p via BTAccessoryManager %p (result = %d).
%s Failed getting ANC capability from BTDevice %p via BTAccessoryManager %p (result = %d).
%s Failed getting Transparency capability from BTDevice %p via BTAccessoryManager %p (result = %d).
%s Failed getting Software Volume capability from BTDevice %p via BTAccessoryManager %p (result = %d).
%s Failed getting Announce Messages capability from BTDevice %p via BTAccessoryManager %p (result = %d).
%s Failed getting Announce Calls capability from BTDevice %p via BTAccessoryManager %p (result = %d).
%s Asset available from CAT from: %{public}@
%s getCATXPCConnection Invalidated
%s Cannot create NSNumber if xpcObject is NULL
%s XPC object type should be BOOL, DOUBLE, INT64, or UINT64
%s Cannot create xpcObject if objcType is NULL
%s Cannot create xpcObject since there is no matching type
%s Stop monitoring : First unlock
%s PhraseSpotter enabled = %{public}@
%s PhraseSpotter is already %{public}@, received duplicated notification!
%s event = %{public}p client = %{public}p cannot handle event
%s ignore unknown types of message
%s message = %{public}p, client = %{public}p, cannot handle message
%s MessageType = %{public}lld
%s Received error %{public}@ from client %{public}@
%s Client %{public}p connection disconnected, noticing xpc listener
%s Cannot deactivateAudioSession since audio recorder doesn't exist
%s Cannot deactivateAudioSession with %{public}@
%s Setting sample rate to %d
%s Could not make Fingerprinter decoder: %{public}.4s
%s Error during conversion for fingerprinter %{public}.4s
%s Getting signature for duration %lf
%s Fingerprinter doesn't support rate %{public}ld
%s Set initial info as current %@.
%s Assign new MHUUID here to %@ (force = %@)
%s mode = %ld
%s endpointerOperationMode = %@, forceUpdate = %d
%s Ignored because endpointer operation mode is unspecified.
%s Ignored because endpointer operation mode can not be changed from %@ to %@.
%s Set Use Automatic Endpointing %d
%s Setting up recording alerts for Dictation.
%s Done setting recording alerts for Dictation.
%s Setting up recording alerts for Siri and other non-Dictation modes.
%s Done setting recording alerts for Siri and other non-Dictation modes.
%s Overriding record starting alert for IFD feature group one.
%s Done overriding record starting alert for IFD feature group one (soundURL = %@).
%s Failed overriding record starting alert for IFD feature group one.
%s Overriding record starting alert from override policy (soundID = %@).
%s Done overriding record starting alert from override policy (soundURL = %@).
%s Failed overriding record starting alert from override policy.
%s Trying to set record buffer duration to %lf
%s Failed setting record buffer duration. Duration is %{public}lf
%s Initalizing speech controller with context %@
%s Set pending info as current %@.
%s Done initializing voice controller
%s Preparing CSSpeechController with settings %@
%s Error setting up CSSpeechController %{public}@
%s Done preparing CSSpeechController
%s reason = %d, speechEvent = %zd (%@), hostTime = %llu
%s reason = %d, hostTime = %llu
StopRecording
%s Really stopping recording
UsefulUserFacingResults
%s Someone else has already asked to stop recording.%@
%s Sending stop recording immediately because CSSpeechController isn't recording
%s recordingState = %zd, context = %@
%s Playing alert %ld
%s Checked audio logging limits, count = %d -> %d
%s info = %@, context = %@
%s Created _audioFileWriter %@.
%s Did not create _audioFileWriter because audioFileType = %ld.
%s supportsVoiceIdentificationTraining = %d
%s supportsSpeechExtraction = %d
%s canGetPCMStream = %d
%s fileLoggingIsEnabled = %d
%s Created _audioLogggingFileWriter %@.
%s Did not create _audioLogggingFileWriter because fileLoggingIsEnabled = %d, canGetPCMStream = %d.
%s Configure _audioFileWriter, _audioLogggingFileWriter with recordSettings = %@.
%s Ask context %@ to configure and record with recordSettings = %@.
%s %ld
%s Prewarming audio session in speech controller
%s Done prewarm audio session in speech controller
%s Prewarming start alert
%s Failed to prewarm start alert due to %@
%s Done prewarming start alert
%s Preparing instead of preheating since we're not in the default mode
%s Preparing speech capture for %@
%s Using Bluetooth audio analyzer style
%s Using driving audio analyzer style
%s Using voice trigger audio analyzer style
%s Using default audio analyzer style
%s Suppressing start alert
%s Playing start alert %@
%s No SoundID URL
%s No start recording alert
%s Setting delayed start delay %lf
%s Asking CSSpeechController to startRecording with settings %@
StartRecording
%s Done asking CSSpeechController to startRecording
%s context = %@
%s Could not set up recording (prepared = %d, started = %d), returning error %{public}@%{public}@ and resetting voice controller.
%s Updated speech synthesis record from %@ to %@.
%s Fetching audio session ID...
%s Done fetching audio session ID %lu.
%s endpointerOperationMode = %@
%s Fingerprinting mode, force (endpointerOperationMode = %@).
%s Legacy property set (useAutomaticEndpointing = %d), override (endpointerOperationMode = %@)
%s info = %@, reason = %@
%s Dropping previous pending activation info %@ for reason %@.
%s Setting audio context %@ for reason %@.
%s Error setting audio context %@ for reason %@ error %{public}@. (%f seconds)
%s Done setting audio context %@ for reason %@. (%f seconds)
%s Ignored setting audio context because there's no speech controller.
%s Updating to post voice for reason %@.
%s Updating using pending info %@ for reason %@.
%s Attempting to release audio session while CSSpeechController is still recording.
%s releaseAudioSessionBehavior = %s
%s Resetting to default audio context on session end
%s %lf %lf
%s Endpointer setStartWaitTime is set to %{public}f
%s (event = %ld, suppressAlert = %d, hostTime = %llu)
%s (suppressAlert = %d)
%s Begin updating audio route info. (reason = %@, forcesUpdate = %d)
%s Fetching audio device info from CSSpeechController...
%s Done fetching audio device info %@ from CSSpeechController.
%s End updating audio route info. (reason = %@, forcesUpdate = %d, duration = %f)
%s Creating recording info (speechEvent = %ld (%@), audioAlertStyle = %ld, includeBTInfo = %d, includeRecordDeviceInfo = %d)
%s alertStartTime = %llu
%s Done creating recording info %@.
%s Got a speech start failure after we already got audio buffers?!
AudioStart
%s success = %d, error = %@
%s isTwoShot = %d
%s SPELLING recordSettings codec=%@
%s Sending speech did start to delegate %@
%s Resetting VoiceController on startRecording failure
%s reason = %ld, estimatedSpeechEndHostTime = %llu
%s Synthesizing a didStart callback, on missing didStart
AudioStop
%s reason = %ld, estimatedSpeechEndHostTime = %llu, errorCodeOverride = %ld, underlyingError = %@
%s Ignoring unexpected didStop callback while in state %ld
%s Starting new recording for two shot mode
%s Failed starting recording for two shot mode
%s audioMetrics = %@
%s Could not make Speex decoder: %{public}d
%s SPELLING Could not make Opus decoder: %{public}d
%s SPELLING Only expecting to get 1 Speex packet at a time, not %lu (isOpus %@)
%s SPELLING (isOpus %@) decoder gave us %d bytes bytes but we really only expected %d
%s SPELLING: Could not finish decoding for offline only mode: %d (isOpus %@)
RecordBufferAvailable
%s buffers.count = %llu, durationInSec = %f, bufferStartHostTime = %llu
RecordBufferHandleBegin
%s Dropped %f seconds of audio buffers recorded at %llu (%f seconds) due to audio recording restriction (accumulatedBufferDuration = %f seconds).
RecordBufferHandleEnd
%s firstBufferStartHostTime = %llu, firstBufferReceiptHostTime = %llu
%s Getting audio route instrumentation with recording info %@...
%s Done getting audio route instrumentation %@.
%s LPCM record buffer is empty.
%s reason = %zd, estimatedSpeechEndHostTime = %llu, isRecordingStopped = %d
%s Ignoring unexpected last buffer callback while in state %ld
%s Ignoring unexpected last buffer callback without first buffer.
%s %d
%s type = %ld, error = %@
%s type = %ld
%s alertPlaybackGroup is nil.
%s numberOfAVVCAlertPlaybacksByType does not have AVVC alert playbacks of type %ld.
%s numberOfAVVCAlertPlaybacksByType is nil.
%s isSiriMode=%d, speechEvent=%ld, wasRequestCancelled=%d, shouldSuppressAlert=%d, isMonitoringMyriadEvents=%d, didMyriadWin=%d
%s Explicitly playing %@ alert
%s BTLE Myriad Not explicitly playing speech stop alert
%s Not explicitly playing alert
%s Language detector is confident:%{private}d of the detected language:'%{private}@' with language code likelihood: %{private}@
%s time = %lf, wantsAudibleFeedback = %d
%s BTLE waiting for Myriad to finish
%s BTLE Myriad loss cancelled two shot feedback
%s BTLE speech controller began waiting for Myriad decision
%s BTLE speech controller end waiting for Myriad decision %lu
%s opType = %tu, reason = %tu
%s Unknown CSRequestOperationType (opType = %tu).
%s reason = %tu
%s time = %lf
%s Ignoring startpoint from stale CSEndpointAnalyzer
%s time = %lf, endpointerMetrics = %@
Endpoint
%s Ignoring hard endpoint from stale CSEndpointAnalyzer
%s Ignoring hard endpoint because (endpointTime = %f, firstBufferTimestamp = %f, mostRecentTTSEndTimestamp = %f, extendedSuppressDuration = %f).
EndpointHandled
SpeechRecorder
%s Overriding timeout and start point on timeout
%s promptType = %ld, time = %f
%s suppressesTwoShotAlert = %d
%s done
%s Fake two shot TTS prompt timed out (%@).
%s Fake two shot TTS prompt timeout is not handled due to context mismatch (fakeTwoShotPromptUUID = %@, _fakeTwoShotPromptUUID = %@).
%s Fake two shot TTS prompt called back (timestamp = %f, duration = %f, error = %@)
%s Fake two shot TTS prompt callback is not handled due to context mismatch (fakeTwoShotPromptUUID = %@, _fakeTwoShotPromptUUID = %@).
%s No endpoint yet, waiting
%s %lf
%s Eager results accepted: %d. Duration: %lf last duration: %lf
%s Got an enforce message without a current completion. Ignoring
%s timeout = %f
%s Done
%s Watchdog timer timed out.
%s duration %lf
%s Starting audio playback request %@...
%s Failed audio playback request %@ due to error %@.
%s Stopped audio playback request %@.
%s scores = %{private}@
%s userInfo = %@
%s Reuse existing session %@ from reusable session pool.
%s Create new session %@.
%s session = %@
%s session = %@, error = %@
%s Add successfully finalized session %@ to reusable session pool.
%s Evict %tu sessions from reusable session pool because %@.
%s Reusable session pool is already empty.
%s Start Of Speech Detector not supported !
%s Start monitoring : Mediaserverd crash / recover event
%s disconnect VoiceTriggerXPCClient
%s ERR: failed to get response !
%s Notifying CoreSpeechDaemon launched
%s Start monitoring : corespeechd state
%s Cannot start monitoring corespeechd state because it was already started
%s Stop monitoring : corespeechd state
%s CoreSpeechDaemon state changed to %{public}u
%s runRecognition failed
%s recognizeWavData failed
%s Partial result confidence: %{public}f
%s CTC: Adding tok=%{public}@
%s CTC: Ignoring tok=%{public}@
%s ERROR: %{public}s
%s CTC: Final-tok: %@(%f):%@
%s Final result confidence: %{public}f
%s EAR Token[%{public}lu]: %s (%{public}f)
%s network state notify key : %s
%s Start monitoring : network availability
%s Stop monitoring : network availability
%s Network availability changed
%s startListenWithOption : %{public}d, %{public}@
%s stopListenWithCompletion : %{public}d, %{public}@
%s hasRemoteVADAvailable : %d
%s hasVADAvailable : %d
%s didStopUnexpectly : %d
%s There is not audio buffer to convert. Skip this.
%s Got asked for %{public}u packets, have %{public}u
%s [%{public}02u of %{public}02u %{public}fs] Opus packet with %u bytes
%s %{public}d bytesConsumed from opus coverter, remains %{public}d bytes
%s Resetting AudioConverter buffer
%s createAudioConverter : initial frames per buffer = dur %{public}.2f * sr %{public}.2f = %{public}u
%s Failed to get audioConverter property (kAudioConverterCurrentOutputStreamDescription) : %{public}d
%s _configureAudioConverter: encoded audio needs minimum of %{public}u bytes per output buffer
%s _configureAudioConverter: AudioConverterGetProperty(kAudioConverterPropertyMinimumOutputBufferSize) returned status %{public}d
%s _configureAudioConverter: final framesPerBuffer: %{public}u
%s _configureAudioConverter: _convertPacketCount: %{public}u
%s _configureAudioConverter: AudioConverterGetProperty(MaximumOutputPacketSize): returned status %{public}d
%s createAudioConverter: outputSizePerPacket: %{public}u
%s _configureAudioConverter: _convertAudioCapacity %{public}u bytes
%s Cannot create AudioConverter using AudioConverterNew : %{public}u
%s Cannot set encoder bit rate : %{public}u
%s RequiredSampleCount reached: currSampleCount=%{public}lu, endingSampleCount=%{public}lu
%s Setting audio injection enabled : %d
%s Fetched audio injection enabled : %d
%s CSAudioInjectionServices Interrupted
%s CSAudioInjectionServices Invalidated
%s XPC connection not exist?
%s Request to create audio injection device type : %ld, deviceName : %@, deviceId : %@, productId : %@
%s Fetching primary device timed-out!!
%s Request to inject audio %@ to deviceUUID %@
%s Request to connect device with UUID %@
%s Connect device timed-out!!
%s Request to disconnect device with UUID %@
%s Disconnect device timed-out!!
%s Request to fetch primary device
%s xpc object should be XPC_TYPE_DICTIONARY
%s xpcObject key or value is NULL
%s Cannot encode key into xpcobject since the key is not NSString class type
%s MpVT: supportedPhrasesInfo: %@
%s MpVT: ctcResults=%@
%s OldTrigPh: %@, NewTrigPh: %@
%s Failed to create AVVC : %{public}@
%s Create new CSAudioRecorder = %{public}p
%s CSAudioRecorder %{public}p deallocated
%s AVVC initialization failed
%s Successfully create AVVC : %{public}p
%s Setting announced call flag to: %d with stream handle Id: %lu
%s Calling AVVC setContext : %@
%s Failed to get handle id : %{public}@
%s setContext elapsed time = %{public}lf, streamHandleId = %{public}lu, streamType = %{public}lu
%s Calling AVVC setContextForStream : %{public}@
%s Tried to setCurrentContext with mode %ld. This method can only be used for auto and post
%s setCurrentContext elapsed time = %{public}lf
%s Failed to prepare remote device : %{public}@
%s Calling AVVC prepareRecordForStream(%{public}llu) : %{public}@
%s AVVC prepareRecordForStream failed : %{public}@
%s prepareRecordForStream elapsed time = %{public}lf
%s ::: CSAudioRecord will inject audio file instead of recording
%s Resetting AudioFilePathIndex
%s Increase AudioFilePathIndex = %d
%s AudioFilePathIndex is out-of-boundary _audioFilePathIndex:%d injectAudioFilePaths:%d
%s AudioFilePathIndex:%d accessing:%@
%s Unable to find injectAudioFilePath = %@
%s Asking startRecording to remote device with context : %{public}@ (original context : %{public}@)
%s Failed to fetch valid context
%s Failed to startRecording : %{public}@
%s startRecordingWithOptions elapsed time = %{public}lf
%s Calling AVVC startRecordForStream : %{public}@
%s startRecordForStream failed : %{public}@
%s startRecordForStream elapsed time = %{public}lf
%s Failed to stopRecording to remoteRecordClient : %{public}@
%s stopRecording elapsed time = %{public}lf
%s Calling AVVC stopRecordForStream
%s Failed to stopRecordForStream : %{public}@
%s stopRecordForStream elapsed time = %{public}lf
%s Session State = %d
%s AudioSessionState = YES
%s AudioSessionState = NO
%s fetch recordDeviceInfo elapsed time = %{public}lf
%s fetch EndpointDeviceType elapsed time = %{public}lf
%s AVVC sampling rate = %{public}f
%s AVVC doesn't return sampleRate, assume it is default sample rate
%s isNarrowBand = NO for streamHandleId = %{public}lu
%s isNarrowBand = %{public}@ for streamHandleId = %{public}lu
%s Calling AVVC setSessionActive for Prewarm
%s Prewarm AudioSession has failed : %{public}@
%s Calling AVVC setRecordMode to mode : %{public}d
%s AVVC successfully setRecordMode
%s setRecordMode elapsed time = %{public}lf
%s Calling AVVC setSessionActivate for activation with streamId(%{public}lu)
%s AVVC setSessionActivate has failed : %{public}@
%s AVVC successfully activated audioSession
%s setSessionActivate elapsed time = %{public}lf
%s Calling AVVC setSessionActivate for deactivation : %{public}tu
%s Calling AVVC setSessionActivate for deactivation for stream %d: %{public}tu
%s Failed to setIamTheAssistant : %{public}@
%s Creating audio session with allow mixable audio while recording to YES
%s Failed to setAllowMixableAudioWhileRecording : %{public}@
%s Calling AVVC : Enable Smart Routing Consideration
%s Calling AVVC : Disable Smart Routing Consideration
%s enableSmartRoutingConsiderationForStream elapsed time = %{public}lf
%s Fail to setSmartRoutingConsideration : %{public}@
%s Calling AVVC setDuckOthersForStream(%d) for DuckOthers/MixWithOthers
%s Failed to setDuckOthersForStream : %{public}@
%s setDuckOthersForStream elapsed time = %{public}lf
%s Calling AVVC setDuckOthersForStream(%d) for MixWithOthers
%s Should not call setDuckOthersOptions with NO in B238
%s enableMiniDucking elapsed time = %{public}lf
%s %{public}@
%s configureAlertBehavior elapsed time = %{public}lf
%s VoiceTriggerInfo is nil from AVVC
%s Updated languageCode to: %{public}@ in VTEI received from remote
%s Peak : %f, Avg : %f
%s AVVCAudioBuffer contains %{public}d packet descriptions, size %{public}d, channels %{public}d. Ignoring
%s packets count %{public}d
%s Bad packet length %{public}d. Skipping rest of record buffer.
%s Cannot handle audio buffer : unexpected format(%{public}u)
%s Calling AVVC playAlertSoundForType to play alert
%s Ignore playing endpoint beep(record stopped beep) since it already played beep in gibraltar
%s Calling AVVC playAlertSoundsForType : %{public}ld
%s Received didStartRecording : %{public}p, forStream:%{public}llu, successfully:%{public}d, error:%{public}@
%s Received audio buffer %{public}d, heartbeat = %{public}llu, streamID (%{public}lu)
%s Received didStopRecording : %{public}p forStream:%{public}llu forReason:%{public}ld
%s Received Stream Invalidated : %{public}llu
%s toConfiguration : %{public}d
%s type : %{public}d, error : %{public}@
%s Encoder error : %{public}@
%s withContext : %{public}@
%s activate : %{public}d
%s AVVC lost mediaserverd connection
%s AVVC informed mediaserverd reset, no further action required
%s hasLocalPendingTwoShot = %{public}d, token : %{public}llu
%s Unsupported audio format!
%s Existing remoteRecordClient (deviceId = %@) doesn't match required one (deviceId = %@), create new remoteRecordClient
%s The input streamHandleId(%{public}lu) is not expected(%{public}lu)
%s Cannot create NSData with size 0
%s xpc object should be XPC_TYPE_DATA
%s endpointer running on corespeechd
%s endpointer running on assistantd
%s Abstract Impl. Returning nil
softlink:r:path:/System/Library/PrivateFrameworks/SiriCore.framework/SiriCore
softlink:r:path:/System/Library/PrivateFrameworks/SiriCore.framework/SiriCore
Statistics
CSCATXPCProtocol
CSGestureMonitor
CSBluetoothWirelessSplitterInfo
CSAudioInjectionBuiltInEngine
CSAudioInjectionEngineDelegate
NSObject
NviDataLogger
NSStreamDelegate
CSMicUsageReporter
CSVoiceTriggerAssetHandler
CSAudioSessionController
CSAudioSessionInfoProvidingDelegate
CSXPCClientDelegate
CSCoreSpeechDaemonStateMonitorDelegate
CSSiriDebugConnection
CSPhoneCallStateMonitor
CSCommandControlListenerOption
CSMediaPlayingMonitor
CSAudioInjectionFileOption
CSMSNExceptionManager
CSVolumeMonitor
CSTimerMonitor
CSAlarmMonitor
CSAudioStreamHolding
CSUserIdentityClassifier
CSAssetManagerEnablePolicyFactory
CSAttSiriServiceProtocol
CSAttSiriServiceDelegate
CSAttSiriServiceClient
CSSiriFanInfoManager
CSSiriFanInfo
CSBiometricMatchMonitor
CSPreMyriadVoiceTriggerMetaData
CSPreMyriadCoordinator
CSVoiceTriggerDelegate
CSSecondPassProgressDelegate
CSAudioInjectionHearstEngine
AVVC
CSAudioZeroCounter
SmartSiriVolume
CSAudioDeviceInfo
NSCopying
NSSecureCoding
NSCoding
CSSpeakerRecognitionProxy
CSSSRXPCClientDelegate
CSVoiceTriggerXPCService
CSVoiceTriggerXPCClientDelegate
CSVoiceTriggerAssetDownloadMonitor
Directory
CSAsset
CSAudioPreprocessor
CSVoiceTriggerAwareZeroFilterDelegate
CSBeepCancellerDelegate
CSAssetDownloadingOption
CSBluetoothManager
CSSiriAssertionMonitor
CSXPCConnectionDelegate
CSAccessorySiriClientBehaviorMonitor
CSSpeakerRecognitionAssetDownloadMonitor
CSTrialAssetDownloadMonitorDelegate
CSPowerAssertionMac
CSAudioFileReader
CSAdBlockerAssetDownloadMonitor
CSAudioRouteChangeMonitorImplWatch
CSAudioSampleRateConverter
CSLanguageDetectorAssetMonitor
CSSiriSpeechRecordingContext
CSSmartSiriVolumeService
CSSmartSiriVolumeServiceDelegate
CSSmartSiriVolumeClient
isPluginContext
CSAudioInjectionProvider
XPCObject
CSOpportuneSpeakListener
CSAudioStreamProvidingDelegate
CSSPGEndpointAnalyzerDelegate
CSVoiceIdXPCClient
AudioInjectionXPCProtocol
CSVoiceTriggerHeartBeatMetricsProvider
CSNNVADEndpointAnalyzer
CSEndpointAnalyzerImpl
CSEndpointAnalyzer
CSActivationXPCClient
CSLanguageDetector
LanguageCode
CSStopRecordingOptions
CSMacWakeSleepMonitor
CSMyriadSelfTriggerCoordinator
CSSelfTriggerDetectorDelegate
CSEndpointLoggingHelper
CSEndpointLatencyInfo
CSCommandControlStreamEventMonitor
CSCommandControlBehaviorMonitorDelegate
CSAVVCRecordingClientMonitor
CSAudioSessionMonitor
CSAudioSessionEventProvidingDelegate
Indexing
CSSiriAudioFileWriter
CSCoreSpeechServices
CSAudioStreamRequest
CSSelfTriggerDetectorEnabledPolicyMac
CSOpportuneSpeakListenerDeviceManager
CSAVVoiceTriggerClientManager
CSSpeechManager
CSAudioServerCrashMonitorDelegate
CSVoiceTriggerAssetHandlerDelegate
CSActivationEventNotificationHandlerDelegate
CSAudioRecorderDelegate
CSAudioProviderDelegate
CSOpportuneSpeakEventMonitorDelegate
CSSpeechEndHostTimeEstimator
CSClamshellStateMonitor
CSCommandControlListener
FlexKwd
CSAssetManager
CSVoiceTriggerAssetMetaUpdateMonitorDelegate
CSSpeechEndpointAssetMetaUpdateMonitorDelegate
CSAdBlockerMetaUpdateMonitorDelegate
CSAssetControllerDelegate
CSSpeakerRecognitionAssetMetaUpdateMonitorDelegate
CSLanguageCodeUpdateMonitorDelegate
CSEndpointerXPCService
CSEndpointerXPCServiceDelegate
CSEndpointerXPCClient
NviDirectionalitySignalProvider
NviSignalProvider
CSConnectionListener
NSXPCListenerDelegate
CSConnectionServiceDelegate
CSAudioRecorderFactory
CSKeywordAnalyzerNDEAPIResult
CSKeywordAnalyzerNDEAPI
CSSpeechController
CSAudioConverterDelegate
CSSmartSiriVolumeControllerDelegate
CSAudioAlertProvidingDelegate
CSAudioSessionControllerDelegate
CSAudioDecoderDelegate
CSEndpointAnalyzerImplDelegate
SOMediaNowPlayingListening
SOClockAlarmListening
SOClockTimerListening
CSAudioSessionProvidingDelegate
CSSpeechManagerDelegate
CSContinuousVoiceTriggerDelegate
CSSSRXPCService
CSSSRXPCServiceDelegate
CSSSRXPCClient
CSAttSiriAttendingTriggerEventInfo
RTModel
CSSiriAudioPlaybackSessionImplAVPlayerBased
CSSiriAudioPlaybackSession
SpeechModelTrainingClient
CSXPCClientFactory
SpeechModelTrainingProtocol
NviSignalProvidersController
CSVoiceTriggerFirstPassHearstAP
CSXPCClient
CSAudioSessionProviding
CSFallbackAudioSessionReleaseProviding
CSAudioStreamProviding
CSAudioAlertProviding
CSAudioSessionInfoProviding
CSAudioMeterProviding
CSAudioMetricProviding
CSAudioTimeConversionProviding
CSTriggerInfoProviding
CSAcousticSLResultProviding
CSStateMachine
CSEventMonitor
CSSmartSiriVolumeManager
CSAlarmMonitorDelegate
CSTimerMonitorDelegate
CSVolumeMonitorDelegate
CSAutomaticVolumeEnabledMonitorDelegate
CSVoiceTriggerDataCollector
CSAudioFileLog
CSActivationEvent
CoreSpeechXPCFakeModelMonitor
CSScreenLockMonitor
CSSmartSiriVolumeUserIntent
CSAssetController
CSEventMonitorDelegate
Utils
CSSyncKeywordAnalyzerQuasar
CSAudioInjectionTvRemoteEngine
CSSiriLauncher
CSAudioRouteChangeMonitor
CSSmartSiriVolumeEnablePolicy
CSAudioInjectionRemoraEngine
CSAudioInjectionEngine
AudioHardware
CSVoiceTriggerAssetChangeMonitor
CSAttSiriRequestContext
NviAudioFileWriter
CSAcousticSLProxy
SLProgressiveCheckerAnalyzerDelegate
CSVoiceTriggerEnabledPolicyNonAOP
CSBluetoothWirelessSplitterMonitor
CSSiriClientBehaviorMonitor
CSSpeechEndpointAssetMetaUpdateMonitor
CSSmartSiriVolumeEstimate
CSVoiceTriggerAssetHandlerMac
CSVoiceTriggerAssetDownloadMonitorDelegate
CSFirstUnlockMonitorDelegate
CSVoiceTriggerAOPModeEnabledPolicyIOS
CSSiriClientBehaviorMonitorDelegate
CSVoiceTriggerStatAggregator
CSOpportuneSpeakBehaviorMonitor
CSMyriadPHash
SignalEstimate
NviConstants
CSSiriAudioActivationInfo
NviUtils
Logging
CSHostPowerSourceMonitor
CSAudioStartStreamOption
CSAssetControllerFactory
AudioDevice
CSSiriAudioPlaybackSessionImplAVAudioPlayerBased
AVAudioPlayerDelegate
CSVoiceTriggerXPCServiceProxy
CSAdBlockerAssetDecoderV2
CSSmartSiriVolumeController
CSSmartSiriVolumeClientDelegate
SpeakerRecognition
CSBluetoothDeviceInfo
CSAttSiriStateMonitor
CSP2PService
CSVoiceTriggerAwareZeroFilter
CSAlwaysDisabledPolicy
CSPostBuildInstallService
CSContinuousAudioFingerprintProvider
CSKeywordAnalyzerNDAPIResult
CSKeywordAnalyzerNDAPI
CSBuiltinSpeakerStateMonitor
NviDirectionalitySignalData
CSEndpointerMetrics
CSSmartSiriVolume
CSMediaPlayingMonitorDelegate
CSSiriEnabledMonitorDelegate
CSSmartSiriVolumeProcessor
CSSACInfoMonitor
CSVoiceTriggerRTModel
CSSiriVibrationManager
CSAudioRouteChangeMonitorImpl
CSAutomaticVolumeEnabledMonitor
CSSiriRecordingInfo
CSSpeakerRecognitionAssetMetaUpdateMonitor
CSVoiceProfileRetrainManager
CSVoiceTriggerEnabledMonitor
CSHybridEndpointer
CSEndpointerAssetManagerDelegate
!2!B
CSRemoteRecordClient
CSSiriEnabledMonitor
NviCSAudioDataSource
NviAudioDataSource
NviDataSource
CSAlertBehaviorPredictor
CSDefaultAudioRouteChangeMonitorMac
CSAudioInjectionEngineFactory
CSSiriBluetoothManager
CSEndpointerAssetManager
CSAssetManagerDelegate
RMSSample
CSShadowMicScoreCreator
CSEndpointDelayReporter
CoreSpeechXPCProtocol
CSActivationEventNotifier
CSLanguageCodeUpdateMonitorImpl
CSVoiceTriggerEventsCoordinator
AudioFile
CSSoftwareUpdateCheckingMonitor
CSPreferences
CSAssetManagerEnablePolicy
CSCoreSpeechServiceListenerDelegate
CSVoiceTriggerAOPModeEnabledPolicyFactory
CSBatteryMonitor
Liminal
CSVoiceTriggerAssetMetaUpdateMonitor
CSAudioRecordDeviceIndicator
CSDarkWakePowerAssertionMac
CSSiriQueueMonitor
_CSSiriQueueObserver
CSAlwaysEnabledPolicy
CSRemoteVADCircularBuffer
CSAdBlockerAssetMetaUpdateMonitor
CSAudioStream
CSSiriAudioSession
CSSiriAudioRoute
CSServerEndpointFeatures
CSActivationEventNotificationHandler
CoreSpeechXPC
CSSiriRestrictionOnLockScreenMonitor
MCProfileConnectionObserver
CSRawAudioInjectionProvider
CSSpringboardStartMonitor
CSAudioProvider
CSAudioPreprocessorDelegate
CSListeningEnabledPolicyWatch
CSAlwaysOnProcessorStateMonitor
CSAdBlockerAssetDecoderFactory
CSMyriadNotifier
CSNovDetectorResult
CSNovDetector
CSAdBlockerAssetDecoderV1
CSUserSessionActiveMonitor
CSTrialAssetDownloadMonitor
CSRemoteDeviceProtocolInfo
Bitset
CSHybridEndpointAnalyzer
OSDAnalyzerDelegate
8!!!B
CSOpportuneSpeakListenerOption
CSAudioInjectionDevice
CSAudioSessionInfoProvider
CSEndpointerProxy
CSEndpointAnalyzerDelegate
CSSiriMobileBluetoothDeviceDataSource
AFInvalidating
CSSiriMobileBluetoothDeviceProxy
AFBluetoothDevice
CSCATAssetManager
CSFirstUnlockMonitor
CSPhraseSpotterEnabledMonitor
CSVoiceIdXPCConnection
NSXPC
CSSiriPreferences
MockRemotePluginXPCProtocol
CSFallbackAudioSessionReleaseProvider
CSSPGEndpointAnalyzer
CSASXSignatureExtracting
CSSiriAcousticFingerprinter
CSLanguageDetectorOption
CSSiriSpeechRecorder
CSSiriAcousticFingerprinterDelegate
CSSpeechControllerDelegate
CSLanguageDetectorDelegate
CSSpeakerIdentificationDelegate
CSSiriSpeechCapturing
CSSiriAudioPlaybackService
AFMemoryPressureListening
AFAudioPlaybackService
CSTrialAssetManager
CSStartOfSpeechDetector
CSAudioServerCrashMonitor
CSAudioServerCrashEventProvidingDelegate
CSVoiceTriggerXPCClient
CSCoreSpeechDaemonStateMonitor
CSKeywordAnalyzerQuasar
_EARSpeechRecognitionResultStream
CSNetworkAvailabilityMonitor
CSSpeechDetectionDevicePresentMonitor
CSAudioRecordDeviceInfo
CSOpportuneSpeakListnerTestService
CSOpportuneSpeakListenerDelegate
CSAudioConverter
CSLanguageCodeUpdateMonitor
CSAudioInjectionServices
CSAdBlockerAssetDecoderV3
Trial
CSGestureDropEvent
RecordContext
CSVTSecondPassPhraseScore
CSVTSecondPassScorer
LanguageDetector
debugDescription
remoteVoiceActivityVADBuffer
CSAudioRecorder
AVVoiceControllerRecordDelegate
CSAudioFileReaderDelegate
CSRemoteRecordClientDelegate
CSAudioServerCrashEventProviding
CSAudioSessionEventProviding
CSCommandControlBehaviorMonitor
CSVoiceProfileContext
NviContext
CSEndpointerFactory
CSJarvisTriggerModeMonitor
CSOpportuneSpeakEventMonitor
CSOpportuneSpeakBehaviorMonitorDelegate
NviSignalData
CSSRFUserSettingMonitor
dictionaryWithObjects:forKeys:count:
dictionaryWithDictionary:
count
numberWithUnsignedInteger:
setObject:forKeyedSubscript:
expressionForConstantValue:
arrayWithObjects:count:
expressionForFunction:arguments:
expressionValueWithObject:context:
doubleValue
sortUsingComparator:
objectAtIndexedSubscript:
numberWithDouble:
distributionDictionary:
fetchRemoteCATAssetForResource:withNameOfFile:completion:
interfaceWithProtocol:
setWithArray:
setClasses:forSelector:argumentIndex:ofReply:
sharedInstance
isTriggerHandheld
wakeGestureTimestamp
setWakeGestureTimestamp:
dismissalTimestamp
setDismissalTimestamp:
_wakeGestureTimestamp
_dismissalTimestamp
TQ,N,V_wakeGestureTimestamp
TQ,N,V_dismissalTimestamp
init
array
string
appendFormat:
countByEnumeratingWithState:objects:count:
address
supportDoAP
splitterState
copy
addObject:
_hasDeviceTemporaryPairedNotInContacts
isTemporaryPairedNotInContacts
description
splitterDeviceList
addDeviceIntoSplitterDeviceList:
shouldDisableSpeakerVerificationInSplitterMode
splitterEnabled
setSplitterEnabled:
.cxx_destruct
_splitterDeviceList
_splitterEnabled
TB,N,V_splitterEnabled
TB,R,N
initWithStreamHandleId:
inputRecordingNumberOfChannels
inputRecordingSampleRate
defaultConverter
initWithNumChannels:recordingDuration:samplingRate:audioTimeConverter:
UUID
setConnectedDevice:
enableAlwaysOnVoiceTrigger
isAlwaysOnVoiceTriggerAvailable
setAlwaysOnVoiceTriggerEnabled:
setDelegate:
dealloc
start
noAlertOption
startAudioStreamWithOption:
stopAudioStream
stop
reset
injectAudio:
injectAudio:withScaleFactor:playbackStarted:completion:
sampleCount
requestHistoricalAudioDataWithHostTime
startRecordingHostTime
objectAtIndex:
objectForKeyedSubscript:
unsignedIntValue
unsignedLongLongValue
getBestSampleCountWithOption:
audioEngineDidStartRecord:audioStreamHandleId:successfully:error:
audioStreamHandleId
audioEngineDidStopRecord:audioStreamHandleId:reason:
length
inputRecordingSampleByteDepth
numberWithUnsignedLongLong:
removeObjectAtIndex:
bytes
addSamples:numSamples:
inputRecordingIsFloat
applyNegative12dBGainToFloatBuffer:
applyNegative12dBGainToShortBuffer:
initWithData:numChannels:numSamples:sampleByteDepth:startSampleCount:hostTime:remoteVAD:
processAudioChunk:
isEarlyDetect
bestEnd
bestStart
secondsToHostTime:
sharedManagerForCoreSpeechDaemon
builtInMicVoiceTriggerEvent:hostTime:
notifyActivationEvent:completion:
inputRecordingBufferDuration
copybufferFrom:to:
audioEngineBufferAvailable:audioStreamHandleId:buffer:remoteVAD:atTime:
isEqual:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
debugDescription
TQ,R
T#,R
T@"NSString",R,C
audioEngineAudioChunkForTvAvailable:audioChunk:
alwaysOnVoiceTriggerEnabled
attachDevice:
isRecording
queue
setQueue:
delegate
keywordAnalyzer
setKeywordAnalyzer:
circularBuffer
setCircularBuffer:
lastForwardedSampleCount
setLastForwardedSampleCount:
hostTimeBuffer
setHostTimeBuffer:
uuid
setUuid:
voiceTriggerEnabled
setVoiceTriggerEnabled:
connectedDevice
isForwarding
setIsForwarding:
voiceTriggerSampleCount
setVoiceTriggerSampleCount:
_voiceTriggerEnabled
_isForwarding
_queue
_delegate
_keywordAnalyzer
_circularBuffer
_lastForwardedSampleCount
_hostTimeBuffer
_uuid
_connectedDevice
_voiceTriggerSampleCount
T@"NSObject<OS_dispatch_queue>",&,N,V_queue
T@"<CSAudioInjectionEngineDelegate>",W,N,V_delegate
T@"CSKeywordAnalyzerNDEAPI",&,N,V_keywordAnalyzer
T@"CSAudioCircularBuffer",&,N,V_circularBuffer
TQ,N,V_lastForwardedSampleCount
T@"NSMutableArray",&,N,V_hostTimeBuffer
T@"NSUUID",&,N,V_uuid
TB,N,V_voiceTriggerEnabled
T@"CSAudioInjectionDevice",W,N,V_connectedDevice
TB,N,V_isForwarding
TQ,N,V_voiceTriggerSampleCount
outputStreamToFileAtPath:append:
currentRunLoop
scheduleInRunLoop:forMode:
open
hasSpaceAvailable
stringWithFormat:
lengthOfBytesUsingEncoding:
cStringUsingEncoding:
write:maxLength:
close
removeFromRunLoop:forMode:
stream:handleEvent:
initWithFilePath:appendHdr:
logData:
endRequest
oStream
setOStream:
_oStream
T@"NSOutputStream",&,N,V_oStream
_reportsDynamicActivityAttribute:bundleId:
reportMicUsage:
reportsDynamicActivityAttributeAsync:bundleId:
reportsDynamicActivityAttributeSync:bundleId:
weakObjectsHashTable
removeObject:
voiceTriggerAssetHandler:endpointId:didChangeCachedAsset:
sharedHandler
getVoiceTriggerAssetWithEndpointId:completion:
defaultFallbackModelIfNil:
registerObserver:
unregisterObserver:
notifyObservers:endpointId:
observers
setObservers:
_observers
T@"NSHashTable",&,N,V_observers
initWithEndpointId:
_startMonitoring
_stopMonitoring
_getAudioSessionID
_createXPCClientConnectionIfNeeded
UUIDString
sessionInfoProvider
audioSessionIdForDeviceId:
audioSessionController:didReceiveAudioSessionInterruptionNotificationWithUserInfo:
audioSessionController:didReceiveAudioSessionRouteChangeNotificationWithUserInfo:
audioSessionController:didReceiveAudioSessionMediaServicesWereLostNotificationWithUserInfo:
audioSessionController:didReceiveAudioSessionMediaServicesWereResetNotificationWithUserInfo:
initWithType:
setSessionInfoProvider:
connect
setShouldKeepConnection:
addObserver:
userInfo
_registerInterruptionNotification
_registerAudioRouteChangeNotification
audioSessionController:didReceiveAudioSessionOwnerLostNotification:
_teardownXPCClientIfNeeded
audioSessionController:didReceiveAudioSessionOwnerResetNotification:
audioSessionInfoProvider:didReceiveAudioSessionInterruptionNotificationWithUserInfo:
audioSessionInfoProvider:didReceiveAudioSessionRouteChangeNotificationWithUserInfo:
audioSessionInfoProvider:didReceiveAudioSessionMediaServicesWereLostNotificationWithUserInfo:
audioSessionInfoProvider:didReceiveAudioSessionMediaServicesWereResetNotificationWithUserInfo:
CSXPCClient:didDisconnect:
coreSpeechDaemonStateMonitor:didReceiveStateChanged:
getAudioSessionIDWithCompletion:
getAudioSessionID
_handleInterruption:
_mediaServicesWereLost:
_mediaServicesWereReset:
_audioRouteChanged:
xpcClient
setXpcClient:
shouldKeepConnection
endpointId
setEndpointId:
_shouldKeepConnection
_sessionInfoProvider
_xpcClient
_endpointId
T@"<CSAudioSessionInfoProviding>",&,N,V_sessionInfoProvider
T@"CSXPCClient",&,N,V_xpcClient
TB,V_shouldKeepConnection
T@"NSUUID",&,N,V_endpointId
initWithAppBundleIdentifier:
initWithTaskDeliverer:
initWithMessage:makeAppFrontmost:
handleSiriRequest:deliveryHandler:completionHandler:
launchSiriDebugAppWithMessage:
_startMonitoringWithQueue:
phoneCallState
defaultOption
_notifyObserver:mediaIsPlayingState:
enumerateObserversInQueue:
defaultCenter
_notePossiblePlayPausedStateChange:
addObserver:selector:name:object:
removeObserver:name:object:
objectForKey:
boolValue
notifyObserver:
CSMediaPlayingMonitor:didReceiveMediaPlayingChanged:
initializeMediaPlayingState
mediaPlayingState
mediaPlayingStateWithCompletion:
_mediaIsPlaying
initWithAudioURL:withScaleFactor:outASBD:
audioURL
outASBD
setOutASBD:
fFile
setFFile:
scaleFactor
_scaleFactor
_audioURL
_fFile
_outASBD
T@"NSURL",R,N,V_audioURL
T{AudioStreamBasicDescription=dIIIIIIII},N,V_outASBD
T^{OpaqueExtAudioFile=},N,V_fFile
Tf,R,N,V_scaleFactor
beginAnnounceMessageException:reason:
endAnnounceMessageException:reason:
fetchVolumeFromAVSystemControllerForAudioCategory:
_startObservingSystemControllerLifecycle
startObservingSystemVolumes
removeObserver:
isEqualToString:
musicVolume
musicVolumeWithCompletion:
alarmVolume
systemVolumeDidChange:
systemControllerDied:
_supportAVSystemVolumeFetch
_musicVolumeLevel
_alarmVolumeLevel
initializeTimerState
timerState
_timerFiringState
initializeAlarmState
alarmState
_alarmFiringState
name
setName:
_name
T@"NSString",&,N,V_name
integerValue
multiUserHighScoreThreshold
multiUserLowScoreThreshold
multiUserDeltaScoreThreshold
multiUserConfidentScoreThreshold
mutableCopy
removeObjectForKey:
pickTopScoringProfileIdFromScores:
classifyUserIdentityFor:withScores:withAsset:
stringFromClassificationCategory:
assetManagerEnabledPolicy
_setupAttSiriSvcXpcConnection
synchronousRemoteObjectProxyWithErrorHandler:
startAttendingWithContext:
stopAttendingWithContext:
siriRequestProcessingCompleted
invalidate
initWithMachServiceName:options:
setRemoteObjectInterface:
attSiriDidDetectAttendingTrigger:
setExportedInterface:
setExportedObject:
attSiriSvcConn
processIdentifier
setAttSiriSvcConn:
setInterruptionHandler:
setInvalidationHandler:
resume
remoteSvcProxy
setRemoteSvcProxy:
_attSiriSvcConn
_remoteSvcProxy
T@"NSXPCConnection",&,N,V_attSiriSvcConn
T@,&,N,V_remoteSvcProxy
T@"<CSAttSiriServiceDelegate>",W,N,V_delegate
sharedManager
getCurrentFanInfo:
fanId
setFanId:
currentSpeed
setCurrentSpeed:
targetSpeed
setTargetSpeed:
_fanId
_currentSpeed
_targetSpeed
TQ,N,V_fanId
Tq,N,V_currentSpeed
Tq,N,V_targetSpeed
startObserving
getLastBiometricMatchEvent:atTime:
getBiometricMatchResultForTriggerTimeStamp:
T@"<CSBiometricMatchMonitorDelegate>",W,N,V_delegate
deviceId
setDeviceId:
isSecondPassRunning
setIsSecondPassRunning:
firstPassMyriadGoodnessScore
setFirstPassMyriadGoodnessScore:
_isSecondPassRunning
_firstPassMyriadGoodnessScore
_deviceId
T@"NSString",&,N,V_deviceId
TB,N,V_isSecondPassRunning
Tf,N,V_firstPassMyriadGoodnessScore
dictionary
pendingSecondPassTriggerWasClearedForClient:deviceId:
_clearPendingRemoraVoiceTrigger
voiceTriggerDidDetectKeyword:deviceId:completion:
_clearPendingBuiltInVoiceTrigger
enumerateKeysAndObjectsUsingBlock:
isBultInVoiceTriggerEvent:
isRemoraVoiceTriggerEvent:
voiceTriggerDidDetectKeyword:deviceId:
handlePendingRemoraVoiceTriggerIfNeeded
handlePendingBuiltInVoiceTriggerIfNeeded
voiceTriggerDidDetectNearMiss:deviceId:
voiceTriggerDidDetectSpeakerReject:
keywordDetectorDidDetectKeyword
voiceTriggerGotSuperVector:
raiseToSpeakDetected:
voiceTriggerDidRejected:deviceId:
setBuiltInVoiceTriggerMetaData:
accessoryVoiceTriggerMetaDataByDeviceId
setObject:forKey:
voiceTriggerDidDetectKeyword:myriadHash:remoteTriggerType:remoteDeviceId:isTriggeredFromFullWake:completion:
secondPassDidStartForClient:deviceId:withFirstPassEstimate:
secondPassDidStopForClient:deviceId:
initWithTargetQueue:
_getHighestRemoraFirstPassGoodnessScore:
_isRemoraSecondPassRunning
builtInSeconPassProgressProvider
setBuiltInSeconPassProgressProvider:
remoraSecondPassProgressProvider
setRemoraSecondPassProgressProvider:
targetQueue
setTargetQueue:
pendingRemoraVoiceTriggerResult
setPendingRemoraVoiceTriggerResult:
pendingRemoraVoiceTriggerDeviceId
setPendingRemoraVoiceTriggerDeviceId:
pendingRemoraVoiceTriggerCompletionBlk
setPendingRemoraVoiceTriggerCompletionBlk:
pendingRemoraVoiceTriggerDetectedTime
setPendingRemoraVoiceTriggerDetectedTime:
pendingBuiltInVoiceTriggerResult
setPendingBuiltInVoiceTriggerResult:
pendingBuiltInVoiceTriggerCompletionBlk
setPendingBuiltInVoiceTriggerCompletionBlk:
pendingBuiltInVoiceTriggerDetectedTime
setPendingBuiltInVoiceTriggerDetectedTime:
builtInVoiceTriggerMetaData
setAccessoryVoiceTriggerMetaDataByDeviceId:
_builtInSeconPassProgressProvider
_remoraSecondPassProgressProvider
_targetQueue
_pendingRemoraVoiceTriggerResult
_pendingRemoraVoiceTriggerDeviceId
_pendingRemoraVoiceTriggerCompletionBlk
_pendingRemoraVoiceTriggerDetectedTime
_pendingBuiltInVoiceTriggerResult
_pendingBuiltInVoiceTriggerCompletionBlk
_pendingBuiltInVoiceTriggerDetectedTime
_builtInVoiceTriggerMetaData
_accessoryVoiceTriggerMetaDataByDeviceId
T@"NSObject<OS_dispatch_queue>",&,N,V_targetQueue
T@"NSDictionary",&,N,V_pendingRemoraVoiceTriggerResult
T@"NSString",&,N,V_pendingRemoraVoiceTriggerDeviceId
T@?,C,N,V_pendingRemoraVoiceTriggerCompletionBlk
TQ,N,V_pendingRemoraVoiceTriggerDetectedTime
T@"NSDictionary",&,N,V_pendingBuiltInVoiceTriggerResult
T@?,C,N,V_pendingBuiltInVoiceTriggerCompletionBlk
TQ,N,V_pendingBuiltInVoiceTriggerDetectedTime
T@"CSPreMyriadVoiceTriggerMetaData",&,N,V_builtInVoiceTriggerMetaData
T@"NSMutableDictionary",&,N,V_accessoryVoiceTriggerMetaDataByDeviceId
T@"<CSVoiceTriggerDelegate>",W,N,V_delegate
T@"<CSSecondPassProgressProviding>",W,N,V_builtInSeconPassProgressProvider
T@"<CSSecondPassProgressProviding>",W,N,V_remoraSecondPassProgressProvider
getAnalyzedResult
bestScore
getThreshold
deviceID
remoteMicVoiceTriggerEvent:activationInfo:hostTime:
lastDetectedVoiceTriggerBeginSampleCount
setLastDetectedVoiceTriggerBeginSampleCount:
_lastDetectedVoiceTriggerBeginSampleCount
T@"CSKeywordAnalyzerNDAPI",&,N,V_keywordAnalyzer
TQ,N,V_lastDetectedVoiceTriggerBeginSampleCount
avvcContext
unsignedIntegerValue
initWithMode:deviceUID:
supportHandsFree
isRequestDuringActiveCall
setActivationMode:
setAnnounceCallsEnabled:
avvcContextSettings
zeroFilterWindowSizeInMs
zeroFilterWindowSizeInMsForReport
shouldDeinterleaveAudioOnCS
sharedAggregator
logAudioZeroRun:
initWithToken:sampleRate:numChannels:
resetWithSampleRate:
getZeroStatisticsFromBuffer:entireSamples:
stopReportZeroStatistics
_methodToken
_continuousZeroCounter
_zeroCounterWinSz
_zeroCounterWinSzForReport
_maxContinuousZeroCount
_numChannels
_analyzeStep
_sampleRate
_shouldDeinterleaveAudio
voiceTriggerEventInfo
route
source
resourcePath
stringByAppendingPathComponent:
decodeJson:
getNumberForKey:category:default:
floatValue
getNumElementInBitset:
_getNumberFromASVDictionaryForKey:category:default:
intValue
_adaptiveSiriVolumeDictionary
SSVNoiseLevelChannelBitset
SSVLKFSChannelBitset
SSVEnergyBufferSize
numberWithUnsignedInt:
SSVNoiseLowerPercentile
SSVNoiseUpperPercentile
SSVLKFSLowerPercentile
SSVLKFSUpperPercentile
SSVNoiseTimeConstant
numberWithFloat:
SSVNoiseMicSensitivityOffset
SSVLKFSTimeConstant
SSVLKFSMicSensitivityOffset
SSVNoiseTTSMappingInputRangeLow
SSVNoiseTTSMappingInputRangeHigh
SSVNoiseTTSMappingOutputRangeLow
SSVNoiseTTSMappingOutputRangeHigh
SSVLKFSTTSMappingInputRangeLow
SSVLKFSTTSMappingInputRangeHigh
SSVLKFSTTSMappingOutputRangeLow
SSVLKFSTTSMappingOutputRangeHigh
SSVUserOffsetInputRangeLow
SSVUserOffsetInputRangeHigh
SSVUserOffsetOutputRangeLow
SSVUserOffsetOutputRangeHigh
SSVTTSVolumeLowerLimitDB
SSVTTSVolumeUpperLimitDB
SSVNoiseWeight
SSVDistanceChannelBitset
SSVNoiseMicSensitivityOffsetDeviceSimple
SSVCAMaxFrameSize
SSVCAVoiceTriggerBasedTTSValidForSeconds
SSVCASmartSiriVolumeUnsyncedMetricLogsToRetain
SSVCASmartSiriVolumeSyncedMetricLogsToRetain
SSVCAVoiceTriggerInitialSilenceDurationSeconds
SSVCADistanceInputBufferDurationSeconds
SSVCAListenPollingIntervalAtStartInSeconds
SSVCADefaultZeroFloatingPointValue
SSVCAAnnouncementStatusFetchTimeoutMs
SSVCADefaultOutputTTSVolume
SSVCANoiseActivityCountThreshold
SSVCASpeakerDistanceFarBoostFactor
SSVCASpeakerDistanceMidBoostFactor
SSVCASpeakerDistanceNearBoostFactor
SSVCADistanceModelConfidenceThreshold
SSVCAMinimumLinearSoundLevel
SSVCAMaximumLinearSoundLevel
SSVCALinearToDecibelConstantMultiplier
SSVCADecibelToLinearLogBase
SSVCASignalToSigmoidNoiseDilationFactor
SSVCASignalToSigmoidMusicDilationFactorDeviceDefault
SSVCASignalToSigmoidMusicDilationFactorDeviceSimple
SSVCASignalToSigmoidSpeechDilationFactor
SSVCASignalToSigmoidNoiseVSpread
SSVCASignalToSigmoidMusicVSpreadDeviceDefault
SSVCASignalToSigmoidMusicVSpreadDeviceSimple
SSVCASignalToSigmoidSpeechVSpread
SSVCASignalToSigmoidNoiseVOffset
SSVCASignalToSigmoidMusicVOffsetDeviceDefault
SSVCASignalToSigmoidMusicVOffsetDeviceSimple
SSVCASignalToSigmoidSpeechVOffset
SSVCASignalToSigmoidNoiseHOffset
SSVCASignalToSigmoidMusicHOffsetDeviceDefault
SSVCASignalToSigmoidMusicHOffsetDeviceSimple
SSVCASignalToSigmoidSpeechHOffset
SSVCASignalToSigmoidMusicSteepnessDeviceDefault
SSVCASignalToSigmoidMusicSteepnessDeviceSimple
SSVCASignalToSigmoidNoiseSteepness
SSVCASignalToSigmoidSpeechSteepness
SSVCADBToTTSMinimumOutput
SSVCADBToTTSMaximumOutput
SSVCADBToTTSTransitionPoint
SSVCADBToTTSPreTransitionOffset
SSVCADBToTTSPreTransitionMultiplier
SSVCADBToTTSPostTransitionOffset
SSVCADBToTTSPostTransitionDC
SSVCADBToTTSPostTransitionMultiplier
SSVCAMinimumDistanceUpdateWaitPeriodSeconds
SSVCANoiseActivityThreshold
SSVCANoiseResultsBufferSize
SSVCAMusicResultsBufferSize
SSVCADefaultSpeechStrength
SSVCADefaultMusicStrength
SSVCANoiseActivityHistoricalSampleCount
SSVCADspCoefsCount
SSVCADspNumStages
SSVCADistanceResultsBufferSize
SSVCAExponentialDistanceHistoryDegradationFactor
SSVCADistanceResultSampleCountTolerance
SSVCAMusicHistoricalSamplesInSeconds
SSVCADeviceSimpleOutputMinTargetDB
SSVCADeviceSimpleOutputMaxTargetDB
SSVCADeviceSimpleOutputSlope
SSVCADeviceSimpleMinTargetDB
SSVCADeviceSimpleMaxTargetDB
SSVCADeviceSimpleDBToSystemVolSlope
SSVCADeviceSimpleMicSensitivityOffset
SSVCADeviceSimplePreTriggerSilenceSampleCount
SSVCAMinTTSSystemVolume
SSVCAMaxTTSSystemVolume
SSVCAUserIntentValidForSeconds
SSVCAUserIntentVolumeIncreaseFactor
SSVCAUserIntentVolumeDecreaseFactor
SSVCAUserIntentPermanentOffsetFactorDelta
SSVCAUserIntentPermanentOffsetFactorLowerBound
SSVCAUserIntentPermanentOffsetFactorUpperBound
SSVCADeviceSimpleMinTTSVolume
SSVCADeviceSimpleMaxTTSVolume
SSVCADeviceDefaultMinTTSVolume
SSVCADeviceDefaultMaxTTSVolume
SSVCADeviceDefaultASVOffMinTTSVolume
SSVCADeviceSimpleASVOffMinTTSVolume
SSVCADeviceDefaultMicSensitivityOffset
SSVCAVolumeHalfLifeSeconds
SSVCAHistoricalVolumeBufferSize
SSVCAMaximumCompensatedSpeechLevelNearField
SSVParameterDirectionary
SSVDefaultNoiseChannelCount
SSVDefaultLKFSChannelCount
SSVDefaultDistanceChannelCount
getSSVDeviceType
TQ,R,N
TI,R,N
Tf,R,N
T@"NSDictionary",R,N
Ti,R,N
Td,R,N
initWithXPCObject:
stringWithUTF8String:
_cs_initWithXPCObject:
initWithRecordDeviceInfo:playbackRoute:playbackDeviceTypeList:
xpcObject
_cs_xpcObject
UTF8String
initWithFormat:
encodeObject:forKey:
decodeObjectOfClass:forKey:
supportsSecureCoding
copyWithZone:
encodeWithCoder:
initWithCoder:
TB,R
recordDeviceInfo
playbackRoute
playbackDeviceTypeList
_recordDeviceInfo
_playbackRoute
_playbackDeviceTypeList
T@"CSAudioRecordDeviceInfo",R,C,N,V_recordDeviceInfo
T@"NSString",R,C,N,V_playbackRoute
T@"NSArray",R,C,N,V_playbackDeviceTypeList
startXPCConnection
didReceiveSpeakerRecognitionScoreCard:
didFinishSpeakerRecognition:
initWithDelegate:
ssrXPCClient
setSsrXPCClient:
_ssrXPCClient
T@"CSSSRXPCClient",&,N,V_ssrXPCClient
T@"<CSSpeakerRecognitionProxyProtocol>",R,W,N,V_delegate
_createXPCClientConnectionIfNeeded:
processInfo
systemUptime
enableVoiceTrigger:withAssertion:timestamp:
enableVoiceTrigger:withAssertion:xpcClient:
setPhraseSpotterBypassing:timeout:
setPhraseSpotterBypassing:timeout:xpcClient:
setRaiseToSpeakBypassing:timeout:
setRaiseToSpeakBypassing:timeout:xpcClient:
notifyVoiceTriggeredSiriSessionCancelled
fetchVoiceTriggerStats
notifyVoiceTriggeredSiriSessionCancelledWithXpcClient:
sharedService
voiceTriggerXPCClient:didDisconnect:
enableVoiceTrigger:withAssertion:
fetchVoiceTriggerDailyStats
T@"CSVoiceTriggerXPCClient",&,N,V_xpcClient
_notificationKey
_didInstalledNewVoiceTriggerAsset
_notifyObserver:
enumerateObservers:
CSVoiceTriggerAssetDownloadMonitor:didInstallNewAsset:
_notifyToken
_sharedDisposeLoggingQueue
dateWithTimeIntervalSinceNow:
distantFuture
getResourceValue:forKey:error:
localizedDescription
compare:
removeItemAtURL:error:
URLsInDirectory:matchingPattern:completion:
_sortedURLsInDirectory:matchingPattern:completion:
_contentsOfDirectoryAtURL:matchingPattern:includingPropertiesForKeys:error:
sortedArrayUsingComparator:
regularExpressionWithPattern:options:error:
contentsOfDirectoryAtURL:includingPropertiesForKeys:options:error:
lastPathComponent
numberOfMatchesInString:options:range:
predicateWithBlock:
filteredArrayUsingPredicate:
removeLogFilesInDirectory:matchingPattern:beforeDays:
clearLogFilesInDirectory:matchingPattern:exceedNumber:
getLocalUrl
path
_compatibilityVersion
stringValue
appendString:
_version
_footprint
assetForAssetType:resourcePath:configVersion:
attributes
state
isPremium
getCSAssetOfType:
isDownloading
isCSAssetInstalled
canBePurged
isLatestCompareTo:
supportZeroFilter:
supportBeepCanceller:
setNumChannels:
resetWithSampleRate:containsVoiceTrigger:voiceTriggerInfo:
setSampleRate:
_isNarrowBand:
upsampler
setUpsampler:
zeroFilter
beepCanceller
convertSampleRateOfBuffer:
processBuffer:atTime:
cancelBeepFromSamples:timestamp:
audioPreprocessor:hasAvailableBuffer:atTime:arrivalTimestampToAudioRecorder:numberOfChannels:
flush
_reportMetrics
isHeadphoneDeviceWithRecordRoute:playbackRoute:
willBeep
_fetchCurrentMetrics
sharedAnalytics
logEventWithType:context:
metrics
inputRecordingSampleRateNarrowBand
zeroFilter:zeroFilteredBufferAvailable:atHostTime:
beepCancellerDidCancelSamples:buffer:timestamp:
initWithSampleRate:withNumberOfChannels:
processBuffer:atTime:arrivalTimestampToAudioRecorder:
willBeepWithRecordRoute:playbackRoute:
reportMetricsForSiriRequestWithUUID:
sampleRate
setZeroFilter:
setBeepCanceller:
zeroCounter
setZeroCounter:
numChannels
_upsampler
_zeroFilter
_beepCanceller
_zeroCounter
Tf,N,V_sampleRate
T@"CSAudioSampleRateConverter",&,N,V_upsampler
T@"CSVoiceTriggerAwareZeroFilter",&,N,V_zeroFilter
T@"CSBeepCanceller",&,N,V_beepCanceller
T@"CSAudioZeroCounter",&,N,V_zeroCounter
Ti,N,V_numChannels
T@"<CSAudioPreprocessorDelegate>",W,N,V_delegate
allowVoiceTriggerAssetDownloading
setAllowVoiceTriggerAssetDownloading:
allowEndpointAssetDownloading
setAllowEndpointAssetDownloading:
allowLanguageDetectorAssetDownloading
setAllowLanguageDetectorAssetDownloading:
allowAdBlockerAssetDownloading
setAllowAdBlockerAssetDownloading:
allowSpeakerRecognitionAssetDownloading
setAllowSpeakerRecognitionAssetDownloading:
allowVoiceTriggerAccessoryAssetDownloading
setAllowVoiceTriggerAccessoryAssetDownloading:
_allowVoiceTriggerAssetDownloading
_allowEndpointAssetDownloading
_allowLanguageDetectorAssetDownloading
_allowAdBlockerAssetDownloading
_allowSpeakerRecognitionAssetDownloading
_allowVoiceTriggerAccessoryAssetDownloading
TB,N,V_allowVoiceTriggerAssetDownloading
TB,N,V_allowEndpointAssetDownloading
TB,N,V_allowLanguageDetectorAssetDownloading
TB,N,V_allowAdBlockerAssetDownloading
TB,N,V_allowSpeakerRecognitionAssetDownloading
TB,N,V_allowVoiceTriggerAccessoryAssetDownloading
stringByAppendingFormat:
_attachBluetoothSession
_getWirelessSplitterInfoFromLocalDevice:
getBTLocalDeviceWithCompletion:
initWithCapacity:
initWithUTF8String:
setAddress:
setSupportDoAP:
setIsTemporaryPairedNotInContacts:
_tearDownLocalDevice
_detachBluetoothSession
_setUpLocalDevice
getWirelessSplitterInfoWithCompletion:
device:serviceMask:serviceEventType:serviceSpecificEvent:result:
_sessionAttached:result:
_sessionDetached:
_sessionTerminated:
localDevice:event:result:
bluetoothSession
setBluetoothSession:
isAttachingBluetoothSession
setIsAttachingBluetoothSession:
localDevice
setLocalDevice:
pairedDeviceAddresses
setPairedDeviceAddresses:
connectedDeviceAddresses
setConnectedDeviceAddresses:
bluetoothSessionSetupGroup
setBluetoothSessionSetupGroup:
_isAttachingBluetoothSession
_bluetoothSession
_localDevice
_pairedDeviceAddresses
_connectedDeviceAddresses
_bluetoothSessionSetupGroup
T^{BTSessionImpl=},N,V_bluetoothSession
TB,N,V_isAttachingBluetoothSession
T^{BTLocalDeviceImpl=},N,V_localDevice
T@"NSArray",&,N,V_pairedDeviceAddresses
T@"NSArray",&,N,V_connectedDeviceAddresses
T@"NSObject<OS_dispatch_group>",&,N,V_bluetoothSessionSetupGroup
isEnabled
CSSiriAssertionMonitor:didReceiveEnabled:
handleXPCMessage:messageBody:client:
CSXPCConnectionReceivedClientError:clientError:client:
enableAssertionReceived
disableAssertionReceived
_assertionState
getSerialQueue:withQualityOfService:andTargetQueue:
_init
accessorySiriClientBehaviorMonitor:willStartStreamWithContext:option:forAccessory:
accessorySiriClientBehaviorMonitor:didStartStreamWithContext:successfully:option:withEventUUID:forAccessory:
accessorySiriClientBehaviorMonitor:willStopStream:reason:forAccessory:
accessorySiriClientBehaviorMonitor:didStopStream:reason:withEventUUID:forAccessory:
notifyWillStartStreamWithContext:option:forAccessory:
notifyDidStartStreamWithContext:successfully:option:withEventUUID:forAccessory:
notifyWillStopStream:reason:forAccessory:
notifyDidStopStream:reason:withEventUUID:forAccessory:
sharedPreferences
isSpeakerRecognitionAvailable
_didInstalledNewAsset
CSSpeakerRecognitionAssetDownloadMonitor:didInstallNewAsset:assetProviderType:
trialAssetDownloadMonitorDelegate:didInstallNewAsset:assetType:
trialAssetMonitor
setTrialAssetMonitor:
_lastUpdatedAssetType
_trialAssetMonitor
T@"CSTrialAssetDownloadMonitor",&,N,V_trialAssetMonitor
initWithTimeout:
_readAudioBufferAndFeed
audioFileReaderDidStartRecording:successfully:error:
dataWithLength:
audioFileReaderBufferAvailable:buffer:atTime:
audioFileReaderDidStopRecording:forReason:
initWithURL:
setRecordBufferDuration:
prepareRecording:
startRecording
stopRecording
readSamplesFromChannelIdx:
_audioFeedTimer
_bufferDuration
T@"<CSAudioFileReaderDelegate>",W,N,V_delegate
_didInstalledNewAdBlockerAsset
CSAdBlockerAssetDownloadMonitor:didInstallNewAsset:assetProviderType:
monitor
setMonitor:
_monitor
T@"CSTrialAssetDownloadMonitor",&,N,V_monitor
_fetchHearstConnectionState
_notifyHearstConnectionState:
_startObservingAudioRouteChange
CSAudioRouteChangeMonitor:didReceiveAudioRouteChangeEvent:
activeAudioRouteDidChange:
getHearstConnected:
hearstConnected
getJarvisConnected:
jarvisConnected
_systemControllerDied:
_isHearstConnected
lpcmNarrowBandASBD
lpcmASBD
initWithInASBD:outASBD:
_createSampleRateConverterWithInASBD:outASBD:
mutableBytes
currentHandler
handleFailureInMethod:object:file:lineNumber:description:
setLength:
downsampler
_sampleRateConverter
_outBufferScaleFactor
_inASBD
languageDetectorAssetMonitor:didReceiveNewAssetWithSupportLocale:
_supportedLocale:
supportLanguageDetector
setAssetDownloadingOption:
languageDetectorSupportedLocale
assetOfType:language:completion:
errorWithDomain:code:userInfo:
startMonitor
supportedLocale:
notifyToken
setNotifyToken:
Ti,N,V_notifyToken
T@"<CSLanguageDetectorAssetMonitorDelegate>",W,N,V_delegate
defaultManager
_finalizeAudioFileWriterWithCompletion:
_removeRecordedAudio
shouldLogForQA
_didBecomeCurrent
_didResignCurrent
remoteDeviceUID
deviceIdentifier
initWithBlock:
invoke
audioSessionActivationTargetDate
timeIntervalSinceNow
setTimestamp:
setReason:
setEffectiveDate:
setUserInfo:
newWithBuilder:
acquireAudioSessionAssertionWithContext:relinquishmentHandler:
dateByAddingTimeIntervalSinceActivation:
date
dateByAddingTimeInterval:
relinquishWithContext:options:
relinquishWithError:options:
_initializeAudioFileWriterWithAudioStreamBasicDescription:
appendAudioData:
createDirectoryAtPath:withIntermediateDirectories:attributes:error:
initWithType:pathGenerator:priority:
configureWithAudioStreamBasicDescription:
flushWithCompletion:
_instrumentSiriCue:
setSiriCueType:
logInstrumentation:machAbsoluteTime:turnIdentifier:
setEndpointType:
_createRequestLinkInfo:component:
setSource:
setTarget:
initWithUUIDString:
initWithNSUUID:
setComponent:
_donateRecordedAudioForVoiceIdentificationTrainingWithCompletion:
containsObject:
numberWithBool:
notifyImplicitTrainingUtteranceAvailable:forVoiceProfileId:withRecordDeviceInfo:withRecordCtxt:withVoiceTriggerCtxt:withOtherCtxt:withCompletion:
initWithSessionUUID:turnIdentifier:
becomeCurrent
resignCurrent
updateStartSpeechId:
updateSelectedResultCandidateId:
updateAccessToRecordedAudioForVoiceIdentificationTraining:forResultCandidateId:sharedUserId:
getAudioRecordRouteAndDeviceIdentificationWithCompletion:
acquireRecordedAudioWithHandler:
updateAudioRecordContext:
updateAudioRecordDeviceInfo:
updateVoiceTriggerInfo:
updateRecordingInfo:
updateRecordingSettings:
willPrepareAndStartRecordingWithAudioActivationInfo:
didDetectTwoShotWithAudioActivationInfo:atTime:
willStopRecordingAtHostTime:
didStopRecordingWithError:
relinquishAudioSessionAssertionsWithContext:
relinquishAudioSessionAssertionsWithError:
beginRecordingAudioWithAudioStreamBasicDescription:
appendRecordedAudioBuffer:
endRecordingAudio
instrumentSiriCue:
instrumentSiriCueForAlertType:
instrumentStopRecordingForEndpointType:
emitRequestLinkEventForMHUUID:
sessionUUID
wantsRecordedAudioBufferLogs
_isCurrent
_startSpeechId
_selectedResultCandidateId
_audioRecordContext
_audioRecordDeviceInfo
_voiceTriggerInfo
_recordingSettings
_recordingInfo
_audioFileWriter
_recordedAudioFileURL
_startRecordingAudioSessionAssertion
_twoShotDetectionAudioSessionAssertion
_recordingAudioGroup
_voiceIdentificationTraining_allowsWithoutResultCandidate
_voiceIdentificationTraining_allowedResultCandidateIds
_voiceIdentificationTraining_resultCandidateToSharedUserIdMap
_turnIdentifier
_voiceIdentificationTraining_withoutResultCandidateSharedUserId
_stopRecordingInstrumented
_wantsRecordedAudioBufferLogs
_sessionUUID
T@"NSString",R,C,N,V_sessionUUID
TB,R,N,V_wantsRecordedAudioBufferLogs
_getRemoteServiceProxyObject
getVolumeForTTSType:withContext:reply:
setSmartSiriVolumePercentage:
setSmartSiriVolumeDirection:
setPermanentVolumeOffsetWithDirection:
didSmartSiriVolumeChangeForReason:
_createClientConnection
code
didTTSVolumeChangeForReason:
ssvConnection
setSsvConnection:
getVolumeForTTSType:withContext:
_ssvConnection
T@"NSXPCConnection",&,N,V_ssvConnection
T@"<CSSmartSiriVolumeClientDelegate>",W,N,V_delegate
type
isPluginContext
initWithDeviceType:deviceName:deviceID:productID:
deviceType
_createSpeechDetectionVADIfNeeded
isPluginDevice
_connectPluginDevice:
_tearDownSpeechDetectionVADIfNeeded
engineWithDeviceType:streamHandleId:
setInjectionEngine:
removeAllObjects
audioRecorderStreamHandleIdInvalidated:
audioRecorderWillBeDestroyed:
injectionEngine
streamHandleId
deviceName
deviceUID
productIdentifier
initWithRoute:isRemoteDevice:remoteDeviceUID:remoteDeviceProductIdentifier:
recordDeviceInfoWithStreamHandleId:recordDeviceIndicator:
setActive:withOptions:error:
setActive:error:
audioRecorderDidStartRecord:audioStreamHandleId:successfully:error:
audioRecorderBufferAvailable:audioStreamHandleId:buffer:remoteVAD:atTime:arrivalTimestampToAudioRecorder:numberOfChannels:
audioRecorderDidStopRecord:audioStreamHandleId:reason:
audioRecorderBufferAvailable:audioStreamHandleId:buffer:
streamHandleID
defaultInjectionProvider
createSharedAudioSession
primaryInputDevice
connectDevice:
disconnectDevice:
willDestroy
setAudioServerCrashEventDelegate:
setAudioSessionEventDelegate:
setContext:completion:
setCurrentContext:streamHandleId:error:
prepareAudioStreamRecord:recordDeviceIndicator:error:
startAudioStreamWithOption:recordDeviceIndicator:error:
stopAudioStreamWithRecordDeviceIndicator:error:
isRecordingWithRecordDeviceIndicator:
recordRouteWithRecordDeviceIndicator:
audioDeviceInfoWithStreamHandleId:recordDeviceIndicator:
recordSettingsWithStreamHandleId:
recordingSampleRateWithStreamHandleId:
isNarrowBandWithStreamHandleId:
prewarmAudioSessionWithStreamHandleId:error:
activateAudioSessionWithReason:streamHandleId:error:
deactivateAudioSession:streamHandleId:error:
deactivateAudioSession:error:
setRecordMode:streamHandleId:error:
setDuckOthersOption:
duckOthersOption
setAlertSoundFromURL:forType:
playRecordStartingAlertAndResetEndpointerFromStream:
playAlertSoundForType:recordDevideIndicator:
alertStartTime
setMeteringEnabled:
updateMeters
peakPowerForChannel:
averagePowerForChannel:
isSessionCurrentlyActivated
voiceTriggerInfoWithRecordDeviceIndicator:
enableMiniDucking:
configureAlertBehavior:audioStreamHandleId:
didStartDelayInSeconds
setDidStartDelayInSeconds:
connectedDevices
setConnectedDevices:
builtInDevice
setBuiltInDevice:
bundleTvRemote
setBundleTvRemote:
builtInAudioInjectionEngine
setBuiltInAudioInjectionEngine:
audioInjectionEngines
setAudioInjectionEngines:
latestPluginStreamId
setLatestPluginStreamId:
activateStartTime
setActivateStartTime:
activateEndTime
setActivateEndTime:
deactivateStartTime
setDeactivateStartTime:
deactivateEndTime
setDeactivateEndTime:
_didStartDelayInSeconds
_connectedDevices
_builtInDevice
_bundleTvRemote
_builtInAudioInjectionEngine
_audioInjectionEngines
_latestPluginStreamId
_activateStartTime
_activateEndTime
_deactivateStartTime
_deactivateEndTime
T@"NSMutableArray",&,N,V_connectedDevices
T@"CSAudioInjectionDevice",&,N,V_builtInDevice
T@"CSAudioInjectionDevice",&,N,V_bundleTvRemote
T@"CSAudioInjectionEngine",&,N,V_builtInAudioInjectionEngine
T@"NSMutableDictionary",&,N,V_audioInjectionEngines
TQ,N,V_latestPluginStreamId
TQ,N,V_activateStartTime
TQ,N,V_activateEndTime
TQ,N,V_deactivateStartTime
TQ,N,V_deactivateEndTime
Tf,N,V_didStartDelayInSeconds
initWithAnalyzeMode
fileLoggingIsEnabled
lpcmNonInterleavedWithRemoteVADASBD
lpcmInterleavedWithRemoteVADASBD
createAudioFileWriterForOpportuneSpeakListenerWithInputFormat:outputFormat:
contextForHearstVoiceTriggerWithDeviceId:
opportuneSpeakListeningType
contextForOpportuneSpeakerListener
contextForOpportuneSpeakerListenerWithCall
_resetAlignBuffer
prepareAudioProviderWithContext:clientType:error:
_startRequestWithCompletion:
defaultRequestWithContext:
setRequiresHistoricalBuffer:
audioStreamWithRequest:streamName:error:
setAudioStream:
getFrameDurationMs
remoteVADDuration
startAudioStreamWithOption:completion:
endAudio
audioStream
stopAudioStreamWithOption:completion:
stopListenWithStateReset:completion:
opportuneSpeakListener:didStopUnexpectly:
gainCompensatedChunk
numSamples
hostTime
processSampleCount:hostTime:
channelForProcessedInput
dataForChannel:
addAudio:numSamples:
remoteVAD
opportuneSpeakListenerBypassEnabled
_addRemoteVADSignal:
dataWithRemoteVADWithScaleFactor:numAudioSamplesPerRemoteVAD:
_shouldReportBoron
_popRemoteVADSignal
opportuneSpeakListener:hasRemoteVADAvailable:
hostTimeFromSampleCount:
opportuneSpeakListener:hasVADAvailable:withHostTime:
opportuneSpeakListener:hasVADAvailable:
audioStreamProvider:didStopStreamUnexpectly:
audioStreamProvider:audioBufferAvailable:
audioStreamProvider:audioChunkForTVAvailable:
audioStreamProvider:didHardwareConfigurationChange:
startListenWithOption:completion:
stopListenWithCompletion:
spgEndpointAnalyzer:hasSilenceScoreEstimate:clientProcessedAudioTimeMS:
spgEndpointAnalyzer
setSpgEndpointAnalyzer:
remoteVADSPGRatio
setRemoteVADSPGRatio:
audioStreamProvider
setAudioStreamProvider:
audioSessionProvider
setAudioSessionProvider:
latestContext
setLatestContext:
isMediaPlayingNow
setIsMediaPlayingNow:
remoteVADAlignBuffer
setRemoteVADAlignBuffer:
remoteVADAlignCount
setRemoteVADAlignCount:
alignBufferQueue
setAlignBufferQueue:
audioFileWriter
setAudioFileWriter:
runningSampleCount
setRunningSampleCount:
audioTimeConverter
setAudioTimeConverter:
_isMediaPlayingNow
_remoteVADSPGRatio
_audioStream
_spgEndpointAnalyzer
_audioStreamProvider
_audioSessionProvider
_latestContext
_remoteVADAlignBuffer
_remoteVADAlignCount
_alignBufferQueue
_runningSampleCount
_audioTimeConverter
T@"CSAudioStream",&,N,V_audioStream
T@"CSSPGEndpointAnalyzer",&,N,V_spgEndpointAnalyzer
Ti,N,V_remoteVADSPGRatio
T@"<CSAudioStreamProviding>",&,N,V_audioStreamProvider
T@"<CSAudioSessionProviding>",&,N,V_audioSessionProvider
T@"CSAudioRecordContext",&,N,V_latestContext
TB,V_isMediaPlayingNow
T@"NSMutableArray",&,N,V_remoteVADAlignBuffer
TQ,N,V_remoteVADAlignCount
T@"NSObject<OS_dispatch_queue>",&,N,V_alignBufferQueue
T@"CSPlainAudioFileWriter",&,N,V_audioFileWriter
TQ,N,V_runningSampleCount
T@"CSAudioTimeConverter",&,N,V_audioTimeConverter
T@"<CSOpportuneSpeakListenerDelegate>",W,N,V_delegate
_handleListenerEvent:
disconnect
_handleListenerError:
initWithDictionary:
_sendMessage:connection:completion:
_decodeError:
notifyImplicitUtterance:audioDeviceType:audioRecordType:voiceTriggerEventInfo:otherCtxt:completion:
xpcConnection
setXpcConnection:
_xpcConnection
T@"NSObject<OS_xpc_object>",&,N,V_xpcConnection
pingpong:completion:
createAudioInjectionDeviceWithType:deviceName:deviceID:productID:completion:
injectAudio:toDeviceWithUUID:withScaleFactor:completion:
connectDeviceWithUUID:completion:
disconnectDeviceWithUUID:completion:
primaryInputDeviceUUIDWithCompletion:
fetchVoiceTriggerHeartBeatMetrics
preheat
endpointStyle
setEndpointStyle:
delay
setDelay:
startWaitTime
setStartWaitTime:
automaticEndpointingSuspensionEndTime
setAutomaticEndpointingSuspensionEndTime:
minimumDurationForEndpointer
setMinimumDurationForEndpointer:
lastEndOfVoiceActivityTime
lastStartOfVoiceActivityTime
bypassSamples
setBypassSamples:
endpointMode
setEndpointMode:
interspeechWaitTime
setInterspeechWaitTime:
endWaitTime
setEndWaitTime:
saveSamplesSeenInReset
setSaveSamplesSeenInReset:
mhId
setMhId:
Tq,N
Td,N
TB,N
T@"NSString",&,N
resetForNewRequestWithSampleRate:recordContext:
processAudioSamplesAsynchronously:
stopEndpointer
recordingStoppedForReason:
trailingSilenceDurationAtEndpoint
implDelegate
setImplDelegate:
canProcessCurrentRequest
activeChannel
setActiveChannel:
processServerEndpointFeatures:
updateEndpointerThreshold:
updateEndpointerDelayedTrigger:
shouldAcceptEagerResultForDuration:resultsCompletionHandler:
logFeaturesWithEvent:locale:
handleVoiceTriggerWithActivationInfo:
processOSDFeatures:withFrameDurationMs:
processFirstAudioPacketTimestamp:firstAudioSampleSensorTimestamp:
setEndpointerOperationMode:
fetchCurrentEndpointerOperationMode
logAnchorMachAbsTime:numSamplesProcessedBeforeAnchorTime:isAnchorTimeBuffered:
processASRFeatures:fromServer:
processTaskString:
endpointerModelVersion
elapsedTimeWithNoSpeech
T@"<CSEndpointAnalyzerDelegate>",W,N
T@"<CSEndpointAnalyzerImplDelegate>",W,N
TQ,N
T@"NSString",R,N
T@"<CSEndpointAnalyzerDelegate>",W,N,Vdelegate
T@"<CSEndpointAnalyzerImplDelegate>",W,N,VimplDelegate
TB,R,N,VcanProcessCurrentRequest
TQ,N,VactiveChannel
Tq,N,VendpointStyle
Td,N,Vdelay
Td,N,VstartWaitTime
Td,N,VautomaticEndpointingSuspensionEndTime
Td,N,VminimumDurationForEndpointer
Td,R,N,VlastEndOfVoiceActivityTime
Td,R,N,VlastStartOfVoiceActivityTime
T@"NSString",&,N,VmhId
initWithModelURL:
recordRecognitionLanguage:
setMostRecentRecognitionLanguage:
setInteractionIDforCurrentRequest:
cancelCurrentRequest
resetForNewRequest:
T@"<CSLanguageDetectorDelegate>",W,N,V_delegate
getSiriLanguageWithFallback:
getSiriLanguageWithEndpointId:fallbackLanguage:
stringWithString:
stopRecordingReason
setStopRecordingReason:
expectedStopHostTime
setExpectedStopHostTime:
_stopRecordingReason
_expectedStopHostTime
TQ,N,V_stopRecordingReason
TQ,N,V_expectedStopHostTime
deviceIsInSleep
dataWithCapacity:
appendBytes:length:
myriadHashFilePath
writeToFile:atomically:
CSMyriadSelfTriggerCoordinator:didGenerateMyriadPHashForSelfTrigger:
selfTriggerDetector:didDetectSelfTrigger:
T@"<CSMyriadSelfTriggerCoordinatorDelegate>",W,N,V_delegate
arrayWithCapacity:
setObject:atIndexedSubscript:
_emitMHEndpointLatencyInfo:withRequestMHUUID:
currentContext
initWithInstanceContext:
addPktInfoWithTimestamp:arrivalTimestamp:currentMachTime:
reportWithRequestMHUUID:
firstPktLatency
setFirstPktLatency:
trailingPktSpeechLatencies
setTrailingPktSpeechLatencies:
trailingPktLatencies
setTrailingPktLatencies:
numOfAudioPackets
setNumOfAudioPackets:
numOfValidTrailingPackets
setNumOfValidTrailingPackets:
numOfValidTrailingSpeechPackets
setNumOfValidTrailingSpeechPackets:
_firstPktLatency
_trailingPktSpeechLatencies
_trailingPktLatencies
_numOfAudioPackets
_numOfValidTrailingPackets
_numOfValidTrailingSpeechPackets
T@"NSMutableArray",&,N,V_trailingPktSpeechLatencies
T@"NSMutableArray",&,N,V_trailingPktLatencies
TQ,N,V_numOfAudioPackets
TQ,N,V_numOfValidTrailingPackets
TQ,N,V_numOfValidTrailingSpeechPackets
Td,N,V_firstPktLatency
_notifyStopCommandControl
commandControlBehaviorMonitor:willStartStreamWithContext:option:
commandControlBehaviorMonitor:didStartStreamWithContext:successfully:option:
commandControlBehaviorMonitor:willStopStream:
commandControlBehaviorMonitor:didStopStream:
isStreaming
_isCommandControlStreaming
numOfAVVCRecordingClients
_numOfAVVCRecordingClients
TQ,R,N,V_numOfAVVCRecordingClients
audioSessionEventProvidingWillSetAudioSessionActive:
audioSessionEventProvidingDidSetAudioSessionActive:
initWithCrashMonitor:
getAudioSessionState
setAudioSessionState:
_audioSessionState
audioSessionState
TQ,N,GgetAudioSessionState,V_audioSessionState
enumerateObjects:
_savedAudioFilesDirectory
URLByAppendingPathComponent:
_initWithType:pathGenerator:xorFileHandle:priority:
fileDescriptor
defaultCStringEncoding
stringWithCString:encoding:
_close
fileURLWithPath:isDirectory:
_generateTemporaryFileURL
initWithDomain:code:userInfo:
_delete
fileSystemRepresentation
initWithFileDescriptor:closeOnDealloc:
initWithType:fileHandle:priority:
cancel
_type
_url
_path
_audioFile
_asbd
_fileHandle
_underlyingError
initWithServiceName:
getCoreSpeechXPCConnection
remoteObjectProxy
installedVoiceTriggerAssetForLanguageCode:completion:
fetchRemoteVoiceTriggerAssetForLanguageCode:completion:
getCoreSpeechServiceConnection
getCurrentVoiceTriggerLocaleWithEndpointId:completion:
voiceTriggerRTModelForVersion:minorVersion:accessoryRTModelType:endpointId:downloadedModels:preinstalledModels:completion:
voiceTriggerRTModelForVersion:minorVersion:accessoryRTModelType:locale:endpointId:downloadedModels:preinstalledModels:completion:
voiceTriggerRTModelForVersion:minorVersion:locale:downloadedModels:preinstalledModels:completion:
voiceTriggerJarvisLanguageList:jarvisSelectedLanguage:completion:
requestUpdatedSATAudio:
getFirstPassRunningMode:
voiceTriggerRTModelForVersion:minorVersion:accessoryRTModelType:downloadedModels:preinstalledModels:completion:
voiceTriggerRTModelForVersion:minorVersion:downloadedModels:preinstalledModels:completion:
requestUpdatedSATAudio
getFirstPassRunningMode
setAudioFormat:
audioConverterBitrate
setEncoderBitRate:
setNumberOfChannels:
inputRecordingSampleBitDepth
setLpcmBitDepth:
setLpcmIsFloat:
setRecordContext:
setUseCustomizedRecordSettings:
recordContext
requiresHistoricalBuffer
useCustomizedRecordSettings
audioFormat
lpcmBitDepth
lpcmIsFloat
numberOfChannels
encoderBitRate
requestForLpcmRecordSettingsWithContext:
requestForOpusRecordSettingsWithContext:
requestForSpeexRecordSettingsWithContext:
initTandemWithRequest:
isSiri
setIsSiri:
_requiresHistoricalBuffer
_useCustomizedRecordSettings
_lpcmIsFloat
_isSiri
_lpcmBitDepth
_numberOfChannels
_encoderBitRate
_recordContext
_audioFormat
T@"NSObject<OS_xpc_object>",R,N
T@"CSAudioRecordContext",&,N,V_recordContext
TB,N,V_requiresHistoricalBuffer
TB,N,V_useCustomizedRecordSettings
Tq,N,V_audioFormat
Td,N,V_sampleRate
TI,N,V_lpcmBitDepth
TB,N,V_lpcmIsFloat
TI,N,V_numberOfChannels
TI,N,V_encoderBitRate
TB,N,V_isSiri
notifyCallbackWithOption:
setCallback:
_subscribeEventMonitors
_addSelfTriggerDetectorEnabledConditions
subscribeEventMonitor:
voiceTriggerEnabledPolicy
addConditions:
currentBuiltinSpeakerState
setVoiceTriggerEnabledPolicy:
_voiceTriggerEnabledPolicy
T@"CSPolicy",&,N,V_voiceTriggerEnabledPolicy
T@"NSString",C,N,V_deviceId
sharedVoiceTriggerClient
startManager
_createClearLoggingFileTimer
registerPostBuildInstallService
_startClearLoggingFilesTimer
supportHearstVoiceTrigger
setDelegate:forType:
supportRemoraVoiceTrigger
supportJarvisVoiceTrigger
shouldRunVTOnCS
supportBluetoothDeviceVoiceTrigger
_getAudioRecorderWithError:
audioProviders
setLatestRecordContext:
initWithAudioStreamHandleId:audioStreamType:audioRecordContext:audioRecorder:
setAudioProviderDelegate:
initWithAudioRecorder:
audioRecorderWithQueue:error:
setAudioRecorder:
setAsset:
daysBeforeRemovingLogFiles
removeLogFilesOlderThanNDays:
removeOppotunisticAudioLoggingOlderThanNDays:
_handleClearLoggingFileTimer
CSAudioServerCrashMonitorDidReceiveServerCrash:
CSAudioServerCrashMonitorDidReceiveServerRestart:
activationEventNotificationHandler:event:completion:
audioRecorderRecordHardwareConfigurationDidChange:toConfiguration:
audioRecorderDidFinishAlertPlayback:ofType:error:
audioRecorderBeginRecordInterruption:
audioRecorderBeginRecordInterruption:withContext:
audioRecorderEndRecordInterruption:
audioRecorder:willSetAudioSessionActive:
audioRecorder:didSetAudioSessionActive:
voiceTriggerDetectedOnAOP:
audioRecorderDisconnected:
audioRecorderLostMediaserverd:
audioRecorderBuiltInAudioStreamInvalidated:error:
audioProviderInvalidated:streamHandleId:
opportuneSpeakEventMonitor:didStreamStateChanged:
audioFingerprintProvider
_getVoiceTriggerAssetIfNeeded:
fetchAcousticAnalyzer
registerSpeechController:
registerSiriClientProxy:
audioProviderWithUUID:
audioProviderWithContext:error:
audioProviderWithStreamID:
fetchFallbackAudioSessionReleaseProvider
_reinitializeSmartSiriVolumeWithAsset:
assetQueryQueue
setAssetQueryQueue:
audioRecorder
setAudioProviders:
fallbackAudioSessionReleaseProvider
setFallbackAudioSessionReleaseProvider:
clientController
setClientController:
clearLoggingFileTimer
setClearLoggingFileTimer:
clearLoggingFileTimerCount
setClearLoggingFileTimerCount:
opportuneSpeakListnerTestService
setOpportuneSpeakListnerTestService:
postBuildInstallService
setPostBuildInstallService:
ssvManager
setSsvManager:
_assetQueryQueue
_audioRecorder
_audioProviders
_fallbackAudioSessionReleaseProvider
_clientController
_clearLoggingFileTimer
_clearLoggingFileTimerCount
_opportuneSpeakListnerTestService
_postBuildInstallService
_ssvManager
T@"NSObject<OS_dispatch_queue>",&,N,V_assetQueryQueue
T@"CSAudioRecorder",&,N,V_audioRecorder
T@"NSMutableDictionary",&,N,V_audioProviders
T@"CSFallbackAudioSessionReleaseProvider",&,N,V_fallbackAudioSessionReleaseProvider
T@"<CSSpeechManagerDelegate>",W,N,V_clientController
T@"NSObject<OS_dispatch_source>",&,N,V_clearLoggingFileTimer
Tq,N,V_clearLoggingFileTimerCount
T@"CSOpportuneSpeakListnerTestService",&,N,V_opportuneSpeakListnerTestService
T@"CSPostBuildInstallService",&,N,V_postBuildInstallService
T@"CSSmartSiriVolumeManager",&,N,V_ssvManager
addNumSamples:hostTime:
notifyTrailingSilenceDurationAtEndpoint:
estimatedSpeechEndHostTime
numAudioSampleForwarded
setNumAudioSampleForwarded:
lastAudioChunkHostTime
setLastAudioChunkHostTime:
endPointNotified
setEndPointNotified:
setTrailingSilenceDurationAtEndpoint:
_endPointNotified
_numAudioSampleForwarded
_lastAudioChunkHostTime
_trailingSilenceDurationAtEndpoint
TQ,N,V_numAudioSampleForwarded
TQ,N,V_lastAudioChunkHostTime
TB,N,V_endPointNotified
Td,N,V_trailingSilenceDurationAtEndpoint
_notifyObserver:withClamshellState:
CSClamshellStateMonitor:didReceiveClamshellStateChange:
isClamshellClosed
_didReceiveClamshellStateChangeNotification:
contextForBuiltInVoiceTrigger
commandControlListener:didStopUnexpectly:
commandControlListener:hasLPCMBufferAvailable:
T@"<CSCommandControlListenerDelegate>",W,N,V_delegate
getStringForKey:category:default:
flexKwdConfigFile
flexKwdThresholdFile
initWithDownloadOption:
defaultController
addObserver:forAssetType:
_createPeriodicalDownloadTimer
_startPeriodicalDownload
_stopPeriodicalDownload
_fetchRemoteMetaData
_canFetchRemoteAsset:
assetOfType:language:
installedAssetOfType:language:
allInstalledAssetsOfType:language:
installedAssetOfType:language:completion:
assetOfType:language:compatibilityVersion:completion:
getInstalledAssetofType:completion:
fetchRemoteMetaOfType:
supportHybridEndpointer
supportAdBlocker
supportsSpeakerRecognitionAssets
assetForCurrentLanguageOfType:completion:
CSAssetManagerDidDownloadNewAsset:
CSVoiceTriggerAssetMetaUpdateMonitor:didReceiveNewVoiceTriggerAssetMetaData:
CSSpeechEndpointAssetMetaUpdateMonitor:didReceiveNewSpeechEndpointAssetMetaData:
CSAdBlockerMetaUpdateMonitor:didReceiveNewAdBlockerAssetMetaData:
CSAssetController:didDownloadNewAssetForType:
CSSpeakerRecognitionAssetMetaUpdateMonitor:didReceiveNewSpeakerRecognitionAssetMetaData:
CSLanguageCodeUpdateMonitor:didReceiveLanguageCodeChanged:
assetForCurrentLanguageOfType:
installedAssetForCurrentLanguageOfType:
installedAssetForCurrentLanguageOfType:completion:
assetOfType:providerType:language:completion:
currentLanguageCode
removeObserver:forAssetType:
_enablePolicy
_currentLanguageCode
_downloadingOption
_downloadTimer
_downloadTimerCount
endpointerOperationMode
useAutomaticEndpointing
csAudioProcessingQueuePriority
getFixedHighPrioritySerialQueueWithLabel:priority:
getEndpointerModelVersionWithReply:
timeIntervalSinceDate:
wordCount
trailingSilenceDuration
eosLikelihood
pauseCounts
silencePosterior
taskName
processedAudioDurationInMilliseconds
processServerFeaturesWithWordCount:trailingSilenceDuration:eosLikelihood:pauseCounts:silencePosterior:taskName:processedAudioDurationInMilliseconds:
getElapsedTimeNoSpeechWithReply:
getTrailingSilenceDurationAtEndpointWithReply:
getEndPointAnalyzerTypeWithReply:
resetForVoiceTriggerTwoShotWithSampleRate:
remoteObjectProxyWithErrorHandler:
didDetectStartpointAtTime:
didDetectHardEndpointAtTime:withMetrics:
didDetectHardEndpointAtTime:withTotalAudioRecorded:endpointBufferHostTime:featuresAtEndpoint:endpointerType:serverFeatureLatencyDistribution:additionalMetrics:
_setQueue:
endpointerConnection
xpcConnectionQueue
setEndpointerConnection:
endpointer:didDetectStartpointAtTime:
endpointer:didDetectHardEndpointAtTime:withMetrics:
initWithTotalAudioRecorded:endpointBufferHostTime:featuresAtEndpoint:endpointerType:serverFeatureLatencyDistribution:additionalMetrics:
endPointAnalyzerType
resetForNewRequestWithSampleRate:recordContext:recordOption:voiceTriggerInfo:
endpointerDelegate
setEndpointerDelegate:
setXpcConnectionQueue:
xpcClientQueue
setXpcClientQueue:
setRemoteObjectProxy:
_endpointerDelegate
_endpointerConnection
_xpcConnectionQueue
_xpcClientQueue
_remoteObjectProxy
T@"NSXPCConnection",&,N,V_endpointerConnection
T@"NSObject<OS_dispatch_queue>",&,N,V_xpcConnectionQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_xpcClientQueue
T@,&,N,V_remoteObjectProxy
initWithDataSource:assetsProvider:
addDelegate:
removeDelegate:
startWithNviContext:didStartHandler:
stopWithDidStopHandler:
sigType
initWithMachServiceName:
xpcConnection:hasEntitlement:
clientConnections
listener:shouldAcceptNewConnection:
notifyClientsWithBlock:
initWithMachService:withServiceInterface:withServiceObject:withDelegateInterface:
resumeConnection
setClientConnections:
machServiceName
setMachServiceName:
_listener
_exportedInterface
_remoteInterface
_proxyObject
_clientConnections
_machServiceName
T@"NSMutableArray",&,N,V_clientConnections
T@"NSString",&,N,V_machServiceName
programmableAudioInjectionEnabled
initWithQueue:error:
initWithBlob:isEarlyDetected:
samplesFed
setSamplesFed:
setBestStart:
setBestEnd:
setBestScore:
isSecondChance
setIsSecondChance:
setIsEarlyDetect:
_isSecondChance
_isEarlyDetect
_bestScore
_samplesFed
_bestStart
_bestEnd
TQ,N,V_samplesFed
TQ,N,V_bestStart
TQ,N,V_bestEnd
Tf,N,V_bestScore
TB,N,V_isSecondChance
TB,N,V_isEarlyDetect
initWithBlob:
checkForTriggerWithBytes:withNumberOfSamples:
processAudioBytes:withNumberOfSamples:
_currentBlob
_activeChannel
TQ,N,V_activeChannel
T@"<CSKeywordAnalyzerNDEAPIScoreDelegate>",W,N,V_delegate
startController
supportPhatic
supportSessionActivateDelay
supportLazySessionActivation
initWithEndpointId:xpcClientFactory:endpointer:continuousVoiceTrigger:siriVolumeController:mediaPlayingMonitor:alarmMonitor:timerMonitor:sacInfoMonitor:audioSessionController:supportPhatic:supportHearstVoiceTrigger:supportTriagleModeSessionActivationRetry:supportSessionActivateDelay:supportLazySessionActivtion:
setEndpointerImplDelegate:
endpointerProxy
twoShotNotificationEnabled
_currentAudioRecorderSampleRate
_createMediaPlayingMonitor
_initializeMediaPlayingState
_createAlarmMonitor
_initializeAlarmState
_createTimerMonitor
_initializeTimerState
supportSmartVolume
audioSessionActivationDelay
defaultFactory
initWithQueue:instanceContext:
initWithQueue:
addListener:
_setMediaPlaybackState:isInterrupted:
_setSoundPlayingState
getPlaybackStateWithCompletion:
_setAlarmIsPlaying:
getFiringAlarmIDsWithCompletion:
_setTimerIsPlaying:
getFiringTimerIDsWithCompletion:
setCurrentRecordContext:error:
isAttentiveSiriEnabled
_refreshSpeakerRecognitionAssets
_shouldResetContextAtPrepare
audioRecordContext
_fetchAudioProviderWithContext:
sessionProvider
enableSmartRoutingConsideration:
isTriggeredFromHearst
_shouldFetchVoiceTriggerInfo
_shouldFetchRaiseToSpeakInfo
_fetchLastTriggerInfo
_activateAudioSessionWithReason:delay:delayRequested:error:
domain
_activateAudioSessionWithReason:error:
prepareAudioStreamSyncWithRequest:error:
streamProvider
isNarrowBand
_setupDownsamplerIfNeeded
_setupAudioConverter:isNarrowBand:
recordRoute
_createAudioPowerMeterIfNeeded
triggerInfoForContext:completion:
createAcousticMetaFileForContext:withContext:
sendAcousticGradingDataToNearbyPeer
acousticSLResultForContext:completion:
isVoiceTriggered
isServerInvoked
isHomePressed
isTVRemote
isDeviceRoleStereo
_isDelayedDuckingSupportedContext
hostTimeToTimeInterval:
logHybridEndpointFeaturesWithEvent:locale:
_scheduleActivateAudioSessionWithDelay:sessionActivateReason:scheduleReason:validator:completion:
_cancelPendingAudioSessionActivateForReason:
_lazyActivateAudioSessionWithReason:error:
speechController:willSetAudioSessionActive:
speechController:didSetAudioSessionActive:
_doActivateAudioSessionWithReason:error:
isDictation
activateAudioSessionWithReason:dynamicAttribute:bundleID:error:
isAudioRecordTypeSupportedByRemora
setType:
_updateRecordContextIfNeeded:
setAudioRecordContext:
setCurrentContext:error:
prewarmAudioSessionWithError:
_teardownAudioProviderIfNeeded
_fetchFallbackAudioSessionReleaseProviding
fallbackDeactivateAudioSession:error:
recordSettings
numberWithInt:
lpcmInt16NarrowBandASBD
lpcmInt16ASBD
setDictationLanguages:
setCurrentKeyboard:
setWasLanguageToggled:
setMultilingualKeyboardLanguages:
setKeyboardConvoLanguagePriors:
setKeyboardGlobalLanguagePriors:
setPreviousMessageLanguage:
setGlobalLastKeyboardUsed:
setDictationLanguagePriors:
setConversationalMessages:
_isRecordRouteBuiltinMic
setAVVCAlertBehavior:
supportOpportunisticZLL
setUseOpportunisticZLL:
setStartRecordingHostTime:
setRequestHistoricalAudioDataWithHostTime:
setRequestMHUUID:
setSiriSessionUUID:
setDisableEndpointer:
setDisableLocalSpeechRecognizer:
_shouldSetStartSampleCount
setRequestHistoricalAudioDataSampleCount:
setStartRecordingSampleCount:
_shouldSetStartSampleCountForRTS
setRequireSingleChannelLookup:
setSelectedChannel:
_setupSpeakerRecognitionController
_startPhaticDecision
lpcmMonoNonInterleavedWithRemoteVADASBD
lpcmMonoInterleavedWithRemoteVADASBD
createAudioFileWriterForRemoteVADWithInputFormat:outputFormat:withLoggingUUID:
createAudioFileWriterWithInputFormat:outputFormat:withLoggingUUID:
_shouldUseLanguageDetector:
_createLanguageDetectorIfNeeded
_languageDetectorOptionFromSettings:
setSamplingRate:
languageDetectorDelegate
isAlertBehaviorOverridedBeep
notifyWillStartStreamWithContext:option:
audioDeviceInfo
speechControllerDidStartRecording:audioDeviceInfo:successfully:error:
speechControllerDidStartRecording:successfully:error:
_shouldTrackLaunchLatency
submitVoiceTriggerIssueReport:
notifyDidStartStreamWithContext:successfully:option:withEventUUID:
_canPlayPhaticDuringMediaPlayback
speechControllerDidDetectVoiceTriggerTwoShot:atTime:wantsAudibleFeedback:
speechControllerDidDetectVoiceTriggerTwoShot:atTime:
shouldDelayPhaticForMyriadDecision
_shouldSchedulePhaticAtStartRecording
_scheduledPhaticDelay
speechControllerRequestsOperation:forReason:completion:
_phaticPlaybackReason
isBuiltInVoiceTriggered
isHearstVoiceTriggered
isJarvisVoiceTriggered
isRemoraVoiceTriggered
isRTSTriggered
startRecordingWithSettings:error:
notifyWillStopStream:reason:
_didStopForReason:
speechControllerDidDeliverLastBuffer:forReason:estimatedSpeechEndHostTime:
canPerformDelayedStop
supportsSiriLiminal
_shouldReportEstimatedSpeechEndHostTime
speechControllerDidStopRecording:audioDeviceInfo:forReason:estimatedSpeechEndHostTime:
speechControllerDidStopRecording:forReason:estimatedSpeechEndHostTime:
addContextKey:withContext:
addContextKey:fromMetaFile:
_shouldFetchAcousticSLResult
_addAcousticSLInfo
_deviceAudioLoggingWithFileWriter:
notifyDidStopStream:withEventUUID:
_logRecordingStopErrorIfNeeded:
subChunkFrom:numSamples:
remoteVADSubChunkFrom:numSamples:numAudioSamplesPerRemoteVAD:
setRemoteVAD:
_audioStreamProvdider:audioBufferAvailable:
data
convertToShortLPCMBufFromFloatLPCMBuf:
sampleByteDepth
processFloatBuffer:stride:inFrameToProcess:
processShortBuffer:stride:inFrameToProcess:
startSampleCount
arrivalHostTimeToAudioRecorder
wasBuffered
initWithData:numChannels:numSamples:sampleByteDepth:startSampleCount:hostTime:arrivalHostTimeToAudioRecorder:wasBuffered:remoteVAD:
addSamples:timestamp:arrivalTimestampToAudioRecorder:
speechControllerLPCMRecordBufferAvailable:buffer:recordedAt:
speechControllerLPCMRecordBufferAvailable:buffer:
_fetchAudioDecoderForTV:
packets
timeStamp
addPackets:audioStreamHandleId:remoteVAD:timestamp:arrivalTimestampToAudioRecorder:wasBuffered:receivedNumChannels:
avgPower
setCachedAvgPower:
peakPower
setCachedPeakPower:
speechControllerRecordBufferAvailable:buffers:durationInSec:recordedAt:audioDeviceInfo:
speechControllerRecordBufferAvailable:buffers:durationInSec:recordedAt:
speechControllerRecordHardwareConfigurationDidChange:toConfiguration:
speechControllerDidFinishAlertPlayback:ofType:error:
speechControllerBeginRecordInterruption:
speechControllerBeginRecordInterruption:withContext:
speechControllerEndRecordInterruption:
speechControllerDidUpdateSmartSiriVolume:forReason:
narrowBandOpusConverter
opusConverter
alertProvider
playAlertSoundForType:
playRecordStartingAlertAndResetEndpointer
audioMeterProvider
getPeakPowerDB
cachedPeakPower
getAveragePowerDB
cachedAvgPower
initWithSampleRate:
channelForOutputReference
speechControllerRequestsOperation:forReason:
audioMetricProvider
audioMetric
supportNonInterruptibleSiri
submitAudioIssueReport:
speexASBD
opusASBD
_createAudioProviderFromXPCWithContext:
clientForAudioProviding
_setupAudioProviderFromXPC:context:
setStreamProvider:
setSessionProvider:
setAlertProvider:
setAudioMeterProvider:
setAudioMetricProvider:
setAudioSessionDelegate:
setAudioAlertDelegate:
clientForFallbackAudioSessionReleaseProviding
allKeys
initWithData:encoding:
_getSpeechIdentifier
generateDeviceAudioLogging:speechId:
isStarkTriggered
debugLogPath
volumeEstimate
getVolumeForTTSType:
setIsMediaPlayingOnAccessory:isMediaPlaying:isInterrupted:interruptedTime:
setIsAlarmPlayingOnAccessory:isAlarmPlaying:
setIsTimerPlayingOnAccessory:isTimerPlaying:
sharedController
isSmartSiriVolumeAvailable
audioConverterDidConvertPackets:packets:durationInSec:timestamp:arrivalTimestampToAudioRecorder:
didTTSVolumeChange:forReason:
audioAlertProvidingDidFinishAlertPlayback:ofType:error:
audioDecoderDidDecodePackets:audioStreamHandleId:buffer:remoteVAD:timestamp:arrivalTimestampToAudioRecorder:wasBuffered:receivedNumChannels:
endpointer:detectedTwoShotAtTime:
endpointer:reportEndpointBufferHostTime:firstBufferHostTime:
nowPlayingObserver:playbackStateDidChangeFrom:to:lastPlayingDate:
nowPlayingObserverNowPlayingInfoDidChange:
nowPlayingObserver:proxyGroupPlayerStateDidChangeFrom:to:
clockAlarmObserver:alarmDidFire:
clockAlarmObserver:alarmDidDismiss:
clockAlarmObserver:snapshotDidUpdateFrom:to:
clockTimerObserver:timerDidFire:
clockTimerObserver:timerDidDismiss:
clockTimerObserver:snapshotDidUpdateFrom:to:
audioSessionProviderBeginInterruption:
audioSessionProviderBeginInterruption:withContext:
audioSessionProviderEndInterruption:
audioSessionProvider:willSetAudioSessionActive:
audioSessionProvider:didSetAudioSessionActive:
audioSessionProvider:providerInvalidated:
audioSessionProvider:didChangeContext:
continuousVoiceTrigger:detectedVoiceTriggerResult:
continuousVoiceTrigger:detectedSilenceAfterVoiceTriggerAt:
initializeRecordSessionWithRecordContext:
prepareRecordWithSettings:error:
_performPendingAudioSessionActivateForReason:
prewarmAudioSession
resetAudioSession
releaseAudioSession
releaseAudioSession:
getLPCMAudioStreamBasicDescription
setSynchronousCallbackEnabled:
getRecordBufferDuration
startRecording:
stopRecordingWithOptions:
peakPowerForOutputReference
averagePowerForOutputReference
outputReferenceChannel
voiceTriggerInfo
fetchAudioMetricsWithCompletion:
endpointAnalyzer
setEndpointAnalyzerDelegate:
resetEndpointer
_contextToString:
getSmartSiriVolume
languageDetectorSetMostRecentRecognitionLanguage:
cancelCurrentLanguageDetectorRequest
setLanguageDetectorInteractionID:
beginWaitingForMyriad
endWaitingForMyriadWithDecision:
setLanguageDetectorDelegate:
speakerIdDelegate
setSpeakerIdDelegate:
setSupportPhatic:
setSupportHearstVoiceTrigger:
supportTriagleModeSessionActivationRetry
setSupportTriagleModeSessionActivationRetry:
setSupportSessionActivateDelay:
supportLazySessionActivtion
setSupportLazySessionActivtion:
setEndpointerProxy:
isOpus
setIsOpus:
isSiriClientListening
setIsSiriClientListening:
setIsNarrowBand:
serverLoggingWriter
setServerLoggingWriter:
volumeController
setVolumeController:
recordEventUUID
setRecordEventUUID:
isAudioSessionActivated
setIsAudioSessionActivated:
deviceRoleIsStereo
setDeviceRoleIsStereo:
speakerRecognitionScores
setSpeakerRecognitionScores:
setTwoShotNotificationEnabled:
isMediaPlaying
setIsMediaPlaying:
isAlarmPlaying
setIsAlarmPlaying:
isTimerPlaying
setIsTimerPlaying:
isSoundPlaying
setIsSoundPlaying:
isRemoteVADAvailableStream
setIsRemoteVADAvailableStream:
myriadPreventingTwoShotFeedback
setMyriadPreventingTwoShotFeedback:
needsPostGain
setNeedsPostGain:
speechEndHostTimeEstimator
setSpeechEndHostTimeEstimator:
bundleIdFromDictation
setBundleIdFromDictation:
languageDetector
setLanguageDetector:
shouldUseLanguageDetectorForCurrentRequest
setShouldUseLanguageDetectorForCurrentRequest:
pendingAudioSessionActivationToken
setPendingAudioSessionActivationToken:
pendingAudioSessionActivationCompletion
setPendingAudioSessionActivationCompletion:
pendingAudioSessionActivationReason
setPendingAudioSessionActivationReason:
setAudioSessionActivationDelay:
xpcClientFactory
setXpcClientFactory:
duckAudioXPCClient
setDuckAudioXPCClient:
powerMeter
setPowerMeter:
didDeliverLastBuffer
setDidDeliverLastBuffer:
didDeliverFirstSpeechPacket
setDidDeliverFirstSpeechPacket:
requestMHUUID
setCanPerformDelayedStop:
endpointLatencyInfo
setEndpointLatencyInfo:
requestedStopRecordingOptions
setRequestedStopRecordingOptions:
numTrailingSamplesAfterSchedulingStop
setNumTrailingSamplesAfterSchedulingStop:
maxAllowedTrailingSamplesAfterSchedulingStop
setMaxAllowedTrailingSamplesAfterSchedulingStop:
decodersForTV
setDecodersForTV:
decoderProcessedSampleCountForTV
setDecoderProcessedSampleCountForTV:
logEventUUID
setLogEventUUID:
ssvLogFilePath
setSsvLogFilePath:
mediaPlayingObserverQueue
setMediaPlayingObserverQueue:
mediaPlayingMonitor
setMediaPlayingMonitor:
alarmMonitor
setAlarmMonitor:
timerMonitor
setTimerMonitor:
volumeMonitor
setVolumeMonitor:
setAudioDeviceInfo:
setupStarted
setSetupStarted:
audioSessionController
setAudioSessionController:
sacInfoMonitor
setSacInfoMonitor:
_contextResetQueue
_opusAudioConverter
_narrowBandOpusConverter
_audioConverter
_downsampler
_requestedRecordSettings
_lastVoiceTriggerInfo
_lastRTSTriggerInfo
_audibleFeedbackQueue
_twoShotAudibleFeedbackDecisionGroup
_supportPhatic
_supportHearstVoiceTrigger
_supportTriagleModeSessionActivationRetry
_supportSessionActivateDelay
_supportLazySessionActivtion
_isOpus
_isSiriClientListening
_isNarrowBand
_isAudioSessionActivated
_deviceRoleIsStereo
_twoShotNotificationEnabled
_isMediaPlaying
_isAlarmPlaying
_isTimerPlaying
_isSoundPlaying
_isRemoteVADAvailableStream
_myriadPreventingTwoShotFeedback
_needsPostGain
_shouldUseLanguageDetectorForCurrentRequest
_didDeliverLastBuffer
_didDeliverFirstSpeechPacket
_canPerformDelayedStop
_setupStarted
_cachedAvgPower
_cachedPeakPower
_languageDetectorDelegate
_speakerIdDelegate
_endpointerProxy
_streamProvider
_sessionProvider
_alertProvider
_audioMeterProvider
_audioMetricProvider
_serverLoggingWriter
_volumeController
_recordEventUUID
_speakerRecognitionScores
_speechEndHostTimeEstimator
_bundleIdFromDictation
_languageDetector
_pendingAudioSessionActivationToken
_pendingAudioSessionActivationCompletion
_pendingAudioSessionActivationReason
_audioSessionActivationDelay
_xpcClientFactory
_duckAudioXPCClient
_powerMeter
_requestMHUUID
_endpointLatencyInfo
_requestedStopRecordingOptions
_numTrailingSamplesAfterSchedulingStop
_maxAllowedTrailingSamplesAfterSchedulingStop
_decodersForTV
_decoderProcessedSampleCountForTV
_logEventUUID
_ssvLogFilePath
_mediaPlayingObserverQueue
_mediaPlayingMonitor
_alarmMonitor
_timerMonitor
_volumeMonitor
_audioDeviceInfo
_audioSessionController
_sacInfoMonitor
TB,N,V_supportPhatic
TB,N,V_supportHearstVoiceTrigger
TB,N,V_supportTriagleModeSessionActivationRetry
TB,N,V_supportSessionActivateDelay
TB,N,V_supportLazySessionActivtion
T@"CSEndpointerProxy",&,N,V_endpointerProxy
T@"CSAudioRecordContext",&,N,V_audioRecordContext
T@"<CSAudioStreamProviding>",&,N,V_streamProvider
T@"<CSAudioSessionProviding>",&,N,V_sessionProvider
T@"<CSAudioAlertProviding>",&,N,V_alertProvider
T@"<CSAudioMeterProviding>",&,N,V_audioMeterProvider
T@"<CSAudioMetricProviding>",&,N,V_audioMetricProvider
TB,N,V_isOpus
TB,N,V_isSiriClientListening
TB,N,V_isNarrowBand
T@"CSSelectiveChannelAudioFileWriter",&,N,V_serverLoggingWriter
T@"CSSmartSiriVolumeController",&,N,V_volumeController
T@"NSString",&,N,V_recordEventUUID
TB,N,V_isAudioSessionActivated
TB,N,V_deviceRoleIsStereo
T@"NSDictionary",&,N,V_speakerRecognitionScores
TB,N,V_twoShotNotificationEnabled
TB,N,V_isMediaPlaying
TB,N,V_isAlarmPlaying
TB,N,V_isTimerPlaying
TB,N,V_isSoundPlaying
TB,N,V_isRemoteVADAvailableStream
TB,N,V_myriadPreventingTwoShotFeedback
TB,N,V_needsPostGain
T@"CSSpeechEndHostTimeEstimator",&,N,V_speechEndHostTimeEstimator
T@"NSString",&,N,V_bundleIdFromDictation
T@"CSLanguageDetector",&,N,V_languageDetector
TB,N,V_shouldUseLanguageDetectorForCurrentRequest
T@"NSUUID",&,N,V_pendingAudioSessionActivationToken
T@?,C,N,V_pendingAudioSessionActivationCompletion
TQ,N,V_pendingAudioSessionActivationReason
Td,N,V_audioSessionActivationDelay
T@"CSXPCClientFactory",&,N,V_xpcClientFactory
T@"CSXPCClient",&,N,V_duckAudioXPCClient
Tf,N,V_cachedAvgPower
Tf,N,V_cachedPeakPower
T@"CSAudioPowerMeter",&,N,V_powerMeter
TB,N,V_didDeliverLastBuffer
TB,N,V_didDeliverFirstSpeechPacket
T@"NSString",&,N,V_requestMHUUID
TB,N,V_canPerformDelayedStop
T@"CSEndpointLatencyInfo",&,N,V_endpointLatencyInfo
T@"CSStopRecordingOptions",&,N,V_requestedStopRecordingOptions
TQ,N,V_numTrailingSamplesAfterSchedulingStop
TQ,N,V_maxAllowedTrailingSamplesAfterSchedulingStop
T@"NSMutableDictionary",&,N,V_decodersForTV
TQ,N,V_decoderProcessedSampleCountForTV
T@"NSString",&,N,V_logEventUUID
T@"NSString",&,N,V_ssvLogFilePath
T@"NSObject<OS_dispatch_queue>",&,N,V_mediaPlayingObserverQueue
T@"SOMediaNowPlayingObserver",&,N,V_mediaPlayingMonitor
T@"SOClockAlarmObserver",&,N,V_alarmMonitor
T@"SOClockTimerObserver",&,N,V_timerMonitor
T@"CSVolumeMonitor",&,N,V_volumeMonitor
T@"CSAudioDeviceInfo",&,N,V_audioDeviceInfo
T@"NSUUID",R,C,N,V_endpointId
TB,N,V_setupStarted
T@"CSAudioSessionController",&,N,V_audioSessionController
T@"CSSACInfoMonitor",&,N,V_sacInfoMonitor
T@"<CSSpeechControllerDelegate>",W,N,V_delegate
T@"<CSLanguageDetectorDelegate>",W,N,V_languageDetectorDelegate
T@"<CSSpeakerIdentificationDelegate>",W,N,V_speakerIdDelegate
T@"<CSEndpointAnalyzer>",R,N
ssrConnection
setSsrConnection:
_ssrConnection
T@"NSXPCConnection",&,N,V_ssrConnection
T@"<CSSSRXPCClientDelegate>",W,N,V_delegate
setCtx:
detectedToken
setDetectedToken:
triggerMachTime
setTriggerMachTime:
triggerAbsStartSampleId
setTriggerAbsStartSampleId:
_ctx
_detectedToken
_triggerMachTime
_triggerAbsStartSampleId
T@"CSAttSiriRequestContext",C,N,V_ctx
T@"NSString",&,N,V_detectedToken
TQ,N,V_triggerMachTime
TQ,N,V_triggerAbsStartSampleId
createRTModelWithLocale:
hearstRTModelWithMajorVersion:minorVersion:locale:
fileExistsAtPath:
dataWithContentsOfFile:
_sha1:
substringWithRange:
_sha256:
initWithData:hash:locale:digest:signature:certificate:
rtModelWithAccessoryRTModelType:majorVersion:minorVersion:locale:
localeMapWithName:
remoraRTModelLocaleMap
hearstRTModelLocaleMap
stringWithCapacity:
RTModelWithFallbackLanguage:
latestHearstRTModelForLocale:
remoraRTModelWithMajorVersion:minorVersion:locale:
jarvisRTModelLocaleMap
rtModelLocaleMapWithModelType:
_prepareWithOptions:audioSession:completion:
_startWithOptions:audioSession:preparationHandler:executionHandler:finalizationHandler:
_stop:
_handleBeginInterruption
_handleEndInterruption:
errorWithCode:
initWithBlock:defaultValue:
status
error
_resetPlayerItem
itemURL
itemData
assetWithData:contentType:options:
initWithAsset:
errorWithCode:description:
invokeWithValue:
initWithDispatchQueue:
volume
setVolume:
setActionAtItemEnd:
setAudioSession:
replaceCurrentItemWithPlayerItem:
currentItem
initWithTimeoutInterval:onQueue:timeoutHandler:
errorWithCode:description:underlyingError:
initWithQueue:qosClass:asynchronous:
_finalizeWithError:
setRate:
playerItemDidPlayToEndTime:
playerItemFailedToPlayToEndTime:
seekToTime:toleranceBefore:toleranceAfter:completionHandler:
seekToTime:toleranceBefore:toleranceAfter:
initWithQueue:request:options:
prepareWithOptions:audioSession:completion:
startWithOptions:audioSession:preparationHandler:executionHandler:finalizationHandler:
stop:completion:
handleBeginInterruption
handleEndInterruption:
request
options
T@"AFAudioPlaybackRequest",R,N
_isActive
_player
_playerItem
_audioSession
_completion
_request
_options
T@"AFAudioPlaybackRequest",R,N,V_request
TQ,R,N,V_options
_serviceProxyWithErrorHandler:
upperCaseString:withReply:
firstObject
stringByStandardizingPath
trainPersonalizedLMWithLanguage:configuration:asset:fides:activity:completion:
trainPersonalizedLMWithLanguage:configuration:fides:write:completion:
trainPersonalizedLMWithLanguage:configuration:asset:directory:completion:
trainPersonalizedLMWithLanguage:configuration:fides:activity:completion:
trainGlobalNNLMwithFidesSessionURL:completion:
buildPhoneticMatchWithLanguage:saveIntermediateFsts:completion:
generateAudioWithTexts:language:completion:
initialize
upperCaseString:completion:
trainPersonalizedLMWithLanguage:directory:completion:
_smtConnection
clientForAudioSessionInfoProviding
clientForSmartSiriVolumeProviding
clientForMacOSDuckAudioDevice
initWithStreamID:atStartHostTime:
avvcAlertBehavior
setStartAlert:
setStopAlert:
setStopOnErrorAlert:
skipAlertBehavior
setSkipAlert:
_alertBehaviorTypeFromAVVCOberrideType:
setStartAlertBehavior:
setStopAlertBehavior:
setErrorAlertBehavior:
startAlertBehavior
_avvcAlertOverrideType:
stopAlertBehavior
errorAlertBehavior
numberWithInteger:
avvcStartRecordSettingsWithAudioStreamHandleId:
_setupSignalProviders:
mapTableWithKeyOptions:valueOptions:
strRepForNviSignalType:
strRepForNviDataSourceType:
signalProvidersMapForContext:
hashTableWithOptions:
_startSignalProvidersWithContext:
_startDataSourcesWithContext:
_stopDataSources
_stopCurrentlyRunningSignalProviders
_iterateSignalMask:withHandler:
initWithAssetsProvider:dataSourceMap:signalProviderToDataSourceMap:
startWithNviContext:
registerSignalProviderDelegate:forSignalTypes:
unregisterSignalProviderDelegate:forSignalType:
registerSignalProviderDelegateForAllSignalTypes:
unregisterSignalProviderDelegateForAllSignalTypes:
assetsProvider
setAssetsProvider:
dataSrcMap
setDataSrcMap:
sigProvidersMap
setSigProvidersMap:
currActiveSigProvTypes
setCurrActiveSigProvTypes:
currActiveDataSourceTypes
setCurrActiveDataSourceTypes:
_assetsProvider
_dataSrcMap
_sigProvidersMap
_currActiveSigProvTypes
_currActiveDataSourceTypes
T@"<NviAssetsProvider>",&,N,V_assetsProvider
T@"NSDictionary",&,N,V_dataSrcMap
T@"NSMapTable",&,N,V_sigProvidersMap
T@"NSHashTable",&,N,V_currActiveSigProvTypes
T@"NSHashTable",&,N,V_currActiveDataSourceTypes
sendXPCClientType
_sendMessageAndReplySync:connection:error:
setAudioSessionProvidingDelegate:
setAudioAlertProvidingDelegate:
initWithAudioStreamProvider:streamName:streamRequest:
createPrepareAudioStreamMessageWithRequest:
createStartAudioStreamMessageWithOption:
createStopAudioStreamMessage
_handleListenerMessage:
_handleSessionProvidingDelegateMessageBody:
_handleStreamProvidingDelegateMessageBody:
_handleAlertProvidingDelegateMessageBody:
_handleSessionInfoProvidingDelegateMessageBody:
_handleListenerDisconnectedError:
_handleAlertProvidingDelegateDidFinishAlertPlayback:
audioAlertProvidingDelegate
_handleSessionProvidingDelegateBeginInterruption:
_handleSessionProvidingDelegateBeginInterruptionWithContext:
_handleSessionProvidingDelegateEndInterruption:
_handleSessionProvidingDelegateWillSetAudioSession:
_handleSessionProvidingDelegateDidSetAudioSession:
_handleSessionProvidingDelegateStreamHandleIdInvalidation:
_handleSessionProvidingDelegateDidChangeContext:
audioSessionProvidingDelegate
_handleSessionInfoProvidingDelegateInterruptionNotification:
_handleSessionInfoProvidingDelegateRouteChangeNotification:
_handleSessionInfoProvidingDelegateMediaServicesWereLostNotification:
_handleSessionInfoProvidingDelegateMediaServicesWereResetNotification:
_handleStreamProvidingDelegateDidStopUnexpectly:
_handleStreamProvidingDelegateChunkAvailable:
_handleStreamProvidingDelegateChunkForTVAvailable:
_handleStreamProvidingDelegateHardwareConfigChange:
createAudioStreamMessageWithRequest:
reportsDynamicActivityAttribute:bundleId:
audioStreamWithRequest:streamName:completion:
prepareAudioStreamSync:request:error:
prepareAudioStream:request:completion:
startAudioStream:option:completion:
stopAudioStream:option:completion:
audioChunkFrom:to:
audioChunkFrom:to:channelIdx:
audioChunkToEndFrom:
audioChunkToEndFrom:channelIdx:
saveRecordingBufferFrom:to:toURL:
saveRecordingBufferToEndFrom:toURL:
holdAudioStreamWithDescription:timeout:
cancelAudioStreamHold:
setAnnounceCallsEnabled:withStreamHandleID:
configureAlertBehavior:
sampleCountFromHostTime:
pingpong:
audioStreamProvidingDelegate
setAudioStreamProvidingDelegate:
xpcReplyQueue
setXpcReplyQueue:
activationAssertions
setActivationAssertions:
audioSessionInfoObservers
setAudioSessionInfoObservers:
xpcClientType
setXpcClientType:
_audioSessionProvidingDelegate
_audioStreamProvidingDelegate
_audioAlertProvidingDelegate
_UUID
_xpcReplyQueue
_activationAssertions
_audioSessionInfoObservers
_xpcClientType
T@"NSObject<OS_dispatch_queue>",&,N,V_xpcReplyQueue
T@"NSMutableSet",&,N,V_activationAssertions
T@"NSHashTable",&,N,V_audioSessionInfoObservers
TQ,N,V_xpcClientType
T@"<CSAudioSessionProvidingDelegate>",W,N,V_audioSessionProvidingDelegate
T@"<CSAudioStreamProvidingDelegate>",W,N,V_audioStreamProvidingDelegate
T@"<CSAudioAlertProvidingDelegate>",W,N,V_audioAlertProvidingDelegate
T@"<CSXPCClientDelegate>",W,N,V_delegate
T@"NSString",R,N,V_UUID
didTransitFrom:to:by:
didIgnoreEvent:from:
initWithInitialState:
addTransitionFrom:to:for:
addTransitionFromAnyStateTo:for:
performTransitionForEvent:
currentState
initialState
setInitialState:
transitions
setTransitions:
eventToStateTransitions
setEventToStateTransitions:
_currentState
_initialState
_transitions
_eventToStateTransitions
Tq,N,V_initialState
T@"NSMutableDictionary",&,N,V_transitions
T@"NSMutableDictionary",&,N,V_eventToStateTransitions
T@"<CSStateMachineDelegate>",W,N,V_delegate
Tq,R,N,V_currentState
CSEventMonitorDidReceiveEvent:
initWithSamplingRate:withAsset:
initWithSamplingRate:asset:
startSmartSiriVolume
getVolumeForTTSType:withOverrideMediaVolume:WithRequestTime:
didReceiveAlarmChanged:
didReceiveTimerChanged:
didReceiveMusicVolumeChanged:
didReceiveAlarmVolumeChanged:
didDetectKeywordWithResult:
CSAlarmMonitor:didReceiveAlarmChanged:
CSTimerMonitor:didReceiveTimerChanged:
CSVolumeMonitor:didReceiveMusicVolumeChanged:
CSVolumeMonitor:didReceiveAlarmVolumeChanged:
CSAutomaticVolumeEnabledMonitor:didReceiveEnabled:
smartSiriVolume
setSmartSiriVolume:
_smartSiriVolume
T@"<CSSmartSiriVolumeProcessor>",&,N,V_smartSiriVolume
T@"<CSConnectionServiceDelegate>",W,N,V_delegate
addVTRejectEntry:truncateData:
addVTAcceptEntryAndSubmit:
utteranceFileASBD
_closeAudioFile
_makeTimestampedAudioLogFilenameWithPrefix:suffix:
baseDir
_audioLogDirectory
fileExistsAtPath:isDirectory:
localeWithLocaleIdentifier:
setLocale:
setDateFormat:
stringFromDate:
_getOrCreateAudioLogDirectory
_nowString
stringByReplacingOccurrencesOfString:withString:
_audioLength
initWithType:deviceId:activationInfo:vadScore:hosttime:
initWithType:deviceId:activationInfo:hosttime:
_activationTypeString
remoteMicVADEvent:vadScore:hostTime:
jarvisVoiceTriggerEvent:activationInfo:hostTime:
remoraVoiceTriggerEvent:hostTime:
remoraVoiceTriggerEvent:activationInfo:hostTime:
mediaserverdLaunchedEvent:
activationInfo
setActivationInfo:
hosttime
setHosttime:
vadScore
setVadScore:
_vadScore
_activationInfo
_hosttime
TQ,N,V_type
T@"NSDictionary",&,N,V_activationInfo
TQ,N,V_hosttime
Tf,N,V_vadScore
componentsSeparatedByString:
shortFormForUUID
_registerForFakeAssetRollNotification
setShouldRollFakeModel:
lastFakeModelUsedHash
setLastFakeModelUsedHash:
shouldRollFakeModel
fakeAssetRollNotificationRegistrationToken
setFakeAssetRollNotificationRegistrationToken:
_shouldRollFakeModel
_fakeAssetRollNotificationRegistrationToken
_lastFakeModelUsedHash
Ti,N,V_fakeAssetRollNotificationRegistrationToken
T@"NSString",&,V_lastFakeModelUsedHash
TB,V_shouldRollFakeModel
isScreenLocked
getASVUserIntent:
setUserIntentValidForSeconds:
applyLowerAndUpperBoundsToVolume:
setASVUserIntent:
initWithStoredInformationAndAsset:
increaseSiriVolumeBasedOnUserIntent
decreaseSiriVolumeBasedOnUserIntent
storeASVStateInformation
applyLowerAndUpperBoundsToVolumeOffset:
userIntentType
setUserIntentType:
userIntentTime
setUserIntentTime:
userIntentValidForSeconds
latestVolumeTime
setLatestVolumeTime:
userIntentVolume
setUserIntentVolume:
latestVolume
setLatestVolume:
permanentOffsetFactor
setPermanentOffsetFactor:
permanentOffsetIsEnabled
setPermanentOffsetIsEnabled:
kSSVCAUserIntentValidForSeconds
kSSVCAUserIntentVolumeIncreaseFactor
kSSVCAUserIntentVolumeDecreaseFactor
kSSVCAUserIntentPermanentOffsetFactorDelta
kSSVCAUserIntentPermanentOffsetFactorLowerBound
kSSVCAUserIntentPermanentOffsetFactorUpperBound
kSSVCA_DEVICE_SIMPLE_MIN_TTS_VOLUME
kSSVCA_DEVICE_SIMPLE_MAX_TTS_VOLUME
kSSVCA_DEVICE_DEFAULT_MIN_TTS_VOLUME
kSSVCA_DEVICE_DEFAULT_MAX_TTS_VOLUME
_permanentOffsetIsEnabled
_userIntentVolume
_latestVolume
_permanentOffsetFactor
_userIntentType
_userIntentTime
_userIntentValidForSeconds
_latestVolumeTime
TQ,N,V_userIntentType
TQ,N,V_userIntentTime
TQ,N,V_userIntentValidForSeconds
TQ,N,V_latestVolumeTime
Tf,N,V_userIntentVolume
Tf,N,V_latestVolume
Tf,N,V_permanentOffsetFactor
TB,N,V_permanentOffsetIsEnabled
getVoiceTriggerAssetTypeString
getEndpointAssetTypeString
getLanguageDetectorAssetTypeString
getAdBlockerAssetTypeString
getSpeakerRecognitionAssetTypeString
_cleanUpMobileAssetV1Directory
_isReadyToUse
installedAssetOfType:withLanguage:
_fetchRemoteAssetOfType:withLanguage:completion:
_assetQueryForAssetType:
returnTypes:
queryMetaDataSync
results
filteredAssetsForAssets:assetType:language:
queryParams
enumerateObjectsUsingBlock:
installedAssetOfType:withLanguage:completion:
addKeyValuePair:with:
addKeyValuePairForQuery:assetType:
_installedAssetOfType:query:withLanguage:completion:
_fetchRemoteAssetOfType:withLanguage:query:completion:
_installedAssetOfType:withLanguage:
_installedAssetOfType:withLanguage:completion:
_findLatestInstalledAsset:
queryMetaData:
isFirstUnlocked
fetchRemoteMetaOfType:allowRetry:
_runAssetQuery:completion:
_downloadAssetCatalogForAssetType:complete:
_updateFromRemoteToLocalAssets:forAssetType:completion:
_defaultDownloadOptions
_isRetryRecommendedWithResult:
startCatalogDownload:options:then:
cancelDownloadSync
purgeSync
_downloadAsset:withComplete:
setAllowsCellularAccess:
setCanUseLocalCacheServer:
setDiscretionary:
assetServerUrl
_startDownloadingAsset:progress:completion:
expectedTimeRemaining
totalWritten
totalExpected
attachProgressCallBack:
spaceCheck:
startDownload:then:
getAssetTypeStringForType:
assetsMigrationQueue
setAssetsMigrationQueue:
csAssetsDictionary
setCsAssetsDictionary:
_assetsMigrationQueue
_csAssetsDictionary
T@"NSObject<OS_dispatch_queue>",&,N,V_assetsMigrationQueue
T@"NSDictionary",&,N,V_csAssetsDictionary
T@"NSMutableDictionary",&,N,V_observers
valueForKey:
supportPremiumAssets
getVoiceTriggerAssetCurrentCompatibilityVersion
getEndpointAssetCurrentCompatibilityVersion
getLanguageDetectorCurrentCompatibilityVersion
getAdBlockerCurrentCompatibilityVersion
getSpeakerRecognitionCurrentCompatibilityVersion
filteredAssetsForFetchRemoteMetaDataForAssets:assetType:
initWithConfiguration:
resetWithSamplingRate:language:taskType:userId:sessionId:deviceId:farField:audioSource:maxAudioBufferSizeSeconds:
resultsWithEndedAudio
_calculateTriggerConfidence:
resultsWithAddedFloatAudio:numberOfSamples:taskName:
resultsWithAddedAudio:numberOfSamples:taskName:
dictionaryWithCapacity:
tokens
lastObject
tokenName
confidence
isMultiPhraseVTEnabled
addObjectsFromArray:
_getConfidence:
caseInsensitiveCompare:
dumpEARSpeechRecognitionResults:
initWithConfigPath:triggerTokens:useKeywordSpotting:preventDuplicatedReset:
resetWithLanguage:withFarField:withAudioSource:
flushAudio
phraseIdScores
triggerConfidence
setTriggerConfidence:
ctcKwdToPhraseIdMap
setCtcKwdToPhraseIdMap:
_previousUtteranceTokens
_lastReportedRecogResults
_triggerTokenList
_syncRecognizer
_useKeywordSpotting
_requireReset
_preventDuplicatedReset
_triggerConfidence
_ctcKwdToPhraseIdMap
Td,N,V_triggerConfidence
T@"NSDictionary",&,N,V_ctcKwdToPhraseIdMap
setPackets:
setTimeStamp:
setStreamHandleID:
opusEncoder
setOpusEncoder:
_opusEncoder
T@"CSAudioConverter",&,N,V_opusEncoder
initWithData:
setPerceptualAudioHash:
initWithOverrideOption:reason:
setOverrideState:
setVoiceTriggerEverUsed
initWithServicePort:
deactivateForReason:options:context:completion:
sharedLauncher
notifyBuiltInVoiceTriggerPrewarm:completion:
notifyBuiltInVoiceTrigger:myriadPHash:completion:
notifyWakeKeywordSpokenInBuiltInMic:
notifyCarPlayVoiceTriggerPrewarm:deviceId:completion:
notifyCarPlayVoiceTrigger:deviceId:myriadPHash:completion:
notifyWakeKeywordSpokenCarPlay:deviceId:
notifyBluetoothDeviceVoiceTriggerPrewarm:deviceId:completion:
notifyBluetoothDeviceVoiceTrigger:deviceId:completion:
notifyWakeKeywordSpokenBluetoothDevice:deviceId:
notifyRemoraVoiceTriggerPrewarm:deviceId:completion:
notifyRemoraVoiceTrigger:myriadPHash:deviceId:completion:
notifyWakeKeywordSpokenRemora:deviceId:
deactivateSiriActivationConnectionWithReason:withOptions:
_addSmartSiriVolumeEnabledConditions
converterForDeviceId:
_createDeInterleaverIfNeeded
_startAudioFeedingTimer
lpcmNonInterleavedASBD
lpcmInterleavedASBD
_deinterleaveBufferIfNeeded:
_compensateChannelDataIfNeeded:receivedNumChannels:
setFileOption:
_defaultOutASBD
injectAudio:withScaleFactor:outASBD:playbackStarted:completion:
initWithLength:
initWithBytes:length:
replaceBytesInRange:withBytes:
lpcmFloatASBD
setAudioStreamHandleId:
fileOption
audioFeedTimer
setAudioFeedTimer:
setIsRecording:
bufferDuration
setBufferDuration:
injectionAudioFileList
setInjectionAudioFileList:
injectionStartNotifyBlocks
setInjectionStartNotifyBlocks:
injectionCompletionNotifyBlocks
setInjectionCompletionNotifyBlocks:
deinterleaver
setDeinterleaver:
pNonInterleavedABL
setPNonInterleavedABL:
didSetScaleFactor
setDidSetScaleFactor:
setScaleFactor:
_isRecording
_didSetScaleFactor
_audioStreamHandleId
_fileOption
_injectionAudioFileList
_injectionStartNotifyBlocks
_injectionCompletionNotifyBlocks
_deinterleaver
_pNonInterleavedABL
TQ,N,V_audioStreamHandleId
T@"CSAudioInjectionFileOption",&,N,V_fileOption
T@"NSObject<OS_dispatch_source>",&,N,V_audioFeedTimer
TB,N,V_isRecording
Td,N,V_bufferDuration
T@"NSMutableArray",&,N,V_injectionAudioFileList
T@"NSMutableArray",&,N,V_injectionStartNotifyBlocks
T@"NSMutableArray",&,N,V_injectionCompletionNotifyBlocks
T^{OpaqueAudioConverter=},N,V_deinterleaver
T^{AudioBufferList=I[1{AudioBuffer=II^v}]},N,V_pNonInterleavedABL
TB,N,V_didSetScaleFactor
Tf,N,V_scaleFactor
hasRemoteBuiltInMic
assetChangeMonitorDidDetectAssetChange:
sharedMonitor
startMonitoring
notifyVoiceTriggerAssetChanged
T@"<CSVoiceTriggerAssetChangeDelegate>",W,N,V_delegate
encodeInteger:forKey:
decodeIntegerForKey:
initWithRequestSource:
reqSrc
setReqSrc:
_reqSrc
TQ,N,V_reqSrc
initWithURL:inputFormat:outputFormat:
fileURL
inASBD
_fileURL
T@"NSURL",R,N,V_fileURL
_setAsset:forTask:
_startRequestWithContext:withVtei:completion:
_reset
_addAudio:
_reportResultToSiriDebugApp
progCheckerConfigFile
supportedInputOrigins
checkerThresholds
progCheckerShadowMode
contConvConfigFile
contConvThresholds
recordTypeString:
initWithConfig:withDelegate:error:
initWithContext:error:
startNewRequestWithContext:
addAudio:
score
voiceTriggerAudioLogDirectory
_timeStampString
stringByAppendingString:
dataWithJSONObject:options:error:
configVersion
analyzedSamples
resultType
numberWithLongLong:
_createResultDict
_logResultToVTDirectory:
_handleUnintededRequests:
acousticSL:didMitigate:withScore:analyzedSamples:taskType:
_reportResultToAnalytics
analyzer:hasPartialResult:
analyzer:hasFinalResult:
setAsset:forTask:
startRequestWithContext:withVtei:completion:
stopRequest
getLatestAcousticSLResult:
currentAsset
setCurrentAsset:
setTaskName:
configFile
setConfigFile:
acousticAnalyzer
setAcousticAnalyzer:
thresholds
setThresholds:
supportedRecordType
setSupportedRecordType:
sessionInProgress
setSessionInProgress:
isShadowModeEnabled
setIsShadowModeEnabled:
latestResult
setLatestResult:
context
setContext:
reportResultBlock
setReportResultBlock:
_sessionInProgress
_isShadowModeEnabled
_currentAsset
_taskName
_configFile
_acousticAnalyzer
_thresholds
_supportedRecordType
_latestResult
_context
_reportResultBlock
T@"CSAsset",&,N,V_currentAsset
T@"NSString",&,N,V_taskName
T@"NSString",&,N,V_configFile
T@"SLProgressiveCheckerAnalyzer",&,N,V_acousticAnalyzer
T@"NSArray",&,N,V_thresholds
TQ,N,V_supportedRecordType
TB,N,V_sessionInProgress
TB,N,V_isShadowModeEnabled
T@"SLProgressiveCheckerResult",&,N,V_latestResult
T@"CSAudioRecordContext",&,N,V_context
T@?,C,N,V_reportResultBlock
T@"<CSAcousticSLProxyDelegate>",W,N,V_delegate
_addVoiceTriggerEnabledConditions
isPresent
isSpringboardStarted
batteryState
isRestricted
isSoftwareUpdateCheckingRunning
splitterState:
siriClientBehaviorMonitor:fetchedAudioStreamWithRequest:audioProviderUUID:successfully:
siriClientBehaviorMonitor:preparedAudioStreamWithRequest:audioProviderUUID:successfully:
siriClientBehaviorMonitor:willStartStreamWithContext:option:
siriClientBehaviorMonitor:didStartStreamWithContext:successfully:option:withEventUUID:
siriClientBehaviorMonitor:didChangedRecordState:withEventUUID:withContext:
siriClientBehaviorMonitor:willStopStream:reason:
siriClientBehaviorMonitor:didStopStream:withEventUUID:
siriClientBehaviorMonitorReleasedAudioSession:
notifyFetchedAudioStreamWithRequest:audioProviderUUID:successfully:
notifyPreparedAudioStreamWithRequest:audioProviderUUID:successfully:
notifyReleaseAudioSession
setIsStreaming:
_isStreaming
TB,N,V_isStreaming
_didReceiveNewSpeechEndpointAssetMetaData
initWithVolumeEstimate:debugLogFile:
_volumeEstimate
_debugLogPath
T@"NSString",R,N,V_debugLogPath
Tf,R,N,V_volumeEstimate
setCachedAsset:
cachedAsset
_getVoiceTriggerAssetFromAssetManager:
_getVoiceTriggerAssetFromAssetManagerWithLocale:completion:
_handleVoiceTriggerAssetWithCompletion:
_handleEndpointVoiceTriggerAsset:completion:
isEqualAsset:
cachedEndpointAssets
_checkNewAssetAvailablity
_checkNewAssetAvailablityForEndpoint
CSFirstUnlockMonitor:didReceiveFirstUnlock:
setCachedEndpointAssets:
_cachedAsset
_cachedEndpointAssets
T@"CSAsset",&,V_cachedAsset
T@"NSMutableDictionary",&,V_cachedEndpointAssets
_addVoiceTriggerAOPModeEnabledConditions
isIOSDeviceSupportingBargeIn
forceVoiceTriggerAPMode
_addConditionsForIOSBargeIn
_addConditionsForIOSAOP
_isSpeechDetectionDevicePresent
isSiriClientConsideredAsRecord
carPlayConnected
pickedRoute
isInAttendingState
setIsSiriClientConsideredAsRecord:
setPendingRecordingStopUUID:
pendingRecordingStopUUID
_recordStateQueue
_isSiriClientConsideredAsRecord
_pendingRecordingStopUUID
TB,N,V_isSiriClientConsideredAsRecord
T@"NSString",&,N,V_pendingRecordingStopUUID
deviceProductType
systemUpTime
sharedPowerLogger
powerWithNumFalseWakeup:withDuration:
logAOPFirstPassTriggerWakeupLatency:
logSecondPassResult:eventInfo:triggerAPWakeUp:
logFalseWakeUp:
logTriggerLengthSampleCountStatistics:withFirstPassDeterministicTriggerLengthSampleCount:
numFalseWakeUp
setNumFalseWakeUp:
lastAggTimeFalseWakeUp
setLastAggTimeFalseWakeUp:
_numFalseWakeUp
_lastAggTimeFalseWakeUp
TQ,N,V_numFalseWakeUp
TQ,N,V_lastAggTimeFalseWakeUp
opportuneSpeakBehaviorMonitor:willStartStreamWithContext:audioProviderUUID:option:
opportuneSpeakBehaviorMonitor:didStartStreamWithContext:audioProviderUUID:successfully:option:
opportuneSpeakBehaviorMonitor:willStopStream:
opportuneSpeakBehaviorMonitor:didStopStream:
notifyWillStartStreamWithContext:audioProviderUUID:option:
notifyDidStartStreamWithContext:audioProviderUUID:successfully:option:
notifyWillStopStream:
notifyDidStopStream:
generateEmptyPHash:writeFile:
notifyHashlessTrigger:
setLastHash:
lastHash
T@"NSData",C
generatePHashFromVoiceTriggerInfo:writeFile:
pHash:length:
signalEstimate
setSignalEstimate:
signalFractional
setSignalFractional:
_signalFractional
_signalEstimate
Ts,N,V_signalEstimate
TC,N,V_signalFractional
inputRecordingFramesPerPacket
inputRecordingBytesPerPacket
inputRecordingBytesPerFrame
numChannelsForNviDirectionality
nviDirectionalityStartingChannelId
nviDirectionalityEndingChannelId
monoChannelLpcmASBD
allChannelsLpcmInterleavedASBD
allChannelsLpcmNonInterleavedASBD
nviDirectionalityLpcmNonInterleavedASBD
nviDirectionalityLpcmInterleavedASBD
nviLogsRootDir
_activationMode
activationEvent
activationEventTime
suppressStartAlert
recordingAlertPolicy
_csAudioRecordTypeForSpeechEvent:useBorealisBuffer:currentClientConfiguration:
speechRecordingMode
activationEventMachAbsoluteTime
homeButtonDownEventMachAbsoluteTime
activationDeviceIdentifier
usePrelisteningMode
isOnPhoneCall
hasPlayedStartAlert
languageDetectionUserContext
dictationInputOrigin
turnIdentifier
applicationDisplayName
applicationBundleIdentifier
presentationMode
mediaPlaybackVolume
dictationVoiceTriggerAbsStartSampleId
_isRequestFromSpokenNotification:
_appendDictationApplicationInfoSettings:
_audioSessionActiveDelayCoreSpeechWithType:
addEntriesFromDictionary:
_csAudioRecordType
initWithRecordType:deviceId:
setIsRequestDuringActiveCall:
setTurnIdentifier:
setIsRequestFromSpokenNotification:
_csAudioRecordTypeForSpeechEvent:currentClientConfiguration:
isDeviceInStarkMode
_canUseZLL
hostTimeForSeconds:
secondsForHostTime:
_alertBehaviorForRecordRoute:playbackRoute:attemptsToUsePastDataBufferFrames:
isDictationVoiceTriggerEnabled
audioAlertStyleForRecordRoute:playbackRoute:
_eventIsVoiceTrigger
shouldOverrideRecordingStartingAlertBehaviorForAlertStyle:
isEqualToNumber:
isVoiceOverTouchEnabled
invocationFeedbackExperiment
isFeatureGroupOneEnabled
_isVoiceOverTouchEnabledInAccessibility
isDeviceInCarDNDMode
_isVibrationDisabledInAccessibility
overrideStartingAlertBeepSoundID
deviceRingerSwitchState
useDeviceSpeakerForTTS
_audioAlertStyleForListenAfterSpeakingWithRecordRoute:playbackRoute:echoCancellation:useDeviceSpeakerForTTS:
vibratesForDeviceRingerSwitchState:
startAlertEnabled
startingAlertBehavior
beepSoundID
_audioSessionActiveDelayUserPerceptionWithType:
accessibilityState
sharedObserver
isVibrationDisabled
_audioSessionActiveDelayOverride
_audioSessionActiveDelayServerConfiguration
_eventIsTVRemote
overrideAudioSessionActiveDelay
serverMediaPlaybackVolumeThresholdForAudioSessionActivationDelay
serverAudioSessionActivationDelayAboveMediaPlaybackVolumeThreshold
serverAudioSessionActivationDelay
initWithSpeechRecordingMode:clientConfiguration:experimentContext:
setSpeechRequestOptions:currentActivationInfo:
setClientConfiguration:
event
recordSettingsWithOptions:
recordContextForSpeechEvent:
startRecordingSettingsWithRecordRoute:playbackRoute:
audioSessionActivated
needsUpdateToPostVoiceMode
beginUpdateToPostVoice
endUpdateToPostVoiceWithContext:success:
canPrewarm
canPrepareWithoutInterruption
shouldTreatTimeoutAsHardEndpoint
requiresBorealisConsumerCheck
canGetPCMStream
_eventIsRaiseToSpeak
canEnterTwoShot
shouldUseVoiceTriggerAnalyzerStyle
shouldExplicitlyPlayAlertOnStart
shouldPlayAlertIfNotPrelistening
shouldSuppressRecordingStopAlert
shouldSuppressRecordingErrorAlert
twoShotPromptTypeForRecordRoute:playbackRoute:
speechEvent
useBorealisBuffer
usePrelistening
audioAlertStyle
activationSystemUptime
activationHostTime
buttonDownHostTime
voiceTriggerEndHostTime
setSpeechRecordingMode:
speechEndpointerOperationMode
speechRecordingAlertPolicy
isSpokenNotification
_storedActivationMode
_currentClientConfiguration
_suppressStartAlert
_experimentContext
_isActivated
_activeMediaPlaybackVolume
_useBorealisBuffer
_usePrelistening
_isOnPhoneCall
_hasPlayedStartAlert
_isSpokenNotification
_speechEvent
_audioAlertStyle
_deviceIdentifier
_activationSystemUptime
_activationHostTime
_buttonDownHostTime
_voiceTriggerEndHostTime
_speechRecordingMode
_speechEndpointerOperationMode
_speechRecordingAlertPolicy
_presentationMode
_languageDetectionUserContext
_dictationInputOrigin
_applicationDisplayName
_applicationBundleIdentifier
_dictationVoiceTriggerAbsStartSampleId
Tq,R,N,V_speechEvent
TB,R,N,V_useBorealisBuffer
TB,R,N,V_usePrelistening
Tq,R,N,V_audioAlertStyle
T@"NSString",R,C,N,V_deviceIdentifier
Td,R,N,V_activationSystemUptime
TQ,R,N,V_activationHostTime
TQ,R,N,V_buttonDownHostTime
TQ,R,N,V_voiceTriggerEndHostTime
Tq,N,V_speechRecordingMode
TB,R,N,V_isOnPhoneCall
TB,R,N,V_hasPlayedStartAlert
Tq,R,N,V_speechEndpointerOperationMode
T@"AFSpeechRecordingAlertPolicy",R,N,V_speechRecordingAlertPolicy
Tq,R,N,V_presentationMode
TB,R,N,V_isSpokenNotification
T@"AFLanguageDetectionUserContext",R,C,N,V_languageDetectionUserContext
Tq,R,N,V_dictationInputOrigin
T@"NSUUID",R,C,N,V_turnIdentifier
T@"NSString",R,C,N,V_applicationDisplayName
T@"NSString",R,C,N,V_applicationBundleIdentifier
TQ,R,N,V_dictationVoiceTriggerAbsStartSampleId
dataWithContentsOfFile:options:error:
JSONObjectWithData:options:error:
isNviEnabled
strRepForNviSignalMask:
nviSignalTypeForStr:
nviDataSourceTypeForStr:
_createDirAtPath:
timeStampString
getVoiceTriggerEndSampleCountFromVTEI:
getVoiceTriggerEndSecsFromVTEI:
readJsonDictionaryAt:
getValueFromDictionaryOfDictionaries:keypath:
createDirAtPath:
silenceFramesCountMs
silenceProbability
silenceDurationMs
processedAudioMs
currentPowerSource
setSkipAlertBehavior:
requestHistoricalAudioDataSampleCount
startRecordingSampleCount
useOpportunisticZLL
requireSingleChannelLookup
selectedChannel
initTandemWithOption:
estimatedStartHostTime
setEstimatedStartHostTime:
disableEndpointer
disableLocalSpeechRecognizer
siriSessionUUID
_requestHistoricalAudioDataWithHostTime
_requestHistoricalAudioDataSampleCount
_useOpportunisticZLL
_skipAlertBehavior
_requireSingleChannelLookup
_disableEndpointer
_disableLocalSpeechRecognizer
_selectedChannel
_startRecordingHostTime
_startRecordingSampleCount
_startAlertBehavior
_stopAlertBehavior
_errorAlertBehavior
_estimatedStartHostTime
_siriSessionUUID
TB,N,V_requestHistoricalAudioDataWithHostTime
TB,N,V_requestHistoricalAudioDataSampleCount
TQ,N,V_startRecordingHostTime
TQ,N,V_startRecordingSampleCount
TB,N,V_useOpportunisticZLL
Tq,N,V_startAlertBehavior
Tq,N,V_stopAlertBehavior
Tq,N,V_errorAlertBehavior
TB,N,V_skipAlertBehavior
TB,N,V_requireSingleChannelLookup
TI,N,V_selectedChannel
TQ,N,V_estimatedStartHostTime
TB,N,V_disableEndpointer
TB,N,V_disableLocalSpeechRecognizer
T@"NSString",&,N,V_siriSessionUUID
currentRoute
outputs
endpointType
isHFPWithRecordRoute:
_prepareWithOptions:audioSession:error:
initWithData:error:
initWithContentsOfURL:error:
numberOfLoops
setNumberOfLoops:
fadeInDuration
prepareToPlay
isPlaying
_didNotStartWithError:
play
setVolume:fadeDuration:
fadeOutDuration
_didStopWithError:
pause
audioPlayerDidFinishPlaying:successfully:
audioPlayerDecodeErrorDidOccur:error:
audioPlayerBeginInterruption:
audioPlayerEndInterruption:withOptions:
audioPlayerEndInterruption:withFlags:
audioPlayerEndInterruption:
_isPrepared
initWithAssertionMonitor:
_fetchAssertionMonitor
CSVoiceTriggerXPCServiceProxy:bypassPhraseSpotter:
CSVoiceTriggerXPCServiceProxy:bypassRaiseToSpeak:
notifyServiceConnectionLost
isPhraseSpotterBypassed
setIsPhraseSpotterBypassed:
isRaiseToSpeakBypassed
setIsRaiseToSpeakBypassed:
assertionMonitor
setAssertionMonitor:
_isPhraseSpotterBypassed
_isRaiseToSpeakBypassed
_assertionMonitor
TB,N,V_isPhraseSpotterBypassed
TB,N,V_isRaiseToSpeakBypassed
T@"CSSiriAssertionMonitor",&,N,V_assertionMonitor
defaultContinousFingerprintBufferDuration
maxFingerprintBufferSize
shouldResetAdsDictionary
assetVersion
payloadData
setPayloadData:
_maxFingerprintBufferSize
_shouldResetAdsDictionary
_assetVersion
_payloadData
T@"NSData",&,N,V_payloadData
Tf,R,N,V_maxFingerprintBufferSize
T@"NSMutableDictionary",R,N,V_shouldResetAdsDictionary
T@"NSString",R,N,V_assetVersion
_createSSVClientConnectionIfNeeded
ssvClient
setSsvClient:
_ssvClient
T@"CSSmartSiriVolumeClient",&,N,V_ssvClient
T@"<CSSmartSiriVolumeControllerDelegate>",W,N,V_delegate
containsCategory:
satScoreThreshold
getBoolForKey:category:default:
containsSpeakerRecognitionCategory
psrCombinationWeight
satImplicitProfileThreshold
satImplicitProfileDeltaThreshold
satVTImplicitThreshold
pruningExplicitUttThresholdSAT
pruningExplicitUttThresholdPSR
pruningThresholdSAT
pruningThresholdPSR
pruningNumRetentionUtterance
maxAllowedEnrollmentUtterances
voiceProfilePruningCookie
keywordDetectorQuasarConfigFilePath
keywordDetectorNDAPIConfigFilePath
satImplicitTrainingEnabled
Tq,R,N
_supportDoAP
_isTemporaryPairedNotInContacts
_address
T@"NSString",C,N,V_address
TB,N,V_supportDoAP
TB,N,V_isTemporaryPairedNotInContacts
notifyUpdatedState:
setCurrentState:
TQ,N,V_currentState
isHeadlessDeviceDataCollectionModeEnabled
_processRemoteHeySiriCommandWithRequest:fromSenderID:withReply:
_processParallelRecordingCommandWithRequest:fromSenderID:withReply:
_receiveParallelRecordingFromPeerId:recordingInfo:withReply:
_receiveVoiceProfileFromPeerId:voiceProfileInfo:withReply:
_processGradingDataFetchCommandWithRequest:fromSenderID:withReply:
_processVoiceProfileDeleteCommandWithRequest:fromSenderID:withReply:
_receiveVoiceGradingDataFromPeerId:requestInfo:withReply:
_processVoiceProfileListQueryCommandFromPeerId:requestInfo:withReply:
_processFetchVoiceProfileCommandFromPeerId:requestInfo:withReply:
_processReverseTransferVoiceProfileCommandFromPeerId:requestInfo:withReply:
_processVoiceProfileUpdateTriggerFromPeerId:requestInfo:withReply:
_sendCoreSpeechGradingDataToPeerId:
_sendVoiceTriggerGradingDataToPeerId:
_sendVoiceProfileUpdateTriggerToPeerId:forLocale:
_sendAcousticGradingDataToPeerId:
dataWithBytes:length:
containsString:
companionSyncVoiceTriggerUtterancesEnabled
pathExtension
isInternalWithoutProfile
URLWithString:
_sendGradingData:withFileName:toPeerId:withCompressedFlag:withUncompressedDataSize:withBatchId:withRetainFileFlag:
_compressFilesInDirectory:matchingPredicate:compressedFileAvailable:
URLByDeletingPathExtension
assistantAudioFileLogDirectory
stringByDeletingPathExtension
stringByDeletingLastPathComponent
dataUsingEncoding:
stringByAppendingPathExtension:
numberWithUnsignedLong:
removeItemAtPath:error:
moveItemAtPath:toPath:error:
sendMessageWithPayload:toPeer:withReply:
_spIdSiriDebugVoiceProfileRootDirectoryForProfile:locale:
writeToFile:options:error:
_spIdSiriDebugGradingDataRootDirectory
temporaryDirectory
_createDirectoryIfDoesNotExist:
writeToURL:atomically:
newVoiceProfileWithLocale:withAppDomain:
initWithVoiceRetrainingContext:error:
_getContentsOfDirectory:
addUtterances:toProfile:withContext:withCompletion:
updateVoiceProfile:withUserName:
profileID
provisionedVoiceProfilesForLocale:
appDomain
profileId
voiceProfileForId:
deleteUserVoiceProfile:
sharedSiriId
dateAdded
homeId
_getHomeUserIdForSharedSiriId:withCompletion:
userName
languageCode
initWithObjectsAndKeys:
enter
leave
getHomeUserIdForSharedUserId:completion:
waitWithTimeout:
_sendVoiceProfile:toPeerId:
siriProfileId
locale
contentsOfDirectoryAtPath:error:
fileURLWithPath:
_spIdSiriDebugVoiceProfileCacheDirectoryForProfile:locale:
URLsForDirectory:inDomains:
remoteP2pLogDirectory
_spIdSiriDebugVTDataDirectory
_spIdSiriDebugVoiceProfileStoreRootDirectory
_spIdSiriDebugVoiceProfileStoreRootDirectoryForLocale:
isP2PTransferEnabled
processRemoteCommandWithPayload:fromPeer:withReply:
sendCoreSpeechGradingDataToNearbyPeer
sendVTNearMissGradingDataToCompanion
sendVoiceProfileUpdatedMessageToNearbyPeerForLocale:
_speakerRecognitionAudioLogsGradingDir
_spIdSiriDebugTrainedUsersFilePathForLocale:
adCompanionServiceProvider
setAdCompanionServiceProvider:
lastCommunicatedPeer
setLastCommunicatedPeer:
voiceTriggerBatchId
setVoiceTriggerBatchId:
voiceIdentificationBatchId
setVoiceIdentificationBatchId:
_adCompanionServiceProvider
_lastCommunicatedPeer
_voiceTriggerBatchId
_voiceIdentificationBatchId
T@"NSString",&,N,V_lastCommunicatedPeer
T@"NSString",&,N,V_voiceTriggerBatchId
T@"NSString",&,N,V_voiceIdentificationBatchId
T@"<CSADCompanionServiceProvider>",W,N,V_adCompanionServiceProvider
getHostClockFrequency
zeroFilterApproxAbsSpeechThreshold
initWithZeroWindowSize:approxAbsSpeechThreshold:numHostTicksPerAudioSample:
filterZerosInAudioPacket:atBufferHostTime:filteredPacket:
endAudioAndFetchAnyTrailingZerosPacket:
vtEndInSampleCount
setVtEndInSampleCount:
numSamplesProcessed
setNumSamplesProcessed:
_vtEndInSampleCount
_numSamplesProcessed
TQ,N,V_vtEndInSampleCount
TQ,N,V_numSamplesProcessed
T@"CSAudioZeroFilter",&,N,V_zeroFilter
T@"<CSVoiceTriggerAwareZeroFilterDelegate>",W,N,V_delegate
_addDisabledConditions
_performPostBuildInstallWithCompletion:
numberWithLong:
setValue:forKey:
_setMaximumBufferSizeFromInUseServices
_startListenPolling
_stopListening
createAudioFileWriterForAdBlockerWithInputFormat:outputFormat:
copyBufferWithNumSamplesCopiedIn:
_startListenPollingWithInterval:completion:
_startListenWithCompletion:
startWithUUID:withMaximumBufferSize:
stopWithUUID:
CSSiriEnabledMonitor:didReceiveEnabled:
isListenPollingStarting
setIsListenPollingStarting:
audioLoggingBuffer
setAudioLoggingBuffer:
inUseServices
setInUseServices:
currentMaximumBufferSize
setCurrentMaximumBufferSize:
_isListenPollingStarting
_currentMaximumBufferSize
_audioLoggingBuffer
_inUseServices
TB,N,V_isListenPollingStarting
T@"CSAudioCircularBuffer",&,N,V_audioLoggingBuffer
T@"NSMutableDictionary",&,N,V_inUseServices
Tf,N,V_currentMaximumBufferSize
phraseId
setPhraseId:
bestPhrase
setBestPhrase:
isEarlyWarning
setIsEarlyWarning:
isRescoring
setIsRescoring:
samplesAtFire
setSamplesAtFire:
setStartSampleCount:
_isEarlyWarning
_isRescoring
_phraseId
_bestPhrase
_samplesAtFire
_startSampleCount
TQ,N,V_phraseId
TQ,N,V_bestPhrase
TB,N,V_isEarlyWarning
TB,N,V_isRescoring
TQ,N,V_samplesAtFire
TQ,N,V_startSampleCount
initWithConfigPath:resourcePath:
_resetStartAnalyzeTime
resetBest
_setStartAnalyzeTime:
analyzeWavFloatData:numSamples:
analyzeWavData:numSamples:
getAnalyzedResultForPhraseId:
sampleFed
getAnalyzedMpVtResults
keywordAnalyzerNDAPI:hasMpVtResultsAvailable:forChannel:
keywordAnalyzerNDAPI:hasResultAvailable:forChannel:
earlyWarning
_keywordAnalyzerNDAPIResultForPhraseId:withNovDetectorResult:
numResultsAvailable
getSuperVectorWithEndPoint:
getOptionValue:
getLoggingThreshold
getRejectLoggingThreshold
activePhraseId
setActivePhraseId:
_novDetector
_startAnalyzeSampleCount
_isStartSampleCountMarked
_lastSampleFed
_sampleFedWrapAroundOffset
_activePhraseId
TI,N,V_activePhraseId
T@"<CSKeywordAnalyzerNDAPIScoreDelegate>",W,N,V_delegate
isBuiltinSpeakerMuted
setBuiltInSpeakerState:
initWithSignalType:timestamp:
sigGenTs
headerString
initWithStartSample:endSample:confidence:azimuth:estimatedAzimuth:
mostSampledAzimuth
stringForLogging
_spatialSpectrumLogStr
startSample
setStartSample:
endSample
setEndSample:
setConfidence:
azimuth
setAzimuth:
estimatedAzimuth
setEstimatedAzimuth:
processedAudioDurMs
setProcessedAudioDurMs:
spatialSpectrumData
setSpatialSpectrumData:
azDistribution
setAzDistribution:
_confidence
_azimuth
_estimatedAzimuth
_startSample
_endSample
_processedAudioDurMs
_spatialSpectrumData
_azDistribution
TQ,N,V_startSample
TQ,N,V_endSample
Tf,N,V_confidence
Tf,N,V_azimuth
Tf,N,V_estimatedAzimuth
Td,N,V_processedAudioDurMs
T@"NSArray",&,N,V_spatialSpectrumData
T@"NSDictionary",&,N,V_azDistribution
totalAudioRecorded
setTotalAudioRecorded:
endpointBufferHostTime
setEndpointBufferHostTime:
featuresAtEndpoint
setFeaturesAtEndpoint:
endpointerType
setEndpointerType:
serverFeatureLatencyDistribution
setServerFeatureLatencyDistribution:
additionalMetrics
setAdditionalMetrics:
_totalAudioRecorded
_endpointBufferHostTime
_featuresAtEndpoint
_endpointerType
_serverFeatureLatencyDistribution
_additionalMetrics
Td,N,V_totalAudioRecorded
TQ,N,V_endpointBufferHostTime
T@"NSArray",&,N,V_featuresAtEndpoint
Tq,N,V_endpointerType
T@"NSDictionary",&,N,V_serverFeatureLatencyDistribution
T@"NSDictionary",&,N,V_additionalMetrics
_setDefaultParameters
_setAsset:
_convertDB2Mag:
fetchInitSystemVolumes
_resumeSSVProcessing
_pauseSSVProcessing
_getDevicedBFSForInputLinearVolume:
_getFloatBufferData:
iterateBitset:block:
_prepareSoundLevelBufferFromSamples:soundType:
_processAudioChunk:soundType:
_estimatedTTSVolume:lowerLimit:upperLimit:TTSmappingInputRangeLow:TTSmappingInputRangeHigh:TTSmappingOutputRangeLow:TTSmappingOutputRangeHigh:
_getUserOffsetFromMusicVolumeDB:
_combineResultsWithOptimalFromNoise:andOptimalFromLkfs:withUserOffset:
_getDeviceSimpleOutputLinearVolumeFordBFSValue:
_scaleInputWithInRangeOutRange:minIn:maxIn:minOut:maxOut:
smartSiriVolumeSoftVolumeEnabled
convertToFloatLPCMBufFromShortLPCMBuf:
_getMusicVolumeDBCSSSVDeviceSimple:
_getMusicVolumeDBCSSSVDeviceDefault:
_deviceSpecificLinearVolumeToDBMappingCSSSVDeviceSimple:
_deviceSpecificDBToLinearVolumeMappingCSSSVDeviceSimple:
_getDeviceSimpledBFSForOutputLinearVolume:
estimateSoundLevelbySoundType:
estimatedTTSVolumeForNoiseLevelAndLKFS:LKFS:
prepareSoundLevelBufferFromSamples:soundType:firedVoiceTriggerEvent:triggerStartTimeSampleOffset:triggerEndTimeSampleOffset:
listenPollingTimer
setListenPollingTimer:
listenPollingTimerCount
setListenPollingTimerCount:
.cxx_construct
_smartSiriVolumeNoiseLevel
_smartSiriVolumeLKFS
_floatBuffer
_defaults
_ssvEnablePolicy
_processedSampleCount
_shouldPauseSSVProcess
_shouldPauseLKFSProcess
_alarmSoundIsFiring
_timerSoundIsFiring
_musicVolumeDB
_alarmVolume
_noiseLevelChannelBitset
_LKFSChannelBitset
_energyBufferSize
_noiseLowerPercentile
_noiseUpperPercentile
_LKFSLowerPercentile
_LKFSUpperPercentile
_noiseTimeConstant
_noiseMicSensitivityOffset
_noiseMicSensitivityOffsetDeviceSimple
_LKFSTimeConstant
_LKFSMicSensitivityOffset
_noiseTTSMappingInputRangeLow
_noiseTTSMappingInputRangeHigh
_noiseTTSMappingOutputRangeLow
_noiseTTSMappingOutputRangeHigh
_LKFSTTSMappingInputRangeLow
_LKFSTTSMappingInputRangeHigh
_LKFSTTSMappingOutputRangeLow
_LKFSTTSMappingOutputRangeHigh
_userOffsetInputRangeLow
_userOffsetInputRangeHigh
_userOffsetOutputRangeLow
_userOffsetOutputRangeHigh
_TTSVolumeLowerLimitDB
_TTSVolumeUpperLimitDB
_noiseWeight
_listenPollingTimer
_listenPollingTimerCount
T@"NSObject<OS_dispatch_source>",&,N,V_listenPollingTimer
Tq,N,V_listenPollingTimerCount
_isDeviceRoleStereo
containsValueForKey:
decodeObjectForKey:
base64EncodedStringWithOptions:
substringToIndex:
initWithHash:locale:
initWithData:hash:locale:
builtInRTModelDictionary
modelData
modelLocale
modelHash
digest
signature
certificate
_modelData
_modelLocale
_modelHash
_digest
_signature
_certificate
T@"NSData",R,N,V_modelData
T@"NSString",R,N,V_modelLocale
T@"NSString",R,N,V_modelHash
T@"NSData",R,N,V_digest
T@"NSData",R,N,V_signature
T@"NSData",R,N,V_certificate
_silentVibrationValue
_ringVibrationValue
_fetchRingVibrationValue
_fetchSilentVibrationValue
handleRingVibrationValueChange
handleSilentVibrationValueChange
_ringVibrationState
_silentVibrationState
_fetchJarvisConnectionState
_notifyJarvisConnectionState:
preferredExternalRouteDidChange:
carPlayAuxStreamSupportDidChange:
carPlayIsConnectedDidChange:
_isJarvisConnected
smartSiriVolumeContextAwareEnabled
_didReceiveAutomaticVolumeToggled:
_notifyObserver:withEnabled:
initWithSuiteName:
addObserver:forKeyPath:options:context:
observeValueForKeyPath:ofObject:change:context:
_isAutomaticVolumeEnabled
retrieveSessionWithID:
inputs
portName
isEarpieceActiveNoiseCancelationEnabled
_fetchBTInfo
currentCarPlayExternalDevice
screenIDs
componentsJoinedByString:
modelName
deviceWithAddress:
deviceWithUID:
deviceInfo
_bluetoothDeviceInfo
vendorID
productID
initWithDictation:fingerprintOnly:secureOfflineOnly:audioAlertStyle:recordSettings:endpointerModelVersion:recordRoute:recordDeviceInfo:playbackRoute:audioDeviceID:audioSessionID:voiceTriggerEventInfo:activationAlertStartTimestamp:startRecordingTimestamp:firstBufferTimestamp:firstBufferHostTime:estimatedSpeechEndHostTime:deviceIdentifier:includeBTInfo:speechEvent:
initWithDictation:codec:
isBluetooth
headsetAddress
vendorId
productId
codecIsNarrowband
isFingerprintOnly
isSecureOfflineOnly
codec
mhSource
destination
dspStatus
headsetName
activationAlertStartTimestamp
startRecordingTimestamp
audioSessionID
firstBufferTimestamp
firstBufferHostTime
isDucking
isEndAlertInfo
setIsEndAlertInfo:
triggeredTwoShotBorealis
setTriggeredTwoShotBorealis:
audioSessionSetActiveEndHostTime
setAudioSessionSetActiveEndHostTime:
bluetoothDevice
_headsetAddress
_isDictation
_isFingerprintOnly
_isSecureOfflineOnly
_isDucking
_isEndAlertInfo
_triggeredTwoShotBorealis
_mhSource
_audioSessionID
_codec
_source
_destination
_route
_deviceInfo
_modelName
_dspStatus
_headsetName
_voiceTriggerEventInfo
_activationAlertStartTimestamp
_startRecordingTimestamp
_firstBufferTimestamp
_firstBufferHostTime
_estimatedSpeechEndHostTime
_audioSessionSetActiveEndHostTime
_endpointerModelVersion
_bluetoothDevice
TB,R,N,V_isDictation
TB,R,N,V_isFingerprintOnly
TB,R,N,V_isSecureOfflineOnly
T@"NSString",R,N,V_codec
T@"NSString",R,N,V_source
Ti,R,N,V_mhSource
T@"NSString",R,N,V_destination
T@"NSString",R,N,V_route
T@"CSAudioRecordDeviceInfo",R,N,V_deviceInfo
T@"NSString",R,N,V_deviceIdentifier
T@"NSString",R,N,V_modelName
T@"NSString",R,N,V_dspStatus
T@"NSString",R,N,V_headsetName
T@"NSDictionary",R,N,V_voiceTriggerEventInfo
Td,R,N,V_activationAlertStartTimestamp
Td,R,N,V_startRecordingTimestamp
TI,R,N,V_audioSessionID
Td,R,N,V_firstBufferTimestamp
TQ,R,N,V_firstBufferHostTime
TQ,R,N,V_estimatedSpeechEndHostTime
TB,R,N,V_isDucking
TB,N,V_isEndAlertInfo
TB,N,V_triggeredTwoShotBorealis
TQ,N,V_audioSessionSetActiveEndHostTime
T@"NSString",R,N,V_endpointerModelVersion
T@"<AFBluetoothDevice>",R,N,V_bluetoothDevice
_asssetMetaUpdatedKey
_didReceiveSpeakerRecognitionAssetMetaData
triggerVoiceProfileRetrainingWithAsset:
_checkVoiceTriggerEnabled
_didReceiveVoiceTriggerSettingChanged:
CSVoiceTriggerEnabledMonitor:didReceiveEnabled:
powerLogHSEnabled:
_didReceiveVoiceTriggerSettingChangedInQueue:
_isVoiceTriggerEnabled
lowercaseString
checkFirstUnlocked
initWithWordCount:trailingSilenceDuration:eosLikelihood:pauseCounts:silencePosterior:taskName:processedAudioDurationInMilliseconds:
initWithSilenceFramesCountMs:silenceProbability:silenceDurationMs:processedAudioMs:
getCurrentEndpointerAsset
_readParametersFromHEPAsset:
initWithConfiguration:modelVersion:
submitEndpointerIssueReport:
updateEndpointerThresholdWithValue:
updateEndpointerDelayedTriggerSwitch:
setIsASRFeatureFromServer:
initWithWordCount:trailingSilenceDuration:endOfSentenceLikelihood:pauseCounts:silencePosterior:clientSilenceFramesCountMs:clientSilenceProbability:silencePosteriorNF:serverFeaturesLatency:eagerResultEndTime:
acceptEagerResultWithFeatures:featuresToLog:
_shouldUsePhaticWithRecordContext
_multimodalEndpointerEnabled
defaultServerEndpointFeatures
endOfSentenceLikelihood
initWithWordCount:trailingSilenceDuration:endOfSentenceLikelihood:pauseCounts:silencePosterior:clientSilenceFramesCountMs:clientSilenceProbability:silencePosteriorNF:serverFeaturesLatency:
didEndpointWithFeatures:audioTimestamp:featuresToLog:endpointPosterior:extraDelayMs:
clientSilenceFramesCountMs
serverFeaturesLatency
clientSilenceProbability
hostTimeFromSampleCount:anchorHostTime:anchorSampleCount:sampleRate:
_emitEndpointDetectedEventWithEndpointTimeMs:endpointBufferHostTime:endpointerFeatures:endpointerDecisionLagInNs:extraDelayMs:endpointScore:asrFeatureLatencies:
_updateEndpointerDelayedTriggerByMhId:
terminateProcessing
requestSupportedWithSamplingRate:
_getCSHybridEndpointerConfigForAsset:
endpointerAssetManagerDidUpdateAsset:
endpointerAssetManagerDidUpdateOSDAsset:
setCanProcessCurrentRequest:
osdFeaturesAtEndpoint
setOsdFeaturesAtEndpoint:
hybridClassifier
setHybridClassifier:
setEndpointerModelVersion:
serverFeaturesQueue
setServerFeaturesQueue:
lastKnownServerEPFeatures
setLastKnownServerEPFeatures:
lastKnownOSDFeatures
setLastKnownOSDFeatures:
serverFeatureLatencies
setServerFeatureLatencies:
lastKnowServerFeaturesLatency
setLastKnowServerFeaturesLatency:
epResult
setEpResult:
serverFeaturesWarmupLatency
setServerFeaturesWarmupLatency:
lastServerFeatureTimestamp
setLastServerFeatureTimestamp:
didReceiveServerFeatures
setDidReceiveServerFeatures:
clientLagThresholdMs
setClientLagThresholdMs:
clampedSFLatencyMsForClientLag
setClampedSFLatencyMsForClientLag:
useDefaultServerFeaturesOnClientLag
setUseDefaultServerFeaturesOnClientLag:
extraDelayFrequency
setExtraDelayFrequency:
taskThresholdMap
setTaskThresholdMap:
hybridClassifierQueue
setHybridClassifierQueue:
lastReportedEndpointTimeMs
setLastReportedEndpointTimeMs:
processedAudioInSeconds
setProcessedAudioInSeconds:
lastEndpointPosterior
setLastEndpointPosterior:
stateSerialQueue
setStateSerialQueue:
didCommunicateEndpoint
setDidCommunicateEndpoint:
currentRequestSampleRate
setCurrentRequestSampleRate:
vtExtraAudioAtStartInMs
setVtExtraAudioAtStartInMs:
hepAudioOriginInMs
setHepAudioOriginInMs:
speechEndpointDetected
setSpeechEndpointDetected:
firstAudioPacketTimestamp
setFirstAudioPacketTimestamp:
firstAudioSampleSensorTimestamp
setFirstAudioSampleSensorTimestamp:
didTimestampFirstAudioPacket
setDidTimestampFirstAudioPacket:
numSamplesProcessedBeforeAnchorTime
setNumSamplesProcessedBeforeAnchorTime:
anchorMachAbsTime
setAnchorMachAbsTime:
isAnchorTimeBuffered
setIsAnchorTimeBuffered:
isRequestTimeout
setIsRequestTimeout:
isASRFeatureFromServer
recordingDidStop
setRecordingDidStop:
didDetectSpeech
setDidDetectSpeech:
setElapsedTimeWithNoSpeech:
_saveSamplesSeenInReset
_canProcessCurrentRequest
_epResult
_didReceiveServerFeatures
_useDefaultServerFeaturesOnClientLag
_didCommunicateEndpoint
_speechEndpointDetected
_didTimestampFirstAudioPacket
_isAnchorTimeBuffered
_isRequestTimeout
_isASRFeatureFromServer
_recordingDidStop
_didDetectSpeech
_lastEndpointPosterior
_implDelegate
_mhId
_endpointStyle
_endpointMode
_startWaitTime
_endWaitTime
_interspeechWaitTime
_delay
_automaticEndpointingSuspensionEndTime
_minimumDurationForEndpointer
_osdFeaturesAtEndpoint
_hybridClassifier
_serverFeaturesQueue
_lastKnownServerEPFeatures
_lastKnownOSDFeatures
_serverFeatureLatencies
_lastKnowServerFeaturesLatency
_serverFeaturesWarmupLatency
_lastServerFeatureTimestamp
_clientLagThresholdMs
_clampedSFLatencyMsForClientLag
_extraDelayFrequency
_taskThresholdMap
_hybridClassifierQueue
_lastReportedEndpointTimeMs
_processedAudioInSeconds
_stateSerialQueue
_currentRequestSampleRate
_vtExtraAudioAtStartInMs
_hepAudioOriginInMs
_firstAudioPacketTimestamp
_firstAudioSampleSensorTimestamp
_numSamplesProcessedBeforeAnchorTime
_anchorMachAbsTime
_elapsedTimeWithNoSpeech
_endpointerOperationMode
T@"OSDFeatures",&,N,V_osdFeaturesAtEndpoint
TB,N,V_canProcessCurrentRequest
T@"_EAREndpointer",&,N,V_hybridClassifier
T@"NSString",&,N,V_endpointerModelVersion
T@"NSObject<OS_dispatch_queue>",&,N,V_serverFeaturesQueue
T@"CSServerEndpointFeatures",&,N,V_lastKnownServerEPFeatures
T@"OSDFeatures",&,N,V_lastKnownOSDFeatures
T@"NSMutableArray",&,N,V_serverFeatureLatencies
Td,N,V_lastKnowServerFeaturesLatency
TB,N,V_epResult
Td,N,V_serverFeaturesWarmupLatency
T@"NSDate",&,N,V_lastServerFeatureTimestamp
TB,N,V_didReceiveServerFeatures
Td,N,V_clientLagThresholdMs
Td,N,V_clampedSFLatencyMsForClientLag
TB,N,V_useDefaultServerFeaturesOnClientLag
TQ,N,V_extraDelayFrequency
T@"NSDictionary",&,N,V_taskThresholdMap
T@"NSObject<OS_dispatch_queue>",&,N,V_hybridClassifierQueue
Td,N,V_lastReportedEndpointTimeMs
Td,N,V_processedAudioInSeconds
Tf,N,V_lastEndpointPosterior
T@"NSObject<OS_dispatch_queue>",&,N,V_stateSerialQueue
TB,N,V_didCommunicateEndpoint
TQ,N,V_currentRequestSampleRate
Td,N,V_vtExtraAudioAtStartInMs
Td,N,V_hepAudioOriginInMs
TB,N,V_speechEndpointDetected
T@"NSDate",&,N,V_firstAudioPacketTimestamp
Td,N,V_firstAudioSampleSensorTimestamp
TB,N,V_didTimestampFirstAudioPacket
TQ,N,V_numSamplesProcessedBeforeAnchorTime
TQ,N,V_anchorMachAbsTime
TB,N,V_isAnchorTimeBuffered
TB,N,V_isRequestTimeout
TB,N,V_isASRFeatureFromServer
TB,N,V_recordingDidStop
TB,N,V_didDetectSpeech
Td,N,V_elapsedTimeWithNoSpeech
Tq,N,V_endpointerOperationMode
T@"<CSEndpointAnalyzerDelegate>",W,N,V_delegate
T@"<CSEndpointAnalyzerImplDelegate>",W,N,V_implDelegate
Tq,N,V_endpointStyle
Td,N,V_delay
Td,N,V_startWaitTime
Td,N,V_automaticEndpointingSuspensionEndTime
Td,N,V_minimumDurationForEndpointer
Tq,N,V_endpointMode
Td,N,V_interspeechWaitTime
Td,N,V_endWaitTime
TB,N,V_saveSamplesSeenInReset
T@"NSString",&,N,V_mhId
initWithDeviceId:audioStreamHandleId:
waitingForConnection:error:
isConnected
startRecordingWithOptions:error:
stopRecording:
didPlayEndpointBeep
hasPendingTwoShotBeep
T@"<CSRemoteRecordClientDelegate>",W,N,V_delegate
TQ,R,N,V_audioStreamHandleId
T@"NSString",R,N,V_deviceId
_didReceiveSiriSettingChanged:
fetchIsEnabled
_isSiriEnabled
_createAudioStreamWithCurrentNviContext
requestHistoricalAudio
reqStartAudioSampleId
receiveOnlyProcessedChannelData
audioChunkAvailable:numChannels:numSamplesPerChannel:startSampleId:atAbsMachTimestamp:
addReceiver:
removeReceiver:
numBytesPerSample
audioStreamProvider:avBufferAvailable:
nviCtx
setNviCtx:
receivers
setReceivers:
_nviCtx
_receivers
T@"NviContext",&,N,V_nviCtx
T@"NSHashTable",&,N,V_receivers
isDefaultInputBuiltInMic
isDefaultOutputBultInSpeaker
defaultOutputAudioDeviceID
prewarm
prewarmDeviceWithIdentifier:
_dataSource
_updateAssetWithCurrentLanguageForAssetType:
_isOSDIncludedInAsset:
_getCurrentHEPAsset
_updateAssetWithLanguage:assetType:
_notifyAssetsUpdate
_updateOEPAssetsWithLanguage:
asrDatapackInstallationStatus
_getModelPathFromInstallationStatusString:
_getOEPVersionFromPath:
assetForAssetType:resourcePath:configVersion:assetProvider:
setCurrentOEPAsset:
currentOEPAsset
currentHEPAsset
getCurrentOSDAsset
setCurrentHEPAsset:
setAsrDatapackInstallationStatus:
_currentHEPAsset
_currentOEPAsset
_asrDatapackInstallationStatus
T@"CSAsset",&,N,V_currentHEPAsset
T@"CSAsset",&,N,V_currentOEPAsset
T@"NSDictionary",&,N,V_asrDatapackInstallationStatus
RMSScore
initWithRMSScore:lastSampleCount:
compareScoresDesc:
setRMSScore:
lastSampleCount
setLastSampleCount:
_RMSScore
_lastSampleCount
Td,N,V_RMSScore
TQ,N,V_lastSampleCount
appendData:
getBytes:range:
_calculateRMSWithFrameData:
_calculateSpeechVoicingLevel
_calculateNumberOfVoicingFrames
numberOfVoicingFrames
sortUsingSelector:
addDataToBuffer:
calculateShadowMicScore
bestStartDetectSample
setBestStartDetectSample:
bestEarlyDetectSample
setBestEarlyDetectSample:
bestEndDetectSample
setBestEndDetectSample:
shadowMicScore
setShadowMicScore:
rmsSamplesForEntireAudio
setRmsSamplesForEntireAudio:
audioBuffer
setAudioBuffer:
speechVoiceLevel
setSpeechVoiceLevel:
setNumberOfVoicingFrames:
numberOfTotalFramesETFT
setNumberOfTotalFramesETFT:
_bestStartDetectSample
_bestEarlyDetectSample
_bestEndDetectSample
_shadowMicScore
_rmsSamplesForEntireAudio
_audioBuffer
_speechVoiceLevel
_numberOfVoicingFrames
_numberOfTotalFramesETFT
T@"NSMutableArray",&,N,V_rmsSamplesForEntireAudio
T@"NSMutableData",&,N,V_audioBuffer
Td,N,V_speechVoiceLevel
TQ,N,V_numberOfVoicingFrames
Tq,N,V_numberOfTotalFramesETFT
TQ,N,V_bestStartDetectSample
TQ,N,V_bestEarlyDetectSample
TQ,N,V_bestEndDetectSample
Td,N,V_shadowMicScore
estimatedUserSpeakingStartedHostTime
estimatedUserSpeakingEndedHostTime
_reportUEIUserSpeakingContext
initWithRequestMHUUID:turnIdentifier:
setSpeechRecognizedContext:withEndpointerMetrics:
reportEndpointDelayIfNeed
endpointTimeInMs
setEndpointTimeInMs:
userSpeakingStartedTimeInMs
setUserSpeakingStartedTimeInMs:
userSpeakingEndedTimeInMs
setUserSpeakingEndedTimeInMs:
userSpeakingStartedHostTime
setUserSpeakingStartedHostTime:
userSpeakingEndedHostTime
setUserSpeakingEndedHostTime:
stopRecordingHostTime
setStopRecordingHostTime:
didReportEndpointDelay
setDidReportEndpointDelay:
_didReportEndpointDelay
_endpointTimeInMs
_userSpeakingStartedTimeInMs
_userSpeakingEndedTimeInMs
_userSpeakingStartedHostTime
_userSpeakingEndedHostTime
_stopRecordingHostTime
Td,N,V_endpointTimeInMs
Td,N,V_userSpeakingStartedTimeInMs
Td,N,V_userSpeakingEndedTimeInMs
TQ,N,V_userSpeakingStartedHostTime
TQ,N,V_userSpeakingEndedHostTime
TQ,N,V_stopRecordingHostTime
T@"NSUUID",&,N,V_turnIdentifier
TB,N,V_didReportEndpointDelay
_createXPCClientConnection
_notifyActivationEvent:completion:
sharedNotifier
notifyActivationEventSynchronously:completion:
notifyActivationEvent:deviceId:activationInfo:completion:
_notifyObserver:withLanguageCode:
_didReceiveLanguageCodeUpdate
notifySiriLanguageCodeChanged:
readAudioChunksFrom:block:
_checkSoftwareUpdateCheckingState
_didReceiveSoftwareUpdateCheckingStateChanged:
_softwareUpdateCheckingState
_notifyObserver:withSoftwareUpdateCheckingRunning:
CSSoftwareUpdateCheckingMonitor:didReceiveStateChanged:
_didReceiveSoftwareUpdateCheckingStateChangedInQueue:
_isSoftwareUpdateCheckingRunning
setFileLoggingIsEnabled:
isPHSSupported
isAttentiveSiriAudioLoggingEnabled
getStartOfSpeechAudioLogFilePath
setAudioInjectionFilePath:
enableAudioInjection:
useSiriActivationSPIForHomePod
trialBaseAssetDirectory
disableAdaptiveSiriVolume:
isAdaptiveSiriVolumeTemporaryIntentValid
isAdaptiveSiriVolumePermanentOffsetEnabled
adaptiveSiriVolumePermanentOffset
adaptiveSiriVolumeRecentIntent
_addAssetManagerEnabledConditions
_shouldCheckNetworkAvailability
isAvailable
getTestResponse:
setDelayInterstitialSounds:level:completion:
getTriggerCount:
clearTriggerCount:
voiceTriggerAOPModeEnabledPolicy
initWithArray:
_mapInputOriginFromAssetToCSAudioRecordType:
keysOfEntriesPassingTest:
T@"NSArray",R,N
_didReceiveNewVoiceTriggerAssetMetaData
notifyNewVoiceTriggerAssetMetaDataUpdated
initWithRecordContext:deviceId:shouldUseRemoteRecorder:streamHandleId:
updateWithLatestRecordContext:
updateDeviceId:
shouldUseRemoteRecorder
_shouldUseRemoteRecorder
_streamHandleId
T@"CSAudioRecordContext",R,N,V_recordContext
TB,R,N,V_shouldUseRemoteRecorder
TQ,R,N,V_streamHandleId
initWithDescription:timeout:
_addQueue:heartBeatInterval:timeoutInterval:timeoutHandler:
_removeQueue:
_beginMonitoring
_endMonitoring
initWithQueue:heartBeatInterval:timeoutInterval:timeoutHandler:
startWithQueue:
allValues
addQueue:heartBeatInterval:timeoutInterval:timeoutHandler:
removeQueue:
beginMonitoring
endMonitoring
_numberOfTransactions
_observersByIdentifier
heartBeatFiredWithQueue:
initWithIdentifier:queue:effectiveDate:expirationDuration:heartBeatInterval:heartBeatHandler:invalidationHandler:
timeoutDetected
invokeWithSignal:
cancelIfNotAlreadyCanceled
_numberOfOccurrences
_heartBeat
_heartBeatInterval
_timeoutInterval
_timeoutHandler
_addAlwaysEnabledCondition
copySamplesFrom:to:
initWithRecordingDuration:audioSamplesPerRemoteVAD:audioSampleRate:
remoteVADSampleCount
copySamplesFromAudioSampleCount:toAudioSampleCount:
capacity
size
beginSampleCount
_remoteVADCircularBufferImpl
_audioSamplesPerRemoteVAD
_capacity
_size
_beginSampleCount
TQ,R,N,V_capacity
TQ,R,N,V_size
TQ,R,N,V_beginSampleCount
_didReceiveNewAdBlockerAssetMetaData
setStreaming:
setStreamRequest:
setStreamingUUID:
setStartStreamOption:
streamingUUID
streaming
prepareAudioStreamWithRequest:completion:
scheduledFutureSample
setScheduledFutureSample:
streamRequest
startStreamOption
isWeakStream
setIsWeakStream:
_scheduledFutureSample
_isWeakStream
_streaming
_streamRequest
_startStreamOption
_streamingUUID
TB,V_streaming
T@"NSUUID",&,V_streamingUUID
T@"<CSAudioStreamProviding>",W,N,V_streamProvider
T@"<CSAudioStreamProvidingDelegate>",W,N,V_delegate
TB,N,V_scheduledFutureSample
T@"CSAudioStreamRequest",&,N,V_streamRequest
T@"CSAudioStartStreamOption",&,N,V_startStreamOption
TB,N,V_isWeakStream
initWithAudioDeviceID:
sharedSession
currentInputDeviceUIDArray
currentInputRoute
currentOutputRoute
_inputRoute
_outputRoute
_isBluetooth
_deviceName
_uid
T@"NSString",R,C,N,V_deviceName
T@"NSString",R,C,N,V_uid
TB,R,N,V_isBluetooth
T@"NSString",R,C,N,V_source
T@"NSString",R,C,N,V_destination
initWithWordCount:trailingSilenceFrames:endOfSilenceLikelihood:pauseCounts:silencePosterior:taskName:
setWordCount:
setTrailingSilenceDuration:
setEosLikelihood:
setPauseCounts:
setSilencePosterior:
setProcessedAudioDurationInMilliseconds:
_wordCount
_trailingSilenceDuration
_eosLikelihood
_pauseCounts
_silencePosterior
_processedAudioDurationInMilliseconds
Tq,N,V_wordCount
Tq,N,V_trailingSilenceDuration
Td,N,V_eosLikelihood
T@"NSArray",C,N,V_pauseCounts
Td,N,V_silencePosterior
Tq,N,V_processedAudioDurationInMilliseconds
T@"NSString",C,N,V_taskName
getSerialQueue:qualityOfService:
strongToWeakObjectsMapTable
_hasPendingActivationForType:
_isVoiceTriggerEvent:
delegates
setDelegates:
pendingActivationEvent
setPendingActivationEvent:
pendingCompletion
setPendingCompletion:
_delegates
_pendingActivationEvent
_pendingCompletion
T@"NSMapTable",&,N,V_delegates
T@"CSActivationEvent",&,N,V_pendingActivationEvent
T@?,C,N,V_pendingCompletion
accessoryModelTypeToString:
setHearstFirstPassModelVersion:
setHearstSecondPassModelVersion:
fakeHearstModelPath
_handleFakeHearstModelRequest:majorVersion:minorVersion:downloadedModels:preinstalledModels:completion:
getAccessoryFallbackLocalTable
selectFallbackModelForLocale:downloadedModels:preinstalledModels:rtLocaleMap:
voiceTriggerHearstRTModelForVersion:minorVersion:locale:downloadedModels:preinstalledModels:completion:
setTriggerMode:
getAccessoryFallbackFamilyLocal:fromLocaleMap:
initWithFakeMonitor:
voiceTriggerRemoraRTModelForVersion:minorVersion:locale:endpointId:downloadedModels:preinstalledModels:completion:
fakeAssetMonitor
setFakeAssetMonitor:
_fakeAssetMonitor
T@"CoreSpeechXPCFakeModelMonitor",&,N,V_fakeAssetMonitor
sharedConnection
_checkSiriRestrictedOnLockScreen
effectiveBoolValueForSetting:
_notifyObserver:withRestricted:
CSSiriRestrictionOnLockScreenMonitor:didReceiveRestrictionChanged:
_didReceiveRestrictionChanged:
profileConnectionDidReceiveRestrictionChangedNotification:userInfo:
profileConnectionDidReceivePasscodeChangedNotification:userInfo:
profileConnectionDidReceivePasscodePolicyChangedNotification:userInfo:
profileConnectionDidReceiveProfileListChangedNotification:userInfo:
profileConnectionDidReceiveEffectiveSettingsChangedNotification:userInfo:
profileConnectionDidReceiveDefaultsChangedNotification:userInfo:
profileConnectionDidReceiveAppWhitelistChangedNotification:userInfo:
_didReceiveRestrictionChangedInQueue:
_isRestricted
setFp:
T^{__sFILE=*iiss{__sbuf=*i}i^v^?^?^?^?{__sbuf=*i}^{__sFILEX}i[3C][1C]{__sbuf=*i}iq},N,V_fp
_checkSpringBoardStarted
_didReceiveSpringboardStarted:
_notifyObserver:withStarted:
CSSpringboardStartMonitor:didReceiveStarted:
_didReceiveSpringboardStartedInQueue:
_isSpringBoardStarted
getFixedPrioritySerialQueueWithLabel:fixedPriority:
setStreamState:
_holdRecordingExceptionIfNeeded:
_updateRemoteDeviceIdFromAVVCIfNeeded
_streamStateName:
setProviderDelegate:
_setLatestRecordContext:
recordDeviceIndicator
_prepareAudioStreamSync:request:error:
historicalBufferRequestStreams
_createCircularBufferIfNeeded
_audioStreamWithRequest:streamName:error:
_handleAudioSystemFailure
setVoiceTriggerInfo:
inputRecordingDurationInSecs
_startAudioStream:option:completion:
_prepareAudioStream:request:completion:
startPendingOnStoppingStreams
startPendingOnStoppingStreamToCompletionDict
_didPlayStartAlertSoundForSiri:audioStream:
alertPlaybackFinishWaitingStreams
alertPlaybackFinishWaitingCompletions
_scheduleAlertFinishTimeout:
_switchToRecordingMode
circularBufferStartHostTime
circularBufferStartSampleCount
sampleCountFromHostTime:anchorHostTime:anchorSampleCount:sampleRate:
startPendingStreams
pendingStartCompletions
_holdRecordingTransactionIfNeeded
_scheduleAudioPacketWatchDog
_scheduleDidStartRecordingDelegateWatchDog
_resetCircularBufferStartTime
setCircularBufferStartHostTime:
setCircularBufferStartSampleCount:
streams
_cancelAudioPacketWatchDog
_clearDidStartRecordingDelegateWatchDog
_releaseRecordingTransactionIfNeeded
_clearDidStopRecordingDelegateWatchDog
_preEpilogueAudioStream
stopPendingStreams
pendingStopCompletions
_postEpilogueAudioStream
_shouldHandleStartPendingOnStopping:withStopReason:
objectEnumerator
_stopAudioStream:option:completion:
audioPreprocessor
_cs_isHashTableEmpty
_shouldStopRecording
_scheduleDidStopRecordingDelegateWatchDog
_switchToListeningMode
_audioChunkFrom:to:
_audioChunkFrom:to:channelIdx:
copySamplesFrom:to:channelIdx:
_saveRecordingBufferFrom:to:toURL:
saveAudioChunck:toURL:
streamHolders
setSessionDelegate:
setDuckOthersForStream:
setMixWithOthersForStream:
_deactivateAudioSession:error:
enableSmartRoutingConsiderationForStream:enable:
setAlertDelegate:
_isVoiceTriggerInfoAvailableLocally:
_hasMultipleVoiceTriggerInfoAvailable:
getVoiceTriggerEventInfoForEndpointId:
_processAudioBuffer:remoteVAD:atTime:arrivalTimestampToAudioRecorder:numberOfChannels:
_handleDidStartAudioStreamWithResult:error:
_handleDidStopAudioStreamWithReason:
sessionDelegate
providerDelegate
bufferLength
_fetchHistoricalAudioAndForwardToStream:remoteVAD:
addSamples:numSamples:atHostTime:
chunkForChannel:
audioInjectionEnabled
_didReceiveFinishStartAlertPlaybackAt:
alertDelegate
initWithName:clientQueue:
initWithDescription:
_onAudioPacketWatchdogFire
_schduleDidStartRecordingDelegateWatchDogWithToken:
_scheduleDidStopRecordingDelegateWatchDog:
_tearDownCircularBufferIfNeeded
notifyProviderContextChanged
recordQueue
setRecordQueue:
loggingQueue
setLoggingQueue:
streamState
setStartPendingStreams:
setStartPendingOnStoppingStreams:
setAlertPlaybackFinishWaitingStreams:
setStreams:
setStopPendingStreams:
setPendingStartCompletions:
setAlertPlaybackFinishWaitingCompletions:
setPendingStopCompletions:
setStartPendingOnStoppingStreamToCompletionDict:
setStreamHolders:
setHistoricalBufferRequestStreams:
lastAudioRecorderContext
setLastAudioRecorderContext:
audioSystemRecovering
setAudioSystemRecovering:
setAudioPreprocessor:
recordingTransaction
setRecordingTransaction:
recordingWillStartGroup
setRecordingWillStartGroup:
waitingForAlertFinish
setWaitingForAlertFinish:
alertPlaybackFinishTimeoutToken
setAlertPlaybackFinishTimeoutToken:
startRecordingWatchDogToken
setStartRecordingWatchDogToken:
stopRecordingWatchDogToken
setStopRecordingWatchDogToken:
audioPacketWatchdog
setAudioPacketWatchdog:
audioStreamType
setAudioStreamType:
setRecordDeviceIndicator:
micUsageReporter
setMicUsageReporter:
audioPacketDeliveryCount
setAudioPacketDeliveryCount:
adpAssertion
setAdpAssertion:
_audioSystemRecovering
_waitingForAlertFinish
_recordQueue
_loggingQueue
_streamState
_startPendingStreams
_startPendingOnStoppingStreams
_alertPlaybackFinishWaitingStreams
_streams
_stopPendingStreams
_pendingStartCompletions
_alertPlaybackFinishWaitingCompletions
_pendingStopCompletions
_startPendingOnStoppingStreamToCompletionDict
_providerDelegate
_sessionDelegate
_streamHolders
_historicalBufferRequestStreams
_alertDelegate
_lastAudioRecorderContext
_audioPreprocessor
_recordingTransaction
_recordingWillStartGroup
_alertPlaybackFinishTimeoutToken
_startRecordingWatchDogToken
_stopRecordingWatchDogToken
_audioPacketWatchdog
_circularBufferStartHostTime
_circularBufferStartSampleCount
_audioStreamType
_recordDeviceIndicator
_micUsageReporter
_audioPacketDeliveryCount
_adpAssertion
T@"NSObject<OS_dispatch_queue>",&,N,V_recordQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_loggingQueue
TQ,N,V_streamState
T@"NSHashTable",&,N,V_startPendingStreams
T@"NSHashTable",&,N,V_startPendingOnStoppingStreams
T@"NSHashTable",&,N,V_alertPlaybackFinishWaitingStreams
T@"NSHashTable",&,N,V_streams
T@"NSHashTable",&,N,V_stopPendingStreams
T@"NSMutableArray",&,N,V_pendingStartCompletions
T@"NSMutableArray",&,N,V_alertPlaybackFinishWaitingCompletions
T@"NSMutableArray",&,N,V_pendingStopCompletions
T@"NSMutableDictionary",&,N,V_startPendingOnStoppingStreamToCompletionDict
T@"<CSAudioProviderDelegate>",W,N,V_providerDelegate
T@"<CSAudioSessionProvidingDelegate>",W,N,V_sessionDelegate
T@"NSMutableArray",&,N,V_streamHolders
T@"NSHashTable",&,N,V_historicalBufferRequestStreams
T@"<CSAudioAlertProvidingDelegate>",W,N,V_alertDelegate
T@"CSAudioRecordContext",&,N,V_lastAudioRecorderContext
TB,N,V_audioSystemRecovering
T@"CSAudioPreprocessor",&,N,V_audioPreprocessor
T@"CSOSTransaction",&,N,V_recordingTransaction
T@"NSObject<OS_dispatch_group>",&,N,V_recordingWillStartGroup
TB,N,V_waitingForAlertFinish
T@"NSUUID",&,N,V_alertPlaybackFinishTimeoutToken
T@"NSUUID",&,N,V_startRecordingWatchDogToken
T@"NSUUID",&,N,V_stopRecordingWatchDogToken
T@"NSObject<OS_dispatch_source>",&,N,V_audioPacketWatchdog
TQ,N,V_circularBufferStartHostTime
TQ,N,V_circularBufferStartSampleCount
Tq,N,V_audioStreamType
T@"CSAudioRecordDeviceIndicator",&,N,V_recordDeviceIndicator
T@"CSMicUsageReporter",&,N,V_micUsageReporter
TQ,N,V_audioPacketDeliveryCount
T@"CSADPPreventStandbyAssertion",&,N,V_adpAssertion
_addListeningEnabledConditions
CSAlwaysOnProcessorStateMonitor:didReceiveStateChange:
_didReceiveAOPListeningStateChange:
_isListeningEnabled
adBlockerAssetDecoderWithVersion:
notifyInEarMyriadTrigger
initWithResult:
setSampleFed:
setEarlyWarning:
_earlyWarning
_sampleFed
TQ,N,V_sampleFed
TB,N,V_earlyWarning
isUserActive
initWithProtocolVersion:buildVersion:deviceProductVersion:deviceProductType:deviceCategory:
deviceBuildVersion
deviceProductVersion
defaultProtocolInfo
localDeviceProtocolInfo
protocolVersion
buildVersion
deviceCategory
_protocolVersion
_buildVersion
_deviceProductVersion
_deviceProductType
_deviceCategory
TQ,R,N,V_protocolVersion
T@"NSString",R,N,V_buildVersion
T@"NSString",R,N,V_deviceProductVersion
T@"NSString",R,N,V_deviceProductType
TQ,R,N,V_deviceCategory
_loadAndSetupEndpointerAssetIfNecessary
subChunkFrom:numSamples:forChannel:
initWithConfigFile:sampleRate:context:queue:delegate:
_updateAssetWithLanguage:
_updateAssetWithCurrentLanguage
osdAnalyzer:didUpdateOSDFeatures:
osdAnalyzer:didDetectStartOfSpeechAt:
osdAnalyzer:didDetectEndOfSpeechAt:
apQueue
setApQueue:
didAddAudio
setDidAddAudio:
osdAnalyzer
setOsdAnalyzer:
osdQueue
setOsdQueue:
_didAddAudio
_apQueue
_osdAnalyzer
_osdQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_apQueue
TB,N,V_didAddAudio
T@"OSDAnalyzer",&,N,V_osdAnalyzer
T@"NSObject<OS_dispatch_queue>",&,N,V_osdQueue
setOpportuneSpeakListeningType:
_opportuneSpeakListeningType
TQ,N,V_opportuneSpeakListeningType
speakAudio:
speakAudio:withScaleFactor:playbackStarted:completion:
speakAudio:withScaleFactor:outASBD:playbackStarted:completion:
setEnableAlwaysOnVoiceTrigger:
setIsConnected:
_isConnected
_enableAlwaysOnVoiceTrigger
_deviceType
_deviceID
_deviceUID
_productIdentifier
_injectionEngine
Tq,R,N,V_deviceType
T@"NSString",R,N,V_deviceName
T@"NSString",R,N,V_deviceID
T@"NSUUID",R,N,V_deviceUID
T@"NSString",R,N,V_productIdentifier
TB,N,V_isConnected
TB,N,V_enableAlwaysOnVoiceTrigger
T@"CSAudioInjectionEngine",W,N,V_injectionEngine
initFileURLWithPath:isDirectory:
createDirectoryAtURL:withIntermediateDirectories:attributes:error:
internalUserClassification
standardUserDefaults
persistentDomainForName:
_deregisterAudioSessionNotifications
contextForRemoraVoiceTriggerWithDeviceId:
sessionForContext:error:
opaqueSessionID
_registerAudioSessionNotifications
sessionInfoQueue
setSessionInfoQueue:
_sessionInfoQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_sessionInfoQueue
_setupNNVADEndpointer
supportCSTwoShotDecision
isWatchRTSTriggered
logEventWithType:machAbsoluteTime:context:
endpointerImplDelegate
hybridEndpointer
setHybridEndpointer:
nnvadEndpointer
setNnvadEndpointer:
activeEndpointer
setActiveEndpointer:
_endpointerImplDelegate
_hybridEndpointer
_nnvadEndpointer
_activeEndpointer
T@"<CSEndpointAnalyzerImpl>",&,N,V_hybridEndpointer
T@"<CSEndpointAnalyzerImpl>",&,N,V_nnvadEndpointer
T@"<CSEndpointAnalyzerImpl>",W,N,V_activeEndpointer
T@"<CSEndpointAnalyzerDelegate>",W,N,V_endpointerDelegate
T@"<CSEndpointAnalyzerImplDelegate>",W,N,V_endpointerImplDelegate
_attachToSession
_cleanUpDeviceProxies
_detachFromSession
_tearDownAccessoryManager
_setUpAccessoryManager
_deviceProxies
reload
_reloadForDevice:
getDeviceInfo:
getUUIDBytes:
_deviceProxyWithAddress:createsIfAbsent:
_deviceProxyWithUID:createsIfAbsent:
initWithAddress:dataSource:queue:
initWithDeviceUID:dataSource:queue:
accessoryManager:event:device:state:
getBTDeviceWithAddress:completion:
getBTDeviceWithDeviceUID:completion:
_session
_accessoryManager
_attachingToSession
_sessionSetupGroup
_deviceProxiesLock
_deviceProxiesByAddress
_deviceProxiesByDeviceUID
_updateDeviceInfo:
_fetchDeviceInfoWithCompletion:
_reload:
_getDeviceInfo:
_accessBTDeviceAndAccessoryManagerUsingBlock:
_invalidate
bluetoothDevice:deviceInfoDidChangeFrom:to:
_enumerateObserversUsingBlock:
setDeviceUID:
mutatedCopyWithMutator:
bluetoothDeviceDidInvalidate:
setRepresentation
identifier
getHeadphoneInEarDetectionState:
getHeadphoneListeningMode:
setHeadphoneListeningMode:completion:
connect:
disconnect:
updateDeviceInfo:
_headphoneInEarDetectionState
_headphoneListeningMode
T@"NSString",R,C,N,V_address
T@"NSUUID",R,C,N,V_deviceUID
setVendorID:
setProductID:
setIsAdvancedAppleAudioDevice:
setSupportsInEarDetection:
setSupportsVoiceTrigger:
setSupportsSpokenNotification:
setSupportsListeningModeANC:
setSupportsListeningModeTransparency:
setSupportsAnnounceCall:
catAssetManagerDelegate:withVersion:withError:
getCATXPCConnection
downloadForManifest:withAssetName:
T@"<CSCATAssetManagerDelegate>",W,N,V_delegate
initWithBool:
initWithDouble:
initWithLongLong:
initWithUnsignedLongLong:
objCType
longLongValue
_checkFirstUnlocked
_didReceiveFirstUnlock:
_notifyObserver:withUnlocked:
_firstUnlockNotified
_didReceiveFirstUnlockInQueue:
_firstUnlocked
_checkPhraseSpotterEnabled
CSPhraseSpotterEnabledMonitor:didReceiveEnabled:
phraseSpotterEnabled
_didReceivePhraseSpotterSettingChangedInQueue:
_phraseSpotterEnabledDidChange
_isPhraseSpotterEnabled
_handleClientEvent:
_handleClientMessage:client:
_handleClientError:client:
_sendReplyMessageWithResult:error:event:client:
initWithConnection:
activateConnection
connection
setConnection:
_connection
T@"NSObject<OS_xpc_object>",&,N,V_connection
valueForEntitlement:
defaultContext
_instanceContext
createMockRemoteDeviceWithName:deviceID:completion:
injectAudio:toDeviceWithUUID:completion:
listMockRemoteDeviecesWithCompletion:
initWithEndpointThreshold:
T@"<CSSPGEndpointAnalyzerDelegate>",W,N,V_delegate
_samplesPerInterval
_cleanUpConnection
appendAcousticData:sampleCount:sampleRate:
getSignature:
_connectionInterrupted
_connectionInvalidated
_configureWithCurrentASBD
_service
_needsConversion
_convertPCMDataForFingerprinting:
acousticFingerprinter:hasFingerprint:duration:
_serviceWithErrorHandler:
setFingerprintInterval:
setASBD:
appendPCMData:
_asxConnection
_totalSampleCount
_nextFingerprintSampleNumber
_sourceASBD
_interval
_fingerprinterConverter
T@"<CSSiriAcousticFingerprinterDelegate>",W,N,V_delegate
samplingRate
dictationLanguages
currentKeyboard
wasLanguageToggled
multilingualKeyboardLanguages
keyboardConvoLanguagePriors
keyboardGlobalLanguagePriors
previousMessageLanguage
globalLastKeyboardUsed
dictationLanguagePriors
conversationalMessages
_wasLanguageToggled
_samplingRate
_dictationLanguages
_currentKeyboard
_multilingualKeyboardLanguages
_keyboardConvoLanguagePriors
_keyboardGlobalLanguagePriors
_previousMessageLanguage
_globalLastKeyboardUsed
_dictationLanguagePriors
_conversationalMessages
Tf,N,V_samplingRate
T@"NSSet",&,N,V_dictationLanguages
T@"NSString",&,N,V_currentKeyboard
TB,N,V_wasLanguageToggled
T@"NSArray",&,N,V_multilingualKeyboardLanguages
T@"NSDictionary",&,N,V_keyboardConvoLanguagePriors
T@"NSDictionary",&,N,V_keyboardGlobalLanguagePriors
T@"NSString",&,N,V_previousMessageLanguage
T@"NSString",&,N,V_globalLastKeyboardUsed
T@"NSDictionary",&,N,V_dictationLanguagePriors
T@"NSArray",&,N,V_conversationalMessages
_speechController
_setEndpointStyle:
_stopRecordingForEndpointReason:
URLForSoundID:
bundleForClass:
URLForResource:withExtension:
_speechControllerWithError:
_currentMHUUID:
sharedLogger
logMHAssistantDaemonAudioInitContextWithMHUUID:withInitStarted:
logMHAssistantDaemonAudioConfigureContextWithMHUUID:withConfigureStarted:
_updateRecordBufferDuration
logMHAssistantDaemonAudioPrepareContextWithMHUUID:withPrepareStarted:
_setAudioContextWithInfo:forReason:
_resetSpeechController
_setLanguageDetectorDelegateIfRequired
_cancelExtendedEndpointTimer
logEventWithType:contextProvider:
logMHAssistantDaemonAudioStopRecordingContextWithMHUUID:withStopRecordingStarted:withADStopRecordingEvent:
_shouldEmitInstrumentation
setStopReasonMajor:
setStopReasonMinor:
speechCapturingWillStopRecordingWithSignpostID:
_logFanState
_mapInstrumentationEndpointTypeFromStopRecordingReason:
_speechControllerDidStartRecording:successfully:error:
speechCapturingDidStopRecordingWithError:endpointMode:totalPacketCount:endpointerMetrics:
_updateAudioContextToPostVoiceForReason:
limitedAudioLoggingEnabled
enumeratorAtPath:
nextObject
hasSuffix:
_checkAudioLoggingLimits:
_stopRecordingWithReason:hostTime:
speechCapturingWillStopRecording
logMHAssistantDaemonAudioPrewarmContextWithMHUUID:withPrewarmStarted:
tapToSiriAudioPlaybackRequest
prewarmRequest:completion:
_prepareSpeechControllerWithOptions:error:
_updateRecordDeviceInfoAndPlaybackRouteForReason:audioDeviceInfo:forcesUpdate:
_recordingInfoForEvent:audioAlertStyle:includeBTInfo:includeRecordDeviceInfo:
_currentRecordingInfo
_setSpeechCapturingMode:
_setEndpointerOperationMode:forceUpdate:
_setAlertsIfNeeded
_currentRecordRoute
_currentPlaybackRoute
_clearEndpointHint
_startAudioPlaybackRequest:options:completion:
initWithItemURL:itemData:numberOfLoops:volume:fadeInDuration:fadeOutDuration:userInfo:
logMHAssistantDaemonAudioStartRecordingContextWithMHUUID:withStartRecordingContext:withFanInfoArray:withActiveSessionDisplayIDs:
_playAudioAlert:
_scheduleExtendedEndpointTimer
beginTimestamp
endTimestamp
initWithQueue:delegate:
logMHAssistantDaemonAudioBluetoothInfoWithMHUUID:withWirelessSplitterSessionState:
getStateWithCompletion:
logEventWithType:contextResolver:
_updateAudioContextWithInfo:reason:
recordDeviceIdentifier
_updateAudioContextWithPendingInfoForReason:
suppressInterruptionEndedNotifications
setSuppressInterruptionEndedNotifications:
_logAudioMetrics:mhUUID:
initWithListenerEndpoint:
logMHAssistantDaemonAudioFetchRouteContextWithMHUUID:withFetchRouteContextStarted:
_currentRecordDeviceInfo
_audioDeviceID
_speechControllerDidStopRecording:audioDeviceInfo:forReason:estimatedSpeechEndHostTime:errorCodeOverride:underlyingError:
getAudioRouteInstrumentationWithRecordingInfo:
audioInputRoute
logMHAssistantDaemonAudioRecordingContextWithMHUUID:withAudioRecordingStarted:withAudioInputRoute:withAudioSource:
logMHASRAudioConfigureStartedWithMHUUID:withAudioCodecString:withAudioSkippedNumSamples:
_logBluetoothStateWithMHUUID:
_logVoiceTriggerInfo:withMHUUID:
speechCapturingDidUpdateRecordingInfo:
speechCapturingDidStartRecordingSuccessfully:error:withInfo:
_setupAudioFileWritingForSpeechController:info:context:
_speechControllerDidReceiveLastAudioRecordBuffer:forReason:estimatedSpeechEndHostTime:isRecordingStopped:
_playStopAlertIfNecessaryForReason:endpointMode:error:
_speechRecordingEventListener
handleSpeechRecordingEvent:
speechCapturing:didFinishWritingAudioFile:error:
_opusDecoder
_speexDecoder
speechCapturingDidRecordPCMAudioData:
logMHAssistantDaemonAudioRecordingMissedBufferDetectedWithMHUUID:
_speechControllerDidReceiveFirstAudioRecordBufferWithHostTime:atHostTime:mhUUID:
_decodeRecordBufferForSecureOfflineOnly:isOpus:
speechCapturingDidRecordSpeechPackets:atTimestamp:totalPacketCount:
logEventWithType:machAbsoluteTime:context:contextNoCopy:
logMHAssistantDaemonAudioLateBufferDetectedWithMHUUID:withBufferReceiptTimeInNs:
logMHAssistantDaemonAudioRecordingFirstBufferWithMHUUID:withStartEvent:withFirstBufferStartTimeOffsetNs:withFirstBufferReceiptTimeOffsetNs:
setInterfaceVendorID:
setInterfaceProductID:
setHardwareInterfaceVendorID:
setAudioInputRoute:
_fingerprinter
reportIssueForType:subType:context:processIdentifier:walkboutStatus:
logMHAssistantDaemonAudioRecordingLastBufferWithMHUUID:withStartEvent:withLastBufferStartTimeOffsetNs:withLastBufferReceiptTimeOffsetNs:
speechCapturingDidReceiveLastAudioBufferWithEndpointMode:totalPacketCount:endpointerMetrics:
logMHAssistantDaemonAudioRecordingInterruptionContextWithMHUUID:withStartEvent:withLinkID:withAvAudioSessionInterruptorName:withAVAudioSessionInterrupterType:
logMHAssistantDaemonAudioRecordingInterruptionStartedTier1WithMHUUID:withLinkID:withActiveSessionDisplayIDs:
speechCapturing:willSetAudioSessionActive:
speechCapturing:didSetAudioSessionActive:
didWin
isMonitoring
speechCapturing:didDetectLanguage:confidenceScores:isConfident:
logTwoShotDetectedWithMHUUID:
_performTwoShotPromptForType:atTime:
waitForMyriadDecisionForReason:withCompletion:
_speechControllerRequestsOperation:forReason:completion:
speechCapturingDidRequestQuickStop:
speechCapturingDidRequestShutdownUI:
_playPhaticWithCompletion:
performBlockAfterAlerts:timeout:
speechCapturingDidRequestUpdateSiriOutputVolume:
speechCapturing:didDetectStartpointAtTime:
_hardEndpointWasDetectedWithMetrics:atTime:
_checkIfLastEndpointHintShouldBeAccepted
speechCapturing:didDetectEndpointAtTime:
logTwoShotStartEventWithPromptType:withMHUUID:
logTwoShotEndEventWithSuppresedAlert:withTimedOut:withMHUUID:
twoShotAudioPlaybackRequest
_handleFakeTwoShotPromptTimeoutWithUUID:
_handleFakeTwoShotPromptCallbackWithUUID:timestamp:duration:error:
speechCapturing:performTwoShotPromptWithType:completion:
_enforceEndpointHint
speechCapturing:didReceiveFingerprint:duration:
startRequest:options:completion:
speechCapturingDidProvideConfidenceScores:classification:classifiedUser:unknownUserScore:duration:version:thresholdingType:assetVersion:
speechCapturing:didInterruptAudioSession:
speechCapturing:didLoseAudioSessionOwnerOrMediaServices:
speechControllerDidDetectStartpoint:
speechControllerDidDetectEndpoint:ofType:atTime:
languageDetectorDidDetectLanguageWithConfidence:confidence:isConfident:
startOfSpeechDetectedAtFrame:
speakerIdentificationDidDetectSpeakerWithScores:
initWithQueue:speechController:audioSessionController:audioPlaybackService:experimentContext:
suspendAutomaticEndpointingInRange:
setSpeechRequestOptions:
setSpeechWasRecognizedForElapsedTime:isFinal:
setFingerprintWasRecognized
stopSpeechCaptureForEvent:suppressAlert:hostTime:
cancelSpeechCaptureSuppressingAlert:
setFingerprintingEnabled:
forceSuccessAudioAlertOnStop
setIsDriving:
getLastStartpointTimestampAndCurrentTime:
playRecordingStartAlert
updateServerEndpointFeatures:
updateEndpointHintForDuration:completion:
enforcePreviousEndpointHint
eagerlyInitializeAudioRecording
prepareSpeechCaptureWithOptions:error:
recordingInfoForPreheatWithEvent:
currentVTSatScore
prepareForMode:
startSpeechCaptureWithContext:willStartHandler:error:
updateSpeechSynthesisRecord:
fetchAudioSessionID
fetchRecordingInfo
_getFanInfoArray
setAudioFileType:
setAudioFileHandle:
setSpeechRecordingEventListeningEndpoint:
suppressUtteranceGradingIfRequired
setEndpointerThreshold:
setEndpointerDelayedTrigger:
setSpeechRecognizedContext:
setEARLanguageDetectorSpeechRequestId:
_setDictationAudioModeEnabled:
_setAudioDuckingEnabled:
_isSpeechControllerInitialized
_audioPlaybackService
_packetCount
_speechCapturingMode
_recordingAlertsConfiguration
_extendedEndpointTimer
_endpointAnalyzer
_currentActivationInfo
_pendingActivationInfo
_fingerprintingEnabled
_audioFileType
_needsAVVCLPCMCallbacks
_hasReceivedEmptyLPCMRecordBuffer
_audioFileHandle
_audioLogggingFileWriter
_startEvent
_recordingState
_didReceiveFirstBuffer
_didReceiveLastBuffer
_didDetectStartpoint
_didDetectEndpoint
_didEnterTwoShotMode
_didFakeTwoShotWithAlert
_fakeTwoShotTTSPromptUUID
_serverDidRecognizeSpeech
_fingerprintWasRecognized
_serverDidEndpoint
_didTimeout
_wasCanceled
_suppressRecordingStoppedAlert
_isRecordingUsingBTRoute
_twoShotStartTime
_didPerformTwoShotPrompt
_forceSuccessAlertOnStop
_isDriving
_lastPrepareTimestamp
_accumulatedBufferDuration
_decoder
_expectedFirstBufferTimestamp
_recordDevice
_audioDuckingEnabled
_speechRecordingEventListenerConnection
_fakeTwoShotTTSPromptWatchdogTimer
_lastAudioRecordBufferStartTime
_lastAudioRecordBufferReceiptTime
_lastEndpointerMetrics
_endpointDelayReporter
_lastEndpointHintDuration
_lastEndpointHintFeatures
_lastEndpointHintCompletion
_mostRecentSpeechSynthesisRecord
_alertPlaybackGroup
_numberOfAVVCAlertPlaybacksByType
_bluetoothWirelessSplitterSessionStateObserver
_mhUUID
_suppressInterruptionEndedNotifications
TB,N,V_suppressInterruptionEndedNotifications
handleFailureInFunction:file:lineNumber:description:
initWithAudioSessionController:
initWithOptions:capacity:
_startRequest:options:preparationHandler:executionHandler:finalizationHandler:
_prewarmRequest:completion:
startRequest:options:preparationHandler:executionHandler:finalizationHandler:
_stopRequest:immediately:
_stopAllRequests:completion:
_stopAllRequestsSynchronously
_createAudioPlaybackSessionWithRequest:options:
_handlePreparationForSession:
_handleExecutionForSession:
_handleFinalizationForSession:error:
audioPlaybackService:willStartRequest:
_enumerateListenersUsingBlock:
audioPlaybackService:didStartRequest:
audioPlaybackService:didStopRequest:error:
removeListener:
_setAudioSessionID:
_evictAllReusableSessionsForReason:
memoryPressureObserver:didChangeFromCondition:toCondition:
stopRequest:immediately:
stopAllRequests:completion:
stopAllRequestsSynchronously
removeAllListeners
_listeners
_activeSessionsByRequest
_reusableSessionsByRequest
initWithConfig:samplingRate:minSpeechFrames:numLeadingFrames:delegate:
resetForNewRequest
T@"<CSStartOfSpeechDetectorDelegate>",W,N,V_delegate
_didReceiveMediaserverNotification:
_notifyObserver:withMediaserverState:
audioServerCrashEventProvidingLostMediaserverd
_mediaserverdDidRestart
serverState
setServerState:
_serverState
TQ,N,V_serverState
T@"<CSVoiceTriggerXPCClientDelegate>",W,N,V_delegate
_didReceiveDaemonStateChanged:
_notifyObserver:withDaemonState:
notifyDaemonStateChanged:
runRecognitionWithResultStream:
_recognizeWavData:length:
addAudioSamples:count:
keywordAnalyzerQuasar:hasResultAvailable:forChannel:
_phraseIdToCtcScoreMap
speechRecognizer:didRecognizePartialResult:
speechRecognizer:didFinishRecognitionWithError:
speechRecognizer:didRecognizeFinalResults:
speechRecognizer:didRecognizeFinalResults:tokenSausage:nBestChoices:
speechRecognizer:didRecognizeFinalResultPackage:
speechRecognizer:didProcessAudioDuration:
speechRecognizer:didRecognizeRawEagerRecognitionCandidate:
speechRecognizer:didProduceEndpointFeaturesWithWordCount:trailingSilenceDuration:eosLikelihood:pauseCounts:silencePosterior:processedAudioDurationInMilliseconds:
speechRecognizer:didRecognizePartialResultNbest:
speechRecognizer:didProduceLoggablePackage:
initWithConfigPath:triggerTokens:useKeywordSpotting:
runRecognition
_recognizer
_recognizerBuffer
Td,R,N,V_triggerConfidence
T@"<CSKeywordAnalyzerQuasarScoreDelegate>",W,N,V_delegate
_availabilityChanged
_didReceivedNetworkAvailabilityChangedNotification:
_notifyObserver:withNetworkAvailability:
CSNetworkAvailabilityMonitor:didReceiveNetworkAvailabilityChanged:
_startObservingSpeechDetectionVADPresence
handleSpeechDetectionVADPresentChange:
initWithRoute:isRemoteDevice:remoteDeviceUID:remoteDeviceProductIdentifier:remoteDeviceUIDString:
isRemoteDevice
remoteProductIdentifier
remoteDeviceUIDString
initWithAVVCRecordDeviceInfo:
remoteDeviceProductIdentifier
_isRemoteDevice
_remoteDeviceUID
_remoteDeviceProductIdentifier
_remoteDeviceUIDString
T@"NSString",R,C,N,V_remoteDeviceUIDString
T@"NSString",R,C,N,V_route
TB,R,N,V_isRemoteDevice
T@"NSUUID",R,C,N,V_remoteDeviceUID
T@"NSString",R,C,N,V_remoteDeviceProductIdentifier
receiveOpportuneSpeakListenerStart
receiveOpportuneSpeakListenerStop
listener
opusNarrowBandASBD
_configureAudioConverter:
_convertBufferedLPCM:allowPartial:timestamp:arrivalTimestampToAudioRecorder:
replaceBytesInRange:withBytes:length:
_opusConverter
_bufferedLPCM
_recordBasePacketsPerSecond
_opusOutASBD
_convertPacketCount
_convertAudioCapacity
_lastTimestamp
_lastArrivalTimestampToAudioRecorder
_outPacketSizeInSec
T@"<CSAudioConverterDelegate>",W,V_delegate
subdataWithRange:
splitAudioDataToReachSampleCount:currSampleCount:numBytesPerSample:completionHandler:
rawMicChannelsDataWithNumSamplesPerChannel:
strRepForFloatData
enableProgrammableAudioInjection:
getAudioInjectionXPCConnection
injectAudio:toDeviceWithUUID:withfadingTimeWindowLength:completion:
setAudioInjectionMode:
getAssetTypeForNamespace:
getTrialIdsForAssetType:withCompletion:
initWithDroppingPrediction:droppedPrediction:timestamp:
toString
droppingPrediction
droppedPrediction
timestamp
_droppingPrediction
_droppedPrediction
_timestamp
Td,R,N,V_droppingPrediction
Td,R,N,V_droppedPrediction
Td,R,N,V_timestamp
isRecordContextBuiltInVoiceTrigger:
isRecordContextHearstVoiceTrigger:
isRecordContextJarvisVoiceTrigger:
isRecordContextRemoraVoiceTrigger:
isRecordContextHearstDoubleTap:
isRecordContextRaiseToSpeak:
isRecordContextAutoPrompt:
isRecordContextVoiceTrigger:
isRecordContextHomeButtonPress:
isRecordContextSpeakerIdTrainingTrigger:
isRecordContextJarvisButtonPress:
isValidRecordContext:
recordContextString:
_update
didTriggerWithSecondChanceEnabled:
initWithPhraseInfoDict:useKeywordSpotting:
updateWithNdapiResult:
updateWithCtcScore:
effectiveThresholdWithSecondChanceEnabled:
hasNearMissTriggerWithSecondChanceEnabled:
dictionaryRepresentationWithSecondChanceEnabled:
phId
setPhId:
phStr
setPhStr:
threshold
setThreshold:
secondChanceThreshold
setSecondChanceThreshold:
loggingThreshold
setLoggingThreshold:
useKwdSpotting
setUseKwdSpotting:
recognizerScoreScaleFactor
setRecognizerScoreScaleFactor:
recognizerThresholdOffset
setRecognizerThresholdOffset:
satThreshold
setSatThreshold:
tdsrSatCombinedSATThreshold
setTdsrSatCombinedSATThreshold:
ndapiScore
setNdapiScore:
ctcCheckerScore
setCtcCheckerScore:
combinedScore
setCombinedScore:
isMaximized
setIsMaximized:
ndapiResult
setNdapiResult:
_useKwdSpotting
_isMaximized
_threshold
_secondChanceThreshold
_loggingThreshold
_recognizerScoreScaleFactor
_recognizerThresholdOffset
_satThreshold
_tdsrSatCombinedSATThreshold
_ndapiScore
_ctcCheckerScore
_combinedScore
_phId
_phStr
_ndapiResult
TQ,N,V_phId
T@"NSString",&,N,V_phStr
Tf,N,V_threshold
Tf,N,V_secondChanceThreshold
Tf,N,V_loggingThreshold
TB,N,V_useKwdSpotting
Tf,N,V_recognizerScoreScaleFactor
Tf,N,V_recognizerThresholdOffset
Tf,N,V_satThreshold
Tf,N,V_tdsrSatCombinedSATThreshold
Tf,N,V_ndapiScore
Tf,N,V_ctcCheckerScore
Tf,N,V_combinedScore
TB,N,V_isMaximized
T@"CSKeywordAnalyzerNDAPIResult",&,N,V_ndapiResult
VTSecondPassCategoryForFirstPassSource:
supportedVTPhrasesInfoForCategory:
VTSecondPassUseKeywordSpottingFrom:
initWithAsset:firstPassSource:
updateWithNdapiResults:
updateWithCtcCheckerResults:
getTriggeredPhraseWithSecondChanceEnabled:
getNearMissPhraseWithSecondChanceEnabled:
bestScoringPhrase
phraseMap
setPhraseMap:
triggeredPhrase
setTriggeredPhrase:
_phraseMap
_triggeredPhrase
T@"CSVTSecondPassPhraseScore",&,N,V_triggeredPhrase
T@"NSDictionary",&,N,V_phraseMap
languageDetectorConfigFile
startOfSpeechDetectorConfigFile
spgConfigFile
activationMode
activationDeviceUID
announceCallsEnabled
streamID
startHostTime
startAlert
stopAlert
stopOnErrorAlert
skipAlert
remoteVoiceActivityAvailable
remoteVoiceActivityVAD
remoteVoiceActivityVADBuffer
_voiceControllerWithError:
_destroyVoiceController
_audioRecorderDidStartRecordingSuccessfully:streamHandleID:error:
setRecordDelegate:
initWithError:
setContext:streamType:error:
setContextForStream:forStream:error:
_getRecordSettingsWithRequest:
_fetchRemoteRecordClientWithDeviceId:streamHandleId:
initWithStreamID:settings:bufferDuration:
prepareRecordForStream:error:
_logResourceNotAvailableErrorIfNeeded:
_shouldInjectAudio
_needResetAudioInjectionIndex:
audioInjectionFilePath
_hasLocalPendingTwoShot
playAlertSoundForType:overrideMode:
_startAudioStreamForAudioInjectionWithAVVCContext:
startRecordForStream:error:
stopRecordForStream:error:
getCurrentSessionState
getCurrentStreamState:
isRemoteDeviceGibraltar
getRecordDeviceInfoForStream:
getRecordSettingsForStream:
isUpsamplingSourceAudio
activateAudioSessionForStream:isPrewarm:error:
_shouldLogResourceNotAvailableError
activateAudioSessionForStream:isPrewarm:recordMode:error:
_convertDeactivateOption:
deactivateAudioSessionWithOptions:
deactivateAudioSessionForStream:withOptions:error:
setIAmTheAssistant:error:
setAllowMixableAudioWhileRecording:error:
enableSmartRoutingConsiderationForStream:enable:error:
initWithDuckOthers:duckToLevel:mixWithOthers:
setDuckOverride:
setDuckOthersForStream:withSettings:error:
_updateLanguageCodeForRemoteVTEIResult:
channels
packetDescriptionCount
bytesDataSize
packetDescriptions
updateMeterForStream:
getPeakPowerForStream:forChannel:
getAveragePowerForStream:forChannel:
setPeakPower:
setAvgPower:
streamDescription
_processAudioChain:audioStreamHandleId:remoteVAD:atTime:arrivalTimestampToAudioRecorder:numberOfChannels:
_processAudioBuffer:audioStreamHandleId:arrivalTimestampToAudioRecorder:
_audioRecorderDidStopRecordingForReason:streamHandleID:
triggerNotifiedMachTime
voiceControllerDidStartRecording:successfully:
voiceControllerDidStartRecording:successfully:error:
voiceControllerDidStopRecording:forReason:
voiceControllerDidDetectStartpoint:
voiceControllerDidDetectEndpoint:ofType:
voiceControllerDidDetectEndpoint:ofType:atTime:
voiceControllerEncoderErrorDidOccur:error:
voiceControllerDidFinishAlertPlayback:ofType:error:
voiceControllerDidFinishAlertPlayback:withSettings:error:
voiceControllerRecordHardwareConfigurationDidChange:toConfiguration:
voiceControllerBeginRecordInterruption:
voiceControllerBeginRecordInterruption:withContext:
voiceControllerEndRecordInterruption:
voiceControllerMediaServicesWereLost:
voiceControllerMediaServicesWereReset:
voiceControllerWillSetAudioSessionActive:willActivate:
voiceControllerDidSetAudioSessionActive:isActivated:
voiceControllerRecordBufferAvailable:buffer:
voiceControllerLPCMRecordBufferAvailable:buffer:
voiceControllerWirelessSplitterRouteAvailable:devices:
voiceControllerDidStartRecording:forStream:successfully:error:
voiceControllerDidStopRecording:forStream:forReason:
voiceControllerAudioCallback:forStream:buffer:
voiceControllerStreamInvalidated:forStream:
remoteRecordDidStartRecordingWithStreamHandleId:error:
remoteRecordDidStopRecordingWithWithStreamHandleId:error:
remoteRecordLPCMBufferAvailable:streamHandleId:
remoteRecordTwoShotDetectedAtTime:
remoteRecordConnectionDisconnected:
_shouldUseRemoteBuiltInMic:
voiceControllerCreationQueue
setVoiceControllerCreationQueue:
crashEventDelegate
setCrashEventDelegate:
sessionEventDelegate
setSessionEventDelegate:
_voiceController
_interleavedABL
_remoteRecordClient
_opusDecoders
_audioFileReader
_audioFilePathIndex
_waitingForDidStart
_pendingTwoShotVTToken
_voiceControllerCreationQueue
_crashEventDelegate
_sessionEventDelegate
T@"NSObject<OS_dispatch_queue>",&,N,V_voiceControllerCreationQueue
T@"<CSAudioServerCrashEventProvidingDelegate>",W,N,V_crashEventDelegate
T@"<CSAudioSessionEventProvidingDelegate>",W,N,V_sessionEventDelegate
notifyDidStartStreamWithContext:successfully:option:
initWithSharedSiriId:languageCode:productCategory:version:sharedHomeId:userName:
setProfileId:
setLanguageCode:
productCategory
setProductCategory:
version
setVersion:
onboardType
setOnboardType:
setHomeId:
setUserName:
_profileId
_languageCode
_productCategory
_onboardType
_homeId
_userName
T@"NSString",&,N,V_profileId
T@"NSString",&,N,V_languageCode
T@"NSString",&,N,V_productCategory
T@"NSNumber",&,N,V_version
TQ,N,V_onboardType
T@"NSString",&,N,V_homeId
T@"NSString",&,N,V_userName
setRequestHistoricalAudio:
setReqStartAudioSampleId:
reqStartMachAbsTime
setReqStartMachAbsTime:
shouldLogRawSensorData
setShouldLogRawSensorData:
rootLogDir
setRootLogDir:
_requestHistoricalAudio
_shouldLogRawSensorData
_reqStartAudioSampleId
_reqStartMachAbsTime
_rootLogDir
T@"NSDictionary",&,N,V_voiceTriggerInfo
TB,N,V_requestHistoricalAudio
TQ,N,V_reqStartAudioSampleId
TQ,N,V_reqStartMachAbsTime
TB,N,V_shouldLogRawSensorData
T@"NSString",&,N,V_rootLogDir
triggerModeStringDescription:
getTriggerMode
_notifyStopOpportuneSpeakWithDelay:
audioProviderUUID
isOpportuneSpeakListening
setIsOpportuneSpeakListening:
setAudioProviderUUID:
token
setToken:
_isOpportuneSpeakListening
_audioProviderUUID
_token
TB,N,V_isOpportuneSpeakListening
T@"NSString",&,N,V_audioProviderUUID
T@"NSUUID",&,N,V_token
decodeInt64ForKey:
encodeInt64:forKey:
setSigType:
setSigGenTs:
_sigType
_sigGenTs
TQ,N,V_sigType
TQ,N,V_sigGenTs
isSiriRestrictedOnLockScreen
@24@0:8@16
v40@0:8@16@24@?32
v40@0:8@"NSURL"16@"NSString"24@?<v@?@"NSString"@"NSString"@"NSError">32
@16@0:8
B16@0:8
Q16@0:8
v24@0:8Q16
v24@0:8@16
v20@0:8B16
v16@0:8
@"NSMutableArray"
B24@0:8@16
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
v44@0:8@16Q24B32@36
v40@0:8@16Q24Q32
v56@0:8@16Q24@32@40Q48
v32@0:8@16@24
v44@0:8@"CSAudioInjectionEngine"16Q24B32@"NSError"36
v40@0:8@"CSAudioInjectionEngine"16Q24Q32
v56@0:8@"CSAudioInjectionEngine"16Q24@"NSData"32@"NSData"40Q48
v32@0:8@"CSAudioInjectionEngine"16@"CSAudioChunkForTV"24
@24@0:8Q16
B44@0:8@16f24@?28@?36
q24@0:8@16
@"NSObject<OS_dispatch_queue>"
@"<CSAudioInjectionEngineDelegate>"
@"CSKeywordAnalyzerNDEAPI"
@"CSAudioCircularBuffer"
@"NSUUID"
@"CSAudioInjectionDevice"
v32@0:8@16Q24
v32@0:8@"NSStream"16Q24
@32@0:8@16@24
@"NSOutputStream"
v32@0:8Q16@24
v32@0:8@16@?24
@"NSHashTable"
v32@0:8@"<CSAudioSessionInfoProviding>"16@"NSDictionary"24
v28@0:8@16B24
v28@0:8@"CSXPCClient"16B24
v32@0:8@"CSCoreSpeechDaemonStateMonitor"16Q24
v24@0:8@?16
I16@0:8
@"<CSAudioSessionInfoProviding>"
@"CSXPCClient"
v32@0:8@16q24
q16@0:8
@68@0:8@16f24{AudioStreamBasicDescription=dIIIIIIII}28
{AudioStreamBasicDescription=dIIIIIIII}16@0:8
v56@0:8{AudioStreamBasicDescription=dIIIIIIII}16
^{OpaqueExtAudioFile=}16@0:8
v24@0:8^{OpaqueExtAudioFile=}16
f16@0:8
@"NSURL"
^{OpaqueExtAudioFile=}
{AudioStreamBasicDescription="mSampleRate"d"mFormatID"I"mFormatFlags"I"mBytesPerPacket"I"mFramesPerPacket"I"mBytesPerFrame"I"mChannelsPerFrame"I"mBitsPerChannel"I"mReserved"I}
@"NSString"
Q40@0:8@16@24@32
v24@0:8@"CSAttSiriRequestContext"16
v24@0:8@"CSAttSiriAttendingTriggerEventInfo"16
@"<CSAttSiriServiceDelegate>"
@"NSXPCConnection"
v24@0:8q16
B32@0:8^B16^Q24
Q24@0:8Q16
@"<CSBiometricMatchMonitorDelegate>"
v20@0:8f16
v60@0:8@16@24Q32@40B48@?52
v32@0:8@"NSDictionary"16@"NSString"24
v40@0:8@"NSDictionary"16@"NSString"24@?<v@?>32
v24@0:8@"NSDictionary"16
v24@0:8@"NSData"16
v60@0:8@"NSDictionary"16@"NSData"24Q32@"NSString"40B48@?<v@?>52
v40@0:8Q16@24d32
v40@0:8Q16@"NSString"24d32
v32@0:8Q16@"NSString"24
@?16@0:8
@"<CSVoiceTriggerDelegate>"
@"<CSSecondPassProgressProviding>"
@"NSDictionary"
@"CSPreMyriadVoiceTriggerMetaData"
@"NSMutableDictionary"
@"CSKeywordAnalyzerNDAPI"
@32@0:8@16f24I28
v28@0:8@16I24
i16@0:8
d16@0:8
@40@0:8@16@24@32
@24@0:8^{_NSZone=}16
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
@"CSAudioRecordDeviceInfo"
@"NSArray"
@"CSSSRXPCClient"
@"<CSSpeakerRecognitionProxyProtocol>"
v28@0:8@"CSVoiceTriggerXPCClient"16B24
v36@0:8B16@20@28
v28@0:8B16@20
v36@0:8B16d20@28
v28@0:8B16d20
@"CSVoiceTriggerXPCClient"
r*16@0:8
v36@0:8@16@24f32
v40@0:8@16@24Q32
@48@0:8@16@24@32^@40
v40@0:8@"CSVoiceTriggerAwareZeroFilter"16@"NSData"24Q32
v40@0:8@"CSBeepCanceller"16@"NSData"24Q32
@24@0:8f16i20
v32@0:8f16B20@24
B20@0:8f16
v20@0:8i16
@"<CSAudioPreprocessorDelegate>"
@"CSAudioSampleRateConverter"
@"CSVoiceTriggerAwareZeroFilter"
@"CSBeepCanceller"
@"CSAudioZeroCounter"
@24@0:8^{BTLocalDeviceImpl=}16
v40@0:8^{BTDeviceImpl=}16I24i28I32i36
v28@0:8^{BTSessionImpl=}16i24
v24@0:8^{BTSessionImpl=}16
v32@0:8^{BTLocalDeviceImpl=}16i24i28
^{BTSessionImpl=}16@0:8
^{BTLocalDeviceImpl=}16@0:8
v24@0:8^{BTLocalDeviceImpl=}16
^{BTSessionImpl=}
^{BTLocalDeviceImpl=}
@"NSObject<OS_dispatch_group>"
v40@0:8@16@24@32
v40@0:8@"NSObject<OS_xpc_object>"16@"NSObject<OS_xpc_object>"24@"NSObject<OS_xpc_object>"32
v40@0:8@"CSXPCConnection"16@"NSObject<OS_xpc_object>"24@"NSObject<OS_xpc_object>"32
v52@0:8@16B24@28@36@44
v40@0:8@16Q24@32
v48@0:8@16Q24@32@40
v36@0:8@16B24Q28
@"CSTrialAssetDownloadMonitor"
@24@0:8d16
B24@0:8d16
@20@0:8I16
@"NSObject<OS_dispatch_source>"
@"<CSAudioFileReaderDelegate>"
@96@0:8{AudioStreamBasicDescription=dIIIIIIII}16{AudioStreamBasicDescription=dIIIIIIII}56
^{OpaqueAudioConverter=}96@0:8{AudioStreamBasicDescription=dIIIIIIII}16{AudioStreamBasicDescription=dIIIIIIII}56
^{OpaqueAudioConverter=}
@"<CSLanguageDetectorAssetMonitorDelegate>"
v32@0:8@16d24
v24@0:8r^{AudioStreamBasicDescription=dIIIIIIII}16
@28@0:8@16i24
@"CSAudioRecordContext"
@"CSSiriRecordingInfo"
@"CSSiriAudioFileWriter"
@"<AFRelinquishableAssertion>"
@"NSMutableSet"
v40@0:8Q16@24@?32
v40@0:8Q16@"NSDictionary"24@?<v@?@"NSError"@"CSSmartSiriVolumeEstimate">32
@32@0:8Q16@24
@"<CSSmartSiriVolumeClientDelegate>"
B40@0:8@16Q24^@32
B40@0:8@16@24^@32
B32@0:8@16^@24
f24@0:8Q16
B24@0:8Q16
B32@0:8Q16^@24
B40@0:8Q16Q24^@32
B40@0:8q16Q24^@32
B32@0:8@16q24
B32@0:8q16@24
@"CSAudioInjectionEngine"
v32@0:8@"<CSAudioStreamProviding>"16q24
v32@0:8@"<CSAudioStreamProviding>"16@"CSAudioChunk"24
v32@0:8@"<CSAudioStreamProviding>"16@"CSAudioChunkForTV"24
v28@0:8B16@?20
v36@0:8@16d24f32
@"<CSOpportuneSpeakListenerDelegate>"
@"CSAudioStream"
@"CSSPGEndpointAnalyzer"
@"<CSAudioStreamProviding>"
@"<CSAudioSessionProviding>"
@"CSPlainAudioFileWriter"
@"CSAudioTimeConverter"
v64@0:8@16@24@32@40@48@?56
@"NSObject<OS_xpc_object>"
v56@0:8q16@24@32@40@?48
v44@0:8@16@24f32@?36
v32@0:8@"NSString"16@?<v@?@"NSString">24
v56@0:8q16@"NSString"24@"NSString"32@"NSString"40@?<v@?B@"NSError"@"NSUUID">48
v44@0:8@"NSURL"16@"NSUUID"24f32@?<v@?B@"NSError"QQ>36
v32@0:8@"NSUUID"16@?<v@?B@"NSError">24
v24@0:8@?<v@?B@"NSError"@"NSUUID">16
v24@0:8d16
v24@0:8@"NSString"16
v32@0:8d16@?24
v36@0:8Q16Q24B32
v32@0:8Q16@"CSAudioRecordContext"24
v24@0:8@"CSAudioChunk"16
@"<CSEndpointAnalyzerDelegate>"16@0:8
v24@0:8@"<CSEndpointAnalyzerDelegate>"16
@"<CSEndpointAnalyzerImplDelegate>"16@0:8
v24@0:8@"<CSEndpointAnalyzerImplDelegate>"16
v24@0:8@"CSServerEndpointFeatures"16
v32@0:8d16@?<v@?B@"NSArray">24
v32@0:8@"NSString"16@"NSString"24
v32@0:8@"OSDFeatures"16d24
v32@0:8@"NSDate"16Q24
v28@0:8@"CSServerEndpointFeatures"16B24
@"<CSEndpointAnalyzerDelegate>"
@"<CSEndpointAnalyzerImplDelegate>"
@"<CSLanguageDetectorDelegate>"
v32@0:8@"CSSelfTriggerDetector"16@"NSDictionary"24
@"<CSMyriadSelfTriggerCoordinatorDelegate>"
v40@0:8Q16Q24Q32
v44@0:8@16@24B32@36
v40@0:8@"CSCommandControlBehaviorMonitor"16@"CSAudioRecordContext"24@"CSAudioStartStreamOption"32
v44@0:8@"CSCommandControlBehaviorMonitor"16@"CSAudioRecordContext"24B32@"CSAudioStartStreamOption"36
v32@0:8@"CSCommandControlBehaviorMonitor"16@"CSAudioStopStreamOption"24
@36@0:8q16@?24I32
@36@0:8q16@24I32
@44@0:8q16@?24@32I40
@"NSFileHandle"
@"NSError"
v64@0:8Q16Q24q32@40@48@?56
v72@0:8Q16Q24q32@40@48@56@?64
v56@0:8Q16Q24@32@40@?48
v20@0:8I16
@"CSPolicy"
v24@0:8@"CSAudioServerCrashMonitor"16
v40@0:8@"CSVoiceTriggerAssetHandler"16@"NSString"24@"CSAsset"32
v40@0:8@"CSActivationEventNotificationHandler"16@"CSActivationEvent"24@?<v@?B@"NSError">32
v68@0:8@16Q24@32@40Q48Q56i64
v40@0:8@16Q24q32
v40@0:8@16q24@32
v68@0:8@"CSAudioRecorder"16Q24@"NSData"32@"NSData"40Q48Q56i64
v40@0:8@"CSAudioRecorder"16Q24@"CSAudioChunkForTV"32
v44@0:8@"CSAudioRecorder"16Q24B32@"NSError"36
v40@0:8@"CSAudioRecorder"16Q24q32
v32@0:8@"CSAudioRecorder"16q24
v40@0:8@"CSAudioRecorder"16q24@"NSError"32
v24@0:8@"CSAudioRecorder"16
v32@0:8@"CSAudioRecorder"16@"NSDictionary"24
v28@0:8@"CSAudioRecorder"16B24
v32@0:8@"CSAudioRecorder"16@"NSError"24
v32@0:8@"CSAudioProvider"16Q24
v28@0:8@"CSOpportuneSpeakEventMonitor"16B24
@32@0:8@16^@24
@24@0:8^@16
@"CSAudioRecorder"
@"CSFallbackAudioSessionReleaseProvider"
@"<CSSpeechManagerDelegate>"
@"CSOpportuneSpeakListnerTestService"
@"CSPostBuildInstallService"
@"CSSmartSiriVolumeManager"
v32@0:8Q16Q24
@"<CSCommandControlListenerDelegate>"
v32@0:8@"CSAssetController"16Q24
v32@0:8@16@"NSString"24
v32@0:8Q16@?24
v48@0:8Q16@24Q32@?40
v48@0:8Q16Q24@32@?40
@"CSAssetDownloadingOption"
v72@0:8q16q24d32@40d48@56q64
v72@0:8q16q24d32@"NSArray"40d48@"NSString"56q64
v24@0:8@?<v@?@"NSError"@"NSString">16
v24@0:8@?<v@?@"NSError"d>16
v24@0:8@?<v@?@"NSError"Q>16
v32@0:8d16@24
v72@0:8d16d24Q32@40q48@56@64
v32@0:8d16@"CSEndpointerMetrics"24
v72@0:8d16d24Q32@"NSArray"40q48@"NSDictionary"56@"NSDictionary"64
v48@0:8Q16@24@32@40
@32@0:8@"<NviDataSource>"16@"<NviAssetsProvider>"24
v24@0:8@"<NviSignalProviderDelegate>"16
v32@0:8@"NviContext"16@?<v@?B@"NSError">24
v24@0:8@?<v@?B@"NSError">16
B32@0:8@16@24
B32@0:8@"NSXPCListener"16@"NSXPCConnection"24
v24@0:8@?<v@?@>16
@48@0:8@16@24@32@40
@"NSXPCListener"
@"NSXPCInterface"
@28@0:8@16B24
@32@0:8r^s16q24
@32@0:8^v16q24
@"NSMutableData"
@"<CSKeywordAnalyzerNDEAPIScoreDelegate>"
v52@0:8@16@24f32Q36Q44
v52@0:8@"CSAudioConverter"16@"NSArray"24f32Q36Q44
v32@0:8@"CSSmartSiriVolumeController"16Q24
v40@0:8@"<CSAudioAlertProviding>"16q24@"NSError"32
v32@0:8@"CSAudioSessionController"16@"NSDictionary"24
v72@0:8@16Q24@32@40Q48Q56B64I68
v72@0:8@"CSAudioDecoder"16Q24@"NSData"32@"NSData"40Q48Q56B64I68
v32@0:8@"<CSEndpointAnalyzerImpl>"16d24
v40@0:8@"<CSEndpointAnalyzerImpl>"16Q24Q32
v48@0:8@16q24q32@40
v32@0:8@16B24B28
v48@0:8@"SOMediaNowPlayingObserver"16q24q32@"NSDate"40
v24@0:8@"SOMediaNowPlayingObserver"16
v32@0:8@"SOMediaNowPlayingObserver"16B24B28
v32@0:8@"SOClockAlarmObserver"16@"NSUUID"24
v40@0:8@"SOClockAlarmObserver"16@"AFClockAlarmSnapshot"24@"AFClockAlarmSnapshot"32
v32@0:8@"SOClockTimerObserver"16@"NSUUID"24
v40@0:8@"SOClockTimerObserver"16@"AFClockTimerSnapshot"24@"AFClockTimerSnapshot"32
v24@0:8@"<CSAudioSessionProviding>"16
v32@0:8@"<CSAudioSessionProviding>"16@"NSDictionary"24
v28@0:8@"<CSAudioSessionProviding>"16B24
v32@0:8@"CSContinuousVoiceTrigger"16@"NSDictionary"24
v32@0:8@"CSContinuousVoiceTrigger"16d24
@116@0:8@16@24@32@40@48@56@64@72@80@88B96B100B104B108B112
B44@0:8Q16d24B32^@36
v56@0:8d16Q24@32@?40@?48
B24@0:8^@16
B24@0:8B16B20
B24@0:8q16
v24@0:8B16B20
@"CSAudioConverter"
@"<CSSpeechControllerDelegate>"
@"<CSSpeakerIdentificationDelegate>"
@"CSEndpointerProxy"
@"<CSAudioAlertProviding>"
@"<CSAudioMeterProviding>"
@"<CSAudioMetricProviding>"
@"CSSelectiveChannelAudioFileWriter"
@"CSSmartSiriVolumeController"
@"CSSpeechEndHostTimeEstimator"
@"CSLanguageDetector"
@"CSXPCClientFactory"
@"CSAudioPowerMeter"
@"CSEndpointLatencyInfo"
@"CSStopRecordingOptions"
@"SOMediaNowPlayingObserver"
@"SOClockAlarmObserver"
@"SOClockTimerObserver"
@"CSVolumeMonitor"
@"CSAudioDeviceInfo"
@"CSAudioSessionController"
@"CSSACInfoMonitor"
@"<CSSSRXPCClientDelegate>"
@"CSAttSiriRequestContext"
@48@0:8q16Q24Q32@40
@40@0:8Q16Q24@32
@24@0:8q16
@40@0:8@16@24Q32
v56@0:8Q16@24@?32@?40@?48
@40@0:8@"NSObject<OS_dispatch_queue>"16@"AFAudioPlaybackRequest"24Q32
v40@0:8Q16@"AVAudioSession"24@?<v@?@"NSError">32
v56@0:8Q16@"AVAudioSession"24@?<v@?>32@?<v@?>40@?<v@?@"NSError">48
v28@0:8B16@?<v@?>20
@"AFAudioPlaybackRequest"16@0:8
@"AVPlayer"
@"AVPlayerItem"
@"AVAudioSession"
@"AFAudioPlaybackRequest"
@24@0:8@?16
v56@0:8@16@24@32@40@?48
v60@0:8@16@24@32B40@44@?52
v52@0:8@16@24B32@36@?44
v36@0:8@16B24@?28
q24@0:8q16
v48@0:8@16@24B32B36@?40
v48@0:8@"NSString"16@"NSString"24B32B36@?<v@?@"NSDictionary"@"NSError">40
v32@0:8@"NSURL"16@?<v@?@"NSError">24
v36@0:8@"NSString"16B24@?<v@?@"NSDictionary"@"NSError">28
v40@0:8@"NSDictionary"16@"NSString"24@?<v@?@"NSDictionary"@"NSError">32
@"<NviAssetsProvider>"
@"NSMapTable"
B48@0:8Q16Q24@32^@40
v24@0:8@"<CSAudioSessionProvidingDelegate>"16
B48@0:8Q16Q24@"NSString"32^@40
@40@0:8@16@24^@32
@32@0:8Q16Q24
@40@0:8Q16Q24Q32
v40@0:8Q16Q24@32
@32@0:8@16d24
v28@0:8B16Q20
B32@0:8@"CSAudioRecordContext"16^@24
@"CSAudioStream"40@0:8@"CSAudioStreamRequest"16@"NSString"24^@32
v40@0:8@"CSAudioStreamRequest"16@"NSString"24@?<v@?@"CSAudioStream"@"NSError">32
B40@0:8@"CSAudioStream"16@"CSAudioStreamRequest"24^@32
v40@0:8@"CSAudioStream"16@"CSAudioStreamRequest"24@?<v@?B@"NSError">32
v40@0:8@"CSAudioStream"16@"CSAudioStartStreamOption"24@?<v@?B@"NSError">32
v40@0:8@"CSAudioStream"16@"CSAudioStopStreamOption"24@?<v@?B@"NSError">32
@"CSAudioChunk"32@0:8Q16Q24
@"CSAudioChunk"40@0:8Q16Q24Q32
@"CSAudioChunk"24@0:8Q16
v40@0:8Q16Q24@"NSURL"32
v32@0:8Q16@"NSURL"24
@"CSAudioStreamHolding"32@0:8@"NSString"16d24
v24@0:8@"CSAudioStreamHolding"16
@"CSAudioRecordDeviceInfo"16@0:8
@"CSAudioDeviceInfo"16@0:8
@"NSDictionary"16@0:8
v24@0:8@"<CSAudioAlertProvidingDelegate>"16
B32@0:8@"NSURL"16q24
I24@0:8@16
v24@0:8@"<CSAudioSessionInfoProvidingDelegate>"16
I24@0:8@"NSString"16
v32@0:8@"CSAudioRecordContext"16@?<v@?@"NSDictionary"@"NSDictionary">24
v32@0:8@"CSAudioRecordContext"16@?<v@?@"NSDictionary">24
@"<CSAudioSessionProvidingDelegate>"
@"<CSAudioStreamProvidingDelegate>"
@"<CSAudioAlertProvidingDelegate>"
@"<CSXPCClientDelegate>"
v40@0:8q16q24q32
v32@0:8q16q24
@"<CSStateMachineDelegate>"
v32@0:8@"CSAlarmMonitor"16q24
v32@0:8@"CSTimerMonitor"16q24
v28@0:8@16f24
v28@0:8@"CSVolumeMonitor"16f24
v28@0:8@"CSAutomaticVolumeEnabledMonitor"16B24
@28@0:8f16@20
@40@0:8Q16@24Q32
@"<CSConnectionServiceDelegate>"
@"<CSSmartSiriVolumeProcessor>"
@36@0:8@16f24Q28
@32@0:8@16Q24
@52@0:8Q16@24@32f40Q44
@48@0:8Q16@24@32Q40
d20@0:8f16
v48@0:8Q16@24@32@?40
v28@0:8Q16B24
v40@0:8@16Q24@?32
v40@0:8@16@?24@?32
@40@0:8@16Q24@32
v32@0:8^@16Q24
@40@0:8@16@24B32B36
v36@0:8@16C24@28
d24@0:8@16
@"_EARSyncSpeechRecognizer"
v48@0:8@16@24@32@?40
v32@0:8q16Q24
B84@0:8@16f24{AudioStreamBasicDescription=dIIIIIIII}28@?68@?76
@24@0:8^{AudioBufferList=I[1{AudioBuffer=II^v}]}16
@28@0:8@16I24
^{OpaqueAudioConverter=}16@0:8
v24@0:8^{OpaqueAudioConverter=}16
^{AudioBufferList=I[1{AudioBuffer=II^v}]}16@0:8
v24@0:8^{AudioBufferList=I[1{AudioBuffer=II^v}]}16
@"CSAudioInjectionFileOption"
^{AudioBufferList=I[1{AudioBuffer=II^v}]}
@"<CSVoiceTriggerAssetChangeDelegate>"
@104@0:8@16{AudioStreamBasicDescription=dIIIIIIII}24{AudioStreamBasicDescription=dIIIIIIII}64
v32@0:8r^v16q24
v32@0:8@"SLProgressiveCheckerAnalyzer"16@"SLProgressiveCheckerResult"24
@"<CSAcousticSLProxyDelegate>"
@"CSAsset"
@"SLProgressiveCheckerAnalyzer"
@"SLProgressiveCheckerResult"
v36@0:8@16@24B32
v44@0:8@16B24@28@36
v28@0:8@"CSFirstUnlockMonitor"16B24
v52@0:8@16@24B32@36@44
v44@0:8@16@24@32B40
v40@0:8@"CSSiriClientBehaviorMonitor"16@"CSAudioRecordContext"24@"CSAudioStartStreamOption"32
v52@0:8@"CSSiriClientBehaviorMonitor"16@"CSAudioRecordContext"24B32@"CSAudioStartStreamOption"36@"NSString"44
v40@0:8@"CSSiriClientBehaviorMonitor"16@"CSAudioStopStreamOption"24Q32
v40@0:8@"CSSiriClientBehaviorMonitor"16@"CSAudioStopStreamOption"24@"NSString"32
v44@0:8@"CSSiriClientBehaviorMonitor"16B24@"NSString"28@"CSAudioRecordContext"36
v44@0:8@"CSSiriClientBehaviorMonitor"16@"CSAudioStreamRequest"24@"NSString"32B40
v24@0:8@"CSSiriClientBehaviorMonitor"16
v32@0:8i16@20B28
@28@0:8Q16B24
S28@0:8^f16i24
s16@0:8
v20@0:8s16
C16@0:8
v20@0:8C16
@40@0:8q16@24@32
q32@0:8q16@24
q36@0:8q16B24@28
@36@0:8@16@24B32
q32@0:8@16@24
q44@0:8@16@24B32q36
@"AFClientConfiguration"
@"AFExperimentContext"
@"AFSpeechRecordingAlertPolicy"
@"AFLanguageDetectionUserContext"
Q24@0:8@16
v28@0:8@"AVAudioPlayer"16B24
v32@0:8@"AVAudioPlayer"16@"NSError"24
v24@0:8@"AVAudioPlayer"16
v32@0:8@"AVAudioPlayer"16Q24
B40@0:8Q16@24^@32
@"AVAudioPlayer"
v36@0:8B16@20d28
@"CSSiriAssertionMonitor"
@"NSData"
@"<CSSmartSiriVolumeControllerDelegate>"
@"CSSmartSiriVolumeClient"
v64@0:8@16@24@32B40Q44@52B60
@"<CSADCompanionServiceProvider>"
@"<CSVoiceTriggerAwareZeroFilterDelegate>"
@"CSAudioZeroFilter"
@28@0:8I16@20
@"CSNovDetector"
@"<CSKeywordAnalyzerNDAPIScoreDelegate>"
@44@0:8Q16Q24f32f36f40
@64@0:8d16Q24@32q40@48@56
v32@0:8@"CSMediaPlayingMonitor"16q24
v28@0:8@"CSSiriEnabledMonitor"16B24
@28@0:8f16@"CSAsset"20
v24@0:8@"CSAsset"16
@"CSSmartSiriVolumeEstimate"40@0:8Q16@"NSNumber"24Q32
v28@0:8I16q20
v52@0:8@16q24B32Q36Q44
f24@0:8q16
f24@0:8f16f20
f20@0:8f16
f36@0:8f16f20f24f28f32
f44@0:8f16f20f24f28f32f36f40
f28@0:8f16f20f24
^f24@0:8@16
{unique_ptr<SmartSiriVolume, std::default_delete<SmartSiriVolume>>="__ptr_"{__compressed_pair<SmartSiriVolume *, std::default_delete<SmartSiriVolume>>="__value_"^{SmartSiriVolume}}}
{vector<float, std::allocator<float>>="__begin_"^f"__end_"^f"__end_cap_"{__compressed_pair<float *, std::allocator<float>>="__value_"^f}}
@"NSUserDefaults"
@"CSSmartSiriVolumeEnablePolicy"
@64@0:8@16@24@32@40@48@56
v48@0:8@16@24@32^v40
@152@0:8B16B20B24q28@36@44@52@60@68I76I80@84d92d100d108Q116Q124@132B140q144
@28@0:8B16@20
@"<AFBluetoothDevice>"
v72@0:8d16Q24@32d40Q48d56@64
@"OSDFeatures"
@"_EAREndpointer"
@"CSServerEndpointFeatures"
@"NSDate"
B32@0:8d16^@24
@"<CSRemoteRecordClientDelegate>"
v24@0:8@"<NviDataReceiver>"16
@"NviContext"
@32@0:8q16Q24
@"CSSiriMobileBluetoothDeviceDataSource"
v24@0:8@"CSAssetManager"16
@32@0:8d16Q24
d24@0:8[80s]16
v80@0:8Q16Q24q32@40@48@56@64@?72
v64@0:8Q16Q24@32@40@48@?56
v32@0:8@"NSString"16@?<v@?@"NSString"@"NSString"@"NSError">24
v80@0:8Q16Q24q32@"NSString"40@"NSUUID"48@"NSArray"56@"NSArray"64@?<v@?@"CSVoiceTriggerRTModel"@"CSVoiceTriggerRTModel"@"NSError">72
v64@0:8Q16Q24@"NSString"32@"NSArray"40@"NSArray"48@?<v@?@"CSVoiceTriggerRTModel"@"CSVoiceTriggerRTModel"@"NSError">56
v40@0:8@"NSArray"16@"NSString"24@?<v@?@"NSString"@"NSError">32
B32@0:8@16@?24
B20@0:8B16
Vv24@0:8@?16
Vv32@0:8@16@?24
Vv40@0:8@16q24@?32
Vv24@0:8@?<v@?@"NSString">16
Vv32@0:8@"NSString"16@?<v@?@"NSString">24
Vv40@0:8@"NSArray"16q24@?<v@?@"NSError">32
Vv24@0:8@?<v@?Q>16
Vv24@0:8@?<v@?>16
Vv24@0:8@?<v@?B>16
Vv24@0:8@?<v@?q>16
@44@0:8@16@24B32Q36
v48@0:8@16d24d32@?40
@48@0:8@16d24d32@?40
@"AFHeartBeat"
@28@0:8f16i20f24
v32@0:8r^v16Q24
{unique_ptr<corespeech::CSAudioCircularBufferImpl<unsigned char>, std::default_delete<corespeech::CSAudioCircularBufferImpl<unsigned char>>>="__ptr_"{__compressed_pair<corespeech::CSAudioCircularBufferImpl<unsigned char> *, std::default_delete<corespeech::CSAudioCircularBufferImpl<unsigned char>>>="__value_"^v}}
@"CSAudioStreamRequest"
@"CSAudioStartStreamOption"
@"CSSiriAudioRoute"
@72@0:8q16q24d32@40d48@56q64
@64@0:8q16q24d32@40d48@56
@"CSActivationEvent"
v64@0:8@16Q24Q32@40@48@?56
v72@0:8Q16Q24@32@40@48@56@?64
@"CoreSpeechXPCFakeModelMonitor"
v32@0:8@"MCProfileConnection"16@"NSDictionary"24
^{__sFILE=*iiss{__sbuf=*i}i^v^?^?^?^?{__sbuf=*i}^{__sFILEX}i[3C][1C]{__sbuf=*i}iq}16@0:8
v24@0:8^{__sFILE=*iiss{__sbuf=*i}i^v^?^?^?^?{__sbuf=*i}^{__sFILEX}i[3C][1C]{__sbuf=*i}iq}16
^{__sFILE=*iiss{__sbuf=*i}i^v^?^?^?^?{__sbuf=*i}^{__sFILEX}i[3C][1C]{__sbuf=*i}iq}
v52@0:8@16@24Q32Q40i48
v52@0:8@"CSAudioPreprocessor"16@"NSData"24Q32Q40i48
@48@0:8Q16q24@32@40
B32@0:8Q16q24
@"<CSAudioProviderDelegate>"
@"CSAudioPreprocessor"
@"CSOSTransaction"
@"CSAudioRecordDeviceIndicator"
@"CSMicUsageReporter"
@"CSADPPreventStandbyAssertion"
@56@0:8Q16@24@32@40Q48
I24@0:8Q16
v32@0:8@"OSDAnalyzer"16@"OSDFeatures"24
v32@0:8@"OSDAnalyzer"16d24
@"OSDAnalyzer"
@48@0:8q16@24@32@40
v40@0:8@16d24@32
v32@0:8@"<CSEndpointAnalyzer>"16d24
v40@0:8@"<CSEndpointAnalyzer>"16d24@"CSEndpointerMetrics"32
@"<CSEndpointAnalyzerImpl>"
v40@0:8^{BTAccessoryManagerImpl=}16i24^{BTDeviceImpl=}28i36
v24@0:8^{BTDeviceImpl=}16
^{BTAccessoryManagerImpl=}
{os_unfair_lock_s="_os_unfair_lock_opaque"I}
v32@0:8q16@?24
@"AFBluetoothDeviceInfo"16@0:8
v24@0:8@?<v@?@"AFBluetoothDeviceInfo">16
v24@0:8@?<v@?@"AFBluetoothHeadphoneInEarDetectionState">16
v24@0:8@?<v@?q>16
v32@0:8q16@?<v@?@"NSError">24
v24@0:8@"<AFBluetoothDeviceObserver>"16
@"AFBluetoothDeviceInfo"
@"AFBluetoothHeadphoneInEarDetectionState"
@"<CSCATAssetManagerDelegate>"
v44@0:8B16@20@28@36
@"AFInstanceContext"
v40@0:8@"NSString"16@"NSString"24@?<v@?B@"NSError"@"NSUUID">32
v40@0:8@"NSURL"16@"NSUUID"24@?<v@?B@"NSError"QQ>32
v24@0:8@?<v@?@"NSMutableArray">16
@20@0:8f16
@"<CSSPGEndpointAnalyzerDelegate>"
Vv20@0:8i16
Vv32@0:8@16i24i28
Vv32@0:8@"NSData"16i24i28
Vv24@0:8@?<v@?@"NSData">16
v24@0:8^{AudioStreamBasicDescription=dIIIIIIII}16
@"<CSSiriAcousticFingerprinterDelegate>"
@"NSSet"
v40@0:8@16@24d32
v40@0:8@"CSSiriAcousticFingerprinter"16@"NSData"24d32
v44@0:8@16@24f32Q36
v52@0:8@16@24f32Q36@44
v36@0:8@16d24B32
v36@0:8@16B24@28
v40@0:8@16q24Q32
v48@0:8@16@24q32Q40
v40@0:8@16q24d32
v40@0:8Q16Q24@?32
v32@0:8@"CSSpeechController"16@"NSData"24
v40@0:8@"CSSpeechController"16@"NSData"24Q32
v44@0:8@"CSSpeechController"16@"NSArray"24f32Q36
v52@0:8@"CSSpeechController"16@"NSArray"24f32Q36@"CSAudioDeviceInfo"44
v32@0:8@"CSSpeechController"16d24
v36@0:8@"CSSpeechController"16d24B32
v36@0:8@"CSSpeechController"16B24@"NSError"28
v44@0:8@"CSSpeechController"16@"CSAudioDeviceInfo"24B32@"NSError"36
v40@0:8@"CSSpeechController"16q24Q32
v48@0:8@"CSSpeechController"16@"CSAudioDeviceInfo"24q32Q40
v24@0:8@"CSSpeechController"16
v40@0:8@"CSSpeechController"16q24d32
v32@0:8@"CSSpeechController"16q24
v32@0:8@"CSSpeechController"16Q24
v40@0:8@"CSSpeechController"16q24@"NSError"32
v32@0:8@"CSSpeechController"16@"NSDictionary"24
v28@0:8@"CSSpeechController"16B24
v40@0:8Q16Q24@?<v@?@"NSError">32
v36@0:8@"NSString"16@"NSDictionary"24B32
@56@0:8@16@24@32@40@48
v32@0:8{AFTimeRange=dd}16
v28@0:8d16B24
v36@0:8q16B24Q28
@56@0:8@"NSObject<OS_dispatch_queue>"16@"CSSpeechController"24@"CSAudioSessionController"32@"CSSiriAudioPlaybackService"40@"AFExperimentContext"48
v24@0:8@"<CSSiriSpeechCapturingDelegate>"16
v24@0:8@"AFSpeechRequestOptions"16
v24@0:8@?<v@?dd>16
@20@0:8B16
v28@0:8q16B24
v28@0:8(?={?=SS}I)16Q20
i20@0:8(?={?=SS}I)16
v20@0:8(?={?=SS}I)16
B40@0:8@16@?24^@32
@40@0:8q16q24B32B36
v64@0:8@16@24q32Q40q48@56
v44@0:8@16q24Q32B40
v40@0:8q16q24@32
v32@0:8q16d24
v48@0:8@16d24d32@40
v32@0:8@?16d24
B40@0:8@16Q24@?32
@"<CSSiriSpeechCapturingDelegate>"
@"CSSpeechController"
@"CSSiriAudioPlaybackService"
@"<CSEndpointAnalyzer>"
@"CSSiriSpeechRecordingContext"
@"CSSiriAudioActivationInfo"
@"CSSiriAcousticFingerprinter"
@"AFWatchdogTimer"
@"CSEndpointerMetrics"
@"CSEndpointDelayReporter"
@"AFSpeechSynthesisRecord"
@"AFBluetoothWirelessSplitterSessionStateObserver"
v40@0:8@16q24q32
v40@0:8@"AFMemoryPressureObserver"16q24q32
v32@0:8@"AFAudioPlaybackRequest"16@?<v@?@"NSError">24
v40@0:8@"AFAudioPlaybackRequest"16Q24@?<v@?@"NSError">32
v28@0:8@"AFAudioPlaybackRequest"16B24
v56@0:8@16Q24@?32@?40@?48
@56@0:8@16Q24Q32Q40@48
@"<CSStartOfSpeechDetectorDelegate>"
@"<CSVoiceTriggerXPCClientDelegate>"
v48@0:8@16@24@32@40
v72@0:8@16q24q32d40@48d56q64
v32@0:8@"_EARSpeechRecognizer"16@"_EARSpeechRecognitionResult"24
v32@0:8@"_EARSpeechRecognizer"16@"NSError"24
v32@0:8@"_EARSpeechRecognizer"16@"NSArray"24
v48@0:8@"_EARSpeechRecognizer"16@"NSArray"24@"NSArray"32@"NSArray"40
v32@0:8@"_EARSpeechRecognizer"16@"_EARSpeechRecognitionResultPackage"24
v32@0:8@"_EARSpeechRecognizer"16d24
v32@0:8@"_EARSpeechRecognizer"16@"_EARSpeechRecognition"24
v72@0:8@"_EARSpeechRecognizer"16q24q32d40@"NSArray"48d56q64
v28@0:8r^s16i24
@"_EARSpeechRecognizer"
@"_EARSpeechRecognitionAudioBuffer"
@"<CSKeywordAnalyzerQuasarScoreDelegate>"
@44@0:8@16B24@28@36
@52@0:8@16B24@28@36@44
v32@0:8@16B24f28
v28@0:8@"CSOpportuneSpeakListener"16B24
v32@0:8@"CSOpportuneSpeakListener"16B24f28
@"CSOpportuneSpeakListener"
v44@0:8@16B24Q28Q36
@"<CSAudioConverterDelegate>"
v48@0:8Q16Q24Q32@?40
v48@0:8@16@24Q32@?40
@40@0:8d16d24d32
f20@0:8B16
@"CSKeywordAnalyzerNDAPIResult"
@"CSVTSecondPassPhraseScore"
v28@0:8@16i24
v36@0:8@16i24d28
v36@0:8@16i24@28
v28@0:8@"AVVoiceController"16B24
v36@0:8@"AVVoiceController"16B24@"NSError"28
v32@0:8@"AVVoiceController"16q24
v24@0:8@"AVVoiceController"16
v28@0:8@"AVVoiceController"16i24
v36@0:8@"AVVoiceController"16i24d28
v32@0:8@"AVVoiceController"16@"NSError"24
v36@0:8@"AVVoiceController"16i24@"NSError"28
v40@0:8@"AVVoiceController"16@"AVVCAlertInformation"24@"NSError"32
v32@0:8@"AVVoiceController"16@"NSDictionary"24
v32@0:8@"AVVoiceController"16@"AVVCAudioBuffer"24
v28@0:8B16@"NSArray"20
v44@0:8@"AVVoiceController"16Q24B32@"NSError"36
v40@0:8@"AVVoiceController"16Q24q32
v40@0:8@"AVVoiceController"16Q24@"AVVCAudioBuffer"32
v32@0:8@"AVVoiceController"16Q24
v40@0:8@"CSAudioFileReader"16@"NSData"24Q32
v36@0:8@"CSAudioFileReader"16B24@"NSError"28
v32@0:8@"CSAudioFileReader"16q24
v32@0:8Q16@"NSError"24
v32@0:8@"NSData"16Q24
v24@0:8@"CSRemoteRecordClient"16
v24@0:8@"<CSAudioServerCrashEventProvidingDelegate>"16
v24@0:8@"<CSAudioSessionEventProvidingDelegate>"16
v60@0:8@16Q24@32Q40Q48i56
v36@0:8B16Q20@28
@"AVVoiceController"
{AudioBufferList="mNumberBuffers"I"mBuffers"[1{AudioBuffer="mNumberChannels"I"mDataByteSize"I"mData"^v}]}
@"CSRemoteRecordClient"
@"CSAudioFileReader"
@"<CSAudioServerCrashEventProvidingDelegate>"
@"<CSAudioSessionEventProvidingDelegate>"
@"NSNumber"
v52@0:8@16@24@32B40@44
v48@0:8@"CSOpportuneSpeakBehaviorMonitor"16@"CSAudioRecordContext"24@"NSString"32@"CSAudioStartStreamOption"40
v52@0:8@"CSOpportuneSpeakBehaviorMonitor"16@"CSAudioRecordContext"24@"NSString"32B40@"CSAudioStartStreamOption"44
v32@0:8@"CSOpportuneSpeakBehaviorMonitor"16@"CSAudioStopStreamOption"24
supo
mcpl
33s@
fff?
333333
333333
333333
