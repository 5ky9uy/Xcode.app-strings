@(#)PROGRAM:AXMediaUtilities  PROJECT:AXMediaUtilities-1
@333333
A@q=
B@)\
?ffffff
e@q=
k@333333
333333
@o@ffffff
@o@{
?UUUUUU
?UUUUUU
?UUUUUU
?433333
?UUUUUU
?UUUUUU
?UUUUUU
?UUUUUU
v24@?0^{_LXEntry=}8*16
Create Lexicon %@
@8@?0
Screen grab not supported on Simulator yet
v8@?0
Library/Accessibility/PhotoCaptionAssets
CompiledModels
UncompiledModels
mlmodelc
mlmodel
Horizon Detector
_detectHorizonRequest
T@"VNDetectHorizonRequest",&,N,S_setDetectHorizonRequest:,V__detectHorizonRequest
VNDetectHorizonRequest
/System/Library/Frameworks/Vision.framework/Vision
mainColors
mainColorWeights
supportsSecureCoding
TB,R
T@"NSArray",&,N,V_mainColors
T@"NSArray",&,N,V_mainColorWeights
remainingColorWeight
Td,N,V_remainingColorWeight
gender
eyes
smiling
faceHair
hairColor
bald
glasses
com.apple.accessibility.AXMediaUtilities
faceattributes.eyes.closed
Accessibility
faceattributes.eyes.open
faceattributes.smiling
faceattributes.facehair.beard
faceattributes.facehair.goatee
faceattributes.facehair.moustache
faceattributes.facehair.stubble
faceattributes.haircolor.black
faceattributes.haircolor.blonde
faceattributes.haircolor.brown
faceattributes.haircolor.gray
faceattributes.haircolor.red
faceattributes.haircolor.white
faceattributes.bald
faceattributes.glasses.prescription
faceattributes.glasses.sunglasses
faceattributes.age.baby
faceattributes.age.child
faceattributes.age.youngadult
faceattributes.age.senior
wearing.glasses
with.face.attributes
three.attributes.described
two.attributes.described
results
T@"NSDictionary",&,N,V_results
ageCategory
Tq,R,N,V_ageCategory
genderCategory
Tq,R,N,V_genderCategory
eyesCategory
Tq,R,N,V_eyesCategory
smilingCategory
Tq,R,N,V_smilingCategory
faceHairCategory
Tq,R,N,V_faceHairCategory
hairColorCategory
Tq,R,N,V_hairColorCategory
baldCategory
Tq,R,N,V_baldCategory
glassesCategory
Tq,R,N,V_glassesCategory
VNFaceAttributeAgeBaby
VNFaceAttributeAgeChild
VNFaceAttributeAgeYoungAdult
VNFaceAttributeAgeSenior
VNFaceAttributeGenderMale
VNFaceAttributeGenderFemale
VNFaceAttributeEyesClosed
VNFaceAttributeEyesOpen
VNFaceAttributeNotSmiling
VNFaceAttributeSmiling
VNFaceAttributeFaceHairBeard
VNFaceAttributeFaceHairGoatee
VNFaceAttributeFaceHairMoustache
VNFaceAttributeFaceHairStubble
VNFaceAttributeFaceHairUnsure
VNFaceAttributeHairColorBlack
VNFaceAttributeHairColorBlonde
VNFaceAttributeHairColorBrown
VNFaceAttributeHairColorGray
VNFaceAttributeHairColorRed
VNFaceAttributeHairColorWhite
VNFaceAttributeNotBald
VNFaceAttributeBald
VNFaceAttributeGlassesPrescription
VNFaceAttributeGlassesSunglasses
VNFaceAttributeGlassesNone
Face Detector
v32@?0@8Q16^B24
v32@?0@"NSString"8@"AXMVisionFeatureFaceDetectionResult"16^B24
_faceRectanglesRequest
T@"VNDetectFaceRectanglesRequest",&,N,V__faceRectanglesRequest
_faceprintRequest
T@"VNCreateFaceprintRequest",&,N,V__faceprintRequest
_faceAttributesRequest
T@"VNClassifyFaceAttributesRequest",&,N,V__faceAttributesRequest
_faceExpressionsRequest
T@"VNDetectFaceExpressionsRequest",&,N,V__faceExpressionsRequest
_faceLandmarksRequest
T@"VNDetectFaceLandmarksRequest",&,N,V__faceLandmarksRequest
_facePoseRequest
T@"VNDetectFacePoseRequest",&,N,V__facePoseRequest
VNDetectFaceExpressionsRequest
VNClassifyFaceAttributesRequest
VNDetectFaceLandmarksRequest
VNDetectFacePoseRequest
VNDetectFaceRectanglesRequest
Aesthetics
_imageAestheticsRequest
T@"VNClassifyImageAestheticsRequest",&,N,V__imageAestheticsRequest
VNClassifyImageAestheticsRequest
AXMServiceConnection
hash
TQ,R
superclass
T#,R
description
T@"NSString",R,C
debugDescription
v16@?0@"NSError"8
xpcConnection
T@"NSXPCConnection",&,N,V_xpcConnection
state
name
metrics
startTime
endTime
startTaskInfoValue
startVMInfoValue
endTaskInfoValue
endVMInfoValue
{mach_task_basic_info=QQQ{time_value=ii}{time_value=ii}ii}
{task_vm_info=QiiQQQQQQQQQQQQQQQQQQQqqqqqqqqqqqqqqqqqqqqqQi}
%.2fMB
%.3fs
T@"NSString",&,N,V_name
representedMetrics
Tq,N,V_representedMetrics
isElapsedTimeMetric
TB,R,N
isMemoryFootprintMetric
initialResidentMemory
T@"NSNumber",R,N
initialResidentMemoryPeak
initialPhysicalFootprint
finalResidentMemory
finalResidentMemoryPeak
finalPhysicalFootprint
residentMemoryDelta
residentMemoryPeakDelta
physicalFootprintDelta
initialTime
finalTime
elapsedTime
AXMDiagnostics
diagnosticsEnabled
AXM_DIAGNOSTICS_ENABLED
TB,N,V_diagnosticsEnabled
T@"NSArray",R,C,N
visionObservations
AXMOutputRequest
B24@?0@"AXMOutputAction"8@"NSDictionary"16
handle
T@"AXMOutputRequestHandle",R,N,V_handle
actions
T@"NSArray",R,N
speechActions
oneShotSoundActions
activeSoundActions
completionBlock
T@?,C,N,V_completionBlock
interruptsAndClearsQueue
TB,N,V_interruptsAndClearsQueue
actionHandles
AXMSpeechFormatter does not implement getObjectValue:forString:errorDescription:
formattingBlock
T@?,C,N,V_formattingBlock
modelURL
Model Detector
Model loading not supported on this platform
T@"NSURL",&,N,V_modelURL
modelIdentifier
T@"NSString",R,N,V_modelIdentifier
region
orientation
Screen Capture
@"AXMPipelineContextInput"24@?0@"NSDictionary"8^@16
screenGrabber
T@"AXMScreenGrabber",&,N,V_screenGrabber
Traits
sampleFrequency
Tq,N,V_sampleFrequency
shouldEvaluateColorInformation
TB,N,V_shouldEvaluateColorInformation
colorDistanceTheshold
Td,N,V_colorDistanceTheshold
VNImageScoreObservation
VNImageBrightnessObservation
VNImageBlurObservation
VNImageBlurScoreRequest
photo.description.brightness.level.1
photo.description.brightness.level.2
photo.description.brightness.level.3
photo.description.brightness.level.4
photo.description.brightness.level.5
photo.description.blurriness.level.1
photo.description.blurriness.level.2
photo.description.blurriness.level.3
photo.description.blurriness.level.4
photo.description.blurriness.level.5
photo.description.blurriness.level.6
q24@?0@"AXMVisionFeature"8@"AXMVisionFeature"16
photo.description.faces
face.number
v32@?0@"NSString"8Q16^B24
q24@?0@"NSString"8@"NSString"16
blurFeature
T@"AXMVisionFeature",&,N,V_blurFeature
brightnessFeature
T@"AXMVisionFeature",&,N,V_brightnessFeature
Identifier
QueueSize
SourceNodes
EvaluationNodes
VisionEngineConfigurationDidChange
AXMVisionEngine
AXMImgRegistration
prioritySchedulingEnabled
prioritySchedulingAllowMultipleNodeExecution
thresholdPriority
v24@?0@"AXMVisionResult"8@"NSError"16
v32@?0@"AXMEvaluationNode"8Q16^B24
Create Image
InputImage
@"NSError"8@?0
Evaluate %@
Node
%@-%ld
%@<%p>: ID:'%@' [PriorSched:%@ threshhold:%lu] maxQueueSize:%ld cacheSize:%ld diagnostics:%@
%@%@
%@Source Nodes:
%@Evaluation Nodes:
Engine queue is at capacity
identifier
T@"NSString",C,V_identifier
axMediaUtilsService
T@"AXMService",&,N,V_axMediaUtilsService
cache
T@"AXMVisionEngineCache",&,N,V_cache
taskDispatcher
T@"AXMTaskDispatcher",&,N,V_taskDispatcher
sequenceRequestManager
T@"AXMSequenceRequestManager",&,N,V_sequenceRequestManager
sourceNodes
evaluationNodes
maximumQueueSize
Tq,V_maximumQueueSize
TB,V_prioritySchedulingEnabled
TB,V_prioritySchedulingAllowMultipleNodeExecution
TQ,V_thresholdPriority
imageRegistrationFilteringEnabled
TB,N,V_imageRegistrationFilteringEnabled
minimumImageRegistrationSignalLevel
Tq,N,V_minimumImageRegistrationSignalLevel
isCachingEnabled
cacheSize
Tq,R,N
TB,N,GareDiagnosticsEnabled,V_diagnosticsEnabled
disableResultLogging
TB,N,V_disableResultLogging
T@"NSUUID",&,N,V_identifier
context
T@"AXMVisionPipelineContext",&,N,V_context
source
T@"AXMSourceNode",&,N,V_source
VNRequestHandlerCleanupOption_AllPipelines
VNCleanupLevel_Complete
VNRequestHandlerCleanupOption_ImageBuffers
VNCleanupPurgeAll
VNImageRequestHandler
AXMLanguage
v16@?0@"NSNotification"8
AXMLanguage<%p> languageID: '%@'. Locale: <%p> '%@'
primaryComponent
secondaryComponent
languageCode
locale
T@"NSString",&,N,V_primaryComponent
T@"NSString",&,N,V_secondaryComponent
T@"NSString",&,N,V_languageCode
T@"NSLocale",&,N,V_locale
languageDisplayName
T@"NSString",R,N
videoFieldOfView
videoZoomFactor
videoSourceWidth
videoSourceHeight
presentationTimestamp
Tf,R,N,V_videoFieldOfView
Tf,R,N,V_videoZoomFactor
Tq,R,N,V_videoSourceWidth
Tq,R,N,V_videoSourceHeight
Td,R,N,V_presentationTimestamp
v56@?0@"NSString"8{_NSRange=QQ}16{_NSRange=QQ}32^B48
input
sourceProvidesResults
sourceparams
features
evaluatedFeatureTypes
analysisOptions
userContext
error
com.apple.accessibility.sceneobservation
AXMVisionPipelineContext<%p>: seqID:%lu source params: %@. error: %@
appliedImageOrientation
sequenceID
A creation node must return a valid image
%@-%ld-%ldx%ld.%@
Processing Context
T@"NSMutableArray",&,N,V_features
T@"NSMutableSet",&,N,V_evaluatedFeatureTypes
T@"NSError",&,N,V_error
T@"AXMVisionAnalysisOptions",&,N,V_analysisOptions
result
T@"AXMVisionResult",&,N,V_result
T@"NSNumber",&,N,V_appliedImageOrientation
diagnostics
T@"AXMDiagnostics",&,N,V_diagnostics
visionImageRequestHandler
T@"VNImageRequestHandler",&,N,V_visionImageRequestHandler
imageRegistrationState
Tq,N,V_imageRegistrationState
T@"NSObject<NSSecureCoding>",&,N,V_userContext
shouldProcessRemotely
TB,N,V_shouldProcessRemotely
resultHandlers
size
T{CGSize=dd},R,N
visionImageRequestHandlerIsLoaded
cacheKey
T@"<NSCopying>",&,N,V_cacheKey
shouldCallCompletionHandlersForEngineBusyError
TB,N,V_shouldCallCompletionHandlersForEngineBusyError
shouldCallCompletionHandlersForEmptyResultSet
TB,N,V_shouldCallCompletionHandlersForEmptyResultSet
evaluationExclusivelyUsesVisionFramework
TB,N,V_evaluationExclusivelyUsesVisionFramework
TQ,N,V_sequenceID
sourceInput
T@"AXMPipelineContextInput",R,N
AXMMinimumCharacterHeight
AXMDetectDiacritics
AXMReturnSubFeatures
AXMMinimizeFalsePositives
Text Detector
@16@?0@"NSString"8
recognitionLanguages
T@"NSArray",C,N,V_recognitionLanguages
customWords
T@"NSArray",C,N,V_customWords
VNTextRecognitionOptionEnglishCharacterSet
VNTextRecognitionOptionIcelandicCharacterSet
VNTextRecognitionOptionNorwegianCharacterSet
VNTextRecognitionOptionSwedishCharacterSet
VNTextRecognitionOptionDanishCharacterSet
VNTextRecognitionOptionGermanCharacterSet
VNTextRecognitionOptionDutchCharacterSet
VNTextRecognitionOptionFrenchCharacterSet
VNTextRecognitionOptionItalianCharacterSet
VNTextRecognitionOptionSpanishCharacterSet
VNTextRecognitionOptionPortugueseCharacterSet
VNDetectTextRectanglesRequest
VNRecognizeTextRequest
AXMGlobalTagLocale
AXMGlobalTagIsSpeakable
AXMGlobalTagIsEvaluated
IsSpeakable
IsNonspeakable
v32@?0@"NSString"8@16^B24
v40@?0@"NSDictionary"8{_NSRange=QQ}16^B32
AXMTaggedText<%p> Speakable:%d. Text: '%@'
AXMTaggedText<%p> : '%@'
 Locale: %@
 Is evaluated? %@
 Is speakable? %@
 Speakable Text: '%@'
 Global Attributes:
  %@ : %@
 Tokens:
  '%@' [%ld %ld] : %@
T@"NSLocale",R,N
speakable
TB,N,GisSpeakable
speakableText
v20@?0@"AXMTask"8B16
count
isEmpty
delegate
T@"<AXMTaskDispatcherDelegate>",W,N,V_delegate
complete
TB,N,GisComplete,V_complete
taskCompleteBlock
T@?,C,N,V_taskCompleteBlock
cameraPixelFocalLength
cameraOpticalOrigin
minimumAspectRatio
maximumAspectRatio
quadratureTolerance
minimumSize
minimumConfidence
maximumNumber
Rectangle Detector
Td,N,V_cameraPixelFocalLength
T{CGPoint=dd},N,V_cameraOpticalOrigin
Td,N,V_minimumAspectRatio
Td,N,V_maximumAspectRatio
Td,N,V_quadratureTolerance
Td,N,V_minimumSize
maximumNumberOfRects
Tq,N,V_maximumNumberOfRects
VNDetectRectanglesRequest
VNImageOptionCameraIntrinsics
green
blue
saturation
brightness
%@<%p> [r:%u g:%u b:%u] [h:%u s:%u b:%u]
redFloat
Td,R,N
greenFloat
blueFloat
hueFloat
saturationFloat
brightnessFloat
Black
Gray
Silver
White
Salmon
Rose
Brown
Coral
Orange
Chestnut
Gold
Olive
Ivory
Beige
Yellow
Lime Green
Light Green
Sea Foam Green
Forest Green
Green
Turquoise
Teal
Cyan
Aqua
Sky Blue
Royal Blue
Navy Blue
Indigo
Lavender
Purple
Fuchsia
Dark Purple
Light Pink
Violet
Pink
Maroon
Crimson
%@ name:%@
allColorMarkers
localizedName
T@"NSString",&,N,V_localizedName
synthesizer
T@"AVSpeechSynthesizer",&,N,V_synthesizer
currentRequestCompletionBlock
T@?,C,N,V_currentRequestCompletionBlock
Capture Session
AXMAVCaptureSessionNode does not support remote triggering
captureSessionNodeDelegate
T@"<AXMAVCaptureSessionNodeDelegate>",W,N,V_captureSessionNodeDelegate
frameDelegate
T@"<AXMAVCaptureSessionNodeFrameDelegate>",W,N,V_frameDelegate
AXMTag<%p>. [%@] [%lu %lu] '%@'
%@|%@|%@
Detected|Detector|PhoneNumber
Detected|Detector|Date
Detected|Regex|Email
Unknown
range
T{_NSRange=QQ},R,N
originalText
isPunctuation
isWhitespace
isSentenceTerminator
isOpenQuote
isCloseQuote
isPhoneNumber
isDate
isEmailAddress
notificationObserverTokens
T@"NSMutableArray",&,N,V_notificationObserverTokens
Ready
Unitialized
Initialize Failure
%@<%p>: state:'%@'
isSupported
componentState
Tq,N,V_componentState
AXMFeatures
AXMImage
__AXMStringForVariablesSentinel
detected.text.hint
detectedTextDescription
detectedFeatureDescription
detectedTextLanguage
AXMVisionResult<%p>: Image:%@ Results:%@ Feature Description: '%@'. Text Description: '%@'.
T@"NSString",&,N,V_detectedFeatureDescription
T@"NSString",&,N,V_detectedTextDescription
image
T@"CIImage",&,N,V_image
T@"NSArray",&,N,V_features
T@"NSSet",&,N,V_evaluatedFeatureTypes
colorInfoFeature
T@"AXMVisionFeature",R,N
assetMetadataFeature
localizedDetectedTextHint
T@"AXMLanguage",R,N
B32@?0@"AXMVisionFeature"8Q16^B24
faceFeatures
sceneClassificationFeatures
objectClassificationFeatures
modelClassificationFeatures
captionFeatures
ocrFeatures
blurFeatures
brightnessFeatures
iconClassFeatures
axm_featuresSortedByConfidence
axm_featureWithHighestConfidence
cacheQueue
AXMVisionEngineCache<%p>: %ld items
AXMVisionEngineCache<%p>: %ld items
  Key:%@
  Result:%@
v32@?0@"<NSCopying>"8@"AXMVisionResult"16^B24
AVPlayerItem
AXMAVPlayerItemNode does not support remote triggering
AXMAVPlayerItemNode-avkit-queue
%@ playerItem:<%@>
targetPlayerItem
T@"AVPlayerItem",W,N,V_targetPlayerItem
triggeringLegibilityEvents
TB,R,N,GisTriggeringLegibilityEvents,V_triggeringLegibilityEvents
Disgust
Neutral
Scream
Smile
Surprise
Suspicious
AXMFeatureFaceLandmarks
AXMFeatureFaceLandmarks3d
AXMFeatureFaceLandmarksConfidence
AXMFeatureFaceExpressions
AXMFeatureFacePose
AXMVisionFeatureCodingKeyFacePoseConfidence
AXMFeatureFaceName
AXMFeatureFaceNameConfidence 
AXMFeatureFaceAttributes
AXMFeatureFaceAttributesConfidence
AXMFeatureFaceRectangles
AXMFeatureFaceRectanglesConfidence
AXMFeatureFaceUUID
photo.description.expression.smile
photo.description.expression.scream
photo.description.expression.disgust
photo.description.expression.surprise
photo.description.expression.suspicious
uuid
T@"NSUUID",&,N,V_uuid
faceId
TQ,N,V_faceId
frame
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_frame
rectanglesConfidence
Td,N,V_rectanglesConfidence
nameConfidence
Td,N,V_nameConfidence
attributes
T@"AXMVisionFeatureFaceAttributes",&,N,V_attributes
attributesConfidence
Td,N,V_attributesConfidence
expressionsAndConfidence
T@"NSDictionary",&,N,V_expressionsAndConfidence
likelyExpression
landmarks
T@"AXMVisionFeatureFaceLandmarks",&,N,V_landmarks
landmarks3d
T@"AXMVisionFeatureFaceLandmarks",&,N,V_landmarks3d
landmarksConfidence
Td,N,V_landmarksConfidence
pose
T{?=[4]},N,V_pose
poseConfidence
Td,N,V_poseConfidence
v32@?0@"NSTextCheckingResult"8Q16^B24
[a-z0-9!#$%&'*+/=?^_`{|}~-]+(?:\.[a-z0-9!#$%&'*+/=?^_`{|}~-]+)*@(?:[a-z0-9](?:[a-z0-9-]*[a-z0-9])?\.)+[a-z0-9](?:[a-z0-9-]*[a-z0-9])?
label
T@"NSString",&,N,V_label
confidence
Td,N,V_confidence
sequenceRequestHandler
T@"VNSequenceRequestHandler",&,N,V_sequenceRequestHandler
VNSequenceRequestHandler
%@ [W:%.2f H:%.2f] [L:%.2f T:%.2f R:%.2f B:%.2f]
T{CGRect={CGPoint=dd}{CGSize=dd}},R,D,N
height
bottom
width
left
right
normalizedFrame
no source features provided
VNTextObservation
/System/Library/PrivateFrameworks/Vision.framework/Vision
VNRecognizedTextObservation
Image Registration
registrationState
VNTranslationalImageRegistrationRequest
VNImageTranslationAlignmentObservation
{CGSize=dd}
{CGPoint=dd}
{CGRect={CGPoint=dd}{CGSize=dd}}
bubbleUp
bubbleDown
pluck1
pluck2
scratch1
scratch2
success1
T@"AXMOutputActionHandle",R,N
text
aiff
sounds
soundFileURL
T@"NSURL",R,N
soundID
T@"AXMActiveSoundOutputActionHandle",R,D,N
handleProvider
T@"<AXMActiveSoundOutputActionHandleProvider>",&,N,V_handleProvider
pitch
Tf,N
rate
inputType
ciImage
use wrapperWithPixelBuffer:
PixelWidth
PixelHeight
T@"CIImage",R,N
pixelBuffer
T@"AXMPixelBufferWrapper",R,N
imageColorSpace
T^{CGColorSpace=},R,N
T^{__CVBuffer=},R,N
TI,R,N
unorientedSize
orientedSize
Sceneprint Creator
@"VNSceneObservation"8@?0
VNCreateSceneprintRequest
Asset Metadata
AXMSetting
writeOutInputImages
TB,D,N
writeOutOCRInputImages
writeOutScreenCaptures
'data' was not of required type NSData
'unarchivedResult' was not of type 'expectedClass'
assetURL
creationDate
localizedTypeDesc
TIFFImageDescription
IPTCCaptionAbstract
EXIFUserComment
PNGImageDescription
name:%@ created:%@ UTI:%@ typeDesc:%@
T@"NSURL",&,N,V_assetURL
T@"NSDate",&,N,V_creationDate
T@"NSString",&,N,V_uti
localizedTypeDescription
T@"NSString",&,N,V_localizedTypeDescription
T@"NSString",&,N,V_TIFFImageDescription
T@"NSString",&,N,V_IPTCCaptionAbstract
T@"NSString",&,N,V_EXIFUserComment
T@"NSString",&,N,V_PNGImageDescription
aestheticScore
wellFramedSubjectScore
wellChosenBackgroundScore
noiseScore
failureScore
pleasantCompositionScore
Aesthetics: aesthetic=%.2f wellFramedSubject=%.2f wellChosenBackground=%.2f noise=%.2f failure=%.2f pleasantComposition=%.2f
Tf,R,N,V_aestheticScore
Tf,R,N,V_wellFramedSubjectScore
Tf,R,N,V_pleasantCompositionScore
Tf,R,N,V_wellChosenBackgroundScore
Tf,R,N,V_noiseScore
Tf,R,N,V_failureScore
AXMDisplayManager
DeviceClassNumber
AXMDisplayManager:<%p> Initialized %ld
Frontbaord Main:%@
CADisplay Main:%@
Static (gestalt) props: %@
screen-dimensions
main-screen-orientation
main-screen-scale
scale
Aixt/MEN2O2B7f+8m4TxUA
supportsDeepColor
displayMonitor
T@"FBSDisplayMonitor",&,N,V_displayMonitor
mobileGestaltOrientation
Td,N,V_mobileGestaltOrientation
frontBoardMainDisplay
T@"AXMDisplay",R,N
coreAnimationMainDisplay
isInitialized
Default
None
CoreAnimation
FrontBoardServices (dynamic)
AXMDisplay<%p>: Backing:%@ Name:%@ scale:%@ size:[%.2f %.2f] orientation:%@ (%s) refBounds:[%.2f %.2f %.2f %.2f] deepColor:%d
backingType
Tq,N,V_backingType
T@"NSString",C,N,V_name
Td,N,V_scale
T{CGSize=dd},N,V_size
Td,N,V_orientation
physicalOrientation
Tq,N,V_physicalOrientation
referenceBounds
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_referenceBounds
TB,N,V_supportsDeepColor
AXMDisplayManagerMainDisplayWasUpdatedNotification
AXMPhysicalDisplayOrientationUnknown
AXMPhysicalDisplayOrientationPortrait
AXMPhysicalDisplayOrientationPortraitUpsideDown
AXMPhysicalDisplayOrientationLandscapeLeft
AXMPhysicalDisplayOrientationLandscapeRight
unknown
MM-dd-HH-mm-ss
image_%dx%d_%ld_%@.jpg
lexiconLocale
language
T@"AXMLanguage",R,N,V_language
Text Processing
v16@?0@"AXMTag"8
v16@?0@"AXMTaggedText"8
Text Pre-Processing
.,!?
axout-tmp
-axtmp
yyyy:MM:dd HH:mm:ss
MMMMddyyyyjjmm
MMMMddjjmm
jjmm
/System/Library/PrivateFrameworks/ScreenReaderCore.framework
SCRCPhotoEvaluator
image/png
filetype.image
image/bmp
image/jpeg
image/vnd.adobe.photoshop
filetype.psd
image/tiff
filetype.tiff
image/svg+xml
filetype.svg
text/css
filetype.css.file
text/csv
filetype.csv.file
text/html
filetype.html.file
text/calendar
filetype.calendar.event
text/plain
filetype.text.file
text/directory
filetype.contact.card
application/pdf
filetype.pdf
application/x-latex
filetype.latex
application/json
filetype.json
application/vnd.ms-excel
filetype.excel
application/onenote
filetype.onenote
application/vnd.ms-powerpoint
filetype.powerpoint
application/msword
filetype.word
application/postscript
filetype.postscript
application/rtf
filetype.rtf
application/xml
filetype.xml
application/rss+xml
filetype.rss
application/zip
filetype.zip
application/x-rar-compressed
filetype.rar
application/x-tar
filetype.tar
audio/mp4
filetype.audio
audio/x-wav
audio/x-m4a
video/quicktime
filetype.video
video/mp4
video/mpeg
video/x-m4v
audio/
com.apple.coreaudio-format
video/
usdz
filetype.3D.model
filetype.unknown
.dizzy
.thinking.heart
.sparkling
.arrow
.wings
.broken
.shattering
.exploding
.beating
.fist
.peace
.thumbs.up.back.of.hand
.thumbs.down
.ok.symbol
.pointing.left
.pointing.right
.crossing.fingers.back.of.hand
.crossing.fingers.palm.of.hand
.raised.hand
.hang.loose
.waving
.waving.royal
.face.eyes.open
.face.eyes.one.eye.closed
.face.eyes.hearts
.eyes.hearts
.eyes.one.eye.closed
.sunglasses
.aviator.sunglasses
.cat.eye.sunglasses
.eyes.furled
.eyes.crying
.eyes.open
.eyes.wide.open
.eyes.closed
.eyes.black.hearts
.eyes.crosses
.eyes.bandages
.eyes.half.closed
.eyes.half.closed.one
.eyes.tearing.up
.mouth.smiling
.mouth.smiling.half.open
.mouth.smiling.wide
.mouth.tongue
.mouth.blowing.kiss
.mouth.smirking
.mouth.half.frowning
.mouth.frowning
.mouth.gasping
.mouth.screaming
.mouth.thermometer
.mouth.surgical.mask
.mouth.smiling.teeth
heart-blue-loop-
emoji.heart.blue
heart-red-loop-
emoji.heart.red
heart-purple-loop-
emoji.heart.purple
hand-loop-
emoji.hand
face-red-loop-
emoji.face.sad
emoji.face.sleeping
emoji.face.confused.and.dismayed
emoji.face
emoji.red.face
face-yellow-loop-
emoji.yellow.face
UIScreen
Unable to find class %s
/System/Library/Frameworks/UIKit.framework/UIKit
UIAccessibilityIsVoiceOverRunning
UIGraphicsBeginImageContextWithOptions
UIGraphicsGetCurrentContext
UIGraphicsEndImageContext
AXMCoreMotionNode_samplesPerSecond
AXMCoreMotionNode_lastSampleTime
Core Motion
lastSampleTime
Td,N,V_lastSampleTime
samplesPerSecond
TQ,N,V_samplesPerSecond
com.apple.AXMediaUtilitiesService
com.apple.AXMediaUtilitiesService-access
contextQueue
Create CIContext
Could not rotate buffer with orientation: %@
could not allocate pixel buffer: %@
Could not rotate buffer: %@
CIAffineTransform
Prominent Object Detector
v32@?0@"VNRectangleObservation"8Q16^B24
_imageSaliencyRequest
T@"VNGenerateAttentionBasedSaliencyImageRequest",&,N,V__imageSaliencyRequest
VNGenerateAttentionBasedSaliencyImageRequest
Barcode
v40@?0{?={?=qq}Q}8^B32
priority
v32@?0@"VNRequest"8Q16^B24
VN PerformRequests
Vision Perform Requests:
ANEDeviceAvailable
TB,R,N,GisANEDeviceAvailable
effectivePriority
TQ,N,V_effectivePriority
Td,N,V_minimumConfidence
TQ,N,V_priority
VNProcessingDevice
speech.formatter.email.address.standard.phonetic
 %@ 
speech.formatter.email.address.at.phonetic
AXMVisionFeatureFaceLandmarksIs3DLandmarks
AXMVisionFeatureFaceLandmarksResults
photo.landmarks.nose
photo.landmarks.face
photo.landmarks.lefteye
photo.landmarks.righteye
photo.landmarks.innerlips
photo.landmarks.leftpupil
photo.landmarks.nosecrest
photo.landmarks.mouth
photo.landmarks.medianline
photo.landmarks.rightpupil
photo.landmarks.lefteyebrow
photo.landmarks.righteyebrow
is3DLandmarks
TB,N,V_is3DLandmarks
VNFaceLandmarks2D
detectionFlavor
minimumCharacterHeight
detectDiacritics
returnSubFeatures
minimizeFalsePositives
recognitionLevel
normalizedMinimumTextHeightRatio
usesLanguageCorrection
correctSpelling
spellCheckingLanguages
textDetectionLanguage
AXMTextDetectionOptions<%p>
  Options: 
    Flavor: Detect Text Rectangles
    Minimum Character Height: %.2f
    Detect Diacritics: %ld
    Return Subfeatures: %ld
    Minimize False Positives: %ld
    Flavor: Recognize Text
    Recognition Level: %@
Fast
Accurate
    Minimum Text Height Ratio: %.3f
    Use Language Correction: %ld
    Detection Language: %@
    Correct Spelling: %ld
    Spell-checking languages: %@
TQ,N,V_detectionFlavor
TB,N,V_correctSpelling
T@"AXMLanguage",&,N,V_textDetectionLanguage
T@"NSSet",&,N,V_spellCheckingLanguages
Td,N,V_minimumCharacterHeight
TB,N,V_detectDiacritics
TB,N,V_returnSubFeatures
TB,N,V_minimizeFalsePositives
TQ,N,V_recognitionLevel
Td,N,V_normalizedMinimumTextHeightRatio
TB,N,V_usesLanguageCorrection
clientID
includeImageInResult
detectText
textDetectionOptions
detectScenes
detectModelClassifications
detectCaptions
detectTraits
detectFaceRectangles
detectFaceNames
detectFaceAttributes
detectFaceExpressions
detectFaceLandmarks
detectFacePose
detectHorizon
detectRectangles
detectProminentObjects
detectAesthetics
ignoredLayerContextIDs
AXMVisionAnalysisOptions<%p>. Client: %ld
  Detectors:
    Traits: %ld
    Faces: %ld
    Text: %ld
      Options: None
      Options: 
        Flavor: Detect Text Rectangles
        Minimum Character Height: %.2f
        Detect Diacritics: %ld
        Return Subfeatures: %ld
        Minimize False Positives: %ld
        Flavor: Recognize Text
        Recognition Level: %@
        Minimum Text Height Ratio: %.3f
        Use Language Correction: %ld
        Detection Language: %@
        Correct Spelling: %ld
        Spell-checking languages: %@
    Scenes: %ld
    Model Classifications: %ld
    Captions: %ld
    Prominent Objects: %ld
    Aesthetics: %ld
Tq,N,V_clientID
hasDetectionsEnabled
detectFaces
TB,N,V_detectFaceRectangles
TB,N,V_detectFaceNames
TB,N,V_detectFaceAttributes
TB,N,V_detectFaceExpressions
TB,N,V_detectFaceLandmarks
TB,N,V_detectFacePose
TB,N,V_detectScenes
TB,N,V_detectModelClassifications
TB,N,V_detectCaptions
TB,N,V_detectTraits
TB,N,V_detectRectangles
TB,N,V_detectHorizon
TB,N,V_detectProminentObjects
TB,N,V_detectAesthetics
TB,N,V_detectText
T@"AXMTextDetectionOptions",&,N,V_textDetectionOptions
TB,N,V_includeImageInResult
T@"NSArray",&,N,V_ignoredLayerContextIDs
OutputManager
AXMOutputManager<%p>: state:'%@'. Speech? %@. Sound? %@.
request
T@"AXMOutputRequest",&,N,V_request
spellChecker
T@"AppleSpell",&,N,V_spellChecker
AXMFeatureType
AXMFeatureCanvasSize
AXMFeatureFrame
AXMFeatureNormalizedFrame
AXMFeatureValue
AXMFeatureBarcodeType
AXMOCRFeatureType
AXMFeatureColorInfo
AXMFeatureAssetMetadata
AXMFeatureBlur
AXMFeatureBrightness
AXMFeatureConfidence
AXMFeatureHorizonTransform
AXMFeatureHorizonAngle
AXMFeatureFaceDetectionResult
AXMFeatureFaceID
AXMDeviceMotion
AXMFeatureDeviceOrientation
AXMFeatureCameraType
AXMFeatureModelID
AXMFeatureAesthetics
AXMFeatureUserContext
detectionLanguage
classificationLocalizedValue
classificationLabel
caption
subfeatures
color info
asset metadata
Top left
Top right
Right
Center
Left
Bottom left
Bottom
Bottom right
Outside top left
Outside top
Outside top right
Outside right
Outside left
Outside bottom left
Outside bottom
Outside bottom right
centered
near.left.edge
near.top-left.edge
near.top.edge
near.top-right.edge
near.right.edge
near.bottom-right.edge
near.bottom.edge
near.bottom-left.edge
outside.left
outside.top-left
outside.top
outside.top-right
outside.right
outside.bottom-right
outside.bottom
outside.bottom-left
.implicit-subject
Document
Region
Line
Char
Diacrit
Brightness
Blur
Color
Face
RealtimeFace
Person
SceneClassification
ObjectClassification
ModelClassifier
Caption
MediaLegibility
AssetMetadata
Horizon
Rectangle
Motion
CameraMetadata
ProminentObject
IconClass
Sequence
Character
Diacritic
AXMVisionFeature<%p> %@
face id: %lu 
Name: %@ 
[faceLandmarks: %@ faceLandmarks3d: %@ faceExpressions: %@ likelyExpression: %@ likelyConfidence: %f] 
Face Attributes : %@
Face location: %@
value:'%@' type:%@ 
classificationLabel:'%@' localizedName:'%@' 
ModelID: '%@' classificationLabel:'%@' 
caption:'%@' 
value:'%.2f' 
value:'%@' 
asset info [%@] 
horizon transform. angle: %f 
location : %@
frame:%@ (normalized:%@) 
confidence:%.2f
dictionaryRepresentation
T@"NSDictionary",R,N
debugRectangles
T@"NSDictionary",&,N,V_debugRectangles
featureType
TQ,R,N
isBarcode
isFace
isRealtimeFace
isPerson
isSceneClassification
isObjectClassification
isBrightness
isBlur
isHorizon
isColor
isMediaLegibility
isAssetMetadata
isRectangle
isModelClassification
isCaption
isMotion
isCameraMetadata
isProminentObject
isIconClass
isImageAesthetics
isOCR
isTextDocument
isTextRegion
isTextLine
isTextSequence
isTextCharacter
isTextDiacritic
canvasSize
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N
value
isValueSpeakable
barcodeType
ocrFeatureType
colorInfo
T@"AXMVisionFeatureColorInfo",R,N
assetMetadata
T@"AXMVisionFeatureAssetMetadata",R,N
blur
faceDetectionResult
T@"AXMVisionFeatureFaceDetectionResult",R,N
unpaddedDetectedFaceRect
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,V_unpaddedDetectedFaceRect
horizonTransform
T{CGAffineTransform=dddddd},R,N
horizonAngle
Tf,R,N
aestheticsResult
T@"AXMVisionFeatureAestheticsResult",R,N,V_aestheticsResult
deviceOrientation
Tq,R,N,V_deviceOrientation
Alex
taggedText
T@"AXMTaggedText",R,N
Caption Detector
taxonomyOptions
Scene Detector
possibleSceneClassifications
_sceneClassificationRequest
T@"VNSceneClassificationRequest",&,N,S_setSceneClassificationRequest:,V__sceneClassificationRequest
TI,N,V_taxonomyOptions
VNSceneClassificationRequest
player
T@"AVAudioPlayerNode",&,N,V_player
timePitch
T@"AVAudioUnitTimePitch",&,N,V_timePitch
configChangedObserverToken
T@,&,N,V_configChangedObserverToken
activeSound
T@"AXMActiveSound",W,N,V_activeSound
soundComponent
T@"AXMSoundComponent",W,N,V_soundComponent
Tf,N,V_rate
Tf,N,V_pitch
datatype-%lu
AXMNodeID
AXNodeEnabled
NodeQueue
%@<%p>: ID:'%@' title:'%@' supported:%@ needsVisionKit:%@ enabled:%@ connected:%@
title
connected
TB,N,GisConnected,V_connected
T@"<AXMVisionEngineNodeConnectionDelegate>",W,N,V_delegate
T@"NSString",C,N,V_identifier
nodeQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_nodeQueue
requiresVisionFramework
enabled
TB,N,GisEnabled,V_enabled
AXMedia Utilities System Report: <Unavailable on this platform>
AXMedia Utilities System Report (privileged): <Unavailable on this platform>
Image
VoiceOver
screenCapture
scene
face
trait
prominentObjects
captions
use init()
captureNode
T@"AXMScreenCaptureNode",W,N,V_captureNode
imageNode
T@"AXMImageNode",W,N,V_imageNode
textDetector
T@"AXMTextDetectorNode",W,N,V_textDetector
sceneDetector
T@"AXMSceneDetectorNode",W,N,V_sceneDetector
faceDetector
T@"AXMFaceDetectorNode",W,N,V_faceDetector
traitDetector
T@"AXMTraitDetectorNode",W,N,V_traitDetector
prominentObjectsDetector
T@"AXMProminentObjectsDetectorNode",W,N,V_prominentObjectsDetector
captionDetector
T@"AXMCaptionDetectorNode",W,N,V_captionDetector
Library/Accessibility
AXMediaUtilities
%.1f,%.1f,%.1f,%.1f
%.2f,%.2f,%.2f,%.2f
%.1f,%.1f
, %@
AXDateFormatter
{CGVector=dd}
{CGAffineTransform=dddddd}
AXMPointValue
T{CGPoint=dd},R,N
AXMVectorValue
T{CGVector=dd},R,N
AXMSizeValue
AXMRectValue
AXMAffineTransformValue
Creating new lexicon for locale (an expensive operation): %@ (language: %@) (id: %@)
Unable to create lexicon: %@
No lexicon found for locale: %@
Could not fetch uncompiled photo caption models: %@
Could not evaluate. VNDetectHorizonRequestSoft was nil
input arrays must be same length
Unhandled mapping for AXMVisionFeatureAgeCategory
Unhandled mapping for AXMVisionFeatureGenderCategory
Unhandled mapping for AXMVisionFeatureEyesCategory
Unhandled mapping for AXMVisionFeatureSmilingCategory
Unhandled mapping for AXMVisionFeatureFaceHairCategory
Unhandled mapping for AXMVisionFeatureHairColorCategory
Unhandled mapping for AXMVisionFeatureBaldCategory
Unhandled mapping for AXMVisionFeatureGlassesCategory
Could not evaluate. VNDetectFaceExpressionsRequestSoft was nil
Could not evaluate. VNClassifyFaceAttributesRequestSoft was nil
Could not evaluate. VNDetectFaceLandmarksRequestSoft was nil
Could not evaluate. VNDetectFacePoseRequestSoft was nil
Could not evaluate. VNDetectFaceRectanglesRequestSoft was nil
AXMFaceDetectorNode: no requests to evaluate
Could not evaluate. VNClassifyImageAestheticsRequestSoft was nil
AXMService being deallocated: %@
Connection to service interrupted. client: %@
Connection to service invalidated. client: %@
Failed to get service proxy: %@
Calling elapsedTime before metric is in finished state is invalid
Could not look up MACH_TASK_BASIC_INFO. err:%@ (%s)
Could not look up TASK_VM_INFO. err:%@ (%s)
Metric must be in 'initialized' state whem calling start
Starting task '%@' PhysFtPrnt '%@' ResMem '%@' ResMemPk '%@'
Metric must be in 'measuring' state whem calling finish
Finished task '%@' Elapsed time '%@' PhysFtPrnt:['%@', +/- '%@'] ResMem:['%@', +/- '%@'] ResMemPk:['%@', +/- '%@']
Could not produce URL for soundID: %@
Could not make soundAction url does not exist: %@
Could not make sound. Action url does not exist: %@
Model Detector not available on this platform
Could not evaluate. VNImageScoreObservationSoft was nil
Could not evaluate. VNImageBrightnessObservationSoft was nil
Could not evaluate. VNImageBlurObservationSoft was nil
Could not evaluate. requestHandler was nil
Could not evaluate: %@
engine threshold priority: %ld
   node <%p> :'%@'. boosted priority:%ld
highest priority node(s): %@
Did not produce result features. Result was nil
Did not produce result features. Features was nil
Did not produce result features. Feature list was empty
Did produce result with %lu features:
  %@
Resulting speakable description. [features:'%@'] [text:'%@']
------------------------------------------------------
With priority scheduling, there can be at most 1 evaluation node per cycle
'writeOutInputImages' is enabled. Writing input images to %@
CreateImage
EvaluateNode
Cannot add source node. %@
Cannot add a node that is already connected
Cannot add evaluation node. %@
A context must be provided
A source must be provided
AXMVisionEngine: canceling queued task to replace with newer incoming task
AXMVisionEngine: ignoring task since queue is full (maximumQueueSize = %ld)
userContext class %@ not in AXMSecureCodingClasses()
Will not perform OCR due to error: %@
Will not perform OCR. Requested language is not supported: %@
Could not evaluate. VNDetectTextRectanglesRequestSoft was nil
Could not evaluate. VNRecognizeTextRequestSoft was nil
Did detect OCR observations
  %@ text:'%@'
Did not detect any VNTextObservations
Could not create text document: %@
Did not detect any OCR observations
Will detect text with options: %@
task should not be in the completed state
taskIsBeingProcessed should be YES
taskIsBeingProcessed should be NO
Task should not be complete if being marked as complete
Could not evaluate. VNDetectRectanglesRequestSoft was nil
handleRequest: expected nil completion block
speech started: '%@'
speech finished: '%@'
didFinish: expected completion block, but found nil.
speech canceled: '%@'
didCancel: expected completion block, but found nil.
speech paused: '%@'
speech resumed: '%@'
There should be 0 or 1 OCR features
Top level text object should be the document
Result found for key: %p. moving to newest position
set nil result. removing key: %p. %ld items remain
set new result. adding key: %p. %ld items remain
cache size too big. evicted key: %p. %ld items remain
purge cache of all keys
Will begin processing legibility events with player item: %@
Asked to auto-trigger events with item: '%@', but same targetPalyerItem was already set!
Asked to auto-trigger events with item: '%@', but targetPalyerItem already exists: '%@'. Unregistering current targetPalyerItem first. 
Will stop processing legibility events for player item: %@
legibility event: %@
Failed to archive expressionsAndConfidence data: %@
Error decoding face expression dict: %@
Metric types are not compatible '%ld' and '%ld'
metric does not support float values: '%ld'
metric does not support frame values: '%ld'
Input feature of unexpected type. expected 'VNTextObservation'. got '%@'
Will assemble lines...
  Next sequence: %@
   Compare w/ line %@
   threshold (%.0f%% of lineItem.height): %.2f
   sequence and line differ. height:%ld top:%ld
  Adding sqeuence to line
  Creating new line with sequence
Will assemble regions...
  Next line: %@
   Compare w/ region %@
   threshold (%.0f%% of regionItem.firstLine.height): %.2f
   line and region differ. height:%ld left:%ld
  Adding line to region
  Creating new region with line
Could not evaluate. VNTranslationalImageRegistrationRequestSoft was nil
Could not evaluate. VNImageTranslationAlignmentObservationSoft was nil
Could not evaluate. VNCreateSceneprintRequestSoft was nil
Did get KVO update for key: '%@'. change: %@
AXMDisplayManager initialized: %@
Unable to look up screenInfo
Unable to look up screen scale
Unexpected physical screen orientation
connected new display. Updating AXMDisplay properties
display config changed. Updating AXMDisplay properties
disconnected new display
unknown interface orienation
Orientation unexpected: AXMPhysicalDisplayOrientationPortraitUpsideDown. If you see this assert, please file a bug with PEP Accessibility and your device type. 
unhandled display orientation. AXMPhysicalDisplayOrientationUnknown / default
Unknown interface orientation. assuming portrait
Will process text: '%s'. language: %@
Text being marked as unspeakable becuase of tag: '%@'
Text being marked as unspeakable becuase no lexicon exists for locale: %@
Result text: '%s
Will pre-process text: '%s'
Preprocessed text: '%s'
AX: Export Session status: %ld %@
AX: EXPORT: 1 Error: %@
AX: EXPORT: 2 Error: %@
AX: EXPORT: 3 Error: %@
Error retrieving caption: %@
Error setting caption: %@
unknown file type: UTI: %@, extension: %@
Could not evaluate. VNGenerateAttentionBasedSaliencyImageRequestSoft was nil
Input text: '%@'
Input locale: '%@'
Token: '%@' [%lu, %lu] Type: '%@' Class: '%@' Lang: '%@' Script: '%@' Entity: '%@' Subtoken: '%@'
Could not evaluate. VNProcessingDeviceSoft was nil
Error decoding face landmark dict: %@
Failed to archive face landmark results: %@
Could not de-activate audio session: %@
Could not activate audio session: %@
Ignoring dispatch request. Output manager not ready
Using languages for spell checking: %s
spell-checking pass %ld of %ld
length of textToCheck is 0. break
Will look for misspelled word in text: '%s'. index: %ld
No misspelled words found. break
Misspelled word found at range [%ld, %ld], '%s'
replacing with correction: '%s' at range:[%ld %ld]
text after replacement: '%s'
No correction found
Source node not connected to any engine
Error decoding subfeatures array: %@
Failed to archive subfeature data: %@
_valueForTextFeature is only valid for OCR features
subfeatures of a document should be regions
subfeatures of a region should be lines
subfeatures of a line should be sequences
textCharacter is not implemented
textDiacritic is not implemented
_isTextFeatureValueSpeakable is only valid for OCR features
Caption Detector not available on this platform
Could not evaluate. VNSceneClassificationRequestSoft was nil
Error starting audio engine: %@
Unexpected state change. from %@. to %@
Could not handle audio request: %@. Error:%@
Could not begin active sound playback: %@
One-shot sound player did finish playing sound
Could not start engine: %@
Subclass should override
Failed to create AXMediaUtilities working directory at path: %@. error: %@
AXMLexiconManager
UnitTesting
AXMScreenGrabber
AXMAssetManager
AXMHorizonDetectorNode
AXMVisionFeatureColorInfo
NSSecureCoding
NSCoding
AXMVisionFeatureFaceAttributes
AXMFaceDetectorNode
AXMImageAestheticsNode
AXMServiceClientInterface
NSObject
AXMService
AXMServiceInterface
AXMDiagnosticMetric
AXMDiagnostics
AXMInertDiagnostics
AXMDiagnosticMetricToken
AXMOutputRequest
AXMOutputRequestHandle
AXMSpeechFormatter
AXMSpeechBlockFormatter
AXMModelDetectorNode
AXMScreenCaptureNode
AXMTraitDetectorNode
AXMDescriptionBuilder
AXMVisionEngine
AXMVisionEngineNodeConnectionDelegate
AXMTaskDispatcherDelegate
NSCopying
AXMDescribing
_AXMVisionEngineAnalysisTask
AXMVisionFeatureComparator
AXMLanguage
AXMCameraFrameContext
AXMPhoneNumberSpeechFormatter
AXMVisionPipelineContext
AXMTextDetectorNode
AXMTaggedText
AXMTaskDispatcher
AXMTask
AXMRectangleDetectorNode
AXMVisionColor
AXMVisionColorMarker
AXMSpeechComponent
AVSpeechSynthesizerDelegate
AXMAVCaptureSessionNode
AXMTag
AXMReplacementTag
AXMAudioSession
AXMOutputComponent
AXMVisionResult
AXMVisionEngineLookupConvenience
AXMVisionEngineCache
_AXMPlayerItemLegibleOutput
AXMAVPlayerItemNode
AVPlayerItemLegibleOutputPushDelegate
AVPlayerItemOutputPushDelegate
AXMVisionFeatureFaceDetectionResult
AXMDataDetector
AXMTaxonomyNode
AXMPhotoVisionSupport
AXMGeometryUtilities
AXMSequenceRequestManager
AXMLayoutItem
AXMLayoutSequence
AXMLayoutLine
AXMLayoutRegion
AXMTextLayoutManager
AXMImageRegistrationNode
AXMExtras
AXMOutputAction
AXMSpeechOutputAction
AXMSoundOutputAction
AXMOneShotSoundOutputAction
AXMActiveSoundOutputAction
AXMOutputActionHandle
AXMActiveSoundOutputActionHandle
AXMPipelineContextInput
AXMPixelBufferWrapper
AXMImageCaptionModel
AXMSceneprintBasedNode
AXMAssetMetadataNode
_AXMSettingObserver
AXMSettings
AXMVisionFeatureAssetMetadata
AXMVisionFeatureAestheticsResult
AXMDisplayManager
FBSDisplayObserving
AXMDisplay
AXMTextProcessingOperation
AXMTextProcessor
AXMCoreMotionNode
AXMProminentObjectsDetectorNode
AXMBarcodeNode
AXMTagger
AXMEvaluationNode
AXMEmailAddressSpeechFormatter
AXMVisionFeatureFaceLandmarks
AXMTextDetectionOptions
AXMVisionAnalysisOptions
AXMOutputManager
_AXMOutputRequestTask
AXMSpellChecker
AXMSourceNode
AXMVisionFeature
AXMJSONSerializable
AXUnitTesting
Private
AXMCaptionDetectorNode
AXMSceneDetectorNode
AXMActiveSound
AXMSoundComponent
AXMActiveSoundOutputActionHandleImpl
AXMActiveSoundOutputActionHandleProvider
AXMSpeechFormatterCache
AXMVisionEngineNode
AXMDeviceInfo
AXMImageNode
AXMVoiceOverVisionEngine
AXMGeomerty
init
dictionary
_lexiconForLocale:diagnostics:
currentLocale
objectForKey:
languageCode
localeIdentifier
dictionaryWithObjects:forKeys:count:
stringWithFormat:
captureMetrics:name:forTask:
setObject:forKey:
lexiconExistsForLocale:diagnostics:
textExistsInLexicon:withLocale:diagnostics:
.cxx_destruct
_cachedLexicons
_opaqueLexiconForLocale:diagnostics:
grabScreenWithRect:orientation:ignoredLayerContextIDs:diagnostics:error:
grabScreenWithRect:orientation:ignoredLayerContextIDs:renderToPixelBufferNow:diagnostics:error:
fileURLWithPath:
URLByAppendingPathComponent:
_modelsDirectoryForType:compiled:
_photoCaptionAssetsDirectory
_modelAssetURLsOfType:sources:compiled:
array
defaultManager
contentsOfDirectoryAtURL:includingPropertiesForKeys:options:error:
countByEnumeratingWithState:objects:count:
pathExtension
isEqualToString:
addObject:
URLByDeletingPathExtension
lastPathComponent
_modelAssetNamesOfType:sources:compiled:
_modelAssetURLForModelNamed:ofType:sources:compiled:
_uncompiledModelsDirectoryForType:
_compiledModelsDirectoryForType:
compiledModelAssetURLsOfType:sources:
uncompiledModelAssetURLsOfType:sources:
compiledModelAssetNamesOfType:sources:
uncompiledModelAssetNamesOfType:sources:
compiledModelAssetURLForModelNamed:ofType:sources:
uncompiledModelAssetURLForModelNamed:ofType:sources:
modelWithName:ofType:sources:compileIfNeeded:persistCompiledModel:error:
nodeInitialize
initWithCoder:
encodeWithCoder:
validateVisionKitSoftLinkSymbols
evaluate:
_detectHorizonRequest
alloc
_setDetectHorizonRequest:
arrayWithObjects:count:
evaluateRequests:withContext:requestHandlerOptions:error:
results
firstObject
size
featureWithVisionRequest:horizonResult:canvasSize:
appendFeature:
supportsSecureCoding
isSupported
title
requiresVisionFramework
__detectHorizonRequest
decodeObjectOfClasses:forKey:
setMainColors:weights:
mainColors
encodeObject:forKey:
mainColorWeights
count
setMainColors:
setMainColorWeights:
objectAtIndexedSubscript:
floatValue
enumerateMainColors:
remainingColorWeight
setRemainingColorWeight:
_remainingColorWeight
_mainColors
_mainColorWeights
ageCategory
label
identifier
_AXMAgeCategoryForVisionCategoryIdentifier:
genderCategory
_AXMGenderCategoryForVisionCategoryIdentifier:
eyesCategory
_AXMEyesCategoryForVisionCategoryIdentifier:
smilingCategory
_AXMSmilingCategoryForVisionCategoryIdentifier:
faceHairCategory
_AXMFaceHairCategoryForVisionCategoryIdentifier:
hairColorCategory
_AXMHairColorCategoryForVisionCategoryIdentifier:
baldCategory
_AXMBaldCategoryForVisionCategoryIdentifier:
glassesCategory
_AXMGlassesCategoryForVisionCategoryIdentifier:
encodeInteger:forKey:
decodeIntegerForKey:
numberWithInteger:
objectForKeyedSubscript:
integerValue
bundleWithIdentifier:
localizedStringForKey:value:table:
_accessibilityLabelForAgeCategory
_accessibilityLabelForSmilingCategory
_accessibilityLabelForFaceHairCategory
_accessibilityLabelForHairColorCategory
_accessibilityLabelForBaldCategory
_accessibilityLabelForGlassesCategory
string
appendString:
unitTestingFaceAttributes
initWithVisionFaceAttributes:
_accessibilityLabelForEyesCategory
accessibilityLabelForAttributes
setResults:
_ageCategory
_genderCategory
_eyesCategory
_smilingCategory
_faceHairCategory
_hairColorCategory
_baldCategory
_glassesCategory
_results
analysisOptions
detectFaceAttributes
_faceAttributesRequest
set_faceAttributesRequest:
detectFaceExpressions
_faceExpressionsRequest
set_faceExpressionsRequest:
detectFaceLandmarks
_faceLandmarksRequest
set_faceLandmarksRequest:
detectFacePose
_facePoseRequest
set_facePoseRequest:
detectFaceRectangles
_faceRectanglesRequest
set_faceRectanglesRequest:
uuid
_faceResultForUUID:inFaceDictionary:
faceId
setFaceId:
setUuid:
boundingBox
setFrame:
confidence
setRectanglesConfidence:
faceAttributes
setAttributes:
setAttributesConfidence:
expressionsAndConfidence
setExpressionsAndConfidence:
landmarks
initWithVisionFaceLandmarks:
setLandmarks:
landmarks3d
setLandmarks3d:
setLandmarksConfidence:
pose
setPose:
setPoseConfidence:
enumerateObjectsUsingBlock:
_createRequestsForContext:
_faceDetectionResultsForVisionRequests:canvasSize:
featureWithFaceDetectionResult:canvasSize:
enumerateKeysAndObjectsUsingBlock:
addEvaluatedFeatureType:
UUIDString
setObject:forKeyedSubscript:
_faceprintRequest
set_faceprintRequest:
__faceRectanglesRequest
__faceprintRequest
__faceAttributesRequest
__faceExpressionsRequest
__faceLandmarksRequest
__facePoseRequest
_imageAestheticsRequest
set_imageAestheticsRequest:
configureForRunningOnANEIfPossibleWithRequest:
featureWithImageAestheticsObservation:
__imageAestheticsRequest
invalidate
_destroyXPCConnection
dealloc
initWithServiceName:
setRemoteObjectInterface:
isEqual:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
description
debugDescription
interfaceWithProtocol:
setExportedInterface:
setExportedObject:
setInterruptionHandler:
setInvalidationHandler:
resume
xpcConnection
remoteObjectProxyWithErrorHandler:
_serviceProxy
prewarmVisionEngineService
visionEngine:evaluateSource:context:options:result:
setXpcConnection:
_xpcConnectionQueue
_xpcConnection
_commonInit
setName:
setRepresentedMetrics:
decodeObjectOfClass:forKey:
isElapsedTimeMetric
decodeInt64ForKey:
isMemoryFootprintMetric
getValue:size:
name
representedMetrics
encodeInt64:forKey:
valueWithBytes:objCType:
numberWithUnsignedLongLong:
initialResidentMemory
finalResidentMemory
unsignedLongLongValue
numberWithLongLong:
initialResidentMemoryPeak
finalResidentMemoryPeak
initialPhysicalFootprint
finalPhysicalFootprint
initialTime
finalTime
numberWithDouble:
numberWithInt:
_capturMachAbsoluteTime:taskInfo:vmInfo:
elapsedTime
doubleValue
physicalFootprintDelta
longLongValue
residentMemoryDelta
residentMemoryPeakDelta
initWithName:metrics:
start
finish
_state
_startTime
_endTime
_startTaskInfo
_startVMInfo
_endTaskInfo
_endVMInfo
_name
_representedMetrics
_init
setWithArray:
mutableCopy
decodeBoolForKey:
setDiagnosticsEnabled:
metrics
diagnosticsEnabled
encodeBool:forKey:
processInfo
environment
boolValue
removeAllObjects
copy
addMetric:
captureMetrics:name:forTask:signpostStartBlock:signpostEndBlock:
addObjectsFromArray:
clearMetrics
startMeasurement:name:
appendVisionObservations:
visionObservations
_queue
_queue_diagnosticMetrics
_queue_visionObservations
_diagnosticsEnabled
sharedInstance
_diagnostics
_metric
initWithString:
actions
predicateWithBlock:
filteredArrayUsingPredicate:
handle
addActionHandle:
initWithText:
_addAction:
initWithSoundID:
initWithURL:
speechItemSeparator
speechActions
oneShotSoundActions
activeSoundActions
addSpeechItem:
addSoundItemWithID:
addSoundItemWithURL:
addActiveSoundItemWithID:
addActiveSoundItemWithURL:
completionBlock
setCompletionBlock:
interruptsAndClearsQueue
setInterruptsAndClearsQueue:
_handle
_queue_actions
_interruptsAndClearsQueue
_completionBlock
actionHandles
_actionHandles
speechStringForObjectValue:
stringForObjectValue:
getObjectValue:forString:errorDescription:
initWithFormattingBlock:
formattingBlock
setFormattingBlock:
_formattingBlock
decodeObjectForKey:
path
preloadModelIfNeeded:
modelURL
setModelURL:
modelIdentifier
_modelURL
_modelIdentifier
setShouldProcessRemotely:
AXMRectValue
ignoredLayerContextIDs
evaluationExclusivelyUsesVisionFramework
screenGrabber
diagnostics
inputWithCIImage:
produceImage:
defaultOptions
axmValueWithCGRect:
contextWithSourceParameters:options:
triggerWithContext:cacheKey:resultHandler:
triggerWithScreenCaptureRegion:interfaceOrientation:options:cacheKey:resultHandler:
setScreenGrabber:
_screenGrabber
shouldEvaluateColorInformation
_evaluateColorInformation:
visionImageRequestHandler
performRequests:error:
_blurValueForVisionObservation:
featureWithVisionRequest:blurValue:canvasSize:
brightness
numberWithFloat:
exposureScore
blurMeasure
blurScore
_brightnessValueForVisionObservation:
sampleFrequency
setSampleFrequency:
setShouldEvaluateColorInformation:
colorDistanceTheshold
setColorDistanceTheshold:
_shouldEvaluateColorInformation
_sampleFrequency
_colorDistanceTheshold
_initWithOptions:
classificationLocalizedValue
addDetectedClassificationLocalizedValue:
length
_addCaptionInformationToDescription:
_addBrightnessInformationToDescription:
_addBlurInformationToDescription:
_addFaceInformationToDescription:
_addClassificationInformationToDescription:
_addIconClassInformationToDescription:
buildSpeakableDescription
hasSuffix:
_stringForPauseType:
appendFormat:
_appendPauseType:toDescriptionIfNeeded:
_appendToDescription:afterPauseType:withContents:
blur
faceDetectionResult
compare:
sortUsingComparator:
localizedStringWithFormat:
likelyExpression
numberWithLong:
attributes
allKeys
localizedStringFormatterForExpression:
caption
allObjects
sortedArrayUsingComparator:
axm_featureWithHighestConfidence
value
builderWithOptions:
addDetectedFaces:
addDetectedClassificationFeatures:
setDetectedCaption:
addDetectedIconClasses:
buildVisualDescription
blurFeature
setBlurFeature:
brightnessFeature
setBrightnessFeature:
_builderOptions
_speakableDescription
_visualDescription
_faceFeatures
_classificationLocalizedValues
_iconClassFeatures
_captionFeature
_blurFeature
_brightnessFeature
setIdentifier:
initWithIdentifier:
setAxMediaUtilsService:
initWithIdentifier:delegate:
setTaskDispatcher:
setSequenceRequestManager:
isEqualToEngine:
sourceNodes
evaluationNodes
archivedDataWithRootObject:requiringSecureCoding:error:
unarchivedObjectOfClass:fromData:error:
setMaximumQueueSize:
setPrioritySchedulingEnabled:
setPrioritySchedulingAllowMultipleNodeExecution:
setThresholdPriority:
addSourceNode:
addEvaluationNode:
maximumQueueSize
areDiagnosticsEnabled
prioritySchedulingEnabled
prioritySchedulingAllowMultipleNodeExecution
thresholdPriority
isCachingEnabled
cacheKey
axMediaUtilsService
_queue_handleEvaluatedContext:result:error:
shouldEvaluate:
detectText
detectScenes
detectModelClassifications
detectCaptions
detectFaces
detectTraits
detectHorizon
detectRectangles
detectProminentObjects
detectAesthetics
isEnabled
_queue_shouldEvaluateNode:withOptions:
arrayWithCapacity:
boostEffectivePriority
effectivePriority
resetEffectivePriority
features
detectedFeatureDescription
detectedTextDescription
sourceProvidesResults
_queue_activeEvaluationNodesForOptions:applyPriorityScheduling:prioritySchedulingAllowMultipleNodeExecution:
_queue_activeEvaluationNodesExclusivelyUseVisionFramework:
setEvaluationExclusivelyUsesVisionFramework:
settings
writeOutInputImages
generateImageRepresentation
generateFileNameForImageWithPrefix:extension:
imageRegistrationFilteringEnabled
error
imageRegistrationState
minimumImageRegistrationSignalLevel
result
disableResultLogging
_queue_logEvaluatedResult:
didFinishProcessingContext
cache
setResult:forKey:
resultHandlers
_invokeResultHandlers:withError:
shouldCallCompletionHandlersForEmptyResultSet
_invokeResultHandlers:withResult:
markAsComplete:
canAddSourceNode:
isConnected
connect:
insertObject:atIndex:
disconnect
removeObject:
canAddEvaluationNode:
_queue_sourceNodeWithIdentifier:
_queue_evaluationNodeWithIdentifier:
_queue_makeUniqueIdentifierForNode:
stringByReplacingOccurrencesOfString:withString:
_queue_nodeIdentifierExists:
_queue_addResultHandler:
_queue_removeResultHandler:
_queue_removeAllResultHandlers
cacheSize
initWithCacheSize:
setCache:
defaultCenter
postNotificationName:object:
requestForcedCleanupWithOptions:completion:
axmIndentationString:
axmDescription
axmAppendRecursiveDescription:withIndentation:
source
context
sequenceRequestManager
addResultHandlers:
_queue_shouldContinueWithoutResultHandlers:
willBeginProcessingContext
shouldProcessRemotely
_queue_remotelyEvaluateWithSource:context:
_queue_evaluateWithSource:context:
taskDispatcher
unscheduleAllTasks
scheduleTask:
_invokeFullQueueResultHandlersForContext:
itemWithSource:context:
shouldCallCompletionHandlersForEngineBusyError
triggerWithSource:context:
engineWillAcceptTiggerWithSource:
captureSessionNodeDidBeginProcessingFrames:
captureSessionNodeDidEndProcessingFrames:
captureSessionNodeWillProcessFrame:
captureSessionNodeDidDropFrame:
dispatcher:handleTask:
copyWithZone:
canAddSourceNodeClass:
insertSourceNode:atIndex:
removeSourceNode:
removeAllSourceNodes
canAddEvaluationNodeClass:
insertEvaluationNode:atIndex:
removeEvaluationNode:
removeAllEvaluationNodes
addSourceNodes:evaluationNodes:
sourceNodeWithIdentifier:
evaluationNodeWithIdentifier:
makeUniqueIdentifierForNode:
nodeIdentifierExists:
addResultHandler:
removeResultHandler:
removeAllResultHandlers
enableResultCachingWithCacheSize:
disableResultCaching
updateEngineConfiguration:
prewarmEngine
purgeResources:
setImageRegistrationFilteringEnabled:
setMinimumImageRegistrationSignalLevel:
setDisableResultLogging:
_queue_sourceNodes
_queue_evaluationNodes
_queue_imageRegistrationNode
_queue_resultHandlers
_queue_shouldNotifyServiceOfEngineConfigChange
_queue_currentTask
_prioritySchedulingEnabled
_prioritySchedulingAllowMultipleNodeExecution
_imageRegistrationFilteringEnabled
_disableResultLogging
_identifier
_maximumQueueSize
_thresholdPriority
_minimumImageRegistrationSignalLevel
_cache
_axMediaUtilsService
_taskDispatcher
_sequenceRequestManager
initWithSource:context:
setSource:
setContext:
UUID
_context
_source
sortedFeatures
objectAtIndex:
compareInitialResult:withFinalResult:indexOfUnequalItem:sortInitialResult:sortFinalResult:
_updateDefaultLanguages
mainQueue
addObserverForName:object:queue:usingBlock:
autoupdatingCurrentLocale
initWithLocale:
preferredLanguages
initWithLanguageCode:
isSupertypeOfLanguage:
lowercaseString
uppercaseString
stringByAppendingFormat:
primaryComponent
secondaryComponent
localizedStringForLanguageCode:
isSubtypeOfLanguage:
locale
isEqualToAXMLanguage:
setPrimaryComponent:
setSecondaryComponent:
setLanguageCode:
setLocale:
initialize
currentSystemLanguage
currentLocaleLanguage
languageCodesForLanguages:
languageInSet:isSupertypeOfLanguage:
languageDisplayName
_primaryComponent
_secondaryComponent
_languageCode
_locale
characterSetWithCharactersInString:
letterCharacterSet
invertedSet
componentsSeparatedByCharactersInSet:
rangeOfCharacterFromSet:
initWithLocaleIdentifier:
decodeFloatForKey:
decodeDoubleForKey:
videoFieldOfView
encodeFloat:forKey:
videoZoomFactor
videoSourceWidth
videoSourceHeight
presentationTimestamp
encodeDouble:forKey:
initWithVideoFieldOfView:zoomFactor:sourceWidth:sourceHeight:presentationTimestamp:
_videoFieldOfView
_videoZoomFactor
_videoSourceWidth
_videoSourceHeight
_presentationTimestamp
whitespaceAndNewlineCharacterSet
addCharactersInString:
enumerateSubstringsInRange:options:usingBlock:
_groupSeperatorCharacterSet
initWithSourceParameters:options:
setAnalysisOptions:
setAppliedImageOrientation:
evaluatedFeatureTypes
appliedImageOrientation
userContext
inputType
ciImage
initWithCIImage:options:
pixelBuffer
orientation
initWithCVPixelBuffer:orientation:options:
initWithURL:options:
_makeRequestHandlerForInput:options:
containsObject:
errorOccurred:
setUserContext:
featureType
numberWithUnsignedInteger:
setFeatures:
setEvaluatedFeatureTypes:
setDiagnostics:
setImageRegistrationState:
includeImageInResult
setImage:
setError:
numberWithBool:
numberWithUnsignedInt:
imageWithCVPixelBuffer:options:
imageWithContentsOfURL:
visionImageRequestHandlerWithOptions:
visionImageRequestHandlerIsLoaded
createSceneObservationIfNilWithBlock:
sceneObservation
sourceInput
setCacheKey:
setShouldCallCompletionHandlersForEngineBusyError:
setShouldCallCompletionHandlersForEmptyResultSet:
sequenceID
setSequenceID:
setResult:
setVisionImageRequestHandler:
_sourceInput
_sourceParameters
_sourceProvidesOwnResults
_resultHandlers
_processingDiagnosticToken
_sceneObservation
_sceneObservationQueue
_shouldProcessRemotely
_shouldCallCompletionHandlersForEngineBusyError
_shouldCallCompletionHandlersForEmptyResultSet
_evaluationExclusivelyUsesVisionFramework
_error
_analysisOptions
_imageRegistrationState
_userContext
_cacheKey
_sequenceID
_features
_evaluatedFeatureTypes
_result
_appliedImageOrientation
_visionImageRequestHandler
freeResources
textDetectionOptions
defaultRecognizeTextOptions
textDetectionLanguage
detectionFlavor
recognitionLevel
supportedRecognitionLanguagesForFlavor:textRecognitionLevel:error:
containsString:
returnSubFeatures
setReportCharacterBoxes:
minimizeFalsePositives
setMinimizeFalseDetections:
minimumCharacterHeight
setMinimumCharacterPixelHeight:
detectDiacritics
setDetectDiacritics:
_visionTextDetectionOptionForLanguage:
setTextRecognition:
text
textDocumentWithVisionObservations:canvasSize:context:error:
_vnRequestTextRecognitionLevelForAXMTextRecognitionLevel:
setRecognitionLevel:
setRecognitionLanguages:
_evaluateByDetectingTextRectangles:textDetectionOptions:
_evaluateByRecognizingText:textDetectionOptions:
supportedRecognitionLanguagesForTextRecognitionLevel:revision:error:
ax_mappedArrayUsingBlock:
recognitionLanguages
customWords
setCustomWords:
_textLayoutManager
_recognitionLanguages
_customWords
beginEditing
addAttribute:value:range:
originalText
replaceCharactersInRange:withString:
endEditing
_evaluateIfNeeded
hasGlobalTag:
addGlobalTag:
removeGlobalTag:
_stringRange
attribute:atIndex:longestEffectiveRange:inRange:
speakableText
enumerateAttributesInRange:options:usingBlock:
_isEvaluated
substringWithRange:
isSpeakable
initWithFormat:
_substringWithRange:
attributesAtIndex:effectiveRange:
_initWithAttributedString:
initWithString:attributes:
mutableString
setAttributes:range:
textWithString:locale:evaluationBlock:
addReplacementTag:withToken:range:
addTag:withToken:range:
setSpeakable:
isRangeSpeakable:
_setNeedEvaluation
initWithAttributedString:
_attrString
_globalAttributes
_evaluationBlock
UTF8String
_queue_processNextTask
_queue_count
_queue_dequeueTask
isComplete
setTaskCompleteBlock:
delegate
_queue_scheduleTask:
_queue_unscheduleAllTasks
removeObjectAtIndex:
isEmpty
setDelegate:
_processQueueSource
_queue_taskList
_queue_taskIsBeingProcessed
_delegate
taskCompleteBlock
setComplete:
_complete
_taskCompleteBlock
setCameraPixelFocalLength:
setCameraOpticalOrigin:
setMinimumAspectRatio:
setMaximumAspectRatio:
setQuadratureTolerance:
setMinimumSize:
setMinimumConfidence:
setMaximumNumberOfRects:
axmDecodePointForKey:
cameraPixelFocalLength
cameraOpticalOrigin
axmEncodePoint:forKey:
minimumAspectRatio
maximumAspectRatio
quadratureTolerance
minimumSize
maximumNumberOfRects
dataWithBytes:length:
minimumConfidence
setMaximumObservations:
featureWithVisionRequest:rectangleResult:canvasSize:
_cameraPixelFocalLength
_minimumAspectRatio
_maximumAspectRatio
_quadratureTolerance
_minimumSize
_maximumNumberOfRects
_cameraOpticalOrigin
_getHue:saturation:brightness:
_getRed:green:blue:
colorWithHue:saturation:brightness:
isEqualToAXMVisionColor:
unsignedCharValue
numberWithUnsignedChar:
saturationFloat
hueRadians
brightnessFloat
hueFloat
colorWithRed:green:blue:
colorWithHueDegrees:saturation:brightness:
euclidianDistanceHSV:
euclidianDistanceHS:
redFloat
greenFloat
blueFloat
_red
_green
_blue
_hue
_saturation
_brightness
setLocalizedName:
colorWithHueDegrees:saturation:brightness:localizedName:
allColorMarkers
localizedName
closestMarkerToColor:withMaximumThreshold:
_localizedName
setSynthesizer:
synthesizer
currentRequestCompletionBlock
speechUtteranceWithAttributedString:
setCurrentRequestCompletionBlock:
speakUtterance:
stopSpeakingAtBoundary:
attributedSpeechString
speechSynthesizer:didStartSpeechUtterance:
speechSynthesizer:didFinishSpeechUtterance:
speechSynthesizer:didPauseSpeechUtterance:
speechSynthesizer:didContinueSpeechUtterance:
speechSynthesizer:didCancelSpeechUtterance:
speechSynthesizer:willSpeakRangeOfSpeechString:utterance:
canHandleRequest:
handleRequest:completion:
stopSpeakingImmediately
stopSpeakingAtNextWord
_synthesizer
_currentRequestCompletionBlock
raise:format:
endVideoFrameEvents
setCaptureSessionNodeDelegate:
beginFrameEventsWithAVCaptureSession:delegate:queue:
endAutoTriggerOfVideoFrameEvents
captureSessionNodeDelegate
frameDelegate
setFrameDelegate:
_autotrigger_queue
_captureSessionNodeDelegate
_frameDelegate
_debugType
range
isPhoneNumber
isDate
isEmailAddress
phoneNumber
initWithNLToken:text:type:lexicalClass:language:script:namedEntity:derivedSubtoken:speechFormatter:
initWithdatatype:text:textCheckingResult:speechFormatter:
isPunctuation
isWhitespace
isSentenceTerminator
isOpenQuote
isCloseQuote
_originalText
_speechFormatter
_nlToken
_nlType
_nlLexicalClass
_nlLanguage
_nlScript
_nlNamedEntity
_nlDerivedSubtoken
_datatype
_textCheckingResult
replacementTagWithSpeakableText:range:
_overrideSpeakableText
_overrideRange
setNotificationObserverTokens:
notificationObserverTokens
removeObserver:
deactivateSessionWithError:
activateSessionWithError:
_notificationObserverTokens
setComponentState:
transitionToState:completion:
componentState
_componentState
resultWithImage:features:orientation:diagnostics:userContext:
normalizedFrame
isOCR
isTextDocument
subfeatures
isValueSpeakable
faceFeatures
sceneClassificationFeatures
objectClassificationFeatures
captionFeatures
blurFeatures
brightnessFeatures
iconClassFeatures
setDetectedTextDescription:
setDetectedFeatureDescription:
image
detectedTextLanguage
resultWithImage:features:orientation:diagnostics:
colorInfoFeature
assetMetadataFeature
localizedDetectedTextHint
_image
_detectedFeatureDescription
_detectedTextDescription
isFace
ax_filteredArrayUsingBlock:
isSceneClassification
isObjectClassification
isCaption
isModelClassification
isBlur
isBrightness
isIconClass
modelClassificationFeatures
ocrFeatures
axm_featuresSortedByConfidence
lastObject
orderedSet
_cacheQueue_cacheSize
_cacheQueue_resultForKey:
_cacheQueue_setResult:forKey:
removeObjectForKey:
resultForKey:
purgeCache
_cacheQueue
_cacheQueue_maxItems
_cacheQueue_orderedKeys
_cacheQueue_results
targetPlayerItem
_mainQueue_endAutoTriggerOfLegibilityEvents
setDelegate:queue:
addOutput:
setTargetPlayerItem:
outputs
removeOutput:
featureWithMediaLegibility:
outputSequenceWasFlushed:
legibleOutput:didOutputAttributedStrings:nativeSampleBuffers:forItemTime:
autoTriggerLegibilityEventsWithAVPlayerItem:
endAutoTriggerOfLegibilityEvents
isTriggeringLegibilityEvents
_avkit_queue
_triggeringLegibilityEvents
_targetPlayerItem
frame
axmEncodeRect:forKey:
rectanglesConfidence
nameConfidence
attributesConfidence
landmarksConfidence
poseConfidence
axmDecodeRectForKey:
setNameConfidence:
axmSecurelyUnarchiveData:withExpectedClass:otherAllowedClasses:error:
getBytes:length:
descriptionForExpression:
_expressionForString:
nameForFaceExpression:
confidenceForExpression:
_likelyExpression
_uuid
_faceId
_rectanglesConfidence
_nameConfidence
_attributes
_attributesConfidence
_expressionsAndConfidence
_landmarks
_landmarks3d
_landmarksConfidence
_poseConfidence
_frame
_pose
unsignedIntegerValue
_enumerateText:textCheckingType:datatype:withBlock:
emailAddressRegex
_enumerateText:regularExpression:datatype:withBlock:
speechFormatterForDatatype:
enumerateMatchesInString:options:range:usingBlock:
dataDetectorWithTypes:error:
regularExpressionWithPattern:options:error:
initWithSpeechFormatterCache:
enumerateText:searchingFordatatypes:withBlock:
_emailAddressRegex
_speechFormatterCache
setLabel:
setConfidence:
_label
_confidence
buildTaxonomyDescription
buildParentChainDescriptionForAllNodes
buildGraphStatisticsDescription
leafNodeLabels
nonLeafNodeLabels
processSceneClassifications:withOptions:
localizedLabelForClassificationObservation:
sequenceRequestHandler
setSequenceRequestHandler:
_sequenceRequestHandler
width
height
left
right
bottom
_metricTypeForMetric:
_floatValueForMetric:
_rectValueForMetric:
boundingFrameForItems:
normalizedBoundingFrameForItems:
metric:inProximityOfMetric:item:threshold:
sequence:
feature
_feature
arrayWithObject:
line:
addSequence:
sequences
_sequences
region:
addLine:
firstLine
lines
_lines
featureWithVisionRequest:textResult:canvasSize:context:
featureWithVisionRequest:recognizedTextResult:canvasSize:context:
_axmVisionFeatureForFeature:canvasSize:context:
_assembleLayoutSequences:canvasSize:context:
_assembleLayoutLines:
_assembleLayoutRegions:
textLineWithBoundingBox:sequences:canvasSize:context:
textRegionWithBoundingBox:lines:canvasSize:context:
textDocumentWithBoundingBox:regions:canvasSize:context:
_textDocumentWithFeatures:canvasSize:context:error:
_resetTranspositionHistory
initWithTargetedCIImage:options:
initWithTargetedCVPixelBuffer:orientation:options:
initWithTargetedImageURL:options:
_translationalImageRegistrationRequestForInput:
performRequests:onCVPixelBuffer:orientation:error:
performRequests:onCIImage:error:
alignmentTransform
_recordTransposition:
_resetImageRegistration
registrationState
_previousInput
_currentInput
_transpositionHistoryCircularBuffer
_transpositionHistoryLastRecordedIndex
_fillingHistoryBuffer
_registrationState
value:withObjCType:
getValue:
axmEncodeSize:forKey:
axmDecodeSizeForKey:
_initWithHandle:
_text
bundleForClass:
URLForResource:withExtension:subdirectory:
fileExistsAtPath:
_soundFileURLForSoundID:
_initWithURL:handle:
_initWithSoundID:handle:
soundFileURL
soundID
_soundID
_soundFileURL
handleProvider
stop
pitch
setPitch:
rate
setRate:
setQuantizedRate:
setHandleProvider:
_handleProvider
_initWithCIImage:
_initWithPixelBuffer:
_initWithURL:
extent
orientedSize
CGImage
wrapperWithPixelBuffer:orientation:
imageWithCVPixelBuffer:
inputWithPixelBuffer:
inputWithURL:
imageColorSpace
_inputType
_ciImage
_pixelBuffer
_extendedSRGBColorSpace
_URL
_cachedImageURLSize
_initWithPixelBuffer:orientation:
unorientedSize
_orientation
initWithModelName:
_preferredModelName
assetMetadataFromURL:
featureWithAssetMetadata:
triggerWithAssetURL:cacheKey:resultHandler:
observer
callback
initWithSuiteName:
registerDefaults:
addObserver:forKeyPath:options:context:
observeValueForKeyPath:ofObject:change:context:
_queue_removeObserver:forSetting:
removeObjectsInArray:
boolForKey:
setBool:forKey:
addObserver:forSeetting:withBlock:
removeObserver:forSetting:
removeObserverForAllSettings:
setWriteOutInputImages:
writeOutOCRInputImages
setWriteOutOCRInputImages:
writeOutScreenCaptures
setWriteOutScreenCaptures:
_defaults
_queue_settingObservers
initForReadingFromData:error:
setWithObjects:
setByAddingObjectsFromSet:
decodeTopLevelObjectOfClasses:forKey:error:
setAssetURL:
setCreationDate:
setUti:
setLocalizedTypeDescription:
setTIFFImageDescription:
setIPTCCaptionAbstract:
setEXIFUserComment:
setPNGImageDescription:
assetURL
creationDate
localizedTypeDescription
TIFFImageDescription
IPTCCaptionAbstract
EXIFUserComment
PNGImageDescription
resourceValuesForKeys:error:
_creationDate
_uti
_localizedTypeDescription
_TIFFImageDescription
_IPTCCaptionAbstract
_EXIFUserComment
_PNGImageDescription
_assetURL
aestheticScore
wellFramedSubjectScore
wellChosenBackgroundScore
noiseScore
failureScore
pleasantCompositionScore
initWithVisionAestheticsObservation:
_aestheticScore
_wellFramedSubjectScore
_pleasantCompositionScore
_wellChosenBackgroundScore
_noiseScore
_failureScore
_initWithBackingType:
setDisplayMonitor:
displayMonitor
connectedIdentities
configurationForIdentity:
isMainDisplay
_updateDisplay:withConfiguration:
addObserver:
isMainThread
mainDisplay
_updateDisplay:withCADisplay:
initWithCompletion:
frontBoardMainDisplay
coreAnimationMainDisplay
_displayPropertiesFromMobileGestalt
currentMode
preferredScale
setScale:
mobileGestaltOrientation
setOrientation:
scale
bounds
_discreteOrientationForOrientation:
setPhysicalOrientation:
setReferenceBounds:
setSize:
pixelSize
setSupportsDeepColor:
_updateDisplayPropertiesWithConfiguration:
displayMonitor:didConnectIdentity:withConfiguration:
displayMonitor:didUpdateIdentity:withConfiguration:
displayMonitor:willDisconnectIdentity:
initAndWaitForMainDisplayConfiguration
isInitialized
setMobileGestaltOrientation:
_queue_CoreAnimationMainDisplay
_queue_FrontBoardMainDisplay
_initialized
_displayMonitor
_mobileGestaltOrientation
referenceBounds
supportsDeepColor
convertPointToDisplay:
convertRectToDisplay:
physicalOrientation
backingType
setBackingType:
_supportsDeepColor
_scale
_physicalOrientation
_backingType
_size
_referenceBounds
_imageOrientationForInterfaceOrientation:displayOrientation:
imageByApplyingOrientation:
_imageOrientationForInterfaceOrientation:isMirrored:
saveToURL:withOrientation:diagnostics:
createDirectoryAtURL:withIntermediateDirectories:attributes:error:
setDateFormat:
date
stringFromDate:
rotatedImageWithInterfaceOrientation:displayOrientation:appliedImageOrientation:
rotatedImageWithInterfaceOrientation:isMirrored:appliedImageOrientation:
writeImageInAllOrientationsToDirectoryAtURL:diagnostics:
_initWithLanguage:diagnostics:
operationWithLanguage:diagnostics:
operationWithSystemLanguage:
lexiconLocale
language
_language
lexiconManager
tagger
dataDetector
enumerateText:locale:block:
_preprocessText:diagnostics:
punctuationCharacterSet
formUnionWithCharacterSet:
removeCharactersInString:
stringByTrimmingCharactersInSet:
symbolCharacterSet
componentsJoinedByString:
spellChecker
processText:withOperation:
_spellChecker
_lexiconManager
_tagger
_dataDetector
_globalWhitelistedWords
_localeWhitelistedWords
intValue
mainScreen
assetWithURL:
commonMetadata
metadataItemsFromArray:withKey:keySpace:
exportSessionWithAsset:presetName:
supportedFileTypes
setOutputFileType:
absoluteString
stringByDeletingPathExtension
stringByAppendingString:
stringByAppendingPathExtension:
URLWithString:
setOutputURL:
metadata
metadataItem
setKeySpace:
setKey:
setValue:
setMetadata:
status
exportAsynchronouslyWithCompletionHandler:
moveItemAtURL:toURL:error:
removeItemAtURL:error:
dateFromString:
currentCalendar
components:fromDate:
year
month
dictionaryWithObjectsAndKeys:
stringByAppendingPathComponent:
bundleWithPath:
load
evaluateImage:forCriteria:inRect:
blurResult
luminanceResult
humanReadableResult
hasPrefix:
rangeOfString:
substringFromIndex:
samplesPerSecond
setSamplesPerSecond:
lastSampleTime
setLastSampleTime:
_samplesPerSecond
_lastSampleTime
setClasses:forSelector:argumentIndex:ofReply:
mainBundle
bundleIdentifier
axmValueWithCGAffineTransform:
filterWithName:withInputParameters:
outputImage
writeJPEGRepresentationOfImage:toURL:colorSpace:options:error:
_imageSaliencyRequest
set_imageSaliencyRequest:
salientObjects
narrowedBoundingBox
prominentObjectWithBoundingBox:canvasSize:confidence:
__imageSaliencyRequest
setPriority:
priority
defaultPriority
defaultANEDevice
setProcessingDevice:
setModelFileBackingStore:
_diagnosticNameForRequests:diagnostics:
stringWithString:
isANEDeviceAvailable
setEffectivePriority:
_minimumConfidence
_priority
_effectivePriority
componentsSeparatedByString:
setIs3DLandmarks:
is3DLandmarks
leftEye
pointsArrayForRegion:
rightEye
leftEyebrow
rightEyebrow
nose
noseCrest
medianLine
outerLips
innerLips
leftPupil
rightPupil
pointCount
normalizedPoints
axmValueWithCGPoint:
unitTestingFaceLandmarksIs3D:
pointValuesForFaceLandmarkType:
localizedStringForLandmarkType:
_is3DLandmarks
initWithDetectionFlavor:
setMinimumCharacterHeight:
setReturnSubFeatures:
setMinimizeFalsePositives:
setNormalizedMinimumTextHeightRatio:
setUsesLanguageCorrection:
setCorrectSpelling:
setSpellCheckingLanguages:
setTextDetectionLanguage:
normalizedMinimumTextHeightRatio
usesLanguageCorrection
correctSpelling
spellCheckingLanguages
defaultDetectTextRectanglesOptions
setDetectionFlavor:
_correctSpelling
_detectDiacritics
_returnSubFeatures
_minimizeFalsePositives
_usesLanguageCorrection
_detectionFlavor
_textDetectionLanguage
_spellCheckingLanguages
_minimumCharacterHeight
_recognitionLevel
_normalizedMinimumTextHeightRatio
setClientID:
setIncludeImageInResult:
setDetectText:
setTextDetectionOptions:
setDetectScenes:
setDetectModelClassifications:
setDetectCaptions:
setDetectTraits:
setDetectFaceRectangles:
setDetectFaceNames:
setDetectFaceAttributes:
setDetectFaceExpressions:
setDetectFaceLandmarks:
setDetectFacePose:
setDetectProminentObjects:
setDetectHorizon:
setDetectRectangles:
detectFaceNames
setDetectAesthetics:
setIgnoredLayerContextIDs:
clientID
voiceOverOptions
hasDetectionsEnabled
_detectFaceRectangles
_detectFaceNames
_detectFaceAttributes
_detectFaceExpressions
_detectFaceLandmarks
_detectFacePose
_detectScenes
_detectModelClassifications
_detectCaptions
_detectTraits
_detectRectangles
_detectHorizon
_detectProminentObjects
_detectAesthetics
_detectText
_includeImageInResult
_clientID
_textDetectionOptions
_ignoredLayerContextIDs
setRequest:
dispatchRequest:
request
initWithComponents:options:
disable
enableWithCompletion:
speak:
interrupt:
interruptImmediately
interruptPolitely
playSound:
playActiveSound:
_outputRequests
_usesPrivateAudioSession
_audioSession
_queue_soundComponent
_queue_speechComponent
_queue_activeComponents
_request
setWithObject:
spellServer:findMisspelledWordInString:languages:wordCount:countOnly:correction:
correctSpellingInText:withLanguages:
textContainsMisspelling:withLanguages:
setSpellChecker:
nodeQueue
_nodeQueue_addResultHandler:
_nodeQueue_removeResultHandler:
_nodeQueue_removeAllResultHandlers
_nodeQueue_resultHandlers
topCandidates:
_aspectFaceRectFromSquareFaceRect:sizeInPixels:
transform
angle
timeIntervalSinceReferenceDate
_serializeWithCoder:orDictionary:
nameForFeatureType:
_nameForOCRFeatureType:
locationForNormalizedFrame:previousLocation:usingThirds:
_valueForTextFeature
isTextRegion
isTextLine
isTextSequence
isTextCharacter
isTextDiacritic
_isTextFeatureValueSpeakable
_append:toList:
locationUsingThirds:
nameForLocation:
barcodeType
ocrFeatureType
classificationLabel
assetMetadata
horizonAngle
isEqualToAXMVisionFeature:
personWithBoundingBox:confidence:canvasSize:
featureWithVisionRequest:brightnessValue:canvasSize:
objectClassificationWithLabel:localizedValue:boundingBox:confidence:canvasSize:
sceneClassificationWithLabel:localizedValue:confidence:canvasSize:
featureWithTaxonomyNode:canvasSize:
featureWithIconClass:confidence:
featureWithColorInfo:canvasSize:
localizedStringForLocation:isSubjectImplicit:
nameForOCRType:
flattenedFeatureList:
dictionaryRepresentation
canvasSize
colorInfo
facePose
horizonTransform
isBarcode
isRealtimeFace
isPerson
isColor
isHorizon
isMediaLegibility
isAssetMetadata
isRectangle
isMotion
isCameraMetadata
isProminentObject
isImageAesthetics
unpaddedDetectedFaceRect
aestheticsResult
deviceOrientation
debugRectangles
setDebugRectangles:
_featureType
_subfeatures
_barcodeType
_ocrFeatureType
_normalizedFrame
_value
_isValueSpeakable
_taggedText
_colorInfo
_assetMetadata
_blur
_horizonTransform
_horizonAngle
_faceDetectionResult
_facePose
_canvasSize
_modelID
_classificationLabel
_classificationLocalizedValue
_caption
_aestheticsResult
_deviceOrientation
_debugRectangles
_unpaddedDetectedFaceRect
unitTestingFaceFeatureWithSize:faceFrame:
unitTestingFeatureWithType:canvasSize:frame:value:barcodeType:ocrFeatureType:subFeatures:
unitTestingFeature
unitTestingFaceFeature
unitTestingProminentObjectFeature
unitTestingHorizonFeature
taggedText
_captionImpl
decodeInt32ForKey:
encodeInt32:forKey:
physicalMemory
knownSceneClassifications
_sceneClassificationRequest
_setSceneClassificationRequest:
taxonomyOptions
possibleSceneClassifications
setTaxonomyOptions:
_taxonomyOptions
__sceneClassificationRequest
setPlayer:
setTimePitch:
player
attachNode:
mainMixerNode
initStandardFormatWithSampleRate:channels:
timePitch
connect:to:fromBus:toBus:format:
nextAvailableInputBus
detachNode:
processingFormat
initWithPCMFormat:frameCapacity:
readIntoBuffer:error:
scheduleBuffer:atTime:options:completionHandler:
play
connectToEngine:
disconnectFromEngine:
beginPlayback:withError:
_player
_timePitch
_startEngineIfNeeded:
initForReading:error:
_scheduleOneShotSound:completion:
_scheduleActiveSound:
setActiveSound:
setSoundComponent:
scheduleFile:atTime:completionHandler:
isRunning
startAndReturnError:
_stopActiveSound:
_logAudioFileInfo:
configChangedObserverToken
setConfigChangedObserverToken:
_engine
_oneShotSoundPlayer
_activeSounds
_configChangedObserverToken
activeSound
soundComponent
_rate
_pitch
_activeSound
_soundComponent
setConnected:
setEnabled:
setNodeQueue:
_connected
_enabled
_nodeQueue
systemReport
privilegedSystemReport
triggerWithImage:options:cacheKey:resultHandler:
triggerWithImageURL:options:cacheKey:resultHandler:
triggerWithPixelBuffer:exifOrientation:options:cacheKey:resultHandler:
setCaptureNode:
setImageNode:
setTextDetector:
setSceneDetector:
setFaceDetector:
setTraitDetector:
setProminentObjectsDetector:
setCaptionDetector:
captureNode
imageNode
textDetector
sceneDetector
faceDetector
traitDetector
prominentObjectsDetector
captionDetector
_captureNode
_imageNode
_textDetector
_sceneDetector
_faceDetector
_traitDetector
_prominentObjectsDetector
_captionDetector
fileExistsAtPath:isDirectory:
createDirectoryAtPath:withIntermediateDirectories:attributes:error:
axmAppendIndentation:
initWithFormat:arguments:
errorWithDomain:code:userInfo:
dateFormatFromTemplate:options:locale:
stringFromNumber:
AXMPointValue
AXMVectorValue
AXMSizeValue
AXMAffineTransformValue
axmValueWithCGVector:
axmValueWithCGSize:
@16@0:8
B32@0:8@16@24
B40@0:8@16@24@32
^{_LXLexicon=}32@0:8@16@24
v16@0:8
@"NSMutableDictionary"
^v32@0:8@16@24
@80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16q48@56@64^@72
@84@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16q48@56B64@68^@76
@24@0:8Q16
@28@0:8Q16B24
@32@0:8Q16Q24
@36@0:8Q16Q24B32
@40@0:8@16Q24Q32
@44@0:8@16Q24Q32B40
@56@0:8@16Q24Q32B40B44^@48
B16@0:8
@24@0:8@16
v24@0:8@16
@"VNDetectHorizonRequest"
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
v32@0:8@16@24
v24@0:8@?16
d16@0:8
v24@0:8d16
@"NSArray"
q24@0:8@16
q16@0:8
@"NSDictionary"
@40@0:8@16{CGSize=dd}24
@32@0:8@16@24
@"VNDetectFaceRectanglesRequest"
@"VNCreateFaceprintRequest"
@"VNClassifyFaceAttributesRequest"
@"VNDetectFaceExpressionsRequest"
@"VNDetectFaceLandmarksRequest"
@"VNDetectFacePoseRequest"
@"VNClassifyImageAestheticsRequest"
B24@0:8@16
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
v56@0:8@16@24@32q40@?48
v56@0:8@"AXMVisionEngine"16@"AXMSourceNode"24@"AXMVisionPipelineContext"32q40@?<v@?@"AXMVisionResult"@"NSError">48
@"NSObject<OS_dispatch_queue>"
@"NSXPCConnection"
@32@0:8@16q24
v40@0:8^Q16^{mach_task_basic_info=QQQ{time_value=ii}{time_value=ii}ii}24^{task_vm_info=QiiQQQQQQQQQQQQQQQQQQQqqqqqqqqqqqqqqqqqqqqqQi}32
v24@0:8q16
{mach_task_basic_info="virtual_size"Q"resident_size"Q"resident_size_max"Q"user_time"{time_value="seconds"i"microseconds"i}"system_time"{time_value="seconds"i"microseconds"i}"policy"i"suspend_count"i}
{task_vm_info="virtual_size"Q"region_count"i"page_size"i"resident_size"Q"resident_size_peak"Q"device"Q"device_peak"Q"internal"Q"internal_peak"Q"external"Q"external_peak"Q"reusable"Q"reusable_peak"Q"purgeable_volatile_pmap"Q"purgeable_volatile_resident"Q"purgeable_volatile_virtual"Q"compressed"Q"compressed_peak"Q"compressed_lifetime"Q"phys_footprint"Q"min_address"Q"max_address"Q"ledger_phys_footprint_peak"q"ledger_purgeable_nonvolatile"q"ledger_purgeable_novolatile_compressed"q"ledger_purgeable_volatile"q"ledger_purgeable_volatile_compressed"q"ledger_tag_network_nonvolatile"q"ledger_tag_network_nonvolatile_compressed"q"ledger_tag_network_volatile"q"ledger_tag_network_volatile_compressed"q"ledger_tag_media_footprint"q"ledger_tag_media_footprint_compressed"q"ledger_tag_media_nofootprint"q"ledger_tag_media_nofootprint_compressed"q"ledger_tag_graphics_footprint"q"ledger_tag_graphics_footprint_compressed"q"ledger_tag_graphics_nofootprint"q"ledger_tag_graphics_nofootprint_compressed"q"ledger_tag_neural_footprint"q"ledger_tag_neural_footprint_compressed"q"ledger_tag_neural_nofootprint"q"ledger_tag_neural_nofootprint_compressed"q"limit_bytes_remaining"Q"decompressions"i}
@"NSString"
@56@0:8q16@24@?32@?40@?48
@40@0:8q16@24@?32
@32@0:8q16@24
v20@0:8B16
@"NSMutableArray"
@"AXMDiagnostics"
@"AXMDiagnosticMetric"
@?16@0:8
@"AXMOutputRequestHandle"
B40@0:8o^@16@24o^@32
@24@0:8@?16
B24@0:8^@16
@"NSURL"
v80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16q48@56@64@?72
@"AXMScreenGrabber"
@24@0:8q16
v32@0:8q16@24
v40@0:8@16q24@32
@"NSMutableString"
@"AXMVisionFeature"
v32@0:8@"AXMSourceNode"16@"AXMVisionPipelineContext"24
B24@0:8@"AXMSourceNode"16
v24@0:8@"AXMAVCaptureSessionNode"16
v32@0:8@"AXMTaskDispatcher"16@"AXMTask"24
@24@0:8^{_NSZone=}16
v32@0:8@16q24
v32@0:8@"NSMutableString"16q24
@32@0:8@16B24B28
v40@0:8@16@24@32
@24@0:8#16
v24@0:8Q16
@"AXMImageRegistrationNode"
@"_AXMVisionEngineAnalysisTask"
@"AXMVisionEngineCache"
@"AXMService"
@"AXMTaskDispatcher"
@"AXMSequenceRequestManager"
@"NSUUID"
@"AXMVisionPipelineContext"
@"AXMSourceNode"
q48@0:8@16@24^q32B40B44
@"NSLocale"
@48@0:8f16f20q24q32d40
f16@0:8
@"NSMutableCharacterSet"
{CGSize=dd}16@0:8
@"AXMPipelineContextInput"
@"AXMDiagnosticMetricToken"
@"VNSceneObservation"
@"NSError"
@"AXMVisionAnalysisOptions"
@"NSObject<NSSecureCoding>"
@"<NSCopying>"
@"NSMutableSet"
@"AXMVisionResult"
@"NSNumber"
@"VNImageRequestHandler"
q24@0:8Q16
@40@0:8Q16Q24^@32
@"AXMTextLayoutManager"
@40@0:8@16@24@?32
v48@0:8@16@24{_NSRange=QQ}32
B32@0:8{_NSRange=QQ}16
{_NSRange=QQ}16@0:8
@32@0:8{_NSRange=QQ}16
@32@0:8Q16^{_NSRange=QQ}24
v40@0:8{_NSRange=QQ}16@32
v40@0:8@16{_NSRange=QQ}24
@"NSMutableAttributedString"
@"NSObject<OS_dispatch_source>"
@"<AXMTaskDispatcherDelegate>"
{CGPoint=dd}16@0:8
v32@0:8{CGPoint=dd}16
{CGPoint="x"d"y"d}
@28@0:8C16C20C24
@40@0:8d16d24d32
v40@0:8*16*24*32
d24@0:8@16
@48@0:8d16d24d32@40
@32@0:8@16d24
v48@0:8@16{_NSRange=QQ}24@40
v32@0:8@"AVSpeechSynthesizer"16@"AVSpeechUtterance"24
v48@0:8@"AVSpeechSynthesizer"16{_NSRange=QQ}24@"AVSpeechUtterance"40
v32@0:8@16@?24
@"AVSpeechSynthesizer"
@"<AXMAVCaptureSessionNodeDelegate>"
@"<AXMAVCaptureSessionNodeFrameDelegate>"
@104@0:8{?={?=qq}Q}16@40@48@56@64@72@80@88@96
@48@0:8Q16@24@32@40
@"AXMSpeechFormatter"
{?="range"{?="location"q"length"q}"attributes"Q}
@"NSTextCheckingResult"
@40@0:8@16{_NSRange=QQ}24
{_NSRange="location"Q"length"Q}
v32@0:8q16@?24
@48@0:8@16@24@32@40
@56@0:8@16@24@32@40@48
@"CIImage"
@"NSSet"
@"NSMutableOrderedSet"
v24@0:8@"AVPlayerItemOutput"16
v64@0:8@16@24@32{?=qiIq}40
v64@0:8@"AVPlayerItemLegibleOutput"16@"NSArray"24@"NSArray"32{?=qiIq}40
@"AVPlayerItem"
d24@0:8q16
{CGRect={CGPoint=dd}{CGSize=dd}}16@0:8
v48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
{?=[4]}16@0:8
v80@0:8{?=[4]}16
@"AXMVisionFeatureFaceAttributes"
@"AXMVisionFeatureFaceLandmarks"
{CGRect="origin"{CGPoint="x"d"y"d}"size"{CGSize="width"d"height"d}}
{?="columns"[4]}
v40@0:8@16@24@?32
v48@0:8@16@24Q32@?40
v48@0:8@16Q24Q32@?40
@"NSRegularExpression"
@"AXMSpeechFormatterCache"
@28@0:8@16I24
@"VNSequenceRequestHandler"
{CGRect={CGPoint=dd}{CGSize=dd}}24@0:8@16
B48@0:8q16q24@32d40
q24@0:8q16
{CGRect={CGPoint=dd}{CGSize=dd}}24@0:8q16
@48@0:8@16{CGSize=dd}24@40
@56@0:8@16{CGSize=dd}24@40^@48
[10{CGPoint="x"d"y"d}]
v40@0:8{CGSize=dd}16@32
{CGSize=dd}24@0:8@16
v40@0:8{CGPoint=dd}16@32
{CGPoint=dd}24@0:8@16
v56@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48
@"AXMOutputActionHandle"
v20@0:8f16
@"<AXMActiveSoundOutputActionHandleProvider>"
^{CGColorSpace=}16@0:8
@"AXMPixelBufferWrapper"
^{CGColorSpace=}
{CGSize="width"d"height"d}
@28@0:8^{__CVBuffer=}16I24
^{__CVBuffer=}16@0:8
I16@0:8
^{__CVBuffer=}
v48@0:8@16@24@32^v40
@"NSUserDefaults"
@48@0:8@16#24@32^@40
@"NSDate"
v40@0:8@"FBSDisplayMonitor"16@"FBSDisplayIdentity"24@"FBSDisplayConfiguration"32
v32@0:8@"FBSDisplayMonitor"16@"FBSDisplayIdentity"24
q24@0:8d16
@"AXMDisplay"
@"FBSDisplayMonitor"
{CGPoint=dd}32@0:8{CGPoint=dd}16
{CGRect={CGPoint=dd}{CGSize=dd}}48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
v32@0:8{CGSize=dd}16
I32@0:8q16q24
I28@0:8q16B24
@40@0:8q16q24^I32
@36@0:8q16B24^I28
v36@0:8@16I24@28
@"AXMLanguage"
@"AXMSpellChecker"
@"AXMLexiconManager"
@"AXMTagger"
@"AXMDataDetector"
@"VNGenerateAttentionBasedSaliencyImageRequest"
B48@0:8@16@24@32^@40
@20@0:8B16
@"AXMTextDetectionOptions"
@"AXMAudioSession"
@"AXMSoundComponent"
@"AXMSpeechComponent"
@"AXMOutputRequest"
@"AppleSpell"
@80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48{CGSize=dd}56@72
@56@0:8@16@24{CGSize=dd}32@48
@72@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGSize=dd}48d64
@72@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16d48{CGSize=dd}56
@44@0:8@16f24{CGSize=dd}28
@48@0:8@16@24{CGSize=dd}32
@84@0:8@16@24{CGRect={CGPoint=dd}{CGSize=dd}}32f64{CGSize=dd}68
@52@0:8@16@24f32{CGSize=dd}36
{CGRect={CGPoint=dd}{CGSize=dd}}64@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGSize=dd}48
@28@0:8q16B24
q60@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16q48B56
@"NSDictionary"16@0:8
{CGAffineTransform=dddddd}16@0:8
q20@0:8B16
@"AXMTaggedText"
@"AXMVisionFeatureColorInfo"
@"AXMVisionFeatureAssetMetadata"
{CGAffineTransform="a"d"b"d"c"d"d"d"tx"d"ty"d}
@"AXMVisionFeatureFaceDetectionResult"
@"AXMVisionFeatureAestheticsResult"
@104@0:8Q16{CGSize=dd}24{CGRect={CGPoint=dd}{CGSize=dd}}40@72@80q88@96
@64@0:8{CGSize=dd}16{CGRect={CGPoint=dd}{CGSize=dd}}32
@"AXMImageCaptionModel"
v20@0:8I16
@"VNSceneClassificationRequest"
B32@0:8@16^@24
@"AVAudioPlayerNode"
@"AVAudioUnitTimePitch"
@"AVAudioEngine"
@"AXMActiveSound"
@"<AXMVisionEngineNodeConnectionDelegate>"
v48@0:8@16@24@32@?40
v52@0:8^{__CVBuffer=}16I24@28@36@?44
@"AXMScreenCaptureNode"
@"AXMImageNode"
@"AXMTextDetectorNode"
@"AXMSceneDetectorNode"
@"AXMFaceDetectorNode"
@"AXMTraitDetectorNode"
@"AXMProminentObjectsDetectorNode"
@"AXMCaptionDetectorNode"
{CGVector=dd}16@0:8
@32@0:8{CGPoint=dd}16
@32@0:8{CGVector=dd}16
@32@0:8{CGSize=dd}16
@48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
@64@0:8{CGAffineTransform=dddddd}16
f024
