a0cTa1cTa2cTa3cTa0hTa1hTa2hTa3hT
Motion
Person
Vehicle
333333
?333333
@(#)PROGRAM:HomeAI  PROJECT:HomeAI-72
N2cv5MatOpE
N2cv14MatOp_IdentityE
N2cv11MatOp_AddExE
N2cv9MatOp_BinE
N2cv9MatOp_CmpE
N2cv10MatOp_GEMME
N2cv12MatOp_InvertE
N2cv7MatOp_TE
N2cv11MatOp_SolveE
N2cv17MatOp_InitializerE
 !"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\]^_`abcdefghijklmnopqrstuvwxyz{|}~
ucwsifdr
N2cv9ExceptionE
14EmptyFuncTable
12GpuFuncTable
N2cv11_InputArrayE
N2cv12_OutputArrayE
featureNames
T@"NSSet",R,N
pixelBuffer
T^{__CVBuffer=},R,V_pixelBuffer
inputName
T@"NSString",R,V_inputName
SignificantActivity
mlmodelc
image__Placeholder__0
ShotNet__ShotNet__ssd_predictions__block8_box__box_offset__0
ShotNet__ShotNet__ssd_predictions__block7_box__box_offset__0
ShotNet__ShotNet__ssd_predictions__block6_box__box_offset__0
ShotNet__ShotNet__ssd_predictions__block9_box__box_offset__0
ShotNet__ShotNet__ssd_predictions__block10_box__box_offset__0
ShotNet__ShotNet__ssd_predictions__block11_box__box_offset__0
ShotNet__ShotNet__ssd_predictions__block8_box__class_prob__0
ShotNet__ShotNet__ssd_predictions__block7_box__class_prob__0
ShotNet__ShotNet__ssd_predictions__block6_box__class_prob__0
ShotNet__ShotNet__ssd_predictions__block9_box__class_prob__0
ShotNet__ShotNet__ssd_predictions__block10_box__class_prob__0
ShotNet__ShotNet__ssd_predictions__block11_box__class_prob__0
CoreML output nil or not of type MLFeatureTypeMultiArray
significant.activity.detector
hash
TQ,R
superclass
T#,R
description
T@"NSString",R,C
debugDescription
mlModel
T@"MLModel",R,V_mlModel
inputFeatureValueName
T@"NSString",R,V_inputFeatureValueName
offsetsFeatureValueNames
T@"NSArray",R,V_offsetsFeatureValueNames
scoresFeatureValueNames
T@"NSArray",R,V_scoresFeatureValueNames
nmsThreshold
Td,R,V_nmsThreshold
useSoftmax
TB,R,V_useSoftmax
predictionOptions
T@"MLPredictionOptions",R,V_predictionOptions
inputDimensions
T{CGSize=dd},R,V_inputDimensions
camera.video.encoder.session
com.apple.videotoolbox.videoencoder.h264.rtvc
HMICameraVideoEncoderSession
Asset writer can't keep up with compression session output, skipping frame
v24@?0i8I12^{opaqueCMSampleBuffer=}16
v8@?0
session
T^{OpaqueVTCompressionSession=},R,V_session
assetWriter
T@"AVAssetWriter",R,V_assetWriter
assetWriterInput
T@"AVAssetWriterInput",R,V_assetWriterInput
encodedAssetData
T@"NSMutableData",R,V_encodedAssetData
activity
T@"HMFActivity",R,V_activity
bitRate
HMISystemResourceUsageLevelLow
HMISystemResourceUsageLevelMed
HMISystemResourceUsageLevelHigh
HMISystemResourceUsageLevelUnknown
HMISystemResourceUsageLevelUndefined
systemResourceUsageLevel
Tq,N,V_systemResourceUsageLevel
delegate
T@"<HMISystemResourceUsageMonitorDelegate>",W
systemResourceUsageMonitorImpl
T@"HMISystemResourceUsageMonitorImpl",R,V_systemResourceUsageMonitorImpl
workQueue
T@"NSObject<OS_dispatch_queue>",R,V_workQueue
JPEGRepresentation
Frame@%llu
camera.video.frame
regionOfInterestPixelBuffer
T^{__CVBuffer=},R,V_regionOfInterestPixelBuffer
jpegData
T@"NSData",R,V_jpegData
motionResult
T@"HMICameraVideoFrameMotionAnalysisResult",&,V_motionResult
presentationTime
T{?=qiIq},R,V_presentationTime
size
T{CGSize=dd},R,V_size
frameId
TQ,R,V_frameId
fragmentSequenceNumber
TQ,R,V_fragmentSequenceNumber
cropAndResizePixelBuffer
Invalid crop rect {x:%f y:%f width:%f height:%f} for source image {width:%f height:%f}
VTPixelTransferSessionCreate failed. Error %d
VTSessionSetProperty failed. Error %d
VTPixelTransferSessionTransferImage failed. Error %d
vision.utilities
services
T@"NSMutableDictionary",R,V_services
lock
T@"HMFUnfairLock",R,N,V_lock
intMin
intMax
target
engageDelta
sharedInstance
T@"HMIPIDController",R
tick
T@"HMFTimer",R,V_tick
controlEffort
Tq,R,V_controlEffort
Invalid parameter not satisfying: %@
PrimaryUsagePage
PrimaryUsage
LocationID
value
T@"NSNumber",R,V_value
date
T@"NSDate",R,V_date
Invalid parameter for windowSize: %lu, windowSize must be > 0
v16@?0@"MovingAverageEntry"8
queue
T@"NSMutableArray",&,N,V_queue
windowSize
TQ,R,N,V_windowSize
movingAverage
Td,V_movingAverage
HKD://
analyzed-video-frames
%#{flags}
Success
SystemResourceUsageHigh
InsufficentTime
AnyMotion
SkippedAnalysis
None
Medium
High
DidAnalyze
DidNotAnalyze
DidFailAnalysis
Canceled
Bypassed
Expired
SessionEnded
InErrorState
duration
T{?=qiIq},V_duration
creationDate
T@"NSDate",&,V_creationDate
lastSequenceNumber
TQ,R,V_lastSequenceNumber
events
Tq,R,V_events
annotationScores
T@"NSDictionary",R,V_annotationScores
posterFrames
T@"NSArray",R,V_posterFrames
frameResults
T@"NSArray",R,V_frameResults
resultCode
Tq,V_resultCode
timeToAnalyzeFragment
Td,V_timeToAnalyzeFragment
timeSinceFragmentWasSubmitted
Td,V_timeSinceFragmentWasSubmitted
videoFragment
T@"HMICameraVideoFragment",&,V_videoFragment
analysisFPS
Tf,V_analysisFPS
local
remote-fragment
serviceType
TQ,V_serviceType
startingMediaIntegritySequenceNumber
TQ,V_startingMediaIntegritySequenceNumber
transcodeFragment
TB,V_transcodeFragment
useScheduler
TB,V_useScheduler
inMediaAnalysis
TB,V_inMediaAnalysis
posterFrameGenerationInterval
TQ,R,V_posterFrameGenerationInterval
posterFrameHeight
TQ,R,V_posterFrameHeight
maxFragmentAnalysisDuration
Td,R,V_maxFragmentAnalysisDuration
maxFragmentDuration
Td,R,V_maxFragmentDuration
videoFrame
T@"HMICameraVideoFrame",R,V_videoFrame
detections
T@"NSArray",R,V_detections
frameWidth
TQ,R,V_frameWidth
frameHeight
TQ,R,V_frameHeight
fragment/%lu
fragmentData
T@"NSMutableData",R
T@"NSURL",&,N,V_url
sequenceNumber
TQ,R,V_sequenceNumber
data
T@"NSData",R,V_data
moovFragment
T@"NSData",R,N,V_moovFragment
eventTypes
Tq,R,V_eventTypes
[%@] [Fragment:%lu] %@
camera.video.analyzer.request
request
T@"HMICameraVideoAnalyzerRequest",R,W,V_request
Start analysis, elapsed time since submission: %fs
v24@?0@"NSData"8@"NSError"16
T@"HMICameraVideoAnalyzerRequestLog",R,V_log
phase
Tq,V_phase
flags
Tq,V_flags
analysisSubmissionTime
T@"NSDate",R,V_analysisSubmissionTime
timeSinceAnalysisSubmission
Td,R
analysisStartTime
T@"NSDate",R,V_analysisStartTime
timeSinceAnalysisStart
maxAnalysisFPS
Td,R,V_maxAnalysisFPS
Td,R,V_analysisFPS
fragment
T@"HMICameraVideoFragment",R,V_fragment
attributes
T@"HMICameraVideoResourceAttributes",R,V_attributes
encoderSession
T@"HMICameraVideoEncoderSession",R,V_encoderSession
posterFrameGenerator
T@"HMICameraVideoPosterFrameGenerator",R,V_posterFrameGenerator
frameSelector
T@"HMICameraVideoFrameSelector",R,V_frameSelector
assetReader
T@"HMICameraVideoAssetReader",R,V_assetReader
analyzer
T@"HMICameraVideoAnalyzer",R,V_analyzer
Tq,V_events
videoFrameResults
T@"NSMutableArray",&,V_videoFrameResults
shouldSkipAnalysis
TB,R
shouldFailAnalysis
HMICameraVideoAnalyzerScheduler
HIGH
Normal
Warning
Critical
Unknown
Undefined
analysisTime: %.2f (%.2f), total: %.2f (%.2f), level: %@, memory: %@, temp: %.2f, controlEffort: %lu, analysisFPS: %.2f, maxAnalyzers: %lu
v16@?0@"HMICameraVideoAnalyzerRequest"8
[%@] [A:%d]
 %@ [%lu,%lu] %@
camera.video.analyzer.scheduler
internalAnalyzers
T@"NSPointerArray",R,V_internalAnalyzers
systemResourceUsageMonitor
T@"HMISystemResourceUsageMonitor",R,V_systemResourceUsageMonitor
systemResourceUsageMonitorUsageLevel
Tq,V_systemResourceUsageMonitorUsageLevel
memoryMonitor
T@"HMFMemoryMonitor",R,V_memoryMonitor
thermalPIDController
T@"HMIPIDController",R,V_thermalPIDController
averageAnalysisTime
averageAnalysisTimeMovingAverage
T@"MovingAverage",R,V_averageAnalysisTimeMovingAverage
averageTotalAnalysisTime
averageTotalAnalysisTimeMovingAverage
T@"MovingAverage",R,V_averageTotalAnalysisTimeMovingAverage
analysisFPSPreference
Td,R,V_analysisFPSPreference
Tq,R
paused
TB,GisPaused,V_paused
analyzers
T@"NSArray",R
maxConcurrentAnalyzers
TQ,R,V_maxConcurrentAnalyzers
HMICameraVideoAnalyzer
Video fragment duration: %fs is greater than expected value: %fs
Video fragment sequence number: %lu is not eqaul to expected value: %lu
Video fragment has no frames
XPC connection was interrupted, retrying.
Unknown delegate name: %@
v24@?0@"NSDictionary"8@"NSError"16
Failed to start reading of the asset: %@
v24@?0@"HMICameraVideoResourceAttributes"8@"NSError"16
End analysis: didAnalyze, significant events detected: %@
Transcoded, bytes: %lu (%f)
End analysis, time spent: %fs, elapsed time since submission: %fs
Stopping analysis due to high system resource usage
Stopping analysis due to cancelling
Stopping analysis due to entering full bypass mode
Stopping analysis due to analysis time past the maximum fragment analysis time: %fs
Frame selector produced 0 frames
Analyzed frame:%lu, SignificantEvents:%@
%@-%06d.%@
%@/%@/%@
[Fragment:%lu] Failed to save the video frame %lu error: %@
[Fragment:%lu] Saving video frame %lu
outcome
sessionId
framesAnalyzedFragment
error
underlyingError
personScore
personConfidence
petScore
petConfidence
vehicleScore
vehicleConfidence
Uploading analytics event %@
com.apple.HomeKit.VideoAnalyzerStats
@"NSMutableDictionary"8@?0
com.apple.HomeAI
homeai: %@
camera.video.analyzer
internalPendingRequests
T@"NSMutableArray",R,V_internalPendingRequests
scheduler
T@"HMICameraVideoAnalyzerScheduler",R,V_scheduler
mediaIntegritySequenceNumber
TQ,V_mediaIntegritySequenceNumber
skipSequentialMediaIntegrityCheck
TB,R,V_skipSequentialMediaIntegrityCheck
analysisInProgress
TB,V_analysisInProgress
inErrorState
TB,V_inErrorState
inBypassMode
TB,V_inBypassMode
configuration
T@"HMICameraVideoAnalyzerConfiguration",&,V_configuration
remoteAnalysisService
T@"HMIAnalysisService",&,N,V_remoteAnalysisService
sessionEnded
TB,V_sessionEnded
uploadVideoAnalysisEvent
TB,R,GshouldUploadVideoAnalysisEvent,V_uploadVideoAnalysisEvent
saveVideoFramesToDisk
TB,GshouldSaveVideoFramesToDisk,V_saveVideoFramesToDisk
pendingRequests
T@"<HMICameraVideoAnalyzerDelegate>",W,V_delegate
identifier
T@"NSUUID",R,C,V_identifier
Initializing HMICameraVideoFrameAnalyzerFactory
Resetting VideoFrameAnalyzer
Warm starting model...
warm_start_model
Failed to create pixel buffer when warm starting model
Failed to warm start model: %@
Warm start of model took: %f
Analyze Frame
camera.video.frame.analyzer.factory
T@"HMICameraVideoFrameAnalyzerFactory",R
frameAnalyzer
T@"<HMICameraVideoFrameAnalyzer>",&,N,V_frameAnalyzer
watchdogTimer
T@"HMFTimer",R,V_watchdogTimer
Label:%d Confidence:%f X:%f Y:%f Width:%f Height:%f}
labelIndex
Ti,R,V_labelIndex
confidence
Td,R,V_confidence
boundingBox
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,V_boundingBox
q24@?0@"HMIObjectDetection"8@"HMIObjectDetection"16
timeOffset
T{?=qiIq},R,V_timeOffset
TQ,R,V_width
TQ,R,V_height
generationFrequency
T{?=qiIq},R,V_generationFrequency
[Fragment:%lu] Failed to generate poster frame for: %lu
camera.video.poster.frame.generator
posterFramesInternal
T@"NSMutableArray",&,V_posterFramesInternal
input
T@"HMICameraVideoPosterFrameGeneratorInput",R,V_input
nextGenerationTime
T{?=qiIq},V_nextGenerationTime
[Fragment:%lu] frames initial width:%lu frames initial height:%lu number of frames to select:%lu
[Fragment:%lu] resized width:%lu resized height:%lu 
[Fragment:%lu] fragmentAnalysisFPS: %f fragmentNominalFrameRate: %f fragmentDuration: %f totalNumFramesInFragment: %lu numberFramesToSelect: %lu enable_optical_flow: %d
Optical Flow
@min.self
camera.video.frame.selector
framesInternal
T@"NSMutableArray",&,V_framesInternal
totalNumberOfFramesInFragment
TQ,V_totalNumberOfFramesInFragment
numberFramesToAdvance
Tf,V_numberFramesToAdvance
nextFrameToSelectForAnalysis
Tf,V_nextFrameToSelectForAnalysis
currentFrameNumber
TQ,V_currentFrameNumber
numberFramesToSelect
TQ,V_numberFramesToSelect
enableOpticalFlow
TB,V_enableOpticalFlow
minRows
T@"NSMutableDictionary",&,V_minRows
maxRows
T@"NSMutableDictionary",&,V_maxRows
minCols
T@"NSMutableDictionary",&,V_minCols
maxCols
T@"NSMutableDictionary",&,V_maxCols
flowArray
T^f,V_flowArray
quantizedFrames
T@"NSMutableArray",&,V_quantizedFrames
connectedComponentsMap
T@"NSMutableArray",&,V_connectedComponentsMap
framesScore
T@"NSMutableArray",&,V_framesScore
TQ,V_frameWidth
TQ,V_frameHeight
actualAnalysisFPS
Tf,V_actualAnalysisFPS
opticalFlowReferenceImage
T^{__CVBuffer=},V_opticalFlowReferenceImage
refFrameNumber
Ti,V_refFrameNumber
targetFrameNumber
Ti,V_targetFrameNumber
numOpticalFlowCalculations
Ti,V_numOpticalFlowCalculations
frames
T@"NSArray",R,V_frames
logIdentifier
T@"NSString",R,V_logIdentifier
maxOpticalFlowCalculations
Ti,V_maxOpticalFlowCalculations
targetSelectionInterval
Ti,V_targetSelectionInterval
referenceSelectionInterval
Ti,V_referenceSelectionInterval
HMIErrorDomain
Unexpected error
Failed to analyze
Failed to read fragment
Failed to generate poster frame
Failed to transcode fragment
Video analyzer in error state
Model failed to load
Fragment is invalid
No pixel buffer
Unknown error code %ld
HMIErrorCodeUnexpectedError
HMIErrorCodeFailedToAnalyze
HMIErrorCodeFailedToReadFragment
HMIErrorCodeFailedToGeneratePosterFrame
HMIErrorcodeFailedToTranscodeFragment
HMIErrorCodeAnalyzerInErrorState
HMIErrorCodeModelFailedToLoad
HMIErrorCodeFragmentIsInvalid
HMIPrivateErrorCodeNilPixelBuffer
HMIPrivateErrorCodeEmptyURL
HMIPrivateErrorCodeAVAssetReaderInitializationFailed
HMIPrivateErrorCodeFailedToLoadProperty
HMIPrivateErrorCodeAssetLoadCancelled
HMIPrivateErrorCodeReadingStartFailed
HMIPrivateErrorCodeNoTrackOutput
HMIPrivateErrorCodeSampleBufferUnavailable
HMIPrivateErrorCodeNoVideoTrackFound
HMIPrivateErrorCodeMultipleVideoTracksFound
HMIPrivateErrorInvalidPresentationTime
HMIPrivateErrorAVAssetReaderNotStarted
HMIPrivateErrorCodeSequentialIntegrityViolated
HMIPrivateErrorCodeAnalysisServiceNoConfiguration
HMIPrivateErrorCodeLoadingCoreMLModelFailed
HMIPrivateErrorCodeCoreMLPredictionFailed
HMIPrivateErrorCodeCoreMLOutputIncorrect
HMIPrivateErrorCodeCropAndResizeFailed
HMIPrivateErrorCodePosterFrameGenerationFailed
HMIPrivateErrorCodeCodecNotAvailable
HMIPrivateErrorCodeEncodingFailed
HMIPrivateErrorCodeInvalidVideoFrameFormatToSave
HMIPrivateErrorCodeInvalidCropRect
HMIPrivateErrorCodeScalerError
ERROR_%ld
%@: %@
HMISyntheticErrorDomain
resourceUsageMonitor
T@"<HMISystemResourceUsageMonitorProtocol>",R,V_resourceUsageMonitor
T@"<HMISystemResourceUsageMonitorDelegate>",W,Vdelegate
camera.video.frame.motion.analysis.result
movingObjectCropRect
T{CGRect={CGPoint=dd}{CGSize=dd}},R,V_movingObjectCropRect
motionScore
Tf,R,V_motionScore
pixelBufferUV
T^{__CVBuffer=},V_pixelBufferUV
video/mp4
Failed to initialize HMICameraVideoResourceAttributes from fragment data, err: %d
camera.video.resource.attributes
assetDuration
T{?=qiIq},R,V_assetDuration
T@"NSDate",R,V_creationDate
firstSequenceNumber
TQ,R,V_firstSequenceNumber
nominalFrameRate
Td,R,V_nominalFrameRate
dimensions
T{CGSize=dd},R,V_dimensions
tracks
firstFragmentSequenceNumber
fragmentCount
timeRange
formatDescriptions
[Fragment:%lu] Creating asset with url: %@
[Fragment:%lu] Failed to initialize AVAssetReader
[Fragment:%lu] Start %0.2f, Duration %0.2f, FPS %0.2f
[Fragment:%lu] No fragment URL found on loading request %@
[Fragment:%lu] No fragment data found for URL %@
[Fragment:%lu] Finished handling load request
camera.video.asset.reader
currentFrameId
TQ,V_currentFrameId
T@"AVAssetReader",&,N,V_assetReader
resourceLoaderWorkQueue
T@"NSObject<OS_dispatch_queue>",R,V_resourceLoaderWorkQueue
T@"HMICameraVideoFragment",R,V_videoFragment
HMICVFR.fi
HMICVFR.e
HMICVFR.as
HMICVFR.d
HMICVFR.fw
HMICVFR.fh
HMICVAR.e
HMICVAR.rc
HMICVAR.fr
HMICVAR.as
HMICVAR.cd
HMICVAR.d
HMICVAR.pf
HMICVAR.ttaf
HMICVAR.tsfws
HMICVAR.lsn
HMICVAR.vf
HMICVAR.af
HMICVAC.pfgi
HMICVAC.pfh
HMICVAC.mfad
HMICVAC.mfd
HMICVAC.st
HMICVAC.smisn
HMICVAC.tf
HMICVASE.e
HMICVASE.vf
HMICVASE.as
HMICVF.et
HMICVF.sn
HMICVF.mf
HMICVF.d
HMICVPF.d
HMICVPF.to
HMICVPF.w
HMICVPF.h
HMICVFMAR.ms
HMICVFMAR.mocrx
HMICVFMAR.mocry
HMICVFMAR.mocrw
HMICVFMAR.mocrh
HMIOD.l
HMIOD.c
HMIOD.b.x
HMIOD.b.y
HMIOD.b.w
HMIOD.b.h
supportsSecureCoding
HMICameraVideoFrame does not support NSSecureCoding in the simulator
preferenceOverrides
videoAnalyzerIdentifier
didAnalyzeFragment
didNotAnalyzeFragment
didFindSignificantEvent
result
significantEvents
HMIAnalysisServiceTypeUnknown
HMIAnalysisServiceTypeLocal
HMIAnalysisServiceTypeRemoteFragment
HMIAnalysisServiceTypeUndefined
v24@?0@"HMICameraVideoFragment"8@"HMICameraVideoAnalyzerResult"16
v24@?0@"HMICameraVideoFragment"8@"NSError"16
T@?,C,N,V_didAnalyzeFragment
didFailAnalysisForFragment
T@?,C,N,V_didFailAnalysisForFragment
T@?,C,N,V_didFindSignificantEvent
T@?,C,N,V_didNotAnalyzeFragment
HMIAnalysisService
Remote analysis not supported in the simulator
Asset data is ignored if the video fragment is passed through the properties dictionary
Analyzer configuration property key (%@) is missing
v24@?0@"HMICameraVideoAnalyzerSignificantEvent"8@"HMICameraVideoFragment"16
camera.video.analysis.service
nextRequestID
Ti,V_nextRequestID
requests
T@"NSMapTable",R,V_requests
runRemotely
TB,V_runRemotely
com.apple.homed
personDetected
petDetected
vehicleDetected
analysisQOS
analysisServiceType
analysisEnableOpticalFlow
processingDevice
confidenceThresholdPersonHigh
confidenceThresholdPetHigh
confidenceThresholdVehicleHigh
confidenceThresholdPersonMedium
confidenceThresholdPetMedium
confidenceThresholdVehicleMedium
modelTimeout
assetReaderMaximizePowerEfficiency
assetReaderForceBGRA
shouldLoadBaseDecodeTimestampAssetProperty
analysisEnableTranscodeFragment
realTimeEncoding
maxConcurrentAnalysisRequests
espressoLowPriority
opticalFlowLowPriority
opticalFlowBackgroundProcessing
syntheticRemoteAnalysisError
syntheticAssetReaderStartReadingError
syntheticAssetReaderReadNextFrameError
analyzeFrameSleep
user-interactive
user-initiated
unspecified
default
utility
background
Preference %@ is now %@, previously was %@
Only NSNumber and NSString properties are supported.
HMIPreference
T@"HMIPreference",R
qosMap
T@"NSDictionary",R
isProductTypeJ105A
preferenceLoggedValues
T@"NSMutableDictionary",R,N,V_preferenceLoggedValues
preferenceOverridesInternal
T@"NSMutableDictionary",R,N,V_preferenceOverridesInternal
usesCPUOnly
Already started listening for the notification
v12@?0i8
HMINotifydObserver
T@"NSObject<OS_dispatch_queue>",R,N,V_queue
callback
T@?,R,N,V_callback
token
Ti,N,V_token
notificationName
Tr*,R,N,V_notificationName
com.apple.HomeAI.%@%@%@.%tu
v32@?0@"NSNumber"8@"NSNumber"16^B24
HMICameraVideoFrameAnalyzerSignificantActivity
@"NSNumber"16@?0@"NSObject"8
none
medium
high
camera.video.frame.analyzer.significant.activity
classHierarchyMap
significantActivityDetector
T@"HMISignificantActivityDetector",R,V_significantActivityDetector
transaction
T@"HMFOSTransaction",&,N,V_transaction
T^{__CVBuffer=},N,V_image__Placeholder__0
T@"MLMultiArray",&,N,V_ShotNet__ShotNet__ssd_predictions__block8_box__class_prob__0
T@"MLMultiArray",&,N,V_ShotNet__ShotNet__ssd_predictions__block8_box__box_offset__0
T@"MLMultiArray",&,N,V_ShotNet__ShotNet__ssd_predictions__block7_box__class_prob__0
T@"MLMultiArray",&,N,V_ShotNet__ShotNet__ssd_predictions__block7_box__box_offset__0
T@"MLMultiArray",&,N,V_ShotNet__ShotNet__ssd_predictions__block6_box__class_prob__0
T@"MLMultiArray",&,N,V_ShotNet__ShotNet__ssd_predictions__block6_box__box_offset__0
T@"MLMultiArray",&,N,V_ShotNet__ShotNet__ssd_predictions__block9_box__class_prob__0
T@"MLMultiArray",&,N,V_ShotNet__ShotNet__ssd_predictions__block9_box__box_offset__0
T@"MLMultiArray",&,N,V_ShotNet__ShotNet__ssd_predictions__block10_box__class_prob__0
T@"MLMultiArray",&,N,V_ShotNet__ShotNet__ssd_predictions__block10_box__box_offset__0
T@"MLMultiArray",&,N,V_ShotNet__ShotNet__ssd_predictions__block11_box__class_prob__0
T@"MLMultiArray",&,N,V_ShotNet__ShotNet__ssd_predictions__block11_box__box_offset__0
model
T@"MLModel",R,N,V_model
scn == 1
convertAndUnrollScalar
/BuildRoot/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/HomeAI-72/OpenCV/src/core/arithm.cpp
op == CMP_LT || op == CMP_LE || op == CMP_EQ || op == CMP_NE || op == CMP_GE || op == CMP_GT
compare
The operation is neither 'array op array' (where arrays have the same size and the same type), nor 'array op scalar', nor 'scalar op array'
The operation is neither 'array op array' (where arrays have the same size and type), nor 'array op scalar', nor 'scalar op array'
binary_op
(mask.type() == CV_8UC1 || mask.type() == CV_8SC1)
mask.size == src1.size
operator()
-256 <= ((b) - (a)) && ((b) - (a)) <= 512
-256 <= ((a) - (b)) && ((a) - (b)) <= 512
The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array'
arithm_op
src2.type() == CV_64F && (src2.rows == 4 || src2.rows == 1)
When the input arrays in add/subtract/multiply/divide functions have different types, the output array type must be explicitly specified
-256 <= (a - b) && (a - b) <= 512
/BuildRoot/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/HomeAI-72/OpenCV/src/core/alloc.cpp
Failed to allocate %lu bytes
OutOfMemoryError
CV_MAT_CN(_type) == e.a.channels()
assign
/BuildRoot/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/HomeAI-72/OpenCV/src/core/matop.cpp
Unknown operation
Invalid matrix initializer type
/BuildRoot/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/HomeAI-72/OpenCV/src/core/opengl_interop_deprecated.cpp
GlBuffer
GlTexture
/BuildRoot/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/HomeAI-72/OpenCV/src/core/persistence.cpp
Invalid pointer to file storage
The node is neither a map nor an empty collection
cvGetFileNodeByName
Null element name
cvStartWriteStruct
The file storage is opened for reading
cvEndWriteStruct
cvWriteInt
cvWriteString
cvWriteRawData
Negative number of elements
Null data pointer
cvStartReadRawData
Null pointer to source file node or reader
The file node should be a numerical scalar or a sequence
cvReadRawDataSlice
Null pointer to reader or destination array
The readed sequence is a scalar, thus len must be 1
The sequence element is not a numerical scalar
The sequence slice does not fit an integer number of records
Null pointers to source file node or destination array
cvReadRawData
opencv-sequence
opencv-sequence-tree
opencv-graph
opencv-sparse-matrix
opencv-image
opencv-matrix
opencv-nd-matrix
Invalid type info
cvRegisterType
Some of required function pointers (is_instance, release, read or write) are NULL
Type name should start with a letter or _
Type name should contain only letters, digits, - and _
NULL double pointer
cvRead
The node does not represent a user object (unknown type?)
Unknown array type
The storage is not opened
icvPuts
An attempt to add element without a key to a map, or add element with key to sequence
icvXMLWriteTag
A single _ is a reserved tag name
Closing tag should not include any attributes
Key should start with a letter or _
Key name may only contain alphanumeric characters [a-zA-Z0-9], '-' and '_'
icvDecodeFormat
fmt_pairs != 0 && max_len > 0
Invalid data type specification
Too long data type specification
%.8e
-.Inf
.Inf
%.16e
elements with keys can not be written to sequence
icvXMLWriteScalar
icvYMLWrite
The key is an empty
The key is too long
Key must start with a letter or _
Key names may only contain alphanumeric characters [a-zA-Z0-9], '-', '_' and ' '
icvReleaseSeq
count
Some of essential sequence attributes are absent
icvReadSeq
The sequence flags are invalid
curve
closed
hole
untyped
header_dt
header_user_data
One of "header_dt" and "header_user_data" is there, while the other is not
rect
origin
Only one of "header_user_data", "rect" and "origin" tags may occur
width
height
color
The image data is not found in file storage
The number of stored elements does not match to "count"
Too complex format for the matrix
icvDecodeSimpleFormat
recursive
false
False
FALSE
icvWriteSeqTree
CV_IS_SEQ( seq )
sequences
icvWriteSeq
level
The size of element calculated from "dt" and the elem_size do not match
icvGetFormat
Size of sequence element (elem_size) is inconsistent with seq->flags
%d%c
The size of header calculated from "header_dt" is greater than header_size
icvWriteHeaderData
opencv-sequence-tree instance should contain a field "sequences" that should be a sequence
icvReadSeqTree
All the sequence tree nodes should contain "level" field
level == prev_level + 1
icvReleaseGraph
vertex_dt
edge_dt
vertex_count
edge_count
Some of essential graph attributes are absent
icvReadGraph
oriented
Graph edges should start with 2 integers and a float
%df%s
vertices
edges
No edges data
No vertices data
Some of stored vertex indices are out of range
Duplicated edge has occured
cvAlignPtr
(align & (align-1)) == 0
icvWriteGraph
CV_IS_GRAPH(graph)
2if%s
sizes
Some of essential matrix attributes are absent
icvReadSparseMat
Could not determine sparse matrix dimensionality
The matrix data is not found in file storage
Sparse matrix data is corrupted
icvWriteSparseMat
CV_IS_SPARSE_MAT(mat)
(reader).seq->elem_size == sizeof(idx)
k < dims
Some of essential image attributes are absent
icvReadImage
layout
interleaved
Only interleaved images can be read
The matrix size does not match to the number of stored elements
icvWriteImage
CV_IS_IMAGE(image)
Images with planar data layout are not supported
top-left
bottom-left
planar
rows
cols
icvReadMat
icvWriteMat
CV_IS_MAT_HDR_Z(mat)
icvReadMatND
Could not determine the matrix dimensionality
icvWriteMatND
CV_IS_MATND_HDR(mat)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/HomeAI-72/OpenCV/src/core/datastructs.cpp
cvReleaseMemStorage
cvRestoreMemStoragePos
NULL storage pointer
cvMemStorageAlloc
Too large memory block is requested
storage->free_space % CV_STRUCT_ALIGN == 0
requested size is negative or too big
(size_t)ptr % CV_STRUCT_ALIGN == 0
cvCreateSeq
Specified element size doesn't match to the size of the specified element type (try to use 0 for element type)
cvSetSeqBlockSize
Storage block size is too small to fit the sequence elements
cvCvtSeqToArray
cvStartReadSeq
cvChangeSeqBlock
cvGetSeqReaderPos
cvSetSeqReaderPos
cvSeqPush
ptr + elem_size <= seq->block_max
block->start_index > 0
NULL sequence pointer
cvSeqPushMulti
number of removed elements is negative
cvSeqPopMulti
delta > 0
cvClearSeq
Invalid sequence header
cvSeqSlice
Bad sequence slice
Bad input sequence
cvSeqSort
Null compare function
cvCreateSet
cvSetAdd
count <= CV_SET_ELEM_IDX_MASK+1
cvCreateGraph
cvGraphAddVtx
cvFindGraphEdgeByPtr
ofs == 1 || start_vtx == edge->vtx[0]
graph pointer is NULL
cvGraphAddEdgeByPtr
vertex pointers coinside (or set to NULL)
edge->flags >= 0
Invalid graph pointer
cvCloneGraph
cvInitTreeNodeIterator
NULL iterator pointer
cvNextTreeNode
icvInitMemStorage
cvAlign
/BuildRoot/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/HomeAI-72/OpenCV/include/opencv2/core/internal.hpp
(align & (align-1)) == 0 && size < INT_MAX
icvDestroyMemStorage
icvGoNextMemBlock
parent->bottom == block
icvGrowSeq
The sequence has NULL storage pointer
storage->free_space >= delta
block->count % seq->elem_size == 0 && block->count > 0
seq->first->start_index == 0
icvFreeSeqBlock
(in_front_of ? block : block->prev)->count == 0
seq->ptr == block->data
block->count > 0 && block->count % seq->elem_size == 0
channels() == CV_MAT_CN(dtype)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/HomeAI-72/OpenCV/src/core/copy.cpp
mask.depth() == CV_8U && (mcn == 1 || mcn == cn)
size() == mask.size()
setTo
repeat
ny > 0 && nx > 0
maskarr == 0
cvCopy
src.depth() == dst.depth() && src.size == dst.size
(coi1 != 0 || src.channels() == 1) && (coi2 != 0 || dst.channels() == 1)
%s:%d: error: (%d) %s in function %s
%s:%d: error: (%d) %s
OpenCV Error: %s (%s) in %s, file %s, line %d
No Error
Backtrace
Unspecified error
Internal error
Insufficient memory
Bad argument
Iterations do not converge
Autotrace call
Incorrect size of input array
Null pointer
Division by zero occured
Image step is wrong
Inplace operation is not supported
Requested object was not found
Input image depth is not supported by function
Formats of input arguments do not match
Sizes of input arguments do not match
One of arguments' values is out of range
Unsupported format or combination of formats
Input COI is not supported
Bad number of channels
Bad flag (parameter or structure field)
Bad parameter of type CvPoint
Bad type of mask argument
Parsing error
The function/feature is not implemented
Memory block has been corrupted
Assertion failed
No GPU support
Gpu API call
No OpenGL support
OpenGL API call
Unknown %s code %d
status
module != 0 && module->name != 0 && module->version != 0
cvRegisterModule
/BuildRoot/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/HomeAI-72/OpenCV/src/core/system.cpp
cxcore
2.4.13.6
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
/BuildRoot/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/HomeAI-72/OpenCV/src/core/convert.cpp
src && nsrcs > 0 && dst && ndsts > 0 && fromTo && npairs > 0
mixChannels
j < nsrcs && src[j].depth() == depth
i1 >= 0 && j < ndsts && dst[j].depth() == depth
unknown function
/BuildRoot/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/HomeAI-72/OpenCV/include/opencv2/dynamicuda/dynamicuda.hpp
copy
copyWithMask
convert
mallocPitch
The library is compiled without CUDA support
type == B.type() && (type == CV_32FC1 || type == CV_64FC1 || type == CV_32FC2 || type == CV_64FC2)
gemm
/BuildRoot/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/HomeAI-72/OpenCV/src/core/matmul.cpp
a_size.width == len
a_size.height == len
C.type() == type && (((flags&GEMM_3_T) == 0 && C.rows == d_size.height && C.cols == d_size.width) || ((flags&GEMM_3_T) != 0 && C.rows == d_size.width && C.cols == d_size.height))
type == CV_64FC2
src1.type() == src2.type()
scaleAdd
src.channels() == 1
mulTransposed
delta.channels() == 1 && (delta.rows == src.rows || delta.rows == 1) && (delta.cols == src.cols || delta.cols == 1)
GEMM_TransposeBlock
MulTransposedR
delta_cols == 1
/BuildRoot/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/HomeAI-72/OpenCV/src/core/opengl_interop.cpp
The library is compiled without OpenGL support
throw_nogl
/BuildRoot/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/HomeAI-72/OpenCV/src/core/lapack.cpp
type == CV_32F || type == CV_64F
invert
m == n
method == DECOMP_LU || method == DECOMP_CHOLESKY
n == 1
type == _src2.type() && (type == CV_32F || type == CV_64F)
solve
(method != DECOMP_LU && method != DECOMP_CHOLESKY) || is_normal || src.rows == src.cols
src.rows == 1
The function can not solve under-determined linear systems
src.rows == src.cols
eigen
w.type() == u.type() && u.type() == vt.type() && u.data && vt.data && w.data
backSubst
u.cols >= nm && vt.rows >= nm && (w.size() == Size(nm, 1) || w.size() == Size(1, nm) || w.size() == Size(vt.rows, u.cols))
rhs.data == 0 || (rhs.type() == type && rhs.rows == m)
_SVDcompute
/BuildRoot/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/HomeAI-72/OpenCV/src/core/array.cpp
Non-positive width or height
cvCreateMatHeader
Invalid matrix type
cvInitMatHeader
Non-positive cols or rows
cvReleaseMat
Bad CvMat header
cvCloneMat
NULL matrix header pointer
cvInitMatNDHeader
invalid array data type
NULL <sizes> pointer
non-positive or too large number of dimensions
one of dimesion sizes is non-positive
The array is too big
cvCreateMatNDHeader
Bad CvMatND header
cvCloneMatND
src->dims <= CV_MAX_DIM
_dst.data == data0
Incorrect number of arrays
cvInitNArrayIterator
Some of required array pointers is NULL
Iterator pointer is NULL
COI set is not allowed here
Number of dimensions is the same for all arrays
Data type is not the same for all arrays
Number of channels is not the same for all arrays
Depth is not the same for all arrays
Mask should have 8uC1 or 8sC1 data type
Dimension sizes are the same for all arrays
cvNextNArraySlice
iterator != 0
cvCreateSparseMat
bad number of dimensions
cvReleaseSparseMat
Invalid sparse array header
cvCloneSparseMat
Invalid sparse matrix header
cvInitSparseMatIterator
Data is already allocated
cvCreateData
unrecognized or unsupported array type
cvReleaseData
Only continuous nD arrays are supported here
cvGetElemType
cvGetDims
Array should be CvMat or IplImage
cvGetSize
index is out of range
cvPtr2D
COI must be non-null in case of planar images
NULL pointer to indices
cvPtrND
NULL array pointer is passed
cvGetMat
The matrix has NULL data pointer
The image has NULL data pointer
Images with planar data layout should be used with COI selected
The image is interleaved and has over CV_CN_MAX channels
Pixel order should be used with coi == 0
Input array has NULL data pointer
Unrecognized or unsupported array type
cvCreateImage
null pointer to header
cvInitImageHeader
Bad input roi
Unsupported format
Bad input origin
Bad input align
cvReleaseImageHeader
cvReleaseImage
cvSetImageROI
rect.width >= 0 && rect.height >= 0 && rect.x < image->width && rect.y < image->height && rect.x + rect.width >= (int)(rect.width > 0) && rect.y + rect.height >= (int)(rect.height > 0)
cvSetImageCOI
cvGetImageCOI
Bad image header
cvCloneImage
cvGetMatND
icvGetNodePtr
CV_IS_SPARSE_MAT( mat )
One of indices is out of range
(newsize & (newsize - 1)) == 0
GRAY
BGRA
0 <= d && d <= CV_MAX_DIM && _sizes
create
/BuildRoot/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/HomeAI-72/OpenCV/src/core/matrix.cpp
step[dims-1] == (size_t)CV_ELEM_SIZE(flags)
m.dims >= 2
0 <= _rowRange.start && _rowRange.start <= _rowRange.end && _rowRange.end <= m.rows
0 <= _colRange.start && _colRange.start <= _colRange.end && _colRange.end <= m.cols
m.dims <= 2
ranges
r == Range::all() || (0 <= r.start && r.start < r.end && r.end <= m.size[i])
dims <= 2
diag
img->dataOrder == IPL_DATA_ORDER_PIXEL
img->dataOrder == IPL_DATA_ORDER_PIXEL || img->roi->coi != 0
(int)nelems >= 0
reserve
resize
COI is not supported by the function
cvarrToMat
seq->total > 0 && CV_ELEM_SIZE(seq->flags) == seq->elem_size
reshape
The matrix is not continuous, thus its number of rows can not be changed
Bad new number of rows
The total number of matrix elements is not divisible by the new number of rows
The total width is not divisible by the new number of channels
cn <= 4
scalarToRawData
i < 0
getMat
0 <= i && i < (int)vv.size()
This method is not implemented for oclMat yet
k == STD_VECTOR_MAT
0 <= i && i < (int)v.size()
getMatVector
This function in deprecated, do not use it
getGlBuffer
getGlTexture
k == GPU_MAT
getGpuMat
i < (int)vv.size()
total
type
empty
!fixedSize() || ((Mat*)obj)->size.operator()() == _sz
!fixedType() || ((Mat*)obj)->type() == mtype
!fixedSize() || ((gpu::GpuMat*)obj)->size() == _sz
!fixedType() || ((gpu::GpuMat*)obj)->type() == mtype
!fixedSize() || ((ogl::Buffer*)obj)->size() == _sz
!fixedType() || ((ogl::Buffer*)obj)->type() == mtype
!fixedSize() || ((Mat*)obj)->size.operator()() == Size(cols, rows)
!fixedSize() || ((gpu::GpuMat*)obj)->size() == Size(cols, rows)
!fixedSize() || ((ogl::Buffer*)obj)->size() == Size(cols, rows)
!fixedType() && !fixedSize()
CV_MAT_TYPE(mtype) == m.type()
m.dims == dims
m.size[j] == sizes[j]
mtype == type0 || (CV_MAT_CN(mtype) == 1 && ((1 << type0) & fixedDepthMask) != 0)
dims == 2 && ((sizes[0] == sz.height && sizes[1] == sz.width) || (allowTransposed && sizes[0] == sz.width && sizes[1] == sz.height))
dims == 2 && (sizes[0] == 1 || sizes[1] == 1 || sizes[0]*sizes[1] == 0)
!fixedSize() || len == vv.size()
mtype == type0 || (CV_MAT_CN(mtype) == CV_MAT_CN(type0) && ((1 << type0) & fixedDepthMask) != 0)
!fixedSize() || len == ((vector<uchar>*)v)->size() / esz
Vectors with element size %d are not supported. Please, modify OutputArray::create()
create() called for the missing output array
!fixedSize() || len == len0
v[j].empty()
i < (int)v.size()
!fixedType() || (CV_MAT_CN(mtype) == m.channels() && ((1 << CV_MAT_TYPE(flags)) & fixedDepthMask) != 0)
!fixedSize()
release
clear
k == MAT
getMatRef
setIdentity
src.dims <= 2 && esz <= (size_t)32
transpose
src.size() == dst.size() && (src.cols == 1 || src.rows == 1)
func != 0
m.dims <= 2 && m.rows == m.cols
completeSymm
src.dims <= 2
src.channels() == dst.channels()
_arrays && (_ptrs || _planes)
init
narrays <= 1000
arrays[i] != 0
A.size == arrays[i0]->size
A.step[d-1] == A.elemSize()
copyTo
convertTo
0 <= _dims && _dims <= CV_MAX_DIM
setSize
s >= 0
%{public}@%{public}@
HMIInputFeatureProvider
MLFeatureProvider
HMISignificantActivityDetector
HMFLogging
NSObject
HMICameraVideoEncoderSession
AVAssetWriterDelegate
HMISystemResourceUsage
HMISystemResourceUsageMonitor
HMISystemResourceUsageMonitorProtocol
HMICameraVideoFrame
HMIVisionUtilities
HMIThermalMonitorService
HMIThermalMonitor
HMIPIDController
HMFTimerDelegate
MovingAverageEntry
MovingAverage
HMICameraVideoAnalyzerResult
HMICameraVideoAnalyzerConfiguration
NSCopying
HMICameraVideoAnalyzerSignificantEvent
HMICameraVideoFrameResult
HMICameraVideoFragment
HMICameraVideoAnalyzerRequestLog
HMICameraVideoAnalyzerRequest
HMICameraVideoAnalyzerScheduler
HMISystemResourceUsageMonitorDelegate
HMICameraVideoAnalyzer
HMICameraVideoFrameAnalyzerFactory
HMIObjectDetection
HMIObjectDetectionUtils
HMICameraVideoPosterFrame
HMICameraVideoPosterFrameGeneratorInput
HMICameraVideoPosterFrameGenerator
HMICameraVideoFrameSelector
HMIError
HMISystemResourceUsageMonitorImpl
HMICameraVideoFrameMotionAnalysisResult
HMICameraVideoResourceAttributes
HMICameraVideoAssetReader
AVAssetResourceLoaderDelegate
NSCoding
NSSecureCoding
HMICameraVideoAnalyzerDelegateAdapter
HMICameraVideoAnalyzerDelegate
HMIAnalysisService
HMIPreference
HMINotifydObserver
HMICameraVideoFrameAnalyzerSignificantActivity
HMICameraVideoFrameAnalyzer
SignificantActivityInput
SignificantActivityOutput
SignificantActivity
init
inputName
arrayWithObjects:count:
setWithArray:
isEqualToString:
pixelBuffer
featureValueWithPixelBuffer:
featureValueForName:
featureNames
initWithPixelBuffer:inputName:
.cxx_destruct
_pixelBuffer
_inputName
count
objectAtIndexedSubscript:
doubleValue
sharedInstance
usesCPUOnly
setUsesCPUOnly:
boolPreferenceForKey:defaultValue:
setAllowBackgroundGPUCompute:
bundleForClass:
pathForResource:ofType:
fileURLWithPath:
modelWithContentsOfURL:configuration:error:
hmiPrivateErrorWithCode:underlyingError:
arrayWithCapacity:
_runNeuralNetworkOnPixelBuffer:offsets:scores:error:
_postProcessOffsets:scores:outputPredictions:
inputFeatureValueName
mlModel
predictionOptions
predictionFromFeatures:options:error:
offsetsFeatureValueNames
type
hmiPrivateErrorWithCode:description:
multiArrayValue
addObject:
scoresFeatureValueNames
array
shape
unsignedLongValue
dataPointer
strides
useSoftmax
init:confidence:boundingBox:
nmsThreshold
nmsMultiClass:output:withThreshold:
countByEnumeratingWithState:objects:count:
labelIndex
confidence
boundingBox
categoryWithName:
logCategory
isEqual:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
description
debugDescription
logIdentifier
initWithConfidenceThresholds:nmsThreshold:error:
predict:detectedObjects:error:
inputDimensions
_confidenceThresholds
_anchorSizes
_numberOfAnchors
_useSoftmax
_mlModel
_inputFeatureValueName
_offsetsFeatureValueNames
_scoresFeatureValueNames
_nmsThreshold
_predictionOptions
_inputDimensions
numberWithBool:
numberWithUnsignedInt:
dictionaryWithObjects:forKeys:count:
mutableCopy
numberWithInt:
setObject:forKey:
hmiPrivateErrorWithCode:
setBitRate:
initWithFileType:error:
assetWriterInputWithMediaType:outputSettings:
setExpectsMediaDataInRealTime:
addInput:
setDelegate:
data
initWithName:
encodedAssetData
appendData:
session
assetWriterInput
isReadyForMoreMediaData
setLength:
assetWriter
startWriting
startSessionAtSourceTime:
internal
stringWithFormat:
appendSampleBuffer:
invalidate
activity
markAsFinished
flush
finishWritingWithCompletionHandler:
status
error
copy
dealloc
assetWriter:didProduceFragmentedHeaderData:
assetWriter:didProduceFragmentedMediaData:fragmentedMediaDataReport:
initWithWidth:height:codecType:realTime:error:
bitRate
startEncoding
encodePixelBuffer:presentationTime:
finishEncodingWithCompletionHandler:
_session
_assetWriter
_assetWriterInput
_encodedAssetData
_activity
systemResourceUsageLevel
setSystemResourceUsageLevel:
_systemResourceUsageLevel
UTF8String
productInfo
productClass
initWithProductClass:workQueue:
workQueue
systemResourceUsageMonitorImpl
delegate
getCurrentSystemResourceUsage
start
_systemResourceUsageMonitorImpl
_workQueue
initWithPixelBuffer:presentationTime:frameId:fragmentSequenceNumber:
jpegData
size
imageWithData:
extent
createIOSurfaceBackedPixelBufferWithWidth:height:pixelBuffer:
contextWithOptions:
render:toCVPixelBuffer:
numberWithUnsignedLong:
dictionaryWithDictionary:
JPEGRepresentationWithDownscaleFactor:outSize:
motionResult
movingObjectCropRect
cropAndResizePixelBuffer:rect:size:error:
regionOfInterestPixelBuffer
presentationTime
initWithPixelBuffer:
initWithJPEGData:presentationTime:frameId:fragmentSequenceNumber:size:
convertToJPEGAndGenerateRegionOfInterestWithSize:error:
frameId
fragmentSequenceNumber
setMotionResult:
_frameId
_fragmentSequenceNumber
_regionOfInterestPixelBuffer
_jpegData
_motionResult
_size
_presentationTime
cropPixelBuffer:cropRect:error:
resizePixelBuffer:resultSize:error:
initWithService:
readValue
_service
dictionary
services
objectForKey:
readValueFromSensor:value:
readMaxValue:
lock
_client
_services
_lock
isProductTypeJ105A
numberWithDouble:
initWithConfiguration:
resumeMonitoring
objectForKeyedSubscript:
floatValue
initWithTimeInterval:options:
updateControlEffortFromValue:
tick
resume
suspend
timerDidFire:
suspendMonitoring
controlEffort
_target
_integrator
_integratorMin
_integratorMax
_engageDelta
_controlEffortMin
_controlEffortMax
_controlEffort
_tick
exceptionWithName:reason:userInfo:
performBlock:
date
initWithValue:
value
_value
_date
windowSize
queue
hmf_removeFirstObject
na_each:
setMovingAverage:
timeIntervalSinceDate:
initWithWindowSize:
addNumber:
movingAverageForInterval:defaultValue:
movingAverage
setQueue:
_movingAverage
_queue
_windowSize
events
annotationScores
confidenceThatEventOccurred:events:annotationScores:
resultCode
lastSequenceNumber
analysisFPS
duration
creationDate
frameResults
isEqualToArray:
isEqualToDictionary:
posterFrames
videoFragment
timeToAnalyzeFragment
timeSinceFragmentWasSubmitted
initWithEvents:posterFrames:frameResults:annotationScores:duration:creationDate:resultCode:lastSequenceNumber:
confidenceThatEventOccurred:
isEqual:excludeTime:
setDuration:
setCreationDate:
setResultCode:
setTimeToAnalyzeFragment:
setTimeSinceFragmentWasSubmitted:
setVideoFragment:
setAnalysisFPS:
_analysisFPS
_events
_annotationScores
_posterFrames
_frameResults
_creationDate
_resultCode
_timeToAnalyzeFragment
_timeSinceFragmentWasSubmitted
_videoFragment
_lastSequenceNumber
_duration
getAnalysisServiceTypePreference
numberWithUnsignedInteger:
numberPreferenceForKey:defaultValue:withMap:
integerValue
allocWithZone:
initWithPosterFrameGenerationInterval:posterFrameHeight:maxFragmentAnalysisDuration:maxFragmentDuration:
copyWithZone:
posterFrameGenerationInterval
posterFrameHeight
maxFragmentAnalysisDuration
maxFragmentDuration
serviceType
setServiceType:
startingMediaIntegritySequenceNumber
setStartingMediaIntegritySequenceNumber:
transcodeFragment
setTranscodeFragment:
useScheduler
setUseScheduler:
inMediaAnalysis
setInMediaAnalysis:
_transcodeFragment
_useScheduler
_inMediaAnalysis
_posterFrameGenerationInterval
_posterFrameHeight
_maxFragmentAnalysisDuration
_maxFragmentDuration
_serviceType
_startingMediaIntegritySequenceNumber
initWithEvents:annotationScores:videoFrame:
videoFrame
_videoFrame
initWithFrameId:events:annotationScores:detections:frameWidth:frameHeight:
detections
frameWidth
frameHeight
_detections
_frameWidth
_frameHeight
initWithSequenceNumber:data:moovFragment:eventTypes:
setUrl:
moovFragment
length
initWithData:
sequenceNumber
stringByAppendingFormat:
URLWithString:
absoluteString
initWithSequenceNumber:data:moovFragment:
initWithSequenceNumber:fragmentData:eventTypes:
initWithSequenceNumber:fragmentData:eventTypes:url:
fragmentData
eventTypes
_sequenceNumber
_data
_moovFragment
_eventTypes
_url
request
analyzer
identifier
UUIDString
fragment
initWithFormat:arguments:
initWithRequest:
info:
debug:
_request
flags
initWithAssetData:error:
loadAttributesFromVideoFragment:
analysisSubmissionTime
attributes
dimensions
encoderSession
initWithGenerationFrequency:andPosterFrameHeight:
initWithInput:
startHandlingFrames
readerForVideoFragment:workQueue:logIdentifier:
maxAnalysisFPS
scheduler
initWithAnalysisFPS:logIdentifier:
startHandlingFramesFromVideoResource:fragmentSequenceNumber:frameWidth:frameHeight:
videoFrameResults
videoAnnotationScoresForFrameResult:
posterFrameGenerator
assetDuration
timeSinceAnalysisStart
timeSinceAnalysisSubmission
analysisStartTime
setFlags:
initWithVideoFragment:analyzer:maxAnalysisFPS:
shouldSkipAnalysis
shouldFailAnalysis
loadAttributes
startAnalysis
startEncodingSessionWithError:
startPosterFrameGeneratorWithInterval:frameHeight:
startAssetReaderWithWorkQueue:logIdentifier:
startFrameSelector
finishEncoderSession
makeDidAnalyzeResult
makeDidNotAnalyzeResultWithResultCode:
cancel
frameSelector
assetReader
setEvents:
setVideoFrameResults:
phase
setPhase:
_analysisSubmissionTime
_analysisStartTime
_maxAnalysisFPS
_fragment
_attributes
_encoderSession
_posterFrameGenerator
_frameSelector
_assetReader
_analyzer
_videoFrameResults
_log
_phase
_flags
alloc
weakObjectsPointerArray
memoryMonitor
setSystemResourceUsageMonitorUsageLevel:
systemResourceUsageMonitorUsageLevel
numberWithInteger:
numberPreferenceForKey:defaultValue:
thermalPIDController
currentState
isPictureInPictureActive
inFullBypassMode
intValue
averageAnalysisTimeMovingAverage
averageTotalAnalysisTimeMovingAverage
averageTotalAnalysisTime
updateAnalysisFPS:
internalAnalyzers
hmf_addObject:
assertOwner
addPointer:
compact
setCount:
_compactInternalAnalyzers
isPaused
logState
analyzers
maxConcurrentAnalyzers
setInBypassMode:
_markPendingRequestsWithFlag:
processPendingRequests
memoryState
averageAnalysisTime
pendingRequests
setZeroPadsFractionDigits:
setAllowedUnits:
setCountStyle:
stringFromByteCount:
stringByPaddingToLength:withString:startingAtIndex:
appendFormat:
_outcomeCountsAsString
mediaIntegritySequenceNumber
_flagCountsAsString
inBypassMode
inErrorState
analysisInProgress
appendString:
allObjects
systemResourceUsageDidChangeTo:
requestDidEnd:outcome:
registerAnalyzer:
removeAllAnalyzers
setPaused:
systemResourceUsageMonitor
analysisFPSPreference
_paused
_maxConcurrentAnalyzers
_internalAnalyzers
_systemResourceUsageMonitor
_systemResourceUsageMonitorUsageLevel
_memoryMonitor
_thermalPIDController
_averageAnalysisTimeMovingAverage
_averageTotalAnalysisTimeMovingAverage
_analysisFPSPreference
qosMap
_scheduleRequest:
sessionEnded
configuration
_handleError:request:
internalPendingRequests
hmf_enqueue:
setSessionEnded:
setRunRemotely:
_handleError:request:description:
skipSequentialMediaIntegrityCheck
firstSequenceNumber
nominalFrameRate
_handleDidNotAnalyzeRequest:resultCode:
_shouldContinueAnalyzingRequest:resultCode:
hmf_maybeDequeue
_analyzeRequest:
setAnalysisInProgress:
_checkRequest:
_analyzeRequestRemotely:retryOnConnectionInterruption:
_analyzeRequestLocally:
setMediaIntegritySequenceNumber:
remoteAnalysisService
preferenceOverrides
hmiSyntheticErrorFromPreference:
analyzer:didFindSignificantEvent:inFragment:
code
_handleError:request:underlyingError:
_handleDidAnalyzeRequest:withResult:
_handleDidNotAnalyzeRequest:withResult:error:
requestAnalysisForAssetData:withProperties:andCompletionHandler:
warmStartModel
_willAnalyzeRequest:
_handleError:request:description:underlyingError:
_analyzeRequestFramesLocally:
startReading:
analyzer:willAnalyzeRequest:
_sendAnalyticsEventForRequest:outcome:result:error:
_requestDidEnd:outcome:
_notifyDidAnalyzeRequest:withResult:
_handleDidNotAnalyzeRequest:resultCode:error:
_notifyDidNotAnalyzeRequest:withResult:
hmiErrorWithCode:description:
callStackSymbols
_enterErrorState
_notifyDidFailAnalysisForRequest:withError:
analyzer:didAnalyzeFragment:withResult:
analyzer:didAnalyzeRequest:withResult:
analyzer:didNotAnalyzeFragment:withResult:
analyzer:didNotAnalyzeRequest:withResult:
analyzer:didFailAnalysisForFragment:withError:
analyzer:didFailAnalysisForRequest:withError:
setInErrorState:
readNextFrame:error:
willHandleFramesFromVideoResource:
handleVideoFrame:error:
willHandleFrames
_analyzeRequestFrames:
_handleDidAnalyzeRequest:
frames
_analyzeVideoFrame:request:result:error:
sleepForTimeInterval:
analyze:targetEventTypes:error:
shouldSaveVideoFramesToDisk
_saveVideoFrame:videoFragment:error:
_analyzeFrame:request:error:
hasPrefix:
lastPathComponent
stringByDeletingPathExtension
shouldUploadVideoAnalysisEvent
numberWithFloat:
userInfo
eventConfidenceThresholdsHigh
eventConfidenceThresholdsMedium
string
bundleWithIdentifier:
infoDictionary
queryVersionInformation
initWithConfiguration:identifier:
analyzeFragment:
clearPendingFragments
pendingRequestsCount
setConfiguration:
setRemoteAnalysisService:
setSaveVideoFramesToDisk:
_flagCounts
_outcomeCounts
_skipSequentialMediaIntegrityCheck
_analysisInProgress
_inErrorState
_inBypassMode
_sessionEnded
_uploadVideoAnalysisEvent
_saveVideoFramesToDisk
_delegate
_identifier
_internalPendingRequests
_scheduler
_mediaIntegritySequenceNumber
_configuration
_remoteAnalysisService
setFrameAnalyzer:
watchdogTimer
modelTimeoutPreference
frameAnalyzer
kick
getConfidenceThresholdPreferenceForKey:defaultConfidenceThreshold:
classify:targetEventTypes:error:
_frameAnalyzer
_watchdogTimer
_labelIndex
_confidence
_boundingBox
sortedArrayUsingComparator:
setObject:forKeyedSubscript:
nonMaximumSuppression:output:withThreshold:
addObjectsFromArray:
intersectionOverUnion:b:
convertObjectDetections:cropRect:originalImageSize:output:
initWithData:timeOffset:width:height:
timeOffset
width
height
_width
_height
_timeOffset
generationFrequency
_generationFrequency
posterFramesInternal
input
nextGenerationTime
removeAllObjects
setNextGenerationTime:
saveAsPosterFrame:error:
setPosterFramesInternal:
_posterFramesInternal
_input
_nextGenerationTime
framesInternal
flowArray
opticalFlowReferenceImage
setTotalNumberOfFramesInFragment:
setFrameWidth:
setFrameHeight:
setActualAnalysisFPS:
actualAnalysisFPS
setNumberFramesToSelect:
setNumberFramesToAdvance:
setCurrentFrameNumber:
setNextFrameToSelectForAnalysis:
getEnableOpticalFlowPreference
setEnableOpticalFlow:
enableOpticalFlow
getScaledFrameWidth
getScaledFrameHeight
calculateOpticalFlowInterval:
setTargetSelectionInterval:
calculateReferenceFrameSelectionFactor
setReferenceSelectionInterval:
totalNumberOfFramesInFragment
referenceSelectionInterval
setMaxOpticalFlowCalculations:
setNumOpticalFlowCalculations:
minRows
minCols
maxRows
maxCols
connectedComponentsMap
quantizedFrames
framesScore
numberFramesToSelect
initWithCapacity:
setObject:atIndexedSubscript:
setFlowArray:
currentFrameNumber
refFrameNumber
setOpticalFlowReferenceImage:
targetSelectionInterval
setTargetFrameNumber:
setRefFrameNumber:
targetFrameNumber
numOpticalFlowCalculations
initWithCVPixelBuffer:options:
initWithTargetedCVPixelBuffer:options:
setEnableFiltering:
setFilterOcclusionWeight:
getOpticalFlowLowPriorityPreference
setMetalContextPriority:
getOpticalFlowBackgroundProcessingPreference
setPreferBackgroundProcessing:
performRequests:error:
results
computeFlowMagnitudeMatrixFromOriginal:error:
initWithMotionScore:pixelBufferUV:cropRect:
quantizedAndBinarizeFrame:frame_height:error:
connectedComponents
unionTheRegoins
allKeys
applyPaddingIndex:
valueForKeyPath:
indexOfObject:
nextFrameToSelectForAnalysis
numberFramesToAdvance
getScaleFactorWidth
getScaleFactorHeight
removeObjectForKey:
maxOpticalFlowCalculations
compare:
sortedArrayUsingSelector:
reverseObjectEnumerator
containsObject:
setFramesInternal:
setMinRows:
setMaxRows:
setMinCols:
setMaxCols:
setQuantizedFrames:
setConnectedComponentsMap:
setFramesScore:
_enableOpticalFlow
_maxOpticalFlowCalculations
_targetSelectionInterval
_referenceSelectionInterval
_numberFramesToAdvance
_nextFrameToSelectForAnalysis
_actualAnalysisFPS
_refFrameNumber
_targetFrameNumber
_numOpticalFlowCalculations
_frames
_logIdentifier
_framesInternal
_totalNumberOfFramesInFragment
_currentFrameNumber
_numberFramesToSelect
_minRows
_maxRows
_minCols
_maxCols
_flowArray
_quantizedFrames
_connectedComponentsMap
_framesScore
_opticalFlowReferenceImage
mainBundle
localizedStringForKey:value:table:
errorWithDomain:code:userInfo:
_hmiErrorWithCode:description:reason:suggestion:underlyingError:
initWithDomain:code:userInfo:
hmiErrorWithCode:underlyingError:
hmiErrorWithCode:
hmiErrorWithCode:description:underlyingError:
hmiPrivateErrorWithCode:description:underlyingError:
resourceUsageMonitor
_resourceUsageMonitor
pixelBufferUV
_motionScoreForObjectRect:
initWithCropRect:motionScore:
initWithMotionScore:
isDetectedObjectStatic:
motionScore
setPixelBufferUV:
_motionScore
_pixelBufferUV
_movingObjectCropRect
initWithAssetDuration:creationDate:firstSequenceNumber:lastSequenceNumber:
bytes
initWithAssetDuration:creationDate:firstSequenceNumber:lastSequenceNumber:nominalFrameRate:dimensions:
initWithAssetDuration:creationDate:
_firstSequenceNumber
_nominalFrameRate
_dimensions
_assetDuration
initWithVideoFragment:workQueue:logIdentifier:
assetWithURL:
resourceLoader
resourceLoaderWorkQueue
setDelegate:queue:
initWithAsset:error:
setAssetReader:
assetKeys
_propertiesLoadedForAsset:resultCallback:
loadValuesAsynchronouslyForKeys:completionHandler:
fragments
lastObject
firstObject
statusOfValueForKey:error:
_didKeyValueLoadFailed:
tracksWithMediaType:
trackKeys
_propertiesLoadedForTrack:fromAsset:resultCallback:
timeRange
initWithTrack:outputSettings:
setAlwaysCopiesSampleData:
setMaximizePowerEfficiency:
addOutput:
startReading
_validateSequentialIntegrityOfFragmentsInAsset:
_sequenceNumberOfLastFragmentInAsset:
_sequenceNumberOfFirstFragmentInAsset:
dateValue
formatDescriptions
outputs
objectAtIndex:
copyNextSampleBuffer
currentFrameId
setCurrentFrameId:
finishLoadingWithError:
contentInformationRequest
setContentLength:
setContentType:
setByteRangeAccessSupported:
dataRequest
requestedOffset
requestsAllDataToEndOfResource
requestedLength
subdataWithRange:
respondWithData:
finishLoading
resourceLoader:shouldWaitForLoadingOfRequestedResource:
resourceLoader:shouldWaitForRenewalOfRequestedResource:
resourceLoader:didCancelLoadingRequest:
resourceLoader:shouldWaitForResponseToAuthenticationChallenge:
resourceLoader:didCancelAuthenticationChallenge:
_currentFrameId
_resourceLoaderWorkQueue
decodeIntegerForKey:
decodeObjectOfClasses:forKey:
decodeObjectOfClass:forKey:
decodeCMTimeForKey:
decodeDoubleForKey:
encodeInteger:forKey:
encodeObject:forKey:
encodeCMTime:forKey:
encodeDouble:forKey:
initWithCoder:
encodeWithCoder:
supportsSecureCoding
decodeBoolForKey:
encodeBool:forKey:
isEqualToData:
decodeIntForKey:
encodeInt:forKey:
decodeFloatForKey:
encodeFloat:forKey:
_finish
didAnalyzeFragment
didFailAnalysisForFragment
didFindSignificantEvent
didNotAnalyzeFragment
setDidAnalyzeFragment:
setDidFailAnalysisForFragment:
setDidNotAnalyzeFragment:
setDidFindSignificantEvent:
_didAnalyzeFragment
_didFailAnalysisForFragment
_didFindSignificantEvent
_didNotAnalyzeFragment
mapTableWithStrongToWeakObjects
nextRequestID
setNextRequestID:
runRemotely
removeAllPreferenceOverrides
addPreferenceOverrideFromDictionary:
UUID
getNextRequestID
requests
expectedClasses
requestAnalysisForPixelBuffer:withProperties:andCompletionHandler:
cancelRequest:
_runRemotely
_nextRequestID
_requests
boolValue
preferenceOverridesInternal
addEntriesFromDictionary:
preferenceLoggedValues
initWithKey:options:domain:defaultValue:
systemPreferenceValueForKey:
logPreferenceForKey:value:
caseInsensitiveCompare:
numberPreferenceForKey:defaultValue:withParser:
valuePreferenceForKey:defaultValue:withParser:
valuePreferenceForKey:defaultValue:withMap:
hasPreferenceForKey:
stringPreferenceForKey:defaultValue:
_preferenceLoggedValues
_preferenceOverridesInternal
setNumberStyle:
numberFromString:
token
notificationName
publishValueForToken:
publishInitialValue
setToken:
callback
initWithNotificationName:andQueue:andCallback:
_token
_notificationName
_callback
stringByDeletingLastPathComponent
defaultManager
createDirectoryAtPath:withIntermediateDirectories:attributes:error:
imageWithCVImageBuffer:
pathExtension
writePNGRepresentationOfImage:toURL:format:colorSpace:options:error:
writeJPEGRepresentationOfImage:toURL:colorSpace:options:error:
classHierarchyMap
enumerateKeysAndObjectsUsingBlock:
_confidenceScoreOverrideForEventType:
significantActivityDetector
arrayWithArray:
_addSimulatedDetectionForEventType:targetEventTypes:events:annotationScores:detections:
transaction
setTransaction:
_significantActivityDetector
_transaction
initWithImage__Placeholder__0:
image__Placeholder__0
setImage__Placeholder__0:
_image__Placeholder__0
featureValueWithMultiArray:
initWithShotNet__ShotNet__ssd_predictions__block8_box__class_prob__0:ShotNet__ShotNet__ssd_predictions__block8_box__box_offset__0:ShotNet__ShotNet__ssd_predictions__block7_box__class_prob__0:ShotNet__ShotNet__ssd_predictions__block7_box__box_offset__0:ShotNet__ShotNet__ssd_predictions__block6_box__class_prob__0:ShotNet__ShotNet__ssd_predictions__block6_box__box_offset__0:ShotNet__ShotNet__ssd_predictions__block9_box__class_prob__0:ShotNet__ShotNet__ssd_predictions__block9_box__box_offset__0:ShotNet__ShotNet__ssd_predictions__block10_box__class_prob__0:ShotNet__ShotNet__ssd_predictions__block10_box__box_offset__0:ShotNet__ShotNet__ssd_predictions__block11_box__class_prob__0:ShotNet__ShotNet__ssd_predictions__block11_box__box_offset__0:
ShotNet__ShotNet__ssd_predictions__block8_box__class_prob__0
setShotNet__ShotNet__ssd_predictions__block8_box__class_prob__0:
ShotNet__ShotNet__ssd_predictions__block8_box__box_offset__0
setShotNet__ShotNet__ssd_predictions__block8_box__box_offset__0:
ShotNet__ShotNet__ssd_predictions__block7_box__class_prob__0
setShotNet__ShotNet__ssd_predictions__block7_box__class_prob__0:
ShotNet__ShotNet__ssd_predictions__block7_box__box_offset__0
setShotNet__ShotNet__ssd_predictions__block7_box__box_offset__0:
ShotNet__ShotNet__ssd_predictions__block6_box__class_prob__0
setShotNet__ShotNet__ssd_predictions__block6_box__class_prob__0:
ShotNet__ShotNet__ssd_predictions__block6_box__box_offset__0
setShotNet__ShotNet__ssd_predictions__block6_box__box_offset__0:
ShotNet__ShotNet__ssd_predictions__block9_box__class_prob__0
setShotNet__ShotNet__ssd_predictions__block9_box__class_prob__0:
ShotNet__ShotNet__ssd_predictions__block9_box__box_offset__0
setShotNet__ShotNet__ssd_predictions__block9_box__box_offset__0:
ShotNet__ShotNet__ssd_predictions__block10_box__class_prob__0
setShotNet__ShotNet__ssd_predictions__block10_box__class_prob__0:
ShotNet__ShotNet__ssd_predictions__block10_box__box_offset__0
setShotNet__ShotNet__ssd_predictions__block10_box__box_offset__0:
ShotNet__ShotNet__ssd_predictions__block11_box__class_prob__0
setShotNet__ShotNet__ssd_predictions__block11_box__class_prob__0:
ShotNet__ShotNet__ssd_predictions__block11_box__box_offset__0
setShotNet__ShotNet__ssd_predictions__block11_box__box_offset__0:
_ShotNet__ShotNet__ssd_predictions__block8_box__class_prob__0
_ShotNet__ShotNet__ssd_predictions__block8_box__box_offset__0
_ShotNet__ShotNet__ssd_predictions__block7_box__class_prob__0
_ShotNet__ShotNet__ssd_predictions__block7_box__box_offset__0
_ShotNet__ShotNet__ssd_predictions__block6_box__class_prob__0
_ShotNet__ShotNet__ssd_predictions__block6_box__box_offset__0
_ShotNet__ShotNet__ssd_predictions__block9_box__class_prob__0
_ShotNet__ShotNet__ssd_predictions__block9_box__box_offset__0
_ShotNet__ShotNet__ssd_predictions__block10_box__class_prob__0
_ShotNet__ShotNet__ssd_predictions__block10_box__box_offset__0
_ShotNet__ShotNet__ssd_predictions__block11_box__class_prob__0
_ShotNet__ShotNet__ssd_predictions__block11_box__box_offset__0
urlOfModelInThisBundle
initWithContentsOfURL:error:
modelWithContentsOfURL:error:
initWithContentsOfURL:configuration:error:
predictionFromFeatures:error:
initWithFeatureProviderArray:
predictionsFromBatch:options:error:
featuresAtIndex:
initWithConfiguration:error:
predictionFromImage__Placeholder__0:error:
predictionsFromInputs:options:error:
model
_model
@24@0:8@16
@16@0:8
@"MLFeatureValue"24@0:8@"NSString"16
@"NSSet"16@0:8
@32@0:8^{__CVBuffer=}16@24
v16@0:8
^{__CVBuffer=}16@0:8
^{__CVBuffer=}
@"NSString"
B24@0:8@16
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B16@0:8
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
@"HMFLogCategory"16@0:8
@40@0:8@16d24^@32
B40@0:8^{__CVBuffer=}16@24^@32
B48@0:8^{__CVBuffer=}16@24@32^@40
v40@0:8@16@24@32
{CGSize=dd}16@0:8
d16@0:8
[91d]
[6[6{CGSize="width"d"height"d}]]
[6Q]
@"MLModel"
@"NSArray"
@"MLPredictionOptions"
{CGSize="width"d"height"d}
v32@0:8@16@24
v32@0:8@"AVAssetWriter"16@"NSData"24
v40@0:8@"AVAssetWriter"16@"NSData"24@"AVFragmentedMediaDataReport"32
@40@0:8i16i20I24B28^@32
i16@0:8
v20@0:8i16
B48@0:8^{__CVBuffer=}16{?=qiIq}24
v24@0:8@?16
^{OpaqueVTCompressionSession=}16@0:8
^{OpaqueVTCompressionSession=}
@"AVAssetWriter"
@"AVAssetWriterInput"
@"NSMutableData"
@"HMFActivity"
q16@0:8
v24@0:8q16
v24@0:8@16
@"HMISystemResourceUsage"16@0:8
@"<HMISystemResourceUsageMonitorDelegate>"16@0:8
v24@0:8@"<HMISystemResourceUsageMonitorDelegate>"16
@"HMISystemResourceUsageMonitorImpl"
@"NSObject<OS_dispatch_queue>"
@24@0:8^{__CVBuffer=}16
@64@0:8^{__CVBuffer=}16{?=qiIq}24Q48Q56
@80@0:8@16{?=qiIq}24Q48Q56{CGSize=dd}64
@28@0:8f16^{CGSize=dd}20
B40@0:8{CGSize=dd}16^@32
{?=qiIq}16@0:8
@"NSData"
@"HMICameraVideoFrameMotionAnalysisResult"
{?="value"q"timescale"i"flags"I"epoch"q}
^{__CVBuffer=}64@0:8^{__CVBuffer=}16{CGRect={CGPoint=dd}{CGSize=dd}}24^@56
^{__CVBuffer=}48@0:8^{__CVBuffer=}16{CGSize=dd}24^@40
^{__CVBuffer=}80@0:8^{__CVBuffer=}16{CGRect={CGPoint=dd}{CGSize=dd}}24{CGSize=dd}56^@72
i40@0:8Q16Q24^^{__CVBuffer}32
@24@0:8^{__IOHIDServiceClient=}16
^{__IOHIDServiceClient=}
B28@0:8i16^d20
B24@0:8^d16
^{__IOHIDEventSystemClient=}
@"NSMutableDictionary"
@"HMFUnfairLock"
v24@0:8@"HMFTimer"16
v20@0:8f16
@"HMFTimer"
@"NSNumber"
@"NSDate"
@24@0:8Q16
d32@0:8d16d24
v24@0:8d16
@"NSMutableArray"
@96@0:8q16@24@32@40{?=qiIq}48@72q80Q88
q24@0:8q16
B28@0:8@16B24
v40@0:8{?=qiIq}16
f16@0:8
@"NSDictionary"
@"HMICameraVideoFragment"
@24@0:8^{_NSZone=}16
@48@0:8Q16Q24d32d40
v24@0:8Q16
v20@0:8B16
@40@0:8q16@24@32
@"HMICameraVideoFrame"
@64@0:8Q16q24@32@40Q48Q56
@40@0:8Q16@24@32
@48@0:8Q16@24@32q40
@40@0:8Q16@24q32
@48@0:8Q16@24q32@40
@"NSURL"
@"HMICameraVideoAnalyzerRequest"
@40@0:8@16@24d32
B24@0:8^@16
B32@0:8Q16Q24
B32@0:8@16@24
@24@0:8q16
@"HMICameraVideoResourceAttributes"
@"HMICameraVideoEncoderSession"
@"HMICameraVideoPosterFrameGenerator"
@"HMICameraVideoFrameSelector"
@"HMICameraVideoAssetReader"
@"HMICameraVideoAnalyzer"
@"HMICameraVideoAnalyzerRequestLog"
v32@0:8@16q24
@"NSPointerArray"
@"HMISystemResourceUsageMonitor"
@"HMFMemoryMonitor"
@"HMIPIDController"
@"MovingAverage"
q40@0:8q16q24@32
@32@0:8@16@24
v28@0:8@16B24
v40@0:8@16q24@32
v32@0:8q16@24
v40@0:8q16@24@32
v48@0:8q16@24@32@40
B32@0:8@16^q24
@40@0:8@16@24^@32
B48@0:8@16@24^@32^@40
B40@0:8@16@24^@32
v48@0:8@16q24@32@40
[6i]
[3i]
@"<HMICameraVideoAnalyzerDelegate>"
@"NSUUID"
@"HMICameraVideoAnalyzerScheduler"
@"HMICameraVideoAnalyzerConfiguration"
@"HMIAnalysisService"
@40@0:8@16q24^@32
@32@0:8@16d24
@"<HMICameraVideoFrameAnalyzer>"
@60@0:8i16d20{CGRect={CGPoint=dd}{CGSize=dd}}28
{CGRect={CGPoint=dd}{CGSize=dd}}16@0:8
{CGRect="origin"{CGPoint="x"d"y"d}"size"{CGSize="width"d"height"d}}
f80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48
v40@0:8@16@24d32
v80@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24{CGSize=dd}56@72
@64@0:8@16{?=qiIq}24Q48Q56
@48@0:8{?=qiIq}16Q40
B32@0:8@16^@24
@"HMICameraVideoPosterFrameGeneratorInput"
@32@0:8d16@24
v48@0:8@16Q24Q32Q40
f32@0:8^{__CVBuffer=}16^@24
{CGRect={CGPoint=dd}{CGSize=dd}}24@0:8@16
B40@0:8Q16Q24^@32
i20@0:8f16
^f16@0:8
v24@0:8^f16
v24@0:8^{__CVBuffer=}16
@56@0:8Q16@24@32@40@48
@32@0:8q16@24
@"<HMISystemResourceUsageMonitorDelegate>"
@"<HMISystemResourceUsageMonitorProtocol>"
@52@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16f48
@20@0:8f16
@60@0:8f16^{__CVBuffer=}20{CGRect={CGPoint=dd}{CGSize=dd}}28
f48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
@64@0:8{?=qiIq}16@40Q48Q56
@48@0:8{?=qiIq}16@40
@88@0:8{?=qiIq}16@40Q48Q56d64{CGSize=dd}72
@32@0:8@16^@24
@40@0:8@16@24@32
B32@0:8@"AVAssetResourceLoader"16@"AVAssetResourceLoadingRequest"24
B32@0:8@"AVAssetResourceLoader"16@"AVAssetResourceRenewalRequest"24
v32@0:8@"AVAssetResourceLoader"16@"AVAssetResourceLoadingRequest"24
B32@0:8@"AVAssetResourceLoader"16@"NSURLAuthenticationChallenge"24
v32@0:8@"AVAssetResourceLoader"16@"NSURLAuthenticationChallenge"24
Q24@0:8@16
v32@0:8@16@?24
v40@0:8@16@24@?32
B32@0:8^@16^@24
@"AVAssetReader"
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
v40@0:8@"HMICameraVideoAnalyzer"16@"HMICameraVideoFragment"24@"HMICameraVideoAnalyzerResult"32
v40@0:8@"HMICameraVideoAnalyzer"16@"HMICameraVideoAnalyzerSignificantEvent"24@"HMICameraVideoFragment"32
v40@0:8@"HMICameraVideoAnalyzer"16@"HMICameraVideoFragment"24@"NSError"32
@?16@0:8
i40@0:8^{__CVBuffer=}16@24@?32
i40@0:8@16@24@?32
B20@0:8i16
@"NSMapTable"
@40@0:8@16@24@?32
@40@0:8r*16@24@?32
r*16@0:8
@40@0:8^{NSDictionary=#}16d24^@32
@"HMICameraVideoFrameResult"40@0:8@"HMICameraVideoFrame"16q24^@32
@"NSDictionary"16@0:8
d24@0:8q16
v56@0:8q16q24^q32@40@48
@"HMISignificantActivityDetector"
@"HMFOSTransaction"
@112@0:8@16@24@32@40@48@56@64@72@80@88@96@104
@"MLMultiArray"
@32@0:8^{__CVBuffer=}16^@24
