UsesIOSurface
HardwareAcceleratedTransfer
HighSpeedTransfer
HMIPixelBufferTransferMultiStageResize
?a0cTa1cTa2cTa3cTa0hTa1hTa2hTa3hT
Motion
Person
Vehicle
sFXg@
+Sg@
?>Ip
?(-_U
=$@'
hp|i1
f?94{W
A`~q@
#>m?
?>Ip
iUK:
\.@;&b|^
hp|i1
333333
@(#)PROGRAM:HomeAI  PROJECT:HomeAI-75.2.18
N2cv5MatOpE
N2cv14MatOp_IdentityE
N2cv11MatOp_AddExE
N2cv9MatOp_BinE
N2cv9MatOp_CmpE
N2cv10MatOp_GEMME
N2cv12MatOp_InvertE
N2cv7MatOp_TE
N2cv11MatOp_SolveE
N2cv17MatOp_InitializerE
 !"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\]^_`abcdefghijklmnopqrstuvwxyz{|}~
 !"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\]^_`abcdefghijklmnopqrstuvwxyz{|}~
p?ucwsifdr
N2cv16MorphologyRunnerE
N2cv14MorphRowFilterINS_5MinOpIhEENS_12MorphRowIVecINS_6VMin8uEEEEE
N2cv14MorphRowFilterINS_5MinOpItEENS_12MorphRowIVecINS_7VMin16uEEEEE
N2cv14MorphRowFilterINS_5MinOpIsEENS_12MorphRowIVecINS_7VMin16sEEEEE
N2cv14MorphRowFilterINS_5MinOpIfEENS_12MorphRowFVecINS_7VMin32fEEEEE
N2cv14MorphRowFilterINS_5MinOpIdEENS_13MorphRowNoVecEEE
N2cv14MorphRowFilterINS_5MaxOpIhEENS_12MorphRowIVecINS_6VMax8uEEEEE
N2cv14MorphRowFilterINS_5MaxOpItEENS_12MorphRowIVecINS_7VMax16uEEEEE
N2cv14MorphRowFilterINS_5MaxOpIsEENS_12MorphRowIVecINS_7VMax16sEEEEE
N2cv14MorphRowFilterINS_5MaxOpIfEENS_12MorphRowFVecINS_7VMax32fEEEEE
N2cv14MorphRowFilterINS_5MaxOpIdEENS_13MorphRowNoVecEEE
N2cv17MorphColumnFilterINS_5MinOpIhEENS_15MorphColumnIVecINS_6VMin8uEEEEE
N2cv17MorphColumnFilterINS_5MinOpItEENS_15MorphColumnIVecINS_7VMin16uEEEEE
N2cv17MorphColumnFilterINS_5MinOpIsEENS_15MorphColumnIVecINS_7VMin16sEEEEE
N2cv17MorphColumnFilterINS_5MinOpIfEENS_15MorphColumnFVecINS_7VMin32fEEEEE
N2cv17MorphColumnFilterINS_5MinOpIdEENS_16MorphColumnNoVecEEE
N2cv17MorphColumnFilterINS_5MaxOpIhEENS_15MorphColumnIVecINS_6VMax8uEEEEE
N2cv17MorphColumnFilterINS_5MaxOpItEENS_15MorphColumnIVecINS_7VMax16uEEEEE
N2cv17MorphColumnFilterINS_5MaxOpIsEENS_15MorphColumnIVecINS_7VMax16sEEEEE
N2cv17MorphColumnFilterINS_5MaxOpIfEENS_15MorphColumnFVecINS_7VMax32fEEEEE
N2cv17MorphColumnFilterINS_5MaxOpIdEENS_16MorphColumnNoVecEEE
N2cv11MorphFilterINS_5MinOpIhEENS_9MorphIVecINS_6VMin8uEEEEE
N2cv11MorphFilterINS_5MinOpItEENS_9MorphIVecINS_7VMin16uEEEEE
N2cv11MorphFilterINS_5MinOpIsEENS_9MorphIVecINS_7VMin16sEEEEE
N2cv11MorphFilterINS_5MinOpIfEENS_9MorphFVecINS_7VMin32fEEEEE
N2cv11MorphFilterINS_5MinOpIdEENS_10MorphNoVecEEE
N2cv11MorphFilterINS_5MaxOpIhEENS_9MorphIVecINS_6VMax8uEEEEE
N2cv11MorphFilterINS_5MaxOpItEENS_9MorphIVecINS_7VMax16uEEEEE
N2cv11MorphFilterINS_5MaxOpIsEENS_9MorphIVecINS_7VMax16sEEEEE
N2cv11MorphFilterINS_5MaxOpIfEENS_9MorphFVecINS_7VMax32fEEEEE
N2cv11MorphFilterINS_5MaxOpIdEENS_10MorphNoVecEEE
N2cv9ExceptionE
N2cv6detail16LKTrackerInvokerE
N2cv15ThresholdRunnerE
14EmptyFuncTable
12GpuFuncTable
N2cv13BaseRowFilterE
N2cv16BaseColumnFilterE
N2cv10BaseFilterE
N2cv12FilterEngineE
N2cv18SymmRowSmallFilterIhiNS_21SymmRowSmallVec_8u32sEEE
N2cv9RowFilterIhiNS_21SymmRowSmallVec_8u32sEEE
N2cv18SymmRowSmallFilterIffNS_19SymmRowSmallVec_32fEEE
N2cv9RowFilterIffNS_19SymmRowSmallVec_32fEEE
N2cv9RowFilterIhiNS_12RowVec_8u32sEEE
N2cv9RowFilterIhfNS_8RowNoVecEEE
N2cv9RowFilterIhdNS_8RowNoVecEEE
N2cv9RowFilterItfNS_8RowNoVecEEE
N2cv9RowFilterItdNS_8RowNoVecEEE
N2cv9RowFilterIsfNS_13RowVec_16s32fEEE
N2cv9RowFilterIsdNS_8RowNoVecEEE
N2cv9RowFilterIffNS_10RowVec_32fEEE
N2cv9RowFilterIfdNS_8RowNoVecEEE
N2cv9RowFilterIddNS_8RowNoVecEEE
N2cv12ColumnFilterINS_13FixedPtCastExIihEENS_11ColumnNoVecEEE
N2cv12ColumnFilterINS_4CastIfhEENS_11ColumnNoVecEEE
N2cv12ColumnFilterINS_4CastIdhEENS_11ColumnNoVecEEE
N2cv12ColumnFilterINS_4CastIftEENS_11ColumnNoVecEEE
N2cv12ColumnFilterINS_4CastIdtEENS_11ColumnNoVecEEE
N2cv12ColumnFilterINS_4CastIfsEENS_11ColumnNoVecEEE
N2cv12ColumnFilterINS_4CastIdsEENS_11ColumnNoVecEEE
N2cv12ColumnFilterINS_4CastIffEENS_11ColumnNoVecEEE
N2cv12ColumnFilterINS_4CastIddEENS_11ColumnNoVecEEE
N2cv21SymmColumnSmallFilterINS_13FixedPtCastExIihEENS_19SymmColumnVec_32s8uEEE
N2cv16SymmColumnFilterINS_13FixedPtCastExIihEENS_19SymmColumnVec_32s8uEEE
N2cv12ColumnFilterINS_13FixedPtCastExIihEENS_19SymmColumnVec_32s8uEEE
N2cv21SymmColumnSmallFilterINS_4CastIisEENS_25SymmColumnSmallVec_32s16sEEE
N2cv16SymmColumnFilterINS_4CastIisEENS_25SymmColumnSmallVec_32s16sEEE
N2cv12ColumnFilterINS_4CastIisEENS_25SymmColumnSmallVec_32s16sEEE
N2cv21SymmColumnSmallFilterINS_4CastIffEENS_22SymmColumnSmallVec_32fEEE
N2cv16SymmColumnFilterINS_4CastIffEENS_22SymmColumnSmallVec_32fEEE
N2cv12ColumnFilterINS_4CastIffEENS_22SymmColumnSmallVec_32fEEE
N2cv16SymmColumnFilterINS_4CastIfhEENS_11ColumnNoVecEEE
N2cv16SymmColumnFilterINS_4CastIdhEENS_11ColumnNoVecEEE
N2cv16SymmColumnFilterINS_4CastIftEENS_11ColumnNoVecEEE
N2cv16SymmColumnFilterINS_4CastIdtEENS_11ColumnNoVecEEE
N2cv16SymmColumnFilterINS_4CastIisEENS_11ColumnNoVecEEE
N2cv12ColumnFilterINS_4CastIisEENS_11ColumnNoVecEEE
N2cv16SymmColumnFilterINS_4CastIfsEENS_20SymmColumnVec_32f16sEEE
N2cv12ColumnFilterINS_4CastIfsEENS_20SymmColumnVec_32f16sEEE
N2cv16SymmColumnFilterINS_4CastIdsEENS_11ColumnNoVecEEE
N2cv16SymmColumnFilterINS_4CastIffEENS_17SymmColumnVec_32fEEE
N2cv12ColumnFilterINS_4CastIffEENS_17SymmColumnVec_32fEEE
N2cv16SymmColumnFilterINS_4CastIddEENS_11ColumnNoVecEEE
@@N2cv9ColumnSumIihEE
N2cv9ColumnSumIitEE
N2cv9ColumnSumIisEE
N2cv6RowSumIhiEE
N2cv6RowSumIhdEE
N2cv6RowSumItiEE
N2cv6RowSumItdEE
N2cv6RowSumIsiEE
N2cv6RowSumIiiEE
N2cv6RowSumIsdEE
N2cv6RowSumIfdEE
N2cv6RowSumIddEE
N2cv9ColumnSumIdhEE
N2cv9ColumnSumIdtEE
N2cv9ColumnSumIdsEE
N2cv9ColumnSumIiiEE
N2cv9ColumnSumIifEE
N2cv9ColumnSumIdfEE
N2cv9ColumnSumIidEE
N2cv9ColumnSumIddEE
N2cv16ParallelLoopBodyE
@N2cv11_InputArrayE
N2cv12_OutputArrayE
featureNames
T@"NSSet",R,N
pixelBuffer
T^{__CVBuffer=},R,V_pixelBuffer
inputName
T@"NSString",R,V_inputName
SignificantActivity
mlmodelc
image__Placeholder__0
ShotNet__ShotNet__ssd_predictions__block8_box__box_offset__0
ShotNet__ShotNet__ssd_predictions__block7_box__box_offset__0
ShotNet__ShotNet__ssd_predictions__block6_box__box_offset__0
ShotNet__ShotNet__ssd_predictions__block9_box__box_offset__0
ShotNet__ShotNet__ssd_predictions__block10_box__box_offset__0
ShotNet__ShotNet__ssd_predictions__block11_box__box_offset__0
ShotNet__ShotNet__ssd_predictions__block8_box__class_prob__0
ShotNet__ShotNet__ssd_predictions__block7_box__class_prob__0
ShotNet__ShotNet__ssd_predictions__block6_box__class_prob__0
ShotNet__ShotNet__ssd_predictions__block9_box__class_prob__0
ShotNet__ShotNet__ssd_predictions__block10_box__class_prob__0
ShotNet__ShotNet__ssd_predictions__block11_box__class_prob__0
CoreML output nil or not of type MLFeatureTypeMultiArray
significant.activity.detector
hash
TQ,R
superclass
T#,R
description
T@"NSString",R,C
debugDescription
mlModel
T@"MLModel",R,V_mlModel
inputFeatureValueName
T@"NSString",R,V_inputFeatureValueName
offsetsFeatureValueNames
T@"NSArray",R,V_offsetsFeatureValueNames
scoresFeatureValueNames
T@"NSArray",R,V_scoresFeatureValueNames
nmsThreshold
Td,R,V_nmsThreshold
useSoftmax
TB,R,V_useSoftmax
predictionOptions
T@"MLPredictionOptions",R,V_predictionOptions
inputDimensions
T{CGSize=dd},R,V_inputDimensions
camera.video.encoder.session
com.apple.videotoolbox.videoencoder.h264.rtvc
HMICameraVideoEncoderSession
Asset writer can't keep up with compression session output, skipping frame
v24@?0i8I12^{opaqueCMSampleBuffer=}16
v8@?0
session
T^{OpaqueVTCompressionSession=},R,V_session
assetWriter
T@"AVAssetWriter",R,V_assetWriter
assetWriterInput
T@"AVAssetWriterInput",R,V_assetWriterInput
encodedAssetData
T@"NSMutableData",R,V_encodedAssetData
activity
T@"HMFActivity",R,V_activity
bitRate
HMISystemResourceUsageLevelLow
HMISystemResourceUsageLevelMed
HMISystemResourceUsageLevelHigh
HMISystemResourceUsageLevelUnknown
HMISystemResourceUsageLevelUndefined
systemResourceUsageLevel
Tq,N,V_systemResourceUsageLevel
delegate
T@"<HMISystemResourceUsageMonitorDelegate>",W
systemResourceUsageMonitorImpl
T@"HMISystemResourceUsageMonitorImpl",R,V_systemResourceUsageMonitorImpl
workQueue
T@"NSObject<OS_dispatch_queue>",R,V_workQueue
JPEGRepresentation
Frame %lu @ %@
camera.video.frame
jpegData
T@"NSData",R,V_jpegData
motionDetections
T@"NSArray",&,V_motionDetections
presentationTime
T{?=qiIq},R,V_presentationTime
size
T{CGSize=dd},R,V_size
frameId
TQ,R,V_frameId
fragmentSequenceNumber
TQ,R,V_fragmentSequenceNumber
Logi Circle 2
%#{flags}
transferPixelBuffer
VTPixelTransferSessionCreate failed. Error %d
VTSessionSetProperty failed. Error %d
VTPixelTransferSessionTransferImage failed. Error %d
Using 720p params for dewarping
Using 1080p params for dewarping
300p skipping dewarp params
vision.utilities
services
T@"NSMutableDictionary",R,V_services
lock
T@"HMFUnfairLock",R,N,V_lock
intMin
intMax
target
engageDelta
sharedInstance
T@"HMIPIDController",R
tick
T@"HMFTimer",R,V_tick
controlEffort
Tq,R,V_controlEffort
Footprint: %@, Average: %@, Peak: %@
OutOfMemory
Reached high water mark.
memory.sampler
average
T@"MovingAverage",R,V_average
highWaterMark
Tq,V_highWaterMark
Invalid parameter not satisfying: %@
PrimaryUsagePage
PrimaryUsage
LocationID
value
T@"NSNumber",R,V_value
date
T@"NSDate",R,V_date
Invalid parameter for windowSize: %lu, windowSize must be > 0
v16@?0@"MovingAverageEntry"8
queue
T@"NSMutableArray",&,N,V_queue
windowSize
TQ,R,N,V_windowSize
movingAverage
Td,V_movingAverage
HKD://
analyzed-video-frames
Success
SystemResourceUsageHigh
InsufficentTime
AnyMotion
SkippedAnalysis
None
Medium
High
DidAnalyze
DidNotAnalyze
DidFailAnalysis
Canceled
Bypassed
Expired
SessionEnded
InErrorState
Predict
duration
T{?=qiIq},V_duration
creationDate
T@"NSDate",&,V_creationDate
lastSequenceNumber
TQ,R,V_lastSequenceNumber
events
Tq,R,V_events
annotationScores
T@"NSDictionary",R,V_annotationScores
posterFrames
T@"NSArray",R,V_posterFrames
frameResults
T@"NSArray",R,V_frameResults
resultCode
Tq,V_resultCode
timeToAnalyzeFragment
Td,V_timeToAnalyzeFragment
timeSinceFragmentWasSubmitted
Td,V_timeSinceFragmentWasSubmitted
videoFragment
T@"HMICameraVideoFragment",&,V_videoFragment
analysisFPS
Tf,V_analysisFPS
local
remote-fragment
serviceType
TQ,V_serviceType
startingMediaIntegritySequenceNumber
TQ,V_startingMediaIntegritySequenceNumber
transcodeFragment
TB,V_transcodeFragment
useScheduler
TB,V_useScheduler
inMediaAnalysis
TB,V_inMediaAnalysis
posterFrameGenerationInterval
TQ,R,V_posterFrameGenerationInterval
posterFrameHeight
TQ,R,V_posterFrameHeight
maxFragmentAnalysisDuration
Td,R,V_maxFragmentAnalysisDuration
maxFragmentDuration
Td,R,V_maxFragmentDuration
videoFrame
T@"HMICameraVideoFrame",R,V_videoFrame
detections
T@"NSArray",R,V_detections
frameWidth
TQ,R,V_frameWidth
frameHeight
TQ,R,V_frameHeight
regionOfInterest
T{CGRect={CGPoint=dd}{CGSize=dd}},R,V_regionOfInterest
fragment/%lu
fragmentData
T@"NSMutableData",R
T@"NSURL",&,N,V_url
sequenceNumber
TQ,R,V_sequenceNumber
T@"NSData",R,V_data
moovFragment
T@"NSData",R,N,V_moovFragment
eventTypes
Tq,R,V_eventTypes
[%@] (%lu) repetitions: %lu/%lu/%lu predictions: %lu/%lu/%lu analyzers: %lu lastEvents: %@ shouldPredict: %@
camera.video.analyzer.history
predictions
Tq,V_predictions
repetitions
Tq,V_repetitions
totalPredictions
Tq,V_totalPredictions
totalRepetitions
Tq,V_totalRepetitions
totalRequests
Tq,V_totalRequests
lastRequestResult
T@"HMICameraVideoAnalyzerResult",&,V_lastRequestResult
lastRequestSignificantEvents
T@"NSArray",&,V_lastRequestSignificantEvents
analyzer
T@"HMICameraVideoAnalyzer",R,W,V_analyzer
minRepetitions
Tq,R,V_minRepetitions
maxPredictions
Tq,R,V_maxPredictions
[%@] [Fragment:%lu] %@
camera.video.analyzer.request
request
T@"HMICameraVideoAnalyzerRequest",R,W,V_request
Start analysis, elapsed time since submission: %fs
v24@?0@"NSData"8@"NSError"16
significantEventsInternal
T@"NSMutableArray",R,V_significantEventsInternal
T@"HMICameraVideoAnalyzerRequestLog",R,V_log
phase
Tq,V_phase
flag
Tq,V_flag
analysisSubmissionTime
T@"NSDate",R,V_analysisSubmissionTime
timeSinceAnalysisSubmission
Td,R
analysisStartTime
T@"NSDate",R,V_analysisStartTime
timeSinceAnalysisStart
maxAnalysisFPS
Td,R,V_maxAnalysisFPS
Td,R,V_analysisFPS
fragment
T@"HMICameraVideoFragment",R,V_fragment
attributes
T@"HMICameraVideoResourceAttributes",R,V_attributes
encoderSession
T@"HMICameraVideoEncoderSession",R,V_encoderSession
posterFrameGenerator
T@"HMICameraVideoPosterFrameGenerator",R,V_posterFrameGenerator
frameSelector
T@"HMICameraVideoFrameSelector",R,V_frameSelector
assetReader
T@"HMICameraVideoAssetReader",R,V_assetReader
T@"HMICameraVideoAnalyzer",R,V_analyzer
Tq,V_events
videoFrameResults
T@"NSMutableArray",&,V_videoFrameResults
significantEvents
T@"NSArray",R
shouldSkipAnalysis
TB,R
shouldFailAnalysis
HMICameraVideoAnalyzerScheduler
HIGH
Normal
Warning
Critical
Unknown
Undefined
analysisTime: %.2f (%.2f), total: %.2f (%.2f), level: %@, memory: %@, availableSystemMemory: %@, temp: %.2f, controlEffort: %lu, analysisFPS: %.2f, analyzers: %lu, activeAnalyzers: %lu, maxAnalyzers: %lu
v16@?0@"HMICameraVideoAnalyzerRequest"8
[%@] [A:%d]
 %@ [%lu,%lu] %@
camera.video.analyzer.scheduler
internalAnalyzers
T@"NSPointerArray",R,V_internalAnalyzers
systemResourceUsageMonitor
T@"HMISystemResourceUsageMonitor",R,V_systemResourceUsageMonitor
systemResourceUsageMonitorUsageLevel
Tq,V_systemResourceUsageMonitorUsageLevel
thermalPIDController
T@"HMIPIDController",R,V_thermalPIDController
averageAnalysisTime
averageAnalysisTimeMovingAverage
T@"MovingAverage",R,V_averageAnalysisTimeMovingAverage
averageTotalAnalysisTime
averageTotalAnalysisTimeMovingAverage
T@"MovingAverage",R,V_averageTotalAnalysisTimeMovingAverage
analysisFPSPreference
Td,R,V_analysisFPSPreference
Tq,R
paused
TB,GisPaused,V_paused
analyzers
maxConcurrentAnalyzers
TQ,R,V_maxConcurrentAnalyzers
activeAnalyzerCount
HMICameraVideoAnalyzer
Video fragment duration: %fs is greater than expected value: %fs
Video fragment sequence number: %lu is not equal to expected value: %lu
Video fragment has no frames
XPC connection was interrupted, retrying.
Unknown delegate name: %@
v24@?0@"NSDictionary"8@"NSError"16
Failed to start reading of the asset: %@
v24@?0@"HMICameraVideoResourceAttributes"8@"NSError"16
End analysis: didAnalyze, significant events detected: %@
Transcoded, bytes: %lu (%f)
End analysis, time spent: %fs, elapsed time since submission: %fs, predicted: %@
Stopping analysis due to high system resource usage
Stopping analysis due to cancelling
Stopping analysis due to entering full bypass mode
Stopping analysis due to analysis time past the maximum fragment analysis time: %fs
Finished early @ %@
Frame selector produced 0 frames
Analyzed frame:%lu, SignificantEvents:%@
%@-%06d.%@
%@/%@/%@
[Fragment:%lu] Failed to save the video frame jpeg %lu error: %@
[Fragment:%lu] Saving video frame %lu
outcome
sessionId
framesAnalyzedFragment
error
underlyingError
personScore
personConfidence
petScore
petConfidence
vehicleScore
vehicleConfidence
Uploading analytics event %@
com.apple.HomeKit.VideoAnalyzerStats
@"NSMutableDictionary"8@?0
com.apple.HomeAI
homeai: %@
camera.video.analyzer
internalPendingRequests
T@"NSMutableArray",R,V_internalPendingRequests
lastRequestSubmissionTime
T@"NSDate",&,V_lastRequestSubmissionTime
history
T@"HMICameraVideoAnalyzerHistory",R,V_history
scheduler
T@"HMICameraVideoAnalyzerScheduler",R,V_scheduler
mediaIntegritySequenceNumber
TQ,V_mediaIntegritySequenceNumber
skipSequentialMediaIntegrityCheck
TB,R,V_skipSequentialMediaIntegrityCheck
analysisInProgress
TB,V_analysisInProgress
inErrorState
TB,V_inErrorState
inBypassMode
TB,V_inBypassMode
configuration
T@"HMICameraVideoAnalyzerConfiguration",&,V_configuration
remoteAnalysisService
T@"HMIAnalysisService",&,N,V_remoteAnalysisService
sessionEnded
TB,V_sessionEnded
uploadVideoAnalysisEvent
TB,R,GshouldUploadVideoAnalysisEvent,V_uploadVideoAnalysisEvent
saveVideoFramesToDisk
TB,GshouldSaveVideoFramesToDisk,V_saveVideoFramesToDisk
pendingRequests
isActive
T@"<HMICameraVideoAnalyzerDelegate>",W,V_delegate
identifier
T@"NSUUID",R,C,V_identifier
Initializing HMICameraVideoFrameAnalyzerFactory
Resetting VideoFrameAnalyzer
Warm starting model...
warm_start_model
Failed to create pixel buffer when warm starting model
Failed to warm start model: %@
Warm start of model took: %f
Analyze Frame
camera.video.frame.analyzer.factory
T@"HMICameraVideoFrameAnalyzerFactory",R
frameAnalyzer
T@"<HMICameraVideoFrameAnalyzer>",&,N,V_frameAnalyzer
watchdogTimer
T@"HMFTimer",R,V_watchdogTimer
Label:%d Confidence:%f X:%f Y:%f Width:%f Height:%f}
labelIndex
Ti,R,V_labelIndex
confidence
Td,R,V_confidence
boundingBox
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,V_boundingBox
q24@?0@"HMIObjectDetection"8@"HMIObjectDetection"16
@16@?0@"HMIObjectDetection"8
timeOffset
T{?=qiIq},R,V_timeOffset
width
TQ,R,V_width
height
TQ,R,V_height
generationFrequency
T{?=qiIq},R,V_generationFrequency
[Fragment:%lu] Failed to generate poster frame for: %lu
camera.video.poster.frame.generator
posterFramesInternal
T@"NSMutableArray",&,V_posterFramesInternal
input
T@"HMICameraVideoPosterFrameGeneratorInput",R,V_input
nextGenerationTime
T{?=qiIq},V_nextGenerationTime
%@ - %f
frame
T@"HMICameraVideoFrame",R,V_frame
score
Tf,R,V_score
sparse
dense
@"HMICameraVideoFrame"16@?0@"HMICameraVideoFrameSelectorFrameScore"8
q24@?0@"HMICameraVideoFrame"8@"HMICameraVideoFrame"16
q24@?0@"HMICameraVideoFrameSelectorFrameScore"8@"HMICameraVideoFrameSelectorFrameScore"16
v16@?0@"HMICameraVideoFrame"8
camera.video.frame.selector
sampler
T@"HMICameraVideoFrameSampler",R,V_sampler
sampleRate
T{?=qiIq},R,V_sampleRate
framesInternal
T@"NSMutableArray",R,V_framesInternal
maxFrameCount
Tq,R,V_maxFrameCount
predictedFrames
T@"NSMutableArray",R,V_predictedFrames
detector
T@"<HMIMotionDetector>",R,V_detector
T@"<HMICameraVideoFrameSelectorDelegate>",W,V_delegate
frames
camera.video.frame.sampler
targetInterval
T{?=qiIq},R,V_targetInterval
sampleInterval
T{?=qiIq},R,V_sampleInterval
unmatchedSampleFrames
T@"NSMutableArray",R,V_unmatchedSampleFrames
T@"HMICameraVideoFrame",&,V_frame
markedAsFinished
TB,GisMarkedAsFinished,V_markedAsFinished
T@"<HMICameraVideoFrameSamplerDelegate>",W,V_delegate
HMIErrorDomain
Unexpected error
Failed to analyze
Failed to read fragment
Failed to verify fragment
Failed to generate poster frame
Failed to transcode fragment
Video analyzer in error state
Model failed to load
Fragment is invalid
No pixel buffer
Unknown error code %ld
HMIErrorCodeUnexpectedError
HMIErrorCodeFailedToAnalyze
HMIErrorCodeFailedToReadFragment
HMIErrorCodeFailedToVerifyFragment
HMIErrorCodeFailedToGeneratePosterFrame
HMIErrorcodeFailedToTranscodeFragment
HMIErrorCodeAnalyzerInErrorState
HMIErrorCodeModelFailedToLoad
HMIErrorCodeFragmentIsInvalid
HMIPrivateErrorCodeNilPixelBuffer
HMIPrivateErrorCodeEmptyURL
HMIPrivateErrorCodeAVAssetReaderInitializationFailed
HMIPrivateErrorCodeFailedToLoadProperty
HMIPrivateErrorCodeAssetLoadCancelled
HMIPrivateErrorCodeReadingStartFailed
HMIPrivateErrorCodeNoTrackOutput
HMIPrivateErrorCodeSampleBufferUnavailable
HMIPrivateErrorCodeNoVideoTrackFound
HMIPrivateErrorCodeMultipleVideoTracksFound
HMIPrivateErrorInvalidPresentationTime
HMIPrivateErrorAVAssetReaderNotStarted
HMIPrivateErrorCodeSequentialIntegrityViolated
HMIPrivateErrorCodeAnalysisServiceNoConfiguration
HMIPrivateErrorCodeLoadingCoreMLModelFailed
HMIPrivateErrorCodeCoreMLPredictionFailed
HMIPrivateErrorCodeCoreMLOutputIncorrect
HMIPrivateErrorCodeCropAndResizeFailed
HMIPrivateErrorCodePosterFrameGenerationFailed
HMIPrivateErrorCodeCodecNotAvailable
HMIPrivateErrorCodeEncodingFailed
HMIPrivateErrorCodeInvalidVideoFrameFormatToSave
HMIPrivateErrorCodeScalerError
ERROR_%ld
%@: %@
resourceUsageMonitor
T@"<HMISystemResourceUsageMonitorProtocol>",R,V_resourceUsageMonitor
T@"<HMISystemResourceUsageMonitorDelegate>",W,Vdelegate
pixelBufferUV
T^{__CVBuffer=},V_pixelBufferUV
time
T{?=qiIq},R,V_time
camera.video.dense.optical.flow
T@"NSMutableArray",R,V_frames
quantizedFrames
T@"NSMutableArray",R,V_quantizedFrames
minRows
T@"NSMutableDictionary",&,V_minRows
maxRows
T@"NSMutableDictionary",&,V_maxRows
minCols
T@"NSMutableDictionary",&,V_minCols
maxCols
T@"NSMutableDictionary",&,V_maxCols
video/mp4
Failed to initialize HMICameraVideoResourceAttributes from fragment data, err: %d
camera.video.resource.attributes
assetDuration
T{?=qiIq},R,V_assetDuration
T@"NSDate",R,V_creationDate
firstSequenceNumber
TQ,R,V_firstSequenceNumber
nominalFrameRate
Td,R,V_nominalFrameRate
dimensions
T{CGSize=dd},R,V_dimensions
tracks
firstFragmentSequenceNumber
fragmentCount
timeRange
formatDescriptions
[Fragment:%lu] Creating asset with url: %@
[Fragment:%lu] Failed to initialize AVAssetReader
[Fragment:%lu] Start %0.2f, Duration %0.2f, FPS %0.2f
[Fragment:%lu] No fragment URL found on loading request %@
[Fragment:%lu] No fragment data found for URL %@
[Fragment:%lu] Finished handling load request
camera.video.asset.reader
currentFrameId
TQ,V_currentFrameId
T@"AVAssetReader",&,N,V_assetReader
resourceLoaderWorkQueue
T@"NSObject<OS_dispatch_queue>",R,V_resourceLoaderWorkQueue
T@"HMICameraVideoFragment",R,V_videoFragment
logIdentifier
T@"NSString",R,V_logIdentifier
HMICVFR.fi
HMICVFR.e
HMICVFR.as
HMICVFR.d
HMICVFR.fw
HMICVFR.fh
HMICVAR.e
HMICVAR.rc
HMICVAR.fr
HMICVAR.as
HMICVAR.cd
HMICVAR.d
HMICVAR.pf
HMICVAR.ttaf
HMICVAR.tsfws
HMICVAR.lsn
HMICVAR.vf
HMICVAR.af
HMICVAC.pfgi
HMICVAC.pfh
HMICVAC.mfad
HMICVAC.mfd
HMICVAC.st
HMICVAC.smisn
HMICVAC.tf
HMICVASE.e
HMICVASE.vf
HMICVASE.as
HMICVF.et
HMICVF.sn
HMICVF.mf
HMICVF.d
HMICVPF.d
HMICVPF.to
HMICVPF.w
HMICVPF.h
HMIOD.l
HMIOD.c
HMIOD.b.x
HMIOD.b.y
HMIOD.b.w
HMIOD.b.h
supportsSecureCoding
HMICameraVideoFrame does not support NSSecureCoding in the simulator
You must override %@ in a subclass
T{CGRect={CGPoint=dd}{CGSize=dd}},R,V_boundingBox
preferenceOverrides
videoAnalyzerIdentifier
didAnalyzeFragment
didNotAnalyzeFragment
didFindSignificantEvent
result
HMIAnalysisServiceTypeUnknown
HMIAnalysisServiceTypeLocal
HMIAnalysisServiceTypeRemoteFragment
HMIAnalysisServiceTypeUndefined
v24@?0@"HMICameraVideoFragment"8@"HMICameraVideoAnalyzerResult"16
v24@?0@"HMICameraVideoFragment"8@"NSError"16
T@?,C,N,V_didAnalyzeFragment
didFailAnalysisForFragment
T@?,C,N,V_didFailAnalysisForFragment
T@?,C,N,V_didFindSignificantEvent
T@?,C,N,V_didNotAnalyzeFragment
HMIAnalysisService
Remote analysis not supported in the simulator
Asset data is ignored if the video fragment is passed through the properties dictionary
Analyzer configuration property key (%@) is missing
v24@?0@"HMICameraVideoAnalyzerSignificantEvent"8@"HMICameraVideoFragment"16
camera.video.analysis.service
nextRequestID
Ti,V_nextRequestID
requests
T@"NSMapTable",R,V_requests
runRemotely
TB,V_runRemotely
com.apple.homed
personDetected
petDetected
vehicleDetected
analysisQOS
analysisServiceType
motionDetector
frameSelectorSampleRateMultiplier
frameSelectorTargetInterval
processingDevice
confidenceThresholdPersonHigh
confidenceThresholdPetHigh
confidenceThresholdVehicleHigh
confidenceThresholdPersonMedium
confidenceThresholdPetMedium
confidenceThresholdVehicleMedium
modelTimeout
assetReaderMaximizePowerEfficiency
assetReaderForceBGRA
analysisEnableTranscodeFragment
realTimeEncoding
maxConcurrentAnalysisRequests
espressoLowPriority
opticalFlowLowPriority
opticalFlowBackgroundProcessing
enableAnalyzerHistory
user-interactive
user-initiated
unspecified
default
utility
background
Preference %@ is now %@, previously was %@
Only NSNumber and NSString properties are supported.
HMIPreference
T@"HMIPreference",R
qosMap
T@"NSDictionary",R
isProductTypeJ42
isProductTypeJ105
isProductTypeB238
preferenceCacheFlushTimer
T@"HMFTimer",R,V_preferenceCacheFlushTimer
preferenceCache
T@"NSMutableDictionary",R,N,V_preferenceCache
preferenceLoggedValues
T@"NSMutableDictionary",R,N,V_preferenceLoggedValues
preferenceOverridesInternal
T@"NSMutableDictionary",R,N,V_preferenceOverridesInternal
usesCPUOnly
Already started listening for the notification
v12@?0i8
HMINotifydObserver
T@"NSObject<OS_dispatch_queue>",R,N,V_queue
callback
T@?,R,N,V_callback
token
Ti,N,V_token
notificationName
Tr*,R,N,V_notificationName
com.apple.HomeAI.%@%@%@.%tu
cropRect
T{CGRect={CGPoint=dd}{CGSize=dd}},R,V_cropRect
T@"HMICameraVideoFrame",R,W,V_frame
T@"NSError",R,V_error
v32@?0@"NSNumber"8@"NSNumber"16^B24
HMICameraVideoFrameAnalyzerSignificantActivity
@"NSNumber"16@?0@"NSObject"8
none
medium
high
camera.video.frame.analyzer.significant.activity
classHierarchyMap
regionOfInterestOperationQueue
T@"NSOperationQueue",R,V_regionOfInterestOperationQueue
regionOfInterestOperations
T@"NSMapTable",R,V_regionOfInterestOperations
significantActivityDetector
T@"HMISignificantActivityDetector",R,V_significantActivityDetector
transaction
T@"HMFOSTransaction",&,N,V_transaction
origin
T{CGPoint=dd},R,V_origin
T{CGPoint=dd},R
motion
T{CGVector=dd},R,V_motion
eventType
Tq,V_eventType
Time %@
motionVectors
T@"NSArray",R,V_motionVectors
Sparse Optical Flow
camera.video.sparse.optical.flow
T^{__CVBuffer=},N,V_image__Placeholder__0
T@"MLMultiArray",&,N,V_ShotNet__ShotNet__ssd_predictions__block8_box__box_offset__0
T@"MLMultiArray",&,N,V_ShotNet__ShotNet__ssd_predictions__block8_box__class_prob__0
T@"MLMultiArray",&,N,V_ShotNet__ShotNet__ssd_predictions__block7_box__box_offset__0
T@"MLMultiArray",&,N,V_ShotNet__ShotNet__ssd_predictions__block7_box__class_prob__0
T@"MLMultiArray",&,N,V_ShotNet__ShotNet__ssd_predictions__block6_box__box_offset__0
T@"MLMultiArray",&,N,V_ShotNet__ShotNet__ssd_predictions__block6_box__class_prob__0
T@"MLMultiArray",&,N,V_ShotNet__ShotNet__ssd_predictions__block9_box__box_offset__0
T@"MLMultiArray",&,N,V_ShotNet__ShotNet__ssd_predictions__block9_box__class_prob__0
T@"MLMultiArray",&,N,V_ShotNet__ShotNet__ssd_predictions__block10_box__box_offset__0
T@"MLMultiArray",&,N,V_ShotNet__ShotNet__ssd_predictions__block10_box__class_prob__0
T@"MLMultiArray",&,N,V_ShotNet__ShotNet__ssd_predictions__block11_box__box_offset__0
T@"MLMultiArray",&,N,V_ShotNet__ShotNet__ssd_predictions__block11_box__class_prob__0
model
T@"MLModel",R,N,V_model
scn == 1
convertAndUnrollScalar
/BuildRoot/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/HomeAI-75.2.18/OpenCV/src/core/arithm.cpp
op == CMP_LT || op == CMP_LE || op == CMP_EQ || op == CMP_NE || op == CMP_GE || op == CMP_GT
compare
The operation is neither 'array op array' (where arrays have the same size and the same type), nor 'array op scalar', nor 'scalar op array'
The operation is neither 'array op array' (where arrays have the same size and type), nor 'array op scalar', nor 'scalar op array'
binary_op
(mask.type() == CV_8UC1 || mask.type() == CV_8SC1)
mask.size == src1.size
operator()
-256 <= ((b) - (a)) && ((b) - (a)) <= 512
-256 <= ((a) - (b)) && ((a) - (b)) <= 512
The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array'
arithm_op
src2.type() == CV_64F && (src2.rows == 4 || src2.rows == 1)
When the input arrays in add/subtract/multiply/divide functions have different types, the output array type must be explicitly specified
-256 <= (a - b) && (a - b) <= 512
/BuildRoot/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/HomeAI-75.2.18/OpenCV/src/core/alloc.cpp
Failed to allocate %lu bytes
OutOfMemoryError
CV_MAT_CN(_type) == e.a.channels()
assign
/BuildRoot/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/HomeAI-75.2.18/OpenCV/src/core/matop.cpp
Unknown operation
Invalid matrix initializer type
/BuildRoot/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/HomeAI-75.2.18/OpenCV/src/imgproc/utils.cpp
top >= 0 && bottom >= 0 && left >= 0 && right >= 0
copyMakeBorder
value[0] == value[1] && value[0] == value[2] && value[0] == value[3]
borderType != BORDER_CONSTANT
pyrDown
/BuildRoot/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/HomeAI-75.2.18/OpenCV/src/imgproc/pyramids.cpp
!_src.empty()
pyrDown_
std::abs(dsize.width*2 - ssize.width) <= 2 && std::abs(dsize.height*2 - ssize.height) <= 2
/BuildRoot/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/HomeAI-75.2.18/OpenCV/src/core/opengl_interop_deprecated.cpp
GlBuffer
GlTexture
/BuildRoot/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/HomeAI-75.2.18/OpenCV/src/core/persistence.cpp
Invalid pointer to file storage
The node is neither a map nor an empty collection
cvGetFileNodeByName
Null element name
cvStartWriteStruct
The file storage is opened for reading
cvEndWriteStruct
cvWriteInt
cvWriteString
cvWriteRawData
Negative number of elements
Null data pointer
cvStartReadRawData
Null pointer to source file node or reader
The file node should be a numerical scalar or a sequence
cvReadRawDataSlice
Null pointer to reader or destination array
The readed sequence is a scalar, thus len must be 1
The sequence element is not a numerical scalar
The sequence slice does not fit an integer number of records
Null pointers to source file node or destination array
cvReadRawData
opencv-sequence
opencv-sequence-tree
opencv-graph
opencv-sparse-matrix
opencv-image
opencv-matrix
opencv-nd-matrix
Invalid type info
cvRegisterType
Some of required function pointers (is_instance, release, read or write) are NULL
Type name should start with a letter or _
Type name should contain only letters, digits, - and _
NULL double pointer
cvRead
The node does not represent a user object (unknown type?)
Unknown array type
The storage is not opened
icvPuts
An attempt to add element without a key to a map, or add element with key to sequence
icvXMLWriteTag
A single _ is a reserved tag name
Closing tag should not include any attributes
Key should start with a letter or _
Key name may only contain alphanumeric characters [a-zA-Z0-9], '-' and '_'
icvDecodeFormat
fmt_pairs != 0 && max_len > 0
Invalid data type specification
Too long data type specification
(align & (align-1)) == 0 && size < INT_MAX
%.8e
-.Inf
.Inf
%.16e
elements with keys can not be written to sequence
icvXMLWriteScalar
icvYMLWrite
The key is an empty
The key is too long
Key must start with a letter or _
Key names may only contain alphanumeric characters [a-zA-Z0-9], '-', '_' and ' '
icvReleaseSeq
flags
count
Some of essential sequence attributes are absent
icvReadSeq
The sequence flags are invalid
curve
closed
hole
untyped
header_dt
header_user_data
One of "header_dt" and "header_user_data" is there, while the other is not
rect
Only one of "header_user_data", "rect" and "origin" tags may occur
color
data
The image data is not found in file storage
The number of stored elements does not match to "count"
Too complex format for the matrix
icvDecodeSimpleFormat
recursive
false
False
FALSE
icvWriteSeqTree
CV_IS_SEQ( seq )
sequences
icvWriteSeq
level
The size of element calculated from "dt" and the elem_size do not match
icvGetFormat
Size of sequence element (elem_size) is inconsistent with seq->flags
%d%c
The size of header calculated from "header_dt" is greater than header_size
icvWriteHeaderData
opencv-sequence-tree instance should contain a field "sequences" that should be a sequence
icvReadSeqTree
All the sequence tree nodes should contain "level" field
level == prev_level + 1
icvReleaseGraph
vertex_dt
edge_dt
vertex_count
edge_count
Some of essential graph attributes are absent
icvReadGraph
oriented
Graph edges should start with 2 integers and a float
%df%s
vertices
edges
No edges data
No vertices data
Some of stored vertex indices are out of range
Duplicated edge has occured
cvAlignPtr
(align & (align-1)) == 0
icvWriteGraph
CV_IS_GRAPH(graph)
2if%s
sizes
Some of essential matrix attributes are absent
icvReadSparseMat
Could not determine sparse matrix dimensionality
The matrix data is not found in file storage
Sparse matrix data is corrupted
icvWriteSparseMat
CV_IS_SPARSE_MAT(mat)
(reader).seq->elem_size == sizeof(idx)
k < dims
Some of essential image attributes are absent
icvReadImage
layout
interleaved
Only interleaved images can be read
The matrix size does not match to the number of stored elements
icvWriteImage
CV_IS_IMAGE(image)
Images with planar data layout are not supported
top-left
bottom-left
planar
rows
cols
icvReadMat
icvWriteMat
CV_IS_MAT_HDR_Z(mat)
icvReadMatND
Could not determine the matrix dimensionality
icvWriteMatND
CV_IS_MATND_HDR(mat)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/HomeAI-75.2.18/OpenCV/src/core/datastructs.cpp
cvReleaseMemStorage
cvRestoreMemStoragePos
NULL storage pointer
cvMemStorageAlloc
Too large memory block is requested
storage->free_space % CV_STRUCT_ALIGN == 0
requested size is negative or too big
(size_t)ptr % CV_STRUCT_ALIGN == 0
cvCreateSeq
Specified element size doesn't match to the size of the specified element type (try to use 0 for element type)
cvSetSeqBlockSize
Storage block size is too small to fit the sequence elements
cvCvtSeqToArray
cvStartReadSeq
cvChangeSeqBlock
cvGetSeqReaderPos
cvSetSeqReaderPos
cvSeqPush
ptr + elem_size <= seq->block_max
block->start_index > 0
NULL sequence pointer
cvSeqPushMulti
number of removed elements is negative
cvSeqPopMulti
delta > 0
cvClearSeq
Invalid sequence header
cvSeqSlice
Bad sequence slice
Bad input sequence
cvSeqSort
Null compare function
cvCreateSet
cvSetAdd
count <= CV_SET_ELEM_IDX_MASK+1
cvCreateGraph
cvGraphAddVtx
cvFindGraphEdgeByPtr
ofs == 1 || start_vtx == edge->vtx[0]
graph pointer is NULL
cvGraphAddEdgeByPtr
vertex pointers coinside (or set to NULL)
edge->flags >= 0
Invalid graph pointer
cvCloneGraph
cvInitTreeNodeIterator
cvNextTreeNode
icvInitMemStorage
icvDestroyMemStorage
icvGoNextMemBlock
parent->bottom == block
icvGrowSeq
The sequence has NULL storage pointer
storage->free_space >= delta
block->count % seq->elem_size == 0 && block->count > 0
seq->first->start_index == 0
icvFreeSeqBlock
(in_front_of ? block : block->prev)->count == 0
seq->ptr == block->data
block->count > 0 && block->count % seq->elem_size == 0
channels() == CV_MAT_CN(dtype)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/HomeAI-75.2.18/OpenCV/src/core/copy.cpp
mask.depth() == CV_8U && (mcn == 1 || mcn == cn)
size() == mask.size()
checkScalar(value, type(), _value.kind(), _InputArray::MAT )
setTo
mask.empty() || mask.type() == CV_8U
repeat
ny > 0 && nx > 0
maskarr == 0
cvCopy
src.depth() == dst.depth() && src.size == dst.size
(coi1 != 0 || src.channels() == 1) && (coi2 != 0 || dst.channels() == 1)
op == MORPH_ERODE || op == MORPH_DILATE
getMorphologyRowFilter
/BuildRoot/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/HomeAI-75.2.18/OpenCV/src/imgproc/morph.cpp
Unsupported data type (=%d)
getMorphologyColumnFilter
getMorphologyFilter
depth == CV_8U || depth == CV_16U || depth == CV_16S || depth == CV_32F || depth == CV_64F
createMorphologyFilter
shape == MORPH_RECT || shape == MORPH_CROSS || shape == MORPH_ELLIPSE
getStructuringElement
anchor.inside(Rect(0, 0, ksize.width, ksize.height))
normalizeAnchor
/BuildRoot/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/HomeAI-75.2.18/OpenCV/src/imgproc/precomp.hpp
morphOp
((size_t)src[i] & 15) == 0
((size_t)_src[i] & 15) == 0
_kernel.type() == CV_8U
MorphFilter
%s:%d: error: (%d) %s in function %s
%s:%d: error: (%d) %s
OpenCV Error: %s (%s) in %s, file %s, line %d
No Error
Backtrace
Unspecified error
Internal error
Insufficient memory
Bad argument
Iterations do not converge
Autotrace call
Incorrect size of input array
Null pointer
Division by zero occured
Image step is wrong
Inplace operation is not supported
Requested object was not found
Input image depth is not supported by function
Formats of input arguments do not match
Sizes of input arguments do not match
One of arguments' values is out of range
Unsupported format or combination of formats
Input COI is not supported
Bad number of channels
Bad flag (parameter or structure field)
Bad parameter of type CvPoint
Bad type of mask argument
Parsing error
The function/feature is not implemented
Memory block has been corrupted
Assertion failed
No GPU support
Gpu API call
No OpenGL support
OpenGL API call
Unknown %s code %d
status
module != 0 && module->name != 0 && module->version != 0
cvRegisterModule
/BuildRoot/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/HomeAI-75.2.18/OpenCV/src/core/system.cpp
cxcore
2.4.13.6
img.depth() == CV_8U && winSize.width > 2 && winSize.height > 2
buildOpticalFlowPyramid
/BuildRoot/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/HomeAI-75.2.18/OpenCV/src/video/lkpyramid.cpp
maxLevel >= 0 && winSize.width > 2 && winSize.height > 2
calcOpticalFlowPyrLK
(npoints = prevPtsMat.checkVector(2, CV_32F, true)) >= 0
nextPtsMat.checkVector(2, CV_32F, true) == npoints
statusMat.isContinuous()
errMat.isContinuous()
levels1 >= 0
ofs.x >= winSize.width && ofs.y >= winSize.height && ofs.x + prevPyr[lvlStep1].cols + winSize.width <= fullSize.width && ofs.y + prevPyr[lvlStep1].rows + winSize.height <= fullSize.height
levels2 >= 0
ofs.x >= winSize.width && ofs.y >= winSize.height && ofs.x + nextPyr[lvlStep2].cols + winSize.width <= fullSize.width && ofs.y + nextPyr[lvlStep2].rows + winSize.height <= fullSize.height
prevPyr[level * lvlStep1].size() == nextPyr[level * lvlStep2].size()
prevPyr[level * lvlStep1].type() == nextPyr[level * lvlStep2].type()
depth == CV_8U
calcSharrDeriv
cvAlign
/BuildRoot/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/HomeAI-75.2.18/OpenCV/include/opencv2/core/internal.hpp
/BuildRoot/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/HomeAI-75.2.18/OpenCV/src/core/convert.cpp
src && nsrcs > 0 && dst && ndsts > 0 && fromTo && npairs > 0
mixChannels
j < nsrcs && src[j].depth() == depth
i1 >= 0 && j < ndsts && dst[j].depth() == depth
threshold
/BuildRoot/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/HomeAI-75.2.18/OpenCV/src/imgproc/thresh.cpp
Unknown threshold type
thresh_8u
thresh_16s
thresh_32f
unknown function
/BuildRoot/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/HomeAI-75.2.18/OpenCV/include/opencv2/dynamicuda/dynamicuda.hpp
copy
copyWithMask
convert
mallocPitch
The library is compiled without CUDA support
/BuildRoot/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/HomeAI-75.2.18/OpenCV/src/imgproc/imgwarp.cpp
Unknown interpolation method
Unknown/unsupported interpolation type
initInterTab2D
initInterTab1D
type == B.type() && (type == CV_32FC1 || type == CV_64FC1 || type == CV_32FC2 || type == CV_64FC2)
gemm
/BuildRoot/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/HomeAI-75.2.18/OpenCV/src/core/matmul.cpp
a_size.width == len
a_size.height == len
C.type() == type && (((flags&GEMM_3_T) == 0 && C.rows == d_size.height && C.cols == d_size.width) || ((flags&GEMM_3_T) != 0 && C.rows == d_size.width && C.cols == d_size.height))
type == CV_64FC2
src1.type() == src2.type()
scaleAdd
src.channels() == 1
mulTransposed
delta.channels() == 1 && (delta.rows == src.rows || delta.rows == 1) && (delta.cols == src.cols || delta.cols == 1)
GEMM_TransposeBlock
MulTransposedR
delta_cols == 1
/BuildRoot/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/HomeAI-75.2.18/OpenCV/src/core/opengl_interop.cpp
The library is compiled without OpenGL support
throw_nogl
src.type() == CV_8UC1 || src.type() == CV_32FC1
/BuildRoot/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/HomeAI-75.2.18/OpenCV/src/imgproc/corner.cpp
cornerEigenValsVecs
cn <= 4 && func != 0
/BuildRoot/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/HomeAI-75.2.18/OpenCV/src/core/stat.cpp
src.channels() == 1 && func != 0
countNonZero
mean
(cn == 1 && (mask.empty() || mask.type() == CV_8U)) || (cn >= 1 && mask.empty() && !minIdx && !maxIdx)
minMaxIdx
img.dims <= 2
src.type() == CV_8UC1
Unknown/unsupported border type
borderInterpolate
/BuildRoot/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/HomeAI-75.2.18/OpenCV/src/imgproc/filter.cpp
columnBorderType != BORDER_WRAP
!rowFilter.empty() && !columnFilter.empty()
bufType == srcType
0 <= anchor.x && anchor.x < ksize.width && 0 <= anchor.y && anchor.y < ksize.height
roi.x >= 0 && roi.y >= 0 && roi.width >= 0 && roi.height >= 0 && roi.x + roi.width <= wholeSize.width && roi.y + roi.height <= wholeSize.height
start
srcRoi.x >= 0 && srcRoi.y >= 0 && srcRoi.width >= 0 && srcRoi.height >= 0 && srcRoi.x + srcRoi.width <= src.cols && srcRoi.y + srcRoi.height <= src.rows
wholeSize.width > 0 && wholeSize.height > 0
proceed
src && dst && count > 0
srcY >= startY
dstY <= roi.height
src.type() == srcType && dst.type() == dstType
apply
dstOfs.x >= 0 && dstOfs.y >= 0 && dstOfs.x + srcRoi.width <= dst.cols && dstOfs.y + srcRoi.height <= dst.rows
_kernel.channels() == 1
getKernelType
cn == CV_MAT_CN(bufType) && ddepth >= std::max(sdepth, CV_32S) && kernel.type() == ddepth
getLinearRowFilter
Unsupported combination of source format (=%d), and buffer format (=%d)
cn == CV_MAT_CN(bufType) && sdepth >= std::max(ddepth, CV_32S) && kernel.type() == sdepth
getLinearColumnFilter
Unsupported combination of buffer format (=%d), and destination format (=%d)
cn == CV_MAT_CN(_dstType)
createSeparableLinearFilter
ktype == CV_8U || ktype == CV_32S || ktype == CV_32F || ktype == CV_64F
preprocess2DKernel
(symmetryType & (KERNEL_SYMMETRICAL | KERNEL_ASYMMETRICAL)) != 0
SymmColumnVec_32s8u
SymmColumnSmallVec_32s16s
SymmColumnSmallVec_32f
SymmColumnVec_32f16s
SymmColumnVec_32f
(symmetryType & (KERNEL_SYMMETRICAL | KERNEL_ASYMMETRICAL)) != 0 && this->ksize <= 5
SymmRowSmallFilter
kernel.type() == DataType<DT>::type && (kernel.rows == 1 || kernel.cols == 1)
RowFilter
kernel.type() == DataType<ST>::type && (kernel.rows == 1 || kernel.cols == 1)
ColumnFilter
this->ksize == 3
SymmColumnSmallFilter
SymmColumnFilter
/BuildRoot/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/HomeAI-75.2.18/OpenCV/src/imgproc/deriv.cpp
getScharrKernels
dx >= 0 && dy >= 0 && dx+dy == 1
getSobelKernels
The kernel size must be odd and not larger than 31
dx >= 0 && dy >= 0 && dx+dy > 0
ksize > order
/BuildRoot/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/HomeAI-75.2.18/OpenCV/src/core/lapack.cpp
type == CV_32F || type == CV_64F
invert
m == n
method == DECOMP_LU || method == DECOMP_CHOLESKY
n == 1
type == _src2.type() && (type == CV_32F || type == CV_64F)
solve
(method != DECOMP_LU && method != DECOMP_CHOLESKY) || is_normal || src.rows == src.cols
src.rows == 1
The function can not solve under-determined linear systems
src.rows == src.cols
eigen
w.type() == u.type() && u.type() == vt.type() && u.data && vt.data && w.data
backSubst
u.cols >= nm && vt.rows >= nm && (w.size() == Size(nm, 1) || w.size() == Size(1, nm) || w.size() == Size(vt.rows, u.cols))
rhs.data == 0 || (rhs.type() == type && rhs.rows == m)
_SVDcompute
CV_MAT_CN(sumType) == CV_MAT_CN(srcType)
getRowSumFilter
/BuildRoot/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/HomeAI-75.2.18/OpenCV/src/imgproc/smooth.cpp
CV_MAT_CN(sumType) == CV_MAT_CN(dstType)
getColumnSumFilter
Unsupported combination of sum format (=%d), and destination format (=%d)
ktype == CV_32F || ktype == CV_64F
sumCount == ksize-1
qualityLevel > 0 && minDistance >= 0 && maxCorners >= 0
goodFeaturesToTrack
/BuildRoot/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/HomeAI-75.2.18/OpenCV/src/imgproc/featureselect.cpp
mask.empty() || (mask.type() == CV_8UC1 && mask.size() == image.size())
/BuildRoot/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/HomeAI-75.2.18/OpenCV/src/core/array.cpp
Non-positive width or height
cvCreateMatHeader
Invalid matrix type
cvInitMatHeader
Non-positive cols or rows
cvReleaseMat
Bad CvMat header
cvCloneMat
NULL matrix header pointer
cvInitMatNDHeader
invalid array data type
NULL <sizes> pointer
non-positive or too large number of dimensions
one of dimesion sizes is non-positive
The array is too big
cvCreateMatNDHeader
Bad CvMatND header
cvCloneMatND
src->dims <= CV_MAX_DIM
_dst.data == data0
Incorrect number of arrays
cvInitNArrayIterator
Some of required array pointers is NULL
Iterator pointer is NULL
COI set is not allowed here
Number of dimensions is the same for all arrays
Data type is not the same for all arrays
Number of channels is not the same for all arrays
Depth is not the same for all arrays
Mask should have 8uC1 or 8sC1 data type
Dimension sizes are the same for all arrays
cvNextNArraySlice
iterator != 0
cvCreateSparseMat
bad number of dimensions
cvReleaseSparseMat
Invalid sparse array header
cvCloneSparseMat
Invalid sparse matrix header
cvInitSparseMatIterator
NULL iterator pointer
Data is already allocated
cvCreateData
unrecognized or unsupported array type
cvReleaseData
Only continuous nD arrays are supported here
cvGetElemType
cvGetDims
Array should be CvMat or IplImage
cvGetSize
index is out of range
cvPtr2D
COI must be non-null in case of planar images
NULL pointer to indices
cvPtrND
NULL array pointer is passed
cvGetMat
The matrix has NULL data pointer
The image has NULL data pointer
Images with planar data layout should be used with COI selected
The image is interleaved and has over CV_CN_MAX channels
Pixel order should be used with coi == 0
Input array has NULL data pointer
Unrecognized or unsupported array type
cvCreateImage
null pointer to header
cvInitImageHeader
Bad input roi
Unsupported format
Bad input origin
Bad input align
cvReleaseImageHeader
cvReleaseImage
cvSetImageROI
rect.width >= 0 && rect.height >= 0 && rect.x < image->width && rect.y < image->height && rect.x + rect.width >= (int)(rect.width > 0) && rect.y + rect.height >= (int)(rect.height > 0)
cvSetImageCOI
cvGetImageCOI
Bad image header
cvCloneImage
cvGetMatND
icvGetNodePtr
CV_IS_SPARSE_MAT( mat )
One of indices is out of range
(newsize & (newsize - 1)) == 0
GRAY
BGRA
0 <= d && d <= CV_MAX_DIM && _sizes
create
/BuildRoot/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/HomeAI-75.2.18/OpenCV/src/core/matrix.cpp
step[dims-1] == (size_t)CV_ELEM_SIZE(flags)
m.dims >= 2
0 <= _rowRange.start && _rowRange.start <= _rowRange.end && _rowRange.end <= m.rows
0 <= _colRange.start && _colRange.start <= _colRange.end && _colRange.end <= m.cols
m.dims <= 2
0 <= roi.x && 0 <= roi.width && roi.x + roi.width <= m.cols && 0 <= roi.y && 0 <= roi.height && roi.y + roi.height <= m.rows
ranges
r == Range::all() || (0 <= r.start && r.start < r.end && r.end <= m.size[i])
dims <= 2
diag
img->dataOrder == IPL_DATA_ORDER_PIXEL
img->dataOrder == IPL_DATA_ORDER_PIXEL || img->roi->coi != 0
(int)nelems >= 0
reserve
resize
COI is not supported by the function
cvarrToMat
seq->total > 0 && CV_ELEM_SIZE(seq->flags) == seq->elem_size
dims <= 2 && step[0] > 0
locateROI
adjustROI
reshape
The matrix is not continuous, thus its number of rows can not be changed
Bad new number of rows
The total number of matrix elements is not divisible by the new number of rows
The total width is not divisible by the new number of channels
cn <= 4
scalarToRawData
i < 0
getMat
0 <= i && i < (int)vv.size()
This method is not implemented for oclMat yet
k == STD_VECTOR_MAT
0 <= i && i < (int)v.size()
getMatVector
This function in deprecated, do not use it
getGlBuffer
getGlTexture
k == GPU_MAT
getGpuMat
i < (int)vv.size()
total
type
empty
!fixedSize() || ((Mat*)obj)->size.operator()() == _sz
!fixedType() || ((Mat*)obj)->type() == mtype
!fixedSize() || ((gpu::GpuMat*)obj)->size() == _sz
!fixedType() || ((gpu::GpuMat*)obj)->type() == mtype
!fixedSize() || ((ogl::Buffer*)obj)->size() == _sz
!fixedType() || ((ogl::Buffer*)obj)->type() == mtype
!fixedSize() || ((Mat*)obj)->size.operator()() == Size(cols, rows)
!fixedSize() || ((gpu::GpuMat*)obj)->size() == Size(cols, rows)
!fixedSize() || ((ogl::Buffer*)obj)->size() == Size(cols, rows)
!fixedType() && !fixedSize()
CV_MAT_TYPE(mtype) == m.type()
m.dims == dims
m.size[j] == sizes[j]
mtype == type0 || (CV_MAT_CN(mtype) == 1 && ((1 << type0) & fixedDepthMask) != 0)
dims == 2 && ((sizes[0] == sz.height && sizes[1] == sz.width) || (allowTransposed && sizes[0] == sz.width && sizes[1] == sz.height))
dims == 2 && (sizes[0] == 1 || sizes[1] == 1 || sizes[0]*sizes[1] == 0)
!fixedSize() || len == vv.size()
mtype == type0 || (CV_MAT_CN(mtype) == CV_MAT_CN(type0) && ((1 << type0) & fixedDepthMask) != 0)
!fixedSize() || len == ((vector<uchar>*)v)->size() / esz
Vectors with element size %d are not supported. Please, modify OutputArray::create()
create() called for the missing output array
!fixedSize() || len == len0
v[j].empty()
i < (int)v.size()
!fixedType() || (CV_MAT_CN(mtype) == m.channels() && ((1 << CV_MAT_TYPE(flags)) & fixedDepthMask) != 0)
!fixedSize()
release
clear
k == MAT
getMatRef
setIdentity
src.dims <= 2 && esz <= (size_t)32
transpose
src.size() == dst.size() && (src.cols == 1 || src.rows == 1)
func != 0
m.dims <= 2 && m.rows == m.cols
completeSymm
src.dims <= 2
src.channels() == dst.channels()
_arrays && (_ptrs || _planes)
init
narrays <= 1000
arrays[i] != 0
A.size == arrays[i0]->size
A.step[d-1] == A.elemSize()
copyTo
convertTo
minMaxLoc
0 <= _dims && _dims <= CV_MAX_DIM
setSize
s >= 0
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
%{public}@%{public}@
HMIInputFeatureProvider
MLFeatureProvider
HMISignificantActivityDetector
HMFLogging
NSObject
HMICameraVideoEncoderSession
AVAssetWriterDelegate
HMISystemResourceUsage
HMISystemResourceUsageMonitor
HMISystemResourceUsageMonitorProtocol
HMICameraVideoFrame
HMIVisionUtilities
HMIThermalMonitorService
HMIThermalMonitor
HMIPIDController
HMFTimerDelegate
HMIMemorySampler
MovingAverageEntry
MovingAverage
HMICameraVideoAnalyzerResult
HMICameraVideoAnalyzerConfiguration
NSCopying
HMICameraVideoAnalyzerSignificantEvent
HMICameraVideoFrameResult
HMICameraVideoFragment
HMICameraVideoAnalyzerHistory
HMICameraVideoAnalyzerRequestLog
HMICameraVideoAnalyzerRequest
HMICameraVideoFrameSelectorDelegate
HMICameraVideoAnalyzerScheduler
HMISystemResourceUsageMonitorDelegate
HMICameraVideoAnalyzer
HMICameraVideoFrameAnalyzerFactory
HMIObjectDetection
HMIObjectDetectionUtils
HMICameraVideoPosterFrame
HMICameraVideoPosterFrameGeneratorInput
HMICameraVideoPosterFrameGenerator
HMICameraVideoFrameSelectorFrameScore
HMICameraVideoFrameSelector
HMICameraVideoFrameSamplerDelegate
HMICameraVideoFrameSampler
HMIError
HMISystemResourceUsageMonitorImpl
HMIDenseOpticalFlowMotionDetection
HMIDenseOpticalFlowFrame
HMIDenseOpticalFlowMotionDetector
HMIMotionDetector
HMICameraVideoResourceAttributes
HMICameraVideoAssetReader
AVAssetResourceLoaderDelegate
NSCoding
NSSecureCoding
HMIMotionDetection
HMICameraVideoAnalyzerDelegateAdapter
HMICameraVideoAnalyzerDelegate
HMIAnalysisService
HMIPreference
HMINotifydObserver
HMIRegionOfInterestOperation
HMICameraVideoFrameAnalyzerSignificantActivity
HMICameraVideoFrameAnalyzer
HMISparseOpticalFlowFeatureVector
HMISparseOpticalFlowFrame
HMISparseOpticalFlowMotionDetection
HMISparseOpticalFlowMotionDetector
SignificantActivityInput
SignificantActivityOutput
SignificantActivity
init
pixelBuffer
dealloc
inputName
arrayWithObjects:count:
setWithArray:
isEqualToString:
featureValueWithPixelBuffer:
featureValueForName:
featureNames
initWithPixelBuffer:inputName:
.cxx_destruct
_pixelBuffer
_inputName
count
objectAtIndexedSubscript:
doubleValue
sharedInstance
usesCPUOnly
setUsesCPUOnly:
boolPreferenceForKey:defaultValue:
setAllowBackgroundGPUCompute:
bundleForClass:
pathForResource:ofType:
fileURLWithPath:
modelWithContentsOfURL:configuration:error:
hmiPrivateErrorWithCode:underlyingError:
arrayWithCapacity:
_runNeuralNetworkOnPixelBuffer:offsets:scores:error:
_postProcessOffsets:scores:outputPredictions:
transferPixelBuffer:pixelFormat:options:error:
inputFeatureValueName
mlModel
predictionOptions
predictionFromFeatures:options:error:
offsetsFeatureValueNames
type
hmiPrivateErrorWithCode:description:
multiArrayValue
addObject:
scoresFeatureValueNames
array
shape
unsignedLongValue
dataPointer
strides
useSoftmax
initWithLabelIndex:confidence:unclampedBoundingBox:
nmsThreshold
nmsMultiClass:output:withThreshold:
countByEnumeratingWithState:objects:count:
boundingBox
labelIndex
confidence
initWithLabelIndex:confidence:boundingBox:
categoryWithName:
logCategory
isEqual:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
description
debugDescription
logIdentifier
initWithConfidenceThresholds:nmsThreshold:error:
predict:detectedObjects:error:
inputDimensions
_confidenceThresholds
_anchorSizes
_numberOfAnchors
_useSoftmax
_mlModel
_inputFeatureValueName
_offsetsFeatureValueNames
_scoresFeatureValueNames
_nmsThreshold
_predictionOptions
_inputDimensions
numberWithBool:
numberWithUnsignedInt:
dictionaryWithObjects:forKeys:count:
mutableCopy
numberWithInt:
setObject:forKey:
hmiPrivateErrorWithCode:
setBitRate:
initWithFileType:error:
assetWriterInputWithMediaType:outputSettings:
setExpectsMediaDataInRealTime:
addInput:
setDelegate:
data
initWithName:
encodedAssetData
appendData:
session
assetWriterInput
isReadyForMoreMediaData
setLength:
assetWriter
startWriting
startSessionAtSourceTime:
internal
stringWithFormat:
appendSampleBuffer:
invalidate
activity
markAsFinished
flush
finishWritingWithCompletionHandler:
status
error
copy
assetWriter:didProduceFragmentedHeaderData:
assetWriter:didProduceFragmentedMediaData:fragmentedMediaDataReport:
initWithWidth:height:codecType:realTime:error:
bitRate
startEncoding
encodePixelBuffer:presentationTime:
finishEncodingWithCompletionHandler:
_session
_assetWriter
_assetWriterInput
_encodedAssetData
_activity
systemResourceUsageLevel
setSystemResourceUsageLevel:
_systemResourceUsageLevel
UTF8String
productInfo
productClass
initWithProductClass:workQueue:
workQueue
systemResourceUsageMonitorImpl
delegate
getCurrentSystemResourceUsage
start
_systemResourceUsageMonitorImpl
_workQueue
initWithPixelBuffer:presentationTime:frameId:fragmentSequenceNumber:
jpegData
size
imageWithData:
extent
createPixelBufferWithSize:pixelFormat:useIOSurface:
contextWithOptions:
render:toCVPixelBuffer:
numberWithUnsignedLong:
dictionaryWithDictionary:
appendBytes:length:
JPEGRepresentationWithDownscaleFactor:outSize:
presentationTime
frameId
initWithPixelBuffer:
initWithJPEGData:presentationTime:frameId:fragmentSequenceNumber:size:
convertToJPEGWithError:
fragmentSequenceNumber
motionDetections
setMotionDetections:
_frameId
_fragmentSequenceNumber
_jpegData
_motionDetections
_size
_presentationTime
transferPixelBuffer:crop:size:pixelFormat:options:error:
applyPadding:withOriginalSize:padding:
cropPixelBuffer:crop:error:
resizePixelBuffer:size:error:
resizePixelBuffer:size:pixelFormat:options:error:
dewarpPixelBuffer:crop:size:pixelFormat:options:cameraModel:error:
imposeMinSizeFor:withOriginalSize:minCrop:
maintainAspectRatio:originalSize:ratioThreshold:
initWithService:
readValue
_service
dictionary
services
objectForKey:
readValueFromSensor:value:
readMaxValue:
lock
_client
_services
_lock
isProductTypeJ105
numberWithDouble:
initWithConfiguration:
setControlEffort:
resumeMonitoring
isProductTypeB238
objectForKeyedSubscript:
floatValue
initWithTimeInterval:options:
updateControlEffortFromValue:
tick
resume
suspend
timerDidFire:
suspendMonitoring
controlEffort
_target
_integrator
_integratorMin
_integratorMax
_engageDelta
_controlEffortMin
_controlEffortMax
_controlEffort
_tick
initWithWindowSize:
numberWithUnsignedLongLong:
addNumber:
movingAverage
setZeroPadsFractionDigits:
setAllowedUnits:
setCountStyle:
setAllowsNonnumericFormatting:
stringFromByteCount:
highWaterMark
initWithName:reason:userInfo:
stop
setHighWaterMark:
average
_highWaterMark
_average
exceptionWithName:reason:userInfo:
performBlock:
date
initWithValue:
value
_value
_date
windowSize
queue
hmf_removeFirstObject
na_each:
setMovingAverage:
timeIntervalSinceDate:
movingAverageForInterval:defaultValue:
setQueue:
_movingAverage
_queue
_windowSize
events
annotationScores
confidenceThatEventOccurred:events:annotationScores:
resultCode
lastSequenceNumber
analysisFPS
duration
creationDate
frameResults
isEqualToArray:
isEqualToDictionary:
posterFrames
videoFragment
timeToAnalyzeFragment
timeSinceFragmentWasSubmitted
initWithEvents:posterFrames:frameResults:annotationScores:duration:creationDate:resultCode:lastSequenceNumber:
confidenceThatEventOccurred:
isEqual:excludeTime:
setDuration:
setCreationDate:
setResultCode:
setTimeToAnalyzeFragment:
setTimeSinceFragmentWasSubmitted:
setVideoFragment:
setAnalysisFPS:
_analysisFPS
_events
_annotationScores
_posterFrames
_frameResults
_creationDate
_resultCode
_timeToAnalyzeFragment
_timeSinceFragmentWasSubmitted
_videoFragment
_lastSequenceNumber
_duration
getAnalysisServiceTypePreference
numberWithUnsignedInteger:
numberPreferenceForKey:defaultValue:withMap:
integerValue
allocWithZone:
initWithPosterFrameGenerationInterval:posterFrameHeight:maxFragmentAnalysisDuration:maxFragmentDuration:
copyWithZone:
posterFrameGenerationInterval
posterFrameHeight
maxFragmentAnalysisDuration
maxFragmentDuration
serviceType
setServiceType:
startingMediaIntegritySequenceNumber
setStartingMediaIntegritySequenceNumber:
transcodeFragment
setTranscodeFragment:
useScheduler
setUseScheduler:
inMediaAnalysis
setInMediaAnalysis:
_transcodeFragment
_useScheduler
_inMediaAnalysis
_posterFrameGenerationInterval
_posterFrameHeight
_maxFragmentAnalysisDuration
_maxFragmentDuration
_serviceType
_startingMediaIntegritySequenceNumber
initWithEvents:annotationScores:videoFrame:
videoFrame
_videoFrame
initWithFrameId:events:annotationScores:detections:regionOfInterest:frameWidth:frameHeight:
detections
frameWidth
frameHeight
regionOfInterest
_detections
_frameWidth
_frameHeight
_regionOfInterest
initWithSequenceNumber:data:moovFragment:eventTypes:
setUrl:
moovFragment
length
initWithData:
sequenceNumber
stringByAppendingFormat:
URLWithString:
absoluteString
initWithSequenceNumber:data:moovFragment:
initWithSequenceNumber:fragmentData:eventTypes:
initWithSequenceNumber:fragmentData:eventTypes:url:
fragmentData
eventTypes
_sequenceNumber
_data
_moovFragment
_eventTypes
_url
totalRequests
setTotalRequests:
flag
predictions
setPredictions:
totalPredictions
setTotalPredictions:
lastRequestResult
repetitions
setRepetitions:
totalRepetitions
setTotalRepetitions:
setLastRequestResult:
setLastRequestSignificantEvents:
analyzer
scheduler
activeAnalyzerCount
maxPredictions
minRepetitions
identifier
UUIDString
lastRequestSignificantEvents
fragment
attributes
assetDuration
initWithMinRepetitions:maxPredictions:analyzer:
addRequest:result:significantEvents:
shouldPredictRequest:
predictedSignificantEventsForRequest:
predictedResultForRequest:
reset
_minRepetitions
_maxPredictions
_predictions
_repetitions
_totalPredictions
_totalRepetitions
_totalRequests
_lastRequestResult
_lastRequestSignificantEvents
_analyzer
request
initWithFormat:arguments:
initWithRequest:
info:
debug:
_request
significantEventsInternal
setFlag:
initWithAssetData:error:
loadAttributesFromVideoFragment:
analysisSubmissionTime
dimensions
encoderSession
initWithGenerationFrequency:andPosterFrameHeight:
initWithInput:
startHandlingFrames
readerForVideoFragment:workQueue:logIdentifier:
maxAnalysisFPS
initWithResourceAttributes:sampleRate:
preAnalyze:
videoFrameResults
videoAnnotationScoresForFrameResult:
posterFrameGenerator
timeSinceAnalysisStart
timeSinceAnalysisSubmission
analysisStartTime
selector:maySelectFrame:
initWithVideoFragment:analyzer:maxAnalysisFPS:
addSignificantEvent:
significantEvents
markForPrediction
shouldSkipAnalysis
shouldFailAnalysis
loadAttributes
startAnalysis
startEncodingSessionWithError:
startPosterFrameGeneratorWithInterval:frameHeight:
startAssetReaderWithWorkQueue:logIdentifier:
startFrameSelector
finishEncoderSession
makeDidAnalyzeResult
makeDidNotAnalyzeResultWithResultCode:
cancel
frameSelector
assetReader
setEvents:
setVideoFrameResults:
phase
setPhase:
_analysisSubmissionTime
_analysisStartTime
_maxAnalysisFPS
_fragment
_attributes
_encoderSession
_posterFrameGenerator
_frameSelector
_assetReader
_videoFrameResults
_significantEventsInternal
_log
_phase
_flag
alloc
weakObjectsPointerArray
setSystemResourceUsageMonitorUsageLevel:
systemResourceUsageMonitorUsageLevel
numberWithInteger:
numberPreferenceForKey:defaultValue:
thermalPIDController
currentState
isPictureInPictureActive
inFullBypassMode
intValue
analyzers
isActive
averageAnalysisTimeMovingAverage
averageTotalAnalysisTimeMovingAverage
averageTotalAnalysisTime
isProductTypeJ42
updateAnalysisFPS:
internalAnalyzers
hmf_addObject:
assertOwner
addPointer:
compact
setCount:
_compactInternalAnalyzers
isPaused
logState
processPendingRequests
history
maxConcurrentAnalyzers
setInBypassMode:
_markPendingRequestsWithFlag:
averageAnalysisTime
pendingRequests
stringByPaddingToLength:withString:startingAtIndex:
appendFormat:
_outcomeCountsAsString
mediaIntegritySequenceNumber
_flagCountsAsString
inBypassMode
inErrorState
analysisInProgress
appendString:
allObjects
systemResourceUsageDidChangeTo:
resumeThermalPIDController
requestDidEnd:outcome:
registerAnalyzer:
removeAllAnalyzers
setPaused:
systemResourceUsageMonitor
analysisFPSPreference
_paused
_maxConcurrentAnalyzers
_internalAnalyzers
_systemResourceUsageMonitor
_systemResourceUsageMonitorUsageLevel
_thermalPIDController
_averageAnalysisTimeMovingAverage
_averageTotalAnalysisTimeMovingAverage
_analysisFPSPreference
qosMap
_scheduleRequest:
sessionEnded
configuration
_handleError:request:
setLastRequestSubmissionTime:
internalPendingRequests
hmf_enqueue:
pendingRequestsCount
lastRequestSubmissionTime
timeIntervalSinceNow
setSessionEnded:
setRunRemotely:
_handleError:request:description:
skipSequentialMediaIntegrityCheck
firstSequenceNumber
nominalFrameRate
_handleDidNotAnalyzeRequest:resultCode:
_shouldContinueAnalyzingRequest:resultCode:
hmf_maybeDequeue
_analyzeRequest:
setAnalysisInProgress:
_checkRequest:
_predictRequest:
_analyzeRequestRemotely:retryOnConnectionInterruption:
_analyzeRequestLocally:
setMediaIntegritySequenceNumber:
remoteAnalysisService
preferenceOverrides
analyzer:didFindSignificantEvent:inFragment:
code
_handleError:request:underlyingError:
_handleDidAnalyzeRequest:withResult:
_handleDidNotAnalyzeRequest:withResult:error:
requestAnalysisForAssetData:withProperties:andCompletionHandler:
warmStartModel
_willAnalyzeRequest:
_handleError:request:description:underlyingError:
_analyzeRequestFramesLocally:
startReading:
analyzer:willAnalyzeRequest:
_sendAnalyticsEventForRequest:outcome:result:error:
_requestDidEnd:outcome:
_notifyDidAnalyzeRequest:withResult:
_handleDidNotAnalyzeRequest:resultCode:error:
_notifyDidNotAnalyzeRequest:withResult:
hmiErrorWithCode:description:
_enterErrorState
_notifyDidFailAnalysisForRequest:withError:
analyzer:didAnalyzeFragment:withResult:
analyzer:didAnalyzeRequest:withResult:
analyzer:didNotAnalyzeFragment:withResult:
analyzer:didNotAnalyzeRequest:withResult:
analyzer:didFailAnalysisForFragment:withError:
analyzer:didFailAnalysisForRequest:withError:
setInErrorState:
readNextFrame:error:
finish
willHandleFramesFromVideoResource:
handleVideoFrame:error:
isFinishedEarly
_analyzeRequestFrames:
_handleDidAnalyzeRequest:
frames
_analyzeVideoFrame:request:result:error:
analyze:targetEventTypes:error:
_analyzeFrame:request:error:
shouldSaveVideoFramesToDisk
_saveVideoFrame:videoFragment:error:
hasPrefix:
lastPathComponent
stringByDeletingPathExtension
shouldUploadVideoAnalysisEvent
numberWithFloat:
userInfo
eventConfidenceThresholdsHigh
eventConfidenceThresholdsMedium
string
bundleWithIdentifier:
infoDictionary
queryVersionInformation
initWithConfiguration:identifier:
analyzeFragment:
clearPendingFragments
setConfiguration:
setRemoteAnalysisService:
setSaveVideoFramesToDisk:
_flagCounts
_outcomeCounts
_skipSequentialMediaIntegrityCheck
_analysisInProgress
_inErrorState
_inBypassMode
_sessionEnded
_uploadVideoAnalysisEvent
_saveVideoFramesToDisk
_delegate
_identifier
_internalPendingRequests
_lastRequestSubmissionTime
_history
_scheduler
_mediaIntegritySequenceNumber
_configuration
_remoteAnalysisService
setFrameAnalyzer:
watchdogTimer
modelTimeoutPreference
frameAnalyzer
kick
getConfidenceThresholdPreferenceForKey:defaultConfidenceThreshold:
ensureFrameAnalyzerWithError:
_frameAnalyzer
_watchdogTimer
_labelIndex
_confidence
_boundingBox
sortedArrayUsingComparator:
setObject:forKeyedSubscript:
nonMaximumSuppression:output:withThreshold:
addObjectsFromArray:
na_map:
intersectionOverUnion:b:
convertObjectDetections:cropRect:originalImageSize:
initWithData:timeOffset:width:height:
timeOffset
width
height
_width
_height
_timeOffset
generationFrequency
_generationFrequency
posterFramesInternal
input
nextGenerationTime
removeAllObjects
setNextGenerationTime:
saveAsPosterFrame:error:
setPosterFramesInternal:
_posterFramesInternal
_input
_nextGenerationTime
frame
score
initWithFrame:score:
_score
_frame
hasPreferenceForKey:
initWithResourceAttributes:sampleRate:targetInterval:
valuePreferenceForKey:defaultValue:withMap:
initWithSize:
framesInternal
detector
appendFramePixelBuffer:atTime:
detectWithGlobalMotionScore:
sortUsingComparator:
maxFrameCount
containsObject:
predictedFrames
removeObject:
sampler
appendFrame:error:
sampler:didFindSample:
sampler:didFindSample:target:
sampler:didDiscardFrame:
sampleRate
_sampler
_framesInternal
_maxFrameCount
_predictedFrames
_detector
_sampleRate
setFrame:
sampleInterval
targetInterval
unmatchedSampleFrames
firstObject
isMarkedAsFinished
_appendFrame:error:
setMarkedAsFinished:
_markedAsFinished
_unmatchedSampleFrames
_targetInterval
_sampleInterval
mainBundle
localizedStringForKey:value:table:
errorWithDomain:code:userInfo:
_hmiErrorWithCode:description:reason:suggestion:underlyingError:
hmiErrorWithCode:underlyingError:
hmiErrorWithCode:
hmiErrorWithCode:description:underlyingError:
hmiPrivateErrorWithCode:description:underlyingError:
resourceUsageMonitor
_resourceUsageMonitor
initWithBoundingBox:
setPixelBufferUV:
classMotionScoreMap
classPaddingMap
scoreForSubBoundingBox:forMetric:
pixelBufferUV
initWithBoundingBox:size:pixelBufferUV:
applyEventTypeAndCheckIfSubBoundingIsStatic:forMetric:eventType:confidence:
_pixelBufferUV
initWithPixelBuffer:atTime:
time
_time
initWithCapacity:
lastObject
initWithCVPixelBuffer:options:
initWithTargetedCVPixelBuffer:options:
setEnableFiltering:
setFilterOcclusionWeight:
setMetalContextPriority:
setPreferBackgroundProcessing:
performRequests:error:
results
computeFlowMagnitudeMatrixFromOriginal:flowArray:error:
quantizedFrames
quantizedAndBinarizeFrame:quantizedFrames:
connectedComponentsQuantizedFrames:
unionTheRegoins
minRows
allKeys
makeRawCropRect:
computeOpticalFlow:with:globalMotionScore:
maxCols
minCols
maxRows
removeObjectForKey:
setObject:atIndexedSubscript:
compare:
sortedArrayUsingSelector:
reverseObjectEnumerator
setup
setMinRows:
setMaxRows:
setMinCols:
setMaxCols:
_frames
_quantizedFrames
_minRows
_maxRows
_minCols
_maxCols
initWithAssetDuration:creationDate:firstSequenceNumber:lastSequenceNumber:
bytes
initWithAssetDuration:creationDate:firstSequenceNumber:lastSequenceNumber:nominalFrameRate:dimensions:
initWithAssetDuration:creationDate:
_firstSequenceNumber
_nominalFrameRate
_dimensions
_assetDuration
initWithVideoFragment:workQueue:logIdentifier:
assetWithURL:
resourceLoader
resourceLoaderWorkQueue
setDelegate:queue:
initWithAsset:error:
setAssetReader:
assetKeys
_propertiesLoadedForAsset:resultCallback:
loadValuesAsynchronouslyForKeys:completionHandler:
fragments
statusOfValueForKey:error:
_didKeyValueLoadFailed:
tracksWithMediaType:
trackKeys
_propertiesLoadedForTrack:fromAsset:resultCallback:
timeRange
initWithTrack:outputSettings:
setAlwaysCopiesSampleData:
setMaximizePowerEfficiency:
addOutput:
startReading
_validateSequentialIntegrityOfFragmentsInAsset:
_sequenceNumberOfLastFragmentInAsset:
_sequenceNumberOfFirstFragmentInAsset:
dateValue
formatDescriptions
outputs
objectAtIndex:
copyNextSampleBuffer
currentFrameId
setCurrentFrameId:
finishLoadingWithError:
contentInformationRequest
setContentLength:
setContentType:
setByteRangeAccessSupported:
dataRequest
requestedOffset
requestsAllDataToEndOfResource
requestedLength
subdataWithRange:
respondWithData:
finishLoading
resourceLoader:shouldWaitForLoadingOfRequestedResource:
resourceLoader:shouldWaitForRenewalOfRequestedResource:
resourceLoader:didCancelLoadingRequest:
resourceLoader:shouldWaitForResponseToAuthenticationChallenge:
resourceLoader:didCancelAuthenticationChallenge:
_logIdentifier
_currentFrameId
_resourceLoaderWorkQueue
decodeIntegerForKey:
decodeObjectOfClasses:forKey:
decodeObjectOfClass:forKey:
decodeCMTimeForKey:
decodeDoubleForKey:
encodeInteger:forKey:
encodeObject:forKey:
encodeCMTime:forKey:
encodeDouble:forKey:
initWithCoder:
encodeWithCoder:
supportsSecureCoding
decodeBoolForKey:
encodeBool:forKey:
isEqualToData:
decodeIntForKey:
encodeInt:forKey:
raise:format:
_finish
didAnalyzeFragment
didFailAnalysisForFragment
didFindSignificantEvent
didNotAnalyzeFragment
setDidAnalyzeFragment:
setDidFailAnalysisForFragment:
setDidNotAnalyzeFragment:
setDidFindSignificantEvent:
_didAnalyzeFragment
_didFailAnalysisForFragment
_didFindSignificantEvent
_didNotAnalyzeFragment
mapTableWithStrongToWeakObjects
nextRequestID
setNextRequestID:
runRemotely
setPreferenceOverrideFromDictionary:
UUID
getNextRequestID
requests
expectedClasses
requestAnalysisForPixelBuffer:withProperties:andCompletionHandler:
cancelRequest:
_runRemotely
_nextRequestID
_requests
boolValue
preferenceCache
preferenceOverridesInternal
addEntriesFromDictionary:
preferenceLoggedValues
initWithKey:options:domain:defaultValue:
null
systemPreferenceValueForKey:
logPreferenceForKey:value:
caseInsensitiveCompare:
addPreferenceOverrideFromDictionary:
removeAllPreferenceOverrides
numberPreferenceForKey:defaultValue:withParser:
valuePreferenceForKey:defaultValue:withParser:
stringPreferenceForKey:defaultValue:
preferenceCacheFlushTimer
_preferenceCacheFlushTimer
_preferenceCache
_preferenceLoggedValues
_preferenceOverridesInternal
setNumberStyle:
numberFromString:
token
notificationName
publishValueForToken:
publishInitialValue
setToken:
callback
initWithNotificationName:andQueue:andCallback:
_token
_notificationName
_callback
stringByDeletingLastPathComponent
defaultManager
createDirectoryAtPath:withIntermediateDirectories:attributes:error:
pathExtension
writeJPEGRepresentationOfImage:toURL:colorSpace:options:error:
imageWithCVImageBuffer:
writePNGRepresentationOfImage:toURL:format:colorSpace:options:error:
initWithFrame:size:
main
cropRect
_error
_cropRect
classHierarchyMap
enumerateKeysAndObjectsUsingBlock:
mapTableWithKeyOptions:valueOptions:
setMaxConcurrentOperationCount:
_confidenceScoreOverrideForEventType:
significantActivityDetector
regionOfInterestOperations
regionOfInterestOperationQueue
addOperation:
waitUntilFinished
rankForClassLabel:
_addSimulatedDetectionForEventType:targetEventTypes:events:annotationScores:detections:
transaction
setTransaction:
_regionOfInterestOperationQueue
_regionOfInterestOperations
_significantActivityDetector
_transaction
initWithOrigin:motion:
target
distance
origin
motion
eventType
setEventType:
_eventType
_origin
_motion
motionVectors
scoreForSubBoundingBox:forMetric:eventType:confidence:
initWithBoundingBox:size:motionVectors:
_motionVectors
_computeOpticalFlow:with:globalMotionScore:
initWithImage__Placeholder__0:
image__Placeholder__0
setImage__Placeholder__0:
_image__Placeholder__0
featureValueWithMultiArray:
initWithShotNet__ShotNet__ssd_predictions__block8_box__box_offset__0:ShotNet__ShotNet__ssd_predictions__block8_box__class_prob__0:ShotNet__ShotNet__ssd_predictions__block7_box__box_offset__0:ShotNet__ShotNet__ssd_predictions__block7_box__class_prob__0:ShotNet__ShotNet__ssd_predictions__block6_box__box_offset__0:ShotNet__ShotNet__ssd_predictions__block6_box__class_prob__0:ShotNet__ShotNet__ssd_predictions__block9_box__box_offset__0:ShotNet__ShotNet__ssd_predictions__block9_box__class_prob__0:ShotNet__ShotNet__ssd_predictions__block10_box__box_offset__0:ShotNet__ShotNet__ssd_predictions__block10_box__class_prob__0:ShotNet__ShotNet__ssd_predictions__block11_box__box_offset__0:ShotNet__ShotNet__ssd_predictions__block11_box__class_prob__0:
ShotNet__ShotNet__ssd_predictions__block8_box__box_offset__0
setShotNet__ShotNet__ssd_predictions__block8_box__box_offset__0:
ShotNet__ShotNet__ssd_predictions__block8_box__class_prob__0
setShotNet__ShotNet__ssd_predictions__block8_box__class_prob__0:
ShotNet__ShotNet__ssd_predictions__block7_box__box_offset__0
setShotNet__ShotNet__ssd_predictions__block7_box__box_offset__0:
ShotNet__ShotNet__ssd_predictions__block7_box__class_prob__0
setShotNet__ShotNet__ssd_predictions__block7_box__class_prob__0:
ShotNet__ShotNet__ssd_predictions__block6_box__box_offset__0
setShotNet__ShotNet__ssd_predictions__block6_box__box_offset__0:
ShotNet__ShotNet__ssd_predictions__block6_box__class_prob__0
setShotNet__ShotNet__ssd_predictions__block6_box__class_prob__0:
ShotNet__ShotNet__ssd_predictions__block9_box__box_offset__0
setShotNet__ShotNet__ssd_predictions__block9_box__box_offset__0:
ShotNet__ShotNet__ssd_predictions__block9_box__class_prob__0
setShotNet__ShotNet__ssd_predictions__block9_box__class_prob__0:
ShotNet__ShotNet__ssd_predictions__block10_box__box_offset__0
setShotNet__ShotNet__ssd_predictions__block10_box__box_offset__0:
ShotNet__ShotNet__ssd_predictions__block10_box__class_prob__0
setShotNet__ShotNet__ssd_predictions__block10_box__class_prob__0:
ShotNet__ShotNet__ssd_predictions__block11_box__box_offset__0
setShotNet__ShotNet__ssd_predictions__block11_box__box_offset__0:
ShotNet__ShotNet__ssd_predictions__block11_box__class_prob__0
setShotNet__ShotNet__ssd_predictions__block11_box__class_prob__0:
_ShotNet__ShotNet__ssd_predictions__block8_box__box_offset__0
_ShotNet__ShotNet__ssd_predictions__block8_box__class_prob__0
_ShotNet__ShotNet__ssd_predictions__block7_box__box_offset__0
_ShotNet__ShotNet__ssd_predictions__block7_box__class_prob__0
_ShotNet__ShotNet__ssd_predictions__block6_box__box_offset__0
_ShotNet__ShotNet__ssd_predictions__block6_box__class_prob__0
_ShotNet__ShotNet__ssd_predictions__block9_box__box_offset__0
_ShotNet__ShotNet__ssd_predictions__block9_box__class_prob__0
_ShotNet__ShotNet__ssd_predictions__block10_box__box_offset__0
_ShotNet__ShotNet__ssd_predictions__block10_box__class_prob__0
_ShotNet__ShotNet__ssd_predictions__block11_box__box_offset__0
_ShotNet__ShotNet__ssd_predictions__block11_box__class_prob__0
urlOfModelInThisBundle
initWithContentsOfURL:error:
modelWithContentsOfURL:error:
initWithContentsOfURL:configuration:error:
predictionFromFeatures:error:
initWithFeatureProviderArray:
predictionsFromBatch:options:error:
featuresAtIndex:
initWithConfiguration:error:
predictionFromImage__Placeholder__0:error:
predictionsFromInputs:options:error:
model
_model
@24@0:8@16
@16@0:8
@"MLFeatureValue"24@0:8@"NSString"16
@"NSSet"16@0:8
@32@0:8^{__CVBuffer=}16@24
v16@0:8
^{__CVBuffer=}16@0:8
^{__CVBuffer=}
@"NSString"
B24@0:8@16
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B16@0:8
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
@"HMFLogCategory"16@0:8
@40@0:8@16d24^@32
B40@0:8^{__CVBuffer=}16@24^@32
B48@0:8^{__CVBuffer=}16@24@32^@40
v40@0:8@16@24@32
{CGSize=dd}16@0:8
d16@0:8
[91d]
[6[6{CGSize="width"d"height"d}]]
[6Q]
@"MLModel"
@"NSArray"
@"MLPredictionOptions"
{CGSize="width"d"height"d}
v32@0:8@16@24
v32@0:8@"AVAssetWriter"16@"NSData"24
v40@0:8@"AVAssetWriter"16@"NSData"24@"AVFragmentedMediaDataReport"32
@40@0:8i16i20I24B28^@32
i16@0:8
v20@0:8i16
B48@0:8^{__CVBuffer=}16{?=qiIq}24
v24@0:8@?16
^{OpaqueVTCompressionSession=}16@0:8
^{OpaqueVTCompressionSession=}
@"AVAssetWriter"
@"AVAssetWriterInput"
@"NSMutableData"
@"HMFActivity"
q16@0:8
v24@0:8q16
v24@0:8@16
@"HMISystemResourceUsage"16@0:8
@"<HMISystemResourceUsageMonitorDelegate>"16@0:8
v24@0:8@"<HMISystemResourceUsageMonitorDelegate>"16
@"HMISystemResourceUsageMonitorImpl"
@"NSObject<OS_dispatch_queue>"
@24@0:8^{__CVBuffer=}16
@64@0:8^{__CVBuffer=}16{?=qiIq}24Q48Q56
@80@0:8@16{?=qiIq}24Q48Q56{CGSize=dd}64
@28@0:8f16^{CGSize=dd}20
B24@0:8^@16
{?=qiIq}16@0:8
@"NSData"
{?="value"q"timescale"i"flags"I"epoch"q}
^{__CVBuffer=}64@0:8^{__CVBuffer=}16{CGRect={CGPoint=dd}{CGSize=dd}}24^@56
^{__CVBuffer=}48@0:8^{__CVBuffer=}16{CGSize=dd}24^@40
^{__CVBuffer=}60@0:8^{__CVBuffer=}16{CGSize=dd}24I40q44^@52
^{__CVBuffer=}44@0:8^{__CVBuffer=}16I24q28^@36
^{__CVBuffer=}92@0:8^{__CVBuffer=}16{CGRect={CGPoint=dd}{CGSize=dd}}24{CGSize=dd}56I72q76^@84
^{__CVBuffer=}100@0:8^{__CVBuffer=}16{CGRect={CGPoint=dd}{CGSize=dd}}24{CGSize=dd}56I72q76@84^@92
^{__CVBuffer=}40@0:8{CGSize=dd}16I32B36
{CGRect={CGPoint=dd}{CGSize=dd}}80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGSize=dd}48{CGSize=dd}64
{CGRect={CGPoint=dd}{CGSize=dd}}68@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGSize=dd}48i64
{CGRect={CGPoint=dd}{CGSize=dd}}68@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGSize=dd}48f64
@24@0:8^{__IOHIDServiceClient=}16
^{__IOHIDServiceClient=}
B28@0:8i16^d20
B24@0:8^d16
^{__IOHIDEventSystemClient=}
@"NSMutableDictionary"
@"HMFUnfairLock"
v24@0:8@"HMFTimer"16
v20@0:8f16
@"HMFTimer"
@"MovingAverage"
@"NSNumber"
@"NSDate"
@24@0:8Q16
d32@0:8d16d24
v24@0:8d16
@"NSMutableArray"
@96@0:8q16@24@32@40{?=qiIq}48@72q80Q88
q24@0:8q16
B28@0:8@16B24
v40@0:8{?=qiIq}16
f16@0:8
@"NSDictionary"
@"HMICameraVideoFragment"
@24@0:8^{_NSZone=}16
@48@0:8Q16Q24d32d40
v24@0:8Q16
v20@0:8B16
@40@0:8q16@24@32
@"HMICameraVideoFrame"
@96@0:8Q16q24@32@40{CGRect={CGPoint=dd}{CGSize=dd}}48Q80Q88
{CGRect={CGPoint=dd}{CGSize=dd}}16@0:8
{CGRect="origin"{CGPoint="x"d"y"d}"size"{CGSize="width"d"height"d}}
@40@0:8Q16@24@32
@48@0:8Q16@24@32q40
@40@0:8Q16@24q32
@48@0:8Q16@24q32@40
@"NSURL"
@40@0:8q16q24@32
@"HMICameraVideoAnalyzerResult"
@"HMICameraVideoAnalyzer"
@"HMICameraVideoAnalyzerRequest"
v32@0:8@"HMICameraVideoFrameSelector"16@"HMICameraVideoFrame"24
@40@0:8@16@24d32
B32@0:8Q16Q24
B32@0:8@16@24
@24@0:8q16
@"HMICameraVideoResourceAttributes"
@"HMICameraVideoEncoderSession"
@"HMICameraVideoPosterFrameGenerator"
@"HMICameraVideoFrameSelector"
@"HMICameraVideoAssetReader"
@"HMICameraVideoAnalyzerRequestLog"
v32@0:8@16q24
@"NSPointerArray"
@"HMISystemResourceUsageMonitor"
@"HMIPIDController"
q40@0:8q16q24@32
@32@0:8@16@24
v28@0:8@16B24
v40@0:8@16q24@32
v32@0:8q16@24
v40@0:8q16@24@32
v48@0:8q16@24@32@40
B32@0:8@16^q24
@40@0:8@16@24^@32
B48@0:8@16@24^@32^@40
B40@0:8@16@24^@32
v48@0:8@16q24@32@40
[7i]
[3i]
@"<HMICameraVideoAnalyzerDelegate>"
@"NSUUID"
@"HMICameraVideoAnalyzerHistory"
@"HMICameraVideoAnalyzerScheduler"
@"HMICameraVideoAnalyzerConfiguration"
@"HMIAnalysisService"
@40@0:8@16q24^@32
@32@0:8@16d24
@"<HMICameraVideoFrameAnalyzer>"
@60@0:8i16d20{CGRect={CGPoint=dd}{CGSize=dd}}28
f80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48
v40@0:8@16@24d32
@72@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24{CGSize=dd}56
@64@0:8@16{?=qiIq}24Q48Q56
@48@0:8{?=qiIq}16Q40
B32@0:8@16^@24
@"HMICameraVideoPosterFrameGeneratorInput"
@28@0:8@16f24
v32@0:8@"HMICameraVideoFrameSampler"16@"HMICameraVideoFrame"24
v40@0:8@"HMICameraVideoFrameSampler"16@"HMICameraVideoFrame"24@"HMICameraVideoFrame"32
@48@0:8@16{?=qiIq}24
@"<HMICameraVideoFrameSelectorDelegate>"
@"HMICameraVideoFrameSampler"
@"<HMIMotionDetector>"
@72@0:8@16{?=qiIq}24{?=qiIq}48
@"<HMICameraVideoFrameSamplerDelegate>"
@56@0:8Q16@24@32@40@48
@32@0:8q16@24
@"<HMISystemResourceUsageMonitorDelegate>"
@"<HMISystemResourceUsageMonitorProtocol>"
@72@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGSize=dd}48^{__CVBuffer=}64
B68@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16q48q56f64
f56@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16q48
v24@0:8^{__CVBuffer=}16
@48@0:8^{__CVBuffer=}16{?=qiIq}24
@32@0:8{CGSize=dd}16
v48@0:8^{__CVBuffer=}16{?=qiIq}24
@24@0:8^f16
@"NSArray"24@0:8^f16
@40@0:8^{__CVBuffer=}16^{__CVBuffer=}24^f32
{CGRect={CGPoint=dd}{CGSize=dd}}24@0:8@16
f40@0:8^{__CVBuffer=}16^f24^@32
q24@0:8@16
B32@0:8^f16@24
@64@0:8{?=qiIq}16@40Q48Q56
@48@0:8{?=qiIq}16@40
@88@0:8{?=qiIq}16@40Q48Q56d64{CGSize=dd}72
@32@0:8@16^@24
@40@0:8@16@24@32
B32@0:8@"AVAssetResourceLoader"16@"AVAssetResourceLoadingRequest"24
B32@0:8@"AVAssetResourceLoader"16@"AVAssetResourceRenewalRequest"24
v32@0:8@"AVAssetResourceLoader"16@"AVAssetResourceLoadingRequest"24
B32@0:8@"AVAssetResourceLoader"16@"NSURLAuthenticationChallenge"24
v32@0:8@"AVAssetResourceLoader"16@"NSURLAuthenticationChallenge"24
Q24@0:8@16
v32@0:8@16@?24
v40@0:8@16@24@?32
B32@0:8^@16^@24
@"AVAssetReader"
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
@48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
v40@0:8@"HMICameraVideoAnalyzer"16@"HMICameraVideoFragment"24@"HMICameraVideoAnalyzerResult"32
v40@0:8@"HMICameraVideoAnalyzer"16@"HMICameraVideoAnalyzerSignificantEvent"24@"HMICameraVideoFragment"32
v40@0:8@"HMICameraVideoAnalyzer"16@"HMICameraVideoFragment"24@"NSError"32
@?16@0:8
i40@0:8^{__CVBuffer=}16@24@?32
i40@0:8@16@24@?32
B20@0:8i16
@"NSMapTable"
@40@0:8@16@24@?32
@40@0:8r*16@24@?32
r*16@0:8
@40@0:8@16{CGSize=dd}24
@"NSError"
@40@0:8^{NSDictionary=#}16d24^@32
v24@0:8@"HMICameraVideoFrame"16
@"HMICameraVideoFrameResult"40@0:8@"HMICameraVideoFrame"16q24^@32
@"NSDictionary"16@0:8
d24@0:8q16
v56@0:8q16q24^q32@40@48
@"NSOperationQueue"
@"HMISignificantActivityDetector"
@"HMFOSTransaction"
@48@0:8{CGPoint=dd}16{CGVector=dd}32
{CGPoint=dd}16@0:8
{CGVector=dd}16@0:8
{CGPoint="x"d"y"d}
{CGVector="dx"d"dy"d}
@72@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGSize=dd}48@64
f68@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16q48q56f64
@112@0:8@16@24@32@40@48@56@64@72@80@88@96@104
@"MLMultiArray"
@32@0:8^{__CVBuffer=}16^@24
