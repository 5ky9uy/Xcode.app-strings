init
_reportsDynamicActivityAttribute:bundleId:
reportMicUsage:
reportsDynamicActivityAttributeAsync:bundleId:
reportsDynamicActivityAttributeSync:bundleId:
queue
setQueue:
.cxx_destruct
_queue
T@"NSObject<OS_dispatch_queue>",&,N,V_queue
upperCaseString:withReply:
trainPersonalizedLMWithLanguage:configuration:fides:write:completion:
trainGlobalNNLMwithFidesSessionURL:completion:
buildPhoneticMatchWithLanguage:saveIntermediateFsts:completion:
generateAudioWithTexts:language:completion:
interfaceWithProtocol:
arrayWithObjects:count:
setWithArray:
setClasses:forSelector:argumentIndex:ofReply:
initWithMachServiceName:options:
setRemoteObjectInterface:
setInterruptionHandler:
setInvalidationHandler:
resume
invalidate
dealloc
synchronousRemoteObjectProxyWithErrorHandler:
_serviceProxyWithErrorHandler:
firstObject
stringByAppendingPathComponent:
stringByStandardizingPath
isEqualToString:
trainPersonalizedLMWithLanguage:configuration:asset:fides:activity:completion:
length
initWithFormat:
dictionaryWithObjects:forKeys:count:
errorWithDomain:code:userInfo:
trainPersonalizedLMWithLanguage:configuration:asset:directory:completion:
trainPersonalizedLMWithLanguage:configuration:fides:activity:completion:
description
initialize
initWithServiceName:
upperCaseString:completion:
trainPersonalizedLMWithLanguage:directory:completion:
_smtConnection
registerXPCActivities
componentsSeparatedByString:
processInfo
systemUptime
initWithConfiguration:
inputRecordingSampleRate
resetWithSamplingRate:language:taskType:userId:sessionId:deviceId:farField:audioSource:maxAudioBufferSizeSeconds:
removeAllObjects
resultsWithEndedAudio
_calculateTriggerConfidence:
dataForChannel:
inputRecordingIsFloat
resultsWithAddedFloatAudio:numberOfSamples:taskName:
resultsWithAddedAudio:numberOfSamples:taskName:
count
dictionaryWithCapacity:
countByEnumeratingWithState:objects:count:
objectForKeyedSubscript:
setObject:forKey:
tokens
lastObject
tokenName
objectForKey:
floatValue
confidence
numberWithDouble:
sharedPreferences
isMultiPhraseVTEnabled
addObjectsFromArray:
_getConfidence:
objectAtIndex:
caseInsensitiveCompare:
enumerateObjectsUsingBlock:
dumpEARSpeechRecognitionResults:
initWithConfigPath:triggerTokens:useKeywordSpotting:preventDuplicatedReset:
resetWithLanguage:withFarField:withAudioSource:
flushAudio
processAudioChunk:
phraseIdScores
triggerConfidence
setTriggerConfidence:
activeChannel
setActiveChannel:
ctcKwdToPhraseIdMap
setCtcKwdToPhraseIdMap:
_previousUtteranceTokens
_lastReportedRecogResults
_triggerTokenList
_syncRecognizer
_useKeywordSpotting
_requireReset
_preventDuplicatedReset
_triggerConfidence
_activeChannel
_ctcKwdToPhraseIdMap
Td,N,V_triggerConfidence
TQ,N,V_activeChannel
T@"NSDictionary",&,N,V_ctcKwdToPhraseIdMap
T@"NSDictionary",R,N
bytes
numberWithUnsignedInteger:
numberWithFloat:
numberWithBool:
initWithBlob:isEarlyDetected:
dictionary
samplesFed
setSamplesFed:
bestStart
setBestStart:
bestEnd
setBestEnd:
bestScore
setBestScore:
isSecondChance
setIsSecondChance:
isEarlyDetect
setIsEarlyDetect:
_isSecondChance
_isEarlyDetect
_bestScore
_samplesFed
_bestStart
_bestEnd
TQ,N,V_samplesFed
TQ,N,V_bestStart
TQ,N,V_bestEnd
Tf,N,V_bestScore
TB,N,V_isSecondChance
TB,N,V_isEarlyDetect
initWithBlob:
checkForTriggerWithBytes:withNumberOfSamples:
processAudioBytes:withNumberOfSamples:
reset
delegate
setDelegate:
_currentBlob
_delegate
T@"<CSKeywordAnalyzerNDEAPIScoreDelegate>",W,N,V_delegate
setXpcConnection:
_handleDeactivateAudioSessionRequestMessage:messageBody:client:
sharedManagerForCoreSpeechDaemon
fetchFallbackAudioSessionReleaseProvider
fallbackDeactivateAudioSession:error:
_sendReply:client:result:error:
domain
UTF8String
code
isEqual:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
debugDescription
TQ,R
T#,R
T@"NSString",R,C
handleXPCMessage:messageBody:client:
CSXPCConnectionReceivedClientError:clientError:client:
initWithXPCConnection:
xpcConnection
_xpcConnection
T@"CSXPCConnection",W,N,V_xpcConnection
integerValue
multiUserHighScoreThreshold
multiUserLowScoreThreshold
multiUserDeltaScoreThreshold
multiUserConfidentScoreThreshold
mutableCopy
removeObjectForKey:
pickTopScoringProfileIdFromScores:
classifyUserIdentityFor:withScores:withAsset:
stringFromClassificationCategory:
startRecordingHostTime
initWithStreamID:atStartHostTime:
avvcAlertBehavior
unsignedIntegerValue
setStartAlert:
setStopAlert:
setStopOnErrorAlert:
skipAlertBehavior
setSkipAlert:
_alertBehaviorTypeFromAVVCOberrideType:
setStartAlertBehavior:
setStopAlertBehavior:
setErrorAlertBehavior:
startAlertBehavior
_avvcAlertOverrideType:
stopAlertBehavior
errorAlertBehavior
numberWithInteger:
avvcStartRecordSettingsWithAudioStreamHandleId:
setAVVCAlertBehavior:
isAlertBehaviorOverridedBeep
_handleListenerEvent:
_handleListenerError:
xpcObject
_sendMessage:connection:completion:
_decodeError:
stringWithUTF8String:
connect
notifyActivationEvent:completion:
T@"NSObject<OS_xpc_object>",&,N,V_xpcConnection
encodeInteger:forKey:
decodeIntegerForKey:
supportsSecureCoding
encodeWithCoder:
initWithCoder:
TB,R
copyWithZone:
initWithRequestSource:
reqSrc
setReqSrc:
_reqSrc
TQ,N,V_reqSrc
lpcmNarrowBandASBD
lpcmASBD
initWithInASBD:outASBD:
_createSampleRateConverterWithInASBD:outASBD:
dataWithLength:
mutableBytes
setLength:
upsampler
downsampler
convertSampleRateOfBuffer:
_sampleRateConverter
_outBufferScaleFactor
_inASBD
_outASBD
_asssetMetaUpdatedKey
_didReceiveSpeakerRecognitionAssetMetaData
_notifyObserver:
enumerateObservers:
notifyObserver:
CSSpeakerRecognitionAssetMetaUpdateMonitor:didReceiveNewSpeakerRecognitionAssetMetaData:
sharedInstance
_startMonitoringWithQueue:
_stopMonitoring
_notifyToken
initWithType:
defaultFactory
clientForAudioProviding
clientForAudioSessionInfoProviding
clientForSmartSiriVolumeProviding
clientForMacOSDuckAudioDevice
clientForFallbackAudioSessionReleaseProviding
fetchVolumeFromAVSystemControllerForAudioCategory:
_startObservingSystemControllerLifecycle
startObservingSystemVolumes
defaultCenter
removeObserver:
musicVolume
musicVolumeWithCompletion:
alarmVolume
systemVolumeDidChange:
systemControllerDied:
_supportAVSystemVolumeFetch
_musicVolumeLevel
_alarmVolumeLevel
audioRecorder
registerObserver:
deactivateAudioSession:error:
localizedDescription
unregisterObserver:
audioRecorderBufferAvailable:audioStreamHandleId:buffer:remoteVAD:atTime:arrivalTimestampToAudioRecorder:numberOfChannels:
audioRecorderBufferAvailable:audioStreamHandleId:buffer:
audioRecorderDidStartRecord:audioStreamHandleId:successfully:error:
audioRecorderDidStopRecord:audioStreamHandleId:reason:
audioRecorderRecordHardwareConfigurationDidChange:toConfiguration:
audioRecorderDidFinishAlertPlayback:ofType:error:
audioRecorderBeginRecordInterruption:
audioRecorderBeginRecordInterruption:withContext:
audioRecorderEndRecordInterruption:
audioRecorder:willSetAudioSessionActive:
audioRecorder:didSetAudioSessionActive:
voiceTriggerDetectedOnAOP:
audioRecorderDisconnected:
audioRecorderLostMediaserverd:
audioRecorderWillBeDestroyed:
audioRecorderBuiltInAudioStreamInvalidated:error:
audioRecorderStreamHandleIdInvalidated:
initWithAudioRecorder:
setAudioRecorder:
_audioRecorder
T@"CSAudioRecorder",&,N,V_audioRecorder
isSpeakerRecognitionAvailable
addObserver:
_notificationKey
_didInstalledNewAsset
enumerateObserversInQueue:
CSSpeakerRecognitionAssetDownloadMonitor:didInstallNewAsset:assetProviderType:
trialAssetDownloadMonitorDelegate:didInstallNewAsset:assetType:
trialAssetMonitor
setTrialAssetMonitor:
_lastUpdatedAssetType
_trialAssetMonitor
T@"CSTrialAssetDownloadMonitor",&,N,V_trialAssetMonitor
initWithWordCount:trailingSilenceDuration:eosLikelihood:pauseCounts:silencePosterior:taskName:processedAudioDurationInMilliseconds:
componentsJoinedByString:
stringWithFormat:
initWithWordCount:trailingSilenceFrames:endOfSilenceLikelihood:pauseCounts:silencePosterior:taskName:
wordCount
setWordCount:
trailingSilenceDuration
setTrailingSilenceDuration:
eosLikelihood
setEosLikelihood:
pauseCounts
setPauseCounts:
silencePosterior
setSilencePosterior:
processedAudioDurationInMilliseconds
setProcessedAudioDurationInMilliseconds:
taskName
setTaskName:
_wordCount
_trailingSilenceDuration
_eosLikelihood
_pauseCounts
_silencePosterior
_processedAudioDurationInMilliseconds
_taskName
Tq,N,V_wordCount
Tq,N,V_trailingSilenceDuration
Td,N,V_eosLikelihood
T@"NSArray",C,N,V_pauseCounts
Td,N,V_silencePosterior
Tq,N,V_processedAudioDurationInMilliseconds
T@"NSString",C,N,V_taskName
initWithAssertionMonitor:
weakObjectsHashTable
addObject:
removeObject:
doubleValue
_fetchAssertionMonitor
enableAssertionReceived
disableAssertionReceived
CSVoiceTriggerXPCServiceProxy:bypassPhraseSpotter:
CSVoiceTriggerXPCServiceProxy:bypassRaiseToSpeak:
copy
enableVoiceTrigger:withAssertion:timestamp:
setPhraseSpotterBypassing:timeout:
setRaiseToSpeakBypassing:timeout:
fetchVoiceTriggerHeartBeatMetrics
notifyVoiceTriggeredSiriSessionCancelled
notifyServiceConnectionLost
fetchVoiceTriggerStats
activationAssertions
setActivationAssertions:
isPhraseSpotterBypassed
setIsPhraseSpotterBypassed:
isRaiseToSpeakBypassed
setIsRaiseToSpeakBypassed:
observers
setObservers:
assertionMonitor
setAssertionMonitor:
_isPhraseSpotterBypassed
_isRaiseToSpeakBypassed
_activationAssertions
_observers
_assertionMonitor
T@"NSMutableSet",&,N,V_activationAssertions
TB,N,V_isPhraseSpotterBypassed
TB,N,V_isRaiseToSpeakBypassed
T@"NSHashTable",&,N,V_observers
T@"CSSiriAssertionMonitor",&,N,V_assertionMonitor
initWithUTF8String:
initWithName:options:queue:delegate:
dispatchStateChangedFrom:to:
notifySiriSessionStateTTSOngoing:
notifySiriSessionStateChange:
notifyObserver:didReceiveNotificationWithToken:
notifyObserver:didChangeStateFrom:to:
initWithDelegate:
siriStateObserver
setSiriStateObserver:
stateNotificationQueue
setStateNotificationQueue:
isSpeaking
setIsSpeaking:
isListening
setIsListening:
isActiveRequest
setIsActiveRequest:
isActiveSession
setIsActiveSession:
_isSpeaking
_isListening
_isActiveRequest
_isActiveSession
_siriStateObserver
_stateNotificationQueue
T@"AFNotifyObserver",&,N,V_siriStateObserver
T@"NSObject<OS_dispatch_queue>",&,N,V_stateNotificationQueue
TB,N,V_isSpeaking
TB,N,V_isListening
TB,N,V_isActiveRequest
TB,N,V_isActiveSession
T@"<CSAttSiriSessionStateDelegate>",R,W,N,V_delegate
audioStream
streamProvider
isStreaming
submitAudioIssueReport:
name
setAudioStream:
setRecordContext:
type
deviceId
_isHubRequest
_setAllowMixableAudioWhileRecording:
notifyWillStopStream:reason:
notifyWillStopStream:reason:forAccessory:
notifyWillStopStream:
notifyDidStopStream:withEventUUID:
notifyDidStopStream:reason:withEventUUID:forAccessory:
notifyDidStopStream:
stopAudioStreamWithOption:completion:
_handleSetCurrentConextMessage:messageBody:client:
_handleAudioStreamRequestMessage:messageBody:client:
_handleAudioStreamPrepareMessage:messageBody:client:
_handleStartAudioStreamMessage:messageBody:client:
_handleStopAudioStreamMessage:messageBody:client:
_handleVoiceTriggerInfoMessage:messageBody:client:
_handleIsRecordingMessage:messageBody:client:
_handleRecordRouteMessage:messageBody:client:
_handleRecordDeviceInfo:messageBody:client:
_handleAudioDeviceInfo:messageBody:client:
_handleRecordSettings:messageBody:client:
_handleIsNarrowband:messageBody:client:
_handlePlaybackRouteMessage:messageBody:client:
audioStreamProviding
initWithXPCObject:
setCurrentContext:error:
audioStreamWithRequest:streamName:error:
notifyFetchedSiriClientAudioStream:successfully:
streamRequest
prepareAudioStreamSyncWithRequest:error:
notifyPreparedSiriClientAudioStream:successfully:
notifyWillStartStreamWithContext:option:
notifyWillStartStreamWithContext:option:forAccessory:
UUID
notifyWillStartStreamWithContext:audioProviderUUID:option:
UUIDString
notifyDidStartStreamWithContext:successfully:option:withEventUUID:
notifyDidStartStreamWithContext:successfully:option:withEventUUID:forAccessory:
notifyDidStartStreamWithContext:successfully:option:
notifyDidStartStreamWithContext:audioProviderUUID:successfully:option:
startAudioStreamWithOption:completion:
fetchVoiceTriggerInfoWithAudioContext:triggerInfoProviding:resultVoiceTriggerInfo:resultRTSTriggerInfo:
_cs_xpcObject
isRecording
recordRoute
recordDeviceInfo
audioDeviceInfo
recordSettings
isNarrowBand
playbackRoute
_sendDelegateMessageToClient:
sendMessageToClient:
setAllowMixableAudioWhileRecording:error:
audioStreamProvider:didStopStreamUnexpectly:
audioStreamProvider:audioBufferAvailable:
audioStreamProvider:audioChunkForTVAvailable:
audioStreamProvider:didHardwareConfigurationChange:
setAudioStreamProvidingForProxy:
setInitialContext:
triggerInfoProviding
setTriggerInfoProviding:
streamClientType
setStreamClientType:
recordContext
recordEventUUID
setRecordEventUUID:
accessoryId
setAccessoryId:
_audioStreamProviding
_triggerInfoProviding
_streamClientType
_audioStream
_recordContext
_recordEventUUID
_accessoryId
T@"CSAudioStream",&,N,V_audioStream
T@"CSAudioRecordContext",&,N,V_recordContext
T@"NSString",&,N,V_recordEventUUID
T@"NSString",&,N,V_accessoryId
T@"<CSAudioStreamProviding>",W,N,SsetAudioStreamProvidingForProxy:,V_audioStreamProviding
T@"<CSTriggerInfoProviding>",W,N,V_triggerInfoProviding
TQ,N,V_streamClientType
initWithToken:score:startSampleID:endSampleId:
dictionaryRepresentation
bestToken
kwdScore
startStampleId
endSampleId
_kwdScore
_bestToken
_startStampleId
_endSampleId
T@"NSString",R,N,V_bestToken
Tf,R,N,V_kwdScore
Tq,R,N,V_startStampleId
Tq,R,N,V_endSampleId
sharedHandler
flexKwdConfigFile
runRecognitionWithResultStream:
flexKwdThresholdFile
getVoiceTriggerAssetWithEndpointId:completion:
startSampleCount
data
numSamples
addAudioSamples:count:
start
appendFormat:
triggerReportedFromFlxKwdSpotter:
cancelRecognition
speechRecognizer:didRecognizePartialResult:
speechRecognizer:didFinishRecognitionWithError:
speechRecognizer:didRecognizeFinalResults:
speechRecognizer:didRecognizeFinalResults:tokenSausage:nBestChoices:
speechRecognizer:didRecognizeFinalResultPackage:
speechRecognizer:didProcessAudioDuration:
speechRecognizer:didRecognizeRawEagerRecognitionCandidate:
speechRecognizer:didProduceEndpointFeaturesWithWordCount:trailingSilenceDuration:eosLikelihood:pauseCounts:silencePosterior:processedAudioDurationInMilliseconds:
speechRecognizer:didRecognizePartialResultNbest:
speechRecognizer:didProduceLoggablePackage:
startKeywordSpottingWithCompletion:
recognizer
setRecognizer:
recognizerBuffer
setRecognizerBuffer:
currReqFirstSampleId
setCurrReqFirstSampleId:
thresholdsMap
setThresholdsMap:
currentAsset
setCurrentAsset:
_recognizer
_recognizerBuffer
_currReqFirstSampleId
_thresholdsMap
_currentAsset
T@"_EARSpeechRecognizer",&,N,V_recognizer
T@"_EARSpeechRecognitionAudioBuffer",&,N,V_recognizerBuffer
Tq,N,V_currReqFirstSampleId
T@"NSDictionary",&,N,V_thresholdsMap
T@"CSAsset",&,N,V_currentAsset
T@"<CSFlexKeywordSpotterDelegate>",W,N,Vdelegate
defaultManager
fileExistsAtPath:isDirectory:
dataWithContentsOfFile:options:error:
JSONObjectWithData:options:error:
initWithSpeechManager:audioStreamProvider:streamName:streamRequest:
audioProviderWithContext:error:
initWithAudioStreamProvider:streamName:streamRequest:
_handleDidAudioStartWithResult:error:
_handleDidStop
containsObject:
attSiriAudioSrcNodeDidStartRecording:successfully:error:
attSiriAudioSrcNodeLPCMRecordBufferAvailable:audioChunk:
attSiriAudioSrcNodeDidStop:
_handleDidStopStreamUnexpectly
attSiriController
handleAttendingAudioStopUnexpectly
initWithAttSiriController:
addReceiver:
removeReceiver:
pause
stop
setAttSiriController:
requiredNodes
mhId
setMhId:
prefetchedAsset
setPrefetchedAsset:
isReady
setIsReady:
T@"CSAttSiriController",W,N
TQ,R,N
T@"NSArray",R,N
T@"NSString",&,N
T@"CSAsset",&,N
TB,N
receivers
setReceivers:
speechManager
setSpeechManager:
_isReady
_type
_requiredNodes
_attSiriController
_mhId
_receivers
_speechManager
T@"NSHashTable",&,N,V_receivers
T@"CSSpeechManager",&,N,V_speechManager
T@"CSAttSiriController",W,N,V_attSiriController
TQ,R,N,V_type
T@"NSArray",R,N,V_requiredNodes
T@"NSString",&,N,V_mhId
TB,N,V_isReady
utteranceFileASBD
_closeAudioFile
_makeTimestampedAudioLogFilenameWithPrefix:suffix:
fileURLWithPath:isDirectory:
baseDir
_audioLogDirectory
createDirectoryAtPath:withIntermediateDirectories:attributes:error:
localeWithLocaleIdentifier:
setLocale:
setDateFormat:
date
stringFromDate:
_getOrCreateAudioLogDirectory
_nowString
stringByReplacingOccurrencesOfString:withString:
startRecording
appendAudioData:
stopRecording
_audioFile
_asbd
_url
_audioLength
_deregisterAudioSessionNotifications
_startMonitoring
supportRemoraVoiceTrigger
contextForRemoraVoiceTriggerWithDeviceId:
avvcContextSettings
sessionForContext:error:
opaqueSessionID
audioSessionInfoProvider:didReceiveAudioSessionMediaServicesWereLostNotificationWithUserInfo:
_registerAudioSessionNotifications
audioSessionInfoProvider:didReceiveAudioSessionMediaServicesWereResetNotificationWithUserInfo:
removeObserver:name:object:
_handleInterruption:
addObserver:selector:name:object:
_audioRouteChanged:
audioSessionInfoProvider:didReceiveAudioSessionInterruptionNotificationWithUserInfo:
userInfo
audioSessionInfoProvider:didReceiveAudioSessionRouteChangeNotificationWithUserInfo:
_registerInterruptionNotification
_registerAudioRouteChangeNotification
audioSessionIdForDeviceId:
CSAudioServerCrashMonitorDidReceiveServerCrash:
CSAudioServerCrashMonitorDidReceiveServerRestart:
sessionInfoQueue
setSessionInfoQueue:
_sessionInfoQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_sessionInfoQueue
setObject:forKeyedSubscript:
didTransitFrom:to:by:
didIgnoreEvent:from:
initWithInitialState:
addTransitionFrom:to:for:
addTransitionFromAnyStateTo:for:
performTransitionForEvent:
currentState
initialState
setInitialState:
transitions
setTransitions:
eventToStateTransitions
setEventToStateTransitions:
_currentState
_initialState
_transitions
_eventToStateTransitions
Tq,N,V_initialState
T@"NSMutableDictionary",&,N,V_transitions
T@"NSMutableDictionary",&,N,V_eventToStateTransitions
T@"<CSStateMachineDelegate>",W,N,V_delegate
Tq,R,N,V_currentState
setDeviceId:
isSecondPassRunning
setIsSecondPassRunning:
firstPassMyriadGoodnessScore
setFirstPassMyriadGoodnessScore:
_isSecondPassRunning
_firstPassMyriadGoodnessScore
_deviceId
T@"NSString",&,N,V_deviceId
TB,N,V_isSecondPassRunning
Tf,N,V_firstPassMyriadGoodnessScore
pendingSecondPassTriggerWasClearedForClient:deviceId:
_clearPendingRemoraVoiceTrigger
voiceTriggerDidDetectKeyword:deviceId:completion:
_clearPendingBuiltInVoiceTrigger
enumerateKeysAndObjectsUsingBlock:
isBultInVoiceTriggerEvent:
isRemoraVoiceTriggerEvent:
voiceTriggerDidDetectKeyword:deviceId:
handlePendingRemoraVoiceTriggerIfNeeded
handlePendingBuiltInVoiceTriggerIfNeeded
voiceTriggerDidDetectNearMiss:deviceId:
voiceTriggerDidDetectSpeakerReject:
keywordDetectorDidDetectKeyword
voiceTriggerGotSuperVector:
raiseToSpeakDetected:
voiceTriggerDidRejected:deviceId:
setBuiltInVoiceTriggerMetaData:
accessoryVoiceTriggerMetaDataByDeviceId
voiceTriggerDidDetectKeyword:myriadHash:remoteTriggerType:remoteDeviceId:isTriggeredFromFullWake:completion:
secondPassDidStartForClient:deviceId:withFirstPassEstimate:
secondPassDidStopForClient:deviceId:
initWithTargetQueue:
_getHighestRemoraFirstPassGoodnessScore:
_isRemoraSecondPassRunning
builtInSeconPassProgressProvider
setBuiltInSeconPassProgressProvider:
remoraSecondPassProgressProvider
setRemoraSecondPassProgressProvider:
targetQueue
setTargetQueue:
pendingRemoraVoiceTriggerResult
setPendingRemoraVoiceTriggerResult:
pendingRemoraVoiceTriggerDeviceId
setPendingRemoraVoiceTriggerDeviceId:
pendingRemoraVoiceTriggerCompletionBlk
setPendingRemoraVoiceTriggerCompletionBlk:
pendingRemoraVoiceTriggerDetectedTime
setPendingRemoraVoiceTriggerDetectedTime:
pendingBuiltInVoiceTriggerResult
setPendingBuiltInVoiceTriggerResult:
pendingBuiltInVoiceTriggerCompletionBlk
setPendingBuiltInVoiceTriggerCompletionBlk:
pendingBuiltInVoiceTriggerDetectedTime
setPendingBuiltInVoiceTriggerDetectedTime:
builtInVoiceTriggerMetaData
setAccessoryVoiceTriggerMetaDataByDeviceId:
_builtInSeconPassProgressProvider
_remoraSecondPassProgressProvider
_targetQueue
_pendingRemoraVoiceTriggerResult
_pendingRemoraVoiceTriggerDeviceId
_pendingRemoraVoiceTriggerCompletionBlk
_pendingRemoraVoiceTriggerDetectedTime
_pendingBuiltInVoiceTriggerResult
_pendingBuiltInVoiceTriggerCompletionBlk
_pendingBuiltInVoiceTriggerDetectedTime
_builtInVoiceTriggerMetaData
_accessoryVoiceTriggerMetaDataByDeviceId
T@"NSObject<OS_dispatch_queue>",&,N,V_targetQueue
T@"NSDictionary",&,N,V_pendingRemoraVoiceTriggerResult
T@"NSString",&,N,V_pendingRemoraVoiceTriggerDeviceId
T@?,C,N,V_pendingRemoraVoiceTriggerCompletionBlk
TQ,N,V_pendingRemoraVoiceTriggerDetectedTime
T@"NSDictionary",&,N,V_pendingBuiltInVoiceTriggerResult
T@?,C,N,V_pendingBuiltInVoiceTriggerCompletionBlk
TQ,N,V_pendingBuiltInVoiceTriggerDetectedTime
T@"CSPreMyriadVoiceTriggerMetaData",&,N,V_builtInVoiceTriggerMetaData
T@"NSMutableDictionary",&,N,V_accessoryVoiceTriggerMetaDataByDeviceId
T@"<CSVoiceTriggerDelegate>",W,N,V_delegate
T@"<CSSecondPassProgressProviding>",W,N,V_builtInSeconPassProgressProvider
T@"<CSSecondPassProgressProviding>",W,N,V_remoraSecondPassProgressProvider
pingpong:completion:
runVTSecondPassModelWithConfig:locale:withUrl:completion:
runLstmPhsModelWithConfig:withUrl:completion:
runOSDAnalyzerWithConfig:withUrl:completion:
isAttentiveSiriAudioLoggingEnabled
mhLogDirectory
fileExistsAtPath:
speechPackage
getTranscriptionForSpeechPackage:
acousticFTMScores
inputOrigin
didDetectSpeechActivity
timeSinceLastQuery
isAirpodsConnected
boronScore
decisionStage
prevStageOutput
speakerIDScore
timeStampString
addEntriesFromDictionary:
latticeMitigatorResult
nldaMetaInfo
dataWithJSONObject:options:error:
writeToFile:options:error:
logMitigationFeatures:forTask:withModelOutput:forMHRequestId:
endpointTime
setEndpointTime:
endPointerMetrics
setEndPointerMetrics:
_endpointTime
_endPointerMetrics
Td,N,V_endpointTime
T@"CSEndpointerMetrics",&,N,V_endPointerMetrics
supportHybridEndpointer
setEndpointerDelegate:
attSiriNode:didDetectHardEndpointAtTime:withMetrics:
attSiriNode:didDetectStartpointAtTime:
stopEndpointer
resetForNewRequestWithSampleRate:recordContext:recordOption:voiceTriggerInfo:
endPointAnalyzerType
isVoiceTriggered
unsignedLongLongValue
setFirstPktLatency:
resetForVoiceTriggerTwoShotWithSampleRate:
recordingStoppedForReason:
processAudioSamplesAsynchronously:
endpointerModelVersion
processASRFeatures:fromServer:
processServerEndpointFeatures:
updateEndpointerThreshold:
updateEndpointerDelayedTrigger:
shouldAcceptEagerResultForDuration:resultsCompletionHandler:
logHybridEndpointFeaturesWithEvent:locale:
setStartWaitTime:
setEndWaitTime:
setAutomaticEndpointingSuspensionEndTime:
setEndpointerOperationMode:
fetchCurrentEndpointerOperationMode
elapsedTimeWithNoSpeech
trailingSilenceDurationAtEndpoint
processTaskString:
processOSDFeatures:withFrameDurationMs:
processFirstAudioPacketTimestamp:firstAudioSampleSensorTimestamp:
logAnchorMachAbsTime:numSamplesProcessedBeforeAnchorTime:isAnchorTimeBuffered:
wasBuffered
hostTime
arrivalHostTimeToAudioRecorder
addPktInfoWithTimestamp:arrivalTimestamp:currentMachTime:
reportWithRequestMHUUID:
_reportHardEndpointToXPCClientWithTime:endpointerMetrics:
endpointerListener
notifyClientsWithBlock:
didDetectStartpointAtTime:
totalAudioRecorded
endpointBufferHostTime
featuresAtEndpoint
endpointerType
serverFeatureLatencyDistribution
additionalMetrics
didDetectHardEndpointAtTime:withTotalAudioRecorded:endpointBufferHostTime:featuresAtEndpoint:endpointerType:serverFeatureLatencyDistribution:additionalMetrics:
endpointer:didDetectStartpointAtTime:
endpointer:didDetectHardEndpointAtTime:withMetrics:
attSiriNode:didUpdateOSDFeatures:withFrameDurationMs:
attSiriNode:didDetectStartOfSpeechAt:
attSiriNode:didDetectEndOfSpeechAt:
attSiriNode:didUpdateFirstAudioPacketTimestamp:firstAudioSampleSensorTimestamp:firstAudioStartSampleCount:
attSiriNode:didUpdateAnchorMachAbsTime:numSamplesProcessedBeforeAnchorTime:isAnchorTimeBuffered:
processServerFeaturesWithWordCount:trailingSilenceDuration:eosLikelihood:pauseCounts:silencePosterior:taskName:processedAudioDurationInMilliseconds:
getEndpointerModelVersionWithReply:
getElapsedTimeNoSpeechWithReply:
getTrailingSilenceDurationAtEndpointWithReply:
getEndPointAnalyzerTypeWithReply:
getUsesAutomaticEndpointing
processASRFeaturesWithWordCount:trailingSilenceDuration:eosLikelihood:pauseCounts:silencePosterior:taskName:processedAudioDurationInMilliseconds:fromServer:
setEndpointerListener:
proxy
setProxy:
endpointLatencyQueue
setEndpointLatencyQueue:
isNNVAD
setIsNNVAD:
endpointLatencyInfo
setEndpointLatencyInfo:
cachedEndpointerInfo
setCachedEndpointerInfo:
_isNNVAD
_endpointerListener
_proxy
_endpointLatencyQueue
_endpointLatencyInfo
_cachedEndpointerInfo
T@"CSEndpointerProxy",&,N,V_proxy
T@"NSObject<OS_dispatch_queue>",&,N,V_endpointLatencyQueue
TB,N,V_isNNVAD
T@"CSEndpointLatencyInfo",&,N,V_endpointLatencyInfo
T@"CSAttSiriCachedEndpointInfo",&,N,V_cachedEndpointerInfo
T@"CSConnectionListener",&,N,V_endpointerListener
initWithAudioURL:withScaleFactor:outASBD:
audioURL
outASBD
setOutASBD:
fFile
setFFile:
scaleFactor
_scaleFactor
_audioURL
_fFile
T@"NSURL",R,N,V_audioURL
T{AudioStreamBasicDescription=dIIIIIIII},N,V_outASBD
T^{OpaqueExtAudioFile=},N,V_fFile
Tf,R,N,V_scaleFactor
_addSmartSiriVolumeEnabledConditions
_subscribeEventMonitors
subscribeEventMonitor:
getAudioSessionState
addConditions:
csAudioProcessingQueuePriority
getFixedHighPrioritySerialQueueWithLabel:priority:
_refreshSpeakerRecognitionAssets
_setupSSRControllerWithAudioContext:withVoiceTriggerEventInfo:
_stopProcessing
attSiriNode:didUpdateWithSpeakerInfo:
attSiriNode:ssrFinishedProcessingWithSpeakerInfo:
siriProfileId
predicateWithBlock:
filteredArrayUsingPredicate:
getSiriLanguageWithFallback:
objectAtIndexedSubscript:
assetProvider
containsMultiUserThresholds
configVersion
provisionedVoiceProfilesForAppDomain:withLocale:
filteredVoiceProfileArray:
arrayByAddingObjectsFromArray:
_setupSpeakerRecognitionForProfiles:WithVTEventInfo:WithLocale:
isBuiltInVoiceTriggered
initWithVoiceRecognitionContext:error:
initWithContext:withDelegate:error:
array
sharedManager
allInstalledAssetsOfType:language:
assetOfType:providerType:language:completion:
_processSpeakerRecognitionResult:
unsignedIntValue
didReceiveSpeakerRecognitionScoreCard:
didFinishSpeakerRecognition:
_mapScoresToSharedSiriId:
voiceProfileForId:
endAudio
newVoiceProfileWithLocale:withAppDomain:
initWithVoiceRetrainingContext:error:
profileID
fileURLWithPath:
addUtterances:toProfile:withContext:withCompletion:
triggerVoiceProfileCleanupWithCompletion:
convertToShortLPCMBufFromFloatLPCMBuf:
processAudio:withNumberOfSamples:
addSamples:numSamples:
speakerRecognitionController:hasSpeakerInfo:
speakerRecognitionFinishedProcessing:withFinalSpeakerInfo:
startXPCConnection
resetForNewRequestWithRecordContext:voiceTriggerInfo:
ssrListener
setSsrListener:
shouldCleanupVoiceProfile
setShouldCleanupVoiceProfile:
ssrController
setSsrController:
voiceProfileManager
setVoiceProfileManager:
ccProfile
setCcProfile:
leadingUtteranceAudioFile
setLeadingUtteranceAudioFile:
leadingUtteranceLogger
setLeadingUtteranceLogger:
asset
setAsset:
ssrAssets
setSsrAssets:
audioRecordContext
setAudioRecordContext:
voiceTriggerEventInfo
setVoiceTriggerEventInfo:
speakerRecognitionScores
setSpeakerRecognitionScores:
_shouldCleanupVoiceProfile
_ssrListener
_ssrController
_voiceProfileManager
_ccProfile
_leadingUtteranceAudioFile
_leadingUtteranceLogger
_asset
_ssrAssets
_audioRecordContext
_voiceTriggerEventInfo
_speakerRecognitionScores
T@"SSRSpeakerRecognitionController",&,N,V_ssrController
T@"SSRVoiceProfileManager",&,N,V_voiceProfileManager
T@"SSRVoiceProfile",&,N,V_ccProfile
T@"NSString",&,N,V_leadingUtteranceAudioFile
T@"<CSAudioFileWriter>",&,N,V_leadingUtteranceLogger
T@"CSAsset",&,N,V_asset
T@"NSArray",&,N,V_ssrAssets
T@"CSAudioRecordContext",&,N,V_audioRecordContext
T@"NSDictionary",&,N,V_voiceTriggerEventInfo
T@"NSDictionary",&,N,V_speakerRecognitionScores
T@"CSConnectionListener",&,N,V_ssrListener
TB,N,V_shouldCleanupVoiceProfile
sharedConnection
_checkSiriRestrictedOnLockScreen
effectiveBoolValueForSetting:
_notifyObserver:withRestricted:
CSSiriRestrictionOnLockScreenMonitor:didReceiveRestrictionChanged:
_didReceiveRestrictionChanged:
profileConnectionDidReceiveRestrictionChangedNotification:userInfo:
profileConnectionDidReceivePasscodeChangedNotification:userInfo:
profileConnectionDidReceivePasscodePolicyChangedNotification:userInfo:
profileConnectionDidReceiveProfileListChangedNotification:userInfo:
profileConnectionDidReceiveEffectiveSettingsChangedNotification:userInfo:
profileConnectionDidReceiveDefaultsChangedNotification:userInfo:
profileConnectionDidReceiveAppWhitelistChangedNotification:userInfo:
isRestricted
_didReceiveRestrictionChangedInQueue:
_isRestricted
createAudioInjectionDeviceWithType:deviceName:deviceID:productID:completion:
injectAudio:toDeviceWithUUID:withScaleFactor:completion:
connectDeviceWithUUID:completion:
disconnectDeviceWithUUID:completion:
primaryInputDeviceUUIDWithCompletion:
isFirstUnlocked
isEnabled
_performPostBuildInstallWithCompletion:
numberWithLong:
sharedService
registerPostBuildInstallService
sharedController
defaultController
addVTRejectEntry:truncateData:
addVTAcceptEntryAndSubmit:
_recognizeWavData:length:
keywordAnalyzerQuasar:hasResultAvailable:forChannel:
_phraseIdToCtcScoreMap
initWithConfigPath:triggerTokens:useKeywordSpotting:
runRecognition
Td,R,N,V_triggerConfidence
T@"<CSKeywordAnalyzerQuasarScoreDelegate>",W,N,V_delegate
initWithVoiceTriggerAssetDownloadMonitor:languageCodeUpdateMonitor:firstUnlockMonitor:trialAssetDownloadMonitor:assetManager:trialAssetManager:
setCachedAsset:
cachedAsset
defaultFallbackModelIfNil:
_getVoiceTriggerAssetFromAssetManager:
getSiriLanguageWithEndpointId:fallbackLanguage:
_getVoiceTriggerAssetFromAssetManagerWithLocale:completion:
_handleVoiceTriggerAssetWithCompletion:
_handleEndpointVoiceTriggerAsset:completion:
assetOfType:language:completion:
getInstalledAssetofType:forLocale:completion:
path
isEqualAsset:
notifyObservers:endpointId:
cachedEndpointAssets
_checkNewAssetAvailablity
_checkNewAssetAvailablityForEndpoint
CSVoiceTriggerAssetDownloadMonitor:didInstallNewAsset:
CSFirstUnlockMonitor:didReceiveFirstUnlock:
CSLanguageCodeUpdateMonitor:didReceiveLanguageCodeChanged:
setCachedEndpointAssets:
voiceTriggerAssetDownloadMonitor
setVoiceTriggerAssetDownloadMonitor:
languageCodeUpdateMonitor
setLanguageCodeUpdateMonitor:
firstUnlockMonitor
setFirstUnlockMonitor:
trialAssetDownloadMonitor
setTrialAssetDownloadMonitor:
assetManager
setAssetManager:
trialAssetManager
setTrialAssetManager:
_cachedAsset
_cachedEndpointAssets
_voiceTriggerAssetDownloadMonitor
_languageCodeUpdateMonitor
_firstUnlockMonitor
_trialAssetDownloadMonitor
_assetManager
_trialAssetManager
T@"CSAsset",&,V_cachedAsset
T@"NSMutableDictionary",&,V_cachedEndpointAssets
T@"CSVoiceTriggerAssetDownloadMonitor",&,N,V_voiceTriggerAssetDownloadMonitor
T@"CSLanguageCodeUpdateMonitor",&,N,V_languageCodeUpdateMonitor
T@"CSFirstUnlockMonitor",&,N,V_firstUnlockMonitor
T@"CSTrialAssetDownloadMonitor",&,N,V_trialAssetDownloadMonitor
T@"CSAssetManager",&,N,V_assetManager
T@"CSTrialAssetManager",&,N,V_trialAssetManager
decodeObjectOfClass:forKey:
encodeObject:forKey:
numberWithUnsignedLongLong:
setCtx:
detectedToken
setDetectedToken:
triggerMachTime
setTriggerMachTime:
triggerAbsStartSampleId
setTriggerAbsStartSampleId:
_ctx
_detectedToken
_triggerMachTime
_triggerAbsStartSampleId
T@"CSAttSiriRequestContext",C,N,V_ctx
T@"NSString",&,N,V_detectedToken
TQ,N,V_triggerMachTime
TQ,N,V_triggerAbsStartSampleId
setSkipAlertBehavior:
noAlertOption
requestHistoricalAudioDataSampleCount
setRequestHistoricalAudioDataSampleCount:
requestHistoricalAudioDataWithHostTime
setRequestHistoricalAudioDataWithHostTime:
setStartRecordingHostTime:
startRecordingSampleCount
setStartRecordingSampleCount:
useOpportunisticZLL
setUseOpportunisticZLL:
requireSingleChannelLookup
setRequireSingleChannelLookup:
selectedChannel
setSelectedChannel:
setDisableEndpointer:
setDisableLocalSpeechRecognizer:
setDisablePrewamLocalSpeechRecognizer:
setRequestMHUUID:
setSiriSessionUUID:
initTandemWithOption:
estimatedStartHostTime
setEstimatedStartHostTime:
disableEndpointer
disableLocalSpeechRecognizer
disablePrewamLocalSpeechRecognizer
requestMHUUID
siriSessionUUID
_requestHistoricalAudioDataWithHostTime
_requestHistoricalAudioDataSampleCount
_useOpportunisticZLL
_skipAlertBehavior
_requireSingleChannelLookup
_disableEndpointer
_disableLocalSpeechRecognizer
_disablePrewamLocalSpeechRecognizer
_selectedChannel
_startRecordingHostTime
_startRecordingSampleCount
_startAlertBehavior
_stopAlertBehavior
_errorAlertBehavior
_estimatedStartHostTime
_requestMHUUID
_siriSessionUUID
TB,N,V_requestHistoricalAudioDataWithHostTime
TB,N,V_requestHistoricalAudioDataSampleCount
TQ,N,V_startRecordingHostTime
TQ,N,V_startRecordingSampleCount
TB,N,V_useOpportunisticZLL
Tq,N,V_startAlertBehavior
Tq,N,V_stopAlertBehavior
Tq,N,V_errorAlertBehavior
TB,N,V_skipAlertBehavior
T@"NSObject<OS_xpc_object>",R,N
T@"NSString",R,N
TB,N,V_requireSingleChannelLookup
TI,N,V_selectedChannel
TQ,N,V_estimatedStartHostTime
TB,N,V_disableEndpointer
TB,N,V_disableLocalSpeechRecognizer
TB,N,V_disablePrewamLocalSpeechRecognizer
T@"NSString",&,N,V_requestMHUUID
T@"NSString",&,N,V_siriSessionUUID
_update
didTriggerWithSecondChanceEnabled:
initWithPhraseInfoDict:useKeywordSpotting:
updateWithNdapiResult:
updateWithCtcScore:
effectiveThresholdWithSecondChanceEnabled:
hasNearMissTriggerWithSecondChanceEnabled:
dictionaryRepresentationWithSecondChanceEnabled:
phId
setPhId:
phStr
setPhStr:
threshold
setThreshold:
secondChanceThreshold
setSecondChanceThreshold:
loggingThreshold
setLoggingThreshold:
useKwdSpotting
setUseKwdSpotting:
recognizerScoreScaleFactor
setRecognizerScoreScaleFactor:
recognizerThresholdOffset
setRecognizerThresholdOffset:
satThreshold
setSatThreshold:
tdsrSatCombinedSATThreshold
setTdsrSatCombinedSATThreshold:
ndapiScore
setNdapiScore:
ctcCheckerScore
setCtcCheckerScore:
combinedScore
setCombinedScore:
isMaximized
setIsMaximized:
ndapiResult
setNdapiResult:
_useKwdSpotting
_isMaximized
_threshold
_secondChanceThreshold
_loggingThreshold
_recognizerScoreScaleFactor
_recognizerThresholdOffset
_satThreshold
_tdsrSatCombinedSATThreshold
_ndapiScore
_ctcCheckerScore
_combinedScore
_phId
_phStr
_ndapiResult
TQ,N,V_phId
T@"NSString",&,N,V_phStr
Tf,N,V_threshold
Tf,N,V_secondChanceThreshold
Tf,N,V_loggingThreshold
TB,N,V_useKwdSpotting
Tf,N,V_recognizerScoreScaleFactor
Tf,N,V_recognizerThresholdOffset
Tf,N,V_satThreshold
Tf,N,V_tdsrSatCombinedSATThreshold
Tf,N,V_ndapiScore
Tf,N,V_ctcCheckerScore
Tf,N,V_combinedScore
TB,N,V_isMaximized
T@"CSKeywordAnalyzerNDAPIResult",&,N,V_ndapiResult
VTSecondPassCategoryForFirstPassSource:
supportedVTPhrasesInfoForCategory:
VTSecondPassUseKeywordSpottingFrom:
arrayWithCapacity:
numberWithUnsignedLong:
string
initWithAsset:firstPassSource:
updateWithNdapiResults:
updateWithCtcCheckerResults:
getTriggeredPhraseWithSecondChanceEnabled:
getNearMissPhraseWithSecondChanceEnabled:
bestScoringPhrase
phraseMap
setPhraseMap:
triggeredPhrase
setTriggeredPhrase:
_phraseMap
_triggeredPhrase
T@"CSVTSecondPassPhraseScore",&,N,V_triggeredPhrase
T@"NSDictionary",&,N,V_phraseMap
getCoreSpeechXPCConnection
remoteObjectProxy
installedVoiceTriggerAssetForLanguageCode:completion:
fetchRemoteVoiceTriggerAssetForLanguageCode:completion:
getCoreSpeechServiceConnection
getCurrentVoiceTriggerLocaleWithEndpointId:completion:
voiceTriggerRTModelForVersion:minorVersion:accessoryRTModelType:endpointId:downloadedModels:preinstalledModels:completion:
voiceTriggerRTModelForVersion:minorVersion:accessoryRTModelType:locale:endpointId:downloadedModels:preinstalledModels:completion:
voiceTriggerRTModelForVersion:minorVersion:locale:downloadedModels:preinstalledModels:completion:
voiceTriggerJarvisLanguageList:jarvisSelectedLanguage:completion:
requestUpdatedSATAudio:
getFirstPassRunningMode:
voiceTriggerRTModelForVersion:minorVersion:accessoryRTModelType:downloadedModels:preinstalledModels:completion:
voiceTriggerRTModelForVersion:minorVersion:downloadedModels:preinstalledModels:completion:
requestUpdatedSATAudio
getFirstPassRunningMode
assetChangeMonitorDidDetectAssetChange:
sharedMonitor
startMonitoring
notifyVoiceTriggerAssetChanged
T@"<CSVoiceTriggerAssetChangeDelegate>",W,N,V_delegate
_didReceiveMediaserverNotification:
_notifyObserver:withMediaserverState:
audioServerCrashEventProvidingLostMediaserverd
_mediaserverdDidRestart
serverState
setServerState:
_serverState
TQ,N,V_serverState
rootQueueWithFixedPriority:
_sendXPCClientType
_disconnect
_sendMessageAsync:completion:
sendMessageAndReplySync:error:
sendMessageAsync:completion:
setAudioSessionProvidingDelegate:
setAudioAlertProvidingDelegate:
_cs_initWithXPCObject:
createPrepareAudioStreamMessageWithRequest:
createStartAudioStreamMessageWithOption:
createStopAudioStreamMessage
isRTSTriggered
_handleListenerMessage:
_handleSessionProvidingDelegateMessageBody:
_handleStreamProvidingDelegateMessageBody:
_handleAlertProvidingDelegateMessageBody:
_handleSessionInfoProvidingDelegateMessageBody:
_handleListenerDisconnectedError:
CSXPCClient:didDisconnect:
_handleAlertProvidingDelegateDidFinishAlertPlayback:
audioAlertProvidingDelegate
audioAlertProvidingDidFinishAlertPlayback:ofType:error:
_handleSessionProvidingDelegateBeginInterruption:
_handleSessionProvidingDelegateBeginInterruptionWithContext:
_handleSessionProvidingDelegateEndInterruption:
_handleSessionProvidingDelegateWillSetAudioSession:
_handleSessionProvidingDelegateDidSetAudioSession:
_handleSessionProvidingDelegateStreamHandleIdInvalidation:
_handleSessionProvidingDelegateDidChangeContext:
audioSessionProvidingDelegate
audioSessionProviderBeginInterruption:
audioSessionProviderBeginInterruption:withContext:
audioSessionProviderEndInterruption:
audioSessionProvider:willSetAudioSessionActive:
audioSessionProvider:didSetAudioSessionActive:
audioSessionProvider:providerInvalidated:
audioSessionProvider:didChangeContext:
_handleSessionInfoProvidingDelegateInterruptionNotification:
_handleSessionInfoProvidingDelegateRouteChangeNotification:
_handleSessionInfoProvidingDelegateMediaServicesWereLostNotification:
_handleSessionInfoProvidingDelegateMediaServicesWereResetNotification:
_handleStreamProvidingDelegateDidStopUnexpectly:
_handleStreamProvidingDelegateChunkAvailable:
_handleStreamProvidingDelegateChunkForTVAvailable:
_handleStreamProvidingDelegateHardwareConfigChange:
createAudioStreamMessageWithRequest:
setAudioSessionDelegate:
prewarmAudioSessionWithError:
activateAudioSessionWithReason:dynamicAttribute:bundleID:error:
duckOthersOption
setDuckOthersOption:
enableMiniDucking:
enableSmartRoutingConsideration:
reportsDynamicActivityAttribute:bundleId:
audioStreamId
audioStreamWithRequest:streamName:completion:
attachTandemStream:toPrimaryStream:completion:
prepareAudioStreamSync:request:error:
prepareAudioStream:request:completion:
startAudioStream:option:completion:
stopAudioStream:option:completion:
audioChunkFrom:to:
audioChunkFrom:to:channelIdx:
audioChunkToEndFrom:
audioChunkToEndFrom:channelIdx:
saveRecordingBufferFrom:to:toURL:
saveRecordingBufferToEndFrom:toURL:
holdAudioStreamWithDescription:timeout:
cancelAudioStreamHold:
setAnnounceCallsEnabled:withStreamHandleID:
setAudioAlertDelegate:
setAlertSoundFromURL:forType:
playAlertSoundForType:
playRecordStartingAlertAndResetEndpointer
alertStartTime
configureAlertBehavior:
setMeteringEnabled:
updateMeters
peakPowerForChannel:
averagePowerForChannel:
audioMetric
hostTimeFromSampleCount:
sampleCountFromHostTime:
triggerInfoForContext:completion:
isConnected
disconnect
prepareAudioProviderWithContext:clientType:error:
pingpong:
acousticSLResultForContext:completion:
audioStreamProvidingDelegate
setAudioStreamProvidingDelegate:
xpcReplyQueue
setXpcReplyQueue:
xpcClientQueue
setXpcClientQueue:
audioSessionInfoObservers
setAudioSessionInfoObservers:
xpcClientType
setXpcClientType:
_audioSessionProvidingDelegate
_audioStreamProvidingDelegate
_audioAlertProvidingDelegate
_UUID
_xpcReplyQueue
_xpcClientQueue
_audioSessionInfoObservers
_xpcClientType
T@"NSObject<OS_dispatch_queue>",&,N,V_xpcReplyQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_xpcClientQueue
T@"NSHashTable",&,N,V_audioSessionInfoObservers
TQ,N,V_xpcClientType
T@"<CSAudioSessionProvidingDelegate>",W,N,V_audioSessionProvidingDelegate
T@"<CSAudioStreamProvidingDelegate>",W,N,V_audioStreamProvidingDelegate
T@"<CSAudioAlertProvidingDelegate>",W,N,V_audioAlertProvidingDelegate
T@"<CSXPCClientDelegate>",W,N,V_delegate
T@"NSString",R,N,V_UUID
receiveOpportuneSpeakListenerStart
receiveOpportuneSpeakListenerStop
startListenWithOption:completion:
stopListenWithCompletion:
opportuneSpeakListener:hasRemoteVADAvailable:
opportuneSpeakListener:hasVADAvailable:
opportuneSpeakListener:hasVADAvailable:withHostTime:
opportuneSpeakListener:didStopUnexpectly:
listener
initializeTimerState
timerState
_timerFiringState
initWithAudioDeviceID:
sharedSession
currentInputDeviceUIDArray
currentInputRoute
currentOutputRoute
_inputRoute
_outputRoute
deviceName
isBluetooth
source
destination
_isBluetooth
_deviceName
_uid
_source
_destination
T@"NSString",R,C,N,V_deviceName
T@"NSString",R,C,N,V_uid
TB,R,N,V_isBluetooth
T@"NSString",R,C,N,V_source
T@"NSString",R,C,N,V_destination
opportuneSpeakEventMonitor:didStreamStateChanged:
_notifyStopOpportuneSpeakWithDelay:
opportuneSpeakBehaviorMonitor:willStartStreamWithContext:audioProviderUUID:option:
opportuneSpeakBehaviorMonitor:didStartStreamWithContext:audioProviderUUID:successfully:option:
opportuneSpeakBehaviorMonitor:willStopStream:
opportuneSpeakBehaviorMonitor:didStopStream:
audioProviderUUID
isOpportuneSpeakListening
setIsOpportuneSpeakListening:
setAudioProviderUUID:
token
setToken:
_isOpportuneSpeakListening
_audioProviderUUID
_token
TB,N,V_isOpportuneSpeakListening
T@"NSString",&,N,V_audioProviderUUID
T@"NSUUID",&,N,V_token
_receivedNewAssetUpdate:
voiceTriggerAssetHandler:endpointId:didChangeCachedAsset:
getMitigationAssetWithEndpointId:completion:
_checkPhraseSpotterEnabled
_notifyObserver:withEnabled:
CSPhraseSpotterEnabledMonitor:didReceiveEnabled:
phraseSpotterEnabled
_didReceivePhraseSpotterSettingChangedInQueue:
_phraseSpotterEnabledDidChange
_isPhraseSpotterEnabled
notifyInEarMyriadTrigger
isModelBenchmarkingEnabled
initWithMachServiceName:
setExportedInterface:
xpcConnection:hasEntitlement:
setExportedObject:
listener:shouldAcceptNewConnection:
listen
_listener
_exportedObject
resourcePath
getStringForKey:category:default:
progCheckerConfigFile
decodeJson:
initWithArray:
_mapInputOriginFromAssetToCSAudioRecordType:
boolValue
contConvConfigFile
keysOfEntriesPassingTest:
supportedInputOrigins
checkerThresholds
progCheckerShadowMode
contConvThresholds
TB,R,N
_notifyObserver:withLanguageCode:
_didReceiveLanguageCodeUpdate
notifySiriLanguageCodeChanged:
generateEmptyPHash:writeFile:
notifyHashlessTrigger:
setLastHash:
lastHash
T@"NSData",C
generatePHashFromVoiceTriggerInfo:writeFile:
pHash:length:
signalEstimate
setSignalEstimate:
signalFractional
setSignalFractional:
_signalFractional
_signalEstimate
Ts,N,V_signalEstimate
TC,N,V_signalFractional
_handleNewRemoteConnection:
machXPCConnection:hasEntitlement:
initWithConnection:
activateConnection
CSVoiceTriggerXPCConnectionReceivedClientError:clientError:client:
setListener:
connections
setConnections:
_connections
T@"NSObject<OS_xpc_object>",&,N,V_listener
T@"NSMutableArray",&,N,V_connections
_servicesListenerShouldAcceptNewConnection:
setDelayInterstitialSounds:level:completion:
getTriggerCount:
clearTriggerCount:
getTestResponse:
gibraltarVoiceTriggerHandler
setGibraltarVoiceTriggerHandler:
servicesListener
setServicesListener:
_gibraltarVoiceTriggerHandler
_servicesListener
T@"NSXPCListener",&,N,V_servicesListener
T@"CSGibraltarVoiceTriggerHandler",&,N,V_gibraltarVoiceTriggerHandler
setName:
_name
T@"NSString",&,N,V_name
estimatedUserSpeakingStartedHostTime
estimatedUserSpeakingEndedHostTime
_reportUEIUserSpeakingContext
initWithRequestMHUUID:turnIdentifier:
setSpeechRecognizedContext:withEndpointerMetrics:
reportEndpointDelayIfNeed
endpointTimeInMs
setEndpointTimeInMs:
userSpeakingStartedTimeInMs
setUserSpeakingStartedTimeInMs:
userSpeakingEndedTimeInMs
setUserSpeakingEndedTimeInMs:
setEndpointBufferHostTime:
userSpeakingStartedHostTime
setUserSpeakingStartedHostTime:
userSpeakingEndedHostTime
setUserSpeakingEndedHostTime:
stopRecordingHostTime
setStopRecordingHostTime:
turnIdentifier
setTurnIdentifier:
didReportEndpointDelay
setDidReportEndpointDelay:
_didReportEndpointDelay
_endpointTimeInMs
_userSpeakingStartedTimeInMs
_userSpeakingEndedTimeInMs
_endpointBufferHostTime
_userSpeakingStartedHostTime
_userSpeakingEndedHostTime
_stopRecordingHostTime
_turnIdentifier
Td,N,V_endpointTimeInMs
Td,N,V_userSpeakingStartedTimeInMs
Td,N,V_userSpeakingEndedTimeInMs
TQ,N,V_endpointBufferHostTime
TQ,N,V_userSpeakingStartedHostTime
TQ,N,V_userSpeakingEndedHostTime
TQ,N,V_stopRecordingHostTime
T@"NSUUID",&,N,V_turnIdentifier
TB,N,V_didReportEndpointDelay
getNumberForKey:category:default:
getNumElementInBitset:
_getNumberFromASVDictionaryForKey:category:default:
intValue
_adaptiveSiriVolumeDictionary
SSVNoiseLevelChannelBitset
SSVLKFSChannelBitset
SSVEnergyBufferSize
numberWithUnsignedInt:
SSVNoiseLowerPercentile
SSVNoiseUpperPercentile
SSVLKFSLowerPercentile
SSVLKFSUpperPercentile
SSVNoiseTimeConstant
SSVNoiseMicSensitivityOffset
SSVLKFSTimeConstant
SSVLKFSMicSensitivityOffset
SSVNoiseTTSMappingInputRangeLow
SSVNoiseTTSMappingInputRangeHigh
SSVNoiseTTSMappingOutputRangeLow
SSVNoiseTTSMappingOutputRangeHigh
SSVLKFSTTSMappingInputRangeLow
SSVLKFSTTSMappingInputRangeHigh
SSVLKFSTTSMappingOutputRangeLow
SSVLKFSTTSMappingOutputRangeHigh
SSVUserOffsetInputRangeLow
SSVUserOffsetInputRangeHigh
SSVUserOffsetOutputRangeLow
SSVUserOffsetOutputRangeHigh
SSVTTSVolumeLowerLimitDB
SSVTTSVolumeUpperLimitDB
SSVNoiseWeight
SSVDistanceChannelBitset
SSVNoiseMicSensitivityOffsetDeviceSimple
SSVCAMaxFrameSize
SSVCAVoiceTriggerBasedTTSValidForSeconds
SSVCASmartSiriVolumeUnsyncedMetricLogsToRetain
SSVCASmartSiriVolumeSyncedMetricLogsToRetain
SSVCAVoiceTriggerInitialSilenceDurationSeconds
SSVCADistanceInputBufferDurationSeconds
SSVCAListenPollingIntervalAtStartInSeconds
SSVCADefaultZeroFloatingPointValue
SSVCAAnnouncementStatusFetchTimeoutMs
SSVCADefaultOutputTTSVolume
SSVCANoiseActivityCountThreshold
SSVCASpeakerDistanceFarBoostFactor
SSVCASpeakerDistanceMidBoostFactor
SSVCASpeakerDistanceNearBoostFactor
SSVCADistanceModelConfidenceThreshold
SSVCAMinimumLinearSoundLevel
SSVCAMaximumLinearSoundLevel
SSVCALinearToDecibelConstantMultiplier
SSVCADecibelToLinearLogBase
SSVCASignalToSigmoidNoiseDilationFactor
SSVCASignalToSigmoidMusicDilationFactorDeviceDefault
SSVCASignalToSigmoidMusicDilationFactorDeviceSimple
SSVCASignalToSigmoidSpeechDilationFactor
SSVCASignalToSigmoidNoiseVSpread
SSVCASignalToSigmoidMusicVSpreadDeviceDefault
SSVCASignalToSigmoidMusicVSpreadDeviceSimple
SSVCASignalToSigmoidSpeechVSpread
SSVCASignalToSigmoidNoiseVOffset
SSVCASignalToSigmoidMusicVOffsetDeviceDefault
SSVCASignalToSigmoidMusicVOffsetDeviceSimple
SSVCASignalToSigmoidSpeechVOffset
SSVCASignalToSigmoidNoiseHOffset
SSVCASignalToSigmoidMusicHOffsetDeviceDefault
SSVCASignalToSigmoidMusicHOffsetDeviceSimple
SSVCASignalToSigmoidSpeechHOffset
SSVCASignalToSigmoidMusicSteepnessDeviceDefault
SSVCASignalToSigmoidMusicSteepnessDeviceSimple
SSVCASignalToSigmoidNoiseSteepness
SSVCASignalToSigmoidSpeechSteepness
SSVCADBToTTSMinimumOutput
SSVCADBToTTSMaximumOutput
SSVCADBToTTSTransitionPoint
SSVCADBToTTSPreTransitionOffset
SSVCADBToTTSPreTransitionMultiplier
SSVCADBToTTSPostTransitionOffset
SSVCADBToTTSPostTransitionDC
SSVCADBToTTSPostTransitionMultiplier
SSVCAMinimumDistanceUpdateWaitPeriodSeconds
SSVCANoiseActivityThreshold
SSVCANoiseResultsBufferSize
SSVCAMusicResultsBufferSize
SSVCADefaultSpeechStrength
SSVCADefaultMusicStrength
SSVCANoiseActivityHistoricalSampleCount
SSVCADspCoefsCount
SSVCADspNumStages
SSVCADistanceResultsBufferSize
SSVCAExponentialDistanceHistoryDegradationFactor
SSVCADistanceResultSampleCountTolerance
SSVCAMusicHistoricalSamplesInSeconds
SSVCADeviceSimpleOutputMinTargetDB
SSVCADeviceSimpleOutputMaxTargetDB
SSVCADeviceSimpleOutputSlope
SSVCADeviceSimpleMinTargetDB
SSVCADeviceSimpleMaxTargetDB
SSVCADeviceSimpleDBToSystemVolSlope
SSVCADeviceSimpleMicSensitivityOffset
SSVCADeviceSimplePreTriggerSilenceSampleCount
SSVCAMinTTSSystemVolume
SSVCAMaxTTSSystemVolume
SSVCAUserIntentValidForSeconds
SSVCAUserIntentVolumeIncreaseFactor
SSVCAUserIntentVolumeDecreaseFactor
SSVCAUserIntentPermanentOffsetFactorDelta
SSVCAUserIntentPermanentOffsetFactorLowerBound
SSVCAUserIntentPermanentOffsetFactorUpperBound
SSVCADeviceSimpleMinTTSVolume
SSVCADeviceSimpleMaxTTSVolume
SSVCADeviceDefaultMinTTSVolume
SSVCADeviceDefaultMaxTTSVolume
SSVCADeviceDefaultASVOffMinTTSVolume
SSVCADeviceSimpleASVOffMinTTSVolume
SSVCADeviceDefaultMicSensitivityOffset
SSVCAVolumeHalfLifeSeconds
SSVCAHistoricalVolumeBufferSize
SSVCAMaximumCompensatedSpeechLevelNearField
SSVParameterDirectionary
SSVDefaultNoiseChannelCount
SSVDefaultLKFSChannelCount
SSVDefaultDistanceChannelCount
getSSVDeviceType
TI,R,N
Tf,R,N
Ti,R,N
Td,R,N
programmableAudioInjectionEnabled
containsValueForKey:
initWithData:hash:locale:digest:signature:certificate:
stringByAppendingString:
base64EncodedStringWithOptions:
substringToIndex:
initWithHash:locale:
initWithData:hash:locale:
builtInRTModelDictionary
modelData
modelLocale
modelHash
digest
signature
certificate
_modelData
_modelLocale
_modelHash
_digest
_signature
_certificate
T@"NSData",R,N,V_modelData
T@"NSString",R,N,V_modelLocale
T@"NSString",R,N,V_modelHash
T@"NSData",R,N,V_digest
T@"NSData",R,N,V_signature
T@"NSData",R,N,V_certificate
getFixedPrioritySerialQueueWithLabel:fixedPriority:
setStreamState:
initWithRecordContext:deviceId:shouldUseRemoteRecorder:streamHandleId:
converterForAudioStreamId:
inputRecordingNumberOfChannels
inputRecordingDurationInSecs
initWithNumChannels:recordingDuration:samplingRate:audioTimeConverter:
_holdRecordingExceptionIfNeeded:
_updateRemoteDeviceIdFromAVVCIfNeeded
_streamStateName:
setProviderDelegate:
_setLatestRecordContext:
updateWithLatestRecordContext:
recordDeviceIndicator
isRecordingWithRecordDeviceIndicator:
_canSetContext
audioStreamHandleId
setCurrentContext:streamHandleId:error:
_prepareAudioStreamSync:request:error:
requiresHistoricalBuffer
historicalBufferRequestStreams
_audioStreamWithRequest:streamName:error:
tandemStreams
updateAudioStreamStartTimeInSampleCount:
scheduledFutureSample
setScheduledFutureSample:
startStreamOption
setStartStreamOption:
setStreamRequest:
_handleAudioSystemFailure
prepareAudioStreamRecord:recordDeviceIndicator:error:
isLocalVoiceTriggerAvailable
voiceTriggerInfoWithRecordDeviceIndicator:
setVoiceTriggerInfo:deviceId:
_startAudioStream:option:completion:
_prepareAudioStream:request:completion:
startPendingOnStoppingStreams
startPendingOnStoppingStreamToCompletionDict
sampleCount
_didPlayStartAlertSoundForSiri:audioStream:
alertPlaybackFinishWaitingStreams
alertPlaybackFinishWaitingCompletions
_scheduleAlertFinishTimeout:
isSiri
_switchToRecordingMode
circularBufferStartHostTime
circularBufferStartSampleCount
sampleCountFromHostTime:anchorHostTime:anchorSampleCount:sampleRate:
startPendingStreams
pendingStartCompletions
_holdRecordingTransactionIfNeeded
initWithSampleRate:withNumberOfChannels:
recordingSampleRateWithStreamHandleId:
resetWithSampleRate:containsVoiceTrigger:voiceTriggerInfo:
startAudioStreamWithOption:recordDeviceIndicator:error:
_scheduleAudioPacketWatchDog
_scheduleDidStartRecordingDelegateWatchDog
_resetCircularBufferStartTime
setCircularBufferStartHostTime:
setCircularBufferStartSampleCount:
supportOpportunisticZLL
streams
_deliverHistoricalAudioToStreamsWithRemoteVAD:
setRecordMode:streamHandleId:error:
_cancelAudioPacketWatchDog
_clearDidStartRecordingDelegateWatchDog
_releaseRecordingTransactionIfNeeded
flush
_clearDidStopRecordingDelegateWatchDog
_preEpilogueAudioStream
stopPendingStreams
isWeakStream
pendingStopCompletions
_postEpilogueAudioStream
_shouldHandleStartPendingOnStopping:withStopReason:
objectEnumerator
_stopAudioStream:option:completion:
audioPreprocessor
reportMetricsForSiriRequestWithUUID:
_cs_isHashTableEmpty
_shouldStopRecording
_scheduleDidStopRecordingDelegateWatchDog
stopAudioStreamWithRecordDeviceIndicator:error:
_switchToListeningMode
_audioChunkFrom:to:
_audioChunkFrom:to:channelIdx:
copySamplesFrom:to:
copySamplesFrom:to:channelIdx:
_saveRecordingBufferFrom:to:toURL:
saveAudioChunck:toURL:
streamHolders
recordRouteWithRecordDeviceIndicator:
recordDeviceInfoWithStreamHandleId:recordDeviceIndicator:
audioDeviceInfoWithStreamHandleId:recordDeviceIndicator:
recordSettingsWithStreamHandleId:
setSessionDelegate:
prewarmAudioSessionWithStreamHandleId:error:
_activateAudioSessionWithReason:error:
activateAudioSessionWithReason:streamHandleId:error:
supportNonInterruptibleSiri
setDuckOthersForStream:
_deactivateAudioSession:error:
deactivateAudioSession:streamHandleId:error:
enableSmartRoutingConsiderationForStream:enable:
setAlertDelegate:
playAlertSoundForType:recordDevideIndicator:
playRecordStartingAlertAndResetEndpointerFromStream:
willBeepWithRecordRoute:playbackRoute:
metrics
isVoiceTriggerInfoAvailableLocally:
_processAudioBuffer:remoteVAD:atTime:arrivalTimestampToAudioRecorder:numberOfChannels:
_handleDidStartAudioStreamWithResult:error:
_handleDidStopAudioStreamWithReason:
sessionDelegate
providerDelegate
audioProviderInvalidated:streamHandleId:
bufferLength
lastForwardedSampleCount
_fetchHistoricalAudioAndForwardToStream:remoteVAD:
setRemoteVAD:
audioStreamProvider:audioBufferAvailable:lastForwardedSampleCount:
addSamples:numSamples:atHostTime:
processSampleCount:hostTime:
inputRecordingSampleByteDepth
initWithData:numChannels:numSamples:sampleByteDepth:startSampleCount:hostTime:arrivalHostTimeToAudioRecorder:wasBuffered:remoteVAD:
_forwardAudioChunk:toStream:
chunkForChannel:
secondsToHostTime:
processBuffer:atTime:arrivalTimestampToAudioRecorder:
audioInjectionEnabled
_forwardAudioChunkForTV:toStream:
isNarrowBandWithStreamHandleId:
_didReceiveFinishStartAlertPlaybackAt:
alertDelegate
willDestroy
initWithName:clientQueue:
initWithDescription:
isSessionCurrentlyActivated
beginAnnounceMessageException:reason:
endAnnounceMessageException:reason:
_onAudioPacketWatchdogFire
_schduleDidStartRecordingDelegateWatchDogWithToken:
_scheduleDidStopRecordingDelegateWatchDog:
audioPreprocessor:hasAvailableBuffer:atTime:arrivalTimestampToAudioRecorder:numberOfChannels:
initWithAudioStreamHandleId:audioStreamType:audioRecordContext:audioRecorder:
setAudioProviderDelegate:
setLatestRecordContext:streamType:
_tearDownCircularBufferIfNeeded
notifyProviderContextChanged
recordQueue
setRecordQueue:
loggingQueue
setLoggingQueue:
streamHandleQueue
setStreamHandleQueue:
streamState
setStartPendingStreams:
setStartPendingOnStoppingStreams:
setAlertPlaybackFinishWaitingStreams:
setStreams:
setStopPendingStreams:
setPendingStartCompletions:
setAlertPlaybackFinishWaitingCompletions:
setPendingStopCompletions:
setStartPendingOnStoppingStreamToCompletionDict:
setStreamHolders:
setHistoricalBufferRequestStreams:
circularBuffer
setCircularBuffer:
lastAudioRecorderContext
setLastAudioRecorderContext:
audioSystemRecovering
setAudioSystemRecovering:
setAudioPreprocessor:
recordingTransaction
setRecordingTransaction:
recordingWillStartGroup
setRecordingWillStartGroup:
waitingForAlertFinish
setWaitingForAlertFinish:
setAudioStreamHandleId:
alertPlaybackFinishTimeoutToken
setAlertPlaybackFinishTimeoutToken:
startRecordingWatchDogToken
setStartRecordingWatchDogToken:
stopRecordingWatchDogToken
setStopRecordingWatchDogToken:
audioPacketWatchdog
setAudioPacketWatchdog:
audioTimeConverter
setAudioTimeConverter:
audioStreamType
setAudioStreamType:
setRecordDeviceIndicator:
micUsageReporter
setMicUsageReporter:
audioPacketDeliveryCount
setAudioPacketDeliveryCount:
adpAssertion
setAdpAssertion:
_audioSystemRecovering
_waitingForAlertFinish
_recordQueue
_loggingQueue
_streamHandleQueue
_streamState
_startPendingStreams
_startPendingOnStoppingStreams
_alertPlaybackFinishWaitingStreams
_streams
_stopPendingStreams
_pendingStartCompletions
_alertPlaybackFinishWaitingCompletions
_pendingStopCompletions
_startPendingOnStoppingStreamToCompletionDict
_providerDelegate
_sessionDelegate
_streamHolders
_historicalBufferRequestStreams
_circularBuffer
_alertDelegate
_lastAudioRecorderContext
_audioPreprocessor
_recordingTransaction
_recordingWillStartGroup
_audioStreamHandleId
_alertPlaybackFinishTimeoutToken
_startRecordingWatchDogToken
_stopRecordingWatchDogToken
_audioPacketWatchdog
_circularBufferStartHostTime
_circularBufferStartSampleCount
_audioTimeConverter
_audioStreamType
_recordDeviceIndicator
_micUsageReporter
_audioPacketDeliveryCount
_adpAssertion
T@"NSObject<OS_dispatch_queue>",&,N,V_recordQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_loggingQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_streamHandleQueue
TQ,N,V_streamState
T@"NSHashTable",&,N,V_startPendingStreams
T@"NSHashTable",&,N,V_startPendingOnStoppingStreams
T@"NSHashTable",&,N,V_alertPlaybackFinishWaitingStreams
T@"NSHashTable",&,N,V_streams
T@"NSHashTable",&,N,V_stopPendingStreams
T@"NSMutableArray",&,N,V_pendingStartCompletions
T@"NSMutableArray",&,N,V_alertPlaybackFinishWaitingCompletions
T@"NSMutableArray",&,N,V_pendingStopCompletions
T@"NSMutableDictionary",&,N,V_startPendingOnStoppingStreamToCompletionDict
T@"<CSAudioProviderDelegate>",W,N,V_providerDelegate
T@"<CSAudioSessionProvidingDelegate>",W,N,V_sessionDelegate
T@"NSMutableArray",&,N,V_streamHolders
T@"NSHashTable",&,N,V_historicalBufferRequestStreams
T@"CSAudioCircularBuffer",&,N,V_circularBuffer
T@"<CSAudioAlertProvidingDelegate>",W,N,V_alertDelegate
T@"CSAudioRecordContext",&,N,V_lastAudioRecorderContext
TB,N,V_audioSystemRecovering
T@"CSAudioPreprocessor",&,N,V_audioPreprocessor
T@"CSOSTransaction",&,N,V_recordingTransaction
T@"NSObject<OS_dispatch_group>",&,N,V_recordingWillStartGroup
TB,N,V_waitingForAlertFinish
TQ,N,V_audioStreamHandleId
T@"NSUUID",&,N,V_alertPlaybackFinishTimeoutToken
T@"NSUUID",&,N,V_startRecordingWatchDogToken
T@"NSUUID",&,N,V_stopRecordingWatchDogToken
T@"NSObject<OS_dispatch_source>",&,N,V_audioPacketWatchdog
TQ,N,V_circularBufferStartHostTime
TQ,N,V_circularBufferStartSampleCount
T@"CSAudioTimeConverter",&,N,V_audioTimeConverter
Tq,N,V_audioStreamType
T@"CSAudioRecordDeviceIndicator",&,N,V_recordDeviceIndicator
T@"CSMicUsageReporter",&,N,V_micUsageReporter
TQ,N,V_audioPacketDeliveryCount
T@"CSADPPreventStandbyAssertion",&,N,V_adpAssertion
initWithAppBundleIdentifier:
initWithTaskDeliverer:
initWithMessage:makeAppFrontmost:
handleSiriRequest:deliveryHandler:completionHandler:
launchSiriDebugAppWithMessage:
allowVoiceTriggerAssetDownloading
setAllowVoiceTriggerAssetDownloading:
allowEndpointAssetDownloading
setAllowEndpointAssetDownloading:
allowLanguageDetectorAssetDownloading
setAllowLanguageDetectorAssetDownloading:
allowAdBlockerAssetDownloading
setAllowAdBlockerAssetDownloading:
allowSpeakerRecognitionAssetDownloading
setAllowSpeakerRecognitionAssetDownloading:
allowVoiceTriggerAccessoryAssetDownloading
setAllowVoiceTriggerAccessoryAssetDownloading:
_allowVoiceTriggerAssetDownloading
_allowEndpointAssetDownloading
_allowLanguageDetectorAssetDownloading
_allowAdBlockerAssetDownloading
_allowSpeakerRecognitionAssetDownloading
_allowVoiceTriggerAccessoryAssetDownloading
TB,N,V_allowVoiceTriggerAssetDownloading
TB,N,V_allowEndpointAssetDownloading
TB,N,V_allowLanguageDetectorAssetDownloading
TB,N,V_allowAdBlockerAssetDownloading
TB,N,V_allowSpeakerRecognitionAssetDownloading
TB,N,V_allowVoiceTriggerAccessoryAssetDownloading
_sharedDisposeLoggingQueue
dateWithTimeIntervalSinceNow:
distantFuture
getResourceValue:forKey:error:
compare:
removeItemAtURL:error:
URLsInDirectory:matchingPattern:completion:
_sortedURLsInDirectory:matchingPattern:completion:
_contentsOfDirectoryAtURL:matchingPattern:includingPropertiesForKeys:error:
sortedArrayUsingComparator:
regularExpressionWithPattern:options:error:
contentsOfDirectoryAtURL:includingPropertiesForKeys:options:error:
lastPathComponent
numberOfMatchesInString:options:range:
removeLogFilesInDirectory:matchingPattern:beforeDays:
clearLogFilesInDirectory:matchingPattern:exceedNumber:
initWithTimeout:
_addVoiceTriggerEnabledConditions
isPresent
isSpringboardStarted
batteryState
isScreenLocked
isSoftwareUpdateCheckingRunning
supportHangUp
phoneCallState
hearstConnected
splitterState
preheat
endpointStyle
setEndpointStyle:
delay
setDelay:
startWaitTime
automaticEndpointingSuspensionEndTime
minimumDurationForEndpointer
setMinimumDurationForEndpointer:
lastEndOfVoiceActivityTime
lastStartOfVoiceActivityTime
bypassSamples
setBypassSamples:
endpointMode
setEndpointMode:
interspeechWaitTime
setInterspeechWaitTime:
endWaitTime
saveSamplesSeenInReset
setSaveSamplesSeenInReset:
Tq,N
Td,N
resetForNewRequestWithSampleRate:recordContext:
implDelegate
setImplDelegate:
canProcessCurrentRequest
logFeaturesWithEvent:locale:
handleVoiceTriggerWithActivationInfo:
T@"<CSEndpointAnalyzerDelegate>",W,N
T@"<CSEndpointAnalyzerImplDelegate>",W,N
TQ,N
T@"<CSEndpointAnalyzerDelegate>",W,N,Vdelegate
T@"<CSEndpointAnalyzerImplDelegate>",W,N,VimplDelegate
TB,R,N,VcanProcessCurrentRequest
TQ,N,VactiveChannel
Tq,N,VendpointStyle
Td,N,Vdelay
Td,N,VstartWaitTime
Td,N,VautomaticEndpointingSuspensionEndTime
Td,N,VminimumDurationForEndpointer
Td,R,N,VlastEndOfVoiceActivityTime
Td,R,N,VlastStartOfVoiceActivityTime
T@"NSString",&,N,VmhId
startObserving
getLastBiometricMatchEvent:atTime:
getBiometricMatchResultForTriggerTimeStamp:
T@"<CSBiometricMatchMonitorDelegate>",W,N,V_delegate
_startObservingSpeechDetectionVADPresence
handleSpeechDetectionVADPresentChange:
_systemControllerDied:
phraseId
setPhraseId:
bestPhrase
setBestPhrase:
isEarlyWarning
setIsEarlyWarning:
isRescoring
setIsRescoring:
samplesAtFire
setSamplesAtFire:
setStartSampleCount:
_isEarlyWarning
_isRescoring
_phraseId
_bestPhrase
_samplesAtFire
_startSampleCount
TQ,N,V_phraseId
TQ,N,V_bestPhrase
TB,N,V_isEarlyWarning
TB,N,V_isRescoring
TQ,N,V_samplesAtFire
TQ,N,V_startSampleCount
initWithConfigPath:resourcePath:
_resetStartAnalyzeTime
resetBest
_setStartAnalyzeTime:
analyzeWavFloatData:numSamples:
analyzeWavData:numSamples:
getAnalyzedResultForPhraseId:
sampleFed
getAnalyzedMpVtResults
keywordAnalyzerNDAPI:hasMpVtResultsAvailable:forChannel:
getAnalyzedResult
keywordAnalyzerNDAPI:hasResultAvailable:forChannel:
earlyWarning
_keywordAnalyzerNDAPIResultForPhraseId:withNovDetectorResult:
numResultsAvailable
setObject:atIndexedSubscript:
getSuperVectorWithEndPoint:
getOptionValue:
getThreshold
getLoggingThreshold
getRejectLoggingThreshold
activePhraseId
setActivePhraseId:
_novDetector
_startAnalyzeSampleCount
_isStartSampleCountMarked
_lastSampleFed
_sampleFedWrapAroundOffset
_activePhraseId
TI,N,V_activePhraseId
T@"<CSKeywordAnalyzerNDAPIScoreDelegate>",W,N,V_delegate
createRTModelWithLocale:
hearstRTModelWithMajorVersion:minorVersion:locale:
dataWithContentsOfFile:
_sha1:
substringWithRange:
_sha256:
rtModelWithAccessoryRTModelType:majorVersion:minorVersion:locale:
localeMapWithName:
remoraRTModelLocaleMap
hearstRTModelLocaleMap
stringWithCapacity:
RTModelWithFallbackLanguage:
latestHearstRTModelForLocale:
remoraRTModelWithMajorVersion:minorVersion:locale:
jarvisRTModelLocaleMap
rtModelLocaleMapWithModelType:
isDefaultInputBuiltInMic
isDefaultOutputBultInSpeaker
defaultOutputAudioDeviceID
isTriggerHandheld
wakeGestureTimestamp
setWakeGestureTimestamp:
dismissalTimestamp
setDismissalTimestamp:
_wakeGestureTimestamp
_dismissalTimestamp
TQ,N,V_wakeGestureTimestamp
TQ,N,V_dismissalTimestamp
_fetchHearstConnectionState
_notifyHearstConnectionState:
_fetchJarvisConnectionState
_notifyJarvisConnectionState:
_startObservingAudioRouteChange
CSAudioRouteChangeMonitor:didReceiveAudioRouteChangeEvent:
preferredExternalRouteDidChange:
carPlayAuxStreamSupportDidChange:
carPlayIsConnectedDidChange:
getHearstConnected:
getJarvisConnected:
jarvisConnected
carPlayConnected
_isHearstConnected
_isJarvisConnected
activationMode
activationDeviceUID
announceCallsEnabled
streamID
startHostTime
startAlert
stopAlert
stopOnErrorAlert
skipAlert
remoteVoiceActivityAvailable
remoteVoiceActivityVAD
dataWithBytes:length:
remoteVoiceActivityVADBuffer
getSerialQueue:qualityOfService:
_voiceControllerWithError:
_destroyVoiceController
_audioRecorderDidStartRecordingSuccessfully:streamHandleID:error:
setRecordDelegate:
initWithError:
setSynchronousCallbackEnabled:
setContext:streamType:error:
timeIntervalSinceDate:
setContextForStream:forStream:error:
_getRecordSettingsWithRequest:
shouldUseRemoteRecorder
streamHandleId
_fetchRemoteRecordClientWithDeviceId:streamHandleId:
waitingForConnection:error:
inputRecordingBufferDuration
initWithStreamID:settings:bufferDuration:
prepareRecordForStream:error:
_logResourceNotAvailableErrorIfNeeded:
_shouldInjectAudio
_needResetAudioInjectionIndex:
audioInjectionFilePath
URLWithString:
initWithURL:
setRecordBufferDuration:
requestForLpcmRecordSettingsWithContext:
prepareRecording:
avvcContext
hasPendingTwoShotBeep
_hasLocalPendingTwoShot
playAlertSoundForType:overrideMode:
isRecordContextVoiceTrigger:
contextForBuiltInVoiceTrigger
startRecordingWithOptions:error:
_startAudioStreamForAudioInjectionWithAVVCContext:
startRecordForStream:error:
stopRecording:
stopRecordForStream:error:
getCurrentSessionState
getCurrentStreamState:
isRemoteDeviceGibraltar
getRecordDeviceInfoForStream:
initWithAVVCRecordDeviceInfo:
currentRoute
outputs
endpointType
initWithRecordDeviceInfo:playbackRoute:playbackDeviceTypeList:
getRecordSettingsForStream:
isUpsamplingSourceAudio
activateAudioSessionForStream:isPrewarm:error:
_shouldLogResourceNotAvailableError
activateAudioSessionForStream:isPrewarm:recordMode:error:
_convertDeactivateOption:
deactivateAudioSessionWithOptions:
deactivateAudioSessionForStream:withOptions:error:
setIAmTheAssistant:error:
enableSmartRoutingConsiderationForStream:enable:error:
initWithDuckOthers:duckToLevel:mixWithOthers:
setDuckOverride:
setDuckOthersForStream:withSettings:error:
_updateLanguageCodeForRemoteVTEIResult:
voiceTriggerInfo
channels
packetDescriptionCount
bytesDataSize
initWithCapacity:
packetDescriptions
initWithBytes:length:
setPackets:
updateMeterForStream:
getPeakPowerForStream:forChannel:
getAveragePowerForStream:forChannel:
setPeakPower:
setAvgPower:
setTimeStamp:
setNumChannels:
streamDescription
setAudioFormat:
setStreamHandleID:
_compensateChannelDataIfNeeded:receivedNumChannels:
timeStamp
_processAudioChain:audioStreamHandleId:remoteVAD:atTime:arrivalTimestampToAudioRecorder:numberOfChannels:
opusASBD
lpcmInt16ASBD
addPackets:audioStreamHandleId:remoteVAD:timestamp:arrivalTimestampToAudioRecorder:wasBuffered:receivedNumChannels:
initWithLength:
replaceBytesInRange:withBytes:
didPlayEndpointBeep
_processAudioBuffer:audioStreamHandleId:arrivalTimestampToAudioRecorder:
_audioRecorderDidStopRecordingForReason:streamHandleID:
audioSessionEventProvidingWillSetAudioSessionActive:
audioSessionEventProvidingDidSetAudioSessionActive:
convertToFloatLPCMBufFromShortLPCMBuf:
triggerNotifiedMachTime
useCustomizedRecordSettings
defaultRequestWithContext:
audioFormat
numberOfChannels
sampleRate
lpcmBitDepth
lpcmIsFloat
encoderBitRate
initWithDeviceId:audioStreamHandleId:
createSharedAudioSession
voiceControllerDidStartRecording:successfully:
voiceControllerDidStartRecording:successfully:error:
voiceControllerDidStopRecording:forReason:
voiceControllerDidDetectStartpoint:
voiceControllerDidDetectEndpoint:ofType:
voiceControllerDidDetectEndpoint:ofType:atTime:
voiceControllerEncoderErrorDidOccur:error:
voiceControllerDidFinishAlertPlayback:ofType:error:
voiceControllerDidFinishAlertPlayback:withSettings:error:
voiceControllerRecordHardwareConfigurationDidChange:toConfiguration:
voiceControllerBeginRecordInterruption:
voiceControllerBeginRecordInterruption:withContext:
voiceControllerEndRecordInterruption:
voiceControllerMediaServicesWereLost:
voiceControllerMediaServicesWereReset:
voiceControllerWillSetAudioSessionActive:willActivate:
voiceControllerDidSetAudioSessionActive:isActivated:
voiceControllerRecordBufferAvailable:buffer:
voiceControllerLPCMRecordBufferAvailable:buffer:
voiceControllerWirelessSplitterRouteAvailable:devices:
voiceControllerDidStartRecording:forStream:successfully:error:
voiceControllerDidStopRecording:forStream:forReason:
voiceControllerAudioCallback:forStream:buffer:
voiceControllerLPCMAudioCallback:forStream:buffer:
voiceControllerStreamInvalidated:forStream:
audioDecoderDidDecodePackets:audioStreamHandleId:buffer:remoteVAD:timestamp:arrivalTimestampToAudioRecorder:wasBuffered:receivedNumChannels:
audioFileReaderBufferAvailable:buffer:atTime:
audioFileReaderDidStartRecording:successfully:error:
audioFileReaderDidStopRecording:forReason:
remoteRecordDidStartRecordingWithStreamHandleId:error:
remoteRecordDidStopRecordingWithWithStreamHandleId:error:
remoteRecordLPCMBufferAvailable:streamHandleId:
remoteRecordTwoShotDetectedAtTime:
remoteRecordConnectionDisconnected:
setAudioServerCrashEventDelegate:
setAudioSessionEventDelegate:
initWithQueue:error:
setContext:completion:
setMixWithOthersForStream:
configureAlertBehavior:audioStreamHandleId:
_shouldUseRemoteBuiltInMic:
voiceControllerCreationQueue
setVoiceControllerCreationQueue:
crashEventDelegate
setCrashEventDelegate:
sessionEventDelegate
setSessionEventDelegate:
_voiceController
_interleavedABL
_pNonInterleavedABL
_remoteRecordClient
_opusDecoders
_audioFileReader
_audioFilePathIndex
_waitingForDidStart
_pendingTwoShotVTToken
_voiceControllerCreationQueue
_crashEventDelegate
_sessionEventDelegate
T@"NSObject<OS_dispatch_queue>",&,N,V_voiceControllerCreationQueue
T@"<CSAudioServerCrashEventProvidingDelegate>",W,N,V_crashEventDelegate
T@"<CSAudioSessionEventProvidingDelegate>",W,N,V_sessionEventDelegate
setPrimaryStream:
initTandemWithRequest:
primaryStream
initWithMasterAudioStream:name:
attachToPrimaryStreamWithCompletion:
prepareAudioStreamWithRequest:completion:
_primaryStream
T@"CSAudioStream",W,N,V_primaryStream
initWithAnalyzeMode
fileLoggingIsEnabled
lpcmNonInterleavedWithRemoteVADASBD
lpcmInterleavedWithRemoteVADASBD
createAudioFileWriterForOpportuneSpeakListenerWithInputFormat:outputFormat:
contextForHearstVoiceTriggerWithDeviceId:
opportuneSpeakListeningType
contextForOpportuneSpeakerListener
contextForOpportuneSpeakerListenerWithCall
_resetAlignBuffer
_startRequestWithCompletion:
setRequiresHistoricalBuffer:
getFrameDurationMs
remoteVADDuration
supportsUnderstandingOnDevice
preheatLocalSpeechRecognitionWithLanguage:source:
stopListenWithStateReset:completion:
gainCompensatedChunk
channelForProcessedInput
addAudio:numSamples:
remoteVAD
opportuneSpeakListenerBypassEnabled
_addRemoteVADSignal:
dataWithRemoteVADWithScaleFactor:numAudioSamplesPerRemoteVAD:
removeObjectAtIndex:
_shouldReportBoron
_popRemoteVADSignal
spgEndpointAnalyzer:hasSilenceScoreEstimate:clientProcessedAudioTimeMS:
spgEndpointAnalyzer
setSpgEndpointAnalyzer:
remoteVADSPGRatio
setRemoteVADSPGRatio:
audioStreamProvider
setAudioStreamProvider:
audioSessionProvider
setAudioSessionProvider:
latestContext
setLatestContext:
isMediaPlayingNow
setIsMediaPlayingNow:
remoteVADAlignBuffer
setRemoteVADAlignBuffer:
remoteVADAlignCount
setRemoteVADAlignCount:
alignBufferQueue
setAlignBufferQueue:
audioFileWriter
setAudioFileWriter:
runningSampleCount
setRunningSampleCount:
_isMediaPlayingNow
_remoteVADSPGRatio
_spgEndpointAnalyzer
_audioStreamProvider
_audioSessionProvider
_latestContext
_remoteVADAlignBuffer
_remoteVADAlignCount
_alignBufferQueue
_audioFileWriter
_runningSampleCount
T@"CSSPGEndpointAnalyzer",&,N,V_spgEndpointAnalyzer
Ti,N,V_remoteVADSPGRatio
T@"<CSAudioStreamProviding>",&,N,V_audioStreamProvider
T@"<CSAudioSessionProviding>",&,N,V_audioSessionProvider
T@"CSAudioRecordContext",&,N,V_latestContext
TB,V_isMediaPlayingNow
T@"NSMutableArray",&,N,V_remoteVADAlignBuffer
TQ,N,V_remoteVADAlignCount
T@"NSObject<OS_dispatch_queue>",&,N,V_alignBufferQueue
T@"CSPlainAudioFileWriter",&,N,V_audioFileWriter
TQ,N,V_runningSampleCount
T@"<CSOpportuneSpeakListenerDelegate>",W,N,V_delegate
CSSiriEnabledMonitor:didReceiveEnabled:
_didReceiveSiriSettingChanged:
fetchIsEnabled
_isSiriEnabled
_attachBluetoothSession
_getWirelessSplitterInfoFromLocalDevice:
getBTLocalDeviceWithCompletion:
setSplitterEnabled:
setAddress:
setSupportDoAP:
setIsTemporaryPairedNotInContacts:
addDeviceIntoSplitterDeviceList:
_tearDownLocalDevice
_detachBluetoothSession
_setUpLocalDevice
getWirelessSplitterInfoWithCompletion:
device:serviceMask:serviceEventType:serviceSpecificEvent:result:
_sessionAttached:result:
_sessionDetached:
_sessionTerminated:
localDevice:event:result:
bluetoothSession
setBluetoothSession:
isAttachingBluetoothSession
setIsAttachingBluetoothSession:
localDevice
setLocalDevice:
pairedDeviceAddresses
setPairedDeviceAddresses:
connectedDeviceAddresses
setConnectedDeviceAddresses:
bluetoothSessionSetupGroup
setBluetoothSessionSetupGroup:
_isAttachingBluetoothSession
_bluetoothSession
_localDevice
_pairedDeviceAddresses
_connectedDeviceAddresses
_bluetoothSessionSetupGroup
T^{BTSessionImpl=},N,V_bluetoothSession
TB,N,V_isAttachingBluetoothSession
T^{BTLocalDeviceImpl=},N,V_localDevice
T@"NSArray",&,N,V_pairedDeviceAddresses
T@"NSArray",&,N,V_connectedDeviceAddresses
T@"NSObject<OS_dispatch_group>",&,N,V_bluetoothSessionSetupGroup
triggerModeStringDescription:
setTriggerMode:
getTriggerMode
CSActivationXPCConnectionReceivedClientError:clientError:client:
initWithStreamHandleId:
initWithConfigFile:configRoot:sampleRate:delegate:queue:
resetForNewRequest
_setupAudioInjectionEngineWithAudioURL:
initWithConfigFile:sampleRate:context:queue:delegate:
initWithData:numChannels:numSamples:sampleByteDepth:startSampleCount:hostTime:remoteVAD:
addAudio:
getLatestSuperVector
lpcmInterleavedASBD
stopAudioStream
injectAudio:withScaleFactor:outASBD:playbackStarted:completion:
startAudioStreamWithOption:
audioEngineDidStartRecord:audioStreamHandleId:successfully:error:
audioEngineDidStopRecord:audioStreamHandleId:reason:
audioEngineBufferAvailable:audioStreamHandleId:buffer:remoteVAD:atTime:
audioEngineAudioChunkForTvAvailable:audioChunk:
vtSecondPassAnalyzer
setVtSecondPassAnalyzer:
psrAudioProcessor
setPsrAudioProcessor:
osdAnalyzer
setOsdAnalyzer:
completion
setCompletion:
audioInjectionEngine
setAudioInjectionEngine:
modelExeQueue
setModelExeQueue:
_vtSecondPassAnalyzer
_psrAudioProcessor
_osdAnalyzer
_completion
_audioInjectionEngine
_modelExeQueue
T@"CSSyncKeywordAnalyzerQuasar",&,N,V_vtSecondPassAnalyzer
T@"EARSyncPSRAudioProcessor",&,N,V_psrAudioProcessor
T@"OSDAnalyzer",&,N,V_osdAnalyzer
T@?,C,N,V_completion
T@"CSAudioInjectionEngine",&,N,V_audioInjectionEngine
T@"NSObject<OS_dispatch_queue>",&,N,V_modelExeQueue
initWithProtocolVersion:buildVersion:deviceProductVersion:deviceProductType:deviceCategory:
deviceBuildVersion
deviceProductVersion
deviceProductType
hasRemoteBuiltInMic
defaultProtocolInfo
localDeviceProtocolInfo
protocolVersion
buildVersion
deviceCategory
_protocolVersion
_buildVersion
_deviceProductVersion
_deviceProductType
_deviceCategory
TQ,R,N,V_protocolVersion
T@"NSString",R,N,V_buildVersion
T@"NSString",R,N,V_deviceProductVersion
T@"NSString",R,N,V_deviceProductType
TQ,R,N,V_deviceCategory
getAssetTypeForNamespace:
getTrialIdsForAssetType:withCompletion:
_handleSessionIDRequestMessage:messageBody:client:
audioSessionInfoProvider
setAudioSessionInfoProvider:
_audioSessionInfoProvider
T@"<CSAudioSessionInfoProviding>",W,N,V_audioSessionInfoProvider
supportSmartVolume
getVolumeForTTSType:withContext:reply:
setSmartSiriVolumePercentage:
setSmartSiriVolumeDirection:
setPermanentVolumeOffsetWithDirection:
didTTSVolumeChangeForReason:
initWithMachService:withServiceInterface:withServiceObject:withDelegateInterface:
setListenerDelegate:
resumeConnection
createSmartSiriVolumeListener
getVoiceTriggerAssetTypeString
getEndpointAssetTypeString
getLanguageDetectorAssetTypeString
getAdBlockerAssetTypeString
getSpeakerRecognitionAssetTypeString
_cleanUpMobileAssetV1Directory
_isReadyToUse
installedAssetOfType:withLanguage:
_fetchRemoteAssetOfType:withLanguage:completion:
_assetQueryForAssetType:
returnTypes:
queryMetaDataSync
results
filteredAssetsForAssets:assetType:language:
queryParams
isLatestCompareTo:
state
getCSAssetOfType:
installedAssetOfType:withLanguage:completion:
addKeyValuePair:with:
addKeyValuePairForQuery:assetType:
_installedAssetOfType:query:withLanguage:completion:
_fetchRemoteAssetOfType:withLanguage:query:completion:
_installedAssetOfType:withLanguage:
_installedAssetOfType:withLanguage:completion:
_findLatestInstalledAsset:
queryMetaData:
attributes
fetchRemoteMetaOfType:allowRetry:
_runAssetQuery:completion:
_downloadAssetCatalogForAssetType:complete:
_updateFromRemoteToLocalAssets:forAssetType:completion:
_defaultDownloadOptions
_isRetryRecommendedWithResult:
startCatalogDownload:options:then:
isCSAssetInstalled
isDownloading
cancelDownloadSync
canBePurged
purgeSync
CSAssetController:didDownloadNewAssetForType:
_downloadAsset:withComplete:
setAllowsCellularAccess:
setCanUseLocalCacheServer:
setDiscretionary:
assetServerUrl
_startDownloadingAsset:progress:completion:
expectedTimeRemaining
totalWritten
totalExpected
attachProgressCallBack:
spaceCheck:
startDownload:then:
getAssetTypeStringForType:
CSEventMonitorDidReceiveEvent:
assetOfType:language:
assetOfType:language:compatibilityVersion:completion:
installedAssetOfType:language:
installedAssetOfType:language:completion:
fetchRemoteMetaOfType:
addObserver:forAssetType:
removeObserver:forAssetType:
assetsMigrationQueue
setAssetsMigrationQueue:
csAssetsDictionary
setCsAssetsDictionary:
_assetsMigrationQueue
_csAssetsDictionary
T@"NSObject<OS_dispatch_queue>",&,N,V_assetsMigrationQueue
T@"NSDictionary",&,N,V_csAssetsDictionary
T@"NSMutableDictionary",&,N,V_observers
valueForKey:
supportPremiumAssets
getVoiceTriggerAssetCurrentCompatibilityVersion
getEndpointAssetCurrentCompatibilityVersion
getLanguageDetectorCurrentCompatibilityVersion
getAdBlockerCurrentCompatibilityVersion
getSpeakerRecognitionCurrentCompatibilityVersion
filteredAssetsForFetchRemoteMetaDataForAssets:assetType:
lowercaseString
setAssetDownloadingOption:
_loadAndSetupEndpointerAssetIfNecessary
initWithSilenceFramesCountMs:silenceProbability:silenceDurationMs:processedAudioMs:
assetForCurrentLanguageOfType:
_readParametersFromHEPAsset:
initWithConfiguration:modelVersion:
submitEndpointerIssueReport:
subChunkFrom:numSamples:forChannel:
updateEndpointerThresholdWithValue:
updateEndpointerDelayedTriggerSwitch:
silenceFramesCountMs
silenceProbability
silenceDurationMs
initWithWordCount:trailingSilenceDuration:endOfSentenceLikelihood:pauseCounts:silencePosterior:clientSilenceFramesCountMs:clientSilenceProbability:silencePosteriorNF:serverFeaturesLatency:eagerResultEndTime:
acceptEagerResultWithFeatures:featuresToLog:
processedAudioMs
supportPhatic
_shouldUsePhaticWithRecordContext
_multimodalEndpointerEnabled
defaultServerEndpointFeatures
endOfSentenceLikelihood
initWithWordCount:trailingSilenceDuration:endOfSentenceLikelihood:pauseCounts:silencePosterior:clientSilenceFramesCountMs:clientSilenceProbability:silencePosteriorNF:serverFeaturesLatency:
didEndpointWithFeatures:audioTimestamp:featuresToLog:endpointPosterior:extraDelayMs:
clientSilenceFramesCountMs
serverFeaturesLatency
clientSilenceProbability
hostTimeFromSampleCount:anchorHostTime:anchorSampleCount:sampleRate:
endpointer:reportEndpointBufferHostTime:firstBufferHostTime:
distributionDictionary:
numberWithInt:
initWithTotalAudioRecorded:endpointBufferHostTime:featuresAtEndpoint:endpointerType:serverFeatureLatencyDistribution:additionalMetrics:
_emitEndpointDetectedEventWithEndpointTimeMs:endpointBufferHostTime:endpointerFeatures:endpointerDecisionLagInNs:extraDelayMs:endpointScore:asrFeatureLatencies:
terminateProcessing
currentLanguageCode
requestSupportedWithSamplingRate:
_getCSHybridEndpointerConfigForAsset:
_updateAssetWithLanguage:
_updateAssetWithCurrentLanguage
isJarvisVoiceTriggered
isStarkTriggered
isIOSDeviceSupportingBargeIn
CSAssetManagerDidDownloadNewAsset:
osdAnalyzer:didUpdateOSDFeatures:
osdAnalyzer:didDetectStartOfSpeechAt:
osdAnalyzer:didDetectEndOfSpeechAt:
setCanProcessCurrentRequest:
apQueue
setApQueue:
numSamplesProcessed
setNumSamplesProcessed:
numSamplesProcessedBeforeAnchorTime
setNumSamplesProcessedBeforeAnchorTime:
anchorMachAbsTime
setAnchorMachAbsTime:
isAnchorTimeBuffered
setIsAnchorTimeBuffered:
isRequestTimeout
setIsRequestTimeout:
didAddAudio
setDidAddAudio:
osdFeaturesAtEndpoint
setOsdFeaturesAtEndpoint:
hybridClassifier
setHybridClassifier:
setEndpointerModelVersion:
serverFeaturesQueue
setServerFeaturesQueue:
lastKnownServerEPFeatures
setLastKnownServerEPFeatures:
lastKnownOSDFeatures
setLastKnownOSDFeatures:
serverFeatureLatencies
setServerFeatureLatencies:
lastKnowServerFeaturesLatency
setLastKnowServerFeaturesLatency:
epResult
setEpResult:
serverFeaturesWarmupLatency
setServerFeaturesWarmupLatency:
lastServerFeatureTimestamp
setLastServerFeatureTimestamp:
didReceiveServerFeatures
setDidReceiveServerFeatures:
clientLagThresholdMs
setClientLagThresholdMs:
clampedSFLatencyMsForClientLag
setClampedSFLatencyMsForClientLag:
useDefaultServerFeaturesOnClientLag
setUseDefaultServerFeaturesOnClientLag:
hybridClassifierQueue
setHybridClassifierQueue:
lastReportedEndpointTimeMs
setLastReportedEndpointTimeMs:
processedAudioInSeconds
setProcessedAudioInSeconds:
lastEndpointPosterior
setLastEndpointPosterior:
stateSerialQueue
setStateSerialQueue:
didCommunicateEndpoint
setDidCommunicateEndpoint:
currentRequestSampleRate
setCurrentRequestSampleRate:
vtExtraAudioAtStartInMs
setVtExtraAudioAtStartInMs:
vtEndInSampleCount
setVtEndInSampleCount:
hepAudioOriginInMs
setHepAudioOriginInMs:
speechEndpointDetected
setSpeechEndpointDetected:
firstAudioPacketTimestamp
setFirstAudioPacketTimestamp:
firstAudioSampleSensorTimestamp
setFirstAudioSampleSensorTimestamp:
didTimestampFirstAudioPacket
setDidTimestampFirstAudioPacket:
recordingDidStop
setRecordingDidStop:
osdQueue
setOsdQueue:
didDetectSpeech
setDidDetectSpeech:
setElapsedTimeWithNoSpeech:
setTrailingSilenceDurationAtEndpoint:
_saveSamplesSeenInReset
_canProcessCurrentRequest
_isAnchorTimeBuffered
_isRequestTimeout
_didAddAudio
_epResult
_didReceiveServerFeatures
_useDefaultServerFeaturesOnClientLag
_didCommunicateEndpoint
_speechEndpointDetected
_didTimestampFirstAudioPacket
_recordingDidStop
_didDetectSpeech
_lastEndpointPosterior
_implDelegate
_endpointStyle
_endpointMode
_startWaitTime
_endWaitTime
_interspeechWaitTime
_delay
_automaticEndpointingSuspensionEndTime
_minimumDurationForEndpointer
_apQueue
_numSamplesProcessed
_numSamplesProcessedBeforeAnchorTime
_anchorMachAbsTime
_osdFeaturesAtEndpoint
_hybridClassifier
_endpointerModelVersion
_serverFeaturesQueue
_lastKnownServerEPFeatures
_lastKnownOSDFeatures
_serverFeatureLatencies
_lastKnowServerFeaturesLatency
_serverFeaturesWarmupLatency
_lastServerFeatureTimestamp
_clientLagThresholdMs
_clampedSFLatencyMsForClientLag
_hybridClassifierQueue
_lastReportedEndpointTimeMs
_processedAudioInSeconds
_stateSerialQueue
_currentRequestSampleRate
_vtExtraAudioAtStartInMs
_vtEndInSampleCount
_hepAudioOriginInMs
_firstAudioPacketTimestamp
_firstAudioSampleSensorTimestamp
_osdQueue
_elapsedTimeWithNoSpeech
_trailingSilenceDurationAtEndpoint
T@"NSObject<OS_dispatch_queue>",&,N,V_apQueue
TQ,N,V_numSamplesProcessed
TQ,N,V_numSamplesProcessedBeforeAnchorTime
TQ,N,V_anchorMachAbsTime
TB,N,V_isAnchorTimeBuffered
TB,N,V_isRequestTimeout
TB,N,V_didAddAudio
T@"OSDFeatures",&,N,V_osdFeaturesAtEndpoint
TB,N,V_canProcessCurrentRequest
T@"_EAREndpointer",&,N,V_hybridClassifier
T@"NSString",&,N,V_endpointerModelVersion
T@"NSObject<OS_dispatch_queue>",&,N,V_serverFeaturesQueue
T@"CSServerEndpointFeatures",&,N,V_lastKnownServerEPFeatures
T@"OSDFeatures",&,N,V_lastKnownOSDFeatures
T@"NSMutableArray",&,N,V_serverFeatureLatencies
Td,N,V_lastKnowServerFeaturesLatency
TB,N,V_epResult
Td,N,V_serverFeaturesWarmupLatency
T@"NSDate",&,N,V_lastServerFeatureTimestamp
TB,N,V_didReceiveServerFeatures
Td,N,V_clientLagThresholdMs
Td,N,V_clampedSFLatencyMsForClientLag
TB,N,V_useDefaultServerFeaturesOnClientLag
T@"NSObject<OS_dispatch_queue>",&,N,V_hybridClassifierQueue
Td,N,V_lastReportedEndpointTimeMs
Td,N,V_processedAudioInSeconds
Tf,N,V_lastEndpointPosterior
T@"NSObject<OS_dispatch_queue>",&,N,V_stateSerialQueue
TB,N,V_didCommunicateEndpoint
TQ,N,V_currentRequestSampleRate
Td,N,V_vtExtraAudioAtStartInMs
TQ,N,V_vtEndInSampleCount
Td,N,V_hepAudioOriginInMs
TB,N,V_speechEndpointDetected
T@"NSDate",&,N,V_firstAudioPacketTimestamp
Td,N,V_firstAudioSampleSensorTimestamp
TB,N,V_didTimestampFirstAudioPacket
TB,N,V_recordingDidStop
T@"NSObject<OS_dispatch_queue>",&,N,V_osdQueue
TB,N,V_didDetectSpeech
Td,N,V_elapsedTimeWithNoSpeech
Td,N,V_trailingSilenceDurationAtEndpoint
T@"<CSEndpointAnalyzerDelegate>",W,N,V_delegate
T@"<CSEndpointAnalyzerImplDelegate>",W,N,V_implDelegate
Tq,N,V_endpointStyle
Td,N,V_delay
Td,N,V_startWaitTime
Td,N,V_automaticEndpointingSuspensionEndTime
Td,N,V_minimumDurationForEndpointer
Tq,N,V_endpointMode
Td,N,V_interspeechWaitTime
Td,N,V_endWaitTime
TB,N,V_saveSamplesSeenInReset
isRecordContextBuiltInVoiceTrigger:
isRecordContextHearstVoiceTrigger:
isRecordContextJarvisVoiceTrigger:
isRecordContextRemoraVoiceTrigger:
isRecordContextHearstDoubleTap:
isRecordContextRaiseToSpeak:
isRecordContextAutoPrompt:
isRecordContextHomeButtonPress:
isRecordContextSpeakerIdTrainingTrigger:
isRecordContextJarvisButtonPress:
isValidRecordContext:
recordContextString:
defaultContinousFingerprintBufferDuration
initWithData:
maxFingerprintBufferSize
shouldResetAdsDictionary
assetVersion
payloadData
setPayloadData:
_maxFingerprintBufferSize
_shouldResetAdsDictionary
_assetVersion
_payloadData
T@"NSData",&,N,V_payloadData
Tf,R,N,V_maxFingerprintBufferSize
T@"NSMutableDictionary",R,N,V_shouldResetAdsDictionary
T@"NSString",R,N,V_assetVersion
mapTableWithStrongToStrongObjects
defaultInjectionProvider
primaryInputDevice
setEnableAlwaysOnVoiceTrigger:
deviceUID
initWithDeviceType:deviceName:deviceID:productID:
speakAudio:withScaleFactor:playbackStarted:completion:
connectDevice:
disconnectDevice:
_deviceMapTable
initWithBool:
initWithDouble:
initWithLongLong:
initWithUnsignedLongLong:
objCType
longLongValue
initWithResult:
setSampleFed:
setEarlyWarning:
_earlyWarning
_sampleFed
TQ,N,V_sampleFed
TB,N,V_earlyWarning
strongToWeakObjectsMapTable
_hasPendingActivationForType:
activationEventNotificationHandler:event:completion:
_notifyActivationEvent:completion:
_isVoiceTriggerEvent:
hosttime
setDelegate:forType:
delegates
setDelegates:
pendingActivationEvent
setPendingActivationEvent:
pendingCompletion
setPendingCompletion:
_delegates
_pendingActivationEvent
_pendingCompletion
T@"NSMapTable",&,N,V_delegates
T@"CSActivationEvent",&,N,V_pendingActivationEvent
T@?,C,N,V_pendingCompletion
_setDefaultParameters
_setAsset:
_convertDB2Mag:
_reset
initializeMediaPlayingState
initializeAlarmState
fetchInitSystemVolumes
_resumeSSVProcessing
_pauseSSVProcessing
setCallback:
_startListenPolling
_startListenPollingWithInterval:completion:
_startListenWithCompletion:
_stopListening
mediaPlayingState
alarmState
_getDevicedBFSForInputLinearVolume:
_getFloatBufferData:
iterateBitset:block:
_prepareSoundLevelBufferFromSamples:soundType:
subChunkFrom:numSamples:
_processAudioChunk:soundType:
_estimatedTTSVolume:lowerLimit:upperLimit:TTSmappingInputRangeLow:TTSmappingInputRangeHigh:TTSmappingOutputRangeLow:TTSmappingOutputRangeHigh:
_getUserOffsetFromMusicVolumeDB:
_combineResultsWithOptimalFromNoise:andOptimalFromLkfs:withUserOffset:
_getDeviceSimpleOutputLinearVolumeFordBFSValue:
_scaleInputWithInRangeOutRange:minIn:maxIn:minOut:maxOut:
sharedAnalytics
logEventWithType:context:
smartSiriVolumeSoftVolumeEnabled
_getMusicVolumeDBCSSSVDeviceSimple:
_getMusicVolumeDBCSSSVDeviceDefault:
_deviceSpecificLinearVolumeToDBMappingCSSSVDeviceSimple:
_deviceSpecificDBToLinearVolumeMappingCSSSVDeviceSimple:
_getDeviceSimpledBFSForOutputLinearVolume:
estimateSoundLevelbySoundType:
estimatedTTSVolumeForNoiseLevelAndLKFS:LKFS:
initWithVolumeEstimate:debugLogFile:
CSMediaPlayingMonitor:didReceiveMediaPlayingChanged:
siriClientBehaviorMonitor:willStartStreamWithContext:option:
siriClientBehaviorMonitor:didStartStreamWithContext:successfully:option:withEventUUID:
siriClientBehaviorMonitor:willStopStream:reason:
siriClientBehaviorMonitor:didStopStream:withEventUUID:
siriClientBehaviorMonitor:didChangedRecordState:withEventUUID:withContext:
siriClientBehaviorMonitor:fetchedSiriClientAudioStream:successfully:
siriClientBehaviorMonitor:preparedSiriClientAudioStream:successfully:
siriClientBehaviorMonitorReleasedAudioSession:
initWithSamplingRate:asset:
startSmartSiriVolume
getVolumeForTTSType:withOverrideMediaVolume:WithRequestTime:
didReceiveAlarmChanged:
didReceiveTimerChanged:
didReceiveMusicVolumeChanged:
didReceiveAlarmVolumeChanged:
didDetectKeywordWithResult:
prepareSoundLevelBufferFromSamples:soundType:firedVoiceTriggerEvent:triggerStartTimeSampleOffset:triggerEndTimeSampleOffset:
listenPollingTimer
setListenPollingTimer:
listenPollingTimerCount
setListenPollingTimerCount:
.cxx_construct
_smartSiriVolumeNoiseLevel
_smartSiriVolumeLKFS
_floatBuffer
_defaults
_ssvEnablePolicy
_processedSampleCount
_isListenPollingStarting
_shouldPauseSSVProcess
_shouldPauseLKFSProcess
_alarmSoundIsFiring
_timerSoundIsFiring
_mediaIsPlaying
_musicVolumeDB
_alarmVolume
_noiseLevelChannelBitset
_LKFSChannelBitset
_energyBufferSize
_noiseLowerPercentile
_noiseUpperPercentile
_LKFSLowerPercentile
_LKFSUpperPercentile
_noiseTimeConstant
_noiseMicSensitivityOffset
_noiseMicSensitivityOffsetDeviceSimple
_LKFSTimeConstant
_LKFSMicSensitivityOffset
_noiseTTSMappingInputRangeLow
_noiseTTSMappingInputRangeHigh
_noiseTTSMappingOutputRangeLow
_noiseTTSMappingOutputRangeHigh
_LKFSTTSMappingInputRangeLow
_LKFSTTSMappingInputRangeHigh
_LKFSTTSMappingOutputRangeLow
_LKFSTTSMappingOutputRangeHigh
_userOffsetInputRangeLow
_userOffsetInputRangeHigh
_userOffsetOutputRangeLow
_userOffsetOutputRangeHigh
_TTSVolumeLowerLimitDB
_TTSVolumeUpperLimitDB
_noiseWeight
_listenPollingTimer
_listenPollingTimerCount
T@"NSObject<OS_dispatch_source>",&,N,V_listenPollingTimer
Tq,N,V_listenPollingTimerCount
isPluginContext
deviceType
_createSpeechDetectionVADIfNeeded
isPluginDevice
_connectPluginDevice:
_tearDownSpeechDetectionVADIfNeeded
engineWithDeviceType:streamHandleId:
setInjectionEngine:
attachDevice:
injectionEngine
deviceID
productIdentifier
initWithRoute:isRemoteDevice:remoteDeviceUID:remoteDeviceProductIdentifier:
useSpeexForAudioInjection
setActive:withOptions:error:
setActive:error:
streamHandleID
didStartDelayInSeconds
setDidStartDelayInSeconds:
uuid
setUuid:
connectedDevices
setConnectedDevices:
builtInDevice
setBuiltInDevice:
bundleTvRemote
setBundleTvRemote:
builtInAudioInjectionEngine
setBuiltInAudioInjectionEngine:
audioInjectionEngines
setAudioInjectionEngines:
latestPluginStreamId
setLatestPluginStreamId:
activateStartTime
setActivateStartTime:
activateEndTime
setActivateEndTime:
deactivateStartTime
setDeactivateStartTime:
deactivateEndTime
setDeactivateEndTime:
atvRemoteDeviceID
setAtvRemoteDeviceID:
_didStartDelayInSeconds
_uuid
_connectedDevices
_builtInDevice
_bundleTvRemote
_builtInAudioInjectionEngine
_audioInjectionEngines
_latestPluginStreamId
_activateStartTime
_activateEndTime
_deactivateStartTime
_deactivateEndTime
_atvRemoteDeviceID
T@"NSUUID",&,N,V_uuid
T@"NSMutableArray",&,N,V_connectedDevices
T@"CSAudioInjectionDevice",&,N,V_builtInDevice
T@"CSAudioInjectionDevice",&,N,V_bundleTvRemote
T@"CSAudioInjectionEngine",&,N,V_builtInAudioInjectionEngine
T@"NSMutableDictionary",&,N,V_audioInjectionEngines
TQ,N,V_latestPluginStreamId
TQ,N,V_activateStartTime
TQ,N,V_activateEndTime
TQ,N,V_deactivateStartTime
TQ,N,V_deactivateEndTime
T@"NSString",&,N,V_atvRemoteDeviceID
Tf,N,V_didStartDelayInSeconds
isInAttendingState
notifyUpdatedState:
setCurrentState:
TQ,N,V_currentState
extractArchiveFromDirectory:toDir:
_addListeningEnabledConditions
supportHandsFree
_startObservingOtherAppRecordingState
isOtherAppRecording
handleOtherAppRecordingStateChange:
currentPowerSource
smartSiriVolumeContextAwareEnabled
_didReceiveAutomaticVolumeToggled:
CSAutomaticVolumeEnabledMonitor:didReceiveEnabled:
initWithSuiteName:
addObserver:forKeyPath:options:context:
observeValueForKeyPath:ofObject:change:context:
_isAutomaticVolumeEnabled
_readAudioBufferAndFeed
close
readSamplesFromChannelIdx:
_audioFeedTimer
_bufferDuration
T@"<CSAudioFileReaderDelegate>",W,N,V_delegate
isAttentiveSiriEnabled
_setupNNVADEndpointer
isHearstVoiceTriggered
isRemoraVoiceTriggered
supportCSTwoShotDecision
isWatchRTSTriggered
endpointer:detectedTwoShotAtTime:
logEventWithType:machAbsoluteTime:context:
initForSidekick
endpointerDelegate
endpointerImplDelegate
setEndpointerImplDelegate:
hybridEndpointer
setHybridEndpointer:
nnvadEndpointer
setNnvadEndpointer:
activeEndpointer
setActiveEndpointer:
_endpointerDelegate
_endpointerImplDelegate
_hybridEndpointer
_nnvadEndpointer
_activeEndpointer
T@"<CSEndpointAnalyzerImpl>",&,N,V_hybridEndpointer
T@"<CSEndpointAnalyzerImpl>",&,N,V_nnvadEndpointer
T@"<CSEndpointAnalyzerImpl>",W,N,V_activeEndpointer
T@"<CSEndpointAnalyzerDelegate>",W,N,V_endpointerDelegate
T@"<CSEndpointAnalyzerImplDelegate>",W,N,V_endpointerImplDelegate
getCurrentOSDAsset
checkConsecutiveBoronSignalWithAudioChunk:
countOfConsecutiveBoron
setCountOfConsecutiveBoron:
numOfConsecutiveBoronActivationThreshold
setLastKnownConsecutiveBoronStartSampleCount:
lastKnownConsecutiveBoronStartSampleCount
setFrameDurationMs:
frameDurationMs
endpointerAssetManagerDidUpdateAsset:
endpointerAssetManagerDidUpdateOSDAsset:
hadSignalsFrom:to:
audioStartSampleCount
fetchLastKnownConsecutiveBoronStartSampleCount
configFile
setConfigFile:
firstAudioStartSampleCount
setFirstAudioStartSampleCount:
setNumOfConsecutiveBoronActivationThreshold:
_prefetchedAsset
_configFile
_firstAudioStartSampleCount
_frameDurationMs
_countOfConsecutiveBoron
_lastKnownConsecutiveBoronStartSampleCount
_numOfConsecutiveBoronActivationThreshold
T@"NSString",N,V_configFile
TQ,N,V_firstAudioStartSampleCount
Td,N,V_frameDurationMs
TQ,N,V_countOfConsecutiveBoron
TQ,N,V_lastKnownConsecutiveBoronStartSampleCount
TQ,N,V_numOfConsecutiveBoronActivationThreshold
T@"CSAsset",&,N,V_prefetchedAsset
RMSScore
initWithRMSScore:lastSampleCount:
compareScoresDesc:
setRMSScore:
lastSampleCount
setLastSampleCount:
_RMSScore
_lastSampleCount
Td,N,V_RMSScore
TQ,N,V_lastSampleCount
appendData:
getBytes:range:
_calculateRMSWithFrameData:
_calculateSpeechVoicingLevel
_calculateNumberOfVoicingFrames
numberOfVoicingFrames
sortUsingSelector:
addDataToBuffer:
calculateShadowMicScore
bestStartDetectSample
setBestStartDetectSample:
bestEarlyDetectSample
setBestEarlyDetectSample:
bestEndDetectSample
setBestEndDetectSample:
shadowMicScore
setShadowMicScore:
rmsSamplesForEntireAudio
setRmsSamplesForEntireAudio:
audioBuffer
setAudioBuffer:
speechVoiceLevel
setSpeechVoiceLevel:
setNumberOfVoicingFrames:
numberOfTotalFramesETFT
setNumberOfTotalFramesETFT:
_bestStartDetectSample
_bestEarlyDetectSample
_bestEndDetectSample
_shadowMicScore
_rmsSamplesForEntireAudio
_audioBuffer
_speechVoiceLevel
_numberOfVoicingFrames
_numberOfTotalFramesETFT
T@"NSMutableArray",&,N,V_rmsSamplesForEntireAudio
T@"NSMutableData",&,N,V_audioBuffer
Td,N,V_speechVoiceLevel
TQ,N,V_numberOfVoicingFrames
Tq,N,V_numberOfTotalFramesETFT
TQ,N,V_bestStartDetectSample
TQ,N,V_bestEarlyDetectSample
TQ,N,V_bestEndDetectSample
Td,N,V_shadowMicScore
dataWithCapacity:
appendBytes:length:
myriadHashFilePath
writeToFile:atomically:
CSMyriadSelfTriggerCoordinator:didGenerateMyriadPHashForSelfTrigger:
selfTriggerDetector:didDetectSelfTrigger:
T@"<CSMyriadSelfTriggerCoordinatorDelegate>",W,N,V_delegate
_updateAssetWithCurrentLanguageForAssetType:
_isOSDIncludedInAsset:
_getCurrentHEPAsset
_updateAssetWithLanguage:assetType:
_notifyAssetsUpdate
_updateOEPAssetsWithLanguage:
asrDatapackInstallationStatus
_getModelPathFromInstallationStatusString:
_getOEPVersionFromPath:
assetForAssetType:resourcePath:configVersion:assetProvider:
setCurrentOEPAsset:
currentOEPAsset
currentHEPAsset
checkFirstUnlocked
getCurrentEndpointerAsset
setCurrentHEPAsset:
setAsrDatapackInstallationStatus:
_currentHEPAsset
_currentOEPAsset
_asrDatapackInstallationStatus
T@"CSAsset",&,N,V_currentHEPAsset
T@"CSAsset",&,N,V_currentOEPAsset
T@"NSDictionary",&,N,V_asrDatapackInstallationStatus
setConnectedDevice:
enableAlwaysOnVoiceTrigger
isAlwaysOnVoiceTriggerAvailable
setAlwaysOnVoiceTriggerEnabled:
injectAudio:
injectAudio:withScaleFactor:playbackStarted:completion:
getBestSampleCountWithOption:
applyNegative12dBGainToFloatBuffer:
applyNegative12dBGainToShortBuffer:
builtInMicVoiceTriggerEvent:hostTime:
copybufferFrom:to:
alwaysOnVoiceTriggerEnabled
keywordAnalyzer
setKeywordAnalyzer:
setLastForwardedSampleCount:
hostTimeBuffer
setHostTimeBuffer:
voiceTriggerEnabled
setVoiceTriggerEnabled:
connectedDevice
isForwarding
setIsForwarding:
voiceTriggerSampleCount
setVoiceTriggerSampleCount:
_voiceTriggerEnabled
_isForwarding
_keywordAnalyzer
_lastForwardedSampleCount
_hostTimeBuffer
_connectedDevice
_voiceTriggerSampleCount
T@"<CSAudioInjectionEngineDelegate>",W,N,V_delegate
T@"CSKeywordAnalyzerNDEAPI",&,N,V_keywordAnalyzer
TQ,N,V_lastForwardedSampleCount
T@"NSMutableArray",&,N,V_hostTimeBuffer
TB,N,V_voiceTriggerEnabled
T@"CSAudioInjectionDevice",W,N,V_connectedDevice
TB,N,V_isForwarding
TQ,N,V_voiceTriggerSampleCount
_checkSpringBoardStarted
_didReceiveSpringboardStarted:
_notifyObserver:withStarted:
CSSpringboardStartMonitor:didReceiveStarted:
_didReceiveSpringboardStartedInQueue:
_isSpringBoardStarted
containsCategory:
satScoreThreshold
getBoolForKey:category:default:
containsSpeakerRecognitionCategory
psrCombinationWeight
satImplicitProfileThreshold
satImplicitProfileDeltaThreshold
satVTImplicitThreshold
pruningExplicitUttThresholdSAT
pruningExplicitUttThresholdPSR
pruningThresholdSAT
pruningThresholdPSR
pruningNumRetentionUtterance
maxAllowedEnrollmentUtterances
voiceProfilePruningCookie
keywordDetectorQuasarConfigFilePath
keywordDetectorNDAPIConfigFilePath
satImplicitTrainingEnabled
Tq,R,N
_createXPCClientConnection
initWithType:deviceId:activationInfo:hosttime:
sharedNotifier
notifyActivationEventSynchronously:completion:
notifyActivationEvent:deviceId:activationInfo:completion:
deviceIsInSleep
_alarmFiringState
ssvManager
setSsvManager:
_ssvManager
T@"CSSmartSiriVolumeManager",&,N,V_ssvManager
handleAudioStopUnexpectly
_fetchAudioDecoderForTV:
packets
numChannels
defaultConverter
speexASBD
attachToMasterStreamWithCompletion:
decodersForTV
setDecodersForTV:
decoderProcessedSampleCountForTV
setDecoderProcessedSampleCountForTV:
_decodersForTV
_decoderProcessedSampleCountForTV
T@"NSMutableDictionary",&,N,V_decodersForTV
TQ,N,V_decoderProcessedSampleCountForTV
_checkFirstUnlocked
_didReceiveFirstUnlock:
_notifyObserver:withUnlocked:
_firstUnlockNotified
_didReceiveFirstUnlockInQueue:
_firstUnlocked
_isBuiltInDeviceFromDeviceId:
rtsTriggerInfo
setRtsTriggerInfo:
setTriggerNotifiedMachTime:
_accessoryVoiceTriggerEvents
_builtInVoiceTriggerEvent
_rtsTriggerInfo
_triggerNotifiedMachTime
T@"NSDictionary",C,N,V_rtsTriggerInfo
TQ,N,V_triggerNotifiedMachTime
initWithRoute:isRemoteDevice:remoteDeviceUID:remoteDeviceProductIdentifier:remoteDeviceUIDString:
initWithUUIDString:
isRemoteDevice
remoteDeviceUID
remoteProductIdentifier
remoteDeviceUIDString
route
remoteDeviceProductIdentifier
_isRemoteDevice
_route
_remoteDeviceUID
_remoteDeviceProductIdentifier
_remoteDeviceUIDString
T@"NSString",R,C,N,V_remoteDeviceUIDString
T@"NSString",R,C,N,V_route
TB,R,N,V_isRemoteDevice
T@"NSUUID",R,C,N,V_remoteDeviceUID
T@"NSString",R,C,N,V_remoteDeviceProductIdentifier
commandControlBehaviorMonitor:willStartStreamWithContext:option:
commandControlBehaviorMonitor:didStartStreamWithContext:successfully:option:
commandControlBehaviorMonitor:willStopStream:
commandControlBehaviorMonitor:didStopStream:
error
setTimestamp:
setPerceptualAudioHash:
initWithOverrideOption:reason:
setOverrideState:
newWithBuilder:
setVoiceTriggerEverUsed
initWithServicePort:
deactivateForReason:options:context:completion:
sharedLauncher
notifyBuiltInVoiceTriggerPrewarm:completion:
notifyBuiltInVoiceTrigger:myriadPHash:completion:
notifyWakeKeywordSpokenInBuiltInMic:
notifyCarPlayVoiceTriggerPrewarm:deviceId:completion:
notifyCarPlayVoiceTrigger:deviceId:myriadPHash:completion:
notifyWakeKeywordSpokenCarPlay:deviceId:
notifyBluetoothDeviceVoiceTriggerPrewarm:deviceId:completion:
notifyBluetoothDeviceVoiceTrigger:deviceId:completion:
notifyWakeKeywordSpokenBluetoothDevice:deviceId:
notifyRemoraVoiceTriggerPrewarm:deviceId:completion:
notifyRemoraVoiceTrigger:myriadPHash:deviceId:completion:
notifyWakeKeywordSpokenRemora:deviceId:
deactivateSiriActivationConnectionWithReason:withOptions:withContext:
initWithNumChannels:recordingDuration:samplingRate:
initWithSiriSessionUUID:
addAudioChunk:
fetchAudioFromCircularBuffer
T@"CSAudioCircularBuffer",R,N,V_circularBuffer
T@"NSString",R,N,V_siriSessionUUID
initWithAttSiriController:localSpeechRecognizer:
_setLocalSpeechRecognizerState:
stopWithReason:
_handleStopDeliverLocalSpeechRecognition
_preheatWithLanguage:preheatSource:shouldDownloadMissingAsset:
requestId
_stopPreviousRecognitionTaskIfNeededWithNewRequestId:
speechRecognitionTask
_startDeliverLocalSpeechRecognitionResultsWithRequestId:
_startLocalSpeechRecognizerIfNeeded
_handleStopSpeechRecognitionTaskIfNeeded:
_clearAudioProcessWaitingBufferIfNeeded
_processAudioChunk:
endpointModeFromEndpointMetrics:
_queryShouldAcceptEagerResultForDuration:requestId:rcId:
getMitigationDecisionForRCId:
localSRBridgeListener
localSpeechServiceDidReceivedEagerResultWithRequestId:rcId:shouldAccept:mitigationSignal:featuresToLog:
_clearEndpointHint
_interactiveLocalSpeechRecognizer
startMissingAssetDownload
_preheatWithLanguage:preheatSource:
initWithLanguage:assetType:
preheatSpeechRecognitionWithAssetConfig:modelOverrideURL:
_adjustEndpointStartTimeWithVoiceTriggerEvent:
_shouldDisableLocalSpeechRecognizerWithOption:audioRecordContext:
isDictation
supportsDictationOnDevice
_stateToString:
shouldStoreAudioOnDevice
overrideModelPath
_fetchInputOriginWithRecordContext:
deliverEagerPackage
UILanguage
_fetchRecognizerLanguageWithSiriLanguage:UILanguage:taskString:
_resetLocalSpeechRecognizerParameters
applicationName
recognitionOverrides
detectUtterances
secureOfflineOnly
continuousListening
shouldHandleCapitalization
maximumRecognitionDuration
location
jitGrammar
initWithLanguage:requestIdentifier:dictationUIInteractionIdentifier:task:loggingContext:applicationName:profile:overrides:modelOverrideURL:originalAudioFileURL:codec:narrowband:detectUtterances:censorSpeech:farField:secureOfflineOnly:shouldStoreAudioOnDevice:continuousListening:shouldHandleCapitalization:isSpeechAPIRequest:maximumRecognitionDuration:endpointStart:inputOrigin:location:jitGrammar:deliverEagerPackage:disableDeliveringAsrFeatures:
startSpeechRecognitionWithParameters:didStartHandlerWithInfo:
addAudioPacket:
_scheduleRecordingTransactionReleaseTimer
finishAudio
_releaseRecordingTransactionIfNeededWithToken:
initWithDelegate:instanceUUID:
writeDESRecord
localSpeechServiceDidReceivedPartialResultWithRequestId:language:tokens:
_handleShouldAcceptEagerResultWithRequestId:rcId:duration:shouldAccept:featuresToLog:
isReceivedTimeInterval:matchCurrentTimeInterval:
_enforceEndpointHintWithRequestId:rcId:shouldAccept:featuresToLog:
isFinal
_handleDidRecognizedFinalSpeechPackage:requestId:
_handleDidRecognizedSpeechPackageForEagerRecognitionCandidate:requestId:rcId:processedAudioDuration:
localSpeechServiceDidReceivedFinalResultWithRequestId:speechPackage:
processResultCandidate:forRCId:forTask:completion:
localSpeechServiceDidReceivedEagerRecognitionCandidateWithRequestId:rcId:speechPackage:duration:
_getUserSpeakingEndedTimeFromSpeechPackage:
localSpeechServiceDidCompletionRecognitionWithStatistics:requestId:endpointMode:error:
_invalidateLocalSpeechRecognizer:
hostTimeToTimeInterval:
setEndpointerFeatureEoS:
modelRoot
setASRModelRootDirectory:
_getAsrInputoriginFromContext:
isRequestFromSpokenNotification
isiOSButtonPress
rawRecognition
phrases
interpretations
silenceStartTime
localSpeechRecognizer:didSelectRecognitionModelWithModelProperties:
localSpeechRecognizer:didRecognizeTokens:
localSpeechRecognizer:didProcessAudioDuration:
localSpeechRecognizer:didRecognizeRawEagerRecognitionCandidate:
localSpeechRecognizer:didRecognizePackage:
localSpeechRecognizer:didCompletionRecognitionWithStatistics:error:
localSpeechRecognizer:didProduceEndpointFeaturesWithWordCount:trailingSilenceDuration:eosLikelihood:pauseCounts:silencePosterior:processedAudioDurationInMilliseconds:
localSpeechRecognizer:didProduceLoggablePackage:
startDeliverLocalSpeechRecognitionResultsWithSettings:
stopDeliverLocalSpeechRecognitionWithReason:
disableLocalSpeechRecognitionForRequestId:
registerEndpointerNode:
registerUresNode:
preheatWithLanguage:shouldDownloadMissingAsset:
prepareToStartSpeechRequestWithStartStreamOption:audioRecordContext:voiceTriggerInfo:
fetchCurrentState
endpointerNode
uresNode
localSpeechRecognizerQueue
setLocalSpeechRecognizerQueue:
interactiveLocalSpeechRecognizer
setInteractiveLocalSpeechRecognizer:
presetLocalSpeechRecognizer
setPresetLocalSpeechRecognizer:
localSpeechRecognizerTaskString
setLocalSpeechRecognizerTaskString:
localSpeechRecognizerState
setLocalSpeechRecognizerState:
audioWaitingBuffer
setAudioWaitingBuffer:
processedAudioDurationInMillisec
setProcessedAudioDurationInMillisec:
language
setLanguage:
setRequestId:
eagerResultId
setEagerResultId:
speechHasAcceptedResultCandidate
setSpeechHasAcceptedResultCandidate:
speechRecognitionSettings
setSpeechRecognitionSettings:
shouldProcessAudio
setShouldProcessAudio:
asrResultDeliveryTransaction
setAsrResultDeliveryTransaction:
recordingToken
setRecordingToken:
endpointStartTimeInSec
setEndpointStartTimeInSec:
audioSampleCountToSkip
setAudioSampleCountToSkip:
didDetectedEndpoint
setDidDetectedEndpoint:
lastEndpointHintDuration
setLastEndpointHintDuration:
lastEndpointHintRCId
setLastEndpointHintRCId:
lastEndpointEagerResultTime
setLastEndpointEagerResultTime:
lastEndpointHintFeatures
setLastEndpointHintFeatures:
endpointDelayReporter
setEndpointDelayReporter:
setLocalSRBridgeListener:
_speechHasAcceptedResultCandidate
_shouldProcessAudio
_didDetectedEndpoint
_endpointerNode
_uresNode
_localSpeechRecognizerQueue
_presetLocalSpeechRecognizer
_localSpeechRecognizerTaskString
_localSpeechRecognizerState
_audioWaitingBuffer
_processedAudioDurationInMillisec
_language
_requestId
_eagerResultId
_speechRecognitionSettings
_asrResultDeliveryTransaction
_recordingToken
_endpointStartTimeInSec
_audioSampleCountToSkip
_lastEndpointHintDuration
_lastEndpointHintRCId
_lastEndpointEagerResultTime
_lastEndpointHintFeatures
_endpointDelayReporter
_localSRBridgeListener
T@"NSObject<OS_dispatch_queue>",&,N,V_localSpeechRecognizerQueue
T@"CoreEmbeddedSpeechRecognizer",&,N,V_interactiveLocalSpeechRecognizer
T@"CoreEmbeddedSpeechRecognizer",&,N,V_presetLocalSpeechRecognizer
T@"NSString",&,N,V_localSpeechRecognizerTaskString
TQ,N,V_localSpeechRecognizerState
T@"CSAudioProcessWaitingBuffer",&,N,V_audioWaitingBuffer
Td,N,V_processedAudioDurationInMillisec
TI,N,V_activeChannel
T@"NSString",&,N,V_language
T@"NSString",&,N,V_requestId
TQ,N,V_eagerResultId
TB,N,V_speechHasAcceptedResultCandidate
T@"LBLocalSpeechRecognitionSettings",&,N,V_speechRecognitionSettings
TB,N,V_shouldProcessAudio
T@"CSOSTransaction",&,N,V_asrResultDeliveryTransaction
T@"NSUUID",&,N,V_recordingToken
Td,N,V_endpointStartTimeInSec
TQ,N,V_audioSampleCountToSkip
TB,N,V_didDetectedEndpoint
Td,N,V_lastEndpointHintDuration
Tq,N,V_lastEndpointHintRCId
TQ,N,V_lastEndpointEagerResultTime
T@"NSArray",&,N,V_lastEndpointHintFeatures
T@"CSEndpointDelayReporter",&,N,V_endpointDelayReporter
T@"CSConnectionListener",&,N,V_localSRBridgeListener
T@"CSAttSiriEndpointerNode",W,N,SregisterEndpointerNode:,V_endpointerNode
T@"CSAttSiriUresNode",W,N,SregisterUresNode:,V_uresNode
completionBlock
setTimer:
setTimerForSecs:completionBlock:
cancelTimer
timer
setCompletionBlock:
_timer
_completionBlock
T@"NSObject<OS_dispatch_source>",&,N,V_timer
T@?,C,N,V_completionBlock
setStreamProvider:
setStreaming:
stringByAppendingFormat:
setStreamingUUID:
streamingUUID
streaming
setIsWeakStream:
_scheduledFutureSample
_isWeakStream
_streaming
_streamProvider
_streamRequest
_startStreamOption
_tandemStreams
_streamingUUID
TB,V_streaming
T@"NSUUID",&,V_streamingUUID
T@"<CSAudioStreamProviding>",W,N,V_streamProvider
T@"<CSAudioStreamProvidingDelegate>",W,N,V_delegate
TQ,R,N,V_startSampleCount
TQ,R,N,V_lastForwardedSampleCount
TB,N,SsetScheduledFutureSample:,V_scheduledFutureSample
T@"CSAudioStreamRequest",&,N,V_streamRequest
T@"CSAudioStartStreamOption",&,N,SsetStartStreamOption:,V_startStreamOption
TB,N,V_isWeakStream
T@"NSHashTable",R,N,V_tandemStreams
_didReceiveNewVoiceTriggerAssetMetaData
CSVoiceTriggerAssetMetaUpdateMonitor:didReceiveNewVoiceTriggerAssetMetaData:
notifyNewVoiceTriggerAssetMetaDataUpdated
setOpportuneSpeakListeningType:
_opportuneSpeakListeningType
TQ,N,V_opportuneSpeakListeningType
supportZeroFilter:
supportBeepCanceller:
resetWithSampleRate:
initWithToken:sampleRate:numChannels:
setSampleRate:
_isNarrowBand:
setUpsampler:
zeroFilter
beepCanceller
getZeroStatisticsFromBuffer:entireSamples:
processBuffer:atTime:
cancelBeepFromSamples:timestamp:
stopReportZeroStatistics
_reportMetrics
isHeadphoneDeviceWithRecordRoute:playbackRoute:
willBeep
_fetchCurrentMetrics
inputRecordingSampleRateNarrowBand
zeroFilter:zeroFilteredBufferAvailable:atHostTime:
beepCancellerDidCancelSamples:buffer:timestamp:
setZeroFilter:
setBeepCanceller:
zeroCounter
setZeroCounter:
_sampleRate
_numChannels
_upsampler
_zeroFilter
_beepCanceller
_zeroCounter
Tf,N,V_sampleRate
T@"CSAudioSampleRateConverter",&,N,V_upsampler
T@"CSVoiceTriggerAwareZeroFilter",&,N,V_zeroFilter
T@"CSBeepCanceller",&,N,V_beepCanceller
T@"CSAudioZeroCounter",&,N,V_zeroCounter
Ti,N,V_numChannels
T@"<CSAudioPreprocessorDelegate>",W,N,V_delegate
getSerialQueue:withQualityOfService:andTargetQueue:
_init
accessorySiriClientBehaviorMonitor:willStartStreamWithContext:option:forAccessory:
accessorySiriClientBehaviorMonitor:didStartStreamWithContext:successfully:option:withEventUUID:forAccessory:
accessorySiriClientBehaviorMonitor:willStopStream:reason:forAccessory:
accessorySiriClientBehaviorMonitor:didStopStream:reason:withEventUUID:forAccessory:
activeAudioRouteDidChange:
_didReceiveNewSpeechEndpointAssetMetaData
CSSpeechEndpointAssetMetaUpdateMonitor:didReceiveNewSpeechEndpointAssetMetaData:
_addDisabledConditions
_handleClientEvent:
_handleClientMessage:client:
_handleClientError:client:
_sendReplyMessageWithResult:error:event:client:
connection
setConnection:
_connection
T@"NSObject<OS_xpc_object>",&,N,V_connection
_addAssetManagerEnabledConditions
_shouldCheckNetworkAvailability
isAvailable
initWithMode:deviceUID:
isRequestDuringActiveCall
setActivationMode:
setAnnounceCallsEnabled:
initWithDescription:timeout:
setIsASRFeatureFromServer:
_updateEndpointerDelayedTriggerByMhId:
extraDelayFrequency
setExtraDelayFrequency:
taskThresholdMap
setTaskThresholdMap:
isASRFeatureFromServer
endpointerOperationMode
_isASRFeatureFromServer
_extraDelayFrequency
_taskThresholdMap
_endpointerOperationMode
TQ,N,V_extraDelayFrequency
T@"NSDictionary",&,N,V_taskThresholdMap
TB,N,V_isASRFeatureFromServer
Tq,N,V_endpointerOperationMode
systemUpTime
sharedPowerLogger
powerWithNumFalseWakeup:withDuration:
numberWithLongLong:
sharedAggregator
logAOPFirstPassTriggerWakeupLatency:
logSecondPassResult:eventInfo:triggerAPWakeUp:
logFalseWakeUp:
logTriggerLengthSampleCountStatistics:withFirstPassDeterministicTriggerLengthSampleCount:
logAudioZeroRun:
numFalseWakeUp
setNumFalseWakeUp:
lastAggTimeFalseWakeUp
setLastAggTimeFalseWakeUp:
_numFalseWakeUp
_lastAggTimeFalseWakeUp
TQ,N,V_numFalseWakeUp
TQ,N,V_lastAggTimeFalseWakeUp
assetManagerEnabledPolicy
audioFeedTimer
setAudioFeedTimer:
setFp:
T@"NSObject<OS_dispatch_source>",&,N,V_audioFeedTimer
T^{__sFILE=*iiss{__sbuf=*i}i^v^?^?^?^?{__sbuf=*i}^{__sFILEX}i[3C][1C]{__sbuf=*i}iq},N,V_fp
speexConverter
opusConverter
addSamples:timestamp:arrivalTimestampToAudioRecorder:
audioConverterDidConvertPackets:packets:durationInSec:timestamp:arrivalTimestampToAudioRecorder:
encoder
setEncoder:
_encoder
T@"CSAudioConverter",&,N,V_encoder
_checkVoiceTriggerEnabled
_didReceiveVoiceTriggerSettingChanged:
CSVoiceTriggerEnabledMonitor:didReceiveEnabled:
_didReceiveVoiceTriggerSettingChangedInQueue:
_isVoiceTriggerEnabled
volumeEstimate
debugLogPath
_volumeEstimate
_debugLogPath
T@"NSString",R,N,V_debugLogPath
Tf,R,N,V_volumeEstimate
CSAlwaysOnProcessorStateMonitor:didReceiveStateChange:
_didReceiveAOPListeningStateChange:
_isListeningEnabled
attSiriNode:didMitigate:withScore:taskType:
_startRequestWithContext:withVtei:withVTAssets:taskType:completion:
_setAsset:forTask:
_startRequestWithContext:withVtei:completion:
_addAudio:
recordTypeString:
initWithConfig:withDelegate:error:
initWithContext:error:
startNewRequestWithContext:
_logAFTMStartMsg:taskType:
score
_shouldHandleMitigationDecision:
analyzedSamples
_logAFTMEndMsgWithScore:analyzedSamples:
_reportResultToAnalytics
_logResultToVTDirectory
_handleAFTMResults:
_createResultDict
voiceTriggerAudioLogDirectory
resultType
analyzer:hasPartialResult:
analyzer:hasFinalResult:
startRequestWithContext:withVtei:withVTAssets:taskType:completion:
startRequestWithContext:withVtei:taskType:completion:
acousticAnalyzer
setAcousticAnalyzer:
thresholds
setThresholds:
supportedRecordType
setSupportedRecordType:
sessionInProgress
setSessionInProgress:
isShadowModeEnabled
setIsShadowModeEnabled:
makeStandaloneMitigation
setMakeStandaloneMitigation:
latestResult
setLatestResult:
context
setContext:
_sessionInProgress
_isShadowModeEnabled
_makeStandaloneMitigation
_acousticAnalyzer
_thresholds
_supportedRecordType
_latestResult
_context
T@"NSString",&,N,V_taskName
T@"NSString",&,N,V_configFile
T@"SLProgressiveCheckerAnalyzer",&,N,V_acousticAnalyzer
T@"NSArray",&,N,V_thresholds
TQ,N,V_supportedRecordType
TB,N,V_sessionInProgress
TB,N,V_isShadowModeEnabled
TB,N,V_makeStandaloneMitigation
T@"SLProgressiveCheckerResult",&,N,V_latestResult
T@"CSAudioRecordContext",&,N,V_context
valueForEntitlement:
_handleXPCTimeConvertProvidingTypeHostTimeFromSampleCountMessage:messageBody:client:streamHandleId:
_handleXPCTimeConvertProvidingTypeSampleCountFromHostTimeMessage:messageBody:client:streamHandleId:
handleXPCMessage:messageBody:client:audioStreamHandleId:
allowSuddenTermination
disallowSuddenTermiation
isHeadlessDeviceDataCollectionModeEnabled
_processRemoteHeySiriCommandWithRequest:fromSenderID:withReply:
_processParallelRecordingCommandWithRequest:fromSenderID:withReply:
_receiveParallelRecordingFromPeerId:recordingInfo:withReply:
_receiveVoiceProfileFromPeerId:voiceProfileInfo:withReply:
_processGradingDataFetchCommandWithRequest:fromSenderID:withReply:
_processVoiceProfileDeleteCommandWithRequest:fromSenderID:withReply:
_receiveVoiceGradingDataFromPeerId:requestInfo:withReply:
_processVoiceProfileListQueryCommandFromPeerId:requestInfo:withReply:
_processFetchVoiceProfileCommandFromPeerId:requestInfo:withReply:
_processReverseTransferVoiceProfileCommandFromPeerId:requestInfo:withReply:
_processVoiceProfileUpdateTriggerFromPeerId:requestInfo:withReply:
_sendCoreSpeechGradingDataToPeerId:
_sendVoiceTriggerGradingDataToPeerId:
_sendVoiceProfileUpdateTriggerToPeerId:forLocale:
_sendAcousticGradingDataToPeerId:
containsString:
companionSyncVoiceTriggerUtterancesEnabled
pathExtension
isInternalWithoutProfile
_sendGradingData:withFileName:toPeerId:withCompressedFlag:withUncompressedDataSize:withBatchId:withRetainFileFlag:
_compressFilesInDirectory:matchingPredicate:compressedFileAvailable:
URLByDeletingPathExtension
assistantAudioFileLogDirectory
stringByDeletingPathExtension
stringByDeletingLastPathComponent
dataUsingEncoding:
stringByAppendingPathExtension:
removeItemAtPath:error:
moveItemAtPath:toPath:error:
sendMessageWithPayload:toPeer:withReply:
_spIdSiriDebugVoiceProfileRootDirectoryForProfile:locale:
_spIdSiriDebugGradingDataRootDirectory
dictionaryWithObject:forKey:
setAttributes:ofItemAtPath:error:
temporaryDirectory
URLByAppendingPathComponent:
_createDirectoryIfDoesNotExist:
writeToURL:atomically:
_getContentsOfDirectory:
updateVoiceProfile:withUserName:
provisionedVoiceProfilesForLocale:
appDomain
profileId
deleteUserVoiceProfile:
_sendCoreSpeechMagusGradingDataToPeerId:
sharedSiriId
dateAdded
homeId
_getHomeUserIdForSharedSiriId:withCompletion:
userName
languageCode
initWithObjectsAndKeys:
enter
leave
getHomeUserIdForSharedUserId:completion:
waitWithTimeout:
_sendVoiceProfile:toPeerId:
locale
contentsOfDirectoryAtPath:error:
_spIdSiriDebugVoiceProfileCacheDirectoryForProfile:locale:
URLsForDirectory:inDomains:
remoteP2pLogDirectory
remoteGradingDataDirectory
_spIdSiriDebugVTDataDirectory
_spIdSiriDebugVoiceProfileStoreRootDirectory
_spIdSiriDebugVoiceProfileStoreRootDirectoryForLocale:
isP2PTransferEnabled
processRemoteCommandWithPayload:fromPeer:withReply:
sendCoreSpeechGradingDataToNearbyPeer
sendVTNearMissGradingDataToCompanion
sendVoiceProfileUpdatedMessageToNearbyPeerForLocale:
sendAcousticGradingDataToNearbyPeer
_speakerRecognitionAudioLogsGradingDir
_spIdSiriDebugTrainedUsersFilePathForLocale:
adCompanionServiceProvider
setAdCompanionServiceProvider:
lastCommunicatedPeer
setLastCommunicatedPeer:
voiceTriggerBatchId
setVoiceTriggerBatchId:
voiceIdentificationBatchId
setVoiceIdentificationBatchId:
_adCompanionServiceProvider
_lastCommunicatedPeer
_voiceTriggerBatchId
_voiceIdentificationBatchId
T@"NSString",&,N,V_lastCommunicatedPeer
T@"NSString",&,N,V_voiceTriggerBatchId
T@"NSString",&,N,V_voiceIdentificationBatchId
T@"<CSADCompanionServiceProvider>",W,N,V_adCompanionServiceProvider
audioRecorderWithQueue:error:
supportAcousticProgressiveChecker
supportsSpeechRecognitionOnDevice
initWithEndpointerNode:osdNode:ssrNode:asrNode:uresNode:flexKwdNode:needsSSRNode:aFtmNode:speechManager:siriEnabledMonitor:siriClientBehaviorMonitor:supportsAcousticProgressiveChecker:supportsUnderstandingOnDevice:requireASROnDevice:
isDeferredActivationEnabled
_fetchMitigationAssets
_handleStartProcessingWithRecordContext:
_setupAudioSrcNodeWithSiriClientStream:
_handleStopProcessing
attSiriSvcListener
attSiriDidDetectAttendingTrigger:
setAudioSrcNode:
_forceBuildGraph:
audioSrcNode
_holdAttSiriTransactionIfNeeded
setInputOriginWithAudioRecordContext:boronScore:
_releaseAttSiriTransactionIfNeeded
attSiriNode:triggerReportedFromFlxKwdSpotter:
startAttendingWithContext:
stopAttendingWithContext:
siriRequestProcessingCompleted
getNodeOfType:
setAttSiriSvcListener:
nodesCache
setNodesCache:
setEndpointerNode:
osdNode
setOsdNode:
asrNode
setAsrNode:
setUresNode:
ssrNode
setSsrNode:
siriClientAudioStartStreamOption
setSiriClientAudioStartStreamOption:
attSiriTransaction
setAttSiriTransaction:
siriClientBehaviorMonitor
setSiriClientBehaviorMonitor:
siriClientStream
setSiriClientStream:
mitigationAsset
setMitigationAsset:
siriEnabledMonitor
setSiriEnabledMonitor:
flexKwdNode
setFlexKwdNode:
aFTMNode
setAFTMNode:
nldaClassifierNode
setNldaClassifierNode:
pendingActivationProcessing
setPendingActivationProcessing:
activationStartSampleId
setActivationStartSampleId:
deferredActivation
setDeferredActivation:
_pendingActivationProcessing
_deferredActivation
_attSiriSvcListener
_nodesCache
_osdNode
_asrNode
_audioSrcNode
_ssrNode
_siriClientAudioStartStreamOption
_attSiriTransaction
_siriClientBehaviorMonitor
_siriClientStream
_mitigationAsset
_siriEnabledMonitor
_flexKwdNode
_aFTMNode
_nldaClassifierNode
_activationStartSampleId
T@"NSMapTable",&,N,V_nodesCache
T@"CSAttSiriEndpointerNode",&,N,V_endpointerNode
T@"CSAttSiriOSDNode",&,N,V_osdNode
T@"CSAttSiriAsrNode",&,N,V_asrNode
T@"CSAttSiriUresNode",&,N,V_uresNode
T@"CSAttSiriAudioSrcNode",&,N,V_audioSrcNode
T@"CSAttSiriSSRNode",&,N,V_ssrNode
T@"CSAudioStartStreamOption",&,N,V_siriClientAudioStartStreamOption
T@"CSOSTransaction",&,N,V_attSiriTransaction
T@"CSSiriClientBehaviorMonitor",&,N,V_siriClientBehaviorMonitor
T@"CSAudioStream",&,N,V_siriClientStream
T@"CSAsset",&,N,V_mitigationAsset
T@"CSSiriEnabledMonitor",&,N,V_siriEnabledMonitor
T@"CSAttSiriFlexKwdNode",&,N,V_flexKwdNode
T@"CSAttSiriAFTMNode",&,N,V_aFTMNode
T@"CSAttSiriNLDAClassifierNode",&,N,V_nldaClassifierNode
TB,N,V_pendingActivationProcessing
TQ,N,V_activationStartSampleId
TB,N,V_deferredActivation
T@"CSConnectionListener",&,N,V_attSiriSvcListener
initWithDownloadOption:
_createPeriodicalDownloadTimer
_startPeriodicalDownload
_stopPeriodicalDownload
_fetchRemoteMetaData
_canFetchRemoteAsset:
supportLanguageDetector
supportAdBlocker
supportsSpeakerRecognitionAssets
assetForCurrentLanguageOfType:completion:
CSAdBlockerMetaUpdateMonitor:didReceiveNewAdBlockerAssetMetaData:
installedAssetForCurrentLanguageOfType:
installedAssetForCurrentLanguageOfType:completion:
_enablePolicy
_currentLanguageCode
_downloadingOption
_downloadTimer
_downloadTimerCount
pickedRoute
isHFPWithRecordRoute:
isBluetoothAudioDeviceConnected
audioPortSubtypeAsString:
zeroFilterWindowSizeInMs
getHostClockFrequency
zeroFilterApproxAbsSpeechThreshold
initWithZeroWindowSize:approxAbsSpeechThreshold:numHostTicksPerAudioSample:
filterZerosInAudioPacket:atBufferHostTime:filteredPacket:
endAudioAndFetchAnyTrailingZerosPacket:
T@"CSAudioZeroFilter",&,N,V_zeroFilter
T@"<CSVoiceTriggerAwareZeroFilterDelegate>",W,N,V_delegate
initWithEndpointThreshold:
T@"<CSSPGEndpointAnalyzerDelegate>",W,N,V_delegate
_handleMetricProvidingRequestTypeAudioMetricMessage:messageBody:client:
audioMetricProvider
setAudioMetricProvider:
_audioMetricProvider
T@"<CSAudioMetricProviding>",W,N,V_audioMetricProvider
_handleActivateEventMesssage:client:
T@"<CSActivateXPCConnectionDelegate>",W,N,V_delegate
address
supportDoAP
isTemporaryPairedNotInContacts
_supportDoAP
_isTemporaryPairedNotInContacts
_address
T@"NSString",C,N,V_address
TB,N,V_supportDoAP
TB,N,V_isTemporaryPairedNotInContacts
notifyReleaseAudioSession
setIsStreaming:
_isStreaming
TB,N,V_isStreaming
attSiriNode:classifierScore:detailedResult:
createNLDAClassifierWithAsset:
nldaConfigFile
initWithConfig:error:locale:
processSpeechPackage:
domainProb
processSpeechPackageSync:
bertModel
setBertModel:
_bertModel
T@"SLBertClassifier",&,N,V_bertModel
remoteMicVoiceTriggerEvent:activationInfo:hostTime:
lastDetectedVoiceTriggerBeginSampleCount
setLastDetectedVoiceTriggerBeginSampleCount:
_lastDetectedVoiceTriggerBeginSampleCount
T@"CSKeywordAnalyzerNDAPI",&,N,V_keywordAnalyzer
TQ,N,V_lastDetectedVoiceTriggerBeginSampleCount
numOfAVVCRecordingClients
_numOfAVVCRecordingClients
TQ,R,N,V_numOfAVVCRecordingClients
mitigatonConfigFile
mitigationModelDefaultAFTMScore
initWithType:deviceId:activationInfo:vadScore:hosttime:
_activationTypeString
remoteMicVADEvent:vadScore:hostTime:
jarvisVoiceTriggerEvent:activationInfo:hostTime:
remoraVoiceTriggerEvent:hostTime:
remoraVoiceTriggerEvent:activationInfo:hostTime:
mediaserverdLaunchedEvent:
activationInfo
vadScore
_vadScore
_activationInfo
_hosttime
T@"NSString",R,N,V_deviceId
T@"NSDictionary",R,N,V_activationInfo
TQ,R,N,V_hosttime
Tf,R,N,V_vadScore
audioConverterBitrate
setEncoderBitRate:
setNumberOfChannels:
inputRecordingSampleBitDepth
setLpcmBitDepth:
setLpcmIsFloat:
setUseCustomizedRecordSettings:
setIsSiri:
requestForOpusRecordSettingsWithContext:
requestForSpeexRecordSettingsWithContext:
_requiresHistoricalBuffer
_useCustomizedRecordSettings
_lpcmIsFloat
_isSiri
_lpcmBitDepth
_numberOfChannels
_encoderBitRate
_audioFormat
TB,N,V_requiresHistoricalBuffer
TB,N,V_useCustomizedRecordSettings
Tq,N,V_audioFormat
Td,N,V_sampleRate
TI,N,V_lpcmBitDepth
TB,N,V_lpcmIsFloat
TI,N,V_numberOfChannels
TI,N,V_encoderBitRate
TB,N,V_isSiri
_didInstalledNewVoiceTriggerAsset
initWithCrashMonitor:
setAudioSessionState:
_audioSessionState
audioSessionState
TQ,N,GgetAudioSessionState,V_audioSessionState
getASVUserIntent:
setUserIntentValidForSeconds:
applyLowerAndUpperBoundsToVolume:
setASVUserIntent:
initWithStoredInformationAndAsset:
increaseSiriVolumeBasedOnUserIntent
decreaseSiriVolumeBasedOnUserIntent
storeASVStateInformation
applyLowerAndUpperBoundsToVolumeOffset:
userIntentType
setUserIntentType:
userIntentTime
setUserIntentTime:
userIntentValidForSeconds
latestVolumeTime
setLatestVolumeTime:
userIntentVolume
setUserIntentVolume:
latestVolume
setLatestVolume:
permanentOffsetFactor
setPermanentOffsetFactor:
permanentOffsetIsEnabled
setPermanentOffsetIsEnabled:
kSSVCAUserIntentValidForSeconds
kSSVCAUserIntentVolumeIncreaseFactor
kSSVCAUserIntentVolumeDecreaseFactor
kSSVCAUserIntentPermanentOffsetFactorDelta
kSSVCAUserIntentPermanentOffsetFactorLowerBound
kSSVCAUserIntentPermanentOffsetFactorUpperBound
kSSVCA_DEVICE_SIMPLE_MIN_TTS_VOLUME
kSSVCA_DEVICE_SIMPLE_MAX_TTS_VOLUME
kSSVCA_DEVICE_DEFAULT_MIN_TTS_VOLUME
kSSVCA_DEVICE_DEFAULT_MAX_TTS_VOLUME
_permanentOffsetIsEnabled
_userIntentVolume
_latestVolume
_permanentOffsetFactor
_userIntentType
_userIntentTime
_userIntentValidForSeconds
_latestVolumeTime
TQ,N,V_userIntentType
TQ,N,V_userIntentTime
TQ,N,V_userIntentValidForSeconds
TQ,N,V_latestVolumeTime
Tf,N,V_userIntentVolume
Tf,N,V_latestVolume
Tf,N,V_permanentOffsetFactor
TB,N,V_permanentOffsetIsEnabled
initWithDroppingPrediction:droppedPrediction:timestamp:
toString
droppingPrediction
droppedPrediction
timestamp
_droppingPrediction
_droppedPrediction
_timestamp
Td,R,N,V_droppingPrediction
Td,R,N,V_droppedPrediction
Td,R,N,V_timestamp
speakAudio:
speakAudio:withScaleFactor:outASBD:playbackStarted:completion:
setIsConnected:
_isConnected
_enableAlwaysOnVoiceTrigger
_deviceType
_deviceID
_deviceUID
_productIdentifier
_injectionEngine
Tq,R,N,V_deviceType
T@"NSString",R,N,V_deviceName
T@"NSString",R,N,V_deviceID
T@"NSUUID",R,N,V_deviceUID
T@"NSString",R,N,V_productIdentifier
TB,N,V_isConnected
TB,N,V_enableAlwaysOnVoiceTrigger
T@"CSAudioInjectionEngine",W,N,V_injectionEngine
setTotalAudioRecorded:
setFeaturesAtEndpoint:
setEndpointerType:
setServerFeatureLatencyDistribution:
setAdditionalMetrics:
_totalAudioRecorded
_featuresAtEndpoint
_endpointerType
_serverFeatureLatencyDistribution
_additionalMetrics
Td,N,V_totalAudioRecorded
T@"NSArray",&,N,V_featuresAtEndpoint
Tq,N,V_endpointerType
T@"NSDictionary",&,N,V_serverFeatureLatencyDistribution
T@"NSDictionary",&,N,V_additionalMetrics
T@"NSString",C,N,V_deviceId
initWithSamplingRate:withAsset:
CSAlarmMonitor:didReceiveAlarmChanged:
CSTimerMonitor:didReceiveTimerChanged:
CSVolumeMonitor:didReceiveMusicVolumeChanged:
CSVolumeMonitor:didReceiveAlarmVolumeChanged:
smartSiriVolume
setSmartSiriVolume:
_smartSiriVolume
T@"<CSSmartSiriVolumeProcessor>",&,N,V_smartSiriVolume
T@"<CSConnectionServiceDelegate>",W,N,V_delegate
setValue:forKey:
_setMaximumBufferSizeFromInUseServices
createAudioFileWriterForAdBlockerWithInputFormat:outputFormat:withAccessoryID:
copyBufferWithNumSamplesCopiedIn:
isAdBlockerAudioLoggingEnabled
startWithUUID:withMaximumBufferSize:
stopWithUUID:
isListenPollingStarting
setIsListenPollingStarting:
audioLoggingBuffer
setAudioLoggingBuffer:
inUseServices
setInUseServices:
currentMaximumBufferSize
setCurrentMaximumBufferSize:
_currentMaximumBufferSize
_audioLoggingBuffer
_inUseServices
TB,N,V_isListenPollingStarting
T@"CSAudioCircularBuffer",&,N,V_audioLoggingBuffer
T@"NSMutableDictionary",&,N,V_inUseServices
Tf,N,V_currentMaximumBufferSize
attSiriUresNode:withUresScore:
_getInputoriginFromRecordType:
setInputOrigin:
setSpeechPackage:
setDidDetectSpeechActivity:
setIsAirpodsConnected:
setDecisionStage:
setTimeSinceLastQuery:
setPrevStageOutput:
setAcousticFTMScores:
setSpeakerIDScore:
setBoronScore:
setNldaScore:
setNldaMetaInfo:
_updateSupportedInputOrigins
_logFinalMitigationDecisionToSelf:
insertObject:atIndex:
_createMitigatorModelWithConfig:
_logURESFailureMsgInput:
_releaseUresProcessingTransaction
didMitigate
_storeMitigationDecision:forRCId:
detailedResult
_logURESResultsForInput:withOutput:
processInputFeats:completion:
_logLRNNFailMsg
_updateSignalsFrom:to:
isEqualToNumber:
_createModelAndRunInferenceForRcId:withCompletion:
_logLatticeRNNResults:
initWithConfig:error:
_holdTransactionForUresProcessing
allValues
isUIButtonPress
isHomePressed
isHearstDoubleTapTriggered
_decodeJsonFromFile:
arrayWithArray:
attSiriNode:didUpdateAttentionState:
getLastMitigationResult
configureAttendingState:
registerNLDAClassifierNode:
getLatestUresFeaturesWithCompletion:
registerOSDNode:
mitigator
setMitigator:
lastInputFeats
setLastInputFeats:
mitigationDecisions
setMitigationDecisions:
setSupportedInputOrigins:
shouldUpdateMitigationResult
setShouldUpdateMitigationResult:
osTransaction
setOsTransaction:
isAttending
setIsAttending:
cachedMitigationDecision
setCachedMitigationDecision:
_shouldUpdateMitigationResult
_isAttending
_cachedMitigationDecision
_mitigator
_lastInputFeats
_mitigationDecisions
_supportedInputOrigins
_osTransaction
T@"SLUresMitigator",&,N,V_mitigator
T@"SLUresMitigatorIpFeats",&,N,V_lastInputFeats
T@"NSMutableArray",&,N,V_mitigationDecisions
T@"NSArray",&,N,V_supportedInputOrigins
TB,N,V_shouldUpdateMitigationResult
T@"CSOSTransaction",&,N,V_osTransaction
TB,N,V_isAttending
TB,N,V_cachedMitigationDecision
T@"CSAttSiriOSDNode",W,N,SregisterOSDNode:,V_osdNode
T@"CSAttSiriNLDAClassifierNode",W,N,SregisterNLDAClassifierNode:,V_nldaClassifierNode
_hasDeviceTemporaryPairedNotInContacts
splitterDeviceList
shouldDisableSpeakerVerificationInSplitterMode
splitterEnabled
_splitterDeviceList
_splitterEnabled
TB,N,V_splitterEnabled
_didInstalledNewAdBlockerAsset
CSAdBlockerAssetDownloadMonitor:didInstallNewAsset:assetProviderType:
monitor
setMonitor:
_monitor
T@"CSTrialAssetDownloadMonitor",&,N,V_monitor
startManager
_createClearLoggingFileTimer
_startClearLoggingFilesTimer
supportHearstVoiceTrigger
supportJarvisVoiceTrigger
supportBluetoothDeviceVoiceTrigger
_getAudioRecorderWithError:
audioProviders
daysBeforeRemovingLogFiles
removeLogFilesOlderThanNDays:
removeOpportunisticAudioLoggingOlderThanNDays:
removeRemoteP2PLogFilesOlderThanNDays:
_handleClearLoggingFileTimer
audioFingerprintProvider
_getVoiceTriggerAssetIfNeeded:
registerSpeechController:
registerSiriClientProxy:
audioProviderWithUUID:
audioProviderWithStreamID:
_reinitializeSmartSiriVolumeWithAsset:
assetQueryQueue
setAssetQueryQueue:
setAudioProviders:
fallbackAudioSessionReleaseProvider
setFallbackAudioSessionReleaseProvider:
clientController
setClientController:
clearLoggingFileTimer
setClearLoggingFileTimer:
clearLoggingFileTimerCount
setClearLoggingFileTimerCount:
opportuneSpeakListnerTestService
setOpportuneSpeakListnerTestService:
postBuildInstallService
setPostBuildInstallService:
_assetQueryQueue
_audioProviders
_fallbackAudioSessionReleaseProvider
_clientController
_clearLoggingFileTimer
_clearLoggingFileTimerCount
_opportuneSpeakListnerTestService
_postBuildInstallService
T@"NSObject<OS_dispatch_queue>",&,N,V_assetQueryQueue
T@"NSMutableDictionary",&,N,V_audioProviders
T@"CSFallbackAudioSessionReleaseProvider",&,N,V_fallbackAudioSessionReleaseProvider
T@"<CSSpeechManagerDelegate>",W,N,V_clientController
T@"NSObject<OS_dispatch_source>",&,N,V_clearLoggingFileTimer
Tq,N,V_clearLoggingFileTimerCount
T@"CSOpportuneSpeakListnerTestService",&,N,V_opportuneSpeakListnerTestService
T@"CSPostBuildInstallService",&,N,V_postBuildInstallService
initWithDictionary:
notifyImplicitUtterance:audioDeviceType:audioRecordType:voiceTriggerEventInfo:otherCtxt:completion:
zeroFilterWindowSizeInMsForReport
shouldDeinterleaveAudioOnCS
_methodToken
_continuousZeroCounter
_zeroCounterWinSz
_zeroCounterWinSzForReport
_maxContinuousZeroCount
_analyzeStep
_shouldDeinterleaveAudio
supportAttentionLostAndGain
dictionaryWithDictionary:
expressionForConstantValue:
expressionForFunction:arguments:
expressionValueWithObject:context:
sortUsingComparator:
audioAlertProvider
setAudioAlertProvider:
setAudioMeterProvider:
_handleAudioProvidingMessage:messageBody:client:
_handlePingPongMessage:client:
_handleSetXPCClientTypeMessage:messageBody:client:
_handleAudioProvidingRequestTypeSwitchMessage:messageBody:client:
_getAudioProvideWithContext:streamClientType:
_notifyXPCDisconnectionToProxies
clientType
_notifyXPCDisconnectionToProxy:
audioSessionProvidingProxy
setAudioSessionProvidingProxy:
fallbackAudioSessionProvidingProxy
setFallbackAudioSessionProvidingProxy:
audioSessionInfoProvidingProxy
setAudioSessionInfoProvidingProxy:
audioStreamProvidingProxy
setAudioStreamProvidingProxy:
audioAlertProvidingProxy
setAudioAlertProvidingProxy:
audioMeterProvidingProxy
setAudioMeterProvidingProxy:
audioMetricProvidingProxy
setAudioMetricProvidingProxy:
setClientType:
_audioSessionProvidingProxy
_fallbackAudioSessionProvidingProxy
_audioSessionInfoProvidingProxy
_audioStreamProvidingProxy
_audioAlertProvidingProxy
_audioMeterProvidingProxy
_audioMetricProvidingProxy
_clientType
T@"CSAudioSessionProvidingProxy",&,N,V_audioSessionProvidingProxy
T@"CSFallbackAudioSessionReleaseProvidingProxy",&,N,V_fallbackAudioSessionProvidingProxy
T@"CSAudioSessionInfoProvidingProxy",&,N,V_audioSessionInfoProvidingProxy
T@"CSAudioStreamProvidingProxy",&,N,V_audioStreamProvidingProxy
T@"CSAudioAlertProvidingProxy",&,N,V_audioAlertProvidingProxy
T@"CSAudioMeterProvidingProxy",&,N,V_audioMeterProvidingProxy
T@"CSAudioMetricProvidingProxy",&,N,V_audioMetricProvidingProxy
TQ,N,V_clientType
T@"<CSXPCConnectionDelegate>",W,N,V_delegate
initWithAttSiriController:supportsAttentiveSiri:supportsSpeechRecognitionOnDevice:supportsSSR:
_setupAttSiriServiceListener
_setupEndpointListener
_setupLocalSpeechRecognitionListener
_setupSSRListener
didDetectHardEndpointAtTime:withMetrics:
setupListeners
localSpeechRecognitionListener
setLocalSpeechRecognitionListener:
setSupportsSpeechRecognitionOnDevice:
supportsSSR
setSupportsSSR:
_supportsSpeechRecognitionOnDevice
_supportsSSR
_localSpeechRecognitionListener
T@"CSAttSiriController",&,N,V_attSiriController
T@"CSConnectionListener",&,N,V_localSpeechRecognitionListener
TB,N,V_supportsSpeechRecognitionOnDevice
TB,N,V_supportsSSR
_daemonDidLaunch
_daemonWillShutdown
_setupNotifyHandlers
notifyDaemonStateChanged:
sharedDaemon
didLaunch
shutdown
xpcListener
setXpcListener:
activationXpcListener
setActivationXpcListener:
voiceIdXpcListener
setVoiceIdXpcListener:
voiceTriggerXpcListener
setVoiceTriggerXpcListener:
audioInjectionXpcListener
setAudioInjectionXpcListener:
attSiriConnectionManager
setAttSiriConnectionManager:
corespeechServiceListener
setCorespeechServiceListener:
speechModelTrainingXpcManager
setSpeechModelTrainingXpcManager:
benchmarkXpcListener
setBenchmarkXpcListener:
signalSource
setSignalSource:
_xpcListener
_activationXpcListener
_voiceIdXpcListener
_voiceTriggerXpcListener
_audioInjectionXpcListener
_attSiriConnectionManager
_corespeechServiceListener
_speechModelTrainingXpcManager
_benchmarkXpcListener
_signalSource
T@"CSXPCListener",&,N,V_xpcListener
T@"CSActivationXPCListener",&,N,V_activationXpcListener
T@"CSVoiceIdXPCListener",&,N,V_voiceIdXpcListener
T@"CSVoiceTriggerXPCListener",&,N,V_voiceTriggerXpcListener
T@"CSAudioInjectionXPCListener",&,N,V_audioInjectionXpcListener
T@"CSAttSiriConnectionManager",&,N,V_attSiriConnectionManager
T@"CSCoreSpeechServicesListener",&,N,V_corespeechServiceListener
T@"CSSpeechModelTrainingXPCManager",&,N,V_speechModelTrainingXpcManager
T@"CSBenchmarkXPCListener",&,N,V_benchmarkXpcListener
T@"NSObject<OS_dispatch_source>",&,N,V_signalSource
_emitMHEndpointLatencyInfo:withRequestMHUUID:
currentContext
initWithInstanceContext:
firstPktLatency
trailingPktSpeechLatencies
setTrailingPktSpeechLatencies:
trailingPktLatencies
setTrailingPktLatencies:
numOfAudioPackets
setNumOfAudioPackets:
numOfValidTrailingPackets
setNumOfValidTrailingPackets:
numOfValidTrailingSpeechPackets
setNumOfValidTrailingSpeechPackets:
_firstPktLatency
_trailingPktSpeechLatencies
_trailingPktLatencies
_numOfAudioPackets
_numOfValidTrailingPackets
_numOfValidTrailingSpeechPackets
T@"NSMutableArray",&,N,V_trailingPktSpeechLatencies
T@"NSMutableArray",&,N,V_trailingPktLatencies
TQ,N,V_numOfAudioPackets
TQ,N,V_numOfValidTrailingPackets
TQ,N,V_numOfValidTrailingSpeechPackets
Td,N,V_firstPktLatency
readAudioChunksFrom:block:
_didReceiveDaemonStateChanged:
_notifyObserver:withDaemonState:
coreSpeechDaemonStateMonitor:didReceiveStateChanged:
currentBuiltinSpeakerState
isBuiltinSpeakerMuted
setBuiltInSpeakerState:
T@"<CSRemoteRecordClientDelegate>",W,N,V_delegate
TQ,R,N,V_audioStreamHandleId
processIdentifier
clientConnections
setClientConnections:
machServiceName
setMachServiceName:
_exportedInterface
_remoteInterface
_proxyObject
_clientConnections
_machServiceName
T@"NSMutableArray",&,N,V_clientConnections
T@"NSString",&,N,V_machServiceName
_enableCoreSpeechDaemonKeepAlive
_coreSpeechDaemonKeepAlived
writeToFile:atomically:encoding:error:
localizedRecoverySuggestion
CSSiriAssertionMonitor:didReceiveEnabled:
_assertionState
resetDucking
_handleSessionProvidingRequestTypePrewarmMessage:client:
_handleSessionProvidingRequestTypeActivateMessage:messageBody:client:
_handleSessionProvidingRequestTypeDeactivateMessage:messageBody:client:
_handleSessionProvidingRequestTypeGetDuckOthersOption:messageBody:client:
_handleSessionProvidingRequestTypeSetDuckOthersOption:messageBody:client:
_handleSessionProvidingRequestTypeEnableMiniDucking:messageBody:client:
_handleSessionProvidingRequestTypeDuckAudioDevice:messageBody:client:
_handleSessionProvidingRequestTypeDuckDefaultOutputAudioDevice:messageBody:client:
_handleSessionProvidingRequestTypeEnableSmartRoutingConsideration:messageBody:client:
_handleSessionProvidingRequestTypeReportDynamicActivityAttribute:messageBody:client:
duckAudioDeviceWithDeviceID:duckedLevel:rampDuration:
duckDefaultOutputAudioDeviceWithDuckedLevel:rampDuration:
audioSessionProvider:didReceiveAudioSessionInterruptionNotificationWithUserInfo:
audioSessionProvider:didReceiveAudioSessionRouteChangeNotificationWithUserInfo:
audioSessionProvider:didReceiveAudioSessionMediaServicesWereLostNotificationWithUserInfo:
audioSessionProvider:didReceiveAudioSessionMediaServicesWereResetNotificationWithUserInfo:
manualDuckingHandler
setManualDuckingHandler:
_manualDuckingHandler
T@"CSManualDuckingHandler",&,N,V_manualDuckingHandler
splitterState:
isUserActive
getLocalUrl
_compatibilityVersion
stringValue
appendString:
_version
_footprint
assetForAssetType:resourcePath:configVersion:
isPremium
_notifyStopCommandControl
_isCommandControlStreaming
_handleAlertProvidingRequestTypeSetAlertSoundMessage:messageBody:client:
_handleAlertProvidingRequestTypePlayAlertSoundMessage:messageBody:client:
_handleAlertProvidingRequestTypePlayRecordStartingAlertAndResetEndpointerMessage:messageBody:client:
_handleAlertProvidingRequestTypeAlertStartTimeMessage:messageBody:client:
_handleAlertProvidingRequestTypeConfigureAlertBehavior:messageBody:client:
_sendReplyMessageWithResult:event:client:
_audioAlertProvider
T@"<CSAudioAlertProviding>",W,N,V_audioAlertProvider
_startObservingAVCallActiveChange
_handleCallActiveDidChangeNotification:
hasConnectedAVCall
_hasConnectedAVCall
_handleVoiceTriggerXPCServiceMessage:client:
_handleServiceConnectionLostIfNeeded
_handlePhraseSpotterBypassRequest:
_handleVoiceTriggeredSiriSessionCancelled
_handleEnableVoiceTriggerWithSiriAssertionRequest:
_handleRaiseToSpeakBypassRequest:
_handleVoiceTriggerStatsFetchEvent:client:
T@"<CSVoiceTriggerXPCConnectionDelegate>",W,N,V_delegate
startWithContext:audioStreamId:
kwdSpotter
setKwdSpotter:
didTrigger
setDidTrigger:
setAudioStreamId:
_didTrigger
_kwdSpotter
_audioStreamId
T@"CSFlexKeywordSpotter",&,N,V_kwdSpotter
T@"CSAttSiriRequestContext",&,N,V_context
TB,N,V_didTrigger
TQ,N,V_audioStreamId
triggerVoiceProfileRetrainingWithAsset:
playbackDeviceTypeList
_recordDeviceInfo
_playbackRoute
_playbackDeviceTypeList
T@"CSAudioRecordDeviceInfo",R,C,N,V_recordDeviceInfo
T@"NSString",R,C,N,V_playbackRoute
T@"NSArray",R,C,N,V_playbackDeviceTypeList
mainRunLoop
_didReceiveNewAdBlockerAssetMetaData
adBlockerAssetDecoderWithVersion:
_createDeInterleaverIfNeeded
_startAudioFeedingTimer
lpcmNonInterleavedASBD
_deinterleaveBufferIfNeeded:
setFileOption:
_defaultOutASBD
lpcmFloatASBD
fileOption
setIsRecording:
bufferDuration
setBufferDuration:
injectionAudioFileList
setInjectionAudioFileList:
injectionStartNotifyBlocks
setInjectionStartNotifyBlocks:
injectionCompletionNotifyBlocks
setInjectionCompletionNotifyBlocks:
deinterleaver
setDeinterleaver:
pNonInterleavedABL
setPNonInterleavedABL:
didSetScaleFactor
setDidSetScaleFactor:
setScaleFactor:
_isRecording
_didSetScaleFactor
_fileOption
_injectionAudioFileList
_injectionStartNotifyBlocks
_injectionCompletionNotifyBlocks
_deinterleaver
T@"CSAudioInjectionFileOption",&,N,V_fileOption
TB,N,V_isRecording
Td,N,V_bufferDuration
T@"NSMutableArray",&,N,V_injectionAudioFileList
T@"NSMutableArray",&,N,V_injectionStartNotifyBlocks
T@"NSMutableArray",&,N,V_injectionCompletionNotifyBlocks
T^{OpaqueAudioConverter=},N,V_deinterleaver
T^{AudioBufferList=I[1{AudioBuffer=II^v}]},N,V_pNonInterleavedABL
TB,N,V_didSetScaleFactor
Tf,N,V_scaleFactor
_checkSoftwareUpdateCheckingState
_didReceiveSoftwareUpdateCheckingStateChanged:
_softwareUpdateCheckingState
_notifyObserver:withSoftwareUpdateCheckingRunning:
CSSoftwareUpdateCheckingMonitor:didReceiveStateChanged:
_didReceiveSoftwareUpdateCheckingStateChangedInQueue:
_isSoftwareUpdateCheckingRunning
lpcmInt16NarrowBandASBD
opusNarrowBandASBD
_configureAudioConverter:
_convertBufferedLPCM:allowPartial:timestamp:arrivalTimestampToAudioRecorder:
replaceBytesInRange:withBytes:length:
narrowBandOpusConverter
_opusConverter
_bufferedLPCM
_recordBasePacketsPerSecond
_opusOutASBD
_convertPacketCount
_convertAudioCapacity
_lastTimestamp
_lastArrivalTimestampToAudioRecorder
_outPacketSizeInSec
T@"<CSAudioConverterDelegate>",W,V_delegate
_notifyObserver:mediaIsPlayingState:
_notePossiblePlayPausedStateChange:
mediaPlayingStateWithCompletion:
_addVoiceTriggerAOPModeEnabledConditions
forceVoiceTriggerAPMode
_addConditionsForIOSBargeIn
_addConditionsForIOSAOP
_isSpeechDetectionDevicePresent
isSiriClientConsideredAsRecord
setIsSiriClientConsideredAsRecord:
setPendingRecordingStopUUID:
notifyCallbackWithOption:
pendingRecordingStopUUID
_recordStateQueue
_isSiriClientConsideredAsRecord
_pendingRecordingStopUUID
TB,N,V_isSiriClientConsideredAsRecord
T@"NSString",&,N,V_pendingRecordingStopUUID
updateDeviceId:
_shouldUseRemoteRecorder
_streamHandleId
T@"CSAudioRecordContext",R,N,V_recordContext
TB,R,N,V_shouldUseRemoteRecorder
TQ,R,N,V_streamHandleId
sharedVoiceTriggerClient
voiceTriggerAOPModeEnabledPolicy
_availabilityChanged
_didReceivedNetworkAvailabilityChangedNotification:
_notifyObserver:withNetworkAvailability:
CSNetworkAvailabilityMonitor:didReceiveNetworkAvailabilityChanged:
_handleMeterProvidingRequestTypeSetMeteringEnabledMessage:messageBody:client:
_handleMeterProvidingRequestTypeUpdateMetersMessage:messageBody:client:
_handleMeterProvidingRequestTypePowerMessage:messageBody:client:powerType:
audioMeterProvider
_audioMeterProvider
T@"<CSAudioMeterProviding>",W,N,V_audioMeterProvider
CSMicUsageReporter
v8@?0
com.apple.siri.speechmodeltraining
com.apple.corespeech.speechmodeltraining.xpc
com.apple.speech.speechmodeltraining
SpeechModelTrainingClient
v24@?0@"NSString"8@"NSError"16
v16@?0@"NSError"8
v16@?0@"NSString"8
v24@?0@"NSDictionary"8@"NSError"16
Assistant/SpeechPersonalizedLM
Assistant/SpeechPersonalizedLM_Fides
Received Error %@
Input directory path(%@) does not match expected path
Dictation
-[CSSyncKeywordAnalyzerQuasar initWithConfigPath:triggerTokens:useKeywordSpotting:preventDuplicatedReset:]
-[CSSyncKeywordAnalyzerQuasar resetWithLanguage:withFarField:withAudioSource:]
-[CSSyncKeywordAnalyzerQuasar flushAudio]
-[CSSyncKeywordAnalyzerQuasar processAudioChunk:]
-[CSSyncKeywordAnalyzerQuasar phraseIdScores]
+[CSSyncKeywordAnalyzerQuasar dumpEARSpeechRecognitionResults:]
v32@?0@"_EARSpeechRecognitionToken"8Q16^B24
samples_fed
best_start
best_end
best_score
is_secondchance
isEarlyDetect
type
-[CSFallbackAudioSessionReleaseProvidingProxy handleXPCMessage:messageBody:client:]
option
-[CSFallbackAudioSessionReleaseProvidingProxy _handleDeactivateAudioSessionRequestMessage:messageBody:client:]
result
resultErrorDomain
resultErrorCode
+[CSUserIdentityClassifier pickTopScoringProfileIdFromScores:]
+[CSUserIdentityClassifier classifyUserIdentityFor:withScores:withAsset:]
Confident
Known
Unknown
Unsure1
UnsureN
+[CSUserIdentityClassifier stringFromClassificationCategory:]
-[CSAudioStartStreamOption(AVVC) avvcStartRecordSettingsWithAudioStreamHandleId:]
com.apple.corespeech.corespeechd.activation.xpc
v16@?0@"NSObject<OS_xpc_object>"8
-[CSActivationXPCClient dealloc]
-[CSActivationXPCClient _handleListenerEvent:]
-[CSActivationXPCClient _handleListenerError:]
-[CSActivationXPCClient notifyActivationEvent:completion:]
v20@?0B8@"NSError"12
event
CSAttSiriRequestSourceKey
SiriFollowupforIdleAndQuiet
LockScreenNotification
-[CSAudioSampleRateConverter _createSampleRateConverterWithInASBD:outASBD:]
i32@?0^I8^{AudioBufferList=I[1{AudioBuffer=II^v}]}16^^{AudioStreamPacketDescription}24
-[CSAudioSampleRateConverter convertSampleRateOfBuffer:]
v12@?0i8
-[CSSpeakerRecognitionAssetMetaUpdateMonitor _startMonitoringWithQueue:]
-[CSSpeakerRecognitionAssetMetaUpdateMonitor _stopMonitoring]
-[CSSpeakerRecognitionAssetMetaUpdateMonitor _didReceiveSpeakerRecognitionAssetMetaData]
v16@?0@8
com.apple.MobileAsset.SpeakerRecognitionAssets.ma.cached-metadata-updated
Audio/Video
Alarm
CSVolumeMonitor queue
-[CSVolumeMonitor _startMonitoringWithQueue:]
-[CSVolumeMonitor fetchVolumeFromAVSystemControllerForAudioCategory:]_block_invoke
-[CSVolumeMonitor systemControllerDied:]
-[CSVolumeMonitor startObservingSystemVolumes]
-[CSVolumeMonitor _startObservingSystemControllerLifecycle]
CSFallbackAudioSessionReleaseProvider
-[CSFallbackAudioSessionReleaseProvider fallbackDeactivateAudioSession:error:]_block_invoke
-[CSFallbackAudioSessionReleaseProvider fallbackDeactivateAudioSession:error:]
-[CSSpeakerRecognitionAssetDownloadMonitor _startMonitoringWithQueue:]
-[CSSpeakerRecognitionAssetDownloadMonitor _stopMonitoring]
-[CSSpeakerRecognitionAssetDownloadMonitor _didInstalledNewAsset]
-[CSSpeakerRecognitionAssetDownloadMonitor trialAssetDownloadMonitorDelegate:didInstallNewAsset:assetType:]
com.apple.MobileAsset.SpeakerRecognitionAssets.ma.new-asset-installed
{wordCount: %ld, trailingSilDuration: %ld, eosLikelihood: %f, pauseCounts: (%@), silencePosterior: %f, taskName: %@, processedAudioDurationInMilliseconds: %ld}
WordCount
TrailingSilDuration
EOSLikelihood
PauseCounts
SilencePosterior
ProcessedAudioDurationInMilliseconds
-[CSVoiceTriggerXPCServiceProxy enableVoiceTrigger:withAssertion:timestamp:]
voicetrigger assertion queue
-[CSVoiceTriggerXPCServiceProxy enableVoiceTrigger:withAssertion:timestamp:]_block_invoke
Enabled
Disabled
phrasespotter assertion queue
-[CSVoiceTriggerXPCServiceProxy setPhraseSpotterBypassing:timeout:]_block_invoke_2
bypassed
NOT bypassed
-[CSVoiceTriggerXPCServiceProxy setPhraseSpotterBypassing:timeout:]_block_invoke
raise-to-speak assertion queue
-[CSVoiceTriggerXPCServiceProxy setRaiseToSpeakBypassing:timeout:]_block_invoke_2
-[CSVoiceTriggerXPCServiceProxy setRaiseToSpeakBypassing:timeout:]_block_invoke
-[CSVoiceTriggerXPCServiceProxy notifyVoiceTriggeredSiriSessionCancelled]
-[CSVoiceTriggerXPCServiceProxy notifyServiceConnectionLost]
-[CSAttSiriAudioSessionStateClient initWithDelegate:]
SiriStateNotificationListener
com.apple.siri.client-state-changed
-[CSAttSiriAudioSessionStateClient notifyObserver:didReceiveNotificationWithToken:]
-[CSAttSiriAudioSessionStateClient notifyObserver:didChangeStateFrom:to:]
-[CSAttSiriAudioSessionStateClient dispatchStateChangedFrom:to:]
-[CSAudioStreamProvidingProxy setAudioStreamProvidingForProxy:]
-[CSAudioStreamProvidingProxy CSXPCConnectionReceivedClientError:clientError:client:]
-[CSAudioStreamProvidingProxy handleXPCMessage:messageBody:client:]
-[CSAudioStreamProvidingProxy _handleSetCurrentConextMessage:messageBody:client:]
context
audioStreamRequest
-[CSAudioStreamProvidingProxy _handleAudioStreamRequestMessage:messageBody:client:]
-[CSAudioStreamProvidingProxy _handleAudioStreamPrepareMessage:messageBody:client:]
startAudioStreamOption
-[CSAudioStreamProvidingProxy _handleStartAudioStreamMessage:messageBody:client:]
-[CSAudioStreamProvidingProxy _handleStopAudioStreamMessage:messageBody:client:]
-[CSAudioStreamProvidingProxy _handleVoiceTriggerInfoMessage:messageBody:client:]
voiceTriggerInfo
rtsTriggerInfo
-[CSAudioStreamProvidingProxy _handleIsRecordingMessage:messageBody:client:]
-[CSAudioStreamProvidingProxy _handleRecordRouteMessage:messageBody:client:]
recordRoute
-[CSAudioStreamProvidingProxy _handleRecordDeviceInfo:messageBody:client:]
recordDeviceInfo
-[CSAudioStreamProvidingProxy _handleAudioDeviceInfo:messageBody:client:]
audioDeviceInfo
-[CSAudioStreamProvidingProxy _handleRecordSettings:messageBody:client:]
recordSettings
-[CSAudioStreamProvidingProxy _handleIsNarrowband:messageBody:client:]
-[CSAudioStreamProvidingProxy _handlePlaybackRouteMessage:messageBody:client:]
playbackRoute
-[CSAudioStreamProvidingProxy audioStreamProvider:didStopStreamUnexpectly:]
stopReason
chunk
-[CSAudioStreamProvidingProxy audioStreamProvider:didHardwareConfigurationChange:]
hardwareConfig
body
-[CSAudioStreamProvidingProxy _setAllowMixableAudioWhileRecording:]
Token
BestScore
StartSampleId
EndSampleId
com.apple.flxkwd
-[CSFlexKeywordSpotter startKeywordSpottingWithCompletion:]_block_invoke_2
-[CSFlexKeywordSpotter startKeywordSpottingWithCompletion:]_block_invoke
Unexpected exception creating KeywordDetector
reason
Exception creating KeywordDetector: %s
v24@?0@"CSAsset"8@"NSError"16
-[CSFlexKeywordSpotter processAudioChunk:]_block_invoke
-[CSFlexKeywordSpotter speechRecognizer:didFinishRecognitionWithError:]
-[CSFlexKeywordSpotter speechRecognizer:didRecognizeFinalResults:]
Kwds: 
%@:%f:%f:%f
===WinningTok=%@, bestScore=%f===
-[CSFlexKeywordSpotter speechRecognizer:didRecognizePartialResultNbest:]_block_invoke
-[CSFlexKeywordSpotter speechRecognizer:didRecognizePartialResult:]
getThresholdsMapAt_block_invoke
-[CSAttSiriAttendingAudioSrcNode initWithAttSiriController:]
CSAttSiriAudioSrcNode Attending queue
-[CSAttSiriAttendingAudioSrcNode initWithSpeechManager:audioStreamProvider:streamName:streamRequest:]
CSAttSiriAudioSrcNode
-[CSAttSiriAttendingAudioSrcNode startAudioStreamWithOption:completion:]_block_invoke_2
-[CSAttSiriAttendingAudioSrcNode addReceiver:]_block_invoke
-[CSAttSiriAttendingAudioSrcNode dealloc]
-[CSAttSiriAttendingAudioSrcNode _handleDidStop]
-[CSAudioFileLog _closeAudioFile]
-[CSAudioFileLog startRecording]_block_invoke
-input.wav
-[CSAudioFileLog appendAudioData:]_block_invoke
-[CSAudioFileLog stopRecording]_block_invoke
Logs/CrashReporter/CoreSpeech/audio/
-[CSAudioFileLog _getOrCreateAudioLogDirectory]
/tmp
en_US_POSIX
yyyyMMdd-HHmmss
%@/%@%@%@
CSAudioSessionInfoProvider
-[CSAudioSessionInfoProvider audioSessionIdForDeviceId:]
-[CSAudioSessionInfoProvider CSAudioServerCrashMonitorDidReceiveServerCrash:]_block_invoke
-[CSAudioSessionInfoProvider CSAudioServerCrashMonitorDidReceiveServerRestart:]_block_invoke
-[CSAudioSessionInfoProvider _registerInterruptionNotification]
-[CSAudioSessionInfoProvider _registerAudioRouteChangeNotification]
-[CSAudioSessionInfoProvider _handleInterruption:]_block_invoke
-[CSAudioSessionInfoProvider _audioRouteChanged:]_block_invoke
RouteChangeNotificationInfo
-[CSAudioSessionInfoProvider _deregisterAudioSessionNotifications]
firstPassTriggerSource
ApplicationProcessor
Remora
CSPreMyriadCoordinator Queue
-[CSPreMyriadCoordinator _clearPendingRemoraVoiceTrigger]
-[CSPreMyriadCoordinator handlePendingRemoraVoiceTriggerIfNeeded]
-[CSPreMyriadCoordinator handlePendingRemoraVoiceTriggerIfNeeded]_block_invoke
-[CSPreMyriadCoordinator _clearPendingBuiltInVoiceTrigger]
-[CSPreMyriadCoordinator handlePendingBuiltInVoiceTriggerIfNeeded]
-[CSPreMyriadCoordinator handlePendingBuiltInVoiceTriggerIfNeeded]_block_invoke
v32@?0@"NSString"8@"CSPreMyriadVoiceTriggerMetaData"16^B24
-[CSPreMyriadCoordinator secondPassDidStopForClient:deviceId:]
-[CSPreMyriadCoordinator secondPassDidStartForClient:deviceId:withFirstPassEstimate:]
+[CSUtils(AttSiri) logMitigationFeatures:forTask:withModelOutput:forMHRequestId:]
%@-%@.json
Task
Transcript
DetailedModelResult
AcousticFTMScore
InputOrigin
osdSignal
timeSinceLastQuery
airpodsConnected
boronSignal
decisionStage
prevInputLevel
speakerIDScore
eosLikelihood
timestamp
RawASRRecogCandidate
LatticeRNNResult
NLDAMetaInfo
triggerEndMachTime
triggerFireMachTime
-[CSAttSiriEndpointerNode initWithAttSiriController:]
CSAttSiriEndpointerNode queue
CSAttSiriEndpointerNode Latency Queue
-[CSAttSiriEndpointerNode addReceiver:]_block_invoke
-[CSAttSiriEndpointerNode resetForNewRequestWithSampleRate:recordContext:recordOption:voiceTriggerInfo:]_block_invoke
audioURL : %@, numberOfChannels : %lu, scaleFactor: %f
CSSmartSiriVolumeEnablePolicy queue
B8@?0
-[CSSmartSiriVolumeEnablePolicy _addSmartSiriVolumeEnabledConditions]_block_invoke
triggerEndSeconds
userIdentityClassification
userClassified
-[CSAttSiriSSRNode stop]_block_invoke
-[CSAttSiriSSRNode addReceiver:]_block_invoke
B24@?0@"SSRVoiceProfile"8@"NSDictionary"16
-[CSAttSiriSSRNode filteredVoiceProfileArray:]
en-US
-[CSAttSiriSSRNode _setupSSRControllerWithAudioContext:withVoiceTriggerEventInfo:]
-[CSAttSiriSSRNode _setupSSRControllerWithAudioContext:withVoiceTriggerEventInfo:]_block_invoke_2
-[CSAttSiriSSRNode _setupSSRControllerWithAudioContext:withVoiceTriggerEventInfo:]_block_invoke
-[CSAttSiriSSRNode _setupSpeakerRecognitionForProfiles:WithVTEventInfo:WithLocale:]
-[CSAttSiriSSRNode _refreshSpeakerRecognitionAssets]
-[CSAttSiriSSRNode startXPCConnection]
-[CSAttSiriSSRNode CSSpeakerRecognitionAssetDownloadMonitor:didInstallNewAsset:assetProviderType:]_block_invoke
-[CSAttSiriSSRNode speakerRecognitionController:hasSpeakerInfo:]_block_invoke
-[CSAttSiriSSRNode speakerRecognitionController:hasSpeakerInfo:]
-[CSAttSiriSSRNode speakerRecognitionFinishedProcessing:withFinalSpeakerInfo:]_block_invoke
-[CSAttSiriSSRNode _processSpeakerRecognitionResult:]
-[CSAttSiriSSRNode _mapScoresToSharedSiriId:]
-[CSAttSiriSSRNode _stopProcessing]
-[CSAttSiriSSRNode _stopProcessing]_block_invoke
-[CSAttSiriSSRNode attSiriAudioSrcNodeDidStop:]_block_invoke
-[CSSiriRestrictionOnLockScreenMonitor _startMonitoringWithQueue:]
-[CSSiriRestrictionOnLockScreenMonitor _stopMonitoring]
-[CSSiriRestrictionOnLockScreenMonitor _checkSiriRestrictedOnLockScreen]
-[CSPostBuildInstallService registerPostBuildInstallService]
-[CSPostBuildInstallService registerPostBuildInstallService]_block_invoke
com.apple.cs.postinstall
com.apple.transcribe.Transcriber
-[CSKeywordAnalyzerQuasar initWithConfigPath:triggerTokens:useKeywordSpotting:]
-[CSKeywordAnalyzerQuasar initWithConfigPath:triggerTokens:useKeywordSpotting:]_block_invoke
-[CSKeywordAnalyzerQuasar reset]
-[CSKeywordAnalyzerQuasar dealloc]
-[CSKeywordAnalyzerQuasar runRecognition]
-[CSKeywordAnalyzerQuasar runRecognition]_block_invoke
-[CSKeywordAnalyzerQuasar endAudio]
-[CSKeywordAnalyzerQuasar endAudio]_block_invoke
-[CSKeywordAnalyzerQuasar _recognizeWavData:length:]
-[CSKeywordAnalyzerQuasar speechRecognizer:didRecognizePartialResult:]_block_invoke
-[CSKeywordAnalyzerQuasar speechRecognizer:didRecognizeFinalResults:]_block_invoke
-[CSKeywordAnalyzerQuasar _phraseIdToCtcScoreMap]
-[CSKeywordAnalyzerQuasar speechRecognizer:didFinishRecognitionWithError:]_block_invoke
-[CSKeywordAnalyzerQuasar _getConfidence:]_block_invoke
-[CSVoiceTriggerAssetHandlerMac _getVoiceTriggerAssetFromAssetManagerWithLocale:completion:]_block_invoke
-[CSVoiceTriggerAssetHandlerMac _getVoiceTriggerAssetFromAssetManagerWithLocale:completion:]_block_invoke_2
-[CSVoiceTriggerAssetHandlerMac _checkNewAssetAvailablity]_block_invoke
-[CSVoiceTriggerAssetHandlerMac _checkNewAssetAvailablityForEndpoint]_block_invoke
-[CSVoiceTriggerAssetHandlerMac CSVoiceTriggerAssetDownloadMonitor:didInstallNewAsset:]
-[CSVoiceTriggerAssetHandlerMac CSLanguageCodeUpdateMonitor:didReceiveLanguageCodeChanged:]
-[CSVoiceTriggerAssetHandlerMac CSFirstUnlockMonitor:didReceiveFirstUnlock:]
-[CSVoiceTriggerAssetHandlerMac trialAssetDownloadMonitorDelegate:didInstallNewAsset:assetType:]
RequestContext
DetectedToken
TriggerMachTime
TriggerAbsStartSampleId
{attendingCtx: %@, detctedToken: %@, triggerMachTime=%llu, triggerStartSampleId=%llu}
[requestHistoricalAudioDataWithHostTime = %@]
[requestHistoricalAudioDataSampleCount = %@]
[useOpportunisticZLL = %@]
[startRecordingHostTime = %llu]
[startRecordingSampleCount = %llu]
[alertBehavior = %llu %llu %llu]
[skipAlertBehavior = %@]
[requireSingleChannelLookup = %@]
[selectedChannel = %u]
[estimatedStartHostTime = %llu
[disableEndpointer = %d]
[disableLocalSpeechRecognizer = %d]
[disablePrewarmLocalSpeechRecognizer = %d]
requestHistoricalAudioDataWithHostTime
requestHistoricalAudioDataSampleCount
startRecordingHostTime
startRecordingSampleCount
useOpportunisticZLL
startAlertBehavior
stopAlertBehavior
errorAlertBehavior
skipAlertBehavior
requireSingleChannelLookup
selectedChannel
estimatedStartHostTime
disableEndpointer
disableLocalSpeechRecognizer
disablePrewarmLocalSpeechRecognizer
requestMHUUID
siriSessionUUID
triggerScore
effectiveThreshold
recognizerScore
recognizerThresholdOffset
threshold
satThreshold
isSecondChance
supportedPhrases
mpvt2ndPassTriggeredPhraseId
phraseId
phraseStr
ndapiScore
2ndChanceThreshold
loggingThreshold
recognizerScoreScaleFactor
tdsrSatCombinedSATThreshold
%lu:%@:ndapi=%f:ctc=%f:comb=%f:thr=%f:maxd=%d:
%lu:%@:ndapi=%f:ctc=%f:comb=%f:thr=%f:maxd=%d:res=%@
-[CSVTSecondPassScorer initWithAsset:firstPassSource:]
-[CSVTSecondPassScorer updateWithCtcCheckerResults:]
-[CSVTSecondPassScorer getTriggeredPhraseWithSecondChanceEnabled:]
%@, 
com.apple.corespeech.corespeechservices
com.apple.corespeech.xpc
+[CSCoreSpeechServices installedVoiceTriggerAssetForLanguageCode:completion:]_block_invoke
CoreSpeechXPC service invalidated
+[CSCoreSpeechServices fetchRemoteVoiceTriggerAssetForLanguageCode:completion:]_block_invoke
+[CSCoreSpeechServices getCurrentVoiceTriggerLocaleWithEndpointId:completion:]
+[CSCoreSpeechServices getCurrentVoiceTriggerLocaleWithEndpointId:completion:]_block_invoke
+[CSCoreSpeechServices voiceTriggerRTModelForVersion:minorVersion:accessoryRTModelType:endpointId:downloadedModels:preinstalledModels:completion:]_block_invoke
+[CSCoreSpeechServices voiceTriggerRTModelForVersion:minorVersion:downloadedModels:preinstalledModels:completion:]
+[CSCoreSpeechServices voiceTriggerRTModelForVersion:minorVersion:downloadedModels:preinstalledModels:completion:]_block_invoke
+[CSCoreSpeechServices voiceTriggerJarvisLanguageList:jarvisSelectedLanguage:completion:]_block_invoke
+[CSCoreSpeechServices voiceTriggerJarvisLanguageList:jarvisSelectedLanguage:completion:]
+[CSCoreSpeechServices requestUpdatedSATAudio]_block_invoke
v12@?0B8
+[CSCoreSpeechServices getFirstPassRunningMode]_block_invoke
v16@?0q8
VoiceTrigger Asset Change Monitor
com.apple.corespeech.voicetriggerassetchange
-[CSAudioServerCrashMonitor _startMonitoringWithQueue:]
CSXPCClient Reply Queue
CSXPCClient connection Queue
-[CSXPCClient connect]_block_invoke
com.apple.corespeech.corespeechd.xpc
-[CSXPCClient _sendXPCClientType]
xpcClientType
-[CSXPCClient prepareAudioProviderWithContext:clientType:error:]
clientType
activateReason
dynamicAttribute
dictationRequestBundleId
deactivateOption
setDuckOthersOption
enableSmartRoutingConsideration
enableMiniDucking
alertType
soundPath
alertStartTime
-[CSXPCClient alertStartTime]_block_invoke
alertBehavior
setMeterEnable
channelNumber
power
-[CSXPCClient peakPowerForChannel:]_block_invoke
-[CSXPCClient averagePowerForChannel:]_block_invoke
-[CSXPCClient audioMetric]_block_invoke
audioMetric
-[CSXPCClient audioStreamWithRequest:streamName:error:]
v24@?0@"CSAudioStream"8@"NSError"16
-[CSXPCClient audioStreamWithRequest:streamName:completion:]
-[CSXPCClient audioStreamWithRequest:streamName:completion:]_block_invoke
-[CSXPCClient prepareAudioStreamSync:request:error:]
-[CSXPCClient prepareAudioStream:request:completion:]
v16@?0@"NSDictionary"8
-[CSXPCClient acousticSLResultForContext:completion:]
-[CSXPCClient acousticSLResultForContext:completion:]_block_invoke_2
acousticSLResult
-[CSXPCClient acousticSLResultForContext:completion:]_block_invoke
v24@?0@"NSDictionary"8@"NSDictionary"16
-[CSXPCClient triggerInfoForContext:completion:]
-[CSXPCClient audioStreamId]
-[CSXPCClient audioChunkFrom:to:]
-[CSXPCClient audioChunkFrom:to:channelIdx:]
-[CSXPCClient audioChunkToEndFrom:]
-[CSXPCClient audioChunkToEndFrom:channelIdx:]
-[CSXPCClient saveRecordingBufferFrom:to:toURL:]
-[CSXPCClient saveRecordingBufferToEndFrom:toURL:]
-[CSXPCClient holdAudioStreamWithDescription:timeout:]
-[CSXPCClient cancelAudioStreamHold:]
-[CSXPCClient isRecording]
-[CSXPCClient setAnnounceCallsEnabled:withStreamHandleID:]
-[CSXPCClient attachTandemStream:toPrimaryStream:completion:]
deviceID
sessionID
-[CSXPCClient audioSessionIdForDeviceId:]
sampleCount
-[CSXPCClient hostTimeFromSampleCount:]_block_invoke
replyHostTime
-[CSXPCClient hostTimeFromSampleCount:]
hostTime
-[CSXPCClient sampleCountFromHostTime:]_block_invoke
replySampleCount
-[CSXPCClient sampleCountFromHostTime:]
-[CSXPCClient _handleListenerEvent:]
-[CSXPCClient _handleListenerMessage:]
-[CSXPCClient _handleListenerError:]
-[CSXPCClient _handleAlertProvidingDelegateMessageBody:]
didFinishAlertPlayback
errorDomain
errorCode
-[CSXPCClient _handleSessionProvidingDelegateMessageBody:]
interruptionContext
-[CSXPCClient _handleSessionProvidingDelegateBeginInterruptionWithContext:]
willSetAudioSessionActive
didSetAudioSessionActive
streamHandleIdInvalidationflag
didChangeContextFlag
-[CSXPCClient _handleSessionInfoProvidingDelegateMessageBody:]
notificationInfo
-[CSXPCClient _handleSessionInfoProvidingDelegateInterruptionNotification:]
-[CSXPCClient _handleSessionInfoProvidingDelegateRouteChangeNotification:]
-[CSXPCClient _handleSessionInfoProvidingDelegateMediaServicesWereLostNotification:]
-[CSXPCClient _handleSessionInfoProvidingDelegateMediaServicesWereResetNotification:]
-[CSXPCClient _handleStreamProvidingDelegateMessageBody:]
CSOpportuneSpeakListnerTestService
com.apple.corespeech.opportunelistner.start
com.apple.corespeech.opportunelistner.stop
A945B95D-69F6-FC77-4FAE-91F50A039CD8
-[CSOpportuneSpeakListnerTestService receiveOpportuneSpeakListenerStart]_block_invoke
-[CSOpportuneSpeakListnerTestService receiveOpportuneSpeakListenerStop]_block_invoke
-[CSOpportuneSpeakListnerTestService opportuneSpeakListener:hasRemoteVADAvailable:]
-[CSOpportuneSpeakListnerTestService opportuneSpeakListener:hasVADAvailable:]
-[CSOpportuneSpeakListnerTestService opportuneSpeakListener:didStopUnexpectly:]
CSTimerMonitor queue
-[CSTimerMonitor _startMonitoringWithQueue:]
-[CSTimerMonitor _stopMonitoring]
BluetoothA2DPOutput
BluetoothHFP
BluetoothLE
MicrophoneBuiltIn
Speaker
Headphones
MicrophoneWired
HDMIOutput
LineIn
USBAudio
ADAudioSessionPortOther
-[CSSiriAudioSession currentInputRoute]_block_invoke
v24@?0^v8Q16
-[CSSiriAudioSession currentOutputRoute]_block_invoke_3
_AudioObjectGetScalarArray
v20@?0I8r^{AudioObjectPropertyAddress=III}12
_AudioDeviceRegisterForChangedNotification
v16@?0^v8
_AudioObjectGetCFTypeRef
v12@?0I8
_AudioObjectGetIntValue
CSOpportuneSpeakEventMonitor
-[CSOpportuneSpeakEventMonitor isStreaming]
-[CSAttSiriMitigationAssetHandler _receivedNewAssetUpdate:]
-[CSAttSiriMitigationAssetHandler trialAssetDownloadMonitorDelegate:didInstallNewAsset:assetType:]
kVTPreferencesPhraseSpotterEnabledDidChangeDarwinNotification
-[CSPhraseSpotterEnabledMonitor _checkPhraseSpotterEnabled]
-[CSPhraseSpotterEnabledMonitor _phraseSpotterEnabledDidChange]
CSVoiceTriggerAssetHandler
-[CSVoiceTriggerAssetHandler getVoiceTriggerAssetWithEndpointId:completion:]
CSVoiceTriggerAssetHandler.m
com.apple.siri.myriad.in.ear
+[CSMyriadNotifier notifyInEarMyriadTrigger]
com.apple.corespeech.benchmark.xpc
-[CSBenchmarkXPCListener listen]
-[CSBenchmarkXPCListener listener:shouldAcceptNewConnection:]
corespeech.benchmark.xpc
Liminal
progChecker.json
progressiveCheckerConfigFile
contionusConversationConfigFile
checkerConfig
validInputOrigins
thresholds
shadowMode
Unspecified
VoiceTrigger
ButtonPress
B32@?0@8@16^B24
v24@?0@8^B16
-[CSLanguageCodeUpdateMonitorImpl _startMonitoringWithQueue:]
-[CSLanguageCodeUpdateMonitorImpl _stopMonitoring]
-[CSLanguageCodeUpdateMonitorImpl _didReceiveLanguageCodeUpdate]
CSVoiceTriggerXPCListener
com.apple.corespeech.voicetriggerservice
-[CSVoiceTriggerXPCListener listen]
-[CSVoiceTriggerXPCListener _handleListenerEvent:]
-[CSVoiceTriggerXPCListener _handleListenerError:]
-[CSVoiceTriggerXPCListener _handleNewRemoteConnection:]
voicetrigger.voicetriggerservice
-[CSVoiceTriggerXPCListener CSXPCConnectionReceivedClientError:clientError:client:]_block_invoke
CSCoreSpeechServicesListener
-[CSCoreSpeechServicesListener listen]
-[CSCoreSpeechServicesListener _servicesListenerShouldAcceptNewConnection:]
corespeech.xpc
-[CSCoreSpeechServicesListener listener:shouldAcceptNewConnection:]
-[CSCoreSpeechServicesListener getTestResponse:]
Test
-[CSCoreSpeechServicesListener setDelayInterstitialSounds:level:completion:]
-[CSCoreSpeechServicesListener getTriggerCount:]
-[CSCoreSpeechServicesListener clearTriggerCount:]
-[CSCoreSpeechServicesListener getFirstPassRunningMode:]
-[CSAudioStreamHolding dealloc]
-[CSEndpointDelayReporter initWithRequestMHUUID:turnIdentifier:]
-[CSEndpointDelayReporter reset]
leadingSilence
trailingSilence
endTime
-[CSEndpointDelayReporter setSpeechRecognizedContext:withEndpointerMetrics:]
Adaptive Siri Volume Disabled
siriVolume.json
smartSiriVolume
noiseLevelChannelBitset
LKFSChannelBitset
DistanceChannelBitset
energyBufferSize
noiseLowerPercentile
noiseUpperPercentile
LKFSLowerPercentile
LKFSUpperPercentile
noiseTimeConstant
noiseMicSensitivityOffset
noiseMicSensitivityOffsetDeviceSimple
LKFSTimeConstant
LKFSMicSensitivityOffset
noiseTTSMappingInputRangeLow
noiseTTSMappingInputRangeHigh
noiseTTSMappingOutputRangeLow
noiseTTSMappingOutputRangeHigh
LKFSTTSMappingInputRangeLow
LKFSTTSMappingInputRangeHigh
LKFSTTSMappingOutputRangeLow
LKFSTTSMappingOutputRangeHigh
userOffsetInputRangeLow
userOffsetInputRangeHigh
userOffsetOutputRangeLow
userOffsetOutputRangeHigh
TTSVolumeLowerLimitDB
TTSVolumeUpperLimitDB
noiseWeight
SSVCAMaxFrameSize
SSVCAVoiceTriggerBasedTTSValidForSeconds
SSVCASmartSiriVolumeUnsyncedMetricLogsToRetain
SSVCASmartSiriVolumeSyncedMetricLogsToRetain
SSVCAVoiceTriggerInitialSilenceDurationSeconds
SSVCADistanceInputBufferDurationSeconds
SSVCAListenPollingIntervalAtStartInSeconds
SSVCADefaultZeroFloatingPointValue
SSVCAAnnouncementStatusFetchTimeoutMs
SSVCADefaultOutputTTSVolume
SSVCANoiseActivityCountThreshold
SSVCASpeakerDistanceFarBoostFactor
SSVCASpeakerDistanceMidBoostFactor
SSVCASpeakerDistanceNearBoostFactor
SSVCADistanceModelConfidenceThreshold
SSVCAMinimumLinearSoundLevel
SSVCAMaximumLinearSoundLevel
SSVCALinearToDecibelConstantMultiplier
SSVCADecibelToLinearLogBase
SSVCASignalToSigmoidNoiseDilationFactor
SSVCASignalToSigmoidMusicDilationFactorDeviceDefault
SSVCASignalToSigmoidMusicDilationFactorDeviceSimple
SSVCASignalToSigmoidSpeechDilationFactor
SSVCASignalToSigmoidNoiseVSpread
SSVCASignalToSigmoidMusicVSpreadDeviceDefault
SSVCASignalToSigmoidMusicVSpreadDeviceSimple
SSVCASignalToSigmoidSpeechVSpread
SSVCASignalToSigmoidNoiseVOffset
SSVCASignalToSigmoidMusicVOffsetDeviceDefault
SSVCASignalToSigmoidMusicVOffsetDeviceSimple
SSVCASignalToSigmoidSpeechVOffset
SSVCASignalToSigmoidNoiseHOffset
SSVCASignalToSigmoidMusicHOffsetDeviceDefault
SSVCASignalToSigmoidMusicHOffsetDeviceSimple
SSVCASignalToSigmoidSpeechHOffset
SSVCASignalToSigmoidMusicSteepnessDeviceDefault
SSVCASignalToSigmoidMusicSteepnessDeviceSimple
SSVCASignalToSigmoidNoiseSteepness
SSVCASignalToSigmoidSpeechSteepness
SSVCADBToTTSMinimumOutput
SSVCADBToTTSMaximumOutput
SSVCADBToTTSTransitionPoint
SSVCADBToTTSPreTransitionOffset
SSVCADBToTTSPreTransitionMultiplier
SSVCADBToTTSPostTransitionOffset
SSVCADBToTTSPostTransitionDC
SSVCADBToTTSPostTransitionMultiplier
SSVCAMinimumDistanceUpdateWaitPeriodSeconds
SSVCANoiseActivityThreshold
SSVCANoiseResultsBufferSize
SSVCAMusicResultsBufferSize
SSVCADefaultSpeechStrength
SSVCADefaultMusicStrength
SSVCANoiseActivityHistoricalSampleCount
SSVCADspCoefsCount
SSVCADspNumStages
SSVCADistanceResultsBufferSize
SSVCAExponentialDistanceHistoryDegradationFactor
SSVCADistanceResultSampleCountTolerance
SSVCAMusicHistoricalSamplesInSeconds
SSVCADeviceSimpleOutputMinTargetDB
SSVCADeviceSimpleOutputMaxTargetDB
SSVCADeviceSimpleOutputSlope
SSVCADeviceSimpleMinTargetDB
SSVCADeviceSimpleMaxTargetDB
SSVCADeviceSimpleDBToSystemVolSlope
SSVCADeviceSimpleMicSensitivityOffset
SSVCADeviceSimplePreTriggerSilenceSampleCount
SSVCAMinTTSSystemVolume
SSVCAMaxTTSSystemVolume
SSVCAUserIntentValidForSeconds
SSVCAUserIntentVolumeIncreaseFactor
SSVCAUserIntentVolumeDecreaseFactor
SSVCAUserIntentPermanentOffsetFactorDelta
SSVCAUserIntentPermanentOffsetFactorLowerBound
SSVCAUserIntentPermanentOffsetFactorUpperBound
SSVCADeviceSimpleMinTTSVolume
SSVCADeviceSimpleMaxTTSVolume
SSVCADeviceDefaultMinTTSVolume
SSVCADeviceDefaultMaxTTSVolume
SSVCADeviceDefaultASVOffMinTTSVolume
SSVCADeviceSimpleASVOffMinTTSVolume
SSVCADeviceDefaultMicSensitivityOffset
SSVCAVolumeHalfLifeSeconds
SSVCAHistoricalVolumeBufferSize
SSVCAMaximumCompensatedSpeechLevelNearField
-[CSAsset(SmartSiriVolume) _getNumberFromASVDictionaryForKey:category:default:]
com.apple.corespeech.audioinjection.xpc
-[CSAudioInjectionXPCListener listen]
-[CSAudioInjectionXPCListener listener:shouldAcceptNewConnection:]
corespeech.audioinjection.xpc
RTModelData
RTModelHash
RTModelLocale
RTModelDigest
RTModelSignature
RTModelCertificate
RT Model for 
 from asset 
CorealisRTModel
CorealisRTModelVersion
dataSize(%d), hash(%@), locale(%@), digest(%@), cert(%@), signature(%@)
CSAudioProvider
CSAudioProvider Stream Handle Queue
CSAudioProvider logging
-[CSAudioProvider initWithAudioStreamHandleId:audioStreamType:audioRecordContext:audioRecorder:]
-[CSAudioProvider dealloc]
-[CSAudioProvider setStreamState:]
-[CSAudioProvider setAudioRecorder:]_block_invoke
-[CSAudioProvider setCurrentContext:error:]
-[CSAudioProvider setCurrentContext:error:]_block_invoke
-[CSAudioProvider _audioStreamWithRequest:streamName:error:]
-[CSAudioProvider attachTandemStream:toPrimaryStream:completion:]_block_invoke_2
failed
successfully
-[CSAudioProvider attachTandemStream:toPrimaryStream:completion:]_block_invoke
-[CSAudioProvider _prepareAudioStreamSync:request:error:]
-[CSAudioProvider _tearDownCircularBufferIfNeeded]_block_invoke
-[CSAudioProvider startAudioStream:option:completion:]
-[CSAudioProvider startAudioStream:option:completion:]_block_invoke
-[CSAudioProvider prepareAudioStreamSync:request:error:]
-[CSAudioProvider prepareAudioStream:request:completion:]
-[CSAudioProvider _startAudioStream:option:completion:]
-[CSAudioProvider _startAudioStream:option:completion:]_block_invoke
-[CSAudioProvider _startAudioStream:option:completion:]_block_invoke_2
-[CSAudioProvider _handleDidStartAudioStreamWithResult:error:]
-[CSAudioProvider _handleDidStopAudioStreamWithReason:]
-[CSAudioProvider _stopAudioStream:option:completion:]
-[CSAudioProvider _stopAudioStream:option:completion:]_block_invoke
-[CSAudioProvider _stopAudioStream:option:completion:]_block_invoke_3
CSAudioProvider.m
-[CSAudioProvider _stopAudioStream:option:completion:]_block_invoke_4
-[CSAudioProvider _stopAudioStream:option:completion:]_block_invoke_2
-[CSAudioProvider _saveRecordingBufferFrom:to:toURL:]_block_invoke
-[CSAudioProvider holdAudioStreamWithDescription:timeout:]
-[CSAudioProvider holdAudioStreamWithDescription:timeout:]_block_invoke_2
-[CSAudioProvider holdAudioStreamWithDescription:timeout:]_block_invoke
-[CSAudioProvider cancelAudioStreamHold:]
-[CSAudioProvider cancelAudioStreamHold:]_block_invoke
-[CSAudioProvider prewarmAudioSessionWithError:]
-[CSAudioProvider activateAudioSessionWithReason:dynamicAttribute:bundleID:error:]
-[CSAudioProvider _activateAudioSessionWithReason:error:]
-[CSAudioProvider deactivateAudioSession:error:]
-[CSAudioProvider _deactivateAudioSession:error:]
-[CSAudioProvider setAlertSoundFromURL:forType:]
-[CSAudioProvider playAlertSoundForType:]
-[CSAudioProvider playRecordStartingAlertAndResetEndpointer]
-[CSAudioProvider alertStartTime]
-[CSAudioProvider triggerInfoForContext:completion:]_block_invoke
-[CSAudioProvider _shouldStopRecording]
-[CSAudioProvider audioRecorderStreamHandleIdInvalidated:]
-[CSAudioProvider audioRecorderWillBeDestroyed:]_block_invoke
-[CSAudioProvider _fetchHistoricalAudioAndForwardToStream:remoteVAD:]
-[CSAudioProvider _scheduleAlertFinishTimeout:]
-[CSAudioProvider _scheduleAlertFinishTimeout:]_block_invoke
-[CSAudioProvider _didReceiveFinishStartAlertPlaybackAt:]
-[CSAudioProvider _didReceiveFinishStartAlertPlaybackAt:]_block_invoke_2
-[CSAudioProvider _didReceiveFinishStartAlertPlaybackAt:]_block_invoke
-[CSAudioProvider audioRecorderBuiltInAudioStreamInvalidated:error:]_block_invoke
-[CSAudioProvider audioRecorderDisconnected:]
-[CSAudioProvider CSAudioServerCrashMonitorDidReceiveServerCrash:]
-[CSAudioProvider CSAudioServerCrashMonitorDidReceiveServerRestart:]
-[CSAudioProvider _handleAudioSystemFailure]
StreamInit
StreamPrepared
StreamStarting
StreamSteaming
StreamStopping
StreamStoppingWithScheduledStart
unknown(%tu)
com.apple.corespeech.recording
Recording transaction
-[CSAudioProvider _releaseRecordingTransactionIfNeeded]
%@-%@
-[CSAudioProvider _onAudioPacketWatchdogFire]
-[CSAudioProvider _scheduleDidStartRecordingDelegateWatchDog]
-[CSAudioProvider _schduleDidStartRecordingDelegateWatchDogWithToken:]
-[CSAudioProvider _clearDidStartRecordingDelegateWatchDog]
-[CSAudioProvider _scheduleDidStopRecordingDelegateWatchDog]
-[CSAudioProvider _scheduleDidStopRecordingDelegateWatchDog:]
-[CSAudioProvider _clearDidStopRecordingDelegateWatchDog]
com.apple.siri.SiriDebug.SpeakerVoiceGradingTrigger
com.apple.siri.SiriDebug.RemoteNearMissGradingTrigger
com.apple.siri.SiriDebug.VoiceProfileAddedTrigger
com.apple.siri.SiriDebug.VoiceProfileSyncTrigger
com.apple.siri.SiriDebug
+[CSSiriDebugConnection launchSiriDebugAppWithMessage:]_block_invoke
v24@?0@"AFSiriResponse"8@"NSError"16
set option : allowVoiceTriggerAssetsDownload ? %@;           allowEndpointAssetDownload ? %@;           allowLanguageDetectorAssetDownload ? %@;           allowAdBlockerAssetDownload ? %@;           allowSpeakerRecognitionAssetDownload ? %@
Dispose Log Queue
+[CSUtils(Directory) removeLogFilesInDirectory:matchingPattern:beforeDays:]_block_invoke
v24@?0@"NSArray"8^@16
+[CSUtils(Directory) clearLogFilesInDirectory:matchingPattern:exceedNumber:]_block_invoke_2
+[CSUtils(Directory) clearLogFilesInDirectory:matchingPattern:exceedNumber:]_block_invoke
Unable to get %@ for file at %@: %@
q24@?0@"NSURL"8@"NSURL"16
B24@?0@"NSURL"8@"NSDictionary"16
+[CSUtils(Directory) _contentsOfDirectoryAtURL:matchingPattern:includingPropertiesForKeys:error:]
-[CSVoiceTriggerEnabledPolicyNonAOP _addVoiceTriggerEnabledConditions]_block_invoke
-[CSNNVADEndpointAnalyzer init]
-[CSNNVADEndpointAnalyzer preheat]
-[CSNNVADEndpointAnalyzer reset]
-[CSNNVADEndpointAnalyzer processAudioSamplesAsynchronously:]
-[CSNNVADEndpointAnalyzer recordingStoppedForReason:]
-[CSNNVADEndpointAnalyzer stopEndpointer]
-[CSNNVADEndpointAnalyzer resetForNewRequestWithSampleRate:recordContext:]
-[CSSpeechDetectionDevicePresentMonitor handleSpeechDetectionVADPresentChange:]
-[CSSpeechDetectionDevicePresentMonitor _systemControllerDied:]
best_phrase
early_warning
is_rescoring
samples_at_fire
start_sample_count
-[CSKeywordAnalyzerNDAPI initWithConfigPath:resourcePath:]
-[CSKeywordAnalyzerNDAPI _setStartAnalyzeTime:]
threshold_normal
-[CSKeywordAnalyzerNDAPI getThreshold]
threshold_logging
-[CSKeywordAnalyzerNDAPI getLoggingThreshold]
threshold_reject_logging
-[CSKeywordAnalyzerNDAPI getRejectLoggingThreshold]
rtblobs
adkblobs
blob
majorVersion
minorVersion
signature
cert
rtlocalemap
jarvislocalemap
adklocalemap
-[CSAsset(RTModel) createRTModelWithLocale:]
-[CSAsset(RTModel) latestHearstRTModelForLocale:]
-[CSAsset(RTModel) rtModelWithAccessoryRTModelType:majorVersion:minorVersion:locale:]
-[CSAsset(RTModel) localeMapWithName:]
%02x
CSAudioRouteChangeMonitorImpl queue
-[CSAudioRouteChangeMonitorImpl preferredExternalRouteDidChange:]_block_invoke
-[CSAudioRouteChangeMonitorImpl carPlayAuxStreamSupportDidChange:]_block_invoke
-[CSAudioRouteChangeMonitorImpl carPlayIsConnectedDidChange:]
-[CSAudioRouteChangeMonitorImpl _startMonitoringWithQueue:]
-[CSAudioRouteChangeMonitorImpl _stopMonitoring]
-[CSAudioRouteChangeMonitorImpl _notifyHearstConnectionState:]
-[CSAudioRouteChangeMonitorImpl _notifyJarvisConnectionState:]
-[CSAudioRouteChangeMonitorImpl _systemControllerDied:]
languageCode
Builtin Microphone
[Context = %ld]
[DeviceId = %@]
[Announced = %d]
[streamHandleId = %d]
[startHostTime = %llu]
[startAlert = %d]
[stopAlert = %d]
[stopOnErrorAlert = %d]
[skipAlert = %@]
-[CSAudioRecorder initWithQueue:error:]
-[CSAudioRecorder willDestroy]
-[CSAudioRecorder dealloc]
-[CSAudioRecorder _destroyVoiceController]
-[CSAudioRecorder _voiceControllerWithError:]_block_invoke
-[CSAudioRecorder _voiceControllerWithError:]
-[CSAudioRecorder setAnnounceCallsEnabled:withStreamHandleID:]
-[CSAudioRecorder setContext:completion:]
-[CSAudioRecorder setCurrentContext:streamHandleId:error:]
-[CSAudioRecorder prepareAudioStreamRecord:recordDeviceIndicator:error:]
-[CSAudioRecorder _startAudioStreamForAudioInjectionWithAVVCContext:]
-[CSAudioRecorder startAudioStreamWithOption:recordDeviceIndicator:error:]
-[CSAudioRecorder stopAudioStreamWithRecordDeviceIndicator:error:]
-[CSAudioRecorder isSessionCurrentlyActivated]
-[CSAudioRecorder recordDeviceInfoWithStreamHandleId:recordDeviceIndicator:]
%llu
-[CSAudioRecorder audioDeviceInfoWithStreamHandleId:recordDeviceIndicator:]
-[CSAudioRecorder recordingSampleRateWithStreamHandleId:]
-[CSAudioRecorder isNarrowBandWithStreamHandleId:]
-[CSAudioRecorder prewarmAudioSessionWithStreamHandleId:error:]
-[CSAudioRecorder setRecordMode:streamHandleId:error:]
-[CSAudioRecorder activateAudioSessionWithReason:streamHandleId:error:]
-[CSAudioRecorder deactivateAudioSession:error:]
-[CSAudioRecorder deactivateAudioSession:streamHandleId:error:]
+[CSAudioRecorder createSharedAudioSession]
-[CSAudioRecorder enableSmartRoutingConsiderationForStream:enable:]
-[CSAudioRecorder setDuckOthersForStream:]
-[CSAudioRecorder setMixWithOthersForStream:]
-[CSAudioRecorder setDuckOthersOption:]
-[CSAudioRecorder enableMiniDucking:]
-[CSAudioRecorder configureAlertBehavior:audioStreamHandleId:]
-[CSAudioRecorder voiceTriggerInfoWithRecordDeviceIndicator:]
-[CSAudioRecorder _updateLanguageCodeForRemoteVTEIResult:]
useRemoteBuiltInMic
-[CSAudioRecorder _processAudioBuffer:audioStreamHandleId:arrivalTimestampToAudioRecorder:]
-[CSAudioRecorder _compensateChannelDataIfNeeded:receivedNumChannels:]
-[CSAudioRecorder playRecordStartingAlertAndResetEndpointerFromStream:]
-[CSAudioRecorder playAlertSoundForType:recordDevideIndicator:]
-[CSAudioRecorder voiceControllerDidStartRecording:forStream:successfully:error:]
-[CSAudioRecorder voiceControllerAudioCallback:forStream:buffer:]
-[CSAudioRecorder voiceControllerDidStopRecording:forStream:forReason:]
-[CSAudioRecorder voiceControllerStreamInvalidated:forStream:]
-[CSAudioRecorder voiceControllerRecordHardwareConfigurationDidChange:toConfiguration:]
-[CSAudioRecorder voiceControllerDidFinishAlertPlayback:ofType:error:]
-[CSAudioRecorder voiceControllerEncoderErrorDidOccur:error:]
-[CSAudioRecorder voiceControllerBeginRecordInterruption:]
-[CSAudioRecorder voiceControllerBeginRecordInterruption:withContext:]
-[CSAudioRecorder voiceControllerEndRecordInterruption:]
-[CSAudioRecorder voiceControllerWillSetAudioSessionActive:willActivate:]
-[CSAudioRecorder voiceControllerDidSetAudioSessionActive:isActivated:]
-[CSAudioRecorder voiceControllerMediaServicesWereLost:]
-[CSAudioRecorder voiceControllerMediaServicesWereReset:]
-[CSAudioRecorder _hasLocalPendingTwoShot]_block_invoke
-[CSAudioRecorder _getRecordSettingsWithRequest:]
-[CSAudioRecorder _fetchRemoteRecordClientWithDeviceId:streamHandleId:]
-[CSAudioTandemStream attachToPrimaryStreamWithCompletion:]
-[CSAudioTandemStream prepareAudioStreamSyncWithRequest:error:]
CSAudioTandemStream.m
-[CSAudioTandemStream prepareAudioStreamWithRequest:completion:]
-[CSAudioTandemStream startAudioStreamWithOption:completion:]
-[CSAudioTandemStream stopAudioStreamWithOption:completion:]
RemoteVAD Align Queue
-[CSOpportuneSpeakListener startListenWithOption:completion:]
-[CSOpportuneSpeakListener _startRequestWithCompletion:]_block_invoke
-[CSOpportuneSpeakListener _startRequestWithCompletion:]
-[CSOpportuneSpeakListener stopListenWithStateReset:completion:]_block_invoke
-[CSOpportuneSpeakListener stopListenWithStateReset:completion:]
-[CSOpportuneSpeakListener audioStreamProvider:audioBufferAvailable:]
-[CSOpportuneSpeakListener spgEndpointAnalyzer:hasSilenceScoreEstimate:clientProcessedAudioTimeMS:]
-[NSData(XPCObject) _cs_initWithXPCObject:]
-[CSSiriEnabledMonitor _startMonitoringWithQueue:]
-[CSSiriEnabledMonitor _stopMonitoring]
_AssistantPrefsChangedNotification
CSBluetoothManager Queue
-[CSBluetoothManager getBTLocalDeviceWithCompletion:]
-[CSBluetoothManager getBTLocalDeviceWithCompletion:]_block_invoke
v16@?0^{BTLocalDeviceImpl=}8
-[CSBluetoothManager _getWirelessSplitterInfoFromLocalDevice:]
-[CSBluetoothManager _detachBluetoothSession]
-[CSBluetoothManager _attachBluetoothSession]
CSBluetoothManager
-[CSBluetoothManager _sessionAttached:result:]
-[CSBluetoothManager _sessionDetached:]
-[CSBluetoothManager _sessionTerminated:]
-[CSBluetoothManager _setUpLocalDevice]
unknown
CSActivationXPCListener
-[CSActivationXPCListener listen]
-[CSActivationXPCListener _handleListenerEvent:]
-[CSActivationXPCListener _handleListenerError:]
-[CSActivationXPCListener _handleNewRemoteConnection:]
corespeechd.activation
-[CSActivationXPCListener CSActivationXPCConnectionReceivedClientError:clientError:client:]_block_invoke
CSBenchMarker Queue
-[CSModelBenchmarker init]
-[CSModelBenchmarker pingpong:completion:]
Model benchmark Queue
HS1_HS2
file audio
-[CSModelBenchmarker audioEngineDidStartRecord:audioStreamHandleId:successfully:error:]_block_invoke
-[CSModelBenchmarker audioEngineDidStopRecord:audioStreamHandleId:reason:]_block_invoke
done
v16@?0Q8
-[CSModelBenchmarker _setupAudioInjectionEngineWithAudioURL:]_block_invoke
-[CSModelBenchmarker _setupAudioInjectionEngineWithAudioURL:]_block_invoke_2
+[CSRemoteDeviceProtocolInfo localDeviceProtocolInfo]
protocolVersion=%lu, deviceCategory=%lu, buildVersion=%@, deviceProductVersion=%@, deviceProductType=%@
protocolVersion
deviceCategory
buildVersion
deviceProductVersion
deviceProductType
-[CSAudioSessionInfoProvidingProxy handleXPCMessage:messageBody:client:]
-[CSAudioSessionInfoProvidingProxy _handleSessionIDRequestMessage:messageBody:client:]
+[CSConnectionListener(SmartSiriVolume) createSmartSiriVolumeListener]
com.apple.corespeech.corespeechd.ssv.service
+[CSConnectionListener(SmartSiriVolume) createSmartSiriVolumeListener]_block_invoke
com.apple.MobileAsset.VoiceTriggerAssetsMac
-[CSAssetController init]
Serial CSAssetController queue
V1 Assets Clean-up queue
-[CSAssetController _cleanUpMobileAssetV1Directory]
-[CSAssetController assetOfType:language:]
-[CSAssetController allInstalledAssetsOfType:language:]
q24@?0@"MAAsset"8@"MAAsset"16
v32@?0@"MAAsset"8Q16^B24
-[CSAssetController assetOfType:language:completion:]
-[CSAssetController assetOfType:language:compatibilityVersion:completion:]
v24@?0@"MAAsset"8@"NSError"16
-[CSAssetController installedAssetOfType:language:]
-[CSAssetController installedAssetOfType:language:completion:]
-[CSAssetController _installedAssetOfType:withLanguage:]
-[CSAssetController _installedAssetOfType:query:withLanguage:completion:]_block_invoke
-[CSAssetController _findLatestInstalledAsset:]
-[CSAssetController _assetQueryForAssetType:]
-[CSAssetController _runAssetQuery:completion:]
-[CSAssetController _runAssetQuery:completion:]_block_invoke
-[CSAssetController fetchRemoteMetaOfType:allowRetry:]
-[CSAssetController fetchRemoteMetaOfType:allowRetry:]_block_invoke
v20@?0@"NSError"8B16
-[CSAssetController _fetchRemoteAssetOfType:withLanguage:completion:]
-[CSAssetController _fetchRemoteAssetOfType:withLanguage:query:completion:]_block_invoke_2
-[CSAssetController _fetchRemoteAssetOfType:withLanguage:query:completion:]_block_invoke
-[CSAssetController _downloadAssetCatalogForAssetType:complete:]_block_invoke
-[CSAssetController _updateFromRemoteToLocalAssets:forAssetType:completion:]
-[CSAssetController _downloadAsset:withComplete:]
v16@?0d8
-[CSAssetController _downloadAsset:withComplete:]_block_invoke
-[CSAssetController _startDownloadingAsset:progress:completion:]
v16@?0@"MAProgressNotification"8
+[CSAssetController(Utils) addKeyValuePairForQuery:assetType:]
com.apple.MobileAsset.VoiceTriggerAssets
com.apple.MobileAsset.VoiceTriggerAssetsIPad
com.apple.MobileAsset.VoiceTriggerAssetsWatch
com.apple.MobileAsset.VoiceTriggerAssetsMarsh
com.apple.MobileAsset.VoiceTriggerAssetsTV
com.apple.MobileAsset.SpeechEndpointAssets
com.apple.MobileAsset.SpeechEndpointAssetsWatch
com.apple.MobileAsset.SpeechEndpointAssetsTV
com.apple.MobileAsset.LanguageDetectorAssets
com.apple.MobileAsset.AdBlockerAssets
com.apple.MobileAsset.SpeakerRecognitionAssets
Warmup
SearchOrMessaging
ExtraDelayMs
EndpointerDecisionLagMs
ClientLagThresholdMsKey
ClampedSFLatencyMsForClientLag
UseDefaultServerFeaturesOnClientLag
com.apple.cs.%@.stateserialqueue
com.apple.cs.%@.sepfQueue
-[CSHybridEndpointAnalyzer init]
com.apple.cs.%@.apQueue
com.apple.cs.%@.hybridClassifierfQueue
com.apple.cs.%@.osdQueue
-[CSHybridEndpointAnalyzer _loadAndSetupEndpointerAssetIfNecessary]
-[CSHybridEndpointAnalyzer processAudioSamplesAsynchronously:]
-[CSHybridEndpointAnalyzer processAudioSamplesAsynchronously:]_block_invoke
-[CSHybridEndpointAnalyzer updateEndpointerThreshold:]
-[CSHybridEndpointAnalyzer updateEndpointerDelayedTrigger:]
-[CSHybridEndpointAnalyzer processServerEndpointFeatures:]
-[CSHybridEndpointAnalyzer shouldAcceptEagerResultForDuration:resultsCompletionHandler:]_block_invoke_2
-[CSHybridEndpointAnalyzer shouldAcceptEagerResultForDuration:resultsCompletionHandler:]_block_invoke
-[CSHybridEndpointAnalyzer osdAnalyzer:didUpdateOSDFeatures:]
-[CSHybridEndpointAnalyzer osdAnalyzer:didUpdateOSDFeatures:]_block_invoke_2
-[CSHybridEndpointAnalyzer osdAnalyzer:didUpdateOSDFeatures:]_block_invoke
locale
endpointerModelVersion
wordCount
trailingSilenceDuration
serverFeaturesLatency
clientSilenceProbability
clientSilenceFramesCountMs
endpointResult
@"NSDictionary"8@?0
-[CSHybridEndpointAnalyzer logFeaturesWithEvent:locale:]_block_invoke
extraSamplesAtStart
-[CSHybridEndpointAnalyzer handleVoiceTriggerWithActivationInfo:]_block_invoke
-[CSHybridEndpointAnalyzer recordingStoppedForReason:]
-[CSHybridEndpointAnalyzer stopEndpointer]
-[CSHybridEndpointAnalyzer resetForNewRequestWithSampleRate:recordContext:]
-[CSHybridEndpointAnalyzer resetForNewRequestWithSampleRate:recordContext:]_block_invoke
-[CSHybridEndpointAnalyzer _readParametersFromHEPAsset:]_block_invoke
-[CSHybridEndpointAnalyzer CSLanguageCodeUpdateMonitor:didReceiveLanguageCodeChanged:]
-[CSHybridEndpointAnalyzer CSAssetManagerDidDownloadNewAsset:]
-[CSHybridEndpointAnalyzer CSFirstUnlockMonitor:didReceiveFirstUnlock:]
-[CSHybridEndpointAnalyzer _updateAssetWithLanguage:]_block_invoke
cs_hep_marsh.json
cs_hep.json
-[CSHybridEndpointAnalyzer _getCSHybridEndpointerConfigForAsset:]
voic
carplay
hearst
raisetospeak
auto
CSAudioInjectionXPC Queue
-[CSAudioInjectionXPC createAudioInjectionDeviceWithType:deviceName:deviceID:productID:completion:]
-[CSAudioInjectionXPC injectAudio:toDeviceWithUUID:withScaleFactor:completion:]
-[CSAudioInjectionXPC injectAudio:toDeviceWithUUID:withScaleFactor:completion:]_block_invoke
-[CSAudioInjectionXPC connectDeviceWithUUID:completion:]
-[CSAudioInjectionXPC disconnectDeviceWithUUID:completion:]
-[CSAudioInjectionXPC disconnectDeviceWithUUID:completion:]_block_invoke
-[CSAudioInjectionXPC primaryInputDeviceUUIDWithCompletion:]
-[NSNumber(XPCObject) _cs_initWithXPCObject:]
-[NSNumber(XPCObject) _cs_xpcObject]
CSActivationEventNotificationHandler Queue
-[CSActivationEventNotificationHandler setDelegate:forType:]_block_invoke
-[CSActivationEventNotificationHandler notifyActivationEvent:completion:]_block_invoke
-[CSActivationEventNotificationHandler _notifyActivationEvent:completion:]
-[CSActivationEventNotificationHandler _notifyActivationEvent:completion:]_block_invoke
-[CSActivationEventNotificationHandler _startMonitoring]
-[CSActivationEventNotificationHandler _stopMonitoring]
triggerStartSampleCount
isMediaPlaying
noiseLevelDB
musicLevelDB
musicPlaybackVolumeDB
alarmVolume
finalTTSVolume
isAlarmPlaying
isTimerPlaying
isLKFSProcessPaused
removeVoiceTriggerSamples
-[CSSmartSiriVolume initWithSamplingRate:asset:]
-[CSSmartSiriVolume startSmartSiriVolume]_block_invoke
RUNNING
PAUSED
v20@?0B8Q12
-[CSSmartSiriVolume _startListenPolling]
-[CSSmartSiriVolume _startListenPollingWithInterval:completion:]
-[CSSmartSiriVolume _startListenPollingWithInterval:completion:]_block_invoke
-[CSSmartSiriVolume _startListenWithCompletion:]_block_invoke_2
-[CSSmartSiriVolume _startListenWithCompletion:]_block_invoke
-[CSSmartSiriVolume _startListenWithCompletion:]
-[CSSmartSiriVolume _stopListening]
-[CSSmartSiriVolume _stopListening]_block_invoke
-[CSSmartSiriVolume initializeMediaPlayingState]_block_invoke
playing
NOT playing
-[CSSmartSiriVolume initializeMediaPlayingState]
-[CSSmartSiriVolume initializeAlarmState]_block_invoke
firing
NOT firing
-[CSSmartSiriVolume initializeTimerState]_block_invoke
-[CSSmartSiriVolume _setAsset:]
-[CSSmartSiriVolume _processAudioChunk:soundType:]
-[CSSmartSiriVolume estimateSoundLevelbySoundType:]_block_invoke
-[CSSmartSiriVolume _pauseSSVProcessing]_block_invoke
-[CSSmartSiriVolume _resumeSSVProcessing]_block_invoke
-[CSSmartSiriVolume audioStreamProvider:audioBufferAvailable:]_block_invoke
-[CSSmartSiriVolume audioStreamProvider:didStopStreamUnexpectly:]
-[CSSmartSiriVolume didDetectKeywordWithResult:]
-[CSSmartSiriVolume didDetectKeywordWithResult:]_block_invoke
-[CSSmartSiriVolume estimatedTTSVolumeForNoiseLevelAndLKFS:LKFS:]_block_invoke
-[CSSmartSiriVolume _combineResultsWithOptimalFromNoise:andOptimalFromLkfs:withUserOffset:]
-[CSSmartSiriVolume CSMediaPlayingMonitor:didReceiveMediaPlayingChanged:]_block_invoke
-[CSSmartSiriVolume didReceiveAlarmChanged:]_block_invoke
-[CSSmartSiriVolume didReceiveTimerChanged:]_block_invoke
-[CSSmartSiriVolume CSSiriEnabledMonitor:didReceiveEnabled:]
-[CSSmartSiriVolume CSAudioServerCrashMonitorDidReceiveServerRestart:]
-[CSSmartSiriVolume siriClientBehaviorMonitor:didStartStreamWithContext:successfully:option:withEventUUID:]_block_invoke
-[CSSmartSiriVolume _setStartAnalyzeTime:]
-[CSSmartSiriVolume getVolumeForTTSType:withOverrideMediaVolume:WithRequestTime:]
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
CSAudioInjectionProvider
ATVRemoteInput
BuiltInMic
-[CSAudioInjectionProvider dealloc]
-[CSAudioInjectionProvider stop]
-[CSAudioInjectionProvider startAudioStreamWithOption:recordDeviceIndicator:error:]
-[CSAudioInjectionProvider stopAudioStreamWithRecordDeviceIndicator:error:]
BuiltInSpeaker
+[CSUtils(Compression) extractArchiveFromDirectory:toDir:]
-[CSListeningEnabledPolicyWatch _addListeningEnabledConditions]_block_invoke
-[CSOtherAppRecordingStateMonitor handleOtherAppRecordingStateChange:]
-[CSOtherAppRecordingStateMonitor _systemControllerDied:]
+[CSUtils(LanguageCode) getSiriLanguageWithFallback:]
+[CSUtils(LanguageCode) getSiriLanguageWithEndpointId:fallbackLanguage:]
-[CSAutomaticVolumeEnabledMonitor observeValueForKeyPath:ofObject:change:context:]_block_invoke
CSAudioFileReader Queue
-[CSAudioFileReader initWithURL:]
-[CSAudioFileReader prepareRecording:]
-[CSAudioFileReader startRecording]
-[CSAudioFileReader _readAudioBufferAndFeed]
-[CSAudioFileReader stopRecording]
-[CSEndpointerProxy resetForNewRequestWithSampleRate:recordContext:recordOption:voiceTriggerInfo:]
-[CSEndpointerProxy resetForVoiceTriggerTwoShotWithSampleRate:]
-[CSEndpointerProxy preheat]
-[CSEndpointerProxy endpointer:didDetectStartpointAtTime:]
-[CSEndpointerProxy endpointer:didDetectHardEndpointAtTime:withMetrics:]
-[CSEndpointerProxy endpointer:detectedTwoShotAtTime:]
-[CSEndpointerProxy endpointerModelVersion]
-[CSEndpointerProxy logHybridEndpointFeaturesWithEvent:locale:]
com.apple.cs.%@.queue
-[CSAttSiriOSDNode addReceiver:]_block_invoke
-[CSAttSiriOSDNode stop]_block_invoke
-[CSAttSiriOSDNode setPrefetchedAsset:]_block_invoke
-[CSAttSiriOSDNode attSiriAudioSrcNodeLPCMRecordBufferAvailable:audioChunk:]_block_invoke
-[CSAttSiriOSDNode checkConsecutiveBoronSignalWithAudioChunk:]
-[CSAttSiriOSDNode attSiriAudioSrcNodeDidStop:]_block_invoke
-[CSAttSiriOSDNode resetForNewRequestWithRecordContext:voiceTriggerInfo:]_block_invoke
-[CSShadowMicScoreCreator calculateShadowMicScore]
-[CSMyriadSelfTriggerCoordinator selfTriggerDetector:didDetectSelfTrigger:]
com.apple.siri.corespeech.selftrigger
SPG.nnet
version
CSEndpointerAssetManager queue
-[CSEndpointerAssetManager init]
-[CSEndpointerAssetManager checkFirstUnlocked]
-[CSEndpointerAssetManager CSLanguageCodeUpdateMonitor:didReceiveLanguageCodeChanged:]_block_invoke
-[CSEndpointerAssetManager CSAssetManagerDidDownloadNewAsset:]_block_invoke
-[CSEndpointerAssetManager CSFirstUnlockMonitor:didReceiveFirstUnlock:]_block_invoke
-[CSEndpointerAssetManager _getCurrentHEPAsset]
-[CSEndpointerAssetManager _updateOEPAssetsWithLanguage:]
-[CSEndpointerAssetManager _notifyAssetsUpdate]
ModelInfo=
-[CSEndpointerAssetManager _getOEPVersionFromPath:]
CSAudioInjectionBuiltInEngine
-[CSAudioInjectionBuiltInEngine dealloc]
SampleCount
HostTime
-[CSAudioInjectionBuiltInEngine getBestSampleCountWithOption:]
trigger-time
-[CSSpringboardStartMonitor _startMonitoringWithQueue:]
-[CSSpringboardStartMonitor _stopMonitoring]
-[CSSpringboardStartMonitor _checkSpringBoardStarted]
com.apple.springboard.finishedstartup
speakerRecognition
combinationWeight
implicitProfileThreshold
implicitProfileDeltaThreshold
implicitVTThreshold
pruningExplicitSATThreshold
pruningExplicitPSRThreshold
pruningSATThreshold
pruningPSRThreshold
numPruningRetentionUtt
maxEnrollmentUtterances
pruningCookie
configFileRecognizer
configFileNDAPI
voiceTriggerSecondPassAOP
implicit_training_enabled
multiUserHighScoreThreshold
multiUserLowScoreThreshold
multiUserConfidentScoreThreshold
multiUserDeltaScoreThreshold
recognizer.json
config.txt
-[CSAsset(SpeakerRecognition) containsMultiUserThresholds]
CSActivationEventNotifier
-[CSActivationEventNotifier notifyActivationEventSynchronously:completion:]
-[CSActivationEventNotifier notifyActivationEvent:completion:]_block_invoke
-[CSActivationEventNotifier notifyActivationEvent:deviceId:activationInfo:completion:]_block_invoke
-[CSActivationEventNotifier _createXPCClientConnection]
CSAlarmMonitor queue
-[CSAlarmMonitor _startMonitoringWithQueue:]
-[CSAlarmMonitor _stopMonitoring]
-[CSSmartSiriVolumeServiceProxy init]
overrideMediaVolume
SSV Manager returned estimate as nil
-[CSSmartSiriVolumeServiceProxy getVolumeForTTSType:withContext:reply:]
SmartSiriVolume not supported on this device type. smartSiriVolume : %p
-[CSSmartSiriVolumeServiceProxy setSmartSiriVolumePercentage:]
-[CSSmartSiriVolumeServiceProxy setSmartSiriVolumeDirection:]
-[CSSmartSiriVolumeServiceProxy setPermanentVolumeOffsetWithDirection:]
CSAttSiriAudioSrcNode queue
-[CSAttSiriAudioSrcNode initWithMasterAudioStream:name:]
-[CSAttSiriAudioSrcNode addReceiver:]_block_invoke
-[CSAttSiriAudioSrcNode dealloc]
-[CSAttSiriAudioSrcNode audioStreamProvider:didStopStreamUnexpectly:]_block_invoke
-[CSAttSiriAudioSrcNode _handleDidStop]
-[CSAttSiriAudioSrcNode _fetchAudioDecoderForTV:]
-[CSFirstUnlockMonitor _stopMonitoring]
-[NSString(XPCObject) _cs_initWithXPCObject:]
-[NSArray(XPCObject) _cs_initWithXPCObject:]
-[NSArray(XPCObject) _cs_initWithXPCObject:]_block_invoke
B24@?0Q8@"NSObject<OS_xpc_object>"16
-[NSArray(XPCObject) _cs_xpcObject]_block_invoke
v32@?0@8Q16^B24
BuiltInMicrophoneDevice
CSVoiceTriggerEventInfoProvider Queue
-[CSVoiceTriggerEventInfoProvider fetchVoiceTriggerInfoWithAudioContext:triggerInfoProviding:resultVoiceTriggerInfo:resultRTSTriggerInfo:]
route
isRemoteDevice
remoteDeviceUID
remoteDeviceProductIdentifier
remoteDeviceUIDString
%@ {route = %@, isRemoteDevice = %d, remoteDeviceUID = %@, remoteDeviceProductIdentifier = %@, remoteDeviceUIDString = %@}
CSCommandControlBehaviorMonitor
-[CSCommandControlBehaviorMonitor notifyWillStartStreamWithContext:option:]_block_invoke
-[CSCommandControlBehaviorMonitor notifyDidStartStreamWithContext:successfully:option:]_block_invoke
-[CSCommandControlBehaviorMonitor notifyWillStopStream:]_block_invoke
-[CSCommandControlBehaviorMonitor notifyDidStopStream:]_block_invoke
ApplicationProcessorWithCall
v16@?0@"AFSiriActivationResult"8
-[CSSiriLauncher notifyBuiltInVoiceTrigger:myriadPHash:completion:]_block_invoke
Trigger was during phone call
v16@?0@"<AFMyriadContextMutating>"8
-[CSSiriLauncher notifyWakeKeywordSpokenInBuiltInMic:]_block_invoke
-[CSSiriLauncher notifyCarPlayVoiceTriggerPrewarm:deviceId:completion:]_block_invoke
-[CSSiriLauncher notifyCarPlayVoiceTrigger:deviceId:myriadPHash:completion:]_block_invoke
-[CSSiriLauncher notifyWakeKeywordSpokenCarPlay:deviceId:]_block_invoke
-[CSSiriLauncher notifyBluetoothDeviceVoiceTrigger:deviceId:completion:]_block_invoke
-[CSSiriLauncher notifyWakeKeywordSpokenBluetoothDevice:deviceId:]_block_invoke
-[CSSiriLauncher deactivateSiriActivationConnectionWithReason:withOptions:withContext:]_block_invoke
clientStartSampleCount
triggerEndSampleCount
-[CSAudioProcessWaitingBuffer initWithSiriSessionUUID:]
-[CSAudioProcessWaitingBuffer dealloc]
localSpeechRecognizerQueue Queue
-[CSAttSiriAsrNode stopWithReason:]
-[CSAttSiriAsrNode stopWithReason:]_block_invoke
-[CSAttSiriAsrNode _adjustEndpointStartTimeWithVoiceTriggerEvent:]
-[CSAttSiriAsrNode preheatLocalSpeechRecognitionWithLanguage:source:]_block_invoke
SRD ASR Result Delivery Transaction
-[CSAttSiriAsrNode startDeliverLocalSpeechRecognitionResultsWithSettings:]_block_invoke
-[CSAttSiriAsrNode _startDeliverLocalSpeechRecognitionResultsWithRequestId:]
-[CSAttSiriAsrNode stopDeliverLocalSpeechRecognitionWithReason:]
-[CSAttSiriAsrNode disableLocalSpeechRecognitionForRequestId:]
-[CSAttSiriAsrNode attSiriAudioSrcNodeLPCMRecordBufferAvailable:audioChunk:]_block_invoke
-[CSAttSiriAsrNode attSiriAudioSrcNodeDidStop:]_block_invoke
-[CSAttSiriAsrNode attSiriNode:didDetectHardEndpointAtTime:withMetrics:]_block_invoke
-[CSAttSiriAsrNode _enforceEndpointHintWithRequestId:rcId:shouldAccept:featuresToLog:]
-[CSAttSiriAsrNode _enforceEndpointHintWithRequestId:rcId:shouldAccept:featuresToLog:]_block_invoke
-[CSAttSiriAsrNode start]
ASRNode Recording Transaction
-[CSAttSiriAsrNode start]_block_invoke
-[CSAttSiriAsrNode _preheatWithLanguage:preheatSource:]
-[CSAttSiriAsrNode prepareToStartSpeechRequestWithStartStreamOption:audioRecordContext:voiceTriggerInfo:]_block_invoke
-[CSAttSiriAsrNode _stopPreviousRecognitionTaskIfNeededWithNewRequestId:]
-[CSAttSiriAsrNode _shouldDisableLocalSpeechRecognizerWithOption:audioRecordContext:]
-[CSAttSiriAsrNode _startLocalSpeechRecognizerIfNeeded]
-[CSAttSiriAsrNode _startLocalSpeechRecognizerIfNeeded]_block_invoke
v24@?0@"CESRModelProperties"8@"NSError"16
-[CSAttSiriAsrNode _processAudioChunk:]
-[CSAttSiriAsrNode _handleStopSpeechRecognitionTaskIfNeeded:]
-[CSAttSiriAsrNode _scheduleRecordingTransactionReleaseTimer]
-[CSAttSiriAsrNode _releaseRecordingTransactionIfNeededWithToken:]
-[CSAttSiriAsrNode _interactiveLocalSpeechRecognizer]
-[CSAttSiriAsrNode localSpeechRecognizer:didRecognizeTokens:]_block_invoke
-[CSAttSiriAsrNode localSpeechRecognizer:didProcessAudioDuration:]_block_invoke
-[CSAttSiriAsrNode _queryShouldAcceptEagerResultForDuration:requestId:rcId:]
v20@?0B8@"NSArray"12
-[CSAttSiriAsrNode _handleShouldAcceptEagerResultWithRequestId:rcId:duration:shouldAccept:featuresToLog:]_block_invoke
-[CSAttSiriAsrNode localSpeechRecognizer:didRecognizePackage:]_block_invoke
-[CSAttSiriAsrNode _handleDidRecognizedFinalSpeechPackage:requestId:]
-[CSAttSiriAsrNode _handleDidRecognizedSpeechPackageForEagerRecognitionCandidate:requestId:rcId:processedAudioDuration:]
-[CSAttSiriAsrNode localSpeechRecognizer:didCompletionRecognitionWithStatistics:error:]_block_invoke
SiriX
enableTelemetry=YES
-[CSAttSiriAsrNode localSpeechRecognizer:didProduceEndpointFeaturesWithWordCount:trailingSilenceDuration:eosLikelihood:pauseCounts:silencePosterior:processedAudioDurationInMilliseconds:]_block_invoke
-[CSAttSiriAsrNode localSpeechRecognizer:didSelectRecognitionModelWithModelProperties:]
-[CSAttSiriAsrNode _fetchInputOriginWithRecordContext:]
HomeButton
-[CSAttSiriAsrNode _setLocalSpeechRecognizerState:]
[Idle]
[Disabled]
[Delivering message]
[Waiting for start deliver message]
[Waiting for start deliver message after client stop]
[Unknown]
-[CSAttSiriAsrNode _fetchRecognizerLanguageWithSiriLanguage:UILanguage:taskString:]
com.apple.corespeech.attsiri-timer
-[CSAttSiriTimer setTimerForSecs:completionBlock:]_block_invoke
-[CSAttSiriTimer cancelTimer]_block_invoke
-[CSAudioStream initWithAudioStreamProvider:streamName:streamRequest:]
-[CSAudioStream dealloc]
-[CSAudioStream startAudioStreamWithOption:completion:]
-[CSAudioStream stopAudioStreamWithOption:completion:]_block_invoke
-[CSAudioStream isStreaming]
-[CSAudioStream updateAudioStreamStartTimeInSampleCount:]
-[CSAudioStream audioStreamProvider:didStopStreamUnexpectly:]
-[CSAudioStream audioStreamProvider:didHardwareConfigurationChange:]
-[CSVoiceTriggerAssetMetaUpdateMonitor _startMonitoringWithQueue:]
-[CSVoiceTriggerAssetMetaUpdateMonitor _stopMonitoring]
-[CSVoiceTriggerAssetMetaUpdateMonitor _didReceiveNewVoiceTriggerAssetMetaData]
com.apple.MobileAsset.VoiceTriggerAssets.ma.cached-metadata-updated
com.apple.MobileAsset.VoiceTriggerAssetsIPad.ma.cached-metadata-updated
com.apple.MobileAsset.VoiceTriggerAssetsWatch.ma.cached-metadata-updated
com.apple.MobileAsset.VoiceTriggerAssetsMarsh.ma.cached-metadata-updated
com.apple.MobileAsset.VoiceTriggerAssetsMac.ma.cached-metadata-updated
com.apple.MobileAsset.VoiceTriggerAssetsTV.ma.cached-metadata-updated
-[CSAudioPreprocessor resetWithSampleRate:containsVoiceTrigger:voiceTriggerInfo:]
-[CSAudioPreprocessor flush]
ZeroFilterMetrics
-[CSAudioPreprocessor _fetchCurrentMetrics]
BeepCancellerMetrics
com.apple.corespeech.CSAccessorySiriClientBehaviourMonitor
-[CSAccessorySiriClientBehaviorMonitor notifyWillStartStreamWithContext:option:forAccessory:]_block_invoke
-[CSAccessorySiriClientBehaviorMonitor notifyDidStartStreamWithContext:successfully:option:withEventUUID:forAccessory:]_block_invoke
-[CSAccessorySiriClientBehaviorMonitor notifyWillStopStream:reason:forAccessory:]_block_invoke
-[CSAccessorySiriClientBehaviorMonitor notifyDidStopStream:reason:withEventUUID:forAccessory:]_block_invoke
CSAudioRouteChangeMonitorImplWatch queue
-[CSAudioRouteChangeMonitorImplWatch activeAudioRouteDidChange:]_block_invoke
-[CSAudioRouteChangeMonitorImplWatch _startMonitoringWithQueue:]
-[CSAudioRouteChangeMonitorImplWatch _stopMonitoring]
-[CSAudioRouteChangeMonitorImplWatch _notifyHearstConnectionState:]
-[CSAudioRouteChangeMonitorImplWatch _systemControllerDied:]
-[CSSpeechEndpointAssetMetaUpdateMonitor _startMonitoringWithQueue:]
-[CSSpeechEndpointAssetMetaUpdateMonitor _stopMonitoring]
-[CSSpeechEndpointAssetMetaUpdateMonitor _didReceiveNewSpeechEndpointAssetMetaData]
com.apple.MobileAsset.SpeechEndpointAssetsWatch.ma.cached-metadata-updated
com.apple.MobileAsset.SpeechEndpointAssetsTV.ma.cached-metadata-updated
com.apple.MobileAsset.SpeechEndpointAssets.ma.cached-metadata-updated
corespeechd speaker xpc connection client queue
-[CSVoiceIdXPCConnection _handleClientEvent:]
-[CSVoiceIdXPCConnection _handleClientMessage:client:]
-[CSVoiceIdXPCConnection _handleClientError:client:]
-[CSAssetManagerEnablePolicy _addAssetManagerEnabledConditions]_block_invoke
-[CSAudioRecordContext(AVVC) avvcContextSettings]
CSXPCListener
-[CSXPCListener listen]
-[CSXPCListener _handleListenerEvent:]
-[CSXPCListener _handleListenerError:]
-[CSXPCListener _handleNewRemoteConnection:]
corespeech.corespeechd.xpc
-[CSXPCListener CSXPCConnectionReceivedClientError:clientError:client:]_block_invoke
extra-delay-frequency
endpoint-threshold
-[CSHybridEndpointer endpointerModelVersion]_block_invoke
-[CSHybridEndpointer updateEndpointerThreshold:]
-[CSHybridEndpointer updateEndpointerDelayedTrigger:]
-[CSHybridEndpointer setEndpointerOperationMode:]_block_invoke
-[CSHybridEndpointer fetchCurrentEndpointerOperationMode]_block_invoke
-[CSHybridEndpointer processTaskString:]_block_invoke
-[CSHybridEndpointer processServerEndpointFeatures:]
-[CSHybridEndpointer shouldAcceptEagerResultForDuration:resultsCompletionHandler:]_block_invoke_2
-[CSHybridEndpointer shouldAcceptEagerResultForDuration:resultsCompletionHandler:]_block_invoke
-[CSHybridEndpointer processFirstAudioPacketTimestamp:firstAudioSampleSensorTimestamp:]_block_invoke
-[CSHybridEndpointer processOSDFeatures:withFrameDurationMs:]
-[CSHybridEndpointer processOSDFeatures:withFrameDurationMs:]_block_invoke_2
-[CSHybridEndpointer processOSDFeatures:withFrameDurationMs:]_block_invoke
-[CSHybridEndpointer logFeaturesWithEvent:locale:]_block_invoke
-[CSHybridEndpointer handleVoiceTriggerWithActivationInfo:]_block_invoke
-[CSHybridEndpointer recordingStoppedForReason:]
-[CSHybridEndpointer stopEndpointer]
-[CSHybridEndpointer resetForNewRequestWithSampleRate:recordContext:]
-[CSHybridEndpointer resetForNewRequestWithSampleRate:recordContext:]_block_invoke
-[CSHybridEndpointer _readParametersFromHEPAsset:]_block_invoke
-[CSHybridEndpointer endpointerAssetManagerDidUpdateAsset:]_block_invoke
-[CSHybridEndpointer _getCSHybridEndpointerConfigForAsset:]
configVersion
com.apple.corespeech.aopFirstPassTriggerWakeupLatency
latency
device
com.apple.corespeech.SecondPassWakeUp
modelVersion
firstPassSource
triggerAPWakeup
-[CSVoiceTriggerStatAggregator logFalseWakeUp:]
-[CSVoiceTriggerStatAggregator logTriggerLengthSampleCountStatistics:withFirstPassDeterministicTriggerLengthSampleCount:]
com.apple.exprAOPSecondPass
newTriggerLengthSampleCount
oldTriggerLengthSampleCount
sampleCountDelta
com.apple.corespeech.AudioZeroRun
duration
-[CSRawAudioInjectionProvider init]
CSRawAudioInjectionProvider
-[CSRawAudioInjectionProvider dealloc]
-[CSRawAudioInjectionProvider setContext:completion:]
-[CSRawAudioInjectionProvider setCurrentContext:streamHandleId:error:]
-[CSRawAudioInjectionProvider prepareAudioStreamRecord:recordDeviceIndicator:error:]
-[CSRawAudioInjectionProvider startAudioStreamWithOption:recordDeviceIndicator:error:]
/var/mobile/darwin_test.wav
-[CSRawAudioInjectionProvider stopAudioStreamWithRecordDeviceIndicator:error:]
-[CSRawAudioInjectionProvider isRecordingWithRecordDeviceIndicator:]
RawAudioInjection
-[CSRawAudioInjectionProvider prewarmAudioSessionWithStreamHandleId:error:]
-[CSRawAudioInjectionProvider activateAudioSessionWithReason:streamHandleId:error:]
CSAudioInjectionTvRemoteEngine
com.apple.coreaudio.BorealisToggled
-[CSVoiceTriggerEnabledMonitor _startMonitoringWithQueue:]_block_invoke
-[CSVoiceTriggerEnabledMonitor _startMonitoringWithQueue:]
-[CSVoiceTriggerEnabledMonitor _stopMonitoring]
-[CSVoiceTriggerEnabledMonitor _checkVoiceTriggerEnabled]
announcemessage
estimatedTTSVolume
debugLogPath
-[CSAlwaysOnProcessorStateMonitor _didReceiveAOPListeningStateChange:]
AcousticSLTaskTypeVoiceTrigger
AcousticSLTaskTypeContConv
AcousticSL
-[CSAttSiriAFTMNode initWithAttSiriController:]
-[CSAttSiriAFTMNode addReceiver:]
-[CSAttSiriAFTMNode stop]_block_invoke
-[CSAttSiriAFTMNode setPrefetchedAsset:]_block_invoke
-[CSAttSiriAFTMNode _startRequestWithContext:withVtei:withVTAssets:taskType:completion:]
-[CSAttSiriAFTMNode startRequestWithContext:withVtei:taskType:completion:]_block_invoke
-[CSAttSiriAFTMNode _setAsset:forTask:]
-[CSAttSiriAFTMNode _startRequestWithContext:withVtei:completion:]
-[CSAttSiriAFTMNode _addAudio:]
-[CSAttSiriAFTMNode _reset]
-[CSAttSiriAFTMNode _handleAFTMResults:]
-[CSAttSiriAFTMNode analyzer:hasFinalResult:]_block_invoke
-[CSAttSiriAFTMNode analyzer:hasPartialResult:]_block_invoke
-[CSAttSiriAFTMNode _logResultToVTDirectory]
-SL.json
SLAssetVersion
SLScore
SLAnalyzedSamples
SLCheckerType
SLThreshold
SLInputOriginType
SLTaskName
-[CSAttSiriAFTMNode _reportResultToAnalytics]
com.apple.
com.apple.private.
-[CSAudioTimeConversionProvidingProxy handleXPCMessage:messageBody:client:audioStreamHandleId:]
deviceId
-[CSAudioTimeConversionProvidingProxy _handleXPCTimeConvertProvidingTypeHostTimeFromSampleCountMessage:messageBody:client:streamHandleId:]
-[CSAudioTimeConversionProvidingProxy _handleXPCTimeConvertProvidingTypeSampleCountFromHostTimeMessage:messageBody:client:streamHandleId:]
meta_version.json
enrollment_version.json
CSP2P_CommandType_Key
CSP2P_CommandDict_Key
corespeech
com.apple.siridebug.command.remote.heysiri
com.apple.siridebug.command.parallel.recording
com.apple.siridebug.command.transfer.voiceprofile
com.apple.siridebug.command.query.voiceprofile
com.apple.siridebug.command.reverse.transfer.voiceprofile
com.apple.siridebug.command.fetch.voiceprofile
com.apple.siridebug.command.voiceprofile.update.trigger
com.apple.siridebug.command.transfer.parallelrecording
com.apple.siridebug.command.fetch.voicegradingdata
com.apple.siridebug.command.transfer.voicegradingdata
com.apple.siridebug.command.delete.voiceprofile
CSP2P_RemoteHeySiriEnable_Key
CSP2P_RemoteHeySiriStatus_Key
CSP2P_RemoteRecordingStart_Key
CSP2P_RemoteRecordingStatus_Key
CSP2P_VoiceProfileData_Key
CSP2P_VoiceProfileFileName_Key
CSP2P_VoiceProfileSpeakerName_Key
CSP2P_VoiceProfileLocale_Key
CSP2P_VoiceProfileDataType_Key
CSP2P_VoiceProfileSegment_Key
CSP2P_VoiceProfileTotalSegments_Key
CSP2P_VoiceProfileStatus_Key
CSP2P_VoiceProfileProfileId_Key
CSP2P_VoiceProfileHomeUserId_Key
CSP2P_VoiceProfileRelativeFilePath_Key
CSP2P_VoiceProfileSiriProfileId_Key
CSP2P_VoiceProfileAppDomain_Key
CSP2P_VoiceProfileOnboardTimeStamp_Key
CSP2P_VoiceProfileTransferCompleted_Key
CSP2P_VoiceProfileRecordedData_Key
CSP2P_VoiceProfileRemoteFileName_Key
CSP2P_VoiceDataToBeGraded_Key
CSP2P_VoiceFileNameToBeGraded_Key
CSP2P_GradingDataTransferStatus_Key
CSP2P_PeerIdentifier_Key
CSP2P_IsDataCompressed_Key
CSP2P_UncompressedDataSize_Key
CSP2P_GradingBatchTransferID_Key
remote
-triggered
-almost
com.apple.corespeech.p2psvc
-[CSP2PService processRemoteCommandWithPayload:fromPeer:withReply:]_block_invoke
CoreSpeech
-[CSP2PService sendCoreSpeechGradingDataToNearbyPeer]_block_invoke
-[CSP2PService sendVTNearMissGradingDataToCompanion]_block_invoke
-[CSP2PService sendVoiceProfileUpdatedMessageToNearbyPeerForLocale:]_block_invoke
-[CSP2PService sendAcousticGradingDataToNearbyPeer]_block_invoke
-[CSP2PService _processRemoteHeySiriCommandWithRequest:fromSenderID:withReply:]
-[CSP2PService _compressFilesInDirectory:matchingPredicate:compressedFileAvailable:]
json
-[CSP2PService _sendVoiceTriggerGradingDataToPeerId:]_block_invoke
v52@?0@"NSString"8@"NSData"16Q24Q32B40@"NSError"44
.wav
.json
-[CSP2PService _sendCoreSpeechGradingDataToPeerId:]_block_invoke_2
-[CSP2PService _sendCoreSpeechGradingDataToPeerId:]_block_invoke
-[CSP2PService _sendCoreSpeechMagusGradingDataToPeerId:]_block_invoke_2
-[CSP2PService _sendCoreSpeechMagusGradingDataToPeerId:]_block_invoke
-[CSP2PService _sendGradingData:withFileName:toPeerId:withCompressedFlag:withUncompressedDataSize:withBatchId:withRetainFileFlag:]
fileData
fileName
peerId
-[CSP2PService _sendGradingData:withFileName:toPeerId:withCompressedFlag:withUncompressedDataSize:withBatchId:withRetainFileFlag:]_block_invoke
-[CSP2PService _receiveParallelRecordingFromPeerId:recordingInfo:withReply:]
%@_%@
-[CSP2PService _receiveVoiceGradingDataFromPeerId:requestInfo:withReply:]
%@.%@.%@
suppressnotification
%@.%@
-[CSP2PService _receiveVoiceProfileFromPeerId:voiceProfileInfo:withReply:]
CoreSpeechCache
audio
tdti
com.apple.siri.corespeech.voiceprofilelist.change
-[CSP2PService _processVoiceProfileDeleteCommandWithRequest:fromSenderID:withReply:]_block_invoke
-[CSP2PService _processGradingDataFetchCommandWithRequest:fromSenderID:withReply:]
-[CSP2PService _processVoiceProfileListQueryCommandFromPeerId:requestInfo:withReply:]
yyyyMMddHHmmss
voiceprofiles
-[CSP2PService _getHomeUserIdForSharedSiriId:withCompletion:]
-[CSP2PService _getHomeUserIdForSharedSiriId:withCompletion:]_block_invoke
homeUserId query for siriProfileId %@ timedout !
-[CSP2PService _processFetchVoiceProfileCommandFromPeerId:requestInfo:withReply:]
Caches/VoiceTrigger/SATUpdate
_%d_%d_%@
-[CSP2PService _sendVoiceProfile:toPeerId:]
td/audio
tdti/audio
ti/audio
-[CSP2PService _sendVoiceProfile:toPeerId:]_block_invoke
-[CSP2PService _processReverseTransferVoiceProfileCommandFromPeerId:requestInfo:withReply:]
-[CSP2PService _processVoiceProfileUpdateTriggerFromPeerId:requestInfo:withReply:]
-[CSP2PService _sendVoiceProfileUpdateTriggerToPeerId:forLocale:]_block_invoke
-synced.wav
-[CSP2PService _sendAcousticGradingDataToPeerId:]_block_invoke_2
-[CSP2PService _sendAcousticGradingDataToPeerId:]_block_invoke
Logs/CoreSpeech/spid/grading
-[CSP2PService _createDirectoryIfDoesNotExist:]
VoiceProfileStore
trained_users.json
Caches
-[CSP2PService _getContentsOfDirectory:]
+[CSAudioRecorderFactory audioRecorderWithQueue:error:]
AttSiriController queue
-[CSAttSiriController siriClientBehaviorMonitor:willStartStreamWithContext:option:]
-[CSAttSiriController siriClientBehaviorMonitor:didStartStreamWithContext:successfully:option:withEventUUID:]_block_invoke
-[CSAttSiriController siriClientBehaviorMonitor:didStopStream:withEventUUID:]_block_invoke
-[CSAttSiriController siriClientBehaviorMonitor:fetchedSiriClientAudioStream:successfully:]_block_invoke
-[CSAttSiriController siriClientBehaviorMonitor:preparedSiriClientAudioStream:successfully:]_block_invoke
-[CSAttSiriController CSSiriEnabledMonitor:didReceiveEnabled:]
-[CSAttSiriController _forceBuildGraph:]
-[CSAttSiriController _setupAudioSrcNodeWithSiriClientStream:]
CSAttSiriController
-[CSAttSiriController _setupAudioSrcNodeWithSiriClientStream:]_block_invoke
-[CSAttSiriController _handleStartProcessingWithRecordContext:]
-[CSAttSiriController _handleStartProcessingWithRecordContext:]_block_invoke
-[CSAttSiriController _handleStopProcessing]
attSiri transaction
-[CSAttSiriController _releaseAttSiriTransactionIfNeeded]
-[CSAttSiriController handleAttendingAudioStopUnexpectly]_block_invoke
-[CSAttSiriController handleAudioStopUnexpectly]_block_invoke
Serial CSAssetManager queue
-[CSAssetManager initWithDownloadOption:]
-[CSAssetManager initWithDownloadOption:]_block_invoke
ENABLED
DISABLED
-[CSAssetManager setAssetDownloadingOption:]_block_invoke
-[CSAssetManager _fetchRemoteMetaData]
-[CSAssetManager _canFetchRemoteAsset:]
-[CSAssetManager CSLanguageCodeUpdateMonitor:didReceiveLanguageCodeChanged:]
-[CSAssetManager _createPeriodicalDownloadTimer]
-[CSAssetManager _createPeriodicalDownloadTimer]_block_invoke
-[CSAssetManager _startPeriodicalDownload]
-[CSAssetManager _stopPeriodicalDownload]
+[CSUtils(AudioDevice) isHFPWithRecordRoute:]
+[CSUtils(AudioDevice) isHeadphoneDeviceWithRecordRoute:playbackRoute:]
+[CSUtils(AudioDevice) isBluetoothAudioDeviceConnected]
BTDetails_IsHFPRoute
-[CSVoiceTriggerAwareZeroFilter resetWithSampleRate:containsVoiceTrigger:voiceTriggerInfo:]
-[CSAudioMetricProvidingProxy handleXPCMessage:messageBody:client:]
-[CSAudioMetricProvidingProxy _handleMetricProvidingRequestTypeAudioMetricMessage:messageBody:client:]
corespeechd xpc connection client queue
-[CSActivationXPCConnection _handleClientEvent:]
-[CSActivationXPCConnection _handleClientMessage:client:]
-[CSActivationXPCConnection _handleClientError:client:]
-[CSActivationXPCConnection _handleActivateEventMesssage:client:]
CSSiriClientBehaviorMonitor
-[CSSiriClientBehaviorMonitor notifyFetchedSiriClientAudioStream:successfully:]_block_invoke
-[CSSiriClientBehaviorMonitor notifyPreparedSiriClientAudioStream:successfully:]_block_invoke
-[CSSiriClientBehaviorMonitor notifyWillStartStreamWithContext:option:]_block_invoke
-[CSSiriClientBehaviorMonitor notifyDidStartStreamWithContext:successfully:option:withEventUUID:]_block_invoke
-[CSSiriClientBehaviorMonitor notifyWillStopStream:reason:]_block_invoke
-[CSSiriClientBehaviorMonitor notifyDidStopStream:withEventUUID:]_block_invoke
-[CSSiriClientBehaviorMonitor notifyReleaseAudioSession]_block_invoke
-[CSLanguageCodeUpdateMonitor _startMonitoringWithQueue:]
CSLanguageCodeUpdateMonitor.m
-[CSLanguageCodeUpdateMonitor _stopMonitoring]
-[CSLanguageCodeUpdateMonitor notifySiriLanguageCodeChanged:]
CSAttSiriNLDANode queue
-[CSAttSiriNLDAClassifierNode initWithAttSiriController:]
-[CSAttSiriNLDAClassifierNode addReceiver:]
-[CSAttSiriNLDAClassifierNode start]
-[CSAttSiriNLDAClassifierNode start]_block_invoke
-[CSAttSiriNLDAClassifierNode stop]_block_invoke
-[CSAttSiriNLDAClassifierNode setPrefetchedAsset:]_block_invoke
-[CSAttSiriNLDAClassifierNode createNLDAClassifierWithAsset:]_block_invoke
-[CSAttSiriNLDAClassifierNode processSpeechPackage:]_block_invoke
CSAudioInjectionHearstEngine
-[CSAudioInjectionHearstEngine dealloc]
Serial CSEventMonitor queue
-[CSEventMonitor _startMonitoringWithQueue:]
CSEventMonitor.m
-[CSEventMonitor _stopMonitoring]
AttSiri
mitigationModelConfigFile
defaultAFTMValue
nldaConfigFile
ouresConfig.json
nldaConfig.json
[%@]
[%llu]
[%f]
BuiltInAOPVoiceTrigger
RemoteMicVoiceTrigger
RemoteMicVAD
JarvisVoiceTrigger
mediaserverdLaunched
RemoraVoiceTrigger
uuid
activationInfo
vadScore
hosttime
+[CSAudioStreamRequest defaultRequestWithContext:]
+[CSAudioStreamRequest requestForLpcmRecordSettingsWithContext:]
+[CSAudioStreamRequest requestForOpusRecordSettingsWithContext:]
+[CSAudioStreamRequest requestForSpeexRecordSettingsWithContext:]
[requiresHistoricalBuffer = %@]
[useCustomizedRecordSettings = %@]
[lpcmIsFloat = %@]
[isSiri = %@]
[sampleRate = %lf]
[numberOfChannels = %lu]
requiresHistoricalBuffer
useCustomizedRecordSettings
audioFormat
sampleRate
lpcmBitDepth
lpcmIsFloat
NumberOfChannels
encoderBitRate
isSiri
recordContext
-[CSVoiceTriggerAssetDownloadMonitor _startMonitoringWithQueue:]
-[CSVoiceTriggerAssetDownloadMonitor _stopMonitoring]
-[CSVoiceTriggerAssetDownloadMonitor _didInstalledNewVoiceTriggerAsset]
com.apple.MobileAsset.VoiceTriggerAssets.ma.new-asset-installed
com.apple.MobileAsset.VoiceTriggerAssetsIPad.ma.new-asset-installed
com.apple.MobileAsset.VoiceTriggerAssetsWatch.ma.new-asset-installed
com.apple.MobileAsset.VoiceTriggerAssetsMarsh.ma.new-asset-installed
com.apple.MobileAsset.VoiceTriggerAssetsMac.ma.new-asset-installed
com.apple.MobileAsset.VoiceTriggerAssetsTV.ma.new-asset-installed
FlexKwdSpotter
recognizer_flexKwd.json
flexKwdConfigFile
flexKwd.Thresholds
flexKwdThresholdsFile
-[CSSmartSiriVolumeUserIntent applyLowerAndUpperBoundsToVolume:]
-[CSSmartSiriVolumeUserIntent applyLowerAndUpperBoundsToVolumeOffset:]
Dpg:%.3f Dpd:%.3f T:%.3f
droppingPrediction
droppedPrediction
-[CSSmartSiriVolumeManager initWithSamplingRate:withAsset:]
-[CSSmartSiriVolumeManager CSAlarmMonitor:didReceiveAlarmChanged:]
-[CSSmartSiriVolumeManager CSTimerMonitor:didReceiveTimerChanged:]
-[CSSmartSiriVolumeManager CSVolumeMonitor:didReceiveMusicVolumeChanged:]
-[CSSmartSiriVolumeManager CSVolumeMonitor:didReceiveAlarmVolumeChanged:]
-[CSSmartSiriVolumeManager CSAutomaticVolumeEnabledMonitor:didReceiveEnabled:]
CSContinuousAudioFingerprintProvider
-[CSContinuousAudioFingerprintProvider startWithUUID:withMaximumBufferSize:]
-[CSContinuousAudioFingerprintProvider startWithUUID:withMaximumBufferSize:]_block_invoke
-[CSContinuousAudioFingerprintProvider stopWithUUID:]
-[CSContinuousAudioFingerprintProvider stopWithUUID:]_block_invoke
-[CSContinuousAudioFingerprintProvider _startListenPollingWithInterval:completion:]
-[CSContinuousAudioFingerprintProvider _startListenPollingWithInterval:completion:]_block_invoke
-[CSContinuousAudioFingerprintProvider _startListenWithCompletion:]_block_invoke_2
-[CSContinuousAudioFingerprintProvider _startListenWithCompletion:]_block_invoke
-[CSContinuousAudioFingerprintProvider _startListenWithCompletion:]
-[CSContinuousAudioFingerprintProvider _startListenPolling]
-[CSContinuousAudioFingerprintProvider _stopListening]
-[CSContinuousAudioFingerprintProvider _stopListening]_block_invoke
-[CSContinuousAudioFingerprintProvider CSSiriEnabledMonitor:didReceiveEnabled:]
-[CSContinuousAudioFingerprintProvider audioStreamProvider:didStopStreamUnexpectly:]
-[CSContinuousAudioFingerprintProvider CSAudioServerCrashMonitorDidReceiveServerRestart:]
mitigation/ouresModel/ouresConfig.json
supportedInputOrigins
CSAttSiriUresNode queue
-[CSAttSiriUresNode initWithAttSiriController:]
-[CSAttSiriUresNode addReceiver:]
-[CSAttSiriUresNode setPrefetchedAsset:]_block_invoke
-[CSAttSiriUresNode setInputOriginWithAudioRecordContext:boronScore:]_block_invoke
-[CSAttSiriUresNode setASRModelRootDirectory:]_block_invoke
-[CSAttSiriUresNode getMitigationDecisionForRCId:]_block_invoke
-[CSAttSiriUresNode _storeMitigationDecision:forRCId:]
-[CSAttSiriUresNode _createModelAndRunInferenceForRcId:withCompletion:]_block_invoke
Mitigation
v16@?0@"SLUresMitigatorResult"8
-[CSAttSiriUresNode processResultCandidate:forRCId:forTask:completion:]_block_invoke
-[CSAttSiriUresNode setEndpointerFeatureEoS:]_block_invoke
-[CSAttSiriUresNode _createMitigatorModelWithConfig:]
-[CSAttSiriUresNode attSiriNode:didMitigate:withScore:taskType:]_block_invoke
-[CSAttSiriUresNode attSiriNode:didUpdateOSDFeatures:withFrameDurationMs:]_block_invoke
-[CSAttSiriUresNode attSiriNode:didUpdateWithSpeakerInfo:]_block_invoke
-[CSAttSiriUresNode attSiriNode:classifierScore:detailedResult:]_block_invoke
Ures ID - %@
-[CSAttSiriUresNode _holdTransactionForUresProcessing]
-[CSAttSiriUresNode _releaseUresProcessingTransaction]
-[CSAttSiriUresNode _decodeJsonFromFile:]
[SplitterEnabled(%d)]
[Device%d(%@) DoAP(%d)]
[SplitterState:%d]
-[CSAdBlockerAssetDownloadMonitor _startMonitoringWithQueue:]
-[CSAdBlockerAssetDownloadMonitor _stopMonitoring]
-[CSAdBlockerAssetDownloadMonitor _didInstalledNewAdBlockerAsset]
-[CSAdBlockerAssetDownloadMonitor trialAssetDownloadMonitorDelegate:didInstallNewAsset:assetType:]
com.apple.MobileAsset.AdBlockerAssets.ma.new-asset-installed
CSVoiceIdXPCListener
com.apple.corespeech.corespeechd.voiceid.xpc
-[CSVoiceIdXPCListener listen]
-[CSVoiceIdXPCListener _handleListenerEvent:]
-[CSVoiceIdXPCListener _handleListenerError:]
-[CSVoiceIdXPCListener _handleNewRemoteConnection:]
corespeech.corespeechd.voiceid.xpc
CSSpeechManager Asset Query Queue
-[CSSpeechManager startManager]
-[CSSpeechManager registerSpeechController:]
-[CSSpeechManager registerSiriClientProxy:]
v32@?0@"NSNumber"8@"CSAudioProvider"16^B24
-[CSSpeechManager audioProviderWithContext:error:]
-[CSSpeechManager audioProviderWithContext:error:]_block_invoke
v32@?0Q8q16@"NSError"24
-[CSSpeechManager audioProviderWithStreamID:]_block_invoke
-[CSSpeechManager _getAudioRecorderWithError:]
-[CSSpeechManager audioProviderInvalidated:streamHandleId:]_block_invoke
-[CSSpeechManager audioRecorderWillBeDestroyed:]_block_invoke
-[CSSpeechManager voiceTriggerAssetHandler:endpointId:didChangeCachedAsset:]
-[CSSpeechManager _handleClearLoggingFileTimer]
-[CSSpeechManager _createClearLoggingFileTimer]
-[CSSpeechManager _startClearLoggingFilesTimer]
-[CSVoiceIdXPCClient _handleListenerEvent:]
-[CSVoiceIdXPCClient _handleListenerError:]
utterencePath
audioDevice
audioRecord
voiceTriggerEventInfo
otherCtxt
-[CSAudioZeroCounter getZeroStatisticsFromBuffer:entireSamples:]
-[CSAudioZeroCounter stopReportZeroStatistics]
CSOpportuneSpeakBehaviorMonitor
-[CSOpportuneSpeakBehaviorMonitor notifyWillStartStreamWithContext:audioProviderUUID:option:]_block_invoke
-[CSOpportuneSpeakBehaviorMonitor notifyDidStartStreamWithContext:audioProviderUUID:successfully:option:]_block_invoke
-[CSOpportuneSpeakBehaviorMonitor notifyWillStopStream:]_block_invoke
-[CSOpportuneSpeakBehaviorMonitor notifyDidStopStream:]_block_invoke
Median
+[CSUtils(Statistics) distributionDictionary:]
average:
stddev:
q24@?0@8@16
-[CSXPCConnection sendMessageToClient:]
-[CSXPCConnection sendMessageToClient:]_block_invoke
-[CSXPCConnection _handleClientEvent:]
-[CSXPCConnection _handleClientMessage:client:]
-[CSXPCConnection _handleAudioProvidingMessage:messageBody:client:]
-[CSXPCConnection _handleAudioProvidingRequestTypeSwitchMessage:messageBody:client:]
-[CSXPCConnection _handleSetXPCClientTypeMessage:messageBody:client:]
-[CSXPCConnection _handleClientError:client:]
-[CSXPCConnection _handlePingPongMessage:client:]
-[CSAttSiriConnectionManager initWithAttSiriController:supportsAttentiveSiri:supportsSpeechRecognitionOnDevice:supportsSSR:]
com.apple.corespeech.corespeechd.endpointer.service
-[CSAttSiriConnectionManager _setupEndpointListener]
-[CSAttSiriConnectionManager _setupLocalSpeechRecognitionListener]
com.apple.corespeech.corespeechd.attsiri.service
-[CSAttSiriConnectionManager _setupAttSiriServiceListener]
com.apple.corespeech.corespeechd.ssr.service
-[CSAttSiriConnectionManager _setupSSRListener]
-[CSHostDaemon init]_block_invoke
CSHostDaemon
-[CSHostDaemon _daemonDidLaunch]
com.apple.notifyd.matching
-[CSHostDaemon _setupNotifyHandlers]_block_invoke
AFLanguageCodeDidChangeDarwinNotification
-[CSHostDaemon _daemonWillShutdown]
FirstPktLatency
TrailingPktLatency
TrailingPktSpeechLatency
-[CSEndpointLatencyInfo addPktInfoWithTimestamp:arrivalTimestamp:currentMachTime:]
-[CSEndpointLatencyInfo reportWithRequestMHUUID:]
+[CSUtils(AudioFile) readAudioChunksFrom:block:]
-[CSCoreSpeechDaemonStateMonitor notifyDaemonStateChanged:]
com.apple.corespeech.corespeechd.launch
-[CSCoreSpeechDaemonStateMonitor _startMonitoringWithQueue:]
-[CSCoreSpeechDaemonStateMonitor _stopMonitoring]
-[CSCoreSpeechDaemonStateMonitor _didReceiveDaemonStateChanged:]
-[CSConnectionListener initWithMachService:withServiceInterface:withServiceObject:withDelegateInterface:]
com.apple.CoreSpeech.Connection.Listener
-[CSConnectionListener dealloc]
-[CSConnectionListener listener:shouldAcceptNewConnection:]
-[CSConnectionListener listener:shouldAcceptNewConnection:]_block_invoke
-[CSConnectionListener listener:shouldAcceptNewConnection:]_block_invoke_2
-[CSConnectionListener notifyClientsWithBlock:]
-[CSConnectionListener notifyClientsWithBlock:]_block_invoke
-[CSConnectionListener resumeConnection]
/var/mobile/Library/VoiceTrigger
/var/mobile/Library/VoiceTrigger/KeepAlive
-[CSCoreSpeechDKeepAliveHandler _enableCoreSpeechDaemonKeepAlive]
KeepAlive
-[CSCoreSpeechDKeepAliveHandler _coreSpeechDaemonKeepAlived]
CSSiriAssertionMonitor queue
-[CSSiriAssertionMonitor init]
-[CSSiriAssertionMonitor _stopMonitoring]
-[CSSiriAssertionMonitor enableAssertionReceived]_block_invoke
-[CSSiriAssertionMonitor disableAssertionReceived]_block_invoke
-[CSAudioSessionProvidingProxy CSXPCConnectionReceivedClientError:clientError:client:]
-[CSAudioSessionProvidingProxy dealloc]
-[CSAudioSessionProvidingProxy handleXPCMessage:messageBody:client:]
-[CSAudioSessionProvidingProxy _handleSessionProvidingRequestTypePrewarmMessage:client:]
-[CSAudioSessionProvidingProxy _handleSessionProvidingRequestTypeActivateMessage:messageBody:client:]
-[CSAudioSessionProvidingProxy _handleSessionProvidingRequestTypeDeactivateMessage:messageBody:client:]
-[CSAudioSessionProvidingProxy _handleSessionProvidingRequestTypeGetDuckOthersOption:messageBody:client:]
-[CSAudioSessionProvidingProxy _handleSessionProvidingRequestTypeSetDuckOthersOption:messageBody:client:]
audioDeviceID
duckLevel
rampDuration
-[CSAudioSessionProvidingProxy _handleSessionProvidingRequestTypeDuckAudioDevice:messageBody:client:]
-[CSAudioSessionProvidingProxy _handleSessionProvidingRequestTypeDuckDefaultOutputAudioDevice:messageBody:client:]
-[CSAudioSessionProvidingProxy _handleSessionProvidingRequestTypeEnableMiniDucking:messageBody:client:]
ENABLE
DISABLE
-[CSAudioSessionProvidingProxy _handleSessionProvidingRequestTypeEnableSmartRoutingConsideration:messageBody:client:]
-[CSAudioSessionProvidingProxy audioSessionProvider:providerInvalidated:]
CSAudioInjectionRemoraEngine
-[CSAudioInjectionRemoraEngine dealloc]
Languages
Footprint
Premium
-[CSCommandControlStreamEventMonitor isStreaming]
-[CSAudioAlertProvidingProxy handleXPCMessage:messageBody:client:]
-[CSAudioAlertProvidingProxy _handleAlertProvidingRequestTypeSetAlertSoundMessage:messageBody:client:]
-[CSAudioAlertProvidingProxy _handleAlertProvidingRequestTypePlayAlertSoundMessage:messageBody:client:]
-[CSAudioAlertProvidingProxy _handleAlertProvidingRequestTypePlayRecordStartingAlertAndResetEndpointerMessage:messageBody:client:]
-[CSAudioAlertProvidingProxy _handleAlertProvidingRequestTypeAlertStartTimeMessage:messageBody:client:]
-[CSAudioAlertProvidingProxy _handleAlertProvidingRequestTypeConfigureAlertBehavior:messageBody:client:]
-[CSAudioAlertProvidingProxy audioAlertProvidingDidFinishAlertPlayback:ofType:error:]
com.apple.corespeech
-[CSAVCallConnectedMonitor _systemControllerDied:]
voicetrigger xpc service connection client queue
-[CSVoiceTriggerXPCConnection _handleClientEvent:]
-[CSVoiceTriggerXPCConnection _handleClientMessage:client:]
-[CSVoiceTriggerXPCConnection _handleClientError:client:]
-[CSVoiceTriggerXPCConnection _handleVoiceTriggerXPCServiceMessage:client:]
phraseSpotterBypass
bypassTimeout
-[CSVoiceTriggerXPCConnection _handlePhraseSpotterBypassRequest:]
raiseToSpeakBypass
-[CSVoiceTriggerXPCConnection _handleVoiceTriggeredSiriSessionCancelled]
enable
assertion
triggerStats
-[CSAttSiriFlexKwdNode initWithAttSiriController:]
-[CSAttSiriFlexKwdNode startWithContext:audioStreamId:]_block_invoke
-[CSAttSiriFlexKwdNode attSiriAudioSrcNodeDidStartRecording:successfully:error:]
-[CSAttSiriFlexKwdNode triggerReportedFromFlxKwdSpotter:]
-[CSAudioRouteChangeMonitor _startMonitoringWithQueue:]
CSAudioRouteChangeMonitor.m
-[CSAudioRouteChangeMonitor _stopMonitoring]
-[CSAudioRouteChangeMonitor getHearstConnected:]
-[CSAudioRouteChangeMonitor hearstConnected]
-[CSAudioRouteChangeMonitor getJarvisConnected:]
-[CSAudioRouteChangeMonitor jarvisConnected]
playbackDeviceTypeList
%@ {recordDeviceInfo = %@, playbackRoute = %@, playbackDevices = %@
+[CSUtils(machXPC) machXPCConnection:hasEntitlement:]
-[CSAdBlockerAssetMetaUpdateMonitor _startMonitoringWithQueue:]
-[CSAdBlockerAssetMetaUpdateMonitor _stopMonitoring]
-[CSAdBlockerAssetMetaUpdateMonitor _didReceiveNewAdBlockerAssetMetaData]
com.apple.MobileAsset.AdBlockerAssets.ma.cached-metadata-updated
+[CSAdBlockerAssetDecoderFactory adBlockerAssetDecoderWithVersion:]
CSAudioInjectionEngine
-[CSAudioInjectionEngine _createDeInterleaverIfNeeded]
-[CSAudioInjectionEngine stop]_block_invoke
-[CSAudioInjectionEngine _readAudioBufferAndFeed]
-[CSAudioInjectionEngine injectAudio:withScaleFactor:outASBD:playbackStarted:completion:]
-[CSAudioInjectionEngine stopAudioStream]_block_invoke
-[CSAudioInjectionEngine _deinterleaveBufferIfNeeded:]
-[CSAudioInjectionEngine _compensateChannelDataIfNeeded:receivedNumChannels:]
-[CSSoftwareUpdateCheckingMonitor _startMonitoringWithQueue:]
-[CSSoftwareUpdateCheckingMonitor _stopMonitoring]
-[CSSoftwareUpdateCheckingMonitor _checkSoftwareUpdateCheckingState]
com.apple.duetscheduler.restartCheckNotification
-[CSAudioConverter _convertBufferedLPCM:allowPartial:timestamp:arrivalTimestampToAudioRecorder:]
-[CSAudioConverter _convertBufferedLPCM:allowPartial:timestamp:arrivalTimestampToAudioRecorder:]_block_invoke
-[CSAudioConverter reset]
-[CSAudioConverter _configureAudioConverter:]
CreateAudioConverter
CSMediaPlayingMonitor queue
-[CSMediaPlayingMonitor initializeMediaPlayingState]_block_invoke_2
-[CSMediaPlayingMonitor _startMonitoringWithQueue:]
-[CSMediaPlayingMonitor _stopMonitoring]
-[CSMediaPlayingMonitor _notePossiblePlayPausedStateChange:]
PLAYING
NOT PLAYING
CSVoiceTriggerAOPModeEnabledPolicyIOS RecordState queue
-[CSVoiceTriggerAOPModeEnabledPolicyIOS _addConditionsForIOSBargeIn]_block_invoke
-[CSVoiceTriggerAOPModeEnabledPolicyIOS _addConditionsForIOSAOP]_block_invoke
-[CSVoiceTriggerAOPModeEnabledPolicyIOS _isSpeechDetectionDevicePresent]
-[CSVoiceTriggerAOPModeEnabledPolicyIOS siriClientBehaviorMonitor:didChangedRecordState:withEventUUID:withContext:]_block_invoke
-[CSAudioRecordDeviceIndicator updateWithLatestRecordContext:]
-[CSNetworkAvailabilityMonitor _startMonitoringWithQueue:]
-[CSNetworkAvailabilityMonitor _stopMonitoring]
-[CSNetworkAvailabilityMonitor _availabilityChanged]
-[NSDictionary(XPCObject) _cs_initWithXPCObject:]
-[NSDictionary(XPCObject) _cs_initWithXPCObject:]_block_invoke
B24@?0r*8@"NSObject<OS_xpc_object>"16
-[NSDictionary(XPCObject) _cs_xpcObject]_block_invoke
v32@?0@8@16^B24
-[CSAudioMeterProvidingProxy handleXPCMessage:messageBody:client:]
-[CSAudioMeterProvidingProxy _handleMeterProvidingRequestTypeSetMeteringEnabledMessage:messageBody:client:]
-[CSAudioMeterProvidingProxy _handleMeterProvidingRequestTypeUpdateMetersMessage:messageBody:client:]
v16@?0B8f12
-[CSAudioMeterProvidingProxy _handleMeterProvidingRequestTypePowerMessage:messageBody:client:powerType:]
CSMicUsageReporter
SpeechModelTrainingProtocol
SpeechModelTrainingClient
CSSpeechModelTrainingXPCManager
CSSyncKeywordAnalyzerQuasar
CSKeywordAnalyzerNDEAPIResult
CSKeywordAnalyzerNDEAPI
CSFallbackAudioSessionReleaseProvidingProxy
CSXPCConnectionDelegate
NSObject
CSUserIdentityClassifier
AVVC
CSActivationXPCClient
CSAttSiriRequestContext
NSSecureCoding
NSCoding
CSAudioSampleRateConverter
CSSpeakerRecognitionAssetMetaUpdateMonitor
CSXPCClientFactory
CSVolumeMonitor
CSFallbackAudioSessionReleaseProvider
CSAudioRecorderDelegate
CSFallbackAudioSessionReleaseProviding
CSSpeakerRecognitionAssetDownloadMonitor
CSTrialAssetDownloadMonitorDelegate
CSServerEndpointFeatures
CSVoiceTriggerXPCServiceProxy
CSAttSiriAudioSessionStateClient
AFNotifyObserverDelegate
CSAudioStreamProvidingProxy
CSAudioStreamProvidingDelegate
CSFlexKeywordResult
CSFlexKeywordSpotter
_EARSpeechRecognitionResultStream
CSAttSiriAudioDataReceiver
CSAttSiriAttendingAudioSrcNode
CSAttSiriNode
CSAudioFileLog
CSAudioSessionInfoProvider
CSAudioSessionInfoProviding
CSStateMachine
CSPreMyriadVoiceTriggerMetaData
CSPreMyriadCoordinator
CSVoiceTriggerDelegate
CSSecondPassProgressDelegate
CSBenchmarkXPCProtocol
AttSiri
CSAttSiriCachedEndpointInfo
CSAttSiriEndpointerNodeDelegate
CSAttSiriEndpointerNode
CSEndpointAnalyzerDelegate
CSAttSiriOSDNodeDelegate
CSEndpointerXPCService
CSAudioInjectionFileOption
CSSmartSiriVolumeEnablePolicy
CSAttSiriSSRNodeDelegate
CSAttSiriSSRNode
SSRSpeakerRecognitionControllerDelegate
CSSSRXPCService
CSSiriRestrictionOnLockScreenMonitor
MCProfileConnectionObserver
AudioInjectionXPCProtocol
CSPostBuildInstallService
CSAssetControllerFactory
CSVoiceTriggerDataCollector
CSKeywordAnalyzerQuasar
CSVoiceTriggerAssetHandlerMac
CSVoiceTriggerAssetDownloadMonitorDelegate
CSFirstUnlockMonitorDelegate
CSLanguageCodeUpdateMonitorDelegate
CSAttSiriAttendingTriggerEventInfo
CSAudioStartStreamOption
NSCopying
CSVTSecondPassPhraseScore
CSVTSecondPassScorer
CSCoreSpeechServices
CSVoiceTriggerAssetChangeMonitor
CSAudioServerCrashMonitor
CSAudioServerCrashEventProvidingDelegate
CSXPCClient
CSAudioSessionProviding
CSAudioStreamProviding
CSAudioAlertProviding
CSAudioMeterProviding
CSAudioMetricProviding
CSAudioTimeConversionProviding
CSTriggerInfoProviding
CSOpportuneSpeakListnerTestService
CSOpportuneSpeakListenerDelegate
CSTimerMonitor
CSSiriAudioSession
CSSiriAudioRoute
CSOpportuneSpeakEventMonitor
CSOpportuneSpeakBehaviorMonitorDelegate
CSAttSiriMitigationAssetHandler
CSVoiceTriggerAssetHandlerDelegate
CSPhraseSpotterEnabledMonitor
CSVoiceTriggerAssetHandler
CSMyriadNotifier
CSBenchmarkXPCListener
NSXPCListenerDelegate
Liminal
CSLanguageCodeUpdateMonitorImpl
CSMyriadPHash
SignalEstimate
CSVoiceTriggerXPCListener
CSVoiceTriggerXPCConnectionDelegate
CSCoreSpeechServicesListener
CSCoreSpeechServiceListenerDelegate
CSAudioStreamHolding
CSEndpointDelayReporter
SmartSiriVolume
CSAudioInjectionXPCListener
CSVoiceTriggerRTModel
CSAudioProvider
CSAudioServerCrashMonitorDelegate
CSAudioPreprocessorDelegate
CSSiriDebugConnection
CSAssetDownloadingOption
Directory
CSPowerAssertionMac
CSVoiceTriggerFirstPassHearstAP
CSOpportuneSpeakEventMonitorDelegate
CSVoiceTriggerEnabledPolicyNonAOP
CSNNVADEndpointAnalyzer
CSEndpointAnalyzerImpl
CSEndpointAnalyzer
CSBiometricMatchMonitor
CSSpeechDetectionDevicePresentMonitor
CSKeywordAnalyzerNDAPIResult
CSKeywordAnalyzerNDAPI
RTModel
CSDefaultAudioRouteChangeMonitorMac
CSGestureMonitor
CSAudioRouteChangeMonitorImpl
debugDescription
remoteVoiceActivityVADBuffer
CSAudioRecorder
AVVoiceControllerRecordDelegate
CSAudioDecoderDelegate
CSAudioFileReaderDelegate
CSRemoteRecordClientDelegate
CSAudioServerCrashEventProviding
CSAudioSessionEventProviding
CSAudioTandemStream
CSOpportuneSpeakListener
CSSPGEndpointAnalyzerDelegate
XPCObject
CSSiriEnabledMonitor
CSBluetoothManager
CSJarvisTriggerModeMonitor
CSActivationXPCListener
CSActivateXPCConnectionDelegate
CSModelBenchmarker
CSAudioInjectionEngineDelegate
CSRemoteDeviceProtocolInfo
AudioHardware
Trial
CSAudioSessionInfoProvidingProxy
CSAudioSessionInfoProvidingDelegate
CSSmartSiriVolumeService
CSSmartSiriVolumeServiceDelegate
CSAssetController
CSEventMonitorDelegate
Utils
CSHybridEndpointAnalyzer
CSAssetManagerDelegate
OSDAnalyzerDelegate
8!!!B
RecordContext
CSAdBlockerAssetDecoderV3
CSAudioInjectionXPC
CSNovDetectorResult
CSNovDetector
CSActivationEventNotificationHandler
CSSmartSiriVolume
CSMediaPlayingMonitorDelegate
CSSiriEnabledMonitorDelegate
CSSiriClientBehaviorMonitorDelegate
CSSmartSiriVolumeProcessor
isPluginContext
CSAudioInjectionProvider
CSAttSiriStateMonitor
Compression
CSRemoteXPCVoiceTriggerEnabledPolicy
CSListeningEnabledPolicyWatch
CSOtherAppRecordingStateMonitor
CSHostPowerSourceMonitor
LanguageCode
CSAutomaticVolumeEnabledMonitor
CSAudioFileReader
CSEndpointerProxy
CSEndpointAnalyzerImplDelegate
CSAttSiriOSDNode
CSEndpointerAssetManagerDelegate
CSAttSiriSignalDataAggregatorProtocol
RMSSample
CSShadowMicScoreCreator
CSMyriadSelfTriggerCoordinator
CSSelfTriggerDetectorDelegate
CSEndpointerAssetManager
CSAudioInjectionBuiltInEngine
CSSpringboardStartMonitor
SpeakerRecognition
CSActivationEventNotifier
CSMacWakeSleepMonitor
CSAlarmMonitor
CSSmartSiriVolumeServiceProxy
CSAttSiriAudioSrcNode
CSFirstUnlockMonitor
CSVoiceTriggerEventInfoProvider
CSAudioRecordDeviceInfo
CSCommandControlBehaviorMonitor
CSSiriLauncher
CSAudioProcessWaitingBuffer
CSAttSiriAsrNode
CoreEmbeddedSpeechRecognizerDelegate
LBLocalSpeechService
CSAttSiriTimer
CSAudioStream
CSVoiceTriggerAssetMetaUpdateMonitor
CSOpportuneSpeakListenerOption
CSAudioPreprocessor
CSVoiceTriggerAwareZeroFilterDelegate
CSBeepCancellerDelegate
CSAccessorySiriClientBehaviorMonitor
CSAudioRouteChangeMonitorImplWatch
CSSpeechEndpointAssetMetaUpdateMonitor
CSAlwaysDisabledPolicy
CSScreenLockMonitor
CSVoiceIdXPCConnection
CSAssetManagerEnablePolicy
CSXPCListener
CSDarkWakePowerAssertionMac
Indexing
CSHybridEndpointer
!2!B
CSVoiceTriggerStatAggregator
CSAssetManagerEnablePolicyFactory
CSRawAudioInjectionProvider
CSAudioInjectionTvRemoteEngine
CSAudioConverterDelegate
CSVoiceTriggerEnabledMonitor
CSMSNExceptionManager
CSSmartSiriVolumeEstimate
CSAlwaysOnProcessorStateMonitor
CSAttSiriAFTMNodeDelegate
CSAttSiriAFTMNode
SLProgressiveCheckerAnalyzerDelegate
CSAttSiriMotionNode
NSXPC
CSAudioTimeConversionProvidingProxy
CSSuddenTerminationProtector
CSP2PService
CSAudioRecorderFactory
CoreSpeechXPCProtocol
CSAttSiriController
CSAttSiriFlexKwdNodeDelegate
CSAttSiriServiceDelegate
CSAttSiriServiceProtocol
CSAssetManager
CSVoiceTriggerAssetMetaUpdateMonitorDelegate
CSSpeechEndpointAssetMetaUpdateMonitorDelegate
CSAdBlockerMetaUpdateMonitorDelegate
CSAssetControllerDelegate
CSSpeakerRecognitionAssetMetaUpdateMonitorDelegate
AudioDevice
CSVoiceTriggerAwareZeroFilter
CSSPGEndpointAnalyzer
CSVoiceTriggerEventsCoordinator
CSAudioMetricProvidingProxy
CSActivationXPCConnection
CSBluetoothDeviceInfo
CSSiriClientBehaviorMonitor
CSLanguageCodeUpdateMonitor
CSAttSiriNLDAClassifierDelegate
CSAttSiriNLDAClassifierNode
CSAudioInjectionHearstEngine
CSAVVCRecordingClientMonitor
CSEventMonitor
CSActivationEvent
CSAudioStreamRequest
CSVoiceTriggerAssetDownloadMonitor
FlexKwd
CSAudioSessionMonitor
CSAudioSessionEventProvidingDelegate
CSSmartSiriVolumeUserIntent
CSGestureDropEvent
CSAudioInjectionDevice
CSEndpointerMetrics
CSOpportuneSpeakListenerDeviceManager
CSSmartSiriVolumeManager
CSAlarmMonitorDelegate
CSTimerMonitorDelegate
CSVolumeMonitorDelegate
CSAutomaticVolumeEnabledMonitorDelegate
CSContinuousAudioFingerprintProvider
CSAttSiriUresNodeDelegate
CSAttSiriUresNode
CSAttSiriAttentionNodeDelegate
CSBluetoothWirelessSplitterInfo
CSAdBlockerAssetDownloadMonitor
CSVoiceIdXPCListener
CSSpeechManager
CSActivationEventNotificationHandlerDelegate
CSAudioProviderDelegate
CSVoiceIdXPCClient
CSAudioZeroCounter
CSOpportuneSpeakBehaviorMonitor
CSAttSiriAttentionNode
Statistics
CSXPCConnection
CSEndpointerXPCServiceDelegate
LBLocalSpeechServiceDelegate
CSSSRXPCServiceDelegate
CSAttSiriConnectionManager
CSHostDaemon
CSEndpointLoggingHelper
CSEndpointLatencyInfo
AudioFile
CSCoreSpeechDaemonStateMonitor
CSBuiltinSpeakerStateMonitor
CSRemoteRecordClient
CSConnectionListener
CSConnectionServiceDelegate
CSCoreSpeechDKeepAliveHandler
CSSiriAssertionMonitor
CSAudioSessionProvidingProxy
CSAudioSessionProvidingDelegate
CSBluetoothWirelessSplitterMonitor
CSUserSessionActiveMonitor
CSAudioInjectionRemoraEngine
CSAsset
CSCommandControlStreamEventMonitor
CSCommandControlBehaviorMonitorDelegate
CSTrialAssetManager
CSAudioAlertProvidingProxy
CSAudioAlertProvidingDelegate
CSAVCallConnectedMonitor
CSVoiceTriggerXPCConnection
CSAttSiriFlexKwdNode
CSFlexKeywordSpotterDelegate
CSVoiceProfileRetrainManager
Bitset
CSAudioRouteChangeMonitor
CSAlertBehaviorPredictor
CSAudioDeviceInfo
CSManualDuckingHandler
machXPC
CSAudioInjectionEngineFactory
CSAdBlockerAssetMetaUpdateMonitor
CSAdBlockerAssetDecoderFactory
CSAdBlockerAssetDecoderV2
CSAudioInjectionEngine
CSSoftwareUpdateCheckingMonitor
CSPhoneCallStateMonitor
CSAudioConverter
CSMediaPlayingMonitor
CSAdBlockerAssetDecoderV1
CSBatteryMonitor
CSVoiceTriggerAOPModeEnabledPolicyIOS
CSAudioRecordDeviceIndicator
CSTrialAssetDownloadMonitor
CSAVVoiceTriggerClientManager
CSVoiceTriggerAOPModeEnabledPolicyFactory
CSNetworkAvailabilityMonitor
CSAudioMeterProvidingProxy
@16@0:8
v20@0:8B16
v32@0:8Q16@24
v24@0:8@16
v16@0:8
@"NSObject<OS_dispatch_queue>"
v32@0:8@16@?24
v48@0:8@16@24B32B36@?40
v36@0:8@16B24@?28
v40@0:8@16@24@?32
v32@0:8@"NSString"16@?<v@?@"NSString">24
v48@0:8@"NSString"16@"NSString"24B32B36@?<v@?@"NSDictionary"@"NSError">40
v32@0:8@"NSURL"16@?<v@?@"NSError">24
v36@0:8@"NSString"16B24@?<v@?@"NSDictionary"@"NSError">28
v40@0:8@"NSDictionary"16@"NSString"24@?<v@?@"NSDictionary"@"NSError">32
@24@0:8@16
@24@0:8@?16
v56@0:8@16@24@32@40@?48
v60@0:8@16@24@32B40@44@?52
v52@0:8@16@24B32@36@?44
@"NSXPCConnection"
@40@0:8@16@24B32B36
v36@0:8@16C24@28
d24@0:8@16
d16@0:8
v24@0:8d16
Q16@0:8
v24@0:8Q16
@"NSMutableArray"
@"NSArray"
@"_EARSyncSpeechRecognizer"
@"NSDictionary"
@28@0:8@16B24
f16@0:8
v20@0:8f16
B16@0:8
@32@0:8r^s16q24
@32@0:8^v16q24
@"NSMutableData"
@"<CSKeywordAnalyzerNDEAPIScoreDelegate>"
B24@0:8@16
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
v40@0:8@16@24@32
v40@0:8@"NSObject<OS_xpc_object>"16@"NSObject<OS_xpc_object>"24@"NSObject<OS_xpc_object>"32
v40@0:8@"CSXPCConnection"16@"NSObject<OS_xpc_object>"24@"NSObject<OS_xpc_object>"32
v44@0:8@16@24B32@36
@"CSXPCConnection"
Q40@0:8@16@24@32
@24@0:8Q16
q24@0:8q16
@"NSObject<OS_xpc_object>"
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
@24@0:8^{_NSZone=}16
@96@0:8{AudioStreamBasicDescription=dIIIIIIII}16{AudioStreamBasicDescription=dIIIIIIII}56
^{OpaqueAudioConverter=}96@0:8{AudioStreamBasicDescription=dIIIIIIII}16{AudioStreamBasicDescription=dIIIIIIII}56
^{OpaqueAudioConverter=}
{AudioStreamBasicDescription="mSampleRate"d"mFormatID"I"mFormatFlags"I"mBytesPerPacket"I"mFramesPerPacket"I"mBytesPerFrame"I"mChannelsPerFrame"I"mBitsPerChannel"I"mReserved"I}
r*16@0:8
v24@0:8@?16
v68@0:8@16Q24@32@40Q48Q56i64
v40@0:8@16Q24@32
v44@0:8@16Q24B32@36
v40@0:8@16Q24q32
v32@0:8@16q24
v40@0:8@16q24@32
v32@0:8@16@24
v28@0:8@16B24
v68@0:8@"CSAudioRecorder"16Q24@"NSData"32@"NSData"40Q48Q56i64
v40@0:8@"CSAudioRecorder"16Q24@"CSAudioChunkForTV"32
v44@0:8@"CSAudioRecorder"16Q24B32@"NSError"36
v40@0:8@"CSAudioRecorder"16Q24q32
v32@0:8@"CSAudioRecorder"16q24
v40@0:8@"CSAudioRecorder"16q24@"NSError"32
v24@0:8@"CSAudioRecorder"16
v32@0:8@"CSAudioRecorder"16@"NSDictionary"24
v28@0:8@"CSAudioRecorder"16B24
v24@0:8@"NSDictionary"16
v32@0:8@"CSAudioRecorder"16@"NSError"24
B32@0:8Q16^@24
@"CSAudioRecorder"
v36@0:8@16B24Q28
@"CSTrialAssetDownloadMonitor"
@72@0:8q16q24d32@40d48@56q64
@64@0:8q16q24d32@40d48@56
q16@0:8
v24@0:8q16
@"NSString"
v36@0:8B16@20d28
v28@0:8B16d20
@"NSMutableSet"
@"NSHashTable"
@"CSSiriAssertionMonitor"
v28@0:8@16i24
v40@0:8@16Q24Q32
v28@0:8@"AFNotifyObserver"16i24
v40@0:8@"AFNotifyObserver"16Q24Q32
v32@0:8Q16Q24
@"<CSAttSiriSessionStateDelegate>"
@"AFNotifyObserver"
v32@0:8@"<CSAudioStreamProviding>"16q24
v32@0:8@"<CSAudioStreamProviding>"16@"CSAudioChunk"24
v32@0:8@"<CSAudioStreamProviding>"16@"CSAudioChunkForTV"24
@"<CSAudioStreamProviding>"
@"<CSTriggerInfoProviding>"
@"CSAudioStream"
@"CSAudioRecordContext"
@44@0:8@16f24q28q36
v48@0:8@16@24@32@40
v32@0:8@16d24
v72@0:8@16q24q32d40@48d56q64
v32@0:8@"_EARSpeechRecognizer"16@"_EARSpeechRecognitionResult"24
v32@0:8@"_EARSpeechRecognizer"16@"NSError"24
v32@0:8@"_EARSpeechRecognizer"16@"NSArray"24
v48@0:8@"_EARSpeechRecognizer"16@"NSArray"24@"NSArray"32@"NSArray"40
v32@0:8@"_EARSpeechRecognizer"16@"_EARSpeechRecognitionResultPackage"24
v32@0:8@"_EARSpeechRecognizer"16d24
v32@0:8@"_EARSpeechRecognizer"16@"_EARSpeechRecognition"24
v72@0:8@"_EARSpeechRecognizer"16q24q32d40@"NSArray"48d56q64
@"<CSFlexKeywordSpotterDelegate>"
@"_EARSpeechRecognizer"
@"_EARSpeechRecognitionAudioBuffer"
@"CSAsset"
v36@0:8@16B24@28
v36@0:8@"<CSAttSiriNode>"16B24@"NSError"28
v32@0:8@"<CSAttSiriNode>"16@"CSAudioChunk"24
v24@0:8@"<CSAttSiriNode>"16
@24@0:8@"CSAttSiriController"16
@"CSAttSiriController"16@0:8
v24@0:8@"CSAttSiriController"16
@"NSArray"16@0:8
v24@0:8@"NSString"16
@"CSAsset"16@0:8
v24@0:8@"CSAsset"16
@40@0:8@16@24@32
@48@0:8@16@24@32@40
v28@0:8B16@20
@"CSAttSiriController"
@"CSSpeechManager"
@32@0:8@16@24
^{OpaqueExtAudioFile=}
@"NSURL"
I24@0:8@16
v24@0:8@"<CSAudioSessionInfoProvidingDelegate>"16
I24@0:8@"NSString"16
@24@0:8q16
v40@0:8q16q24q32
v32@0:8q16q24
@"<CSStateMachineDelegate>"
@"NSMutableDictionary"
v60@0:8@16@24Q32@40B48@?52
v32@0:8@"NSDictionary"16@"NSString"24
v40@0:8@"NSDictionary"16@"NSString"24@?<v@?>32
v24@0:8@"NSData"16
v60@0:8@"NSDictionary"16@"NSData"24Q32@"NSString"40B48@?<v@?>52
v40@0:8Q16@24d32
v40@0:8Q16@"NSString"24d32
v32@0:8Q16@"NSString"24
@?16@0:8
@"<CSVoiceTriggerDelegate>"
@"<CSSecondPassProgressProviding>"
@"CSPreMyriadVoiceTriggerMetaData"
v48@0:8@16@24@32@?40
v48@0:8@"NSString"16@"NSString"24@"NSURL"32@?<v@?@"NSString">40
v40@0:8@"NSString"16@"NSURL"24@?<v@?@"NSString">32
@"CSEndpointerMetrics"
v40@0:8@16d24@32
v40@0:8@"<CSAttSiriNode>"16d24@"CSEndpointerMetrics"32
v32@0:8@"<CSAttSiriNode>"16d24
v32@0:8@"<CSEndpointAnalyzer>"16d24
v40@0:8@"<CSEndpointAnalyzer>"16d24@"CSEndpointerMetrics"32
v40@0:8@16@24d32
v48@0:8@16@24Q32Q40
v44@0:8@16Q24Q32B40
v40@0:8@"<CSAttSiriNode>"16@"OSDFeatures"24d32
v48@0:8@"<CSAttSiriNode>"16@"NSDate"24Q32Q40
v44@0:8@"<CSAttSiriNode>"16Q24Q32B40
v72@0:8q16q24d32@40d48@56q64
v32@0:8d16@?24
v72@0:8q16q24d32@"NSArray"40d48@"NSString"56q64
v24@0:8@?<v@?@"NSError"@"NSString">16
v32@0:8d16@?<v@?B@"NSArray">24
v24@0:8@?<v@?@"NSError"d>16
v24@0:8@?<v@?@"NSError"Q>16
v48@0:8Q16@24@32@40
v76@0:8q16q24d32@40d48@56q64B72
v32@0:8d16@24
@"CSConnectionListener"
@"CSEndpointerProxy"
@"CSEndpointLatencyInfo"
@"CSAttSiriCachedEndpointInfo"
@68@0:8@16f24{AudioStreamBasicDescription=dIIIIIIII}28
{AudioStreamBasicDescription=dIIIIIIII}16@0:8
v56@0:8{AudioStreamBasicDescription=dIIIIIIII}16
^{OpaqueExtAudioFile=}16@0:8
v24@0:8^{OpaqueExtAudioFile=}16
v32@0:8@"<CSAttSiriNode>"16@"NSDictionary"24
v32@0:8@"SSRSpeakerRecognitionController"16@"NSDictionary"24
@"SSRSpeakerRecognitionController"
@"SSRVoiceProfileManager"
@"SSRVoiceProfile"
@"<CSAudioFileWriter>"
v32@0:8@"MCProfileConnection"16@"NSDictionary"24
v56@0:8q16@24@32@40@?48
v44@0:8@16@24f32@?36
v56@0:8q16@"NSString"24@"NSString"32@"NSString"40@?<v@?B@"NSError"@"NSUUID">48
v44@0:8@"NSURL"16@"NSUUID"24f32@?<v@?B@"NSError"QQ>36
v32@0:8@"NSUUID"16@?<v@?B@"NSError">24
v24@0:8@?<v@?B@"NSError"@"NSUUID">16
@36@0:8@16@24B32
v28@0:8r^s16i24
@"<CSKeywordAnalyzerQuasarScoreDelegate>"
v28@0:8@"CSFirstUnlockMonitor"16B24
v32@0:8@16@"NSString"24
@64@0:8@16@24@32@40@48@56
@"CSVoiceTriggerAssetDownloadMonitor"
@"CSLanguageCodeUpdateMonitor"
@"CSFirstUnlockMonitor"
@"CSAssetManager"
@"CSTrialAssetManager"
@"CSAttSiriRequestContext"
I16@0:8
v20@0:8I16
B20@0:8B16
f20@0:8B16
@20@0:8B16
@"CSKeywordAnalyzerNDAPIResult"
@32@0:8@16Q24
@"CSVTSecondPassPhraseScore"
v64@0:8Q16Q24q32@40@48@?56
v72@0:8Q16Q24q32@40@48@56@?64
v56@0:8Q16Q24@32@40@?48
@"<CSVoiceTriggerAssetChangeDelegate>"
v32@0:8@16Q24
B24@0:8^@16
B48@0:8Q16Q24@32^@40
v24@0:8@"<CSAudioSessionProvidingDelegate>"16
B48@0:8Q16Q24@"NSString"32^@40
B32@0:8@16^@24
@40@0:8@16@24^@32
B40@0:8@16@24^@32
@32@0:8Q16Q24
@40@0:8Q16Q24Q32
v40@0:8Q16Q24@32
@32@0:8@16d24
v28@0:8B16Q20
B32@0:8@"CSAudioRecordContext"16^@24
@"CSAudioStream"40@0:8@"CSAudioStreamRequest"16@"NSString"24^@32
v40@0:8@"CSAudioStreamRequest"16@"NSString"24@?<v@?@"CSAudioStream"@"NSError">32
v40@0:8@"CSAudioStream"16@"CSAudioStream"24@?<v@?B@"NSError">32
B40@0:8@"CSAudioStream"16@"CSAudioStreamRequest"24^@32
v40@0:8@"CSAudioStream"16@"CSAudioStreamRequest"24@?<v@?B@"NSError">32
v40@0:8@"CSAudioStream"16@"CSAudioStartStreamOption"24@?<v@?B@"NSError">32
v40@0:8@"CSAudioStream"16@"CSAudioStopStreamOption"24@?<v@?B@"NSError">32
@"CSAudioChunk"32@0:8Q16Q24
@"CSAudioChunk"40@0:8Q16Q24Q32
@"CSAudioChunk"24@0:8Q16
v40@0:8Q16Q24@"NSURL"32
v32@0:8Q16@"NSURL"24
@"CSAudioStreamHolding"32@0:8@"NSString"16d24
v24@0:8@"CSAudioStreamHolding"16
@"CSAudioRecordDeviceInfo"16@0:8
@"CSAudioDeviceInfo"16@0:8
@"NSDictionary"16@0:8
B32@0:8@16q24
B24@0:8q16
v24@0:8@"<CSAudioAlertProvidingDelegate>"16
B32@0:8@"NSURL"16q24
f24@0:8Q16
Q24@0:8Q16
v32@0:8@"CSAudioRecordContext"16@?<v@?@"NSDictionary"@"NSDictionary">24
B40@0:8@16Q24^@32
@"<CSAudioSessionProvidingDelegate>"
@"<CSAudioStreamProvidingDelegate>"
@"<CSAudioAlertProvidingDelegate>"
@"<CSXPCClientDelegate>"
v32@0:8@16B24f28
v28@0:8@"CSOpportuneSpeakListener"16B24
v32@0:8@"CSOpportuneSpeakListener"16B24f28
@"CSOpportuneSpeakListener"
@"CSSiriAudioRoute"
@20@0:8I16
v52@0:8@16@24@32B40@44
v48@0:8@"CSOpportuneSpeakBehaviorMonitor"16@"CSAudioRecordContext"24@"NSString"32@"CSAudioStartStreamOption"40
v52@0:8@"CSOpportuneSpeakBehaviorMonitor"16@"CSAudioRecordContext"24@"NSString"32B40@"CSAudioStartStreamOption"44
v32@0:8@"CSOpportuneSpeakBehaviorMonitor"16@"CSAudioStopStreamOption"24
@"NSUUID"
v40@0:8@"CSVoiceTriggerAssetHandler"16@"NSString"24@"CSAsset"32
B32@0:8@16@24
B32@0:8@"NSXPCListener"16@"NSXPCConnection"24
@"NSXPCListener"
@"CSModelBenchmarker"
Q24@0:8@16
@28@0:8Q16B24
S28@0:8^f16i24
s16@0:8
v20@0:8s16
C16@0:8
v20@0:8C16
v40@0:8@"CSVoiceTriggerXPCConnection"16@"NSObject<OS_xpc_object>"24@"NSObject<OS_xpc_object>"32
Vv24@0:8@?16
Vv32@0:8@16@?24
Vv40@0:8@16q24@?32
Vv24@0:8@?<v@?@"NSString">16
Vv32@0:8@"NSString"16@?<v@?@"NSString">24
Vv40@0:8@"NSArray"16q24@?<v@?@"NSError">32
Vv24@0:8@?<v@?Q>16
Vv24@0:8@?<v@?>16
Vv24@0:8@?<v@?B>16
Vv24@0:8@?<v@?q>16
@"CSGibraltarVoiceTriggerHandler"
i16@0:8
@"CSAudioInjectionXPC"
@"NSData"
v24@0:8@"CSAudioServerCrashMonitor"16
v52@0:8@16@24Q32Q40i48
v52@0:8@"CSAudioPreprocessor"16@"NSData"24Q32Q40i48
@48@0:8Q16q24@32@40
B32@0:8Q16q24
@"<CSAudioProviderDelegate>"
@"CSAudioCircularBuffer"
@"CSAudioPreprocessor"
@"CSOSTransaction"
@"NSObject<OS_dispatch_group>"
@"NSObject<OS_dispatch_source>"
@"CSAudioTimeConverter"
@"CSAudioRecordDeviceIndicator"
@"CSMicUsageReporter"
@"CSADPPreventStandbyAssertion"
v36@0:8@16@24f32
v40@0:8@16@24Q32
@48@0:8@16@24@32^@40
@24@0:8d16
v28@0:8@"CSOpportuneSpeakEventMonitor"16B24
v36@0:8Q16Q24B32
v32@0:8Q16@"CSAudioRecordContext"24
v24@0:8@"CSAudioChunk"16
@"<CSEndpointAnalyzerDelegate>"16@0:8
v24@0:8@"<CSEndpointAnalyzerDelegate>"16
@"<CSEndpointAnalyzerImplDelegate>"16@0:8
v24@0:8@"<CSEndpointAnalyzerImplDelegate>"16
v24@0:8@"CSServerEndpointFeatures"16
v32@0:8@"NSString"16@"NSString"24
v32@0:8@"OSDFeatures"16d24
v32@0:8@"NSDate"16Q24
v28@0:8@"CSServerEndpointFeatures"16B24
@"<CSEndpointAnalyzerDelegate>"
@"<CSEndpointAnalyzerImplDelegate>"
B32@0:8^B16^Q24
@"<CSBiometricMatchMonitorDelegate>"
@28@0:8I16@20
@"CSNovDetector"
@"<CSKeywordAnalyzerNDAPIScoreDelegate>"
@48@0:8q16Q24Q32@40
@40@0:8Q16Q24@32
v36@0:8@16i24d28
v36@0:8@16i24@28
v28@0:8@"AVVoiceController"16B24
v36@0:8@"AVVoiceController"16B24@"NSError"28
v32@0:8@"AVVoiceController"16q24
v24@0:8@"AVVoiceController"16
v28@0:8@"AVVoiceController"16i24
v36@0:8@"AVVoiceController"16i24d28
v32@0:8@"AVVoiceController"16@"NSError"24
v36@0:8@"AVVoiceController"16i24@"NSError"28
v40@0:8@"AVVoiceController"16@"AVVCAlertInformation"24@"NSError"32
v32@0:8@"AVVoiceController"16@"NSDictionary"24
v32@0:8@"AVVoiceController"16@"AVVCAudioBuffer"24
v28@0:8B16@"NSArray"20
v44@0:8@"AVVoiceController"16Q24B32@"NSError"36
v40@0:8@"AVVoiceController"16Q24q32
v40@0:8@"AVVoiceController"16Q24@"AVVCAudioBuffer"32
v32@0:8@"AVVoiceController"16Q24
v72@0:8@16Q24@32@40Q48Q56B64I68
v72@0:8@"CSAudioDecoder"16Q24@"NSData"32@"NSData"40Q48Q56B64I68
v40@0:8@"CSAudioFileReader"16@"NSData"24Q32
v36@0:8@"CSAudioFileReader"16B24@"NSError"28
v32@0:8@"CSAudioFileReader"16q24
v32@0:8Q16@"NSError"24
v32@0:8@"NSData"16Q24
v24@0:8@"CSRemoteRecordClient"16
v24@0:8@"<CSAudioServerCrashEventProvidingDelegate>"16
v24@0:8@"<CSAudioSessionEventProvidingDelegate>"16
@32@0:8@16^@24
@24@0:8^@16
@32@0:8Q16@24
B24@0:8Q16
B40@0:8q16Q24^@32
B40@0:8Q16Q24^@32
v28@0:8Q16B24
v60@0:8@16Q24@32Q40Q48i56
@28@0:8@16I24
B32@0:8q16@24
v36@0:8B16Q20@28
v32@0:8q16Q24
@"AVVoiceController"
{AudioBufferList="mNumberBuffers"I"mBuffers"[1{AudioBuffer="mNumberChannels"I"mDataByteSize"I"mData"^v}]}
^{AudioBufferList=I[1{AudioBuffer=II^v}]}
@"CSRemoteRecordClient"
@"CSAudioFileReader"
@"<CSAudioServerCrashEventProvidingDelegate>"
@"<CSAudioSessionEventProvidingDelegate>"
v28@0:8B16@?20
v36@0:8@16d24f32
v20@0:8i16
@"<CSOpportuneSpeakListenerDelegate>"
@"CSSPGEndpointAnalyzer"
@"<CSAudioSessionProviding>"
@"CSPlainAudioFileWriter"
@24@0:8^{BTLocalDeviceImpl=}16
v40@0:8^{BTDeviceImpl=}16I24i28I32i36
v28@0:8^{BTSessionImpl=}16i24
v24@0:8^{BTSessionImpl=}16
v32@0:8^{BTLocalDeviceImpl=}16i24i28
^{BTSessionImpl=}16@0:8
^{BTLocalDeviceImpl=}16@0:8
v24@0:8^{BTLocalDeviceImpl=}16
^{BTSessionImpl=}
^{BTLocalDeviceImpl=}
v40@0:8@"CSActivationXPCConnection"16@"NSObject<OS_xpc_object>"24@"NSObject<OS_xpc_object>"32
v56@0:8@16Q24@32@40Q48
v44@0:8@"CSAudioInjectionEngine"16Q24B32@"NSError"36
v40@0:8@"CSAudioInjectionEngine"16Q24Q32
v56@0:8@"CSAudioInjectionEngine"16Q24@"NSData"32@"NSData"40Q48
v32@0:8@"CSAudioInjectionEngine"16@"CSAudioChunkForTV"24
@"CSSyncKeywordAnalyzerQuasar"
@"EARSyncPSRAudioProcessor"
@"OSDAnalyzer"
@"CSAudioInjectionEngine"
@56@0:8Q16@24@32@40Q48
v32@0:8Q16@?24
v32@0:8@"<CSAudioSessionInfoProviding>"16@"NSDictionary"24
@"<CSAudioSessionInfoProviding>"
v40@0:8Q16@24@?32
v40@0:8Q16@"NSDictionary"24@?<v@?@"NSError"@"CSSmartSiriVolumeEstimate">32
v48@0:8Q16@24Q32@?40
v48@0:8Q16@24@32@?40
v40@0:8@16Q24@?32
v40@0:8@16@?24@?32
@40@0:8@16Q24@32
v32@0:8^@16Q24
v24@0:8@"CSAssetManager"16
v32@0:8@"OSDAnalyzer"16@"OSDFeatures"24
v32@0:8@"OSDAnalyzer"16d24
v72@0:8d16Q24@32d40Q48d56@64
@"OSDFeatures"
@"_EAREndpointer"
@"CSServerEndpointFeatures"
@"NSDate"
@"NSMapTable"
@"CSActivationEvent"
v32@0:8@"CSMediaPlayingMonitor"16q24
v28@0:8@"CSSiriEnabledMonitor"16B24
v52@0:8@16@24B32@36@44
v44@0:8@16B24@28@36
v36@0:8@16@24B32
v40@0:8@"CSSiriClientBehaviorMonitor"16@"CSAudioRecordContext"24@"CSAudioStartStreamOption"32
v52@0:8@"CSSiriClientBehaviorMonitor"16@"CSAudioRecordContext"24B32@"CSAudioStartStreamOption"36@"NSString"44
v40@0:8@"CSSiriClientBehaviorMonitor"16@"CSAudioStopStreamOption"24Q32
v40@0:8@"CSSiriClientBehaviorMonitor"16@"CSAudioStopStreamOption"24@"NSString"32
v44@0:8@"CSSiriClientBehaviorMonitor"16B24@"NSString"28@"CSAudioRecordContext"36
v36@0:8@"CSSiriClientBehaviorMonitor"16@"CSAudioStream"24B32
v24@0:8@"CSSiriClientBehaviorMonitor"16
@28@0:8f16@20
@40@0:8Q16@24Q32
@28@0:8f16@"CSAsset"20
@"CSSmartSiriVolumeEstimate"40@0:8Q16@"NSNumber"24Q32
v28@0:8I16q20
v52@0:8@16q24B32Q36Q44
f24@0:8q16
f24@0:8f16f20
f20@0:8f16
f36@0:8f16f20f24f28f32
f44@0:8f16f20f24f28f32f36f40
f28@0:8f16f20f24
^f24@0:8@16
{unique_ptr<SmartSiriVolume, std::default_delete<SmartSiriVolume>>="__ptr_"{__compressed_pair<SmartSiriVolume *, std::default_delete<SmartSiriVolume>>="__value_"^{SmartSiriVolume}}}
{vector<float, std::allocator<float>>="__begin_"^f"__end_"^f"__end_cap_"{__compressed_pair<float *, std::allocator<float>>="__value_"^f}}
@"NSUserDefaults"
@"CSSmartSiriVolumeEnablePolicy"
@"CSAudioInjectionDevice"
v48@0:8@16@24@32^v40
B24@0:8d16
@"<CSAudioFileReaderDelegate>"
v32@0:8@"<CSEndpointAnalyzerImpl>"16d24
v40@0:8@"<CSEndpointAnalyzerImpl>"16Q24Q32
@"<CSEndpointAnalyzerImpl>"
B32@0:8Q16Q24
@32@0:8d16Q24
q24@0:8@16
d24@0:8[80s]16
v32@0:8@"CSSelfTriggerDetector"16@"NSDictionary"24
@"<CSMyriadSelfTriggerCoordinatorDelegate>"
B44@0:8@16f24@?28@?36
@"<CSAudioInjectionEngineDelegate>"
@"CSKeywordAnalyzerNDEAPI"
@"CSSmartSiriVolumeManager"
v48@0:8@16@24^@32^@40
@44@0:8@16B24@28@36
@52@0:8@16B24@28@36@44
v40@0:8q16Q24@32
v32@0:8@"CoreEmbeddedSpeechRecognizer"16@"CESRModelProperties"24
v32@0:8@"CoreEmbeddedSpeechRecognizer"16@"NSArray"24
v32@0:8@"CoreEmbeddedSpeechRecognizer"16d24
v32@0:8@"CoreEmbeddedSpeechRecognizer"16@"AFSpeechRecognition"24
v32@0:8@"CoreEmbeddedSpeechRecognizer"16@"AFSpeechPackage"24
v40@0:8@"CoreEmbeddedSpeechRecognizer"16@"NSDictionary"24@"NSError"32
v72@0:8@"CoreEmbeddedSpeechRecognizer"16q24q32d40@"NSArray"48d56q64
Vv32@0:8@16Q24
Vv24@0:8@16
Vv24@0:8Q16
Vv32@0:8@"NSString"16Q24
Vv24@0:8@"LBLocalSpeechRecognitionSettings"16
Vv24@0:8@"NSString"16
v36@0:8@16Q24B32
v40@0:8d16@24Q32
v52@0:8@16Q24d32B40@44
v48@0:8@16@24Q32d40
@"CSAttSiriEndpointerNode"
@"CSAttSiriUresNode"
@"CoreEmbeddedSpeechRecognizer"
@"CSAudioProcessWaitingBuffer"
@"LBLocalSpeechRecognitionSettings"
@"CSEndpointDelayReporter"
@"CSAudioStreamRequest"
@"CSAudioStartStreamOption"
v40@0:8@"CSVoiceTriggerAwareZeroFilter"16@"NSData"24Q32
v40@0:8@"CSBeepCanceller"16@"NSData"24Q32
@24@0:8f16i20
v32@0:8f16B20@24
B20@0:8f16
@"<CSAudioPreprocessorDelegate>"
@"CSAudioSampleRateConverter"
@"CSVoiceTriggerAwareZeroFilter"
@"CSBeepCanceller"
@"CSAudioZeroCounter"
v52@0:8@16B24@28@36@44
v48@0:8@16Q24@32@40
v44@0:8B16@20@28@36
v32@0:8i16@20B28
^{__sFILE=*iiss{__sbuf=*i}i^v^?^?^?^?{__sbuf=*i}^{__sFILEX}i[3C][1C]{__sbuf=*i}iq}16@0:8
v24@0:8^{__sFILE=*iiss{__sbuf=*i}i^v^?^?^?^?{__sbuf=*i}^{__sFILEX}i[3C][1C]{__sbuf=*i}iq}16
^{__sFILE=*iiss{__sbuf=*i}i^v^?^?^?^?{__sbuf=*i}^{__sFILEX}i[3C][1C]{__sbuf=*i}iq}
v52@0:8@16@24f32Q36Q44
v52@0:8@"CSAudioConverter"16@"NSArray"24f32Q36Q44
@"CSAudioConverter"
v40@0:8@16B24f28@32
v40@0:8@"<CSAttSiriNode>"16B24f28@"NSString"32
v32@0:8@"SLProgressiveCheckerAnalyzer"16@"SLProgressiveCheckerResult"24
v28@0:8f16Q20
@"SLProgressiveCheckerAnalyzer"
@"SLProgressiveCheckerResult"
v48@0:8@16@24@32Q40
v64@0:8@16@24@32B40Q44@52B60
@"<CSADCompanionServiceProvider>"
v80@0:8Q16Q24q32@40@48@56@64@?72
v64@0:8Q16Q24@32@40@48@?56
v32@0:8@"NSString"16@?<v@?@"NSString"@"NSString"@"NSError">24
v80@0:8Q16Q24q32@"NSString"40@"NSUUID"48@"NSArray"56@"NSArray"64@?<v@?@"CSVoiceTriggerRTModel"@"CSVoiceTriggerRTModel"@"NSError">72
v64@0:8Q16Q24@"NSString"32@"NSArray"40@"NSArray"48@?<v@?@"CSVoiceTriggerRTModel"@"CSVoiceTriggerRTModel"@"NSError">56
v40@0:8@"NSArray"16@"NSString"24@?<v@?@"NSString"@"NSError">32
v32@0:8@"<CSAttSiriNode>"16@"CSAttSiriAttendingTriggerEventInfo"24
v24@0:8@"CSAttSiriAttendingTriggerEventInfo"16
v24@0:8@"CSAttSiriRequestContext"16
@112@0:8@16@24@32@40@48@56B64@68@76@84@92B100B104B108
@"CSAttSiriOSDNode"
@"CSAttSiriAsrNode"
@"CSAttSiriAudioSrcNode"
@"CSAttSiriSSRNode"
@"CSSiriClientBehaviorMonitor"
@"CSSiriEnabledMonitor"
@"CSAttSiriFlexKwdNode"
@"CSAttSiriAFTMNode"
@"CSAttSiriNLDAClassifierNode"
v32@0:8@"CSAssetController"16Q24
v48@0:8Q16Q24@32@?40
@"CSPolicy"
@"CSAssetDownloadingOption"
@"<CSVoiceTriggerAwareZeroFilterDelegate>"
@"CSAudioZeroFilter"
@20@0:8f16
@"<CSSPGEndpointAnalyzerDelegate>"
@"<CSAudioMetricProviding>"
@"<CSActivateXPCConnectionDelegate>"
v36@0:8@16f24@28
v36@0:8@"<CSAttSiriNode>"16f24@"NSDictionary"28
@"SLBertClassifier"
@"CSKeywordAnalyzerNDAPI"
@40@0:8@16@24Q32
@36@0:8@16f24Q28
@52@0:8Q16@24@32f40Q44
@48@0:8Q16@24@32Q40
d20@0:8f16
@40@0:8d16d24d32
@48@0:8q16@24@32@40
B84@0:8@16f24{AudioStreamBasicDescription=dIIIIIIII}28@?68@?76
@64@0:8d16Q24@32q40@48@56
v32@0:8@"CSAlarmMonitor"16q24
v32@0:8@"CSTimerMonitor"16q24
v28@0:8@16f24
v28@0:8@"CSVolumeMonitor"16f24
v28@0:8@"CSAutomaticVolumeEnabledMonitor"16B24
@"<CSConnectionServiceDelegate>"
@"<CSSmartSiriVolumeProcessor>"
v28@0:8@"<CSAttSiriNode>"16f24
v32@0:8@"<CSAttSiriNode>"16Q24
v48@0:8@16Q24@32@?40
@"SLUresMitigator"
@"SLUresMitigatorIpFeats"
v40@0:8@"CSActivationEventNotificationHandler"16@"CSActivationEvent"24@?<v@?B@"NSError">32
v32@0:8@"CSAudioProvider"16Q24
@"CSFallbackAudioSessionReleaseProvider"
@"<CSSpeechManagerDelegate>"
@"CSOpportuneSpeakListnerTestService"
@"CSPostBuildInstallService"
v64@0:8@16@24@32@40@48@?56
@32@0:8@16f24I28
v28@0:8@16I24
B32@0:8@16Q24
@"<CSXPCConnectionDelegate>"
@"CSAudioSessionProvidingProxy"
@"CSFallbackAudioSessionReleaseProvidingProxy"
@"CSAudioSessionInfoProvidingProxy"
@"CSAudioStreamProvidingProxy"
@"CSAudioAlertProvidingProxy"
@"CSAudioMeterProvidingProxy"
@"CSAudioMetricProvidingProxy"
v72@0:8d16d24Q32@40q48@56@64
v32@0:8d16@"CSEndpointerMetrics"24
v72@0:8d16d24Q32@"NSArray"40q48@"NSDictionary"56@"NSDictionary"64
Vv40@0:8@16@24@32
Vv32@0:8@16@24
Vv48@0:8@16Q24@32d40
Vv48@0:8@16Q24B32B36@40
Vv48@0:8@16@24q32@40
Vv40@0:8@"NSString"16@"NSString"24@"NSArray"32
Vv32@0:8@"NSString"16@"AFSpeechPackage"24
Vv48@0:8@"NSString"16Q24@"AFSpeechPackage"32d40
Vv48@0:8@"NSString"16Q24B32B36@"NSArray"40
Vv48@0:8@"NSDictionary"16@"NSString"24q32@"NSError"40
@36@0:8@16B24B28B32
@"CSXPCListener"
@"CSActivationXPCListener"
@"CSVoiceIdXPCListener"
@"CSVoiceTriggerXPCListener"
@"CSAudioInjectionXPCListener"
@"CSAttSiriConnectionManager"
@"CSCoreSpeechServicesListener"
@"CSSpeechModelTrainingXPCManager"
@"CSBenchmarkXPCListener"
v40@0:8Q16Q24Q32
B32@0:8@16@?24
B32@0:8d16^@24
@"<CSRemoteRecordClientDelegate>"
v24@0:8@?<v@?@>16
@"NSXPCInterface"
v24@0:8@"<CSAudioSessionProviding>"16
v32@0:8@"<CSAudioSessionProviding>"16@"NSDictionary"24
v28@0:8@"<CSAudioSessionProviding>"16B24
@"CSManualDuckingHandler"
v40@0:8@"CSCommandControlBehaviorMonitor"16@"CSAudioRecordContext"24@"CSAudioStartStreamOption"32
v44@0:8@"CSCommandControlBehaviorMonitor"16@"CSAudioRecordContext"24B32@"CSAudioStartStreamOption"36
v32@0:8@"CSCommandControlBehaviorMonitor"16@"CSAudioStopStreamOption"24
v40@0:8@"<CSAudioAlertProviding>"16q24@"NSError"32
v36@0:8B16@20@28
@"<CSAudioAlertProviding>"
@"<CSVoiceTriggerXPCConnectionDelegate>"
v24@0:8@"CSFlexKeywordResult"16
@"CSFlexKeywordSpotter"
I24@0:8Q16
@"CSAudioRecordDeviceInfo"
v24@0:8f16f20
v28@0:8I16f20f24
@32@0:8q16Q24
@24@0:8^{AudioBufferList=I[1{AudioBuffer=II^v}]}16
^{OpaqueAudioConverter=}16@0:8
v24@0:8^{OpaqueAudioConverter=}16
^{AudioBufferList=I[1{AudioBuffer=II^v}]}16@0:8
v24@0:8^{AudioBufferList=I[1{AudioBuffer=II^v}]}16
@"CSAudioInjectionFileOption"
v44@0:8@16B24Q28Q36
@"<CSAudioConverterDelegate>"
@44@0:8@16@24B32Q36
@"<CSAudioMeterProviding>"
%@ Interrupted
%@ Invalidated
Dealloc-ing
personalizedLMPath=%@ fidesPersonalizedLMPath=%@
Client is 24-hour job
Client is DictationPersonalizationFidesPlugin
Client is PersonalizedLmFidesPlugin
Received an error while accessing %@ service: %@
Invalidating
%s Transcriber trigger token list: %{public}@
%s Initializing Quasar with config: %{public}@
%s Failed initialization in _EARSyncSpeechRecognizer initWithConfiguration
%s ERR: Exception initializing _EARSyncSpeechRecognizer: %{public}s
%s Speech model loading took %{public}.3fms
%s endAudio failed
%s processAudioChunk failed
%s MpVT: phId=%{public}@, tok=%{public}@
%s Res-%lu: 
%s tok=%@
%s Cannot handle unexpected message type : %lld
%s CSFallbackAudioSessionReleaseProvider is nil from CSSpeechManager
%s ERR: topScoringUser is nil from %{public}@
%s ERR: invalid arguments passed %{public}@ %{public}@
%s ERR: Incorrect category %{public}d passed
%s Start Recording Host Time = %{public}llu
%s disconnect activationXPCClient
%s cannot handle event : event = %{public}p
%s ignore unknown types of message 
%s cannot handle error : error = %{public}p
%s Listener connection disconnected
%s connection error: %{public}s
%s Cannot create SampleRateConverter using AudioConverterNew : %{public}d
%s Cannot set Quality property to audioConverter
%s Cannot set Complexity property to audioConverter
%s Audio resampling done : %lu
%s AudioConverter is sad: 0x%{public}xd
%s Start monitoring : SpeakerRecognition Asset meta update
%s Stop monitoring : SpeakerRecognition Asset meta update
%s New Speaker Recognition asset metadata is available
%s Celestial is not available on this platform.
%s notification = %{public}@
%s Cannot deactivateAudioSession since audio recorder doesn't exist
%s Cannot deactivateAudioSession with %{public}@
%s Start monitoring : SpeakerRecognition Asset Download
%s Stop monitoring : SpeakerRecognition Assets Download
%s New SpeakerRecognition Assets is now installed
%s ERR: Delegate received for invalid Trial assetType:%lu
%s ::: %{public}s enable: %{public}d reason: %{public}@ timestamp : %{public}lf
%s Ignoring request to enable/disable voice trigger with nil reason.
%s ::: Asserting that VoiceTrigger should be %{public}@ with reason: %{public}@. Existing assertions (%{public}lu): %{public}@; times: %{public}@ vs %{public}f
%s Ignoring request to enable/disable voice trigger - time order violation.
%s ::: Ignore request as phraseSpotter already %{public}@
%s ::: Asserting that PhraseSpotter should be %{public}@, timeout: %{public}f
%s ::: Timeout!! PhraseSpotter should be NOT bypassed
%s ::: Ignore request as raiseToSpeak already %{public}@
%s ::: Asserting that raiseToSpeak should be %{public}@, timeout: %{public}f
%s ::: Timeout!! raiseToSpeak should be NOT bypassed
%s HandleDisconnect
%s token:%d
%s fromState:%llu, toState:%llu
%s SiriState - isActiveSession:%d
%s SiriState - isActiveRequest:%d
%s SiriState - isListening:%d
%s SiriState - isSpeaking:%d
%s tts Finished:%u
%s Audio steam %{public}@ is still streaming when we get new streamProvider
%s CSAudioStreamProvidingProxy has received xpc disconnection
%s Trying to stop audio stream on CSAudioStreamProvidingProxy
%s Unknown body type : %{public}lld
%s Cannot handle setCurrentContext throught XPC : audioStreamProviding is nil
%s Cannot handle setCurrentContext throught XPC : given context is nil
%s Cannot handle AudioStreamRequest throught XPC : given audioStreamRequest is nil
%s Cannot handle AudioStreamRequest throught XPC : audioStreamProviding is nil
%s Getting audio stream has failed : %{public}@
%s Cannot handle PrepareRequest throught XPC : audioStreamProviding is nil
%s Given audioStreamRequest is nil, use default audioStreamRequest
%s Cannot handle startAudioStream : given audio stream option is nil
%s Cannot handle startAudioStream : audioStream is nil
%s Cannot handle startAudioStream : audioStreamProviding is nil
%s Cannot handle stopAudioStream : audioStreamProviding is nil
%s Cannot handle stopAudioStream : audioStream is nil
%s Fail to parse recordContext
%s Cannot handle IsRecording : audioStreamProviding is nil
%s Cannot handle RecordRoute : audioStreamProviding is nil
%s Cannot handle RecordDeviceInfo : audioStreamProviding is nil
%s Cannot handle AudioDeviceInfo : audioStreamProviding is nil
%s Cannot handle RecordSettings : audioStreamProviding is nil
%s Cannot handle IsNarrowband : audioStreamProviding is nil
%s Cannot handle PlaybackRoute : audioStreamProviding is nil
%s CSAudioStreamProvidingProxy
%s setting allow mixable audio while recording to %{public}@
%s Failed to setAllowMixableAudioWhileRecording : %{public}@
%s Unable to get VT asset for FlexKwd Spotter
%s configPath=%@
%s _thresholdsMap=%@
%s startProcessingSampleCount=%{public}ld, recognizer: %{public}@
%s didFinishRecognition: err=%@
%s FinalResults: %@
%s %@
%s ===PWinningTok=%@, bestScore=%f====
%s Unexpected!
%s Json file doesnt exist at: %{public}@
%s Could not read Json file at: %{public}@, err: %{public}@
%s Failed to parse json at: %{public}@, err: %{public}@
%s Not implemented
%s audioStreamProvider is nil, fetch audioProvider from context
%s attSiriAudioStreamProvider is nil!
%s Failed to start audio data source: %{public}@
%s Unsupported receiver: %@
%s CSAttSiriAttendingAudioSrcNode deallocated
%s Failure disposing audio file %{public}d
%s Audio file already configured, closing first
%s Creating audio file at URL %{public}@
%s Failed creating audio file at url %{public}@ %{public}d
%s Error setting input format %{public}d
%s No audio file to append data
%s Failed writing audio file %{public}d
%s Closing file at URL %{public}@, audio size: %{public}u
%s Couldn't create CoreSpeech log directory at path %{public}@ %{public}@
%s Session Query Failed : %{public}@
%s Mediaserverd/bridgeaudiod crashed
%s Mediaserverd/bridgeaudiod recovered from crash
%s Start monitoring : AudioSessionInterruption
%s Start monitoring : AudioSessionRouteChangeNotification
%s Stop monitoring AudioSession activities
%s Clearing pending homekit accessory voice trigger %{private}@
%s Handling Pending Remora VoiceTrigger Event
%s Time since last pending remora voice trigger %f. Ignoring.
%s Clearing pending built-in voice trigger %{private}@
%s Handling Pending BuiltInVoiceTrigger Event
%s Time since last pending builtin voice trigger %f. Ignoring.
%s client: %lu, deviceId: %{private}@
%s AttSiri logging not enabled
%s Couldn't create Ures slogging directory at path %{public}@ %{public}@
%s Failed to serialize data with err: %{public}@
%s %{public}.2f ms after vtEnd
%s SmartSiriVolume cannot be resumed since Siri is speaking
%s _shouldCleanupVoiceProfile: %lu
%s SSR Assets is nil for %{public}@ - Bailing out
%s Asset Vers (Speaker Recognition): %{public}@
%s Failed to get asset with %{public}@
%s Asset Vers (VT): %{public}@
%s Voice Profiles not present for %{public}@ - Bailing out
%s Setting up SSR controller with {%{public}@, %{public}@, %{public}ldusers, %{public}fsecs}
%s ERR: Failed to create SSR context with error %@
%s ERR: Failed to create SSR controller with error %@
%s Initialized SSRNode with assets %{public}@
%s XPC connection with client established
%s Received SSR asset download notification, updated asset cache to %{public}@
%s UserClassification: %{public}@ UserIdentified: %{public}@ Scores: %{public}@
%s _speakerRecognitionScores:%@
%s ERR: Discarded reporting ScoreCard!!
%s _speakerRecognitionScores is nil!
%s spkrRecognizer is nil!
%s speakerInfo is nil!
%s ERR: Discarded reporting final ScoreCard!!
%s SpeakerIdInfo from incorrect SpeakerRecognizer: expected: %{public}@, spkrRecognizer: %{public}@
%s ERR: Failed to get classified user from %{public}@
%s mappedSpeakerIdInfo:%@
%s Voice Profile for profileID %@ not found
%s ERR: Failed to init retrainCtxt for profileID %{public}@ with error %{public}@
%s ERR: Failed to add profileID %{public}@ with error %{public}@
%s trigger VoiceProfileCleanup
%s ERR: Failed VoiceProfile Cleanup with error %{public}@
%s Start monitoring : Setting preference change
%s Stop monitoring : Setting preference change
%s Siri restricted on lock screen : %{public}@
%s Registering for post build install/first unlock activity - %s
%s Received event for XPC activity: %@ in state: %ld
%s XPC activity: %@ deferred: %@ firstUnlock: %@
%s Registered XPC activity got triggered...
%s VT is disabled, skipping post build activity !
%s Post build install/first unlock tasks got completed with error - %{public}@
%s Registered XPC activity complete. State: %@.
%s runRecognition failed
%s recognizeWavData failed
%s Partial result confidence: %{public}f
%s CTC: Adding tok=%{public}@
%s CTC: Ignoring tok=%{public}@
%s ERROR: %{public}s
%s CTC: Final-tok: %@(%f):%@
%s Final result confidence: %{public}f
%s EAR Token[%{public}lu]: %s (%{public}f)
%s CSVoiceTriggerAsset (%{public}@) found: %{public}@
%s Cannot get a VoiceTrigger mobile asset : %{public}@
%s Trial assets not available, fallback to MA assets
%s Asset Query failed : %{public}@
%s cached asset:%{public}@, new asset:%{public}@
%s New asset is same as cached asset, ignore notification
%s New asset is different from cached one. Updating cached asset
%s new VoiceTrigger asset downloaded
%s Language Code Changed : %{public}@
%s First unlock notification received : %{public}d
%s Ignore Trial asset update for type: %lu
%s MpVT: supportedPhrasesInfo: %@
%s MpVT: ctcResults=%@
%s OldTrigPh: %@, NewTrigPh: %@
%s getCoreSpeechXPCConnection Invalidated
%s making connection to corespeechd with (%{public}d)
%s Asking VoiceTrigger locale to corespeechd
%s Current VoiceTrigger Locale = %{public}@
%s Cannot get Current VoiceTrigger Locale, falling back to en-US : %{public}@
%s Asking current VoiceTrigger aset for %{public}d.%{public}d
%s Asking keyword language given Jarvis language list %{public}@, jarvis-selected language: %{public}@
%s CSCoreSpeechServices Invalidated
%s Request updated SAT audio succeed.
%s Request updated SAT audio failed.
%s Start monitoring : Mediaserverd crash / recover event
%s Initializing new xpcConnection
%s Sending XPCClientType : %{public}d
%s Prepare Audio Provider with Context : %{public}@
%s Failed to get reply result correctly
%s Received alertStartTime = %{public}llu
%s Received peakPower = %{public}f
%s Received averagePower = %{public}f
%s Sending audioMetric request
%s Failed to get audioMetric reply
%s audioMetric : %{public}@
%s Received invalid audioMetric
%s Error creating message
%s audioStreamWithRequest for stream %{public}@
%s xpcConnection not exist
%s Invalid message: stream is nil or request is nil
%s PrepareAudioStream %{public}@
%s Sending AcousticSLResult request
%s Failed to get AcousticSLResult reply
%s Received AcousticSLResult %{public}@
%s Failed to parse AcousticSLResult from raw data
%s Message not valid
%s Sending VoiceTriggerInfo request
%s Failed to get VoiceTriggerInfo request
%s Received VoiceTriggerInfo %{public}@
%s Failed to parse VoiceTriggerInfo from raw data
%s Received rtsTriggerInfo %{public}@
%s Failed to parse rtsTriggerInfo from raw data
%s NO reply!!!
%s No message!!
%s No reply for hostTimeFromSampleCount request with sampleCount %{public}llu
%s xpcConnection not existing
%s No message for hostTimeFromSampleCount request with sampleCount %{public}llu
%s No reply for sampleCountFromHostTime request with hostTime %{public}llu
%s No message for sampleCountFromHostTime request with hostTime %{public}llu
%s Cannot handle nil message
%s Unexpected message type : %{public}lld
%s AlertProvidingDelegate messageType : %{public}lld
%s Unexpected type : %{public}lld
%s SessionProvidingDelegate messageType : %{public}lld
%s context : %{public}@
%s invalid context
%s SessionInfoProvidingDelegate messageType : %{public}lld
%s Received notificationInfo %{public}@
%s Failed to parse notificationInfo from raw data
%s startListenWithOption : %{public}d, %{public}@
%s stopListenWithCompletion : %{public}d, %{public}@
%s hasRemoteVADAvailable : %d
%s hasVADAvailable : %d
%s didStopUnexpectly : %d
%s MobileTimer is not available on this platform.
%s Input route changed
%s Output route changed
%s Failed getting audio property %{public}.4s %{public}d
%s Failed getting audio property size %{public}.4s %d{public}
%s Failed registering for property listener %{public}.4s %{public}d
%s Fetching CommandControl Listening State: %d
%s Updated cache with new Trial asset %@
%s Cache already contains Trial asset, ignore MA asset update
%s Updated cache with new MA asset %@
%s Ignore Trial asset update even for mitigation
%s PhraseSpotter enabled = %{public}@
%s PhraseSpotter is already %{public}@, received duplicated notification!
%s Send a In-Ear Myriad notification
%s CSBenchmarkXPCListener start listening
%s we got unknown types of XPC connection request
%s CSBenchmarkXPCListener here
%s Start monitoring : Siri language code
%s Stop monitoring : Siri language code
%s Siri language changed to : %{public}@
%s Ignore notifying change of language code, since it is nil
%s CSVoiceTriggerXPCListener start listening
%s Received new remote control connection request
%s Connection request is nil
%s Error = %{public}s
%s Getting new client connection : %{public}p
%s Client connection disconnected, removing %{public}p from client connection pool
%s Register CoreSpeech Services
%s Received accept request : %{public}@
%s Connectin request %{public}@ rejected due to missing entitlement
%s get test response. return string Test
%s Setting Delay Interstitial Sound
%s Get Trigger Count
%s Clear Trigger Count
%s Get FirstPass running mode
%s Dealloc audioStreamHolding : %{public}@
%s _requestMHUUID: %@, _turnIdentifier: %@
%s _userSpeakingStartedTimeInMs %{public}f, _userSpeakingEndedTimeInMs: %{public}f, _userSpeakingStartedHostTime: %{public}llu, _userSpeakingEndedHostTime: %{public}llu, _stopRecordingHostTime: %{public}llu, _endpointBufferHostTime: %{public}llu
%s Cannot access to %{public}@ %{public}@ using default value=%{public}@
%s CSAudioInjectionXPCListener start listening
%s CSAudioProvider[%{public}@]:Create circular buffer
%s CSAudioProvider is deallocated
%s CSAudioProvider[%{public}@]:StreamState changed from : %{public}@ to : %{public}@
%s CSAudioProvider[%{public}@]:Setting audioRecorder : %{public}p
%s Reset recordDeviceIndicator as we have new audioRecorder
%s CSAudioProvider[%{public}@]:setCurrentContext : %{public}@
%s CSAudioProvider[%{public}@]:Cannot change context since audio recorder is currently recording
%s CSAudioProvider[%{public}@]:audioStreamWithRequest for stream <%{public}@>
%s Failed to _prepareAudioStreamSync : %{public}@
%s Attached stream %{public}@ as tandem to master stream %{public}@ %{public}@, error : %{public}@
%s PrimaryStream is already tandem of stream %{public}@, can't add mutual tandem relation here!
%s Invalid input streams
%s CSAudioProvider[%{public}@]:Prepare audio stream reuqested while state is %{public}@
%s CSAudioProvider[%{public}@]:Cannot prepare, audio system is recovering
%s CSAudioProvider[%{public}@]:Asking AudioRecorder prepareAudioStreamRecord
%s CSAudioProvider[%{public}@]:prepareAudioStreamRecord failed : %{public}@
%s CSAudioProvider[%{public}@]:Tear down circular buffer
%s CSAudioProvider[%{public}@]:startAudioStream with stream : %{public}@ with stream state : %{public}@, option : %{public}@, streamId : %{public}llu
%s CSAudioProvider[%{public}@]:state was %{public}@, prepareAudioStream first
%s CSAudioProvider[%{public}@]:prepareAudioStreamSync with stream : %{public}@ with stream state : %{public}@, request : %{public}@
%s CSAudioProvider[%{public}@]:prepareAudioStream with stream : %{public}@ with stream state : %{public}@
%s CSAudioProvider[%{public}@]:Cannot handle start audio stream on : %{public}@
%s CSAudioProvider[%{public}@]:Cannot startAudioStream, audio system is recovering
%s CSAudioProvider[%{public}@]:Requested startHostTime = %{public}llu, _clientStartSampleCount = %{public}tu
%s CSAudioProvider[%{public}@]:%{public}@ is requesting earlier audio than asked, we can't deliver earlier audio
%s CSAudioProvider[%{public}@]:Set circularBufferStartHostTime = %{public}llu, circularBufferStartSampleCount = %{public}lu
%s CSAudioProvider[%{public}@]:Entering dispatch group for recordingWillStartGroup
%s CSAudioProvider[%{public}@]:Failed to fetch historical audio since _clientStartSampleCount is newer than audioBuffer sample count(%{public}llu)
%s Start deliver historical audio buffer immediately
%s CSAudioProvider[%{public}@]:Leaving dispatch group for recordingWillStartGroup
%s CSAudioProvider[%{public}@]:Received didStartRecording while %{public}@
%s CSAudioProvider[%{public}@]:Received didStopRecording reason : %{public}d, streamState : %{public}@
%s Calling unexpected didStop for all weak streams
%s CSAudioProvider[%{public}@]:Received didStopRecording while %{public}@
%s CSAudioProvider[%{public}@]:Waiting for recordingWillStartGroup before scheduling stopAudioStream
%s CSAudioProvider[%{public}@]:Scheduled stopAudioStream after waiting for recordingWillStartGroup - stopAudioStream %{public}@ with streamState : %{public}@
%s CSAudioProvider[%{public}@]:requested stop audio stream while stoppingWithScheduledStart, take out audio stream from schedule
%s CSAudioProvider[%{public}@]:Stream %{public}@ is not streaming on stream state : %{public}@, ignore the stopAudioStream request
%s CSAudioProvider[%{public}@]:Cannot handle stop audio stream on : %{public}@
%s CSAudioProvider[%{public}@]:requested stop audio stream while stopping, adding audio stream into stop pending
%s CSAudioProvider[%{public}@]:Stop all recordings, moving stream state to %{public}@
%s CSAudioProvider[%{public}@]:Failed to stop audioStream : %{public}@
%s Saving circular buffer from %{public}lu to %{public}lu
%s CSAudioProvider[%{public}@]:%{public}@ ask for audio hold stream for %{public}f
%s CSAudioProvider[%{public}@]:Timeout for %{public}@ has fired
%s CSAudioProvider[%{public}@]:Removing %{public}@ from stream holders
%s CSAudioProvider[%{public}@]:%{public}@ stream holder was already removed from stream holders
%s CSAudioProvider[%{public}@]:%{public}@ ask for cancel hold stream
%s Failed to prewarmAudioSessionWithError : %{public}@
%s Failed to activateAudioSessionWithReason: %{public}@
%s CSAudioProvider[%{public}@]:Activating Audio Session under : %{public}@
%s Failed to activateAudioSession : %{public}@
%s Failed to deactivate audio session : %{public}@
%s CSAudioProvider[%{public}@]:Deactivating Audio Session under : %{public}@
%s Failed to deactivateAudioSession : %{public}@
%s CSAudioProvider[%{public}@]:AVVC is recovering, ignore command...
%s Not handled by this function
%s Fetching voiceTriggerInfo from audioRecorder
%s CSAudioProvider[%{public}@]:Cannot stopRecording as there are %{public}tu streamHolders
%s CSAudioProvider[%{public}@]:Shouldn't stop AVVC recording as there are %{public}tu streams
%s CSAudioProvider[%{public}@]:
%s CSAudioProvider[%{public}@]:Buffer underrun!!!!, lastForwardedSampleTime:%{public}lu, oldestSampleTimeInBuffer:%{public}lu, stream:%{public}@
%s CSAudioProvider[%{public}@]:Ignore forwarding stream %{public}@                                        the audio packets until sampleCount == %{public}lu (theMostRecentSampleCount:%{public}lu)
%s CSAudioProvider[%{public}@]:Buffer overrun!!! lastForwardedSampleTime:%{public}lu,                                    theMostRecentSampleCount:%{public}lu, stream:%{public}@
%s Forward %d samples from historical audio buffer
%s ScheduleAlertFinishTimeout : %{public}@
%s ScheduleAlertFinishTimeout will be ignored : %{public}@, %{public}@
%s Received finishStartAlertPlaybackAt:%{public}llu streamState : %{public}@
%s CSAudioProvider[%{public}@]:Requested alertFinishHostTime = %{public}llu, _clientStartSampleCount = %{public}tu, circularBufferSampleCount = %{public}tu
%s Audio Streaming already stopped
%s Will invalidate current builtIn audio stream : %{public}@
%s failed to stopAudioStream : %{public}@
%s CSAudioProvider[%{public}@]:Audio Recorder Disconnected
%s CSAudioProvider[%{public}@]:Mediaserverd/bridgeaudiod crashed
%s CSAudioProvider[%{public}@]:Mediaserverd/bridgeaudiod recovered from crash
%s CSAudioProvider[%{public}@]:AudioRecorder will be destroyed
%s CSAudioProvider[%{public}@]:recordingTransaction already released
%s CSAudioProvider[%{public}@]:Release recording transaction at streamState : %{public}@
%s Audio Packet Delivery WatchDog fired, trying to recover
%s Schedule didStart WDT %{public}@ for %{public}lf seconds
%s startRecordingWatchDogDidFire : %{public}@, currentToken : %{public}@
%s startRecordingWatchDogToken doesn't match. Ignore this WDT fire
%s Clearing didStartRecordingDelegate WatchDogTimer : %{public}@
%s Schedule didStop WDT %{public}@ for %{public}lf seconds
%s stopRecordingWatchDogDidFire : %{public}@, currentToken : %{public}@
%s stopRecordingWatchDogToken doesn't match. Ignore this WDT fire
%s Clearing didStopRecordingDelegate WatchDogTimer : %{public}@
%s %@ task delivered.
%s %@ completed with response %@ and error %@.
%s CS logging files under %{public}@ created before %{public}@ will be removed.
%s Couldn't get creation date: %{public}@
%s Could not remove %{public}@: %{public}@
%s CS logging files number %{public}lu with pattern %{public}@ under %{public}@ exceeding limit, only keep the latest %{public}lu ones
%s Regular expression is nil!
%s Directory URL is nil!
%s VoiceTrigger cannot be turned on since SpeechDetectionVAD is not present
%s VoiceTrigger cannot be turned on since voiceTriggerInCoreSpeech is NO
%s VoiceTrigger cannot be turned on since VoiceTrigger is disabled
%s VoiceTrigger cannot be turned on since Siri is disabled
%s VoiceTrigger cannot be turned on since SpringBoard is not started yet
%s VoiceTrigger cannot be turned on since device is not unlocked after restart
%s VoiceTrigger cannot be turned on since device is on battery
%s VoiceTrigger cannot be turned on since Siri is restricted on lock screen
%s VoiceTrigger cannot be turned on since Software Update Checking is running
%s VoiceTrigger cannot be turned on since we are not in a desired call state
%s VoiceTrigger cannot be turned on because we are in a ringtone and hearstState: %d builtInState: %d isInSplitterMode: %d
%s Not supported on this platform
%s NDAPI initialization failed
%s set StartAnalyzeSampleCount = %{public}lld
%s NDAPI config doesn't contain threshold_normal
%s NDAPI config doesn't contain threshold_logging
%s NDAPI config doesn't contain threshold_reject_logging
%s CS doesn't have ndblobbuilder!
%s latestMajorVersion = %d, LatestMinorVersion = %d
%s corespeech.json doesn't contains rtblobs
%s blob file name is not exists
%s blob file is not exists at %{public}@
%s Reading blob from : %{public}@
%s Blob is nil : %{public}@
%s Locale map for %{public}@ is not available on asset
%s Received external route change notification
%s Received CarPlay AuxStream support change notification
%s Received CarPlay connection change notification
%s Start monitoring : AudioRouteChangeMonitor
%s Stop monitoring : AudioRouteChangeMonitor
%s Notifying Hearst Connection State : %{public}d
%s Notifying Jarvis Connection State : %{public}d
%s Failed to create AVVC : %{public}@
%s Create new CSAudioRecorder = %{public}p
%s CSAudioRecorder %{public}p deallocated
%s AVVC initialization failed
%s Successfully create AVVC : %{public}p
%s Setting announced call flag to: %d with stream handle Id: %lu
%s Calling AVVC setContext : %@
%s Failed to get handle id : %{public}@
%s setContext elapsed time = %{public}lf, streamHandleId = %{public}lu, streamType = %{public}lu
%s Calling AVVC setContextForStream : %{public}@
%s Tried to setCurrentContext with mode %ld. This method can only be used for auto and post
%s setCurrentContext elapsed time = %{public}lf
%s Failed to prepare remote device : %{public}@
%s Calling AVVC prepareRecordForStream(%{public}llu) : %{public}@
%s AVVC prepareRecordForStream failed : %{public}@
%s prepareRecordForStream elapsed time = %{public}lf
%s ::: CSAudioRecord will inject audio file instead of recording
%s Resetting AudioFilePathIndex
%s Increase AudioFilePathIndex = %d
%s AudioFilePathIndex is out-of-boundary _audioFilePathIndex:%d injectAudioFilePaths:%d
%s AudioFilePathIndex:%d accessing:%@
%s Unable to find injectAudioFilePath = %@
%s Asking startRecording to remote device with context : %{public}@ (original context : %{public}@)
%s Failed to fetch valid context
%s Failed to startRecording : %{public}@
%s startRecordingWithOptions elapsed time = %{public}lf
%s Calling AVVC startRecordForStream : %{public}@
%s startRecordForStream failed : %{public}@
%s startRecordForStream elapsed time = %{public}lf
%s Failed to stopRecording to remoteRecordClient : %{public}@
%s stopRecording elapsed time = %{public}lf
%s Calling AVVC stopRecordForStream
%s Failed to stopRecordForStream : %{public}@
%s stopRecordForStream elapsed time = %{public}lf
%s Session State = %d
%s AudioSessionState = YES
%s AudioSessionState = NO
%s fetch recordDeviceInfo elapsed time = %{public}lf
%s fetch EndpointDeviceType elapsed time = %{public}lf
%s AVVC sampling rate = %{public}f
%s AVVC doesn't return sampleRate, assume it is default sample rate
%s isNarrowBand = NO for streamHandleId = %{public}lu
%s isNarrowBand = %{public}@ for streamHandleId = %{public}lu
%s Calling AVVC setSessionActive for Prewarm
%s Prewarm AudioSession has failed : %{public}@
%s Calling AVVC setRecordMode to mode : %{public}d
%s AVVC successfully setRecordMode
%s setRecordMode elapsed time = %{public}lf
%s Calling AVVC setSessionActivate for activation with streamId(%{public}lu)
%s AVVC setSessionActivate has failed : %{public}@
%s AVVC successfully activated audioSession
%s setSessionActivate elapsed time = %{public}lf
%s Calling AVVC setSessionActivate for deactivation : %{public}tu
%s Calling AVVC setSessionActivate for deactivation for stream %d: %{public}tu
%s Failed to setIamTheAssistant : %{public}@
%s Creating audio session with allow mixable audio while recording to YES
%s Calling AVVC : Enable Smart Routing Consideration
%s Calling AVVC : Disable Smart Routing Consideration
%s enableSmartRoutingConsiderationForStream elapsed time = %{public}lf
%s Fail to setSmartRoutingConsideration : %{public}@
%s Calling AVVC setDuckOthersForStream(%d) for DuckOthers/MixWithOthers
%s Failed to setDuckOthersForStream : %{public}@
%s setDuckOthersForStream elapsed time = %{public}lf
%s Calling AVVC setDuckOthersForStream(%d) for MixWithOthers
%s Should not call setDuckOthersOptions with NO in B238
%s enableMiniDucking elapsed time = %{public}lf
%s %{public}@
%s configureAlertBehavior elapsed time = %{public}lf
%s VoiceTriggerInfo is nil from AVVC
%s Updated languageCode to: %{public}@ in VTEI received from remote
%s Peak : %f, Avg : %f
%s AVVCAudioBuffer contains %{public}d packet descriptions, size %{public}d, channels %{public}d. Ignoring
%s packets count %{public}d
%s Bad packet length %{public}d. Skipping rest of record buffer.
%s Cannot handle audio buffer : unexpected format(%{public}u)
%s Compensating %{public}u channel(s), heartbeat = %{public}lld
%s Calling AVVC playAlertSoundForType to play alert
%s Ignore playing endpoint beep(record stopped beep) since it already played beep in gibraltar
%s Calling AVVC playAlertSoundsForType : %{public}ld
%s Received didStartRecording : %{public}p, forStream:%{public}llu, successfully:%{public}d, error:%{public}@
%s Received audio buffer %{public}d, heartbeat = %{public}llu, streamID (%{public}lu)
%s Received didStopRecording : %{public}p forStream:%{public}llu forReason:%{public}ld
%s Received Stream Invalidated : %{public}llu
%s toConfiguration : %{public}d
%s type : %{public}d, error : %{public}@
%s Encoder error : %{public}@
%s withContext : %{public}@
%s activate : %{public}d
%s AVVC lost mediaserverd connection
%s AVVC informed mediaserverd reset, no further action required
%s hasLocalPendingTwoShot = %{public}d, token : %{public}llu
%s Unsupported audio format!
%s Existing remoteRecordClient (deviceId = %@) doesn't match required one (deviceId = %@), create new remoteRecordClient
%s The input streamHandleId(%{public}lu) is not expected(%{public}lu)
%s primaryStream already torn down
%s Start Listening request with deviceId : %{public}@
%s CSOpportuneSpeakListener received didStart : %{public}d, %{public}@
%s remoteVADDuration = %{public}d, spgDuration = %{public}d, _remoteVADSPGRatio = %{public}d
%s AudioStreamRequest has failed : %{public}@
%s CSOpportuneSpeakListener received didStop : %{public}d, %{public}@
%s Request stop CSOpportuneSpeakListener
%s Audio coming from DoAP should contains RemoteVAD
%s boronScore : %{public}d, reportBoron : %{public}d, slienceScore : %{public}lf
%s Cannot create NSData with size 0
%s xpc object should be XPC_TYPE_DATA
%s Start monitoring : Siri setting switch, Siri is %{public}@
%s Stop monitoring : Siri setting switch
%s Siri Enabled = %{public}@
%s Trying to access BTLocalDevice
%s Accessing BTLocalDevice
%s BTLocalDevice %{public}p
%s Failed to get sharing enable flag : %d
%s Failed getting sharing device addresses %d
%s Failed converting address from BTDeviceAddress (result = %d).
%s Device is temporary paired and not in contacts
%s Detaching bluetooth session : %{public}p
%s Already Attaching Bluetooth Session
%s Start attaching bluetooth session
%s session = %{public}p, result = %{public}d
%s session = %p
%s detached session is different from currently attached session, ignore
%s terminated session is different from currently attached session, ignore
%s Bluetooth Session is NULL
%s Failed to get default local device from session %{public}p, (result = %{public}d)
%s Failed to add local device callback from session %{public}p, (result = %{public}d
%s CSActivationXPCListener start listening
%s startRecording
%s stopRecording
%s score %f
%s sv %@
%s Audio file read start
%s Audio file read end
%s Unsupported protocol for this device
%s sessionID(for deviceId %{public}@ = %{public}llu
%s Trying to get sessionID when audioSessionInfoProvider is nil
%s SmartSiriVolume not supported on this platform - Bailing out
%s SmartSiriVolume connection started listening
%s _csAssetsDictionary = %{public}@
%s CSAssetController cannot query for nil language
%s ::: found %{public}lu installed assets for assetType=%{public}lu, matching query: %{public}@
%s Error running asset-query for assetType:%{public}lu, query: %{public}@, error: %{public}lu
%s ::: found %{public}lu assets for assetType=%{public}lu, matching query: %{public}@
%s Asset state : %{public}ld
%s ::: %{public}s
%s ::: %{public}s; query: %{public}@
%s Found %{public}lu assets
%s Error running asset query: error %{public}lu, or result is empty
%s ::: Request Fetching RemoteMetaData : assetType : %{public}d
%s Fetching remote meta data failed, scheduled retry after %{public}f seconds
%s ::: Request fetching remote asset
%s ::: found %{public}lu assets for assetType %{public}lu
%s Failed to finish query for assetType %{public}lu with error %{public}lu
%s Meta data downloaded successfully for assetType %{public}lu
%s Failed to download meta data for assetType %{public}lu with error %{public}lu
%s ::: Fetching remote asset
%s ::: Purging installed asset : %{public}@
%s ::: Request downloading remote asset for assetType %{public}lu
%s ::: Start downloading asset
%s ::: download progress: %{public}3.0f%%
%s ::: Error downloading from %{public}@ with error %{public}@
%s ::: download completed successfully from %{public}@.
%s Attempting to download asset %{public}@, asset state : %{public}ld
%s ERR: Unknown AssetType: %{public}lu
%s Device is firstUnlocked. Fetching HEP assets
%s Device is NOT firstUnlocked. Will fetch assets after firstUnlock
%s Failed to get HEP asset
%s HEP Asset: %{public}@, path: %{public}@
%s endpointerModelVersion is still nil after fetching it from EAREndpointer
%s HEP::RecordingDidStop: Ignoring processAudioSamplesAsynchronously: Not queueing
%s first audio buffer host time: %{public}llu
%s HEP::RecordingDidStop: Ignoring processAudioSamplesAsynchronously
%s addAudio first sample offset: %{public}lu
%s Updated endpointer threshold: %{public}f
%s Updated endpointer delayed trigger: %{public}d
%s EARSPG: CSServerEndpointFeatures: %{public}@
%s Accepting RC: RCTime < 0: Server's processedAudioDuration(%{public}f) > _lastReportedEndpointTimeMs(%{public}f): sfLatency: %{public}f, rcTimeMs: %{public}f
%s Rejecting RC: SFLatency < 0: Server's processedAudioDuration(%{public}f): _lastReportedEndpointTimeMs(%{public}f): sfLatency: %{public}f, rcTimeMs: %{public}f
%s rcEpFeatures: %{public}@ shouldAccept: %{public}d
%s HEP::RecordingDidStop: Ignoring silenceScoreEstimateAvailable, Not queuing
%s Detected speech start at %{public}f of effectiveClientProcessedAudioMs
%s HEP::RecordingDidStop: Ignoring silenceScoreEstimateAvailable
%s Already communicated end-pt: Not Invoking hybridClassifier for silposnf=%{public}f
%s ClientLag: serverProcessedAudioMs(%{public}ld) > effectiveClientProcessedAudioMs(%{public}f)
%s ClientLag: Not invoking HybridClassifier: sfLatency > clientLagThreshold: %{public}f > %{public}f
%s ClientLag: Using DefaultServerFeatures with disconnected-state sfLatency: %{public}f
%s ClientLag: Using ServerFeatures with ClampedSFLatency: %{public}f
%s Using ServerFeatures with ClampedSFLatency
%s ClientLag: Not Invoking HybridClassifier as serverProcessedAudioMs > effectiveClientProcessedAudioMs
%s HEP.feats: [%{public}ld,%{public}f,%{public}f,%{public}ld,%{public}f,%{public}f] & [(%{public}@),%{public}f] @ %{public}lu [%{public}f, %{public}d]
%s HEP.posterior=%{public}f, result=1, endpointedBuffer.hostTime=%{public}llu, isAnchorTimeBuffered=%{public}d
%s request timeout with features %{public}@
%s ServerFeaturesLatencyDistribution: %{public}@ additionalMetrics: %{public}@
%s MMEP:: HEP detected at %{public}f but will continue running for MMEP.
%s Already communicated end-pt: Not scheduling work for hybridClassifierQueue for silposnf=%{public}f
%s Log hybrid endpointer features for event: %{public}@, and locale: %{public}@
%s triggerEndSeconds: %{public}f, _vtEndInSampleCount: %{public}lu, _vtExtraAudioAtStartInMs: %{public}lu,  _hepAudioOriginInMs: %{public}f, voiceTriggerInfo: %{public}@,
%s CSHybridEndpointAnalyzer recordingStoppedForReason: %{public}ld
%s sampleRate=%{public}lu, recordContext=%{public}@
%s CSEndpointAsset exists: %{public}@
%s No asset for CSHybridEndpointer for currentLanguage: %{public}@. Fallback to VAD2
%s Created OSDAnalyzer: %{public}@
%s Created HybridClassifier(%{public}@); canProcessCurrentRequest after reset: %{public}d,for sampleRate: %{public}lu, lang=%{public}@, version=%{public}@
%s HEP.logs.hdr: [ServerASR_trailingSilenceDuration,ClientSPG_SilenceFramesCountMs,ServerASR_endOfSentenceLikelihood,ServerASR_wordCount,ServerFeaturesLatency,ClientSPG_SilenceProbabilityHMMFiltered] & [ServerASR_pauseCounts,ServerASR_silencePosterior,ClientSPG_silenceProbailitySPGRaw] @ effectiveClientProcessedAudioMs : [HEPPosteriorOut,HEPDecision]
%s csHepConfig: %{public}@
%s _clientHepConfig: %{public}f, _clampedSFLatencyForClientLag: %{public}f, _useDefaultServerFeaturesOnClientLag: %{public}d
%s Language changed to: %{public}@
%s New hybrid endpoint asset downloaded
%s FirstUnlock notification received: %{public}d
%s _currentAsset changed to : %{public}@
%s %{public}@ doesnt exist
%s Could not read: %{public}@
%s Could not decode contents of: %{public}@: err: %{public}@
%s Request to init device with deviceType : %ld, deviceName : %@, deviceId : %@, productId : %@
%s Request inject audio %@ into device with UUID %@ and scale factor %f
%s Audio url %@ is nil, or url not existing in path
%s Can't find device with uuid %@
%s Device speak audio with startTime = %llu, stopTime = %llu
%s Request connect device with UUID %@
%s input device uuid is nil
%s Request disconnect device with UUID %@
%s deviceUUID %@ not existing in deviceDictionary, already disconnected
%s Request fetching primary input device
%s Error fetching primary device!
%s Cannot create NSNumber if xpcObject is NULL
%s XPC object type should be BOOL, DOUBLE, INT64, or UINT64
%s Cannot create xpcObject if objcType is NULL
%s Cannot create xpcObject since there is no matching type
%s Found pending activation : %{public}@, handle pending activation immediately
%s Received Activation Event in CoreSpeechDaemon: %{public}@
%s Returning error for already existing pending activation event : %{public}@
%s No delegate registered : Postpone activation event handling until we have delegate registered
%s Pending Timeout fired for %{public}@ returning error for timeout
%s There is no pending activation event to timeout
%s corespeechd received mediaserverd launched event
%s Start monitoring : AOP First Pass trigger
%s Stop monitoring : AOP First Pass trigger
%s SmartSiriVolume: deleted %{public}u elements in energy buffer.
%s SmartSiriVolume: number of elements to delete exceeds energy buffer size, ignore.
%s SmartSiriVolume init value for noise estimation %{public}f
%s SmartSiriVolume init value for LKFS estimation %{public}f
%s SmartSiriVolume enable policy changed : %{public}@
%s Already started listen polling, skip
%s listen polling has failed : %{public}@
%s Skip listen polling since audio is streaming / Siri disabled
%s Start audio stream successfully ? %{public}@, error : %{public}@
%s Received didStartRecording when Siri is off
%s Failed in requesting audio stream : %{public}@
%s Failed to stop audio stream : %{public}@
%s No audio stream to stop, we shouldn't hit this
%s SmartSiriVolume received MediaRemote initial state as %{public}@
%s SmartSiriVolume haven't got MediaRemote callback yet, let's assume media is playing.
%s SmartSiriVolume received alarm initial state as %{public}@
%s SmartSiriVolume received timer initial state as %{public}@
%s asset is nil, use default parameters(this should not happen).
%s SmartSiriVolume configure: %{public}@
%s SmartSiriVolume heartbeat = %{public}lld
%s SmartSiriVolume: estimated noise level %{public}f
%s SmartSiriVolume: estimated LKFS %{public}f
%s SmartSiriVolume: pause SSV calculation.
%s SmartSiriVolume: resume SSV calculation.
%s Siri is disabled, we shouldn't receive audio here, heartbeat = %{public}lld
%s stream stopped unexpectedly : %{public}ld
%s SmartSiriVolume received VT event!
%s SmartSiriVolume remove samples from VT utterances by %{public}llu, with startAnalyzeSampleCount = %{public}llu, samplesFed = %{public}llu, triggerStartSampleCount = %{public}llu
%s SmartSiriVolume trying to delete too many VT samples, set triggerDurationToDelete to be limited max: %{public}llu
%s SmartSiriVolume got empty VT event!
%s SmartSiriVolume dismiss alarm firing as VoiceTrigger detected.
%s SmartSiriVolume dismiss timer firing as VoiceTrigger detected.
%s SmartSiriVolume: final estimated TTS volume in dB %{public}f
%s SmartSiriVolume: adjust TTS volume since alarm/timer is firing.
%s SmartSiriVolume: TTS volume in dB from noise %{public}f, from LKFS %{public}f, with user offset %{public}f
%s SmartSiriVolume: soft volume algorithm in use
%s SmartSiriVolume: pause LKFS calculation according to MediaRemote notification.
%s SmartSiriVolume: resume LKFS calculation according to MediaRemote notification.
%s SmartSiriVolume received unknown media playing state, let's assume media is playing.
%s SmartSiriVolume received unknown alarm state, let's reset alarm state.
%s SmartSiriVolume: alarm firing status = %@ according to MobileTimer notification.
%s SmartSiriVolume received unknown timer state, let's reset timer state.
%s SmartSiriVolume: timer firing status = %@ according to MobileTimer notification.
%s Siri enabled : %{public}d
%s SmartSiriVolume dismiss alarm firing as Siri client is recording.
%s SmartSiriVolume dismiss timer firing as Siri client is recording.
%s SmartSiriVolume: set StartAnalyzeSampleCount = %{public}lld
%s SmartSiriVolume: final estimated TTS volume %{public}f with music volume %{public}f
%s Dealloc CSAudioInjectionProvider : %@
%s Stopping Audio Injection Provider : %@
%s Calling start audio stream : %@ %@
%s Calling stop audio stream : %@
%s Unable to expand archive %{public}@ to directory %{public}@
%s Listening on watch cannot be turned on since speech detection VAD is disabled
%s Listening on watch cannot be turned on since Siri is disabled
%s Listening on watch cannot be turned on since SpringBoard is not started
%s Listening on watch cannot be turned on since device is not unlocked after restart
%s Hey Siri is enabled. Checking if we are in a call.
%s Hey Siri is disabled. Not checking if we are in a call.
%s Listening on watch cannot be turned on since Siri assertion is disabled and or its not in a ringtone state
%s Listening on watch cannot be turned on since audioInjection is enabled
%s Listening on watch cant be turned on because we are in a connected or outgoing call
%s No app is currently recording now
%s Siri language is nil, falling back to %@
%s endpointUUID not provided, fallback to legacy query
%s Failed to query language code with endpointId %@, trying legacy query
%s Automatic Volume Toggled. Automatic Volume Enabled: %{public}d
%s ::: Error reading file %@, err: %d
%s CSAudioFileReader requires prepare recording settings to feed audio
%s CSAudioFileReader only support LinearPCM to feed
%s Setting ExtAudioFileSetProperty failed : %d
%s Starting audio file feed timer, bufferDuration = %f sampleRate = %f, bytesPerFrame = %d, channelsPerFrame = %d
%s ::: Error reading data from audio file : %d
%s Reach to EOF, chunkSize = %d
%s Stopping audio file feed timer
%s Endpointer is disabled in recordOption: %@
%s CSHybridEndpointer canProcessCurrentRequest
%s CSHybridEndpointer can-NOT-ProcessCurrentRequest, fallback  to NNVAD
%s _activeEndpointer=%{public}@
%s shouldUseCVT2ShotDecision: %{public}d, isWatchRTSTriggered=%{public}d
%s preheat
%s endpointer: %{public}@: didDetectStartpointAtTime: %{public}f
%s EP_PROXY::RecordingDidStop: Ignoring startPoint-reporting
%s EP_PROXY::RecordingDidStop: Ignoring didDetectHardpoint-reporting
%s %{public}@: Endpointer didDetectHardEndpointAtTime:withMetrics: %{public}f, CallingDelegate: %{public}@
%s Reported 2-shot at: %{public}f secs
%s Queried endpointerModelVersion: %{public}@
%s WARN: endpointerModelVersion called when CSHybridEndpointer is not available
%s WARN: logEndpointFeatures called when CSHybridEndpointer is not available
%s setting prefetched asset %@
%s update lastKnownConsecutiveBoronStartSampleCount to: %llu
%s Created OSDAnalyzer: %{public}@ model path: %{public}@
%s Cannot create OSDAnalyzer
%s _bestStartDetectSample %lu was greater than _bestEarlyDetectSample %lu or _bestEndDetectSample %lu
%s _bestEarlyDetectSample %lu was greater than _bestEndDetectSample %lu
%s _speechVoiceLevel %lu is 0
%s _numberOfTotalFramesETFT %lu is 0
%s Advert data: %{public}@
%s advert data write failed
%s elapsed time to get HEP assets: %{public}lf
%s installationString: %@, for language: %@
%s File not exist: %{public}@
%s endpointAsset: %{public}@, osdAsset: %{public}@
%s Dealloc CSAudioInjectionEngine : %@
%s Looking up audio diff:%llu sampleCount:%llu %@
%s Start monitoring : Springboard start
%s Cannot start monitoring Springboard start because it was already started
%s Stop monitoring : Springboard start
%s SpringBoard started = %{public}@
%s Received Activation Event : %{public}@
%s Cannot handle activation event : %{public}@
%s activation client not exist
%s ERR: Failed to initialize SSV Manager!
%s ERR: %{public}@
%s Primary stream is nil !
%s CSAttSiriAudioSrcNode deallocated
%s Tandem stream stopped unexpectly for reason: %ld
%s Unexpected audioFormat for ATV : %{public}u
%s Create audioDecoder for audioFormat %{public}u
%s Stop monitoring : First unlock
%s xpc object string return nil
%s xpc object should be XPC_TYPE_STRING
%s xpc object should be XPC_TYPE_ARRAY
%s xpcObject value is NULL
%s Cannot decode non-plist types of XPC object
%s Cannot encode non-plist types into XPC object : %{public}@
%s Timed-out for fetching voiceTriggerInfo
%s TiggerInfoProviding is nil
%s Overriding Myriad state as request was made during a phone call
%s Invoked Siri client
%s Cannot invoke Siri client : %{public}@
%s Cannot notify wake keyword spoken event : %{public}@
%s AFSiriActivationCarPlayDeviceVoiceTriggerPrewarm success
%s AFSiriActivationCarPlayDeviceVoiceTriggerPrewarm failed : %{public}@
%s Invoked Siri client for voice trigger from Jarvis
%s Cannot invoke Siri client for voice trigger from Jarvis : %{public}@
%s SiriActivationConnection deactivated due to %ld
%s siriSessionUUID = %{public}@
%s CSAudioProcessWaitingBuffer deallocated
%s Reason : %{public}lu
%s Received xpc disconnection
%s Updated endpoint start time in sec : %{public}.3f
%s Adjusted endpoint start time to : %{public}.3f, audioSampleCountToSkip : %{public}lu
%s Preheat LocalSpeechRecognition now
%s Settings : %{public}@
%s Unsupported speech recognizer task : %{public}lu
%s _localSpeechRecognizerState:%lu
%s Received nill requestId, generate requestId under corespeechd
%s Start deliver asr results with requestId: %@
%s Handle late start request from Request Dispatcher
%s Clear audio waiting buffer since current requestId(%@) doesn't match expected one (%{public}@)
%s requestId : %@
%s Request Dispatcher hasn't asked to start local ASR yet, cache the audio
%s %lf
%s Already accepted result candidate for request
%s Sending RC selection delegate with parameters, RcId: %{public}lu mitigationSignal: %{public}d shouldAccept %{public}d
%s Reset endpointStart and audioSampleCountToSkip since recordContext is %{public}@
%s Preheat local speech recognizer with language : %@
%s Local speech recognizer disabled, ignore prepare
%s cached requestId : %@, newRequestId : %@
%s Disable local SR for dictation
%s current state = %{public}@
%s speech recognizer task not specified, fallback to SearchOrMessage
%s Calling local speech recognition with settings : task(%{public}@), endpointStart(%{public}.3f), inputOrigin(%{public}@), location(%{public}@), shouldCensorSpeech(%{public}@), jitGrammar(%{public}@)
%s didStart local speech recognition with error :%@, model properties : %@
%s Local speech recognizer can't started : locale(%{public}@), taskName(%{public}@)
%s Skip %{public}lu samples (current audioSampleCountToSkip = %{public}lu)
%s Received %{public}lu samples, added %{public}lu samples to local speech recognizer
%s Stopping task %@
%s Request dispatcher didn't ask to start until end
%s Complete task now since taskString(%{public}@) or localSR(%{public}p) is nil
%s Complete task now since local SR is disabled
%s Schedule RecordingTransactionReleaseTimer %{public}@ for %{public}lf seconds
%s Token : %{public}@, currentToken : %{public}@
%s recordingToken doesn't match, ignore
%s %@ created speech recognizer %@
%s Ignoring completion from previous recognizer!
%s Exceeding max local speech recognition duration (%{public}f) : %{public}f, force endbooking the ASR task
%s Skip query as already accepted result candidate for request
%s didDetectedEndpoint = %{public}@, usesAutomaticEndpointing = %{public}@, waiting
%s Eager results accepted: %{public}d. Duration: %{public}lf last duration: %{public}lf
%s Received duration not matching last duration
%s isFinal package : %{public}@
%s There is no valid RC to deliver, or previous RC already got accepted
%s Enforce previous endpointHint
%s Speech recognition encountered error: %{public}@
%s Invalidating local speech recognizer for finish
%{public, signpost.description:begin_time}llu, %s %s
%{public, signpost.description:end_time}llu, %s %s
ondevice_EagerCPL
%s eagerCPL time interval: %{public}f, userSpeakingEndedHostTime: %{public}llu, lastEndpointEagerResultTime: %{public}llu
%s wordCount = %ld, trailingSilenceDuration = %ld, eosLikelihood = %f, pauseCounts = %@, silencePosterior = %f, processedAudioDurationInMilliseconds = %ld
%s Received ASR datapack root directory: %{public}@
%s Received inputOrigin: %{public}@ from Request Dispatcher, use hard-coded map
%s set current state from %{public}@ to %{public}@
%s Selected recognizer language : %{public}@
%s Timer already running. Cannot schedule another task
%s CSAttSiriTimer fired: event-handler called
%s Starting CSAttSiriTimer...
%s Cancelling pending timer...
%s stream %{public}@ initialized
%s stream %{public}@ is deallocated
%s Creating UUID for start audio stream request : %{public}@
%s Delivering didStop to %{public}lu tandem stream(s)
%s AudioStream<%{public}@> is streaming : %{public}d
%s Stream %{public}@ set startTimeInSampleCount : %{public}llu
%s AudioStream<%{public}@> has received didStopStreamUnexpectly
%s AudioStream<%{public}@> has received didHardwareConfigurationChange
%s Start monitoring : VoiceTrigger Asset meta update
%s Stop monitoring : VoiceTrigger Asset meta update
%s New VoiceTrigger asset metadata is available
%s Resetting audio preprocessor : %{public}f, containsVoiceTrigger:%{public}d
%s Flushing audio preprocessor
%s Zero Filter Metrics: %{public}@
%s Beep Canceller Metrics : %{public}@
%s accessoryId %{private}@
%s Received active route change notification
%s Start monitoring : speech endpoint asset meta update
%s Stop monitoring : speech endpoint asset meta update
%s New speech endpoint asset is available
%s event = %{public}p client = %{public}p cannot handle event
%s ignore unknown types of message
%s message = %{public}p, client = %{public}p, cannot handle message
%s MessageType = %{public}lld
%s Received error %{public}@ from client %{public}@
%s Client %{public}p connection disconnected, noticing xpc listener
%s AssetManager cannot be turned on since isFirstUnlocked is NO
%s AssetManager cannot be turned on since network is not available
%s Setting mixable to yes as we are in an active call
%s CSXPCListener start listening
%s setEndpointerOperationMode : %{public}d
%s current EndpointerOperationMode : %{public}d
%s update endpointer threshold to %{public}f for task %{public}@
%s HEP.posterior=%{public}f, result=1, endpointedBuffer.hostTime=%{public}llu isAnchorTimeBuffered=%{public}d
%s CSHybridEndpointer recordingStoppedForReason: %{public}ld
%s _clientHepConfig: %{public}f, _clampedSFLatencyForClientLag: %{public}f, _useDefaultServerFeaturesOnClientLag: %{public}d, _extraDelayFrequency: %{public}lu, _taskThresholdMap: %{public}@
%s update assets to: %@
%s ::: incrementing false wakeup to %{public}llu
%s PowerLog : HeySiriFalseTrigger numFalseWakeUp:%{public}d, secondsSinceLastReport:%{public}lf
%s ::: accumulated false wakeup count is %{public}llu so far, not reporting yet because it has been only %{public}.2f seconds since last report
%s Sending event with non determenistic triggerLengthSampleCount %llu, triggerLengthSampleCountDetermenisticFromFirstPass %llu, and delta of %lld samples
%s Initializing CSRawAudioInjectionProvider
%s Done initializing CSRawAudioInjectionProvider
%s Dealloc CSRawAudioInjectionProvider
%s Calling StreamId for : %@
%s Calling prepare
%s Calling start audio stream : %@
%s Calling stop audio stream
%s Calling isRecording
%s Calling prewarm
%s Calling activate audio session
%s VoiceTrigger is already %{public}@, received duplicated notification!
%s Start monitring : VoiceTrigger setting switch
%s Cannot start monitoring VoiceTrigger setting switch because it was already started
%s Stop monitring : VoiceTrigger setting switch
%s VoiceTrigger enabled = %{public}@
%s Received AOP Listening state change notification : %{public}d
%s Created AFTM-AS node
%s Don't run AFTM for recordType: %lld
%s Prefetched asset not set
%s Invalid FTM config read from configFile %{public}@ for task %{public}@
%s Reading config from: %{public}@ for task %{public}@
%s Configured recording types: %{public}lu
%s Thresholds read: %{public}@
%s Shadow Mode: %{public}d
%s Received start request for record type: %{public}@, supportedRecordTypes: %{public}lx taskName %{public}@
%s Unable to create progressive checker with error:%{public}@
%s Unable to create progressive checker context with error:%{public}@
%s Created SLProgressiveCheckerAnalyzer %{public}@ with context %{public}@
%s CSAcousticProxy has received %{public}d samples, heartbeat = %{public}lld
%s Siri session ended, stoping acoustic checker
%s Cancelling Siri request, score: %{public}.3f, threshold: %{public}.3f
%s Invalid Analyzer: %{public}@
%s FINAL: Analyzed samples: %lu, score: %f
%s PARTIAL: Analyzed samples: %lu, score: %f
%s Assistant audio log not available
%s Error writing out AcousticSL info meta: %{public}@
%s Saving AcousticSL results at %{public}@
%s Submitting AcousticFTM analytics: %@
%s Unexpected XPC audioTimeConvert providing request : %{public}lld
%s From sampleCount %{public}llu fetched hostTime = %{public}llu
%s From hostTime %{public}llu fetched sampleCount = %{public}llu
%s Non internal build, Ignoring command %@ from peerId %@ - Bailing out!
%s Received Malformed command %@ from peerId %@ - Bailing out!
%s Command %@ received from peerId %@
%s Unknown Command: (%@) - Ignoring
%s Triggering sync with peer - %@
%s Triggering nearmiss sync with peer - %@
%s Triggering voice profile sync with peer - %@
%s Triggering acoustic data sync with peer - %@
%s CSP2P_RemoteHeySiriCmd: ENABLE HeySiri: Not Implemented Yet: 
%s CSP2P_RemoteHeySiriCmd: DISABLE HeySiri: Not Implemented Yet: 
%s Cannot read contents of directory: %@, err: %@
%s Could not determine if [%@] is a directory or not. Err=%@
%s Found dir: %@. Skipping compression
%s _compressFilesInDirectory: Malloc failed for file %@ (%lu) - Discarding
%s _compressFilesInDirectory: Compression failed for file %@ (%lu) - Sending Uncompressed
%s _compressFilesInDirectory: File %@ compressed from %ld to %ld 
%s Failed in compressing %{public}@ with errror %{public}@ - Bailing out
%s Transfering NearMiss file %@ withCompression %{public}@ and size %ld in batch %{public}@
%s Transfering grading file %@ withCompression %{public}@ and size %ld in batch %{public}@
%s %@ is nil - Bailing out
%s Failed in transporting Voice file %@ with reponse: %@, error %@
%s Failed to remove the file %@ with error %@
%s Failed to move the file %@ to %@ with error %@
%s CSP2P_VoiceProfileParallelRecordingTransferCmd: received malformed command - %@ %@ %@
%s CSP2P_VoiceProfileParallelRecordingTransferCmd: unknown IDS peer with passed Identifier %@, %@ %@
%s CSP2P_VoiceProfileParallelRecordingTransferCmd: received malformed command - %@
%s CSP2P_VoiceProfileParallelRecordingTransferCmd: Creating directory failed with error %@
%s Ignoring sync of existing file %@ from %@
%s Syncing parallel recorded audio file - %@ from %@
%s Uncompressed file %@ sent by peer %@
%s ERR: Failed to allocate buffer of size %zu, bailing out
%s Writing to file(%@) failed!. Err=%@
%s received malformed command - %@ %@ %@
%s unknown IDS peer with passed Identifier %@, %@ %@
%s received malformed command - %@
%s Syncing audio file - %@ from %@
%s Error setting remoteP2Plog file to NSFileProtectionCompleteUntilFirstUserAuthentication. file=%@ Err=%@
%s CSP2P_VoiceProfileTransferCmd: received malformed command - %@ %@ %@
%s CSP2P_VoiceProfileTransferCmd: received malformed command: CSP2P_VoiceProfileData_Key: %@CSP2P_VoiceProfileFileName_Key: %@CSP2P_VoiceProfileSpeakerName_Key: %@CSP2P_VoiceProfileLocale_Key: %@CSP2P_VoiceProfileDataType_Key: %@CSP2P_VoiceProfileTotalSegments_Key: %@CSP2P_VoiceProfileSegment_Key: %@
%s CSP2P_VoiceProfileTransferCmd: Received VoiceProfile Segment (%@/%@) from peerId %@
%s CSP2P_VoiceProfileTransferCmd: Failed to delete the directory %@ with error %@
%s CSP2P_VoiceProfileTransferCmd: received VoiceProfileSegment %@, expected %d
%s CSP2P_VoiceProfileTransferCmd: Creating directory failed with error %@
%s CSP2P_VoiceProfileTransferCmd: Writing to file failed!!!
%s Received request to delete VoiceProfile %@ from peerId %@
%s Cannot send data across when _adCompanionServiceProvider is nil - returning
%s ERR: Rejecting command %@ sent to non Horseman device
%s ERR: received malformed command - %@ %@
%s ERR: unknown IDS peer with passed Identifier %@, %@ %@
%s ERR: received malformed command with locale nil - %@
%s Fetching homeUserId for siriProfileId %{public}@
%s siriProfileId %{public}@ maps to homeUserId %{public}@
%s ERR: Home User Id erred %{public}@ for Siri Profile Id %{private}@
%s ERR: %@
%s ERR: received malformed command with profileId nil - %@
%s ERR: Failed to find voice profile with identifier - %@
%s CSP2P_VoiceProfileFetchCmd: Transferring voice profile %{public}@
%s CSP2P_VoiceProfileFetchCmd: File %@ isCompressed: %d, compressedSize: %ld, err: %@
%s CSP2P_VoiceProfileReverseTransferCmd: Failed VoiceProfileTransfer: %@, error %@
%s CSP2P_VoiceProfileReverseTransferCmd: Successfully transferred %@
%s CSP2P_VoiceProfileReverseTransferCmd: Failed transferring voice profile %@ with error %@
%s CSP2P_VoiceProfileReverseTransferCmd: Successfully transferred voice profile %@
%s ERR: Rejecting command %@ sent to Horseman device
%s ERR: received malformed command with relative path nil - %@
%s Failed in sending trigger for Voice profile update to peer %@ with error %@
%s SpkrId:: path is nil - Bailing out
%s SpkrId:: Direntry with same name exists, this will be removed: %@
%s SpkrId:: Creating Directory : %@
%s SpkrId:: Creating Directory failed : %@
%s Error reading directory at %@: err: %@
%s %@ is empty
%s Using audioInjectionProvider as recorder
%s context : %@
%s context:%@, flag:%u option:%@, eventUUID:%@
%s _requestMHUUID set to :%@
%s Skip asking audioSrcNode to record since Siri client failed to start audio
%s Cached siri client stream, attach after nodes start
%s Skip asking audioSrcNode to prepare since Siri client failed to prepare audio
%s %@ is ready
%s Attached to siri client stream with result: %d error:%@
%s Failed to setup audioSrcNode
%s Skip processing for remora requests!
%s AFTM started for siri request status: %{public}d with error: %{public}@
%s attSiriTransaction already released
%s init-_currentLanguageCode: %{public}@
%s Asset Manager Policy has been %{public}@
%s Asset Manager Policy has been enabled, start fetching meta data now
%s Need to fetch remote meta now, since we have new asset need to be downloaded
%s Does not need to fetch remote meta now
%s Cannot fetch VoiceTrigger asset meta data
%s Undefined assetType : %{public}u
%s _currentLanguageCode changed: %{public}@
%s Trying to start download meta data
%s Periodical downloading is already scheduled, ignore request.
%s No periodical downloading is scheduled, ignore request.
%s Record route to verify = %{public}@
%s Record route = %{public}@, playback route = %{public}@
%s Device endpointType = %{public}lu
%s hypotheticalRoute = %{public}@
%s Audio route changing to HFP is expected
%s zeroFilterWinSz: %{public}tu, numHostTicksPerAudioSample: %{public}f
%s _vtEndInSampleCount:%{public}ld, _numSamplesProcessed: %{public}ld, voiceTriggerInfo: %{public}@
%s Metric Providing Request Message has arrived : %{public}lld
%s Unexpected XPC Metric providing request : %{public}lld
%s audioMetric = %{public}@
%s audioMetricProvider not existing
%s Message type = %{public}lld
%s Cannot handle wrong message type
%s Cannot handle activateEventMessage since event is nil
%s Successfully ? %{public}@
%s Notify release of audio session
%s Created NLDA-AS node
%s Bert model already present, nothing to do
%s Unable to create Bert model with error: %{public}@
%s Created Bert model !
%s Model not available
%s Failed to get result from Bert
%s NLDA detailed Result: %{public}@
%s Start monitoring : VoiceTrigger Asset Download
%s Stop monitoring : VoiceTrigger Asset Download
%s New VoiceTrigger is now installed
%s SmartSiriVolumeContextAware TTS volume post lower and upper bounds is: %f
%s TTS volume offset post lower and upper bounds is: %{public}f
%s Smart Siri Volume not supported on this platform - Bailing out
%s ERR: Failed to initialize Smart Siri Volume with sampling %{public}f and %{public}@
%s AlarmState changed to %{public}d
%s TimerState changed to %{public}d
%s MusicVolume changed to %{public}f
%s AlarmVolume changed to %{public}f
%s Automatic Volume State changed to %{public}d
%s UUID was nil will not start fingerprint provider
%s Updated in use services for fingerprintProvider. %lu services in use
%s Starting continuousFingerprintProvider
%s UUID was nil will not stop fingerprint provider
%s Updated in use services for fingerprintProvider. %lu services remaining
%s Stopping continuousFingerprintProvider
%s Created URES-AS node
%s Set input origin to: %@
%s Using config file at : %{public}@
%s Got mitigation result: %{public}d for RCId: %{public}lu
%s Mitigation signal for RCId: %{public}lu not found
%s ASR node fetched mitigation signal, unload NLDA model
%s Replacing already made decision for RCId: %{public}lu
%s Failed to get result from UReS, don't mitigate
%s Final mitigation result: %{public}@ for RCId: %{public}lu
%s Received RC from ASR, make UReS decision
%s UReS not supported for inputOrigin: %{public}@, abort
%s Unable to get all required inputs for decision - (inputOrigin: %{public}@ speechResult: %{public}@), abort
%s Recognizer task: %{public}@ isn't support, don't run URES mitigator
%s Speech package doesn't contain LRNN scores, don't run URES mitigator
%s AttSignal: NLDA Score: %.3f
%s Input origin not set, Abort !
%s AttSignal: EoS Likelihood %{public}f
%s Unable to create Ures mitigator with err: %{public}@
%s Created URES Mitigator !
%s Received AFTM score: %{public}f for task: %{public}@
%s AttSignal: aftmScore: %.3f
%s AttSignal: osdActivity: %{public}@ for duration %.3f
%s ERR: Failed to retrieve Speaker score, letting trigger through - %{public}@
%s SPKR Accept: Score %{public}.3f Threshold %{public}f 
%s SPKR Reject: Score %{public}.3f Threshold %{public}f 
%s AttSignal: ssrScore: %.3f
%s OS transaction obtained for UReS inference
%s osTransaction already released
%s OS transaction released after UReS inference
%s ERR: metaData is nil, defaulting to NO for %{public}@
%s ERR: read metafile %{public}@ failed with %{public}@ - defaulting to NO
%s Start monitoring : AdBlocker Asset Download
%s Stop monitoring : AdBlocker Asset Download
%s New AdBlockerAsset is now installed
%s CSVoiceIdXPCListener start listening
%s speechController = %{public}p
%s xpcListener = %{public}p
%s context = %{public}@
%s Failed to create audio recorder : %{public}@
%s For Context : %{public}@, audioStreamId(%llu) has allocated
%s Failed to get audio stream handle ID : %{publid}@
%s has match with audio stream handle id : %llu
%s does not match with audio stream handle id(%llu), creating new audio provider
%s No audioRecorder available, return nil for audioProvider
%s have matched audioProvider with stream handle id : %llu
%s don't have matched audioProvider with stream handle id : %llu, need to create one later
%s audioProvider[%{public}@] invalidated with streamHandleId : %{public}llu
%s No matched audioProvider found for streamHandleId : %{public}llu
%s Received VoiceTrigger cached asset change notification, let's reinitialize VoiceTrigger
%s Trying to start clear logging files
%s Clear logging file timer is already started, ignore startClearLoggingFilesTimer request.
%s cannot handle nil event 
%s ignore unknown types of message: %{public}@
%s cannot handle nil error
%s In %@: Continuous digital zero detected, lasting %{public}u samples per channel
%s In %@: Continuous digital zero in this audio chunk detected, lasting %{public}u samples per channel
%s input dictionary is nil
%s Cannot send nil message
%s Unable to send message to client since there is no connection
%s Cannot handle audio providing message
%s Audio Providing Request Message has arrived : %{public}lld
%s Unable to handle audio providing switch message : context is nil
%s Setting XPCClientType to %{public}d
%s Handing PingPong message
%s Attentive Siri not supported on device
%s Endpointer xpc connection started listening
%s LocalSpeechRecognition xpc connection started listening
%s AttSiriServiceListener xpc connection started listening: _attSiriSvcListener=%@
%s SSR xpc connection started listening
%s Received SIGTERM. Exiting
%s CSHostDaemon didLaunch
%s Got xpc event for notification %s
%s Daemon WillShutdown
%s %{public}.2f ms after firstBufferStart
%s Invalid timestamp (currentMachTime: %{public}llu timestamp: %{public}llu)
%s Invalid timestamp (currentMachTime: %{public}llu arrivalTimestamp: %{public}llu)
%s numOfAudioPackets: %{public}lu, numOfValidTrailingPackets: %{public}lu, numOfValidTrailingSpeechPackets: %{public}lu, 
trailingPktLatencies: %{public}@ 
trailingPktSpeechLatencies: %{public}@
%s Error reading audio file: %{public}d, skipping...
%s Notifying CoreSpeechDaemon launched
%s Start monitoring : corespeechd state
%s Cannot start monitoring corespeechd state because it was already started
%s Stop monitoring : corespeechd state
%s CoreSpeechDaemon state changed to %{public}u
%s ERR: Mach Service Name is nil - Bailing out
%s ERR: Proxy Object is nil - Bailing out
%s ERR: Exported interface is nil - Bailing out
%s Started listening for %{public}@
%s Service %{public}@ dealloced - %{public}@
%s Got connection on service %{public}@
%s [Service:%{public}@] Invalid listener - %{public}@
%s Rejecting connection to %{public}@ due to entitlement
%s [Service:%{public}@] Listener Interruption Handler: %{public}@, client PID: %{public}d)
%s [Service:%{public}@] Listener Invalidation Handler: %{public}@, client PID: %{public}d exited
%s [Service:%{public}@] Adding connection for client PID (%{public}d)
%s [Service:%{public}@] Client connections dump:
[Service:%{public}@] For client PID (%d): %@
%s _machServiceName:%@ clientConnCount:%lu 
%s Sending message for client PID (%{public}d)
%s RemoteObjectProxy is nil for client PID (%{public}d)
%s [Service:%{public}@]
%s Cannot create directory at : %{public}@ : %{public}@
%s Successfully make CoreSpeechDaemon as KeepAlive
%s Failed to make CoreSpeechDaemon as KeepAlive : Cannot create file at %{public}@, error : %{public}@, %{public}@
%s KeepAlive file %{public}@ already existing
%s Start monitoring: siri assertion enable/disable
%s Stop monitoring: siri assertion enable/disable
%s did receive enable assertion
%s did receive disable assertion
%s CSAudioSessionProvidingProxy has received xpc disconnection _streamClientType : %{public}d
%s Trying to release audio stream on CSAudioSessionProvidingProxy
%s deallocated
%s Session Providing Request Message has arrived : %{public}lld
%s Unexpected XPC session providing request : %{public}lld
%s Failed to prewarm audio session, error : %{public}@
%s Session activate reason : %{public}u, dynamicAttributeType : %{public}u, bundleId: %{public}@
%s Failed to activate audio session, error : %{public}@
%s Session activate reason : %{public}u
%s Failed to deactivate audio session, error : %{public}@
%s Session request getting duck others option
%s Trying to get duck others option when audioSessionProvider is nil
%s Session set duck others option : %{public}d
%s Trying to set duck others option when audioSessionProvider is nil
%s Manual ducking handler not supported!
%s Session %{public}@ mini ducking
%s Trying to enalbe mini ducking when audioSessionProvider is nil
%s Session %{public}@ smart routing consideration
%s Trying to enable smart routing consideration when audioSessionProvider is nil
%s Dealloc CSAudioInjectionEngineRemoraEngine : %@
%s Alert Providing Request Message has arrived : %{public}lld
%s Unexpected XPC alert providing request : %{public}lld
%s Alert sound url : %{public}@, alertType = %{public}d
%s Set alert sound successful ? %{public}@
%s audioAlertProvider not existing
%s AlertType = %{public}d
%s Play alert sound successful ? %{public}@
%s PlayRecordStartingAlertAndResetEndpointer successful ? %{public}@
%s alertStartTime = %{public}llu
%s Invalid alert behavior
%s Alert behavior : %{public}@
%s Request to bypass PhraseSpotter : %{public}d with timeout %{public}lf seconds
%s Received Siri Session did cancelled
%s Created FlexKwd-AS node
%s Unable to start Flex Kwd with error %{public}@
%s Unable to start audio stream for Flex Kwd with error %{public}@
%s Trigger info already sent, ignore result
%s Reporting trigger with result: %{public}@
%s Connection %{public}p rejected due to missing entitlement
%s Start monitoring : AdBlocker Asset meta update
%s Stop monitoring : AdBlocker Asset meta update
%s New AdBlocker asset metadata is available
%s Error reading file
%s Version of AdBlockerAsset: %d
%s Cannot create de-interleaver using AudioConverterNew: %{public}d
%s Created de-interleaver
%s Stopping AudioInjectionEngine : %@
%s Failed to open audio file %@, error : %d
%s Streaming from %@
%s Cannot speak nil Audio URL
%s Cannot speak since audio file does not exists : %@
%s Calling stopAudioStream
%s Failed to deinterleave the data: %{public}d
%s Start monitoring : Software update checking state
%s Cannot start monitoring software update checking state because it was already started
%s Stop monitoring : Software update checking state
%s Software update checking running : %{public}@
%s There is not audio buffer to convert. Skip this.
%s Got asked for %{public}u packets, have %{public}u
%s [%{public}02u of %{public}02u %{public}fs] Opus packet with %u bytes
%s %{public}d bytesConsumed from opus coverter, remains %{public}d bytes
%s Resetting AudioConverter buffer
%s createAudioConverter : initial frames per buffer = dur %{public}.2f * sr %{public}.2f = %{public}u
%s Failed to get audioConverter property (kAudioConverterCurrentOutputStreamDescription) : %{public}d
%s _configureAudioConverter: encoded audio needs minimum of %{public}u bytes per output buffer
%s _configureAudioConverter: AudioConverterGetProperty(kAudioConverterPropertyMinimumOutputBufferSize) returned status %{public}d
%s _configureAudioConverter: final framesPerBuffer: %{public}u
%s _configureAudioConverter: _convertPacketCount: %{public}u
%s _configureAudioConverter: AudioConverterGetProperty(MaximumOutputPacketSize): returned status %{public}d
%s createAudioConverter: outputSizePerPacket: %{public}u
%s _configureAudioConverter: _convertAudioCapacity %{public}u bytes
%s Cannot create AudioConverter using AudioConverterNew : %{public}u
%s Cannot set encoder bit rate : %{public}u
%s Get initial state from MediaRemote: media is on playing state %{public}ld.
%s Start monitoring MediaRemote: media playback
%s Stop monitoring MediaRemote: media playback
%s MediaRemote reported the now playing app playback state changed to %s (state %d)
%s Turn on AP mode since device is hands free state
%s CommandControl Streaming = %{public}d
%s Turn on AP mode since command control is streaming
%s VoiceTrigger AOP mode cannot be turned on since builtIn speaker is active
%s AudioRecordContext = %{public}@, recordState = RECORDING
%s CarPlay is connected, we will still run AOP mode
%s VoiceTrigger AOP mode cannot be turned on since Siri client is recording
%s AOP Listening is disabled
%s Turn on AP mode since siri is in attending state
%s Turn on AP mode since device is in a ringtone, connected, or outgoing call.
%s Speech Detection VAD is not available, we will still running in AOP mode
%s Will notify Siri Client record state change to STOPPED in %{public}f seconds, eventUUID = %{public}@
%s Notifying Siri Client record state change to STOPPED, eventUUID = %{public}@
%s There is no pending event to timeout : pendingRecordingStopUUID = %{public}@, timeoutTargetUUID = %{public}@
%s Replace deviceId(%{public}@) to nil for VoiceTrigger from Gibraltar.
%s network state notify key : %s
%s Start monitoring : network availability
%s Stop monitoring : network availability
%s Network availability changed
%s xpc object should be XPC_TYPE_DICTIONARY
%s xpcObject key or value is NULL
%s Cannot encode key into xpcobject since the key is not NSString class type
%s Meter Providing Request Message has arrived : %{public}lld
%s Unexpected XPC Meter providing request : %{public}lld
%s setMeteringEnabled : %{public}d
%s audioMeterProvider not existing
%s updateMeters
%s power = %{public}f with powerType %{public}u
mcplsupoxeps
(knN
ffffff
@mcpl
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
<key>BuildMachineOSBuild</key>
<string>20A241128</string>
<key>CFBundleIdentifier</key>
<string>com.apple.corespeechd</string>
<key>CFBundleName</key>
<string>corespeech daemon</string>
<key>CFBundleSupportedPlatforms</key>
<array>
<string>AppleTVSimulator</string>
</array>
<key>DTCompiler</key>
<string>com.apple.compilers.llvm.clang.1_0</string>
<key>DTPlatformBuild</key>
<string>19L5419b</string>
<key>DTPlatformName</key>
<string>appletvsimulator</string>
<key>DTPlatformVersion</key>
<string>15.4</string>
<key>DTSDKBuild</key>
<string>19L5419b</string>
<key>DTSDKName</key>
<string>appletvsimulator15.4.internal</string>
<key>DTXcode</key>
<string>1330</string>
<key>DTXcodeBuild</key>
<string>13E6049a</string>
<key>MinimumOSVersion</key>
<string>15.4</string>
<key>UIDeviceFamily</key>
<array>
<integer>3</integer>
<integer>5</integer>
</array>
</dict>
</plist>
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
<key>application-identifier</key>
<string></string>
<key>com.apple.airplay.carplayavvc</key>
<true/>
<key>com.apple.assistant.analytics</key>
<true/>
<key>com.apple.assistant.client</key>
<true/>
<key>com.apple.assistant.dictation.prerecorded</key>
<true/>
<key>com.apple.assistant.multiuser.service</key>
<true/>
<key>com.apple.assistant.settings</key>
<true/>
<key>com.apple.avfoundation.allow-system-wide-context</key>
<true/>
<key>com.apple.avfoundation.allows-access-to-device-list</key>
<true/>
<key>com.apple.bluetooth.system</key>
<true/>
<key>com.apple.coreaudio.CanRecordPastData</key>
<true/>
<key>com.apple.coreaudio.CanRecordWithoutSessionActivation</key>
<true/>
<key>com.apple.coreaudio.i-am-siri</key>
<true/>
<key>com.apple.coreaudio.register-internal-aus</key>
<true/>
<key>com.apple.coreduetd.context</key>
<true/>
<key>com.apple.corespeech.cat.xpc</key>
<true/>
<key>com.apple.hid.system.user-access-fast-path</key>
<true/>
<key>com.apple.managedconfiguration.profiled.profile-list-read</key>
<true/>
<key>com.apple.private.DistributedEvaluation.RecordAccess-com.apple.fides.borealis</key>
<true/>
<key>com.apple.private.DistributedEvaluation.RecordAccess-com.apple.fides.phs</key>
<true/>
<key>com.apple.private.ShazamKit</key>
<true/>
<key>com.apple.private.assets.accessible-asset-types</key>
<array>
<string>com.apple.MobileAsset.AdBlockerAssets</string>
<string>com.apple.MobileAsset.VoiceTriggerAssets</string>
<string>com.apple.MobileAsset.VoiceTriggerAssetsIPad</string>
<string>com.apple.MobileAsset.VoiceTriggerAssetsWatch</string>
<string>com.apple.MobileAsset.VoiceTriggerAssetsMarsh</string>
<string>com.apple.MobileAsset.VoiceTriggerAssetsTV</string>
<string>com.apple.MobileAsset.SpeechEndpointAssets</string>
<string>com.apple.MobileAsset.SpeechEndpointAssetsWatch</string>
<string>com.apple.MobileAsset.SpeechEndpointAssetsTV</string>
<string>com.apple.MobileAsset.RaiseToSpeakAssets</string>
<string>com.apple.MobileAsset.VoiceTriggerAssetsMac</string>
<string>com.apple.MobileAsset.SpeakerRecognitionAssets</string>
<string>com.apple.MobileAsset.EmbeddedSpeech</string>
</array>
<key>com.apple.private.attentionawareness</key>
<true/>
<key>com.apple.private.attentionawareness.samplewhileabsent</key>
<true/>
<key>com.apple.private.attribution.implicitly-assumed-identity</key>
<dict>
<key>type</key>
<string>path</string>
<key>value</key>
<string>/System/Library/PrivateFrameworks/CoreSpeech.framework/corespeechd</string>
</dict>
<key>com.apple.private.audio.dark-wake-audio</key>
<true/>
<key>com.apple.private.audio.hal.aop-audio.user-access</key>
<true/>
<key>com.apple.private.audio.notification-wake-audio</key>
<true/>
<key>com.apple.private.audio.suppress-mic-indicator</key>
<true/>
<key>com.apple.private.avfoundation.capture.nonstandard-client.allow</key>
<true/>
<key>com.apple.private.avfoundation.capture.nonstandard-client.allowed-media-types</key>
<dict>
<key>AVMediaTypeMetadataObject</key>
<array>
<string>AVMetadataObjectTypeTrackedFaces</string>
</array>
</dict>
<key>com.apple.private.bmk.allow</key>
<true/>
<key>com.apple.private.coreaudio.viewInterruptorName.allow</key>
<true/>
<key>com.apple.private.corespeech.xpc.remote</key>
<true/>
<key>com.apple.private.corespeechd.activation</key>
<true/>
<key>com.apple.private.healthkit</key>
<true/>
<key>com.apple.private.healthkit.medicaliddata</key>
<true/>
<key>com.apple.private.hid.client.event-monitor</key>
<true/>
<key>com.apple.private.homehubd</key>
<array>
<string>endpoint-read</string>
</array>
<key>com.apple.private.homekit.siri-audio-connection</key>
<true/>
<key>com.apple.private.iokit.darkwake-control</key>
<true/>
<key>com.apple.private.mediaexperience.allowrecordingduringcall</key>
<true/>
<key>com.apple.private.mediasafetynet.exception.announcemessage</key>
<true/>
<key>com.apple.private.mobiletimerd</key>
<true/>
<key>com.apple.private.siri.activation</key>
<true/>
<key>com.apple.private.siri.invoke</key>
<true/>
<key>com.apple.private.speech-model-training</key>
<true/>
<key>com.apple.private.tcc.allow</key>
<array>
<string>kTCCServiceMicrophone</string>
<string>kTCCServiceCamera</string>
</array>
<key>com.apple.private.tcc.manager.access.read</key>
<array>
<string>kTCCServiceAll</string>
</array>
<key>com.apple.proactive.eventtracker</key>
<true/>
<key>com.apple.rootless.storage.CoreSpeech</key>
<true/>
<key>com.apple.security.exception.files.absolute-path.read-only</key>
<array>
<string>/Library/Audio/Tunings/</string>
</array>
<key>com.apple.security.exception.files.home-relative-path.read-only</key>
<array>
<string>/Library/Caches/com.apple.corespeech.cat.xpc/</string>
</array>
<key>com.apple.security.exception.files.home-relative-path.read-write</key>
<array>
<string>/Library/VoiceTrigger/</string>
<string>/Library/Logs/CrashReporter/Assistant/</string>
<string>/Library/Logs/CrashReporter/VoiceTrigger/</string>
<string>/Library/Logs/CrashReporter/ssr/</string>
<string>/Library/Logs/CrashReporter/CoreSpeech/</string>
<string>/Library/Logs/CrashReporter/RTS/</string>
<string>/Library/Caches/VoiceTrigger/</string>
<string>/Library/Caches/com.apple.corespeechd/</string>
<string>/Documents/Logs/CoreSpeech/</string>
</array>
<key>com.apple.security.exception.iokit-user-client-class</key>
<array>
<string>AppleSPUHIDDriverUserClient</string>
<string>IOHIDEventServiceFastPathUserClient</string>
<string>AGXDeviceUserClient</string>
<string>IOSurfaceRootUserClient</string>
<string>AGXSharedUserClient</string>
<string>AGXCommandQueue</string>
<string>AGXDevice</string>
<string>H11ANEInDirectPathClient</string>
</array>
<key>com.apple.security.exception.mach-lookup.global-name</key>
<array>
<string>com.apple.carousel.backlightxpc</string>
<string>com.apple.usernotifications.usernotificationservice</string>
<string>com.apple.frontboard.systemappservices</string>
<string>com.apple.assistant.settings</string>
<string>com.apple.MobileTimer.timerserver</string>
<string>com.apple.MobileTimer.alarmserver</string>
<string>com.apple.audio.voicetrigger.xpc</string>
<string>com.apple.audio.AudioComponentRegistrar</string>
<string>com.apple.voicetrigger.voicetriggerservice</string>
<string>com.apple.audio.AudioQueueServer</string>
<string>com.apple.server.bluetooth</string>
<string>com.apple.SystemConfiguration.NetworkInformation</string>
<string>com.apple.mediaremoted.xpc</string>
<string>com.apple.coremedia.carplayavvc.xpc</string>
<string>com.apple.iohideventsystem</string>
<string>com.apple.siri.activation</string>
<string>com.apple.siri.activation.horseman</string>
<string>com.apple.siri.activation.blackbird</string>
<string>com.apple.assistant.analytics</string>
<string>com.apple.audio.SystemSoundServer-iOS</string>
<string>com.apple.BTLEAudioController.xpc</string>
<string>com.apple.healthd.server</string>
<string>com.apple.SystemConfiguration.configd</string>
<string>com.apple.managedconfiguration.profiled</string>
<string>com.apple.locationd.registration</string>
<string>com.apple.backlightd</string>
<string>com.apple.carousel.wakegesturemonitor</string>
<string>com.apple.homekit.audio.xpc</string>
<string>com.apple.SBUserNotification</string>
<string>com.apple.nsurlsessiond.NSURLSessionProxyService</string>
<string>com.apple.nsurlstorage-cache</string>
<string>com.apple.commcenter.xpc</string>
<string>com.apple.mediasafetynet.exceptions</string>
<string>com.apple.symptom_diagnostics</string>
<string>com.apple.corespeech.mockremoteplugin.xpc</string>
<string>com.apple.systemstatus.activityattribution</string>
<string>com.apple.assistant.multiuser.service</string>
<string>com.apple.callkit.callcontrollerhost</string>
<string>com.apple.siri.morphunassetsupdaterd</string>
<string>com.apple.homehubd.manage</string>
<string>com.apple.AttentionAwareness</string>
<string>com.apple.corespeech.speechmodeltraining.xpc</string>
<string>com.apple.siri.analytics.assistant</string>
<string>com.apple.remoted</string>
<string>com.apple.PairingManager</string>
</array>
<key>com.apple.security.exception.shared-preference.read-only</key>
<array>
<string>com.apple.assistant</string>
<string>com.apple.nano</string>
<string>com.apple.raisetospeak</string>
<string>com.apple.assistant.backedup</string>
<string>com.apple.assistant.support</string>
<string>com.apple.CoreMotion</string>
<string>com.apple.airplay</string>
<string>com.apple.mediaremote</string>
</array>
<key>com.apple.security.exception.shared-preference.read-write</key>
<array>
<string>com.apple.niservices</string>
<string>com.apple.voicetrigger</string>
<string>com.apple.voicetrigger.notbackedup</string>
<string>com.apple.avfoundation.avvc</string>
<string>com.apple.audio.virtualaudio</string>
<string>com.apple.speakerrecognition</string>
<string>com.apple.coreaudio</string>
<string>com.apple.coremedia</string>
<string>com.apple.raisetospeak</string>
</array>
<key>com.apple.security.exception.sysctl.read-only</key>
<array>
<string>net.routetable.0.0.3.0</string>
</array>
<key>com.apple.security.ts.ane-client</key>
<true/>
<key>com.apple.security.ts.mobile-keybag-access</key>
<true/>
<key>com.apple.security.ts.play-audio</key>
<true/>
<key>com.apple.security.ts.play-media</key>
<true/>
<key>com.apple.security.ts.power-assertions</key>
<true/>
<key>com.apple.sensorkit.writer.allow</key>
<array>
<string>com.apple.SensorKit.speechMetrics.siri</string>
<string>com.apple.SensorKit.speechEmotion.siri</string>
<string>com.apple.SensorKit.soundDetection.siri</string>
</array>
<key>com.apple.siri.activation</key>
<true/>
<key>com.apple.siri.embeddedspeech</key>
<true/>
<key>com.apple.siri.external_request</key>
<true/>
<key>com.apple.systemstatus.activityattribution</key>
<true/>
<key>com.apple.systemstatus.publisher.domains</key>
<array>
<string>media</string>
</array>
<key>com.apple.trial.client</key>
<array>
<string>200</string>
<string>322</string>
<string>404</string>
<string>372</string>
<string>401</string>
<string>751</string>
<string>757</string>
</array>
<key>com.apple.voicetrigger.voicetriggerservice</key>
<true/>
<key>keychain-access-groups</key>
<array>
<string>com.apple.corespeech</string>
</array>
<key>platform-application</key>
<true/>
<key>seatbelt-profiles</key>
<array>
<string>temporary-sandbox</string>
</array>
</dict>
</plist>
33s@
fff?
xeps
supo
333333
333333
mcplsupoxeps
 %*/
(knN
ffffff
@mcpl
init
_reportsDynamicActivityAttribute:bundleId:
reportMicUsage:
reportsDynamicActivityAttributeAsync:bundleId:
reportsDynamicActivityAttributeSync:bundleId:
queue
setQueue:
.cxx_destruct
_queue
T@"NSObject<OS_dispatch_queue>",&,N,V_queue
upperCaseString:withReply:
trainPersonalizedLMWithLanguage:configuration:fides:write:completion:
trainGlobalNNLMwithFidesSessionURL:completion:
buildPhoneticMatchWithLanguage:saveIntermediateFsts:completion:
generateAudioWithTexts:language:completion:
interfaceWithProtocol:
arrayWithObjects:count:
setWithArray:
setClasses:forSelector:argumentIndex:ofReply:
initWithMachServiceName:options:
setRemoteObjectInterface:
setInterruptionHandler:
setInvalidationHandler:
resume
invalidate
dealloc
synchronousRemoteObjectProxyWithErrorHandler:
_serviceProxyWithErrorHandler:
firstObject
stringByAppendingPathComponent:
stringByStandardizingPath
isEqualToString:
trainPersonalizedLMWithLanguage:configuration:asset:fides:activity:completion:
length
initWithFormat:
dictionaryWithObjects:forKeys:count:
errorWithDomain:code:userInfo:
trainPersonalizedLMWithLanguage:configuration:asset:directory:completion:
trainPersonalizedLMWithLanguage:configuration:fides:activity:completion:
description
initialize
initWithServiceName:
upperCaseString:completion:
trainPersonalizedLMWithLanguage:directory:completion:
_smtConnection
registerXPCActivities
componentsSeparatedByString:
processInfo
systemUptime
initWithConfiguration:
inputRecordingSampleRate
resetWithSamplingRate:language:taskType:userId:sessionId:deviceId:farField:audioSource:maxAudioBufferSizeSeconds:
removeAllObjects
resultsWithEndedAudio
_calculateTriggerConfidence:
dataForChannel:
inputRecordingIsFloat
resultsWithAddedFloatAudio:numberOfSamples:taskName:
resultsWithAddedAudio:numberOfSamples:taskName:
count
dictionaryWithCapacity:
countByEnumeratingWithState:objects:count:
objectForKeyedSubscript:
setObject:forKey:
tokens
lastObject
tokenName
objectForKey:
floatValue
confidence
numberWithDouble:
sharedPreferences
isMultiPhraseVTEnabled
addObjectsFromArray:
_getConfidence:
objectAtIndex:
caseInsensitiveCompare:
enumerateObjectsUsingBlock:
dumpEARSpeechRecognitionResults:
initWithConfigPath:triggerTokens:useKeywordSpotting:preventDuplicatedReset:
resetWithLanguage:withFarField:withAudioSource:
flushAudio
processAudioChunk:
phraseIdScores
triggerConfidence
setTriggerConfidence:
activeChannel
setActiveChannel:
ctcKwdToPhraseIdMap
setCtcKwdToPhraseIdMap:
_previousUtteranceTokens
_lastReportedRecogResults
_triggerTokenList
_syncRecognizer
_useKeywordSpotting
_requireReset
_preventDuplicatedReset
_triggerConfidence
_activeChannel
_ctcKwdToPhraseIdMap
Td,N,V_triggerConfidence
TQ,N,V_activeChannel
T@"NSDictionary",&,N,V_ctcKwdToPhraseIdMap
T@"NSDictionary",R,N
bytes
numberWithUnsignedInteger:
numberWithFloat:
numberWithBool:
initWithBlob:isEarlyDetected:
dictionary
samplesFed
setSamplesFed:
bestStart
setBestStart:
bestEnd
setBestEnd:
bestScore
setBestScore:
isSecondChance
setIsSecondChance:
isEarlyDetect
setIsEarlyDetect:
_isSecondChance
_isEarlyDetect
_bestScore
_samplesFed
_bestStart
_bestEnd
TQ,N,V_samplesFed
TQ,N,V_bestStart
TQ,N,V_bestEnd
Tf,N,V_bestScore
TB,N,V_isSecondChance
TB,N,V_isEarlyDetect
initWithBlob:
checkForTriggerWithBytes:withNumberOfSamples:
processAudioBytes:withNumberOfSamples:
reset
delegate
setDelegate:
_currentBlob
_delegate
T@"<CSKeywordAnalyzerNDEAPIScoreDelegate>",W,N,V_delegate
setXpcConnection:
_handleDeactivateAudioSessionRequestMessage:messageBody:client:
sharedManagerForCoreSpeechDaemon
fetchFallbackAudioSessionReleaseProvider
fallbackDeactivateAudioSession:error:
_sendReply:client:result:error:
domain
UTF8String
code
isEqual:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
debugDescription
TQ,R
T#,R
T@"NSString",R,C
handleXPCMessage:messageBody:client:
CSXPCConnectionReceivedClientError:clientError:client:
initWithXPCConnection:
xpcConnection
_xpcConnection
T@"CSXPCConnection",W,N,V_xpcConnection
integerValue
multiUserHighScoreThreshold
multiUserLowScoreThreshold
multiUserDeltaScoreThreshold
multiUserConfidentScoreThreshold
mutableCopy
removeObjectForKey:
pickTopScoringProfileIdFromScores:
classifyUserIdentityFor:withScores:withAsset:
stringFromClassificationCategory:
startRecordingHostTime
initWithStreamID:atStartHostTime:
avvcAlertBehavior
unsignedIntegerValue
setStartAlert:
setStopAlert:
setStopOnErrorAlert:
skipAlertBehavior
setSkipAlert:
_alertBehaviorTypeFromAVVCOberrideType:
setStartAlertBehavior:
setStopAlertBehavior:
setErrorAlertBehavior:
startAlertBehavior
_avvcAlertOverrideType:
stopAlertBehavior
errorAlertBehavior
numberWithInteger:
avvcStartRecordSettingsWithAudioStreamHandleId:
setAVVCAlertBehavior:
isAlertBehaviorOverridedBeep
_handleListenerEvent:
_handleListenerError:
xpcObject
_sendMessage:connection:completion:
_decodeError:
stringWithUTF8String:
connect
notifyActivationEvent:completion:
T@"NSObject<OS_xpc_object>",&,N,V_xpcConnection
encodeInteger:forKey:
decodeIntegerForKey:
supportsSecureCoding
encodeWithCoder:
initWithCoder:
TB,R
copyWithZone:
initWithRequestSource:
reqSrc
setReqSrc:
_reqSrc
TQ,N,V_reqSrc
lpcmNarrowBandASBD
lpcmASBD
initWithInASBD:outASBD:
_createSampleRateConverterWithInASBD:outASBD:
dataWithLength:
mutableBytes
setLength:
upsampler
downsampler
convertSampleRateOfBuffer:
_sampleRateConverter
_outBufferScaleFactor
_inASBD
_outASBD
_asssetMetaUpdatedKey
_didReceiveSpeakerRecognitionAssetMetaData
_notifyObserver:
enumerateObservers:
notifyObserver:
CSSpeakerRecognitionAssetMetaUpdateMonitor:didReceiveNewSpeakerRecognitionAssetMetaData:
sharedInstance
_startMonitoringWithQueue:
_stopMonitoring
_notifyToken
initWithType:
defaultFactory
clientForAudioProviding
clientForAudioSessionInfoProviding
clientForSmartSiriVolumeProviding
clientForMacOSDuckAudioDevice
clientForFallbackAudioSessionReleaseProviding
fetchVolumeFromAVSystemControllerForAudioCategory:
_startObservingSystemControllerLifecycle
startObservingSystemVolumes
defaultCenter
removeObserver:
musicVolume
musicVolumeWithCompletion:
alarmVolume
systemVolumeDidChange:
systemControllerDied:
_supportAVSystemVolumeFetch
_musicVolumeLevel
_alarmVolumeLevel
audioRecorder
registerObserver:
deactivateAudioSession:error:
localizedDescription
unregisterObserver:
audioRecorderBufferAvailable:audioStreamHandleId:buffer:remoteVAD:atTime:arrivalTimestampToAudioRecorder:numberOfChannels:
audioRecorderBufferAvailable:audioStreamHandleId:buffer:
audioRecorderDidStartRecord:audioStreamHandleId:successfully:error:
audioRecorderDidStopRecord:audioStreamHandleId:reason:
audioRecorderRecordHardwareConfigurationDidChange:toConfiguration:
audioRecorderDidFinishAlertPlayback:ofType:error:
audioRecorderBeginRecordInterruption:
audioRecorderBeginRecordInterruption:withContext:
audioRecorderEndRecordInterruption:
audioRecorder:willSetAudioSessionActive:
audioRecorder:didSetAudioSessionActive:
voiceTriggerDetectedOnAOP:
audioRecorderDisconnected:
audioRecorderLostMediaserverd:
audioRecorderWillBeDestroyed:
audioRecorderBuiltInAudioStreamInvalidated:error:
audioRecorderStreamHandleIdInvalidated:
initWithAudioRecorder:
setAudioRecorder:
_audioRecorder
T@"CSAudioRecorder",&,N,V_audioRecorder
isSpeakerRecognitionAvailable
addObserver:
_notificationKey
_didInstalledNewAsset
enumerateObserversInQueue:
CSSpeakerRecognitionAssetDownloadMonitor:didInstallNewAsset:assetProviderType:
trialAssetDownloadMonitorDelegate:didInstallNewAsset:assetType:
trialAssetMonitor
setTrialAssetMonitor:
_lastUpdatedAssetType
_trialAssetMonitor
T@"CSTrialAssetDownloadMonitor",&,N,V_trialAssetMonitor
initWithWordCount:trailingSilenceDuration:eosLikelihood:pauseCounts:silencePosterior:taskName:processedAudioDurationInMilliseconds:
componentsJoinedByString:
stringWithFormat:
initWithWordCount:trailingSilenceFrames:endOfSilenceLikelihood:pauseCounts:silencePosterior:taskName:
wordCount
setWordCount:
trailingSilenceDuration
setTrailingSilenceDuration:
eosLikelihood
setEosLikelihood:
pauseCounts
setPauseCounts:
silencePosterior
setSilencePosterior:
processedAudioDurationInMilliseconds
setProcessedAudioDurationInMilliseconds:
taskName
setTaskName:
_wordCount
_trailingSilenceDuration
_eosLikelihood
_pauseCounts
_silencePosterior
_processedAudioDurationInMilliseconds
_taskName
Tq,N,V_wordCount
Tq,N,V_trailingSilenceDuration
Td,N,V_eosLikelihood
T@"NSArray",C,N,V_pauseCounts
Td,N,V_silencePosterior
Tq,N,V_processedAudioDurationInMilliseconds
T@"NSString",C,N,V_taskName
initWithAssertionMonitor:
weakObjectsHashTable
addObject:
removeObject:
doubleValue
_fetchAssertionMonitor
enableAssertionReceived
disableAssertionReceived
CSVoiceTriggerXPCServiceProxy:bypassPhraseSpotter:
CSVoiceTriggerXPCServiceProxy:bypassRaiseToSpeak:
copy
enableVoiceTrigger:withAssertion:timestamp:
setPhraseSpotterBypassing:timeout:
setRaiseToSpeakBypassing:timeout:
fetchVoiceTriggerHeartBeatMetrics
notifyVoiceTriggeredSiriSessionCancelled
notifyServiceConnectionLost
fetchVoiceTriggerStats
activationAssertions
setActivationAssertions:
isPhraseSpotterBypassed
setIsPhraseSpotterBypassed:
isRaiseToSpeakBypassed
setIsRaiseToSpeakBypassed:
observers
setObservers:
assertionMonitor
setAssertionMonitor:
_isPhraseSpotterBypassed
_isRaiseToSpeakBypassed
_activationAssertions
_observers
_assertionMonitor
T@"NSMutableSet",&,N,V_activationAssertions
TB,N,V_isPhraseSpotterBypassed
TB,N,V_isRaiseToSpeakBypassed
T@"NSHashTable",&,N,V_observers
T@"CSSiriAssertionMonitor",&,N,V_assertionMonitor
initWithUTF8String:
initWithName:options:queue:delegate:
dispatchStateChangedFrom:to:
notifySiriSessionStateTTSOngoing:
notifySiriSessionStateChange:
notifyObserver:didReceiveNotificationWithToken:
notifyObserver:didChangeStateFrom:to:
initWithDelegate:
siriStateObserver
setSiriStateObserver:
stateNotificationQueue
setStateNotificationQueue:
isSpeaking
setIsSpeaking:
isListening
setIsListening:
isActiveRequest
setIsActiveRequest:
isActiveSession
setIsActiveSession:
_isSpeaking
_isListening
_isActiveRequest
_isActiveSession
_siriStateObserver
_stateNotificationQueue
T@"AFNotifyObserver",&,N,V_siriStateObserver
T@"NSObject<OS_dispatch_queue>",&,N,V_stateNotificationQueue
TB,N,V_isSpeaking
TB,N,V_isListening
TB,N,V_isActiveRequest
TB,N,V_isActiveSession
T@"<CSAttSiriSessionStateDelegate>",R,W,N,V_delegate
audioStream
streamProvider
isStreaming
submitAudioIssueReport:
name
setAudioStream:
setRecordContext:
type
deviceId
_isHubRequest
_setAllowMixableAudioWhileRecording:
notifyWillStopStream:reason:
notifyWillStopStream:reason:forAccessory:
notifyWillStopStream:
notifyDidStopStream:withEventUUID:
notifyDidStopStream:reason:withEventUUID:forAccessory:
notifyDidStopStream:
stopAudioStreamWithOption:completion:
_handleSetCurrentConextMessage:messageBody:client:
_handleAudioStreamRequestMessage:messageBody:client:
_handleAudioStreamPrepareMessage:messageBody:client:
_handleStartAudioStreamMessage:messageBody:client:
_handleStopAudioStreamMessage:messageBody:client:
_handleVoiceTriggerInfoMessage:messageBody:client:
_handleIsRecordingMessage:messageBody:client:
_handleRecordRouteMessage:messageBody:client:
_handleRecordDeviceInfo:messageBody:client:
_handleAudioDeviceInfo:messageBody:client:
_handleRecordSettings:messageBody:client:
_handleIsNarrowband:messageBody:client:
_handlePlaybackRouteMessage:messageBody:client:
audioStreamProviding
initWithXPCObject:
setCurrentContext:error:
audioStreamWithRequest:streamName:error:
notifyFetchedSiriClientAudioStream:successfully:
streamRequest
prepareAudioStreamSyncWithRequest:error:
notifyPreparedSiriClientAudioStream:successfully:
notifyWillStartStreamWithContext:option:
notifyWillStartStreamWithContext:option:forAccessory:
UUID
notifyWillStartStreamWithContext:audioProviderUUID:option:
UUIDString
notifyDidStartStreamWithContext:successfully:option:withEventUUID:
notifyDidStartStreamWithContext:successfully:option:withEventUUID:forAccessory:
notifyDidStartStreamWithContext:successfully:option:
notifyDidStartStreamWithContext:audioProviderUUID:successfully:option:
startAudioStreamWithOption:completion:
fetchVoiceTriggerInfoWithAudioContext:triggerInfoProviding:resultVoiceTriggerInfo:resultRTSTriggerInfo:
_cs_xpcObject
isRecording
recordRoute
recordDeviceInfo
audioDeviceInfo
recordSettings
isNarrowBand
playbackRoute
_sendDelegateMessageToClient:
sendMessageToClient:
setAllowMixableAudioWhileRecording:error:
audioStreamProvider:didStopStreamUnexpectly:
audioStreamProvider:audioBufferAvailable:
audioStreamProvider:audioChunkForTVAvailable:
audioStreamProvider:didHardwareConfigurationChange:
setAudioStreamProvidingForProxy:
setInitialContext:
triggerInfoProviding
setTriggerInfoProviding:
streamClientType
setStreamClientType:
recordContext
recordEventUUID
setRecordEventUUID:
accessoryId
setAccessoryId:
_audioStreamProviding
_triggerInfoProviding
_streamClientType
_audioStream
_recordContext
_recordEventUUID
_accessoryId
T@"CSAudioStream",&,N,V_audioStream
T@"CSAudioRecordContext",&,N,V_recordContext
T@"NSString",&,N,V_recordEventUUID
T@"NSString",&,N,V_accessoryId
T@"<CSAudioStreamProviding>",W,N,SsetAudioStreamProvidingForProxy:,V_audioStreamProviding
T@"<CSTriggerInfoProviding>",W,N,V_triggerInfoProviding
TQ,N,V_streamClientType
initWithToken:score:startSampleID:endSampleId:
dictionaryRepresentation
bestToken
kwdScore
startStampleId
endSampleId
_kwdScore
_bestToken
_startStampleId
_endSampleId
T@"NSString",R,N,V_bestToken
Tf,R,N,V_kwdScore
Tq,R,N,V_startStampleId
Tq,R,N,V_endSampleId
sharedHandler
flexKwdConfigFile
runRecognitionWithResultStream:
flexKwdThresholdFile
getVoiceTriggerAssetWithEndpointId:completion:
startSampleCount
data
numSamples
addAudioSamples:count:
start
appendFormat:
triggerReportedFromFlxKwdSpotter:
cancelRecognition
speechRecognizer:didRecognizePartialResult:
speechRecognizer:didFinishRecognitionWithError:
speechRecognizer:didRecognizeFinalResults:
speechRecognizer:didRecognizeFinalResults:tokenSausage:nBestChoices:
speechRecognizer:didRecognizeFinalResultPackage:
speechRecognizer:didProcessAudioDuration:
speechRecognizer:didRecognizeRawEagerRecognitionCandidate:
speechRecognizer:didProduceEndpointFeaturesWithWordCount:trailingSilenceDuration:eosLikelihood:pauseCounts:silencePosterior:processedAudioDurationInMilliseconds:
speechRecognizer:didRecognizePartialResultNbest:
speechRecognizer:didProduceLoggablePackage:
startKeywordSpottingWithCompletion:
recognizer
setRecognizer:
recognizerBuffer
setRecognizerBuffer:
currReqFirstSampleId
setCurrReqFirstSampleId:
thresholdsMap
setThresholdsMap:
currentAsset
setCurrentAsset:
_recognizer
_recognizerBuffer
_currReqFirstSampleId
_thresholdsMap
_currentAsset
T@"_EARSpeechRecognizer",&,N,V_recognizer
T@"_EARSpeechRecognitionAudioBuffer",&,N,V_recognizerBuffer
Tq,N,V_currReqFirstSampleId
T@"NSDictionary",&,N,V_thresholdsMap
T@"CSAsset",&,N,V_currentAsset
T@"<CSFlexKeywordSpotterDelegate>",W,N,Vdelegate
defaultManager
fileExistsAtPath:isDirectory:
dataWithContentsOfFile:options:error:
JSONObjectWithData:options:error:
initWithSpeechManager:audioStreamProvider:streamName:streamRequest:
audioProviderWithContext:error:
initWithAudioStreamProvider:streamName:streamRequest:
_handleDidAudioStartWithResult:error:
_handleDidStop
containsObject:
attSiriAudioSrcNodeDidStartRecording:successfully:error:
attSiriAudioSrcNodeLPCMRecordBufferAvailable:audioChunk:
attSiriAudioSrcNodeDidStop:
_handleDidStopStreamUnexpectly
attSiriController
handleAttendingAudioStopUnexpectly
initWithAttSiriController:
addReceiver:
removeReceiver:
pause
stop
setAttSiriController:
requiredNodes
mhId
setMhId:
prefetchedAsset
setPrefetchedAsset:
isReady
setIsReady:
T@"CSAttSiriController",W,N
TQ,R,N
T@"NSArray",R,N
T@"NSString",&,N
T@"CSAsset",&,N
TB,N
receivers
setReceivers:
speechManager
setSpeechManager:
_isReady
_type
_requiredNodes
_attSiriController
_mhId
_receivers
_speechManager
T@"NSHashTable",&,N,V_receivers
T@"CSSpeechManager",&,N,V_speechManager
T@"CSAttSiriController",W,N,V_attSiriController
TQ,R,N,V_type
T@"NSArray",R,N,V_requiredNodes
T@"NSString",&,N,V_mhId
TB,N,V_isReady
utteranceFileASBD
_closeAudioFile
_makeTimestampedAudioLogFilenameWithPrefix:suffix:
fileURLWithPath:isDirectory:
baseDir
_audioLogDirectory
createDirectoryAtPath:withIntermediateDirectories:attributes:error:
localeWithLocaleIdentifier:
setLocale:
setDateFormat:
date
stringFromDate:
_getOrCreateAudioLogDirectory
_nowString
stringByReplacingOccurrencesOfString:withString:
startRecording
appendAudioData:
stopRecording
_audioFile
_asbd
_url
_audioLength
_deregisterAudioSessionNotifications
_startMonitoring
supportRemoraVoiceTrigger
contextForRemoraVoiceTriggerWithDeviceId:
avvcContextSettings
sessionForContext:error:
opaqueSessionID
audioSessionInfoProvider:didReceiveAudioSessionMediaServicesWereLostNotificationWithUserInfo:
_registerAudioSessionNotifications
audioSessionInfoProvider:didReceiveAudioSessionMediaServicesWereResetNotificationWithUserInfo:
removeObserver:name:object:
_handleInterruption:
addObserver:selector:name:object:
_audioRouteChanged:
audioSessionInfoProvider:didReceiveAudioSessionInterruptionNotificationWithUserInfo:
userInfo
audioSessionInfoProvider:didReceiveAudioSessionRouteChangeNotificationWithUserInfo:
_registerInterruptionNotification
_registerAudioRouteChangeNotification
audioSessionIdForDeviceId:
CSAudioServerCrashMonitorDidReceiveServerCrash:
CSAudioServerCrashMonitorDidReceiveServerRestart:
sessionInfoQueue
setSessionInfoQueue:
_sessionInfoQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_sessionInfoQueue
setObject:forKeyedSubscript:
didTransitFrom:to:by:
didIgnoreEvent:from:
initWithInitialState:
addTransitionFrom:to:for:
addTransitionFromAnyStateTo:for:
performTransitionForEvent:
currentState
initialState
setInitialState:
transitions
setTransitions:
eventToStateTransitions
setEventToStateTransitions:
_currentState
_initialState
_transitions
_eventToStateTransitions
Tq,N,V_initialState
T@"NSMutableDictionary",&,N,V_transitions
T@"NSMutableDictionary",&,N,V_eventToStateTransitions
T@"<CSStateMachineDelegate>",W,N,V_delegate
Tq,R,N,V_currentState
setDeviceId:
isSecondPassRunning
setIsSecondPassRunning:
firstPassMyriadGoodnessScore
setFirstPassMyriadGoodnessScore:
_isSecondPassRunning
_firstPassMyriadGoodnessScore
_deviceId
T@"NSString",&,N,V_deviceId
TB,N,V_isSecondPassRunning
Tf,N,V_firstPassMyriadGoodnessScore
pendingSecondPassTriggerWasClearedForClient:deviceId:
_clearPendingRemoraVoiceTrigger
voiceTriggerDidDetectKeyword:deviceId:completion:
_clearPendingBuiltInVoiceTrigger
enumerateKeysAndObjectsUsingBlock:
isBultInVoiceTriggerEvent:
isRemoraVoiceTriggerEvent:
voiceTriggerDidDetectKeyword:deviceId:
handlePendingRemoraVoiceTriggerIfNeeded
handlePendingBuiltInVoiceTriggerIfNeeded
voiceTriggerDidDetectNearMiss:deviceId:
voiceTriggerDidDetectSpeakerReject:
keywordDetectorDidDetectKeyword
voiceTriggerGotSuperVector:
raiseToSpeakDetected:
voiceTriggerDidRejected:deviceId:
setBuiltInVoiceTriggerMetaData:
accessoryVoiceTriggerMetaDataByDeviceId
voiceTriggerDidDetectKeyword:myriadHash:remoteTriggerType:remoteDeviceId:isTriggeredFromFullWake:completion:
secondPassDidStartForClient:deviceId:withFirstPassEstimate:
secondPassDidStopForClient:deviceId:
initWithTargetQueue:
_getHighestRemoraFirstPassGoodnessScore:
_isRemoraSecondPassRunning
builtInSeconPassProgressProvider
setBuiltInSeconPassProgressProvider:
remoraSecondPassProgressProvider
setRemoraSecondPassProgressProvider:
targetQueue
setTargetQueue:
pendingRemoraVoiceTriggerResult
setPendingRemoraVoiceTriggerResult:
pendingRemoraVoiceTriggerDeviceId
setPendingRemoraVoiceTriggerDeviceId:
pendingRemoraVoiceTriggerCompletionBlk
setPendingRemoraVoiceTriggerCompletionBlk:
pendingRemoraVoiceTriggerDetectedTime
setPendingRemoraVoiceTriggerDetectedTime:
pendingBuiltInVoiceTriggerResult
setPendingBuiltInVoiceTriggerResult:
pendingBuiltInVoiceTriggerCompletionBlk
setPendingBuiltInVoiceTriggerCompletionBlk:
pendingBuiltInVoiceTriggerDetectedTime
setPendingBuiltInVoiceTriggerDetectedTime:
builtInVoiceTriggerMetaData
setAccessoryVoiceTriggerMetaDataByDeviceId:
_builtInSeconPassProgressProvider
_remoraSecondPassProgressProvider
_targetQueue
_pendingRemoraVoiceTriggerResult
_pendingRemoraVoiceTriggerDeviceId
_pendingRemoraVoiceTriggerCompletionBlk
_pendingRemoraVoiceTriggerDetectedTime
_pendingBuiltInVoiceTriggerResult
_pendingBuiltInVoiceTriggerCompletionBlk
_pendingBuiltInVoiceTriggerDetectedTime
_builtInVoiceTriggerMetaData
_accessoryVoiceTriggerMetaDataByDeviceId
T@"NSObject<OS_dispatch_queue>",&,N,V_targetQueue
T@"NSDictionary",&,N,V_pendingRemoraVoiceTriggerResult
T@"NSString",&,N,V_pendingRemoraVoiceTriggerDeviceId
T@?,C,N,V_pendingRemoraVoiceTriggerCompletionBlk
TQ,N,V_pendingRemoraVoiceTriggerDetectedTime
T@"NSDictionary",&,N,V_pendingBuiltInVoiceTriggerResult
T@?,C,N,V_pendingBuiltInVoiceTriggerCompletionBlk
TQ,N,V_pendingBuiltInVoiceTriggerDetectedTime
T@"CSPreMyriadVoiceTriggerMetaData",&,N,V_builtInVoiceTriggerMetaData
T@"NSMutableDictionary",&,N,V_accessoryVoiceTriggerMetaDataByDeviceId
T@"<CSVoiceTriggerDelegate>",W,N,V_delegate
T@"<CSSecondPassProgressProviding>",W,N,V_builtInSeconPassProgressProvider
T@"<CSSecondPassProgressProviding>",W,N,V_remoraSecondPassProgressProvider
pingpong:completion:
runVTSecondPassModelWithConfig:locale:withUrl:completion:
runLstmPhsModelWithConfig:withUrl:completion:
runOSDAnalyzerWithConfig:withUrl:completion:
isAttentiveSiriAudioLoggingEnabled
mhLogDirectory
fileExistsAtPath:
speechPackage
getTranscriptionForSpeechPackage:
acousticFTMScores
inputOrigin
didDetectSpeechActivity
timeSinceLastQuery
isAirpodsConnected
boronScore
decisionStage
prevStageOutput
speakerIDScore
timeStampString
addEntriesFromDictionary:
latticeMitigatorResult
nldaMetaInfo
dataWithJSONObject:options:error:
writeToFile:options:error:
logMitigationFeatures:forTask:withModelOutput:forMHRequestId:
endpointTime
setEndpointTime:
endPointerMetrics
setEndPointerMetrics:
_endpointTime
_endPointerMetrics
Td,N,V_endpointTime
T@"CSEndpointerMetrics",&,N,V_endPointerMetrics
supportHybridEndpointer
setEndpointerDelegate:
attSiriNode:didDetectHardEndpointAtTime:withMetrics:
attSiriNode:didDetectStartpointAtTime:
stopEndpointer
resetForNewRequestWithSampleRate:recordContext:recordOption:voiceTriggerInfo:
endPointAnalyzerType
isVoiceTriggered
unsignedLongLongValue
setFirstPktLatency:
resetForVoiceTriggerTwoShotWithSampleRate:
recordingStoppedForReason:
processAudioSamplesAsynchronously:
endpointerModelVersion
processASRFeatures:fromServer:
processServerEndpointFeatures:
updateEndpointerThreshold:
updateEndpointerDelayedTrigger:
shouldAcceptEagerResultForDuration:resultsCompletionHandler:
logHybridEndpointFeaturesWithEvent:locale:
setStartWaitTime:
setEndWaitTime:
setAutomaticEndpointingSuspensionEndTime:
setEndpointerOperationMode:
fetchCurrentEndpointerOperationMode
elapsedTimeWithNoSpeech
trailingSilenceDurationAtEndpoint
processTaskString:
processOSDFeatures:withFrameDurationMs:
processFirstAudioPacketTimestamp:firstAudioSampleSensorTimestamp:
logAnchorMachAbsTime:numSamplesProcessedBeforeAnchorTime:isAnchorTimeBuffered:
wasBuffered
hostTime
arrivalHostTimeToAudioRecorder
addPktInfoWithTimestamp:arrivalTimestamp:currentMachTime:
reportWithRequestMHUUID:
_reportHardEndpointToXPCClientWithTime:endpointerMetrics:
endpointerListener
notifyClientsWithBlock:
didDetectStartpointAtTime:
totalAudioRecorded
endpointBufferHostTime
featuresAtEndpoint
endpointerType
serverFeatureLatencyDistribution
additionalMetrics
didDetectHardEndpointAtTime:withTotalAudioRecorded:endpointBufferHostTime:featuresAtEndpoint:endpointerType:serverFeatureLatencyDistribution:additionalMetrics:
endpointer:didDetectStartpointAtTime:
endpointer:didDetectHardEndpointAtTime:withMetrics:
attSiriNode:didUpdateOSDFeatures:withFrameDurationMs:
attSiriNode:didDetectStartOfSpeechAt:
attSiriNode:didDetectEndOfSpeechAt:
attSiriNode:didUpdateFirstAudioPacketTimestamp:firstAudioSampleSensorTimestamp:firstAudioStartSampleCount:
attSiriNode:didUpdateAnchorMachAbsTime:numSamplesProcessedBeforeAnchorTime:isAnchorTimeBuffered:
processServerFeaturesWithWordCount:trailingSilenceDuration:eosLikelihood:pauseCounts:silencePosterior:taskName:processedAudioDurationInMilliseconds:
getEndpointerModelVersionWithReply:
getElapsedTimeNoSpeechWithReply:
getTrailingSilenceDurationAtEndpointWithReply:
getEndPointAnalyzerTypeWithReply:
getUsesAutomaticEndpointing
processASRFeaturesWithWordCount:trailingSilenceDuration:eosLikelihood:pauseCounts:silencePosterior:taskName:processedAudioDurationInMilliseconds:fromServer:
setEndpointerListener:
proxy
setProxy:
endpointLatencyQueue
setEndpointLatencyQueue:
isNNVAD
setIsNNVAD:
endpointLatencyInfo
setEndpointLatencyInfo:
cachedEndpointerInfo
setCachedEndpointerInfo:
_isNNVAD
_endpointerListener
_proxy
_endpointLatencyQueue
_endpointLatencyInfo
_cachedEndpointerInfo
T@"CSEndpointerProxy",&,N,V_proxy
T@"NSObject<OS_dispatch_queue>",&,N,V_endpointLatencyQueue
TB,N,V_isNNVAD
T@"CSEndpointLatencyInfo",&,N,V_endpointLatencyInfo
T@"CSAttSiriCachedEndpointInfo",&,N,V_cachedEndpointerInfo
T@"CSConnectionListener",&,N,V_endpointerListener
initWithAudioURL:withScaleFactor:outASBD:
audioURL
outASBD
setOutASBD:
fFile
setFFile:
scaleFactor
_scaleFactor
_audioURL
_fFile
T@"NSURL",R,N,V_audioURL
T{AudioStreamBasicDescription=dIIIIIIII},N,V_outASBD
T^{OpaqueExtAudioFile=},N,V_fFile
Tf,R,N,V_scaleFactor
_addSmartSiriVolumeEnabledConditions
_subscribeEventMonitors
subscribeEventMonitor:
getAudioSessionState
addConditions:
csAudioProcessingQueuePriority
getFixedHighPrioritySerialQueueWithLabel:priority:
_refreshSpeakerRecognitionAssets
_setupSSRControllerWithAudioContext:withVoiceTriggerEventInfo:
_stopProcessing
attSiriNode:didUpdateWithSpeakerInfo:
attSiriNode:ssrFinishedProcessingWithSpeakerInfo:
siriProfileId
predicateWithBlock:
filteredArrayUsingPredicate:
getSiriLanguageWithFallback:
objectAtIndexedSubscript:
assetProvider
containsMultiUserThresholds
configVersion
provisionedVoiceProfilesForAppDomain:withLocale:
filteredVoiceProfileArray:
arrayByAddingObjectsFromArray:
_setupSpeakerRecognitionForProfiles:WithVTEventInfo:WithLocale:
isBuiltInVoiceTriggered
initWithVoiceRecognitionContext:error:
initWithContext:withDelegate:error:
array
sharedManager
allInstalledAssetsOfType:language:
assetOfType:providerType:language:completion:
_processSpeakerRecognitionResult:
unsignedIntValue
didReceiveSpeakerRecognitionScoreCard:
didFinishSpeakerRecognition:
_mapScoresToSharedSiriId:
voiceProfileForId:
endAudio
newVoiceProfileWithLocale:withAppDomain:
initWithVoiceRetrainingContext:error:
profileID
fileURLWithPath:
addUtterances:toProfile:withContext:withCompletion:
triggerVoiceProfileCleanupWithCompletion:
convertToShortLPCMBufFromFloatLPCMBuf:
processAudio:withNumberOfSamples:
addSamples:numSamples:
speakerRecognitionController:hasSpeakerInfo:
speakerRecognitionFinishedProcessing:withFinalSpeakerInfo:
startXPCConnection
resetForNewRequestWithRecordContext:voiceTriggerInfo:
ssrListener
setSsrListener:
shouldCleanupVoiceProfile
setShouldCleanupVoiceProfile:
ssrController
setSsrController:
voiceProfileManager
setVoiceProfileManager:
ccProfile
setCcProfile:
leadingUtteranceAudioFile
setLeadingUtteranceAudioFile:
leadingUtteranceLogger
setLeadingUtteranceLogger:
asset
setAsset:
ssrAssets
setSsrAssets:
audioRecordContext
setAudioRecordContext:
voiceTriggerEventInfo
setVoiceTriggerEventInfo:
speakerRecognitionScores
setSpeakerRecognitionScores:
_shouldCleanupVoiceProfile
_ssrListener
_ssrController
_voiceProfileManager
_ccProfile
_leadingUtteranceAudioFile
_leadingUtteranceLogger
_asset
_ssrAssets
_audioRecordContext
_voiceTriggerEventInfo
_speakerRecognitionScores
T@"SSRSpeakerRecognitionController",&,N,V_ssrController
T@"SSRVoiceProfileManager",&,N,V_voiceProfileManager
T@"SSRVoiceProfile",&,N,V_ccProfile
T@"NSString",&,N,V_leadingUtteranceAudioFile
T@"<CSAudioFileWriter>",&,N,V_leadingUtteranceLogger
T@"CSAsset",&,N,V_asset
T@"NSArray",&,N,V_ssrAssets
T@"CSAudioRecordContext",&,N,V_audioRecordContext
T@"NSDictionary",&,N,V_voiceTriggerEventInfo
T@"NSDictionary",&,N,V_speakerRecognitionScores
T@"CSConnectionListener",&,N,V_ssrListener
TB,N,V_shouldCleanupVoiceProfile
sharedConnection
_checkSiriRestrictedOnLockScreen
effectiveBoolValueForSetting:
_notifyObserver:withRestricted:
CSSiriRestrictionOnLockScreenMonitor:didReceiveRestrictionChanged:
_didReceiveRestrictionChanged:
profileConnectionDidReceiveRestrictionChangedNotification:userInfo:
profileConnectionDidReceivePasscodeChangedNotification:userInfo:
profileConnectionDidReceivePasscodePolicyChangedNotification:userInfo:
profileConnectionDidReceiveProfileListChangedNotification:userInfo:
profileConnectionDidReceiveEffectiveSettingsChangedNotification:userInfo:
profileConnectionDidReceiveDefaultsChangedNotification:userInfo:
profileConnectionDidReceiveAppWhitelistChangedNotification:userInfo:
isRestricted
_didReceiveRestrictionChangedInQueue:
_isRestricted
createAudioInjectionDeviceWithType:deviceName:deviceID:productID:completion:
injectAudio:toDeviceWithUUID:withScaleFactor:completion:
connectDeviceWithUUID:completion:
disconnectDeviceWithUUID:completion:
primaryInputDeviceUUIDWithCompletion:
isFirstUnlocked
isEnabled
_performPostBuildInstallWithCompletion:
numberWithLong:
sharedService
registerPostBuildInstallService
sharedController
defaultController
addVTRejectEntry:truncateData:
addVTAcceptEntryAndSubmit:
_recognizeWavData:length:
keywordAnalyzerQuasar:hasResultAvailable:forChannel:
_phraseIdToCtcScoreMap
initWithConfigPath:triggerTokens:useKeywordSpotting:
runRecognition
Td,R,N,V_triggerConfidence
T@"<CSKeywordAnalyzerQuasarScoreDelegate>",W,N,V_delegate
initWithVoiceTriggerAssetDownloadMonitor:languageCodeUpdateMonitor:firstUnlockMonitor:trialAssetDownloadMonitor:assetManager:trialAssetManager:
setCachedAsset:
cachedAsset
defaultFallbackModelIfNil:
_getVoiceTriggerAssetFromAssetManager:
getSiriLanguageWithEndpointId:fallbackLanguage:
_getVoiceTriggerAssetFromAssetManagerWithLocale:completion:
_handleVoiceTriggerAssetWithCompletion:
_handleEndpointVoiceTriggerAsset:completion:
assetOfType:language:completion:
getInstalledAssetofType:forLocale:completion:
path
isEqualAsset:
notifyObservers:endpointId:
cachedEndpointAssets
_checkNewAssetAvailablity
_checkNewAssetAvailablityForEndpoint
CSVoiceTriggerAssetDownloadMonitor:didInstallNewAsset:
CSFirstUnlockMonitor:didReceiveFirstUnlock:
CSLanguageCodeUpdateMonitor:didReceiveLanguageCodeChanged:
setCachedEndpointAssets:
voiceTriggerAssetDownloadMonitor
setVoiceTriggerAssetDownloadMonitor:
languageCodeUpdateMonitor
setLanguageCodeUpdateMonitor:
firstUnlockMonitor
setFirstUnlockMonitor:
trialAssetDownloadMonitor
setTrialAssetDownloadMonitor:
assetManager
setAssetManager:
trialAssetManager
setTrialAssetManager:
_cachedAsset
_cachedEndpointAssets
_voiceTriggerAssetDownloadMonitor
_languageCodeUpdateMonitor
_firstUnlockMonitor
_trialAssetDownloadMonitor
_assetManager
_trialAssetManager
T@"CSAsset",&,V_cachedAsset
T@"NSMutableDictionary",&,V_cachedEndpointAssets
T@"CSVoiceTriggerAssetDownloadMonitor",&,N,V_voiceTriggerAssetDownloadMonitor
T@"CSLanguageCodeUpdateMonitor",&,N,V_languageCodeUpdateMonitor
T@"CSFirstUnlockMonitor",&,N,V_firstUnlockMonitor
T@"CSTrialAssetDownloadMonitor",&,N,V_trialAssetDownloadMonitor
T@"CSAssetManager",&,N,V_assetManager
T@"CSTrialAssetManager",&,N,V_trialAssetManager
decodeObjectOfClass:forKey:
encodeObject:forKey:
numberWithUnsignedLongLong:
setCtx:
detectedToken
setDetectedToken:
triggerMachTime
setTriggerMachTime:
triggerAbsStartSampleId
setTriggerAbsStartSampleId:
_ctx
_detectedToken
_triggerMachTime
_triggerAbsStartSampleId
T@"CSAttSiriRequestContext",C,N,V_ctx
T@"NSString",&,N,V_detectedToken
TQ,N,V_triggerMachTime
TQ,N,V_triggerAbsStartSampleId
setSkipAlertBehavior:
noAlertOption
requestHistoricalAudioDataSampleCount
setRequestHistoricalAudioDataSampleCount:
requestHistoricalAudioDataWithHostTime
setRequestHistoricalAudioDataWithHostTime:
setStartRecordingHostTime:
startRecordingSampleCount
setStartRecordingSampleCount:
useOpportunisticZLL
setUseOpportunisticZLL:
requireSingleChannelLookup
setRequireSingleChannelLookup:
selectedChannel
setSelectedChannel:
setDisableEndpointer:
setDisableLocalSpeechRecognizer:
setDisablePrewamLocalSpeechRecognizer:
setRequestMHUUID:
setSiriSessionUUID:
initTandemWithOption:
estimatedStartHostTime
setEstimatedStartHostTime:
disableEndpointer
disableLocalSpeechRecognizer
disablePrewamLocalSpeechRecognizer
requestMHUUID
siriSessionUUID
_requestHistoricalAudioDataWithHostTime
_requestHistoricalAudioDataSampleCount
_useOpportunisticZLL
_skipAlertBehavior
_requireSingleChannelLookup
_disableEndpointer
_disableLocalSpeechRecognizer
_disablePrewamLocalSpeechRecognizer
_selectedChannel
_startRecordingHostTime
_startRecordingSampleCount
_startAlertBehavior
_stopAlertBehavior
_errorAlertBehavior
_estimatedStartHostTime
_requestMHUUID
_siriSessionUUID
TB,N,V_requestHistoricalAudioDataWithHostTime
TB,N,V_requestHistoricalAudioDataSampleCount
TQ,N,V_startRecordingHostTime
TQ,N,V_startRecordingSampleCount
TB,N,V_useOpportunisticZLL
Tq,N,V_startAlertBehavior
Tq,N,V_stopAlertBehavior
Tq,N,V_errorAlertBehavior
TB,N,V_skipAlertBehavior
T@"NSObject<OS_xpc_object>",R,N
T@"NSString",R,N
TB,N,V_requireSingleChannelLookup
TI,N,V_selectedChannel
TQ,N,V_estimatedStartHostTime
TB,N,V_disableEndpointer
TB,N,V_disableLocalSpeechRecognizer
TB,N,V_disablePrewamLocalSpeechRecognizer
T@"NSString",&,N,V_requestMHUUID
T@"NSString",&,N,V_siriSessionUUID
_update
didTriggerWithSecondChanceEnabled:
initWithPhraseInfoDict:useKeywordSpotting:
updateWithNdapiResult:
updateWithCtcScore:
effectiveThresholdWithSecondChanceEnabled:
hasNearMissTriggerWithSecondChanceEnabled:
dictionaryRepresentationWithSecondChanceEnabled:
phId
setPhId:
phStr
setPhStr:
threshold
setThreshold:
secondChanceThreshold
setSecondChanceThreshold:
loggingThreshold
setLoggingThreshold:
useKwdSpotting
setUseKwdSpotting:
recognizerScoreScaleFactor
setRecognizerScoreScaleFactor:
recognizerThresholdOffset
setRecognizerThresholdOffset:
satThreshold
setSatThreshold:
tdsrSatCombinedSATThreshold
setTdsrSatCombinedSATThreshold:
ndapiScore
setNdapiScore:
ctcCheckerScore
setCtcCheckerScore:
combinedScore
setCombinedScore:
isMaximized
setIsMaximized:
ndapiResult
setNdapiResult:
_useKwdSpotting
_isMaximized
_threshold
_secondChanceThreshold
_loggingThreshold
_recognizerScoreScaleFactor
_recognizerThresholdOffset
_satThreshold
_tdsrSatCombinedSATThreshold
_ndapiScore
_ctcCheckerScore
_combinedScore
_phId
_phStr
_ndapiResult
TQ,N,V_phId
T@"NSString",&,N,V_phStr
Tf,N,V_threshold
Tf,N,V_secondChanceThreshold
Tf,N,V_loggingThreshold
TB,N,V_useKwdSpotting
Tf,N,V_recognizerScoreScaleFactor
Tf,N,V_recognizerThresholdOffset
Tf,N,V_satThreshold
Tf,N,V_tdsrSatCombinedSATThreshold
Tf,N,V_ndapiScore
Tf,N,V_ctcCheckerScore
Tf,N,V_combinedScore
TB,N,V_isMaximized
T@"CSKeywordAnalyzerNDAPIResult",&,N,V_ndapiResult
VTSecondPassCategoryForFirstPassSource:
supportedVTPhrasesInfoForCategory:
VTSecondPassUseKeywordSpottingFrom:
arrayWithCapacity:
numberWithUnsignedLong:
string
initWithAsset:firstPassSource:
updateWithNdapiResults:
updateWithCtcCheckerResults:
getTriggeredPhraseWithSecondChanceEnabled:
getNearMissPhraseWithSecondChanceEnabled:
bestScoringPhrase
phraseMap
setPhraseMap:
triggeredPhrase
setTriggeredPhrase:
_phraseMap
_triggeredPhrase
T@"CSVTSecondPassPhraseScore",&,N,V_triggeredPhrase
T@"NSDictionary",&,N,V_phraseMap
getCoreSpeechXPCConnection
remoteObjectProxy
installedVoiceTriggerAssetForLanguageCode:completion:
fetchRemoteVoiceTriggerAssetForLanguageCode:completion:
getCoreSpeechServiceConnection
getCurrentVoiceTriggerLocaleWithEndpointId:completion:
voiceTriggerRTModelForVersion:minorVersion:accessoryRTModelType:endpointId:downloadedModels:preinstalledModels:completion:
voiceTriggerRTModelForVersion:minorVersion:accessoryRTModelType:locale:endpointId:downloadedModels:preinstalledModels:completion:
voiceTriggerRTModelForVersion:minorVersion:locale:downloadedModels:preinstalledModels:completion:
voiceTriggerJarvisLanguageList:jarvisSelectedLanguage:completion:
requestUpdatedSATAudio:
getFirstPassRunningMode:
voiceTriggerRTModelForVersion:minorVersion:accessoryRTModelType:downloadedModels:preinstalledModels:completion:
voiceTriggerRTModelForVersion:minorVersion:downloadedModels:preinstalledModels:completion:
requestUpdatedSATAudio
getFirstPassRunningMode
assetChangeMonitorDidDetectAssetChange:
sharedMonitor
startMonitoring
notifyVoiceTriggerAssetChanged
T@"<CSVoiceTriggerAssetChangeDelegate>",W,N,V_delegate
_didReceiveMediaserverNotification:
_notifyObserver:withMediaserverState:
audioServerCrashEventProvidingLostMediaserverd
_mediaserverdDidRestart
serverState
setServerState:
_serverState
TQ,N,V_serverState
rootQueueWithFixedPriority:
_sendXPCClientType
_disconnect
_sendMessageAsync:completion:
sendMessageAndReplySync:error:
sendMessageAsync:completion:
setAudioSessionProvidingDelegate:
setAudioAlertProvidingDelegate:
_cs_initWithXPCObject:
createPrepareAudioStreamMessageWithRequest:
createStartAudioStreamMessageWithOption:
createStopAudioStreamMessage
isRTSTriggered
_handleListenerMessage:
_handleSessionProvidingDelegateMessageBody:
_handleStreamProvidingDelegateMessageBody:
_handleAlertProvidingDelegateMessageBody:
_handleSessionInfoProvidingDelegateMessageBody:
_handleListenerDisconnectedError:
CSXPCClient:didDisconnect:
_handleAlertProvidingDelegateDidFinishAlertPlayback:
audioAlertProvidingDelegate
audioAlertProvidingDidFinishAlertPlayback:ofType:error:
_handleSessionProvidingDelegateBeginInterruption:
_handleSessionProvidingDelegateBeginInterruptionWithContext:
_handleSessionProvidingDelegateEndInterruption:
_handleSessionProvidingDelegateWillSetAudioSession:
_handleSessionProvidingDelegateDidSetAudioSession:
_handleSessionProvidingDelegateStreamHandleIdInvalidation:
_handleSessionProvidingDelegateDidChangeContext:
audioSessionProvidingDelegate
audioSessionProviderBeginInterruption:
audioSessionProviderBeginInterruption:withContext:
audioSessionProviderEndInterruption:
audioSessionProvider:willSetAudioSessionActive:
audioSessionProvider:didSetAudioSessionActive:
audioSessionProvider:providerInvalidated:
audioSessionProvider:didChangeContext:
_handleSessionInfoProvidingDelegateInterruptionNotification:
_handleSessionInfoProvidingDelegateRouteChangeNotification:
_handleSessionInfoProvidingDelegateMediaServicesWereLostNotification:
_handleSessionInfoProvidingDelegateMediaServicesWereResetNotification:
_handleStreamProvidingDelegateDidStopUnexpectly:
_handleStreamProvidingDelegateChunkAvailable:
_handleStreamProvidingDelegateChunkForTVAvailable:
_handleStreamProvidingDelegateHardwareConfigChange:
createAudioStreamMessageWithRequest:
setAudioSessionDelegate:
prewarmAudioSessionWithError:
activateAudioSessionWithReason:dynamicAttribute:bundleID:error:
duckOthersOption
setDuckOthersOption:
enableMiniDucking:
enableSmartRoutingConsideration:
reportsDynamicActivityAttribute:bundleId:
audioStreamId
audioStreamWithRequest:streamName:completion:
attachTandemStream:toPrimaryStream:completion:
prepareAudioStreamSync:request:error:
prepareAudioStream:request:completion:
startAudioStream:option:completion:
stopAudioStream:option:completion:
audioChunkFrom:to:
audioChunkFrom:to:channelIdx:
audioChunkToEndFrom:
audioChunkToEndFrom:channelIdx:
saveRecordingBufferFrom:to:toURL:
saveRecordingBufferToEndFrom:toURL:
holdAudioStreamWithDescription:timeout:
cancelAudioStreamHold:
setAnnounceCallsEnabled:withStreamHandleID:
setAudioAlertDelegate:
setAlertSoundFromURL:forType:
playAlertSoundForType:
playRecordStartingAlertAndResetEndpointer
alertStartTime
configureAlertBehavior:
setMeteringEnabled:
updateMeters
peakPowerForChannel:
averagePowerForChannel:
audioMetric
hostTimeFromSampleCount:
sampleCountFromHostTime:
triggerInfoForContext:completion:
isConnected
disconnect
prepareAudioProviderWithContext:clientType:error:
pingpong:
acousticSLResultForContext:completion:
audioStreamProvidingDelegate
setAudioStreamProvidingDelegate:
xpcReplyQueue
setXpcReplyQueue:
xpcClientQueue
setXpcClientQueue:
audioSessionInfoObservers
setAudioSessionInfoObservers:
xpcClientType
setXpcClientType:
_audioSessionProvidingDelegate
_audioStreamProvidingDelegate
_audioAlertProvidingDelegate
_UUID
_xpcReplyQueue
_xpcClientQueue
_audioSessionInfoObservers
_xpcClientType
T@"NSObject<OS_dispatch_queue>",&,N,V_xpcReplyQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_xpcClientQueue
T@"NSHashTable",&,N,V_audioSessionInfoObservers
TQ,N,V_xpcClientType
T@"<CSAudioSessionProvidingDelegate>",W,N,V_audioSessionProvidingDelegate
T@"<CSAudioStreamProvidingDelegate>",W,N,V_audioStreamProvidingDelegate
T@"<CSAudioAlertProvidingDelegate>",W,N,V_audioAlertProvidingDelegate
T@"<CSXPCClientDelegate>",W,N,V_delegate
T@"NSString",R,N,V_UUID
receiveOpportuneSpeakListenerStart
receiveOpportuneSpeakListenerStop
startListenWithOption:completion:
stopListenWithCompletion:
opportuneSpeakListener:hasRemoteVADAvailable:
opportuneSpeakListener:hasVADAvailable:
opportuneSpeakListener:hasVADAvailable:withHostTime:
opportuneSpeakListener:didStopUnexpectly:
listener
initializeTimerState
timerState
_timerFiringState
initWithAudioDeviceID:
sharedSession
currentInputDeviceUIDArray
currentInputRoute
currentOutputRoute
_inputRoute
_outputRoute
deviceName
isBluetooth
source
destination
_isBluetooth
_deviceName
_uid
_source
_destination
T@"NSString",R,C,N,V_deviceName
T@"NSString",R,C,N,V_uid
TB,R,N,V_isBluetooth
T@"NSString",R,C,N,V_source
T@"NSString",R,C,N,V_destination
opportuneSpeakEventMonitor:didStreamStateChanged:
_notifyStopOpportuneSpeakWithDelay:
opportuneSpeakBehaviorMonitor:willStartStreamWithContext:audioProviderUUID:option:
opportuneSpeakBehaviorMonitor:didStartStreamWithContext:audioProviderUUID:successfully:option:
opportuneSpeakBehaviorMonitor:willStopStream:
opportuneSpeakBehaviorMonitor:didStopStream:
audioProviderUUID
isOpportuneSpeakListening
setIsOpportuneSpeakListening:
setAudioProviderUUID:
token
setToken:
_isOpportuneSpeakListening
_audioProviderUUID
_token
TB,N,V_isOpportuneSpeakListening
T@"NSString",&,N,V_audioProviderUUID
T@"NSUUID",&,N,V_token
_receivedNewAssetUpdate:
voiceTriggerAssetHandler:endpointId:didChangeCachedAsset:
getMitigationAssetWithEndpointId:completion:
_checkPhraseSpotterEnabled
_notifyObserver:withEnabled:
CSPhraseSpotterEnabledMonitor:didReceiveEnabled:
phraseSpotterEnabled
_didReceivePhraseSpotterSettingChangedInQueue:
_phraseSpotterEnabledDidChange
_isPhraseSpotterEnabled
notifyInEarMyriadTrigger
isModelBenchmarkingEnabled
initWithMachServiceName:
setExportedInterface:
xpcConnection:hasEntitlement:
setExportedObject:
listener:shouldAcceptNewConnection:
listen
_listener
_exportedObject
resourcePath
getStringForKey:category:default:
progCheckerConfigFile
decodeJson:
initWithArray:
_mapInputOriginFromAssetToCSAudioRecordType:
boolValue
contConvConfigFile
keysOfEntriesPassingTest:
supportedInputOrigins
checkerThresholds
progCheckerShadowMode
contConvThresholds
TB,R,N
_notifyObserver:withLanguageCode:
_didReceiveLanguageCodeUpdate
notifySiriLanguageCodeChanged:
generateEmptyPHash:writeFile:
notifyHashlessTrigger:
setLastHash:
lastHash
T@"NSData",C
generatePHashFromVoiceTriggerInfo:writeFile:
pHash:length:
signalEstimate
setSignalEstimate:
signalFractional
setSignalFractional:
_signalFractional
_signalEstimate
Ts,N,V_signalEstimate
TC,N,V_signalFractional
_handleNewRemoteConnection:
machXPCConnection:hasEntitlement:
initWithConnection:
activateConnection
CSVoiceTriggerXPCConnectionReceivedClientError:clientError:client:
setListener:
connections
setConnections:
_connections
T@"NSObject<OS_xpc_object>",&,N,V_listener
T@"NSMutableArray",&,N,V_connections
_servicesListenerShouldAcceptNewConnection:
setDelayInterstitialSounds:level:completion:
getTriggerCount:
clearTriggerCount:
getTestResponse:
gibraltarVoiceTriggerHandler
setGibraltarVoiceTriggerHandler:
servicesListener
setServicesListener:
_gibraltarVoiceTriggerHandler
_servicesListener
T@"NSXPCListener",&,N,V_servicesListener
T@"CSGibraltarVoiceTriggerHandler",&,N,V_gibraltarVoiceTriggerHandler
setName:
_name
T@"NSString",&,N,V_name
estimatedUserSpeakingStartedHostTime
estimatedUserSpeakingEndedHostTime
_reportUEIUserSpeakingContext
initWithRequestMHUUID:turnIdentifier:
setSpeechRecognizedContext:withEndpointerMetrics:
reportEndpointDelayIfNeed
endpointTimeInMs
setEndpointTimeInMs:
userSpeakingStartedTimeInMs
setUserSpeakingStartedTimeInMs:
userSpeakingEndedTimeInMs
setUserSpeakingEndedTimeInMs:
setEndpointBufferHostTime:
userSpeakingStartedHostTime
setUserSpeakingStartedHostTime:
userSpeakingEndedHostTime
setUserSpeakingEndedHostTime:
stopRecordingHostTime
setStopRecordingHostTime:
turnIdentifier
setTurnIdentifier:
didReportEndpointDelay
setDidReportEndpointDelay:
_didReportEndpointDelay
_endpointTimeInMs
_userSpeakingStartedTimeInMs
_userSpeakingEndedTimeInMs
_endpointBufferHostTime
_userSpeakingStartedHostTime
_userSpeakingEndedHostTime
_stopRecordingHostTime
_turnIdentifier
Td,N,V_endpointTimeInMs
Td,N,V_userSpeakingStartedTimeInMs
Td,N,V_userSpeakingEndedTimeInMs
TQ,N,V_endpointBufferHostTime
TQ,N,V_userSpeakingStartedHostTime
TQ,N,V_userSpeakingEndedHostTime
TQ,N,V_stopRecordingHostTime
T@"NSUUID",&,N,V_turnIdentifier
TB,N,V_didReportEndpointDelay
getNumberForKey:category:default:
getNumElementInBitset:
_getNumberFromASVDictionaryForKey:category:default:
intValue
_adaptiveSiriVolumeDictionary
SSVNoiseLevelChannelBitset
SSVLKFSChannelBitset
SSVEnergyBufferSize
numberWithUnsignedInt:
SSVNoiseLowerPercentile
SSVNoiseUpperPercentile
SSVLKFSLowerPercentile
SSVLKFSUpperPercentile
SSVNoiseTimeConstant
SSVNoiseMicSensitivityOffset
SSVLKFSTimeConstant
SSVLKFSMicSensitivityOffset
SSVNoiseTTSMappingInputRangeLow
SSVNoiseTTSMappingInputRangeHigh
SSVNoiseTTSMappingOutputRangeLow
SSVNoiseTTSMappingOutputRangeHigh
SSVLKFSTTSMappingInputRangeLow
SSVLKFSTTSMappingInputRangeHigh
SSVLKFSTTSMappingOutputRangeLow
SSVLKFSTTSMappingOutputRangeHigh
SSVUserOffsetInputRangeLow
SSVUserOffsetInputRangeHigh
SSVUserOffsetOutputRangeLow
SSVUserOffsetOutputRangeHigh
SSVTTSVolumeLowerLimitDB
SSVTTSVolumeUpperLimitDB
SSVNoiseWeight
SSVDistanceChannelBitset
SSVNoiseMicSensitivityOffsetDeviceSimple
SSVCAMaxFrameSize
SSVCAVoiceTriggerBasedTTSValidForSeconds
SSVCASmartSiriVolumeUnsyncedMetricLogsToRetain
SSVCASmartSiriVolumeSyncedMetricLogsToRetain
SSVCAVoiceTriggerInitialSilenceDurationSeconds
SSVCADistanceInputBufferDurationSeconds
SSVCAListenPollingIntervalAtStartInSeconds
SSVCADefaultZeroFloatingPointValue
SSVCAAnnouncementStatusFetchTimeoutMs
SSVCADefaultOutputTTSVolume
SSVCANoiseActivityCountThreshold
SSVCASpeakerDistanceFarBoostFactor
SSVCASpeakerDistanceMidBoostFactor
SSVCASpeakerDistanceNearBoostFactor
SSVCADistanceModelConfidenceThreshold
SSVCAMinimumLinearSoundLevel
SSVCAMaximumLinearSoundLevel
SSVCALinearToDecibelConstantMultiplier
SSVCADecibelToLinearLogBase
SSVCASignalToSigmoidNoiseDilationFactor
SSVCASignalToSigmoidMusicDilationFactorDeviceDefault
SSVCASignalToSigmoidMusicDilationFactorDeviceSimple
SSVCASignalToSigmoidSpeechDilationFactor
SSVCASignalToSigmoidNoiseVSpread
SSVCASignalToSigmoidMusicVSpreadDeviceDefault
SSVCASignalToSigmoidMusicVSpreadDeviceSimple
SSVCASignalToSigmoidSpeechVSpread
SSVCASignalToSigmoidNoiseVOffset
SSVCASignalToSigmoidMusicVOffsetDeviceDefault
SSVCASignalToSigmoidMusicVOffsetDeviceSimple
SSVCASignalToSigmoidSpeechVOffset
SSVCASignalToSigmoidNoiseHOffset
SSVCASignalToSigmoidMusicHOffsetDeviceDefault
SSVCASignalToSigmoidMusicHOffsetDeviceSimple
SSVCASignalToSigmoidSpeechHOffset
SSVCASignalToSigmoidMusicSteepnessDeviceDefault
SSVCASignalToSigmoidMusicSteepnessDeviceSimple
SSVCASignalToSigmoidNoiseSteepness
SSVCASignalToSigmoidSpeechSteepness
SSVCADBToTTSMinimumOutput
SSVCADBToTTSMaximumOutput
SSVCADBToTTSTransitionPoint
SSVCADBToTTSPreTransitionOffset
SSVCADBToTTSPreTransitionMultiplier
SSVCADBToTTSPostTransitionOffset
SSVCADBToTTSPostTransitionDC
SSVCADBToTTSPostTransitionMultiplier
SSVCAMinimumDistanceUpdateWaitPeriodSeconds
SSVCANoiseActivityThreshold
SSVCANoiseResultsBufferSize
SSVCAMusicResultsBufferSize
SSVCADefaultSpeechStrength
SSVCADefaultMusicStrength
SSVCANoiseActivityHistoricalSampleCount
SSVCADspCoefsCount
SSVCADspNumStages
SSVCADistanceResultsBufferSize
SSVCAExponentialDistanceHistoryDegradationFactor
SSVCADistanceResultSampleCountTolerance
SSVCAMusicHistoricalSamplesInSeconds
SSVCADeviceSimpleOutputMinTargetDB
SSVCADeviceSimpleOutputMaxTargetDB
SSVCADeviceSimpleOutputSlope
SSVCADeviceSimpleMinTargetDB
SSVCADeviceSimpleMaxTargetDB
SSVCADeviceSimpleDBToSystemVolSlope
SSVCADeviceSimpleMicSensitivityOffset
SSVCADeviceSimplePreTriggerSilenceSampleCount
SSVCAMinTTSSystemVolume
SSVCAMaxTTSSystemVolume
SSVCAUserIntentValidForSeconds
SSVCAUserIntentVolumeIncreaseFactor
SSVCAUserIntentVolumeDecreaseFactor
SSVCAUserIntentPermanentOffsetFactorDelta
SSVCAUserIntentPermanentOffsetFactorLowerBound
SSVCAUserIntentPermanentOffsetFactorUpperBound
SSVCADeviceSimpleMinTTSVolume
SSVCADeviceSimpleMaxTTSVolume
SSVCADeviceDefaultMinTTSVolume
SSVCADeviceDefaultMaxTTSVolume
SSVCADeviceDefaultASVOffMinTTSVolume
SSVCADeviceSimpleASVOffMinTTSVolume
SSVCADeviceDefaultMicSensitivityOffset
SSVCAVolumeHalfLifeSeconds
SSVCAHistoricalVolumeBufferSize
SSVCAMaximumCompensatedSpeechLevelNearField
SSVParameterDirectionary
SSVDefaultNoiseChannelCount
SSVDefaultLKFSChannelCount
SSVDefaultDistanceChannelCount
getSSVDeviceType
TI,R,N
Tf,R,N
Ti,R,N
Td,R,N
programmableAudioInjectionEnabled
containsValueForKey:
initWithData:hash:locale:digest:signature:certificate:
stringByAppendingString:
base64EncodedStringWithOptions:
substringToIndex:
initWithHash:locale:
initWithData:hash:locale:
builtInRTModelDictionary
modelData
modelLocale
modelHash
digest
signature
certificate
_modelData
_modelLocale
_modelHash
_digest
_signature
_certificate
T@"NSData",R,N,V_modelData
T@"NSString",R,N,V_modelLocale
T@"NSString",R,N,V_modelHash
T@"NSData",R,N,V_digest
T@"NSData",R,N,V_signature
T@"NSData",R,N,V_certificate
getFixedPrioritySerialQueueWithLabel:fixedPriority:
setStreamState:
initWithRecordContext:deviceId:shouldUseRemoteRecorder:streamHandleId:
converterForAudioStreamId:
inputRecordingNumberOfChannels
inputRecordingDurationInSecs
initWithNumChannels:recordingDuration:samplingRate:audioTimeConverter:
_holdRecordingExceptionIfNeeded:
_updateRemoteDeviceIdFromAVVCIfNeeded
_streamStateName:
setProviderDelegate:
_setLatestRecordContext:
updateWithLatestRecordContext:
recordDeviceIndicator
isRecordingWithRecordDeviceIndicator:
_canSetContext
audioStreamHandleId
setCurrentContext:streamHandleId:error:
_prepareAudioStreamSync:request:error:
requiresHistoricalBuffer
historicalBufferRequestStreams
_audioStreamWithRequest:streamName:error:
tandemStreams
updateAudioStreamStartTimeInSampleCount:
scheduledFutureSample
setScheduledFutureSample:
startStreamOption
setStartStreamOption:
setStreamRequest:
_handleAudioSystemFailure
prepareAudioStreamRecord:recordDeviceIndicator:error:
isLocalVoiceTriggerAvailable
voiceTriggerInfoWithRecordDeviceIndicator:
setVoiceTriggerInfo:deviceId:
_startAudioStream:option:completion:
_prepareAudioStream:request:completion:
startPendingOnStoppingStreams
startPendingOnStoppingStreamToCompletionDict
sampleCount
_didPlayStartAlertSoundForSiri:audioStream:
alertPlaybackFinishWaitingStreams
alertPlaybackFinishWaitingCompletions
_scheduleAlertFinishTimeout:
isSiri
_switchToRecordingMode
circularBufferStartHostTime
circularBufferStartSampleCount
sampleCountFromHostTime:anchorHostTime:anchorSampleCount:sampleRate:
startPendingStreams
pendingStartCompletions
_holdRecordingTransactionIfNeeded
initWithSampleRate:withNumberOfChannels:
recordingSampleRateWithStreamHandleId:
resetWithSampleRate:containsVoiceTrigger:voiceTriggerInfo:
startAudioStreamWithOption:recordDeviceIndicator:error:
_scheduleAudioPacketWatchDog
_scheduleDidStartRecordingDelegateWatchDog
_resetCircularBufferStartTime
setCircularBufferStartHostTime:
setCircularBufferStartSampleCount:
supportOpportunisticZLL
streams
_deliverHistoricalAudioToStreamsWithRemoteVAD:
setRecordMode:streamHandleId:error:
_cancelAudioPacketWatchDog
_clearDidStartRecordingDelegateWatchDog
_releaseRecordingTransactionIfNeeded
flush
_clearDidStopRecordingDelegateWatchDog
_preEpilogueAudioStream
stopPendingStreams
isWeakStream
pendingStopCompletions
_postEpilogueAudioStream
_shouldHandleStartPendingOnStopping:withStopReason:
objectEnumerator
_stopAudioStream:option:completion:
audioPreprocessor
reportMetricsForSiriRequestWithUUID:
_cs_isHashTableEmpty
_shouldStopRecording
_scheduleDidStopRecordingDelegateWatchDog
stopAudioStreamWithRecordDeviceIndicator:error:
_switchToListeningMode
_audioChunkFrom:to:
_audioChunkFrom:to:channelIdx:
copySamplesFrom:to:
copySamplesFrom:to:channelIdx:
_saveRecordingBufferFrom:to:toURL:
saveAudioChunck:toURL:
streamHolders
recordRouteWithRecordDeviceIndicator:
recordDeviceInfoWithStreamHandleId:recordDeviceIndicator:
audioDeviceInfoWithStreamHandleId:recordDeviceIndicator:
recordSettingsWithStreamHandleId:
setSessionDelegate:
prewarmAudioSessionWithStreamHandleId:error:
_activateAudioSessionWithReason:error:
activateAudioSessionWithReason:streamHandleId:error:
supportNonInterruptibleSiri
setDuckOthersForStream:
_deactivateAudioSession:error:
deactivateAudioSession:streamHandleId:error:
enableSmartRoutingConsiderationForStream:enable:
setAlertDelegate:
playAlertSoundForType:recordDevideIndicator:
playRecordStartingAlertAndResetEndpointerFromStream:
willBeepWithRecordRoute:playbackRoute:
metrics
isVoiceTriggerInfoAvailableLocally:
_processAudioBuffer:remoteVAD:atTime:arrivalTimestampToAudioRecorder:numberOfChannels:
_handleDidStartAudioStreamWithResult:error:
_handleDidStopAudioStreamWithReason:
sessionDelegate
providerDelegate
audioProviderInvalidated:streamHandleId:
bufferLength
lastForwardedSampleCount
_fetchHistoricalAudioAndForwardToStream:remoteVAD:
setRemoteVAD:
audioStreamProvider:audioBufferAvailable:lastForwardedSampleCount:
addSamples:numSamples:atHostTime:
processSampleCount:hostTime:
inputRecordingSampleByteDepth
initWithData:numChannels:numSamples:sampleByteDepth:startSampleCount:hostTime:arrivalHostTimeToAudioRecorder:wasBuffered:remoteVAD:
_forwardAudioChunk:toStream:
chunkForChannel:
secondsToHostTime:
processBuffer:atTime:arrivalTimestampToAudioRecorder:
audioInjectionEnabled
_forwardAudioChunkForTV:toStream:
isNarrowBandWithStreamHandleId:
_didReceiveFinishStartAlertPlaybackAt:
alertDelegate
willDestroy
initWithName:clientQueue:
initWithDescription:
isSessionCurrentlyActivated
beginAnnounceMessageException:reason:
endAnnounceMessageException:reason:
_onAudioPacketWatchdogFire
_schduleDidStartRecordingDelegateWatchDogWithToken:
_scheduleDidStopRecordingDelegateWatchDog:
audioPreprocessor:hasAvailableBuffer:atTime:arrivalTimestampToAudioRecorder:numberOfChannels:
initWithAudioStreamHandleId:audioStreamType:audioRecordContext:audioRecorder:
setAudioProviderDelegate:
setLatestRecordContext:streamType:
_tearDownCircularBufferIfNeeded
notifyProviderContextChanged
recordQueue
setRecordQueue:
loggingQueue
setLoggingQueue:
streamHandleQueue
setStreamHandleQueue:
streamState
setStartPendingStreams:
setStartPendingOnStoppingStreams:
setAlertPlaybackFinishWaitingStreams:
setStreams:
setStopPendingStreams:
setPendingStartCompletions:
setAlertPlaybackFinishWaitingCompletions:
setPendingStopCompletions:
setStartPendingOnStoppingStreamToCompletionDict:
setStreamHolders:
setHistoricalBufferRequestStreams:
circularBuffer
setCircularBuffer:
lastAudioRecorderContext
setLastAudioRecorderContext:
audioSystemRecovering
setAudioSystemRecovering:
setAudioPreprocessor:
recordingTransaction
setRecordingTransaction:
recordingWillStartGroup
setRecordingWillStartGroup:
waitingForAlertFinish
setWaitingForAlertFinish:
setAudioStreamHandleId:
alertPlaybackFinishTimeoutToken
setAlertPlaybackFinishTimeoutToken:
startRecordingWatchDogToken
setStartRecordingWatchDogToken:
stopRecordingWatchDogToken
setStopRecordingWatchDogToken:
audioPacketWatchdog
setAudioPacketWatchdog:
audioTimeConverter
setAudioTimeConverter:
audioStreamType
setAudioStreamType:
setRecordDeviceIndicator:
micUsageReporter
setMicUsageReporter:
audioPacketDeliveryCount
setAudioPacketDeliveryCount:
adpAssertion
setAdpAssertion:
_audioSystemRecovering
_waitingForAlertFinish
_recordQueue
_loggingQueue
_streamHandleQueue
_streamState
_startPendingStreams
_startPendingOnStoppingStreams
_alertPlaybackFinishWaitingStreams
_streams
_stopPendingStreams
_pendingStartCompletions
_alertPlaybackFinishWaitingCompletions
_pendingStopCompletions
_startPendingOnStoppingStreamToCompletionDict
_providerDelegate
_sessionDelegate
_streamHolders
_historicalBufferRequestStreams
_circularBuffer
_alertDelegate
_lastAudioRecorderContext
_audioPreprocessor
_recordingTransaction
_recordingWillStartGroup
_audioStreamHandleId
_alertPlaybackFinishTimeoutToken
_startRecordingWatchDogToken
_stopRecordingWatchDogToken
_audioPacketWatchdog
_circularBufferStartHostTime
_circularBufferStartSampleCount
_audioTimeConverter
_audioStreamType
_recordDeviceIndicator
_micUsageReporter
_audioPacketDeliveryCount
_adpAssertion
T@"NSObject<OS_dispatch_queue>",&,N,V_recordQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_loggingQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_streamHandleQueue
TQ,N,V_streamState
T@"NSHashTable",&,N,V_startPendingStreams
T@"NSHashTable",&,N,V_startPendingOnStoppingStreams
T@"NSHashTable",&,N,V_alertPlaybackFinishWaitingStreams
T@"NSHashTable",&,N,V_streams
T@"NSHashTable",&,N,V_stopPendingStreams
T@"NSMutableArray",&,N,V_pendingStartCompletions
T@"NSMutableArray",&,N,V_alertPlaybackFinishWaitingCompletions
T@"NSMutableArray",&,N,V_pendingStopCompletions
T@"NSMutableDictionary",&,N,V_startPendingOnStoppingStreamToCompletionDict
T@"<CSAudioProviderDelegate>",W,N,V_providerDelegate
T@"<CSAudioSessionProvidingDelegate>",W,N,V_sessionDelegate
T@"NSMutableArray",&,N,V_streamHolders
T@"NSHashTable",&,N,V_historicalBufferRequestStreams
T@"CSAudioCircularBuffer",&,N,V_circularBuffer
T@"<CSAudioAlertProvidingDelegate>",W,N,V_alertDelegate
T@"CSAudioRecordContext",&,N,V_lastAudioRecorderContext
TB,N,V_audioSystemRecovering
T@"CSAudioPreprocessor",&,N,V_audioPreprocessor
T@"CSOSTransaction",&,N,V_recordingTransaction
T@"NSObject<OS_dispatch_group>",&,N,V_recordingWillStartGroup
TB,N,V_waitingForAlertFinish
TQ,N,V_audioStreamHandleId
T@"NSUUID",&,N,V_alertPlaybackFinishTimeoutToken
T@"NSUUID",&,N,V_startRecordingWatchDogToken
T@"NSUUID",&,N,V_stopRecordingWatchDogToken
T@"NSObject<OS_dispatch_source>",&,N,V_audioPacketWatchdog
TQ,N,V_circularBufferStartHostTime
TQ,N,V_circularBufferStartSampleCount
T@"CSAudioTimeConverter",&,N,V_audioTimeConverter
Tq,N,V_audioStreamType
T@"CSAudioRecordDeviceIndicator",&,N,V_recordDeviceIndicator
T@"CSMicUsageReporter",&,N,V_micUsageReporter
TQ,N,V_audioPacketDeliveryCount
T@"CSADPPreventStandbyAssertion",&,N,V_adpAssertion
initWithAppBundleIdentifier:
initWithTaskDeliverer:
initWithMessage:makeAppFrontmost:
handleSiriRequest:deliveryHandler:completionHandler:
launchSiriDebugAppWithMessage:
allowVoiceTriggerAssetDownloading
setAllowVoiceTriggerAssetDownloading:
allowEndpointAssetDownloading
setAllowEndpointAssetDownloading:
allowLanguageDetectorAssetDownloading
setAllowLanguageDetectorAssetDownloading:
allowAdBlockerAssetDownloading
setAllowAdBlockerAssetDownloading:
allowSpeakerRecognitionAssetDownloading
setAllowSpeakerRecognitionAssetDownloading:
allowVoiceTriggerAccessoryAssetDownloading
setAllowVoiceTriggerAccessoryAssetDownloading:
_allowVoiceTriggerAssetDownloading
_allowEndpointAssetDownloading
_allowLanguageDetectorAssetDownloading
_allowAdBlockerAssetDownloading
_allowSpeakerRecognitionAssetDownloading
_allowVoiceTriggerAccessoryAssetDownloading
TB,N,V_allowVoiceTriggerAssetDownloading
TB,N,V_allowEndpointAssetDownloading
TB,N,V_allowLanguageDetectorAssetDownloading
TB,N,V_allowAdBlockerAssetDownloading
TB,N,V_allowSpeakerRecognitionAssetDownloading
TB,N,V_allowVoiceTriggerAccessoryAssetDownloading
_sharedDisposeLoggingQueue
dateWithTimeIntervalSinceNow:
distantFuture
getResourceValue:forKey:error:
compare:
removeItemAtURL:error:
URLsInDirectory:matchingPattern:completion:
_sortedURLsInDirectory:matchingPattern:completion:
_contentsOfDirectoryAtURL:matchingPattern:includingPropertiesForKeys:error:
sortedArrayUsingComparator:
regularExpressionWithPattern:options:error:
contentsOfDirectoryAtURL:includingPropertiesForKeys:options:error:
lastPathComponent
numberOfMatchesInString:options:range:
removeLogFilesInDirectory:matchingPattern:beforeDays:
clearLogFilesInDirectory:matchingPattern:exceedNumber:
initWithTimeout:
_addVoiceTriggerEnabledConditions
isPresent
isSpringboardStarted
batteryState
isScreenLocked
isSoftwareUpdateCheckingRunning
supportHangUp
phoneCallState
hearstConnected
splitterState
preheat
endpointStyle
setEndpointStyle:
delay
setDelay:
startWaitTime
automaticEndpointingSuspensionEndTime
minimumDurationForEndpointer
setMinimumDurationForEndpointer:
lastEndOfVoiceActivityTime
lastStartOfVoiceActivityTime
bypassSamples
setBypassSamples:
endpointMode
setEndpointMode:
interspeechWaitTime
setInterspeechWaitTime:
endWaitTime
saveSamplesSeenInReset
setSaveSamplesSeenInReset:
Tq,N
Td,N
resetForNewRequestWithSampleRate:recordContext:
implDelegate
setImplDelegate:
canProcessCurrentRequest
logFeaturesWithEvent:locale:
handleVoiceTriggerWithActivationInfo:
T@"<CSEndpointAnalyzerDelegate>",W,N
T@"<CSEndpointAnalyzerImplDelegate>",W,N
TQ,N
T@"<CSEndpointAnalyzerDelegate>",W,N,Vdelegate
T@"<CSEndpointAnalyzerImplDelegate>",W,N,VimplDelegate
TB,R,N,VcanProcessCurrentRequest
TQ,N,VactiveChannel
Tq,N,VendpointStyle
Td,N,Vdelay
Td,N,VstartWaitTime
Td,N,VautomaticEndpointingSuspensionEndTime
Td,N,VminimumDurationForEndpointer
Td,R,N,VlastEndOfVoiceActivityTime
Td,R,N,VlastStartOfVoiceActivityTime
T@"NSString",&,N,VmhId
startObserving
getLastBiometricMatchEvent:atTime:
getBiometricMatchResultForTriggerTimeStamp:
T@"<CSBiometricMatchMonitorDelegate>",W,N,V_delegate
_startObservingSpeechDetectionVADPresence
handleSpeechDetectionVADPresentChange:
_systemControllerDied:
phraseId
setPhraseId:
bestPhrase
setBestPhrase:
isEarlyWarning
setIsEarlyWarning:
isRescoring
setIsRescoring:
samplesAtFire
setSamplesAtFire:
setStartSampleCount:
_isEarlyWarning
_isRescoring
_phraseId
_bestPhrase
_samplesAtFire
_startSampleCount
TQ,N,V_phraseId
TQ,N,V_bestPhrase
TB,N,V_isEarlyWarning
TB,N,V_isRescoring
TQ,N,V_samplesAtFire
TQ,N,V_startSampleCount
initWithConfigPath:resourcePath:
_resetStartAnalyzeTime
resetBest
_setStartAnalyzeTime:
analyzeWavFloatData:numSamples:
analyzeWavData:numSamples:
getAnalyzedResultForPhraseId:
sampleFed
getAnalyzedMpVtResults
keywordAnalyzerNDAPI:hasMpVtResultsAvailable:forChannel:
getAnalyzedResult
keywordAnalyzerNDAPI:hasResultAvailable:forChannel:
earlyWarning
_keywordAnalyzerNDAPIResultForPhraseId:withNovDetectorResult:
numResultsAvailable
setObject:atIndexedSubscript:
getSuperVectorWithEndPoint:
getOptionValue:
getThreshold
getLoggingThreshold
getRejectLoggingThreshold
activePhraseId
setActivePhraseId:
_novDetector
_startAnalyzeSampleCount
_isStartSampleCountMarked
_lastSampleFed
_sampleFedWrapAroundOffset
_activePhraseId
TI,N,V_activePhraseId
T@"<CSKeywordAnalyzerNDAPIScoreDelegate>",W,N,V_delegate
createRTModelWithLocale:
hearstRTModelWithMajorVersion:minorVersion:locale:
dataWithContentsOfFile:
_sha1:
substringWithRange:
_sha256:
rtModelWithAccessoryRTModelType:majorVersion:minorVersion:locale:
localeMapWithName:
remoraRTModelLocaleMap
hearstRTModelLocaleMap
stringWithCapacity:
RTModelWithFallbackLanguage:
latestHearstRTModelForLocale:
remoraRTModelWithMajorVersion:minorVersion:locale:
jarvisRTModelLocaleMap
rtModelLocaleMapWithModelType:
isDefaultInputBuiltInMic
isDefaultOutputBultInSpeaker
defaultOutputAudioDeviceID
isTriggerHandheld
wakeGestureTimestamp
setWakeGestureTimestamp:
dismissalTimestamp
setDismissalTimestamp:
_wakeGestureTimestamp
_dismissalTimestamp
TQ,N,V_wakeGestureTimestamp
TQ,N,V_dismissalTimestamp
_fetchHearstConnectionState
_notifyHearstConnectionState:
_fetchJarvisConnectionState
_notifyJarvisConnectionState:
_startObservingAudioRouteChange
CSAudioRouteChangeMonitor:didReceiveAudioRouteChangeEvent:
preferredExternalRouteDidChange:
carPlayAuxStreamSupportDidChange:
carPlayIsConnectedDidChange:
getHearstConnected:
getJarvisConnected:
jarvisConnected
carPlayConnected
_isHearstConnected
_isJarvisConnected
activationMode
activationDeviceUID
announceCallsEnabled
streamID
startHostTime
startAlert
stopAlert
stopOnErrorAlert
skipAlert
remoteVoiceActivityAvailable
remoteVoiceActivityVAD
dataWithBytes:length:
remoteVoiceActivityVADBuffer
getSerialQueue:qualityOfService:
_voiceControllerWithError:
_destroyVoiceController
_audioRecorderDidStartRecordingSuccessfully:streamHandleID:error:
setRecordDelegate:
initWithError:
setSynchronousCallbackEnabled:
setContext:streamType:error:
timeIntervalSinceDate:
setContextForStream:forStream:error:
_getRecordSettingsWithRequest:
shouldUseRemoteRecorder
streamHandleId
_fetchRemoteRecordClientWithDeviceId:streamHandleId:
waitingForConnection:error:
inputRecordingBufferDuration
initWithStreamID:settings:bufferDuration:
prepareRecordForStream:error:
_logResourceNotAvailableErrorIfNeeded:
_shouldInjectAudio
_needResetAudioInjectionIndex:
audioInjectionFilePath
URLWithString:
initWithURL:
setRecordBufferDuration:
requestForLpcmRecordSettingsWithContext:
prepareRecording:
avvcContext
hasPendingTwoShotBeep
_hasLocalPendingTwoShot
playAlertSoundForType:overrideMode:
isRecordContextVoiceTrigger:
contextForBuiltInVoiceTrigger
startRecordingWithOptions:error:
_startAudioStreamForAudioInjectionWithAVVCContext:
startRecordForStream:error:
stopRecording:
stopRecordForStream:error:
getCurrentSessionState
getCurrentStreamState:
isRemoteDeviceGibraltar
getRecordDeviceInfoForStream:
initWithAVVCRecordDeviceInfo:
currentRoute
outputs
endpointType
initWithRecordDeviceInfo:playbackRoute:playbackDeviceTypeList:
getRecordSettingsForStream:
isUpsamplingSourceAudio
activateAudioSessionForStream:isPrewarm:error:
_shouldLogResourceNotAvailableError
activateAudioSessionForStream:isPrewarm:recordMode:error:
_convertDeactivateOption:
deactivateAudioSessionWithOptions:
deactivateAudioSessionForStream:withOptions:error:
setIAmTheAssistant:error:
enableSmartRoutingConsiderationForStream:enable:error:
initWithDuckOthers:duckToLevel:mixWithOthers:
setDuckOverride:
setDuckOthersForStream:withSettings:error:
_updateLanguageCodeForRemoteVTEIResult:
voiceTriggerInfo
channels
packetDescriptionCount
bytesDataSize
initWithCapacity:
packetDescriptions
initWithBytes:length:
setPackets:
updateMeterForStream:
getPeakPowerForStream:forChannel:
getAveragePowerForStream:forChannel:
setPeakPower:
setAvgPower:
setTimeStamp:
setNumChannels:
streamDescription
setAudioFormat:
setStreamHandleID:
_compensateChannelDataIfNeeded:receivedNumChannels:
timeStamp
_processAudioChain:audioStreamHandleId:remoteVAD:atTime:arrivalTimestampToAudioRecorder:numberOfChannels:
opusASBD
lpcmInt16ASBD
addPackets:audioStreamHandleId:remoteVAD:timestamp:arrivalTimestampToAudioRecorder:wasBuffered:receivedNumChannels:
initWithLength:
replaceBytesInRange:withBytes:
didPlayEndpointBeep
_processAudioBuffer:audioStreamHandleId:arrivalTimestampToAudioRecorder:
_audioRecorderDidStopRecordingForReason:streamHandleID:
audioSessionEventProvidingWillSetAudioSessionActive:
audioSessionEventProvidingDidSetAudioSessionActive:
convertToFloatLPCMBufFromShortLPCMBuf:
triggerNotifiedMachTime
useCustomizedRecordSettings
defaultRequestWithContext:
audioFormat
numberOfChannels
sampleRate
lpcmBitDepth
lpcmIsFloat
encoderBitRate
initWithDeviceId:audioStreamHandleId:
createSharedAudioSession
voiceControllerDidStartRecording:successfully:
voiceControllerDidStartRecording:successfully:error:
voiceControllerDidStopRecording:forReason:
voiceControllerDidDetectStartpoint:
voiceControllerDidDetectEndpoint:ofType:
voiceControllerDidDetectEndpoint:ofType:atTime:
voiceControllerEncoderErrorDidOccur:error:
voiceControllerDidFinishAlertPlayback:ofType:error:
voiceControllerDidFinishAlertPlayback:withSettings:error:
voiceControllerRecordHardwareConfigurationDidChange:toConfiguration:
voiceControllerBeginRecordInterruption:
voiceControllerBeginRecordInterruption:withContext:
voiceControllerEndRecordInterruption:
voiceControllerMediaServicesWereLost:
voiceControllerMediaServicesWereReset:
voiceControllerWillSetAudioSessionActive:willActivate:
voiceControllerDidSetAudioSessionActive:isActivated:
voiceControllerRecordBufferAvailable:buffer:
voiceControllerLPCMRecordBufferAvailable:buffer:
voiceControllerWirelessSplitterRouteAvailable:devices:
voiceControllerDidStartRecording:forStream:successfully:error:
voiceControllerDidStopRecording:forStream:forReason:
voiceControllerAudioCallback:forStream:buffer:
voiceControllerLPCMAudioCallback:forStream:buffer:
voiceControllerStreamInvalidated:forStream:
audioDecoderDidDecodePackets:audioStreamHandleId:buffer:remoteVAD:timestamp:arrivalTimestampToAudioRecorder:wasBuffered:receivedNumChannels:
audioFileReaderBufferAvailable:buffer:atTime:
audioFileReaderDidStartRecording:successfully:error:
audioFileReaderDidStopRecording:forReason:
remoteRecordDidStartRecordingWithStreamHandleId:error:
remoteRecordDidStopRecordingWithWithStreamHandleId:error:
remoteRecordLPCMBufferAvailable:streamHandleId:
remoteRecordTwoShotDetectedAtTime:
remoteRecordConnectionDisconnected:
setAudioServerCrashEventDelegate:
setAudioSessionEventDelegate:
initWithQueue:error:
setContext:completion:
setMixWithOthersForStream:
configureAlertBehavior:audioStreamHandleId:
_shouldUseRemoteBuiltInMic:
voiceControllerCreationQueue
setVoiceControllerCreationQueue:
crashEventDelegate
setCrashEventDelegate:
sessionEventDelegate
setSessionEventDelegate:
_voiceController
_interleavedABL
_pNonInterleavedABL
_remoteRecordClient
_opusDecoders
_audioFileReader
_audioFilePathIndex
_waitingForDidStart
_pendingTwoShotVTToken
_voiceControllerCreationQueue
_crashEventDelegate
_sessionEventDelegate
T@"NSObject<OS_dispatch_queue>",&,N,V_voiceControllerCreationQueue
T@"<CSAudioServerCrashEventProvidingDelegate>",W,N,V_crashEventDelegate
T@"<CSAudioSessionEventProvidingDelegate>",W,N,V_sessionEventDelegate
setPrimaryStream:
initTandemWithRequest:
primaryStream
initWithMasterAudioStream:name:
attachToPrimaryStreamWithCompletion:
prepareAudioStreamWithRequest:completion:
_primaryStream
T@"CSAudioStream",W,N,V_primaryStream
initWithAnalyzeMode
fileLoggingIsEnabled
lpcmNonInterleavedWithRemoteVADASBD
lpcmInterleavedWithRemoteVADASBD
createAudioFileWriterForOpportuneSpeakListenerWithInputFormat:outputFormat:
contextForHearstVoiceTriggerWithDeviceId:
opportuneSpeakListeningType
contextForOpportuneSpeakerListener
contextForOpportuneSpeakerListenerWithCall
_resetAlignBuffer
_startRequestWithCompletion:
setRequiresHistoricalBuffer:
getFrameDurationMs
remoteVADDuration
supportsUnderstandingOnDevice
preheatLocalSpeechRecognitionWithLanguage:source:
stopListenWithStateReset:completion:
gainCompensatedChunk
channelForProcessedInput
addAudio:numSamples:
remoteVAD
opportuneSpeakListenerBypassEnabled
_addRemoteVADSignal:
dataWithRemoteVADWithScaleFactor:numAudioSamplesPerRemoteVAD:
removeObjectAtIndex:
_shouldReportBoron
_popRemoteVADSignal
spgEndpointAnalyzer:hasSilenceScoreEstimate:clientProcessedAudioTimeMS:
spgEndpointAnalyzer
setSpgEndpointAnalyzer:
remoteVADSPGRatio
setRemoteVADSPGRatio:
audioStreamProvider
setAudioStreamProvider:
audioSessionProvider
setAudioSessionProvider:
latestContext
setLatestContext:
isMediaPlayingNow
setIsMediaPlayingNow:
remoteVADAlignBuffer
setRemoteVADAlignBuffer:
remoteVADAlignCount
setRemoteVADAlignCount:
alignBufferQueue
setAlignBufferQueue:
audioFileWriter
setAudioFileWriter:
runningSampleCount
setRunningSampleCount:
_isMediaPlayingNow
_remoteVADSPGRatio
_spgEndpointAnalyzer
_audioStreamProvider
_audioSessionProvider
_latestContext
_remoteVADAlignBuffer
_remoteVADAlignCount
_alignBufferQueue
_audioFileWriter
_runningSampleCount
T@"CSSPGEndpointAnalyzer",&,N,V_spgEndpointAnalyzer
Ti,N,V_remoteVADSPGRatio
T@"<CSAudioStreamProviding>",&,N,V_audioStreamProvider
T@"<CSAudioSessionProviding>",&,N,V_audioSessionProvider
T@"CSAudioRecordContext",&,N,V_latestContext
TB,V_isMediaPlayingNow
T@"NSMutableArray",&,N,V_remoteVADAlignBuffer
TQ,N,V_remoteVADAlignCount
T@"NSObject<OS_dispatch_queue>",&,N,V_alignBufferQueue
T@"CSPlainAudioFileWriter",&,N,V_audioFileWriter
TQ,N,V_runningSampleCount
T@"<CSOpportuneSpeakListenerDelegate>",W,N,V_delegate
CSSiriEnabledMonitor:didReceiveEnabled:
_didReceiveSiriSettingChanged:
fetchIsEnabled
_isSiriEnabled
_attachBluetoothSession
_getWirelessSplitterInfoFromLocalDevice:
getBTLocalDeviceWithCompletion:
setSplitterEnabled:
setAddress:
setSupportDoAP:
setIsTemporaryPairedNotInContacts:
addDeviceIntoSplitterDeviceList:
_tearDownLocalDevice
_detachBluetoothSession
_setUpLocalDevice
getWirelessSplitterInfoWithCompletion:
device:serviceMask:serviceEventType:serviceSpecificEvent:result:
_sessionAttached:result:
_sessionDetached:
_sessionTerminated:
localDevice:event:result:
bluetoothSession
setBluetoothSession:
isAttachingBluetoothSession
setIsAttachingBluetoothSession:
localDevice
setLocalDevice:
pairedDeviceAddresses
setPairedDeviceAddresses:
connectedDeviceAddresses
setConnectedDeviceAddresses:
bluetoothSessionSetupGroup
setBluetoothSessionSetupGroup:
_isAttachingBluetoothSession
_bluetoothSession
_localDevice
_pairedDeviceAddresses
_connectedDeviceAddresses
_bluetoothSessionSetupGroup
T^{BTSessionImpl=},N,V_bluetoothSession
TB,N,V_isAttachingBluetoothSession
T^{BTLocalDeviceImpl=},N,V_localDevice
T@"NSArray",&,N,V_pairedDeviceAddresses
T@"NSArray",&,N,V_connectedDeviceAddresses
T@"NSObject<OS_dispatch_group>",&,N,V_bluetoothSessionSetupGroup
triggerModeStringDescription:
setTriggerMode:
getTriggerMode
CSActivationXPCConnectionReceivedClientError:clientError:client:
initWithStreamHandleId:
initWithConfigFile:configRoot:sampleRate:delegate:queue:
resetForNewRequest
_setupAudioInjectionEngineWithAudioURL:
initWithConfigFile:sampleRate:context:queue:delegate:
initWithData:numChannels:numSamples:sampleByteDepth:startSampleCount:hostTime:remoteVAD:
addAudio:
getLatestSuperVector
lpcmInterleavedASBD
stopAudioStream
injectAudio:withScaleFactor:outASBD:playbackStarted:completion:
startAudioStreamWithOption:
audioEngineDidStartRecord:audioStreamHandleId:successfully:error:
audioEngineDidStopRecord:audioStreamHandleId:reason:
audioEngineBufferAvailable:audioStreamHandleId:buffer:remoteVAD:atTime:
audioEngineAudioChunkForTvAvailable:audioChunk:
vtSecondPassAnalyzer
setVtSecondPassAnalyzer:
psrAudioProcessor
setPsrAudioProcessor:
osdAnalyzer
setOsdAnalyzer:
completion
setCompletion:
audioInjectionEngine
setAudioInjectionEngine:
modelExeQueue
setModelExeQueue:
_vtSecondPassAnalyzer
_psrAudioProcessor
_osdAnalyzer
_completion
_audioInjectionEngine
_modelExeQueue
T@"CSSyncKeywordAnalyzerQuasar",&,N,V_vtSecondPassAnalyzer
T@"EARSyncPSRAudioProcessor",&,N,V_psrAudioProcessor
T@"OSDAnalyzer",&,N,V_osdAnalyzer
T@?,C,N,V_completion
T@"CSAudioInjectionEngine",&,N,V_audioInjectionEngine
T@"NSObject<OS_dispatch_queue>",&,N,V_modelExeQueue
initWithProtocolVersion:buildVersion:deviceProductVersion:deviceProductType:deviceCategory:
deviceBuildVersion
deviceProductVersion
deviceProductType
hasRemoteBuiltInMic
defaultProtocolInfo
localDeviceProtocolInfo
protocolVersion
buildVersion
deviceCategory
_protocolVersion
_buildVersion
_deviceProductVersion
_deviceProductType
_deviceCategory
TQ,R,N,V_protocolVersion
T@"NSString",R,N,V_buildVersion
T@"NSString",R,N,V_deviceProductVersion
T@"NSString",R,N,V_deviceProductType
TQ,R,N,V_deviceCategory
getAssetTypeForNamespace:
getTrialIdsForAssetType:withCompletion:
_handleSessionIDRequestMessage:messageBody:client:
audioSessionInfoProvider
setAudioSessionInfoProvider:
_audioSessionInfoProvider
T@"<CSAudioSessionInfoProviding>",W,N,V_audioSessionInfoProvider
supportSmartVolume
getVolumeForTTSType:withContext:reply:
setSmartSiriVolumePercentage:
setSmartSiriVolumeDirection:
setPermanentVolumeOffsetWithDirection:
didTTSVolumeChangeForReason:
initWithMachService:withServiceInterface:withServiceObject:withDelegateInterface:
setListenerDelegate:
resumeConnection
createSmartSiriVolumeListener
getVoiceTriggerAssetTypeString
getEndpointAssetTypeString
getLanguageDetectorAssetTypeString
getAdBlockerAssetTypeString
getSpeakerRecognitionAssetTypeString
_cleanUpMobileAssetV1Directory
_isReadyToUse
installedAssetOfType:withLanguage:
_fetchRemoteAssetOfType:withLanguage:completion:
_assetQueryForAssetType:
returnTypes:
queryMetaDataSync
results
filteredAssetsForAssets:assetType:language:
queryParams
isLatestCompareTo:
state
getCSAssetOfType:
installedAssetOfType:withLanguage:completion:
addKeyValuePair:with:
addKeyValuePairForQuery:assetType:
_installedAssetOfType:query:withLanguage:completion:
_fetchRemoteAssetOfType:withLanguage:query:completion:
_installedAssetOfType:withLanguage:
_installedAssetOfType:withLanguage:completion:
_findLatestInstalledAsset:
queryMetaData:
attributes
fetchRemoteMetaOfType:allowRetry:
_runAssetQuery:completion:
_downloadAssetCatalogForAssetType:complete:
_updateFromRemoteToLocalAssets:forAssetType:completion:
_defaultDownloadOptions
_isRetryRecommendedWithResult:
startCatalogDownload:options:then:
isCSAssetInstalled
isDownloading
cancelDownloadSync
canBePurged
purgeSync
CSAssetController:didDownloadNewAssetForType:
_downloadAsset:withComplete:
setAllowsCellularAccess:
setCanUseLocalCacheServer:
setDiscretionary:
assetServerUrl
_startDownloadingAsset:progress:completion:
expectedTimeRemaining
totalWritten
totalExpected
attachProgressCallBack:
spaceCheck:
startDownload:then:
getAssetTypeStringForType:
CSEventMonitorDidReceiveEvent:
assetOfType:language:
assetOfType:language:compatibilityVersion:completion:
installedAssetOfType:language:
installedAssetOfType:language:completion:
fetchRemoteMetaOfType:
addObserver:forAssetType:
removeObserver:forAssetType:
assetsMigrationQueue
setAssetsMigrationQueue:
csAssetsDictionary
setCsAssetsDictionary:
_assetsMigrationQueue
_csAssetsDictionary
T@"NSObject<OS_dispatch_queue>",&,N,V_assetsMigrationQueue
T@"NSDictionary",&,N,V_csAssetsDictionary
T@"NSMutableDictionary",&,N,V_observers
valueForKey:
supportPremiumAssets
getVoiceTriggerAssetCurrentCompatibilityVersion
getEndpointAssetCurrentCompatibilityVersion
getLanguageDetectorCurrentCompatibilityVersion
getAdBlockerCurrentCompatibilityVersion
getSpeakerRecognitionCurrentCompatibilityVersion
filteredAssetsForFetchRemoteMetaDataForAssets:assetType:
lowercaseString
setAssetDownloadingOption:
_loadAndSetupEndpointerAssetIfNecessary
initWithSilenceFramesCountMs:silenceProbability:silenceDurationMs:processedAudioMs:
assetForCurrentLanguageOfType:
_readParametersFromHEPAsset:
initWithConfiguration:modelVersion:
submitEndpointerIssueReport:
subChunkFrom:numSamples:forChannel:
updateEndpointerThresholdWithValue:
updateEndpointerDelayedTriggerSwitch:
silenceFramesCountMs
silenceProbability
silenceDurationMs
initWithWordCount:trailingSilenceDuration:endOfSentenceLikelihood:pauseCounts:silencePosterior:clientSilenceFramesCountMs:clientSilenceProbability:silencePosteriorNF:serverFeaturesLatency:eagerResultEndTime:
acceptEagerResultWithFeatures:featuresToLog:
processedAudioMs
supportPhatic
_shouldUsePhaticWithRecordContext
_multimodalEndpointerEnabled
defaultServerEndpointFeatures
endOfSentenceLikelihood
initWithWordCount:trailingSilenceDuration:endOfSentenceLikelihood:pauseCounts:silencePosterior:clientSilenceFramesCountMs:clientSilenceProbability:silencePosteriorNF:serverFeaturesLatency:
didEndpointWithFeatures:audioTimestamp:featuresToLog:endpointPosterior:extraDelayMs:
clientSilenceFramesCountMs
serverFeaturesLatency
clientSilenceProbability
hostTimeFromSampleCount:anchorHostTime:anchorSampleCount:sampleRate:
endpointer:reportEndpointBufferHostTime:firstBufferHostTime:
distributionDictionary:
numberWithInt:
initWithTotalAudioRecorded:endpointBufferHostTime:featuresAtEndpoint:endpointerType:serverFeatureLatencyDistribution:additionalMetrics:
_emitEndpointDetectedEventWithEndpointTimeMs:endpointBufferHostTime:endpointerFeatures:endpointerDecisionLagInNs:extraDelayMs:endpointScore:asrFeatureLatencies:
terminateProcessing
currentLanguageCode
requestSupportedWithSamplingRate:
_getCSHybridEndpointerConfigForAsset:
_updateAssetWithLanguage:
_updateAssetWithCurrentLanguage
isJarvisVoiceTriggered
isStarkTriggered
isIOSDeviceSupportingBargeIn
CSAssetManagerDidDownloadNewAsset:
osdAnalyzer:didUpdateOSDFeatures:
osdAnalyzer:didDetectStartOfSpeechAt:
osdAnalyzer:didDetectEndOfSpeechAt:
setCanProcessCurrentRequest:
apQueue
setApQueue:
numSamplesProcessed
setNumSamplesProcessed:
numSamplesProcessedBeforeAnchorTime
setNumSamplesProcessedBeforeAnchorTime:
anchorMachAbsTime
setAnchorMachAbsTime:
isAnchorTimeBuffered
setIsAnchorTimeBuffered:
isRequestTimeout
setIsRequestTimeout:
didAddAudio
setDidAddAudio:
osdFeaturesAtEndpoint
setOsdFeaturesAtEndpoint:
hybridClassifier
setHybridClassifier:
setEndpointerModelVersion:
serverFeaturesQueue
setServerFeaturesQueue:
lastKnownServerEPFeatures
setLastKnownServerEPFeatures:
lastKnownOSDFeatures
setLastKnownOSDFeatures:
serverFeatureLatencies
setServerFeatureLatencies:
lastKnowServerFeaturesLatency
setLastKnowServerFeaturesLatency:
epResult
setEpResult:
serverFeaturesWarmupLatency
setServerFeaturesWarmupLatency:
lastServerFeatureTimestamp
setLastServerFeatureTimestamp:
didReceiveServerFeatures
setDidReceiveServerFeatures:
clientLagThresholdMs
setClientLagThresholdMs:
clampedSFLatencyMsForClientLag
setClampedSFLatencyMsForClientLag:
useDefaultServerFeaturesOnClientLag
setUseDefaultServerFeaturesOnClientLag:
hybridClassifierQueue
setHybridClassifierQueue:
lastReportedEndpointTimeMs
setLastReportedEndpointTimeMs:
processedAudioInSeconds
setProcessedAudioInSeconds:
lastEndpointPosterior
setLastEndpointPosterior:
stateSerialQueue
setStateSerialQueue:
didCommunicateEndpoint
setDidCommunicateEndpoint:
currentRequestSampleRate
setCurrentRequestSampleRate:
vtExtraAudioAtStartInMs
setVtExtraAudioAtStartInMs:
vtEndInSampleCount
setVtEndInSampleCount:
hepAudioOriginInMs
setHepAudioOriginInMs:
speechEndpointDetected
setSpeechEndpointDetected:
firstAudioPacketTimestamp
setFirstAudioPacketTimestamp:
firstAudioSampleSensorTimestamp
setFirstAudioSampleSensorTimestamp:
didTimestampFirstAudioPacket
setDidTimestampFirstAudioPacket:
recordingDidStop
setRecordingDidStop:
osdQueue
setOsdQueue:
didDetectSpeech
setDidDetectSpeech:
setElapsedTimeWithNoSpeech:
setTrailingSilenceDurationAtEndpoint:
_saveSamplesSeenInReset
_canProcessCurrentRequest
_isAnchorTimeBuffered
_isRequestTimeout
_didAddAudio
_epResult
_didReceiveServerFeatures
_useDefaultServerFeaturesOnClientLag
_didCommunicateEndpoint
_speechEndpointDetected
_didTimestampFirstAudioPacket
_recordingDidStop
_didDetectSpeech
_lastEndpointPosterior
_implDelegate
_endpointStyle
_endpointMode
_startWaitTime
_endWaitTime
_interspeechWaitTime
_delay
_automaticEndpointingSuspensionEndTime
_minimumDurationForEndpointer
_apQueue
_numSamplesProcessed
_numSamplesProcessedBeforeAnchorTime
_anchorMachAbsTime
_osdFeaturesAtEndpoint
_hybridClassifier
_endpointerModelVersion
_serverFeaturesQueue
_lastKnownServerEPFeatures
_lastKnownOSDFeatures
_serverFeatureLatencies
_lastKnowServerFeaturesLatency
_serverFeaturesWarmupLatency
_lastServerFeatureTimestamp
_clientLagThresholdMs
_clampedSFLatencyMsForClientLag
_hybridClassifierQueue
_lastReportedEndpointTimeMs
_processedAudioInSeconds
_stateSerialQueue
_currentRequestSampleRate
_vtExtraAudioAtStartInMs
_vtEndInSampleCount
_hepAudioOriginInMs
_firstAudioPacketTimestamp
_firstAudioSampleSensorTimestamp
_osdQueue
_elapsedTimeWithNoSpeech
_trailingSilenceDurationAtEndpoint
T@"NSObject<OS_dispatch_queue>",&,N,V_apQueue
TQ,N,V_numSamplesProcessed
TQ,N,V_numSamplesProcessedBeforeAnchorTime
TQ,N,V_anchorMachAbsTime
TB,N,V_isAnchorTimeBuffered
TB,N,V_isRequestTimeout
TB,N,V_didAddAudio
T@"OSDFeatures",&,N,V_osdFeaturesAtEndpoint
TB,N,V_canProcessCurrentRequest
T@"_EAREndpointer",&,N,V_hybridClassifier
T@"NSString",&,N,V_endpointerModelVersion
T@"NSObject<OS_dispatch_queue>",&,N,V_serverFeaturesQueue
T@"CSServerEndpointFeatures",&,N,V_lastKnownServerEPFeatures
T@"OSDFeatures",&,N,V_lastKnownOSDFeatures
T@"NSMutableArray",&,N,V_serverFeatureLatencies
Td,N,V_lastKnowServerFeaturesLatency
TB,N,V_epResult
Td,N,V_serverFeaturesWarmupLatency
T@"NSDate",&,N,V_lastServerFeatureTimestamp
TB,N,V_didReceiveServerFeatures
Td,N,V_clientLagThresholdMs
Td,N,V_clampedSFLatencyMsForClientLag
TB,N,V_useDefaultServerFeaturesOnClientLag
T@"NSObject<OS_dispatch_queue>",&,N,V_hybridClassifierQueue
Td,N,V_lastReportedEndpointTimeMs
Td,N,V_processedAudioInSeconds
Tf,N,V_lastEndpointPosterior
T@"NSObject<OS_dispatch_queue>",&,N,V_stateSerialQueue
TB,N,V_didCommunicateEndpoint
TQ,N,V_currentRequestSampleRate
Td,N,V_vtExtraAudioAtStartInMs
TQ,N,V_vtEndInSampleCount
Td,N,V_hepAudioOriginInMs
TB,N,V_speechEndpointDetected
T@"NSDate",&,N,V_firstAudioPacketTimestamp
Td,N,V_firstAudioSampleSensorTimestamp
TB,N,V_didTimestampFirstAudioPacket
TB,N,V_recordingDidStop
T@"NSObject<OS_dispatch_queue>",&,N,V_osdQueue
TB,N,V_didDetectSpeech
Td,N,V_elapsedTimeWithNoSpeech
Td,N,V_trailingSilenceDurationAtEndpoint
T@"<CSEndpointAnalyzerDelegate>",W,N,V_delegate
T@"<CSEndpointAnalyzerImplDelegate>",W,N,V_implDelegate
Tq,N,V_endpointStyle
Td,N,V_delay
Td,N,V_startWaitTime
Td,N,V_automaticEndpointingSuspensionEndTime
Td,N,V_minimumDurationForEndpointer
Tq,N,V_endpointMode
Td,N,V_interspeechWaitTime
Td,N,V_endWaitTime
TB,N,V_saveSamplesSeenInReset
isRecordContextBuiltInVoiceTrigger:
isRecordContextHearstVoiceTrigger:
isRecordContextJarvisVoiceTrigger:
isRecordContextRemoraVoiceTrigger:
isRecordContextHearstDoubleTap:
isRecordContextRaiseToSpeak:
isRecordContextAutoPrompt:
isRecordContextHomeButtonPress:
isRecordContextSpeakerIdTrainingTrigger:
isRecordContextJarvisButtonPress:
isValidRecordContext:
recordContextString:
defaultContinousFingerprintBufferDuration
initWithData:
maxFingerprintBufferSize
shouldResetAdsDictionary
assetVersion
payloadData
setPayloadData:
_maxFingerprintBufferSize
_shouldResetAdsDictionary
_assetVersion
_payloadData
T@"NSData",&,N,V_payloadData
Tf,R,N,V_maxFingerprintBufferSize
T@"NSMutableDictionary",R,N,V_shouldResetAdsDictionary
T@"NSString",R,N,V_assetVersion
mapTableWithStrongToStrongObjects
defaultInjectionProvider
primaryInputDevice
setEnableAlwaysOnVoiceTrigger:
deviceUID
initWithDeviceType:deviceName:deviceID:productID:
speakAudio:withScaleFactor:playbackStarted:completion:
connectDevice:
disconnectDevice:
_deviceMapTable
initWithBool:
initWithDouble:
initWithLongLong:
initWithUnsignedLongLong:
objCType
longLongValue
initWithResult:
setSampleFed:
setEarlyWarning:
_earlyWarning
_sampleFed
TQ,N,V_sampleFed
TB,N,V_earlyWarning
strongToWeakObjectsMapTable
_hasPendingActivationForType:
activationEventNotificationHandler:event:completion:
_notifyActivationEvent:completion:
_isVoiceTriggerEvent:
hosttime
setDelegate:forType:
delegates
setDelegates:
pendingActivationEvent
setPendingActivationEvent:
pendingCompletion
setPendingCompletion:
_delegates
_pendingActivationEvent
_pendingCompletion
T@"NSMapTable",&,N,V_delegates
T@"CSActivationEvent",&,N,V_pendingActivationEvent
T@?,C,N,V_pendingCompletion
_setDefaultParameters
_setAsset:
_convertDB2Mag:
_reset
initializeMediaPlayingState
initializeAlarmState
fetchInitSystemVolumes
_resumeSSVProcessing
_pauseSSVProcessing
setCallback:
_startListenPolling
_startListenPollingWithInterval:completion:
_startListenWithCompletion:
_stopListening
mediaPlayingState
alarmState
_getDevicedBFSForInputLinearVolume:
_getFloatBufferData:
iterateBitset:block:
_prepareSoundLevelBufferFromSamples:soundType:
subChunkFrom:numSamples:
_processAudioChunk:soundType:
_estimatedTTSVolume:lowerLimit:upperLimit:TTSmappingInputRangeLow:TTSmappingInputRangeHigh:TTSmappingOutputRangeLow:TTSmappingOutputRangeHigh:
_getUserOffsetFromMusicVolumeDB:
_combineResultsWithOptimalFromNoise:andOptimalFromLkfs:withUserOffset:
_getDeviceSimpleOutputLinearVolumeFordBFSValue:
_scaleInputWithInRangeOutRange:minIn:maxIn:minOut:maxOut:
sharedAnalytics
logEventWithType:context:
smartSiriVolumeSoftVolumeEnabled
_getMusicVolumeDBCSSSVDeviceSimple:
_getMusicVolumeDBCSSSVDeviceDefault:
_deviceSpecificLinearVolumeToDBMappingCSSSVDeviceSimple:
_deviceSpecificDBToLinearVolumeMappingCSSSVDeviceSimple:
_getDeviceSimpledBFSForOutputLinearVolume:
estimateSoundLevelbySoundType:
estimatedTTSVolumeForNoiseLevelAndLKFS:LKFS:
initWithVolumeEstimate:debugLogFile:
CSMediaPlayingMonitor:didReceiveMediaPlayingChanged:
siriClientBehaviorMonitor:willStartStreamWithContext:option:
siriClientBehaviorMonitor:didStartStreamWithContext:successfully:option:withEventUUID:
siriClientBehaviorMonitor:willStopStream:reason:
siriClientBehaviorMonitor:didStopStream:withEventUUID:
siriClientBehaviorMonitor:didChangedRecordState:withEventUUID:withContext:
siriClientBehaviorMonitor:fetchedSiriClientAudioStream:successfully:
siriClientBehaviorMonitor:preparedSiriClientAudioStream:successfully:
siriClientBehaviorMonitorReleasedAudioSession:
initWithSamplingRate:asset:
startSmartSiriVolume
getVolumeForTTSType:withOverrideMediaVolume:WithRequestTime:
didReceiveAlarmChanged:
didReceiveTimerChanged:
didReceiveMusicVolumeChanged:
didReceiveAlarmVolumeChanged:
didDetectKeywordWithResult:
prepareSoundLevelBufferFromSamples:soundType:firedVoiceTriggerEvent:triggerStartTimeSampleOffset:triggerEndTimeSampleOffset:
listenPollingTimer
setListenPollingTimer:
listenPollingTimerCount
setListenPollingTimerCount:
.cxx_construct
_smartSiriVolumeNoiseLevel
_smartSiriVolumeLKFS
_floatBuffer
_defaults
_ssvEnablePolicy
_processedSampleCount
_isListenPollingStarting
_shouldPauseSSVProcess
_shouldPauseLKFSProcess
_alarmSoundIsFiring
_timerSoundIsFiring
_mediaIsPlaying
_musicVolumeDB
_alarmVolume
_noiseLevelChannelBitset
_LKFSChannelBitset
_energyBufferSize
_noiseLowerPercentile
_noiseUpperPercentile
_LKFSLowerPercentile
_LKFSUpperPercentile
_noiseTimeConstant
_noiseMicSensitivityOffset
_noiseMicSensitivityOffsetDeviceSimple
_LKFSTimeConstant
_LKFSMicSensitivityOffset
_noiseTTSMappingInputRangeLow
_noiseTTSMappingInputRangeHigh
_noiseTTSMappingOutputRangeLow
_noiseTTSMappingOutputRangeHigh
_LKFSTTSMappingInputRangeLow
_LKFSTTSMappingInputRangeHigh
_LKFSTTSMappingOutputRangeLow
_LKFSTTSMappingOutputRangeHigh
_userOffsetInputRangeLow
_userOffsetInputRangeHigh
_userOffsetOutputRangeLow
_userOffsetOutputRangeHigh
_TTSVolumeLowerLimitDB
_TTSVolumeUpperLimitDB
_noiseWeight
_listenPollingTimer
_listenPollingTimerCount
T@"NSObject<OS_dispatch_source>",&,N,V_listenPollingTimer
Tq,N,V_listenPollingTimerCount
isPluginContext
deviceType
_createSpeechDetectionVADIfNeeded
isPluginDevice
_connectPluginDevice:
_tearDownSpeechDetectionVADIfNeeded
engineWithDeviceType:streamHandleId:
setInjectionEngine:
attachDevice:
injectionEngine
deviceID
productIdentifier
initWithRoute:isRemoteDevice:remoteDeviceUID:remoteDeviceProductIdentifier:
useSpeexForAudioInjection
setActive:withOptions:error:
setActive:error:
streamHandleID
didStartDelayInSeconds
setDidStartDelayInSeconds:
uuid
setUuid:
connectedDevices
setConnectedDevices:
builtInDevice
setBuiltInDevice:
bundleTvRemote
setBundleTvRemote:
builtInAudioInjectionEngine
setBuiltInAudioInjectionEngine:
audioInjectionEngines
setAudioInjectionEngines:
latestPluginStreamId
setLatestPluginStreamId:
activateStartTime
setActivateStartTime:
activateEndTime
setActivateEndTime:
deactivateStartTime
setDeactivateStartTime:
deactivateEndTime
setDeactivateEndTime:
atvRemoteDeviceID
setAtvRemoteDeviceID:
_didStartDelayInSeconds
_uuid
_connectedDevices
_builtInDevice
_bundleTvRemote
_builtInAudioInjectionEngine
_audioInjectionEngines
_latestPluginStreamId
_activateStartTime
_activateEndTime
_deactivateStartTime
_deactivateEndTime
_atvRemoteDeviceID
T@"NSUUID",&,N,V_uuid
T@"NSMutableArray",&,N,V_connectedDevices
T@"CSAudioInjectionDevice",&,N,V_builtInDevice
T@"CSAudioInjectionDevice",&,N,V_bundleTvRemote
T@"CSAudioInjectionEngine",&,N,V_builtInAudioInjectionEngine
T@"NSMutableDictionary",&,N,V_audioInjectionEngines
TQ,N,V_latestPluginStreamId
TQ,N,V_activateStartTime
TQ,N,V_activateEndTime
TQ,N,V_deactivateStartTime
TQ,N,V_deactivateEndTime
T@"NSString",&,N,V_atvRemoteDeviceID
Tf,N,V_didStartDelayInSeconds
isInAttendingState
notifyUpdatedState:
setCurrentState:
TQ,N,V_currentState
extractArchiveFromDirectory:toDir:
_addListeningEnabledConditions
supportHandsFree
_startObservingOtherAppRecordingState
isOtherAppRecording
handleOtherAppRecordingStateChange:
currentPowerSource
smartSiriVolumeContextAwareEnabled
_didReceiveAutomaticVolumeToggled:
CSAutomaticVolumeEnabledMonitor:didReceiveEnabled:
initWithSuiteName:
addObserver:forKeyPath:options:context:
observeValueForKeyPath:ofObject:change:context:
_isAutomaticVolumeEnabled
_readAudioBufferAndFeed
close
readSamplesFromChannelIdx:
_audioFeedTimer
_bufferDuration
T@"<CSAudioFileReaderDelegate>",W,N,V_delegate
isAttentiveSiriEnabled
_setupNNVADEndpointer
isHearstVoiceTriggered
isRemoraVoiceTriggered
supportCSTwoShotDecision
isWatchRTSTriggered
endpointer:detectedTwoShotAtTime:
logEventWithType:machAbsoluteTime:context:
initForSidekick
endpointerDelegate
endpointerImplDelegate
setEndpointerImplDelegate:
hybridEndpointer
setHybridEndpointer:
nnvadEndpointer
setNnvadEndpointer:
activeEndpointer
setActiveEndpointer:
_endpointerDelegate
_endpointerImplDelegate
_hybridEndpointer
_nnvadEndpointer
_activeEndpointer
T@"<CSEndpointAnalyzerImpl>",&,N,V_hybridEndpointer
T@"<CSEndpointAnalyzerImpl>",&,N,V_nnvadEndpointer
T@"<CSEndpointAnalyzerImpl>",W,N,V_activeEndpointer
T@"<CSEndpointAnalyzerDelegate>",W,N,V_endpointerDelegate
T@"<CSEndpointAnalyzerImplDelegate>",W,N,V_endpointerImplDelegate
getCurrentOSDAsset
checkConsecutiveBoronSignalWithAudioChunk:
countOfConsecutiveBoron
setCountOfConsecutiveBoron:
numOfConsecutiveBoronActivationThreshold
setLastKnownConsecutiveBoronStartSampleCount:
lastKnownConsecutiveBoronStartSampleCount
setFrameDurationMs:
frameDurationMs
endpointerAssetManagerDidUpdateAsset:
endpointerAssetManagerDidUpdateOSDAsset:
hadSignalsFrom:to:
audioStartSampleCount
fetchLastKnownConsecutiveBoronStartSampleCount
configFile
setConfigFile:
firstAudioStartSampleCount
setFirstAudioStartSampleCount:
setNumOfConsecutiveBoronActivationThreshold:
_prefetchedAsset
_configFile
_firstAudioStartSampleCount
_frameDurationMs
_countOfConsecutiveBoron
_lastKnownConsecutiveBoronStartSampleCount
_numOfConsecutiveBoronActivationThreshold
T@"NSString",N,V_configFile
TQ,N,V_firstAudioStartSampleCount
Td,N,V_frameDurationMs
TQ,N,V_countOfConsecutiveBoron
TQ,N,V_lastKnownConsecutiveBoronStartSampleCount
TQ,N,V_numOfConsecutiveBoronActivationThreshold
T@"CSAsset",&,N,V_prefetchedAsset
RMSScore
initWithRMSScore:lastSampleCount:
compareScoresDesc:
setRMSScore:
lastSampleCount
setLastSampleCount:
_RMSScore
_lastSampleCount
Td,N,V_RMSScore
TQ,N,V_lastSampleCount
appendData:
getBytes:range:
_calculateRMSWithFrameData:
_calculateSpeechVoicingLevel
_calculateNumberOfVoicingFrames
numberOfVoicingFrames
sortUsingSelector:
addDataToBuffer:
calculateShadowMicScore
bestStartDetectSample
setBestStartDetectSample:
bestEarlyDetectSample
setBestEarlyDetectSample:
bestEndDetectSample
setBestEndDetectSample:
shadowMicScore
setShadowMicScore:
rmsSamplesForEntireAudio
setRmsSamplesForEntireAudio:
audioBuffer
setAudioBuffer:
speechVoiceLevel
setSpeechVoiceLevel:
setNumberOfVoicingFrames:
numberOfTotalFramesETFT
setNumberOfTotalFramesETFT:
_bestStartDetectSample
_bestEarlyDetectSample
_bestEndDetectSample
_shadowMicScore
_rmsSamplesForEntireAudio
_audioBuffer
_speechVoiceLevel
_numberOfVoicingFrames
_numberOfTotalFramesETFT
T@"NSMutableArray",&,N,V_rmsSamplesForEntireAudio
T@"NSMutableData",&,N,V_audioBuffer
Td,N,V_speechVoiceLevel
TQ,N,V_numberOfVoicingFrames
Tq,N,V_numberOfTotalFramesETFT
TQ,N,V_bestStartDetectSample
TQ,N,V_bestEarlyDetectSample
TQ,N,V_bestEndDetectSample
Td,N,V_shadowMicScore
dataWithCapacity:
appendBytes:length:
myriadHashFilePath
writeToFile:atomically:
CSMyriadSelfTriggerCoordinator:didGenerateMyriadPHashForSelfTrigger:
selfTriggerDetector:didDetectSelfTrigger:
T@"<CSMyriadSelfTriggerCoordinatorDelegate>",W,N,V_delegate
_updateAssetWithCurrentLanguageForAssetType:
_isOSDIncludedInAsset:
_getCurrentHEPAsset
_updateAssetWithLanguage:assetType:
_notifyAssetsUpdate
_updateOEPAssetsWithLanguage:
asrDatapackInstallationStatus
_getModelPathFromInstallationStatusString:
_getOEPVersionFromPath:
assetForAssetType:resourcePath:configVersion:assetProvider:
setCurrentOEPAsset:
currentOEPAsset
currentHEPAsset
checkFirstUnlocked
getCurrentEndpointerAsset
setCurrentHEPAsset:
setAsrDatapackInstallationStatus:
_currentHEPAsset
_currentOEPAsset
_asrDatapackInstallationStatus
T@"CSAsset",&,N,V_currentHEPAsset
T@"CSAsset",&,N,V_currentOEPAsset
T@"NSDictionary",&,N,V_asrDatapackInstallationStatus
setConnectedDevice:
enableAlwaysOnVoiceTrigger
isAlwaysOnVoiceTriggerAvailable
setAlwaysOnVoiceTriggerEnabled:
injectAudio:
injectAudio:withScaleFactor:playbackStarted:completion:
getBestSampleCountWithOption:
applyNegative12dBGainToFloatBuffer:
applyNegative12dBGainToShortBuffer:
builtInMicVoiceTriggerEvent:hostTime:
copybufferFrom:to:
alwaysOnVoiceTriggerEnabled
keywordAnalyzer
setKeywordAnalyzer:
setLastForwardedSampleCount:
hostTimeBuffer
setHostTimeBuffer:
voiceTriggerEnabled
setVoiceTriggerEnabled:
connectedDevice
isForwarding
setIsForwarding:
voiceTriggerSampleCount
setVoiceTriggerSampleCount:
_voiceTriggerEnabled
_isForwarding
_keywordAnalyzer
_lastForwardedSampleCount
_hostTimeBuffer
_connectedDevice
_voiceTriggerSampleCount
T@"<CSAudioInjectionEngineDelegate>",W,N,V_delegate
T@"CSKeywordAnalyzerNDEAPI",&,N,V_keywordAnalyzer
TQ,N,V_lastForwardedSampleCount
T@"NSMutableArray",&,N,V_hostTimeBuffer
TB,N,V_voiceTriggerEnabled
T@"CSAudioInjectionDevice",W,N,V_connectedDevice
TB,N,V_isForwarding
TQ,N,V_voiceTriggerSampleCount
_checkSpringBoardStarted
_didReceiveSpringboardStarted:
_notifyObserver:withStarted:
CSSpringboardStartMonitor:didReceiveStarted:
_didReceiveSpringboardStartedInQueue:
_isSpringBoardStarted
containsCategory:
satScoreThreshold
getBoolForKey:category:default:
containsSpeakerRecognitionCategory
psrCombinationWeight
satImplicitProfileThreshold
satImplicitProfileDeltaThreshold
satVTImplicitThreshold
pruningExplicitUttThresholdSAT
pruningExplicitUttThresholdPSR
pruningThresholdSAT
pruningThresholdPSR
pruningNumRetentionUtterance
maxAllowedEnrollmentUtterances
voiceProfilePruningCookie
keywordDetectorQuasarConfigFilePath
keywordDetectorNDAPIConfigFilePath
satImplicitTrainingEnabled
Tq,R,N
_createXPCClientConnection
initWithType:deviceId:activationInfo:hosttime:
sharedNotifier
notifyActivationEventSynchronously:completion:
notifyActivationEvent:deviceId:activationInfo:completion:
deviceIsInSleep
_alarmFiringState
ssvManager
setSsvManager:
_ssvManager
T@"CSSmartSiriVolumeManager",&,N,V_ssvManager
handleAudioStopUnexpectly
_fetchAudioDecoderForTV:
packets
numChannels
defaultConverter
speexASBD
attachToMasterStreamWithCompletion:
decodersForTV
setDecodersForTV:
decoderProcessedSampleCountForTV
setDecoderProcessedSampleCountForTV:
_decodersForTV
_decoderProcessedSampleCountForTV
T@"NSMutableDictionary",&,N,V_decodersForTV
TQ,N,V_decoderProcessedSampleCountForTV
_checkFirstUnlocked
_didReceiveFirstUnlock:
_notifyObserver:withUnlocked:
_firstUnlockNotified
_didReceiveFirstUnlockInQueue:
_firstUnlocked
_isBuiltInDeviceFromDeviceId:
rtsTriggerInfo
setRtsTriggerInfo:
setTriggerNotifiedMachTime:
_accessoryVoiceTriggerEvents
_builtInVoiceTriggerEvent
_rtsTriggerInfo
_triggerNotifiedMachTime
T@"NSDictionary",C,N,V_rtsTriggerInfo
TQ,N,V_triggerNotifiedMachTime
initWithRoute:isRemoteDevice:remoteDeviceUID:remoteDeviceProductIdentifier:remoteDeviceUIDString:
initWithUUIDString:
isRemoteDevice
remoteDeviceUID
remoteProductIdentifier
remoteDeviceUIDString
route
remoteDeviceProductIdentifier
_isRemoteDevice
_route
_remoteDeviceUID
_remoteDeviceProductIdentifier
_remoteDeviceUIDString
T@"NSString",R,C,N,V_remoteDeviceUIDString
T@"NSString",R,C,N,V_route
TB,R,N,V_isRemoteDevice
T@"NSUUID",R,C,N,V_remoteDeviceUID
T@"NSString",R,C,N,V_remoteDeviceProductIdentifier
commandControlBehaviorMonitor:willStartStreamWithContext:option:
commandControlBehaviorMonitor:didStartStreamWithContext:successfully:option:
commandControlBehaviorMonitor:willStopStream:
commandControlBehaviorMonitor:didStopStream:
error
setTimestamp:
setPerceptualAudioHash:
initWithOverrideOption:reason:
setOverrideState:
newWithBuilder:
setVoiceTriggerEverUsed
initWithServicePort:
deactivateForReason:options:context:completion:
sharedLauncher
notifyBuiltInVoiceTriggerPrewarm:completion:
notifyBuiltInVoiceTrigger:myriadPHash:completion:
notifyWakeKeywordSpokenInBuiltInMic:
notifyCarPlayVoiceTriggerPrewarm:deviceId:completion:
notifyCarPlayVoiceTrigger:deviceId:myriadPHash:completion:
notifyWakeKeywordSpokenCarPlay:deviceId:
notifyBluetoothDeviceVoiceTriggerPrewarm:deviceId:completion:
notifyBluetoothDeviceVoiceTrigger:deviceId:completion:
notifyWakeKeywordSpokenBluetoothDevice:deviceId:
notifyRemoraVoiceTriggerPrewarm:deviceId:completion:
notifyRemoraVoiceTrigger:myriadPHash:deviceId:completion:
notifyWakeKeywordSpokenRemora:deviceId:
deactivateSiriActivationConnectionWithReason:withOptions:withContext:
initWithNumChannels:recordingDuration:samplingRate:
initWithSiriSessionUUID:
addAudioChunk:
fetchAudioFromCircularBuffer
T@"CSAudioCircularBuffer",R,N,V_circularBuffer
T@"NSString",R,N,V_siriSessionUUID
initWithAttSiriController:localSpeechRecognizer:
_setLocalSpeechRecognizerState:
stopWithReason:
_handleStopDeliverLocalSpeechRecognition
_preheatWithLanguage:preheatSource:shouldDownloadMissingAsset:
requestId
_stopPreviousRecognitionTaskIfNeededWithNewRequestId:
speechRecognitionTask
_startDeliverLocalSpeechRecognitionResultsWithRequestId:
_startLocalSpeechRecognizerIfNeeded
_handleStopSpeechRecognitionTaskIfNeeded:
_clearAudioProcessWaitingBufferIfNeeded
_processAudioChunk:
endpointModeFromEndpointMetrics:
_queryShouldAcceptEagerResultForDuration:requestId:rcId:
getMitigationDecisionForRCId:
localSRBridgeListener
localSpeechServiceDidReceivedEagerResultWithRequestId:rcId:shouldAccept:mitigationSignal:featuresToLog:
_clearEndpointHint
_interactiveLocalSpeechRecognizer
startMissingAssetDownload
_preheatWithLanguage:preheatSource:
initWithLanguage:assetType:
preheatSpeechRecognitionWithAssetConfig:modelOverrideURL:
_adjustEndpointStartTimeWithVoiceTriggerEvent:
_shouldDisableLocalSpeechRecognizerWithOption:audioRecordContext:
isDictation
supportsDictationOnDevice
_stateToString:
shouldStoreAudioOnDevice
overrideModelPath
_fetchInputOriginWithRecordContext:
deliverEagerPackage
UILanguage
_fetchRecognizerLanguageWithSiriLanguage:UILanguage:taskString:
_resetLocalSpeechRecognizerParameters
applicationName
recognitionOverrides
detectUtterances
secureOfflineOnly
continuousListening
shouldHandleCapitalization
maximumRecognitionDuration
location
jitGrammar
initWithLanguage:requestIdentifier:dictationUIInteractionIdentifier:task:loggingContext:applicationName:profile:overrides:modelOverrideURL:originalAudioFileURL:codec:narrowband:detectUtterances:censorSpeech:farField:secureOfflineOnly:shouldStoreAudioOnDevice:continuousListening:shouldHandleCapitalization:isSpeechAPIRequest:maximumRecognitionDuration:endpointStart:inputOrigin:location:jitGrammar:deliverEagerPackage:disableDeliveringAsrFeatures:
startSpeechRecognitionWithParameters:didStartHandlerWithInfo:
addAudioPacket:
_scheduleRecordingTransactionReleaseTimer
finishAudio
_releaseRecordingTransactionIfNeededWithToken:
initWithDelegate:instanceUUID:
writeDESRecord
localSpeechServiceDidReceivedPartialResultWithRequestId:language:tokens:
_handleShouldAcceptEagerResultWithRequestId:rcId:duration:shouldAccept:featuresToLog:
isReceivedTimeInterval:matchCurrentTimeInterval:
_enforceEndpointHintWithRequestId:rcId:shouldAccept:featuresToLog:
isFinal
_handleDidRecognizedFinalSpeechPackage:requestId:
_handleDidRecognizedSpeechPackageForEagerRecognitionCandidate:requestId:rcId:processedAudioDuration:
localSpeechServiceDidReceivedFinalResultWithRequestId:speechPackage:
processResultCandidate:forRCId:forTask:completion:
localSpeechServiceDidReceivedEagerRecognitionCandidateWithRequestId:rcId:speechPackage:duration:
_getUserSpeakingEndedTimeFromSpeechPackage:
localSpeechServiceDidCompletionRecognitionWithStatistics:requestId:endpointMode:error:
_invalidateLocalSpeechRecognizer:
hostTimeToTimeInterval:
setEndpointerFeatureEoS:
modelRoot
setASRModelRootDirectory:
_getAsrInputoriginFromContext:
isRequestFromSpokenNotification
isiOSButtonPress
rawRecognition
phrases
interpretations
silenceStartTime
localSpeechRecognizer:didSelectRecognitionModelWithModelProperties:
localSpeechRecognizer:didRecognizeTokens:
localSpeechRecognizer:didProcessAudioDuration:
localSpeechRecognizer:didRecognizeRawEagerRecognitionCandidate:
localSpeechRecognizer:didRecognizePackage:
localSpeechRecognizer:didCompletionRecognitionWithStatistics:error:
localSpeechRecognizer:didProduceEndpointFeaturesWithWordCount:trailingSilenceDuration:eosLikelihood:pauseCounts:silencePosterior:processedAudioDurationInMilliseconds:
localSpeechRecognizer:didProduceLoggablePackage:
startDeliverLocalSpeechRecognitionResultsWithSettings:
stopDeliverLocalSpeechRecognitionWithReason:
disableLocalSpeechRecognitionForRequestId:
registerEndpointerNode:
registerUresNode:
preheatWithLanguage:shouldDownloadMissingAsset:
prepareToStartSpeechRequestWithStartStreamOption:audioRecordContext:voiceTriggerInfo:
fetchCurrentState
endpointerNode
uresNode
localSpeechRecognizerQueue
setLocalSpeechRecognizerQueue:
interactiveLocalSpeechRecognizer
setInteractiveLocalSpeechRecognizer:
presetLocalSpeechRecognizer
setPresetLocalSpeechRecognizer:
localSpeechRecognizerTaskString
setLocalSpeechRecognizerTaskString:
localSpeechRecognizerState
setLocalSpeechRecognizerState:
audioWaitingBuffer
setAudioWaitingBuffer:
processedAudioDurationInMillisec
setProcessedAudioDurationInMillisec:
language
setLanguage:
setRequestId:
eagerResultId
setEagerResultId:
speechHasAcceptedResultCandidate
setSpeechHasAcceptedResultCandidate:
speechRecognitionSettings
setSpeechRecognitionSettings:
shouldProcessAudio
setShouldProcessAudio:
asrResultDeliveryTransaction
setAsrResultDeliveryTransaction:
recordingToken
setRecordingToken:
endpointStartTimeInSec
setEndpointStartTimeInSec:
audioSampleCountToSkip
setAudioSampleCountToSkip:
didDetectedEndpoint
setDidDetectedEndpoint:
lastEndpointHintDuration
setLastEndpointHintDuration:
lastEndpointHintRCId
setLastEndpointHintRCId:
lastEndpointEagerResultTime
setLastEndpointEagerResultTime:
lastEndpointHintFeatures
setLastEndpointHintFeatures:
endpointDelayReporter
setEndpointDelayReporter:
setLocalSRBridgeListener:
_speechHasAcceptedResultCandidate
_shouldProcessAudio
_didDetectedEndpoint
_endpointerNode
_uresNode
_localSpeechRecognizerQueue
_presetLocalSpeechRecognizer
_localSpeechRecognizerTaskString
_localSpeechRecognizerState
_audioWaitingBuffer
_processedAudioDurationInMillisec
_language
_requestId
_eagerResultId
_speechRecognitionSettings
_asrResultDeliveryTransaction
_recordingToken
_endpointStartTimeInSec
_audioSampleCountToSkip
_lastEndpointHintDuration
_lastEndpointHintRCId
_lastEndpointEagerResultTime
_lastEndpointHintFeatures
_endpointDelayReporter
_localSRBridgeListener
T@"NSObject<OS_dispatch_queue>",&,N,V_localSpeechRecognizerQueue
T@"CoreEmbeddedSpeechRecognizer",&,N,V_interactiveLocalSpeechRecognizer
T@"CoreEmbeddedSpeechRecognizer",&,N,V_presetLocalSpeechRecognizer
T@"NSString",&,N,V_localSpeechRecognizerTaskString
TQ,N,V_localSpeechRecognizerState
T@"CSAudioProcessWaitingBuffer",&,N,V_audioWaitingBuffer
Td,N,V_processedAudioDurationInMillisec
TI,N,V_activeChannel
T@"NSString",&,N,V_language
T@"NSString",&,N,V_requestId
TQ,N,V_eagerResultId
TB,N,V_speechHasAcceptedResultCandidate
T@"LBLocalSpeechRecognitionSettings",&,N,V_speechRecognitionSettings
TB,N,V_shouldProcessAudio
T@"CSOSTransaction",&,N,V_asrResultDeliveryTransaction
T@"NSUUID",&,N,V_recordingToken
Td,N,V_endpointStartTimeInSec
TQ,N,V_audioSampleCountToSkip
TB,N,V_didDetectedEndpoint
Td,N,V_lastEndpointHintDuration
Tq,N,V_lastEndpointHintRCId
TQ,N,V_lastEndpointEagerResultTime
T@"NSArray",&,N,V_lastEndpointHintFeatures
T@"CSEndpointDelayReporter",&,N,V_endpointDelayReporter
T@"CSConnectionListener",&,N,V_localSRBridgeListener
T@"CSAttSiriEndpointerNode",W,N,SregisterEndpointerNode:,V_endpointerNode
T@"CSAttSiriUresNode",W,N,SregisterUresNode:,V_uresNode
completionBlock
setTimer:
setTimerForSecs:completionBlock:
cancelTimer
timer
setCompletionBlock:
_timer
_completionBlock
T@"NSObject<OS_dispatch_source>",&,N,V_timer
T@?,C,N,V_completionBlock
setStreamProvider:
setStreaming:
stringByAppendingFormat:
setStreamingUUID:
streamingUUID
streaming
setIsWeakStream:
_scheduledFutureSample
_isWeakStream
_streaming
_streamProvider
_streamRequest
_startStreamOption
_tandemStreams
_streamingUUID
TB,V_streaming
T@"NSUUID",&,V_streamingUUID
T@"<CSAudioStreamProviding>",W,N,V_streamProvider
T@"<CSAudioStreamProvidingDelegate>",W,N,V_delegate
TQ,R,N,V_startSampleCount
TQ,R,N,V_lastForwardedSampleCount
TB,N,SsetScheduledFutureSample:,V_scheduledFutureSample
T@"CSAudioStreamRequest",&,N,V_streamRequest
T@"CSAudioStartStreamOption",&,N,SsetStartStreamOption:,V_startStreamOption
TB,N,V_isWeakStream
T@"NSHashTable",R,N,V_tandemStreams
_didReceiveNewVoiceTriggerAssetMetaData
CSVoiceTriggerAssetMetaUpdateMonitor:didReceiveNewVoiceTriggerAssetMetaData:
notifyNewVoiceTriggerAssetMetaDataUpdated
setOpportuneSpeakListeningType:
_opportuneSpeakListeningType
TQ,N,V_opportuneSpeakListeningType
supportZeroFilter:
supportBeepCanceller:
resetWithSampleRate:
initWithToken:sampleRate:numChannels:
setSampleRate:
_isNarrowBand:
setUpsampler:
zeroFilter
beepCanceller
getZeroStatisticsFromBuffer:entireSamples:
processBuffer:atTime:
cancelBeepFromSamples:timestamp:
stopReportZeroStatistics
_reportMetrics
isHeadphoneDeviceWithRecordRoute:playbackRoute:
willBeep
_fetchCurrentMetrics
inputRecordingSampleRateNarrowBand
zeroFilter:zeroFilteredBufferAvailable:atHostTime:
beepCancellerDidCancelSamples:buffer:timestamp:
setZeroFilter:
setBeepCanceller:
zeroCounter
setZeroCounter:
_sampleRate
_numChannels
_upsampler
_zeroFilter
_beepCanceller
_zeroCounter
Tf,N,V_sampleRate
T@"CSAudioSampleRateConverter",&,N,V_upsampler
T@"CSVoiceTriggerAwareZeroFilter",&,N,V_zeroFilter
T@"CSBeepCanceller",&,N,V_beepCanceller
T@"CSAudioZeroCounter",&,N,V_zeroCounter
Ti,N,V_numChannels
T@"<CSAudioPreprocessorDelegate>",W,N,V_delegate
getSerialQueue:withQualityOfService:andTargetQueue:
_init
accessorySiriClientBehaviorMonitor:willStartStreamWithContext:option:forAccessory:
accessorySiriClientBehaviorMonitor:didStartStreamWithContext:successfully:option:withEventUUID:forAccessory:
accessorySiriClientBehaviorMonitor:willStopStream:reason:forAccessory:
accessorySiriClientBehaviorMonitor:didStopStream:reason:withEventUUID:forAccessory:
activeAudioRouteDidChange:
_didReceiveNewSpeechEndpointAssetMetaData
CSSpeechEndpointAssetMetaUpdateMonitor:didReceiveNewSpeechEndpointAssetMetaData:
_addDisabledConditions
_handleClientEvent:
_handleClientMessage:client:
_handleClientError:client:
_sendReplyMessageWithResult:error:event:client:
connection
setConnection:
_connection
T@"NSObject<OS_xpc_object>",&,N,V_connection
_addAssetManagerEnabledConditions
_shouldCheckNetworkAvailability
isAvailable
initWithMode:deviceUID:
isRequestDuringActiveCall
setActivationMode:
setAnnounceCallsEnabled:
initWithDescription:timeout:
setIsASRFeatureFromServer:
_updateEndpointerDelayedTriggerByMhId:
extraDelayFrequency
setExtraDelayFrequency:
taskThresholdMap
setTaskThresholdMap:
isASRFeatureFromServer
endpointerOperationMode
_isASRFeatureFromServer
_extraDelayFrequency
_taskThresholdMap
_endpointerOperationMode
TQ,N,V_extraDelayFrequency
T@"NSDictionary",&,N,V_taskThresholdMap
TB,N,V_isASRFeatureFromServer
Tq,N,V_endpointerOperationMode
systemUpTime
sharedPowerLogger
powerWithNumFalseWakeup:withDuration:
numberWithLongLong:
sharedAggregator
logAOPFirstPassTriggerWakeupLatency:
logSecondPassResult:eventInfo:triggerAPWakeUp:
logFalseWakeUp:
logTriggerLengthSampleCountStatistics:withFirstPassDeterministicTriggerLengthSampleCount:
logAudioZeroRun:
numFalseWakeUp
setNumFalseWakeUp:
lastAggTimeFalseWakeUp
setLastAggTimeFalseWakeUp:
_numFalseWakeUp
_lastAggTimeFalseWakeUp
TQ,N,V_numFalseWakeUp
TQ,N,V_lastAggTimeFalseWakeUp
assetManagerEnabledPolicy
audioFeedTimer
setAudioFeedTimer:
setFp:
T@"NSObject<OS_dispatch_source>",&,N,V_audioFeedTimer
T^{__sFILE=*iiss{__sbuf=*i}i^v^?^?^?^?{__sbuf=*i}^{__sFILEX}i[3C][1C]{__sbuf=*i}iq},N,V_fp
speexConverter
opusConverter
addSamples:timestamp:arrivalTimestampToAudioRecorder:
audioConverterDidConvertPackets:packets:durationInSec:timestamp:arrivalTimestampToAudioRecorder:
encoder
setEncoder:
_encoder
T@"CSAudioConverter",&,N,V_encoder
_checkVoiceTriggerEnabled
_didReceiveVoiceTriggerSettingChanged:
CSVoiceTriggerEnabledMonitor:didReceiveEnabled:
_didReceiveVoiceTriggerSettingChangedInQueue:
_isVoiceTriggerEnabled
volumeEstimate
debugLogPath
_volumeEstimate
_debugLogPath
T@"NSString",R,N,V_debugLogPath
Tf,R,N,V_volumeEstimate
CSAlwaysOnProcessorStateMonitor:didReceiveStateChange:
_didReceiveAOPListeningStateChange:
_isListeningEnabled
attSiriNode:didMitigate:withScore:taskType:
_startRequestWithContext:withVtei:withVTAssets:taskType:completion:
_setAsset:forTask:
_startRequestWithContext:withVtei:completion:
_addAudio:
recordTypeString:
initWithConfig:withDelegate:error:
initWithContext:error:
startNewRequestWithContext:
_logAFTMStartMsg:taskType:
score
_shouldHandleMitigationDecision:
analyzedSamples
_logAFTMEndMsgWithScore:analyzedSamples:
_reportResultToAnalytics
_logResultToVTDirectory
_handleAFTMResults:
_createResultDict
voiceTriggerAudioLogDirectory
resultType
analyzer:hasPartialResult:
analyzer:hasFinalResult:
startRequestWithContext:withVtei:withVTAssets:taskType:completion:
startRequestWithContext:withVtei:taskType:completion:
acousticAnalyzer
setAcousticAnalyzer:
thresholds
setThresholds:
supportedRecordType
setSupportedRecordType:
sessionInProgress
setSessionInProgress:
isShadowModeEnabled
setIsShadowModeEnabled:
makeStandaloneMitigation
setMakeStandaloneMitigation:
latestResult
setLatestResult:
context
setContext:
_sessionInProgress
_isShadowModeEnabled
_makeStandaloneMitigation
_acousticAnalyzer
_thresholds
_supportedRecordType
_latestResult
_context
T@"NSString",&,N,V_taskName
T@"NSString",&,N,V_configFile
T@"SLProgressiveCheckerAnalyzer",&,N,V_acousticAnalyzer
T@"NSArray",&,N,V_thresholds
TQ,N,V_supportedRecordType
TB,N,V_sessionInProgress
TB,N,V_isShadowModeEnabled
TB,N,V_makeStandaloneMitigation
T@"SLProgressiveCheckerResult",&,N,V_latestResult
T@"CSAudioRecordContext",&,N,V_context
valueForEntitlement:
_handleXPCTimeConvertProvidingTypeHostTimeFromSampleCountMessage:messageBody:client:streamHandleId:
_handleXPCTimeConvertProvidingTypeSampleCountFromHostTimeMessage:messageBody:client:streamHandleId:
handleXPCMessage:messageBody:client:audioStreamHandleId:
allowSuddenTermination
disallowSuddenTermiation
isHeadlessDeviceDataCollectionModeEnabled
_processRemoteHeySiriCommandWithRequest:fromSenderID:withReply:
_processParallelRecordingCommandWithRequest:fromSenderID:withReply:
_receiveParallelRecordingFromPeerId:recordingInfo:withReply:
_receiveVoiceProfileFromPeerId:voiceProfileInfo:withReply:
_processGradingDataFetchCommandWithRequest:fromSenderID:withReply:
_processVoiceProfileDeleteCommandWithRequest:fromSenderID:withReply:
_receiveVoiceGradingDataFromPeerId:requestInfo:withReply:
_processVoiceProfileListQueryCommandFromPeerId:requestInfo:withReply:
_processFetchVoiceProfileCommandFromPeerId:requestInfo:withReply:
_processReverseTransferVoiceProfileCommandFromPeerId:requestInfo:withReply:
_processVoiceProfileUpdateTriggerFromPeerId:requestInfo:withReply:
_sendCoreSpeechGradingDataToPeerId:
_sendVoiceTriggerGradingDataToPeerId:
_sendVoiceProfileUpdateTriggerToPeerId:forLocale:
_sendAcousticGradingDataToPeerId:
containsString:
companionSyncVoiceTriggerUtterancesEnabled
pathExtension
isInternalWithoutProfile
_sendGradingData:withFileName:toPeerId:withCompressedFlag:withUncompressedDataSize:withBatchId:withRetainFileFlag:
_compressFilesInDirectory:matchingPredicate:compressedFileAvailable:
URLByDeletingPathExtension
assistantAudioFileLogDirectory
stringByDeletingPathExtension
stringByDeletingLastPathComponent
dataUsingEncoding:
stringByAppendingPathExtension:
removeItemAtPath:error:
moveItemAtPath:toPath:error:
sendMessageWithPayload:toPeer:withReply:
_spIdSiriDebugVoiceProfileRootDirectoryForProfile:locale:
_spIdSiriDebugGradingDataRootDirectory
dictionaryWithObject:forKey:
setAttributes:ofItemAtPath:error:
temporaryDirectory
URLByAppendingPathComponent:
_createDirectoryIfDoesNotExist:
writeToURL:atomically:
_getContentsOfDirectory:
updateVoiceProfile:withUserName:
provisionedVoiceProfilesForLocale:
appDomain
profileId
deleteUserVoiceProfile:
_sendCoreSpeechMagusGradingDataToPeerId:
sharedSiriId
dateAdded
homeId
_getHomeUserIdForSharedSiriId:withCompletion:
userName
languageCode
initWithObjectsAndKeys:
enter
leave
getHomeUserIdForSharedUserId:completion:
waitWithTimeout:
_sendVoiceProfile:toPeerId:
locale
contentsOfDirectoryAtPath:error:
_spIdSiriDebugVoiceProfileCacheDirectoryForProfile:locale:
URLsForDirectory:inDomains:
remoteP2pLogDirectory
remoteGradingDataDirectory
_spIdSiriDebugVTDataDirectory
_spIdSiriDebugVoiceProfileStoreRootDirectory
_spIdSiriDebugVoiceProfileStoreRootDirectoryForLocale:
isP2PTransferEnabled
processRemoteCommandWithPayload:fromPeer:withReply:
sendCoreSpeechGradingDataToNearbyPeer
sendVTNearMissGradingDataToCompanion
sendVoiceProfileUpdatedMessageToNearbyPeerForLocale:
sendAcousticGradingDataToNearbyPeer
_speakerRecognitionAudioLogsGradingDir
_spIdSiriDebugTrainedUsersFilePathForLocale:
adCompanionServiceProvider
setAdCompanionServiceProvider:
lastCommunicatedPeer
setLastCommunicatedPeer:
voiceTriggerBatchId
setVoiceTriggerBatchId:
voiceIdentificationBatchId
setVoiceIdentificationBatchId:
_adCompanionServiceProvider
_lastCommunicatedPeer
_voiceTriggerBatchId
_voiceIdentificationBatchId
T@"NSString",&,N,V_lastCommunicatedPeer
T@"NSString",&,N,V_voiceTriggerBatchId
T@"NSString",&,N,V_voiceIdentificationBatchId
T@"<CSADCompanionServiceProvider>",W,N,V_adCompanionServiceProvider
audioRecorderWithQueue:error:
supportAcousticProgressiveChecker
supportsSpeechRecognitionOnDevice
initWithEndpointerNode:osdNode:ssrNode:asrNode:uresNode:flexKwdNode:needsSSRNode:aFtmNode:speechManager:siriEnabledMonitor:siriClientBehaviorMonitor:supportsAcousticProgressiveChecker:supportsUnderstandingOnDevice:requireASROnDevice:
isDeferredActivationEnabled
_fetchMitigationAssets
_handleStartProcessingWithRecordContext:
_setupAudioSrcNodeWithSiriClientStream:
_handleStopProcessing
attSiriSvcListener
attSiriDidDetectAttendingTrigger:
setAudioSrcNode:
_forceBuildGraph:
audioSrcNode
_holdAttSiriTransactionIfNeeded
setInputOriginWithAudioRecordContext:boronScore:
_releaseAttSiriTransactionIfNeeded
attSiriNode:triggerReportedFromFlxKwdSpotter:
startAttendingWithContext:
stopAttendingWithContext:
siriRequestProcessingCompleted
getNodeOfType:
setAttSiriSvcListener:
nodesCache
setNodesCache:
setEndpointerNode:
osdNode
setOsdNode:
asrNode
setAsrNode:
setUresNode:
ssrNode
setSsrNode:
siriClientAudioStartStreamOption
setSiriClientAudioStartStreamOption:
attSiriTransaction
setAttSiriTransaction:
siriClientBehaviorMonitor
setSiriClientBehaviorMonitor:
siriClientStream
setSiriClientStream:
mitigationAsset
setMitigationAsset:
siriEnabledMonitor
setSiriEnabledMonitor:
flexKwdNode
setFlexKwdNode:
aFTMNode
setAFTMNode:
nldaClassifierNode
setNldaClassifierNode:
pendingActivationProcessing
setPendingActivationProcessing:
activationStartSampleId
setActivationStartSampleId:
deferredActivation
setDeferredActivation:
_pendingActivationProcessing
_deferredActivation
_attSiriSvcListener
_nodesCache
_osdNode
_asrNode
_audioSrcNode
_ssrNode
_siriClientAudioStartStreamOption
_attSiriTransaction
_siriClientBehaviorMonitor
_siriClientStream
_mitigationAsset
_siriEnabledMonitor
_flexKwdNode
_aFTMNode
_nldaClassifierNode
_activationStartSampleId
T@"NSMapTable",&,N,V_nodesCache
T@"CSAttSiriEndpointerNode",&,N,V_endpointerNode
T@"CSAttSiriOSDNode",&,N,V_osdNode
T@"CSAttSiriAsrNode",&,N,V_asrNode
T@"CSAttSiriUresNode",&,N,V_uresNode
T@"CSAttSiriAudioSrcNode",&,N,V_audioSrcNode
T@"CSAttSiriSSRNode",&,N,V_ssrNode
T@"CSAudioStartStreamOption",&,N,V_siriClientAudioStartStreamOption
T@"CSOSTransaction",&,N,V_attSiriTransaction
T@"CSSiriClientBehaviorMonitor",&,N,V_siriClientBehaviorMonitor
T@"CSAudioStream",&,N,V_siriClientStream
T@"CSAsset",&,N,V_mitigationAsset
T@"CSSiriEnabledMonitor",&,N,V_siriEnabledMonitor
T@"CSAttSiriFlexKwdNode",&,N,V_flexKwdNode
T@"CSAttSiriAFTMNode",&,N,V_aFTMNode
T@"CSAttSiriNLDAClassifierNode",&,N,V_nldaClassifierNode
TB,N,V_pendingActivationProcessing
TQ,N,V_activationStartSampleId
TB,N,V_deferredActivation
T@"CSConnectionListener",&,N,V_attSiriSvcListener
initWithDownloadOption:
_createPeriodicalDownloadTimer
_startPeriodicalDownload
_stopPeriodicalDownload
_fetchRemoteMetaData
_canFetchRemoteAsset:
supportLanguageDetector
supportAdBlocker
supportsSpeakerRecognitionAssets
assetForCurrentLanguageOfType:completion:
CSAdBlockerMetaUpdateMonitor:didReceiveNewAdBlockerAssetMetaData:
installedAssetForCurrentLanguageOfType:
installedAssetForCurrentLanguageOfType:completion:
_enablePolicy
_currentLanguageCode
_downloadingOption
_downloadTimer
_downloadTimerCount
pickedRoute
isHFPWithRecordRoute:
isBluetoothAudioDeviceConnected
audioPortSubtypeAsString:
zeroFilterWindowSizeInMs
getHostClockFrequency
zeroFilterApproxAbsSpeechThreshold
initWithZeroWindowSize:approxAbsSpeechThreshold:numHostTicksPerAudioSample:
filterZerosInAudioPacket:atBufferHostTime:filteredPacket:
endAudioAndFetchAnyTrailingZerosPacket:
T@"CSAudioZeroFilter",&,N,V_zeroFilter
T@"<CSVoiceTriggerAwareZeroFilterDelegate>",W,N,V_delegate
initWithEndpointThreshold:
T@"<CSSPGEndpointAnalyzerDelegate>",W,N,V_delegate
_handleMetricProvidingRequestTypeAudioMetricMessage:messageBody:client:
audioMetricProvider
setAudioMetricProvider:
_audioMetricProvider
T@"<CSAudioMetricProviding>",W,N,V_audioMetricProvider
_handleActivateEventMesssage:client:
T@"<CSActivateXPCConnectionDelegate>",W,N,V_delegate
address
supportDoAP
isTemporaryPairedNotInContacts
_supportDoAP
_isTemporaryPairedNotInContacts
_address
T@"NSString",C,N,V_address
TB,N,V_supportDoAP
TB,N,V_isTemporaryPairedNotInContacts
notifyReleaseAudioSession
setIsStreaming:
_isStreaming
TB,N,V_isStreaming
attSiriNode:classifierScore:detailedResult:
createNLDAClassifierWithAsset:
nldaConfigFile
initWithConfig:error:locale:
processSpeechPackage:
domainProb
processSpeechPackageSync:
bertModel
setBertModel:
_bertModel
T@"SLBertClassifier",&,N,V_bertModel
remoteMicVoiceTriggerEvent:activationInfo:hostTime:
lastDetectedVoiceTriggerBeginSampleCount
setLastDetectedVoiceTriggerBeginSampleCount:
_lastDetectedVoiceTriggerBeginSampleCount
T@"CSKeywordAnalyzerNDAPI",&,N,V_keywordAnalyzer
TQ,N,V_lastDetectedVoiceTriggerBeginSampleCount
numOfAVVCRecordingClients
_numOfAVVCRecordingClients
TQ,R,N,V_numOfAVVCRecordingClients
mitigatonConfigFile
mitigationModelDefaultAFTMScore
initWithType:deviceId:activationInfo:vadScore:hosttime:
_activationTypeString
remoteMicVADEvent:vadScore:hostTime:
jarvisVoiceTriggerEvent:activationInfo:hostTime:
remoraVoiceTriggerEvent:hostTime:
remoraVoiceTriggerEvent:activationInfo:hostTime:
mediaserverdLaunchedEvent:
activationInfo
vadScore
_vadScore
_activationInfo
_hosttime
T@"NSString",R,N,V_deviceId
T@"NSDictionary",R,N,V_activationInfo
TQ,R,N,V_hosttime
Tf,R,N,V_vadScore
audioConverterBitrate
setEncoderBitRate:
setNumberOfChannels:
inputRecordingSampleBitDepth
setLpcmBitDepth:
setLpcmIsFloat:
setUseCustomizedRecordSettings:
setIsSiri:
requestForOpusRecordSettingsWithContext:
requestForSpeexRecordSettingsWithContext:
_requiresHistoricalBuffer
_useCustomizedRecordSettings
_lpcmIsFloat
_isSiri
_lpcmBitDepth
_numberOfChannels
_encoderBitRate
_audioFormat
TB,N,V_requiresHistoricalBuffer
TB,N,V_useCustomizedRecordSettings
Tq,N,V_audioFormat
Td,N,V_sampleRate
TI,N,V_lpcmBitDepth
TB,N,V_lpcmIsFloat
TI,N,V_numberOfChannels
TI,N,V_encoderBitRate
TB,N,V_isSiri
_didInstalledNewVoiceTriggerAsset
initWithCrashMonitor:
setAudioSessionState:
_audioSessionState
audioSessionState
TQ,N,GgetAudioSessionState,V_audioSessionState
getASVUserIntent:
setUserIntentValidForSeconds:
applyLowerAndUpperBoundsToVolume:
setASVUserIntent:
initWithStoredInformationAndAsset:
increaseSiriVolumeBasedOnUserIntent
decreaseSiriVolumeBasedOnUserIntent
storeASVStateInformation
applyLowerAndUpperBoundsToVolumeOffset:
userIntentType
setUserIntentType:
userIntentTime
setUserIntentTime:
userIntentValidForSeconds
latestVolumeTime
setLatestVolumeTime:
userIntentVolume
setUserIntentVolume:
latestVolume
setLatestVolume:
permanentOffsetFactor
setPermanentOffsetFactor:
permanentOffsetIsEnabled
setPermanentOffsetIsEnabled:
kSSVCAUserIntentValidForSeconds
kSSVCAUserIntentVolumeIncreaseFactor
kSSVCAUserIntentVolumeDecreaseFactor
kSSVCAUserIntentPermanentOffsetFactorDelta
kSSVCAUserIntentPermanentOffsetFactorLowerBound
kSSVCAUserIntentPermanentOffsetFactorUpperBound
kSSVCA_DEVICE_SIMPLE_MIN_TTS_VOLUME
kSSVCA_DEVICE_SIMPLE_MAX_TTS_VOLUME
kSSVCA_DEVICE_DEFAULT_MIN_TTS_VOLUME
kSSVCA_DEVICE_DEFAULT_MAX_TTS_VOLUME
_permanentOffsetIsEnabled
_userIntentVolume
_latestVolume
_permanentOffsetFactor
_userIntentType
_userIntentTime
_userIntentValidForSeconds
_latestVolumeTime
TQ,N,V_userIntentType
TQ,N,V_userIntentTime
TQ,N,V_userIntentValidForSeconds
TQ,N,V_latestVolumeTime
Tf,N,V_userIntentVolume
Tf,N,V_latestVolume
Tf,N,V_permanentOffsetFactor
TB,N,V_permanentOffsetIsEnabled
initWithDroppingPrediction:droppedPrediction:timestamp:
toString
droppingPrediction
droppedPrediction
timestamp
_droppingPrediction
_droppedPrediction
_timestamp
Td,R,N,V_droppingPrediction
Td,R,N,V_droppedPrediction
Td,R,N,V_timestamp
speakAudio:
speakAudio:withScaleFactor:outASBD:playbackStarted:completion:
setIsConnected:
_isConnected
_enableAlwaysOnVoiceTrigger
_deviceType
_deviceID
_deviceUID
_productIdentifier
_injectionEngine
Tq,R,N,V_deviceType
T@"NSString",R,N,V_deviceName
T@"NSString",R,N,V_deviceID
T@"NSUUID",R,N,V_deviceUID
T@"NSString",R,N,V_productIdentifier
TB,N,V_isConnected
TB,N,V_enableAlwaysOnVoiceTrigger
T@"CSAudioInjectionEngine",W,N,V_injectionEngine
setTotalAudioRecorded:
setFeaturesAtEndpoint:
setEndpointerType:
setServerFeatureLatencyDistribution:
setAdditionalMetrics:
_totalAudioRecorded
_featuresAtEndpoint
_endpointerType
_serverFeatureLatencyDistribution
_additionalMetrics
Td,N,V_totalAudioRecorded
T@"NSArray",&,N,V_featuresAtEndpoint
Tq,N,V_endpointerType
T@"NSDictionary",&,N,V_serverFeatureLatencyDistribution
T@"NSDictionary",&,N,V_additionalMetrics
T@"NSString",C,N,V_deviceId
initWithSamplingRate:withAsset:
CSAlarmMonitor:didReceiveAlarmChanged:
CSTimerMonitor:didReceiveTimerChanged:
CSVolumeMonitor:didReceiveMusicVolumeChanged:
CSVolumeMonitor:didReceiveAlarmVolumeChanged:
smartSiriVolume
setSmartSiriVolume:
_smartSiriVolume
T@"<CSSmartSiriVolumeProcessor>",&,N,V_smartSiriVolume
T@"<CSConnectionServiceDelegate>",W,N,V_delegate
setValue:forKey:
_setMaximumBufferSizeFromInUseServices
createAudioFileWriterForAdBlockerWithInputFormat:outputFormat:withAccessoryID:
copyBufferWithNumSamplesCopiedIn:
isAdBlockerAudioLoggingEnabled
startWithUUID:withMaximumBufferSize:
stopWithUUID:
isListenPollingStarting
setIsListenPollingStarting:
audioLoggingBuffer
setAudioLoggingBuffer:
inUseServices
setInUseServices:
currentMaximumBufferSize
setCurrentMaximumBufferSize:
_currentMaximumBufferSize
_audioLoggingBuffer
_inUseServices
TB,N,V_isListenPollingStarting
T@"CSAudioCircularBuffer",&,N,V_audioLoggingBuffer
T@"NSMutableDictionary",&,N,V_inUseServices
Tf,N,V_currentMaximumBufferSize
attSiriUresNode:withUresScore:
_getInputoriginFromRecordType:
setInputOrigin:
setSpeechPackage:
setDidDetectSpeechActivity:
setIsAirpodsConnected:
setDecisionStage:
setTimeSinceLastQuery:
setPrevStageOutput:
setAcousticFTMScores:
setSpeakerIDScore:
setBoronScore:
setNldaScore:
setNldaMetaInfo:
_updateSupportedInputOrigins
_logFinalMitigationDecisionToSelf:
insertObject:atIndex:
_createMitigatorModelWithConfig:
_logURESFailureMsgInput:
_releaseUresProcessingTransaction
didMitigate
_storeMitigationDecision:forRCId:
detailedResult
_logURESResultsForInput:withOutput:
processInputFeats:completion:
_logLRNNFailMsg
_updateSignalsFrom:to:
isEqualToNumber:
_createModelAndRunInferenceForRcId:withCompletion:
_logLatticeRNNResults:
initWithConfig:error:
_holdTransactionForUresProcessing
allValues
isUIButtonPress
isHomePressed
isHearstDoubleTapTriggered
_decodeJsonFromFile:
arrayWithArray:
attSiriNode:didUpdateAttentionState:
getLastMitigationResult
configureAttendingState:
registerNLDAClassifierNode:
getLatestUresFeaturesWithCompletion:
registerOSDNode:
mitigator
setMitigator:
lastInputFeats
setLastInputFeats:
mitigationDecisions
setMitigationDecisions:
setSupportedInputOrigins:
shouldUpdateMitigationResult
setShouldUpdateMitigationResult:
osTransaction
setOsTransaction:
isAttending
setIsAttending:
cachedMitigationDecision
setCachedMitigationDecision:
_shouldUpdateMitigationResult
_isAttending
_cachedMitigationDecision
_mitigator
_lastInputFeats
_mitigationDecisions
_supportedInputOrigins
_osTransaction
T@"SLUresMitigator",&,N,V_mitigator
T@"SLUresMitigatorIpFeats",&,N,V_lastInputFeats
T@"NSMutableArray",&,N,V_mitigationDecisions
T@"NSArray",&,N,V_supportedInputOrigins
TB,N,V_shouldUpdateMitigationResult
T@"CSOSTransaction",&,N,V_osTransaction
TB,N,V_isAttending
TB,N,V_cachedMitigationDecision
T@"CSAttSiriOSDNode",W,N,SregisterOSDNode:,V_osdNode
T@"CSAttSiriNLDAClassifierNode",W,N,SregisterNLDAClassifierNode:,V_nldaClassifierNode
_hasDeviceTemporaryPairedNotInContacts
splitterDeviceList
shouldDisableSpeakerVerificationInSplitterMode
splitterEnabled
_splitterDeviceList
_splitterEnabled
TB,N,V_splitterEnabled
_didInstalledNewAdBlockerAsset
CSAdBlockerAssetDownloadMonitor:didInstallNewAsset:assetProviderType:
monitor
setMonitor:
_monitor
T@"CSTrialAssetDownloadMonitor",&,N,V_monitor
startManager
_createClearLoggingFileTimer
_startClearLoggingFilesTimer
supportHearstVoiceTrigger
supportJarvisVoiceTrigger
supportBluetoothDeviceVoiceTrigger
_getAudioRecorderWithError:
audioProviders
daysBeforeRemovingLogFiles
removeLogFilesOlderThanNDays:
removeOpportunisticAudioLoggingOlderThanNDays:
removeRemoteP2PLogFilesOlderThanNDays:
_handleClearLoggingFileTimer
audioFingerprintProvider
_getVoiceTriggerAssetIfNeeded:
registerSpeechController:
registerSiriClientProxy:
audioProviderWithUUID:
audioProviderWithStreamID:
_reinitializeSmartSiriVolumeWithAsset:
assetQueryQueue
setAssetQueryQueue:
setAudioProviders:
fallbackAudioSessionReleaseProvider
setFallbackAudioSessionReleaseProvider:
clientController
setClientController:
clearLoggingFileTimer
setClearLoggingFileTimer:
clearLoggingFileTimerCount
setClearLoggingFileTimerCount:
opportuneSpeakListnerTestService
setOpportuneSpeakListnerTestService:
postBuildInstallService
setPostBuildInstallService:
_assetQueryQueue
_audioProviders
_fallbackAudioSessionReleaseProvider
_clientController
_clearLoggingFileTimer
_clearLoggingFileTimerCount
_opportuneSpeakListnerTestService
_postBuildInstallService
T@"NSObject<OS_dispatch_queue>",&,N,V_assetQueryQueue
T@"NSMutableDictionary",&,N,V_audioProviders
T@"CSFallbackAudioSessionReleaseProvider",&,N,V_fallbackAudioSessionReleaseProvider
T@"<CSSpeechManagerDelegate>",W,N,V_clientController
T@"NSObject<OS_dispatch_source>",&,N,V_clearLoggingFileTimer
Tq,N,V_clearLoggingFileTimerCount
T@"CSOpportuneSpeakListnerTestService",&,N,V_opportuneSpeakListnerTestService
T@"CSPostBuildInstallService",&,N,V_postBuildInstallService
initWithDictionary:
notifyImplicitUtterance:audioDeviceType:audioRecordType:voiceTriggerEventInfo:otherCtxt:completion:
zeroFilterWindowSizeInMsForReport
shouldDeinterleaveAudioOnCS
_methodToken
_continuousZeroCounter
_zeroCounterWinSz
_zeroCounterWinSzForReport
_maxContinuousZeroCount
_analyzeStep
_shouldDeinterleaveAudio
supportAttentionLostAndGain
dictionaryWithDictionary:
expressionForConstantValue:
expressionForFunction:arguments:
expressionValueWithObject:context:
sortUsingComparator:
audioAlertProvider
setAudioAlertProvider:
setAudioMeterProvider:
_handleAudioProvidingMessage:messageBody:client:
_handlePingPongMessage:client:
_handleSetXPCClientTypeMessage:messageBody:client:
_handleAudioProvidingRequestTypeSwitchMessage:messageBody:client:
_getAudioProvideWithContext:streamClientType:
_notifyXPCDisconnectionToProxies
clientType
_notifyXPCDisconnectionToProxy:
audioSessionProvidingProxy
setAudioSessionProvidingProxy:
fallbackAudioSessionProvidingProxy
setFallbackAudioSessionProvidingProxy:
audioSessionInfoProvidingProxy
setAudioSessionInfoProvidingProxy:
audioStreamProvidingProxy
setAudioStreamProvidingProxy:
audioAlertProvidingProxy
setAudioAlertProvidingProxy:
audioMeterProvidingProxy
setAudioMeterProvidingProxy:
audioMetricProvidingProxy
setAudioMetricProvidingProxy:
setClientType:
_audioSessionProvidingProxy
_fallbackAudioSessionProvidingProxy
_audioSessionInfoProvidingProxy
_audioStreamProvidingProxy
_audioAlertProvidingProxy
_audioMeterProvidingProxy
_audioMetricProvidingProxy
_clientType
T@"CSAudioSessionProvidingProxy",&,N,V_audioSessionProvidingProxy
T@"CSFallbackAudioSessionReleaseProvidingProxy",&,N,V_fallbackAudioSessionProvidingProxy
T@"CSAudioSessionInfoProvidingProxy",&,N,V_audioSessionInfoProvidingProxy
T@"CSAudioStreamProvidingProxy",&,N,V_audioStreamProvidingProxy
T@"CSAudioAlertProvidingProxy",&,N,V_audioAlertProvidingProxy
T@"CSAudioMeterProvidingProxy",&,N,V_audioMeterProvidingProxy
T@"CSAudioMetricProvidingProxy",&,N,V_audioMetricProvidingProxy
TQ,N,V_clientType
T@"<CSXPCConnectionDelegate>",W,N,V_delegate
initWithAttSiriController:supportsAttentiveSiri:supportsSpeechRecognitionOnDevice:supportsSSR:
_setupAttSiriServiceListener
_setupEndpointListener
_setupLocalSpeechRecognitionListener
_setupSSRListener
didDetectHardEndpointAtTime:withMetrics:
setupListeners
localSpeechRecognitionListener
setLocalSpeechRecognitionListener:
setSupportsSpeechRecognitionOnDevice:
supportsSSR
setSupportsSSR:
_supportsSpeechRecognitionOnDevice
_supportsSSR
_localSpeechRecognitionListener
T@"CSAttSiriController",&,N,V_attSiriController
T@"CSConnectionListener",&,N,V_localSpeechRecognitionListener
TB,N,V_supportsSpeechRecognitionOnDevice
TB,N,V_supportsSSR
_daemonDidLaunch
_daemonWillShutdown
_setupNotifyHandlers
notifyDaemonStateChanged:
sharedDaemon
didLaunch
shutdown
xpcListener
setXpcListener:
activationXpcListener
setActivationXpcListener:
voiceIdXpcListener
setVoiceIdXpcListener:
voiceTriggerXpcListener
setVoiceTriggerXpcListener:
audioInjectionXpcListener
setAudioInjectionXpcListener:
attSiriConnectionManager
setAttSiriConnectionManager:
corespeechServiceListener
setCorespeechServiceListener:
speechModelTrainingXpcManager
setSpeechModelTrainingXpcManager:
benchmarkXpcListener
setBenchmarkXpcListener:
signalSource
setSignalSource:
_xpcListener
_activationXpcListener
_voiceIdXpcListener
_voiceTriggerXpcListener
_audioInjectionXpcListener
_attSiriConnectionManager
_corespeechServiceListener
_speechModelTrainingXpcManager
_benchmarkXpcListener
_signalSource
T@"CSXPCListener",&,N,V_xpcListener
T@"CSActivationXPCListener",&,N,V_activationXpcListener
T@"CSVoiceIdXPCListener",&,N,V_voiceIdXpcListener
T@"CSVoiceTriggerXPCListener",&,N,V_voiceTriggerXpcListener
T@"CSAudioInjectionXPCListener",&,N,V_audioInjectionXpcListener
T@"CSAttSiriConnectionManager",&,N,V_attSiriConnectionManager
T@"CSCoreSpeechServicesListener",&,N,V_corespeechServiceListener
T@"CSSpeechModelTrainingXPCManager",&,N,V_speechModelTrainingXpcManager
T@"CSBenchmarkXPCListener",&,N,V_benchmarkXpcListener
T@"NSObject<OS_dispatch_source>",&,N,V_signalSource
_emitMHEndpointLatencyInfo:withRequestMHUUID:
currentContext
initWithInstanceContext:
firstPktLatency
trailingPktSpeechLatencies
setTrailingPktSpeechLatencies:
trailingPktLatencies
setTrailingPktLatencies:
numOfAudioPackets
setNumOfAudioPackets:
numOfValidTrailingPackets
setNumOfValidTrailingPackets:
numOfValidTrailingSpeechPackets
setNumOfValidTrailingSpeechPackets:
_firstPktLatency
_trailingPktSpeechLatencies
_trailingPktLatencies
_numOfAudioPackets
_numOfValidTrailingPackets
_numOfValidTrailingSpeechPackets
T@"NSMutableArray",&,N,V_trailingPktSpeechLatencies
T@"NSMutableArray",&,N,V_trailingPktLatencies
TQ,N,V_numOfAudioPackets
TQ,N,V_numOfValidTrailingPackets
TQ,N,V_numOfValidTrailingSpeechPackets
Td,N,V_firstPktLatency
readAudioChunksFrom:block:
_didReceiveDaemonStateChanged:
_notifyObserver:withDaemonState:
coreSpeechDaemonStateMonitor:didReceiveStateChanged:
currentBuiltinSpeakerState
isBuiltinSpeakerMuted
setBuiltInSpeakerState:
T@"<CSRemoteRecordClientDelegate>",W,N,V_delegate
TQ,R,N,V_audioStreamHandleId
processIdentifier
clientConnections
setClientConnections:
machServiceName
setMachServiceName:
_exportedInterface
_remoteInterface
_proxyObject
_clientConnections
_machServiceName
T@"NSMutableArray",&,N,V_clientConnections
T@"NSString",&,N,V_machServiceName
_enableCoreSpeechDaemonKeepAlive
_coreSpeechDaemonKeepAlived
writeToFile:atomically:encoding:error:
localizedRecoverySuggestion
CSSiriAssertionMonitor:didReceiveEnabled:
_assertionState
resetDucking
_handleSessionProvidingRequestTypePrewarmMessage:client:
_handleSessionProvidingRequestTypeActivateMessage:messageBody:client:
_handleSessionProvidingRequestTypeDeactivateMessage:messageBody:client:
_handleSessionProvidingRequestTypeGetDuckOthersOption:messageBody:client:
_handleSessionProvidingRequestTypeSetDuckOthersOption:messageBody:client:
_handleSessionProvidingRequestTypeEnableMiniDucking:messageBody:client:
_handleSessionProvidingRequestTypeDuckAudioDevice:messageBody:client:
_handleSessionProvidingRequestTypeDuckDefaultOutputAudioDevice:messageBody:client:
_handleSessionProvidingRequestTypeEnableSmartRoutingConsideration:messageBody:client:
_handleSessionProvidingRequestTypeReportDynamicActivityAttribute:messageBody:client:
duckAudioDeviceWithDeviceID:duckedLevel:rampDuration:
duckDefaultOutputAudioDeviceWithDuckedLevel:rampDuration:
audioSessionProvider:didReceiveAudioSessionInterruptionNotificationWithUserInfo:
audioSessionProvider:didReceiveAudioSessionRouteChangeNotificationWithUserInfo:
audioSessionProvider:didReceiveAudioSessionMediaServicesWereLostNotificationWithUserInfo:
audioSessionProvider:didReceiveAudioSessionMediaServicesWereResetNotificationWithUserInfo:
manualDuckingHandler
setManualDuckingHandler:
_manualDuckingHandler
T@"CSManualDuckingHandler",&,N,V_manualDuckingHandler
splitterState:
isUserActive
getLocalUrl
_compatibilityVersion
stringValue
appendString:
_version
_footprint
assetForAssetType:resourcePath:configVersion:
isPremium
_notifyStopCommandControl
_isCommandControlStreaming
_handleAlertProvidingRequestTypeSetAlertSoundMessage:messageBody:client:
_handleAlertProvidingRequestTypePlayAlertSoundMessage:messageBody:client:
_handleAlertProvidingRequestTypePlayRecordStartingAlertAndResetEndpointerMessage:messageBody:client:
_handleAlertProvidingRequestTypeAlertStartTimeMessage:messageBody:client:
_handleAlertProvidingRequestTypeConfigureAlertBehavior:messageBody:client:
_sendReplyMessageWithResult:event:client:
_audioAlertProvider
T@"<CSAudioAlertProviding>",W,N,V_audioAlertProvider
_startObservingAVCallActiveChange
_handleCallActiveDidChangeNotification:
hasConnectedAVCall
_hasConnectedAVCall
_handleVoiceTriggerXPCServiceMessage:client:
_handleServiceConnectionLostIfNeeded
_handlePhraseSpotterBypassRequest:
_handleVoiceTriggeredSiriSessionCancelled
_handleEnableVoiceTriggerWithSiriAssertionRequest:
_handleRaiseToSpeakBypassRequest:
_handleVoiceTriggerStatsFetchEvent:client:
T@"<CSVoiceTriggerXPCConnectionDelegate>",W,N,V_delegate
startWithContext:audioStreamId:
kwdSpotter
setKwdSpotter:
didTrigger
setDidTrigger:
setAudioStreamId:
_didTrigger
_kwdSpotter
_audioStreamId
T@"CSFlexKeywordSpotter",&,N,V_kwdSpotter
T@"CSAttSiriRequestContext",&,N,V_context
TB,N,V_didTrigger
TQ,N,V_audioStreamId
triggerVoiceProfileRetrainingWithAsset:
playbackDeviceTypeList
_recordDeviceInfo
_playbackRoute
_playbackDeviceTypeList
T@"CSAudioRecordDeviceInfo",R,C,N,V_recordDeviceInfo
T@"NSString",R,C,N,V_playbackRoute
T@"NSArray",R,C,N,V_playbackDeviceTypeList
mainRunLoop
_didReceiveNewAdBlockerAssetMetaData
adBlockerAssetDecoderWithVersion:
_createDeInterleaverIfNeeded
_startAudioFeedingTimer
lpcmNonInterleavedASBD
_deinterleaveBufferIfNeeded:
setFileOption:
_defaultOutASBD
lpcmFloatASBD
fileOption
setIsRecording:
bufferDuration
setBufferDuration:
injectionAudioFileList
setInjectionAudioFileList:
injectionStartNotifyBlocks
setInjectionStartNotifyBlocks:
injectionCompletionNotifyBlocks
setInjectionCompletionNotifyBlocks:
deinterleaver
setDeinterleaver:
pNonInterleavedABL
setPNonInterleavedABL:
didSetScaleFactor
setDidSetScaleFactor:
setScaleFactor:
_isRecording
_didSetScaleFactor
_fileOption
_injectionAudioFileList
_injectionStartNotifyBlocks
_injectionCompletionNotifyBlocks
_deinterleaver
T@"CSAudioInjectionFileOption",&,N,V_fileOption
TB,N,V_isRecording
Td,N,V_bufferDuration
T@"NSMutableArray",&,N,V_injectionAudioFileList
T@"NSMutableArray",&,N,V_injectionStartNotifyBlocks
T@"NSMutableArray",&,N,V_injectionCompletionNotifyBlocks
T^{OpaqueAudioConverter=},N,V_deinterleaver
T^{AudioBufferList=I[1{AudioBuffer=II^v}]},N,V_pNonInterleavedABL
TB,N,V_didSetScaleFactor
Tf,N,V_scaleFactor
_checkSoftwareUpdateCheckingState
_didReceiveSoftwareUpdateCheckingStateChanged:
_softwareUpdateCheckingState
_notifyObserver:withSoftwareUpdateCheckingRunning:
CSSoftwareUpdateCheckingMonitor:didReceiveStateChanged:
_didReceiveSoftwareUpdateCheckingStateChangedInQueue:
_isSoftwareUpdateCheckingRunning
lpcmInt16NarrowBandASBD
opusNarrowBandASBD
_configureAudioConverter:
_convertBufferedLPCM:allowPartial:timestamp:arrivalTimestampToAudioRecorder:
replaceBytesInRange:withBytes:length:
narrowBandOpusConverter
_opusConverter
_bufferedLPCM
_recordBasePacketsPerSecond
_opusOutASBD
_convertPacketCount
_convertAudioCapacity
_lastTimestamp
_lastArrivalTimestampToAudioRecorder
_outPacketSizeInSec
T@"<CSAudioConverterDelegate>",W,V_delegate
_notifyObserver:mediaIsPlayingState:
_notePossiblePlayPausedStateChange:
mediaPlayingStateWithCompletion:
_addVoiceTriggerAOPModeEnabledConditions
forceVoiceTriggerAPMode
_addConditionsForIOSBargeIn
_addConditionsForIOSAOP
_isSpeechDetectionDevicePresent
isSiriClientConsideredAsRecord
setIsSiriClientConsideredAsRecord:
setPendingRecordingStopUUID:
notifyCallbackWithOption:
pendingRecordingStopUUID
_recordStateQueue
_isSiriClientConsideredAsRecord
_pendingRecordingStopUUID
TB,N,V_isSiriClientConsideredAsRecord
T@"NSString",&,N,V_pendingRecordingStopUUID
updateDeviceId:
_shouldUseRemoteRecorder
_streamHandleId
T@"CSAudioRecordContext",R,N,V_recordContext
TB,R,N,V_shouldUseRemoteRecorder
TQ,R,N,V_streamHandleId
sharedVoiceTriggerClient
voiceTriggerAOPModeEnabledPolicy
_availabilityChanged
_didReceivedNetworkAvailabilityChangedNotification:
_notifyObserver:withNetworkAvailability:
CSNetworkAvailabilityMonitor:didReceiveNetworkAvailabilityChanged:
_handleMeterProvidingRequestTypeSetMeteringEnabledMessage:messageBody:client:
_handleMeterProvidingRequestTypeUpdateMetersMessage:messageBody:client:
_handleMeterProvidingRequestTypePowerMessage:messageBody:client:powerType:
audioMeterProvider
_audioMeterProvider
T@"<CSAudioMeterProviding>",W,N,V_audioMeterProvider
CSMicUsageReporter
v8@?0
com.apple.siri.speechmodeltraining
com.apple.corespeech.speechmodeltraining.xpc
com.apple.speech.speechmodeltraining
SpeechModelTrainingClient
v24@?0@"NSString"8@"NSError"16
v16@?0@"NSError"8
v16@?0@"NSString"8
v24@?0@"NSDictionary"8@"NSError"16
Assistant/SpeechPersonalizedLM
Assistant/SpeechPersonalizedLM_Fides
Received Error %@
Input directory path(%@) does not match expected path
Dictation
-[CSSyncKeywordAnalyzerQuasar initWithConfigPath:triggerTokens:useKeywordSpotting:preventDuplicatedReset:]
-[CSSyncKeywordAnalyzerQuasar resetWithLanguage:withFarField:withAudioSource:]
-[CSSyncKeywordAnalyzerQuasar flushAudio]
-[CSSyncKeywordAnalyzerQuasar processAudioChunk:]
-[CSSyncKeywordAnalyzerQuasar phraseIdScores]
+[CSSyncKeywordAnalyzerQuasar dumpEARSpeechRecognitionResults:]
v32@?0@"_EARSpeechRecognitionToken"8Q16^B24
samples_fed
best_start
best_end
best_score
is_secondchance
isEarlyDetect
type
-[CSFallbackAudioSessionReleaseProvidingProxy handleXPCMessage:messageBody:client:]
option
-[CSFallbackAudioSessionReleaseProvidingProxy _handleDeactivateAudioSessionRequestMessage:messageBody:client:]
result
resultErrorDomain
resultErrorCode
+[CSUserIdentityClassifier pickTopScoringProfileIdFromScores:]
+[CSUserIdentityClassifier classifyUserIdentityFor:withScores:withAsset:]
Confident
Known
Unknown
Unsure1
UnsureN
+[CSUserIdentityClassifier stringFromClassificationCategory:]
-[CSAudioStartStreamOption(AVVC) avvcStartRecordSettingsWithAudioStreamHandleId:]
com.apple.corespeech.corespeechd.activation.xpc
v16@?0@"NSObject<OS_xpc_object>"8
-[CSActivationXPCClient dealloc]
-[CSActivationXPCClient _handleListenerEvent:]
-[CSActivationXPCClient _handleListenerError:]
-[CSActivationXPCClient notifyActivationEvent:completion:]
v20@?0B8@"NSError"12
event
CSAttSiriRequestSourceKey
SiriFollowupforIdleAndQuiet
LockScreenNotification
-[CSAudioSampleRateConverter _createSampleRateConverterWithInASBD:outASBD:]
i32@?0^I8^{AudioBufferList=I[1{AudioBuffer=II^v}]}16^^{AudioStreamPacketDescription}24
-[CSAudioSampleRateConverter convertSampleRateOfBuffer:]
v12@?0i8
-[CSSpeakerRecognitionAssetMetaUpdateMonitor _startMonitoringWithQueue:]
-[CSSpeakerRecognitionAssetMetaUpdateMonitor _stopMonitoring]
-[CSSpeakerRecognitionAssetMetaUpdateMonitor _didReceiveSpeakerRecognitionAssetMetaData]
v16@?0@8
com.apple.MobileAsset.SpeakerRecognitionAssets.ma.cached-metadata-updated
Audio/Video
Alarm
CSVolumeMonitor queue
-[CSVolumeMonitor _startMonitoringWithQueue:]
-[CSVolumeMonitor fetchVolumeFromAVSystemControllerForAudioCategory:]_block_invoke
-[CSVolumeMonitor systemControllerDied:]
-[CSVolumeMonitor startObservingSystemVolumes]
-[CSVolumeMonitor _startObservingSystemControllerLifecycle]
CSFallbackAudioSessionReleaseProvider
-[CSFallbackAudioSessionReleaseProvider fallbackDeactivateAudioSession:error:]_block_invoke
-[CSFallbackAudioSessionReleaseProvider fallbackDeactivateAudioSession:error:]
-[CSSpeakerRecognitionAssetDownloadMonitor _startMonitoringWithQueue:]
-[CSSpeakerRecognitionAssetDownloadMonitor _stopMonitoring]
-[CSSpeakerRecognitionAssetDownloadMonitor _didInstalledNewAsset]
-[CSSpeakerRecognitionAssetDownloadMonitor trialAssetDownloadMonitorDelegate:didInstallNewAsset:assetType:]
com.apple.MobileAsset.SpeakerRecognitionAssets.ma.new-asset-installed
{wordCount: %ld, trailingSilDuration: %ld, eosLikelihood: %f, pauseCounts: (%@), silencePosterior: %f, taskName: %@, processedAudioDurationInMilliseconds: %ld}
WordCount
TrailingSilDuration
EOSLikelihood
PauseCounts
SilencePosterior
ProcessedAudioDurationInMilliseconds
-[CSVoiceTriggerXPCServiceProxy enableVoiceTrigger:withAssertion:timestamp:]
voicetrigger assertion queue
-[CSVoiceTriggerXPCServiceProxy enableVoiceTrigger:withAssertion:timestamp:]_block_invoke
Enabled
Disabled
phrasespotter assertion queue
-[CSVoiceTriggerXPCServiceProxy setPhraseSpotterBypassing:timeout:]_block_invoke_2
bypassed
NOT bypassed
-[CSVoiceTriggerXPCServiceProxy setPhraseSpotterBypassing:timeout:]_block_invoke
raise-to-speak assertion queue
-[CSVoiceTriggerXPCServiceProxy setRaiseToSpeakBypassing:timeout:]_block_invoke_2
-[CSVoiceTriggerXPCServiceProxy setRaiseToSpeakBypassing:timeout:]_block_invoke
-[CSVoiceTriggerXPCServiceProxy notifyVoiceTriggeredSiriSessionCancelled]
-[CSVoiceTriggerXPCServiceProxy notifyServiceConnectionLost]
-[CSAttSiriAudioSessionStateClient initWithDelegate:]
SiriStateNotificationListener
com.apple.siri.client-state-changed
-[CSAttSiriAudioSessionStateClient notifyObserver:didReceiveNotificationWithToken:]
-[CSAttSiriAudioSessionStateClient notifyObserver:didChangeStateFrom:to:]
-[CSAttSiriAudioSessionStateClient dispatchStateChangedFrom:to:]
-[CSAudioStreamProvidingProxy setAudioStreamProvidingForProxy:]
-[CSAudioStreamProvidingProxy CSXPCConnectionReceivedClientError:clientError:client:]
-[CSAudioStreamProvidingProxy handleXPCMessage:messageBody:client:]
-[CSAudioStreamProvidingProxy _handleSetCurrentConextMessage:messageBody:client:]
context
audioStreamRequest
-[CSAudioStreamProvidingProxy _handleAudioStreamRequestMessage:messageBody:client:]
-[CSAudioStreamProvidingProxy _handleAudioStreamPrepareMessage:messageBody:client:]
startAudioStreamOption
-[CSAudioStreamProvidingProxy _handleStartAudioStreamMessage:messageBody:client:]
-[CSAudioStreamProvidingProxy _handleStopAudioStreamMessage:messageBody:client:]
-[CSAudioStreamProvidingProxy _handleVoiceTriggerInfoMessage:messageBody:client:]
voiceTriggerInfo
rtsTriggerInfo
-[CSAudioStreamProvidingProxy _handleIsRecordingMessage:messageBody:client:]
-[CSAudioStreamProvidingProxy _handleRecordRouteMessage:messageBody:client:]
recordRoute
-[CSAudioStreamProvidingProxy _handleRecordDeviceInfo:messageBody:client:]
recordDeviceInfo
-[CSAudioStreamProvidingProxy _handleAudioDeviceInfo:messageBody:client:]
audioDeviceInfo
-[CSAudioStreamProvidingProxy _handleRecordSettings:messageBody:client:]
recordSettings
-[CSAudioStreamProvidingProxy _handleIsNarrowband:messageBody:client:]
-[CSAudioStreamProvidingProxy _handlePlaybackRouteMessage:messageBody:client:]
playbackRoute
-[CSAudioStreamProvidingProxy audioStreamProvider:didStopStreamUnexpectly:]
stopReason
chunk
-[CSAudioStreamProvidingProxy audioStreamProvider:didHardwareConfigurationChange:]
hardwareConfig
body
-[CSAudioStreamProvidingProxy _setAllowMixableAudioWhileRecording:]
Token
BestScore
StartSampleId
EndSampleId
com.apple.flxkwd
-[CSFlexKeywordSpotter startKeywordSpottingWithCompletion:]_block_invoke_2
-[CSFlexKeywordSpotter startKeywordSpottingWithCompletion:]_block_invoke
Unexpected exception creating KeywordDetector
reason
Exception creating KeywordDetector: %s
v24@?0@"CSAsset"8@"NSError"16
-[CSFlexKeywordSpotter processAudioChunk:]_block_invoke
-[CSFlexKeywordSpotter speechRecognizer:didFinishRecognitionWithError:]
-[CSFlexKeywordSpotter speechRecognizer:didRecognizeFinalResults:]
Kwds: 
%@:%f:%f:%f
===WinningTok=%@, bestScore=%f===
-[CSFlexKeywordSpotter speechRecognizer:didRecognizePartialResultNbest:]_block_invoke
-[CSFlexKeywordSpotter speechRecognizer:didRecognizePartialResult:]
getThresholdsMapAt_block_invoke
-[CSAttSiriAttendingAudioSrcNode initWithAttSiriController:]
CSAttSiriAudioSrcNode Attending queue
-[CSAttSiriAttendingAudioSrcNode initWithSpeechManager:audioStreamProvider:streamName:streamRequest:]
CSAttSiriAudioSrcNode
-[CSAttSiriAttendingAudioSrcNode startAudioStreamWithOption:completion:]_block_invoke_2
-[CSAttSiriAttendingAudioSrcNode addReceiver:]_block_invoke
-[CSAttSiriAttendingAudioSrcNode dealloc]
-[CSAttSiriAttendingAudioSrcNode _handleDidStop]
-[CSAudioFileLog _closeAudioFile]
-[CSAudioFileLog startRecording]_block_invoke
-input.wav
-[CSAudioFileLog appendAudioData:]_block_invoke
-[CSAudioFileLog stopRecording]_block_invoke
Logs/CrashReporter/CoreSpeech/audio/
-[CSAudioFileLog _getOrCreateAudioLogDirectory]
/tmp
en_US_POSIX
yyyyMMdd-HHmmss
%@/%@%@%@
CSAudioSessionInfoProvider
-[CSAudioSessionInfoProvider audioSessionIdForDeviceId:]
-[CSAudioSessionInfoProvider CSAudioServerCrashMonitorDidReceiveServerCrash:]_block_invoke
-[CSAudioSessionInfoProvider CSAudioServerCrashMonitorDidReceiveServerRestart:]_block_invoke
-[CSAudioSessionInfoProvider _registerInterruptionNotification]
-[CSAudioSessionInfoProvider _registerAudioRouteChangeNotification]
-[CSAudioSessionInfoProvider _handleInterruption:]_block_invoke
-[CSAudioSessionInfoProvider _audioRouteChanged:]_block_invoke
RouteChangeNotificationInfo
-[CSAudioSessionInfoProvider _deregisterAudioSessionNotifications]
firstPassTriggerSource
ApplicationProcessor
Remora
CSPreMyriadCoordinator Queue
-[CSPreMyriadCoordinator _clearPendingRemoraVoiceTrigger]
-[CSPreMyriadCoordinator handlePendingRemoraVoiceTriggerIfNeeded]
-[CSPreMyriadCoordinator handlePendingRemoraVoiceTriggerIfNeeded]_block_invoke
-[CSPreMyriadCoordinator _clearPendingBuiltInVoiceTrigger]
-[CSPreMyriadCoordinator handlePendingBuiltInVoiceTriggerIfNeeded]
-[CSPreMyriadCoordinator handlePendingBuiltInVoiceTriggerIfNeeded]_block_invoke
v32@?0@"NSString"8@"CSPreMyriadVoiceTriggerMetaData"16^B24
-[CSPreMyriadCoordinator secondPassDidStopForClient:deviceId:]
-[CSPreMyriadCoordinator secondPassDidStartForClient:deviceId:withFirstPassEstimate:]
+[CSUtils(AttSiri) logMitigationFeatures:forTask:withModelOutput:forMHRequestId:]
%@-%@.json
Task
Transcript
DetailedModelResult
AcousticFTMScore
InputOrigin
osdSignal
timeSinceLastQuery
airpodsConnected
boronSignal
decisionStage
prevInputLevel
speakerIDScore
eosLikelihood
timestamp
RawASRRecogCandidate
LatticeRNNResult
NLDAMetaInfo
triggerEndMachTime
triggerFireMachTime
-[CSAttSiriEndpointerNode initWithAttSiriController:]
CSAttSiriEndpointerNode queue
CSAttSiriEndpointerNode Latency Queue
-[CSAttSiriEndpointerNode addReceiver:]_block_invoke
-[CSAttSiriEndpointerNode resetForNewRequestWithSampleRate:recordContext:recordOption:voiceTriggerInfo:]_block_invoke
audioURL : %@, numberOfChannels : %lu, scaleFactor: %f
CSSmartSiriVolumeEnablePolicy queue
B8@?0
-[CSSmartSiriVolumeEnablePolicy _addSmartSiriVolumeEnabledConditions]_block_invoke
triggerEndSeconds
userIdentityClassification
userClassified
-[CSAttSiriSSRNode stop]_block_invoke
-[CSAttSiriSSRNode addReceiver:]_block_invoke
B24@?0@"SSRVoiceProfile"8@"NSDictionary"16
-[CSAttSiriSSRNode filteredVoiceProfileArray:]
en-US
-[CSAttSiriSSRNode _setupSSRControllerWithAudioContext:withVoiceTriggerEventInfo:]
-[CSAttSiriSSRNode _setupSSRControllerWithAudioContext:withVoiceTriggerEventInfo:]_block_invoke_2
-[CSAttSiriSSRNode _setupSSRControllerWithAudioContext:withVoiceTriggerEventInfo:]_block_invoke
-[CSAttSiriSSRNode _setupSpeakerRecognitionForProfiles:WithVTEventInfo:WithLocale:]
-[CSAttSiriSSRNode _refreshSpeakerRecognitionAssets]
-[CSAttSiriSSRNode startXPCConnection]
-[CSAttSiriSSRNode CSSpeakerRecognitionAssetDownloadMonitor:didInstallNewAsset:assetProviderType:]_block_invoke
-[CSAttSiriSSRNode speakerRecognitionController:hasSpeakerInfo:]_block_invoke
-[CSAttSiriSSRNode speakerRecognitionController:hasSpeakerInfo:]
-[CSAttSiriSSRNode speakerRecognitionFinishedProcessing:withFinalSpeakerInfo:]_block_invoke
-[CSAttSiriSSRNode _processSpeakerRecognitionResult:]
-[CSAttSiriSSRNode _mapScoresToSharedSiriId:]
-[CSAttSiriSSRNode _stopProcessing]
-[CSAttSiriSSRNode _stopProcessing]_block_invoke
-[CSAttSiriSSRNode attSiriAudioSrcNodeDidStop:]_block_invoke
-[CSSiriRestrictionOnLockScreenMonitor _startMonitoringWithQueue:]
-[CSSiriRestrictionOnLockScreenMonitor _stopMonitoring]
-[CSSiriRestrictionOnLockScreenMonitor _checkSiriRestrictedOnLockScreen]
-[CSPostBuildInstallService registerPostBuildInstallService]
-[CSPostBuildInstallService registerPostBuildInstallService]_block_invoke
com.apple.cs.postinstall
com.apple.transcribe.Transcriber
-[CSKeywordAnalyzerQuasar initWithConfigPath:triggerTokens:useKeywordSpotting:]
-[CSKeywordAnalyzerQuasar initWithConfigPath:triggerTokens:useKeywordSpotting:]_block_invoke
-[CSKeywordAnalyzerQuasar reset]
-[CSKeywordAnalyzerQuasar dealloc]
-[CSKeywordAnalyzerQuasar runRecognition]
-[CSKeywordAnalyzerQuasar runRecognition]_block_invoke
-[CSKeywordAnalyzerQuasar endAudio]
-[CSKeywordAnalyzerQuasar endAudio]_block_invoke
-[CSKeywordAnalyzerQuasar _recognizeWavData:length:]
-[CSKeywordAnalyzerQuasar speechRecognizer:didRecognizePartialResult:]_block_invoke
-[CSKeywordAnalyzerQuasar speechRecognizer:didRecognizeFinalResults:]_block_invoke
-[CSKeywordAnalyzerQuasar _phraseIdToCtcScoreMap]
-[CSKeywordAnalyzerQuasar speechRecognizer:didFinishRecognitionWithError:]_block_invoke
-[CSKeywordAnalyzerQuasar _getConfidence:]_block_invoke
-[CSVoiceTriggerAssetHandlerMac _getVoiceTriggerAssetFromAssetManagerWithLocale:completion:]_block_invoke
-[CSVoiceTriggerAssetHandlerMac _getVoiceTriggerAssetFromAssetManagerWithLocale:completion:]_block_invoke_2
-[CSVoiceTriggerAssetHandlerMac _checkNewAssetAvailablity]_block_invoke
-[CSVoiceTriggerAssetHandlerMac _checkNewAssetAvailablityForEndpoint]_block_invoke
-[CSVoiceTriggerAssetHandlerMac CSVoiceTriggerAssetDownloadMonitor:didInstallNewAsset:]
-[CSVoiceTriggerAssetHandlerMac CSLanguageCodeUpdateMonitor:didReceiveLanguageCodeChanged:]
-[CSVoiceTriggerAssetHandlerMac CSFirstUnlockMonitor:didReceiveFirstUnlock:]
-[CSVoiceTriggerAssetHandlerMac trialAssetDownloadMonitorDelegate:didInstallNewAsset:assetType:]
RequestContext
DetectedToken
TriggerMachTime
TriggerAbsStartSampleId
{attendingCtx: %@, detctedToken: %@, triggerMachTime=%llu, triggerStartSampleId=%llu}
[requestHistoricalAudioDataWithHostTime = %@]
[requestHistoricalAudioDataSampleCount = %@]
[useOpportunisticZLL = %@]
[startRecordingHostTime = %llu]
[startRecordingSampleCount = %llu]
[alertBehavior = %llu %llu %llu]
[skipAlertBehavior = %@]
[requireSingleChannelLookup = %@]
[selectedChannel = %u]
[estimatedStartHostTime = %llu
[disableEndpointer = %d]
[disableLocalSpeechRecognizer = %d]
[disablePrewarmLocalSpeechRecognizer = %d]
requestHistoricalAudioDataWithHostTime
requestHistoricalAudioDataSampleCount
startRecordingHostTime
startRecordingSampleCount
useOpportunisticZLL
startAlertBehavior
stopAlertBehavior
errorAlertBehavior
skipAlertBehavior
requireSingleChannelLookup
selectedChannel
estimatedStartHostTime
disableEndpointer
disableLocalSpeechRecognizer
disablePrewarmLocalSpeechRecognizer
requestMHUUID
siriSessionUUID
triggerScore
effectiveThreshold
recognizerScore
recognizerThresholdOffset
threshold
satThreshold
isSecondChance
supportedPhrases
mpvt2ndPassTriggeredPhraseId
phraseId
phraseStr
ndapiScore
2ndChanceThreshold
loggingThreshold
recognizerScoreScaleFactor
tdsrSatCombinedSATThreshold
%lu:%@:ndapi=%f:ctc=%f:comb=%f:thr=%f:maxd=%d:
%lu:%@:ndapi=%f:ctc=%f:comb=%f:thr=%f:maxd=%d:res=%@
-[CSVTSecondPassScorer initWithAsset:firstPassSource:]
-[CSVTSecondPassScorer updateWithCtcCheckerResults:]
-[CSVTSecondPassScorer getTriggeredPhraseWithSecondChanceEnabled:]
%@, 
com.apple.corespeech.corespeechservices
com.apple.corespeech.xpc
+[CSCoreSpeechServices installedVoiceTriggerAssetForLanguageCode:completion:]_block_invoke
CoreSpeechXPC service invalidated
+[CSCoreSpeechServices fetchRemoteVoiceTriggerAssetForLanguageCode:completion:]_block_invoke
+[CSCoreSpeechServices getCurrentVoiceTriggerLocaleWithEndpointId:completion:]
+[CSCoreSpeechServices getCurrentVoiceTriggerLocaleWithEndpointId:completion:]_block_invoke
+[CSCoreSpeechServices voiceTriggerRTModelForVersion:minorVersion:accessoryRTModelType:endpointId:downloadedModels:preinstalledModels:completion:]_block_invoke
+[CSCoreSpeechServices voiceTriggerRTModelForVersion:minorVersion:downloadedModels:preinstalledModels:completion:]
+[CSCoreSpeechServices voiceTriggerRTModelForVersion:minorVersion:downloadedModels:preinstalledModels:completion:]_block_invoke
+[CSCoreSpeechServices voiceTriggerJarvisLanguageList:jarvisSelectedLanguage:completion:]_block_invoke
+[CSCoreSpeechServices voiceTriggerJarvisLanguageList:jarvisSelectedLanguage:completion:]
+[CSCoreSpeechServices requestUpdatedSATAudio]_block_invoke
v12@?0B8
+[CSCoreSpeechServices getFirstPassRunningMode]_block_invoke
v16@?0q8
VoiceTrigger Asset Change Monitor
com.apple.corespeech.voicetriggerassetchange
-[CSAudioServerCrashMonitor _startMonitoringWithQueue:]
CSXPCClient Reply Queue
CSXPCClient connection Queue
-[CSXPCClient connect]_block_invoke
com.apple.corespeech.corespeechd.xpc
-[CSXPCClient _sendXPCClientType]
xpcClientType
-[CSXPCClient prepareAudioProviderWithContext:clientType:error:]
clientType
activateReason
dynamicAttribute
dictationRequestBundleId
deactivateOption
setDuckOthersOption
enableSmartRoutingConsideration
enableMiniDucking
alertType
soundPath
alertStartTime
-[CSXPCClient alertStartTime]_block_invoke
alertBehavior
setMeterEnable
channelNumber
power
-[CSXPCClient peakPowerForChannel:]_block_invoke
-[CSXPCClient averagePowerForChannel:]_block_invoke
-[CSXPCClient audioMetric]_block_invoke
audioMetric
-[CSXPCClient audioStreamWithRequest:streamName:error:]
v24@?0@"CSAudioStream"8@"NSError"16
-[CSXPCClient audioStreamWithRequest:streamName:completion:]
-[CSXPCClient audioStreamWithRequest:streamName:completion:]_block_invoke
-[CSXPCClient prepareAudioStreamSync:request:error:]
-[CSXPCClient prepareAudioStream:request:completion:]
v16@?0@"NSDictionary"8
-[CSXPCClient acousticSLResultForContext:completion:]
-[CSXPCClient acousticSLResultForContext:completion:]_block_invoke_2
acousticSLResult
-[CSXPCClient acousticSLResultForContext:completion:]_block_invoke
v24@?0@"NSDictionary"8@"NSDictionary"16
-[CSXPCClient triggerInfoForContext:completion:]
-[CSXPCClient audioStreamId]
-[CSXPCClient audioChunkFrom:to:]
-[CSXPCClient audioChunkFrom:to:channelIdx:]
-[CSXPCClient audioChunkToEndFrom:]
-[CSXPCClient audioChunkToEndFrom:channelIdx:]
-[CSXPCClient saveRecordingBufferFrom:to:toURL:]
-[CSXPCClient saveRecordingBufferToEndFrom:toURL:]
-[CSXPCClient holdAudioStreamWithDescription:timeout:]
-[CSXPCClient cancelAudioStreamHold:]
-[CSXPCClient isRecording]
-[CSXPCClient setAnnounceCallsEnabled:withStreamHandleID:]
-[CSXPCClient attachTandemStream:toPrimaryStream:completion:]
deviceID
sessionID
-[CSXPCClient audioSessionIdForDeviceId:]
sampleCount
-[CSXPCClient hostTimeFromSampleCount:]_block_invoke
replyHostTime
-[CSXPCClient hostTimeFromSampleCount:]
hostTime
-[CSXPCClient sampleCountFromHostTime:]_block_invoke
replySampleCount
-[CSXPCClient sampleCountFromHostTime:]
-[CSXPCClient _handleListenerEvent:]
-[CSXPCClient _handleListenerMessage:]
-[CSXPCClient _handleListenerError:]
-[CSXPCClient _handleAlertProvidingDelegateMessageBody:]
didFinishAlertPlayback
errorDomain
errorCode
-[CSXPCClient _handleSessionProvidingDelegateMessageBody:]
interruptionContext
-[CSXPCClient _handleSessionProvidingDelegateBeginInterruptionWithContext:]
willSetAudioSessionActive
didSetAudioSessionActive
streamHandleIdInvalidationflag
didChangeContextFlag
-[CSXPCClient _handleSessionInfoProvidingDelegateMessageBody:]
notificationInfo
-[CSXPCClient _handleSessionInfoProvidingDelegateInterruptionNotification:]
-[CSXPCClient _handleSessionInfoProvidingDelegateRouteChangeNotification:]
-[CSXPCClient _handleSessionInfoProvidingDelegateMediaServicesWereLostNotification:]
-[CSXPCClient _handleSessionInfoProvidingDelegateMediaServicesWereResetNotification:]
-[CSXPCClient _handleStreamProvidingDelegateMessageBody:]
CSOpportuneSpeakListnerTestService
com.apple.corespeech.opportunelistner.start
com.apple.corespeech.opportunelistner.stop
A945B95D-69F6-FC77-4FAE-91F50A039CD8
-[CSOpportuneSpeakListnerTestService receiveOpportuneSpeakListenerStart]_block_invoke
-[CSOpportuneSpeakListnerTestService receiveOpportuneSpeakListenerStop]_block_invoke
-[CSOpportuneSpeakListnerTestService opportuneSpeakListener:hasRemoteVADAvailable:]
-[CSOpportuneSpeakListnerTestService opportuneSpeakListener:hasVADAvailable:]
-[CSOpportuneSpeakListnerTestService opportuneSpeakListener:didStopUnexpectly:]
CSTimerMonitor queue
-[CSTimerMonitor _startMonitoringWithQueue:]
-[CSTimerMonitor _stopMonitoring]
BluetoothA2DPOutput
BluetoothHFP
BluetoothLE
MicrophoneBuiltIn
Speaker
Headphones
MicrophoneWired
HDMIOutput
LineIn
USBAudio
ADAudioSessionPortOther
-[CSSiriAudioSession currentInputRoute]_block_invoke
v24@?0^v8Q16
-[CSSiriAudioSession currentOutputRoute]_block_invoke_3
_AudioObjectGetScalarArray
v20@?0I8r^{AudioObjectPropertyAddress=III}12
_AudioDeviceRegisterForChangedNotification
v16@?0^v8
_AudioObjectGetCFTypeRef
v12@?0I8
_AudioObjectGetIntValue
CSOpportuneSpeakEventMonitor
-[CSOpportuneSpeakEventMonitor isStreaming]
-[CSAttSiriMitigationAssetHandler _receivedNewAssetUpdate:]
-[CSAttSiriMitigationAssetHandler trialAssetDownloadMonitorDelegate:didInstallNewAsset:assetType:]
kVTPreferencesPhraseSpotterEnabledDidChangeDarwinNotification
-[CSPhraseSpotterEnabledMonitor _checkPhraseSpotterEnabled]
-[CSPhraseSpotterEnabledMonitor _phraseSpotterEnabledDidChange]
CSVoiceTriggerAssetHandler
-[CSVoiceTriggerAssetHandler getVoiceTriggerAssetWithEndpointId:completion:]
CSVoiceTriggerAssetHandler.m
com.apple.siri.myriad.in.ear
+[CSMyriadNotifier notifyInEarMyriadTrigger]
com.apple.corespeech.benchmark.xpc
-[CSBenchmarkXPCListener listen]
-[CSBenchmarkXPCListener listener:shouldAcceptNewConnection:]
corespeech.benchmark.xpc
Liminal
progChecker.json
progressiveCheckerConfigFile
contionusConversationConfigFile
checkerConfig
validInputOrigins
thresholds
shadowMode
Unspecified
VoiceTrigger
ButtonPress
B32@?0@8@16^B24
v24@?0@8^B16
-[CSLanguageCodeUpdateMonitorImpl _startMonitoringWithQueue:]
-[CSLanguageCodeUpdateMonitorImpl _stopMonitoring]
-[CSLanguageCodeUpdateMonitorImpl _didReceiveLanguageCodeUpdate]
CSVoiceTriggerXPCListener
com.apple.corespeech.voicetriggerservice
-[CSVoiceTriggerXPCListener listen]
-[CSVoiceTriggerXPCListener _handleListenerEvent:]
-[CSVoiceTriggerXPCListener _handleListenerError:]
-[CSVoiceTriggerXPCListener _handleNewRemoteConnection:]
voicetrigger.voicetriggerservice
-[CSVoiceTriggerXPCListener CSXPCConnectionReceivedClientError:clientError:client:]_block_invoke
CSCoreSpeechServicesListener
-[CSCoreSpeechServicesListener listen]
-[CSCoreSpeechServicesListener _servicesListenerShouldAcceptNewConnection:]
corespeech.xpc
-[CSCoreSpeechServicesListener listener:shouldAcceptNewConnection:]
-[CSCoreSpeechServicesListener getTestResponse:]
Test
-[CSCoreSpeechServicesListener setDelayInterstitialSounds:level:completion:]
-[CSCoreSpeechServicesListener getTriggerCount:]
-[CSCoreSpeechServicesListener clearTriggerCount:]
-[CSCoreSpeechServicesListener getFirstPassRunningMode:]
-[CSAudioStreamHolding dealloc]
-[CSEndpointDelayReporter initWithRequestMHUUID:turnIdentifier:]
-[CSEndpointDelayReporter reset]
leadingSilence
trailingSilence
endTime
-[CSEndpointDelayReporter setSpeechRecognizedContext:withEndpointerMetrics:]
Adaptive Siri Volume Disabled
siriVolume.json
smartSiriVolume
noiseLevelChannelBitset
LKFSChannelBitset
DistanceChannelBitset
energyBufferSize
noiseLowerPercentile
noiseUpperPercentile
LKFSLowerPercentile
LKFSUpperPercentile
noiseTimeConstant
noiseMicSensitivityOffset
noiseMicSensitivityOffsetDeviceSimple
LKFSTimeConstant
LKFSMicSensitivityOffset
noiseTTSMappingInputRangeLow
noiseTTSMappingInputRangeHigh
noiseTTSMappingOutputRangeLow
noiseTTSMappingOutputRangeHigh
LKFSTTSMappingInputRangeLow
LKFSTTSMappingInputRangeHigh
LKFSTTSMappingOutputRangeLow
LKFSTTSMappingOutputRangeHigh
userOffsetInputRangeLow
userOffsetInputRangeHigh
userOffsetOutputRangeLow
userOffsetOutputRangeHigh
TTSVolumeLowerLimitDB
TTSVolumeUpperLimitDB
noiseWeight
SSVCAMaxFrameSize
SSVCAVoiceTriggerBasedTTSValidForSeconds
SSVCASmartSiriVolumeUnsyncedMetricLogsToRetain
SSVCASmartSiriVolumeSyncedMetricLogsToRetain
SSVCAVoiceTriggerInitialSilenceDurationSeconds
SSVCADistanceInputBufferDurationSeconds
SSVCAListenPollingIntervalAtStartInSeconds
SSVCADefaultZeroFloatingPointValue
SSVCAAnnouncementStatusFetchTimeoutMs
SSVCADefaultOutputTTSVolume
SSVCANoiseActivityCountThreshold
SSVCASpeakerDistanceFarBoostFactor
SSVCASpeakerDistanceMidBoostFactor
SSVCASpeakerDistanceNearBoostFactor
SSVCADistanceModelConfidenceThreshold
SSVCAMinimumLinearSoundLevel
SSVCAMaximumLinearSoundLevel
SSVCALinearToDecibelConstantMultiplier
SSVCADecibelToLinearLogBase
SSVCASignalToSigmoidNoiseDilationFactor
SSVCASignalToSigmoidMusicDilationFactorDeviceDefault
SSVCASignalToSigmoidMusicDilationFactorDeviceSimple
SSVCASignalToSigmoidSpeechDilationFactor
SSVCASignalToSigmoidNoiseVSpread
SSVCASignalToSigmoidMusicVSpreadDeviceDefault
SSVCASignalToSigmoidMusicVSpreadDeviceSimple
SSVCASignalToSigmoidSpeechVSpread
SSVCASignalToSigmoidNoiseVOffset
SSVCASignalToSigmoidMusicVOffsetDeviceDefault
SSVCASignalToSigmoidMusicVOffsetDeviceSimple
SSVCASignalToSigmoidSpeechVOffset
SSVCASignalToSigmoidNoiseHOffset
SSVCASignalToSigmoidMusicHOffsetDeviceDefault
SSVCASignalToSigmoidMusicHOffsetDeviceSimple
SSVCASignalToSigmoidSpeechHOffset
SSVCASignalToSigmoidMusicSteepnessDeviceDefault
SSVCASignalToSigmoidMusicSteepnessDeviceSimple
SSVCASignalToSigmoidNoiseSteepness
SSVCASignalToSigmoidSpeechSteepness
SSVCADBToTTSMinimumOutput
SSVCADBToTTSMaximumOutput
SSVCADBToTTSTransitionPoint
SSVCADBToTTSPreTransitionOffset
SSVCADBToTTSPreTransitionMultiplier
SSVCADBToTTSPostTransitionOffset
SSVCADBToTTSPostTransitionDC
SSVCADBToTTSPostTransitionMultiplier
SSVCAMinimumDistanceUpdateWaitPeriodSeconds
SSVCANoiseActivityThreshold
SSVCANoiseResultsBufferSize
SSVCAMusicResultsBufferSize
SSVCADefaultSpeechStrength
SSVCADefaultMusicStrength
SSVCANoiseActivityHistoricalSampleCount
SSVCADspCoefsCount
SSVCADspNumStages
SSVCADistanceResultsBufferSize
SSVCAExponentialDistanceHistoryDegradationFactor
SSVCADistanceResultSampleCountTolerance
SSVCAMusicHistoricalSamplesInSeconds
SSVCADeviceSimpleOutputMinTargetDB
SSVCADeviceSimpleOutputMaxTargetDB
SSVCADeviceSimpleOutputSlope
SSVCADeviceSimpleMinTargetDB
SSVCADeviceSimpleMaxTargetDB
SSVCADeviceSimpleDBToSystemVolSlope
SSVCADeviceSimpleMicSensitivityOffset
SSVCADeviceSimplePreTriggerSilenceSampleCount
SSVCAMinTTSSystemVolume
SSVCAMaxTTSSystemVolume
SSVCAUserIntentValidForSeconds
SSVCAUserIntentVolumeIncreaseFactor
SSVCAUserIntentVolumeDecreaseFactor
SSVCAUserIntentPermanentOffsetFactorDelta
SSVCAUserIntentPermanentOffsetFactorLowerBound
SSVCAUserIntentPermanentOffsetFactorUpperBound
SSVCADeviceSimpleMinTTSVolume
SSVCADeviceSimpleMaxTTSVolume
SSVCADeviceDefaultMinTTSVolume
SSVCADeviceDefaultMaxTTSVolume
SSVCADeviceDefaultASVOffMinTTSVolume
SSVCADeviceSimpleASVOffMinTTSVolume
SSVCADeviceDefaultMicSensitivityOffset
SSVCAVolumeHalfLifeSeconds
SSVCAHistoricalVolumeBufferSize
SSVCAMaximumCompensatedSpeechLevelNearField
-[CSAsset(SmartSiriVolume) _getNumberFromASVDictionaryForKey:category:default:]
com.apple.corespeech.audioinjection.xpc
-[CSAudioInjectionXPCListener listen]
-[CSAudioInjectionXPCListener listener:shouldAcceptNewConnection:]
corespeech.audioinjection.xpc
RTModelData
RTModelHash
RTModelLocale
RTModelDigest
RTModelSignature
RTModelCertificate
RT Model for 
 from asset 
CorealisRTModel
CorealisRTModelVersion
dataSize(%d), hash(%@), locale(%@), digest(%@), cert(%@), signature(%@)
CSAudioProvider
CSAudioProvider Stream Handle Queue
CSAudioProvider logging
-[CSAudioProvider initWithAudioStreamHandleId:audioStreamType:audioRecordContext:audioRecorder:]
-[CSAudioProvider dealloc]
-[CSAudioProvider setStreamState:]
-[CSAudioProvider setAudioRecorder:]_block_invoke
-[CSAudioProvider setCurrentContext:error:]
-[CSAudioProvider setCurrentContext:error:]_block_invoke
-[CSAudioProvider _audioStreamWithRequest:streamName:error:]
-[CSAudioProvider attachTandemStream:toPrimaryStream:completion:]_block_invoke_2
failed
successfully
-[CSAudioProvider attachTandemStream:toPrimaryStream:completion:]_block_invoke
-[CSAudioProvider _prepareAudioStreamSync:request:error:]
-[CSAudioProvider _tearDownCircularBufferIfNeeded]_block_invoke
-[CSAudioProvider startAudioStream:option:completion:]
-[CSAudioProvider startAudioStream:option:completion:]_block_invoke
-[CSAudioProvider prepareAudioStreamSync:request:error:]
-[CSAudioProvider prepareAudioStream:request:completion:]
-[CSAudioProvider _startAudioStream:option:completion:]
-[CSAudioProvider _startAudioStream:option:completion:]_block_invoke
-[CSAudioProvider _startAudioStream:option:completion:]_block_invoke_2
-[CSAudioProvider _handleDidStartAudioStreamWithResult:error:]
-[CSAudioProvider _handleDidStopAudioStreamWithReason:]
-[CSAudioProvider _stopAudioStream:option:completion:]
-[CSAudioProvider _stopAudioStream:option:completion:]_block_invoke
-[CSAudioProvider _stopAudioStream:option:completion:]_block_invoke_3
CSAudioProvider.m
-[CSAudioProvider _stopAudioStream:option:completion:]_block_invoke_4
-[CSAudioProvider _stopAudioStream:option:completion:]_block_invoke_2
-[CSAudioProvider _saveRecordingBufferFrom:to:toURL:]_block_invoke
-[CSAudioProvider holdAudioStreamWithDescription:timeout:]
-[CSAudioProvider holdAudioStreamWithDescription:timeout:]_block_invoke_2
-[CSAudioProvider holdAudioStreamWithDescription:timeout:]_block_invoke
-[CSAudioProvider cancelAudioStreamHold:]
-[CSAudioProvider cancelAudioStreamHold:]_block_invoke
-[CSAudioProvider prewarmAudioSessionWithError:]
-[CSAudioProvider activateAudioSessionWithReason:dynamicAttribute:bundleID:error:]
-[CSAudioProvider _activateAudioSessionWithReason:error:]
-[CSAudioProvider deactivateAudioSession:error:]
-[CSAudioProvider _deactivateAudioSession:error:]
-[CSAudioProvider setAlertSoundFromURL:forType:]
-[CSAudioProvider playAlertSoundForType:]
-[CSAudioProvider playRecordStartingAlertAndResetEndpointer]
-[CSAudioProvider alertStartTime]
-[CSAudioProvider triggerInfoForContext:completion:]_block_invoke
-[CSAudioProvider _shouldStopRecording]
-[CSAudioProvider audioRecorderStreamHandleIdInvalidated:]
-[CSAudioProvider audioRecorderWillBeDestroyed:]_block_invoke
-[CSAudioProvider _fetchHistoricalAudioAndForwardToStream:remoteVAD:]
-[CSAudioProvider _scheduleAlertFinishTimeout:]
-[CSAudioProvider _scheduleAlertFinishTimeout:]_block_invoke
-[CSAudioProvider _didReceiveFinishStartAlertPlaybackAt:]
-[CSAudioProvider _didReceiveFinishStartAlertPlaybackAt:]_block_invoke_2
-[CSAudioProvider _didReceiveFinishStartAlertPlaybackAt:]_block_invoke
-[CSAudioProvider audioRecorderBuiltInAudioStreamInvalidated:error:]_block_invoke
-[CSAudioProvider audioRecorderDisconnected:]
-[CSAudioProvider CSAudioServerCrashMonitorDidReceiveServerCrash:]
-[CSAudioProvider CSAudioServerCrashMonitorDidReceiveServerRestart:]
-[CSAudioProvider _handleAudioSystemFailure]
StreamInit
StreamPrepared
StreamStarting
StreamSteaming
StreamStopping
StreamStoppingWithScheduledStart
unknown(%tu)
com.apple.corespeech.recording
Recording transaction
-[CSAudioProvider _releaseRecordingTransactionIfNeeded]
%@-%@
-[CSAudioProvider _onAudioPacketWatchdogFire]
-[CSAudioProvider _scheduleDidStartRecordingDelegateWatchDog]
-[CSAudioProvider _schduleDidStartRecordingDelegateWatchDogWithToken:]
-[CSAudioProvider _clearDidStartRecordingDelegateWatchDog]
-[CSAudioProvider _scheduleDidStopRecordingDelegateWatchDog]
-[CSAudioProvider _scheduleDidStopRecordingDelegateWatchDog:]
-[CSAudioProvider _clearDidStopRecordingDelegateWatchDog]
com.apple.siri.SiriDebug.SpeakerVoiceGradingTrigger
com.apple.siri.SiriDebug.RemoteNearMissGradingTrigger
com.apple.siri.SiriDebug.VoiceProfileAddedTrigger
com.apple.siri.SiriDebug.VoiceProfileSyncTrigger
com.apple.siri.SiriDebug
+[CSSiriDebugConnection launchSiriDebugAppWithMessage:]_block_invoke
v24@?0@"AFSiriResponse"8@"NSError"16
set option : allowVoiceTriggerAssetsDownload ? %@;           allowEndpointAssetDownload ? %@;           allowLanguageDetectorAssetDownload ? %@;           allowAdBlockerAssetDownload ? %@;           allowSpeakerRecognitionAssetDownload ? %@
Dispose Log Queue
+[CSUtils(Directory) removeLogFilesInDirectory:matchingPattern:beforeDays:]_block_invoke
v24@?0@"NSArray"8^@16
+[CSUtils(Directory) clearLogFilesInDirectory:matchingPattern:exceedNumber:]_block_invoke_2
+[CSUtils(Directory) clearLogFilesInDirectory:matchingPattern:exceedNumber:]_block_invoke
Unable to get %@ for file at %@: %@
q24@?0@"NSURL"8@"NSURL"16
B24@?0@"NSURL"8@"NSDictionary"16
+[CSUtils(Directory) _contentsOfDirectoryAtURL:matchingPattern:includingPropertiesForKeys:error:]
-[CSVoiceTriggerEnabledPolicyNonAOP _addVoiceTriggerEnabledConditions]_block_invoke
-[CSNNVADEndpointAnalyzer init]
-[CSNNVADEndpointAnalyzer preheat]
-[CSNNVADEndpointAnalyzer reset]
-[CSNNVADEndpointAnalyzer processAudioSamplesAsynchronously:]
-[CSNNVADEndpointAnalyzer recordingStoppedForReason:]
-[CSNNVADEndpointAnalyzer stopEndpointer]
-[CSNNVADEndpointAnalyzer resetForNewRequestWithSampleRate:recordContext:]
-[CSSpeechDetectionDevicePresentMonitor handleSpeechDetectionVADPresentChange:]
-[CSSpeechDetectionDevicePresentMonitor _systemControllerDied:]
best_phrase
early_warning
is_rescoring
samples_at_fire
start_sample_count
-[CSKeywordAnalyzerNDAPI initWithConfigPath:resourcePath:]
-[CSKeywordAnalyzerNDAPI _setStartAnalyzeTime:]
threshold_normal
-[CSKeywordAnalyzerNDAPI getThreshold]
threshold_logging
-[CSKeywordAnalyzerNDAPI getLoggingThreshold]
threshold_reject_logging
-[CSKeywordAnalyzerNDAPI getRejectLoggingThreshold]
rtblobs
adkblobs
blob
majorVersion
minorVersion
signature
cert
rtlocalemap
jarvislocalemap
adklocalemap
-[CSAsset(RTModel) createRTModelWithLocale:]
-[CSAsset(RTModel) latestHearstRTModelForLocale:]
-[CSAsset(RTModel) rtModelWithAccessoryRTModelType:majorVersion:minorVersion:locale:]
-[CSAsset(RTModel) localeMapWithName:]
%02x
CSAudioRouteChangeMonitorImpl queue
-[CSAudioRouteChangeMonitorImpl preferredExternalRouteDidChange:]_block_invoke
-[CSAudioRouteChangeMonitorImpl carPlayAuxStreamSupportDidChange:]_block_invoke
-[CSAudioRouteChangeMonitorImpl carPlayIsConnectedDidChange:]
-[CSAudioRouteChangeMonitorImpl _startMonitoringWithQueue:]
-[CSAudioRouteChangeMonitorImpl _stopMonitoring]
-[CSAudioRouteChangeMonitorImpl _notifyHearstConnectionState:]
-[CSAudioRouteChangeMonitorImpl _notifyJarvisConnectionState:]
-[CSAudioRouteChangeMonitorImpl _systemControllerDied:]
languageCode
Builtin Microphone
[Context = %ld]
[DeviceId = %@]
[Announced = %d]
[streamHandleId = %d]
[startHostTime = %llu]
[startAlert = %d]
[stopAlert = %d]
[stopOnErrorAlert = %d]
[skipAlert = %@]
-[CSAudioRecorder initWithQueue:error:]
-[CSAudioRecorder willDestroy]
-[CSAudioRecorder dealloc]
-[CSAudioRecorder _destroyVoiceController]
-[CSAudioRecorder _voiceControllerWithError:]_block_invoke
-[CSAudioRecorder _voiceControllerWithError:]
-[CSAudioRecorder setAnnounceCallsEnabled:withStreamHandleID:]
-[CSAudioRecorder setContext:completion:]
-[CSAudioRecorder setCurrentContext:streamHandleId:error:]
-[CSAudioRecorder prepareAudioStreamRecord:recordDeviceIndicator:error:]
-[CSAudioRecorder _startAudioStreamForAudioInjectionWithAVVCContext:]
-[CSAudioRecorder startAudioStreamWithOption:recordDeviceIndicator:error:]
-[CSAudioRecorder stopAudioStreamWithRecordDeviceIndicator:error:]
-[CSAudioRecorder isSessionCurrentlyActivated]
-[CSAudioRecorder recordDeviceInfoWithStreamHandleId:recordDeviceIndicator:]
%llu
-[CSAudioRecorder audioDeviceInfoWithStreamHandleId:recordDeviceIndicator:]
-[CSAudioRecorder recordingSampleRateWithStreamHandleId:]
-[CSAudioRecorder isNarrowBandWithStreamHandleId:]
-[CSAudioRecorder prewarmAudioSessionWithStreamHandleId:error:]
-[CSAudioRecorder setRecordMode:streamHandleId:error:]
-[CSAudioRecorder activateAudioSessionWithReason:streamHandleId:error:]
-[CSAudioRecorder deactivateAudioSession:error:]
-[CSAudioRecorder deactivateAudioSession:streamHandleId:error:]
+[CSAudioRecorder createSharedAudioSession]
-[CSAudioRecorder enableSmartRoutingConsiderationForStream:enable:]
-[CSAudioRecorder setDuckOthersForStream:]
-[CSAudioRecorder setMixWithOthersForStream:]
-[CSAudioRecorder setDuckOthersOption:]
-[CSAudioRecorder enableMiniDucking:]
-[CSAudioRecorder configureAlertBehavior:audioStreamHandleId:]
-[CSAudioRecorder voiceTriggerInfoWithRecordDeviceIndicator:]
-[CSAudioRecorder _updateLanguageCodeForRemoteVTEIResult:]
useRemoteBuiltInMic
-[CSAudioRecorder _processAudioBuffer:audioStreamHandleId:arrivalTimestampToAudioRecorder:]
-[CSAudioRecorder _compensateChannelDataIfNeeded:receivedNumChannels:]
-[CSAudioRecorder playRecordStartingAlertAndResetEndpointerFromStream:]
-[CSAudioRecorder playAlertSoundForType:recordDevideIndicator:]
-[CSAudioRecorder voiceControllerDidStartRecording:forStream:successfully:error:]
-[CSAudioRecorder voiceControllerAudioCallback:forStream:buffer:]
-[CSAudioRecorder voiceControllerDidStopRecording:forStream:forReason:]
-[CSAudioRecorder voiceControllerStreamInvalidated:forStream:]
-[CSAudioRecorder voiceControllerRecordHardwareConfigurationDidChange:toConfiguration:]
-[CSAudioRecorder voiceControllerDidFinishAlertPlayback:ofType:error:]
-[CSAudioRecorder voiceControllerEncoderErrorDidOccur:error:]
-[CSAudioRecorder voiceControllerBeginRecordInterruption:]
-[CSAudioRecorder voiceControllerBeginRecordInterruption:withContext:]
-[CSAudioRecorder voiceControllerEndRecordInterruption:]
-[CSAudioRecorder voiceControllerWillSetAudioSessionActive:willActivate:]
-[CSAudioRecorder voiceControllerDidSetAudioSessionActive:isActivated:]
-[CSAudioRecorder voiceControllerMediaServicesWereLost:]
-[CSAudioRecorder voiceControllerMediaServicesWereReset:]
-[CSAudioRecorder _hasLocalPendingTwoShot]_block_invoke
-[CSAudioRecorder _getRecordSettingsWithRequest:]
-[CSAudioRecorder _fetchRemoteRecordClientWithDeviceId:streamHandleId:]
-[CSAudioTandemStream attachToPrimaryStreamWithCompletion:]
-[CSAudioTandemStream prepareAudioStreamSyncWithRequest:error:]
CSAudioTandemStream.m
-[CSAudioTandemStream prepareAudioStreamWithRequest:completion:]
-[CSAudioTandemStream startAudioStreamWithOption:completion:]
-[CSAudioTandemStream stopAudioStreamWithOption:completion:]
RemoteVAD Align Queue
-[CSOpportuneSpeakListener startListenWithOption:completion:]
-[CSOpportuneSpeakListener _startRequestWithCompletion:]_block_invoke
-[CSOpportuneSpeakListener _startRequestWithCompletion:]
-[CSOpportuneSpeakListener stopListenWithStateReset:completion:]_block_invoke
-[CSOpportuneSpeakListener stopListenWithStateReset:completion:]
-[CSOpportuneSpeakListener audioStreamProvider:audioBufferAvailable:]
-[CSOpportuneSpeakListener spgEndpointAnalyzer:hasSilenceScoreEstimate:clientProcessedAudioTimeMS:]
-[NSData(XPCObject) _cs_initWithXPCObject:]
-[CSSiriEnabledMonitor _startMonitoringWithQueue:]
-[CSSiriEnabledMonitor _stopMonitoring]
_AssistantPrefsChangedNotification
CSBluetoothManager Queue
-[CSBluetoothManager getBTLocalDeviceWithCompletion:]
-[CSBluetoothManager getBTLocalDeviceWithCompletion:]_block_invoke
v16@?0^{BTLocalDeviceImpl=}8
-[CSBluetoothManager _getWirelessSplitterInfoFromLocalDevice:]
-[CSBluetoothManager _detachBluetoothSession]
-[CSBluetoothManager _attachBluetoothSession]
CSBluetoothManager
-[CSBluetoothManager _sessionAttached:result:]
-[CSBluetoothManager _sessionDetached:]
-[CSBluetoothManager _sessionTerminated:]
-[CSBluetoothManager _setUpLocalDevice]
unknown
CSActivationXPCListener
-[CSActivationXPCListener listen]
-[CSActivationXPCListener _handleListenerEvent:]
-[CSActivationXPCListener _handleListenerError:]
-[CSActivationXPCListener _handleNewRemoteConnection:]
corespeechd.activation
-[CSActivationXPCListener CSActivationXPCConnectionReceivedClientError:clientError:client:]_block_invoke
CSBenchMarker Queue
-[CSModelBenchmarker init]
-[CSModelBenchmarker pingpong:completion:]
Model benchmark Queue
HS1_HS2
file audio
-[CSModelBenchmarker audioEngineDidStartRecord:audioStreamHandleId:successfully:error:]_block_invoke
-[CSModelBenchmarker audioEngineDidStopRecord:audioStreamHandleId:reason:]_block_invoke
done
v16@?0Q8
-[CSModelBenchmarker _setupAudioInjectionEngineWithAudioURL:]_block_invoke
-[CSModelBenchmarker _setupAudioInjectionEngineWithAudioURL:]_block_invoke_2
+[CSRemoteDeviceProtocolInfo localDeviceProtocolInfo]
protocolVersion=%lu, deviceCategory=%lu, buildVersion=%@, deviceProductVersion=%@, deviceProductType=%@
protocolVersion
deviceCategory
buildVersion
deviceProductVersion
deviceProductType
-[CSAudioSessionInfoProvidingProxy handleXPCMessage:messageBody:client:]
-[CSAudioSessionInfoProvidingProxy _handleSessionIDRequestMessage:messageBody:client:]
+[CSConnectionListener(SmartSiriVolume) createSmartSiriVolumeListener]
com.apple.corespeech.corespeechd.ssv.service
+[CSConnectionListener(SmartSiriVolume) createSmartSiriVolumeListener]_block_invoke
com.apple.MobileAsset.VoiceTriggerAssetsMac
-[CSAssetController init]
Serial CSAssetController queue
V1 Assets Clean-up queue
-[CSAssetController _cleanUpMobileAssetV1Directory]
-[CSAssetController assetOfType:language:]
-[CSAssetController allInstalledAssetsOfType:language:]
q24@?0@"MAAsset"8@"MAAsset"16
v32@?0@"MAAsset"8Q16^B24
-[CSAssetController assetOfType:language:completion:]
-[CSAssetController assetOfType:language:compatibilityVersion:completion:]
v24@?0@"MAAsset"8@"NSError"16
-[CSAssetController installedAssetOfType:language:]
-[CSAssetController installedAssetOfType:language:completion:]
-[CSAssetController _installedAssetOfType:withLanguage:]
-[CSAssetController _installedAssetOfType:query:withLanguage:completion:]_block_invoke
-[CSAssetController _findLatestInstalledAsset:]
-[CSAssetController _assetQueryForAssetType:]
-[CSAssetController _runAssetQuery:completion:]
-[CSAssetController _runAssetQuery:completion:]_block_invoke
-[CSAssetController fetchRemoteMetaOfType:allowRetry:]
-[CSAssetController fetchRemoteMetaOfType:allowRetry:]_block_invoke
v20@?0@"NSError"8B16
-[CSAssetController _fetchRemoteAssetOfType:withLanguage:completion:]
-[CSAssetController _fetchRemoteAssetOfType:withLanguage:query:completion:]_block_invoke_2
-[CSAssetController _fetchRemoteAssetOfType:withLanguage:query:completion:]_block_invoke
-[CSAssetController _downloadAssetCatalogForAssetType:complete:]_block_invoke
-[CSAssetController _updateFromRemoteToLocalAssets:forAssetType:completion:]
-[CSAssetController _downloadAsset:withComplete:]
v16@?0d8
-[CSAssetController _downloadAsset:withComplete:]_block_invoke
-[CSAssetController _startDownloadingAsset:progress:completion:]
v16@?0@"MAProgressNotification"8
+[CSAssetController(Utils) addKeyValuePairForQuery:assetType:]
com.apple.MobileAsset.VoiceTriggerAssets
com.apple.MobileAsset.VoiceTriggerAssetsIPad
com.apple.MobileAsset.VoiceTriggerAssetsWatch
com.apple.MobileAsset.VoiceTriggerAssetsMarsh
com.apple.MobileAsset.VoiceTriggerAssetsTV
com.apple.MobileAsset.SpeechEndpointAssets
com.apple.MobileAsset.SpeechEndpointAssetsWatch
com.apple.MobileAsset.SpeechEndpointAssetsTV
com.apple.MobileAsset.LanguageDetectorAssets
com.apple.MobileAsset.AdBlockerAssets
com.apple.MobileAsset.SpeakerRecognitionAssets
Warmup
SearchOrMessaging
ExtraDelayMs
EndpointerDecisionLagMs
ClientLagThresholdMsKey
ClampedSFLatencyMsForClientLag
UseDefaultServerFeaturesOnClientLag
com.apple.cs.%@.stateserialqueue
com.apple.cs.%@.sepfQueue
-[CSHybridEndpointAnalyzer init]
com.apple.cs.%@.apQueue
com.apple.cs.%@.hybridClassifierfQueue
com.apple.cs.%@.osdQueue
-[CSHybridEndpointAnalyzer _loadAndSetupEndpointerAssetIfNecessary]
-[CSHybridEndpointAnalyzer processAudioSamplesAsynchronously:]
-[CSHybridEndpointAnalyzer processAudioSamplesAsynchronously:]_block_invoke
-[CSHybridEndpointAnalyzer updateEndpointerThreshold:]
-[CSHybridEndpointAnalyzer updateEndpointerDelayedTrigger:]
-[CSHybridEndpointAnalyzer processServerEndpointFeatures:]
-[CSHybridEndpointAnalyzer shouldAcceptEagerResultForDuration:resultsCompletionHandler:]_block_invoke_2
-[CSHybridEndpointAnalyzer shouldAcceptEagerResultForDuration:resultsCompletionHandler:]_block_invoke
-[CSHybridEndpointAnalyzer osdAnalyzer:didUpdateOSDFeatures:]
-[CSHybridEndpointAnalyzer osdAnalyzer:didUpdateOSDFeatures:]_block_invoke_2
-[CSHybridEndpointAnalyzer osdAnalyzer:didUpdateOSDFeatures:]_block_invoke
locale
endpointerModelVersion
wordCount
trailingSilenceDuration
serverFeaturesLatency
clientSilenceProbability
clientSilenceFramesCountMs
endpointResult
@"NSDictionary"8@?0
-[CSHybridEndpointAnalyzer logFeaturesWithEvent:locale:]_block_invoke
extraSamplesAtStart
-[CSHybridEndpointAnalyzer handleVoiceTriggerWithActivationInfo:]_block_invoke
-[CSHybridEndpointAnalyzer recordingStoppedForReason:]
-[CSHybridEndpointAnalyzer stopEndpointer]
-[CSHybridEndpointAnalyzer resetForNewRequestWithSampleRate:recordContext:]
-[CSHybridEndpointAnalyzer resetForNewRequestWithSampleRate:recordContext:]_block_invoke
-[CSHybridEndpointAnalyzer _readParametersFromHEPAsset:]_block_invoke
-[CSHybridEndpointAnalyzer CSLanguageCodeUpdateMonitor:didReceiveLanguageCodeChanged:]
-[CSHybridEndpointAnalyzer CSAssetManagerDidDownloadNewAsset:]
-[CSHybridEndpointAnalyzer CSFirstUnlockMonitor:didReceiveFirstUnlock:]
-[CSHybridEndpointAnalyzer _updateAssetWithLanguage:]_block_invoke
cs_hep_marsh.json
cs_hep.json
-[CSHybridEndpointAnalyzer _getCSHybridEndpointerConfigForAsset:]
voic
carplay
hearst
raisetospeak
auto
CSAudioInjectionXPC Queue
-[CSAudioInjectionXPC createAudioInjectionDeviceWithType:deviceName:deviceID:productID:completion:]
-[CSAudioInjectionXPC injectAudio:toDeviceWithUUID:withScaleFactor:completion:]
-[CSAudioInjectionXPC injectAudio:toDeviceWithUUID:withScaleFactor:completion:]_block_invoke
-[CSAudioInjectionXPC connectDeviceWithUUID:completion:]
-[CSAudioInjectionXPC disconnectDeviceWithUUID:completion:]
-[CSAudioInjectionXPC disconnectDeviceWithUUID:completion:]_block_invoke
-[CSAudioInjectionXPC primaryInputDeviceUUIDWithCompletion:]
-[NSNumber(XPCObject) _cs_initWithXPCObject:]
-[NSNumber(XPCObject) _cs_xpcObject]
CSActivationEventNotificationHandler Queue
-[CSActivationEventNotificationHandler setDelegate:forType:]_block_invoke
-[CSActivationEventNotificationHandler notifyActivationEvent:completion:]_block_invoke
-[CSActivationEventNotificationHandler _notifyActivationEvent:completion:]
-[CSActivationEventNotificationHandler _notifyActivationEvent:completion:]_block_invoke
-[CSActivationEventNotificationHandler _startMonitoring]
-[CSActivationEventNotificationHandler _stopMonitoring]
triggerStartSampleCount
isMediaPlaying
noiseLevelDB
musicLevelDB
musicPlaybackVolumeDB
alarmVolume
finalTTSVolume
isAlarmPlaying
isTimerPlaying
isLKFSProcessPaused
removeVoiceTriggerSamples
-[CSSmartSiriVolume initWithSamplingRate:asset:]
-[CSSmartSiriVolume startSmartSiriVolume]_block_invoke
RUNNING
PAUSED
v20@?0B8Q12
-[CSSmartSiriVolume _startListenPolling]
-[CSSmartSiriVolume _startListenPollingWithInterval:completion:]
-[CSSmartSiriVolume _startListenPollingWithInterval:completion:]_block_invoke
-[CSSmartSiriVolume _startListenWithCompletion:]_block_invoke_2
-[CSSmartSiriVolume _startListenWithCompletion:]_block_invoke
-[CSSmartSiriVolume _startListenWithCompletion:]
-[CSSmartSiriVolume _stopListening]
-[CSSmartSiriVolume _stopListening]_block_invoke
-[CSSmartSiriVolume initializeMediaPlayingState]_block_invoke
playing
NOT playing
-[CSSmartSiriVolume initializeMediaPlayingState]
-[CSSmartSiriVolume initializeAlarmState]_block_invoke
firing
NOT firing
-[CSSmartSiriVolume initializeTimerState]_block_invoke
-[CSSmartSiriVolume _setAsset:]
-[CSSmartSiriVolume _processAudioChunk:soundType:]
-[CSSmartSiriVolume estimateSoundLevelbySoundType:]_block_invoke
-[CSSmartSiriVolume _pauseSSVProcessing]_block_invoke
-[CSSmartSiriVolume _resumeSSVProcessing]_block_invoke
-[CSSmartSiriVolume audioStreamProvider:audioBufferAvailable:]_block_invoke
-[CSSmartSiriVolume audioStreamProvider:didStopStreamUnexpectly:]
-[CSSmartSiriVolume didDetectKeywordWithResult:]
-[CSSmartSiriVolume didDetectKeywordWithResult:]_block_invoke
-[CSSmartSiriVolume estimatedTTSVolumeForNoiseLevelAndLKFS:LKFS:]_block_invoke
-[CSSmartSiriVolume _combineResultsWithOptimalFromNoise:andOptimalFromLkfs:withUserOffset:]
-[CSSmartSiriVolume CSMediaPlayingMonitor:didReceiveMediaPlayingChanged:]_block_invoke
-[CSSmartSiriVolume didReceiveAlarmChanged:]_block_invoke
-[CSSmartSiriVolume didReceiveTimerChanged:]_block_invoke
-[CSSmartSiriVolume CSSiriEnabledMonitor:didReceiveEnabled:]
-[CSSmartSiriVolume CSAudioServerCrashMonitorDidReceiveServerRestart:]
-[CSSmartSiriVolume siriClientBehaviorMonitor:didStartStreamWithContext:successfully:option:withEventUUID:]_block_invoke
-[CSSmartSiriVolume _setStartAnalyzeTime:]
-[CSSmartSiriVolume getVolumeForTTSType:withOverrideMediaVolume:WithRequestTime:]
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
CSAudioInjectionProvider
ATVRemoteInput
BuiltInMic
-[CSAudioInjectionProvider dealloc]
-[CSAudioInjectionProvider stop]
-[CSAudioInjectionProvider startAudioStreamWithOption:recordDeviceIndicator:error:]
-[CSAudioInjectionProvider stopAudioStreamWithRecordDeviceIndicator:error:]
BuiltInSpeaker
+[CSUtils(Compression) extractArchiveFromDirectory:toDir:]
-[CSListeningEnabledPolicyWatch _addListeningEnabledConditions]_block_invoke
-[CSOtherAppRecordingStateMonitor handleOtherAppRecordingStateChange:]
-[CSOtherAppRecordingStateMonitor _systemControllerDied:]
+[CSUtils(LanguageCode) getSiriLanguageWithFallback:]
+[CSUtils(LanguageCode) getSiriLanguageWithEndpointId:fallbackLanguage:]
-[CSAutomaticVolumeEnabledMonitor observeValueForKeyPath:ofObject:change:context:]_block_invoke
CSAudioFileReader Queue
-[CSAudioFileReader initWithURL:]
-[CSAudioFileReader prepareRecording:]
-[CSAudioFileReader startRecording]
-[CSAudioFileReader _readAudioBufferAndFeed]
-[CSAudioFileReader stopRecording]
-[CSEndpointerProxy resetForNewRequestWithSampleRate:recordContext:recordOption:voiceTriggerInfo:]
-[CSEndpointerProxy resetForVoiceTriggerTwoShotWithSampleRate:]
-[CSEndpointerProxy preheat]
-[CSEndpointerProxy endpointer:didDetectStartpointAtTime:]
-[CSEndpointerProxy endpointer:didDetectHardEndpointAtTime:withMetrics:]
-[CSEndpointerProxy endpointer:detectedTwoShotAtTime:]
-[CSEndpointerProxy endpointerModelVersion]
-[CSEndpointerProxy logHybridEndpointFeaturesWithEvent:locale:]
com.apple.cs.%@.queue
-[CSAttSiriOSDNode addReceiver:]_block_invoke
-[CSAttSiriOSDNode stop]_block_invoke
-[CSAttSiriOSDNode setPrefetchedAsset:]_block_invoke
-[CSAttSiriOSDNode attSiriAudioSrcNodeLPCMRecordBufferAvailable:audioChunk:]_block_invoke
-[CSAttSiriOSDNode checkConsecutiveBoronSignalWithAudioChunk:]
-[CSAttSiriOSDNode attSiriAudioSrcNodeDidStop:]_block_invoke
-[CSAttSiriOSDNode resetForNewRequestWithRecordContext:voiceTriggerInfo:]_block_invoke
-[CSShadowMicScoreCreator calculateShadowMicScore]
-[CSMyriadSelfTriggerCoordinator selfTriggerDetector:didDetectSelfTrigger:]
com.apple.siri.corespeech.selftrigger
SPG.nnet
version
CSEndpointerAssetManager queue
-[CSEndpointerAssetManager init]
-[CSEndpointerAssetManager checkFirstUnlocked]
-[CSEndpointerAssetManager CSLanguageCodeUpdateMonitor:didReceiveLanguageCodeChanged:]_block_invoke
-[CSEndpointerAssetManager CSAssetManagerDidDownloadNewAsset:]_block_invoke
-[CSEndpointerAssetManager CSFirstUnlockMonitor:didReceiveFirstUnlock:]_block_invoke
-[CSEndpointerAssetManager _getCurrentHEPAsset]
-[CSEndpointerAssetManager _updateOEPAssetsWithLanguage:]
-[CSEndpointerAssetManager _notifyAssetsUpdate]
ModelInfo=
-[CSEndpointerAssetManager _getOEPVersionFromPath:]
CSAudioInjectionBuiltInEngine
-[CSAudioInjectionBuiltInEngine dealloc]
SampleCount
HostTime
-[CSAudioInjectionBuiltInEngine getBestSampleCountWithOption:]
trigger-time
-[CSSpringboardStartMonitor _startMonitoringWithQueue:]
-[CSSpringboardStartMonitor _stopMonitoring]
-[CSSpringboardStartMonitor _checkSpringBoardStarted]
com.apple.springboard.finishedstartup
speakerRecognition
combinationWeight
implicitProfileThreshold
implicitProfileDeltaThreshold
implicitVTThreshold
pruningExplicitSATThreshold
pruningExplicitPSRThreshold
pruningSATThreshold
pruningPSRThreshold
numPruningRetentionUtt
maxEnrollmentUtterances
pruningCookie
configFileRecognizer
configFileNDAPI
voiceTriggerSecondPassAOP
implicit_training_enabled
multiUserHighScoreThreshold
multiUserLowScoreThreshold
multiUserConfidentScoreThreshold
multiUserDeltaScoreThreshold
recognizer.json
config.txt
-[CSAsset(SpeakerRecognition) containsMultiUserThresholds]
CSActivationEventNotifier
-[CSActivationEventNotifier notifyActivationEventSynchronously:completion:]
-[CSActivationEventNotifier notifyActivationEvent:completion:]_block_invoke
-[CSActivationEventNotifier notifyActivationEvent:deviceId:activationInfo:completion:]_block_invoke
-[CSActivationEventNotifier _createXPCClientConnection]
CSAlarmMonitor queue
-[CSAlarmMonitor _startMonitoringWithQueue:]
-[CSAlarmMonitor _stopMonitoring]
-[CSSmartSiriVolumeServiceProxy init]
overrideMediaVolume
SSV Manager returned estimate as nil
-[CSSmartSiriVolumeServiceProxy getVolumeForTTSType:withContext:reply:]
SmartSiriVolume not supported on this device type. smartSiriVolume : %p
-[CSSmartSiriVolumeServiceProxy setSmartSiriVolumePercentage:]
-[CSSmartSiriVolumeServiceProxy setSmartSiriVolumeDirection:]
-[CSSmartSiriVolumeServiceProxy setPermanentVolumeOffsetWithDirection:]
CSAttSiriAudioSrcNode queue
-[CSAttSiriAudioSrcNode initWithMasterAudioStream:name:]
-[CSAttSiriAudioSrcNode addReceiver:]_block_invoke
-[CSAttSiriAudioSrcNode dealloc]
-[CSAttSiriAudioSrcNode audioStreamProvider:didStopStreamUnexpectly:]_block_invoke
-[CSAttSiriAudioSrcNode _handleDidStop]
-[CSAttSiriAudioSrcNode _fetchAudioDecoderForTV:]
-[CSFirstUnlockMonitor _stopMonitoring]
-[NSString(XPCObject) _cs_initWithXPCObject:]
-[NSArray(XPCObject) _cs_initWithXPCObject:]
-[NSArray(XPCObject) _cs_initWithXPCObject:]_block_invoke
B24@?0Q8@"NSObject<OS_xpc_object>"16
-[NSArray(XPCObject) _cs_xpcObject]_block_invoke
v32@?0@8Q16^B24
BuiltInMicrophoneDevice
CSVoiceTriggerEventInfoProvider Queue
-[CSVoiceTriggerEventInfoProvider fetchVoiceTriggerInfoWithAudioContext:triggerInfoProviding:resultVoiceTriggerInfo:resultRTSTriggerInfo:]
route
isRemoteDevice
remoteDeviceUID
remoteDeviceProductIdentifier
remoteDeviceUIDString
%@ {route = %@, isRemoteDevice = %d, remoteDeviceUID = %@, remoteDeviceProductIdentifier = %@, remoteDeviceUIDString = %@}
CSCommandControlBehaviorMonitor
-[CSCommandControlBehaviorMonitor notifyWillStartStreamWithContext:option:]_block_invoke
-[CSCommandControlBehaviorMonitor notifyDidStartStreamWithContext:successfully:option:]_block_invoke
-[CSCommandControlBehaviorMonitor notifyWillStopStream:]_block_invoke
-[CSCommandControlBehaviorMonitor notifyDidStopStream:]_block_invoke
ApplicationProcessorWithCall
v16@?0@"AFSiriActivationResult"8
-[CSSiriLauncher notifyBuiltInVoiceTrigger:myriadPHash:completion:]_block_invoke
Trigger was during phone call
v16@?0@"<AFMyriadContextMutating>"8
-[CSSiriLauncher notifyWakeKeywordSpokenInBuiltInMic:]_block_invoke
-[CSSiriLauncher notifyCarPlayVoiceTriggerPrewarm:deviceId:completion:]_block_invoke
-[CSSiriLauncher notifyCarPlayVoiceTrigger:deviceId:myriadPHash:completion:]_block_invoke
-[CSSiriLauncher notifyWakeKeywordSpokenCarPlay:deviceId:]_block_invoke
-[CSSiriLauncher notifyBluetoothDeviceVoiceTrigger:deviceId:completion:]_block_invoke
-[CSSiriLauncher notifyWakeKeywordSpokenBluetoothDevice:deviceId:]_block_invoke
-[CSSiriLauncher deactivateSiriActivationConnectionWithReason:withOptions:withContext:]_block_invoke
clientStartSampleCount
triggerEndSampleCount
-[CSAudioProcessWaitingBuffer initWithSiriSessionUUID:]
-[CSAudioProcessWaitingBuffer dealloc]
localSpeechRecognizerQueue Queue
-[CSAttSiriAsrNode stopWithReason:]
-[CSAttSiriAsrNode stopWithReason:]_block_invoke
-[CSAttSiriAsrNode _adjustEndpointStartTimeWithVoiceTriggerEvent:]
-[CSAttSiriAsrNode preheatLocalSpeechRecognitionWithLanguage:source:]_block_invoke
SRD ASR Result Delivery Transaction
-[CSAttSiriAsrNode startDeliverLocalSpeechRecognitionResultsWithSettings:]_block_invoke
-[CSAttSiriAsrNode _startDeliverLocalSpeechRecognitionResultsWithRequestId:]
-[CSAttSiriAsrNode stopDeliverLocalSpeechRecognitionWithReason:]
-[CSAttSiriAsrNode disableLocalSpeechRecognitionForRequestId:]
-[CSAttSiriAsrNode attSiriAudioSrcNodeLPCMRecordBufferAvailable:audioChunk:]_block_invoke
-[CSAttSiriAsrNode attSiriAudioSrcNodeDidStop:]_block_invoke
-[CSAttSiriAsrNode attSiriNode:didDetectHardEndpointAtTime:withMetrics:]_block_invoke
-[CSAttSiriAsrNode _enforceEndpointHintWithRequestId:rcId:shouldAccept:featuresToLog:]
-[CSAttSiriAsrNode _enforceEndpointHintWithRequestId:rcId:shouldAccept:featuresToLog:]_block_invoke
-[CSAttSiriAsrNode start]
ASRNode Recording Transaction
-[CSAttSiriAsrNode start]_block_invoke
-[CSAttSiriAsrNode _preheatWithLanguage:preheatSource:]
-[CSAttSiriAsrNode prepareToStartSpeechRequestWithStartStreamOption:audioRecordContext:voiceTriggerInfo:]_block_invoke
-[CSAttSiriAsrNode _stopPreviousRecognitionTaskIfNeededWithNewRequestId:]
-[CSAttSiriAsrNode _shouldDisableLocalSpeechRecognizerWithOption:audioRecordContext:]
-[CSAttSiriAsrNode _startLocalSpeechRecognizerIfNeeded]
-[CSAttSiriAsrNode _startLocalSpeechRecognizerIfNeeded]_block_invoke
v24@?0@"CESRModelProperties"8@"NSError"16
-[CSAttSiriAsrNode _processAudioChunk:]
-[CSAttSiriAsrNode _handleStopSpeechRecognitionTaskIfNeeded:]
-[CSAttSiriAsrNode _scheduleRecordingTransactionReleaseTimer]
-[CSAttSiriAsrNode _releaseRecordingTransactionIfNeededWithToken:]
-[CSAttSiriAsrNode _interactiveLocalSpeechRecognizer]
-[CSAttSiriAsrNode localSpeechRecognizer:didRecognizeTokens:]_block_invoke
-[CSAttSiriAsrNode localSpeechRecognizer:didProcessAudioDuration:]_block_invoke
-[CSAttSiriAsrNode _queryShouldAcceptEagerResultForDuration:requestId:rcId:]
v20@?0B8@"NSArray"12
-[CSAttSiriAsrNode _handleShouldAcceptEagerResultWithRequestId:rcId:duration:shouldAccept:featuresToLog:]_block_invoke
-[CSAttSiriAsrNode localSpeechRecognizer:didRecognizePackage:]_block_invoke
-[CSAttSiriAsrNode _handleDidRecognizedFinalSpeechPackage:requestId:]
-[CSAttSiriAsrNode _handleDidRecognizedSpeechPackageForEagerRecognitionCandidate:requestId:rcId:processedAudioDuration:]
-[CSAttSiriAsrNode localSpeechRecognizer:didCompletionRecognitionWithStatistics:error:]_block_invoke
SiriX
enableTelemetry=YES
-[CSAttSiriAsrNode localSpeechRecognizer:didProduceEndpointFeaturesWithWordCount:trailingSilenceDuration:eosLikelihood:pauseCounts:silencePosterior:processedAudioDurationInMilliseconds:]_block_invoke
-[CSAttSiriAsrNode localSpeechRecognizer:didSelectRecognitionModelWithModelProperties:]
-[CSAttSiriAsrNode _fetchInputOriginWithRecordContext:]
HomeButton
-[CSAttSiriAsrNode _setLocalSpeechRecognizerState:]
[Idle]
[Disabled]
[Delivering message]
[Waiting for start deliver message]
[Waiting for start deliver message after client stop]
[Unknown]
-[CSAttSiriAsrNode _fetchRecognizerLanguageWithSiriLanguage:UILanguage:taskString:]
com.apple.corespeech.attsiri-timer
-[CSAttSiriTimer setTimerForSecs:completionBlock:]_block_invoke
-[CSAttSiriTimer cancelTimer]_block_invoke
-[CSAudioStream initWithAudioStreamProvider:streamName:streamRequest:]
-[CSAudioStream dealloc]
-[CSAudioStream startAudioStreamWithOption:completion:]
-[CSAudioStream stopAudioStreamWithOption:completion:]_block_invoke
-[CSAudioStream isStreaming]
-[CSAudioStream updateAudioStreamStartTimeInSampleCount:]
-[CSAudioStream audioStreamProvider:didStopStreamUnexpectly:]
-[CSAudioStream audioStreamProvider:didHardwareConfigurationChange:]
-[CSVoiceTriggerAssetMetaUpdateMonitor _startMonitoringWithQueue:]
-[CSVoiceTriggerAssetMetaUpdateMonitor _stopMonitoring]
-[CSVoiceTriggerAssetMetaUpdateMonitor _didReceiveNewVoiceTriggerAssetMetaData]
com.apple.MobileAsset.VoiceTriggerAssets.ma.cached-metadata-updated
com.apple.MobileAsset.VoiceTriggerAssetsIPad.ma.cached-metadata-updated
com.apple.MobileAsset.VoiceTriggerAssetsWatch.ma.cached-metadata-updated
com.apple.MobileAsset.VoiceTriggerAssetsMarsh.ma.cached-metadata-updated
com.apple.MobileAsset.VoiceTriggerAssetsMac.ma.cached-metadata-updated
com.apple.MobileAsset.VoiceTriggerAssetsTV.ma.cached-metadata-updated
-[CSAudioPreprocessor resetWithSampleRate:containsVoiceTrigger:voiceTriggerInfo:]
-[CSAudioPreprocessor flush]
ZeroFilterMetrics
-[CSAudioPreprocessor _fetchCurrentMetrics]
BeepCancellerMetrics
com.apple.corespeech.CSAccessorySiriClientBehaviourMonitor
-[CSAccessorySiriClientBehaviorMonitor notifyWillStartStreamWithContext:option:forAccessory:]_block_invoke
-[CSAccessorySiriClientBehaviorMonitor notifyDidStartStreamWithContext:successfully:option:withEventUUID:forAccessory:]_block_invoke
-[CSAccessorySiriClientBehaviorMonitor notifyWillStopStream:reason:forAccessory:]_block_invoke
-[CSAccessorySiriClientBehaviorMonitor notifyDidStopStream:reason:withEventUUID:forAccessory:]_block_invoke
CSAudioRouteChangeMonitorImplWatch queue
-[CSAudioRouteChangeMonitorImplWatch activeAudioRouteDidChange:]_block_invoke
-[CSAudioRouteChangeMonitorImplWatch _startMonitoringWithQueue:]
-[CSAudioRouteChangeMonitorImplWatch _stopMonitoring]
-[CSAudioRouteChangeMonitorImplWatch _notifyHearstConnectionState:]
-[CSAudioRouteChangeMonitorImplWatch _systemControllerDied:]
-[CSSpeechEndpointAssetMetaUpdateMonitor _startMonitoringWithQueue:]
-[CSSpeechEndpointAssetMetaUpdateMonitor _stopMonitoring]
-[CSSpeechEndpointAssetMetaUpdateMonitor _didReceiveNewSpeechEndpointAssetMetaData]
com.apple.MobileAsset.SpeechEndpointAssetsWatch.ma.cached-metadata-updated
com.apple.MobileAsset.SpeechEndpointAssetsTV.ma.cached-metadata-updated
com.apple.MobileAsset.SpeechEndpointAssets.ma.cached-metadata-updated
corespeechd speaker xpc connection client queue
-[CSVoiceIdXPCConnection _handleClientEvent:]
-[CSVoiceIdXPCConnection _handleClientMessage:client:]
-[CSVoiceIdXPCConnection _handleClientError:client:]
-[CSAssetManagerEnablePolicy _addAssetManagerEnabledConditions]_block_invoke
-[CSAudioRecordContext(AVVC) avvcContextSettings]
CSXPCListener
-[CSXPCListener listen]
-[CSXPCListener _handleListenerEvent:]
-[CSXPCListener _handleListenerError:]
-[CSXPCListener _handleNewRemoteConnection:]
corespeech.corespeechd.xpc
-[CSXPCListener CSXPCConnectionReceivedClientError:clientError:client:]_block_invoke
extra-delay-frequency
endpoint-threshold
-[CSHybridEndpointer endpointerModelVersion]_block_invoke
-[CSHybridEndpointer updateEndpointerThreshold:]
-[CSHybridEndpointer updateEndpointerDelayedTrigger:]
-[CSHybridEndpointer setEndpointerOperationMode:]_block_invoke
-[CSHybridEndpointer fetchCurrentEndpointerOperationMode]_block_invoke
-[CSHybridEndpointer processTaskString:]_block_invoke
-[CSHybridEndpointer processServerEndpointFeatures:]
-[CSHybridEndpointer shouldAcceptEagerResultForDuration:resultsCompletionHandler:]_block_invoke_2
-[CSHybridEndpointer shouldAcceptEagerResultForDuration:resultsCompletionHandler:]_block_invoke
-[CSHybridEndpointer processFirstAudioPacketTimestamp:firstAudioSampleSensorTimestamp:]_block_invoke
-[CSHybridEndpointer processOSDFeatures:withFrameDurationMs:]
-[CSHybridEndpointer processOSDFeatures:withFrameDurationMs:]_block_invoke_2
-[CSHybridEndpointer processOSDFeatures:withFrameDurationMs:]_block_invoke
-[CSHybridEndpointer logFeaturesWithEvent:locale:]_block_invoke
-[CSHybridEndpointer handleVoiceTriggerWithActivationInfo:]_block_invoke
-[CSHybridEndpointer recordingStoppedForReason:]
-[CSHybridEndpointer stopEndpointer]
-[CSHybridEndpointer resetForNewRequestWithSampleRate:recordContext:]
-[CSHybridEndpointer resetForNewRequestWithSampleRate:recordContext:]_block_invoke
-[CSHybridEndpointer _readParametersFromHEPAsset:]_block_invoke
-[CSHybridEndpointer endpointerAssetManagerDidUpdateAsset:]_block_invoke
-[CSHybridEndpointer _getCSHybridEndpointerConfigForAsset:]
configVersion
com.apple.corespeech.aopFirstPassTriggerWakeupLatency
latency
device
com.apple.corespeech.SecondPassWakeUp
modelVersion
firstPassSource
triggerAPWakeup
-[CSVoiceTriggerStatAggregator logFalseWakeUp:]
-[CSVoiceTriggerStatAggregator logTriggerLengthSampleCountStatistics:withFirstPassDeterministicTriggerLengthSampleCount:]
com.apple.exprAOPSecondPass
newTriggerLengthSampleCount
oldTriggerLengthSampleCount
sampleCountDelta
com.apple.corespeech.AudioZeroRun
duration
-[CSRawAudioInjectionProvider init]
CSRawAudioInjectionProvider
-[CSRawAudioInjectionProvider dealloc]
-[CSRawAudioInjectionProvider setContext:completion:]
-[CSRawAudioInjectionProvider setCurrentContext:streamHandleId:error:]
-[CSRawAudioInjectionProvider prepareAudioStreamRecord:recordDeviceIndicator:error:]
-[CSRawAudioInjectionProvider startAudioStreamWithOption:recordDeviceIndicator:error:]
/var/mobile/darwin_test.wav
-[CSRawAudioInjectionProvider stopAudioStreamWithRecordDeviceIndicator:error:]
-[CSRawAudioInjectionProvider isRecordingWithRecordDeviceIndicator:]
RawAudioInjection
-[CSRawAudioInjectionProvider prewarmAudioSessionWithStreamHandleId:error:]
-[CSRawAudioInjectionProvider activateAudioSessionWithReason:streamHandleId:error:]
CSAudioInjectionTvRemoteEngine
com.apple.coreaudio.BorealisToggled
-[CSVoiceTriggerEnabledMonitor _startMonitoringWithQueue:]_block_invoke
-[CSVoiceTriggerEnabledMonitor _startMonitoringWithQueue:]
-[CSVoiceTriggerEnabledMonitor _stopMonitoring]
-[CSVoiceTriggerEnabledMonitor _checkVoiceTriggerEnabled]
announcemessage
estimatedTTSVolume
debugLogPath
-[CSAlwaysOnProcessorStateMonitor _didReceiveAOPListeningStateChange:]
AcousticSLTaskTypeVoiceTrigger
AcousticSLTaskTypeContConv
AcousticSL
-[CSAttSiriAFTMNode initWithAttSiriController:]
-[CSAttSiriAFTMNode addReceiver:]
-[CSAttSiriAFTMNode stop]_block_invoke
-[CSAttSiriAFTMNode setPrefetchedAsset:]_block_invoke
-[CSAttSiriAFTMNode _startRequestWithContext:withVtei:withVTAssets:taskType:completion:]
-[CSAttSiriAFTMNode startRequestWithContext:withVtei:taskType:completion:]_block_invoke
-[CSAttSiriAFTMNode _setAsset:forTask:]
-[CSAttSiriAFTMNode _startRequestWithContext:withVtei:completion:]
-[CSAttSiriAFTMNode _addAudio:]
-[CSAttSiriAFTMNode _reset]
-[CSAttSiriAFTMNode _handleAFTMResults:]
-[CSAttSiriAFTMNode analyzer:hasFinalResult:]_block_invoke
-[CSAttSiriAFTMNode analyzer:hasPartialResult:]_block_invoke
-[CSAttSiriAFTMNode _logResultToVTDirectory]
-SL.json
SLAssetVersion
SLScore
SLAnalyzedSamples
SLCheckerType
SLThreshold
SLInputOriginType
SLTaskName
-[CSAttSiriAFTMNode _reportResultToAnalytics]
com.apple.
com.apple.private.
-[CSAudioTimeConversionProvidingProxy handleXPCMessage:messageBody:client:audioStreamHandleId:]
deviceId
-[CSAudioTimeConversionProvidingProxy _handleXPCTimeConvertProvidingTypeHostTimeFromSampleCountMessage:messageBody:client:streamHandleId:]
-[CSAudioTimeConversionProvidingProxy _handleXPCTimeConvertProvidingTypeSampleCountFromHostTimeMessage:messageBody:client:streamHandleId:]
meta_version.json
enrollment_version.json
CSP2P_CommandType_Key
CSP2P_CommandDict_Key
corespeech
com.apple.siridebug.command.remote.heysiri
com.apple.siridebug.command.parallel.recording
com.apple.siridebug.command.transfer.voiceprofile
com.apple.siridebug.command.query.voiceprofile
com.apple.siridebug.command.reverse.transfer.voiceprofile
com.apple.siridebug.command.fetch.voiceprofile
com.apple.siridebug.command.voiceprofile.update.trigger
com.apple.siridebug.command.transfer.parallelrecording
com.apple.siridebug.command.fetch.voicegradingdata
com.apple.siridebug.command.transfer.voicegradingdata
com.apple.siridebug.command.delete.voiceprofile
CSP2P_RemoteHeySiriEnable_Key
CSP2P_RemoteHeySiriStatus_Key
CSP2P_RemoteRecordingStart_Key
CSP2P_RemoteRecordingStatus_Key
CSP2P_VoiceProfileData_Key
CSP2P_VoiceProfileFileName_Key
CSP2P_VoiceProfileSpeakerName_Key
CSP2P_VoiceProfileLocale_Key
CSP2P_VoiceProfileDataType_Key
CSP2P_VoiceProfileSegment_Key
CSP2P_VoiceProfileTotalSegments_Key
CSP2P_VoiceProfileStatus_Key
CSP2P_VoiceProfileProfileId_Key
CSP2P_VoiceProfileHomeUserId_Key
CSP2P_VoiceProfileRelativeFilePath_Key
CSP2P_VoiceProfileSiriProfileId_Key
CSP2P_VoiceProfileAppDomain_Key
CSP2P_VoiceProfileOnboardTimeStamp_Key
CSP2P_VoiceProfileTransferCompleted_Key
CSP2P_VoiceProfileRecordedData_Key
CSP2P_VoiceProfileRemoteFileName_Key
CSP2P_VoiceDataToBeGraded_Key
CSP2P_VoiceFileNameToBeGraded_Key
CSP2P_GradingDataTransferStatus_Key
CSP2P_PeerIdentifier_Key
CSP2P_IsDataCompressed_Key
CSP2P_UncompressedDataSize_Key
CSP2P_GradingBatchTransferID_Key
remote
-triggered
-almost
com.apple.corespeech.p2psvc
-[CSP2PService processRemoteCommandWithPayload:fromPeer:withReply:]_block_invoke
CoreSpeech
-[CSP2PService sendCoreSpeechGradingDataToNearbyPeer]_block_invoke
-[CSP2PService sendVTNearMissGradingDataToCompanion]_block_invoke
-[CSP2PService sendVoiceProfileUpdatedMessageToNearbyPeerForLocale:]_block_invoke
-[CSP2PService sendAcousticGradingDataToNearbyPeer]_block_invoke
-[CSP2PService _processRemoteHeySiriCommandWithRequest:fromSenderID:withReply:]
-[CSP2PService _compressFilesInDirectory:matchingPredicate:compressedFileAvailable:]
json
-[CSP2PService _sendVoiceTriggerGradingDataToPeerId:]_block_invoke
v52@?0@"NSString"8@"NSData"16Q24Q32B40@"NSError"44
.wav
.json
-[CSP2PService _sendCoreSpeechGradingDataToPeerId:]_block_invoke_2
-[CSP2PService _sendCoreSpeechGradingDataToPeerId:]_block_invoke
-[CSP2PService _sendCoreSpeechMagusGradingDataToPeerId:]_block_invoke_2
-[CSP2PService _sendCoreSpeechMagusGradingDataToPeerId:]_block_invoke
-[CSP2PService _sendGradingData:withFileName:toPeerId:withCompressedFlag:withUncompressedDataSize:withBatchId:withRetainFileFlag:]
fileData
fileName
peerId
-[CSP2PService _sendGradingData:withFileName:toPeerId:withCompressedFlag:withUncompressedDataSize:withBatchId:withRetainFileFlag:]_block_invoke
-[CSP2PService _receiveParallelRecordingFromPeerId:recordingInfo:withReply:]
%@_%@
-[CSP2PService _receiveVoiceGradingDataFromPeerId:requestInfo:withReply:]
%@.%@.%@
suppressnotification
%@.%@
-[CSP2PService _receiveVoiceProfileFromPeerId:voiceProfileInfo:withReply:]
CoreSpeechCache
audio
tdti
com.apple.siri.corespeech.voiceprofilelist.change
-[CSP2PService _processVoiceProfileDeleteCommandWithRequest:fromSenderID:withReply:]_block_invoke
-[CSP2PService _processGradingDataFetchCommandWithRequest:fromSenderID:withReply:]
-[CSP2PService _processVoiceProfileListQueryCommandFromPeerId:requestInfo:withReply:]
yyyyMMddHHmmss
voiceprofiles
-[CSP2PService _getHomeUserIdForSharedSiriId:withCompletion:]
-[CSP2PService _getHomeUserIdForSharedSiriId:withCompletion:]_block_invoke
homeUserId query for siriProfileId %@ timedout !
-[CSP2PService _processFetchVoiceProfileCommandFromPeerId:requestInfo:withReply:]
Caches/VoiceTrigger/SATUpdate
_%d_%d_%@
-[CSP2PService _sendVoiceProfile:toPeerId:]
td/audio
tdti/audio
ti/audio
-[CSP2PService _sendVoiceProfile:toPeerId:]_block_invoke
-[CSP2PService _processReverseTransferVoiceProfileCommandFromPeerId:requestInfo:withReply:]
-[CSP2PService _processVoiceProfileUpdateTriggerFromPeerId:requestInfo:withReply:]
-[CSP2PService _sendVoiceProfileUpdateTriggerToPeerId:forLocale:]_block_invoke
-synced.wav
-[CSP2PService _sendAcousticGradingDataToPeerId:]_block_invoke_2
-[CSP2PService _sendAcousticGradingDataToPeerId:]_block_invoke
Logs/CoreSpeech/spid/grading
-[CSP2PService _createDirectoryIfDoesNotExist:]
VoiceProfileStore
trained_users.json
Caches
-[CSP2PService _getContentsOfDirectory:]
+[CSAudioRecorderFactory audioRecorderWithQueue:error:]
AttSiriController queue
-[CSAttSiriController siriClientBehaviorMonitor:willStartStreamWithContext:option:]
-[CSAttSiriController siriClientBehaviorMonitor:didStartStreamWithContext:successfully:option:withEventUUID:]_block_invoke
-[CSAttSiriController siriClientBehaviorMonitor:didStopStream:withEventUUID:]_block_invoke
-[CSAttSiriController siriClientBehaviorMonitor:fetchedSiriClientAudioStream:successfully:]_block_invoke
-[CSAttSiriController siriClientBehaviorMonitor:preparedSiriClientAudioStream:successfully:]_block_invoke
-[CSAttSiriController CSSiriEnabledMonitor:didReceiveEnabled:]
-[CSAttSiriController _forceBuildGraph:]
-[CSAttSiriController _setupAudioSrcNodeWithSiriClientStream:]
CSAttSiriController
-[CSAttSiriController _setupAudioSrcNodeWithSiriClientStream:]_block_invoke
-[CSAttSiriController _handleStartProcessingWithRecordContext:]
-[CSAttSiriController _handleStartProcessingWithRecordContext:]_block_invoke
-[CSAttSiriController _handleStopProcessing]
attSiri transaction
-[CSAttSiriController _releaseAttSiriTransactionIfNeeded]
-[CSAttSiriController handleAttendingAudioStopUnexpectly]_block_invoke
-[CSAttSiriController handleAudioStopUnexpectly]_block_invoke
Serial CSAssetManager queue
-[CSAssetManager initWithDownloadOption:]
-[CSAssetManager initWithDownloadOption:]_block_invoke
ENABLED
DISABLED
-[CSAssetManager setAssetDownloadingOption:]_block_invoke
-[CSAssetManager _fetchRemoteMetaData]
-[CSAssetManager _canFetchRemoteAsset:]
-[CSAssetManager CSLanguageCodeUpdateMonitor:didReceiveLanguageCodeChanged:]
-[CSAssetManager _createPeriodicalDownloadTimer]
-[CSAssetManager _createPeriodicalDownloadTimer]_block_invoke
-[CSAssetManager _startPeriodicalDownload]
-[CSAssetManager _stopPeriodicalDownload]
+[CSUtils(AudioDevice) isHFPWithRecordRoute:]
+[CSUtils(AudioDevice) isHeadphoneDeviceWithRecordRoute:playbackRoute:]
+[CSUtils(AudioDevice) isBluetoothAudioDeviceConnected]
BTDetails_IsHFPRoute
-[CSVoiceTriggerAwareZeroFilter resetWithSampleRate:containsVoiceTrigger:voiceTriggerInfo:]
-[CSAudioMetricProvidingProxy handleXPCMessage:messageBody:client:]
-[CSAudioMetricProvidingProxy _handleMetricProvidingRequestTypeAudioMetricMessage:messageBody:client:]
corespeechd xpc connection client queue
-[CSActivationXPCConnection _handleClientEvent:]
-[CSActivationXPCConnection _handleClientMessage:client:]
-[CSActivationXPCConnection _handleClientError:client:]
-[CSActivationXPCConnection _handleActivateEventMesssage:client:]
CSSiriClientBehaviorMonitor
-[CSSiriClientBehaviorMonitor notifyFetchedSiriClientAudioStream:successfully:]_block_invoke
-[CSSiriClientBehaviorMonitor notifyPreparedSiriClientAudioStream:successfully:]_block_invoke
-[CSSiriClientBehaviorMonitor notifyWillStartStreamWithContext:option:]_block_invoke
-[CSSiriClientBehaviorMonitor notifyDidStartStreamWithContext:successfully:option:withEventUUID:]_block_invoke
-[CSSiriClientBehaviorMonitor notifyWillStopStream:reason:]_block_invoke
-[CSSiriClientBehaviorMonitor notifyDidStopStream:withEventUUID:]_block_invoke
-[CSSiriClientBehaviorMonitor notifyReleaseAudioSession]_block_invoke
-[CSLanguageCodeUpdateMonitor _startMonitoringWithQueue:]
CSLanguageCodeUpdateMonitor.m
-[CSLanguageCodeUpdateMonitor _stopMonitoring]
-[CSLanguageCodeUpdateMonitor notifySiriLanguageCodeChanged:]
CSAttSiriNLDANode queue
-[CSAttSiriNLDAClassifierNode initWithAttSiriController:]
-[CSAttSiriNLDAClassifierNode addReceiver:]
-[CSAttSiriNLDAClassifierNode start]
-[CSAttSiriNLDAClassifierNode start]_block_invoke
-[CSAttSiriNLDAClassifierNode stop]_block_invoke
-[CSAttSiriNLDAClassifierNode setPrefetchedAsset:]_block_invoke
-[CSAttSiriNLDAClassifierNode createNLDAClassifierWithAsset:]_block_invoke
-[CSAttSiriNLDAClassifierNode processSpeechPackage:]_block_invoke
CSAudioInjectionHearstEngine
-[CSAudioInjectionHearstEngine dealloc]
Serial CSEventMonitor queue
-[CSEventMonitor _startMonitoringWithQueue:]
CSEventMonitor.m
-[CSEventMonitor _stopMonitoring]
AttSiri
mitigationModelConfigFile
defaultAFTMValue
nldaConfigFile
ouresConfig.json
nldaConfig.json
[%@]
[%llu]
[%f]
BuiltInAOPVoiceTrigger
RemoteMicVoiceTrigger
RemoteMicVAD
JarvisVoiceTrigger
mediaserverdLaunched
RemoraVoiceTrigger
uuid
activationInfo
vadScore
hosttime
+[CSAudioStreamRequest defaultRequestWithContext:]
+[CSAudioStreamRequest requestForLpcmRecordSettingsWithContext:]
+[CSAudioStreamRequest requestForOpusRecordSettingsWithContext:]
+[CSAudioStreamRequest requestForSpeexRecordSettingsWithContext:]
[requiresHistoricalBuffer = %@]
[useCustomizedRecordSettings = %@]
[lpcmIsFloat = %@]
[isSiri = %@]
[sampleRate = %lf]
[numberOfChannels = %lu]
requiresHistoricalBuffer
useCustomizedRecordSettings
audioFormat
sampleRate
lpcmBitDepth
lpcmIsFloat
NumberOfChannels
encoderBitRate
isSiri
recordContext
-[CSVoiceTriggerAssetDownloadMonitor _startMonitoringWithQueue:]
-[CSVoiceTriggerAssetDownloadMonitor _stopMonitoring]
-[CSVoiceTriggerAssetDownloadMonitor _didInstalledNewVoiceTriggerAsset]
com.apple.MobileAsset.VoiceTriggerAssets.ma.new-asset-installed
com.apple.MobileAsset.VoiceTriggerAssetsIPad.ma.new-asset-installed
com.apple.MobileAsset.VoiceTriggerAssetsWatch.ma.new-asset-installed
com.apple.MobileAsset.VoiceTriggerAssetsMarsh.ma.new-asset-installed
com.apple.MobileAsset.VoiceTriggerAssetsMac.ma.new-asset-installed
com.apple.MobileAsset.VoiceTriggerAssetsTV.ma.new-asset-installed
FlexKwdSpotter
recognizer_flexKwd.json
flexKwdConfigFile
flexKwd.Thresholds
flexKwdThresholdsFile
-[CSSmartSiriVolumeUserIntent applyLowerAndUpperBoundsToVolume:]
-[CSSmartSiriVolumeUserIntent applyLowerAndUpperBoundsToVolumeOffset:]
Dpg:%.3f Dpd:%.3f T:%.3f
droppingPrediction
droppedPrediction
-[CSSmartSiriVolumeManager initWithSamplingRate:withAsset:]
-[CSSmartSiriVolumeManager CSAlarmMonitor:didReceiveAlarmChanged:]
-[CSSmartSiriVolumeManager CSTimerMonitor:didReceiveTimerChanged:]
-[CSSmartSiriVolumeManager CSVolumeMonitor:didReceiveMusicVolumeChanged:]
-[CSSmartSiriVolumeManager CSVolumeMonitor:didReceiveAlarmVolumeChanged:]
-[CSSmartSiriVolumeManager CSAutomaticVolumeEnabledMonitor:didReceiveEnabled:]
CSContinuousAudioFingerprintProvider
-[CSContinuousAudioFingerprintProvider startWithUUID:withMaximumBufferSize:]
-[CSContinuousAudioFingerprintProvider startWithUUID:withMaximumBufferSize:]_block_invoke
-[CSContinuousAudioFingerprintProvider stopWithUUID:]
-[CSContinuousAudioFingerprintProvider stopWithUUID:]_block_invoke
-[CSContinuousAudioFingerprintProvider _startListenPollingWithInterval:completion:]
-[CSContinuousAudioFingerprintProvider _startListenPollingWithInterval:completion:]_block_invoke
-[CSContinuousAudioFingerprintProvider _startListenWithCompletion:]_block_invoke_2
-[CSContinuousAudioFingerprintProvider _startListenWithCompletion:]_block_invoke
-[CSContinuousAudioFingerprintProvider _startListenWithCompletion:]
-[CSContinuousAudioFingerprintProvider _startListenPolling]
-[CSContinuousAudioFingerprintProvider _stopListening]
-[CSContinuousAudioFingerprintProvider _stopListening]_block_invoke
-[CSContinuousAudioFingerprintProvider CSSiriEnabledMonitor:didReceiveEnabled:]
-[CSContinuousAudioFingerprintProvider audioStreamProvider:didStopStreamUnexpectly:]
-[CSContinuousAudioFingerprintProvider CSAudioServerCrashMonitorDidReceiveServerRestart:]
mitigation/ouresModel/ouresConfig.json
supportedInputOrigins
CSAttSiriUresNode queue
-[CSAttSiriUresNode initWithAttSiriController:]
-[CSAttSiriUresNode addReceiver:]
-[CSAttSiriUresNode setPrefetchedAsset:]_block_invoke
-[CSAttSiriUresNode setInputOriginWithAudioRecordContext:boronScore:]_block_invoke
-[CSAttSiriUresNode setASRModelRootDirectory:]_block_invoke
-[CSAttSiriUresNode getMitigationDecisionForRCId:]_block_invoke
-[CSAttSiriUresNode _storeMitigationDecision:forRCId:]
-[CSAttSiriUresNode _createModelAndRunInferenceForRcId:withCompletion:]_block_invoke
Mitigation
v16@?0@"SLUresMitigatorResult"8
-[CSAttSiriUresNode processResultCandidate:forRCId:forTask:completion:]_block_invoke
-[CSAttSiriUresNode setEndpointerFeatureEoS:]_block_invoke
-[CSAttSiriUresNode _createMitigatorModelWithConfig:]
-[CSAttSiriUresNode attSiriNode:didMitigate:withScore:taskType:]_block_invoke
-[CSAttSiriUresNode attSiriNode:didUpdateOSDFeatures:withFrameDurationMs:]_block_invoke
-[CSAttSiriUresNode attSiriNode:didUpdateWithSpeakerInfo:]_block_invoke
-[CSAttSiriUresNode attSiriNode:classifierScore:detailedResult:]_block_invoke
Ures ID - %@
-[CSAttSiriUresNode _holdTransactionForUresProcessing]
-[CSAttSiriUresNode _releaseUresProcessingTransaction]
-[CSAttSiriUresNode _decodeJsonFromFile:]
[SplitterEnabled(%d)]
[Device%d(%@) DoAP(%d)]
[SplitterState:%d]
-[CSAdBlockerAssetDownloadMonitor _startMonitoringWithQueue:]
-[CSAdBlockerAssetDownloadMonitor _stopMonitoring]
-[CSAdBlockerAssetDownloadMonitor _didInstalledNewAdBlockerAsset]
-[CSAdBlockerAssetDownloadMonitor trialAssetDownloadMonitorDelegate:didInstallNewAsset:assetType:]
com.apple.MobileAsset.AdBlockerAssets.ma.new-asset-installed
CSVoiceIdXPCListener
com.apple.corespeech.corespeechd.voiceid.xpc
-[CSVoiceIdXPCListener listen]
-[CSVoiceIdXPCListener _handleListenerEvent:]
-[CSVoiceIdXPCListener _handleListenerError:]
-[CSVoiceIdXPCListener _handleNewRemoteConnection:]
corespeech.corespeechd.voiceid.xpc
CSSpeechManager Asset Query Queue
-[CSSpeechManager startManager]
-[CSSpeechManager registerSpeechController:]
-[CSSpeechManager registerSiriClientProxy:]
v32@?0@"NSNumber"8@"CSAudioProvider"16^B24
-[CSSpeechManager audioProviderWithContext:error:]
-[CSSpeechManager audioProviderWithContext:error:]_block_invoke
v32@?0Q8q16@"NSError"24
-[CSSpeechManager audioProviderWithStreamID:]_block_invoke
-[CSSpeechManager _getAudioRecorderWithError:]
-[CSSpeechManager audioProviderInvalidated:streamHandleId:]_block_invoke
-[CSSpeechManager audioRecorderWillBeDestroyed:]_block_invoke
-[CSSpeechManager voiceTriggerAssetHandler:endpointId:didChangeCachedAsset:]
-[CSSpeechManager _handleClearLoggingFileTimer]
-[CSSpeechManager _createClearLoggingFileTimer]
-[CSSpeechManager _startClearLoggingFilesTimer]
-[CSVoiceIdXPCClient _handleListenerEvent:]
-[CSVoiceIdXPCClient _handleListenerError:]
utterencePath
audioDevice
audioRecord
voiceTriggerEventInfo
otherCtxt
-[CSAudioZeroCounter getZeroStatisticsFromBuffer:entireSamples:]
-[CSAudioZeroCounter stopReportZeroStatistics]
CSOpportuneSpeakBehaviorMonitor
-[CSOpportuneSpeakBehaviorMonitor notifyWillStartStreamWithContext:audioProviderUUID:option:]_block_invoke
-[CSOpportuneSpeakBehaviorMonitor notifyDidStartStreamWithContext:audioProviderUUID:successfully:option:]_block_invoke
-[CSOpportuneSpeakBehaviorMonitor notifyWillStopStream:]_block_invoke
-[CSOpportuneSpeakBehaviorMonitor notifyDidStopStream:]_block_invoke
Median
+[CSUtils(Statistics) distributionDictionary:]
average:
stddev:
q24@?0@8@16
-[CSXPCConnection sendMessageToClient:]
-[CSXPCConnection sendMessageToClient:]_block_invoke
-[CSXPCConnection _handleClientEvent:]
-[CSXPCConnection _handleClientMessage:client:]
-[CSXPCConnection _handleAudioProvidingMessage:messageBody:client:]
-[CSXPCConnection _handleAudioProvidingRequestTypeSwitchMessage:messageBody:client:]
-[CSXPCConnection _handleSetXPCClientTypeMessage:messageBody:client:]
-[CSXPCConnection _handleClientError:client:]
-[CSXPCConnection _handlePingPongMessage:client:]
-[CSAttSiriConnectionManager initWithAttSiriController:supportsAttentiveSiri:supportsSpeechRecognitionOnDevice:supportsSSR:]
com.apple.corespeech.corespeechd.endpointer.service
-[CSAttSiriConnectionManager _setupEndpointListener]
-[CSAttSiriConnectionManager _setupLocalSpeechRecognitionListener]
com.apple.corespeech.corespeechd.attsiri.service
-[CSAttSiriConnectionManager _setupAttSiriServiceListener]
com.apple.corespeech.corespeechd.ssr.service
-[CSAttSiriConnectionManager _setupSSRListener]
-[CSHostDaemon init]_block_invoke
CSHostDaemon
-[CSHostDaemon _daemonDidLaunch]
com.apple.notifyd.matching
-[CSHostDaemon _setupNotifyHandlers]_block_invoke
AFLanguageCodeDidChangeDarwinNotification
-[CSHostDaemon _daemonWillShutdown]
FirstPktLatency
TrailingPktLatency
TrailingPktSpeechLatency
-[CSEndpointLatencyInfo addPktInfoWithTimestamp:arrivalTimestamp:currentMachTime:]
-[CSEndpointLatencyInfo reportWithRequestMHUUID:]
+[CSUtils(AudioFile) readAudioChunksFrom:block:]
-[CSCoreSpeechDaemonStateMonitor notifyDaemonStateChanged:]
com.apple.corespeech.corespeechd.launch
-[CSCoreSpeechDaemonStateMonitor _startMonitoringWithQueue:]
-[CSCoreSpeechDaemonStateMonitor _stopMonitoring]
-[CSCoreSpeechDaemonStateMonitor _didReceiveDaemonStateChanged:]
-[CSConnectionListener initWithMachService:withServiceInterface:withServiceObject:withDelegateInterface:]
com.apple.CoreSpeech.Connection.Listener
-[CSConnectionListener dealloc]
-[CSConnectionListener listener:shouldAcceptNewConnection:]
-[CSConnectionListener listener:shouldAcceptNewConnection:]_block_invoke
-[CSConnectionListener listener:shouldAcceptNewConnection:]_block_invoke_2
-[CSConnectionListener notifyClientsWithBlock:]
-[CSConnectionListener notifyClientsWithBlock:]_block_invoke
-[CSConnectionListener resumeConnection]
/var/mobile/Library/VoiceTrigger
/var/mobile/Library/VoiceTrigger/KeepAlive
-[CSCoreSpeechDKeepAliveHandler _enableCoreSpeechDaemonKeepAlive]
KeepAlive
-[CSCoreSpeechDKeepAliveHandler _coreSpeechDaemonKeepAlived]
CSSiriAssertionMonitor queue
-[CSSiriAssertionMonitor init]
-[CSSiriAssertionMonitor _stopMonitoring]
-[CSSiriAssertionMonitor enableAssertionReceived]_block_invoke
-[CSSiriAssertionMonitor disableAssertionReceived]_block_invoke
-[CSAudioSessionProvidingProxy CSXPCConnectionReceivedClientError:clientError:client:]
-[CSAudioSessionProvidingProxy dealloc]
-[CSAudioSessionProvidingProxy handleXPCMessage:messageBody:client:]
-[CSAudioSessionProvidingProxy _handleSessionProvidingRequestTypePrewarmMessage:client:]
-[CSAudioSessionProvidingProxy _handleSessionProvidingRequestTypeActivateMessage:messageBody:client:]
-[CSAudioSessionProvidingProxy _handleSessionProvidingRequestTypeDeactivateMessage:messageBody:client:]
-[CSAudioSessionProvidingProxy _handleSessionProvidingRequestTypeGetDuckOthersOption:messageBody:client:]
-[CSAudioSessionProvidingProxy _handleSessionProvidingRequestTypeSetDuckOthersOption:messageBody:client:]
audioDeviceID
duckLevel
rampDuration
-[CSAudioSessionProvidingProxy _handleSessionProvidingRequestTypeDuckAudioDevice:messageBody:client:]
-[CSAudioSessionProvidingProxy _handleSessionProvidingRequestTypeDuckDefaultOutputAudioDevice:messageBody:client:]
-[CSAudioSessionProvidingProxy _handleSessionProvidingRequestTypeEnableMiniDucking:messageBody:client:]
ENABLE
DISABLE
-[CSAudioSessionProvidingProxy _handleSessionProvidingRequestTypeEnableSmartRoutingConsideration:messageBody:client:]
-[CSAudioSessionProvidingProxy audioSessionProvider:providerInvalidated:]
CSAudioInjectionRemoraEngine
-[CSAudioInjectionRemoraEngine dealloc]
Languages
Footprint
Premium
-[CSCommandControlStreamEventMonitor isStreaming]
-[CSAudioAlertProvidingProxy handleXPCMessage:messageBody:client:]
-[CSAudioAlertProvidingProxy _handleAlertProvidingRequestTypeSetAlertSoundMessage:messageBody:client:]
-[CSAudioAlertProvidingProxy _handleAlertProvidingRequestTypePlayAlertSoundMessage:messageBody:client:]
-[CSAudioAlertProvidingProxy _handleAlertProvidingRequestTypePlayRecordStartingAlertAndResetEndpointerMessage:messageBody:client:]
-[CSAudioAlertProvidingProxy _handleAlertProvidingRequestTypeAlertStartTimeMessage:messageBody:client:]
-[CSAudioAlertProvidingProxy _handleAlertProvidingRequestTypeConfigureAlertBehavior:messageBody:client:]
-[CSAudioAlertProvidingProxy audioAlertProvidingDidFinishAlertPlayback:ofType:error:]
com.apple.corespeech
-[CSAVCallConnectedMonitor _systemControllerDied:]
voicetrigger xpc service connection client queue
-[CSVoiceTriggerXPCConnection _handleClientEvent:]
-[CSVoiceTriggerXPCConnection _handleClientMessage:client:]
-[CSVoiceTriggerXPCConnection _handleClientError:client:]
-[CSVoiceTriggerXPCConnection _handleVoiceTriggerXPCServiceMessage:client:]
phraseSpotterBypass
bypassTimeout
-[CSVoiceTriggerXPCConnection _handlePhraseSpotterBypassRequest:]
raiseToSpeakBypass
-[CSVoiceTriggerXPCConnection _handleVoiceTriggeredSiriSessionCancelled]
enable
assertion
triggerStats
-[CSAttSiriFlexKwdNode initWithAttSiriController:]
-[CSAttSiriFlexKwdNode startWithContext:audioStreamId:]_block_invoke
-[CSAttSiriFlexKwdNode attSiriAudioSrcNodeDidStartRecording:successfully:error:]
-[CSAttSiriFlexKwdNode triggerReportedFromFlxKwdSpotter:]
-[CSAudioRouteChangeMonitor _startMonitoringWithQueue:]
CSAudioRouteChangeMonitor.m
-[CSAudioRouteChangeMonitor _stopMonitoring]
-[CSAudioRouteChangeMonitor getHearstConnected:]
-[CSAudioRouteChangeMonitor hearstConnected]
-[CSAudioRouteChangeMonitor getJarvisConnected:]
-[CSAudioRouteChangeMonitor jarvisConnected]
playbackDeviceTypeList
%@ {recordDeviceInfo = %@, playbackRoute = %@, playbackDevices = %@
+[CSUtils(machXPC) machXPCConnection:hasEntitlement:]
-[CSAdBlockerAssetMetaUpdateMonitor _startMonitoringWithQueue:]
-[CSAdBlockerAssetMetaUpdateMonitor _stopMonitoring]
-[CSAdBlockerAssetMetaUpdateMonitor _didReceiveNewAdBlockerAssetMetaData]
com.apple.MobileAsset.AdBlockerAssets.ma.cached-metadata-updated
+[CSAdBlockerAssetDecoderFactory adBlockerAssetDecoderWithVersion:]
CSAudioInjectionEngine
-[CSAudioInjectionEngine _createDeInterleaverIfNeeded]
-[CSAudioInjectionEngine stop]_block_invoke
-[CSAudioInjectionEngine _readAudioBufferAndFeed]
-[CSAudioInjectionEngine injectAudio:withScaleFactor:outASBD:playbackStarted:completion:]
-[CSAudioInjectionEngine stopAudioStream]_block_invoke
-[CSAudioInjectionEngine _deinterleaveBufferIfNeeded:]
-[CSAudioInjectionEngine _compensateChannelDataIfNeeded:receivedNumChannels:]
-[CSSoftwareUpdateCheckingMonitor _startMonitoringWithQueue:]
-[CSSoftwareUpdateCheckingMonitor _stopMonitoring]
-[CSSoftwareUpdateCheckingMonitor _checkSoftwareUpdateCheckingState]
com.apple.duetscheduler.restartCheckNotification
-[CSAudioConverter _convertBufferedLPCM:allowPartial:timestamp:arrivalTimestampToAudioRecorder:]
-[CSAudioConverter _convertBufferedLPCM:allowPartial:timestamp:arrivalTimestampToAudioRecorder:]_block_invoke
-[CSAudioConverter reset]
-[CSAudioConverter _configureAudioConverter:]
CreateAudioConverter
CSMediaPlayingMonitor queue
-[CSMediaPlayingMonitor initializeMediaPlayingState]_block_invoke_2
-[CSMediaPlayingMonitor _startMonitoringWithQueue:]
-[CSMediaPlayingMonitor _stopMonitoring]
-[CSMediaPlayingMonitor _notePossiblePlayPausedStateChange:]
PLAYING
NOT PLAYING
CSVoiceTriggerAOPModeEnabledPolicyIOS RecordState queue
-[CSVoiceTriggerAOPModeEnabledPolicyIOS _addConditionsForIOSBargeIn]_block_invoke
-[CSVoiceTriggerAOPModeEnabledPolicyIOS _addConditionsForIOSAOP]_block_invoke
-[CSVoiceTriggerAOPModeEnabledPolicyIOS _isSpeechDetectionDevicePresent]
-[CSVoiceTriggerAOPModeEnabledPolicyIOS siriClientBehaviorMonitor:didChangedRecordState:withEventUUID:withContext:]_block_invoke
-[CSAudioRecordDeviceIndicator updateWithLatestRecordContext:]
-[CSNetworkAvailabilityMonitor _startMonitoringWithQueue:]
-[CSNetworkAvailabilityMonitor _stopMonitoring]
-[CSNetworkAvailabilityMonitor _availabilityChanged]
-[NSDictionary(XPCObject) _cs_initWithXPCObject:]
-[NSDictionary(XPCObject) _cs_initWithXPCObject:]_block_invoke
B24@?0r*8@"NSObject<OS_xpc_object>"16
-[NSDictionary(XPCObject) _cs_xpcObject]_block_invoke
v32@?0@8@16^B24
-[CSAudioMeterProvidingProxy handleXPCMessage:messageBody:client:]
-[CSAudioMeterProvidingProxy _handleMeterProvidingRequestTypeSetMeteringEnabledMessage:messageBody:client:]
-[CSAudioMeterProvidingProxy _handleMeterProvidingRequestTypeUpdateMetersMessage:messageBody:client:]
v16@?0B8f12
-[CSAudioMeterProvidingProxy _handleMeterProvidingRequestTypePowerMessage:messageBody:client:powerType:]
CSMicUsageReporter
SpeechModelTrainingProtocol
SpeechModelTrainingClient
CSSpeechModelTrainingXPCManager
CSSyncKeywordAnalyzerQuasar
CSKeywordAnalyzerNDEAPIResult
CSKeywordAnalyzerNDEAPI
CSFallbackAudioSessionReleaseProvidingProxy
CSXPCConnectionDelegate
NSObject
CSUserIdentityClassifier
AVVC
CSActivationXPCClient
CSAttSiriRequestContext
NSSecureCoding
NSCoding
CSAudioSampleRateConverter
CSSpeakerRecognitionAssetMetaUpdateMonitor
CSXPCClientFactory
CSVolumeMonitor
CSFallbackAudioSessionReleaseProvider
CSAudioRecorderDelegate
CSFallbackAudioSessionReleaseProviding
CSSpeakerRecognitionAssetDownloadMonitor
CSTrialAssetDownloadMonitorDelegate
CSServerEndpointFeatures
CSVoiceTriggerXPCServiceProxy
CSAttSiriAudioSessionStateClient
AFNotifyObserverDelegate
CSAudioStreamProvidingProxy
CSAudioStreamProvidingDelegate
CSFlexKeywordResult
CSFlexKeywordSpotter
_EARSpeechRecognitionResultStream
CSAttSiriAudioDataReceiver
CSAttSiriAttendingAudioSrcNode
CSAttSiriNode
CSAudioFileLog
CSAudioSessionInfoProvider
CSAudioSessionInfoProviding
CSStateMachine
CSPreMyriadVoiceTriggerMetaData
CSPreMyriadCoordinator
CSVoiceTriggerDelegate
CSSecondPassProgressDelegate
CSBenchmarkXPCProtocol
AttSiri
CSAttSiriCachedEndpointInfo
CSAttSiriEndpointerNodeDelegate
CSAttSiriEndpointerNode
CSEndpointAnalyzerDelegate
CSAttSiriOSDNodeDelegate
CSEndpointerXPCService
CSAudioInjectionFileOption
CSSmartSiriVolumeEnablePolicy
CSAttSiriSSRNodeDelegate
CSAttSiriSSRNode
SSRSpeakerRecognitionControllerDelegate
CSSSRXPCService
CSSiriRestrictionOnLockScreenMonitor
MCProfileConnectionObserver
AudioInjectionXPCProtocol
CSPostBuildInstallService
CSAssetControllerFactory
CSVoiceTriggerDataCollector
CSKeywordAnalyzerQuasar
CSVoiceTriggerAssetHandlerMac
CSVoiceTriggerAssetDownloadMonitorDelegate
CSFirstUnlockMonitorDelegate
CSLanguageCodeUpdateMonitorDelegate
CSAttSiriAttendingTriggerEventInfo
CSAudioStartStreamOption
NSCopying
CSVTSecondPassPhraseScore
CSVTSecondPassScorer
CSCoreSpeechServices
CSVoiceTriggerAssetChangeMonitor
CSAudioServerCrashMonitor
CSAudioServerCrashEventProvidingDelegate
CSXPCClient
CSAudioSessionProviding
CSAudioStreamProviding
CSAudioAlertProviding
CSAudioMeterProviding
CSAudioMetricProviding
CSAudioTimeConversionProviding
CSTriggerInfoProviding
CSOpportuneSpeakListnerTestService
CSOpportuneSpeakListenerDelegate
CSTimerMonitor
CSSiriAudioSession
CSSiriAudioRoute
CSOpportuneSpeakEventMonitor
CSOpportuneSpeakBehaviorMonitorDelegate
CSAttSiriMitigationAssetHandler
CSVoiceTriggerAssetHandlerDelegate
CSPhraseSpotterEnabledMonitor
CSVoiceTriggerAssetHandler
CSMyriadNotifier
CSBenchmarkXPCListener
NSXPCListenerDelegate
Liminal
CSLanguageCodeUpdateMonitorImpl
CSMyriadPHash
SignalEstimate
CSVoiceTriggerXPCListener
CSVoiceTriggerXPCConnectionDelegate
CSCoreSpeechServicesListener
CSCoreSpeechServiceListenerDelegate
CSAudioStreamHolding
CSEndpointDelayReporter
SmartSiriVolume
CSAudioInjectionXPCListener
CSVoiceTriggerRTModel
CSAudioProvider
CSAudioServerCrashMonitorDelegate
CSAudioPreprocessorDelegate
CSSiriDebugConnection
CSAssetDownloadingOption
Directory
CSPowerAssertionMac
CSVoiceTriggerFirstPassHearstAP
CSOpportuneSpeakEventMonitorDelegate
CSVoiceTriggerEnabledPolicyNonAOP
CSNNVADEndpointAnalyzer
CSEndpointAnalyzerImpl
CSEndpointAnalyzer
CSBiometricMatchMonitor
CSSpeechDetectionDevicePresentMonitor
CSKeywordAnalyzerNDAPIResult
CSKeywordAnalyzerNDAPI
RTModel
CSDefaultAudioRouteChangeMonitorMac
CSGestureMonitor
CSAudioRouteChangeMonitorImpl
debugDescription
remoteVoiceActivityVADBuffer
CSAudioRecorder
AVVoiceControllerRecordDelegate
CSAudioDecoderDelegate
CSAudioFileReaderDelegate
CSRemoteRecordClientDelegate
CSAudioServerCrashEventProviding
CSAudioSessionEventProviding
CSAudioTandemStream
CSOpportuneSpeakListener
CSSPGEndpointAnalyzerDelegate
XPCObject
CSSiriEnabledMonitor
CSBluetoothManager
CSJarvisTriggerModeMonitor
CSActivationXPCListener
CSActivateXPCConnectionDelegate
CSModelBenchmarker
CSAudioInjectionEngineDelegate
CSRemoteDeviceProtocolInfo
AudioHardware
Trial
CSAudioSessionInfoProvidingProxy
CSAudioSessionInfoProvidingDelegate
CSSmartSiriVolumeService
CSSmartSiriVolumeServiceDelegate
CSAssetController
CSEventMonitorDelegate
Utils
CSHybridEndpointAnalyzer
CSAssetManagerDelegate
OSDAnalyzerDelegate
8!!!B
RecordContext
CSAdBlockerAssetDecoderV3
CSAudioInjectionXPC
CSNovDetectorResult
CSNovDetector
CSActivationEventNotificationHandler
CSSmartSiriVolume
CSMediaPlayingMonitorDelegate
CSSiriEnabledMonitorDelegate
CSSiriClientBehaviorMonitorDelegate
CSSmartSiriVolumeProcessor
isPluginContext
CSAudioInjectionProvider
CSAttSiriStateMonitor
Compression
CSRemoteXPCVoiceTriggerEnabledPolicy
CSListeningEnabledPolicyWatch
CSOtherAppRecordingStateMonitor
CSHostPowerSourceMonitor
LanguageCode
CSAutomaticVolumeEnabledMonitor
CSAudioFileReader
CSEndpointerProxy
CSEndpointAnalyzerImplDelegate
CSAttSiriOSDNode
CSEndpointerAssetManagerDelegate
CSAttSiriSignalDataAggregatorProtocol
RMSSample
CSShadowMicScoreCreator
CSMyriadSelfTriggerCoordinator
CSSelfTriggerDetectorDelegate
CSEndpointerAssetManager
CSAudioInjectionBuiltInEngine
CSSpringboardStartMonitor
SpeakerRecognition
CSActivationEventNotifier
CSMacWakeSleepMonitor
CSAlarmMonitor
CSSmartSiriVolumeServiceProxy
CSAttSiriAudioSrcNode
CSFirstUnlockMonitor
CSVoiceTriggerEventInfoProvider
CSAudioRecordDeviceInfo
CSCommandControlBehaviorMonitor
CSSiriLauncher
CSAudioProcessWaitingBuffer
CSAttSiriAsrNode
CoreEmbeddedSpeechRecognizerDelegate
LBLocalSpeechService
CSAttSiriTimer
CSAudioStream
CSVoiceTriggerAssetMetaUpdateMonitor
CSOpportuneSpeakListenerOption
CSAudioPreprocessor
CSVoiceTriggerAwareZeroFilterDelegate
CSBeepCancellerDelegate
CSAccessorySiriClientBehaviorMonitor
CSAudioRouteChangeMonitorImplWatch
CSSpeechEndpointAssetMetaUpdateMonitor
CSAlwaysDisabledPolicy
CSScreenLockMonitor
CSVoiceIdXPCConnection
CSAssetManagerEnablePolicy
CSXPCListener
CSDarkWakePowerAssertionMac
Indexing
CSHybridEndpointer
!2!B
CSVoiceTriggerStatAggregator
CSAssetManagerEnablePolicyFactory
CSRawAudioInjectionProvider
CSAudioInjectionTvRemoteEngine
CSAudioConverterDelegate
CSVoiceTriggerEnabledMonitor
CSMSNExceptionManager
CSSmartSiriVolumeEstimate
CSAlwaysOnProcessorStateMonitor
CSAttSiriAFTMNodeDelegate
CSAttSiriAFTMNode
SLProgressiveCheckerAnalyzerDelegate
CSAttSiriMotionNode
NSXPC
CSAudioTimeConversionProvidingProxy
CSSuddenTerminationProtector
CSP2PService
CSAudioRecorderFactory
CoreSpeechXPCProtocol
CSAttSiriController
CSAttSiriFlexKwdNodeDelegate
CSAttSiriServiceDelegate
CSAttSiriServiceProtocol
CSAssetManager
CSVoiceTriggerAssetMetaUpdateMonitorDelegate
CSSpeechEndpointAssetMetaUpdateMonitorDelegate
CSAdBlockerMetaUpdateMonitorDelegate
CSAssetControllerDelegate
CSSpeakerRecognitionAssetMetaUpdateMonitorDelegate
AudioDevice
CSVoiceTriggerAwareZeroFilter
CSSPGEndpointAnalyzer
CSVoiceTriggerEventsCoordinator
CSAudioMetricProvidingProxy
CSActivationXPCConnection
CSBluetoothDeviceInfo
CSSiriClientBehaviorMonitor
CSLanguageCodeUpdateMonitor
CSAttSiriNLDAClassifierDelegate
CSAttSiriNLDAClassifierNode
CSAudioInjectionHearstEngine
CSAVVCRecordingClientMonitor
CSEventMonitor
CSActivationEvent
CSAudioStreamRequest
CSVoiceTriggerAssetDownloadMonitor
FlexKwd
CSAudioSessionMonitor
CSAudioSessionEventProvidingDelegate
CSSmartSiriVolumeUserIntent
CSGestureDropEvent
CSAudioInjectionDevice
CSEndpointerMetrics
CSOpportuneSpeakListenerDeviceManager
CSSmartSiriVolumeManager
CSAlarmMonitorDelegate
CSTimerMonitorDelegate
CSVolumeMonitorDelegate
CSAutomaticVolumeEnabledMonitorDelegate
CSContinuousAudioFingerprintProvider
CSAttSiriUresNodeDelegate
CSAttSiriUresNode
CSAttSiriAttentionNodeDelegate
CSBluetoothWirelessSplitterInfo
CSAdBlockerAssetDownloadMonitor
CSVoiceIdXPCListener
CSSpeechManager
CSActivationEventNotificationHandlerDelegate
CSAudioProviderDelegate
CSVoiceIdXPCClient
CSAudioZeroCounter
CSOpportuneSpeakBehaviorMonitor
CSAttSiriAttentionNode
Statistics
CSXPCConnection
CSEndpointerXPCServiceDelegate
LBLocalSpeechServiceDelegate
CSSSRXPCServiceDelegate
CSAttSiriConnectionManager
CSHostDaemon
CSEndpointLoggingHelper
CSEndpointLatencyInfo
AudioFile
CSCoreSpeechDaemonStateMonitor
CSBuiltinSpeakerStateMonitor
CSRemoteRecordClient
CSConnectionListener
CSConnectionServiceDelegate
CSCoreSpeechDKeepAliveHandler
CSSiriAssertionMonitor
CSAudioSessionProvidingProxy
CSAudioSessionProvidingDelegate
CSBluetoothWirelessSplitterMonitor
CSUserSessionActiveMonitor
CSAudioInjectionRemoraEngine
CSAsset
CSCommandControlStreamEventMonitor
CSCommandControlBehaviorMonitorDelegate
CSTrialAssetManager
CSAudioAlertProvidingProxy
CSAudioAlertProvidingDelegate
CSAVCallConnectedMonitor
CSVoiceTriggerXPCConnection
CSAttSiriFlexKwdNode
CSFlexKeywordSpotterDelegate
CSVoiceProfileRetrainManager
Bitset
CSAudioRouteChangeMonitor
CSAlertBehaviorPredictor
CSAudioDeviceInfo
CSManualDuckingHandler
machXPC
CSAudioInjectionEngineFactory
CSAdBlockerAssetMetaUpdateMonitor
CSAdBlockerAssetDecoderFactory
CSAdBlockerAssetDecoderV2
CSAudioInjectionEngine
CSSoftwareUpdateCheckingMonitor
CSPhoneCallStateMonitor
CSAudioConverter
CSMediaPlayingMonitor
CSAdBlockerAssetDecoderV1
CSBatteryMonitor
CSVoiceTriggerAOPModeEnabledPolicyIOS
CSAudioRecordDeviceIndicator
CSTrialAssetDownloadMonitor
CSAVVoiceTriggerClientManager
CSVoiceTriggerAOPModeEnabledPolicyFactory
CSNetworkAvailabilityMonitor
CSAudioMeterProvidingProxy
@16@0:8
v20@0:8B16
v32@0:8Q16@24
v24@0:8@16
v16@0:8
@"NSObject<OS_dispatch_queue>"
v32@0:8@16@?24
v48@0:8@16@24B32B36@?40
v36@0:8@16B24@?28
v40@0:8@16@24@?32
v32@0:8@"NSString"16@?<v@?@"NSString">24
v48@0:8@"NSString"16@"NSString"24B32B36@?<v@?@"NSDictionary"@"NSError">40
v32@0:8@"NSURL"16@?<v@?@"NSError">24
v36@0:8@"NSString"16B24@?<v@?@"NSDictionary"@"NSError">28
v40@0:8@"NSDictionary"16@"NSString"24@?<v@?@"NSDictionary"@"NSError">32
@24@0:8@16
@24@0:8@?16
v56@0:8@16@24@32@40@?48
v60@0:8@16@24@32B40@44@?52
v52@0:8@16@24B32@36@?44
@"NSXPCConnection"
@40@0:8@16@24B32B36
v36@0:8@16C24@28
d24@0:8@16
d16@0:8
v24@0:8d16
Q16@0:8
v24@0:8Q16
@"NSMutableArray"
@"NSArray"
@"_EARSyncSpeechRecognizer"
@"NSDictionary"
@28@0:8@16B24
f16@0:8
v20@0:8f16
B16@0:8
@32@0:8r^s16q24
@32@0:8^v16q24
@"NSMutableData"
@"<CSKeywordAnalyzerNDEAPIScoreDelegate>"
B24@0:8@16
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
v40@0:8@16@24@32
v40@0:8@"NSObject<OS_xpc_object>"16@"NSObject<OS_xpc_object>"24@"NSObject<OS_xpc_object>"32
v40@0:8@"CSXPCConnection"16@"NSObject<OS_xpc_object>"24@"NSObject<OS_xpc_object>"32
v44@0:8@16@24B32@36
@"CSXPCConnection"
Q40@0:8@16@24@32
@24@0:8Q16
q24@0:8q16
@"NSObject<OS_xpc_object>"
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
@24@0:8^{_NSZone=}16
@96@0:8{AudioStreamBasicDescription=dIIIIIIII}16{AudioStreamBasicDescription=dIIIIIIII}56
^{OpaqueAudioConverter=}96@0:8{AudioStreamBasicDescription=dIIIIIIII}16{AudioStreamBasicDescription=dIIIIIIII}56
^{OpaqueAudioConverter=}
{AudioStreamBasicDescription="mSampleRate"d"mFormatID"I"mFormatFlags"I"mBytesPerPacket"I"mFramesPerPacket"I"mBytesPerFrame"I"mChannelsPerFrame"I"mBitsPerChannel"I"mReserved"I}
r*16@0:8
v24@0:8@?16
v68@0:8@16Q24@32@40Q48Q56i64
v40@0:8@16Q24@32
v44@0:8@16Q24B32@36
v40@0:8@16Q24q32
v32@0:8@16q24
v40@0:8@16q24@32
v32@0:8@16@24
v28@0:8@16B24
v68@0:8@"CSAudioRecorder"16Q24@"NSData"32@"NSData"40Q48Q56i64
v40@0:8@"CSAudioRecorder"16Q24@"CSAudioChunkForTV"32
v44@0:8@"CSAudioRecorder"16Q24B32@"NSError"36
v40@0:8@"CSAudioRecorder"16Q24q32
v32@0:8@"CSAudioRecorder"16q24
v40@0:8@"CSAudioRecorder"16q24@"NSError"32
v24@0:8@"CSAudioRecorder"16
v32@0:8@"CSAudioRecorder"16@"NSDictionary"24
v28@0:8@"CSAudioRecorder"16B24
v24@0:8@"NSDictionary"16
v32@0:8@"CSAudioRecorder"16@"NSError"24
B32@0:8Q16^@24
@"CSAudioRecorder"
v36@0:8@16B24Q28
@"CSTrialAssetDownloadMonitor"
@72@0:8q16q24d32@40d48@56q64
@64@0:8q16q24d32@40d48@56
q16@0:8
v24@0:8q16
@"NSString"
v36@0:8B16@20d28
v28@0:8B16d20
@"NSMutableSet"
@"NSHashTable"
@"CSSiriAssertionMonitor"
v28@0:8@16i24
v40@0:8@16Q24Q32
v28@0:8@"AFNotifyObserver"16i24
v40@0:8@"AFNotifyObserver"16Q24Q32
v32@0:8Q16Q24
@"<CSAttSiriSessionStateDelegate>"
@"AFNotifyObserver"
v32@0:8@"<CSAudioStreamProviding>"16q24
v32@0:8@"<CSAudioStreamProviding>"16@"CSAudioChunk"24
v32@0:8@"<CSAudioStreamProviding>"16@"CSAudioChunkForTV"24
@"<CSAudioStreamProviding>"
@"<CSTriggerInfoProviding>"
@"CSAudioStream"
@"CSAudioRecordContext"
@44@0:8@16f24q28q36
v48@0:8@16@24@32@40
v32@0:8@16d24
v72@0:8@16q24q32d40@48d56q64
v32@0:8@"_EARSpeechRecognizer"16@"_EARSpeechRecognitionResult"24
v32@0:8@"_EARSpeechRecognizer"16@"NSError"24
v32@0:8@"_EARSpeechRecognizer"16@"NSArray"24
v48@0:8@"_EARSpeechRecognizer"16@"NSArray"24@"NSArray"32@"NSArray"40
v32@0:8@"_EARSpeechRecognizer"16@"_EARSpeechRecognitionResultPackage"24
v32@0:8@"_EARSpeechRecognizer"16d24
v32@0:8@"_EARSpeechRecognizer"16@"_EARSpeechRecognition"24
v72@0:8@"_EARSpeechRecognizer"16q24q32d40@"NSArray"48d56q64
@"<CSFlexKeywordSpotterDelegate>"
@"_EARSpeechRecognizer"
@"_EARSpeechRecognitionAudioBuffer"
@"CSAsset"
v36@0:8@16B24@28
v36@0:8@"<CSAttSiriNode>"16B24@"NSError"28
v32@0:8@"<CSAttSiriNode>"16@"CSAudioChunk"24
v24@0:8@"<CSAttSiriNode>"16
@24@0:8@"CSAttSiriController"16
@"CSAttSiriController"16@0:8
v24@0:8@"CSAttSiriController"16
@"NSArray"16@0:8
v24@0:8@"NSString"16
@"CSAsset"16@0:8
v24@0:8@"CSAsset"16
@40@0:8@16@24@32
@48@0:8@16@24@32@40
v28@0:8B16@20
@"CSAttSiriController"
@"CSSpeechManager"
@32@0:8@16@24
^{OpaqueExtAudioFile=}
@"NSURL"
I24@0:8@16
v24@0:8@"<CSAudioSessionInfoProvidingDelegate>"16
I24@0:8@"NSString"16
@24@0:8q16
v40@0:8q16q24q32
v32@0:8q16q24
@"<CSStateMachineDelegate>"
@"NSMutableDictionary"
v60@0:8@16@24Q32@40B48@?52
v32@0:8@"NSDictionary"16@"NSString"24
v40@0:8@"NSDictionary"16@"NSString"24@?<v@?>32
v24@0:8@"NSData"16
v60@0:8@"NSDictionary"16@"NSData"24Q32@"NSString"40B48@?<v@?>52
v40@0:8Q16@24d32
v40@0:8Q16@"NSString"24d32
v32@0:8Q16@"NSString"24
@?16@0:8
@"<CSVoiceTriggerDelegate>"
@"<CSSecondPassProgressProviding>"
@"CSPreMyriadVoiceTriggerMetaData"
v48@0:8@16@24@32@?40
v48@0:8@"NSString"16@"NSString"24@"NSURL"32@?<v@?@"NSString">40
v40@0:8@"NSString"16@"NSURL"24@?<v@?@"NSString">32
@"CSEndpointerMetrics"
v40@0:8@16d24@32
v40@0:8@"<CSAttSiriNode>"16d24@"CSEndpointerMetrics"32
v32@0:8@"<CSAttSiriNode>"16d24
v32@0:8@"<CSEndpointAnalyzer>"16d24
v40@0:8@"<CSEndpointAnalyzer>"16d24@"CSEndpointerMetrics"32
v40@0:8@16@24d32
v48@0:8@16@24Q32Q40
v44@0:8@16Q24Q32B40
v40@0:8@"<CSAttSiriNode>"16@"OSDFeatures"24d32
v48@0:8@"<CSAttSiriNode>"16@"NSDate"24Q32Q40
v44@0:8@"<CSAttSiriNode>"16Q24Q32B40
v72@0:8q16q24d32@40d48@56q64
v32@0:8d16@?24
v72@0:8q16q24d32@"NSArray"40d48@"NSString"56q64
v24@0:8@?<v@?@"NSError"@"NSString">16
v32@0:8d16@?<v@?B@"NSArray">24
v24@0:8@?<v@?@"NSError"d>16
v24@0:8@?<v@?@"NSError"Q>16
v48@0:8Q16@24@32@40
v76@0:8q16q24d32@40d48@56q64B72
v32@0:8d16@24
@"CSConnectionListener"
@"CSEndpointerProxy"
@"CSEndpointLatencyInfo"
@"CSAttSiriCachedEndpointInfo"
@68@0:8@16f24{AudioStreamBasicDescription=dIIIIIIII}28
{AudioStreamBasicDescription=dIIIIIIII}16@0:8
v56@0:8{AudioStreamBasicDescription=dIIIIIIII}16
^{OpaqueExtAudioFile=}16@0:8
v24@0:8^{OpaqueExtAudioFile=}16
v32@0:8@"<CSAttSiriNode>"16@"NSDictionary"24
v32@0:8@"SSRSpeakerRecognitionController"16@"NSDictionary"24
@"SSRSpeakerRecognitionController"
@"SSRVoiceProfileManager"
@"SSRVoiceProfile"
@"<CSAudioFileWriter>"
v32@0:8@"MCProfileConnection"16@"NSDictionary"24
v56@0:8q16@24@32@40@?48
v44@0:8@16@24f32@?36
v56@0:8q16@"NSString"24@"NSString"32@"NSString"40@?<v@?B@"NSError"@"NSUUID">48
v44@0:8@"NSURL"16@"NSUUID"24f32@?<v@?B@"NSError"QQ>36
v32@0:8@"NSUUID"16@?<v@?B@"NSError">24
v24@0:8@?<v@?B@"NSError"@"NSUUID">16
@36@0:8@16@24B32
v28@0:8r^s16i24
@"<CSKeywordAnalyzerQuasarScoreDelegate>"
v28@0:8@"CSFirstUnlockMonitor"16B24
v32@0:8@16@"NSString"24
@64@0:8@16@24@32@40@48@56
@"CSVoiceTriggerAssetDownloadMonitor"
@"CSLanguageCodeUpdateMonitor"
@"CSFirstUnlockMonitor"
@"CSAssetManager"
@"CSTrialAssetManager"
@"CSAttSiriRequestContext"
I16@0:8
v20@0:8I16
B20@0:8B16
f20@0:8B16
@20@0:8B16
@"CSKeywordAnalyzerNDAPIResult"
@32@0:8@16Q24
@"CSVTSecondPassPhraseScore"
v64@0:8Q16Q24q32@40@48@?56
v72@0:8Q16Q24q32@40@48@56@?64
v56@0:8Q16Q24@32@40@?48
@"<CSVoiceTriggerAssetChangeDelegate>"
v32@0:8@16Q24
B24@0:8^@16
B48@0:8Q16Q24@32^@40
v24@0:8@"<CSAudioSessionProvidingDelegate>"16
B48@0:8Q16Q24@"NSString"32^@40
B32@0:8@16^@24
@40@0:8@16@24^@32
B40@0:8@16@24^@32
@32@0:8Q16Q24
@40@0:8Q16Q24Q32
v40@0:8Q16Q24@32
@32@0:8@16d24
v28@0:8B16Q20
B32@0:8@"CSAudioRecordContext"16^@24
@"CSAudioStream"40@0:8@"CSAudioStreamRequest"16@"NSString"24^@32
v40@0:8@"CSAudioStreamRequest"16@"NSString"24@?<v@?@"CSAudioStream"@"NSError">32
v40@0:8@"CSAudioStream"16@"CSAudioStream"24@?<v@?B@"NSError">32
B40@0:8@"CSAudioStream"16@"CSAudioStreamRequest"24^@32
v40@0:8@"CSAudioStream"16@"CSAudioStreamRequest"24@?<v@?B@"NSError">32
v40@0:8@"CSAudioStream"16@"CSAudioStartStreamOption"24@?<v@?B@"NSError">32
v40@0:8@"CSAudioStream"16@"CSAudioStopStreamOption"24@?<v@?B@"NSError">32
@"CSAudioChunk"32@0:8Q16Q24
@"CSAudioChunk"40@0:8Q16Q24Q32
@"CSAudioChunk"24@0:8Q16
v40@0:8Q16Q24@"NSURL"32
v32@0:8Q16@"NSURL"24
@"CSAudioStreamHolding"32@0:8@"NSString"16d24
v24@0:8@"CSAudioStreamHolding"16
@"CSAudioRecordDeviceInfo"16@0:8
@"CSAudioDeviceInfo"16@0:8
@"NSDictionary"16@0:8
B32@0:8@16q24
B24@0:8q16
v24@0:8@"<CSAudioAlertProvidingDelegate>"16
B32@0:8@"NSURL"16q24
f24@0:8Q16
Q24@0:8Q16
v32@0:8@"CSAudioRecordContext"16@?<v@?@"NSDictionary"@"NSDictionary">24
B40@0:8@16Q24^@32
@"<CSAudioSessionProvidingDelegate>"
@"<CSAudioStreamProvidingDelegate>"
@"<CSAudioAlertProvidingDelegate>"
@"<CSXPCClientDelegate>"
v32@0:8@16B24f28
v28@0:8@"CSOpportuneSpeakListener"16B24
v32@0:8@"CSOpportuneSpeakListener"16B24f28
@"CSOpportuneSpeakListener"
@"CSSiriAudioRoute"
@20@0:8I16
v52@0:8@16@24@32B40@44
v48@0:8@"CSOpportuneSpeakBehaviorMonitor"16@"CSAudioRecordContext"24@"NSString"32@"CSAudioStartStreamOption"40
v52@0:8@"CSOpportuneSpeakBehaviorMonitor"16@"CSAudioRecordContext"24@"NSString"32B40@"CSAudioStartStreamOption"44
v32@0:8@"CSOpportuneSpeakBehaviorMonitor"16@"CSAudioStopStreamOption"24
@"NSUUID"
v40@0:8@"CSVoiceTriggerAssetHandler"16@"NSString"24@"CSAsset"32
B32@0:8@16@24
B32@0:8@"NSXPCListener"16@"NSXPCConnection"24
@"NSXPCListener"
@"CSModelBenchmarker"
Q24@0:8@16
@28@0:8Q16B24
S28@0:8^f16i24
s16@0:8
v20@0:8s16
C16@0:8
v20@0:8C16
v40@0:8@"CSVoiceTriggerXPCConnection"16@"NSObject<OS_xpc_object>"24@"NSObject<OS_xpc_object>"32
Vv24@0:8@?16
Vv32@0:8@16@?24
Vv40@0:8@16q24@?32
Vv24@0:8@?<v@?@"NSString">16
Vv32@0:8@"NSString"16@?<v@?@"NSString">24
Vv40@0:8@"NSArray"16q24@?<v@?@"NSError">32
Vv24@0:8@?<v@?Q>16
Vv24@0:8@?<v@?>16
Vv24@0:8@?<v@?B>16
Vv24@0:8@?<v@?q>16
@"CSGibraltarVoiceTriggerHandler"
i16@0:8
@"CSAudioInjectionXPC"
@"NSData"
v24@0:8@"CSAudioServerCrashMonitor"16
v52@0:8@16@24Q32Q40i48
v52@0:8@"CSAudioPreprocessor"16@"NSData"24Q32Q40i48
@48@0:8Q16q24@32@40
B32@0:8Q16q24
@"<CSAudioProviderDelegate>"
@"CSAudioCircularBuffer"
@"CSAudioPreprocessor"
@"CSOSTransaction"
@"NSObject<OS_dispatch_group>"
@"NSObject<OS_dispatch_source>"
@"CSAudioTimeConverter"
@"CSAudioRecordDeviceIndicator"
@"CSMicUsageReporter"
@"CSADPPreventStandbyAssertion"
v36@0:8@16@24f32
v40@0:8@16@24Q32
@48@0:8@16@24@32^@40
@24@0:8d16
v28@0:8@"CSOpportuneSpeakEventMonitor"16B24
v36@0:8Q16Q24B32
v32@0:8Q16@"CSAudioRecordContext"24
v24@0:8@"CSAudioChunk"16
@"<CSEndpointAnalyzerDelegate>"16@0:8
v24@0:8@"<CSEndpointAnalyzerDelegate>"16
@"<CSEndpointAnalyzerImplDelegate>"16@0:8
v24@0:8@"<CSEndpointAnalyzerImplDelegate>"16
v24@0:8@"CSServerEndpointFeatures"16
v32@0:8@"NSString"16@"NSString"24
v32@0:8@"OSDFeatures"16d24
v32@0:8@"NSDate"16Q24
v28@0:8@"CSServerEndpointFeatures"16B24
@"<CSEndpointAnalyzerDelegate>"
@"<CSEndpointAnalyzerImplDelegate>"
B32@0:8^B16^Q24
@"<CSBiometricMatchMonitorDelegate>"
@28@0:8I16@20
@"CSNovDetector"
@"<CSKeywordAnalyzerNDAPIScoreDelegate>"
@48@0:8q16Q24Q32@40
@40@0:8Q16Q24@32
v36@0:8@16i24d28
v36@0:8@16i24@28
v28@0:8@"AVVoiceController"16B24
v36@0:8@"AVVoiceController"16B24@"NSError"28
v32@0:8@"AVVoiceController"16q24
v24@0:8@"AVVoiceController"16
v28@0:8@"AVVoiceController"16i24
v36@0:8@"AVVoiceController"16i24d28
v32@0:8@"AVVoiceController"16@"NSError"24
v36@0:8@"AVVoiceController"16i24@"NSError"28
v40@0:8@"AVVoiceController"16@"AVVCAlertInformation"24@"NSError"32
v32@0:8@"AVVoiceController"16@"NSDictionary"24
v32@0:8@"AVVoiceController"16@"AVVCAudioBuffer"24
v28@0:8B16@"NSArray"20
v44@0:8@"AVVoiceController"16Q24B32@"NSError"36
v40@0:8@"AVVoiceController"16Q24q32
v40@0:8@"AVVoiceController"16Q24@"AVVCAudioBuffer"32
v32@0:8@"AVVoiceController"16Q24
v72@0:8@16Q24@32@40Q48Q56B64I68
v72@0:8@"CSAudioDecoder"16Q24@"NSData"32@"NSData"40Q48Q56B64I68
v40@0:8@"CSAudioFileReader"16@"NSData"24Q32
v36@0:8@"CSAudioFileReader"16B24@"NSError"28
v32@0:8@"CSAudioFileReader"16q24
v32@0:8Q16@"NSError"24
v32@0:8@"NSData"16Q24
v24@0:8@"CSRemoteRecordClient"16
v24@0:8@"<CSAudioServerCrashEventProvidingDelegate>"16
v24@0:8@"<CSAudioSessionEventProvidingDelegate>"16
@32@0:8@16^@24
@24@0:8^@16
@32@0:8Q16@24
B24@0:8Q16
B40@0:8q16Q24^@32
B40@0:8Q16Q24^@32
v28@0:8Q16B24
v60@0:8@16Q24@32Q40Q48i56
@28@0:8@16I24
B32@0:8q16@24
v36@0:8B16Q20@28
v32@0:8q16Q24
@"AVVoiceController"
{AudioBufferList="mNumberBuffers"I"mBuffers"[1{AudioBuffer="mNumberChannels"I"mDataByteSize"I"mData"^v}]}
^{AudioBufferList=I[1{AudioBuffer=II^v}]}
@"CSRemoteRecordClient"
@"CSAudioFileReader"
@"<CSAudioServerCrashEventProvidingDelegate>"
@"<CSAudioSessionEventProvidingDelegate>"
v28@0:8B16@?20
v36@0:8@16d24f32
v20@0:8i16
@"<CSOpportuneSpeakListenerDelegate>"
@"CSSPGEndpointAnalyzer"
@"<CSAudioSessionProviding>"
@"CSPlainAudioFileWriter"
@24@0:8^{BTLocalDeviceImpl=}16
v40@0:8^{BTDeviceImpl=}16I24i28I32i36
v28@0:8^{BTSessionImpl=}16i24
v24@0:8^{BTSessionImpl=}16
v32@0:8^{BTLocalDeviceImpl=}16i24i28
^{BTSessionImpl=}16@0:8
^{BTLocalDeviceImpl=}16@0:8
v24@0:8^{BTLocalDeviceImpl=}16
^{BTSessionImpl=}
^{BTLocalDeviceImpl=}
v40@0:8@"CSActivationXPCConnection"16@"NSObject<OS_xpc_object>"24@"NSObject<OS_xpc_object>"32
v56@0:8@16Q24@32@40Q48
v44@0:8@"CSAudioInjectionEngine"16Q24B32@"NSError"36
v40@0:8@"CSAudioInjectionEngine"16Q24Q32
v56@0:8@"CSAudioInjectionEngine"16Q24@"NSData"32@"NSData"40Q48
v32@0:8@"CSAudioInjectionEngine"16@"CSAudioChunkForTV"24
@"CSSyncKeywordAnalyzerQuasar"
@"EARSyncPSRAudioProcessor"
@"OSDAnalyzer"
@"CSAudioInjectionEngine"
@56@0:8Q16@24@32@40Q48
v32@0:8Q16@?24
v32@0:8@"<CSAudioSessionInfoProviding>"16@"NSDictionary"24
@"<CSAudioSessionInfoProviding>"
v40@0:8Q16@24@?32
v40@0:8Q16@"NSDictionary"24@?<v@?@"NSError"@"CSSmartSiriVolumeEstimate">32
v48@0:8Q16@24Q32@?40
v48@0:8Q16@24@32@?40
v40@0:8@16Q24@?32
v40@0:8@16@?24@?32
@40@0:8@16Q24@32
v32@0:8^@16Q24
v24@0:8@"CSAssetManager"16
v32@0:8@"OSDAnalyzer"16@"OSDFeatures"24
v32@0:8@"OSDAnalyzer"16d24
v72@0:8d16Q24@32d40Q48d56@64
@"OSDFeatures"
@"_EAREndpointer"
@"CSServerEndpointFeatures"
@"NSDate"
@"NSMapTable"
@"CSActivationEvent"
v32@0:8@"CSMediaPlayingMonitor"16q24
v28@0:8@"CSSiriEnabledMonitor"16B24
v52@0:8@16@24B32@36@44
v44@0:8@16B24@28@36
v36@0:8@16@24B32
v40@0:8@"CSSiriClientBehaviorMonitor"16@"CSAudioRecordContext"24@"CSAudioStartStreamOption"32
v52@0:8@"CSSiriClientBehaviorMonitor"16@"CSAudioRecordContext"24B32@"CSAudioStartStreamOption"36@"NSString"44
v40@0:8@"CSSiriClientBehaviorMonitor"16@"CSAudioStopStreamOption"24Q32
v40@0:8@"CSSiriClientBehaviorMonitor"16@"CSAudioStopStreamOption"24@"NSString"32
v44@0:8@"CSSiriClientBehaviorMonitor"16B24@"NSString"28@"CSAudioRecordContext"36
v36@0:8@"CSSiriClientBehaviorMonitor"16@"CSAudioStream"24B32
v24@0:8@"CSSiriClientBehaviorMonitor"16
@28@0:8f16@20
@40@0:8Q16@24Q32
@28@0:8f16@"CSAsset"20
@"CSSmartSiriVolumeEstimate"40@0:8Q16@"NSNumber"24Q32
v28@0:8I16q20
v52@0:8@16q24B32Q36Q44
f24@0:8q16
f24@0:8f16f20
f20@0:8f16
f36@0:8f16f20f24f28f32
f44@0:8f16f20f24f28f32f36f40
f28@0:8f16f20f24
^f24@0:8@16
{unique_ptr<SmartSiriVolume, std::default_delete<SmartSiriVolume>>="__ptr_"{__compressed_pair<SmartSiriVolume *, std::default_delete<SmartSiriVolume>>="__value_"^{SmartSiriVolume}}}
{vector<float, std::allocator<float>>="__begin_"^f"__end_"^f"__end_cap_"{__compressed_pair<float *, std::allocator<float>>="__value_"^f}}
@"NSUserDefaults"
@"CSSmartSiriVolumeEnablePolicy"
@"CSAudioInjectionDevice"
v48@0:8@16@24@32^v40
B24@0:8d16
@"<CSAudioFileReaderDelegate>"
v32@0:8@"<CSEndpointAnalyzerImpl>"16d24
v40@0:8@"<CSEndpointAnalyzerImpl>"16Q24Q32
@"<CSEndpointAnalyzerImpl>"
B32@0:8Q16Q24
@32@0:8d16Q24
q24@0:8@16
d24@0:8[80s]16
v32@0:8@"CSSelfTriggerDetector"16@"NSDictionary"24
@"<CSMyriadSelfTriggerCoordinatorDelegate>"
B44@0:8@16f24@?28@?36
@"<CSAudioInjectionEngineDelegate>"
@"CSKeywordAnalyzerNDEAPI"
@"CSSmartSiriVolumeManager"
v48@0:8@16@24^@32^@40
@44@0:8@16B24@28@36
@52@0:8@16B24@28@36@44
v40@0:8q16Q24@32
v32@0:8@"CoreEmbeddedSpeechRecognizer"16@"CESRModelProperties"24
v32@0:8@"CoreEmbeddedSpeechRecognizer"16@"NSArray"24
v32@0:8@"CoreEmbeddedSpeechRecognizer"16d24
v32@0:8@"CoreEmbeddedSpeechRecognizer"16@"AFSpeechRecognition"24
v32@0:8@"CoreEmbeddedSpeechRecognizer"16@"AFSpeechPackage"24
v40@0:8@"CoreEmbeddedSpeechRecognizer"16@"NSDictionary"24@"NSError"32
v72@0:8@"CoreEmbeddedSpeechRecognizer"16q24q32d40@"NSArray"48d56q64
Vv32@0:8@16Q24
Vv24@0:8@16
Vv24@0:8Q16
Vv32@0:8@"NSString"16Q24
Vv24@0:8@"LBLocalSpeechRecognitionSettings"16
Vv24@0:8@"NSString"16
v36@0:8@16Q24B32
v40@0:8d16@24Q32
v52@0:8@16Q24d32B40@44
v48@0:8@16@24Q32d40
@"CSAttSiriEndpointerNode"
@"CSAttSiriUresNode"
@"CoreEmbeddedSpeechRecognizer"
@"CSAudioProcessWaitingBuffer"
@"LBLocalSpeechRecognitionSettings"
@"CSEndpointDelayReporter"
@"CSAudioStreamRequest"
@"CSAudioStartStreamOption"
v40@0:8@"CSVoiceTriggerAwareZeroFilter"16@"NSData"24Q32
v40@0:8@"CSBeepCanceller"16@"NSData"24Q32
@24@0:8f16i20
v32@0:8f16B20@24
B20@0:8f16
@"<CSAudioPreprocessorDelegate>"
@"CSAudioSampleRateConverter"
@"CSVoiceTriggerAwareZeroFilter"
@"CSBeepCanceller"
@"CSAudioZeroCounter"
v52@0:8@16B24@28@36@44
v48@0:8@16Q24@32@40
v44@0:8B16@20@28@36
v32@0:8i16@20B28
^{__sFILE=*iiss{__sbuf=*i}i^v^?^?^?^?{__sbuf=*i}^{__sFILEX}i[3C][1C]{__sbuf=*i}iq}16@0:8
v24@0:8^{__sFILE=*iiss{__sbuf=*i}i^v^?^?^?^?{__sbuf=*i}^{__sFILEX}i[3C][1C]{__sbuf=*i}iq}16
^{__sFILE=*iiss{__sbuf=*i}i^v^?^?^?^?{__sbuf=*i}^{__sFILEX}i[3C][1C]{__sbuf=*i}iq}
v52@0:8@16@24f32Q36Q44
v52@0:8@"CSAudioConverter"16@"NSArray"24f32Q36Q44
@"CSAudioConverter"
v40@0:8@16B24f28@32
v40@0:8@"<CSAttSiriNode>"16B24f28@"NSString"32
v32@0:8@"SLProgressiveCheckerAnalyzer"16@"SLProgressiveCheckerResult"24
v28@0:8f16Q20
@"SLProgressiveCheckerAnalyzer"
@"SLProgressiveCheckerResult"
v48@0:8@16@24@32Q40
v64@0:8@16@24@32B40Q44@52B60
@"<CSADCompanionServiceProvider>"
v80@0:8Q16Q24q32@40@48@56@64@?72
v64@0:8Q16Q24@32@40@48@?56
v32@0:8@"NSString"16@?<v@?@"NSString"@"NSString"@"NSError">24
v80@0:8Q16Q24q32@"NSString"40@"NSUUID"48@"NSArray"56@"NSArray"64@?<v@?@"CSVoiceTriggerRTModel"@"CSVoiceTriggerRTModel"@"NSError">72
v64@0:8Q16Q24@"NSString"32@"NSArray"40@"NSArray"48@?<v@?@"CSVoiceTriggerRTModel"@"CSVoiceTriggerRTModel"@"NSError">56
v40@0:8@"NSArray"16@"NSString"24@?<v@?@"NSString"@"NSError">32
v32@0:8@"<CSAttSiriNode>"16@"CSAttSiriAttendingTriggerEventInfo"24
v24@0:8@"CSAttSiriAttendingTriggerEventInfo"16
v24@0:8@"CSAttSiriRequestContext"16
@112@0:8@16@24@32@40@48@56B64@68@76@84@92B100B104B108
@"CSAttSiriOSDNode"
@"CSAttSiriAsrNode"
@"CSAttSiriAudioSrcNode"
@"CSAttSiriSSRNode"
@"CSSiriClientBehaviorMonitor"
@"CSSiriEnabledMonitor"
@"CSAttSiriFlexKwdNode"
@"CSAttSiriAFTMNode"
@"CSAttSiriNLDAClassifierNode"
v32@0:8@"CSAssetController"16Q24
v48@0:8Q16Q24@32@?40
@"CSPolicy"
@"CSAssetDownloadingOption"
@"<CSVoiceTriggerAwareZeroFilterDelegate>"
@"CSAudioZeroFilter"
@20@0:8f16
@"<CSSPGEndpointAnalyzerDelegate>"
@"<CSAudioMetricProviding>"
@"<CSActivateXPCConnectionDelegate>"
v36@0:8@16f24@28
v36@0:8@"<CSAttSiriNode>"16f24@"NSDictionary"28
@"SLBertClassifier"
@"CSKeywordAnalyzerNDAPI"
@40@0:8@16@24Q32
@36@0:8@16f24Q28
@52@0:8Q16@24@32f40Q44
@48@0:8Q16@24@32Q40
d20@0:8f16
@40@0:8d16d24d32
@48@0:8q16@24@32@40
B84@0:8@16f24{AudioStreamBasicDescription=dIIIIIIII}28@?68@?76
@64@0:8d16Q24@32q40@48@56
v32@0:8@"CSAlarmMonitor"16q24
v32@0:8@"CSTimerMonitor"16q24
v28@0:8@16f24
v28@0:8@"CSVolumeMonitor"16f24
v28@0:8@"CSAutomaticVolumeEnabledMonitor"16B24
@"<CSConnectionServiceDelegate>"
@"<CSSmartSiriVolumeProcessor>"
v28@0:8@"<CSAttSiriNode>"16f24
v32@0:8@"<CSAttSiriNode>"16Q24
v48@0:8@16Q24@32@?40
@"SLUresMitigator"
@"SLUresMitigatorIpFeats"
v40@0:8@"CSActivationEventNotificationHandler"16@"CSActivationEvent"24@?<v@?B@"NSError">32
v32@0:8@"CSAudioProvider"16Q24
@"CSFallbackAudioSessionReleaseProvider"
@"<CSSpeechManagerDelegate>"
@"CSOpportuneSpeakListnerTestService"
@"CSPostBuildInstallService"
v64@0:8@16@24@32@40@48@?56
@32@0:8@16f24I28
v28@0:8@16I24
B32@0:8@16Q24
@"<CSXPCConnectionDelegate>"
@"CSAudioSessionProvidingProxy"
@"CSFallbackAudioSessionReleaseProvidingProxy"
@"CSAudioSessionInfoProvidingProxy"
@"CSAudioStreamProvidingProxy"
@"CSAudioAlertProvidingProxy"
@"CSAudioMeterProvidingProxy"
@"CSAudioMetricProvidingProxy"
v72@0:8d16d24Q32@40q48@56@64
v32@0:8d16@"CSEndpointerMetrics"24
v72@0:8d16d24Q32@"NSArray"40q48@"NSDictionary"56@"NSDictionary"64
Vv40@0:8@16@24@32
Vv32@0:8@16@24
Vv48@0:8@16Q24@32d40
Vv48@0:8@16Q24B32B36@40
Vv48@0:8@16@24q32@40
Vv40@0:8@"NSString"16@"NSString"24@"NSArray"32
Vv32@0:8@"NSString"16@"AFSpeechPackage"24
Vv48@0:8@"NSString"16Q24@"AFSpeechPackage"32d40
Vv48@0:8@"NSString"16Q24B32B36@"NSArray"40
Vv48@0:8@"NSDictionary"16@"NSString"24q32@"NSError"40
@36@0:8@16B24B28B32
@"CSXPCListener"
@"CSActivationXPCListener"
@"CSVoiceIdXPCListener"
@"CSVoiceTriggerXPCListener"
@"CSAudioInjectionXPCListener"
@"CSAttSiriConnectionManager"
@"CSCoreSpeechServicesListener"
@"CSSpeechModelTrainingXPCManager"
@"CSBenchmarkXPCListener"
v40@0:8Q16Q24Q32
B32@0:8@16@?24
B32@0:8d16^@24
@"<CSRemoteRecordClientDelegate>"
v24@0:8@?<v@?@>16
@"NSXPCInterface"
v24@0:8@"<CSAudioSessionProviding>"16
v32@0:8@"<CSAudioSessionProviding>"16@"NSDictionary"24
v28@0:8@"<CSAudioSessionProviding>"16B24
@"CSManualDuckingHandler"
v40@0:8@"CSCommandControlBehaviorMonitor"16@"CSAudioRecordContext"24@"CSAudioStartStreamOption"32
v44@0:8@"CSCommandControlBehaviorMonitor"16@"CSAudioRecordContext"24B32@"CSAudioStartStreamOption"36
v32@0:8@"CSCommandControlBehaviorMonitor"16@"CSAudioStopStreamOption"24
v40@0:8@"<CSAudioAlertProviding>"16q24@"NSError"32
v36@0:8B16@20@28
@"<CSAudioAlertProviding>"
@"<CSVoiceTriggerXPCConnectionDelegate>"
v24@0:8@"CSFlexKeywordResult"16
@"CSFlexKeywordSpotter"
I24@0:8Q16
@"CSAudioRecordDeviceInfo"
v24@0:8f16f20
v28@0:8I16f20f24
@32@0:8q16Q24
@24@0:8^{AudioBufferList=I[1{AudioBuffer=II^v}]}16
^{OpaqueAudioConverter=}16@0:8
v24@0:8^{OpaqueAudioConverter=}16
^{AudioBufferList=I[1{AudioBuffer=II^v}]}16@0:8
v24@0:8^{AudioBufferList=I[1{AudioBuffer=II^v}]}16
@"CSAudioInjectionFileOption"
v44@0:8@16B24Q28Q36
@"<CSAudioConverterDelegate>"
@44@0:8@16@24B32Q36
@"<CSAudioMeterProviding>"
%@ Interrupted
%@ Invalidated
Dealloc-ing
personalizedLMPath=%@ fidesPersonalizedLMPath=%@
Client is 24-hour job
Client is DictationPersonalizationFidesPlugin
Client is PersonalizedLmFidesPlugin
Received an error while accessing %@ service: %@
Invalidating
%s Transcriber trigger token list: %{public}@
%s Initializing Quasar with config: %{public}@
%s Failed initialization in _EARSyncSpeechRecognizer initWithConfiguration
%s ERR: Exception initializing _EARSyncSpeechRecognizer: %{public}s
%s Speech model loading took %{public}.3fms
%s endAudio failed
%s processAudioChunk failed
%s MpVT: phId=%{public}@, tok=%{public}@
%s Res-%lu: 
%s tok=%@
%s Cannot handle unexpected message type : %lld
%s CSFallbackAudioSessionReleaseProvider is nil from CSSpeechManager
%s ERR: topScoringUser is nil from %{public}@
%s ERR: invalid arguments passed %{public}@ %{public}@
%s ERR: Incorrect category %{public}d passed
%s Start Recording Host Time = %{public}llu
%s disconnect activationXPCClient
%s cannot handle event : event = %{public}p
%s ignore unknown types of message 
%s cannot handle error : error = %{public}p
%s Listener connection disconnected
%s connection error: %{public}s
%s Cannot create SampleRateConverter using AudioConverterNew : %{public}d
%s Cannot set Quality property to audioConverter
%s Cannot set Complexity property to audioConverter
%s Audio resampling done : %lu
%s AudioConverter is sad: 0x%{public}xd
%s Start monitoring : SpeakerRecognition Asset meta update
%s Stop monitoring : SpeakerRecognition Asset meta update
%s New Speaker Recognition asset metadata is available
%s Celestial is not available on this platform.
%s notification = %{public}@
%s Cannot deactivateAudioSession since audio recorder doesn't exist
%s Cannot deactivateAudioSession with %{public}@
%s Start monitoring : SpeakerRecognition Asset Download
%s Stop monitoring : SpeakerRecognition Assets Download
%s New SpeakerRecognition Assets is now installed
%s ERR: Delegate received for invalid Trial assetType:%lu
%s ::: %{public}s enable: %{public}d reason: %{public}@ timestamp : %{public}lf
%s Ignoring request to enable/disable voice trigger with nil reason.
%s ::: Asserting that VoiceTrigger should be %{public}@ with reason: %{public}@. Existing assertions (%{public}lu): %{public}@; times: %{public}@ vs %{public}f
%s Ignoring request to enable/disable voice trigger - time order violation.
%s ::: Ignore request as phraseSpotter already %{public}@
%s ::: Asserting that PhraseSpotter should be %{public}@, timeout: %{public}f
%s ::: Timeout!! PhraseSpotter should be NOT bypassed
%s ::: Ignore request as raiseToSpeak already %{public}@
%s ::: Asserting that raiseToSpeak should be %{public}@, timeout: %{public}f
%s ::: Timeout!! raiseToSpeak should be NOT bypassed
%s HandleDisconnect
%s token:%d
%s fromState:%llu, toState:%llu
%s SiriState - isActiveSession:%d
%s SiriState - isActiveRequest:%d
%s SiriState - isListening:%d
%s SiriState - isSpeaking:%d
%s tts Finished:%u
%s Audio steam %{public}@ is still streaming when we get new streamProvider
%s CSAudioStreamProvidingProxy has received xpc disconnection
%s Trying to stop audio stream on CSAudioStreamProvidingProxy
%s Unknown body type : %{public}lld
%s Cannot handle setCurrentContext throught XPC : audioStreamProviding is nil
%s Cannot handle setCurrentContext throught XPC : given context is nil
%s Cannot handle AudioStreamRequest throught XPC : given audioStreamRequest is nil
%s Cannot handle AudioStreamRequest throught XPC : audioStreamProviding is nil
%s Getting audio stream has failed : %{public}@
%s Cannot handle PrepareRequest throught XPC : audioStreamProviding is nil
%s Given audioStreamRequest is nil, use default audioStreamRequest
%s Cannot handle startAudioStream : given audio stream option is nil
%s Cannot handle startAudioStream : audioStream is nil
%s Cannot handle startAudioStream : audioStreamProviding is nil
%s Cannot handle stopAudioStream : audioStreamProviding is nil
%s Cannot handle stopAudioStream : audioStream is nil
%s Fail to parse recordContext
%s Cannot handle IsRecording : audioStreamProviding is nil
%s Cannot handle RecordRoute : audioStreamProviding is nil
%s Cannot handle RecordDeviceInfo : audioStreamProviding is nil
%s Cannot handle AudioDeviceInfo : audioStreamProviding is nil
%s Cannot handle RecordSettings : audioStreamProviding is nil
%s Cannot handle IsNarrowband : audioStreamProviding is nil
%s Cannot handle PlaybackRoute : audioStreamProviding is nil
%s CSAudioStreamProvidingProxy
%s setting allow mixable audio while recording to %{public}@
%s Failed to setAllowMixableAudioWhileRecording : %{public}@
%s Unable to get VT asset for FlexKwd Spotter
%s configPath=%@
%s _thresholdsMap=%@
%s startProcessingSampleCount=%{public}ld, recognizer: %{public}@
%s didFinishRecognition: err=%@
%s FinalResults: %@
%s %@
%s ===PWinningTok=%@, bestScore=%f====
%s Unexpected!
%s Json file doesnt exist at: %{public}@
%s Could not read Json file at: %{public}@, err: %{public}@
%s Failed to parse json at: %{public}@, err: %{public}@
%s Not implemented
%s audioStreamProvider is nil, fetch audioProvider from context
%s attSiriAudioStreamProvider is nil!
%s Failed to start audio data source: %{public}@
%s Unsupported receiver: %@
%s CSAttSiriAttendingAudioSrcNode deallocated
%s Failure disposing audio file %{public}d
%s Audio file already configured, closing first
%s Creating audio file at URL %{public}@
%s Failed creating audio file at url %{public}@ %{public}d
%s Error setting input format %{public}d
%s No audio file to append data
%s Failed writing audio file %{public}d
%s Closing file at URL %{public}@, audio size: %{public}u
%s Couldn't create CoreSpeech log directory at path %{public}@ %{public}@
%s Session Query Failed : %{public}@
%s Mediaserverd/bridgeaudiod crashed
%s Mediaserverd/bridgeaudiod recovered from crash
%s Start monitoring : AudioSessionInterruption
%s Start monitoring : AudioSessionRouteChangeNotification
%s Stop monitoring AudioSession activities
%s Clearing pending homekit accessory voice trigger %{private}@
%s Handling Pending Remora VoiceTrigger Event
%s Time since last pending remora voice trigger %f. Ignoring.
%s Clearing pending built-in voice trigger %{private}@
%s Handling Pending BuiltInVoiceTrigger Event
%s Time since last pending builtin voice trigger %f. Ignoring.
%s client: %lu, deviceId: %{private}@
%s AttSiri logging not enabled
%s Couldn't create Ures slogging directory at path %{public}@ %{public}@
%s Failed to serialize data with err: %{public}@
%s %{public}.2f ms after vtEnd
%s SmartSiriVolume cannot be resumed since Siri is speaking
%s _shouldCleanupVoiceProfile: %lu
%s SSR Assets is nil for %{public}@ - Bailing out
%s Asset Vers (Speaker Recognition): %{public}@
%s Failed to get asset with %{public}@
%s Asset Vers (VT): %{public}@
%s Voice Profiles not present for %{public}@ - Bailing out
%s Setting up SSR controller with {%{public}@, %{public}@, %{public}ldusers, %{public}fsecs}
%s ERR: Failed to create SSR context with error %@
%s ERR: Failed to create SSR controller with error %@
%s Initialized SSRNode with assets %{public}@
%s XPC connection with client established
%s Received SSR asset download notification, updated asset cache to %{public}@
%s UserClassification: %{public}@ UserIdentified: %{public}@ Scores: %{public}@
%s _speakerRecognitionScores:%@
%s ERR: Discarded reporting ScoreCard!!
%s _speakerRecognitionScores is nil!
%s spkrRecognizer is nil!
%s speakerInfo is nil!
%s ERR: Discarded reporting final ScoreCard!!
%s SpeakerIdInfo from incorrect SpeakerRecognizer: expected: %{public}@, spkrRecognizer: %{public}@
%s ERR: Failed to get classified user from %{public}@
%s mappedSpeakerIdInfo:%@
%s Voice Profile for profileID %@ not found
%s ERR: Failed to init retrainCtxt for profileID %{public}@ with error %{public}@
%s ERR: Failed to add profileID %{public}@ with error %{public}@
%s trigger VoiceProfileCleanup
%s ERR: Failed VoiceProfile Cleanup with error %{public}@
%s Start monitoring : Setting preference change
%s Stop monitoring : Setting preference change
%s Siri restricted on lock screen : %{public}@
%s Registering for post build install/first unlock activity - %s
%s Received event for XPC activity: %@ in state: %ld
%s XPC activity: %@ deferred: %@ firstUnlock: %@
%s Registered XPC activity got triggered...
%s VT is disabled, skipping post build activity !
%s Post build install/first unlock tasks got completed with error - %{public}@
%s Registered XPC activity complete. State: %@.
%s runRecognition failed
%s recognizeWavData failed
%s Partial result confidence: %{public}f
%s CTC: Adding tok=%{public}@
%s CTC: Ignoring tok=%{public}@
%s ERROR: %{public}s
%s CTC: Final-tok: %@(%f):%@
%s Final result confidence: %{public}f
%s EAR Token[%{public}lu]: %s (%{public}f)
%s CSVoiceTriggerAsset (%{public}@) found: %{public}@
%s Cannot get a VoiceTrigger mobile asset : %{public}@
%s Trial assets not available, fallback to MA assets
%s Asset Query failed : %{public}@
%s cached asset:%{public}@, new asset:%{public}@
%s New asset is same as cached asset, ignore notification
%s New asset is different from cached one. Updating cached asset
%s new VoiceTrigger asset downloaded
%s Language Code Changed : %{public}@
%s First unlock notification received : %{public}d
%s Ignore Trial asset update for type: %lu
%s MpVT: supportedPhrasesInfo: %@
%s MpVT: ctcResults=%@
%s OldTrigPh: %@, NewTrigPh: %@
%s getCoreSpeechXPCConnection Invalidated
%s making connection to corespeechd with (%{public}d)
%s Asking VoiceTrigger locale to corespeechd
%s Current VoiceTrigger Locale = %{public}@
%s Cannot get Current VoiceTrigger Locale, falling back to en-US : %{public}@
%s Asking current VoiceTrigger aset for %{public}d.%{public}d
%s Asking keyword language given Jarvis language list %{public}@, jarvis-selected language: %{public}@
%s CSCoreSpeechServices Invalidated
%s Request updated SAT audio succeed.
%s Request updated SAT audio failed.
%s Start monitoring : Mediaserverd crash / recover event
%s Initializing new xpcConnection
%s Sending XPCClientType : %{public}d
%s Prepare Audio Provider with Context : %{public}@
%s Failed to get reply result correctly
%s Received alertStartTime = %{public}llu
%s Received peakPower = %{public}f
%s Received averagePower = %{public}f
%s Sending audioMetric request
%s Failed to get audioMetric reply
%s audioMetric : %{public}@
%s Received invalid audioMetric
%s Error creating message
%s audioStreamWithRequest for stream %{public}@
%s xpcConnection not exist
%s Invalid message: stream is nil or request is nil
%s PrepareAudioStream %{public}@
%s Sending AcousticSLResult request
%s Failed to get AcousticSLResult reply
%s Received AcousticSLResult %{public}@
%s Failed to parse AcousticSLResult from raw data
%s Message not valid
%s Sending VoiceTriggerInfo request
%s Failed to get VoiceTriggerInfo request
%s Received VoiceTriggerInfo %{public}@
%s Failed to parse VoiceTriggerInfo from raw data
%s Received rtsTriggerInfo %{public}@
%s Failed to parse rtsTriggerInfo from raw data
%s NO reply!!!
%s No message!!
%s No reply for hostTimeFromSampleCount request with sampleCount %{public}llu
%s xpcConnection not existing
%s No message for hostTimeFromSampleCount request with sampleCount %{public}llu
%s No reply for sampleCountFromHostTime request with hostTime %{public}llu
%s No message for sampleCountFromHostTime request with hostTime %{public}llu
%s Cannot handle nil message
%s Unexpected message type : %{public}lld
%s AlertProvidingDelegate messageType : %{public}lld
%s Unexpected type : %{public}lld
%s SessionProvidingDelegate messageType : %{public}lld
%s context : %{public}@
%s invalid context
%s SessionInfoProvidingDelegate messageType : %{public}lld
%s Received notificationInfo %{public}@
%s Failed to parse notificationInfo from raw data
%s startListenWithOption : %{public}d, %{public}@
%s stopListenWithCompletion : %{public}d, %{public}@
%s hasRemoteVADAvailable : %d
%s hasVADAvailable : %d
%s didStopUnexpectly : %d
%s MobileTimer is not available on this platform.
%s Input route changed
%s Output route changed
%s Failed getting audio property %{public}.4s %{public}d
%s Failed getting audio property size %{public}.4s %d{public}
%s Failed registering for property listener %{public}.4s %{public}d
%s Fetching CommandControl Listening State: %d
%s Updated cache with new Trial asset %@
%s Cache already contains Trial asset, ignore MA asset update
%s Updated cache with new MA asset %@
%s Ignore Trial asset update even for mitigation
%s PhraseSpotter enabled = %{public}@
%s PhraseSpotter is already %{public}@, received duplicated notification!
%s Send a In-Ear Myriad notification
%s CSBenchmarkXPCListener start listening
%s we got unknown types of XPC connection request
%s CSBenchmarkXPCListener here
%s Start monitoring : Siri language code
%s Stop monitoring : Siri language code
%s Siri language changed to : %{public}@
%s Ignore notifying change of language code, since it is nil
%s CSVoiceTriggerXPCListener start listening
%s Received new remote control connection request
%s Connection request is nil
%s Error = %{public}s
%s Getting new client connection : %{public}p
%s Client connection disconnected, removing %{public}p from client connection pool
%s Register CoreSpeech Services
%s Received accept request : %{public}@
%s Connectin request %{public}@ rejected due to missing entitlement
%s get test response. return string Test
%s Setting Delay Interstitial Sound
%s Get Trigger Count
%s Clear Trigger Count
%s Get FirstPass running mode
%s Dealloc audioStreamHolding : %{public}@
%s _requestMHUUID: %@, _turnIdentifier: %@
%s _userSpeakingStartedTimeInMs %{public}f, _userSpeakingEndedTimeInMs: %{public}f, _userSpeakingStartedHostTime: %{public}llu, _userSpeakingEndedHostTime: %{public}llu, _stopRecordingHostTime: %{public}llu, _endpointBufferHostTime: %{public}llu
%s Cannot access to %{public}@ %{public}@ using default value=%{public}@
%s CSAudioInjectionXPCListener start listening
%s CSAudioProvider[%{public}@]:Create circular buffer
%s CSAudioProvider is deallocated
%s CSAudioProvider[%{public}@]:StreamState changed from : %{public}@ to : %{public}@
%s CSAudioProvider[%{public}@]:Setting audioRecorder : %{public}p
%s Reset recordDeviceIndicator as we have new audioRecorder
%s CSAudioProvider[%{public}@]:setCurrentContext : %{public}@
%s CSAudioProvider[%{public}@]:Cannot change context since audio recorder is currently recording
%s CSAudioProvider[%{public}@]:audioStreamWithRequest for stream <%{public}@>
%s Failed to _prepareAudioStreamSync : %{public}@
%s Attached stream %{public}@ as tandem to master stream %{public}@ %{public}@, error : %{public}@
%s PrimaryStream is already tandem of stream %{public}@, can't add mutual tandem relation here!
%s Invalid input streams
%s CSAudioProvider[%{public}@]:Prepare audio stream reuqested while state is %{public}@
%s CSAudioProvider[%{public}@]:Cannot prepare, audio system is recovering
%s CSAudioProvider[%{public}@]:Asking AudioRecorder prepareAudioStreamRecord
%s CSAudioProvider[%{public}@]:prepareAudioStreamRecord failed : %{public}@
%s CSAudioProvider[%{public}@]:Tear down circular buffer
%s CSAudioProvider[%{public}@]:startAudioStream with stream : %{public}@ with stream state : %{public}@, option : %{public}@, streamId : %{public}llu
%s CSAudioProvider[%{public}@]:state was %{public}@, prepareAudioStream first
%s CSAudioProvider[%{public}@]:prepareAudioStreamSync with stream : %{public}@ with stream state : %{public}@, request : %{public}@
%s CSAudioProvider[%{public}@]:prepareAudioStream with stream : %{public}@ with stream state : %{public}@
%s CSAudioProvider[%{public}@]:Cannot handle start audio stream on : %{public}@
%s CSAudioProvider[%{public}@]:Cannot startAudioStream, audio system is recovering
%s CSAudioProvider[%{public}@]:Requested startHostTime = %{public}llu, _clientStartSampleCount = %{public}tu
%s CSAudioProvider[%{public}@]:%{public}@ is requesting earlier audio than asked, we can't deliver earlier audio
%s CSAudioProvider[%{public}@]:Set circularBufferStartHostTime = %{public}llu, circularBufferStartSampleCount = %{public}lu
%s CSAudioProvider[%{public}@]:Entering dispatch group for recordingWillStartGroup
%s CSAudioProvider[%{public}@]:Failed to fetch historical audio since _clientStartSampleCount is newer than audioBuffer sample count(%{public}llu)
%s Start deliver historical audio buffer immediately
%s CSAudioProvider[%{public}@]:Leaving dispatch group for recordingWillStartGroup
%s CSAudioProvider[%{public}@]:Received didStartRecording while %{public}@
%s CSAudioProvider[%{public}@]:Received didStopRecording reason : %{public}d, streamState : %{public}@
%s Calling unexpected didStop for all weak streams
%s CSAudioProvider[%{public}@]:Received didStopRecording while %{public}@
%s CSAudioProvider[%{public}@]:Waiting for recordingWillStartGroup before scheduling stopAudioStream
%s CSAudioProvider[%{public}@]:Scheduled stopAudioStream after waiting for recordingWillStartGroup - stopAudioStream %{public}@ with streamState : %{public}@
%s CSAudioProvider[%{public}@]:requested stop audio stream while stoppingWithScheduledStart, take out audio stream from schedule
%s CSAudioProvider[%{public}@]:Stream %{public}@ is not streaming on stream state : %{public}@, ignore the stopAudioStream request
%s CSAudioProvider[%{public}@]:Cannot handle stop audio stream on : %{public}@
%s CSAudioProvider[%{public}@]:requested stop audio stream while stopping, adding audio stream into stop pending
%s CSAudioProvider[%{public}@]:Stop all recordings, moving stream state to %{public}@
%s CSAudioProvider[%{public}@]:Failed to stop audioStream : %{public}@
%s Saving circular buffer from %{public}lu to %{public}lu
%s CSAudioProvider[%{public}@]:%{public}@ ask for audio hold stream for %{public}f
%s CSAudioProvider[%{public}@]:Timeout for %{public}@ has fired
%s CSAudioProvider[%{public}@]:Removing %{public}@ from stream holders
%s CSAudioProvider[%{public}@]:%{public}@ stream holder was already removed from stream holders
%s CSAudioProvider[%{public}@]:%{public}@ ask for cancel hold stream
%s Failed to prewarmAudioSessionWithError : %{public}@
%s Failed to activateAudioSessionWithReason: %{public}@
%s CSAudioProvider[%{public}@]:Activating Audio Session under : %{public}@
%s Failed to activateAudioSession : %{public}@
%s Failed to deactivate audio session : %{public}@
%s CSAudioProvider[%{public}@]:Deactivating Audio Session under : %{public}@
%s Failed to deactivateAudioSession : %{public}@
%s CSAudioProvider[%{public}@]:AVVC is recovering, ignore command...
%s Not handled by this function
%s Fetching voiceTriggerInfo from audioRecorder
%s CSAudioProvider[%{public}@]:Cannot stopRecording as there are %{public}tu streamHolders
%s CSAudioProvider[%{public}@]:Shouldn't stop AVVC recording as there are %{public}tu streams
%s CSAudioProvider[%{public}@]:
%s CSAudioProvider[%{public}@]:Buffer underrun!!!!, lastForwardedSampleTime:%{public}lu, oldestSampleTimeInBuffer:%{public}lu, stream:%{public}@
%s CSAudioProvider[%{public}@]:Ignore forwarding stream %{public}@                                        the audio packets until sampleCount == %{public}lu (theMostRecentSampleCount:%{public}lu)
%s CSAudioProvider[%{public}@]:Buffer overrun!!! lastForwardedSampleTime:%{public}lu,                                    theMostRecentSampleCount:%{public}lu, stream:%{public}@
%s Forward %d samples from historical audio buffer
%s ScheduleAlertFinishTimeout : %{public}@
%s ScheduleAlertFinishTimeout will be ignored : %{public}@, %{public}@
%s Received finishStartAlertPlaybackAt:%{public}llu streamState : %{public}@
%s CSAudioProvider[%{public}@]:Requested alertFinishHostTime = %{public}llu, _clientStartSampleCount = %{public}tu, circularBufferSampleCount = %{public}tu
%s Audio Streaming already stopped
%s Will invalidate current builtIn audio stream : %{public}@
%s failed to stopAudioStream : %{public}@
%s CSAudioProvider[%{public}@]:Audio Recorder Disconnected
%s CSAudioProvider[%{public}@]:Mediaserverd/bridgeaudiod crashed
%s CSAudioProvider[%{public}@]:Mediaserverd/bridgeaudiod recovered from crash
%s CSAudioProvider[%{public}@]:AudioRecorder will be destroyed
%s CSAudioProvider[%{public}@]:recordingTransaction already released
%s CSAudioProvider[%{public}@]:Release recording transaction at streamState : %{public}@
%s Audio Packet Delivery WatchDog fired, trying to recover
%s Schedule didStart WDT %{public}@ for %{public}lf seconds
%s startRecordingWatchDogDidFire : %{public}@, currentToken : %{public}@
%s startRecordingWatchDogToken doesn't match. Ignore this WDT fire
%s Clearing didStartRecordingDelegate WatchDogTimer : %{public}@
%s Schedule didStop WDT %{public}@ for %{public}lf seconds
%s stopRecordingWatchDogDidFire : %{public}@, currentToken : %{public}@
%s stopRecordingWatchDogToken doesn't match. Ignore this WDT fire
%s Clearing didStopRecordingDelegate WatchDogTimer : %{public}@
%s %@ task delivered.
%s %@ completed with response %@ and error %@.
%s CS logging files under %{public}@ created before %{public}@ will be removed.
%s Couldn't get creation date: %{public}@
%s Could not remove %{public}@: %{public}@
%s CS logging files number %{public}lu with pattern %{public}@ under %{public}@ exceeding limit, only keep the latest %{public}lu ones
%s Regular expression is nil!
%s Directory URL is nil!
%s VoiceTrigger cannot be turned on since SpeechDetectionVAD is not present
%s VoiceTrigger cannot be turned on since voiceTriggerInCoreSpeech is NO
%s VoiceTrigger cannot be turned on since VoiceTrigger is disabled
%s VoiceTrigger cannot be turned on since Siri is disabled
%s VoiceTrigger cannot be turned on since SpringBoard is not started yet
%s VoiceTrigger cannot be turned on since device is not unlocked after restart
%s VoiceTrigger cannot be turned on since device is on battery
%s VoiceTrigger cannot be turned on since Siri is restricted on lock screen
%s VoiceTrigger cannot be turned on since Software Update Checking is running
%s VoiceTrigger cannot be turned on since we are not in a desired call state
%s VoiceTrigger cannot be turned on because we are in a ringtone and hearstState: %d builtInState: %d isInSplitterMode: %d
%s Not supported on this platform
%s NDAPI initialization failed
%s set StartAnalyzeSampleCount = %{public}lld
%s NDAPI config doesn't contain threshold_normal
%s NDAPI config doesn't contain threshold_logging
%s NDAPI config doesn't contain threshold_reject_logging
%s CS doesn't have ndblobbuilder!
%s latestMajorVersion = %d, LatestMinorVersion = %d
%s corespeech.json doesn't contains rtblobs
%s blob file name is not exists
%s blob file is not exists at %{public}@
%s Reading blob from : %{public}@
%s Blob is nil : %{public}@
%s Locale map for %{public}@ is not available on asset
%s Received external route change notification
%s Received CarPlay AuxStream support change notification
%s Received CarPlay connection change notification
%s Start monitoring : AudioRouteChangeMonitor
%s Stop monitoring : AudioRouteChangeMonitor
%s Notifying Hearst Connection State : %{public}d
%s Notifying Jarvis Connection State : %{public}d
%s Failed to create AVVC : %{public}@
%s Create new CSAudioRecorder = %{public}p
%s CSAudioRecorder %{public}p deallocated
%s AVVC initialization failed
%s Successfully create AVVC : %{public}p
%s Setting announced call flag to: %d with stream handle Id: %lu
%s Calling AVVC setContext : %@
%s Failed to get handle id : %{public}@
%s setContext elapsed time = %{public}lf, streamHandleId = %{public}lu, streamType = %{public}lu
%s Calling AVVC setContextForStream : %{public}@
%s Tried to setCurrentContext with mode %ld. This method can only be used for auto and post
%s setCurrentContext elapsed time = %{public}lf
%s Failed to prepare remote device : %{public}@
%s Calling AVVC prepareRecordForStream(%{public}llu) : %{public}@
%s AVVC prepareRecordForStream failed : %{public}@
%s prepareRecordForStream elapsed time = %{public}lf
%s ::: CSAudioRecord will inject audio file instead of recording
%s Resetting AudioFilePathIndex
%s Increase AudioFilePathIndex = %d
%s AudioFilePathIndex is out-of-boundary _audioFilePathIndex:%d injectAudioFilePaths:%d
%s AudioFilePathIndex:%d accessing:%@
%s Unable to find injectAudioFilePath = %@
%s Asking startRecording to remote device with context : %{public}@ (original context : %{public}@)
%s Failed to fetch valid context
%s Failed to startRecording : %{public}@
%s startRecordingWithOptions elapsed time = %{public}lf
%s Calling AVVC startRecordForStream : %{public}@
%s startRecordForStream failed : %{public}@
%s startRecordForStream elapsed time = %{public}lf
%s Failed to stopRecording to remoteRecordClient : %{public}@
%s stopRecording elapsed time = %{public}lf
%s Calling AVVC stopRecordForStream
%s Failed to stopRecordForStream : %{public}@
%s stopRecordForStream elapsed time = %{public}lf
%s Session State = %d
%s AudioSessionState = YES
%s AudioSessionState = NO
%s fetch recordDeviceInfo elapsed time = %{public}lf
%s fetch EndpointDeviceType elapsed time = %{public}lf
%s AVVC sampling rate = %{public}f
%s AVVC doesn't return sampleRate, assume it is default sample rate
%s isNarrowBand = NO for streamHandleId = %{public}lu
%s isNarrowBand = %{public}@ for streamHandleId = %{public}lu
%s Calling AVVC setSessionActive for Prewarm
%s Prewarm AudioSession has failed : %{public}@
%s Calling AVVC setRecordMode to mode : %{public}d
%s AVVC successfully setRecordMode
%s setRecordMode elapsed time = %{public}lf
%s Calling AVVC setSessionActivate for activation with streamId(%{public}lu)
%s AVVC setSessionActivate has failed : %{public}@
%s AVVC successfully activated audioSession
%s setSessionActivate elapsed time = %{public}lf
%s Calling AVVC setSessionActivate for deactivation : %{public}tu
%s Calling AVVC setSessionActivate for deactivation for stream %d: %{public}tu
%s Failed to setIamTheAssistant : %{public}@
%s Creating audio session with allow mixable audio while recording to YES
%s Calling AVVC : Enable Smart Routing Consideration
%s Calling AVVC : Disable Smart Routing Consideration
%s enableSmartRoutingConsiderationForStream elapsed time = %{public}lf
%s Fail to setSmartRoutingConsideration : %{public}@
%s Calling AVVC setDuckOthersForStream(%d) for DuckOthers/MixWithOthers
%s Failed to setDuckOthersForStream : %{public}@
%s setDuckOthersForStream elapsed time = %{public}lf
%s Calling AVVC setDuckOthersForStream(%d) for MixWithOthers
%s Should not call setDuckOthersOptions with NO in B238
%s enableMiniDucking elapsed time = %{public}lf
%s %{public}@
%s configureAlertBehavior elapsed time = %{public}lf
%s VoiceTriggerInfo is nil from AVVC
%s Updated languageCode to: %{public}@ in VTEI received from remote
%s Peak : %f, Avg : %f
%s AVVCAudioBuffer contains %{public}d packet descriptions, size %{public}d, channels %{public}d. Ignoring
%s packets count %{public}d
%s Bad packet length %{public}d. Skipping rest of record buffer.
%s Cannot handle audio buffer : unexpected format(%{public}u)
%s Compensating %{public}u channel(s), heartbeat = %{public}lld
%s Calling AVVC playAlertSoundForType to play alert
%s Ignore playing endpoint beep(record stopped beep) since it already played beep in gibraltar
%s Calling AVVC playAlertSoundsForType : %{public}ld
%s Received didStartRecording : %{public}p, forStream:%{public}llu, successfully:%{public}d, error:%{public}@
%s Received audio buffer %{public}d, heartbeat = %{public}llu, streamID (%{public}lu)
%s Received didStopRecording : %{public}p forStream:%{public}llu forReason:%{public}ld
%s Received Stream Invalidated : %{public}llu
%s toConfiguration : %{public}d
%s type : %{public}d, error : %{public}@
%s Encoder error : %{public}@
%s withContext : %{public}@
%s activate : %{public}d
%s AVVC lost mediaserverd connection
%s AVVC informed mediaserverd reset, no further action required
%s hasLocalPendingTwoShot = %{public}d, token : %{public}llu
%s Unsupported audio format!
%s Existing remoteRecordClient (deviceId = %@) doesn't match required one (deviceId = %@), create new remoteRecordClient
%s The input streamHandleId(%{public}lu) is not expected(%{public}lu)
%s primaryStream already torn down
%s Start Listening request with deviceId : %{public}@
%s CSOpportuneSpeakListener received didStart : %{public}d, %{public}@
%s remoteVADDuration = %{public}d, spgDuration = %{public}d, _remoteVADSPGRatio = %{public}d
%s AudioStreamRequest has failed : %{public}@
%s CSOpportuneSpeakListener received didStop : %{public}d, %{public}@
%s Request stop CSOpportuneSpeakListener
%s Audio coming from DoAP should contains RemoteVAD
%s boronScore : %{public}d, reportBoron : %{public}d, slienceScore : %{public}lf
%s Cannot create NSData with size 0
%s xpc object should be XPC_TYPE_DATA
%s Start monitoring : Siri setting switch, Siri is %{public}@
%s Stop monitoring : Siri setting switch
%s Siri Enabled = %{public}@
%s Trying to access BTLocalDevice
%s Accessing BTLocalDevice
%s BTLocalDevice %{public}p
%s Failed to get sharing enable flag : %d
%s Failed getting sharing device addresses %d
%s Failed converting address from BTDeviceAddress (result = %d).
%s Device is temporary paired and not in contacts
%s Detaching bluetooth session : %{public}p
%s Already Attaching Bluetooth Session
%s Start attaching bluetooth session
%s session = %{public}p, result = %{public}d
%s session = %p
%s detached session is different from currently attached session, ignore
%s terminated session is different from currently attached session, ignore
%s Bluetooth Session is NULL
%s Failed to get default local device from session %{public}p, (result = %{public}d)
%s Failed to add local device callback from session %{public}p, (result = %{public}d
%s CSActivationXPCListener start listening
%s startRecording
%s stopRecording
%s score %f
%s sv %@
%s Audio file read start
%s Audio file read end
%s Unsupported protocol for this device
%s sessionID(for deviceId %{public}@ = %{public}llu
%s Trying to get sessionID when audioSessionInfoProvider is nil
%s SmartSiriVolume not supported on this platform - Bailing out
%s SmartSiriVolume connection started listening
%s _csAssetsDictionary = %{public}@
%s CSAssetController cannot query for nil language
%s ::: found %{public}lu installed assets for assetType=%{public}lu, matching query: %{public}@
%s Error running asset-query for assetType:%{public}lu, query: %{public}@, error: %{public}lu
%s ::: found %{public}lu assets for assetType=%{public}lu, matching query: %{public}@
%s Asset state : %{public}ld
%s ::: %{public}s
%s ::: %{public}s; query: %{public}@
%s Found %{public}lu assets
%s Error running asset query: error %{public}lu, or result is empty
%s ::: Request Fetching RemoteMetaData : assetType : %{public}d
%s Fetching remote meta data failed, scheduled retry after %{public}f seconds
%s ::: Request fetching remote asset
%s ::: found %{public}lu assets for assetType %{public}lu
%s Failed to finish query for assetType %{public}lu with error %{public}lu
%s Meta data downloaded successfully for assetType %{public}lu
%s Failed to download meta data for assetType %{public}lu with error %{public}lu
%s ::: Fetching remote asset
%s ::: Purging installed asset : %{public}@
%s ::: Request downloading remote asset for assetType %{public}lu
%s ::: Start downloading asset
%s ::: download progress: %{public}3.0f%%
%s ::: Error downloading from %{public}@ with error %{public}@
%s ::: download completed successfully from %{public}@.
%s Attempting to download asset %{public}@, asset state : %{public}ld
%s ERR: Unknown AssetType: %{public}lu
%s Device is firstUnlocked. Fetching HEP assets
%s Device is NOT firstUnlocked. Will fetch assets after firstUnlock
%s Failed to get HEP asset
%s HEP Asset: %{public}@, path: %{public}@
%s endpointerModelVersion is still nil after fetching it from EAREndpointer
%s HEP::RecordingDidStop: Ignoring processAudioSamplesAsynchronously: Not queueing
%s first audio buffer host time: %{public}llu
%s HEP::RecordingDidStop: Ignoring processAudioSamplesAsynchronously
%s addAudio first sample offset: %{public}lu
%s Updated endpointer threshold: %{public}f
%s Updated endpointer delayed trigger: %{public}d
%s EARSPG: CSServerEndpointFeatures: %{public}@
%s Accepting RC: RCTime < 0: Server's processedAudioDuration(%{public}f) > _lastReportedEndpointTimeMs(%{public}f): sfLatency: %{public}f, rcTimeMs: %{public}f
%s Rejecting RC: SFLatency < 0: Server's processedAudioDuration(%{public}f): _lastReportedEndpointTimeMs(%{public}f): sfLatency: %{public}f, rcTimeMs: %{public}f
%s rcEpFeatures: %{public}@ shouldAccept: %{public}d
%s HEP::RecordingDidStop: Ignoring silenceScoreEstimateAvailable, Not queuing
%s Detected speech start at %{public}f of effectiveClientProcessedAudioMs
%s HEP::RecordingDidStop: Ignoring silenceScoreEstimateAvailable
%s Already communicated end-pt: Not Invoking hybridClassifier for silposnf=%{public}f
%s ClientLag: serverProcessedAudioMs(%{public}ld) > effectiveClientProcessedAudioMs(%{public}f)
%s ClientLag: Not invoking HybridClassifier: sfLatency > clientLagThreshold: %{public}f > %{public}f
%s ClientLag: Using DefaultServerFeatures with disconnected-state sfLatency: %{public}f
%s ClientLag: Using ServerFeatures with ClampedSFLatency: %{public}f
%s Using ServerFeatures with ClampedSFLatency
%s ClientLag: Not Invoking HybridClassifier as serverProcessedAudioMs > effectiveClientProcessedAudioMs
%s HEP.feats: [%{public}ld,%{public}f,%{public}f,%{public}ld,%{public}f,%{public}f] & [(%{public}@),%{public}f] @ %{public}lu [%{public}f, %{public}d]
%s HEP.posterior=%{public}f, result=1, endpointedBuffer.hostTime=%{public}llu, isAnchorTimeBuffered=%{public}d
%s request timeout with features %{public}@
%s ServerFeaturesLatencyDistribution: %{public}@ additionalMetrics: %{public}@
%s MMEP:: HEP detected at %{public}f but will continue running for MMEP.
%s Already communicated end-pt: Not scheduling work for hybridClassifierQueue for silposnf=%{public}f
%s Log hybrid endpointer features for event: %{public}@, and locale: %{public}@
%s triggerEndSeconds: %{public}f, _vtEndInSampleCount: %{public}lu, _vtExtraAudioAtStartInMs: %{public}lu,  _hepAudioOriginInMs: %{public}f, voiceTriggerInfo: %{public}@,
%s CSHybridEndpointAnalyzer recordingStoppedForReason: %{public}ld
%s sampleRate=%{public}lu, recordContext=%{public}@
%s CSEndpointAsset exists: %{public}@
%s No asset for CSHybridEndpointer for currentLanguage: %{public}@. Fallback to VAD2
%s Created OSDAnalyzer: %{public}@
%s Created HybridClassifier(%{public}@); canProcessCurrentRequest after reset: %{public}d,for sampleRate: %{public}lu, lang=%{public}@, version=%{public}@
%s HEP.logs.hdr: [ServerASR_trailingSilenceDuration,ClientSPG_SilenceFramesCountMs,ServerASR_endOfSentenceLikelihood,ServerASR_wordCount,ServerFeaturesLatency,ClientSPG_SilenceProbabilityHMMFiltered] & [ServerASR_pauseCounts,ServerASR_silencePosterior,ClientSPG_silenceProbailitySPGRaw] @ effectiveClientProcessedAudioMs : [HEPPosteriorOut,HEPDecision]
%s csHepConfig: %{public}@
%s _clientHepConfig: %{public}f, _clampedSFLatencyForClientLag: %{public}f, _useDefaultServerFeaturesOnClientLag: %{public}d
%s Language changed to: %{public}@
%s New hybrid endpoint asset downloaded
%s FirstUnlock notification received: %{public}d
%s _currentAsset changed to : %{public}@
%s %{public}@ doesnt exist
%s Could not read: %{public}@
%s Could not decode contents of: %{public}@: err: %{public}@
%s Request to init device with deviceType : %ld, deviceName : %@, deviceId : %@, productId : %@
%s Request inject audio %@ into device with UUID %@ and scale factor %f
%s Audio url %@ is nil, or url not existing in path
%s Can't find device with uuid %@
%s Device speak audio with startTime = %llu, stopTime = %llu
%s Request connect device with UUID %@
%s input device uuid is nil
%s Request disconnect device with UUID %@
%s deviceUUID %@ not existing in deviceDictionary, already disconnected
%s Request fetching primary input device
%s Error fetching primary device!
%s Cannot create NSNumber if xpcObject is NULL
%s XPC object type should be BOOL, DOUBLE, INT64, or UINT64
%s Cannot create xpcObject if objcType is NULL
%s Cannot create xpcObject since there is no matching type
%s Found pending activation : %{public}@, handle pending activation immediately
%s Received Activation Event in CoreSpeechDaemon: %{public}@
%s Returning error for already existing pending activation event : %{public}@
%s No delegate registered : Postpone activation event handling until we have delegate registered
%s Pending Timeout fired for %{public}@ returning error for timeout
%s There is no pending activation event to timeout
%s corespeechd received mediaserverd launched event
%s Start monitoring : AOP First Pass trigger
%s Stop monitoring : AOP First Pass trigger
%s SmartSiriVolume: deleted %{public}u elements in energy buffer.
%s SmartSiriVolume: number of elements to delete exceeds energy buffer size, ignore.
%s SmartSiriVolume init value for noise estimation %{public}f
%s SmartSiriVolume init value for LKFS estimation %{public}f
%s SmartSiriVolume enable policy changed : %{public}@
%s Already started listen polling, skip
%s listen polling has failed : %{public}@
%s Skip listen polling since audio is streaming / Siri disabled
%s Start audio stream successfully ? %{public}@, error : %{public}@
%s Received didStartRecording when Siri is off
%s Failed in requesting audio stream : %{public}@
%s Failed to stop audio stream : %{public}@
%s No audio stream to stop, we shouldn't hit this
%s SmartSiriVolume received MediaRemote initial state as %{public}@
%s SmartSiriVolume haven't got MediaRemote callback yet, let's assume media is playing.
%s SmartSiriVolume received alarm initial state as %{public}@
%s SmartSiriVolume received timer initial state as %{public}@
%s asset is nil, use default parameters(this should not happen).
%s SmartSiriVolume configure: %{public}@
%s SmartSiriVolume heartbeat = %{public}lld
%s SmartSiriVolume: estimated noise level %{public}f
%s SmartSiriVolume: estimated LKFS %{public}f
%s SmartSiriVolume: pause SSV calculation.
%s SmartSiriVolume: resume SSV calculation.
%s Siri is disabled, we shouldn't receive audio here, heartbeat = %{public}lld
%s stream stopped unexpectedly : %{public}ld
%s SmartSiriVolume received VT event!
%s SmartSiriVolume remove samples from VT utterances by %{public}llu, with startAnalyzeSampleCount = %{public}llu, samplesFed = %{public}llu, triggerStartSampleCount = %{public}llu
%s SmartSiriVolume trying to delete too many VT samples, set triggerDurationToDelete to be limited max: %{public}llu
%s SmartSiriVolume got empty VT event!
%s SmartSiriVolume dismiss alarm firing as VoiceTrigger detected.
%s SmartSiriVolume dismiss timer firing as VoiceTrigger detected.
%s SmartSiriVolume: final estimated TTS volume in dB %{public}f
%s SmartSiriVolume: adjust TTS volume since alarm/timer is firing.
%s SmartSiriVolume: TTS volume in dB from noise %{public}f, from LKFS %{public}f, with user offset %{public}f
%s SmartSiriVolume: soft volume algorithm in use
%s SmartSiriVolume: pause LKFS calculation according to MediaRemote notification.
%s SmartSiriVolume: resume LKFS calculation according to MediaRemote notification.
%s SmartSiriVolume received unknown media playing state, let's assume media is playing.
%s SmartSiriVolume received unknown alarm state, let's reset alarm state.
%s SmartSiriVolume: alarm firing status = %@ according to MobileTimer notification.
%s SmartSiriVolume received unknown timer state, let's reset timer state.
%s SmartSiriVolume: timer firing status = %@ according to MobileTimer notification.
%s Siri enabled : %{public}d
%s SmartSiriVolume dismiss alarm firing as Siri client is recording.
%s SmartSiriVolume dismiss timer firing as Siri client is recording.
%s SmartSiriVolume: set StartAnalyzeSampleCount = %{public}lld
%s SmartSiriVolume: final estimated TTS volume %{public}f with music volume %{public}f
%s Dealloc CSAudioInjectionProvider : %@
%s Stopping Audio Injection Provider : %@
%s Calling start audio stream : %@ %@
%s Calling stop audio stream : %@
%s Unable to expand archive %{public}@ to directory %{public}@
%s Listening on watch cannot be turned on since speech detection VAD is disabled
%s Listening on watch cannot be turned on since Siri is disabled
%s Listening on watch cannot be turned on since SpringBoard is not started
%s Listening on watch cannot be turned on since device is not unlocked after restart
%s Hey Siri is enabled. Checking if we are in a call.
%s Hey Siri is disabled. Not checking if we are in a call.
%s Listening on watch cannot be turned on since Siri assertion is disabled and or its not in a ringtone state
%s Listening on watch cannot be turned on since audioInjection is enabled
%s Listening on watch cant be turned on because we are in a connected or outgoing call
%s No app is currently recording now
%s Siri language is nil, falling back to %@
%s endpointUUID not provided, fallback to legacy query
%s Failed to query language code with endpointId %@, trying legacy query
%s Automatic Volume Toggled. Automatic Volume Enabled: %{public}d
%s ::: Error reading file %@, err: %d
%s CSAudioFileReader requires prepare recording settings to feed audio
%s CSAudioFileReader only support LinearPCM to feed
%s Setting ExtAudioFileSetProperty failed : %d
%s Starting audio file feed timer, bufferDuration = %f sampleRate = %f, bytesPerFrame = %d, channelsPerFrame = %d
%s ::: Error reading data from audio file : %d
%s Reach to EOF, chunkSize = %d
%s Stopping audio file feed timer
%s Endpointer is disabled in recordOption: %@
%s CSHybridEndpointer canProcessCurrentRequest
%s CSHybridEndpointer can-NOT-ProcessCurrentRequest, fallback  to NNVAD
%s _activeEndpointer=%{public}@
%s shouldUseCVT2ShotDecision: %{public}d, isWatchRTSTriggered=%{public}d
%s preheat
%s endpointer: %{public}@: didDetectStartpointAtTime: %{public}f
%s EP_PROXY::RecordingDidStop: Ignoring startPoint-reporting
%s EP_PROXY::RecordingDidStop: Ignoring didDetectHardpoint-reporting
%s %{public}@: Endpointer didDetectHardEndpointAtTime:withMetrics: %{public}f, CallingDelegate: %{public}@
%s Reported 2-shot at: %{public}f secs
%s Queried endpointerModelVersion: %{public}@
%s WARN: endpointerModelVersion called when CSHybridEndpointer is not available
%s WARN: logEndpointFeatures called when CSHybridEndpointer is not available
%s setting prefetched asset %@
%s update lastKnownConsecutiveBoronStartSampleCount to: %llu
%s Created OSDAnalyzer: %{public}@ model path: %{public}@
%s Cannot create OSDAnalyzer
%s _bestStartDetectSample %lu was greater than _bestEarlyDetectSample %lu or _bestEndDetectSample %lu
%s _bestEarlyDetectSample %lu was greater than _bestEndDetectSample %lu
%s _speechVoiceLevel %lu is 0
%s _numberOfTotalFramesETFT %lu is 0
%s Advert data: %{public}@
%s advert data write failed
%s elapsed time to get HEP assets: %{public}lf
%s installationString: %@, for language: %@
%s File not exist: %{public}@
%s endpointAsset: %{public}@, osdAsset: %{public}@
%s Dealloc CSAudioInjectionEngine : %@
%s Looking up audio diff:%llu sampleCount:%llu %@
%s Start monitoring : Springboard start
%s Cannot start monitoring Springboard start because it was already started
%s Stop monitoring : Springboard start
%s SpringBoard started = %{public}@
%s Received Activation Event : %{public}@
%s Cannot handle activation event : %{public}@
%s activation client not exist
%s ERR: Failed to initialize SSV Manager!
%s ERR: %{public}@
%s Primary stream is nil !
%s CSAttSiriAudioSrcNode deallocated
%s Tandem stream stopped unexpectly for reason: %ld
%s Unexpected audioFormat for ATV : %{public}u
%s Create audioDecoder for audioFormat %{public}u
%s Stop monitoring : First unlock
%s xpc object string return nil
%s xpc object should be XPC_TYPE_STRING
%s xpc object should be XPC_TYPE_ARRAY
%s xpcObject value is NULL
%s Cannot decode non-plist types of XPC object
%s Cannot encode non-plist types into XPC object : %{public}@
%s Timed-out for fetching voiceTriggerInfo
%s TiggerInfoProviding is nil
%s Overriding Myriad state as request was made during a phone call
%s Invoked Siri client
%s Cannot invoke Siri client : %{public}@
%s Cannot notify wake keyword spoken event : %{public}@
%s AFSiriActivationCarPlayDeviceVoiceTriggerPrewarm success
%s AFSiriActivationCarPlayDeviceVoiceTriggerPrewarm failed : %{public}@
%s Invoked Siri client for voice trigger from Jarvis
%s Cannot invoke Siri client for voice trigger from Jarvis : %{public}@
%s SiriActivationConnection deactivated due to %ld
%s siriSessionUUID = %{public}@
%s CSAudioProcessWaitingBuffer deallocated
%s Reason : %{public}lu
%s Received xpc disconnection
%s Updated endpoint start time in sec : %{public}.3f
%s Adjusted endpoint start time to : %{public}.3f, audioSampleCountToSkip : %{public}lu
%s Preheat LocalSpeechRecognition now
%s Settings : %{public}@
%s Unsupported speech recognizer task : %{public}lu
%s _localSpeechRecognizerState:%lu
%s Received nill requestId, generate requestId under corespeechd
%s Start deliver asr results with requestId: %@
%s Handle late start request from Request Dispatcher
%s Clear audio waiting buffer since current requestId(%@) doesn't match expected one (%{public}@)
%s requestId : %@
%s Request Dispatcher hasn't asked to start local ASR yet, cache the audio
%s %lf
%s Already accepted result candidate for request
%s Sending RC selection delegate with parameters, RcId: %{public}lu mitigationSignal: %{public}d shouldAccept %{public}d
%s Reset endpointStart and audioSampleCountToSkip since recordContext is %{public}@
%s Preheat local speech recognizer with language : %@
%s Local speech recognizer disabled, ignore prepare
%s cached requestId : %@, newRequestId : %@
%s Disable local SR for dictation
%s current state = %{public}@
%s speech recognizer task not specified, fallback to SearchOrMessage
%s Calling local speech recognition with settings : task(%{public}@), endpointStart(%{public}.3f), inputOrigin(%{public}@), location(%{public}@), shouldCensorSpeech(%{public}@), jitGrammar(%{public}@)
%s didStart local speech recognition with error :%@, model properties : %@
%s Local speech recognizer can't started : locale(%{public}@), taskName(%{public}@)
%s Skip %{public}lu samples (current audioSampleCountToSkip = %{public}lu)
%s Received %{public}lu samples, added %{public}lu samples to local speech recognizer
%s Stopping task %@
%s Request dispatcher didn't ask to start until end
%s Complete task now since taskString(%{public}@) or localSR(%{public}p) is nil
%s Complete task now since local SR is disabled
%s Schedule RecordingTransactionReleaseTimer %{public}@ for %{public}lf seconds
%s Token : %{public}@, currentToken : %{public}@
%s recordingToken doesn't match, ignore
%s %@ created speech recognizer %@
%s Ignoring completion from previous recognizer!
%s Exceeding max local speech recognition duration (%{public}f) : %{public}f, force endbooking the ASR task
%s Skip query as already accepted result candidate for request
%s didDetectedEndpoint = %{public}@, usesAutomaticEndpointing = %{public}@, waiting
%s Eager results accepted: %{public}d. Duration: %{public}lf last duration: %{public}lf
%s Received duration not matching last duration
%s isFinal package : %{public}@
%s There is no valid RC to deliver, or previous RC already got accepted
%s Enforce previous endpointHint
%s Speech recognition encountered error: %{public}@
%s Invalidating local speech recognizer for finish
%{public, signpost.description:begin_time}llu, %s %s
%{public, signpost.description:end_time}llu, %s %s
ondevice_EagerCPL
%s eagerCPL time interval: %{public}f, userSpeakingEndedHostTime: %{public}llu, lastEndpointEagerResultTime: %{public}llu
%s wordCount = %ld, trailingSilenceDuration = %ld, eosLikelihood = %f, pauseCounts = %@, silencePosterior = %f, processedAudioDurationInMilliseconds = %ld
%s Received ASR datapack root directory: %{public}@
%s Received inputOrigin: %{public}@ from Request Dispatcher, use hard-coded map
%s set current state from %{public}@ to %{public}@
%s Selected recognizer language : %{public}@
%s Timer already running. Cannot schedule another task
%s CSAttSiriTimer fired: event-handler called
%s Starting CSAttSiriTimer...
%s Cancelling pending timer...
%s stream %{public}@ initialized
%s stream %{public}@ is deallocated
%s Creating UUID for start audio stream request : %{public}@
%s Delivering didStop to %{public}lu tandem stream(s)
%s AudioStream<%{public}@> is streaming : %{public}d
%s Stream %{public}@ set startTimeInSampleCount : %{public}llu
%s AudioStream<%{public}@> has received didStopStreamUnexpectly
%s AudioStream<%{public}@> has received didHardwareConfigurationChange
%s Start monitoring : VoiceTrigger Asset meta update
%s Stop monitoring : VoiceTrigger Asset meta update
%s New VoiceTrigger asset metadata is available
%s Resetting audio preprocessor : %{public}f, containsVoiceTrigger:%{public}d
%s Flushing audio preprocessor
%s Zero Filter Metrics: %{public}@
%s Beep Canceller Metrics : %{public}@
%s accessoryId %{private}@
%s Received active route change notification
%s Start monitoring : speech endpoint asset meta update
%s Stop monitoring : speech endpoint asset meta update
%s New speech endpoint asset is available
%s event = %{public}p client = %{public}p cannot handle event
%s ignore unknown types of message
%s message = %{public}p, client = %{public}p, cannot handle message
%s MessageType = %{public}lld
%s Received error %{public}@ from client %{public}@
%s Client %{public}p connection disconnected, noticing xpc listener
%s AssetManager cannot be turned on since isFirstUnlocked is NO
%s AssetManager cannot be turned on since network is not available
%s Setting mixable to yes as we are in an active call
%s CSXPCListener start listening
%s setEndpointerOperationMode : %{public}d
%s current EndpointerOperationMode : %{public}d
%s update endpointer threshold to %{public}f for task %{public}@
%s HEP.posterior=%{public}f, result=1, endpointedBuffer.hostTime=%{public}llu isAnchorTimeBuffered=%{public}d
%s CSHybridEndpointer recordingStoppedForReason: %{public}ld
%s _clientHepConfig: %{public}f, _clampedSFLatencyForClientLag: %{public}f, _useDefaultServerFeaturesOnClientLag: %{public}d, _extraDelayFrequency: %{public}lu, _taskThresholdMap: %{public}@
%s update assets to: %@
%s ::: incrementing false wakeup to %{public}llu
%s PowerLog : HeySiriFalseTrigger numFalseWakeUp:%{public}d, secondsSinceLastReport:%{public}lf
%s ::: accumulated false wakeup count is %{public}llu so far, not reporting yet because it has been only %{public}.2f seconds since last report
%s Sending event with non determenistic triggerLengthSampleCount %llu, triggerLengthSampleCountDetermenisticFromFirstPass %llu, and delta of %lld samples
%s Initializing CSRawAudioInjectionProvider
%s Done initializing CSRawAudioInjectionProvider
%s Dealloc CSRawAudioInjectionProvider
%s Calling StreamId for : %@
%s Calling prepare
%s Calling start audio stream : %@
%s Calling stop audio stream
%s Calling isRecording
%s Calling prewarm
%s Calling activate audio session
%s VoiceTrigger is already %{public}@, received duplicated notification!
%s Start monitring : VoiceTrigger setting switch
%s Cannot start monitoring VoiceTrigger setting switch because it was already started
%s Stop monitring : VoiceTrigger setting switch
%s VoiceTrigger enabled = %{public}@
%s Received AOP Listening state change notification : %{public}d
%s Created AFTM-AS node
%s Don't run AFTM for recordType: %lld
%s Prefetched asset not set
%s Invalid FTM config read from configFile %{public}@ for task %{public}@
%s Reading config from: %{public}@ for task %{public}@
%s Configured recording types: %{public}lu
%s Thresholds read: %{public}@
%s Shadow Mode: %{public}d
%s Received start request for record type: %{public}@, supportedRecordTypes: %{public}lx taskName %{public}@
%s Unable to create progressive checker with error:%{public}@
%s Unable to create progressive checker context with error:%{public}@
%s Created SLProgressiveCheckerAnalyzer %{public}@ with context %{public}@
%s CSAcousticProxy has received %{public}d samples, heartbeat = %{public}lld
%s Siri session ended, stoping acoustic checker
%s Cancelling Siri request, score: %{public}.3f, threshold: %{public}.3f
%s Invalid Analyzer: %{public}@
%s FINAL: Analyzed samples: %lu, score: %f
%s PARTIAL: Analyzed samples: %lu, score: %f
%s Assistant audio log not available
%s Error writing out AcousticSL info meta: %{public}@
%s Saving AcousticSL results at %{public}@
%s Submitting AcousticFTM analytics: %@
%s Unexpected XPC audioTimeConvert providing request : %{public}lld
%s From sampleCount %{public}llu fetched hostTime = %{public}llu
%s From hostTime %{public}llu fetched sampleCount = %{public}llu
%s Non internal build, Ignoring command %@ from peerId %@ - Bailing out!
%s Received Malformed command %@ from peerId %@ - Bailing out!
%s Command %@ received from peerId %@
%s Unknown Command: (%@) - Ignoring
%s Triggering sync with peer - %@
%s Triggering nearmiss sync with peer - %@
%s Triggering voice profile sync with peer - %@
%s Triggering acoustic data sync with peer - %@
%s CSP2P_RemoteHeySiriCmd: ENABLE HeySiri: Not Implemented Yet: 
%s CSP2P_RemoteHeySiriCmd: DISABLE HeySiri: Not Implemented Yet: 
%s Cannot read contents of directory: %@, err: %@
%s Could not determine if [%@] is a directory or not. Err=%@
%s Found dir: %@. Skipping compression
%s _compressFilesInDirectory: Malloc failed for file %@ (%lu) - Discarding
%s _compressFilesInDirectory: Compression failed for file %@ (%lu) - Sending Uncompressed
%s _compressFilesInDirectory: File %@ compressed from %ld to %ld 
%s Failed in compressing %{public}@ with errror %{public}@ - Bailing out
%s Transfering NearMiss file %@ withCompression %{public}@ and size %ld in batch %{public}@
%s Transfering grading file %@ withCompression %{public}@ and size %ld in batch %{public}@
%s %@ is nil - Bailing out
%s Failed in transporting Voice file %@ with reponse: %@, error %@
%s Failed to remove the file %@ with error %@
%s Failed to move the file %@ to %@ with error %@
%s CSP2P_VoiceProfileParallelRecordingTransferCmd: received malformed command - %@ %@ %@
%s CSP2P_VoiceProfileParallelRecordingTransferCmd: unknown IDS peer with passed Identifier %@, %@ %@
%s CSP2P_VoiceProfileParallelRecordingTransferCmd: received malformed command - %@
%s CSP2P_VoiceProfileParallelRecordingTransferCmd: Creating directory failed with error %@
%s Ignoring sync of existing file %@ from %@
%s Syncing parallel recorded audio file - %@ from %@
%s Uncompressed file %@ sent by peer %@
%s ERR: Failed to allocate buffer of size %zu, bailing out
%s Writing to file(%@) failed!. Err=%@
%s received malformed command - %@ %@ %@
%s unknown IDS peer with passed Identifier %@, %@ %@
%s received malformed command - %@
%s Syncing audio file - %@ from %@
%s Error setting remoteP2Plog file to NSFileProtectionCompleteUntilFirstUserAuthentication. file=%@ Err=%@
%s CSP2P_VoiceProfileTransferCmd: received malformed command - %@ %@ %@
%s CSP2P_VoiceProfileTransferCmd: received malformed command: CSP2P_VoiceProfileData_Key: %@CSP2P_VoiceProfileFileName_Key: %@CSP2P_VoiceProfileSpeakerName_Key: %@CSP2P_VoiceProfileLocale_Key: %@CSP2P_VoiceProfileDataType_Key: %@CSP2P_VoiceProfileTotalSegments_Key: %@CSP2P_VoiceProfileSegment_Key: %@
%s CSP2P_VoiceProfileTransferCmd: Received VoiceProfile Segment (%@/%@) from peerId %@
%s CSP2P_VoiceProfileTransferCmd: Failed to delete the directory %@ with error %@
%s CSP2P_VoiceProfileTransferCmd: received VoiceProfileSegment %@, expected %d
%s CSP2P_VoiceProfileTransferCmd: Creating directory failed with error %@
%s CSP2P_VoiceProfileTransferCmd: Writing to file failed!!!
%s Received request to delete VoiceProfile %@ from peerId %@
%s Cannot send data across when _adCompanionServiceProvider is nil - returning
%s ERR: Rejecting command %@ sent to non Horseman device
%s ERR: received malformed command - %@ %@
%s ERR: unknown IDS peer with passed Identifier %@, %@ %@
%s ERR: received malformed command with locale nil - %@
%s Fetching homeUserId for siriProfileId %{public}@
%s siriProfileId %{public}@ maps to homeUserId %{public}@
%s ERR: Home User Id erred %{public}@ for Siri Profile Id %{private}@
%s ERR: %@
%s ERR: received malformed command with profileId nil - %@
%s ERR: Failed to find voice profile with identifier - %@
%s CSP2P_VoiceProfileFetchCmd: Transferring voice profile %{public}@
%s CSP2P_VoiceProfileFetchCmd: File %@ isCompressed: %d, compressedSize: %ld, err: %@
%s CSP2P_VoiceProfileReverseTransferCmd: Failed VoiceProfileTransfer: %@, error %@
%s CSP2P_VoiceProfileReverseTransferCmd: Successfully transferred %@
%s CSP2P_VoiceProfileReverseTransferCmd: Failed transferring voice profile %@ with error %@
%s CSP2P_VoiceProfileReverseTransferCmd: Successfully transferred voice profile %@
%s ERR: Rejecting command %@ sent to Horseman device
%s ERR: received malformed command with relative path nil - %@
%s Failed in sending trigger for Voice profile update to peer %@ with error %@
%s SpkrId:: path is nil - Bailing out
%s SpkrId:: Direntry with same name exists, this will be removed: %@
%s SpkrId:: Creating Directory : %@
%s SpkrId:: Creating Directory failed : %@
%s Error reading directory at %@: err: %@
%s %@ is empty
%s Using audioInjectionProvider as recorder
%s context : %@
%s context:%@, flag:%u option:%@, eventUUID:%@
%s _requestMHUUID set to :%@
%s Skip asking audioSrcNode to record since Siri client failed to start audio
%s Cached siri client stream, attach after nodes start
%s Skip asking audioSrcNode to prepare since Siri client failed to prepare audio
%s %@ is ready
%s Attached to siri client stream with result: %d error:%@
%s Failed to setup audioSrcNode
%s Skip processing for remora requests!
%s AFTM started for siri request status: %{public}d with error: %{public}@
%s attSiriTransaction already released
%s init-_currentLanguageCode: %{public}@
%s Asset Manager Policy has been %{public}@
%s Asset Manager Policy has been enabled, start fetching meta data now
%s Need to fetch remote meta now, since we have new asset need to be downloaded
%s Does not need to fetch remote meta now
%s Cannot fetch VoiceTrigger asset meta data
%s Undefined assetType : %{public}u
%s _currentLanguageCode changed: %{public}@
%s Trying to start download meta data
%s Periodical downloading is already scheduled, ignore request.
%s No periodical downloading is scheduled, ignore request.
%s Record route to verify = %{public}@
%s Record route = %{public}@, playback route = %{public}@
%s Device endpointType = %{public}lu
%s hypotheticalRoute = %{public}@
%s Audio route changing to HFP is expected
%s zeroFilterWinSz: %{public}tu, numHostTicksPerAudioSample: %{public}f
%s _vtEndInSampleCount:%{public}ld, _numSamplesProcessed: %{public}ld, voiceTriggerInfo: %{public}@
%s Metric Providing Request Message has arrived : %{public}lld
%s Unexpected XPC Metric providing request : %{public}lld
%s audioMetric = %{public}@
%s audioMetricProvider not existing
%s Message type = %{public}lld
%s Cannot handle wrong message type
%s Cannot handle activateEventMessage since event is nil
%s Successfully ? %{public}@
%s Notify release of audio session
%s Created NLDA-AS node
%s Bert model already present, nothing to do
%s Unable to create Bert model with error: %{public}@
%s Created Bert model !
%s Model not available
%s Failed to get result from Bert
%s NLDA detailed Result: %{public}@
%s Start monitoring : VoiceTrigger Asset Download
%s Stop monitoring : VoiceTrigger Asset Download
%s New VoiceTrigger is now installed
%s SmartSiriVolumeContextAware TTS volume post lower and upper bounds is: %f
%s TTS volume offset post lower and upper bounds is: %{public}f
%s Smart Siri Volume not supported on this platform - Bailing out
%s ERR: Failed to initialize Smart Siri Volume with sampling %{public}f and %{public}@
%s AlarmState changed to %{public}d
%s TimerState changed to %{public}d
%s MusicVolume changed to %{public}f
%s AlarmVolume changed to %{public}f
%s Automatic Volume State changed to %{public}d
%s UUID was nil will not start fingerprint provider
%s Updated in use services for fingerprintProvider. %lu services in use
%s Starting continuousFingerprintProvider
%s UUID was nil will not stop fingerprint provider
%s Updated in use services for fingerprintProvider. %lu services remaining
%s Stopping continuousFingerprintProvider
%s Created URES-AS node
%s Set input origin to: %@
%s Using config file at : %{public}@
%s Got mitigation result: %{public}d for RCId: %{public}lu
%s Mitigation signal for RCId: %{public}lu not found
%s ASR node fetched mitigation signal, unload NLDA model
%s Replacing already made decision for RCId: %{public}lu
%s Failed to get result from UReS, don't mitigate
%s Final mitigation result: %{public}@ for RCId: %{public}lu
%s Received RC from ASR, make UReS decision
%s UReS not supported for inputOrigin: %{public}@, abort
%s Unable to get all required inputs for decision - (inputOrigin: %{public}@ speechResult: %{public}@), abort
%s Recognizer task: %{public}@ isn't support, don't run URES mitigator
%s Speech package doesn't contain LRNN scores, don't run URES mitigator
%s AttSignal: NLDA Score: %.3f
%s Input origin not set, Abort !
%s AttSignal: EoS Likelihood %{public}f
%s Unable to create Ures mitigator with err: %{public}@
%s Created URES Mitigator !
%s Received AFTM score: %{public}f for task: %{public}@
%s AttSignal: aftmScore: %.3f
%s AttSignal: osdActivity: %{public}@ for duration %.3f
%s ERR: Failed to retrieve Speaker score, letting trigger through - %{public}@
%s SPKR Accept: Score %{public}.3f Threshold %{public}f 
%s SPKR Reject: Score %{public}.3f Threshold %{public}f 
%s AttSignal: ssrScore: %.3f
%s OS transaction obtained for UReS inference
%s osTransaction already released
%s OS transaction released after UReS inference
%s ERR: metaData is nil, defaulting to NO for %{public}@
%s ERR: read metafile %{public}@ failed with %{public}@ - defaulting to NO
%s Start monitoring : AdBlocker Asset Download
%s Stop monitoring : AdBlocker Asset Download
%s New AdBlockerAsset is now installed
%s CSVoiceIdXPCListener start listening
%s speechController = %{public}p
%s xpcListener = %{public}p
%s context = %{public}@
%s Failed to create audio recorder : %{public}@
%s For Context : %{public}@, audioStreamId(%llu) has allocated
%s Failed to get audio stream handle ID : %{publid}@
%s has match with audio stream handle id : %llu
%s does not match with audio stream handle id(%llu), creating new audio provider
%s No audioRecorder available, return nil for audioProvider
%s have matched audioProvider with stream handle id : %llu
%s don't have matched audioProvider with stream handle id : %llu, need to create one later
%s audioProvider[%{public}@] invalidated with streamHandleId : %{public}llu
%s No matched audioProvider found for streamHandleId : %{public}llu
%s Received VoiceTrigger cached asset change notification, let's reinitialize VoiceTrigger
%s Trying to start clear logging files
%s Clear logging file timer is already started, ignore startClearLoggingFilesTimer request.
%s cannot handle nil event 
%s ignore unknown types of message: %{public}@
%s cannot handle nil error
%s In %@: Continuous digital zero detected, lasting %{public}u samples per channel
%s In %@: Continuous digital zero in this audio chunk detected, lasting %{public}u samples per channel
%s input dictionary is nil
%s Cannot send nil message
%s Unable to send message to client since there is no connection
%s Cannot handle audio providing message
%s Audio Providing Request Message has arrived : %{public}lld
%s Unable to handle audio providing switch message : context is nil
%s Setting XPCClientType to %{public}d
%s Handing PingPong message
%s Attentive Siri not supported on device
%s Endpointer xpc connection started listening
%s LocalSpeechRecognition xpc connection started listening
%s AttSiriServiceListener xpc connection started listening: _attSiriSvcListener=%@
%s SSR xpc connection started listening
%s Received SIGTERM. Exiting
%s CSHostDaemon didLaunch
%s Got xpc event for notification %s
%s Daemon WillShutdown
%s %{public}.2f ms after firstBufferStart
%s Invalid timestamp (currentMachTime: %{public}llu timestamp: %{public}llu)
%s Invalid timestamp (currentMachTime: %{public}llu arrivalTimestamp: %{public}llu)
%s numOfAudioPackets: %{public}lu, numOfValidTrailingPackets: %{public}lu, numOfValidTrailingSpeechPackets: %{public}lu, 
trailingPktLatencies: %{public}@ 
trailingPktSpeechLatencies: %{public}@
%s Error reading audio file: %{public}d, skipping...
%s Notifying CoreSpeechDaemon launched
%s Start monitoring : corespeechd state
%s Cannot start monitoring corespeechd state because it was already started
%s Stop monitoring : corespeechd state
%s CoreSpeechDaemon state changed to %{public}u
%s ERR: Mach Service Name is nil - Bailing out
%s ERR: Proxy Object is nil - Bailing out
%s ERR: Exported interface is nil - Bailing out
%s Started listening for %{public}@
%s Service %{public}@ dealloced - %{public}@
%s Got connection on service %{public}@
%s [Service:%{public}@] Invalid listener - %{public}@
%s Rejecting connection to %{public}@ due to entitlement
%s [Service:%{public}@] Listener Interruption Handler: %{public}@, client PID: %{public}d)
%s [Service:%{public}@] Listener Invalidation Handler: %{public}@, client PID: %{public}d exited
%s [Service:%{public}@] Adding connection for client PID (%{public}d)
%s [Service:%{public}@] Client connections dump:
[Service:%{public}@] For client PID (%d): %@
%s _machServiceName:%@ clientConnCount:%lu 
%s Sending message for client PID (%{public}d)
%s RemoteObjectProxy is nil for client PID (%{public}d)
%s [Service:%{public}@]
%s Cannot create directory at : %{public}@ : %{public}@
%s Successfully make CoreSpeechDaemon as KeepAlive
%s Failed to make CoreSpeechDaemon as KeepAlive : Cannot create file at %{public}@, error : %{public}@, %{public}@
%s KeepAlive file %{public}@ already existing
%s Start monitoring: siri assertion enable/disable
%s Stop monitoring: siri assertion enable/disable
%s did receive enable assertion
%s did receive disable assertion
%s CSAudioSessionProvidingProxy has received xpc disconnection _streamClientType : %{public}d
%s Trying to release audio stream on CSAudioSessionProvidingProxy
%s deallocated
%s Session Providing Request Message has arrived : %{public}lld
%s Unexpected XPC session providing request : %{public}lld
%s Failed to prewarm audio session, error : %{public}@
%s Session activate reason : %{public}u, dynamicAttributeType : %{public}u, bundleId: %{public}@
%s Failed to activate audio session, error : %{public}@
%s Session activate reason : %{public}u
%s Failed to deactivate audio session, error : %{public}@
%s Session request getting duck others option
%s Trying to get duck others option when audioSessionProvider is nil
%s Session set duck others option : %{public}d
%s Trying to set duck others option when audioSessionProvider is nil
%s Manual ducking handler not supported!
%s Session %{public}@ mini ducking
%s Trying to enalbe mini ducking when audioSessionProvider is nil
%s Session %{public}@ smart routing consideration
%s Trying to enable smart routing consideration when audioSessionProvider is nil
%s Dealloc CSAudioInjectionEngineRemoraEngine : %@
%s Alert Providing Request Message has arrived : %{public}lld
%s Unexpected XPC alert providing request : %{public}lld
%s Alert sound url : %{public}@, alertType = %{public}d
%s Set alert sound successful ? %{public}@
%s audioAlertProvider not existing
%s AlertType = %{public}d
%s Play alert sound successful ? %{public}@
%s PlayRecordStartingAlertAndResetEndpointer successful ? %{public}@
%s alertStartTime = %{public}llu
%s Invalid alert behavior
%s Alert behavior : %{public}@
%s Request to bypass PhraseSpotter : %{public}d with timeout %{public}lf seconds
%s Received Siri Session did cancelled
%s Created FlexKwd-AS node
%s Unable to start Flex Kwd with error %{public}@
%s Unable to start audio stream for Flex Kwd with error %{public}@
%s Trigger info already sent, ignore result
%s Reporting trigger with result: %{public}@
%s Connection %{public}p rejected due to missing entitlement
%s Start monitoring : AdBlocker Asset meta update
%s Stop monitoring : AdBlocker Asset meta update
%s New AdBlocker asset metadata is available
%s Error reading file
%s Version of AdBlockerAsset: %d
%s Cannot create de-interleaver using AudioConverterNew: %{public}d
%s Created de-interleaver
%s Stopping AudioInjectionEngine : %@
%s Failed to open audio file %@, error : %d
%s Streaming from %@
%s Cannot speak nil Audio URL
%s Cannot speak since audio file does not exists : %@
%s Calling stopAudioStream
%s Failed to deinterleave the data: %{public}d
%s Start monitoring : Software update checking state
%s Cannot start monitoring software update checking state because it was already started
%s Stop monitoring : Software update checking state
%s Software update checking running : %{public}@
%s There is not audio buffer to convert. Skip this.
%s Got asked for %{public}u packets, have %{public}u
%s [%{public}02u of %{public}02u %{public}fs] Opus packet with %u bytes
%s %{public}d bytesConsumed from opus coverter, remains %{public}d bytes
%s Resetting AudioConverter buffer
%s createAudioConverter : initial frames per buffer = dur %{public}.2f * sr %{public}.2f = %{public}u
%s Failed to get audioConverter property (kAudioConverterCurrentOutputStreamDescription) : %{public}d
%s _configureAudioConverter: encoded audio needs minimum of %{public}u bytes per output buffer
%s _configureAudioConverter: AudioConverterGetProperty(kAudioConverterPropertyMinimumOutputBufferSize) returned status %{public}d
%s _configureAudioConverter: final framesPerBuffer: %{public}u
%s _configureAudioConverter: _convertPacketCount: %{public}u
%s _configureAudioConverter: AudioConverterGetProperty(MaximumOutputPacketSize): returned status %{public}d
%s createAudioConverter: outputSizePerPacket: %{public}u
%s _configureAudioConverter: _convertAudioCapacity %{public}u bytes
%s Cannot create AudioConverter using AudioConverterNew : %{public}u
%s Cannot set encoder bit rate : %{public}u
%s Get initial state from MediaRemote: media is on playing state %{public}ld.
%s Start monitoring MediaRemote: media playback
%s Stop monitoring MediaRemote: media playback
%s MediaRemote reported the now playing app playback state changed to %s (state %d)
%s Turn on AP mode since device is hands free state
%s CommandControl Streaming = %{public}d
%s Turn on AP mode since command control is streaming
%s VoiceTrigger AOP mode cannot be turned on since builtIn speaker is active
%s AudioRecordContext = %{public}@, recordState = RECORDING
%s CarPlay is connected, we will still run AOP mode
%s VoiceTrigger AOP mode cannot be turned on since Siri client is recording
%s AOP Listening is disabled
%s Turn on AP mode since siri is in attending state
%s Turn on AP mode since device is in a ringtone, connected, or outgoing call.
%s Speech Detection VAD is not available, we will still running in AOP mode
%s Will notify Siri Client record state change to STOPPED in %{public}f seconds, eventUUID = %{public}@
%s Notifying Siri Client record state change to STOPPED, eventUUID = %{public}@
%s There is no pending event to timeout : pendingRecordingStopUUID = %{public}@, timeoutTargetUUID = %{public}@
%s Replace deviceId(%{public}@) to nil for VoiceTrigger from Gibraltar.
%s network state notify key : %s
%s Start monitoring : network availability
%s Stop monitoring : network availability
%s Network availability changed
%s xpc object should be XPC_TYPE_DICTIONARY
%s xpcObject key or value is NULL
%s Cannot encode key into xpcobject since the key is not NSString class type
%s Meter Providing Request Message has arrived : %{public}lld
%s Unexpected XPC Meter providing request : %{public}lld
%s setMeteringEnabled : %{public}d
%s audioMeterProvider not existing
%s updateMeters
%s power = %{public}f with powerType %{public}u
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
<key>BuildMachineOSBuild</key>
<string>20A241128</string>
<key>CFBundleIdentifier</key>
<string>com.apple.corespeechd</string>
<key>CFBundleName</key>
<string>corespeech daemon</string>
<key>CFBundleSupportedPlatforms</key>
<array>
<string>AppleTVSimulator</string>
</array>
<key>DTCompiler</key>
<string>com.apple.compilers.llvm.clang.1_0</string>
<key>DTPlatformBuild</key>
<string>19L5419b</string>
<key>DTPlatformName</key>
<string>appletvsimulator</string>
<key>DTPlatformVersion</key>
<string>15.4</string>
<key>DTSDKBuild</key>
<string>19L5419b</string>
<key>DTSDKName</key>
<string>appletvsimulator15.4.internal</string>
<key>DTXcode</key>
<string>1330</string>
<key>DTXcodeBuild</key>
<string>13E6049a</string>
<key>MinimumOSVersion</key>
<string>15.4</string>
<key>UIDeviceFamily</key>
<array>
<integer>3</integer>
<integer>5</integer>
</array>
</dict>
</plist>
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
<key>application-identifier</key>
<string></string>
<key>com.apple.airplay.carplayavvc</key>
<true/>
<key>com.apple.assistant.analytics</key>
<true/>
<key>com.apple.assistant.client</key>
<true/>
<key>com.apple.assistant.dictation.prerecorded</key>
<true/>
<key>com.apple.assistant.multiuser.service</key>
<true/>
<key>com.apple.assistant.settings</key>
<true/>
<key>com.apple.avfoundation.allow-system-wide-context</key>
<true/>
<key>com.apple.avfoundation.allows-access-to-device-list</key>
<true/>
<key>com.apple.bluetooth.system</key>
<true/>
<key>com.apple.coreaudio.CanRecordPastData</key>
<true/>
<key>com.apple.coreaudio.CanRecordWithoutSessionActivation</key>
<true/>
<key>com.apple.coreaudio.i-am-siri</key>
<true/>
<key>com.apple.coreaudio.register-internal-aus</key>
<true/>
<key>com.apple.coreduetd.context</key>
<true/>
<key>com.apple.corespeech.cat.xpc</key>
<true/>
<key>com.apple.hid.system.user-access-fast-path</key>
<true/>
<key>com.apple.managedconfiguration.profiled.profile-list-read</key>
<true/>
<key>com.apple.private.DistributedEvaluation.RecordAccess-com.apple.fides.borealis</key>
<true/>
<key>com.apple.private.DistributedEvaluation.RecordAccess-com.apple.fides.phs</key>
<true/>
<key>com.apple.private.ShazamKit</key>
<true/>
<key>com.apple.private.assets.accessible-asset-types</key>
<array>
<string>com.apple.MobileAsset.AdBlockerAssets</string>
<string>com.apple.MobileAsset.VoiceTriggerAssets</string>
<string>com.apple.MobileAsset.VoiceTriggerAssetsIPad</string>
<string>com.apple.MobileAsset.VoiceTriggerAssetsWatch</string>
<string>com.apple.MobileAsset.VoiceTriggerAssetsMarsh</string>
<string>com.apple.MobileAsset.VoiceTriggerAssetsTV</string>
<string>com.apple.MobileAsset.SpeechEndpointAssets</string>
<string>com.apple.MobileAsset.SpeechEndpointAssetsWatch</string>
<string>com.apple.MobileAsset.SpeechEndpointAssetsTV</string>
<string>com.apple.MobileAsset.RaiseToSpeakAssets</string>
<string>com.apple.MobileAsset.VoiceTriggerAssetsMac</string>
<string>com.apple.MobileAsset.SpeakerRecognitionAssets</string>
<string>com.apple.MobileAsset.EmbeddedSpeech</string>
</array>
<key>com.apple.private.attentionawareness</key>
<true/>
<key>com.apple.private.attentionawareness.samplewhileabsent</key>
<true/>
<key>com.apple.private.attribution.implicitly-assumed-identity</key>
<dict>
<key>type</key>
<string>path</string>
<key>value</key>
<string>/System/Library/PrivateFrameworks/CoreSpeech.framework/corespeechd</string>
</dict>
<key>com.apple.private.audio.dark-wake-audio</key>
<true/>
<key>com.apple.private.audio.hal.aop-audio.user-access</key>
<true/>
<key>com.apple.private.audio.notification-wake-audio</key>
<true/>
<key>com.apple.private.audio.suppress-mic-indicator</key>
<true/>
<key>com.apple.private.avfoundation.capture.nonstandard-client.allow</key>
<true/>
<key>com.apple.private.avfoundation.capture.nonstandard-client.allowed-media-types</key>
<dict>
<key>AVMediaTypeMetadataObject</key>
<array>
<string>AVMetadataObjectTypeTrackedFaces</string>
</array>
</dict>
<key>com.apple.private.bmk.allow</key>
<true/>
<key>com.apple.private.coreaudio.viewInterruptorName.allow</key>
<true/>
<key>com.apple.private.corespeech.xpc.remote</key>
<true/>
<key>com.apple.private.corespeechd.activation</key>
<true/>
<key>com.apple.private.healthkit</key>
<true/>
<key>com.apple.private.healthkit.medicaliddata</key>
<true/>
<key>com.apple.private.hid.client.event-monitor</key>
<true/>
<key>com.apple.private.homehubd</key>
<array>
<string>endpoint-read</string>
</array>
<key>com.apple.private.homekit.siri-audio-connection</key>
<true/>
<key>com.apple.private.iokit.darkwake-control</key>
<true/>
<key>com.apple.private.mediaexperience.allowrecordingduringcall</key>
<true/>
<key>com.apple.private.mediasafetynet.exception.announcemessage</key>
<true/>
<key>com.apple.private.mobiletimerd</key>
<true/>
<key>com.apple.private.siri.activation</key>
<true/>
<key>com.apple.private.siri.invoke</key>
<true/>
<key>com.apple.private.speech-model-training</key>
<true/>
<key>com.apple.private.tcc.allow</key>
<array>
<string>kTCCServiceMicrophone</string>
<string>kTCCServiceCamera</string>
</array>
<key>com.apple.private.tcc.manager.access.read</key>
<array>
<string>kTCCServiceAll</string>
</array>
<key>com.apple.proactive.eventtracker</key>
<true/>
<key>com.apple.rootless.storage.CoreSpeech</key>
<true/>
<key>com.apple.security.exception.files.absolute-path.read-only</key>
<array>
<string>/Library/Audio/Tunings/</string>
</array>
<key>com.apple.security.exception.files.home-relative-path.read-only</key>
<array>
<string>/Library/Caches/com.apple.corespeech.cat.xpc/</string>
</array>
<key>com.apple.security.exception.files.home-relative-path.read-write</key>
<array>
<string>/Library/VoiceTrigger/</string>
<string>/Library/Logs/CrashReporter/Assistant/</string>
<string>/Library/Logs/CrashReporter/VoiceTrigger/</string>
<string>/Library/Logs/CrashReporter/ssr/</string>
<string>/Library/Logs/CrashReporter/CoreSpeech/</string>
<string>/Library/Logs/CrashReporter/RTS/</string>
<string>/Library/Caches/VoiceTrigger/</string>
<string>/Library/Caches/com.apple.corespeechd/</string>
<string>/Documents/Logs/CoreSpeech/</string>
</array>
<key>com.apple.security.exception.iokit-user-client-class</key>
<array>
<string>AppleSPUHIDDriverUserClient</string>
<string>IOHIDEventServiceFastPathUserClient</string>
<string>AGXDeviceUserClient</string>
<string>IOSurfaceRootUserClient</string>
<string>AGXSharedUserClient</string>
<string>AGXCommandQueue</string>
<string>AGXDevice</string>
<string>H11ANEInDirectPathClient</string>
</array>
<key>com.apple.security.exception.mach-lookup.global-name</key>
<array>
<string>com.apple.carousel.backlightxpc</string>
<string>com.apple.usernotifications.usernotificationservice</string>
<string>com.apple.frontboard.systemappservices</string>
<string>com.apple.assistant.settings</string>
<string>com.apple.MobileTimer.timerserver</string>
<string>com.apple.MobileTimer.alarmserver</string>
<string>com.apple.audio.voicetrigger.xpc</string>
<string>com.apple.audio.AudioComponentRegistrar</string>
<string>com.apple.voicetrigger.voicetriggerservice</string>
<string>com.apple.audio.AudioQueueServer</string>
<string>com.apple.server.bluetooth</string>
<string>com.apple.SystemConfiguration.NetworkInformation</string>
<string>com.apple.mediaremoted.xpc</string>
<string>com.apple.coremedia.carplayavvc.xpc</string>
<string>com.apple.iohideventsystem</string>
<string>com.apple.siri.activation</string>
<string>com.apple.siri.activation.horseman</string>
<string>com.apple.siri.activation.blackbird</string>
<string>com.apple.assistant.analytics</string>
<string>com.apple.audio.SystemSoundServer-iOS</string>
<string>com.apple.BTLEAudioController.xpc</string>
<string>com.apple.healthd.server</string>
<string>com.apple.SystemConfiguration.configd</string>
<string>com.apple.managedconfiguration.profiled</string>
<string>com.apple.locationd.registration</string>
<string>com.apple.backlightd</string>
<string>com.apple.carousel.wakegesturemonitor</string>
<string>com.apple.homekit.audio.xpc</string>
<string>com.apple.SBUserNotification</string>
<string>com.apple.nsurlsessiond.NSURLSessionProxyService</string>
<string>com.apple.nsurlstorage-cache</string>
<string>com.apple.commcenter.xpc</string>
<string>com.apple.mediasafetynet.exceptions</string>
<string>com.apple.symptom_diagnostics</string>
<string>com.apple.corespeech.mockremoteplugin.xpc</string>
<string>com.apple.systemstatus.activityattribution</string>
<string>com.apple.assistant.multiuser.service</string>
<string>com.apple.callkit.callcontrollerhost</string>
<string>com.apple.siri.morphunassetsupdaterd</string>
<string>com.apple.homehubd.manage</string>
<string>com.apple.AttentionAwareness</string>
<string>com.apple.corespeech.speechmodeltraining.xpc</string>
<string>com.apple.siri.analytics.assistant</string>
<string>com.apple.remoted</string>
<string>com.apple.PairingManager</string>
</array>
<key>com.apple.security.exception.shared-preference.read-only</key>
<array>
<string>com.apple.assistant</string>
<string>com.apple.nano</string>
<string>com.apple.raisetospeak</string>
<string>com.apple.assistant.backedup</string>
<string>com.apple.assistant.support</string>
<string>com.apple.CoreMotion</string>
<string>com.apple.airplay</string>
<string>com.apple.mediaremote</string>
</array>
<key>com.apple.security.exception.shared-preference.read-write</key>
<array>
<string>com.apple.niservices</string>
<string>com.apple.voicetrigger</string>
<string>com.apple.voicetrigger.notbackedup</string>
<string>com.apple.avfoundation.avvc</string>
<string>com.apple.audio.virtualaudio</string>
<string>com.apple.speakerrecognition</string>
<string>com.apple.coreaudio</string>
<string>com.apple.coremedia</string>
<string>com.apple.raisetospeak</string>
</array>
<key>com.apple.security.exception.sysctl.read-only</key>
<array>
<string>net.routetable.0.0.3.0</string>
</array>
<key>com.apple.security.ts.ane-client</key>
<true/>
<key>com.apple.security.ts.mobile-keybag-access</key>
<true/>
<key>com.apple.security.ts.play-audio</key>
<true/>
<key>com.apple.security.ts.play-media</key>
<true/>
<key>com.apple.security.ts.power-assertions</key>
<true/>
<key>com.apple.sensorkit.writer.allow</key>
<array>
<string>com.apple.SensorKit.speechMetrics.siri</string>
<string>com.apple.SensorKit.speechEmotion.siri</string>
<string>com.apple.SensorKit.soundDetection.siri</string>
</array>
<key>com.apple.siri.activation</key>
<true/>
<key>com.apple.siri.embeddedspeech</key>
<true/>
<key>com.apple.siri.external_request</key>
<true/>
<key>com.apple.systemstatus.activityattribution</key>
<true/>
<key>com.apple.systemstatus.publisher.domains</key>
<array>
<string>media</string>
</array>
<key>com.apple.trial.client</key>
<array>
<string>200</string>
<string>322</string>
<string>404</string>
<string>372</string>
<string>401</string>
<string>751</string>
<string>757</string>
</array>
<key>com.apple.voicetrigger.voicetriggerservice</key>
<true/>
<key>keychain-access-groups</key>
<array>
<string>com.apple.corespeech</string>
</array>
<key>platform-application</key>
<true/>
<key>seatbelt-profiles</key>
<array>
<string>temporary-sandbox</string>
</array>
</dict>
</plist>
33s@
fff?
xeps
supo
333333
333333
