init
dealloc
initWithBlob:
processAudioChunk:
reset
.cxx_destruct
activeChannel
setActiveChannel:
delegate
setDelegate:
_currentBlob
_activeChannel
_delegate
startRecordingHostTime
initWithStreamID:atStartHostTime:
avvcAlertBehavior
numberWithInt:
objectForKeyedSubscript:
unsignedIntegerValue
setStartAlert:
setStopAlert:
setStopOnErrorAlert:
dictionary
requestHistoricalAudioDataWithHostTime
numberWithUnsignedLongLong:
setObject:forKey:
_alertBehaviorTypeFromAVVCOberrideType:
setStartAlertBehavior:
setStopAlertBehavior:
setErrorAlertBehavior:
startAlertBehavior
_avvcAlertOverrideType:
stopAlertBehavior
errorAlertBehavior
numberWithInteger:
avvcStartRecordSettingsWithAudioStreamHandleId:
avvcSettings
setAVVCAlertBehavior:
_handleListenerEvent:
_handleListenerError:
xpcObject
_sendMessage:connection:completion:
connect
notifyActivationEvent:completion:
xpcConnection
setXpcConnection:
_xpcConnection
hostTimeFromSampleCount:anchorHostTime:anchorSampleCount:
sampleCountFromHostTime:anchorHostTime:anchorSampleCount:
sharedInstance
processSampleCount:hostTime:
hostTimeFromSampleCount:
sampleCountFromHostTime:
queue
setQueue:
anchorSampleCount
setAnchorSampleCount:
anchorHostTime
setAnchorHostTime:
_queue
_anchorSampleCount
_anchorHostTime
lpcmNarrowBandASBD
lpcmASBD
initWithInASBD:outASBD:
_createSampleRateConverterWithInASBD:outASBD:
length
dataWithLength:
mutableBytes
bytes
setLength:
upsampler
downsampler
convertSampleRateOfBuffer:
_sampleRateConverter
_outBufferScaleFactor
_inASBD
_outASBD
fetchVolumeFromAVSystemControllerForAudioCategory:
_startObservingSystemControllerLifecycle
startObservingSystemVolumes
defaultCenter
removeObserver:
isEqualToString:
_startMonitoringWithQueue:
musicVolume
musicVolumeWithCompletion:
alarmVolume
systemVolumeDidChange:
systemControllerDied:
_musicVolumeLevel
_alarmVolumeLevel
initWithBytes:length:
subdataWithRange:
dataWithCapacity:
appendData:
initWithData:numChannels:numSamples:sampleByteDepth:startSampleCount:hostTime:remoteVAD:
numSamples
subChunkFrom:numSamples:
remoteVADDuration
inputRecordingSampleRate
initWithXPCObject:
dataForChannel:
dataWithRemoteVADWithScaleFactor:numAudioSamplesPerRemoteVAD:
remoteVADAvailable
subChunkFrom:numSamples:forChannel:
skipSamplesAtStartSuchThatNumSamplesReceivedSoFar:reachesACountOf:completionHandler:
splitAudioChunkSuchThatNumSamplesReceivedSoFar:reachesACountOf:completionHandler:
splitRemoteVADFrom:numSamples:
data
numChannels
sampleByteDepth
startSampleCount
hostTime
remoteVAD
setRemoteVAD:
_data
_numChannels
_numSamples
_sampleByteDepth
_startSampleCount
_hostTime
_remoteVAD
audioStream
stopAudioStreamWithOption:completion:
_handleSetCurrentConextMessage:messageBody:client:
_handleAudioStreamRequestMessage:messageBody:client:
_handleAudioStreamPrepareMessage:messageBody:client:
_handleStartAudioStreamMessage:messageBody:client:
_handleStopAudioStreamMessage:messageBody:client:
_handleVoiceTriggerInfoMessage:messageBody:client:
_handleIsRecordingMessage:messageBody:client:
_handleRecordRouteMessage:messageBody:client:
_handleRecordDeviceInfo:messageBody:client:
_handleRecordSettings:messageBody:client:
_handleIsNarrowband:messageBody:client:
_handlePlaybackRouteMessage:messageBody:client:
audioStreamProviding
_sendReply:client:result:error:
setRecordContext:
setCurrentContext:error:
audioStreamWithRequest:streamName:error:
setAudioStream:
localizedDescription
streamRequest
prepareAudioStreamSync:request:error:
notifyWillStartStreamWithContext:option:
notifyDidStartStreamWithContext:successfully:option:
startAudioStream:option:completion:
notifyWillStopStream:
notifyDidStopStream:
stopAudioStream:option:completion:
voiceTriggerInfo
setLastVoiceTriggerInfo:
rtsTriggerInfo
setLastRTSTriggerInfo:
lastVoiceTriggerInfo
_cs_xpcObject
lastRTSTriggerInfo
isRecording
recordRoute
UTF8String
recordDeviceInfo
recordSettings
isNarrowBand
playbackRoute
_sendDelegateMessageToClient:
sendMessageToClient:
isEqual:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
description
debugDescription
handleXPCMessage:messageBody:client:
CSXPCConnectionReceivedClientError:clientError:client:
audioStreamProvider:didStopStreamUnexpectly:
audioStreamProvider:audioBufferAvailable:
audioStreamProvider:audioChunkForTVAvailable:
audioStreamProvider:didHardwareConfigurationChange:
initWithXPCConnection:
setAudioStreamProviding:
voiceTriggerInfoProviding
setVoiceTriggerInfoProviding:
recordContext
_audioStreamProviding
_voiceTriggerInfoProviding
_audioStream
_lastVoiceTriggerInfo
_lastRTSTriggerInfo
_recordContext
utteranceFileASBD
_closeAudioFile
fileURLWithPath:isDirectory:
startRecording
appendAudioData:
stopRecording
_audioFile
_asbd
_url
_audioLength
weakObjectsHashTable
_deregisterAudioSessionNotifications
addObject:
count
_startMonitoring
removeObject:
_stopMonitoring
opaqueSessionID
countByEnumeratingWithState:objects:count:
audioSessionInfoProvider:didReceiveAudioSessionMediaServicesWereLostNotificationWithUserInfo:
_registerAudioSessionNotifications
audioSessionInfoProvider:didReceiveAudioSessionMediaServicesWereResetNotificationWithUserInfo:
addObserver:
removeObserver:name:object:
_handleInterruption:
addObserver:selector:name:object:
_audioRouteChanged:
audioSessionInfoProvider:didReceiveAudioSessionInterruptionNotificationWithUserInfo:
userInfo
audioSessionInfoProvider:didReceiveAudioSessionRouteChangeNotificationWithUserInfo:
_registerInterruptionNotification
_registerAudioRouteChangeNotification
registerObserver:
unregisterObserver:
audioSessionID
CSAudioServerCrashMonitorDidReceiveServerCrash:
CSAudioServerCrashMonitorDidReceiveServerRestart:
sessionInfoQueue
setSessionInfoQueue:
observers
setObservers:
_sessionInfoQueue
_observers
_sharedAudioLoggingQueue
fileURL
URLByDeletingLastPathComponent
path
sharedPreferences
assistantAudioFileLogDirectory
containsString:
defaultManager
removeItemAtURL:error:
inputRecordingNumberOfChannels
inputRecordingSampleByteDepth
seekToEndOfFile
seekToFileOffset:
readDataOfLength:
getBytes:length:
initWithData:encoding:
offsetInFile
writeData:
fileLoggingIsEnabled
_createAudioFileWriterWithLoggingDir:inputFormat:outputFormat:
_getDateLabel
stringWithFormat:
stringByAppendingPathComponent:
fileURLWithPath:
getNumElementInBitset:
lpcmNonInterleavedASBDWithSampleRate:numberOfChannels:
lpcmInterleavedASBDWithSampleRate:numberOfChannels:
initWithURL:inputFormat:outputFormat:channelBitset:
maxNumLoggingFiles
pruneNumberOfLogFilesTo:
URLWithString:
initWithURL:inputFormat:outputFormat:
localeWithLocaleIdentifier:
setLocale:
setDateFormat:
stringFromDate:
removeLogFilesInDirectory:matchingPattern:beforeDays:
arrayWithObjects:
clearLogFilesInDirectory:matchingPattern:exceedNumber:
isAttentiveSiriAudioLoggingEnabled
assistantLogDirectory
fileExistsAtPath:isDirectory:
removeItemAtPath:error:
createDirectoryAtPath:withIntermediateDirectories:attributes:error:
generateDeviceAudioLogging:speechId:
_readDataFromFileHandle:toFileHandle:
createAudioFileWriterForRemoteVADWithInputFormat:outputFormat:
createAudioFileWriterFromWithInputFormat:outputFormat:
createSelectiveChannelAudioFileWriterWithChannelBitset:
removeLogFilesOlderThanNDays:
audioFileWriterForAttentiveSiri
setObject:forKeyedSubscript:
integerValue
didTransitFrom:to:by:
didIgnoreEvent:from:
initWithInitialState:
addTransitionFrom:to:for:
performTransitionForEvent:
currentState
initialState
setInitialState:
transitions
setTransitions:
_currentState
_initialState
_transitions
_addSmartSiriVolumeEnabledConditions
_subscribeEventMonitors
subscribeEventMonitor:
getAudioSessionState
addConditions:
sharedConnection
_checkSiriRestrictedOnLockScreen
effectiveBoolValueForSetting:
_notifyObserver:withRestricted:
enumerateObserversInQueue:
notifyObserver:
CSSiriRestrictionOnLockScreenMonitor:didReceiveRestrictionChanged:
_didReceiveRestrictionChanged:
profileConnectionDidReceiveRestrictionChangedNotification:userInfo:
profileConnectionDidReceivePasscodeChangedNotification:userInfo:
profileConnectionDidReceivePasscodePolicyChangedNotification:userInfo:
profileConnectionDidReceiveProfileListChangedNotification:userInfo:
profileConnectionDidReceiveEffectiveSettingsChangedNotification:userInfo:
profileConnectionDidReceiveDefaultsChangedNotification:userInfo:
profileConnectionDidReceiveAppWhitelistChangedNotification:userInfo:
isRestricted
_didReceiveRestrictionChangedInQueue:
_isRestricted
initWithRecordType:deviceId:
contextForServerInvoke
stringWithUTF8String:
recordTypeFromAVVCActivationMode:
copy
setType:
setAlwaysUseRemoteBuiltInMic:
copyWithZone:
setDeviceId:
_createAVVCContextWithType:deviceId:
avvcActivationMode:
type
deviceId
string
recordTypeString:
appendFormat:
contextForHearstVoiceTriggerWithDeviceId:
contextForBuiltInVoiceTrigger
contextForJarvisWithDeviceId:
contextForBTLE
contextForVoiceTriggerTraining
defaultContext
initWithAVVCContext:
avvcContext
alwaysUseRemoteBuiltInMic
_alwaysUseRemoteBuiltInMic
_type
_deviceId
dataWithBytes:length:
array
numberWithUnsignedLong:
dictionaryWithObjects:forKeys:count:
initWithZeroWindowSize:approxAbsSpeechThreshold:numHostTicksPerAudioSample:
filterZerosInAudioPacket:atBufferHostTime:filteredPacket:
endAudioAndFetchAnyTrailingZerosPacket:
metrics
.cxx_construct
_audioZeroFilterImpl
initWithConfigPath:triggerTokens:useKeywordSpotting:
runRecognition
endAudio
_recognizeWavData:length:
triggerConfidence
_previousUtteranceTokens
_triggerTokenList
_useKeywordSpotting
_triggerConfidence
regularExpressionWithPattern:options:error:
firstMatchInString:options:range:
numberOfRanges
rangeAtIndex:
substringWithRange:
assetHashInResourcePath:
start
setCachedAsset:
cachedAsset
defaultFallbackModelIfNil:
_getVoiceTriggerAssetFromAssetManager:
sharedManager
assetForCurrentLanguageOfType:completion:
isEqualAsset:
notifyObservers:
_checkNewAssetAvailablity
CSVoiceTriggerAssetDownloadMonitor:didInstallNewAsset:
CSFirstUnlockMonitor:didReceiveFirstUnlock:
CSLanguageCodeUpdateMonitor:didReceiveLanguageCodeChanged:
getVoiceTriggerAsset:
_cachedAsset
mutedOption
setRequestHistoricalAudioDataWithHostTime:
requestHistoricalAudioDataSampleCount
setRequestHistoricalAudioDataSampleCount:
setStartRecordingHostTime:
startRecordingSampleCount
setStartRecordingSampleCount:
useOpportunisticZLL
setUseOpportunisticZLL:
_requestHistoricalAudioDataWithHostTime
_requestHistoricalAudioDataSampleCount
_useOpportunisticZLL
_startRecordingHostTime
_startRecordingSampleCount
_startAlertBehavior
_stopAlertBehavior
_errorAlertBehavior
_didReceiveMediaserverNotification:
_notifyObserver:withMediaserverState:
notifyAudioServerCrash
_mediaserverdDidRestart
serverState
setServerState:
_serverState
disconnect
_sendMessageAndReplySync:connection:
setAudioSessionProvidingDelegate:
setAudioAlertProvidingDelegate:
_cs_initWithXPCObject:
errorWithDomain:code:userInfo:
initWithAudioStreamProvider:streamName:streamRequest:
name
processInfo
systemUptime
objectForKey:
doubleValue
numberWithDouble:
_handleListenerMessage:
_handleSessionProvidingDelegateMessageBody:
_handleStreamProvidingDelegateMessageBody:
_handleAlertProvidingDelegateMessageBody:
_handleSessionInfoProvidingDelegateMessageBody:
_handleListenerDisconnectedError:
_handleAlertProvidingDelegateDidFinishAlertPlayback:
audioAlertProvidingDelegate
audioAlertProvidingDidFinishAlertPlayback:ofType:error:
_handleSessionProvidingDelegateBeginInterruption:
_handleSessionProvidingDelegateBeginInterruptionWithContext:
_handleSessionProvidingDelegateEndInterruption:
_handleSessionProvidingDelegateWillSetAudioSession:
_handleSessionProvidingDelegateDidSetAudioSession:
_handleSessionProvidingDelegateStreamHandleIdInvalidation:
audioSessionProvidingDelegate
audioSessionProviderBeginInterruption:
audioSessionProviderBeginInterruption:withContext:
audioSessionProviderEndInterruption:
audioSessionProvider:willSetAudioSessionActive:
audioSessionProvider:didSetAudioSessionActive:
audioSessionProvider:providerInvalidated:
_handleSessionInfoProvidingDelegateInterruptionNotification:
_handleSessionInfoProvidingDelegateRouteChangeNotification:
_handleSessionInfoProvidingDelegateMediaServicesWereLostNotification:
_handleSessionInfoProvidingDelegateMediaServicesWereResetNotification:
_handleStreamProvidingDelegateDidStopUnexpectly:
_handleStreamProvidingDelegateChunkAvailable:
_handleStreamProvidingDelegateChunkForTVAvailable:
_handleStreamProvidingDelegateHardwareConfigChange:
setAudioSessionDelegate:
prewarmAudioSessionWithError:
activateAudioSessionWithReason:error:
deactivateAudioSession:error:
duckOthersOption
setDuckOthersOption:
enableMiniDucking:
audioStreamWithRequest:streamName:completion:
prepareAudioStream:request:completion:
audioChunkFrom:to:
audioChunkToEndFrom:
saveRecordingBufferFrom:to:toURL:
saveRecordingBufferToEndFrom:toURL:
holdAudioStreamWithDescription:timeout:
cancelAudioStreamHold:
setAudioAlertDelegate:
setAlertSoundFromURL:forType:
playAlertSoundForType:
playRecordStartingAlertAndResetEndpointer
alertStartTime
configureAlertBehavior:
setMeteringEnabled:
updateMeters
peakPowerForChannel:
averagePowerForChannel:
audioMetric
getEstimatedTTSVolume
updateMusicVolume:
updateAlarmVolume:
updateAlarmState:
updateTimerState:
prepareAudioProviderWithContext:error:
pingpong:
voiceTriggerInfo:
enableVoiceTrigger:withAssertion:
audioStreamProvidingDelegate
setAudioStreamProvidingDelegate:
activationAssertions
setActivationAssertions:
audioSessionInfoObservers
setAudioSessionInfoObservers:
_audioSessionProvidingDelegate
_audioStreamProvidingDelegate
_audioAlertProvidingDelegate
_activationAssertions
_audioSessionInfoObservers
receiveOpportuneSpeakListenerStart
receiveOpportuneSpeakListenerStop
startListenWithOption:completion:
stopListenWithCompletion:
opportuneSpeakListener:hasRemoteVADAvailable:
opportuneSpeakListener:hasVADAvailable:
opportuneSpeakListener:didStopUnexpectly:
_notifyToken
listener
initializeTimerState
timerState
_timerFiringState
_checkPhraseSpotterEnabled
_notifyObserver:withEnabled:
CSPhraseSpotterEnabledMonitor:didReceiveEnabled:
phraseSpotterEnabled
_didReceivePhraseSpotterSettingChangedInQueue:
isEnabled
_phraseSpotterEnabledDidChange
_isPhraseSpotterEnabled
voiceTriggerAssetHandler:didChangeCachedAsset:
sharedHandler
inputRecordingSampleRateNarrowBand
inputRecordingBytesPerPacket
inputRecordingFramesPerPacket
inputRecordingBytesPerFrame
inputRecordingSampleBitDepth
lpcmInt16ASBD
lpcmInt16NarrowBandASBD
opusASBD
opusNarrowBandASBD
lpcmInterleavedASBD
lpcmInterleavedWithRemoteVADASBD
lpcmNonInterleavedASBD
lpcmNonInterleavedWithRemoteVADASBD
aiffFileASBD
spIdSATModelDirForLocale:spidType:
createDirectoryIfDoesNotExist:
spIdSATAudioDirForLocale:spidType:
spIdSATModelDirForLocale:profileId:spidType:
utteranceDirectory
contentsOfDirectoryAtPath:error:
predicateWithFormat:
filteredArrayUsingPredicate:
caseInsensitiveCompare:
sortedArrayUsingSelector:
modelPath
fileExistsAtPath:
_isDirectoryEmpty:
initWithSpeakerModelFileName:languageCode:
tiModelPath
tdtiModelPath
tdtiUtteranceDirectory
tiUtteranceDirectory
enrollmentUtterance
needsRetrain
discard
isValid
_modelFileName
_languageCode
_modelPath
_utteranceDirectory
_tdtiModelPath
_tdtiUtteranceDirectory
_tiModelPath
_tiUtteranceDirectory
setName:
_name
getNumberForKey:category:default:
unsignedLongLongValue
numberWithUnsignedInt:
unsignedIntValue
numberWithFloat:
floatValue
SSVNoiseLevelChannelBitset
SSVLKFSChannelBitset
SSVEnergyBufferSize
SSVNoiseLowerPercentile
SSVNoiseUpperPercentile
SSVLKFSLowerPercentile
SSVLKFSUpperPercentile
SSVNoiseTimeConstant
SSVNoiseMicSensitivityOffset
SSVLKFSTimeConstant
SSVLKFSMicSensitivityOffset
SSVNoiseTTSMappingInputRangeLow
SSVNoiseTTSMappingInputRangeHigh
SSVNoiseTTSMappingOutputRangeLow
SSVNoiseTTSMappingOutputRangeHigh
SSVLKFSTTSMappingInputRangeLow
SSVLKFSTTSMappingInputRangeHigh
SSVLKFSTTSMappingOutputRangeLow
SSVLKFSTTSMappingOutputRangeHigh
SSVUserOffsetInputRangeLow
SSVUserOffsetInputRangeHigh
SSVUserOffsetOutputRangeLow
SSVUserOffsetOutputRangeHigh
SSVTTSVolumeLowerLimitDB
SSVTTSVolumeUpperLimitDB
SSVNoiseWeight
SSVParameterDirectionary
containsValueForKey:
decodeObjectForKey:
encodeObject:forKey:
stringByAppendingString:
base64EncodedStringWithOptions:
substringToIndex:
supportsSecureCoding
encodeWithCoder:
initWithCoder:
initWithData:hash:locale:digest:signature:certificate:
initWithHash:locale:
initWithData:hash:locale:
builtInRTModelDictionary
modelData
modelLocale
modelHash
digest
signature
certificate
_modelData
_modelLocale
_modelHash
_digest
_signature
_certificate
UUID
UUIDString
audioRecorder
audioStreamHandleId
isRecordingWithStreamHandleId:
setCurrentContext:streamHandleId:error:
sampleCount
setLastForwardedSampleCount:
_prepareAudioStreamSync:request:error:
requiresHistoricalBuffer
historicalBufferRequestStreams
_createCircularBufferIfNeeded
_audioStreamWithRequest:streamName:error:
setStreamRequest:
_streamStateName:
_handleAudioSystemFailure
prepareAudioStreamRecord:streamHandleId:error:
voiceTriggerInCoreSpeech
setVoiceTriggerInfo:
inputRecordingDurationInSecs
initWithNumChannels:recordingDuration:samplingRate:
_startAudioStream:option:completion:
_prepareAudioStream:request:completion:
_didPlayStartAlertSoundForSiri:audioStream:
alertPlaybackFinishWaitingStreams
alertPlaybackFinishWaitingCompletions
_scheduleAlertFinishTimeout:
startPendingStreams
pendingStartCompletions
passThroughVoiceTriggerInfo
_holdRecordingTransactionIfNeeded
initWithSampleRate:
recordingSampleRateWithStreamHandleId:
resetWithSampleRate:containsVoiceTrigger:voiceTriggerInfo:
startAudioStreamWithOption:streamHandleId:error:
supportOpportunisticZLL
streams
removeAllObjects
_releaseRecordingTransactionIfNeeded
flush
stopPendingStreams
pendingStopCompletions
_stopAudioStream:option:completion:
_shouldStopRecording
stopAudioStreamWithStreamHandleId:error:
_audioChunkFrom:to:
copySamplesFrom:to:
_saveRecordingBufferFrom:to:toURL:
streamHolders
containsObject:
recordRouteWithStreamHandleId:
recordDeviceInfoWithStreamHandleId:
recordSettingsWithStreamHandleId:
setSessionDelegate:
prewarmAudioSessionWithStreamHandleId:error:
_activateAudioSessionWithReason:error:
activateAudioSessionWithReason:streamHandleId:error:
_deactivateAudioSession:error:
deactivateAudioSession:streamHandleId:error:
setAlertDelegate:
willBeep
_processAudioBuffer:remoteVAD:atTime:
_handleDidStartAudioStreamWithResult:error:
_handleDidStopAudioStreamWithReason:
sessionDelegate
addSamples:numSamples:atHostTime:
bufferLength
lastForwardedSampleCount
processBuffer:atTime:
audioInjectionEnabled
isNarrowBandWithStreamHandleId:
_didReceiveFinishStartAlertPlaybackAt:
alertDelegate
willDestroy
numberWithUnsignedInteger:
initWithDescription:
isSessionCurrentlyActivated
audioRecorderBufferAvailable:audioStreamHandleId:buffer:remoteVAD:atTime:
audioRecorderBufferAvailable:audioStreamHandleId:buffer:
audioRecorderDidStartRecord:audioStreamHandleId:successfully:error:
audioRecorderDidStopRecord:audioStreamHandleId:reason:
audioRecorderRecordHardwareConfigurationDidChange:toConfiguration:
audioRecorderDidFinishAlertPlayback:ofType:error:
audioRecorderBeginRecordInterruption:
audioRecorderBeginRecordInterruption:withContext:
audioRecorderEndRecordInterruption:
audioRecorder:willSetAudioSessionActive:
audioRecorder:didSetAudioSessionActive:
voiceTriggerDetectedOnAOP:
audioRecorderDisconnected:
audioRecorderLostMediaserverd:
audioRecorderWillBeDestroyed:
audioRecorderBuiltInAudioStreamInvalidated:error:
audioRecorderStreamHandleIdInvalidated:
audioPreprocessor:hasAvailableBuffer:atTime:
voiceTriggerDidDetectKeyword:deviceId:
voiceTriggerDidDetectNearMiss:
voiceTriggerDidDetectSpeakerReject:
keywordDetectorDidDetectKeyword
voiceTriggerGotSuperVector:
raiseToSpeakDetected:
initWithAudioStreamHandleId:audioRecorder:
setAudioRecorder:
_tearDownCircularBufferIfNeeded
recordQueue
setRecordQueue:
streamState
setStreamState:
setStartPendingStreams:
setAlertPlaybackFinishWaitingStreams:
setStreams:
setStopPendingStreams:
setPendingStartCompletions:
setAlertPlaybackFinishWaitingCompletions:
setPendingStopCompletions:
setStreamHolders:
setHistoricalBufferRequestStreams:
circularBuffer
setCircularBuffer:
lastAudioRecorderContext
setLastAudioRecorderContext:
audioSystemRecovering
setAudioSystemRecovering:
audioPreprocessor
setAudioPreprocessor:
recordingTransaction
setRecordingTransaction:
setAudioStreamHandleId:
alertPlaybackFinishTimeoutToken
setAlertPlaybackFinishTimeoutToken:
_audioSystemRecovering
_UUID
_recordQueue
_audioRecorder
_streamState
_startPendingStreams
_alertPlaybackFinishWaitingStreams
_streams
_stopPendingStreams
_pendingStartCompletions
_alertPlaybackFinishWaitingCompletions
_pendingStopCompletions
_sessionDelegate
_streamHolders
_historicalBufferRequestStreams
_circularBuffer
_alertDelegate
_lastAudioRecorderContext
_audioPreprocessor
_recordingTransaction
_audioStreamHandleId
_alertPlaybackFinishTimeoutToken
allowVoiceTriggerAssetDownloading
setAllowVoiceTriggerAssetDownloading:
allowEndpointAssetDownloading
setAllowEndpointAssetDownloading:
allowLanguageDetectorAssetDownloading
setAllowLanguageDetectorAssetDownloading:
_allowVoiceTriggerAssetDownloading
_allowEndpointAssetDownloading
_allowLanguageDetectorAssetDownloading
dateWithTimeIntervalSinceNow:
distantFuture
getResourceValue:forKey:error:
compare:
URLsInDirectory:matchingPattern:completion:
objectAtIndex:
_sortedURLsInDirectory:matchingPattern:completion:
_contentsOfDirectoryAtURL:matchingPattern:includingPropertiesForKeys:error:
arrayWithObjects:count:
sortedArrayUsingComparator:
contentsOfDirectoryAtURL:includingPropertiesForKeys:options:error:
lastPathComponent
numberOfMatchesInString:options:range:
predicateWithBlock:
_addVoiceTriggerEnabledConditions
isSpringboardStarted
isFirstUnlocked
batteryState
isScreenLocked
isSoftwareUpdateCheckingRunning
isPresent
initWithConfigPath:resourcePath:
_resetStartAnalyzeTime
resetBest
_setStartAnalyzeTime:
analyzeWavData:numSamples:
getAnalyzedResultForPhraseId:
sampleFed
getAnalyzedResult
keywordAnalyzerNDAPI:hasResultAvailable:forChannel:
initWithResult:
bestStart
setBestStart:
bestEnd
setBestEnd:
mutableCopy
getSuperVectorWithEndPoint:
getOptionValue:
getThreshold
getLoggingThreshold
activePhraseId
setActivePhraseId:
_novDetector
_startAnalyzeSampleCount
_isStartSampleCountMarked
_lastSampleFed
_sampleFedWrapAroundOffset
_activePhraseId
hearstRTModelWithMajorVersion:minorVersion:locale:
resourcePath
dataWithContentsOfFile:
_sha1:
_sha256:
stringWithCapacity:
RTModelWithFallbackLanguage:
latestHearstRTModelForLocale:
hearstRTModelLocaleMap
remoteVoiceActivityAvailable
remoteVoiceActivityVAD
remoteVoiceActivityVADBuffer
_voiceControllerWithError:
_destroyVoiceController
_audioRecorderDidStartRecordingSuccessfully:error:
setRecordDelegate:
initWithError:
setSynchronousCallbackEnabled:
date
avvcContextSettings
setContext:error:
timeIntervalSinceDate:
setContextForStream:forStream:error:
_getRecordSettingsWithRequest:
_createDeInterleaverIfNeeded
inputRecordingBufferDuration
initWithStreamID:settings:bufferDuration:
prepareRecordForStream:error:
_shouldInjectAudio
_needResetAudioInjectionIndex:
audioInjectionFilePath
initWithURL:
setRecordBufferDuration:
lpcmRecordSettings
prepareRecording:
_startAudioStreamForAudioInjection
startRecordForStream:error:
stopRecordForStream:error:
getCurrentSessionState
hasRemoteBuiltInMic
getCurrentStreamState:
getRecordDeviceInfoForStream:
currentRecordDeviceInfo
initWithAVVCRecordDeviceInfo:
getRecordSettingsForStream:
activateAudioSessionForStream:isPrewarm:error:
_convertDeactivateOption:
deactivateAudioSessionWithOptions:
voiceTriggerEventInfo
boolValue
channels
packetDescriptionCount
bytesDataSize
initWithCapacity:
packetDescriptions
setPackets:
setPeakPower:
setAvgPower:
timeStamp
setTimeStamp:
initWithLength:
replaceBytesInRange:withBytes:
_compensateChannelDataIfNeeded:receivedNumChannels:
_processAudioBuffer:audioStreamHandleId:
notifyAduioSessionStateChange:
shouldDeinterleaveAudioOnCS
_processAudioChain:audioStreamHandleId:remoteVAD:atTime:
_audioRecorderDidStopRecordingForReason:
useCustomizedRecordSettings
defaultRequestWithContext:
audioFormat
sampleRate
lpcmBitDepth
lpcmIsFloat
numberWithBool:
numberOfChannels
encoderBitRate
voiceControllerDidStartRecording:successfully:
voiceControllerDidStartRecording:successfully:error:
voiceControllerDidStopRecording:forReason:
voiceControllerDidDetectStartpoint:
voiceControllerDidDetectEndpoint:ofType:
voiceControllerDidDetectEndpoint:ofType:atTime:
voiceControllerEncoderErrorDidOccur:error:
voiceControllerDidFinishAlertPlayback:ofType:error:
voiceControllerRecordHardwareConfigurationDidChange:toConfiguration:
voiceControllerBeginRecordInterruption:
voiceControllerBeginRecordInterruption:withContext:
voiceControllerEndRecordInterruption:
voiceControllerMediaServicesWereLost:
voiceControllerMediaServicesWereReset:
voiceControllerWillSetAudioSessionActive:willActivate:
voiceControllerDidSetAudioSessionActive:isActivated:
voiceControllerRecordBufferAvailable:buffer:
voiceControllerLPCMRecordBufferAvailable:buffer:
voiceControllerWirelessSplitterRouteAvailable:devices:
voiceControllerDidStartRecording:forStream:successfully:error:
voiceControllerDidStopRecording:forStream:forReason:
voiceControllerAudioCallback:forStream:buffer:
voiceControllerStreamInvalidated:forStream:
audioDecoderDidDecodePackets:audioStreamHandleId:buffer:remoteVAD:timestamp:receivedNumChannels:
audioFileReaderBufferAvailable:buffer:atTime:
audioFileReaderDidStartRecording:successfully:error:
audioFileReaderDidStopRecording:forReason:
initWithQueue:error:
_shouldUseRemoteRecordForContext:
_shouldUseRemoteBuiltInMic:
_deinterleaveBufferIfNeeded:
_voiceController
_deinterleaver
_interleavedABL
_pNonInterleavedABL
_remoteRecordClient
_latestContext
_shouldUseRemoteRecord
_opusDecoders
_audioFileReader
_audioFilePathIndex
_waitingForDidStart
initWithAnalyzeMode
_startRequestWithCompletion:
getFrameDurationMs
initializeMediaPlayingState
mediaPlayingState
startAudioStreamWithOption:completion:
audioSessionProvider
stopListenWithStateReset:completion:
channelForProcessedInput
addAudio:numSamples:
CSMediaPlayingMonitor:didReceiveMediaPlayingChanged:
spgEndpointAnalyzer:hasSilenceScoreEstimate:
spgEndpointAnalyzer
setSpgEndpointAnalyzer:
remoteVADSPGRatio
setRemoteVADSPGRatio:
audioStreamProvider
setAudioStreamProvider:
setAudioSessionProvider:
latestContext
setLatestContext:
isMediaPlayingNow
setIsMediaPlayingNow:
_isMediaPlayingNow
_remoteVADSPGRatio
_spgEndpointAnalyzer
_audioStreamProvider
_audioSessionProvider
speakerDetectorThreshold
maxSpeakerVectorsToPersist
_initializeSAT:
addLastTriggerToProfileWithSuperVector:
initWithAsset:speakerModel:
_initializeNDAPI:resourcePath:
getSatThreshold
computeSATScore:
analyzeWavForEnrollment:numSamples:
addLastTriggerToProfile
getSATVectorCount
getMaxSpeakerVectorsToPersist
_threshold
_maxSpeakerVectorsToPersist
_spkModel
CSSiriEnabledMonitor:didReceiveEnabled:
_didReceiveSiriSettingChanged:
_isSiriEnabled
_handleGetTTSVolumeRequestMessage:messageBody:client:
_handleUpdateMusicVolumeRequestMessage:messageBody:client:
_handleUpdateAlarmVolumeRequestMessage:messageBody:client:
_handleUpdateAlarmStateRequestMessage:messageBody:client:
_handleUpdateTimerStateRequestMessage:messageBody:client:
sharedManagerForCoreSpeechDaemon
smartSiriVolume
supportSmartVolume
estimateSoundLevelbySoundType:
estimatedTTSVolumeForNoiseLevelAndLKFS:LKFS:
CSVolumeMonitor:didReceiveMusicVolumeChanged:
CSVolumeMonitor:didReceiveAlarmVolumeChanged:
CSAlarmMonitor:didReceiveAlarmChanged:
CSTimerMonitor:didReceiveTimerChanged:
initWithCSspIdType:userName:assetResourcePath:satDirectory:assetHash:
spIdType
userName
sysConfigFile
sysConfigRoot
satModelDir
satAudioDir
satScoreThreshold
analyzeSpeakerVector:numElements:
updateSAT
profileID
sysConfigFilepath
satScoreVTScale
satScoreVTOffset
satScoreNonVTScale
satScoreNonVTOffset
satLogitCeilScore
satLogitFloorScore
satImplicitBaseProfileThreshold
satImplicitProfileThreshold
satImplicitProfileDeltaThreshold
retrainThresholdTrigger
retrainExplicitUttThresholdSAT
retrainExplicitUttThresholdTDSR
retrainThresholdSAT
retrainThresholdTDSR
pruningNumRetentionUtterance
maximumSpeakerVectors
voiceProfilePruningCookie
_satScoreVTScale
_satScoreVTOffset
_satScoreNonVTScale
_satScoreNonVTOffset
_satLogitCeilScore
_satLogitFloorScore
_retrainThresholdTrigger
_retrainExplicitUttThresholdSAT
_retrainExplicitUttThresholdTDSR
_retrainThresholdSAT
_retrainThresholdTDSR
_pruningNumRetentionUtterance
_maximumSpeakerVectors
_profileID
_sysConfigFilepath
_satImplicitBaseProfileThreshold
_satImplicitProfileThreshold
_satImplicitProfileDeltaThreshold
_voiceProfilePruningCookie
setTriggerMode:
getTriggerMode
mapTableWithWeakToStrongObjects
_handleNewRemoteConnection:
initWithConnection:
activateConnection
removeObjectForKey:
CSActivationXPCConnectionReceivedClientError:clientError:client:
listen
setListener:
connections
setConnections:
_listener
_connections
supportIOSBargeIn
_handleSessionIDRequestMessage:messageBody:client:
audioSessionInfoProvider
setAudioSessionInfoProvider:
_audioSessionInfoProvider
getVoiceTriggerAssetTypeString
getEndpointAssetTypeString
getLanguageDetectorAssetTypeString
_cleanUpMobileAssetV1Directory
_isReadyToUse
installedAssetOfType:withLanguage:
_fetchRemoteAssetOfType:withLanguage:completion:
installedAssetOfType:withLanguage:completion:
_installedAssetOfType:withLanguage:
getCSAssetOfType:
_installedAssetOfType:withLanguage:completion:
_assetQueryForAssetType:
queryMetaDataSync
results
filteredAssetsForAssets:assetType:language:
queryParams
_findLatestInstalledAsset:
_installedAssetWithoutMetaDataForType:withLanguage:
_installedAssetWithoutMetaDataForType:withLanguage:completion:
queryMetaData:
returnTypes:
state
isLatestCompareTo:
attributes
initWithType:
addKeyValuePairForQuery:assetType:
_runAssetQuery:completion:
_downloadAssetCatalogForAssetType:complete:
_updateFromRemoteToLocalAssets:forAssetType:completion:
_defaultDownloadOptions
startCatalogDownload:options:then:
isCSAssetInstalled
isDownloading
cancelDownloadSync
canBePurged
purgeSync
CSAssetController:didDownloadNewAssetForType:
_downloadAsset:withComplete:
setAllowsCellularAccess:
setCanUseLocalCacheServer:
assetServerUrl
_startDownloadingAsset:progress:completion:
expectedTimeRemaining
totalWritten
totalExpected
attachProgressCallBack:
spaceCheck:
startDownload:then:
sharedController
CSEventMonitorDidReceiveEvent:
assetOfType:language:
assetOfType:language:completion:
installedAssetOfType:language:
installedAssetOfType:language:completion:
fetchRemoteMetaOfType:
addObserver:forAssetType:
removeObserver:forAssetType:
_csAssetsDictionary
_assetsMigrationQueue
valueForKey:
supportPremiumAssets
getVoiceTriggerAssetCurrentCompatibilityVersion
getEndpointAssetCurrentCompatibilityVersion
getLanguageDetectorCurrentCompatibilityVersion
addKeyValuePair:with:
filteredAssetsForFetchRemoteMetaDataForAssets:assetType:
isRecordContextVoiceTrigger:
isRecordContextJarvisVoiceTrigger:
isRecordContextHearstDoubleTap:
isRecordContextRaiseToSpeak:
isRecordContextAutoPrompt:
isRecordContextHomeButtonPress:
isRecordContextSpeakerIdTrainingTrigger:
isRecordContextHearstVoiceTrigger:
isRecordContextJarvisButtonPress:
recordContextString:
initWithBool:
initWithDouble:
initWithLongLong:
initWithUnsignedLongLong:
objCType
longLongValue
bestPhrase
bestScore
earlyWarning
setSampleFed:
setBestPhrase:
setBestScore:
setEarlyWarning:
isRescoring
setIsRescoring:
_earlyWarning
_isRescoring
_bestScore
_sampleFed
_bestPhrase
_bestStart
_bestEnd
_setDefaultParameters
_setAsset:
_convertDB2Mag:
_reset
initializeAlarmState
fetchInitSystemVolumes
_resumeSSVProcessing
_pauseSSVProcessing
setCallback:
_startListenPolling
_startListenPollingWithInterval:completion:
isStreaming
_startListenWithCompletion:
corespeechDaemonEnabled
audioProviderWithContext:error:
_stopListening
alarmState
_getMusicVolumeDB:
convertToFloatLPCMBufFromShortLPCMBuf:
iterateBitset:block:
_prepareSoundLevelBufferFromSamples:soundType:
_processAudioChunk:soundType:
_estimatedTTSVolume:lowerLimit:upperLimit:TTSmappingInputRangeLow:TTSmappingInputRangeHigh:TTSmappingOutputRangeLow:TTSmappingOutputRangeHigh:
_combineResultsWithOptimalFromNoise:andOptimalFromLkfs:withUserOffset:
_scaleInputWithInRangeOutRange:minIn:maxIn:minOut:maxOut:
sharedAnalytics
logEventWithType:context:
smartSiriVolumeSoftVolumeEnabled
CSSmartSiriVolumeDidReceiveAlarmChanged:
CSSmartSiriVolumeDidReceiveTimerChanged:
CSSmartSiriVolumeDidReceiveMusicVolumeChanged:
initWithSamplingRate:asset:
startSmartSiriVolume
setAsset:
prepareSoundLevelBufferFromSamples:soundType:firedVoiceTriggerEvent:triggerStartTimeSampleOffset:triggerEndTimeSampleOffset:
listenPollingTimer
setListenPollingTimer:
listenPollingTimerCount
setListenPollingTimerCount:
_smartSiriVolumeNoiseLevel
_smartSiriVolumeLKFS
_floatBuffer
_defaults
_ssvEnablePolicy
_samplesFed
_processedSampleCount
_isListenPollingStarting
_shouldPauseSSVProcess
_shouldPauseLKFSProcess
_alarmSoundIsFiring
_timerSoundIsFiring
_mediaIsPlaying
_currentAsset
_musicVolumeDB
_alarmVolume
_noiseLevelChannelBitset
_LKFSChannelBitset
_energyBufferSize
_noiseLowerPercentile
_noiseUpperPercentile
_LKFSLowerPercentile
_LKFSUpperPercentile
_noiseTimeConstant
_noiseMicSensitivityOffset
_LKFSTimeConstant
_LKFSMicSensitivityOffset
_noiseTTSMappingInputRangeLow
_noiseTTSMappingInputRangeHigh
_noiseTTSMappingOutputRangeLow
_noiseTTSMappingOutputRangeHigh
_LKFSTTSMappingInputRangeLow
_LKFSTTSMappingInputRangeHigh
_LKFSTTSMappingOutputRangeLow
_LKFSTTSMappingOutputRangeHigh
_userOffsetInputRangeLow
_userOffsetInputRangeHigh
_userOffsetOutputRangeLow
_userOffsetOutputRangeHigh
_TTSVolumeLowerLimitDB
_TTSVolumeUpperLimitDB
_noiseWeight
_listenPollingTimer
_listenPollingTimerCount
_addListeningEnabledConditions
getSiriLanguageWithFallback:
_readAudioBufferAndFeed
close
readSamplesFromChannelIdx:
_fFile
_audioFeedTimer
_bufferDuration
appendBytes:length:
writeToFile:atomically:
CSMyriadSelfTriggerCoordinator:didGenerateMyriadPHashForSelfTrigger:
selfTriggerDetector:didDetectSelfTrigger:
initStore
currentLanguageCode
_loadVoiceProfilesForLocale:
retrainVoiceProfilesForLanguage:withForceRetrain:withCompletion:
_trainedUsersForLocale:
siriDebugID
siriProfileId
initWithVoiceProfile:modelType:satRunMode:
spIdSATAudioDirForLocale:profileId:spidType:
getEnrollmentUtterancesCountFromDirectory:withCountBlock:
baseProfileConfidenceScoreThreshold
implicitConfidenceScoreThreshold
implicitDeltaConfidenceScoreThreshold
evaluateSpeakerVector:withVectorSize:forProfile:withBaseThreshold:withImplicitThreshold:withDeltaThreshold:
copyItemAtURL:toURL:error:
moveItemAtURL:toURL:error:
saveUtteranceMetadataForUtterance:enrollmentType:isHandheldEnrollment:triggerSource:audioInput:otherBiometricResult:containsPayload:
incrementVoiceProfileVersionForUpdateType:forVoiceProfile:
processUtterance:ofSpIdType:withUpdatePolicyBlock:withCompletionBlock:
locale
createSATAnalyzersForCSSpIdType:withAsset:
analyzeSpeakerVector:numVectors:
speakerIdScoreReportingType
objectAtIndexedSubscript:
mapRawScores:toScoresOfType:withRawScoreOffset:withRawScoreScale:withLogitCeil:withLogitFloor:withSATThreshold:
_getTopScoringProfileIdFromScores:
enumerateKeysAndObjectsUsingBlock:
voiceProfileFilePath
_getContentsOfDirectory:
stringForCSSpIdType:
copyItemAtPath:toPath:error:
enumerateObjectsUsingBlock:
removeItemAtPath:
URLByAppendingPathComponent:
getExplicitEnrollmentUtterancesFromDirectory:
URLByDeletingPathExtension
URLByAppendingPathExtension:
_importVoiceProfile:forModelType:withContentsOfDirectory:
_updateTrainedUsersWithAction:UserVoiceProfile:
userVoiceProfileForVoiceProfileID:
_retrainExplicitOnlyModelForVoiceProfile:withForceRetrain:
_updateHomeUserId:forProfileWithSiriProfileId:
sendVoiceProfileUpdatedMessageToNearbyPeerForLocale:
getHomeUserIdForSharedUserId:completion:
userVoiceProfilesForLocale:
_retrainVoiceProfile:withForceRetrain:withCompletion:
_retrainVoiceProfile:forModelType:withForceRetrain:
spIdSATDirForLocale:
arrayWithCapacity:
spIdTrainedUsersFilePathForLocale:
initNewVoiceProfileWithLocale:
setDateAdded:
setSiriDebugID:
moveItemAtPath:toPath:error:
JSONObjectWithData:options:error:
initWithDictionary:
getProfileVersionFilePathForProfileId:forLanguageCode:
getVoiceProfileBaseVersionfromVersionFile:
setBaseVersion:
getVoiceProfileImplicitVersionfromVersionFile:
setImplicitVersion:
sharedHomeID
removeObjectAtIndex:
_saveTrainedUsers:forLocale:
dictionaryRepresentation
dataWithJSONObject:options:error:
writeToFile:options:error:
userVoiceProfileForSiriProfileId:
setSharedHomeID:
getExplicitOnlyEnrollmentUtterancesFromDirectory:
_retrainVoiceProfile:forModelType:withUtterances:withForceRetrain:
getEnrollmentUtterancesFromDirectory:
checkIfUpdateNecessaryForAudioFileCount:
addUtterances:withScoreThreshold:withCompletionBlock:
speakerIdiTunesAccountSigninEnabled
addiTunesAccountWithMultiUserToken:withDsid:withAltDsid:withHomeId:withHomeUserId:forProfileId:
userVoiceProfileForSharedSiriDebugID:
addImplicitUtterance:toVoiceProfile:withTriggerSource:withAudioInput:withCompletion:
addUserVoiceProfile:fromUtteranceCache:withCompletion:
deleteUserVoiceProfile:
_migrationAssistantForUserVoiceProfilesForLocale:
addiTunesAccountForVoiceProfile:withMultiUserToken:withDsid:withAltDsid:withHomeId:withHomeUserId:withCompletionBlock:
voiceProfileArray
setVoiceProfileArray:
languageCode
setLanguageCode:
_voiceProfileArray
bundleForClass:
bundlePath
dataWithContentsOfFile:options:error:
zeroFilterWindowSizeInMs
convertToShortLPCMBufFromFloatLPCMBuf:
beepCancellerDidCancelSamples:buffer:timestamp:
cancelBeepFromSamples:timestamp:
_beepCanceller
_beepFloatVec
_shortBuffer
_numTotalInputSamples
_numTotalOutputSamples
_checkSpringBoardStarted
_didReceiveSpringboardStarted:
_notifyObserver:withStarted:
enumerateObservers:
CSSpringboardStartMonitor:didReceiveStarted:
_didReceiveSpringboardStartedInQueue:
_isSpringBoardStarted
strongToWeakObjectsMapTable
_createXPCClientConnectionIfNeeded
_notifyActivationEvent:completion:
_isVoiceTriggerEvent:
activationEventNotifier:event:completion:
initWithType:deviceId:activationInfo:hosttime:
_hasPendingActivationForType:
hosttime
secondsToHostTime:
receiveTestNotificationAPMode
receiveTestNotificationAOPMode
sharedNotifier
sharedNotifierForCoreSpeechDaemon
stop
notifyActivationEventForCoreSpeechDaemon:completion:
notifyActivationEvent:deviceId:activationInfo:completion:
setDelegate:for:
_didReceiveAOPFirstPassTrigger:completion:
_setupTestNotification
notifyToken
setNotifyToken:
delegates
setDelegates:
pendingActivationEvent
setPendingActivationEvent:
pendingCompletion
setPendingCompletion:
activationXPCClient
setActivationXPCClient:
_delegates
_pendingActivationEvent
_pendingCompletion
_activationXPCClient
_alarmFiringState
processImplicitTrainingUtterance:forVoiceProfileId:withMetaInfo:withCompletion:
setRecordingContext:
startRecordingImplicitTrainingUtteranceWithVoiceTriggerEventInfo:
recordingStoppedForReason:
_checkFirstUnlocked
_notifyObserver:withUnlocked:
_didReceiveFirstUnlockInQueue:
_didReceiveFirstUnlock:
_firstUnlocked
initWithUTF8String:
saveMetadata:isExplicitEnrollment:
saveUtterance:utteranceAudioPath:numSamplesToWrite:isExplicitEnrollment:
addSamples:numSamples:
stringByReplacingOccurrencesOfString:withString:
_getBaseMetaDictionaryForUtterancePath:
dictionaryWithDictionary:
timeStampWithSaltGrain
writeMetaDict:atMetaPath:
deviceProductType
deviceProductVersion
saveRawUtteranceAndMetadata:to:isExplicitEnrollment:
saveUtteranceAndMetadata:atDirectory:isExplicitEnrollment:
cleanupInvalidSATEntriesAtSATRoot:payloadUtteranceLifeTimeInDays:dryRun:
initWithArray:
packets
avgPower
peakPower
_avgPower
_peakPower
_packets
_timeStamp
initWithUUIDString:
initWithFormat:
decodeObjectOfClass:forKey:
initWithRoute:isRemoteDevice:remoteDeviceUID:remoteDeviceProductIdentifier:
isRemoteDevice
remoteDeviceUID
remoteProductIdentifier
route
remoteDeviceProductIdentifier
_isRemoteDevice
_route
_remoteDeviceUID
_remoteDeviceProductIdentifier
initWithFilepath:
isWriting
fFile
inASBD
outASBD
_fileURL
setStreamProvider:
setStreaming:
stringByAppendingFormat:
streamProvider
streaming
prepareAudioStreamSyncWithRequest:error:
prepareAudioStreamWithRequest:completion:
_streaming
_lastForwardedSampleCount
_streamRequest
_streamProvider
_asssetMetaUpdatedKey
_didReceiveNewVoiceTriggerAssetMetaData
_notifyObserver:
CSVoiceTriggerAssetMetaUpdateMonitor:didReceiveNewVoiceTriggerAssetMetaData:
initWithCSspIdType:withSysConfigFile:sysConfigRoot:delegate:
processAudioData:
supportZeroFilter
supportBeepCanceller
resetWithSampleRate:
initWithToken:sampleRate:numChannels:
setSampleRate:
_isNarrowBand:
setUpsampler:
zeroFilter
beepCanceller
getZeroStatisticsFromBuffer:entireSamples:
_reportMetrics
stopReportZeroStatistics
zeroFilter:zeroFilteredBufferAvailable:atHostTime:
setZeroFilter:
setBeepCanceller:
zeroCounter
setZeroCounter:
_sampleRate
_upsampler
_zeroFilter
_zeroCounter
_logUptime
systemUpTime
_makeKeyWithLanguageAndAssetString:
_pushValueForDistributionKey:withValue:
_addValueForScalarKey:withValue:
_makeKey:
sharedAggregator
cumulativeUptime:cumulativeDowntime:reset:
setAssetString:
logVoiceProfilePruningFailureWithReasonCode:
logProfileUpdateScoreMSE:
logTdPsrSATRetrainingTimedOut
logTdPsrSATRetrainingWaitTimeMs:
logProfileUpdateNumPrunedUttsPHS:
logProfileUpdateNumDiscardedUttsPHS:
logProfileUpdateNumRetainedUttsPHS:
logProfileUpdateUtt:withScore:
_lastAggTime
_cumulativeUptime
_cumulativeDowntime
_lastAggTimeFalseWakeUp
_numFalseWakeUp
_timer
_assetString
_writeMetaDict:forUtterancePath:
_saveMetaVersionFileAtPath:
_upgradeLocaleDirectoryIfNecessary:
writeToURL:atomically:
_audioDirectoryNeedsUpgrade:
absoluteString
pathExtension
_upgradeUtteranceMeta:
dataWithContentsOfURL:
stringByDeletingPathExtension
stringByAppendingPathExtension:
dateFromString:
saveMetaVersionFileAtSATAudioDirectory:
upgradeMetaFilesIfNecessaaryAtSATRoot:
isUtteranceImplicitlyTrained:
getUtteranceEnrollmentType:
recordedTimeStampOfFile:
_didReceiveNewSpeechEndpointAssetMetaData
CSSpeechEndpointAssetMetaUpdateMonitor:didReceiveNewSpeechEndpointAssetMetaData:
baseDir
initWithSharedSiriId:languageCode:productCategory:version:sharedHomeId:userName:
profileId
setProfileId:
productCategory
setProductCategory:
version
setVersion:
onboardType
setOnboardType:
homeId
setHomeId:
setUserName:
baseVersion
implicitVersion
siriDebugProfileId
setSiriDebugProfileId:
_profileId
_productCategory
_version
_onboardType
_homeId
_userName
_baseVersion
_implicitVersion
_siriDebugProfileId
_handleClientEvent:client:
_handleClientMessage:client:
_handleClientError:client:
processSingleUserImplicitTrainingUtterance:audioDeviceType:audioRecordType:withVoiceTriggerCtxt:withCompletion:
connection
setConnection:
_connection
deviceCategoryForDeviceProductType:
setCurrentDeviceCategory:
processImplicitTrainingUtterance:forVoiceProfileId:withRecordDeviceInfo:withRecordCtxt:withVoiceTriggerCtxt:withOtherCtxt:withCompletion:
_createAndSendImplicitUtterenceXPCMessage:withRecordDeviceInfo:withRecordCtxt:withVoiceTriggerCtxt:withCompletion:
_CSSATDownloadPath
_getUserVoiceProfileDownloadCacheDirectoryWithUpdatePath:
_downloadAndEnrollVoiceProfileForProfileId:withDownloadTriggerBlock:
CSSATBasePath
isSATEnrolledForLanguageCode:
isCurrentDeviceCompatibleWithVoiceProfileAt:
spIdSATDirForLocale:profileId:spidType:
_markSATEnrollmentSuccessForSiriProfileId:forLanguageCode:
_markSATEnrollmentMigratedForSiriProfileId:forLanguageCode:
_enrollVoiceProfileForSiriProfileId:fromCacheDirectoryPath:
_downloadVoiceProfileForProfileId:forDeviceCategory:withDownloadTriggerBlock:withCompletion:
deviceCategoryStringRepresentationForCategoryType:
_getUserVoiceProfileDownloadCacheDirectoryForProfileId:forDeviceCategory:forVoiceProfileVersion:
_checkIfProfileNeedsUpdateForSiriProfileId:forLanguage:fromSourceDir:
_enrollVoiceProfileForSiriProfileId:forLanguage:fromSourceDir:
_copyVoiceProfileFromSrcDir:toDestDir:
_markVoiceProfileMigrationCompleteForSiriProfileId:forLanguageCode:
_enableVoiceTriggerIfLanguageMatches:
isCurrentDeviceCompatibleWithNewerVoiceProfileAt:
_prepareVoiceProfilesForUpload:
_CSSATUploadPath
_CSSATLegacyUploadPath
enumeratorAtURL:includingPropertiesForKeys:options:errorHandler:
getCurrentVoiceProfileVersionForProfileId:forLanguageCode:
spIdSATDirForLocale:profileId:
enumeratorAtPath:
_isDirectory:
_getVoiceProfilePathsToBeUploaded
_copyVoiceProfileAtPath:toPath:
getDevicesWithAvailablePHSAssetsOnDeviceCheck:
devicesWithVoiceProfileIniCloudForLanguage:
getDevicesWithAvailablePHSAssetsForLanguage:completion:
markSATEnrollmentSuccessForSiriProfileId:forLanguageCode:
_isSATMarkedForSiriProfileId:withMarker:forLanguageCode:
isSATEnrolledForSiriProfileId:forLanguageCode:
isSATEnrollmentMigratedForSiriProfileId:forLanguageCode:
updateVoiceProfileVersionFileForProfileId:forLanguageCode:
_markSATEnrollmentWithMarker:forLanguage:forSiriProfileId:
createFileAtPath:contents:attributes:
getImplicitUtterenceCacheDirectory
notifyImplicitUtterance:audioDeviceType:audioRecordType:voiceTriggerEventInfo:completion:
getSATEnrollmentPath
isSATAvailable
notifyImplicitTrainingUtteranceAvailable:forVoiceProfileId:withRecordDeviceInfo:withRecordCtxt:withVoiceTriggerCtxt:withOtherCtxt:withCompletion:
getUserVoiceProfileUpdateDirectory
notifyUserVoiceProfileDownloadReadyForUser:getData:completion:
notifyUserVoiceProfileUpdateReady
uploadUserVoiceProfile:completion:
notifyUserVoiceProfileUploadComplete:
getUserVoiceProfileUploadPathWithEnrolledLanguageList:
notifyUserVoiceProfileUploadComplete
_getEnrolledLanguageList
getCachedVoiceProfileAvailabilityMetaBlob
hasVoiceProfileIniCloudForLanguageCode:withBackupMetaBlob:
isVoiceProfileUploadedToiCloudForLanguageCode:withCompletionBlock:
hasVoiceProfileIniCloudForLanguageCode:
enableVoiceTriggerUponVoiceProfileSyncForLanguage:
provisionedVoiceProfilesForLocale:
markSATEnrollmentSuccessForLanguageCode:
isSATEnrollmentMigratedForLanguageCode:
_isRemoteVoiceTriggerAvailable
discardSATEnrollmentForLanguageCode:
discardSATEnrollmentForProfileId:forLanguageCode:
discardAllSATEnrollment
_getSATEnrollmentAudioPathForLanguageCodeForLegacyVoiceProfile:
_CSSATCachePath
currentDeviceCategory
xpcClient
setXpcClient:
_currentDeviceCategory
_xpcClient
_addAssetManagerEnabledConditions
_shouldCheckNetworkAvailability
isAvailable
initWithMode:deviceUID:
assetManagerEnabledPolicy
_checkVoiceTriggerEnabled
_didReceiveVoiceTriggerSettingChanged:
CSVoiceTriggerEnabledMonitor:didReceiveEnabled:
voiceTriggerEnabled
_didReceiveVoiceTriggerSettingChangedInQueue:
_isVoiceTriggerEnabled
CSAlwaysOnProcessorStateMonitor:didReceiveStateChange:
_didReceiveAOPListeningStateChange:
_isListeningEnabled
_handleXPCTimeConvertProvidingTypeHostTimeFromSampleCountMessage:messageBody:client:
_handleXPCTimeConvertProvidingTypeSampleCountFromHostTimeMessage:messageBody:client:
isRetrainerRunning
_processRemoteHeySiriCommandWithRequest:fromSenderID:withReply:
_processParallelRecordingCommandWithRequest:fromSenderID:withReply:
_sendParallelRecordingsToPeerId:voiceProfileRequestInfo:withReply:
_receiveParallelRecordingFromPeerId:recordingInfo:withReply:
_receiveVoiceProfileFromPeerId:voiceProfileInfo:withReply:
_processDataFetchCommandWithRequest:fromSenderID:withReply:
_processVoiceProfileDeleteCommandWithRequest:fromSenderID:withReply:
_receiveData1FromPeerId:requestInfo:withReply:
_processMusicAccountSignInCommandFromPeerId:requestInfo:withReply:
_processVoiceProfileListQueryCommandFromPeerId:requestInfo:withReply:
_processFetchVoiceProfileCommandFromPeerId:requestInfo:withReply:
_processReverseTransferVoiceProfileCommandFromPeerId:requestInfo:withReply:
_processVoiceProfileUpdateTriggerFromPeerId:requestInfo:withReply:
_sendData1ToPeerId:
_sendVoiceTriggerGradingDataToPeerId:
_sendVoiceProfileUpdateTriggerToPeerId:forLocale:
spidAudioTrainUtterancesDir
sendMessageWithPayload:toPeer:withReply:
_compressFilesInDirectory:matchingPredicate:compressedFileAvailable:
companionSyncVoiceTriggerUtterancesEnabled
voiceTriggerAudioLogDirectory
_sendData1File:withFileName:toPeerId:withCompressedFlag:withUncompressedDataSize:withBatchId:withRetainFileFlag:
spIdAudioLogsDir2
spIdSiriDebugVoiceProfileRootDirectoryForProfile:locale:
spIdDataRootDirectory
launchSiriDebugAppWithMessage:
speakerIdEnabled
isSpidAssetsAvailable
temporaryDirectory
setOnboardedType:
dateAdded
onboardedType
initWithObjectsAndKeys:
_sendVoiceProfile:toPeerId:
stringByDeletingLastPathComponent
spIdSiriDebugVoiceProfileCacheDirectoryForProfile:locale:
processRemoteCommandWithPayload:fromPeer:withReply:
sendInfo1ToNearbyPeer
sendVoiceTriggerGradingDataToCompanion
adCompanionServiceProvider
setAdCompanionServiceProvider:
lastCommunicatedPeer
setLastCommunicatedPeer:
voiceTriggerBatchId
setVoiceTriggerBatchId:
voiceIdentificationBatchId
setVoiceIdentificationBatchId:
_adCompanionServiceProvider
_lastCommunicatedPeer
_voiceTriggerBatchId
_voiceIdentificationBatchId
supportRaiseToSpeak
supportHearstVoiceTrigger
shouldRunVTOnCS
supportTTS
supportJarvisVoiceTrigger
supportBluetoothDeviceVoiceTrigger
rootQueueWithFixedPriority:
csAudioProcessingQueuePriority
supportContinuousVoiceTrigger
supportKeywordDetector
supportSelfTriggerSuppression
supportCSTwoShotDecision
supportHybridEndpointer
supportImplicitTraining
supportSAT
supportPremiumModel
supportPhatic
shouldDelayPhaticForMyriadDecision
supportSessionActivateDelay
supportLanguageDetector
supportTdsrOnCS
shouldDownloadVTAssetsOnDaemon
hasRemoteCoreSpeech
supportCircularBuffer
getFixedPrioritySerialQueueWithLabel:fixedPriority:
getFixedHighPrioritySerialQueueWithLabel:
deviceUserAssignedName
deviceBuildVersion
dateWithTimeIntervalSince1970:
timeIntervalSince1970
dictionaryWithObjectsAndKeys:
setVoiceProfileFilePath:
setProfileID:
setSiriProfileId:
profileOriginIdentifier
setProfileOriginIdentifier:
_locale
_dateAdded
_voiceProfileFilePath
_siriProfileId
_onboardedType
_profileOriginIdentifier
_sharedHomeID
_siriDebugID
initWithDownloadOption:
_createPeriodicalDownloadTimer
_startPeriodicalDownload
_stopPeriodicalDownload
_fetchRemoteMetaData
_canFetchRemoteAsset:
CSAssetManagerDidDownloadNewAsset:
setAssetDownloadingOption:
assetForCurrentLanguageOfType:
installedAssetForCurrentLanguageOfType:
installedAssetForCurrentLanguageOfType:completion:
_enablePolicy
_currentLanguageCode
_downloadingOption
_downloadTimer
_downloadTimerCount
getHostClockFrequency
zeroFilterApproxAbsSpeechThreshold
vtEndInSampleCount
setVtEndInSampleCount:
numSamplesProcessed
setNumSamplesProcessed:
_vtEndInSampleCount
_numSamplesProcessed
initWithEndpointThreshold:
_transaction
_description
_handleMetricProvidingRequestTypeAudioMetricMessage:messageBody:client:
audioMetricProvider
setAudioMetricProvider:
_audioMetricProvider
_handleActivateEventMesssage:client:
siriClientBehaviorMonitor:willStartStreamWithContext:option:
siriClientBehaviorMonitor:didStartStreamWithContext:successfully:option:
siriClientBehaviorMonitor:willStopStream:
siriClientBehaviorMonitor:didStopStream:
_checkAllConditionsEnabled
notifyCallback:
notifyCallback
_monitors
_conditions
_callback
_notifyObserver:withLanguageCode:
_didReceiveLanguageCodeUpdate
URLsForDirectory:inDomains:
lastObject
spIdAudioLogsDir
satConfigFileNameForCSSpIdType:
getVoiceProfileVersionFromVersionFilePath:
intValue
getVoiceProfileProductCategoryFromVersionFilePath:
setValue:forKey:
setWithObjects:
spIdSiriDebugVTDataDirectory
spIdSiriDebugVoiceProfileStoreRootDirectory
spIdSiriDebugVoiceProfileStoreRootDirectoryForLocale:
dictionaryWithCapacity:
getImplicitEnrollmentUtterancesFromDirectory:
compare:options:
stringForInvocationStyle:
spIdTypeForString:
stringForCSSATRunMode:
spIdSATImplicitAudioCacheDirForLocale:profileId:
spIdVoiceProfileImportRootDir
spIdAudioLogsCountLimitReached
streamAudioFromFileUrl:audioStreamBasicDescriptor:samplesPerStreamChunk:audioDataAvailableHandler:
getCurrentVoiceProfileProductCategoryForLanguageCode:
checkIfMigrationNecessaryForCompatibilityVersion:forLanguageCode:
migrateVoiceProfileToVersion:forLanguageCode:
spIdSiriDebugTrainedUsersFilePathForLocale:
spIdMapScoresToSharedSiriID:
spIdMapIdentifiersToSiriDebugID:
spIdComposeProfileVersionsFor:
getExplicitEnrollmentUtterancesForType:forLanguageCode:forProfileID:
getSortedImplicitEnrollmentUtterancesForType:forLanguageCode:forProfileID:
getImplicitEnrollmentUtterancesPriorTo:forType:forLanguageCode:forProfileID:
deleteExistingSATModelForLanguageCode:
initWithType:deviceId:activationInfo:vadScore:hosttime:
_activationTypeString
remoteMicVoiceTriggerEvent:activationInfo:hostTime:
remoteMicVADEvent:vadScore:hostTime:
builtInMicVoiceTriggerEvent:hostTime:
jarvisVoiceTriggerEvent:activationInfo:hostTime:
builtInVoiceTriggerStartEvent:hostTime:
builtInVoiceTriggerStopEvent:hostTime:
activationInfo
setActivationInfo:
setHosttime:
vadScore
setVadScore:
_vadScore
_activationInfo
_hosttime
_notificationKey
_didInstalledNewVoiceTriggerAsset
addUtterances:toProfile:toModel:withScoreThreshold:withCompletionBlock:
_baseProfileConfidenceScoreThreshold
_implicitConfidenceScoreThreshold
_implicitDeltaConfidenceScoreThreshold
setAudioSessionState:
_audioSessionState
startManager
_createClearLoggingFileTimer
_startClearLoggingFilesTimer
_getAudioRecorderWithError:
audioProviders
daysBeforeRemovingLogFiles
_getVoiceTriggerAssetIfNeeded:
registerSpeechController:
registerSiriClientProxy:
registerVolumeController:
audioProviderWithUUID:
_reinitializeSmartSiriVolumeWithAsset:
assetQueryQueue
setAssetQueryQueue:
setAudioProviders:
clientController
setClientController:
volumeClientController
setVolumeClientController:
voiceTriggerImplicitTraining
setVoiceTriggerImplicitTraining:
voiceTriggerSATCleaner
setVoiceTriggerSATCleaner:
clearLoggingFileTimer
setClearLoggingFileTimer:
clearLoggingFileTimerCount
setClearLoggingFileTimerCount:
opportuneSpeakListnerTestService
setOpportuneSpeakListnerTestService:
_smartSiriVolume
_assetQueryQueue
_audioProviders
_clientController
_volumeClientController
_voiceTriggerImplicitTraining
_voiceTriggerSATCleaner
_clearLoggingFileTimer
_clearLoggingFileTimerCount
_opportuneSpeakListnerTestService
audioConverterBitrate
alertMuteBehaviorDict
voiceTriggerRecordContext
hearstVoiceTriggerRecordContext:
jarvisVoiceTriggerRecordContext:
opusRecordSettings
speexRecordSettings
alertMuteSettings
_methodToken
_continuousZeroCounter
_zeroCounterWinSz
_analyzeStep
_shouldDeinterleaveAudio
setRtsTriggerInfo:
_voiceTriggerInfo
_rtsTriggerInfo
hybridEndpointerAssetFilename
initWithResourcePath:configFile:configVersion:
fallBackAssetResourcePath
_decodeJson:
assetForAssetType:resourcePath:configVersion:
defaultFallBackAssetForSmartSiriVolume
defaultFallBackAssetForHearst
getBoolForKey:category:default:
getStringForKey:category:default:
containsKey:category:
containsCategory:
hashFromResourcePath
configVersion
_decodedInfo
_path
_resourcePath
_configVersion
setAudioAlertProvider:
setAudioMeterProvider:
_handleAudioProvidingMessage:messageBody:client:
_handlePingPongMessage:client:
_handleAudioProvidingRequestTypeSwitchMessage:messageBody:client:
_getAudioProvideWithContext:
_notifyXPCDisconnectionToProxies
_notifyXPCDisconnectionToProxy:
audioSessionProvidingProxy
setAudioSessionProvidingProxy:
audioSessionInfoProvidingProxy
setAudioSessionInfoProvidingProxy:
audioStreamProvidingProxy
setAudioStreamProvidingProxy:
audioAlertProvidingProxy
setAudioAlertProvidingProxy:
audioMeterProvidingProxy
setAudioMeterProvidingProxy:
audioMetricProvidingProxy
setAudioMetricProvidingProxy:
smartSiriVolumeProvidingProxy
setSmartSiriVolumeProvidingProxy:
_audioSessionProvidingProxy
_audioSessionInfoProvidingProxy
_audioStreamProvidingProxy
_audioAlertProvidingProxy
_audioMeterProvidingProxy
_audioMetricProvidingProxy
_smartSiriVolumeProvidingProxy
_daemonDidLaunch
mainRunLoop
_daemonWillShutdown
_setupNotifyHandlers
notifyDaemonStateChanged:
sharedDaemon
shutdown
xpcListener
setXpcListener:
activationXpcListener
setActivationXpcListener:
voiceIdXpcListener
setVoiceIdXpcListener:
_xpcListener
_activationXpcListener
_voiceIdXpcListener
stringWithCString:encoding:
createAudioCircularBufferWithDefaultSettings
copySamplesFromHostTime:
copyBufferWithNumSamplesCopiedIn:
setBufferLength:
_csAudioCircularBufferImpl
_bufferLength
readAudioChunksFrom:block:
_didReceiveDaemonStateChanged:
_notifyObserver:withDaemonState:
coreSpeechDaemonStateMonitor:didReceiveStateChanged:
hostTimeToSeconds:
hostTimeToTimeInterval:
macHostTimeFromBridgeHostTime:
currentBuiltinSpeakerState
isBuiltinSpeakerMuted
waitingForConnection:error:
isConnected
startRecordingWithOptions:error:
stopRecording:
didPlayEndpointBeep
hasPendingTwoShotBeep
opusDecoder
addPackets:audioStreamHandleId:remoteVAD:timestamp:receivedNumChannels:
_decoder
CSSiriAssertionMonitor:didReceiveEnabled:
enableAssertionReceived
disableAssertionReceived
_assertionState
psrTdAssetExistsAtResourcePath:
initWithResourcePath:satDirectory:assetHash:shouldCreateModelDir:delegate:
getThresholdSAT
getCombinationWeight
resetForNewRequest
processAudio:numSamples:
satScore
deleteExistingSATModel
deleteVectorAtIndex:
logWithAudioFilepath:
tdSATModelFilePath
tdPsrCanProcessRequest
lastRequestSatScore
_tdPsrCanProcessRequest
_lastRequestSatScore
_tdSATModelFilePath
_getSATVectorCount
_handleSessionProvidingRequestTypePrewarmMessage:client:
_handleSessionProvidingRequestTypeActivateMessage:messageBody:client:
_handleSessionProvidingRequestTypeDeactivateMessage:messageBody:client:
_handleSessionProvidingRequestTypeGetDuckOthersOption:messageBody:client:
_handleSessionProvidingRequestTypeSetDuckOthersOption:messageBody:client:
_handleSessionProvidingRequestTypeEnableMiniDucking:messageBody:client:
_sendReplyMessageWithResult:event:client:
audioSessionProvider:didReceiveAudioSessionInterruptionNotificationWithUserInfo:
audioSessionProvider:didReceiveAudioSessionRouteChangeNotificationWithUserInfo:
audioSessionProvider:didReceiveAudioSessionMediaServicesWereLostNotificationWithUserInfo:
audioSessionProvider:didReceiveAudioSessionMediaServicesWereResetNotificationWithUserInfo:
getLocalUrl
_compatibilityVersion
stringValue
appendString:
_footprint
isPremium
_handleAlertProvidingRequestTypeSetAlertSoundMessage:messageBody:client:
_handleAlertProvidingRequestTypePlayAlertSoundMessage:messageBody:client:
_handleAlertProvidingRequestTypePlayRecordStartingAlertAndResetEndpointerMessage:messageBody:client:
_handleAlertProvidingRequestTypeAlertStartTimeMessage:messageBody:client:
_handleAlertProvidingRequestTypeConfigureAlertBehavior:messageBody:client:
audioAlertProvider
_audioAlertProvider
_storeModeEnabled
setFileLoggingLevel:
fileLoggingLevel
interstitialRelativeDirForLevel:
isAttentiveSiriEnabled
twoShotNotificationEnabled
setFileLoggingIsEnabled:
secondPassAudioLoggingEnabled
jarvisAudioLoggingEnabled
setJarvisTriggerMode:
getJarvisTriggerMode
startOfSpeechAudioLoggingEnabled
getStartOfSpeechAudioLogFilePath
remoteVoiceTriggerDelayTime
remoteVoiceTriggerEndpointTimeoutWithDefault:
interstitialAbsoluteDirForLevel:
myriadFileLoggingEnabled
enableAudioInjection:
setAudioInjectionFilePath:
audioSessionActivationDelay
useSiriActivationSPIForHomePod
useSiriActivationSPIForwatchOS
iOSBargeInPowerSavingEnabled
iOSBargeInSupportEnabled
shouldOverwriteRemoteVADScore
overwritingRemoteVADScore
setHearstFirstPassModelVersion:
setHearstSecondPassModelVersion:
fakeHearstModelPath
_fetchHearstConnectionState
_notifyHearstConnectionState:
_fetchJarvisConnectionState
_notifyJarvisConnectionState:
CSAudioRouteChangeMonitor:didReceiveAudioRouteChangeEvent:
getHearstConnected:
hearstConnected
getJarvisConnected:
jarvisConnected
preferredExternalRouteDidChange:
carPlayAudioRouteDidChange:
_isHearstConnected
_isJarvisConnected
EncryptionAudioSampleByteDepth
inputRecordingEncoderAudioQuality
inputRecordingSampleRateConverterAlgorithm
channelForOutputReference
serverLoggingChannelBitset
setAudioFormat:
setEncoderBitRate:
setNumberOfChannels:
setLpcmBitDepth:
setLpcmIsFloat:
setUseCustomizedRecordSettings:
requestForLpcmRecordSettingsWithContext:
requestForOpusRecordSettingsWithContext:
requestForSpeexRecordSettingsWithContext:
setRequiresHistoricalBuffer:
isSiri
setIsSiri:
_requiresHistoricalBuffer
_useCustomizedRecordSettings
_lpcmIsFloat
_isSiri
_lpcmBitDepth
_numberOfChannels
_encoderBitRate
_audioFormat
initWithAppBundleIdentifier:
initWithTaskDeliverer:
initWithMessage:makeAppFrontmost:
handleSiriRequest:deliveryHandler:completionHandler:
selectedChannelList
_checkSoftwareUpdateCheckingState
_didReceiveSoftwareUpdateCheckingStateChanged:
_softwareUpdateCheckingState
_notifyObserver:withSoftwareUpdateCheckingRunning:
CSSoftwareUpdateCheckingMonitor:didReceiveStateChanged:
_didReceiveSoftwareUpdateCheckingStateChangedInQueue:
_isSoftwareUpdateCheckingRunning
_notifyObserver:mediaIsPlayingState:
_notePossiblePlayPausedStateChange:
mediaPlayingStateWithCompletion:
_addVoiceTriggerAOPModeEnabledConditions
_addConditionsForIOSBargeIn
_addConditionsForIOSAOP
voiceTriggerAOPModeEnabledPolicy
_availabilityChanged
_didReceivedNetworkAvailabilityChangedNotification:
_notifyObserver:withNetworkAvailability:
CSNetworkAvailabilityMonitor:didReceiveNetworkAvailabilityChanged:
_handleMeterProvidingRequestTypeSetMeteringEnabledMessage:messageBody:client:
_handleMeterProvidingRequestTypeUpdateMetersMessage:messageBody:client:
_handleMeterProvidingRequestTypePowerMessage:messageBody:client:powerType:
audioMeterProvider
_audioMeterProvider
CSKeywordAnalyzerNDEAPI
AVVC
CSActivationXPCClient
CSAudioTimeConverter
CSAudioSampleRateConverter
CSVolumeMonitor
CSAudioChunk
CSAudioStreamProvidingProxy
CSXPCConnectionDelegate
NSObject
CSAudioStreamProvidingDelegate
CSAudioFileLog
CSAudioSessionInfoProvider
CSAudioSessionInfoProviding
CSAudioFileManager
CSStateMachine
CSSmartSiriVolumeEnablePolicy
CSSiriRestrictionOnLockScreenMonitor
MCProfileConnectionObserver
CSAudioRecordContext
NSCopying
CSAudioZeroFilter
CSKeywordAnalyzerQuasar
ResourcePathHash
CSVoiceTriggerAssetHandlerMac
CSVoiceTriggerAssetDownloadMonitorDelegate
CSFirstUnlockMonitorDelegate
CSLanguageCodeUpdateMonitorDelegate
CSAudioStartStreamOption
CSAudioServerCrashMonitor
CSXPCClient
CSAudioSessionProviding
CSAudioStreamProviding
CSAudioAlertProviding
CSAudioMeterProviding
CSAudioMetricProviding
CSSmartSiriVolumeProviding
CSAudioTimeConversionProviding
CSOpportuneSpeakListnerTestService
CSOpportuneSpeakListenerDelegate
CSTimerMonitor
CSPhraseSpotterEnabledMonitor
CSVoiceTriggerAssetHandler
AudioStreamBasicDescription
CSSpeakerModel
CSAudioStreamHolding
SmartSiriVolume
CSVoiceTriggerRTModel
NSSecureCoding
NSCoding
CSAudioProvider
CSAudioRecorderDelegate
CSAudioServerCrashMonitorDelegate
CSAudioPreprocessorDelegate
CSPassThroughVoiceTriggerInfoProviding
CSVoiceTriggerDelegate
CSAssetDownloadingOption
Directory
CSVoiceTriggerEnabledPolicyNonAOP
CSSpeechDetectionDevicePresentMonitor
CSKeywordAnalyzerNDAPI
RTModel
remoteVoiceActivityVADBuffer
CSAudioRecorder
AVVoiceControllerRecordDelegate
CSAudioDecoderDelegate
CSAudioFileReaderDelegate
CSOpportuneSpeakListener
CSSPGEndpointAnalyzerDelegate
CSMediaPlayingMonitorDelegate
CSSpeakerDetectorNDAPI
XPCObject
CSSiriEnabledMonitor
CSSmartSiriVolumeProvidingProxy
CSSpIdSATAnalyzer
CSJarvisTriggerModeMonitor
CSActivationXPCListener
CSActivateXPCConnectionDelegate
AudioHardware
CSAudioSessionInfoProvidingProxy
CSAudioSessionInfoProvidingDelegate
CSAssetController
CSEventMonitorDelegate
Utils
RecordContext
CSNovDetectorResult
CSNovDetector
CSSmartSiriVolume
CSSiriEnabledMonitorDelegate
CSAlarmMonitorDelegate
CSTimerMonitorDelegate
CSVolumeMonitorDelegate
CSListeningEnabledPolicyWatch
LanguageCode
CSAudioFileReader
CSMyriadSelfTriggerCoordinator
CSSelfTriggerDetectorDelegate
CSUserVoiceProfileStore
CSBeepCanceller
CSSpringboardStartMonitor
CSActivationEventNotifier
CSAlarmMonitor
CSSpIdImplicitTraining
CSFirstUnlockMonitor
CSVoiceTriggerEnrollmentDataManager
CSInvalidSATEntriesCleaner
LPCMTypeConversion
CSAudioChunkForTV
CSAudioRecordDeviceInfo
CSPlainAudioFileWriter
CSAudioFileWriter
CSAudioStream
CSVoiceTriggerAssetMetaUpdateMonitor
CSOpportuneSpeakListenerOption
CSSpIdSpeakerVectorGenerator
CSAudioPreprocessor
CSVoiceTriggerAwareZeroFilterDelegate
CSBeepCancellerDelegate
CSAggregator
CSUtteranceMetadataManager
CSSpeechEndpointAssetMetaUpdateMonitor
CSScreenLockMonitor
CSVoiceProfileContext
CSVoiceIdXPCConnection
CSVoiceProfileManager
CSAssetManagerEnablePolicy
CSXPCListener
CSAssetManagerEnablePolicyFactory
CSVoiceTriggerEnabledMonitor
CSAlwaysOnProcessorStateMonitor
CSAudioTimeConversionProvidingProxy
CSVoiceProfileRetrainManager
CSP2PService
CSUtils
CSUserVoiceProfile
CSAssetManager
CSVoiceTriggerAssetMetaUpdateMonitorDelegate
CSSpeechEndpointAssetMetaUpdateMonitorDelegate
CSAssetControllerDelegate
CSVoiceTriggerAwareZeroFilter
CSSPGEndpointAnalyzer
CSOSTransaction
CSAudioMetricProvidingProxy
CSActivationXPCConnection
CSSiriClientBehaviorMonitor
CSPolicy
CSLanguageCodeUpdateMonitor
CSEventMonitor
SpeakerId
CSActivationEvent
CSVoiceTriggerAssetDownloadMonitor
CSVoiceProfileTrainer
CSAudioSessionMonitor
CSOpportuneSpeakListenerDeviceManager
CSVoiceIdXPCListener
CSSpeechManager
CSStateMachineDelegate
CSVoiceTriggerAssetHandlerDelegate
CSActivationEventNotifierDelegate
CSVoiceIdXPCClient
VoiceTriggerRecord
CSAudioZeroCounter
CSVoiceTriggerEventInfoProvider
CSAsset
CSXPCConnection
CSHostDaemon
CSAudioCircularBuffer
AudioFile
CSCoreSpeechDaemonStateMonitor
Time
CSBuiltinSpeakerStateMonitor
CSRemoteRecordClient
CSAudioDecoder
CSSiriAssertionMonitor
CSSpIdVTTextDependentSpeakerRecognizer
CSAudioSessionProvidingProxy
CSAudioSessionProvidingDelegate
CSAudioAlertProvidingProxy
CSAudioAlertProvidingDelegate
CSPreferences
Bitset
CSAudioRouteChangeMonitor
CSAlertBehaviorPredictor
CSConfig
CSAudioStreamRequest
CSSiriDebugConnection
CSSelectiveChannelAudioFileWriter
CSSoftwareUpdateCheckingMonitor
CSMediaPlayingMonitor
CSBatteryMonitor
CSiTunesAccountManager
CSVoiceTriggerAOPModeEnabledPolicyIOS
CSVoiceTriggerAOPModeEnabledPolicyFactory
CSNetworkAvailabilityMonitor
CSAudioMeterProvidingProxy
@24@0:8@16
v16@0:8
v24@0:8@16
Q16@0:8
v24@0:8Q16
@16@0:8
@"NSMutableData"
@"<CSKeywordAnalyzerNDEAPIScoreDelegate>"
@24@0:8Q16
q24@0:8q16
v32@0:8@16@?24
v40@0:8@16@24@?32
@"NSObject<OS_xpc_object>"
v32@0:8Q16Q24
Q24@0:8Q16
@"NSObject<OS_dispatch_queue>"
@96@0:8{AudioStreamBasicDescription=dIIIIIIII}16{AudioStreamBasicDescription=dIIIIIIII}56
^{OpaqueAudioConverter=}96@0:8{AudioStreamBasicDescription=dIIIIIIII}16{AudioStreamBasicDescription=dIIIIIIII}56
^{OpaqueAudioConverter=}
{AudioStreamBasicDescription="mSampleRate"d"mFormatID"I"mFormatFlags"I"mBytesPerPacket"I"mFramesPerPacket"I"mBytesPerFrame"I"mChannelsPerFrame"I"mBitsPerChannel"I"mReserved"I}
f16@0:8
v24@0:8@?16
@72@0:8@16Q24Q32Q40Q48Q56@64
@28@0:8f16Q20
B16@0:8
@40@0:8Q16Q24Q32
@32@0:8Q16Q24
v40@0:8Q16Q24@?32
@"NSData"
B24@0:8@16
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
v40@0:8@16@24@32
v40@0:8@"NSObject<OS_xpc_object>"16@"NSObject<OS_xpc_object>"24@"NSObject<OS_xpc_object>"32
v40@0:8@"CSXPCConnection"16@"NSObject<OS_xpc_object>"24@"NSObject<OS_xpc_object>"32
v32@0:8@16q24
v32@0:8@16@24
v32@0:8@"<CSAudioStreamProviding>"16q24
v32@0:8@"<CSAudioStreamProviding>"16@"CSAudioChunk"24
v32@0:8@"<CSAudioStreamProviding>"16@"CSAudioChunkForTV"24
v44@0:8@16@24B32@36
@"<CSAudioStreamProviding>"
@"<CSPassThroughVoiceTriggerInfoProviding>"
@"CSXPCConnection"
@"CSAudioStream"
@"NSDictionary"
@"CSAudioRecordContext"
^{OpaqueExtAudioFile=}
@"NSURL"
I16@0:8
v24@0:8@"<CSAudioSessionInfoProvidingDelegate>"16
@"NSHashTable"
@104@0:8@16{AudioStreamBasicDescription=dIIIIIIII}24{AudioStreamBasicDescription=dIIIIIIII}64
v20@0:8f16
@24@0:8q16
v40@0:8q16q24q32
v24@0:8q16
q16@0:8
@"<CSStateMachineDelegate>"
@"NSMutableDictionary"
v32@0:8@"MCProfileConnection"16@"NSDictionary"24
v20@0:8B16
v28@0:8@16B24
@24@0:8^{_NSZone=}16
@32@0:8q16@24
@"NSString"
@36@0:8Q16S24d28
Q40@0:8@16Q24^@32
Q24@0:8^@16
{unique_ptr<CSAudioZeroFilterImpl<unsigned short>, std::__1::default_delete<CSAudioZeroFilterImpl<unsigned short> > >="__ptr_"{__compressed_pair<CSAudioZeroFilterImpl<unsigned short> *, std::__1::default_delete<CSAudioZeroFilterImpl<unsigned short> > >="__value_"^{CSAudioZeroFilterImpl<unsigned short>}}}
@36@0:8@16@24B32
v28@0:8r^s16i24
d16@0:8
@"NSMutableArray"
@"NSArray"
@"<CSKeywordAnalyzerQuasarScoreDelegate>"
v28@0:8@"CSFirstUnlockMonitor"16B24
v32@0:8@16@"NSString"24
@"CSAsset"
v32@0:8@16Q24
B24@0:8^@16
B32@0:8Q16^@24
v24@0:8@"<CSAudioSessionProvidingDelegate>"16
B32@0:8@16^@24
@40@0:8@16@24^@32
B40@0:8@16@24^@32
v40@0:8Q16Q24@32
v32@0:8Q16@24
@32@0:8@16d24
B32@0:8@"CSAudioRecordContext"16^@24
@"CSAudioStream"40@0:8@"CSAudioStreamRequest"16@"NSString"24^@32
v40@0:8@"CSAudioStreamRequest"16@"NSString"24@?<v@?@"CSAudioStream"@"NSError">32
B40@0:8@"CSAudioStream"16@"CSAudioStreamRequest"24^@32
v40@0:8@"CSAudioStream"16@"CSAudioStreamRequest"24@?<v@?B@"NSError">32
v40@0:8@"CSAudioStream"16@"CSAudioStartStreamOption"24@?<v@?B@"NSError">32
v40@0:8@"CSAudioStream"16@"CSAudioStopStreamOption"24@?<v@?B@"NSError">32
@"CSAudioChunk"32@0:8Q16Q24
@"CSAudioChunk"24@0:8Q16
v40@0:8Q16Q24@"NSURL"32
v32@0:8Q16@"NSURL"24
@"CSAudioStreamHolding"32@0:8@"NSString"16d24
v24@0:8@"CSAudioStreamHolding"16
@"CSAudioRecordDeviceInfo"16@0:8
@"NSDictionary"16@0:8
B32@0:8@16q24
B24@0:8q16
v24@0:8@"<CSAudioAlertProvidingDelegate>"16
B32@0:8@"NSURL"16q24
v24@0:8@"NSDictionary"16
f24@0:8Q16
v28@0:8B16@20
B32@0:8@16@24
@"<CSAudioSessionProvidingDelegate>"
@"<CSAudioStreamProvidingDelegate>"
@"<CSAudioAlertProvidingDelegate>"
@"NSMutableSet"
v28@0:8@"CSOpportuneSpeakListener"16B24
@"CSOpportuneSpeakListener"
{AudioStreamBasicDescription=dIIIIIIII}16@0:8
{AudioStreamBasicDescription=dIIIIIIII}24@0:8f16I20
@32@0:8@16@24
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
@64@0:8@16@24@32@40@48@56
@40@0:8@16@24@32
v56@0:8@16Q24@32@40Q48
v40@0:8@16Q24@32
v44@0:8@16Q24B32@36
v40@0:8@16Q24q32
v40@0:8@16q24@32
v56@0:8@"CSAudioRecorder"16Q24@"NSData"32@"NSData"40Q48
v40@0:8@"CSAudioRecorder"16Q24@"CSAudioChunkForTV"32
v44@0:8@"CSAudioRecorder"16Q24B32@"NSError"36
v40@0:8@"CSAudioRecorder"16Q24q32
v32@0:8@"CSAudioRecorder"16q24
v40@0:8@"CSAudioRecorder"16q24@"NSError"32
v24@0:8@"CSAudioRecorder"16
v32@0:8@"CSAudioRecorder"16@"NSDictionary"24
v28@0:8@"CSAudioRecorder"16B24
v32@0:8@"CSAudioRecorder"16@"NSError"24
v24@0:8@"CSAudioServerCrashMonitor"16
v40@0:8@16@24Q32
v40@0:8@"CSAudioPreprocessor"16@"NSData"24Q32
v32@0:8@"NSDictionary"16@"NSString"24
v24@0:8@"NSData"16
@32@0:8Q16@24
v24@0:8d16
@"CSAudioRecorder"
@"CSAudioCircularBuffer"
@"CSAudioPreprocessor"
@"CSOSTransaction"
@"NSUUID"
v36@0:8@16@24f32
@48@0:8@16@24@32^@40
v20@0:8I16
@"CSNovDetector"
@"<CSKeywordAnalyzerNDAPIScoreDelegate>"
@40@0:8Q16Q24@32
v36@0:8@16B24@28
v28@0:8@16i24
v36@0:8@16i24d28
v36@0:8@16i24@28
v28@0:8@"AVVoiceController"16B24
v36@0:8@"AVVoiceController"16B24@"NSError"28
v32@0:8@"AVVoiceController"16q24
v24@0:8@"AVVoiceController"16
v28@0:8@"AVVoiceController"16i24
v36@0:8@"AVVoiceController"16i24d28
v32@0:8@"AVVoiceController"16@"NSError"24
v36@0:8@"AVVoiceController"16i24@"NSError"28
v32@0:8@"AVVoiceController"16@"NSDictionary"24
v32@0:8@"AVVoiceController"16@"AVVCAudioBuffer"24
v28@0:8B16@"NSArray"20
v44@0:8@"AVVoiceController"16Q24B32@"NSError"36
v40@0:8@"AVVoiceController"16Q24q32
v40@0:8@"AVVoiceController"16Q24@"AVVCAudioBuffer"32
v32@0:8@"AVVoiceController"16Q24
v60@0:8@16Q24@32@40Q48I56
v60@0:8@"CSAudioDecoder"16Q24@"NSData"32@"NSData"40Q48I56
v40@0:8@"CSAudioFileReader"16@"NSData"24Q32
v36@0:8@"CSAudioFileReader"16B24@"NSError"28
v32@0:8@"CSAudioFileReader"16q24
@32@0:8@16^@24
@24@0:8^@16
Q32@0:8@16^@24
B40@0:8@16Q24^@32
B24@0:8Q16
B40@0:8Q16Q24^@32
v48@0:8@16Q24@32Q40
@28@0:8@16I24
@"AVVoiceController"
{AudioBufferList="mNumberBuffers"I"mBuffers"[1{AudioBuffer="mNumberChannels"I"mDataByteSize"I"mData"^v}]}
^{AudioBufferList=I[1{AudioBuffer=II^v}]}
@"CSRemoteRecordClient"
@"CSAudioFileReader"
v32@0:8@"CSMediaPlayingMonitor"16q24
v28@0:8B16@?20
v28@0:8@16f24
i16@0:8
v20@0:8i16
@"<CSOpportuneSpeakListenerDelegate>"
@"CSSPGEndpointAnalyzer"
@"<CSAudioSessionProviding>"
f24@0:8@16
@32@0:8@16Q24
@"CSSpeakerModel"
@"<CSSpeakerDetectorNDAPIDelegate>"
@56@0:8Q16@24@32@40@48
f32@0:8@16Q24
v40@0:8@"CSActivationXPCConnection"16@"NSObject<OS_xpc_object>"24@"NSObject<OS_xpc_object>"32
@"NSMapTable"
v32@0:8@"<CSAudioSessionInfoProviding>"16@"NSDictionary"24
@"<CSAudioSessionInfoProviding>"
v40@0:8Q16@24@?32
v32@0:8Q16@?24
v40@0:8@16Q24@?32
v40@0:8@16@?24@?32
@40@0:8@16Q24@32
v32@0:8^@16Q24
@20@0:8I16
v28@0:8@"CSSiriEnabledMonitor"16B24
v32@0:8@"CSAlarmMonitor"16q24
v32@0:8@"CSTimerMonitor"16q24
v28@0:8@"CSVolumeMonitor"16f24
@28@0:8f16@20
v32@0:8d16@?24
v28@0:8I16q20
v52@0:8@16q24B32Q36Q44
f24@0:8q16
f24@0:8f16f20
f36@0:8f16f20f24f28f32
f44@0:8f16f20f24f28f32f36f40
f28@0:8f16f20f24
f20@0:8f16
{unique_ptr<SmartSiriVolume, std::__1::default_delete<SmartSiriVolume> >="__ptr_"{__compressed_pair<SmartSiriVolume *, std::__1::default_delete<SmartSiriVolume> >="__value_"^{SmartSiriVolume}}}
{vector<float, std::__1::allocator<float> >="__begin_"^f"__end_"^f"__end_cap_"{__compressed_pair<float *, std::__1::allocator<float> >="__value_"^f}}
@"NSUserDefaults"
@"CSSmartSiriVolumeEnablePolicy"
@"<CSSmartSiriVolumeDelegate>"
@"NSObject<OS_dispatch_source>"
B24@0:8d16
@"<CSAudioFileReaderDelegate>"
v32@0:8@"CSSelfTriggerDetector"16@"NSDictionary"24
@"<CSMyriadSelfTriggerCoordinatorDelegate>"
v56@0:8@16@24@32@40@?48
@64@0:8@16Q24@32Q40Q48Q56
v36@0:8@16B24@?28
@28@0:8@16B24
@36@0:8@16Q24B32
@44@0:8@16Q24@32B40
v72@0:8@16@24@32@40@48@56@?64
{unique_ptr<BatchBeepCanceller, std::__1::default_delete<BatchBeepCanceller> >="__ptr_"{__compressed_pair<BatchBeepCanceller *, std::__1::default_delete<BatchBeepCanceller> >="__value_"^{BatchBeepCanceller}}}
{vector<short, std::__1::allocator<short> >="__begin_"^s"__end_"^s"__end_cap_"{__compressed_pair<short *, std::__1::allocator<short> >="__value_"^s}}
@"<CSBeepCancellerDelegate>"
v48@0:8Q16@24@32@?40
@?16@0:8
@"CSActivationEvent"
@"CSActivationXPCClient"
v48@0:8@16@24@32@?40
v36@0:8@16@24B32
B36@0:8@16@24B32
B44@0:8@16@24Q32B40
B28@0:8@16B24
@36@0:8@16q24B32
@44@0:8@16B24@28@36
B32@0:8r^v16Q24
B32@0:8r^v16q24
@"CSAudioStreamRequest"
r*16@0:8
@48@0:8Q16@24@32@40
v40@0:8@"CSVoiceTriggerAwareZeroFilter"16@"NSData"24Q32
v40@0:8@"CSBeepCanceller"16@"NSData"24Q32
@20@0:8f16
v32@0:8f16B20@24
B20@0:8f16
@"<CSAudioPreprocessorDelegate>"
@"CSAudioSampleRateConverter"
@"CSVoiceTriggerAwareZeroFilter"
@"CSBeepCanceller"
@"CSAudioZeroCounter"
v36@0:8^@16^@24B32
v32@0:8@16d24
v64@0:8@16@24B32@36@44Q52B60
@"NSNumber"
@32@0:8@16@?24
v48@0:8@16Q24@?32@?40
B40@0:8@16@24@32
@40@0:8@16Q24Q32
v32@0:8@?16@?24
@24@0:8@?16
@"CSVoiceIdXPCClient"
v64@0:8@16@24@32B40Q44@52B60
@"<CSADCompanionServiceProvider>"
@20@0:8i16
@28@0:8@16i24
@"NSDate"
v32@0:8@"CSAssetController"16Q24
@"CSPolicy"
@"CSAssetDownloadingOption"
@"<CSVoiceTriggerAwareZeroFilterDelegate>"
@"CSAudioZeroFilter"
@"<CSSPGEndpointAnalyzerDelegate>"
@"NSObject<OS_os_transaction>"
@"<CSAudioMetricProviding>"
@"<CSActivateXPCConnectionDelegate>"
Q24@0:8@16
@40@0:8@16@24Q32
v80@0:8@16{AudioStreamBasicDescription=dIIIIIIII}24Q64@?72
Q32@0:8@16@24
B32@0:8Q16@24
@52@0:8@16Q24f32f36f40f44f48
@40@0:8Q16@24@32
@48@0:8@16Q24@32@40
q24@0:8@16
@36@0:8@16f24Q28
@52@0:8Q16@24@32f40Q44
@48@0:8Q16@24@32Q40
v52@0:8@16@24Q32f40@?44
v32@0:8q16q24
v32@0:8@"CSVoiceTriggerAssetHandler"16@"CSAsset"24
v40@0:8@"CSActivationEventNotifier"16@"CSActivationEvent"24@?<v@?B@"NSError">32
@"CSSmartSiriVolume"
@"<CSSpeechManagerDelegate>"
@"CSSpIdImplicitTraining"
@"CSInvalidSATEntriesCleaner"
@"CSOpportuneSpeakListnerTestService"
@32@0:8@16f24I28
v28@0:8@16I24
@"<CSXPCConnectionDelegate>"
@"CSAudioSessionProvidingProxy"
@"CSAudioSessionInfoProvidingProxy"
@"CSAudioStreamProvidingProxy"
@"CSAudioAlertProvidingProxy"
@"CSAudioMeterProvidingProxy"
@"CSAudioMetricProvidingProxy"
@"CSSmartSiriVolumeProvidingProxy"
@"CSXPCListener"
@"CSActivationXPCListener"
@"CSVoiceIdXPCListener"
@32@0:8Q16f24f28
v32@0:8r^v16Q24
v40@0:8r^v16Q24Q32
@24@0:8^Q16
{unique_ptr<corespeech::CSAudioCircularBufferImpl<unsigned short>, std::__1::default_delete<corespeech::CSAudioCircularBufferImpl<unsigned short> > >="__ptr_"{__compressed_pair<corespeech::CSAudioCircularBufferImpl<unsigned short> *, std::__1::default_delete<corespeech::CSAudioCircularBufferImpl<unsigned short> > >="__value_"^{CSAudioCircularBufferImpl<unsigned short>}}}
B32@0:8@16@?24
Q20@0:8f16
d24@0:8Q16
Q40@0:8Q16Q24Q32
B32@0:8d16^@24
@"<CSRemoteRecordClientDelegate>"
v52@0:8@16Q24@32Q40I48
@"<CSAudioDecoderDelegate>"
@52@0:8@16@24@32B40@44
v32@0:8r^s16Q24
v24@0:8@"<CSAudioSessionProviding>"16
v32@0:8@"<CSAudioSessionProviding>"16@"NSDictionary"24
v28@0:8@"<CSAudioSessionProviding>"16B24
v36@0:8B16@20@28
v40@0:8@"<CSAudioAlertProviding>"16q24@"NSError"32
@"<CSAudioAlertProviding>"
d24@0:8d16
B20@0:8B16
I24@0:8Q16
S16@0:8
@112@0:8@16{AudioStreamBasicDescription=dIIIIIIII}24{AudioStreamBasicDescription=dIIIIIIII}64Q104
C16@0:8
v48@0:8@16@24@32Q40
@"<CSAudioMeterProviding>"
activeChannel
TQ,N,V_activeChannel
delegate
T@"<CSKeywordAnalyzerNDEAPIScoreDelegate>",W,N,V_delegate
-[CSAudioStartStreamOption(AVVC) avvcStartRecordSettingsWithAudioStreamHandleId:]
com.apple.corespeech.corespeechd.activation.xpc
v16@?0@"NSObject<OS_xpc_object>"8
-[CSActivationXPCClient _handleListenerEvent:]
-[CSActivationXPCClient _handleListenerError:]
-[CSActivationXPCClient notifyActivationEvent:completion:]
v20@?0B8@"NSError"12
type
event
result
xpcConnection
T@"NSObject<OS_xpc_object>",&,N,V_xpcConnection
v8@?0
CSSampleCountHostTimeConverter
queue
T@"NSObject<OS_dispatch_queue>",&,N,V_queue
anchorSampleCount
TQ,N,V_anchorSampleCount
anchorHostTime
TQ,N,V_anchorHostTime
-[CSAudioSampleRateConverter _createSampleRateConverterWithInASBD:outASBD:]
i32@?0^I8^{AudioBufferList=I[1{AudioBuffer=II^v}]}16^^{AudioStreamPacketDescription}24
-[CSAudioSampleRateConverter convertSampleRateOfBuffer:]
Audio/Video
Alarm
CSVolumeMonitor queue
-[CSVolumeMonitor _startMonitoringWithQueue:]
-[CSVolumeMonitor fetchVolumeFromAVSystemControllerForAudioCategory:]_block_invoke
-[CSVolumeMonitor systemControllerDied:]
-[CSVolumeMonitor startObservingSystemVolumes]
-[CSVolumeMonitor _startObservingSystemControllerLifecycle]
-[CSAudioChunk subChunkFrom:numSamples:forChannel:]
-[CSAudioChunk subChunkFrom:numSamples:]
-[CSAudioChunk splitAudioChunkSuchThatNumSamplesReceivedSoFar:reachesACountOf:completionHandler:]
T@"NSData",R,N,V_data
TQ,R,N,V_numChannels
TQ,R,N,V_numSamples
TQ,R,N,V_sampleByteDepth
TQ,R,N,V_startSampleCount
TQ,R,N,V_hostTime
remoteVADAvailable
TB,R,N
T@"NSData",&,N,V_remoteVAD
xpcObject
T@"NSObject<OS_xpc_object>",R,N
numChannels
numSamples
sampleByteDepth
startSampleCount
hostTime
data
remoteVAD
-[CSAudioStreamProvidingProxy CSXPCConnectionReceivedClientError:clientError:client:]
-[CSAudioStreamProvidingProxy handleXPCMessage:messageBody:client:]
-[CSAudioStreamProvidingProxy _handleSetCurrentConextMessage:messageBody:client:]
context
audioStreamRequest
-[CSAudioStreamProvidingProxy _handleAudioStreamRequestMessage:messageBody:client:]
-[CSAudioStreamProvidingProxy _handleAudioStreamPrepareMessage:messageBody:client:]
startAudioStreamOption
-[CSAudioStreamProvidingProxy _handleStartAudioStreamMessage:messageBody:client:]
-[CSAudioStreamProvidingProxy _handleStopAudioStreamMessage:messageBody:client:]
voiceTriggerInfo
rtsTriggerInfo
-[CSAudioStreamProvidingProxy _handleIsRecordingMessage:messageBody:client:]
-[CSAudioStreamProvidingProxy _handleRecordRouteMessage:messageBody:client:]
recordRoute
-[CSAudioStreamProvidingProxy _handleRecordDeviceInfo:messageBody:client:]
recordDeviceInfo
-[CSAudioStreamProvidingProxy _handleRecordSettings:messageBody:client:]
recordSettings
-[CSAudioStreamProvidingProxy _handleIsNarrowband:messageBody:client:]
-[CSAudioStreamProvidingProxy _handlePlaybackRouteMessage:messageBody:client:]
playbackRoute
stopReason
-[CSAudioStreamProvidingProxy audioStreamProvider:audioBufferAvailable:]
chunk
-[CSAudioStreamProvidingProxy audioStreamProvider:audioChunkForTVAvailable:]
-[CSAudioStreamProvidingProxy audioStreamProvider:didHardwareConfigurationChange:]
hardwareConfig
body
hash
TQ,R
superclass
T#,R
description
T@"NSString",R,C
debugDescription
audioStream
T@"CSAudioStream",&,N,V_audioStream
lastVoiceTriggerInfo
T@"NSDictionary",C,V_lastVoiceTriggerInfo
lastRTSTriggerInfo
T@"NSDictionary",C,V_lastRTSTriggerInfo
recordContext
T@"CSAudioRecordContext",&,N,V_recordContext
audioStreamProviding
T@"<CSAudioStreamProviding>",W,N,V_audioStreamProviding
voiceTriggerInfoProviding
T@"<CSPassThroughVoiceTriggerInfoProviding>",W,N,V_voiceTriggerInfoProviding
T@"CSXPCConnection",W,N,V_xpcConnection
-[CSAudioFileLog _closeAudioFile]
-[CSAudioFileLog startRecording]_block_invoke
-input.wav
-[CSAudioFileLog appendAudioData:]_block_invoke
-[CSAudioFileLog stopRecording]_block_invoke
CSAudioSessionInfoProvider
-[CSAudioSessionInfoProvider CSAudioServerCrashMonitorDidReceiveServerCrash:]_block_invoke
-[CSAudioSessionInfoProvider CSAudioServerCrashMonitorDidReceiveServerRestart:]_block_invoke
-[CSAudioSessionInfoProvider _registerInterruptionNotification]
-[CSAudioSessionInfoProvider _registerAudioRouteChangeNotification]
-[CSAudioSessionInfoProvider _handleInterruption:]_block_invoke
-[CSAudioSessionInfoProvider _audioRouteChanged:]_block_invoke
-[CSAudioSessionInfoProvider _deregisterAudioSessionNotifications]
sessionInfoQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_sessionInfoQueue
observers
T@"NSHashTable",&,N,V_observers
PCM-
OPUS_
-synced
com.apple.CoreSpeech.AudioLogging
+[CSAudioFileManager generateDeviceAudioLogging:speechId:]_block_invoke
FLLR
+[CSAudioFileManager _readDataFromFileHandle:toFileHandle:]
%@%@.wav
%@/%@%@.wav
+[CSAudioFileManager _createAudioFileWriterWithLoggingDir:inputFormat:outputFormat:]
en_US_POSIX
yyyy_MM_dd-HHmmss.SSS
^%@*
attsiri
+[CSAudioFileManager audioFileWriterForAttentiveSiri]
%@.wav
initialState
Tq,N,V_initialState
transitions
T@"NSMutableDictionary",&,N,V_transitions
T@"<CSStateMachineDelegate>",W,N,V_delegate
currentState
Tq,R,N,V_currentState
CSSmartSiriVolumeEnablePolicy queue
B8@?0
-[CSSmartSiriVolumeEnablePolicy _addSmartSiriVolumeEnabledConditions]_block_invoke
-[CSSiriRestrictionOnLockScreenMonitor _startMonitoringWithQueue:]
-[CSSiriRestrictionOnLockScreenMonitor _stopMonitoring]
-[CSSiriRestrictionOnLockScreenMonitor _checkSiriRestrictedOnLockScreen]
v16@?0@8
+[CSAudioRecordContext defaultContext]
CSAudioRecordTypeUnspecified
CSAudioRecordTypeHomePress
CSAudioRecordTypeWiredHeadsetButtonPress
CSAudioRecordTypeBluetoothHeadSetButtonPress
CSAudioRecordTypeUIButtonPress
CSAudioRecordTypeServerInvoke
CSAudioRecordTypeVoiceTrigger
CSAudioRecordTypeStark
CSAudioRecordTypeTVRemote
CSAudioRecordTypeRaiseToSpeak
CSAudioRecordTypeHearstDoubleTap
CSAudioRecordTypeHearstVoice
CSAudioRecordTypeJarvis
CSAudioRecordTypePost
CSAudioRecordTypeDictation
CSAudioRecordTypeVoiceTriggerTraining
CSAudioRecordTypeUnknown
recordType[%@] deviceId[%@] alwaysUseBuiltInMic[%d]
Tq,N,V_type
T@"NSString",&,N,V_deviceId
TB,N,V_alwaysUseRemoteBuiltInMic
alwaysUseRemoteBuiltInMic
deviceId
CSInitialContinousZeros
CSMaxContinousZeros
CSMidSegmentContinousZeros
start
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
-[CSKeywordAnalyzerQuasar runRecognition]
-[CSKeywordAnalyzerQuasar endAudio]
triggerConfidence
Td,R,N,V_triggerConfidence
T@"<CSKeywordAnalyzerQuasarScoreDelegate>",W,N,V_delegate
nohash
((?:[a-z]|[0-9])*)\.asset
+[CSUtils(ResourcePathHash) assetHashInResourcePath:]
v24@?0@"CSAsset"8@"NSError"16
-[CSVoiceTriggerAssetHandlerMac _getVoiceTriggerAssetFromAssetManager:]_block_invoke
-[CSVoiceTriggerAssetHandlerMac _checkNewAssetAvailablity]_block_invoke
-[CSVoiceTriggerAssetHandlerMac CSVoiceTriggerAssetDownloadMonitor:didInstallNewAsset:]
-[CSVoiceTriggerAssetHandlerMac CSLanguageCodeUpdateMonitor:didReceiveLanguageCodeChanged:]
-[CSVoiceTriggerAssetHandlerMac CSFirstUnlockMonitor:didReceiveFirstUnlock:]
cachedAsset
T@"CSAsset",&,V_cachedAsset
[requestHistoricalAudioDataWithHostTime = %@]
[requestHistoricalAudioDataSampleCount = %@]
[useOpportunisticZLL = %@]
[startRecordingHostTime = %llu]
[startRecordingSampleCount = %llu]
[alertBehavior = %llu %llu %llu]
TB,N,V_requestHistoricalAudioDataWithHostTime
TB,N,V_requestHistoricalAudioDataSampleCount
TQ,N,V_startRecordingHostTime
TQ,N,V_startRecordingSampleCount
TB,N,V_useOpportunisticZLL
Tq,N,V_startAlertBehavior
Tq,N,V_stopAlertBehavior
Tq,N,V_errorAlertBehavior
localizedDescription
T@"NSString",R,N
requestHistoricalAudioDataWithHostTime
requestHistoricalAudioDataSampleCount
startRecordingHostTime
startRecordingSampleCount
useOpportunisticZLL
startAlertBehavior
stopAlertBehavior
errorAlertBehavior
-[CSAudioServerCrashMonitor _startMonitoringWithQueue:]
serverState
TQ,N,V_serverState
com.apple.corespeech.corespeechd.xpc
-[CSXPCClient prepareAudioProviderWithContext:error:]
activateReason
deactivateOption
setDuckOthersOption
enableMiniDucking
alertType
soundPath
alertStartTime
-[CSXPCClient alertStartTime]
alertBehavior
setMeterEnable
channelNumber
power
-[CSXPCClient peakPowerForChannel:]
-[CSXPCClient averagePowerForChannel:]
-[CSXPCClient audioMetric]
audioMetric
-[CSXPCClient audioStreamWithRequest:streamName:error:]
v24@?0@"CSAudioStream"8@"NSError"16
-[CSXPCClient audioStreamWithRequest:streamName:completion:]
-[CSXPCClient prepareAudioStreamSync:request:error:]
-[CSXPCClient prepareAudioStream:request:completion:]
v24@?0@"NSDictionary"8@"NSDictionary"16
-[CSXPCClient voiceTriggerInfo:]
-[CSXPCClient enableVoiceTrigger:withAssertion:]
voicetrigger assertion queue
-[CSXPCClient enableVoiceTrigger:withAssertion:]_block_invoke
Enabled
Disabled
sessionID
-[CSXPCClient audioSessionID]
volume
-[CSXPCClient getEstimatedTTSVolume]
alarmState
timerState
sampleCount
replyHostTime
-[CSXPCClient hostTimeFromSampleCount:]
replySampleCount
-[CSXPCClient sampleCountFromHostTime:]
-[CSXPCClient _handleListenerEvent:]
-[CSXPCClient _handleListenerMessage:]
-[CSXPCClient _handleListenerError:]
-[CSXPCClient _handleAlertProvidingDelegateMessageBody:]
didFinishAlertPlayback
-[CSXPCClient _handleSessionProvidingDelegateMessageBody:]
interruptionContext
-[CSXPCClient _handleSessionProvidingDelegateBeginInterruptionWithContext:]
willSetAudioSessionActive
didSetAudioSessionActive
streamHandleIdInvalidationflag
-[CSXPCClient _handleSessionInfoProvidingDelegateMessageBody:]
notificationInfo
-[CSXPCClient _handleSessionInfoProvidingDelegateInterruptionNotification:]
-[CSXPCClient _handleSessionInfoProvidingDelegateRouteChangeNotification:]
-[CSXPCClient _handleSessionInfoProvidingDelegateMediaServicesWereLostNotification:]
-[CSXPCClient _handleSessionInfoProvidingDelegateMediaServicesWereResetNotification:]
-[CSXPCClient _handleStreamProvidingDelegateMessageBody:]
activationAssertions
T@"NSMutableSet",&,N,V_activationAssertions
audioSessionInfoObservers
T@"NSHashTable",&,N,V_audioSessionInfoObservers
audioSessionProvidingDelegate
T@"<CSAudioSessionProvidingDelegate>",W,N,V_audioSessionProvidingDelegate
audioStreamProvidingDelegate
T@"<CSAudioStreamProvidingDelegate>",W,N,V_audioStreamProvidingDelegate
audioAlertProvidingDelegate
T@"<CSAudioAlertProvidingDelegate>",W,N,V_audioAlertProvidingDelegate
CSOpportuneSpeakListnerTestService
com.apple.corespeech.opportunelistner.start
v12@?0i8
com.apple.corespeech.opportunelistner.stop
A945B95D-69F6-FC77-4FAE-91F50A039CD8
-[CSOpportuneSpeakListnerTestService receiveOpportuneSpeakListenerStart]_block_invoke
-[CSOpportuneSpeakListnerTestService receiveOpportuneSpeakListenerStop]_block_invoke
-[CSOpportuneSpeakListnerTestService opportuneSpeakListener:hasRemoteVADAvailable:]
-[CSOpportuneSpeakListnerTestService opportuneSpeakListener:hasVADAvailable:]
-[CSOpportuneSpeakListnerTestService opportuneSpeakListener:didStopUnexpectly:]
CSTimerMonitor queue
-[CSTimerMonitor _startMonitoringWithQueue:]
-[CSTimerMonitor _stopMonitoring]
kVTPreferencesPhraseSpotterEnabledDidChangeDarwinNotification
-[CSPhraseSpotterEnabledMonitor _checkPhraseSpotterEnabled]
-[CSPhraseSpotterEnabledMonitor _phraseSpotterEnabledDidChange]
CSVoiceTriggerAssetHandler
self ENDSWITH '.wav'
-[CSSpeakerModel discard]
modelPath
utteranceDirectory
tiModelPath
tiUtteranceDirectory
tdtiModelPath
tdtiUtteranceDirectory
enrollmentUtterance
T@"NSArray",R,N
isValid
needsRetrain
-[CSAudioStreamHolding dealloc]
name
T@"NSString",&,N,V_name
smartSiriVolume
noiseLevelChannelBitset
LKFSChannelBitset
energyBufferSize
noiseLowerPercentile
noiseUpperPercentile
LKFSLowerPercentile
LKFSUpperPercentile
noiseTimeConstant
noiseMicSensitivityOffset
LKFSTimeConstant
LKFSMicSensitivityOffset
noiseTTSMappingInputRangeLow
noiseTTSMappingInputRangeHigh
noiseTTSMappingOutputRangeLow
noiseTTSMappingOutputRangeHigh
LKFSTTSMappingInputRangeLow
LKFSTTSMappingInputRangeHigh
LKFSTTSMappingOutputRangeLow
LKFSTTSMappingOutputRangeHigh
userOffsetInputRangeLow
userOffsetInputRangeHigh
userOffsetOutputRangeLow
userOffsetOutputRangeHigh
TTSVolumeLowerLimitDB
TTSVolumeUpperLimitDB
noiseWeight
SSVNoiseLevelChannelBitset
TQ,R,N
SSVLKFSChannelBitset
SSVEnergyBufferSize
TI,R,N
SSVNoiseLowerPercentile
SSVNoiseUpperPercentile
SSVLKFSLowerPercentile
SSVLKFSUpperPercentile
SSVNoiseTimeConstant
Tf,R,N
SSVNoiseMicSensitivityOffset
SSVLKFSTimeConstant
SSVLKFSMicSensitivityOffset
SSVNoiseTTSMappingInputRangeLow
SSVNoiseTTSMappingInputRangeHigh
SSVNoiseTTSMappingOutputRangeLow
SSVNoiseTTSMappingOutputRangeHigh
SSVLKFSTTSMappingInputRangeLow
SSVLKFSTTSMappingInputRangeHigh
SSVLKFSTTSMappingOutputRangeLow
SSVLKFSTTSMappingOutputRangeHigh
SSVUserOffsetInputRangeLow
SSVUserOffsetInputRangeHigh
SSVUserOffsetOutputRangeLow
SSVUserOffsetOutputRangeHigh
SSVTTSVolumeLowerLimitDB
SSVTTSVolumeUpperLimitDB
SSVNoiseWeight
SSVParameterDirectionary
T@"NSDictionary",R,N
RTModelData
RTModelHash
RTModelLocale
RTModelDigest
RTModelSignature
RTModelCertificate
RT Model for 
 from asset 
CorealisRTModel
CorealisRTModelVersion
dataSize(%d), hash(%@), locale(%@), digest(%@), cert(%@), signature(%@)
supportsSecureCoding
TB,R
modelData
T@"NSData",R,N,V_modelData
modelLocale
T@"NSString",R,N,V_modelLocale
modelHash
T@"NSString",R,N,V_modelHash
digest
T@"NSData",R,N,V_digest
signature
T@"NSData",R,N,V_signature
certificate
T@"NSData",R,N,V_certificate
CSAudioProvider
-[CSAudioProvider setAudioRecorder:]_block_invoke
-[CSAudioProvider setCurrentContext:error:]
-[CSAudioProvider setCurrentContext:error:]_block_invoke
-[CSAudioProvider _audioStreamWithRequest:streamName:error:]
-[CSAudioProvider _prepareAudioStreamSync:request:error:]
-[CSAudioProvider _createCircularBufferIfNeeded]
-[CSAudioProvider _tearDownCircularBufferIfNeeded]
-[CSAudioProvider startAudioStream:option:completion:]
-[CSAudioProvider startAudioStream:option:completion:]_block_invoke
-[CSAudioProvider prepareAudioStreamSync:request:error:]
-[CSAudioProvider prepareAudioStream:request:completion:]
-[CSAudioProvider _startAudioStream:option:completion:]
-[CSAudioProvider _handleDidStartAudioStreamWithResult:error:]
-[CSAudioProvider _handleDidStopAudioStreamWithReason:]
-[CSAudioProvider _stopAudioStream:option:completion:]
-[CSAudioProvider holdAudioStreamWithDescription:timeout:]
-[CSAudioProvider holdAudioStreamWithDescription:timeout:]_block_invoke_2
-[CSAudioProvider holdAudioStreamWithDescription:timeout:]_block_invoke
-[CSAudioProvider cancelAudioStreamHold:]
-[CSAudioProvider cancelAudioStreamHold:]_block_invoke
-[CSAudioProvider prewarmAudioSessionWithError:]
-[CSAudioProvider activateAudioSessionWithReason:error:]
-[CSAudioProvider _activateAudioSessionWithReason:error:]
-[CSAudioProvider deactivateAudioSession:error:]
-[CSAudioProvider _deactivateAudioSession:error:]
-[CSAudioProvider setAlertSoundFromURL:forType:]
-[CSAudioProvider playAlertSoundForType:]
-[CSAudioProvider playRecordStartingAlertAndResetEndpointer]
-[CSAudioProvider alertStartTime]
-[CSAudioProvider _shouldStopRecording]
-[CSAudioProvider audioRecorderStreamHandleIdInvalidated:]
-[CSAudioProvider audioRecorderWillBeDestroyed:]_block_invoke
-[CSAudioProvider _processAudioBuffer:remoteVAD:atTime:]
-[CSAudioProvider _scheduleAlertFinishTimeout:]
-[CSAudioProvider _scheduleAlertFinishTimeout:]_block_invoke
-[CSAudioProvider _didReceiveFinishStartAlertPlaybackAt:]
-[CSAudioProvider audioRecorderBuiltInAudioStreamInvalidated:error:]_block_invoke
-[CSAudioProvider audioRecorderDisconnected:]
-[CSAudioProvider CSAudioServerCrashMonitorDidReceiveServerCrash:]
-[CSAudioProvider CSAudioServerCrashMonitorDidReceiveServerRestart:]
-[CSAudioProvider _handleAudioSystemFailure]
StreamInit
StreamPrepared
StreamStarting
StreamSteaming
StreamStopping
unknown(%tu)
Recording transaction
-[CSAudioProvider _releaseRecordingTransactionIfNeeded]
recordQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_recordQueue
audioRecorder
T@"CSAudioRecorder",&,N,V_audioRecorder
streamState
TQ,N,V_streamState
startPendingStreams
T@"NSHashTable",&,N,V_startPendingStreams
alertPlaybackFinishWaitingStreams
T@"NSHashTable",&,N,V_alertPlaybackFinishWaitingStreams
streams
T@"NSHashTable",&,N,V_streams
stopPendingStreams
T@"NSHashTable",&,N,V_stopPendingStreams
pendingStartCompletions
T@"NSMutableArray",&,N,V_pendingStartCompletions
alertPlaybackFinishWaitingCompletions
T@"NSMutableArray",&,N,V_alertPlaybackFinishWaitingCompletions
pendingStopCompletions
T@"NSMutableArray",&,N,V_pendingStopCompletions
sessionDelegate
T@"<CSAudioSessionProvidingDelegate>",W,N,V_sessionDelegate
streamHolders
T@"NSMutableArray",&,N,V_streamHolders
historicalBufferRequestStreams
T@"NSHashTable",&,N,V_historicalBufferRequestStreams
circularBuffer
T@"CSAudioCircularBuffer",&,N,V_circularBuffer
alertDelegate
T@"<CSAudioAlertProvidingDelegate>",W,N,V_alertDelegate
lastAudioRecorderContext
T@"CSAudioRecordContext",&,N,V_lastAudioRecorderContext
audioSystemRecovering
TB,N,V_audioSystemRecovering
audioPreprocessor
T@"CSAudioPreprocessor",&,N,V_audioPreprocessor
recordingTransaction
T@"CSOSTransaction",&,N,V_recordingTransaction
audioStreamHandleId
TQ,N,V_audioStreamHandleId
alertPlaybackFinishTimeoutToken
T@"NSUUID",&,N,V_alertPlaybackFinishTimeoutToken
UUID
T@"NSString",R,N,V_UUID
allowVoiceTriggerAssetDownloading
TB,N,V_allowVoiceTriggerAssetDownloading
allowEndpointAssetDownloading
TB,N,V_allowEndpointAssetDownloading
allowLanguageDetectorAssetDownloading
TB,N,V_allowLanguageDetectorAssetDownloading
+[CSUtils(Directory) removeLogFilesInDirectory:matchingPattern:beforeDays:]_block_invoke
v24@?0@"NSArray"8^@16
+[CSUtils(Directory) clearLogFilesInDirectory:matchingPattern:exceedNumber:]_block_invoke_2
+[CSUtils(Directory) clearLogFilesInDirectory:matchingPattern:exceedNumber:]_block_invoke
Unable to get %@ for file at %@: %@
q24@?0@"NSURL"8@"NSURL"16
B24@?0@"NSURL"8@"NSDictionary"16
+[CSUtils(Directory) _contentsOfDirectoryAtURL:matchingPattern:includingPropertiesForKeys:error:]
-[CSVoiceTriggerEnabledPolicyNonAOP _addVoiceTriggerEnabledConditions]_block_invoke
-[CSKeywordAnalyzerNDAPI initWithConfigPath:resourcePath:]
-[CSKeywordAnalyzerNDAPI _setStartAnalyzeTime:]
samples_at_fire
threshold_normal
-[CSKeywordAnalyzerNDAPI getThreshold]
threshold_logging
-[CSKeywordAnalyzerNDAPI getLoggingThreshold]
activePhraseId
TI,N,V_activePhraseId
T@"<CSKeywordAnalyzerNDAPIScoreDelegate>",W,N,V_delegate
rtblobs
blob
majorVersion
minorVersion
cert
rtlocalemap
-[CSAsset(RTModel) RTModelWithFallbackLanguage:]
-[CSAsset(RTModel) latestHearstRTModelForLocale:]
-[CSAsset(RTModel) hearstRTModelWithMajorVersion:minorVersion:locale:]
-[CSAsset(RTModel) hearstRTModelLocaleMap]
%02x
-[CSAudioRecorder initWithQueue:error:]
-[CSAudioRecorder willDestroy]
-[CSAudioRecorder dealloc]
-[CSAudioRecorder _destroyVoiceController]
-[CSAudioRecorder _voiceControllerWithError:]
-[CSAudioRecorder setContext:error:]
-[CSAudioRecorder setCurrentContext:streamHandleId:error:]
-[CSAudioRecorder prepareAudioStreamRecord:streamHandleId:error:]
-[CSAudioRecorder _startAudioStreamForAudioInjection]
-[CSAudioRecorder startAudioStreamWithOption:streamHandleId:error:]
-[CSAudioRecorder stopAudioStreamWithStreamHandleId:error:]
-[CSAudioRecorder isSessionCurrentlyActivated]
Builtin Microphone
-[CSAudioRecorder recordingSampleRateWithStreamHandleId:]
-[CSAudioRecorder prewarmAudioSessionWithStreamHandleId:error:]
-[CSAudioRecorder activateAudioSessionWithReason:streamHandleId:error:]
-[CSAudioRecorder deactivateAudioSession:streamHandleId:error:]
-[CSAudioRecorder setDuckOthersOption:]
-[CSAudioRecorder enableMiniDucking:]
-[CSAudioRecorder configureAlertBehavior:]
-[CSAudioRecorder voiceTriggerInfo]
useRemoteBuiltInMic
-[CSAudioRecorder _processAudioBuffer:audioStreamHandleId:]
-[CSAudioRecorder _compensateChannelDataIfNeeded:receivedNumChannels:]
-[CSAudioRecorder playAlertSoundForType:]
-[CSAudioRecorder voiceControllerDidStartRecording:forStream:successfully:error:]
-[CSAudioRecorder voiceControllerAudioCallback:forStream:buffer:]
-[CSAudioRecorder voiceControllerDidStopRecording:forStream:forReason:]
-[CSAudioRecorder voiceControllerStreamInvalidated:forStream:]
-[CSAudioRecorder voiceControllerRecordHardwareConfigurationDidChange:toConfiguration:]
-[CSAudioRecorder voiceControllerDidFinishAlertPlayback:ofType:error:]
-[CSAudioRecorder voiceControllerEncoderErrorDidOccur:error:]
-[CSAudioRecorder voiceControllerBeginRecordInterruption:]
-[CSAudioRecorder voiceControllerBeginRecordInterruption:withContext:]
-[CSAudioRecorder voiceControllerEndRecordInterruption:]
-[CSAudioRecorder voiceControllerWillSetAudioSessionActive:willActivate:]
-[CSAudioRecorder voiceControllerDidSetAudioSessionActive:isActivated:]
-[CSAudioRecorder voiceControllerMediaServicesWereLost:]
-[CSAudioRecorder voiceControllerMediaServicesWereReset:]
-[CSAudioRecorder _deinterleaveBufferIfNeeded:]
-[CSAudioRecorder _createDeInterleaverIfNeeded]
-[CSAudioRecorder _getRecordSettingsWithRequest:]
duckOthersOption
TB,N
-[CSOpportuneSpeakListener startListenWithOption:completion:]
-[CSOpportuneSpeakListener _startRequestWithCompletion:]_block_invoke_2
-[CSOpportuneSpeakListener _startRequestWithCompletion:]_block_invoke
-[CSOpportuneSpeakListener stopListenWithStateReset:completion:]
-[CSOpportuneSpeakListener stopListenWithStateReset:completion:]_block_invoke
-[CSOpportuneSpeakListener spgEndpointAnalyzer:hasSilenceScoreEstimate:]
-[CSOpportuneSpeakListener CSMediaPlayingMonitor:didReceiveMediaPlayingChanged:]
spgEndpointAnalyzer
T@"CSSPGEndpointAnalyzer",&,N,V_spgEndpointAnalyzer
remoteVADSPGRatio
Ti,N,V_remoteVADSPGRatio
audioStreamProvider
T@"<CSAudioStreamProviding>",&,N,V_audioStreamProvider
audioSessionProvider
T@"<CSAudioSessionProviding>",&,N,V_audioSessionProvider
latestContext
T@"CSAudioRecordContext",&,N,V_latestContext
isMediaPlayingNow
TB,V_isMediaPlayingNow
T@"<CSOpportuneSpeakListenerDelegate>",W,N,V_delegate
-[CSSpeakerDetectorNDAPI _initializeSAT:]
T@"<CSSpeakerDetectorNDAPIDelegate>",W,N,V_delegate
-[NSData(XPCObject) _cs_initWithXPCObject:]
-[CSSiriEnabledMonitor _startMonitoringWithQueue:]
-[CSSiriEnabledMonitor _stopMonitoring]
_AssistantPrefsChangedNotification
-[CSSmartSiriVolumeProvidingProxy handleXPCMessage:messageBody:client:]
-[CSSmartSiriVolumeProvidingProxy _handleGetTTSVolumeRequestMessage:messageBody:client:]
spIdType
profileID
T@"NSString",R,N,V_profileID
sysConfigFilepath
T@"NSString",R,N,V_sysConfigFilepath
sysConfigRoot
satModelDir
satAudioDir
satScoreThreshold
satScoreVTScale
Tf,R,N,V_satScoreVTScale
satScoreVTOffset
Tf,R,N,V_satScoreVTOffset
satScoreNonVTScale
Tf,R,N,V_satScoreNonVTScale
satScoreNonVTOffset
Tf,R,N,V_satScoreNonVTOffset
satLogitCeilScore
Tf,R,N,V_satLogitCeilScore
satLogitFloorScore
Tf,R,N,V_satLogitFloorScore
satImplicitBaseProfileThreshold
TQ,R,N,V_satImplicitBaseProfileThreshold
satImplicitProfileThreshold
TQ,R,N,V_satImplicitProfileThreshold
satImplicitProfileDeltaThreshold
TQ,R,N,V_satImplicitProfileDeltaThreshold
retrainThresholdTrigger
Tf,R,N,V_retrainThresholdTrigger
retrainExplicitUttThresholdSAT
Tf,R,N,V_retrainExplicitUttThresholdSAT
retrainExplicitUttThresholdTDSR
Tf,R,N,V_retrainExplicitUttThresholdTDSR
retrainThresholdSAT
Tf,R,N,V_retrainThresholdSAT
retrainThresholdTDSR
Tf,R,N,V_retrainThresholdTDSR
pruningNumRetentionUtterance
Ti,R,N,V_pruningNumRetentionUtterance
maximumSpeakerVectors
Ti,R,N,V_maximumSpeakerVectors
voiceProfilePruningCookie
T@"NSString",R,N,V_voiceProfilePruningCookie
CSActivationXPCListener
-[CSActivationXPCListener listen]
-[CSActivationXPCListener _handleListenerEvent:]
-[CSActivationXPCListener _handleListenerError:]
-[CSActivationXPCListener _handleNewRemoteConnection:]
-[CSActivationXPCListener CSXPCConnectionReceivedClientError:clientError:client:]
listener
T@"NSObject<OS_xpc_object>",&,N,V_listener
connections
T@"NSMapTable",&,N,V_connections
-[CSAudioSessionInfoProvidingProxy handleXPCMessage:messageBody:client:]
-[CSAudioSessionInfoProvidingProxy _handleSessionIDRequestMessage:messageBody:client:]
audioSessionInfoProvider
T@"<CSAudioSessionInfoProviding>",W,N,V_audioSessionInfoProvider
com.apple.MobileAsset.VoiceTriggerAssets
com.apple.MobileAsset.VoiceTriggerAssetsWatch
com.apple.MobileAsset.VoiceTriggerAssetsMarsh
com.apple.MobileAsset.VoiceTriggerAssetsMac
com.apple.MobileAsset.SpeechEndpointAssets
com.apple.MobileAsset.LanguageDetectorAssets
-[CSAssetController init]
Serial CSAssetController queue
V1 Assets Clean-up queue
-[CSAssetController _cleanUpMobileAssetV1Directory]
-[CSAssetController assetOfType:language:]
-[CSAssetController assetOfType:language:completion:]
-[CSAssetController installedAssetOfType:language:]
-[CSAssetController installedAssetOfType:language:completion:]
v24@?0@"MAAsset"8@"NSError"16
-[CSAssetController _installedAssetOfType:withLanguage:]
-[CSAssetController _installedAssetOfType:withLanguage:completion:]_block_invoke
v16@?0q8
-[CSAssetController _installedAssetWithoutMetaDataForType:withLanguage:completion:]_block_invoke
-[CSAssetController _installedAssetWithoutMetaDataForType:withLanguage:]
-[CSAssetController _findLatestInstalledAsset:]
-[CSAssetController _assetQueryForAssetType:]
-[CSAssetController _runAssetQuery:completion:]
-[CSAssetController _runAssetQuery:completion:]_block_invoke
-[CSAssetController fetchRemoteMetaOfType:]
v16@?0@"NSError"8
-[CSAssetController _fetchRemoteAssetOfType:withLanguage:completion:]
-[CSAssetController _fetchRemoteAssetOfType:withLanguage:completion:]_block_invoke_2
-[CSAssetController _fetchRemoteAssetOfType:withLanguage:completion:]_block_invoke
-[CSAssetController _downloadAssetCatalogForAssetType:complete:]_block_invoke
-[CSAssetController _updateFromRemoteToLocalAssets:forAssetType:completion:]
-[CSAssetController _downloadAsset:withComplete:]
v16@?0d8
-[CSAssetController _downloadAsset:withComplete:]_block_invoke
-[CSAssetController _startDownloadingAsset:progress:completion:]
v16@?0@"MAProgressNotification"8
+[CSAssetController(Utils) addKeyValuePairForQuery:assetType:]
voic
carplay
hearst
raisetospeak
auto
unknown
-[NSNumber(XPCObject) _cs_initWithXPCObject:]
-[NSNumber(XPCObject) _cs_xpcObject]
samples_fed
best_phrase
best_start
best_end
best_score
early_warning
is_rescoring
sampleFed
TQ,N,V_sampleFed
bestPhrase
TQ,N,V_bestPhrase
bestStart
TQ,N,V_bestStart
bestEnd
TQ,N,V_bestEnd
bestScore
Tf,N,V_bestScore
earlyWarning
TB,N,V_earlyWarning
isRescoring
TB,N,V_isRescoring
dictionary
triggerStartSampleCount
isMediaPlaying
noiseLevelDB
musicLevelDB
musicPlaybackVolumeDB
alarmVolume
finalTTSVolume
isAlarmPlaying
isTimerPlaying
isLKFSProcessPaused
removeVoiceTriggerSamples
-[CSSmartSiriVolume initWithSamplingRate:asset:]
-[CSSmartSiriVolume startSmartSiriVolume]_block_invoke
RUNNING
PAUSED
v12@?0B8
-[CSSmartSiriVolume _startListenPolling]
-[CSSmartSiriVolume _startListenPollingWithInterval:completion:]
-[CSSmartSiriVolume _startListenPollingWithInterval:completion:]_block_invoke
-[CSSmartSiriVolume _startListenWithCompletion:]_block_invoke_4
-[CSSmartSiriVolume _startListenWithCompletion:]_block_invoke
-[CSSmartSiriVolume _stopListening]
-[CSSmartSiriVolume _stopListening]_block_invoke
-[CSSmartSiriVolume initializeMediaPlayingState]_block_invoke
playing
NOT playing
-[CSSmartSiriVolume initializeMediaPlayingState]
-[CSSmartSiriVolume initializeAlarmState]_block_invoke
firing
NOT firing
-[CSSmartSiriVolume initializeTimerState]_block_invoke
-[CSSmartSiriVolume _setAsset:]
-[CSSmartSiriVolume _processAudioChunk:soundType:]
v16@?0Q8
-[CSSmartSiriVolume estimateSoundLevelbySoundType:]_block_invoke
-[CSSmartSiriVolume _pauseSSVProcessing]_block_invoke
-[CSSmartSiriVolume _resumeSSVProcessing]_block_invoke
-[CSSmartSiriVolume audioStreamProvider:audioBufferAvailable:]_block_invoke
-[CSSmartSiriVolume audioStreamProvider:didStopStreamUnexpectly:]
-[CSSmartSiriVolume voiceTriggerDidDetectKeyword:deviceId:]
-[CSSmartSiriVolume voiceTriggerDidDetectKeyword:deviceId:]_block_invoke
-[CSSmartSiriVolume estimatedTTSVolumeForNoiseLevelAndLKFS:LKFS:]_block_invoke
-[CSSmartSiriVolume _combineResultsWithOptimalFromNoise:andOptimalFromLkfs:withUserOffset:]
-[CSSmartSiriVolume CSMediaPlayingMonitor:didReceiveMediaPlayingChanged:]_block_invoke
-[CSSmartSiriVolume CSAlarmMonitor:didReceiveAlarmChanged:]_block_invoke
-[CSSmartSiriVolume CSTimerMonitor:didReceiveTimerChanged:]_block_invoke
-[CSSmartSiriVolume CSSiriEnabledMonitor:didReceiveEnabled:]
-[CSSmartSiriVolume CSAudioServerCrashMonitorDidReceiveServerRestart:]
-[CSSmartSiriVolume _setStartAnalyzeTime:]
listenPollingTimer
T@"NSObject<OS_dispatch_source>",&,N,V_listenPollingTimer
listenPollingTimerCount
Tq,N,V_listenPollingTimerCount
T@"<CSSmartSiriVolumeDelegate>",W,N,V_delegate
-[CSListeningEnabledPolicyWatch _addListeningEnabledConditions]_block_invoke
+[CSUtils(LanguageCode) getSiriLanguageWithFallback:]
CSAudioFileReader Queue
-[CSAudioFileReader initWithURL:]
-[CSAudioFileReader prepareRecording:]
-[CSAudioFileReader startRecording]
-[CSAudioFileReader _readAudioBufferAndFeed]
-[CSAudioFileReader stopRecording]
T@"<CSAudioFileReaderDelegate>",W,N,V_delegate
triggerEndMachTime
-[CSMyriadSelfTriggerCoordinator selfTriggerDetector:didDetectSelfTrigger:]
/private/var/tmp/siriBC
com.apple.siri.corespeech.selftrigger
T@"<CSMyriadSelfTriggerCoordinatorDelegate>",W,N,V_delegate
com.apple.corespeech.voiceprofilestore
-[CSUserVoiceProfileStore initStore]_block_invoke
com.apple.siri.corespeech.voiceprofilelist.change
.wav
-[CSUserVoiceProfileStore addImplicitUtterance:toVoiceProfile:withTriggerSource:withAudioInput:withCompletion:]_block_invoke_2
v32@?0Q8Q16Q24
-[CSUserVoiceProfileStore addImplicitUtterance:toVoiceProfile:withTriggerSource:withAudioInput:withCompletion:]_block_invoke
Failed to copy %@ to %@ with error %@
reason
Failed to move %@ to %@ with error %@
ERR: Utterance %@ in profile %@ resulted in invalid %@ 
Rejecting Implicit utterance %@ for profile %@
@"NSError"24@?0@"NSData"8Q16
-[CSUserVoiceProfileStore evaluateSpeakerVector:withVectorSize:forProfile:withBaseThreshold:withImplicitThreshold:withDeltaThreshold:]
v32@?0@"NSString"8@"NSNumber"16^B24
Profile is nil!
-[CSUserVoiceProfileStore addUserVoiceProfile:fromUtteranceCache:withCompletion:]_block_invoke
directoryPathURL is nil!
audio
v32@?0@"NSString"8Q16^B24
json
v32@?0@"NSURL"8Q16^B24
-[CSUserVoiceProfileStore addUserVoiceProfile:fromUtteranceCache:withCompletion:]_block_invoke_2
v24@?0@"NSString"8@"NSError"16
-[CSUserVoiceProfileStore deleteUserVoiceProfile:]_block_invoke
Profile path is nil!
Failed to delete profile at %@ with error %@
-[CSUserVoiceProfileStore retrainVoiceProfilesForLanguage:withForceRetrain:withCompletion:]_block_invoke
VoiceProfile is nil - Bailing out
-[CSUserVoiceProfileStore _retrainVoiceProfile:withForceRetrain:withCompletion:]
-[CSUserVoiceProfileStore _migrationAssistantForUserVoiceProfilesForLocale:]
-[CSUserVoiceProfileStore _trainedUsersForLocale:]
v32@?0@"CSUserVoiceProfile"8Q16^B24
-[CSUserVoiceProfileStore _updateTrainedUsersWithAction:UserVoiceProfile:]
-[CSUserVoiceProfileStore _saveTrainedUsers:forLocale:]
-[CSUserVoiceProfileStore _getContentsOfDirectory:]
-[CSUserVoiceProfileStore _updateHomeUserId:forProfileWithSiriProfileId:]
-[CSUserVoiceProfileStore _retrainExplicitOnlyModelForVoiceProfile:withForceRetrain:]
No audio files for VoiceProfile %@ and modelType %@ 
-[CSUserVoiceProfileStore _retrainVoiceProfile:forModelType:withUtterances:withForceRetrain:]
-[CSUserVoiceProfileStore _retrainVoiceProfile:forModelType:withUtterances:withForceRetrain:]_block_invoke
v32@?0@"NSError"8@"NSDictionary"16@"NSDictionary"24
-[CSUserVoiceProfileStore _importVoiceProfile:forModelType:withContentsOfDirectory:]
-[CSUserVoiceProfileStore _importVoiceProfile:forModelType:withContentsOfDirectory:]_block_invoke
Too less (%d) audio files at %@ 
voiceProfileArray
T@"NSMutableArray",&,V_voiceProfileArray
languageCode
T@"NSString",&,N,V_languageCode
beepLocation
statsComputed
beepPower
signalPower
originalPower
absMaxVal
above95pcOfMax
totalInputSamples
totalOutputSamples
jbl_begin.bin
-[CSBeepCanceller init]
-[CSBeepCanceller willBeep]
-[CSBeepCanceller reset]
T@"<CSBeepCancellerDelegate>",W,N,V_delegate
metrics
-[CSSpringboardStartMonitor _startMonitoringWithQueue:]
-[CSSpringboardStartMonitor _stopMonitoring]
-[CSSpringboardStartMonitor _checkSpringBoardStarted]
com.apple.springboard.finishedstartup
CSActivationEventNotifier
-[CSActivationEventNotifier notifyActivationEvent:completion:]_block_invoke
-[CSActivationEventNotifier notifyActivationEventForCoreSpeechDaemon:completion:]_block_invoke
-[CSActivationEventNotifier _notifyActivationEvent:completion:]
-[CSActivationEventNotifier _notifyActivationEvent:completion:]_block_invoke
-[CSActivationEventNotifier notifyActivationEvent:deviceId:activationInfo:completion:]_block_invoke
-[CSActivationEventNotifier setDelegate:for:]_block_invoke
-[CSActivationEventNotifier _didReceiveAOPFirstPassTrigger:completion:]
-[CSActivationEventNotifier _didReceiveAOPFirstPassTrigger:completion:]_block_invoke
TestSetAPMode
TestSetAOPMode
-[CSActivationEventNotifier receiveTestNotificationAPMode]
-[CSActivationEventNotifier receiveTestNotificationAOPMode]
-[CSActivationEventNotifier _createXPCClientConnectionIfNeeded]
notifyToken
Ti,N,V_notifyToken
delegates
T@"NSMapTable",&,N,V_delegates
pendingActivationEvent
T@"CSActivationEvent",&,N,V_pendingActivationEvent
pendingCompletion
T@?,C,N,V_pendingCompletion
activationXPCClient
T@"CSActivationXPCClient",&,N,V_activationXPCClient
CSAlarmMonitor queue
-[CSAlarmMonitor _startMonitoringWithQueue:]
-[CSAlarmMonitor _stopMonitoring]
-[CSFirstUnlockMonitor _stopMonitoring]
-[NSString(XPCObject) _cs_initWithXPCObject:]
+[CSVoiceTriggerEnrollmentDataManager saveRawUtteranceAndMetadata:to:isExplicitEnrollment:]
.json
+[CSVoiceTriggerEnrollmentDataManager saveUtteranceAndMetadata:atDirectory:isExplicitEnrollment:]
+[CSVoiceTriggerEnrollmentDataManager saveUtterance:utteranceAudioPath:numSamplesToWrite:isExplicitEnrollment:]
+[CSVoiceTriggerEnrollmentDataManager saveMetadata:isExplicitEnrollment:]
+[CSVoiceTriggerEnrollmentDataManager _getBaseMetaDictionaryForUtterancePath:]
+[CSVoiceTriggerEnrollmentDataManager writeMetaDict:atMetaPath:]
+[CSInvalidSATEntriesCleaner cleanupInvalidSATEntriesAtSATRoot:payloadUtteranceLifeTimeInDays:dryRun:]
-[NSArray(XPCObject) _cs_initWithXPCObject:]
-[NSArray(XPCObject) _cs_initWithXPCObject:]_block_invoke
B24@?0Q8@"NSObject<OS_xpc_object>"16
-[NSArray(XPCObject) _cs_xpcObject]_block_invoke
v32@?0@8Q16^B24
-[CSAudioChunkForTV initWithXPCObject:]
T@"NSArray",&,N,V_packets
Tf,N,V_avgPower
Tf,N,V_peakPower
TQ,N,V_timeStamp
avgPower
peakPower
timeStamp
packets
route
isRemoteDevice
remoteDeviceUID
remoteDeviceProductIdentifier
%@ {route = %@, isRemoteDevice = %d, remoteDeviceUID = %@, remoteDeviceProductIdentifier = %@}
T@"NSString",R,C,N,V_route
TB,R,N,V_isRemoteDevice
T@"NSUUID",R,C,N,V_remoteDeviceUID
T@"NSString",R,C,N,V_remoteDeviceProductIdentifier
-[CSPlainAudioFileWriter initWithURL:inputFormat:outputFormat:]
-[CSPlainAudioFileWriter addSamples:numSamples:]
fileURL
T@"NSURL",R,N,V_fileURL
-[CSAudioStream initWithAudioStreamProvider:streamName:streamRequest:]
-[CSAudioStream dealloc]
-[CSAudioStream isStreaming]
-[CSAudioStream audioStreamProvider:didStopStreamUnexpectly:]
-[CSAudioStream audioStreamProvider:didHardwareConfigurationChange:]
streamProvider
T@"<CSAudioStreamProviding>",W,N,V_streamProvider
streaming
TB,V_streaming
T@"<CSAudioStreamProvidingDelegate>",W,N,V_delegate
lastForwardedSampleCount
TQ,N,V_lastForwardedSampleCount
streamRequest
T@"CSAudioStreamRequest",&,N,V_streamRequest
-[CSVoiceTriggerAssetMetaUpdateMonitor _startMonitoringWithQueue:]
-[CSVoiceTriggerAssetMetaUpdateMonitor _stopMonitoring]
-[CSVoiceTriggerAssetMetaUpdateMonitor _didReceiveNewVoiceTriggerAssetMetaData]
com.apple.MobileAsset.VoiceTriggerAssets.ma.cached-metadata-updated
com.apple.MobileAsset.VoiceTriggerAssetsWatch.ma.cached-metadata-updated
com.apple.MobileAsset.VoiceTriggerAssetsMarsh.ma.cached-metadata-updated
com.apple.MobileAsset.VoiceTriggerAssetsMac.ma.cached-metadata-updated
-[CSAudioPreprocessor resetWithSampleRate:containsVoiceTrigger:voiceTriggerInfo:]
-[CSAudioPreprocessor flush]
ZeroFilterMetrics
-[CSAudioPreprocessor _reportMetrics]
BeepCancellerMetrics
sampleRate
Tf,N,V_sampleRate
upsampler
T@"CSAudioSampleRateConverter",&,N,V_upsampler
zeroFilter
T@"CSVoiceTriggerAwareZeroFilter",&,N,V_zeroFilter
beepCanceller
T@"CSBeepCanceller",&,N,V_beepCanceller
zeroCounter
T@"CSAudioZeroCounter",&,N,V_zeroCounter
T@"<CSAudioPreprocessorDelegate>",W,N,V_delegate
profileUpdateNumPrunedUttsPHS
profileUpdateNumDiscardedUttsPHS
profileUpdateNumRetainedUttsPHS
xx_XX
com.apple.corespeech.aggregator
uptimeSeconds
-[CSAggregator _logUptime]
downtimeSeconds
profileUpdateFailCode
profileUpdateScoreMSE
TdPsrSATRetrainingTimedOut
TdPsrSATRetrainingWaitTimeMs
%@.%@
com.apple.corespeech
%@.%@.%@
-[CSAggregator _addValueForScalarKey:withValue:]
-[CSAggregator _pushValueForDistributionKey:withValue:]
ADClientAddValueForScalarKey
/System/Library/PrivateFrameworks/AggregateDictionary.framework/AggregateDictionary
ADClientPushValueForDistributionKey
meta_version.json
enrollment_version.json
meta_version
trainingType
explicit
implicit
implicitBaseProfile
handheld
near-field
far-field
utteranceWav
productVersion
productType
triggerSource
audioInputSource
otherSourceProfileMatch
containsPayload
grainedDate
+[CSUtteranceMetadataManager saveUtteranceMetadataForUtterance:enrollmentType:isHandheldEnrollment:triggerSource:audioInput:otherBiometricResult:containsPayload:]
+[CSUtteranceMetadataManager _getBaseMetaDictionaryForUtterancePath:]
+[CSUtteranceMetadataManager _writeMetaDict:forUtterancePath:]
+[CSUtteranceMetadataManager upgradeMetaFilesIfNecessaaryAtSATRoot:]
+[CSUtteranceMetadataManager _saveMetaVersionFileAtPath:]
+[CSUtteranceMetadataManager _upgradeLocaleDirectoryIfNecessary:]
enrollment_completed
+[CSUtteranceMetadataManager _audioDirectoryNeedsUpgrade:]
+[CSUtteranceMetadataManager _upgradeUtteranceMeta:]
+[CSUtteranceMetadataManager isUtteranceImplicitlyTrained:]
+[CSUtteranceMetadataManager getUtteranceEnrollmentType:]
+[CSUtteranceMetadataManager recordedTimeStampOfFile:]
yyyyMMdd
-[CSSpeechEndpointAssetMetaUpdateMonitor _startMonitoringWithQueue:]
-[CSSpeechEndpointAssetMetaUpdateMonitor _stopMonitoring]
-[CSSpeechEndpointAssetMetaUpdateMonitor _didReceiveNewSpeechEndpointAssetMetaData]
com.apple.MobileAsset.SpeechEndpointAssets.ma.cached-metadata-updated
Framework
Logs/CrashReporter/CoreSpeech/audio/
%@/%@%@%@
::: Initializing CoreSpeech logging...
yyyyMMdd-HHmmss
CSLogInitIfNeeded_block_invoke
gitrelno_unavailable
_CSGetOrCreateAudioLogDirectory
/tmp
[profileId: %@, language: %@, product: %@, version: %@, homeId: %@, name: %@]
profileId
T@"NSString",&,N,V_profileId
productCategory
T@"NSString",&,N,V_productCategory
version
T@"NSNumber",&,N,V_version
onboardType
TQ,N,V_onboardType
homeId
T@"NSString",&,N,V_homeId
userName
T@"NSString",&,N,V_userName
baseVersion
T@"NSNumber",&,N,V_baseVersion
implicitVersion
T@"NSNumber",&,N,V_implicitVersion
siriDebugProfileId
T@"NSString",&,N,V_siriDebugProfileId
corespeechd speaker xpc connection client queue
-[CSVoiceIdXPCConnection _handleClientEvent:client:]
-[CSVoiceIdXPCConnection _handleClientMessage:client:]
utterencePath
audioDevice
audioRecord
voiceTriggerEventInfo
-[CSVoiceIdXPCConnection _handleClientMessage:client:]_block_invoke
-[CSVoiceIdXPCConnection _handleClientError:client:]
connection
T@"NSObject<OS_xpc_object>",&,N,V_connection
satTriggered
Library
VoiceTrigger/SAT
-[CSVoiceProfileManager notifyImplicitTrainingUtteranceAvailable:forVoiceProfileId:withRecordDeviceInfo:withRecordCtxt:withVoiceTriggerCtxt:withOtherCtxt:withCompletion:]
Missing downloadTriggerBlock - Bailing out
-[CSVoiceProfileManager notifyUserVoiceProfileDownloadReadyForUser:getData:completion:]
Unknown device category for device type %@ - Bailing out
-[CSVoiceProfileManager notifyUserVoiceProfileUpdateReady]
-[CSVoiceProfileManager notifyUserVoiceProfileUpdateReady]_block_invoke
Enable VoiceTrigger Upon VoiceProfile Sync For Language
-[CSVoiceProfileManager _downloadAndEnrollVoiceProfileForProfileId:withDownloadTriggerBlock:]_block_invoke
v24@?0@"NSError"8@"NSString"16
SAT download path is nil - Bailing out
-[CSVoiceProfileManager _downloadVoiceProfileForProfileId:forDeviceCategory:withDownloadTriggerBlock:withCompletion:]
Download for %@ failed with %@
Failed to get contents of %@ with error %@
-[CSVoiceProfileManager _enrollVoiceProfileForSiriProfileId:fromCacheDirectoryPath:]
Source directory %@ doesnt exist
-[CSVoiceProfileManager _copyVoiceProfileFromSrcDir:toDestDir:]
Profile %@ with mismatch product category - Skipping
Error to copy profile from %@ to %@, error: %@
Migrated language %@ for %@ but failed to mark SAT enrollment
-[CSVoiceProfileManager _markVoiceProfileMigrationCompleteForSiriProfileId:forLanguageCode:]
Failed to mark migrated for %@ in language %@
-[CSVoiceProfileManager _enableVoiceTriggerIfLanguageMatches:]
Caches/VoiceTrigger/SATUpdate
Caches/VoiceTrigger/SATUpdateNewerZone
_%d_%d
-[CSVoiceProfileManager _getUserVoiceProfileDownloadCacheDirectoryWithUpdatePath:]
-[CSVoiceProfileManager uploadUserVoiceProfile:completion:]
Upload for %@ not supported - Bailing out
@"NSError"24@?0@"CSVoiceProfileContext"8@"NSString"16
-[CSVoiceProfileManager notifyUserVoiceProfileUploadComplete:]
-[CSVoiceProfileManager notifyUserVoiceProfileUploadComplete]
-[CSVoiceProfileManager _getVoiceProfilePathsToBeUploaded]
-[CSVoiceProfileManager _copyVoiceProfileAtPath:toPath:]
audiocache
Failed to copy to SATUpload Diretory : %@
ERR: Number of training utterances copied from %@ to %@ is too less %ld
Cannot delete existing SATUpload Diretory : %@
-[CSVoiceProfileManager _prepareVoiceProfilesForUpload:]
Cannot create SAT Upload Directory : %@
Failed to upload %@ with error %@ - Bailing out
-[CSVoiceProfileManager getCachedVoiceProfileAvailabilityMetaBlob]_block_invoke
v24@?0@"NSDictionary"8@"NSError"16
-[CSVoiceProfileManager getCachedVoiceProfileAvailabilityMetaBlob]
-[CSVoiceProfileManager hasVoiceProfileIniCloudForLanguageCode:withBackupMetaBlob:]
ERR: Unknown product type. Returning false, language: %@
-[CSVoiceProfileManager isVoiceProfileUploadedToiCloudForLanguageCode:withCompletionBlock:]
ERR: Unknown device-category for device: %@, languageCode: %@
-[CSVoiceProfileManager isVoiceProfileUploadedToiCloudForLanguageCode:withCompletionBlock:]_block_invoke
-[CSVoiceProfileManager hasVoiceProfileIniCloudForLanguageCode:]
-[CSVoiceProfileManager enableVoiceTriggerUponVoiceProfileSyncForLanguage:]
-[CSVoiceProfileManager devicesWithVoiceProfileIniCloudForLanguage:]
-[CSVoiceProfileManager devicesWithVoiceProfileIniCloudForLanguage:]_block_invoke
v16@?0@"NSArray"8
Caches/VoiceTrigger/SATLegacyUpload
-[CSVoiceProfileManager markSATEnrollmentSuccessForSiriProfileId:forLanguageCode:]
enrollment_migrated
-[CSVoiceProfileManager _markSATEnrollmentWithMarker:forLanguage:forSiriProfileId:]
Library/Caches/VoiceTrigger
Caches/VoiceTrigger/SATUpload
-[CSVoiceProfileManager _createAndSendImplicitUtterenceXPCMessage:withRecordDeviceInfo:withRecordCtxt:withVoiceTriggerCtxt:withCompletion:]
%lld
-[CSVoiceProfileManager _createAndSendImplicitUtterenceXPCMessage:withRecordDeviceInfo:withRecordCtxt:withVoiceTriggerCtxt:withCompletion:]_block_invoke
currentDeviceCategory
TQ,N,V_currentDeviceCategory
xpcClient
T@"CSVoiceIdXPCClient",&,N,V_xpcClient
-[CSAssetManagerEnablePolicy _addAssetManagerEnabledConditions]_block_invoke
CSXPCListener
-[CSXPCListener listen]
-[CSXPCListener _handleListenerEvent:]
-[CSXPCListener _handleListenerError:]
-[CSXPCListener _handleNewRemoteConnection:]
-[CSXPCListener CSXPCConnectionReceivedClientError:clientError:client:]
com.apple.coreaudio.BorealisToggled
-[CSVoiceTriggerEnabledMonitor _startMonitoringWithQueue:]_block_invoke
-[CSVoiceTriggerEnabledMonitor _startMonitoringWithQueue:]
-[CSVoiceTriggerEnabledMonitor _stopMonitoring]
-[CSVoiceTriggerEnabledMonitor _checkVoiceTriggerEnabled]
-[CSAlwaysOnProcessorStateMonitor _didReceiveAOPListeningStateChange:]
-[CSAudioTimeConversionProvidingProxy handleXPCMessage:messageBody:client:]
-[CSAudioTimeConversionProvidingProxy _handleXPCTimeConvertProvidingTypeHostTimeFromSampleCountMessage:messageBody:client:]
-[CSAudioTimeConversionProvidingProxy _handleXPCTimeConvertProvidingTypeSampleCountFromHostTimeMessage:messageBody:client:]
CSP2P_CommandType_Key
CSP2P_CommandDict_Key
corespeech
com.apple.siridebug.command.remote.heysiri
com.apple.siridebug.command.parallel.recording
com.apple.siridebug.command.transfer.voiceprofile
com.apple.siridebug.command.query.voiceprofile
com.apple.siridebug.command.reverse.transfer.voiceprofile
com.apple.siridebug.command.fetch.voiceprofile
com.apple.siridebug.command.voiceprofile.update.trigger
com.apple.siridebug.command.fetch.parallelrecording
com.apple.siridebug.command.transfer.parallelrecording
com.apple.siridebug.command.fetch.voicegradingdata
com.apple.siridebug.command.transfer.voicegradingdata
com.apple.siridebug.command.delete.voiceprofile
com.apple.siridebug.command.musicaccount.signin
CSP2P_RemoteHeySiriEnable_Key
CSP2P_RemoteHeySiriStatus_Key
CSP2P_RemoteRecordingStart_Key
CSP2P_RemoteRecordingStatus_Key
CSP2P_VoiceProfileData_Key
CSP2P_VoiceProfileFileName_Key
CSP2P_VoiceProfileSpeakerName_Key
CSP2P_VoiceProfileLocale_Key
CSP2P_VoiceProfileDataType_Key
CSP2P_VoiceProfileSegment_Key
CSP2P_VoiceProfileTotalSegments_Key
CSP2P_VoiceProfileStatus_Key
CSP2P_VoiceProfileProfileId_Key
CSP2P_VoiceProfileHomeId_Key
CSP2P_VoiceProfileRelativeFilePath_Key
CSP2P_VoiceProfileBaseVersion_Key
CSP2P_VoiceProfileImplicitVersion_Key
CSP2P_VoiceProfileSiriProfileId_Key
CSP2P_VoiceProfileOnboardType_Key
CSP2P_VoiceProfileOnboardTimeStamp_Key
CSP2P_VoiceProfileTransferCompleted_Key
CSP2P_VoiceProfileRecordedData_Key
CSP2P_VoiceProfileRemoteFileName_Key
CSP2P_VoiceDataToBeGraded_Key
CSP2P_VoiceFileNameToBeGraded_Key
CSP2P_GradingDataTransferStatus_Key
CSP2P_PeerIdentifier_Key
CSP2P_IsDataCompressed_Key
CSP2P_UncompressedDataSize_Key
CSP2P_GradingBatchTransferID_Key
CSP2P_MusicSigninMultiUserToken_Key
CSP2P_MusicSigninDsid_Key
CSP2P_MusicSigninAltDsid_Key
CSP2P_MusicSigninHomeUserId_Key
CSP2P_MusicSigninHomeId_Key
CSP2P_MusicSigninSiriDebugProfileId_Key
remote
-triggered
-almost
com.apple.corespeech.p2psvc
-[CSP2PService processRemoteCommandWithPayload:fromPeer:withReply:]_block_invoke
CoreSpeech
-[CSP2PService sendInfo1ToNearbyPeer]_block_invoke
-[CSP2PService sendVoiceTriggerGradingDataToCompanion]_block_invoke
-[CSP2PService sendVoiceProfileUpdatedMessageToNearbyPeerForLocale:]_block_invoke
-[CSP2PService _processRemoteHeySiriCommandWithRequest:fromSenderID:withReply:]
-[CSP2PService _compressFilesInDirectory:matchingPredicate:compressedFileAvailable:]
-[CSP2PService _sendParallelRecordingsToPeerId:voiceProfileRequestInfo:withReply:]
-[CSP2PService _sendParallelRecordingsToPeerId:voiceProfileRequestInfo:withReply:]_block_invoke
v52@?0@"NSString"8@"NSData"16Q24Q32B40@"NSError"44
-[CSP2PService _sendVoiceTriggerGradingDataToPeerId:]_block_invoke_2
-[CSP2PService _sendVoiceTriggerGradingDataToPeerId:]_block_invoke
-detected.json
-rejected.json
-[CSP2PService _sendData1ToPeerId:]_block_invoke_2
-detected.wav
-[CSP2PService _sendData1ToPeerId:]_block_invoke
-rejected.wav
-[CSP2PService _sendData1File:withFileName:toPeerId:withCompressedFlag:withUncompressedDataSize:withBatchId:withRetainFileFlag:]
fileData
fileName
peerId
-[CSP2PService _sendData1File:withFileName:toPeerId:withCompressedFlag:withUncompressedDataSize:withBatchId:withRetainFileFlag:]_block_invoke
-[CSP2PService _receiveParallelRecordingFromPeerId:recordingInfo:withReply:]
%@_%@
-[CSP2PService _receiveData1FromPeerId:requestInfo:withReply:]
suppressnotification
-[CSP2PService _processMusicAccountSignInCommandFromPeerId:requestInfo:withReply:]
-[CSP2PService _receiveVoiceProfileFromPeerId:voiceProfileInfo:withReply:]
CoreSpeechCache
-[CSP2PService _processVoiceProfileDeleteCommandWithRequest:fromSenderID:withReply:]_block_invoke
-[CSP2PService _processDataFetchCommandWithRequest:fromSenderID:withReply:]
-[CSP2PService _processVoiceProfileListQueryCommandFromPeerId:requestInfo:withReply:]
voiceprofiles
-[CSP2PService _processFetchVoiceProfileCommandFromPeerId:requestInfo:withReply:]
-[CSP2PService _sendVoiceProfile:toPeerId:]
-[CSP2PService _sendVoiceProfile:toPeerId:]_block_invoke
-[CSP2PService _processReverseTransferVoiceProfileCommandFromPeerId:requestInfo:withReply:]
-[CSP2PService _processVoiceProfileUpdateTriggerFromPeerId:requestInfo:withReply:]
-[CSP2PService _sendVoiceProfileUpdateTriggerToPeerId:forLocale:]_block_invoke
lastCommunicatedPeer
T@"NSString",&,N,V_lastCommunicatedPeer
voiceTriggerBatchId
T@"NSString",&,N,V_voiceTriggerBatchId
voiceIdentificationBatchId
T@"NSString",&,N,V_voiceIdentificationBatchId
adCompanionServiceProvider
T@"<CSADCompanionServiceProvider>",W,N,V_adCompanionServiceProvider
InternalBuild
PTQ+ABwag03BwO/CKvIK/A
UserVoiceProfileDateTrained
UserVoiceProfilePath
UserVoiceProfileID
UserSharedSiriID
UserSharedHomeID
UserSharedSiriDebugID
UserVoiceProfileUserName
UserVoiceProfileOnboardType
Creating CSUserVoiceProfile with no UserName: vpDict: %@
locale
T@"NSString",&,N,V_locale
dateAdded
T@"NSDate",&,N,V_dateAdded
voiceProfileFilePath
T@"NSString",&,N,V_voiceProfileFilePath
T@"NSString",&,N,V_profileID
siriProfileId
T@"NSString",&,N,V_siriProfileId
onboardedType
TQ,N,V_onboardedType
profileOriginIdentifier
T@"NSString",&,N,V_profileOriginIdentifier
Tq,N,V_baseVersion
Tq,N,V_implicitVersion
sharedHomeID
T@"NSString",&,N,V_sharedHomeID
siriDebugID
T@"NSString",&,N,V_siriDebugID
Serial CSAssetManager queue
en-US
-[CSAssetManager initWithDownloadOption:]
-[CSAssetManager initWithDownloadOption:]_block_invoke
ENABLED
DISABLED
-[CSAssetManager setAssetDownloadingOption:]_block_invoke
-[CSAssetManager _fetchRemoteMetaData]
-[CSAssetManager _canFetchRemoteAsset:]
-[CSAssetManager CSLanguageCodeUpdateMonitor:didReceiveLanguageCodeChanged:]
-[CSAssetManager _createPeriodicalDownloadTimer]
-[CSAssetManager _createPeriodicalDownloadTimer]_block_invoke
-[CSAssetManager _startPeriodicalDownload]
-[CSAssetManager _stopPeriodicalDownload]
currentLanguageCode
-[CSVoiceTriggerAwareZeroFilter resetWithSampleRate:containsVoiceTrigger:voiceTriggerInfo:]
triggerEndSeconds
vtEndInSampleCount
TQ,N,V_vtEndInSampleCount
numSamplesProcessed
TQ,N,V_numSamplesProcessed
T@"CSAudioZeroFilter",&,N,V_zeroFilter
T@"<CSVoiceTriggerAwareZeroFilterDelegate>",W,N,V_delegate
T@"<CSSPGEndpointAnalyzerDelegate>",W,N,V_delegate
%@-%@
-[CSOSTransaction initWithDescription:]
-[CSOSTransaction dealloc]
-[CSAudioMetricProvidingProxy handleXPCMessage:messageBody:client:]
-[CSAudioMetricProvidingProxy _handleMetricProvidingRequestTypeAudioMetricMessage:messageBody:client:]
audioMetricProvider
T@"<CSAudioMetricProviding>",W,N,V_audioMetricProvider
corespeechd xpc connection client queue
-[CSActivationXPCConnection _handleClientEvent:client:]
-[CSActivationXPCConnection _handleClientMessage:client:]
-[CSActivationXPCConnection _handleClientError:client:]
-[CSActivationXPCConnection _handleActivateEventMesssage:client:]
T@"<CSActivateXPCConnectionDelegate>",W,N,V_delegate
CSSiriClientBehaviorMonitor
-[CSSiriClientBehaviorMonitor notifyWillStartStreamWithContext:option:]_block_invoke
-[CSSiriClientBehaviorMonitor notifyDidStartStreamWithContext:successfully:option:]_block_invoke
-[CSSiriClientBehaviorMonitor notifyWillStopStream:]_block_invoke
-[CSSiriClientBehaviorMonitor notifyDidStopStream:]_block_invoke
Serial CSPolicy queue
-[CSLanguageCodeUpdateMonitor _startMonitoringWithQueue:]
-[CSLanguageCodeUpdateMonitor _stopMonitoring]
-[CSLanguageCodeUpdateMonitor _didReceiveLanguageCodeUpdate]
Serial CSEventMonitor queue
VoiceProfileCompatabiltyVersion
VoiceProfileProductType
VoiceProfileSWVersion
VoiceProfileCategoryType
VoiceProfileIdentifier
baseProfileVersion
implicitProfileVersion
spIdUnknownUserScore
spIdKnownUserScores
SpIdScoreThreshold
Unknown InvocationStyle: %lu
tdti
tdtiexplicit
Unknown CSSpIdType: %ld
+[CSUtils(SpeakerId) spIdTypeForString:]
EnrollmentRunMode
DetectionRunMode
RetrainingMode
config_td_spid.txt
config_ti_spid.txt
config_tdti_spid.txt
config.txt
trained_users.json
+[CSUtils(SpeakerId) spIdSATDirForLocale:]
spid
+[CSUtils(SpeakerId) spIdSATAudioDirForLocale:spidType:]
model
+[CSUtils(SpeakerId) spIdSATModelDirForLocale:spidType:]
spid-imported
+[CSUtils(SpeakerId) createDirectoryIfDoesNotExist:]
Logs/CoreSpeech/spid/
grading
+[CSUtils(SpeakerId) spIdAudioLogsCountLimitReached]
VoiceProfileCache
AudioFileOpenURL Failed : %@
EARTests
AudioFileOpenURL failed: %@
ExtAudioFileWrapAudioFileID failed: %@
Error reading audio-file: %d
EOF. Num bytes read: %lu
+[CSUtils(SpeakerId) isSpidAssetsAvailable]
+[CSUtils(SpeakerId) getVoiceProfileVersionFromVersionFilePath:]
+[CSUtils(SpeakerId) getVoiceProfileProductCategoryFromVersionFilePath:]
+[CSUtils(SpeakerId) checkIfMigrationNecessaryForCompatibilityVersion:forLanguageCode:]
+[CSUtils(SpeakerId) migrateVoiceProfileToVersion:forLanguageCode:]
td-sr-model
+[CSUtils(SpeakerId) updateVoiceProfileVersionFileForProfileId:forLanguageCode:]
kCSDeviceCategory_Unknown
kCSDeviceCategory_iOS_NonAop
kCSDeviceCategory_iOS_Aop
kCSDeviceCategory_macOS
kCSDeviceCategory_audioAccessory
iPad3,4
iPad3,5
iPad3,6
iPad4,1
iPad4,2
iPad4,3
iPad4,4
iPad4,5
iPad4,6
iPad4,7
iPad4,8
iPad4,9
iPad5,1
iPad5,2
iPad5,3
iPad5,4
iPad6,7
iPad6,8
iPad6,11
iPad6,12
iPhone5,1
iPhone5,2
iPhone5,3
iPhone5,4
iPhone6,1
iPhone6,2
iPhone7,1
iPhone7,2
iPad
iPhone
Accessory
+[CSUtils(SpeakerId) deviceCategoryForDeviceProductType:]
+[CSUtils(SpeakerId) isCurrentDeviceCompatibleWithNewerVoiceProfileAt:]
+[CSUtils(SpeakerId) isCurrentDeviceCompatibleWithVoiceProfileAt:]
pathExtension='json'
Caches/VoiceTrigger/ImplicitUtterences
SiriDebugVT
SpeakerIDToGradeData
VoiceProfiles
Caches
+[CSUtils(SpeakerId) mapRawScores:toScoresOfType:withRawScoreOffset:withRawScoreScale:withLogitCeil:withLogitFloor:withSATThreshold:]
+[CSUtils(SpeakerId) spIdMapScoresToSharedSiriID:]
+[CSUtils(SpeakerId) spIdMapIdentifiersToSiriDebugID:]
+[CSUtils(SpeakerId) spIdComposeProfileVersionsFor:]
%ld.%ld
+[CSUtils(SpeakerId) getEnrollmentUtterancesFromDirectory:]
self.absoluteString ENDSWITH '.wav'
+[CSUtils(SpeakerId) getImplicitEnrollmentUtterancesPriorTo:forType:forLanguageCode:forProfileID:]
+[CSUtils(SpeakerId) getImplicitEnrollmentUtterancesPriorTo:forType:forLanguageCode:forProfileID:]_block_invoke
+[CSUtils(SpeakerId) removeItemAtPath:]
+[CSUtils(SpeakerId) incrementVoiceProfileVersionForUpdateType:forVoiceProfile:]
+[CSUtils(SpeakerId) getVoiceProfileBaseVersionfromVersionFile:]
+[CSUtils(SpeakerId) getVoiceProfileImplicitVersionfromVersionFile:]
+[CSUtils(SpeakerId) deleteExistingSATModelForLanguageCode:]
[%@]
[%llu]
[%f]
BuiltInAOPVoiceTrigger
RemoteMicVoiceTrigger
RemoteMicVAD
JarvisVoiceTrigger
BuiltInVoiceTriggerStart
BuiltInVoiceTriggerStop
Unknown
TQ,N,V_type
T@"NSDictionary",&,N,V_activationInfo
TQ,N,V_hosttime
Tf,N,V_vadScore
uuid
activationInfo
vadScore
hosttime
-[CSVoiceTriggerAssetDownloadMonitor _startMonitoringWithQueue:]
-[CSVoiceTriggerAssetDownloadMonitor _stopMonitoring]
-[CSVoiceTriggerAssetDownloadMonitor _didInstalledNewVoiceTriggerAsset]
com.apple.MobileAsset.VoiceTriggerAssets.ma.new-asset-installed
com.apple.MobileAsset.VoiceTriggerAssetsWatch.ma.new-asset-installed
com.apple.MobileAsset.VoiceTriggerAssetsMarsh.ma.new-asset-installed
com.apple.MobileAsset.VoiceTriggerAssetsMac.ma.new-asset-installed
baseProfileConfidenceScoreThreshold
Tf,R,N,V_baseProfileConfidenceScoreThreshold
implicitConfidenceScoreThreshold
Tf,R,N,V_implicitConfidenceScoreThreshold
implicitDeltaConfidenceScoreThreshold
Tf,R,N,V_implicitDeltaConfidenceScoreThreshold
audioSessionState
TQ,N,GgetAudioSessionState,V_audioSessionState
T@"NSString",C,N,V_deviceId
CSVoiceIdXPCListener
com.apple.corespeech.corespeechd.voiceid.xpc
-[CSVoiceIdXPCListener listen]
-[CSVoiceIdXPCListener _handleListenerEvent:]
-[CSVoiceIdXPCListener _handleListenerError:]
-[CSVoiceIdXPCListener _handleNewRemoteConnection:]
CSSpeechManager Asset Query Queue
-[CSSpeechManager startManager]
-[CSSpeechManager registerSpeechController:]
-[CSSpeechManager registerSiriClientProxy:]
-[CSSpeechManager registerVolumeController:]
v32@?0@"NSNumber"8@"CSAudioProvider"16^B24
-[CSSpeechManager audioProviderWithContext:error:]
-[CSSpeechManager audioProviderWithContext:error:]_block_invoke
-[CSSpeechManager _getAudioRecorderWithError:]
-[CSSpeechManager audioRecorderWillBeDestroyed:]_block_invoke
-[CSSpeechManager voiceTriggerAssetHandler:didChangeCachedAsset:]
-[CSSpeechManager _createClearLoggingFileTimer]
-[CSSpeechManager _createClearLoggingFileTimer]_block_invoke
-[CSSpeechManager _startClearLoggingFilesTimer]
assetQueryQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_assetQueryQueue
audioProviders
T@"NSMutableDictionary",&,N,V_audioProviders
clientController
T@"<CSSpeechManagerDelegate>",W,N,V_clientController
volumeClientController
T@"<CSSmartSiriVolumeDelegate>",W,N,V_volumeClientController
voiceTriggerImplicitTraining
T@"CSSpIdImplicitTraining",&,N,V_voiceTriggerImplicitTraining
voiceTriggerSATCleaner
T@"CSInvalidSATEntriesCleaner",&,N,V_voiceTriggerSATCleaner
clearLoggingFileTimer
T@"NSObject<OS_dispatch_source>",&,N,V_clearLoggingFileTimer
clearLoggingFileTimerCount
Tq,N,V_clearLoggingFileTimerCount
opportuneSpeakListnerTestService
T@"CSOpportuneSpeakListnerTestService",&,N,V_opportuneSpeakListnerTestService
T@"CSSmartSiriVolume",R,N,V_smartSiriVolume
-[CSVoiceIdXPCClient _handleListenerEvent:]
-[CSVoiceIdXPCClient _handleListenerError:]
-[CSAudioZeroCounter getZeroStatisticsFromBuffer:entireSamples:]
-[CSAudioZeroCounter stopReportZeroStatistics]
T@"NSDictionary",C,N,V_voiceTriggerInfo
T@"NSDictionary",C,N,V_rtsTriggerInfo
corespeech.json
assets.json
hybridendpointer.json
hybridendpointer_marsh.json
/System/Library/PrivateFrameworks/CoreSpeech.framework
+[CSAsset fallBackAssetResourcePath]
defaultFallbackHearst
-[CSAsset initWithResourcePath:configFile:configVersion:]
-[CSAsset _decodeJson:]
-[CSAsset getNumberForKey:category:default:]
-[CSAsset getStringForKey:category:default:]
configVersion:%@ resourcePath:%@ path:%@
path
T@"NSString",R,N,V_path
resourcePath
T@"NSString",R,N,V_resourcePath
hashFromResourcePath
configVersion
T@"NSString",R,N,V_configVersion
-[CSXPCConnection sendMessageToClient:]
-[CSXPCConnection sendMessageToClient:]_block_invoke
-[CSXPCConnection _handleClientEvent:client:]
-[CSXPCConnection _handleClientMessage:client:]
-[CSXPCConnection _handleAudioProvidingMessage:messageBody:client:]
-[CSXPCConnection _handleAudioProvidingRequestTypeSwitchMessage:messageBody:client:]
-[CSXPCConnection _handleClientError:client:]
-[CSXPCConnection _handlePingPongMessage:client:]
audioSessionProvidingProxy
T@"CSAudioSessionProvidingProxy",&,N,V_audioSessionProvidingProxy
audioSessionInfoProvidingProxy
T@"CSAudioSessionInfoProvidingProxy",&,N,V_audioSessionInfoProvidingProxy
audioStreamProvidingProxy
T@"CSAudioStreamProvidingProxy",&,N,V_audioStreamProvidingProxy
audioAlertProvidingProxy
T@"CSAudioAlertProvidingProxy",&,N,V_audioAlertProvidingProxy
audioMeterProvidingProxy
T@"CSAudioMeterProvidingProxy",&,N,V_audioMeterProvidingProxy
audioMetricProvidingProxy
T@"CSAudioMetricProvidingProxy",&,N,V_audioMetricProvidingProxy
smartSiriVolumeProvidingProxy
T@"CSSmartSiriVolumeProvidingProxy",&,N,V_smartSiriVolumeProvidingProxy
T@"<CSXPCConnectionDelegate>",W,N,V_delegate
CSHostDaemon
-[CSHostDaemon _daemonDidLaunch]
com.apple.notifyd.matching
-[CSHostDaemon _setupNotifyHandlers]_block_invoke
xpcListener
T@"CSXPCListener",&,N,V_xpcListener
activationXpcListener
T@"CSActivationXPCListener",&,N,V_activationXpcListener
voiceIdXpcListener
T@"CSVoiceIdXPCListener",&,N,V_voiceIdXpcListener
-[CSAudioCircularBuffer initWithNumChannels:recordingDuration:samplingRate:]
-[CSAudioCircularBuffer copySamplesFromHostTime:]
-[CSAudioCircularBuffer copySamplesFrom:to:]
-[CSAudioCircularBuffer copyBufferWithNumSamplesCopiedIn:]
-[CSAudioCircularBuffer reset]
-[CSAudioCircularBuffer saveRecordingBufferFrom:to:toURL:]
bufferLength
TQ,N,V_bufferLength
copySamples
  mNumChannels: 
  mRecordingDurationInSecs: 
  mSampleRate: 
  mBytesPerSample: 
  mBufferLengthInSamples: 
  mNextWritePos: 
  mSamplesCount: 
  mMemoryPool(
): [
    chan-
: sz=
: mem-sz: 
+[CSUtils(AudioFile) readAudioChunksFrom:block:]
-[CSCoreSpeechDaemonStateMonitor notifyDaemonStateChanged:]
com.apple.corespeech.corespeechd.launch
-[CSCoreSpeechDaemonStateMonitor _startMonitoringWithQueue:]
-[CSCoreSpeechDaemonStateMonitor _stopMonitoring]
-[CSCoreSpeechDaemonStateMonitor _didReceiveDaemonStateChanged:]
+[CSUtils(Time) hostTimeFromSampleCount:anchorHostTime:anchorSampleCount:]
+[CSUtils(Time) sampleCountFromHostTime:anchorHostTime:anchorSampleCount:]
+[CSUtils(Time) macHostTimeFromBridgeHostTime:]
CSRemoteRecordClient Queue
T@"<CSRemoteRecordClientDelegate>",W,N,V_delegate
T@"<CSAudioDecoderDelegate>",W,V_delegate
kVTSiriAssertionEnabledDarwinNotification
kVTSiriAssertionDisabledDarwinNotification
CSSiriAssertionMonitor queue
-[CSSiriAssertionMonitor init]
-[CSSiriAssertionMonitor _stopMonitoring]
-[CSSiriAssertionMonitor enableAssertionReceived]_block_invoke
-[CSSiriAssertionMonitor disableAssertionReceived]_block_invoke
-[CSSiriAssertionMonitor handleXPCMessage:messageBody:client:]
tdSATModelFilePath
T@"NSString",R,N,V_tdSATModelFilePath
getSATVectorCount
Tq,R,N,V_getSATVectorCount
tdPsrCanProcessRequest
TB,R,N,V_tdPsrCanProcessRequest
lastRequestSatScore
Tf,R,N,V_lastRequestSatScore
-[CSAudioSessionProvidingProxy handleXPCMessage:messageBody:client:]
-[CSAudioSessionProvidingProxy _handleSessionProvidingRequestTypePrewarmMessage:client:]
-[CSAudioSessionProvidingProxy _handleSessionProvidingRequestTypeActivateMessage:messageBody:client:]
-[CSAudioSessionProvidingProxy _handleSessionProvidingRequestTypeDeactivateMessage:messageBody:client:]
-[CSAudioSessionProvidingProxy _handleSessionProvidingRequestTypeGetDuckOthersOption:messageBody:client:]
-[CSAudioSessionProvidingProxy _handleSessionProvidingRequestTypeSetDuckOthersOption:messageBody:client:]
-[CSAudioSessionProvidingProxy _handleSessionProvidingRequestTypeEnableMiniDucking:messageBody:client:]
ENABLE
DISABLE
T@"<CSAudioSessionProviding>",W,N,V_audioSessionProvider
Languages
Footprint
Premium
-[CSAudioAlertProvidingProxy handleXPCMessage:messageBody:client:]
-[CSAudioAlertProvidingProxy _handleAlertProvidingRequestTypeSetAlertSoundMessage:messageBody:client:]
-[CSAudioAlertProvidingProxy _handleAlertProvidingRequestTypePlayAlertSoundMessage:messageBody:client:]
-[CSAudioAlertProvidingProxy _handleAlertProvidingRequestTypePlayRecordStartingAlertAndResetEndpointerMessage:messageBody:client:]
v20@?0B8Q12
-[CSAudioAlertProvidingProxy _handleAlertProvidingRequestTypeAlertStartTimeMessage:messageBody:client:]
-[CSAudioAlertProvidingProxy _handleAlertProvidingRequestTypeConfigureAlertBehavior:messageBody:client:]
-[CSAudioAlertProvidingProxy audioAlertProvidingDidFinishAlertPlayback:ofType:error:]
audioAlertProvider
T@"<CSAudioAlertProviding>",W,N,V_audioAlertProvider
com.apple.voicetrigger
com.apple.voicetrigger.notbackedup
kCSPreferencesJarvisTriggerModeDidChangeDarwinNotification
VoiceTrigger Enabled
Phrase Detector Enabled
AttentiveSiri Enabled
AttentiveSiri AudioLogging Enabled
VoiceTrigger CoreSpeech Enabled
-[CSPreferences voiceTriggerInCoreSpeech]_block_invoke
CoreSpeech Daemon Enabled
-[CSPreferences corespeechDaemonEnabled]_block_invoke
Enable Two Shot Notification
com.apple.demo-settings
StoreDemoMode
File Logging Level
Logs/CrashReporter/VoiceTrigger/audio/
/Logs/CrashReporter/Assistant/
SpeechLogs
-[CSPreferences assistantAudioFileLogDirectory]
Second Pass Audio Logging Enabled
Jarvis Audio Logging Enabled
Jarvis Trigger Mode
Enable SoS Audio Logging
mobile
Logs/CrashReporter/CoreSpeech/sos/
-[CSPreferences getStartOfSpeechAudioLogFilePath]
yyyyMMdd_HHmmss.SSS
%@/%@
Remote VoiceTrigger Delay
Remote VoiceTrigger Endpoint Timeout
VoiceTrigger/interstitial
Myriad File Logging Enabled
-[CSPreferences enableAudioInjection:]
Audio Injection Enabled
-[CSPreferences setAudioInjectionFilePath:]
Audio Injection File Path
-[CSPreferences audioInjectionFilePath]
-[CSPreferences audioInjectionFilePath]_block_invoke
SpeakerId Enabled
iTunes Account Signin Enabled
SpeakerId Score Type
SmartSiriVolume SoftVolume Enabled
Audio Session Activation Delay
Max Number Logging Files
Enable SiriActivation HomePod
Enable SiriActivation watchOS
IOS Barge-in Power Saving Enabled
-[CSPreferences iOSBargeInPowerSavingEnabled]_block_invoke
-[CSPreferences iOSBargeInPowerSavingEnabled]
IOS Support Barge-in
-[CSPreferences iOSBargeInSupportEnabled]_block_invoke
-[CSPreferences iOSBargeInSupportEnabled]
Overwrite Remote VAD Score
Hearst First Pass Model Version
Hearst Second Pass Model Version
Hearst Fake Model Path
VoiceTrigger Companion Sync Enabled
CSAudioRouteChangeMonitor queue
-[CSAudioRouteChangeMonitor preferredExternalRouteDidChange:]_block_invoke
-[CSAudioRouteChangeMonitor carPlayAudioRouteDidChange:]_block_invoke
-[CSAudioRouteChangeMonitor _stopMonitoring]
-[CSAudioRouteChangeMonitor _notifyHearstConnectionState:]
-[CSAudioRouteChangeMonitor _notifyJarvisConnectionState:]
+[CSAudioStreamRequest defaultRequestWithContext:]
+[CSAudioStreamRequest requestForLpcmRecordSettingsWithContext:]
+[CSAudioStreamRequest requestForOpusRecordSettingsWithContext:]
+[CSAudioStreamRequest requestForSpeexRecordSettingsWithContext:]
TB,N,V_requiresHistoricalBuffer
TB,N,V_useCustomizedRecordSettings
Tq,N,V_audioFormat
Td,N,V_sampleRate
TI,N,V_lpcmBitDepth
TB,N,V_lpcmIsFloat
numberOfChannels
TI,N,V_numberOfChannels
TI,N,V_encoderBitRate
TB,N,V_isSiri
requiresHistoricalBuffer
useCustomizedRecordSettings
audioFormat
lpcmBitDepth
lpcmIsFloat
NumberOfChannels
encoderBitRate
isSiri
com.apple.siri.SiriDebug.SpeakerVoiceGradingTrigger
com.apple.siri.SiriDebug.RemoteNearMissGradingTrigger
com.apple.siri.SiriDebug.VoiceProfileAddedTrigger
com.apple.siri.SiriDebug.VoiceProfileSyncTrigger
com.apple.siri.SiriDebug
+[CSSiriDebugConnection launchSiriDebugAppWithMessage:]_block_invoke
v24@?0@"AFSiriResponse"8@"NSError"16
-[CSSelectiveChannelAudioFileWriter initWithURL:inputFormat:outputFormat:channelBitset:]
-[CSSelectiveChannelAudioFileWriter addSamples:numSamples:]
TI,R,N,V_numberOfChannels
-[CSSoftwareUpdateCheckingMonitor _startMonitoringWithQueue:]
-[CSSoftwareUpdateCheckingMonitor _stopMonitoring]
-[CSSoftwareUpdateCheckingMonitor _checkSoftwareUpdateCheckingState]
com.apple.duetscheduler.restartCheckNotification
CSMediaPlayingMonitor queue
-[CSMediaPlayingMonitor initializeMediaPlayingState]_block_invoke_2
v12@?0I8
-[CSMediaPlayingMonitor _startMonitoringWithQueue:]
-[CSMediaPlayingMonitor _stopMonitoring]
-[CSMediaPlayingMonitor _notePossiblePlayPausedStateChange:]
PLAYING
NOT PLAYING
deque
-[CSVoiceTriggerAOPModeEnabledPolicyIOS _addConditionsForIOSBargeIn]_block_invoke
-[CSVoiceTriggerAOPModeEnabledPolicyIOS _addConditionsForIOSAOP]_block_invoke
-[CSNetworkAvailabilityMonitor _startMonitoringWithQueue:]
-[CSNetworkAvailabilityMonitor _stopMonitoring]
-[CSNetworkAvailabilityMonitor _availabilityChanged]
-[NSDictionary(XPCObject) _cs_initWithXPCObject:]
-[NSDictionary(XPCObject) _cs_initWithXPCObject:]_block_invoke
B24@?0r*8@"NSObject<OS_xpc_object>"16
-[NSDictionary(XPCObject) _cs_xpcObject]_block_invoke
v32@?0@8@16^B24
-[CSAudioMeterProvidingProxy handleXPCMessage:messageBody:client:]
-[CSAudioMeterProvidingProxy _handleMeterProvidingRequestTypeSetMeteringEnabledMessage:messageBody:client:]
-[CSAudioMeterProvidingProxy _handleMeterProvidingRequestTypeUpdateMetersMessage:messageBody:client:]
v16@?0B8f12
-[CSAudioMeterProvidingProxy _handleMeterProvidingRequestTypePowerMessage:messageBody:client:powerType:]
audioMeterProvider
T@"<CSAudioMeterProviding>",W,N,V_audioMeterProvider
%s Start Recording Host Time = %{public}llu
%s cannot handle event : event = %{public}p
%s ignore unknown types of message 
%s cannot handle error : error = %{public}p
%s Listener connection disconnected
%s connection error: %{public}s
%s Cannot create SampleRateConverter using AudioConverterNew : %{public}d
%s Cannot set Quality property to audioConverter
%s Cannot set Complexity property to audioConverter
%s Audio resampling done : %lu
%s AudioConverter is sad: 0x%{public}xd
%s Celestial is not available on this platform.
%s notification = %{public}@
%s Cannot generate subChunk since channel(%{public}tu) is larger than number of channels(%{public}tu)
%s Cannot generate subChunk if it reuqest more than it has : %{public}tu %{public}tu %{public}tu
%s SpkrId:: Processing ended at: numSamplesProcessed=%lu, totalSampleCountToReach=%lu
%s CSAudioStreamProvidingProxy has received xpc disconnection
%s Trying to stop audio stream on CSAudioStreamProvidingProxy
%s MessageType for stream providing = %{public}lld
%s Unknown body type : %{public}lld
%s Cannot handle setCurrentContext throught XPC : audioStreamProviding is nil
%s Cannot handle setCurrentContext throught XPC : given context is nil
%s Cannot handle AudioStreamRequest throught XPC : given audioStreamRequest is nil
%s Cannot handle AudioStreamRequest throught XPC : audioStreamProviding is nil
%s Getting audio stream has failed : %{public}@
%s Cannot handle PrepareRequest throught XPC : audioStreamProviding is nil
%s Cannot handle PrepareRequest : audioStream is nil
%s Given audioStreamRequest is nil, use default audioStreamRequest
%s Cannot handle startAudioStream : given audio stream option is nil
%s Cannot handle startAudioStream : audioStream is nil
%s Cannot handle startAudioStream : audioStreamProviding is nil
%s Cannot handle stopAudioStream : audioStreamProviding is nil
%s Cannot handle stopAudioStream : audioStream is nil
%s Cannot handle IsRecording : audioStreamProviding is nil
%s Cannot handle RecordRoute : audioStreamProviding is nil
%s Cannot handle RecordDeviceInfo : audioStreamProviding is nil
%s Cannot handle RecordSettings : audioStreamProviding is nil
%s Cannot handle IsNarrowband : audioStreamProviding is nil
%s Cannot handle PlaybackRoute : audioStreamProviding is nil
%s CSAudioStreamProvidingProxy
%s Failure disposing audio file %{public}d
%s Audio file already configured, closing first
%s Creating audio file at URL %{public}@
%s Failed creating audio file at url %{public}@ %{public}d
%s Error setting input format %{public}d
%s No audio file to append data
%s Failed writing audio file %{public}d
%s Closing file at URL %{public}@, audio size: %{public}u
%s Mediaserverd/bridgeaudiod crashed
%s Mediaserverd/bridgeaudiod recovered from crash
%s Start monitoring : AudioSessionInterruption
%s Start monitoring : AudioSessionRouteChangeNotification
%s Stop monitoring AudioSession activities
%s Plan removing the temp file %{public}@
%s Failed to remove temp file %{public}@ reason: %{public}@
%s Start copying %{public}u bytes of data to crashreporter with wav file header offset %{public}llu
%s Failed to read data from %{public}@
%s Finished copying data to crashreporter.
%s Logging audio file into : %{public}@
%s Removing non-dir at AttentiveSiri AudioLog dir: %@
%s Error removing %@: err: %@
%s Failed to create AudioLogging directory for AttentiveSiri: %@
%s Created AudioLogging dir for AttentiveSiri at: %@
%s SmartSiriVolume cannot be resumed since Siri is speaking
%s Start monitoring : Setting preference change
%s Stop monitoring : Setting preference change
%s Siri restricted on lock screen : %{public}@
%s default to recordContext : %{public}@
%s Failed to create regular expression : %{public}@
%s Cannot get a VoiceTrigger asset : %{public}@
%s CSVoiceTriggerAsset found: %{public}@
%s Asset Query failed : %{public}@
%s cached asset:%{public}@, new asset:%{public}@
%s New asset is same as cached asset, ignore notification
%s New asset is different from cached one. Updating cached asset
%s new VoiceTrigger asset downloaded
%s Language Code Changed : %{public}@
%s First unlock notification received : %{public}d
%s Start monitoring : Mediaserverd crash / recover event
%s Prepare Audio Provider with Context : %{public}@
%s Failed to get reply result correctly
%s Received alertStartTime = %{public}llu
%s Received peakPower = %{public}f
%s Received averagePower = %{public}f
%s Sending audioMetric request
%s Failed to get audioMetric reply
%s audioMetric : %{public}@
%s Received invalid audioMetric
%s Error creating message
%s audioStreamWithRequest for stream %{public}@
%s Invalid message: stream is nil or request is nil
%s PrepareAudioStream %{public}@
%s Sending VoiceTriggerInfo request
%s Received VoiceTriggerInfo %{public}@
%s Failed to parse VoiceTriggerInfo from raw data
%s Received rtsTriggerInfo %{public}@
%s Failed to parse rtsTriggerInfo from raw data
%s Message not valid
%s ::: %{public}s enable: %{public}d reason: %{public}@
%s Ignoring request to enable/disable voice trigger with nil reason.
%s ::: Asserting that VoiceTrigger should be %{public}@ with reason: %{public}@. Existing assertions (%{public}lu): %{public}@; times: %{public}@ vs %{public}f
%s Ignoring request to enable/disable voice trigger - time order violation.
%s assertionType = %{public}lld
%s NO reply!!!
%s No message!!
%s No reply for hostTimeFromSampleCount request with sampleCount %{public}llu
%s No message for hostTimeFromSampleCount request with sampleCount %{public}llu
%s No reply for sampleCountFromHostTime request with hostTime %{public}llu
%s No message for sampleCountFromHostTime request with hostTime %{public}llu
%s Cannot handle nil message
%s MessageType = %{public}lld
%s Unexpected message type : %{public}lld
%s AlertProvidingDelegate messageType : %{public}lld
%s Unexpected type : %{public}lld
%s SessionProvidingDelegate messageType : %{public}lld
%s context : %{public}@
%s invalid context
%s SessionInfoProvidingDelegate messageType : %{public}lld
%s Received notificationInfo %{public}@
%s Failed to parse notificationInfo from raw data
%s StreamProvidingDelegate messageType : %{public}lld
%s startListenWithOption : %{public}d, %{public}@
%s stopListenWithCompletion : %{public}d, %{public}@
%s hasRemoteVADAvailable : %d
%s hasVADAvailable : %d
%s didStopUnexpectly : %d
%s MobileTimer is not available on this platform.
%s PhraseSpotter enabled = %{public}@
%s PhraseSpotter is already %{public}@, received duplicated notification!
%s Cannot remove model directory(%@) : %@
%s Cannot remove utterance directory(%@) : %@
%s Dealloc audioStreamHolding : %{public}@
%s CSAudioProvider[%{public}@]:Setting audioRecorder : %{public}p
%s CSAudioProvider[%{public}@]:setCurrentContext : %{public}@
%s CSAudioProvider[%{public}@]:Cannot change context since audio recorder is currently recording
%s CSAudioProvider[%{public}@]:audioStreamWithRequest for stream <%{public}@>
%s Failed to _prepareAudioStreamSync : %{public}@
%s CSAudioProvider[%{public}@]:Prepare audio stream reuqested while state is %{public}@
%s CSAudioProvider[%{public}@]:Cannot prepare, audio system is recovering
%s CSAudioProvider[%{public}@]:Asking AudioRecorder prepareAudioStreamRecord
%s CSAudioProvider[%{public}@]:prepareAudioStreamRecord failed : %{public}@
%s CSAudioProvider[%{public}@]:Create circular buffer
%s CSAudioProvider[%{public}@]:Tear down circular buffer
%s CSAudioProvider[%{public}@]:startAudioStream with stream : %{public}@ with stream state : %{public}@, option : %{public}@, streamId : %{public}llu
%s CSAudioProvider[%{public}@]:state was %{public}@, prepareAudioStream first
%s CSAudioProvider[%{public}@]:prepareAudioStreamSync with stream : %{public}@ with stream state : %{public}@
%s CSAudioProvider[%{public}@]:prepareAudioStream with stream : %{public}@ with stream state : %{public}@
%s CSAudioProvider[%{public}@]:Cannot handle start audio stream on : %{public}@
%s CSAudioProvider[%{public}@]:Cannot startAudioStream, audio system is recovering
%s CSAudioProvider[%{public}@]:Requested startHostTime = %{public}llu, _clientStartSampleCount = %{public}tu
%s CSAudioProvider[%{public}@]:Failed to fetch historical audio since _clientStartSampleCount is newer than audioBuffer sample count(%{public}llu)
%s CSAudioProvider[%{public}@]:Received didStartRecording while %{public}@
%s CSAudioProvider[%{public}@]:Received didStopRecording reason : %{public}d, streamState : %{public}@
%s CSAudioProvider[%{public}@]:Received didStopRecording while %{public}@
%s CSAudioProvider[%{public}@]:stopAudioStream %{public}@ with streamState : %{public}@
%s CSAudioProvider[%{public}@]:Cannot handle stop audio stream on : %{public}@
%s CSAudioProvider[%{public}@]:requested stop audio stream while stopping, adding audio stream into stop pending
%s CSAudioProvider[%{public}@]:Stop all recordings, moving stream state to %{public}@
%s CSAudioProvider[%{public}@]:Failed to stop audioStream : %{public}@
%s CSAudioProvider[%{public}@]:%{public}@ ask for audio hold stream for %{public}f
%s CSAudioProvider[%{public}@]:Timeout for %{public}@ has fired
%s CSAudioProvider[%{public}@]:Removing %{public}@ from stream holders
%s CSAudioProvider[%{public}@]:%{public}@ stream holder was already removed from stream holders
%s CSAudioProvider[%{public}@]:%{public}@ ask for cancel hold stream
%s Failed to prewarmAudioSessionWithError : %{public}@
%s Failed to activateAudioSessionWithReason: %{public}@
%s CSAudioProvider[%{public}@]:Activating Audio Session under : %{public}@
%s Failed to activateAudioSession : %{public}@
%s Failed to deactivate audio session : %{public}@
%s CSAudioProvider[%{public}@]:Deactivating Audio Session under : %{public}@
%s Failed to deactivateAudioSession : %{public}@
%s CSAudioProvider[%{public}@]:AVVC is recovering, ignore command...
%s CSAudioProvider[%{public}@]:Cannot stopRecording as there are %{public}tu streamHolders
%s CSAudioProvider[%{public}@]:Shouldn't stop AVVC recording as there are %{public}tu streams
%s CSAudioProvider[%{public}@]:
%s CSAudioProvider[%{public}@]:Buffer underrun!!!!, lastForwardedSampleTime:%{public}lu, oldestSampleTimeInBuffer:%{public}lu
%s ScheduleAlertFinishTimeout : %{public}@
%s ScheduleAlertFinishTimeout will be ignored : %{public}@, %{public}@
%s Received finishStartAlertPlaybackAt:%{public}llu streamState : %{public}@
%s CSAudioProvider[%{public}@]:Requested alertFinishHostTime = %{public}llu, _clientStartSampleCount = %{public}tu
%s Audio Streaming already stopped
%s Will invalidate current builtIn audio stream : %{public}@
%s failed to stopAudioStream : %{public}@
%s CSAudioProvider[%{public}@]:Audio Recorder Disconnected
%s CSAudioProvider[%{public}@]:Mediaserverd/bridgeaudiod crashed
%s CSAudioProvider[%{public}@]:Mediaserverd/bridgeaudiod recovered from crash
%s CSAudioProvider[%{public}@]:AudioRecorder will be destroyed
%s CSAudioProvider[%{public}@]:recordingTransaction already released
%s CSAudioProvider[%{public}@]:Release recording transaction at streamState : %{public}@
%s CS logging files under %{public}@ created before %{public}@ will be removed.
%s Couldn't get creation date: %{public}@
%s Could not remove %{public}@: %{public}@
%s CS logging files number %{public}lu with pattern %{public}@ under %{public}@ exceeding limit, only keep the latest %{public}lu ones
%s Regular expression is nil!
%s VoiceTrigger cannot be turned on since voiceTriggerInCoreSpeech is NO
%s VoiceTrigger cannot be turned on since VoiceTrigger is disabled
%s VoiceTrigger cannot be turned on since Siri is disabled
%s VoiceTrigger cannot be turned on since SpringBoard is not started yet
%s VoiceTrigger cannot be turned on since device is not unlocked after restart
%s VoiceTrigger cannot be turned on since device is on battery
%s VoiceTrigger cannot be turned on since Siri is restricted on lock screen
%s VoiceTrigger cannot be turned on since Software Update Checking is running
%s NDAPI initialization failed
%s set StartAnalyzeSampleCount = %{public}lld
%s NDAPI config doesn't contain threshold_normal
%s NDAPI config doesn't contain threshold_logging
%s CS doesn't have ndblobbuilder!
%s latestMajorVersion = %d, LatestMinorVersion = %d
%s corespeech.json doesn't contains rtblobs
%s blob file name is not exists
%s blob file is not exists at %{public}@
%s Reading blob from : %{public}@
%s Blob is nil : %{public}@
%s RTLocaleMap is not available on asset
%s Failed to create AVVC : %{public}@
%s Create new CSAudioRecorder = %{public}p
%s CSAudioRecorder %{public}p deallocated
%s AVVC initialization failed
%s Successfully create AVVC : %{public}p
%s Calling AVVC setContext
%s Failed to get handle id : %{public}@
%s setContext elapsed time = %{public}lf
%s Calling AVVC setContextForStream : %{public}@
%s setCurrentContext elapsed time = %{public}lf
%s Calling AVVC prepareRecordForStream(%{public}llu) : %{public}@
%s AVVC prepareRecordForStream failed : %{public}@
%s prepareRecordForStream elapsed time = %{public}lf
%s ::: CSAudioRecord will inject audio file instead of recording
%s Resetting AudioFilePathIndex
%s Increase AudioFilePathIndex = %d
%s AudioFilePathIndex is out-of-boundary _audioFilePathIndex:%d injectAudioFilePaths:%d
%s AudioFilePathIndex:%d accessing:%@
%s Unable to find injectAudioFilePath = %@
%s Calling AVVC startRecordForStream : %{public}@
%s startRecordForStream failed : %{public}@
%s startRecordForStream elapsed time = %{public}lf
%s Call AVVC stopRecordForStream
%s Failed to stopRecordForStream : %{public}@
%s stopRecordForStream elapsed time = %{public}lf
%s Session State = %d
%s AudioSessionState = YES
%s AudioSessionState = NO
%s AVVC sampling rate = %{public}f
%s AVVC doesn't return sampleRate, assume it is default sample rate
%s Calling AVVC setSessionActive for Prewarm
%s Prewarm AudioSession has failed : %{public}@
%s Calling AVVC setSessionActivate for activation
%s AVVC setSessionActivate has failed : %{public}@
%s AVVC successfully activated audioSession
%s setSessionActivate elapsed time = %{public}lf
%s Calling AVVC setSessionActivate for deactivation : %{public}tu
%s Should not call setDuckOthersOptions with NO in B238
%s enableMiniDucking elapsed time = %{public}lf
%s %{public}@
%s configureAlertBehavior elapsed time = %{public}lf
%s VoiceTriggerInfo is nil from AVVC
%s AVVCAudioBuffer contains %{public}d packet descriptions, size %{public}d, channels %{public}d. Ignoring
%s packetCount %{public}d
%s Bad packet length %{public}d. Skipping rest of record buffer.
%s Peak : %f, Avg : %f
%s Compensating %{public}u channel(s), heartbeat = %{public}lld
%s Calling AVVC playAlertSoundsForType : %{public}ld
%s Received didStartRecording : %{public}p, forStream:%{public}llu, successfully:%{public}d, error:%{public}@
%s Received audio buffer %{public}d, heartbeat = %{public}llu
%s Received didStopRecording : %{public}p forStream:%{public}llu forReason:%{public}ld
%s Received Stream Invalidated : %{public}llu
%s toConfiguration : %{public}d
%s type : %{public}d, error : %{public}@
%s Encoder error : %{public}@
%s withContext : %{public}@
%s activate : %{public}d
%s AVVC lost mediaserverd connection
%s AVVC informed mediaserverd reset, no further action required
%s Failed to deinterleave the data: %{public}d
%s Cannot create de-interleaver using AudioConverterNew: %{public}d
%s Created de-interleaver
%s Unsupported audio format!
%s Start Listening request with deviceId : %{public}@
%s remoteVADDuration = %{public}d, spgDuration = %{public}d, _remoteVADSPGRatio = %{public}d
%s Current mediaplaying state = %{public}d
%s AudioStreamRequest has failed : %{public}@
%s Stopping OpportuneSpeakListener with resetState = %{public}d, mediaplaying = %{public}d
%s Executing Theremin recovery logic by activating audio session
%s Deactivating audio session
%s Failed to deactivate audio session? : %{public}@
%s slience score estimate : %{public}f
%s ReceivedMediaPlayingChagned = %{public}d
%s SAT successfully initialized : %{public}@
%s Cannot create NSData with size 0
%s xpc object should be XPC_TYPE_DATA
%s Start monitoring : Siri setting switch, Siri is %{public}@
%s Stop monitoring : Siri setting switch
%s Siri Enabled = %{public}@
%s Cannot handle unexpected message type : %lld
%s SmartSiriVolume: final estimated TTS volume %{public}f with music volume %{public}f
%s Wrongly called: SmartSiriVolume is not supported on this device type. smartSiriVolume : %{public}p
%s CSActivationXPCListener start listening
%s Received new remote control connection request
%s Connection request is nil
%s Error = %{public}s
%s Getting new client connection : %{public}p
%s connection key and value not matching! client: %{public}p, xpcConnection: %{public}p
%s Client connection disconnected, removing %{public}p from client connection pool
%s sessionID = %{public}llu
%s Trying to get sessionID when audioSessionInfoProvider is nil
%s _csAssetsDictionary = %{public}@
%s CSAssetController cannot query for nil language
%s ::: found %{public}lu assets for assetType=%{public}lu, matching query: %{public}@
%s ::: Meta data not available, query again with returnType MAUnionOfCatalogInstalled
%s Error running asset-query for assetType:%{public}lu, query: %{public}@, error: %{public}lu
%s Meta data not available, query again with returnType MAUnionOfCatalogInstalled
%s Asset state : %{public}ld
%s ::: %{public}s
%s ::: %{public}s; query: %{public}@
%s Found %{public}lu assets
%s Error running asset query: error %{public}lu, or result is empty
%s ::: Request Fetching RemoteMetaData : assetType : %{public}d
%s ::: Request fetching remote asset
%s ::: found %{public}lu assets for assetType %{public}lu
%s Failed to finish query for assetType %{public}lu with error %{public}lu
%s Meta data downloaded successfully for assetType %{public}lu
%s Failed to download meta data for assetType %{public}lu with error %{public}lu
%s ::: Fetching remote asset
%s ::: Purging installed asset : %{public}@
%s ::: Request downloading remote asset for assetType %{public}lu
%s ::: Start downloading asset
%s ::: download progress: %{public}3.0f%%
%s ::: Error downloading from %{public}@ with error %{public}@
%s ::: download completed successfully from %{public}@.
%s Attempting to download asset %{public}@, asset state : %{public}ld
%s ERR: Unknown AssetType: %{public}lu
%s Cannot create NSNumber if xpcObject is NULL
%s XPC object type should be BOOL, DOUBLE, INT64, or UINT64
%s Cannot create xpcObject if objcType is NULL
%s Cannot create xpcObject since there is no matching type
%s SmartSiriVolume: deleted %{public}u elements in energy buffer.
%s SmartSiriVolume: number of elements to delete exceeds energy buffer size, ignore.
%s SmartSiriVolume init value for noise estimation %{public}f
%s SmartSiriVolume init value for LKFS estimation %{public}f
%s SmartSiriVolume enable policy changed : %{public}@
%s Already started listen polling, skip
%s listen polling has failed : %{public}@
%s Skip listen polling since audio is streaming / Siri disabled
%s Start audio stream successfully ? %{public}@, error : %{public}@
%s Received didStartRecording when Siri is off
%s Failed in requesting audio stream : %{public}@
%s Failed to stop audio stream : %{public}@
%s No audio stream to stop, we shouldn't hit this
%s SmartSiriVolume received MediaRemote initial state as %{public}@
%s SmartSiriVolume haven't got MediaRemote callback yet, let's assume media is playing.
%s SmartSiriVolume received alarm initial state as %{public}@
%s SmartSiriVolume received timer initial state as %{public}@
%s asset is nil, use default parameters(this should not happen).
%s SmartSiriVolume configure: %{public}@
%s SmartSiriVolume heartbeat = %{public}lld
%s SmartSiriVolume: estimated noise level %{public}f
%s SmartSiriVolume: estimated LKFS %{public}f
%s SmartSiriVolume: pause SSV calculation.
%s SmartSiriVolume: resume SSV calculation.
%s Siri is disabled, we shouldn't receive audio here, heartbeat = %{public}lld
%s stream stopped unexpectedly : %{public}ld
%s SmartSiriVolume received VT event!
%s SmartSiriVolume remove samples from VT utterances by %{public}llu, with startAnalyzeSampleCount = %{public}llu, samplesFed = %{public}llu, triggerStartSampleCount = %{public}llu
%s SmartSiriVolume trying to delete too many VT samples, set triggerDurationToDelete to be limited max: %{public}llu
%s SmartSiriVolume got empty VT event!
%s SmartSiriVolume dismiss alarm firing as VoiceTrigger detected.
%s SmartSiriVolume dismiss timer firing as VoiceTrigger detected.
%s SmartSiriVolume: final estimated TTS volume in dB %{public}f
%s SmartSiriVolume: adjust TTS volume since alarm/timer is firing.
%s SmartSiriVolume: TTS volume in dB from noise %{public}f, from LKFS %{public}f, with user offset %{public}f
%s SmartSiriVolume: soft volume algorithm in use
%s SmartSiriVolume: pause LKFS calculation according to MediaRemote notification.
%s SmartSiriVolume: resume LKFS calculation according to MediaRemote notification.
%s SmartSiriVolume received unknown media playing state, let's assume media is playing.
%s SmartSiriVolume received unknown alarm state, let's reset alarm state.
%s SmartSiriVolume: alarm firing status = %@ according to MobileTimer notification.
%s SmartSiriVolume received unknown timer state, let's reset timer state.
%s SmartSiriVolume: timer firing status = %@ according to MobileTimer notification.
%s Siri enabled : %{public}d
%s SmartSiriVolume: set StartAnalyzeSampleCount = %{public}lld
%s Listening on watch cannot be turned on since Siri is disabled
%s Listening on watch cannot be turned on since SpringBoard is not started
%s Listening on watch cannot be turned on since device is not unlocked after restart
%s Listening on watch cannot be turned on since Siri assertion is disabled
%s Siri language is nil, falling back to %@
%s ::: Error reading file %@, err: %d
%s CSAudioFileReader requires prepare recording settings to feed audio
%s CSAudioFileReader only support LinearPCM to feed
%s Setting ExtAudioFileSetProperty failed : %d
%s Starting audio file feed timer, bufferDuration = %f sampleRate = %f, bytesPerFrame = %d, channelsPerFrame = %d
%s ::: Error reading data from audio file : %d
%s Reach to EOF, chunkSize = %d
%s Stopping audio file feed timer
%s Advert data: %{public}@
%s advert data write failed
%s Failed to retrain voice profiles on initialization with error %{public}@
%s Finished retraining on launch
%s Profile %{public}@ has [%luE, %luB, %luI]
%s Ignoring new implicit utterance as voice profile is filled
%s Saved tdti implicit base profile utterance %{public}@ in profile %{public}@
%s Saved tdti implicit utterance %{public}@ in profile %{public}@
%s ERR: %{public}@
%s ERR: Failed in adding %{public}@ to %{public}@ with error %{public}@
%s ERR: Cannot create SAT analyzers
%s ERR: Failed to get top scorer in %{public}@ - Bailing out
%s ERR: Utterance scored %d (%{public}@) with next top score %d (%{public}@) for profileId %{public}@
%s Utterance scored %d (%{public}@) with next top score %d (%{public}@)
%s Error to copy profile from %{public}@ to %{public}@, error: %{public}@
%s Copied %@ to %@
%s Trigger %{public}@ Voice Profile training with import Dir %{public}@
%s Error to copy TD utterance from %{public}@ to %{public}@, error: %{public}@
%s Copied TD Utterance from %{public}@ to %{public}@
%s Error to copy TD jsonFile from %{public}@ to %{public}@, error: %{public}@
%s Copied TD jsonFile from %{public}@ to %{public}@
%s Successfully copied %{public}lu(%{public}lu) TD utterances to TDTI which now has %{public}lu(%{public}lu) utterances
%s Copied %{public}@ to %{public}@ with error %{public}@
%s ExplicitModelTraining: Failed to get voice profile for %{public}@ - Bailing out
%s Fetching homeUserId for siriProfileId %{public}@
%s ERR: Home User Id erred %{public}@ for Siri Profile Id %{private}@
%s Deleting VoiceProfile %{public}@
%s Err: %@
%s Retraining for locale %{public}@ with force %d
%s Retraining finished for %@ with error %@ in %fms
%s ERR: %@
%s ERR: Failed training %{public}@ of %{public}@ with error %{public}@
%s Failed to create explicit utterance only model with error %{public}@ for profile %{public}@
%s spIdRootDir is nil for %@ locale - Bailing out
%s Migration is not required - Bailing out
%s Moving profile %@ to %@ failed with error %@ - Bailing out
%s Migrated User Voice Profile %@
%s Could not read existing %@ file: err: %@
%s Adding User Voice Profile %@
%s Updating User Voice Profile to %@ from %@
%s Err: Failed to delete profile at %@ with error %@
%s Deleting User Voice Profile %@
%s User Voice Profile not found %@ - Bailing out
%s ERR: UserVoiceProfile Action undefined %ld - Bailing out
%s ERR: error creating usersJsonArr: %@, err: %@
%s ERR: Error writing usersArrJson at: %@, err:%@
%s Error reading directory at %@: err: %@
%s %@ is empty
%s ERR: Voice Profile not found for SiriProfileId: %{private}@ - Bailing out
%s Updating sharedHomeUserId %{private}@ for siriProfileId %{private}@
%s Skipping %{public}@ model update for profile %{public}@ 
%s Deleting %{public}@
%s ERR: Failed deleting %{public}@ with error %{public}@
%s ERR: Failed in retraining %{public}@ with error %{public}@
%s ERR: Failed to delete the model at %{public}@
%s Added utterance %{public}@ with score %{public}@
%s Rejected utterance %{public}@ with score %{public}@
%s BeepCanceller asset file loading from : %{public}@
%s Could not read beep file: %@
%s beepVector Size = %{public}lu
%s Cannot initialize beep canceller
%s Beep canceller initialized with maxNumSamples = %{public}d
%s It will beep now
%s Reset beep cancellation
%s Start monitoring : Springboard start
%s Cannot start monitoring Springboard start because it was already started
%s Stop monitoring : Springboard start
%s SpringBoard started = %{public}@
%s Received Activation Event : %{public}@
%s Received Activation Event in CoreSpeechDaemon: %{public}@
%s Returning error for already existing pending activation event : %{public}@
%s No delegate registered : Postpone activation event handling until we have delegate registered
%s Pending Timeout fired for %{public}@ returning error for timeout
%s There is no pending activation event to timeout
%s Cannot handle activation event : %{public}@
%s Found pending activation : %{public}@, handle pending activation immediately
%s AOP First Pass trigger detected
%s activation client not exist
%s CoreSpeechDaemon not enabled, no need to create xpc client
%s Stop monitoring : First unlock
%s xpc object string return nil
%s xpc object should be XPC_TYPE_STRING
%s Saving utterance and meta as %{public}@ training.
%s Failed to write utterance into %{public}@
%s Saving %{public}@ at %{public}@ as %{public}@ training.
%s numSamplesToWrite %{public}lu
%s Failed to get CSAudioFileWriter:
%s Failed to addSamples to CSAudioFileWriter: %{public}@
%s Failed to endAudio on CSAudioFileWriter: %{public}@
%s ERR: called with nil metaPath
%s ERR: called with nil uttPath
%s ERR: called with nil uttMeta
%s Cannot create json file : %{public}@
%s SATCleaner: Not supported !
%s xpc object should be XPC_TYPE_ARRAY
%s xpcObject value is NULL
%s Cannot decode non-plist types of XPC object
%s Cannot encode non-plist types into XPC object : %{public}@
%s invalid packets
%s ::: Error creating output file %{public}@, err: %{public}d
%s ::: Error writing to output wave file. : %{public}ld
%s stream %{public}@ initialized
%s stream %{public}@ is deallocated
%s AudioStream<%{public}@> is streaming : %{public}d
%s AudioStream<%{public}@> has received didStopStreamUnexpectly
%s AudioStream<%{public}@> has received didHardwareConfigurationChange
%s Start monitoring : VoiceTrigger Asset meta update
%s Stop monitoring : VoiceTrigger Asset meta update
%s New VoiceTrigger asset metadata is available
%s Resetting audio preprocessor : %{public}f, containsVoiceTrigger:%{public}d
%s Flushing audio preprocessor
%s Zero Filter Metrics: %{public}@
%s Beep Canceller Metrics : %{public}@
%s ::: VoiceTrigger has been ACTIVE for an interval of %{public}5.3f seconds.
%s ::: VoiceTrigger has been INACTIVE for an interval of %{public}5.3f seconds.
%s Adding value for scalar key %{public}@ : %{public}lld
%s Pushing value for distribution key %{public}@ : %{public}lf
%s ERR: uttPath is nil -  Bailing out
%s ERR: uttPath is nil - Bailing out
%s ERR: uttMeta is nil - Bailing out
%s ::: Error creating json Metadata: %{public}@
%s Error reading contents of SAT root: %{public}@: err: %{public}@
%s Error determining if file is dir-entry: url=%{public}@, err=%{public}@
%s ERROR creating meta-version json-data from dict: ERR: %{public}@
%s Error reading contents of audioDir: %{public}@, err: %{public}@
%s Missing meta-file: Creating new Meta file for audio file: %{public}@
%s ERR: Unexpected. metaVersionFileData is empty while the file exists at: %{public}@
%s Json-Err reading metaVersionFile: %{public}@: err: %{public}@
%s ERR: uttMetaURL is nil
%s ERR: Unexpected. metaData is nil while the uttMetaPath exists at: %{public}@
%s error reading meta-file: %{public}@
%s ERR: uttMetaURL is nil, defaulting to NO
%s ERR: metaData is nil, defaulting to NO for %{public}@
%s ERR: read metafile %{public}@ failed with %{public}@ - defaulting to NO
%s ERR: missing %{public}@ key in %{public}@ - defaulting to NO
%s ERR: uttMetaURL is nil - Bailing out
%s ERR: metaData is nil for %{public}@ - Bailing out
%s ERR: read metafile %{public}@ failed with %{public}@ - Bailing out
%s ERR: missing %{public}@ key in %{public}@ - Bailing out
%s ERR: %{public}@ is not present
%s Start monitoring : speech endpoint asset meta update
%s Stop monitoring : speech endpoint asset meta update
%s New speech endpoint asset is available
%s ::: CoreSpeech logging initialized (%s)
%s Couldn't create CoreSpeech log directory at path %{public}@ %{public}@
%s event = %{public}p client = %{public}p cannot handle event
%s ignore unknown types of message
%s message = %{public}p, client = %{public}p, cannot handle message
%s Received msg of type %{public}lld for utt %{public}@
%s Implicit utterence processing done with error %{public}@
%s Utt: %{public}@ removed from cache with error %{public}@
%s Received error %{public}@ from client %{public}@
%s Client %{public}p connection disconnected, noticing xpc listener
%s ERR: FilePath is nil - Bailing out
%s ERR: Training utterance doesnt exist at %@ - Bailing out
%s ERR: Training utterance is marked as directory at %@ - Bailing out
%s ERR: sharedSiriId is nil - Bailing out
%s Failed to enroll voice profiles with error %{public}@
%s Failed to get device hash list %{public}@
%s Processing sync data from device hash: %{public}@
%s Skipping language [%{public}@] since we already have enrollment data for this language
%s Skipping marking enrollment success for language %{public}@ with error %{public}@
%s language: %{public}@, enableVTAfterSyncLanguage: %{public}@, currSiriLanguage: %{public}@
%s Enabling VoiceTrigger Upon VoiceProfile sync for language: %{public}@ and enrolled language: %{public}@
%s VoiceTrigger does not exist for this platform, not setting VoiceTriggerEnabled
%s Not enabling VoiceTrigger Upon VoiceProfile sync for language: %{public}@
%s Sucessfully migrated language %{public}@
%s Migrated language %{public}@ but failed to mark SAT enrollment
%s Sucessfully marked as migrated for language : %{public}@
%s Failed to mark migrated for language : %{public}@
%s Failed to remove update path [%{public}@] upon migration completion, error: %{public}@
%s Failed to download voice profiles with error %{public}@
%s Enrolled voice profiles with error %{public}@
%s Failed to downlod voice profiles with error %{public}@
%s Skipping profile update for %{public}@ not matching current language %{public}@
%s Skipping profile Update for %{public}@ in %{public}@
%s Failed migrating Voice profile with ID %{public}@ for language %{public}@ with error %{public}@
%s Failed marking Voice profile with ID %{public}@ for language %{public}@ with error %{public}@
%s Sucessfully enrolled %{public}@ for language %{public}@
%s PHS update directory already exists, remove before we move forward
%s Failed to delete PHS update directory
%s Failed to create PHS update directory
%s Upload of Voice Profiles completed with error %@
%s Cannot delete existing SATUpload Diretory : %{public}@
%s Skipping uploading legacy version (%lu) of voice profile, current version %lu
%s Cannot create %{public}@ with error %{public}@ - Skipping language
%s Cannot create directory(%{public}@)
%s Skipping audiocache file %@
%s Cannot copy file %{public}@ to %{public}@ with error %{public}@
%s Cannot copy voice profile from %{public}@ to %{public}@ with error %{public}@
%s Triggering upload of voice profile %{public}@
%s Upload of voice profile at %{public}@ completed successfully
%s ERR: Fetching cached devices resulted in error %{public}@
%s ERR: error creating profilesJsonData: %@, err: %@
%s Cached devices with VoiceProfile in iCloud: %{public}@
%s CachedVoiceProfileFetch: Done Waiting with timedOut=%ld, waitTimeMs: %fms
%s ERR: metaBlob is nil. Returning false, language: %{public}@
%s ERR: Unknown device. Returning false, language: %{public}@
%s ERR: Unknown device-category for device: %{public}@, languageCode: %{public}@
%s ERR: %{public}s: Bailing out as language is nil!
%s ERR: Failed to deserialize metaBlob with error %{public}@
%s Looking VoiceProfile for CurrDevice: %{public}@{%{public}@} in metablob %{public}@
%s currDevice=[%{public}@ : {%{public}@}] ; syncedDevice=[%{public}@ : {%{public}@}]
%s VoiceProfile MATCH
%s VoiceProfile MIS-MATCH
%s CurrDevice: [%{public}@ : {%{public}@}] DOES NOT have VoiceProfile synced in iCloud
%s Looking VoiceProfile for CurrDevice: %{public}@{%{public}@} in devices %{public}@
%s Searching for synced-VoiceProfile for CurrDevice: %{public}@{%{public}@}
%s Will Enable VoiceTrigger after VoiceProfile sync for language: %{public}@
languageCode: %{public}@
%s Devices with VoiceProfile in iCloud for language: %{public}@:%{public}@
%s Timedout waiting for AFSettingsConnection:getDevicesWithAvailablePHSAssetsForLanguage: %{public}ld, waitedFor: %{public}d, Returning nil
%s timeToRet(AFSettingsConnection:getDevicesWithAvailablePHSAssetsForLanguage:): %{public}fms
%s ERR: Failed in marking Enrollment as Successful
%s Coudn't mark SAT enrollment %{public}@ at path %{public}@
%s Marked SAT enrollment %{public}@ at path %{public}@
%s We can't mark SAT %{public}@ when there is no audio directory
%s ERR: SAT did not trigger!!! - Bailing out
%s CSSpIdImplicitTraining not available
%s Unable to copy implicit utterence to %{public}@ with error %{public}@
%s Received xpc completion with result %d
%s AssetManager cannot be turned on since isFirstUnlocked is NO
%s AssetManager cannot be turned on since network is not available
%s CSXPCListener start listening
%s VoiceTrigger is already %{public}@, received duplicated notification!
%s Start monitring : VoiceTrigger setting switch
%s Cannot start monitoring VoiceTrigger setting switch because it was already started
%s Stop monitring : VoiceTrigger setting switch
%s VoiceTrigger enabled = %{public}@
%s Received AOP Listening state change notification : %{public}d
%s Unexpected XPC audioTimeConvert providing request : %{public}lld
%s From sampleCount %{public}llu fetched hostTime = %{public}llu
%s From hostTime %{public}llu fetched sampleCount = %{public}llu
%s Non internal build, Ignoring command %@ from peerId %@ - Bailing out!
%s Received Malformed command %@ from peerId %@ - Bailing out!
%s Command %@ received from peerId %@
%s Unknown Command: (%@) - Ignoring
%s Triggering sync with peer - %@
%s Triggering nearmiss sync with peer - %@
%s Triggering voice profile sync with peer - %@
%s CSP2P_RemoteHeySiriCmd: ENABLE HeySiri: Not Implemented Yet: 
%s CSP2P_RemoteHeySiriCmd: DISABLE HeySiri: Not Implemented Yet: 
%s Cannot read contents of directory: %@, err: %@
%s Could not determine if [%@] is a directory or not. Err=%@
%s Found dir: %@. Skipping compression
%s _compressFilesInDirectory: Malloc failed for file %@ (%lu) - Discarding
%s _compressFilesInDirectory: Compression failed for file %@ (%lu) - Sending Uncompressed
%s _compressFilesInDirectory: File %@ compressed from %ld to %ld 
%s CSP2P_VoiceProfileParallelRecordingsFetchCmd: Cannot send VoiceProfile when _adCompanionServiceProvider is nil - returning
%s CSP2P_VoiceProfileParallelRecordingsFetchCmd: Message incomplete - Bailing out %@
%s CSP2P_VoiceProfileParallelRecordingsFetchCmd: File %@ isCompressed: %d, compressedSize: %ld, err: %@ 
%s CSP2P_VoiceProfileParallelRecordingsFetchCmd: Failed VoiceProfileTransfer: %@, error %@
%s Failed to remove the file %@
%s Failed in compressing %{public}@ with errror %{public}@ - Bailing out
%s Transfering NearMiss file %@ withCompression %{public}@ and size %ld in batch %{public}@
%s Failed moving file from %@ to %@ with error %@
%s Transfering VoiceId file %@ withCompression %{public}@ and size %ld in batch %{public}@
%s %@ is nil - Bailing out
%s Failed in transporting Voice file %@ with reponse: %@, error %@
%s Failed to remove the file %@ with error %@
%s Failed to move the file %@ to %@ with error %@
%s CSP2P_VoiceProfileParallelRecordingTransferCmd: received malformed command - %@ %@ %@
%s CSP2P_VoiceProfileParallelRecordingTransferCmd: unknown IDS peer with passed Identifier %@, %@ %@
%s CSP2P_VoiceProfileParallelRecordingTransferCmd: received malformed command - %@
%s CSP2P_VoiceProfileParallelRecordingTransferCmd: Creating directory failed with error %@
%s Ignoring sync of existing file %@ from %@
%s Syncing parallel recorded audio file - %@ from %@
%s Uncompressed file %@ sent by peer %@
%s ERR: Failed to allocate buffer of size %zu, bailing out
%s Writing to file(%@) failed!. Err=%@
%s received malformed command - %@ %@ %@
%s unknown IDS peer with passed Identifier %@, %@ %@
%s received malformed command - %@
%s Syncing audio file - %@ from %@
%s received Music account credentials before voice profile landed for %@
%s CSP2P_VoiceProfileTransferCmd: received malformed command - %@ %@ %@
%s CSP2P_VoiceProfileTransferCmd: received malformed command: CSP2P_VoiceProfileData_Key: %@CSP2P_VoiceProfileFileName_Key: %@CSP2P_VoiceProfileSpeakerName_Key: %@CSP2P_VoiceProfileLocale_Key: %@CSP2P_VoiceProfileDataType_Key: %@CSP2P_VoiceProfileTotalSegments_Key: %@CSP2P_VoiceProfileSegment_Key: %@
%s CSP2P_VoiceProfileTransferCmd: received command when speakerId is disabled - Bailing out
%s CSP2P_VoiceProfileTransferCmd: SpId Assets are not available - Bailing out
%s CSP2P_VoiceProfileTransferCmd: Received VoiceProfile Segment (%@/%@) from peerId %@
%s CSP2P_VoiceProfileTransferCmd: Failed to delete the directory %@ with error %@
%s CSP2P_VoiceProfileTransferCmd: received VoiceProfileSegment %@, expected %d
%s CSP2P_VoiceProfileTransferCmd: Creating directory failed with error %@
%s CSP2P_VoiceProfileTransferCmd: Writing to file failed!!!
%s Received request to delete VoiceProfile %@ from peerId %@
%s Cannot send data across when _adCompanionServiceProvider is nil - returning
%s ERR: Rejecting command %@ sent to non Horseman device
%s ERR: received malformed command - %@ %@
%s ERR: unknown IDS peer with passed Identifier %@, %@ %@
%s ERR: received malformed command with locale nil - %@
%s ERR: received malformed command with profileId nil - %@
%s ERR: Failed to find voice profile with identifier - %@
%s CSP2P_VoiceProfileFetchCmd: Transferring voice profile %{public}@
%s CSP2P_VoiceProfileFetchCmd: File %@ isCompressed: %d, compressedSize: %ld, err: %@
%s CSP2P_VoiceProfileReverseTransferCmd: Failed VoiceProfileTransfer: %@, error %@
%s CSP2P_VoiceProfileReverseTransferCmd: Successfully transferred %@
%s CSP2P_VoiceProfileReverseTransferCmd: Failed transferring voice profile %@ with error %@
%s CSP2P_VoiceProfileReverseTransferCmd: Successfully transferred voice profile %@
%s ERR: Rejecting command %@ sent to Horseman device
%s ERR: received malformed command with relative path nil - %@
%s Failed in sending trigger for Voice profile update to peer %@ with error %@
%s init-_currentLanguageCode: %{public}@
%s Asset Manager Policy has been %{public}@
%s Asset Manager Policy has been enabled, start fetching meta data now
%s set option : allowVoiceTriggerAssetsDownload ? %{public}@;               allowEndpointAssetDownload ? %{public}@;               allowLanguageDetectorAssetDownload ? %{public}@
%s Need to fetch remote meta now, since we have new asset need to be downloaded
%s Does not need to fetch remote meta now
%s Cannot fetch VoiceTrigger asset meta data
%s Undefined assetType : %{public}u
%s _currentLanguageCode changed: %{public}@
%s Trying to start download meta data
%s Periodical downloading is already scheduled, ignore request.
%s No periodical downloading is scheduled, ignore request.
%s zeroFilterWinSz: %{public}tu, numHostTicksPerAudioSample: %{public}f
%s _vtEndInSampleCount:%{public}ld, _numSamplesProcessed: %{public}ld, voiceTriggerInfo: %{public}@
%s Creating OS Transaction for %{public}@
%s Release OS Transaction for %{public}@
%s Metric Providing Request Message has arrived : %{public}lld
%s Unexpected XPC Metric providing request : %{public}lld
%s audioMetric = %{public}@
%s audioMetricProvider not existing
%s Message type = %{public}lld
%s Cannot handle wrong message type
%s Cannot handle activateEventMessage since event is nil
%s Start monitoring : Siri language code
%s Stop monitoring : Siri language code
%s Siri language changed to : %{public}@
%s Ignore notifying change of language code, since it is nil
%s SpkrId:: Unknown CSSpIdType string: %@
%s SpkrId:: ERR: spIdRootDirForLocale called with locale=nil
%s SpkrId:: Incorrect usage of API - Bailing out
%s SpkrId:: path is nil - Bailing out
%s SpkrId:: Direntry with same name exists, this will be removed: %@
%s SpkrId:: Creating Directory : %@
%s SpkrId:: Creating Directory failed : %@
%s SpkrId:: Exceeded privacy limit for grading utterances : %ld (%d)
%s SpkrId:: SpeakerId Assets missing at %@
%s SpkrId:: Could not read existing %@ file: err: %@
%s SpkrId:: ERR: Could not read existing %@ file: err: %@
%s SpkrId:: ERR: %@ is a directory
%s SpkrId:: ERR: Could not find version file - %@
%s ERR: Migration API called on HomePod - Bailing out
%s ERR: Failed to move %{public}@ to %{public}@ with error %{public}@
%s ERR: Failed to delete %{public}@ with error %{public}@
%s Successfully moved %{public}@ to %{public}@
%s Skipping moving of file %{public}@
%s Coudn't fetch the list of files at path: %{public}@ %{public}@
%s Migrating Voice Profile for %{public}@ from %lu to %lu not supported
%s ERR: error creating updatedVoiceProfileJsonData from: %@, err: %@
%s ERR: error removing voice profile version file at: %@, err: %@
%s ERR: Error writing voice profile version file at: %@, err:%@
%s Unknown Device category for deviceProduceType: %@
%s ERR: Unknown device. returning false: %{public}@
%s ERR: satLanguagePath is nil. returning false
%s Voice Profile Mismatch - CurrentDeviceCategory %@ VoiceProfileCategory %@
%s Malformed audio-dir URL for string <%{public}@>:url
%s ERR: reading contents of audioDir: %{public}@
%s No jsonFiles found in %{public}@: jsonFiles.count=%{public}lu
%s Unexpected: empty JSON data for file: %{public}@
%s Error reading metaDict at path: %{public}@
%s metaProductType: %{public}@
%s vtprofile: currDevice=[%{public}@:%{public}@] ; vpDirDevice=[%{public}@:%{public}@]
%s Could not find productType in VT-Meta file, trying next one
%s No compatible VT profile found for CurrDevice: %{public}@
%s Incorrect logitCeil %f and logitFloor %f - defaulting them to %f and %f
%s Capping the score %f to 1.0
%s Flooring the score %f to 0.0
%s SpeakerIDScores: %@ --> (%@, %@, %@)
%s Voice Profile for profileID %@ not found
%s ERR: SharedSiriID is not available, defaulting to profileID %@
%s ERR: SiriDebugID is not available, falling to profileID %@
%s ERR: SiriProfileId is not available, defaulting to profileID %@
%s satAudioDirectory is nil - Bailing out
%s ERR: date is nil - Bailing out
%s Filtered %@ with enrolled date %@
%s ERR: Failed to get version file for profile %{public}@
%s ERR: Invoked this API on wrong device
%s ERR: %@ doesnt exist - Bailing out
%s ERR: %@ file is a directory - Bailing out
%s SpkrId:: Updated %{public}@ voice profile %{public}@ to %d
%s ERR: Version file passed in nil - Bailing out
%s ERR: trying to remove %@ directory, bailing out
%s ERR: satTDModelDirector is nil for LanguageCode %@
%s Couldn't delete invalidated speaker model at path %{public}@ %{public}@
%s Start monitoring : VoiceTrigger Asset Download
%s Stop monitoring : VoiceTrigger Asset Download
%s New VoiceTrigger is now installed
%s CSVoiceIdXPCListener start listening
%s speechController = %{public}p
%s xpcListener = %{public}p
%s volumeController = %{public}p
%s context = %{public}@
%s Failed to create audio recorder : %{public}@
%s For Context : %{public}@, audioStreamId(%llu) has allocated
%s Failed to get audio stream handle ID : %{publid}@
%s has match with audio stream handle id : %llu
%s does not match with audio stream handle id(%llu), creating new audio provider
%s Received VoiceTrigger cached asset change notification, let's reinitialize VoiceTrigger
%s Trying to start clear logging files
%s Clear logging file timer is already started, ignore startClearLoggingFilesTimer request.
%s cannot handle nil event 
%s ignore unknown types of message: %{public}@
%s cannot handle nil error
%s In %@: Continuous digital zero detected, lasting %{public}u samples per channel
%s In %@: Continuous digital zero in this audio chunk detected, lasting %{public}u samples per channel
%s Fallback asset resource path : %{public}@
%s Cannot find corespeech asset from resourcePath : %{public}@
%s Configuration file is not exists : %{public}@
%s Cannot read configuration file : %{public}@
%s Cannot decode configuration json file : %{public}@
%s Configuration json file is not expected format
%s Cannot access to %{public}@ %{public}@ using default value
%s Cannot send nil message
%s Sending Message to Client
%s Unable to send message to client since there is no connection
%s Cannot handle audio providing message
%s Audio Providing Request Message has arrived : %{public}lld
%s Unable to handle audio providing switch message : context is nil
%s Handing PingPong message
%s CSHostDaemon didLaunch
%s Got xpc event for notification %s
%s numChannels: %{public}lu, recordingDuration: %{public}f, sampleRate: %{public}f
%s Cannot copy samples since this is empty
%s Could NOT copyFrom: %{public}lu to: %{public}lu, retSampleCount: %{public}lu
%s copyBuffer: oldestSample: %{public}lu latestSample: %{public}lu, numSamplesCopied: %{public}lu
%s CSAudioCircularBuffer.reset
%s saveRecordingBufferFrom: %{public}lu to: %{public}lu toURL: %{public}@
%s csrb: %{public}@
%s Invalid request: (%{public}lu, %{public}lu): noting to write to file
%s Invalid request: reqStartSample=%{public}lu, reqEndSample=%{public}lu, oldestSampleInBuffer: %{public}lu, latestSampleInBuffer=%{public}lu
%s Error reading audio file: %{public}d, skipping...
%s Notifying CoreSpeechDaemon launched
%s Start monitoring : corespeechd state
%s Cannot start monitoring corespeechd state because it was already started
%s Stop monitoring : corespeechd state
%s CoreSpeechDaemon state changed to %{public}u
%s Delta is larger than anchorHostTime: anchorSampleCount = %{public}lld, sampleTime = %{public}lld, anchorHostTime = %{public}lld
%s Delta is larger than anchorSampleCount
%s Not supported on this platform
%s Start monitoring: siri assertion enable/disable
%s Stop monitoring: siri assertion enable/disable
%s did receive enable assertion
%s did receive disable assertion
%s Session Providing Request Message has arrived : %{public}lld
%s Unexpected XPC session providing request : %{public}lld
%s Failed to prewarm audio session, error : %{public}@
%s Session activate reason : %{public}u
%s Failed to activate audio session, error : %{public}@
%s Failed to deactivate audio session, error : %{public}@
%s Session request getting duck others option
%s Trying to get duck others option when audioSessionProvider is nil
%s Session set duck others option : %{public}d
%s Trying to set duck others option when audioSessionProvider is nil
%s Session %{public}@ mini ducking
%s Trying to enalbe mini ducking when audioSessionProvider is nil
%s Alert Providing Request Message has arrived : %{public}lld
%s Unexpected XPC alert providing request : %{public}lld
%s Alert sound url : %{public}@, alertType = %{public}d
%s Set alert sound successful ? %{public}@
%s audioAlertProvider not existing
%s AlertType = %{public}d
%s Play alert sound successful ? %{public}@
%s PlayRecordStartingAlertAndResetEndpointer successful ? %{public}@
%s alertStartTime = %{public}llu
%s Invalid alert behavior
%s Alert behavior : %{public}@
%s value = %{public}d
%s Couldn't create speech log directory at path %{public}@ %{public}@
%s Couldn't create SoS log directory at path %{public}@ %{public}@
%s enableAudioInection: is only available on internal builds
%s setAudioInjectionFilePath: is only available on internal builds
%s kCSAudioInjectionFilePathKey is not array type
%s kCSAudioInjectionFilePathKey array size = %d
%s kCSAudioInjectionFilePathKey doesn't have NSString as an array entry
%s Device on power saving mode ? %{public}@
%s Shouldn't be called on non-iOS platform
%s Device support barge-in? %{public}@
%s Received external route change notification
%s Received CarPlay route change notification
%s Stop monitoring : AudioRouteChangeMonitor
%s Notifying Hearst Connection State : %{public}d
%s Notifying Jarvis Connection State : %{public}d
%s %@ task delivered.
%s %@ completed with response %@ and error %@.
%s Start monitoring : Software update checking state
%s Cannot start monitoring software update checking state because it was already started
%s Stop monitoring : Software update checking state
%s Software update checking running : %{public}@
%s Get initial state from MediaRemote: media is on playing state %{public}ld.
%s Start monitoring MediaRemote: media playback
%s Stop monitoring MediaRemote: media playback
%s MediaRemote reported the now playing app playback state changed to %s (state %d)
%s VoiceTrigger AOP mode cannot be turned on since powerOnCharger = %{public}d, speakerState = %{public}d
%s VoiceTrigger AOP mode cannot be turned on since Timer is firing
%s VoiceTrigger AOP mode cannot be turned on since Alarm is firing
%s VoiceTrigger AOP mode cannot be turned on since audio session is active
%s VoiceTrigger AOP mode cannot be turned on since built-in speaker is active
%s AOP Listening is disabled
%s Speech Detection VAD is not present
%s Still AOP mode, since speech detection VAD is not available
%s network state notify key : %s
%s Start monitoring : network availability
%s Stop monitoring : network availability
%s Network availability changed
%s xpc object should be XPC_TYPE_DICTIONARY
%s xpcObject key or value is NULL
%s Cannot encode key into xpcobject since the key is not NSString class type
%s Meter Providing Request Message has arrived : %{public}lld
%s Unexpected XPC Meter providing request : %{public}lld
%s setMeteringEnabled : %{public}d
%s audioMeterProvider not existing
%s updateMeters
%s power = %{public}f with powerType %{public}u
pbhw
pbtb
pbiu
otua
ciov
bhev
eltb
siar
tdtb
cvdh
cvpc
pbiu
tsop
rtsh
mcpl
supo
mcplsupoxeps
ffffff
BNSt3__118basic_stringstreamIcNS_11char_traitsIcEENS_9allocatorIcEEEE
NSt3__115basic_stringbufIcNS_11char_traitsIcEENS_9allocatorIcEEEE
NSt3__119basic_ostringstreamIcNS_11char_traitsIcEENS_9allocatorIcEEEE
@mcpl
fff?
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
<key>com.apple.airplay.carplayavvc</key>
<true/>
<key>com.apple.assistant.analytics</key>
<true/>
<key>com.apple.assistant.client</key>
<true/>
<key>com.apple.assistant.settings</key>
<true/>
<key>com.apple.avfoundation.allows-access-to-device-list</key>
<true/>
<key>com.apple.coreaudio.CanRecordPastData</key>
<true/>
<key>com.apple.coreaudio.CanRecordWithoutSessionActivation</key>
<true/>
<key>com.apple.coreaudio.i-am-siri</key>
<true/>
<key>com.apple.coreaudio.register-internal-aus</key>
<true/>
<key>com.apple.hid.system.user-access-fast-path</key>
<true/>
<key>com.apple.private.DistributedEvaluation.RecordAccess-com.apple.fides.borealis</key>
<true/>
<key>com.apple.private.DistributedEvaluation.RecordAccess-com.apple.fides.phs</key>
<true/>
<key>com.apple.private.assets.accessible-asset-types</key>
<array>
<string>com.apple.MobileAsset.VoiceTriggerAssets</string>
<string>com.apple.MobileAsset.VoiceTriggerAssetsWatch</string>
<string>com.apple.MobileAsset.VoiceTriggerAssetsMarsh</string>
<string>com.apple.MobileAsset.SpeechEndpointAssets</string>
<string>com.apple.MobileAsset.RaiseToSpeakAssets</string>
<string>com.apple.MobileAsset.VoiceTriggerAssetsMac</string>
</array>
<key>com.apple.private.bmk.allow</key>
<true/>
<key>com.apple.private.corespeech.xpc.remote</key>
<true/>
<key>com.apple.private.healthkit</key>
<true/>
<key>com.apple.private.healthkit.medicaliddata</key>
<true/>
<key>com.apple.private.hid.client.event-monitor</key>
<true/>
<key>com.apple.private.iokit.darkwake-control</key>
<true/>
<key>com.apple.private.mobiletimerd</key>
<true/>
<key>com.apple.private.siri.activation</key>
<true/>
<key>com.apple.private.siri.invoke</key>
<true/>
<key>com.apple.private.tcc.allow</key>
<array>
<string>kTCCServiceMicrophone</string>
</array>
<key>com.apple.proactive.eventtracker</key>
<true/>
<key>com.apple.rootless.storage.CoreSpeech</key>
<true/>
<key>com.apple.security.exception.files.absolute-path.read-only</key>
<array>
<string>/private/var/mobile/Library/Trial/Treatments/200/</string>
<string>/private/var/mobile/Library/Trial/NamespaceDescriptors/</string>
</array>
<key>com.apple.security.exception.mach-lookup.global-name</key>
<array>
<string>com.apple.MobileTimer.timerserver</string>
<string>com.apple.MobileTimer.alarmserver</string>
</array>
<key>com.apple.security.exception.shared-preference.read-only</key>
<array>
<string>com.apple.raisetospeak</string>
<string>com.apple.niservices</string>
</array>
<key>com.apple.siri.activation</key>
<true/>
<key>com.apple.siri.external_request</key>
<true/>
<key>com.apple.voicetrigger.voicetriggerservice</key>
<true/>
<key>keychain-access-groups</key>
<array>
<string>com.apple.corespeech</string>
</array>
</dict>
</plist>
