@(#)PROGRAM:EmbeddedAcousticRecognition  PROJECT:embeddedacousticrecognition-1
_NSt3__120__shared_ptr_pointerIPN6quasar14LmeDataFactoryENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN6quasar14LmeDataFactoryEEE
NSt3__120__shared_ptr_emplaceIN6quasar14GlobalLRUCacheINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_6vectorIS8_NS6_IS8_EEEEEENS6_ISC_EEEE
N6quasar14GlobalLRUCacheINSt3__112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEENS1_6vectorIS7_NS5_IS7_EEEEEE
NSt3__120__shared_ptr_pointerIPN6quasar14GlobalLRUCacheINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_6vectorIS8_NS6_IS8_EEEEEENS_14default_deleteISC_EENS6_ISC_EEEE
NSt3__114default_deleteIN6quasar14GlobalLRUCacheINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_6vectorIS8_NS6_IS8_EEEEEEEE
MbP?
12LmFstWrapper
NSt3__120__shared_ptr_emplaceINS_19basic_istringstreamIcNS_11char_traitsIcEENS_9allocatorIcEEEENS4_IS6_EEEE
NSt3__119basic_istringstreamIcNS_11char_traitsIcEENS_9allocatorIcEEEE
NSt3__120__shared_ptr_pointerIPN5kaldi5TimerENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN5kaldi5TimerEEE
NSt3__120__shared_ptr_emplaceIN6quasar16RecogAudioBufferENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar16MultiAudioBufferENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_pointerIP12LmFstWrapperNS_14default_deleteIS1_EENS_9allocatorIS1_EEEE
NSt3__114default_deleteI12LmFstWrapperEE
NSt3__113__assoc_stateIN6quasar8LocationEEE
NSt3__120__shared_ptr_emplaceIN6quasar14RunAsyncParamsENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceI19ResultStreamWrapperNS_9allocatorIS1_EEEE
19ResultStreamWrapper
NSt3__120__shared_ptr_pointerIPN6quasar20SyncSpeechRecognizerENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN6quasar20SyncSpeechRecognizerEEE
9SpeechITN
13QuasarITNImpl
N5boost9algorithm6detail13token_finderFINS1_10is_any_ofFIcEEEE
N5boost16exception_detail10clone_implINS0_19error_info_injectorINS_17bad_function_callEEEEE
N5boost16exception_detail19error_info_injectorINS_17bad_function_callEEE
N5boost17bad_function_callE
N5boost9exceptionE
<N5sdapi14SdapiTokenizerE
?NSt3__120__shared_ptr_emplaceIN6quasar17PSRAudioProcessorENS_9allocatorIS2_EEEE
N5sdapi12SdapiITNImplE
NSt3__120__shared_ptr_emplaceIN6quasar25SilencePosteriorGeneratorENS_9allocatorIS2_EEEE
?22EARContextAwareLDModel
29EARContextAwareLDModelFactory
25EARAcousticLDModelFactory
NSt3__120__shared_ptr_emplaceI21CoreMLAcousticLDModelNS_9allocatorIS1_EEEE
21CoreMLAcousticLDModel
NSt3__120__shared_ptr_emplaceIN6quasar9LDContextENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceI17EARLDResultStreamNS_9allocatorIS1_EEEE
17EARLDResultStream
NSt3__120__shared_ptr_emplaceIKN6quasar9LDContextENS_9allocatorIS3_EEEE
N5sdapi8SdapiG2PE
NSt3__120__shared_ptr_emplaceIN5sdapi18SimpleStringMapperENS_9allocatorIS2_EEEE
N6marisa9ExceptionE
We love Marisa.
N13sentencepiece10normalizer10NormalizerE
N5Darts15DoubleArrayImplIvvivEE
N13sentencepiece22SentencePieceProcessorE
N13sentencepiece4word5ModelE
N13sentencepiece9character5ModelE
N13sentencepiece7unigram7LatticeE
N13sentencepiece7unigram9ModelBaseE
N13sentencepiece7unigram5ModelE
N5Darts7Details9ExceptionE
N13sentencepiece11TrainerSpecE
N13sentencepiece14NormalizerSpecE
N13sentencepiece24ModelProto_SentencePieceE
N13sentencepiece10ModelProtoE
NSt3__112basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEE
NSt3__121__basic_string_commonILb1EEE
N13sentencepiece14ModelInterfaceE
N13sentencepiece31SentencePieceText_SentencePieceE
N13sentencepiece17SentencePieceTextE
N13sentencepiece22NBestSentencePieceTextE
N6google8protobuf8internal29InternalMetadataWithArenaBaseINSt3__112basic_stringIcNS3_11char_traitsIcEENS3_9allocatorIcEEEENS1_29InternalMetadataWithArenaLiteEE9ContainerE
N13sentencepiece3bpe5ModelE
N6google8protobuf11MessageLiteE
N6google8protobuf8internal12FieldSkipperE
N6google8protobuf8internal29CodedOutputStreamFieldSkipperE
N6google8protobuf14FatalExceptionE
N6google8protobuf7ClosureE
N6google8protobuf8internal16FunctionClosure0E
N6google8protobuf2io20ZeroCopyOutputStreamE
N6google8protobuf2io17ArrayOutputStreamE
N6google8protobuf2io18StringOutputStreamE
N6google8protobuf8internal15ExtensionFinderE
N6google8protobuf8internal24GeneratedExtensionFinderE
N6google8protobuf13RepeatedFieldIiEE
N6google8protobuf13RepeatedFieldIxEE
N6google8protobuf13RepeatedFieldIjEE
N6google8protobuf13RepeatedFieldIyEE
N6google8protobuf13RepeatedFieldIfEE
N6google8protobuf13RepeatedFieldIdEE
N6google8protobuf13RepeatedFieldIbEE
N6google8protobuf16RepeatedPtrFieldINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEEE
N6google8protobuf8internal20RepeatedPtrFieldBaseE
N6google8protobuf16RepeatedPtrFieldINS0_11MessageLiteEEE
N3fst13TopOrderQueueIiEE
NSt3__112__deque_baseIiNS_9allocatorIiEEEE
N3fst3FstINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEE
N3fst7FstImplINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEE
NSt3__114basic_ofstreamIcNS_11char_traitsIcEEEE
N3fst18DeterminizeFsaImplINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_20DefaultCommonDivisorIS4_EENS_24DefaultDeterminizeFilterIS6_EENS_28DefaultDeterminizeStateTableIS6_NS_18IntegerFilterStateIaEEEEEE
N3fst22DeterminizeFstImplBaseINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEE
N3fst9CacheImplINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEE
N3fst13CacheBaseImplINS_10CacheStateINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENSt3__19allocatorIS7_EEEENS_17DefaultCacheStoreIS7_EEEE
N3fst13StateIteratorINS_14DeterminizeFstINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEEEE
N3fst18CacheStateIteratorINS_14DeterminizeFstINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEEEE
N3fst17StateIteratorBaseINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEE
CN6quasar12IModelLoaderE
N6quasar11ModelLoaderE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar15NnlmDecoderWordENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar14CEInferenceNetENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar15FofeLmEvaluatorENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar14RnnlmEvaluatorENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar14DnnlmEvaluatorENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_pointerIPN3fst9VectorFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEENS1_11VectorStateIS6_NS_9allocatorIS6_EEEEEENS_14default_deleteISB_EENS8_ISB_EEEE
NSt3__114default_deleteIN3fst9VectorFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEENS1_11VectorStateIS6_NS_9allocatorIS6_EEEEEEEE
N3fst12ConstFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEEjEE
N3fst8ConstFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEjEE
N3fst17ImplToExpandedFstINS_12ConstFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEEjEENS_11ExpandedFstIS5_EEEE
N3fst9ImplToFstINS_12ConstFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEEjEENS_11ExpandedFstIS5_EEEE
NSt3__120__shared_ptr_pointerIPN3fst8ConstFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEEjEENS_14default_deleteIS7_EENS_9allocatorIS7_EEEE
NSt3__114default_deleteIN3fst8ConstFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEEjEEEE
N3fst12NGramFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0EEE
N3fst12NGramFstDataINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0EEE
N3fst8NGramFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0EEE
N3fst17ImplToExpandedFstINS_12NGramFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0EEENS_11ExpandedFstIS5_EEEE
N3fst9ImplToFstINS_12NGramFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0EEENS_11ExpandedFstIS5_EEEE
N3fst11ArcIteratorINS_8NGramFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0EEEEE
N3fst15NGramFstMatcherINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0EEE
NSt3__120__shared_ptr_pointerIPN3fst8NGramFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb0EEENS_14default_deleteIS7_EENS_9allocatorIS7_EEEE
NSt3__114default_deleteIN3fst8NGramFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb0EEEEE
N3fst12NGramFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1EEE
N3fst12NGramFstDataINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1EEE
N3fst8NGramFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1EEE
N3fst17ImplToExpandedFstINS_12NGramFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1EEENS_11ExpandedFstIS5_EEEE
N3fst9ImplToFstINS_12NGramFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1EEENS_11ExpandedFstIS5_EEEE
N3fst11ArcIteratorINS_8NGramFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1EEEEE
N3fst15NGramFstMatcherINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1EEE
NSt3__120__shared_ptr_pointerIPN3fst8NGramFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb1EEENS_14default_deleteIS7_EENS_9allocatorIS7_EEEE
NSt3__114default_deleteIN3fst8NGramFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb1EEEEE
N3fst14ReducedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb0EEE
N3fst10ReducedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb0EEE
N3fst17ImplToExpandedFstINS_14ReducedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb0EEENS_11ExpandedFstIS5_EEEE
N3fst9ImplToFstINS_14ReducedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb0EEENS_11ExpandedFstIS5_EEEE
N3fst13StateIteratorINS_10ReducedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb0EEEEE
NSt3__120__shared_ptr_pointerIPN3fst10ReducedFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb0ELb0EEENS_14default_deleteIS7_EENS_9allocatorIS7_EEEE
NSt3__114default_deleteIN3fst10ReducedFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb0ELb0EEEEE
N3fst14ReducedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb0EEE
N3fst10ReducedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb0EEE
N3fst17ImplToExpandedFstINS_14ReducedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb0EEENS_11ExpandedFstIS5_EEEE
N3fst9ImplToFstINS_14ReducedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb0EEENS_11ExpandedFstIS5_EEEE
N3fst13StateIteratorINS_10ReducedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb0EEEEE
N3fst11ArcIteratorINS_10ReducedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb0EEEEE
NSt3__120__shared_ptr_pointerIPN3fst10ReducedFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb1ELb0EEENS_14default_deleteIS7_EENS_9allocatorIS7_EEEE
NSt3__114default_deleteIN3fst10ReducedFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb1ELb0EEEEE
N3fst14ReducedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb1EEE
N3fst10ReducedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb1EEE
N3fst17ImplToExpandedFstINS_14ReducedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb1EEENS_11ExpandedFstIS5_EEEE
N3fst9ImplToFstINS_14ReducedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb1EEENS_11ExpandedFstIS5_EEEE
N3fst13StateIteratorINS_10ReducedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb1EEEEE
N3fst11ArcIteratorINS_10ReducedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb1EEEEE
NSt3__120__shared_ptr_pointerIPN3fst10ReducedFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb0ELb1EEENS_14default_deleteIS7_EENS_9allocatorIS7_EEEE
NSt3__114default_deleteIN3fst10ReducedFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb0ELb1EEEEE
N3fst14ReducedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb1EEE
N3fst10ReducedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb1EEE
N3fst17ImplToExpandedFstINS_14ReducedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb1EEENS_11ExpandedFstIS5_EEEE
N3fst9ImplToFstINS_14ReducedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb1EEENS_11ExpandedFstIS5_EEEE
N3fst13StateIteratorINS_10ReducedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb1EEEEE
N3fst11ArcIteratorINS_10ReducedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb1EEEEE
NSt3__120__shared_ptr_pointerIPN3fst10ReducedFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb1ELb1EEENS_14default_deleteIS7_EENS_9allocatorIS7_EEEE
NSt3__114default_deleteIN3fst10ReducedFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb1ELb1EEEEE
N3fst15SqueezedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb0EEE
N3fst11SqueezedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb0EEE
N3fst17ImplToExpandedFstINS_15SqueezedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb0EEENS_11ExpandedFstIS5_EEEE
N3fst9ImplToFstINS_15SqueezedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb0EEENS_11ExpandedFstIS5_EEEE
NSt3__120__shared_ptr_pointerIPN3fst11SqueezedFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb0ELb0EEENS_14default_deleteIS7_EENS_9allocatorIS7_EEEE
NSt3__114default_deleteIN3fst11SqueezedFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb0ELb0EEEEE
N3fst15SqueezedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb0EEE
N3fst11SqueezedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb0EEE
N3fst17ImplToExpandedFstINS_15SqueezedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb0EEENS_11ExpandedFstIS5_EEEE
N3fst9ImplToFstINS_15SqueezedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb0EEENS_11ExpandedFstIS5_EEEE
N3fst11ArcIteratorINS_11SqueezedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb0EEEEE
NSt3__120__shared_ptr_pointerIPN3fst11SqueezedFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb1ELb0EEENS_14default_deleteIS7_EENS_9allocatorIS7_EEEE
NSt3__114default_deleteIN3fst11SqueezedFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb1ELb0EEEEE
N3fst15SqueezedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb1EEE
N3fst11SqueezedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb1EEE
N3fst17ImplToExpandedFstINS_15SqueezedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb1EEENS_11ExpandedFstIS5_EEEE
N3fst9ImplToFstINS_15SqueezedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb1EEENS_11ExpandedFstIS5_EEEE
N3fst11ArcIteratorINS_11SqueezedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb0ELb1EEEEE
NSt3__120__shared_ptr_pointerIPN3fst11SqueezedFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb0ELb1EEENS_14default_deleteIS7_EENS_9allocatorIS7_EEEE
NSt3__114default_deleteIN3fst11SqueezedFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb0ELb1EEEEE
N3fst15SqueezedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb1EEE
N3fst11SqueezedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb1EEE
N3fst17ImplToExpandedFstINS_15SqueezedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb1EEENS_11ExpandedFstIS5_EEEE
N3fst9ImplToFstINS_15SqueezedFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb1EEENS_11ExpandedFstIS5_EEEE
N3fst11ArcIteratorINS_11SqueezedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEELb1ELb1EEEEE
NSt3__120__shared_ptr_pointerIPN3fst11SqueezedFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb1ELb1EEENS_14default_deleteIS7_EENS_9allocatorIS7_EEEE
NSt3__114default_deleteIN3fst11SqueezedFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEELb1ELb1EEEEE
NSt3__120__shared_ptr_emplaceIN5kaldi15TransitionModelENS_9allocatorIS2_EEEE
N5boost13property_tree11json_parser17json_parser_errorE
N5boost13property_tree17file_parser_errorE
N5boost13property_tree11ptree_errorE
N6quasar5PTree14JsonParseErrorE
N6quasar5PTree5ErrorE
N6quasar5PTree7BadPathE
N5boost16exception_detail10clone_implINS0_19error_info_injectorINS_13property_tree11json_parser17json_parser_errorEEEEE
N5boost16exception_detail19error_info_injectorINS_13property_tree11json_parser17json_parser_errorEEE
NSt3__114basic_ifstreamIcNS_11char_traitsIcEEEE
NSt3__113basic_filebufIcNS_11char_traitsIcEEEE
NSt3__110__function6__funcINS_6__bindIRFvRNS_8functionIFvvEEERKNS_6atomicIbEEEJS6_RKNS_12placeholders4__phILi1EEEEEENS_9allocatorISI_EEFvSA_EEE
NSt3__110__function6__baseIFvRKNS_6atomicIbEEEEE
NSt3__16__bindIRFvRNS_8functionIFvvEEERKNS_6atomicIbEEEJS4_RKNS_12placeholders4__phILi1EEEEEE
NSt3__118__weak_result_typeIPFvRNS_8functionIFvvEEERKNS_6atomicIbEEEEE
NSt3__115binary_functionIRNS_8functionIFvvEEERKNS_6atomicIbEEvEE
NSt3__120__shared_ptr_emplaceIN6quasar16SimpleThreadPool4TaskENS_9allocatorIS3_EEEE
N6quasar12SystemConfigE
N5boost2io18basic_altstringbufIcNSt3__111char_traitsIcEENS2_9allocatorIcEEEE
N5boost16exception_detail10clone_implINS0_19error_info_injectorINS_2io17bad_format_stringEEEEE
N5boost16exception_detail19error_info_injectorINS_2io17bad_format_stringEEE
N5boost2io17bad_format_stringE
N5boost2io12format_errorE
N5boost16exception_detail10clone_implINS0_19error_info_injectorINS_2io13too_many_argsEEEEE
N5boost16exception_detail19error_info_injectorINS_2io13too_many_argsEEE
N5boost2io13too_many_argsE
N5boost2io22basic_oaltstringstreamIcNSt3__111char_traitsIcEENS2_9allocatorIcEEEE
N5boost16base_from_memberINS_10shared_ptrINS_2io18basic_altstringbufIcNSt3__111char_traitsIcEENS4_9allocatorIcEEEEEELi0EEE
N5boost6detail18sp_counted_impl_pdIPNS_2io18basic_altstringbufIcNSt3__111char_traitsIcEENS4_9allocatorIcEEEENS2_22basic_oaltstringstreamIcS6_S8_E5No_OpEEE
N5boost6detail15sp_counted_baseE
N5boost2io22basic_oaltstringstreamIcNSt3__111char_traitsIcEENS2_9allocatorIcEEE5No_OpE
N5boost16exception_detail10clone_implINS0_19error_info_injectorINS_2io12too_few_argsEEEEE
N5boost16exception_detail19error_info_injectorINS_2io12too_few_argsEEE
N5boost2io12too_few_argsE
N6quasar6Bitmap21CoordinatesOutOfRangeE
N6quasar6BitmapE
N6quasar12BitmapLoaderE
N6quasar16BitmapLoaderImplE
N6quasar15MappedPgmBitmapE
NSt3__120__shared_ptr_pointerIPN6quasar15MappedPgmBitmapENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN6quasar15MappedPgmBitmapEEE
N6quasar3G2PE
N4utf815not_enough_roomE
N4utf89exceptionE
N4utf812invalid_utf8E
N4utf818invalid_code_pointE
N6quasar13QuasarG2PBaseE
NSt3__111__end_stateIcEE
NSt3__16__nodeIcEE
NSt3__120__shared_ptr_pointerIPNS_13__empty_stateIcEENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteINS_13__empty_stateIcEEEE
NSt3__113__empty_stateIcEE
NSt3__116__owns_one_stateIcEE
NSt3__115__has_one_stateIcEE
NSt3__110__l_anchorIcEE
NSt3__110__r_anchorIcEE
NSt3__115__word_boundaryIcNS_12regex_traitsIcEEEE
NSt3__111__lookaheadIcNS_12regex_traitsIcEEEE
NSt3__123__match_any_but_newlineIcEE
NSt3__118__match_char_icaseIcNS_12regex_traitsIcEEEE
NSt3__120__match_char_collateIcNS_12regex_traitsIcEEEE
NSt3__112__match_charIcEE
NSt3__116__back_ref_icaseIcNS_12regex_traitsIcEEEE
NSt3__118__back_ref_collateIcNS_12regex_traitsIcEEEE
NSt3__110__back_refIcEE
NSt3__120__bracket_expressionIcNS_12regex_traitsIcEEEE
NSt3__128__begin_marked_subexpressionIcEE
NSt3__126__end_marked_subexpressionIcEE
NSt3__16__loopIcEE
NSt3__117__owns_two_statesIcEE
NSt3__117__repeat_one_loopIcEE
NSt3__111__alternateIcEE
NSt3__121__empty_non_own_stateIcEE
NSt3__111__match_anyIcEE
N6quasar16PhonetisaurusG2PE
NSt3__120__shared_ptr_emplaceI13PhonetisaurusNS_9allocatorIS1_EEEE
N6quasar7PDecG2PE
N5kaldi6quasar21TranslationBeamSearchINS0_19TorchEncoderDecoderEEE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar10PhraseBookENS_9allocatorIS3_EEEE
N3fst31BackoffDeterministicOnDemandFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_3FstIS4_EEEE
N3fst13SortedMatcherINS_3FstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEE
NSt3__120__shared_ptr_emplaceIN3fst14BackoffArcInfoENS_9allocatorIS2_EEEE
N3fst9VectorFstINS_6ArcTplINS_16LatticeWeightTplIfEEEENS_11VectorStateIS4_NSt3__19allocatorIS4_EEEEEE
N3fst13VectorFstImplINS_11VectorStateINS_6ArcTplINS_16LatticeWeightTplIfEEEENSt3__19allocatorIS5_EEEEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_6ArcTplINS_16LatticeWeightTplIfEEEENSt3__19allocatorIS5_EEEEEE
N3fst7FstImplINS_6ArcTplINS_16LatticeWeightTplIfEEEEEE
N3fst9QueueBaseIiEE
N3fst8SccQueueIiNS_9QueueBaseIiEEEE
N3fst14DeterminizeFstINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEE
N3fst22DeterminizeFstImplBaseINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEE
N3fst13StateIteratorINS_14DeterminizeFstINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEEEE
N6quasar16CommandTransformE
N6quasar23AllCapsCommandTransformE
N6quasar25AllCapsOnCommandTransformE
N6quasar19CapCommandTransformE
N6quasar22CapsOnCommandTransformE
N6quasar23CapsOffCommandTransformE
N6quasar22NoCapsCommandTransformE
N6quasar24NoCapsOnCommandTransformE
N6quasar23NoSpaceCommandTransformE
N6quasar25NoSpaceOnCommandTransformE
N6quasar26NoSpaceOffCommandTransformE
N6quasar23NewLineCommandTransformE
N6quasar28NewParagraphCommandTransformE
N6quasar31PeriodParagraphCommandTransformE
N6quasar22TabKeyCommandTransformE
N6quasar28NoBreakSpaceCommandTransformE
N6quasar24SpaceBarCommandTransformE
N6quasar25BackslashCommandTransformE
N6quasar26AllCapsOffCommandTransformE
N6quasar25NoCapsOffCommandTransformE
NSt3__120__shared_ptr_emplaceIN6quasar23AllCapsCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar25AllCapsOnCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar26AllCapsOffCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar19CapCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar22CapsOnCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar23CapsOffCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar22NoCapsCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar24NoCapsOnCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar25NoCapsOffCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar23NoSpaceCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar25NoSpaceOnCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar26NoSpaceOffCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar23NewLineCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar28NewParagraphCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar31PeriodParagraphCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar22TabKeyCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar28NoBreakSpaceCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar24SpaceBarCommandTransformENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar25BackslashCommandTransformENS_9allocatorIS2_EEEE
N6quasar21InverseTextNormalizerE
NSt3__120__shared_ptr_emplaceIN6quasar25URegularExpressionWrapperENS_9allocatorIS2_EEEE
NSt3__112codecvt_utf8IDiLm1114111ELNS_12codecvt_modeE0EEE
NSt3__120__shared_ptr_pointerIPN6quasar34SpaceApplyDefaultFstTokenTransformENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN6quasar34SpaceApplyDefaultFstTokenTransformEEE
NSt3__120__shared_ptr_pointerIPN6quasar39RewriteApplyCapitalizeFstTokenTransformENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN6quasar39RewriteApplyCapitalizeFstTokenTransformEEE
NSt3__120__shared_ptr_pointerIPN6quasar36RewriteApplyDefaultFstTokenTransformENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN6quasar36RewriteApplyDefaultFstTokenTransformEEE
NSt3__120__shared_ptr_pointerIPN6quasar24ComposeFstTokenTransformENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN6quasar24ComposeFstTokenTransformEEE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar10PrefixTreeINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEES9_EENS7_ISA_EEEE
N6quasar17FstTokenTransformE
N6quasar14TokenTransformIN3fst9VectorFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEENS1_11VectorStateIS6_NSt3__19allocatorIS6_EEEEEEEE
N6quasar24ComposeFstTokenTransformE
N6quasar34SpaceApplyDefaultFstTokenTransformE
N6quasar39RewriteApplyCapitalizeFstTokenTransformE
N6quasar36RewriteApplyDefaultFstTokenTransformE
N6quasar10TranslatorE
N6quasar17TranslatorFactoryE
NSt3__120__shared_ptr_emplaceIN6quasar21PDecTranslatorFactoryENS_9allocatorIS2_EEEE
@N6quasar11PDecOptionsE
N6quasar17TranslatorOptionsE
N6quasar19PDecTranslatorBlockE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar21TranslationBeamSearchINS2_19TorchEncoderDecoderEEENS_9allocatorIS5_EEEE
N5kaldi8CuMatrixIfEE
N5kaldi12CuVectorBaseIfEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_16LatticeWeightTplIfEEEENSt3__19allocatorIS6_EEEEEENS_10MutableFstIS6_EEEE
N3fst10MutableFstINS_6ArcTplINS_16LatticeWeightTplIfEEEEEE
N3fst15ArcIteratorBaseINS_6ArcTplINS_16LatticeWeightTplIfEEEEEE
NSt3__112codecvt_utf8IwLm1114111ELNS_12codecvt_modeE0EEE
N6quasar17PhraseBookOptionsE
N6quasar19PDecPhraseBookBlockE
N6quasar20PDecEngineBlockMixinE
N6quasar14PDecTranslatorE
N6quasar11OptionValueINSt3__112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEEEE
N6quasar23SharedPhraseBookOptionsE
N6quasar15PhraseBookBlockE
NSt3__120__shared_ptr_pointerIPN6quasar16SharedPhraseBookENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN6quasar16SharedPhraseBookEEE
N6quasar22SimpleTokenizerOptionsE
N6quasar20SimpleTokenizerBlockE
N6quasar25ConfiguredProcessingBlockINS_22SimpleTokenizerOptionsEEE
NSt3__111__end_stateIwEE
NSt3__16__nodeIwEE
NSt3__120__shared_ptr_pointerIPNS_13__empty_stateIwEENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteINS_13__empty_stateIwEEEE
NSt3__113__empty_stateIwEE
NSt3__116__owns_one_stateIwEE
NSt3__115__has_one_stateIwEE
NSt3__110__l_anchorIwEE
NSt3__110__r_anchorIwEE
NSt3__115__word_boundaryIwNS_12regex_traitsIwEEEE
NSt3__111__lookaheadIwNS_12regex_traitsIwEEEE
NSt3__123__match_any_but_newlineIwEE
NSt3__118__match_char_icaseIwNS_12regex_traitsIwEEEE
NSt3__120__match_char_collateIwNS_12regex_traitsIwEEEE
NSt3__112__match_charIwEE
NSt3__116__back_ref_icaseIwNS_12regex_traitsIwEEEE
NSt3__118__back_ref_collateIwNS_12regex_traitsIwEEEE
NSt3__110__back_refIwEE
NSt3__120__bracket_expressionIwNS_12regex_traitsIwEEEE
NSt3__128__begin_marked_subexpressionIwEE
NSt3__126__end_marked_subexpressionIwEE
NSt3__16__loopIwEE
NSt3__117__owns_two_statesIwEE
NSt3__117__repeat_one_loopIwEE
NSt3__111__alternateIwEE
NSt3__121__empty_non_own_stateIwEE
NSt3__111__match_anyIwEE
N6quasar28AlternativesProcessorOptionsE
N6quasar26AlternativesProcessorBlockE
N6quasar18InputHammerOptionsE
N6quasar16InputHammerBlockE
N6quasar20SentencePieceOptionsE
N6quasar18SentencePieceBlockE
NSt3__120__shared_ptr_emplaceIN13sentencepiece22SentencePieceProcessorENS_9allocatorIS2_EEEE
N6quasar25AmbiguityAnnotatorOptionsE
N6quasar23AmbiguityAnnotatorBlockE
N6quasar16RomanizerOptionsE
N6quasar14RomanizerBlockE
N6quasar25ConfiguredProcessingBlockINS_16RomanizerOptionsEEE
N6quasar21PDecTranslatorFactoryE
NSt3__120__shared_ptr_emplaceIN6quasar14PDecTranslatorENS_9allocatorIS2_EEEE
N6quasar15OptionValueBaseE
N6quasar11OptionsBaseE
N6quasar15ProcessingBlockE
N6quasar16ProcessingSourceE
N6quasar14ProcessingSinkE
N6quasar13MergerOptionsE
N6quasar11MergerBlockE
N6quasar25ConfiguredProcessingBlockINS_13MergerOptionsEEE
N6quasar15ProcessingGraphE
N6quasar21LinearProcessingGraphE
N6quasar23DirectedProcessingGraphE
N6quasar25ConfiguredProcessingBlockINS_17TranslatorOptionsEEE
N6quasar11OptionValueIiEE
N6quasar11OptionValueIdEE
N6quasar11OptionValueIbEE
N6quasar25ConfiguredProcessingBlockINS_17PhraseBookOptionsEEE
N6quasar25ConfiguredProcessingBlockINS_28AlternativesProcessorOptionsEEE
N6quasar25ConfiguredProcessingBlockINS_25AmbiguityAnnotatorOptionsEEE
NSt3__118codecvt_utf8_utf16IwLm1114111ELNS_12codecvt_modeE0EEE
N6quasar25ConfiguredProcessingBlockINS_23SharedPhraseBookOptionsEEE
N6quasar25ConfiguredProcessingBlockINS_18InputHammerOptionsEEE
N6quasar25ConfiguredProcessingBlockINS_20SentencePieceOptionsEEE
NSt3__120__shared_ptr_emplaceIN6quasar14ProcessingSinkENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar16ProcessingSourceENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_pointerIPN6quasar15ProcessingBlockENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN6quasar15ProcessingBlockEEE
N6quasar11SyncDecoderE
NSt3__120__shared_ptr_emplaceIN6quasar26KeywordSpottingSyncDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar11ClassLmPlugENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceINS_6vectorINS1_INS1_IN6quasar5TokenENS_9allocatorIS3_EEEENS4_IS6_EEEENS4_IS8_EEEENS4_ISA_EEEE
N6quasar9DecodableE
NSt3__120__shared_ptr_emplaceIN6quasar36OnlineDecodableMatrixScaledDecodableENS_9allocatorIS2_EEEE
N6quasar36OnlineDecodableMatrixScaledDecodableE
NSt3__120__shared_ptr_pointerIPN5kaldi27OnlineDecodableMatrixScaledENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN5kaldi27OnlineDecodableMatrixScaledEEE
NSt3__120__shared_ptr_emplaceIN6quasar42OnlineDecodableMatrixScaledMappedDecodableENS_9allocatorIS2_EEEE
N6quasar42OnlineDecodableMatrixScaledMappedDecodableE
NSt3__120__shared_ptr_emplaceIN5kaldi33OnlineDecodableMatrixScaledMappedENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar44OnlineDecodableMatrixScaledMappedTmDecodableENS_9allocatorIS2_EEEE
N6quasar44OnlineDecodableMatrixScaledMappedTmDecodableE
NSt3__120__shared_ptr_emplaceIN5kaldi35OnlineDecodableMatrixScaledMappedTmENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar39OnlineDecodableIdenticalMatrixDecodableENS_9allocatorIS2_EEEE
N6quasar39OnlineDecodableIdenticalMatrixDecodableE
NSt3__120__shared_ptr_pointerIPN5kaldi30OnlineDecodableIdenticalMatrixENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN5kaldi30OnlineDecodableIdenticalMatrixEEE
NSt3__120__shared_ptr_emplaceIN6quasar33OnlineDecodableNnet1LazyDecodableENS_9allocatorIS2_EEEE
N6quasar33OnlineDecodableNnet1LazyDecodableE
NSt3__120__shared_ptr_emplaceIN5kaldi24OnlineDecodableNnet1LazyENS_9allocatorIS2_EEEE
N6quasar7DecoderE
N3fst18MutableArcIteratorINS_9VectorFstINS_6ArcTplINS_16LatticeWeightTplIfEEEENS_11VectorStateIS5_NSt3__19allocatorIS5_EEEEEEEE
N3fst22MutableArcIteratorBaseINS_6ArcTplINS_16LatticeWeightTplIfEEEEEE
N3fst18ShortestFirstQueueIiNS_18StateWeightCompareIiNS_11NaturalLessINS_16LatticeWeightTplIfEEEEEELb0EEE
N3fst9FifoQueueIiEE
N3fst9VectorFstINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENS_11VectorStateIS6_NSt3__19allocatorIS6_EEEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENSt3__19allocatorIS8_EEEEEENS_10MutableFstIS8_EEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENSt3__19allocatorIS7_EEEEEE
N3fst9ImplToFstINS_22DeterminizeFstImplBaseINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEENS_3FstIS7_EEEE
N3fst18DeterminizeFsaImplINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENS_20DefaultCommonDivisorIS4_EENS_24DefaultDeterminizeFilterIS6_EENS_28DefaultDeterminizeStateTableIS6_NS_18IntegerFilterStateIaEEEEEE
N3fst9CacheImplINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEE
N3fst13CacheBaseImplINS_10CacheStateINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENSt3__19allocatorIS7_EEEENS_17DefaultCacheStoreIS7_EEEE
N3fst18CacheStateIteratorINS_14DeterminizeFstINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEEEE
N3fst17StateIteratorBaseINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEE
NSt3__120__shared_ptr_emplaceINS_6vectorINS1_IN6quasar5TokenENS_9allocatorIS3_EEEENS4_IS6_EEEENS4_IS8_EEEE
NSt3__120__shared_ptr_emplaceINS_6vectorIdNS_9allocatorIdEEEENS2_IS4_EEEE
NSt3__117bad_function_callE
NSt3__120__shared_ptr_emplaceIN6quasar31OnlineLatticeBiglmFasterDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar34OnlineLatticeBiglmLmeFasterDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar34OnlineLatticeBiglmLmeFasterDecoder23LmeCreationDependenciesENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar15SymbolTableListENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar29OnlineLatticeRescalingDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar33OnlineLatticeWordAlignmentDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar24OnlineLmRescoringDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar31OnlineLatticeRealignmentDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar19ErrorBlamingDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar30OnlineLatticeConfidenceDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar20LatticeFasterDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar28OnlineKeywordSpottingDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar18OnlineSeevaDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar22OnlineSeevaStepDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar27OnlineSeevaStepBigLmDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar18SeevaGreedyDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar31ConfusionNetworkCombinerDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar20PhoneticMatchDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar19FingerprintDetectorENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar27OnlineAudioAnalyticsDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar17WatermarkDetectorENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar21AudioAnalyticsDecoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar19LatticeRnnMitigatorENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar14HwcnConfidenceENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar18WatermarkDetector2ENS_9allocatorIS2_EEEE
N6quasar18AMKeywordDetectionE
N6quasar11RecogResultE
N6quasar21RecogResultStreamBaseE
N6quasar31ConfusionNetworkCombinerDecoderE
N6quasar19ErrorBlamingDecoderE
N3fst3FstINS_6ArcTplINS_16LatticeWeightTplIfEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEE4LinkEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEENS_11VectorStateIS7_NSt3__19allocatorIS7_EEEEEEEE
N3fst22MutableArcIteratorBaseINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEE
NSt3__120__shared_ptr_emplaceIN5kaldi16WordBoundaryInfoENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar10LexiconFstENS_9allocatorIS3_EEEE
N3fst13StateIteratorINS_10ReplaceFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_24DefaultReplaceStateTableIS5_lEENS_17DefaultCacheStoreIS5_EEEEEE
N3fst17ReplaceFstMatcherINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_24DefaultReplaceStateTableIS4_lEENS_17DefaultCacheStoreIS4_EEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_11ArcIteratorINS_10ReplaceFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_24DefaultReplaceStateTableIS7_lEENS_17DefaultCacheStoreIS7_EEEEEEE4LinkEEE
NSt3__120__shared_ptr_emplaceIN5kaldi21TrainingGraphCompilerENS_9allocatorIS2_EEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_16LatticeWeightTplIfEEEENSt3__19allocatorIS6_EEEEEENS_10MutableFstIS6_EEEE
NSt3__120__shared_ptr_emplaceIN3fst9VectorFstINS1_6ArcTplINS1_23CompactLatticeWeightTplINS1_16LatticeWeightTplIfEEiEEEENS1_11VectorStateIS8_NS_9allocatorIS8_EEEEEENSA_ISD_EEEE
N6quasar19FingerprintDetectorE
N6quasar14HwcnConfidenceE
NSt3__120__shared_ptr_emplaceIN6marisa4TrieENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi6MatrixIfEENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar22WlatArcFeWordEmbeddingENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar14WlatArcFeIsLmeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar14WlatArcFeLmeIdENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar14WlatArcFeIsSilENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar18WlatArcFeNumPhonesENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar29WlatArcFeAcousticCostUnpushedENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar19WlatArcFeInBestPathENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar21WlatArcFeAcousticCostENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar18WlatArcFeGraphCostENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar18WlatArcFeNumFramesENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar21WlatArcFeLogPosteriorENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar21WlatArcFeLinPosteriorENS_9allocatorIS2_EEEE
N6quasar20LatticeFasterDecoderE
N3fst10MemoryPoolINS_8DfsStateINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEE
N3fst10MutableFstINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEE
N3fst13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENSt3__19allocatorIS7_EEEEEE
N3fst7FstImplINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEE
N3fst15ArcIteratorBaseINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEE
N6quasar19LatticeRnnMitigatorE
NSt3__120__shared_ptr_emplaceIN6quasar20WlatArcFeBagOfPhonesENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar16WlatArcFeKeywordENS_9allocatorIS2_EEEE
N6quasar28OnlineKeywordSpottingDecoderE
N6quasar18OnlineSeevaDecoderE
N5kaldi6quasar26SeevaStreamInferenceConfigE
N5kaldi6quasar20SeevaInferenceConfigE
NSt3__113basic_fstreamIcNS_11char_traitsIcEEEE
N6quasar22OnlineSeevaStepDecoderE
N5kaldi6quasar24SeevaStepInferenceConfigE
N6quasar27OnlineSeevaStepBigLmDecoderE
N5kaldi6quasar26SeevaStepLmInferenceConfigE
N5kaldi12CuMatrixBaseIfEE
NSt3__120__shared_ptr_emplaceIN3fst31BackoffDeterministicOnDemandFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEENS1_3FstIS6_EEEENS_9allocatorIS9_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar31DeterministicOnDemandFstCreatorIN3fst6ArcTplINS4_17TropicalWeightTplIfEEEEEENS_9allocatorIS9_EEEE
N3fst7FstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N3fst3FstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N3fst10ReplaceFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_24DefaultReplaceStateTableIS4_lEENS_17DefaultCacheStoreIS4_EEEE
N3fst9ImplToFstINS_14ReplaceFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_24DefaultReplaceStateTableIS5_lEENS_17DefaultCacheStoreIS5_EEEENS_3FstIS5_EEEE
N3fst18CacheStateIteratorINS_10ReplaceFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_24DefaultReplaceStateTableIS5_lEENS_17DefaultCacheStoreIS5_EEEEEE
N3fst13SortedMatcherINS_10ReplaceFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_24DefaultReplaceStateTableIS5_lEENS_17DefaultCacheStoreIS5_EEEEEE
N3fst10MemoryPoolINS_11ArcIteratorINS_10ReplaceFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_24DefaultReplaceStateTableIS6_lEENS_17DefaultCacheStoreIS6_EEEEEEEE
N5kaldi6quasar27NeuralNgramDeterministicFstIN3fst6ArcTplINS2_17TropicalWeightTplIfEEEEEE
NSt3__120__shared_ptr_emplaceINS_6vectorINS_4pairIPN3fst24DeterministicOnDemandFstINS3_6ArcTplINS3_17TropicalWeightTplIfEEEEEEfEENS_9allocatorISB_EEEENSC_ISE_EEEE
N3fst35InterpolateDeterministicOnDemandFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
NSt3__120__shared_ptr_emplaceIN3fst13InterpArcInfoENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN3fst31ComposeDeterministicOnDemandFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEENS1_24DeterministicOnDemandFstIS6_EES8_EENS_9allocatorIS9_EEEE
NSt3__120__shared_ptr_emplaceIN3fst29CacheDeterministicOnDemandFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEENS1_24DeterministicOnDemandFstIS6_EEEENS_9allocatorIS9_EEEE
N6quasar18SeevaGreedyDecoderE
N6quasar31OnlineLatticeBiglmFasterDecoderE
N3fst10MutableFstINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEE
NSt3__110__function6__funcIZN6quasar31OnlineLatticeBiglmFasterDecoder26doEverythingWithRawLatticeERNS2_15DecoderPassDataERKNS_10shared_ptrINS2_18DecoderChainOutputEEERKNS6_INS2_17SpeechRequestDataEEERKN5kaldi6quasar37OnlineLatticeBiglmFasterDecoderConfigERKNS_6atomicIbEEE3$_0NS_9allocatorISO_EEFbvEEE
ZN6quasar31OnlineLatticeBiglmFasterDecoder26doEverythingWithRawLatticeERNS_15DecoderPassDataERKNSt3__110shared_ptrINS_18DecoderChainOutputEEERKNS4_INS_17SpeechRequestDataEEERKN5kaldi6quasar37OnlineLatticeBiglmFasterDecoderConfigERKNS3_6atomicIbEEE3$_0
NSt3__120__shared_ptr_emplaceIN6quasar23StateAccessRecordingFstENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar21LRStreamingConfidenceENS_9allocatorIS2_EEEE
N3fst14ReplaceFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_24DefaultReplaceStateTableIS4_lEENS_17DefaultCacheStoreIS4_EEEE
N3fst13CacheBaseImplINS_10CacheStateINS_6ArcTplINS_17TropicalWeightTplIfEEEENSt3__19allocatorIS5_EEEENS_17DefaultCacheStoreIS5_EEEE
N3fst29CacheDeterministicOnDemandFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_24DeterministicOnDemandFstIS4_EEEE
N5kaldi6quasar31RecurrentNeuralDeterministicFstIN3fst6ArcTplINS2_17TropicalWeightTplIfEEEEEE
NSt3__120__shared_ptr_emplaceIN6quasar13EagerDecisionENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar31OnlineLatticeBiglmFasterDecoder23LatticeGenerationOutputENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN3fst35InterpolateDeterministicOnDemandFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEEEENS_9allocatorIS7_EEEE
NSt3__120__shared_ptr_emplaceIN3fst7ArcInfoENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN3fst35LeftContextDeterministicOnDemandFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEEEENS_9allocatorIS7_EEEE
N3fst35LeftContextDeterministicOnDemandFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N3fst31ComposeDeterministicOnDemandFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_24DeterministicOnDemandFstIS4_EES6_EE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar31OnlineLatticeBiglmFasterDecoderIN3fst3FstINS4_6ArcTplINS4_17TropicalWeightTplIfEEEEEENS4_29CacheDeterministicOnDemandFstIS9_NS4_24DeterministicOnDemandFstIS9_EEEEEENS_9allocatorISF_EEEE
N5kaldi6quasar31OnlineLatticeBiglmFasterDecoderIN3fst3FstINS2_6ArcTplINS2_17TropicalWeightTplIfEEEEEENS2_29CacheDeterministicOnDemandFstIS7_NS2_24DeterministicOnDemandFstIS7_EEEEEE
N5kaldi6quasar34LatticeBiglmFasterTraceBackDecoderIN3fst3FstINS2_6ArcTplINS2_17TropicalWeightTplIfEEEEEENS2_29CacheDeterministicOnDemandFstIS7_NS2_24DeterministicOnDemandFstIS7_EEEEEE
NSt3__120__shared_ptr_emplaceIN6quasar31OnlineLatticeBiglmFasterDecoder24LatticeGenerationContextENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar15DecoderPassDataENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar18DecoderChainOutputENS_9allocatorIS2_EEEE
N6quasar34OnlineLatticeBiglmLmeFasterDecoderE
NSt3__120__shared_ptr_emplaceIN6quasar7LmeDataENS_9allocatorIS2_EEEE
N6quasar30OnlineLatticeConfidenceDecoderE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar8WordConfENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN3fst9VectorFstINS1_6ArcTplINS1_17TropicalWeightTplIfEEEENS1_11VectorStateIS6_NS_9allocatorIS6_EEEEEENS8_ISB_EEEE
NSt3__120__shared_ptr_emplaceIN3fst9VectorFstINS1_6ArcTplINS1_16LatticeWeightTplIfEEEENS1_11VectorStateIS6_NS_9allocatorIS6_EEEEEENS8_ISB_EEEE
N6quasar29OnlineLatticeRescalingDecoderE
N6quasar31OnlineLatticeRealignmentDecoderE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENSt3__19allocatorIS8_EEEEEENS_10MutableFstIS8_EEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENSt3__19allocatorIS8_EEEEEENS_10MutableFstIS8_EEEE
N3fst11ExpandedFstINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEE
N3fst3FstINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEE
N3fst10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEEE4LinkEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENS_11VectorStateIS7_NSt3__19allocatorIS7_EEEEEEEE
N3fst22MutableArcIteratorBaseINS_10ReverseArcINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEE
N3fst9ImplToFstINS_18ComposeFstImplBaseINS_6ArcTplINS_16LatticeWeightTplIfEEEENS_17DefaultCacheStoreIS5_EEEENS_3FstIS5_EEEE
N3fst13SortedMatcherINS_3FstINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEE
N3fst11MatcherBaseINS_6ArcTplINS_16LatticeWeightTplIfEEEEEE
N3fst10MemoryPoolINS_11ArcIteratorINS_3FstINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_11ArcIteratorINS_3FstINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEEEE4LinkEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENS_21SequenceComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst13CacheBaseImplINS_10CacheStateINS_6ArcTplINS_16LatticeWeightTplIfEEEENSt3__19allocatorIS5_EEEENS_17DefaultCacheStoreIS5_EEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENS_22LookAheadComposeFilterINS_24AltSequenceComposeFilterINS_16LookAheadMatcherINS_3FstIS5_EEEESC_EESC_SC_LNS_9MatchTypeE2EEENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSI_EENS_21CompactHashStateTableISK_NS_11ComposeHashISK_EEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENS_22LookAheadComposeFilterINS_21SequenceComposeFilterINS_16LookAheadMatcherINS_3FstIS5_EEEESC_EESC_SC_LNS_9MatchTypeE2EEENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSI_EENS_21CompactHashStateTableISK_NS_11ComposeHashISK_EEEEEEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENS_22LookAheadComposeFilterINS_21SequenceComposeFilterINS_16LookAheadMatcherINS_3FstIS5_EEEESC_EESC_SC_LNS_9MatchTypeE2EEENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSI_EENS_21CompactHashStateTableISK_NS_11ComposeHashISK_EEEEEEEE
N3fst17StateIteratorBaseINS_6ArcTplINS_16LatticeWeightTplIfEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENS_17NullComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENS_18MatchComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENS_18MatchComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N6quasar33OnlineLatticeWordAlignmentDecoderE
N6quasar24OnlineLmRescoringDecoderE
N6quasar20PhoneticMatchDecoderE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar13SymbolDecoderINS2_8PhonomapEEENS_9allocatorIS5_EEEE
N3fst10ComposeFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_17DefaultCacheStoreIS4_EEEE
N3fst9ImplToFstINS_18ComposeFstImplBaseINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_17DefaultCacheStoreIS5_EEEENS_3FstIS5_EEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_11ArcIteratorINS_3FstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEEE4LinkEEE
N6quasar27OnlineAudioAnalyticsDecoderE
@N6quasar17WatermarkDetectorE
N6quasar21AudioAnalyticsDecoderE
N6quasar18WatermarkDetector2E
N6quasar26KeywordSpottingSyncDecoderE
NSt3__114default_deleteIN3fst11SymbolTableEEE
NSt3__120__shared_ptr_emplaceIN5kaldi17LatticeScoreCacheENS_9allocatorIS2_EEEE
N6quasar10EndPointerE
N6quasar15BasicEndPointerE
N6quasar14NnetEndPointerE
N6quasar16FeatureExtractorE
N6quasar11OnlineCmnFeE
N6quasar12OnlineCmvnFeE
N6quasar13OnlineDeltaFeE
N6quasar13OnlineFbankFeE
N6quasar22OnlineFbankWithPitchFeE
N6quasar31OnlineFbankWithAudioAnalyticsFeE
N6quasar11OnlineLdaFeE
N6quasar12OnlineMfccFeE
N6quasar19OnlineNnetForwardFeE
N6quasar23OnlineNnetForwardSkipFeE
N6quasar14OnlineSpliceFeE
N6quasar23OnlineStaticTransformFeE
N6quasar18OnlineCacheInputFeE
N6quasar25OnlineComputeAheadInputFeE
N6quasar17OnlineSubsampleFeE
NSt3__120__shared_ptr_emplaceIN5kaldi17OnlineSubsampleFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar11OnlineCmnFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar12OnlineCmvnFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar13OnlineDeltaFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar13OnlineFbankFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar22OnlineFbankWithPitchFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar11OnlineLdaFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar12OnlineMfccFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar19OnlineNnetForwardFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar23OnlineNnetForwardSkipFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar14OnlineSpliceFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar17OnlineSubsampleFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar23OnlineStaticTransformFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar25OnlineComputeAheadInputFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar31OnlineFbankWithAudioAnalyticsFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar14OnlineAppendFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi14OnlineCmnInputENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi15OnlineCmvnInputENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi16OnlineDeltaInputENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi5FbankENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi13OnlineFeInputINS1_5FbankEEENS_9allocatorIS4_EEEE
N5kaldi13OnlineFeInputINS_5FbankEEE
NSt3__120__shared_ptr_emplaceIN5kaldi14FbankWithPitchENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi13OnlineFeInputINS1_14FbankWithPitchEEENS_9allocatorIS4_EEEE
N5kaldi13OnlineFeInputINS_14FbankWithPitchEEE
NSt3__120__shared_ptr_emplaceIN5kaldi23FbankWithAudioAnalyticsENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi13OnlineFeInputINS1_23FbankWithAudioAnalyticsEEENS_9allocatorIS4_EEEE
N5kaldi13OnlineFeInputINS_23FbankWithAudioAnalyticsEEE
NSt3__120__shared_ptr_emplaceIN5kaldi14OnlineLdaInputENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi4MfccENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi13OnlineFeInputINS1_4MfccEEENS_9allocatorIS4_EEEE
N5kaldi13OnlineFeInputINS_4MfccEEE
NSt3__120__shared_ptr_emplaceIN5kaldi5nnet18PdfPriorENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi22OnlineNnetForwardInputENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi29OnlineNnetForwardSkippedInputENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi17OnlineSpliceInputENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi20OnlineTransformInputENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi16OnlineCacheInputENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar21ComputeAheadFeatInputENS_9allocatorIS2_EEEE
N6quasar21ComputeAheadFeatInputE
N3fst17VectorFstBaseImplINS_11VectorStateINS_6ArcTplINS_17TropicalWeightTplIfEEEENSt3__19allocatorIS5_EEEEEE
NSt3__120__shared_ptr_emplaceIN3fst14StringCompilerINS1_6ArcTplINS1_17TropicalWeightTplIfEEEEEENS_9allocatorIS7_EEEE
N3fst11MatcherBaseINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_21SequenceComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_23PushLabelsComposeFilterINS_24PushWeightsComposeFilterINS_22LookAheadComposeFilterINS_24AltSequenceComposeFilterINS_16LookAheadMatcherINS_3FstIS5_EEEESE_EESE_SE_LNS_9MatchTypeE2EEESE_SE_LSG_2EEESE_SE_LSG_2EEENS_24GenericComposeStateTableIS5_NS_15PairFilterStateINSL_INS_18IntegerFilterStateIaEENS_17WeightFilterStateIS4_EEEENSM_IiEEEENS_24DefaultComposeStateTupleIiSS_EENS_21CompactHashStateTableISU_NS_11ComposeHashISU_EEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_23PushLabelsComposeFilterINS_24PushWeightsComposeFilterINS_22LookAheadComposeFilterINS_21SequenceComposeFilterINS_16LookAheadMatcherINS_3FstIS5_EEEESE_EESE_SE_LNS_9MatchTypeE2EEESE_SE_LSG_2EEESE_SE_LSG_2EEENS_24GenericComposeStateTableIS5_NS_15PairFilterStateINSL_INS_18IntegerFilterStateIaEENS_17WeightFilterStateIS4_EEEENSM_IiEEEENS_24DefaultComposeStateTupleIiSS_EENS_21CompactHashStateTableISU_NS_11ComposeHashISU_EEEEEEEE
N3fst13StateIteratorINS_10ComposeFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_17DefaultCacheStoreIS5_EEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_17NullComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_17NullComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_24AltSequenceComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_18MatchComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst14DeterminizeFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N3fst9ImplToFstINS_22DeterminizeFstImplBaseINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_3FstIS5_EEEE
N3fst9ArcMapFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE3EEENS_14ToGallicMapperIS4_LS6_3EEEEE
N3fst3FstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEEEE
N3fst13CacheBaseImplINS_10CacheStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEENSt3__19allocatorIS8_EEEENS_17DefaultCacheStoreIS8_EEEE
N3fst10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEEEEE4LinkEEE
N3fst13StateIteratorINS_9ArcMapFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE3EEENS_14ToGallicMapperIS5_LS7_3EEEEEEE
N3fst17StateIteratorBaseINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEEEE
N3fst14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEENSt3__19allocatorIS9_EEEEEENS_10MutableFstIS9_EEEE
N3fst11ExpandedFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N3fst3FstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEEE4LinkEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEENSt3__19allocatorISB_EEEEEENS_10MutableFstISB_EEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEENSt3__19allocatorISB_EEEEEENS_10MutableFstISB_EEEE
N3fst11ExpandedFstINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEEEE
N3fst10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEEEEE4LinkEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEENS_11VectorStateISA_NSt3__19allocatorISA_EEEEEEEE
N3fst9CacheImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N3fst13StateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEENS_12GallicFactorIiS5_LS7_0EEEEEEE
N6quasar13WordPronCacheE
N6quasar7LmeDataE
NSt3__120__shared_ptr_pointerIPN3fst11SymbolTableENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
N6quasar14LmeDataFactoryE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar7LexiconENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar6LmeFstENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN3fst11SymbolTableENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_pointerIPN3fst10MappedFileENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN3fst10MappedFileEEE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar12ConstLexiconENS_9allocatorIS3_EEEE
NSt3__110__function6__funcINS_6__bindIRFbRKN6quasar18LmeDataFactoryBase4WordEiEJRKNS_12placeholders4__phILi1EEERiEEENS_9allocatorISG_EEFbS7_EEE
NSt3__110__function6__baseIFbRKN6quasar18LmeDataFactoryBase4WordEEEE
NSt3__16__bindIRFbRKN6quasar18LmeDataFactoryBase4WordEiEJRKNS_12placeholders4__phILi1EEERiEEE
NSt3__118__weak_result_typeIPFbRKN6quasar18LmeDataFactoryBase4WordEiEEE
NSt3__115binary_functionIRKN6quasar18LmeDataFactoryBase4WordEibEE
N6quasar7FeatureE
N6quasar17IntToFloatFeatureE
N6quasar19SamplingRateFeatureE
N6quasar15LocationFeatureE
N6quasar14OnlineAppendFeE
NSt3__120__shared_ptr_emplaceIN6quasar19SamplingRateFeatureENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar15LocationFeatureENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi17OnlineAppendInputENS_9allocatorIS2_EEEE
N6quasar24OfflineRecogResultStreamE
N6quasar24ConfusionNetworkCombinerE
N6quasar14ResultCombinerE
N6quasar21RankingResultCombinerE
N6quasar22ResultStreamStabilizerE
NSt3__120__shared_ptr_emplaceIN6quasar15SyncRecogResultENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar20SyncRecogAudioBufferENS_9allocatorIS2_EEEE
N6quasar16SpeechRecognizerE
N6quasar16RecogAudioBufferE
N6quasar16MultiAudioBufferE
NSt3__120__shared_ptr_emplaceINS_5mutexENS_9allocatorIS1_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi5nnet14NnetENS_9allocatorIS3_EEEE
NSt3__115basic_stringbufIcNS_11char_traitsIcEENS_9allocatorIcEEEE
NSt3__120__shared_ptr_pointerIPN6quasar26DecoderChainPersistentDataENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN6quasar26DecoderChainPersistentDataEEE
NSt3__118basic_stringstreamIcNS_11char_traitsIcEENS_9allocatorIcEEEE
NSt3__120__shared_ptr_emplaceIN6quasar16SimpleThreadPoolENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar9GeographyENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar21ConfusionNetworkCacheENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar23SpeechRequestResultDataENS_9allocatorIS2_EEEE
NSt3__110__function6__funcINS_6__bindIMN6quasar16SpeechRecognizerEFbvEJPS4_EEENS_9allocatorIS8_EEFbvEEE
NSt3__110__function6__baseIFbvEEE
NSt3__16__bindIMN6quasar16SpeechRecognizerEFbvEJPS2_EEE
NSt3__118__weak_result_typeIMN6quasar16SpeechRecognizerEFbvEEE
NSt3__114unary_functionIPN6quasar16SpeechRecognizerEbEE
NSt3__120__shared_ptr_emplaceIN6quasar19EndPointModelConfigENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar11EagerConfigENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar20RecognizerComponentsINS1_7DecoderEEENS_9allocatorIS4_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar18RecogRequestFilterENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar31SilencePosteriorGeneratorConfigENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi5TimerENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar17SpeechRequestDataENS_9allocatorIS2_EEEE
NSt3__110__function6__funcINS_6__bindIMN6quasar16SpeechRecognizerEFvvEJPS4_EEENS_9allocatorIS8_EEFvvEEE
NSt3__110__function6__baseIFvvEEE
NSt3__16__bindIMN6quasar16SpeechRecognizerEFvvEJPS2_EEE
NSt3__118__weak_result_typeIMN6quasar16SpeechRecognizerEFvvEEE
NSt3__114unary_functionIPN6quasar16SpeechRecognizerEvEE
NSt3__120__shared_ptr_emplaceIN5kaldi20OnlineBufferingInputENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar18OnlineCacheInputFeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN5kaldi19OnlineFeatureMatrixENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar22ResultStreamStabilizerENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar5PTreeENS_9allocatorIS2_EEEE
N5boost16exception_detail10clone_implINS0_19error_info_injectorISt12length_errorEEEE
N5boost16exception_detail19error_info_injectorISt12length_errorEE
N5boost16exception_detail10clone_baseE
N6quasar20RecogAudioBufferBaseE
N6quasar20SpeechRecognizerBaseE
N6quasar18LmeDataFactoryBaseE
NSt3__120__shared_ptr_emplaceIN6quasar25ConcreteSpeechRequestDataENS_9allocatorIS2_EEEE
N6quasar23StateAccessRecordingFstE
N6quasar19StreamingConfidenceE
N6quasar21LRStreamingConfidenceE
N6quasar27PrefixSearchableSymbolTableE
N6quasar9SymbolMap19SymbolMapMarisaImplE
NSt3__120__shared_ptr_emplaceIN6quasar9SymbolMap19SymbolMapQuasarImplENS_9allocatorIS3_EEEE
N6quasar9SymbolMap19SymbolMapQuasarImplE
NSt3__120__shared_ptr_pointerIPN6quasar9SymbolMap19SymbolMapMarisaImplENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIN6quasar9SymbolMap19SymbolMapMarisaImplEEE
N6quasar20SyncRecogAudioBufferE
N6quasar20SyncSpeechRecognizerE
NSt3__120__shared_ptr_emplaceIN6quasar20RecognizerComponentsINS1_11SyncDecoderEEENS_9allocatorIS4_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar11SessionDataENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar9GeoRegionENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar17RegionsBitmapDataENS_9allocatorIS2_EEEE
N6quasar9GeoRegionE
NSt3__120__shared_ptr_emplaceIN6quasar12BitmapRegionENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar12CircleRegionENS_9allocatorIS2_EEEE
N6quasar16WlatArcFeKeywordE
N6quasar23WlatArcFeatureExtractorE
N6quasar14WlatArcFeIsLmeE
N6quasar14WlatArcFeLmeIdE
N6quasar14WlatArcFeIsSilE
N6quasar18WlatArcFeNumPhonesE
N6quasar29WlatArcFeAcousticCostUnpushedE
N6quasar19WlatArcFeInBestPathE
N6quasar21WlatArcFeAcousticCostE
N6quasar18WlatArcFeGraphCostE
N6quasar18WlatArcFeNumFramesE
N6quasar21WlatArcFeLogPosteriorE
N6quasar21WlatArcFeLinPosteriorE
N6quasar20WlatArcFeBagOfPhonesE
N6quasar22WlatArcFeWordEmbeddingE
N6quasar9SanitizerE
NSt3__120__shared_ptr_emplaceIN5kaldi6quasar5VocabENS_9allocatorIS3_EEEE
N3fst10MemoryPoolINS_11ArcIteratorINS_3FstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_21SequenceComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N6quasar13CommandTaggerE
NSt3__120__shared_ptr_emplaceIN6quasar18QuasarTextProcImplENS_9allocatorIS2_EEEE
N6quasar18QuasarTextProcImplE
N6quasar14QuasarTextProcE
NSt3__120__shared_ptr_emplaceIN6quasar21InverseTextNormalizerENS_9allocatorIS2_EEEE
N6quasar8TextProcE
p}?N6quasar17DerivedEnumeratorE
N6quasar17DerivedEnumerator9AlgorithmE
N6quasar15EnLikeAlgorithmE
N6quasar15ZhLikeAlgorithmE
N6quasar20ExhaustiveEnumeratorE
N6quasar14NameEnumeratorE
N6quasar17RawCopyEnumeratorE
NSt3__120__shared_ptr_emplaceIN6quasar20SimpleNameEnumeratorENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar17RawCopyEnumeratorENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar20ExhaustiveEnumeratorENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar15RegexEnumeratorENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar17DerivedEnumeratorENS_9allocatorIS2_EEEE
N6quasar20SimpleNameEnumeratorE
N6quasar15RegexEnumeratorE
NSt3__120__shared_ptr_emplaceIN6quasar11ReplaceStepENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar9SplitStepENS_9allocatorIS2_EEEE
N6quasar9RegexStepE
N6quasar11ReplaceStepE
N6quasar9SplitStepE
NSt3__120__shared_ptr_emplaceIN6quasar11ReplaceStep9RegexRuleENS_9allocatorIS3_EEEE
N6quasar17LmeWordTaggerBaseE
N6quasar22IndexRuleLmeWordTaggerE
N6quasar18BasicTextSanitizerE
N6quasar13TextSanitizerE
N6quasar13TextTokenizerE
N6quasar14BasicTokenizerE
~*?NSt3__120__shared_ptr_emplaceIN6quasar11ModelLoaderENS_9allocatorIS2_EEEE
N3fst11ExpandedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N3fst9LifoQueueIiEE
NSt3__15dequeIiNS_9allocatorIiEEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENSt3__19allocatorIS8_EEEEEENS_10MutableFstIS8_EEEE
N3fst10MutableFstINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEEE4LinkEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_11VectorStateIS7_NSt3__19allocatorIS7_EEEEEEEE
NSt3__120__shared_ptr_emplaceIN6quasar18QsrTextSymbolTableENS_9allocatorIS2_EEEE
N6quasar9PronCacheINSt3__112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEENS1_6vectorIS7_NS5_IS7_EEEEEE
NSt3__120__shared_ptr_emplaceIN6quasar14LmeDataFactoryENS_9allocatorIS2_EEEE
N3fst9AutoQueueIiEE
N3fst15StateOrderQueueIiEE
N3fst18ShortestFirstQueueIiNS_18StateWeightCompareIiNS_11NaturalLessINS_17TropicalWeightTplIfEEEEEELb0EEE
N3fst13StateIteratorINS_14DeterminizeFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE3EEENS_14ToGallicMapperIS5_LS7_3EEEEENS_3FstIS8_EEEE
N3fst13ArcMapFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE3EEENS_14ToGallicMapperIS4_LS6_3EEEEE
N3fst9CacheImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEEEE
N3fst7FstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEEEE
N3fst9ImplToFstINS_22DeterminizeFstImplBaseINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEEEENS_3FstIS8_EEEE
N3fst18DeterminizeFsaImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEENS_19GallicCommonDivisorIiS4_LS6_3ENS_20DefaultCommonDivisorIS4_EEEENS_24DefaultDeterminizeFilterIS7_EENS_28DefaultDeterminizeStateTableIS7_NS_18IntegerFilterStateIaEEEEEE
N3fst22DeterminizeFstImplBaseINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEEEE
N3fst13StateIteratorINS_14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEEEEEE
N3fst18CacheStateIteratorINS_14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEEEEEE
N3fst15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEENS_12GallicFactorIiS4_LS6_3EEEEE
N3fst9ImplToFstINS_19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEENS_12GallicFactorIiS5_LS7_3EEEEENS_3FstIS8_EEEE
N3fst19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEENS_12GallicFactorIiS4_LS6_3EEEEE
N3fst13StateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEENS_12GallicFactorIiS5_LS7_3EEEEEEE
N3fst18CacheStateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEENS_12GallicFactorIiS5_LS7_3EEEEEEE
N3fst9ArcMapFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEES5_NS_16FromGallicMapperIS5_LS6_3EEEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEES6_NS_16FromGallicMapperIS6_LS7_3EEEEENS_3FstIS6_EEEE
N3fst13ArcMapFstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEES5_NS_16FromGallicMapperIS5_LS6_3EEEEE
N3fst13StateIteratorINS_9ArcMapFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3EEES6_NS_16FromGallicMapperIS6_LS7_3EEEEEEE
N3fst18DeterminizeFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2ENS_20DefaultCommonDivisorIS3_EENS_24DefaultDeterminizeFilterIS4_EENS_28DefaultDeterminizeStateTableIS4_NS_18IntegerFilterStateIaEEEEEE
N3fst9ArcMapFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE2EEENS_14ToGallicMapperIS4_LS6_2EEEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE2EEENS_14ToGallicMapperIS5_LS7_2EEEEENS_3FstIS8_EEEE
N3fst3FstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEEEE
N3fst13ArcMapFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE2EEENS_14ToGallicMapperIS4_LS6_2EEEEE
N3fst9CacheImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEEEE
N3fst13CacheBaseImplINS_10CacheStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEENSt3__19allocatorIS8_EEEENS_17DefaultCacheStoreIS8_EEEE
N3fst7FstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEEEE
N3fst10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEEEEE4LinkEEE
N3fst13StateIteratorINS_9ArcMapFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE2EEENS_14ToGallicMapperIS5_LS7_2EEEEEEE
N3fst17StateIteratorBaseINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEEEE
N3fst14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEEEE
N3fst9ImplToFstINS_22DeterminizeFstImplBaseINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEEEENS_3FstIS8_EEEE
N3fst18DeterminizeFsaImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEENS_19GallicCommonDivisorIiS4_LS6_2ENS_20DefaultCommonDivisorIS4_EEEENS_24DefaultDeterminizeFilterIS7_EENS_28DefaultDeterminizeStateTableIS7_NS_18IntegerFilterStateIaEEEEEE
N3fst22DeterminizeFstImplBaseINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEEEE
N3fst13StateIteratorINS_14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEEEEEE
N3fst18CacheStateIteratorINS_14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEEEEEE
N3fst15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEENS_12GallicFactorIiS4_LS6_2EEEEE
N3fst9ImplToFstINS_19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEENS_12GallicFactorIiS5_LS7_2EEEEENS_3FstIS8_EEEE
N3fst19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEENS_12GallicFactorIiS4_LS6_2EEEEE
N3fst13StateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEENS_12GallicFactorIiS5_LS7_2EEEEEEE
N3fst18CacheStateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEENS_12GallicFactorIiS5_LS7_2EEEEEEE
N3fst9ArcMapFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEES5_NS_16FromGallicMapperIS5_LS6_2EEEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEES6_NS_16FromGallicMapperIS6_LS7_2EEEEENS_3FstIS6_EEEE
N3fst13ArcMapFstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEES5_NS_16FromGallicMapperIS5_LS6_2EEEEE
N3fst13StateIteratorINS_9ArcMapFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE2EEES6_NS_16FromGallicMapperIS6_LS7_2EEEEEEE
N3fst18DeterminizeFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4ENS_20DefaultCommonDivisorIS3_EENS_24DefaultDeterminizeFilterIS4_EENS_28DefaultDeterminizeStateTableIS4_NS_18IntegerFilterStateIaEEEEEE
N3fst9ArcMapFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE4EEENS_14ToGallicMapperIS4_LS6_4EEEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE4EEENS_14ToGallicMapperIS5_LS7_4EEEEENS_3FstIS8_EEEE
N3fst3FstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEEEE
N3fst13ArcMapFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE4EEENS_14ToGallicMapperIS4_LS6_4EEEEE
N3fst9CacheImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEEEE
N3fst13CacheBaseImplINS_10CacheStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEENSt3__19allocatorIS8_EEEENS_17DefaultCacheStoreIS8_EEEE
N3fst7FstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEEEE
N3fst10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEEEEE4LinkEEE
N3fst13StateIteratorINS_9ArcMapFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE4EEENS_14ToGallicMapperIS5_LS7_4EEEEEEE
N3fst17StateIteratorBaseINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEEEE
N3fst14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEEEE
N3fst9ImplToFstINS_22DeterminizeFstImplBaseINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEEEENS_3FstIS8_EEEE
N3fst18DeterminizeFsaImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEENS_19GallicCommonDivisorIiS4_LS6_4ENS_20DefaultCommonDivisorIS4_EEEENS_24DefaultDeterminizeFilterIS7_EENS_28DefaultDeterminizeStateTableIS7_NS_18IntegerFilterStateIaEEEEEE
N3fst22DeterminizeFstImplBaseINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEEEE
N3fst13StateIteratorINS_14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEEEEEE
N3fst18CacheStateIteratorINS_14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEEEEEE
N3fst15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEENS_12GallicFactorIiS4_LS6_4EEEEE
N3fst9ImplToFstINS_19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEENS_12GallicFactorIiS5_LS7_4EEEEENS_3FstIS8_EEEE
N3fst19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEENS_12GallicFactorIiS4_LS6_4EEEEE
N3fst13StateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEENS_12GallicFactorIiS5_LS7_4EEEEEEE
N3fst18CacheStateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEENS_12GallicFactorIiS5_LS7_4EEEEEEE
N3fst9ArcMapFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEES5_NS_16FromGallicMapperIS5_LS6_4EEEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEES6_NS_16FromGallicMapperIS6_LS7_4EEEEENS_3FstIS6_EEEE
N3fst13ArcMapFstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEES5_NS_16FromGallicMapperIS5_LS6_4EEEEE
N3fst13StateIteratorINS_9ArcMapFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE4EEES6_NS_16FromGallicMapperIS6_LS7_4EEEEEEE
ffffff
?N6quasar15AcousticLDModelE
N6quasar22AcousticLDModelFactoryE
N6quasar14LDResultStreamE
N6quasar19ContextAwareLDModelE
N6quasar24DummyContextAwareLDModelE
N6quasar26ContextAwareLDModelFactoryE
NSt3__120__shared_ptr_emplaceIKN5kaldi5TimerENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIKN6quasar10LDFrontendENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar8LDConfigENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIKN6quasar25ContextAwareLDModelConfigENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN6quasar14LDRequestStateENS_9allocatorIS2_EEEE
NSt3__110__function6__funcIZNK6quasar16LanguageDetector21processAcousticResultERNS2_14LDRequestStateERNS3_23WrappedLDAcousticResultEE3$_2NS_9allocatorIS8_EEFNS_12basic_stringIcNS_11char_traitsIcEENS9_IcEEEERKNS2_6LocaleEEEE
NSt3__110__function6__baseIFNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEERKN6quasar6LocaleEEEE
ZNK6quasar16LanguageDetector21processAcousticResultERNS_14LDRequestStateERNS0_23WrappedLDAcousticResultEE3$_2
;N5kaldi8CuMatrixIdEE
N5kaldi12CuMatrixBaseIdEE
N5kaldi11CuSubMatrixIdEE
N5kaldi8CuVectorIdEE
N5kaldi12CuVectorBaseIdEE
NSt3__120__shared_ptr_emplaceIN5kaldi10SnrTrackerENS_9allocatorIS2_EEEE
333333
333333
N5kaldi18OnlinePitchFeatureE
N5kaldi27OnlineAudioAnalyticsFeatureE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_16LatticeWeightTplIfEEEENSt3__19allocatorIS6_EEEEEENS_10MutableFstIS6_EEEE
N3fst11ExpandedFstINS_6ArcTplINS_16LatticeWeightTplIfEEEEEE
N3fst3FstINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEE
N3fst9ImplToFstINS_18ComposeFstImplBaseINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEENS_17DefaultCacheStoreISB_EEEENS_3FstISB_EEEE
N3fst3FstINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEE
N3fst10MemoryPoolINS_8DfsStateINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEE4LinkEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEENSt3__19allocatorISC_EEEEEENS_10MutableFstISC_EEEE
N3fst10MutableFstINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEE
N3fst11ExpandedFstINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEENSt3__19allocatorIS8_EEEEEENS_10MutableFstIS8_EEEE
N3fst18ShortestFirstQueueIiNS_18StateWeightCompareIiNS_11NaturalLessINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEELb0EEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEENSt3__19allocatorISA_EEEEEENS_10MutableFstISA_EEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEENSt3__19allocatorISA_EEEEEENS_10MutableFstISA_EEEE
N3fst10MutableFstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEE
N3fst11ExpandedFstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEE
N3fst3FstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEE
N3fst13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEENSt3__19allocatorIS9_EEEEEE
N3fst7FstImplINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEE
N3fst10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEEE4LinkEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEENS_11VectorStateIS9_NSt3__19allocatorIS9_EEEEEEEE
N3fst22MutableArcIteratorBaseINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEE
N3fst15ArcIteratorBaseINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEE
N3fst9ImplToFstINS_22DeterminizeFstImplBaseINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEENS_3FstIS9_EEEE
N3fst18DeterminizeFsaImplINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEENS_20DefaultCommonDivisorIS6_EENS_24DefaultDeterminizeFilterIS8_EENS_28DefaultDeterminizeStateTableIS8_NS_18IntegerFilterStateIaEEEEEE
N3fst9CacheImplINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEE
N3fst18CacheStateIteratorINS_14DeterminizeFstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEEEE
N3fst17StateIteratorBaseINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEE
N3fst9VectorFstINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEENS_11VectorStateISA_NSt3__19allocatorISA_EEEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEENSt3__19allocatorISC_EEEEEENS_10MutableFstISC_EEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEENSt3__19allocatorISC_EEEEEENS_10MutableFstISC_EEEE
N3fst13VectorFstImplINS_11VectorStateINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEENSt3__19allocatorISB_EEEEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEENSt3__19allocatorISB_EEEEEE
N3fst7FstImplINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEENS_11VectorStateISB_NSt3__19allocatorISB_EEEEEEEE
N3fst22MutableArcIteratorBaseINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEE
N3fst15ArcIteratorBaseINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEE
N3fst13SortedMatcherINS_3FstINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEE
N3fst11MatcherBaseINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEE
N3fst10MemoryPoolINS_11ArcIteratorINS_3FstINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_11ArcIteratorINS_3FstINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEEE4LinkEEE
N3fst10ComposeFstINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEENS_17DefaultCacheStoreISA_EEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEENS_21SequenceComposeFilterINS_13SortedMatcherINS_3FstISB_EEEESH_EENS_24GenericComposeStateTableISB_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSL_EENS_21CompactHashStateTableISN_NS_11ComposeHashISN_EEEEEEEE
N3fst18ComposeFstImplBaseINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEENS_17DefaultCacheStoreISA_EEEE
N3fst13CacheBaseImplINS_10CacheStateINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEENSt3__19allocatorISB_EEEENS_17DefaultCacheStoreISB_EEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEENS_21SequenceComposeFilterINS_13SortedMatcherINS_3FstISB_EEEESH_EENS_24GenericComposeStateTableISB_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSL_EENS_21CompactHashStateTableISN_NS_11ComposeHashISN_EEEEEEEE
N3fst13StateIteratorINS_10ComposeFstINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEENS_17DefaultCacheStoreISB_EEEEEE
N3fst18CacheStateIteratorINS_10ComposeFstINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEENS_17DefaultCacheStoreISB_EEEEEE
N3fst17StateIteratorBaseINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEE
N3fst18ShortestFirstQueueIiNS_18StateWeightCompareIiNS_11NaturalLessINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEELb0EEE
N3fst9VectorFstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEENS_11VectorStateISC_NSt3__19allocatorISC_EEEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEENSt3__19allocatorISE_EEEEEENS_10MutableFstISE_EEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEENSt3__19allocatorISE_EEEEEENS_10MutableFstISE_EEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEENSt3__19allocatorISE_EEEEEENS_10MutableFstISE_EEEE
N3fst10MutableFstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEE
N3fst11ExpandedFstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEE
N3fst3FstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEE
N3fst13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEENSt3__19allocatorISD_EEEEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEENSt3__19allocatorISD_EEEEEE
N3fst7FstImplINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEE
N3fst10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEEE4LinkEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEENS_11VectorStateISD_NSt3__19allocatorISD_EEEEEEEE
N3fst22MutableArcIteratorBaseINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEE
N3fst15ArcIteratorBaseINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEE
N3fst14DeterminizeFstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEE
N3fst9ImplToFstINS_22DeterminizeFstImplBaseINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEENS_3FstISD_EEEE
N3fst18DeterminizeFsaImplINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEENS_20DefaultCommonDivisorISA_EENS_24DefaultDeterminizeFilterISC_EENS_28DefaultDeterminizeStateTableISC_NS_18IntegerFilterStateIaEEEEEE
N3fst22DeterminizeFstImplBaseINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEE
N3fst9CacheImplINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEE
N3fst13CacheBaseImplINS_10CacheStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEENSt3__19allocatorISD_EEEENS_17DefaultCacheStoreISD_EEEE
N3fst13StateIteratorINS_14DeterminizeFstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEEEE
N3fst18CacheStateIteratorINS_14DeterminizeFstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEEEE
N3fst17StateIteratorBaseINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_19LexicographicWeightINS_17TropicalWeightTplIfEENS_16LatticeWeightTplIfEEEEiEEEEEEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEENSt3__19allocatorIS8_EEEEEENS_10MutableFstIS8_EEEE
N3fst11ExpandedFstINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_6ArcTplINS_16LatticeWeightTplIfEEEEEEE4LinkEEE
N3fst9VectorFstINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEENS_11VectorStateIS6_NSt3__19allocatorIS6_EEEEEE
N3fst10ComposeFstINS_6ArcTplINS_16LatticeWeightTplIfEEEENS_17DefaultCacheStoreIS4_EEEE
N3fst18ComposeFstImplBaseINS_6ArcTplINS_16LatticeWeightTplIfEEEENS_17DefaultCacheStoreIS4_EEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENS_21SequenceComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENS_22LookAheadComposeFilterINS_24AltSequenceComposeFilterINS_16LookAheadMatcherINS_3FstIS5_EEEESC_EESC_SC_LNS_9MatchTypeE2EEENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSI_EENS_21CompactHashStateTableISK_NS_11ComposeHashISK_EEEEEEEE
N3fst13StateIteratorINS_10ComposeFstINS_6ArcTplINS_16LatticeWeightTplIfEEEENS_17DefaultCacheStoreIS5_EEEEEE
N3fst18CacheStateIteratorINS_10ComposeFstINS_6ArcTplINS_16LatticeWeightTplIfEEEENS_17DefaultCacheStoreIS5_EEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENS_24AltSequenceComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
>N3fst10MemoryPoolINS_8DfsStateINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENSt3__19allocatorIS8_EEEEEENS_10MutableFstIS8_EEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENSt3__19allocatorIS8_EEEEEENS_10MutableFstIS8_EEEE
N3fst13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENSt3__19allocatorIS7_EEEEEE
N3fst10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEEEE
N3fst9ImplToFstINS_22DeterminizeFstImplBaseINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEENS_3FstIS7_EEEE
P?N3fst13VectorFstImplINS_11VectorStateINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEENSt3__19allocatorIS7_EEEEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEENSt3__19allocatorIS7_EEEEEE
N3fst9VectorFstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEENS_11VectorStateIS8_NSt3__19allocatorIS8_EEEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEENSt3__19allocatorISA_EEEEEENS_10MutableFstISA_EEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEENSt3__19allocatorIS9_EEEEEE
N5kaldi8CuVectorIfEE
NSt3__120__shared_ptr_emplaceIN5kaldi14WordHypLatticeENS_9allocatorIS2_EEEE
N5kaldi26ContextDependencyInterfaceE
N5kaldi18DecodableInterfaceE
N5kaldi10OptionsItfE
N5kaldi17FeedForwardNetItfE
N5kaldi15InferenceNetItfE
N5kaldi6quasar12ESTensorDataE
N5kaldi6quasar15ESNetworkConfigE
N5kaldi6quasar13ESNetworkPlanE
N5kaldi5nnet118ScaledDotAttentionE
N5kaldi5nnet118MultiHeadAttentionE
N5kaldi5nnet128SupervisedMultiHeadAttentionE
N5kaldi5nnet113SelfAttentionE
N5kaldi5nnet116AverageAttentionE
N5kaldi5nnet115AffineTransformE
N5kaldi5nnet131BidirectionalRecurrentComponentE
?N5kaldi5nnet19ComponentE
N5kaldi5nnet118UpdatableComponentE
N5kaldi5nnet119HistoricalComponentE
N5kaldi5nnet122RecurrentBaseComponentE
N5kaldi5nnet122AttentionBaseComponentE
N5kaldi5nnet131RecurrentAttentionBaseComponentE
N5kaldi5nnet131AttentionBaseInferenceComponentE
N5kaldi5nnet127Quantizable8BitComponentItfE
N5kaldi5nnet128Quantizable16BitComponentItfE
N5kaldi5nnet117Nnet1InferenceNetE
N5kaldi5nnet114RelaxedSoftmaxE
N5kaldi5nnet110LogSoftmaxE
N5kaldi5nnet17SoftmaxE
N5kaldi5nnet112BlockSoftmaxE
N5kaldi5nnet17SigmoidE
N5kaldi5nnet14TanhE
N5kaldi5nnet17DropoutE
N5kaldi5nnet115MaxoutComponentE
N5kaldi5nnet114PNormComponentE
N5kaldi5nnet124RectifiedLinearComponentE
N5kaldi5nnet126ExponentialLinearComponentE
N5kaldi5nnet132ScaledExponentialLinearComponentE
N5kaldi5nnet15KlHmmE
N5kaldi5nnet16SpliceE
N5kaldi5nnet113CopyComponentE
N5kaldi5nnet117IdentityComponentE
N5kaldi5nnet118DuplicateComponentE
N5kaldi5nnet18AddShiftE
N5kaldi5nnet17RescaleE
N5kaldi5nnet137VectorwiseQuantizable8BitComponentItfE
N5kaldi5nnet17RbmBaseE
N5kaldi5nnet13RbmE
N5kaldi5nnet112MultiSoftmaxE
N5kaldi5nnet19RecurrentE
N5kaldi5nnet122ConvolutionalComponentE
N5kaldi5nnet123AveragePoolingComponentE
N5kaldi5nnet119MaxPoolingComponentE
N5kaldi5nnet127TemporalMaxPoolingComponentE
N5kaldi5nnet125AveragePooling2DComponentE
N5kaldi5nnet121MaxPooling2DComponentE
N5kaldi5nnet18DespliceE
N5kaldi5nnet126SentenceAveragingComponentE
N5kaldi5nnet121FramePoolingComponentE
N5kaldi5nnet117ParallelComponentE
N5kaldi5nnet122InterpolationComponentE
N5kaldi5nnet126CompressedWordVecComponentE
N5kaldi5nnet124CompressibleComponentItfE
N5kaldi5nnet116WordVecComponentE
N5kaldi5nnet120FofeWordVecComponentE
N5kaldi5nnet118SharedNceComponentE
N5kaldi5nnet128CompressedWordTransComponentE
N5kaldi5nnet132ConvolutionalMaxPoolingComponentINS_12CuMatrixBaseIfEEEE
N5kaldi5nnet132ConvolutionalMaxPoolingComponentINS_15QuantizedMatrixIaEEEE
N5kaldi5nnet132ConvolutionalMaxPoolingComponentINS_15QuantizedMatrixIsEEEE
N5kaldi5nnet113LstmComponentINS_15QuantizedMatrixIaEEEE
N5kaldi5nnet113LstmComponentINS_15QuantizedMatrixIsEEEE
N5kaldi5nnet124QuantizedAffineTransformIaEE
N5kaldi5nnet124QuantizedAffineTransformIsEE
N5kaldi5nnet134VectorwiseQuantizedAffineTransformIaEE
N5kaldi5nnet134VectorwiseQuantizedAffineTransformIsEE
N5kaldi5nnet124Convolutional2DComponentINS_12CuMatrixBaseIfEEEE
N5kaldi5nnet124Convolutional2DComponentINS_15QuantizedMatrixIaEEEE
N5kaldi5nnet124Convolutional2DComponentINS_15QuantizedMatrixIsEEEE
N5kaldi5nnet121CnnRearrangeComponentE
N5kaldi5nnet116PaddingComponentE
N5kaldi5nnet118Padding2DComponentE
N5kaldi5nnet123FixedAttentionComponentE
N5kaldi5nnet124GlobalAttentionComponentE
N5kaldi5nnet124GlobalRecurrentAttentionE
N5kaldi5nnet118GatedRecurrentUnitE
N5kaldi5nnet19LayerNormE
N5kaldi5nnet115LinearTransformINS_12CuMatrixBaseIfEEEE
N5kaldi5nnet115LinearTransformINS_15QuantizedMatrixIaEEEE
N5kaldi5nnet115LinearTransformINS_15QuantizedMatrixIsEEEE
+2N5kaldi5nnet116LossEvaluatorItfE
N5kaldi5nnet14XentE
N5kaldi5nnet13MseE
N5kaldi11CuSubMatrixIfEE
N5kaldi5nnet124MovingAttentionComponentE
?N5kaldi5nnet116NnetTrainOptionsE
N5kaldi5nnet114HistoryOptionsE
N5kaldi5nnet113LstmComponentINS_12CuMatrixBaseIfEEEE
N5kaldi5nnet125RecurrentNnetTrainOptionsE
NSt3__120__shared_ptr_emplaceIN5kaldi5nnet117Nnet1InferenceNetENS_9allocatorIS3_EEEE
N5kaldi32SequentialTableReaderArchiveImplINS_17KaldiObjectHolderINS_6VectorIfEEEEEE
N5kaldi29SequentialTableReaderImplBaseINS_17KaldiObjectHolderINS_6VectorIfEEEEEE
N5kaldi31SequentialTableReaderScriptImplINS_17KaldiObjectHolderINS_6VectorIfEEEEEE
333333
?N5kaldi5nnet118NormalizeComponentE
N5kaldi11CuSubVectorIfEE
N5kaldi5nnet121WordMultiVecComponentINS_12CuMatrixBaseIfEEEE
N5kaldi5nnet121WordMultiVecComponentINS_16CompressedMatrixEEE
N5kaldi18CoreMLInferenceNetE
NSt3__120__shared_ptr_emplaceIN5kaldi18CoreMLInferenceNetENS_9allocatorIS2_EEEE
N5kaldi20OnlineAudioSourceItfE
N5kaldi27OnlineDecodableMatrixScaledE
N5kaldi30OnlineDecodableIdenticalMatrixE
N5kaldi33OnlineDecodableMatrixScaledMappedE
N5kaldi35OnlineDecodableMatrixScaledMappedTmE
N5kaldi24OnlineDecodableNnet1LazyE
N5kaldi18OnlineFeatInputItfE
N5kaldi15OnlineCmvnInputE
N5kaldi14OnlineCmnInputE
N5kaldi16OnlineCacheInputE
N5kaldi19OnlineRecordedInputE
N5kaldi17OnlineSpliceInputE
N5kaldi22OnlineSpliceBatchInputE
N5kaldi22OnlineNnetForwardInputE
N5kaldi29OnlineNnetForwardSkippedInputE
N5kaldi17OnlineAppendInputE
N5kaldi17OnlineSubsampleFeE
N5kaldi14OnlineLdaInputE
N5kaldi20OnlineTransformInputE
N5kaldi20OnlineBufferingInputE
N5kaldi16OnlineDeltaInputE
N3fst7ArcInfoE
N3fst14BackoffArcInfoE
N3fst13InterpArcInfoE
N5kaldi6quasar16CoreMLTensorDataE
N5kaldi6quasar19CoreMLNetworkConfigE
N5kaldi6quasar17CoreMLNetworkPlanE
N3fst12ArcPosingFstINS_6ArcTplINS_12LogWeightTplIfEEEENS1_INS_17TropicalWeightTplIfEEEEEE
N3fst3FstINS_6ArcTplINS_12LogWeightTplIfEEEEEE
N3fst11ArcIteratorINS_12ArcPosingFstINS_6ArcTplINS_12LogWeightTplIfEEEENS2_INS_17TropicalWeightTplIfEEEEEEEE
N3fst10MutableFstINS_6ArcTplINS_12LogWeightTplIfEEEEEE
N3fst22MutableArcIteratorBaseINS_6ArcTplINS_12LogWeightTplIfEEEEEE
N3fst15ArcIteratorBaseINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEENSt3__19allocatorIS9_EEEEEENS_10MutableFstIS9_EEEE
N3fst10MutableFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEEE4LinkEEE
N3fst22MutableArcIteratorBaseINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEENSt3__19allocatorISB_EEEEEENS_10MutableFstISB_EEEE
N3fst3FstINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEEEE
N3fst13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEENSt3__19allocatorISA_EEEEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEENS_11VectorStateISA_NSt3__19allocatorISA_EEEEEEEE
N3fst13CacheBaseImplINS_10CacheStateINS_6ArcTplINS_12LogWeightTplIfEEEENSt3__19allocatorIS5_EEEENS_17DefaultCacheStoreIS5_EEEE
N3fst13StateIteratorINS_9ArcMapFstINS_6ArcTplINS_12LogWeightTplIfEEEES5_NS_14RmWeightMapperIS5_S5_EEEEEE
N3fst9ArcMapFstINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE0EEENS_14ToGallicMapperIS4_LS6_0EEEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE0EEENS_14ToGallicMapperIS5_LS7_0EEEEENS_3FstIS8_EEEE
N3fst13ArcMapFstImplINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE0EEENS_14ToGallicMapperIS4_LS6_0EEEEE
N3fst13StateIteratorINS_9ArcMapFstINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE0EEENS_14ToGallicMapperIS5_LS7_0EEEEEEE
N3fst13StateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEENS_12GallicFactorIiS5_LS7_0EEEEEEE
N5kaldi6quasar17AbstractAttributeE
N5kaldi6quasar10MajorErrorE
N5kaldi6quasar15SchemaAttributeE
N5kaldi6quasar15StringAttributeE
N5kaldi6quasar14FloatAttributeE
N5kaldi6quasar13BaseAttributeE
N5kaldi6quasar16AttributeWrapperE
N5kaldi6quasar16ContextAttributeE
N5kaldi6quasar13WordConfusionE
N5kaldi6quasar16AttributeFactoryE
N5kaldi6quasar11ErrorBlamerE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENS_17NullComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_16LatticeWeightTplIfEEEEEENS_24AltSequenceComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N5kaldi6quasar12ErrorProfileE
N5kaldi6quasar11ErrorRegionE
N5kaldi17ContextDependencyE
N5kaldi8EventMapE
N5kaldi16ConstantEventMapE
N5kaldi13TableEventMapE
N5kaldi13SplitEventMapE
NSt3__119basic_ostringstreamIcNS_11char_traitsIcEENS_9allocatorIcEEEE
@(kn
N5kaldi6quasar19SeevaBeamSearchBaseE
N5kaldi6quasar20SeevaBeamSearchBigLmE
N5kaldi6quasar20SeevaStreamInferenceE
N5kaldi6quasar18SeevaStepInferenceE
NSt3__119__deque_base_commonILb1EEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_24AltSequenceComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_18MatchComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N5kaldi13InputImplBaseE
N5kaldi13FileInputImplE
N5kaldi17StandardInputImplE
N5kaldi13PipeInputImplE
N5kaldi19OffsetFileInputImplE
N5kaldi13basic_pipebufIcEE
N5kaldi6quasar14CEInferenceNetE
N5kaldi6quasar22ComputeEngineBufferItfE
N5kaldi6quasar16ComputeEngineItfE
N5kaldi6quasar22ComputeEngineConfigItfE
N5kaldi6quasar10LexiconItfE
N5kaldi6quasar7LexiconE
N5kaldi6quasar12ConstLexiconE
N3fst24DeterministicOnDemandFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N3fst10MutableFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEE4LinkEEE
N3fst7FstImplINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEE
N3fst14DeterminizeFstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEE
N3fst22DeterminizeFstImplBaseINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEE
N3fst13CacheBaseImplINS_10CacheStateINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEENSt3__19allocatorIS9_EEEENS_17DefaultCacheStoreIS9_EEEE
N3fst13StateIteratorINS_14DeterminizeFstINS_10ReverseArcINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_17TropicalWeightTplIfEEEENSt3__19allocatorIS6_EEEEEENS_10MutableFstIS6_EEEE
N3fst13StateIteratorINS_12ArcPosingFstINS_6ArcTplINS_12LogWeightTplIfEEEENS2_INS_17TropicalWeightTplIfEEEEEEEE
N3fst15ArcIteratorBaseINS_6ArcTplINS_12LogWeightTplIfEEEEEE
N3fst19MutableArcPosingFstINS_6ArcTplINS_12LogWeightTplIfEEEENS1_INS_17TropicalWeightTplIfEEEEEE
N3fst11ArcIteratorINS_19MutableArcPosingFstINS_6ArcTplINS_12LogWeightTplIfEEEENS2_INS_17TropicalWeightTplIfEEEEEEEE
N3fst18MutableArcIteratorINS_19MutableArcPosingFstINS_6ArcTplINS_12LogWeightTplIfEEEENS2_INS_17TropicalWeightTplIfEEEEEEEE
N3fst12ArcPosingFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS1_INS_12LogWeightTplIfEEEEEE
N3fst13StateIteratorINS_12ArcPosingFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS2_INS_12LogWeightTplIfEEEEEEEE
N3fst11ArcIteratorINS_12ArcPosingFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS2_INS_12LogWeightTplIfEEEEEEEE
N3fst10MemoryPoolINS_8DfsStateINS_6ArcTplINS_12LogWeightTplIfEEEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_6ArcTplINS_12LogWeightTplIfEEEEEEE4LinkEEE
N3fst9VectorFstINS_10ReverseArcINS_6ArcTplINS_12LogWeightTplIfEEEEEENS_11VectorStateIS6_NSt3__19allocatorIS6_EEEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_12LogWeightTplIfEEEEEENSt3__19allocatorIS8_EEEEEENS_10MutableFstIS8_EEEE
N3fst10MutableFstINS_10ReverseArcINS_6ArcTplINS_12LogWeightTplIfEEEEEEEE
N3fst13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_12LogWeightTplIfEEEEEENSt3__19allocatorIS7_EEEEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_12LogWeightTplIfEEEEEENSt3__19allocatorIS7_EEEEEE
N3fst7FstImplINS_10ReverseArcINS_6ArcTplINS_12LogWeightTplIfEEEEEEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_10ReverseArcINS_6ArcTplINS_12LogWeightTplIfEEEEEENS_11VectorStateIS7_NSt3__19allocatorIS7_EEEEEEEE
N3fst14DeterminizeFstINS_6ArcTplINS_12LogWeightTplIfEEEEEE
N3fst9ImplToFstINS_22DeterminizeFstImplBaseINS_6ArcTplINS_12LogWeightTplIfEEEEEENS_3FstIS5_EEEE
N3fst18DeterminizeFsaImplINS_6ArcTplINS_12LogWeightTplIfEEEENS_20DefaultCommonDivisorIS3_EENS_24DefaultDeterminizeFilterIS4_EENS_28DefaultDeterminizeStateTableIS4_NS_18IntegerFilterStateIaEEEEEE
N3fst22DeterminizeFstImplBaseINS_6ArcTplINS_12LogWeightTplIfEEEEEE
N3fst13StateIteratorINS_14DeterminizeFstINS_6ArcTplINS_12LogWeightTplIfEEEEEEEE
N3fst18CacheStateIteratorINS_14DeterminizeFstINS_6ArcTplINS_12LogWeightTplIfEEEEEEEE
N3fst18DeterminizeFstImplINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3ENS_20DefaultCommonDivisorIS3_EENS_24DefaultDeterminizeFilterIS4_EENS_28DefaultDeterminizeStateTableIS4_NS_18IntegerFilterStateIaEEEEEE
N3fst9ArcMapFstINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE3EEENS_14ToGallicMapperIS4_LS6_3EEEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE3EEENS_14ToGallicMapperIS5_LS7_3EEEEENS_3FstIS8_EEEE
N3fst3FstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEEEE
N3fst13ArcMapFstImplINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE3EEENS_14ToGallicMapperIS4_LS6_3EEEEE
N3fst7FstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEEEEE4LinkEEE
N3fst13StateIteratorINS_9ArcMapFstINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE3EEENS_14ToGallicMapperIS5_LS7_3EEEEEEE
N3fst17StateIteratorBaseINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEEEE
N3fst14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEEEE
N3fst18DeterminizeFsaImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEENS_19GallicCommonDivisorIiS4_LS6_3ENS_20DefaultCommonDivisorIS4_EEEENS_24DefaultDeterminizeFilterIS7_EENS_28DefaultDeterminizeStateTableIS7_NS_18IntegerFilterStateIaEEEEEE
N3fst22DeterminizeFstImplBaseINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEEEE
N3fst13StateIteratorINS_14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEEEEEE
N3fst18CacheStateIteratorINS_14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEEEEEE
N3fst15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEENS_12GallicFactorIiS4_LS6_3EEEEE
N3fst9ImplToFstINS_19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEENS_12GallicFactorIiS5_LS7_3EEEEENS_3FstIS8_EEEE
N3fst19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEENS_12GallicFactorIiS4_LS6_3EEEEE
N3fst13StateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEENS_12GallicFactorIiS5_LS7_3EEEEEEE
N3fst18CacheStateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEENS_12GallicFactorIiS5_LS7_3EEEEEEE
N3fst9ArcMapFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEES5_NS_16FromGallicMapperIS5_LS6_3EEEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEES6_NS_16FromGallicMapperIS6_LS7_3EEEEENS_3FstIS6_EEEE
N3fst13ArcMapFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEES5_NS_16FromGallicMapperIS5_LS6_3EEEEE
N3fst13StateIteratorINS_9ArcMapFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEES6_NS_16FromGallicMapperIS6_LS7_3EEEEEEE
N3fst18DeterminizeFstImplINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2ENS_20DefaultCommonDivisorIS3_EENS_24DefaultDeterminizeFilterIS4_EENS_28DefaultDeterminizeStateTableIS4_NS_18IntegerFilterStateIaEEEEEE
N3fst9ArcMapFstINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE2EEENS_14ToGallicMapperIS4_LS6_2EEEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE2EEENS_14ToGallicMapperIS5_LS7_2EEEEENS_3FstIS8_EEEE
N3fst3FstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEEEE
N3fst13ArcMapFstImplINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE2EEENS_14ToGallicMapperIS4_LS6_2EEEEE
N3fst9CacheImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEEEE
N3fst13CacheBaseImplINS_10CacheStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEENSt3__19allocatorIS8_EEEENS_17DefaultCacheStoreIS8_EEEE
N3fst7FstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEEEE
N3fst10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEEEEE4LinkEEE
N3fst13StateIteratorINS_9ArcMapFstINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE2EEENS_14ToGallicMapperIS5_LS7_2EEEEEEE
N3fst17StateIteratorBaseINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEEEE
N3fst14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEEEE
N3fst9ImplToFstINS_22DeterminizeFstImplBaseINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEEEENS_3FstIS8_EEEE
N3fst18DeterminizeFsaImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEENS_19GallicCommonDivisorIiS4_LS6_2ENS_20DefaultCommonDivisorIS4_EEEENS_24DefaultDeterminizeFilterIS7_EENS_28DefaultDeterminizeStateTableIS7_NS_18IntegerFilterStateIaEEEEEE
N3fst22DeterminizeFstImplBaseINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEEEE
N3fst13StateIteratorINS_14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEEEEEE
N3fst18CacheStateIteratorINS_14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEEEEEE
N3fst15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEENS_12GallicFactorIiS4_LS6_2EEEEE
N3fst9ImplToFstINS_19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEENS_12GallicFactorIiS5_LS7_2EEEEENS_3FstIS8_EEEE
N3fst19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEENS_12GallicFactorIiS4_LS6_2EEEEE
N3fst13StateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEENS_12GallicFactorIiS5_LS7_2EEEEEEE
N3fst18CacheStateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEENS_12GallicFactorIiS5_LS7_2EEEEEEE
N3fst9ArcMapFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEES5_NS_16FromGallicMapperIS5_LS6_2EEEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEES6_NS_16FromGallicMapperIS6_LS7_2EEEEENS_3FstIS6_EEEE
N3fst13ArcMapFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEES5_NS_16FromGallicMapperIS5_LS6_2EEEEE
N3fst13StateIteratorINS_9ArcMapFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE2EEES6_NS_16FromGallicMapperIS6_LS7_2EEEEEEE
N3fst18DeterminizeFstImplINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4ENS_20DefaultCommonDivisorIS3_EENS_24DefaultDeterminizeFilterIS4_EENS_28DefaultDeterminizeStateTableIS4_NS_18IntegerFilterStateIaEEEEEE
N3fst9ArcMapFstINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE4EEENS_14ToGallicMapperIS4_LS6_4EEEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE4EEENS_14ToGallicMapperIS5_LS7_4EEEEENS_3FstIS8_EEEE
N3fst3FstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEEEE
N3fst13ArcMapFstImplINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE4EEENS_14ToGallicMapperIS4_LS6_4EEEEE
N3fst9CacheImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEEEE
N3fst13CacheBaseImplINS_10CacheStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEENSt3__19allocatorIS8_EEEENS_17DefaultCacheStoreIS8_EEEE
N3fst7FstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEEEE
N3fst10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEEEEE4LinkEEE
N3fst13StateIteratorINS_9ArcMapFstINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE4EEENS_14ToGallicMapperIS5_LS7_4EEEEEEE
N3fst17StateIteratorBaseINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEEEE
N3fst14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEEEE
N3fst9ImplToFstINS_22DeterminizeFstImplBaseINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEEEENS_3FstIS8_EEEE
N3fst18DeterminizeFsaImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEENS_19GallicCommonDivisorIiS4_LS6_4ENS_20DefaultCommonDivisorIS4_EEEENS_24DefaultDeterminizeFilterIS7_EENS_28DefaultDeterminizeStateTableIS7_NS_18IntegerFilterStateIaEEEEEE
N3fst22DeterminizeFstImplBaseINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEEEE
N3fst13StateIteratorINS_14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEEEEEE
N3fst18CacheStateIteratorINS_14DeterminizeFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEEEEEE
N3fst15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEENS_12GallicFactorIiS4_LS6_4EEEEE
N3fst9ImplToFstINS_19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEENS_12GallicFactorIiS5_LS7_4EEEEENS_3FstIS8_EEEE
N3fst19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEENS_12GallicFactorIiS4_LS6_4EEEEE
N3fst13StateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEENS_12GallicFactorIiS5_LS7_4EEEEEEE
N3fst18CacheStateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEENS_12GallicFactorIiS5_LS7_4EEEEEEE
N3fst9ArcMapFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEES5_NS_16FromGallicMapperIS5_LS6_4EEEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEES6_NS_16FromGallicMapperIS6_LS7_4EEEEENS_3FstIS6_EEEE
N3fst13ArcMapFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEES5_NS_16FromGallicMapperIS5_LS6_4EEEEE
N3fst13StateIteratorINS_9ArcMapFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE4EEES6_NS_16FromGallicMapperIS6_LS7_4EEEEEEE
N3fst9VectorFstINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_11VectorStateIS6_NSt3__19allocatorIS6_EEEEEE
N3fst11ExpandedFstINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENSt3__19allocatorIS7_EEEEEE
N3fst22MutableArcIteratorBaseINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEE
N3fst15ArcIteratorBaseINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEE
N3fst12TableMatcherINS_3FstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_13SortedMatcherIS6_EEEE
N3fst16TableMatcherImplINS_3FstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_13SortedMatcherIS6_EEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_21SequenceComposeFilterINS_12TableMatcherINS_3FstIS5_EENS_13SortedMatcherISA_EEEESC_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSH_EENS_21CompactHashStateTableISJ_NS_11ComposeHashISJ_EEEEEEEE
N3fst18ComposeFstImplBaseINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_17DefaultCacheStoreIS4_EEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_21SequenceComposeFilterINS_12TableMatcherINS_3FstIS5_EENS_13SortedMatcherISA_EEEESC_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSH_EENS_21CompactHashStateTableISJ_NS_11ComposeHashISJ_EEEEEEEE
N3fst18CacheStateIteratorINS_10ComposeFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_17DefaultCacheStoreIS5_EEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_21SequenceComposeFilterINS_13SortedMatcherINS_3FstIS5_EEEENS_12TableMatcherISA_SB_EEEENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSH_EENS_21CompactHashStateTableISJ_NS_11ComposeHashISJ_EEEEEEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_21SequenceComposeFilterINS_13SortedMatcherINS_3FstIS5_EEEENS_12TableMatcherISA_SB_EEEENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSH_EENS_21CompactHashStateTableISJ_NS_11ComposeHashISJ_EEEEEEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEENSt3__19allocatorIS9_EEEEEENS_10MutableFstIS9_EEEE
N3fst10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEENS_11VectorStateIS8_NSt3__19allocatorIS8_EEEEEEEE
N3fst22MutableArcIteratorBaseINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N3fst3FstINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEEEE
N3fst22MutableArcIteratorBaseINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEEEE
N3fst19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEENS_12GallicFactorIiS4_LS6_0EEEEE
N5kaldi6quasar14DnnlmEvaluatorE
N5kaldi6quasar15FofeLmEvaluatorE
N5kaldi6quasar14RnnlmEvaluatorE
N5kaldi6quasar17NnlmEvaluatorBaseE
N5boost10filesystem16filesystem_errorE
N5boost6system12system_errorE
N5boost6detail17sp_counted_impl_pINS_10filesystem16filesystem_error5m_impEEE
N3fst11SymbolTableE
N3fst10MappedFileE
N3fst15MemoryArenaBaseE
N3fst14MemoryPoolBaseE
N3fst9VectorFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_11VectorStateIS4_NSt3__19allocatorIS4_EEEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_17TropicalWeightTplIfEEEENSt3__19allocatorIS6_EEEEEENS_10MutableFstIS6_EEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_17TropicalWeightTplIfEEEENSt3__19allocatorIS6_EEEEEENS_10MutableFstIS6_EEEE
N3fst9VectorFstINS_6ArcTplINS_12LogWeightTplIfEEEENS_11VectorStateIS4_NSt3__19allocatorIS4_EEEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_12LogWeightTplIfEEEENSt3__19allocatorIS6_EEEEEENS_10MutableFstIS6_EEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_12LogWeightTplIfEEEENSt3__19allocatorIS6_EEEEEENS_10MutableFstIS6_EEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_11VectorStateIS5_NSt3__19allocatorIS5_EEEEEEEE
N3fst22MutableArcIteratorBaseINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_6ArcTplINS_12LogWeightTplIfEEEENS_11VectorStateIS5_NSt3__19allocatorIS5_EEEEEEEE
N5kaldi27DecodableMatrixScaledMappedE
N5kaldi6quasar18TooManyTokensErrorE
N5kaldi6quasar24TooManyForwardLinksErrorE
N3fst10MemoryPoolINS_8DfsStateINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEENSt3__19allocatorIS8_EEEEEENS_10MutableFstIS8_EEEE
N3fst15ArcIteratorBaseINS_6ArcTplINS_23CompactLatticeWeightTplINS_16LatticeWeightTplIfEEiEEEEEE
N3fst10ContextFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEiEE
N3fst14ContextFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEEiEE
N3fst13StateIteratorINS_10ContextFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEiEEEE
N3fst18CacheStateIteratorINS_10ContextFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEiEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_21SequenceComposeFilterINS_14ContextMatcherIS5_iEES9_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSD_EENS_21CompactHashStateTableISF_NS_11ComposeHashISF_EEEEEEEE
N3fst14ContextMatcherINS_6ArcTplINS_17TropicalWeightTplIfEEEEiEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_21SequenceComposeFilterINS_14ContextMatcherIS5_iEES9_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSD_EENS_21CompactHashStateTableISF_NS_11ComposeHashISF_EEEEEEEE
N5boost6system14error_category12std_categoryE
N5boost6system12_GLOBAL__N_121system_error_categoryE
N5boost6system14error_categoryE
N5boost12noncopyable_11noncopyableE
N5boost6system12_GLOBAL__N_122generic_error_categoryE
N5kaldi6quasar19TorchEncoderDecoder14AttentionModelE
N5kaldi6quasar19TorchEncoderDecoderE
N3fst9ImplToFstINS_18ComposeFstImplBaseINS_6ArcTplINS_12LogWeightTplIfEEEENS_17DefaultCacheStoreIS5_EEEENS_3FstIS5_EEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_12LogWeightTplIfEEEENSt3__19allocatorIS6_EEEEEENS_10MutableFstIS6_EEEE
N3fst11ExpandedFstINS_6ArcTplINS_12LogWeightTplIfEEEEEE
N3fst10ComposeFstINS_6ArcTplINS_12LogWeightTplIfEEEENS_17DefaultCacheStoreIS4_EEEE
N3fst13SortedMatcherINS_3FstINS_6ArcTplINS_12LogWeightTplIfEEEEEEEE
N3fst11MatcherBaseINS_6ArcTplINS_12LogWeightTplIfEEEEEE
N3fst10MemoryPoolINS_11ArcIteratorINS_3FstINS_6ArcTplINS_12LogWeightTplIfEEEEEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_11ArcIteratorINS_3FstINS_6ArcTplINS_12LogWeightTplIfEEEEEEEEE4LinkEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_12LogWeightTplIfEEEEEENS_21SequenceComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst18ComposeFstImplBaseINS_6ArcTplINS_12LogWeightTplIfEEEENS_17DefaultCacheStoreIS4_EEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_12LogWeightTplIfEEEEEENS_21SequenceComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_12LogWeightTplIfEEEEEENS_23PushLabelsComposeFilterINS_24PushWeightsComposeFilterINS_22LookAheadComposeFilterINS_24AltSequenceComposeFilterINS_16LookAheadMatcherINS_3FstIS5_EEEESE_EESE_SE_LNS_9MatchTypeE2EEESE_SE_LSG_2EEESE_SE_LSG_2EEENS_24GenericComposeStateTableIS5_NS_15PairFilterStateINSL_INS_18IntegerFilterStateIaEENS_17WeightFilterStateIS4_EEEENSM_IiEEEENS_24DefaultComposeStateTupleIiSS_EENS_21CompactHashStateTableISU_NS_11ComposeHashISU_EEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_12LogWeightTplIfEEEEEENS_23PushLabelsComposeFilterINS_24PushWeightsComposeFilterINS_22LookAheadComposeFilterINS_21SequenceComposeFilterINS_16LookAheadMatcherINS_3FstIS5_EEEESE_EESE_SE_LNS_9MatchTypeE2EEESE_SE_LSG_2EEESE_SE_LSG_2EEENS_24GenericComposeStateTableIS5_NS_15PairFilterStateINSL_INS_18IntegerFilterStateIaEENS_17WeightFilterStateIS4_EEEENSM_IiEEEENS_24DefaultComposeStateTupleIiSS_EENS_21CompactHashStateTableISU_NS_11ComposeHashISU_EEEEEEEE
N3fst13StateIteratorINS_10ComposeFstINS_6ArcTplINS_12LogWeightTplIfEEEENS_17DefaultCacheStoreIS5_EEEEEE
N3fst18CacheStateIteratorINS_10ComposeFstINS_6ArcTplINS_12LogWeightTplIfEEEENS_17DefaultCacheStoreIS5_EEEEEE
N3fst17StateIteratorBaseINS_6ArcTplINS_12LogWeightTplIfEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_12LogWeightTplIfEEEEEENS_17NullComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_12LogWeightTplIfEEEEEENS_17NullComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_12LogWeightTplIfEEEEEENS_24AltSequenceComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_12LogWeightTplIfEEEEEENS_24AltSequenceComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_12LogWeightTplIfEEEEEENS_18MatchComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_12LogWeightTplIfEEEEEENS_18MatchComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst15ArcIteratorBaseINS_10ReverseArcINS_6ArcTplINS_12LogWeightTplIfEEEEEEEE
N3fst9VectorFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEENS_11VectorStateIS7_NSt3__19allocatorIS7_EEEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEENSt3__19allocatorIS9_EEEEEENS_10MutableFstIS9_EEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEENSt3__19allocatorIS9_EEEEEENS_10MutableFstIS9_EEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEENSt3__19allocatorIS9_EEEEEENS_10MutableFstIS9_EEEE
N3fst10MutableFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEE
N3fst11ExpandedFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEE
N3fst3FstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEE
N3fst13VectorFstImplINS_11VectorStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEENSt3__19allocatorIS8_EEEEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEENSt3__19allocatorIS8_EEEEEE
N3fst7FstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEE
N3fst10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEEE4LinkEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEENS_11VectorStateIS8_NSt3__19allocatorIS8_EEEEEEEE
N3fst22MutableArcIteratorBaseINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEE
N3fst15ArcIteratorBaseINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEE
N3fst9VectorFstINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEENS_11VectorStateIS9_NSt3__19allocatorIS9_EEEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEENSt3__19allocatorISB_EEEEEENS_10MutableFstISB_EEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEENSt3__19allocatorISB_EEEEEENS_10MutableFstISB_EEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEENSt3__19allocatorISB_EEEEEENS_10MutableFstISB_EEEE
N3fst10MutableFstINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEEEE
N3fst11ExpandedFstINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEEEE
N3fst3FstINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEEEE
N3fst13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEENSt3__19allocatorISA_EEEEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEENSt3__19allocatorISA_EEEEEE
N3fst7FstImplINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEEEE
N3fst10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEEEEE4LinkEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEENS_11VectorStateISA_NSt3__19allocatorISA_EEEEEEEE
N3fst22MutableArcIteratorBaseINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEEEE
N3fst15ArcIteratorBaseINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEEEE
N3fst9ArcMapFstINS_6ArcTplINS_12LogWeightTplIfEEEES4_NS_14RmWeightMapperIS4_S4_EEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_6ArcTplINS_12LogWeightTplIfEEEES5_NS_14RmWeightMapperIS5_S5_EEEENS_3FstIS5_EEEE
N3fst13ArcMapFstImplINS_6ArcTplINS_12LogWeightTplIfEEEES4_NS_14RmWeightMapperIS4_S4_EEEE
N3fst9ArcMapFstINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE1EEENS_14ToGallicMapperIS4_LS6_1EEEEE
N3fst9ImplToFstINS_13ArcMapFstImplINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE1EEENS_14ToGallicMapperIS5_LS7_1EEEEENS_3FstIS8_EEEE
N3fst13ArcMapFstImplINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS4_LNS_10GallicTypeE1EEENS_14ToGallicMapperIS4_LS6_1EEEEE
N3fst9CacheImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEE
N3fst13CacheBaseImplINS_10CacheStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEENSt3__19allocatorIS8_EEEENS_17DefaultCacheStoreIS8_EEEE
N3fst13StateIteratorINS_9ArcMapFstINS_6ArcTplINS_12LogWeightTplIfEEEENS_9GallicArcIS5_LNS_10GallicTypeE1EEENS_14ToGallicMapperIS5_LS7_1EEEEEEE
N3fst17StateIteratorBaseINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEEEE
N3fst15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEENS_12GallicFactorIiS4_LS6_1EEEEE
N3fst9ImplToFstINS_19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEENS_12GallicFactorIiS5_LS7_1EEEEENS_3FstIS8_EEEE
N3fst19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEENS_12GallicFactorIiS4_LS6_1EEEEE
N3fst13StateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEENS_12GallicFactorIiS5_LS7_1EEEEEEE
N3fst18CacheStateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE1EEENS_12GallicFactorIiS5_LS7_1EEEEEEE
N3fst12SigmaMatcherINS_13SortedMatcherINS_3FstINS_6ArcTplINS_12LogWeightTplIfEEEEEEEEEE
N3fst10RhoMatcherINS_12SigmaMatcherINS_13SortedMatcherINS_3FstINS_6ArcTplINS_12LogWeightTplIfEEEEEEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_12LogWeightTplIfEEEEEENS_21SequenceComposeFilterINS_10RhoMatcherINS_12SigmaMatcherINS_13SortedMatcherINS_3FstIS5_EEEEEEEESF_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSJ_EENS_21CompactHashStateTableISL_NS_11ComposeHashISL_EEEEEEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_12LogWeightTplIfEEEEEENS_21SequenceComposeFilterINS_10RhoMatcherINS_12SigmaMatcherINS_13SortedMatcherINS_3FstIS5_EEEEEEEESF_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSJ_EENS_21CompactHashStateTableISL_NS_11ComposeHashISL_EEEEEEEE
N3fst12SigmaMatcherINS_13SortedMatcherINS_3FstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_21SequenceComposeFilterINS_12SigmaMatcherINS_13SortedMatcherINS_3FstIS5_EEEEEESD_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSH_EENS_21CompactHashStateTableISJ_NS_11ComposeHashISJ_EEEEEEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_21SequenceComposeFilterINS_12SigmaMatcherINS_13SortedMatcherINS_3FstIS5_EEEEEESD_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSH_EENS_21CompactHashStateTableISJ_NS_11ComposeHashISJ_EEEEEEEE
N3fst17StateIteratorBaseINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N3fst18DeterminizeFsaImplINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_20DefaultCommonDivisorIS3_EENS_24DefaultDeterminizeFilterIS4_EENS_28DefaultDeterminizeStateTableIS4_NS_18IntegerFilterStateIaEEEEEE
N3fst22DeterminizeFstImplBaseINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N3fst9CacheImplINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N3fst18DeterminizeFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE3ENS_20DefaultCommonDivisorIS3_EENS_24DefaultDeterminizeFilterIS4_EENS_28DefaultDeterminizeStateTableIS4_NS_18IntegerFilterStateIaEEEEEE
N3fst18CacheStateIteratorINS_14DeterminizeFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEE
N3fst9VectorFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEENS_11VectorStateIS7_NSt3__19allocatorIS7_EEEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEENSt3__19allocatorIS9_EEEEEENS_10MutableFstIS9_EEEE
N3fst10MutableFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N3fst13VectorFstImplINS_11VectorStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEENSt3__19allocatorIS8_EEEEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEENSt3__19allocatorIS8_EEEEEE
N3fst7FstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N3fst15ArcIteratorBaseINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N3fst9VectorFstINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEENS_11VectorStateIS9_NSt3__19allocatorIS9_EEEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEENSt3__19allocatorISB_EEEEEENS_10MutableFstISB_EEEE
N3fst10MutableFstINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEEEE
N3fst13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEENSt3__19allocatorISA_EEEEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEENSt3__19allocatorISA_EEEEEE
N3fst7FstImplINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEEEE
N3fst15ArcIteratorBaseINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEEEE
N3fst15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEENS_12GallicFactorIiS4_LS6_0EEEEE
N3fst9ImplToFstINS_19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEENS_12GallicFactorIiS5_LS7_0EEEEENS_3FstIS8_EEEE
N3fst13CacheBaseImplINS_10CacheStateINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEENSt3__19allocatorIS8_EEEENS_17DefaultCacheStoreIS8_EEEE
N3fst18CacheStateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEENS_12GallicFactorIiS5_LS7_0EEEEEEE
N3fst17StateIteratorBaseINS_9GallicArcINS_6ArcTplINS_17TropicalWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N3fst13VectorFstImplINS_11VectorStateINS_6ArcTplINS_17TropicalWeightTplIfEEEENSt3__19allocatorIS5_EEEEEE
N3fst14DeterminizeFstINS_10ReverseArcINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEE
N3fst13VectorFstImplINS_11VectorStateINS_6ArcTplINS_12LogWeightTplIfEEEENSt3__19allocatorIS5_EEEEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_6ArcTplINS_12LogWeightTplIfEEEENSt3__19allocatorIS5_EEEEEE
N3fst7FstImplINS_6ArcTplINS_12LogWeightTplIfEEEEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_12LogWeightTplIfEEEEEENSt3__19allocatorIS8_EEEEEENS_10MutableFstIS8_EEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_6ArcTplINS_12LogWeightTplIfEEEEEENSt3__19allocatorIS8_EEEEEENS_10MutableFstIS8_EEEE
N3fst11ExpandedFstINS_10ReverseArcINS_6ArcTplINS_12LogWeightTplIfEEEEEEEE
N3fst3FstINS_10ReverseArcINS_6ArcTplINS_12LogWeightTplIfEEEEEEEE
N3fst10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_6ArcTplINS_12LogWeightTplIfEEEEEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_6ArcTplINS_12LogWeightTplIfEEEEEEEEE4LinkEEE
N3fst22MutableArcIteratorBaseINS_10ReverseArcINS_6ArcTplINS_12LogWeightTplIfEEEEEEEE
N3fst9CacheImplINS_6ArcTplINS_12LogWeightTplIfEEEEEE
N3fst9CacheImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEEEE
N3fst13CacheBaseImplINS_10CacheStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEENSt3__19allocatorIS8_EEEENS_17DefaultCacheStoreIS8_EEEE
N3fst10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEEEEEE
N3fst9ImplToFstINS_22DeterminizeFstImplBaseINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE3EEEEENS_3FstIS8_EEEE
N3fst9VectorFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEENS_11VectorStateIS7_NSt3__19allocatorIS7_EEEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEENSt3__19allocatorIS9_EEEEEENS_10MutableFstIS9_EEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEENSt3__19allocatorIS9_EEEEEENS_10MutableFstIS9_EEEE
N3fst11ExpandedFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N3fst3FstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N3fst13VectorFstImplINS_11VectorStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEENSt3__19allocatorIS8_EEEEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEENSt3__19allocatorIS8_EEEEEE
N3fst7FstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N3fst10MemoryPoolINS_8DfsStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEENS_11VectorStateIS8_NSt3__19allocatorIS8_EEEEEEEE
N3fst15ArcIteratorBaseINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N3fst9VectorFstINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEENS_11VectorStateIS9_NSt3__19allocatorIS9_EEEEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEENSt3__19allocatorISB_EEEEEENS_10MutableFstISB_EEEE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEENSt3__19allocatorISB_EEEEEENS_10MutableFstISB_EEEE
N3fst10MutableFstINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEEEE
N3fst11ExpandedFstINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEENSt3__19allocatorISA_EEEEEE
N3fst7FstImplINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEEEE
N3fst10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEEEEE4LinkEEE
N3fst22MutableArcIteratorBaseINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEEEE
N3fst15ArcIteratorBaseINS_10ReverseArcINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEEEE
N3fst15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEENS_12GallicFactorIiS4_LS6_0EEEEE
N3fst9ImplToFstINS_19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEENS_12GallicFactorIiS5_LS7_0EEEEENS_3FstIS8_EEEE
N3fst19FactorWeightFstImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEENS_12GallicFactorIiS4_LS6_0EEEEE
N3fst9CacheImplINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEE
N3fst13CacheBaseImplINS_10CacheStateINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEENSt3__19allocatorIS8_EEEENS_17DefaultCacheStoreIS8_EEEE
N3fst18CacheStateIteratorINS_15FactorWeightFstINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEENS_12GallicFactorIiS5_LS7_0EEEEEEE
N3fst17StateIteratorBaseINS_9GallicArcINS_6ArcTplINS_12LogWeightTplIfEEEELNS_10GallicTypeE0EEEEE
-z
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
Could not convert
orthography
T@"NSString",R,N,V_orthography
Tq,R,N,V_tag
tagName
T@"NSString",R,N
frequency
TQ,R,N,V_frequency
pronunciations
T@"NSSet",R,N,V_pronunciations
Can't init factory :(
v32@?0@"NSString"8@"NSString"16^B24
Can't init LmeDataFactory: (unexpected exception)
Can't init LmeDataFactory: %s
could not get LME data :( %d
Failed to read quasar pronunciation cache from profile blob with error : 
\contact-first
\contact-middle
\contact-last
\contact-nickname
\company-first
\app-first
\jit
{ wordCount: %ld, trailingSilenceDuration: %ld, endOfSentenceLikelihood: %f, pauseCounts: ( %@ ), silencePosterior: %f, clientSilenceFramesCountMs: %f, clientSilenceProbability: %f, silencePosteriorNF: %f, serverFeaturesLatency: %f, eagerResultEndTime: %ld }
wordCount
Tq,N,V_wordCount
trailingSilenceDuration
Tq,N,V_trailingSilenceDuration
endOfSentenceLikelihood
Td,N,V_endOfSentenceLikelihood
pauseCounts
T@"NSArray",C,N,V_pauseCounts
silencePosterior
Td,N,V_silencePosterior
clientSilenceFramesCountMs
Td,N,V_clientSilenceFramesCountMs
clientSilenceProbability
Td,N,V_clientSilenceProbability
silencePosteriorNF
Tf,N,V_silencePosteriorNF
serverFeaturesLatency
Tf,N,V_serverFeaturesLatency
eagerResultEndTime
Tq,N,V_eagerResultEndTime
Tf,N,V_endOfSentenceLikelihood
Tf,N,V_silencePosterior
Configuration file %@ does not exist
RecogCpuTimeMs
AverageActiveTokensPerFrame
EARErrorDomain
speakingRate
averagePauseDuration
jitter
shimmer
pitch
voicing
 tokenName=%@, start=%f, silenceStart=%f, end=%f, confidence=%f, hasSpaceAfter=%d, hasSpaceBefore=%d, phoneSeq=%@, ipaPhoneSeq=%@
quasarToken
T{Token={basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}IIIfBB{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}},R,N,V_quasarToken
tokenName
T@"NSString",R,C,N
start
Td,R,N
silenceStart
confidence
hasSpaceAfter
TB,R,N
hasSpaceBefore
phoneSequence
ipaPhoneSequence
acousticFeatureValuePerFrame
T@"NSArray",R,C,N,V_acousticFeatureValuePerFrame
frameDuration
Td,R,N,V_frameDuration
speechRecognitionFeatures
T@"NSDictionary",R,C,N,V_speechRecognitionFeatures
acousticFeatures
T@"NSDictionary",R,C,N,V_acousticFeatures
<tokenSausage = %@, interpretationIndices = %@>
tokenSausage
T@"NSArray",R,C,N,V_tokenSausage
interpretationIndices
T@"NSArray",R,C,N,V_interpretationIndices
recognition
T@"_EARSpeechRecognition",R,C,N,V_recognition
preITNRecognition
T@"_EARSpeechRecognition",R,C,N,V_preITNRecognition
recognitionIsFormatted
TB,R,N,V_recognitionIsFormatted
isFinal
TB,R,N,V_isFinal
audioAnalytics
T@"_EARAudioAnalytics",R,C,N,V_audioAnalytics
quasarTokens
T{vector<quasar::Token, std::__1::allocator<quasar::Token> >=^{Token}^{Token}{__compressed_pair<quasar::Token *, std::__1::allocator<quasar::Token> >=^{Token}}},R,N,V_quasarTokens
quasarPreItnTokens
T{vector<quasar::Token, std::__1::allocator<quasar::Token> >=^{Token}^{Token}{__compressed_pair<quasar::Token *, std::__1::allocator<quasar::Token> >=^{Token}}},R,N,V_quasarPreItnTokens
tokens
T@"NSArray",R,C,N
preITNTokens
%d.%d
com.apple._EARSpeechRecognizer.recognition
com.apple._EARSpeechRecognizer.formatter
v32@?0@"NSString"8Q16^B24
v8@?0
Could not build recognizer: %d
dispatch.voc
lexicon.enh
token_s.enh
com.apple._EARSpeechRecognizer.recognition.workloop
Tokenized "
" to "
", "
en_US
Dictation
</s>
@"NSString"12@?0i8
v28@?0@"<_EARLanguageModelDataSource>"8f16^B20
Disabling eager to maintain compatibility with utterance detection
userProfileData
T@"NSData",C,N,V_userProfileData
jitProfileData
T@"NSData",C,N,V_jitProfileData
modelInfo
T@"_EARSpeechModelInfo",R,N
detectUtterances
TB,N,V_detectUtterances
concatenateUtterances
TB,N,V_concatenateUtterances
endpointStart
Td,N,V_endpointStart
recognizeEagerCandidates
TB,N,V_recognizeEagerCandidates
farField
TB,N,V_farField
highPriority
TB,N,V_highPriority
maximumRecognitionDuration
Td,N,V_maximumRecognitionDuration
recognitionReplacements
T@"NSDictionary",C,N,V_recognitionReplacements
recognitionConfidenceSubtraction
T@"NSDictionary",C,N,V_recognitionConfidenceSubtraction
leftContext
T@"NSArray",C,N,V_leftContext
inputOrigin
T@"NSString",C,N,V_inputOrigin
deviceId
T@"NSString",C,N,V_deviceId
refTranscriptForErrorBlaming
T@"NSString",C,N,V_refTranscriptForErrorBlaming
bluetoothDeviceId
T@"NSString",C,N,V_bluetoothDeviceId
userId
T@"NSString",C,N,V_userId
sessionId
T@"NSString",C,N,V_sessionId
version
samplingRates
T@"NSSet",R,N
tasks
language
phoneSetVersion
acousticProfileVersion
hash
TQ,R
superclass
T#,R
description
T@"NSString",R,C
debugDescription
error
T@"NSError",R,N,V_error
results
T@"NSArray",R,N,V_results
Quasar internal unknown exception
Quasar internal C++ exception: %s
Could not get thread info 
Final
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/EmbeddedAcousticRecognition-216.6/embeddedacousticrecognition/EmbeddedAcousticRecognition/EARSpeechRecognizer.mm
static_cast<size_t>(s) < _stateVec.size()
isfinite(log_prob)
GetArc
QSR_CRASH_ON_WARN
Quasar executor unknown exception
Quasar executor C++ exception: %s
Could not report recognition error: %@
v32@?0@"NSString"8@16^B24
Recognition was unsucessful
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/EmbeddedAcousticRecognition-216.6/embeddedacousticrecognition/EmbeddedAcousticRecognition/EARSdapiHelper.mm
<Unknown File>
Failed to initialize SDAPI
com.apple.siri._EARSpeechRecognitionAudioBuffer
Ending current audio stream.
sausage
T@"NSArray",C,N,V_sausage
nBestIndexes
T@"NSArray",C,N,V_nBestIndexes
confidences
T@"NSArray",C,N,V_confidences
nBestStrings
T@"NSArray",C,N,V_nBestStrings
nBestSourceIndexes
T@"NSArray",C,N,V_nBestSourceIndexes
originalRanks
T@"NSArray",C,N,V_originalRanks
LDContext
T{LDContext={map<quasar::Locale, double, std::__1::less<quasar::Locale>, std::__1::allocator<std::__1::pair<const quasar::Locale, double> > >={__tree<std::__1::__value_type<quasar::Locale, double>, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true>, std::__1::allocator<std::__1::__value_type<quasar::Locale, double> > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<quasar::Locale, double>, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true> >=Q}}}{optional<std::__1::set<quasar::Locale, std::__1::less<quasar::Locale>, std::__1::allocator<quasar::Locale> > >=(?=c{set<quasar::Locale, std::__1::less<quasar::Locale>, std::__1::allocator<quasar::Locale> >={__tree<quasar::Locale, std::__1::less<quasar::Locale>, std::__1::allocator<quasar::Locale> >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<quasar::Locale, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::less<quasar::Locale> >=Q}}})B}{optional<quasar::Locale>=(?=c{Locale={basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}})B}{optional<bool>=(?=cB)B}{optional<std::__1::vector<quasar::Locale, std::__1::allocator<quasar::Locale> > >=(?=c{vector<quasar::Locale, std::__1::allocator<quasar::Locale> >=^{Locale}^{Locale}{__compressed_pair<quasar::Locale *, std::__1::allocator<quasar::Locale> >=^{Locale}}})B}{optional<std::__1::map<quasar::Locale, double, std::__1::less<quasar::Locale>, std::__1::allocator<std::__1::pair<const quasar::Locale, double> > > >=(?=c{map<quasar::Locale, double, std::__1::less<quasar::Locale>, std::__1::allocator<std::__1::pair<const quasar::Locale, double> > >={__tree<std::__1::__value_type<quasar::Locale, double>, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true>, std::__1::allocator<std::__1::__value_type<quasar::Locale, double> > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<quasar::Locale, double>, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true> >=Q}}})B}{optional<std::__1::map<quasar::Locale, double, std::__1::less<quasar::Locale>, std::__1::allocator<std::__1::pair<const quasar::Locale, double> > > >=(?=c{map<quasar::Locale, double, std::__1::less<quasar::Locale>, std::__1::allocator<std::__1::pair<const quasar::Locale, double> > >={__tree<std::__1::__value_type<quasar::Locale, double>, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true>, std::__1::allocator<std::__1::__value_type<quasar::Locale, double> > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<quasar::Locale, double>, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true> >=Q}}})B}{optional<quasar::Locale>=(?=c{Locale={basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}})B}{optional<quasar::Locale>=(?=c{Locale={basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}})B}{optional<std::__1::map<quasar::Locale, double, std::__1::less<quasar::Locale>, std::__1::allocator<std::__1::pair<const quasar::Locale, double> > > >=(?=c{map<quasar::Locale, double, std::__1::less<quasar::Locale>, std::__1::allocator<std::__1::pair<const quasar::Locale, double> > >={__tree<std::__1::__value_type<quasar::Locale, double>, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true>, std::__1::allocator<std::__1::__value_type<quasar::Locale, double> > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<quasar::Locale, double>, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true> >=Q}}})B}},R
languagePriors
T@"NSDictionary",C,N,V_languagePriors
dictationLanguages
T@"NSSet",C,N,V_dictationLanguages
currentDictationLanguage
T@"NSString",C,N,V_currentDictationLanguage
wasLanguageToggled
T@"NSNumber",C,N,V_wasLanguageToggled
multilingualKeyboardLanguages
T@"NSArray",C,N,V_multilingualKeyboardLanguages
keyboardConvoLanguagePriors
T@"NSDictionary",C,N,V_keyboardConvoLanguagePriors
keyboardGlobalLanguagePriors
T@"NSDictionary",C,N,V_keyboardGlobalLanguagePriors
previousMessageLanguage
T@"NSString",C,N,V_previousMessageLanguage
globalLastKeyboardUsed
T@"NSString",C,N,V_globalLastKeyboardUsed
dictationLanguagePriors
T@"NSDictionary",C,N,V_dictationLanguagePriors
recentMessages
T@"NSArray",C,N,V_recentMessages
v32@?0@8@16^B24
call to empty boost::function
NoGradNorm
v16@?0^v8
token
T@"NSString",C,N,V_token
T@"NSArray",C,N,V_pronunciations
 correctedUtterances=%@
correctedUtterances
T@"NSArray",R,C,N,V_correctedUtterances
Could not load general voc
Sdapi has errored. Dying.
Could not tokenize
Could not get info from tokenized result
Failed TPToken_GetResultData with error code : 
Failed TPToken_DeleteResult with error code : 
No starting states!
error: %s
memory error: %s
Initialized profile service failed 
Initialization of profile service succeeded 
Initialization of textproc failed 
Initialization of textproc succeeded 
Loading of general voc failed for voc=
, svc=
 with value=
Loading succeeded for voc=
 and svc=
Loaded CP1252 voc
Loaded UTF8 voc
locale: 
modelVersion: 
languageId: 
emptyDeltaVoc: 
pgVoc: 
generalVoc: 
paramsetHolder: 
generalVocTP: 
generalSvcTP: 
lexiconTP: 
staticTokenTP: 
staticItnTP: 
NcsDatapackManager loaded locale 
Error: Voc does not contain the tokencoll collation table
oh no:
 gave us 
Could not open lexicon
Could not open ITN
Could not do TPToken_Open
com.apple.siri
sdapi
SDhAdapter
SDAdaptAlignment
SDAdaptMethod
SDAdaptResultCode
SDhAdaptAccumResult
SDhAdaptApplyResult
SDAdapterInfo
SDAdaptConfigAndStatsItem
SDAdaptAccumResultInfo
SDAdaptApplyResultInfo
SDhChannel
SDChannelType
SDChannelResultCode
SDChannelFileFormat
SDExtChanDataType
SDWaveEncodingType
SDSignalFormat
SDChannelInfo
SDExtChanServerEventResult
SDExtChanServerEventType
SDExtChanServerEventSink
SDExtChanClientEventType
SDExtChanClientEventSource
SDExternalChannel
SDhColl
SDhCorpus
SDhCorpusWord
SDCorpusDocumentInfo
SDCorpusInfo
SDFPExceptionType
SDMemStats
SDEnvContainerType
SDEnvSpec
SDhEnvHolder
SDEnvHolderSource
SDEnvHolderInfo
SDInteger
SDUnsigned
SDUnsigned16
SDArraySize
SDByte
SDBool
SDChar
SDWideChar
SDFileSpec
SDInteger64
SDUnsigned64
SDDuration
SDUttFrameDuration
SDRecogFrameDuration
SDMicrosecTime
SDCycleTime
SDUserData
SDUniqueId
SDMemoryErrorUserData
SDErrorUserData
SDLogUserData
SDSnapTime
SDPlatformInfo
SDInitializeResultCode
SDFinalizeResultCode
SDProgressCallback
SDReallocateArrayCallback
SDMemoryErrorHandler
SDErrorHandler
SDLogHandler
SDAccumCallback
SDApplyCallback
SDFileFormat
SDFileSupportType
SDFileCompatibility
SDSaveResultCode
SDhGlobalParam
SDParamType
SDParamQueryMode
SDhLattice
SDTokenType
SDRuleParseTokenType
SDConfidence
SDLatticeInfo
SDChoiceConfidencePredictors
SDChoiceInfo
SDTokenConfidencePredictors
SDToken
SDPartialToken
SDRuleParseToken
SDLatticeLink
SDChoiceTokenConfidencePredictors
SDChoiceToken
SDLmAdaptMode
SDLmClearLoadedType
SDhWeights
SDhTopicLmSlot
SDhFactoryCorrectiveLm
SDTopicWeight
SDWeightsInfo
SDLmScoreComponentType
SDDetailedLmScore
SDInitCheckRecord
SDInitTypeSize
SDhAdapterParamSet
SDhChannelParamSet
SDhConfidenceParamSet
SDhLatticeNBestParamSet
SDhLatticePostProbParamSet
SDhPrefiltererBuildParamSet
SDhPrefiltererSearchParamSet
SDhPronGuessParamSet
SDhSausageParamSet
SDhSearchParamSet
SDhSearchCrossLayerParamSet
SDhUserDeltaParamSet
SDParamSetContainerType
SDParamSetSpec
SDParamSetInfo
SDhParamSetHolder
SDParamSetHolderInfo
SDhParamSetParam
SDPrefiltererInfo
SDhPrefilterer
SDhPrefilterResult
SDProfileStyle
SDFunctionDemangleStyle
SDhRecognizer
SDPronGuessResultCode
SDRecognizerInfo
SDWordAlignInfo
SDhSegmentResult
SDSegmentationScores
SDPartialResultScore
SDhRepro
SDReproType
SDReproInfo
SDhRule
SDRuleItemType
SDRuleOperType
SDRuleInfo
SDRuleItem
SDRuleSpec
SDhSausage
SDSausageTokenType
SDSausageInfo
SDSausageToken
SDSausageChoiceToken
SDhSigProc
SDSigProcAdaptationDataType
SDSigProcInfo
SDhState
SDStateInfo
SDStateSpec
SDStateWordSpec
SDhTransducer
SDStateTransducerSpec
SDhUser
SDUserCovarianceType
SDUserInfo
SDhUtt
SDUttType
SDEnergyStatus
SDPitchStatus
SDFrameType
SDUttTimeStamp
SDUttInfo
SDUttFrameInfo
SDhUttFile
SDUttFileFormat
SDhVoc
SDCharType
SDVocTagSetType
SDVocInfo
SDhWord
SDWordSourceType
SDWordInfo
SDWordSpec
datapackDir
locales
name
modelVersion
languageId
language_model_set
acoustic_model_set
empty_delta_voc
pg_voc
general_voc
paramset_holder
textproc_model_set.model_voc
textproc_model_set.model_svc
textproc_model_set.lexicon
textproc_model_set.static_token
textproc_model_set.static_itn
dictation-languages
current-dictation-language
was-language-toggled
multilingual-keyboard-languages
keyboard-convo-language-priors
keyboard-global-language-priors
previous-message-language
global-last-keyboard-used
dictation-language-priors
com.apple.sequoia.tokenizer
mini.json
ncs/dispatch.voc
ncs/lexicon.enh
ncs/itn_s.enh
outputLocale
T@"NSLocale",R,N,V_outputLocale
EAR Initialization failed for custom-lm, error:
CustomLMBuilderErrorDomain
%@/oovProfile.txt
com.apple.ear
EARPSRAudioProcessor
delegate
T@"<EARPSRAudioProcessorDelegate>",W,N,V_delegate
configRoot
T@"NSString",&,N,V_configRoot
queue
T@"NSObject<OS_dispatch_queue>",&,N,V_queue
RowData
../libquasar/libkaldi/src/matrix/kaldi-matrix.h
static_cast<UnsignedMatrixIndexT>(i) < static_cast<UnsignedMatrixIndexT>(num_rows_)
text
T@"NSString",R,N,V_text
Tf,R,N,V_confidence
precededBySpace
TB,R,N,V_precededBySpace
followedBySpace
TB,R,N,V_followedBySpace
Failed TPLexicon_GetInfo()
could not format word sequence: 
could not get text of word sequence
could not get result
could not get result Alignment 
result could not be deleted
UnescapeDTFString
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/EmbeddedAcousticRecognition-216.6/embeddedacousticrecognition/EmbeddedAcousticRecognition/SdapiWrappers/SdapiITN.cpp
ch >= '0' && ch <= '9'
ch2 >= 'A' && ch2 <= 'F'
num >= 0 && num < 256
mt-quasar-config.json
com.apple.sequoia
Failed to parse mt-quasar-config.json
siri
v32@?0@"SFTranscriptionSegment"8Q16^B24
callbackQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_callbackQueue
framework
weight must be between 0 and 1 inclusive (weight=%f)
total weight must be between 0 and 1 inclusive (weight=%f, current total weight=%f)
totalWeight
Tf,R,N,V_totalWeight
Quasar Itn missing in configuration
T@"NSString",C,N,V_language
locale
T@"NSLocale",R,N,V_locale
T@"NSArray",R,N,V_tokens
lowConfidence
TB,R,N,V_lowConfidence
metaInfo
T@"NSString",R,N,V_metaInfo
silenceFramesCountMs
Td,N,V_silenceFramesCountMs
silenceProbability
Td,N,V_silenceProbability
silenceDurationMs
Td,N,V_silenceDurationMs
processedAudioMs
Td,N,V_processedAudioMs
EARSPG: SilencePosteriorGenerator Config file does not exist at %@
T@"<EARCaesuraSilencePosteriorGeneratorDelegate>",W,N,V_delegate
loggingDict
T@"NSDictionary",C,N,V_loggingDict
context
T@"_EARLanguageDetectorRequestContext",C,N,V_context
T@"NSDictionary",C,N,V_confidences
isConfident
TB,N,V_isConfident
Failed to allocate array
Failed to create feature provider
Error during prediction
EARLanguageDetector
_EARLanguageDetector init failed
The configuration file or models for _EARLanguageDetector are incorrect.
quasar
%{public}s
commandId
T@"NSString",R,C,N,V_commandId
tagSequence
T@"NSArray",R,C,N,V_tagSequence
commandTaggings
T@"NSArray",R,C,N,V_commandTaggings
text mapper entries must be unique
Overriding parameter: 
overrideParams
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/EmbeddedAcousticRecognition-216.6/embeddedacousticrecognition/EmbeddedAcousticRecognition/SdapiWrappers/SdapiG2P.cpp
paramType == SDPARAMTYPE_ENUM
Overrides JSON does not contain section for '
'.  Skipping.
Json config filename=
Overrides JSON does not exist in datapack; falling back to default overrides.
non_acoustic_default
dictation_cs50
dictation
Failed to load paramset holder
Loaded paramset holder file:  
Could not find file 
Could not laod Empty voc
Could not load PG voc
Mandatory config field missing
Pronguess paramset value is not valid.
Search paramset value is not valid.
Lattice-nbest paramset value is not valid.
FragmentWordsState
OptionalPronWordsState
SdapiG2P
nColls == 1
Generating pronunciations for orthography=
, spoken-form=
Orthography=
, Prons=
pronguess_paramset_name
search_paramset_name
lattice_nbest_paramset_name
napg_params
overrides
title_format
pronguess_overrides
search_overrides
lattice_nbest_overrides
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-16/lib/marisa/agent.cc
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-16/lib/marisa/agent.cc:13: MARISA_NULL_ERROR: str == NULL
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-16/lib/marisa/agent.cc:36: MARISA_STATE_ERROR: state_.get() != NULL
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-16/lib/marisa/agent.cc:38: MARISA_MEMORY_ERROR: state_.get() == NULL
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-16/lib/marisa/scoped-ptr.h
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-16/lib/marisa/scoped-ptr.h:19: MARISA_RESET_ERROR: (ptr != NULL) && (ptr == ptr_)
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-16/lib/marisa/grimoire/io/mapper.cc
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-16/lib/marisa/grimoire/io/mapper.cc:63: MARISA_NULL_ERROR: (ptr == NULL) && (size != 0)
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-16/lib/marisa/grimoire/io/mapper.cc:71: MARISA_STATE_ERROR: !is_open()
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-16/lib/marisa/grimoire/io/mapper.cc:72: MARISA_IO_ERROR: size > avail_
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-16/lib/marisa/grimoire/io/mapper.cc:99: MARISA_STATE_ERROR: !is_open()
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-16/lib/marisa/grimoire/io/mapper.cc:100: MARISA_IO_ERROR: size > avail_
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-16/lib/marisa/grimoire/trie/louds-trie.cc
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-16/lib/marisa/grimoire/trie/louds-trie.cc:73: MARISA_BOUND_ERROR: agent.query().id() >= size()
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-16/lib/marisa/grimoire/trie/louds-trie.cc:542: MARISA_MEMORY_ERROR: next_trie_.get() == NULL
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-16/lib/marisa/grimoire/trie/config.h
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-16/lib/marisa/grimoire/trie/config.h:59: MARISA_CODE_ERROR: (config_flags & ~MARISA_CONFIG_MASK) != 0
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-16/lib/marisa/grimoire/trie/config.h:101: MARISA_CODE_ERROR: undefined cache level
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-16/lib/marisa/grimoire/trie/config.h:121: MARISA_CODE_ERROR: undefined tail mode
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-16/lib/marisa/grimoire/trie/config.h:141: MARISA_CODE_ERROR: undefined node order
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-16/lib/marisa/grimoire/trie/header.h
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-16/lib/marisa/grimoire/trie/header.h:21: MARISA_FORMAT_ERROR: !test_header(ptr)
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-16/lib/marisa/grimoire/trie/../io/mapper.h
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-16/lib/marisa/grimoire/trie/../io/mapper.h:28: MARISA_NULL_ERROR: (objs == NULL) && (num_objs != 0)
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-16/lib/marisa/grimoire/trie/../io/mapper.h:30: MARISA_SIZE_ERROR: num_objs > (MARISA_SIZE_MAX / sizeof(T))
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-16/lib/marisa/grimoire/trie/../vector/bit-vector.h
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-16/lib/marisa/grimoire/trie/../vector/vector.h
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-16/lib/marisa/grimoire/trie/../vector/bit-vector.h:135: MARISA_FORMAT_ERROR: temp_num_1s > size_
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-16/lib/marisa/grimoire/trie/../vector/vector.h:202: MARISA_FORMAT_ERROR: (total_size % sizeof(T)) != 0
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-16/lib/marisa/grimoire/trie/../vector/vector.h:107: MARISA_STATE_ERROR: fixed_
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-16/lib/marisa/grimoire/trie/../vector/flat-vector.h
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-16/lib/marisa/grimoire/trie/../vector/flat-vector.h:134: MARISA_FORMAT_ERROR: temp_value_size > 32
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-16/lib/marisa/grimoire/trie/../algorithm/../../scoped-ptr.h
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-16/lib/marisa/grimoire/trie/../algorithm/../../scoped-ptr.h:19: MARISA_RESET_ERROR: (ptr != NULL) && (ptr == ptr_)
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-16/lib/marisa/trie.cc
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-16/lib/marisa/trie.cc:33: MARISA_NULL_ERROR: (ptr == NULL) && (size != 0)
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-16/lib/marisa/trie.cc:36: MARISA_MEMORY_ERROR: temp.get() == NULL
precompiled_charsmap is empty.
Normalizer model is not available.
length < 0
norm_to_org and normalized are inconsistent
Trie blob is broken.
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-14/src/util.h
'result' Must be non NULL
Cannot open 
input ifstream is null
Model file is broken
Model is not initialized.
Normalizer is not initialized.
output container is null
Empty piece is not allowed.
consumed index is out-of-range.
original index is out-of-range.
all normalized characters are not consumed.
output proto is null
NBestEncode returns empty result
nbest_size must be 0 < nbest_size <= 512 or nbest_size < 0.
/dev/urandom
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-14/src/sentencepiece_processor.cc
LOG(
Returns default value 
Unknown extra_option type
reverse
option 
 is not available.
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-14/ProtocolBuffers/src/google/protobuf/arenastring.h
CHECK failed: initial_value != NULL: 
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-14/ProtocolBuffers/src/google/protobuf/repeated_field.h
CHECK failed: (index) >= (0): 
CHECK failed: (index) < (current_size_): 
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-14/src/model_factory.cc
Unknown model_type: 
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-14/src/char_model.cc
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-14/src/unigram_model.cc
best_node
nbest_size >= 1. Returns empty result.
Too big agenda. shrinking
(num_nodes) < (trie_results.size())
No pieces are loaded.
Cannot build double-array.
No entry is found in the trie.
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-14/third_party/darts_clone/darts.h:703: exception: failed to resize pool: std::bad_alloc
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-14/third_party/darts_clone/darts.h:1141: exception: failed to insert key: negative value
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-14/third_party/darts_clone/darts.h:1143: exception: failed to insert key: zero-length key
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-14/third_party/darts_clone/darts.h:1157: exception: failed to insert key: invalid null character
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-14/third_party/darts_clone/darts.h:1162: exception: failed to insert key: wrong key order
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-14/third_party/darts_clone/darts.h:842: exception: failed to build rank index: std::bad_alloc
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-14/third_party/darts_clone/darts.h:1380: exception: failed to modify unit: too large offset
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-14/third_party/darts_clone/darts.h:1726: exception: failed to build double-array: invalid null character
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-14/third_party/darts_clone/darts.h:1728: exception: failed to build double-array: negative value
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-14/third_party/darts_clone/darts.h:1743: exception: failed to build double-array: wrong key order
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-14/src/sentencepiece_model.pb.cc
CHECK failed: !model_prefix_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
CHECK failed: !input_format_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
CHECK failed: (&from) != (this): 
sentencepiece.TrainerSpec
CHECK failed: !name_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
CHECK failed: !precompiled_charsmap_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
sentencepiece.NormalizerSpec
CHECK failed: !piece_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
sentencepiece.ModelProto.SentencePiece
CHECK failed: trainer_spec_ != NULL: 
CHECK failed: normalizer_spec_ != NULL: 
sentencepiece.ModelProto
CHECK failed: (n) >= (0): 
down_cast
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-14/ProtocolBuffers/src/google/protobuf/stubs/casts.h
f == NULL || dynamic_cast<To>(f) != NULL
CHECK failed: (&other) != (this): 
User defined symbol is not supported.
 is already defined.
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-14/src/model_interface.cc
!result.empty()
Cancelled
Invalid argument
Deadline exceeded
Not found
Already exists
Permission denied
Unauthenticated
Resource exhausted
Failed precondition
Aborted
Out of range
Internal
Unavailable
Data loss
Unkown code:
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-14/src/sentencepiece.pb.cc
CHECK failed: !surface_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
sentencepiece.SentencePieceText.SentencePiece
CHECK failed: !text_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
sentencepiece.SentencePieceText
sentencepiece.NBestSentencePieceText
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-14/src/bpe_model.cc
Invalid character length.
(index) >= (0)
(index) < (static_cast<int>(symbols.size()))
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-14/src/model_interface.h
Not implemented.
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-14/ProtocolBuffers/src/google/protobuf/message_lite.cc
CHECK failed: !coded_out.HadError(): 
parse
Can't 
 message of type "
" because it is missing required fields: 
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-14/ProtocolBuffers/src/google/protobuf/wire_format_lite.cc
CHECK failed: (value.size()) <= (kint32max): 
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-14/ProtocolBuffers/src/google/protobuf/io/coded_stream.cc
A protocol message was rejected because it was too big (more than 
 bytes).  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
CHECK failed: (buffer_size) >= (0): 
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-14/ProtocolBuffers/src/google/protobuf/generated_message_util.cc
Not implemented field number 
 with type 
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-14/ProtocolBuffers/src/google/protobuf/stubs/common.cc
This program requires version 
 of the Protocol Buffer runtime library, but the installed version is 
.  Please update your library.  If you compiled the program yourself, make sure that your headers are from the same version of Protocol Buffers as your link-time library.  (Version verification failed in "
This program was compiled against version 
 of the Protocol Buffer runtime library, which is not compatible with the installed version (
).  Contact the program author for an update.  If you compiled the program yourself, make sure that your headers are from the same version of Protocol Buffers as your link-time library.  (Version verification failed in "
%d.%d.%d
[libprotobuf %s %s:%d] %s
pthread_mutex_lock: 
pthread_mutex_unlock: 
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-14/ProtocolBuffers/src/google/protobuf/io/zero_copy_stream.cc
This ZeroCopyOutputStream doesn't support aliasing. Reaching here usually means a ZeroCopyOutputStream implementation bug.
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-14/ProtocolBuffers/src/google/protobuf/io/zero_copy_stream_impl_lite.cc
CHECK failed: (last_returned_size_) > (0): 
BackUp() can only be called after a successful Next().
CHECK failed: (count) <= (last_returned_size_): 
CHECK failed: (count) >= (0): 
CHECK failed: target_ != NULL: 
Cannot allocate buffer larger than kint32max for 
StringOutputStream.
CHECK failed: (count) <= (target_->size()): 
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-14/ProtocolBuffers/src/google/protobuf/extension_set.cc
Non-primitive types can't be packed.
can't reach here.
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-14/ProtocolBuffers/src/google/protobuf/arena.cc
CHECK failed: (min_bytes) <= (std::numeric_limits<size_t>::max() - kHeaderSize): 
Too many states on the stack. There may be a cycle.
LabelsToUTF8String: Bad code point: 
LabelsToUTF8String: Invalid character found: 
QuasarC
[QSR] FATAL %s
[QSR] ERROR %s
[QSR] WARN %s
[QSR] PRODINFO %s
[QSR] INFO %s
[QSR] DEBUG %s
[QSR] TRACE %s
Could not read the NNLM word map file 
Compile with USE_TENSORFLOW=ON to use TensorFlow models
found object in map for fst 
Could not open decoding-graph FST 
Reading FST: error reading FST header.
FST with arc type 
 not supported.
vector
const
ngram
ngram_quantized
reduced_transducer
reduced_acceptor
reduced_quantized_transducer
reduced_quantized_acceptor
squeezed_transducer
squeezed_acceptor
squeezed_quantized_transducer
squeezed_quantized_acceptor
Reading FST: unsupported FST type: 
Error reading FST (after reading header).
.espresso/code.nitroir
.espresso.net
HIT vs MISS: 
lm-score 
penultimate 
tropical
standard
ERROR
null
INFO
FstImpl::ReadHeader: source: 
, fst_type: 
, arc_type: 
, version: 
, flags: 
FstImpl::ReadHeader: Fst not of type "
FstImpl::ReadHeader: Arc not of type "
FstImpl::ReadHeader: Obsolete 
 Fst version: 
FATAL
TestProperties: stored Fst properties incorrect
 (stored: props1, computed: props2)
CompatProperties: mismatch: 
: props1 = 
, props2 = 
Fst::Write: No write stream method for 
 Fst type
Fst::Write: No write filename method for 
ConstFst::Read: Alignment failed: 
ConstFst::Read: Read failed: 
Could not align file during write after header
Could not align file during write after writing states
ConstFst Write write failed: 
Inconsistent number of states observed during write
Inconsistent number of arcs observed during write
Fst::UpdateFstHeader: write failed: 
Fst::Write: Can't open file: 
standard output
NGramFst::Read: Alignment failed: 
NGramFst::Read: Read failed: 
Malformed file
_quantized
ReducedFst::Read: Alignment failed: 
ReducedFst::Read: Read failed: 
reduced
_transducer
State 
 missing in new FST!
Too much data for reduced file format: 
Not enough bits for quantization: 
_acceptor
SqueezedFst::Read: Alignment failed before aligning states region: 
SqueezedFst::Read: Alignment failed before aligning arcs region: 
SqueezedFst::Read: Read failed after reading states and arcs: 
SqueezedFst::Read: Alignment failed before aligning final states region: 
SqueezedFst::Read: Read failed after reading final states: 
squeezed
Could not align file during write after states
Could not align file during write after arcs
Too much data for squeezed file format: 
Invalid format for boolean argument [expected true or false]: 
Use add() to append array elements
Leaves can't have children
Can't add a value dictionary-like to a tree that is already array-like
Can't add a value array-like to a tree that is already dictionary-like
nested erase() not implemented
expected value
expected key string
expected ':'
expected '}' or ','
void boost::property_tree::json_parser::detail::source<boost::property_tree::json_parser::detail::encoding<char>, std::__1::istreambuf_iterator<char, std::__1::char_traits<char> >, std::__1::istreambuf_iterator<char, std::__1::char_traits<char> > >::parse_error(const char *) [Encoding = boost::property_tree::json_parser::detail::encoding<char>, Iterator = std::__1::istreambuf_iterator<char, std::__1::char_traits<char> >, Sentinel = std::__1::istreambuf_iterator<char, std::__1::char_traits<char> >]
/AppleInternal/BuildRoot/Applications/Xcode.app/Contents/Developer/Platforms/AppleTVSimulator.platform/Developer/SDKs/AppleTVSimulator13.4.Internal.sdk/usr/local/include/boost/property_tree/json_parser/detail/parser.hpp
<unspecified file>
expected ']' or ','
unterminated string
invalid code sequence
invalid escape sequence
invalid codepoint, stray low surrogate
invalid codepoint, stray high surrogate
expected codepoint reference after high surrogate
expected low surrogate after high surrogate
expected 'true'
expected 'false'
expected 'null'
expected digits after -
need at least one digit after '.'
need at least one digit in exponent
garbage after data
cannot open file
void boost::property_tree::json_parser::read_json(const std::string &, Ptree &, const std::locale &) [Ptree = boost::property_tree::basic_ptree<std::__1::basic_string<char>, std::__1::basic_string<char>, std::__1::less<std::__1::basic_string<char> > >]
/AppleInternal/BuildRoot/Applications/Xcode.app/Contents/Developer/Platforms/AppleTVSimulator.platform/Developer/SDKs/AppleTVSimulator13.4.Internal.sdk/usr/local/include/boost/property_tree/json_parser.hpp
void boost::property_tree::json_parser::write_json(const std::string &, const Ptree &, const std::locale &, bool) [Ptree = boost::property_tree::basic_ptree<std::__1::basic_string<char>, std::__1::basic_string<char>, std::__1::less<std::__1::basic_string<char> > >]
ptree contains data that cannot be represented in JSON format
void boost::property_tree::json_parser::write_json_internal(std::basic_ostream<typename Ptree::key_type::value_type> &, const Ptree &, const std::string &, bool) [Ptree = boost::property_tree::basic_ptree<std::__1::basic_string<char>, std::__1::basic_string<char>, std::__1::less<std::__1::basic_string<char> > >]
/AppleInternal/BuildRoot/Applications/Xcode.app/Contents/Developer/Platforms/AppleTVSimulator.platform/Developer/SDKs/AppleTVSimulator13.4.Internal.sdk/usr/local/include/boost/property_tree/json_parser/detail/write.hpp
write error
0123456789ABCDEF
thread constructor failed
 000000000000
Could not make Unicode regex: 
Could not open BreakIterator: 
Config file must be loaded before calling this method.
File 
 not found.
remove child: 
override config version << 
 is incompatible with main config version: 
override config type << 
 is not the same as main config type: 
model-info.version
override config language [
] is not the same as main config langauge [
We only support override of speech model.
This method can be called only once throughout the lifetime of this object.
Reading json file 
Config override: 
Set json config file path to 
failed to parse json file 
, error: 
version-major
version-minor
Config file version is missing. 
Reading version 
 as 15.0
Version of currently loaded config file: 
 Supported config file version: 
 (minimum supported version: 
Config file version 
 is lower than the minimum supported version 
 is higher than the supported version 
 is lower than the current supported version 
). Please update the config file ASAP.
Config file does not have speech model-info node.
Config file does not have mt-model-info node.
Config file does not have model-info node.
model-info
mt-model-info
Only one of model-info and mt-model-info can exist in the config
model-info.language
model-info.os-types
Empty model-info.os-types
model-info.sampling-rates
Empty model-info.sampling-rates
model-info.tasks
Empty model-info.tasks
model-info.phoneset-version
model-info.acoustic-profile-version
lme-create.template-map
ACE category name 
 occurs twice in lme-create.template-map
lme-create.name-enumerator-map
Quasar template name 
 occurs twice in lme-create.name-enumerator-map
type
g2p.model-version
model-info.hybrid-endpointer-version
Error parsing model-info 
mt-model-info.version
mt-model-info.source-language
mt-model-info.target-language
mt-model-info.language-pairs
invalid language pair: 
Non source and target language pair.
mt-model-info.tasks
Empty mt-model-info.tasks
mt-decoders.
missing decoder config for task 
language-pair-specific-settings
invalid language pair name: 
missing specific setting, this should not happen.
source language 
 using 
' tokenizer.
target language 
Error parsing mt-model-info 
hybrid-client-configs
hybrid-client-configs.hybrid-ep-thresholds
hybrid-client-configs.hybrid-ep-extra-delay-frequency
%s : %s
%s : %d
%s : %f
parameter [
] is not in original config.
] is not a leaf node.
-file
nt-fsts.\NT-bizname
g2p-blacklist
-directory
-ark-file
ark:
-file-list
rule-fst
Could not find required name "
Parameter "
" requires minimum version 
 but config version is 
" requires maximum version 
Ignoring unrecognized option 
Required parameter "
" not found
Prefix must end with '.' : 
Incompatible system config version. Needs to be >= 
 to use 
Incompatible system config version. Needs to be <= 
Invalid integer option "
Invalid floating-point option "
Parameter name 
 already registered
boost::bad_format_string: format-string is ill-formed
boost::too_many_args: format-string referred to fewer arguments than were passed
boost::too_few_args: format-string referred to more arguments than were passed
Invalid UTF8 string:
Could not extract UTF8 length: 
Could not extract UTF8 chars: 
Regex compilation failed for:
Failed to initialize regex: 
Could not set regext text: 
Could not create space text: 
Error getting capacity for splitting text: 
Could not set regex text: 
Could not set region: 
Could not trim: 
Could not create input text: 
Could not create to text: 
Could not replace text with regex: 
Could not get utf-8 string: 
) Could not decode UTF8: 
) Could not set regex input: 
) Failed to apply regex: 
Could not extract UTF16 length: 
Could not extract UTF16 chars: 
BreakIterator construction failed: 
Texture coordinates (
) out of range
Bitmap coordinates (
) out of bounds
Internal error, unexpected pixel size 
Cannot open bitmap file 
Unexpected magic 
Bitmap width must be positive but was 
Bitmap height must be positive but was 
Whitespace expected before binary data
PGM header suggests different file size than actual size, expected=
 actual=
Could not map file 
 into memory
Mapped a PGM bitmap fileName=
 width=
 height=
 maxGreyValue=
Detected latency overflow, change to int_max.
dup stat: token=
, source=
Empty tokenStrings received
Empty tokenStrings[0] received
Token=
 found in Lexicon, prons=
Skipping invalid token=
 found in PronCache
Failed to generated pronunciations for word=
in backoff window, skip updating pron cache for token 
Invalid code point, 
Invalid UTF-8, 
Not enough space, 
input contains | which is the separator for g2p model.
[a-zA-Z]\.[a-zA-Z]
[a-zA-Z]-[a-zA-Z]
^[a-zA-Z]+[0-9]+$
([0-9])
num-best
PhonetisaurusG2P Config: model=
, nBest=
g2p model file doesn't exist, or it's a directory: 
Phonetisaurus failed to load model!
Empty token received
Increase nbest, and try again. nbest=
beam
lm-weight
max-seq-length
max-seq-length-veto-factor
veto-factor
lm-model-file
PDecG2P Config: model=
, beam=
, lmWeight=
, maxSeqLength=
, vetoFactor=
, lmModelFile=
, maxLengthVetoFactor=
Failed to read lm fst from: 
Reducing maximum sequence length from 
 because of max-seq-length-veto-factor
Apply BPE source : 
Apply BPE target : 
</w>
<space>
enable
Failed to read model from 
Already mapped from a file
Failed to read model
Using the special symbols ids <unk>=
, <s> = 
, </s> = 
Applying log to output probs 
Has BPE Model
No embedded BPE Model
Configuring multilang decorator
<HasPhraseBook>
# PhraseBook entries 
No phrasebook in the model
Reading phrasebook
<PhraseBook>
num_entries 
</PhraseBook>
# of keys 
Failed to create unicode string for "
Failed to create UTF-8 string: 
ReplaceFst: inconsistent arc iterator flags
Re-decode without LM 
Couldn't find symbol 
 or <unk> UNK symbol
Input : 
Greedy decoding
Beam decoding
input_batch_idx: 
hyp_idx: 
Final word in hyp list
Nothing left in heap
Beam decoder hit maximum sequence length
Pruned all hyps, nothing left to expand
dropping worse identical hyp; score-diff: 
using lattice state:
Adding invalid arc 
At output position 
, # surviving hypotheses: 
No hyps finished, setting 
 partial hyps to final
Setting longest vetoted translation as best 
# of cached states 
 diff 
Didn't extract any paths from the lattice
Initializing NbestCompare. alpha: 
, sigma: 
PTree::Error, Error reading JSON config file: 
PTree::JsonParseError, Error reading JSON config file: 
engine-type
creating PhonetisaurusG2P object
creating PDecG2P object 
Unknown quasar G2P engine type: 
PNSR
PDEC
Version mismatch for PronChoice
Unknown format for pronunciation string
Empty pronunciations for one of the tokens. Exiting with 0 pron combinations.
pron combination = 
, logWeight = 
Unrecognized commandId=
\all-caps
\all-caps-on
\all-caps-off
\cap
\spelling-cap
\caps-on
\caps-off
\no-caps
\no-caps-on
\no-caps-off
\no-space
\no-space-on
\no-space-off
\new-line
\new-paragraph
.\period-paragraph
\tab-key
\no-break-space
\spelling-no-break-space
\space-bar
\backslash
\spelling-backslash
ucasemap_utf8ToUpper failed
ucasemap_utf8ToTitle failed
action-fst-directory
label-tsv-file
convert-to-plain-text-after-label
spaceApplyDefault.fst
spaceApplyRemoveBefore.fst
rewriteApplyCapitalize.fst
rewriteApplyDefault.fst
default-backoff-label
Missing supported tasks.
shared-num-nn-components
InverseTextNormalizer already initialized.
punctuation
.punctuation
Initialized ITN
Invalid line in compound word list file
chunk overlap is bigger than chunk length.
cluster-id-file
File containing cluster Ids.
compound-word-file
no-title-casing-file
File with list of words that should not be title-cased
token-boundary-id
Token boundary symbol ID
word-sense-file
File containing list of word senses.
align-right-preitn-tokens-file
File storing list of pre-ITN tokens that should map to next post-ITN token.
regex-feat-file
TSV file storing regex-to-feature map.
double-regex-feat-file
guard-markers-file
TSV file storing guard markers that prevent ITN.
supplement-config-file
supplemental json file which may contain punctuation and other frequently updated paramters such as max-num-feats
chunk-length
Number of tokens in each chunk
chunk-overlap
the number of overlap tokens between two chunks
entity-tsv-file
Duplicate occurrence of entity "
Unknown start entity "
Unknown end entity "
Initialized EntityTransformer.
inputToken=
 label=
outputToken=
Sublabel application 
 failed for token 
Applying 
 overrides
start entity <
end entity <
Encountered orphan start entity 
This cannot happen
inputToken="
" label=
 concateFst="
ITN failed.
Missing TokenBoundary label
Something that should never happen, just happened. Debug me please...
Regex match for 
) with label 
Preprocessed token: 
tokenNum=
 tokenId=
 word=
 tag=
 tagIsSense=
index=
 token=
 commandId=
French
dictionary
eats
five
hotdogs
Tantor
mighty
fine
elephant.
" ~ 
" -> 
Merging pre-token 
 to next post token
 to previous post token
Tantor-ITN numInputTokens=
 numOutputTokens=
 numOverrides=
 input="
 output="
 overrides=
 preToPostTokMap=
ITN failed
WARNING: No concatenation point found
Detected size mismatch between chunkAlignment=
 and currentPostItnChunk=
chunk_tokens_str: 
chunk_post_itn: 
chunk_alignment: 
result_post_itn: 
result_alignment: 
token sequence time is not monotonic increasing.
reset token timing.
unordered_map::at: key not found
creating PDecTranslatorFactory
Unknown mt engine type: 
fallback
unknown phrase-book-mode: 
integrated
rescore_bpe
rescore_word
unknown lm-mode: 
length
gnmt
unknown 'norm-mode': 
specifying both 'norm-cost' (old parameter name) and 'norm-mode' (new name) at the same time is not allowed.
nbeam
best
finished_score
unknown stop-mode: 
prefilter input
use shared phrasebook: 
load phrasebook: 
Cache phrasebook: 
failed loading phrasebook: 
Model file name not supplied (configuration value 'model-file' is empty)
PDecTranslatorBlock does not support stream-decoding
Invalid entry terminating ReadRaw : 
 phrasebook entries
Failed to create ICU Transilerator for scripts : 
Extract quality transform
Failed to extract quality transform
Quality transform : 
remove-softmax must be set for quality transform, setting to true
Reading tag filters from : 
<DNFList>
Skipping tag 
Input hammer has 
 known entries it will remove
Add tag 
 to pass lists
Not configured for locale : 
 on line 
Input hammer has DNF 
 known entries across 
 locales it will leave in place
RemoveUnderScores = 
, StripTokenLocales = 
, # of entries 
</DNFList>
<RemoveUnderScores>
<StripTokenLocales>
Nbestlist cannot be null
Total # of phrasebook matches : 
Word level LM re-scoring
Applying confidence scores to n-best list
Decoder beam (
) should not be negative.
Decoder confidence threshold (
) should be in the range [0, 1000].
Decoder maximum nbest list size (
Locale not in pass list 
Input hammer did not change anything 
Input hammer removed tags 
model does not support the use of src/tar tags
A Both type TagFormat requires non-empty source and target tags
SrcTag cannot be empty for TagFormat::Src
TarTag cannot be empty for TagFormat::Tar
<src-
> <tar-
Source locale 
, Target locale 
 source tag 
 target locale 
, # of phrasebooks 
BPE input 
 not contained in BPE encoder 
 mapping to 
FindInPhraseBooks # 
Phrasebook fallback match
Phrasebook locale match
, phrasebook idx=
Looking for UNK symbol 
UNK label : 
No UNK symbol in translation model vocabulary
Language model does not have output symbol table
LM UNK ID 
Language model does not have OOV symbol : 
 in LM
Word lookup failure : 
 (label=
Old Cost = 
, New cost = 
, Hyp = 
 finalcost=
Error converting BPE to word list 
Not applying BPE to target
Alignment cost 
 "source":"decoder"
input
output
cost
norm_cost
, "status":"vetoed"
, "status":"stopped"
, "status":"phrasebook_exact"
, "status":"phrasebook_fuzzy"
, "status":"fine"
, "romanization":"
, "word confidences":"
, "subword confidences":"
, "sentence confidence":"
, "low confidence":"
, "subword string":"
Illegal value for 'phrase-book-mode' in 'PDecPhraseBookBlock': 
mt-decoders
blocks
graph
block-definitions
block
block-type
phrase-book-mode
missing source or target locale, skipping parsing language-pair-specific-settings
block definition '
' (referenced in '
]') not found
<overlay-settings>
phrase_book_only
disable
Changing phrase book mode using command line overlay causes use of previously ignored translation model file: 
.graph
source-token
target-token
missing source or target locale!
Unknown block definition name: 
source-locale
target-locale
<constructor argument>
missing source or target locale, skipping parsing 
PDecPhraseBookBlock
PDecTranslatorBlock
Config file does not support task: 
Config file does not support language pair: 
<default>
Malformed phrasebook line:
Unicode error (ICU): 
failed to open phrasebook file 
Loading phrasebook: 
# of keys: 
status
phrasebook_exact
1000
 1000
word confidences
sentence confidence
low confidence
simple tokenizer in: 
simple tokenizer out: 
Only (global) replacement operations are supported, got 
 with specifier 
read expression: "
", mapping to "
Simple tokenization read in 
 regular expressions
tag [
] is not recognized; panicking, cannot produce metaValue
Failed adding meta info, original metaInfo 
Mapping file '
' is not found
decode
decode-api
Unknown sentence piece action: 
SentencePiece error while loading file '
sentencepiece encoder input
sentencepiece encoder output
sentencepiece decoder input
sentencepiece decoder output
subword confidences
 config:
error parsing Json <
AmbiguityAnnotatorBlock::handleSourceInput() called twice for the same utterance
AmbiguityAnnotatorBlock::handleSourceInput() called called with empty input
AmbiguityAnnotatorBlock::handleNbestInput() called twice for the same utterance
AmbiguityAnnotatorBlock::handleNbestInput() called called with empty input
empty input received
source
ambiguity annotator block received invalid input name: <
senses
sense ID
definition
source match
source index
source length
target match
target index
target length
lexid
noun
Configuration needs either 'romanizer' or 'pron-guide-model-file'
romanization
    
Multiple connections to receiving block input name: 
output port not connected: 
 Config:
Unsuported merge-style: 
ProcessingSource
ProcessingSink
MergerBlock
ProcessingGraph: Unknown blocktype '
', did you forget to call 'registerBlockType'?
final
graph-output
graph-input
Block ID allready exist: 
Creating graph connection: 
Unknown block identifier in 'receives-from': 
No config block allowed for '
updateConfiguration called for nonexisting block id: 
receive-from
Invalid connection syntax in: 
Block has no outgoing connections: 
' can have no outgoing connections
Block has no incomming connections: 
' can have no incomming connections
 graph connectivity errors
Invalid block index: 
merge-style
type of merge performed
mt model file name
maximum number of active beams in pruning
as-beam
as_beam pruning value
rs-beam
rs_beam pruning value
confidence-threshold
confidence threshold
path to language model file
language model weight
MT defcoding veto factor
veto-factor-exclude-input-tags
MT decoding, exclude input tags in  veto factor computation
veto-factor-num-external-input-tags
MT decoding, num externally provided tags to exclude for veto factor
norm-costs
normalize costs in mt decoding? (backward compatible version)
norm-mode
normalize costs in mt decoding? (off|length|gnmt)
norm-alpha
normalization alpha parameter
norm-sigma
normalization sigma parameter
unk-replace
maximum decoding sequence length
lm-mode
lm mode
confidence-model-file
confidence model file
stop-mode
stop mode in mt decoding (nbeam|best|finished_score)
block-control
flow control for block sequence (<empty>|optional|optional_stop_on_success)
shortlist-lang-pair
language pair used for shortlist
shortlist-cond-n
top n in condition table used for shortlist
shortlist-freq-n
top n in freq words used for shortlist
nbest
maximum entries in nbest list to produce (default to same as 'beam'}
stop-mode-finished-score-beam
number of finished hypotheses considered for finished score stop mode (default: 1)
stream-buffer-n
stream decoding initial read length (effective read buffer)
stream-block-m
stream decoding read/write length (block size for looped read/write calls)
stream-stabilize
stabilize partial stream decoding results after each read/write block
use memory map
phrase book mode
pron-guide-model-file
pron guide model file
pron-guide-preprocessing
pron guide preprocessing (splitting into characters and <space> insertion)
romanizer
phrasebook-case-sensitve
case sensitive phrase book?
filter-list-file
filter list file
pb-file-list
phrase book file list
maximum entries in nbest list to produce
reset-meta-info
reset metaInfo json
source locale
target locale
source tag for multilingual model
target tag for multilingual model
AlternativesProcessorBlock
filter-redundant-tags
flag on whether to filter out or keep hypotheses with redundant tags
tag-to-meta-json-file
a json file that contains a mapping between tags and their corresponding string in the meta info 
AmbiguityAnnotatorBlock
disambiguation-dictionary-file
disambiguation dictionary file
case-sensitive
used to disable phrase book block
SimpleTokenizerBlock
tokenizer-file
tokenizer regular expression replacement (sed / perl -p style)
PhraseBookBlock
InputHammerBlock
RomanizerBlock
SentencePieceBlock
sentence-piece-file
sentence piece model file
action
encode
action to perform (encode/decode/decode-api)
 ||| 
Input not monotonic
Adjacent 'ID'
Adjacent 'DI'
Unexpected character
Invalid alignment string
String is all I's, all D's, or empty
Output not monotonic
Coding error: SyncDecoder 
 has already been initialized.
keyword-spotting-decoder
Ignoring unknown SyncDecoder type "
" in "
Recognition will crash if you try to use it
region[
Rejected client conf network due to invalid HatText encoding
Stored conf network!
Must first call init() for 
 before calling createDecodable().
Building Decodable 
Unknown decodable type "
matrix-scaled
matrix-scaled-mapped
matrix-scaled-mapped-tm
ctc-online-kwd
dummy
nnet1-lazy
am-file
Acoustic model (transition model) filename (only used for lattice stuff)
am-scale
Scaling factor for acoustic likelihoods
tid2pdf-file
Text file of ints representing PDF IDs for transition IDs 0, 1, 2, ... 
Read transModel
Using TID2PDF file
Created OnlineDecodableMatrixScaled decodable
decodable type "
Acoustic model (transition model) filename
Created OnlineDecodableMatrixScaledMapped decodable
OnlineDecodableMatrixScaledMapped: mismatch, matrix has 
 rows but transition-model has 
 pdf-ids.
tm-weight
Weight factor for tm likelihoods
Created OnlineDecodableMatrixScaledMappedTm decodable
Created OnlineDecodableIdenticalMatrix decodable
compute-sil-model-posteriors-from-realign-model
True if penultimate activations from realign model are the input to the silence model, otherwise use the penultimate activations from the main acoustic model
workspace-size-kb
Workspace size in Kilo Bytes
realign-model-file
Name of nnet model file for computing posteriors for later realignment of 1st/2nd pass lattices
realign-class-frame-counts-file
File containing vector with frame counts of pdfs to compute log-priors. This is the same as class-frame-counts, but allows paths that are relative to the json config file (class-frame-counts requires absolute paths). If class-frame-counts is also specified, this param will override it.
compute-realign-model-posteriors-from-penultimate
True if penultimate activations from main acoustic model are the input to the realignment model, otherwise use the same features as the main acoustic model as input
skip-blanks-threshold
Threshold for skipping frames with a CTC trained acoustic model, applied to posterior probability of the blank symbol
blank-pdf-id
Pdf-id of blank symbol of CTC trained acoustic model, used in combination with skip-blanks-threshold
Read mapped nnetTransf
Read nnetTransf
Read pdfPrior
Read model file for computing realignment posteriors=
Created OnlineDecodableNnet1LazyDecodable decodable
Parameters realign_model_input_is_penultimate_ and sil_model_input_is_realign_penultimate_ cannot both be true at the same time.
Realignment model (nnet_realign) must be set in order to pass its penultimate activations to the silence model.
skip_across_batch does not work with skip_blanks_threshold or nnet_realign
supported by OnlineDecodableNnet1Lazy. Use a separate splice 
OnlineDecodableNnet1Lazy. Use a separate splice operation to 
Parameters for 
 have already been registered.
Must call init() for 
 before calling run().
Running Decoder: 
 failed.
Time
FirstPassCpuMs
stabilizer-averaging-period-ms
Duration in milliseconds over which to stabilize partial results
stabilizer-minimum-word-seen-ms
Minimum duration in milliseconds that word must be recognized before it is considered stable
Linear Output Failed
Skipping calculateNBest since we already did it (eager)
nbest size=
symTableId=
, but decoderChainOutput->lmeStatus.size()=
empty partial results!
empty or mismatched number of timestamps for final result
partial result: 
, partial result timestamp: 
, partial reference: 
partial_results_toggle_count=
partial_results_average_feedback_lag=
faster_partial_results_toggle_count=
faster_partial_results_average_feedback_lag=
Building Decoder 
lattice-biglm-faster
lattice-scale-rescore
lattice-word-aligner
lattice-lm-rescore
lattice-realigner
error-blamer
lattice-confidence
lattice-faster
seeva-decoder
seeva-step-decoder
seeva-step-biglm-decoder
seeva-greedy-decoder
confusion-network-combiner
phonetic-match
fingerprint-detector
audio-analytics-decoder
watermark-detector
audio-analytics-only
lattice-rnn-mitigator
lattice-confidence2
watermark-detector2
Unknown decoder type "
No word boundary info found. Cannot give proper phone sequence.
Phone sequencing failed; ran out of words for unknown reasons. 
Lattice word alignment and confidence computation will also fail. 
PLEASE FILE A RADAR
Phone sequencing failed; Ran out of phones, probably because 
the last word got clipped in the audio. 
Lattice word alignment and confidence computation will also fail.
 was not specified in word-boundary file (or options)
error-blaming-report
failure-reason
empty CTC keyword
wait-milliseconds
The number of milliseconds to wait for a confusion network to become available in the cache
No confusion network cache found.
No confusion network found in decodeChainOutput. Doing nothing.
This doesn't work when utt detect/concatenation is enabled. Doing nothing.
No confusion network found in cache. Doing nothing.
Detected phrases in confusion network - backing off to flattened 1-best (this is OK)
Combined sausage is empty. Doing nothing.
Tokens not monotonic and have been corrected.
Number of output lattice states is getting out of hand, aborting conversion
Could not find arc for input_state 
 in LM. Failed to reconstruct lattice (incompatible LM?).
Acoustic model file
tree-file
Tree file
phone-syms-file
Phone table file
optional-silence
Optional silence phone
silence-prob
Silence probability (0.0 to 1.0)
Decoding beam
retry-beam
Fall-back decoding beam
Word boundary file
align-lattice-expand-limit
Lattice expansion limit when doing word alignment(0 for none)
reconstruct-lattice-expand-limit
Lattice expansion limit when doing lattice reconstruction(0 for none)
big-g-fst-file
Map FST/NNLM models into memory (requires aligned models)
Negative SmallG FST filename
raw-smallg-fst-file
SmallG FST (with no phone or word loops for nonterminals) filename
extended-report
Set to false if only the concise error-report should be generated.
lm-context-length
Language model context length (e.g. 4-gram has length 3)
overlap-percentage
Required overlap in percent of two regions in reference and hypothesis to be viewed as the same region.
json-output-format
True if error reports should be formatted as JSON file.
You have not specified unpronounced-word-file. This will prevent you from using class LM tags 
like \CS-GeoBizName-start and \CS-GeoBizName-end in the ref transcription for error blamer. 
Created lexicon FST
WORD-DIS-
 phone words (including word disambig symbols) in base word table
inv-g-fst-file is now ignored because it does not work with class LMs. 
Please use raw-smallg-fst-file.
The number of big FST LMs + NN LMs doesn't match the number of weights (FST LMs + NN LMs)
Word alignment failed.
Word alignment lattice empty.
Lattice reconstruction failed.
 not found in symbol table(s).
 has word ID 0.
Ref transcription word: 
, ID: 
HypoStartFrame
HypoEndFrame
RefStartFrame
RefEndFrame
RefLmCost
HypoLmCost
RefAmCost
HypoAmCost
RefWords
HypoWords
Confusions
RefModel
HypoModel
RefPhone
HypoPhone
Word
StartFrame
EndFrame
LmCost
AmCost
RefTotalCost
HypoTotalCost
RefGraphCost
HypoGraphCost
Attributes
ErrorRegions
PresentInLattice
RankInLattice
Recoverable
AmScaleFactorToRecover
ReferenceInfo
No reference transcription provided.
no first pass LM defined
total number of LMs is 
, but the number of interpolation weights is 
Left context labels not yet implemented.
Failed to map compound LME words. LME data is probably corrupt.
Could not map all words to symbol ids.
failed-words
Problem creating decoding graph for utterance
Encountered problem while creating decoding graph for reference.
Retrying utterance with beam 
Problem decoding utterance for forced alignment.
Encountered problem while force aligning the reference.
Determinization finished earlier than the beam
Word alignment failed for reference lattice. Aborting error-blaming.
Encountered problem while word-aligning the reference lattice.
Reference lattice reconstruction failed. Aborting error-blaming.
Encountered problem while reconstructing the reference lattice.
Word alignment failed for hypothesis lattice. Aborting error-blaming.
Encountered problem while word-aligning the hypothesis lattice.
Hypothesis lattice reconstruction failed.
Encountered problem while reconstructing the hypothesis lattice.
LM rescoring in error-blamer was not successful.
LM rescoring was not successful.
bigG
Lattice reconstruction with smallG failed.
Encountered problem while trying to reconstruct lattices with smallG.
smallG
transition-scale
Scale of transition probabilities (excluding self-loops)
self-loop-scale
Scale of self-loop vs. non-self-loop probability mass 
Reorder transition ids for greater decoding efficiency.
rm-eps
Remove [most] epsilons before minimization (only applicable if disambig symbols present)
ivector file 
 cannot be opened
Landmark hash ark file 
imposterMean=
imposterStd=
Name of nnet file
Threshold to apply to ivector score
ivector-fingerprint-ark-file
ark file with ivectors for fingerprints
ivector-imposter-ark-file
ark file with ivectors with imposters
trigger-preceding-max-ms
Maximum amount of audio used before trigger phrase
trigger-trailing-min-ms
Minimum amount of audio used after trigger phrase
trigger-trailing-max-ms
Maximum amount of audio used after trigger phrase
ivector-threshold
ivector-score-bias
Bias to apply to ivector score when combining with lmark
lmark-hash-strategy
Hashing strategy (e.g. 3x3)
lmark-hash-start-idx
Feature start idx for hashing
lmark-hash-end-idx
Feature end idx for hashing
lmark-hash-fingerprint-ark-file
ark file with landmark hash vectors for fingerprints
lmark-hash-imposter-ark-file
ark file with landmark hash vectors for imposters
lmark-min-len
Min num frames for computing similarity between landmark hash vectors
lmark-max-len
Max num frames for computing similarity between landmark hash vectors
lmark-threshold
Threshold to apply to landmark similarity
imposter ivector file 
 is empty
fp-ivectors=enabled
Unrecognized hash strategy string 
Landmark params not properly set
fp-landmark=enabled
Invalid fbank dims. 
Expected: 
 Got: 
Encountered zero iVector
Speaker embedding=
Index=
 similarity=
 exceeded threshold=
Did not match any known fingerprints
Trigger phrase not detected
Not enough audio to make a decision.
Hash strategy 
 is not implemented
Landmark hash=
] Unnormalized landmark hash score: 
] T-normalized landmark hash score: 
FingerprintDetector not run on input origin 
Error: Utterance features were improperly cached.
Zero-length utterance. Rejecting utterance.
Error: getAudioProcessingWindow failed
Processed Frames: 
Best i-vector match score=
 index=
Adjusted i-vector score=
 thres=
FingerprintAlgo
FingerprintIndex
FingerprintScore
FingerprintDetected
FingerprintDetected=
 MatchingIndex=
 matchingScore=
Minimum CMN window used at start of decoding (adds latency only at start). Only applicable if center == false, ignored otherwise.
norm-vars
If true, normalize variance to one.
center
If true, use a window centered on the current frame (to the extent possible, modulo end effects). If false, window is set based on "cmn-window" and "lookahead".
lookahead
Number of frames to look ahead for online CMN. Ignored if center==true.
This doesn't work when utt detect is enabled. Doing nothing.
Lattice is null. Doing nothing
Lattice is empty. Doing nothing
Best conf result sessionId: 
 result: 
WORD_EMBED
IS_LME
LME_ID
IS_SIL
NUM_PHONES
AC_COST_UNPUSHED
IN_BEST_PATH
AC_COST
GRAPH_COST
NUM_FRAMES
LOG_POSTERIOR
LIN_POSTERIOR
Unknown feature type: 
Comma-separated list of arc features. Example: "BAG_OF_PHONES,KEYWORD:hey,KEYWORD:Siri,LM_SCORE,AC_SCORE,NUM_FRAMES,LOG_POSTERIOR,LIN_POSTERIOR"
sil-phone-csl-file
File containing colon-separated list of silence phones.
node-merge-tol-ms
Node merging tolerance in ms
word-emb-marisa-file
MARISA trie file for word embedding lookup
word-emb-mat-flt32-file
Kaldi binary matrix file (float32) that stores word embeddings
word-boundary-int-file
Word boundary file with format <integer-phone-id> [begin|end|singleton|internal|nonword]
unpronounced-word-file
File containing newline-separated list of words with no pronunciation.
See LatticeRnn in nnet/lattice-rnn.h
forward-model-file
backward-model-file
arc-output-model-file
Obtained HWCN in 
silence-label
Numeric id of word symbol that is to be used for silence arcs in the word-aligned lattice (zero is OK)
partial-word-label
Numeric id of word symbol that is to be used for arcs in the word-aligned lattice corresponding to partial words at the end of "forced-out" utterances (zero is OK)
reorder
True if the lattices were generated from graphs that had the --reorder option true, relating to reordering self-loops (typically true)
word symbol table text format filename
fst-file
HCLG FST filename
/sil_I/
Problem decoding utterance.
FINAL RESULT:
Result Choice[
Pronounciation Choice[
update-interval
Beam update interval in frames
beam-update
Beam update rate
max-beam-update
Max beam update rate
inter-utt-sil
Maximum # of silence frames to trigger new utterance
max-utt-sil
Maximum # of silence frames to trigger end of speech while no speech presented
max-utt-length
If the utterance becomes longer than this number of frames, shorter silence is acceptable as an utterance separator
det-max-mem
Maximum approximate memory usage in determinization (real usage might be many times this)
det-max-loop
Option used to detect a particular type of determinization failure, typically due to invalid input (e.g., negative-cost loops)
Decoding beam.
max-active
Decoder max active states.
min-active
Decoder minimum #active states.
lattice-beam
Lattice generation beam
prune-interval
Interval (in frames) at which to prune tokens
determinize-lattice
If true, determinize the lattice (in a special sense, keeping only best pdf-sequence for each word-sequence).
beam-delta
Increment used in decoding-- this parameter is obscure and relates to a speedup in the way the max-active constraint is applied.  Larger is more accurate.
hash-ratio
Setting used in decoder to control hash behavior
word-ins-penalty
Word insertion penalty applied to each word
Tolerance used in determinization
max-mem
Maximum approximate memory usage in determinization (real usage might be many times this).
phone-determinize
If true, do an initial pass of determinization on both phones and words (see also --word-determinize)
word-determinize
If true, do a second pass of determinization on words only (see also --phone-determinize)
minimize
If true, push and minimize after determinization.
Could not topologically sort lattice: this probably means it has bad properties e.g. epsilon cycles.  Your LM or lexicon might be broken, e.g. LM with epsilon cycles or lexicon with empty words.
determinization did not succeed(partial output will be pruned tighter than the specified beam.)
Beam: 
; Speed: 
 xRT
filter-devices cannot be empty
filter-input-origins cannot be empty
An earlier LatticeRnn in the decoder chain already ran. Doing nothing.
Request does not match filter. Doing nothing.
LatticeRnn output is incorrect 
latnnMitigatorScore
Model version
output-model-file
phone-pd2pi-file
bag-of-phones-model-file
0 = not trigger, 1 = trigger
filter-devices
FORMAT: Pipe-separated list of devices with support for wildcards. Wildcards must come at the end of each device in the list. Example 1: "filter-devices": "*" - matches any device. Example 2: "filter-devices": "iPhone7|Watch*|AudioAccessory1" - matches iPhone7, AudioAccessory1, and devices starting with "Watch". USAGE: One decoder chain can have multiple LatticeRnnMitigators, which are specified using colon notation to create unique names. Example decoder chain: lattice-biglm-lme-faster, ..., lattice-rnn-mitigator:X, lattice-rnn-mitigator:Y, lattice-rnn-mitigator:Z. The LatticeRnnMitigators are checked one-by-one in order. The first one that matches a request will 'claim' the request, run, and prevent the rest from running. All the filter-* conditions are AND'ed together, so a request must match all of them for the corresponding LatticeRnnMitigator to run.
filter-input-origins
List of input origins with the same format as filter-devices.
AC_SCORE
BAG_OF_PHONES
KEYWORD
Cannot find symbol ID for 
LM_SCORE
symbole table file
Reset scores after each batch result
keyword mismatch 
No keywords found.
Start of batches
unmatched  posterior matrix dimension and number of symbols
empty posterior matrix
About to process 
 frames in batch
End of batch
End of batches
seeva
seeva inference graph file
vocab-file
the vocab file that describes model output token
vocab-is-binary
vocab file is binary
model-format-version
model format version
feature transform file
<spc>
@[a-z]*#|#[a-z]*@
Unsupported model format version.
/cpu:0
length-penalty
if >= 0, use this value as length penalty weight. Default means using the default in the graph
mmapped-graph
is it a memory mapped graph?
num-inter-op-threads
The maximum number of threads for inter ops in TF graph
num-intra-op-threads
The maximum number of threads for intra ops in TF graph
default-device
TF default device
allow-soft-placement
TF allow soft placement
log-device-placement
TF log device placement
profiling-granularity
Level of profiling (higher means more precise breakdown per operation)
model-config-file
The config file for the model
model-config-binary
is the config file binary?
model-config-end-token
The config file's end token
number of frames in each batch, if <0 will feed whole speech in one batch
pad-size
if the whole audio is too short, pad to this length
encoder-only
only streaming the encoder, no partial results
length-penalty-stream
if >= 0, use this value as length penalty during streaming. Otherwise use the value in the graph
coverage-penalty
if > 0, use this value as the coverage penalty. Otherwise use the value in the graph
cover-pen-ceil
the maximum coverage penalty
cover-pen-step-size
dynamically adjusting coverage penalty with this step size
silence-thresh
if > 0, turn on dynamic coverage penalty when encounter this amount of silence
min-input-count
if > 0, set the minimum number of frames to start streaming. Otherwise use the value in the graph
min-input-left
if > 0, set the minimum number of frames for leftover during streaming. Otherwise use the value in the graph
min-aln-weight
if > 0, set the minimum alignment weight during streaming. Otherwise use the value in the graph
min-init-aln
if > 0, set the minimum initial peak alignment value for the streaming. Otherwise use the value in the graph
min-cont-aln
if > 0, set the minimum continuous peak alignment value for the streaming. Otherwise use the value in the graph
aln-step-size
reduce the min-aln value by this size to increase streaming
min-aln-floor
the aln-value floor when reduction happens
max-input-count
if > 0 && < received_frames, reduce min-aln value to generate partial result if not already so
count-step-size
adjust the min-aln value according to this frequency
init-stable-tokens
number of tokens needed for stablizing the streaming inference at the initial stage
cont-stable-tokens
number of tokens needed for stablizing the streaming inference
dynamic-stable-tokens
turn on dynamic stable tokens to encourage streaming
min-token-floor
the stable token floor when reduction happens
utt-end-beam
if > 0, use this beam at the utterance end. Otherwise use the value in the graph
lme-score-scale
if > 0, scale the LME FST score. Otherwise use the value in the graph
nonlme-score-scale
if > 0, scale the nonLME arc score when LME is active. Otherwise use the value in the graph
SeevaModel/__QNNI__source_input
SeevaModel/__QNNI__length_penalty_weight
SeevaModel/__QNNI__coverage_penalty_weight
SeevaModel/__QNNI__minimum_input_count
SeevaModel/__QNNI__minimum_input_left
SeevaModel/__QNNI__minimum_alignment_weight
SeevaModel/__QNNI__minimum_peak_alignment
SeevaModel/__QNNI__stable_tokens
SeevaModel/__QNNI__utt_end_beam
SeevaModel/__QNNI__trace_back
SeevaModel/decoder/__QNNO__nbest_list
SeevaModel/decoder/__QNNO__nbest_score
SeevaModel/decoder/__QNNO__graph_reset
SeevaModel/decoder/__QNNO__partial_result
SeevaModel/decoder/__QNNO__encoder_only
SeevaModel/__QNNI__lme_fst_header
SeevaModel/__QNNI__lme_fst_states
SeevaModel/__QNNI__lme_fst_arcs
SeevaModel/__QNNI__lme_score_scale
SeevaModel/__QNNI__nonlme_score_scale
seeva-step
encoder-model-file
seeva inference encoder graph file
decoder-model-file
seeva inference decoder graph file
num-encoder-states
number of encoder states
num-decoder-states
number of decoder states
align-state-list
alignment state indices in the decoder states
the vocab file for the model output token
number of frames in each batch
model-beam
the beam size used in the model
time-reduction-factor
source sequence length reduction factor in the model
max-decode-length
the maximum number of decoding steps
if > 0, use this value as the coverage penalty.
if > 0, use this beam at the utterance end.
SeevaModel/encoder/__QNNO__encoder_output
SeevaModel/encoder/__QNNI__encoder_state_
SeevaModel/encoder/__QNNO__encoder_state_
SeevaModel/__QNNI__target_input
SeevaModel/__QNNI__encoder_output
SeevaModel/decoder/__QNNO__decoder_full_score
SeevaModel/decoder/__QNNI__decoder_state_
SeevaModel/decoder/__QNNO__decoder_state_
wordmap
number of start/end LME class tags doesn't match: 
cannot find 
 in the vocab file
 LME classes, their IDs are not contiguous
lme-start-tag-list
a list of LME start tag
lme-end-tag-list
a list of LME end tag
speller-fst-file
the speller FST file
inv-g-fst-file
Inverted small grammar FST filename
list of BigGrammar FST filename, use comma to separate multiple ones
the interpolation weights for the FST LMs, use comma to separate multiple ones
big-g-nnet-file-list
list of BigGrammar NNLM filename, use comma to separate multiple ones
nnet-map-file-ext
the file extension name of the corresponding NNLM word map file
big-g-nnet-weight-list
the interpolation weights for the NNLMs, use comma to separate multiple ones
nnlm-nce-norm-factor-list
the normalization factor for NCE trained NNLMs, use comma to separate multiple ones
rnnlm-max-context-size
maximal context for RNN style LM, no-op for other style of LMs
lm-unknown-word
the unknown word (OOV) in the LM
the lm beam should be no less than the model beam, 
gInvFst: input label is not sorted!
loaded an inverted G, make sure the speller FST is weighted
do not have an inverted G, make sure the speller FST is unweighted
spellerFst: input label is not sorted
No BigG FST or NNLM specified. Hint: This is a BigLm decoder.
bigGFst: input label is not sorted!
Could not read the NNLM normalization factor info
the number of NNLM files and the number of NNLM norm factors do not match
Could not read FST LM interpolation weight info
The number of big FST LMs and the number of weights mismatch
Could not read NN LM interpolation weight info
The number of big NN LMs and the number of weights mismatch
Language model weight must be 1 when using a single LM
cannot find the OOV word 
 in the symbol table
Finished initializing OnlineSeevaStepBigLmDecoder
some FST/NN LMs failed to load
scale the LME FST score when LME is active
scale the nonLME arc score when LME is active.
lm-score-scale
scale external LM score when available
lm-miss-penalty
penalty for missing LM arc
lm-miss-final-penalty
penalty for missing LM arc in final
lm-beam
use this beam value for the external LM
lme-beam
use this beam value for the LME arcs
length-penalty-lm
the length penalty value when using external LM
the base LM is NULL or empty
replace
ReplaceFstImpl: input symbols of Fst 
 does not match input symbols of base Fst (0'th fst)
ReplaceFstImpl: output symbols of Fst 
 does not match output symbols of base Fst 
(0'th fst)
ReplaceFstImpl: no Fst corresponding to root label '
' in the input tuple vector
ReplaceFstImpl::ReplaceFstImpl: always_cache = 
Not using replace matcher
the provided NnlmEvaluator is neither DNN nor RNN
The LME class 
 is not modeled by the NNLM
multiple LME FSTs are mapped into the same non-terminals classes, wrong config?
the individual DeterministicOnDemandFst is NULL or empty
you are requesting linear interpolation, but the total weight is not 1
seeva-greedy
model file
list of vocab
transform file
SeevaModel/__QNNO__prediction
@[^#]*#|#[^@]*@
WRITE 
EMPTY 
CANCEL 
.recorded_state_accesses
Writing accessed states for 
utt-detect.
utt-detect
g-fst-file
Grammar FST filename
Inverted Grammar FST filename (overrides uninverted)
silence-phone-list
List of silence phones.
Phone symbol table (text format) filename
enable-state-access-recording
Record which states in each FST are accessed, to allow for efficient reordering
recog-progress-freq
Frequency(in milliseconds) of reporting recognition progress
enable-endpointing
Enable server endpointing
streaming-conf-model-file
Filename for streaming confidence model file, format <WEIGHT> <FEATURE> (one per line)
streaming-conf-normstats-file
Filename for normalization statistics file for streaming confidence, format <FEATURES-LIST>
 <MEANS-LIST>
 <Standard-Deviations-LIST>
 (each line has a comma separated value for all features)
use-endpoint-for-utt-detect
Use endpoint configuration for doing utterance detection
autocomplete-partial-result
Allow partial result to hallucinate word even if speaker hasn't finished saying it yet. For example, Pneumonoultramicroscopicsilicovolcanoconiosis is recognized after a few syllables.
compute-trailing-silence-from-lattice
True if trailing silence should be computed from the lattice, otherwise use a separate two-state machine to compute trailing silence separately (set this parameter to false if a CTC trained acoustic model is being used).
enable-eager
Enable eager
use-partial-traceback-with-final-cost
For partial results, use traceback which taking final cost into account.
If non-empty: This is a key into the top-level 'spg' dictionary of the config file, and this decoder will run a SilencePosteriorGenerator configured from the corresponding dictionary value. If empty: This decoder will not run a SilencePosteriorGenerator.
Using pre-inverted grammar: 
Using regular grammar, need to negate in memory: 
State access recording is enabled. This will slow decoding, so disregard performance.
 but does not match 
the auto-determined silence label 
Failed to read phone symbol table file: 
ERROR 1: Cannot compute pause counts - word boundary info is missing
ERROR 2: autocomplete-partial-result is false (default), but word-boundary-int-file is missing.
Option 1: Set autocomplete-partial-result=true. This is *usually* done only for 'srch' and 'srch'-variant (WebSearch) decoder chains. This is required if the model doesn't have word-boundary-int-file.
Option 2: Keep using autocomplete-partial-result=false, but add a word-boundary-int-file. This is *usually* done for all other tasks.
needPauseCounts=true and autocomplete-partial-result=true is not supported yet.
Eager disabled because word-boundary-int-file is missing.
VoiceTrigger phrase word "
Decoding beam: 
Finished initializing OnlineLatticeBiglmFasterDecoder.
Extra LM weight must sum to less than 1.0
Using 
Created new decoder
uttDetector: 
endPointer: 
RaiseToSpeak
eagerDecisionLog
MATCH
NOMATCH
eagerOutputLog
Failed to get recognition lattice
Average number of active tokens: 
Last frame processed 
EstimatedEpTruncation
EstimatedEndPointerTrailingSilence
Server side end pointer first triggered frame 
ProcessEmittingWallMs
ProcessEmittingCpuMs
ProcessNonemittingWallMs
ProcessNonemittingCpuMs
PruneActiveTokensWallMs
PruneActiveTokensCpuMs
Recognition cancelled
spg batch size > 1 unexpected because spg->config.frameByFrame should be set
spgSilenceFramesCount=
 spgSilencePosterior=
 spgSilenceProbabilityRaw=
Raw pauses = [
], words = [
Server side end pointer triggered frame 
ep-features
Reporting end point status=
Since endpointer is not enabled ignoring utterance 
Utterance detector triggered 
Utterance detector force triggered because current utterance has too many frames: 
Sending recognition progress report for frameCount=
 processedAudioDurationMs=
This should only be called if endPointer exists
rt-min
Approximate minimum decoding run time factor
rt-max
Approximate maximum decoding run time factor
max-total-forward-links
Max total allocated forward links at any time.
small-lm-prune-beam-diff
Pruning threshold for small LM before checking with big LM; smaller prunes more aggresively
early-endpoint-threshold
Threshold for early endpoint detection
pause-threshold-list
Comma-separated list for pause-threshold vector, which is used for determining the pause-counts vector that is an endpointer feature. pause-counts[n] is the number of interword pauses >= pause-threshold[n]. For example, pause-threshold=[3,30,100] and pauses of 90 frames and 100 frames will result in pause-counts=[2,2,1].
pauses-as-bool
Needs pause-threshold-list. If true, then pause-threshold vector is used to create a pause-counts vector,where pause-counts[n] is a boolean for asserting interword pauses >= pause-threshold[n]. For example, pause-threshold=[3,30,100] and pause of 90 frames will result in pause-counts=[1,1,0].
Delaying the endpointer trigger decision by the given amount of time (in msec), when specified in recog request.
use-nnet
Use nnet for utterance detection if true
Use left context for utterance detection if true
hard-max-utt-length-ms
If the utterance exceeds this length, force trigger the utterance detector. Ignored if <= 0. It is named 'hard' because there is a softer 'max-utt-length' config that does not trigger right away when exceeded.
Invalid word symbol, clipping left context: 
Error in ProcessNonemitting: no surviving tokens: frame is 
Ran out of forward links in storage
PruneActiveTokensFinal: pruned tokens from 
 links from 
 pruned_tok_frames_ 
 pruned_link_toks_ 
No tokens alive [doing pruning].. warning first time only for each utterance
link_extra_cost is NAN
: not producing lattice.
GetRawLattice: NumStates 
 NumArcs 
 NumFinal 
Cannot undo PruneActiveTokensFinal(undoable=false)
UndoPruneActiveTokensFinal: restored tokens from 
Compacted in 
 ms 
tokens 
 and forward links 
Move the partial traceback to the end of word phone
Pause error - Consecutive word-begin
Pause error - Consecutive word-end
Pause error - Word with missing startframe or endframe
Pause error - Word-end before word-begin
Pause error - Word spans into next word
Pause error - Found more word times than words
cache-size
Cache size for lazy replace operation
enable-lme
Enable LME
lme-sym-start-key
Starting key value for LME symbols
classLM-fst-file-list
list of classLM FST filenames, use comma to separate multiple ones
classLM-template-list
list of classLM templates, in the same order as the classLM-fst-file-list
Could not find "
" in base symbol table
Cached template ID 
 for 
The number of classLM templates = 
, which does not match the number of classLM Fst files = 
Expected range start to be symbol id 1 and a phone word: 
Expected range end to be a disambiguation symbol: 
Disabling small LM pruning for symbols [
:lmeLoadingTime
LME data stream 
 is null.
 has phone set version 
. This data stream will not be used.
Bad LME data (empty): stream=
, symTableFirstKey=
, symTableLastKey=
Bad LME data (invalid last key): stream=
, symTable->AvailableKey()=
 in blob is not supported by datapack.
 in blob uses different enumeration type (
) in datapack.
G2P model version 
 in blob is older than datapack's version 
Ignoring unsupported template 
 in stream # 
geoLocationStatus
ClassLM template 
 assigned to FST from 
classlm_origin[
geoContextFound
geoLastRegionIdWasCached
geoLastRegionIdCacheMiss
Using decoder-specific classLM slot for template=
, location-specific slot not available
Filtering out unsupported classLM template=
max-slot-depth
If >0, the max number of words to allow in each slot of the confusion network.
alt-confidence-model-file
eps-confidence-model-file
Filename for epsilon confidence model file, format <FEATURE> <WEIGHT> (one per line)
scale-low
Acoustic scaling factor (divisor) for low-end, eg, 2 (for a standard divisor of 12 = 0.08333)
scale-high
Acoustic scaling factor (divisor) for high-end, eg, 20 (for a standard divisor of 12 = 0.08333)
acoustic-scale
Scaling factor for acoustic likelihoods, default 0.08333
do-acoustic-stability
Turn computation of acoustic stability features (at multiple acoustic scales) on/off with true(default)/false.
do-process-alternatives
Control whether or not to process alternatives in the sausage network, or run in 1-Best mode, using true(default)/false.
do-process-sausage
Turn computation of features derived from the structure of the sausage network on/off with true(default)/false.
do-process-rank
Turn computation of rank-based features (at multiple acoustic scales) on/off with true(default)/false.
do-process-faninout
Turn computation of contextual posterior features related to fan-in and fan-out context on/off with true(default)/false.
do-process-post
Turn computation of lattice state posteriors (used for time-based-posterior and other measures) on/off with true(default)/false.
Turn computation of confidence score from the model off, effectively generating the time-based posterior as the confidence score,turn on/off with true(default)/false.
do-add-epsilon
Turn computation of epsilon confidence score on, this will use the supplied epsilon confidence model parameters score,turn on/off with true(default)/false.
decode-mbr
If true, do Minimum Bayes Risk decoding (else, Maximum a Posteriori)
number of NBest hypotheses to produce hypotheses (with confidence) for.
Prune incoming lattice to this beam
Finished initializing OnlineLatticeConfidenceDecoder.
sausage-labels
symList.size() != symListWords.size()
Note: Have trimmed confusion network slot depth from 
tokenDur: 
speechDur: 
Best-path failed
lm-scale
Scaling factor for LM probabilities. Note: the ratio acoustic-scale/lm-scale is all that matters.
first-pass-lattice-beam
First pass lattice beam
Decoding lattice beam
HCP FST filename
phone-map-file
Phone mappings file
Conversion of alignments in lattice is only supported for models with context width = 1, other models will result in alignments which do not properly consider cross-word contexts
Problem decoding utterance for re-alignment.
kaldi::OnlineDecodableNnet1Lazy is required at this point in the first pass with configured realign-model parameter.
Silence label is set to 
 but does not match the auto-determined silence label 
. Will use latter.
Word alignment for MBR decoding failed.
Empty aligned lattice. MBR decoding failed.
Lattice word alignment time: 
max-expand
If >0, the max amount by which lattices will be expanded.
lm_interp_weights
nbest-size
number of NBest from 1st pass used for interpolation weight estimation
the lattice beam for the rescored lattice
The rescoring LM interpolation weights:
Rescoring with 
 symbol(s) for left context from 
 word(s)
Total LM cost after rescoring = 
output-symtab-file
Output symbol table file
lg-fst-file
LG FST file
phonomap-file
Phonomap file
sys-select-bias
System selection bias
sys-select-lm-scale
System selection LM scale
regex-list-file
List of regular expressions that will be used to catch inputs for phonetic match.
regex-whitelist-file
Regex whitelist
regex-blacklist-file
Regex blacklist
lm-logprob-threshold
Only do PM if LVCSR's LM logprob is less than this.
entity-tags-tsv-file
File containing start and end entity tags
sys-select-score-scale
Scale factor for PM-overallScore for addition to confidences
sys-select-score-min
Minimum PM-overallScore at which to discard the PM result
sys-select-length-norm
Divide PM-overallScore by phone sequence length
do-use-confmodel
Flag for whether or not to use a confidence model, if true confidence-model-file must also be set
Filename for confidence model file, format <FEATURE> <WEIGHT> (one per line)
l-fst-file
L FST file (if specified per-word segmentation will be output)
max-align-total-tokens
Maximum number of tokens used just for alignment pass
Phonetic match decoder is using subroutine feature but config version < 111
Read in Confidence Model 
 added 
~w01
phoneSeq="
" tokenName=
 start=
 end=
phone=
Number of phones is 0
PM Failed.
PM ELAPSED: 
 num_phones=
graphCost[
 pmOutput[
PM ALIGN ELAPSED: 
PM Alignment failed
PM Failed to get any results from alignment lattice
PM Failed to get any results from lattice
graphCost=
 numStates=
 decodeScore=
 overallScore=
No LM cost found. Skipping PM decoder. Hint: Did you include lattice-lm-rescore?
LVCSR LM logprob=
 is greater than threshold 
. Skipping PM.
pmInput="
Not a match with the regex whitelist. Skipping PM.
Matches the regex blacklist. Skipping PM.
pmOutput="
Score low. Discarding PM result.
Switching to phonetic match decoder output
PM-lvcsrLmLogProb
PM-isWhiteListMatch
PM-isBlackListMatch
PM-graphCost
PM-decodeScore
PM-overallScore
PM-confidence
PM-result
PM-used
PM-decoder
Symbol decoder beam
Symbol decoder max active states
Symbol decoder beam delta
Symbol decoder hash ratio
ac-scale
Symbol decoder acoustic scale
max-total-tokens
Max total allocated tokens at any time.
pm_overall_score
slm_mean_confidence
trans_slm_mean_confidence
<n/a>
Greated than 256 rec symbols (phones) in phonomap 
 can't be supported
Frame 
Max tokens 
 exceeded - 
Allocated max tokens 
 prev_id=
 nextstate=
 weight=
 ilabel=
 olabel=
 phone=
Ran out of token storage
Process non-emitting with cutoff=
Exit subroutine state=
subroutine=
 prevnextstate=
Cannot enter subroutine=
 ret_state=
 (nesting not allowed)
Process emitting isym=
Failed to reach final state
Subroutine index 
 already defined
 not used - subroutines indexes must be consecutive
 phonetic match subroutines 
VoiceTrigger
WatermarkDetector not run on input origin 
WatermarkDetector: not enough audio cached.
Failed to compute spectrogram.
WatermarkPeakAvg
WatermarkPeakMax
WatermarkDetected
WatermarkDetector peakMax=
, peakAvg=
, detected=
above-hi
Frequency (in Hz) of top of upper band
above-lo
Frequency (in Hz) of bottom of upper band
notch-hi
Frequency (in Hz) of top of notch
notch-lo
Frequency (in Hz) of bottom of notch
below-hi
Frequency (in Hz) of top of lower band
below-lo
Frequency (in Hz) of bottom of lower band
supported-input-origins-list
The input origins that are supported (should be comma separated)
watermark-threshold
Average notch threshold value to detect a watermark
min-voicing-duration
Minimum duration of voicing
acoustic-feature-window-width
Minimum width of the normalization window for acoustic audio analytics features
Error: no utterance features were provided
No audio features generated. Rejecting utterance.
Audio analytics finished..
WatermarkDetector2 not run on input origin 
WatermarkDetector2 not supported for sampling rate=
WatermarkDetector2: missing trigger phrase endTime.
WatermarkDetector2: not enough audio cached.
WatermarkDetector2: Trigger phrase not detected
WatermarkDetector2: score=
 detected=
Watermark2Score
Watermark2Detected
Watermark2StartTimeSecs
threshold
Threshold value to detect a watermark
anti-notch-offset
Frequency (in Hz) of anti notch offset
notch-width
Frequency (in Hz) of width of notch
notch-freq
comma separated list of notch frequencies
classifier
comma separated list of classifier values
trigger-num-tokens
The number of tokens in the trigger phrase (two for hey siri)
<blk>
keyword-spotting
The threshold for the keyword score
frame-offset
frame offset
do-viterbi
apply viterbi for keyword detection
tokens-file
symbol table file
keyword-list-file
list of keywords and their corresponding tokens sequence
Number of frames that get decoded in one go
do-batch-reset
Reset scores after each result
do-top-result-only
Only return the best keyword score
Number of labels: 
Blank label "
" not found in symbol table.
Blank label index: 
Invalid keyword-phrase line
Adding keyword: 
Symbol "
Number of keywords: 
DP contains no keywords for detection
Coding error. Keyword 
Dimension mismatch. Code or DP error
KWD 
Frames seen so far: 
keyword detected
no keywords detected
keyword search finished with 
 detected hypothesis.
Lattice word alignment failed. Cannot obtain word hyp lattice.
Empty word-aligned lattice. Cannot obtain word hyp lattice.
If silence posteriors are available, trigger only when the average silence posterior is >= this value. Otherwise, ignore this value.
silence-window
Sliding window size (in frames) for silence posterior average. Silence posterior is ignored if this value is <= 0.
stable-partials
Trigger only after the number of stable partial results (one per frame) exceeds this value. (Eager's stabilization is unrelated to ResultStreamStabilizer stabilization). Regardless of this value, the trigger always looks for at least 1 stable partial result.
early
backoff
max-triggers
Ignored if <= 0: Maximum number of eager result triggers. Once exceeded, no more eager results are created.
require-silence-posterior
If true, disable eager for requests that don't have silence posteriors. Defaults to true since 'false eager results' increase without silence posteriors. Set this to false for experimentation or if the number of 'false eager results' is acceptable.
debug
Debug mode: require-silence-posterior=false and trigger every frame without affecting state machine
{silencePosterior=
 silenceWindow=
 stablePartials=
{early=
 backoff=
 maxTriggers=
 requireSilencePosterior=
 debug=
{frame=
 finalActive=
 words=[
 ids=[
 trailingSilence=
 silencePosterior=
 allowTrigger=
n must be positive
init() was not called
Cannot compute average of 0 items
ENABLED 
 hasSilencePosterior=
trigger=
 numTriggers=
 thisFrame=
 avgSilPost={
 numStable=
INVALID 
INVALIDATED 
TRIGGER 
TRIGGERED 
Invalidate and trigger shouldn't happen on the same frame
Bad state transition: triggered 
num-of-words
num-trailing-sil
end-of-sentence
pause-counts
silence-posterior
client-silence-frames-count-ms
client-silence-probability
silence-posterior-nf
server-features-latency
eager-result-end-time
spg-silence-frames-count
spg-silence-posterior
spg-silence-probability-raw
Read endpoint model file =
endpoint-feature-list cannot be empty
Writing to json string failed. 
BasicEndPointer inter-utt-sil=
, max-utt-length=
, max-utt-sil=
Feature unknown, features allowed are: 
Feature type unknown. Ignoring feature ..
NNet model file for endpointing cannot be empty when use-nnet-endpointer is set
Empty feature list (endpoint.feature-list). Specify features from: 
Invalid pause-threshold-list string 
pause-threshold-list should not be empty if pauses-as-bool is set
NnetEndPointer endpoint-threshold=
num-frames
sequence-of-words
num-input-label-words
stream-conf
 before calling createOnlineFeInput().
subsample
stride
Take every n'th feature, for this value of stride(with negative value, repeats each feature n times)
' cannot occur at the first stage of feature-extract
Building FeatureExtractor 
cmvn
delta
fbank
fbankwithpitch
mfcc
nnet-forward
nnet-forward-skip
splice
transform
cache-input
compute-ahead-input
fbank-with-audio-analytics
append
Unknown feature-extract type "
Finished reading matrix file 
cmn-window
Window in frames for running average CMN computation
min-cmn-window
Minumum CMN window used at start of decoding (adds latency only at start). 
init-cmvn-stats-file
Stats File for warm-start online CMVN
prior-count
number of frames used from prior CMVN stats file
buffer-output
Use OnlineBufferingInput
cmvn-window
Window in frames for running average CMVN computation
min-cmvn-window
Minumum CMVN window used at start of decoding (adds latency only at start). 
low-watermark
Low watermark (in number of frames) for audio buffer read. Ignored if <= 0.
resample-freq
The frequency to resample to.
resample-cutoff-hz
The cutoff for the filter for resampling the audio
resample-num-zeros
Controls sharpness of filter.
' can only occur at the first stage of feature-extract
sample-frequency
Waveform data sample frequency (must match the waveform file, if specified there)
frame-length
Frame length in milliseconds
frame-shift
Frame shift in milliseconds
preemphasis-coefficient
Coefficient for use in signal preemphasis
remove-dc-offset
Subtract mean from waveform on each frame
dither
Dithering constant (0.0 means no dither)
window-type
Type of window ("hamming"|"hanning"|"povey"|"rectangular")
round-to-power-of-two
If true, round window size to power of two.
snip-edges
If true, end effects will be handled by outputting only frames that completely fit in the file, and the number of frames depends on the frame-length.  If false, the number of frames depends only on the frame-shift, and we reflect the data at the ends.
analytics-sample-frequency
analytics-frame-length
analytics-frame-shift
analytics-preemphasis-coefficient
Coefficient for use in signal preemphasis (deprecated)
min-f0
min. F0 to search for (Hz)
max-f0
max. F0 to search for (Hz)
soft-min-f0
Minimum f0, applied in soft way, must not exceed min-f0
penalty-factor
cost factor for FO change.
lowpass-cutoff
cutoff frequency for LowPass filter (Hz) 
resample-frequency
Frequency that we down-sample the signal to. Must be more than twice lowpass-cutoff
delta-pitch
Smallest relative change in pitch that our algorithm measures
nccf-ballast
Increasing this factor reduces NCCF for quiet frames
nccf-ballast-online
This is useful mainly for debug; it affects how the NCCF ballast is computed.
lowpass-filter-width
Integer that determines filter width of lowpass filter, more gives sharper filter
upsample-filter-width
Integer that determines filter width when upsampling NCCF
frames-per-chunk
Only relevant for offline pitch extraction (e.g. compute-kaldi-pitch-feats), you can set it to a small nonzero value, such as 10, for better feature compatibility with online decoding (affects energy normalization in the algorithm)
simulate-first-pass-online
If true, compute-kaldi-pitch-feats will output features that correspond to what an online decoder would see in the first pass of decoding-- not the final version of the features, which is the default.  Relevant if --frames-per-chunk > 0
recompute-frame
Only relevant for online pitch extraction, or for compatibility with online pitch extraction.  A non-critical parameter; the frame at which we recompute some of the forward pointers, after revising our estimate of the signal energy.  Relevant if--frames-per-chunk > 0
max-frames-latency
Maximum number of frames of latency that we allow pitch tracking to introduce into the feature processing (affects output only if --frames-per-chunk > 0 and --simulate-first-pass-online=true
analytics-snip-edges
If this is set to false, the incomplete frames near the ending edge won't be snipped, so that the number of frames is the file size divided by the frame-shift. This makes different types of features give the same number of frames.
pitch-viterbi-window
Number of frames over which we want to run viterbi for computing pitch.
lda-matrix-file
LDA matrix filename
left-context
Number of frames of left context
right-context
Number of frames of right context
Map model into memory (requires aligned models)
Name of nnet model file
transform-file
File for feature transform in front of nnet's main network (in nnet format)
no-softmax
No softmax on MLP output (or remove it if found), the pre-softmax activations will be used as log-likelihoods, log-priors will be subtracted
apply-log
Transform MLP output to logscale
use-gpu-id
Unused, kaldi is compiled w/o CUDA
class-frame-counts-file
File containing vector with frame-counts of pdfs to compute log-priors. This is the same as class-frame-counts, but allows paths that are relative to the json config file (class-frame-counts requires absolute paths). If class-frame-counts is also specified, this param will override it.
silence-model-file
Name of nnet model file for computing silence posteriors
batch-left-context
Number of frames of left context to prepend to the batch as extra rows
batch-right-context
Number of frames of right context to append to the batch as extra rows
Read model file for computing silence posteriors=
Nonsense option combination : --apply-log=true and --no-softmax=true
Option --class-frame-counts has to be used together with 
--no-softmax or --apply-log
Used --apply-log=true, but nnet 
 does not have <softmax> as last component!
skip-frames
Number of frames to be skipped in nnet computation.
skip-across-batch
Make skip-frames deterministic by skipping across batches instead of within batches (default: false).
File for any linear (or affine) feature transformation
cache-data
If true, cache all data (e.g. fbank feats)
cache-analytics
If true, cache all analytics data
povey
delta-order
Order of delta computation
delta-window
Parameter controlling window for delta computation (actual window size for each delta order is 1 + 2*delta-window-size)
use-energy
Add an extra dimension with energy to the FBANK output.
energy-floor
Floor on energy (absolute, not relative) in FBANK computation
raw-energy
If true, compute energy before preemphasis and windowing
htk-compat
If true, put energy last.  Warning: not sufficient to get HTK compatible features (need to change other parameters).
use-log-fbank
If true, produce log-filterbank, else produce linear.
cache-energy
If true, cache energy values.
num-mel-bins
Number of triangular mel-frequency bins
low-freq
Low cutoff frequency for mel bins
high-freq
High cutoff frequency for mel bins (if < 0, offset from Nyquist)
vtln-low
Low inflection point in piecewise linear VTLN warping function
vtln-high
High inflection point in piecewise linear VTLN warping function (if negative, offset from high-mel-freq
debug-mel
Print out debugging information for mel bin computation
Frequency that we down-sample the signal to.  Must be more than twice lowpass-cutoff
pitch-scale
Scaling factor for the final normalized log-pitch value
pov-scale
Scaling factor for final POV (probability of voicing) feature
pov-offset
This can be used to add an offset to the POV feature. Intended for use in online decoding as a substitute for  CMN.
delta-pitch-scale
Term to scale the final delta log-pitch feature
delta2-pitch-scale
Term to scale the final 2nd-order log-pitch feature
delta-pitch-noise-stddev
Standard deviation for noise we add to the delta log-pitch (before scaling); should be about the same as delta-pitch option to pitch creation.  The purpose is to get rid of peaks in the delta-pitch caused by discretization of pitch values.
normalization-left-context
Left-context (in frames) for moving window normalization
normalization-right-context
Right-context (in frames) for moving window normalization
Number of frames on each side of central frame, to use for delta window.
delay
Number of frames by which the pitch information is delayed.
add-pov-feature
If true, the warped NCCF is added to output features
add-normalized-log-pitch
If true, the log-pitch with POV-weighted mean subtraction over 1.5 second window is added to output features
add-delta-pitch
If true, time derivative of log-pitch is added to output features
add-delta2-pitch
If true, 2nd order time derivative of log-pitch is added to output features
add-raw-log-pitch
If true, log(pitch) is added to output features
use-pitch
Add extra dimensions for pitch to the FBANK output.
add-pitch-period
If true, pitch period is added to output features
add-pov
If true, probability of voicing is added to output features
add-max-amplitude
If true, max amplitude is added to output features
num-ceps
Number of cepstra in MFCC computation (including C0)
Use energy (not C0) in MFCC computation
Floor on energy (absolute, not relative) in MFCC computation
cepstral-lifter
Constant that controls scaling of MFCCs
If true, put energy or C0 last and use a factor of sqrt(2) on C0.  Warning: not sufficient to get HTK compatible features (need to change other parameters).
class-frame-counts
Vector with frame-counts of pdfs to compute log-priors. (priors are typically subtracted from log-posteriors or pre-softmax activations)
prior-scale
Scaling factor to be applied on pdf-log-priors
prior-cutoff
Classes with priors lower than cutoff will have 0 likelihood
No feature vectors requested?!
nnet transformation contains splicing, which is not 
supported by OnlineNnetForwardInput. Use a separate splice 
operation to perform splicing.
nnet contains splicing, which is not supported by 
OnlineNnetForwardInput. Use a separate splice operation to 
perform splicing.
Skipping 
 frames may not give you good results.
skip_across_batch cannot be set if you aren't frame skipping
ComputeAheadFeatInput
Unable to parse input string.
Pre-alignment tokens not monotonic.
Aligner failed. There is a BUG. FIX THIS!!!
 alignment=
 src=[
] dest=[
Hammer rewrite failed.
UTF8StringToLabels: continuation byte as lead byte
UTF8StringToLabels: truncated utf-8 byte sequence
UTF8StringToLabels: missing/invalid continuation byte
UTF8StringToLabels: Invalid character found: 
StringCompiler::ConvertSymbolToLabel: Symbol "
" is not mapped to any integer label, symbol table = 
StringCompiler::ConvertSymbolToLabel: Bad label integer 
LookAheadComposeFilter: 1st argument cannot 
match/look-ahead on output labels and 2nd argument 
cannot match/look-ahead on input labels.
LookAheadMatcher: No look-ahead matcher defined
MultiEpsMatcher: Bad multi-eps label: 0
LmeDataNotChecked
LmeDataOK
LmeDataNull
LmeDataOKButVersionOutdated
LmeDataVersionUnsupported
LmeDataPhoneSetMismatch
LmeDataCorrupt
Unknown
LmeNotUsed
LmeUsedNotRecognized
LmeUsedAndRecognized
, phoneSeq: 
, startSil: 
, confidence: 
, ipaPhoneSeq: 
There should be one cost for each result choice
concatNbest aChoices=
 bChoicesOrig=
 bChoices=
concatNbest[
 cost=(
 aIndex=
 bIndex=
Inconsistent number of columns. Expected 
 got 
Failed to open file: 
Could not read mapped file
Not caching word with too many prons: "
" has 
 prons
Skipping illegal word: "
Encoding should be either QsrText or NotEncoded
Skipping illegal Word
UNKNOWN
LME STREAM DUMP 
: nWords = 
: orthography = 
: nProns = 
: pron = 
Ignoring corrupted prons: orthography = 
, nProns = 
enumerationTypeMap dump, key=
enumerationTypeMap dump, enumerationType=
: nMapSize = 
: key = 
: enumerationType = 
Duplicate key is being added to enumerationTypeMap with key=
Invalid write version choice: 
, it is now set to: 
done.
formatVersion=
Failed to read LmeData stream. Incorrect version: 
Error reading LmeData stream: 
LME STREAM DUMP [Body]
: g2pModelVersion = 
: symTableFirstKey = 
: symTableLastKey = 
: fstSize = 
: phoneSetVersion = 
LME STREAM DUMP [Pron Cache]
: templateName = 
: <FST>
: <symTable:
 symbols>
LME data stream successfully read with 
 symbols; 
) ~ "
LME STREAM DUMP         
LME data stream version is old, but still supported. Current write version is 
 and stream version is 
Sanitization returned empty string
Tokenizer returned empty tokens
Pronguesser returned empty prons for orthography 
orth
freq
prons
profile
AddConfigOverride() can only be called before init()
LmeDataFactory already initialized.
lme-create.
lme-create
Failed to find 
 in template-map, skipped.
params
lme-create.name-enumerator-map.
.params.
name-scale-map
name-average-cost-map
name-deviation-cost-map
read mmaped lexicon from 
Could not read lexicon data from mmaped source 
can not open 
Cannot open g2p rewrite file 
G2P blacklist does not support rewrite rules
Malformed g2p rewrite file line=
g2p rewrite file contains whitespace line=
Failed to encode g2p rewrite entry in QsrText: 
G2P rewrite rule 
 -> 
G2P rewrite size=
Error reading JSON config file: 
/sil_B/
/sil_S/
/sil_E/
LmeDataFactory initialized.
LmeDataFactory not initialized.
Starting LME for new speaker.
AOT LME data has already been provided.
LME data has phone set version 
 which is different from model phone set version 
Adding AOT LME for speaker. lmeDataStatus=
, nextLmeStartSymbolKey[AotLme]=
Multipe LmeType in single user data is not supported.
is UserData empty? not able to tell which lmeType from userData which has size: 
generate Lme Data for lmeType: 
Serializing.
Deserialization test failed. Cannot properly serialize this data.
Deserialization test passed.
User data is empty
Lme enumerating return NothingToDo, errorCode=
Lme enumerating failed, errorCode=
Failed to build the LME fst using the direct method
_num_word_homophones=
_num_fst_paths=
_num_word_homophones
_num_fst_paths
Failed to build the LME fst
LmeEnumeratingTimeMs=
, lmeFstCreatingTimeMs=
, maxPronsPerWordSeen=
LmeEnumeratingTimeMs
LmeFstCreatingTimeMs
Created lmeData.symTable
lmeData.symTableFirstKey = 
 lmeData.symTableLastKey = 
Ignoring user data key 
Getting LME data for userDataKey = 
 quasarTemplateName = 
No supported templates were found in userData. Only the templates specified under 
"supported-lme-template-list" in the json config file are supported.
Skipping name containing bad word:
Skipping name containing bad word
Could not find enumerator for quasar template 
Enumeration type:
Word has empty orthography
Word with hex sequence 
has frequency 
Word has no prons, orthography=
Word has pron with 
 phones, exceeds maxPronLen=
, orthography=
Rewriting from=
 to=
Could not read magic header from 
Magic header was wrong in 
Could not read the number of words from the mapped file 
Could not read the offset region in the mapped file 
base-dict-file
Base lexicon file
base-dict-mapped-file
Base lexicon file, mmap-able (overrides text lexicon file)
lme-scale
Scaling factor for the LME FST
lme-average-cost
the cost of entering an LME FST
lme-deviation-cost
the cost of deviating from an average size LME class
supported-lme-template-plist
Comma-delimited LME template names, ordered by enrollment priority
supported-lme-template-list
Comma-delimited LME template names
contacts-template-name
Quasar template name for user's contact names
appcontacts-template-name
Quasar template name for 3rd-party app contact names
max-num-enumerated-contacts
Maximum number of contacts (e.g. in NT-contact and NT-appcontact) to allow in a user's profile
just-in-time-template-name
Just in time LME template name
template-map
Mapping from ACE category names to Quasar template names
name-enumerator-map
Mapping from Quasar template names to enumerator names
max-prons-compound-word
Maximum number of pronunciations for compound words
During G2P, empty prons will be returned for tokens listed in this file. File format: same as a lexicon text file (not hat encoded) with the prons removed so that only one column remains per line. Order does not matter.
g2p-rewrite-file
File format: If a rule is in the form of 'A -> B' (whitespace optional), then rewrite token A to token B before doing G2P. If a rule is in the form of 'A', then rewrite A to an empty string. This 2nd rule has the same format and effect as g2p-blacklist entries and therefore makes g2p-rewrite-file a superset of g2p-blacklist.
LME scale for specific Quasar template names
the cost of entering an LME FST for a specific template
the cost of deviating from an average size LME class for a specific template
Exceeded enumeration limit. Stopped enumerating.
 vs 
<unspecified>
\NT-buzz
~w00
\NT-inline
\NT-contact
\NT-appcontact
Config Version is not high enough for personalization
personalization-recipe.personalization-version
Personalization not configured
personalization-recipe.
personalization-recipe
personalization-recipe.categories
Personalization version: 
personalization-version
The version of the categories data
chars-to-trim
The characters to be trimmed from the edges of the raw entity string
chars-to-split
The characters used to split the raw entity string
The relative frequency of the data
template-name
The template name for LME
tag-name
The tag name for LME (also important for enumerations)
Category 
 not supported
Ignoring entry with orthography 
: Cannot find key: 
Unknown location
Building appendable feature 
sampling-rate
location
Unknown appendable feature: 
uapd
LME STREAM DUMP [Header]
: qsrHeader = 
Incorrect quasar blob header
: metaVersion = 
Incorrect quasar blob version
: dataTypeStr = 
Incorrect data type for Lme
Incorrect data type for UserAcusticProfileData
Incorrect data type for UserAcousticProfileData
: dataVersion = 
word-syms-marisa-file
Base word symbol table in MARISA trie format (overrides other format files)
word-syms-map-file
Base word symbol table mappable format filename (overrides text and binary format file)
word-syms-binary-file
Base word symbol table binary format filename (overrides text format file)
word-syms-file
Base word symbol table text format filename
Could not read symbol table from marisa file 
Could not read symbol table from mappable file 
Could not read symbol table from binary file 
Could not read symbol table from text file 
No word symbol table file specified.
Failed to convert HatText token to QsrText token:
Failed to convert QsrText token to HatText token:
Programming error: Invalid output encoding
The number of recognition request parameters is 
 (requirement is 3)
 (requirement is 5 for config file ver 15.0+)
Illegal char '*' found in task type 
Illegal char '*' found in device type 
farField type must be '*', 'true', or 'false': 
Illegal char '*' found in bluetooth device id 
VersionUnsupported: 
result-combiner
result-combiner.
1.0,1.0
compute-conf
Whether to use existing confidence or re-compute a score from the tokens, default = true.
nbest-depth
The maximum number of alternatives to allow in the combined output, default = 10.
system-weights
A comma-separated list of weights to apply to each system, in the same order as the provided system input, default is 1.0,1.0.
contact-first@contact-middle@contact-last@appname-first@appname-last,contact-first@contact-middle@contact-last@appname-first@appname-last
backbone-system
The index of the system to use as the reference/backbone system. This is the default system, and the one which is used for alignment.
eps-backbone
The epsilon confidence score for epsilons inserted into the backbone.
eps-alternative
The epsilon confidence score for epsilons inserted into the alternative systems.
do-selection
Switch to control whether to do system selection or combination, default is 'true' (i.e. do selection only).
combine-any-region
Switch to control whether, if regions are specified, to do region combination within the entire utterance, if the region exists at all in the two CNs.
combine-in-region-only
Switch to control whether, if regions are specified, to do region combination only in slots where the region exists.
confidence-delta
The delta by which the competing systems must be better than the backbone in order to be considered better.
region-list
List of regional terminals to mach for use for system combination (works with region-combine options). Comma-separated for each system, and @-separated for each region within a system (e.g. contact-first@appname-first,contact-last).
do-flatten
Switch to control whether to flatten the confusion network such that only a 1-best combination/selection is performed.
do-partial-merge
Switch to control whether to allow merging a partial hypothesis with a longer one before doign selection.
max-partial-shift
The amount of jitter or shift to allow when deciding whether to merge a longer hypothesis with a partial one.
truncation-delta-milliseconds
Skip system combination if (backbone speech end - competing speech end) >= this value. Value can be positive or negative. This prevents truncation if the CN being combined with is too short. By default, we don't enable this check, value = huge number.
Could not read system weight info
Number of systems is 
System 
 Number of alternatives is 
Alternative = 
Final alternatives list:
DECODER OPTION in slot 
 word 
 score = 
 phoneSeq 
CONSENSUS in slot 
 selected word 
End time of competing confusion network is 
ConfusionNetworkMerge: Backbone word starts at the same time as the end of the competing CN. Merge starting at 
ConfusionNetworkMerge: Exceeded the maximum allowable shift amount (
) with 
 won't try to merge anymore.
ConfusionNetworkMerge: Backbone word starts before the end of the competing CN, ends after and covers more audio. Merge starting at 
ConfusionNetworkMerge: We have exceeded the maximum allowable shift amount (
 we won't try to merge anymore.
ConfusionNetworkMerge: Backbone word starts after end of the competing CN, and haven't started merging yet, and the word doesn't start too long after. Merge starting at 
Merging the word/words in slot 
 onto the end of the competing confusion network
Found a region of interest in the confusion network
Could not find a region of interest in the confusion network
BestConfidence is 
Competing Confidence for system 
 is 
Best system End Time is 
End time for competing system 
Competing system does not cover enough speech (max truncation is 
 ,current truncation is 
Exiting selection logic
Proceeding with selection logic using merged partial confusion network
Switching selected system from 
 new score = 
 old score = 
Selected system is 
FINAL HYPOTHESIS IS  : 
This class is internal to Quasar, and this function is never called
Decoding for only the last utterance failed. Updating recogStatus to success
Left context for utterance detection does not work. Ignoring user-provided value of allowUttDetectLeftContext and disabling left context.
endpoint.
endpoint
eager.
eager
recognizers
Found missing recognizer request handlers.
feature-read.
feature-read
spg.
Decoder 
 references spg that does not exist: 
Initialized SpeechRecognizer with config 
SpeechRecognizer must be in initialized state before you call runAsync(). 
Hint: Make sure you call waitForAsyncRecogToFinish() before calling runAsync() again.
Utterance concatenation should only be used with utterance detection
Eager + utterance detection without concatenation is not allowed
Posted runAsyncWorker() to threadPool
Cancelling recognition
This function can only be called in Recognizing or Cancelling state
PM-input
PM-output
finalResultTokens
cache
geoLocationStatusUponRunAsync
Symbol table list passed to runSync() must start empty
Invalid recognition request parameters
Created OnlineFeatInputItf chain
Feature extraction misconfigured
Frontend and SPG frame durations differ: 
End of recognition.
Start recognition of a new utterance...
Ran out of forward link storage during decode: 
Ran out of token storage during decode: 
Reporting empty result due to thrown exception during decode
far_field
SpeechRecognizer must be initialized before calling runSync()
Symbol table list passed to runSyncUtterance() must start empty
uttNum
jsonConfigFilePath
taskType
recognizerComponents
enableWhisperDetection
numLmeDataStreams
utteranceDetection
utteranceConcatenation
epExtraDelay
InputOrigin
LME DataStreams=
 samplingRate=
 taskType=
 deviceId=
 farField=
 enableWhisperDetection=
 endpointerExtraDelay=
 inputOrigin=
 highPriority=
You have provided a reference transcript, which will trigger error-blaming (if specified in 
the config file). This is an EXPERIMENTAL feature that uses lots of memory and incurs lots of 
latency!
runSync:initTime
There is no decoder which affects recognition, this must be a configuration error.
eagerRequested
Eager disabled: not supported by first-pass decoder: 
Eager disabled: silence posterior required but not available: 
Eager disabled: not supported by second-pass decoder: 
eagerUsed
Waiting for first valid feature frame of first utterance...
uttDetectAbort
Rejected
geoLocationStatusUponRequestComplete
recognitionStatus
frontends.
decodables.
decoders.
audioReadTime
featureComputeTime
whisperScore
whisperDetected
utteranceLength
audioEndTime
utteranceEndTime
timeElapsedSinceRunAsyncCall
timeElapsedSinceRunSyncCall
EagerUsed
recognizer-components
DidConfNetCombination
ConfNetWaitTimeMs
ConfNetworkCombinedNbestSourceID
ConfNetworkCombinerStartTimeMs
LastWordClipped
Write results got a NULL lattice
NullLattice
PartialResultsAvgLagMs
PartialResultsToggleCount
FasterPartialResultsAvgLagMs
FasterPartialResultsToggleCount
Shortest path cost: 
lmeStatus
Lattice was not NULL, but failed to generate any choices
NoChoices
RecogThreadCpuTimeMs
EosToPreItnMs
geo-config-file
The 
 field available since version 
. Please upgrade config.
No audio left, and endOfAudio set. Returning false.
Waiting for more audio or endOfAudio
Copied 
 samples (
) into data
returning code: 
Maximum buffer length 
 has been reached. All additional audio will be dropped.
Maximum ring size 
Clipped audio length 
Added 
 samples: 
Signalling end of audio...
PacketsReceived="
Server endpoint triggered so moving buffer marker to end of buffer.
It does not make sense for maxRingSizeSeconds (limit on the amount of unread audio queued in the buffer) to be greater than maxBufferLenReached (limit on the total amount of audio written to the buffer)
Endpointing model file
feature-list
List of features
voice-trigger-phrase
VoiceTrigger phrase as space separated list of tokens as recognized by the decoder
batch-size
Number of feature vectors processed w/o interruption
Could not find the recognizer components for the params samplingRate=
 task=
 device=
 bluetoothDeviceId=
unique_lock::unlock: not locked
unique_lock::lock: references null mutex
unique_lock::lock: already locked
circular_buffer
Token(
Word(
lmeType: 
 is not listed in lmeTypeInOffsetOrder.
Unchecked
Detected
Not Detected
Clipping left context because of unknown word: "
Clipped too big left context: 
 words; limit is 
feature index=
 is in models file but missing in normstats file.
 is in normstats file but missing in model file.
Invalid line in file=
 line=
Did not find feature=
Atleast one feature weight and Intercept is needed in model file=
Successfully loaded streaming confidence model file=
Confidence model file connot be empty. Missing configuration parameter confidence-model-file
Normalization statistics is not in the correct format
Number of features does not match with model file, 
Incorrect number of feature means, 
Incorrect number of feature stddevs, 
Standard deviation is 0 for feature=
Unknown feature=
 in normalization statistics file
Successfully loaded streaming confidence normalization stats file=
Confidence normalization stats file cannot be empty. Missing configuration parameter norm-stats-file
Missing feature index=
 in input features
 feature[
] = 
 in means or stddev stats
Evaluated features=
, confidence=
INTERCEPT
isfirst
isinside
avg_active
avg_bestcost
avg_epsilenceframes
num_frames
Could not read magic header
Magic header was wrong
Could not read number of words
SymbolTable::ReadText: Can't open file 
SymbolTable::Read: Can't open file 
 are padded words
Slow linear search called! This is OK if called during recognition initialization, but should 
NEVER be called during online recognition.
Tried to add overlapping and/or out-of-order symbol table to symbol table list: 
symTableFirstKey=
, previous symbol table's last key=
Word ID 
 not in symbol table 
 with start key 
<eps>
Got word: 
) from symbol table 
 is already in the symbol list - indices in different symbol tables are not distinct
Found an empty LME word, which should not happen
Coding error. addAudio() called after endAudio()
Initialized SyncSpeechRecognizer with config 
SyncSpeechRecognizer not initialized
The value of the 
 field has to be a positive integer but is 
max-radius-km
Geo config file loaded but some parts of config JSON have never been used
Dumping unused parts of geo config JSON ...
Finished loading geography from 
geo-config-version
Unsupported geo config version 
cache-region-id-enabled
regions
Loaded circle geoRegion="
Same 
bitmap-color
 in region 
Loaded bitmap geoRegion="
Internal error. At this point geoRegion=
 must have either bitmap or circle info
Loaded geoCircleRegions=
 geoBitmapRegions=
regions-bitmap
The regions-bitmap section is not available
The config file contains some bitmap regions but the 
 field is missing
Geo ClassLM template=
 assigned to FST from geoRegion=
 based on regions bitmap
Using regionId 
 instead of location
 based on known region id
Internal error, known location expected but got 
Computing geo context for 
Internal error, unknown location expected but got 
Access to geo location denied
 based on cached region id
Cannot resolve regionId=
Location is within max radius of geoRegion=
 based on circle regions
long-name
Long-name field not allowed
, geoRegion=
Bitmap region not allowed
Circle info required
Both circle and bitmap info used in region 
, which is prohibited
Neither bitmap nor circle info found in region 
classLM-template-to-fst-map
Empty FST file name for template 
ClassLM template map required
 in geo config version 
, upgrade to version 
 to avoid this warning
Coordinates out of bounds latitude=
 longitude=
This or other location undefined, can't computer distance
lat=DENIED lon=DENIED
lat=UNDEFINED lon=UNDEFINED
lat=
 lon=
DENIED
UNDEFINED
Unexpected location variant 
KNOWN
bitmap-file
lon-left
lon-right
The value of 
 is not greater than 
lat-bottom
lat-top
Bitmap file name cannot be empty!
.pgm
The bitmap file 
 has unexpected suffix, should be 
Loaded regions bitmap width=
Cannot use degenerate regions bitmap width=
Internal error, expecting a real location at this point
The value 
 is not a valid longitude
 is not a valid latitude
Coding error: the number of arcs has changed after node-merging
column == arcFeatDims
Cannot phone pd2pi file 
Malformed phone pd2pi file line=
Coding error. norm_word not found for arc
Coding error. wordEmbMat not loaded.
Missing voicing regions in audio analytics
Voiced region start: 
 end:
Voicing threshold=
 mean=
 stddev=
Invalid path found.
#Corrections: QsrText-encoded keyword: 
fst-phonomap-file
Phonomap file as an fst. This must be input-arc sorted
phonetic-syms-file
Symbol table file representing the phone set.
default-n-best-size
The default value for n-best size.
corrections.keyword-finder
corrections.
keyword-finder.
corrections.sanitization
#Corrections: No sanitization model is provided.
#Corrections: Keyword Finder returning due to null input (not necessarily an error).
#Corrections: Keyword Finder original input utterance: 
#Corrections: Keyword: 
#Corrections: Keyword pronunciation: 
#Corrections: Keyword location: 
#Corrections: Edit distance: 
#Corrections: 
 KWF results from 
-best list
#Corrections: Pre-itn stitched result 
ImplToFst: Assignment operator disallowed
Sanitizer already initialized.
Initialized Sanitizer
The model is not of type nnet1::Nnet1InferenceNet.
max-num-feats
Maximum number of feats
source-vocab-file
Source vocabulary file
nnet-file
Neural net file
StopWatch is still running.
StopWatch is already running.
StopWatch is not running.
Empty phone in phonetic sequence: 
Could not interpret 
 as a phone. Found in phonetic sequence: 
tag-start
tag-end
parameter-prefix
command-phrase-prefix
Error with configuration for CommandTagger
command-tagger
text-proc
pre = "
post = "
map = 
Reading FST: unsupported hammer FST type: 
Hammer didn't change any text. Therefore returning the original input.
Number of outputs (n) cannot be less than 1.
, start silence: 
Empty tokenName
Pre-text-proc Choice[
Post-text-proc Choice[
Pre-sanitization: 
Post-sanitization Choice[
modelFile doesn't exist, or it's a directory: 
Key not found: 
post-itn-hammer configured key='
' prefix=
Empty post-itn-hammer rule
, jsonConfigPath=
 configured
itn2 configured key='
ignogre itn2 config of 
, what we are looking for is 
Failed to configure itn2
Ignore unknown node text-proc.
Key does not match 'locale' or 'locale::keyboard': 
Locale cannot include leading/trailing whitespace: 
Keyboard cannot include leading/trailing whitespace: 
Locale with separator '
' not supported: 
Keyboard with separator '
Locale=
 should only be used with keyboard=*
Keyboard=* is reserved for internal use
There are itn2 models, but cannot find one for locale=
empty ITN input tokens
locale=
 keyboard="
 itn2="
empty sanitizer input tokens
empty postItnHammer input tokens
 postItnHammer="
post-itn-hammer
default
sanitizer
itn2
lattice-proc
Changed confidence for slot=
1best: 
phrase=
 orig: 
 new: 
Unsupported n-best index configuration
n-best output size is wrong
tag-sequences
en-like
zh_CN
zh-like
algorithm
Algorithm name. Possible values: en-like, zh-like
Invalid algorithm
Index error: [
-derived
Tag with multiple words: 
\contact-first-derived
\contact-last-derived
phrase-length-limit
max-num-enumerations
Building NameEnumerator 
simple
raw-copy
exhaustive
regex
derived
Unknown NameEnumerator "
rule-config-file
rule-type
Rule config file does not exist or it is a directory. File path = 
Read rule config file = 
Failed to parse config file = 
rule: 
 is not valid.
clone-from field is invalid. Rule config file path=
clone-from
pre-alt-gen
post-alt-gen
alt-gen
We do not support step = 
Please check config file for regex rule, step name = 
Enumeration is calculated already.
Step name must be 
 or 
mutually-exclusive-group
from
validate-brackets
validate-brackets will be overwritten by validate-brackets = 
(?i)
split-case-sensitive
max-alt
max-alt will be overwritten by max-alt = 
split-case-sensitive will be overwritten by split-case-sensitive = 
\g<0>
Config Version is not high enough for index rule denumeration
Enumeration rules not configured
The default tag for denumeration
Config Version is not high enough for denumeration
LmeWordTagger not used
Unsupported number of lme-word-taggers
Unsupported lme-word-tagger
lme-word-tagger
index-rule-tagger
rules
index
default-tag
Invalid or out-of-range hex value
Found token separator char in token: "
Found unassigned code point 
 in string "
Unicode normalization failed for:
Input string is not Unicode normalized:
Found illegal char with value 
~U is not followed by 8 hex digits
~U is not followed by a valid unloggly code point
~w is not followed by 2 hex digits
~w followed by hexValue=
Encountered invalid tilde char: 
Unicode normalization failed for :
Illegal occurrence of ^ in HatText token 
Illegal use of ^ followed by value 
 in HatText token 
Conversion failed for qsr token 
Illegal occurrence of ~U in QsrText token 
Illegal occurrence of ~w in QsrText token 
Unsupported occurrence of ~w in QsrText token 
Illegal use of ~ in QsrText token 
Illegal occurrence of ~U in QsrText string 
Illegal occurrence of ~w in QsrText string 
Unsupported occurrence of ~w in QsrText string 
Illegal use of ~ in QsrText string 
) -> 
Failed to encode srcToken="
" dstToken="
u_strFromUTF8() failed with error=
Unicode NFC normalization failed.
u_strToUTF8() failed with error=
TextSanitizer is already initialized
[^\u0000-\uFFEF]
Failed to compile unicode outliers regex
|\(|\)|"|\[|\]|\{|\}|
|,|;|\?|\!|\\
Failed to compile special characters regex
(\s)+
Failed to compile duplicate spaces regex
[\p{C}]+
Failed to compile control characters regex
TextSanitizer is not initialized
Empty string received.
wstring_convert failed for text: 
Failed to normalize 
Could not open UTF8: : 
Failed to replace unicode characters in range [\u0000-\uFFEF]: 
Failed to remove some special characters: 
Failed to remove redundant space characters: 
Failed to remove control characters: 
sanitized string is empty
Intermidiate basic sanitization result=
wstring_convert: from_bytes error
wstring_convert: to_bytes error
text=
 tokens=[
.frontend
.nfhat
Silence posterior generator created with incorrect version
frameByFrame requires output batch size of 1
same-state-transition-probability
Same state transition probablity
acoustic-evidence-deweighting-power
Acoustic evidence deweighting power
Endpoint model file
model-feature-list
sequence of features for endpoint model
enable-memory-map
model is memory mapped
endpoint-threshold
Threshold for final endpoint detection
trailing-silence-limit
An upper limit for trailing silence duration (miliseconds) after which recognizer should be forced to endpoint
extra-delay-ms
delaying the endpointer trigger decision by th given amount of time (in msec), when specified.
silence-posterior-nfhat-limit
An upper limit for silence posterior NFHat estimate (miliseconds) after which recognizer should be forced to endpoint
server-features-latency-clamp-begin
Starting point (in miliseconds)for ServerFeaturesLatency Clamp. ServerFeaturesLatency will be clamped at this value for the duration of clamp i.e [serverFeaturesLatencyClampBeginMs, serverFeaturesLatencyClampEndMs]
server-features-latency-clamp-end
Ending point (in miliseconds)for ServerFeaturesLatency Clamp. ServerFeaturesLatency will be allowed to update after this point i.e it will not be clamped anymore
endpoint-threshold needs to be configured to a value between 0-1
num-of-words default
trailing-silence-duration default
eos-likelihood default
silence-posterior default
Hybrid endpointer created with incorrect version
hybrid-endpoint
hybrid-endpoint.
Missing hybrid endpointer config
eager-result-acceptance
eager-result-acceptance.
Missing eager-result-acceptance config
default-server-ep-features
default-server-ep-features.
No available endpointer for samplingRate = 
Feature dim=
 does not match model dim=
Nnet output for endpointing is incorrect
, ep-nnet-value=
EagerResultAccept not configured
Nnet output for recognitionResult validation is incorrect
, nnet-output=
Initialized nnet with Model file =
Endpoint model file cannot be empty
Feature unknown, 
features allowed are ("num-of-words","num-trailing-sil", "num-frames","end-of-sentence","pause-counts","num-input-label-words","stream-conf","silence-posterior","client-silence-frames-count-ms","client-silence-probability","silence-posterior-nf","server-features-latency", "eager-result-end-time")
ASR prons are empty
Unsupported language=
Unknown asr phoneme = 
Language = 
, IPA prons=
, ASR prons=
en_AU
en_GB
es_ES
es_US
fr_CA
fr_FR
it_IT
ja_JP
ko_KR
zh_HK
aai1
aai2
aai3
aai4
aai5
aai6
aau1
aau2
aau3
aau4
aau5
aau6
eoi1
eoi2
eoi3
eoi4
eoi5
eoi6
zh_TW
de_DE
notch-detector.hfpower.txt
notch-detector.wt.txt
notch-detector.weighted.spectrum.txt
avlo = 
  avhi = 
bands_below.lo = 
, bands_below.hi = 
bands_notch.lo = 
, bands_notch.hi = 
bands_above.lo = 
, bands_above.hi = 
bands_across.lo = 
, bands_across.hi = 
notch-detector.peak.txt
notchWidth %d, antiNotch %d, mR %d, mK %d, mN %d 
notchVec[%d]=%d 
notch-detector.psd.txt
notch-detector.fft.txt
notch-detector.feats.txt
fst_custom.fst
decoders
lattice-biglm-lme-faster.big-g-fst-file-list
big-g-fst-file-list not found for decoder 
lattice-biglm-lme-faster.word-syms-map-file
Symbol-table file not found in json file 
lmeDataFactory initialization failed!
G2P model does not exist
1shot_new.json
{{TEMPLATE}}
\NT-unknown
Failed to tokenize
Tokenizer could not tokenize
template list not found for used template 
template list not found for used template: 
template names should be enclosed in {} and contain only one word (lowercase)
Number of OOVs = 
\unknown-first
No OOVs
could not get LME data
Template names should be enclosed in {} and contain only one word (in lowercase)
No templates provided
Template names should be enclosed in {} and contain only one word
Template list found more than once for : 
WARNING
Input FST is cyclic
Could not write fst to file path 
Could not write fst to file
big-g-fst-file-list
big-g-fst-weight-list
lattice-biglm-lme-faster
ArcMap: non-zero arc labels for superfinal arc
EncodeMapper: Label-encoded arc has different input and output labels
EncodeMapper: Weight-encoded arc has non-trivial weight
EncodeMapper: decode failed
EncodeTable::Decode: unknown decode key: 
FST is not an unweighted acceptor
Acyclic Minimization
Cyclic Minimization
Weight::Properties() & kIdempotent
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/EmbeddedAcousticRecognition-216.6/libquasar/libkaldi/tools/openfst/src/include/fst/minimize.h
Check failed: "
" file: 
 line: 
VectorFst::Write: write failed: 
reverse_
PrePartition
Initial Partition: 
StateSort: bad order vector size: 
AutoQueue: using state-order discipline
AutoQueue: using top-order discipline
AutoQueue: using LIFO discipline
AutoQueue: using SCC meta-discipline
AutoQueue: SCC #
: using trivial discipline
: using shortest-first discipline
: using LIFO disciplle
: using FIFO disciplle
TopOrderQueue: fst is not acyclic.
DeterminizeFst:
 distance to final states computed for acceptors only
DeterminizeFst: argument not an acceptor
determinize
DeterminizeFsaImpl: cannot copy with out_dist vector
GCCacheStore: Enter GC: object = 
), free recently cached = 
, cache size = 
, cache frac = 
, cache limit = 
(size) <= (cache_size_)
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/EmbeddedAcousticRecognition-216.6/libquasar/libkaldi/tools/openfst/src/include/fst/cache.h
GCCacheStore:GC: Unable to free all cached states
GCCacheStore: Exit GC: object = 
DeterminizeFst: 
a state table can not be passed with transducer input
ArcMapFst: non-zero arc labels for superfinal arc
StringWeight::Divide: 
only explicit left or right division is defined 
for the 
 semiring
restricted_string
factor_weight
FactorWeightFst: factor mode is set to 0: 
factoring neither arc weights nor final weights.
FromGallicMapper: unrepresentable weight: 
 for arc with ilabel = 
, olabel = 
, nextstate = 
CompositeWeightWriter: 
FLAGS_fst_weight_separator.size() is not equal to 1
FLAGS_fst_weight_parentheses.size() is not equal to 2
Epsilon
Infinity
BadString
-Infinity
BadNumber
StringWeight::Plus: unequal arguments 
(non-functional FST?)
 w1 = 
 w2 = 
EmptySet
BadSet
RmEpsilon: inconsistent acyclic property bit
latency
numFramesProcessed
totalWallTime
acousticLatency
contextModelLatency
localeSpecificMetrics
languageCode
posterior
messageLanguageTaggingLatency
detectedLocale
conversationMessagePriors
lastMessageLanguage
numAcousticRuns
acousticScores
Invalid locale string given 
Logging LDContext
priors=
dictation_locales=[
current_dictaion_locale=
was_language_toggled=
multilingual_keyboard_locales=[
keyboard_convo_locale_priors=
keyboard_global_locale_priors=
previous_message_locale=
global_last_keyboard_used=
dictation_locale_priors=
window-size
The number of frames to be considered per decision. In flexible input size, this is the minimum window.
feature-dim
The dimension size of the features.
languages-list
Comma separated list of languages
compiled-model-file
The name of the compiled model file
model-input-name
The name of the key for the model input
model-output-name
The name of the key for the model output
use-flexible-model
Whether or not the model accepts flexible (variable) input size.
max-window-size
The maximum size window for processing. Only works with flexible input size enabled.
use-cpu-only
Only use the CPU for inference
send-only-final-result
Do not send incremental results, send only the final result. Fixed input will always only send the final result.
minimum-confidence
For flexible input size, the minimum confidence for sending early results back. Only works with flexible input size enabled.
prediction-interval
The interval which we should make decisions (-1 is only once). Only works with flexible input size enabled.
ui-minimum-confidence
Determines whether or no the UI should consider the result non-confident. Should be greater than or equal to minimum-confidence.
input-tensor-shape
The shape of the input tensor specified by (dims, row index, col index).
Only use prediction interval with variable size input.
Max window size much be configured for flexible model
Must unable useFlexibleModel to have variable input size.
Maximum window size configured to be less than window size
Shape of the input tensor must be specified through (dims, row index, col index).
Input tensor row index must be non-negative and less than input tensor dims.
Input tensor col index must be non-negative less than input tensor dims.
Context provided no locale priors.
No acoustic posteriors.
Using dummy context model. Since acoustic posteriors are equal, defaulting to dictationLocales and currentDictationLocale from the context.
core-ml
acousticLanguagePosteriors
dictationLocales
currentDictationLocale
wasLocaleToggled
multilingualKeyboardLocales
keyboardConvoLocalePriors
keyboardGlobalLocalePriors
previousMessageLocale
dictationLocalePriors
model-file
path to the model file
supported-locales
the locales understood by the model
supported-languages
the languages understood by the model
model-file-format
the format of the model file, must be "core-ml"
model-input-names
the input features expected by the model
the output feature that contains the locale posteriors
Invalid model file format "
Model input names contains duplicates
Invalid context-aware input feature name "
language-detectors
Configuration is incorrect. Only two components are supported.
ld-frontends.
ld-inference-model.
Something went wrong initializing the model.
override-locale-language-map
ld-context-aware-model
 found in config file, but no ContextAwareLDModelFactory was provided.
Something went wrong initializing the ContextAwareLDModelConfig.
Invalid sampling rate 
given.
Resetting for new request.
Version 118 or greater is required.
Unable to reset model.
Processed 
 frames of audio.
Data is empty
Reached maximum window size. Treating this as the end of audio.
Not enough features yet to meet minimum window size.
Waiting until the next predictionInterval to run.
Running LanguageDetector with 
 frames
Something went wrong in LD inference.
Error in processing acoustic result.
Error running acoustic model.
No valid window found. Running contextual model based on equal acoustic priors.
Contextual model failed to run properly.
Language detector max confidence: 
Metrics for locale not in input: 
No context.
Empty priors.
If dictation priors are defined, then dictation locales must be.
map::at:  key not found
4, 1, 2
unimplemented
Non matching dimensions: Rows:
 VectorDim:
Non matching dimensions: Cols:
matrix A and B can not be transposed at the same time, not implemented yet
cannot write data to zero size vector
Failed to create a 
 by 
 matrix with only 
 bytes available in the workspace
Failed to create a vector of 
 elements with only 
size >= 0
mem_size_bytes >= 0
Can't create a child workspace of 
. Only have 
 bytes
bitset set argument out of range
No frames fit in file (#samples is 
Non-finite log energy found for frame 
#remaining_frames for fbank 
 and energy 
 don't match!
mismatch between finished pitch frames and remaining frames+new wav frames: 
 v.s. 
Non-finite energy found for frame 
. Waveform is: 
mismatch between finished audio analytics frames and remaining frames+new wav frames: 
hanning
hamming
rectangular
Invalid window type 
Inconsistent setting: center=true but lookahead is set to 
Flooring variance When normalizing variance, floored 
 elements; num-frames was 
Must have at least 3 mel bins
Bad values in options: low-freq 
 and high-freq 
 vs. nyquist 
Bad values in options: vtln-low 
 and vtln-high 
, versus 
low-freq 
Invalid indexing. You may have set --num-mel-bins too large.
bin 
, offset = 
, vec = 
MEL BANKS:
No frames output in pitch extraction
Pitch-tracking Viterbi cost is 
 per frame, over 
Forward-cost per frame changed from 
Latency is 
Undefined GCD since m = 0, n = 0.
Invalid frame range. Coding error.
signal energy (dB) = 
 noise energy (dB) = 
Pruned state-level lattice with beam 
 and retrying determinization with that beam.
Effective beam 
 was less than beam 
 * cutoff 
, pruning raw 
lattice with new beam 
 and retrying.
Both --phone-determinize and --word-determinize are set to 
false, copying lattice without determinization.
Doing first pass of determinization on phone + word 
lattices.
Doing second pass of determinization on word lattices.
Pushing and minimizing on word lattices.
Topological sorting of state-level lattice failed (probably
 your lexicon has empty words or your LM has epsilon cycles
Lattice determinization terminated but not 
 because of lattice-beam.  (#states, #arcs) is ( 
 ), versus limits ( 
 ) (else, may be memory limit).
Total weight of input lattice is zero.
Lattice determinization aborted since looped more than 
Cost below best cost was encountered:
Rebuilt repository in determinize-lattice: repository shrank from 
 bytes (approximately)
Did not reach requested beam in determinize-lattice: 
size exceeds maximum 
 bytes; (repo,arcs,elems) = (
), after rebuilding, repo size was 
, effective beam was 
 vs. requested beam 
Rebuilding repository.
empty subset
Zero weight!
New cost is less (check the difference is small) 
strlen(FLAGS_fst_weight_separator) == 1
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/EmbeddedAcousticRecognition-216.6/libquasar/libkaldi/src/fstext/lattice-weight.h
 score= 
Cycles detected in lattice.
Invalid list of region specifiers provided 
Using non-terminal regions for combination from 
Splitting into labels : 
NULL
 Check start 
 end 
 against start 
 lab in lat 
 lab in check 
Found state 
 id 
 start 
 For MBR start 
 distance is 
Match 
not_in_static_vocab
 Find Overlapping With 
Word with ID = 
 does not exist in word map. Is a dynamic vocabulary being used?
No arc to continue with
Recomputing TBP on Ref Interval 
 for arc on 
Recomputed TBP is 
 post score avg is 
Compact Lattice Current state=
 ARC ilabel: 
 olabel: 
 weight1: 
 weight2: 
Next State=
 duration = 
 word is 
Original Duration Was 
 without silence it is 
Warning - state Time Mismatch - 
Time = 
 not in state posterior map...
Couldn't find state 
 at time 
 defaulting posterior to 0, w1=
 w2=
No states in the word posterior computation - this may be because the word has 0 duration (could happen for class LM)
Utterance ID is 
Needed to find 
 actually only found 
Couldn't find arc
Warning: MISMATCH BETWEEN LENGTH OF 1-BEST and LENGTH OF CONFIDENCE VECTOR
Finished generating 1-best word-level confidence features for 
 words in utterance 
Add Candidate: 
 to candidate/confusion set
Candidate Update: 
Confidence score @ word 
 MBR SCORE IS 
Confidence score @ alt word 
Using special symbol for silence = 
Adding hypothesis number 
 additional cost for non 1-best 
Adding 1-best [
] pen= 0.0 score= 
Add 1-Best word 
 confidence 
Adding alternative [
] pen= 
Was not able to topologically sort lattice (cycles found?)
INIT
MODEL
No Confidence Model Supplied.
constant
intercept
Setting constant term/intercept to 
Setting 
Feature 
 is not in the model definition.
Read in Confidence Model , added 
 features
Scaling feature 
 with value of 
 by weight = 
Warning - confidence is NaN or inf, or will be inf in log - confidence model could be bad/compromised. Defaulting to 1.0
Confidence score is 
Rank in list = 
 Orig = 
 sc= 
 LOW 
 HIGH 
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/EmbeddedAcousticRecognition-216.6/libquasar/libkaldi/src/../tools/openfst/src/include/fst/cache.h
p_avg
p_max
p_min
p_geo
comb_score
lm_post
am_post
n_match
n_intersect
p_wcr
p_uni_lm
p_avg_low
p_avg_high
p_avg_diffhigh
p_avg_difflow
rank_score
low_rank_score
high_rank_score
delta_low
delta_high
p_mbr
p_fan_out
n_fan_out
p_fan_in
n_fan_in
n_wrd_inutt
avg_depth
avg_post
avg_ac
avg_lm
avg_conf
avg_like
avg_likelow
avg_likehigh
avg_ac_like
avg_ac_likelow
avg_ac_likehigh
ob_start
ob_dur
ob_p_avg
ob_p_max
ob_p_min
ob_p_geo
ob_comb_score
ob_lm_post
ob_am_post
ob_n_match
ob_n_intersect
ob_p_wcr
ob_p_uni_lm
ob_p_avg_low
ob_p_avg_high
ob_p_avg_diffhigh
ob_p_avg_difflow
ob_rank_score
ob_low_rank_score
ob_high_rank_score
ob_delta_low
ob_delta_high
ob_p_mbr
ob_p_fan_out
ob_n_fan_out
ob_p_fan_in
ob_n_fan_in
cand_p_avg
cand_p_min
cand_p_max
is_eps
alt_hyp_overlap
hyp_sub_alt_prev
hyp_sub_alt
hyp_sub_alt_next
alt_sub_hyp_prev
alt_sub_hyp
alt_sub_hyp_next
alt_lthalf_hyp
hyp_lthalf_alt
alt_in_prev
alt_prev_score
alt_in_next
alt_next_score
alt_tbp
ob_tbp
num_in_confset
prev_in_ob
next_in_ob
prev_best_score
next_best_score
cand_avg_p_avg
cand_avg_tbp
cand_avg_p_max
cand_avg_p_min
cand_wrd_len
sub_compound_left
sub_compound_right
is_lme_word
ob_is_lme_word
alt_has_lme_word
is_one_best
phonetic_dist_to_ob
min_phonetic_dist_confset
m.size() == Features::kFeatureCount
lattice4
compact
SingleShortestPath: for nshortest > 1, use ShortestPath
 instead
SingleShortestPath: weight and state thresholds not applicable
NShortestPath: FST has a cycle and include_final_ties was set to true. This is not currently supported.
Division by zero [0/0] in CompactLatticeWeightTpl
Error: division by zero in CompactLatticeWeightTpl::Divide()
Error in Divide (CompactLatticeWeightTpl): cannot divide, length mismatch.
Error in Divide (CompactLatticeWeighTpl): cannot divide, data mismatch.
Cannot divide CompactLatticeWeightTpl with DIVIDE_ANY.
LatticeWeightTpl::Divide, NaN or invalid number produced. 
[dividing by zero?]  Returning zero.
_LT_
SortedMatcher: bad match type
ComposeFst: Weights must be a commutative semiring: 
compose
ComposeFst: output symbol table of 1st argument 
does not match input symbol table of 2nd argument
CompatSymbols: Symbol table check sums do not match. 
Table sizes are 
ComposeFst: 1st argument requires matching but cannot.
ComposeFst: 2nd argument requires matching but cannot.
ComposeFst: 1st argument cannot match on output labels 
and 2nd argument cannot match on input labels (sort?).
ComposeFst: both sides can't require match
ComposeFstMatcher: safe copy not supported
Union: input/output symbol tables of 1st argument 
do not match input/output symbol tables of 2nd argument
Cycles detected in lattice
Input lattice must be topologically sorted.
Invalid lattice: different paths have a different number of frames
Utterance does not seem to have a consistent length.
Utterance does not have a final-state.
Invalid lattice: final state before max_time
Total forward probability over lattice = 
, while total backward probability = 
Non-finite total probability in lattice (
Topological sorting failed
Done Topo Sort
Failure in best-path algorithm for lattice (infinite costs?)
Add 
 ilabel 
 olabel 
 usedarcind 
 weight 
Rescoring empty lattice
the DeterministicOnDemandFst is invalid
cannot find arc with label 
 on state 
 in the LM FST, wrong input?
Lattice score cache indices = 
 vals = 
Supplied frame 
 is out of range of cache which is in [0,
Pdf 
 is not in cache for frame 
Topological sorting of state-level lattice failed (probably your lexicon has empty words or your LM has epsilon cycles; this  is a bad idea.)
Minimizing lattice with self-loops (lattices should not have self-loops)
Largest equivalence group (using hash) is 
, minimization might be slow.
Removing 
 states.
Pushing weights of empty compact lattice
Lattice has non-coaccessible states.
Changing word 
Iter = 
, delta-Q = 
Iterating too many times in MbrDecode; stopping.
Edit distance increased: 
L = 
Invalid b_arc value
sum of gamma[
,s] is 
Times out of order
MBR Sausage Alignment Epsilon Symbol is 
Phone changed before final transition-id found [broken lattice or mismatched model or wrong --reorder option?]
Phone changed unexpectedly in lattice [broken lattice or mismatched model?]
Unexpected phone 
 found inside a word.
Phone changed while following final self-loop [broken lattice or mismatched model or wrong --reorder option?]
Invalid word at end of lattice [partial lattice, forced out?]
Discarding word-ids at the end of a sentence, that don't have alignments.
Broken silence arc at end of utterance (the phone changed); code error
Broken silence arc at end of utterance (does not reach end of silence)
Partial word detected at end of utterance
Code error, word-aligning lattice
Not expecting binary unpronounced words file.
Invalid line in unpronounced words file: 
Invalid line in word-boundary file: 
nonword
begin
singleton
internal
Empty word-boundary file
[Lattice has input epsilons and/or is not input-deterministic 
(in Mohri sense)]-- i.e. lattice is not deterministic.  
Word-alignment may be slow and-or blow up in memory.
Trying to word-align empty lattice.
Number of states in lattice exceeded max-states of 
, original lattice had 
 states.  Returning what we have.
final_weight.String().empty()
final_weight.Weight().Value1() == 0.0
final_weight.Weight().Value2() == 0.0
best cost = 
path len=
 mean conf=
Write failure in WriteBasicType<bool>
Read failure in ReadBasicType<bool>, file position is 
ReadBasicType: expected float, saw 
ReadBasicType: failed to read, at file position 
Write failure in WriteToken.
ReadToken, failed to read token at file position 
ReadToken, expected space after token, saw instead 
Error ungetting '<' in PeekToken
Failed to read token [started at file position 
], expected 
Expected token "
", got instead "
NumFramesReady() not implemented for this decodable type.
KALDI_ASSERT: at 
, failed: 
Stack trace is:
[stack trace: ]
'%c'
[character %d]
Unsupported storage type 
<Function>
<OutputTensor>
ret == ESPRESSO_STATUS_SUCCESS
Espresso failed to reset plan with 
Espresso failed to declare input `
' with 
Espresso failed to declare output `
Espresso failed to unpack shape for input `
Espresso failed to change input blob shapes with 
Espresso failed to build plan with 
Tensor rank is greater than 2: 
arc_output_model_file.empty()
output_model_file.empty()
Mismatch in number of key and value pairs in ScaledDotAttention, got 
 keys and 
 values
Mismatch of key matrix input in ScaledDotAttention, expected 
, but got 
Mismatch of value matrix input in ScaledDotAttention, expected 
SetKeyValueStores needs to be called in ScaledDotAttention for attention to work
<AddQuery>
<QueryTransform>
<KeyTransform>
<ValueTransform>
<OutputTransform>
Reading ScaledDotAttention component
reading query transform failed
reading key transform failed
reading value transform failed
reading output transform failed
<NumberHeads>
Reading MultiHeadAttention component
<SupervisedHeads>
Reading SupervisedMultiHeadAttention component
Reading SelfAttention component
<Attention>
failed to read attention component in SelfAttention
ResetHistoryState for SelfAttention makes only sense if all utterances get reset at the same time
<AverageFfn>
<Gate>
Reading AverageAttention component
reading average feed-forward network failed
done
reading input gate network failed
</AverageAttention>
Recurrent neural networks are not supported inside the average attention component.
ResetHistoryState for AverageAttention makes only sense if all utterances get reset at the same time
Performing vectorization of affine transform component
veccorrs->size() == linearity_corr_.size() && veccorrs->size() == bias_corr_.size()
(LinearityCorr(ic).NumRows() * LinearityCorr(ic).NumCols() + bias_corr_[ic]->Dim()) == NumParams()
Done  vectorization of affine transform component
 (ParamStddev|BiasMean|BiasRange|LearnRateCoef|BiasLearnRateCoef|MaxNorm|InitTransformType|GradientNormType|MaxGrad|RandomSeed)
Bias().Dim() == vec.Dim()
<RecurrentComponentType>
 (RecurrentComponentType)
you defined two different recurrent component types 
this is not a recurrent component, initialization failed, you used 
forward component is not an RNN
backward component is not an RNN
## Forward RNN: input-dim 
## Backward RNN: input-dim 
no recursive recurrent definition
the forward RNN's input dimension does not match the component's input dimension 
the backward RNN's input dimension does not match the component's input dimension 
the component has output dimension 
 , doesn't equal the sum of individual RNN 
This function is probably not meaningful for bidirectional RNNs.
Running on single input doesn't make sense for bidirectional RNNs, since history state is not saved.
Forward RNN is not quantizable
Backward RNN is not quantizable
Unknown component type: 
Unknown gradient normalizaiton type: 
Unknown matrix initialization type: 
please update to formatted name 
 ASAP, you used 
Unknown component type marker: 
Unknown gradient normalization marker: 
Unknown matrix initialization marker: 
Missing type: 
Initializing component of type 
<InputDim>
<OutputDim>
the L2 Norm clipping value must be greater than 0, you set 
either the gradient or the gradient norm data is not initialized
the gradient clipping value must be greater than 0, you set 
the gradient data is not initialized
the factor in RMSPROP must be [0, 1], you set 
The input dimension is not divisible by the output dimension
VectorizeWeightsCorrs
 is not implemented for 
 component.
the vector cannot be represented as a matrix with rows 
 , while it has dimension 
GetUnitOutputFnc
GetNormalizedLearningRate
PerturbParams
GetGradient
need RecurrentNnetTrainOptions in recurrent style component, ignoring SetTrainOptions
Non-matching dims! Input batch size: 
 output dim : 
Requested output for invalid unit: 
; total units = 
Relaxation factor must be positive; found: 
<RelaxFactor>
<BlockDims>
</Component>
Unknown token 
, a typo in config?
 (BlockDims)
ReadIntegerVector: expected to see type of size 
, saw instead 
, at file position 
ReadIntegerVector: expected to see [, saw 
ReadIntegerVector: read failure at file position 
Total block dimensions and output dimension mismatch
Could not align output
Write failure in WriteIntegerType.
<DropoutRetention>
 (DropoutRetention)
<Alpha>
Unimplemented
  frame_offsets 
<ReadVector>
<BuildVector>
</BuildVector>
 (ReadVector|BuildVector)
Error parsing <BuildVector>
BackpropagateFnc
Not implemented!
Unity component doesn't expect any tokens
<DuplicateStart>
<DuplicateSize>
<NumDuplicates>
 (DuplicateStart|DuplicateSize|NumDuplicates)
Requested duplication doesn't match the output and input sizes
Duplication parameters out of range
 shift_data
  shift_data_grad
, lr-coef 
<InitParam>
<LearnRateCoef>
<GradientNormType>
<MaxGrad>
 (InitParam|LearnRateCoef|GradientNormType|MaxGrad)
unrecognized config token 
 scale_data
  scale_data_grad
 (InitParam)
<VisibleType>
<HiddenType>
<VisibleBiasMean>
<VisibleBiasRange>
<HiddenBiasMean>
<HiddenBiasRange>
<ParamStddev>
<VisibleBiasCmvnFilename>
<RandomSeed>
 Typo in config?
 (VisibleType|HiddenType|VisibleBiasMean|VisibleBiasRange|HiddenBiasMean|HiddenBiasRange|ParamStddev|VisibleBiasCmvnFilename|RandomSeed)
bern
Bernoulli
gauss
Gaussian
Wrong <VisibleType>
Wrong <HiddenType>
Initializing from <VisibleBiasCmvnFilename> 
Unknown type 
Nonmatching dims, component:
pos_vis
pos_hid
neg_vis
Mismatch between pos_vis and neg_vis variances, 
danger of weight explosion. a) Reducing weights with scale 
 b) Lowering learning rate to 
 [pos_vis_std:
,neg_vis_std:
'inf' in 
'nan' in 
Forcing the variance to be non-negative! 
->0.0
<MSDims>
 (MSDims)
this implementation only models the strict recurrent component, i.e, it requests the input 
and output dimensions be the same,  you set input/out dimension to 
<BiasMean>
<BiasRange>
<MaxNorm>
<BiasLearnRateCoef>
<Nonlinearity>
<InitTransformType>
 (Nonlinearity|ParamStddev|BiasMean|BiasRange|LearnRateCoef|BiasLearnRateCoef|MaxNorm|RandomSeed|MaxGrad|InitTransformType|GradientNormType)
 linearity
 bias
  linearity_grad is uninitialized
  bias_grad is uninitialized
  linearity_grad
, max-norm 
  bias_grad
Unknown nonlinearity type: 
 filters: 
 bias: 
  filters_grad
<PatchDim>
<PatchStep>
<PatchStride>
 (ParamStddev|BiasMean|BiasRange|PatchDim|PatchStep|PatchStride|MaxNorm|GradientNormType|MaxGrad|RandomSeed)
num_splice 
num_patches 
filter_dim 
num_filters 
<PoolSize>
<PoolStep>
<PoolStride>
<Scale>
 (PoolSize|PoolStep|PoolStride|Scale)
 (PoolSize|PoolStep|PoolStride)
<FmapXLen>
<FmapYLen>
<PoolXLen>
<PoolYLen>
<PoolXStep>
<PoolYStep>
 (FmapXLen|FmapYLen|PoolXLen|PoolYLen|PoolXStep|PoolYStep)
num_fmaps 
Invalid component parameters
<SpliceLength>
<RowStride>
<TimeLength>
nested_network {
nested_gradient {
<NestedNnetFilename>
<NestedNnetProto>
<LearnRateFactor>
  (offset,weights) : 
  lr-coef 
  (offset,weights_grad) : 
<FeatureDim>
<CentralOffset>
<PoolWeight>
<Normalize>
 (FeatureDim|CentralOffset <vec>|PoolSize <vec>|LearnRateCoef|Normalize)
Initializing from pool-weight vector
<FrameOffset>
<FrameWeight>
the multi subbatch version for this class is not implemented yet
the ParallelComponent has history size 
</NestedNnetFilename>
</NestedNnetProto>
, typo in config?
 (NestedNnetFilename|NestedNnetProto)
Input dimension of parallel component and input dimensions of nested networks do not match.
Output dimension of parallel component and output dimensions of nested networks do not match.
<NestedNnetCount>
<NestedNnet>
</ParallelComponent>
nested_network #
nested_gradient #
nested_propagate #
nested_backpropagate #
<NumComponents>
The input dimension is not divisible by the number of components
The output dimension does not match the dimension of individual component
<ComponentWeight>
</InterpolationComponent>
 CompressedWordVec table
 WordVec table
 we don't save intermediate gradient
<VocabSize>
<FillerSymbolId>
 (ParamStddev|LearnRateCoef|VocabSize|RandomSeed|InitTransformType|GradientNormType|MaxGrad)
invalid vocabulary size 
it doesn't make sense to initialize the word vec as an identify matrix
Wrong quantizer type (neither 
 nor 
 ): 
RMSPROP is not implemented in word embedding yet
not implemented
, bias-lr-coef 
 (ParamStddev|BiasMean|BiasRange|LearnRateCoef|BiasLearnRateCoef|InitTransformType|RandomSeed|GradientNormType|MaxGrad)
it does not make sense to do RMSPROP in this component
 CompressedWordTrans table
ReadBasicType: encountered end of stream.
ReadBasicType: did not get expected integer type, 
 vs. 
.  You can change this code to successfully
 read it later, if needed.
Read failure in ReadBasicType, file position is 
, next char is 
Write failure in WriteBasicType.
<AffineTransform>
<LinearTransform>
<Quantized8BitLinearTransform>
<Quantized16BitLinearTransform>
<SharedNceComponent>
<ConvolutionalComponent>
<ConvolutionalMaxPoolingComponent>
<Quantized8BitConvolutionalMaxPoolingComponent>
<Quantized16BitConvolutionalMaxPoolingComponent>
<Convolutional2DComponent>
<Quantized8BitConvolutional2DComponent>
<Quantized16BitConvolutional2DComponent>
<LstmComponent>
<Quantized8BitLstmComponent>
<Quantized16BitLstmComponent>
<GatedRecurrentUnit>
<Recurrent>
<BidirectionalRecurrentComponent>
<WordVecComponent>
<FofeWordVecComponent>
<WordMultiVecComponent>
<CompressedWordMultiVecComponent>
<CompressedWordVecComponent>
<FixedAttentionComponent>
<MovingAttentionComponent>
<GlobalAttentionComponent>
<GlobalRecurrentAttention>
<ScaledDotAttention>
<MultiHeadAttention>
<SupervisedMultiHeadAttention>
<SelfAttention>
<AverageAttention>
<LayerNorm>
<Softmax>
<LogSoftmax>
<BlockSoftmax>
<MultiSoftmax>
<RelaxedSoftmax>
<Sigmoid>
<Tanh>
<Dropout>
<Maxout>
<Rectified>
<ExponentialLinear>
<ScaledExponentialLinear>
<PNorm>
<Rbm>
<Splice>
<Desplice>
<Copy>
<CnnRearrangeComponent>
<PaddingComponent>
<Padding2DComponent>
<AddShift>
<Rescale>
<QuantizedAffineTransform>
<Quantized16BitAffineTransform>
<NormalizeComponent>
<KlHmm>
<AveragePoolingComponent>
<AveragePooling2DComponent>
<MaxPoolingComponent>
<MaxPooling2DComponent>
<SentenceAveragingComponent>
<FramePoolingComponent>
<ParallelComponent>
<Duplicate>
<Identity>
<TemporalMaxPooling>
<InterpolationComponent>
<CompressedWordTransComponent>
<VectorwiseQuantized8BitAffineTransform>
<VectorwiseQuantized16BitAffineTransform>
ClipValue
ClipL2Norm
Rmsprop
Identity
Uniform
Gauss
  linearity is quantized
  bias
 Not implemented!
  linearity is vectorwise quantized
<FiltXLen>
<FiltYLen>
<FiltXStep>
<FiltYStep>
<PadX>
<PadY>
 (ParamStddev|BiasMean|BiasRange|FmapXLen|FmapYLen|FiltXLen|FiltYLen|FiltXStep|FiltYStep|ConnectFmap|LearnRateCoef|BiasLearnRateCoef|RandomSeed|GradientNormType|MaxGrad)
input_dim_ % (fmap_x_len_ * fmap_y_len_) == 0
output_dim_ % (out_fmap_x_len * out_fmap_y_len) == 0
filters_->NumRows() == num_output_fmaps && filters_->NumCols() == num_input_fmaps * filt_x_len_ * filt_y_len_
wei_src.Dim() == NumParams()
 OutSizeX:
 OutSizeY:
 InFmaps:
 OutFmaps:
Performing vectorization of convolutional 2d component
(nlinparams + bias_->Dim()) == NumParams()
Done  vectorization of convolutional 2D component
Convolutional2DComponent needs workspace set to perform back-propagation
Unsupported BNNS filter weight arrangement
It did not work
BNNS only supports one batch
Unsupported
After assign, Convolution filter has padding? 
<InFeatureMaps>
<OutFeatureMaps>
<SectionStep>
<SectionSize>
<FilterSize>
<InSharedBands>
 (ParamStddev|BiasMean|BiasRange|InFeatureMaps|OutFeatureMaps|PatchStep|SectionStep|SectionSize|FilterSize|LearnRateCoef|BiasLearnRateCoef|MaxNorm|RandomSeed)
ConvolutionalMaxPoolingComponent: Invalid max pooling size
ConvolutionalMaxPoolingComponent: Max pooling step must be >= 1
ConvolutionalMaxPoolingComponent: output dim mismatch
ConvolutionalMaxPoolingComponent: input dim mismatch
ConvolutionalMaxPoolingComponent: too few input bands to compute the output
pointer is thought to be un-initialized here
<Filters>
<Bias>
  filters
 , # of sections: 
, section size after pooling: 
Backpropagation of CNN ConvolutionalMaxPoolingComponent is not supported for quantized weights
Not supported for quantized weights
Backpropagation of CNN ConvolutionalMaxPoolingComponent is not supported on CPU
ConvolutionalMaxPoolingComponent::AccumGradients can't be called before ConvolutionalMaxPoolingComponent::Backpropagate
Performing vectorization of convolutional maxpooling component
(nlinparams + Bias().Dim()) == NumParams()
veccorrs->size() == filters_grad_.size() && veccorrs->size() == bias_grad_.size()
(filters_grad_[ic]->NumRows() * filters_grad_[ic]->NumCols() + bias_grad_[ic]->Dim()) == NumParams()
Done  vectorization of convolutional maxpooling component
<NumBands>
 (NumBands)
NumBands should be > 0
Invalid NumBands value
 CnnRearrange 
<PrePadding>
<PostPadding>
<Postamble>
<PadValue>
Invalid pre and post padding sizes
Invalid postamble size
 PaddingComponent 
<PadTop>
<PadBottom>
<PadLeft>
<PadRight>
h > 0 && w > 0
num_to_trim_h < h
num_to_trim_w < w
input_dim_ % (h * w) == 0
output_dim_ % (out_h * out_w) == 0
c == out_c
<SourceStateDimension>
<MaxAttentions>
 (SourceStateDimension|MaxAttentions)
Unrecognized token 
this is a non-recurrent version, cannot have a recurrent internal component
no recursive inclusion
component is not initialized, max attention is 
, source state dimension is 
component has input dim 
, attentions 
, source state dimension 
, however, the internal training component has input dim 
the output dim of attention component is 
 , however, the internal training component has output dim 
<SourceDotTransform>
this is not an updatable component, you used 
<TargetDotTransform>
<SourceAddTransform>
<TargetAddTransform>
Reading attention model
read source dot transform failed
read target dot transform failed
read source add transform failed
## Source Dot Transform: input-dim 
## Target Dot Transform: input-dim 
## Source Add Transform: input-dim 
## Target Add Transform: input-dim 
source state dimension is 
 , but the source dot transform has input dim 
 , but the source add transform has input dim 
the component has input dim 
 , but the target dot transform has input dim 
 , but the target add transform has input dim 
the source and target dot transform has different output dim 
the source and target add transform has different output dim 
the source/target add transform has output dim 
 , but the component has output dim 
it doesn't make sense to use a non-reccurent network here
cannot initialize source dot transform from 
cannot initialize target dot transform from 
it doesn't make sense to use a non-recurrent network here
## Internal recurrent network info 
not implemented yet
the internal recurrent network has output dim 
the internal network takes input dimension 
 , that is not equal the sum of 
source vector dimension 
target input network dim 
the internal network has output dim 
(BiasMean|BiasRange|ParamStddev|LearnRateCoef|MaxNorm|MaxGrad|InitTransformType
|GradientNormType|RandomSeed)
 Gate recurrent weights:
 Activation recurrent weights:
  Gate recurrent weights gradient: 
  Activation recurrent weights gradient: 
  Candidate activations: 
  Activations: 
  Candidate activation diff: 
  Activation diff: 
; output dim = 
Gate recurrent weights #rows = 
Gate recurrent weights #columns = 
Activation recurrent weights #rows = 
Activation recurrent weights #columns = 
Saving last activation batch 
<Epsilon>
<Gamma>
<Beta>
Reading LayerNorm component
 (ParamStddev|LearnRateCoef|InitTransformType|RandomSeed|GradientNormType|MaxGrad)
Linearity().NumRows() == mat.NumRows() && Linearity().NumCols() == mat.NumCols()
Unexpected mismatch in indexes: 
Performing  vectorization of linear component
veccorrs->size() == linearity_corr_.size()
LinearityCorr(ic).NumRows() * LinearityCorr(ic).NumCols() == NumParams()
Done  vectorization of linear component
Non-finite loss (
) in cross-entropy calculation
Non-finite entropy (
Posterior pdf-id out of NN-output dimension, please check number of pdfs by 'hmm-info'.
 nn-outputs : 
, posterior pdf-id : 
ProgressLoss[
h]: 
 (Xent)
Can't collect performance from non Xent object
AvgLoss: 
 (Xent), 
[AvgXent: 
, AvgTargetEnt: 
progress: [
FRAME_ACCURACY >> 
% <<
Loss
Entropy
Correct
Frames
) in MSE calculation
 (Mse)
Can't collect performance from non Mse object
 (Mse), 
[RMS 
). Numeric problems with model?
Not Implemented
deep copy constructor not implemented in the case of vectorized_weights.
<NumCells>
<ForgetGateBiasMean>
<ForgetGateBiasRange>
<ProjectionLearnRateCoef>
<MaxCell>
<NoPeep>
<OutputCellValues>
Invalid token 
. Allowed tokens: 
(NumCells|BiasMean|BiasRange|ForgetGateBiasMean|ForgetGateBiasRange|ParamStddev|LearnRateCoef|ProjectionLearnRateCoef|MaxNorm|
MaxGrad|MaxCell|NoPeep|InitTransformType|GradientNormType|RandomSeed)
bias_ thought to be initialized here
# LSTM cells (
) should not be less than output dim (
input_weights_ thougth to be un-initialized here
recurrent_weights_ thougth to be un-initialized here
peephole_weights_ thougth to be un-initialized here
bias_ thougth to be un-initialized here
projection_weights_ thougth to be un-initialized here
 Input weights:
 Recurrent weights:
 Bias:
 Forget gate bias:
 Peephole weights:
 Projection weights:
  Gradients are uninitialized
 For batch 
  Number of cells : 
  Input weights gradient: 
  Recurrent weights gradient: 
  Bias gradient: 
  Peephole weights gradient: 
  Projection weights gradient: 
  Gates values: 
  Cell values: 
  Cell outputs: 
  Cell outputs gated: 
  Output values: 
  Gates diff: 
  Cell diff: 
  Cell out gated diff: 
  Output diff: 
Running forward propagation for batch size = 
, which contains 
 frames each from 
 utterances.
Running backward propagation for batch size = 
Accumulating gradients for batch id = 
Reset previous states for utts 
input_weights_
recurrent_weights_
peephole_weights_
projection_weights_
input_weights_gradient_.size() > ib
input_weights_gradient_[ib]
recurrent_weights_gradient_.size() > ib
recurrent_weights_gradient_[ib]
bias_gradient_.size() > ib
bias_gradient_[ib]
has_peepholes_
peephole_weights_gradient_.size() > ib
peephole_weights_gradient_[ib]
has_projection_layer_
projection_weights_gradient_.size() > ib
projection_weights_gradient_[ib]
input_weights_ thought to be un-initialized here
recurrent_weights_ thought to be un-initialized here
bias_ thought to be un-initialized here
peephole_weights_ thought to be un-initialized here
projection_weights_ thought to be un-initialized here
Allocated memory for the parameters: 
Allocating forward buffers for batch 
; batch size = 
Allocating backward buffers for batch 
input_weights_gradient_.size() == 0
recurrent_weights_gradient_.size() == 0
bias_gradient_.size() == 0
peephole_weights_gradient_.size() == 0
projection_weights_gradient_.size() == 0
Allocated memory for the gradients: 
Saving last output and cell state for batch 
Input weights #rows = 
; expecting 
; #cells = 
Input weights #columns = 
 (same as input dim)
Recurrent weights #rows = 
Recurrent weights #columns = 
 (same as output dim)
Peephole weights #rows = 
Peephole weights #columns = 
 (same as #cells)
Bias dim = 
Projection weights #rows = 
Projection weights #columns = 
learn_rate_coeff_ must not be negative; found: 
projection_learn_rate_coeff_ must not be negative; found: 
max_norm_ must not be negative; found: 
max_grad_ must not be negative; found: 
max_cell_values_ must not be negative; found: 
Unimplemented except for BaseFloat weights
the multi batch gradient quantization does not work yet
Weights are already vectorized
Performing  vectorization of lstm component
gradients_valid_ is thought to be false here
input_weights_gradient_[ic]->NumRows() == InputWeights().NumRows() && input_weights_gradient_[ic]->NumCols() == InputWeights().NumCols()
recurrent_weights_gradient_[ic]->NumRows() == RecurrentWeights().NumRows() && recurrent_weights_gradient_[ic]->NumCols() == RecurrentWeights().NumCols()
bias_gradient_[ic]->Dim() == Bias().Dim()
peephole_weights_gradient_[ic]->NumRows() == PeepholeWeights().NumRows() && peephole_weights_gradient_[ic]->NumCols() == PeepholeWeights().NumCols()
projection_weights_gradient_[ic]->NumRows() == ProjectionWeights().NumRows() && projection_weights_gradient_[ic]->NumCols() == ProjectionWeights().NumCols()
Done vectorization of lstm component
Insufficient storage area: 
 needed: 
<LeftContext>
<RightContext>
<SourceReversed>
<NoTargetConcat>
<ReattachTarget>
<DotProductRelation>
 (SourceStateDimension|MaxAttentions|LeftContext|RightContext)
component is not initialized, left and right context is 
The target input is concatenated. component has input dim 
The target input is not concatenated. component has input dim 
 , and output dim 
, and you requested to reattch the target, however, 
the internal component has output dim 
component has output dim 
 does not match the internal component's output dim 
the maximum attention is 
 , that does not match the left_context + 1 + right_context, you defined left/right context as 
the source state must have the same dimension as the input dimension of the component if want to take the dot product between them
if not taking the dot production relation from the source and target, you must at least concatenate or reattach the target
.mlmodelc
 from 
 to 
true
false
the network has history size 
 , but the input history data has dimension 
freezing component 
 (1-based) in this Update
Components to propagate (startCompIdx=
, num_comps=
) must not be greater than 
#components in the network (
Components to propagate to (
Freezing specified components (1-based):
<NnetProto>
Missing </NnetProto> at the end.
</NnetProto>
The network '
' is empty.
Dimensionality mismatch!
 Previous layer output:
 Current layer input:
Could not read any components
Nnet already mapped from a file
The mapped network '
<Nnet>
</Nnet>
num-components 
input-dim 
output-dim 
number-of-parameters 
 millions
component 
, input-dim 
, output-dim 
### No gradient info
### Gradient stats :
Component 
### Forward propagation buffers not initialized
### Forward propagation buffer content, note in the parallel GPU training, this only includes the first subbatch content :
[0] output of <Input> 
] output of 
### Backward propagation buffers not initialized
### Backward propagation buffer content, Note in multi subbatch case, only the first subbatch is reported :
[0] diff of <Input> 
] diff-output of 
Dimension mismatch between output/input of components 
 and 
 <--> 
The word vec component can only be the first component
The word multivec component can only be the first component
The compressed word vec component can only be the first component
Inconsistent return type: RecurrentBaseComponent::GetTrainOptions() can not be cast to RecurrentNnetTrainOptions
a recurrent trainer option. 
a regular trainer option. 
workspace_size_bytes >= 0
Set workspace of 
 bytes for 
 sub-batches
Two different learning rates: 
xent
Invalid set to freeze ( non-unique components ): --freeze-components 
Using workspace of size: 
 KBs
Unknown objective function code : 
At iteration 
 of 
Non-matching output dims, component:
 data:
Backpropagate() attempted while disabled
Non-matching dims! 
 input-dim : 
 data : 
linearity_
bias_
Function is not implemented for this class
linearity_corr_.size() > batch_idx
linearity_corr_[batch_idx]
bias_corr_.size() > batch_idx
bias_corr_[batch_idx]
'inf' in component parameters (weight explosion, try lower learning rate?)
'nan' in component parameters (try lower learning rate?)
, and Recurrent style components have additional configurations 
bptt_steps 
num_sequences 
NnetTrainOptions : 
learn_rate 
momentum 
l2_penalty 
l1_penalty 
qtype_compact_grad 
step_compact_grad 
num_subbatches 
average_gradients 
vectorize_weights 
The GPU ID for the matrix randomizer is 
Function not implemented for this class
 ( min 
, max 
, mean 
, variance 
, skewness 
, kurtosis 
Removing softmax from the nnet 
last_component_idx_ >= 0
Memory allocation failed when initializing CuVector 
with dimension 
 object size in bytes: 
Memory mapping failed. Not a valid Kaldi binary file: 
Memory mapping failed. mapped_file_ is NULL
memory mapped file 
we should have allocated enough space, instead we get in 
this expensive copy/resize on GPU. buffer size 
 , current end 
 , incoming data size 
Computing pdf-priors from : 
 classes have counts
 lower than 
--class-frame-counts is empty: Cannot initialize priors 
without the counts.
Dimensionality mismatch,
 class_frame_counts 
 pdf_output_llk 
Invalid pdf (
): log-prior dimension = 
SequentialTableReader<Holder>::Open(), could not close previously open object.
Invalid rspecifier 
Trying to use empty SequentialTableReader (perhaps you 
passed the empty string as an argument to a program?)
TableReader::Open, error closing previous input (only warning, since permissive mode).
TableReader::Open, error closing previous input.
TableReader: failed to open stream 
TableReader: error beginning to read table (wrong filename?): 
Done() called on TableReader object at the wrong time.
IsOpen() called on invalid object.
Key() called on TableReader object at the wrong time.
Value() called on TableReader object at the wrong time.
KaldiObjectHolder::Value() called wrongly.
TableReader: FreeCurernt called at the wrong time.
TableReader: Next() called wrongly.
Error reading archive 
Invalid archive file format: expected space after key 
, got character 
, reading 
Object read failed, reading archive 
Reading Table object, failed reading binary header
Exception caught reading Table object 
ERROR 
Close() called on TableReader twice or otherwise wrongly.
Error detected closing TableReader for archive 
 but ignoring 
it as permissive mode specified.
TableReader: reading archive failed: 
TableReader::Open, error closing previous input 
Failed to open script file 
TableReader: failed to load object from 
 (to suppress this error, add the permissive 
(p, ) option to the rspecifier.
TableReader: you called Value() after FreeCurrent().
TableReader: Value() called at the wrong time.
TableReader: LoadCurrent() called at the wrong time.
TableReader: failed to open file 
TableReader: FreeCurrent called at the wrong time.
SequentialTableReader, reading script file: Next called wrongly.
Close() called on input that was not open.
Close() called on scp file with read error, ignoring the error because permissive mode specified.
TableReader: reading script file failed: from scp 
Found 
<NumGroups>
<NumTables>
<VocabSizes>
<MaxItems>
<EmbedDimensions>
<AssignedTable>
<InitializeToConcat>
<UseTransform>
, a typo in config? 
(NumGroups|VocabSizes|MaxDimensions|EmbedDimensions|LearnRateCoef|ParamStddev|RandomSeed|InitTransformType|GradientNormType|MaxGrad)
<FeatureTransform>
require an updatable component, you used 
dimension mismatch, cannot initialize to concatenation, expected dim is 
 actual dim is 
cannot initialize to concatenation for this transform
initialized the transform for concatenation
it doesn't make sense to initialize the embedding table as an identify matrix
, a typo in config? (NumGroups|VocabSizes|MaxDimensions|EmbedDimensions|LearnRateCoef)
failed to read feature transform
## Embedding Table: 
## Feature Transform: input-dim 
No intermediate gradients for embedding tables, here is the gradient info for the transforms: 
RMSPROP is not implemented in word multi embedding yet
must have at least one group, you used 
must have at least one embedding table, you used 
there are only 
 groups, but you set 
 embedding tables
there are 
 groups, but the number vocab list size is 
 groups, but the max item list size is 
 groups, but the embedding dim list size is 
 groups, but 
 groups have assigned tables
the actual number of embedding tables is 
 and different than 
 groups, but the number of feature transforms is 
the 
-th group has assigned table index 
 , the number of tables is 
-th group has invalid vocab size 
-th group has invalid max item value 
-th group has invalid embedding dimension value 
-th group has mismatched embedding table and vocab size 
-th group has mismatched embedding table and embedding dim 
-th group has mismatched embedding table and feature transform 
-th group has feature transform output dim 
 does not match component output dim 
input dim of the component is 
 , while the input dim defined in max items is 
Total embedding size of 
 doesn't match the component output size of 
 when transforms are not used
Not implemented yet when transforms are used
Not implemented
WordMultiVecComponent doesn't support multi-batches yet
Using transform with gradient compression is not supported yet
Performing vectorization of WordMultiVecComponent
veccorrs->size() == 1
Done  vectorization of WordMultiVecComponent
input1
output1
Could not load 
could not make features: 
CoreML prediction failed, falling back to CPU inference
could not predict: 
No output from CoreML: 
Could not make multiarray from matrix 
Unexpected output shape from CoreML: 
Unexpected output from CoreML: 
Could not make multiarray from vector 
Non-vector shape output from CoreML: 
Did not get correct batch [
) for frame 
Request for expired frame (
): current frame offset is 
Request for invalid frame (
): you need to check
 IsLastFrame, or, for frame zero, check that the input is valid.
Could not calculate silence posterior for frame=
, current frame offset is=
Silence posterior cache incorrectly calculated rows=
, cols=
Requested posteriors for realignment do no longer exist.
Realignment model posterior cache is empty, make sure that acoustic model for realignment is configured correctly
Request for invalid frame (you need to check IsLastFrame,
 or, for frame zero, check that the input is valid.
LogLikelihood() must be called before this method as silence posteriors are pre-computed there
Invalid parameters supplied to OnlineLdaInput
Invalid parameters supplied to OnlineTransformInput
NaN in features
inf in features
Must use penultimate-compatible AM with silence nnet
Frames consumed by model (
) does not match frames added by batchwise splicing (
). Hint: Are batch-left-context and batch-right-context correct for this model?
NaN in NNet output
inf in NNet output
(!has_sil_post_ && next_sil_post.NumRows() == 0) || (has_sil_post_ && next_features.NumRows() == next_sil_post.NumRows())
Unexpected point reached in code: 
possibly you are skipping frames?
Attempting to get a discarded frame.
Attempt get frame without check its validity.
Not tested yet
Can't deal with this yet
CoreML feature provider creation failed: 
CoreML evaluation failed: 
Output was not a multiarray: 
Asked for float32 of a non-float32 buffer
CoreMLTensorData copy failed: 
Copy failed: 
Asked for int32 of a non-int32 buffer
CoreMLTensorData create failed: 
unsupport matrix data configuration
Could not make MLMultiArray: 
not supported MLMultiArray data type: 
<Topology>
</Topology>
<TopologyEntry>
Reading HmmTopology object, expected </Topology> or <TopologyEntry>, got 
<ForPhones>
Reading HmmTopology object, unexpected end of file while expecting phones.
</ForPhones>
Reading HmmTopology object, expected integer, got instead 
</TopologyEntry>
<State>
Expected </TopologyEntry> or <State>, got instead 
States are expected to be in order from zero, expected 
<PdfClass>
<Transition>
<Final>
You are trying to read old-format topology with new Kaldi.
</State>
Reading HmmTopology,  unexpected token 
Phone with index 
 appears in multiple topology entries.
HmmTopology::Check(), empty object.
HmmTopology::Check(), phone has no valid index.
HmmTopoloy::Check(), entry with no corresponding phones.
HmmTopology::Check(), cannot only have one state (i.e., must have at least one emitting state).
HmmTopology::Check(), last state must have no transitions.
HmmTopology::Check(), last state must not be emitting.
HmmTopology::Check(), negative or zero transition prob.
We do not allow any state to be nonemitting and have a transition to the final-state (this would stop the SplitToPhones function from identifying the last state of a phone.
HmmTopology::Check(), invalid dest state 
HmmTopology::Check(), duplicate transition found.
Total probability for state 
 in topology entry is 
HmmTopology::Check, state 
 has no input transitions.
HmmTopology::Check(), pdf_classes are expected to be contiguous and start from zero.
TopologyForPhone(), phone 
 not covered.
Context size mismatch, ilabel-info [from context FST is 
, context-dependency object expects 
phone == 0.  Possibly you are trying to get a reversed FST with a non-central "central position" P (i.e. asymmetric context), but forgot to initialize the ContextFst object with P as N-1-P (or it could be a simpler problem)
phone == 0.  Some mismatch happened, or there is a code error.
GetHmmAsFst: context-dependency object could not produce 
an answer: pdf-class = 
 ctx-window = 
.  This probably points to either a coding error in some graph-building process, a mismatch of topology with context-dependency object, the wrong FST being passed on a command-line, or something of  that general nature.
tree did not succeed in converting phone window 
ConvertAlignment: could not map phone 
ConvertAlignment: error converting alingment, possibly different topologies?
AddTransitionProbs: invalid symbol 
 on graph input side.
 on lattice input side.
AddSelfLoops: graph already has self-loops.
Label 
 neither 0, nor a disambiguation symbol 
(#transition id = 
TransitionModel::TripleToTransitionState, triple not found.
 (incompatible tree and model?)
ComputeDerivedOfProbs(): non-self-loop prob is 
<TransitionModel>
<Triples>
</Triples>
<LogProbs>
</LogProbs>
</TransitionModel>
 out of 
 frames.
Error reading phone map from 
 (bad line 
Read empty phone map from 
CORRECT
SEARCH_ERROR
HOMOPHONE
LM_OVER
GRAPH_OVER
AM_OVER
REF_TOO_SHORT
HYPO_TOO_SHORT
Invalid Category given 
TRANS_ID
PHONE
WORD
Invalid level given 
GENERAL
SCHEMA
CONTEXT
MIN_DURATION
PATTERN
AC-MATCH
AC-MISMATCH
WORD-CONFUSION
Invalid info given 
HYPO
AMONLY
Invalid source given 
CONFIDENCE
LENGTH
FRAME_LENGTH
Blaming 
Cannot blame given reference and hypothesis, one of them is empty.
Schematics have to be registered first before usage, call RegisterSchematics first
Size of registered schematics is 
 does not match with supplied schematics for utterance, which are 
Unexpected number of confidenceScores
Unexpected number of confidenceScores got 
 words in lattice and got 
 confidence scores
Supplied utterance id is out of bounds
RefDurations
HypoDurations
Reference
Hypothesis
RefTotalScore
HypoTotalScore
RefAmScore
HypoAmScore
Reference is not in hypo lattice
Reference is in hypo lattice (Rank: 
) and 
cannot be recovered
can be recovered by multiplying the current acoustic-scale with 
Not able to convert given phone_id 
, check if given phone symbol table is the correct one.
Requested word position is out of bounds 
Supplied word position index 
, is out of bounds in ErrorRegion, should be in range [0,
Algorithmic error, do not know what to do with level 
Supplied region_id is out of bound, have only 
 regions, asked for 
--------------------------------------------
From frame 
LM scores:
Hyp 
AM scores: 
Ref: 
Hyp: 
Ref Models:
Hyp Models:
Ref Phones:
Hyp Phones:
Ref Scores:
Hyp Scores:
           
Supplied frame is not part of given transition ids
Invalid partition id 
 has to be in range [0,
split
ContextDependency
ToPdf
EndContextDependency
ToLength
Got unexpected token 
 reading context-dependency object.
EventMap::read, was not expecting character 
ConstantEventMap::Write(), could not write to stream.
Could not map value 
 for key 
Multiple values map to the same point: this code cannot 
handle this case.
TableEventMap::Write(), could not write to stream.
Value 
, for key 
, cannot be mapped.
SplitEventMap::Write(), could not write to stream.
SplitEventMap::Read, NULL pointers.
EventMap::MaxResult(), empty result
Error writing compressed matrix to stream.
Expected token 
Seeking for aligned data failed
Failed to read header
Failed to read data.
Matrix::Read, size mismatch 
Can not map into the wrong matrix data type
Reading aligned matrix as a stream
: Expected token 
, got 
. This could mean that you're trying to memory map an unaligned file.
: Seeking failed
: Reading whole matrix failed
: Reading a matrix row failed
: Seek for padding 
 failed
: Expected "[", got EOF
: Expected "[", got "
Got EOF while reading matrix data
After end of matrix data, read error.
Matrix has inconsistent #cols: 
 vs.
 (processing row
Stream failure/EOF while reading matrix data.
infinity
Reading negative infinite value into matrix.
Reading negative NaN value into matrix.
Expecting numeric matrix data, got 
Reading infinite value into matrix.
Reading NaN value into matrix.
Failed to read matrix from stream.  
 File position at start is 
, currently 
New stride (
) must not be smaller than
 the current stride (
) must be a multiple of 
current stride (
Wrong sized arguments
Wrong size of arguments.
index item is bigger than the voc size 
index 
 is too big for matrix that has rows = 
Failed to write matrix to stream: stream not good
Failed to write matrix to stream
 [ ]
Attempt to write into immutable matrix
Too many rows*cols for 8-bit Matrix
Quantized matrix improperly serialized
Vector<Real>::Read, adding but dimensions mismatch 
Error reading vector data (binary mode); truncated stream? (size = 
EOF while trying to read vector.
Expected "[" but got 
Failed to read number.
Expected whitespace after number.
Reading negative infinite value into vector.
Reading negative NaN value into vector.
Expecting numeric vector data, got 
After end of vector data, read error.
EOF while reading vector data.
Newline found while reading vector (maybe it's a matrix?)
Reading infinite value into vector.
Reading NaN value into vector.
Failed to read vector from stream.  
SoftMax produced NaN on vector
Empty vector
Failed to write vector to stream: stream not good
Failed to write vector to stream
SplitRadixComplexFft called with invalid number of points 
Error: logn is out of bounds in SRFFT
use coverage penalty 
Cannot have leading or trailing space in filename "
Found ~ at the beginning of filename "
". Shell like path expansions not supported.
Found what looks like an rspecifier instead of a filename "
Trying to classify rxfilename with pipe symbol in the wrong place (pipe without | at the end?): 
Error opening input stream 
Invalid input filename format 
Input::Stream(), not open.
Was looking for B, but got 
open called on already open file.
, errno is 
Pipe 
 had nonzero return status 
FileInputImpl::Open(), 
FileInputImpl::Stream(), file is not open.
FileInputImpl::Close(), file is not open.
StandardInputImpl::Open(), open called on already open file.
StandardInputImpl::Stream(), object not initialized.
StandardInputImpl::Close(), file is not open.
Failed opening pipe for reading, command is: 
Pipe opened with command 
 is empty.
PipeInputImpl::Stream(), object not initialized.
PipeInputImpl::Close(), file is not open.
Cannot get offset from filename 
 (possibly you compiled in 32-bit and have a >32-bit
 byte offset into a file; you'll have to compile 64-bit.
"). 
Trailing whitespace not allowd in rspecifier (found "
Will treat this as kNoRspecifier.
[]~#^_-+=:.,/
'\''
"`$\
Invalid silence-phones string 
No silence phones given!
Empty silence phones
<InputData>
<InputDataDim>
<InputDataShape>
<OutputData>
<OutputDataDim>
<InputExtraList>
<OutputExtraList>
<InputPenultimate>
<OutputPenultimate>
<OutputPenultimateDim>
<InputRequestedUnit>
<GraphReset>
<IsRNN>
<IsFOFE>
<Engine>
, a typo in config file?
row_index >= 0 && col_index >= 0
!shape.empty()
.config
!out_node.empty()
out_vec.Dim() % in.NumRows() == 0
Unimplemented TODO
the number of input tensors 
 != 
 , the list of input tensor names
you requested additional outputs, but haven't defined any tensors for that
No ComputeEngineConfigItf for model file: 
the input grammar data is empty
the input symbol table is empty
LME: no user data available for creating a grammar FST
word <
> not in the input symbol table
silence phone probability must be [0,1) 
invalid silence phone value <
the input lexicon is empty
Cannot dereference iterator that is already at the end
Cannot increment iterator that is already at the end
/WORD-DIS-
Illegal word: 
Invalid phone in pron for word: 
Word 
Word does not exist in lexicon: 
Phone 
) does not exist in the lexicon
Illegal phone: 
For a lexicon using pos-dep phones, cannot view disambig IDs with pos-indep phones
For a lexicon using pos-indep phones, cannot view disambig IDs with pos-dep phones
Invalid phone 
 not found in lexicon.
Removing a pron for word: 
the base lexicon is not at base phone set mode
the preferred lexicon is not at base phone set mode
the base lexicon and preferred lexicon have different phone set
the guessed lexicon is not at base phone set mode
the base lexicon and guessed lexicon have different phone set
the preferred lexicon and guessed lexicon has different phone set
all input lexicons (base, preferred, guessed) are empty
input user data is empty
there are different number of items in each vector
linear weights converged after 
 iterations
Last state of linear clat is not a final state (perhaps text contains \CS-xx-start without \CS-xx-end?) LM score will not be accurate.
fail to top-sort the rescored lattice
no old LM defined
total number of old LMs is 
 , but the number of interpolation weights is 
no new LM defined
failed to estimate the interpolation weights
total number of new LMs is 
can not perform LM rescoring on the lattice
Failed to get a best path in the lattice
Failed to get new total LM score
invalid deterministic on-demand FST
can not find label 
 from state 
 . Wrong LM intput?
only linear weight estimation has been implemented now
Caught exception doing lattice determinization
Memory allocation error doing lattice determinization; using 
 bytes (max = 
 (repo,arcs,elems) = (
[empty subset]
Failure in determinize-lattice: size exceeds maximum 
the base lexicon is empty
the base symbol table is empty
the number of templates in the user data is zero
insufficient number of word disambiguation symbols in the graph, 
 . deleting offending pronunciations.
number of word symbols before LME: 
number of word symbols after LME: 
LME: number of disambiguation symbols is 
the optional silence 
 is not defined in the symbol table
the word boundary string can only have non-space characters, you set it (
number of prons, pre/post-compound:
 #comp_words:
can not find symbol 
 in the input symbol table
LME: no available user data for 
-th template
LME: detected a zero frequency - ignoring this word
not in the compound mode, and the number of words in this entry is more than 1, use CreateFst() instead
remove excessive homophone prons without removing words, rebuild the FST now
has to remove 
 words, rebuild the FST now
LME: spent 
 seconds on creating the compound lexicon for 
 items
the output symtable is not empty
Determinization aborted since passed 
 states.
max-states reached in determinization
Determinization terminated since passed 
 states, partial results will be generated.
Determinization aborted since looped more than 
 times during epsilon closure.
looped more than max-states times in determinization
DeterminizerStar: FST was not functional -> not determinizable
First string: 
Second string: 
Non-functional FST: cannot determinize.
Debug function called (probably SIGUSR1 caught).
Nothing to trace back
Traceback did not reach start state (possibly debug-code error)
Traceback below (or on standard error) in format ilabel (olabel olabel) ilabel (olabel) ...
NaturalLess: Weight type is not idempotent: 
ShortestDistance: Weight needs to be right distributive: 
ShortestDistance: first_path option disallowed when 
Weight does not have the path property: 
Prune: Weight needs to have the path property and
 be commutative: 
DeterminizeFst: Weight needs to have the 
path property to disambiguate output: 
TableMatcher: bad match type
gallic_
left_gallic
right_gallic
Reweight: Reweighting to the final states requires 
Weight to be right distributive: 
StringWeight::Divide: only left division is defined 
for the left string semiring
_from_gallic
GallicToNewSymbolMapper: unrepresentable weight: 
Input symbol id 
 symbol '
' missing from target symbol table.
Target symbol table missing: 
 input symbols.
Output symbol id 
 output symbols.
 missing from target vocabulary
Backed by either TensorFlow or Espresso.
the NCE normalization factor is 
This is a FOFE model
using RNN style LM in the decoder
<UnknownWord>
<BeginOfSentenceWord>
<EndOfSentenceWord>
<NullWord>
<ContextSize>
<SymbolToWord>
<WordToSymbol>
<PhoneWordSymbol>
boost::filesystem::current_path
boost::filesystem::status
expanded
mutable
acceptor
not acceptor
input deterministic
non input deterministic
output deterministic
non output deterministic
input/output epsilons
no input/output epsilons
input epsilons
no input epsilons
output epsilons
no output epsilons
input label sorted
not input label sorted
output label sorted
not output label sorted
weighted
unweighted
cyclic
acyclic
cyclic at initial state
acyclic at initial state
top sorted
not top sorted
accessible
not accessible
coaccessible
not coaccessible
string
not string
SymbolTable::ReadText: Bad number of columns (
file = 
SymbolTable::ReadText: Bad non-negative integer "
SymbolTable::AddSymbol: symbol = 
 already in symbol_map_ with key = 
 but supplied new key = 
 (ignoring new key)
SymbolTable::Read: read failed
SymbolTable::Write: write failed
Missing required field separator
Negative symbol table entry when not allowed
read
, line = 
AlignInput: can't determine stream position
AlignOutput: can't determine stream position
FstHeader::Read: Bad FST header: 
FstHeader::Read: read failed: 
Unknown file read mode 
failed to unmap region: 
mmap'ed region of 
 at offset 
 to addr 
Mapping of file failed: 
File mapping at offset 
 of size 
 of file 
 could not be honored, reading instead.
Failed to read 
 bytes at offset 
from "
Read 
 bytes. 
 remaining.
VectorFst::Read: read failed: 
VectorFst::Read: unexpected end of file: 
ExpandedFst::Read: Can't open file: 
standard input
(end) <= (Bits())
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/EmbeddedAcousticRecognition_Sim/EmbeddedAcousticRecognition-216.6/libquasar/libkaldi/tools/openfst/src/extensions/ngram/bitmap-index.cc
DecodableMatrixScaledMapped: mismatch, matrix has 
You cannot call FinalizeDecoding() and then call 
GetRawLattice() with use_final_probs == false
GetRawLattice: no tokens active on frame 
: not producing lattice.
init:
 buckets:
 load:
 max:
No tokens alive [doing pruning].. warning first time only for each utterance
Negative extra_cost: 
No tokens alive at end of file
No tokens alive [doing pruning]
PruneActiveTokens: pruned tokens from 
pruned tokens from 
Error, no surviving tokens: frame is 
Possible memory leak: 
: you might have forgotten to call Delete on 
some Elems
No tokens alive at end of file
No tokens alive [doing pruning]
 tokens active.
Disambiguation symbol 
 is also a phone.
Context FST created but there are no phone symbols: probably input FST was empty.
ContextFst: CreateArc, invalid olabel supplied [confusion about phone list or disambig symbols?]: 
ContextFst copying not yet supported [not hard, but would have to test.]
ContextMatcher: bad match type
system
generic
Unknown error
<ShortlistTable>
<ShortlistLangPairs>
Has shortlist, but dissabled due to shortlist-lang-pair = 
, lp = 
, shortlist-cond-n = 
, shortlist-freq-n = 
Using shortlist, reducing Voc size to 
ConstrainSoftmax
Begin
Both
both
None
none
Unknown AddTag format
bothAsOne
bothasone
bothSeparate
bothseparate
Unknown tag format 
Reading Whe_
Whe_.Dims() 
Reading Whd_
Whd_.Dims() 
Reading Whc_
Whc_.Dims() 
Handover is not supported for stream input.
Model type requires full handover.
BidirectionalEncoder is not supported for stream input.
Un-supported model type : 
Unknown label not described in the model
Left symbol sequence : 
 (# 
Right symbol sequence : 
Empty source/target sentence. Skipping alignment.
 including </s>) 
Constrained Softmax with force alignment decoding is not Supported!
no symbol 
Decoder hit max sentence length : 
osyms
<SymbolTable>
</SymbolTable>
<ModelType>
Full ModelType 
Undefined Torch model type
ModelType 
TorchN
TorchM
TorchT
TorchF
Unsupported Torch model type : 
Processing token 
Found BPE token
SHORTLIST
Found SHORTLIST token
TMPATT
Found TMPATT token
CHILD
PyTorch
Found PyTorch token
DotT
Found DotT token
AddTag:
Extracted add tag : 
AddTag value 
TagFormat:
Extracted tag format : 
TagFormat value 
ShareEmbed
Found shared embeddings token
EncPos
Found encoder position embedding token
DecPos
Found decoder position embedding token
AddSrcBos
Found add beginning of sentence tag
AddSrcEos
Found add end of sentence tag
AlignModel
Unknown model sub tag 
dot attention 
<HandoverCellStateOnly>
<HasHandoverLayer>
Handover layer not supported with PyTorch models 
 Cell handover 
 Has handover layer 
<HasInputSymbolTable>
Has input symbol table 
isyms
Embedded input symbols could not read
PyTorch require symbol table
<unk>
Special input symbol(s) not defined <s> </s> <unk> 
Overridding default input symbols <<unk> = 
, </s> =  
<HasOutputSymbolTable>
Has output symbol table 
Embedded output symbols could not read
PyTorch requires symbol table
Special output symbol(s) not defined <s> </s> <unk> 
Overridding default output symbols <<unk> = 
Trying to read embedded BPE model 
Number of BPE entries : 
Trying to read Shortlist
Searching for SupervisedMultiHeadAttention component
Done reading model 
<UnkMode>
<UnkToken>
<Version>
<NumBpe>
Expected to read number of BPE units now, but got 
BPE model version: 
# of BPE model entries : 
 # of chars 
BPE model unk mode = 
, unk token = 
Wrong number of fields, ignoring : 
keep
char2unk
word2unk
dropword
dropchar
Unknown BPE unknown mode
Unknown unk mode : 
syms
<sigma>
<rho>
<phi>
lattice-
.fst
wmapper-
rpathcounter-
mapper-cd-
Push: pushing type is set to 0: 
pushing neither labels nor weights.
Reweight: Reweighting to the initial state requires 
Weight to be left distributive: 
right_gallic_
StringWeight::Divide: only right division is defined 
for the right string semiring
SigmaMatcher: bad match type
SigmaMatcher: 0 cannot be used as sigma_label
SigmaMatcher:: bad match type: 
SigmaMatcher::Find: bad label (sigma)
RhoMatcher: bad match type
RhoMatcher: 0 cannot be used as rho_label
RhoMatcher:: bad match type: 
RhoMatcher::Find: bad label (rho)
resize overflow
sparsehash: FATAL ERROR: failed to reallocate %lu elements for ptr %p
insert overflow
Symbol: '
' not found in input symbols table.
 Mapping to null...
Not enough space
Invalid UTF-8
Invalid code point
Audio buffer has been deallocated; not restarting recognition
Result stream wrapper has been deallocated; not restarting recognition
Recognition failure in execution %{public}@
Recognizer has been deallocated; not writing partial results
Recognizer has been deallocated; not writing final choices
Result stream has been deallocated; not writing final choices
Recognizer has been deallocated; not reporting result progress
Result stream has been deallocated; not reporting result progress
Recognizer has been deallocated; not writing end point data
Result stream has been deallocated; not writing end point data
PSR: EARAudioProcessor Config file does not exist at %@
PSR: ERR: AudioProcessorPipeline created with incorrect version
endAudio
resetForNewRequest
ComputeTask done
dealloc
Error loading context-aware model: %@
%s, error %@
No supported languages found in acousticPosteriors
context.currentDictationLanguage is empty, setting currentDictationLocale to zeroes.
context.wasLanguageToggled not set, defaulting to false.
context.multilingualKeyboardLanguages not set, setting multilingualKeyboardLocales to zeroes.
context.keyboardConvoLanguagePriors not set, setting keyboardConvoLocalePriors to uniform probability.
context.keyboardGlobalLanguagePriors not set, setting keyboardGlobalLocalePriors to uniform probability.
context.previousMessageLanguage not set, setting previousMessageLocale to zeroes.
context.globalLastKeyboardUsed not set, setting globalLastKeyboardUsed to zeroes.
context.dictationLanguagePriors not set, setting dictationLocalePriors to uniform probability.
Exception in EARContextAwareLDModelFactory::createModel: %s
Unsupported model file format "%s"
Identified languages of messages = %@
%@ maps to %@
There is no keyboard language for %@
Starting new request
previousMessageLanguage and keyboardConvoLanguagePriors are both set, so recentMessages will be ignored.
Unsupported locales (%s) found in context, will be ignored
Error initializing model.
Attempting to load model file: %@
Failed to reload CoreML model with error: %@
Failed to create feature multiarray with error %@
Failed to create feature provider with error %@
Error during prediction: %@
LanguageDetector: EARLanguageDetector model file does not exist at %@
Received didFinishProcessingFrames
Got an error when trying to print logging info
Logging Data: %@
Sending logging info to delegate
Received didComputeResult
Sending language detector result to delegate
Sending language detector confidences to delegate
%{public}s
_EARWordPart
_EARUserProfileBuilder
_EARUserProfile
_EAREndpointFeatures
_EARDefaultServerEndpointFeatures
_EAREndpointer
_EARSpeechRecognitionToken
NSCopying
_EARAcousticFeature
_EARAudioAnalytics
_EARSpeechRecognition
_EARSpeechRecognitionResultPackage
_EARSpeechRecognitionResult
_EARSpeechRecognizer
_EARSpeechModelInfo
_EARSyncResultStreamHelper
_EARSpeechRecognitionResultStream
NSObject
EARSdapiHelper
_EARTransformUtil
_EARSpeechRecognitionAudioBuffer
_EARSyncSpeechRecognizer
_EARSystemResult
_EARCombinedResult
_EARResultCombiner
_EARLanguageDetectorRequestContext
_EARNnetUtil
EARTokenPronounciations
EARKeywordFinderResult
EARKeywordFinder
EARStringView
EMTTokenizer
_EARCustomLMBuilder
EARPSRAudioProcessor
EARCSpeechRecognitionResultStreamGlue
_EARLanguageDetectorAudioBuffer
EMTToken
EMTTranslator
_EARLanguageModel
_EARFormatter
EMTResult
EARClientSilenceFeatures
EARCaesuraSilencePosteriorGenerator
_EARLanguageDetectorLoggingInfo
_EARLanguageDetectorResult
_EARLanguageDetector
_EARCommandTagging
_EARCommandTaggingResult
_EARCommandTagger
numberWithDouble:
numberWithInt:
numberWithBool:
stringWithUTF8String:
addObject:
setValue:forKeyPath:
_initWithCommandTaggings:
countByEnumeratingWithState:objects:count:
objectForKey:
UTF8String
array
copy
_initWithQuasarToken:
quasarToken
quasarTokens
quasarPreItnTokens
_initWithQuasarCommandTagging:
init
initWithOrthography:pronunciations:tag:
initWithOrthography:pronunciations:tagName:frequency:
tagName
orthography
frequency
pronunciations
.cxx_destruct
_tagName
_orthography
_tag
_frequency
_pronunciations
EnsureSDAPIInitialized
localeIdentifier
fileSystemRepresentation
initWithConfiguration:language:overrides:sdapiOverrides:generalVoc:emptyVoc:pgVoc:lexiconEnh:tokenEnh:paramsetHolder:
enumerateKeysAndObjectsUsingBlock:
dataWithBytes:length:
bytes
length
initialize
isEasyToRecognizeWord:forLocale:
initWithConfiguration:withLanguage:withSdapiOverrides:withSdapiConfig:
initWithConfiguration:language:sdapiOverrides:generalVoc:emptyVoc:pgVoc:lexiconEnh:tokenEnh:paramsetHolder:
addWordWithParts:templateName:
removeAllWords
dataProfile
readUserProfile:
addPersonalizationData:
addPersonalizationJsonData:
writeOutUserDataToJson:withConfig:
pronunciationsForOrthography:
sanitizedStringWithString:
.cxx_construct
_userData
_dataFactory
_tokenizer
_g2p
_pronCache
_sanitizer
_personalizationRecipe
_quasarLmeData
initWithWordCount:trailingSilenceDuration:endOfSentenceLikelihood:pauseCounts:silencePosterior:clientSilenceFramesCountMs:clientSilenceProbability:silencePosteriorNF:serverFeaturesLatency:eagerResultEndTime:
componentsJoinedByString:
stringWithFormat:
initWithWordCount:trailingSilenceDuration:endOfSentenceLikelihood:pauseCounts:silencePosterior:clientSilenceFramesCountMs:clientSilenceProbability:silencePosteriorNF:serverFeaturesLatency:
description
wordCount
setWordCount:
trailingSilenceDuration
setTrailingSilenceDuration:
endOfSentenceLikelihood
setEndOfSentenceLikelihood:
pauseCounts
setPauseCounts:
silencePosterior
setSilencePosterior:
clientSilenceFramesCountMs
setClientSilenceFramesCountMs:
clientSilenceProbability
setClientSilenceProbability:
silencePosteriorNF
setSilencePosteriorNF:
serverFeaturesLatency
setServerFeaturesLatency:
eagerResultEndTime
setEagerResultEndTime:
_silencePosteriorNF
_serverFeaturesLatency
_wordCount
_trailingSilenceDuration
_endOfSentenceLikelihood
_pauseCounts
_silencePosterior
_clientSilenceFramesCountMs
_clientSilenceProbability
_eagerResultEndTime
initWithWordCount:trailingSilenceDuration:endOfSentenceLikelihood:silencePosterior:
initWithConfiguration:modelVersion:
defaultManager
fileExistsAtPath:
initWithConfiguration:
initWithConfiguration:delaysTrigger:modelVersion:
requestSupportedWithSamplingRate:
updateEndpointerThresholdWithValue:
updateEndpointerDelayedTriggerSwitch:
didEndpointWithFeatures:audioTimestamp:featuresToLog:endpointPosterior:extraDelayMs:
defaultServerEndpointFeatures
acceptEagerResultWithFeatures:featuresToLog:
_endpointer
unsignedIntValue
tokenName
hash
start
silenceStart
confidence
hasSpaceAfter
hasSpaceBefore
phoneSequence
ipaPhoneSequence
stringByAppendingFormat:
copyWithZone:
isEqual:
initWithTokenName:start:end:silenceStart:confidence:hasSpaceAfter:hasSpaceBefore:phoneSequence:ipaPhoneSequence:
_quasarToken
_initWithAcousticFeatureValues:frameDuration:
acousticFeatureValuePerFrame
frameDuration
_acousticFeatureValuePerFrame
_frameDuration
_initWithSpeechRecognitionFeatures:acousticFeatures:
speechRecognitionFeatures
acousticFeatures
_speechRecognitionFeatures
_acousticFeatures
_initWithTokenPhraseChoiceList:
initWithCapacity:
numberWithUnsignedInt:
_initWithTokenSausage:interpretationIndices:
count
objectAtIndex:
intValue
addObjectsFromArray:
firstObject
_tokenPhraseChoiceList
_initWithNBestList:useHatText:
nBest
oneBest
granularizedRecognition
tokenSausage
interpretationIndices
_tokenSausage
_interpretationIndices
_initWithRecognition:preITNRecognition:recognitionIsFormatted:isFinal:audioAnalytics:
_initWithTokens:preITNTokens:
_initWithRecognition:preITNRecognition:recognitionIsFormatted:isFinal:
nBestResults
recognition
preITNRecognition
recognitionIsFormatted
isFinal
audioAnalytics
_recognitionIsFormatted
_isFinal
_recognition
_preITNRecognition
_audioAnalytics
tokens
preITNTokens
_quasarTokens
_quasarPreItnTokens
formatWords:task:
initWithConfiguration:overrides:overrideConfigFiles:
enumerateObjectsUsingBlock:
initWithLanguage:withSdapiConfig:quasarConfig:
initWithConfiguration:overrides:overrideConfigFiles:generalVoc:lexiconEnh:itnEnh:
supportedByQuasarConfig:
initWithQuasarConfig:
initWithGeneralVoc:withLexiconEnh:withItnEnh:
initWithConfig:
stringByDeletingLastPathComponent
stringByAppendingPathComponent:
setLeftContext:
_restartActiveRecognition
runRecognitionWithResultStream:language:task:samplingRate:
enumerateDataSourcesAndWeightsUsingBlock:
runRecognitionWithResultStream:language:task:samplingRate:userProfileData:
_detachFromRecognizer
_audioBufferWithLangauge:task:samplingRate:userProfileData:resultStream:
_initWithAudioBuffer:speechRecognizer:
stringByReplacingOccurrencesOfString:withString:
_setUnderlyingBuffer:
addAudioSampleData:
endAudio
waitForCompletion
results
recognitionResultsWithAudioData:userProfileData:language:task:samplingRate:
setObject:forKeyedSubscript:
minimumSupportedConfigurationVersion
maximumSupportedConfigurationVersion
rawTokenResultsFromRecognitionResults:
initWithConfiguration:overrides:
initWithConfiguration:overrideConfigFiles:
initWithConfiguration:withLanguage:withSdapiConfig:
initWithConfiguration:withGeneralVoc:withLexiconEnh:withItnEnh:
initWithConfiguration:overrides:generalVoc:lexiconEnh:itnEnh:
initWithConfiguration:overrideConfigFiles:generalVoc:lexiconEnh:itnEnh:
initWithConfiguration:useQuasarFormatter:
modelInfo
setHighPriority:
setLeftContextText:
setUserProfileData:
setJitProfileData:
runRecognitionWithResultStream:
updateUserProfileData:
updateJitProfileData:
requestParametersWithUserProfileData:task:samplingRate:resultStream:extraLanguageModel:symbolTableList:
recognitionResultsWithAudioData:userProfileData:language:task:samplingRate:extraLanguageModel:
cancelRecognition
recognitionStatistics
getFormatterWithBlock:
setAlternateRawRecognitionTokenSausage:
userProfileData
jitProfileData
detectUtterances
setDetectUtterances:
concatenateUtterances
setConcatenateUtterances:
endpointStart
setEndpointStart:
recognizeEagerCandidates
setRecognizeEagerCandidates:
farField
setFarField:
highPriority
maximumRecognitionDuration
setMaximumRecognitionDuration:
recognitionReplacements
setRecognitionReplacements:
recognitionConfidenceSubtraction
setRecognitionConfidenceSubtraction:
leftContext
inputOrigin
setInputOrigin:
deviceId
setDeviceId:
refTranscriptForErrorBlaming
setRefTranscriptForErrorBlaming:
bluetoothDeviceId
setBluetoothDeviceId:
userId
setUserId:
sessionId
setSessionId:
_formatterQueue
_formatter
_recognizer
_currentAudioBuffer
_currentResultStreamWrapper
_currentLanguage
_currentTask
_currentSamplingRate
_recognitionQueue
_configPath
_detectUtterances
_concatenateUtterances
_recognizeEagerCandidates
_farField
_highPriority
_userProfileData
_jitProfileData
_endpointStart
_maximumRecognitionDuration
_recognitionReplacements
_recognitionConfidenceSubtraction
_leftContext
_inputOrigin
_deviceId
_refTranscriptForErrorBlaming
_bluetoothDeviceId
_userId
_sessionId
setWithCapacity:
initWithInt:
version
samplingRates
tasks
language
phoneSetVersion
acousticProfileVersion
_speechModelInfo
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
superclass
debugDescription
speechRecognizer:didRecognizePartialResult:
speechRecognizer:didFinishRecognitionWithError:
speechRecognizer:didRecognizeFinalResults:
speechRecognizer:didRecognizeFinalResults:tokenSausage:nBestChoices:
speechRecognizer:didRecognizeFinalResultPackage:
speechRecognizer:didProcessAudioDuration:
speechRecognizer:didRecognizeRawEagerRecognitionCandidate:
speechRecognizer:didProduceEndpointFeaturesWithWordCount:trailingSilenceDuration:eosLikelihood:pauseCounts:silencePosterior:processedAudioDurationInMilliseconds:
speechRecognizer:didRecognizePartialResultNbest:
error
_finishSemaphore
_error
_results
raise:format:
condititionalProbabilityOfWordID:contextWordIDs:count:symbolLookupBlock:
dictionaryWithObjects:forKeys:count:
errorWithDomain:code:userInfo:
lowercaseString
setObject:forKey:
floatValue
currentHandler
handleFailureInMethod:object:file:lineNumber:description:
hatToQsrString:
hatToQsrStrings:
addAudioSamples:count:
triggerServerSideEndPointer
_buffer
_queue
_speechRecognizer
_cancelled
_ended
getSpeechRecognitionResultFromTokens:taskName:
resetWithSamplingRate:language:taskType:userId:sessionId:deviceId:farField:audioSource:maxAudioBufferSizeSeconds:
resultsWithAddedAudio:numberOfSamples:taskName:
resultsWithEndedAudio
_syncRecognizer
sausage
setSausage:
nBestIndexes
setNBestIndexes:
confidences
setConfidences:
_sausage
_nBestIndexes
_confidences
nBestStrings
setNBestStrings:
nBestSourceIndexes
setNBestSourceIndexes:
originalRanks
setOriginalRanks:
_nBestStrings
_nBestSourceIndexes
_originalRanks
combinedResultWithSystemResults:
_combiner
unsignedLongValue
numberWithUnsignedLong:
numberWithFloat:
languagePriors
dictationLanguages
currentDictationLanguage
wasLanguageToggled
boolValue
multilingualKeyboardLanguages
keyboardConvoLanguagePriors
keyboardGlobalLanguagePriors
previousMessageLanguage
globalLastKeyboardUsed
dictationLanguagePriors
setLanguagePriors:
setDictationLanguages:
setCurrentDictationLanguage:
setWasLanguageToggled:
setMultilingualKeyboardLanguages:
setKeyboardConvoLanguagePriors:
setKeyboardGlobalLanguagePriors:
setPreviousMessageLanguage:
setGlobalLastKeyboardUsed:
setDictationLanguagePriors:
alloc
recentMessages
setRecentMessages:
contextFromLDContext:
LDContext
_languagePriors
_dictationLanguages
_currentDictationLanguage
_wasLanguageToggled
_multilingualKeyboardLanguages
_keyboardConvoLanguagePriors
_keyboardGlobalLanguagePriors
_previousMessageLanguage
_globalLastKeyboardUsed
_dictationLanguagePriors
_recentMessages
doubleValue
doBackPropWithNnetModelFile:inputFeatureVector:inputTargetVector:inputLearningRate:inputFreezeComponents:inputNumLocalIterations:inputGradNormFactor:inputGradNormType:inputBatchSize:inputObjectiveFunction:outTrainingLosses:outModelLayersUpdated:
lastObject
doBackPropWithNnetModelFile:inputFeatureVector:inputTargetVector:inputLearningRate:inputFreezeComponents:inputNumLocalIterations:inputGradNormFactor:inputGradNormType:inputBatchSize:inputObjectiveFunction:outTrainingLoss:outModelLayersUpdated:
arrayWithObjects:count:
initWithDataPointer:shape:dataType:strides:deallocator:error:
initWithToken:pronunciations:
_quasarProns
token
setToken:
setPronunciations:
_token
_initWithCorrectedUtterances:
correctedUtterances
_correctedUtterances
correctedResultWithKeyword:tokenizedKeyword:preItnSausage:preItnOneBest:preItnOneBestIndices:nbestSize:
_kwf
initWithBytes:length:encoding:
ear_stringWithStringView:
URLByAppendingPathComponent:
path
text
formattedStringWithStrings:preToPostItnArray:
formattedStringWithStrings:
initWithModelURL:
format:preToPostItnMap:
format:
outputLocale
_outputLocale
mutableCopy
defaultCStringEncoding
stringWithCString:encoding:
writeToFile:options:error:
getFstGrammar:overrideFolder:weight:errorOut:
_customLMBuilder
initWithConfigFile:configRoot:sampleRate:delegate:queue:
_startComputeTask
delegate
processInfo
systemUptime
psrAudioProcessor:hasSpeakerVector:speakerVectorSize:processedAudioDurationMs:
psrAudioProcessor:hasResult:numElements:
psrAudioProcessor:finishedWithFinalSpeakerVector:speakerVectorSize:processedAudioDurationMs:
dealloc
initWithConfigFile:configRoot:sampleRate:delegate:
addAudio:
resetForNewRequest
configRoot
setConfigRoot:
setDelegate:
queue
setQueue:
_audioProcessor
_sysConfig
_sampleRate
_configRoot
_delegate
initWithStream:
_stream
initWithConfiguration:usage:
commandId
tagSequence
tokensForTag:
commandTaggings
commandTaggingFromRecognitionResult:activeCommands:
parameterTagForIndex:
commandPhraseTagForIndex:
isParameterTag:
isCommandPhraseTag:
_initWithAudioBuffer:
precededBySpace
followedBySpace
initWithText:confidence:precededBySpace:followedBySpace:
_precededBySpace
_followedBySpace
_confidence
_text
translateSpeech:from:to:completion:
rawTranscription
segments
substring
translateTokens:from:to:completion:
translateString:from:to:completion:
_tokenizeString:
_translate:from:to:completion:
componentsSeparatedByString:
initWithLocale:tokens:confidence:lowConfidence:metaInfo:
loadTranslatorFrom:to:
translateSpeech:completion:
translateString:completion:
callbackQueue
setCallbackQueue:
_translatorFactory
_config
_translationQueue
_callbackQueue
addDataSource:weight:
totalWeight
_dataSources
_totalWeight
formattedStringWithStrings:task:
convertStringsToQuasarTokens:
getOrthography:
formattedStringWithStrings:preToPostItnArray:task:
formatWords:
initWithQuasarConfig:language:
formattedRecognitionWithNBestList:
setLanguage:
_itn
_language
removeLastObject
locale
lowConfidence
metaInfo
_lowConfidence
_locale
_tokens
_metaInfo
initWithSilenceFramesCountMs:silenceProbability:silenceDurationMs:silencePosterior:processedAudioMs:
silenceFramesCountMs
setSilenceFramesCountMs:
silenceProbability
setSilenceProbability:
silenceDurationMs
setSilenceDurationMs:
processedAudioMs
setProcessedAudioMs:
_silenceFramesCountMs
_silenceProbability
_silenceDurationMs
_processedAudioMs
initWithConfigFile:samplingRate:
initWithConfigFile:samplingRate:queue:
clientSilenceFeaturesAvailable:
silenceDurationEstimateAvailable:numEstimates:clientProcessedAudioMs:
initWithConfigFile:
addAudio:numSamples:
getFrameDurationMs
_silenceGenerator
_spgQueue
loggingDict
setLoggingDict:
context
setContext:
_loggingDict
_context
isConfident
setIsConfident:
_isConfident
fileURLWithPath:isDirectory:
modelWithContentsOfURL:error:
localizedDescription
numberWithUnsignedInteger:
initWithShape:dataType:error:
setObject:atIndexedSubscript:
dictionaryWithCapacity:
initWithDictionary:error:
setUsesCPUOnly:
predictionFromFeatures:options:error:
featureValueForName:
dictionaryValue
objectForKeyedSubscript:
initWithConfigFile:overrides:
quasarLocalesOfMessages:
arrayWithCapacity:
null
dominantLanguageForString:
isEqualToString:
objectAtIndexedSubscript:
updateContext:withMessageLocales:
localesOfMessages:
startRequestWith:context:delegate:
languageDetector
absoluteString
arrayWithObjects:
dictionaryWithObject:forKey:
dictionary
multiArrayValue
dictionaryWithObjects:forKeys:
languageDetectorDidCompleteProcessing:loggingInfo:
languageDetector:result:
languageDetector:confidences:
fileExistsAtPath:isDirectory:
createDirectoryAtPath:withIntermediateDirectories:attributes:error:
_tagging
_commandId
_tagSequence
_commandTaggings
_tagger
modelDescription
inputDescriptionsByName
multiArrayConstraint
shape
outputDescriptionsByName
fileURLWithFileSystemRepresentation:isDirectory:relativeToURL:
featureNames
strides
longValue
dataType
dataPointer
setComputeUnits:
modelWithContentsOfURL:configuration:error:
unsignedIntegerValue
copyIntoMultiArray:error:
integerValue
@40@0:8@16@24q32
@48@0:8@16@24@32Q40
@16@0:8
q16@0:8
Q16@0:8
v16@0:8
@"NSString"
@"NSSet"
B32@0:8@16@24
@48@0:8@16@24@32@40
@88@0:8@16@24@32@40@48@56@64@72@80
@96@0:8@16@24@32@40@48@56@64@72@80@88
v32@0:8@16@24
v24@0:8@16
@24@0:8@16
{map<std::__1::basic_string<char>, std::__1::vector<std::__1::vector<quasar::LmeDataFactoryBase::Word, std::__1::allocator<quasar::LmeDataFactoryBase::Word> >, std::__1::allocator<std::__1::vector<quasar::LmeDataFactoryBase::Word, std::__1::allocator<quasar::LmeDataFactoryBase::Word> > > >, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, std::__1::vector<std::__1::vector<quasar::LmeDataFactoryBase::Word, std::__1::allocator<quasar::LmeDataFactoryBase::Word> >, std::__1::allocator<std::__1::vector<quasar::LmeDataFactoryBase::Word, std::__1::allocator<quasar::LmeDataFactoryBase::Word> > > > > > >="__tree_"{__tree<std::__1::__value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::vector<quasar::LmeDataFactoryBase::Word, std::__1::allocator<quasar::LmeDataFactoryBase::Word> >, std::__1::allocator<std::__1::vector<quasar::LmeDataFactoryBase::Word, std::__1::allocator<quasar::LmeDataFactoryBase::Word> > > > >, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::vector<quasar::LmeDataFactoryBase::Word, std::__1::allocator<quasar::LmeDataFactoryBase::Word> >, std::__1::allocator<std::__1::vector<quasar::LmeDataFactoryBase::Word, std::__1::allocator<quasar::LmeDataFactoryBase::Word> > > > >, std::__1::less<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::vector<quasar::LmeDataFactoryBase::Word, std::__1::allocator<quasar::LmeDataFactoryBase::Word> >, std::__1::allocator<std::__1::vector<quasar::LmeDataFactoryBase::Word, std::__1::allocator<quasar::LmeDataFactoryBase::Word> > > > > > >="__begin_node_"^{__tree_end_node<std::__1::__tree_node_base<void *> *>}"__pair1_"{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::vector<quasar::LmeDataFactoryBase::Word, std::__1::allocator<quasar::LmeDataFactoryBase::Word> >, std::__1::allocator<std::__1::vector<quasar::LmeDataFactoryBase::Word, std::__1::allocator<quasar::LmeDataFactoryBase::Word> > > > >, void *> > >="__value_"{__tree_end_node<std::__1::__tree_node_base<void *> *>="__left_"^{__tree_node_base<void *>}}}"__pair3_"{__compressed_pair<unsigned long, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::vector<quasar::LmeDataFactoryBase::Word, std::__1::allocator<quasar::LmeDataFactoryBase::Word> >, std::__1::allocator<std::__1::vector<quasar::LmeDataFactoryBase::Word, std::__1::allocator<quasar::LmeDataFactoryBase::Word> > > > >, std::__1::less<std::__1::basic_string<char> >, true> >="__value_"Q}}}
{shared_ptr<quasar::LmeDataFactory>="__ptr_"^{LmeDataFactory}"__cntrl_"^{__shared_weak_count}}
{unique_ptr<sdapi::SdapiTokenizer, std::__1::default_delete<sdapi::SdapiTokenizer> >="__ptr_"{__compressed_pair<sdapi::SdapiTokenizer *, std::__1::default_delete<sdapi::SdapiTokenizer> >="__value_"^{SdapiTokenizer}}}
{unique_ptr<quasar::G2P, std::__1::default_delete<quasar::G2P> >="__ptr_"{__compressed_pair<quasar::G2P *, std::__1::default_delete<quasar::G2P> >="__value_"^{G2P}}}
{shared_ptr<quasar::PronCache<std::__1::basic_string<char>, std::__1::vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > > > >="__ptr_"^{PronCache<std::__1::basic_string<char>, std::__1::vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > > >}"__cntrl_"^{__shared_weak_count}}
{BasicTextSanitizer="_vptr$TextSanitizer"^^?"mUnicodeOutliers"{shared_ptr<quasar::URegularExpressionWrapper>="__ptr_"^{URegularExpressionWrapper}"__cntrl_"^{__shared_weak_count}}"mSpecialChars"{shared_ptr<quasar::URegularExpressionWrapper>="__ptr_"^{URegularExpressionWrapper}"__cntrl_"^{__shared_weak_count}}"mDupSpacePattern"{shared_ptr<quasar::URegularExpressionWrapper>="__ptr_"^{URegularExpressionWrapper}"__cntrl_"^{__shared_weak_count}}"mCtrlCharsPattern"{shared_ptr<quasar::URegularExpressionWrapper>="__ptr_"^{URegularExpressionWrapper}"__cntrl_"^{__shared_weak_count}}"state"i"UTF8_MAP"{unordered_map<std::__1::basic_string<char>, std::__1::basic_string<char>, std::__1::hash<std::__1::basic_string<char> >, std::__1::equal_to<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, std::__1::basic_string<char> > > >="__table_"{__hash_table<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::__unordered_map_hasher<std::__1::basic_string<char>, std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::hash<std::__1::basic_string<char> >, true>, std::__1::__unordered_map_equal<std::__1::basic_string<char>, std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::equal_to<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::basic_string<char> > > >="__bucket_list_"{unique_ptr<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, void *> *> *[], std::__1::__bucket_list_deallocator<std::__1::allocator<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, void *> *> *> > >="__ptr_"{__compressed_pair<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, void *> *> **, std::__1::__bucket_list_deallocator<std::__1::allocator<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, void *> *> *> > >="__value_"^^{__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, void *> *>}"__value_"{__bucket_list_deallocator<std::__1::allocator<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, void *> *> *> >="__data_"{__compressed_pair<unsigned long, std::__1::allocator<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, void *> *> *> >="__value_"Q}}}}"__p1_"{__compressed_pair<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, void *> *>, std::__1::allocator<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, void *> > >="__value_"{__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, void *> *>="__next_"^{__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, void *> *>}}}"__p2_"{__compressed_pair<unsigned long, std::__1::__unordered_map_hasher<std::__1::basic_string<char>, std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::hash<std::__1::basic_string<char> >, true> >="__value_"Q}"__p3_"{__compressed_pair<float, std::__1::__unordered_map_equal<std::__1::basic_string<char>, std::__1::__hash_value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::equal_to<std::__1::basic_string<char> >, true> >="__value_"f}}}"unicode_map"{unordered_map<char32_t, char32_t, std::__1::hash<char32_t>, std::__1::equal_to<char32_t>, std::__1::allocator<std::__1::pair<const char32_t, char32_t> > >="__table_"{__hash_table<std::__1::__hash_value_type<char32_t, char32_t>, std::__1::__unordered_map_hasher<char32_t, std::__1::__hash_value_type<char32_t, char32_t>, std::__1::hash<char32_t>, true>, std::__1::__unordered_map_equal<char32_t, std::__1::__hash_value_type<char32_t, char32_t>, std::__1::equal_to<char32_t>, true>, std::__1::allocator<std::__1::__hash_value_type<char32_t, char32_t> > >="__bucket_list_"{unique_ptr<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<char32_t, char32_t>, void *> *> *[], std::__1::__bucket_list_deallocator<std::__1::allocator<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<char32_t, char32_t>, void *> *> *> > >="__ptr_"{__compressed_pair<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<char32_t, char32_t>, void *> *> **, std::__1::__bucket_list_deallocator<std::__1::allocator<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<char32_t, char32_t>, void *> *> *> > >="__value_"^^{__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<char32_t, char32_t>, void *> *>}"__value_"{__bucket_list_deallocator<std::__1::allocator<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<char32_t, char32_t>, void *> *> *> >="__data_"{__compressed_pair<unsigned long, std::__1::allocator<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<char32_t, char32_t>, void *> *> *> >="__value_"Q}}}}"__p1_"{__compressed_pair<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<char32_t, char32_t>, void *> *>, std::__1::allocator<std::__1::__hash_node<std::__1::__hash_value_type<char32_t, char32_t>, void *> > >="__value_"{__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<char32_t, char32_t>, void *> *>="__next_"^{__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<char32_t, char32_t>, void *> *>}}}"__p2_"{__compressed_pair<unsigned long, std::__1::__unordered_map_hasher<char32_t, std::__1::__hash_value_type<char32_t, char32_t>, std::__1::hash<char32_t>, true> >="__value_"Q}"__p3_"{__compressed_pair<float, std::__1::__unordered_map_equal<char32_t, std::__1::__hash_value_type<char32_t, char32_t>, std::__1::equal_to<char32_t>, true> >="__value_"f}}}}
{unique_ptr<quasar::PersonalizationRecipe, std::__1::default_delete<quasar::PersonalizationRecipe> >="__ptr_"{__compressed_pair<quasar::PersonalizationRecipe *, std::__1::default_delete<quasar::PersonalizationRecipe> >="__value_"^{PersonalizationRecipe}}}
{unique_ptr<quasar::LmeData, std::__1::default_delete<quasar::LmeData> >="__ptr_"{__compressed_pair<quasar::LmeData *, std::__1::default_delete<quasar::LmeData> >="__value_"^{LmeData}}}
@80@0:8q16q24d32@40d48d56d64f72f76
@88@0:8q16q24d32@40d48d56d64f72f76q80
v24@0:8q16
d16@0:8
v24@0:8d16
f16@0:8
v20@0:8f16
@"NSArray"
@40@0:8q16q24f32f36
@32@0:8@16^@24
@36@0:8@16B24^@28
B24@0:8Q16
v20@0:8B16
B56@0:8@16d24^@32^f40^i48
B32@0:8@16^@24
{unique_ptr<quasar::HybridEndpointer, std::__1::default_delete<quasar::HybridEndpointer> >="__ptr_"{__compressed_pair<quasar::HybridEndpointer *, std::__1::default_delete<quasar::HybridEndpointer> >="__value_"^{HybridEndpointer}}}
@24@0:8^{_NSZone=}16
B24@0:8@16
@80@0:8@16d24d32d40d48B56B60@64@72
@24@0:8r^{Token={basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}IIIfBB{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}}16
B16@0:8
{Token={basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}IIIfBB{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}}16@0:8
{Token="tokenName"{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >="__r_"{__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >="__value_"{__rep=""(?="__l"{__long="__cap_"Q"__size_"Q"__data_"*}"__s"{__short=""(?="__size_"C"__lx"c)"__data_"[23c]}"__r"{__raw="__words"[3Q]})}}}"startMilliseconds"I"endMilliseconds"I"silStartMilliSeconds"I"confidence"f"hasSpaceAfter"B"hasSpaceBefore"B"phoneSeq"{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >="__r_"{__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >="__value_"{__rep=""(?="__l"{__long="__cap_"Q"__size_"Q"__data_"*}"__s"{__short=""(?="__size_"C"__lx"c)"__data_"[23c]}"__r"{__raw="__words"[3Q]})}}}"ipaPhoneSeq"{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >="__r_"{__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >="__value_"{__rep=""(?="__l"{__long="__cap_"Q"__size_"Q"__data_"*}"__s"{__short=""(?="__size_"C"__lx"c)"__data_"[23c]}"__r"{__raw="__words"[3Q]})}}}}
@28@0:8@16f24
@32@0:8@16@24
@"NSDictionary"
@28@0:8r^{vector<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> >, std::__1::allocator<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> > > >=^{vector<quasar::Token, std::__1::allocator<quasar::Token> >}^{vector<quasar::Token, std::__1::allocator<quasar::Token> >}{__compressed_pair<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> > *, std::__1::allocator<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> > > >=^{vector<quasar::Token, std::__1::allocator<quasar::Token> >}}}16B24
@24@0:8r^{pair<std::__1::vector<std::__1::vector<unsigned int, std::__1::allocator<unsigned int> >, std::__1::allocator<std::__1::vector<unsigned int, std::__1::allocator<unsigned int> > > >, std::__1::vector<std::__1::vector<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> >, std::__1::allocator<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> > > >, std::__1::allocator<std::__1::vector<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> >, std::__1::allocator<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> > > > > > >={vector<std::__1::vector<unsigned int, std::__1::allocator<unsigned int> >, std::__1::allocator<std::__1::vector<unsigned int, std::__1::allocator<unsigned int> > > >=^{vector<unsigned int, std::__1::allocator<unsigned int> >}^{vector<unsigned int, std::__1::allocator<unsigned int> >}{__compressed_pair<std::__1::vector<unsigned int, std::__1::allocator<unsigned int> > *, std::__1::allocator<std::__1::vector<unsigned int, std::__1::allocator<unsigned int> > > >=^{vector<unsigned int, std::__1::allocator<unsigned int> >}}}{vector<std::__1::vector<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> >, std::__1::allocator<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> > > >, std::__1::allocator<std::__1::vector<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> >, std::__1::allocator<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> > > > > >=^{vector<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> >, std::__1::allocator<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> > > >}^{vector<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> >, std::__1::allocator<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> > > >}{__compressed_pair<std::__1::vector<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> >, std::__1::allocator<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> > > > *, std::__1::allocator<std::__1::vector<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> >, std::__1::allocator<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> > > > > >=^{vector<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> >, std::__1::allocator<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> > > >}}}}16
{pair<std::__1::vector<std::__1::vector<unsigned int, std::__1::allocator<unsigned int> >, std::__1::allocator<std::__1::vector<unsigned int, std::__1::allocator<unsigned int> > > >, std::__1::vector<std::__1::vector<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> >, std::__1::allocator<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> > > >, std::__1::allocator<std::__1::vector<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> >, std::__1::allocator<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> > > > > > >={vector<std::__1::vector<unsigned int, std::__1::allocator<unsigned int> >, std::__1::allocator<std::__1::vector<unsigned int, std::__1::allocator<unsigned int> > > >=^{vector<unsigned int, std::__1::allocator<unsigned int> >}^{vector<unsigned int, std::__1::allocator<unsigned int> >}{__compressed_pair<std::__1::vector<unsigned int, std::__1::allocator<unsigned int> > *, std::__1::allocator<std::__1::vector<unsigned int, std::__1::allocator<unsigned int> > > >=^{vector<unsigned int, std::__1::allocator<unsigned int> >}}}{vector<std::__1::vector<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> >, std::__1::allocator<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> > > >, std::__1::allocator<std::__1::vector<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> >, std::__1::allocator<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> > > > > >=^{vector<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> >, std::__1::allocator<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> > > >}^{vector<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> >, std::__1::allocator<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> > > >}{__compressed_pair<std::__1::vector<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> >, std::__1::allocator<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> > > > *, std::__1::allocator<std::__1::vector<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> >, std::__1::allocator<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> > > > > >=^{vector<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> >, std::__1::allocator<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> > > >}}}}16@0:8
@40@0:8@16@24B32B36
@48@0:8@16@24B32B36@40
@"_EARSpeechRecognition"
@"_EARAudioAnalytics"
@64@0:8{vector<quasar::Token, std::__1::allocator<quasar::Token> >=^{Token}^{Token}{__compressed_pair<quasar::Token *, std::__1::allocator<quasar::Token> >=^{Token}}}16{vector<quasar::Token, std::__1::allocator<quasar::Token> >=^{Token}^{Token}{__compressed_pair<quasar::Token *, std::__1::allocator<quasar::Token> >=^{Token}}}40
{vector<quasar::Token, std::__1::allocator<quasar::Token> >=^{Token}^{Token}{__compressed_pair<quasar::Token *, std::__1::allocator<quasar::Token> >=^{Token}}}16@0:8
{vector<quasar::Token, std::__1::allocator<quasar::Token> >="__begin_"^{Token}"__end_"^{Token}"__end_cap_"{__compressed_pair<quasar::Token *, std::__1::allocator<quasar::Token> >="__value_"^{Token}}}
@40@0:8@16@24@32
@64@0:8@16@24@32@40@48@56
@56@0:8@16@24@32@40@48
@28@0:8@16B24
^{TextTokenizer=^^?}16@0:8
{shared_ptr<quasar::SpeechRequestData>=^{SpeechRequestData}^{__shared_weak_count}}72@0:8@16@24Q32{shared_ptr<quasar::RecogResultStreamBase>=^{RecogResultStreamBase}^{__shared_weak_count}}40@56r^{shared_ptr<quasar::SymbolTableList>=^{SymbolTableList}^{__shared_weak_count}}64
@56@0:8@16@24@32Q40@48
{shared_ptr<quasar::RecogAudioBufferBase>=^{RecogAudioBufferBase}^{__shared_weak_count}}64@0:8@16@24Q32@40{shared_ptr<quasar::RecogResultStreamBase>=^{RecogResultStreamBase}^{__shared_weak_count}}48
@56@0:8@16@24@32@40Q48
@64@0:8@16@24@32@40Q48@56
v24@0:8@?16
@"NSObject<OS_dispatch_queue>"
@"_EARFormatter"
{unique_ptr<quasar::SpeechRecognizer, std::__1::default_delete<quasar::SpeechRecognizer> >="__ptr_"{__compressed_pair<quasar::SpeechRecognizer *, std::__1::default_delete<quasar::SpeechRecognizer> >="__value_"^{SpeechRecognizer}}}
{unique_ptr<quasar::TextTokenizer, std::__1::default_delete<quasar::TextTokenizer> >="__ptr_"{__compressed_pair<quasar::TextTokenizer *, std::__1::default_delete<quasar::TextTokenizer> >="__value_"^{TextTokenizer}}}
@"_EARSpeechRecognitionAudioBuffer"
{weak_ptr<ResultStreamWrapper>="__ptr_"^{ResultStreamWrapper}"__cntrl_"^{__shared_weak_count}}
@"NSData"
{SpeechModelInfo="version"{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >="__r_"{__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >="__value_"{__rep=""(?="__l"{__long="__cap_"Q"__size_"Q"__data_"*}"__s"{__short=""(?="__size_"C"__lx"c)"__data_"[23c]}"__r"{__raw="__words"[3Q]})}}}"samplingRates"{set<int, std::__1::less<int>, std::__1::allocator<int> >="__tree_"{__tree<int, std::__1::less<int>, std::__1::allocator<int> >="__begin_node_"^{__tree_end_node<std::__1::__tree_node_base<void *> *>}"__pair1_"{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<int, void *> > >="__value_"{__tree_end_node<std::__1::__tree_node_base<void *> *>="__left_"^{__tree_node_base<void *>}}}"__pair3_"{__compressed_pair<unsigned long, std::__1::less<int> >="__value_"Q}}}"tasks"{set<std::__1::basic_string<char>, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::basic_string<char> > >="__tree_"{__tree<std::__1::basic_string<char>, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::basic_string<char> > >="__begin_node_"^{__tree_end_node<std::__1::__tree_node_base<void *> *>}"__pair1_"{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::basic_string<char>, void *> > >="__value_"{__tree_end_node<std::__1::__tree_node_base<void *> *>="__left_"^{__tree_node_base<void *>}}}"__pair3_"{__compressed_pair<unsigned long, std::__1::less<std::__1::basic_string<char> > >="__value_"Q}}}"osTypes"{set<std::__1::basic_string<char>, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::basic_string<char> > >="__tree_"{__tree<std::__1::basic_string<char>, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::basic_string<char> > >="__begin_node_"^{__tree_end_node<std::__1::__tree_node_base<void *> *>}"__pair1_"{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::basic_string<char>, void *> > >="__value_"{__tree_end_node<std::__1::__tree_node_base<void *> *>="__left_"^{__tree_node_base<void *>}}}"__pair3_"{__compressed_pair<unsigned long, std::__1::less<std::__1::basic_string<char> > >="__value_"Q}}}"language"{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >="__r_"{__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >="__value_"{__rep=""(?="__l"{__long="__cap_"Q"__size_"Q"__data_"*}"__s"{__short=""(?="__size_"C"__lx"c)"__data_"[23c]}"__r"{__raw="__words"[3Q]})}}}"phoneSetVersion"{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >="__r_"{__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >="__value_"{__rep=""(?="__l"{__long="__cap_"Q"__size_"Q"__data_"*}"__s"{__short=""(?="__size_"C"__lx"c)"__data_"[23c]}"__r"{__raw="__words"[3Q]})}}}"acousticProfileVersion"{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >="__r_"{__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >="__value_"{__rep=""(?="__l"{__long="__cap_"Q"__size_"Q"__data_"*}"__s"{__short=""(?="__size_"C"__lx"c)"__data_"[23c]}"__r"{__raw="__words"[3Q]})}}}"aceToQuasarTemplate"{map<std::__1::basic_string<char>, std::__1::basic_string<char>, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, std::__1::basic_string<char> > > >="__tree_"{__tree<std::__1::__value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::less<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__value_type<std::__1::basic_string<char>, std::__1::basic_string<char> > > >="__begin_node_"^{__tree_end_node<std::__1::__tree_node_base<void *> *>}"__pair1_"{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, void *> > >="__value_"{__tree_end_node<std::__1::__tree_node_base<void *> *>="__left_"^{__tree_node_base<void *>}}}"__pair3_"{__compressed_pair<unsigned long, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::less<std::__1::basic_string<char> >, true> >="__value_"Q}}}"quasarTemplateToAce"{map<std::__1::basic_string<char>, std::__1::vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > >, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, std::__1::vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > > > > >="__tree_"{__tree<std::__1::__value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > > >, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > > >, std::__1::less<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > > > > >="__begin_node_"^{__tree_end_node<std::__1::__tree_node_base<void *> *>}"__pair1_"{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > > >, void *> > >="__value_"{__tree_end_node<std::__1::__tree_node_base<void *> *>="__left_"^{__tree_node_base<void *>}}}"__pair3_"{__compressed_pair<unsigned long, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > > >, std::__1::less<std::__1::basic_string<char> >, true> >="__value_"Q}}}"quasarTemplateToEnumerationType"{map<std::__1::basic_string<char>, std::__1::basic_string<char>, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, std::__1::basic_string<char> > > >="__tree_"{__tree<std::__1::__value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::less<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__value_type<std::__1::basic_string<char>, std::__1::basic_string<char> > > >="__begin_node_"^{__tree_end_node<std::__1::__tree_node_base<void *> *>}"__pair1_"{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, void *> > >="__value_"{__tree_end_node<std::__1::__tree_node_base<void *> *>="__left_"^{__tree_node_base<void *>}}}"__pair3_"{__compressed_pair<unsigned long, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::less<std::__1::basic_string<char> >, true> >="__value_"Q}}}"g2pModelVersion"i"hybridEndpointerVersion"i}
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
v48@0:8@16@24@32@40
v32@0:8@16d24
v72@0:8@16q24q32d40@48d56q64
v32@0:8@"_EARSpeechRecognizer"16@"_EARSpeechRecognitionResult"24
v32@0:8@"_EARSpeechRecognizer"16@"NSError"24
v32@0:8@"_EARSpeechRecognizer"16@"NSArray"24
v48@0:8@"_EARSpeechRecognizer"16@"NSArray"24@"NSArray"32@"NSArray"40
v32@0:8@"_EARSpeechRecognizer"16@"_EARSpeechRecognitionResultPackage"24
v32@0:8@"_EARSpeechRecognizer"16d24
v32@0:8@"_EARSpeechRecognizer"16@"_EARSpeechRecognition"24
v72@0:8@"_EARSpeechRecognizer"16q24q32d40@"NSArray"48d56q64
@"NSObject<OS_dispatch_semaphore>"
@"NSError"
@40@0:8{shared_ptr<quasar::RecogAudioBufferBase>=^{RecogAudioBufferBase}^{__shared_weak_count}}16@32
v32@0:8r^s16Q24
v32@0:8{shared_ptr<quasar::RecogAudioBufferBase>=^{RecogAudioBufferBase}^{__shared_weak_count}}16
{shared_ptr<quasar::RecogAudioBufferBase>="__ptr_"^{RecogAudioBufferBase}"__cntrl_"^{__shared_weak_count}}
@"_EARSpeechRecognizer"
v76@0:8I16@20@28@36@44@52B60@64I72
@48@0:8{vector<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> >, std::__1::allocator<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> > > >=^{vector<quasar::Token, std::__1::allocator<quasar::Token> >}^{vector<quasar::Token, std::__1::allocator<quasar::Token> >}{__compressed_pair<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> > *, std::__1::allocator<std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> > > >=^{vector<quasar::Token, std::__1::allocator<quasar::Token> >}}}16@40
@40@0:8@16Q24@32
{shared_ptr<quasar::SyncSpeechRecognizer>="__ptr_"^{SyncSpeechRecognizer}"__cntrl_"^{__shared_weak_count}}
{unique_ptr<quasar::ResultCombiner, std::__1::default_delete<quasar::ResultCombiner> >="__ptr_"{__compressed_pair<quasar::ResultCombiner *, std::__1::default_delete<quasar::ResultCombiner> >="__value_"^{ResultCombiner}}}
@24@0:8r^{LDContext={map<quasar::Locale, double, std::__1::less<quasar::Locale>, std::__1::allocator<std::__1::pair<const quasar::Locale, double> > >={__tree<std::__1::__value_type<quasar::Locale, double>, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true>, std::__1::allocator<std::__1::__value_type<quasar::Locale, double> > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<quasar::Locale, double>, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true> >=Q}}}{optional<std::__1::set<quasar::Locale, std::__1::less<quasar::Locale>, std::__1::allocator<quasar::Locale> > >=(?=c{set<quasar::Locale, std::__1::less<quasar::Locale>, std::__1::allocator<quasar::Locale> >={__tree<quasar::Locale, std::__1::less<quasar::Locale>, std::__1::allocator<quasar::Locale> >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<quasar::Locale, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::less<quasar::Locale> >=Q}}})B}{optional<quasar::Locale>=(?=c{Locale={basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}})B}{optional<bool>=(?=cB)B}{optional<std::__1::vector<quasar::Locale, std::__1::allocator<quasar::Locale> > >=(?=c{vector<quasar::Locale, std::__1::allocator<quasar::Locale> >=^{Locale}^{Locale}{__compressed_pair<quasar::Locale *, std::__1::allocator<quasar::Locale> >=^{Locale}}})B}{optional<std::__1::map<quasar::Locale, double, std::__1::less<quasar::Locale>, std::__1::allocator<std::__1::pair<const quasar::Locale, double> > > >=(?=c{map<quasar::Locale, double, std::__1::less<quasar::Locale>, std::__1::allocator<std::__1::pair<const quasar::Locale, double> > >={__tree<std::__1::__value_type<quasar::Locale, double>, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true>, std::__1::allocator<std::__1::__value_type<quasar::Locale, double> > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<quasar::Locale, double>, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true> >=Q}}})B}{optional<std::__1::map<quasar::Locale, double, std::__1::less<quasar::Locale>, std::__1::allocator<std::__1::pair<const quasar::Locale, double> > > >=(?=c{map<quasar::Locale, double, std::__1::less<quasar::Locale>, std::__1::allocator<std::__1::pair<const quasar::Locale, double> > >={__tree<std::__1::__value_type<quasar::Locale, double>, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true>, std::__1::allocator<std::__1::__value_type<quasar::Locale, double> > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<quasar::Locale, double>, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true> >=Q}}})B}{optional<quasar::Locale>=(?=c{Locale={basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}})B}{optional<quasar::Locale>=(?=c{Locale={basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}})B}{optional<std::__1::map<quasar::Locale, double, std::__1::less<quasar::Locale>, std::__1::allocator<std::__1::pair<const quasar::Locale, double> > > >=(?=c{map<quasar::Locale, double, std::__1::less<quasar::Locale>, std::__1::allocator<std::__1::pair<const quasar::Locale, double> > >={__tree<std::__1::__value_type<quasar::Locale, double>, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true>, std::__1::allocator<std::__1::__value_type<quasar::Locale, double> > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<quasar::Locale, double>, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true> >=Q}}})B}}16
{LDContext={map<quasar::Locale, double, std::__1::less<quasar::Locale>, std::__1::allocator<std::__1::pair<const quasar::Locale, double> > >={__tree<std::__1::__value_type<quasar::Locale, double>, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true>, std::__1::allocator<std::__1::__value_type<quasar::Locale, double> > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<quasar::Locale, double>, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true> >=Q}}}{optional<std::__1::set<quasar::Locale, std::__1::less<quasar::Locale>, std::__1::allocator<quasar::Locale> > >=(?=c{set<quasar::Locale, std::__1::less<quasar::Locale>, std::__1::allocator<quasar::Locale> >={__tree<quasar::Locale, std::__1::less<quasar::Locale>, std::__1::allocator<quasar::Locale> >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<quasar::Locale, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::less<quasar::Locale> >=Q}}})B}{optional<quasar::Locale>=(?=c{Locale={basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}})B}{optional<bool>=(?=cB)B}{optional<std::__1::vector<quasar::Locale, std::__1::allocator<quasar::Locale> > >=(?=c{vector<quasar::Locale, std::__1::allocator<quasar::Locale> >=^{Locale}^{Locale}{__compressed_pair<quasar::Locale *, std::__1::allocator<quasar::Locale> >=^{Locale}}})B}{optional<std::__1::map<quasar::Locale, double, std::__1::less<quasar::Locale>, std::__1::allocator<std::__1::pair<const quasar::Locale, double> > > >=(?=c{map<quasar::Locale, double, std::__1::less<quasar::Locale>, std::__1::allocator<std::__1::pair<const quasar::Locale, double> > >={__tree<std::__1::__value_type<quasar::Locale, double>, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true>, std::__1::allocator<std::__1::__value_type<quasar::Locale, double> > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<quasar::Locale, double>, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true> >=Q}}})B}{optional<std::__1::map<quasar::Locale, double, std::__1::less<quasar::Locale>, std::__1::allocator<std::__1::pair<const quasar::Locale, double> > > >=(?=c{map<quasar::Locale, double, std::__1::less<quasar::Locale>, std::__1::allocator<std::__1::pair<const quasar::Locale, double> > >={__tree<std::__1::__value_type<quasar::Locale, double>, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true>, std::__1::allocator<std::__1::__value_type<quasar::Locale, double> > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<quasar::Locale, double>, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true> >=Q}}})B}{optional<quasar::Locale>=(?=c{Locale={basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}})B}{optional<quasar::Locale>=(?=c{Locale={basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}})B}{optional<std::__1::map<quasar::Locale, double, std::__1::less<quasar::Locale>, std::__1::allocator<std::__1::pair<const quasar::Locale, double> > > >=(?=c{map<quasar::Locale, double, std::__1::less<quasar::Locale>, std::__1::allocator<std::__1::pair<const quasar::Locale, double> > >={__tree<std::__1::__value_type<quasar::Locale, double>, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true>, std::__1::allocator<std::__1::__value_type<quasar::Locale, double> > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<quasar::Locale, double>, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true> >=Q}}})B}}16@0:8
@"NSNumber"
@96@0:8@16@24@32f40@44i52f56@60f68@72^f80^@88
@96@0:8@16@24@32f40@44i52f56@60f68@72^@80^@88
{TokenProns={basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}{vector<quasar::PronChoice, std::__1::allocator<quasar::PronChoice> >=^{PronChoice}^{PronChoice}{__compressed_pair<quasar::PronChoice *, std::__1::allocator<quasar::PronChoice> >=^{PronChoice}}}{vector<quasar::PronChoice, std::__1::allocator<quasar::PronChoice> >=^{PronChoice}^{PronChoice}{__compressed_pair<quasar::PronChoice *, std::__1::allocator<quasar::PronChoice> >=^{PronChoice}}}}16@0:8
@64@0:8@16@24@32@40@48q56
{unique_ptr<quasar::KeywordFinder, std::__1::default_delete<quasar::KeywordFinder> >="__ptr_"{__compressed_pair<quasar::KeywordFinder *, std::__1::default_delete<quasar::KeywordFinder> >="__value_"^{KeywordFinder}}}
@32@0:8{basic_string_view<char, std::__1::char_traits<char> >=*Q}16
@"NSLocale"
B44@0:8@16@24f32^@36
{unique_ptr<quasar::CustomLMBuilder, std::__1::default_delete<quasar::CustomLMBuilder> >="__ptr_"{__compressed_pair<quasar::CustomLMBuilder *, std::__1::default_delete<quasar::CustomLMBuilder> >="__value_"^{CustomLMBuilder}}}
@48@0:8@16@24Q32@40
@56@0:8@16@24Q32@40@48
{shared_ptr<quasar::PSRAudioProcessor>="__ptr_"^{PSRAudioProcessor}"__cntrl_"^{__shared_weak_count}}
{SystemConfig="_vptr$OptionsItf"^^?"jsonConfigFilePath"{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >="__r_"{__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >="__value_"{__rep=""(?="__l"{__long="__cap_"Q"__size_"Q"__data_"*}"__s"{__short=""(?="__size_"C"__lx"c)"__data_"[23c]}"__r"{__raw="__words"[3Q]})}}}"configFileVersion"{Version="versionMajor"i"versionMinor"i}"configPath"{Path="str"{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >="__r_"{__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >="__value_"{__rep=""(?="__l"{__long="__cap_"Q"__size_"Q"__data_"*}"__s"{__short=""(?="__size_"C"__lx"c)"__data_"[23c]}"__r"{__raw="__words"[3Q]})}}}}"prefix"{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >="__r_"{__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >="__value_"{__rep=""(?="__l"{__long="__cap_"Q"__size_"Q"__data_"*}"__s"{__short=""(?="__size_"C"__lx"c)"__data_"[23c]}"__r"{__raw="__words"[3Q]})}}}"pTree"{PTree="dataType"i"dataValue"{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >="__r_"{__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >="__value_"{__rep=""(?="__l"{__long="__cap_"Q"__size_"Q"__data_"*}"__s"{__short=""(?="__size_"C"__lx"c)"__data_"[23c]}"__r"{__raw="__words"[3Q]})}}}"map"{vector<std::__1::pair<std::__1::basic_string<char>, quasar::PTree>, std::__1::allocator<std::__1::pair<std::__1::basic_string<char>, quasar::PTree> > >="__begin_"^{pair<std::__1::basic_string<char>, quasar::PTree>}"__end_"^{pair<std::__1::basic_string<char>, quasar::PTree>}"__end_cap_"{__compressed_pair<std::__1::pair<std::__1::basic_string<char>, quasar::PTree> *, std::__1::allocator<std::__1::pair<std::__1::basic_string<char>, quasar::PTree> > >="__value_"^{pair<std::__1::basic_string<char>, quasar::PTree>}}}"isALeaf"B}"speechModelInfo"{SpeechModelInfo="version"{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >="__r_"{__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >="__value_"{__rep=""(?="__l"{__long="__cap_"Q"__size_"Q"__data_"*}"__s"{__short=""(?="__size_"C"__lx"c)"__data_"[23c]}"__r"{__raw="__words"[3Q]})}}}"samplingRates"{set<int, std::__1::less<int>, std::__1::allocator<int> >="__tree_"{__tree<int, std::__1::less<int>, std::__1::allocator<int> >="__begin_node_"^{__tree_end_node<std::__1::__tree_node_base<void *> *>}"__pair1_"{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<int, void *> > >="__value_"{__tree_end_node<std::__1::__tree_node_base<void *> *>="__left_"^{__tree_node_base<void *>}}}"__pair3_"{__compressed_pair<unsigned long, std::__1::less<int> >="__value_"Q}}}"tasks"{set<std::__1::basic_string<char>, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::basic_string<char> > >="__tree_"{__tree<std::__1::basic_string<char>, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::basic_string<char> > >="__begin_node_"^{__tree_end_node<std::__1::__tree_node_base<void *> *>}"__pair1_"{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::basic_string<char>, void *> > >="__value_"{__tree_end_node<std::__1::__tree_node_base<void *> *>="__left_"^{__tree_node_base<void *>}}}"__pair3_"{__compressed_pair<unsigned long, std::__1::less<std::__1::basic_string<char> > >="__value_"Q}}}"osTypes"{set<std::__1::basic_string<char>, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::basic_string<char> > >="__tree_"{__tree<std::__1::basic_string<char>, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::basic_string<char> > >="__begin_node_"^{__tree_end_node<std::__1::__tree_node_base<void *> *>}"__pair1_"{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::basic_string<char>, void *> > >="__value_"{__tree_end_node<std::__1::__tree_node_base<void *> *>="__left_"^{__tree_node_base<void *>}}}"__pair3_"{__compressed_pair<unsigned long, std::__1::less<std::__1::basic_string<char> > >="__value_"Q}}}"language"{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >="__r_"{__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >="__value_"{__rep=""(?="__l"{__long="__cap_"Q"__size_"Q"__data_"*}"__s"{__short=""(?="__size_"C"__lx"c)"__data_"[23c]}"__r"{__raw="__words"[3Q]})}}}"phoneSetVersion"{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >="__r_"{__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >="__value_"{__rep=""(?="__l"{__long="__cap_"Q"__size_"Q"__data_"*}"__s"{__short=""(?="__size_"C"__lx"c)"__data_"[23c]}"__r"{__raw="__words"[3Q]})}}}"acousticProfileVersion"{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >="__r_"{__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >="__value_"{__rep=""(?="__l"{__long="__cap_"Q"__size_"Q"__data_"*}"__s"{__short=""(?="__size_"C"__lx"c)"__data_"[23c]}"__r"{__raw="__words"[3Q]})}}}"aceToQuasarTemplate"{map<std::__1::basic_string<char>, std::__1::basic_string<char>, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, std::__1::basic_string<char> > > >="__tree_"{__tree<std::__1::__value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::less<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__value_type<std::__1::basic_string<char>, std::__1::basic_string<char> > > >="__begin_node_"^{__tree_end_node<std::__1::__tree_node_base<void *> *>}"__pair1_"{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, void *> > >="__value_"{__tree_end_node<std::__1::__tree_node_base<void *> *>="__left_"^{__tree_node_base<void *>}}}"__pair3_"{__compressed_pair<unsigned long, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::less<std::__1::basic_string<char> >, true> >="__value_"Q}}}"quasarTemplateToAce"{map<std::__1::basic_string<char>, std::__1::vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > >, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, std::__1::vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > > > > >="__tree_"{__tree<std::__1::__value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > > >, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > > >, std::__1::less<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > > > > >="__begin_node_"^{__tree_end_node<std::__1::__tree_node_base<void *> *>}"__pair1_"{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > > >, void *> > >="__value_"{__tree_end_node<std::__1::__tree_node_base<void *> *>="__left_"^{__tree_node_base<void *>}}}"__pair3_"{__compressed_pair<unsigned long, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > > >, std::__1::less<std::__1::basic_string<char> >, true> >="__value_"Q}}}"quasarTemplateToEnumerationType"{map<std::__1::basic_string<char>, std::__1::basic_string<char>, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, std::__1::basic_string<char> > > >="__tree_"{__tree<std::__1::__value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::less<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__value_type<std::__1::basic_string<char>, std::__1::basic_string<char> > > >="__begin_node_"^{__tree_end_node<std::__1::__tree_node_base<void *> *>}"__pair1_"{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, void *> > >="__value_"{__tree_end_node<std::__1::__tree_node_base<void *> *>="__left_"^{__tree_node_base<void *>}}}"__pair3_"{__compressed_pair<unsigned long, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::less<std::__1::basic_string<char> >, true> >="__value_"Q}}}"g2pModelVersion"i"hybridEndpointerVersion"i}"translationModelInfo"{TranslationModelInfo="version"{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >="__r_"{__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >="__value_"{__rep=""(?="__l"{__long="__cap_"Q"__size_"Q"__data_"*}"__s"{__short=""(?="__size_"C"__lx"c)"__data_"[23c]}"__r"{__raw="__words"[3Q]})}}}"tasks"{set<std::__1::basic_string<char>, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::basic_string<char> > >="__tree_"{__tree<std::__1::basic_string<char>, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::basic_string<char> > >="__begin_node_"^{__tree_end_node<std::__1::__tree_node_base<void *> *>}"__pair1_"{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::basic_string<char>, void *> > >="__value_"{__tree_end_node<std::__1::__tree_node_base<void *> *>="__left_"^{__tree_node_base<void *>}}}"__pair3_"{__compressed_pair<unsigned long, std::__1::less<std::__1::basic_string<char> > >="__value_"Q}}}"languagePairs"{vector<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> > > >="__begin_"^{pair<std::__1::basic_string<char>, std::__1::basic_string<char> >}"__end_"^{pair<std::__1::basic_string<char>, std::__1::basic_string<char> >}"__end_cap_"{__compressed_pair<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> > *, std::__1::allocator<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> > > >="__value_"^{pair<std::__1::basic_string<char>, std::__1::basic_string<char> >}}}"pairSpecificSettings"{unordered_map<std::__1::basic_string<char>, quasar::TranslationPairSetting, std::__1::hash<std::__1::basic_string<char> >, std::__1::equal_to<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, quasar::TranslationPairSetting> > >="__table_"{__hash_table<std::__1::__hash_value_type<std::__1::basic_string<char>, quasar::TranslationPairSetting>, std::__1::__unordered_map_hasher<std::__1::basic_string<char>, std::__1::__hash_value_type<std::__1::basic_string<char>, quasar::TranslationPairSetting>, std::__1::hash<std::__1::basic_string<char> >, true>, std::__1::__unordered_map_equal<std::__1::basic_string<char>, std::__1::__hash_value_type<std::__1::basic_string<char>, quasar::TranslationPairSetting>, std::__1::equal_to<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__hash_value_type<std::__1::basic_string<char>, quasar::TranslationPairSetting> > >="__bucket_list_"{unique_ptr<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, quasar::TranslationPairSetting>, void *> *> *[], std::__1::__bucket_list_deallocator<std::__1::allocator<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, quasar::TranslationPairSetting>, void *> *> *> > >="__ptr_"{__compressed_pair<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, quasar::TranslationPairSetting>, void *> *> **, std::__1::__bucket_list_deallocator<std::__1::allocator<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, quasar::TranslationPairSetting>, void *> *> *> > >="__value_"^^{__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, quasar::TranslationPairSetting>, void *> *>}"__value_"{__bucket_list_deallocator<std::__1::allocator<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, quasar::TranslationPairSetting>, void *> *> *> >="__data_"{__compressed_pair<unsigned long, std::__1::allocator<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, quasar::TranslationPairSetting>, void *> *> *> >="__value_"Q}}}}"__p1_"{__compressed_pair<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, quasar::TranslationPairSetting>, void *> *>, std::__1::allocator<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, quasar::TranslationPairSetting>, void *> > >="__value_"{__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, quasar::TranslationPairSetting>, void *> *>="__next_"^{__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<std::__1::basic_string<char>, quasar::TranslationPairSetting>, void *> *>}}}"__p2_"{__compressed_pair<unsigned long, std::__1::__unordered_map_hasher<std::__1::basic_string<char>, std::__1::__hash_value_type<std::__1::basic_string<char>, quasar::TranslationPairSetting>, std::__1::hash<std::__1::basic_string<char> >, true> >="__value_"Q}"__p3_"{__compressed_pair<float, std::__1::__unordered_map_equal<std::__1::basic_string<char>, std::__1::__hash_value_type<std::__1::basic_string<char>, quasar::TranslationPairSetting>, std::__1::equal_to<std::__1::basic_string<char> >, true> >="__value_"f}}}}"modelLoader"{shared_ptr<quasar::ModelLoader>="__ptr_"^{ModelLoader}"__cntrl_"^{__shared_weak_count}}"hybridClientConfigs"{HybridClientConfigs="hybridEndpointerThresholds"{map<int, std::__1::map<std::__1::basic_string<char>, double, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, double> > >, std::__1::less<int>, std::__1::allocator<std::__1::pair<const int, std::__1::map<std::__1::basic_string<char>, double, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, double> > > > > >="__tree_"{__tree<std::__1::__value_type<int, std::__1::map<std::__1::basic_string<char>, double, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, double> > > >, std::__1::__map_value_compare<int, std::__1::__value_type<int, std::__1::map<std::__1::basic_string<char>, double, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, double> > > >, std::__1::less<int>, true>, std::__1::allocator<std::__1::__value_type<int, std::__1::map<std::__1::basic_string<char>, double, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, double> > > > > >="__begin_node_"^{__tree_end_node<std::__1::__tree_node_base<void *> *>}"__pair1_"{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<int, std::__1::map<std::__1::basic_string<char>, double, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, double> > > >, void *> > >="__value_"{__tree_end_node<std::__1::__tree_node_base<void *> *>="__left_"^{__tree_node_base<void *>}}}"__pair3_"{__compressed_pair<unsigned long, std::__1::__map_value_compare<int, std::__1::__value_type<int, std::__1::map<std::__1::basic_string<char>, double, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, double> > > >, std::__1::less<int>, true> >="__value_"Q}}}"hybridEndpointerExtraDelayFrequency"{map<std::__1::basic_string<char>, int, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, int> > >="__tree_"{__tree<std::__1::__value_type<std::__1::basic_string<char>, int>, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, int>, std::__1::less<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__value_type<std::__1::basic_string<char>, int> > >="__begin_node_"^{__tree_end_node<std::__1::__tree_node_base<void *> *>}"__pair1_"{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<std::__1::basic_string<char>, int>, void *> > >="__value_"{__tree_end_node<std::__1::__tree_node_base<void *> *>="__left_"^{__tree_node_base<void *>}}}"__pair3_"{__compressed_pair<unsigned long, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, int>, std::__1::less<std::__1::basic_string<char> >, true> >="__value_"Q}}}}"mainModelVersion"{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >="__r_"{__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >="__value_"{__rep=""(?="__l"{__long="__cap_"Q"__size_"Q"__data_"*}"__s"{__short=""(?="__size_"C"__lx"c)"__data_"[23c]}"__r"{__raw="__words"[3Q]})}}}"boolMap"{map<std::__1::basic_string<char>, bool *, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, bool *> > >="__tree_"{__tree<std::__1::__value_type<std::__1::basic_string<char>, bool *>, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, bool *>, std::__1::less<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__value_type<std::__1::basic_string<char>, bool *> > >="__begin_node_"^{__tree_end_node<std::__1::__tree_node_base<void *> *>}"__pair1_"{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<std::__1::basic_string<char>, bool *>, void *> > >="__value_"{__tree_end_node<std::__1::__tree_node_base<void *> *>="__left_"^{__tree_node_base<void *>}}}"__pair3_"{__compressed_pair<unsigned long, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, bool *>, std::__1::less<std::__1::basic_string<char> >, true> >="__value_"Q}}}"intMap"{map<std::__1::basic_string<char>, int *, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, int *> > >="__tree_"{__tree<std::__1::__value_type<std::__1::basic_string<char>, int *>, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, int *>, std::__1::less<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__value_type<std::__1::basic_string<char>, int *> > >="__begin_node_"^{__tree_end_node<std::__1::__tree_node_base<void *> *>}"__pair1_"{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<std::__1::basic_string<char>, int *>, void *> > >="__value_"{__tree_end_node<std::__1::__tree_node_base<void *> *>="__left_"^{__tree_node_base<void *>}}}"__pair3_"{__compressed_pair<unsigned long, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, int *>, std::__1::less<std::__1::basic_string<char> >, true> >="__value_"Q}}}"uintMap"{map<std::__1::basic_string<char>, unsigned int *, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, unsigned int *> > >="__tree_"{__tree<std::__1::__value_type<std::__1::basic_string<char>, unsigned int *>, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, unsigned int *>, std::__1::less<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__value_type<std::__1::basic_string<char>, unsigned int *> > >="__begin_node_"^{__tree_end_node<std::__1::__tree_node_base<void *> *>}"__pair1_"{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<std::__1::basic_string<char>, unsigned int *>, void *> > >="__value_"{__tree_end_node<std::__1::__tree_node_base<void *> *>="__left_"^{__tree_node_base<void *>}}}"__pair3_"{__compressed_pair<unsigned long, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, unsigned int *>, std::__1::less<std::__1::basic_string<char> >, true> >="__value_"Q}}}"int64Map"{map<std::__1::basic_string<char>, long long *, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, long long *> > >="__tree_"{__tree<std::__1::__value_type<std::__1::basic_string<char>, long long *>, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, long long *>, std::__1::less<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__value_type<std::__1::basic_string<char>, long long *> > >="__begin_node_"^{__tree_end_node<std::__1::__tree_node_base<void *> *>}"__pair1_"{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<std::__1::basic_string<char>, long long *>, void *> > >="__value_"{__tree_end_node<std::__1::__tree_node_base<void *> *>="__left_"^{__tree_node_base<void *>}}}"__pair3_"{__compressed_pair<unsigned long, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, long long *>, std::__1::less<std::__1::basic_string<char> >, true> >="__value_"Q}}}"floatMap"{map<std::__1::basic_string<char>, float *, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, float *> > >="__tree_"{__tree<std::__1::__value_type<std::__1::basic_string<char>, float *>, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, float *>, std::__1::less<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__value_type<std::__1::basic_string<char>, float *> > >="__begin_node_"^{__tree_end_node<std::__1::__tree_node_base<void *> *>}"__pair1_"{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<std::__1::basic_string<char>, float *>, void *> > >="__value_"{__tree_end_node<std::__1::__tree_node_base<void *> *>="__left_"^{__tree_node_base<void *>}}}"__pair3_"{__compressed_pair<unsigned long, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, float *>, std::__1::less<std::__1::basic_string<char> >, true> >="__value_"Q}}}"doubleMap"{map<std::__1::basic_string<char>, double *, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, double *> > >="__tree_"{__tree<std::__1::__value_type<std::__1::basic_string<char>, double *>, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, double *>, std::__1::less<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__value_type<std::__1::basic_string<char>, double *> > >="__begin_node_"^{__tree_end_node<std::__1::__tree_node_base<void *> *>}"__pair1_"{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<std::__1::basic_string<char>, double *>, void *> > >="__value_"{__tree_end_node<std::__1::__tree_node_base<void *> *>="__left_"^{__tree_node_base<void *>}}}"__pair3_"{__compressed_pair<unsigned long, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, double *>, std::__1::less<std::__1::basic_string<char> >, true> >="__value_"Q}}}"stringMap"{map<std::__1::basic_string<char>, std::__1::basic_string<char> *, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, std::__1::basic_string<char> *> > >="__tree_"{__tree<std::__1::__value_type<std::__1::basic_string<char>, std::__1::basic_string<char> *>, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, std::__1::basic_string<char> *>, std::__1::less<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__value_type<std::__1::basic_string<char>, std::__1::basic_string<char> *> > >="__begin_node_"^{__tree_end_node<std::__1::__tree_node_base<void *> *>}"__pair1_"{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<std::__1::basic_string<char>, std::__1::basic_string<char> *>, void *> > >="__value_"{__tree_end_node<std::__1::__tree_node_base<void *> *>="__left_"^{__tree_node_base<void *>}}}"__pair3_"{__compressed_pair<unsigned long, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, std::__1::basic_string<char> *>, std::__1::less<std::__1::basic_string<char> >, true> >="__value_"Q}}}"stringVecMap"{map<std::__1::basic_string<char>, std::__1::vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > > *, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, std::__1::vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > > *> > >="__tree_"{__tree<std::__1::__value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > > *>, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > > *>, std::__1::less<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > > *> > >="__begin_node_"^{__tree_end_node<std::__1::__tree_node_base<void *> *>}"__pair1_"{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > > *>, void *> > >="__value_"{__tree_end_node<std::__1::__tree_node_base<void *> *>="__left_"^{__tree_node_base<void *>}}}"__pair3_"{__compressed_pair<unsigned long, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > > *>, std::__1::less<std::__1::basic_string<char> >, true> >="__value_"Q}}}"stringPairVecMap"{map<std::__1::basic_string<char>, std::__1::vector<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> > > > *, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, std::__1::vector<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> > > > *> > >="__tree_"{__tree<std::__1::__value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> > > > *>, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> > > > *>, std::__1::less<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> > > > *> > >="__begin_node_"^{__tree_end_node<std::__1::__tree_node_base<void *> *>}"__pair1_"{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> > > > *>, void *> > >="__value_"{__tree_end_node<std::__1::__tree_node_base<void *> *>="__left_"^{__tree_node_base<void *>}}}"__pair3_"{__compressed_pair<unsigned long, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, std::__1::vector<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char>, std::__1::basic_string<char> > > > *>, std::__1::less<std::__1::basic_string<char> >, true> >="__value_"Q}}}"paramMinVersionMap"{map<std::__1::basic_string<char>, quasar::SystemConfig::Version, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, quasar::SystemConfig::Version> > >="__tree_"{__tree<std::__1::__value_type<std::__1::basic_string<char>, quasar::SystemConfig::Version>, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, quasar::SystemConfig::Version>, std::__1::less<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__value_type<std::__1::basic_string<char>, quasar::SystemConfig::Version> > >="__begin_node_"^{__tree_end_node<std::__1::__tree_node_base<void *> *>}"__pair1_"{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<std::__1::basic_string<char>, quasar::SystemConfig::Version>, void *> > >="__value_"{__tree_end_node<std::__1::__tree_node_base<void *> *>="__left_"^{__tree_node_base<void *>}}}"__pair3_"{__compressed_pair<unsigned long, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, quasar::SystemConfig::Version>, std::__1::less<std::__1::basic_string<char> >, true> >="__value_"Q}}}"paramMaxVersionMap"{map<std::__1::basic_string<char>, quasar::SystemConfig::Version, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, quasar::SystemConfig::Version> > >="__tree_"{__tree<std::__1::__value_type<std::__1::basic_string<char>, quasar::SystemConfig::Version>, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, quasar::SystemConfig::Version>, std::__1::less<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__value_type<std::__1::basic_string<char>, quasar::SystemConfig::Version> > >="__begin_node_"^{__tree_end_node<std::__1::__tree_node_base<void *> *>}"__pair1_"{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<std::__1::basic_string<char>, quasar::SystemConfig::Version>, void *> > >="__value_"{__tree_end_node<std::__1::__tree_node_base<void *> *>="__left_"^{__tree_node_base<void *>}}}"__pair3_"{__compressed_pair<unsigned long, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, quasar::SystemConfig::Version>, std::__1::less<std::__1::basic_string<char> >, true> >="__value_"Q}}}"requiredParams"{map<std::__1::basic_string<char>, std::__1::set<std::__1::basic_string<char>, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::basic_string<char> > >, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, std::__1::set<std::__1::basic_string<char>, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::basic_string<char> > > > > >="__tree_"{__tree<std::__1::__value_type<std::__1::basic_string<char>, std::__1::set<std::__1::basic_string<char>, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::basic_string<char> > > >, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, std::__1::set<std::__1::basic_string<char>, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::basic_string<char> > > >, std::__1::less<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__value_type<std::__1::basic_string<char>, std::__1::set<std::__1::basic_string<char>, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::basic_string<char> > > > > >="__begin_node_"^{__tree_end_node<std::__1::__tree_node_base<void *> *>}"__pair1_"{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<std::__1::basic_string<char>, std::__1::set<std::__1::basic_string<char>, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::basic_string<char> > > >, void *> > >="__value_"{__tree_end_node<std::__1::__tree_node_base<void *> *>="__left_"^{__tree_node_base<void *>}}}"__pair3_"{__compressed_pair<unsigned long, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, std::__1::set<std::__1::basic_string<char>, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::basic_string<char> > > >, std::__1::less<std::__1::basic_string<char> >, true> >="__value_"Q}}}"state"i"configType"i}
@"<EARPSRAudioProcessorDelegate>"
@24@0:8^{EARCSpeechRecognitionResultStream=^v^?^?^?^?^?}16
{EARCSpeechRecognitionResultStream="ctx"^v"DisposeContext"^?"DidRecognizePartialResultTokens"^?"DidFinishRecognitionWithError"^?"DidRecognizeFinalResults"^?"DidProcessAudioDuration"^?}
@24@0:8r^{shared_ptr<quasar::RecogAudioBuffer>=^{RecogAudioBuffer}^{__shared_weak_count}}16
{shared_ptr<quasar::RecogAudioBuffer>="__ptr_"^{RecogAudioBuffer}"__cntrl_"^{__shared_weak_count}}
@36@0:8@16f24B28B32
v32@0:8@16@?24
v48@0:8@16@24@32@?40
{vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > >=^{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >}^{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >}{__compressed_pair<std::__1::basic_string<char> *, std::__1::allocator<std::__1::basic_string<char> > >=^{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >}}}24@0:8@16
v64@0:8{vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > >=^{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >}^{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >}{__compressed_pair<std::__1::basic_string<char> *, std::__1::allocator<std::__1::basic_string<char> > >=^{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >}}}16@40@48@?56
{shared_ptr<quasar::TranslatorFactory>="__ptr_"^{TranslatorFactory}"__cntrl_"^{__shared_weak_count}}
v28@0:8@16f24
{vector<std::__1::pair<id<_EARLanguageModelDataSource>, float>, std::__1::allocator<std::__1::pair<id<_EARLanguageModelDataSource>, float> > >="__begin_"^{pair<id<_EARLanguageModelDataSource>, float>}"__end_"^{pair<id<_EARLanguageModelDataSource>, float>}"__end_cap_"{__compressed_pair<std::__1::pair<id<_EARLanguageModelDataSource>, float> *, std::__1::allocator<std::__1::pair<id<_EARLanguageModelDataSource>, float> > >="__value_"^{pair<id<_EARLanguageModelDataSource>, float>}}}
{vector<quasar::Token, std::__1::allocator<quasar::Token> >=^{Token}^{Token}{__compressed_pair<quasar::Token *, std::__1::allocator<quasar::Token> >=^{Token}}}24@0:8@16
{vector<quasar::Token, std::__1::allocator<quasar::Token> >=^{Token}^{Token}{__compressed_pair<quasar::Token *, std::__1::allocator<quasar::Token> >=^{Token}}}24@0:8r^{vector<quasar::Token, std::__1::allocator<quasar::Token> >=^{Token}^{Token}{__compressed_pair<quasar::Token *, std::__1::allocator<quasar::Token> >=^{Token}}}16
{vector<quasar::Token, std::__1::allocator<quasar::Token> >=^{Token}^{Token}{__compressed_pair<quasar::Token *, std::__1::allocator<quasar::Token> >=^{Token}}}32@0:8r^{vector<quasar::Token, std::__1::allocator<quasar::Token> >=^{Token}^{Token}{__compressed_pair<quasar::Token *, std::__1::allocator<quasar::Token> >=^{Token}}}16@24
{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}24@0:8r^{vector<quasar::Token, std::__1::allocator<quasar::Token> >=^{Token}^{Token}{__compressed_pair<quasar::Token *, std::__1::allocator<quasar::Token> >=^{Token}}}16
{unique_ptr<SpeechITN, std::__1::default_delete<SpeechITN> >="__ptr_"{__compressed_pair<SpeechITN *, std::__1::default_delete<SpeechITN> >="__value_"^{SpeechITN}}}
@48@0:8@16@24f32B36@40
@56@0:8d16d24d32d40d48
@32@0:8@16Q24
v32@0:8@16Q24
{shared_ptr<quasar::SilencePosteriorGenerator>="__ptr_"^{SilencePosteriorGenerator}"__cntrl_"^{__shared_weak_count}}
@"<EARCaesuraSilencePosteriorGeneratorDelegate>"
@"_EARLanguageDetectorRequestContext"
{vector<std::__1::optional<quasar::Locale>, std::__1::allocator<std::__1::optional<quasar::Locale> > >=^{optional<quasar::Locale>}^{optional<quasar::Locale>}{__compressed_pair<std::__1::optional<quasar::Locale> *, std::__1::allocator<std::__1::optional<quasar::Locale> > >=^{optional<quasar::Locale>}}}24@0:8@16
{shared_ptr<const quasar::LDContext>=^{LDContext}^{__shared_weak_count}}32@0:8r^{LDContext={map<quasar::Locale, double, std::__1::less<quasar::Locale>, std::__1::allocator<std::__1::pair<const quasar::Locale, double> > >={__tree<std::__1::__value_type<quasar::Locale, double>, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true>, std::__1::allocator<std::__1::__value_type<quasar::Locale, double> > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<quasar::Locale, double>, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true> >=Q}}}{optional<std::__1::set<quasar::Locale, std::__1::less<quasar::Locale>, std::__1::allocator<quasar::Locale> > >=(?=c{set<quasar::Locale, std::__1::less<quasar::Locale>, std::__1::allocator<quasar::Locale> >={__tree<quasar::Locale, std::__1::less<quasar::Locale>, std::__1::allocator<quasar::Locale> >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<quasar::Locale, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::less<quasar::Locale> >=Q}}})B}{optional<quasar::Locale>=(?=c{Locale={basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}})B}{optional<bool>=(?=cB)B}{optional<std::__1::vector<quasar::Locale, std::__1::allocator<quasar::Locale> > >=(?=c{vector<quasar::Locale, std::__1::allocator<quasar::Locale> >=^{Locale}^{Locale}{__compressed_pair<quasar::Locale *, std::__1::allocator<quasar::Locale> >=^{Locale}}})B}{optional<std::__1::map<quasar::Locale, double, std::__1::less<quasar::Locale>, std::__1::allocator<std::__1::pair<const quasar::Locale, double> > > >=(?=c{map<quasar::Locale, double, std::__1::less<quasar::Locale>, std::__1::allocator<std::__1::pair<const quasar::Locale, double> > >={__tree<std::__1::__value_type<quasar::Locale, double>, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true>, std::__1::allocator<std::__1::__value_type<quasar::Locale, double> > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<quasar::Locale, double>, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true> >=Q}}})B}{optional<std::__1::map<quasar::Locale, double, std::__1::less<quasar::Locale>, std::__1::allocator<std::__1::pair<const quasar::Locale, double> > > >=(?=c{map<quasar::Locale, double, std::__1::less<quasar::Locale>, std::__1::allocator<std::__1::pair<const quasar::Locale, double> > >={__tree<std::__1::__value_type<quasar::Locale, double>, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true>, std::__1::allocator<std::__1::__value_type<quasar::Locale, double> > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<quasar::Locale, double>, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true> >=Q}}})B}{optional<quasar::Locale>=(?=c{Locale={basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}})B}{optional<quasar::Locale>=(?=c{Locale={basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}})B}{optional<std::__1::map<quasar::Locale, double, std::__1::less<quasar::Locale>, std::__1::allocator<std::__1::pair<const quasar::Locale, double> > > >=(?=c{map<quasar::Locale, double, std::__1::less<quasar::Locale>, std::__1::allocator<std::__1::pair<const quasar::Locale, double> > >={__tree<std::__1::__value_type<quasar::Locale, double>, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true>, std::__1::allocator<std::__1::__value_type<quasar::Locale, double> > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<quasar::Locale, double>, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<quasar::Locale, std::__1::__value_type<quasar::Locale, double>, std::__1::less<quasar::Locale>, true> >=Q}}})B}}16r^{vector<std::__1::optional<quasar::Locale>, std::__1::allocator<std::__1::optional<quasar::Locale> > >=^{optional<quasar::Locale>}^{optional<quasar::Locale>}{__compressed_pair<std::__1::optional<quasar::Locale> *, std::__1::allocator<std::__1::optional<quasar::Locale> > >=^{optional<quasar::Locale>}}}24
@40@0:8Q16@24@32
{unique_ptr<quasar::LanguageDetector, std::__1::default_delete<quasar::LanguageDetector> >="__ptr_"{__compressed_pair<quasar::LanguageDetector *, std::__1::default_delete<quasar::LanguageDetector> >="__value_"^{LanguageDetector}}}
@24@0:8r^{CommandTagging={map<std::__1::basic_string<char>, std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> >, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> > > > >={__tree<std::__1::__value_type<std::__1::basic_string<char>, std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> > >, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> > >, std::__1::less<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__value_type<std::__1::basic_string<char>, std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> > > > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<std::__1::basic_string<char>, std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> > >, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, std::__1::vector<quasar::Token, std::__1::allocator<quasar::Token> > >, std::__1::less<std::__1::basic_string<char> >, true> >=Q}}}{vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > >=^{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >}^{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >}{__compressed_pair<std::__1::basic_string<char> *, std::__1::allocator<std::__1::basic_string<char> > >=^{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >}}}{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}}16
{unique_ptr<quasar::CommandTagging, std::__1::default_delete<quasar::CommandTagging> >="__ptr_"{__compressed_pair<quasar::CommandTagging *, std::__1::default_delete<quasar::CommandTagging> >="__value_"^{CommandTagging}}}
@32@0:8@16q24
@24@0:8q16
{unique_ptr<quasar::CommandTagger, std::__1::default_delete<quasar::CommandTagger> >="__ptr_"{__compressed_pair<quasar::CommandTagger *, std::__1::default_delete<quasar::CommandTagger> >="__value_"^{CommandTagger}}}
