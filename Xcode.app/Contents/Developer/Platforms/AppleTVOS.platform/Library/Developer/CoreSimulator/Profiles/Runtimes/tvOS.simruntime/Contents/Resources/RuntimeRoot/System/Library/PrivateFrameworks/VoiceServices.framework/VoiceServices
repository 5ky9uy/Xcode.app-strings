_bundleIdentifier
_compatibilityVersion
_contentVersion
_masteredVersion
_downloadSize
_isPurgeable
supportsSecureCoding
TB,R
bundleIdentifier
T@"NSString",C,N,V_bundleIdentifier
compatibilityVersion
T@"NSNumber",C,N,V_compatibilityVersion
contentVersion
T@"NSNumber",C,N,V_contentVersion
masteredVersion
T@"NSString",C,N,V_masteredVersion
downloadSize
T@"NSNumber",C,N,V_downloadSize
isPurgeable
TB,N,V_isPurgeable
_utterance
_voiceAssetKey
_voiceResourceAssetKey
_audioOutputRoute
_clientBundleIdentifier
_experimentIdentifier
_promptCount
_sourceOfTTS
_errorCode
_requestCreatedTimestamp
_synthesisBeginTimestamp
_synthesisEndTimestamp
_speechBeginTimestamp
_speechEndTimestamp
_audioStartTimestampDiffs
_audioDuration
_isWarmStart
_isCacheHitFromDisk
_isCacheHitFromMemory
_isSpeechRequest
_canUseServerTTS
_isServerTTS
_isServerStreamTTS
_isServerTimeout
_isServerTTSRacing
_neuralAlignmentStall
v8@?0
character_count
voice_asset_key
voice_resource_asset_key
is_warm_start
tts_synthesis_latency
tts_total_latency
audio_queue_latency
audio_duration
is_speech_request
synthesis_to_speech_time_gap
is_synthesis_cached
prompt_count
source_of_tts
audio_output_route
error_code
client_bundle_identifier
experiment_identifier
is_server_tts
is_server_stream_tts
is_server_timeout
can_use_server_tts
is_server_tts_racing
real_time_factor
neural_alignment_stall
utterance
T@"NSString",C,V_utterance
voiceAssetKey
T@"NSString",C,V_voiceAssetKey
voiceResourceAssetKey
T@"NSString",C,V_voiceResourceAssetKey
audioOutputRoute
T@"NSString",C,V_audioOutputRoute
clientBundleIdentifier
T@"NSString",C,V_clientBundleIdentifier
experimentIdentifier
T@"NSString",C,V_experimentIdentifier
requestCreatedTimestamp
Tq,V_requestCreatedTimestamp
eagerRequestCreatedTimeStampDiffs
Tq,V_eagerRequestCreatedTimeStampDiffs
synthesisBeginTimestamp
Tq,V_synthesisBeginTimestamp
synthesisEndTimestamp
Tq,V_synthesisEndTimestamp
speechBeginTimestamp
Tq,V_speechBeginTimestamp
speechEndTimestamp
Tq,V_speechEndTimestamp
audioStartTimestampDiffs
Tq,V_audioStartTimestampDiffs
audioDuration
Td,V_audioDuration
isWarmStart
TB,V_isWarmStart
isServerTTS
TB,V_isServerTTS
isServerStreamTTS
TB,V_isServerStreamTTS
isServerTimeout
TB,V_isServerTimeout
isServerTTSRacing
TB,V_isServerTTSRacing
canUseServerTTS
TB,V_canUseServerTTS
neuralAlignmentStall
TB,V_neuralAlignmentStall
promptCount
Tq,V_promptCount
errorCode
Tq,V_errorCode
sourceOfTTS
Tq,V_sourceOfTTS
isSpeechRequest
TB,V_isSpeechRequest
isCacheHitFromDisk
TB,V_isCacheHitFromDisk
isCacheHitFromMemory
TB,V_isCacheHitFromMemory
VSMobileAssetServiceErrorDomain
MobileAssetProperties
com.apple.MobileAsset.VoiceServicesVocalizerVoice
com.apple.MobileAsset.VoiceServices.CustomVoice
com.apple.MobileAsset.VoiceServices.GryphonVoice
com.apple.MobileAsset.VoiceServices.VoiceResources
Name
Languages
LanguagesCompatibility
Language
Gender
Footprint
Type
TTSResources/PreinstallAssets/
/private/var/mobile/Library/VoiceServices/voices/
%@.tmp
VSMobileAssetsManager.m
negative size
voiceData
T@"VSVoiceAsset",&,V_voiceData
asset
T@"MAAsset",&,V_asset
builtInVoicePath
T@"NSString",&,V_builtInVoicePath
voicePath
T@"NSString",&,N,V_voicePath
v16@?0q8
com.apple.voiced.assetQueryQueue
com.apple.voiceservices
preinstall_metadata.plist
_RelativePath
AssetData
Assets
q24@?0@"MAAsset"8@"MAAsset"16
en-US
VSMobileAssetManager
Cleaning voice assets is disabled in internal setting.
v24@?0@"NSMutableArray"8q16
%@_%@_%@_%@
B24@?0@"MAAsset"8@"NSDictionary"16
v20@?0d8f16
v16@?0@"NSError"8
Unable to cancel an asset download: %@
Unable to download catalog
v16@?0@"MAProgressNotification"8
Unable to download asset
discretionary
immediate
Asset is in an unknown state
q24@?0@"VSVoiceAssetSelection"8@"VSVoiceAssetSelection"16
%@_%@
Info.plist
CFBundleIdentifier
@"NSString"8@?0
local_voice
assetQueryQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_assetQueryQueue
cachedVoiceSelections
T@"NSCache",&,N,V_cachedVoiceSelections
cachedVoiceResources
T@"NSCache",&,N,V_cachedVoiceResources
_default
VSRecognition
<VSRecognition: %p model=%@>
recognition is already active
recognition reuse attempted
error converting disambiguation context to server
error converting audio input path to server
error converting model identifier
connection failure
recognition request denied
couldn't establish connection
recognition cancelled
connection lost
com.apple.voiceserviceslogging
default
event
enableAudioDump
logSensitiveText
DisableCaching
DisableAssetCleaning
EnableLocalVoices
whisper
ServerTTSTimeout
defaultVolume
forceServerTTS
disableServerTTS
disableDeviceRacing
disableOsprey
forceOsprey
disableOspreyStreaming
StreamBufferDuration
useBetaVoice
ospreyEndpointURL
simulateNetworkStall
disableDeviceNeuralTTS
useSSMLInput
disableMobileAssetURLReset
ignoreThermalState
isInternalBuild
TB,N,V_isInternalBuild
internalDefaults
T@"NSUserDefaults",&,N,V_internalDefaults
internalBuild
TB,R,N,V_internalBuild
TB,N
disableCache
disableAssetCleaning
enableLocalVoices
Tf,N
serverTTSTimeout
streamBufferDuration
T@"NSString",C,N
TB,R,N
ignorePowerAndThermalState
tts_languages
plist
tts_language_fallbacks
_VSServerConnection
com.apple.voiced
%@:%@:%@
allowing_cellular
download_size
download_duration
download_progress
voiceDownloadKey
T@"NSString",R,V_voiceDownloadKey
downloadBeginTimestamp
Tq,R,V_downloadBeginTimestamp
downloadEndTimestamp
Tq,R,V_downloadEndTimestamp
isCellularAllowed
TB,V_isCellularAllowed
TB,V_discretionary
T@"NSNumber",C,V_downloadSize
downloadProgress
Tf,V_downloadProgress
note.server.died
note.recog.prepare
note.recog.start
note.recog.results
note.recog.cancel
note.recog.error
key.recog.results
key.recog.errordesc
key.recog.errorcode
VSErrorDomain
vsplist
yyyy-MM-dd-HH-mm-ss'.vslog'
Library
Logs
CrashReporter
VoiceServicesRecognition
Latest.vslog
HH-mm-ss-
MaxLogCount
q24@?0@"NSURL"8@"NSURL"16
classes
phrases
modelid
handler
) <%@>
VSRecognitionResult
%@:%@
seqtag
known
knownp
ambig
ambigp
VSRecognitionDisambiguationContext
<VSRecognitionDisambiguationContext %p [%@]> 
 will disambiguate with sequence tag %@
 known class values:
constrained ambiguous classes:
  %@ = "%@" (%@)
  %@ = "%@"
  %@ =
     "%@" (%@)
     "%@"
com.apple.voiceservices.kwidxchanged
top-level
class-kws
__model-kws
s5l8942x
s5l8947x
s7002
t8002
HardwarePlatform
DeviceClassNumber
+N9mZUAHooNvMiQnjeTJ8g
eJGhnVvylF3dMOHBKJzeiw
InternalBuild
com.apple.voiceservices.logging
VSLogLevel
VSOutputLevel
com.apple.voiceservices.language
lang-id
%@Library/Managed Preferences/mobile/%@.plist
mobile
com.apple.AppSupport.loggingDefaultsChanged
%@-%@
en-GB
zh-HK
zh-TW
RecognitionResources/Express
TTSResources
language_fallbacks.plist
zh-Hans
zh-CN
com.apple.language.changed
range
\audio=
\audio="%@"\
\mrk=%@=%@\
.wav
\\pause=['"]?([0-9]+)['"]?\\
<break time=['"]([0-9]+)ms['"]\s*/>
\\toi=lhp\\([^
'(?:[^'\\]|\\.)*'
"(?:[^"\\]|\\.)*"
(?:%@|%@)
\w+=%@
<phoneme\s+(%@)\s+(%@)\s*/>
alphabet=
\\toi=\w+\\.*?
\\toi=orth\\
\\toi=\w+\\.*
<phoneme.*?/>
\\\w+=.+?\\
</?.*?>
\toi=lhp\
\toi=orth\
\tn=normal\
\tn=
<speak>
speak
<phoneme alphabet="lhp" ph="
phoneme
"></phoneme>
SSML error
unbalanced phoneme tag
say-as
</say-as>
unbalanced say-as tag
Error in tn override tag, ignore
<say-as interpret-as="%@">
</%@>
com.apple.voiceservices.assetInstalled
common
Library/VoiceServices/Assets
FormatVersion
/System/Library/PrivateFrameworks/VoiceServices.framework/
.migrated
NotForSiri
voice_format_version.plist
broker.hdr
broker.hdr.tmp
broker.hdr.asset
Tones
%@%@
.tmp
word_timings
TTSWordTimings
female
male
wordTimings
T@"NSDictionary",&,N,V_wordTimings
hash
TQ,R
superclass
T#,R
description
T@"NSString",R,C
debugDescription
VSRecognitionSessionKeywordsDidChangeNotification
action already in progress
session is finished or invalid
session is invalid or not finished
session is already speaking
VSSpeechServiceDecoderErrorDomain
@"AVAudioBuffer"20@?0I8^q12
opusDataHandler
T@?,C,N,V_opusDataHandler
errorHandler
T@?,C,N,V_errorHandler
fromFormat
T@"AVAudioFormat",&,N,V_fromFormat
toFormat
T@"AVAudioFormat",&,N,V_toFormat
converter
T@"AVAudioConverter",&,N,V_converter
outputBuffer
T@"AVAudioCompressedBuffer",&,N,V_outputBuffer
opusDataOffset
Tq,N,V_opusDataOffset
v32@?0@"NSData"8Q16^B24
Failed to create opus decoder
i32@?0^I8^{AudioBufferList=I[1{AudioBuffer=II^v}]}16^^{AudioStreamPacketDescription}24
decoder gave us %d bytes bytes but we really only expected %d
Could not finish decoding, res %@
<private>
recognition action not implemented
VOICE_SERVICES_OOB_SIRI_INTRO
VOICE_SERVICES_OOB_TRY_SAY_0
VOICE_SERVICES_OOB_SIRI_CAPABILITIES
VOICE_SERVICES_OOB_SIRI_CAPABILITY_HOME
VOICE_SERVICES_OOB_SIRI_CAPABILITY_NEWS
VOICE_SERVICES_OOB_SIRI_CAPABILITY_WEATHER
VOICE_SERVICES_OOB_SIRI_CAPABILITY_CLOCK
VOICE_SERVICES_OOB_SIRI_CAPABILITY_MUSIC
VOICE_SERVICES_OOB_TRY_SAY_1
VOICE_SERVICES_OOB_HEY_SIRI_CAPABILITIES
VOICE_SERVICES_OOB_HEY_SIRI_HOME
VOICE_SERVICES_OOB_HEY_SIRI_NEWS
VOICE_SERVICES_OOB_HEY_SIRI_WEATHER
VOICE_SERVICES_OOB_HEY_SIRI_WEATHER_2
VOICE_SERVICES_OOB_HEY_SIRI_MUSIC
VOICE_SERVICES_OOB_HEY_SIRI_CLOCK
VOICE_SERVICES_OOB_HEY_SIRI_CLOCK_PLANK_TIMER
VOICE_SERVICES_NETWORK_STALL
strings
%@_%d
Interstitials
DeviceSetup
VSSpeechLangCharset
CharacterBinaryMaps
characterSet
T@"NSCharacterSet",&,N,V_characterSet
could not create recognition instance
recognition already attempted or in progress
com.apple.voiceservices.metrics
com.apple.voiceservices.download
@"NSDictionary"8@?0
voice_configs.plist
vocalizer_resource_order
vocalizer_resources
_voices
server_voices
legacy
premiumhigh
VoiceServices-Config.plist
voice_speech_rate
voice_speech_pitch
voice_speech_volume
VoiceResource: %@_CV%@
_languages
_searchPathURL
voiceConfig
T@"NSDictionary",C,N,V_voiceConfig
rate
Tf,N,V_rate
pitch
Tf,N,V_pitch
volume
Tf,N,V_volume
vocalizerConfig
T@"NSDictionary",&,N,V_vocalizerConfig
languages
T@"NSArray",C,N,V_languages
resourceList
T@"NSArray",C,N,V_resourceList
resourceMimeTypes
T@"NSDictionary",C,N,V_resourceMimeTypes
searchPathURL
T@"NSURL",C,N,V_searchPathURL
_startTime
_textRange
startTime
Td,N,V_startTime
textRange
T{_NSRange=QQ},N,V_textRange
model <%@> class <%@>
com.apple.yn
0x%x
no URL to launch
{AudioStreamBasicDescription=dIIIIIIII}
_audioData
_text
_identifier
_audioSessionID
_enqueue
%@%@kHz
Opus
PCM%@KHz
sessionId %u, clientId %@, %@ bytes, input format %@, output format %@, requestCreatedTime %@, text '%@', identifier: %@
T@"NSString",C,N,V_clientBundleIdentifier
pcmDataSize
TQ,N,V_pcmDataSize
stopHandler
T@?,C,N,V_stopHandler
audioSessionID
TI,N,V_audioSessionID
audioData
T@"NSData",R,C,N,V_audioData
decoderStreamDescription
T{AudioStreamBasicDescription=dIIIIIIII},R,N,V_decoderStreamDescription
playerStreamDescription
T{AudioStreamBasicDescription=dIIIIIIII},R,N,V_playerStreamDescription
enqueue
TB,N,V_enqueue
text
T@"NSString",&,N,V_text
identifier
T@"NSString",&,N,V_identifier
TQ,N,V_requestCreatedTimestamp
match
replace
case-sensitive
eat-punct
com.apple.voiceservices.class
title
name
text:'%@', language:%@, type:%@, gender:%@, footprint:%@, rate:%.2f, pitch:%.2f, volume:%.2f, canUseServerTTS:%d, shouldCache:%d, contextInfo:%@, customResourceURLs: %@, startTime: %llu
textForAttributes
attributes
_languageCode
_voiceName
_footprint
_voiceType
_gender
_outputPath
_rate
_pitch
_volume
_shouldCache
_disableCompactVoiceFallback
_forceServerTTS
_retryDeviceOnNetworkStall
_resourceListURL
_resourceSearchPathURL
_customResourceURLs
_contextInfo
_pointer
%@%@: %@
v32@?0@8@16^B24
attributedText
T@"NSAttributedString",C,N,V_attributedText
T@"NSString",C,N,V_utterance
pauseHandler
T@?,C,N,V_pauseHandler
pointer
Tq,N,V_pointer
voiceName
T@"NSString",C,N,V_voiceName
T@"NSString",C,N,V_text
languageCode
T@"NSString",C,N,V_languageCode
footprint
Tq,N,V_footprint
voiceType
Tq,N,V_voiceType
gender
Tq,N,V_gender
outputPath
T@"NSURL",C,N,V_outputPath
shouldCache
TB,N,V_shouldCache
Td,N,V_rate
Td,N,V_pitch
Td,N,V_volume
contextInfo
T@"NSDictionary",C,N,V_contextInfo
disableCompactVoiceFallback
TB,N,V_disableCompactVoiceFallback
TB,N,V_forceServerTTS
TB,N,V_canUseServerTTS
retryDeviceOnNetworkStall
TB,N,V_retryDeviceOnNetworkStall
resourceListURL
T@"NSURL",C,N,V_resourceListURL
resourceSearchPathURL
T@"NSURL",C,N,V_resourceSearchPathURL
customResourceURLs
T@"NSArray",&,N,V_customResourceURLs
VSMappedData%p
filePath
T@"NSString",&,N,V_filePath
totalLength
TQ,N,V_totalLength
mmappedData
T^v,N,V_mmappedData
mappedLength
TQ,N,V_mappedLength
fallbackInMemoryData
T@"NSMutableData",&,N,V_fallbackInMemoryData
shouldCleanFile
TB,N,V_shouldCleanFile
%02x
%@ %ld
com.apple.voiceservices.keepalive
com.apple.voiceservices.tts
VoiceServicesErrorDomain
completion
T@?,C,N,V_completion
nil request
language is not set
input text is not set
audio data is invalid
v16@?0@"VSVoiceResourceAsset"8
%@_%@_legacy.caf
%@_%@.caf
v12@?0B8
VSSpeechSynthesizer
VSSpeechSynthesizerCallbackThread
language_fallbacks
VSSpeechSynthesizer_%p@%@_%d
nil languageCode
stop presynthesized request timeout
stop request timeout
pause request timeout
Either identifier or audio information must be non-nil
Missing text of this request
ar-SA
da-DK
it-IT
ja-JP
nb-NO
nl-NL
ru-RU
sv-SE
%@:%d
generic
-[VSSpeechSynthesizer estimateDurationOfRequest:completion:]_block_invoke
v24@?0d8@"NSError"16
-[VSSpeechSynthesizer connection:speechRequest:didStopAtEnd:phonemesSpoken:error:]_block_invoke
-[VSSpeechSynthesizer connection:synthesisRequest:didFinishWithInstrumentMetrics:error:]_block_invoke
language
T@"NSString",C,N,V_language
durationRequests
T@"NSMutableDictionary",&,N,V_durationRequests
delegate
T@"<VSSpeechSynthesizerDelegate>",W,N,V_delegate
voice
T@"NSString",&,N,V_voice
autoDownloadedAssets
Auto Downloaded Assets
lastTTSRequestDate
deviceID
allowCellularVoiceUpdate
com.apple.AssistantServices
defaults
T@"NSUserDefaults",&,N,V_defaults
T@"NSDate",&,N
deviceUUID
T@"NSString",R,N
audioType
Tq,N,V_audioType
active
TB,N,V_active
keepAudioSessionActive
TB,N,V_keepAudioSessionActive
com.apple.voiceservices.xpcconnection
-[VSSpeechConnection _remoteObjectSync]_block_invoke
v32@?0@"NSValue"8@"VSSpeechRequest"16^B24
-[VSSpeechConnection queryPhaticCapabilityWithRequest:]_block_invoke
v16@?0@"NSArray"8
-[VSSpeechConnection isSystemSpeaking]_block_invoke
-[VSSpeechConnection isSystemSpeakingOnBehalfOfCurrentConnection]_block_invoke
-[VSSpeechConnection forwardStreamObject:]_block_invoke
xpcConnection
T@"NSXPCConnection",&,N,V_xpcConnection
delegateWrapper
T@"VSSpeechConnectionDelegateWrapper",&,N,V_delegateWrapper
threadSafeQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_threadSafeQueue
T@"<VSSpeechConnectionDelegate>",W,N,V_delegate
request
T@"VSSpeechRequest",R,N
presynthesizedAudioRequest
T@"VSPresynthesizedAudioRequest",R,N
T@"VSSpeechRequest",&,N,V_request
concurrentSynthesisRequests
T@"NSMutableDictionary",&,N,V_concurrentSynthesisRequests
T@"VSPresynthesizedAudioRequest",&,N,V_presynthesizedAudioRequest
connection
T@"VSSpeechConnection",W,N,V_connection
undefined
compact
premium
beta
vocalizer
custom
gryphon
neural
builtin
%@:%@:%@:%@:%@:%@
%@:%@:%@:%@:%@:CV%@:MV%@:Compatibility%@
Type:%@, Name: %@, Languages: %@, Gender: %@, Footprint: %@, Installed: %@, ContentVersion: %@, MasteredVersion: %@, downloadSize: %@, isBuiltIn: %@
_name
_type
_isInstalled
_isBuiltInVoice
_isVoiceReadyToUse
MasteredVersion
ContentVersion
B24@?0@8@"NSDictionary"16
unknown
T@"NSString",C,N,V_name
type
Tq,N,V_type
isInstalled
TB,N,V_isInstalled
isBuiltInVoice
TB,N,V_isBuiltInVoice
isVoiceReadyToUse
TB,N,V_isVoiceReadyToUse
v16@?0@8
_endpoint
endpoint
T@"NSXPCListenerEndpoint",&,N,V_endpoint
queue
T@"NSObject<OS_dispatch_queue>",&,N,V_queue
listener
T@"NSXPCListener",&,N,V_listener
T@?,C,N,V_handler
MbP?
@mcpl
@mcpl
@supo
@supo
@mcpl
ASAttributeCompatibilityVersion should be NSNumber, got NSString for %@
CV: %@
Compatibility: %@
#MobileAsset migrate '%@', error: %@
#MobileAsset migrate '%@', success
Found cached voice resource %@ for %@
Cached voice resource is corrupted %@
Unable to find asset for VoiceResources %@
Unable to get content of VoiceResource '%{public}@', error: %{public}@
Empty asset folder '%{public}@'
Purge corrupted asset: %{public}@
Unable to find VoiceResource for %@ after the corrupted asset is purged
#MobileAsset Missing language in voice data: %@
#MobileAsset Can't find VoiceResources for %@
#MobileAsset current in-use asset, %@
Cleaning unused voice assets.
#MobileAsset Cleaning voice assets is disabled in internal setting. Skip cleaning...
#MobileAsset Purged asset: %@
#MobileAsset Unable to clean asset: %@, error: %@
Found cached voice selection %@ for voice query key %@
#MobileAsset Search local voices for lang: %{public}@, gender: %@
#MobileAsset Built-in voice is requested.
#MobileAsset Search beta voice asset for lang: %{public}@, type: %@, gender: %@, footprint: %@
#MobileAsset Search voice asset for lang: %{public}@, type: %@, gender: %@, footprint: %@
#MobileAsset Ignore neural voice since device neural TTS is disabled.
#MobileAsset Ignore neural voice since it is not ready for use.
#MobileAsset Neural voice not found, search gryphon voice asset
#MobileAsset Gryphon voice not found, search premium custom voice asset with same gender
#MobileAsset Search voices in pre-installed location as fallback
#MobileAsset Search custom compact voice assets with same gender
#MobileAsset Search available vocalizer voice assets with same gender
#MobileAsset Fallback to built-in compact voice for lang: %{public}@
#MobileAsset Selected %{public}@
#MobileAsset Unable to amend voice that is not well defined: %@
#MobileAsset Start querying: %@
No available neural voice found, fallback to amend with gryphon voice.
#MobileAsset Unable to download voice that is not well defined: %@
#MobileAsset Enqueued downloading: %@
No available neural voice found, fallback to download gryphon voice.
#MobileAsset Can't download due to unfound asset: %@
#MobileAsset Asset is installed already: %@
#MobileAsset Enqueued download cancellation for: %@
#MobileAsset No assets results: can't cancel anything
#MobileAsset Download cancellation success count: %lu. The rest was not downloading.
#MobileAsset Download cancellation failure: %@
#MobileAsset Removing voice: %@
#MobileAsset not removed because it is not present: %@
#MobileAsset Catalog Start downloading for: %@
#MobileAsset Start downloading: %@
#MobileAsset Asset not found for %@
#MobileAsset WARNING query '%@', error: %@
#MobileAsset Catalog '%@' download error: %@
#MobileAsset err %@, unable to download asset %@
#MobileAsset Finished downloading asset %@
#MobileAsset Begin %@ download, allowing cellular %{BOOL}d: %@
#MobileAsset Asset is already downloading: %@
#MobileAsset Asset is already installed: %@
#MobileAsset Asset is in an unknown state: %@
#MobileAsset purge asset: %@
#MobileAsset purge error: %@
#MobileAsset cancel downloading asset: %@
#MobileAsset Cancel download error: %@
#MobileAsset Purge cannot find asset: %@
#MobileAsset not removed because it is required by the OS: %@
#MobileAsset Couldn't find any built-in voice for lang: %@
Unable to query local voice directory, %@
Failed to convert %ld recognition results
No cache directory from which to get the size: %@
Error getting cache path: %@, error: %@
Unable to get URL: %@, URL resources: %@
Can't remove file '%@', error: %@
Cleaned directory: '%@', LRU limit: %d, latency: %f
compact explicitly specified, look at framework asset first
Now looking for the fallback language: %@
Looking for the resources in %@
Can't find the resources anywhere!
Found the resources here: %@
No TTS resources for asset. Trying fallback language for %@
Using asset fallback language %@
Couldn't get the engine format version for language %@
VoiceEngineFormatVersions hasn't been initialized, voices may not be compatible
Trying to migrate asset because it's not valid: %@
After migrating asset, it's still not valid -- sorry
---> asset's version is %@
---> engine's version is %@
Couldn't get asset's version and/or language
Deleting the asset located here: %@ because the format versions don't match
***ERROR*** There was an error (%d - %s) when trying to symlink %s to %s
Symlinked %s to %s
Successfully appended broker header files
***ERROR*** couldn't append broker header files (%d - %s)
***ERROR*** couldn't move broker header file to final location (%d - %s)
Couldn't initialize the engine voice format versions
Unable to lock temporary asset: %s; presumably peer was first - error: %d
Temporary asset: %s has moved; presumably peer was first - error: %d
Couldn't move the temporary asset: %s to the real asset: %s - error: %d
Moved the temporary asset: %s to the real asset: %s
Couldn't get the contents of the assets directory (error %ld)
Deleting asset at url: %@
Unable to locate word '%@' in '%@'
Found prepared word timing info for text: '%@'
Invalid target asbd: %@
Could not create Opus decoder: %{public}@
Only expecting to get 1 packet at a time, not %lu
Localize for '%@' in '%@', '%@'
Unable to find '%@' localized string for key '%@', return empty string
Searching predefined string for '%@' in '%@', '%@'
Unable to find '%@' predefined string for key '%@', return default en-US string
Unable to find '%@' predefined string for key '%@', return empty string
CoreAnalytics eventName:%@ not sent. Event name must not be in current config
Successfully reportEvent with domain '%@'
Unable to load plist at '%{public}@', error: %{public}@
Unable to read voice_configs.plist
voice_configs.plist does not have key '_voices'
Out of word boundary: %ld - %ld
Failed is_neural_voice_ready: %s
Failed is_ane_model_compiled: %s
Failed compile_ane_model: %s
Enqueuing request: %@
Queue is now:
Unable to resize mapped file, errno: %d, error: %s
Unable to mmap file, errno: %d, error: %s
Unable to locate resource directory for %@
Unable to locate preview sample file for %@
#PrewarmRequest %llu from client:%@, request: %@
Stop #SpeechPresynthesizedAudioRequest %llu from client:%@, synchronously: %{BOOL}d
Stop #SpeechPresynthesizedAudioRequest from client:%@ was ignored, no request to stop
Stop #SpeechRequest %llu from client:%@, boundary: %@, synchronously: %{BOOL}d
Stop #SpeechRequest from client:%@ was ignored, no request to stop
Pause #SpeechRequest %llu from client:%@, boundary: %@, synchronously: %{BOOL}d
Pause #SpeechRequest from client:%@ was ignored, no request to pause
Start #SynthesisRequest %llu from client:%@, %@
Invalid #SpeechRequest: %@, error: %@
Start #SpeechRequest %llu from client:%@, %@
Start #PresynthesizedAudioRequest %llu: %@
Presynthesized audio request failed validation
Cache #PresynthesizedAudioRequest %llu: %@
Error Stop #SpeechRequest %@
Error Stop #PresynthesizedAudioRequest %@
Resume #SpeechRequest %llu from client:%@
Resume #SpeechRequest from client:%@ was ignored, no request to resume
#RoughEstimateDuration Request utterance: %@
#RoughEstimateDuration calculated duration: %.2f, using %@ locale, for text: %@
#EstimateDuration Request text: %@
Error %s, %@
#EstimateDuration Received duration: %.2f, for text: %@
%s, callback received in framework. %@
Current xpc connection %@ does not match %@
Delegate %@ uses deprecated callback %@
Notify daemon crash from: %@
#AudioPower Begin update
#AudioPower End update
#AutoDownloadRequest #MobileAsset, client: %@, language: %@, gender: %ld, type: %ld, footprint: %ld, name: %@
%@ is not TTS language, fallback to %@
%@ has an auto-downloading voice: %@
Closing xpc connection %p
%s, error: %@
Error updateWithConnectionIdentifier: %@
Can't prewarm %@
Error at %s , %@ 
Error estimateDurationWithRequest:reply: %@
Error %@ asking for voices
%s, Error: %@
VSAssetBase
NSSecureCoding
NSCoding
VSInstrumentMetrics
MobileAsset
VSVoiceAssetSelection
VSMobileAssetsManager
VSSpeechInternalSettings
VSSpeechSynthesizerPreference
VSDownloadMetrics
VoiceServices
VSUtilities
VSSpeechService
VSWordTimingService
VSRecognitionResultHandler
NSObject
VSRecognitionResult
VSRecognitionSession
VSRecognitionSessionKeywords
VSOpusEncoder
VSOpusDecoder
VSRecognitionAction
VSLocalizedString
VSRecognitionDisambiguateAction
VSSpeechCharacterSet
VSRecognitionRecognizeAction
VSAnalytics
VSVoiceResourceAsset
VSSpeechWordTimingInfo
VSNeuralTTSUtils
VSCacheUpdateListener
VSCacheUpdateRequest
VSRecognitionModelDataProvider
VSRecognitionConfirmAction
VS4CC
VSRecognitionURLAction
VSRecognitionSpeakAction
VSPresynthesizedAudioRequest
NSCopying
VSRecognitionResultHandlingThread
VSRecognitionResultHandlingRequest
VSTextPreProcessor
VSTextPreProcessorRule
VSSpeechAdditions
VSFormatArgument
VSSpeechRequest
VSMappedData
Hash
VSAudioPreviewDelegate
AVAudioPlayerDelegate
VSDurationRequest
VSSpeechSynthesizer
VSSpeechConnectionDelegate
VSPreferencesInterface
VSRemoteKeepAlive
VSKeepAlive
VSSpeechXPCServiceProtocol
VSSpeechServiceDelegate
VSSpeechConnection
VSSpeechConnectionDelegateWrapper
VSVoiceAsset
VSGenericUpdate
VSGenericUpdateEndpoint
NSXPCListenerDelegate
VSGenericBlockHolder
encodeObject:forKey:
encodeBool:forKey:
init
decodeObjectOfClass:forKey:
decodeBoolForKey:
supportsSecureCoding
encodeWithCoder:
initWithCoder:
bundleIdentifier
setBundleIdentifier:
compatibilityVersion
setCompatibilityVersion:
contentVersion
setContentVersion:
masteredVersion
setMasteredVersion:
downloadSize
setDownloadSize:
isPurgeable
setIsPurgeable:
.cxx_destruct
_isPurgeable
_bundleIdentifier
_compatibilityVersion
_contentVersion
_masteredVersion
_downloadSize
dictionaryMetrics
description
encodeInteger:forKey:
encodeInt64:forKey:
encodeDouble:forKey:
decodeIntegerForKey:
decodeInt64ForKey:
decodeDoubleForKey:
_clockFactor
ttsSynthesisLatency
realTimeFactor
numberWithDouble:
length
numberWithUnsignedInteger:
numberWithBool:
timeToSpeakLatency
audioQueueLatency
eagerRequestTimeGap
isSynthesisCached
numberWithInteger:
cappedRealTimeFactor
dictionaryWithObjects:forKeys:count:
utterance
setUtterance:
voiceAssetKey
setVoiceAssetKey:
voiceResourceAssetKey
setVoiceResourceAssetKey:
audioOutputRoute
setAudioOutputRoute:
clientBundleIdentifier
setClientBundleIdentifier:
experimentIdentifier
setExperimentIdentifier:
requestCreatedTimestamp
setRequestCreatedTimestamp:
eagerRequestCreatedTimeStampDiffs
setEagerRequestCreatedTimeStampDiffs:
synthesisBeginTimestamp
setSynthesisBeginTimestamp:
synthesisEndTimestamp
setSynthesisEndTimestamp:
speechBeginTimestamp
setSpeechBeginTimestamp:
speechEndTimestamp
setSpeechEndTimestamp:
audioStartTimestampDiffs
setAudioStartTimestampDiffs:
audioDuration
setAudioDuration:
isWarmStart
setIsWarmStart:
isServerTTS
setIsServerTTS:
isServerStreamTTS
setIsServerStreamTTS:
isServerTimeout
setIsServerTimeout:
isServerTTSRacing
setIsServerTTSRacing:
canUseServerTTS
setCanUseServerTTS:
neuralAlignmentStall
setNeuralAlignmentStall:
promptCount
setPromptCount:
errorCode
setErrorCode:
sourceOfTTS
setSourceOfTTS:
isSpeechRequest
setIsSpeechRequest:
isCacheHitFromDisk
setIsCacheHitFromDisk:
isCacheHitFromMemory
setIsCacheHitFromMemory:
_isWarmStart
_isServerTTS
_isServerStreamTTS
_isServerTimeout
_isServerTTSRacing
_canUseServerTTS
_neuralAlignmentStall
_isSpeechRequest
_isCacheHitFromDisk
_isCacheHitFromMemory
_utterance
_voiceAssetKey
_voiceResourceAssetKey
_audioOutputRoute
_clientBundleIdentifier
_experimentIdentifier
_requestCreatedTimestamp
_eagerRequestCreatedTimeStampDiffs
_synthesisBeginTimestamp
_synthesisEndTimestamp
_speechBeginTimestamp
_speechEndTimestamp
_audioStartTimestampDiffs
_audioDuration
_promptCount
_errorCode
_sourceOfTTS
languagesFromMobileAssetAttributes:
setLanguages:
objectForKeyedSubscript:
genderFromString:
setGender:
typeFromString:
setType:
footprintFromString:
setFootprint:
amendNameVersionAndSizeWithMobileAssetAttributes:
name
setName:
compatibilityVersionFromMobileAssetAttributes:
count
arrayWithCapacity:
countByEnumeratingWithState:objects:count:
stringByReplacingOccurrencesOfString:withString:
addObject:
arrayWithObjects:count:
integerValue
initFromMobileAssetAttributes:
voiceData
voiceKey
descriptiveKey
asset
getLocalUrl
path
languages
firstObject
stringWithFormat:
stringByAppendingPathComponent:
defaultManager
fileExistsAtPath:
attributes
currentHandler
handleFailureInMethod:object:file:lineNumber:description:
wasLocal
state
type
isVoiceReadyToUse
footprint
floatValue
voicePath
size
isInstalled
isDownloading
preferenceScore
setVoiceData:
setAsset:
builtInVoicePath
setBuiltInVoicePath:
setVoicePath:
_voiceData
_asset
_builtInVoicePath
_voicePath
migrateAssetIfNeededWithAssetType:
initWithType:
returnTypes:
downloadCatalog:options:completion:
queryMetaData:
setCountLimit:
numberWithLong:
longValue
_getVoiceAssetsForType:voicename:language:gender:footprint:returnTypes:
voiceDataFromAsset:
gender
pickCorrectAssetFromLocalAssets:
legacyLocalVocalizerVoiceAssetForLanguage:
bundleWithIdentifier:
bundlePath
preinstallAssetsDirectory
dictionaryWithContentsOfFile:
setIsInstalled:
setIsBuiltInVoice:
setIsVoiceReadyToUse:
preinstallAssetsMetadata
array
isEqualToString:
voiceAssetFromPreinstallMetadata:
preinstalledVoicesForLanguage:gender:
allKeys
_builtInVoiceForLanguage:
queryForVoiceResourceAsset:returnTypes:
_getResults:
sortUsingComparator:
lastObject
cachedVoiceResources
objectForKey:
searchPathURL
contentsOfDirectoryAtPath:error:
removeObjectForKey:
_installedVoiceResourceAssetForLanguage:
getLocalFileUrl
_purgeAsset:
voiceResourceFromAsset:
setObject:forKey:
initWithCapacity:
bundleIdentifierForVoiceType:
arrayWithObjects:
addKeyValueArray:with:
arrayWithObject:
typeStringFromType:
addKeyValuePair:with:
footprintStringFromFootprint:
genderStringFromGender:
intValue
selectVoiceResourceAssetForLanguage:
amendVoice:withDefaultSettingsFrom:
defaultVoiceType
isNeuralTTSPlatform
defaultVoiceGender
defaultVoiceFootprint
sharedManager
amendVoiceWithDefaultSettings:
defaultInstance
autoDownloadedVoicesForClientID:
selectVoiceForLang:type:gender:footprint:
_nonCacheVoiceSelectionForLanguage:type:gender:footprint:
activeVoiceAssets
installedAssetsForType:voicename:language:gender:footprint:
assetType
containsObject:
standardInstance
disableAssetCleaning
errorWithDomain:code:userInfo:
inactiveVoiceAssets
purge:
resetCache
dictionary
setObject:forKeyedSubscript:
cachedVoiceSelections
removeAllObjects
enableLocalVoices
_localVoiceForLanguage:gender:
useBetaVoice
disableDeviceNeuralTTS
selectPreinstalledVoiceForLanguage:gender:
setDiscretionary:
setRequiresPowerPluggedIn:
isVoiceAssetWellDefined:
assetQueryQueue
predicateWithBlock:
filteredArrayUsingPredicate:
getLatestAssetFromArray:
downloadOptionsWithBattery:
downloadVoiceAsset:options:progressUpdateHandler:
downloadCatalog:options:
initWithVoiceName:languageCode:gender:
mainBundle
allowsCellularAccess
setIsCellularAllowed:
discretionary
setDownloadProgress:
code
reportDownloadMetrics:
_downloadAsset:options:progress:completion:
cancelDownloads:error:
cancelDownload:
downloadVoiceResource:options:completion:
downloadVoiceResourceCatalogWithCompletion:
queryMetaDataSync
results
queryForLanguage:forType:voicename:gender:footprint:returnTypes:
isWatch
setAllowsCellularAccess:
currentRunLoop
dateWithTimeIntervalSinceNow:
runUntilDate:
startCatalogDownload:options:then:
isStalled
expectedTimeRemaining
totalExpected
totalWritten
attachProgressCallBack:
startDownload:then:
purgeSync
cancelDownloadSync
setSearchPathURL:
wasPurgeable
sortedArrayUsingComparator:
pathWithComponents:
voiceDataWithBundleIdentifier:attributes:voicePathCallback:
componentsSeparatedByString:
fileExistsAtPath:isDirectory:
typeFromBundleIdentifier:
isNeuralVoiceReady:
migrateAssets
builtInVoices
cleanUnusedVoiceAssets
cleanOldVoiceResources
resetResourcesCache
installedVoiceResources
amendVoiceAssetWithLatestKnownData:
downloadVoiceAsset:useBattery:progressUpdateHandler:
cancelDownload:completion:
cancelResourceDownload:completion:
removeVoiceAsset:completion:
downloadVoiceResource:completion:
removeVoiceResource:completion:
voiceAssetWithName:localOnly:outError:
purgeAsset:
installedLocalVoices
setAssetQueryQueue:
setCachedVoiceSelections:
setCachedVoiceResources:
_assetQueryQueue
_cachedVoiceSelections
_cachedVoiceResources
isInternalBuild
initWithSuiteName:
boolForKey:
setBool:forKey:
floatForKey:
setFloat:forKey:
stringForKey:
enableAudioDump
setEnableAudioDump:
logSensitiveText
setLogSensitiveText:
disableCache
setDisableCache:
setDisableAssetCleaning:
setEnableLocalVoices:
whisper
setWhisper:
serverTTSTimeout
setServerTTSTimeout:
defaultVolume
setDefaultVolume:
forceServerTTS
setForceServerTTS:
disableServerTTS
setDisableServerTTS:
disableDeviceRacing
setDisableDeviceRacing:
disableOsprey
setDisableOsprey:
forceOsprey
setForceOsprey:
disableOspreyStreaming
setDisableOspreyStreaming:
streamBufferDuration
setStreamBufferDuration:
setUseBetaVoice:
ospreyEndpointURL
setOspreyEndpointURL:
simulateNetworkStall
setSimulateNetworkStall:
setDisableDeviceNeuralTTS:
useSSMLInput
disableMobileAssetURLReset
ignorePowerAndThermalState
setIgnorePowerAndThermalState:
internalBuild
setIsInternalBuild:
internalDefaults
setInternalDefaults:
_internalBuild
_isInternalBuild
_internalDefaults
bundleForClass:
pathForResource:ofType:
arrayWithContentsOfFile:
setWithArray:
availableLanguages
rangeOfString:
substringWithRange:
fallbackLanguageForLanguage:
downloadDuration
numberWithFloat:
endMetrics
isCellularAllowed
downloadProgress
voiceDownloadKey
downloadBeginTimestamp
downloadEndTimestamp
_isCellularAllowed
_discretionary
_downloadProgress
_voiceDownloadKey
_downloadBeginTimestamp
_downloadEndTimestamp
fileURLWithPath:isDirectory:
contentsOfDirectoryAtURL:includingPropertiesForKeys:options:error:
resourceValuesForKeys:error:
longLongValue
fileURLWithPath:
removeItemAtURL:error:
getResourceValue:forKey:error:
compare:
subarrayWithRange:
timeIntervalSinceDate:
directorySize:
removeDirectory:
cleanDirectory:withLRULimit:
cleanDirectory:withDateOlderThan:
hasANE
hasAMX
legacyPlatforms
hardwarePlatform
isHomePod
isSeedBuild
initWithFormat:
initWithContentsOfFile:
stringWithString:
rangeOfString:options:range:
stringByAppendingString:
replaceCharactersInRange:withString:
string
appendString:
vs_markerStringForContext:
regularExpressionWithPattern:options:error:
matchesInString:options:range:
characterAtIndex:
whitespaceCharacterSet
characterIsMember:
punctuationCharacterSet
rangeAtIndex:
_vs_countPhoneticSyllables_lhp:
numberOfRanges
hasPrefix:
containsString:
_vs_countPhoneticSyllables_xsampa:
stringByReplacingMatchesInString:options:range:withTemplate:
addCharactersInRange:
vs_isCJKCharacter:
initWithString:
removeLastObject
raise:format:
appendFormat:
vs_textifyEmojiWithLanguage:
vs_substituteAudioWithLocalPath
vs_insertContextInfo:
vs_measurePauses
vs_countPhoneticSyllables
vs_removePhonetics
vs_removeSpeechTags
vs_hasCJKCharacter
vs_convertToSSML
stringByStandardizingPath
initWithContentsOfURL:
filePathURL
attributesOfItemAtPath:error:
textRange
setTextRange:
allValues
doubleValue
setStartTime:
pathForResource:ofType:inDirectory:
timingPlistForLanguage:
timingInfosFrom:withText:
estimatedTTSWordTimingForText:withLanguage:withGender:
wordTimings
setWordTimings:
_wordTimings
objectAtIndex:
mutableCopy
removeObjectAtIndex:
replaceObjectAtIndex:withObject:
modelIdentifier
recognitionResultWithModelIdentifier:classIdentifiers:values:
elementCount
getElementClassIdentifier:value:atIndex:
bundleWithPath:
load
isEqual:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
debugDescription
actionForRecognitionResult:
actionForRecognitionResults:
instancesRespondToSelector:
initialize
recognitionResultByReplacingValueForClassIdentifier:withValue:
valueOfFirstElementWithClassIdentifier:
createHandler
setRecognitionAction:
recognitionAction
reset
_init
cancel
setDelegate:
setActive:
dealloc
recognitionSessionDidBeginAction:
recognitionSessionWillBeginAction:
recognitionSession:openURL:
recognitionSession:didCompleteActionWithError:
recognitionSession:didFinishSpeakingFeedbackStringWithError:
_notifyDelegateActionStarted
_continueAfterDeferredStart
perform
_hasDeferredStartCallback
_currentRecognizeAction
_debugDumpPath
setAudioType:
setKeepAudioSessionActive:
initWithModelIdentifier:
_setAction:
_isRecognizing
_isActivelyRecognizing
completionType
_setBluetoothInputAllowed:
invalidate
stopSpeakingAtNextBoundary:synchronously:error:
cancelMaintainingKeepAlive:
methodSignatureForSelector:
invocationWithMethodSignature:
setSelector:
setTarget:
setArgument:atIndex:
retainArguments
scheduledTimerWithTimeInterval:invocation:repeats:
_setSession:
_setDebugDumpPath:
_setDebugDumpEnabled:
_setPreferredEngine:
_setAudioInputPath:
_setInputLevelUpdateInterval:
_setEngineResetRequired:
defaultCenter
postNotificationName:object:
_handledThreadedResults:nextAction:
spokenFeedbackString
spokenFeedbackAttributedString
resultDisplayString
statusDisplayString
_inputLevel
_inputLevelDB
_keywordAtIndex:
_keywordCount
_scrambledKeywordsAndAddToSet:
_nextKeywordUsingCursors:
removeObject:
allObjects
_createKeywordIndex
_createPhaseSortedKeywordsFromArray:
_topLevelKeywords
_keywordIndexChanged
postNotificationName:object:userInfo:
_beginSpeakingAttributedString:
beginSpeakingString:
_beginSpeakingString:attributedString:
_notifyDelegateFinishedSpeakingWithError:
initForInputFeedback
setAttributedText:
setText:
setLanguageCode:
setOutputPath:
startSpeakingRequest:
beginNextAction
isRecognizing
isActivelyRecognizing
isFinished
isValid
hasDeferredAction
isBusy
nextActionWillTerminateSession
nextActionWillRecognize
setSensitiveActionsEnabled:
sensitiveActionsEnabled
setBluetoothInputAllowed:
_actionCompleted:nextAction:error:
_actionStarted:
_notifyDelegateOpenURL:
_recognitionResultHandlingThread
recognitionResultHandlingThread:didHandleResults:nextAction:
displayResultString
displayStatusString
setInputLevelUpdateInterval:
inputLevel
inputLevelDB
setKeywordPhase:
keywordAtIndex:
keywordCount
_keywordsForModelIdentifier:
beginSpeakingFeedbackString
speechSynthesizer:didFinishSpeaking:withError:
setDebugDumpEnabled:
debugDumpPath
setNextRecognitionAudioInputPath:
setNextRecognitionRequiresReset:
setPreferredEngine:
setPerformRecognitionHandlerActions:
_modelIdentifier
_keepAlive
_delegate
_currentAction
_handlingThread
_synthesizer
_languageID
_audioInputPath
_levelInterval
_keywordPhase
_sessionFlags
exchangeObjectAtIndex:withObjectAtIndex:
initWithStreamDescription:
initFromFormat:toFormat:
maximumOutputPacketSize
initWithFormat:packetCapacity:maximumPacketSize:
streamDescription
data
initWithPCMFormat:frameCapacity:
setFrameLength:
mutableAudioBufferList
bytes
convertToBuffer:error:withInputFromBlock:
audioBufferList
appendBytes:length:
packetCount
packetDescriptions
encodeChunk:
initWithSourceASBD:
setOpusDataHandler:
setErrorHandler:
beginEncoding
endEncoding
opusDataHandler
errorHandler
fromFormat
setFromFormat:
toFormat
setToFormat:
converter
setConverter:
outputBuffer
setOutputBuffer:
opusDataOffset
setOpusDataOffset:
_opusDataHandler
_errorHandler
_fromFormat
_toFormat
_converter
_outputBuffer
_opusDataOffset
vs_stringFrom4CC:
beginChunkDecoderForStreamDescription:
decodeChunk:outError:
appendData:
enumerateObjectsUsingBlock:
endChunkDecoding
_opusDecoder:
initWithLength:
mutableBytes
dataWithBytes:length:
sharedInstance
decodeChunks:streamDescription:outError:
_decoder
_asbd
_session
setResultDisplayString:
setStatusDisplayString:
setSpokenFeedbackString:
setSpokenFeedbackAttributedString:
completeWithNextAction:error:
_resultString
_statusString
_spokenString
_spokenStringIsAttributed
uppercaseString
localizations
preferredLocalizationsFromArray:forPreferences:
URLForResource:withExtension:subdirectory:localization:
predefinedStringForKey:language:gender:table:
appendRandomizationKey:withCount:
localizedStringForKey:language:gender:table:
localizedInterstitialStringForKey:language:gender:
localizedOOBStringForKey:language:gender:
_disambiguationContext
_reset
setRepeatedSpokenFeedbackString:
repeatedSpokenFeedbackString
sequenceTag
setSequenceTag:
knownValueForClassIdentifier:
setKnownValue:phoneticValue:forClassIdentifier:
knownValuesForClassIdentifier:
setKnownValues:phoneticValues:forClassIdentifier:
ambiguousValuesForClassIdentifier:
setAmbiguousValues:phoneticValues:forClassIdentifier:
_keywords
setKeywords:
_createRecognitionInstanceWithCallbacks:info:
_actionForEmptyResults
_repeatedSpokenFeedbackString
_sequenceTag
_knownValues
_knownPhoneticValues
_ambiguousValues
_ambiguousPhoneticValues
_context
addObjectsFromArray:
languageMapping
dataWithContentsOfFile:
characterSetWithBitmapRepresentation:
characterSet
valueWithRange:
initWithLanguage:
unspeakableRangeOfText:
setCharacterSet:
_characterSet
_setDebugDumpEnabled:dumpPath:
_configureNewRecognitionInstance
_setResults:
_releaseFromPrepare
requiresThreadedProcessing
handleResults:withHandler:
makeObjectsPerformSelector:withObject:
_handleRecognitionPrepared:
_handleRecognitionStarted:
_handleRecognitionCompleted:withResults:error:
_recognition
_results
_recognizeFlags
reportEvent:payload:
reportInstrumentMetrics:
componentsJoinedByString:
decodeObjectOfClasses:forKey:
vocalizerConfig
URLByAppendingPathComponent:
dictionaryWithContentsOfURL:
dictionaryWithContentsOfURL:error:
voiceConfig
_defaultVoice
defaultVoice
rate
pitch
volume
resourceMimeTypes
resourceList
serverVoiceNameForGender:
defaultTypeString
defaultFootprintString
setVoiceConfig:
setRate:
setPitch:
setVolume:
setVocalizerConfig:
setResourceList:
setResourceMimeTypes:
_rate
_pitch
_volume
_languages
_searchPathURL
_voiceConfig
_vocalizerConfig
_resourceList
_resourceMimeTypes
rangeValue
whitespaceAndNewlineCharacterSet
UTF8String
lengthOfBytesUsingEncoding:
startTime
extraBytesFromUTF8ToUTF16With:totalLength:begin:end:
wordTimingInfoFrom:timestamps:
utf16TimingInfoWithUTF8Range:withText:
_startTime
_textRange
isANEModelCompiled:
compileANEModel:
stopListening
lock
_spokenLanguageChanged:
addObserver:selector:name:object:
unlock
beginReportingChanges
makeObjectsPerformSelector:
stopReportingChanges
removeObserver:name:object:
_flush
initWithModelIdentifier:classIdentifier:
_enqueueRequest:
performUpdateForModelIdentifier:classIdentifier:
coalescedRequest:
timerWithTimeInterval:target:selector:userInfo:repeats:
mainRunLoop
addTimer:forMode:
setFireDate:
classIdentifier
sharedListener
sharedListenerIfExists
_initShared
startListening
_lock
_updateRequestQueue
_dataProviders
_flushTimer
_isListening
_modelID
_classID
valueCountForClassWithIdentifier:inModelWithIdentifier:
valueAtIndex:forClassWithIdentifier:inModelWithIdentifier:
getValue:weight:atIndex:forClassWithIdentifier:inModelWithIdentifier:
phoneticValueAtIndex:forClassWithIdentifier:inModelWithIdentifier:
cacheValidityIdentifier
isCacheValidityIdentifierValid:
_setConfirmed:
setConfirmedAction:
confirmedAction
setDeniedAction:
deniedAction
_confirmedAction
_deniedAction
_confirmFlags
setURL:
_url
pathForResource:ofType:inDirectory:forLocalization:
initFileURLWithPath:
initWithSpokenFeedbackString:willTerminate:
_shouldTerminate
canLogRequestText
encodeValueOfObjCType:at:
encodeInt32:forKey:
initWithAudioData:decoderStreamDescription:playerStreamDescription:
decodeValueOfObjCType:at:size:
decodeInt32ForKey:
numberWithUnsignedLongLong:
logText
copyWithZone:
initWithAudioData:playerStreamDescription:
initWithIdentifier:
audioSessionID
setAudioSessionID:
audioData
decoderStreamDescription
playerStreamDescription
enqueue
setEnqueue:
text
identifier
setIdentifier:
pcmDataSize
setPcmDataSize:
stopHandler
setStopHandler:
_enqueue
_audioSessionID
_audioData
_text
_identifier
_pcmDataSize
_stopHandler
_decoderStreamDescription
_playerStreamDescription
initWithCondition:
initWithHandler:results:
_handleRequests
detachNewThreadSelector:toTarget:withObject:
unlockWithCondition:
nextAction
lockWhenCondition:
handler
setNextAction:
_notifyRequestHandled:
performSelectorOnMainThread:withObject:waitUntilDone:
_requests
_resultHandlingFlags
_handler
_action
initWithDictionaryRepresentation:
matchedString:forTokenInRange:
initWithContentsOfPath:languageIdentifier:
processedTextFromString:
_rules
_tokenizer
boolValue
_matchPattern
_replacement
_caseSensitive
_eatPunctuation
appendString:withAttributes:
attributedStringWithFormatAndAttributes:
formatSpecifier
formattedArg
setAttributes:range:
contextInfoString
languageCode
contextInfo
isEqualToDictionary:
voiceType
customResourceURLs
isEqualToArray:
allocWithZone:
setVoiceType:
outputPath
shouldCache
setShouldCache:
setContextInfo:
disableCompactVoiceFallback
setDisableCompactVoiceFallback:
resourceListURL
setResourceListURL:
resourceSearchPathURL
setResourceSearchPathURL:
setCustomResourceURLs:
decodePropertyListForKey:
enumerateKeysAndObjectsUsingBlock:
logUtterance
isSimilarTo:
retryDeviceOnNetworkStall
setRetryDeviceOnNetworkStall:
attributedText
pauseHandler
setPauseHandler:
pointer
setPointer:
voiceName
setVoiceName:
_shouldCache
_disableCompactVoiceFallback
_forceServerTTS
_retryDeviceOnNetworkStall
_languageCode
_footprint
_voiceType
_gender
_outputPath
_contextInfo
_resourceListURL
_resourceSearchPathURL
_customResourceURLs
_attributedText
_pauseHandler
_pointer
_voiceName
createFileAtPath:contents:attributes:
fileHandleForUpdatingAtPath:
fileDescriptor
closeFile
initWithFilePath:initialSize:
removeItemAtPath:error:
_convertToFallbackMemory
_appendToFallbackMemory:
_appendToMappedMemory:
bytesAtOffset:
filePath
setFilePath:
totalLength
setTotalLength:
mmappedData
setMmappedData:
mappedLength
setMappedLength:
fallbackInMemoryData
setFallbackInMemoryData:
shouldCleanFile
setShouldCleanFile:
_shouldCleanFile
_filePath
_totalLength
_mmappedData
_mappedLength
_fallbackInMemoryData
stringWithCapacity:
stringByAppendingFormat:
md5hash
sha256hex
preinstalledAudioHashForLanguage:gender:
completion
audioPlayerDidFinishPlaying:successfully:
audioPlayerDecodeErrorDidOccur:error:
audioPlayerBeginInterruption:
audioPlayerEndInterruption:withOptions:
audioPlayerEndInterruption:withFlags:
audioPlayerEndInterruption:
setCompletion:
_completion
errorWithReason:
playVoicePreviewForLanguageCode:gender:completion:
getVoiceResourceForLanguage:reply:
URLByAppendingPathComponent:isDirectory:
isPlaying
stop
category
setActive:withOptions:error:
setCategory:error:
initWithContentsOfURL:error:
setActive:error:
play
preferredLocalizations
processInfo
processName
processIdentifier
opaqueSessionID
speechSynthesizer:didFinishPrewarmRequest:withError:
prewarmIfNeededWithRequest:reply:
queryPhaticCapabilityWithRequest:
speechSynthesizer:didStartSpeakingRequest:
speechSynthesizerDidStartSpeaking:
speechSynthesizer:didFinishSpeakingRequest:successfully:withError:
speechSynthesizer:didFinishSpeakingRequest:successfully:phonemesSpoken:withError:
speechSynthesizer:didFinishSpeaking:phonemesSpoken:withError:
speechSynthesizer:didPauseSpeakingRequest:
speechSynthesizerDidPauseSpeaking:
speechSynthesizer:didContinueSpeakingRequest:
speechSynthesizerDidContinueSpeaking:
speechSynthesizer:willSpeakRangeOfSpeechString:forRequest:
speechSynthesizer:willSpeakRangeOfSpeechString:
speechSynthesizer:didFinishSpeakingRequest:withInstrumentMetrics:
presynthesizedAudioRequest
stopPresynthesizedAudioRequest
request
stopCurrentSpeechRequestAtMark:
pauseCurrentSpeechRequestAtMark:
_setDelegate:
validateRequest:
startSynthesisRequest:
startSpeechRequest:
validatePresynthesizedAudioRequest:
connection:presynthesizedAudioRequest:didStopAtEnd:error:
startPresynthesizedAudioRequest:
cachePresynthesizedAudioRequest:
_stopSpeakingRequestAtNextBoundary:synchronously:
_stopSpeakingPresynthesizedAudioRequestSynchronously:
_pauseSpeakingRequestAtNextBoundary:synchronously:
isSystemSpeakingOnBehalfOfCurrentConnection
isSystemSpeaking
continueCurrentSpeechRequest
decimalDigitCharacterSet
numberWithInt:
characterClassCountForUtterance:language:
objectAtIndexedSubscript:
unsignedIntegerValue
estimateDurationWithRequest:reply:
speechSynthesizer:withRequest:didReceiveTimingInfo:
valueWithNonretainedObject:
durationRequests
speechSynthesizer:didFinishSynthesisRequest:withInstrumentMetrics:error:
speechSynthesizer:didFinishSynthesisRequest:withError:
speechSynthesizer:didStartPresynthesizedAudioRequest:
speechSynthesizer:didStopPresynthesizedAudioRequest:atEnd:error:
speechSynthesizer:didStopPresynthesizedAudioRequestAtEnd:error:
speechSynthesizer:didFinishPresynthesizedAudioRequest:withInstrumentMetrics:error:
speechSynthesizer:daemonDidCrashWithError:
setLogToFile:
getLogToFile:
_continueSpeakingRequest
getTTSServerVoicesWithFilter:reply:
forwardStreamObject:
cancelDownloads:
invokeDaemon:
killDaemon
beginAudioPowerUpdateWithReply:
endAudioPowerUpdate
cleanUnusedAssets:
getLocalVoiceAssetsForLanguage:reply:
getLocalVoiceResources:
setAutoDownloadedVoiceAssets:withClientID:
getAutoDownloadedVoiceAssetsWithClientID:reply:
getVoiceInfoForLanguageCode:footprint:gender:type:reply:
availableVoicesForLanguageCode:
availableFootprintsForVoice:languageCode:
playVoicePreviewForLanguageCode:gender:
connection:speechRequestDidStart:
connection:speechRequestDidPause:
connection:speechRequestDidContinue:
connection:speechRequest:didStopAtEnd:phonemesSpoken:error:
connection:speechRequest:willSpeakMark:inRange:
connection:speechRequest:successWithInstrumentMetrics:
connection:speechRequest:didReceiveTimingInfo:
connection:synthesisRequest:didFinishWithInstrumentMetrics:error:
connection:presynthesizedAudioRequestDidStart:
connection:presynthesizedAudioRequest:successWithInstrumentMetrics:error:
connection:invalidatedWithError:
prewarmIfNeededWithRequest:
queryPhaticCapability:
startSynthesizingRequest:
startSpeakingPresynthesizedAudioRequest:
stopSpeakingPresynthesizedAudioSynchronously:error:
pauseSpeakingAtNextBoundary:synchronously:error:
isSpeaking
speechString
minimumRate
maximumRate
estimateDurationOfRequest:
estimateDurationOfRequest:completion:
setMaintainPersistentConnection:
setMaintainInactivePersistentConnection:
useSharedAudioSession:
useSpecificAudioSession:
continueSpeakingWithError:
getLocalVoiceAssets:
setAutoDownloadedVoiceAssets:
getAutoDownloadedVoiceAssets:
availableLanguageCodes
delegate
voice
setVoice:
language
setLanguage:
setDurationRequests:
_queue
_callbackQueue
_xpcConnection
_synthesizerFlags
_voice
_language
_durationRequests
migrateDefaults
arrayForKey:
dictionaryForKey:
dictionaryRepresentation
UUID
UUIDString
setAutoDownloadedVoices:withClientID:
setLastTTSRequestDate:
lastTTSRequestDate
deviceUUID
defaults
setDefaults:
_defaults
initWithMachServiceName:options:
maintainWithAudioType:keepAudioSessionActive:
interfaceWithProtocol:
setRemoteObjectInterface:
_ensureKeepAliveMaintenance
setInterruptionHandler:
resume
_serverConnection
remoteObjectProxy
_remoteKeepAlive
audioType
active
keepAudioSessionActive
_audioType
_active
_keepAudioSessionActive
setConnection:
updateWithConnectionIdentifier:
queryPhaticCapabilityWithRequest:reply:
startSpeechRequest:reply:
pauseSpeechRequestAtMark:
continueSpeechRequest
stopSpeechRequestAtMark:
getVoiceNamesForLanguage:reply:
getFootprintsForVoiceName:languageCode:reply:
getSpeechIsActiveReply:
getSpeechIsActiveForConnectionReply:
getLocalVoicesForLanguage:reply:
getLocalVoiceResourcesReply:
setClasses:forSelector:argumentIndex:ofReply:
_connectionInvalidated
setInvalidationHandler:
xpcConnection
speechRequestDidStart
speechRequestDidPause
speechRequestDidContinue
speechRequestMark:didStartForRange:
speechRequestDidStopWithSuccess:phonemesSpoken:error:
speechRequestSuccessWithInstrumentMetrics:
speechRequestDidReceiveTimingInfo:
synthesisRequest:didReceiveTimingInfo:
synthesisRequest:didFinishWithInstrumentMetrics:error:
presynthesizedAudioRequestDidStart
presynthesizedAudioRequestDidStopAtEnd:error:
presynthesizedAudioRequestSuccessWithInstrumentMetrics:error:
setExportedInterface:
delegateWrapper
setExportedObject:
synchronousRemoteObjectProxyWithErrorHandler:
remoteObjectProxyWithErrorHandler:
concurrentSynthesisRequests
setXpcConnection:
setRequest:
setPresynthesizedAudioRequest:
setConcurrentSynthesisRequests:
_remoteObjectWithErrorHandler:
_remoteObject
_remoteObjectSync
localizedDescription
setDelegateWrapper:
threadSafeQueue
setThreadSafeQueue:
_delegateWrapper
_threadSafeQueue
connection
_request
_concurrentSynthesisRequests
_presynthesizedAudioRequest
_connection
nameKey
lowercaseString
isBuiltInVoice
_isInstalled
_isBuiltInVoice
_isVoiceReadyToUse
_name
_type
anonymousListener
setQueue:
setHandler:
setListener:
endpoint
setEndpoint:
_setQueue:
invokeUpdateWithObject:
initWithBlock:
initWithListenerEndpoint:
configuredEndpointWithUpdateHandler:withConnection:
remoteUpdateHanderForEndpoint:
listener:shouldAcceptNewConnection:
queue
listener
_endpoint
_listener
_block
B16@0:8
v24@0:8@16
@24@0:8@16
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
@16@0:8
v20@0:8B16
v16@0:8
@"NSString"
@"NSNumber"
d16@0:8
q16@0:8
v24@0:8q16
v24@0:8d16
Q16@0:8
@"VSVoiceAsset"
@"MAAsset"
@64@0:8@16q24@32q40q48q56
@32@0:8@16q24
v32@0:8@16@24
@20@0:8B16
@24@0:8q16
q24@0:8@16
B24@0:8@16
@48@0:8@16q24q32q40
@56@0:8q16@24@32q40q48
v36@0:8@16B24@?28
v40@0:8@16@24@?32
v32@0:8@16@?24
B32@0:8@16^@24
v24@0:8@?16
@36@0:8@16B24^@28
@64@0:8q16@24@32q40q48q56
@32@0:8@16@24
v48@0:8@16@24@?32@?40
@40@0:8@16@24@?32
@"NSObject<OS_dispatch_queue>"
@"NSCache"
f16@0:8
v20@0:8f16
@"NSUserDefaults"
@40@0:8@16@24q32
Q24@0:8@16
v32@0:8@16Q24
B20@0:8S16
@"NSDictionary"
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
@"VSRecognitionAction"24@0:8@"VSRecognitionResult"16
@"VSRecognitionAction"24@0:8@"NSArray"16
@40@0:8@16@24@32
B40@0:8^@16^@24q32
B20@0:8B16
v40@0:8@16@24@32
v24@0:8Q16
^{__CFDictionary=}16@0:8
v36@0:8@16B24@28
B20@0:8i16
@"VSKeepAlive"
@"<VSRecognitionSessionDelegate>"
@"VSRecognitionAction"
@"NSArray"
@"VSSpeechSynthesizer"
{?="delegateWillBegin"b1"delegateBegin"b1"delegateOpenURL"b1"delegateFinishedSpeaking"b1"delegateComplete"b1"debugDumpEnabled"b1"preferredEngine"b2"performHandlerActions"b1"allowSensitiveActions"b1"bluetoothAllowed"b1"resetNextAction"b1"isSpeaking"b1"actionBegan"b1"actionBeginning"b1"actionBeginDeferred"b1"invalid"b1"observeKeywordChange"b1}
@24@0:8^{__CFDictionary=}16
@56@0:8{AudioStreamBasicDescription=dIIIIIIII}16
@?16@0:8
@"AVAudioFormat"
@"AVAudioConverter"
@"AVAudioCompressedBuffer"
^{OpaqueAudioConverter=}56@0:8{AudioStreamBasicDescription=dIIIIIIII}16
@72@0:8@16{AudioStreamBasicDescription=dIIIIIIII}24^@64
@32@0:8@16^@24
^{OpaqueAudioConverter=}
{AudioStreamBasicDescription="mSampleRate"d"mFormatID"I"mFormatFlags"I"mBytesPerPacket"I"mFramesPerPacket"I"mBytesPerFrame"I"mChannelsPerFrame"I"mBitsPerChannel"I"mReserved"I}
i16@0:8
(?="stringValue"@"NSString""attributedStringValue"@"NSAttributedString")
@"VSRecognitionSession"
@48@0:8@16@24@32@40
@28@0:8@16i24
^{__VSRecognitionDisambiguationContext=}16@0:8
^{__VSRecognition=}32@0:8^{?=^?^?^?}16^v24
@"NSMutableDictionary"
@"NSCharacterSet"
B24@0:8d16
B28@0:8B16@20
v24@0:8^{__VSRecognition=}16
v40@0:8^{__VSRecognition=}16^{__CFArray=}24^{__CFError=}32
{?="debugDumpEnabled"b1"preferredEngine"b2"resetEngine"b1"bluetoothAllowed"b1"hasStarted"b1}
@"NSURL"
Q48@0:8r*16Q24Q32Q40
{_NSRange=QQ}16@0:8
v32@0:8{_NSRange=QQ}16
{_NSRange="location"Q"length"Q}
@"NSLock"
@"NSMutableArray"
@"NSTimer"
q32@0:8@16@24
@40@0:8q16@24@32
B56@0:8^@16^q24q32@40@48
q32@0:8@"NSString"16@"NSString"24
@"NSString"40@0:8q16@"NSString"24@"NSString"32
B56@0:8^@16^q24q32@"NSString"40@"NSString"48
@"NSDictionary"16@0:8
B24@0:8@"NSDictionary"16
{?="initializing"b1"confirmed"b1}
@20@0:8i16
@28@0:8@16B24
@24@0:8^{_NSZone=}16
@64@0:8@16{AudioStreamBasicDescription=dIIIIIIII}24
@104@0:8@16{AudioStreamBasicDescription=dIIIIIIII}24{AudioStreamBasicDescription=dIIIIIIII}64
I16@0:8
v20@0:8I16
{AudioStreamBasicDescription=dIIIIIIII}16@0:8
@"NSData"
@"<VSRecognitionResultHandlingThreadDelegate>"
@"NSConditionLock"
{?="running"b1"delegateDidHandleResults"b1"valid"b1}
@"<VSRecognitionResultHandler>"
^{__CFStringTokenizer=}
@32@0:8@16^{?=qq}24
@"NSAttributedString"
@32@0:8@16Q24
{_NSRange=QQ}24@0:8@16
^v24@0:8Q16
^v16@0:8
v24@0:8^v16
@"NSMutableData"
v28@0:8@16B24
v28@0:8@"AVAudioPlayer"16B24
v32@0:8@"AVAudioPlayer"16@"NSError"24
v24@0:8@"AVAudioPlayer"16
v32@0:8@"AVAudioPlayer"16Q24
B32@0:8@16q24
B40@0:8@16q24@?32
v52@0:8@16@24B32@36@44
v56@0:8@16@24q32{_NSRange=QQ}40
v48@0:8@16@24@32@40
v44@0:8@16@24B32@36
v32@0:8@"VSSpeechConnection"16@"VSSpeechRequest"24
v52@0:8@"VSSpeechConnection"16@"VSSpeechRequest"24B32@"NSString"36@"NSError"44
v56@0:8@"VSSpeechConnection"16@"VSSpeechRequest"24q32{_NSRange=QQ}40
v40@0:8@"VSSpeechConnection"16@"VSSpeechRequest"24@"VSInstrumentMetrics"32
v40@0:8@"VSSpeechConnection"16@"VSSpeechRequest"24@"NSArray"32
v48@0:8@"VSSpeechConnection"16@"VSSpeechRequest"24@"VSInstrumentMetrics"32@"NSError"40
v32@0:8@"VSSpeechConnection"16@"VSPresynthesizedAudioRequest"24
v44@0:8@"VSSpeechConnection"16@"VSPresynthesizedAudioRequest"24B32@"NSError"36
v48@0:8@"VSSpeechConnection"16@"VSPresynthesizedAudioRequest"24@"VSInstrumentMetrics"32@"NSError"40
v32@0:8@"VSSpeechConnection"16@"NSError"24
@28@0:8q16B24
B36@0:8q16B24^@28
B28@0:8B16^@20
d24@0:8@16
B24@0:8^@16
v56@0:8@16q24q32q40@?48
@"VSSpeechConnection"
{?="delegateStart"b1"delegateFinish"b1"delegateFinishWithPhonemesSpoken"b1"delegatePause"b1"delegateContinue"b1"delegateWillSpeak"b1"delegateStartWithRequest"b1"delegateFinishWithRequest"b1"delegateFinishWithPhonemesSpokenWithRequest"b1"delegateSuccessWithInstrumentMetrics"b1"delegatePauseWithRequest"b1"delegateContinueWithRequest"b1"delegateWillSpeakWithRequest"b1"willUseInput"b1}
@"<VSSpeechSynthesizerDelegate>"
Vv28@0:8q16B24
@"NSXPCConnection"
Vv24@0:8@16
Vv32@0:8@16@?24
Vv24@0:8q16
Vv40@0:8@16@24@?32
Vv24@0:8@?16
Vv32@0:8@16@24
Vv56@0:8@16q24q32q40@?48
Vv20@0:8B16
Vv24@0:8@"NSString"16
Vv32@0:8@"VSSpeechRequest"16@?<v@?@"NSError">24
Vv32@0:8@"VSSpeechRequest"16@?<v@?B>24
Vv32@0:8@"VSSpeechRequest"16@?<v@?d@"NSError">24
Vv32@0:8@"VSSpeechRequest"16@?<v@?>24
Vv24@0:8@"VSSpeechRequest"16
Vv24@0:8@"VSPresynthesizedAudioRequest"16
Vv32@0:8@"NSString"16@?<v@?@"NSArray">24
Vv40@0:8@"NSString"16@"NSString"24@?<v@?@"NSArray">32
Vv24@0:8@?<v@?B>16
Vv24@0:8@?<v@?@"AFXPCWrapper">16
Vv24@0:8@?<v@?@"NSError">16
Vv32@0:8@"NSString"16@?<v@?@"NSArray"@"NSError">24
Vv24@0:8@?<v@?@"NSArray"@"NSError">16
Vv32@0:8@"NSArray"16@"NSString"24
Vv32@0:8@"NSString"16@?<v@?@"VSVoiceResourceAsset">24
Vv56@0:8@"NSString"16q24q32q40@?<v@?@"VSVoiceAsset">48
Vv24@0:8@?<v@?>16
Vv32@0:8@"VSVoiceAsset"16@?<v@?@"NSArray"@"NSError">24
Vv24@0:8@"SATTSSpeechSynthesisStreaming"16
Vv40@0:8q16{_NSRange=QQ}24
Vv36@0:8B16@20@28
Vv40@0:8@16@24@32
Vv28@0:8B16@20
Vv36@0:8B16@"NSString"20@"NSError"28
Vv24@0:8@"VSInstrumentMetrics"16
Vv24@0:8@"NSArray"16
Vv32@0:8@"VSSpeechRequest"16@"NSArray"24
Vv40@0:8@"VSSpeechRequest"16@"VSInstrumentMetrics"24@"NSError"32
Vv28@0:8B16@"NSError"20
Vv32@0:8@"VSInstrumentMetrics"16@"NSError"24
@24@0:8@?16
@"<VSSpeechConnectionDelegate>"
@"VSSpeechConnectionDelegateWrapper"
@"VSSpeechRequest"
@"VSPresynthesizedAudioRequest"
@32@0:8@?16@24
@?24@0:8@16
B32@0:8@16@24
B32@0:8@"NSXPCListener"16@"NSXPCConnection"24
@"NSXPCListenerEndpoint"
@"NSXPCListener"
|?5^
