softlink:r:path:/System/Library/PrivateFrameworks/HearingUtilities.framework/HearingUtilities
v8@?0
AXCustomPronunciations
AXVoiceOverActivities
Reconciled iCloud pronunciations: adding: %{private}@
Did not find a change, not updating
ICLOUD[%p]: Waiting 5s to publish, deleting %@
Created an empty length archive, not synching
ICLOUD[%p]: Publishing data to iCloud %{private}@
Custom pronunications settings updated
refresh-voices
It's been too soon since we last updated our available voices. We need to wait longer. %f
/Library/Caches/com.apple.xbs/Sources/AccessibilityFrameworks_Sim/AccessibilityFrameworks-2879/Source/AXAssetAndDataServer/AXAssetAndDataServer.m
-[AXAssetAndDataServer _updateCachedTTSVoiceAssets]_block_invoke
We just refreshed voices, why are they missing?
-[AXAssetAndDataServer _handleExtantVoices]
Why is name nil for %@
VoiceId
Language
Name
en-US
com.apple.speech.synthesis.voice
@"NSArray"8@?0
@"NSString"32@?0@"MAAsset"8@"NSString"16q24
B24@?0@"MAAsset"8Q16
LastSpeechAssetUpdateCheck
com.apple.accessibility.api
com.apple.private.kernel.jetsam
com.apple.CoreRoutine.preferences
com.apple.TVServices.DisplayManager
com.apple.accessibility.voiceover
com.apple.appletv.pbs.display-manager-service-access
com.apple.accessibility.axctl
delete
options
audioLevel
female
Adding
Removing
neural
non-neural
v16@?0@"NSArray"8
got transcription results: %@
AXSpeechPronunciationClient
results
v24@?0@"NSDictionary"8@"NSError"16
Fail: %@, %d
Error
error
Starting pronunciation dication: %@, %@, %@
((%@ IN attributes.%K) || %@ = attributes.%K) && (attributes.%K != %d)
q24@?0@"MAAsset"8@"MAAsset"16
v16@?0@"MAProgressNotification"8
v16@?0q8
hash
TQ,R
superclass
T#,R
description
T@"NSString",R,C
debugDescription
AXAssetAndDataServer
AXUIService
NSObject
AFAssistantUIService
AFSpeechDelegate
AFDictationDelegate
init
sharedInstance
mobileAssetWorkQueue
initWithTargetSerialQueue:
setAutomaticallyCancelPendingBlockUponSchedulingNewBlock:
_monitoriCloudVoiceOverData
_icloudDataChanged:
afterDelay:processBlock:
defaultStore
dataForKey:
initForReadingFromData:error:
arrayWithObjects:count:
setWithArray:
decodeObjectOfClasses:forKey:
count
_iCloudReconcileDataStore:
_iCloudReconcileActivitiesStore:
synchronize
syncPronunciationsWithCloudKit
_reconcilePronunciations
_reconcileActivities
voiceOverActivities
countByEnumeratingWithState:objects:count:
indexOfObject:
objectAtIndexedSubscript:
isIdenticalTo:
setVoiceOverActivities:
ignoreLogging
identifier
customPronunciationSubstitutions
containsObject:
_syncToWatch
setCustomPronunciationSubstitutions:
copy
archivedDataWithRootObject:requiringSecureCoding:error:
length
setData:forKey:
_saveCustomPronuciationsToExternalsAndDelete:
_customPronunicationsSettingsChanged
registerUpdateBlock:forRetrieveSelector:withListener:
_saveActivitiesToExternalsAndDelete:
defaultCenter
addObserver:selector:name:object:
userDidSelectVoiceForLanguage:source:
availableVoicesForLanguageCode:queryingMobileAssets:
isDefault
speechVoiceIdentifierForLanguage:source:exists:
voiceForIdentifier:
isEqualToString:
footprint
isNeuralSiriVoiceIdentifier:
setSpeechVoiceIdentifier:forLanguage:source:
updateSiriVoiceUsageForIdentifier:add:
dictionary
numberWithBool:
setObject:forKeyedSubscript:
refreshAllAvailableVoices
allAvailableVoices
setCurrentVoices:
availableVoices:
currentVoices
_handleExtantVoices
objectForKeyedSubscript:
_updateDefaultVoiceIfNecessaryForLanguage:source:
mobileAssetDownloadQueue
_downloadAssetsForSelectedVoices
attributes
firstObject
stringByReplacingOccurrencesOfString:withString:
_combinedVocalizerAssets:
boolValue
intValue
_languageForAsset:
setIsCombinedVoice:
setNonCombinedVoiceId:
objectForKey:
allInstalledAssetsForVoiceId:
setIdentifier:
setLanguage:
setNonLocalizedNameWithoutQuality:
setQuality:
setGender:
setIsInstalled:
unsignedIntegerValue
setAssetSize:
setCanBeDownloaded:
addObject:
_vocalizerAssets:
state
supportsAlex
nameForVoiceIdentifier:
hasPrefix:
canBeDownloaded
isCombinedFootprint
supportsSiri
array
_normamizedSiriName:
axSafelyAddObject:
_handleSiriStyleVoices:assetRetrieval:voiceIdentifier:voiceName:
axFilterObjectsUsingBlock:
setExtantVoices:
lowercaseString
replaceObjectAtIndex:withObject:
migratePrefToNeuralVoiceIfNecessaryForVoice:
language
isSiriVoiceIdentifier:
isInstalled
startDownloadingAlternateVoice:
standardUserDefaults
date
dateByAddingTimeInterval:
setObject:forKey:
timeIntervalSinceReferenceDate
extantVoices
_checkForMacinTalkAssetUpdates
_checkForVocalizerAssetUpdates
_updateCachedTTSVoiceAssets
setWithObjects:
_checkForAssets:
valueForKey:
secureUnarchiveData:withExpectedClass:otherAllowedClasses:
_startPronunciationSession:
_cancelPronunciationSession
_stopPronunciationSession
_pronunciationAudioLevel
numberWithFloat:
dictionaryWithObjects:forKeys:count:
initWithType:
setDoNotBlockBeforeFirstUnlock:
queryMetaDataSync
results
updateSiriVoiceListWithGender:language:add:isNeural:
setSiriAutoUpdateListInitialized:
componentsSeparatedByString:
setLanguages:
setType:
mutableCopy
gender
languages
type
removeObjectsInArray:
setAutoDownloadedVoiceAssets:
getAutoDownloadedVoiceAssets:
_handleFailureForSpeechPronunciation:
averagePower
stopSpeechWithOptions:
cancelSpeech
phonemeSuggestions
clientMessengerWithIdentifier:
backgroundAccessQueue
sendAsynchronousMessage:withIdentifier:targetAccessQueue:completion:
endSession
description
setDelegate:
setTranscriptionMode:
orthography
setOrthography:
initWithActivationEvent:
setIsEyesFree:
setEndpointerOperationMode:
startDictationWithLanguageCode:options:speechOptions:
returnTypes:
stringWithFormat:
addKeyValuePair:with:
predicateWithFormat:
filteredArrayUsingPredicate:
sortedArrayUsingComparator:
setAllowsCellularAccess:
totalWritten
totalExpected
_alexAssets
_beginDownloadIfNecessaryForAssets:
_vocalizerAssetsForLanguage:
selectedIdsForTesting
selectedSpeechVoiceIdentifiers
assetForVoiceId:
_voiceFromInternalVoiceListWithIdentifier:
isOldSiriVoiceIdentifier:
isNashvilleSystemVoice:
compare:options:
cleanUpExtraInstalledAssetsIfNecessary:
inUnitTestMode
replaceTestAsset:withAsset:
spaceCheck:
_handleAssetProgress:asset:installedAsset:
attachProgressCallBack:
_mobileAssetDownloadOptions
_updateAsset:existingAsset:
startDownload:then:
assetType
alexLocalAssetURL
getLocalFileUrl
isEqual:
_addToDownloadQueue:
purge:
_purgeExistingAsset:inFavorOfAsset:
setAlexLocalAssetURL:
defaultManager
path
setAttributes:ofItemAtPath:error:
possibleRequiredEntitlementsForProcessingMessageWithIdentifier:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
debugDescription
processMessage:withIdentifier:fromClientWithIdentifier:error:
messageWithIdentifierShouldBeProcessedAsynchronously:
processMessageAsynchronously:withIdentifier:fromClientWithIdentifier:completion:
accessQueueForProcessingMessageWithIdentifier:
messageWithIdentifierRequiresWritingBlock:
processInitializationMessage:
serviceWasFullyInitialized
connectionWillBeInterruptedForClientWithIdentifier:
requiredEntitlementForProcessingMessageWithIdentifier:
assistantConnectionRequestWillStart:
assistantConnectionDismissAssistant:
assistantConnectionRequestFinished:
assistantConnection:receivedCommand:completion:
assistantConnection:requestFailedWithError:requestClass:
assistantConnection:openURL:completion:
assistantConnection:openApplicationWithBundleID:URL:completion:
assistantConnection:shouldSpeak:
assistantConnection:didChangeAudioSessionID:
assistantConnectionAudioSessionDidBeginInterruption:
assistantConnectionAudioSessionDidEndInterruption:shouldResume:
assistantConnectionWillStartAcousticIDRequest:
assistantConnectionDidDetectMusic:
assistantConnection:didFinishAcousticIDRequestWithSuccess:
assistantConnection:setUserActivtiyInfoAndMakeCurrent:webpageURL:
assistantConnectionInvalidateCurrentUserActivity:
assistantConnection:wantsToCacheImage:
assistantConnection:extensionRequestWillStartForApplication:
assistantConnection:extensionRequestFinishedForApplication:error:
assistantConnection:startUIRequestWithText:completion:
assistantConnection:startUIRequestWithInfo:completion:
assistantConnection:willStartAudioPlaybackRequest:
assistantConnection:didStartAudioPlaybackRequest:
assistantConnection:didStopAudioPlaybackRequest:error:
assistantConnection:didHandleQuickStopWithAction:
assistantConnection:willProcessStartPlayback:intent:completion:
assistantConnection:willProcessStartPlayback:
assistantConnection:startPlaybackDidFail:
assistantConnection:audioSessionWillBecomeActive:
assistantConnection:audioSessionDidBecomeActive:
assistantConnection:willProcessAppLaunchWithBundleIdentifier:
assistantConnection:appLaunchFailedWithBundleIdentifier:
assistantConnectionSpeechRecordingWillBegin:
assistantConnection:speechRecordingWillBeginWithInputAudioPowerXPCWrapper:
assistantConnection:speechRecordingDidBeginOnAVRecordRoute:
assistantConnection:speechRecordingDidBeginOnAVRecordRoute:audioSessionID:
assistantConnection:speechRecordingDidChangeAVRecordRoute:
assistantConnectionSpeechRecordingDidDetectStartpoint:
assistantConnection:speechRecordingPerformTwoShotPromptWithType:completion:
assistantConnectionSpeechRecordingDidEnd:
assistantConnectionSpeechRecordingDidCancel:
assistantConnection:speechRecordingDidFail:
assistantConnectionDidChangeAudioRecordingPower:
assistantConnection:speechRecognitionDidFail:
assistantConnection:speechRecognized:
assistantConnection:speechRecognizedPartialResult:
assistantConnection:recognizedAdditionalSpeechInterpretation:refId:
assistantConnection:recognitionUpdateWithPhrases:utterances:refId:
assistantConnection:recognitionUpdateWillBeginForTask:
dictationConnectionSpeechRecordingWillBegin:
dictationConnectionSpeechRecordingDidBegin:
dictationConnection:speechRecordingDidBeginWithOptions:
dictationConnection:didBeginLocalRecognitionWithModelInfo:
dictationConnectionSpeechRecordingDidEnd:
dictationConnectionSpeechRecordingDidCancel:
dictationConnection:speechRecordingDidFail:
dictationConnection:speechRecognitionDidFail:
dictationConnection:didDetectLanguage:confidenceScores:
dictationConnection:didDetectLanguage:confidenceScores:isConfident:
dictationConnection:didRecognizeMultilingualSpeech:
dictationConnection:languageDetectorFailedWithError:
dictationConnection:didRecognizePhrases:languageModel:correctionIdentifier:
dictationConnection:didRecognizePhrases:languageModel:correctionIdentifier:replacingPreviousPhrasesCount:
dictationConnection:didRecognizeTokens:languageModel:
dictationConnection:didRecognizePartialResult:
dictationConnection:didProcessAudioDuration:
dictationConnectionSpeechRecognitionDidSucceed:
dictationConnection:didRecognizeTranscriptionObjects:languageModel:
dictationConnnectionDidChangeAvailability:
dictationConnection:didFinishWritingAudioFile:error:
dictationConnection:didReceiveSearchResults:recognizedText:stable:final:
dictationConnection:didRecognizePackage:
_isVocalizerAsset:
.cxx_destruct
_lastTTSVoiceAssetUpdate
_pronunciationPusher
_lastActivitiesICloudRetrieval
_activitiesPusher
_isUpdatingCachedTTSVoices
_dictationConnection
_isRecording
Checking pronunciations
%{public}@
Got pronunciations: %{private}@, count: %d
Exception decoding data: %@
Checking activities
Got activities: count: %d
did not find %@ in %@
%@ not identical to %@
Reconciled iCloud activities: adding: %{private}@
Did not find a change, not updating
Skipping publishing to iCloud because we just retrieved this data
Created an empty length archive, not synching
ICLOUD[%p]: Publishing data to iCloud %{private}@
Switching voice from %@ to %@ for source %ld because default voice has changed, and the user hasn't selected one for language %@
Updated TextToSpeech's available voices cache with voices: %@
Vocalizer assets example[0]: %{public}@
Victoria macinTalkAsset: %{public}@
local macinTalkAsset: %{public}@
remote macinTalkAsset: %{public}@
New siri names %@
Original old siri assets %@
Filtered out old siri assets so we're left with %@
Siri voices not supported
Set extant voices: %{public}@
Retrieved siri-style assets: %{public}@
Siri style: skipping non premium: %@
Siri style: skipping neural: %@
Processed Siri-style assets: %{public}@
made siri voice %@ with asset %@
Updating spoken content settings bedcause the selected voice was a Siri voice, but a neural voice matching the same gender and language: %@ was available
Downloading %@ because a non-neural variant was previously selected, but a neural variant is now available
Removing %@ from active siri list, because neural voice was available and non-neural version wasn't in use outside of Speech Features
Force checking speech assets: %d date: %{public}@
No previous LastSpeechAssetUpdateCheck was found. Setting date earlier: %{public}@.
Has speech asset data: %d
Not checking voice assets because it's too soon: %{public}@ - only %f seconds 
Checking on assets now
%@ %@ %@ %@ voice to active siri voice list
Setting Siri auto-downloaded voices: %@
MAAssetQuery error fetching results %{public}@ %{public}@ %{public}@
MAAssetQuery error fetching vocalizer results %{public}@
MAAssetQuery error fetching results %{public}@
Asset progress: %{public}@ - %f
Checking assets: %{public}@
no language present for %{public}@, so not trying to update
checking assets[%{public}@] %{public}@
could not parse voice identifier %{public}@
could not find asset for voice identifier %{public}@ but the voice was installed. This is expected if it is a built-in voice.
could not find asset for voice identifier %{public}@
selected voice %{public}@ is already downloading.
selected voice %{public}@ is required by the OS.
selected voice %{public}@ is installed but not in the catalog.
selected voice %{public}@ has unknown state.
selected voice %{public}@ is already installed.
selected voice %{public}@ is not present. Beginning download.
Updating siri voice list usage after downloading a selected voice ID that was missing
Asset not present, but no space to download voice %{public}@: %{public}@
asset installed with os
Adding asset to queue: %{public}@
No macintalk or siri asset installed
Installed asset %{public}@, latest asset: %{public}@
Detected new Asset, downloading: %{public}@
Enough disk space available - start %{public}@
Error: %{public}@
Asset state: %@
Error: Not enough disk space
No newer asset than %{public}@ - %@ [installed asset %{public}@]
Purging old asset: %{public}@
Purged old asset: %{public}@, %{public}@
Trying to update unknown asset (expecting Macintalk, Combined, or Siri): %{public}@
Could not remove file protection from: %{public}@
Updating Installed Asset: %{public}@
Could not purge old asset: %{public}@
@16@0:8
@24@0:8Q16
B24@0:8@16
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B16@0:8
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
@48@0:8@16Q24@32^@40
B24@0:8Q16
v48@0:8@16Q24@32@?40
v24@0:8@16
v16@0:8
@"NSDictionary"48@0:8@"NSDictionary"16Q24@"NSString"32^@40
v48@0:8@"NSDictionary"16Q24@"NSString"32@?<v@?@"NSDictionary"@"NSError">40
@"AXAccessQueue"24@0:8Q16
v24@0:8@"NSDictionary"16
v24@0:8@"NSString"16
@"NSString"24@0:8Q16
@"NSSet"24@0:8Q16
v40@0:8@16@24@?32
v40@0:8@16@24@32
v48@0:8@16@24@32@?40
v28@0:8@16B24
v28@0:8@16I24
v32@0:8@16@24
v32@0:8@16Q24
v48@0:8@16q24@32@?40
v32@0:8@16q24
v24@0:8@"AFConnection"16
v40@0:8@"AFConnection"16@"AceObject<SAAceCommand>"24@?<v@?@"AceObject<SAAceCommand>">32
v40@0:8@"AFConnection"16@"NSError"24@"NSString"32
v40@0:8@"AFConnection"16@"NSURL"24@?<v@?B>32
v48@0:8@"AFConnection"16@"NSString"24@"NSURL"32@?<v@?B>40
v28@0:8@"AFConnection"16B24
v28@0:8@"AFConnection"16I24
v40@0:8@"AFConnection"16@"NSDictionary"24@"NSURL"32
v32@0:8@"AFConnection"16@"INImage"24
v32@0:8@"AFConnection"16@"NSString"24
v40@0:8@"AFConnection"16@"NSString"24@"NSError"32
v40@0:8@"AFConnection"16@"NSString"24@?<v@?B>32
v40@0:8@"AFConnection"16@"AFRequestInfo"24@?<v@?B>32
v32@0:8@"AFConnection"16@"AFAudioPlaybackRequest"24
v40@0:8@"AFConnection"16@"AFAudioPlaybackRequest"24@"NSError"32
v32@0:8@"AFConnection"16Q24
v48@0:8@"AFConnection"16q24@"INIntent"32@?<v@?BB>40
v32@0:8@"AFConnection"16q24
v36@0:8@16@24I32
v40@0:8@16q24@?32
v48@0:8@16@24@32@40
v32@0:8@"AFConnection"16@"AFXPCWrapper"24
v36@0:8@"AFConnection"16@"NSString"24I32
v40@0:8@"AFConnection"16q24@?<v@?dd@"NSError">32
v32@0:8@"AFConnection"16@"NSError"24
v32@0:8@"AFConnection"16@"SASSpeechRecognized"24
v32@0:8@"AFConnection"16@"SASSpeechPartialResult"24
v40@0:8@"AFConnection"16@"AFSpeechInterpretation"24@"NSString"32
v48@0:8@"AFConnection"16@"NSArray"24@"NSArray"32@"NSString"40
v44@0:8@16@24@32B40
v56@0:8@16@24@32@40Q48
v32@0:8@16d24
v48@0:8@16@24@32B40B44
v24@0:8@"AFDictationConnection"16
v32@0:8@"AFDictationConnection"16@"AFDictationOptions"24
v32@0:8@"AFDictationConnection"16@"NSString"24
v32@0:8@"AFDictationConnection"16@"NSError"24
v40@0:8@"AFDictationConnection"16@"NSString"24@"NSDictionary"32
v44@0:8@"AFDictationConnection"16@"NSString"24@"NSDictionary"32B40
v32@0:8@"AFDictationConnection"16@"SASMultilingualSpeechRecognized"24
v48@0:8@"AFDictationConnection"16@"NSArray"24@"NSString"32@40
v56@0:8@"AFDictationConnection"16@"NSArray"24@"NSString"32@40Q48
v40@0:8@"AFDictationConnection"16@"NSArray"24@"NSString"32
v32@0:8@"AFDictationConnection"16@"SASSpeechPartialResult"24
v32@0:8@"AFDictationConnection"16d24
v40@0:8@"AFDictationConnection"16@"NSFileHandle"24@"NSError"32
v48@0:8@"AFDictationConnection"16@"NSArray"24@"NSString"32B40B44
v32@0:8@"AFDictationConnection"16@"AFSpeechPackage"24
@24@0:8@16
v48@0:8@16@?24@?32@?40
v20@0:8B16
v40@0:8@16@24B32B36
f16@0:8
@20@0:8B16
@"AXDispatchTimer"
@"AFDictationConnection"
