ASRPreheatContextTimestamp
-[ESSelfHelper initWithTask:isSpeechAPIRequest:]
-[ESSelfHelper logFinalResultGeneratedWithEARPackage:]
-[ESSelfHelper logRequestEndedOrFailedOrCancelledWithError:recognizerComponents:averageActiveTokensPerFrame:languageModelInterpolationWeights:signalToNoiseRatioInDecibels:recognitionDurationInSec:audioDurationMs:eagerUsed:utteranceDetectionEnabled:utteranceConcatenationEnabled:cpuRealTimeFactor:numLmeDataStreams:]
floatValue
-[ESSelfHelper wrapAndEmitTopLevelEvent:timestampInTicks:]
v32@?0@"NSArray"8Q16^B24
com.apple.MobileSMS
quasarModelPath
type
com.apple.trial.NamespaceUpdate.SIRI_DICTATION_ASSETS
com.apple.trial.NamespaceUpdate.SIRI_UNDERSTANDING_ASR_ASSISTANT
trial
QuasarDir
PreferOverServer
RequiredCapabilityIdentifier
SupportsContinuousListening
SupportsOnDeviceSearch
InstalledLanguages
GeoLMAssetsInfo
mini.json
-[MAAsset(ESAdditions) _es_purgeSync]
FormatVersion
Asset: content version: %@, mastered version %@, installed %@, language: %@, path: %@
Language
-[MAAsset(ESAdditions) _es_isInstalled]
v8@?0
-[ESAssetManager _kickCatalogDownload]_block_invoke
v16@?0q8
com.apple.siri.embeddedspeech.ESAssetManager
v12@?0i8
-[ESAssetManager registerNotifications]
-[ESAssetManager installationStatusForLanguagesIgnoringCache:assetType:withDetailedStatus:withError:]
-[ESAssetManager installationStatusForLanguagesIgnoringCache:assetType:withDetailedStatus:withError:]_block_invoke
-[ESAssetManager _invalidateInstallationStatusCacheForAssetType:]
-[ESAssetManager _queryInstallationStatusForLanguagesWithError:]
%@: %@: AssetId=%@:
-[ESAssetManager installedModelInfoForAssetConfig:error:triggerDownload:]
/System/Library/SpellingKeyboardSpeechModels
-[ESAssetManager _fetchRemoteAssetForLanguage:]_block_invoke_2
-[ESAssetManager _fetchRemoteAssetForLanguage:]_block_invoke
-[ESAssetManager _installedAssetForLanguage:error:]
-[ESAssetManager _installedAssetFromFoundAssets:language:error:]
-[ESAssetManager _installedLocalAssetForLanguage:error:]
+[ESAssetManager _assetQueryForLanguage:]
-[ESAssetManager _startedDownloadingEmbeddedSpeechAsset:error:]
v16@?0@"MAProgressNotification"8
-[ESAssetManager _startedDownloadingEmbeddedSpeechAsset:error:]_block_invoke
v24@?0@"MAAsset"8^B16
-[ESAssetManager purgeInstalledAssetsExceptLanguages:assetType:error:]_block_invoke
-[ESAssetManager purgeOutdatedAssets]_block_invoke
-[ESAssetManager _purgeMobileAssetsForLanguage:error:]_block_invoke
-[ESAssetManager startMissingAssetDownload]
: %@
%@: ModelInfo=%@: AssetId=%@:
com.apple.internal.ck
disableTrialAssetDelivery
-[ESAssetManager trialAssetDeliveryEnabled:]
enableTrialAssetDelivery
Siri
trial_dictation_asset_delivery
-[ESAssetManager prepareHammerConfigFile:]
-[ESAssetManager _installedGeoLMRegionMappingForLanguage:]
-[ESAssetManager geoLMRegionIdForLanguage:location:]
-[ESAssetManager installedGeoLMRegionSpecificAssetForLanguage:regionId:mainAssetConfig:]
-[ESAssetManager _geoLMCompatibleWithMainAsset:geoAssetConfig:]
-[ESAssetManager purgeUnusedGeoLMAssetsForLangauge:]_block_invoke
q24@?0@8@16
-[ESAssetManager purgeUnusedGeoLMAssetsForLangauge:]_block_invoke_2
-[ESAssetManager _purgeUserDefaultsGeoLMAssetsInfoDictExceptLanguages:]
Installed
Installing
Not Installing
Waiting to Install
Not Supported
Unknown
EnumerateInstalledAssets
overrides
confidenceThresholds
confidenceModels
keyboardLM
locationOfInterest
spatialLocationOfInterest
interaction
search
calendarEvent
pexNamedEntity
frequency
wordConfidenceThreshold
utteranceConfidenceThreshold
charsToTrim
charsToSplit
tagName
templateName
tagNameList
minimumWordLength
\NT-contact
\NT-appname
continuousListening
shouldHandleCapitalization
QuasarModel
replicateDataPacketPersonalization
distributedEvaluation
adaptation
WallRTF
AverageActiveTokensPerFrame
lm_interp_weights
jitQueryDurationInMs
jitLmeDurationInMs
version
data
language
assetPath
PERSONALINFO
com.apple.fides.asr
com.apple.siri.speech-dictation-personalization
ModelOverrideURL
com.apple.siri.ESConnection
-[ESConnection initWithXPCConnection:]_block_invoke
-[ESConnection dealloc]
com.apple.siri.ESConnection.fidesEval
com.apple.siri.embeddedspeech.preheat-keepalive
-[ESConnection _preheatKeepAlive]
-[ESConnection _preheatKeepAlive]_block_invoke
v24@?0@"NSDictionary"8@"NSError"16
-[ESConnection fetchModelInfoForAssetConfig:triggerDownload:completion:]
-[ESConnection fetchUserDataForLanguage:completion:]_block_invoke
B8@?0
v16@?0@"CESRUserData"8
v24@?0@"CESRUserDataOptions"8@"NSError"16
-[ESConnection getOfflineAssetStatusIgnoringCache:assetType:withDetailedStatus:withCompletion:]
enableParallelLoading
+[ESConnection _speechRecognizerWithAssetConfig:geoLMRegionId:enableITN:overrides:modelOverrideURL:preloadModels:enableParallelLoading:geoLMLoadedOut:error:]
Failed to create recognizer from %@
AlreadyLoaded
Preheating
-[ESConnection preheatSpeechRecognitionWithAssetConfig:modelOverrideURL:]
 with CustomModelURL %@
Success
(none)
Failure
-[ESConnection shouldWriteDictationRecord:]
Dictation
v24@?0@"CESRModelProperties"8@"NSError"16
-[ESConnection startSpeechRecognitionWithParameters:didStartHandlerWithInfo:]
Recognizer is busy
@"NSDictionary"8@?0
v32@?0@"NSString"8@"NSString"16^B24
-[ESConnection sendSpeechCorrectionInfo:interactionIdentifier:]_block_invoke
-[ESConnection readProfileAndUserDataWithLanguage:allowOverride:completion:]
Not a dictionary: %@
Not an array: %@
orth
prons
freq
v32@?0@"NSString"8@"NSArray"16^B24
-[ESConnection updateSpeechProfileWithLanguage:modelOverridePath:existingProfile:existingAssetPath:completion:]
Could not build empty user profile
-[ESConnection updateSpeechProfileWithLanguage:modelOverridePath:existingProfile:existingAssetPath:completion:]_block_invoke_3
-[ESConnection updateSpeechProfileWithLanguage:modelOverridePath:existingProfile:existingAssetPath:completion:]_block_invoke
Empty user data
User data unchanged
Could not create user profile
UserData
+[ESConnection _parseRequiredParameter:expectedClass:domain:recipe:error:]
Missing %@ for %@
+[ESConnection _runAdaptationRecipeForNamesWithFrequency:tagNames:templateName:charSetToTrim:charSetToSplit:minimumWordLength:nameFrequencies:profile:]
+[ESConnection _runAdaptationRecipeForNamesWithFrequency:tagNames:templateName:charSetToTrim:charSetToSplit:minimumWordLength:nameFrequencies:profile:]_block_invoke_2
v32@?0@"NSString"8Q16^B24
v32@?0@"NSString"8@"NSNumber"16^B24
+[ESConnection _runAdaptationRecipeForKeyboardLMWithFrequency:tagName:templateName:charSetToTrim:charSetToSplit:minimumWordLength:userData:profile:]
+[ESConnection _runAdaptationRecipeForLocationOfInterestWithFrequency:tagName:templateName:charSetToTrim:charSetToSplit:minimumWordLength:locationOfInterestNames:profile:]
+[ESConnection _runAdaptionRecipeForCalendarEventsWithFrequency:tagName:templateName:charSetToTrim:charSetToSplit:minimumWordLength:userData:profile:]
+[ESConnection _scheduleCooldownTimer]
+[ESConnection _cancelCooldownTimer]
+[ESConnection _cooldownTimerFired]
+[ESConnection _cachedRecognizerCleanUp]
+[ESConnection purgeOutdatedAssets]_block_invoke
+[ESConnection _sendPendingAnalyticsEvents]
+[ESConnection _adaptRecipe:userData:profile:]_block_invoke
v32@?0@"NSString"8@"NSDictionary"16^B24
recipeType
-[ESConnection readTableFromURL:]
-[ESConnection runRecipeEvaluationDistributedEvaluation:recordData:attachments:completion:]
returnHypothesis
returnOverallWER
returnOverallRTF
returnPerUtteranceWER
returnPerUtteranceRTF
locale
task
sampleRate
wordSenseWhitelist
wav.scp
raw.ref
-[ESConnection runRecipeEvaluationDistributedEvaluation:recordData:attachments:completion:]_block_invoke
token
confidence
transcription
\\\S+$
EditDistance
details
modelVersion
overall-rtf
overall-wer
v24@?0@"NSData"8@"NSString"16
SiriCoreLocalSpeechUserData
-[ESConnection runDefaultAdaptationEvaluation:recordData:attachments:completion:]
Recipe has no profile
Voicemail audio file deleted by user
%@ %@
.model
Malformed overrides
ConfidenceMean
ConfidenceMin
ConfidenceMax
AlternateConfidenceMean
AlternateConfidenceMin
AlternateConfidenceMax
Baseline
CustomModel
ModelVersion
Adapted
Alignment
name
callStackReturnAddresses
callStackSymbols
reason
userInfo
(unknown C++ exception)
-[ESConnection runCorrectedTextEvaluationWithAudioDatas:recordDatas:language:samplingRate:caseSensitive:skipLME:wordSenseAccessListSet:completion:]_block_invoke
No tokenizer for %@
Interrupted corrected text evaluation during speech recognition
correctedOutput
recognizedOutput
editDistanceRecognizedCorrected
editDistanceRecognizedTTSASR
timestamp
interactionId
asrSelfComponentIdentifier
results
-[ESConnection _userProfileWithAssetConfig:modelOverridePath:overrides:foundPath:error:]
en_US_napg.json
dispatch.voc
vocdelta.voc
pg.voc
lexicon.enh
token_s.enh
mrec.psh
Error during _EARUserProfile initialization
-[ESConnection _userProfileConfigWithAssetConfig:modelOverridePath:overrides:error:]
_EARUserProfileConfig initialization failed: %@ with reason: %@
-[ESConnection _modelRootWithAssetConfig:modelOverridePath:overrides:error:]
asrSelfComponentId
asset
applicationName
metrics
tokens
alignments
uttInfos
uttInfosCompressed
alignmentReferences
usePersonalizedLM
corrected
recognized
useJIT
disableAOT
contextualData
overrideFiles
restoreAOT
evaluations
-[ESConnection runEvaluationWithDESRecordDatas:language:recipe:attachments:fidesPersonalizedLMPath:fidesPersonalizedLMTrainingAsset:scrubResult:completion:]_block_invoke
Unknown evaluation name found in alignmentReferences: %@
scoreNbest
compress
Interrupted evaluation redecoding
-[ESConnection runEvaluationWithDESRecordDatas:language:recipe:attachments:fidesPersonalizedLMPath:fidesPersonalizedLMTrainingAsset:scrubResult:completion:]_block_invoke_2
Interrupted evaluation tokenization
-[ESConnection _deleteTemporaryDirectoryIfExists:]
-[ESConnection resetCacheAndCompileAllAssetsWithCompletion:]
-[ESConnection _fetchUserDataOptionsWithAssetConfig:modelOverridePath:overrides:completion:]_block_invoke
Failed to fetch user data options, for unknown reason
-[ESConnection _writeDESRecord:oneRecordPerDay:]
-[ESConnection _writeDESRecord:oneRecordPerDay:]_block_invoke
-[ESConnection _writeDESRecord:oneRecordPerDay:]_block_invoke_2
-[ESConnection speechRecognizer:didProduceEndpointFeaturesWithWordCount:trailingSilenceDuration:eosLikelihood:pauseCounts:silencePosterior:processedAudioDurationInMilliseconds:]_block_invoke
\jit
\entity-first
-[ESConnection speechRecognizer:didProduceLoggablePackage:]_block_invoke
-[ESConnection speechRecognizer:didRecognizePartialResult:]_block_invoke
Unsupported EAR build?
Unsupported EAR package build?
-[ESConnection speechRecognizer:didFinishRecognitionWithError:]_block_invoke
recognizer-components
audioDurationMs
recognitionDurationMs
EagerUsed
numLmeDataStreams
PM-input
PM-output
tokenName
-[ESConnection speechRecognizer:didRecognizeRawEagerRecognitionCandidate:]_block_invoke_2
v16@?0@"_EARFormatter"8
-[ESConnection speechRecognizer:didRecognizeRawEagerRecognitionCandidate:]_block_invoke
lastPathComponent == %@
_ESDecompressArchiveWithURL
VoiceTriggerFidesArchive
Failed to specify compression algorithm
Failed to specify format
Failed to open file for reading
Unable to extract file to: %@
Task %@ not available for %@, supported tasks are %@
etiquette.json
ReplacementDictionaryForAssetConfig
ReplacementDictionaryForAssetConfig_block_invoke
v32@?0@"NSString"8@16^B24
voicemail_confidence_subtraction.json
sampling rate = %@
task type = %@
far field = %@
device ID = %@
Bluetooth device ID = %@
PersonalizationRecipeForAssetConfig
personalization.json
v32@?0@"CESRVocabularyCategory"8@"NSSet"16^B24
\correction-first
\NT-correction
AddWordsToUserProfile
ReadAudioDataFromFileURL
\\\S*$
Insertions
Deletions
Substitutions
ReferenceSize
\contact-first
CONTACTFIRSTNAME
\contact-middle
CONTACTMIDDLENAME
\contact-last
CONTACTLASTNAME
\contact-nickname
\app-first
APPNAMEFIRSTNAME
\company-first
COMPANYFIRSTNAME
\interaction-first
\interaction-middle
\interaction-last
INLINEFIRSTNAME
\contact-first-derived
\contact-middle-derived
\contact-last-derived
\contact-nickname-derived
Recipe evaluation failed
Empty recognition Result
Error
UtteranceLength
NumberOfNonTerminals
WordsAboveThreshold
UtteranceAboveThreshold
Override file is not found in attachments or device
restoreJIT
configurationFile
JIT LME: JIT profile builder is not initialized
JIT LME: required configuration/file is missing
JIT LME: configuration file is not found in attachments or device
zlibCompressedJson
AFSpeechLatticeMitigatorResultForEar
dictationUIInteractionIdentifier
interactionIdentifier
samplingTimestamp
codec
samplingRate
inferenceSpeakerCode
numTrainedFrames
trainingNnetVersion
isSpeakerCodeUsed
-[ESStoreAudioData initWithUUIDString:language:task:codec:samplingRate:inferenceSpeakerCode:numTrainedFrames:trainingNnetVersion:isSpeakerCodeUsed:isSamplingForDictation:selfLogger:]
-[ESStoreAudioData saveAudioToDisk]
-[ESStoreAudioData _deleteItemAtPath:]
-[ESStoreAudioData _cleanupCacheAndReset:]
-[ESStoreAudioData _saveAudioToCache:]
-[ESStoreAudioData _moveAudioToVarMobile:]
%@.plist
-[ESStoreAudioData _saveAudioMetadataToFilePath:]
-[ESStoreAudioData _createAudioFilePath]
%.0f
%@_%@_%@.pcm
unixTime
samplingDate
success
failed
errorCode
errorDomain
UNDEFINED
description
underlyingErrorCode
underlyingErrorDomain
Audio file to be moved nil
Sampling Date is nil
Unable to create sampling directory
Unable to create dated directory
status
com.apple.siri.embeddedspeech
com.apple.private.des-service
Rejecting %@, no %@ or %@ entitlement
timeZoneWithAbbreviation:
setTimeZone:
doubleValue
dateWithTimeIntervalSince1970:
date
currentCalendar
components:fromDate:toDate:options:
calculateDiffInDaysFromTimestamp:
init
isLoggingAllowedForCurrentRequestWithTask:isSpeechAPIRequest:
UUID
isTranscriptLoggingAllowedForCurrentRequestWithTask:
sharedPreferences
isDictationHIPAACompliant
siriDataSharingOptInStatus
isEqualToString:
initWithNSUUID:
setUuid:
setComponent:
setSource:
setTarget:
sharedStream
emitMessage:
setExists:
numberWithUnsignedLongLong:
setTimestampInTicks:
setStartedOrChanged:
setFailed:
setStatus:
setEnded:
countByEnumeratingWithState:objects:count:
timestampInTicks
wrapAndEmitTopLevelEvent:timestampInTicks:
setLinkId:
setDialogContexts:
setTask:
stringByReplacingOccurrencesOfString:withString:
convertLanguageCodeToSchemaLocale:
setModelLocale:
boolValue
setIsHighQualityAsset:
unsignedLongLongValue
setSpeechProfileAgeInNs:
initWithUUIDString:
setDictationUiInteractionId:
setDatapackVersion:
setHammerVersion:
setGeoLanguageModelRegion:
setGeoLanguageModelLoaded:
setPortraitExperimentVariantName:
setPhoneticMatchInput:
setPhoneticMatchOutput:
setUnrepairedPostItn:
recognition
interpretationIndices
count
isFinal
setIsFinal:
setPackage:
correctPartialResultIndexList
setCorrectPartialResultIndexLists:
preITNRecognition
oneBest
silenceStart
utteranceStart
numberWithDouble:
addObject:
setTokenSilenceStartTimeInNsLists:
componentsJoinedByString:
UTF8String
setPersonalizedLanguageModelAgeInNs:
floatValue
setPersonalizedLanguageModelWeight:
setAverageActiveTokensPerFrame:
setSignalToNoiseRatioInDecibels:
setRecognitionDurationInNs:
setAudioDurationInNs:
setEagerEnabled:
setCpuRealTimeFactor:
setNumLanguageModelEnrollmentDataStreams:
setUtteranceDetectionEnabled:
setUtteranceConcatenationEnabled:
setContinuousListeningEnabled:
componentsSeparatedByString:
objectAtIndexedSubscript:
setFrontend:
setDecoder:
setDecodable:
setRecognizerComponents:
setStartTimeInNs:
setEndTimeInNs:
valueForKey:
setWeights:
setLanguageModelInterpolationWeights:
code
setMetrics:
setReason:
setCancelled:
setErrorCode:
domain
setErrorDomain:
userInfo
objectForKey:
setUnderlyingErrorCode:
setUnderlyingErrorDomain:
setSampledAudioStorageFailureReason:
setAsrId:
setEventMetadata:
setPreheatContext:
setRequestContext:
setPartialResultGenerated:
setPackageGenerated:
setRecognitionResultTier1:
setFinalResultGenerated:
setIntermediateUtteranceInfoTier1:
setInitializationContext:
setAssetLoadContext:
setLanguageModelEnrollmentContext:
setJitLanguageModelEnrollmentEndedTier1:
setAudioPacketArrivalContext:
setFirstAudioPacketProcessed:
setFinalAudioPacketContainingSpeechReceived:
setSampledAudioFileStored:
setSampledAudioFileStorageFailed:
emitMessage:timestamp:
createPreheatStartedOrChangedEvent
createPreheatFailedEvent
createPreheatEndedEventWithPreheatAlreadyDone:
initWithTask:isSpeechAPIRequest:
logRequestLinkWithRequestId:
logPendingPreheatContextEvents:
logInitializationStartedOrChangedWithTimeInTicks:
logInitializationEnded
logAssetLoadStartedOrChanged
logAssetLoadEnded
logJitLmeStartedOrChangedWithTimeInTicks:
logJitLmeEndedAndEndedTier1WithDialogContext:
logAudioPacketArrivalStartedOrChangedWithTimeInTicks:
logAudioPacketArrivalEndedWithTimeInTicks:
logFirstAudioPacketProcessed
logFinalAudioPacketContainingSpeechReceivedWithTimeInTicks:
logRequestStartedOrChangedWithTask:modelLocale:modelVersion:isHighQualityAsset:hammerVersion:geoLanguageModelRegion:geoLanguageModelLoaded:speechProfileAgeInSec:dictationUIInteractionId:portraitExperimentVariantName:
logPartialResultGenerated
logIntermediateUtteranceInfoTier1WithPmInput:pmOutput:
logPackageGeneratedAndRecognitionResultTier1WithEARPackage:
logFinalResultGeneratedWithEARPackage:
logRequestEndedOrFailedOrCancelledWithError:recognizerComponents:averageActiveTokensPerFrame:languageModelInterpolationWeights:signalToNoiseRatioInDecibels:recognitionDurationInSec:audioDurationMs:eagerUsed:utteranceDetectionEnabled:utteranceConcatenationEnabled:cpuRealTimeFactor:numLmeDataStreams:
logSampledAudioFileStoredSuccessfully
logSampledAudioFileStoredWithError:customFailureReason:
asrId
recognitionTask
unrepairedPostItn
personalizedLmWeight
setPersonalizedLmWeight:
personalizedLmAgeInSec
setPersonalizedLmAgeInSec:
continuousListeningEnabled
.cxx_destruct
_asrId
_recognitionTask
_packageLogged
_isTranscriptLoggingAllowedForCurrentRequest
_continuousListeningEnabled
_unrepairedPostItn
_personalizedLmWeight
_personalizedLmAgeInSec
T@"NSUUID",R,N,V_asrId
T@"NSString",R,N,V_recognitionTask
T@"NSString",&,N,V_unrepairedPostItn
T@"NSNumber",&,N,V_personalizedLmWeight
T@"NSNumber",&,N,V_personalizedLmAgeInSec
TB,N,V_continuousListeningEnabled
T@"NSNumber",&,N
setRawRecognition:
setPostItn:
tokenSausage
setPhrases:
setUtterances:
linkId
orderedSetWithArray:
array
setInterpretationIndices:
objectAtIndex:
unsignedIntegerValue
setTokens:
containsObject:
indexOfObject:
numberWithUnsignedInteger:
arrayByAddingObject:
enumerateObjectsUsingBlock:
copy
setInterpretations:
initWithCapacity:
start
hasSpaceAfter
setAppendSpaceAfter:
setSilenceStartTimeInNs:
confidence
setConfidence:
tokenName
setText:
phoneSequence
setPhoneSequence:
ipaPhoneSequence
setIpaPhoneSequence:
setLinkIndex:
markRecognition
sendEvent
recognitionEndTime
setRecognitionEndTime:
applicationName
setApplicationName:
interactionId
setInteractionId:
taskName
setTaskName:
hasRecognizedAnything
_hasRecognizedAnything
_recognitionEndTime
_applicationName
_interactionId
_taskName
Td,N,V_recognitionEndTime
T@"NSString",C,N,V_applicationName
T@"NSString",C,N,V_interactionId
T@"NSString",C,N,V_taskName
TB,R,N,V_hasRecognizedAnything
_es_quasarModelPath
stringByAppendingPathComponent:
purgeCompiledRecognizerModelsWithConfiguration:
purgeSync
attributes
integerValue
_es_requiredCapabilityIdentifier
minimumSupportedConfigurationVersion
maximumSupportedConfigurationVersion
_es_contentVersion
_es_masteredVersion
_es_isInstalled
_es_language
_es_path
stringWithFormat:
stringValue
getLocalFileUrl
path
state
defaultManager
fileExistsAtPath:isDirectory:
refreshState
_es_purgeSync
compare:options:
compare:
_es_compareByVersion:
_es_isCompatibleWithThisDevice
_es_description
_es_isDownloading
_es_status
_es_quasarDir
_es_preferOverServer
_es_moreRecentAsset:
_es_supportsContinuousListening
_es_supportsOnDeviceSearch
timeIntervalSinceReferenceDate
_exponentialBackoffIntervalWithAttempts:
startCatalogDownload:then:
registerNotifications
distantPast
dictionary
trialAssetDeliveryEnabled:
_kickCatalogDownload
_invalidateInstallationStatusCacheForAssetType:
dealloc
objectForKeyedSubscript:
installationStatusForLanguagesForAssetType:includeDetailedStatus:error:
_queryInstallationStatusForLanguagesWithError:
setObject:forKeyedSubscript:
installationStatusForLanguagesForAssetType:error:
_assetQueryForLanguage:
queryMetaDataSync
numberWithInteger:
dictionaryWithObjects:forKeys:count:
errorWithDomain:code:userInfo:
results
modelTypeStatusStringAndVersionWithAsset:
setObject:forKey:
isEqual:
modelAttributesStatusStringWithAsset:
assetId
standardUserDefaults
stringArrayForKey:
mutableCopy
removeObject:
logLocalRecognitionAssetEvictedForLanguage:
synchronize
installedModelInfoForAssetConfig:error:
installedModelInfoForAssetConfig:error:triggerDownload:
language
assetType
sharedInstance
installedAssetWithConfig:regionId:triggerDownload:
modelQualityTypeStatusStringWithConfig:
numberWithBool:
setAssetsProvisionalForAssetType:
promoteAssetsForAssetType:
_installedAssetFromFoundAssets:language:error:
queryMetaData:
_installedLocalAssetForLanguage:error:
_startedDownloadingEmbeddedSpeechAsset:error:
initWithType:
returnTypes:
addKeyValuePair:with:
isStalled
totalWritten
totalExpected
expectedTimeRemaining
spaceCheck:
isBelowLimitForLocale:
attachProgressCallBack:
startDownload:then:
_purgeUserDefaultsGeoLMAssetsInfoDictExceptLanguages:
purgeInstalledAssetsExceptLanguages:assetType:error:
allKeys
cancelDownloadSync
assistantIsEnabled
languageCode
initWithLanguage:assetType:
installedAssetWithConfig:
setWithObject:
_purgeMobileAssetsForLanguage:error:
stringByAppendingFormat:
initWithSuiteName:
isSiriXEnabled
length
jsonFilenameForAssetType:
initWithConfig:
_installedGeoLMRegionMappingForLanguage:
coordinate
initWithConfiguration:
regionIdForLatitude:longitude:
installedAssetWithConfig:regionId:
_geoLMCompatibleWithMainAsset:geoAssetConfig:
_updateGeoLMAssetsInfoDictWithRegionId:language:
purgeInstalledAssetForAssetType:language:regionId:error:
version
_loadGeoLMAssetsInfoDictForLanguage:
timeIntervalSince1970
_updateUserDefaultsWithGeoLMAssetsInfoDict:language:
keysSortedByValueUsingComparator:
lastObject
removeObjectForKey:
supportedLanguagesWithAssetType:
_userDefaultsGeoLMAssetsInfoDictKeyForLangauge:
dictionaryForKey:
stringByAppendingString:
installationStatusForLanguagesIgnoringCache:assetType:withDetailedStatus:withError:
installedQuasarModelPathForAssetConfig:error:
installedQuasarModelPathForAssetConfig:error:triggerDownload:
prepareModelInfo:withAssetType:
promoteModelInfo:withAssetType:
_fetchRemoteAssetForLanguage:
_installedAssetForLanguage:error:
installedAssetSizeWithError:
purgeOutdatedAssets
startMissingAssetDownload
modelQualityTypeStatusStringWithAsset:
installedHammerConfigFileForLanguage:
prepareHammerConfigFile:
promoteHammerConfigFile
geoLMRegionIdForLanguage:location:
installedGeoLMRegionSpecificAssetForLanguage:regionId:mainAssetConfig:
purgeUnusedGeoLMAssetsForLangauge:
_queue
_languageInstallationCache
_maAssetUpdatedNotificationToken
_dictationAssetUpdatedNotificationToken
_assistantAssetUpdatedNotificationToken
_lastCatalogDownload
_numFailedCatalogDownloadAttempts
_lastFailedCatalogDownload
_recognizerAssetPathsInUse
_profileAssetPathsInUse
_geoLMAssetsInfoDict
longLongValue
numberWithLongLong:
allocWithZone:
numberOfInsertions
setNumberOfInsertions:
numberOfSubstitutions
setNumberOfSubstitutions:
numberOfDeletions
setNumberOfDeletions:
totalCost
setTotalCost:
copyWithZone:
incrementInsertions
incrementDeletions
incrementSubstitutions
incrementCost
_numberOfInsertions
_numberOfDeletions
_numberOfSubstitutions
_totalCost
Tq,N,V_numberOfInsertions
Tq,N,V_numberOfDeletions
Tq,N,V_numberOfSubstitutions
Tq,N,V_totalCost
setModelType:
modelType
setModelRoot:
modelRoot
T@"NSString",C,N
_setQueue:
_UUID
cancelRecognition
invalidate
setInterruptionHandler:
setInvalidationHandler:
remoteObjectProxy
fetchAssetsForAssetConfig:completion:
fetchModelInfoForAssetConfig:completion:
fetchModelInfoForAssetConfig:triggerDownload:completion:
setWithArray:
initWithModelVersion:modelType:modelRoot:
data
dictionaryRepresentation
dataWithJSONObject:options:error:
fetchUserDataWithLanguage:options:keepGoing:completion:
_fetchUserDataOptionsWithAssetConfig:modelOverridePath:overrides:completion:
getOfflineAssetStatusIgnoringCache:assetType:withDetailedStatus:withCompletion:
getOfflineAssetStatusIgnoringCache:assetType:withCompletion:
_speechRecognizerWithAssetConfig:geoLMRegionId:enableITN:overrides:modelOverrideURL:preloadModels:enableParallelLoading:geoLMLoadedOut:error:
switchToNewAssetsForAssetType:
processInfo
systemUptime
activeConfigurationForEverything
setSamplingRateFilter:
setTaskTypeFilter:
setFarFieldFilter:
setDeviceIdFilter:
setBluetoothDeviceIdFilter:
initWithConfiguration:useQuasarFormatter:activeConfiguration:
setDetectUtterances:
setRecognizeEagerCandidates:
setConcatenateUtterances:
logLocalRecognitionLoadedForLanguage:duration:
preheatSpeechRecognitionWithAssetConfig:modelOverrideURL:
_preheatKeepAlive
_clearPendingAnalyticsEvents
_addPendingAnalyticsEvent:
_clearPendingSelfPreheatEvents
_addPendingSelfPreheatEvent:
_scheduleCooldownTimer
modelVersion
startSpeechRecognitionWithParameters:didStartHandlerWithInfo:
_sendPendingAnalyticsEvents
startRequestActivityWithCompletion:
overrides
continuousListening
shouldHandleCapitalization
modelOverrideURL
task
initWithLanguage:task:
location
interruptTraining
isEqualToDictionary:
modelInfo
_delegate
speechServiceDidSelectRecognitionModelWithModelProperties:
isSpeechAPIRequest
speechProfileDataLastModifiedDataForLanguage:
timeIntervalSinceNow
dictationUIInteractionIdentifier
requestIdentifier
censorSpeech
setRecognitionReplacements:
enumerateKeysAndObjectsUsingBlock:
setRecognitionConfidenceSubtraction:
disableDeliveringAsrFeatures
endpointStart
setEndpointStart:
profile
setUserProfileData:
_modelRootWithAssetConfig:modelOverridePath:overrides:error:
jitGrammar
addObjectsFromArray:
initWithConfiguration:taskName:applicationName:
_userProfileWithAssetConfig:modelOverridePath:overrides:foundPath:error:
createInlineLmeUserDataForContextStrings:
dataProfile
contextualData
fetchNamedEntitiesWithTimeInterval:
createInlineLmeUserDataForContextData:speechProfile:
setJitProfileData:
inputOrigin
setInputOrigin:
setExtraLmList:
detectUtterances
deliverEagerPackage
maximumRecognitionDuration
setMaximumRecognitionDuration:
farField
setFarField:
setAllowUtteranceDelay:
setFormatAcrossUtterances:
narrowband
codec
activeConfiguration
farFieldFilter
setByAddingObject:
samplingRateFilter
taskTypeFilter
setActiveConfiguration:
runRecognitionWithResultStream:speakerCodeWriter:language:task:samplingRate:
sharedManager
isRequestSelectedForSamplingFromConfigForLanguage:
updateRequestCountWithFlag:
shouldStoreAudioOnDevice
isRequestSelectedForSamplingForTask:
secureOfflineOnly
siriDataSharingOptedIn
loggingContext
UUIDString
recordWithLanguage:task:context:narrowband:farField:interactionIdentifier:asrSelfComponentIdentifier:pluginId:
setProfile:
originalAudioFileURL
setOriginalAudioFileURL:
shouldWriteDictationRecord:
recordWithLanguage:task:context:narrowband:farField:interactionIdentifier:asrSelfComponentIdentifier:pluginId:frequency:
speakerCodeInfo
inferenceSpeakerCode
numFrames
nnetVersion
isSpeakerCodeUsed
initWithUUIDString:language:task:codec:samplingRate:inferenceSpeakerCode:numTrainedFrames:trainingNnetVersion:isSpeakerCodeUsed:isSamplingForDictation:selfLogger:
removeAllObjects
bytes
addAudioSamples:count:
addAudioPacket:
updateAudioDuration:
endAudio
_cancelCooldownTimer
correctedText
interactionIdentifier
setCorrectedText:
_writeDESRecord:oneRecordPerDay:
_writeDESRecord:
offlineDictationProfileOverridePath
dataWithContentsOfFile:options:error:
dictionaryWithContentsProfilePathForLanguage:errorOut:
JSONObjectWithData:options:error:
objectEnumerator
nextObject
initWithOrthography:pronunciations:tagName:frequency:
addWordWithParts:templateName:
readUserProfile:
peopleSuggesterConfig
contactsCount
setPeopleSuggesterContactsCount:
bestContactsCount
setBestPeopleSuggesterContactsCount:
bestContactsBonus
setBestPeopleSuggesterContactsBonus:
description
componentsSeparatedByCharactersInSet:
arrayWithObjects:count:
firstObject
pronunciationsForOrthography:
keyboardLMDynamicVocabularyItems
dictionaryWithDictionary:
whitespaceCharacterSet
countForObject:
eventTitles
eventLocationNames
arrayByAddingObjectsFromArray:
stringByTrimmingCharactersInSet:
_runAdaptationRecipeForKeyboardLMWithFrequency:tagName:templateName:charSetToTrim:charSetToSplit:minimumWordLength:userData:profile:
locationOfInterestNames
_runAdaptationRecipeForLocationOfInterestWithFrequency:tagName:templateName:charSetToTrim:charSetToSplit:minimumWordLength:locationOfInterestNames:profile:
spatialLocationOfInterestNames
interactionSenderDisplayNames
_runAdaptationRecipeForNamesWithFrequency:tagNames:templateName:charSetToTrim:charSetToSplit:minimumWordLength:nameFrequencies:profile:
searchEventValues
_runAdaptionRecipeForCalendarEventsWithFrequency:tagName:templateName:charSetToTrim:charSetToSplit:minimumWordLength:userData:profile:
pexNamedEntityNames
_cooldownTimerFired
_cachedRecognizerCleanUp
releaseClients
sharedAnalytics
logEvents:
_parseRequiredParameter:expectedClass:domain:recipe:error:
characterSetWithCharactersInString:
_runAdaptationRecipeForDomain:frequency:tagNames:templateName:charSetToTrim:charSetToSplit:minimumWordLength:userData:profile:
runDefaultAdaptationEvaluation:recordData:attachments:completion:
runRecipeEvaluationDistributedEvaluation:recordData:attachments:completion:
stringWithContentsOfURL:encoding:error:
whitespaceAndNewlineCharacterSet
rangeOfString:
substringToIndex:
substringFromIndex:
URLByAppendingPathComponent:
readTableFromURL:
_speechRecognizerWithAssetConfig:enableITN:error:
_deleteTemporaryDirectoryIfExists:
recognitionResultsWithAudioData:userProfileData:language:task:samplingRate:extraLanguageModel:
preITNTokens
setValue:forKey:
regularExpressionWithPattern:options:error:
firstMatchInString:options:range:
range
substringWithRange:
numberWithFloat:
readProfileAndUserDataWithLanguage:allowOverride:completion:
initForReadingFromData:error:
setClass:forClassName:
decodeObjectOfClass:forKey:
finishDecoding
samplingRate
audioPackets
appendData:
userData
appendString:
fileURLWithPath:
createDirectoryAtURL:withIntermediateDirectories:attributes:error:
writeToURL:atomically:encoding:error:
name
callStackReturnAddresses
callStackSymbols
reason
initWithDomain:code:userInfo:
_fidesEvalQueue
initWithNcsRoot:
_invalidated
recordFromData:
recognizedText
tokenize:
removeObjectAtIndex:
timestamp
asrSelfComponentIdentifier
initWithConfiguration:language:overrides:sdapiOverrides:generalVoc:emptyVoc:pgVoc:lexiconEnh:tokenEnh:paramsetHolder:
initWithConfiguration:overrides:
fileExistsAtPath:
concatenatedAudioPackets
addEntriesFromDictionary:
setScoreNbest:
setScoreNbestExtraLmList:
setEnableSpeakerCodeTraining:
recognitionUtterenceStatistics
recognitionUtteranceInfos
removeItemAtURL:error:
compileRecognizerModelsWithConfiguration:
loadConfigs
deleteAllRecordsForPlugin:completion:
_userProfileConfigWithAssetConfig:modelOverridePath:overrides:error:
hasData
saveOneRecordPerDay
save
pluginId
setUserData:
speechServiceDidProduceEndpointFeaturesWithWordCount:trailingSilenceDuration:eosLikelihood:pauseCounts:silencePosterior:processedAudioDurationInMilliseconds:
speechServiceDidProduceLoggablePackage:
performSelector:withObject:
rawRecognition
phrases
interpretations
tokens
text
hasSuffix:
setRecognizedText:
unrepairedRecognition
packetArrivalTimestampFromAudioTime:
speechServiceDidRecognizeTokens:
raise:format:
utterances
concatenateUtterances
speechServiceDidRecognizePackage:
recognitionStatistics
speechServiceDidFinishRecognitionWithStatistics:error:
saveAudioToDisk
speechServiceDidProcessAudioDuration:
nBest
formattedRecognitionWithNBestList:
speechServiceDidRecognizeRawEagerRecognitionCandidate:
getFormatterWithBlock:
initialize
_adaptRecipe:userData:profile:
getRecognizerQueue
class
self
performSelector:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
debugDescription
TQ,R
T#,R
T@"NSString",R,C
speechRecognizer:didRecognizePartialResult:
speechRecognizer:didFinishRecognitionWithError:
speechRecognizer:didRecognizeFinalResults:
speechRecognizer:didRecognizeFinalResults:tokenSausage:nBestChoices:
speechRecognizer:didRecognizeFinalResultPackage:
speechRecognizer:didProcessAudioDuration:
speechRecognizer:didRecognizeRawEagerRecognitionCandidate:
speechRecognizer:didProduceEndpointFeaturesWithWordCount:trailingSilenceDuration:eosLikelihood:pauseCounts:silencePosterior:processedAudioDurationInMilliseconds:
speechRecognizer:didRecognizePartialResultNbest:
speechRecognizer:didProduceLoggablePackage:
resetCacheAndCompileAllAssetsWithCompletion:
preheatSpeechRecognitionWithLanguage:modelOverrideURL:
startSpeechRecognitionWithParameters:didStartHandler:
finishAudio
createSpeechProfileWithLanguage:modelOverridePath:JSONData:completion:
updateSpeechProfileWithLanguage:modelOverridePath:existingProfile:existingAssetPath:completion:
getOfflineDictationStatusIgnoringCache:withCompletion:
fetchAssetsForLanguage:completion:
fetchModelPropertiesForAssetConfig:completion:
fetchUserDataForLanguage:completion:
runAdaptationRecipeEvaluation:recordData:attachments:completion:
runCorrectedTextEvaluationWithAudioDatas:recordDatas:language:samplingRate:caseSensitive:skipLME:wordSenseAccessListSet:completion:
getInstalledAssetSizeWithCompletion:
purgeInstalledAssetsExceptLanguages:completion:
purgeInstalledAssetsExceptLanguages:assetType:completion:
setAssetsPurgeabilityExceptLanguages:assetType:
writeDESRecord
sendSpeechCorrectionInfo:interactionIdentifier:
invalidatePersonalizedLM
removePersonalizedLMForFidesOnly:completion:
runEvaluationWithDESRecordDatas:language:recipe:attachments:fidesPersonalizedLMPath:fidesPersonalizedLMTrainingAsset:scrubResult:completion:
deleteAllDESRecordsForDictationPersonalizationWithCompletion:
invalidateUaapLm
initWithXPCConnection:
_recognizer
_audioBuffer
_disableDeliveringAsrFeatures
_connection
_lastRecognizedPackage
_bufferedAudioPackets
_bufferedAudioEnded
_validDomains
_requestCompletion
_storeAudioData
_biomeRecord
_selfHelper
_samplingRate
_audioDurationMs
_processedAudioDuration
_firstAudioPacketReceivedTime
_firstAudioPacketTimeUntilFirstPartial
_lastAudioPacketReceivedTime
_firstAudioPacketReceivedTimeInTicks
_lastAudioPacketReceivedTimeInTicks
_firstAudioPacketProcessedTime
_localMetrics
_recognitionBeginTime
_recognitionAbsoluteEndTime
_speakerCodeWriter
_weakFidesRecognizer
_lastWordCount
_taskToUse
_desRecord
_desRecordDictation
predicateWithFormat:
filteredArrayUsingPredicate:
fileURLWithPath:isDirectory:
fileSystemRepresentation
stringWithUTF8String:
tasks
deviceIdFilter
bluetoothDeviceIdFilter
removeAllWords
contactWordsWithFrequency
vocabularyWords
tagName
templateName
corrections
appNames
initWithOrthography:pronunciations:tag:
signalEndOfUserData
components
frequency
assetWithURL:
tracksWithMediaType:
assetReaderWithAsset:error:
assetReaderAudioMixOutputWithAudioTracks:audioSettings:
canAddOutput:
addOutput:
startReading
copyNextSampleBuffer
dataWithBytes:length:
setObject:atIndexedSubscript:
lowercaseString
stringByReplacingMatchesInString:options:range:withTemplate:
reverseObjectEnumerator
allObjects
lastPathComponent
compressedDataUsingAlgorithm:error:
base64EncodedStringWithOptions:
setStartTime:
setSilenceStartTime:
setEndTime:
setRemoveSpaceBefore:
setConfidenceScore:
audioAnalytics
latticeMitigatorResult
initWithRecognition:rawRecognition:audioAnalytics:isFinal:utteranceStart:latticeMitigatorResult:
acousticFeatures
speechRecognitionFeatures
initWithSpeechRecognitionFeatures:acousticFeatures:snr:
acousticFeatureValuePerFrame
frameDuration
initWithAcousticFeatureValue:frameDuration:
score
threshold
initWithResults:score:threshold:
initWithPhrases:utterances:processedAudioDuration:
initWithInterpretationIndices:confidenceScore:
confidenceScore
setIsLowConfidence:
setUUIDString:
setLanguage:
component
_createAudioFilePath
_saveAudioToCache:
_moveAudioToVarMobile:
_logAudioSampledEventsWithStatus:error:customReasonForFailure:
_cleanupCacheAndReset:
deleteItemAtFilePath:
_deleteItemAtPath:
cleanupCacheAndReset
writeToFile:options:error:
pathComponents
samplingDateAsString
createSamplingDirectory
moveItemAtPath:toPath:error:
stringByDeletingPathExtension
_saveAudioMetadataToFilePath:
writeToFile:atomically:
_createCachesDirectoryIfItDoesNotExist
sampledCachesSubDirectoryPath
initWithDictionary:
localizedDescription
logEventWithType:context:
_trimAudioIfNeeded:
setCodec:
setSamplingRate:
setAudioPackets:
setHasRecognizedAnything:
numTrainedFrames
trainingNnetVersion
isSamplingForDictation
selfLogger
setSelfLogger:
audioMetadata
setAudioMetadata:
collectedAudioDurationMS
setCollectedAudioDurationMS:
currentAudioFilePath
setCurrentAudioFilePath:
logPrefix
setLogPrefix:
_isSpeakerCodeUsed
_isSamplingForDictation
_UUIDString
_language
_task
_codec
_audioPackets
_inferenceSpeakerCode
_numTrainedFrames
_trainingNnetVersion
_selfLogger
_audioMetadata
_collectedAudioDurationMS
_currentAudioFilePath
_logPrefix
T@"NSString",C,N,V_UUIDString
T@"NSString",C,N,V_language
T@"NSString",C,N,V_task
T@"NSString",&,N,V_codec
TQ,N,V_samplingRate
T@"NSMutableData",&,N,V_audioPackets
TB,N,V_hasRecognizedAnything
T@"NSString",R,N,V_inferenceSpeakerCode
T@"NSNumber",R,N,V_numTrainedFrames
T@"NSNumber",R,N,V_trainingNnetVersion
TB,R,N,V_isSpeakerCodeUsed
TB,R,N,V_isSamplingForDictation
T@"ESSelfHelper",&,N,V_selfLogger
T@"NSMutableDictionary",&,N,V_audioMetadata
Td,N,V_collectedAudioDurationMS
T@"NSString",C,N,V_currentAudioFilePath
T@"NSString",C,N,V_logPrefix
valueForEntitlement:
setExportedInterface:
setExportedObject:
setRemoteObjectInterface:
resume
listener:shouldAcceptNewConnection:
enableTransactions
serviceListener
setDelegate:
ESUtilities
ESSelfHelper
Timestamp
ESBiomeRecord
ESAdditions
ESAssetManager
ESAlignmentState
NSCopying
ESConnectionModelInfo
ESConnection
_EARSpeechRecognitionResultStream
NSObject
CESRSpeechService
ESStoreAudioData
ESListenerDelegate
NSXPCListenerDelegate
q24@0:8@16
@16@0:8
@20@0:8B16
@28@0:8@16B24
B28@0:8@16B24
B24@0:8@16
v24@0:8@16
v16@0:8
v92@0:8@16@24@32@40@48@56B64@68@76@84
v32@0:8@16@24
v104@0:8@16@24@32@40@48@56@64@72B80B84@88@96
v32@0:8@16q24
B16@0:8
v20@0:8B16
@"NSUUID"
@"NSString"
@"NSNumber"
d16@0:8
v24@0:8d16
q16@0:8
@24@0:8@16
d24@0:8Q16
@40@0:8B16Q20B28^@32
v24@0:8Q16
@24@0:8^@16
@32@0:8@16^@24
@36@0:8@16^@24B32
v32@0:8@16Q24
@40@0:8@16@24^@32
B32@0:8@16^@24
B40@0:8@16Q24^@32
B24@0:8Q16
@32@0:8@16@24
@40@0:8@16@24@32
B32@0:8@16@24
@"NSObject<OS_dispatch_queue>"
@"NSMutableDictionary"
@24@0:8^{_NSZone=}16
v24@0:8q16
@36@0:8@16B24^@28
@76@0:8@16@24B32@36@44B52B56^@60^@68
@56@0:8@16#24@32@40^@48
B80@0:8d16@24@32@40@48Q56@64@72
B88@0:8@16d24@32@40@48@56Q64@72@80
v40@0:8@16@24@32
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
v48@0:8@16@24@32@40
v32@0:8@16d24
v72@0:8@16q24q32d40@48d56q64
v32@0:8@"_EARSpeechRecognizer"16@"_EARSpeechRecognitionResult"24
v32@0:8@"_EARSpeechRecognizer"16@"NSError"24
v32@0:8@"_EARSpeechRecognizer"16@"NSArray"24
v48@0:8@"_EARSpeechRecognizer"16@"NSArray"24@"NSArray"32@"NSArray"40
v32@0:8@"_EARSpeechRecognizer"16@"_EARSpeechRecognitionResultPackage"24
v32@0:8@"_EARSpeechRecognizer"16d24
v32@0:8@"_EARSpeechRecognizer"16@"_EARSpeechRecognition"24
v72@0:8@"_EARSpeechRecognizer"16q24q32d40@"NSArray"48d56q64
Vv24@0:8@?16
Vv32@0:8@16@24
Vv32@0:8@16@?24
Vv24@0:8@16
Vv48@0:8@16@24@32@?40
Vv56@0:8@16@24@32@40@?48
Vv36@0:8B16Q20@?28
Vv40@0:8B16Q20B28@?32
Vv28@0:8B16@?20
Vv72@0:8@16@24@32Q40B48B52@56@?64
Vv36@0:8@16B24@?28
Vv40@0:8@16Q24@?32
Vv32@0:8@16Q24
Vv76@0:8@16@24@32@40@48@56B64@?68
Vv24@0:8@?<v@?@"NSError">16
Vv32@0:8@"NSString"16@"NSURL"24
Vv32@0:8@"CESRAssetConfig"16@"NSURL"24
Vv24@0:8@?<v@?>16
Vv32@0:8@"CESRSpeechParameters"16@?<v@?@"CESRModelProperties"@"NSError">24
Vv32@0:8@"CESRSpeechParameters"16@?<v@?@"NSString"@"NSString"@"NSError">24
Vv24@0:8@"NSData"16
Vv48@0:8@"NSString"16@"NSString"24@"NSData"32@?<v@?@"NSData"@"NSError">40
Vv56@0:8@"NSString"16@"NSString"24@"NSData"32@"NSString"40@?<v@?@"NSData"@"NSString"@"NSError">48
Vv36@0:8B16Q20@?<v@?@"NSDictionary"@"NSError">28
Vv40@0:8B16Q20B28@?<v@?@"NSDictionary"@"NSError">32
Vv28@0:8B16@?<v@?@"NSDictionary"@"NSError">20
Vv32@0:8@"NSString"16@?<v@?@"NSString"@"NSError">24
Vv32@0:8@"CESRAssetConfig"16@?<v@?@"NSString"@"NSError">24
Vv32@0:8@"CESRAssetConfig"16@?<v@?@"CESRModelProperties"@"NSError">24
Vv32@0:8@"NSString"16@?<v@?@"NSData">24
Vv48@0:8@"NSDictionary"16@"NSData"24@"NSArray"32@?<v@?@"NSDictionary"@"NSData"@"NSError">40
Vv72@0:8@"NSDictionary"16@"NSDictionary"24@"NSString"32Q40B48B52@"NSSet"56@?<v@?@"NSDictionary"@"NSError">64
Vv36@0:8@"NSString"16B24@?<v@?@"NSData"@"NSString">28
Vv24@0:8@?<v@?@"NSNumber"@"NSError">16
Vv32@0:8@"NSSet"16@?<v@?@"NSNumber"@"NSError">24
Vv40@0:8@"NSSet"16Q24@?<v@?B@"NSError">32
Vv32@0:8@"NSSet"16Q24
Vv32@0:8@"AFSpeechCorrectionInfo"16@"NSString"24
Vv28@0:8B16@?<v@?>20
Vv76@0:8@"NSDictionary"16@"NSString"24@"NSDictionary"32@"NSArray"40@"NSString"48@"NSString"56B64@?<v@?@"NSDictionary"@"NSError">68
v36@0:8@16B24@?28
v48@0:8@16@24@32@?40
@56@0:8@16@24@32^@40^@48
@48@0:8@16@24@32^@40
v24@0:8^@16
v28@0:8^@16B24
@"_EARSpeechRecognizer"
@"_EARSpeechRecognitionAudioBuffer"
@"NSXPCConnection"
@"AFSpeechPackage"
@"NSMutableArray"
@"NSSet"
@"ESStoreAudioData"
@"ESBiomeRecord"
@"ESSelfHelper"
@"_EARSpeakerCodeWriter"
@"CESRFidesASRRecord"
@96@0:8@16@24@32@40Q48@56@64@72B80B84@88
v40@0:8q16@24q32
@"NSMutableData"
B32@0:8@"NSXPCListener"16@"NSXPCConnection"24
%s SELF: Logging object created successfully (logging allowed for current request). asrId=%@, recognitionTask=%@, isSpeechAPIRequest=%@, isHipaaCompliant=%@, siriOptInStatus=%@, isTranscriptLoggingAllowed=%@
%s SELF: Logging disabled because it is not allowed for the current request. recognitionTask=%@, isSpeechAPIRequest=%@
%s SELF: Correct Partial Result Index List is %s, Silence Start Time List is %s
%s SELF: Encountered malformed string during SELF logging for recognizer components in speech results from recognizer. String: (%@)
%s SELF: Expected three recognizer components separated by delimiter '::'. Ex: 'dnn-rfdnn-aa-cache::dnn-lazy-16k-rfdnn-dictation::msg'
%s SELF: Encountered malformed string during SELF logging for interpolation weights in speech results from recognizer. String: %@
%s SELF: Expected interpolation weight sets separated by delimiter ';' - starting with a set of weights delimited by ',' and ending the with start/end times delimited by ':'. Ex: '0.999646,0.000354:0:4280;0.947514,0.000158:0:3859'
%s SELF: Logging ASRRequestContext->failed in SELF based on error result from recognizer.
%s SELF: Logging ASRRequestContext->cancelled with reason RECOGNITION_CANCELLED in SELF based on error result from recognizer.
%s SELF: Logging ASRRequestContext->cancelled with reason RECOGNITION_REJECTED in SELF based on error result from recognizer.
%s SELF: Logging ASRRequestContext->cancelled with reason RECOGNITION_REJECTED in SELF because nothing was recognized (SpeechNoMatch).
%s SELF: Logging ASRRequestContext->ended in SELF based on success status from recognizer.
%s SELF: Failed trying to wrap and emit top-level ASR event because event type was not mapped to loggable message type in the ASR SELF schema.
%s SELF: Wrapping and logging an event of type %@
%s Purging compiled assets if there are any.
%s Previously installed asset has been removed: %{public}@
%s Installed asset is corrupt! Triggering emergency purge %{public}@
%s Skipping catalog download because it has only been %.0f seconds
%s Skipping catalog download because it has only been %.0f seconds since last failed attempt
%s The MobileAsset catalog download result was %ld
%s The MobileAsset catalog downloaded successfully
%s Failed to register for MA asset update notifications.
%s Failed to register for dictation asset update notifications.
%s Failed to register for assistant asset update notifications.
%s Installation status for languages (ignoring cache: %@)
%s Trial asset delivery is enabled!
%s Invalidating installation status cache for %lu
%s Language installation status query failed: %@
%s MobileAsset is broken: %ld
%s Found assets: %@
%s Previously installed offline language(s) removed; installed list: [%@] -> [%@]
%s Using ASR Trial assets at %@
%s No assets available for language: %@ asset type: %{public}@
%s Falling back to MA assets for language: %@ asset type: %{public}@
%s Returning no model path for nil language
%s Remote fetch asset fetch got assets but none have been installed yet: %@
%s Async asset query failed for query=%@, error=%ld
%s Returning no installed asset for nil language
%s Recording newly installed offline language (%@) installed list is now: [%@]
%s Previously installed offline language (%@) removed; installed list is now: [%@]
%s Found %lu asset(s) for %@, with latest being (%@)
%s Starting a download because %p != %p
%s %@
%s MobileAsset is having trouble with queryMetaDataSync: %ld
%s MobileAsset said it succeeded but it didn't for %{public}@: query=%{public}@
%s No assets were found for query: %@
%s Trial asset delivery is enabled. No need to start a MobileAsset download
%s Downloading %@
%s Asset Download Progress: %lld of %lld bytes, ~%.2f seconds remaining
%s Asset Download Progress stalled at %lld of %lld bytes
%s Asset is already installed, no need to start download
%s Asset requires %lld bytes, starting download
%s Asset download successful
%s Asset download failed: %ld
%s Not enough space to download asset, size=%{public}lld
%s Asset download is already queued and in progress
%s Unexpected asset state %ld
%s Asset download state=%ld, success=%d, error=%@
%s Ignoring Purging asset: %@, language %@
%s Purging asset: %@, language %@
%s Purging failed: %@
%s Purging Trial assets failed: %@
%s Purging outdated assets.
%s Error canceling download of (%@) before fetching newer version: %ld
%s Error purging (%@) before fetching newer version: %ld
%s Purged old asset %@
%s Just ignoring %@
%s Purging failed: %lu
%s Checking for missing assets.
%s Missing Trial ASR assistant assets for %@. Starting a download.
%s Trial ASR assistant assets for %@ are already downloaded.
%s Purging all assistant ASR assets except for %@
%s Purging all assistant ASR assets
%s Encountered error trying to purge unused assistant ASR assets: %@
%s Trial asset delivery disabled for assistant assets. Bailing out of missing asset check.
%s Hit error querying installation status of MobileAssets: %@
%s Trial dictation assets for %@ are already downloaded. Purging corresponding assets from MobileAssets
%s Hit error purging assets from MobileAssets: %d %@
%s Missing trial dictation assets for %@. Starting a download.
%s Trial asset delivery disabled for dictation assets. Bailing out of missing asset check.
%s Trial asset delivery explicitly disabled!
%s Trial asset delivery explicitly enabled!
%s Hammer model info=%@
%s Exception thrown while reading hammer config
%s GeoLM: region mapping json file=%@
%s GeoLM: region mapping json file is nil Or there is no regionMapping for given language=%@
%s GeoLM: For the given location, selected regionId=%@
%s GeoLM: location is nil.
%s GeoLM: region specific [%@] geo-config json file=%@
%s GeoLM: geoLM asset exisits on device, but not compatible. Deleting...
%s GeoLM: Exception thrown while reading geo-config json
%s GeoLM: region specific asset is not found for given language=%@ regionId=%@
%s GeoLM: model-info.version doesn't match. mainASRModelInfo.version=%@ geoLMModelInfo.version=%@ mainAssetConfig=%@ geoAssetConfig=%@
%s GeoLM: Exception thrown while reading json configs
%s GeoLM: language is nil. Skipping.
%s GeoLM: regionIdToBePurged: %@, lastWhenUsed: %ld days ago
%s GeoLM: regionIdToBePurged: %@, _geoLMAssetsInfoDict count: %ld
%s GeoLM: supportedLanguages count:%ld
%s GeoLM: Going to delete: %@
%s MobileAsset is sad: %ld
%s %@ cancelling instance %@
%s %@ deallocating
%s Acquired os_transaction for dictation preheat
%s Released os_transaction for dictation preheat
%s Failing to fetch assets for nil language
%s Could not get offline language for fetch fallback: %{public}@
%s Fell back asset fetch from %{public}@ to %{public}@
%s Failed to fall back asset fetch from %{public}@ to %{public}@, got %{public}@
%s Can't get user data options: %{public}@
%s Unable to serialize user profile to JSON data: %{public}@
%s Could not get installed offline language statuses: %{public}@
%s Override json files=%@
%s Failed to create recognizer from %{public}@
%s EmbeddedSpeechMetric: Created recognizer in %lf sec from %@
%s Skipping preheat for %@; recognizer already loaded
%s Preheated for language %{public}@, asset type %{public}@, regionId %@%{public}@
%s Could not preheat for language %{public}@, asset type %{public}@, regionId %@%{public}@: %@
%s dictationCapable=%d task=%@ aneCapable=%d
%s Starting
%s Recognizer is busy
%s Interrupting training for cached recognizer
%s Cached recognizer for language %{public}@, asset type %{public}@, regionId %@ already  loaded
%s Cached recognizer is for language %{public}@, asset type %{public}@, regionId %@,  requesting recognizer for language %{public}@, asset type %{public}@, regionId %@
%s No cached recognizer.
%s EndpointStart > 0 but asr features delivery is disabled!
%s EndpointStart < 0
%s Injecting contextual data to recognizer
%s Built inline LME from contextual data, size: %zu
%s Injected %lu jit strings or contextual data to recognizer
%s Failed to build jitData for jitGrammar or contextual data
%s Failed to initialize jit profile builder due to error : %@
%s Failed to get model root, error: %@
%s Duration spent in adding jit strings = %{public}lfs
%s Set inputOrigin to: %@
%s Switching off UC/UD for this request
%s Changing active configuration from 
%@ to 
%s Create DES record
%s Cancelling delayedBlock
%s Create DES record for Dictation with interactionId=%@
%s _storeAudioData should be nil. Critical Error. Please check.
%s Interaction identifier did not match the DES record in memory
First Audio Packet
ES: First Audio Packet
%s Using override profile at %@
%s Could not use override profile at %@: %@
%s Deserialization of existing speech profile failed: %{public}@
%s Mismatch in speech profile language in content (%{public}@) and filename (%{public}@)
%s Profile version on disk (%{public}@) does not match the expected version (%{public}@)
%s Successfully deserialized existing speech profile for %@
%s Creating profile for %@
%s Re-using existing profile data because the asset (%@) is unchanged
%s Ignoring existing profile data because the asset changed (%@ to %@)
%s Cancelling profile update for %@ due to invalidation
%s Got no data from CESRUserData
%s Skipping profile update for %@ because user data has not actually changed
%s Created new profile with %ld bytes (was %ld bytes)
%s Recipe for %{public}@ is missing "%{public}@"
%s Recipe for %{public}@ contains parameter %{public}@, expected type %{public}@ but got %{public}@
%s Using name frequencies adaption for names: %@ into slot %@ for template %@
%s Ignoring name part "%@" because it is too short (minimum length is %lu)
%s Using keyboardLMAdaptation adaption for names %@ into slot %@ for template %@
%s Ignoring keyboardDynamicVocabularyItem "%@" because it is too short (minimum length is %lu)
%s Using locationOfInterestNameAdaptationFrequency adaption for names %@ into slot %@ for template %@
%s Ignoring locationOfInterestName "%@" because it is too short (minimum length is %lu)
%s Using eventLocationNameAdaptationFrequency adaption for names %@ into slot %@ for template %@
%s Ignoring calendar event word "%@" because it is too short (minimum length is %lu)
%s Cooldown timer triggered TRIClient release
%s Cooldown timer triggered asset purge
%s embeddedspeech process launch triggered asset purge
%s Sending %lu events
%s Recipe has invalid json for "%{public}@"
%s Recipe has invalid tagName for "%{public}@": "%{public}@"
%s Error executing recipe for domain %{public}@
%s Unable to load the contents of file %@: %@
%s Invalid file format
%s Running distributed evaluation for ASR
%s No attachments given, cannot run distributed evaluation
%s Failed to extract test set: %@
%s Cannot initialize recognizer for locale: %@ task: %@
%s Loaded speech profile
%s Unable to load speech profile
%s Test set contains more utterances than allowed, only running %d utterances
%s Unable to load audio file %@
%s Unable to find reference transcriptions for %@
%s Recipe has no profile
%s Stop adaption recipe. Audio file not readable. Voicemail has been deleted by user
%s Read %lu bytes from audio file
%s Using on device personalization recipe for baseline
%s Recognizer doesn't support the task %{public}@
%s Couldn't create create path for temporary confidence model overrides at %@
%s Couldn't write data to temporary confidence model file at path %@
%s Could not make baseline results
%s Failed to extract quasar model: %@
%s No recognizer created for custom model: %@
%s Could not make results with custom model
%s Profile overrides failed
%s Ignoring malformed overrides: %{public}@
%s Recipe has no recognizer
%s Could not make adapted results
%s Exception evaluating recipe: %@
%s Unknown exception evaluating recipe
%s No tokenizer for %@
%s Interrupted corrected text evaluation redecoding
%s Examining localSpeechDESRecord: %@
%s Unable to load localSpeechDESRecord
%s No audio data provided for UUID %@
%s Recognition result %@, %lu
%s Edit distance between tts ASR and original ASR %@
%s correctedOutput: %@, recognizedOutput %@
%s Set model root to %@
%s Use currently installed asset.
%s %{public}@
%s Unknown evaluation name found in alignmentReferences: %@
%s modelRoot: %@
%s No modelRoot for %@: %@
%s Unable to load audio
%s Recognizer doesn't support the task %{public}@: %@
%s Interrupted evaluation redecoding
%s Running recognition for evalName: %@
%s Failed to get override files, error: %@
%s Creating recognizer with overrides: %@
%s Using Personalized LM
%s Not using Personalized LM
%s Unable to restore speech profile
%s Using JIT LME
%s JIT LME: Injecting JIT data
%s JIT LME: Error fetching JIT data, error: %@
%s No results for evalName %@: %@
%s Tokenizing correctedText
%s Interrupted evaluation tokenization
%s Computing alignments
%s Failed to delete temporary directory: %@
%s Error when getting dictation language status: %@
%s Starting to compile dictation language: %@
%s Error when compiling dictation language model: %@
%s Starting to compile assistant language: %@
%s Error when compiling assistant language model: %@
%s Error when getting assistant language status: %@
%s Failed to fetch user data options
%s No DES record, nothing to write
%s Not saving DES Record with no data or recognition
%s Fetch user data for language: %@
%s Can't get user data options for DES record language: %@, not writing record
%s Got nil user data for DES record language: %@, not writing record
%s wordCount = %ld, trailingSilenceDuration = %ld, eosLikelihood = %f, pauseCounts = %@, silencePosterior = %f
%s Setting recognized text
%s %lu results
%s EmbeddedSpeechMetric: first audio packet to first partial result = %lf secs
Words recognized: %ld
ES: Partial Recognition
%s Audio finish to recognizer finish = %lf sec, connection is %@, error %@
%s _recognitionBeginTime (%@) is greater than _recognitionEndTime (%@)
%s Local speech recognition completed without error, write DES record when needed
%s Writing DES record after 30 seconds delay: interactionId=%@
%s Submitted delayedBlock to dispatch_after
%s #ASR on device eager formatted recognition candidate: %@
%s raw eager recognition candidate: %@
%s Could not make temporary attachment directory at %@: %@
%s Failed to specify compression algorithm: %s
%s Failed to specify format: %s
%s Start extracting archive at path: %s
%s Failed to open archive for reading: %s
%s Entry extraction path: %@
%s Unable to extract file to: %@
%s Finished extracting archive to: %@
%s Could not read %@: %@
%s Could not parse %@: %@
%s %@ is wrong type: %@
%s %@ contains bogus key/value pair: %@ => %@
%s Could not locate asset: %@
%s Could not read personalization.json: %@
%s Could not parse personalization.json: %@
%s User Profile: Starting AddWordsToUserProfile
%s VoiceMail asset could not be read: %@
%s Could not create asset reader output
%s Cannot add output
%s Could not get data pointer: %d
%s JSON serialization failed: %@
%s Compression failed: %@
%s AFSpeechLatticeMitigatorResult Score = %f, Threshold = %f
%s AFSpeechLatticeMitigatorResult nil
%s Sampling: Error while initializing ESStoreAudioData because uuid is invalid.
%s %@ Sampling: Won't save audio because - has not recognized anything or has no data.
%s %@ Sampling: Won't save audio because - _currentAudioFilePath is null
%s %@ Sampling: invalid filePath or it is null.
%s %@ Sampling: Done with cleanup of audioFile=%@ and reset of variables.
%s %@ Sampling: Failed to save audio to cache dir. Error: %@
%s %@ Sampling: Successfully saved audio file to cache dir, path=%@
%s %@ Sampling: audioFileToBeMoved is nil
%s %@ Sampling: currentSamplingDate is nil
%s %@ Sampling: Error while creating Sampled directory in /var/mobile
%s %@ Sampling: Error while creating dated Sampled directory in %@ with date - %@
%s %@ Sampling: Error while moving file from cache directory to var/mobile/Library - %@
%s %@ Sampling: Successfully moved audio file to var/mobile/Library dir, path=%@
%s %@ Sampling: Error while writing audio metadata dict to plist - %@
%s %@ Sampling: currentSamplingDateString is null
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
<key>application-identifier</key>
<string>com.apple.siri.embeddedspeech</string>
<key>com.apple.CoreRoutine.LocationOfInterest</key>
<true/>
<key>com.apple.accounts.appleaccount.fullaccess</key>
<true/>
<key>com.apple.application-identifier</key>
<string>com.apple.siri.embeddedspeech</string>
<key>com.apple.coreaudio.allow-amr-decode</key>
<true/>
<key>com.apple.coreduetd.allow</key>
<true/>
<key>com.apple.coreduetd.people</key>
<true/>
<key>com.apple.developer.homekit</key>
<true/>
<key>com.apple.frontboardservices.display-layout-monitor</key>
<true/>
<key>com.apple.locationd.effective_bundle</key>
<true/>
<key>com.apple.private.DistributedEvaluation.RecordAccess-com.apple.fides.asr</key>
<true/>
<key>com.apple.private.DistributedEvaluation.RecordAccess-com.apple.siri.speech-dictation-personalization</key>
<true/>
<key>com.apple.private.assets.accessible-asset-types</key>
<array>
<string>com.apple.MobileAsset.EmbeddedSpeech</string>
<string>com.apple.MobileAsset.EmbeddedSpeechWatch</string>
<string>com.apple.MobileAsset.EmbeddedSpeechMac</string>
</array>
<key>com.apple.private.attribution.implicitly-assumed-identity</key>
<dict>
<key>type</key>
<string>path</string>
<key>value</key>
<string>/System/Library/PrivateFrameworks/CoreEmbeddedSpeechRecognition.framework/XPCServices/com.apple.siri.embeddedspeech.xpc/com.apple.siri.embeddedspeech</string>
</dict>
<key>com.apple.private.biome.read-write</key>
<array>
<string>SiriDictation</string>
</array>
<key>com.apple.private.calendar.allow-suggestions</key>
<true/>
<key>com.apple.private.contacts</key>
<true/>
<key>com.apple.private.corerecents</key>
<true/>
<key>com.apple.private.corespotlight.internal</key>
<true/>
<key>com.apple.private.homekit</key>
<true/>
<key>com.apple.private.security.storage.SpeechPersonalizedLM</key>
<true/>
<key>com.apple.private.tcc.allow</key>
<array>
<string>kTCCServiceAddressBook</string>
<string>kTCCServiceCalendar</string>
<string>kTCCServiceWillow</string>
<string>kTCCServiceMediaLibrary</string>
</array>
<key>com.apple.proactive.PersonalizationPortrait.Config</key>
<true/>
<key>com.apple.proactive.PersonalizationPortrait.NamedEntity.readOnly</key>
<true/>
<key>com.apple.proactive.eventtracker</key>
<true/>
<key>com.apple.security.exception.files.absolute-path.read-only</key>
<array>
<string>/private/var/tmp/com.apple.siri-distributed-evaluation/</string>
</array>
<key>com.apple.security.exception.mach-lookup.global-name</key>
<array>
<string>com.apple.suggestd.contacts</string>
</array>
<key>com.apple.security.iokit-user-client-class</key>
<array>
<string>AGXCommandQueue</string>
<string>AGXDevice</string>
<string>AGXDeviceUserClient</string>
<string>AGXSharedUserClient</string>
<string>H11ANEInDirectPathClient</string>
<string>IOAccelContext</string>
<string>IOAccelContext2</string>
<string>IOAccelDevice</string>
<string>IOAccelDevice2</string>
<string>IOAccelSharedUserClient</string>
<string>IOAccelSharedUserClient2</string>
<string>IOAccelSubmitter2</string>
<string>IOSurfaceRootUserClient</string>
</array>
<key>com.apple.security.personal-information.addressbook</key>
<true/>
<key>com.apple.security.temporary-exception.mach-lookup.global-name</key>
<array>
<string>com.apple.triald.namespace-management</string>
</array>
<key>com.apple.siriknowledged</key>
<true/>
<key>com.apple.spotlight.search</key>
<true/>
<key>com.apple.trial.client</key>
<array>
<string>372</string>
<string>401</string>
<string>751</string>
</array>
</dict>
</plist>
mcpl
ASRPreheatContextTimestamp
-[ESSelfHelper initWithTask:isSpeechAPIRequest:]
-[ESSelfHelper logFinalResultGeneratedWithEARPackage:]
-[ESSelfHelper logRequestEndedOrFailedOrCancelledWithError:recognizerComponents:averageActiveTokensPerFrame:languageModelInterpolationWeights:signalToNoiseRatioInDecibels:recognitionDurationInSec:audioDurationMs:eagerUsed:utteranceDetectionEnabled:utteranceConcatenationEnabled:cpuRealTimeFactor:numLmeDataStreams:]
floatValue
-[ESSelfHelper wrapAndEmitTopLevelEvent:timestampInTicks:]
v32@?0@"NSArray"8Q16^B24
com.apple.MobileSMS
quasarModelPath
type
com.apple.trial.NamespaceUpdate.SIRI_DICTATION_ASSETS
com.apple.trial.NamespaceUpdate.SIRI_UNDERSTANDING_ASR_ASSISTANT
trial
QuasarDir
PreferOverServer
RequiredCapabilityIdentifier
SupportsContinuousListening
SupportsOnDeviceSearch
InstalledLanguages
GeoLMAssetsInfo
mini.json
-[MAAsset(ESAdditions) _es_purgeSync]
FormatVersion
Asset: content version: %@, mastered version %@, installed %@, language: %@, path: %@
Language
-[MAAsset(ESAdditions) _es_isInstalled]
v8@?0
-[ESAssetManager _kickCatalogDownload]_block_invoke
v16@?0q8
com.apple.siri.embeddedspeech.ESAssetManager
v12@?0i8
-[ESAssetManager registerNotifications]
-[ESAssetManager installationStatusForLanguagesIgnoringCache:assetType:withDetailedStatus:withError:]
-[ESAssetManager installationStatusForLanguagesIgnoringCache:assetType:withDetailedStatus:withError:]_block_invoke
-[ESAssetManager _invalidateInstallationStatusCacheForAssetType:]
-[ESAssetManager _queryInstallationStatusForLanguagesWithError:]
%@: %@: AssetId=%@:
-[ESAssetManager installedModelInfoForAssetConfig:error:triggerDownload:]
/System/Library/SpellingKeyboardSpeechModels
-[ESAssetManager _fetchRemoteAssetForLanguage:]_block_invoke_2
-[ESAssetManager _fetchRemoteAssetForLanguage:]_block_invoke
-[ESAssetManager _installedAssetForLanguage:error:]
-[ESAssetManager _installedAssetFromFoundAssets:language:error:]
-[ESAssetManager _installedLocalAssetForLanguage:error:]
+[ESAssetManager _assetQueryForLanguage:]
-[ESAssetManager _startedDownloadingEmbeddedSpeechAsset:error:]
v16@?0@"MAProgressNotification"8
-[ESAssetManager _startedDownloadingEmbeddedSpeechAsset:error:]_block_invoke
v24@?0@"MAAsset"8^B16
-[ESAssetManager purgeInstalledAssetsExceptLanguages:assetType:error:]_block_invoke
-[ESAssetManager purgeOutdatedAssets]_block_invoke
-[ESAssetManager _purgeMobileAssetsForLanguage:error:]_block_invoke
-[ESAssetManager startMissingAssetDownload]
: %@
%@: ModelInfo=%@: AssetId=%@:
com.apple.internal.ck
disableTrialAssetDelivery
-[ESAssetManager trialAssetDeliveryEnabled:]
enableTrialAssetDelivery
Siri
trial_dictation_asset_delivery
-[ESAssetManager prepareHammerConfigFile:]
-[ESAssetManager _installedGeoLMRegionMappingForLanguage:]
-[ESAssetManager geoLMRegionIdForLanguage:location:]
-[ESAssetManager installedGeoLMRegionSpecificAssetForLanguage:regionId:mainAssetConfig:]
-[ESAssetManager _geoLMCompatibleWithMainAsset:geoAssetConfig:]
-[ESAssetManager purgeUnusedGeoLMAssetsForLangauge:]_block_invoke
q24@?0@8@16
-[ESAssetManager purgeUnusedGeoLMAssetsForLangauge:]_block_invoke_2
-[ESAssetManager _purgeUserDefaultsGeoLMAssetsInfoDictExceptLanguages:]
Installed
Installing
Not Installing
Waiting to Install
Not Supported
Unknown
EnumerateInstalledAssets
overrides
confidenceThresholds
confidenceModels
keyboardLM
locationOfInterest
spatialLocationOfInterest
interaction
search
calendarEvent
pexNamedEntity
frequency
wordConfidenceThreshold
utteranceConfidenceThreshold
charsToTrim
charsToSplit
tagName
templateName
tagNameList
minimumWordLength
\NT-contact
\NT-appname
continuousListening
shouldHandleCapitalization
QuasarModel
replicateDataPacketPersonalization
distributedEvaluation
adaptation
WallRTF
AverageActiveTokensPerFrame
lm_interp_weights
jitQueryDurationInMs
jitLmeDurationInMs
version
data
language
assetPath
PERSONALINFO
com.apple.fides.asr
com.apple.siri.speech-dictation-personalization
ModelOverrideURL
com.apple.siri.ESConnection
-[ESConnection initWithXPCConnection:]_block_invoke
-[ESConnection dealloc]
com.apple.siri.ESConnection.fidesEval
com.apple.siri.embeddedspeech.preheat-keepalive
-[ESConnection _preheatKeepAlive]
-[ESConnection _preheatKeepAlive]_block_invoke
v24@?0@"NSDictionary"8@"NSError"16
-[ESConnection fetchModelInfoForAssetConfig:triggerDownload:completion:]
-[ESConnection fetchUserDataForLanguage:completion:]_block_invoke
B8@?0
v16@?0@"CESRUserData"8
v24@?0@"CESRUserDataOptions"8@"NSError"16
-[ESConnection getOfflineAssetStatusIgnoringCache:assetType:withDetailedStatus:withCompletion:]
enableParallelLoading
+[ESConnection _speechRecognizerWithAssetConfig:geoLMRegionId:enableITN:overrides:modelOverrideURL:preloadModels:enableParallelLoading:geoLMLoadedOut:error:]
Failed to create recognizer from %@
AlreadyLoaded
Preheating
-[ESConnection preheatSpeechRecognitionWithAssetConfig:modelOverrideURL:]
 with CustomModelURL %@
Success
(none)
Failure
-[ESConnection shouldWriteDictationRecord:]
Dictation
v24@?0@"CESRModelProperties"8@"NSError"16
-[ESConnection startSpeechRecognitionWithParameters:didStartHandlerWithInfo:]
Recognizer is busy
@"NSDictionary"8@?0
v32@?0@"NSString"8@"NSString"16^B24
-[ESConnection sendSpeechCorrectionInfo:interactionIdentifier:]_block_invoke
-[ESConnection readProfileAndUserDataWithLanguage:allowOverride:completion:]
Not a dictionary: %@
Not an array: %@
orth
prons
freq
v32@?0@"NSString"8@"NSArray"16^B24
-[ESConnection updateSpeechProfileWithLanguage:modelOverridePath:existingProfile:existingAssetPath:completion:]
Could not build empty user profile
-[ESConnection updateSpeechProfileWithLanguage:modelOverridePath:existingProfile:existingAssetPath:completion:]_block_invoke_3
-[ESConnection updateSpeechProfileWithLanguage:modelOverridePath:existingProfile:existingAssetPath:completion:]_block_invoke
Empty user data
User data unchanged
Could not create user profile
UserData
+[ESConnection _parseRequiredParameter:expectedClass:domain:recipe:error:]
Missing %@ for %@
+[ESConnection _runAdaptationRecipeForNamesWithFrequency:tagNames:templateName:charSetToTrim:charSetToSplit:minimumWordLength:nameFrequencies:profile:]
+[ESConnection _runAdaptationRecipeForNamesWithFrequency:tagNames:templateName:charSetToTrim:charSetToSplit:minimumWordLength:nameFrequencies:profile:]_block_invoke_2
v32@?0@"NSString"8Q16^B24
v32@?0@"NSString"8@"NSNumber"16^B24
+[ESConnection _runAdaptationRecipeForKeyboardLMWithFrequency:tagName:templateName:charSetToTrim:charSetToSplit:minimumWordLength:userData:profile:]
+[ESConnection _runAdaptationRecipeForLocationOfInterestWithFrequency:tagName:templateName:charSetToTrim:charSetToSplit:minimumWordLength:locationOfInterestNames:profile:]
+[ESConnection _runAdaptionRecipeForCalendarEventsWithFrequency:tagName:templateName:charSetToTrim:charSetToSplit:minimumWordLength:userData:profile:]
+[ESConnection _scheduleCooldownTimer]
+[ESConnection _cancelCooldownTimer]
+[ESConnection _cooldownTimerFired]
+[ESConnection _cachedRecognizerCleanUp]
+[ESConnection purgeOutdatedAssets]_block_invoke
+[ESConnection _sendPendingAnalyticsEvents]
+[ESConnection _adaptRecipe:userData:profile:]_block_invoke
v32@?0@"NSString"8@"NSDictionary"16^B24
recipeType
-[ESConnection readTableFromURL:]
-[ESConnection runRecipeEvaluationDistributedEvaluation:recordData:attachments:completion:]
returnHypothesis
returnOverallWER
returnOverallRTF
returnPerUtteranceWER
returnPerUtteranceRTF
locale
task
sampleRate
wordSenseWhitelist
wav.scp
raw.ref
-[ESConnection runRecipeEvaluationDistributedEvaluation:recordData:attachments:completion:]_block_invoke
token
confidence
transcription
\\\S+$
EditDistance
details
modelVersion
overall-rtf
overall-wer
v24@?0@"NSData"8@"NSString"16
SiriCoreLocalSpeechUserData
-[ESConnection runDefaultAdaptationEvaluation:recordData:attachments:completion:]
Recipe has no profile
Voicemail audio file deleted by user
%@ %@
.model
Malformed overrides
ConfidenceMean
ConfidenceMin
ConfidenceMax
AlternateConfidenceMean
AlternateConfidenceMin
AlternateConfidenceMax
Baseline
CustomModel
ModelVersion
Adapted
Alignment
name
callStackReturnAddresses
callStackSymbols
reason
userInfo
(unknown C++ exception)
-[ESConnection runCorrectedTextEvaluationWithAudioDatas:recordDatas:language:samplingRate:caseSensitive:skipLME:wordSenseAccessListSet:completion:]_block_invoke
No tokenizer for %@
Interrupted corrected text evaluation during speech recognition
correctedOutput
recognizedOutput
editDistanceRecognizedCorrected
editDistanceRecognizedTTSASR
timestamp
interactionId
asrSelfComponentIdentifier
results
-[ESConnection _userProfileWithAssetConfig:modelOverridePath:overrides:foundPath:error:]
en_US_napg.json
dispatch.voc
vocdelta.voc
pg.voc
lexicon.enh
token_s.enh
mrec.psh
Error during _EARUserProfile initialization
-[ESConnection _userProfileConfigWithAssetConfig:modelOverridePath:overrides:error:]
_EARUserProfileConfig initialization failed: %@ with reason: %@
-[ESConnection _modelRootWithAssetConfig:modelOverridePath:overrides:error:]
asrSelfComponentId
asset
applicationName
metrics
tokens
alignments
uttInfos
uttInfosCompressed
alignmentReferences
usePersonalizedLM
corrected
recognized
useJIT
disableAOT
contextualData
overrideFiles
restoreAOT
evaluations
-[ESConnection runEvaluationWithDESRecordDatas:language:recipe:attachments:fidesPersonalizedLMPath:fidesPersonalizedLMTrainingAsset:scrubResult:completion:]_block_invoke
Unknown evaluation name found in alignmentReferences: %@
scoreNbest
compress
Interrupted evaluation redecoding
-[ESConnection runEvaluationWithDESRecordDatas:language:recipe:attachments:fidesPersonalizedLMPath:fidesPersonalizedLMTrainingAsset:scrubResult:completion:]_block_invoke_2
Interrupted evaluation tokenization
-[ESConnection _deleteTemporaryDirectoryIfExists:]
-[ESConnection resetCacheAndCompileAllAssetsWithCompletion:]
-[ESConnection _fetchUserDataOptionsWithAssetConfig:modelOverridePath:overrides:completion:]_block_invoke
Failed to fetch user data options, for unknown reason
-[ESConnection _writeDESRecord:oneRecordPerDay:]
-[ESConnection _writeDESRecord:oneRecordPerDay:]_block_invoke
-[ESConnection _writeDESRecord:oneRecordPerDay:]_block_invoke_2
-[ESConnection speechRecognizer:didProduceEndpointFeaturesWithWordCount:trailingSilenceDuration:eosLikelihood:pauseCounts:silencePosterior:processedAudioDurationInMilliseconds:]_block_invoke
\jit
\entity-first
-[ESConnection speechRecognizer:didProduceLoggablePackage:]_block_invoke
-[ESConnection speechRecognizer:didRecognizePartialResult:]_block_invoke
Unsupported EAR build?
Unsupported EAR package build?
-[ESConnection speechRecognizer:didFinishRecognitionWithError:]_block_invoke
recognizer-components
audioDurationMs
recognitionDurationMs
EagerUsed
numLmeDataStreams
PM-input
PM-output
tokenName
-[ESConnection speechRecognizer:didRecognizeRawEagerRecognitionCandidate:]_block_invoke_2
v16@?0@"_EARFormatter"8
-[ESConnection speechRecognizer:didRecognizeRawEagerRecognitionCandidate:]_block_invoke
lastPathComponent == %@
_ESDecompressArchiveWithURL
VoiceTriggerFidesArchive
Failed to specify compression algorithm
Failed to specify format
Failed to open file for reading
Unable to extract file to: %@
Task %@ not available for %@, supported tasks are %@
etiquette.json
ReplacementDictionaryForAssetConfig
ReplacementDictionaryForAssetConfig_block_invoke
v32@?0@"NSString"8@16^B24
voicemail_confidence_subtraction.json
sampling rate = %@
task type = %@
far field = %@
device ID = %@
Bluetooth device ID = %@
PersonalizationRecipeForAssetConfig
personalization.json
v32@?0@"CESRVocabularyCategory"8@"NSSet"16^B24
\correction-first
\NT-correction
AddWordsToUserProfile
ReadAudioDataFromFileURL
\\\S*$
Insertions
Deletions
Substitutions
ReferenceSize
\contact-first
CONTACTFIRSTNAME
\contact-middle
CONTACTMIDDLENAME
\contact-last
CONTACTLASTNAME
\contact-nickname
\app-first
APPNAMEFIRSTNAME
\company-first
COMPANYFIRSTNAME
\interaction-first
\interaction-middle
\interaction-last
INLINEFIRSTNAME
\contact-first-derived
\contact-middle-derived
\contact-last-derived
\contact-nickname-derived
Recipe evaluation failed
Empty recognition Result
Error
UtteranceLength
NumberOfNonTerminals
WordsAboveThreshold
UtteranceAboveThreshold
Override file is not found in attachments or device
restoreJIT
configurationFile
JIT LME: JIT profile builder is not initialized
JIT LME: required configuration/file is missing
JIT LME: configuration file is not found in attachments or device
zlibCompressedJson
AFSpeechLatticeMitigatorResultForEar
dictationUIInteractionIdentifier
interactionIdentifier
samplingTimestamp
codec
samplingRate
inferenceSpeakerCode
numTrainedFrames
trainingNnetVersion
isSpeakerCodeUsed
-[ESStoreAudioData initWithUUIDString:language:task:codec:samplingRate:inferenceSpeakerCode:numTrainedFrames:trainingNnetVersion:isSpeakerCodeUsed:isSamplingForDictation:selfLogger:]
-[ESStoreAudioData saveAudioToDisk]
-[ESStoreAudioData _deleteItemAtPath:]
-[ESStoreAudioData _cleanupCacheAndReset:]
-[ESStoreAudioData _saveAudioToCache:]
-[ESStoreAudioData _moveAudioToVarMobile:]
%@.plist
-[ESStoreAudioData _saveAudioMetadataToFilePath:]
-[ESStoreAudioData _createAudioFilePath]
%.0f
%@_%@_%@.pcm
unixTime
samplingDate
success
failed
errorCode
errorDomain
UNDEFINED
description
underlyingErrorCode
underlyingErrorDomain
Audio file to be moved nil
Sampling Date is nil
Unable to create sampling directory
Unable to create dated directory
status
com.apple.siri.embeddedspeech
com.apple.private.des-service
Rejecting %@, no %@ or %@ entitlement
timeZoneWithAbbreviation:
setTimeZone:
doubleValue
dateWithTimeIntervalSince1970:
date
currentCalendar
components:fromDate:toDate:options:
calculateDiffInDaysFromTimestamp:
init
isLoggingAllowedForCurrentRequestWithTask:isSpeechAPIRequest:
UUID
isTranscriptLoggingAllowedForCurrentRequestWithTask:
sharedPreferences
isDictationHIPAACompliant
siriDataSharingOptInStatus
isEqualToString:
initWithNSUUID:
setUuid:
setComponent:
setSource:
setTarget:
sharedStream
emitMessage:
setExists:
numberWithUnsignedLongLong:
setTimestampInTicks:
setStartedOrChanged:
setFailed:
setStatus:
setEnded:
countByEnumeratingWithState:objects:count:
timestampInTicks
wrapAndEmitTopLevelEvent:timestampInTicks:
setLinkId:
setDialogContexts:
setTask:
stringByReplacingOccurrencesOfString:withString:
convertLanguageCodeToSchemaLocale:
setModelLocale:
boolValue
setIsHighQualityAsset:
unsignedLongLongValue
setSpeechProfileAgeInNs:
initWithUUIDString:
setDictationUiInteractionId:
setDatapackVersion:
setHammerVersion:
setGeoLanguageModelRegion:
setGeoLanguageModelLoaded:
setPortraitExperimentVariantName:
setPhoneticMatchInput:
setPhoneticMatchOutput:
setUnrepairedPostItn:
recognition
interpretationIndices
count
isFinal
setIsFinal:
setPackage:
correctPartialResultIndexList
setCorrectPartialResultIndexLists:
preITNRecognition
oneBest
silenceStart
utteranceStart
numberWithDouble:
addObject:
setTokenSilenceStartTimeInNsLists:
componentsJoinedByString:
UTF8String
setPersonalizedLanguageModelAgeInNs:
floatValue
setPersonalizedLanguageModelWeight:
setAverageActiveTokensPerFrame:
setSignalToNoiseRatioInDecibels:
setRecognitionDurationInNs:
setAudioDurationInNs:
setEagerEnabled:
setCpuRealTimeFactor:
setNumLanguageModelEnrollmentDataStreams:
setUtteranceDetectionEnabled:
setUtteranceConcatenationEnabled:
setContinuousListeningEnabled:
componentsSeparatedByString:
objectAtIndexedSubscript:
setFrontend:
setDecoder:
setDecodable:
setRecognizerComponents:
setStartTimeInNs:
setEndTimeInNs:
valueForKey:
setWeights:
setLanguageModelInterpolationWeights:
code
setMetrics:
setReason:
setCancelled:
setErrorCode:
domain
setErrorDomain:
userInfo
objectForKey:
setUnderlyingErrorCode:
setUnderlyingErrorDomain:
setSampledAudioStorageFailureReason:
setAsrId:
setEventMetadata:
setPreheatContext:
setRequestContext:
setPartialResultGenerated:
setPackageGenerated:
setRecognitionResultTier1:
setFinalResultGenerated:
setIntermediateUtteranceInfoTier1:
setInitializationContext:
setAssetLoadContext:
setLanguageModelEnrollmentContext:
setJitLanguageModelEnrollmentEndedTier1:
setAudioPacketArrivalContext:
setFirstAudioPacketProcessed:
setFinalAudioPacketContainingSpeechReceived:
setSampledAudioFileStored:
setSampledAudioFileStorageFailed:
emitMessage:timestamp:
createPreheatStartedOrChangedEvent
createPreheatFailedEvent
createPreheatEndedEventWithPreheatAlreadyDone:
initWithTask:isSpeechAPIRequest:
logRequestLinkWithRequestId:
logPendingPreheatContextEvents:
logInitializationStartedOrChangedWithTimeInTicks:
logInitializationEnded
logAssetLoadStartedOrChanged
logAssetLoadEnded
logJitLmeStartedOrChangedWithTimeInTicks:
logJitLmeEndedAndEndedTier1WithDialogContext:
logAudioPacketArrivalStartedOrChangedWithTimeInTicks:
logAudioPacketArrivalEndedWithTimeInTicks:
logFirstAudioPacketProcessed
logFinalAudioPacketContainingSpeechReceivedWithTimeInTicks:
logRequestStartedOrChangedWithTask:modelLocale:modelVersion:isHighQualityAsset:hammerVersion:geoLanguageModelRegion:geoLanguageModelLoaded:speechProfileAgeInSec:dictationUIInteractionId:portraitExperimentVariantName:
logPartialResultGenerated
logIntermediateUtteranceInfoTier1WithPmInput:pmOutput:
logPackageGeneratedAndRecognitionResultTier1WithEARPackage:
logFinalResultGeneratedWithEARPackage:
logRequestEndedOrFailedOrCancelledWithError:recognizerComponents:averageActiveTokensPerFrame:languageModelInterpolationWeights:signalToNoiseRatioInDecibels:recognitionDurationInSec:audioDurationMs:eagerUsed:utteranceDetectionEnabled:utteranceConcatenationEnabled:cpuRealTimeFactor:numLmeDataStreams:
logSampledAudioFileStoredSuccessfully
logSampledAudioFileStoredWithError:customFailureReason:
asrId
recognitionTask
unrepairedPostItn
personalizedLmWeight
setPersonalizedLmWeight:
personalizedLmAgeInSec
setPersonalizedLmAgeInSec:
continuousListeningEnabled
.cxx_destruct
_asrId
_recognitionTask
_packageLogged
_isTranscriptLoggingAllowedForCurrentRequest
_continuousListeningEnabled
_unrepairedPostItn
_personalizedLmWeight
_personalizedLmAgeInSec
T@"NSUUID",R,N,V_asrId
T@"NSString",R,N,V_recognitionTask
T@"NSString",&,N,V_unrepairedPostItn
T@"NSNumber",&,N,V_personalizedLmWeight
T@"NSNumber",&,N,V_personalizedLmAgeInSec
TB,N,V_continuousListeningEnabled
T@"NSNumber",&,N
setRawRecognition:
setPostItn:
tokenSausage
setPhrases:
setUtterances:
linkId
orderedSetWithArray:
array
setInterpretationIndices:
objectAtIndex:
unsignedIntegerValue
setTokens:
containsObject:
indexOfObject:
numberWithUnsignedInteger:
arrayByAddingObject:
enumerateObjectsUsingBlock:
copy
setInterpretations:
initWithCapacity:
start
hasSpaceAfter
setAppendSpaceAfter:
setSilenceStartTimeInNs:
confidence
setConfidence:
tokenName
setText:
phoneSequence
setPhoneSequence:
ipaPhoneSequence
setIpaPhoneSequence:
setLinkIndex:
markRecognition
sendEvent
recognitionEndTime
setRecognitionEndTime:
applicationName
setApplicationName:
interactionId
setInteractionId:
taskName
setTaskName:
hasRecognizedAnything
_hasRecognizedAnything
_recognitionEndTime
_applicationName
_interactionId
_taskName
Td,N,V_recognitionEndTime
T@"NSString",C,N,V_applicationName
T@"NSString",C,N,V_interactionId
T@"NSString",C,N,V_taskName
TB,R,N,V_hasRecognizedAnything
_es_quasarModelPath
stringByAppendingPathComponent:
purgeCompiledRecognizerModelsWithConfiguration:
purgeSync
attributes
integerValue
_es_requiredCapabilityIdentifier
minimumSupportedConfigurationVersion
maximumSupportedConfigurationVersion
_es_contentVersion
_es_masteredVersion
_es_isInstalled
_es_language
_es_path
stringWithFormat:
stringValue
getLocalFileUrl
path
state
defaultManager
fileExistsAtPath:isDirectory:
refreshState
_es_purgeSync
compare:options:
compare:
_es_compareByVersion:
_es_isCompatibleWithThisDevice
_es_description
_es_isDownloading
_es_status
_es_quasarDir
_es_preferOverServer
_es_moreRecentAsset:
_es_supportsContinuousListening
_es_supportsOnDeviceSearch
timeIntervalSinceReferenceDate
_exponentialBackoffIntervalWithAttempts:
startCatalogDownload:then:
registerNotifications
distantPast
dictionary
trialAssetDeliveryEnabled:
_kickCatalogDownload
_invalidateInstallationStatusCacheForAssetType:
dealloc
objectForKeyedSubscript:
installationStatusForLanguagesForAssetType:includeDetailedStatus:error:
_queryInstallationStatusForLanguagesWithError:
setObject:forKeyedSubscript:
installationStatusForLanguagesForAssetType:error:
_assetQueryForLanguage:
queryMetaDataSync
numberWithInteger:
dictionaryWithObjects:forKeys:count:
errorWithDomain:code:userInfo:
results
modelTypeStatusStringAndVersionWithAsset:
setObject:forKey:
isEqual:
modelAttributesStatusStringWithAsset:
assetId
standardUserDefaults
stringArrayForKey:
mutableCopy
removeObject:
logLocalRecognitionAssetEvictedForLanguage:
synchronize
installedModelInfoForAssetConfig:error:
installedModelInfoForAssetConfig:error:triggerDownload:
language
assetType
sharedInstance
installedAssetWithConfig:regionId:triggerDownload:
modelQualityTypeStatusStringWithConfig:
numberWithBool:
setAssetsProvisionalForAssetType:
promoteAssetsForAssetType:
_installedAssetFromFoundAssets:language:error:
queryMetaData:
_installedLocalAssetForLanguage:error:
_startedDownloadingEmbeddedSpeechAsset:error:
initWithType:
returnTypes:
addKeyValuePair:with:
isStalled
totalWritten
totalExpected
expectedTimeRemaining
spaceCheck:
isBelowLimitForLocale:
attachProgressCallBack:
startDownload:then:
_purgeUserDefaultsGeoLMAssetsInfoDictExceptLanguages:
purgeInstalledAssetsExceptLanguages:assetType:error:
allKeys
cancelDownloadSync
assistantIsEnabled
languageCode
initWithLanguage:assetType:
installedAssetWithConfig:
setWithObject:
_purgeMobileAssetsForLanguage:error:
stringByAppendingFormat:
initWithSuiteName:
isSiriXEnabled
length
jsonFilenameForAssetType:
initWithConfig:
_installedGeoLMRegionMappingForLanguage:
coordinate
initWithConfiguration:
regionIdForLatitude:longitude:
installedAssetWithConfig:regionId:
_geoLMCompatibleWithMainAsset:geoAssetConfig:
_updateGeoLMAssetsInfoDictWithRegionId:language:
purgeInstalledAssetForAssetType:language:regionId:error:
version
_loadGeoLMAssetsInfoDictForLanguage:
timeIntervalSince1970
_updateUserDefaultsWithGeoLMAssetsInfoDict:language:
keysSortedByValueUsingComparator:
lastObject
removeObjectForKey:
supportedLanguagesWithAssetType:
_userDefaultsGeoLMAssetsInfoDictKeyForLangauge:
dictionaryForKey:
stringByAppendingString:
installationStatusForLanguagesIgnoringCache:assetType:withDetailedStatus:withError:
installedQuasarModelPathForAssetConfig:error:
installedQuasarModelPathForAssetConfig:error:triggerDownload:
prepareModelInfo:withAssetType:
promoteModelInfo:withAssetType:
_fetchRemoteAssetForLanguage:
_installedAssetForLanguage:error:
installedAssetSizeWithError:
purgeOutdatedAssets
startMissingAssetDownload
modelQualityTypeStatusStringWithAsset:
installedHammerConfigFileForLanguage:
prepareHammerConfigFile:
promoteHammerConfigFile
geoLMRegionIdForLanguage:location:
installedGeoLMRegionSpecificAssetForLanguage:regionId:mainAssetConfig:
purgeUnusedGeoLMAssetsForLangauge:
_queue
_languageInstallationCache
_maAssetUpdatedNotificationToken
_dictationAssetUpdatedNotificationToken
_assistantAssetUpdatedNotificationToken
_lastCatalogDownload
_numFailedCatalogDownloadAttempts
_lastFailedCatalogDownload
_recognizerAssetPathsInUse
_profileAssetPathsInUse
_geoLMAssetsInfoDict
longLongValue
numberWithLongLong:
allocWithZone:
numberOfInsertions
setNumberOfInsertions:
numberOfSubstitutions
setNumberOfSubstitutions:
numberOfDeletions
setNumberOfDeletions:
totalCost
setTotalCost:
copyWithZone:
incrementInsertions
incrementDeletions
incrementSubstitutions
incrementCost
_numberOfInsertions
_numberOfDeletions
_numberOfSubstitutions
_totalCost
Tq,N,V_numberOfInsertions
Tq,N,V_numberOfDeletions
Tq,N,V_numberOfSubstitutions
Tq,N,V_totalCost
setModelType:
modelType
setModelRoot:
modelRoot
T@"NSString",C,N
_setQueue:
_UUID
cancelRecognition
invalidate
setInterruptionHandler:
setInvalidationHandler:
remoteObjectProxy
fetchAssetsForAssetConfig:completion:
fetchModelInfoForAssetConfig:completion:
fetchModelInfoForAssetConfig:triggerDownload:completion:
setWithArray:
initWithModelVersion:modelType:modelRoot:
data
dictionaryRepresentation
dataWithJSONObject:options:error:
fetchUserDataWithLanguage:options:keepGoing:completion:
_fetchUserDataOptionsWithAssetConfig:modelOverridePath:overrides:completion:
getOfflineAssetStatusIgnoringCache:assetType:withDetailedStatus:withCompletion:
getOfflineAssetStatusIgnoringCache:assetType:withCompletion:
_speechRecognizerWithAssetConfig:geoLMRegionId:enableITN:overrides:modelOverrideURL:preloadModels:enableParallelLoading:geoLMLoadedOut:error:
switchToNewAssetsForAssetType:
processInfo
systemUptime
activeConfigurationForEverything
setSamplingRateFilter:
setTaskTypeFilter:
setFarFieldFilter:
setDeviceIdFilter:
setBluetoothDeviceIdFilter:
initWithConfiguration:useQuasarFormatter:activeConfiguration:
setDetectUtterances:
setRecognizeEagerCandidates:
setConcatenateUtterances:
logLocalRecognitionLoadedForLanguage:duration:
preheatSpeechRecognitionWithAssetConfig:modelOverrideURL:
_preheatKeepAlive
_clearPendingAnalyticsEvents
_addPendingAnalyticsEvent:
_clearPendingSelfPreheatEvents
_addPendingSelfPreheatEvent:
_scheduleCooldownTimer
modelVersion
startSpeechRecognitionWithParameters:didStartHandlerWithInfo:
_sendPendingAnalyticsEvents
startRequestActivityWithCompletion:
overrides
continuousListening
shouldHandleCapitalization
modelOverrideURL
task
initWithLanguage:task:
location
interruptTraining
isEqualToDictionary:
modelInfo
_delegate
speechServiceDidSelectRecognitionModelWithModelProperties:
isSpeechAPIRequest
speechProfileDataLastModifiedDataForLanguage:
timeIntervalSinceNow
dictationUIInteractionIdentifier
requestIdentifier
censorSpeech
setRecognitionReplacements:
enumerateKeysAndObjectsUsingBlock:
setRecognitionConfidenceSubtraction:
disableDeliveringAsrFeatures
endpointStart
setEndpointStart:
profile
setUserProfileData:
_modelRootWithAssetConfig:modelOverridePath:overrides:error:
jitGrammar
addObjectsFromArray:
initWithConfiguration:taskName:applicationName:
_userProfileWithAssetConfig:modelOverridePath:overrides:foundPath:error:
createInlineLmeUserDataForContextStrings:
dataProfile
contextualData
fetchNamedEntitiesWithTimeInterval:
createInlineLmeUserDataForContextData:speechProfile:
setJitProfileData:
inputOrigin
setInputOrigin:
setExtraLmList:
detectUtterances
deliverEagerPackage
maximumRecognitionDuration
setMaximumRecognitionDuration:
farField
setFarField:
setAllowUtteranceDelay:
setFormatAcrossUtterances:
narrowband
codec
activeConfiguration
farFieldFilter
setByAddingObject:
samplingRateFilter
taskTypeFilter
setActiveConfiguration:
runRecognitionWithResultStream:speakerCodeWriter:language:task:samplingRate:
sharedManager
isRequestSelectedForSamplingFromConfigForLanguage:
updateRequestCountWithFlag:
shouldStoreAudioOnDevice
isRequestSelectedForSamplingForTask:
secureOfflineOnly
siriDataSharingOptedIn
loggingContext
UUIDString
recordWithLanguage:task:context:narrowband:farField:interactionIdentifier:asrSelfComponentIdentifier:pluginId:
setProfile:
originalAudioFileURL
setOriginalAudioFileURL:
shouldWriteDictationRecord:
recordWithLanguage:task:context:narrowband:farField:interactionIdentifier:asrSelfComponentIdentifier:pluginId:frequency:
speakerCodeInfo
inferenceSpeakerCode
numFrames
nnetVersion
isSpeakerCodeUsed
initWithUUIDString:language:task:codec:samplingRate:inferenceSpeakerCode:numTrainedFrames:trainingNnetVersion:isSpeakerCodeUsed:isSamplingForDictation:selfLogger:
removeAllObjects
bytes
addAudioSamples:count:
addAudioPacket:
updateAudioDuration:
endAudio
_cancelCooldownTimer
correctedText
interactionIdentifier
setCorrectedText:
_writeDESRecord:oneRecordPerDay:
_writeDESRecord:
offlineDictationProfileOverridePath
dataWithContentsOfFile:options:error:
dictionaryWithContentsProfilePathForLanguage:errorOut:
JSONObjectWithData:options:error:
objectEnumerator
nextObject
initWithOrthography:pronunciations:tagName:frequency:
addWordWithParts:templateName:
readUserProfile:
peopleSuggesterConfig
contactsCount
setPeopleSuggesterContactsCount:
bestContactsCount
setBestPeopleSuggesterContactsCount:
bestContactsBonus
setBestPeopleSuggesterContactsBonus:
description
componentsSeparatedByCharactersInSet:
arrayWithObjects:count:
firstObject
pronunciationsForOrthography:
keyboardLMDynamicVocabularyItems
dictionaryWithDictionary:
whitespaceCharacterSet
countForObject:
eventTitles
eventLocationNames
arrayByAddingObjectsFromArray:
stringByTrimmingCharactersInSet:
_runAdaptationRecipeForKeyboardLMWithFrequency:tagName:templateName:charSetToTrim:charSetToSplit:minimumWordLength:userData:profile:
locationOfInterestNames
_runAdaptationRecipeForLocationOfInterestWithFrequency:tagName:templateName:charSetToTrim:charSetToSplit:minimumWordLength:locationOfInterestNames:profile:
spatialLocationOfInterestNames
interactionSenderDisplayNames
_runAdaptationRecipeForNamesWithFrequency:tagNames:templateName:charSetToTrim:charSetToSplit:minimumWordLength:nameFrequencies:profile:
searchEventValues
_runAdaptionRecipeForCalendarEventsWithFrequency:tagName:templateName:charSetToTrim:charSetToSplit:minimumWordLength:userData:profile:
pexNamedEntityNames
_cooldownTimerFired
_cachedRecognizerCleanUp
releaseClients
sharedAnalytics
logEvents:
_parseRequiredParameter:expectedClass:domain:recipe:error:
characterSetWithCharactersInString:
_runAdaptationRecipeForDomain:frequency:tagNames:templateName:charSetToTrim:charSetToSplit:minimumWordLength:userData:profile:
runDefaultAdaptationEvaluation:recordData:attachments:completion:
runRecipeEvaluationDistributedEvaluation:recordData:attachments:completion:
stringWithContentsOfURL:encoding:error:
whitespaceAndNewlineCharacterSet
rangeOfString:
substringToIndex:
substringFromIndex:
URLByAppendingPathComponent:
readTableFromURL:
_speechRecognizerWithAssetConfig:enableITN:error:
_deleteTemporaryDirectoryIfExists:
recognitionResultsWithAudioData:userProfileData:language:task:samplingRate:extraLanguageModel:
preITNTokens
setValue:forKey:
regularExpressionWithPattern:options:error:
firstMatchInString:options:range:
range
substringWithRange:
numberWithFloat:
readProfileAndUserDataWithLanguage:allowOverride:completion:
initForReadingFromData:error:
setClass:forClassName:
decodeObjectOfClass:forKey:
finishDecoding
samplingRate
audioPackets
appendData:
userData
appendString:
fileURLWithPath:
createDirectoryAtURL:withIntermediateDirectories:attributes:error:
writeToURL:atomically:encoding:error:
name
callStackReturnAddresses
callStackSymbols
reason
initWithDomain:code:userInfo:
_fidesEvalQueue
initWithNcsRoot:
_invalidated
recordFromData:
recognizedText
tokenize:
removeObjectAtIndex:
timestamp
asrSelfComponentIdentifier
initWithConfiguration:language:overrides:sdapiOverrides:generalVoc:emptyVoc:pgVoc:lexiconEnh:tokenEnh:paramsetHolder:
initWithConfiguration:overrides:
fileExistsAtPath:
concatenatedAudioPackets
addEntriesFromDictionary:
setScoreNbest:
setScoreNbestExtraLmList:
setEnableSpeakerCodeTraining:
recognitionUtterenceStatistics
recognitionUtteranceInfos
removeItemAtURL:error:
compileRecognizerModelsWithConfiguration:
loadConfigs
deleteAllRecordsForPlugin:completion:
_userProfileConfigWithAssetConfig:modelOverridePath:overrides:error:
hasData
saveOneRecordPerDay
save
pluginId
setUserData:
speechServiceDidProduceEndpointFeaturesWithWordCount:trailingSilenceDuration:eosLikelihood:pauseCounts:silencePosterior:processedAudioDurationInMilliseconds:
speechServiceDidProduceLoggablePackage:
performSelector:withObject:
rawRecognition
phrases
interpretations
tokens
text
hasSuffix:
setRecognizedText:
unrepairedRecognition
packetArrivalTimestampFromAudioTime:
speechServiceDidRecognizeTokens:
raise:format:
utterances
concatenateUtterances
speechServiceDidRecognizePackage:
recognitionStatistics
speechServiceDidFinishRecognitionWithStatistics:error:
saveAudioToDisk
speechServiceDidProcessAudioDuration:
nBest
formattedRecognitionWithNBestList:
speechServiceDidRecognizeRawEagerRecognitionCandidate:
getFormatterWithBlock:
initialize
_adaptRecipe:userData:profile:
getRecognizerQueue
class
self
performSelector:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
debugDescription
TQ,R
T#,R
T@"NSString",R,C
speechRecognizer:didRecognizePartialResult:
speechRecognizer:didFinishRecognitionWithError:
speechRecognizer:didRecognizeFinalResults:
speechRecognizer:didRecognizeFinalResults:tokenSausage:nBestChoices:
speechRecognizer:didRecognizeFinalResultPackage:
speechRecognizer:didProcessAudioDuration:
speechRecognizer:didRecognizeRawEagerRecognitionCandidate:
speechRecognizer:didProduceEndpointFeaturesWithWordCount:trailingSilenceDuration:eosLikelihood:pauseCounts:silencePosterior:processedAudioDurationInMilliseconds:
speechRecognizer:didRecognizePartialResultNbest:
speechRecognizer:didProduceLoggablePackage:
resetCacheAndCompileAllAssetsWithCompletion:
preheatSpeechRecognitionWithLanguage:modelOverrideURL:
startSpeechRecognitionWithParameters:didStartHandler:
finishAudio
createSpeechProfileWithLanguage:modelOverridePath:JSONData:completion:
updateSpeechProfileWithLanguage:modelOverridePath:existingProfile:existingAssetPath:completion:
getOfflineDictationStatusIgnoringCache:withCompletion:
fetchAssetsForLanguage:completion:
fetchModelPropertiesForAssetConfig:completion:
fetchUserDataForLanguage:completion:
runAdaptationRecipeEvaluation:recordData:attachments:completion:
runCorrectedTextEvaluationWithAudioDatas:recordDatas:language:samplingRate:caseSensitive:skipLME:wordSenseAccessListSet:completion:
getInstalledAssetSizeWithCompletion:
purgeInstalledAssetsExceptLanguages:completion:
purgeInstalledAssetsExceptLanguages:assetType:completion:
setAssetsPurgeabilityExceptLanguages:assetType:
writeDESRecord
sendSpeechCorrectionInfo:interactionIdentifier:
invalidatePersonalizedLM
removePersonalizedLMForFidesOnly:completion:
runEvaluationWithDESRecordDatas:language:recipe:attachments:fidesPersonalizedLMPath:fidesPersonalizedLMTrainingAsset:scrubResult:completion:
deleteAllDESRecordsForDictationPersonalizationWithCompletion:
invalidateUaapLm
initWithXPCConnection:
_recognizer
_audioBuffer
_disableDeliveringAsrFeatures
_connection
_lastRecognizedPackage
_bufferedAudioPackets
_bufferedAudioEnded
_validDomains
_requestCompletion
_storeAudioData
_biomeRecord
_selfHelper
_samplingRate
_audioDurationMs
_processedAudioDuration
_firstAudioPacketReceivedTime
_firstAudioPacketTimeUntilFirstPartial
_lastAudioPacketReceivedTime
_firstAudioPacketReceivedTimeInTicks
_lastAudioPacketReceivedTimeInTicks
_firstAudioPacketProcessedTime
_localMetrics
_recognitionBeginTime
_recognitionAbsoluteEndTime
_speakerCodeWriter
_weakFidesRecognizer
_lastWordCount
_taskToUse
_desRecord
_desRecordDictation
predicateWithFormat:
filteredArrayUsingPredicate:
fileURLWithPath:isDirectory:
fileSystemRepresentation
stringWithUTF8String:
tasks
deviceIdFilter
bluetoothDeviceIdFilter
removeAllWords
contactWordsWithFrequency
vocabularyWords
tagName
templateName
corrections
appNames
initWithOrthography:pronunciations:tag:
signalEndOfUserData
components
frequency
assetWithURL:
tracksWithMediaType:
assetReaderWithAsset:error:
assetReaderAudioMixOutputWithAudioTracks:audioSettings:
canAddOutput:
addOutput:
startReading
copyNextSampleBuffer
dataWithBytes:length:
setObject:atIndexedSubscript:
lowercaseString
stringByReplacingMatchesInString:options:range:withTemplate:
reverseObjectEnumerator
allObjects
lastPathComponent
compressedDataUsingAlgorithm:error:
base64EncodedStringWithOptions:
setStartTime:
setSilenceStartTime:
setEndTime:
setRemoveSpaceBefore:
setConfidenceScore:
audioAnalytics
latticeMitigatorResult
initWithRecognition:rawRecognition:audioAnalytics:isFinal:utteranceStart:latticeMitigatorResult:
acousticFeatures
speechRecognitionFeatures
initWithSpeechRecognitionFeatures:acousticFeatures:snr:
acousticFeatureValuePerFrame
frameDuration
initWithAcousticFeatureValue:frameDuration:
score
threshold
initWithResults:score:threshold:
initWithPhrases:utterances:processedAudioDuration:
initWithInterpretationIndices:confidenceScore:
confidenceScore
setIsLowConfidence:
setUUIDString:
setLanguage:
component
_createAudioFilePath
_saveAudioToCache:
_moveAudioToVarMobile:
_logAudioSampledEventsWithStatus:error:customReasonForFailure:
_cleanupCacheAndReset:
deleteItemAtFilePath:
_deleteItemAtPath:
cleanupCacheAndReset
writeToFile:options:error:
pathComponents
samplingDateAsString
createSamplingDirectory
moveItemAtPath:toPath:error:
stringByDeletingPathExtension
_saveAudioMetadataToFilePath:
writeToFile:atomically:
_createCachesDirectoryIfItDoesNotExist
sampledCachesSubDirectoryPath
initWithDictionary:
localizedDescription
logEventWithType:context:
_trimAudioIfNeeded:
setCodec:
setSamplingRate:
setAudioPackets:
setHasRecognizedAnything:
numTrainedFrames
trainingNnetVersion
isSamplingForDictation
selfLogger
setSelfLogger:
audioMetadata
setAudioMetadata:
collectedAudioDurationMS
setCollectedAudioDurationMS:
currentAudioFilePath
setCurrentAudioFilePath:
logPrefix
setLogPrefix:
_isSpeakerCodeUsed
_isSamplingForDictation
_UUIDString
_language
_task
_codec
_audioPackets
_inferenceSpeakerCode
_numTrainedFrames
_trainingNnetVersion
_selfLogger
_audioMetadata
_collectedAudioDurationMS
_currentAudioFilePath
_logPrefix
T@"NSString",C,N,V_UUIDString
T@"NSString",C,N,V_language
T@"NSString",C,N,V_task
T@"NSString",&,N,V_codec
TQ,N,V_samplingRate
T@"NSMutableData",&,N,V_audioPackets
TB,N,V_hasRecognizedAnything
T@"NSString",R,N,V_inferenceSpeakerCode
T@"NSNumber",R,N,V_numTrainedFrames
T@"NSNumber",R,N,V_trainingNnetVersion
TB,R,N,V_isSpeakerCodeUsed
TB,R,N,V_isSamplingForDictation
T@"ESSelfHelper",&,N,V_selfLogger
T@"NSMutableDictionary",&,N,V_audioMetadata
Td,N,V_collectedAudioDurationMS
T@"NSString",C,N,V_currentAudioFilePath
T@"NSString",C,N,V_logPrefix
valueForEntitlement:
setExportedInterface:
setExportedObject:
setRemoteObjectInterface:
resume
listener:shouldAcceptNewConnection:
enableTransactions
serviceListener
setDelegate:
ESUtilities
ESSelfHelper
Timestamp
ESBiomeRecord
ESAdditions
ESAssetManager
ESAlignmentState
NSCopying
ESConnectionModelInfo
ESConnection
_EARSpeechRecognitionResultStream
NSObject
CESRSpeechService
ESStoreAudioData
ESListenerDelegate
NSXPCListenerDelegate
q24@0:8@16
@16@0:8
@20@0:8B16
@28@0:8@16B24
B28@0:8@16B24
B24@0:8@16
v24@0:8@16
v16@0:8
v92@0:8@16@24@32@40@48@56B64@68@76@84
v32@0:8@16@24
v104@0:8@16@24@32@40@48@56@64@72B80B84@88@96
v32@0:8@16q24
B16@0:8
v20@0:8B16
@"NSUUID"
@"NSString"
@"NSNumber"
d16@0:8
v24@0:8d16
q16@0:8
@24@0:8@16
d24@0:8Q16
@40@0:8B16Q20B28^@32
v24@0:8Q16
@24@0:8^@16
@32@0:8@16^@24
@36@0:8@16^@24B32
v32@0:8@16Q24
@40@0:8@16@24^@32
B32@0:8@16^@24
B40@0:8@16Q24^@32
B24@0:8Q16
@32@0:8@16@24
@40@0:8@16@24@32
B32@0:8@16@24
@"NSObject<OS_dispatch_queue>"
@"NSMutableDictionary"
@24@0:8^{_NSZone=}16
v24@0:8q16
@36@0:8@16B24^@28
@76@0:8@16@24B32@36@44B52B56^@60^@68
@56@0:8@16#24@32@40^@48
B80@0:8d16@24@32@40@48Q56@64@72
B88@0:8@16d24@32@40@48@56Q64@72@80
v40@0:8@16@24@32
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
v48@0:8@16@24@32@40
v32@0:8@16d24
v72@0:8@16q24q32d40@48d56q64
v32@0:8@"_EARSpeechRecognizer"16@"_EARSpeechRecognitionResult"24
v32@0:8@"_EARSpeechRecognizer"16@"NSError"24
v32@0:8@"_EARSpeechRecognizer"16@"NSArray"24
v48@0:8@"_EARSpeechRecognizer"16@"NSArray"24@"NSArray"32@"NSArray"40
v32@0:8@"_EARSpeechRecognizer"16@"_EARSpeechRecognitionResultPackage"24
v32@0:8@"_EARSpeechRecognizer"16d24
v32@0:8@"_EARSpeechRecognizer"16@"_EARSpeechRecognition"24
v72@0:8@"_EARSpeechRecognizer"16q24q32d40@"NSArray"48d56q64
Vv24@0:8@?16
Vv32@0:8@16@24
Vv32@0:8@16@?24
Vv24@0:8@16
Vv48@0:8@16@24@32@?40
Vv56@0:8@16@24@32@40@?48
Vv36@0:8B16Q20@?28
Vv40@0:8B16Q20B28@?32
Vv28@0:8B16@?20
Vv72@0:8@16@24@32Q40B48B52@56@?64
Vv36@0:8@16B24@?28
Vv40@0:8@16Q24@?32
Vv32@0:8@16Q24
Vv76@0:8@16@24@32@40@48@56B64@?68
Vv24@0:8@?<v@?@"NSError">16
Vv32@0:8@"NSString"16@"NSURL"24
Vv32@0:8@"CESRAssetConfig"16@"NSURL"24
Vv24@0:8@?<v@?>16
Vv32@0:8@"CESRSpeechParameters"16@?<v@?@"CESRModelProperties"@"NSError">24
Vv32@0:8@"CESRSpeechParameters"16@?<v@?@"NSString"@"NSString"@"NSError">24
Vv24@0:8@"NSData"16
Vv48@0:8@"NSString"16@"NSString"24@"NSData"32@?<v@?@"NSData"@"NSError">40
Vv56@0:8@"NSString"16@"NSString"24@"NSData"32@"NSString"40@?<v@?@"NSData"@"NSString"@"NSError">48
Vv36@0:8B16Q20@?<v@?@"NSDictionary"@"NSError">28
Vv40@0:8B16Q20B28@?<v@?@"NSDictionary"@"NSError">32
Vv28@0:8B16@?<v@?@"NSDictionary"@"NSError">20
Vv32@0:8@"NSString"16@?<v@?@"NSString"@"NSError">24
Vv32@0:8@"CESRAssetConfig"16@?<v@?@"NSString"@"NSError">24
Vv32@0:8@"CESRAssetConfig"16@?<v@?@"CESRModelProperties"@"NSError">24
Vv32@0:8@"NSString"16@?<v@?@"NSData">24
Vv48@0:8@"NSDictionary"16@"NSData"24@"NSArray"32@?<v@?@"NSDictionary"@"NSData"@"NSError">40
Vv72@0:8@"NSDictionary"16@"NSDictionary"24@"NSString"32Q40B48B52@"NSSet"56@?<v@?@"NSDictionary"@"NSError">64
Vv36@0:8@"NSString"16B24@?<v@?@"NSData"@"NSString">28
Vv24@0:8@?<v@?@"NSNumber"@"NSError">16
Vv32@0:8@"NSSet"16@?<v@?@"NSNumber"@"NSError">24
Vv40@0:8@"NSSet"16Q24@?<v@?B@"NSError">32
Vv32@0:8@"NSSet"16Q24
Vv32@0:8@"AFSpeechCorrectionInfo"16@"NSString"24
Vv28@0:8B16@?<v@?>20
Vv76@0:8@"NSDictionary"16@"NSString"24@"NSDictionary"32@"NSArray"40@"NSString"48@"NSString"56B64@?<v@?@"NSDictionary"@"NSError">68
v36@0:8@16B24@?28
v48@0:8@16@24@32@?40
@56@0:8@16@24@32^@40^@48
@48@0:8@16@24@32^@40
v24@0:8^@16
v28@0:8^@16B24
@"_EARSpeechRecognizer"
@"_EARSpeechRecognitionAudioBuffer"
@"NSXPCConnection"
@"AFSpeechPackage"
@"NSMutableArray"
@"NSSet"
@"ESStoreAudioData"
@"ESBiomeRecord"
@"ESSelfHelper"
@"_EARSpeakerCodeWriter"
@"CESRFidesASRRecord"
@96@0:8@16@24@32@40Q48@56@64@72B80B84@88
v40@0:8q16@24q32
@"NSMutableData"
B32@0:8@"NSXPCListener"16@"NSXPCConnection"24
%s SELF: Logging object created successfully (logging allowed for current request). asrId=%@, recognitionTask=%@, isSpeechAPIRequest=%@, isHipaaCompliant=%@, siriOptInStatus=%@, isTranscriptLoggingAllowed=%@
%s SELF: Logging disabled because it is not allowed for the current request. recognitionTask=%@, isSpeechAPIRequest=%@
%s SELF: Correct Partial Result Index List is %s, Silence Start Time List is %s
%s SELF: Encountered malformed string during SELF logging for recognizer components in speech results from recognizer. String: (%@)
%s SELF: Expected three recognizer components separated by delimiter '::'. Ex: 'dnn-rfdnn-aa-cache::dnn-lazy-16k-rfdnn-dictation::msg'
%s SELF: Encountered malformed string during SELF logging for interpolation weights in speech results from recognizer. String: %@
%s SELF: Expected interpolation weight sets separated by delimiter ';' - starting with a set of weights delimited by ',' and ending the with start/end times delimited by ':'. Ex: '0.999646,0.000354:0:4280;0.947514,0.000158:0:3859'
%s SELF: Logging ASRRequestContext->failed in SELF based on error result from recognizer.
%s SELF: Logging ASRRequestContext->cancelled with reason RECOGNITION_CANCELLED in SELF based on error result from recognizer.
%s SELF: Logging ASRRequestContext->cancelled with reason RECOGNITION_REJECTED in SELF based on error result from recognizer.
%s SELF: Logging ASRRequestContext->cancelled with reason RECOGNITION_REJECTED in SELF because nothing was recognized (SpeechNoMatch).
%s SELF: Logging ASRRequestContext->ended in SELF based on success status from recognizer.
%s SELF: Failed trying to wrap and emit top-level ASR event because event type was not mapped to loggable message type in the ASR SELF schema.
%s SELF: Wrapping and logging an event of type %@
%s Purging compiled assets if there are any.
%s Previously installed asset has been removed: %{public}@
%s Installed asset is corrupt! Triggering emergency purge %{public}@
%s Skipping catalog download because it has only been %.0f seconds
%s Skipping catalog download because it has only been %.0f seconds since last failed attempt
%s The MobileAsset catalog download result was %ld
%s The MobileAsset catalog downloaded successfully
%s Failed to register for MA asset update notifications.
%s Failed to register for dictation asset update notifications.
%s Failed to register for assistant asset update notifications.
%s Installation status for languages (ignoring cache: %@)
%s Trial asset delivery is enabled!
%s Invalidating installation status cache for %lu
%s Language installation status query failed: %@
%s MobileAsset is broken: %ld
%s Found assets: %@
%s Previously installed offline language(s) removed; installed list: [%@] -> [%@]
%s Using ASR Trial assets at %@
%s No assets available for language: %@ asset type: %{public}@
%s Falling back to MA assets for language: %@ asset type: %{public}@
%s Returning no model path for nil language
%s Remote fetch asset fetch got assets but none have been installed yet: %@
%s Async asset query failed for query=%@, error=%ld
%s Returning no installed asset for nil language
%s Recording newly installed offline language (%@) installed list is now: [%@]
%s Previously installed offline language (%@) removed; installed list is now: [%@]
%s Found %lu asset(s) for %@, with latest being (%@)
%s Starting a download because %p != %p
%s %@
%s MobileAsset is having trouble with queryMetaDataSync: %ld
%s MobileAsset said it succeeded but it didn't for %{public}@: query=%{public}@
%s No assets were found for query: %@
%s Trial asset delivery is enabled. No need to start a MobileAsset download
%s Downloading %@
%s Asset Download Progress: %lld of %lld bytes, ~%.2f seconds remaining
%s Asset Download Progress stalled at %lld of %lld bytes
%s Asset is already installed, no need to start download
%s Asset requires %lld bytes, starting download
%s Asset download successful
%s Asset download failed: %ld
%s Not enough space to download asset, size=%{public}lld
%s Asset download is already queued and in progress
%s Unexpected asset state %ld
%s Asset download state=%ld, success=%d, error=%@
%s Ignoring Purging asset: %@, language %@
%s Purging asset: %@, language %@
%s Purging failed: %@
%s Purging Trial assets failed: %@
%s Purging outdated assets.
%s Error canceling download of (%@) before fetching newer version: %ld
%s Error purging (%@) before fetching newer version: %ld
%s Purged old asset %@
%s Just ignoring %@
%s Purging failed: %lu
%s Checking for missing assets.
%s Missing Trial ASR assistant assets for %@. Starting a download.
%s Trial ASR assistant assets for %@ are already downloaded.
%s Purging all assistant ASR assets except for %@
%s Purging all assistant ASR assets
%s Encountered error trying to purge unused assistant ASR assets: %@
%s Trial asset delivery disabled for assistant assets. Bailing out of missing asset check.
%s Hit error querying installation status of MobileAssets: %@
%s Trial dictation assets for %@ are already downloaded. Purging corresponding assets from MobileAssets
%s Hit error purging assets from MobileAssets: %d %@
%s Missing trial dictation assets for %@. Starting a download.
%s Trial asset delivery disabled for dictation assets. Bailing out of missing asset check.
%s Trial asset delivery explicitly disabled!
%s Trial asset delivery explicitly enabled!
%s Hammer model info=%@
%s Exception thrown while reading hammer config
%s GeoLM: region mapping json file=%@
%s GeoLM: region mapping json file is nil Or there is no regionMapping for given language=%@
%s GeoLM: For the given location, selected regionId=%@
%s GeoLM: location is nil.
%s GeoLM: region specific [%@] geo-config json file=%@
%s GeoLM: geoLM asset exisits on device, but not compatible. Deleting...
%s GeoLM: Exception thrown while reading geo-config json
%s GeoLM: region specific asset is not found for given language=%@ regionId=%@
%s GeoLM: model-info.version doesn't match. mainASRModelInfo.version=%@ geoLMModelInfo.version=%@ mainAssetConfig=%@ geoAssetConfig=%@
%s GeoLM: Exception thrown while reading json configs
%s GeoLM: language is nil. Skipping.
%s GeoLM: regionIdToBePurged: %@, lastWhenUsed: %ld days ago
%s GeoLM: regionIdToBePurged: %@, _geoLMAssetsInfoDict count: %ld
%s GeoLM: supportedLanguages count:%ld
%s GeoLM: Going to delete: %@
%s MobileAsset is sad: %ld
%s %@ cancelling instance %@
%s %@ deallocating
%s Acquired os_transaction for dictation preheat
%s Released os_transaction for dictation preheat
%s Failing to fetch assets for nil language
%s Could not get offline language for fetch fallback: %{public}@
%s Fell back asset fetch from %{public}@ to %{public}@
%s Failed to fall back asset fetch from %{public}@ to %{public}@, got %{public}@
%s Can't get user data options: %{public}@
%s Unable to serialize user profile to JSON data: %{public}@
%s Could not get installed offline language statuses: %{public}@
%s Override json files=%@
%s Failed to create recognizer from %{public}@
%s EmbeddedSpeechMetric: Created recognizer in %lf sec from %@
%s Skipping preheat for %@; recognizer already loaded
%s Preheated for language %{public}@, asset type %{public}@, regionId %@%{public}@
%s Could not preheat for language %{public}@, asset type %{public}@, regionId %@%{public}@: %@
%s dictationCapable=%d task=%@ aneCapable=%d
%s Starting
%s Recognizer is busy
%s Interrupting training for cached recognizer
%s Cached recognizer for language %{public}@, asset type %{public}@, regionId %@ already  loaded
%s Cached recognizer is for language %{public}@, asset type %{public}@, regionId %@,  requesting recognizer for language %{public}@, asset type %{public}@, regionId %@
%s No cached recognizer.
%s EndpointStart > 0 but asr features delivery is disabled!
%s EndpointStart < 0
%s Injecting contextual data to recognizer
%s Built inline LME from contextual data, size: %zu
%s Injected %lu jit strings or contextual data to recognizer
%s Failed to build jitData for jitGrammar or contextual data
%s Failed to initialize jit profile builder due to error : %@
%s Failed to get model root, error: %@
%s Duration spent in adding jit strings = %{public}lfs
%s Set inputOrigin to: %@
%s Switching off UC/UD for this request
%s Changing active configuration from 
%@ to 
%s Create DES record
%s Cancelling delayedBlock
%s Create DES record for Dictation with interactionId=%@
%s _storeAudioData should be nil. Critical Error. Please check.
%s Interaction identifier did not match the DES record in memory
First Audio Packet
ES: First Audio Packet
%s Using override profile at %@
%s Could not use override profile at %@: %@
%s Deserialization of existing speech profile failed: %{public}@
%s Mismatch in speech profile language in content (%{public}@) and filename (%{public}@)
%s Profile version on disk (%{public}@) does not match the expected version (%{public}@)
%s Successfully deserialized existing speech profile for %@
%s Creating profile for %@
%s Re-using existing profile data because the asset (%@) is unchanged
%s Ignoring existing profile data because the asset changed (%@ to %@)
%s Cancelling profile update for %@ due to invalidation
%s Got no data from CESRUserData
%s Skipping profile update for %@ because user data has not actually changed
%s Created new profile with %ld bytes (was %ld bytes)
%s Recipe for %{public}@ is missing "%{public}@"
%s Recipe for %{public}@ contains parameter %{public}@, expected type %{public}@ but got %{public}@
%s Using name frequencies adaption for names: %@ into slot %@ for template %@
%s Ignoring name part "%@" because it is too short (minimum length is %lu)
%s Using keyboardLMAdaptation adaption for names %@ into slot %@ for template %@
%s Ignoring keyboardDynamicVocabularyItem "%@" because it is too short (minimum length is %lu)
%s Using locationOfInterestNameAdaptationFrequency adaption for names %@ into slot %@ for template %@
%s Ignoring locationOfInterestName "%@" because it is too short (minimum length is %lu)
%s Using eventLocationNameAdaptationFrequency adaption for names %@ into slot %@ for template %@
%s Ignoring calendar event word "%@" because it is too short (minimum length is %lu)
%s Cooldown timer triggered TRIClient release
%s Cooldown timer triggered asset purge
%s embeddedspeech process launch triggered asset purge
%s Sending %lu events
%s Recipe has invalid json for "%{public}@"
%s Recipe has invalid tagName for "%{public}@": "%{public}@"
%s Error executing recipe for domain %{public}@
%s Unable to load the contents of file %@: %@
%s Invalid file format
%s Running distributed evaluation for ASR
%s No attachments given, cannot run distributed evaluation
%s Failed to extract test set: %@
%s Cannot initialize recognizer for locale: %@ task: %@
%s Loaded speech profile
%s Unable to load speech profile
%s Test set contains more utterances than allowed, only running %d utterances
%s Unable to load audio file %@
%s Unable to find reference transcriptions for %@
%s Recipe has no profile
%s Stop adaption recipe. Audio file not readable. Voicemail has been deleted by user
%s Read %lu bytes from audio file
%s Using on device personalization recipe for baseline
%s Recognizer doesn't support the task %{public}@
%s Couldn't create create path for temporary confidence model overrides at %@
%s Couldn't write data to temporary confidence model file at path %@
%s Could not make baseline results
%s Failed to extract quasar model: %@
%s No recognizer created for custom model: %@
%s Could not make results with custom model
%s Profile overrides failed
%s Ignoring malformed overrides: %{public}@
%s Recipe has no recognizer
%s Could not make adapted results
%s Exception evaluating recipe: %@
%s Unknown exception evaluating recipe
%s No tokenizer for %@
%s Interrupted corrected text evaluation redecoding
%s Examining localSpeechDESRecord: %@
%s Unable to load localSpeechDESRecord
%s No audio data provided for UUID %@
%s Recognition result %@, %lu
%s Edit distance between tts ASR and original ASR %@
%s correctedOutput: %@, recognizedOutput %@
%s Set model root to %@
%s Use currently installed asset.
%s %{public}@
%s Unknown evaluation name found in alignmentReferences: %@
%s modelRoot: %@
%s No modelRoot for %@: %@
%s Unable to load audio
%s Recognizer doesn't support the task %{public}@: %@
%s Interrupted evaluation redecoding
%s Running recognition for evalName: %@
%s Failed to get override files, error: %@
%s Creating recognizer with overrides: %@
%s Using Personalized LM
%s Not using Personalized LM
%s Unable to restore speech profile
%s Using JIT LME
%s JIT LME: Injecting JIT data
%s JIT LME: Error fetching JIT data, error: %@
%s No results for evalName %@: %@
%s Tokenizing correctedText
%s Interrupted evaluation tokenization
%s Computing alignments
%s Failed to delete temporary directory: %@
%s Error when getting dictation language status: %@
%s Starting to compile dictation language: %@
%s Error when compiling dictation language model: %@
%s Starting to compile assistant language: %@
%s Error when compiling assistant language model: %@
%s Error when getting assistant language status: %@
%s Failed to fetch user data options
%s No DES record, nothing to write
%s Not saving DES Record with no data or recognition
%s Fetch user data for language: %@
%s Can't get user data options for DES record language: %@, not writing record
%s Got nil user data for DES record language: %@, not writing record
%s wordCount = %ld, trailingSilenceDuration = %ld, eosLikelihood = %f, pauseCounts = %@, silencePosterior = %f
%s Setting recognized text
%s %lu results
%s EmbeddedSpeechMetric: first audio packet to first partial result = %lf secs
Words recognized: %ld
ES: Partial Recognition
%s Audio finish to recognizer finish = %lf sec, connection is %@, error %@
%s _recognitionBeginTime (%@) is greater than _recognitionEndTime (%@)
%s Local speech recognition completed without error, write DES record when needed
%s Writing DES record after 30 seconds delay: interactionId=%@
%s Submitted delayedBlock to dispatch_after
%s #ASR on device eager formatted recognition candidate: %@
%s raw eager recognition candidate: %@
%s Could not make temporary attachment directory at %@: %@
%s Failed to specify compression algorithm: %s
%s Failed to specify format: %s
%s Start extracting archive at path: %s
%s Failed to open archive for reading: %s
%s Entry extraction path: %@
%s Unable to extract file to: %@
%s Finished extracting archive to: %@
%s Could not read %@: %@
%s Could not parse %@: %@
%s %@ is wrong type: %@
%s %@ contains bogus key/value pair: %@ => %@
%s Could not locate asset: %@
%s Could not read personalization.json: %@
%s Could not parse personalization.json: %@
%s User Profile: Starting AddWordsToUserProfile
%s VoiceMail asset could not be read: %@
%s Could not create asset reader output
%s Cannot add output
%s Could not get data pointer: %d
%s JSON serialization failed: %@
%s Compression failed: %@
%s AFSpeechLatticeMitigatorResult Score = %f, Threshold = %f
%s AFSpeechLatticeMitigatorResult nil
%s Sampling: Error while initializing ESStoreAudioData because uuid is invalid.
%s %@ Sampling: Won't save audio because - has not recognized anything or has no data.
%s %@ Sampling: Won't save audio because - _currentAudioFilePath is null
%s %@ Sampling: invalid filePath or it is null.
%s %@ Sampling: Done with cleanup of audioFile=%@ and reset of variables.
%s %@ Sampling: Failed to save audio to cache dir. Error: %@
%s %@ Sampling: Successfully saved audio file to cache dir, path=%@
%s %@ Sampling: audioFileToBeMoved is nil
%s %@ Sampling: currentSamplingDate is nil
%s %@ Sampling: Error while creating Sampled directory in /var/mobile
%s %@ Sampling: Error while creating dated Sampled directory in %@ with date - %@
%s %@ Sampling: Error while moving file from cache directory to var/mobile/Library - %@
%s %@ Sampling: Successfully moved audio file to var/mobile/Library dir, path=%@
%s %@ Sampling: Error while writing audio metadata dict to plist - %@
%s %@ Sampling: currentSamplingDateString is null
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
<key>application-identifier</key>
<string>com.apple.siri.embeddedspeech</string>
<key>com.apple.CoreRoutine.LocationOfInterest</key>
<true/>
<key>com.apple.accounts.appleaccount.fullaccess</key>
<true/>
<key>com.apple.application-identifier</key>
<string>com.apple.siri.embeddedspeech</string>
<key>com.apple.coreaudio.allow-amr-decode</key>
<true/>
<key>com.apple.coreduetd.allow</key>
<true/>
<key>com.apple.coreduetd.people</key>
<true/>
<key>com.apple.developer.homekit</key>
<true/>
<key>com.apple.frontboardservices.display-layout-monitor</key>
<true/>
<key>com.apple.locationd.effective_bundle</key>
<true/>
<key>com.apple.private.DistributedEvaluation.RecordAccess-com.apple.fides.asr</key>
<true/>
<key>com.apple.private.DistributedEvaluation.RecordAccess-com.apple.siri.speech-dictation-personalization</key>
<true/>
<key>com.apple.private.assets.accessible-asset-types</key>
<array>
<string>com.apple.MobileAsset.EmbeddedSpeech</string>
<string>com.apple.MobileAsset.EmbeddedSpeechWatch</string>
<string>com.apple.MobileAsset.EmbeddedSpeechMac</string>
</array>
<key>com.apple.private.attribution.implicitly-assumed-identity</key>
<dict>
<key>type</key>
<string>path</string>
<key>value</key>
<string>/System/Library/PrivateFrameworks/CoreEmbeddedSpeechRecognition.framework/XPCServices/com.apple.siri.embeddedspeech.xpc/com.apple.siri.embeddedspeech</string>
</dict>
<key>com.apple.private.biome.read-write</key>
<array>
<string>SiriDictation</string>
</array>
<key>com.apple.private.calendar.allow-suggestions</key>
<true/>
<key>com.apple.private.contacts</key>
<true/>
<key>com.apple.private.corerecents</key>
<true/>
<key>com.apple.private.corespotlight.internal</key>
<true/>
<key>com.apple.private.homekit</key>
<true/>
<key>com.apple.private.security.storage.SpeechPersonalizedLM</key>
<true/>
<key>com.apple.private.tcc.allow</key>
<array>
<string>kTCCServiceAddressBook</string>
<string>kTCCServiceCalendar</string>
<string>kTCCServiceWillow</string>
<string>kTCCServiceMediaLibrary</string>
</array>
<key>com.apple.proactive.PersonalizationPortrait.Config</key>
<true/>
<key>com.apple.proactive.PersonalizationPortrait.NamedEntity.readOnly</key>
<true/>
<key>com.apple.proactive.eventtracker</key>
<true/>
<key>com.apple.security.exception.files.absolute-path.read-only</key>
<array>
<string>/private/var/tmp/com.apple.siri-distributed-evaluation/</string>
</array>
<key>com.apple.security.exception.mach-lookup.global-name</key>
<array>
<string>com.apple.suggestd.contacts</string>
</array>
<key>com.apple.security.iokit-user-client-class</key>
<array>
<string>AGXCommandQueue</string>
<string>AGXDevice</string>
<string>AGXDeviceUserClient</string>
<string>AGXSharedUserClient</string>
<string>H11ANEInDirectPathClient</string>
<string>IOAccelContext</string>
<string>IOAccelContext2</string>
<string>IOAccelDevice</string>
<string>IOAccelDevice2</string>
<string>IOAccelSharedUserClient</string>
<string>IOAccelSharedUserClient2</string>
<string>IOAccelSubmitter2</string>
<string>IOSurfaceRootUserClient</string>
</array>
<key>com.apple.security.personal-information.addressbook</key>
<true/>
<key>com.apple.security.temporary-exception.mach-lookup.global-name</key>
<array>
<string>com.apple.triald.namespace-management</string>
</array>
<key>com.apple.siriknowledged</key>
<true/>
<key>com.apple.spotlight.search</key>
<true/>
<key>com.apple.trial.client</key>
<array>
<string>372</string>
<string>401</string>
<string>751</string>
</array>
</dict>
</plist>
mcpl
