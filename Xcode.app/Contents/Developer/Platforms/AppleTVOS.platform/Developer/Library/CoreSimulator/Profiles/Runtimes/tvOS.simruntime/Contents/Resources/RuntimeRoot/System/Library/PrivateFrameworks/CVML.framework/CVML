NSt3__120__shared_ptr_pointerIPN6vision3mod24NNHierarchicalClusteringENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIN6vision3mod24NNHierarchicalClusteringEEE
NSt3__120__shared_ptr_emplaceINS_6vectorIhNS_9allocatorIhEEEENS2_IS4_EEEE
NSt3__120__shared_ptr_pointerIPN6vision3mod23GreedyClustererFacesAPIENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIN6vision3mod23GreedyClustererFacesAPIEEE
NSt3__120__shared_ptr_emplaceIN6vision3mod23ImageClassifierEspressoENS_9allocatorIS3_EEEE
N6vision3mod23ImageClassifierAbstractE
N6vision3mod29ImageDescriptorBufferAbstractE
NSt3__118basic_stringstreamIcNS_11char_traitsIcEENS_9allocatorIcEEEE
NSt3__115basic_stringbufIcNS_11char_traitsIcEENS_9allocatorIcEEEE
333?
NSt3__120__shared_ptr_emplaceIN6vision3mod33ImageClassifier_HierarchicalModelENS_9allocatorIS3_EEEE
N6vision3mod24SimilarityMatrixAbstractE
N6vision3mod5ERT2DIfEE
N6vision3mod16Transformation2DE
N6vision3mod23Transformation2DPrivateI19_Geometry2D_Affine_EE
N6vision3mod23Transformation2DPrivateI16_Geometry2D_RST_EE
?N6vision3mod23Transformation2DPrivateIA9_fEE
333333
N6vision3mod23ImageClassifierEspressoE
NSt3__120__shared_ptr_emplaceIN6vision3mod23ImageClassifierEspresso9private_tENS_9allocatorIS4_EEEE
N6vision3mod32ImageDescriptorProcessorAbstractE
fff?
4N6vision3mod14FaceboxAlignerE
?xwwwww
?xwwwww
?N6vision3mod30ObjectDetector_DCNFaceDetectorE
N6vision3mod22ObjectDetectorAbstractE
NSt3__120__shared_ptr_emplaceIN8Espresso4blobIDv4_hLi2EEENS_9allocatorIS4_EEEE
N8Espresso4blobIDv4_hLi2EEE
NSt3__120__shared_ptr_emplaceIN6vision3mod30ObjectDetector_DCNFaceDetector4privENS_9allocatorIS4_EEEE
NSt3__120__shared_ptr_emplaceIN6vision3mod29ImageDescriptor_EspressoSceneENS_9allocatorIS3_EEEE
N6vision3mod29ImageDescriptor_EspressoSceneE
yE>333333
NSt3__120__shared_ptr_emplaceIN6vision3mod28ImageDescriptor_EspressoFaceENS_9allocatorIS3_EEEE
N6vision3mod28ImageDescriptor_EspressoFaceE
NSt3__120__shared_ptr_pointerIPN6vision3mod11ModelValuesENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIN6vision3mod11ModelValuesEEE
NSt3__120__shared_ptr_emplaceIiNS_9allocatorIiEEEE
NSt3__120__shared_ptr_emplaceIfNS_9allocatorIfEEEE
NSt3__120__shared_ptr_pointerIPhNS_14default_deleteIA_hEENS_9allocatorIhEEEE
NSt3__114default_deleteIA_hEE
NSt3__120__shared_ptr_pointerIPfNS_14default_deleteIA_fEENS_9allocatorIfEEEE
NSt3__114default_deleteIA_fEE
NSt3__120__shared_ptr_pointerIPiNS_14default_deleteIA_iEENS_9allocatorIiEEEE
NSt3__114default_deleteIA_iEE
NSt3__120__shared_ptr_pointerIPjNS_14default_deleteIA_jEENS_9allocatorIjEEEE
NSt3__114default_deleteIA_jEE
NSt3__120__shared_ptr_emplaceIN6vision3mod28ImageDescriptor_EspressoJunkENS_9allocatorIS3_EEEE
N6vision3mod28ImageDescriptor_EspressoJunkE
NSt3__120__shared_ptr_pointerIPKhZN4cvml4util31binserialized_table_of_contents9blob_infoC1ES2_RK26_BinSerializer_blobHeader_EUlS2_E_NS_9allocatorIS1_EEEE
ZN4cvml4util31binserialized_table_of_contents9blob_infoC1EPKhRK26_BinSerializer_blobHeader_EUlS4_E_
NSt3__120__shared_ptr_pointerIPN6vision3mod18LandmarkAttributesENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIN6vision3mod18LandmarkAttributesEEE
L>_p
Mb`?
N6vision3mod24NNHierarchicalClusteringE
N6vision3mod28ImageDescriptorBufferFloat32E
NSt3__120__shared_ptr_pointerIPN6vision3mod29ImageDescriptorBufferAbstractENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIN6vision3mod29ImageDescriptorBufferAbstractEEE
NSt3__120__shared_ptr_emplaceIN6vision3mod28ImageDescriptorBufferFloat32ENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_pointerIP6LCKSVDNS_14default_deleteIS1_EENS_9allocatorIS1_EEEE
NSt3__114default_deleteI6LCKSVDEE
 Aff&?
NSt3__111__end_stateIcEE
NSt3__16__nodeIcEE
NSt3__120__shared_ptr_pointerIPNS_13__empty_stateIcEENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteINS_13__empty_stateIcEEEE
NSt3__113__empty_stateIcEE
NSt3__116__owns_one_stateIcEE
NSt3__115__has_one_stateIcEE
NSt3__110__l_anchorIcEE
NSt3__110__r_anchorIcEE
NSt3__115__word_boundaryIcNS_12regex_traitsIcEEEE
NSt3__111__lookaheadIcNS_12regex_traitsIcEEEE
NSt3__123__match_any_but_newlineIcEE
NSt3__118__match_char_icaseIcNS_12regex_traitsIcEEEE
NSt3__120__match_char_collateIcNS_12regex_traitsIcEEEE
NSt3__112__match_charIcEE
NSt3__116__back_ref_icaseIcNS_12regex_traitsIcEEEE
NSt3__118__back_ref_collateIcNS_12regex_traitsIcEEEE
NSt3__110__back_refIcEE
NSt3__120__bracket_expressionIcNS_12regex_traitsIcEEEE
NSt3__128__begin_marked_subexpressionIcEE
NSt3__126__end_marked_subexpressionIcEE
NSt3__16__loopIcEE
NSt3__117__owns_two_statesIcEE
NSt3__117__repeat_one_loopIcEE
NSt3__111__alternateIcEE
NSt3__121__empty_non_own_stateIcEE
NSt3__111__match_anyIcEE
6SCDict
9SCDictOMP
9SCDictFSS
12PackedCoeffs
?NSt3__120__shared_ptr_pointerIPN6vision3mod17VIPIdentificationENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIN6vision3mod17VIPIdentificationEEE
N6vision3mod16LandmarkDetectorE
N6vision3mod32ImageDescriptorProcessorEspressoE
NSt3__120__shared_ptr_emplaceIN6vision3mod32ImageDescriptorProcessorEspresso9private_tENS_9allocatorIS4_EEEE
NSt3__120__shared_ptr_emplaceIN8Espresso22dropout_augment_lowmemENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_pointerIPN6vision3mod13FaceRegionMapENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIN6vision3mod13FaceRegionMapEEE
10SCDictKSVD
N6vision3mod20SimilarityMatrixFullE
N6vision3mod18ClusteringAbstractE
yA$H
ITCA
vA,2
q@,2
5mAv<
9Bh6
NSt3__120__shared_ptr_emplaceIN6vision3mod22ImageClassifierGlimmerENS_9allocatorIS3_EEEE
Ga=33
N6vision3mod31ColorGaborImageDescriptorBufferE
N6vision3mod34ColorGaborImageDescriptorProcessorE
NSt3__120__shared_ptr_emplaceIN6vision3mod31ColorGaborImageDescriptorBufferENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_pointerIPN6vision3mod16LandmarkDetectorENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIN6vision3mod16LandmarkDetectorEEE
@@NSt3__120__shared_ptr_pointerIPN6vision3mod30ObjectDetector_DCNFaceDetectorENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIN6vision3mod30ObjectDetector_DCNFaceDetectorEEE
W[q>
N6vision3mod28ImageDescriptorAugmenterFlipE
N6vision3mod32ImageDescriptorAugmenterAbstractE
N6vision3mod22ImageClassifierGlimmerE
NSt3__120__shared_ptr_emplaceIN6vision3mod22ImageClassifierGlimmer9private_tENS_9allocatorIS4_EEEE
NSt3__120__shared_ptr_pointerIPN6vision3mod15FaceFrontalizerENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIN6vision3mod15FaceFrontalizerEEE
NSt3__120__shared_ptr_pointerIPN6vision3mod28ImageDescriptorAugmenterFlipENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIN6vision3mod28ImageDescriptorAugmenterFlipEEE
5?ff
?333333
N6vision3mod23GreedyClustererFacesAPIE
N6vision3mod14FaceClusteringE
N6vision3mod15GreedyClustererE
NSt3__120__shared_ptr_pointerIPN4cvml4util15RAMBackingStoreENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIN4cvml4util15RAMBackingStoreEEE
NSt3__120__shared_ptr_emplaceIN6vision3mod15GreedyClusterer9private_tENS_9allocatorIS4_EEEE
NSt3__120__shared_ptr_emplaceINS_6vectorImNS_9allocatorImEEEENS2_IS4_EEEE
NSt3__120__shared_ptr_emplaceINS_6vectorINS_4pairImmEENS_9allocatorIS3_EEEENS4_IS6_EEEE
?333?
&:/1
mVA=
\L;&
*RY;4|
KdC<
+/l?
rTD?
9FI?
W@+/l?
,A?P
?+/l?
+/l?@
q@4J?
9Q>`^
w=?k+K
F?]"!@R
?bD&>xzr?
uw?-
Fs?)
'I^?`
l?6a
>xq%
$@t=
;?`1S>
>M;{?
?;+n?
{f=~C
G]Z?
_=E3
wi@^ 
?k+H
7kV@
333?
?33s?
NSt3__120__shared_ptr_pointerIPfZN6vision3mod28readBinSerializedModelValuesEP7__sFILEPKcRKNS3_26BinSerializedModelFileInfoEbRNS3_11ModelValuesEE3$_0NS_9allocatorIfEEEE
ZN6vision3mod28readBinSerializedModelValuesEP7__sFILEPKcRKNS0_26BinSerializedModelFileInfoEbRNS0_11ModelValuesEE3$_0
NSt3__120__shared_ptr_pointerIPhZN6vision3mod28readBinSerializedModelValuesEP7__sFILEPKcRKNS3_26BinSerializedModelFileInfoEbRNS3_11ModelValuesEE3$_1NS_9allocatorIhEEEE
ZN6vision3mod28readBinSerializedModelValuesEP7__sFILEPKcRKNS0_26BinSerializedModelFileInfoEbRNS0_11ModelValuesEE3$_1
333333
?333333
N12_GLOBAL__N_120FaceDescriptorBufferE
NSt3__120__shared_ptr_pointerIPN6vision3mod20SimilarityMatrixFullENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIN6vision3mod20SimilarityMatrixFullEEE
NSt3__120__shared_ptr_pointerIPN6vision3mod20SimilarityMatrixLazyENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIN6vision3mod20SimilarityMatrixLazyEEE
NSt3__120__shared_ptr_pointerIPN6vision3mod24SimilarityMatrixAbstractENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIN6vision3mod24SimilarityMatrixAbstractEEE
NSt3__120__shared_ptr_pointerIPN6vision3mod14FaceboxAlignerENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIN6vision3mod14FaceboxAlignerEEE
N6vision3mod20SimilarityMatrixLazyE
@(#)PROGRAM:CVML  PROJECT:CVML-1.64.0
kCVMLClusteringDistanceThreshold
kCVMLClusteringDescriptorIds
kCVMLClusteringDistanceMatrix
Hierarchical clustering
clustering with hierarchical method
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
en_US_POSIX
yyyy-MM-dd_HH-mm-ss-SSS
cvmlClusteringLog
%@_%@.log
Level %@ cluster map:
ClusterId: %lld
%@Faces: 
%lld
0 Lookup
1 Lookup
logFolderURL
T@"NSURL",R,V_logFolderURL
logFileURL
T@"NSURL",R,V_logFileURL
logEnabled
TB,R,V_logEnabled
fileNameBase
T@"NSString",R,V_fileNameBase
cvmlSuggestionLog
Input query - face IDs with flags (clusterIdsWithFlags):
faceId: %@
%@can be returned: %@
Suggested face IDs: %@:
ClusterId: %@   
%@Suggestions: 
%@, 
all sugestions for given input query (suggestionLists)
filtered suggestions to include only those that are part of input query (suggestedInputsLists)
Connected groups of suggestions face IDs (connectedSuggestedInputs):
Group %d suggestions: 
Final list of suggestions face IDs (results):
cvml_debug_enable_cluster_log
v8@?0
Cache folder '%s' could not be created.
RestoreClusteringState must have an NSData object
Error initializing cluster state
Clusterer state is inconsistent with clusterer version.  Please restart clustering
Clustering with greedy algorithm
Greedy clustering
adding faces (%lu): %s
Clusters:
  %d: prevcount=%d, curcount=%d, shouldUpdateRep = %d
clusters:
  clusterId: %ld, %s
greedy clustering based suggestions require knowledge of valid outputs from the input list
this CVML request option was depricated
-[CVMLGreedyClustering getLevel1ClusteredIdsGroupedByLevel0ClustersForFaceId:]_block_invoke
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/VisionKitFramework/CVML/internal/CVMLGreedyClustering.mm
level0FaceIds.count != 0
v24@?0@"NSNumber"8@"NSMutableOrderedSet"16
v32@?0@8Q16^B24
getRepresentativenessForFaces was cancelled
  face[%d].representativeness = %.3f
  best rep = %d
Unexpected internal error in get clusters
getClusters was cancelled
%s error %lld:%s in %s @ %s:%d
void *vision::mod::ImageDescriptorBufferAbstract::getDataForKthDescriptor(int) const
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/ImageDescriptor/ImageDescriptor_BufferAbstract.h
map::at:  key not found
apple_scenes_onlyfc
std::map<std::string, float> vision::mod::ImageClassifierAbstract::classifyDescriptor(const vision::mod::ImageDescriptorBufferAbstract &, bool, bool)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/ImageClassifier/ImageClassifier_Abstract.h
ClusterObservation couldn't initialize
ClusterObservation couldn't initialize
Couldn't add descriptors to matrix.
Couldn't add descriptors to matrix.
Couldn't add descriptors to clustering engine.
Couldn't add descriptors to clustering engine.
matrix
Could not get clusters (getClustersWithOptions) in clusterFacesWithOptions
Couldn't get cluster state from clustering engine.
Couldn't restore cluster state.
T@"CVMLSimilarityMatrix",&,V_matrix
clusterMethod
T@"NSString",R,V_clusterMethod
useClusterObservation
TB,R,V_useClusterObservation
clusteredFaceIds
T@"NSSet",R,GgetClusteredFaceIds
Disgust
Neutral
Scream
Smile
Surprise
Suspicious
CVML_status vision::mod::ImageDescriptorBufferAbstract::initBufferWithData(void *, size_t, size_t, bool)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/ImageDescriptor/ImageDescriptor_BufferAbstract.cpp
vision::mod::ImageDescriptorBufferAbstract::ImageDescriptorBufferAbstract(void *, size_t, size_t, bool)
vision::mod::ImageDescriptorBufferAbstract::ImageDescriptorBufferAbstract(const std::vector<ImageDescriptorId> &, void *, size_t, size_t, bool)
virtual CVML_status vision::mod::ImageDescriptorBufferAbstract::appendDescriptors(const vision::mod::ImageDescriptorBufferAbstract &)
virtual CVML_status vision::mod::ImageDescriptorBufferAbstract::deleteDescriptorAtIndex(const int, std::vector<int> *)
virtual CVML_status vision::mod::ImageDescriptorBufferAbstract::deleteDescriptorsAtIndexes(const std::vector<int> &, std::vector<int> *)
virtual CVML_status vision::mod::ImageDescriptorBufferAbstract::deleteDescriptorsWithIds(const std::vector<ImageDescriptorId> &, std::vector<ImageDescriptorId> *)
int vision::mod::ImageDescriptorBufferAbstract::getSelfDistanceIndexOnFlattenedList(int, int)
virtual float vision::mod::ImageDescriptorBufferAbstract::computeDistanceFrom(const vision::mod::ImageDescriptorBufferAbstract &)
vision::mod::ImageDescriptorBufferAbstract &vision::mod::ImageDescriptorBufferAbstract::setDescriptorIdForKthDescriptor(int, ImageDescriptorId)
void vision::mod::ImageDescriptorBufferAbstract::resizeForDescriptorsCount(size_t, bool)
virtual vision::mod::ImageDescriptorBufferAbstract *vision::mod::ImageDescriptorBufferAbstract::createEmptyCopy() const
Descriptor count = 
Descriptor length = 
 bytes
virtual vision::mod::ImageDescriptorBufferAbstract *vision::mod::ImageDescriptorBufferAbstract::getRepresentative(vision::mod::ImageDescriptorBufferAbstractRepresentativeMode, ImageDescriptorId) const
Processing suggestionsForClusters request
Trying to call suggestions request with no prior clustering context loaded (need to have a CVMLClusterObservationsRequest first)
Couldn't get clusters from clustering engine.
Trying to cancel a suggestion request with no context
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/FaceWarper/FaceWarper_Warp.c
CVML_status FaceWarper_computeAnchorRST(const Geometry2D_cart2D *, const int *, int, const Geometry2D_point2D *, const Geometry2D_size2D *, Geometry2D_RST *)
v16@?0Q8
createBridgeSegment
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/RectangleDetector/QuadDetect/ContourUtilities.c
mPnts == nPnts
reverseContour
currCPtr != NULL
AnnealContour
sPtrPrev != sPtr
sPtr != sPtrNext
rPtr != NULL
annealSegments
sPrevPtr != sPtr
newCurr != NULL
mergeContourEnd
cPtr2->active
PCOORD_EQUAL(sPtr2->pary[sPtr2->nPnts-1], pc3)
(code == 1) || (code == 2)
mergeEndpointSearch4
code1 != -1
code2 != -1
com.apple.Foundation
Vision.framework
scene-descriptor
scene-classifier
scene-classifier-labels
scene-classifier-relationships
B16@?0^@8
Image buffer supplied with 0 length dimension (width or height)
Could not compute image descriptor for image
cvml_scene_classifier_debug_intermediates/
.json
CVML_DEBUG_DUMP_SCENE_INTERMEDIATES
  calculateChecksumMD5ForFile: error reading %d bytes from file
Geometry2D_cart2D vision::mod::ERT2D<float>::predict(const Geometry2D_cart2D &, const Geometry2D_cart2D &) [F = float]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/ERT/ERT2D.cpp
algParam
void vision::mod::ERT2D<float>::init(const vision::mod::ModelValues &, const char *) [F = float]
nodeParam
leafParam
regLookup
ERT - p : %d
testFeature
p.n > 0
ERT - node params are unavailable
ERT - reg lookup is unavailable
ERT - maxCacheSize: %lu
ERT - cacheIndexL : %d
ERT - cacheIndexR : %d
false
ERT - anchorIndex : %d
CVML_status vision::mod::ERT2D<float>::testFeature(int, int, int, const vision::mod::Transformation2D *, Geometry2D_cart2D &, bool &) [F = float]
CVML_status vision::mod::ERT2D<float>::testCascade(int, const vision::mod::Transformation2D *, Geometry2D_cart2D &) [F = float]
CVML_status vision::mod::ERT2D<float>::testCascade(int, const vision::mod::Transformation2D *, Geometry2D_cart2D &) [F = float]_block_invoke
com.apple.cvml
request %@ was cancelled
request was cancelled
CVMLRequest
Internal Error Occurred. Code: %d; description: %s; reason: %s
ERROR: unknown transformation
CVMLImageRequestHandler_ImageOrientation
CVMLImageRequestHandler_ImageProperties
CVMLRequestHandlerCleanupOption_AllPipelines
CVMLRequestHandlerCleanupOption_FacePipeline
CVMLRequestHandlerCleanupOption_ScenePipeline
CVMLRequestHandlerCleanupOption_JunkPipeline
CVMLCleanupLevel_Complete
CVMLCleanupLevel_Partial
CVMLRequestHandlerCleanupOption_ImageBuffers
CVMLCleanupPurgeAll
com.apple.CVMLRequestHandler_Async
The requests parameter must be an array of CVMLRequests
Error could not obtain processing queue to perform request
cachedResults
T@"NSMutableDictionary",&,V_cachedResults
clusterContext
T@"NSObject",&,V_clusterContext
VNImageRequestHandler: processing asset: %s
imageBuffer
T@"CVMLImageBuffer",R,V_imageBuffer
properties
T@"NSDictionary",R,V_properties
previousRequests
T@"NSMutableDictionary",R,V_previousRequests
CVML_status LandmarkDetector_getIntensityFeature(const vImage_Buffer &, const Geometry2D_point2D &, LandmarkDetector_intensitySamplingMode, bool, uint8_t, float &)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/LandmarkDetector/LandmarkDetector_Features.cpp
CVML_status LandmarkDetector_getImagePreProcessedSamplingPixelPoint(const vImage_Buffer &, const Geometry2D_point2D &, bool, uint8_t, int, Geometry2D_point2D &)
CVML_status LandmarkDetector_rotateCoordinates(const Geometry2D_point2D &, uint8_t, const Geometry2D_size2D &, Geometry2D_point2D &)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/LandmarkDetector/LandmarkDetector_Utils.h
float LandmarkDetector_getImagePreProcessedGaussianSmoothedIntensity(const vImage_Buffer &, const Geometry2D_point2D &)
CVML_status FastRegistration_computeSignatures(const vImage_Buffer *, _Bool, dispatch_queue_t, FastRegistration_Signatures *)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/ImageRegistration/FastRegistration/FastRegistration_Core.c
CVML_status FastRegistration_register(const FastRegistration_Signatures *, const FastRegistration_Signatures *, float, dispatch_queue_t, float *, float *, float *, float *)
CVML_status FastRegistration_processProjections(float *, vImagePixelCount)
Could not initialize scene classification module
q24@?0@"CVMLClassification"8@"CVMLClassification"16
static CVML_status vision::mod::image_quality::BlurMeasure::computeEdgeBasedBlurForImageRegionUsingBlurSignature(void *, Geometry2D_rect2D, float *, float, int *, int *)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/ImageQuality/BlurMeasure/BlurMeasure.mm
CVML_status (anonymous namespace)::computeBlurStatsOnImageData(uint8_t *, int, int, int, float, float *, int *, int *, void **)
CVML_status (anonymous namespace)::applyInsetFactorToData(uint8_t **, int *, int *, int, int, float)
CVML_status (anonymous namespace)::computeBlurScoreOnImageSubblocks(uint8_t *, int, int, int, int, float, int, float *, int *, int *)
CVML_status (anonymous namespace)::applyInsetFactorToROI(Geometry2D_rect2D *, float)
Error while computing blur score: %s
Processing refinedSuggestionsForClusters request
refinedSuggestionsForClusters request missing the CVMLRequestOption_InputClusters input
refinedSuggestionsForClusters request missing the CVMLRequestOption_InputClusterIds input
virtual vision::mod::ImageClassifierAbstract &vision::mod::ImageClassifierEspresso::setDescriptorProcessor(const std::shared_ptr<ImageDescriptorProcessorAbstract> &)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/ImageClassifier/ImageClassifierEspresso/ImageClassifier_Espresso.mm
virtual std::map<std::string, float> vision::mod::ImageClassifierEspresso::classifyDescriptorHandler(const vision::mod::ImageDescriptorBufferAbstract &)
v16@?0r^{shared_ptr<Espresso::abstract_batch>=^{abstract_batch}^{__shared_weak_count}}8
v24@?0{shared_ptr<Espresso::blob<float, 4> >=^{blob<float, 4>}^{__shared_weak_count}}8
void vision::mod::ImageClassifierEspresso::private_t::loadClassifier(ImageClassifierEspresso::Options, vision::mod::ImageClassifierEspresso *, const char *, const char *, ImageClassifierEspresso::PLATFORM, ImageClassifierEspresso::COMPUTE_PATH)
virtual std::map<std::string, float> vision::mod::ImageClassifierEspresso::classifyImage_RGBA8888(const vImage_Buffer &)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/ImageClassifier/ImageClassifierEspresso/ImageClassifier_Espresso.h
virtual std::map<std::string, float> vision::mod::ImageClassifierEspresso::classifyImage_BGRA8888(const vImage_Buffer &)
virtual std::map<std::string, float> vision::mod::ImageClassifierEspresso::classifyImage_Planar8(const vImage_Buffer &)
hash
TQ,R
superclass
T#,R
description
T@"NSString",R,C
debugDescription
name
T@"NSString",R
registryID
maxThreadsPerThreadgroup
T{?=QQQ},R
lowPower
TB,R,GisLowPower
headless
TB,R,GisHeadless
removable
TB,R,GisRemovable
recommendedMaxWorkingSetSize
depth24Stencil8PixelFormatSupported
TB,R,GisDepth24Stencil8PixelFormatSupported
readWriteTextureSupport
argumentBuffersSupport
rasterOrderGroupsSupported
TB,R,GareRasterOrderGroupsSupported
currentAllocatedSize
maxThreadgroupMemoryLength
programmableSamplePositionsSupported
TB,R,GareProgrammableSamplePositionsSupported
Incorrect value for 'CVMLRequestOption_PreferredMetalContext' option
Requested Metal Device is not supported: %@
metalDevice
T@"<MTLDevice>",R,V_metalDevice
wisdomParams
T@"NSDictionary",R,V_wisdomParams
useGPU
TB,R,V_useGPU
CVMLDetectorProcessOption_InputImageBuffers
CVMLDetectorProcessOption_UseFullBuffer
CVML
com.apple.cvml.processingQueue
%@ does not implement %@
@"NSString"8@?0
+[CVMLDetector bestImageWidth:height:format:]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/VisionKitFramework/CVML/internal/CVMLDetector.m
Cannot initialize Metal Context
processingQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_processingQueue
BinSerializer
Face3D
FaceDescriptor
FaceFrontalizer
FaceWarper
Geometry2D
Geometry3D
ImageGrouping
ImageQuality
LandmarkDetector
MomentProcessor
FaceboxAligner
ImageDescriptor
ImageClassifier
ImageProcessing
VIPIdentification
ImageRegistration
SimilarityMatrix
Clustering
HumanDetector
FaceRegionMap
ObjectDetector
ImageTools
ImageWarper
ThirdParty
FaceProcessorCLI
ImageClassifierCLI
MPCmdlineClientCLI
ClusteringCLI
ImageProcessorCLI
!!! you should not read this !!!
feature extraction error
initialization error
no saved state to revert to error
nominal distance not changed
batch size violation
a computation kill request was issued by the system
too few ids to build VIP model
video error
error with the projection computation
missing positional parameter
inconsistent state error
warping error
GL error
invalid format
out of bounds error
singular point configuration error
Division by zero error
LAPACK error
platform endianess not supported
the hash is already in use
invalid ID
invalid data type
data inconsistency error
I/O error
unknown option
invalid option
missing option
delegate error
vImage related error
memory allocation error
invalid parameter
undexpected null pointer
internal error
not implemented error
CVMLFaceRegionMap_CodingVersionCodingKey
CVMLFaceRegionMap_UserBoundsOriginXCodingKey
CVMLFaceRegionMap_UserBoundsOriginYCodingKey
CVMLFaceRegionMap_UserBoundsSizeWidthCodingKey
CVMLFaceRegionMap_UserBoundsSizeHeightCodingKey
CVMLFaceRegionMap_AlignedBoundsOriginXCodingKey
CVMLFaceRegionMap_AlignedBoundsOriginYCodingKey
CVMLFaceRegionMap_AlignedBoundsSizeWidthCodingKey
CVMLFaceRegionMap_AlignedBoundsSizeHeightCodingKey
CVMLFaceRegionMap_RegionMapDataCodingKey
CVMLFaceRegionMap_RegionMapWidthCodingKey
CVMLFaceRegionMap_RegionMapHeightCodingKey
CVMLFaceRegionMap_RegionMapRowBytesCodingKey
CVMLFaceRegionMap_PixelToRegionMapCodingKey
Unknown
Processing representativeForClusters request
Trying to call getRepresentative request with no prior clustering context loaded (need to have a CVMLClusterObservationsRequest first)
Trying to call representative face request but value for CVMLRequestOption_InputFaces was not found
Trying to call representative face request but no faces were included in CVMLRequestOption_InputFaces
value CVMLRequestOption_InputFaces must be an NSArray of CVMLFaceObservation
com.apple.CVML.gaborFilterCreateGaborFilterBankGCDQueue
com.apple.CVML.GaborFilterExtractGaborDescriptorGCDQueue
CVML_status Geometry3D_projectCart(const Geometry3D_cart3D *, const float *, const Geometry3D_pose *, const Geometry2D_cart2D *)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/Geometry3D/Geometry3D_Projection.c
Processing Remove faces from face model request
Required arguments, CVMLRequestOption_InputFaces and CVMLRequestOption_InputFaceModels, were not specified
CVMLRequestOption_InputFaceModels option not supplied
CVMLRequestOption_InputFaceModels is not a NSArray CVMLFaceModelObservations
CVMLRequestOption_InputFaces option not supplied
CVMLRequestOption_InputFaces is not a NSArray CVMLFaceObservations
A model specified in CVMLRequestOption_InputFaceModels is invalid
An element in CVMLRequestOption_InputFaces is not a CVMLFaceObservation
Attempt to add a face observation that doesn't have a faceprint.
Attempt to add a face observation that doesn't have a name.
CVML_status FaceRegionMap_addForeheadLandmarks(std::vector<Geometry2D_point2D> &)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/FaceRegionMap/FaceRegionMap_Core.cpp
CVMLImageBufferOption_DownscaleCGInterpolationQuality
CVMLImageBufferOption_UpscaleCGInterpolationQuality
ERROR while purging caches %s | %@
-[CVMLImageBufferManager purgeAllCaches]
CVMLImageBuffer - unhandled orientation: %d
CVMLImageBuffer - failed the image transfer
this release call should not be used with anything but a referencing pixelbuffer %s
void CVPixelBufferReleaseReferencingPixelBufferCallback(void * _Nullable, const void * _Nullable)
Failed to create image for processing
Failed to create image for processing due to invalid requested buffer dimensions
Failed to transfer pixel buffer from _origPixelBuffer %d
Failed to create a CGBitmapContext
Failed to transfer interim buffer. Error %d
Failed to create an interim buffer. Error %d
Unable to create a CGBitmapContext
Operation failed due to attempt to crop zero or near zero dimensioned area
Failed to transfer _origPixelBuffer to croppedBuffer. Error %d
Faile to crop the original CGImageRef.
invalid ROI size of %f x %f
invalid chunk size of %ld x %ld
invalid chunk increment of %lu x %lu
width
height
fileURL
T@"NSURL",R
CVML_status Geometry2D_buildCalibrationMatrix(Geometry2D_size2D *, float, float *)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/Geometry2D/Geometry2D_Calibration.c
CVML_status Geometry2D_pixelToMetricHomo2D(const Geometry2D_homo2D *, const float *, Geometry2D_homo2D *)
CVML_status Geometry2D_metricToPixelHomo2D(const Geometry2D_homo2D *, const float *, Geometry2D_homo2D *)
faceboxAligner
void vision::mod::FaceboxAligner::init(const vision::mod::ModelValues &)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/LandmarkDetector/FaceboxAligner.cpp
std::pair<Geometry2D_rect2D, float> vision::mod::FaceboxAligner::makeFaceBox(std::vector<Geometry2D_point2D> &, Geometry2D_point2D, FaceBoxAligner_boxMode)
Geometry2D_rect2D vision::mod::FaceboxAligner::enforceBoxBoundaries(const Geometry2D_rect2D, float, float)
void vision::mod::FaceboxAligner::preProcessImage(const vImage_Buffer &, const Geometry2D_rect2D &)
meanShape
meanShapeLandmarksInBox
com.apple.espresso.mainqueue
vision::mod::ObjectDetector_DCNFaceDetector::ObjectDetector_DCNFaceDetector(const Options &)_block_invoke
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/ObjectDetector/DCNFaceDetector/ObjectDetector_DCNFaceDetector.mm
virtual std::vector<std::vector<DetectedObject> > vision::mod::ObjectDetector_DCNFaceDetector::detectObjectsInImages_Planar8(const std::vector<vImage_Buffer> &)
virtual std::vector<DetectedObject> vision::mod::ObjectDetector_DCNFaceDetector::detectObjectsInImage_Planar8(const vImage_Buffer &)
Unspecified error
face
model8c_.espresso.net
CVMLRequestDetectFaceRectangles
CVMLRequestDetectFaceLandmarks
CVMLRequestDetectFaceExpressions
CVMLRequestDetectFace3DLandmarks
CVMLRequestDetectFacePose
CVMLRequestDetectFaceAttributes
CVMLRequestDetectHumanRectangles
CVMLRequestImageBlurriness
CVMLRequestImageBrightness
CVMLRequestImageRegistration
CVMLRequestSceneClassification
CVMLRequestKnownSceneClassifications
CVMLRequestIdentifyJunk
CVMLRequestCreateFaceModels
CVMLRequestAddFaceToFaceModels
CVMLRequestRemoveFaceFromFaceModels
CVMLRequestRemoveIdentityFromFaceModels
CVMLRequestUpdateFaceModels
CVMLRequestIdentifyFace
CVMLRequestCreateFaceprint
CVMLRequestCreateFaceRegionMap
CVMLRequestDetectRectangles
CVMLRequestDetectHorizon
CVMLRequestClusterObservations
CVMLRequestAlignFaceBBox
CVMLRequestCreateImageprint
CVMLRequestGroupImagesByTimeAndContent
CVMLRequestSuggestionsForClusters
CVMLRequestRefinedSuggestionsForClusters
CVMLRequestRepresentativeForCluster
CVMLRequestGetClusters
CVMLRequestOption_RepresentativeSample
CVMLRequestGetDistances
CVMLRequestOption_InputImage
CVMLRequestOption_InputFaces
CVMLRequestOption_AddObjectsToClustering
CVMLRequestOption_RemoveObjectsFromClustering
CVMLRequestOption_InputClusterIds
CVMLRequestOption_InputClusterFlags
CVMLRequestOption_ForceFaceprintCreation
CVMLRequestOption_InputClusters
CVMLRequestOption_InputFaceModels
CVMLRequestOption_InputIdentities
CVMLRequestOption_CacheFolderPath
CVMLRequestOption_GetClusteredFaceIds
CVMLRequestOption_GetClusteredFaceIdsForFaceId
CVMLRequestOption_GetDistanceBetweenClustersWithFaceIds
CVMLRequestOption_GetDistanceBetweenClusters
CVMLRequestOption_DumpIntermediateImages
CVMLRequestOption_CameraPixelFocalLength
CVMLRequestOption_CameraOpticalCenter
CVMLRequestOption_RectangleMinimumAspectRatio
CVMLRequestOption_RectangleMaximumAspectRatio
CVMLRequestOption_RectangleQuadratureTolerance
CVMLRequestOption_RectangleMinimumSize
CVMLRequestOption_RectangleMinimumConfidence
CVMLRequestOption_RectangleMaximumNumber
CVMLRequestOption_RectangleAspectRatio
CVMLRequestOption_InputObservations
CVMLRequestOption_InputThreshold
CVMLRequestOption_InputTimestamp
CVMLRequestOption_InputImageprints
CVMLRequestOption_InputRegionOfInterest
CVMLRequestOption_PreferBackgroundProcessing
CVMLRequestOption_PreferredMetalContext
CVMLRequestOption_MetalContextPriority
CVMLRequestOption_MaximumIntermediateSideLength
CVMLRequestOption_ClusteringAlgorithm
CVMLClusteringAlgorithm_Greedy
CVMLClusteringAlgorithm_Agglomerative
CVMLClusteringAlgorithm_Hierarchical
CVMLRequestOption_SaveClusteringState
CVMLRequestOption_RestoreClusteringState
CVMLRequestOption_DetectionLevel
CVMLRequestOptionDetectionLevel_Accurate
CVMLRequestOptionDetectionLevel_Balanced
CVMLRequestOptionDetectionLevel_Fast
CVMLRequestOption_FaceRectangleDetectorEnableLowMemoryMode
CVMLRequestOption_RectangleDetectorRequiredVersion
CVMLRequestOption_BlurMethod
CVMLRequestWarning_ImageTooSmall
CVMLRequestWarning_ImageMinimumLongDimension
CVMLRequestWarning_ImageMinimumShortDimension
v32@?0@"NSString"8#16^B24
com.apple.CVMLRequestQueue
Encountered error cancelling request(%d): %s
the %@ handler has not been implemented
the %@ cancellation handler has not been implemented
Attempt to process a %@ request with a non-CVMLImageRequestHandler
All elements in the %@ array must be of class %@ (%@)
cancellationSemaphore
T@"NSObject<OS_dispatch_semaphore>",&,V_cancellationSemaphore
cancellable
TB,V_cancellable
T{CGRect={CGPoint=dd}{CGSize=dd}},V_roi
requestName
T@"NSString",R,V_requestName
options
T@"NSDictionary",R,V_options
results
T@"NSArray",R,V_results
completionHandler
T@?,C,N,V_completionHandler
The %@ required option was not found
The %@ option was expected to be a %@, but was instead a %@ (%@)
apple_scenes
virtual CVML_status vision::mod::ImageDescriptorProcessorAbstract::computeDescriptorForImage(const vImage_Buffer &, ImageProcessing_ImageType, vision::mod::ImageDescriptorBufferAbstract &)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/ImageDescriptor/ImageDescriptor_ProcessorAbstract.h
virtual CVML_status vision::mod::ImageDescriptorProcessorAbstract::computeDescriptorsForImages(const std::vector<vImage_Buffer> &, ImageProcessing_ImageType, vision::mod::ImageDescriptorBufferAbstract &)
virtual CVML_status vision::mod::ImageDescriptorProcessorAbstract::computeDescriptorsForAugmentedImages(const std::vector<vImage_Buffer> &, ImageProcessing_ImageType, vision::mod::ImageDescriptorAugmenterAbstract &, vision::mod::ImageDescriptorBufferAbstract &)
CVML_status vision::mod::ImageDescriptorAugmenterAbstract::augment(const std::vector<vImage_Buffer> &, ImageProcessing_ImageType)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/ImageDescriptor/ImageDescriptor_AugmenterAbstract.h
std::vector<vImage_Buffer *> vision::mod::ImageDescriptorAugmenterAbstract::getAugmentedBatch(int)
std::vector<vImage_Buffer> vision::mod::ImageDescriptorAugmenterAbstract::getAugmentedImages() const
ConnectedComponents
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/RectangleDetector/QuadDetect/ConnectedComponents.c
pneighbor(*(Pcoord *)dequeFirst(dbLookup[mnid]), pix)
pneighbor(*(Pcoord *)dequeFirst(dbLookup[nid]), pix)
pneighbor(*(Pcoord *)dequeFirst(dbLookup[mid]), pix)
pneighbor(*(Pcoord *)dequeFirst(dbLookup[pid]), pix)
loc != -1
cidcnt < MAX_CONTOURS
eraseContourPixels
deque != NULL
Processing DetectHumans request
Error initializing human detection module.
CVML_status Geometry2D_cartToBari2D(const Geometry2D_cart2D *, const Geometry2D_cart2D *, Geometry2D_bari2D *)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/Geometry2D/Geometry2D_Baricentric.c
CVML_status Geometry2D_bariToCart2D(const Geometry2D_bari2D *, const Geometry2D_cart2D *, Geometry2D_cart2D *)
-[MomentProcessor initWithOptions:error:]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/MomentProcessor/Moments/MomentProcessor.mm
error != nil
-[MomentProcessor processImagesFromDataProvider:error:]
-[MomentProcessor computeClusteringOfImageDescriptors:intoKGroups:error:]
-[MomentProcessor computeNaturalClusteringOfImageDescriptors:error:]
-[MomentProcessor computeClusteringTreeForImageDescriptors:assumeDescriptorsAreSorted:error:]
q24@?0@"MPImageDescriptor"8@"MPImageDescriptor"16
context
T@"CVMLMPContext",&,N,V_context
node
T^v,V_node
freeNodeOnDealloc
TB,V_freeNodeOnDealloc
cvallocator
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/VisionKitFramework/CVML/algorithm_util/memory_pools.h
pool_.current_min_size( ) >= MinAllocSize && pool_.current_max_size( ) <= MaxAllocSize && "Request size out of pool bounds"
unique_lock::unlock: not locked
operator[]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/VisionKitFramework/CVML/algorithm_util/paged_allocator.h
index < size_
~paged_allocator: unclean shutdown, there are still %zu memory blocks allocated
linear_range_storage_profile
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/VisionKitFramework/CVML/algorithm_util/pool_storage_profile.h
2 == std::distance(begin, end)
start_size > 0 && "Linear range storage policy seg size must be positive"
prepare_sb
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/VisionKitFramework/CVML/algorithm_util/memory_pool_storage.h
qh && block_pool.qh_
hzone
alloc_block
bl->ptr_ && "Block with invalid zone"
block_for_size
blocks_.end() != found && "requested block size out of range"
can_adopt_block
blocks_.size() && blocks_.begin() != found && "freed block too small"
adopt_block
bl && bl->ptr_ && bl->size_ && qh
toWrite: short write
***%s: unaligned file size
%s: short read
writeFloatsFd: short write
write
readFloatsFd: short read
read
  CI:follow_edges - stack increase failed
follow_edges
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/HorizonDetector/CannyEdge.c
facerec
kCVMLFaceModelObservation_CodingVersionCodingKey
kCVMLFaceModelObservation_FaceModelVersionCodingKey
kCVMLFaceModelObservation_FaceModelMinorVersionCodingKey
kCVMLFaceModelObservation_FaceprintTypeCodingKey
kCVMLFaceModelObservation_UUIDToInternalIdMapCodingKey
kCVMLFaceModelObservation_InternalIdToUUIDMapCodingKey
kCVMLFaceModelObservation_FaceprintCacheCodingKey
kCVMLFaceModelObservation_InternalIdCacheCodingKey
kCVMLFaceModelObservation_FaceCountPerIdCodingKey
kCVMLFaceModelObservation_IsModelBuiltCodingKey
kCVMLFaceModelObservation_ModelValuesCodingKey
kCVMLFaceModelObservation_ModelLabelsCodingKey
kByte
kFloat32
kInt32
kUInt32
Attempt to add faceprint that is associated with another face!
We can only enroll 20 unique identities.
We can only enroll up to 300 faces per identity.
modelLabels
T@"NSArray",&,V_modelLabels
std::shared_ptr<ImageDescriptorProcessorAbstract> vision::mod::ImageDescriptor_EspressoJunk_CurrentModel(const char *, int, vision::mod::ImageDescriptorProcessorEspresso::PLATFORM, vision::mod::ImageDescriptorProcessorEspresso::COMPUTE_PATH, vision::mod::ImageDescriptorProcessorEspresso::Options)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/ImageDescriptor/ImageDescriptorEspresso/Models/Junk/ImageDescriptor_EspressoJunk.mm
model_junk_12_espresso
Processing add faces to face model  request
CVMLFaceExpressionDetectorProcessOption_InputFaceObservations
com.apple.CVML
landmarkRefinerAndPupil
Invalid expression model resource path
Invalid landmark refiner model resource path
Could not read expressions model data
Could not create face expression module
CVMLFaceExpressionDetector face does not have landmark points
Corrupt face mark data
unexpected exception
model file is corrupt
void cvml::util::binserialized_table_of_contents::init(const void *const, size_t)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/VisionKitFramework/CVML/algorithm_util/binserialized_mapped_file_contents.h
Error %s when executing %s in file %s:%d
syslog_assert_failed
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/VisionKitFramework/CVML/algorithm_util/common_defines.h
Model file info populated incorrectly
void cvml::util::binserialized_contents::init_model_values(const cvml::util::binserialized_table_of_contents &, const char *, const vision::mod::BinSerializedModelFileInfo &)
CVMLDetectorProcessingQueueOption
com.apple.CVML.Espresso
invalid status code %lld
failure with status %lld
 (%s)
encountered unknown exception
encountered an unexpected condition: %s
encountered an unexpected condition: %@
NSException
Error in sgesv in parameter: %d
Diagonal element at %d is exactly zero
CVMLFaceLandmarkDetectorType
CVMLFaceDetectorType
CVMLFaceExpressionDetectorType
CVMLFaceprintGeneratorDetectorType
CVMLHumanDetectorType
CVMLJunkIdentifierType
CVMLSceneClassifierType
CVMLImageprintGeneratorType
com.apple.CVML.faceDetectorAccurate
com.apple.CVML.faceDetectorBalanced
com.apple.CVML.faceDetectorFast
com.apple.CVML.faceLandmarks
com.apple.CVML.faceExpressions
com.apple.CVML.facePrinter
com.apple.CVML.humanDetector
com.apple.CVML.junkDetector
com.apple.CVML.sceneDetector
com.apple.CVML.imageprintGenerator
A %@ detector cannot be created
Error opening 
sumSpatialPooling
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/HumanDetector/cv/CVCommon.cpp
pooledW = sumSpatialPoolingX(pooledRespY, Ncol, ptrPooledX, r)
convTriX
w0<=w1
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/Clustering/Clustering/NNHierarchical/NNHierarchicalClustering.cpp
the size of the distance array is not correct
addDistances
nodes.size() % 2 == 1
runningIndexCurrent[0] != -1
movingRunningIndex[0] != stayingRunningIndex[0]
movingRunningIndex[1] != stayingRunningIndex[1]
human_3_model
could not operate on buffer
loadModel
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/HumanDetector/humandetector/TemplateObjectDetectorApply.h
readFastDTreeDict
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/HumanDetector/ml/DecisionTreeApply.h
idx>=0 && idx<fastDTreeDict.size()
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/ImageDescriptor/ImageDescriptor_BufferFloat32.cpp
virtual std::vector<float> vision::mod::ImageDescriptorBufferFloat32::computeDistancesFrom(const vision::mod::ImageDescriptorBufferAbstract &) const
float vision::mod::ImageDescriptorBufferFloat32::computeDistanceFrom(const vision::mod::ImageDescriptorBufferAbstract &) const
virtual std::vector<float> vision::mod::ImageDescriptorBufferFloat32::computeSelfDistances()
CVML_status vision::mod::ImageDescriptorBufferFloat32::computeDistanceBetweenDescriptorAndDescriptors(const float *, const float *, size_t, float *) const
CVML_status vision::mod::ImageDescriptorBufferFloat32::computeDistanceBetweenDescriptors(const float *, const float *, float &) const
virtual vision::mod::ImageDescriptorBufferFloat32 *vision::mod::ImageDescriptorBufferFloat32::getRepresentative(vision::mod::ImageDescriptorBufferAbstractRepresentativeMode, ImageDescriptorId) const
void vision::mod::descriptorBufferPackScores(vision::mod::ImageDescriptorBufferFloat32 *, const std::vector<float> &)
std::shared_ptr<ImageDescriptorBufferFloat32> vision::mod::descriptorBufferUnpackedScores(const vision::mod::ImageDescriptorBufferFloat32 &, std::vector<float> &, int)
 = [
CVML_status Face3D_estimateCameraProjective(const Geometry2D_cart2D &, const Geometry3D_cart3D &, const float *, Geometry3D_pose &)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/Face3D/Face3D_Core.cpp
CVML_status Face3D_estimateShapeProjective(const Geometry2D_cart2D &, const float *, const float *, int, const float *, const Geometry3D_pose &, float *)
CVML_status Face3D_updateShape(const float *, const float *, const float *, int, Geometry3D_cart3D &)
CVML_status Face3D_computeReprojectionError(const Geometry2D_cart2D &, const Geometry3D_cart3D &, const float *, const Geometry3D_pose &, float &)
faceprintSimilarityThreshold
numAtomsPerID
tolerance
maxIterations
sqrtAlpha
sqrtBeta
scdType
kMinIDsToEnroll
kMaxIDsToEnroll
kMinFacesPerID
kMaxFacesPerId
kFacePrintDimensionalityParamName
At X0, %ld variables are exactly at the bounds
Cauchy X = 
%5.2e 
There are %ld breakpoints
Piece %ld --f1, f2 at start point %.2e %.2e
Distance to the next break point = %.2e
Distance to the stationary point = %.2e
Variable %ld is fixed
GCP found in this segment. Piece %ld --f1, f2 at start point %.2e %.2e
Variable %ld leaves the set of free variables
%ld variables leave; %ld variables enter
%ld variables are free at GCP iter %ld
This problem is unconstrained
The initial X is infeasible. Restart with its projection
-------------- exit CAUCHY -----------
CAUCHY entered
Subnorm = 0. GCP = X.
----------------- exit SUBSM --------------
Positive dir derivative in projection 
Using the backtracking step
---------------SUBSM entered---------
Processing ClusterObservations request
Trying to reuse cluster request handler with differing cluster method
RestoreState must have an NSData object
Existing clustering context is invalid
Couldn't get clusters from clustering engine.
Trying to cancel a clustering request with no context
CVML_status ImageProcessing_getBytesPerPixelFromImageType(ImageProcessing_ImageType, size_t *)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/ImageProcessing/ImageProcessing_Utils.c
CVML_status ImageProcessing_reallocVImageBuffer(vImage_Buffer *, vImagePixelCount, vImagePixelCount, size_t)
CVML_status ImageProcessing_copyVImageBufferData(const vImage_Buffer *, size_t, vImage_Buffer *)
CVML_status ImageProcessing_save(const char *, const vImage_Buffer *, ImageProcessing_ImageType)
yyyy:MM:dd HH:mm:ss
WARNING: failed to compute ranking %@
CVML_status ImageProcessing_computeTilingParametersSimple(const vImage_Buffer *, size_t, int, vImagePixelCount, vImage_Buffer *, vImagePixelCount *, vImagePixelCount *)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/ImageProcessing/ImageProcessing_Tiling.c
CVML_status ImageProcessing_computeTilingParameters(const vImage_Buffer *, size_t, int, int, vImagePixelCount, vImagePixelCount, vImage_Buffer *, vImagePixelCount *, vImagePixelCount *)
CVML_status ImageProcessing_tileImage(const vImage_Buffer *, size_t, vImagePixelCount, vImagePixelCount, vImagePixelCount, vImagePixelCount, vImage_Buffer ***, int *, int *)
CVML_status ImageProcessing_computeSegmentTiling(vImagePixelCount, vImagePixelCount, int, vImagePixelCount *, vImagePixelCount *)
CVML_status Geometry3D_POSIT(const Geometry2D_cart2D *, const Geometry3D_cart3D *, const float *, float *, float *)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/Geometry3D/Geometry3D_POSIT.c
CVML_status Geometry3D_POSIT_getR1AndR2(__CLPK_real *, __CLPK_real *, __CLPK_integer, float *, float *)
The %d argument had an illegal value.
The %d-th diagonal element of the triangular factor of A is zero, so that A does not have full rank; the least squares solution could not be computed.
CVML_status Geometry2D_computeMinimumAlignedBoundingBox(const Geometry2D_cart2D *, Geometry2D_rect2D *)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/Geometry2D/Geometry2D_Regions.c
unknown
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/ImageClassifier/ImageClassifier_HierarchicalModel.cpp
vision::mod::ImageClassifier_HierarchicalModel::ImageClassifier_HierarchicalModel(const char *, const char *, const std::vector<std::pair<std::string, bool> > &)
void vision::mod::ImageClassifier_HierarchicalModel::verifyClassificationMapCorrectness(const std::map<std::string, float> &)
void vision::mod::ImageClassfier_Graph::filterGraphForBasicNodes(const std::vector<std::pair<std::string, ImageClassfier_GraphNodeType> > &, bool)
std::vector<std::pair<std::string, std::vector<bool> > > ImageClassifier_loadLabelsAndBooleanFlags(const char *, const char *)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/ImageClassifier/ImageClassifier_IO.cpp
\s*([^\s]+)\s*->\s*([^\s]+)\s*
std::vector<std::pair<std::string, std::string> > ImageClassifier_loadRelations(const char *, const char *)
std::vector<std::string> ImageClassifier_readLinesFromFile(const char *, const char *)
true
bool ImageClassifier_stringToBool(const std::string &)
***SCDict::initLearn: error in updateDictionary
***SCDict::initFromFile: file not blockSize-aligned
***SCDict::initFromFile: unexpected file size
   expected %llu floats; read %llu floats
***SCDict::writeToFile: no dictionary to write
***SCDict::writeToDictWriter: no dictionary to write
***SCDict::allocDict: no dictionary size specified
***SCDict: malloc failure; dictionary size %llu bytes
***SCDict: Internal error in allocScratch
***SCDict::allocScratch: malloc failure; bufsize %llu bytes
***SCDict::encodeBlock: error in getCoeffs
Not enough features to build dictionary. Required >= %d, got only %d
all zero sparse code 
Fatal error: memory allocation failure for scratch buffer
CVML_status Geometry2D_normalizePoints(const Geometry2D_cart2D *, float *, Geometry2D_cart2D *, float *, float *, float *)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/Geometry2D/Geometry2D_Normalization.c
Geometry2D_makeCart2DFromPoint2D
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/Geometry2D/Geometry2D_Cartesian.c
q.x != NULL
q.y != NULL
q.n > 0
Geometry2D_cloneUsingIndicesCart2D
CVMLFaceIdProcessOption_QueryThreshold
Attempt to enroll non face data
Attempt to add face with no faceprint
Attempt to remove face with no faceprint
Attempt to remove face that is not in the face model
Attempt to remove an identity that is not in the face model
CVMLFaceId expecting a CVMLFaceObservation as input
modelData
T@"CVMLFaceModelObservation",&,V_modelData
buildModels
TB,R,N
-[MPImageData initWithVImage:externalImageId:andExifTimestampValue:error:]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/MomentProcessor/Moments/MPImageData.m
ERROR: The input image does not seem to be 8888
-[MPImageData initWithCVPixelBufferImage:externalImageId:andExifTimestampValue:error:]
image
T^{vImage_Buffer=^vQQQ},R,V_image
imageCVPixelBuffer
T^{__CVBuffer=},R,V_imageCVPixelBuffer
imageFilePath
T@"NSString",&,V_imageFilePath
freeImageInDealloc
TB,V_freeImageInDealloc
externalImageId
T@"NSString",R,V_externalImageId
exifTimestamp
Tq,R,V_exifTimestamp
void vision::mod::LandmarkDetector::init(const vision::mod::ModelValues &, const char *)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/LandmarkDetector/LandmarkDetector.cpp
void vision::mod::LandmarkDetector::preProcessImage(const vImage_Buffer &, const Geometry2D_rect2D &)
CVML_status vision::mod::LandmarkDetector::initMeanShapeWithLandmarks(const std::vector<Geometry2D_point2D> &, const LandmarkDetector_initializationMode)
CVML_status vision::mod::LandmarkDetector::initMeanShapeWithEyeTiltAngle(float)
std::vector<Geometry2D_point2D> vision::mod::LandmarkDetector::detectLandmarksCore(int)
Processing DetectFaceLandmarks request
Could not initialize face landmarks module
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/ImageDescriptor/ImageDescriptorEspresso/ImageDescriptor_Espresso.mm
vision::mod::ImageDescriptorProcessorEspresso::ImageDescriptorProcessorEspresso(vision::mod::ImageDescriptorProcessorEspresso::Options, const char *, const char *, vision::mod::ImageDescriptorProcessorEspresso::PLATFORM, vision::mod::ImageDescriptorProcessorEspresso::COMPUTE_PATH)
void vision::mod::ImageDescriptorProcessorEspresso::setNetworkBatchNumber(int)
CVML_status vision::mod::ImageDescriptorProcessorEspresso::private_t::compute_batch(const std::vector<vImage_Buffer> &, const int, float *, const Espresso::vimage2espresso_param &)
virtual CVML_status vision::mod::ImageDescriptorProcessorEspresso::computeDescriptorForImage_RGBA8888(const vImage_Buffer &, vision::mod::ImageDescriptorBufferAbstract &)
virtual CVML_status vision::mod::ImageDescriptorProcessorEspresso::computeDescriptorForImage_BGRA8888(const vImage_Buffer &, vision::mod::ImageDescriptorBufferAbstract &)
CVML_status vision::mod::ImageDescriptorProcessorEspresso::computeDescriptorForImage_XYZA8888(const vImage_Buffer &, vision::mod::ImageDescriptorBufferAbstract &, bool)
virtual CVML_status vision::mod::ImageDescriptorProcessorEspresso::computeDescriptorForImage_Planar8(const vImage_Buffer &, vision::mod::ImageDescriptorBufferAbstract &)
virtual CVML_status vision::mod::ImageDescriptorProcessorEspresso::computeDescriptorForAugmentedImage(const vImage_Buffer &, ImageProcessing_ImageType, vision::mod::ImageDescriptorAugmenterAbstract &, vision::mod::ImageDescriptorBufferAbstract &)
virtual CVML_status vision::mod::ImageDescriptorProcessorEspresso::computeDescriptorsForImages_RGBA8888(const std::vector<vImage_Buffer> &, vision::mod::ImageDescriptorBufferAbstract &)
virtual CVML_status vision::mod::ImageDescriptorProcessorEspresso::computeDescriptorsForImages_BGRA8888(const std::vector<vImage_Buffer> &, vision::mod::ImageDescriptorBufferAbstract &)
CVML_status vision::mod::ImageDescriptorProcessorEspresso::computeDescriptorsForImages_XYZA8888(const std::vector<vImage_Buffer> &, vision::mod::ImageDescriptorBufferAbstract &, bool)
virtual CVML_status vision::mod::ImageDescriptorProcessorEspresso::computeDescriptorsForImages_Planar8(const std::vector<vImage_Buffer> &, vision::mod::ImageDescriptorBufferAbstract &)
Inconsistent state
virtual CVML_status vision::mod::ImageDescriptorProcessorAbstract::computeDescriptorForAugmentedImage(const vImage_Buffer &, ImageProcessing_ImageType, vision::mod::ImageDescriptorAugmenterAbstract &, vision::mod::ImageDescriptorBufferAbstract &)
CVML_status vision::mod::ImageDescriptorAugmenterAbstract::augment(const vImage_Buffer &, ImageProcessing_ImageType)
CVML_status Geometry2D_estimateAffine(const Geometry2D_cart2D *, const Geometry2D_cart2D *, Geometry2D_Affine *)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/Geometry2D/Geometry2D_Affine.c
CVML_status Geometry2D_mapAffine(const Geometry2D_cart2D *, const Geometry2D_Affine *, Geometry2D_cart2D *)
CVMLFaceGeometryEstimatorInitOption_ImageSize
CVMLFaceGeometryEstimatorInitOption_CameraFocalLength
CVMLFaceGeometryEstimatorProcessOption_EstimatePoseOnly
CVMLFaceGeometryEstimatorProcessOption_InputFaceObservation
eigenshape-current
CVMLFaceRegionMapGeneratorProcessOption_InputFaceObservations
faceRegionMap-current
CVMLRequestResultFaces
CVMLRequestResultHumans
CVMLRequestResultBlur
CVMLRequestResultRegistration
CVMLRequestResultRegistrationSignature
CVMLRequestResultClustering
CVMLRequestResultSceneClassification
CVMLRequestResultFace_Rectangle
CVMLRequestResultFace_Landmarks
CVMLRequestResultFace_Expression
CVMLRequestResultFace_3DLandmarks
CVMLRequestResultRectangles
CVMLRequestResultHorizon
CVMLObservation_CodingVersionCodingKey
CVMLObservation_ConfidenceCodingKey
CVMLDetectedObject_CodingVersionCodingKey
CVMLDetectedObject_BoundingBoxOriginXCodingKey
CVMLDetectedObject_BoundingBoxOriginYCodingKey
CVMLDetectedObject_BoundingBoxSizeWidthCodingKey
CVMLDetectedObject_BoundingBoxSizeHeightCodingKey
CVMLDetectedObject_IdentifierCodingKey
CVMLFaceprint_CodingVersionCodingKey
CVMLFaceprint_FaceprintTypeCodingKey
CVMLFaceprint_FaceprintCodingKey
CVMLFaceprint_KeyCodingKey
CVMLFaceprint_ProfileCodingKey
CVMLFaceprint_PlatformCodingKey
CVMLFaceObservation_CodingVersionCodingKey
CVMLFaceObservation_BoundsOriginXCodingKey
CVMLFaceObservation_BoundsOriginYCodingKey
CVMLFaceObservation_BoundsSizeWidthCodingKey
CVMLFaceObservation_BoundsSizeHeightCodingKey
CVMLFaceObservation_LandmarkPointsCodingKey
CVMLFaceObservation_LandmarkPoints3dCodingKey
CVMLFaceObservation_PoseCodingKey
CVMLFaceObservation_ExpressionsCodingKey
CVMLFaceObservation_FaceIdCodingKey
CVMLFaceObservation_FaceIdConfidenceCodingKey
CVMLFaceObservation_FaceprintCodingKey
CVMLFaceObservation_hasBBoxBeenAlignedCodingKey
CVMLFaceObservation_FaceRegionMapCodingKey
CVMLFaceObservation_FaceIsBlinkingCodingKey
CVMLFaceObservation_AlignedMeanShapeCodingKey
CVMLFaceObservation_LandmarksScoreCodingKey
CVMLImageprintObservation_ObjectCodingKey
CVMLImageprintObservation_VersionCodingKey
CVMLImageprintObservation_ImageprintTypeCodingKey
CVMLImageprintObservation_ImageprintDescriptorCodingKey
CVMLImageprintObservation_UUIDCodingKey
CVMLImageprintObservation_ImageprintTypeColorGabor
CVMLImageprintObservation_ImageprintDescriptorColorGaborVersion
[CVMLObservation initWithData:forKey:] failed with error: %@
confidence
Tf,V_confidence
boundingBox
T{CGRect={CGPoint=dd}{CGSize=dd}},V_boundingBox
identifier
T@"NSUUID",&,V_identifier
nil faceprint supplied
could not compute faceprint distance
faceprint
T@"NSData",&
T@"NSData",&,V_faceprint
T@"NSString",C,V_key
platform
TI,V_platform
profile
TI,V_profile
faceprintInputPath
T@"NSString",C,V_faceprintInputPath
id=%lu
landmarks
T@"CVMLFaceLandmarks",&,N,V_landmarks
landmarks3d
T@"CVMLFaceLandmarks",&,N,V_landmarks3d
hasBBoxBeenAligned
TB,V_hasBBoxBeenAligned
alignedBoundingBox
T{_Geometry2D_rect2D_={_Geometry2D_point2D_=ff}{_Geometry2D_size2D_=ff}},V_alignedBoundingBox
landmarkPointsScore
Tf,V_landmarkPointsScore
landmarkPoints
T@"NSData",&,V_landmarkPoints
landmarkPoints3d
T@"NSData",&,V_landmarkPoints3d
poseData
T@"NSData",&,V_poseData
faceRegionMap
T@"CVMLFaceRegionMap",&,N,V_faceRegionMap
faceIdConfidence
Tf,V_faceIdConfidence
alignedMeanShape
T@"NSData",&,V_alignedMeanShape
nameConfidence
Tf,R
faceId
TQ,V_faceId
T@"CVMLFaceprint",&,V_faceprint
expressionsAndConfidence
T@"NSDictionary",R
pose
T{?=[4]},R
alignmentTransform
T{CGAffineTransform=dddddd},V_alignmentTransform
baseImageSignature
T@"CVMLImageRegistrationSignature",&,V_baseImageSignature
currentImageSignature
T@"CVMLImageRegistrationSignature",&,V_currentImageSignature
blurMeasure
Tf,V_blurMeasure
brightness
Tf,V_brightness
state cannot be nil
Unexpected size of serialized state of the object of type %@
Failed to calculate MD5
imageprintDescriptor
T@"MPImageDescriptor",&,V_imageprintDescriptor
imageprintType
T@"NSString",&,V_imageprintType
imageprintVersion
T@"NSString",&,V_imageprintVersion
rawImageprintDescriptor
T@"NSData",R
 "%@" (%f)
classification
T@"NSString",R,V_classification
topLeft
T{CGPoint=dd},V_topLeft
topRight
T{CGPoint=dd},V_topRight
bottomLeft
T{CGPoint=dd},V_bottomLeft
bottomRight
T{CGPoint=dd},V_bottomRight
transform
T{CGAffineTransform=dddddd},V_transform
angle
Tf,V_angle
  clusterId = %lu;
  totalObjCount = %lu;
  objects = %s;
  shouldUpdateRep = %d;
  suggestedIdsForRep = %s;
  representativenessById = %s;
objects
T@"NSArray",&,V_objects
clusterId
TQ,V_clusterId
totalObjectCount
TQ,V_totalObjectCount
shouldUpdateRepresentative
TB,V_shouldUpdateRepresentative
suggestedIdsForRepresentative
T@"NSArray",&,V_suggestedIdsForRepresentative
representativenessById
T@"NSDictionary",&,V_representativenessById
clusters
T@"NSArray",&,V_clusters
suggestionsForCluster
T@"NSArray",&,V_suggestionsForCluster
clusterState
T@"NSData",&,V_clusterState
T@"NSSet",&,V_clusteredFaceIds
groupedClusteredFaceIdsForCluster
T@"NSArray",&,V_groupedClusteredFaceIdsForCluster
distance
T@"NSNumber",&,V_distance
distances
T@"NSDictionary",&,V_distances
distancesById
T@"NSDictionary",&,V_distancesById
horizonDetector: props exist
horizonDetector: Orientation = %d
  Found makerNotes
    Found vector: %.3f,%.3f,%.3f
acc = (%.5f, %.5f, %.5f)
accelTilt = %.3f deg, accelPitch = %.3f deg, accMagnitudeDev %.3f
accelPitch = %.3f deg, accelMagnitudeDev = %.3f
MaxPitch = %.3f, MaxPixelTilt = %.3f, MinPixelTilt = %.3f, MaxAccelMagDev = %.3f, MaxAccelFFTDifff = %.3f
FFT detected angle = %.3f deg
***SCDictKSVD::updateAtom: gesdd() error
KSVD
Processing DetectFacePose request
Unable to create request to compute landmarks
Processing getDistances request
Trying to call getDistances request with no prior clustering context loaded (need to have a CVMLClusterObservationsRequest first)
The getDistances request requires the CVMLRequestOption_InputFaces entry to be set in the options dictionary
virtual CVML_status vision::mod::SimilarityMatrixFull::deleteDescriptorsWithIds(const std::vector<ImageDescriptorId> &)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/SimilarityMatrix/SimilarityMatrix/SimilarityMatrix_Full.cpp
CVML_status Geometry2D_cartToHomo2D(const Geometry2D_cart2D *, Geometry2D_homo2D *)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/Geometry2D/Geometry2D_Homogeneous.c
CVML_status Geometry2D_estimateHomography(const Geometry2D_cart2D *, const Geometry2D_cart2D *, float *)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/Geometry2D/Geometry2D_Homography.c
CVML_status Geometry2D_mapHomography(const Geometry2D_cart2D *, const float *, Geometry2D_cart2D *)
CVML_status Geometry2D_estimateHomographyMSS(const Geometry2D_cart2D *, const Geometry2D_cart2D *, float *, __CLPK_integer, float *)
CVML_status Geometry2D_estimateHomographyOD(const Geometry2D_cart2D *, const Geometry2D_cart2D *, float *, __CLPK_integer, float *)
Geometry2D_denormalizeHomography
H != NULL
pred
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/HumanDetector/ml/AdaBoostApply.cpp
weakModels.size()
CVML_status Geometry2D_estimateRST(const Geometry2D_cart2D *, const Geometry2D_cart2D *, Geometry2D_RST *)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/Geometry2D/Geometry2D_RST.c
CVML_status Geometry2D_mapRST(const Geometry2D_cart2D *, const Geometry2D_RST *, Geometry2D_cart2D *)
CVMLImageGrouperProcessOption_Threshold
CVMLImageGrouperProcessOption_AdjustDistancesWithTimestamp
virtual CVML_status vision::mod::ClusteringAbstract::addDescriptor(ImageDescriptorId, vision::mod::SimilarityMatrixAbstract &)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/Clustering/Clustering/Clustering_Abstract.cpp
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/BinSerializer/BinSerializer_Core.c
CVML_status BinSerializer_fseek(FILE *, const char *)
CVML_status BinSerializer_freadInBytes(FILE *, const char *, _Bool, void **, size_t *)
CVML_status BinSerializer_freadInFloat(FILE *, const char *, _Bool, float **, size_t *)
_Bool LandmarkDetector_generateNormalizedFaceMesh63Landmarks(const Geometry2D_point2D *, const Geometry2D_size2D *, Geometry2D_cart2D *)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/LandmarkDetector/LandmarkDetector_Mesh.c
initializeSpanList
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/RectangleDetector/QuadDetect/Spans.c
spl != NULL
addSpan
virtual CVML_status vision::mod::ImageDescriptorProcessorAbstract::computeDescriptorsForImages_BGRA8888(const std::vector<vImage_Buffer> &, vision::mod::ImageDescriptorBufferAbstract &)
hw.logicalcpu
%d %d %a %d
%d %d %a
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/HumanDetector/ml/DecisionTreeApply.cpp
DTreeDict.size()
CVML_status Geometry2D_cumulativeEuclideanDistanceCart2D(const Geometry2D_cart2D *, const Geometry2D_cart2D *, float *)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/Geometry2D/Geometry2D_Distances.c
virtual CVML_status vision::mod::ImageDescriptorProcessorAbstract::computeDescriptorsForImages_RGBA8888(const std::vector<vImage_Buffer> &, vision::mod::ImageDescriptorBufferAbstract &)
virtual CVML_status vision::mod::ImageDescriptorProcessorAbstract::computeDescriptorsForImages_Planar8(const std::vector<vImage_Buffer> &, vision::mod::ImageDescriptorBufferAbstract &)
virtual std::vector<float> vision::mod::ColorGaborImageDescriptorBuffer::computeSelfDistances()
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/ImageDescriptor/ImageDescriptorColorGabor/ColorGaborImageDescriptor.h
cmap
Processing DetectFace3DLandmarks request
Error 1
Error 2
in acicDotProd: mOut not 128 byte aligned! Not optimal for cblas_sgemm
in acicDotProd: m2 not 128 byte aligned! Not optimal for cblas_sgemm
in acicDotProd: m1 not 128 byte aligned! Not optimal for cblas_sgemm
At iterate %5ld, f(x)= %5.2e, ||proj grad||_infty = %.2e
ITERATION %5ld
  ys=%10.3e  -gs=%10.3e BFGS update SKIPPED
 Bad direction in the line search;
 Singular triangular system detected;
 Nonpositive definiteness in Cholesky factorization in formk;
 Nonpositive definiteness in Cholesky factorization in formt;
   refresh the lbfgs memory and restart the iteration.
CVMLFaceLandmarkDetectorProcessOption_InputFaceObservations
CVMLFaceLandmarkDetectorProcessOption_RefineLeftEye
CVMLFaceLandmarkDetectorProcessOption_RefineRightEye
CVMLFaceLandmarkDetectorProcessOption_RefineMouth
CVMLFaceLandmarkDetectorProcessOption_BlinkDetection
landmarks_v2
Invalid landmark model resource path
Could not read landmark model data
Could not read landmark refiner model data
mouth
righteye
lefteye
refinerLandmarksPath
Invalid face bounds supplied to face aligner
Could not create memory efficient crop for landmark detection
memory allocation failure
Landmark Detector did not provide any data
unexpected exception thrown
ascend direction in projection gd = %.2e
junk-descriptor-current
junk-classifier-current
junk-classifier-labels-current
junk
Trying to run junk classifier when the classifier failed to initialize
cvml_junk_classifier_debug_intermediates
CVML_DEBUG_DUMP_JUNK_INTERMEDIATES
Mapping beyond limit of 2
 CVMLRequestOption_RectangleDetectorRequiredVersion value is out of bounds: %d
 CVMLRequestOption_InputRegionOfInterest value malformed: %@
 CVMLRequestOption_CameraOpticalCenter value malformed: %@
 CVMLRequestOption_CameraPixelFocalLength value is out of bounds: %f
 CVMLRequestOption_RectangleMinimumAspectRatio value is out of bounds: %f
 CVMLRequestOption_RectangleMaximumAspectRatio value is out of bounds: %f
 CVMLRequestOption_RectangleMinimumAspectRatio value, %f is greater than CVMLRequestOption_RectangleMaximumAspectRatio value, %f
 CVMLRequestOption_RectangleQuadratureTolerance value is out of bounds: %f
 CVMLRequestOption_RectangleMinimumSize value is out of bounds: %f
 CVMLRequestOption_RectangleMinimumConfidence value is out of bounds: %f
 CVMLRequestOption_RectangleMaximumNumber value is out of bounds: %d
Processing CVMLImageBlurMetric request
Zero dimensioned image passed into blur detector.
Internal error processing image
%s.svm
CVMLFaceDetectorInitOption_MinFaceSize
CVMLFaceDetectorInitOption_EnableLowMemoryMode
faceDetector-current
cvml_facedetector_debug_intermediates/
_fd_image.vdump
_fd_image.png
_raw_bboxes.json
%@_face_%d
_raw_bbox_crop.png
imageURL
<binary-data>
rect
CVML Face detector debug intermediates written to: %@
Face detection module failed due to unexpected error
CVMLFaceDetector error aligning a detected bounding box
B56@?0@"CVMLImageBuffer"8{CGRect={CGPoint=dd}{CGSize=dd}}16^@48
Wiping layers for face detector unsuccessful.
Exception thrown while trying to purge face detector layers.
CVML_DEBUG_DUMP_FACE_DETECT_INTERMEDIATES
pointCount
TQ,V_pointCount
points
Tr^{CGPoint=dd},V_points
Tr^,V_points
CVMLFaceLandmarksRegion_AllPoints
CVMLFaceLandmarksRegion_FaceContour
CVMLFaceLandmarksRegion_LeftEye
CVMLFaceLandmarksRegion_RightEye
CVMLFaceLandmarksRegion_LeftEyebrow
CVMLFaceLandmarksRegion_RightEyebrow
CVMLFaceLandmarksRegion_Nose
CVMLFaceLandmarksRegion_NoseCrest
CVMLFaceLandmarksRegion_MedianLine
CVMLFaceLandmarksRegion_OuterLips
CVMLFaceLandmarksRegion_InnerLips
CVMLFaceLandmarksRegion_LeftPupil
CVMLFaceLandmarksRegion_RightPupil
is3DLandmarks
TB,V_is3DLandmarks
regions
T@"NSMutableDictionary",&,V_regions
pointsData
T@"NSData",&,V_pointsData
alignedBBox
T{_Geometry2D_rect2D_={_Geometry2D_point2D_=ff}{_Geometry2D_size2D_=ff}},V_alignedBBox
userFacingBBox
T{CGRect={CGPoint=dd}{CGSize=dd}},V_userFacingBBox
zero-dimensioned image (%ld x %ld)
No input option specified
Input is not provided in an NSArray
The number of %@ options (%lu) did not meet the minimum required (%lu)
The number of %@ options (%lu) exceeded the maximum allowed (%lu)
Input array contains an element that is not the correct type
%@ was given %@
Image registration can only be performed on CVMLImageRequestHandler and CVMLSequenceRequestHandler
InputImage missing in options
failed to create image buffer
Machine precision = %.2e
 N = %10ld
 M = %10ld
L  =
%.2e 
X0 =
U  =
LINE SEARCH %ld times; norm of step = %.2e
%5ld %5ld %5ld %5ld %5ld %5ld
%6.2e %9.5e
X = 
 %.2e
F(x) = %.9e
 Input nbd(%ld) is invalid
 l(%ld) > u(%ld). No feasible solution.
Cauchy                time %.3e seconds.
Subspace minimization time %.3e seconds.
Line search           time %.3e seconds.
 Total User time %.3e seconds.
        RUNNING THE L-BFGS-B CODE
           * * *
 Line search cannot locate an adequate point after 20 function
  and gradient evaluations.  Previous x, f and g restored.
                  2 rounding error dominate computation.
 The triangular system is singular.
 Warning:  more than 10 function and gradient
   evaluations in the last line search.  Termination
   may possibly be caused by a bad search direction.
 Derivative >= 0, backtracking line search impossible.
  Previous x, f and g restored.
 Possible causes: 1 error in function or gradient evaluation;
                  2 rounding errors dominate computation.
 Matrix in the Cholesky factorization in formt is not Pos. Def.
 Matrix in 2nd Cholesky factorization in formk is not Pos. Def.
 Matrix in 1st Cholesky factorization in formk is not Pos. Def.
Tit   = total number of iterations
Tnf   = total number of function evaluations
Tnint = total number of segments explored during Cauchy searches
Skip  = number of BFGS updates skipped
Nact  = number of active bounds at final generalized Cauchy point
Projg = norm of the final projected gradient
F     = final function value
           * * * 
   N    Tit   Tnf  Tnint  Skip  Nact      Projg        F
_source_scaled.png
_source_scaled.vdump
CVML Image Classifier debug intermediates written to: %@
scalingFactor
augmentationMode
numTiles
imageID
_tile_
.png
.vdump
debugID
labelsAndConfidence
MinConfidenceForClassificationRaw
hierarchicalLabelsAndConfidence
MinConfidenceForHierarchical
virtual vision::mod::ImageDescriptorAugmenterAbstract::~ImageDescriptorAugmenterAbstract()
CVML_status vision::mod::ImageDescriptorAugmenterAbstract::clearAugmentedImages()
virtual CVML_status vision::mod::ImageDescriptorAugmenterFlip::augmentImage(const vImage_Buffer &, ImageProcessing_ImageType, const std::vector<vImage_Buffer *> &)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/ImageDescriptor/ImageDescriptor_AugmenterFlip.h
CVML_status vision::mod::ImageDescriptorAugmenterFlip::flipLR(const vImage_Buffer *, ImageProcessing_ImageType, vImage_Buffer *)
CVML_status vision::mod::ImageDescriptorAugmenterFlip::flipUD(const vImage_Buffer *, ImageProcessing_ImageType, vImage_Buffer *)
virtual CVML_status vision::mod::ImageDescriptorAugmenterFlip::combine(const vision::mod::ImageDescriptorBufferAbstract &, vision::mod::ImageDescriptorBufferAbstract &)
std::map<std::string, float> vision::mod::ImageClassifierAbstract::classifyDescriptors(const vision::mod::ImageDescriptorBufferAbstract &, bool, bool)
vision::mod::ImageClassifierAbstract &vision::mod::ImageClassifierAbstract::setMinConfidence(float)
Processing Create imageprint request
Attempt to create an image print request without a timestamp
Attempt to create an imageprint failed
virtual vision::mod::ImageClassifierAbstract &vision::mod::ImageClassifierGlimmer::setDescriptorProcessor(const std::shared_ptr<ImageDescriptorProcessorAbstract> &)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/ImageClassifier/ImageClassifierGlimmer/ImageClassifier_Glimmer.mm
void vision::mod::ImageClassifierGlimmer::private_t::loadData(void *, size_t, int)
void vision::mod::ImageClassifierGlimmer::private_t::loadClassifier(vision::mod::ImageClassifierGlimmer *, const char *)
void vision::mod::ImageClassifierGlimmer::private_t::loadClassifierBinserializer(vision::mod::ImageClassifierGlimmer *, const char *, const char *)
virtual std::map<std::string, float> vision::mod::ImageClassifierGlimmer::classifyImage_RGBA8888(const vImage_Buffer &)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/ImageClassifier/ImageClassifierGlimmer/ImageClassifier_Glimmer.h
virtual std::map<std::string, float> vision::mod::ImageClassifierGlimmer::classifyImage_BGRA8888(const vImage_Buffer &)
virtual std::map<std::string, float> vision::mod::ImageClassifierGlimmer::classifyImage_Planar8(const vImage_Buffer &)
FaceRegionMap::Width
FaceRegionMap::Height
FaceRegionMap::Data
FaceRegionMap::Triangles
FaceRegionMap::NormalizedLandmarks
void vision::mod::FaceRegionMap::init(const vision::mod::ModelValues &)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/FaceRegionMap/FaceRegionMap.cpp
Background
Left eye
Right eye
Left eyebrow
Right eyebrow
Root of nose
Nose
Chin
Lower left cheek
Lower right cheek
Between mouth and nose
Left cheek
Right cheek
Left temple
Right temple
Between eyebrows
Above left eye
Above right eye
Upper lip
Lower lip
Between lips
Forehead
Tip of nose
CVML_status vision::mod::FaceRegionMap::computeFaceRegionMap(const Geometry2D_rect2D, const std::vector<Geometry2D_point2D> &, vImage_Buffer &)
AdjacentContourHeal
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/RectangleDetector/QuadDetect/Contours.c
PCOORD_EQUAL(joinPoint, LAST_PCOORD(cPtrN))
PCOORD_EQUAL(joinPoint, FIRST_PCOORD(cPtrN))
healCenters
ady == 2
heal
(endpoint2 == 4)|| (endpoint2 == 8)
(endpoint2 == 8)|| (endpoint2 == 6)
(endpoint2 == 6)|| (endpoint2 == 2)
(endpoint2 == 2)|| (endpoint2 == 4)
testJoin
(orn >= 0) && (orn <= 8)
orn != 4
straightLineLSQ
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/RectangleDetector/QuadDetect/Leq.c
maxDev != -1.f
straightLineWLSQ
CVML_status FaceWarper_estimateEyesRST(const Geometry2D_cart2D *, const Geometry2D_point2D *, const Geometry2D_size2D *, _Bool, Geometry2D_RST *)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/FaceWarper/FaceWarper_Mesh.c
CVML_status FaceWarper_estimateAnchorsRST(const Geometry2D_cart2D *, const int *, int, const Geometry2D_point2D *, const Geometry2D_size2D *, _Bool, Geometry2D_RST *)
chk_ptr
malloc_chk
malloc
allocSegments
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/RectangleDetector/QuadDetect/Segments.c
sdb->nSegments <= sdb->maxSegments
baseAddress
Tr^v,R,N
length
TQ,R,N
resourcePath
T@"NSString",&,N
void cvml::util::mapped_model_file::advise(int) const
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/VisionKitFramework/CVML/algorithm_util/mapped_model_file.h
mmap MAP_FAILED
cvml::util::mapped_model_file::mapped_model_file(const char *, bool)
void cvml::util::mapped_model_file::open_file(const char *)
Processing Remove identity from face model request
Required arguments, CVMLRequestOption_InputIdentities and CVMLRequestOption_InputFaceModels, were not specified
CVMLRequestOption_Identities option not supplied
CVMLRequestOption_Identities is not a NSArray of NSUUID
An element in CVMLRequestOption_InputIdentities is not a NSUUID
MPImageDescriptor_externalImageId
MPImageDescriptor_exifTimestamp
MPImageDescriptor_quality
MPImageDescriptor_ColorGaborImageDescriptorBuffer_type
MPImageDescriptor_ColorGaborImageDescriptorBuffer_lengthInBytes
MPImageDescriptor_ColorGaborImageDescriptorBuffer_data
MPImageDescriptor_ColorGaborImageDescriptorBuffer_count
MPImageDescriptor_ColorGaborImageDescriptorBuffer_stride
ERROR: Could not compute the image descriptor
ERROR: Could not compute the convnet-based image descriptor
ERROR: Could not compute image registration features
ERROR: Could not compute image quality
-[MPImageDescriptor computeDescriptorForImageData:context:error:]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/MomentProcessor/Moments/MPImageDescriptor.mm
-[MPImageDescriptor computeQualityForImageData:andQualityCriteria:context:error:]
ERROR: image data property is not initialized
ERROR: all ranking criteria failed
ERROR: state cannot be nil
ERROR: invalid image Id format
previousLeafId
Tq,V_previousLeafId
nextLeafId
Tq,V_nextLeafId
nextLeafDescriptorDistance
Tf,V_nextLeafDescriptorDistance
previousLeafDescriptorDistance
Tf,V_previousLeafDescriptorDistance
nextLeafTimestampDistance
Tq,V_nextLeafTimestampDistance
previousLeafTimestampDistance
Tq,V_previousLeafTimestampDistance
nextLeafTotalDistance
Tf,V_nextLeafTotalDistance
previousLeafTotalDistance
Tf,V_previousLeafTotalDistance
rawColorGaborDescriptor
T@"NSString",R,V_imageFilePath
descriptorId
Tq,R,V_descriptorId
quality
Tf,R,V_quality
colorGaborDescriptor
T^v,R,V_colorGaborDescriptor
sceneClassifierDescriptor
T^v,R,V_sceneClassifierDescriptor
imageRegistrationDescriptor
T^v,R,V_imageRegistrationDescriptor
Processing DetectFaceRectangles request
Unable to initialize face detection module
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/FaceFrontalizer/FaceFrontalizer.cpp
CVML_status vision::mod::FaceFrontalizer::frontalize_8(const vImage_Buffer &, const Geometry2D_rect2D &, vImage_Buffer &)
Processing getClusters request
RAMBackingStore::createFromContentsOfFile -- file does not exist '%s'
RAMBackingStore::createFromContentsOfFile -- Could not open file '%s'
RAMBackingStore::createFromContentsOfFile -- error seeking in provided file
RAMBackingStore::createFromContentsOfFile -- failed to allocate buffer
RAMBackingStore::createFromContentsOfFile -- failed to read contents of file '%s'
RAMBackingStore::createFromContentsOfFile -- failed to close file
RAMBackingStore::growStorage -- could not grow storage
%@/%s
writeBackingStoreToFile-- Could not create file: '%s'
writeBackingStoreToFile-- error writing out data
writeBackingStoreToFile-- error closing file, file could be corrupt
writeBackingStoreToFile -- File exists at output path '%s', and we cannot safely overwrite this file
writeBackingStoreToFile-- File exists at output path '%s', and could not copy file to temporary directory
writeBackingStoreToFile-- Could not move file from temporary directory
writeBackingStoreToFile -- Non critical error -- Could not remove original file after rename
writeBackingStoreToFile-- Error closing file
writeBackingStoreToFile -- could not remove temporary file.
writeBackingStoreToFile-- Catastrophic error.  Original file damaged during save.
CVMLFaceprintGeneratorType
CVMLFaceprintGeneratorTypeEspressoCPU
CVMLFaceprintGeneratorProcessOption_InputFaceObservations
CVMLFaceprintGeneratorProcessingOption_CheckForJunkFaces
Descriptor type not specified!
Unsupported descriptor type
faceDescriptor-current
Could not find face descriptor model resource!
Faceprint generator recieved a zero dimensioned image
Could not create memory efficient crop for face printing
cvml_faceprinter_debug_intermediates/
_pre_frontalized.vdump
_frontalized.vdump
_frontalized.png
_pre_frontalized.png
_bbox.json
_bbox_crop.png
CVML Faceprinter debug intermediate written to: %@
Poor quality face print candidate detected.  Not generating faceprint
Could not compute face descriptor due to internal error
CVML_DEBUG_DUMP_FACEPRINTER_INTERMEDIATES
Processing Create FaceRegionMap request
Error initializing face region map module
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/Clustering/Clustering/Agglomerative/cluster_descs.cc
s >= 0
heap_assert_cap
h.n + 1 <= h.a.size()
h.n + 1 <= h.a_rev.size()
heap_swap
i >= 1
i <= h.n
j >= 1
j <= h.n
i != j
heap_up
heap_down
heap_remove
heap_top
h.n >= 1
heap_update
candidate_heap %d
cluster_descs_mean_agg_cpp
h.n > 0
i_max < j_max
root_cc_i >= 0
root_cc_i < n_rem
orig_j == root_orig_i
BOOL faceWarperComputeAnchorTransform(NSData *__strong, CGAffineTransform *)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/VisionKitFramework/CVML/internal/CVMLFaceWarper.m
Processing CreateFaceModel request
Attempt to add a face observation that doesn't have a identifier.
Failed to initialize rectangle detector
The rectangle detector request failed
Processing Identify Face request
Required arguments, CVMLRequestOption_InputFaces was not specified
Required arguments, CVMLRequestOption_InputFaceModels was not specified
No face model observation specified in input options
A model specified in CVMLRequestOption_InputFaceModels is invalid!
Processing IdentifyJunk request
Error initializing junk detection module
std::shared_ptr<std::vector<size_t> > vision::mod::GreedyClusterer::addDescriptors(float *, int, int, size_t, const std::vector<float> &, const std::vector<int> &)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/Clustering/Clustering/Greedy/GreedyClustering.cpp
addDescriptors
elementSize == ELEMENT_SIZE
std::shared_ptr<std::vector<size_t> > vision::mod::GreedyClusterer::addDescriptors(const vision::mod::ImageDescriptorBufferAbstract &, const std::vector<float> &, const std::vector<int> &)
  GreedyClusterer::serializeStatus - enter
  GreedyClusterer: Failed to open file - skipping serialization
Error creating file name
  GreedyClusterer::serializeStatus - saving map file: %s
  GreedyClusterer: failed to save the file
virtual bool vision::mod::GreedyClusterer::serializeStatus(int)
  GreedyClusterer::serializeStatus - deleting previous cache
  GreedyClusterer::serializeStatus - done
  GreedyClusterer::deserializeStatus - failed to read clusterFileLength
  GreedyClusterer::deserializeStatus - failed to malloc file path
  GreedyClusterer::deserializeStatus - failed to read file name
  GreedyClusterer::deserializeStatus - failed to load memory map file
  GreedyClusterer::deserializeStatus - loaded a corrupt file as expected element size does not match
CVML_status vision::mod::GreedyClustererFacesAPI::update_private(const vision::mod::ImageDescriptorBufferAbstract &, const std::vector<float> &, const std::vector<int> &, std::vector<faceIdPair> &)
remove_private
void vision::mod::GreedyClustererFacesAPI::getAverageDescriptorOfClusterContainingFace(ImageDescriptorId, std::map<ImageDescriptorId, std::vector<ImageDescriptorId> > &, float *)
  GreedyClustererFacesAPI::serialize - enter
  GreedyClustererFacesAPI::serialize - deleting previous path: %s
  GreedyClustererFacesAPI::serialize - cachefile: %s
  GreedyClustererFacesAPI::serialize - error creating new map file for serialization
  GreedyClustererFacesAPI::serialize - error calculating checksum for cluster data file
  GreedyClustererFacesAPI::serialize - opening cluster cache file for reading
  GreedyClustererFacesAPI::serialize - error reading cluster file length
  GreedyClustererFacesAPI::serialize - error allocating space for file path
  GreedyClustererFacesAPI::serialize - error reading cluster file name
  GreedyClustererFacesAPI::serialize - done
  Clusterer - couldn't find sanity value
  Clusterer - versions mismatch (serialized: %d, current: %d
  Clusterer - data checksum mismatch
  GreedyClustererFacesAPI: Failed to open '%s': errno=%d
  GreedyClustererFacesAPI: Opening '%s'
  GreedyClustererFacesAPI: Failed to read '%s': errno=%d
  GreedyClustererFacesAPI: Failed to malloc cluster file name
%s%s.cmap
BackedBuffer<BackingStore>::allocateElement -- could not allocate new element because grow failed
BackedBuffer<BackingStore>::createByMappingDirectlyFromFile -- Invalid header detected for file '%s'
BackedBuffer<BackingStore>::createByMappingDirectlyFromFile -- The valid element list is corrupt
BackedBuffer<BackingStore>::isValidHeader -- cannot open source file '%s'
BackedBuffer<BackingStore>::isValidHeader -- corrupt header detected in file '%s'
BackedBuffer<BackingStore>::isValidHeader -- inconsistent header detected -- zero element size detected for file '%s'
BackedBuffer<BackingStore>::isValidHeader -- inconsistent header detected -- element count does not match max free element capacity for file '%s'
BackedBuffer<BackingStore>::isValidHeader -- inconsistent header detected -- free element count exceeds free element capacity for file '%s'
BackedBuffer<BackingStore>::isValidHeader -- inconsistent header detected -- could not validate file size for file '%s'
BackedBuffer<BackingStore>::isValidHeader -- inconsistent header detected -- expected file size does not match actual file size for file '%s'
Processing Group Images By Time and Content Request
Attempt to create an image print request an imageprint array
Input imageprint array contains an item that is not an imageprint
Image grouper failed
Processing Align Face BBox request
Could not initialize face bounds aligner module
Attempt to process align face bboxes when no faces were specified
debugMode
Ti,V_debugMode
timerMode
Ti,V_timerMode
clusterSplitDistanceType
Ti,V_clusterSplitDistanceType
qualityCriteriaList
T@"NSArray",&,V_qualityCriteriaList
useTimestampAdjustedDistances
TB,V_useTimestampAdjustedDistances
performClustersPostprocessing
TB,V_performClustersPostprocessing
performSceneClassification
TB,V_performSceneClassification
roiAreaThreshold
Tf,V_roiAreaThreshold
inliersRatioThreshold
Tf,V_inliersRatioThreshold
numberOfKeypointsToConsider
Ti,V_numberOfKeypointsToConsider
naturalClusteringDistanceThreshold
Tf,V_naturalClusteringDistanceThreshold
splitIntoMonotonicSpans
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/RectangleDetector/QuadDetect/SegmentUtilities.c
cPtr->nPnts > 1
!closedP
idx <= monoLength
mergeSegment
sPtr2 != NULL
bool vision::mod::faceIsJunk(vision::mod::ImageDescriptorBufferAbstract &)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/Clustering/Clustering/Greedy/GreedyClustering_hacks.cpp
/all_3lp_nodropout-symbol.espresso.bin
void vision::mod::readBinSerializedModelValues(const char *const, const char *, const vision::mod::BinSerializedModelFileInfo &, vision::mod::ModelValues &, bool)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/CVML/CVML_BinSerializedModelReader.cpp
void vision::mod::readBinSerializedModelValues(FILE *, const char *, const vision::mod::BinSerializedModelFileInfo &, bool, vision::mod::ModelValues &)
void vision::mod::Face3D::init(const vision::mod::ModelValues &, const float *)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/Face3D/Face3D.cpp
CVML_status vision::mod::Face3D::estimatePoseAndStructure(const std::vector<Geometry2D_point2D> &, Geometry3D_pose &, std::vector<Geometry3D_point3D> &, int)
CVML_status vision::mod::Face3D::estimatePose(const std::vector<Geometry2D_point2D> &, Geometry3D_pose &)
CVML_status Projections_computeShiftBruteForce(const float *, int, const Projections_meanStdTable *, const float *, int, const Projections_meanStdTable *, int, float, float *, float *, float *, float *)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/ImageRegistration/Projections/Projections_Optimizer.c
CVML_status Projections_computeCost(int, float, float, const float *, int, const Projections_meanStdTable *, const float *, int, const Projections_meanStdTable *, int, float *)
Unknown sparse coding dictionary type. Defaulting to KSVD
Not enough features to build dictionary for for class %d. Required >= %d, got only %d
Fata error: Problem in memory allocation for LCKSVD!
public.png
com.microsoft.bmp
public.jpeg
convertYUV420ToRGBA8888: src must be YUV420 format!
***malloc fialure
***malloc failure
Processing DetectFaceExpressions request
Could not initialize expression module.
scorPdiffParameters
void vision::mod::LandmarkAttributes::init(const vision::mod::ModelValues &, bool)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/LandmarkDetector/LandmarkDetector_Attributes.mm
exprParameters
blinkParametersApp
smileBlinkParametersGeo
lmarkQuality
exprParamsv1
pupilMeanStd
float vision::mod::LandmarkAttributes::computeFittingScoreIntensityDifference(const vImage_Buffer &, const Geometry2D_rect2D &, const std::vector<Geometry2D_point2D> &)
std::map<expressionAttributeType, float> vision::mod::LandmarkAttributes::computeExpressionAttributes(const Geometry2D_rect2D &, const std::vector<Geometry2D_point2D> &)
std::map<blinkType, float> vision::mod::LandmarkAttributes::computeBlinkAttributes(const Geometry2D_rect2D &, const std::vector<Geometry2D_point2D> &, std::vector<float> &)
clustering with agglomerative method
Missing grouping option
Clustering distance option must be specified
Matrix must be specified
-[CVMLAgglomerativeClustering getClustersWithOptions:error:]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/VisionKitFramework/CVML/internal/CVMLAgglomerativeClustering.mm
distWrap.count >= N && "simmatrix inconsistency"
CVML clustering: %zu clusters for distance: %@
faceIdsMapping
T@"NSMutableDictionary",&,V_faceIdsMapping
TB,V_debugMode
CVMLSimilarityMatrixType_Lazy
CVMLSimilarityMatrixType_Full
CVMLSimilarityMatrixInitOption_SimilarityMatrixType
-[CVMLSimilarityMatrix getDescriptorIdsForRange:]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/VisionKitFramework/CVML/internal/CVMLSimilarityMatrix.mm
start <= end && "getDescriptorIdsForRange invalid range"
Similarity matrix
matrixSize
TQ,R,N,GgetMatrixSize
maximumValidMatrixDistance
Tf,R,N,GgetMaximumValidMatrixDistance
impl
T^v,R,N,GgetImpl
virtual std::vector<float> (anonymous namespace)::FaceDescriptorBuffer::computeDistancesFrom(const vision::mod::ImageDescriptorBufferAbstract &) const
Processing Create Faceprint request
Could not create face detection request!
Unable to create request to compute bbox alignment
Could not create faceprinter
Could not create faceprint
CVMLFaceBBoxAlignerProcessOption_InputFaceObservations
faceBoxAlignerExpanded
Could not read face box aligner model
Could not map face box aligner model
CVMLAlignBBox recieved a zero dimensioned image
Could not create memory efficient crop for bbox alignment
Error aligning face bounds.  Bounds are likely out of bounds
cvml_facealigner_debug_intermediates/
_aligner_image.vdump
_aligner_image.png
_bboxes.json
_aligned_bbox_crop.png
aligned
CVML aligner debug intermediates written to: %@
CVML_DEBUG_DUMP_FACE_ALIGNER_INTERMEDIATES
computeMag2d
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/HumanDetector/cv/gradient.cpp
Nrow>1 && Ncol>1
***acicOMP: NULL pointer or zero count
***acicOMP: no nnz or tolerance specified
***acicOMP: both nnz and tolerance specified
***acicOMP: nnz > dictionarySize
Processing CVMLImageBrightnessMetric request
virtual float vision::mod::SimilarityMatrixLazy::getDistanceBetweenDescriptorIndexes(int, int)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/SimilarityMatrix/SimilarityMatrix/SimilarityMatrix_Lazy.cpp
virtual CVML_status vision::mod::SimilarityMatrixLazy::deleteDescriptorsWithIds(const std::vector<ImageDescriptorId> &)
computeACF
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/HumanDetector/cv/ChnsFeature.cpp
img.channels==3
expFeatSz[0]==featSz[0]
expFeatSz[1]==featSz[1]
expFeatSz[0]==histSz[0]
expFeatSz[1]==histSz[1]
nil buffer passed into initWithImageBuffer
Error while trying to allocate CVMLImageRegistrationSignature object: %s
Error while trying to register signatures: %s
CVMLImageprintGeneratorProcessOption_Timestamp
CVMLImageprintGeneratorTypeColorGabor
At least one of the image dimension is zero: width=%d, height=%d
unknown format for image buffer
projectionRows_planar8UtoF
projectionCols_planar8UtoF
CVML_status Projections_projectionRowsCols_planar8UtoF(const uint8_t *, int, int, size_t, float *, float *)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/ImageRegistration/Projections/Projections_Core.c
CVML_status Projections_computeProjectionDerivative(const float *, int, float *)
fastSlidingAdaBoostPred
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/HumanDetector/humandetector/TemplateObjectDetectorApply.cpp
slidingSVMPred
svm.W.size() == svmSz[0]*svmSz[1]*svmSz[2]
Corr3d
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VisionKit_Sim/VisionKit-1.64/HumanDetector/cv/CVCommon.h
featSz.size() == 3
templateSz.size() == 3
Template.size() == templateSz[0] * templateSz[1] * templateSz[2]
templateSz[0] <= featSz[0]
templateSz[1] <= featSz[1]
templateSz[2] == featSz[2]
rowcorr
lenResult==lenA-lenB+1
Failed to initialize horizon detector
The horizon detector request failed
init
unsignedIntegerValue
getImpl
dictionary
errorWithDomain:code:userInfo:
valueForKey:
stringValue
UTF8String
array
addDescriptorIds:withSimilarityMatrix:error:
getClustersWithOptions:error:
suggestionsForClusterIds:affinityThreshold:error:
suggestionsForClusterIdsWithFlags:affinityThreshold:error:
cancelClustering:
refinedSuggestionsForClusterIds:fromClusters:affinityThreshold:error:
getClusterState:
getClusteredIds
getLevel1ClusteredIdsGroupedByLevel0ClustersForFaceId:
getDistanceBetweenLevel0ClustersWithFaceIds:
getDistanceBetweenLevel1Clusters:
getRepresentativenessForFaces:error:
getClustersForClusterIds:options:error:
getDistances:to:
initWithOptions:error:
.cxx_destruct
.cxx_construct
m_ClusteringImpl
count
firstObject
methodSignatureForSelector:
invocationWithMethodSignature:
setSelector:
countByEnumeratingWithState:objects:count:
setTarget:
invoke
getReturnValue:
numberWithUnsignedInt:
addObject:
class
setArgument:atIndex:
defaultManager
stringByDeletingLastPathComponent
fileExistsAtPath:isDirectory:
fileHandleForUpdatingAtPath:
writeToFile:atomically:encoding:error:
seekToEndOfFile
stringByAppendingString:
dataUsingEncoding:
writeData:
closeFile
length
stringWithString:
stringWithCapacity:
insertString:atIndex:
stringWithFormat:
replaceCharactersInRange:withString:
localeWithLocaleIdentifier:
setLocale:
setDateFormat:
date
stringFromDate:
resetFileNameURLWithCurentDateTime
initWithOptions:logEnabled:logFileNameBase:
currentDateTime
URLByAppendingPathComponent:
path
appendString:toLogFile:
padStringWithSpaces:toSize:
appendFormat:
logString:
logClusterMap:level:
initWithOptions:logEnabled:
logClusterMapL0:
logClusterLookupMapL0:
logClusterMapL1:
logClusterLookupMapL1:
logFolderURL
logFileURL
logEnabled
fileNameBase
_logEnabled
_logFolderURL
_logFileURL
_fileNameBase
allKeys
objectForKeyedSubscript:
deleteCharactersInRange:
appendString:
logSuggestons:description:
objectAtIndexedSubscript:
logInputFaceIdsWithFlags:
logAllSuggestons:
logFilteredByInputQuerySuggestons:
logConnectedGroups:
logFinalSuggestionsList:
standardUserDefaults
boolForKey:
pathExtension
createDirectoryAtPath:withIntermediateDirectories:attributes:error:
floatValue
isKindOfClass:
errorWithCode:message:
bytes
isLogEnabled
fileURLWithPath:
alloc
objectAtIndex:
faceprint
faceId
numberWithLongLong:
arrayWithObject:
setObjects:
setClusterId:
setObject:forKeyedSubscript:
stringWithCString:encoding:
dictionaryWithObjects:forKeys:count:
errorWithAlgorithmError:
description
addFaceObservations:toFaceDescriptorBuffer:
_cancellableUpdate:facesToMove:
convertUpdatePairsToClusters:
clusterId
setTotalObjectCount:
totalObjectCount
objects
setShouldUpdateRepresentative:
shouldUpdateRepresentative
allObjects
setSuggestedIdsForRepresentative:
dictionaryWithCapacity:
objectForKey:
numberWithBool:
isEqual:
numberWithFloat:
containsObject:
setWithObject:
allValues
unionSet:
minusSet:
mutableCopy
isEqualToSet:
dataWithBytes:length:
unsignedIntValue
orderedSetWithCapacity:
longLongValue
getLevel0ClusteredIdsForFaceId:
minusOrderedSet:
unsignedLongValue
enumerateObjectsUsingBlock:
setObject:forKey:
numberWithUnsignedInteger:
boolValue
numberWithInt:
clusteringLogger
suggestionsLogger
isEqualToString:
initWithOptions:
clusterMethod
setFaceId:
addDescriptors:error:
errorWithCode:message:underlyingError:
removeObjectForKey:
deleteDescriptors:
dictionaryWithDictionary:
numberWithUnsignedLongLong:
useClusterObservation
addFaces:error:
removeFaces:error:
reset
clusterFacesWithOptions:error:
clusterState
restoreClusterState:cacheFolderPath:
getClusteredFaceIds
getGroupedClusteredFaceIdsForFaceId:
getDistanceBetweenClustersWithFaceIds:
getDistanceBetweenClusters:
matrix
setMatrix:
_obsDictById
_clustering
_threshold
_maxFaceId
_cacheFolderPath
_useClusterObservation
_matrix
_clusterMethod
initWithName:options:completionHandler:
setCancellable:
clusterContext
options
arrayWithObjects:count:
arrayWithCapacity:
code
setSuggestionsForCluster:
setResults:
internalProcessWithHandler:error:
internalCancelRequestWithHandler:error:
bundleWithIdentifier:
bundlePath
stringByAppendingPathComponent:
bundleWithPath:
pathForResource:ofType:
initializeMetalContext:error:
useGPU
metalDevice
wisdomParams
errorForMemoryAllocationFailure
setWithCapacity:
stringWithUTF8String:
copy
validatedImageBufferFromOptions:error:
width
height
shouldDumpDebugIntermediates
createDirectoryAtURL:withIntermediateDirectories:attributes:error:
computeImageDescriptorsWithImage:regionOfInterest:usingDescriptorProcessor:withTileCount:andScaleImage:andAugmentationMode:andPopulateTheBuffer:debugIntermediatesDumpPath:outputDebugDictionary:options:metalContext:error:
logInternalError:
classifyImageHierarchicallyWithDescriptors:usingImageClassifier:andHierarchicalClassifier:andMinConfidenceForClassification:outputDebugDictionary:options:metalContext:error:
classification
fileURL
lastPathComponent
stringByDeletingPathExtension
dataWithJSONObject:options:error:
writeToFile:atomically:
processWithOptions:regionOfInterest:warningRecorder:error:
getLabels
mDescriptorProcessor
mClassifier
mHierarchicalClassifier
mBlacklistedTerms
userInfo
requestName
dictionaryWithObjectsAndKeys:
localizedDescription
cStringUsingEncoding:
localizedFailureReason
errorForCancellationOfRequest:
_orderedRequestsForRequests:
lock
initWithCapacity:
unlock
removeObject:
processWithHandler:error:
_performRequests:error:
asyncProcessingDispatchQueue
_validateRequests:error:
_asyncProcessingDispatchQueue:
_asynchronouslyDispatchRequests:onDispatchQueue:completion:
cachedResults
initWithArray:
addObjectsFromArray:
cancel
removeAllObjects
requestForcedCleanupWithOptions:
forcedCleanupWithOptions:
requestForcedCleanupWithOptions:completion:
sharedInstance
purgeAll
manager
forcedCleanup
purgeAllCaches
handlerWithOptions:
requestForcedCleanup
performRequestsAsynchronous:error:queue:
performRequests:error:
getCachedResultsForKey:
addUniqueResultsIntoCacheForKey:withResultValues:
clearResultsCacheForKey:
cancelAllRequests
setCachedResults:
setClusterContext:
_requestsInFlight
_requestsPending
_requestLock
_cachedResults
_clusterContext
initWithBuffer:options:
initWithCGImage:options:
initWithCIImage:options:
initWithURL:options:
initWithData:options:
releaseOriginalBuffer
dealloc
imageBuffer
isBufferInMemoryWithWidth:height:format:
boundingBox
handlerForBuffer:options:
handlerForCGImage:options:
handlerForCIImage:options:
handlerForURL:options:
handlerForData:options:
useFullImageBufferForFaces:
properties
_imageBuffer
_properties
previousRequests
_previousRequests
detectorOfType:options:error:
imageRequestHandlerForHandler:error:
getSerialDispatchQueueSceneDetector
confidence
compare:
sortedArrayUsingComparator:
setClassification:withConfidence:
initWithSignatureData:
computeBlurSignatureForGrayscaleImage:error:
setSignatureData:
getSignatureData
_signatureData
computeBlurScore:onGrayscaleImage:andWithRegionOfInterestInImageCoordinates:andRegionOfInterestInsetFactor:error:
computeBlurScore:onGrayscaleImage:insetFactor:error:
computeBlurScore:usingBlurSignature:insetFactor:imageROI:error:
computeEdgeWidthBlurScore:onGrayscaleImage:error:
computeApproximateBlurScore:onGrayscaleImage:sampledPixelsCount:insetFactor:error:
computeApproximateBlurScore:onRGBAImage:sampledPixelsCount:insetFactor:error:
setMetalDevice:
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
debugDescription
newCommandQueue
newCommandQueueWithMaxCommandBufferCount:
heapTextureSizeAndAlignWithDescriptor:
heapBufferSizeAndAlignWithLength:options:
newHeapWithDescriptor:
newBufferWithLength:options:
newBufferWithBytes:length:options:
newBufferWithBytesNoCopy:length:options:deallocator:
newDepthStencilStateWithDescriptor:
newTextureWithDescriptor:
newSamplerStateWithDescriptor:
newDefaultLibrary
newDefaultLibraryWithBundle:error:
newLibraryWithFile:error:
newLibraryWithURL:error:
newLibraryWithData:error:
newLibraryWithSource:options:error:
newLibraryWithSource:options:completionHandler:
newRenderPipelineStateWithDescriptor:error:
newRenderPipelineStateWithDescriptor:options:reflection:error:
newRenderPipelineStateWithDescriptor:completionHandler:
newRenderPipelineStateWithDescriptor:options:completionHandler:
newComputePipelineStateWithFunction:error:
newComputePipelineStateWithFunction:options:reflection:error:
newComputePipelineStateWithFunction:completionHandler:
newComputePipelineStateWithFunction:options:completionHandler:
newComputePipelineStateWithDescriptor:options:reflection:error:
newComputePipelineStateWithDescriptor:options:completionHandler:
newFence
supportsFeatureSet:
supportsTextureSampleCount:
minimumLinearTextureAlignmentForPixelFormat:
getDefaultSamplePositions:count:
newArgumentEncoderWithArguments:
name
registryID
maxThreadsPerThreadgroup
isLowPower
isHeadless
isRemovable
recommendedMaxWorkingSetSize
isDepth24Stencil8PixelFormatSupported
readWriteTextureSupport
argumentBuffersSupport
areRasterOrderGroupsSupported
currentAllocatedSize
maxThreadgroupMemoryLength
areProgrammableSamplePositionsSupported
initWisdomParams
mapMetalDeviceNameToWisdomParams
containsString:
initWithMetalDevice:
_useGPU
_metalDevice
_wisdomParams
hasPrefix:
substringFromIndex:
detectorName
validateNonZeroImageWidth:height:componentNameProvidingBlock:error:
arrayFromOptions:withOptionName:andEnsureClass:withCountRange:error:
validateImageBuffer:error:
bestImageWidth:height:format:
processingQueue
setProcessingQueue:
_metalContext
_processingQueue
uppercaseLetterCharacterSet
scannerWithString:
isAtEnd
scanUpToCharactersFromSet:intoString:
scanCharactersFromSet:intoString:
decodeObjectForKey:
unsignedLongLongValue
encodeObject:forKey:
dataWithBytesNoCopy:length:freeWhenDone:
numberWithUnsignedChar:
getRegionNameAtNormalizedAlignedFaceCoordinate:
encodeWithCoder:
initWithCoder:
setRegionMap:deallocateBuffer:withUserBBox:andAlignedBBox:andValueToLabelMap:
getRegionLabels
getRegionNameAtImageCoordinate:andImageSize:
getRegionNameAtNormalizedFaceCoordinate:
mRegionMap
mUserBBox
mInternalAlignedBBox
mDeallocateBuffer
mPixelValueToRegionLabelMap
setRepresentativenessById:
setClusters:
initWithFaceModelData:error:
identifier
removeFace:andParameters:error:
buildModels
weakObjectsHashTable
objectEnumerator
nextObject
purgeCachedRepresentations
contextWithMTLDevice:options:
contextWithOptions:
addImageBuffer:
removeBuffer:
sharedCIContextWithOptions:
mainCIContext
mainCIContextMetalDevice
lowPriorityCIContext
lowPriorityCIContextMetalDevice
activeImageBuffers
bufferTableLock
initWithBufferOrImage:options:
intValue
isSubclassOfClass:
copyColorspaceForFormat:bitmapInfo:
_useCoreImageForFormat:
extent
imageByApplyingTransform:highQualityDownsample:
render:toCVPixelBuffer:bounds:colorSpace:
imageWithContentsOfURL:options:
imageWithData:options:
imageByApplyingTransform:
imageByCroppingToRect:
bufferWithWidth:height:format:options:error:
croppedBufferWithWidth:height:format:cropRect:options:error:
imageBufferWithBufferOrImage:options:
imageBufferWithBuffer:options:
imageBufferWithCGImage:options:
imageBufferWithCIImage:options:
imageBufferWithURL:options:
imageBufferWithData:options:
processInChunksOfSize:overlapFraction:options:roi:handler:error:
makeClippedRectAgainstImageExtentUsingOriginalRect:
createBufferWithMaxSideLengthOf:andPixelFormat:andOptions:error:
createCroppedBufferWithMaxSideLengthOf:andCropBounds:andPixelFormat:andOptions:error:
_origPixelBuffer
_origCGImage
_origCIImage
_origData
_origURL
_origImageSource
_origImageSourceSubsample8
_origImageSourceSubsample4
_origImageSourceSubsample2
_pixelBufferReps
_orientation
_orientationPassedIn
_origImageWidth
_origImageHeight
mainBundle
shared
bundleForClass:
setIs_memory_tight:
is_memory_tight
setContext_metal:
setContext_cpu:
autoSetupNetBaseName:weights:scaleConfig:setupMode:computePath:autoAspectRatio:forceReset:useLowPriorityMode:gpuPriority:
initWithNetwork:
detect:face:sublandmark:doFaceRectFix:
newface
setForceMaxNScales:
wipeLayersMemory
context_metal
autoResizeForAspectRatio:useLowPriorityMode:gpuPriority:
processBlobNoRotation:tex:doBGRA2RGBA:
getFacesFromNetworkResultOriginalWidth:originalHeight:
bounds
initWithNetworkAtPath:context:platform:computePath:
strongToStrongObjectsMapTable
enumerateKeysAndObjectsUsingBlock:
requestWithName:options:completionHandler:
recordDefaultOptionsInDictionary:
addEntriesFromDictionary:
cancellable
completionHandler
recordWarning:value:
valueForWarning:
warnings
doubleValue
getOptionalArray:forKey:inOptions:withElementsOfClass:error:
getFloatValue:forKey:inOptions:withDefaultValue:error:
initialize
requestWithName:options:
getOptionalObject:ofClass:forKey:inOptions:error:
getRequiredObject:ofClass:forKey:inOptions:error:
getDoubleValue:forKey:inOptions:error:
getDoubleValue:forKey:inOptions:withDefaultValue:error:
getFloatValue:forKey:inOptions:error:
getOptionalInputFacesArray:inOptions:error:
getPixelFocalLength:inOptions:withDefaultValue:error:
results
setCompletionHandler:
cancellationSemaphore
setCancellationSemaphore:
setRoi:
_requestName
_options
_detector
_warningRecorder
_cancellationSemaphore
_cancellationQueue
_cancellable
_results
_completionHandler
_roi
getSerialDispatchQueueHumanDetector
setContext:
context
getKey:fromDictionary:withDefault:
integerValue
setDebugMode:
setTimerMode:
setQualityCriteriaList:
setClusterSplitDistanceType:
setUseTimestampAdjustedDistances:
setPerformClustersPostprocessing:
setPerformSceneClassification:
numberWithDouble:
setRoiAreaThreshold:
setInliersRatioThreshold:
setNumberOfKeypointsToConsider:
setNaturalClusteringDistanceThreshold:
getNextImage:
qualityCriteriaList
initWithImageData:andQualityCriteria:context:error:
computeClusteringTreeForImageDescriptors:error:
computeClusteringForClusteringTree:intoKGroups:error:
computeNaturalClusteringForClusteringTree:error:
computeClusteringTreeForImageDescriptors:assumeDescriptorsAreSorted:error:
getHostTime
sortImageDescriptorsChronologically:
computeHierarchicalClusteringOfImageDescriptors:results:context:
initWithNode:freeNodeOnDealloc:
node
computeClusteringIntoKGroups:forHierarchicalTree:context:
convertClusterNodesListToDescriptorsList:
performClustersPostprocessing:error:
computeClusteringUsingDistanceThreshold:forHierarchicalTree:context:
computeNaturalClusteringForHierarchicalTree:context:
exifTimestamp
descriptorId
processImagesFromDataProvider:error:
computeClusteringOfImageDescriptors:intoKGroups:error:
computeNaturalClusteringOfImageDescriptors:error:
computeClusteringForClusteringTree:usingThreshold:error:
_context
setNode:
setFreeNodeOnDealloc:
nodeId
descriptor
left
right
distance
avgDistance
leafsCount
getLeafNodes
freeNodeOnDealloc
_freeNodeOnDealloc
_node
setModelValuesFromDictionary:
maxIdentitiesCount
facePrintLength
createDictionaryRepresentationOfModelValuesNoCopy
flattenedFaceprintCache
flattenedFaceIdCache
UUIDString
enrolledIdentitiesCount
minRequiredFaceprintsPerIdentityCount
minRequiredIdentitiesCount
initWithUUIDString:
maxFaceprintCountPerIdentity
identitiesEnrolledInModel
removeObjectAtIndex:
modelVersion
vipAlgorithmState
setVIPAlgorithmState:
enrolledFaceCount
enrolledFaceCountForIdentity:
canBuildModel
isModelReadyToIdentifyFaces
setIsModelBuilt:
getUUIDForInternalId:
addFace:error:
removeFace:
removeIdentity:
identitiesModelCanIdentify
algorithmMajorVersion
algorithmMinorVersion
modelLabels
setModelLabels:
mIsModelBuilt
mModelVersion
mModelMinorVersion
mEnrolledFaceCount
mFaceprintType
mUUIDToInternalIdMap
mInternalIdToUUIDMap
mFaceprintCountPerIdentity
mModelValues
mFaceprintToInternalIdMap
_modelLabels
setValue:forKey:
enrollFace:andParameters:error:
load:
baseAddress
unload:
faceObservationFromOptions:withOptionName:error:
landmarkPoints
alignedBoundingBox
setExpressionsAndScores:
expressionTypeFromString:
createExpressionAndConfidencesDictionaryFromScores:
createExpressionDetectionDictionaryFromScores:
m_FaceAttributesImpl
m_LandmarkRefinerModelFileHandle
purgeIntermediates
forcedCleanupFacePipelineWithLevel:
forcedCleanupScenePipelineWithLevel:
forcedCleanupJunkPipelineWithLevel:
getSerialDispatchQueueFaceDetectorAccurate
getSerialDispatchQueueFaceDetectorBalanced
getSerialDispatchQueueFaceDetectorFast
getSerialDispatchQueueFaceLandmarkDetector
getSerialDispatchQueueFaceExpressionDetector
getSerialDispatchQueueFacePrinter
getSerialDispatchQueueJunkDetector
getSerialDispatchQueueImageprintGenerator
_faceDetectorAccurate
_faceDetectorBalanced
_faceDetectorFast
_faceLandmarkDetector
_faceExpressionDetector
_faceprintGenerator
_humanDetector
_junkIdentifier
_sceneClassifier
_imageprintGenerator
_faceDetectorAccurateSerialQueue
_faceDetectorBalancedSerialQueue
_faceDetectorFastSerialQueue
_faceLandmarkDetectorSerialQueue
_faceExpressionDetectorSerialQueue
_faceprintGeneratorSerialQueue
_humanDetectorSerialQueue
_junkIdentifierSerialQueue
_sceneClassifierSerialQueue
_imageprintGeneratorSerialQueue
setBoundingBox:
mHumanDetectorAlgorithmImpl_
hasWarnings
_warnings
numberWithUnsignedLong:
setClusterState:
setClusteredFaceIds:
setGroupedClusteredFaceIdsForCluster:
setDistance:
setDistances:
_initializationError
dateFromString:
timeIntervalSince1970
getHostTimeInNanos
createErrorWithCode:andMessage:
freeVImageBuffer:
parseExifTimestamp:
computeSharpnessQualityForImage:result:
computeImageQuality:forCriteria:error:
setIdentifier:
setFaceIdConfidence:
removeIdentity:andParameters:error:
probeForIdentity:andParameters:error:
modelData
setModelData:
_mVIPAlgorithmImpl
_modelData
initWithVImage:externalImageId:andExifTimestampValue:error:
initWithCVPixelBufferImage:externalImageId:andExifTimestampValue:error:
initWithVImage:externalImageId:andExifTimestampString:error:
initWithCVPixelBufferImage:externalImageId:andExifTimestampString:error:
image
imageCVPixelBuffer
imageFilePath
setImageFilePath:
freeImageInDealloc
setFreeImageInDealloc:
externalImageId
_freeImageInDealloc
_image
_imageCVPixelBuffer
_imageFilePath
_externalImageId
_exifTimestamp
hasBBoxBeenAligned
internalDetermineFacesToProcessFrom:outputFacesThatNeedNoProcessing:outputFacesThatNeedAlignment:outputFacesThatNeedLandmarks:
_inputFaces
initWithBytes:length:
setLandmarkPoints3d:
setPoseData:
mCameraCalibrationMatrix
setFaceRegionMap:
mFaceRegionMapAlgorithmImpl
initForReadingWithData:
setDecodingFailurePolicy:
error
finishDecoding
initForWritingWithMutableData:
finishEncoding
initWithData:forKey:
serializeSelfForKey:
setConfidence:
_confidence
decodeObjectOfClass:forKey:
observationWithBoundingBox:
_identifier
_boundingBox
setFaceprint:
computeDistanceToFaceprint:withDistanceFunction:error:
setKey:
platform
setPlatform:
profile
setProfile:
faceprintInputPath
setFaceprintInputPath:
_platform
_profile
_faceprint
_key
_faceprintInputPath
setHasBBoxBeenAligned:
setAlignedBoundingBox:
initWithData:pointCount:is3D:userFacingBBox:alignedBBox:
landmarkPoints3d
observationWithBoundingBox:andAlignedBoundingBox:
computeYawPitchRollFromPoseMatrix:outputYaw:outputPitch:outputRoll:
expressionsAndConfidence
nameConfidence
landmarks
landmarks3d
pose
getComputedRectifyingTransform:
setIsBlinking:
isBlinking
alignedBoundingBoxAsCGRect
expressionsAndScores
expressionsAndDetections
setLandmarkScore:
landmarkScore
faceRegionMap
setLandmarks:
setLandmarks3d:
landmarkPointsScore
setLandmarkPointsScore:
setLandmarkPoints:
poseData
faceIdConfidence
alignedMeanShape
setAlignedMeanShape:
_landmarkScore
_isBlinking
_expressionsAndScores
_hasBBoxBeenAligned
_landmarkPointsScore
_faceIdConfidence
_faceRegionMap
_landmarks
_landmarks3d
_landmarkPoints
_landmarkPoints3d
_poseData
_alignedMeanShape
_faceId
_alignedBoundingBox
alignmentTransform
setAlignmentTransform:
baseImageSignature
setBaseImageSignature:
currentImageSignature
setCurrentImageSignature:
_baseImageSignature
_currentImageSignature
_alignmentTransform
blurMeasure
setBlurMeasure:
_blurMeasure
brightness
setBrightness:
_brightness
initWithData:
calculateDistanceFromImageprint:
imageprintDescriptor
distanceFromDescriptor:
calculateDistanceFromImageprintObservation:
initWithRawColorGaborDescriptor:
rawColorGaborDescriptor
serializedLength
mutableBytes
serializeStateIntoData:startingAtByteOffset:error:
dataWithLength:
calculateDistanceBetweenImageprint1:andImageprint2:
serialize
isImageprintValid
initWithRawImageprintDescriptor:
rawImageprintDescriptor
serializeAsVNImageprintStateAndReturnError:
imageprintVersion
setImageprintVersion:
setImageprintDescriptor:
imageprintType
setImageprintType:
_imageprintVersion
_imageprintDescriptor
_imageprintType
stringByAppendingFormat:
_classification
topLeft
setTopLeft:
topRight
setTopRight:
bottomLeft
setBottomLeft:
bottomRight
setBottomRight:
_topLeft
_topRight
_bottomLeft
_bottomRight
transform
setTransform:
angle
setAngle:
_angle
_transform
string
suggestedIdsForRepresentative
representativenessById
_shouldUpdateRepresentative
_objects
_clusterId
_totalObjectCount
_suggestedIdsForRepresentative
_representativenessById
clusters
suggestionsForCluster
clusteredFaceIds
groupedClusteredFaceIdsForCluster
distances
distancesById
setDistancesById:
_clusters
_suggestionsForCluster
_clusterState
_clusteredFaceIds
_groupedClusteredFaceIdsForCluster
_distance
_distances
_distancesById
internalDetermineFacesToProcessFrom:outputFacesThatNeedNoProcessing:outputFacesThatNeedProcessing:outputFacesThatNeed2DLandmarks:
_pixelFocalLengthNumber
groupImageprints:withOptions:error:
useTimestampAdjustedDistances
computeTotalDistanceForDescriptorDistance:timestampDiff:useTimestampAdjustment:
setPreviousLeafId:
setNextLeafId:
setPreviousLeafDescriptorDistance:
setNextLeafDescriptorDistance:
setPreviousLeafTimestampDistance:
setNextLeafTimestampDistance:
setPreviousLeafTotalDistance:
setNextLeafTotalDistance:
clusterSplitDistanceType
getDistanceForClusterNode:splitDistanceType:
computeClusteringIntoKGroups:orUsingDistanceThreshold:forHierarchicalTree:context:
naturalClusteringDistanceThreshold
computeTimestampAdjustedDistanceForBaseDistance:andTimestampDiff:
quality
setWithArray:
contentsOfDirectoryAtPath:error:
removeItemAtPath:error:
mFaceLandmarkAlgorithmImpl
mFaceLandmarkMouthRefinerImpl
mFaceLandmarkRightEyeRefinerImpl
mFaceLandmarkLeftEyeRefinerImpl
mFaceAttributesPupilRefiner
mCoreLandmarkModelFileHandle
mLandmarkRefinerModelFileHandle
fileURLWithPath:isDirectory:
numberWithInteger:
classifyImageWithDescriptors:usingImageClassifier:andMinConfidenceForClassification:outputDebugDictionary:options:metalContext:error:
mJunkDescriptorImpl
mJunkClassifierImpl
_perMeshPtr
processWithOptions:warningRecorder:error:
setObject:atIndexedSubscript:
newCropAroundBounds:extendBoundsWithinImageBy:fromImageBuffer:error:
mFaceDetectorImpl
mBBoxAlignerImpl
getPointCount
pointCount
setPointCount:
_pointCount
pointAtIndex:
initWithPoints:pointCount:
points
setPoints:
_points
userFacingBBox
alignedBBox
is3DLandmarks
pointsData
isUserFacingBBoxEquivalentToAlignedBBox
regions
createPointArray:count:
setRegions:
regionForName:
setIs3DLandmarks:
setPointsData:
setAlignedBBox:
setUserFacingBBox:
_is3DLandmarks
_regions
_pointsData
_alignedBBox
_userFacingBBox
arrayFromOptions:withOptionName:andEnsureClass:error:
initWithImageBuffer:andOptions:error:
registerImageSignature:withSignature:andOptions:minimumOverlap:error:
advise:
resourcePath
setResourcePath:
initWithMappedModel:
m_impl
initWithLearnedMetric:error:
addFaceToMetric:andParameters:error:
mMetricLearningImpl
computeDescriptorForImageData:context:error:
computeConvnetDescriptorForImageData:context:error:
computeRegistrationFeaturesForImageData:context:error:
initWithImageData:context:error:
computeQualityForImageData:andQualityCriteria:context:error:
longValue
shortValue
numberWithLong:
numberWithShort:
timerMode
colorGaborDescriptor
computeFinalDescriptorBasedDistanceForColorDistance:andSceneClassifierDistance:
getUUIDBytes:
initWithImageData:andCustomQualityScore:context:error:
sceneClassifierDescriptor
imageRegistrationDescriptor
previousLeafId
nextLeafId
nextLeafDescriptorDistance
previousLeafDescriptorDistance
nextLeafTimestampDistance
previousLeafTimestampDistance
nextLeafTotalDistance
previousLeafTotalDistance
_quality
_nextLeafDescriptorDistance
_previousLeafDescriptorDistance
_nextLeafTotalDistance
_previousLeafTotalDistance
_descriptorId
_colorGaborDescriptor
_sceneClassifierDescriptor
_imageRegistrationDescriptor
_previousLeafId
_nextLeafId
_nextLeafTimestampDistance
_previousLeafTimestampDistance
mUseLowMemoryMode
mDetectionLevel
fileExistsAtPath:
UUID
copyItemAtPath:toPath:error:
moveItemAtPath:toPath:error:
computeFromBuffer:withChannels:error:
computeFromPixelBuffer:withChannels:error:
m_FaceDescriptorImpl
m_FaceFrontalizerImpl
m_DescriptorAugmenter
m_FaceFrontalizerWorkingBuffer
m_FaceFrontalizerImageBuffer
m_RequiredImageSize
_useLowPriorityMode
_metalContextPriority
doesAreaOverlapBetweenRect:andOtherRect:withOverlapRatioGreaterThan:
computeNormalizedCosineDistanceOfFaceprint:toFaceprint:
doesAreaOverlapSignificantlyBetweenRect:andOtherRect:
_inputArguments
internalDetermineFacesToProcessFrom:outputFacesThatNeedNoProcessing:outputFacesThatNeedProcessing:
debugMode
performClustersPostprocessing
performSceneClassification
roiAreaThreshold
inliersRatioThreshold
numberOfKeypointsToConsider
_useTimestampAdjustedDistances
_performClustersPostprocessing
_performSceneClassification
_debugMode
_timerMode
_clusterSplitDistanceType
_roiAreaThreshold
_inliersRatioThreshold
_numberOfKeypointsToConsider
_naturalClusteringDistanceThreshold
_qualityCriteriaList
_mInputFaces
addFaceIds:withSimilarityMatrix:error:
_addFaceId:withSimilarityMatrix:
raise:format:
getMatrixSize
getDescriptorIdsForRange:
getAllDistancesForId:
faceIdsMapping
setFaceIdsMapping:
distances_map
_faceIdsMapping
computeBrightnessScore:onImage:error:
getMaximumValidMatrixDistance
createCopyForDescriptorIds:
getDistanceBetweenDescriptor:andDescriptor:
containsId:
m_MatrixImpl
internalDetermineFacesToProcessFrom:outputFacesThatNeedNoProcessing:outputFacesThatNeedAlignment:outputFacesThatNeedFaceprints:
mFaceBoxAlignerImpl
mFaceBoxAlignerModelFileHandle
initWithBrightness:
brightnessWithValue:
signature
mSignature_
objectForInfoDictionaryKey:
CVMLHierarchicalClustering
CVMLClustering
CVMLClusteringLogger
CVMLSuggestionsLogger
CVMLGreedyClustering
CVMLClusterContext
CVMLSuggestionsForClustersRequest
CVMLSceneClassifier
CVMLError
CVMLRequestHandler
CVMLImageRequestHandler
CVMLSequenceRequestHandler
CVMLSceneClassificationRequest
CVMLKnownSceneClassificationsRequest
CVMLBlurSignature
CVMLBlurMeasure
CVMLRefinedSuggestionsForClustersRequest
MTLDevice
NSObject
CVMLMetalContext
CVMLDetector
CVMLFaceRegionMap
NSCoding
CVMLRepresentativeForClusterRequest
CVMLRemoveFaceFromFaceModelsRequest
CVMLImageBufferManager
CVMLImageBuffer
CVMLRequest
CVMLWarningRecorder
CVMLDetectHumanRectanglesRequest
MomentProcessor
CVMLMPClusteringTreeNodeWrapper
CVMLFaceModelObservation
CVMLAddFaceToFaceModelsRequest
CVMLFaceExpressionDetector
CVMLDetectorManager
CVMLHumanDetector
CVMLClusterObservationsRequest
CVMLMPUtils
CVMLMPImageQuality
CVMLFaceId
MPImageData
CVMLDetectFaceLandmarksRequest
CVMLFaceGeometryEstimator
CVMLFaceRegionMapGenerator
CVMLObservation
CVMLDetectedObject
CVMLFaceprint
CVMLFaceprintModel
CVMLFaceObservation
CVMLImageAlignmentObservation
CVMLImageBlurObservation
CVMLImageBrightnessObservation
CVMLImageprintObservation
CVMLClassification
CVMLRectangleObservation
CVMLHumanObservation
CVMLHorizonObservation
CVMLCluster
CVMLClusterObservation
CVMLHorizonDetector
CVMLDetectFacePoseRequest
CVMLGetDistancesRequest
CVMLImageGrouper
CVMLLearnedDistanceMetricObservation
CVMLMPImageGrouping
CVMLDetectFace3DLandmarksRequest
CVMLFaceLandmarkDetector
CVMLJunkIdentifier
CVMLRectangleDetector
CVMLImageBlurMetricRequest
CVMLFaceDetector
CVMLFaceLandmarksRegion
CVMLFaceLandmarksRegion2D
CVMLFaceLandmarksRegion3D
CVMLFaceLandmarks
CVMLValidationUtilities
CVMLImageRegistrationRequest
CVMLImageClassifier
CVMLCreateImageprintRequest
CVMLModelFileImpl
CVMLModelFile
CVMLModelFilesCache
CVMLRemoveIdentityFromFaceModelsRequest
CVMLMetricLearning
MPImageDescriptor
CVMLDetectFaceRectanglesRequest
CVMLGetClustersRequest
CVMLFaceprintGenerator
CVMLCreateFaceRegionMapRequest
CVMLDebugHelpers
CVMLCreateFaceModelsRequest
CVMLDetectRectanglesRequest
CVMLIdentifyFaceRequest
CVMLIdentifyJunkRequest
CVMLGroupImagesByTimeAndContentRequest
CVMLAlignFaceBBoxPrivateRequest
CVMLMPContext
CVMLDetectFaceExpressionsRequest
CVMLAgglomerativeClustering
CVMLBrightnessMeasure
CVMLSimilarityMatrix
CVMLCreateFaceprintRequest
CVMLFaceBBoxAligner
CVMLImageBrightnessMetricRequest
CVMLImageRegistrationSignature
CVMLImageRegistration
CVMLMPImageSharpness
CVMLImageprintGenerator
CVMLDetectHorizonRequest
B40@0:8@16@24^@32
@32@0:8@16^@24
@36@0:8@16f24^@28
B24@0:8^@16
@44@0:8@16@24f32^@36
@24@0:8^@16
@16@0:8
@24@0:8@16
@40@0:8@16@24^@32
@32@0:8@16@24
B40@0:8@"NSArray"16@"CVMLSimilarityMatrix"24^@32
@"NSArray"32@0:8@"NSDictionary"16^@24
@"NSArray"36@0:8@"NSArray"16f24^@28
@"NSArray"36@0:8@"NSDictionary"16f24^@28
@"NSArray"44@0:8@"NSArray"16@"NSArray"24f32^@36
@"NSData"24@0:8^@16
@"NSSet"16@0:8
@"NSArray"24@0:8@"NSNumber"16
@"NSNumber"24@0:8@"NSArray"16
@"NSDictionary"24@0:8@"NSArray"16
@"NSDictionary"32@0:8@"NSArray"16^@24
@"NSArray"40@0:8@"NSArray"16@"NSDictionary"24^@32
@"NSDictionary"32@0:8@"NSArray"16@"NSArray"24
v16@0:8
{shared_ptr<vision::mod::ClusteringAbstract>="__ptr_"^{ClusteringAbstract}"__cntrl_"^{__shared_weak_count}}
v32@0:8@16@24
@32@0:8@16q24
@36@0:8@16B24@28
@28@0:8@16B24
v24@0:8@16
v32@0:8r^{map<long long, std::__1::vector<long long, std::__1::allocator<long long> >, std::__1::less<long long>, std::__1::allocator<std::__1::pair<const long long, std::__1::vector<long long, std::__1::allocator<long long> > > > >={__tree<std::__1::__value_type<long long, std::__1::vector<long long, std::__1::allocator<long long> > >, std::__1::__map_value_compare<long long, std::__1::__value_type<long long, std::__1::vector<long long, std::__1::allocator<long long> > >, std::__1::less<long long>, true>, std::__1::allocator<std::__1::__value_type<long long, std::__1::vector<long long, std::__1::allocator<long long> > > > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<long long, std::__1::vector<long long, std::__1::allocator<long long> > >, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<long long, std::__1::__value_type<long long, std::__1::vector<long long, std::__1::allocator<long long> > >, std::__1::less<long long>, true> >=Q}}}16@24
v24@0:8r^{map<long long, std::__1::vector<long long, std::__1::allocator<long long> >, std::__1::less<long long>, std::__1::allocator<std::__1::pair<const long long, std::__1::vector<long long, std::__1::allocator<long long> > > > >={__tree<std::__1::__value_type<long long, std::__1::vector<long long, std::__1::allocator<long long> > >, std::__1::__map_value_compare<long long, std::__1::__value_type<long long, std::__1::vector<long long, std::__1::allocator<long long> > >, std::__1::less<long long>, true>, std::__1::allocator<std::__1::__value_type<long long, std::__1::vector<long long, std::__1::allocator<long long> > > > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<long long, std::__1::vector<long long, std::__1::allocator<long long> > >, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<long long, std::__1::__value_type<long long, std::__1::vector<long long, std::__1::allocator<long long> > >, std::__1::less<long long>, true> >=Q}}}16
B16@0:8
@"NSURL"
@"NSString"
v32@0:8@16^{ImageDescriptorBufferFloat32=^^?{vector<long long, std::__1::allocator<long long> >=^q^q{__compressed_pair<long long *, std::__1::allocator<long long> >=^q}}{map<long long, int, std::__1::less<long long>, std::__1::allocator<std::__1::pair<const long long, int> > >={__tree<std::__1::__value_type<long long, int>, std::__1::__map_value_compare<long long, std::__1::__value_type<long long, int>, std::__1::less<long long>, true>, std::__1::allocator<std::__1::__value_type<long long, int> > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<long long, int>, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<long long, std::__1::__value_type<long long, int>, std::__1::less<long long>, true> >=Q}}}^vQQQBQi^f}24
@24@0:8^{vector<std::__1::pair<long long, long long>, std::__1::allocator<std::__1::pair<long long, long long> > >=^{pair<long long, long long>}^{pair<long long, long long>}{__compressed_pair<std::__1::pair<long long, long long> *, std::__1::allocator<std::__1::pair<long long, long long> > >=^{pair<long long, long long>}}}16
q32@0:8^{ImageDescriptorBufferFloat32=^^?{vector<long long, std::__1::allocator<long long> >=^q^q{__compressed_pair<long long *, std::__1::allocator<long long> >=^q}}{map<long long, int, std::__1::less<long long>, std::__1::allocator<std::__1::pair<const long long, int> > >={__tree<std::__1::__value_type<long long, int>, std::__1::__map_value_compare<long long, std::__1::__value_type<long long, int>, std::__1::less<long long>, true>, std::__1::allocator<std::__1::__value_type<long long, int> > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<long long, int>, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<long long, std::__1::__value_type<long long, int>, std::__1::less<long long>, true> >=Q}}}^vQQQBQi^f}16^{vector<std::__1::pair<long long, long long>, std::__1::allocator<std::__1::pair<long long, long long> > >=^{pair<long long, long long>}^{pair<long long, long long>}{__compressed_pair<std::__1::pair<long long, long long> *, std::__1::allocator<std::__1::pair<long long, long long> > >=^{pair<long long, long long>}}}24
{shared_ptr<vision::mod::GreedyClustererFacesAPI>="__ptr_"^{GreedyClustererFacesAPI}"__cntrl_"^{__shared_weak_count}}
@"CVMLClusteringLogger"
@"CVMLSuggestionsLogger"
B32@0:8@16^@24
@24@0:8Q16
B32@0:8@16@24
@"NSMutableDictionary"
@"<CVMLClustering>"
@"CVMLSimilarityMatrix"
@40@0:8@16@24@?32
@72@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24@56^@64
{shared_ptr<vision::mod::ImageDescriptorProcessorAbstract>="__ptr_"^{ImageDescriptorProcessorAbstract}"__cntrl_"^{__shared_weak_count}}
{shared_ptr<vision::mod::ImageClassifierAbstract>="__ptr_"^{ImageClassifierAbstract}"__cntrl_"^{__shared_weak_count}}
{shared_ptr<vision::mod::ImageClassifier_HierarchicalModel>="__ptr_"^{ImageClassifier_HierarchicalModel}"__cntrl_"^{__shared_weak_count}}
@"NSSet"
@28@0:8i16@20
@36@0:8i16@20@28
v32@0:8@16@?24
v40@0:8@16@24@?32
B40@0:8@16^@24@32
B24@0:8@16
@"NSMutableArray"
@"NSLock"
@"NSObject"
@32@0:8^{__CVBuffer=}16@24
@32@0:8^{CGImage=}16@24
@"CVMLImageBuffer"
@"NSDictionary"
@32@0:8^{__CVBuffer=}16^@24
@24@0:8^v16
v24@0:8^v16
^v16@0:8
B76@0:8^f16^{__CVBuffer=}24{CGRect={CGPoint=dd}{CGSize=dd}}32f64^@68
B44@0:8^f16^{__CVBuffer=}24f32^@36
B76@0:8^f16@24f32{CGRect={CGPoint=dd}{CGSize=dd}}36^@68
B40@0:8^f16^{__CVBuffer=}24^@32
B48@0:8^f16^{__CVBuffer=}24i32f36^@40
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
{?=QQ}24@0:8@16
{?=QQ}32@0:8Q16Q24
@32@0:8Q16Q24
@40@0:8r^v16Q24Q32
@48@0:8^v16Q24Q32@?40
@48@0:8@16Q24^@32^@40
v40@0:8@16Q24@?32
B24@0:8Q16
Q24@0:8Q16
v32@0:8^{?=ff}16Q24
{?=QQQ}16@0:8
@"<MTLCommandQueue>"16@0:8
@"<MTLCommandQueue>"24@0:8Q16
{?=QQ}24@0:8@"MTLTextureDescriptor"16
@"<MTLHeap>"24@0:8@"MTLHeapDescriptor"16
@"<MTLBuffer>"32@0:8Q16Q24
@"<MTLBuffer>"40@0:8r^v16Q24Q32
@"<MTLBuffer>"48@0:8^v16Q24Q32@?<v@?^vQ>40
@"<MTLDepthStencilState>"24@0:8@"MTLDepthStencilDescriptor"16
@"<MTLTexture>"24@0:8@"MTLTextureDescriptor"16
@"<MTLSamplerState>"24@0:8@"MTLSamplerDescriptor"16
@"<MTLLibrary>"16@0:8
@"<MTLLibrary>"32@0:8@"NSBundle"16^@24
@"<MTLLibrary>"32@0:8@"NSString"16^@24
@"<MTLLibrary>"32@0:8@"NSURL"16^@24
@"<MTLLibrary>"32@0:8@"NSObject<OS_dispatch_data>"16^@24
@"<MTLLibrary>"40@0:8@"NSString"16@"MTLCompileOptions"24^@32
v40@0:8@"NSString"16@"MTLCompileOptions"24@?<v@?@"<MTLLibrary>"@"NSError">32
@"<MTLRenderPipelineState>"32@0:8@"MTLRenderPipelineDescriptor"16^@24
@"<MTLRenderPipelineState>"48@0:8@"MTLRenderPipelineDescriptor"16Q24^@32^@40
v32@0:8@"MTLRenderPipelineDescriptor"16@?<v@?@"<MTLRenderPipelineState>"@"NSError">24
v40@0:8@"MTLRenderPipelineDescriptor"16Q24@?<v@?@"<MTLRenderPipelineState>"@"MTLRenderPipelineReflection"@"NSError">32
@"<MTLComputePipelineState>"32@0:8@"<MTLFunction>"16^@24
@"<MTLComputePipelineState>"48@0:8@"<MTLFunction>"16Q24^@32^@40
v32@0:8@"<MTLFunction>"16@?<v@?@"<MTLComputePipelineState>"@"NSError">24
v40@0:8@"<MTLFunction>"16Q24@?<v@?@"<MTLComputePipelineState>"@"MTLComputePipelineReflection"@"NSError">32
@"<MTLComputePipelineState>"48@0:8@"MTLComputePipelineDescriptor"16Q24^@32^@40
v40@0:8@"MTLComputePipelineDescriptor"16Q24@?<v@?@"<MTLComputePipelineState>"@"MTLComputePipelineReflection"@"NSError">32
@"<MTLFence>"16@0:8
@"<MTLArgumentEncoder>"24@0:8@"NSArray"16
@"<MTLDevice>"
B40@0:8^Q16^Q24^I32
@"CVMLMetalContext"
@"NSObject<OS_dispatch_queue>"
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
v84@0:8^{vImage_Buffer=^vQQQ}16B24{CGRect={CGPoint=dd}{CGSize=dd}}28{_Geometry2D_rect2D_={_Geometry2D_point2D_=ff}{_Geometry2D_size2D_=ff}}60@76
@32@0:8{CGPoint=dd}16
@48@0:8{CGPoint=dd}16{CGSize=dd}32
{vImage_Buffer="data"^v"height"Q"width"Q"rowBytes"Q}
{CGRect="origin"{CGPoint="x"d"y"d}"size"{CGSize="width"d"height"d}}
{_Geometry2D_rect2D_="origin"{_Geometry2D_point2D_="x"f"y"f}"size"{_Geometry2D_size2D_="height"f"width"f}}
@"CIContext"
@"NSHashTable"
^{__CVBuffer=}52@0:8Q16Q24I32@36^@44
^{__CVBuffer=}84@0:8Q16Q24I32{CGRect={CGPoint=dd}{CGSize=dd}}36@68^@76
B36@0:8Q16Q24I32
B84@0:8Q16f24@28{CGRect={CGPoint=dd}{CGSize=dd}}36@?68^@76
{CGRect={CGPoint=dd}{CGSize=dd}}48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
^{__CVBuffer=}44@0:8Q16I24@28^@36
^{__CVBuffer=}76@0:8Q16{CGRect={CGPoint=dd}{CGSize=dd}}24I56@60^@68
B20@0:8I16
^{CGColorSpace=}28@0:8I16^I20
^{__CVBuffer=}
^{CGImage=}
@"CIImage"
@"NSData"
^{CGImageSource=}
^{__CFArray=}
B56@0:8^@16#24@32@40^@48
B48@0:8^d16@24@32^@40
B56@0:8^d16@24@32d40^@48
B48@0:8^f16@24@32^@40
B52@0:8^f16@24@32f40^@44
B56@0:8^@16@24@32#40^@48
B40@0:8^@16@24^@32
B44@0:8^f16@24f32^@36
v32@0:8@"NSString"16@24
@24@0:8@"NSString"16
@?16@0:8
v24@0:8@?16
v20@0:8B16
{CGRect={CGPoint=dd}{CGSize=dd}}16@0:8
v48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
@"CVMLDetector"
@"CVMLWarningRecorder"
@"NSObject<OS_dispatch_semaphore>"
@"NSArray"
@36@0:8@16i24^@28
@36@0:8@16B24^@28
@40@0:8{vector<MPClusteringTreeNode *, std::__1::allocator<MPClusteringTreeNode *> >=^^{MPClusteringTreeNode}^^{MPClusteringTreeNode}{__compressed_pair<MPClusteringTreeNode **, std::__1::allocator<MPClusteringTreeNode *> >=^^{MPClusteringTreeNode}}}16
@40@0:8@16@24@32
@"CVMLMPContext"
@28@0:8^v16B24
i16@0:8
f16@0:8
I16@0:8
r^v16@0:8
B24@0:8^v16
i24@0:8@16
@20@0:8i16
{vector<int, std::__1::allocator<int> >="__begin_"^i"__end_"^i"__end_cap_"{__compressed_pair<int *, std::__1::allocator<int> >="__first_"^i}}
{shared_ptr<vision::mod::ModelValues>="__ptr_"^{ModelValues}"__cntrl_"^{__shared_weak_count}}
{map<(anonymous namespace)::Faceprint, int, std::__1::less<(anonymous namespace)::Faceprint>, std::__1::allocator<std::__1::pair<const (anonymous namespace)::Faceprint, int> > >="__tree_"{__tree<std::__1::__value_type<(anonymous namespace)::Faceprint, int>, std::__1::__map_value_compare<(anonymous namespace)::Faceprint, std::__1::__value_type<(anonymous namespace)::Faceprint, int>, std::__1::less<(anonymous namespace)::Faceprint>, true>, std::__1::allocator<std::__1::__value_type<(anonymous namespace)::Faceprint, int> > >="__begin_node_"^{__tree_end_node<std::__1::__tree_node_base<void *> *>}"__pair1_"{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<(anonymous namespace)::Faceprint, int>, void *> > >="__first_"{__tree_end_node<std::__1::__tree_node_base<void *> *>="__left_"^{__tree_node_base<void *>}}}"__pair3_"{__compressed_pair<unsigned long, std::__1::__map_value_compare<(anonymous namespace)::Faceprint, std::__1::__value_type<(anonymous namespace)::Faceprint, int>, std::__1::less<(anonymous namespace)::Faceprint>, true> >="__first_"Q}}}
{shared_ptr<vision::mod::LandmarkAttributes>="__ptr_"^{LandmarkAttributes}"__cntrl_"^{__shared_weak_count}}
@"<CVMLModelFile>"
@"CVMLFaceDetector"
@"CVMLFaceLandmarkDetector"
@"CVMLFaceExpressionDetector"
@"CVMLFaceprintGenerator"
@"CVMLHumanDetector"
@"CVMLJunkIdentifier"
@"CVMLSceneClassifier"
@"CVMLImageprintGenerator"
^{TemplateObjectDetectorApply=iiiiB[2f][2f]fBBffif{hog={gradient=}}{ChnsFeat=ii{hog={gradient=}}{gradient=}}i{vector<vision::hum::DTreeApply, std::__1::allocator<vision::hum::DTreeApply> >=^{DTreeApply}^{DTreeApply}{__compressed_pair<vision::hum::DTreeApply *, std::__1::allocator<vision::hum::DTreeApply> >=^{DTreeApply}}}{vector<std::__1::map<int, vision::hum::DTreeNode, std::__1::less<int>, std::__1::allocator<std::__1::pair<const int, vision::hum::DTreeNode> > >, std::__1::allocator<std::__1::map<int, vision::hum::DTreeNode, std::__1::less<int>, std::__1::allocator<std::__1::pair<const int, vision::hum::DTreeNode> > > > >=^{map<int, vision::hum::DTreeNode, std::__1::less<int>, std::__1::allocator<std::__1::pair<const int, vision::hum::DTreeNode> > >}^{map<int, vision::hum::DTreeNode, std::__1::less<int>, std::__1::allocator<std::__1::pair<const int, vision::hum::DTreeNode> > >}{__compressed_pair<std::__1::map<int, vision::hum::DTreeNode, std::__1::less<int>, std::__1::allocator<std::__1::pair<const int, vision::hum::DTreeNode> > > *, std::__1::allocator<std::__1::map<int, vision::hum::DTreeNode, std::__1::less<int>, std::__1::allocator<std::__1::pair<const int, vision::hum::DTreeNode> > > > >=^{map<int, vision::hum::DTreeNode, std::__1::less<int>, std::__1::allocator<std::__1::pair<const int, vision::hum::DTreeNode> > >}}}{vector<float, std::__1::allocator<float> >=^f^f{__compressed_pair<float *, std::__1::allocator<float> >=^f}}{vector<vision::hum::DTreeNode *, std::__1::allocator<vision::hum::DTreeNode *> >=^^{DTreeNode}^^{DTreeNode}{__compressed_pair<vision::hum::DTreeNode **, std::__1::allocator<vision::hum::DTreeNode *> >=^^{DTreeNode}}}f{adaBoostApply={vector<vision::hum::DTreeApply, std::__1::allocator<vision::hum::DTreeApply> >=^{DTreeApply}^{DTreeApply}{__compressed_pair<vision::hum::DTreeApply *, std::__1::allocator<vision::hum::DTreeApply> >=^{DTreeApply}}}}{linearSVMApply={vector<float, std::__1::allocator<float> >=^f^f{__compressed_pair<float *, std::__1::allocator<float> >=^f}}f{vector<float, std::__1::allocator<float> >=^f^f{__compressed_pair<float *, std::__1::allocator<float> >=^f}}}@}
@"NSError"
d16@0:8
@32@0:8q16@24
v24@0:8^{vImage_Buffer=^vQQQ}16
q24@0:8@16
f40@0:8^{vImage_Buffer=^vQQQ}16@24^@32
{shared_ptr<vision::mod::VIPIdentification>="__ptr_"^{VIPIdentification}"__cntrl_"^{__shared_weak_count}}
@"CVMLFaceModelObservation"
@48@0:8^{vImage_Buffer=^vQQQ}16@24@32^@40
@48@0:8^{vImage_Buffer=^vQQQ}16@24q32^@40
@48@0:8^{__CVBuffer=}16@24@32^@40
@48@0:8^{__CVBuffer=}16@24q32^@40
^{vImage_Buffer=^vQQQ}16@0:8
^{__CVBuffer=}16@0:8
q16@0:8
^{vImage_Buffer=^vQQQ}
v48@0:8@16@24@32@40
[9f]
{shared_ptr<vision::mod::FaceRegionMap>="__ptr_"^{FaceRegionMap}"__cntrl_"^{__shared_weak_count}}
v20@0:8f16
@48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
@"NSUUID"
@"NSData"16@0:8
v24@0:8@"NSData"16
@40@0:8@16q24^@32
v20@0:8I16
@80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48
B104@0:8{?=[4]}16^f80^f88^f96
{?=[4]}16@0:8
B24@0:8^{CGAffineTransform=dddddd}16
{_Geometry2D_rect2D_={_Geometry2D_point2D_=ff}{_Geometry2D_size2D_=ff}}16@0:8
v32@0:8{_Geometry2D_rect2D_={_Geometry2D_point2D_=ff}{_Geometry2D_size2D_=ff}}16
v24@0:8Q16
@"CVMLFaceRegionMap"
@"CVMLFaceLandmarks"
@"CVMLFaceprint"
{CGAffineTransform=dddddd}16@0:8
v64@0:8{CGAffineTransform=dddddd}16
@"CVMLImageRegistrationSignature"
{CGAffineTransform="a"d"b"d"c"d"d"d"tx"d"ty"d}
Q40@0:8@16Q24^@32
@"MPImageDescriptor"
v28@0:8@16f24
{CGPoint=dd}16@0:8
v32@0:8{CGPoint=dd}16
{CGPoint="x"d"y"d}
@"NSNumber"
q40@0:8@16^^{MPClusteringTreeNode}24@32
f28@0:8^{MPClusteringTreeNode=@iffi^{MPClusteringTreeNode}^{MPClusteringTreeNode}^{MPClusteringTreeNode}^{MPClusteringTreeNode}}16i24
{vector<MPClusteringTreeNode *, std::__1::allocator<MPClusteringTreeNode *> >=^^{MPClusteringTreeNode}^^{MPClusteringTreeNode}{__compressed_pair<MPClusteringTreeNode **, std::__1::allocator<MPClusteringTreeNode *> >=^^{MPClusteringTreeNode}}}40@0:8i16f20^{MPClusteringTreeNode=@iffi^{MPClusteringTreeNode}^{MPClusteringTreeNode}^{MPClusteringTreeNode}^{MPClusteringTreeNode}}24@32
{vector<MPClusteringTreeNode *, std::__1::allocator<MPClusteringTreeNode *> >=^^{MPClusteringTreeNode}^^{MPClusteringTreeNode}{__compressed_pair<MPClusteringTreeNode **, std::__1::allocator<MPClusteringTreeNode *> >=^^{MPClusteringTreeNode}}}36@0:8i16^{MPClusteringTreeNode=@iffi^{MPClusteringTreeNode}^{MPClusteringTreeNode}^{MPClusteringTreeNode}^{MPClusteringTreeNode}}20@28
{vector<MPClusteringTreeNode *, std::__1::allocator<MPClusteringTreeNode *> >=^^{MPClusteringTreeNode}^^{MPClusteringTreeNode}{__compressed_pair<MPClusteringTreeNode **, std::__1::allocator<MPClusteringTreeNode *> >=^^{MPClusteringTreeNode}}}36@0:8f16^{MPClusteringTreeNode=@iffi^{MPClusteringTreeNode}^{MPClusteringTreeNode}^{MPClusteringTreeNode}^{MPClusteringTreeNode}}20@28
{vector<MPClusteringTreeNode *, std::__1::allocator<MPClusteringTreeNode *> >=^^{MPClusteringTreeNode}^^{MPClusteringTreeNode}{__compressed_pair<MPClusteringTreeNode **, std::__1::allocator<MPClusteringTreeNode *> >=^^{MPClusteringTreeNode}}}32@0:8^{MPClusteringTreeNode=@iffi^{MPClusteringTreeNode}^{MPClusteringTreeNode}^{MPClusteringTreeNode}^{MPClusteringTreeNode}}16@24
f28@0:8f16q20
f32@0:8f16q20B28
{shared_ptr<vision::mod::LandmarkDetector>="__ptr_"^{LandmarkDetector}"__cntrl_"^{__shared_weak_count}}
^{__CVBuffer=}68@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16f48@52^@60
{shared_ptr<vision::mod::ObjectDetector_DCNFaceDetector>="__ptr_"^{ObjectDetector_DCNFaceDetector}"__cntrl_"^{__shared_weak_count}}
@"CVMLFaceBBoxAligner"
{CGPoint=dd}24@0:8Q16
@32@0:8^{CGPoint=dd}16Q24
r^{CGPoint=dd}16@0:8
v24@0:8r^{CGPoint=dd}16
r^{CGPoint=dd}
24@0:8Q16
@32@0:8^16Q24
r^16@0:8
v24@0:8r^16
^v32@0:8r^i16Q24
@84@0:8@16Q24B32{CGRect={CGPoint=dd}{CGSize=dd}}36{_Geometry2D_rect2D_={_Geometry2D_point2D_=ff}{_Geometry2D_size2D_=ff}}68
B48@0:8Q16Q24@?32^@40
@64@0:8@16@24#32{_NSRange=QQ}40^@56
@48@0:8@16@24#32^@40
B124@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24^{ImageDescriptorProcessorAbstract=^^?}56i64B68I72^{ImageDescriptorBufferAbstract=^^?{vector<long long, std::__1::allocator<long long> >=^q^q{__compressed_pair<long long *, std::__1::allocator<long long> >=^q}}{map<long long, int, std::__1::less<long long>, std::__1::allocator<std::__1::pair<const long long, int> > >={__tree<std::__1::__value_type<long long, int>, std::__1::__map_value_compare<long long, std::__1::__value_type<long long, int>, std::__1::less<long long>, true>, std::__1::allocator<std::__1::__value_type<long long, int> > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<long long, int>, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<long long, std::__1::__value_type<long long, int>, std::__1::less<long long>, true> >=Q}}}^vQQQB}76@84@92@100@108^@116
@68@0:8r^{ImageDescriptorBufferAbstract=^^?{vector<long long, std::__1::allocator<long long> >=^q^q{__compressed_pair<long long *, std::__1::allocator<long long> >=^q}}{map<long long, int, std::__1::less<long long>, std::__1::allocator<std::__1::pair<const long long, int> > >={__tree<std::__1::__value_type<long long, int>, std::__1::__map_value_compare<long long, std::__1::__value_type<long long, int>, std::__1::less<long long>, true>, std::__1::allocator<std::__1::__value_type<long long, int> > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<long long, int>, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<long long, std::__1::__value_type<long long, int>, std::__1::less<long long>, true> >=Q}}}^vQQQB}16^{ImageClassifierAbstract=^^?{vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > >=^{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >}^{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >}{__compressed_pair<std::__1::basic_string<char> *, std::__1::allocator<std::__1::basic_string<char> > >=^{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >}}}{map<std::__1::basic_string<char>, float, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, float> > >={__tree<std::__1::__value_type<std::__1::basic_string<char>, float>, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, float>, std::__1::less<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__value_type<std::__1::basic_string<char>, float> > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<std::__1::basic_string<char>, float>, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, float>, std::__1::less<std::__1::basic_string<char> >, true> >=Q}}}{vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > >=^{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >}^{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >}{__compressed_pair<std::__1::basic_string<char> *, std::__1::allocator<std::__1::basic_string<char> > >=^{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >}}}iffii}24f32@36@44@52^@60
@76@0:8r^{ImageDescriptorBufferAbstract=^^?{vector<long long, std::__1::allocator<long long> >=^q^q{__compressed_pair<long long *, std::__1::allocator<long long> >=^q}}{map<long long, int, std::__1::less<long long>, std::__1::allocator<std::__1::pair<const long long, int> > >={__tree<std::__1::__value_type<long long, int>, std::__1::__map_value_compare<long long, std::__1::__value_type<long long, int>, std::__1::less<long long>, true>, std::__1::allocator<std::__1::__value_type<long long, int> > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<long long, int>, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<long long, std::__1::__value_type<long long, int>, std::__1::less<long long>, true> >=Q}}}^vQQQB}16^{ImageClassifierAbstract=^^?{vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > >=^{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >}^{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >}{__compressed_pair<std::__1::basic_string<char> *, std::__1::allocator<std::__1::basic_string<char> > >=^{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >}}}{map<std::__1::basic_string<char>, float, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, float> > >={__tree<std::__1::__value_type<std::__1::basic_string<char>, float>, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, float>, std::__1::less<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__value_type<std::__1::basic_string<char>, float> > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<std::__1::basic_string<char>, float>, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, float>, std::__1::less<std::__1::basic_string<char> >, true> >=Q}}}{vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > >=^{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >}^{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >}{__compressed_pair<std::__1::basic_string<char> *, std::__1::allocator<std::__1::basic_string<char> > >=^{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >}}}iffii}24^{ImageClassifier_HierarchicalModel=^{ImageClassfier_Graph}}32f40@44@52@60^@68
v24@0:8q16
v24@0:8@"NSString"16
@24@0:8r^{mapped_model_file=i^vQ}16
r^{mapped_model_file=i^vQ}
{unique_ptr<cvml::util::model_file_cache, std::__1::default_delete<cvml::util::model_file_cache> >="__ptr_"{__compressed_pair<cvml::util::model_file_cache *, std::__1::default_delete<cvml::util::model_file_cache> >="__first_"^{model_file_cache}}}
{shared_ptr<DML>="__ptr_"^{DML}"__cntrl_"^{__shared_weak_count}}
@48@0:8@16@24@32^@40
@44@0:8@16f24@28^@36
B48@0:8@16@24@32^@40
f24@0:8@16
f24@0:8f16f20
@40@0:8^{__CVBuffer=}16Q24^@32
@40@0:8^{vImage_Buffer=^vQQQ}16Q24^@32
{shared_ptr<vision::mod::FaceFrontalizer>="__ptr_"^{FaceFrontalizer}"__cntrl_"^{__shared_weak_count}}
{shared_ptr<vision::mod::ImageDescriptorAugmenterFlip>="__ptr_"^{ImageDescriptorAugmenterFlip}"__cntrl_"^{__shared_weak_count}}
{shared_ptr<unsigned char>="__ptr_"*"__cntrl_"^{__shared_weak_count}}
{_Geometry2D_size2D_="height"f"width"f}
f32@0:8@16@24
B80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48
B88@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48d80
v40@0:8@16@24@32
v20@0:8i16
@32@0:8{_NSRange=QQ}16
f32@0:8Q16Q24
{shared_ptr<vision::mod::SimilarityMatrixAbstract>="__ptr_"^{SimilarityMatrixAbstract}"__cntrl_"^{__shared_weak_count}}
{shared_ptr<vision::mod::FaceboxAligner>="__ptr_"^{FaceboxAligner}"__cntrl_"^{__shared_weak_count}}
@20@0:8f16
r^{FastRegistration_Signatures=^fQ{Projections_meanStdTable=^f^f}^fQ{Projections_meanStdTable=^f^f}*}16@0:8
{FastRegistration_Signatures="piRow"^f"nPiRow"Q"piRowTable"{Projections_meanStdTable="sumTable"^f"sumSqTable"^f}"piCol"^f"nPiCol"Q"piColTable"{Projections_meanStdTable="sumTable"^f"sumSqTable"^f}"_memoryContainer"*}
{CGAffineTransform=dddddd}52@0:8@16@24@32f40^@44
q32@0:8^{vImage_Buffer=^vQQQ}16^f24
MbP?
