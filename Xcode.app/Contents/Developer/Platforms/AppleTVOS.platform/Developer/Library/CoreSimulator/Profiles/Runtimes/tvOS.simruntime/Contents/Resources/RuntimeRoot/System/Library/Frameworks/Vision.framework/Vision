:D7V
"nN%
AA)Z
>Y1\
?*Ral!
WXp?
>J6h
iQ~V?
iN^d
iN^d
N} y
?9(a
g|_\
&4I,)
|F"4
_Cp\
vj.7
ip[[
'Hlw
?VF#
uoEb
?\='
@ut\
?'/2
h?RD
"nN%
t><K
!sePmp
|zlK
c\qq
0Xr
9x&4
^Cp\
`!sePm
?aobHN
.5B?S
i3NCT
"nN%
|a2U0
%Tpx
"nN%
~NA~
lscz
AA)Z
r?jl@
<e5]O
! _B
?`vO
^Cp\F
@Y32
d:tz
N} y
?Uka
SrNl
-:Yj
tBFe@
@!"5
O7+]3n@
h8en
;a@O
?!=E
"LQ.
OVW
"nN%
0Xr
W zR&
/5B?S
|a2U0*
?EUwv
E|'f
i3NCT
1zn!
"nN%
#gaO;|
[@h=|
2uWv
 |(
?K[\
NSt3__120__shared_ptr_emplaceIN6vision3mod23ImageClassifierEspressoENS_9allocatorIS3_EEEE
N6vision3mod23ImageClassifierAbstractE
N6vision3mod29ImageDescriptorBufferAbstractE
NSt3__118basic_stringstreamIcNS_11char_traitsIcEENS_9allocatorIcEEEE
NSt3__115basic_stringbufIcNS_11char_traitsIcEENS_9allocatorIcEEEE
_333?
NSt3__120__shared_ptr_emplaceIN6vision3mod33ImageClassifier_HierarchicalModelENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_pointerIPN6vision3mod28ImageDescriptorBufferFloat32ENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIN6vision3mod28ImageDescriptorBufferFloat32EEE
NSt3__120__shared_ptr_emplaceIN6vision3mod37FaceClassifier_BoostedPixelDifferenceENS_9allocatorIS3_EEEE
N6vision3mod24SimilarityMatrixAbstractE
N6vision3mod5ERT2DIfEE
N6vision3mod16Transformation2DE
N6vision3mod23Transformation2DPrivateI19_Geometry2D_Affine_EE
N6vision3mod23Transformation2DPrivateI16_Geometry2D_RST_EE
NSt3__120__shared_ptr_pointerIPfNS_14default_deleteIA_fEENS_9allocatorIfEEEE
NSt3__114default_deleteIA_fEE
Dfff?
?N6vision3mod23Transformation2DPrivateIA9_fEE
N12_GLOBAL__N_120FaceDescriptorBufferE
NSt3__120__shared_ptr_pointerIPN6vision3mod20SimilarityMatrixFullENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIN6vision3mod20SimilarityMatrixFullEEE
NSt3__120__shared_ptr_pointerIPN6vision3mod20SimilarityMatrixLazyENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIN6vision3mod20SimilarityMatrixLazyEEE
NSt3__120__shared_ptr_pointerIPN6vision3mod24SimilarityMatrixAbstractENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIN6vision3mod24SimilarityMatrixAbstractEEE
333333
?N6vision3mod23ImageClassifierEspressoE
NSt3__120__shared_ptr_emplaceIN6vision3mod32ImageDescriptorProcessorEspressoENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN6vision3mod23ImageClassifierEspresso9private_tENS_9allocatorIS4_EEEE
N6vision3mod32ImageDescriptorProcessorAbstractE
?11ImageBlocks
N6vision3mod14FaceboxAlignerE
?xwwwww
?xwwwww
?N6vision3mod30ObjectDetector_DCNFaceDetectorE
N6vision3mod22ObjectDetectorAbstractE
NSt3__120__shared_ptr_emplaceIN8Espresso4blobIDv4_hLi2EEENS_9allocatorIS4_EEEE
N8Espresso4blobIDv4_hLi2EEE
NSt3__120__shared_ptr_emplaceIN6vision3mod30ObjectDetector_DCNFaceDetector4privENS_9allocatorIS4_EEEE



,,,,,,,
,,,,,,,,,,
""""""
,,,,,,,,,,,
""""""
,,,,,,,,,,,
"""""
,,,,,,,,,,
"""""
///////,,,,
""""
////////////
/////////////
//////////////
///////////////
/////////////////
//////////////////
///////////////////
////////////////////
/////////////////////""
////////////////////
/////////////////////
//////////////////////
///////////////////////""
000000
**



,,,,,
,,,,,,,,,
""""
,,,,,,,,,,,
""""""
,,,,,,,,,,,
"""""
,,,,,,,,,,,
"""""
//////,,,,,
""""
//////////,
/////////////
//////////////
///////////////
/////////////////
//////////////////
///////////////////
////////////////////
/////////////////////""
/////////////////////
/////////////////////
//////////////////////
///////////////////////""
00000000
0000000
0000
0000
***
**



,,,,,,,,,
,,,,,,,,,,,
"""""
,,,,,,,,,,,
"""""
,,,,,,,,,,,
"""""
////,,,,,,,
""""
/////////,,
/////////////
//////////////
///////////////
////////////////
//////////////////
///////////////////
////////////////////
/////////////////////""
//////////////////////
/////////////////////
//////////////////////
///////////////////////""
00000000
000000000
00000000
000000
00000
***.....




,,,,,,,
,,,,,,,,,,
,,,,,,,,,,,,
"""""
,,,,,,,,,,,,
"""""
,,,,,,,,,,,
"""""
////////,,,
""""
/////////////
//////////////
///////////////
////////////////
//////////////////
///////////////////
////////////////////
/////////////////////"""
//////////////////////"
/////////////////////
//////////////////////
///////////////////////""
000000000
000000000
0000000000
000000000
0000000
.....
.....

....



,,,,
,,,,,,,,,,
,,,,,,,,,,,,
,,,,,,,,,,,,,
"""""
,,,,,,,,,,,,
"""""
//////,,,,,,
""""
////////////
//////////////
///////////////
""""
////////////////
""""
/////////////////
///////////////////
////////////////////
/////////////////////"""
//////////////////////""
///////////////////////
//////////////////////
///////////////////////""
$$$$00000
$$0000000
0000000000
00000000000
0000000000
00000..
.....
.........
.....

.....


,,,,,,,
,,,,,,,,,,,
,,,,,,,,,,,,
""""
,,,,,,,,,,,,,,
"""""
,,,,,,,,,,,,,
"""""
/////////,,,,
""""
//////////////
///////////////
""""
////////////////
"""""
/////////////////
""""
///////////////////
////////////////////
/////////////////////"""
//////////////////////"""
///////////////////////""
////////////////////////
///////////////////////""
$$$$$$00
$$$$$0000
$$$$$00000
$$$$$$00000
$$$$$000000
$$0000000..
$$$....
...........
.........
......

....


,,,,,,
,,,,,,,,,,
,,,,,,,,,,,,
,,,,,,,,,,,,,
""""
,,,,,,,,,,,,,,,
"""""
//////,,,,,,,,
"""""
//////////////
""""
///////////////
////////////////
""""
/////////////////
"""""
//////////////////
""""
////////////////////
/////////////////////
//////////////////////"""
///////////////////////"""
////////////////////////""
////////////////////////""
111$$
$$$$$$
$$$$$$000
$$$$$$$0000
$$$$$$$$0000
$$$$$$$$$$00
$$$$$$$$$$..
.....$$.....
............
.........
......

...&&

,,,,,
,,,,,,,,
,,,,,,,,,,,,
,,,,,,,,,,,,,
,,,,,,,,,,,,,,,((((""""
,,,,,,,,,,,,,,,,((("""""
/////////,,,,,,
"""""
///////////////
""""
////////////////
""""
/////////////////
"""""
//////////////////
"""""
///////////////////
/////////////////////
//////////////////////"""
///////////////////////"""
////////////////////////""
/////////////////////////"
111111
11111$$
$$$$$$
$$$$$$$$00
$$$$$$$$0000
$$$$$$$$$$000
$$$$$$$$$$$0
$$$$$$$$$$$))
......$$.)))))
...........)))
.........
.....&&

...&&&
,,,,,,,
,,,,,,,,,,,
,,,,,,,,,,,,,
,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,((((("""
///////,,,,,,,,,(((("""""
////////////,,,
"""""
////////////////
""""
/////////////////
""""
//////////////////
"""""
///////////////////
"""""
////////////////////
""""
//////////////////////
///////////////////////"""
////////////////////////"""
/////////////////////////""
1111111
1111111
1111$$
$$$$$
$$$$$$$$$
$$$$$$$$$$
$$$$$$$$$$$000
$$$$$$$$$$$$)
$$$$$$$$$)))))
......)))))))))
...........))))
........&&&
......&&&&

   ...&&&
,,,,,
,,,,,,,,
,,,,,,,,,,,,
,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,(((((
,,,,,,,,,,,,,,,,(((((("""
//////////,,,,,,,(((("""""
////////////////
"""""
/////////////////
""""
//////////////////
""""
///////////////////
"""""
////////////////////
"""""
//////////////////////
///////////////////////
////////////////////////"""
/////////////////////////"""
111111111
11111111
11111111
111$
$$$$
$$$$$$$$$
$$$$$$$$$$
$$$$$$$$$$$$
$$$$$$$$$$$)))
$$$$$$)))))))))
...)))))))))))))
...........)))))&&
.......)&&&&&
  ......&&&&
   ..&&&&
    
,,,,,,,
,,,,,,,,
,,,,,,,,,,,,,
,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,((((((
////,,,,,,,,,,,,,(((((("""
////////////,,,,(((((("""""
/////////////////
""""
//////////////////
///////////////////
""""
////////////////////
"""""
/////////////////////
"""""
///////////////////////
////////////////////////
/////////////////////////"""
11111111
111111111
111111111
1111111
$$$$
$$$$$$$$$$
$$$$$$$$$$$
$$$$$$$$$$$$)
$$$$$$$$$$)))))
))))))))))))
...)))))))))))))))
......)...)))))))&&
   .....)))&&&&&
       ...&&&&&
      &&&&&
       
&&&&
,,,,,
    
,,,,,,,
,,,,,,,,,
,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,((((((
/////////,,,,,,,(((((((("""
////////////////((((((((""""
//////////////////(
""""
///////////////////
////////////////////
""""
/////////////////////
"""""
//////////////////////
""""
////////////////////////
/////////////////////////
''''''''
11111111
111111111
111111111
111111
$$$$
$$$$$$$$$$$
$$$$$$$$$$$$
$$$$$$))
)))))))
))))))))))))
...))))))))))))))))
))))))))).))))))))&&
        ...))))&&&&&
         &&&&&&&
         &&&&&&&
       
&&&&&&
,,,,,,
    
&&&&&
,,,,,,,,
&&&&
,,,,,,,,,,
,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,((((((
/,,,,,,,,,,,,,,,((((((((
////////////////((((((((((
/////////////////(((((((("""
///////////////////((
////////////////////
/////////////////////
""""
//////////////////////
""""
///////////////////////
////////////////////////
'''''''''
'''''''''
111111111
111111111
111111111
1111
$$$$
$$$$$$$$$$$$
$$$$$$
$$$)))
)))))))
))))))))))))
))))))))))))))))))))
)))))))))))))))))))&&
          ..)))))&&&&&
          )&&&&&&&&
            &&&&&&&&&
,,,,
        &&&&&&&
,,,,,,,
     &&&&&&&
,,,,,,,,,
   &
&&&&
,,,,,,,,,,,
,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,(((((((((
///////////////((((((((((
/////////////////((((((((((
//////////////////((((((((""
////////////////////((
/////////////////////
//////////////////////
""""
///////////////////////
////////////////////////
'''''''''
'''''''''
'''''''''
1111111''
11111111'
111111
$$$$
$$$$
$$$$$
$))))
)))))))
))))))))))))
)))))))))))))))))))))
  ))))))))))))))))))&&
           )))))))&&&&&
             )))&&&&&&&&&
            &&&&&&&&&
,,,,,
        &&&&&&&&
,,,,,,,,
     &&&&&&&
,,,,,,,,,,
   &&&&&&
,,,,,,,,,,,,
,,,,,,,,,,,,,,((((((((((
/////////,,,,,,((((((((((
////////////////((((((((((
//////////////////((((((((((
///////////////////((((((((""
/////////////////////(((
""""
//////////////////////
""""
///////////////////////
""""
////////////////////////
""""
''''''''''
''''''''''
'''''''''
'''''''''
111111''''
11111111'
11111
$$$$
$$$$
$)))
))))
)))))))
))))))))))))
))))))))))))))))))))))
    )))))))))))))))))&&
           ))))))))&&&&&&
              )))&&&&&&&&&
              &&&&&&&&&
,,,,,,,
       &&&&&&&&&
,,,,,,,,,
      &&&&&&&
,,,,,,,,,,,
    &&&&&&
,,,,,,,,,,,,,
(((((((((
,,////,,,,,,,,(((((((((((
///////////////(((((((((((
/////////////////((((((((((
///////////////////((((((((((
////////////////////((((((((""
/////////////////////((((((""""
///////////////////////
"""""////////////////////////
"""""'''''''''''
'''''''''''
''''''''''
''''''''''
''''''''''
111111'''''
1111111111
)))))))
))))))))))))
)))))))))))))))))))))))
     )))))))))))))))))&&
            ))))))))&&&&&&
               )))&&&&&&&&&
                   &&&&&&&&&
,,,,,,,,
       &&&&&&&&&
,,,,,,,,,,,
       &&&&&&&
,,,,,,,,,,,,,
((((((   &&&&&&
,,,,,,,,,,,,,,((((((((((
//////////,,,,,(((((((((((
////////////////(((((((((((
//////////////////((((((((((
///////////////////(((((((((((
/////////////////////((((((((""
//////////////////////((((("""""////////////////////////
"""""''''''''''''
''''''''''''
''''''''''''
'''''''''''
''''''''''
111'''''''
11111111'''
11111111111
)))))))
))))))))))))
  ))))))))))))))))))))))
       )))))))))))))))))&
             ))))))))&&&&&&
                )))&&&&&&&&&
                   &&&&&&&&&&&
   ,,,,,, 
       &&&&&&&&&&
,,,,,,,,,,,,
(((      &&&&&&&&
,,,,,,,,,,,,,((((((((   &&&&&&&
,,,,,,,,,,,,,,,((((((((((
&&&////////////,,,,(((((((((((
/////////////////(((((((((((
///////////////////((((((((((
////////////////////(((((((((((
/////////////////////((((((((("///////////////////////(((((""""--'''''''''''
'''''''''''''
'''''''''''''
''''''''''''
''''''''''''
'''''''''''
111111'''''
1111111111
111111
++++
++++
))))))
))))))))))))
    )))))))))))))))))))))
        ))))))))))))))))&&&
              )))))))&&&&&&&
                 ))&&&&&&&&&&
                   &&&&&&&&&&&&
,,,,,,,,,,  
(      &&&&&&&&&&&
,,,,,,,,,,,,,(((((     &&&&&&&&
,,,,,,,,,,,,,,((((((((   &&&&&&&////////,,,,,,,(((((((((((
&&/////////////////(((((((((((
///////////////////((((((((((
////////////////////((((((((((
/////////////////////(((((((((((
//////////////////(((((((((------'''''''
-----''''''''
---''''''''''
'''''''''''''
'''''''''''''
'''''''''''''
1'''''''''''
11111111'''
11111111111
1111
+++++
++++
)))))
))))))))))))
      ))))))))))))))))))))
         )))))))))))))))&&&&
               )))))))&&&&&&&
                  
&&&&&&&&&&
                   &&&&&&&&&&&&&,,,,,,,,,,,((((     &&&&&&&&&&&&,,,,,,,,,,,,,((((((      &&&&&&&,,,,,,,,,,,,,,(((((((((   &&&&&&////////////,,,((((((((((((
&//////////////////(((((((((((
(((((((////////////(((((((((((
(((((((//////////////((((((((((
///////////////////((((((((((--------'''''
-------''''''
------'''''''
----'''''''''
'''''''''''''
'''''''''''''
''''''''''''''
11111''''''''
1111111111
111111111111
1111
++++
+++++
++++
))))
)))))))))))
!!     ))))))))))))))))))
          ))))))))))))
                ))
&&&&&&
                  
&&&&&&&&&&&(((((((((           &&&&&&&&&&&&((((((((((((((((      &&&&&&&&&&,,,,,,,,,,,,,((((((       &&&&&&,,,,,,,,,,,,,,((((((((((   &&&&&((((((///////////(((((((((((
(((((((////////////(((((((((((
(((((((((///////////(((((((((((
(((((((((/////////////((((((((((----------'''
---------''''
---------'''''
--------''''''
------''''''''
'''''''''''''
''''''''''''''
''''''''''''''
1111111''''''
11111111111
1111111111111
####1111
###++
++++
++++
++++
))))
!!!!
)))))))))))
!!!!!   )))))))))))))
           ))))))
                 
&&&&
                   
&&&&((((((((((((         
&&&&(((((((((((((((((     
&&&&&&((((((((((((((((((((       &&&&&(((((((((((((((((((((((((  &&&&&!!((((((((((//////(((((((((((&
((((((((((//////////(((((((((((
(((((((((((//////////(((((((((((-------------
------------'
-----------'''
----------''''
---------'''''
-------'''''''
''''''''''''''
''''''''''''''
1111''''''''''
111111111''''
1111111111111
########111111
############111
##++
++++
++++
++++
!!!!!!
)))))))
!!!!!!!!!!)))))))
!!!!!!!!!!!!
!!!!!!!!!!       
&&&!(((((((((         
&&(((((((((((((        
&&((((((((((((((((((     
&&&&(((((((((((((((((((((      &&&&&!!((((((((((((((((((((((((&&&&&&!!!!!(((((((((/////(((((((((&&&
(((((((((((//////////(((((((((((--------------
--------------
-------------
-------------
-----------'''
----------'''''
-------''''''''
'''''''''''''''
''''''''''''''
1111111'''''''
11111111111'''
11111111111111
###########11111
########111
#+++
++++
++++
++++
!!!!
!!!!!!!!!
!!!!!!!!!!!!
!!!!!!!!!!!!!
&&!!!!!!!!!!!!!!   
&&!!!!!((((((        
&((((((((((((((       
&!!!!(((((((((((((((    
&&&!!!!!(((((((((((((((((  
&&&&&!!!!!((((((((((((((((((((((&&&&&!!!!!!!(((((((((///((((((((((&&&---------------
---------------
---------------
--------------
--------------
------------'''
-----------'''''
-------'''''''''
'''''''''''''''
11''''''''''''
111111111''''''
111111111111'''
#########111111
############11111
######11
++++
+++++
++++
++++
!!!!!!!!
!!!!!!!!!!!!!!
!!!!!!!!!!!!!
!!!!!!!!!!!!!!
!!!!!!!!!!!!!!! 
!!!!!!!!(((!      
!!!!!!(((((((((     
!!!!!!!!(((((((((((    
&&!!!!!!!!(((((((((((((  
&&&&!!!!!!!(((((((((((((((((((((&&&&--------------''
---------------'
---------------
---------------
---------------
---------------
------------''''
-----------''''''
'''''''''''''''''
'''''''''''''''
111111'''''''''
1111111111'''''
######11111111
##########111111
#############11111
######1
++++
+++++
+++++
++++
!!!!!
!!!!!!!!!!!!!!
!!!!!!!!!!!!!!!
!!!!!!!!!!!!!!
!!!!!!!!!!!!!!!
!!!!!!!!!!!!!!!!
!!!!!!!!!!(!!!    
!!!!!!!!!((((((     
!!!!!!!!!!!((((((((   
&!!!!!!!!!(((((((((((   
&&&&---------------''
---------------''
---------------''
---------------'
----------------
----------------
--------------''
------------'''''
----------''''''''
'''''''''''''''''
''''''''''''''''
11111111'''''''
111111111111'''
########1111111
############11111
###############1111
#####
++++
+++++
+++++
++++
!!!!!!!!!!!
!!!!!!!!!!!!!!!
!!!!!!!!!!!!!!!!
!!!!!!!!!!!!!!!
!!!!!!!!!!!!!!!!
!!!!!!!!!!!!!!!!!
!!!!!!!!!!!!!!!   
!!!!!!!!!!!!((((   
!!!!!!!!!!!!!!(((((   
----------------'
----------------''
----------------''
----------------'
----------------'
---------------''
---------------''
-------------''''
-----------'''''''
''''''''''''''''''
''''''''''''''''''
11111''''''''''''
1111111111''''''
#####111111111
##########111111
#############11111
################11
#####
++++
++++
+++++
!!!!!!!!
!!!!!!!!!!!!!
!!!!!!!!!!!!!!!!
!!!!!!!!!!!!!!!!!
!!!!!!!!!!!!!!!!
!!!!!!!!!!!!!!!!!
!!!!!!!!!!!!!!!!!!
!!!!!!!!!!!!!!!!! 
!!!!!!!!!!!!!!!!!
------------------
------------------
-----------------
-----------------
-----------------
----------------''
---------------'''
--------------''''
------------''''''
---------'''''''''
''''''''''''''''''
''''''''''''''''''
11111111'''''''''
111111111111''''
########1111111
############11111
###############1111
#################
#####
++++
+++++
+++++
!!!!!!!!!!!!
!!!!!!!!!!!!!!!
%%%%%
!!!!!!!!!!!!!!!!!%%%%%%%
!!!!!!!!!!!!!!!!!!
!!!!!!!!!!!!!!!!!
!!!!!!!!!!!!!!!!!!
!!!!!!!!!!!!!!!!!!!
!!!!!!!!!!!!!!!!!!
-------------------
-------------------
-------------------
------------------
------------------
-----------------
-----------------'
---------------''''
-------------''''''
-----------''''''''
-------''''''''''''
''''''''''''''''''
111''''''''''''''''
1111111111''''''''
###11111111111''
##########111111
#############11111
################11
##################
###+
++++
+++++
+++++
!!!!!!!!!!!!!
!!!!!!!!!!!!!!!!
%%%%%%%%%
!!!!!!!!!!!!!!!!!!%%%%%%%%%
!!!!!!!!!!!!!!!!!!!%%%%%%
!!!!!!!!!!!!!!!!!!
%%%%
!!!!!!!!!!!!!!!!!!!%%%%
!!!!!!!!!!!!!!!!!!!!
---------------------
--------------------
--------------------
--------------------
-------------------
-------------------
------------------
-----------------'
---------------''''
-------------''''''
-----------''''''''
------'''''''''''''
'''''''''''''''''''
1111111''''''''''''
11111111111'''''''
#######111111111
###########111111
##############111111
##################
###################
#+++
+++++
++++
+++++
!!!!
!!!!!!!!!!!!!!
%%%%%%
!!!!!!!!!!!!!!!!!
%%%%%%%%%%%%%%!!!!!!!!!!!!!!!!!!!%%%%%%%%%%%%%!!!!!!!!!!!!!!!!!!!%%%%%%%%%%%%%!!!!!!!!!!!!!!!!!!!%%%%%%%%%%%%
!!!!!!!!!!!!!!!!!!!!%%%%%%%
----------------------
----------------------
---------------------
---------------------
---------------------
--------------------
--------------------
-------------------
------------------
----------------'''
--------------'''''
-----------''''''''
-------''''''''''''
11'''''''''''''''''
111111111''''''''''
1111111111111'''''
#########11111111
#############111111
################1111
###################
####################
++++
++++
++++
+++++
!!!!!!!
!!!!!!!!!!!!!!!!
%%%%%%%%%%!!!!!!!!!!!!!!!!!!%%%%%%%%%%%%%%!!!!!!!!!!!!!!!!!!!%%%%%%%%%%%%%!!!!!!!!!!!!!!!!!!%%%%%%%%%%%%%%!!!!!!!!!!!!!!!!!!!%%%%%%%%%%%%%
NSt3__120__shared_ptr_emplaceIN6vision3mod29ImageDescriptor_EspressoSceneENS_9allocatorIS3_EEEE
N6vision3mod29ImageDescriptor_EspressoSceneE
NSt3__120__shared_ptr_pointerIPN6vision3mod21ObjectTrackerAbstractENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIN6vision3mod21ObjectTrackerAbstractEEE
+>>%I
>X|E
6>%I
~|zxvuusqpnmkjiggfecba`_^]]\[ZYXWVUTTSRQQPONNMMLKKJIIHGGGFFEDDCCBBBAA@@??>>===<<;;:::999888776666555444333322211110000////.....----,,,,+++++*****)))))((((('''''''&&&&&&%%%%%%$$$$$$$########""""""!!!!!!!!!        
333333
?ff&?
NSt3__120__shared_ptr_emplaceIN6vision3mod28ImageDescriptor_EspressoFaceENS_9allocatorIS3_EEEE
N6vision3mod28ImageDescriptor_EspressoFaceE
NSt3__120__shared_ptr_emplaceIN6vision3mod28ImageDescriptor_EspressoJunkENS_9allocatorIS3_EEEE
N6vision3mod28ImageDescriptor_EspressoJunkE
NSt3__120__shared_ptr_pointerIPKhZN4cvml4util31binserialized_table_of_contents9blob_infoC1ES2_RK26_BinSerializer_blobHeader_EUlS2_E_NS_9allocatorIS1_EEEE
ZN4cvml4util31binserialized_table_of_contents9blob_infoC1EPKhRK26_BinSerializer_blobHeader_EUlS4_E_
NSt3__120__shared_ptr_pointerIPN6vision3mod18LandmarkAttributesENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIN6vision3mod18LandmarkAttributesEEE
f024800L
L>_p
Mb`?
?ffffff
?N6vision3mod24NNHierarchicalClusteringE
NSt3__114basic_ofstreamIcNS_11char_traitsIcEEEE
NSt3__113basic_filebufIcNS_11char_traitsIcEEEE
NSt3__114basic_ifstreamIcNS_11char_traitsIcEEEE
N6vision3mod28ImageDescriptorBufferFloat32E
NSt3__120__shared_ptr_pointerIPN6vision3mod29ImageDescriptorBufferAbstractENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIN6vision3mod29ImageDescriptorBufferAbstractEEE
NSt3__120__shared_ptr_emplaceIN6vision3mod28ImageDescriptorBufferFloat32ENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_pointerIP6LCKSVDNS_14default_deleteIS1_EENS_9allocatorIS1_EEEE
NSt3__114default_deleteI6LCKSVDEE
NSt3__120__shared_ptr_emplaceIiNS_9allocatorIiEEEE
NSt3__120__shared_ptr_emplaceIfNS_9allocatorIfEEEE
NSt3__120__shared_ptr_pointerIPjNS_14default_deleteIA_jEENS_9allocatorIjEEEE
NSt3__114default_deleteIA_jEE
NSt3__110__function6__funcIZN6vision3mod14broadcastMinusIfLm16EEEvRKNS3_10CVMLMatrixIT_XT0_EEERKNS3_10CVMLVectorIS6_XT0_EEEiRS7_bEUlffE_NS_9allocatorISF_EEFfffEEE
NSt3__110__function6__baseIFfffEEE
ZN6vision3mod14broadcastMinusIfLm16EEEvRKNS0_10CVMLMatrixIT_XT0_EEERKNS0_10CVMLVectorIS3_XT0_EEEiRS4_bEUlffE_
NSt3__117bad_function_callE
NSt3__110__function6__funcIZN6vision3mod12broadcastAddIfLm16EEEvRKNS3_10CVMLMatrixIT_XT0_EEERKNS3_10CVMLVectorIS6_XT0_EEEiRS7_bEUlffE_NS_9allocatorISF_EEFfffEEE
ZN6vision3mod12broadcastAddIfLm16EEEvRKNS0_10CVMLMatrixIT_XT0_EEERKNS0_10CVMLVectorIS3_XT0_EEEiRS4_bEUlffE_
NSt3__110__function6__funcIZN6vision3mod14broadcastMinusIdLm16EEEvRKNS3_10CVMLMatrixIT_XT0_EEERKNS3_10CVMLVectorIS6_XT0_EEEiRS7_bEUlddE_NS_9allocatorISF_EEFdddEEE
NSt3__110__function6__baseIFdddEEE
ZN6vision3mod14broadcastMinusIdLm16EEEvRKNS0_10CVMLMatrixIT_XT0_EEERKNS0_10CVMLVectorIS3_XT0_EEEiRS4_bEUlddE_
NSt3__110__function6__funcIZN6vision3mod12broadcastAddIdLm16EEEvRKNS3_10CVMLMatrixIT_XT0_EEERKNS3_10CVMLVectorIS6_XT0_EEEiRS7_bEUlddE_NS_9allocatorISF_EEFdddEEE
ZN6vision3mod12broadcastAddIdLm16EEEvRKNS0_10CVMLMatrixIT_XT0_EEERKNS0_10CVMLVectorIS3_XT0_EEEiRS4_bEUlddE_
NSt3__111__end_stateIcEE
NSt3__16__nodeIcEE
NSt3__120__shared_ptr_pointerIPNS_13__empty_stateIcEENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteINS_13__empty_stateIcEEEE
NSt3__113__empty_stateIcEE
NSt3__116__owns_one_stateIcEE
NSt3__115__has_one_stateIcEE
NSt3__110__l_anchorIcEE
NSt3__110__r_anchorIcEE
NSt3__115__word_boundaryIcNS_12regex_traitsIcEEEE
NSt3__111__lookaheadIcNS_12regex_traitsIcEEEE
NSt3__123__match_any_but_newlineIcEE
NSt3__118__match_char_icaseIcNS_12regex_traitsIcEEEE
NSt3__120__match_char_collateIcNS_12regex_traitsIcEEEE
NSt3__112__match_charIcEE
NSt3__116__back_ref_icaseIcNS_12regex_traitsIcEEEE
NSt3__118__back_ref_collateIcNS_12regex_traitsIcEEEE
NSt3__110__back_refIcEE
NSt3__120__bracket_expressionIcNS_12regex_traitsIcEEEE
NSt3__128__begin_marked_subexpressionIcEE
NSt3__126__end_marked_subexpressionIcEE
NSt3__16__loopIcEE
NSt3__117__owns_two_statesIcEE
NSt3__117__repeat_one_loopIcEE
NSt3__111__alternateIcEE
NSt3__121__empty_non_own_stateIcEE
NSt3__111__match_anyIcEE
6SCDict
14PerThreadLearn
9SCDictOMP
9SCDictFSS
12PackedCoeffs
?9SDFWriter
9SDFHeader
9SDFReader
N6vision3mod16LandmarkDetectorE
N6vision3mod32ImageDescriptorProcessorEspressoE
NSt3__120__shared_ptr_pointerIPfNS_14default_deleteIfEENS_9allocatorIfEEEE
NSt3__114default_deleteIfEE
NSt3__120__shared_ptr_emplaceIN6vision3mod32ImageDescriptorProcessorEspresso9private_tENS_9allocatorIS4_EEEE
NSt3__120__shared_ptr_emplaceIN8Espresso22dropout_augment_lowmemENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_pointerIPN6vision3mod13FaceRegionMapENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIN6vision3mod13FaceRegionMapEEE
@10SCDictKSVD
N6vision3mod20SimilarityMatrixFullE
N6vision3mod24ObjectTrackerCorrelationE
N6vision3mod18ClusteringAbstractE
yA$H
ITCA
vA,2
q@,2
5mAv<
9Bh6
8N6vision3mod29ColorImageDescriptorProcessorE
N6vision3mod26ColorImageDescriptorBufferE
NSt3__120__shared_ptr_emplaceIN6vision3mod26ColorImageDescriptorBufferENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN6vision3mod22ImageClassifierGlimmerENS_9allocatorIS3_EEEE
p}?33S?
?ffffff
N6vision3mod31ImageDescriptorProcessorGlimmerE
NSt3__120__shared_ptr_emplaceIN6vision3mod31ImageDescriptorProcessorGlimmer9private_tENS_9allocatorIS4_EEEE
Ga=33
N6vision3mod31ColorGaborImageDescriptorBufferE
N6vision3mod34ColorGaborImageDescriptorProcessorE
NSt3__120__shared_ptr_emplaceIN6vision3mod31ColorGaborImageDescriptorBufferENS_9allocatorIS3_EEEE
?2w-!
?O#-
?o/i
?`vO
?+0du
_{fI
tYLl>
?A+0du
++MJ
?S?o*Ra
?G=D
? <
?S\U
|a2U
?G8-x
??5^
?o*Ral!
tYLl
?gDio
?h?RD
?|DL
?pB!
FZ*o
?@M-[
#bJ$Q
?p%;6
FZ*oG
?+5{
?%]3
_{fI
?`vO
h"lx
?%]3
?U0*
?pB!
?Mg'
?a2U0*
o%;6
?,+MJA
?Ral!
?o*Ral!
?8J^
?Dio
?:#J{
?q $
$#ga
?{Ic
?scz
?o*Ral!
?U0*
?S?o*Ra
?Dio
8b->
?o/i
R?o*
?G8-x
?G8-x
?2ZGU
?Z*oG8-
?MJA
R?o*R
?`vO
_{fI
FZ*o
$#gaO
?{fI
?N6vision3mod12_GLOBAL__N_119BoxAlignerExceptionE
N6vision3mod20ObjectTrackerOptionsE
N6vision3mod21ObjectTrackerAbstractE
NSt3__120__shared_ptr_pointerIPN6vision3mod20ObjectTrackerOptionsENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIN6vision3mod20ObjectTrackerOptionsEEE
NSt3__120__shared_ptr_pointerIPN6vision3mod16LandmarkDetectorENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIN6vision3mod16LandmarkDetectorEEE
@@NSt3__120__shared_ptr_pointerIPN6vision3mod30ObjectDetector_DCNFaceDetectorENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIN6vision3mod30ObjectDetector_DCNFaceDetectorEEE
N6vision3mod27BoundingBoxDescriptorBufferE
W[q>
N6vision3mod28ImageDescriptorAugmenterFlipE
N6vision3mod32ImageDescriptorAugmenterAbstractE
9PerThread
10ThreadPool
N6vision3mod22ImageClassifierGlimmerE
NSt3__120__shared_ptr_emplaceIN6vision3mod22ImageClassifierGlimmer9private_tENS_9allocatorIS4_EEEE
NSt3__120__shared_ptr_emplaceIN6vision3mod31ImageDescriptorProcessorGlimmerENS_9allocatorIS3_EEEE
.eB!
NSt3__120__shared_ptr_pointerIPN6vision3mod11FaceIDModelENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIN6vision3mod11FaceIDModelEEE
NSt3__120__shared_ptr_pointerIPN4cvml4util20MMapFileBackingStoreENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIN4cvml4util20MMapFileBackingStoreEEE
NSt3__120__shared_ptr_pointerIPN6vision3mod15FaceFrontalizerENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIN6vision3mod15FaceFrontalizerEEE
NSt3__120__shared_ptr_pointerIPhNS_14default_deleteIA_hEENS_9allocatorIhEEEE
NSt3__114default_deleteIA_hEE
NSt3__120__shared_ptr_pointerIPN6vision3mod28ImageDescriptorAugmenterFlipENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIN6vision3mod28ImageDescriptorAugmenterFlipEEE
=33s?
B33XB
 BmQv9
333333
zd?333333
>UUUUUU
q=J?\
~|zxvuusqpnmkjiggfecba`_^]]\[ZYXWVUTTSRQQPONNMMLKKJIIHGGGFFEDDCCBBBAA@@??>>===<<;;:::999888776666555444333322211110000////.....----,,,,+++++*****)))))((((('''''''&&&&&&%%%%%%$$$$$$$########""""""!!!!!!!!!        N6vision3mod15ObjectTrackerExE
>N6vision3mod13CVMLCancellerE
5?ff
?333333
N6vision3mod20GreedyClustererFacesE
N6vision3mod14FaceClusteringE
N6vision3mod15GreedyClustererE
NSt3__120__shared_ptr_pointerIPN4cvml4util12BackedBufferINS2_15RAMBackingStoreEEENS_14default_deleteIS5_EENS_9allocatorIS5_EEEE
NSt3__114default_deleteIN4cvml4util12BackedBufferINS2_15RAMBackingStoreEEEEE
NSt3__120__shared_ptr_pointerIPN4cvml4util15RAMBackingStoreENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIN4cvml4util15RAMBackingStoreEEE
NSt3__120__shared_ptr_pointerIPKN4cvml4util12BackedBufferINS2_15RAMBackingStoreEEENS_14default_deleteIS6_EENS_9allocatorIS6_EEEE
NSt3__114default_deleteIKN4cvml4util12BackedBufferINS2_15RAMBackingStoreEEEEE
NSt3__120__shared_ptr_emplaceINS_6vectorIhNS_9allocatorIhEEEENS2_IS4_EEEE
NSt3__120__shared_ptr_emplaceIN6vision3mod20GreedyClustererFacesENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN6vision3mod15GreedyClusterer9private_tENS_9allocatorIS4_EEEE
NSt3__120__shared_ptr_emplaceINS_6vectorImNS_9allocatorImEEEENS2_IS4_EEEE
NSt3__120__shared_ptr_emplaceINS_6vectorINS_4pairImmEENS_9allocatorIS3_EEEENS4_IS6_EEEE
17VNNSDataStreambuf
24VNNSMutableDataStreambuf
?333?
&:/1
mVA=
\L;&
*RY;4|
KdC<
+/l?
rTD?
9FI?
W@+/l?
,A?P
?+/l?
+/l?@
q@4J?
9Q>`^
w=?k+K
F?]"!@R
?bD&>xzr?
uw?-
Fs?)
'I^?`
l?6a
>xq%
$@t=
;?`1S>
>M;{?
?;+n?
{f=~C
G]Z?
_=E3
wi@^ 
?k+H
7kV@
333?
?33s?
NSt3__120__shared_ptr_pointerIPfZN6vision3mod28readBinSerializedModelValuesEP7__sFILEPKcRKNS3_26BinSerializedModelFileInfoEbRNS3_11ModelValuesEE3$_0NS_9allocatorIfEEEE
ZN6vision3mod28readBinSerializedModelValuesEP7__sFILEPKcRKNS0_26BinSerializedModelFileInfoEbRNS0_11ModelValuesEE3$_0
NSt3__120__shared_ptr_pointerIPhZN6vision3mod28readBinSerializedModelValuesEP7__sFILEPKcRKNS3_26BinSerializedModelFileInfoEbRNS3_11ModelValuesEE3$_1NS_9allocatorIhEEEE
ZN6vision3mod28readBinSerializedModelValuesEP7__sFILEPKcRKNS0_26BinSerializedModelFileInfoEbRNS0_11ModelValuesEE3$_1
333333
Q9RI
Q9RI
7:RI
Q9RI
d*;4
>;_)K;
DX;B`e;
{r;l
k;B`e;
Q;_)K;
#;RI
7:RI
Q9RI
d*;4
7;_)K;
DX;B`e;
{r;o
{r;B`e;
DX;_)K;4
d*;RI
7:RI
Q9RI
7;_)K;
y;KY
3"<U
-<X94<
b<B`e<
4o<E
{r<!
ew<l
{r<E
h<B`e<e
#9<X94<
3"<RI
^;_)K;4
7:RI
Q9RI
k;KY
Q:RI
Q9RI
k:RI
DX;$
d*<4
?F<4
DX;4
Q:RI
>;B`e;'
#<X94<
z<KY
$=yX(=V
7=5^:=[
2D=]mE=
?F=]mE=
2D=\
<=5^:=
-2=2
+=yX(=
D<X94<
;B`e;
>;RI
{r<&
=R' =T
b=B`e=B>h=h
4o= Aq=
{r=F
{r= Aq=
(m=h
j=B>h=B`e=e
WJ=9
E6=|
%=R' =Qk
k:RI
7;B`e;
?$=V
b=B>h=D
s=Gry=
\~=n
\~=Gry=F
m=B>h=e
?$=v
;B`e;4
DX;'
3"<4
=R' =U
(=W[1=Z
B=_)K=a
S=d]\=
d=d]\=a
S=_)K=\
9=W[1=U
(=R' =P
j<<b
ew=I
{r<b
j<<>
ew<M
ew<>
=yX(=
A=;pN=
h=k+v=n
=k+v=
[=;pN=
5=yX(=
ew<b
7:RI
{r<M
7x=J{
/>:#
O/<N
=yX(=Y
U=B`e=
9#>/
$>0L&>
d*>1
'>0L&>/
Yu=B`e=
?F=Y
7=yX(=u
7;KY
=z6+=
/;=:
K=d]\=D
m=I.
V,>i
9>lx:>
<>6<=>
=>6<=>
;>lx:>l
u1>i
V,>
m=d]\=:
/;=z6+=
;_)K;
{r<)\
q,=6<==
Ga=F
s=J{
u >/
!N>`vO>
|P>`vO>
2D>7
~;>~
N=6<==
;_)K;o
<X94<
=z6+=6<==
ew=o
G!>ff&>
+>io0>F%5>
9>[B>>%uB>
qJ>_
QZ>?
+e>x
F>%uB>[B>>
9>F%5>io0>
+>ff&>
P=6<==z6+=u
/]<X94<r
Q9RI
{r<N
=yX(=
x=p_
/>aT
X>RI]>
Ga>f
n>W[q>}
=y>lxz>Zd{>
|>HP|>HP|>
|>Zd{>lxz>
s>W[q>
rh>f
Ga>RI]>P
/>o
/;=yX(=
y;RI
d*;KY
d*<b
ew=p_
2>Gr9>[
sW>v
8g>1
|>n4
3b>v
?>Gr9>
%>d;
Ga=:
d*<o
?F=d]\=F
8V>?
c>gDi>
t>5^z>$
>5^z>
4o>gDi>
s=d]\=
<;p
:_)K;RI
=yX(=
m=J{
P>>yX>
_>>yX>
kI>n
v>=yX(=
;_)K;
T<KY
L=B`e=I.
..>}
6>I.?>
h>iop>~
x>iop>
DX>r
G>I.?>}
c>]
=B`e=
;B`e;X9
c<)\
>B>(>W[1>lx:>
C>lx:>W[1>B>(>-!
;B`e;o
5=;pN=
>R' >z
!=>]
|P>]
g3>z
)>R' >b
xi=;pN=
{r;'
>R' >
m4>m
ZS>-
-r>HP|>
>HP|>
J*>R' >
?F<N
h=J{
H?>:#J>+
U>:#J>
m4>z
)>-!
=R' =
sW=k+v=(
>B>(>
g3>m
>>:#J>=
U>w-a>
l>w-a>=
U>:#J>m
g3>B>(>
=k+v=
:=R' =
#<B`
d*;u
Sc=n
%>W[1>
U>w-a>
\m>~
\m>w-a>+
!=>W[1>
Jj<1
d*;RI
=W[1=
..>lx:>]
ZS>]
F>lx:>
AO=W[1=
5<HP
7;RI
|P>-
:_)K;|
?$=\
Sc=o
/>>y
2>I.?>_
6Z>_
L>I.?>
%>>y
/>n4
Sc=\
;_)K;4
+=_)K=
(m=p
q,>#
q?_
q?h
q,>d;
(m=_)K=V
ew=r
\m>HP|>
c?r
>HP|>
%>>y
ew=a
2=tF
:B`e;
9=d]\=I
=d]\=Z
9=Qk
u`<RI
;B`e;
=R' =
d=&S
:p>7
R&?t
@=R' =
l=q=
~*>Gr9>p
H>>yX>
f%?=
+?-C,?
,?-C,?
h>>yX>p
H>Gr9>
{r<U
:0>[
_>iop>I
;.?{
;.?$
@"?$
>iop>
G!><
;X94<
fU=$
>ff&>
y'?u
c,?r
0?EG2?}
7?^K8?Y
8?^K8?
+5?}
3?EG2?
c,?u
y'?j
8V>9
5>ff&>
fU=|
<X94<B`
?n4 ?
,?I./?
1?I./?D
#?n4 ?
E6=tF
u >io0>
t>J{
$?B>(?
1?X94?
6?X94?
+?B>(?
@>io0>
@=B>h=
$>F%5>
sW>gDi>
V?E
%?gD)?
,?R'0?
S3?0L6?
>?R'@?
8E?a
B?R'@?_
9?0L6?
S3?R'0?
,?gD)?"
V?0
~{>gDi>
F>F%5>/
=B>h=
B<HP
41?4
=?io@?
H?q=J?
~K?(~L?6<M?H
M?6<M?(~L?
~K?q=J?U
B?io@?d
41?h
4o>v
WJ=F
s=Nb
->[B>>r
4!?"
1?]m5?
I<?Di??aTB?
O?2UP?
aQ?2UP?
E?aTB?Di??
8?]m5?
3b>r
O>[B>>V
=yX(=
N=Gry=*
0>%uB>
8g>5^z>
?n4 ?
$?gD)?h
F?GrI?
HN?2UP?
&R?F
V?p_W?
W?p_W?
&R?2UP?
K?GrI?}
-?gD)?
$?n4 ?
>5^z>
T>%uB>|
=Gry=
N=yX(=
Q<KY
S#>4
#?B>(?
41?]m5?c
A?o
X?GrY?
Z??W[?
[?h"\?h"\?
[??W[?
Z?GrY?~
\=?c
9?]m5?
,?B>(?
S#><
ZS=V
Y<RI
sW=n
qJ>RI]>
+?R'0?4
D?yXH?q
Q?tFT?}
Z?HP\?
_?R'`?
h`?R'`?$
]?HP\?h
V?tFT?n
K?yXH?
4?R'0?
p>RI]>
qJ>~
sW=2
<RI
~;>_
|@?o
D?yXH?
UO?A
R?]mU?~
c?=,d?Ttd?Ttd?=,d?
X?]mU?A
K?yXH?o
Ga>_
~;>
y'?D
1?0L6?
:?Di??
UO?X
.^?Nb`?aTb?
d?]me?
eg?+
Dh?+
f?]me?
d?aTb?Nb`?
UO?q
C?Di??
:?0L6?
V,>,
<B`e<
b='1
rh>[
*?I./?X94?
=?aTB?}
U?gDY?
I\?gDY?
F?aTB?d
9?X94?I./?u
rh>O
/>G
<B`e<
=5^:=B`e=q=
k>n4
;?io@?
E?GrI?
Q?]mU?
&b?O
(l?mVm??5n?
n??5n?mVm?
X?]mU?n
M?GrI?
E?io@?
=B`e=5^:=
<=B>h=
q?aT
:P?tFT?~
m?-!o?
Np?-!o?
X?tFT?
a!>r
=B>h=[
4o<z6
9#>X
\>W[q>
f%?
;?R'@?
g?U0j?
n?2Up?N
q?2Up?
l?U0j?
E?R'@?C
>W[q>?
(m=M
G!?=
,?EG2?
K?2UP?O
\?Nb`?}
?t?]mu?KYv?
v?KYv?]mu?
?t?<
c?Nb`?$
T?2UP?
7?EG2?$
G!?Zd
{r<V}
>0L&>l
;.?}
&R?+
^?aTb?
t?KYv?
w?>yx?
y?,ey?,ey?
y?>yx?
w?KYv?
e?aTb?
J9?}
9>0L&>tF
4o=\
B=Qk
2D= Aq=
'>lx:>
!N>x
8E?q=J?
X?HP\?
m?2Up?<
v?'1x?
ky?'1x?
r?2Up?
H`?HP\?~
O?q=J?
+5?{
!N>lx:>
= Aq=
t<RI
=]mE=
;>`vO>x
~K?2UP?
U?GrY?
a?]me?5
(l?-!o?N
?t?KYv?'1x?^
{?(~|?
|?(~|?
y?'1x?KYv?
?t?N
q?-!o?
(l?5
h?]me?
]?GrY?
U?2UP?
=y>x
d>`vO>
{r=]mE=
u<RI
ew<3
?F=F
+e>lxz>B>
eG?(~L?
aQ?4
j?mVm?
Np?S
s?]mu?
/|?q
w?]mu?S
Np?mVm?
aQ?(~L?
>lxz>
^)>=
?F=RI
)>6<=>
e>Zd{>9
R&?-C,?
$H?6<M?
V??W[?$
eg?c
j??5n?
s?KYv?>yx?
Wz?>yx?KYv?
4q??5n?c
_??W[?
&R?6<M?
2?-C,?
A ?:#
>Zd{>
4Q>6<=>
Yu=*
2?^K8?
R?p_W?
[?R'`?=,d?+
z?(~|?H
}?(~|?
g?=,d?R'`?
[?p_W?
=?^K8?\
d*>+
f>HP|>L7
W?h"\?
h`?Ttd?
Dh?6
>w?,ey?
C{?,ey?
Dh?Ttd?
h`?h"\?
!>?Y
>HP|>B
 <X9
f>HP|>L7
W?h"\?
h`?Ttd?
Dh?6
>w?,ey?
C{?,ey?
Dh?Ttd?
h`?h"\?
!>?Y
>HP|>B
 <X9
Yu=*
2?^K8?
R?p_W?
[?R'`?=,d?+
z?(~|?H
}?(~|?
g?=,d?R'`?
[?p_W?
=?^K8?\
d*>+
)>6<=>
e>Zd{>9
R&?-C,?
$H?6<M?
V??W[?$
eg?c
j??5n?
s?KYv?>yx?
Wz?>yx?KYv?
4q??5n?c
_??W[?
&R?6<M?
2?-C,?
A ?:#
>Zd{>
4Q>6<=>
ew<3
?F=F
+e>lxz>B>
eG?(~L?
aQ?4
j?mVm?
Np?S
s?]mu?
/|?q
w?]mu?S
Np?mVm?
aQ?(~L?
>lxz>
^)>=
?F=RI
=]mE=
;>`vO>x
~K?2UP?
U?GrY?
a?]me?5
(l?-!o?N
?t?KYv?'1x?^
{?(~|?
|?(~|?
y?'1x?KYv?
?t?N
q?-!o?
(l?5
h?]me?
]?GrY?
U?2UP?
=y>x
d>`vO>
{r=]mE=
u<RI
2D= Aq=
'>lx:>
!N>x
8E?q=J?
X?HP\?
m?2Up?<
v?'1x?
ky?'1x?
r?2Up?
H`?HP\?~
O?q=J?
+5?{
!N>lx:>
= Aq=
t<RI
{r<V}
>0L&>l
;.?}
&R?+
^?aTb?
t?KYv?
w?>yx?
y?,ey?,ey?
y?>yx?
w?KYv?
e?aTb?
J9?}
9>0L&>tF
4o=\
B=Qk
(m=M
G!?=
,?EG2?
K?2UP?O
\?Nb`?}
?t?]mu?KYv?
v?KYv?]mu?
?t?<
c?Nb`?$
T?2UP?
7?EG2?$
G!?Zd
4o<z6
9#>X
\>W[q>
f%?
;?R'@?
g?U0j?
n?2Up?N
q?2Up?
l?U0j?
E?R'@?C
>W[q>?
<=B>h=
q?aT
:P?tFT?~
m?-!o?
Np?-!o?
X?tFT?
a!>r
=B>h=[
=5^:=B`e=q=
k>n4
;?io@?
E?GrI?
Q?]mU?
&b?O
(l?mVm??5n?
n??5n?mVm?
X?]mU?n
M?GrI?
E?io@?
=B`e=5^:=
<B`e<
b='1
rh>[
*?I./?X94?
=?aTB?}
U?gDY?
I\?gDY?
F?aTB?d
9?X94?I./?u
rh>O
/>G
<B`e<
y'?D
1?0L6?
:?Di??
UO?X
.^?Nb`?aTb?
d?]me?
eg?+
Dh?+
f?]me?
d?aTb?Nb`?
UO?q
C?Di??
:?0L6?
V,>,
~;>_
|@?o
D?yXH?
UO?A
R?]mU?~
c?=,d?Ttd?Ttd?=,d?
X?]mU?A
K?yXH?o
Ga>_
~;>
Y<RI
sW=n
qJ>RI]>
+?R'0?4
D?yXH?q
Q?tFT?}
Z?HP\?
_?R'`?
h`?R'`?$
]?HP\?h
V?tFT?n
K?yXH?
4?R'0?
p>RI]>
qJ>~
sW=2
<RI
S#>4
#?B>(?
41?]m5?c
A?o
X?GrY?
Z??W[?
[?h"\?h"\?
[??W[?
Z?GrY?~
\=?c
9?]m5?
,?B>(?
S#><
ZS=V
=yX(=
N=Gry=*
0>%uB>
8g>5^z>
?n4 ?
$?gD)?h
F?GrI?
HN?2UP?
&R?F
V?p_W?
W?p_W?
&R?2UP?
K?GrI?}
-?gD)?
$?n4 ?
>5^z>
T>%uB>|
=Gry=
N=yX(=
Q<KY
WJ=F
s=Nb
->[B>>r
4!?"
1?]m5?
I<?Di??aTB?
O?2UP?
aQ?2UP?
E?aTB?Di??
8?]m5?
3b>r
O>[B>>V
41?4
=?io@?
H?q=J?
~K?(~L?6<M?H
M?6<M?(~L?
~K?q=J?U
B?io@?d
41?h
4o>v
@=B>h=
$>F%5>
sW>gDi>
V?E
%?gD)?
,?R'0?
S3?0L6?
>?R'@?
8E?a
B?R'@?_
9?0L6?
S3?R'0?
,?gD)?"
V?0
~{>gDi>
F>F%5>/
=B>h=
B<HP
u >io0>
t>J{
$?B>(?
1?X94?
6?X94?
+?B>(?
@>io0>
?n4 ?
,?I./?
1?I./?D
#?n4 ?
E6=tF
;X94<
fU=$
>ff&>
y'?u
c,?r
0?EG2?}
7?^K8?Y
8?^K8?
+5?}
3?EG2?
c,?u
y'?j
8V>9
5>ff&>
fU=|
<X94<B`
:0>[
_>iop>I
;.?{
;.?$
@"?$
>iop>
G!><
l=q=
~*>Gr9>p
H>>yX>
f%?=
+?-C,?
,?-C,?
h>>yX>p
H>Gr9>
{r<U
=R' =
d=&S
:p>7
R&?t
@=R' =
:B`e;
9=d]\=I
=d]\=Z
9=Qk
u`<RI
;B`e;
ew=r
\m>HP|>
c?r
>HP|>
%>>y
ew=a
2=tF
+=_)K=
(m=p
q,>#
q?_
q?h
q,>d;
(m=_)K=V
:_)K;|
?$=\
Sc=o
/>>y
2>I.?>_
6Z>_
L>I.?>
%>>y
/>n4
Sc=\
;_)K;4
|P>-
=W[1=
..>lx:>]
ZS>]
F>lx:>
AO=W[1=
5<HP
7;RI
d*;u
Sc=n
%>W[1>
U>w-a>
\m>~
\m>w-a>+
!=>W[1>
Jj<1
d*;RI
=R' =
sW=k+v=(
>B>(>
g3>m
>>:#J>=
U>w-a>
l>w-a>=
U>:#J>m
g3>B>(>
=k+v=
:=R' =
#<B`
h=J{
H?>:#J>+
U>:#J>
m4>z
)>-!
>R' >
m4>m
ZS>-
-r>HP|>
>HP|>
J*>R' >
?F<N
5=;pN=
>R' >z
!=>]
|P>]
g3>z
)>R' >b
xi=;pN=
{r;'
;B`e;X9
c<)\
>B>(>W[1>lx:>
C>lx:>W[1>B>(>-!
;B`e;o
T<KY
L=B`e=I.
..>}
6>I.?>
h>iop>~
x>iop>
DX>r
G>I.?>}
c>]
=B`e=
:_)K;RI
=yX(=
m=J{
P>>yX>
_>>yX>
kI>n
v>=yX(=
;_)K;
?F=d]\=F
8V>?
c>gDi>
t>5^z>$
>5^z>
4o>gDi>
s=d]\=
<;p
d*;KY
d*<b
ew=p_
2>Gr9>[
sW>v
8g>1
|>n4
3b>v
?>Gr9>
%>d;
Ga=:
d*<o
Q9RI
{r<N
=yX(=
x=p_
/>aT
X>RI]>
Ga>f
n>W[q>}
=y>lxz>Zd{>
|>HP|>HP|>
|>Zd{>lxz>
s>W[q>
rh>f
Ga>RI]>P
/>o
/;=yX(=
y;RI
<X94<
=z6+=6<==
ew=o
G!>ff&>
+>io0>F%5>
9>[B>>%uB>
qJ>_
QZ>?
+e>x
F>%uB>[B>>
9>F%5>io0>
+>ff&>
P=6<==z6+=u
/]<X94<r
;_)K;
{r<)\
q,=6<==
Ga=F
s=J{
u >/
!N>`vO>
|P>`vO>
2D>7
~;>~
N=6<==
;_)K;o
7;KY
=z6+=
/;=:
K=d]\=D
m=I.
V,>i
9>lx:>
<>6<=>
=>6<=>
;>lx:>l
u1>i
V,>
m=d]\=:
/;=z6+=
=yX(=Y
U=B`e=
9#>/
$>0L&>
d*>1
'>0L&>/
Yu=B`e=
?F=Y
7=yX(=u
{r<M
7x=J{
/>:#
O/<N
=yX(=
A=;pN=
h=k+v=n
=k+v=
[=;pN=
5=yX(=
ew<b
7:RI
j<<>
ew<M
ew<>
j<<b
ew=I
{r<b
DX;'
3"<4
=R' =U
(=W[1=Z
B=_)K=a
S=d]\=
d=d]\=a
S=_)K=\
9=W[1=U
(=R' =P
7;B`e;
?$=V
b=B>h=D
s=Gry=
\~=n
\~=Gry=F
m=B>h=e
?$=v
;B`e;4
{r<&
=R' =T
b=B`e=B>h=h
4o= Aq=
{r=F
{r= Aq=
(m=h
j=B>h=B`e=e
WJ=9
E6=|
%=R' =Qk
k:RI
>;B`e;'
#<X94<
z<KY
$=yX(=V
7=5^:=[
2D=]mE=
?F=]mE=
2D=\
<=5^:=
-2=2
+=yX(=
D<X94<
;B`e;
>;RI
DX;$
d*<4
?F<4
DX;4
Q:RI
Q9RI
k:RI
Q9RI
k;KY
Q:RI
Q9RI
7;_)K;
y;KY
3"<U
-<X94<
b<B`e<
4o<E
{r<!
ew<l
{r<E
h<B`e<e
#9<X94<
3"<RI
^;_)K;4
7:RI
Q9RI
d*;4
7;_)K;
DX;B`e;
{r;o
{r;B`e;
DX;_)K;4
d*;RI
7:RI
Q9RI
d*;4
>;_)K;
DX;B`e;
{r;l
k;B`e;
Q;_)K;
#;RI
7:RI
Q9RI
7:RI
Q9RI
NSt3__120__shared_ptr_pointerIPN6vision3mod18FaceBoxPoseAlignerIaEENS_14default_deleteIS4_EENS_9allocatorIS4_EEEE
NSt3__114default_deleteIN6vision3mod18FaceBoxPoseAlignerIaEEEE
14SfWeightVector
N6vision3mod20SimilarityMatrixLazyE
NSt3__120__shared_ptr_emplaceIN6vision3mod22BoostedClassifierLightENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN6vision3mod44ImageDescriptor_PixelPairDifferenceProcessorENS_9allocatorIS3_EEEE
N6vision3mod44ImageDescriptor_PixelPairDifferenceProcessorE
@(#)PROGRAM:Vision  PROJECT:Vision-1.0.30
@(#)PROGRAM:TemporalRegistration-tvOS  PROJECT:Vision-1.0.30
com.apple.cvml.%@
CVML module = %@
CVML_debug_enable_cluster_log
v8@?0
en_US_POSIX
yyyy-MM-dd_HH-mm-ss-SSS
VNClusteringLog
%@_%@.log
Level %@ cluster map:
ClusterId: %lld
%@Faces: 
%lld
0 Lookup
1 Lookup
logFolderURL
T@"NSURL",R,V_logFolderURL
logFileURL
T@"NSURL",R,V_logFileURL
logEnabled
TB,R,V_logEnabled
fileNameBase
T@"NSString",R,V_fileNameBase
VNSuggestionLog
Input query - face IDs with flags (clusterIdsWithFlags):
faceId: %@
%@can be returned: %@
Suggested face IDs: %@:
ClusterId: %@   
%@Suggestions: 
%@, 
all sugestions for given input query (suggestionLists)
filtered suggestions to include only those that are part of input query (suggestedInputsLists)
Connected groups of suggestions face IDs (connectedSuggestedInputs):
Group %d suggestions: 
Final list of suggestions face IDs (results):
Cache file path is a required option
Invalid cache file path: %@
Clustering threshold is a required option
RestoreClusteringState must have an NSData object
Clustering vector access method is a required option
Error initializing cluster state
Greedy clusterer failed with unknown error
Greedy clusterer failed with error: %s
Greedy clusterer failed with error: %llu
Internal error querying similar faces
getLevel1ClusteredIdsGroupedByLevel0ClustersForFaceId: m_ClusteringImpl_const (%llu) and/or faceId (%@) are/is not initialized
getLevel1ClusteredIdsGroupedByLevel0ClustersForFaceId: Level-1 cluster size is zero for a valid clusterID descriptor (%lld)
B24@?0@"NSNumber"8@"NSMutableOrderedSet"16
Parameter validation failed for getDistanceBetweenLevel1Clusters
v32@?0@8Q16^B24
getRepresentativenessForFaces was cancelled
  face[%d].representativeness = %.3f
  best rep = %d
-[VNGreedyClusteringReadOnly getDistances:to:error:]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/VisionKitFramework/VN/internal/VNGreedyClustering.mm
distances.size() == clusterIds.count * faces.count
Internal error in maximumFaceIdInModelAndReturnError
Clustering with greedy algorithm
Greedy clustering
adding faces (%lu): %s
Clusters:
  %d: prevcount=%d, curcount=%d, shouldUpdateRep = %d
clusters:
  clusterId: %ld, %s
VNClusteringDistanceThreshold
getLevel1ClusteredIdsGroupedByLevel0ClustersForFaceId: m_ClusteringImpl (%llu) and/or faceId (%@) are/is not initialized
getLevel1ClusteredIdsGroupedByLevel0ClustersForFaceId: There is no level-1 cluster that contains faceId = %d
getLevel1ClusteredIdsGroupedByLevel0ClustersForFaceId: Level-1 cluster size is zero for a valid clusterID descriptor (%ll)
getLevel1ClusteredIdsGroupedByLevel0ClustersForFaceId: Level-0 cluster size is zero for a faceId (%d) from Level-1 cluster.
getClusters was cancelled
-[VNGreedyClustering getDistances:to:]
%s error %lld:%s in %s @ %s:%d
void *vision::mod::ImageDescriptorBufferAbstract::getDataForKthDescriptor(int) const
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/ImageDescriptor/ImageDescriptor_BufferAbstract.h
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
map::at:  key not found
value
epoch
timescale
faceId
Ti,VfaceId
faceRect
T{CGRect={CGPoint=dd}{CGSize=dd}},VfaceRect
framesSinceLast
Ti,VframesSinceLast
maxScore
Tf,VmaxScore
minScore
Tf,VminScore
numScores
Ti,VnumScores
swFaceId
Ti,VswFaceId
swCenter
T{CGPoint=dd},VswCenter
swSize
T{CGSize=dd},VswSize
swLastFrameSeen
Ti,VswLastFrameSeen
hwFaceId
Ti,VhwFaceId
hwCenter
T{CGPoint=dd},VhwCenter
hwSize
T{CGSize=dd},VhwSize
hwLastFrameSeen
Ti,VhwLastFrameSeen
    orientation = %d
Number of HW faces = %d - calculating rect
   hwFaceRect: (%.3f,%.3f,%.3f,%.3f), hasLeftEye = %d, hasRightEye = %d
Setting needSWFaceDetection = YES (v2)
   face %d = (%.3f,%.3f,%.3f,%.3f)
   fcrect  = (%.3f,%.3f,%.3f,%.3f)
   inserting prev face (hw%d,sw=%d) = (%.3f,%.3f,%.3f,%.3f) padding=(%.3f,%.3f)
Setting needSWFaceDetection = YES (v1)
Faces before filtering:
  face rect : (%.3f,%.3f,%.3f,%.3f)
q24@?0@"VNFaceObservation"8@"VNFaceObservation"16
Faces after filtering:
swFaceDetection forced = %d
Skipping face detection
v24@?0@"VNRequest"8@"NSError"16
calculateFaceFocus:
   adding rect: %.3f,%.3f,%.3f,%.3f
{CGRect={CGPoint=dd}{CGSize=dd}}
   focusScore = %d, %.3f
AdjustFaceIds: Examining '%s'
faceStat.id = %d
    rename found: %d mapped to %d
    new id: %d mapped to %d
    no id: assigning %d
    map found: %d maps to %d
       entry exists with same id: %d
%d faces so far unmatched:
    face %d
    %d overlaps with %d by %.3f %% : 
    matched!  mapping %d to %d
    not matched
      no match found for id %d - adding face
  prevConfig has %d entries
Found mapping!
   mapping not found for %d, mapping to itself
removing config entry: %d
Timestamp
  face ID = %d, timestamp = %.6f
FaceID
Rect
Width
Height
    inserting at index %d, count=%d
  extractFacesFromMetadata
extractFaceMetadata: invalid properties
AccumulatedFaceMetadata
  accumulatedFaceMetadata = %x
adding %d faces
Regions
regions exist
RegionList
  num regions = %d
    latestFaceTimestamp = %.6f
addFacesToImageStat: timestamp = %.6f, lastFaceIndex=%d
    imageTimestamp > latestFaceTimestamp
RollAngle
YawAngle
PitchAngle
LeftEyeX
LeftEyeY
LeftEyeWidth
LeftEyeHeight
LeftEyeBlinkLevel
RightEyeX
RightEyeY
RightEyeWidth
RightEyeHeight
RightEyeBlinkLevel
SmileLevel
      found face id %d, timestamp=%.6f, x=%.3f,y=%.3f,w=%.3f,h=%.3f
    adding face id %d, timestamp %.6f
    face id %d, timestamp %.6f - delta = %.6f, perhaps should use FaceCore
FaceInfoArray:
hwId = %d (lastSeen=%d, ctr=%.3f,%.3f size=%.3f,%.3f), swId = %d (lastSeen=%d, ctr=%.3f,%.3f size=%.3f,%.3f)
curConfig
T@"NSMutableDictionary",&,V_curConfig
faceIdMapping
T@"NSMutableDictionary",&,V_faceIdMapping
renameMapping
T@"NSMutableDictionary",&,V_renameMapping
faceIdCounter
Ti,V_faceIdCounter
faceInfoArray
T@"NSMutableArray",&,V_faceInfoArray
numFramesSinceFullFaceCore
Ti,V_numFramesSinceFullFaceCore
numFramesNoFaces
Ti,V_numFramesNoFaces
faceTimestampArray
T@"NSMutableArray",&,V_faceTimestampArray
latestImageTimestamp
Td,V_latestImageTimestamp
lastFaceIndex
Ti,V_lastFaceIndex
timeFaceDetectionDone
Td,VtimeFaceDetectionDone
timeBlinkDetectionDone
Td,VtimeBlinkDetectionDone
forceFaceDetectionEnable
TB,VforceFaceDetectionEnable
forceFaceDetailsEnable
TB,V_forceFaceDetailsEnable
latestFaceTimestamp
Td,VlatestFaceTimestamp
version
Ti,V_version
scaled Average Camera Travel Distance = %f
scaled Max Registration Error Integral = %f
scaled Mean peak registration error / Max peak registration error = %f
scaled Beginning vs. End AEMatrix difference vs. Average of Adjacent AE Matrix Differences = %f
scaled In-out ratio = %f
scaled Max inner distance = %f
scaled Average registration error skewness = %f
Sequence classified as NON-ACTION due to complete lack of local motion (%f, threshold %f)
Non-Linear SVM Action classifier called with:
Average Camera Travel Distance = %f
Max Registration Error Integral = %f
Mean peak registration error / Max peak registration error = %f
Beginning vs. End AEMatrix difference vs. Average of Adjacent AE Matrix Differences = %f
In-out ratio = %f
Max inner distance = %f
Average registration error skewness = %f
PREDICTION: --- %s --- (value = %f)
ACTION
NON-ACTION
testMaxInnerDistance
Tf,VtestMaxInnerDistance
testInOutRatio
Tf,VtestInOutRatio
testMaxPeakRegistrationError
Tf,VtestMaxPeakRegistrationError
testMeanPeakRegistrationError
Tf,VtestMeanPeakRegistrationError
testMinRegionOfInterestSize
Tf,VtestMinRegionOfInterestSize
testMaxRegistrationErrorSkewness
Tf,VtestMaxRegistrationErrorSkewness
testMaxRegistrationErrorIntegral
Tf,VtestMaxRegistrationErrorIntegral
testAverageCameraTravelDistance
Tf,VtestAverageCameraTravelDistance
testAverageRegistrationErrorSkewness
Tf,VtestAverageRegistrationErrorSkewness
testBeginningVsEndAEMatrixVsAverageAdjacentAEMatrix
Tf,VtestBeginningVsEndAEMatrixVsAverageAdjacentAEMatrix
svmParameters
T^{__SVMParameters=[7{__SVMScaleOffset=ff}]ddii^{BurstSupportVector}^{BurstSupportVector}},V_svmParameters
Processing refinedSuggestionsForClusters request
refinedSuggestionsForClusters request missing the VNRequestOptionInputClusters input
refinedSuggestionsForClusters request missing the VNRequestOptionInputClusterIds input
apple_scenes_onlyfc
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/ImageClassifier/ImageClassifier_Abstract.h
classifyDescriptor
Classification mode is invalid
std::map<std::string, float> vision::mod::ImageClassifierAbstract::classifyDescriptor(const vision::mod::ImageDescriptorBufferAbstract &, bool, bool)
wipeLayersMemory
Not implemented for this class
VNClusterOptionVectorMapReadOnlyFlag
Invalid Clusterer cache directory: %@
Invalid Clusterer type: %@
Failed to create clusterer; Error = %@
ClusterObservation couldn't initialize
ClusterObservation couldn't initialize
failed to create %@ clusterer
Couldn't add descriptors to matrix.
Couldn't add descriptors to matrix.
Couldn't add descriptors to clustering engine.
Couldn't add descriptors to clustering engine.
matrix
Could not get clusters (getClustersWithOptions) in clusterFacesWithOptions
Couldn't get cluster state from clustering engine.
Couldn't restore cluster state.
unsupported clustering method: %@.
unsupported clustering method: %@
T@"VNSimilarityMatrix",&,V_matrix
clusterMethod
T@"NSString",R,V_clusterMethod
useClusterObservation
TB,R,V_useClusterObservation
clusteredFaceIds
T@"NSSet",R,GgetClusteredFaceIds
Disgust
Neutral
Scream
Smile
Surprise
Suspicious
CVML_status vision::mod::ImageDescriptorBufferAbstract::initBufferWithData(void *, size_t, size_t, bool)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/ImageDescriptor/ImageDescriptor_BufferAbstract.cpp
vision::mod::ImageDescriptorBufferAbstract::ImageDescriptorBufferAbstract(void *, size_t, size_t, bool)
vision::mod::ImageDescriptorBufferAbstract::ImageDescriptorBufferAbstract(const std::vector<ImageDescriptorId> &, void *, size_t, size_t, bool)
<%s:(%s@%d)> 
appendDescriptors
ERROR: Descriptors lenghts don't match
virtual CVML_status vision::mod::ImageDescriptorBufferAbstract::appendDescriptors(const vision::mod::ImageDescriptorBufferAbstract &)
ERROR: Both descriptor buffers have to either contain descriptor ids values or not
ERROR: Descriptor ids values count does not match the descriptors count in the base buffer
ERROR: Descriptor ids values count does not match the descriptors count in the appended buffer
ERROR: One of the descriptor ids from the appended descriptor buffer already exists in the base descriptor buffer (id: %lld).
deleteDescriptorAtIndex
ERROR: Can't delete descriptor with given index: %d (highest descriptor index in the buffer is %d)
virtual CVML_status vision::mod::ImageDescriptorBufferAbstract::deleteDescriptorAtIndex(const int, std::vector<int> *)
virtual CVML_status vision::mod::ImageDescriptorBufferAbstract::deleteDescriptorsAtIndexes(const std::vector<int> &, std::vector<int> *)
deleteDescriptorsWithIds
ERROR: Can't delete descriptors with given ids - ids information is not present
virtual CVML_status vision::mod::ImageDescriptorBufferAbstract::deleteDescriptorsWithIds(const std::vector<ImageDescriptorId> &, std::vector<ImageDescriptorId> *)
getSelfDistanceIndexOnFlattenedList
ERROR: Flattened list indexes cannot be equal
int vision::mod::ImageDescriptorBufferAbstract::getSelfDistanceIndexOnFlattenedList(int, int)
computeDistanceFrom
ERROR: Incorrect count of descriptors in one of the buffers, expected exactly 1
virtual float vision::mod::ImageDescriptorBufferAbstract::computeDistanceFrom(const vision::mod::ImageDescriptorBufferAbstract &) const
setDescriptorIdForKthDescriptor
ERROR: Can't set descriptor id - ids vector is empty
vision::mod::ImageDescriptorBufferAbstract &vision::mod::ImageDescriptorBufferAbstract::setDescriptorIdForKthDescriptor(int, ImageDescriptorId)
resetDescriptorIds
ERROR: the number of descriptor ids should match the number of descriptors in the buffer
resizeForDescriptorsCount
ERROR: the resizeForDescriptorsCount method is probably called without ever initializing the descriptor buffer
void vision::mod::ImageDescriptorBufferAbstract::resizeForDescriptorsCount(size_t, bool)
virtual vision::mod::ImageDescriptorBufferAbstract *vision::mod::ImageDescriptorBufferAbstract::createEmptyCopy() const
Descriptor count = 
Descriptor length = 
 bytes
virtual vision::mod::ImageDescriptorBufferAbstract *vision::mod::ImageDescriptorBufferAbstract::getRepresentative(vision::mod::ImageDescriptorBufferAbstractRepresentativeMode, ImageDescriptorId) const
CVML_status ImageProcessing_fill_XYZA8888(vImage_Buffer *, const Geometry2D_rect2D *, const int *)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/ImageProcessing/ImageProcessing_Fill.c
Processing suggestionsForClusters request
clusterIDs
T@"NSArray",R,C,N
CVML_status FaceWarper_warpBoundingBoxRST_Planar8(const vImage_Buffer *, Geometry2D_cart2D *, dispatch_queue_t, vImage_Buffer *)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/FaceWarper/FaceWarper_Warp.c
CVML_status FaceWarper_computeEyesRST(const Geometry2D_cart2D *, const Geometry2D_point2D *, const Geometry2D_size2D *, Geometry2D_RST *)
CVML_status FaceWarper_warpEyesRST_Planar8(const vImage_Buffer *, const Geometry2D_cart2D *, const Geometry2D_point2D *, dispatch_queue_t, vImage_Buffer *)
CVML_status FaceWarper_computeAnchorRST(const Geometry2D_cart2D *, const int *, int, const Geometry2D_point2D *, const Geometry2D_size2D *, Geometry2D_RST *)
CVML_status FaceWarper_warpAnchorsRST_Planar8(const vImage_Buffer *, const Geometry2D_cart2D *, const int *, int, const Geometry2D_point2D *, dispatch_queue_t, vImage_Buffer *)
CVML_status FaceWarper_warp3D_Planar8(const vImage_Buffer *, const Geometry2D_cart2D *, const Geometry3D_cart3D *, const Geometry2D_point2D *, const float *, FaceWarper_Mirroring, dispatch_queue_t, vImage_Buffer *)
v16@?0Q8
createBridgeSegment
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/RectangleDetector/QuadDetect/ContourUtilities.c
mPnts == nPnts
reverseContour
currCPtr != NULL
AnnealContour
sPtrPrev != sPtr
sPtr != sPtrNext
rPtr != NULL
annealSegments
sPrevPtr != sPtr
newCurr != NULL
mergeContourEnd
cPtr2->active
PCOORD_EQUAL(sPtr2->pary[sPtr2->nPnts-1], pc3)
(code == 1) || (code == 2)
mergeEndpointSearch4
code1 != -1
code2 != -1
scene-descriptor
scene-classifier
scene-classifier-labels
scene-classifier-relationships
B16@?0^@8
VN_scene_classifier_debug_intermediates/
Error calculating screenprint
.json
Could not compute image descriptor for image
Invalid data for input sceneprint descriptors
Invalid data for input image descriptor option
Could not compute raw softmax labels and confidence for image
Cannot calculate scene classification image descriptor
Image buffer is not initialized
Image buffer supplied with 0 length dimension (width or height)
VN_DEBUG_DUMP_SCENE_INTERMEDIATES
cla20k512_01f
Cannot load model for FaceClassifier_BoostedPixelDifference, model file path is nil
Cannot create FaceClassifier_BoostedPixelDifference with model path:'%s'
No image object passed to face prediction
Face Boosting Classifier initialization error
  calculateChecksumMD5ForFile: error reading %d bytes from file
Geometry2D_cart2D vision::mod::ERT2D<float>::predict(const Geometry2D_cart2D &, const Geometry2D_cart2D &, const uint32_t) [F = float]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/ERT/ERT2D.cpp
predict
ERROR: Unsupported warp mode
algParam
init
ERROR: Algorithm parameters were not correctly specified in ERT constructor
void vision::mod::ERT2D<float>::init(const vision::mod::ModelValues &, const char *, int32_t) [F = float]
ERROR: Algorithm parameters not available
nodeParam
ERROR: Node parameters were not correctly specified in the ERT constructor
leafParam
ERROR: Leaf parameters were not correctly specified in the ERT constructor
regLookup
ERROR: Reg lookup parameters were not correctly specified in the ERT constructor
ERROR: Bad number of node parameters
Could not allocate b container
Could not allocate bTransformedb container
ERT - p : %d
testFeature
p.n > 0
ERT - node params are unavailable
ERT - reg lookup is unavailable
ERT - maxCacheSize: %d
ERT - cacheIndexL : %d
ERT - cacheIndexR : %d
false
ERT - anchorIndex : %d
CVML_status vision::mod::ERT2D<float>::testFeature(int, int, int, const vision::mod::Transformation2D *, Geometry2D_cart2D &, bool &) [F = float]
testCascade
ERROR: Could not create the worker group
CVML_status vision::mod::ERT2D<float>::testCascade(int, const vision::mod::Transformation2D *, Geometry2D_cart2D &) [F = float]
CVML_status vision::mod::ERT2D<float>::testCascade(int, const vision::mod::Transformation2D *, Geometry2D_cart2D &) [F = float]_block_invoke
ERROR: dispatch_group_wait failed
com.apple.vis
request %@ was cancelled
request was cancelled
VNRequest
missing option %@
option %@ has an invalid value of %@
argument %@ has an invalid value of %@
Internal Error Occurred. Code: %d; description: %s; reason: %s
"%@"
Processing appendBurstSequenceFrame request
burst context is not available
burstFrameIdentifier
T@"NSString",C,N,V_burstFrameIdentifier
imageProperties
T@"NSDictionary",C,N,V_imageProperties
VNBarcodeSymbologyAztec
VNBarcodeSymbologyCODE39
VNBarcodeSymbologyCODE39Checksum
VNBarcodeSymbologyCODE39FullASCII
VNBarcodeSymbologyCODE39FullASCIIChecksum
VNBarcodeSymbologyCODE93
VNBarcodeSymbologyCODE93i
VNBarcodeSymbologyCODE128
VNBarcodeSymbologyDataMatrix
VNBarcodeSymbologyEAN8
VNBarcodeSymbologyEAN13
VNBarcodeSymbologyI2OF5
VNBarcodeSymbologyI2OF5Checksum
VNBarcodeSymbologyITF14
VNBarcodeSymbologyPDF417
VNBarcodeSymbologyQR
VNBarcodeSymbologyUPCE
leftEyeOpen
TB,VleftEyeOpen
rightEyeOpen
TB,VrightEyeOpen
smiling
TB,Vsmiling
leftEyeBlinkScore
Tf,VleftEyeBlinkScore
rightEyeBlinkScore
Tf,VrightEyeBlinkScore
smileScore
Tf,VsmileScore
hasLeftEye
TB,VhasLeftEye
hasRightEye
TB,VhasRightEye
foundByFaceCore
TB,VfoundByFaceCore
normalizedFaceRect
T{CGRect={CGPoint=dd}{CGSize=dd}},VnormalizedFaceRect
focusScore
Tf,VfocusScore
faceScore
Tf,VfaceScore
leftEyeRect
T{CGRect={CGPoint=dd}{CGSize=dd}},VleftEyeRect
rightEyeRect
T{CGRect={CGPoint=dd}{CGSize=dd}},VrightEyeRect
FCRLeftEyeFeaturesOffset
Ti,VFCRLeftEyeFeaturesOffset
FCRRightEyeFeaturesOffset
Ti,VFCRRightEyeFeaturesOffset
FCRSmileFeaturesOffset
Ti,VFCRSmileFeaturesOffset
FCRBlinkFeaturesSize
Ti,VFCRBlinkFeaturesSize
FCRSmileFeaturesSize
Ti,VFCRSmileFeaturesSize
FCRSmileAndBlinkFeatures
T@"NSMutableArray",&,VFCRSmileAndBlinkFeatures
hwFaceRect
T{CGRect={CGPoint=dd}{CGSize=dd}},V_hwFaceRect
normalizedFocusScore
Tf,VnormalizedFocusScore
normalizedSigma
Tf,VnormalizedSigma
hasRollAngle
TB,VhasRollAngle
hasYawAngle
TB,VhasYawAngle
hasPitchAngle
TB,V_hasPitchAngle
rollAngle
Tf,VrollAngle
yawAngle
Tf,VyawAngle
pitchAngle
Tf,V_pitchAngle
timestamp
Td,Vtimestamp
isSyncedWithImage
TB,V_isSyncedWithImage
smallFace
TB,VsmallFace
Image_ImageROIGridStartX
Image_ImageROIGridStartY
Image_ImageROIGridEndX
Image_ImageROIGridEndY
Original ROI = %d,%d -> %d,%d
Smoothed ROI = %d,%d -> %d,%d
Sharpness ROI for %s updated to (%d,%d)->(%d,%d)
%s REGISTERED AGAINST %s
Registration result: tx = %d, ty = %d
----------REGISTRATION ERROR INTEGRAL 
Row interval: (%d->%d)
Column interval: (%d->%d)
sensedROI = (%d,%d)->(%d,%d)
referenceROI = (%d,%d)->(%d,%d)
Registration rejected due to ROI too large or too small.
Registration in favor of face detection ROI.
Registration rejected due to skewness, which can indicate a bad registration result.
Registration rejected due to insufficient local motion.
----------------------- facecore count = %d, numHWFaces = %d
Limited ROI = (%d,%d)->(%d,%d)
Computing sharpness over grid points (%d,%d)->(%d,%d)
After collapse avgHorzDiffY = %f, blurExtent = %f
Num HW faces = %d, facecore faces = %d
combined normalized focus score for face core detections = %f
Limited sharpness score = %f, with number of faces = %d
Thumbnail selection score computation for %s
Average facial focus score = %f
Initial score (no faces) = %f (isGarbage = %d)
Action selection score = %f
imageId
T@"NSString",&,V_imageId
orientation
Ti,Vorientation
faceStatArray
T@"NSMutableArray",&,V_faceStatArray
exclude
TB,Vexclude
AEStable
TB,VAEStable
AEAverage
Ti,VAEAverage
AETarget
Ti,VAETarget
AFStable
TB,VAFStable
temporalOrder
Ti,VtemporalOrder
avgHorzDiffY
Tf,VavgHorzDiffY
blurExtent
Tf,VblurExtent
imageScore
Tf,VimageScore
actionScore
Tf,VactionScore
timeReceived
Td,VtimeReceived
maxSkewness
Tf,VmaxSkewness
registrationErrorX
Tf,VregistrationErrorX
registrationErrorY
Tf,VregistrationErrorY
registrationErrorIntegral
Tf,VregistrationErrorIntegral
actionClusteringScore
Tf,VactionClusteringScore
hasRegistrationData
TB,VhasRegistrationData
facesRoiRect
T{CGRect={CGPoint=dd}{CGSize=dd}},VfacesRoiRect
numHWFaces
Ti,VnumHWFaces
emotionallyRejected
TB,VemotionallyRejected
doLimitedSharpnessAndBlur
TB,VdoLimitedSharpnessAndBlur
Tf,Vtx
Tf,Vty
isGarbage
TB,VisGarbage
roiSize
Tf,VroiSize
AEDelta
Ti,V_AEDelta
Registration error stats: mean=%f, stdDev=%f, skewness=%f, maxValue=%f
Insufficient peak error for ROI computation %f (threshold %f)
Peak rejection threshold = %f (mean = %f, std = %f)
Starting ROI construction at %d->%d
ERROR: unknown transformation
VNImageOptionImageOrientation
VNImageOptionProperties
VNImageOptionCameraPixelFocalLength
VNImageOptionCameraIntrinsics
VNImageOptionCameraOpticalCenter
VNRequestHandlerCleanupOption_AllPipelines
VNRequestHandlerCleanupOption_FacePipeline
VNRequestHandlerCleanupOption_ScenePipeline
VNRequestHandlerCleanupOption_JunkPipeline
VNCleanupLevel_Complete
VNCleanupLevel_Partial
VNRequestHandlerCleanupOption_ImageBuffers
VNCleanupPurgeAll
could not create an image buffer
imageSpecifier
com.apple.VNRequestHandler
VNClusterContext
Cluster context has not been created
Trying to reuse cluster request handler with differing cluster method
RestoreState must be an NSData object
cannot restore cluster state without a cache folder path
modelContextObject
T@"NSObject",&,N,V_modelContextObject
burstAnalysisLoggingCallback
T@?,C,N,V_burstAnalysisLoggingCallback
VNPhotosRequestHandler
model request handler not available
VNSequenceRequestHandlerOption_LoggingCallback
VNSimilarityMatrixType_Lazy
VNSimilarityMatrixType_Full
VNSimilarityMatrixInitOption_SimilarityMatrixType
-[VNSimilarityMatrix getDescriptorIdsForRange:]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/VisionKitFramework/VN/internal/VNSimilarityMatrix.mm
start <= end && "getDescriptorIdsForRange invalid range"
Similarity matrix
matrixSize
TQ,R,N,GgetMatrixSize
maximumValidMatrixDistance
Tf,R,N,GgetMaximumValidMatrixDistance
impl
T^v,R,N,GgetImpl
virtual std::vector<float> (anonymous namespace)::FaceDescriptorBuffer::computeDistancesFrom(const vision::mod::ImageDescriptorBufferAbstract &) const
CVML_status LandmarkDetector_getIntensityFeature(const vImage_Buffer &, const Geometry2D_point2D &, LandmarkDetector_intensitySamplingMode, bool, uint8_t, float &)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/LandmarkDetector/LandmarkDetector_Features.cpp
LandmarkDetector_getIntensityFeature
ERROR: invalid intenisty sampling mode
LandmarkDetector_generateSmoothingKernel
ERROR: Could not allocate the smoothing kernel
CVML_status LandmarkDetector_generateSmoothingKernel(float, float, float *&)
CVML_status LandmarkDetector_getImagePreProcessedSamplingPixelPoint(const vImage_Buffer &, const Geometry2D_point2D &, bool, uint8_t, int, Geometry2D_point2D &)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/LandmarkDetector/LandmarkDetector_Utils.h
LandmarkDetector_rotateCoordinates
ERROR: Invalid rotation angle for the face crop
LandmarkDetector_getImagePreProcessedGaussianSmoothedIntensity
ERROR: getImagePreProcessedGaussianSmoothedIntensity not implemented
float LandmarkDetector_getImagePreProcessedGaussianSmoothedIntensity(const vImage_Buffer &, const Geometry2D_point2D &)
failed to create a %lu x %lu pixel buffer of type '%c%c%c%c'
failed to warp image
failed to create GL context
failed to create image registration context
CVML_status FastRegistration_computeSignatures(const vImage_Buffer *, _Bool, dispatch_queue_t, FastRegistration_Signatures *)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/ImageRegistration/FastRegistration/FastRegistration_Core.c
CVML_status FastRegistration_register(const FastRegistration_Signatures *, const FastRegistration_Signatures *, float, dispatch_queue_t, float *, float *, float *, float *)
CVML_status FastRegistration_compareSignatures(const FastRegistration_Signatures *, const FastRegistration_Signatures *, float, float, float *, vImagePixelCount *, float *, vImagePixelCount *)
CVML_status FastRegistration_processProjections(float *, vImagePixelCount)
Unable to obtain the known scene classifications - %@
q24@?0@"VNClassificationObservation"8@"VNClassificationObservation"16
v32@?0@"NSString"8@16^B24
knownSceneClassifications
T@"NSArray",R,N
sceneObservation
T@"VNSceneObservation",R,&,N,V_sceneObservation
static CVML_status vision::mod::image_quality::BlurMeasure::computeEdgeBasedBlurForImageRegionUsingBlurSignature(void *, Geometry2D_rect2D, float *, float, int *, int *)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/ImageQuality/BlurMeasure/BlurMeasure.mm
CVML_status (anonymous namespace)::computeBlurStatsOnImageData(uint8_t *, int, int, int, float, float *, int *, int *, void **)
applyInsetFactorToData
Both width and height have to be >= 32 after applying the inset factor. Given w/h: %d/%d
CVML_status (anonymous namespace)::applyInsetFactorToData(uint8_t **, int *, int *, int, int, float)
CVML_status (anonymous namespace)::computeBlurScoreOnImageSubblocks(uint8_t *, int, int, int, int, float, int, float *, int *, int *)
applyInsetFactorToROI
CVML_status (anonymous namespace)::applyInsetFactorToROI(Geometry2D_rect2D *, float)
%s %llu:%.6f
%s #
Error while computing blur score: %s
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/ImageClassifier/ImageClassifierEspresso/ImageClassifier_Espresso.mm
setDescriptorProcessor
EXCEPTION: invalid call to setDescriptorProcessor
virtual vision::mod::ImageClassifierAbstract &vision::mod::ImageClassifierEspresso::setDescriptorProcessor(const std::shared_ptr<ImageDescriptorProcessorAbstract> &)
virtual std::map<std::string, float> vision::mod::ImageClassifierEspresso::classifyDescriptorHandler(const vision::mod::ImageDescriptorBufferAbstract &)
v16@?0r^{shared_ptr<Espresso::abstract_batch>=^{abstract_batch}^{__shared_weak_count}}8
v24@?0{shared_ptr<Espresso::blob<float, 4> >=^{blob<float, 4>}^{__shared_weak_count}}8
void vision::mod::ImageClassifierEspresso::private_t::loadDescriptor(ImageDescriptorProcessorEspresso::Options, vision::mod::ImageClassifierEspresso *, const char *, const char *, ImageDescriptorProcessorEspresso::PLATFORM, ImageDescriptorProcessorEspresso::COMPUTE_PATH)
Inconsistent platform
void vision::mod::ImageClassifierEspresso::private_t::loadClassifier(ImageClassifierEspresso::Options, vision::mod::ImageClassifierEspresso *, const char *, const char *, ImageClassifierEspresso::PLATFORM, ImageClassifierEspresso::COMPUTE_PATH)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/ImageClassifier/ImageClassifierEspresso/ImageClassifier_Espresso.h
classifyImage_RGBA8888
EXCEPTION: the Espresso based image classifier should only operate on descriptors buffers
virtual std::map<std::string, float> vision::mod::ImageClassifierEspresso::classifyImage_RGBA8888(const vImage_Buffer &)
classifyImage_BGRA8888
virtual std::map<std::string, float> vision::mod::ImageClassifierEspresso::classifyImage_BGRA8888(const vImage_Buffer &)
classifyImage_Planar8
virtual std::map<std::string, float> vision::mod::ImageClassifierEspresso::classifyImage_Planar8(const vImage_Buffer &)
%@:Trk=%@
tracker type is undefined
tracking level is undefined
input observation is not available
%@ does not override %@
Tracker key has changed, restarting tracking sequesnce: current tracker key = %@; new tracker key = %@
Tracker level has changed, restarting tracking sequesnce: current tracking level = %@; new tracking level = %@
Internal error: internal type conversion failed
Internal error: unexpeted tracked object bounding box size
Bounding box input location has changed, restarting tracking sequesnce
currentTrackerBBox.x = %f; currentTrackerBBox.x = %f; currentTrackerBBox.width = %f; currentTrackerBBox.height = %f; 
newTrackerBBox.x = %f; newTrackerBBox.x = %f; newTrackerBBox.width = %f; newTrackerBBox.height = %f; 
currentBBoxArea = %f; overlappedBBoxArea = %f; overlappedBBoxArea / currentBBoxArea = %f
inputObservation
T@"VNDetectedObjectObservation",&,N,V_inputObservation
trackingLevel
TQ,N,V_trackingLevel
lastFrame
TB,N,GisLastFrame,V_lastFrame
hash
TQ,R
superclass
T#,R
description
T@"NSString",R,C
debugDescription
name
T@"NSString",R
registryID
maxThreadsPerThreadgroup
T{?=QQQ},R
lowPower
TB,R,GisLowPower
headless
TB,R,GisHeadless
removable
TB,R,GisRemovable
recommendedMaxWorkingSetSize
depth24Stencil8PixelFormatSupported
TB,R,GisDepth24Stencil8PixelFormatSupported
readWriteTextureSupport
argumentBuffersSupport
indirectArgumentBuffersSupport
rasterOrderGroupsSupported
TB,R,GareRasterOrderGroupsSupported
currentAllocatedSize
maxThreadgroupMemoryLength
programmableSamplePositionsSupported
TB,R,GareProgrammableSamplePositionsSupported
Incorrect value for 'VNRequestOptionPreferredMetalContext' option
Requested Metal Device is not supported: %@
metalDevice
T@"<MTLDevice>",R,V_metalDevice
wisdomParams
T@"NSDictionary",R,V_wisdomParams
useGPU
TB,R,V_useGPU
VNDetectorProcessOption_InputImageBuffers
VNDetectorProcessOption_ModelBackingStore
VNDetectorProcessOption_ImageCropAndScaleOption
com.apple.VN.processingQueue
unable to create processing queue
%@ does not implement %@
@"NSString"8@?0
+[VNDetector bestImageWidth:height:format:]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/VisionKitFramework/VN/internal/VNDetector.mm
Cannot initialize Metal Context
processingQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_processingQueue
backingStore
TQ,R,V_backingStore
Unspecified CVML module
BinSerializer
Face3D
FaceDescriptor
FaceFrontalizer
FaceWarper
Geometry2D
Geometry3D
ImageGrouping
ImageQuality
LandmarkDetector
MomentProcessor
FaceboxAligner
ImageDescriptor
ImageClassifier
ImageProcessing
VIPIdentification
ImageRegistration
SimilarityMatrix
Clustering
HumanDetector
FaceRegionMap
ObjectDetector
ObjectTracker
SRCClassifier
Kmeans
SparseCoding
Generic
ImageTools
VideoTools
ImageWarper
ThirdPartyBinSerializerProcessorAppleNetParser
FaceProcessorCLI
ImageClassifierCLI
MPCmdlineClientCLI
ClusteringCLI
ImageProcessorCLI
PhotosProcessor_CLI
CVMLEngine
!!! you should not read this !!!
small sparsity error
feature extraction error
initialization error
no saved state to revert to error
nominal distance not changed
batch size violation
a computation kill request was issued by the system
too few ids to build VIP model
video error
error with the projection computation
missing positional parameter
inconsistent state error
warping error
GL error
invalid format
out of bounds error
singular point configuration error
Division by zero error
LAPACK error
platform endianess not supported
the hash is already in use
invalid ID
invalid data type
data inconsistency error
I/O error
unknown option
invalid option
missing option
delegate error
vImage related error
memory allocation error
invalid parameter
undexpected null pointer
internal error
not implemented error
VNFaceRegionMapVersion
userX
userY
userW
userH
alignX
alignY
alignW
alignH
rgnMapData
rgnMapW
rgnMapH
rgnMapRowBytes
pixelToRgnMap
Unknown
supportsSecureCoding
TB,R
regionLabels
T@"NSArray",C,V_regionLabels
CVML_status ImageProcessing_createCGImageFromVImageBuffer(const vImage_Buffer *, ImageProcessing_ImageType, CGImageRef *)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/ImageProcessing/ImageProcessing_CoreGraphicsUtils.c
Processing representativeForClusters request
com.apple.CVML.gaborFilterCreateGaborFilterBankGCDQueue
com.apple.CVML.GaborFilterExtractGaborDescriptorGCDQueue
CVML_status Geometry3D_projectCart(const Geometry3D_cart3D *, const float *, const Geometry3D_pose *, const Geometry2D_cart2D *)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/Geometry3D/Geometry3D_Projection.c
CVML_status FaceRegionMap_addForeheadLandmarks(std::vector<Geometry2D_point2D> &)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/FaceRegionMap/FaceRegionMap_Core.cpp
VNImageBufferOption_DownscaleCGInterpolationQuality
VNImageBufferOption_UpscaleCGInterpolationQuality
ERROR while purging caches %s | %@
-[VNImageBufferManager purgeAllCaches]
this release call should not be used with anything but a referencing pixelbuffer %s
void CVPixelBufferReleaseReferencingPixelBufferCallback(void * _Nullable, const void * _Nullable)
Failed to create image for processing
Failed to create image for processing due to invalid requested buffer dimensions
Operation failed due to attempt to crop zero or near zero dimensioned area
unable to create the interim YUV buffer
unable to create the Y plane wrapper buffer
Failed to transfer _origPixelBuffer to croppedBuffer. Error %d
VNImageBuffer - unhandled orientation: %d
Unable to crop image from source buffer
Unable to create a CGBitmapContext
Could not create buffer with format %@ (%ld)
invalid ROI size of %f x %f
invalid chunk size of %ld x %ld
invalid chunk increment of %lu x %lu
width
height
fileURL
T@"NSURL",R
'%c%c%c%c'
0x%x
CVML_status Geometry2D_buildCalibrationMatrix(Geometry2D_size2D *, float, float *)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/Geometry2D/Geometry2D_Calibration.c
CVML_status Geometry2D_pixelToMetricHomo2D(const Geometry2D_homo2D *, const float *, Geometry2D_homo2D *)
CVML_status Geometry2D_metricToPixelHomo2D(const Geometry2D_homo2D *, const float *, Geometry2D_homo2D *)
***ImageBlocks::addImage: realloc failure
faceboxAligner
::meanShape
void vision::mod::FaceboxAligner::init(const vision::mod::ModelValues &)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/LandmarkDetector/FaceboxAligner.cpp
::meanShapeLandmarksInBox
std::pair<Geometry2D_rect2D, float> vision::mod::FaceboxAligner::makeFaceBox(std::vector<Geometry2D_point2D> &, Geometry2D_point2D, FaceBoxAligner_boxMode)
Geometry2D_rect2D vision::mod::FaceboxAligner::enforceBoxBoundaries(const Geometry2D_rect2D, float, float)
preProcessImage
ERROR: vImage error during scaling
void vision::mod::FaceboxAligner::preProcessImage(const vImage_Buffer &, const Geometry2D_rect2D &)
meanShape
meanShapeLandmarksInBox
com.apple.espresso.mainqueue
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/ObjectDetector/DCNFaceDetector/ObjectDetector_DCNFaceDetector.mm
ObjectDetector_DCNFaceDetector_block_invoke
Option not supported on GPU path
vision::mod::ObjectDetector_DCNFaceDetector::ObjectDetector_DCNFaceDetector(const Options &)_block_invoke
virtual std::vector<std::vector<DetectedObject> > vision::mod::ObjectDetector_DCNFaceDetector::detectObjectsInImages_Planar8(const std::vector<vImage_Buffer> &)
virtual std::vector<DetectedObject> vision::mod::ObjectDetector_DCNFaceDetector::detectObjectsInImage_Planar8(const vImage_Buffer &)
Unspecified error
face
model8c_.espresso.net
VNRequestNameDetectFaceRectangles
VNRequestNameDetectFaceLandmarks
VNRequestNameDetectFaceExpressions
VNRequestNameDetectFace3DLandmarks
VNRequestNameDetectFacePose
VNRequestNameDetectHumanRectangles
VNRequestNameImageBlurriness
VNRequestNameExposureScore
VNRequestNameImageBrightness
VNRequestNameImageRegistration
VNRequestNameSceneClassification
VNRequestIdentifyJunk
VNRequestNameMLTransform
VNRequestNameSupportedBarcodeSymbologies
VNRequestNameDetectBarcodes
VNRequestCreateFaceprint
VNRequestNameCreateFaceprint
VNRequestCreateFaceRegionMap
VNRequestNameDetectRectangles
VNRequestNameDetectHorizon
VNRequestNameClusterObservations
VNRequestNameAlignFaceRectangle
VNRequestNameCreateImageprint
VNRequestNameGroupImagesByTimeAndContent
VNRequestSuggestionsForClusters
VNRequestRefinedSuggestionsForClusters
VNRequestRepresentativeForCluster
VNRequestGetClusters
VNRequestOptionRepresentativeSample
VNRequestGetDistances
VNRequestNameObjectTracking
VNRequestNameFaceTracking
VNRequestNameRectangleTracking
VNRequestBurstAnalysisResults
VNRequestOptionInputImage
VNRequestOptionInputFaces
VNRequestOptionAddObjectsToClustering
VNRequestOptionRemoveObjectsFromClustering
VNRequestOptionInputClusterIds
VNRequestOptionInputClusterFlags
VNRequestOptionForceFaceprintCreation
VNRequestOptionInputClusters
VNRequestOptionCacheFolderPath
VNRequestOptionGetClusteredFaceIds
VNRequestOptionGetClusteredFaceIdsForFaceId
VNRequestOptionGetDistanceBetweenClustersWithFaceIds
VNRequestOptionDumpIntermediateImages
VNRequestOptionRectangleMinimumAspectRatio
VNRequestOptionRectangleMaximumAspectRatio
VNRequestOptionRectangleQuadratureTolerance
VNRequestOptionRectangleMinimumSize
VNRequestOptionRectangleMinimumConfidence
VNRequestOptionRectangleMaximumNumber
VNRequestOptionInputThreshold
VNRequestOptionInputTimestamp
VNRequestOptionInputImageprints
VNRequestOptionInputRegionOfInterest
VNRequestOptionPreferBackgroundProcessing
VNRequestOptionPreferredMetalContext
VNRequestOptionMetalContextPriority
VNRequestOptionMaximumIntermediateSideLength
VNRequestOptionClusteringAlgorithm
VNClusteringAlgorithm_Greedy
VNClusteringAlgorithm_Agglomerative
VNClusteringAlgorithm_Hierarchical
VNRequestOptionSaveClusteringState
VNRequestOptionRestoreClusteringState
VNRequestOptionDetectionLevel
VNRequestOptionDetectionLevel_Accurate
VNRequestOptionDetectionLevel_Balanced
VNRequestOptionDetectionLevel_Fast
VNRequestOptionFaceRectangleDetectorEnableLowMemoryMode
VNRequestOptionRectangleDetectorRequiredVersion
VNRequestCreateSceneprint
VNRequestOptionInputSceneprints
VNRequestOptionInputSceneClassificationAllResults
VNRequestOptionBlurMethod
VNRequestAppendBurstSequenceFrame
VNRequestOptionInputImageProperties
VNRequestOptionBurstFrameIdentifier
VNRequestOptionBurstAllImageIdentifiers
VNRequestOptionBurstImageStats
VNRequestOptionBurstClusters
VNRequestNameDetectTextRectangles
VNRequestOptionReportCharacterBoxes
VNRequestOptionBarcodeSymbologies
VNRequestOptionTrackingLevel
VNRequestOptionTrackingLevelAccurate
VNRequestOptionTrackingLevelFast
VNRequestOptionTrackingInputObject
VNRequestOptionInputRectangle
VNRequestOptionDetectTextRectanglesRequiredVersion
VNRequestOptionTextRecognition
VNRequestOptionVNCoreMLModel
VNRequestOptionVNCoreMLModelParameters
VNTextRecognitionOptionNone
VNTextRecognitionOptionASCIICharacterSet
VNTextRecognitionOptionEnglishCharacterSet
VNTextRecognitionOptionDanishCharacterSet
VNTextRecognitionOptionDutchCharacterSet
VNTextRecognitionOptionFrenchCharacterSet
VNTextRecognitionOptionGermanCharacterSet
VNTextRecognitionOptionIcelandicCharacterSet
VNTextRecognitionOptionItalianCharacterSet
VNTextRecognitionOptionNorwegianCharacterSet
VNTextRecognitionOptionPortugueseCharacterSet
VNTextRecognitionOptionSpanishCharacterSet
VNTextRecognitionOptionSwedishCharacterSet
VNRequestOptionTextRecognitionAdditionalCharacters
VNRequestOptionMinimumLinePixelHeight
VNRequestWarningImageTooSmall
VNRequestWarningImageTooSmallForFaceObservations
VNRequestWarningImageMinimumLongDimension
VNRequestWarningImageMinimumShortDimension
v32@?0@"NSString"8#16^B24
%@:BG=%c:MTL=%@:Det=%lu
%@:MTL=%@:Det=%lu
unable to prepare %@
com.apple.VNRequestCancellationQueue
Encountered error cancelling request: %@
-[%@ %@] has not been implemented
the %@ cancellation handler has not been implemented
imageBuffer
All elements in the %@ array must be of class %@ (%@)
cancellationSemaphore
T@"NSObject<OS_dispatch_semaphore>",&,V_cancellationSemaphore
cancellationTriggered
TB,V_cancellationTriggered
modelFileBackingStore
TQ,N,V_modelFileBackingStore
dumpIntermediateImages
TB,N
metalContextPriority
TQ,N,V_metalContextPriority
disallowsGPUUse
TB,N,V_disallowsGPUUse
detectionLevel
TQ,N
requestName
T@"NSString",R,C,N,V_requestName
options
T@"NSDictionary",R,C,N,V_options
preferBackgroundProcessing
preferredMetalContext
T@"<MTLDevice>",&,N,V_preferredMetalContext
results
T@"NSArray",R,C,N,V_results
completionHandler
T@?,R,C,N,V_completionHandler
The %@ required option was not found
The %@ option was expected to be a %@, but was instead a %@ (%@)
apple_scenes
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/ImageDescriptor/ImageDescriptor_ProcessorAbstract.h
computeDescriptorForImage
ERROR: This descriptor processor does not know how to handle CVPixelBuffers
ERROR: this function can handle only one image type
virtual CVML_status vision::mod::ImageDescriptorProcessorAbstract::computeDescriptorForImage(const vImage_Buffer &, ImageProcessing_ImageType, vision::mod::ImageDescriptorBufferAbstract &)
computeDescriptorsForImages
virtual CVML_status vision::mod::ImageDescriptorProcessorAbstract::computeDescriptorsForImages(const std::vector<vImage_Buffer> &, ImageProcessing_ImageType, vision::mod::ImageDescriptorBufferAbstract &)
virtual CVML_status vision::mod::ImageDescriptorProcessorAbstract::computeDescriptorsForAugmentedImages(const std::vector<vImage_Buffer> &, ImageProcessing_ImageType, vision::mod::ImageDescriptorAugmenterAbstract &, vision::mod::ImageDescriptorBufferAbstract &)
CVML_status vision::mod::ImageDescriptorAugmenterAbstract::augment(const std::vector<vImage_Buffer> &, ImageProcessing_ImageType)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/ImageDescriptor/ImageDescriptor_AugmenterAbstract.h
std::vector<vImage_Buffer *> vision::mod::ImageDescriptorAugmenterAbstract::getAugmentedBatch(int)
getAugmentedImages
ERROR: It appears that you are requesting the list of augmented images without having created them
std::vector<vImage_Buffer> vision::mod::ImageDescriptorAugmenterAbstract::getAugmentedImages() const
ConnectedComponents
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/RectangleDetector/QuadDetect/ConnectedComponents.c
pneighbor(*(Pcoord *)dequeFirst(dbLookup[mnid]), pix)
pneighbor(*(Pcoord *)dequeFirst(dbLookup[nid]), pix)
pneighbor(*(Pcoord *)dequeFirst(dbLookup[mid]), pix)
pneighbor(*(Pcoord *)dequeFirst(dbLookup[pid]), pix)
loc != -1
cidcnt < MAX_CONTOURS
eraseContourPixels
deque != NULL
VNFaceObservation object is expected to initialize Face Tracker
Object identifier is not initialized in the input face observation
Internal error: Face tracking failed
Internal error: Unable to create request to compute bbox alignment
Internal error: One or more face bounding boxes cannot be aligned
Internal error: Cannot create face classifier
Internal error: One or more face bounding boxes is not aligned
inputFaceObservations
Processing DetectHumans request
CVML_status Geometry2D_cartToBari2D(const Geometry2D_cart2D *, const Geometry2D_cart2D *, Geometry2D_bari2D *)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/Geometry2D/Geometry2D_Baricentric.c
CVML_status Geometry2D_bariToCart2D(const Geometry2D_bari2D *, const Geometry2D_cart2D *, Geometry2D_cart2D *)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/SparseCoding/SparseCoding.cpp
sparseCoding_imageDescriptor
ERROR: only takes stride of multiples of sizeof(float)
ERROR: dimensions of dictionary element and sample mismatch
ERROR: numbers of code elements and samples mismatch
ERROR: numbers of code dimensions and dictionary elements mismatch
matrix size mismatch
matrix size too small for output
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/SparseCoding/FeatureSign.h
encode
lambda must be > 0
encoder is not initialized
ERROR: memory allocation failure
row index out of range
matrix vector size mismatch
vector size too small for output
ERROR: dictionary index out of range
ERROR: sparsity constraint is too small, increase lambda
choleskySolve
ERROR: Cholesky solve: dimension mismatch between vector b and matrix A
ERROR: illegal value when solving linear equations
ERROR: empty active set: nothing to delete
ERROR: index to delete not in active set
choleskyDelete
ERROR: row index to delete out of range
-[VNMomentProcessor initWithOptions:error:]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/MomentProcessor/Moments/MomentProcessor.mm
error != nil
-[VNMomentProcessor processImagesFromDataProvider:error:]
-[VNMomentProcessor computeClusteringOfImageDescriptors:intoKGroups:error:]
-[VNMomentProcessor computeNaturalClusteringOfImageDescriptors:error:]
-[VNMomentProcessor computeClusteringTreeForImageDescriptors:assumeDescriptorsAreSorted:error:]
Sorting of the image list took: %3.3f ms
Computation of the hierarchical clustering took: %3.3f ms
q24@?0@"VNMPImageDescriptor"8@"VNMPImageDescriptor"16
context
T@"VNMPContext",&,N,V_context
node
T^v,V_node
freeNodeOnDealloc
TB,V_freeNodeOnDealloc
cvallocator
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/VisionKitFramework/VN/algorithm_util/memory_pools.h
pool_.current_min_size( ) >= MinAllocSize && pool_.current_max_size( ) <= MaxAllocSize && "Request size out of pool bounds"
unique_lock::unlock: not locked
operator[]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/VisionKitFramework/VN/algorithm_util/paged_allocator.h
index < size_
~paged_allocator: unclean shutdown, there are still %zu memory blocks allocated
linear_range_storage_profile
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/VisionKitFramework/VN/algorithm_util/pool_storage_profile.h
2 == std::distance(begin, end)
start_size > 0 && "Linear range storage policy seg size must be positive"
prepare_sb
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/VisionKitFramework/VN/algorithm_util/memory_pool_storage.h
qh && block_pool.qh_
hzone
alloc_block
bl->ptr_ && "Block with invalid zone"
block_for_size
blocks_.end() != found && "requested block size out of range"
can_adopt_block
blocks_.size() && blocks_.begin() != found && "freed block too small"
adopt_block
bl && bl->ptr_ && bl->size_ && qh
pixelBuffer
cgImage
ciImage
imageURL
imageData
image buffer is no longer available
%@ must be overridden
object
%@:PB=%p
: %@
%@:CG=%p
%@:CI=%p
%@:URL=%s
%@:Data=%p
toWrite: short write
***%s: unaligned file size
%s: short read
writeFloatsFd: short write
write
readFloatsFd: short read
read
readUint32Fd: short read
VNRectangleTracking_BottomLeftTracker
VNRectangleTracking_BottomRightTracker
VNRectangleTracking_TopLeftTracker
VNRectangleTracking_TopRightTracker
No objects to track passed to the tracker
setTrackedObjects finished for %s
Internal error: wrong type of a corner tracker allocated
Internal error: initialization of internal object
Internal error: Setting input rectangles to one of the rectangle corners failed
v32@?0@8@16^B24
Internal error: Tracker is not initialized
trackInFrame started for %s
Internal error: wrong type of a corner tracker object created
Internal error: tracking of one or more of the rectangle corners failed
trackInFrame finished for %s
Internal error: Resetting tracker failed with error: %llu
VNRectangleObservation object is expected to initialize Rectangle Tracker
Internal error: Tracking of one of the corners failed, confidence = %f; threshold = %f
isTracking
includeClusters
TB,N,V_includeClusters
includeAllImageIdentifiers
TB,N,V_includeAllImageIdentifiers
includeAllImageStats
TB,N,V_includeAllImageStats
  CI:follow_edges - stack increase failed
follow_edges
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/HorizonDetector/CannyEdge.c
facerec
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/ImageDescriptor/ImageDescriptorEspresso/Models/Junk/ImageDescriptor_EspressoJunk.mm
ImageDescriptor_EspressoJunk_CurrentModel
The GPU path for ImageDescriptor_EspressoJunk has been deprecated, please use only the CPU path that is as fast as the GPU one, since the network is too small
std::shared_ptr<ImageDescriptorProcessorAbstract> vision::mod::ImageDescriptor_EspressoJunk_CurrentModel(const char *, int, vision::mod::ImageDescriptorProcessorEspresso::PLATFORM, vision::mod::ImageDescriptorProcessorEspresso::COMPUTE_PATH, vision::mod::ImageDescriptorProcessorEspresso::Options)
model_junk_12_espresso
VNFaceExpressionDetectorProcessOption_InputFaceObservations
landmarkRefinerAndPupil_v2
Invalid landmark refiner model resource path
Could not read expressions model data
Could not create face expression module
VNFaceExpressionDetector face does not have landmark points
Corrupt face mark data
unexpected exception
model file is corrupt
void cvml::util::binserialized_table_of_contents::init(const void *const, size_t)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/VisionKitFramework/VN/algorithm_util/binserialized_mapped_file_contents.h
Error %s when executing %s in file %s:%d
syslog_assert_failed
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/VisionKitFramework/VN/algorithm_util/common_defines.h
Model file info populated incorrectly
void cvml::util::binserialized_contents::init_model_values(const cvml::util::binserialized_table_of_contents &, const char *, const vision::mod::BinSerializedModelFileInfo &)
data
elementsCount
length
distanceMode
labelsAndConfidence
VNSceneprint
algorithmVersion
descriptorData
T@"NSData",&,V_descriptorData
elementCount
TQ,V_elementCount
lengthInBytes
TQ,V_lengthInBytes
Tq,V_distanceMode
softmaxLabelsAndConfidence
T@"NSDictionary",&,V_softmaxLabelsAndConfidence
T@"NSString",R,V_version
VNDetectorProcessingQueueOption
invalid status code %lld
failure with status %lld
 (%s)
encountered unknown exception
encountered an unexpected condition: %s
encountered an unexpected condition: %@
NSException
dividerScore
Tf,VdividerScore
trueLocalMaximum
Ti,VtrueLocalMaximum
leftImage
Ti,VleftImage
actionAmount
Tf,VactionAmount
noiseThreshold
Tf,VnoiseThreshold
highNoiseThreshold
Tf,VhighNoiseThreshold
ASCII
%@:Algo=[%lu]
Text detector object was not created
Processing detectTextRectangles request
invalid VNRequestOptionDetectTextRectanglesRequiredVersion algorithm value of %lu
algorithm
TQ,N,V_algorithm
minimumCharacterPixelHeight
TQ,N,V_minimumCharacterPixelHeight
detectDiacritics
TB,N,V_detectDiacritics
minimizeFalseDetections
TB,N,V_minimizeFalseDetections
textRecognition
T@"NSString",C,N,V_textRecognition
reportCharacterBoxes
TB,N,V_reportCharacterBoxes
Warning: %s
Error: %s
VN_DEBUGLOG_LEVEL
unknown
Planar8: 8 bit planar
RGBA8888: 8 bit RGBA interleaved
BGRA8888: 8 bit BGRA interleaved
ARGB8888: 8 bit ARGB interleaved
ABGR8888: 8 bit ABGR interleaved
PlanarF: float 32 bit planar
RGBAFFFF: float 32 bit RGBA interleaved
BGRAFFFF: float 32 bit BGRA interleaved
ARGBFFFF: float 32 bit ARGB interleaved
ABGRFFFF: float 32 bit ABGR interleaved
Error in sgesv in parameter: %d
Diagonal element at %d is exactly zero
VNFaceLandmarkDetectorType
VNFaceDetectorType
VNFaceBoxAlignerType
VNFaceExpressionDetectorType
VNFaceprintGeneratorDetectorType
VNHumanDetectorType
VNJunkIdentifierType
VNSceneClassifierType
VNImageprintGeneratorType
com.apple.VN.faceDetectorAccurate
com.apple.VN.faceDetectorBalanced
com.apple.VN.faceDetectorFast
com.apple.VN.faceBoxAligner
com.apple.VN.faceLandmarks
com.apple.VN.faceExpressions
com.apple.VN.facePrinter
com.apple.VN.humanDetector
com.apple.VN.junkDetector
com.apple.VN.sceneDetector
com.apple.VN.imageprintGenerator
A %@ detector cannot be created
%s.txt
Error opening 
%d %d
%d %d
%.11f 
ROC=[
 %f, %f, %f; 
DET=[
 %.8f, %.8f, %.8f; 
previous request results
%@ must override %@
sumSpatialPooling
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/HumanDetector/cv/CVCommon.cpp
pooledW = sumSpatialPoolingX(pooledRespY, len, pooledResp[rIdx], r)
pooledW = sumSpatialPoolingX(pooledRespY, Ncol, ptrPooledX, r)
convTriX
w0<=w1
[&&NHX:merge_dist=
checkConsistency
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/Clustering/Clustering/NNHierarchical/NNHierarchicalClustering.cpp
nodes[i].left == -1
nodes[i].right == -1
nodes.size() == 1 || nodes[i].parent != -1
nodes[i].distance == 0.
nodes[i].left != -1
nodes[i].right != -1
(rootIndex == i) || (nodes[i].parent != -1)
nodes[i].distance > 0.
nodes[i].distance <= nodes[nodes[i].parent].distance
nodes[i].distance >= nodes[nodes[i].left].distance
nodes[i].distance >= nodes[nodes[i].right].distance
fast_index != index
the size of the distance array is not correct
addDistances
nodes.size() % 2 == 1
runningIndexCurrent[0] != -1
movingRunningIndex[0] != stayingRunningIndex[0]
movingRunningIndex[1] != stayingRunningIndex[1]
human_3_model
could not operate on buffer
loadModel
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/HumanDetector/humandetector/TemplateObjectDetectorApply.h
readFastDTreeDict
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/HumanDetector/ml/DecisionTreeApply.h
idx>=0 && idx<fastDTreeDict.size()
vision::mod::ImageDescriptorBufferFloat32::ImageDescriptorBufferFloat32(const char *)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/ImageDescriptor/ImageDescriptor_BufferFloat32.cpp
parameters
desc
virtual std::vector<float> vision::mod::ImageDescriptorBufferFloat32::computeDistancesFrom(const vision::mod::ImageDescriptorBufferAbstract &) const
Invalid number of descriptors, should be 1
virtual float vision::mod::ImageDescriptorBufferFloat32::computeDistanceFrom(const vision::mod::ImageDescriptorBufferAbstract &) const
virtual std::vector<float> vision::mod::ImageDescriptorBufferFloat32::computeSelfDistances() const
CVML_status vision::mod::ImageDescriptorBufferFloat32::computeDistanceBetweenDescriptorAndDescriptors(const float *, const float *, size_t, float *) const
computeDistanceBetweenDescriptorAndDescriptors
Unknown distance function
CVML_status vision::mod::ImageDescriptorBufferFloat32::computeDistanceBetweenDescriptors(const float *, const float *, float &) const
computeDistanceBetweenDescriptors
getRepresentative
Cannot compute the representative of an empty buffer
virtual vision::mod::ImageDescriptorBufferFloat32 *vision::mod::ImageDescriptorBufferFloat32::getRepresentative(vision::mod::ImageDescriptorBufferAbstractRepresentativeMode, ImageDescriptorId) const
Unknown representative mode
void vision::mod::descriptorBufferPackScores(vision::mod::ImageDescriptorBufferFloat32 *, const std::vector<float> &)
std::shared_ptr<ImageDescriptorBufferFloat32> vision::mod::descriptorBufferUnpackedScores(const vision::mod::ImageDescriptorBufferFloat32 &, std::vector<float> &, size_t)
 = [
CVML_status Face3D_estimateCameraProjective(const Geometry2D_cart2D &, const Geometry3D_cart3D &, const float *, Geometry3D_pose &)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/Face3D/Face3D_Core.cpp
CVML_status Face3D_estimateShapeProjective(const Geometry2D_cart2D &, const float *, const float *, int, const float *, const Geometry3D_pose &, float *)
CVML_status Face3D_updateShape(const float *, const float *, const float *, int, Geometry3D_cart3D &)
CVML_status Face3D_computeReprojectionError(const Geometry2D_cart2D &, const Geometry3D_cart3D &, const float *, const Geometry3D_pose &, float &)
faceprintSimilarityThreshold
numAtomsPerID
tolerance
maxIterations
sqrtAlpha
sqrtBeta
scdType
kMinIDsToEnroll
kMaxIDsToEnroll
kMinFacesPerID
kMaxFacesPerId
kFacePrintDimensionalityParamName
kIDToLabelLUTParamName
kDictionaryIDsParamName
kDictionaryValuesParamName
kDictionaryClassfiersParamName
At X0, %ld variables are exactly at the bounds
Cauchy X = 
%5.2e 
There are %ld breakpoints
Piece %ld --f1, f2 at start point %.2e %.2e
Distance to the next break point = %.2e
Distance to the stationary point = %.2e
Variable %ld is fixed
GCP found in this segment. Piece %ld --f1, f2 at start point %.2e %.2e
Variable %ld leaves the set of free variables
%ld variables leave; %ld variables enter
%ld variables are free at GCP iter %ld
This problem is unconstrained
The initial X is infeasible. Restart with its projection
-------------- exit CAUCHY -----------
CAUCHY entered
Subnorm = 0. GCP = X.
----------------- exit SUBSM --------------
Positive dir derivative in projection 
Using the backtracking step
---------------SUBSM entered---------
 vs. 
Features not in ascending sorted order.
Wrong format for input data:
Empty example string.
Class label must be real number.
Processing ClusterObservations request
Existing clustering context is invalid
CVML_status ImageProcessing_getBytesPerPixelFromImageType(ImageProcessing_ImageType, size_t *)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/ImageProcessing/ImageProcessing_Utils.c
CVML_status ImageProcessing_reallocVImageBuffer(vImage_Buffer *, vImagePixelCount, vImagePixelCount, size_t)
ImageProcessing_reallocVImageBuffer
Reallocating %ld bytes -> %ld bytes
CVML_status ImageProcessing_copyVImageBufferData(const vImage_Buffer *, size_t, vImage_Buffer *)
CVML_status ImageProcessing_loadInfo(const char *, vImage_Buffer *, ImageProcessing_ImageType *, uint32_t *)
CVML_status ImageProcessing_load(const char *, _Bool, vImage_Buffer *, ImageProcessing_ImageType *)
CVML_status ImageProcessing_save(const char *, const vImage_Buffer *, ImageProcessing_ImageType)
CVML_status ImageProcessing_loadInfoFromFileHandle(FILE *, vImage_Buffer *, ImageProcessing_ImageType *, uint32_t *)
yyyy:MM:dd HH:mm:ss
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/Kmeans/Kmeans.cpp
Kmeans_descriptorBuffer
WARNING: Kmeans supports only Euclidean distance!
ERROR: the output buffer size mismatches on number of clusters
ERROR: the output buffer size mismatches on feature dimension
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/Kmeans/Kmeans_Abstract.h
ERROR: invalid parameters in kmeans
kmeans++
ERROR: only kmeans++ is supported for initialization
ERROR: memory allocation failure in kmeans
is_mean_computed and allocate cannot be true together
vector length < cols
vector length < rows
invalid axis value, axis must be either 0 or 1
invalid axis value: axis must be 0 or 1
broadcast op: dimension mismatch
unknown axis value
dimensions of data points mismatch
output distance matrix too small
col index out of range
empty cumsum vector
kmeansSingle_
ERROR: precompute flag not implemented
labelEstimation_
output matrix size too small
WARNING: failed to compute ranking %@
CVML_status ImageProcessing_computeTilingParametersSimple(const vImage_Buffer *, size_t, int, vImagePixelCount, vImage_Buffer *, vImagePixelCount *, vImagePixelCount *)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/ImageProcessing/ImageProcessing_Tiling.c
CVML_status ImageProcessing_computeTilingParameters(const vImage_Buffer *, size_t, int, int, vImagePixelCount, vImagePixelCount, vImage_Buffer *, vImagePixelCount *, vImagePixelCount *)
CVML_status ImageProcessing_tileImage(const vImage_Buffer *, size_t, vImagePixelCount, vImagePixelCount, vImagePixelCount, vImagePixelCount, vImage_Buffer ***, int *, int *)
CVML_status ImageProcessing_computeSegmentTiling(vImagePixelCount, vImagePixelCount, int, vImagePixelCount *, vImagePixelCount *)
CVML_status Geometry3D_POSIT(const Geometry2D_cart2D *, const Geometry3D_cart3D *, const float *, float *, float *)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/Geometry3D/Geometry3D_POSIT.c
CVML_status Geometry3D_POSIT_getR1AndR2(__CLPK_real *, __CLPK_real *, __CLPK_integer, float *, float *)
The %d argument had an illegal value.
The %d-th diagonal element of the triangular factor of A is zero, so that A does not have full rank; the least squares solution could not be computed.
CVML_status Geometry2D_computeMinimumAlignedBoundingBox(const Geometry2D_cart2D *, Geometry2D_rect2D *)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/Geometry2D/Geometry2D_Regions.c
CVML_status Geometry2D_isInsideTriangle(const Geometry2D_cart2D *, const Geometry2D_cart2D *, _Bool *, int *)
CVML_status Geometry2D_isInsideRect(const Geometry2D_cart2D *, const Geometry2D_rect2D *, _Bool *, int *)
CVML_status ctpl_setupTrackerWithReferenceFrame(s_tplTracker *, CVPixelBufferRef, float, float, float, float)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/ObjectTracker/temporalEx/cTemplateTrackerFuncs.c
CVML_status ctpl_trackInFrame(s_tplTracker *, const CVPixelBufferRef)
vision::mod::ImageClassifier_HierarchicalModel::ImageClassifier_HierarchicalModel(const char *, const char *, const std::vector<std::string> &)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/ImageClassifier/ImageClassifier_HierarchicalModel.cpp
vision::mod::ImageClassifier_HierarchicalModel::ImageClassifier_HierarchicalModel(const char *, const char *, const std::vector<std::pair<std::string, bool> > &)
verifyClassificationMapCorrectness
ERROR: Invalid node label 
 found in the node probabilities map
void vision::mod::ImageClassifier_HierarchicalModel::verifyClassificationMapCorrectness(const std::map<std::string, float> &)
ERROR: the graph basic node 
 is not present in the node probabilities map
filterGraphForBasicNodes
ERROR: Invalid basic node label 
 found
void vision::mod::ImageClassfier_Graph::filterGraphForBasicNodes(const std::vector<std::pair<std::string, ImageClassfier_GraphNodeType> > &, bool)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/ImageClassifier/ImageClassifier_IO.cpp
ImageClassifier_loadLabelsAndBooleanFlag
The requested flag is not present
std::vector<std::pair<std::string, bool> > ImageClassifier_loadLabelsAndBooleanFlag(const char *, const char *, int)
ImageClassifier_loadLabelsBooleanFlagAndConfidenceThreshold
std::vector<std::tuple<std::string, bool, float> > ImageClassifier_loadLabelsBooleanFlagAndConfidenceThreshold(const char *, const char *, int)
\s*([^\s]+)\s*->\s*([^\s]+)\s*
ImageClassifier_loadRelations
Could not parse the relation file
std::vector<std::pair<std::string, std::string> > ImageClassifier_loadRelations(const char *, const char *)
std::vector<std::string> ImageClassifier_readLinesFromFile(const char *, const char *)
true
ImageClassifier_stringToBool
Could not parse boolean flag 
 in the labels file
bool ImageClassifier_stringToBool(const std::string &)
numCoeffs=%u coeffs={
%12.5e
} indices={
%llu
***PerThreadLearn: malloc failure
Malloc failure
***SCDict::initLearn: error in updateDictionary
***SCDict::initFromFile: file not blockSize-aligned
***SCDict::initFromFile: unexpected file size
   expected %llu floats; read %llu floats
***SCDict::writeToFile: no dictionary to write
***SCDict::writeToDictWriter: no dictionary to write
***SCDict::initFromArray: file not blockSize-aligned
***SCDict::allocDict: no dictionary size specified
***SCDict: malloc failure; dictionary size %llu bytes
***SCDict: Internal error in allocScratch
***SCDict::allocScratch: malloc failure; bufsize %llu bytes
***SCDict::encodeBlock: error in getCoeffs
Not enough features to build dictionary. Required >= %d, got only %d
all zero sparse code 
Fatal error: memory allocation failure for scratch buffer
v32@?0@"NSString"8@"NSString"16^B24
Unable to obtain the supported barcode symbologies
%@:Symb=[%@]
VNDetectBarcodesLocateModeCenterOneVertical
VNDetectBarcodesLocateModeCenterOneVerticalThick
VNDetectBarcodesLocateModeCenterThreeVertical
VNDetectBarcodesLocateModeCenterThreeVerticalCrossed
VNDetectBarcodesLocateModeCenterOneHorizontal
VNDetectBarcodesLocateModeCenterOneHorizontalThick
VNDetectBarcodesLocateModeCenterThreeHorizontal
VNDetectBarcodesLocateModeCenterThreeHorizontalCrossed
VNDetectBarcodesLocateModeCenterOneEachDirection
VNDetectBarcodesLocateModeCenterThreeEachDirection
VNDetectBarcodesLocateModeCenterFiveEachDirection
VNDetectBarcodesLocateModeCenterThreeEachDirectionAndCoverageAndDiagonals
VNDetectBarcodesLocateModeCenterThreeVerticalAndCoverageAndDiagonals
VNDetectBarcodesLocateModeCenterThreeHorizontalAndCoverageAndDiagonals
VNDetectBarcodesLocateModeFastSearch
VNDetectBarcodesLocateModeRegularIntervalHorizontal
VNDetectBarcodesLocateModeRegularIntervalVertical
%@ is not a supported barcode symbology
barcode type is not available
unknown barcode type of '%@'
_new%@DescriptorForACBSBarcodeInfo:
creation of a barcode descriptor for %@ is not supported
VNDetectBarcodesRequest
unable to create a barcode descriptor for %@
barcode location is not available
failed to analyze image
supportedSymbologies
locateMode
T@"NSString",C,N,V_locateMode
symbologies
T@"NSArray",C,N
CVML_status Geometry2D_normalizePoints(const Geometry2D_cart2D *, float *, Geometry2D_cart2D *, float *, float *, float *)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/Geometry2D/Geometry2D_Normalization.c
VNObjectTrackerType
VNFaceTrackerType
VNRectangleTrackerType
v32@?0@"NSUUID"8@"VNTracker"16^B24
com.apple.VN.trackersCollectionManagementQueue
com.apple.VN.trackingProcessingQueue
Cannot create a Tracker with unknown tracker type: %@
A tracker cannot be created without specifying a unique tracker key
Internal error: Exceeded maximum allowed number of Trackers for a tracker type: %@
CVML_status ImageProcessing_warpTriangle_Planar8(const vImage_Buffer *, const Geometry2D_cart2D *, const Geometry2D_cart2D *, dispatch_queue_t, vImage_Buffer *)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/ImageProcessing/ImageProcessing_Warp.c
CVML_status ImageProcessing_warpImageRST_Planar8(const vImage_Buffer *, const Geometry2D_RST *, dispatch_queue_t, vImage_Buffer *)
CVML_status ImageProcessing_warpImageRST_Planar8(const vImage_Buffer *, const Geometry2D_RST *, dispatch_queue_t, vImage_Buffer *)_block_invoke
***SDFWriter::writeHeader failure
***SDFReader::SDFReader: bad header
Bad SDFHeader
-[VNMPImageData initWithVImage:externalImageId:andExifTimestampValue:error:]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/MomentProcessor/Moments/MPImageData.m
ERROR: The input image does not seem to be 8888
-[VNMPImageData initWithCVPixelBufferImage:externalImageId:andExifTimestampValue:error:]
image
T^{vImage_Buffer=^vQQQ},R,V_image
imageCVPixelBuffer
T^{__CVBuffer=},R,V_imageCVPixelBuffer
imageFilePath
T@"NSString",&,V_imageFilePath
freeImageInDealloc
TB,V_freeImageInDealloc
externalImageId
T@"NSString",R,V_externalImageId
exifTimestamp
Tq,R,V_exifTimestamp
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/LandmarkDetector/LandmarkDetector.cpp
ERROR: Mean shape coordinates not specified to landmark detector constructor!
void vision::mod::LandmarkDetector::init(const vision::mod::ModelValues &, const char *)
ERROR: Could not allocate meanShape container
ERROR: Could not allocate meanShapeAligned container
void vision::mod::LandmarkDetector::preProcessImage(const vImage_Buffer &, const Geometry2D_rect2D &)
CVML_status vision::mod::LandmarkDetector::initMeanShapeWithDCNLandmarks(const std::vector<Geometry2D_point2D> &)
CVML_status vision::mod::LandmarkDetector::initMeanShapeWithLandmarks(const std::vector<Geometry2D_point2D> &, const LandmarkDetector_initializationMode)
CVML_status vision::mod::LandmarkDetector::initMeanShapeWithEyeTiltAngle(float)
std::vector<Geometry2D_point2D> vision::mod::LandmarkDetector::detectLandmarksCore(int, int)
detectLandmarksCore
ERROR: Could not instantiate perturbation
ERROR: could not compute the minimum aligned bounding box (
ERROR: could not allocate meanShapePerturbed
ERROR: could not allocate meanShapeAlignedPerturbed
/dev/urandom
ERROR: could not allocate predShape
ERROR: could not allocate vx container
ERROR: could not allocate vy container
%@:rm=%d,rle=%d,rre=%d,bd=%d,cs=%@
Processing DetectFaceLandmarks request
refineMouthRegion
TB,N,V_refineMouthRegion
refineLeftEyeRegion
TB,N,V_refineLeftEyeRegion
refineRightEyeRegion
TB,N,V_refineRightEyeRegion
performBlinkDetection
TB,N,V_performBlinkDetection
cascadeStepCount
T@"NSNumber",&,N,V_cascadeStepCount
VNIp
ipType
MPImDesc
VNIpDescColGaborV
Failed to initialize VNImageprint object
state cannot be nil
Invalid format of VNImageprint serialized state
Failed to calculate MD5
Serialized and calculated MD5s don't match
Unexpected size of deserialized state of the object of type %@
otherImageprint cannot be nil
unexpected error while calculating distance between faceprints
faceprints with invalid data supplied
could not compute faceprint distance
Unexpected size of serialized state of the object of type %@
serializedLength
TQ,R,N
currentVersion
descriptor
T@"VNMPImageDescriptor",&,N,V_descriptor
type
TQ,N,V_type
TQ,N,V_version
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/ImageDescriptor/ImageDescriptorEspresso/ImageDescriptor_Espresso.mm
ImageDescriptorProcessorEspresso
ERROR: Network not present
vision::mod::ImageDescriptorProcessorEspresso::ImageDescriptorProcessorEspresso(vision::mod::ImageDescriptorProcessorEspresso::Options, const std::shared_ptr<Espresso::net> &, vision::mod::ImageDescriptorProcessorEspresso::PLATFORM, vision::mod::ImageDescriptorProcessorEspresso::COMPUTE_PATH)
ERROR: The network layer size is zero
ERROR: Could not load network from %s
vision::mod::ImageDescriptorProcessorEspresso::ImageDescriptorProcessorEspresso(vision::mod::ImageDescriptorProcessorEspresso::Options, const char *, const char *, int, int, int, int, vision::mod::ImageDescriptorProcessorEspresso::PLATFORM, vision::mod::ImageDescriptorProcessorEspresso::COMPUTE_PATH)
vision::mod::ImageDescriptorProcessorEspresso::ImageDescriptorProcessorEspresso(vision::mod::ImageDescriptorProcessorEspresso::Options, const char *, const char *, vision::mod::ImageDescriptorProcessorEspresso::PLATFORM, vision::mod::ImageDescriptorProcessorEspresso::COMPUTE_PATH)
setNetworkBatchNumber
ImageDescriptorProcessorEspresso::setNetworkBatchNumber nBatch>0
void vision::mod::ImageDescriptorProcessorEspresso::setNetworkBatchNumber(int)
conv6a
CVML_status vision::mod::ImageDescriptorProcessorEspresso::private_t::compute_batch(vision::mod::ImageDescriptorProcessorEspresso *, const std::vector<vImage_Buffer> &, const int, float *, const Espresso::vimage2espresso_param &)
virtual CVML_status vision::mod::ImageDescriptorProcessorEspresso::computeDescriptorForImage_RGBA8888(const vImage_Buffer &, vision::mod::ImageDescriptorBufferAbstract &)
virtual CVML_status vision::mod::ImageDescriptorProcessorEspresso::computeDescriptorForImage_BGRA8888(const vImage_Buffer &, vision::mod::ImageDescriptorBufferAbstract &)
computeDescriptorForImage_XYZA8888
The number of images submitted to batch compute the descriptors is less than the size of the internal Espresso network batch size (resulting in a waste of memory and computation)
CVML_status vision::mod::ImageDescriptorProcessorEspresso::computeDescriptorForImage_XYZA8888(const vImage_Buffer &, vision::mod::ImageDescriptorBufferAbstract &, bool)
virtual CVML_status vision::mod::ImageDescriptorProcessorEspresso::computeDescriptorForImage_Planar8(const vImage_Buffer &, vision::mod::ImageDescriptorBufferAbstract &)
computeDescriptorForImage_Planar8
virtual CVML_status vision::mod::ImageDescriptorProcessorEspresso::computeDescriptorForAugmentedImage(const vImage_Buffer &, ImageProcessing_ImageType, vision::mod::ImageDescriptorAugmenterAbstract &, vision::mod::ImageDescriptorBufferAbstract &)
virtual CVML_status vision::mod::ImageDescriptorProcessorEspresso::computeDescriptorsForImages_RGBA8888(const std::vector<vImage_Buffer> &, vision::mod::ImageDescriptorBufferAbstract &)
virtual CVML_status vision::mod::ImageDescriptorProcessorEspresso::computeDescriptorsForImages_BGRA8888(const std::vector<vImage_Buffer> &, vision::mod::ImageDescriptorBufferAbstract &)
computeDescriptorsForImages_XYZA8888
CVML_status vision::mod::ImageDescriptorProcessorEspresso::computeDescriptorsForImages_XYZA8888(const std::vector<vImage_Buffer> &, vision::mod::ImageDescriptorBufferAbstract &, bool)
virtual CVML_status vision::mod::ImageDescriptorProcessorEspresso::computeDescriptorsForImages_Planar8(const std::vector<vImage_Buffer> &, vision::mod::ImageDescriptorBufferAbstract &)
computeDescriptorsForImages_Planar8
Inconsistent state
virtual CVML_status vision::mod::ImageDescriptorProcessorAbstract::computeDescriptorForAugmentedImage(const vImage_Buffer &, ImageProcessing_ImageType, vision::mod::ImageDescriptorAugmenterAbstract &, vision::mod::ImageDescriptorBufferAbstract &)
CVML_status vision::mod::ImageDescriptorAugmenterAbstract::augment(const vImage_Buffer &, ImageProcessing_ImageType)
CVML_status Geometry2D_estimateAffine(const Geometry2D_cart2D *, const Geometry2D_cart2D *, Geometry2D_Affine *)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/Geometry2D/Geometry2D_Affine.c
CVML_status Geometry2D_mapAffine(const Geometry2D_cart2D *, const Geometry2D_Affine *, Geometry2D_cart2D *)
CVML_status Geometry2D_mapPointAffine(const Geometry2D_point2D *, const Geometry2D_Affine *, Geometry2D_point2D *)
VNFaceGeometryEstimatorInitOption_ImageSize
VNFaceGeometryEstimatorInitOption_CameraFocalLength
VNFaceGeometryEstimatorProcessOption_EstimatePoseOnly
VNFaceGeometryEstimatorProcessOption_InputFaceObservation
eigenshape-current
***sdfWriteDicts: SDFWriter.writeHeader error
***sdfWriteDicts: SCDict.writeToDictWriter error
***sdfReadDicts: bad magic number
***sdfReadDicts: bad dictionary size/position info
dictionary
***sdfReadDicts: bad dictionary
lseek
VNFaceRegionMapGeneratorProcessOption_InputFaceObservations
faceRegionMap-current
[%g %g %g %g %g %g]
'%@' is not a valid CGAffineTransform encoding
3x3:|%g %g %g %g %g %g %g %g %g|
3x3:|
'%@' is not a valid matrix_float3x3 encoding
4x4:|%g %g %g %g %g %g %g %g %g %g %g %g %g %g %g %g|
4x4:|
'%@' is not a valid matrix_float4x4 encoding
VNObservation
uuid
confidence
 %@ %g
T@"NSUUID",&,N,SsetUUID:,V_uuid
Tf,N,V_confidence
VNDetectedObjectObservation
 [%g %g %g %g]
boundingBox
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_boundingBox
identifier
T@"NSUUID",C
VNFaceprint
profile
platform
Attempt to deserialize nil
Input data is not a VNFaceprint
Input State is not a VNFaceprint
Error computing checksum
Checksum mismatch.  State is corrupt
faceprint
Error deserializing VNFaceprint
Attempt to write out nil faceprint.
Attempt to write out corrupt faceprint.
Could not allocate serialized data
Checksum calculation failed
nil faceprint(s) supplied
faceprint(s) with nil key property supplied
faceprints with different length supplied
faceprints with different versions supplied
T@"NSData",&,N
T@"NSData",&,N,V_faceprint
T@"NSString",C,N,V_key
TI,N,V_platform
TI,N,V_profile
faceprintInputPath
T@"NSString",C,N,V_faceprintInputPath
VNFaceObservation
alignedBBX
alignedBBY
alignedBBW
alignedBBH
landmarks
landmarks3D
pose
expressions
faceID
faceIDConfidence
hasAlignedBBox
alignedRotAngle
faceRegionMap
blinking
blinkScore
alignedMeanShape
landmarksScore
faceOrientationIndex
faceJunkinessIndex
invalid pose data
 ID=%lu
 landmarks %g
T@"VNFaceLandmarks2D",&,N,V_landmarks
hasBBoxBeenAligned
TB,N,V_hasBBoxBeenAligned
alignedBoundingBox
T{_Geometry2D_rect2D_={_Geometry2D_point2D_=ff}{_Geometry2D_size2D_=ff}},N,V_alignedBoundingBox
alignedRotationAngle
Tf,N,V_alignedRotationAngle
landmarkPoints
T@"NSData",&,N,V_landmarkPoints
landmarkPoints3d
T@"NSData",&,N,V_landmarkPoints3d
poseData
T@"NSData",&,N,V_poseData
faceIdConfidence
Tf,N,V_faceIdConfidence
T@"NSData",&,N,V_alignedMeanShape
landmarks3d
T@"VNFaceLandmarks3D",R,N
T@"VNFaceRegionMap",R,N,V_faceRegionMap
expressionsAndConfidence
T@"NSDictionary",R,C,N
T{?=[4]},R,N
nameConfidence
Tf,R,N
TQ,N,V_faceId
T@"VNFaceprint",&,N,V_faceprint
Tf,R
Tf,R,N,GfaceJunkinessIndex
Tf,R,N,GfaceOrientationIndex
referenceImageSignature
floatingImageSignature
%@ is not supported by %@
T@"VNImageRegistrationSignature",&,N,V_referenceImageSignature
T@"VNImageRegistrationSignature",&,N,V_floatingImageSignature
alignmentTransform
T{CGAffineTransform=dddddd},N
 [%g %g %g %g %g %g]
T{CGAffineTransform=dddddd},N,V_alignmentTransform
warpTransform
T{?=[3]},N,V_warpTransform
blur
exposure
blurScore
T@"NSNumber",&,N,V_blurScore
exposureScore
T@"NSNumber",&,N,V_exposureScore
VNImageprintObservation
VNImageprint
nil imageprint supplied
Failed creating a new VNImageprintObservation object
imageprint
T@"VNImageprint",&,N,V_imageprint
T@"NSUUID",C,N
imageprintValid
TB,R,N,V_imageprintValid
imageprintVersion
T@"NSString",R,C,N,V_imageprintVersion
rawImageprintDescriptor
T@"NSData",R,N
 "%@" (%f)
T@"NSString",R,C,N,V_identifier
featureValue
T@"MLFeatureValue",R,C,N,V_featureValue
T^{__CVBuffer=},R,N,V_pixelBuffer
topLeft
T{CGPoint=dd},N,V_topLeft
topRight
T{CGPoint=dd},N,V_topRight
bottomLeft
T{CGPoint=dd},N,V_bottomLeft
bottomRight
T{CGPoint=dd},N,V_bottomRight
transform
angle
T{CGAffineTransform=dddddd},N,V_transform
Td,N,V_angle
  clusterId = %lu;
  totalObjCount = %lu;
  objects = %@;
  shouldUpdateRep = %d;
  suggestedIdsForRep = %@;
  representativenessById = %@;
objects
T@"NSArray",&,N,V_objects
clusterId
TQ,N,V_clusterId
totalObjectCount
TQ,N,V_totalObjectCount
shouldUpdateRepresentative
TB,N,V_shouldUpdateRepresentative
suggestedIdsForRepresentative
T@"NSArray",&,N,V_suggestedIdsForRepresentative
representativenessById
T@"NSDictionary",&,N,V_representativenessById
clusters
suggestions
clusterState
clusteredFaceIDs
groupedClusteredFaceIDs
level0Distance
distancesByID
T@"NSArray",&,N,V_clusters
suggestionsForCluster
T@"NSArray",&,N,V_suggestionsForCluster
T@"NSData",&,N,V_clusterState
T@"NSSet",&,N,V_clusteredFaceIds
groupedClusteredFaceIdsForCluster
T@"NSArray",&,N,V_groupedClusteredFaceIdsForCluster
distance
T@"NSNumber",&,N,V_distance
distancesById
T@"NSDictionary",&,N,V_distancesById
VNSceneObservation
algo
descriptors
Undefined
Major component of encoded sceneprint is different than major component currently supported by software. The sceneprint object cannot be decoded.
Minor component of encoded sceneprint is different than minor component currently supported by software.
sceneprints
T@"NSArray",C,N,V_sceneprints
sceneprintVersion
T@"NSString",R,C,N,V_sceneprintVersion
allImages
bestImages
imageStats
coverImage
isAction
isPortrait
allImageIdentifiers
T@"NSArray",&,N,V_allImageIdentifiers
bestImageIdentifiers
T@"NSArray",&,N,V_bestImageIdentifiers
allImageStats
T@"NSDictionary",&,N,V_allImageStats
coverImageIdentifier
T@"NSString",&,N,V_coverImageIdentifier
TB,N,V_isAction
TB,N,V_isPortrait
characterBoxes
text
T@"NSString",R,C,N
symbology
barcodeDescriptor
T@"NSString",R,C,N,V_symbology
T@"CIBarcodeDescriptor",R,N,V_barcodeDescriptor
horizonDetector: props exist
horizonDetector: Orientation = %d
  Found makerNotes
    Found vector: %.3f,%.3f,%.3f
acc = (%.5f, %.5f, %.5f)
accelTilt = %.3f deg, accelPitch = %.3f deg, accMagnitudeDev %.3f
accelPitch = %.3f deg, accelMagnitudeDev = %.3f
MaxPitch = %.3f, MaxPixelTilt = %.3f, MinPixelTilt = %.3f, MaxAccelMagDev = %.3f, MaxAccelFFTDifff = %.3f
FFT detected angle = %.3f deg
***SCDictKSVD::updateAtom: gesdd() error
KSVD
Processing DetectFacePose request
Processing getDistances request
T@"NSArray",R,C,N,V_clusterIDs
%@:RoI=%g,%g,%g,%g:InFace[%@]
B32@?0@"VNFaceObservation"8Q16^B24
regionOfInterest
T{CGRect={CGPoint=dd}{CGSize=dd}},N
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/SimilarityMatrix/SimilarityMatrix/SimilarityMatrix_Full.cpp
setDistanceBetweenDescriptorIndexes
ERROR: Cannot set distance other than 0.0 between a given descriptor and itself - descriptor indexes passed to the setDistance method cannot be equal
addDescriptors
ERROR: Descriptor added to the similarity matrix needs to contain id values
ERROR: Could not append descriptors, error in module: %s, error description: %s
virtual CVML_status vision::mod::SimilarityMatrixFull::deleteDescriptorsWithIds(const std::vector<ImageDescriptorId> &)
CVML_status Geometry2D_cartToHomo2D(const Geometry2D_cart2D *, Geometry2D_homo2D *)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/Geometry2D/Geometry2D_Homogeneous.c
CVML_status Geometry2D_homoToCart2D(const Geometry2D_homo2D *, Geometry2D_cart2D *)
CVML_status Geometry2D_estimateHomography(const Geometry2D_cart2D *, const Geometry2D_cart2D *, float *)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/Geometry2D/Geometry2D_Homography.c
CVML_status Geometry2D_mapHomography(const Geometry2D_cart2D *, const float *, Geometry2D_cart2D *)
CVML_status Geometry2D_mapPointHomography(const Geometry2D_point2D *, const float *, Geometry2D_point2D *)
CVML_status Geometry2D_estimateHomographyMSS(const Geometry2D_cart2D *, const Geometry2D_cart2D *, float *, __CLPK_integer, float *)
CVML_status Geometry2D_estimateHomographyOD(const Geometry2D_cart2D *, const Geometry2D_cart2D *, float *, __CLPK_integer, float *)
pred
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/HumanDetector/ml/AdaBoostApply.cpp
weakModels.size()
predCal
CVML_status Geometry2D_estimateRST(const Geometry2D_cart2D *, const Geometry2D_cart2D *, Geometry2D_RST *)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/Geometry2D/Geometry2D_RST.c
CVML_status Geometry2D_mapRST(const Geometry2D_cart2D *, const Geometry2D_RST *, Geometry2D_cart2D *)
CVML_status Geometry2D_mapPointRST(const Geometry2D_point2D *, const Geometry2D_RST *, Geometry2D_point2D *)
InitializeWithKRandomCenters
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/DictionaryLearning/LCKSVD/sofia-ml-read-only/cluster-src/sf-kmeans-methods.cc
k > 0 && k <= data_set.NumExamples()
SamplingFarthestFirst
ClassicKmeansPlusPlus
No unique points left for cluster centers.
OptimizedKmeansPlusPlus
OptimizedKmeansPlusPlusTI
SamplingKmeansPlusPlus
sample_size > 0
OneBatchKmeansOptimization
cluster_centers->Size() > 0
SfClusterCenters
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/DictionaryLearning/LCKSVD/sofia-ml-read-only/cluster-src/sf-cluster-centers.cc
dimensionality_ >= 0
num_clusters >= 0
Error reading file 
SqDistanceToCenterId
center_id >= 0 && static_cast<unsigned int>(center_id) < cluster_centers_.size()
SqDistanceToClosestCenter
!cluster_centers_.empty()
closest_center_id != NULL
ClusterCenterMappingType 
not supported.
CVML_status Geometry3D_cumulativeEuclideanDistanceCart3D(const Geometry3D_cart3D *, const Geometry3D_cart3D *, float *)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/Geometry3D/Geometry3D_Distances.c
VNImageGrouperProcessOption_Threshold
VNImageGrouperProcessOption_AdjustDistancesWithTimestamp
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/Clustering/Clustering/Clustering_Abstract.cpp
addDescriptor
Descriptor already clustered, skipping (descriptor id: %d)
virtual CVML_status vision::mod::ClusteringAbstract::addDescriptor(ImageDescriptorId, vision::mod::SimilarityMatrixAbstract &)
float8
float16
float32
float64
double8
double16
double32
double64
byte
CVML_status BinSerializer_bseek(void *, size_t, const char *, void **)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/BinSerializer/BinSerializer_Core.c
CVML_status BinSerializer_fseek(FILE *, const char *)
CVML_status BinSerializer_fgetInfoStr(FILE *, char **)
%d) hash: %lld, type: %s, min: %g, max: %g, number of values: %llu, blob size: %s
CVML_status BinSerializer_getInfoStr(const char *, char **)
CVML_status BinSerializer_bgetBlobInfo(void *, const char *, uint64_t *, uint16_t *, double *, double *, uint64_t *)
CVML_status BinSerializer_fgetBlobInfo(FILE *, const char *, uint64_t *, uint16_t *, double *, double *, uint64_t *)
CVML_status BinSerializer_getBlobInfo(const char *, const char *, uint64_t *, uint16_t *, double *, double *, uint64_t *)
CVML_status BinSerializer_frenameBlob(FILE *, const char *, const char *)
CVML_status BinSerializer_renameBlob(const char *, const char *, const char *)
CVML_status BinSerializer_freadInBytes(FILE *, const char *, _Bool, void **, size_t *)
CVML_status BinSerializer_breadInFloat(void *, size_t, const char *, _Bool, float **, size_t *)
CVML_status BinSerializer_freadInFloat(FILE *, const char *, _Bool, float **, size_t *)
CVML_status BinSerializer_writeBytes(const char *, const char *, const void *, size_t)
CVML_status BinSerializer_writeFloatToFloat32(const char *, const char *, const float *, size_t)
CVML_status BinSerializer_writeFloatToFloat16(const char *, const char *, const float *, size_t)
CVML_status BinSerializer_writeFloatToFloat8(const char *, const char *, const float *, size_t)
char *BinSerializer_getBlobSizeDescription(BinSerializer_blobHeader *, CVML_status *)
%llu %s
%.1f %s
bytes
CVML_status BinSerializer_fwrite(FILE *, const char *, BinSerializer_dataType, const void *, size_t)
CVML_status BinSerializer_fwrite_float(FILE *, const char *, BinSerializer_dataType, const float *, size_t)
_Bool LandmarkDetector_generateNormalizedFaceMesh63Landmarks(const Geometry2D_point2D *, const Geometry2D_size2D *, Geometry2D_cart2D *)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/LandmarkDetector/LandmarkDetector_Mesh.c
initializeSpanList
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/RectangleDetector/QuadDetect/Spans.c
spl != NULL
createSpanList
resetSpanList
addSpan
mergeSpans
(startIndex >= 0) && (endIndex >= 0) && (startIndex <= endIndex) && (startIndex < spl->nSpans) && (endIndex < spl->nSpans)
CVML_status vision::mod::ColorImageDescriptorProcessor::computeDescriptorForImage_RGBA8888(const vImage_Buffer &, float *)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/ImageDescriptor/ImageDescriptorColor/ColorImageDescriptor.cpp
virtual CVML_status vision::mod::ColorImageDescriptorProcessor::computeDescriptorsForImages_RGBA8888(const std::vector<vImage_Buffer> &, vision::mod::ImageDescriptorBufferAbstract &)
CVML_status vision::mod::ColorImageDescriptorProcessor::computeSamplingGrid(vImagePixelCount, vImagePixelCount, std::vector<vImagePixelCount> &, int *, std::vector<vImagePixelCount> &, int *)
CVML_status vision::mod::ColorImageDescriptorProcessor::computeHistogram(const vImage_Buffer &, int, vImagePixelCount, vImagePixelCount, vImagePixelCount, vImagePixelCount, float *)
computeDescriptorForImage_BGRA8888
ERROR: This descriptor processor does not know how to handle BGRA8888 images
virtual CVML_status vision::mod::ColorImageDescriptorProcessor::computeDescriptorForImage_Planar8(const vImage_Buffer &, vision::mod::ImageDescriptorBufferAbstract &)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/ImageDescriptor/ImageDescriptorColor/ColorImageDescriptor.h
virtual CVML_status vision::mod::ImageDescriptorProcessorAbstract::computeDescriptorsForImages_BGRA8888(const std::vector<vImage_Buffer> &, vision::mod::ImageDescriptorBufferAbstract &)
virtual CVML_status vision::mod::ColorImageDescriptorProcessor::computeDescriptorsForImages_Planar8(const std::vector<vImage_Buffer> &, vision::mod::ImageDescriptorBufferAbstract &)
setPriority
virtual std::vector<float> vision::mod::ColorImageDescriptorBuffer::computeSelfDistances() const
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/FaceID2/FaceID.cpp
searchUpdatedLabels_
ERROR: size mismatch
initDict_
ERROR: incomplete labelInfo
ERROR: dimension or stride mismatch
ERROR: size or stride mismatch
buildSubDictionary_
ERROR: dimension mismatch between input data and global dictionary
ERROR: index out of range
ERROR: kmeans error
ERROR: duplicated labels detected when build sub-dictionary
shrinkD_
ERROR: stride mismatch
checkTrainingParams_
ERROR: negative or zero minElems_
ERROR: negative or zero maxNumIds_
ERROR: negative or zero minNumIds_
ERROR: negative or zero maxIter_
ERROR: negative or zero nInits_ in kmeans
ERROR: invalid tol_ in kmeans
buildModel
ERROR: invalid image descriptor buffer for training
ERROR: size mismatch between descriptors and their labels
ERROR: error happened in searching updated labels
ERROR: error happened in initializing global dictionary
ERROR: error happened in building subdictionary
ERROR: size mismatch in the end: bad memory access
ERROR: an unexpected exception thrown
ERROR: memory allocation error
checkTestingParams_
ERROR: empty usedIds_
ERROR: negative or zero sparsity
ERROR: empty dictionary D_
ERROR: empty dictionary labels
ERROR: invalid image descriptor buffer
ERROR: error happened in sparse coding
ERROR: unexpected exception thrown
ERROR: memory allocation failed
FaceIDModel_v1_d16
deserialize
ERROR: incorrect header
ERROR: rows,cols,stride do not make sense
ERROR: negative number of dictionary labels
hw.logicalcpu
%d %d %a %d
%d %d %a
%s.dt
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/HumanDetector/ml/DecisionTreeApply.cpp
DTreeDict.size()
CVML_status Geometry2D_cumulativeEuclideanDistanceCart2D(const Geometry2D_cart2D *, const Geometry2D_cart2D *, float *)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/Geometry2D/Geometry2D_Distances.c
CVML_status Geometry2D_cumulativeEuclideanDistanceHomo2D(const Geometry2D_homo2D *, const Geometry2D_homo2D *, float *)
3.000 - Oct 20, 2016
burst_mode_logging
staccato_mode_logging
burst_max_pending_frames
burst_disable_analysis
burst_force_face_detection
burst_force_face_detail_detection
burst_dummy_analysis
burst_disable_facecore
burst_use_fixed_image
burst_fixed_image_filename
burst_dump_yuv
staccato_yuv_dump
burst_use_version
BurstSet_AlgorithmVersion
Image_FacesArray
Image_ISPFacesArray
Image_ImageScore
Image_Timestamp
Image_YUVData
ImageYUVWidth
ImageYUVHeight
ImageYData
ImageUVData
ImageYUVBytesPerRow
Image_TimeReceived
Image_TimeQueued
Image_TimeConverted
Image_TimeStartedAnalysis
Image_TimeStartedFaceDetection
Image_TimeDoneFaceDetection
Image_TimeDoneFaceBlinkDetection
Image_TimeDoneFaceFocusScore
Image_TimeDoneAnalysis
ImageFace_ID
ImageFaceX
ImageFaceY
ImageFaceW
ImageFaceH
ImageFaceFocusScore
ImageFaceLeftEyeOpen
ImageFaceRightEyeOpen
ImageFaceSmiling
ImageFaceLeftEyePosX
ImageFaceLeftEyePosY
ImageFaceRightEyePosX
ImageFaceRightEyePosY
ImageFaceTimestamp
ImageFaceRollAngle
ImageFaceYawAngle
ImageFacePitchAngle
ImageFaceLeftEyeBlinkScore
ImageFaceRightEyeBlinkScore
ImageFaceSmileScore
ImageFaceSmallFace
com.apple.camera
/var/mobile/Library/Caches/com.apple.camera
burstSets
com.apple.burstAnalyzer
dd-MM-yyyy'_'HH-mm-ss'_burstLog.txt'
kern.osversion
BURST ANALYSIS VERSION = %s (%s)
com.apple.staccato_dump
counter.bin
BurstDoc_AllImageStats
BurstDoc_AllImageIdentifiers
BurstDoc_BestImageIds
BurstDoc_LogFile
Computing action selection threshold
Mean non-zero actions = %f, std dev = %f
ACTION SELECTION THRESHOLD = %f
Examining image, id=%s, timestamp = %.6f, done=%d
Not processing frames, imageStat.timestamp = %.6f, latestFaceTimestamp = %.6f
LeftEyeFeaturesOffset
RightEyeFeaturesOffset
SmileFeaturesOffset
BlinkFeaturesSize
SmileFeaturesSize
foundByISP
burstimage_%06d.yuv
Image_FaceRectROI
Image_Width
Image_Height
Image_AEAverage
Image_AETarget
Image_AEStable
Image_AFStable
Image_Orientation
Image_AEMatrix
Error!  Done adding, but there are still frames left!
analysis is disabled
too many analysis frames pending
Adding image: %s
Image %d:%s has emotional score %d
Image %d:%s has been emotionally rejected.
Skipping projection computation because data isn't present
LOOKING FOR FALSE-POSITIVE FACES...
Analyzing %s...
REMOVING false-positive face with ID = %d
Keeping face with ID = %d
Collapsing %s
*_*_* GARBAGE DETECTOR FOR %s *_*_*
Travel = %f, maxSkewness = %f, avgSkewness = %f, blur = %f, avgBlur = %f, stdBlur = %f
hasFaces = %d
notBlurry = %d
veryBlurry = %d
potentiallyBlurry = %d
poorRegistration = %d
suspectRegistration = %d
******Image %s classified as garbage.
**** Image %s classified as garbage by association.
Score for %s:%d is %f 
with action score %f and center bias %f (isGarbage=%d)
NEW BEST
Cover photo PORTRAIT selection score for %d:%s = %f (unbiased = %f)
Cover photo ACTION selection score for %d:%s = %f
%s:   # faces = %d, avgH = %f
    face id=%d, rect=%.3f,%.3f,%.3f,%.3f, focus=%.3f, faceScore=%.3f, leftEyeOpen=%d, rightEyeOpen=%d
Performing emotional rejection of face images in cluster %d:
Items in next cluster:
Image %s is classified as garbage for portrait mode, no sharp faces.
Checking temporal order: %d vs. %d
Removing %d:%s
All items in one cluster.
BurstSet_TimeDoneCapturing
BurstSet_TimeDone
BurstSet_Setting_MaxNumPendingFrames
BurstSet_Setting_DisableAnalysis
BurstSet_Setting_DisableFaceCore
BurstSet_Setting_DummyAnalysisCount
BurstSet_Setting_EnableDumpYUV
BurstSet_IsAction
BurstSet_IsPortrait
BurstSet_CoverImage
  <CVMLBurst> Trying to write xml file to '%s'
loggingCallback
T@?,C,N,V_loggingCallback
faceAnalysisContext
T@"BurstImageFaceAnalysisContext",&,V_faceAnalysisContext
overrideImage
T@"VNImageBuffer",&,V_overrideImage
overrideProps
T@"NSDictionary",&,V_overrideProps
clusterArray
T@"NSMutableArray",&,V_clusterArray
Ti,V_temporalOrder
faceIDCounts
T@"NSCountedSet",&,V_faceIDCounts
T@"NSMutableArray",&,V_allImageIdentifiers
statsByImageIdentifier
T@"NSMutableDictionary",&,V_statsByImageIdentifier
clusterByImageIdentifier
T@"NSMutableDictionary",&,V_clusterByImageIdentifier
burstLogFileName
T@"NSString",&,V_burstLogFileName
actionClassifier
T@"BurstActionClassifier",&,V_actionClassifier
maxNumPendingFrames
Ti,V_maxNumPendingFrames
enableAnalysis
TB,V_enableAnalysis
dummyAnalysisCount
Ti,V_dummyAnalysisCount
enableFaceCore
TB,V_enableFaceCore
enableDumpYUV
TB,V_enableDumpYUV
burstCoverSelection
T@"NSString",&,V_burstCoverSelection
burstId
T@"NSString",&,V_burstId
bestImageIdentifiersArray
T@"NSArray",&,V_bestImageIdentifiersArray
versionString
T@"NSString",&,V_versionString
Images without faces = %d, threshold = %d, total # = %d
Classified as portrait mode. Affects cover photo selection.
all costs within valid region: 
mean = %f, std = %f
First average cost = %f
Second average cost = %f
--Invalidating two outliers from the start of the burst
--Invalidating one outlier from the start of the burst
Last average cost = %f
Second-to-last average cost = %f
--Invalidating two outliers from the end of the burst
--Invalidating one outlier from the end of the burst
Number of images too few after invalidation at the endpoints. Return one selection.
Result of three-way division: finalCost: %f, inOutRatio: %f
Classified as non-action.
Classified as action.
Between %d and %d: 
motion: %f
Action mean = %f, action std = %f, action threshold = %f
Local statistics for divider %03d
 with score %f:
 noise threshold = %f, high threshold = %f (mean %f, std %f)
Overall mean divider score = %f
clusterDividerArraySize = %d
Locally-maximal divider %d not considered due to being potential noise (%f vs %f,%f)
Locally-maximal divider %d not considered due to lack of any motion: %f
Locally-maximal divider %d not considered due to being potential noise (nearby peak).
local maxima size: %ld
divider %d
Re-running three-way division with minClusterSize = %d, maxClusterSize = %d
Strongest local maxima: %d and %d
Expanding main peak to include divider %d
Adding action-based cluster boundaries.
Cluster %d is too small for action-based cluster boundaries
Action statistics for cluster %d: mean %f std %f threshold %f
Adding ACTION DIVIDER at location %d
***Finding three way division:
firstValidImage = %d, lastValidImage = %d
NEW BEST: largestInnerDistance = %f, bestRatio = %f
Divider1 = %d, Divider2 = %d
RECURSING: (%d->%d) becomes (%d->%d)
Clustering costs: maxInner = %f, inOutRatio = %f
Threshold for dupes: %f
Distance between selections %d and %d: %f, %f
Selection score of %d is %f... isGarbage = %d
Choosing candidate %d from a series of dupes
Throwing away all dupes due to garbage classification
Keeping candidate %d
Tossing out the %s on %d
trash
reject
All images are garbage. Picking the middle selection = %s.
CVML_status ImageProcessing_gradientFirstOrder_Planar8_PlanarF(const vImage_Buffer *, vImage_Buffer *, vImage_Buffer *)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/ImageProcessing/ImageProcessing_Gradients.c
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/ImageDescriptor/ImageDescriptorGlimmer/ImageDescriptor_Glimmer.cpp
This path is deprecated, ImageDescriptorProcessorGlimmer is only used for Planar8 images
virtual CVML_status vision::mod::ImageDescriptorProcessorGlimmer::computeDescriptorForImage_BGRA8888(const vImage_Buffer &, vision::mod::ImageDescriptorBufferAbstract &)
computeDescriptorForImage_RGBA8888
virtual CVML_status vision::mod::ImageDescriptorProcessorGlimmer::computeDescriptorForImage_RGBA8888(const vImage_Buffer &, vision::mod::ImageDescriptorBufferAbstract &)
virtual CVML_status vision::mod::ImageDescriptorProcessorGlimmer::computeDescriptorForImage_Planar8(const vImage_Buffer &, vision::mod::ImageDescriptorBufferAbstract &)
virtual CVML_status vision::mod::ImageDescriptorProcessorAbstract::computeDescriptorsForImages_RGBA8888(const std::vector<vImage_Buffer> &, vision::mod::ImageDescriptorBufferAbstract &)
virtual CVML_status vision::mod::ImageDescriptorProcessorAbstract::computeDescriptorsForImages_Planar8(const std::vector<vImage_Buffer> &, vision::mod::ImageDescriptorBufferAbstract &)
CVML_status ImageProcessing_detectSalientRegion_Planar8(const vImage_Buffer *, const Geometry2D_size2D *, Geometry2D_point2D *)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/ImageProcessing/ImageProcessing_Saliency.c
VectorAt
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/DictionaryLearning/LCKSVD/sofia-ml-read-only/src/sf-data-set.cc
index >= 0 && static_cast<unsigned long int>(index) < vectors_.size()
virtual std::vector<float> vision::mod::ColorGaborImageDescriptorBuffer::computeSelfDistances() const
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/ImageDescriptor/ImageDescriptorColorGabor/ColorGaborImageDescriptor.h
ERROR: This descriptor processor does not know how to handle RGBA8888 images
ERROR: This descriptor processor does not know how to handle Planar8 images
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/MomentProcessor/ImageGrouping/MPImageGrouping.mm
+[VNMPImageGrouping computeHierarchicalClusteringOfImageDescriptors:results:context:]
starting clustering
merging leaf clusters [%d, %d] with score : %f
found parent clusters to merge [%d, %d]
end clustering, iterations : %d
+[ImageProcessing_CoreImageUtils newCIImageFromVImage:withType:error:]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/ImageProcessing/ImageProcessing_CoreImageUtils.m
Unable to create CIImage
+[ImageProcessing_CoreImageUtils newCGImageFromCIImage:error:]
Unable to create CGImage from CIImage
+[ImageProcessing_CoreImageUtils newVImageBufferFromCIImage:error:]
Unable to create vImage_Buffer from CIImage
ERTFaceBox::ERTNumCascadeStages
ERTFaceBox::ERTNumTrees
ERTFaceBox::ERTNumPredictions
ERTFaceBox::ERTNodesThresholds
ERTFaceBox::ERTNodesPredictions
ERTFaceBox::ERTNodesFeatureIDs
ERTFaceBox::ERTNodesLeafFlags
ERTFaceBox::ERTGlobalShift
ERTFaceBox::ERTDefaultPixelValue
ERTFaceBox::ERTDefaultFeatureValue
ERTFaceBox::ERTNumXYPairs
ERTFaceBox::ERTXYPairs
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/LandmarkDetector/FaceBoxPoseAligner.cpp
loadERTModel
ERROR: ERTDefaultPixelValue failed to load from ERT model file!
loadDefaultPixelValue
ERROR: ERTDefaultFeatureValue failed to load from ERT model file!
loadDefaultFeatureValue
loadGlobalShifts
loadXYPairs
ERROR: numCascadeStages failed to load from ERT model file!
CVML_status vision::mod::FaceBoxPoseAligner<signed char>::loadERTModel(const char *) [T = signed char]
ERROR: numTreesPerStage failed to load from ERT model file!
ERROR: ERTNumPredictions failed to load from ERT model file!
ERROR: ERTNodesThresholds failed to load from ERT model file!
ERROR: ERTNodesPredictions failed to load from ERT model file!
ERROR: ERTNodesFeatureIDs failed to load from ERT model file!
ERROR: ERTNodesLeafFlags failed to load from ERT model file!
CVML_status vision::mod::FaceBoxPoseAligner<signed char>::loadDefaultPixelValue(const char *, uint8_t *) [T = signed char]
CVML_status vision::mod::FaceBoxPoseAligner<signed char>::loadDefaultFeatureValue(const char *, T *) [T = signed char]
ERROR: ERTGlobalShift failed to load from ERT model file!
CVML_status vision::mod::FaceBoxPoseAligner<signed char>::loadGlobalShifts(const char *, std::vector<float> &) [T = signed char]
ERROR: ERTNumXYPairs failed to load from ERT model file!
CVML_status vision::mod::FaceBoxPoseAligner<signed char>::loadXYPairs(const char *, std::vector<float> &) [T = signed char]
ERROR: ERTXYPairs failed to load from ERT model file!
CVML_status vision::mod::FaceBoxPoseAligner<short>::loadERTModel(const char *) [T = short]
CVML_status vision::mod::FaceBoxPoseAligner<short>::loadDefaultPixelValue(const char *, uint8_t *) [T = short]
CVML_status vision::mod::FaceBoxPoseAligner<short>::loadDefaultFeatureValue(const char *, T *) [T = short]
CVML_status vision::mod::FaceBoxPoseAligner<short>::loadGlobalShifts(const char *, std::vector<float> &) [T = short]
CVML_status vision::mod::FaceBoxPoseAligner<short>::loadXYPairs(const char *, std::vector<float> &) [T = short]
Error: 
 failed to load from ERT model file!
 unexpected size of value
cmap
Processing DetectFace3DLandmarks request
Error 1
Error 2
in acicDotProd: mOut not 128 byte aligned! Not optimal for cblas_sgemm
in acicDotProd: m2 not 128 byte aligned! Not optimal for cblas_sgemm
in acicDotProd: m1 not 128 byte aligned! Not optimal for cblas_sgemm
At iterate %5ld, f(x)= %5.2e, ||proj grad||_infty = %.2e
ITERATION %5ld
  ys=%10.3e  -gs=%10.3e BFGS update SKIPPED
 Bad direction in the line search;
 Singular triangular system detected;
 Nonpositive definiteness in Cholesky factorization in formk;
 Nonpositive definiteness in Cholesky factorization in formt;
   refresh the lbfgs memory and restart the iteration.
VNFaceLandmarkDetectorProcessOption_InputFaceObservations
VNFaceLandmarkDetectorProcessOption_RefineLeftEye
VNFaceLandmarkDetectorProcessOption_RefineRightEye
VNFaceLandmarkDetectorProcessOption_RefineMouth
VNFaceLandmarkDetectorProcessOption_BlinkDetection
VNFaceLandmarkDetectorProcessOption_CascadeStepCount
landmarks_v2
Invalid landmark model resource path
Could not read landmark model data
Could not read landmark refiner model data
mouth
righteye
lefteye
unknown exception thrown
memory allocation failure
Landmark Detector did not provide any data
unexpected exception thrown
ascend direction in projection gd = %.2e
junk
junk-descriptor-current
junk-classifier-current
junk-classifier-labels-current
Trying to run junk classifier when the classifier failed to initialize
VN_junk_classifier_debug_intermediates
VN_DEBUG_DUMP_JUNK_INTERMEDIATES
Mapping beyond limit of 2
 VNRequestOptionRectangleDetectorRequiredVersion value is out of bounds: %d
 VNRequestOptionInputRegionOfInterest value malformed: %@
 PixelFocalLength value is out of bounds: %f
 VNRequestOptionRectangleMinimumAspectRatio value is out of bounds: %f
 VNRequestOptionRectangleMaximumAspectRatio value is out of bounds: %f
 VNRequestOptionRectangleMinimumAspectRatio value, %f is greater than VNRequestOptionRectangleMaximumAspectRatio value, %f
 VNRequestOptionRectangleQuadratureTolerance value is out of bounds: %f
 VNRequestOptionRectangleMinimumSize value is out of bounds: %f
 VNRequestOptionRectangleMinimumConfidence value is out of bounds: %f
 VNRequestOptionRectangleMaximumNumber value is out of bounds: %d
%@:maxLen=%lu:mthd=%lu
Processing VNImageBlurMetric request
maximumIntermediateSideLength
blurDeterminationMethod
TQ,N,V_maximumIntermediateSideLength
%s.svm
VNFaceDetectorInitOption_MinFaceSize
VNFaceDetectorInitOption_EnableLowMemoryMode
faceDetector-current
VN_facedetector_debug_intermediates/
_fd_image.vdump
_fd_image.png
_raw_bboxes.json
%@_face_%d
_raw_bbox_crop.png
<binary-data>
rect
VN Face detector debug intermediates written to: %@
VNFaceDetector error aligning a detected bounding box
B56@?0@"VNImageBuffer"8{CGRect={CGPoint=dd}{CGSize=dd}}16^@48
Wiping layers for face detector unsuccessful.
Exception thrown while trying to purge face detector layers.
VN_DEBUG_DUMP_FACE_DETECT_INTERMEDIATES
pointCount
TQ,V_pointCount
points
Tr^,V_points
Can't use abstract base class. Must be VNVaceLandmark2D or 3D
pointsData
T@"NSData",&,V_pointsData
alignedBBox
T{_Geometry2D_rect2D_={_Geometry2D_point2D_=ff}{_Geometry2D_size2D_=ff}},V_alignedBBox
userFacingBBox
T{CGRect={CGPoint=dd}{CGSize=dd}},V_userFacingBBox
Tf,R,V_confidence
allPoints
T@"VNFaceLandmarkRegion2D",R
faceContour
leftEye
rightEye
leftEyebrow
rightEyebrow
nose
noseCrest
medianLine
outerLips
innerLips
leftPupil
rightPupil
T@"VNFaceLandmarkRegion3D",R
zero-dimensioned image (%ld x %ld)
array
%@ is nil
The %@ array has %lu items, which is less than the required count of %lu
The %@ array has %lu items, which is more than the maximum allowed of %lu
expectedAncestoralClass
All elements in the %@ array must be a Class object (%@)
All elements in the %@ array must be a VNRequest subclass (%@)
face observations
cluster IDs
face observation is nil
face observation must have a valid faceprint
%@ was given %@
virtual std::vector<float> vision::mod::BoundingBoxDescriptorBuffer::computeSelfDistances() const
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/ImageDescriptor/BoundingBoxDescriptor/BoundingBoxDescriptor.h
The model does not have a valid input feature of type image
%@:Type=%lu
model
T@"MLModel",&,V_model
modelType
Ti,V_modelType
inputImageKey
T@"NSString",&,V_inputImageKey
predictedFeatureKey
T@"NSString",&,V_predictedFeatureKey
predictedProbabilitiesKey
T@"NSString",R,V_predictedProbabilitiesKey
inputImageWidth
TQ,R,V_inputImageWidth
inputImageHeight
TQ,R,V_inputImageHeight
inputImageFormat
TI,R,V_inputImageFormat
No valid VNCoreMLModel found in passed in options
%@:Model=%@
T@"VNCoreMLModel",R,V_model
Error with task_info(): %s
Resident: %llu; Virtual: %llu; Max: %llu
%s%s. Memory usage: %@
 --> begin
 --> end
computeFeat
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/HumanDetector/cv/hog.cpp
features.size() == featSz[0] * featSz[1] * featSz[2]
tplTracker_FFT_3324
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/ObjectTracker/temporalEx/tplTrackerFFT.c
(outputIndex >= 0) && (outputIndex < 72)
tplTracker_IFFT_3324
Machine precision = %.2e
 N = %10ld
 M = %10ld
L  =
%.2e 
X0 =
U  =
LINE SEARCH %ld times; norm of step = %.2e
%5ld %5ld %5ld %5ld %5ld %5ld
%6.2e %9.5e
X = 
 %.2e
F(x) = %.9e
 Input nbd(%ld) is invalid
 l(%ld) > u(%ld). No feasible solution.
Cauchy                time %.3e seconds.
Subspace minimization time %.3e seconds.
Line search           time %.3e seconds.
 Total User time %.3e seconds.
        RUNNING THE L-BFGS-B CODE
           * * *
 Line search cannot locate an adequate point after 20 function
  and gradient evaluations.  Previous x, f and g restored.
                  2 rounding error dominate computation.
 The triangular system is singular.
 Warning:  more than 10 function and gradient
   evaluations in the last line search.  Termination
   may possibly be caused by a bad search direction.
 Derivative >= 0, backtracking line search impossible.
  Previous x, f and g restored.
 Possible causes: 1 error in function or gradient evaluation;
                  2 rounding errors dominate computation.
 Matrix in the Cholesky factorization in formt is not Pos. Def.
 Matrix in 2nd Cholesky factorization in formk is not Pos. Def.
 Matrix in 1st Cholesky factorization in formk is not Pos. Def.
Tit   = total number of iterations
Tnf   = total number of function evaluations
Tnint = total number of segments explored during Cauchy searches
Skip  = number of BFGS updates skipped
Nact  = number of active bounds at final generalized Cauchy point
Projg = norm of the final projected gradient
F     = final function value
           * * * 
   N    Tit   Tnf  Tnint  Skip  Nact      Projg        F
_source_scaled.png
_source_scaled.vdump
VN Image Classifier debug intermediates written to: %@
scalingFactor
augmentationMode
numTiles
imageID
_tile_
.png
.vdump
debugID
MinConfidenceForClassificationRaw
hierarchicalLabelsAndConfidence
MinConfidenceForHierarchical
virtual vision::mod::ImageDescriptorAugmenterAbstract::~ImageDescriptorAugmenterAbstract()
CVML_status vision::mod::ImageDescriptorAugmenterAbstract::clearAugmentedImages()
virtual CVML_status vision::mod::ImageDescriptorAugmenterFlip::augmentImage(const vImage_Buffer &, ImageProcessing_ImageType, const std::vector<vImage_Buffer *> &)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/ImageDescriptor/ImageDescriptor_AugmenterFlip.h
CVML_status vision::mod::ImageDescriptorAugmenterFlip::flipLR(const vImage_Buffer *, ImageProcessing_ImageType, vImage_Buffer *)
CVML_status vision::mod::ImageDescriptorAugmenterFlip::flipUD(const vImage_Buffer *, ImageProcessing_ImageType, vImage_Buffer *)
virtual CVML_status vision::mod::ImageDescriptorAugmenterFlip::combine(const vision::mod::ImageDescriptorBufferAbstract &, vision::mod::ImageDescriptorBufferAbstract &)
setMinConfidenceRatio
The minimum confidence ratio should be positive float
vision::mod::ImageClassifierAbstract &vision::mod::ImageClassifierAbstract::setMinConfidenceRatio(float)
setMinConfidence
The minimum confidence should be positive float
vision::mod::ImageClassifierAbstract &vision::mod::ImageClassifierAbstract::setMinConfidence(float)
setMaxLabels
The maximum number of labels should be positive integer
vision::mod::ImageClassifierAbstract &vision::mod::ImageClassifierAbstract::setMaxLabels(int)
classifyDescriptors
std::map<std::string, float> vision::mod::ImageClassifierAbstract::classifyDescriptors(const vision::mod::ImageDescriptorBufferAbstract &, bool, bool)
tpThreadInit error
hw.activecpu
Processing Create imageprint request
Attempt to create an image print request without a timestamp
Attempt to create an imageprint failed
timeStamp
T@"NSNumber",&,N,V_timeStamp
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/ImageClassifier/ImageClassifierGlimmer/ImageClassifier_Glimmer.mm
virtual vision::mod::ImageClassifierAbstract &vision::mod::ImageClassifierGlimmer::setDescriptorProcessor(const std::shared_ptr<ImageDescriptorProcessorAbstract> &)
void vision::mod::ImageClassifierGlimmer::private_t::loadData(void *, size_t, int)
void vision::mod::ImageClassifierGlimmer::private_t::loadClassifier(vision::mod::ImageClassifierGlimmer *, const char *)
void vision::mod::ImageClassifierGlimmer::private_t::loadClassifierBinserializer(vision::mod::ImageClassifierGlimmer *, const char *, const char *)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/ImageClassifier/ImageClassifierGlimmer/ImageClassifier_Glimmer.h
EXCEPTION: the Glimmer based image classifier should only operate on descriptors buffers
virtual std::map<std::string, float> vision::mod::ImageClassifierGlimmer::classifyImage_RGBA8888(const vImage_Buffer &)
virtual std::map<std::string, float> vision::mod::ImageClassifierGlimmer::classifyImage_BGRA8888(const vImage_Buffer &)
virtual std::map<std::string, float> vision::mod::ImageClassifierGlimmer::classifyImage_Planar8(const vImage_Buffer &)
FaceRegionMap::Width
FaceRegionMap::Height
FaceRegionMap::Data
FaceRegionMap::Triangles
FaceRegionMap::NormalizedLandmarks
void vision::mod::FaceRegionMap::init(const vision::mod::ModelValues &)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/FaceRegionMap/FaceRegionMap.cpp
Background
Left eye
Right eye
Left eyebrow
Right eyebrow
Root of nose
Nose
Chin
Lower left cheek
Lower right cheek
Between mouth and nose
Left cheek
Right cheek
Left temple
Right temple
Between eyebrows
Above left eye
Above right eye
Upper lip
Lower lip
Between lips
Forehead
Tip of nose
CVML_status vision::mod::FaceRegionMap::computeFaceRegionMap(const Geometry2D_rect2D, const std::vector<Geometry2D_point2D> &, vImage_Buffer &)
AdjacentContourHeal
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/RectangleDetector/QuadDetect/Contours.c
PCOORD_EQUAL(joinPoint, LAST_PCOORD(cPtrN))
PCOORD_EQUAL(joinPoint, FIRST_PCOORD(cPtrN))
healCenters
ady == 2
heal
(endpoint2 == 4)|| (endpoint2 == 8)
(endpoint2 == 8)|| (endpoint2 == 6)
(endpoint2 == 6)|| (endpoint2 == 2)
(endpoint2 == 2)|| (endpoint2 == 4)
testJoin
(orn >= 0) && (orn <= 8)
orn != 4
straightLineLSQ
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/RectangleDetector/QuadDetect/Leq.c
maxDev != -1.f
straightLineWLSQ
CVML_status ImageProcessing_writeIntensity_F_Planar8(const float *, Geometry2D_cart2D *, _Bool, vImage_Buffer *)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/ImageProcessing/ImageProcessing_Interpolation.c
CVML_status ImageProcessing_writeIntensity_F_PlanarF(const float *, Geometry2D_cart2D *, _Bool, vImage_Buffer *)
CVML_status ImageProcessing_getIntensityBilinear_Planar8_8(const vImage_Buffer *, const Geometry2D_point2D *, uint8_t, uint8_t *)
CVML_status ImageProcessing_getIntensitiesBilinear_Planar8_F(const vImage_Buffer *, const Geometry2D_cart2D *, float, dispatch_queue_t, float *)
CVML_status ImageProcessing_getIntensitiesBilinear_Planar8_8(const vImage_Buffer *, const Geometry2D_cart2D *, uint8_t, dispatch_queue_t, uint8_t *)
VNDetectedObjectObservation object is expected to initialize Object Tracker
Object identifier is not initialized in detected object observation
CVML_status FaceWarper_estimateEyesRST(const Geometry2D_cart2D *, const Geometry2D_point2D *, const Geometry2D_size2D *, _Bool, Geometry2D_RST *)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/FaceWarper/FaceWarper_Mesh.c
CVML_status FaceWarper_estimateAnchorsRST(const Geometry2D_cart2D *, const int *, int, const Geometry2D_point2D *, const Geometry2D_size2D *, _Bool, Geometry2D_RST *)
CVML_status FaceWarper_getNormalizedFaceVertices(const Geometry3D_cart3D *, const Geometry2D_size2D *, const Geometry2D_point2D *, const float *, Geometry2D_cart2D *)
CVML_status FaceWarper_getBackgroundMesh(const Geometry2D_cart2D *, const Geometry2D_cart2D *, const Geometry2D_size2D *, Geometry2D_cart2D *, Geometry2D_cart2D *)
assert_little_endian
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/ImageDescriptor/ImageDescriptorGlimmer/infer.c
cond
chk_ptr
malloc_chk
s > 0
malloc
mult_chk32
r >= 0
r < (int64) INT_MAX
read_int
ret == n_items
read_bytes
ret == n_bytes
assert_eof
ret == 0
assert_zrange
x >= 0
x < b
init_dims
m != NULL
normalize_fb
new_working_state
num_images_max > 0
num_images_max <= NUM_IMAGES_MAX_GLOBAL
teardown_working_state
st != NULL
fopen model
[infer.c] %d fs=%d n=%d ps=%d pool=%d
new_model_from_params
rl <= model_metadata_len
fbh == fbw
opt_maxpool == 0 || opt_maxpool == 1
ind == image_depth
ind == m->num_filters[l - 1]
rl == model_metadata_len
rl <= model_data_len
rl == model_data_len
teardown_model
model_get_desc_len
dest_final
maxpool
prod_scale
tfbncc
lsum_check
descs_sum_check
process2
n_images >= 0
n_images <= st->num_images_max
st->num_images_max <= NUM_IMAGES_MAX_GLOBAL
imdata_len == n_images * m->dim_h[0] * m->dim_w[0] * m->dim_d[0]
descs_out_len == df * st->num_images
allocSegments
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/RectangleDetector/QuadDetect/Segments.c
sdb->nSegments <= sdb->maxSegments
ThumbnailCluster - adding %s
[BurstThumbnailCluster initWithImageData] : metadata parsing error
[BurstThumbnailCluster initWithImageData] : no error
burstImages
T@"NSMutableArray",&,V_burstImages
imageProps
T@"NSMutableDictionary",&,V_imageProps
completionBlock
T@?,C,V_completionBlock
imagePixelBuffer
T^{__CVBuffer=},V_imagePixelBuffer
baseAddress
Tr^v,R,N
resourcePath
T@"NSString",&,N
void cvml::util::mapped_model_file::advise(int) const
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/VisionKitFramework/VN/algorithm_util/mapped_model_file.h
mmap MAP_FAILED
cvml::util::mapped_model_file::mapped_model_file(const char *, bool)
void cvml::util::mapped_model_file::open_file(const char *)
VNMPImageDescriptor_externalImageId
VNMPImageDescriptor_exifTimestamp
VNMPImageDescriptor_quality
VNMPImageDescriptor_ColorGaborImageDescriptorBuffer_type
VNMPImageDescriptor_ColorGaborImageDescriptorBuffer_lengthInBytes
VNMPImageDescriptor_ColorGaborImageDescriptorBuffer_data
VNMPImageDescriptor_ColorGaborImageDescriptorBuffer_count
VNMPImageDescriptor_ColorGaborImageDescriptorBuffer_stride
ERROR: Could not compute the image descriptor
ERROR: Could not compute the convnet-based image descriptor
ERROR: Could not compute image registration features
ERROR: Could not compute image quality
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/MomentProcessor/Moments/MPImageDescriptor.mm
-[VNMPImageDescriptor initWithCoder:]
Constructing image descriptor failed
ERROR: state cannot be nil
MPImageDescriptor cannot be serialized without being created
ERROR: invalid image Id format
Failed to initialize VNMPImageDescriptor object
state parameter cannot be nil
Invalid state format
-[VNMPImageDescriptor initWithState:startingAtByteOffset:error:]
-[VNMPImageDescriptor computeDescriptorForImageData:context:error:]
%s, current computation took %3.3f ms
Image color descriptor computation
%s, computation stats: %3.3f ms per computation (%d computations total)
-[VNMPImageDescriptor computeQualityForImageData:andQualityCriteria:context:error:]
ERROR: image data property is not initialized
ERROR: all ranking criteria failed
Image quality computation
Image quality is %f
-[VNMPImageDescriptor initWithRawColorGaborDescriptor:]
previousLeafId
Tq,V_previousLeafId
nextLeafId
Tq,V_nextLeafId
nextLeafDescriptorDistance
Tf,V_nextLeafDescriptorDistance
previousLeafDescriptorDistance
Tf,V_previousLeafDescriptorDistance
nextLeafTimestampDistance
Tq,V_nextLeafTimestampDistance
previousLeafTimestampDistance
Tq,V_previousLeafTimestampDistance
nextLeafTotalDistance
Tf,V_nextLeafTotalDistance
previousLeafTotalDistance
Tf,V_previousLeafTotalDistance
rawColorGaborDescriptor
T@"NSData",R
T@"NSString",R,V_imageFilePath
descriptorId
Tq,R,V_internalNonSerializedDescriptorId
quality
Tf,R,V_quality
colorGaborDescriptor
T^v,R,V_colorGaborDescriptor
sceneClassifierDescriptor
T^v,R,V_sceneClassifierDescriptor
imageRegistrationDescriptor
T^v,R,V_imageRegistrationDescriptor
Processing DetectFaceRectangles request
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/FaceFrontalizer/FaceFrontalizer.cpp
frontalize_Planar8
ERROR: desired frontalization method is undefined
CVML_status vision::mod::FaceFrontalizer::frontalize_Planar8(const vImage_Buffer &, const std::vector<Geometry2D_point2D> &, vImage_Buffer &)
ERROR: so far only 63 point models are supported
CVML_status vision::mod::FaceFrontalizer::frontalize_Planar8(const vImage_Buffer &, const std::vector<Geometry2D_point2D> &, const std::vector<Geometry3D_point3D> &, const Geometry3D_pose &, vImage_Buffer &)
ERROR: the desired frontalization method cannot be auto at this point
CVML_status vision::mod::FaceFrontalizer::frontalize_Planar8(const vImage_Buffer &, const Geometry2D_rect2D &, vImage_Buffer &)
FaceWarper_Mirroring vision::mod::FaceFrontalizer::computeMirroringMode(const Geometry3D_pose &)
Processing getClusters request
T@"NSArray",C,N,V_clusterIDs
v24@?0@"NSString"8@"NSError"16
operation timeout
burst frame '%@' failed to be added
T@?,C,N
CVML_status ImageProcessing_smoothGaussian_Planar8(const vImage_Buffer *, const vImage_Buffer *, void **, float, float, Pixel_8, vImage_Flags)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/ImageProcessing/ImageProcessing_Smoothing.c
personUID
personUIDClass
 '%@' (%f)
T@"VNFaceObservation",R,V_face
predictedPersonUniqueIdentifier
T@"<NSObject><NSCopying><NSSecureCoding>",R,&,V_predictedPersonUniqueIdentifier
maxFaceprintsPerPerson
maxFaceprintsPerPerson=%lu
maximumFaceprintsPerPerson
TQ,N,V_maximumFaceprintsPerPerson
VNPersonsModelConfiguration
VNPersonsModelPersonUniqueIdentifierToSerialNumberMap
VNPersonsModelSerialNumberToFaceprintsMap
VNPersonsModelFaceIDModelData
VNPersonsModelLastAssignedFaceprintSerialNumber
missing required unique identifier mapping
missing required serial number mapping
unique identifier and serial number counts do not match
last assigned faceprint serial number (%d) is inside the limit of recorded serial numbers (%d)
Face ID model data deserialization failed with code %@
unique identifier '%@' has an unrecorded serial number (%@)
unable to serialize the face ID model (status = %@)
v32@?0@"NSNumber"8@"NSArray"16^B24
A prediction for an unknown identity with serial number %@ and confidence %f was provided
q24@?0@"VNPersonsModelPrediction"8@"VNPersonsModelPrediction"16
<%@: %p> %lu identities, %lu faceprints
 <dirty>
RAMBackingStore::createFromContentsOfFile -- file does not exist '%s'
RAMBackingStore::createFromContentsOfFile -- Could not open file '%s'
RAMBackingStore::createFromContentsOfFile -- error seeking in provided file
RAMBackingStore::createFromContentsOfFile -- failed to allocate buffer
RAMBackingStore::createFromContentsOfFile -- failed to read contents of file '%s'
RAMBackingStore::createFromContentsOfFile -- failed to close file
RAMBackingStore::growStorage -- could not grow storage
MMapFileBackingStore::create -- Could not generate a valid path for temporary file
MMapFileBackingStore::create -- Could not open temporary file for mmaping
MMapFileBackingStore::create -- Unable to grow file to desired capacity -- seek
MMapFileBackingStore::create -- Unable to grow file to desired capacity -- write
MMapFileBackingStore::create -- Memory mapping failed for temporary file
MMapFileBackingStore::create -- unable to unmap new file
MMapFileBackingStore::create -- could not close new file
MMapFileBackingStore::create -- could not remove corrupt new file
MMapFileBackedBuffer::createFromContentsOfFile -- Could not generate a valid path for temporary file
MMapFileBackedBuffer::createFromContentsOfFile -- Could not create a temporary file for file backed storage
MMapFileBackingStore::createByMappingDirectlyFromFile -- Could not open temporary file for mmaping
MMapFileBackingStore::createByMappingDirectlyFromFile -- error seeking in provided file
MMapFileBackedBuffer::createByMappingDirectlyFromFile -- Memory mapping failed for temporary file
MMapFileBackedBuffer::createByMappingDirectlyFromFile -- Could not remove file '%s'
MMapFileBackingStore::destructor -- could not unmap file
MMapFileBackingStore::destructor -- error closing file
MMapFileBackingStore::destructor -- Could not remove temporary file '%s'
%@%s
##INVALID##
writeBackingStoreToFile-- Could not create file: '%s'
writeBackingStoreToFile-- error writing out data
writeBackingStoreToFile-- error closing file, file could be corrupt
writeBackingStoreToFile -- File exists at output path '%s', and we cannot safely overwrite this file
writeBackingStoreToFile-- File exists at output path '%s', and could not copy file to temporary directory
writeBackingStoreToFile-- Could not move file from temporary directory
writeBackingStoreToFile -- Non critical error -- Could not remove original file after rename
writeBackingStoreToFile-- Error closing file
writeBackingStoreToFile -- could not remove temporary file.
writeBackingStoreToFile-- Catastrophic error.  Original file damaged during save.
VNFaceprintGeneratorType
VNFaceprintGeneratorTypeEspressoCPU
VNFaceprintGeneratorProcessOption_InputFaceObservations
VNFaceprintGeneratorProcessingOption_CheckForJunkFaces
Descriptor type not specified!
Unsupported descriptor type
faceDescriptor-current
Could not find face descriptor model resource!
Could not create new face observation instance
Faceprint generator recieved a zero dimensioned image
Could not create memory efficient crop for face printing
VN_faceprinter_debug_intermediates/
_pre_frontalized.vdump
_frontalized.vdump
_frontalized.png
_pre_frontalized.png
_bbox.json
_bbox_crop.png
VN Faceprinter debug intermediate written to: %@
Poor quality face print candidate detected.  Not generating faceprint
Could not compute face descriptor due to internal error
VN_DEBUG_DUMP_FACEPRINTER_INTERMEDIATES
Geometry2D_computeHistogramPeaks
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/Geometry2D/Geometry2D_Histograms.c
count != NULL
Geometry2D_cart2D Geometry2D_computeHistogramPeaks(const Geometry2D_cart2D *, int, int **, CVML_status *)
CVML_status ctrTrackerComputation_trackNewFrame(CVPixelBufferRef, ctrTracker_context *, CGPoint *, _Bool *, _Bool *, float *)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/ObjectTracker/correlationTracker/ctrTrackerTrack.c
CVML_status ctrTrackerComputation_updateHistory(CVPixelBufferRef, ctrTracker_context *, CGPoint *, _Bool *, float *)
Processing Create FaceRegionMap request
floatVectorSumProd
T^f,VfloatVectorSumProd
pulseVectorHeightCharBox
T*,VpulseVectorHeightCharBox
pulseVectorHeightCharBoxAdaptive
T*,VpulseVectorHeightCharBoxAdaptive
charBoxFlags
T^Q,VcharBoxFlags
charboxROIFullVectorRowStart
T^S,VcharboxROIFullVectorRowStart
charboxROIFullVectorHeight2
T^S,VcharboxROIFullVectorHeight2
allocationSize
TI,VallocationSize
mTop
Tf,VmTop
mBottom
Tf,VmBottom
bTop
Tf,VbTop
bBottom
Tf,VbBottom
posUL
Tf,VposUL
posLL
Tf,VposLL
posUR
Tf,VposUR
posLR
Tf,VposLR
medianHeightTop
TS,VmedianHeightTop
medianHeightBottom
TS,VmedianHeightBottom
loopBigBox
Ts,VloopBigBox
loopBigBoxPrev
Ts,VloopBigBoxPrev
filterWalkUpDownCount
TS,VfilterWalkUpDownCount
CCTextDetector_EnableDebug
CCTextDetector_DebugPathname
  Could not create debug output folder '%s'.  Shutting debugging off
creditCardSubsampleImage.png
votingImage.png
inverseVotingImage.png
/var/mobile/Media/DCIM/ccOutDebug/
textOutFirstPassImage.png
textOutSecondPassImage.png
adaptiveOutImage.png
selectedTextOutImageArray.png
uOutImage.png
textBoxRevised
textBoxRevisedNormalized
stubBox
stubBoxNormalized
{{%i,%i},{%i,%i}}
{{%2.4f,%2.4f},{%2.4f,%2.4f}}
textBox
textBoxMM
charBox
charBoxMM
charConfidence
{{1,1},{1,1}}
connectedComponents.png
stubBoxMM
CCTextDetector internal error
q24@?0@"VNTextObservation"8@"VNTextObservation"16
computeZCVectorHighProbability
TB,V_computeZCVectorHighProbability
midRow
Ti,V_midRow
minHeight
TI,V_minHeight
maxHeight
TI,V_maxHeight
startMaxFind
TI,V_startMaxFind
stopMaxFind
TI,V_stopMaxFind
mmHeightCard
Tf,V_mmHeightCard
mmWidthCard
Tf,V_mmWidthCard
pixelHeightCard
TI,V_pixelHeightCard
pixelWidthCard
TI,V_pixelWidthCard
minBoxWidth
TI,V_minBoxWidth
maxBoxWidth
TI,V_maxBoxWidth
startNormal
TI,V_startNormal
stopNormal
TI,V_stopNormal
startSensitized
TI,V_startSensitized
stopSensitized
TI,V_stopSensitized
charBoxContext
T@"CCCharBoxContext",&,V_charBoxContext
TC,V_ii
profileNormal
TC,V_profileNormal
debugMatlab
TB,V_debugMatlab
debugOut
TB,V_debugOut
debugFilename
T@"NSString",C,V_debugFilename
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/Clustering/Clustering/Agglomerative/cluster_descs.cc
s >= 0
heap_assert_cap
h.n + 1 <= h.a.size()
h.n + 1 <= h.a_rev.size()
heap_swap
i >= 1
i <= h.n
j >= 1
j <= h.n
i != j
heap_up
heap_down
heap_remove
heap_top
h.n >= 1
heap_pop
heap_update
candidate_heap %d
cluster_descs_mean_agg_cpp
h.n > 0
i_max < j_max
root_cc_i >= 0
root_cc_i < n_rem
orig_j == root_orig_i
BOOL faceWarperComputeAnchorTransform(NSData *__strong, CGAffineTransform *)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/VisionKitFramework/VN/internal/VNFaceWarper.mm
VNObservationsCache
%@:AR%g-%g:QTol=%g:%g:%g:n=%lu
requiredVersion
TQ,N,SsetRequiredVersion:,V_requiredVersion
minimumAspectRatio
Tf,N
maximumAspectRatio
quadratureTolerance
minimumSize
minimumConfidence
maximumObservations
returnAllResults
TB,N,V_returnAllResults
tpThreadDispatch: thread %u not idle
***tpThread: Error waiting on condition; error %d; aborting.
setThreadAffinity: thread_policy_set returned %d
***tpThreadInit: Error starting up server thread
***tpThreadInit: Error initializing pthreadCond
***tpThreadInit: Error initializing mutex
***tpThreadInit: malloc failure
***Error acquiring server lock; aborting.
***Error waking main thread; aborting.
***Error acquiring lock; aborting.
***tpThread: Error acquiring lock; aborting.
tpThreadDispatch: cond_broadcast error
tpThreadDispatch: mutex error
***tpThreadFinish: Error waiting on condition
***tpThreadFinish: Error acquiring lock
The requests parameter must be an array of VNRequests
q24@?0@"VNRequest"8@"VNRequest"16
request classes
requests
Processing IdentifyJunk request
float vision::mod::GreedyClusterer::internalDistGreedy(float *, float *, int) const
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/Clustering/Clustering/Greedy/GreedyClustering.cpp
std::shared_ptr<std::vector<size_t> > vision::mod::GreedyClusterer::addDescriptors(float *, int, int, size_t, const std::vector<float> &, const std::vector<int> &)
elementSize == ELEMENT_SIZE
GreedyClusterer::addDescriptors must be called with a ImageDescriptorBufferFloat32 buffer
std::shared_ptr<std::vector<size_t> > vision::mod::GreedyClusterer::addDescriptors(const vision::mod::ImageDescriptorBufferAbstract &, const std::vector<float> &, const std::vector<int> &)
For consistency, GreedyClusterer::addDescriptors must be called with a ImageDescriptorBufferFloat32 having the same distance mode as GreedyClusterer::distance_mode
  GreedyClusterer::serializeStatus - enter
  GreedyClusterer: Failed to open file - skipping serialization
  GreedyClusterer::serializeStatus - saving map file: %s
  GreedyClusterer: failed to save the file
virtual bool vision::mod::GreedyClusterer::serializeStatus(int) const
  GreedyClusterer::serializeStatus - deleting previous cache
  GreedyClusterer::serializeStatus - done
  GreedyClusterer::deserializeStatus - failed to load memory map file
  GreedyClusterer::deserializeStatus - loaded a corrupt file as expected element size does not match
CVML_status vision::mod::GreedyClustererFaces::updateInternal(const vision::mod::ImageDescriptorBufferAbstract &, const std::vector<float> &, const std::vector<int> &, std::vector<faceIdPair> &)
updateInternal
wrong number of descriptors id in descriptor buffer
TH %f
void vision::mod::GreedyClustererFaces::getAverageDescriptorOfClusterContainingFace(ImageDescriptorId, std::map<ImageDescriptorId, std::vector<ImageDescriptorId> > &, float *) const
anomalyForGroup
FaceId=%lld not present in clustering
  GreedyClustererFaces::serialize - enter
  GreedyClustererFaces::serialize - deleting previous path: %s
  GreedyClustererFaces::serialize - cachefile: %s
  GreedyClustererFaces::serialize - error creating new map file for serialization
  GreedyClustererFaces::serialize - error calculating checksum for cluster data file
  Clusterer - couldn't find sanity value
  Clusterer - versions mismatch (serialized: %d, current: %d
  Clusterer - data checksum mismatch
  GreedyClustererFaces: Failed to open '%s': errno=%d
  GreedyClustererFaces: Opening '%s'
void vision::mod::GreedyClustererFaces::getIdsForCluster(ImageDescriptorId, std::vector<ImageDescriptorId> &, std::unordered_multimap<ImageDescriptorId, ImageDescriptorId> *) const
isFaceIdInClustererState
FaceId=%lld not present in l0 clustering
/tmp/
vision::mod::dist_greedy_status_t::dist_greedy_status_t(int, vision::mod::ImageDescriptorBufferFloat32DistanceMode)
BackedBuffer<BackingStore>::allocateElement -- could not allocate new element because grow failed
copy
GreedyClusterer::clusters_t: Cannot clone MMapVector object
void vision::mod::GreedyClusterer::private_t::throwOnCancellation()
.cmap
BackedBuffer<BackingStore>::createByMappingDirectlyFromFile -- Invalid header detected for file '%s'
BackedBuffer<BackingStore>::createByMappingDirectlyFromFile -- The valid element list is corrupt
BackedBuffer<BackingStore>::isValidHeader -- cannot open source file '%s'
BackedBuffer<BackingStore>::isValidHeader -- corrupt header detected in file '%s'
BackedBuffer<BackingStore>::isValidHeader -- inconsistent header detected -- zero element size detected for file '%s'
BackedBuffer<BackingStore>::isValidHeader -- inconsistent header detected -- element count does not match max free element capacity for file '%s'
BackedBuffer<BackingStore>::isValidHeader -- inconsistent header detected -- free element count exceeds free element capacity for file '%s'
BackedBuffer<BackingStore>::isValidHeader -- inconsistent header detected -- could not validate file size for file '%s'
BackedBuffer<BackingStore>::isValidHeader -- inconsistent header detected -- expected file size does not match actual file size for file '%s'
Processing Group Images By Time and Content Request
Attempt to create an image print request an imageprint array
Input imageprint array contains an item that is not an imageprint
Image grouper failed
%@:[%@]
Processing Align Face Rectangle request
Input faces not provided to face rectangle aligner
T@"NSArray",R,C,N,V_inputFaceObservations
T@"NSString",&,N,V_type
cachePath
T@"NSString",&,N,V_cachePath
state
T@"NSData",&,N,V_state
threshold
Tf,N,V_threshold
options parameter cannot be nil
Failed to initialize rectangle detector
The VNCoreMLTransform request failed
T@"VNCoreMLModel",R,N,V_model
imageCropAndScaleOption
Ti,N,V_imageCropAndScaleOption
debugMode
Ti,V_debugMode
timerMode
Ti,V_timerMode
clusterSplitDistanceType
Ti,V_clusterSplitDistanceType
qualityCriteriaList
T@"NSArray",&,V_qualityCriteriaList
useTimestampAdjustedDistances
TB,V_useTimestampAdjustedDistances
performClustersPostprocessing
TB,V_performClustersPostprocessing
performSceneClassification
TB,V_performSceneClassification
roiAreaThreshold
Tf,V_roiAreaThreshold
inliersRatioThreshold
Tf,V_inliersRatioThreshold
numberOfKeypointsToConsider
Ti,V_numberOfKeypointsToConsider
naturalClusteringDistanceThreshold
Tf,V_naturalClusteringDistanceThreshold
splitIntoMonotonicSpans
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/RectangleDetector/QuadDetect/SegmentUtilities.c
cPtr->nPnts > 1
!closedP
idx <= monoLength
mergeSegment
sPtr2 != NULL
vision::mod::BoostedClassifierLight::BoostedClassifierLight(std::string)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/Classifiers/BoostedClassifierLight/BoostedClassifierLight.cpp
IMAGE_FEATURES_PAIR_DIFF
THRESHOLDS
WEIGHTS
CVML_status vision::mod::BoostedClassifierLight::loadClassifierFromFile(std::string)
bool vision::mod::faceIsJunk(vision::mod::ImageDescriptorBufferAbstract &)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/Clustering/Clustering/Greedy/GreedyClustering_hacks.cpp
/all_3lp_nodropout-symbol.espresso.bin
faceattrs
softmax_baby
softmax_glasses
softmax_beard
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/CVML/CVML_BinSerializedModelReader.cpp
readBinSerializedModelValues
ERROR: Model file path cannot be NULL
void vision::mod::readBinSerializedModelValues(const char *const, const char *, const vision::mod::BinSerializedModelFileInfo &, vision::mod::ModelValues &, bool)
ERROR: Could not open model file 
ERROR: Unexpected null fileptr passed into readBinSerializedModelValues
void vision::mod::readBinSerializedModelValues(FILE *, const char *, const vision::mod::BinSerializedModelFileInfo &, bool, vision::mod::ModelValues &)
ERROR: File seek failed! 
ERROR: Could not read 
void vision::mod::Face3D::init(const vision::mod::ModelValues &, const float *)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/Face3D/Face3D.cpp
CVML_status vision::mod::Face3D::estimatePoseAndStructure(const std::vector<Geometry2D_point2D> &, Geometry3D_pose &, std::vector<Geometry3D_point3D> &, int)
CVML_status vision::mod::Face3D::estimatePoseAndStructure(const std::vector<Geometry2D_point2D> &, Geometry3D_pose &, std::vector<Geometry3D_point3D> &, std::vector<float> &, int)
CVML_status vision::mod::Face3D::estimatePose(const std::vector<Geometry2D_point2D> &, Geometry3D_pose &)
CVML_status Projections_computeShiftBruteForce(const float *, int, const Projections_meanStdTable *, const float *, int, const Projections_meanStdTable *, int, float, float *, float *, float *, float *)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/ImageRegistration/Projections/Projections_Optimizer.c
CVML_status Projections_computeShiftDescent(const float *, int, const Projections_meanStdTable *, const float *, int, const Projections_meanStdTable *, int, float *, float *)
CVML_status Projections_computeCost(int, float, float, const float *, int, const Projections_meanStdTable *, const float *, int, const Projections_meanStdTable *, int, float *)
Unknown sparse coding dictionary type. Defaulting to KSVD
Not enough features to build dictionary for for class %d. Required >= %d, got only %d
AR_Success
AR_ParamErr
AR_Memory
AR_IO
AR_Unimplemented
AR_Overflow
AR_EndOfFile
AR_Alignment
AR_Compression
AR_BadFileFormat
AR_Internal
<Unknown> (%d)
Gray
RGBA
Unknown colorMode
Fata error: Problem in memory allocation for LCKSVD!
convertYUV420ToRGBA8888: invalid dst size of %lu x %lu
convertYUV420ToRGBA8888: failed to allocate %lu bytes
public.png
com.microsoft.bmp
public.jpeg
convertYUV420ToRGBA8888: src must be YUV420 format!
convertRGBA8888ToYUV420: src must be RGBA8888 format!
***malloc fialure
***malloc failure
Processing DetectFaceExpressions request
scorPdiffParameters
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/LandmarkDetector/LandmarkDetector_Attributes.mm
ERROR: Could not retrieve model value 'scorPdiffParameters'
void vision::mod::LandmarkAttributes::init(const vision::mod::ModelValues &, bool)
exprParameters
ERROR: Could not retrieve model value 'exprParameters'
blinkParametersApp
ERROR: Could not retrieve model value 'blinkAttributeAppearanceParameters'
smileBlinkParametersGeo
ERROR: Could not retrieve model value 'smileBlinkParameters'
lmarkQuality
ERROR: Could not retrieve model value 'lmarkQuality'
exprParamsv1
ERROR: Could not retrieve model value 'exprParamsv1'
pupilMeanStd
ERROR: Could not retrieve model value 'pupilMeanStd'
pupil
LandmarkAttributes
ERROR: Could not retrieve model value 'pupil'
vision::mod::LandmarkAttributes::LandmarkAttributes(const char *, bool)
computeFittingScoreIntensityDifference
ERROR: The size of the parameter vector for computeFittingScoreIntensityDifference (
) does not match the size of the descriptor (
float vision::mod::LandmarkAttributes::computeFittingScoreIntensityDifference(const vImage_Buffer &, const Geometry2D_rect2D &, const std::vector<Geometry2D_point2D> &)
computeExpressionAttributes
The size of the parameter vector for computeExpressionAttributes (
std::map<expressionAttributeType, float> vision::mod::LandmarkAttributes::computeExpressionAttributes(const Geometry2D_rect2D &, const std::vector<Geometry2D_point2D> &)
computeBlinkFunction
ERROR: Crop Requested for Blink Feature Extraction is Ill Formed
int vision::mod::LandmarkAttributes::computeBlinkFunction(const vImage_Buffer &, const Geometry2D_rect2D &, const std::vector<Geometry2D_point2D> &, vImage_Buffer &, vImage_Buffer &, std::vector<float> &, std::vector<float> &)
computeBlinkAttributes
std::map<blinkType, float> vision::mod::LandmarkAttributes::computeBlinkAttributes(const Geometry2D_rect2D &, const std::vector<Geometry2D_point2D> &, std::vector<float> &)
Processing Create Faceprint request
ctrTracker_context *ctrTrackerInitialization_allocContext()
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/ObjectTracker/correlationTracker/ctrTrackerInitialization.c
CVML_status ctrTrackerInitialization_setUpTracker(CVPixelBufferRef, ctrTracker_context *, CGPoint *)
VNFaceBBoxAlignerProcessOption_InputFaceObservations
faceBoxPoseAligner-current
Could not read face box aligner model
Could not map face box aligner model
VN_facealigner_debug_intermediates/
_aligner_image.vdump
_aligner_image.png
_bboxes.json
_aligned_bbox_crop.png
aligned
VN aligner debug intermediates written to: %@
VNAlignBBox recieved a zero dimensioned image
Invalid face bounds supplied to face aligner
Could not create memory efficient crop for bbox alignment
Error aligning face bounds.  Bounds are likely out of bounds
VN_DEBUG_DUMP_FACE_ALIGNER_INTERMEDIATES
VNTrackingOption_ProcessingQueue
VNTrackingOption_TrackerKey
VNTrackingOption_TrackerType
VNTrackingOption_TrackingLevel
VNTrackingOption_InputBBox
Internal error: Tracker is busy with previous tracking requests. It needs to be reset to restart tracking sequence
Internal error: Conversion to Tracker coordinate system failed
Internal error: No frame to track objects was passed to the tracker
Internal error: Setting objects to track failed with error: %llu
Internal error: Tracking objects failed with error: %llu
Internal error: failed to initialize object IDs to rectangles dictionary
trackedFrameNumber
Tq,V_trackedFrameNumber
lastTrackedBBox
T{CGRect={CGPoint=dd}{CGSize=dd}},V_lastTrackedBBox
T@"NSUUID",R,V_key
level
T@"NSString",R,V_level
computeMag2d
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/HumanDetector/cv/gradient.cpp
Nrow>1 && Ncol>1
***acicOMP: NULL pointer or zero count
***acicOMP: no nnz or tolerance specified
***acicOMP: both nnz and tolerance specified
***acicOMP: nnz > dictionarySize
Processing VNImageBrightnessMetric request
Illegal dimensionality of weight vector less than 1.
dimensions_: 
Feature 
 exceeds dimensionality of weight vector: 
Error: scaling weight vector by non-positive value!
This can cause numerical errors in PEGASOS projection.
This is likely due to too large a value of eta * lambda.
Illegal index 
 in ValueOf. 
virtual float vision::mod::SimilarityMatrixLazy::getDistanceBetweenDescriptorIndexes(int, int)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/SimilarityMatrix/SimilarityMatrix/SimilarityMatrix_Lazy.cpp
virtual CVML_status vision::mod::SimilarityMatrixLazy::deleteDescriptorsWithIds(const std::vector<ImageDescriptorId> &)
XYPAIRS
CVML_status vision::mod::FaceClassifier_BoostedPixelDifference::loadModelFromFile(std::string)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/Classifiers/FaceClassifier_BoostedPixelDifference/FaceClassifier_BoostedPixelDifference.cpp
(%.2f,%.2f,%.2f,%.2f) 
(%.2f,%.2f,%.2f) 
 ...
%s (len %llu):
%7.4f 
More (y/anything)? 
VN can use Metal, device = %@, supported feature level = %ld
VN can use Metal but there's no device.
no request performer available
no image is available
vision::mod::ImageDescriptor_PixelPairDifferenceProcessor::ImageDescriptor_PixelPairDifferenceProcessor(const std::string)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/ImageDescriptor/ImageDescriptorPixelPairDifference/ImageDescriptor_PixelPairDifference.cpp
CVML_status vision::mod::ImageDescriptor_PixelPairDifferenceProcessor::loadPixelPairXYList(std::vector<float>)
CVML_status vision::mod::ImageDescriptor_PixelPairDifferenceProcessor::computeDescriptorForImage_Planar8(const vImage_Buffer &, float *)
virtual CVML_status vision::mod::ImageDescriptor_PixelPairDifferenceProcessor::computeDescriptorForImage_RGBA8888(const vImage_Buffer &, vision::mod::ImageDescriptorBufferAbstract &)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/ImageDescriptor/ImageDescriptorPixelPairDifference/ImageDescriptor_PixelPairDifference.hpp
virtual CVML_status vision::mod::ImageDescriptor_PixelPairDifferenceProcessor::computeDescriptorForImages_RGBA8888(const std::vector<vImage_Buffer> &, vision::mod::ImageDescriptorBufferAbstract &)
virtual CVML_status vision::mod::ImageDescriptor_PixelPairDifferenceProcessor::computeDescriptorForImages_Planar8(const std::vector<vImage_Buffer> &, vision::mod::ImageDescriptorBufferAbstract &)
CVML_status Geometry3D_SO3ToEuler(const float *, float *, float *, float *)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/Geometry3D/Geometry3D_Rotations.c
computeACF
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/HumanDetector/cv/ChnsFeature.cpp
img.channels==3
expFeatSz[0]==featSz[0]
expFeatSz[1]==featSz[1]
expFeatSz[0]==histSz[0]
expFeatSz[1]==histSz[1]
CVML_status ImageProcessing_ConvertABCD8888ToABCDPlanar(const vImage_Buffer *, vImage_Buffer *, _Bool)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/ImageProcessing/ImageProcessing_Conversions.c
CVML_status ImageProcessing_ConvertABCD8888ToBCDAPlanar(const vImage_Buffer *, vImage_Buffer *, _Bool)
CVML_status ImageProcessing_ConvertABCD8888ToBACDPlanar(const vImage_Buffer *, vImage_Buffer *, _Bool)
CVML_status ImageProcessing_ConvertABCD8888ToCBADPlanar(const vImage_Buffer *, vImage_Buffer *, _Bool)
CVML_status ImageProcessing_ConvertCVPixelBuffery420ToBGRA8888(const CVPixelBufferRef, vImage_Buffer *, _Bool)
2vuy
420f
y420
420v
CVML_status ImageProcessing_ConvertCVPixelBuffery420ToAYCbCr444(const CVPixelBufferRef, vImage_Buffer *, _Bool)
CVML_status ImageProcessing_ConvertCVPixelBuffery420ToLuma(const CVPixelBufferRef, vImage_Buffer *, _Bool)
CVML_status ImageProcessing_ConvertABCD8888ToGrayPlanar8(const vImage_Buffer *, ImageProcessing_ImageType, vImage_Buffer *, _Bool)
nil buffer passed into initWithImageBuffer
Error while trying to allocate VNImageRegistrationSignature object
rowProjections
rowSum
rowSumSq
colProjections
colSum
colSumSq
inconsistent row data
inconsistent column data
CVML_status Geometry3D_cartToHomo3D(const Geometry3D_cart3D *, Geometry3D_homo3D *)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/Geometry3D/Geometry3D_Homogeneous.c
CVML_status Geometry3D_homoToCart3D(const Geometry3D_homo3D *, Geometry3D_cart3D *)
VNImageprintGeneratorProcessOption_Timestamp
At least one of the image dimension is zero: width=%d, height=%d
unknown format for image buffer
Round ROI: %.2f %.2f %.2f %.2f
SrcMin: %d %d
SrcMax: %d %d
DstMin: %d %d
CVML_status ImageProcessing_deepCopyBufferFromCentralScaledROI(const vImage_Buffer *, ImageProcessing_ImageType, vImage_Buffer *)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/ImageProcessing/ImageProcessing_Crop.c
no valid initial image specifier was provided
projectionRows_planar8UtoF
projectionCols_planar8UtoF
CVML_status Projections_projectionRowsCols_planar8UtoF(const uint8_t *, int, int, size_t, float *, float *)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/ImageRegistration/Projections/Projections_Core.c
CVML_status Projections_computeProjectionDerivative(const float *, int, float *)
fastSlidingAdaBoostPred
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/HumanDetector/humandetector/TemplateObjectDetectorApply.cpp
slidingAdaBoostPred2
slidingSVMPred
svm.W.size() == svmSz[0]*svmSz[1]*svmSz[2]
Corr3d
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Vision_Sim/Vision-1.0.30/HumanDetector/cv/CVCommon.h
featSz.size() == 3
templateSz.size() == 3
Template.size() == templateSz[0] * templateSz[1] * templateSz[2]
templateSz[0] <= featSz[0]
templateSz[1] <= featSz[1]
templateSz[2] == featSz[2]
rowcorr
lenResult==lenA-lenB+1
GeomTransform_constructor: unknown transform model (%d)
GeomTransform_minSupportPoints: unknown transform model (%d), reset to RIGID
GeomTransform_changeCoordinateSystem failed
GeomTransform_setModel: unknown new model (%d) use the old model (%d)
GeomTransform_estimate: unknown transform model (%d) use RIGID
GeomTransform_numTestsToDo: unknown transform model (%d) use RIGID
Transf:
 %.9g, %.9g, %.9g 
 %.9g, %.9g, %.9g 
 %.9g, %.9g, %.9g
Transf: %f, %f, %f 
 %f, %f, %f 
 %f, %f, %f
RigidTransform_estimate: not symmetric positive definite matrix
RigidTransform_estimate: the %ld-th argument is wrong in sposv_ call
AffineTransform_estimate: not symmetric positive definite matrix
AffineTransform_estimate: the %ld-th argument is wrong in sposv_ call
HomographyTransform_estimate:The %ld-th eigenvector failed to converge
HomographyTransform_estimate:The %ld-th eigenvector failed to converge
HomographyTransform_estimate: the %ld-th argument is wrong in ssyevx_ call
HomographyTransform_estimate: the %ld-th argument is wrong in ssyevx_ call
HomographyTransform_estimate: the 9-th parameter is too small pp[8]=%f 
IPDetector_constructor: Cannot allocate mFltImage 
IPDetector_constructor: Cannot allocate mTmpBuffer 
IPDetector_constructor: Cannot allocate mCornerVec 
IPDetector_constructor: Cannot allocate mBX, mBY 
IPDetector_response: box filter failed
v16@?0i8i12
histogram equalization queue
histEqualization_uint8_inPlace: hist equalization err=%d
boxFilter_uint8_init: box filter failed when request minimum size err=%d
boxFilter_uint8: box filter failed err=%d
 invMatrix failed INFO1 = %ld
 invMatrix failed INFO2 = %ld
Norm_dirGeomTransform failed
%s : -[EAGLContext setParameter:...] failed with error %d
gl_UtilsCreateContext
%s : calloc failed
ImageRegistrationCreateContext
%s : CFDictionaryCreateMutable failed
%s : CFArrayCreateMutable failed
%s : HistEqCreateContext failed
%s : RegistrationEngine_constructor failed
imageRegQueue
%s : dispatch_queue_create failed
%s : NULL input parameters
ImageRegistrationPreregisterOneImage
%s : inputBuffer and extraBuffer image size mismatch
%s : histogram equalization failed during pre-registration
ImageRegistrationUnregisterOneImage
ImageRegister
%s : Need at least one non-reference image
%s : CFArrayGetCount(imageRegCtx->availExtraBuffers) != 0
%s : Could not locate scratch buffers
%s : CPU histogram equalization failed
HistogramEqualization
%s : invalid histogram equalization method
HistEqualizeCPU
%s : Unsupported image width,height
%s : Couldn't lock output buffer
%s : Couldn't lock input buffer
%s : CFArrayGetCount(imageRegCtx->availExtraBuffers) returned %d
GetUnusedExtraBuffer
GeomTransform_estimate failed
Pyramid_loadImage: incompatible size in pyramid (%lu!=%lu) or (%lu!=%lu)
v40@?0^Q8^Q16Q24Q32
WARNING: insufficient number of external corners provided (only %hu corners provided but minumum is %d)
Registration could not detect more that %d inlier corners at the highest resolution.
%s : GL warping program failed to compile/link
WarpingEngine_constructor
position
Binding vertext position attribute caused relinking failure in WarpingEngine!
texture
%s : glGetError returned 0x%04x
%s SHADER COMPILATION FAILED
VERTEX
FRAGMENT
<unknown>
Shader compile log:
<OOM with failed shader compile log>
PROGRAM LINK FAILED
Program link log:
<OOM with failed program link log>
attribute vec2 position;
varying   vec3 v_texCoord;
uniform mat3 H;
void main() { 
   v_texCoord.xy = 0.5 * (position + 1.0);
   v_texCoord = vec3(v_texCoord.xy, 1.0)*H;
   gl_Position = vec4(position.x, position.y, 0.0, 1.0);
varying   vec3 v_texCoord;
uniform sampler2D texture; 
void main() { 
   gl_FragColor = texture2DProj( texture, v_texCoord);
%s : GL program failed to compile/link
HistEqCreateContext
source
textureScale
textureBias
attribute vec2 position;
varying vec2 texcoord;
void main()
  texcoord = 0.5 * (position + 1.0);
  gl_Position = vec4(position.x, position.y, 0.0, 1.0);
precision mediump float;
uniform sampler2D source;
uniform sampler2D lut;
uniform float textureScale;
uniform float textureBias;
varying highp vec2 texcoord;
void main()
  vec4 texColor = texture2D(source, texcoord);
  texColor = textureScale * texColor + textureBias;
  gl_FragColor.xyzw = vec4(texture2D(lut, vec2(texColor.x, 0.0)).x,
                           texture2D(lut, vec2(texColor.y, 0.0)).x,
                           texture2D(lut, vec2(texColor.z, 0.0)).x,
                           texture2D(lut, vec2(texColor.w, 0.0)).x);
__cpu_indicator_init
/BuildRoot/Library/Caches/com.apple.xbs/Sources/clang/clang-900.2.26/src/projects/compiler-rt/lib/builtins/cpu_model.c
__cpu_model.__cpu_type < CPU_TYPE_MAX
__cpu_model.__cpu_subtype < CPU_SUBTYPE_MAX
libcompiler_rt abort
kCFAllocatorNull
CFDataCreateWithBytesNoCopy
CFPropertyListCreateWithData
CFPropertyListCreateFromXMLData
CFStringCreateWithCStringNoCopy
CFDictionaryGetValue
CFGetTypeID
CFStringGetTypeID
CFStringGetCString
CFRelease
/System/Library/CoreServices/SystemVersion.plist
IPHONE_SIMULATOR_ROOT
ProductVersion
%d.%d.%d
stringWithUTF8String:
stringWithFormat:
mainBundle
localizedStringForKey:value:table:
dictionaryWithObjects:forKeys:count:
errorWithDomain:code:userInfo:
exceptionWithName:reason:userInfo:
createNSErrorWithStatus:andMessage:
createNSExceptionWithStatus:andMessage:
standardUserDefaults
boolForKey:
defaultManager
stringByDeletingLastPathComponent
fileExistsAtPath:isDirectory:
fileHandleForUpdatingAtPath:
writeToFile:atomically:encoding:error:
seekToEndOfFile
stringByAppendingString:
dataUsingEncoding:
writeData:
closeFile
length
stringWithString:
stringWithCapacity:
insertString:atIndex:
replaceCharactersInRange:withString:
localeWithLocaleIdentifier:
setLocale:
setDateFormat:
date
stringFromDate:
init
resetFileNameURLWithCurentDateTime
initWithOptions:logEnabled:logFileNameBase:
currentDateTime
URLByAppendingPathComponent:
path
appendString:toLogFile:
padStringWithSpaces:toSize:
appendFormat:
logString:
logClusterMap:level:
isLogEnabled
initWithOptions:logEnabled:
logClusterMapL0:
logClusterLookupMapL0:
logClusterMapL1:
logClusterLookupMapL1:
.cxx_destruct
logFolderURL
logFileURL
logEnabled
fileNameBase
_logEnabled
_logFolderURL
_logFileURL
_fileNameBase
count
allKeys
countByEnumeratingWithState:objects:count:
objectForKeyedSubscript:
deleteCharactersInRange:
appendString:
logSuggestons:description:
objectAtIndexedSubscript:
UTF8String
logInputFaceIdsWithFlags:
logAllSuggestons:
logFilteredByInputQuerySuggestons:
logConnectedGroups:
logFinalSuggestionsList:
errorForInternalErrorWithLocalizedDescription:
class
isKindOfClass:
fileURLWithPath:
alloc
_parseOptions:error:
floatValue
boolValue
bytes
initializeLogging
objectAtIndex:
faceprint
faceId
numberWithLongLong:
addObject:
arrayWithObject:
setObjects:
setClusterId:
setObject:forKeyedSubscript:
dictionaryWithCapacity:
unsignedIntegerValue
objectForKey:
numberWithBool:
isEqual:
dictionary
numberWithFloat:
containsObject:
setWithObject:
allValues
unionSet:
minusSet:
allObjects
mutableCopy
isEqualToSet:
dataWithBytes:length:
unsignedIntValue
orderedSetWithCapacity:
longLongValue
intValue
array
getLevel0ClusteredIdsForFaceId:error:
errorForInternalErrorWithLocalizedDescription:underlyingError:
minusOrderedSet:
firstObject
unsignedLongValue
errorWithCode:message:
enumerateObjectsUsingBlock:
setObject:forKey:
addFaceObservations:toFaceDescriptorBuffer:
numberWithUnsignedInteger:
setShouldUpdateRepresentative:
setSuggestedIdsForRepresentative:
setTotalObjectCount:
numberWithInt:
getRepresentativenessForFaces:error:
suggestionsForClusterIdsWithFlags:affinityThreshold:error:
getClusterState:
getClusteredIds:
getLevel1ClusteredIdsGroupedByLevel0ClustersForFaceId:error:
getDistanceBetweenLevel0ClustersWithFaceId:andFaceId:error:
getDistanceBetweenLevel1Clusters:error:
getClustersForClusterIds:options:error:
getDistances:to:error:
maximumFaceIdInModelAndReturnError:
initWithOptions:error:
setGreedyClustererFaces_const:
convertUpdatePairsToClusters:
.cxx_construct
_clusteringLogger
_suggestionsLogger
_cacheFolderPath
_thresholdN
_state
_vectorMapReadOnlyFlagN
m_ClusteringImpl_const
stringWithCString:encoding:
errorWithAlgorithmError:
description
_cancellableUpdate:facesToMove:
clusterId
totalObjectCount
objects
shouldUpdateRepresentative
getClustersWithOptions:error:
cancelClustering:
m_ClusteringImpl
getLevel0ClusteredIdsForFaceId:
getDistanceBetweenLevel0ClustersWithFaceId:andFaceId:
addDescriptorIds:withSimilarityMatrix:error:
suggestionsForClusterIds:affinityThreshold:error:
refinedSuggestionsForClusterIds:fromClusters:affinityThreshold:error:
getClusteredIds
getLevel1ClusteredIdsGroupedByLevel0ClustersForFaceId:
getDistanceBetweenLevel0ClustersWithFaceIds:
getDistanceBetweenLevel1Clusters:
getDistances:to:
initWithRect:withFaceId:
setFaceId:
faceRect
setFaceRect:
framesSinceLast
setFramesSinceLast:
computeAverage
initWithScore:
addScore:
computeStandardDeviation
maxScore
setMaxScore:
minScore
setMinScore:
numScores
setNumScores:
sumScores
sumSqScores
setSwFaceId:
setSwCenter:
setSwSize:
setSwLastFrameSeen:
setHwFaceId:
setHwCenter:
setHwSize:
setHwLastFrameSeen:
hwCenter
hwSize
swCenter
swSize
hwFaceId
hwFaceRect
swFaceId
swFaceRect
overlapWithHwRect:
overlapWithSwRect:
swLastFrameSeen
hwLastFrameSeen
setCurConfig:
setFaceIdMapping:
setRenameMapping:
setFaceIdCounter:
arrayWithCapacity:
setFaceInfoArray:
setNumFramesSinceFullFaceCore:
setNumFramesNoFaces:
setForceFaceDetectionEnable:
setForceFaceDetailsEnable:
setFaceTimestampArray:
setLatestFaceTimestamp:
setLatestImageTimestamp:
setLastFaceIndex:
isEqualToString:
setVersion:
orientation
version
faceStatArray
setHwFaceRect:
hasLeftEye
hasRightEye
padRoiRect:paddingX:paddingY:
isSyncedWithImage
temporalOrder
faceInfoArray
setFacesRoiRect:
setNumHWFaces:
boundingBox
sortedArrayUsingComparator:
subarrayWithRange:
calculateFaceCoreROI:imageStat:needSWFaceDetection:
initWithCVPixelBuffer:options:
forceFaceDetectionEnable
setDetectionLevel:
setRegionOfInterest:
arrayWithObjects:count:
performRequests:error:
results
observationWithBoundingBox:
forceFaceDetailsEnable
_filterFacesToProcess:imageSize:imageStat:
initWithCompletionHandler:
applyConfigurationOfRequest:
setInputFaceObservations:
facesRoiRect
setNormalizedFaceRect:
setFoundByFaceCore:
landmarks
leftEye
setHasLeftEye:
isBlinking
setLeftEyeOpen:
setLeftEyeBlinkScore:
setLeftEyeRect:
rightEye
setHasRightEye:
setRightEyeOpen:
setRightEyeBlinkScore:
setRightEyeRect:
expressionsAndScores
setSmiling:
leftEyeRect
rightEyeRect
value:withObjCType:
getValue:
setFocusScore:
burstImages
focusScore
setNormalizedFocusScore:
setNormalizedSigma:
imageId
faceIdCounter
renameMapping
removeObjectForKey:
faceIdMapping
curConfig
addEntriesFromDictionary:
removeObjectAtIndex:
arrayWithArray:
dictionaryWithDictionary:
unsignedLongLongValue
faceTimestampArray
doubleValue
numberWithDouble:
insertObject:atIndex:
addFaceToArray:
timestamp
lastFaceIndex
setTimestamp:
setHasRollAngle:
setRollAngle:
setHasYawAngle:
setYawAngle:
setHasPitchAngle:
setPitchAngle:
setSmileScore:
setIsSyncedWithImage:
initWithVersion:
findOverlappingFaceStat:imageStat:
findFacesInImage:imageStat:
calculateFaceFocusInImage:imageStat:
calcFaceScores:
adjustFaceIdsForImageStat:
extractFacesFromMetadata:
addFacesToImageStat:imageSize:
dumpFaceInfoArray
timeBlinkDetectionDone
setTimeBlinkDetectionDone:
timeFaceDetectionDone
setTimeFaceDetectionDone:
latestFaceTimestamp
numFramesSinceFullFaceCore
numFramesNoFaces
latestImageTimestamp
_forceFaceDetailsEnable
_faceIdCounter
_numFramesSinceFullFaceCore
_numFramesNoFaces
_lastFaceIndex
_version
_curConfig
_faceIdMapping
_renameMapping
_faceInfoArray
_faceTimestampArray
_latestImageTimestamp
points
pointCount
setSvmParameters:
svmParameters
computeKernelValueWithSupportVector:
scaleVector
predictResult
isBurstAction
testAverageCameraTravelDistance
setTestAverageCameraTravelDistance:
testMaxRegistrationErrorIntegral
setTestMaxRegistrationErrorIntegral:
testMaxPeakRegistrationError
setTestMaxPeakRegistrationError:
testMeanPeakRegistrationError
setTestMeanPeakRegistrationError:
testBeginningVsEndAEMatrixVsAverageAdjacentAEMatrix
setTestBeginningVsEndAEMatrixVsAverageAdjacentAEMatrix:
testInOutRatio
setTestInOutRatio:
testMaxInnerDistance
setTestMaxInnerDistance:
testAverageRegistrationErrorSkewness
setTestAverageRegistrationErrorSkewness:
testMinRegionOfInterestSize
setTestMinRegionOfInterestSize:
testMaxRegistrationErrorSkewness
setTestMaxRegistrationErrorSkewness:
hasBeenScaled
testVector
_svmParameters
warmUpRequestPerformer:error:
initWithName:options:completionHandler:
modelRequestHandlerAndReturnError:
options
clusterContextWithOptions:allowingCreation:error:
setSuggestionsForCluster:
setResults:
observationsCacheKey
sequencedRequestPreviousObservationsKey
internalPerformInContext:error:
initWithType:cachePath:state:readOnly:threshold:error:
_createGreedyClustererWith:error:
localizedDescription
initWithType:cachePath:state:threshold:error:
_createGreedyClusterer:state:error:
_threshold
_cacheDirectoryPath
_readOnly
computeDistanceToFaceprint:withDistanceFunction:error:
conformsToProtocol:
representativenessForFaces:error:
distanceBetweenFacesWithFaceprint:andFaceprint:error:
allClusteredFaceIdsAndReturnError:
clusteredFaceIdsForClusterContainingFaceId:error:
l1ClusteredFaceIdsGroupedByL0ClustersForClustersContainingFaceIds:error:
distanceBetweenClustersWithFaceId:andFaceId:error:
distanceBetweenLevel1Clusters:error:
suggestionsForClustersWithFaceIds:affinityThreshold:error:
_clusterer
updateModelByAddingFaces:andRemovingFaces:error:
resetModelState:error:
saveAndReturnCurrentModelState:
updateModelByAddingFaces:error:
updateModelByRemovingFaces:error:
errorForMemoryAllocationFailure
clusterMethod
addDescriptors:error:
errorWithCode:message:underlyingError:
deleteDescriptors:
numberWithUnsignedLongLong:
useClusterObservation
errorForUnimplementedFunctionWithLocalizedDescription:
addFaces:error:
removeFaces:error:
reset
clusterFacesWithOptions:error:
clusterState
restoreClusterState:cacheFolderPath:error:
getClusteredFaceIds
getGroupedClusteredFaceIdsForFaceId:
getDistanceBetweenClustersWithFaceIds:
matrix
setMatrix:
_obsDictById
_clustering
_maxFaceId
_useClusterObservation
_matrix
_clusterMethod
initWithClusterIDs:completionHandler:
copy
clusterIDs
completionHandler
validateRequiredClusterIDs:error:
initWithClusterIDs:
hasCancellationHook
newDefaultRequestInstance
internalCancelInContext:error:
_clusterIDs
pathForResource:ofType:
initializeMetalContext:error:
useGPU
metalDevice
wisdomParams
setWithCapacity:
shouldDumpDebugIntermediates
createDirectoryAtURL:withIntermediateDirectories:attributes:error:
initImageDescriptorBuffer:descriptorBuffer:error:
classifyImageHierarchicallyWithDescriptors:usingImageClassifier:andHierarchicalClassifier:andMinConfidenceForClassification:andMinConfidenceRatioForClassification:andMaxLabelsToReturn:outputDebugDictionary:options:metalContext:error:
identifier
validatedImageBufferFromOptions:error:
fileURL
lastPathComponent
stringByDeletingPathExtension
stringValue
dataWithJSONObject:options:error:
writeToFile:atomically:
logInternalError:
sceneprints
lengthInBytes
descriptorData
distanceMode
calculateImageDescriptors:regionOfInterest:warningRecorder:descriptorBuffer:debugIntermediatesDumpPath:outputDebugDictionary:error:
computeSoftmaxLabelsAndConfidence:andUsingDescriptorBuffer:andPopulateSoftmaxLabelsAndConfidence:options:metalContext:error:
initWithData:elementCount:lengthInBytes:distanceMode:softmaxLabelsAndConfidence:
observationWithSceneprints:
width
height
computeImageDescriptorsWithImage:regionOfInterest:usingDescriptorProcessor:withTileCount:andScaleImage:andAugmentationMode:andPopulateTheBuffer:debugIntermediatesDumpPath:outputDebugDictionary:options:metalContext:error:
processWithOptions:regionOfInterest:warningRecorder:error:
calculateImageDescriptors:regionOfInterest:warningRecorder:error:
getLabels
mDescriptorProcessor
mClassifier
mHierarchicalClassifier
mBlacklistedTerms
alignedBoundingBox
croppedBufferWithWidth:height:format:cropRect:options:error:
alignedRotationAngle
predictFaceOnImageCrop:faceObservation:error:
mPixelDifferenceFaceClassifier
dictionaryWithObjectsAndKeys:
code
userInfo
cStringUsingEncoding:
localizedFailureReason
errorForCancellationOfRequest:
errorForMissingOptionNamed:
errorForInvalidOption:named:
errorForInvalidArgument:named:
initWithTargetedCVPixelBuffer:completionHandler:
initWithTargetedCGImage:completionHandler:
initWithTargetedCIImage:completionHandler:
initWithTargetedImageURL:completionHandler:
initWithTargetedImageData:completionHandler:
burstFrameIdentifier
imageProperties
requiredTargetedImageSpecifierReturningError:
imageBufferAndReturnError:
modelContextObject
burstAnalysisLoggingCallback
setLoggingCallback:
setModelContextObject:
addBurstFrameWithIdentifier:fromImageBuffer:withProperties:error:
setBurstFrameIdentifier:
setImageProperties:
_burstFrameIdentifier
_imageProperties
UUID
UUIDString
leftEyeOpen
rightEyeOpen
smiling
foundByFaceCore
normalizedFaceRect
normalizedSigma
normalizedFocusScore
faceScore
leftEyeBlinkScore
rightEyeBlinkScore
smileScore
FCRLeftEyeFeaturesOffset
FCRRightEyeFeaturesOffset
FCRSmileFeaturesOffset
FCRBlinkFeaturesSize
FCRSmileFeaturesSize
allocWithZone:
initWithFaceStat:
copyWithZone:
setFaceScore:
setFCRLeftEyeFeaturesOffset:
setFCRRightEyeFeaturesOffset:
setFCRSmileFeaturesOffset:
setFCRBlinkFeaturesSize:
setFCRSmileFeaturesSize:
FCRSmileAndBlinkFeatures
setFCRSmileAndBlinkFeatures:
hasRollAngle
hasYawAngle
rollAngle
yawAngle
smallFace
setSmallFace:
hasPitchAngle
pitchAngle
_hasPitchAngle
_isSyncedWithImage
_pitchAngle
_hwFaceRect
setImageId:
setFaceStatArray:
setOrientation:
setMaxSkewness:
setHasRegistrationData:
dealloc
getSharpnessAndBlurLimits
AEAverage
setAEDelta:
maxSkewness
setRegistrationErrorX:
setRegistrationErrorY:
setRegistrationErrorIntegral:
registrationErrorIntegral
setActionClusteringScore:
updateROI:
computeImageColorHistogram:
computeImageSharpnessOnGrid:
computeBlurStatsOnGrid:
computeImageProjections:
getBytes:length:
computeFacialFocusScoreSum
allocateMeanStdPingPongBuffers::::
assignMeanStdBuffers:
initWithIdentifier:
computeSmoothedGridROI:nextStat:
flagAsGarbage
performRegistration:deltaCol:deltaRow:
canRegister
writeGridROI:
computeImageData:faceIDCounts:
collapseSharpnessGrid
computeRuleOfThreeDistance
computeSmilePercentage
computeImageDistance:
computeAEMatrixDifference:
setAEMatrix:
computeAEMatrix:
aeMatrix
computeScore:
compareImageStats:
compareImageOrder:
colorHistogram
exclude
setExclude:
AEStable
setAEStable:
setAEAverage:
AETarget
setAETarget:
AFStable
setAFStable:
setTemporalOrder:
avgHorzDiffY
setAvgHorzDiffY:
blurExtent
setBlurExtent:
imageScore
setImageScore:
actionScore
setActionScore:
timeReceived
setTimeReceived:
registrationErrorX
registrationErrorY
hasRegistrationData
actionClusteringScore
numHWFaces
emotionallyRejected
setEmotionallyRejected:
doLimitedSharpnessAndBlur
setDoLimitedSharpnessAndBlur:
setTx:
setTy:
isGarbage
setIsGarbage:
roiSize
setRoiSize:
AEDelta
numEntries
dissimilarity
projectionSignature
sharpnessGrid
gridWidth
gridHeight
gridROI
smoothedROI
_AEDelta
_imageId
_faceStatArray
initWithRequestPerformer:imageBuffer:observationsCache:
performRequests:inContext:error:
performRequests:onCVPixelBuffer:orientation:error:
initWithBuffer:options:
_performRequests:onUnvettedImageBuffer:error:
performRequests:onCGImage:orientation:error:
initWithCGImage:options:
performRequests:onCIImage:orientation:error:
initWithCIImage:options:
performRequests:onImageURL:orientation:error:
initWithURL:options:
performRequests:onImageData:orientation:error:
initWithData:options:
prepareForPerformingRequestsOfClass:error:
prepareForPerformingRequests:error:
cancelAllRequests
requestForcedCleanupWithOptions:
forcedCleanupWithOptions:
requestForcedCleanupWithOptions:completion:
asyncProcessingDispatchQueue
sharedInstance
purgeAll
manager
forcedCleanup
purgeAllCaches
requestForcedCleanup
performRequests:onCVPixelBuffer:error:
performRequests:onCGImage:error:
performRequests:onCIImage:error:
performRequests:onImageURL:error:
performRequests:onImageData:error:
performRequests:onImageSpecifier:error:
_requestPerformer
initWithBuffer:orientation:options:
initWithCVPixelBuffer:orientation:options:
imageSpecifierWithCVPixelBuffer:orientation:options:error:
initWithImageSpecifier:
initWithCGImage:orientation:options:
imageSpecifierWithCGImage:orientation:options:error:
initWithCIImage:orientation:options:
imageSpecifierWithCIImage:orientation:options:error:
initWithURL:orientation:options:
imageSpecifierWithURL:orientation:options:error:
initWithData:orientation:options:
imageSpecifierWithData:orientation:options:error:
_options
_imageSpecifier
_observationsCache
setModelRequestHandler:
setBurstAnalysisLoggingCallback:
_burstAnalysisLoggingCallback
_modelContextObject
setValue:forKey:
getMatrixSize
getMaximumValidMatrixDistance
createCopyForDescriptorIds:
getDescriptorIdsForRange:
getDistanceBetweenDescriptor:andDescriptor:
getAllDistancesForId:
containsId:
getImpl
m_MatrixImpl
methodSignatureForSelector:
invocationWithMethodSignature:
setSelector:
setTarget:
setArgument:atIndex:
invoke
getReturnValue:
bufferWithWidth:height:format:options:error:
_createN:CVPixelBuffers:withPixelFormat:width:height:error:
cachedFloatingImageBufferReturningError:
_createHomographicPixelBufferFromImageBuffer:options:error:
getReferenceImageBuffer:registrationSignature:forRequestPerformingContext:options:error:
_calculateHomographicWarpTransform:ofFloatingImagePixelBuffer:ontoReferenceImagePixelBuffer:usingImageRegistrationContext:glContext:seededWithPreviousWarpTransform:error:
cachedFloatingImageRegistrationSignatureReturningError:
setReferenceImageSignature:
setFloatingImageSignature:
setWarpTransform:
wantsSequencedRequestObservationsRecording
detectorOfType:options:error:
initWithIdentifier:confidence:
initWithSceneObservation:completionHandler:
setValue:forRequestOption:
sceneObservation
validateImageBuffer:ofNonZeroWidth:andHeight:error:
qosClass
requestPerformerAndReturnError:
warnings
regionOfInterest
getSerialDispatchQueueSceneDetector
confidence
compare:
recordWarning:value:
enumerateKeysAndObjectsUsingBlock:
knownSceneClassifications
initWithSceneObservation:
setSceneObservation:
_sceneObservation
initWithSignatureData:
computeBlurSignatureForGrayscaleImage:error:
setSignatureData:
getSignatureData
_signatureData
computeBlurScore:onGrayscaleImage:andWithRegionOfInterestInImageCoordinates:andRegionOfInterestInsetFactor:error:
computeBlurScore:onGrayscaleImage:insetFactor:error:
computeBlurScore:usingBlurSignature:insetFactor:imageROI:error:
computeEdgeWidthBlurScore:onGrayscaleImage:error:
computeApproximateBlurScore:onGrayscaleImage:sampledPixelsCount:insetFactor:error:
computeApproximateBlurScore:onRGBAImage:sampledPixelsCount:insetFactor:error:
recordDefaultOptionsInDictionary:
_newTrackerOptionsAndReturnError:
trackerWithOptions:error:
releaseTracker:
_trackingLevelOptionFromTrackingLevelEnum
trackerType
inputObservation
uuid
_trackingLevelEnumFromTrackingLevelOption:
initWithDetectedObjectObservation:completionHandler:
trackingLevel
isLastFrame
raise:format:
_resetTrackerIfNeeded:trackerProvider:options:error:
isTracking
setTrackedObjects:inFrame:error:
trackInFrame:error:
level
lastTrackedBBox
setTrackingLevel:
initWithDetectedObjectObservation:
setInputObservation:
setLastFrame:
_inputObservation
_trackingLevel
_lastFrame
setMetalDevice:
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isMemberOfClass:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
debugDescription
newCommandQueue
newCommandQueueWithMaxCommandBufferCount:
heapTextureSizeAndAlignWithDescriptor:
heapBufferSizeAndAlignWithLength:options:
newHeapWithDescriptor:
newBufferWithLength:options:
newBufferWithBytes:length:options:
newBufferWithBytesNoCopy:length:options:deallocator:
newDepthStencilStateWithDescriptor:
newTextureWithDescriptor:
newSamplerStateWithDescriptor:
newDefaultLibrary
newDefaultLibraryWithBundle:error:
newLibraryWithFile:error:
newLibraryWithURL:error:
newLibraryWithData:error:
newLibraryWithSource:options:error:
newLibraryWithSource:options:completionHandler:
newRenderPipelineStateWithDescriptor:error:
newRenderPipelineStateWithDescriptor:options:reflection:error:
newRenderPipelineStateWithDescriptor:completionHandler:
newRenderPipelineStateWithDescriptor:options:completionHandler:
newComputePipelineStateWithFunction:error:
newComputePipelineStateWithFunction:options:reflection:error:
newComputePipelineStateWithFunction:completionHandler:
newComputePipelineStateWithFunction:options:completionHandler:
newComputePipelineStateWithDescriptor:options:reflection:error:
newComputePipelineStateWithDescriptor:options:completionHandler:
newFence
supportsFeatureSet:
supportsTextureSampleCount:
minimumLinearTextureAlignmentForPixelFormat:
getDefaultSamplePositions:count:
newArgumentEncoderWithArguments:
newIndirectArgumentEncoderWithArguments:
name
registryID
maxThreadsPerThreadgroup
isLowPower
isHeadless
isRemovable
recommendedMaxWorkingSetSize
isDepth24Stencil8PixelFormatSupported
currentAllocatedSize
maxThreadgroupMemoryLength
areProgrammableSamplePositionsSupported
readWriteTextureSupport
argumentBuffersSupport
indirectArgumentBuffersSupport
areRasterOrderGroupsSupported
initWisdomParams
mapMetalDeviceNameToWisdomParams
containsString:
initWithMetalDevice:
_useGPU
_metalDevice
_wisdomParams
hasPrefix:
substringFromIndex:
detectorName
validateNonZeroImageWidth:height:componentNameProvidingBlock:error:
getArray:forKey:inOptions:withElementsOfClass:requiredMinimumCount:allowedMaximumCount:error:
validateImageBuffer:error:
bestImageWidth:height:format:
processingQueue
setProcessingQueue:
backingStore
_metalContext
_backingStore
_processingQueue
uppercaseLetterCharacterSet
scannerWithString:
isAtEnd
scanUpToCharactersFromSet:intoString:
scanCharactersFromSet:intoString:
decodeObjectOfClass:forKey:
decodeObjectForKey:
numberWithUnsignedInt:
encodeObject:forKey:
dataWithBytesNoCopy:length:freeWhenDone:
initWithCapacity:
numberWithUnsignedChar:
regionNameAtNormalizedAlignedFaceCoordinate:
supportsSecureCoding
encodeWithCoder:
initWithCoder:
setRegionMap:deallocateBuffer:userBBox:alignedBBox:valueToLabelMap:
getRegionLabels
regionNameAtImageCoordinate:imageSize:
regionNameAtNormalizedFaceCoordinate:
regionLabels
setRegionLabels:
mRegionMap
mUserBBox
mInternalAlignedBBox
mDeallocateBuffer
mPixelValueToRegionLabelMap
_regionLabels
methodForSelector:
instancesRespondToSelector:
instanceMethodForSelector:
object:overridesSelector:
inputFaceObservations
validateRequiredFaceObservations:error:
setRepresentativenessById:
setClusters:
resetWithSignallingBlock:
releaseSignallingBlock
resetAndPerformBlock:usingSignallingBlock:
signalCancellation
wasSignalled
_signallingBlock
_lock
_signalled
weakObjectsHashTable
lock
objectEnumerator
nextObject
purgeCachedRepresentations
unlock
removeObject:
contextWithMTLDevice:options:
contextWithOptions:
addImageBuffer:
removeBuffer:
sharedCIContextWithOptions:
mainCIContext
mainCIContextMetalDevice
lowPriorityCIContext
lowPriorityCIContextMetalDevice
activeImageBuffers
bufferTableLock
obtainImageSourceRefWithSubSampleFactor:andLowPriorityHint:
_obtainCreatedCGImageSourceRefAtAddress:forSubSampleFactor:protectedWithUnfairLock:operatingInLowPriority:
obtainImageSourceRef
initWithImageURL:
initWithImageData:
imageURL
imageData
exifOrientation
_getOrientationLock
_loadSubSample1Lock
_loadSubSample2Lock
_loadSubSample4Lock
_loadSubSample8Lock
_imageSourceSubsample1
_imageSourceSubsample2
_imageSourceSubsample4
_imageSourceSubsample8
_imageURL
_imageData
_orientation
isSubclassOfClass:
initWithOptions:
_helpReadOrientationFromOptionsDictionary:
imageWithCGImage:
imageByApplyingOrientation:
imageByCroppingToRect:
imageByApplyingTransform:highQualityDownsample:
extent
copyColorspaceForFormat:bitmapInfo:
render:toCVPixelBuffer:bounds:colorSpace:
_useCoreImageForFormat:
imageWithContentsOfURL:options:
imageWithData:options:
imageByApplyingTransform:
calculateOrientationCorrectedImageDimensions
getCameraIntrinsicsAvailable:
initWithBufferOrImage:options:
originalPixelBuffer
getPixelFocalLengthIfAvailable:
getCameraOpticalCenterIfAvailable:
isBufferInMemoryWithWidth:height:format:
processInChunksOfSize:overlapFraction:options:roi:handler:error:
makeClippedRectAgainstImageExtentUsingOriginalRect:
createBufferWithMaxSideLengthOf:andPixelFormat:andOptions:error:
createCroppedBufferWithMaxSideLengthOf:andCropBounds:andPixelFormat:andOptions:error:
_origPixelBuffer
_pixelBufferReps
_origCIImage
_imageSourceManager
_origImageWidth
_origImageHeight
shared
bundleForClass:
setIs_memory_tight:
is_memory_tight
setContext_metal:
setContext_cpu:
autoSetupNetBaseName:weights:scaleConfig:setupMode:computePath:autoAspectRatio:forceReset:useLowPriorityMode:gpuPriority:
initWithNetwork:
detect:face:sublandmark:doFaceRectFix:
newface
setForceMaxNScales:
wipeLayersMemory
autoResizeForAspectRatio:useLowPriorityMode:gpuPriority:
processBlobNoRotation:tex:doBGRA2RGBA:
getFacesFromNetworkResultOriginalWidth:originalHeight:
bounds
pathExtension
initWithNetworkAtPath:context:platform:computePath:
strongToStrongObjectsMapTable
preferBackgroundProcessing
preferredMetalContext
detectionLevel
integerValue
requestWithName:options:completionHandler:
defaultRequestInstanceWarmUpPerformer:error:
requestWithName:options:
copyStateOfRequest:
setWarnings:
cancellationTriggered
cachedObservationsForRequest:
recordSequencedObservationsForRequest:
cacheObservationsForRequest:
valueForWarning:
setCancellationTriggered:
disallowsGPUUse
null
_updateVNRequestOptionPreferredMetalContext
getOptionalArray:forKey:inOptions:withElementsOfClass:error:
initialize
getOptionalObject:ofClass:forKey:inOptions:error:
getRequiredObject:ofClass:forKey:inOptions:error:
getDoubleValue:forKey:inOptions:error:
getDoubleValue:forKey:inOptions:withDefaultValue:error:
getFloatValue:forKey:inOptions:error:
getFloatValue:forKey:inOptions:withDefaultValue:error:
getOptionalInputFacesArray:inOptions:error:
dependencyProcessingOrdinality
setValue:forPrivateOption:
valueForPrivateOption:
performInContext:error:
cancel
setPreferBackgroundProcessing:
dumpIntermediateImages
setDumpIntermediateImages:
setPreferredMetalContext:
setDisallowsGPUUse:
metalContextPriority
setMetalContextPriority:
cancellationSemaphore
setCancellationSemaphore:
modelFileBackingStore
setModelFileBackingStore:
requestName
_requestName
_completionHandler
_warningRecorder
_cancellationSemaphore
_cancellationQueue
_detectionLevel
_preferredMetalContext
_metalContextPriority
_disallowsGPUUse
_preferBackgroundProcessing
_dumpIntermediateImages
_cancellationTriggered
_results
_modelFileBackingStore
_createTrackerWithLevel:options:error:
setUUID:
_convertDetectedObjectObservationsToFaceObservations:error:
_runBBoxAlignmentOnTrackingResults:trackerResults:error:
_runFaceClassifierOnBBoxAlignmentResults:trackingResults:bBoxAlignmentResults:error:
_postProcessTrackingResults:trackerResults:error:
initWithFaceObservations:
faceClassifierBoostedPixelDifference
hasBBoxBeenAligned
setBoundingBox:
setConfidence:
_parseInputObservations:imageBuffer:error:
initWithFaceObservations:completionHandler:
getOptionalValidatedInputFaceObservations:error:
validatedInputFaceObservationsWithError:
_inputFaceObservations
getSerialDispatchQueueHumanDetector
setContext:
context
getKey:fromDictionary:withDefault:
setDebugMode:
setTimerMode:
setQualityCriteriaList:
setClusterSplitDistanceType:
setUseTimestampAdjustedDistances:
setPerformClustersPostprocessing:
setPerformSceneClassification:
setRoiAreaThreshold:
setInliersRatioThreshold:
setNumberOfKeypointsToConsider:
setNaturalClusteringDistanceThreshold:
getNextImage:
qualityCriteriaList
initWithImageData:andQualityCriteria:context:error:
computeClusteringTreeForImageDescriptors:error:
computeClusteringForClusteringTree:intoKGroups:error:
computeNaturalClusteringForClusteringTree:error:
computeClusteringTreeForImageDescriptors:assumeDescriptorsAreSorted:error:
getHostTime
sortImageDescriptorsChronologically:
computeHierarchicalClusteringOfImageDescriptors:results:context:
initWithNode:freeNodeOnDealloc:
node
computeClusteringIntoKGroups:forHierarchicalTree:context:
convertClusterNodesListToDescriptorsList:
performClustersPostprocessing:error:
computeClusteringUsingDistanceThreshold:forHierarchicalTree:context:
computeNaturalClusteringForHierarchicalTree:context:
exifTimestamp
descriptorId
processImagesFromDataProvider:error:
computeClusteringOfImageDescriptors:intoKGroups:error:
computeNaturalClusteringOfImageDescriptors:error:
computeClusteringForClusteringTree:usingThreshold:error:
_context
setNode:
setFreeNodeOnDealloc:
nodeId
descriptor
left
right
distance
avgDistance
leafsCount
getLeafNodes
freeNodeOnDealloc
_freeNodeOnDealloc
_node
imageSpecifierWithCVPixelBuffer:orientation:error:
initWithCVPixelBuffer:
imageSpecifierWithCGImage:orientation:error:
initWithCGImage:
imageSpecifierWithCIImage:orientation:error:
initWithCIImage:
imageSpecifierWithURL:orientation:error:
isFileURL
initWithFileURL:
imageSpecifierWithData:orientation:error:
initWithData:
imageSpecifierWithCVPixelBuffer:error:
imageSpecifierWithCGImage:error:
imageSpecifierWithCIImage:error:
imageSpecifierWithURL:error:
imageSpecifierWithData:error:
initInternal
newImageBufferWithOptions:error:
_imageBuffer
imageSpecifierWithObject:error:
pixelBuffer
stringByAppendingFormat:
_pixelBuffer
cgImage
_cgImage
ciImage
_ciImage
fileSystemRepresentation
_fileURL
data
_data
trackedCorners
_convertCornerObservationsToRectangleObservation:error:
setLastTrackedBBox:
setTrackedFrameNumber:
trackedFrameNumber
reset:
bottomLeft
_trackingRectAroundPoint:trackingRectSize:
bottomRight
topLeft
topRight
setBottomLeft:
setTopLeft:
setBottomRight:
setTopRight:
_cornerTrackersImpl
_rectangleTrackingProcessingQueue
includeClusters
includeAllImageIdentifiers
includeAllImageStats
bestImageIdentifiers
setBestImageIdentifiers:
coverImageIdentifier
setCoverImageIdentifier:
isAction
setIsAction:
isPortrait
setIsPortrait:
allClusters
allImageIdentifiers
setAllImageIdentifiers:
allImageStats
setAllImageStats:
setIncludeClusters:
setIncludeAllImageIdentifiers:
setIncludeAllImageStats:
_includeClusters
_includeAllImageIdentifiers
_includeAllImageStats
load:
baseAddress
unload:
requiredFaceObservationInOptions:withOptionName:error:
landmarkPoints
setExpressionsAndScores:
expressionTypeFromString:
createExpressionAndConfidencesDictionaryFromScores:
createExpressionDetectionDictionaryFromScores:
m_FaceAttributesImpl
mModelFilesWereMemmapped
m_LandmarkRefinerModelFileHandle
currentVersion
vn_decodeCodingVersionForKey:
decodeIntegerForKey:
setWithObjects:
decodeObjectOfClasses:forKey:
vn_encodeCodingVersion:forKey:
encodeInteger:forKey:
elementCount
softmaxLabelsAndConfidence
setDescriptorData:
setElementCount:
setLengthInBytes:
setSoftmaxLabelsAndConfidence:
setDistanceMode:
_softmaxLabelsAndConfidence
_descriptorData
_elementCount
_lengthInBytes
_distanceMode
dividerScore
leftImage
actionAmount
compareDividers:
compareIndices:
compareActionAmounts:
setDividerScore:
setLeftImage:
trueLocalMaximum
setTrueLocalMaximum:
setActionAmount:
noiseThreshold
setNoiseThreshold:
highNoiseThreshold
setHighNoiseThreshold:
setAlgorithm:
valueForKey:
textBoxesForImage:error:
reportCharacterBoxes
initWithDimensions:
minimumCharacterPixelHeight
setMinimumCharacterHeight:
detectDiacritics
setDetectDiacritics:
minimizeFalseDetections
setMinimizeFalseDetections:
minimumCharacterHeight
setRecognitionLanguage:
setReturnSubFeatures:
regionOfInterestPixelRectForWidth:height:
detectFeaturesInBuffer:withRegionOfInterest:error:
type
textObservationWithBoundingBox:
text
setText:
subFeatures
setCharacterBoxes:
algorithm
textRecognition
_detectTextWithRequestPerformingContext:error:
_detectCreditCardTextWithRequestPerformingContext:error:
setReportCharacterBoxes:
setTextRecognition:
setMinimumCharacterPixelHeight:
_algorithm
_textRecognition
_minimumCharacterPixelHeight
_reportCharacterBoxes
_detectDiacritics
_minimizeFalseDetections
corners
initWithTopLeft:bottomLeft:bottomRight:topRight:
initWithBoundingBox:
detectorOfType:backingStore:options:error:
cascadeStepCountLoaded
cascadeStepCountInOriginalModel
purgeIntermediates
forcedCleanupFacePipelineWithLevel:
forcedCleanupScenePipelineWithLevel:
forcedCleanupJunkPipelineWithLevel:
getSerialDispatchQueueFaceDetectorAccurate
getSerialDispatchQueueFaceDetectorBalanced
getSerialDispatchQueueFaceDetectorFast
getSerialDispatchQueueFaceBoxAligner
getSerialDispatchQueueFaceLandmarkDetector
getSerialDispatchQueueFaceExpressionDetector
getSerialDispatchQueueFacePrinter
getSerialDispatchQueueJunkDetector
getSerialDispatchQueueImageprintGenerator
_faceDetectorAccurate
_faceDetectorBalanced
_faceDetectorFast
_faceBoxAligner
_faceLandmarkDetector
_faceExpressionDetector
_faceprintGenerator
_humanDetector
_junkIdentifier
_sceneClassifier
_imageprintGenerator
_faceDetectorAccurateSerialQueue
_faceDetectorBalancedSerialQueue
_faceDetectorFastSerialQueue
_faceBoxAlignerSerialQueue
_faceLandmarkDetectorSerialQueue
_faceExpressionDetectorSerialQueue
_faceprintGeneratorSerialQueue
_humanDetectorSerialQueue
_junkIdentifierSerialQueue
_sceneClassifierSerialQueue
_imageprintGeneratorSerialQueue
initWithImageBuffer:andOptions:error:
previousSequencedObservationsForRequest:
validateArray:named:hasElementsOfClass:requiredMinimumCount:allowedMaximumCount:error:
floatingImageSignature
optionNameForTargetedImageSpecifyingObject
_cachedFloatingImageBuffer
_cachedFloatingImageSignature
mHumanDetectorAlgorithmImpl_
removeAllObjects
hasWarnings
recordWarnings:
_warnings
indexOfObject:
numberWithUnsignedLong:
setClusterState:
setClusteredFaceIds:
clusteredFaceIds
setGroupedClusteredFaceIdsForCluster:
groupedClusteredFaceIdsForCluster
setDistance:
dateFromString:
timeIntervalSince1970
getHostTimeInNanos
createErrorWithCode:andMessage:
freeVImageBuffer:
parseExifTimestamp:
computeSharpnessQualityForImage:result:
computeImageQuality:forCriteria:error:
sortedArrayUsingSelector:
_allBarcodeSymbologies
componentsJoinedByString:
unsignedCharValue
initWithPayload:symbolVersion:maskPattern:errorCorrectionLevel:
initWithPayload:isCompact:layerCount:dataCodewordCount:
initWithPayload:isCompact:rowCount:columnCount:
locateMode
initWithKeyOptions:valueOptions:capacity:
_ACBarcodeRecognizerLocateMode
symbologies
barcodeSymbologyForACBSBarcodeType:
_getCornerPointsFromCodeLocationPoints:bottomLeft:topLeft:topRight:bottomRight:
initWithSymbology:descriptor:topLeft:bottomLeft:bottomRight:topRight:
newBarcodeObservationForACBSBarcodeInfo:imageWidth:imageHeight:roiCroppingPixelRect:scanConfidence:error:
_createACBSConfigAndReturnError:
_barcodesDetectedInImageBuffer:usingACBSConfig:error:
ACBSBarcodeTypeForBarcodeSymbology:
supportedSymbologies
_newVNBarcodeSymbologyQRDescriptorForACBSBarcodeInfo:
_newVNBarcodeSymbologyAztecDescriptorForACBSBarcodeInfo:
_newVNBarcodeSymbologyPDF417DescriptorForACBSBarcodeInfo:
setSymbologies:
setLocateMode:
_symbologies
_locateMode
releaseAllTrackers
numberWithInteger:
_getTracker:
_createTracker:type:options:error:
_maximumTrackersOfType:
releaseManager
_trackerTypeToClassDictionary
_trackerClassToNameMapTable
_liveTrackerCounter
_trackingProcessingQueue
_trackersCollectionManagementQueue
_liveTrackerCounterLimit
_trackers
initWithVImage:externalImageId:andExifTimestampValue:error:
initWithCVPixelBufferImage:externalImageId:andExifTimestampValue:error:
initWithVImage:externalImageId:andExifTimestampString:error:
initWithCVPixelBufferImage:externalImageId:andExifTimestampString:error:
image
imageCVPixelBuffer
imageFilePath
setImageFilePath:
freeImageInDealloc
setFreeImageInDealloc:
externalImageId
_freeImageInDealloc
_image
_imageCVPixelBuffer
_imageFilePath
_externalImageId
_exifTimestamp
cascadeStepCount
refineMouthRegion
refineLeftEyeRegion
refineRightEyeRegion
performBlinkDetection
getOptionalValidatedInputFaceObservations:clippedToRegionOfInterest:error:
_determineFacesToProcessFrom:outputFacesThatNeedNoProcessing:outputFacesThatNeedAlignment:outputFacesThatNeedLandmarks:
addObjectsFromArray:
setCascadeStepCount:
setRefineMouthRegion:
setRefineLeftEyeRegion:
setRefineRightEyeRegion:
setPerformBlinkDetection:
_cascadeStepCount
_refineMouthRegion
_refineLeftEyeRegion
_refineRightEyeRegion
_performBlinkDetection
initWithRawColorGaborDescriptor:
initWithImageDescriptor:type:version:
serializeAsVNImageprintStateAndReturnError:
initWithState:startingAtByteOffset:error:
serializedLength
setDescriptor:
setType:
distanceFromDescriptor:
mutableBytes
serializeStateIntoData:startingAtByteOffset:error:
dataWithLength:
isSerializedImageprintCompatibleWithCurrentVersion:
serializeStateAndReturnError:
initWithState:error:
distanceToImageprint:error:
_descriptor
_type
initWithBytes:length:
setLandmarkPoints3d:
setPoseData:
mCameraCalibrationMatrix
setFaceRegionMap:
mFaceRegionMapAlgorithmImpl
encodeInt32:forKey:
decodeInt32ForKey:
scanString:intoString:
scanDouble:
vn_encodeCGAffineTransform:forKey:
vn_decodeCGAffineTransformForKey:
vn_encode3x3Matrix:forKey:
vn_decode3x3MatrixForKey:
vn_encode4x4Matrix:forKey:
vn_decode4x4MatrixForKey:
decodeFloatForKey:
encodeFloat:forKey:
_confidence
_uuid
excludesBoundingBoxFromCoding
decodeDoubleForKey:
encodeDouble:forKey:
setIdentifier:
setBoundingBoxFromQuadrilateralPointsAtTopLeft:topRight:bottomRight:bottomLeft:
_boundingBox
initForReadingWithData:
finishDecoding
initWithLength:
platform
profile
setFaceprint:
setKey:
setPlatform:
setProfile:
faceprintInputPath
setFaceprintInputPath:
_platform
_profile
_faceprint
_key
_faceprintInputPath
decodeBoolForKey:
encodeBool:forKey:
landmarkPoints3d
poseData
faceIdConfidence
faceRegionMap
alignedMeanShape
landmarkScore
faceJunkinessIndex
faceOrientationIndex
setAlignedMeanShape:
setLandmarkPoints:
setHasBBoxBeenAligned:
setAlignedBoundingBox:
setAlignedRotationAngle:
setLandmarkScore:
setIsBlinking:
setBlinkScore:
setFaceIdConfidence:
setFaceJunkinessIndex:
setFaceOrientationIndex:
initWithData:pointCount:userFacingBBox:alignedBBox:landmarkScore:
faceObservationWithBoundingBox:andAlignedBoundingBox:
computeYawPitchRollFromPoseMatrix:outputYaw:outputPitch:outputRoll:
expressionsAndConfidence
nameConfidence
landmarks3d
pose
getComputedRectifyingTransform:
blinkScore
alignedBoundingBoxAsCGRect
expressionsAndDetections
setLandmarks:
_cachedLandmarks
_cachedLandmarks3d
_faceRegionMap
_landmarkScore
_isBlinking
_blinkScore
_expressionsAndScores
_faceJunkinessIndex
_faceOrientationIndex
_hasBBoxBeenAligned
_alignedRotationAngle
_faceIdConfidence
_landmarks
_landmarkPoints
_landmarkPoints3d
_poseData
_alignedMeanShape
_faceId
_alignedBoundingBox
referenceImageSignature
alignmentTransform
setAlignmentTransform:
_referenceImageSignature
_floatingImageSignature
_alignmentTransform
warpTransform
_warpTransform
setBlurScore:
setExposureScore:
blurScore
exposureScore
_blurScore
_exposureScore
setImageprint:
imageprint
observationWithImageprint:error:
calculateDistanceFromImageprintObservation:
isImageprintValid
initWithRawImageprintDescriptor:
rawImageprintDescriptor
imageprintValid
imageprintVersion
_imageprintValid
_imageprint
_imageprintVersion
blurMeasure
brightness
_identifier
initWithFeatureValue:
featureValue
_featureValue
_topLeft
_bottomLeft
_bottomRight
_topRight
setTransform:
setAngle:
transform
angle
_transform
_angle
suggestedIdsForRepresentative
representativenessById
_shouldUpdateRepresentative
_objects
_clusterId
_totalObjectCount
_suggestedIdsForRepresentative
_representativenessById
clusters
suggestionsForCluster
distancesById
setDistancesById:
_clusters
_suggestionsForCluster
_clusterState
_clusteredFaceIds
_groupedClusteredFaceIdsForCluster
_distance
_distancesById
initWithSceneprints:
componentsSeparatedByString:
p_isSeparatedString:equalToString:atIndex:usingSeparator:
sceneprintCurrentVersion
p_isMajorVersion:equalToMajorVersion:
p_isMinorVersion:equalToMinorVersion:
setSceneprints:
sceneprintVersion
_sceneprints
_sceneprintVersion
_allImageIdentifiers
_bestImageIdentifiers
_allImageStats
_coverImageIdentifier
_isAction
_isPortrait
characterBoxes
_characterBoxes
_text
symbology
barcodeDescriptor
initWithSymbology:descriptor:boundingBox:
_symbology
_barcodeDescriptor
scanFloat:
_determineFacesToProcessFrom:outputFacesThatNeedNoProcessing:outputFacesThatNeedProcessing:outputFacesThatNeed2DLandmarks:
initWithFaceObservations:clusterIDs:completionHandler:
initWithFaceObservations:clusterIDs:
isFullCoverageRegionOfInterest
indexesOfObjectsPassingTest:
objectsAtIndexes:
_faceObservationsForRegionOfInterestContainingFaceObservations:
validatedInputFaceObservationsClippedToRegionOfInterest:error:
regionOfInterestNonIntegralPixelRectForWidth:height:
_regionOfInterest
groupImageprints:withOptions:error:
persistentDomainForName:
stringByAppendingPathComponent:
burstId
createDirectoryAtPath:withIntermediateDirectories:attributes:error:
defaultVersionString
setVersionString:
versionString
setActionClassifier:
setStatsByImageIdentifier:
setClusterByImageIdentifier:
setBestImageIdentifiersArray:
setBurstCoverSelection:
setOverrideImage:
setOverrideProps:
burstDocumentDirectory
setBurstLogFileName:
burstLogFileName
fileExistsAtPath:
imageProps
imagePixelBuffer
_reorientFaceRects:imageSize:orientation:
_reorientROIRect:imageSize:orientation:
setImagePixelBuffer:
completionBlock
initWithImageData:dict:identifier:imageProps:completionBlock:
processClusters:
overrideImage
overrideProps
statsByImageIdentifier
_addImageInternal:properties:identifier:imageProps:completionBlock:
computeEmotion:
actionClassifier
countForObject:
computeCameraTravelDistance
computeBeginningVsEndAEMatrixDiffVsAverageAdjacent
computeActionSelectionThreshold
lastObject
computeAllImageScores
performEmotionalRejectionOnCluster:
findBestImage:useActionScores:
selectCoverPhotoFromMultiple:burstSize:
addItemsFromCluster:
secondsSinceStart
maxNumPendingFrames
enableAnalysis
enableFaceCore
dummyAnalysisCount
enableDumpYUV
stringByAppendingPathExtension:
burstCoverSelection
clusterByImageIdentifier
bestImageIdentifiersArray
addImage:properties:identifier:completionBlock:
imageClusterForIdentifier:
allImageClusters
isFaceDetectionForced
faceIDCounts
setFaceIDCounts:
faceAnalysisContext
setFaceAnalysisContext:
clusterArray
setClusterArray:
setMaxNumPendingFrames:
setEnableAnalysis:
setDummyAnalysisCount:
setEnableFaceCore:
setEnableDumpYUV:
setBurstId:
loggingCallback
_burstAnalyzerDispatchQueue
_pendingFramesSemaphore
_yuvdumpDispatchQueue
_temporalOrder
_maxNumPendingFrames
_enableAnalysis
_dummyAnalysisCount
_enableFaceCore
_enableDumpYUV
_burstLogFileHandle
_currentClusterIndexToProcess
_clusterArray
_faceAnalysisContext
_faceIDCounts
_burstId
_loggingCallback
_overrideImage
_overrideProps
_statsByImageIdentifier
_clusterByImageIdentifier
_burstLogFileName
_actionClassifier
_burstCoverSelection
_bestImageIdentifiersArray
_versionString
useTimestampAdjustedDistances
computeTotalDistanceForDescriptorDistance:timestampDiff:useTimestampAdjustment:
setPreviousLeafId:
setNextLeafId:
setPreviousLeafDescriptorDistance:
setNextLeafDescriptorDistance:
setPreviousLeafTimestampDistance:
setNextLeafTimestampDistance:
setPreviousLeafTotalDistance:
setNextLeafTotalDistance:
clusterSplitDistanceType
getDistanceForClusterNode:splitDistanceType:
computeClusteringIntoKGroups:orUsingDistanceThreshold:forHierarchicalTree:context:
naturalClusteringDistanceThreshold
computeTimestampAdjustedDistanceForBaseDistance:andTimestampDiff:
quality
createCGImage:fromRect:
newCGImageFromCIImage:error:
newCIImageFromVImage:withType:error:
newVImageBufferFromCIImage:error:
setWithArray:
contentsOfDirectoryAtPath:error:
removeItemAtPath:error:
mFaceLandmarkAlgorithmImpl
mFaceLandmarkMouthRefinerImpl
mFaceLandmarkRightEyeRefinerImpl
mFaceLandmarkLeftEyeRefinerImpl
mFaceAttributesPupilRefiner
mCoreLandmarkModelFileHandle
mLandmarkRefinerModelFileHandle
fileURLWithPath:isDirectory:
classifyImageWithDescriptors:usingImageClassifier:andMinConfidenceForClassification:outputDebugDictionary:options:metalContext:error:
mJunkDescriptorImpl
mJunkClassifierImpl
_perMeshPtr
setBlurDeterminationMethod:
maximumIntermediateSideLength
blurDeterminationMethod
setMaximumIntermediateSideLength:
_maximumIntermediateSideLength
_blurDeterminationMethod
processWithOptions:warningRecorder:error:
setObject:atIndexedSubscript:
newCropAroundBounds:extendBoundsWithinImageBy:fromImageBuffer:error:
mFaceDetectorImpl
mBBoxAlignerImpl
setPointCount:
_pointCount
pointAtIndex:
initWithPoints:pointCount:
setPoints:
_points
userFacingBBox
alignedBBox
pointsData
createPointArray:count:
isUserFacingBBoxEquivalentToAlignedBBox
setPointsData:
setAlignedBBox:
setUserFacingBBox:
_pointsData
_alignedBBox
_userFacingBBox
allPoints
faceContour
leftEyebrow
rightEyebrow
nose
noseCrest
medianLine
outerLips
innerLips
leftPupil
rightPupil
_allPoints
_faceContour
_leftEye
_rightEye
_leftEyebrow
_rightEyebrow
_nose
_noseCrest
_medianLine
_outerLips
_innerLips
_leftPupil
_rightPupil
validateClassArray:named:hasElementsAncestoredFromClass:requiredMinimumCount:allowedMaximumCount:error:
validateOptionalFaceObservations:error:
validateFaceprintedFaceObservation:error:
requiredObjectOfClass:forKey:inOptions:error:
requiredArrayForKey:inOptions:withElementsOfClass:error:
requiredInputFacesArrayInOptions:error:
dataUsingEncoding:allowLossyConversion:
initWithData:encoding:
initWithMLModel:error:
modelDescription
setupInputImageFromModelDescription:
predictedFeatureName
outputDescriptionsByName
predictedProbabilitiesName
inputDescriptionsByName
imageConstraint
imageHeight
osType
inputImageKey
featureValueWithPixelBuffer:
initWithDictionary:error:
model
predictionFromFeatures:error:
modelType
modelForMLModel:error:
predictWithCVPixelBuffer:options:error:
setModel:
setModelType:
setInputImageKey:
predictedFeatureKey
setPredictedFeatureKey:
predictedProbabilitiesKey
inputImageWidth
inputImageHeight
inputImageFormat
_modelType
_inputImageFormat
_model
_inputImageKey
_predictedFeatureKey
_predictedProbabilitiesKey
_inputImageWidth
_inputImageHeight
featureValueForName:
dictionaryValue
imageBufferValue
initWithOptions:model:error:
timeStamp
setTimeStamp:
_timeStamp
setBurstImages:
setImageProps:
computeMergeCost:::
setCompletionBlock:
_imagePixelBuffer
_completionBlock
_burstImages
_imageProps
advise:
resourcePath
setResourcePath:
initWithMappedModel:
m_impl
computeDescriptorForImageData:context:error:
computeConvnetDescriptorForImageData:context:error:
computeRegistrationFeaturesForImageData:context:error:
initWithImageData:context:error:
computeQualityForImageData:andQualityCriteria:context:error:
longValue
shortValue
numberWithLong:
numberWithShort:
initWithUUIDString:
getUUIDBytes:
initWithUUIDBytes:
rawColorGaborDescriptor
timerMode
colorGaborDescriptor
computeFinalDescriptorBasedDistanceForColorDistance:andSceneClassifierDistance:
initWithImageData:andCustomQualityScore:context:error:
sceneClassifierDescriptor
imageRegistrationDescriptor
previousLeafId
nextLeafId
nextLeafDescriptorDistance
previousLeafDescriptorDistance
nextLeafTimestampDistance
previousLeafTimestampDistance
nextLeafTotalDistance
previousLeafTotalDistance
_internalNonSerializedDescriptorId
_quality
_nextLeafDescriptorDistance
_previousLeafDescriptorDistance
_nextLeafTotalDistance
_previousLeafTotalDistance
_colorGaborDescriptor
_sceneClassifierDescriptor
_imageRegistrationDescriptor
_previousLeafId
_nextLeafId
_nextLeafTimestampDistance
_previousLeafTimestampDistance
setClusterIDs:
_burstSet
computeTransform:forRegisteringImageSignature:withSignature:andOptions:minimumOverlap:error:
initWithFace:predictedPersonUniqueIdentifier:confidence:
predictedPersonUniqueIdentifier
face
_face
_predictedPersonUniqueIdentifier
setMaximumFaceprintsPerPerson:
maximumFaceprintsPerPerson
faceIDModelMaximumElementsPerID
_maximumFaceprintsPerPerson
failWithError:
initWithConfiguration:
decodeIntForKey:
allKeysForObject:
_addUniqueFaceprints:toIdentityWithSerialNumber:
encodeInt:forKey:
_concatenateFaceprintImageDescriptorBufferWithFaceprints:forIdentityWithSerialNumber:
intersectSet:
_rebuildFaceprintImageDescriptorBufferIfNecessary
arrayByAddingObjectsFromArray:
_invalidateFaceprintImageDescriptorBuffer
removeObjectsInArray:
_removeExistingFaceprints:fromIdentityWithSerialNumber:
_rebuildModelIfNecessaryWithFaceIDCanceller:error:
sortUsingComparator:
removeObjectsInRange:
personUniqueIdentifiers
_faceprintCountForPersonWithUniqueIdentifier:
personCount
_uniqueFaceprintsWithRegistrationState:forFaceObservations:ofPersonWithUniqueIdentifier:error:
_addUniqueFaceprints:toPersonWithUniqueIdentifier:
_removeExistingFaceprints:fromPersonWithUniqueIdentifier:
_removeAllFaceprintsFromIdentityWithSerialNumber:
_personPredictionsForFace:withDescriptor:limit:faceIDCanceller:error:
addFaces:toPersonWithUniqueIdentifier:error:
removeFaces:fromPersonWithUniqueIdentifier:error:
removeAllFacesFromPersonWithUniqueIdentifier:
removePersonWithUniqueIdentifier:
predictPersonFromFace:limit:canceller:error:
_configuration
_personUniqueIdentifierToSerialNumberMapping
_serialNumberToFaceprintsMapping
_faceprintImageDescriptorBuffer
_faceprintLabels
_faceIDModel
_lastAssignedFaceprintSerialNumber
copyItemAtPath:toPath:error:
moveItemAtPath:toPath:error:
computeFromBuffer:withChannels:error:
computeFromPixelBuffer:withChannels:error:
m_FaceDescriptorImpl
m_FaceFrontalizerImpl
m_DescriptorAugmenter
m_FaceFrontalizerWorkingBuffer
m_FaceFrontalizerImageBuffer
m_RequiredImageSize
_useLowPriorityMode
setFlag:atIndex:
clearFlag:atIndex:
checkFlag:atIndex:
copyFlagValue:toTarget:atIndex:
resetBoxBounds
releaseAllocations
floatVectorSumProd
setFloatVectorSumProd:
pulseVectorHeightCharBox
setPulseVectorHeightCharBox:
pulseVectorHeightCharBoxAdaptive
setPulseVectorHeightCharBoxAdaptive:
charBoxFlags
setCharBoxFlags:
charboxROIFullVectorRowStart
setCharboxROIFullVectorRowStart:
charboxROIFullVectorHeight2
setCharboxROIFullVectorHeight2:
allocationSize
setAllocationSize:
mTop
setMTop:
mBottom
setMBottom:
bTop
setBTop:
bBottom
setBBottom:
posUL
setPosUL:
posLL
setPosLL:
posUR
setPosUR:
posLR
setPosLR:
medianHeightTop
setMedianHeightTop:
medianHeightBottom
setMedianHeightBottom:
loopBigBox
setLoopBigBox:
loopBigBoxPrev
setLoopBigBoxPrev:
filterWalkUpDownCount
setFilterWalkUpDownCount:
setDebugOut:
setDebugFilename:
setComputeZCVectorHighProbability:
setMidRow:
setMinHeight:
setMaxHeight:
setStartMaxFind:
setStopMaxFind:
setMmHeightCard:
setMmWidthCard:
setPixelHeightCard:
setPixelWidthCard:
setMinBoxWidth:
setMaxBoxWidth:
setStartNormal:
setStopNormal:
setStartSensitized:
setStopSensitized:
midRow
debugOut
debugFilename
examinePulseWindow:prodBoostNormalized:pwContext:minHeight:maxHeight:thresholdSet:
_allocateSumDerivVectors:size:
_computeColumnSumsOverRange:sampleImageAddress:rowSumOut:rowDerivOut:
_computeProdBoostNormalizedResult:size:binOverride:
generatePulses:minHeight:maxHeight:thresholdSet:prodBoostNormalized:pulseVectorFlag:
_freeSumDerivVectors:
minHeight
maxHeight
profileNormal
computeNumCropCols:width:start:
setIi:
setProfileNormal:
_allocateVImage:height:rowBytes:imageOut:
_freeVImage:
createLumaImage:lumaImage:numCropRows:rowStartLocation:
createLumaImageAlternative:lumaImageAlternative:numCropRows:rowStartLocation:
computeMainStub:numCropRows:numCropColsOut:maxY:start:
allocateColorProfileContext:width:height:rowBytes:
getVotingHistogram:colorProfileContext:startCC:rowStartLocation:
getLumaHistogram:startCC:colorProfileContext:
determineColorProfileType:
generateHistogramBounds:rgbVector2Ref:numPixels1:numPixels2:minMaxRGB:lowHighRGB:
_generateBinarizationForImage:textOut:firstOrSecondPassIndicator:minMaxRGB:
freeColorProfileContext:
string
pixelHeightCard
pixelWidthCard
mmHeightCard
mmWidthCard
maxBoxWidth
groupEndpoints:finalCharBoxCoordCount:
computeDependentTopAndBottomComponents:finalCharBoxCoordCount:
computeIndependentTopAndBottomComponents:finalCharBoxCoordCount:
_getFilterResultOut:defaultRows:bufferHeight:minHeight:maxHeight:startRange:stopRange:startMaxFind:stopMaxFind:bytesPerRow:thresholdSet:sampleImageAddressRef:sampleImageFloatAddressRef:pulseVectorFlag:
minBoxWidth
computePulseVectorSum:start:stop:imageHeight:imageWidth:bottomHeight:topHeight:
tightenBox:startTop:startBottom:startPosition:stopPosition:imageHeight:halfWalk:
startSensitized
stopSensitized
_extractCharBoxCuts:heightConstraint:medianHeightTopVector:medianHeightBottomVector:isAdaptive:
computeZCVectorHighProbability
charBoxesFromTextBoxes:bigBoxes:ccYTopLocationsForSort:ccYBottomLocationsForSort:
extractCharBoxHeightInfo:ccCharBoxesFiltered:ccYTopLocationsForSort:ccYBottomLocationsForSort:aggregateGreenBoxesForStubCount:imageWidth:
calculateSumProd:prodROIRef:prodROIRotateRef:rowStartLocation2:height:
calculateSumProdAlternative:prodROIRef:prodROIRotateRef:rowStartLocation2:height:
startMaxFind
stopMaxFind
_generateZeroCrossingVector:zcVectorFlag:width:
extractBoxesForStub:bigBoxesAdapt:countBigBox:rowStartLocation2:rowStopLocation2:heightConstraint:imageWidth:height:ccCharBoxesAggr:ccCharBoxesFiltered:useLowLightEnhancement:
fillInOneVector:checkFlag:checkHeight:
charBoxContext
_generateCRCharBoxInformation_zcFinalVectorOriginate:textOut:adaptOut:bigBoxes:bigBoxesAdapt:ccCharBoxesAggr:ccCharBoxesFiltered:height:rowStartLocation2:rowStopLocation2:singleVotingImageAddressRef:countBigBox:filterWalkUpDownCount:useLowLightEnhancement:
_generateCRCharBoxInformation_zcFinalVectorHighProbability:zcFinalRange:
_generateCRCharBoxInformation_zcFinalVectorFillIn:
_generateCRCharBoxInformation_spaceBoxRemovalMagicThresh:magicMinHeight:magicMaxHeight:rowStartLocation2:magicThresh:magicThreshPrev:useLowLightEnhancement:
_generateCRCharBoxInformation_spaceBoxRemovalHistogram:zcStartLeft:zcStopRight:rowStartLocation2:lowHighRGB:histCompliancePercent:varSpaceBox:
_generateCRCharBoxInformation_spaceBoxRemovalTruthFilter:magicThresh:zcStartLeft:zcStopRight:isSpaceBoxAccepted:histCompliancePercent:useLowLightEnhancement:
_generateCRCharBoxInformation_spaceBoxRemovalTightenBox:singleVotingImageAddressRef:adaptOut:textOut:zcStartLeft:zcStopRight:finalCoordinatesForStub:finalCoordinatesForStubRevised:finalCharBoxCoordCount:useLowLightEnhancement:
_generateCRCharBoxInformation_TrackBox:finalCharBoxCoordCount:
_generateCRCharBoxInformation_extendTextBoxes:countBigBox:rowStartLocation2:finalCharBoxCoordCount:finalCoordinatesForStubRevised:width:height:bigBoxIndicator:
startNormal
stopNormal
_getFilterResultOutBothSumDeriv:floatVectorResult:bufferHeight:minHeight:maxHeight:config:bytesPerRow:thresholdSet:sampleImageAddressRef:
_generatePulseAggregate:pulseVectorMain:pulseVectorResult:metricSelection:bufferHeight:bufferWidth:
_generateFilteredPulseVector:target:height:
generateDominantPulse:rowLocationsRef:debugOut:bufferHeight:bufferWidth:
_generatePulseAggregateSmallStubs:pulseVectorResult:bufferHeight:bufferWidth:
_allocateCRCharBoxContext:
initializeForImage:
_generateVotingImage:votingImage:useLowLightEnhancement:
_generatePulseVectorOutputs:votingImage:rowLocationsRef:
_generateAndApplyColorProfileForImage:votingImage:textOut:minMaxRGB:lowHighRGB:numCropRows:rowStartLocation:rowStopLocation:sumTextOutFirstPass:useLowLightEnhancement:
_generateSmoothedImage:uImage:
_generateBoxes:pulseVector:uImage:countBigBoxOut:bigBoxes:bigBoxesA:useLowLightEnhancement:
_generateAdaptiveBinarization:adaptImage:useLowLightEnhancement:
_generateCC:ccBigBoxes:textOut:countBigBox:bufferHeight:
_generateCRCharBoxInformation:inputImage:singleVotingImageAddressRef:bigBoxes:bigBoxesAdapt:textOut:adaptOut:lowHighRGB:countBigBox:useLowLightEnhancement:
_freeCRCharBoxContext
textBoxesForBuffer:error:
setCharBoxContext:
debugMatlab
setDebugMatlab:
_getFilter_callCount
_computeZCVectorHighProbability
_profileNormal
_debugMatlab
_debugOut
_midRow
_minHeight
_maxHeight
_startMaxFind
_stopMaxFind
_mmHeightCard
_mmWidthCard
_pixelHeightCard
_pixelWidthCard
_minBoxWidth
_maxBoxWidth
_startNormal
_stopNormal
_startSensitized
_stopSensitized
_charBoxContext
_debugFilename
setName:
setCountLimit:
setTotalCostLimit:
setObject:forKey:cost:
observationsForKey:
setObservations:forKey:
doesAreaOverlapBetweenRect:andOtherRect:withOverlapRatioGreaterThan:
computeNormalizedCosineDistanceOfFaceprint:toFaceprint:
doesAreaOverlapSignificantlyBetweenRect:andOtherRect:
requiredVersion
minimumAspectRatio
maximumAspectRatio
quadratureTolerance
minimumSize
minimumConfidence
maximumObservations
setMinimumAspectRatio:
setMaximumAspectRatio:
setQuadratureTolerance:
setMinimumSize:
setMinimumConfidence:
setRequiredVersion:
setMaximumObservations:
_minimumAspectRatio
_maximumAspectRatio
_quadratureTolerance
_minimumSize
_minimumConfidence
_maximumObservations
_requiredVersion
returnAllResults
setReturnAllResults:
_returnAllResults
_validateAndPrepareRequests:error:
_orderedRequestsForRequests:
_requestLock
_requestsInFlight
_requestsPending
_sequencedRequestObservations
_trackerKeys
setLength:
_determineFacesToProcessFrom:outputFacesThatNeedNoProcessing:outputFacesThatNeedProcessing:
initWithType:cachePath:state:threshold:
cachePath
setCachePath:
state
setState:
threshold
setThreshold:
_cachePath
clustererQueryWithOptions:error:
distanceBetweenFacesWithFaceObservation:andFaceObservation:error:
clustererBuilderWithOptions:error:
initWithModel:completionHandler:
imageCropAndScaleOption
initWithModel:
setImageCropAndScaleOption:
_imageCropAndScaleOption
debugMode
performClustersPostprocessing
performSceneClassification
roiAreaThreshold
inliersRatioThreshold
numberOfKeypointsToConsider
_useTimestampAdjustedDistances
_performClustersPostprocessing
_performSceneClassification
_debugMode
_timerMode
_clusterSplitDistanceType
_roiAreaThreshold
_inliersRatioThreshold
_numberOfKeypointsToConsider
_naturalClusteringDistanceThreshold
_qualityCriteriaList
computeBrightnessScore:onImage:error:
initWithRectangleObservation:completionHandler:
initWithRectangleObservation:
_determineFacesToProcessFrom:outputFacesThatNeedNoProcessing:outputFacesThatNeedAlignment:outputFacesThatNeedFaceprints:
dumpDebugIntermediatesWithImageBuffer:lumaIntermediate:rawBBoxInLumaIntermediateCoordinates:alignedBBoxInLumaIntermediateCoordinates:rotationAngle:
mFaceBoxPoseAlignerImpl
mFaceBoxAlignerModelFileHandle
VNTrackerOptionToTrackerType:
_visionBBoxToTrackerBBox:trackedObjects:imageSize:results:error:
_updateTrackerWithModifiedBBoxForImageBuffer:error:
mTrackerImpl
_trackedFrameNumber
_level
_lastTrackedBBox
initWithRequestPerformer:imageBuffer:observationsCache:qosClass:
_observationCacheKeyForRequest:
_qosClass
_requestPerformer_DO_NOT_DIRECTLY_ACCESS
_imageBuffer_DO_NOT_DIRECTLY_ACCESS
_requestToObservationCacheKeyMap
signature
mSignature_
initWithTargetedImageSpecifier:completionHandler:
targetedImageSpecifier
initWithTargetedCVPixelBuffer:
initWithTargetedCGImage:
initWithTargetedCIImage:
initWithTargetedImageURL:
initWithTargetedImageData:
_targetedImageSpecifier
initWithFaceObservation:completionHandler:
initWithFaceObservation:
initWithAPI:properties:
setParameter:to:
setCurrentContext:
CVML_Error
VNClusteringLogger
VNSuggestionsLogger
VNGreedyClusteringReadOnly
VNClusteringReadOnly
VNGreedyClusteringReadWrite
VNClusteringWritable
VNGreedyClustering
VNClustering
BurstFaceConfigEntry
BurstFaceScoreEntry
BurstFaceInfo
BurstImageFaceAnalysisContext
BurstActionClassifier
VNRefinedSuggestionsForClustersRequest
VNClustererContextBase
VNClustererReadOnlyContext
VNClustererModelQuerying
VNClustererReadWriteContext
VNClustererModelBuilding
VNClusterContext
VNSuggestionsForClustersRequest
VNSceneClassifier
VNFaceClassifierBoostedPixelDifference
VNError
VNAppendBurstSequenceFrameRequest
BurstFaceStat
NSCopying
BurstImageStat
VNSequenceRequestHandler
VNRequestWarming
VNRequestCancelling
VNImageRequestHandler
ClusteringAdditions
VNPhotosRequestHandler
VNPhotosRequestHandlerSupport
VNSimilarityMatrix
VNHomographicImageRegistrationRequest
VNSceneClassificationRequest
VNBlurSignature
VNBlurMeasure
VNTrackingRequest
MTLDevice
NSObject
VNMetalContext
VNDetector
VNObservationsCacheKeyProviding
VNFaceRegionMap
NSSecureCoding
NSCoding
VNRuntimeUtilities
VNRepresentativeForClusterRequest
VNCanceller
VNImageBufferManager
VNImageSourceManager
VNImageBuffer
VNRequest
VNWarningRecorder
VNSequencedRequestSupporting
VNFaceTracker
VNFaceObservationDrivenClusteringRequest
VNDetectHumanRectanglesRequest
VNMomentProcessor
VNMPClusteringTreeNodeWrapper
VNImageSpecifier
OptionsDictionaryCompatability
_VNPixelBufferSpecifier
_VNCGImageSpecifier
_VNCIImageSpecifier
_VNFileURLImageSpecifier
_VNDataImageSpecifier
VNRectangleTracker
VNBurstAnalysisResultsRequest
VNFaceExpressionDetector
VNSceneprint
BurstClusterDivider
VNDetectTextRectanglesRequest
VNDetectorManager
VNImageRegistrationRequest
VNHumanDetector
VNClusterObservationsRequest
VNMPUtils
VNMPImageQuality
VNDetectBarcodesRequest
VNTrackerManager
VNMPImageData
VNDetectFaceLandmarksRequest
VNFaceObservationAccepting
VNImageprint
VNSerializingInternal
VNSerializing
VNFaceGeometryEstimator
VNFaceRegionMapGenerator
VisionAdditions
VNObservation
VNDetectedObjectObservation
VNFaceprint
VNFaceprintModel
VNFaceObservation
VNImageAlignmentObservation
VNImageTranslationAlignmentObservation
VNImageHomographicAlignmentObservation
VNImageScoreObservation
VNImageprintObservation
VNImageBlurObservation
VNImageBrightnessObservation
VNClassificationObservation
VNCoreMLFeatureValueObservation
VNPixelBufferObservation
VNRectangleObservation
VNHumanObservation
VNHorizonObservation
VNCluster
VNClusterObservation
VNSceneObservation
VNBurstObservation
_VNTextObservationCharacterBox
VNTextObservation
VNBarcodeObservation
VNHorizonDetector
VNDetectFacePoseRequest
VNGetDistancesRequest
VNImageBasedRequest
VNFaceObservationAcceptingInternal
VNImageGrouper
BurstImageSetInternal
VNMPImageGrouping
ImageProcessing_CoreImageUtils
VNDetectFace3DLandmarksRequest
VNFaceLandmarkDetector
VNJunkIdentifier
VNRectangleDetector
VNImageBlurScoreRequest
VNFaceDetector
VNFaceLandmarkRegion
VNFaceLandmarkRegion2D
VNFaceLandmarkRegion3D
VNFaceLandmarks
VNFaceLandmarks2D
VNFaceLandmarks3D
VNValidationUtilities
VNCoreMLModel
VNCoreMLTransformer
VNImageClassifier
VNCreateImageprintRequest
VNObjectTracker
BurstThumbnailCluster
VNModelFileImpl
VNModelFile
VNModelFilesCache
VNMPImageDescriptor
VNDetectFaceRectanglesRequest
VNGetClustersRequest
VNBurstContext
VNTranslationalImageRegistrationRequest
VNPersonsModelPrediction
VNPersonsModelConfiguration
VNPersonsModel
VNFaceprintGenerator
VNCreateFaceRegionMapRequest
CCCharBoxContext
CCTextDetector
VNObservationsCache
VNDebugHelpers
VNDetectRectanglesRequest
VNCreateSceneprintRequest
VNRequestPerformer
VNTrackerProviding
VNIdentifyJunkRequest
VNGroupImagesByTimeAndContentRequest
VNAlignFaceRectangleRequest
VNClustererOptions
VNClustererQueryOptions
VNClustererBuilderOptions
VNClustererQuery
VNClustererBuilder
VNCoreMLRequest
VNMPContext
VNDetectFaceExpressionsRequest
VNBrightnessMeasure
VNTrackRectangleRequest
VNCreateFaceprintRequest
VNTrackObjectRequest
VNFaceBBoxAligner
VNTracker
VNImageExposureScoreRequest
VNRequestPerformingContext
VNImageBufferProviding
VNImageRegistrationSignature
VNImageRegistration
VNMPImageSharpness
VNImageprintGenerator
VNTargetedImageRequest
VNTrackFaceRequest
VNDetectHorizonRequest
TemporalRegistration
@32@0:8q16@24
B16@0:8
v32@0:8@16@24
@32@0:8@16q24
@16@0:8
@36@0:8@16B24@28
@28@0:8@16B24
v16@0:8
v24@0:8@16
v32@0:8r^{map<long long, std::__1::vector<long long, std::__1::allocator<long long> >, std::__1::less<long long>, std::__1::allocator<std::__1::pair<const long long, std::__1::vector<long long, std::__1::allocator<long long> > > > >={__tree<std::__1::__value_type<long long, std::__1::vector<long long, std::__1::allocator<long long> > >, std::__1::__map_value_compare<long long, std::__1::__value_type<long long, std::__1::vector<long long, std::__1::allocator<long long> > >, std::__1::less<long long>, true>, std::__1::allocator<std::__1::__value_type<long long, std::__1::vector<long long, std::__1::allocator<long long> > > > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<long long, std::__1::vector<long long, std::__1::allocator<long long> > >, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<long long, std::__1::__value_type<long long, std::__1::vector<long long, std::__1::allocator<long long> > >, std::__1::less<long long>, true> >=Q}}}16@24
v24@0:8r^{map<long long, std::__1::vector<long long, std::__1::allocator<long long> >, std::__1::less<long long>, std::__1::allocator<std::__1::pair<const long long, std::__1::vector<long long, std::__1::allocator<long long> > > > >={__tree<std::__1::__value_type<long long, std::__1::vector<long long, std::__1::allocator<long long> > >, std::__1::__map_value_compare<long long, std::__1::__value_type<long long, std::__1::vector<long long, std::__1::allocator<long long> > >, std::__1::less<long long>, true>, std::__1::allocator<std::__1::__value_type<long long, std::__1::vector<long long, std::__1::allocator<long long> > > > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<long long, std::__1::vector<long long, std::__1::allocator<long long> > >, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<long long, std::__1::__value_type<long long, std::__1::vector<long long, std::__1::allocator<long long> > >, std::__1::less<long long>, true> >=Q}}}16
@"NSURL"
@"NSString"
v32@0:8@16^{ImageDescriptorBufferFloat32=^^?{vector<long long, std::__1::allocator<long long> >=^q^q{__compressed_pair<long long *, std::__1::allocator<long long> >=^q}}{map<long long, int, std::__1::less<long long>, std::__1::allocator<std::__1::pair<const long long, int> > >={__tree<std::__1::__value_type<long long, int>, std::__1::__map_value_compare<long long, std::__1::__value_type<long long, int>, std::__1::less<long long>, true>, std::__1::allocator<std::__1::__value_type<long long, int> > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<long long, int>, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<long long, std::__1::__value_type<long long, int>, std::__1::less<long long>, true> >=Q}}}^vQQQBQi^f}24
@32@0:8@16^@24
@36@0:8@16f24^@28
@24@0:8^@16
@40@0:8@16@24^@32
@"NSArray"36@0:8@"NSDictionary"16f24^@28
@"NSData"24@0:8^@16
@"NSSet"24@0:8^@16
@"NSArray"32@0:8@"NSNumber"16^@24
@"NSNumber"40@0:8@"NSNumber"16@"NSNumber"24^@32
@"NSDictionary"32@0:8@"NSArray"16^@24
@"NSArray"40@0:8@"NSArray"16@"NSDictionary"24^@32
@"NSDictionary"40@0:8@"NSArray"16@"NSArray"24^@32
@"NSNumber"24@0:8^@16
B32@0:8@16^@24
v32@0:8{shared_ptr<const vision::mod::GreedyClustererFaces>=^{GreedyClustererFaces}^{__shared_weak_count}}16
@24@0:8^{vector<std::__1::pair<long long, long long>, std::__1::allocator<std::__1::pair<long long, long long> > >=^{pair<long long, long long>}^{pair<long long, long long>}{__compressed_pair<std::__1::pair<long long, long long> *, std::__1::allocator<std::__1::pair<long long, long long> > >=^{pair<long long, long long>}}}16
@"VNClusteringLogger"
@"VNSuggestionsLogger"
@"NSNumber"
@"NSData"
{shared_ptr<const vision::mod::GreedyClustererFaces>="__ptr_"^{GreedyClustererFaces}"__cntrl_"^{__shared_weak_count}}
B24@0:8^@16
@"NSArray"32@0:8@"NSDictionary"16^@24
q32@0:8^{ImageDescriptorBufferFloat32=^^?{vector<long long, std::__1::allocator<long long> >=^q^q{__compressed_pair<long long *, std::__1::allocator<long long> >=^q}}{map<long long, int, std::__1::less<long long>, std::__1::allocator<std::__1::pair<const long long, int> > >={__tree<std::__1::__value_type<long long, int>, std::__1::__map_value_compare<long long, std::__1::__value_type<long long, int>, std::__1::less<long long>, true>, std::__1::allocator<std::__1::__value_type<long long, int> > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<long long, int>, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<long long, std::__1::__value_type<long long, int>, std::__1::less<long long>, true> >=Q}}}^vQQQBQi^f}16^{vector<std::__1::pair<long long, long long>, std::__1::allocator<std::__1::pair<long long, long long> > >=^{pair<long long, long long>}^{pair<long long, long long>}{__compressed_pair<std::__1::pair<long long, long long> *, std::__1::allocator<std::__1::pair<long long, long long> > >=^{pair<long long, long long>}}}24
{shared_ptr<vision::mod::GreedyClustererFaces>="__ptr_"^{GreedyClustererFaces}"__cntrl_"^{__shared_weak_count}}
B40@0:8@16@24^@32
@44@0:8@16@24f32^@36
@24@0:8@16
@32@0:8@16@24
B40@0:8@"NSArray"16@"VNSimilarityMatrix"24^@32
@"NSArray"36@0:8@"NSArray"16f24^@28
@"NSArray"44@0:8@"NSArray"16@"NSArray"24f32^@36
@"NSSet"16@0:8
@"NSArray"24@0:8@"NSNumber"16
@"NSNumber"24@0:8@"NSArray"16
@"NSDictionary"24@0:8@"NSArray"16
@"NSDictionary"32@0:8@"NSArray"16@"NSArray"24
@52@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16i48
i16@0:8
v20@0:8i16
{CGRect={CGPoint=dd}{CGSize=dd}}16@0:8
v48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
{CGRect="origin"{CGPoint="x"d"y"d}"size"{CGSize="width"d"height"d}}
@20@0:8f16
v20@0:8f16
f16@0:8
f48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
{CGPoint=dd}16@0:8
v32@0:8{CGPoint=dd}16
{CGSize=dd}16@0:8
v32@0:8{CGSize=dd}16
{CGPoint="x"d"y"d}
{CGSize="width"d"height"d}
{CGRect={CGPoint=dd}{CGSize=dd}}56@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16f48f52
{CGRect={CGPoint=dd}{CGSize=dd}}64@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48^B56
@56@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48
@48@0:8@16{CGSize=dd}24@40
i32@0:8^{__CVBuffer=}16@24
v32@0:8^{__CVBuffer=}16@24
v40@0:8@16{CGSize=dd}24
d16@0:8
v24@0:8d16
v20@0:8B16
@"NSMutableDictionary"
@"NSMutableArray"
@20@0:8i16
d24@0:8r^{BurstSupportVector=d[7d]}16
^{__SVMParameters=[7{__SVMScaleOffset=ff}]ddii^{BurstSupportVector}^{BurstSupportVector}}16@0:8
v24@0:8^{__SVMParameters=[7{__SVMScaleOffset=ff}]ddii^{BurstSupportVector}^{BurstSupportVector}}16
[7d]
^{__SVMParameters=[7{__SVMScaleOffset=ff}]ddii^{BurstSupportVector}^{BurstSupportVector}}
@40@0:8@16@24@?32
@56@0:8@16@24@32B40f44^@48
@52@0:8@16@24@32f40^@44
@40@0:8#16@24^@32
@"NSArray"32@0:8@"NSArray"16^@24
@"<VNClusteringReadOnly>"
B32@0:8@"NSData"16^@24
@"NSArray"40@0:8@"NSArray"16@"NSArray"24^@32
@"<VNClusteringReadOnly><VNClusteringWritable>"
@24@0:8Q16
@"<VNClustering>"
@"VNSimilarityMatrix"
@32@0:8@16@?24
@"NSArray"
@72@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24@56^@64
B40@0:8@16^{shared_ptr<vision::mod::ImageDescriptorBufferAbstract>=^{ImageDescriptorBufferAbstract}^{__shared_weak_count}}24^@32
B96@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24@56^{shared_ptr<vision::mod::ImageDescriptorBufferAbstract>=^{ImageDescriptorBufferAbstract}^{__shared_weak_count}}64@72@80^@88
{shared_ptr<vision::mod::ImageDescriptorProcessorAbstract>="__ptr_"^{ImageDescriptorProcessorAbstract}"__cntrl_"^{__shared_weak_count}}
{shared_ptr<vision::mod::ImageClassifierAbstract>="__ptr_"^{ImageClassifierAbstract}"__cntrl_"^{__shared_weak_count}}
{shared_ptr<vision::mod::ImageClassifier_HierarchicalModel>="__ptr_"^{ImageClassifier_HierarchicalModel}"__cntrl_"^{__shared_weak_count}}
@"NSSet"
{shared_ptr<vision::mod::FaceClassifier_BoostedPixelDifference>="__ptr_"^{FaceClassifier_BoostedPixelDifference}"__cntrl_"^{__shared_weak_count}}
@40@0:8q16@24@32
@32@0:8^{__CVBuffer=}16@?24
@32@0:8^{CGImage=}16@?24
@"NSDictionary"
@24@0:8^{_NSZone=}16
v48@0:8^^f16^^f24^^f32^^f40
v24@0:8^f16
v48@0:8{vImage_Buffer=^vQQQ}16
{GridROI_t=iiii}16@0:8
f32@0:8@16@24
v32@0:8{GridROI_t=iiii}16
v40@0:8@16^f24^f32
f24@0:8@16
i24@0:8@16
v24@0:8^{__CVBuffer=}16
^S16@0:8
f20@0:8f16
q24@0:8@16
^f16@0:8
[1024f]
[256S]
{FastRegistration_Signatures="piRow"^f"nPiRow"Q"piRowTable"{Projections_meanStdTable="sumTable"^f"sumSqTable"^f}"piCol"^f"nPiCol"Q"piColTable"{Projections_meanStdTable="sumTable"^f"sumSqTable"^f}"_memoryContainer"*}
^{SharpnessGridElement_t=CCf}
{GridROI_t="startX"i"startY"i"endX"i"endY"i}
v32@0:8@16@?24
B32@0:8@"NSArray"16^@24
B40@0:8@16^{__CVBuffer=}24^@32
B44@0:8@16^{__CVBuffer=}24i32^@36
B40@0:8@16^{CGImage=}24^@32
B44@0:8@16^{CGImage=}24i32^@36
B44@0:8@16@24i32^@36
@"VNRequestPerformer"
@32@0:8^{__CVBuffer=}16@24
@36@0:8^{__CVBuffer=}16i24@28
@32@0:8^{CGImage=}16@24
@36@0:8^{CGImage=}16i24@28
@36@0:8@16i24@28
@"VNImageSpecifier"
@"VNObservationsCache"
@36@0:8@16B24^@28
@?16@0:8
v24@0:8@?16
@"NSObject"
Q16@0:8
@32@0:8{_NSRange=QQ}16
f32@0:8Q16Q24
B24@0:8Q16
^v16@0:8
{shared_ptr<vision::mod::SimilarityMatrixAbstract>="__ptr_"^{SimilarityMatrixAbstract}"__cntrl_"^{__shared_weak_count}}
^{__CVBuffer=}40@0:8@16@24^@32
B60@0:8Q16^^{__CVBuffer}24I32Q36Q44^@52
B72@0:8^{?=[3]}16^{__CVBuffer=}24^{__CVBuffer=}32^{ImageRegistrationCtx_s=}40^v48r^{?=[3]}56^@64
@"VNSceneObservation"
@32@0:8^{__CVBuffer=}16^@24
@24@0:8^v16
v24@0:8^v16
B76@0:8^f16^{__CVBuffer=}24{CGRect={CGPoint=dd}{CGSize=dd}}32f64^@68
B44@0:8^f16^{__CVBuffer=}24f32^@36
B76@0:8^f16@24f32{CGRect={CGPoint=dd}{CGSize=dd}}36^@68
B40@0:8^f16^{__CVBuffer=}24^@32
B48@0:8^f16^{__CVBuffer=}24i32f36^@40
Q24@0:8@16
v24@0:8Q16
@48@0:8@16@24@32^@40
@"VNDetectedObjectObservation"
B24@0:8@16
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
{?=QQ}24@0:8@16
{?=QQ}32@0:8Q16Q24
@32@0:8Q16Q24
@40@0:8r^v16Q24Q32
@48@0:8^v16Q24Q32@?40
v40@0:8@16@24@?32
@48@0:8@16Q24^@32^@40
v40@0:8@16Q24@?32
Q24@0:8Q16
v32@0:8^{?=ff}16Q24
{?=QQQ}16@0:8
@"<MTLCommandQueue>"16@0:8
@"<MTLCommandQueue>"24@0:8Q16
{?=QQ}24@0:8@"MTLTextureDescriptor"16
@"<MTLHeap>"24@0:8@"MTLHeapDescriptor"16
@"<MTLBuffer>"32@0:8Q16Q24
@"<MTLBuffer>"40@0:8r^v16Q24Q32
@"<MTLBuffer>"48@0:8^v16Q24Q32@?<v@?^vQ>40
@"<MTLDepthStencilState>"24@0:8@"MTLDepthStencilDescriptor"16
@"<MTLTexture>"24@0:8@"MTLTextureDescriptor"16
@"<MTLSamplerState>"24@0:8@"MTLSamplerDescriptor"16
@"<MTLLibrary>"16@0:8
@"<MTLLibrary>"32@0:8@"NSBundle"16^@24
@"<MTLLibrary>"32@0:8@"NSString"16^@24
@"<MTLLibrary>"32@0:8@"NSURL"16^@24
@"<MTLLibrary>"32@0:8@"NSObject<OS_dispatch_data>"16^@24
@"<MTLLibrary>"40@0:8@"NSString"16@"MTLCompileOptions"24^@32
v40@0:8@"NSString"16@"MTLCompileOptions"24@?<v@?@"<MTLLibrary>"@"NSError">32
@"<MTLRenderPipelineState>"32@0:8@"MTLRenderPipelineDescriptor"16^@24
@"<MTLRenderPipelineState>"48@0:8@"MTLRenderPipelineDescriptor"16Q24^@32^@40
v32@0:8@"MTLRenderPipelineDescriptor"16@?<v@?@"<MTLRenderPipelineState>"@"NSError">24
v40@0:8@"MTLRenderPipelineDescriptor"16Q24@?<v@?@"<MTLRenderPipelineState>"@"MTLRenderPipelineReflection"@"NSError">32
@"<MTLComputePipelineState>"32@0:8@"<MTLFunction>"16^@24
@"<MTLComputePipelineState>"48@0:8@"<MTLFunction>"16Q24^@32^@40
v32@0:8@"<MTLFunction>"16@?<v@?@"<MTLComputePipelineState>"@"NSError">24
v40@0:8@"<MTLFunction>"16Q24@?<v@?@"<MTLComputePipelineState>"@"MTLComputePipelineReflection"@"NSError">32
@"<MTLComputePipelineState>"48@0:8@"MTLComputePipelineDescriptor"16Q24^@32^@40
v40@0:8@"MTLComputePipelineDescriptor"16Q24@?<v@?@"<MTLComputePipelineState>"@"MTLComputePipelineReflection"@"NSError">32
@"<MTLFence>"16@0:8
@"<MTLArgumentEncoder>"24@0:8@"NSArray"16
@"<MTLIndirectArgumentEncoder>"24@0:8@"NSArray"16
@"<MTLDevice>"
B40@0:8^Q16^Q24^I32
@"<NSObject><NSCopying>"16@0:8
@"VNMetalContext"
@"NSObject<OS_dispatch_queue>"
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
v84@0:8^{vImage_Buffer=^vQQQ}16B24{CGRect={CGPoint=dd}{CGSize=dd}}28{_Geometry2D_rect2D_={_Geometry2D_point2D_=ff}{_Geometry2D_size2D_=ff}}60@76
@32@0:8{CGPoint=dd}16
@48@0:8{CGPoint=dd}16{CGSize=dd}32
{vImage_Buffer="data"^v"height"Q"width"Q"rowBytes"Q}
{_Geometry2D_rect2D_="origin"{_Geometry2D_point2D_="x"f"y"f}"size"{_Geometry2D_size2D_="height"f"width"f}}
B32@0:8@16:24
v32@0:8@?16@?24
{os_unfair_lock_s="_os_unfair_lock_opaque"I}
@"CIContext"
@"NSHashTable"
@"NSLock"
^{CGImageSource=}40@0:8^^{CGImageSource}16I24^{os_unfair_lock_s=I}28B36
^{CGImageSource=}16@0:8
^{CGImageSource=}24@0:8I16B20
^{CGImageSource=}
^{CGColorSpace=}28@0:8I16^I20
^{__CVBuffer=}16@0:8
^{__CVBuffer=}52@0:8Q16Q24I32@36^@44
^{__CVBuffer=}84@0:8Q16Q24I32{CGRect={CGPoint=dd}{CGSize=dd}}36@68^@76
B24@0:8^f16
B24@0:8^{CGPoint=dd}16
B24@0:8^{?=[3]}16
B36@0:8Q16Q24I32
B84@0:8Q16f24@28{CGRect={CGPoint=dd}{CGSize=dd}}36@?68^@76
{CGRect={CGPoint=dd}{CGSize=dd}}48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
^{__CVBuffer=}44@0:8Q16I24@28^@36
^{__CVBuffer=}76@0:8Q16{CGRect={CGPoint=dd}{CGSize=dd}}24I56@60^@68
B20@0:8I16
^{__CVBuffer=}
^{__CFArray=}
@"CIImage"
@"VNImageSourceManager"
B56@0:8^@16#24@32@40^@48
B48@0:8^d16@24@32^@40
B56@0:8^d16@24@32d40^@48
B48@0:8^f16@24@32^@40
B52@0:8^f16@24@32f40^@44
B56@0:8^@16@24@32#40^@48
B40@0:8^@16@24^@32
v32@0:8@"NSString"16@24
@24@0:8@"NSString"16
q16@0:8
@24@0:8@?16
B48@0:8@16^Q24^Q32^@40
@"VNWarningRecorder"
@"NSObject<OS_dispatch_semaphore>"
B32@0:8^@16^@24
@36@0:8@16i24^@28
@40@0:8{vector<MPClusteringTreeNode *, std::__1::allocator<MPClusteringTreeNode *> >=^^{MPClusteringTreeNode}^^{MPClusteringTreeNode}{__compressed_pair<MPClusteringTreeNode **, std::__1::allocator<MPClusteringTreeNode *> >=^^{MPClusteringTreeNode}}}16
@40@0:8@16@24@32
@"VNMPContext"
@28@0:8^v16B24
@36@0:8^{__CVBuffer=}16i24^@28
@44@0:8^{__CVBuffer=}16i24@28^@36
@32@0:8^{CGImage=}16^@24
@36@0:8^{CGImage=}16i24^@28
@44@0:8^{CGImage=}16i24@28^@36
@44@0:8@16i24@28^@36
@"VNImageBuffer"
@24@0:8^{__CVBuffer=}16
@24@0:8^{CGImage=}16
^{CGImage=}16@0:8
^{CGImage=}
{shared_ptr<vision::mod::LandmarkAttributes>="__ptr_"^{LandmarkAttributes}"__cntrl_"^{__shared_weak_count}}
@"<VNModelFile>"
@56@0:8*16Q24Q32q40^{map<std::__1::basic_string<char>, float, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, float> > >={__tree<std::__1::__value_type<std::__1::basic_string<char>, float>, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, float>, std::__1::less<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__value_type<std::__1::basic_string<char>, float> > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<std::__1::basic_string<char>, float>, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, float>, std::__1::less<std::__1::basic_string<char> >, true> >=Q}}}48
v24@0:8q16
@48@0:8@16Q24@32^@40
@"VNFaceDetector"
@"VNFaceBBoxAligner"
@"VNFaceLandmarkDetector"
@"VNFaceExpressionDetector"
@"VNFaceprintGenerator"
@"VNHumanDetector"
@"VNJunkIdentifier"
@"VNSceneClassifier"
@"VNImageprintGenerator"
B56@0:8^@16^@24@32@40^@48
@"VNImageRegistrationSignature"
^{TemplateObjectDetectorApply=iiiiB[2f][2f]fBBffif{hog={gradient=}}{ChnsFeat=ii{hog={gradient=}}{gradient=}}i{vector<vision::hum::DTreeApply, std::__1::allocator<vision::hum::DTreeApply> >=^{DTreeApply}^{DTreeApply}{__compressed_pair<vision::hum::DTreeApply *, std::__1::allocator<vision::hum::DTreeApply> >=^{DTreeApply}}}{vector<std::__1::map<int, vision::hum::DTreeNode, std::__1::less<int>, std::__1::allocator<std::__1::pair<const int, vision::hum::DTreeNode> > >, std::__1::allocator<std::__1::map<int, vision::hum::DTreeNode, std::__1::less<int>, std::__1::allocator<std::__1::pair<const int, vision::hum::DTreeNode> > > > >=^{map<int, vision::hum::DTreeNode, std::__1::less<int>, std::__1::allocator<std::__1::pair<const int, vision::hum::DTreeNode> > >}^{map<int, vision::hum::DTreeNode, std::__1::less<int>, std::__1::allocator<std::__1::pair<const int, vision::hum::DTreeNode> > >}{__compressed_pair<std::__1::map<int, vision::hum::DTreeNode, std::__1::less<int>, std::__1::allocator<std::__1::pair<const int, vision::hum::DTreeNode> > > *, std::__1::allocator<std::__1::map<int, vision::hum::DTreeNode, std::__1::less<int>, std::__1::allocator<std::__1::pair<const int, vision::hum::DTreeNode> > > > >=^{map<int, vision::hum::DTreeNode, std::__1::less<int>, std::__1::allocator<std::__1::pair<const int, vision::hum::DTreeNode> > >}}}{vector<float, std::__1::allocator<float> >=^f^f{__compressed_pair<float *, std::__1::allocator<float> >=^f}}{vector<vision::hum::DTreeNode *, std::__1::allocator<vision::hum::DTreeNode *> >=^^{DTreeNode}^^{DTreeNode}{__compressed_pair<vision::hum::DTreeNode **, std::__1::allocator<vision::hum::DTreeNode *> >=^^{DTreeNode}}}f{adaBoostApply={vector<vision::hum::DTreeApply, std::__1::allocator<vision::hum::DTreeApply> >=^{DTreeApply}^{DTreeApply}{__compressed_pair<vision::hum::DTreeApply *, std::__1::allocator<vision::hum::DTreeApply> >=^{DTreeApply}}}}{linearSVMApply={vector<float, std::__1::allocator<float> >=^f^f{__compressed_pair<float *, std::__1::allocator<float> >=^f}}f{vector<float, std::__1::allocator<float> >=^f^f{__compressed_pair<float *, std::__1::allocator<float> >=^f}}}@}
v24@0:8^{vImage_Buffer=^vQQQ}16
f40@0:8^{vImage_Buffer=^vQQQ}16@24^@32
^{ACBSConfig=}24@0:8^@16
B56@0:8@16^{CGPoint=dd}24^{CGPoint=dd}32^{CGPoint=dd}40^{CGPoint=dd}48
@84@0:8@16Q24Q32{CGRect={CGPoint=dd}{CGSize=dd}}40f72^@76
@40@0:8@16^{ACBSConfig=}24^@32
@"NSMapTable"
@48@0:8^{vImage_Buffer=^vQQQ}16@24@32^@40
@48@0:8^{vImage_Buffer=^vQQQ}16@24q32^@40
@48@0:8^{__CVBuffer=}16@24@32^@40
@48@0:8^{__CVBuffer=}16@24q32^@40
^{vImage_Buffer=^vQQQ}16@0:8
^{vImage_Buffer=^vQQQ}
@"NSArray"16@0:8
v24@0:8@"NSArray"16
v48@0:8@16@24@32@40
Q40@0:8@16Q24^@32
@40@0:8@16Q24^@32
Q40@0:8@"NSMutableData"16Q24^@32
@40@0:8@"NSData"16Q24^@32
@32@0:8@"NSData"16^@24
@40@0:8@16Q24Q32
@"VNMPImageDescriptor"
[9f]
{shared_ptr<vision::mod::FaceRegionMap>="__ptr_"^{FaceRegionMap}"__cntrl_"^{__shared_weak_count}}
v28@0:8I16@20
I24@0:8@16
v72@0:8{CGAffineTransform=dddddd}16@64
{CGAffineTransform=dddddd}24@0:8@16
v72@0:8{?=[3]}16@64
{?=[3]}24@0:8@16
v88@0:8{?=[4]}16@80
{?=[4]}24@0:8@16
@"NSUUID"
@48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
v80@0:8{CGPoint=dd}16{CGPoint=dd}32{CGPoint=dd}48{CGPoint=dd}64
@"NSData"16@0:8
v24@0:8@"NSData"16
@40@0:8@16q24^@32
I16@0:8
v20@0:8I16
@80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48
B104@0:8{?=[4]}16^f80^f88^f96
{?=[4]}16@0:8
B24@0:8^{CGAffineTransform=dddddd}16
{_Geometry2D_rect2D_={_Geometry2D_point2D_=ff}{_Geometry2D_size2D_=ff}}16@0:8
v32@0:8{_Geometry2D_rect2D_={_Geometry2D_point2D_=ff}{_Geometry2D_size2D_=ff}}16
@"VNFaceLandmarks2D"
@"VNFaceLandmarks3D"
@"VNFaceRegionMap"
@"VNFaceprint"
{CGAffineTransform=dddddd}16@0:8
v64@0:8{CGAffineTransform=dddddd}16
{CGAffineTransform="a"d"b"d"c"d"d"d"tx"d"ty"d}
{?=[3]}16@0:8
v64@0:8{?=[3]}16
{?="columns"[3]}
@"VNImageprint"
@28@0:8@16f24
@"MLFeatureValue"
@80@0:8{CGPoint=dd}16{CGPoint=dd}32{CGPoint=dd}48{CGPoint=dd}64
B48@0:8@16@24Q32@40
B32@0:8@16@24
@96@0:8@16@24{CGPoint=dd}32{CGPoint=dd}48{CGPoint=dd}64{CGPoint=dd}80
@64@0:8@16@24{CGRect={CGPoint=dd}{CGSize=dd}}32
@"CIBarcodeDescriptor"
B36@0:8^@16B24^@28
@28@0:8B16^@20
@"NSArray"28@0:8B16^@20
{CGRect={CGPoint=dd}{CGSize=dd}}32@0:8Q16Q24
{CGRect={CGPoint=dd}{CGSize=dd}}68@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGSize=dd}48i64
v44@0:8@16{CGSize=dd}24i40
v56@0:8@16@24@32@40@?48
v48@0:8@16@24@32@?40
v28@0:8@16i24
^{__sFILE=*iiss{__sbuf=*i}i^v^?^?^?^?{__sbuf=*i}^{__sFILEX}i[3C][1C]{__sbuf=*i}iq}
@"BurstImageFaceAnalysisContext"
@"NSCountedSet"
@"BurstActionClassifier"
q40@0:8@16^^{MPClusteringTreeNode}24@32
f28@0:8^{MPClusteringTreeNode=@iffi^{MPClusteringTreeNode}^{MPClusteringTreeNode}^{MPClusteringTreeNode}^{MPClusteringTreeNode}}16i24
{vector<MPClusteringTreeNode *, std::__1::allocator<MPClusteringTreeNode *> >=^^{MPClusteringTreeNode}^^{MPClusteringTreeNode}{__compressed_pair<MPClusteringTreeNode **, std::__1::allocator<MPClusteringTreeNode *> >=^^{MPClusteringTreeNode}}}40@0:8i16f20^{MPClusteringTreeNode=@iffi^{MPClusteringTreeNode}^{MPClusteringTreeNode}^{MPClusteringTreeNode}^{MPClusteringTreeNode}}24@32
{vector<MPClusteringTreeNode *, std::__1::allocator<MPClusteringTreeNode *> >=^^{MPClusteringTreeNode}^^{MPClusteringTreeNode}{__compressed_pair<MPClusteringTreeNode **, std::__1::allocator<MPClusteringTreeNode *> >=^^{MPClusteringTreeNode}}}36@0:8i16^{MPClusteringTreeNode=@iffi^{MPClusteringTreeNode}^{MPClusteringTreeNode}^{MPClusteringTreeNode}^{MPClusteringTreeNode}}20@28
{vector<MPClusteringTreeNode *, std::__1::allocator<MPClusteringTreeNode *> >=^^{MPClusteringTreeNode}^^{MPClusteringTreeNode}{__compressed_pair<MPClusteringTreeNode **, std::__1::allocator<MPClusteringTreeNode *> >=^^{MPClusteringTreeNode}}}36@0:8f16^{MPClusteringTreeNode=@iffi^{MPClusteringTreeNode}^{MPClusteringTreeNode}^{MPClusteringTreeNode}^{MPClusteringTreeNode}}20@28
{vector<MPClusteringTreeNode *, std::__1::allocator<MPClusteringTreeNode *> >=^^{MPClusteringTreeNode}^^{MPClusteringTreeNode}{__compressed_pair<MPClusteringTreeNode **, std::__1::allocator<MPClusteringTreeNode *> >=^^{MPClusteringTreeNode}}}32@0:8^{MPClusteringTreeNode=@iffi^{MPClusteringTreeNode}^{MPClusteringTreeNode}^{MPClusteringTreeNode}^{MPClusteringTreeNode}}16@24
f28@0:8f16q20
f32@0:8f16q20B28
@36@0:8^{vImage_Buffer=^vQQQ}16i24^@28
^{CGImage=}32@0:8@16^@24
{vImage_Buffer=^vQQQ}32@0:8@16^@24
{shared_ptr<vision::mod::LandmarkDetector>="__ptr_"^{LandmarkDetector}"__cntrl_"^{__shared_weak_count}}
^{__CVBuffer=}68@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16f48@52^@60
{shared_ptr<vision::mod::ObjectDetector_DCNFaceDetector>="__ptr_"^{ObjectDetector_DCNFaceDetector}"__cntrl_"^{__shared_weak_count}}
24@0:8Q16
@32@0:8^16Q24
r^16@0:8
v24@0:8r^16
^v32@0:8r^i16Q24
@84@0:8@16Q24{CGRect={CGPoint=dd}{CGSize=dd}}32{_Geometry2D_rect2D_={_Geometry2D_point2D_=ff}{_Geometry2D_size2D_=ff}}64f80
@"VNFaceLandmarkRegion2D"
@"VNFaceLandmarkRegion3D"
B48@0:8Q16Q24@?32^@40
B64@0:8@16@24#32Q40Q48^@56
@48@0:8#16@24@32^@40
B72@0:8^@16@24@32#40Q48Q56^@64
@48@0:8@16@24#32^@40
@40@0:8^{__CVBuffer=}16@24^@32
@"MLModel"
@"VNCoreMLModel"
B124@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24^{ImageDescriptorProcessorAbstract=^^?}56i64B68I72^{ImageDescriptorBufferAbstract=^^?{vector<long long, std::__1::allocator<long long> >=^q^q{__compressed_pair<long long *, std::__1::allocator<long long> >=^q}}{map<long long, int, std::__1::less<long long>, std::__1::allocator<std::__1::pair<const long long, int> > >={__tree<std::__1::__value_type<long long, int>, std::__1::__map_value_compare<long long, std::__1::__value_type<long long, int>, std::__1::less<long long>, true>, std::__1::allocator<std::__1::__value_type<long long, int> > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<long long, int>, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<long long, std::__1::__value_type<long long, int>, std::__1::less<long long>, true> >=Q}}}^vQQQB}76@84@92@100@108^@116
B64@0:8^{ImageClassifierAbstract=^^?{vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > >=^{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >}^{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >}{__compressed_pair<std::__1::basic_string<char> *, std::__1::allocator<std::__1::basic_string<char> > >=^{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >}}}{map<std::__1::basic_string<char>, float, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, float> > >={__tree<std::__1::__value_type<std::__1::basic_string<char>, float>, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, float>, std::__1::less<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__value_type<std::__1::basic_string<char>, float> > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<std::__1::basic_string<char>, float>, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, float>, std::__1::less<std::__1::basic_string<char> >, true> >=Q}}}{vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > >=^{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >}^{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >}{__compressed_pair<std::__1::basic_string<char> *, std::__1::allocator<std::__1::basic_string<char> > >=^{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >}}}iffii}16^{ImageDescriptorBufferAbstract=^^?{vector<long long, std::__1::allocator<long long> >=^q^q{__compressed_pair<long long *, std::__1::allocator<long long> >=^q}}{map<long long, int, std::__1::less<long long>, std::__1::allocator<std::__1::pair<const long long, int> > >={__tree<std::__1::__value_type<long long, int>, std::__1::__map_value_compare<long long, std::__1::__value_type<long long, int>, std::__1::less<long long>, true>, std::__1::allocator<std::__1::__value_type<long long, int> > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<long long, int>, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<long long, std::__1::__value_type<long long, int>, std::__1::less<long long>, true> >=Q}}}^vQQQB}24^{vector<std::__1::map<std::__1::basic_string<char>, float, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, float> > >, std::__1::allocator<std::__1::map<std::__1::basic_string<char>, float, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, float> > > > >=^{map<std::__1::basic_string<char>, float, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, float> > >}^{map<std::__1::basic_string<char>, float, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, float> > >}{__compressed_pair<std::__1::map<std::__1::basic_string<char>, float, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, float> > > *, std::__1::allocator<std::__1::map<std::__1::basic_string<char>, float, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, float> > > > >=^{map<std::__1::basic_string<char>, float, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, float> > >}}}32@40@48^@56
@68@0:8r^{ImageDescriptorBufferAbstract=^^?{vector<long long, std::__1::allocator<long long> >=^q^q{__compressed_pair<long long *, std::__1::allocator<long long> >=^q}}{map<long long, int, std::__1::less<long long>, std::__1::allocator<std::__1::pair<const long long, int> > >={__tree<std::__1::__value_type<long long, int>, std::__1::__map_value_compare<long long, std::__1::__value_type<long long, int>, std::__1::less<long long>, true>, std::__1::allocator<std::__1::__value_type<long long, int> > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<long long, int>, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<long long, std::__1::__value_type<long long, int>, std::__1::less<long long>, true> >=Q}}}^vQQQB}16^{ImageClassifierAbstract=^^?{vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > >=^{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >}^{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >}{__compressed_pair<std::__1::basic_string<char> *, std::__1::allocator<std::__1::basic_string<char> > >=^{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >}}}{map<std::__1::basic_string<char>, float, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, float> > >={__tree<std::__1::__value_type<std::__1::basic_string<char>, float>, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, float>, std::__1::less<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__value_type<std::__1::basic_string<char>, float> > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<std::__1::basic_string<char>, float>, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, float>, std::__1::less<std::__1::basic_string<char> >, true> >=Q}}}{vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > >=^{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >}^{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >}{__compressed_pair<std::__1::basic_string<char> *, std::__1::allocator<std::__1::basic_string<char> > >=^{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >}}}iffii}24f32@36@44@52^@60
@84@0:8r^{ImageDescriptorBufferAbstract=^^?{vector<long long, std::__1::allocator<long long> >=^q^q{__compressed_pair<long long *, std::__1::allocator<long long> >=^q}}{map<long long, int, std::__1::less<long long>, std::__1::allocator<std::__1::pair<const long long, int> > >={__tree<std::__1::__value_type<long long, int>, std::__1::__map_value_compare<long long, std::__1::__value_type<long long, int>, std::__1::less<long long>, true>, std::__1::allocator<std::__1::__value_type<long long, int> > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<long long, int>, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<long long, std::__1::__value_type<long long, int>, std::__1::less<long long>, true> >=Q}}}^vQQQB}16^{ImageClassifierAbstract=^^?{vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > >=^{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >}^{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >}{__compressed_pair<std::__1::basic_string<char> *, std::__1::allocator<std::__1::basic_string<char> > >=^{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >}}}{map<std::__1::basic_string<char>, float, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, float> > >={__tree<std::__1::__value_type<std::__1::basic_string<char>, float>, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, float>, std::__1::less<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__value_type<std::__1::basic_string<char>, float> > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<std::__1::basic_string<char>, float>, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, float>, std::__1::less<std::__1::basic_string<char> >, true> >=Q}}}{vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > >=^{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >}^{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >}{__compressed_pair<std::__1::basic_string<char> *, std::__1::allocator<std::__1::basic_string<char> > >=^{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >}}}iffii}24^{ImageClassifier_HierarchicalModel=^{ImageClassfier_Graph}}32f40f44i48@52@60@68^@76
@56@0:8^{__CVBuffer=}16@24@32@40@?48
f36@0:8@16^i24i32
r^v16@0:8
v24@0:8@"NSString"16
@24@0:8r^{mapped_model_file=i^vQ}16
r^{mapped_model_file=i^vQ}
{unique_ptr<cvml::util::model_file_cache, std::__1::default_delete<cvml::util::model_file_cache> >="__ptr_"{__compressed_pair<cvml::util::model_file_cache *, std::__1::default_delete<cvml::util::model_file_cache> >="__first_"^{model_file_cache}}}
@44@0:8@16f24@28^@36
B48@0:8@16@24@32^@40
f24@0:8f16f20
@"BurstImageSetInternal"
@36@0:8@16@24f32
@"VNFaceObservation"
@"<NSObject><NSCopying><NSSecureCoding>"
@44@0:8B16@20@28^@36
B32@0:8^{CVMLCanceller=^^?Bi}16^@24
@56@0:8@16r^{ImageDescriptorBufferFloat32=^^?{vector<long long, std::__1::allocator<long long> >=^q^q{__compressed_pair<long long *, std::__1::allocator<long long> >=^q}}{map<long long, int, std::__1::less<long long>, std::__1::allocator<std::__1::pair<const long long, int> > >={__tree<std::__1::__value_type<long long, int>, std::__1::__map_value_compare<long long, std::__1::__value_type<long long, int>, std::__1::less<long long>, true>, std::__1::allocator<std::__1::__value_type<long long, int> > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<long long, int>, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<long long, std::__1::__value_type<long long, int>, std::__1::less<long long>, true> >=Q}}}^vQQQBQi^f}24Q32^{CVMLCanceller=^^?Bi}40^@48
@"VNPersonsModelConfiguration"
{shared_ptr<vision::mod::ImageDescriptorBufferFloat32>="__ptr_"^{ImageDescriptorBufferFloat32}"__cntrl_"^{__shared_weak_count}}
{vector<int, std::__1::allocator<int> >="__begin_"^i"__end_"^i"__end_cap_"{__compressed_pair<int *, std::__1::allocator<int> >="__first_"^i}}
{shared_ptr<vision::mod::FaceIDModel>="__ptr_"^{FaceIDModel}"__cntrl_"^{__shared_weak_count}}
@40@0:8^{__CVBuffer=}16Q24^@32
@40@0:8^{vImage_Buffer=^vQQQ}16Q24^@32
{shared_ptr<vision::mod::FaceFrontalizer>="__ptr_"^{FaceFrontalizer}"__cntrl_"^{__shared_weak_count}}
{shared_ptr<vision::mod::ImageDescriptorAugmenterFlip>="__ptr_"^{ImageDescriptorAugmenterFlip}"__cntrl_"^{__shared_weak_count}}
{shared_ptr<unsigned char>="__ptr_"*"__cntrl_"^{__shared_weak_count}}
{_Geometry2D_size2D_="height"f"width"f}
v28@0:8Q16I24
I28@0:8Q16I24
v36@0:8Q16Q24I32
*16@0:8
v24@0:8*16
^Q16@0:8
v24@0:8^Q16
v24@0:8^S16
S16@0:8
v20@0:8S16
s16@0:8
v20@0:8s16
i48@0:8Q16Q24Q32^{vImage_Buffer=^vQQQ}40
i88@0:8{vImage_Buffer=^vQQQ}16{vImage_Buffer=^vQQQ}48*80
v56@0:8S16^f20^{__CCPulseWindowContext=^{__CCRange}SSsB}28C36C40{ThresholdSet_t=fff}44
i56@0:8S16C20C24{ThresholdSet_t=fff}28^f40Q48
v48@0:8^{__CCRange=SS}16*24^i32^i40
i28@0:8^{__CCSumDerivVectors=^f^f^f^f^fffii}16i24
v24@0:8^{__CCSumDerivVectors=^f^f^f^f^fffii}16
v32@0:8^{__CCSumDerivVectors=^f^f^f^f^fffii}16i24C28
i72@0:8C16^f20S28C32C36^{__CCFilterSumDerivConfig={__CCRange=SS}{__CCRange=SS}BBQQ}40S48{ThresholdSet_t=fff}52*64
i96@0:8^f16S24S28C32C36S40S44I48I52S56{ThresholdSet_t=fff}60*72^f80Q88
v52@0:8Q16Q24Q32C40S44S48
v40@0:8Q16Q24S32S36
v44@0:8Q16^S24C32S36S40
i56@0:8^{__rgbaColor=CCCC}16^{__rgbaColor=CCCC}24I32I36^{__rgbMinMaxU8=CCCCCC}40^{__rgbMinMaxFloat=ffffff}48
I92@0:8{vImage_Buffer=^vQQQ}16{vImage_Buffer=^vQQQ}48C80^{__rgbMinMaxFloat=ffffff}84
f88@0:8{vImage_Buffer=^vQQQ}16{vImage_Buffer=^vQQQ}48S80S84
v64@0:8{vImage_Buffer=^vQQQ}16^{__CCColorProfileContext={vImage_Buffer=^vQQQ}{vImage_Buffer=^vQQQ}{vImage_Buffer=^vQQQ}{vImage_Buffer=^vQQQ}iiSS}48S56S60
v60@0:8{vImage_Buffer=^vQQQ}16S48^{__CCColorProfileContext={vImage_Buffer=^vQQQ}{vImage_Buffer=^vQQQ}{vImage_Buffer=^vQQQ}{vImage_Buffer=^vQQQ}iiSS}52
S40@0:8^f16Q24^S32
i72@0:8{vImage_Buffer=^vQQQ}16S48^S52f60^S64
v24@0:8^{__CCColorProfileContext={vImage_Buffer=^vQQQ}{vImage_Buffer=^vQQQ}{vImage_Buffer=^vQQQ}{vImage_Buffer=^vQQQ}iiSS}16
i40@0:8^{__CCColorProfileContext={vImage_Buffer=^vQQQ}{vImage_Buffer=^vQQQ}{vImage_Buffer=^vQQQ}{vImage_Buffer=^vQQQ}iiSS}16S24S28Q32
i152@0:8{vImage_Buffer=^vQQQ}16{vImage_Buffer=^vQQQ}48{vImage_Buffer=^vQQQ}80^{__rgbMinMaxU8=CCCCCC}112^{__rgbMinMaxFloat=ffffff}120S128S132S136^I140C148
i84@0:8{vImage_Buffer=^vQQQ}16{vImage_Buffer=^vQQQ}48C80
i80@0:8{vImage_Buffer=^vQQQ}16{vImage_Buffer=^vQQQ}48
i92@0:8@16Q24{vImage_Buffer=^vQQQ}32^Q64^{__CCBigBox=SSSS[50{__CCCharBox=SSSSS}]}72^{__CCBigBox=SSSS[50{__CCCharBox=SSSSS}]}80C88
v72@0:8@16^{__CCBigBox=SSSS[50{__CCCharBox=SSSSS}]}24{vImage_Buffer=^vQQQ}32C64S68
v32@0:8^{__CCBox=SSSS}16^Q24
i32@0:8^{__CCBox=SSSS}16^Q24
i56@0:8*16S24S28Q32Q40S48S52
{__CCRange=SS}76@0:8{vImage_Buffer=^vQQQ}16S48S52S56S60Q64S72
v156@0:8{vImage_Buffer=^vQQQ}16*48{vImage_Buffer=^vQQQ}56{vImage_Buffer=^vQQQ}88S120S124^{__CCBox=SSSS}128^{__CCBox=SSSS}136^Q144C152
v60@0:8^f16^f24S32S36^B40^f48C56
v84@0:8{vImage_Buffer=^vQQQ}16S48S52S56^{__rgbMinMaxFloat=ffffff}60^f68^f76
i80@0:8{vImage_Buffer=^vQQQ}16f48f52S56^f60^f68C76
I48@0:8^{__CCBigBox=SSSS[50{__CCCharBox=SSSSS}]}16C24^S28^S36B44
v40@0:8Q16Q24Q32
v72@0:8{vImage_Buffer=^vQQQ}16^f48^f56S64S68
v56@0:8^{__CCCharBox=SSSSS}16^{__CCCharBox=SSSSS}24^S32^S40S48S52
S48@0:8^{__CCCharBox=SSSSS}16^{__CCBigBox=SSSS[50{__CCCharBox=SSSSS}]}24^S32^S40
i76@0:8^{__CCBigBox=SSSS[50{__CCCharBox=SSSSS}]}16^{__CCBigBox=SSSS[50{__CCCharBox=SSSSS}]}24C32S36S40C44S48S52^{__CCCharBox=SSSSS}56^{__CCCharBox=SSSSS}64C72
i180@0:8{vImage_Buffer=^vQQQ}16{vImage_Buffer=^vQQQ}48{vImage_Buffer=^vQQQ}80^{__CCBigBox=SSSS[50{__CCCharBox=SSSSS}]}112^{__CCBigBox=SSSS[50{__CCCharBox=SSSSS}]}120^{__CCCharBox=SSSSS}128^{__CCCharBox=SSSSS}136S144S148S152*156C164^S168C176
i52@0:8{vImage_Buffer=^vQQQ}16S48
v60@0:8{vImage_Buffer=^vQQQ}16Q48B56
i24@0:8Q16
i68@0:8^{__CCBigBox=SSSS[50{__CCCharBox=SSSSS}]}16C24S28Q32^{__CCBox=SSSS}40Q48S56*60
i160@0:8@16{vImage_Buffer=^vQQQ}24*56^{__CCBigBox=SSSS[50{__CCCharBox=SSSSS}]}64^{__CCBigBox=SSSS[50{__CCCharBox=SSSSS}]}72{vImage_Buffer=^vQQQ}80{vImage_Buffer=^vQQQ}112^{__rgbMinMaxFloat=ffffff}144C152C156
i88@0:8{vImage_Buffer=^vQQQ}16{vImage_Buffer=^vQQQ}48^S80
@56@0:8{vImage_Buffer=^vQQQ}16^@48
C16@0:8
v20@0:8C16
@"CCCharBoxContext"
@"NSCache"
B80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48
B88@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48d80
@"VNTracker"32@0:8@"NSDictionary"16^@24
v24@0:8@"VNTracker"16
@"NSMutableSet"
v40@0:8@16@24@32
@44@0:8@16@24@32f40
@"VNClustererReadOnlyContext"
@"VNClustererReadWriteContext"
v68@0:8@16^{__CVBuffer=}24{_Geometry2D_rect2D_={_Geometry2D_point2D_=ff}{_Geometry2D_size2D_=ff}}32{_Geometry2D_rect2D_={_Geometry2D_point2D_=ff}{_Geometry2D_size2D_=ff}}48f64
{shared_ptr<vision::mod::FaceBoxPoseAligner<signed char> >="__ptr_"^{FaceBoxPoseAligner<signed char>}"__cntrl_"^{__shared_weak_count}}
^{ObjectTrackerAbstract=^^?^{ObjectDetectorAbstract}{shared_ptr<vision::mod::ObjectTrackerOptions>=^{ObjectTrackerOptions}^{__shared_weak_count}}}40@0:8@16^{ObjectTrackerOptions=^^?@i}24^@32
B64@0:8@16^{vector<vision::mod::DetectedObject, std::__1::allocator<vision::mod::DetectedObject> >=^{DetectedObject}^{DetectedObject}{__compressed_pair<vision::mod::DetectedObject *, std::__1::allocator<vision::mod::DetectedObject> >=^{DetectedObject}}}24{CGSize=dd}32@48^@56
{shared_ptr<vision::mod::ObjectTrackerAbstract>="__ptr_"^{ObjectTrackerAbstract}"__cntrl_"^{__shared_weak_count}}
@"VNImageBuffer"24@0:8^@16
@44@0:8@16@24@32I40
r^{FastRegistration_Signatures=^fQ{Projections_meanStdTable=^f^f}^fQ{Projections_meanStdTable=^f^f}*}16@0:8
B60@0:8^{CGAffineTransform=dddddd}16@24@32@40f48^@52
q32@0:8^{vImage_Buffer=^vQQQ}16^f24
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
?P$
{v=Y
>C<
">U:#>
j%>j
)>+2*>
*>2;+>
A,>c
,>NF->
->wH.>
.>rH/>
/>AF0>_
2>:33>N
u7>d
8>.N9>:
<>`\=>
?>(m@>
A>8%B>R
B>gkC>h
CD>]
E>$XF>
H>U4I>
J>LiJ>
5K>n
L>^/M>
M>5[N>
!O>m
O>*IP>!
Q>*nQ>I
Q>&0R>
T>`-U>
`W>~
Z>6R[>
`\>l
]>5m]>B
^>H(_>;
a>v8b>
b>,:c>
d>A8e>
4f>t
f>i/g>
g>z(h>!{h>
j>Ggj>
Ml>u
,n>"|n>Z
o>>io>
Tp>"
p>"?q>
'r>@ur>`
s>3\s>
v>]Tv>
5w>V
z>ydz>
~>"Z~>
MbP?
Me!>
`Y?*
K/>n
4?Rc
As?@
[?>Y
5?+3A?&S
>;9W?@1
^y>?
>3PI>
j?}Y
?}wG?X
&>CVK?
q'?ep0?
xj>t
>: i?
6:>0
>=`Z?
=aR<>=
aK=e
>A*q?C
t=+jp>B
->g,&?"R;?
>?k}A>}
G?c%
O?Ig
>obp?
$X?7pG>
>h@=>H
\'?`
7?BZg?
{>?q
g?> 
=6rQ?
8?6v
y?F$&?~
L?6X
GS?R
>FA?6Wq?
{?OX
>9{3?1
*?<h6>
?X:/>
XQ?$~
>S\%>o
v#?Y
@#?o+u?
{v>U
*X?S]
>c~j?'
>5)E?
>:u)?w1E?
>}y)?
W?:U?<L
B%?-|
?sc~?
>}>2?
=?!"
6=JCA?
.?m<4?
I>O\R?
Dc?#I
D?R(
LA?:
>R`U?
\?@h}?:
?=`b?
L>h\
??yYS?
>WCB>mq
>k,a=T
a?V)}?
?]m}?
>$%M?
Oi>-
d?6x{?
>|HX?DnV>
>W!E>w
>~t*>+
OU=0cn?
E\?+5o?
)?kb
}?C<
uQ?1A
=Nd6>
Ch=R
Nx>(-\=c)
`I>K9
"~=p
=8hS?.
\)<]pF=
$?OZ
>9`'?
r=?}vp>5&<?-yx? 
R>x~
rj>?V$?
>L?;
E?oI2?
>b1*>
>?pB
>:X'?
C?AcB?
=?Vb>?
>BAY>T
~'> ~*?
d?%=
t?`w
@?5(j>yt
^$?v
-Z?mq
ms?@O
