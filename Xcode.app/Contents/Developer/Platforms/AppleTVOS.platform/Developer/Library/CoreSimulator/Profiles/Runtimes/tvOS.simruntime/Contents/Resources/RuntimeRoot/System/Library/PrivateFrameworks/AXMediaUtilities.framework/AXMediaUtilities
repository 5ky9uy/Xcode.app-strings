init
dictionary
_lexiconForLocale:diagnostics:
currentLocale
languageCode
localeIdentifier
objectForKey:
dictionaryWithObjects:forKeys:count:
stringWithFormat:
captureMetrics:name:forTask:
setObject:forKey:
lexiconExistsForLocale:diagnostics:
textExistsInLexicon:withLocale:diagnostics:
.cxx_destruct
_cachedLexicons
_opaqueLexiconForLocale:diagnostics:
grabScreenWithRect:orientation:ignoredLayerContextIDs:renderToPixelBufferNow:diagnostics:error:
getFaceLeftRightLocationInImage
getFaceTopBottomLocationInImage
computeFaceLocationUsingLeftRightLoc:andTopBottomLoc:
swap:with:
isLargeFace
getFaceCoordsInImage
getFaceLocationInImage
getFaceLocationOnScreen
imageWidth
setImageWidth:
imageHeight
setImageHeight:
size
setSize:
bounds
setBounds:
screenOrientation
setScreenOrientation:
imageMirrored
setImageMirrored:
smiling
setSmiling:
blinking
setBlinking:
_imageMirrored
_smiling
_blinking
_imageWidth
_imageHeight
_size
_screenOrientation
_bounds
nodeInitialize
initWithCoder:
encodeWithCoder:
validateVisionKitSoftLinkSymbols
evaluate:
visionImageRequestHandler
alloc
arrayWithObjects:count:
performRequests:error:
results
firstObject
featureWithVisionRequest:horizonResult:canvasSize:
appendFeature:
supportsSecureCoding
isSupported
title
requiresVisionFramework
decodeObjectOfClasses:forKey:
setMainColors:weights:
mainColors
encodeObject:forKey:
mainColorWeights
count
setMainColors:
setMainColorWeights:
objectAtIndexedSubscript:
floatValue
enumerateMainColors:
remainingColorWeight
setRemainingColorWeight:
_remainingColorWeight
_mainColors
_mainColorWeights
countByEnumeratingWithState:objects:count:
featureWithVisionRequest:faceResult:canvasSize:
invalidate
_destroyXPCConnection
dealloc
initWithServiceName:
setRemoteObjectInterface:
isEqual:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
description
debugDescription
interfaceWithProtocol:
setExportedInterface:
setExportedObject:
setInterruptionHandler:
setInvalidationHandler:
resume
xpcConnection
remoteObjectProxyWithErrorHandler:
_serviceProxy
prewarmVisionEngineService
visionEngine:evaluateSource:context:options:result:
setXpcConnection:
_xpcConnectionQueue
_xpcConnection
_commonInit
setName:
setRepresentedMetrics:
decodeIntegerForKey:
decodeObjectOfClass:forKey:
isElapsedTimeMetric
decodeInt64ForKey:
isMemoryFootprintMetric
getValue:size:
encodeInteger:forKey:
name
representedMetrics
encodeInt64:forKey:
valueWithBytes:objCType:
numberWithUnsignedLongLong:
initialResidentMemory
finalResidentMemory
unsignedLongLongValue
numberWithLongLong:
initialResidentMemoryPeak
finalResidentMemoryPeak
initialPhysicalFootprint
finalPhysicalFootprint
initialTime
finalTime
numberWithDouble:
numberWithInt:
_capturMachAbsoluteTime:taskInfo:vmInfo:
elapsedTime
doubleValue
physicalFootprintDelta
longLongValue
residentMemoryDelta
residentMemoryPeakDelta
initWithName:metrics:
start
finish
_state
_startTime
_endTime
_startTaskInfo
_startVMInfo
_endTaskInfo
_endVMInfo
_name
_representedMetrics
_init
array
setWithArray:
mutableCopy
decodeBoolForKey:
setDiagnosticsEnabled:
metrics
diagnosticsEnabled
encodeBool:forKey:
processInfo
environment
boolValue
addObject:
removeAllObjects
copy
addMetric:
captureMetrics:name:forTask:signpostStartBlock:signpostEndBlock:
clearMetrics
startMeasurement:name:
_queue
_queue_diagnosticMetrics
_diagnosticsEnabled
sharedInstance
_diagnostics
_metric
initWithString:
speechItemSeparator
appendAttributedString:
bundleForClass:
URLForResource:withExtension:subdirectory:
addSoundItemWithURL:
defaultManager
path
fileExistsAtPath:
speechSequence
addSpeechItem:
soundFileURLs
addSoundItemWithID:
interruptsAndClearsQueue
setInterruptsAndClearsQueue:
_speechSequence
_soundFileURLs
_interruptsAndClearsQueue
speechStringForObjectValue:
stringForObjectValue:
getObjectValue:forString:errorDescription:
initWithFormattingBlock:
formattingBlock
setFormattingBlock:
_formattingBlock
decodeObjectForKey:
fileURLWithPath:
preloadModelIfNeeded:
modelURL
setModelURL:
_modelURL
setShouldProcessRemotely:
evaluationExclusivelyUsesVisionFramework
objectForKeyedSubscript:
AXMRectValue
integerValue
analysisOptions
ignoredLayerContextIDs
screenGrabber
diagnostics
produceImage:
defaultOptions
axmValueWithCGRect:
numberWithInteger:
contextWithSourceParameters:options:
triggerWithContext:cacheKey:resultHandler:
triggerWithScreenCaptureRegion:interfaceOrientation:options:cacheKey:resultHandler:
setScreenGrabber:
_screenGrabber
shouldEvaluateColorInformation
_evaluateColorInformation:
_blurValueForVisionObservation:
featureWithVisionRequest:blurValue:canvasSize:
brightness
numberWithFloat:
exposureScore
blurMeasure
blurScore
colorWithHue:saturation:brightness:
featureWithColorInfo:canvasSize:
analyzeBuffer:
_brightnessValueForVisionObservation:
sampleFrequency
setSampleFrequency:
setShouldEvaluateColorInformation:
colorDistanceTheshold
setColorDistanceTheshold:
_shouldEvaluateColorInformation
_sampleFrequency
_colorDistanceTheshold
setIdentifier:
initWithDelegate:targetQueue:
weakToWeakObjectsMapTable
setAxMediaUtilsService:
initWithIdentifier:delegate:
setTaskDispatcher:
isEqualToEngine:
identifier
isEqualToString:
sourceNodes
evaluationNodes
archivedDataWithRootObject:requiringSecureCoding:error:
unarchivedObjectOfClass:fromData:error:
setMaximumQueueSize:
setPrioritySchedulingEnabled:
setThresholdPriority:
setFeatureTrackingEnabled:
maximumQueueSize
addSourceNode:
addEvaluationNode:
areDiagnosticsEnabled
prioritySchedulingEnabled
isFeatureTrackingEnabled
thresholdPriority
isCachingEnabled
cacheKey
addResultHandlers:
resultHandlers
_queue_shouldContinueWithoutResultHandlers:
axMediaUtilsService
_queue_handleEvaluatedContext:result:error:
shouldEvaluate:
detectText
detectScenes
detectModelClassifications
detectFaces
detectTraits
detectHumans
detectHorizon
detectRectangles
isEnabled
_queue_shouldEvaluateNode:withOptions:
boostEffectivePriority
effectivePriority
resetEffectivePriority
features
detectedFeatureDescription
detectedTextDescription
sourceProvidesResults
_queue_activeEvaluationNodesForOptions:applyPriorityScheduling:
_queue_activeEvaluationNodesExclusivelyUseVisionFramework:
setEvaluationExclusivelyUsesVisionFramework:
settings
writeOutInputImages
generateImageRepresentation
generateFileNameForImageWithPrefix:extension:
URLByAppendingPathComponent:
error
result
_queue_logEvaluatedResult:
didFinishProcessingContext
cache
setResult:forKey:
queue_processResult:
_invokeResultHandlers:withError:
shouldCallCompletionHandlersForEmptyResultSet
_invokeResultHandlers:withResult:
markAsComplete:
canAddSourceNode:
isConnected
connect:
insertObject:atIndex:
disconnect
removeObject:
canAddEvaluationNode:
_queue_sourceNodeWithIdentifier:
_queue_evaluationNodeWithIdentifier:
_queue_makeUniqueIdentifierForNode:
stringByReplacingOccurrencesOfString:withString:
_queue_nodeIdentifierExists:
_queue_addResultHandler:
_queue_removeResultHandler:
_queue_removeAllResultHandlers
cacheSize
initWithCacheSize:
setCache:
defaultCenter
postNotificationName:object:
requestForcedCleanupWithOptions:completion:
axmIndentationString:
axmDescription
appendFormat:
axmAppendRecursiveDescription:withIndentation:
source
context
willBeginProcessingContext
shouldProcessRemotely
_queue_remotelyEvaluateWithSource:context:
_queue_evaluateWithSource:context:
_queue_addFeatureTrackingObbserver:targetQueue:
_queue_removeFeatureTrackingObbserver:
removeObjectForKey:
_queue_removeAllFeatureTrackingObservers
queue_trackedFeatures
queue_trackedText
queue_trackedRectangles
queue_trackedModelClassifiers
keyEnumerator
visionEngine:didBeginTrackingFeature:appliedOrientation:
visionEngine:didFinishTrackingFeature:appliedOrientation:
visionEngine:trackingFeatureLocationDidChange:appliedOrientation:
taskDispatcher
shouldCallCompletionHandlersForEngineBusyError
addObjectsFromArray:
itemWithSource:context:
scheduleTask:
triggerWithSource:context:
engineWillAcceptTiggerWithSource:
captureSessionNodeDidBeginProcessingFrames:
captureSessionNodeDidEndProcessingFrames:
captureSessionNodeWillProcessFrame:
captureSessionNodeDidDropFrame:
trackingManager:didBeginTrackingFeature:appliedOrientation:
trackingManager:didFinishTrackingFeature:appliedOrientation:
trackingManager:trackingFeatureLocationDidChange:appliedOrientation:
dispatcher:handleTask:
copyWithZone:
initWithIdentifier:
canAddSourceNodeClass:
insertSourceNode:atIndex:
removeSourceNode:
removeAllSourceNodes
canAddEvaluationNodeClass:
insertEvaluationNode:atIndex:
removeEvaluationNode:
removeAllEvaluationNodes
addSourceNodes:evaluationNodes:
sourceNodeWithIdentifier:
evaluationNodeWithIdentifier:
makeUniqueIdentifierForNode:
nodeIdentifierExists:
addResultHandler:
removeResultHandler:
removeAllResultHandlers
enableResultCachingWithCacheSize:
disableResultCaching
updateEngineConfiguration:
prewarmEngine
purgeResources:
addFeatureTrackingObbserver:targetQueue:
removeFeatureTrackingObbserver:
removeAllFeatureTrackingObservers
trackedFaces
trackedText
trackedRectangles
trackedModelClassifiers
_queue_sourceNodes
_queue_evaluationNodes
_queue_resultHandlers
_queue_shouldNotifyServiceOfEngineConfigChange
_queue_currentTask
_queue_featureTrackingManager
_queue_featureTrackingObservers
_prioritySchedulingEnabled
_featureTrackingEnabled
_identifier
_maximumQueueSize
_thresholdPriority
_cache
_axMediaUtilsService
_taskDispatcher
initWithSource:context:
setSource:
setContext:
UUID
_context
_source
sortedFeatures
objectAtIndex:
compareInitialResult:withFinalResult:indexOfUnequalItem:sortInitialResult:sortFinalResult:
_updateDefaultLanguages
mainQueue
addObserverForName:object:queue:usingBlock:
autoupdatingCurrentLocale
initWithLocale:
preferredLanguages
length
initWithLanguageCode:
isSupertypeOfLanguage:
lowercaseString
uppercaseString
stringByAppendingFormat:
primaryComponent
secondaryComponent
localizedStringForLanguageCode:
isSubtypeOfLanguage:
locale
isEqualToAXMLanguage:
setPrimaryComponent:
setSecondaryComponent:
setLanguageCode:
setLocale:
initialize
currentSystemLanguage
currentLocaleLanguage
languageCodesForLanguages:
languageInSet:isSupertypeOfLanguage:
languageDisplayName
_primaryComponent
_secondaryComponent
_languageCode
_locale
characterSetWithCharactersInString:
letterCharacterSet
invertedSet
componentsSeparatedByCharactersInSet:
rangeOfCharacterFromSet:
initWithLocaleIdentifier:
whitespaceAndNewlineCharacterSet
addCharactersInString:
string
enumerateSubstringsInRange:options:usingBlock:
appendString:
_groupSeperatorCharacterSet
initWithSourceParameters:options:
setAnalysisOptions:
setAppliedImageOrientation:
appliedImageOrientation
extent
includeImageInResult
initWithCIImage:options:
_discardSourceImageIfPossible
nativeFormatPixelBufferRenderIfNeeded:
initWithCVPixelBuffer:options:
CGImage
errorOccurred:
pixelBuffer
imageColorSpace
render:toCVPixelBuffer:bounds:colorSpace:
numberWithLong:
resultWithImage:features:orientation:diagnostics:
resultWithFeatures:orientation:diagnostics:
setError:
imageWithCVPixelBuffer:
visionImageRequestHandlerWithOptions:
visionImageRequestHandlerIsLoaded
setCacheKey:
setShouldCallCompletionHandlersForEngineBusyError:
setShouldCallCompletionHandlersForEmptyResultSet:
sequenceID
setSequenceID:
setDiagnostics:
setFeatures:
setResult:
setVisionImageRequestHandler:
_sourceImage
_sourceParameters
_sourceProvidesOwnResults
_nativeFormatPixelBuffer
_resultHandlers
_extendedSRGBColorSpace
_cachedSize
_processingDiagnosticToken
_shouldProcessRemotely
_shouldCallCompletionHandlersForEngineBusyError
_shouldCallCompletionHandlersForEmptyResultSet
_evaluationExclusivelyUsesVisionFramework
_error
_analysisOptions
_appliedImageOrientation
_cacheKey
_sequenceID
_features
_result
_visionImageRequestHandler
freeResources
decodeFloatForKey:
setMinimumCharacterHeight:
setDetectDiacritics:
setReturnSubFeatures:
setMinimizeFalsePositives:
minimumCharacterHeight
encodeFloat:forKey:
detectDiacritics
returnSubFeatures
minimizeFalsePositives
textDetectionLanguage
supportedDetectionLanguages
writeOutOCRInputImages
initWithDimensions:
setMinimizeFalseDetections:
setRecognitionLanguage:
minimizeFalseDetections
recognitionLanguage
detectFeaturesInBuffer:withRegionOfInterest:error:
text
textDocumentWithFutharkFeatures:canvasSize:context:error:
containsString:
setReportCharacterBoxes:
setMinimumCharacterPixelHeight:
_visionTextDetectionOptionForLangauge:
setTextRecognition:
minimumCharacterPixelHeight
reportCharacterBoxes
textRecognition
textDocumentWithVisionObservations:canvasSize:context:error:
_evaluateWithFutharkFlavor:
_evaluateWithVisionFlavor:
detectionFlavor
setDetectionFlavor:
_textDetector
_textLayoutManager
_detectDiacritics
_returnSubFeatures
_minimizeFalsePositives
_detectionFlavor
_minimumCharacterHeight
setObject:forKeyedSubscript:
numberWithBool:
beginEditing
addAttribute:value:range:
endEditing
_evaluateIfNeeded
hasGlobalTag:
addGlobalTag:
removeGlobalTag:
_stringRange
attribute:atIndex:longestEffectiveRange:inRange:
speakableText
enumerateKeysAndObjectsUsingBlock:
enumerateAttributesInRange:options:usingBlock:
_isEvaluated
substringWithRange:
initWithFormat:
isSpeakable
_substringWithRange:
attributesAtIndex:effectiveRange:
_initWithAttributedString:
initWithString:attributes:
mutableString
replaceCharactersInRange:withString:
setAttributes:range:
textWithString:locale:evaluationBlock:
addTag:withToken:range:
setSpeakable:
isRangeSpeakable:
_setNeedEvaluation
initWithAttributedString:
_attrString
_globalAttributes
_evaluationBlock
UTF8String
_queue_processNextTask
_queue_count
_queue_dequeueTask
isComplete
setTaskCompleteBlock:
delegate
_queue_scheduleTask:
_queue_unscheduleAllTasks
removeObjectAtIndex:
isEmpty
unscheduleAllTasks
setDelegate:
_processQueueSource
_queue_taskList
_queue_taskIsBeingProcessed
_delegate
taskCompleteBlock
setComplete:
_complete
_taskCompleteBlock
setCameraPixelFocalLength:
setCameraOpticalOrigin:
setMinimumAspectRatio:
setMaximumAspectRatio:
setQuadratureTolerance:
setMinimumSize:
setMinimumConfidence:
setMaximumNumberOfRects:
decodeDoubleForKey:
axmDecodePointForKey:
cameraPixelFocalLength
encodeDouble:forKey:
cameraOpticalOrigin
axmEncodePoint:forKey:
minimumAspectRatio
maximumAspectRatio
quadratureTolerance
minimumSize
minimumConfidence
maximumNumberOfRects
dataWithBytes:length:
featureWithVisionRequest:rectangleResult:canvasSize:
_prepareRectangleRequestOptions
_cameraPixelFocalLength
_minimumAspectRatio
_maximumAspectRatio
_quadratureTolerance
_minimumSize
_maximumNumberOfRects
_cameraOpticalOrigin
_getHue:saturation:brightness:
_getRed:green:blue:
isEqualToAXMVisionColor:
unsignedCharValue
numberWithUnsignedChar:
saturationFloat
hueRadians
brightnessFloat
hueFloat
colorWithRed:green:blue:
colorWithHueDegrees:saturation:brightness:
euclidianDistanceHSV:
euclidianDistanceHS:
redFloat
greenFloat
blueFloat
_red
_green
_blue
_hue
_saturation
_brightness
setLocalizedName:
colorWithHueDegrees:saturation:brightness:localizedName:
allColorMarkers
localizedName
closestMarkerToColor:withMaximumThreshold:
_localizedName
setSynthesizer:
synthesizer
currentRequestCompletionBlock
speechUtteranceWithAttributedString:
setCurrentRequestCompletionBlock:
speakUtterance:
stopSpeakingAtBoundary:
attributedSpeechString
speechSynthesizer:didStartSpeechUtterance:
speechSynthesizer:didFinishSpeechUtterance:
speechSynthesizer:didPauseSpeechUtterance:
speechSynthesizer:didContinueSpeechUtterance:
speechSynthesizer:didCancelSpeechUtterance:
speechSynthesizer:willSpeakRangeOfSpeechString:utterance:
canHandleRequest:options:
handleRequest:options:completion:
stopSpeakingImmediately
stopSpeakingAtNextWord
_synthesizer
_currentRequestCompletionBlock
raise:format:
autoTriggerVideoFrameEventsWithAVCaptureSession:options:delegate:
endAutoTriggerOfVideoFrameEvents
captureSessionNodeDelegate
setCaptureSessionNodeDelegate:
_avkit_queue
_captureSessionNodeDelegate
initWithFeature:
normalizedFrame
type
currentLocation
featureType
value
faceId
trackerWithFeature:
update:
_backingFeature
_currentLocation
_debugType
range
isPhoneNumber
isDate
isEmailAddress
phoneNumber
initWithNLToken:text:type:lexicalClass:language:script:namedEntity:derivedSubtoken:speechFormatter:
initWithdatatype:text:textCheckingResult:speechFormatter:
originalText
isPunctuation
isWhitespace
isSentenceTerminator
_originalText
_speechFormatter
_nlToken
_nlType
_nlLexicalClass
_nlLanguage
_nlScript
_nlNamedEntity
_nlDerivedSubtoken
_datatype
_textCheckingResult
setNotificationObserverTokens:
notificationObserverTokens
removeObserver:
activateSessionWithError:
_notificationObserverTokens
setComponentState:
transitionToState:completion:
componentState
_componentState
setImage:
frame
compare:
sortedArrayUsingComparator:
detectionLanguage
isOCR
isTextDocument
subfeatures
isValueSpeakable
isFace
isClassification
isBlur
isBrightness
bundleWithIdentifier:
localizedStringForKey:value:table:
localizedStringWithFormat:
likelyExpression
allKeys
localizedStringFormatterForExpression:
blur
setDetectedTextDescription:
setDetectedFeatureDescription:
image
detectedTextLanguage
speakableDescription
colorInfoFeature
assetMetadataFeature
localizedDetectedTextHint
speakableDescriptionContainsDiscoveredText
_image
_detectedFeatureDescription
_detectedTextDescription
orderedSet
_cacheQueue_cacheSize
_cacheQueue_resultForKey:
_cacheQueue_setResult:forKey:
resultForKey:
purgeCache
_cacheQueue
_cacheQueue_maxItems
_cacheQueue_orderedKeys
_cacheQueue_results
targetPlayerItem
_mainQueue_endAutoTriggerOfLegibilityEvents
setDelegate:queue:
addOutput:
setTargetPlayerItem:
outputs
removeOutput:
featureWithMediaLegibility:
outputSequenceWasFlushed:
legibleOutput:didOutputAttributedStrings:nativeSampleBuffers:forItemTime:
autoTriggerLegibilityEventsWithAVPlayerItem:
endAutoTriggerOfLegibilityEvents
isTriggeringLegibilityEvents
_triggeringLegibilityEvents
_targetPlayerItem
unsignedIntegerValue
_enumerateText:textCheckingType:datatype:withBlock:
emailAddressRegex
_enumerateText:regularExpression:datatype:withBlock:
speechFormatterForDatatype:
enumerateMatchesInString:options:range:usingBlock:
dataDetectorWithTypes:error:
regularExpressionWithPattern:options:error:
initWithSpeechFormatterCache:
enumerateText:searchingFordatatypes:withBlock:
_emailAddressRegex
_speechFormatterCache
dictionaryWithDictionary:
setValue:forKey:
currentDevice
userInterfaceIdiom
initWithOptions:
sharedFaceDetector
detectFacesInCGImage:options:error:
extractDetailsForFaces:inCGImage:options:error:
scale
convertFCRFacesArrayToFaceWrappersArray:sourceImageSize:activeCameraReturnsMirroredImage:scale:
face
faceSize
sharedApplication
interfaceOrientation
expressionFeatures
photoFaceWrappers:
photoDescription:withFaceCount:
width
height
left
right
bottom
_metricTypeForMetric:
_floatValueForMetric:
_rectValueForMetric:
boundingFrameForItems:
normalizedBoundingFrameForItems:
metric:inProximityOfMetric:item:threshold:
sequence:
feature
_feature
arrayWithObject:
line:
addSequence:
sequences
_sequences
region:
addLine:
firstLine
lines
_lines
featureWithFutharkFeature:canvasSize:context:
featureWithVisionRequest:textResult:canvasSize:context:
_axmVisionFeatureForFeature:canvasSize:context:
_assembleLayoutSequences:canvasSize:context:
_assembleLayoutLines:
_assembleLayoutRegions:
textLineWithBoundingBox:sequences:canvasSize:context:
textRegionWithBoundingBox:lines:canvasSize:context:
textDocumentWithBoundingBox:regions:canvasSize:context:
_textDocumentWithFeatures:canvasSize:context:error:
value:withObjCType:
getValue:
axmEncodeSize:forKey:
axmDecodeSizeForKey:
axmEncodeRect:forKey:
axmDecodeRectForKey:
assetMetadataFromURL:
featureWithAssetMetadata:
triggerWithAssetURL:cacheKey:resultHandler:
observer
callback
initWithSuiteName:
registerDefaults:
addObserver:forKeyPath:options:context:
observeValueForKeyPath:ofObject:change:context:
_queue_removeObserver:forSetting:
removeObjectsInArray:
boolForKey:
setBool:forKey:
addObserver:forSeetting:withBlock:
removeObserver:forSetting:
removeObserverForAllSettings:
setWriteOutInputImages:
setWriteOutOCRInputImages:
writeOutScreenCaptures
setWriteOutScreenCaptures:
_defaults
_queue_settingObservers
initForReadingFromData:error:
setWithObjects:
setByAddingObjectsFromSet:
decodeTopLevelObjectOfClasses:forKey:error:
axmSecurelyUnarchiveData:withExpectedClass:otherAllowedClasses:error:
isTrackable
_queue_trackerContainerForFeature:
initWithFeature:queue:
tracker
activeTimer
afterDelay:processBlock:cancelBlock:
queue_trackedFaces
processResult:
trackedFeatures
maximumSizeThreshold
setMaximumSizeThreshold:
maximumDistanceThreshold
setMaximumDistanceThreshold:
_queue_trackedFeatureContainers
_maximumSizeThreshold
_maximumDistanceThreshold
initWithTargetSerialQueue:
setAutomaticallyCancelPendingBlockUponSchedulingNewBlock:
setTracker:
setActiveTimer:
_tracker
_activeTimer
setAssetURL:
setCreationDate:
setUti:
setLocalizedTypeDescription:
setTIFFImageDescription:
setIPTCCaptionAbstract:
setEXIFUserComment:
setPNGImageDescription:
assetURL
creationDate
localizedTypeDescription
TIFFImageDescription
IPTCCaptionAbstract
EXIFUserComment
PNGImageDescription
resourceValuesForKeys:error:
_creationDate
_uti
_localizedTypeDescription
_TIFFImageDescription
_IPTCCaptionAbstract
_EXIFUserComment
_PNGImageDescription
_assetURL
_initWithBackingType:
isMainDisplay
_updateDisplay:withConfiguration:
initWithInitializationCompletion:
setDisplayMonitor:
displayMonitor
addObserver:
isMainThread
mainDisplay
_updateDisplay:withCADisplay:
initWithCompletion:
frontBoardMainDisplay
coreAnimationMainDisplay
_displayPropertiesFromMobileGestalt
currentMode
preferredScale
setScale:
mobileGestaltOrientation
setOrientation:
orientation
_discreteOrientationForOrientation:
setPhysicalOrientation:
setReferenceBounds:
pixelSize
setSupportsDeepColor:
_updateDisplayPropertiesWithConfiguration:
displayMonitor:didConnectIdentity:withConfiguration:
displayMonitor:didUpdateIdentity:withConfiguration:
displayMonitor:willDisconnectIdentity:
initAndWaitForMainDisplayConfiguration
isInitialized
setMobileGestaltOrientation:
_queue_CoreAnimationMainDisplay
_queue_FrontBoardMainDisplay
_initialized
_displayMonitor
_mobileGestaltOrientation
referenceBounds
supportsDeepColor
convertPointToDisplay:
convertRectToDisplay:
physicalOrientation
backingType
setBackingType:
_supportsDeepColor
_scale
_orientation
_physicalOrientation
_backingType
_referenceBounds
_imageOrientationForInterfaceOrientation:displayOrientation:
imageByApplyingOrientation:
_imageOrientationForInterfaceOrientation:isMirrored:
saveToURL:withOrientation:diagnostics:
createDirectoryAtURL:withIntermediateDirectories:attributes:error:
setDateFormat:
date
stringFromDate:
rotatedImageWithInterfaceOrientation:displayOrientation:appliedImageOrientation:
rotatedImageWithInterfaceOrientation:isMirrored:appliedImageOrientation:
writeImageInAllOrientationsToDirectoryAtURL:diagnostics:
_initWithLanguage:diagnostics:
operationWithLanguage:diagnostics:
operationWithSystemLanguage:
lexiconLocale
language
_language
lexiconManager
tagger
dataDetector
numberWithUnsignedInteger:
enumerateText:locale:block:
_preprocessText:diagnostics:
punctuationCharacterSet
formUnionWithCharacterSet:
removeCharactersInString:
stringByTrimmingCharactersInSet:
symbolCharacterSet
componentsJoinedByString:
spellChecker
processText:withOperation:
_spellChecker
_lexiconManager
_tagger
_dataDetector
_globalWhitelistedWords
_localeWhitelistedWords
intValue
mainScreen
assetWithURL:
commonMetadata
metadataItemsFromArray:withKey:keySpace:
exportSessionWithAsset:presetName:
supportedFileTypes
setOutputFileType:
absoluteString
stringByAppendingString:
URLWithString:
setOutputURL:
metadata
metadataItem
setKeySpace:
setKey:
setValue:
setMetadata:
status
exportAsynchronouslyWithCompletionHandler:
moveItemAtURL:toURL:error:
removeItemAtURL:error:
dateFromString:
currentCalendar
components:fromDate:
year
month
dictionaryWithObjectsAndKeys:
indexOfObject:
stringByAppendingPathComponent:
bundleWithPath:
load
evaluateImage:forCriteria:inRect:
blurResult
luminanceResult
humanReadableResult
pathExtension
hasPrefix:
lastPathComponent
stringByDeletingPathExtension
rangeOfString:
substringFromIndex:
setClasses:forSelector:argumentIndex:ofReply:
mainBundle
bundleIdentifier
axmValueWithCGAffineTransform:
filterWithName:withInputParameters:
outputImage
writeJPEGRepresentationOfImage:toURL:colorSpace:options:error:
featureWithVisionRequest:humanResult:canvasSize:
setPriority:
priority
defaultPriority
stringWithString:
_diagnosticNameForRequests:diagnostics:
setEffectivePriority:
_minimumConfidence
_priority
_effectivePriority
componentsSeparatedByString:
setIs3DLandmarks:
setResults:
is3DLandmarks
leftEye
pointsArrayForRegion:
rightEye
leftEyebrow
rightEyebrow
nose
noseCrest
medianLine
outerLips
innerLips
leftPupil
rightPupil
pointCount
points
axmValueWithCGPoint:
unitTestingFaceLandmarksIs3D:
initWithVisionFaceLandmarks:
pointValuesForFaceLandmarkType:
localizedStringForLandmarkType:
_is3DLandmarks
_results
setClientID:
setIncludeImageInResult:
setDetectText:
setDetectScenes:
setDetectModelClassifications:
setDetectTraits:
setDetectFaces:
setDetectHumans:
setDetectHorizon:
setDetectRectangles:
setCorrectSpelling:
setTextDetectionLanguage:
setSpellCheckingLanguages:
setIgnoredLayerContextIDs:
clientID
correctSpelling
spellCheckingLanguages
voiceOverOptions
_detectText
_detectFaces
_detectScenes
_detectModelClassifications
_detectTraits
_detectRectangles
_detectHumans
_detectHorizon
_correctSpelling
_includeImageInResult
_clientID
_textDetectionLanguage
_spellCheckingLanguages
_ignoredLayerContextIDs
setRequest:
setOptions:
dispatchRequest:options:
request
options
enableWithCompletion:
speak:
interrupt:
interruptImmediately
interruptPolitely
playSound:
_outputRequests
_audioSession
_queue_soundComponent
_queue_speechComponent
_queue_activeComponents
_request
_options
setWithObject:
allObjects
spellServer:findMisspelledWordInString:languages:wordCount:countOnly:correction:
correctSpellingInText:withLanguages:
textContainsMisspelling:withLanguages:
setSpellChecker:
nodeQueue
_nodeQueue_addResultHandler:
_nodeQueue_removeResultHandler:
_nodeQueue_removeAllResultHandlers
_nodeQueue_resultHandlers
corners
boundingBox
confidence
landmarks
landmarks3d
expressionsAndConfidence
pose
transform
angle
timeIntervalSinceReferenceDate
getBytes:length:
_serializeWithCoder:orDictionary:
nameForFeatureType:
_nameForOCRFeatureType:
faceExpressionsAndConfidence
_valueForTextFeature
isTextRegion
isTextLine
isTextSequence
isTextCharacter
isTextDiacritic
_isTextFeatureValueSpeakable
_append:toList:
faceLandmarks
faceLandmarks3d
stringForExpression:
confidenceForExpression:
barcodeType
ocrFeatureType
assetMetadata
horizonAngle
isEqualToAXMVisionFeature:
expressionForString:
featureWithMetadata:canvasSize:
featureWithVisionRequest:brightnessValue:canvasSize:
featureWithVisionRequest:classificationResult:canvasSize:
nameForOCRType:
nameForFaceExpression:
flattenedFeatureList:
dictionaryRepresentation
colorInfo
facePose
horizonTransform
isBarcode
isHuman
isModelClassification
isColor
isHorizon
isMediaLegibility
isAssetMetadata
isRectangle
_featureType
_subfeatures
_barcodeType
_ocrFeatureType
_detectionLanguage
_frame
_normalizedFrame
_value
_isValueSpeakable
_taggedText
_colorInfo
_assetMetadata
_blur
_confidence
_horizonTransform
_horizonAngle
_faceLandmarks
_faceLandmarks3d
_faceExpressionsAndConfidence
_likelyExpression
_faceId
_facePose
_canvasSize
unitTestingFeatureWithType:canvasSize:frame:value:barcodeType:ocrFeatureType:subFeatures:
unitTestingFeature
unitTestingFaceFeature
unitTestingHorizonFeature
taggedText
physicalMemory
knownSceneClassifications
possibleSceneClassifications
setSoundPlayer:
setConfigChangedObserverToken:
_buildEngine
_wireEngineConnections
_startEngineIfNeeded:
configChangedObserverToken
initForReading:error:
soundPlayer
scheduleFile:atTime:completionHandler:
play
setEngine:
engine
attachNode:
mainMixerNode
initStandardFormatWithSampleRate:channels:
nextAvailableInputBus
connect:to:fromBus:toBus:format:
isRunning
startAndReturnError:
_logAudioFileInfo:
_engine
_soundPlayer
_configChangedObserverToken
setConnected:
setEnabled:
setNodeQueue:
_connected
_enabled
_nodeQueue
systemReport
privilegedSystemReport
imageWithContentsOfURL:
triggerWithImage:options:cacheKey:resultHandler:
triggerWithImageURL:options:cacheKey:resultHandler:
triggerWithImage:cacheKey:options:resultHandler:
triggerWithImage:cacheKey:options:clientID:resultHandler:
setCaptureNode:
setImageNode:
setTextDetector:
setSceneDetector:
setFaceDetector:
setTraitDetector:
setVisionRecognitionOptions:
captureNode
imageNode
textDetector
sceneDetector
faceDetector
traitDetector
_captureNode
_imageNode
_sceneDetector
_faceDetector
_traitDetector
fileExistsAtPath:isDirectory:
createDirectoryAtPath:withIntermediateDirectories:attributes:error:
axmAppendIndentation:
initWithFormat:arguments:
errorWithDomain:code:userInfo:
allocWithZone:
dateFormatFromTemplate:options:locale:
stringFromNumber:
AXMPointValue
AXMVectorValue
AXMSizeValue
AXMAffineTransformValue
axmValueWithCGVector:
axmValueWithCGSize:
checking token against lexicon
Using locale for lexicon: %@ (language: %@) (id: %@)
Creating new lexicon for locale (an expensive operation): %@ (language: %@) (id: %@)
Unable to create lexicon: %@
No lexicon found for locale: %@
Could not evaluate. VNDetectHorizonRequestSoft was nil
Could not evaluate. requestHandler was nil
Could not evaluate: %@
input arrays must be same length
Could not evaluate. VNDetectFaceExpressionsRequestSoft was nil
Could not evaluate. VNClassifyFaceAttributesRequestSoft was nil
AXMService being deallocated: %@
Connection to service interrupted. client: %@
Connection to service invalidated. client: %@
Failed to get service proxy: %@
Calling elapsedTime before metric is in finished state is invalid
Could not look up MACH_TASK_BASIC_INFO. err:%@ (%s)
Could not look up TASK_VM_INFO. err:%@ (%s)
Metric must be in 'initialized' state whem calling start
Starting task '%@' PhysFtPrnt '%@' ResMem '%@' ResMemPk '%@'
Metric must be in 'measuring' state whem calling finish
Finished task '%@' Elapsed time '%@' PhysFtPrnt:['%@', +/- '%@'] ResMem:['%@', +/- '%@'] ResMemPk:['%@', +/- '%@']
Could not make soundAction url does not exist: %@
Could not produce URL for soundID: %@
Model Detector not available on this platform
Could not evaluate. VNImageScoreObservationSoft was nil
Could not evaluate. VNImageBrightnessObservationSoft was nil
Could not evaluate. VNImageBlurObservationSoft was nil
Error evaluating color information: %@
engine threshold priorty: %ld
   node <%p> :'%@'. boosted priorty:%ld
highest priority node: %@
Did not produce result features. Result was nil
Did not produce result features. Features was nil
Did not produce result features. Feature list was empty
Did produce result with %lu features:
  %@
Resulting speakable description. [features:'%@'] [text:'%@']
------------------------------------------------------
With priority scheduling, there can be at most 1 evaluation node per cycle
'writeOutInputImages' is enabled. Writing input images to %@
CreateImage
EvaluateNode
Cannot add source node. %@
Cannot add a node that is already connected
Cannot add evaluation node. %@
A context must be provided
A source must be provided
pipeline context error. CVPixelBufferCreate returned NULL buffer for ocr pixel buffer. CVReturn: %@
RenderPixelBuffer
Will detect text with Futhark flavor
Could not evaluate with OCR. Input pixel buffer was nil
Could not evaluate with OCR. FKTextDetectorSoft unexpectedly NULL
'writeOutOCRInputImages' is enabled. Writing OCR input images to %@
Will detect text with parameters: [minCharHeight:%d] [minimizeFalseDetections:%d] [returnSubfeatures:%d] [detectDiacritics:%d] [language:%@]
Could not OCR image. OCR detection error: %@
Did detect futhark features:
Did not detect any text features
Could not create text document: %@
Could not evaluate. VNDetectTextRectanglesRequestSoft was nil
Will detect text with Vision (Version 1) flavor
Will detect text with parameters: [minCharHeight:%lu] [minimizeFalseDetections:%d] [returnSubfeatures:%d] [detectDiacritics:%d] [language:%@]
Did detect VNTextObservations
  %@ text:'%@'
Did not detect any VNTextObservations
task should not be in the completed state
taskIsBeingProcessed should be YES
taskIsBeingProcessed should be NO
Task should not be complete if being marked as complete
Could not evaluate. VNDetectRectanglesRequestSoft was nil
handleRequest: expected nil completion block
speech started: '%@'
speech finished: '%@'
didFinish: expected completion block, but found nil.
speech canceled: '%@'
didCancel: expected completion block, but found nil.
speech paused: '%@'
speech resumed: '%@'
There should be 0 or 1 OCR features
Top level text object should be the document
Result found for key: %p. moving to newest position
set nil result. removing key: %p. %ld items remain
set new result. adding key: %p. %ld items remain
cache size too big. evicted key: %p. %ld items remain
purge cache of all keys
Will begin processing legibility events with player item: %@
Asked to auto-trigger events with item: '%@', but same targetPalyerItem was already set!
Asked to auto-trigger events with item: '%@', but targetPalyerItem already exists: '%@'. Unregistering current targetPalyerItem first. 
Will stop processing legibility events for player item: %@
legibility event: %@
Metric types are not compatible '%ld' and '%ld'
metric does not support float values: '%ld'
metric does not support frame values: '%ld'
Will assemble lines...
  Next sequence: %@
   Compare w/ line %@
   threshold (%.0f%% of lineItem.height): %.2f
   sequence and line differ. height:%ld top:%ld
  Adding sqeuence to line
  Creating new line with sequence
Will assemble regions...
  Next line: %@
   Compare w/ region %@
   threshold (%.0f%% of regionItem.firstLine.height): %.2f
   line and region differ. height:%ld left:%ld
  Adding line to region
  Creating new region with line
Did get KVO update for key: '%@'. change: %@
begin tracking: %@
update tracking: %@
finish tracking: %@
tracker and feature differ in size more than limit: (%.2f). skip
tracker and feature distance too far: (%.2f). skip
AXMDisplayManager initialized: %@
Unable to look up screenInfo
Unable to look up screen scale
Unexpected physical screen orientation
connected new display. Updating AXMDisplay properties
display config changed. Updating AXMDisplay properties
disconnected new display
Orientation unexpected: AXMPhysicalDisplayOrientationPortraitUpsideDown. If you see this assert, please file a bug with PEP Accessibility and your device type. 
unknown interface orienation
unhandled display orientation. AXMPhysicalDisplayOrientationUnknown / default
Unknown interface orientation. assuming portrait
Will process text: '%s'. language: %@
Result text: '%s'
Will pre-process text: '%s'
AX: Export Session status: %ld %@
AX: EXPORT: 1 Error: %@
AX: EXPORT: 2 Error: %@
AX: EXPORT: 3 Error: %@
unknown file type: %@, UTI: %@, extension: %@
Could not evaluate. VNDetectHumanRectanglesRequestSoft was nil
Input text: '%@'
Input locale: '%@'
Token '%@' [%lu, %lu]
  Type: %@
  Lex Class: %@
  Language: %@
  Script: %@
  Named Entity: %@
  DerivedSubtoken: %@
Error decoding face landmark dict: %@
Failed to archive face landmark results: %@
Could not activate audio session: %@
Ignoring dispatch request. Output manager not ready
Using languages for spell checking: %s
spell-checking pass %ld of %ld
length of textToCheck is 0. break
Will look for misspelled word in text: '%s'. index: %ld
No misspelled words found. break
Misspelled word found at range [%ld, %ld], '%s'
replacing with correction: '%s' at range:[%ld %ld]
text after replacement: '%s'
No correction found
Source node not connected to any engine
Error decoding face expression dict: %@
Error decoding subfeatures array: %@
Failed to archive subfeature data: %@
Error: %@
_valueForTextFeature is only valid for OCR features
subfeatures of a document should be regions
subfeatures of a region should be lines
subfeatures of a line should be sequences
textCharacter is not implemented
textDiacritic is not implemented
_isTextFeatureValueSpeakable is only valid for OCR features
This process does not have the '%@' entitlement, and will not be able to connect to the photo analysis service. Scene classification will be limited
Could not evaluate. VNSceneClassificationRequestSoft was nil
Could not handle audio request: %@. Error:%@
SoundPlayer did finish playing sound
Could not start engine: %@
Subclass should override
Failed to create AXMediaUtilities working directory at path: %@. error: %@
v24@?0^{_LXEntry=}8*16
Create Lexicon %@
@8@?0
Screen grab not supported on Simulator yet
imageWidth
Ti,N,V_imageWidth
imageHeight
Ti,N,V_imageHeight
size
Ti,N,V_size
bounds
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_bounds
screenOrientation
Tq,N,V_screenOrientation
imageMirrored
TB,N,V_imageMirrored
smiling
TB,N,V_smiling
blinking
TB,N,V_blinking
Horizon Detector
VNDetectHorizonRequest
v8@?0
/System/Library/Frameworks/Vision.framework/Vision
mainColors
mainColorWeights
supportsSecureCoding
TB,R
T@"NSArray",&,N,V_mainColors
T@"NSArray",&,N,V_mainColorWeights
remainingColorWeight
Td,N,V_remainingColorWeight
Face Detector
VNDetectFaceExpressionsRequest
AXMServiceConnection
hash
TQ,R
superclass
T#,R
description
T@"NSString",R,C
debugDescription
v16@?0@"NSError"8
xpcConnection
T@"NSXPCConnection",&,N,V_xpcConnection
state
name
metrics
startTime
endTime
startTaskInfoValue
startVMInfoValue
endTaskInfoValue
endVMInfoValue
{mach_task_basic_info=QQQ{time_value=ii}{time_value=ii}ii}
{task_vm_info=QiiQQQQQQQQQQQQQQQQQQQ}
%.2fMB
%.3fs
T@"NSString",&,N,V_name
representedMetrics
Tq,N,V_representedMetrics
isElapsedTimeMetric
TB,R,N
isMemoryFootprintMetric
initialResidentMemory
T@"NSNumber",R,N
initialResidentMemoryPeak
initialPhysicalFootprint
finalResidentMemory
finalResidentMemoryPeak
finalPhysicalFootprint
residentMemoryDelta
residentMemoryPeakDelta
physicalFootprintDelta
initialTime
finalTime
elapsedTime
AXMDiagnostics
diagnosticsEnabled
AXM_DIAGNOSTICS_ENABLED
TB,N,V_diagnosticsEnabled
T@"NSArray",R,C,N
ItemAppeared
aiff
sounds
ItemDisappeared
speechSequence
T@"NSAttributedString",R,N
interruptsAndClearsQueue
TB,N,V_interruptsAndClearsQueue
soundFileURLs
T@"NSArray",R,N
AXMSpeechFormatter does not implement getObjectValue:forString:errorDescription:
formattingBlock
T@?,C,N,V_formattingBlock
modelURL
Model Detector
Model loading not supported on this platform
T@"NSURL",&,N,V_modelURL
region
orientation
Screen Capture
@"CIImage"24@?0@"NSDictionary"8^@16
screenGrabber
T@"AXMScreenGrabber",&,N,V_screenGrabber
Traits
v40@?0{vImage_Buffer=^vQQQ}8
sampleFrequency
Tq,N,V_sampleFrequency
shouldEvaluateColorInformation
TB,N,V_shouldEvaluateColorInformation
colorDistanceTheshold
Td,N,V_colorDistanceTheshold
VNImageScoreObservation
VNImageBrightnessObservation
VNImageBlurObservation
VNImageBlurScoreRequest
Identifier
QueueSize
SourceNodes
EvaluationNodes
VisionEngineConfigurationDidChange
AXMVisionEngine
prioritySchedulingEnabled
thresholdPriority
featureTrackingEnabled
v24@?0@"AXMVisionResult"8@"NSError"16
Create Image
InputImage
@"NSError"8@?0
Evaluate %@
Node
%@-%ld
%@<%p>: ID:'%@' [PriorSched:%@ threshhold:%lu] maxQueueSize:%ld cacheSize:%ld tracking:%@ diagnostics:%@
%@%@
%@Source Nodes:
%@Evaluation Nodes:
Engine queue is at capacity
identifier
T@"NSString",C,V_identifier
axMediaUtilsService
T@"AXMService",&,N,V_axMediaUtilsService
cache
T@"AXMVisionEngineCache",&,N,V_cache
taskDispatcher
T@"AXMTaskDispatcher",&,N,V_taskDispatcher
sourceNodes
evaluationNodes
maximumQueueSize
Tq,V_maximumQueueSize
TB,V_prioritySchedulingEnabled
TQ,V_thresholdPriority
isCachingEnabled
cacheSize
Tq,R,N
TB,N,GisFeatureTrackingEnabled,V_featureTrackingEnabled
trackedFaces
trackedText
trackedRectangles
trackedModelClassifiers
TB,N,GareDiagnosticsEnabled,V_diagnosticsEnabled
T@"NSUUID",&,N,V_identifier
context
T@"AXMVisionPipelineContext",&,N,V_context
source
T@"AXMSourceNode",&,N,V_source
VNRequestHandlerCleanupOption_AllPipelines
VNCleanupLevel_Complete
VNRequestHandlerCleanupOption_ImageBuffers
VNCleanupPurgeAll
VNImageRequestHandler
AXMLanguage
v16@?0@"NSNotification"8
AXMLanguage<%p> languageID: '%@'. Locale: <%p> '%@'
primaryComponent
secondaryComponent
languageCode
locale
T@"NSString",&,N,V_primaryComponent
T@"NSString",&,N,V_secondaryComponent
T@"NSString",&,N,V_languageCode
T@"NSLocale",&,N,V_locale
languageDisplayName
T@"NSString",R,N
v56@?0@"NSString"8{_NSRange=QQ}16{_NSRange=QQ}32^B48
inputImage
appliedOrientation
sourceProvidesResults
sourceparams
features
analysisOptions
error
AXMVisionPipelineContext<%p>: seqID:%lu source params: %@. error: %@
appliedImageOrientation
sequenceID
Create VNImageRequestHandler
A creation node must return a valid image
RenderPixelBuffer
ReleaseSourceImage
error initializing vImageBuffer from CVPixelBuffer: %@
error initializing vImageBuffer from CGImageRef: %@
No inputImage or pixelBuffer found to initialize vImage_Buffer
%@-%ld-%ldx%ld.%@
Processing Context
T@"NSMutableArray",&,N,V_features
T@"NSError",&,N,V_error
T@"AXMVisionAnalysisOptions",&,N,V_analysisOptions
result
T@"AXMVisionResult",&,N,V_result
T@"NSNumber",&,N,V_appliedImageOrientation
diagnostics
T@"AXMDiagnostics",&,N,V_diagnostics
visionImageRequestHandler
T@"VNImageRequestHandler",&,N,V_visionImageRequestHandler
shouldProcessRemotely
TB,N,V_shouldProcessRemotely
resultHandlers
T{CGSize=dd},R,N
visionImageRequestHandlerIsLoaded
cacheKey
T@"<NSCopying>",&,N,V_cacheKey
shouldCallCompletionHandlersForEngineBusyError
TB,N,V_shouldCallCompletionHandlersForEngineBusyError
shouldCallCompletionHandlersForEmptyResultSet
TB,N,V_shouldCallCompletionHandlersForEmptyResultSet
evaluationExclusivelyUsesVisionFramework
TB,N,V_evaluationExclusivelyUsesVisionFramework
TQ,N,V_sequenceID
AXMMinimumCharacterHeight
AXMDetectDiacritics
AXMReturnSubFeatures
AXMMinimizeFalsePositives
detectionFlavor
Text Detector
OCRInput
[FKTextDetector detectFeaturesInBuffer]
supportedDetectionLanguages
T@"NSSet",R,N
TQ,N,V_detectionFlavor
minimumCharacterHeight
Td,N,V_minimumCharacterHeight
detectDiacritics
TB,N,V_detectDiacritics
returnSubFeatures
TB,N,V_returnSubFeatures
minimizeFalsePositives
TB,N,V_minimizeFalsePositives
FKTextDetector
/System/Library/PrivateFrameworks/Futhark.framework/Futhark
VNTextRecognitionOptionEnglishCharacterSet
VNTextRecognitionOptionIcelandicCharacterSet
VNTextRecognitionOptionNorwegianCharacterSet
VNTextRecognitionOptionSwedishCharacterSet
VNTextRecognitionOptionDanishCharacterSet
VNTextRecognitionOptionGermanCharacterSet
VNTextRecognitionOptionDutchCharacterSet
VNTextRecognitionOptionFrenchCharacterSet
VNTextRecognitionOptionItalianCharacterSet
VNTextRecognitionOptionSpanishCharacterSet
VNTextRecognitionOptionPortugueseCharacterSet
VNDetectTextRectanglesRequest
AXMGlobalTagLocale
AXMGlobalTagIsSpeakable
AXMGlobalTagIsEvaluated
IsSpeakable
IsNonspeakable
v32@?0@"NSString"8@16^B24
v40@?0@"NSDictionary"8{_NSRange=QQ}16^B32
AXMTaggedText<%p> : '%@'
 Locale: %@
 Is evaluated? %@
 Is speakable? %@
 Speakable Text: '%@'
 Global Attributes:
  %@ : %@
 Tokens:
  '%@' [%ld %ld] : %@
T@"NSLocale",R,N
speakable
TB,N,GisSpeakable
speakableText
v20@?0@"AXMTask"8B16
count
isEmpty
delegate
T@"<AXMTaskDispatcherDelegate>",W,N,V_delegate
complete
TB,N,GisComplete,V_complete
taskCompleteBlock
T@?,C,N,V_taskCompleteBlock
cameraPixelFocalLength
cameraOpticalOrigin
minimumAspectRatio
maximumAspectRatio
quadratureTolerance
minimumSize
minimumConfidence
maximumNumber
Rectangle Detector
Td,N,V_cameraPixelFocalLength
T{CGPoint=dd},N,V_cameraOpticalOrigin
Td,N,V_minimumAspectRatio
Td,N,V_maximumAspectRatio
Td,N,V_quadratureTolerance
Td,N,V_minimumSize
maximumNumberOfRects
Tq,N,V_maximumNumberOfRects
VNRequestOptionRectangleMinimumAspectRatio
VNRequestOptionRectangleMaximumAspectRatio
VNRequestOptionRectangleQuadratureTolerance
VNRequestOptionRectangleMinimumSize
VNRequestOptionRectangleMinimumConfidence
VNRequestOptionRectangleMaximumNumber
VNDetectRectanglesRequest
VNImageOptionCameraIntrinsics
green
blue
saturation
brightness
%@<%p> [r:%u g:%u b:%u] [h:%u s:%u b:%u]
redFloat
Td,R,N
greenFloat
blueFloat
hueFloat
saturationFloat
brightnessFloat
Black
Gray
Silver
White
Salmon
Rose
Brown
Coral
Orange
Chestnut
Gold
Olive
Ivory
Beige
Yellow
Lime Green
Light Green
Sea Foam Green
Forest Green
Green
Turquoise
Teal
Cyan
Aqua
Sky Blue
Royal Blue
Navy Blue
Indigo
Lavender
Purple
Fuchsia
Dark Purple
Light Pink
Violet
Pink
Maroon
Crimson
%@ name:%@
allColorMarkers
localizedName
T@"NSString",&,N,V_localizedName
synthesizer
T@"AVSpeechSynthesizer",&,N,V_synthesizer
currentRequestCompletionBlock
T@?,C,N,V_currentRequestCompletionBlock
Capture Session
AXMAVCaptureSessionNode does not support remote triggering
AXMAVCaptureSessionNode-avkit-queue
captureSessionNodeDelegate
T@"<AXMAVCaptureSessionNodeDelegate>",W,N,V_captureSessionNodeDelegate
AXMFeatureTracker<%p>: type:%ld loc:%@
type
TQ,R,N
currentLocation
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,V_currentLocation
value
faceId
AXMTag<%p>. [%@] [%lu %lu] '%@'
%@|%@|%@
Detected|Detector|PhoneNumber
Detected|Detector|Date
Detected|Regex|Email
Unknown
range
T{_NSRange=QQ},R,N
originalText
isPunctuation
isWhitespace
isSentenceTerminator
isPhoneNumber
isDate
isEmailAddress
notificationObserverTokens
T@"NSMutableArray",&,N,V_notificationObserverTokens
Ready
Unitialized
Initialize Failure
%@<%p>: state:'%@'
isSupported
componentState
Tq,N,V_componentState
AXMFeatures
AXMImage
q24@?0@"AXMVisionFeature"8@"AXMVisionFeature"16
photo.description.expression.smile
photo.description.expression.scream
photo.description.expression.disgust
photo.description.expression.surprise
photo.description.expression.suspicious
__AXMStringForVariablesSentinel
com.apple.accessibility.AXMediaUtilities
photo.description.faces
Accessibility
photo.description.blurriness.level.1
photo.description.blurriness.level.2
photo.description.blurriness.level.3
photo.description.blurriness.level.4
photo.description.blurriness.level.5
photo.description.blurriness.level.6
photo.description.brightness.level.1
photo.description.brightness.level.2
photo.description.brightness.level.3
photo.description.brightness.level.4
photo.description.brightness.level.5
detected.text.hint
detectedTextDescription
detectedFeatureDescription
detectedTextLanguage
AXMVisionResult<%p>: Image:%@ Results:%@ Speakable Description: %@
image
T@"CIImage",&,N,V_image
T@"NSArray",&,N,V_features
T@"NSString",&,N,V_detectedFeatureDescription
T@"NSString",&,N,V_detectedTextDescription
colorInfoFeature
T@"AXMVisionFeature",R,N
assetMetadataFeature
localizedDetectedTextHint
T@"AXMLanguage",R,N
cacheQueue
AXMVisionEngineCache<%p>: %ld items
AXMVisionEngineCache<%p>: %ld items
  Key:%@
  Result:%@
v32@?0@"<NSCopying>"8@"AXMVisionResult"16^B24
AVPlayerItem
AXMAVPlayerItemNode does not support remote triggering
AXMAVPlayerItemNode-avkit-queue
%@ playerItem:<%@>
targetPlayerItem
T@"AVPlayerItem",W,N,V_targetPlayerItem
triggeringLegibilityEvents
TB,R,N,GisTriggeringLegibilityEvents,V_triggeringLegibilityEvents
v32@?0@"NSTextCheckingResult"8Q16^B24
[a-z0-9!#$%&'*+/=?^_`{|}~-]+(?:\.[a-z0-9!#$%&'*+/=?^_`{|}~-]+)*@(?:[a-z0-9](?:[a-z0-9-]*[a-z0-9])?\.)+[a-z0-9](?:[a-z0-9-]*[a-z0-9])?
post
face.count
UIDevice
Unable to find class %s
/System/Library/Frameworks/UIKit.framework/UIKit
UIApplication
%@ [W:%.2f H:%.2f] [L:%.2f T:%.2f R:%.2f B:%.2f]
frame
T{CGRect={CGPoint=dd}{CGSize=dd}},R,D,N
height
bottom
width
left
right
normalizedFrame
no source features provided
FKTextFeature
VNTextObservation
/System/Library/PrivateFrameworks/Vision.framework/Vision
{CGSize=dd}
{CGPoint=dd}
{CGRect={CGPoint=dd}{CGSize=dd}}
Asset Metadata
AXMSetting
writeOutInputImages
TB,D,N
writeOutOCRInputImages
writeOutScreenCaptures
'data' was not of required type NSData
'unarchivedResult' was not of type 'expectedClass'
T@"<AXMFeatureTrackingManagerDelegate>",W,N,V_delegate
maximumSizeThreshold
Td,N,V_maximumSizeThreshold
maximumDistanceThreshold
Td,N,V_maximumDistanceThreshold
tracker
T@"AXMFeatureTracker",&,N,V_tracker
activeTimer
T@"AXDispatchTimer",&,N,V_activeTimer
assetURL
creationDate
localizedTypeDesc
TIFFImageDescription
IPTCCaptionAbstract
EXIFUserComment
PNGImageDescription
name:%@ created:%@ UTI:%@ typeDesc:%@
T@"NSURL",&,N,V_assetURL
T@"NSDate",&,N,V_creationDate
T@"NSString",&,N,V_uti
localizedTypeDescription
T@"NSString",&,N,V_localizedTypeDescription
T@"NSString",&,N,V_TIFFImageDescription
T@"NSString",&,N,V_IPTCCaptionAbstract
T@"NSString",&,N,V_EXIFUserComment
T@"NSString",&,N,V_PNGImageDescription
T@"NSURL",R,N
AXMDisplayManager
DeviceClassNumber
v24@?0@"FBSDisplayMonitor"8@"NSSet"16
AXMDisplayManager:<%p> Initialized %ld
Frontbaord Main:%@
CADisplay Main:%@
Static (gestalt) props: %@
screen-dimensions
main-screen-orientation
main-screen-scale
scale
Aixt/MEN2O2B7f+8m4TxUA
supportsDeepColor
displayMonitor
T@"FBSDisplayMonitor",&,N,V_displayMonitor
mobileGestaltOrientation
Td,N,V_mobileGestaltOrientation
frontBoardMainDisplay
T@"AXMDisplay",R,N
coreAnimationMainDisplay
isInitialized
Default
None
CoreAnimation
FrontBoardServices (dynamic)
AXMDisplay<%p>: Backing:%@ Name:%@ scale:%@ size:[%.2f %.2f] orientation:%@ (%s) refBounds:[%.2f %.2f %.2f %.2f] deepColor:%d
backingType
Tq,N,V_backingType
T@"NSString",C,N,V_name
Td,N,V_scale
T{CGSize=dd},N,V_size
Td,N,V_orientation
physicalOrientation
Tq,N,V_physicalOrientation
referenceBounds
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_referenceBounds
TB,N,V_supportsDeepColor
AXMDisplayManagerMainDisplayWasUpdatedNotification
AXMPhysicalDisplayOrientationUnknown
AXMPhysicalDisplayOrientationPortrait
AXMPhysicalDisplayOrientationPortraitUpsideDown
AXMPhysicalDisplayOrientationLandscapeLeft
AXMPhysicalDisplayOrientationLandscapeRight
unknown
MM-dd-HH-mm-ss
image_%dx%d_%ld_%@.jpg
lexiconLocale
language
T@"AXMLanguage",R,N,V_language
Text Processing
v16@?0@"AXMTag"8
v16@?0@"AXMTaggedText"8
Text Pre-Processing
.,!?
-axout-tmp
-axtmp
yyyy:MM:dd HH:mm:ss
MMMMddyyyyjjmm
MMMMddjjmm
jjmm
face detect error: %@
face.smiling
face.blinking
face.number.format
/System/Library/PrivateFrameworks/ScreenReaderCore.framework
SCRCPhotoEvaluator
image/png
filetype.image
image/bmp
image/jpeg
image/vnd.adobe.photoshop
filetype.psd
image/tiff
filetype.tiff
image/svg+xml
filetype.svg
text/css
filetype.css.file
text/csv
filetype.csv.file
text/html
filetype.html.file
text/calendar
filetype.calendar.event
text/plain
filetype.text.file
text/directory
filetype.contact.card
application/pdf
filetype.pdf
application/x-latex
filetype.latex
application/json
filetype.json
application/vnd.ms-excel
filetype.excel
application/onenote
filetype.onenote
application/vnd.ms-powerpoint
filetype.powerpoint
application/msword
filetype.word
application/postscript
filetype.postscript
application/rtf
filetype.rtf
application/xml
filetype.xml
application/rss+xml
filetype.rss
application/zip
filetype.zip
application/x-rar-compressed
filetype.rar
application/x-tar
filetype.tar
audio/mp4
filetype.audio
audio/x-wav
audio/x-m4a
video/quicktime
filetype.video
video/mp4
video/mpeg
video/x-m4v
audio/
com.apple.coreaudio-format
video/
usdz
filetype.3D.model
filetype.unknown
.dizzy
.thinking.heart
.sparkling
.arrow
.wings
.broken
.shattering
.exploding
.beating
.fist
.peace
.thumbs.up.back.of.hand
.thumbs.down
.ok.symbol
.pointing.left
.pointing.right
.crossing.fingers.back.of.hand
.crossing.fingers.palm.of.hand
.raised.hand
.hang.loose
.waving
.waving.royal
.face.eyes.open
.face.eyes.one.eye.closed
.face.eyes.hearts
.eyes.hearts
.eyes.one.eye.closed
.sunglasses
.aviator.sunglasses
.cat.eye.sunglasses
.eyes.furled
.eyes.crying
.eyes.open
.eyes.wide.open
.eyes.closed
.eyes.black.hearts
.eyes.crosses
.eyes.bandages
.eyes.half.closed
.eyes.half.closed.one
.eyes.tearing.up
.mouth.smiling
.mouth.smiling.half.open
.mouth.smiling.wide
.mouth.tongue
.mouth.blowing.kiss
.mouth.smirking
.mouth.half.frowning
.mouth.frowning
.mouth.gasping
.mouth.screaming
.mouth.thermometer
.mouth.surgical.mask
.mouth.smiling.teeth
heart-blue-loop-
emoji.heart.blue
heart-red-loop-
emoji.heart.red
heart-purple-loop-
emoji.heart.purple
hand-loop-
emoji.hand
face-red-loop-
emoji.face.sad
emoji.face.sleeping
emoji.face.confused.and.dismayed
emoji.face
emoji.red.face
face-yellow-loop-
emoji.yellow.face
UIScreen
FCRPreciseDetectionParameters
/System/Library/PrivateFrameworks/FaceCore.framework/FaceCore
FCRSetupParamMinFaceSize
FCRSetupParamNumberOfAngles
FCRFaceDetector
UIGraphicsBeginImageContextWithOptions
UIGraphicsGetCurrentContext
UIGraphicsEndImageContext
FCRExtractionParamExtractSmile
FCRExtractionParamExtractBlink
FCRFaceExpressionSmile
FCRFaceExpressionLeftEyeClosed
FCRFaceExpressionRightEyeClosed
UIAccessibilityIsVoiceOverRunning
com.apple.AXMediaUtilitiesService
contextQueue
Create CIContext
Could not rotate buffer with orientation: %@
could not allocate pixel buffer: %@
Could not rotate buffer: %@
CIAffineTransform
Human Detector
VNDetectHumanRectanglesRequest
Barcode
v40@?0{?={?=qq}Q}8^B32
priority
VN PerformRequests
Vision Perform Requests:
effectivePriority
TQ,N,V_effectivePriority
Td,N,V_minimumConfidence
TQ,N,V_priority
speech.formatter.email.address.standard.phonetic
 %@ 
speech.formatter.email.address.at.phonetic
AXMVisionFeatureFaceLandmarksIs3DLandmarks
AXMVisionFeatureFaceLandmarksResults
photo.landmarks.nose
photo.landmarks.face
photo.landmarks.lefteye
photo.landmarks.righteye
photo.landmarks.innerlips
photo.landmarks.leftpupil
photo.landmarks.nosecrest
photo.landmarks.mouth
photo.landmarks.medianline
photo.landmarks.rightpupil
photo.landmarks.lefteyebrow
photo.landmarks.righteyebrow
is3DLandmarks
TB,N,V_is3DLandmarks
results
T@"NSDictionary",&,N,V_results
VNFaceLandmarks2D
clientID
includeImageInResult
detectText
detectScenes
detectModelClassifications
detectTraits
detectFaces
detectHumans
detectHorizon
detectRectangles
correctSpelling
spellCheckingLanguages
textDetectionLanguage
ignoredLayerContextIDs
Tq,N,V_clientID
TB,N,V_detectText
TB,N,V_detectFaces
TB,N,V_detectScenes
TB,N,V_detectModelClassifications
TB,N,V_detectTraits
TB,N,V_detectRectangles
TB,N,V_detectHumans
TB,N,V_detectHorizon
TB,N,V_correctSpelling
T@"AXMLanguage",&,N,V_textDetectionLanguage
T@"NSSet",&,N,V_spellCheckingLanguages
TB,N,V_includeImageInResult
T@"NSArray",&,N,V_ignoredLayerContextIDs
OutputManager
AXMOutputManager<%p>: state:'%@'. Speech? %@. Sound? %@.
request
T@"AXMOutputRequest",&,N,V_request
options
T@"AXMOutputRequestDispatchOptions",&,N,V_options
spellChecker
T@"AppleSpell",&,N,V_spellChecker
AXMFeatureType
AXMFeatureCanvasSize
AXMFeatureFrame
AXMFeatureNormalizedFrame
AXMFeatureValue
AXMFeatureBarcodeType
AXMOCRFeatureType
AXMFeatureColorInfo
AXMFeatureAssetMetadata
AXMFeatureBlur
AXMFeatureBrightness
AXMFeatureConfidence
AXMFeatureHorizonTransform
AXMFeatureHorizonAngle
AXMFeatureFaceLandmarks
AXMFeatureFaceLandmarks3d
AXMFeatureFaceExpressions
AXMFeatureFacePose
Disgust
Neutral
Scream
Smile
Surprise
Suspicious
Unknown AVMetadataObject
detectionLanguage
subfeatures
color info
asset metadata
Document
Region
Line
Char
Diacrit
Brightness
Blur
Color
Face
Human
Classification
ModelClassifier
MediaLegibility
AssetMetadata
Horizon
Rectangle
Sequence
Character
Diacritic
AXMVisionFeature<%p> %@
ID:%lu [faceLandmarks: %@ faceLandmarks3d: %@ faceExpressions: %@ likelyExpression: %@ likelyConfidence: %f] 
value:'%@' type:%@ 
value:'%@' 
value:'%.2f' 
asset info [%@] 
horizon transform. angle: %f 
frame:%@ (normalized:%@) 
confidence:%.2f
dictionaryRepresentation
T@"NSDictionary",R,N
featureType
isBarcode
isFace
isHuman
isClassification
isBrightness
isBlur
isHorizon
isColor
isMediaLegibility
isAssetMetadata
isRectangle
isModelClassification
isOCR
isTextDocument
isTextRegion
isTextLine
isTextSequence
isTextCharacter
isTextDiacritic
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N
confidence
isValueSpeakable
barcodeType
ocrFeatureType
colorInfo
T@"AXMVisionFeatureColorInfo",R,N
assetMetadata
T@"AXMVisionFeatureAssetMetadata",R,N
blur
faceLandmarks
T@"AXMVisionFeatureFaceLandmarks",R,N
faceLandmarks3d
faceExpressionsAndConfidence
likelyExpression
facePose
T{?=[4]},R,N
horizonTransform
T{CGAffineTransform=dddddd},R,N
horizonAngle
Tf,R,N
isTrackable
taggedText
T@"AXMTaggedText",R,N
com.apple.private.photoanalysisd.access
Scene Detector
possibleSceneClassifications
VNSceneClassificationRequest
engine
T@"AVAudioEngine",&,N,V_engine
soundPlayer
T@"AVAudioPlayerNode",&,N,V_soundPlayer
configChangedObserverToken
T@,&,N,V_configChangedObserverToken
datatype-%lu
AXMNodeID
AXNodeEnabled
NodeQueue
%@<%p>: ID:'%@' title:'%@' supported:%@ needsVisionKit:%@ enabled:%@ connected:%@
title
connected
TB,N,GisConnected,V_connected
T@"<AXMVisionEngineNodeConnectionDelegate>",W,N,V_delegate
T@"NSString",C,N,V_identifier
nodeQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_nodeQueue
requiresVisionFramework
enabled
TB,N,GisEnabled,V_enabled
AXMedia Utilities System Report: <Unavailable on this platform>
AXMedia Utilities System Report (privileged): <Unavailable on this platform>
Image
VoiceOver
screenCapture
text
scene
face
trait
use init()
captureNode
T@"AXMScreenCaptureNode",W,N,V_captureNode
imageNode
T@"AXMImageNode",W,N,V_imageNode
textDetector
T@"AXMTextDetectorNode",W,N,V_textDetector
sceneDetector
T@"AXMSceneDetectorNode",W,N,V_sceneDetector
faceDetector
T@"AXMFaceDetectorNode",W,N,V_faceDetector
traitDetector
T@"AXMTraitDetectorNode",W,N,V_traitDetector
Library/Accessibility
AXMediaUtilities
%.1f,%.1f,%.1f,%.1f
%.2f,%.2f,%.2f,%.2f
%.1f,%.1f
, %@
AXDateFormatter
{CGVector=dd}
{CGAffineTransform=dddddd}
AXMPointValue
T{CGPoint=dd},R,N
AXMVectorValue
T{CGVector=dd},R,N
AXMSizeValue
AXMRectValue
AXMAffineTransformValue
AXMLexiconManager
UnitTesting
AXMScreenGrabber
FaceWrapper
AXMHorizonDetectorNode
AXMVisionFeatureColorInfo
NSSecureCoding
NSCoding
AXMFaceDetectorNode
AXMServiceClientInterface
NSObject
AXMService
AXMServiceInterface
AXMDiagnosticMetric
AXMDiagnostics
AXMInertDiagnostics
AXMDiagnosticMetricToken
AXMOutputRequest
AXMOutputRequestDispatchOptions
AXMSpeechFormatter
AXMSpeechBlockFormatter
AXMModelDetectorNode
AXMScreenCaptureNode
AXMTraitDetectorNode
AXMVisionEngine
AXMVisionEngineNodeConnectionDelegate
AXMFeatureTrackingManagerDelegate
AXMTaskDispatcherDelegate
NSCopying
AXMDescribing
_AXMVisionEngineAnalysisTask
AXMVisionFeatureComparator
AXMLanguage
AXMPhoneNumberSpeechFormatter
AXMVisionPipelineContext
AXMTextDetectorNode
AXMTaggedText
AXMTaskDispatcher
AXMTask
AXMRectangleDetectorNode
AXMVisionColor
AXMVisionColorMarker
AXMSpeechComponent
AVSpeechSynthesizerDelegate
AXMAVCaptureSessionNode
AXMFeatureTracker
AXMTag
AXMAudioSession
AXMOutputComponent
AXMVisionResult
AXMVisionEngineCache
_AXMPlayerItemLegibleOutput
AXMAVPlayerItemNode
AVPlayerItemLegibleOutputPushDelegate
AVPlayerItemOutputPushDelegate
AXMDataDetector
AXFaceDetection
AXMLayoutItem
AXMLayoutSequence
AXMLayoutLine
AXMLayoutRegion
AXMTextLayoutManager
AXMExtras
AXMAssetMetadataNode
_AXMSettingObserver
AXMSettings
AXMFeatureTrackingManager
_AXMFeatureTrackerContainer
AXMVisionFeatureAssetMetadata
FaceCoreLightWrapper
AXMDisplayManager
FBSDisplayObserving
AXMDisplay
AXMTextProcessingOperation
AXMTextProcessor
AXMHumanDetectorNode
AXMBarcodeNode
AXMTagger
AXMEvaluationNode
AXMEmailAddressSpeechFormatter
AXMVisionFeatureFaceLandmarks
AXMVisionAnalysisOptions
AXMOutputManager
_AXMOutputRequestTask
AXMSpellChecker
AXMSourceNode
AXMVisionFeature
AXMJSONSerializable
AXUnitTesting
Private
AXMSceneDetectorNode
AXMSoundComponent
AXMSpeechFormatterCache
AXMVisionEngineNode
AXMDeviceInfo
AXMImageNode
AXMVoiceOverVisionEngine
AXMGeomerty
@16@0:8
B32@0:8@16@24
B40@0:8@16@24@32
^{_LXLexicon=}32@0:8@16@24
v16@0:8
@"NSMutableDictionary"
^v32@0:8@16@24
@84@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16q48@56B64@68^@76
B16@0:8
{CGRect={CGPoint=dd}{CGSize=dd}}16@0:8
i16@0:8
q16@0:8
i32@0:8q16q24
v32@0:8^q16^q24
v20@0:8i16
v48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
v24@0:8q16
v20@0:8B16
{CGRect="origin"{CGPoint="x"d"y"d}"size"{CGSize="width"d"height"d}}
@24@0:8@16
v24@0:8@16
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
v32@0:8@16@24
v24@0:8@?16
d16@0:8
v24@0:8d16
@"NSArray"
B24@0:8@16
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
v56@0:8@16@24@32q40@?48
v56@0:8@"AXMVisionEngine"16@"AXMSourceNode"24@"AXMVisionPipelineContext"32q40@?<v@?@"AXMVisionResult"@"NSError">48
@"NSObject<OS_dispatch_queue>"
@"NSXPCConnection"
@32@0:8@16q24
v40@0:8^Q16^{mach_task_basic_info=QQQ{time_value=ii}{time_value=ii}ii}24^{task_vm_info=QiiQQQQQQQQQQQQQQQQQQQ}32
{mach_task_basic_info="virtual_size"Q"resident_size"Q"resident_size_max"Q"user_time"{time_value="seconds"i"microseconds"i}"system_time"{time_value="seconds"i"microseconds"i}"policy"i"suspend_count"i}
{task_vm_info="virtual_size"Q"region_count"i"page_size"i"resident_size"Q"resident_size_peak"Q"device"Q"device_peak"Q"internal"Q"internal_peak"Q"external"Q"external_peak"Q"reusable"Q"reusable_peak"Q"purgeable_volatile_pmap"Q"purgeable_volatile_resident"Q"purgeable_volatile_virtual"Q"compressed"Q"compressed_peak"Q"compressed_lifetime"Q"phys_footprint"Q"min_address"Q"max_address"Q}
@"NSString"
@56@0:8q16@24@?32@?40@?48
@40@0:8q16@24@?32
@32@0:8q16@24
@"NSMutableArray"
@"AXMDiagnostics"
@"AXMDiagnosticMetric"
@"NSMutableAttributedString"
B40@0:8o^@16@24o^@32
@24@0:8@?16
@?16@0:8
B24@0:8^@16
@"NSURL"
v80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16q48@56@64@?72
@"AXMScreenGrabber"
v32@0:8@"AXMSourceNode"16@"AXMVisionPipelineContext"24
B24@0:8@"AXMSourceNode"16
v24@0:8@"AXMAVCaptureSessionNode"16
v40@0:8@16@24@32
v40@0:8@"AXMFeatureTrackingManager"16@"AXMFeatureTracker"24@"NSNumber"32
v32@0:8@"AXMTaskDispatcher"16@"AXMTask"24
@24@0:8^{_NSZone=}16
v32@0:8@16q24
v32@0:8@"NSMutableString"16q24
@28@0:8@16B24
@24@0:8#16
v24@0:8Q16
@"_AXMVisionEngineAnalysisTask"
@"AXMFeatureTrackingManager"
@"NSMapTable"
@"AXMVisionEngineCache"
@"AXMService"
@"AXMTaskDispatcher"
@32@0:8@16@24
@"NSUUID"
@"AXMVisionPipelineContext"
@"AXMSourceNode"
q48@0:8@16@24^q32B40B44
@"NSLocale"
@"NSMutableCharacterSet"
{CGSize=dd}16@0:8
^{CGColorSpace=}16@0:8
^{__CVBuffer=}20@0:8B16
@"CIImage"
@"NSDictionary"
^{__CVBuffer=}
^{CGColorSpace=}
{CGSize="width"d"height"d}
@"AXMDiagnosticMetricToken"
@"NSError"
@"AXMVisionAnalysisOptions"
@"NSNumber"
@"<NSCopying>"
@"AXMVisionResult"
@"VNImageRequestHandler"
@"FKTextDetector"
@"AXMTextLayoutManager"
@40@0:8@16@24@?32
v48@0:8@16@24{_NSRange=QQ}32
B32@0:8{_NSRange=QQ}16
{_NSRange=QQ}16@0:8
@32@0:8{_NSRange=QQ}16
@32@0:8Q16^{_NSRange=QQ}24
v40@0:8{_NSRange=QQ}16@32
v40@0:8@16{_NSRange=QQ}24
@"NSObject<OS_dispatch_source>"
@"<AXMTaskDispatcherDelegate>"
{CGPoint=dd}16@0:8
v32@0:8{CGPoint=dd}16
{CGPoint="x"d"y"d}
@28@0:8C16C20C24
@40@0:8d16d24d32
v40@0:8*16*24*32
d24@0:8@16
@48@0:8d16d24d32@40
@32@0:8@16d24
v48@0:8@16{_NSRange=QQ}24@40
v32@0:8@"AVSpeechSynthesizer"16@"AVSpeechUtterance"24
v48@0:8@"AVSpeechSynthesizer"16{_NSRange=QQ}24@"AVSpeechUtterance"40
v40@0:8@16@24@?32
@"AVSpeechSynthesizer"
@"<AXMAVCaptureSessionNodeDelegate>"
@"AXMVisionFeature"
@104@0:8{?={?=qq}Q}16@40@48@56@64@72@80@88@96
@48@0:8Q16@24@32@40
@"AXMSpeechFormatter"
{?="range"{?="location"q"length"q}"attributes"Q}
@"NSTextCheckingResult"
v32@0:8q16@?24
@48@0:8@16@24@32@40
@40@0:8@16@24@32
@24@0:8q16
@"NSMutableOrderedSet"
v24@0:8@"AVPlayerItemOutput"16
v64@0:8@16@24@32{?=qiIq}40
v64@0:8@"AVPlayerItemLegibleOutput"16@"NSArray"24@"NSArray"32{?=qiIq}40
@"AVPlayerItem"
v48@0:8@16@24Q32@?40
v48@0:8@16Q24Q32@?40
@"NSRegularExpression"
@"AXMSpeechFormatterCache"
@48@0:8@16{CGSize=dd}24B40f44
{CGRect={CGPoint=dd}{CGSize=dd}}24@0:8@16
B48@0:8q16q24@32d40
q24@0:8q16
d24@0:8q16
{CGRect={CGPoint=dd}{CGSize=dd}}24@0:8q16
@48@0:8@16{CGSize=dd}24@40
@56@0:8@16{CGSize=dd}24@40^@48
v40@0:8{CGSize=dd}16@32
{CGSize=dd}24@0:8@16
v40@0:8{CGPoint=dd}16@32
{CGPoint=dd}24@0:8@16
v56@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48
v48@0:8@16@24@32^v40
@"NSUserDefaults"
@48@0:8@16#24@32^@40
@"<AXMFeatureTrackingManagerDelegate>"
@"AXMFeatureTracker"
@"AXDispatchTimer"
@"NSDate"
v40@0:8@"FBSDisplayMonitor"16@"FBSDisplayIdentity"24@"FBSDisplayConfiguration"32
v32@0:8@"FBSDisplayMonitor"16@"FBSDisplayIdentity"24
q24@0:8d16
@"AXMDisplay"
@"FBSDisplayMonitor"
{CGPoint=dd}32@0:8{CGPoint=dd}16
{CGRect={CGPoint=dd}{CGSize=dd}}48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
v32@0:8{CGSize=dd}16
q32@0:8q16q24
q28@0:8q16B24
@40@0:8q16q24^q32
@36@0:8q16B24^q28
v40@0:8@16q24@32
@"AXMLanguage"
@"AXMSpellChecker"
@"AXMLexiconManager"
@"AXMTagger"
@"AXMDataDetector"
@20@0:8B16
@24@0:8Q16
@"NSSet"
@"AXMAudioSession"
@"AXMSoundComponent"
@"AXMSpeechComponent"
@"AXMOutputRequest"
@"AXMOutputRequestDispatchOptions"
@"AppleSpell"
@40@0:8@16{CGSize=dd}24
@80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48{CGSize=dd}56@72
@56@0:8@16@24{CGSize=dd}32@48
@48@0:8@16@24{CGSize=dd}32
@44@0:8@16f24{CGSize=dd}28
@"NSDictionary"16@0:8
{?=[4]}16@0:8
{CGAffineTransform=dddddd}16@0:8
f16@0:8
q24@0:8@16
@"AXMTaggedText"
@"AXMVisionFeatureColorInfo"
@"AXMVisionFeatureAssetMetadata"
{CGAffineTransform="a"d"b"d"c"d"d"d"tx"d"ty"d}
@"AXMVisionFeatureFaceLandmarks"
{?="columns"[4]}
@104@0:8Q16{CGSize=dd}24{CGRect={CGPoint=dd}{CGSize=dd}}40@72@80q88@96
@"AVAudioEngine"
@"AVAudioPlayerNode"
@"<AXMVisionEngineNodeConnectionDelegate>"
v48@0:8@16@24@32@?40
v56@0:8@16@24Q32q40@?48
@"AXMScreenCaptureNode"
@"AXMImageNode"
@"AXMTextDetectorNode"
@"AXMSceneDetectorNode"
@"AXMFaceDetectorNode"
@"AXMTraitDetectorNode"
{CGVector=dd}16@0:8
@32@0:8{CGPoint=dd}16
@32@0:8{CGVector=dd}16
@32@0:8{CGSize=dd}16
@48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
@64@0:8{CGAffineTransform=dddddd}16
@333333
A@q=
B@)\
?ffffff
e@q=
k@333333
333333
?UUUUUU
?UUUUUU
?UUUUUU
?433333
MbP?@(#)PROGRAM:AXMediaUtilities  PROJECT:AXMediaUtilities-1
f024
