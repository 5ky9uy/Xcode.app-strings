MbP?
@mcpl
@(#)PROGRAM:Speech  PROJECT:SpeechRecognition-1
init
statusCode
intValue
headers
enumerateKeysAndObjectsUsingBlock:
_responseWithCFURLResponse:
result
searchType
isEqualToString:
JSONObjectWithData:options:error:
description
alloc
dataWithJSONObject:options:error:
initWithData:encoding:
stringByAppendingString:
initWithVoiceSearchResult:
.cxx_destruct
response
data
_response
_data
_searchType
copy
UUID
UUIDString
taskHint
_startedConnectionWithLanguageCode:delegate:taskHint:requestIdentifier:
stopSpeechWithOptions:
cancelSpeech
peakPower
averagePower
addRecordedSpeechSampleData:
array
string
countByEnumeratingWithState:objects:count:
removeSpaceBefore
removeSpaceAfter
appendString:
text
length
startTime
silenceStartTime
endTime
confidenceScore
_initWithSubstring:range:timestamp:duration:confidence:alternativeSubstrings:
addObject:
_initWithSegments:formattedString:
recognition
phrases
rawRecognition
_initWithBestTranscription:rawTranscription:final:
transcriptionsWithTokens:
recognizedResultFromPackage:
isEqual:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
debugDescription
dictationConnectionSpeechRecordingWillBegin:
dictationConnectionSpeechRecordingDidBegin:
dictationConnectionSpeechRecordingDidEnd:
dictationConnectionSpeechRecordingDidCancel:
dictationConnection:speechRecordingDidFail:
dictationConnection:speechRecognitionDidFail:
dictationConnection:didRecognizePhrases:languageModel:correctionIdentifier:
dictationConnection:didRecognizeTokens:languageModel:
dictationConnection:didProcessAudioDuration:
dictationConnectionSpeechRecognitionDidSucceed:
dictationConnection:didRecognizeTranscriptionObjects:languageModel:
dictationConnnectionDidChangeAvailability:
dictationConnection:didFinishWritingAudioFile:error:
dictationConnection:didReceiveSearchResults:recognizedText:stable:final:
dictationConnection:didRecognizePackage:
stopSpeech
_initWithRequest:queue:languageCode:taskHint:
state
finish
cancel
_taskHint
isFinishing
isCancelled
error
requestIdentifier
_dictationConnection
_externalQueue
_languageCode
_request
_internalQueue
_completed
_running
_finishing
_cancelled
_error
_requestIdentifier
isFinal
addOperationWithBlock:
errorWithDomain:code:userInfo:
_fireResultHandlerWithResult:error:
_finalizeResultHandler
shouldReportPartialResults
_initWithRequest:queue:languageCode:taskHint:resultHandler:
_resultHandler
_hasFiredFinalResult
_searchRequest
speechRecognitionTaskWasCancelled:
speechRecognitionTask:didFinishSuccessfully:
_tellDelegateDidFinishSuccessfully:
speechRecognitionTaskFinishedReadingAudio:
speechRecognitionTask:didReceiveSearchResults:recognizedText:stable:final:
bestTranscription
formattedString
speechRecognitionTask:didFinishRecognition:
speechRecognitionTask:didHypothesizeTranscription:
speechRecognitionTask:didProcessAudioDuration:
numberWithInteger:
setObject:forKey:
_initWithRequest:queue:languageCode:taskHint:delegate:
_delegate
_recognitionResultToReportAfterFinalSearchResults
_selfReference
_waitForVoiceSearchResult
_hasSentRealSearchResults
interpretations
firstObject
tokens
enumerateObjectsUsingBlock:
stringByAppendingFormat:
arrayWithObjects:count:
setWithArray:
decodeObjectOfClasses:forKey:
decodeBoolForKey:
encodeObject:forKey:
encodeBool:forKey:
segments
alternativeSubstrings
mutableCopy
substring
insertObject:atIndex:
subarrayWithRange:
addObjectsFromArray:
substringRange
removeObjectAtIndex:
timestamp
duration
confidence
count
stringByReplacingCharactersInRange:withString:
expandTranscription:
supportsSecureCoding
copyWithZone:
encodeWithCoder:
initWithCoder:
_initWithBestTranscription:final:
transcriptions
rawTranscriptions
rawTranscription
_transcriptions
_rawTranscriptions
_final
_bestTranscription
_rawTranscription
setWithCapacity:
localeWithLocaleIdentifier:
currentLocale
initWithLocale:
localeIdentifier
stringByReplacingOccurrencesOfString:withString:
containsObject:
objectForKey:
stringWithFormat:
mainQueue
setDelegate:
beginAvailabilityMonitoring
defaultCenter
_informDelegateOfPreferencesChange
addObserverForName:object:queue:usingBlock:
endSession
cancelAvailabilityMonitoring
removeObserver:
dealloc
dictationIsEnabled
dictationIsAvailableForLanguage:
forcedOfflineDictationIsAvailableForLanguage:
requestOfflineDictationSupportForLanguage:completion:
getForcedOfflineDictationSupportedLanguagesWithCompletion:
raise:format:
sendEngagementFeedback:voiceQueryIdentifier:
_informDelegateOfAvailabilityChange
speechRecognizer:availabilityDidChange:
isAvailable
initialize
supportedLocales
authorizationStatus
requestAuthorization:
_fetchSupportedForcedOfflineLocalesWithCompletion:
_isAvailableForForcedOfflineRecognition
_requestOfflineDictationSupportWithCompletion:
_isInternalTaskHint:
recognitionTaskWithRequest:resultHandler:
recognitionTaskWithRequest:delegate:
_sendEngagementFeedback:requestIdentifier:
setQueue:
locale
delegate
defaultTaskHint
setDefaultTaskHint:
queue
_facetimeObserver
_foregroundObserver
_preferencesObserver
_locale
_defaultTaskHint
_queue
numberWithDouble:
numberWithFloat:
encodeInteger:forKey:
encodeDouble:forKey:
decodeObjectOfClass:forKey:
decodeIntegerForKey:
decodeDoubleForKey:
_confidence
_substring
_timestamp
_duration
_alternativeSubstrings
_substringRange
searchTypes
setSearchTypes:
headerFields
setHeaderFields:
queryParameters
setQueryParameters:
_searchTypes
_headerFields
_queryParameters
mainBundle
bundleIdentifier
setApplicationName:
infoDictionary
setApplicationVersion:
setInlineItemList:
setRequestIdentifier:
setVoiceTriggerEventInfo:
setMaximumRecognitionDuration:
setDetectUtterances:
setVoiceSearchTypeOptions:
setVoiceSearchQueryParameters:
setVoiceSearchHeaderFields:
setKeyboardType:
setTaskHint:
setInteractionIdentifier:
setForceOfflineRecognition:
setRecognitionOverrides:
setModelOverrideURL:
initWithActivationEvent:
automaticallyEndpoint
setUseAutomaticEndpointing:
setUseStreamingDictation:
processInfo
systemUptime
setActivationEventTime:
_setSearchRequests:
_searchRequests
_powerMeteringAvailable
_dictationOptionsWithTaskHint:requestIdentifier:
_speechRequestOptions
_maximumRecognitionDuration
_setMaximumRecognitionDuration:
_forceOfflineRecognition
_setForceOfflineRecognition:
_setSearchRequest:
_voiceTriggerEventInfo
_setVoiceTriggerEventInfo:
_recognitionOverrides
_setRecognitionOverrides:
_modelOverrideURL
_setModelOverrideURL:
setShouldReportPartialResults:
contextualStrings
setContextualStrings:
interactionIdentifier
detectMultipleUtterances
setDetectMultipleUtterances:
_shouldReportPartialResults
_detectMultipleUtterances
_maxiumRecognitionDuration
_contextualStrings
_interactionIdentifier
setFieldLabel:
assetWithURL:
setOriginalAudioFileURL:
tracksWithMediaType:
formatDescriptions
startRecordedAudioDictationWithOptions:forLanguage:narrowband:
assetReaderWithAsset:error:
numberWithUnsignedInt:
numberWithUnsignedInteger:
numberWithInt:
numberWithBool:
dictionaryWithObjects:forKeys:count:
assetReaderAudioMixOutputWithAudioTracks:audioSettings:
canAddOutput:
addOutput:
startReading
copyNextSampleBuffer
initWithURL:
_URL
initWithStreamDescription:
stringWithUTF8String:
currentHandler
handleFailureInMethod:object:file:lineNumber:description:
startRecordedAudioDictationWithOptions:forLanguage:
_appendAudioPCMBuffer:
_appendAudioSampleBuffer:
_endAudio
nativeAudioFormat
format
_drainAndClearAudioConverter
int16ChannelData
frameLength
dataWithBytes:length:
_convertAndFeedPCMBuffer:
initWithPCMFormat:frameCapacity:
setFrameLength:
convertToBuffer:error:withInputFromBlock:
inputFormat
initFromFormat:toFormat:
setSampleRateConverterQuality:
mutableAudioBufferList
appendAudioPCMBuffer:
appendAudioSampleBuffer:
endAudio
_bufferDelegate
_queuedBuffers
_converter
_audioEnded
initWithLength:
mutableBytes
_formattedString
_segments
v32@?0@"NSString"8@"NSString"16^B24
response
T@"NSHTTPURLResponse",R,N,V_response
data
T@"NSData",R,N,V_data
searchType
Tq,R,N,V_searchType
com.apple.Speech.Task.Internal
v8@?0
hash
TQ,R
superclass
T#,R
description
T@"NSString",R,C
debugDescription
_taskHint
Tq,R,N,V_taskHint
requestIdentifier
T@"NSString",R,C,N,V_requestIdentifier
state
Tq,R,N
finishing
TB,R,N,GisFinishing,V_finishing
cancelled
TB,R,N,GisCancelled,V_cancelled
error
T@"NSError",R,C,N,V_error
v24@?0@"SFSpeechRecognitionResult"8@"NSError"16
v32@?0@"AFSpeechToken"8Q16^B24
v32@?0@"AFSpeechInterpretation"8Q16^B24
_bestTranscription
_rawTranscription
_final
 final=%d, bestTranscription=%@
v32@?0@"NSString"8Q16^B24
v32@?0@"SFTranscriptionSegment"8Q16^B24
supportsSecureCoding
TB,R
rawTranscription
T@"SFTranscription",R,C,N,V_rawTranscription
rawTranscriptions
T@"NSArray",R,C,N
bestTranscription
T@"SFTranscription",R,C,N,V_bestTranscription
transcriptions
final
TB,R,N,GisFinal,V_final
Cannot make recognizer for %@. Supported locale identifiers are %@
%@-%@
v16@?0@"NSNotification"8
v16@?0@"NSArray"8
Result handler must be non-null
%@ queue must not be nil
_availableForForcedOfflineRecognition
TB,R,N,G_isAvailableForForcedOfflineRecognition
available
TB,R,N,GisAvailable
locale
T@"NSLocale",R,C,N,V_locale
delegate
T@"<SFSpeechRecognizerDelegate>",W,N,V_delegate
defaultTaskHint
Tq,N,V_defaultTaskHint
queue
T@"NSOperationQueue",&,N,V_queue
, substringRange=%@, timestamp=%@, duration=%@, confidence=%@, substring=%@, alternativeSubstrings=%@
_substring
_substringRange.location
_substringRange.length
_timestamp
_duration
_confidence
_alternativeSubstrings
substring
T@"NSString",R,C,N,V_substring
substringRange
T{_NSRange=QQ},R,N,V_substringRange
timestamp
Td,R,N,V_timestamp
duration
Td,R,N,V_duration
confidence
Tf,R,N,V_confidence
alternativeSubstrings
T@"NSArray",R,N,V_alternativeSubstrings
SFSpeechPreecordedRequest
searchTypes
Tq,N,V_searchTypes
headerFields
T@"NSDictionary",C,N,V_headerFields
queryParameters
T@"NSDictionary",C,N,V_queryParameters
_searchRequest
T@"_SFSearchRequest",&,N,G_searchRequest,S_setSearchRequest:,V_searchRequest
detectMultipleUtterances
TB,N,V_detectMultipleUtterances
_forceOfflineRecognition
TB,N,G_forceOfflineRecognition,S_setForceOfflineRecognition:,V_forceOfflineRecognition
_voiceTriggerEventInfo
T@"NSDictionary",&,N,G_voiceTriggerEventInfo,S_setVoiceTriggerEventInfo:,V_voiceTriggerEventInfo
_maxiumRecognitionDuration
Td,N,G_maximumRecognitionDuration,S_setMaximumRecognitionDuration:,V_maxiumRecognitionDuration
_recognitionOverrides
T@"NSDictionary",&,N,G_recognitionOverrides,S_setRecognitionOverrides:,V_recognitionOverrides
_modelOverrideURL
T@"NSURL",&,N,G_modelOverrideURL,S_setModelOverrideURL:,V_modelOverrideURL
taskHint
Tq,N,V_taskHint
shouldReportPartialResults
TB,N,V_shouldReportPartialResults
contextualStrings
T@"NSArray",C,N,V_contextualStrings
interactionIdentifier
T@"NSString",C,N,V_interactionIdentifier
Use -[SFSpeechURLRecognitionRequest initWithURL:]
Could not add output for %@
B8@?0
T@"NSURL",R,C,N,V_URL
com.apple.SFSpeechAudioBufferRecognitionRequest
/BuildRoot/Library/Caches/com.apple.xbs/Sources/SpeechFramework_Sim/SpeechFramework-65/SpeechRecognition/SFSpeechRecognitionRequest.m
<Unknown File>
%@ cannot be re-used
Invalid audio format
@"AVAudioBuffer"20@?0I8^q12
Could not drain converter %@
Could not run audio converter %@
nativeAudioFormat
T@"AVAudioFormat",R,N
CMBlockBufferCopyDataBytes could not copy data: %d
, formattedString=%@, segments=%@
_segments
_formattedString
formattedString
T@"NSString",R,C,N,V_formattedString
segments
T@"NSArray",R,C,N,V_segments
_SFSearchResult
SFSpeechRecognitionTask
AFDictationDelegate
NSObject
SFSpeechRecognitionBufferDelegate
_SFSpeechRecognitionBlockTask
_SFSpeechRecognitionDelegateTask
SFSpeechRecognitionResult
NSCopying
NSSecureCoding
NSCoding
SFSpeechRecognizer
SFTranscriptionSegment
_SFSearchRequest
SFSpeechRecognitionRequest
SFSpeechURLRecognitionRequest
SFSpeechAudioBufferRecognitionRequest
SFTranscription
@24@0:8@16
@16@0:8
v16@0:8
q16@0:8
@"NSHTTPURLResponse"
@"NSData"
B24@0:8@16
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B16@0:8
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
v24@0:8@16
v32@0:8@16@24
v48@0:8@16@24@32@40
v40@0:8@16@24@32
v32@0:8@16d24
v48@0:8@16@24@32B40B44
v24@0:8@"AFDictationConnection"16
v32@0:8@"AFDictationConnection"16@"NSError"24
v48@0:8@"AFDictationConnection"16@"NSArray"24@"NSString"32@40
v40@0:8@"AFDictationConnection"16@"NSArray"24@"NSString"32
v32@0:8@"AFDictationConnection"16d24
v40@0:8@"AFDictationConnection"16@"NSFileHandle"24@"NSError"32
v48@0:8@"AFDictationConnection"16@"NSArray"24@"NSString"32B40B44
v32@0:8@"AFDictationConnection"16@"AFSpeechPackage"24
v24@0:8@"NSData"16
@48@0:8@16@24@32q40
f16@0:8
@"AFDictationConnection"
@"NSOperationQueue"
@"NSString"
@"SFSpeechRecognitionRequest"
@"NSObject<OS_dispatch_queue>"
@"NSError"
@56@0:8@16@24@32q40@?48
@56@0:8@16@24@32q40@48
v20@0:8B16
@"<_SFSpeechRecognitionTaskDelegatePrivate>"
@"SFSpeechRecognitionResult"
@"_SFSpeechRecognitionDelegateTask"
@24@0:8^{_NSZone=}16
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
@28@0:8@16B24
@36@0:8@16@24B32
@"NSArray"
@"SFTranscription"
v24@0:8@?16
B24@0:8q16
@32@0:8@16@?24
@32@0:8@16@24
v32@0:8q16@24
v24@0:8q16
@"<NSObject>"
@"NSLocale"
@"<SFSpeechRecognizerDelegate>"
@68@0:8@16{_NSRange=QQ}24d40d48f56@60
{_NSRange=QQ}16@0:8
d16@0:8
{_NSRange="location"Q"length"Q}
@"NSDictionary"
@48@0:8@16@24q32@40
@32@0:8q16@24
v24@0:8d16
@"_SFSearchRequest"
@"NSURL"
v24@0:8^{opaqueCMSampleBuffer=}16
@"<SFSpeechRecognitionBufferDelegate>"
@"NSMutableArray"
@"AVAudioConverter"
