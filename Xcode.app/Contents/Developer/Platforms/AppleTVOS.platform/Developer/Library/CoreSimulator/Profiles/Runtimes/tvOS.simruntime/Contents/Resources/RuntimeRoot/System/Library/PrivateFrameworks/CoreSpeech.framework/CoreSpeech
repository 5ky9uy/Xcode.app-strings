mcpl
supo
333?
NSt3__114basic_ifstreamIcNS_11char_traitsIcEEEE
NSt3__113basic_filebufIcNS_11char_traitsIcEEEE
@mcpl
NSt3__118basic_stringstreamIcNS_11char_traitsIcEENS_9allocatorIcEEEE
NSt3__115basic_stringbufIcNS_11char_traitsIcEENS_9allocatorIcEEEE
NSt3__119basic_ostringstreamIcNS_11char_traitsIcEENS_9allocatorIcEEEE
xfua2vpelppa
?ffffff
Affffff
triggerStartSampleCount
triggerEndSampleCount
triggerFireSeconds
triggerScore
isContinuous
activeChannel
CSContinuousVoiceTrigger Queue
v8@?0
Setting two shot decision mode lastFireSampleCounts = %tu (%.3f), twoShotThreshold = %.3f, twoShotDecisionWaitSamples = %tu
best_score
best_phrase
Shot: best score = %f for phrase = %tu for channel = %tu
totalSampleCounts : %tu, sum : %tu
Entering two shot at %.2f with [score: %.3f > threshold: %.3f]
Not entering two shot: [score: %.3f < threshold: %.3f]
Not entering two shot: best_phrase(%tu) with score(%.3f) is not silence
NDAPI continuous voicetrigger best score = %f for channel = %tu
best_start
best_end
hash
TQ,R
superclass
T#,R
description
T@"NSString",R,C
debugDescription
speechManager
T@"CSSpeechManager",W,N,V_speechManager
queue
T@"NSObject<OS_dispatch_queue>",&,N,V_queue
currentAsset
T@"CSAsset",&,N,V_currentAsset
keywordAnalyzer
T@"CSKeywordAnalyzerNDAPI",&,N,V_keywordAnalyzer
keywordThreshold
Tf,N,V_keywordThreshold
mode
Tq,N,V_mode
totalSampleCounts
TQ,N,V_totalSampleCounts
lastFireSampleCount
TQ,N,V_lastFireSampleCount
twoShotDecisionWaitSamples
TQ,N,V_twoShotDecisionWaitSamples
twoShotThreshold
Tf,N,V_twoShotThreshold
delegate
T@"<CSVoiceTriggerDelegate>",W,N,V_delegate
same name of file exists, this will be removed
Creating Directory : %@
Creating Directory failed : %@
Library/VoiceTrigger/SAT
xx_XX
model
audio
self ENDSWITH '.wav'
modelPath
T@"NSString",R,N
utteranceDirectory
enrollmentUtterance
T@"NSArray",R,N
isValid
TB,R,N,V_isValid
needsRetrain
TB,R,N
firstPassDetectedChannel
firstPassScore
firstPassBestStartSampleCount
firstPassBestEndSampleCount
firstPassFireSampleCount
VoiceTrigger First Pass Queue
Initializing first pass Corealis for channel : %tu
%tu first pass Corealis were created
v16@?0Q8
VoiceTrigger start policy changed : %@
RUNNING
STOPPED
v12@?0B8
_voiceTriggerEnabled = %@
NDAPI first pass best score = %f for channel = %tu
We have a trigger pending, ignore score = %f for channel = %tu
samples_at_fire
Sending early detect notification upon first pass trigger
com.apple.voicetrigger.EarlyDetect
voiceTriggerStartPolicy
T@"CSVoiceTriggerEnabledPolicyNonAOP",&,N,V_voiceTriggerStartPolicy
voiceTriggerEnabled
TB,N,V_voiceTriggerEnabled
keywordAnalyzersNDAPI
T@"NSMutableArray",&,N,V_keywordAnalyzersNDAPI
hasTriggerPending
TB,N,V_hasTriggerPending
firstPassThreshold
Tf,N,V_firstPassThreshold
T@"<CSVoiceTriggerFirstPassDelegate>",W,N,V_delegate
speechManagerStartSampleCount
CSSpeechManager Queue
CSVoiceTriggerAsset found: %@
Cannot find voicetrigger asset from asset manager, let's fallback to asset in the framework
event : %@
Creating new CSAudioRecorder with context : %@
Cannot create audio recorder : %@
It cannot change context because it is recording
Cannot change context : %@
AVVC already recording, nothing to prepare
AVVC Prepare recording failed : %@
Not supported in this platform
context : %@
Cannot prepare since audio recorder was not initialized
recordingSettings from CS : %@
settings : %@
startRecording failed : %@
Activate Context = %@
setCurrentContext failed : %@
ReleaseAudioSession called while RecordingWithVTRunning
startRecordingBy %@
_lastForwardedSampleCounts = %tu, audioBufferSampleCount = %tu
Generating fake didStopRecording delegate
Mediaserverd recovered from crash
from:%@ to:%@ by:%@
Ignore event(%@) from(%@) since we don't have transition
Trying to startListening
_createRecorderWithContextIfNeeded failed, it will try again %f seconds later
_prepareListenWithSettings failed, it will try again %f seconds later
startListening succeed
startListening failed, it will try again %f seconds later
ignore because lastForwardedSampleCount:%lu, theMostRecentSampleCount:%lu
Buffer underrun!!!!, lastForwardedSampleTime:%lu, oldestSampleTimeInBuffer:%lu
%@, sucessfully:%@ error:%@
Init
Stop
FirstPass
SecondPass
RecordPending
RecordWithVTRunning
RecordWithVTStopped
PollingListening
StoppingWithVTRunning
StoppingWithVTStopped
unknown(%tu)
ClientPrepare
AudioRecorderRelease
VoiceTriggerRunning
VoiceTriggerStopped
FirstPassTriggered
SecondPassTriggered
SecondPassRejected
SelfTriggerDetected
RecordPendingTimeout
ClientStartRecording
ClientStopRecording
ClientReleaseRecordSession
RecordingDidStop
ListeningSucceed
MediaserverdRestarted
kDidStartFailed
stateMachine
T@"CSStateMachine",&,N,V_stateMachine
audioBuffer
T@"CSAudioCircularBuffer",&,N,V_audioBuffer
currentVoiceTriggerAsset
T@"CSAsset",&,N,V_currentVoiceTriggerAsset
voiceTriggerFirstPass
T@"CSVoiceTriggerFirstPass",&,N,V_voiceTriggerFirstPass
voiceTriggerSecondPass
T@"CSVoiceTriggerSecondPass",&,N,V_voiceTriggerSecondPass
clientController
T@"<CSSpeechManagerDelegate>",W,N,V_clientController
voiceTriggerEventNotifier
T@"CSVoiceTriggerEventNotifier",&,N,V_voiceTriggerEventNotifier
voiceTriggerFileLogger
T@"CSVoiceTriggerFileLogger",&,N,V_voiceTriggerFileLogger
selfTriggerDetector
T@"CSSelfTriggerDetector",&,N,V_selfTriggerDetector
continuousVoiceTrigger
T@"CSContinuousVoiceTrigger",&,N,V_continuousVoiceTrigger
keywordDetector
T@"CSKeywordDetector",&,N,V_keywordDetector
myriad
T@"CSMyriadPHash",&,N,V_myriad
voiceTriggerFidesClient
T@"CSVoiceTriggerFidesClient",&,N,V_voiceTriggerFidesClient
activeAudioProcessors
T@"NSHashTable",&,N,V_activeAudioProcessors
lastForwardedSampleCount
TQ,N,V_lastForwardedSampleCount
secondPassStartSampleCount
TQ,N,V_secondPassStartSampleCount
clientStartSampleCount
TQ,N,V_clientStartSampleCount
recordingPendingTimeout
Tq,N,V_recordingPendingTimeout
lastVoiceTriggerEventInfo
T@"NSDictionary",&,N,V_lastVoiceTriggerEventInfo
listenPollingTimer
T@"NSObject<OS_dispatch_source>",&,N,V_listenPollingTimer
audioRecorder
T@"CSAudioRecorder",&,N,V_audioRecorder
com.apple.MobileAsset.VoiceTriggerAssets
com.apple.MobileAsset.VoiceTriggerAssetsWatch
com.apple.MobileAsset.VoiceTriggerAssetsMarsh
com.apple.MobileAsset.SpeechEndpointAssets
en-US
init-_currentLanguageCode: %@
Serial CSAssetManager queue
Error running asset-query for assetType:%lu, query: %@, predicate: %@, error: %@
::: found %lu assets for assetType=%lu, matching query: %@
::: %s
-[CSAssetManager _assetQueryForAssetType:withPredicate:localOnly:]
::: predicate: %@
-[CSAssetManager _runAssetQuery:completion:]
::: %s; query: %@
-[CSAssetManager _runAssetQuery:completion:]_block_invoke
Error running asset query: error %@
v24@?0@"NSArray"8@"NSError"16
::: Request Fetching RemoteMetaData
::: Request fetching remote asset
::: Fetching remote asset
::: Purging installed asset : %@
::: Request downloading remote asset
-[CSAssetManager _defaultDownloadOptions]
::: Start downloading asset
::: download progress: %3.0f%%
v16@?0d8
::: Error downloading; %@
::: download completed successfully.
v16@?0@"NSError"8
-[CSAssetManager _startDownloadingVoiceTriggerAsset:progress:completion:]
Attempting to download asset %@
v24@?0@"NSDictionary"8@"NSError"16
Failure resuming paused voice asset %@
Asset doesn't need downloading, invoking completion
_currentLanguageCode changed: %@
currentLanguageCode
ERR: Unknown AssetType: %lu
(%@ == %K)
(%@ IN %K)
((%K == nil) OR (%K != %@))
 && 
configFileNDAPI
threshold
config.txt
VTFirstPassConfigPathNDAPI
VTFirstPassThreshold
Tf,R,N
isTriggerEvent
totalSampleCount
Called with status : %d
returning status to UI : %d
Already reported status or no callback
%s Called
-[CSVTUITrainingSession suspendTraining]
Will suspend training
-[CSVTUITrainingSession resumeTraining]
Will resume training
%s called
-[CSVTUITrainingSession setupPhraseSpotter]
Decide to delay ending ASR: [%ld] samples
v16@?0@"NSDictionary"8
Triggered! Event info: %@
%9lld %9lld %9lld
analyzing.... score so far: %5.3f
feeding tailing: [%ld] samples
correctSampleSize:    [%ld]
accumSampleSize:      [%ld]
startBufferIndex:     [%ld]
startBufferSampleSize:[%ld]
samplesToBeDeleted:   [%ld]
Total Number of buffs:[%ld]
Adjusting the start buffer
Adjusting the array elements
Unsupported
Begin of speech detected
End of speech detected
PHS explicit training utterance
[%ld] VTUISession Number:[%ld]
%s CALLED
-[CSVTUITrainingSession startMasterTimerWithTimeout:]
Master Timeout Fired
-[CSVTUITrainingSession stopMasterTimer]
-[CSVTUITrainingSession speechRecognitionTask:didHypothesizeTranscription:]
recognized text = %@
Context : %@
Ask start recording from: %tu
SpeechController to receive data from channel %tu
SpeechManager still forwarding audio after didStopForwarding, we shouldn't have this
AVVCAudioBuffer contains %{public}d packet descriptions, size %{public}d, channels %{public}d. Ignoring
packetCount %d
Bad packet length %{public}d. Skipping rest of record buffer.
SpeechController is trying to forward encoded audio after didStopForwarding, we shouldn't have this
Not available
Requesting QuickStop operation upon detecting keyword
%c%c%c%c
none
endpointerProxy
T@"CSEndpointerProxy",&,N,V_endpointerProxy
avvcContext
T@"NSDictionary",&,N,V_avvcContext
isOpus
TB,N,V_isOpus
isActivated
TB,N,V_isActivated
TQ,N,V_activeChannel
T@"<CSSpeechControllerDelegate>",W,N,V_delegate
duckOthersOption
TB,N
endpointAnalyzer
T@"<CSEndpointAnalyzer>",R,N
com.apple.voicetrigger
VoiceTrigger Enabled
VoiceTrigger CoreSpeech Enabled
com.apple.demo-settings
StoreDemoMode
File Logging Level
Library
Logs/CrashReporter/VoiceTrigger/audio/
VoiceTrigger/SAT
Caches/VoiceTrigger/SATUpdate
Caches/VoiceTrigger/SATUpload
Cannot delete existing SATUpload Diretory : %@
Cannot create SAT Upload Directory : %@
Cannot create directory(%@)
json
Cannot copy file from %@ to %@ : %@
PHS update directory already exists, remove before we move forward
Failed to delete PHS update directory
Failed to create PHS update directory
We need SAT directory, deleting the file with same name first
Failed to get device hash list %@
Processing sync data from device hash: %@
Error to copy profile from %@ to %@, error: %@
Sucessfully migrated language %@
Migrated language %@ but failed to mark SAT enrollment
Failed to remove update path [%@] upon migration completion, error: %@
enrollment_completed
Coudn't mark SAT enrollment success at path %@
Marked SAT enrollment success at path %@
We can't mark SAT success when there is no audio directory
transitions
T@"NSMutableDictionary",&,N,V_transitions
T@"<CSStateMachineDelegate>",W,N,V_delegate
currentState
Tq,R,N,V_currentState
Serial CSEventMonitor queue
/BuildRoot/Library/Caches/com.apple.xbs/Sources/CoreSpeech_Sim/CoreSpeech-65.1/CoreSpeech/CSEventMonitor.m
<Unknown File>
Subclasses need to overwrite this method
Failure disposing audio file %d
Audio file already configured, closing first
-input.wav
Creating audio file at URL %@
Failed creating audio file at url %@ %d
Error setting input format %d
No audio file to append data
Failed writing audio file %d
Closing file at URL %@, audio size: %u
VoiceTrigger audio logging queue
Couldn't create voice trigger audio logging directory at path %@ %@
/tmp
yyyyMMdd-HHmmss
%@%@%@
.json
Error writing out event info meta: %@
-triggered
.wav
-almost
-rejected
T@"CSAudioCircularBuffer",W,N,V_audioBuffer
extraSamplesAtStart
2ndChanceThreshold
loggingThreshold
configFileRecognizer
useKeywordSpotting
recognizerThresholdOffset
recognizerScoreScaleFactor
recognizerToken
config_marsh.txt
recognizer.json
hey_Siri
VTSecondPassExtraSamplesAtStart
TQ,R,N
VTSecondPassConfigPathNDAPI
VTSecondPassThreshold
VTSecondPass2ndChanceThreshold
VTSecondPassLoggingThreshold
VTSecondPassConfigPathRecognizer
VTSecondPassUserKeywordSpotting
VTSecondPassRecognizerThresholdOffset
VTSecondPassRecognizerScoreScaleFactor
VTSecondPassRecognizerToken
B8@?0
could not allocate %d bytes for %@
sqrt
complex part zero vec
fft magnitudes array
normalized fft magnitudes
begin zerocross vad, lentotal = %d
ran out of buffer, no voice activity
HammingWindow
myriad_audio_analysis
windowed array for signal estimation
sigsum = %f sigNorm= %d
vad offset = %d, lentotal = %d
vad could not find a start offset %d > %d - %d
last energy value set
current energy value set
BTLE AudioPayload ringBuffer startpoint: %lld samplesAvail: %lu
BTLE raw audio size = %ld
BTLE padded %ld samples to fill out buffer
Advert data: %@
/private/var/tmp/siriBC
advert data write failed
com.apple.siri.myriad.apayload
Posted siri audio hash notification
signalEstimate
Ts,N,V_signalEstimate
com.apple.fides.borealis.record-creation
com.apple.fides.borealis
Skipping DES record creation
type
languageCode
triggerSampleCount
csChunk
Failed to create DES record: %@
Created DES record with identifier: %@
v24@?0@"NSUUID"8@"NSError"16
Fides trigger (trigger): %@
Fides trigger (near-miss): %@
near-miss
trigger
speaker-reject
unknown
numChannels
numSamples
sampleByteDepth
startSampleCount
hostTime
Testing [%@] against regex.
regex.json
Cannot parse to JSON
Cannot find the file
trailing_garbage
leading_garbage
regex
com.apple.VoiceTriggerUI.TrainingSessionQueue
com.apple.VoiceTriggerUI.TrainingManager
Locale: [%@]
No locale set when creating phrase spotter.
Creation of Keyword Detector failed.
-[CSVTUITrainingManager cleanupWithCompletion:]
%s async called
-[CSVTUITrainingManager cleanupWithCompletion:]_block_invoke
Called before completion called
BEGIN num:%ld use:%d
AudioSession setup failed
Has wrong audio routing, ask user to unplug headset
Start Audio Session failed
_sessionNumber [%ld]
%s Canceling Training
-[CSVTUITrainingManager cancelTrainingForID:]
-[CSVTUITrainingManager _shouldShowHeadsetDisconnectionMessage]
-[CSVTUITrainingManager _startAudioSession]
AudioSession StartRecording Failed
Setting suspendAudio:[%d]
Resume training
Suspend training
Stop Listening
Tf,V_rms
T@"<CSVTUITrainingManagerDelegate>",W,N,V_delegate
speechRecognizerAvailable
TB,R,V_speechRecognizerAvailable
audioSource
suspendAudio
NDAPI initialization failed
set StartAnalyzeSampleCount = %lld
T@"<CSKeywordAnalyzerNDAPIScoreDelegate>",W,N,V_delegate
com.apple.corespeech
Framework
Logs/CrashReporter/CoreSpeech/
Logs/CrashReporter/CoreSpeech/audio/
%@/%@%@%@
Couldn't create CoreSpeech log directory at path %@ %@
totalAudioRecorded
Td,N,V_totalAudioRecorded
featuresAtEndpoint
T@"NSArray",&,N,V_featuresAtEndpoint
endpointerType
Tq,N,V_endpointerType
serverFeatureLatencyDistribution
T@"NSDictionary",&,N,V_serverFeatureLatencyDistribution
additionalMetrics
T@"NSDictionary",&,N,V_additionalMetrics
Languages
Footprint
Premium
com.apple.coreaudio.BorealisToggled
v12@?0i8
Start monitring : VoiceTrigger setting switch
Cannot start monitoring VoiceTrigger setting switch because it was already started
Stop monitring : VoiceTrigger setting switch
v16@?0@8
VoiceTrigger enabled = %@
waitTimeSinceVT
keyword_detector.json
keywordDetectorConfigPathRecognizer
keywordDetectorThreshold
keywordDetectorWaitTimeSinceVT
isMaximized
samples_fed
Dictionary to JSON conversion failed : %@
Borealis Input
com.apple.VoiceTriggerUI.AVVCSessionQueue
Creating new AVVC
Error initializing voice controller with context %@ %@
Trying to set record buffer duration to %lf
Failed setting record buffer duration. Duration is %lf
AVVC startRecordingWithSettings failed.
AVVC Stop Recording
audioInput:[%@]
No Reocrd Route detected
audioOutput:[%@]
T@"<CSVTUIAudioSessionDelegate>",W,N,V_delegate
feedFloat
/BuildRoot/Library/Caches/com.apple.xbs/Sources/CoreSpeech_Sim/CoreSpeech-65.1/CoreSpeech/CSBeepCanceller.mm
m_iInputDataSize + a_iNumSamples < m_inputData.size()
matrixVectorMultiply
a_vectorSize * a_productVector.size() == a_matrix.size()
jbl_begin.bin
BeepCanceller asset file loaindg from : %@
inva200.bin
beepVector Size = %lu
_inverseAutoCorrMatrix Size = %lu
Cannot initialize beep canceller
T@"<CSBeepCancellerDelegate>",W,N,V_delegate
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
triggerFireSampleCount
triggerStartSeconds
triggerEndSeconds
effectiveThreshold
recognizerScore
recognizerScaleFactor
triggerStartMachTime
triggerEndMachTime
triggerFireMachTime
hardwareSamplerate
VoiceTrigger Second Pass Queue
numBypassSamples set to: %tu
Received first pass triggered in channel: %tu with trigger start: %tu
Second pass set to analyze %tu samples (%.2fs) from %tu to %tu
Stop feeding audio to recognizer per sampleCount: %tu > %tu
Set to analyze %.3f more audio until recognizer comes back
Notify second pass reject at: %tu with best score up to: %.3f
NDAPI second pass best score = %f for phrase = %tu for channel = %tu with analyzed samples: %tu
Trigger detected with %tu analyzed samples in NDAPI
Detected near miss!!!, %@
Waiting for logging near miss until timeout %tu samples
Detected near miss candidate at %tu, let's wait %tu samples to log
recognizerScore updated from %.3f to: %.3f
keywordAnalyzerNDAPI
T@"CSKeywordAnalyzerNDAPI",&,N,V_keywordAnalyzerNDAPI
keywordAnalyzerQuasar
T@"CSKeywordAnalyzerQuasar",&,N,V_keywordAnalyzerQuasar
speakerDetector
T@"CSSpeakerDetectorNDAPI",&,N,V_speakerDetector
speakerModel
T@"CSSpeakerModel",&,N,V_speakerModel
secondPassTimeout
TQ,N,V_secondPassTimeout
numAnalyzedSamples
TQ,N,V_numAnalyzedSamples
keywordLoggingThreshold
Tf,N,V_keywordLoggingThreshold
lastScore
Tf,N,V_lastScore
bestKeywordScore
Tf,N,V_bestKeywordScore
bestKeywordStart
TQ,N,V_bestKeywordStart
bestKeywordEnd
TQ,N,V_bestKeywordEnd
TQ,N,V_extraSamplesAtStart
useSAT
TB,N,V_useSAT
nearMissDelayTimeout
TQ,N,V_nearMissDelayTimeout
nearMissCandidateDetectedSamples
TQ,N,V_nearMissCandidateDetectedSamples
hasPendingNearMiss
TB,N,V_hasPendingNearMiss
lastAnalyzerResult
T@"NSDictionary",&,N,V_lastAnalyzerResult
numBypassSamples
Tq,N,V_numBypassSamples
Tf,N,V_recognizerScore
isRunningRecognizer
TB,N,V_isRunningRecognizer
recognizerResultPending
TB,N,V_recognizerResultPending
Tf,N,V_recognizerScoreScaleFactor
VoiceTriggerEventNotifier queue
EventNotifier received VoiceTrigger event
Notifying VoiceTrigger Trigger!!!!
com.apple.coreaudio.borealisTrigger
com.apple.voicetrigger.nearMiss
Reporting VoiceTrigger two shot detection at time : %lf
isContinuousRunningMode
TB,N,V_isContinuousRunningMode
Error reading audio file: %d, skipping...
numChannels: %lu, recordingDuration: %f, sampleRate: %f
Cannot copy samples since this is empty
Could NOT copyFrom: %lu to: %lu, retSampleCount: %lu
copyBuffer: oldestSample: %lu latestSample: %lu, numSamplesCopied: %lu
CSAudioCircularBuffer.reset
saveRecordingBufferFrom: %lu to: %lu toURL: %@
csrb: %@
-ch%zu.wav
Invalid request: (%lu, %lu): noting to write to file
bufferLength
TQ,N,V_bufferLength
Invalid request: reqStartSample=%lu, reqEndSample=%lu, oldestSampleInBuffer: %lu, latestSampleInBuffer=%lu
  mNumChannels: 
  mRecordingDurationInSecs: 
  mSampleRate: 
  mBytesPerSample: 
  mBufferLengthInSamples: 
  mNextWritePos: 
  mSamplesCount: 
  mMemoryPool(
): [
    chan-
: sz=
: mem-sz: 
speakerDetectorNDAPI
configPath
retrainTriggerThreshold
speakerDetectorNDAPIConfigPath
speakerDetectorThreshold
speakerDetectorRetrainTriggerThreshold
{wordCount: %ld, trailingSilDuration: %ld, eosLikelihood: %f, pauseCounts: %@, silencePosterior: %f, taskName: %@, processedAudioDurationInMilliseconds: %ld}
wordCount
Tq,N,V_wordCount
trailingSilenceDuration
Tq,N,V_trailingSilenceDuration
eosLikelihood
Td,N,V_eosLikelihood
pauseCounts
T@"NSArray",C,N,V_pauseCounts
silencePosterior
Td,N,V_silencePosterior
processedAudioDurationInMilliseconds
Tq,N,V_processedAudioDurationInMilliseconds
taskName
T@"NSString",C,N,V_taskName
com.apple.cs.%@.apQueue
VAD2 preheat...
CSVAD2EndpointAnalyzer: resetForNewRequestWithSampleRate
%@ Resetting with style %ld
_audioUnitEPVAD2=%p, auNeedsReset: %zd
Failed to reset EPVAD2: %d
VAD2::RecordingDidStop: Ignoring processAudioSamplesAsynchronously, not queueing
VAD2::RecordingDidStop: Ignoring processAudioSamplesAsynchronously from async
Already communicated endpoint...returning
VAD2::RecordingDidStop: Ignoring _processAudioSamples
Empty samplesBuffer!
Received audio buffer with 8 frames of zeroes
Not configured
done: %zd, _detectedOneShotStartpoint: %zd, _communicatedEndpointDetection: %zd, _startWaitTime: %f_samplesSeen: %f, _delay: %f, _sampleRate: %f(_startWaitTime + _delay) * _sampleRate): %f, (_samplesSeen / _sampleRate): %f, _automaticEndpointingSuspensionEndTime: %f
No startpoint detected after %f, timing out
Ignoring recurrent endpoint at %f becuase it's too early (< %f)
Fell back to recurrent endpoint (%f) because one-shot is too early (%f < %f)
Reporting EndpointDetection: delegate=%@ atTime: %f
endpointStyle
Tq,N
delay
Td,N
startWaitTime
automaticEndpointingSuspensionEndTime
minimumDurationForEndpointer
lastEndOfVoiceActivityTime
Td,R,N
lastStartOfVoiceActivityTime
bypassSamples
endpointMode
interspeechWaitTime
endWaitTime
saveSamplesSeenInReset
T@"<CSEndpointAnalyzerDelegate>",W,N
canProcessCurrentRequest
TQ,N
endpointerModelVersion
sampleRate
Td,N,V_sampleRate
frameRate
TI,N,V_frameRate
detectedOneShotStartpoint
TB,N,V_detectedOneShotStartpoint
detectedRecurrentStartpoint
TB,N,V_detectedRecurrentStartpoint
communicatedStartPointDetection
TB,N,V_communicatedStartPointDetection
detectedOneShotEndpoint
TB,N,V_detectedOneShotEndpoint
detectedRecurrentEndpoint
TB,N,V_detectedRecurrentEndpoint
communicatedEndpointDetection
TB,N,V_communicatedEndpointDetection
samplesSeen
Td,N,V_samplesSeen
lastOneShotStartpoint
Td,N,V_lastOneShotStartpoint
lastOneShotEndpoint
Td,N,V_lastOneShotEndpoint
lastRecurrentStartpoint
Td,N,V_lastRecurrentStartpoint
lastRecurrentEndpoint
Td,N,V_lastRecurrentEndpoint
floatSampleBuffer
T@"NSMutableData",&,N,V_floatSampleBuffer
topLevelParameterDict
T@"NSDictionary",&,N,V_topLevelParameterDict
modelDictPath
T@"NSString",&,N,V_modelDictPath
isConfigured
TB,N,V_isConfigured
previousSamplesSeen
Td,N,V_previousSamplesSeen
apQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_apQueue
recordingDidStop
TB,N,V_recordingDidStop
Tq,N,V_endpointStyle
Td,N,V_delay
Td,N,V_startWaitTime
Td,N,V_automaticEndpointingSuspensionEndTime
Td,N,V_minimumDurationForEndpointer
Td,N,V_bypassSamples
Tq,N,V_endpointMode
Td,N,V_interspeechWaitTime
Td,N,V_endWaitTime
TB,N,V_saveSamplesSeenInReset
T@"<CSEndpointAnalyzerDelegate>",W,N,V_delegate
sampleRate: %lf frameRate: %d
Skipping re-initialization of EPVAD2; no audio consumed yet
EPVAD2 reset with existing parameters
Could not find endpointer audio unit component
AU instantiation error: %d
No model available for mode: %d
Error reading plist endpoint model at %@
Could not set kAUEndpointVADProperty_ViterbiModelData: %d
Could not set %@ to %@: %d
kAUEndpointVAD2Property_EDLStartWaitTimeSec
kAUEndpointVAD2Property_EDLInterspeechWaitTimeSec
kAUEndpointVAD2Property_EDLSpeechStartAdjustSec
kAUEndpointVAD2Property_EDLSpeechEndAdjustSec
kAUEndpointVAD2Property_EDLWindowLengthSeconds
kAUEndpointVAD2Property_EDLSpeechFraction
kAUEndpointVAD2Property_EDLNonspeechFraction
kAUEndpointVAD2Property_IsRealtimeOperationMode
kAUEndpointVAD2Property_DecoderLatencySeconds
kAudioUnitProperty_MaximumFramesPerSlice
Could not initialize audio unit: %d
Endpointer is configured
Unexpected block size of %u, not %u. Skipping this block of audio.
Could not process audio via endpointer: %d
Library/Audio/Tunings/Generic/AU/
tuningLibraryPath: %@
aufx-epv2-bluetooth8khz-appl.plist
aufx-epv2-appl.plist
VAD2-epModelPath: %@
Could not read kAUEndpointVAD2Property_LatestEndpointerEventTimeSeconds: %d
Found one shot startpoint at %.3f seconds
Found one shot endpoint at %.3f seconds
Could not read kAUEndpointVAD2Property_LatestRecurrentVADEventTimeSeconds: %d
Found recurrent startpoint at %.3f seconds
Found recurrent endpoint at %.3f seconds
Cannot generate subChunk since channel(%tu) is larger than number of channels(%tu)
Cannot generate subChunk if it reuqest more than it has : %tu %tu %tu
data
T@"NSData",R,N,V_data
TQ,R,N,V_numChannels
TQ,R,N,V_numSamples
TQ,R,N,V_sampleByteDepth
TQ,R,N,V_startSampleCount
TQ,R,N,V_hostTime
early_warning
is_rescoring
sampleFed
TQ,N,V_sampleFed
bestPhrase
TQ,N,V_bestPhrase
bestStart
TQ,N,V_bestStart
bestEnd
TQ,N,V_bestEnd
bestScore
Tf,N,V_bestScore
earlyWarning
TB,N,V_earlyWarning
isRescoring
TB,N,V_isRescoring
dictionary
T@"NSDictionary",R,N
Fired VoiceTrigger Timeout
Stop right now since ASR has issue
EOS Timeout Fired
AudioSession Started
AudioSession Stopped
unknown endpoint type
Non Final: [%@]
NON Final Matching
Final: [%@]
Final Matching
Final Not Matching
SPEECH RECOGNITION TASK FINISH UNSUCCESSFULLY
%@ %@ %ld %@
Recog Result: [%ld]
SearchOrMessaging
Warmup
Median
ExtraDelayMs
EndpointerDecisionLagMs
CSEndpointAsset: %@, path: %@
com.apple.cs.%@.stateserialqueue
com.apple.cs.%@.sepfQueue
com.apple.cs.%@.hybridClassifierfQueue
HEP::RecordingDidStop: Ignoring processAudioSamplesAsynchronously: Not queueing
HEP::RecordingDidStop: Ignoring processAudioSamplesAsynchronously
addAudio first sample offset: %lu
Updated endpointer threshold: %f
Updated endpointer delayed trigger: %d
EARSPG: CSServerEndpointFeatures: %@
ERROR: Unexpected RC-query: sfLatency: %f, rcTimeMs: %f
rcEpFeatures: %@ shouldAccept: %d
HEP::RecordingDidStop: Ignoring silenceScoreEstimateAvailable, Not queuing
silposnf=%f, clientProcessedAudioMs: %f, effectiveClientProcessedAudioMs: %lu
HEP::RecordingDidStop: Ignoring silenceScoreEstimateAvailable
Already communicated end-pt: Not Invoking hybridClassifier for silposnf=%f
serverProcessedAudioMs(%ld) > effectiveClientProcessedAudioMs(%f)
Not Invoking HybridClassifier as serverProcessedAudioMs > effectiveClientProcessedAudioMs
EARSPG: Invoking HybridClassifier with parameters: %@ at effectiveClientProcessedAudioMs: %lu, endpointPosterior: %f, result: %d
ServerFeaturesLatencyDistribution: %@ additionalMetrics: %@
Already communicated end-pt: Not scheduling work for hybridClassifierQueue for silposnf=%f
unsorted-serverFeatureLatencies: %@
q24@?0@8@16
triggerEndSeconds: %f, _vtEndInSampleCount: %lu, _vtExtraAudioAtStartInMs: %lu, voiceTriggerInfo: %@
CSHybridEndpointAnalyzer recordingStoppedForReason: %lu
CSHybridEndpointer resetForNewRequestWithSampleRate: %lu
CSEndpointAsset exists: %@
No asset for CSHybridEndpointer for currentLanguage: %@. Fallback to VAD2
Created EARCaesuraSilencePosteriorGenerator: %@
Created HybridClassifier(%@); canProcessCurrentRequest after reset: %zd, for sampleRate: %lu, lang=%@, version=%@
/BuildRoot/Library/Caches/com.apple.xbs/Sources/CoreSpeech_Sim/CoreSpeech-65.1/CoreSpeech/CSHybridEndpointAnalyzer.m
CSHybridEndpointAnalyzer reset called
language changed to: %@: CSHybridEndpointer new asset: %@
numSamplesProcessed
TQ,N,V_numSamplesProcessed
didAddAudio
TB,N,V_didAddAudio
caesuraSPG
T@"EARCaesuraSilencePosteriorGenerator",&,N,V_caesuraSPG
TB,N,V_canProcessCurrentRequest
hybridClassifier
T@"_EAREndpointer",&,N,V_hybridClassifier
T@"NSString",&,N,V_endpointerModelVersion
serverFeaturesQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_serverFeaturesQueue
lastKnownServerEPFeatures
T@"CSServerEndpointFeatures",&,N,V_lastKnownServerEPFeatures
serverFeatureLatencies
T@"NSMutableArray",&,N,V_serverFeatureLatencies
serverFeaturesWarmupLatency
Td,N,V_serverFeaturesWarmupLatency
lastServerFeatureTimestamp
T@"NSDate",&,N,V_lastServerFeatureTimestamp
hybridClassifierQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_hybridClassifierQueue
lastReportedEndpointTimeMs
Td,N,V_lastReportedEndpointTimeMs
nfhatAtLastReportedEndpoint
Tf,N,V_nfhatAtLastReportedEndpoint
stateSerialQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_stateSerialQueue
didCommunicateEndpoint
TB,N,V_didCommunicateEndpoint
currentRequestSampleRate
TQ,N,V_currentRequestSampleRate
vtExtraAudioAtStartInMs
Td,N,V_vtExtraAudioAtStartInMs
vtEndInSampleCount
TQ,N,V_vtEndInSampleCount
firstAudioPacketTimestamp
T@"NSDate",&,N,V_firstAudioPacketTimestamp
didTimestampFirstAudioPacket
TB,N,V_didTimestampFirstAudioPacket
Delta is larger than anchorHostTime
Delta is larger than anchorSampleCount
CSHybridEndpointer canProcessCurrentRequest
CSHybridEndpointer can-NOT-ProcessCurrentRequest, fallback  to VAD2
_activeEndpointer=%@
endpointer: %@: didDetectStartpointAtTime: %f
EP_PROXY::RecordingDidStop: Ignoring startPoint-reporting
EP_PROXY::RecordingDidStop: Ignoring didDetectHardpoint-reporting
CSEndpointerProxy: didDetectHardEndpoint: ep-time: %f, triggerEnd: %f, vad2EndWaitTime: %f, delta: %f, legacyTwoShotThreshold: %f, enterTwoShot: %zd
EP_PROXY::RecordingDidStop: Ignoring VAD2 2-shot reporting
CSEndpointerProxy didDetectHardEndpoint using for 1-2 shot at Time: %f
EP_PROXY::RecordingDidStop: Ignoring didDetectHardEndpointAtTime:
%@: Endpointer didDetectHardEndpointAtTime:withMetrics: %f, CallingDelegate: %@
WARN: endpointerModelVersion called when CSHybridEndpointer is not available
hybridEndpointer
T@"<CSEndpointAnalyzerImpl>",&,N,V_hybridEndpointer
vad2Endpointer
T@"<CSEndpointAnalyzerImpl>",&,N,V_vad2Endpointer
activeEndpointer
T@"<CSEndpointAnalyzerImpl>",W,N,V_activeEndpointer
didEnterTwoshot
TB,N,V_didEnterTwoshot
endpointerDelegate
T@"<CSEndpointAnalyzerDelegate>",W,N,V_endpointerDelegate
Stop monitoring : First unlock
Start monitoring : Springboard start
Cannot start monitoring Springboard start because it was already started
Stop monitoring : Springboard start
SpringBoard started = %@
com.apple.springboard.finishedstartup
com.apple.transcribe.Transcriber
Transcriber trigger token list: %@
Initializing Quasar with config: %@
Speech model loading took %.3fms
Failed initialization in _EARSpeechRecognizer initWithConfiguration
runRecognition failed
endAudio failed
recognizeWavData failed
Partial result confidence: %f
ERROR: %s
Final result confidence: %f
EAR Token[%lu]: %s (%f)
v32@?0@"_EARSpeechRecognitionToken"8Q16^B24
triggerConfidence
Td,R,N,V_triggerConfidence
T@"<CSKeywordAnalyzerQuasarScoreDelegate>",W,N,V_delegate
corespeech.json
hybridendpointer.json
hybridendpointer_marsh.json
/BuildRoot/Library/Caches/com.apple.xbs/Sources/CoreSpeech_Sim/CoreSpeech-65.1/CoreSpeech/CSAsset.m
ERR: Unknown assetType: %lu
Fallback asset resource path : %@
Cannot find corespeech asset from resourcePath : %@
Configuration file is not exists : %@
Cannot read configuration file : %@
Cannot decode configuration json file : %@
Configuration json file is not expected format
version
Cannot access to %@ %@ using default value
path
T@"NSString",R,N,V_path
resourcePath
T@"NSString",R,N,V_resourcePath
assetVersion
hashFromResourcePath
There is not audio buffer to convert. Skip this.
Got asked for %u packets, have %u
/BuildRoot/Library/Caches/com.apple.xbs/Sources/CoreSpeech_Sim/CoreSpeech-65.1/CoreSpeech/CSAudioConverter.m
Too many buffers
Cannot produce ASPD for PCM
i32@?0^I8^{AudioBufferList=I[1{AudioBuffer=II^v}]}16^^{AudioStreamPacketDescription}24
[%02u of %02u] Opus packet with %u bytes
AudioConverter is sad: 0x%{public}xd
%d bytesConsumed from opus coverter, remains %d bytes
Resetting AudioConverter buffer
createAudioConverter : initial frames per buffer = dur %.2f * sr %.2f = %u
_configureAudioConverter: encoded audio needs minimum of %u bytes per output buffer
_configureAudioConverter: AudioConverterGetProperty(kAudioConverterPropertyMinimumOutputBufferSize) returned status %d
_configureAudioConverter: final framesPerBuffer: %u
_configureAudioConverter: _convertPacketCount: %u
_configureAudioConverter: AudioConverterGetProperty(MaximumOutputPacketSize): returned status %d
createAudioConverter: outputSizePerPacket: %u
_configureAudioConverter: _convertAudioCapacity %u bytes
T@"<CSAudioConverterDelegate>",W,V_delegate
Cannot create AudioConverter using AudioConverterNew
Cannot set encoder bit rate : %u
Start monitoring : Siri language code
Stop monitoring : Siri language code
Siri language changed to : %@
Serial CSPolicy queue
CSSelfVoiceTriggerDetector Queue
Output NDAPI second pass best score = %f for channel = %tu
Notifying self trigger detected
com.apple.siri.corespeech.selftrigger
outputAudioChannel
TQ,N,V_outputAudioChannel
SAT successfully initialized : %@
SAT Score = %f, threshold = %f
T@"<CSSpeakerDetectorNDAPIDelegate>",W,N,V_delegate
Cannot create CSVTUIKeywordDetector since there is no asset available
Cannot create CSVTUIKeywordDetector since we cannot initialize NDAPI
AVVC initialization failed
Trying to set record buffer duration : %lf
Failed setting record buffer duration. Duration is %{public}lf
Creating beep canceller...
Failed to deinterleave the data: %d
Cannot create de-interleaver using AudioConverterNew: %d
Created de-interleaver
T@"<CSAudioRecorderDelegate>",W,N,V_delegate
twoShotDecisionWaitTime
CVTConfigPathNDAPI
CVTThreshold
CVTTwoShotThreshold
CVTTwoShotDecisionWaitTime
CSKeywordDetector Queue
Setting decisionWaitSampleCount at %tu (%.3f) given vtEndSampleCount at %tu (%.3f)
Keyword detected at %tu with %.3f confidence
Keyword NOT detected at %tu with %.3f confidence
T@"CSKeywordAnalyzerQuasar",&,N,V_keywordAnalyzer
analyzedSampleCount
TQ,N,V_analyzedSampleCount
decisionWaitSampleCount
TQ,N,V_decisionWaitSampleCount
((?:[a-z]|[0-9])*)\.asset
Failed to create regular expression : %@
nohash
::: Error creating output file %@, err: %d
::: Error writing to output wave file.
init
CVTConfigPathNDAPI
resourcePath
alloc
initWithConfigPath:resourcePath:
setDelegate:
setActiveChannel:
CVTThreshold
inputRecordingSampleRate
CVTTwoShotDecisionWaitTime
CVTTwoShotThreshold
_reset
reset
objectForKeyedSubscript:
doubleValue
numSamples
channelForProcessedInput
subChunkFrom:numSamples:forChannel:
processAudioChunk:
_shotAnalyzerNDAPI:hasResultAvailable:forChannel:
_keywordAnalyzerNDAPI:hasResultAvailable:forChannel:
floatValue
unsignedIntValue
resetBest
supportCSTwoShotDecision
voiceTriggerDidDetectTwoShotAtTime:
respondsToSelector:
numberWithFloat:
numberWithBool:
numberWithUnsignedInteger:
dictionaryWithObjects:forKeys:count:
voiceTriggerDidDetectKeyword:
isEqual:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
retain
release
autorelease
retainCount
zone
hash
superclass
description
debugDescription
keywordAnalyzerNDAPI:hasResultAvailable:forChannel:
speechManagerRecordBufferAvailable:buffer:
speechManagerLPCMRecordBufferAvailable:chunk:
speechManagerDidStartForwarding:successfully:error:
speechManagerDidStopForwarding:forReason:
speechManagerRecordingContext
initWithManager:asset:
startDetectTwoShot:
.cxx_destruct
delegate
speechManager
setSpeechManager:
queue
setQueue:
currentAsset
setCurrentAsset:
keywordAnalyzer
setKeywordAnalyzer:
keywordThreshold
setKeywordThreshold:
mode
setMode:
totalSampleCounts
setTotalSampleCounts:
lastFireSampleCount
setLastFireSampleCount:
twoShotDecisionWaitSamples
setTwoShotDecisionWaitSamples:
twoShotThreshold
setTwoShotThreshold:
_keywordThreshold
_twoShotThreshold
_delegate
_speechManager
_queue
_currentAsset
_keywordAnalyzer
_mode
_totalSampleCounts
_lastFireSampleCount
_twoShotDecisionWaitSamples
length
initWithLength:
bytes
mutableBytes
convertToFloatLPCMBufFromShortLPCMBuf:
convertToShortLPCMBufFromFloatLPCMBuf:
modelDirectory
_createDirectoryIfNotExist:
utteranceDirectory
defaultManager
fileExistsAtPath:isDirectory:
removeItemAtPath:error:
createDirectoryAtPath:withIntermediateDirectories:attributes:error:
localizedDescription
sharedPreferences
baseDir
stringByAppendingPathComponent:
_satPath
hashFromResourcePath
array
contentsOfDirectoryAtPath:error:
predicateWithFormat:
filteredArrayUsingPredicate:
caseInsensitiveCompare:
sortedArrayUsingSelector:
countByEnumeratingWithState:objects:count:
addObject:
count
modelPath
fileExistsAtPath:
_isDirectoryEmpty:
initWithAsset:languageCode:
enrollmentUtterance
needsRetrain
isValid
_asset
_languageCode
_modelPath
_utteranceDirectory
_isValid
VTFirstPassThreshold
VTFirstPassConfigPathNDAPI
inputRecordingProcessingChannelsBitset
iterateBitset:block:
_transitVoiceTriggerStatus:
setCallback:
isEnabled
_startVoiceTrigger
_stopVoiceTrigger
startRecordingWithSetting:event:error:
stopRecordingWithEvent:
voiceTriggerFirstPass:didDetectKeyword:
voiceTriggerStartPolicy
setVoiceTriggerStartPolicy:
voiceTriggerEnabled
setVoiceTriggerEnabled:
keywordAnalyzersNDAPI
setKeywordAnalyzersNDAPI:
hasTriggerPending
setHasTriggerPending:
firstPassThreshold
setFirstPassThreshold:
_voiceTriggerEnabled
_hasTriggerPending
_firstPassThreshold
_voiceTriggerStartPolicy
_keywordAnalyzersNDAPI
setDelayInterstitialSounds:level:
inputRecordingSampleByteDepth
inputRecordingFramesPerPacket
inputRecordingBytesPerFrame
inputRecordingBytesPerPacket
inputRecordingNumberOfChannels
inputRecordingDurationInSecs
inputRecordingSampleBitDepth
inputRecordingEncoderAudioQuality
inputRecordingSampleRateConverterAlgorithm
inputRecordingBufferDuration
audioConverterBitrate
channelForOutputReference
weakObjectsHashTable
_createListenPollingTimer
_setupStateMachine
_setupCircularBuffer
defaultCenter
mediaserverdDidRestart
addObserver:selector:name:object:
_setupVoiceTrigger
sharedInstance
addObserver:
removeObserver:
dealloc
supportContinuousVoiceTrigger
shouldRunVTOnCS
defaultFallBackAssetForVoiceTrigger
initWithAudioBuffer:
registerObserver:
containsObject:
removeObject:
supportSelfTriggerSuppression
supportKeywordDetector
initWithNumChannels:recordingDuration:samplingRate:
initWithInitialState:
addTransitionFrom:to:for:
currentState
_notifyEvent:
_eventName:
performTransitionForEvent:
audioRecorder
initWithContext:error:
setAudioRecorder:
isRecording
setCurrentContext:error:
prepareRecordWithSettings:error:
prewarmAudioSession
recordRoute
recordSettings
_createRecorderWithContextIfNeeded:error:
_prepareRecorderWithSettings:error:
startRecordingWithSettings:error:
releaseClientAudioSession:
_releaseClientAudioSession:
_releaseAudioSessionForListening:
_setRecordMode:error:
releaseAudioSession:
sampleCount
_setCurrentContext:error:
_startRecordingWithSettings:error:
_startRecordingForClient:error:
unsignedIntegerValue
supportOpportunisticZLL
unsignedLongLongValue
sampleCountFromHostTime:
stopRecording
_stateName:
_stopFirstPassVoiceTrigger
_stopSelfTriggerDetector
_stopSecondPassVoiceTrigger
_stopForwardingToClient
_stopContinuousVoiceTrigger
_stopKeywordDetector
_startFirstPassVoiceTrigger
_startSelfTriggerDetector
_startSecondPassVoiceTrigger
_startForwardingToClient
_startContinuousVoiceTrigger
_startKeywordDetector
_startListenPolling
voiceTriggerRecordContext
lpcmRecordSettings
_prepareListenWithSettings:error:
_startListening:
_stopListenPolling
setIsContinuousRunningMode:
_getClientRecordContext
isRecordContextVoiceTrigger:
voiceTriggerInfo
startDetectKeyword:
addSamples:numSamples:atHostTime:
notifyEvent:
bufferLength
copySamplesFrom:to:
hostTimeFromSampleCount:
_changeLanguageCode
numberWithInteger:
stringWithFormat:
audioRecorderBufferAvailable:buffer:atTime:
audioRecorderBufferAvailable:buffer:
audioRecorderDidStartRecording:successfully:error:
audioRecorderDidStopRecording:forReason:
audioRecorderRecordHardwareConfigurationDidChange:toConfiguration:
audioRecorderBeginRecordInterruption:
audioRecorderBeginRecordInterruption:withContext:
audioRecorderEndRecordInterruption:
voiceTriggerDetectedOnAOP:
didTransitFrom:to:by:
didIgnoreEvent:from:
voiceTriggerDidDetectNearMiss:
voiceTriggerDidDetectSpeakerReject:
keywordDetectorDidDetectKeyword
CSLanguageCodeUpdateMonitor:didReceiveLanguageCodeChanged:
initWithVoiceTriggerFirstPass:voicetriggerSecondPass:voicetriggerEventNotifier:audioRecorder:
registerSpeechController:
getCurrentState
isClientRecording
setClientContext:error:
prepareRecordingForClient:error:
releaseClientAudioSession
stateMachine
setStateMachine:
audioBuffer
setAudioBuffer:
currentVoiceTriggerAsset
setCurrentVoiceTriggerAsset:
voiceTriggerFirstPass
setVoiceTriggerFirstPass:
voiceTriggerSecondPass
setVoiceTriggerSecondPass:
clientController
setClientController:
voiceTriggerEventNotifier
setVoiceTriggerEventNotifier:
voiceTriggerFileLogger
setVoiceTriggerFileLogger:
selfTriggerDetector
setSelfTriggerDetector:
continuousVoiceTrigger
setContinuousVoiceTrigger:
keywordDetector
setKeywordDetector:
myriad
setMyriad:
voiceTriggerFidesClient
setVoiceTriggerFidesClient:
activeAudioProcessors
setActiveAudioProcessors:
lastForwardedSampleCount
setLastForwardedSampleCount:
secondPassStartSampleCount
setSecondPassStartSampleCount:
clientStartSampleCount
setClientStartSampleCount:
recordingPendingTimeout
setRecordingPendingTimeout:
lastVoiceTriggerEventInfo
setLastVoiceTriggerEventInfo:
listenPollingTimer
setListenPollingTimer:
_audioRecorder
_stateMachine
_audioBuffer
_currentVoiceTriggerAsset
_voiceTriggerFirstPass
_voiceTriggerSecondPass
_clientController
_voiceTriggerEventNotifier
_voiceTriggerFileLogger
_selfTriggerDetector
_continuousVoiceTrigger
_keywordDetector
_myriad
_voiceTriggerFidesClient
_activeAudioProcessors
_lastForwardedSampleCount
_secondPassStartSampleCount
_clientStartSampleCount
_recordingPendingTimeout
_lastVoiceTriggerEventInfo
_listenPollingTimer
lowercaseString
hasPrefix:
substringFromIndex:
regularExpressionWithPattern:options:error:
mutableCopy
replaceMatchesInString:options:range:withTemplate:
_stringByStrippingLeadingNoise:
_stringByStrippingTrailingNoise:
rangeOfString:options:
numberOfMatchesInString:options:range:
stringValue
isEqualToString:
_firstMatchesForRegularExpression:
firstMatchInString:options:range:
numberOfRanges
rangeAtIndex:
substringWithRange:
_stringByFixingNamePattern:
_stringByStrippingNoiseLeadingNoise:TrailingNoise:
_hasSubstring:
_matchesRegularExpression:
_caseInsensitiveHasMatchInEnumeration:
_firstMatchesForRegularExpressions:
getVoiceTriggerAssetTypeString
getEndpointAssetTypeString
_fetchRemoteMetaData
assetOfType:language:
_isReadyToUse
predicateForAssetType:language:
installedAssetOfType:withPredicate:
_fetchRemoteAssetOfType:withPredicate:
_installedAssetOfType:withPredicate:
getCSAssetOfType:
_assetQueryForAssetType:withPredicate:localOnly:
runQueryAndReturnError:
predicate
_findLatestInstalledAsset:
state
isLatestCompareTo:
initWithAssetType:
setPredicate:
setQueriesLocalAssetInformationOnly:
startQuery:
isSpringboardStarted
isFirstUnlocked
predicateForfetchRemoteMetadataForAssetType:
_runAssetQuery:completion:
_updateFromRemoteToLocalAssets:
isInstalled
isDownloading
cancelDownloadAndReturnError:
path
purgeAndReturnError:
_downloadAsset:withComplete:
_startDownloadingVoiceTriggerAsset:progress:completion:
objectForKey:
setProgressHandler:
requiredDiskSpaceIsAvailable:error:
_defaultDownloadOptions
beginDownloadWithOptions:
resumeDownload:
adjustDownloadOptions:completion:
sharedManager
assetForCurrentLanguageOfType:
installedAssetOfType:language:
currentLanguageCode
_csAssetsDictionary
_enablePolicy
_currentLanguageCode
getVoiceTriggerAssetCurrentCompatibilityVersion
getEndpointAssetCurrentCompatibilityVersion
supportPremiumAssets
componentsJoinedByString:
predicateWithFormat:argumentArray:
getStringForKey:category:default:
getNumberForKey:category:default:
setupPhraseSpotter
startMasterTimerWithTimeout:
resultAlreadyReported
stopMasterTimer
closeSessionWithStatus:successfully:complete:
closeSessionWithCompletion:
removeAllObjects
updateMeterAndForward
pushAudioInputIntoPCMBuffer:
requestTriggeredUtterance:
sharedTrainer
trainUtterance:languageCode:
setupSpeechRecognitionTaskWithVoiceTriggerEventInfo:
trimBeginingOfPCMBufferWithVoiceTriggerEventInfo:
computeRequiredTrailingSamples
feedSpeechRecognitionWithPCMBuffer
closeSessionWithStatus:successfully:
handleAudioBufferForVTWithAudioInput:withDetectedBlock:
finishSpeechRecognitionTask
feedSpeechRecognitionTrailingSamplesWithCompletedBlock:
triggeredUtterance:
updateMeters
averagePower
CSVTUITrainingSessionRMSAvailable:
analyze:
boolValue
numSamplesInPCMBuffer
objectAtIndex:
appendAudioPCMBuffer:
removeObjectAtIndex:
frameLength
initWithCommonFormat:sampleRate:channels:interleaved:
initWithPCMFormat:frameCapacity:
mutableAudioBufferList
setFrameLength:
replaceObjectAtIndex:withObject:
removeObjectsInRange:
createAVAudioPCMBufferWithNSData:
handleAudioInput:
sharedGrammars
getLMEforLocale:
setContextualStrings:
setTaskHint:
setObject:forKey:
_setVoiceTriggerEventInfo:
recognitionTaskWithRequest:delegate:
endAudio
finish
handleMasterTimeout:
scheduledTimerWithTimeInterval:target:selector:userInfo:repeats:
invalidate
formattedString
whitespaceAndNewlineCharacterSet
stringByTrimmingCharactersInSet:
speechRecognitionDidDetectSpeech:
speechRecognitionTask:didHypothesizeTranscription:
speechRecognitionTask:didFinishRecognition:
speechRecognitionTaskFinishedReadingAudio:
speechRecognitionTaskWasCancelled:
speechRecognitionTask:didFinishSuccessfully:
audioSessionDidStartRecording:error:
audioSessionDidStopRecording:
audioSessionRecordBufferAvailable:
audioSessionUnsupportedAudioRoute
audioSessionErrorDidOccur:
didDetectBeginOfSpeech
didDetectEndOfSpeech:
initWithUtteranceId:sessionNumber:Locale:audioSession:keywordDetector:speechRecognizer:speechRecognitionRequest:sessionDelegate:sessionDispatchQueue:completion:
startTraining
suspendTraining
resumeTraining
_status
_utteranceId
_sessionNumber
_locale
_audioSession
_speechRecognizer
_speechRecognitionRequest
_speechRecognitionTask
_masterTimer
_pcmBufArray
_resultReported
_sessionProcess
_sessionSuspended
_ASRErrorOccured
_sessionDelegate
_trainingCompletion
_numRequiredTrailingSamples
_numTrailingSamples
initWithManager:
UTF8String
_contextToString:
_getRecordSettings
_setupAudioConverter:
wavFileASBD
duckOthersOption
setDuckOthersOption:
_isVoiceTriggered
_currentAudioRecorderSampleRate
resetForNewRequestWithSampleRate:
dataForChannel:
hostTime
addSamples:timestamp:
speechControllerLPCMRecordBufferAvailable:buffer:
processAudioSamplesAsynchronously:
channels
packetDescriptionCount
bytesDataSize
initWithCapacity:
data
packetDescriptions
initWithBytes:length:
timeStamp
speechControllerRecordBufferAvailable:buffers:recordedAt:
speechControllerDidStartRecording:successfully:error:
recordingStoppedForReason:
flush
speechControllerDidStopRecording:forReason:
setAlertSoundFromURL:forType:
playAlertSoundForType:
alertStartTime
resetEndpointer
setMeteringEnabled:
peakPowerForChannel:
averagePowerForChannel:
passThruVoiceTriggerInfo
speechControllerDidDetectVoiceTriggerTwoShot:atTime:
speechControllerRequestsOperation:forReason:
metrics
setEndpointerDelegate:
processServerEndpointFeatures:
numberWithInt:
numberWithUnsignedInt:
lastEndOfVoiceActivityTime
endpointerModelVersion
updateEndpointerThreshold:
updateEndpointerDelayedTrigger:
shouldAcceptEagerResultForDuration:resultsCompletionHandler:
sharedController
audioConverterDidConvertPackets:packets:timestamp:
initializeRecordSessionWithContext:
preheat
resetAudioSession
releaseAudioSession
getLPCMAudioStreamBasicDescription
setSynchronousCallbackEnabled:
setRecordBufferDuration:
getRecordBufferDuration
startRecording:
isVoiceTriggered
playRecordStartingAlertAndResetEndpointer
peakPowerForOutputReference
averagePowerForOutputReference
outputReferenceChannel
endpointAnalyzer
setEndpointAnalyzerDelegate:
endpointerProxy
setEndpointerProxy:
avvcContext
setAvvcContext:
isOpus
setIsOpus:
isActivated
setIsActivated:
activeChannel
_audioConverter
_requestedRecordSettings
_lastVoiceTriggerInfo
_isOpus
_isActivated
_endpointerProxy
_avvcContext
_activeChannel
_storeModeEnabled
setFileLoggingLevel:
fileLoggingLevel
intValue
CSSATBasePath
URLWithString:
arrayWithObjects:count:
enumeratorAtURL:includingPropertiesForKeys:options:errorHandler:
getResourceValue:forKey:error:
lastPathComponent
getUserVoiceProfileUploadPathWithEnrolledLanguageList:
_CSSATUploadPath
_getEnrolledLanguageList
enumeratorAtPath:
_isDirectory:
pathExtension
copyItemAtPath:toPath:error:
_CSSATUpdatePath
_markSATEnrollmentSuccessForLanguageCode:
createFileAtPath:contents:attributes:
initialize
voiceTriggerInCoreSpeech
setFileLoggingIsEnabled:
fileLoggingIsEnabled
voiceTriggerAudioLogDirectory
getUserVoiceProfileFileList
getUserVoiceProfileUploadPath
notifyUserVoiceProfileUploadComplete
getUserVoiceProfileUpdateDirectory
notifyUserVoiceProfileUpdateReady
dictionary
setObject:forKeyedSubscript:
integerValue
transitions
setTransitions:
_currentState
_transitions
_stopMonitoring
_startMonitoringWithQueue:
enumerateObservers:
CSEventMonitorDidReceiveEvent:
stringWithUTF8String:
currentHandler
handleFailureInMethod:object:file:lineNumber:description:
enumerateObserversInQueue:
notifyObserver:
_observers
utteranceFileASBD
_closeAudioFile
fileURLWithPath:isDirectory:
startRecording
appendAudioData:
_audioFile
_asbd
_url
_audioLength
setDateFormat:
date
stringFromDate:
_audioLogDirectory
_timeStampString
dataWithJSONObject:options:error:
writeToFile:atomically:
_metaFilenameWithPrefix:
stringByReplacingOccurrencesOfString:withString:
saveRecordingBufferFrom:to:toURL:
_writeDictionary:toPath:
VTSecondPassExtraSamplesAtStart
VTSecondPassConfigPathNDAPI
VTSecondPassThreshold
VTSecondPass2ndChanceThreshold
VTSecondPassLoggingThreshold
VTSecondPassConfigPathRecognizer
VTSecondPassUserKeywordSpotting
VTSecondPassRecognizerThresholdOffset
VTSecondPassRecognizerScoreScaleFactor
VTSecondPassRecognizerToken
_addVoiceTriggerEnabledConditions
_subscribeEventMonitors
subscribeEventMonitor:
addConditions:
opusRecordSettings
pHash:length:
signalEstimate
dataWithCapacity:
appendBytes:length:
_generateMyriadInfo:score:
setSignalEstimate:
_signalEstimate
initWithBundleIdentifier:
isPermitted
shouldMakeRecordWithFrequency:
_lastTriggerDataWithResult:
_fidesRecordInfo
addEntriesFromDictionary:
UUIDString
saveRecordWithData:recordInfo:completion:
_logDESRecordWithType:result:
numChannels
sampleByteDepth
startSampleCount
numberWithUnsignedLongLong:
matchWithString:TrailingStr:LeadingStr:Pattern:
createGrammars
bundleForClass:
bundlePath
dataWithContentsOfFile:
JSONObjectWithData:options:error:
_getTrailingPatternsWithGrammars:withLocale:
_getLeadingPatternsWithGrammars:withLocale:
_getRegexPatternsWithGrammars:withUtt:withLocale:
_getLMEWithGrammar:withLocale:
URLSession:didBecomeInvalidWithError:
URLSession:didReceiveChallenge:completionHandler:
URLSessionDidFinishEventsForBackgroundURLSession:
getTrailingPatternsForUtt:Locale:
getLeadingPatternsForUtt:Locale:
getRegexPatternsForUtt:Locale:
_grammar
initWithLocaleIdentifier:withAudioSession:
setLocaleIdentifier:
createKeywordDetector
initWithLanguageCode:
localeWithLocaleIdentifier:
initWithLocale:
_stopAudioSession
destroySpeakerTrainer
_destroyAudioSession
_setupAudioSession
closeSessionBeforeStartWithStatus:successfully:withCompletion:
_createAudioAnalyzer
_shouldShowHeadsetDisconnectionMessage
_startAudioSession
createSpeechRecognizer
sharedtrainingSessionQueue
_audioSource
audioSource
prepareRecord
hasCorrectAudioRoute
VTUITrainingManagerFeedLevel:
resetEndPointer
VTUITrainingManagerStopListening
trainingManagerWithLocaleID:
CSVTUITrainingSessionStopListen
endpointer:didDetectStartpointAtTime:
endpointer:didDetectHardEndpointAtTime:withMetrics:
_beginOfSpeechDetected
_endOfSpeechDetected
cleanupWithCompletion:
trainUtterance:shouldUseASR:completion:
cancelTrainingForID:
suspendAudio
setSuspendAudio:
startRMS
stopRMS
shouldPerformRMS
didDetectForceEndPoint
VTUITrainingSessionStopListen
setRms:
speechRecognizerAvailable
_performRMS
_audioAnalyzer
_trainingSessions
_currentTrainingSession
_suspendAudio
_cleanupCompletion
_speechRecognizerAvailable
_rms
_resetStartAnalyzeTime
_setStartAnalyzeTime:
analyzeWavData:numSamples:
getAnalyzedResult
sampleFed
initWithResult:
bestStart
setBestStart:
bestEnd
setBestEnd:
getSuperVectorWithEndPoint:
_novDetector
_startAnalyzeSampleCount
_isStartSampleCountMarked
_lastSampleFed
_sampleFedWrapAroundOffset
initWithTotalAudioRecorded:featuresAtEndpoint:endpointerType:serverFeatureLatencyDistribution:additionalMetrics:
totalAudioRecorded
setTotalAudioRecorded:
featuresAtEndpoint
setFeaturesAtEndpoint:
endpointerType
setEndpointerType:
serverFeatureLatencyDistribution
setServerFeatureLatencyDistribution:
additionalMetrics
setAdditionalMetrics:
_totalAudioRecorded
_featuresAtEndpoint
_endpointerType
_serverFeatureLatencyDistribution
_additionalMetrics
localURL
assetForAssetType:resourcePath:
attributes
isPremium
converterInASBD
opusASBD
lpcmInterleavedASBD
lpcmNonInterleavedASBD
aiffFileASBD
_checkVoiceTriggerEnabled
_didReceiveVoiceTriggerSettingChanged:
_notifyObserver:withEnabled:
CSVoiceTriggerEnabledMonitor:didReceiveEnabled:
_didReceiveVoiceTriggerSettingChangedInQueue:
_notifyToken
_isVoiceTriggerEnabled
keywordDetectorThreshold
keywordDetectorConfigPathRecognizer
keywordDetectorWaitTimeSinceVT
initWithAsset:languageCode:speakerModel:
subdataWithRange:
analyzeWavForEnrollment:numSamples:
addLastTriggerToProfile
_saveUtterance:meta:to:
stringByAppendingString:
initWithURL:inputFormat:outputFormat:
addSamples:len:
close
voiceController
setStopOnEndpointEnabled:
setRecordEndpointMode:
setRecordDelegate:
setPlaybackDelegate:
numberWithDouble:
playbackRoute
_hasInputAudioRoute
_hasCorrectInputAudioRoute
_hasCorrectOutputAudioRoute
convertStopReason:
hasAudioRoute
voiceControllerDidStartRecording:successfully:
voiceControllerDidStartRecording:successfully:error:
voiceControllerDidStopRecording:forReason:
voiceControllerDidDetectStartpoint:
voiceControllerDidDetectEndpoint:ofType:
voiceControllerDidDetectEndpoint:ofType:atTime:
voiceControllerEncoderErrorDidOccur:error:
voiceControllerLPCMRecordBufferAvailable:buffer:
voiceControllerRecordHardwareConfigurationDidChange:toConfiguration:
voiceControllerBeginRecordInterruption:
voiceControllerBeginRecordInterruption:withContext:
voiceControllerEndRecordInterruption:
voiceControllerRecordBufferAvailable:buffer:
voiceControllerPlaybackBufferAvailable:buffer:
voiceControllerDidStartPlaying:successfully:
voiceControllerDidStopPlaying:forReason:
voiceControllerDecoderErrorDidOccur:error:
voiceControllerPlaybackHardwareConfigurationDidChange:toConfiguration:
voiceControllerBeginPlaybackInterruption:
voiceControllerEndPlaybackInterruption:
_voiceController
dataWithBytes:length:
beepCancellerDidCancelSamples:buffer:timestamp:
cancelBeepFromSamples:timestamp:
willBeep
.cxx_construct
_beepCanceller
_beepFloatVec
_inverseAutoCorrMatrix
_floatBuffer
_shortBuffer
initWithConfigPath:triggerTokens:useKeywordSpotting:
triggerConfidence
_notifySecondPassReject
runRecognition
processSuperVector:withResult:
_analyzeForKeywordDetection:result:forChannel:
speakerDetector:didDetectSpeaker:
speakerDetector:didDetectSpeakerReject:
keywordAnalyzerQuasar:hasResultAvailable:forChannel:
setBypassForSeconds:
keywordAnalyzerNDAPI
setKeywordAnalyzerNDAPI:
keywordAnalyzerQuasar
setKeywordAnalyzerQuasar:
speakerDetector
setSpeakerDetector:
speakerModel
setSpeakerModel:
secondPassTimeout
setSecondPassTimeout:
numAnalyzedSamples
setNumAnalyzedSamples:
keywordLoggingThreshold
setKeywordLoggingThreshold:
lastScore
setLastScore:
bestKeywordScore
setBestKeywordScore:
bestKeywordStart
setBestKeywordStart:
bestKeywordEnd
setBestKeywordEnd:
extraSamplesAtStart
setExtraSamplesAtStart:
useSAT
setUseSAT:
nearMissDelayTimeout
setNearMissDelayTimeout:
nearMissCandidateDetectedSamples
setNearMissCandidateDetectedSamples:
hasPendingNearMiss
setHasPendingNearMiss:
lastAnalyzerResult
setLastAnalyzerResult:
numBypassSamples
setNumBypassSamples:
recognizerScore
setRecognizerScore:
isRunningRecognizer
setIsRunningRecognizer:
recognizerResultPending
setRecognizerResultPending:
recognizerScoreScaleFactor
setRecognizerScoreScaleFactor:
_useSAT
_hasPendingNearMiss
_isRunningRecognizer
_recognizerResultPending
_keywordLoggingThreshold
_lastScore
_bestKeywordScore
_recognizerScore
_recognizerScoreScaleFactor
_keywordAnalyzerNDAPI
_keywordAnalyzerQuasar
_speakerDetector
_speakerModel
_secondPassTimeout
_numAnalyzedSamples
_bestKeywordStart
_bestKeywordEnd
_extraSamplesAtStart
_nearMissDelayTimeout
_nearMissCandidateDetectedSamples
_lastAnalyzerResult
_numBypassSamples
_notifyTriggerEvent:
_notifyNearMissEvent:
_notifySpeakerReject:
_notifyTwoShotDetectionAt:
_notifyKeywordDetect
unregisterObserver:
isContinuousRunningMode
_isContinuousRunningMode
dataWithLength:
readAudioChunksFrom:block:
_addAssetManagerEnabledConditions
sampleCountFromHostTime:anchorHostTime:anchorSampleCount:
hostTimeFromSampleCount:anchorHostTime:anchorSampleCount:
initWithData:numChannels:numSamples:sampleByteDepth:startSampleCount:hostTime:
stringWithCString:encoding:
absoluteString
createAudioCircularBufferWithDefaultSettings
addSamples:numSamples:
copySamplesFromHostTime:
copyBufferWithNumSamplesCopiedIn:
setBufferLength:
_csAudioCircularBufferImpl
_anchorSampleCount
_anchorHostTime
_bufferLength
speakerDetectorNDAPIConfigPath
speakerDetectorThreshold
speakerDetectorRetrainTriggerThreshold
initWithWordCount:trailingSilenceDuration:eosLikelihood:pauseCounts:silencePosterior:taskName:processedAudioDurationInMilliseconds:
initWithWordCount:trailingSilenceFrames:endOfSilenceLikelihood:pauseCounts:silencePosterior:taskName:
wordCount
setWordCount:
trailingSilenceDuration
setTrailingSilenceDuration:
eosLikelihood
setEosLikelihood:
pauseCounts
setPauseCounts:
silencePosterior
setSilencePosterior:
processedAudioDurationInMilliseconds
setProcessedAudioDurationInMilliseconds:
taskName
setTaskName:
_wordCount
_trailingSilenceDuration
_eosLikelihood
_pauseCounts
_silencePosterior
_processedAudioDurationInMilliseconds
_taskName
_configureWithASBD:andFrameRate:
setLength:
_configureWithSampleRate:andFrameRate:
_processAudioSamples:
_detectVoiceActivityInSamples:numSamples:
replaceBytesInRange:withBytes:length:
_getEndpointMetricsForAudioTimestamp:
endpointStyle
setEndpointStyle:
delay
setDelay:
startWaitTime
setStartWaitTime:
automaticEndpointingSuspensionEndTime
setAutomaticEndpointingSuspensionEndTime:
minimumDurationForEndpointer
setMinimumDurationForEndpointer:
lastStartOfVoiceActivityTime
bypassSamples
setBypassSamples:
endpointMode
setEndpointMode:
interspeechWaitTime
setInterspeechWaitTime:
endWaitTime
setEndWaitTime:
saveSamplesSeenInReset
setSaveSamplesSeenInReset:
canProcessCurrentRequest
handleVoiceTriggerWithActivationInfo:
sampleRate
setSampleRate:
frameRate
setFrameRate:
detectedOneShotStartpoint
setDetectedOneShotStartpoint:
detectedRecurrentStartpoint
setDetectedRecurrentStartpoint:
communicatedStartPointDetection
setCommunicatedStartPointDetection:
detectedOneShotEndpoint
setDetectedOneShotEndpoint:
detectedRecurrentEndpoint
setDetectedRecurrentEndpoint:
communicatedEndpointDetection
setCommunicatedEndpointDetection:
samplesSeen
setSamplesSeen:
lastOneShotStartpoint
setLastOneShotStartpoint:
lastOneShotEndpoint
setLastOneShotEndpoint:
lastRecurrentStartpoint
setLastRecurrentStartpoint:
lastRecurrentEndpoint
setLastRecurrentEndpoint:
floatSampleBuffer
setFloatSampleBuffer:
topLevelParameterDict
setTopLevelParameterDict:
modelDictPath
setModelDictPath:
isConfigured
setIsConfigured:
previousSamplesSeen
setPreviousSamplesSeen:
apQueue
setApQueue:
recordingDidStop
setRecordingDidStop:
_audioUnitEPVAD2
_saveSamplesSeenInReset
_detectedOneShotStartpoint
_detectedRecurrentStartpoint
_communicatedStartPointDetection
_detectedOneShotEndpoint
_detectedRecurrentEndpoint
_communicatedEndpointDetection
_isConfigured
_recordingDidStop
_frameRate
_endpointStyle
_endpointMode
_interspeechWaitTime
_startWaitTime
_endWaitTime
_automaticEndpointingSuspensionEndTime
_minimumDurationForEndpointer
_bypassSamples
_delay
_sampleRate
_samplesSeen
_lastOneShotStartpoint
_lastOneShotEndpoint
_lastRecurrentStartpoint
_lastRecurrentEndpoint
_floatSampleBuffer
_topLevelParameterDict
_modelDictPath
_previousSamplesSeen
_apQueue
copy
dictionaryWithContentsOfFile:
appendData:
_data
_numChannels
_numSamples
_sampleByteDepth
_startSampleCount
_hostTime
bestPhrase
bestScore
earlyWarning
setSampleFed:
setBestPhrase:
setBestScore:
setEarlyWarning:
isRescoring
setIsRescoring:
_earlyWarning
_isRescoring
_bestScore
_sampleFed
_bestPhrase
_bestStart
_bestEnd
isAvailable
_firedVoiceTriggerTimeout
shouldHandleSession
shouldMatchPayload
_firedEndPointTimeout
_registerVoiceTriggerTimeout
_reportStopListening
_registerEndPointTimeout
matchRecognitionResult:withMatchedBlock:withNonMatchedBlock:
bestTranscription
_detectBOS
_ASRResultReceived
_reportedStopListening
addAudio:numSamples:
updateEndpointerThresholdWithValue:
updateEndpointerDelayedTriggerSwitch:
timeIntervalSinceDate:
initWithWordCount:trailingSilenceDuration:endOfSentenceLikelihood:pauseCounts:silencePosterior:silencePosteriorNF:serverFeaturesLatency:eagerResultEndTime:
acceptEagerResultWithFeatures:featuresToLog:
initWithWordCount:trailingSilenceDuration:endOfSentenceLikelihood:pauseCounts:silencePosterior:silencePosteriorNF:serverFeaturesLatency:
didEndpointWithFeatures:audioTimestamp:featuresToLog:endpointPosterior:extraDelayMs:
silencePosteriorNF
getFrameDurationMs
serverFeaturesLatencyDistributionDictionary
dictionaryWithDictionary:
sortUsingComparator:
objectAtIndexedSubscript:
initWithConfigFile:
initWithConfiguration:modelVersion:
defaultServerEndpointFeatures
isHybridEndpointerAvailableForCurrentPlatform
requestSupportedWithSamplingRate:
endOfSentenceLikelihood
silenceScoreEstimateAvailable:clientProcessedAudioMs:
silenceDurationEstimateAvailable:numEstimates:clientProcessedAudioMs:
setCanProcessCurrentRequest:
numSamplesProcessed
setNumSamplesProcessed:
didAddAudio
setDidAddAudio:
caesuraSPG
setCaesuraSPG:
hybridClassifier
setHybridClassifier:
setEndpointerModelVersion:
serverFeaturesQueue
setServerFeaturesQueue:
lastKnownServerEPFeatures
setLastKnownServerEPFeatures:
serverFeatureLatencies
setServerFeatureLatencies:
serverFeaturesWarmupLatency
setServerFeaturesWarmupLatency:
lastServerFeatureTimestamp
setLastServerFeatureTimestamp:
hybridClassifierQueue
setHybridClassifierQueue:
lastReportedEndpointTimeMs
setLastReportedEndpointTimeMs:
nfhatAtLastReportedEndpoint
setNfhatAtLastReportedEndpoint:
stateSerialQueue
setStateSerialQueue:
didCommunicateEndpoint
setDidCommunicateEndpoint:
currentRequestSampleRate
setCurrentRequestSampleRate:
vtExtraAudioAtStartInMs
setVtExtraAudioAtStartInMs:
vtEndInSampleCount
setVtEndInSampleCount:
firstAudioPacketTimestamp
setFirstAudioPacketTimestamp:
didTimestampFirstAudioPacket
setDidTimestampFirstAudioPacket:
_canProcessCurrentRequest
_didAddAudio
_didCommunicateEndpoint
_didTimestampFirstAudioPacket
_nfhatAtLastReportedEndpoint
_numSamplesProcessed
_caesuraSPG
_hybridClassifier
_endpointerModelVersion
_serverFeaturesQueue
_lastKnownServerEPFeatures
_serverFeatureLatencies
_serverFeaturesWarmupLatency
_lastServerFeatureTimestamp
_hybridClassifierQueue
_lastReportedEndpointTimeMs
_stateSerialQueue
_currentRequestSampleRate
_vtExtraAudioAtStartInMs
_vtEndInSampleCount
_firstAudioPacketTimestamp
getFrequency
secondsToHostTime:
endpointerDelegate
hybridEndpointer
setHybridEndpointer:
vad2Endpointer
setVad2Endpointer:
activeEndpointer
setActiveEndpointer:
didEnterTwoshot
setDidEnterTwoshot:
_didEnterTwoshot
_endpointerDelegate
_hybridEndpointer
_vad2Endpointer
_activeEndpointer
_checkFirstUnlocked
_notifyObserver:withUnlocked:
CSFirstUnlockMonitor:didReceiveFirstUnlock:
_didReceiveFirstUnlockInQueue:
_didReceiveFirstUnlock:
_firstUnlocked
_checkSpringBoardStarted
_didReceiveSpringboardStarted:
_notifyObserver:withStarted:
CSSpringboardStartMonitor:didReceiveStarted:
_didReceiveSpringboardStartedInQueue:
_isSpringBoardStarted
componentsSeparatedByString:
processInfo
systemUptime
initWithConfiguration:
runRecognitionWithResultStream:
_recognizeWavData:length:
addAudioSamples:count:
tokens
_getConfidence:
firstObject
addObjectsFromArray:
lastObject
confidence
tokenName
enumerateObjectsUsingBlock:
speechRecognizer:didRecognizePartialResult:
speechRecognizer:didFinishRecognitionWithError:
speechRecognizer:didRecognizeFinalResults:
speechRecognizer:didRecognizeFinalResults:tokenSausage:nBestChoices:
speechRecognizer:didRecognizeFinalResultPackage:
speechRecognizer:didProcessAudioDuration:
speechRecognizer:didRecognizeRawEagerRecognitionCandidate:
_previousUtteranceTokens
_triggerTokenList
_recognizer
_recognizerBuffer
_useKeywordSpotting
_triggerConfidence
hybridEndpointerAssetFilename
initWithResourcePath:configFile:
fallBackAssetResourcePath
_decodeJson:
assetHashInResourcePath:
assetVersion
getBoolForKey:category:default:
_decodedInfo
_path
_resourcePath
_configureAudioConverter:
_convertBufferedLPCM:allowPartial:timestamp:
_opusConverter
_bufferedLPCM
_recordBasePacketsPerSecond
_opusOutASBD
_convertPacketCount
_convertAudioCapacity
_lastTimestamp
_notifyObserver:withLanguageCode:
_didReceiveLanguageCodeUpdate
_checkAllConditionsEnabled
notifyCallback:
_monitors
_conditions
_callback
outputAudioChannel
setOutputAudioChannel:
_outputAudioChannel
_initializeSAT:
_computeSATScore:
_initializeNDAPI:resourcePath:
_threshold
_spkModel
_retrainTriggerThreshold
stringByAppendingPathExtension:
_sampleLengthFrom:To:
_lastKeywordAnalyzeResult
_lastKeywordScore
_voiceControllerWithContext:error:
_createDeInterleaverIfNeeded
_processAudioChain:atTime:
enableVoiceTriggerOnAOP:
updateVoiceTriggerAOPModel:
voiceTriggerOccuredNotification:
_deinterleaveBufferIfNeeded:
_deinterleaver
_interleavedABL
_pNonInterleavedABL
analyzedSampleCount
setAnalyzedSampleCount:
decisionWaitSampleCount
setDecisionWaitSampleCount:
_analyzedSampleCount
_decisionWaitSampleCount
isWriting
fFile
CSContinuousVoiceTrigger
CSKeywordAnalyzerNDAPIScoreDelegate
NSObject
CSSpeechManagerDelegate
LPCMTypeConversion
CSSpeakerModel
CSVoiceTriggerFirstPass
CSCoreSpeechServices
CSConfig
CSSpeechManager
CSAudioRecorderDelegate
CSStateMachineDelegate
CSVoiceTriggerDelegate
CSLanguageCodeUpdateMonitorDelegate
CSVTUIEditDistance
CSAssetManager
Utils
VoiceTriggerFirstPass
CSVTUITrainingSession
SFSpeechRecognitionTaskDelegate
CSVTUIAudioSessionDelegate
CSVTUIEndPointDelegate
CSSpeechController
CSAudioConverterDelegate
CSPreferences
CSStateMachine
Meter
CSEventMonitor
CSAudioFileLog
Alert
CSVoiceTriggerFileLogger
Metrics
VoiceTriggerSecondPass
VoiceTriggerPassThru
CSVoiceTriggerEnabledPolicyNonAOP
VoiceTriggerRecord
CSMyriadPHash
CSVoiceTriggerFidesClient
FidesRecordInfoHelper
CSVTUIRegularExpressionMatcher
CSVTUIASRGrammars
NSURLSessionDelegate
CSVTUITrainingManager
CSVTUITrainingSessionDelegate
CSEndpointAnalyzerDelegate
CSUtils
CSKeywordAnalyzerNDAPI
CSEndpointerMetrics
CSAsset
AudioStreamBasicDescription
CSVoiceTriggerEnabledMonitor
KeywordDetector
CSVoiceTriggerSpeakerTrainer
CSVTUIAudioSessionAVVC
CSVTUIAudioSession
AVVoiceControllerRecordDelegate
AVVoiceControllerPlaybackDelegate
CSBeepCanceller
CSVoiceTriggerSecondPass
CSSpeakerDetectorNDAPIDelegate
CSKeywordAnalyzerQuasarScoreDelegate
CSVoiceTriggerFirstPassDelegate
CSVoiceTriggerEventNotifier
AudioFile
CSAssetManagerEnablePolicy
CSAudioCircularBuffer
SpeakerDetectorNDAPI
CSServerEndpointFeatures
CSVAD2EndpointAnalyzer
CSEndpointAnalyzerImpl
CSEndpointAnalyzer
private
CSAudioChunk
CSNovDetectorResult
CSNovDetector
Bitset
CSVTUITrainingSessionWithPayload
CSHybridEndpointAnalyzer
EARCaesuraSilencePosteriorGeneratorDelegate
Time
CSEndpointerProxy
CSFirstUnlockMonitor
CSSpringboardStartMonitor
CSKeywordAnalyzerQuasar
_EARSpeechRecognitionResultStream
CSAudioConverter
CSLanguageCodeUpdateMonitor
CSPolicy
CSEventMonitorDelegate
CSSelfTriggerDetector
RecordContext
CSSpeakerDetectorNDAPI
CSVTUIKeywordDetector
CSAudioRecorder
CSBeepCancellerDelegate
ContinuousVoiceTrigger
DuckOption
EndpointAnalyzer
CSKeywordDetector
ResourcePathHash
CSAudioFileWriter
B24@0:8@16
#16@0:8
@16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B16@0:8
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
v40@0:8@16@24Q32
v40@0:8@"CSKeywordAnalyzerNDAPI"16@"NSDictionary"24Q32
v32@0:8@16@24
v36@0:8@16B24@28
v32@0:8@16q24
v32@0:8@"CSSpeechManager"16@"AVVCAudioBuffer"24
v32@0:8@"CSSpeechManager"16@"CSAudioChunk"24
v36@0:8@"CSSpeechManager"16B24@"NSError"28
v32@0:8@"CSSpeechManager"16q24
@"NSDictionary"16@0:8
@32@0:8@16@24
v16@0:8
v24@0:8@16
f16@0:8
v20@0:8f16
q16@0:8
v24@0:8q16
v24@0:8Q16
@"<CSVoiceTriggerDelegate>"
@"CSSpeechManager"
@"NSObject<OS_dispatch_queue>"
@"CSAsset"
@"CSKeywordAnalyzerNDAPI"
@24@0:8@16
@"NSString"
v20@0:8B16
@"<CSVoiceTriggerFirstPassDelegate>"
@"CSVoiceTriggerEnabledPolicyNonAOP"
@"NSMutableArray"
I16@0:8
d16@0:8
v40@0:8@"CSAudioRecorder"16@"NSData"24Q32
v32@0:8@"CSAudioRecorder"16@"AVVCAudioBuffer"24
v36@0:8@"CSAudioRecorder"16B24@"NSError"28
v32@0:8@"CSAudioRecorder"16q24
v24@0:8@"CSAudioRecorder"16
v32@0:8@"CSAudioRecorder"16@"NSDictionary"24
v24@0:8@"NSDictionary"16
v40@0:8q16q24q32
v32@0:8q16q24
v24@0:8d16
v32@0:8@16@"NSString"24
@48@0:8@16@24@32@40
B32@0:8@16^@24
B24@0:8^@16
B32@0:8q16^@24
B40@0:8@16Q24^@32
v32@0:8@16^@24
Q24@0:8Q16
@24@0:8q16
@24@0:8Q16
@"CSAudioRecorder"
@"CSStateMachine"
@"CSAudioCircularBuffer"
@"CSVoiceTriggerFirstPass"
@"CSVoiceTriggerSecondPass"
@"<CSSpeechManagerDelegate>"
@"CSVoiceTriggerEventNotifier"
@"CSVoiceTriggerFileLogger"
@"CSSelfTriggerDetector"
@"CSContinuousVoiceTrigger"
@"CSKeywordDetector"
@"CSMyriadPHash"
@"CSVoiceTriggerFidesClient"
@"NSHashTable"
@"NSDictionary"
@"NSObject<OS_dispatch_source>"
@32@0:8Q16@24
@36@0:8Q16@24B32
v32@0:8@16@?24
v32@0:8Q16@24
v40@0:8@16@?24@?32
@"CSPolicy"
v28@0:8@16B24
v24@0:8@"SFSpeechRecognitionTask"16
v32@0:8@"SFSpeechRecognitionTask"16@"SFTranscription"24
v32@0:8@"SFSpeechRecognitionTask"16@"SFSpeechRecognitionResult"24
v28@0:8@"SFSpeechRecognitionTask"16B24
v28@0:8B16@20
v28@0:8B16@"NSError"20
v24@0:8@"NSData"16
v24@0:8@"NSError"16
@96@0:8q16q24@32@40@48@56@64@72@80@?88
v24@0:8@?16
v24@0:8i16B20
v32@0:8i16B20@?24
@"CSVTUIKeywordDetector"
@"<CSVTUIAudioSession>"
@"SFSpeechRecognizer"
@"SFSpeechAudioBufferRecognitionRequest"
@"SFSpeechRecognitionTask"
@"NSTimer"
@"<CSVTUITrainingSessionDelegate>"
v40@0:8@"CSAudioConverter"16@"NSArray"24Q32
{AudioStreamBasicDescription=dIIIIIIII}16@0:8
B24@0:8d16
B32@0:8@16q24
B24@0:8q16
f24@0:8Q16
v32@0:8d16@?24
@"CSAudioConverter"
@"<CSSpeechControllerDelegate>"
@"CSEndpointerProxy"
@24@0:8^@16
@"<CSStateMachineDelegate>"
@"NSMutableDictionary"
^{OpaqueExtAudioFile=}
{AudioStreamBasicDescription="mSampleRate"d"mFormatID"I"mFormatFlags"I"mBytesPerPacket"I"mFramesPerPacket"I"mBytesPerFrame"I"mChannelsPerFrame"I"mBitsPerChannel"I"mReserved"I}
@"NSURL"
S28@0:8^f16i24
@28@0:8Q16f24
s16@0:8
v20@0:8s16
v32@0:8q16@24
q48@0:8@16@24@32@40
v40@0:8@16@24@?32
v32@0:8@"NSURLSession"16@"NSError"24
v40@0:8@"NSURLSession"16@"NSURLAuthenticationChallenge"24@?<v@?q@"NSURLCredential">32
v24@0:8@"NSURLSession"16
@32@0:8q16@24
@40@0:8@16q24@32
v32@0:8@16d24
v40@0:8@16d24@32
v32@0:8@"<CSEndpointAnalyzer>"16d24
v40@0:8@"<CSEndpointAnalyzer>"16d24@"CSEndpointerMetrics"32
@24@0:8@?16
q36@0:8q16B24@?28
@"CSVAD2EndpointAnalyzer"
@"CSVTUITrainingSession"
@"<CSVTUITrainingManagerDelegate>"
v32@0:8@16Q24
@"CSNovDetector"
@"<CSKeywordAnalyzerNDAPIScoreDelegate>"
@56@0:8d16@24q32@40@48
@"NSArray"
B32@0:8@16@24
B40@0:8@16@24@32
v24@0:8@"<CSVTUIAudioSessionDelegate>"16
v24@0:8@"<Endpointer>"16
v28@0:8@16i24
v36@0:8@16i24d28
v28@0:8@"AVVoiceController"16B24
v36@0:8@"AVVoiceController"16B24@"NSError"28
v32@0:8@"AVVoiceController"16q24
v24@0:8@"AVVoiceController"16
v28@0:8@"AVVoiceController"16i24
v36@0:8@"AVVoiceController"16i24d28
v32@0:8@"AVVoiceController"16@"NSError"24
v32@0:8@"AVVoiceController"16@"AVVCAudioBuffer"24
v32@0:8@"AVVoiceController"16@"NSDictionary"24
q24@0:8q16
@"AVVoiceController"
@"<CSVTUIAudioSessionDelegate>"
{unique_ptr<BatchBeepCanceller, std::__1::default_delete<BatchBeepCanceller> >="__ptr_"{__compressed_pair<BatchBeepCanceller *, std::__1::default_delete<BatchBeepCanceller> >="__first_"^{BatchBeepCanceller}}}
{vector<float, std::__1::allocator<float> >="__begin_"^f"__end_"^f"__end_cap_"{__compressed_pair<float *, std::__1::allocator<float> >="__first_"^f}}
{vector<double, std::__1::allocator<double> >="__begin_"^d"__end_"^d"__end_cap_"{__compressed_pair<double *, std::__1::allocator<double> >="__first_"^d}}
{vector<short, std::__1::allocator<short> >="__begin_"^s"__end_"^s"__end_cap_"{__compressed_pair<short *, std::__1::allocator<short> >="__first_"^s}}
@"<CSBeepCancellerDelegate>"
v32@0:8@"CSSpeakerDetectorNDAPI"16@"NSDictionary"24
v40@0:8@"CSKeywordAnalyzerQuasar"16@"NSDictionary"24Q32
v32@0:8@"CSVoiceTriggerFirstPass"16@"NSDictionary"24
@"CSKeywordAnalyzerQuasar"
@"CSSpeakerDetectorNDAPI"
@"CSSpeakerModel"
B32@0:8@16@?24
@32@0:8Q16f24f28
v32@0:8r^v16Q24
v40@0:8r^v16Q24Q32
@32@0:8Q16Q24
@24@0:8^Q16
v40@0:8Q16Q24@32
{unique_ptr<corespeech::CSAudioCircularBufferImpl<unsigned short>, std::__1::default_delete<corespeech::CSAudioCircularBufferImpl<unsigned short> > >="__ptr_"{__compressed_pair<corespeech::CSAudioCircularBufferImpl<unsigned short> *, std::__1::default_delete<corespeech::CSAudioCircularBufferImpl<unsigned short> > >="__first_"^{CSAudioCircularBufferImpl<unsigned short>}}}
@72@0:8q16q24d32@40d48@56q64
@64@0:8q16q24d32@40d48@56
v24@0:8@"CSAudioChunk"16
@"<CSEndpointAnalyzerDelegate>"16@0:8
v24@0:8@"<CSEndpointAnalyzerDelegate>"16
v24@0:8@"CSServerEndpointFeatures"16
v32@0:8d16@?<v@?B@"NSArray">24
v20@0:8I16
^{OpaqueAudioComponentInstance=}
@"<CSEndpointAnalyzerDelegate>"
@"NSMutableData"
@24@0:8d16
B28@0:8^{AudioStreamBasicDescription=dIIIIIIII}16I24
v28@0:8d16I24
v28@0:8^f16I24
@64@0:8@16Q24Q32Q40Q48Q56
@40@0:8Q16Q24Q32
@"NSData"
v32@0:8Q16@?24
v24@0:8f16f20
v36@0:8^f16Q24f32
@"EARCaesuraSilencePosteriorGenerator"
@"_EAREndpointer"
@"CSServerEndpointFeatures"
@"NSDate"
Q20@0:8f16
Q40@0:8Q16Q24Q32
@"<CSEndpointAnalyzerImpl>"
v48@0:8@16@24@32@40
v32@0:8@"_EARSpeechRecognizer"16@"_EARSpeechRecognitionResult"24
v32@0:8@"_EARSpeechRecognizer"16@"NSError"24
v32@0:8@"_EARSpeechRecognizer"16@"NSArray"24
v48@0:8@"_EARSpeechRecognizer"16@"NSArray"24@"NSArray"32@"NSArray"40
v32@0:8@"_EARSpeechRecognizer"16@"_EARSpeechRecognitionResultPackage"24
v32@0:8@"_EARSpeechRecognizer"16d24
v32@0:8@"_EARSpeechRecognizer"16@"_EARSpeechRecognition"24
@36@0:8@16@24B32
v28@0:8r^s16i24
d24@0:8@16
@"_EARSpeechRecognizer"
@"_EARSpeechRecognitionAudioBuffer"
@"<CSKeywordAnalyzerQuasarScoreDelegate>"
@40@0:8@16@24@32
B36@0:8@16@24B32
v36@0:8@16B24Q28
v24@0:8^{OpaqueAudioConverter=}16
^{OpaqueAudioConverter=}
@"<CSAudioConverterDelegate>"
f24@0:8@16
@32@0:8@16Q24
@"<CSSpeakerDetectorNDAPIDelegate>"
Q24@0:8I16I20
v40@0:8@"CSBeepCanceller"16@"NSData"24Q32
@32@0:8@16^@24
@"CSBeepCanceller"
{AudioBufferList="mNumberBuffers"I"mBuffers"[1{AudioBuffer="mNumberChannels"I"mDataByteSize"I"mData"^v}]}
^{AudioBufferList=I[1{AudioBuffer=II^v}]}
@"<CSAudioRecorderDelegate>"
@104@0:8@16{AudioStreamBasicDescription=dIIIIIIII}24{AudioStreamBasicDescription=dIIIIIIII}64
s32@0:8r^v16q24
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
