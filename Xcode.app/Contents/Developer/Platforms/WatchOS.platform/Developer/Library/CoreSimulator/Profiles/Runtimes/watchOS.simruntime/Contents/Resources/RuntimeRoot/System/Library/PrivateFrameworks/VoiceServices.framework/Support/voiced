?.dat
error setting SRC quality: %d
%s: error %d %s level metering
Error AudioUnitSetProperty _floatConverter %d
Error AudioUnitSetProperty _integerConverter %d
Error AudioComponentInstanceNew _voiceBoostUnit %d
Error AudioUnitSetProperty _voiceBoostUnit, kAudioUnitProperty_MaximumFramesPerSlice %d
Error AudioUnitSetProperty _voiceBoostUnit, kAudioUnitProperty_StreamFormat, kAudioUnitScope_Input %d
Error AudioUnitSetProperty _voiceBoostUnit, kAudioUnitProperty_StreamFormat, kAudioUnitScope_Output,  %d
Error AudioUnitInitialize _voiceBoostUnit %d
Error AudioUnitSetParameter %d
Error AudioConverterConvertComplexBuffer _floatConverter %d
Error AudioUnitProcess _voiceBoostUnit %d
Error AudioConverterConvertComplexBuffer _integerConverter %d
Failed ve_ttsGetLipSyncInfo 0x%x
Error ve_ttsInitialize: 0x%x
Error ve_ttsGetLanguageList: 0x%x
Error ve_ttsGetVoiceList: 0x%x
Error ve_ttsOpen 0x%x
Error ve_ttsSetParamList 0x%x
Error ve_ttsClose 0x%x
Error ve_ttsUnInitialize 0x%x
Error ve_ttsResourceLoad 0x%x, path: '%@', type: '%@'
Success ve_ttsResourceLoad, path: '%@', type: '%@'
Error ve_ttsSetOutDevice 0x%x
Error ve_ttsProcessText2Speech 0x%x
Error ve_ttsStop 0x%x
Error getting components in voice path, %@
Engine preheating latency: %.3f
Unable to open file '%s', error: %d
Unable to get size of file '%s', error: %d
Unable to mmap '%s', error: %d
madvise failed for '%s', error: %s
Reloaded %lu memory mapped files
Unable to find broker file
%s: error converting disambiguation context
%s: allowing recognition start
%s: recognition requested when busy
%s: releasing active client to begin
%s: client requested cancellation of active recognition
%s: client requested cancellation of queued recognition
cancelling recognition
released from holding.. beginning now.
Running with background thread priority
couldn't create instance for client port - cancelling
couldn't open audio input file for reading
%s: sample rate change (now %d Hz); invalidating queue
%s: no valid models could be created
%s: client died - cancelling recognition
couldn't add listener for queue running state (%d)
couldn't create audio queue
setting recognition thread priority to %d
%s: sleeping for %g s
%s: finished starting queue in %g s
couldn't start audio queue for recognition (%d)
%s: starting recognition
%s: starting recognition from file
couldn't get file format description.
Recognition results:
--------------------
%s: error posting client completion notification
%s: error posting client error notification
Caching is disabled. Skipping caching.
Cached task %p in memory, caching to disk now.
Task %p is cached in disk
Error converting audio during caching. %@
Can't add audio cache, error: %@
On-disk cached synthesis %@ is found.
In-memory cached synthesis %@ is found.
decoderStreamDescription formatID: %@, sample rate: %@
Unknown server audio format ID: %d
Invalid chunk size: %d at offset %d, bytes count = %d
Received AceObject: %@
Voice count for %@_%@: %@
Voice: %@:%@:%@:%@:%@:%@
Error: %@
Sent AceObject: %@
Request %p received AceObject: %@, %s
Server TTS word timing info size: %d
Server TTS word timing info, offset: %ld, length: %ld, word: %@, sampleIndex: %@, timestamp: %.2f
Error: %@, %s
Synthesis completed, total packet number: %d, %s
Request %p gets completion call. %s
%s: posted %s to client
caching model <%s> class <%s> ...
no valid cache found; recaching everything.
cache for model <%s> is valid; skipping recache request.
... finished caching model in %g s with error %d <%s> class <%s>
cache for model <%s> is valid; skipping recache.
recache for model <%s> done in %g s
error caching model <%s>
%s: couldn't write keyword index for cache
%s: couldn't create manifest for cache
%s: error setting info dict on temp cache
%s: couldn't move temp cache into place... deleting
%s: couldn't save cache; no base dir exists or couldn't create temp cache
error writing model configuration cache Info.plist:
beginning plugin registry rebuild...
finished.
%s: error examining plugins directory (%ld)
%s: error writing plugin registry cache:
Preference changed for UseNewBackend, deleted cached engine
Prewarming: Invoked with request: '%@'
Prewarming: Started with request: '%@'
Unable to prewarm, error: %@
Can't prewarm engine with path '%@'
Engine is previously prewarmed with path '%@'
Prewarm latency: %.3f
Prewarming: Completed with request: '%@'
Using timestamp inside voiced
Speaking pre-synthesized audio: %@
Can't create VSAudioPlaybackService
Error, %@
Pre-synthesized audio request stopped
Finished speaking pre-synthesized audio: %@
Task is cancelled by user: %@
data provider does not implement value method
%s: plugin class does not conform to appropriate protocol
%s: plugin class not found
%s: error loading plugin:
Can't create engine with path '%@'
Enqueuing cached audio
playbackService is initialized already.
Starting AudioQueue
Reset MobileAsset query cache and retry selecting voice
No voice available
Compact voice is explicitly disabled.
Voice is deleted at path '%@'
Task %p is cancelled by user. text: '%@'
Finished task %p with error, text: '%@', error: %@
Task %p: Finished %@ utterance: '%@', voice: %{public}@:%@:%{public}@:%@:%@:%@:%{public}@:%@, voice resource: %{public}@:%{public}@, rate:%.2f, pitch:%.2f, volume:%.2f, isEager:%@
Ignore unspeakable task, type: %@
Start spinNextTask
Dispatch speaking task %p
%p wait another speaking task %p
%p interrupt task %p
Speak task %p is attached to eager task %p
Dispatch synthesis task %p
Finish spinNextTask
Starting synthesize task: %p
Task %p reported word time info
Task %p: Instrument metric: %@
Task %p started speaking
Task %p reported finish, error: %@
err %d copying manifest
Error %s, %@
Cache type name too long %@
Can't remove cache file '%@', error: %@
Time to cleaning cache: %f
Error getting cache path: %@, error: %@
Unable to get URL: %@, URL resources: %@
#AudioSession session interrupted
#AudioSession mediaserverd died
#AudioSession : Setting up audio session
#AudioSession error setting HW sample rate: %ld
#AudioSession : category = %d
#AudioSession error %ld setting audio category
#AudioSession error %ld setting bluetooth allowability
#AudioSession : Bluetooth %sabled
#AudioSession active count went negative for input!
#AudioSession active count went negative for output!
#AudioSession active count went negative!
#AudioSession : activity %d --> %s
#AudioSession : Active --> FALSE
#AudioSession : Active --> TRUE
#AudioSession error %ld activating or deactivating session for activity %ld
#AudioSession could not stop queue (%d)
Error AudioQueueNewOutputWithAudioSession %d
VSAudioPlaybackService init latency: %.3f
Error AudioQueueDispose %d
mediaserverd reset
Error AudioQueueStart %d
Success AudioQueueStart
Error AudioQueueAllocateBuffer %d
Detected AudioQueue stall, enqueueing %.2f samples of silence
Error AudioQueueEnqueueBuffer %d
Enqueued audio buffer at sample time: %.2f, size: %ld
Error AudioQueueFlush %d
Error AudioQueueStop %d
Error AudioQueuePause %d
Success AudioQueuePause
Error AudioQueueReset %d
Error AudioQueueAddPropertyListener %d
Error AudioQueueRemovePropertyListener %d
Error AudioQueueGetProperty isRunning %d
Unable to enable kAudioQueueProperty_EnableLevelMetering, err: %d
Unable to disable kAudioQueueProperty_EnableLevelMetering, err: %d
Error: %s, errno: %d
Played audio buffer at sample time: %f, size: %ld
Error AudioQueueFreeBuffer %d
Looking for data %s
Found data at path %s
-----------> Preheat: Preheating %u bytes of uselect starting at %u on same thread %s .....
-----------> done preheating %u bytes (%g seconds)
Reading cache %@ error: %@
Update with connection identifier: %{public}@
Created server speak task: %p
Created speak task: %p
Created presynthesized task: %p
Created server synthesis task: %p
Created synthesis task: %p
set auto download voice assets:%@
%@ is not TTS language, fallback to %@
Using requestCreatedTimestamp inside voiced
Wait for network response, timeout value: %.3f
Server TTS is ready. Start playing audio...
Server TTS timed out. Falling back to device TTS task: %p
Error in task %p, error: %@
Task %p: Finished speaking utterance: '%@', isEager:%@
Starting speech task: %p
#CacheDelete purgeable urgency: %d, info: %@
#CacheDelete purge urgency: %d, info: %@
#CacheDelete periodic urgency: %d, info: %@
voiced starting up...
Cannot register CacheDelete service.
Receive notification %s
Skipping voice download: %@
xpc_activity state must be RUN, got: %ld
running xpc_activity
Error cleanUnusedAssets in scheduled background task: %@
XPC connection invalidated, identifier: %{public}@
_VSAudioQueueSetLevelMeteringPropertyValue
enabling
disabling
com.apple.voiceservices.notification.voice-update
com.apple.voiceservices.request
v4@?0
%@.%@.%@
client
%@.%@
voice
locale
gender
footprint
loggingPrefix
T@"NSString",&,N,V_loggingPrefix
asbd
T{AudioStreamBasicDescription=dIIIIIIII},N,V_asbd
pcmBufferSize
TI,N,V_pcmBufferSize
floatConverter
T^{OpaqueAudioConverter=},N,V_floatConverter
integerConverter
T^{OpaqueAudioConverter=},N,V_integerConverter
voiceBoostUnit
T^{OpaqueAudioComponentInstance=},N,V_voiceBoostUnit
audioTimeStamp
T{AudioTimeStamp=dQdQ{SMPTETime=ssILLssss}LI},N,V_audioTimeStamp
voiceBoostGainDecibels
Tf,N,V_voiceBoostGainDecibels
audioData
T@"NSData",&,N,V_audioData
packetCount
Ti,N,V_packetCount
packetDescriptions
T@"NSData",&,N,V_packetDescriptions
mappedData
T^v,N,V_mappedData
fileSizeInBytes
TL,N,V_fileSizeInBytes
fileName
T@"NSString",C,N,V_fileName
broker.hdr
broker.hdr.asset
VSVocalizerEngine
@unionOfObjects.startTime
text
T@"NSString",&,N,V_text
utf8WordTimingInfos
T@"NSMutableArray",&,N,V_utf8WordTimingInfos
markerCount
TI,N,V_markerCount
mutablePCMData
T@"NSMutableData",&,N,V_mutablePCMData
stopMark
Tl,N,V_stopMark
callback
T@?,C,N,V_callback
state
Ti,N,V_state
error
T@"NSError",&,N,V_error
engine
T@"VSSpeechEngine",&,N,V_engine
nil path or nil mimeType
path
mimeType
ve_ttsResourceLoad
ve_ttsSetOutDevice
ve_ttsProcessText2Speech
indx
mdnf
rnnf
clc_
<COMPONENT>monogryph/featextract</COMPONENT>
voicePath
T@"NSString",&,N,V_voicePath
vocalizerSpeech
T{_VE_HSAFE=^vI},N,V_vocalizerSpeech
vocalizerInstance
T{_VE_HSAFE=^vI},N,V_vocalizerInstance
vocalizerDataClass
T^v,N,V_vocalizerDataClass
language
T{_VE_LANGUAGE=[128c][4c][128c]S},N,V_language
voiceInfo
T{?=[128c][128c][128c][128c][128c]S},N,V_voiceInfo
currentCallbackResult
T@"VSSpeechSynthesisCallbackResult",&,N,V_currentCallbackResult
memoryMappedFiles
T@"NSMutableArray",&,N,V_memoryMappedFiles
T{AudioStreamBasicDescription=dIIIIIIII},R,N,V_asbd
rate
Tf,N,V_rate
pitch
Tf,N,V_pitch
volume
Tf,N,V_volume
_default
server_VSRecognitionPrepareOrBegin
server_VSRecognitionBegin
server_VSRecognitionCancel
com.apple.voiceservices.recognition
Error %d at %s:%d
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VoiceServicesDaemons_Sim/VoiceServices-421/Daemon/VSRecognitionServer.c
_CreateEngineIfNecessary
_InitializeEngine
_RecognitionClientInvalidationCallback
Error %d at %s:%d (%s)
couldn't start recognition
recording.wav
_BeginRecognition
_SendChoices
com.apple.voiced.cachingQueue
@"AVAudioBuffer"12@?0I4^i8
threadLock
T@"NSLock",&,N,V_threadLock
inMemoryCacheTasks
T@"NSMutableArray",&,N,V_inMemoryCacheTasks
cacheStore
T@"VSSpeechCache",&,N,V_cacheStore
cachingQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_cachingQueue
VoiceServicesErrorDomain
ServerTTSErrorDomain
v8@?0@"SABaseCommand"4
v12@?0B4@"NSError"8
-[VSSiriTTSClient startSynthesisRequest:responseHandler:completion:]_block_invoke
@unionOfObjects.timestamp
Unable to parse audio data
afClient
T@"AFClientLite",&,N,V_afClient
VSClientPostNotification
VSLocaleIdentifier
VSVersion
VSPluginVersions
KeywordIndex.plist
%@%@
.vscache
Info.plist
temp.vscache.XXXXX
_SaveEngineToCache
VSEngineIdentifier
temp.vscache.
PluginPath
PluginRegistry.plist
_CreateRegistryAndSaveToCache
modelid-desc
pluginid-vers
pluginpath-moddate
/System/Library/VoiceServices/PlugIns
com.apple.voiced.prewarmQueue
useNewBackend
Prewarm textify emoji
cachedEngine
T@"VSSpeechEngine",&,N,V_cachedEngine
prewarmQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_prewarmQueue
Library
Caches
VoiceServices
task: inprogress %@, request: %@
Can't create VSAudioPlaybackService
Can't decode audio data
hash
TI,R
superclass
T#,R
description
T@"NSString",R,C
debugDescription
request
T@"VSPresynthesizedAudioRequest",R,N,V_request
delegate
T@"<VSSpeechServiceDelegate>",W,N,V_delegate
playbackService
T@"VSAudioPlaybackService",&,N,V_playbackService
instrumentMetrics
T@"VSInstrumentMetrics",&,N,V_instrumentMetrics
T@"NSMutableData",&,N,V_audioData
VSRecognitionVersion
VSRecognitionModels
VSRecognitionModelIdentifier
VSRecognitionModelFileName
VSRecognitionModelIsTopLevel
VSRecognitionModelWeight
VSRecognitionModelIsCancelModel
VSRecognitionModelRequiredCapabilities
VSRecognitionModelDataProvider
VSRecognitionResultValidator
VSRecognitionResultHandler
vsplugin
lang
VSRecognitionModelDefinition
.plist
VSPlugin
<VSPlugin %p: %@>
VSRecognitionClasses
VSRecognitionSequences
VSRecognitionKeywords
VSRecognitionClassIdentifier
VSRecognitionClassRequiredCapabilities
VSRecognitionClassElements
VSRecognitionClassElementValues
VSRecognitionClassSequences
VSRecognitionClassType
VSRecognitionClassWeight
VSRecognitionClassContainsKeywords
VSRecognitionClassTypeCommand
VSRecognitionClassTypePersonName
VSRecognitionClassTypeStreetName
VSRecognitionClassTypeCityName
VSRecognitionClassTypeSongTitle
VSRecognitionClassTypeArtistName
VSRecognitionClassTypeAlbumName
VSRecognitionSequenceElements
VSRecognitionSequenceDisambiguationTag
_InstantiatePluginClassWithRecognitionModelKeyedName
_LoadPluginIfNecessary
isvalid
VSRecognitionClassDataProvider
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VoiceServicesDaemons_Sim/VoiceServices-421/Daemon/VSSpeechSpeakTask+Utilities.m
<Unknown File>
Invalid parameter not satisfying: %@
self.voiceSelection != nil
VoiceServices/config
Can't create VSSpeechEngine
[self.speechCache isKindOfClass:[VSSpeechCacheAudio class]]
No voice available
Compact voice is explicitly disabled.
Voice is deleted already.
speaking
synthesizing
previousProvider
T@"<AFAudioPowerProviding>",W,N,V_previousProvider
dflt%ld
VSRecognitionModel
com.apple.voiced.speakingQueue
eagerTasks
T@"NSMutableArray",&,N,V_eagerTasks
speakTasks
T@"NSMutableArray",&,N,V_speakTasks
currentTask
T@"<VSSpeechTaskProtocol>",&,N,V_currentTask
threadMutex
T{_opaque_pthread_mutex_t=l[40c]},N,V_threadMutex
threadMutexAttr
T{_opaque_pthread_mutexattr_t=l[8c]},N,V_threadMutexAttr
speakingQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_speakingQueue
lastSynthesisRequest
T@"VSSpeechRequest",&,N,V_lastSynthesisRequest
lastSynthesisRequestCreatedTimeStamp
TQ,N,V_lastSynthesisRequestCreatedTimeStamp
VSRecognitionClass
VSRecognitionSequence
<%@>
Synthesis is cancelled/interrupted.
@"NSError"8@?0@"VSSpeechSynthesisCallbackResult"4
speakTask
T@"VSSpeechSpeakTask",&,N,V_speakTask
readyForEagerTask
TB,N,V_readyForEagerTask
Manifest.sqlitedb
SELECT model_id, validity FROM Model;
 WHERE model_id = ?;
INSERT OR REPLACE INTO ValueTranslation (model_id, class_id, original_value, translated_value) VALUES (?, ?, ?, ?);
SELECT original_value FROM ValueTranslation WHERE model_id = ? AND class_id = ? AND translated_value = ?;
DELETE FROM ValueTranslation
 model_id = ?
 class_id = ?
 WHERE
 AND
VSRecognitionConfigurationCacheManifest
Model
model_id
validity
last_update
SELECT %s FROM %s WHERE ROWID = ?
UPDATE %s SET %s = ? WHERE ROWID = ?
ValueTranslation
CREATE TABLE Model (ROWID INTEGER PRIMARY KEY AUTOINCREMENT, model_id TEXT, validity TEXT, last_update INTEGER, UNIQUE(model_id));
CREATE INDEX ModelIdIndex on Model(model_id);
CREATE TABLE ValueTranslation (ROWID INTEGER PRIMARY KEY AUTOINCREMENT, model_id TEXT, class_id TEXT, original_value TEXT, translated_value TEXT, UNIQUE(model_id, class_id, original_value));
CREATE INDEX ValueTranslationModelIdClassIdIndex on ValueTranslation(model_id, class_id, translated_value);
/var/mobile/Library/VoiceServices/SpeechCache
VSSpeechCacheErrorDomain
-[VSSpeechCache initWithStorePath:]
Cache type name too long
-[VSSpeechCache addCache:]
i12@?0@"NSURL"4@"NSURL"8
dirPath
T@"NSString",&,N,V_dirPath
VSAudioSessionQueue
ACTIVE
INACTIVE
LatencyFudgeFactor
Error AudioQueueStart
-[VSAudioPlaybackService getAveragePower:andPeakPower:]
audioQueue
T^{OpaqueAudioQueue=},N,V_audioQueue
waitForStateChangeMutex
T{_opaque_pthread_mutex_t=l[40c]},N,V_waitForStateChangeMutex
stateChangeCondition
T{_opaque_pthread_cond_t=l[24c]},N,V_stateChangeCondition
enqueuedSampleCount
Td,N,V_enqueuedSampleCount
initialSampleTime
Td,N,V_initialSampleTime
lastPlayedSampleTime
Td,N,V_lastPlayedSampleTime
sessionID
TI,N,V_sessionID
_VSVocalizerDataMappingImplMap
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VoiceServicesDaemons_Sim/VoiceServices-421/Daemon/VSVocalizerPlatform.c
info->mappedData == NULL
uselect
T@"NSString",&,N,V_key
magicVersion
Ti,R,N,V_magicVersion
timingInfos
T@"NSArray",R,N,V_timingInfos
audio
T@"VSAudioData",R,N,V_audio
VSAudioPowerUpdateQueue
-[VSSpeechXPCHandler beginAudioPowerUpdateWithReply:]
v8@?0@"AFXPCWrapper"4
-[VSSpeechXPCHandler endAudioPowerUpdate]
connectionIdentifier
T@"NSString",&,N,V_connectionIdentifier
audioPowerUpdateQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_audioPowerUpdateQueue
audioPowerUpdater
T@"AFAudioPowerUpdater",&,N,V_audioPowerUpdater
%@:%@:server
v12@?0@"VSAudioData"4@"NSArray"8
v8@?0@"NSError"4
Operation is cancelled before server response.
Unable to create playback service
Unexpected pthread_cond_timedwait return: %d
Server TTS timedout
shouldSpeak
TB,N,V_shouldSpeak
T@"VSSpeechRequest",&,N,V_request
wordTimingInfo
T@"NSArray",&,N,V_wordTimingInfo
timeoutCondition
T{_opaque_pthread_cond_t=l[24c]},N,V_timeoutCondition
T@"VSSpeechServerTask",&,N,V_speakTask
\audio=
\audio="%@"\
\mrk=%@=%@\
.wav
%02x
%@ %@ %@ %.2f %.2f %.2f %@
Speech is cancelled/interrupted.
T@"NSArray",&,N,V_timingInfos
voiceBooster
T@"VSVoiceBooster",&,N,V_voiceBooster
voiceSelection
T@"VSVoiceAssetSelection",&,N,V_voiceSelection
voiceResource
T@"VSVoiceResourceAsset",&,N,V_voiceResource
cachingService
T@"VSCachingService",&,N,V_cachingService
speechCache
T@"<VSSpeechCacheItem>",&,N,V_speechCache
phonemes
T@"NSArray",&,N,V_phonemes
utterance
T@"NSString",&,N,V_utterance
T@"VSAudioData",&,N,V_audio
taskAuxiliaryQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_taskAuxiliaryQueue
CACHE_DELETE_AMOUNT
CACHE_DELETE_VOLUME
com.apple.voiced.CacheDelete
r^{__CFDictionary=}12@?0i4r^{__CFDictionary=}8
com.apple.notifyd.matching
v8@?0@"NSObject<OS_xpc_object>"4
com.apple.MobileAsset.VoiceServices.CustomVoice.cached-metadata-updated
com.apple.MobileAsset.VoiceServicesVocalizerVoice.cached-metadata-updated
com.apple.MobileAsset.VoiceServices.CustomVoice.new-asset-installed
com.apple.MobileAsset.VoiceServices.GryphonVoice.new-asset-installed
com.apple.MobileAsset.VoiceServicesVocalizerVoice.new-asset-installed
com.apple.MobileAsset.VoiceServices.VoiceResources.new-asset-installed
com.apple.voiced
KeepAliveManager
com.apple.voiceservices.keepalive
connectionCount
TI,N,V_connectionCount
runloopSourceRef
T^{__CFRunLoopSource=},N,V_runloopSourceRef
listener
T@"NSXPCListener",&,N,V_listener
init
alloc
initWithLoggingPrefix:
stringWithFormat:
class
isMemberOfClass:
speakTask
request
clientBundleIdentifier
recordCategory:value:
voiceSelection
voiceData
masteredVersion
name
languages
firstObject
gender
genderStringFromGender:
footprint
footprintStringFromFootprint:
defaultService
tallyTask:
.cxx_destruct
loggingPrefix
setLoggingPrefix:
_loggingPrefix
uninitialize
dealloc
initialize
voiceBoostGainDecibels
length
mutableBytes
dataWithLength:
errorWithDomain:code:userInfo:
initWithStreamDescription:pcmBufferSize:
setVoiceBoostGainDecibels:
processData:
asbd
setAsbd:
pcmBufferSize
setPcmBufferSize:
floatConverter
setFloatConverter:
integerConverter
setIntegerConverter:
voiceBoostUnit
setVoiceBoostUnit:
audioTimeStamp
setAudioTimeStamp:
_voiceBoostGainDecibels
_pcmBufferSize
_floatConverter
_integerConverter
_voiceBoostUnit
_asbd
_audioTimeStamp
audioData
packetCount
duration
setAudioData:
setPacketCount:
packetDescriptions
setPacketDescriptions:
_audioData
_packetCount
_packetDescriptions
initWithMmapData:fileSizeInBytes:fileName:
mappedData
setMappedData:
fileSizeInBytes
setFileSizeInBytes:
fileName
setFileName:
_mappedData
_fileSizeInBytes
_fileName
array
setLength:
engine
setStartTime:
setTextRange:
addObject:
valueForKeyPath:
wordTimingInfoFrom:timestamps:
arrayWithCapacity:
vocalizerInstance
stringWithUTF8String:
initWithCallback:pcmBufferSize:
resetPCMBuffer
pcmData
markerBuffer
markerBufferSize
saveUTF8WordTimingInfo
wordTimingInfos
phonemes
state
setState:
error
setError:
text
setText:
utf8WordTimingInfos
setUtf8WordTimingInfos:
markerCount
setMarkerCount:
mutablePCMData
setMutablePCMData:
stopMark
setStopMark:
callback
setCallback:
setEngine:
_markerBuffer
_state
_error
_text
_utf8WordTimingInfos
_markerCount
_mutablePCMData
_stopMark
_callback
_engine
brokerInfoData
bytes
isGryphonVoice:
standardInstance
useNewBackend
UTF8String
dictionaryWithObjects:forKeys:count:
dataWithContentsOfFile:
currentCallbackResult
lengthOfBytesUsingEncoding:
defaultManager
voicePath
contentsOfDirectoryAtPath:error:
countByEnumeratingWithState:objects:count:
shouldPreheatComponent:
stringByAppendingPathComponent:
mmapAndScanFile:
code
domain
isEqualToString:
arrayWithObjects:count:
setWithArray:
containsObject:
hasPrefix:
memoryMappedFiles
count
appendBytes:length:
initWithData:encoding:
containsString:
isUserCancelError:
initWithVoicePath:
setVolume:
setRate:
setPitch:
loadResourceAtPath:mimeType:
synthesizeText:callback:
stopAtMarker:
preheat
reloadMappedFiles
setVoicePath:
rate
pitch
volume
vocalizerSpeech
setVocalizerSpeech:
setVocalizerInstance:
vocalizerDataClass
setVocalizerDataClass:
language
setLanguage:
voiceInfo
setVoiceInfo:
setCurrentCallbackResult:
setMemoryMappedFiles:
_voicePath
_rate
_pitch
_volume
_vocalizerDataClass
_currentCallbackResult
_memoryMappedFiles
_vocalizerSpeech
_vocalizerInstance
_language
_voiceInfo
disableCache
md5hash
audio
timingInfos
initWithKey:audio:wordTimingInfo:
setSpeechCache:
threadLock
lock
inMemoryCacheTasks
unlock
cachingQueue
cacheTask:
removeObject:
initWithStreamDescription:
initFromFormat:toFormat:
initWithPCMFormat:frameCapacity:
setFrameLength:
mutableAudioBufferList
data
maximumOutputPacketSize
initWithFormat:packetCapacity:maximumPacketSize:
convertToBuffer:error:withInputFromBlock:
audioBufferList
cacheStore
addCache:
speechCache
cacheDataForKey:
inMemoryCacheForSimilarTask:
instrumentMetrics
setIsCacheHitFromDisk:
setIsCacheHitFromMemory:
isKindOfClass:
setTimingInfos:
setAudioDuration:
initWithCache:
enqueueCacheSpeakTask:completion:
onDiskCacheForSimilarTask:
fetchCacheForTask:
setThreadLock:
setInMemoryCacheTasks:
setCacheStore:
setCachingQueue:
_threadLock
_inMemoryCacheTasks
_cacheStore
_cachingQueue
decoderStreamDescription
formatID
sampleRate
unsignedIntegerValue
doubleValue
formatFlags
unsignedIntValue
bytesPerPacket
framesPerPacket
bytesPerFrame
channelsPerFrame
bitsPerChannel
reserved
audioBuffer
populateWithPCMData:
populateWithOpusData:
audioDataFromSAUIAudioData:
forceServerTTS
isAudioAccessory
sharedManager
languageCode
voiceType
selectVoiceForLang:type:gender:footprint:
fetchSpeechSynthesisVoiceRequest
setLanguageCode:
genderStringFromVSGender:
setGender:
speechSynthesisVoice
setFilteredVoiceKey:
voiceKeyList
numberWithUnsignedInteger:
contentVersion
quality
keyString
setLanguages:
genderFromString:
setName:
integerValue
numberWithInteger:
setContentVersion:
footprintFromString:
setFootprint:
localizedDescription
handleCommand:afterCurrentRequest:commandHandler:completion:
startSpeechSynthesisRequest
setAudioType:
setStreaming:
setEnableAudioInfo:
errorCode
reason
reasonDescription
aceAudioData
aceAudioInfo
wordTimingInfoList
floatValue
numberWithFloat:
offset
word
sampleIndex
timestamp
totalPacketNumber
defaultClient
shouldUseServerTTSForRequest:
queryVoices:reply:
startSynthesisRequest:responseHandler:completion:
afClient
setAfClient:
_afClient
addObserver:forKeyPath:options:context:
defaultCenter
removeObserver:
initWithRequest:
fetchVoiceAsset
fetchVoiceResource
prepareForSynthesis
prewarmWithEngine:
textifyEmojiWithLanguage:
sharedService
observeValueForKeyPath:ofObject:change:context:
prewarmWithRequest:
waitUntilPrewarmFinish
cachedEngine
setCachedEngine:
prewarmQueue
setPrewarmQueue:
_cachedEngine
_prewarmQueue
requestCreatedTimestamp
setRequestCreatedTimestamp:
isExecuting
numberWithBool:
setSynthesisBeginTimestamp:
audioSessionID
initWithAudioSessionID:asbd:
setPlaybackService:
playbackService
delegate
presynthesizedAudioRequestSuccessWithInstrumentMetrics:error:
isCancelled
presynthesizedAudioRequestDidStopAtEnd:error:
presynthesizedAudioRequestDidStart
start
setAudioStartTimestampDiffs:
enqueue:packetCount:packetDescriptions:
flushAndStop
setSpeechEndTimestamp:
stop
cancel
pause
audioPowerProvider
isEqual:
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
description
debugDescription
suspend
resume
reportFinish
isSpeaking
reportInstrumentMetrics
reportSpeechStart
reportTimingInfo
_clockFactor
main
setDelegate:
setInstrumentMetrics:
_request
_delegate
_playbackService
_instrumentMetrics
getValue:weight:atIndex:forClassWithIdentifier:inModelWithIdentifier:
phoneticValueAtIndex:forClassWithIdentifier:inModelWithIdentifier:
valueCountForClassWithIdentifier:inModelWithIdentifier:
valueAtIndex:forClassWithIdentifier:inModelWithIdentifier:
cacheValidityIdentifier
isCacheValidityIdentifierValid:
beginReportingChanges
stopReportingChanges
validRecognitionResultFromRecognitionResult:
validRecognitionResultFromRecognitionResult:knownDisambiguationValues:
currentHandler
handleFailureInMethod:object:file:lineNumber:description:
voiceResource
searchPathURL
path
resourceList
objectForKeyedSubscript:
setIsWarmStart:
_createEngine
setVoiceBooster:
voiceBooster
gainDecibelWithVolume:
stringByReplacingOccurrencesOfString:withString:
contextInfo
insertContextInfo:
substituteAudioWithLocalPath
precomposedStringWithCanonicalMapping
setUtterance:
synthesisBeginTimestamp
setSynthesisEndTimestamp:
startPlaybackServiceWithAudioSessionID:
taskAuxiliaryQueue
audioStartTimestampDiffs
markerStringForContext:
textRange
selectVoiceResourceAssetForLanguage:
setVoiceResource:
_fetchVoiceAsset_NoRetry
resetCache
disableCompactVoiceFallback
fileExistsAtPath:
setVoiceSelection:
setVoiceAssetKey:
type
typeStringFromType:
isBuiltInVoice
eagerRequestCreatedTimeStampDiffs
speakCachedAudio
waitUntilAudioFinished
pausePlayback
resumePlayback
adjustWordTimingInfo
logFinish
sharedQueue
currentTask
didEndAccessPower
getCurrentAudioPowerProvider
willBeginAccessPower
getAveragePower:andPeakPower:
sharedServices
previousProvider
setPreviousProvider:
_previousProvider
spinNextTask
removeObjectAtIndex:
isSimilarTo:
setEagerRequestCreatedTimeStampDiffs:
readyForEagerTask
setSpeakTask:
addTask:
cancelCurrentTask
suspendCurrentTask
resumeCurrentTask
eagerTasks
setEagerTasks:
speakTasks
setSpeakTasks:
setCurrentTask:
threadMutex
setThreadMutex:
threadMutexAttr
setThreadMutexAttr:
speakingQueue
setSpeakingQueue:
lastSynthesisRequest
setLastSynthesisRequest:
lastSynthesisRequestCreatedTimeStamp
setLastSynthesisRequestCreatedTimeStamp:
_eagerTasks
_speakTasks
_currentTask
_speakingQueue
_lastSynthesisRequest
_lastSynthesisRequestCreatedTimeStamp
_threadMutexAttr
_threadMutex
cachingService
synthesize
speechBeginTimestamp
setReadyForEagerTask:
saveToFile
shouldCache
utterance
appendData:
outputPath
synthesisRequest:didReceiveTimingInfo:
speechRequestDidReceiveTimingInfo:
speechRequestSuccessWithInstrumentMetrics:
voiceAssetKey
synthesisEndTimestamp
setSpeechBeginTimestamp:
speechEndTimestamp
audioDuration
isWarmStart
speechRequestDidStart
speechRequestDidStopWithSuccess:phonemesSpoken:error:
componentsJoinedByString:
synthesisRequest:didFinishWithInstrumentMetrics:error:
_readyForEagerTask
_speakTask
createDirectoryAtPath:withIntermediateDirectories:attributes:error:
initWithStorePath:
dataUsingEncoding:
serializedData
dataWithCapacity:
dirPath
writeToFile:options:error:
subdataWithRange:
initWithKey:data:
fileURLWithPath:
contentsOfDirectoryAtURL:includingPropertiesForKeys:options:error:
getResourceValue:forKey:error:
compare:
sortedArrayUsingComparator:
subarrayWithRange:
removeItemAtURL:error:
fileURLWithPath:isDirectory:
resourceValuesForKeys:error:
defaultCacheStore
cleanCache
totalCacheSize
deleteCache
setDirPath:
_dirPath
_audioSessionInterrupted:
addObserver:selector:name:object:
_mediaServicesWereReset:
userInfo
objectForKey:
_setupAudioSession
sharedInstance
setPreferredSampleRate:error:
setCategory:error:
categoryOptions
setCategory:withOptions:error:
_setCategoryForActivity:
_nextActivityForActive:activity:serverActivity:
setActive:error:
category
_safeSetupAudioSession
_safeServerGeneration
_safeSetCategoryForActivity:
_safeSetActive:withActivity:
_safeSetBluetoothInputAllowed:
_queue
_audioSessionIsSetUp
_desiredState
_cachedState
_bluetoothAllowed
_activityBag
_serverGeneration
outputLatency
inputLatency
IOBufferDuration
currentRoute
inputs
objectAtIndex:
portType
opaqueSessionID
handleMediaServerReset
waitForAudioQueueStop
signalQueueRunningStateChange
isAudioQueueRunning
durationOfAudioDataLength:withAudioDescription:
bytesOfDuration:withAudioDescription:
reset
audioQueue
setAudioQueue:
sessionID
setSessionID:
waitForStateChangeMutex
setWaitForStateChangeMutex:
stateChangeCondition
setStateChangeCondition:
enqueuedSampleCount
setEnqueuedSampleCount:
initialSampleTime
setInitialSampleTime:
lastPlayedSampleTime
setLastPlayedSampleTime:
_audioQueue
_sessionID
_enqueuedSampleCount
_initialSampleTime
_lastPlayedSampleTime
_stateChangeCondition
_waitForStateChangeMutex
archivedDataWithRootObject:requiringSecureCoding:error:
getBytes:range:
setWithObjects:
unarchivedObjectOfClasses:fromData:error:
magicVersion
setKey:
_magicVersion
_timingInfos
_audio
_key
invalidate
initWithRequest:shouldSpeak:
setCompletionBlock:
audioPowerUpdateQueue
initWithProvider:queue:frequency:delegate:
audioPowerUpdater
createNewXPCWrapperWithCompletion:
beginUpdate
endUpdate
setAudioPowerUpdater:
installedAssetsForType:voicename:language:gender:footprint:
remoteObjectProxy
speechRequestDidPause
speechRequestDidContinue
speechRequestMark:didStartForRange:
cleanOldVoiceResources
cleanUnusedVoiceAssets
installedVoiceResources
availableLanguages
fallbackLanguageForLanguage:
initWithDictionaryRepresentation:
dictionaryRepresentation
boolValue
sharedCurrentSpeakingTaskQueue
updateWithConnectionIdentifier:
prewarmIfNeededWithRequest:
startSpeechRequest:
startSynthesisRequest:
pauseSpeechRequestAtMark:
continueSpeechRequest
stopSpeechRequestAtMark:
startPresynthesizedAudioRequest:
stopPresynthesizedAudioRequest
getVoiceNamesForLanguage:reply:
getFootprintsForVoiceName:languageCode:reply:
getSpeechIsActiveReply:
getSpeechIsActiveForConnectionReply:
beginAudioPowerUpdateWithReply:
endAudioPowerUpdate
cleanUnusedAssets:
getLocalVoicesReply:
getLocalVoiceResourcesReply:
setAutoDownloadedVoiceAssets:
getAutoDownloadedVoiceAssets:
getVoiceResourceForLanguage:reply:
getVoiceInfoForLanguageCode:footprint:gender:type:reply:
setLogToFile:
getLogToFile:
getTTSServerVoicesWithFilter:reply:
initWithConnection:
connectionIdentifier
setConnectionIdentifier:
setAudioPowerUpdateQueue:
_connection
_connectionIdentifier
_audioPowerUpdateQueue
_audioPowerUpdater
setIsServerTTS:
serverTTSTimeout
setWordTimingInfo:
shouldSpeak
wordTimingInfo
setShouldSpeak:
setRequest:
timeoutCondition
setTimeoutCondition:
_shouldSpeak
_wordTimingInfo
_timeoutCondition
stringWithString:
rangeOfString:options:range:
substringWithRange:
stringByAppendingString:
replaceCharactersInRange:withString:
stringWithCapacity:
appendFormat:
string
appendString:
synthesizeAndSpeak
setIsSpeechRequest:
addObjectsFromArray:
setPhonemes:
setCachingService:
setAudio:
setTaskAuxiliaryQueue:
_voiceBooster
_voiceSelection
_voiceResource
_cachingService
_speechCache
_phonemes
_utterance
_taskAuxiliaryQueue
longLongValue
activeVoiceAssets
inactiveVoiceAssets
totalSizeOfAssets:
asset
attributes
purgeableVoiceAssetsWithInfo:urgency:
numberWithLongLong:
purgeAsset:
purgeable:urgency:
purge:urgency:
periodic:urgency:
registerCacheDelete
timeIntervalSinceNow
date
initWithMachServiceName:
maintainWithAudioType:keepAudioSessionActive:
interfaceWithProtocol:
setExportedInterface:
setExportedObject:
setInvalidationHandler:
listener:shouldAcceptNewConnection:
_keepAliveListener
_keepAliveManager
hasActiveKeepAlives
maintainKeepAlive:
cancelKeepAlive:
_activeKeepAlives
_shouldChangeAudioSession
setManager:
_manager
_isActive
_activity
_keepSessionActive
_transaction
_registryRunLoopSource
amendVoiceWithDefaultSettings:
downloadVoiceAsset:useBattery:completion:
cancelDownload:completion:
scheduleBackgroundTask
setRemoteObjectInterface:
setClasses:forSelector:argumentIndex:ofReply:
connectionCount
setConnectionCount:
runloopSourceRef
setRunloopSourceRef:
listener
setListener:
_connectionCount
_runloopSourceRef
_listener
VSAggdService
VSVoiceBooster
VSAudioData
MemoryMappedFileInfo
VSSpeechSynthesisCallbackResult
VSSpeechEngine
VSCachingService
SAUIAudioData
VSSiriTTSClient
VSPrewarmService
VSSpeechPresynthesizedTask
VSSpeechSpeakableProtocol
VSSpeechTaskProtocol
NSObject
VSRecognitionModelDataProvider
VSRecognitionResultValidator
Utilities
VSSpeechAudioPowerService
AFAudioPowerProviding
VSSpeechEagerProtocol
VSSpeechTaskQueue
VSSpeechSynthesisTask
VSSpeechCache
VSAudioSession
VSAudioPlaybackService
VSSpeechCacheAudio
VSSpeechCacheItem
VSSpeechXPCHandler
VSSpeechXPCServiceProtocol
VSSpeechServiceDelegate
VSSpeechServerTask
VSSpeechService
VSSpeechSpeakTask
VSCacheDeleteService
VSRemoteKeepAlive
VSKeepAliveServer
NSXPCListenerDelegate
VSServerKeepAliveManager
VSKeepAliveClient
VSSpeechServer
SpeechService
@8@0:4
@12@0:4@8
v16@0:4@8@12
v12@0:4@8
v8@0:4
@"NSString"
@52@0:4{AudioStreamBasicDescription=dIIIIIIII}8I48
B8@0:4
v12@0:4f8
f8@0:4
{AudioStreamBasicDescription=dIIIIIIII}8@0:4
v48@0:4{AudioStreamBasicDescription=dIIIIIIII}8
I8@0:4
v12@0:4I8
^{OpaqueAudioConverter=}8@0:4
v12@0:4^{OpaqueAudioConverter=}8
^{OpaqueAudioComponentInstance=}8@0:4
v12@0:4^{OpaqueAudioComponentInstance=}8
{AudioTimeStamp=dQdQ{SMPTETime=ssILLssss}LI}8@0:4
v72@0:4{AudioTimeStamp=dQdQ{SMPTETime=ssILLssss}LI}8
^{OpaqueAudioConverter=}
^{OpaqueAudioComponentInstance=}
{AudioStreamBasicDescription="mSampleRate"d"mFormatID"I"mFormatFlags"I"mBytesPerPacket"I"mFramesPerPacket"I"mBytesPerFrame"I"mChannelsPerFrame"I"mBitsPerChannel"I"mReserved"I}
{AudioTimeStamp="mSampleTime"d"mHostTime"Q"mRateScalar"d"mWordClockTime"Q"mSMPTETime"{SMPTETime="mSubframes"s"mSubframeDivisor"s"mCounter"I"mType"L"mFlags"L"mHours"s"mMinutes"s"mSeconds"s"mFrames"s}"mFlags"L"mReserved"I}
d8@0:4
i8@0:4
v12@0:4i8
@"NSData"
@20@0:4^v8L12@16
^v8@0:4
v12@0:4^v8
L8@0:4
v12@0:4L8
@16@0:4@?8I12
^{?=IiIIIISII*}8@0:4
l8@0:4
v12@0:4l8
@?8@0:4
v12@0:4@?8
[64{?="ulMrkInfo"I"eMrkType"i"ulSrcPos"I"ulSrcTextLen"I"ulDestPos"I"ulDestLen"I"usPhoneme"S"ulMrkId"I"ulParam"I"szPromptID"*}]
@"NSError"
@"NSMutableArray"
@"NSMutableData"
@"VSSpeechEngine"
B12@0:4@8
@16@0:4@8@12
@16@0:4@8@?12
{_VE_HSAFE=^vI}8@0:4
v16@0:4{_VE_HSAFE=^vI}8
{_VE_LANGUAGE=[128c][4c][128c]S}8@0:4
v270@0:4{_VE_LANGUAGE=[128c][4c][128c]S}8
{?=[128c][128c][128c][128c][128c]S}8@0:4
v650@0:4{?=[128c][128c][128c][128c][128c]S}8
@"VSSpeechSynthesisCallbackResult"
{_VE_HSAFE="pHandleData"^v"u32Check"I}
{_VE_LANGUAGE="szLanguage"[128c]"szLanguageTLW"[4c]"szVersion"[128c]"u16LangId"S}
{?="szVersion"[128c]"szLanguage"[128c]"szVoiceName"[128c]"szVoiceAge"[128c]"szVoiceType"[128c]"u16LangId"S}
v16@0:4@8@?12
@"NSLock"
@"VSSpeechCache"
@"NSObject<OS_dispatch_queue>"
@12@0:4l8
v20@0:4@8@?12@?16
@"AFClientLite"
v24@0:4@8@12@16^v20
#8@0:4
@12@0:4:8
@16@0:4:8@12
@20@0:4:8@12@16
B12@0:4#8
B12@0:4:8
Vv8@0:4
^{_NSZone=}8@0:4
B12@0:4@"Protocol"8
@"NSString"8@0:4
@"VSSpeechRequest"8@0:4
@"VSInstrumentMetrics"8@0:4
@"<AFAudioPowerProviding>"8@0:4
@"VSPresynthesizedAudioRequest"
@"<VSSpeechServiceDelegate>"
@"VSAudioPlaybackService"
@"VSInstrumentMetrics"
i16@0:4@8@12
@20@0:4i8@12@16
B28@0:4^@8^i12i16@20@24
i16@0:4@"NSString"8@"NSString"12
@"NSString"20@0:4i8@"NSString"12@"NSString"16
B28@0:4^@8^i12i16@"NSString"20@"NSString"24
@"NSDictionary"8@0:4
B12@0:4@"NSDictionary"8
@"VSRecognitionResult"12@0:4@"VSRecognitionResult"8
@"VSRecognitionResult"16@0:4@"VSRecognitionResult"8@"NSDictionary"12
B16@0:4^f8^f12
@"<AFAudioPowerProviding>"
v12@0:4@"<VSSpeechSpeakableProtocol>"8
{_opaque_pthread_mutex_t=l[40c]}8@0:4
v52@0:4{_opaque_pthread_mutex_t=l[40c]}8
{_opaque_pthread_mutexattr_t=l[8c]}8@0:4
v20@0:4{_opaque_pthread_mutexattr_t=l[8c]}8
Q8@0:4
v16@0:4Q8
@"<VSSpeechTaskProtocol>"
@"VSSpeechRequest"
{_opaque_pthread_mutexattr_t="__sig"l"__opaque"[8c]}
{_opaque_pthread_mutex_t="__sig"l"__opaque"[40c]}
v12@0:4B8
@"VSSpeechSpeakTask"
l20@0:4B8l12l16
v16@0:4B8l12
{?="category"i"activity"l}
^{__CFBag=}
d52@0:4I8{AudioStreamBasicDescription=dIIIIIIII}12
I56@0:4d8{AudioStreamBasicDescription=dIIIIIIII}16
@52@0:4I8{AudioStreamBasicDescription=dIIIIIIII}12
@20@0:4@8i12@16
^{OpaqueAudioQueue=}8@0:4
v12@0:4^{OpaqueAudioQueue=}8
{_opaque_pthread_cond_t=l[24c]}8@0:4
v36@0:4{_opaque_pthread_cond_t=l[24c]}8
v16@0:4d8
^{OpaqueAudioQueue=}
{_opaque_pthread_cond_t="__sig"l"__opaque"[24c]}
@"NSData"8@0:4
@16@0:4@"NSString"8@"NSData"12
@20@0:4@8@12@16
@"NSArray"
@"VSAudioData"
Vv12@0:4@8
Vv12@0:4l8
Vv16@0:4@8@?12
Vv20@0:4@8@12@?16
Vv12@0:4@?8
Vv28@0:4@8l12l16l20@?24
Vv12@0:4B8
Vv12@0:4@"NSString"8
Vv12@0:4@"VSSpeechRequest"8
Vv12@0:4@"VSPresynthesizedAudioRequest"8
Vv16@0:4@"NSString"8@?<v@?@"NSArray">12
Vv20@0:4@"NSString"8@"NSString"12@?<v@?@"NSArray">16
Vv12@0:4@?<v@?B>8
Vv12@0:4@?<v@?@"AFXPCWrapper">8
Vv12@0:4@?<v@?@"NSError">8
Vv12@0:4@?<v@?@"NSArray"@"NSError">8
Vv12@0:4@"NSArray"8
Vv12@0:4@?<v@?@"NSArray">8
Vv16@0:4@"NSString"8@?<v@?@"VSVoiceResourceAsset">12
Vv28@0:4@"NSString"8l12l16l20@?<v@?@"VSVoiceAsset">24
Vv16@0:4@"VSVoiceAsset"8@?<v@?@"NSArray"@"NSError">12
Vv20@0:4l8{_NSRange=II}12
Vv20@0:4B8@12@16
Vv16@0:4@8@12
Vv20@0:4@8@12@16
Vv16@0:4B8@12
Vv20@0:4B8@"NSString"12@"NSError"16
Vv12@0:4@"VSInstrumentMetrics"8
Vv16@0:4@"VSSpeechRequest"8@"NSArray"12
Vv20@0:4@"VSSpeechRequest"8@"VSInstrumentMetrics"12@"NSError"16
Vv16@0:4B8@"NSError"12
Vv16@0:4@"VSInstrumentMetrics"8@"NSError"12
@"NSXPCConnection"
@"AFAudioPowerUpdater"
@16@0:4@8B12
@"VSSpeechServerTask"
@"VSVoiceBooster"
@"VSVoiceAssetSelection"
@"VSVoiceResourceAsset"
@"VSCachingService"
@"<VSSpeechCacheItem>"
@16@0:4@8i12
q12@0:4@8
Vv16@0:4i8B12
B16@0:4@8@12
B16@0:4@"NSXPCListener"8@"NSXPCConnection"12
@"NSXPCListener"
@"VSServerKeepAliveManager"
@"NSMutableSet"
@"NSObject<OS_os_transaction>"
^{__CFRunLoopSource=}
^{__CFRunLoopSource=}8@0:4
v12@0:4^{__CFRunLoopSource=}8
f16@0:4d8
bplist00
 !"#$%&'($)_
BuildMachineOSBuild_
CFBundleDevelopmentRegion_
CFBundleExecutable_
CFBundleIdentifier_
CFBundleInfoDictionaryVersion\CFBundleName_
CFBundlePackageType_
CFBundleShortVersionString_
CFBundleSignature_
CFBundleSupportedPlatforms_
CFBundleVersionZDTCompiler_
DTPlatformBuild^DTPlatformName_
DTPlatformVersionZDTSDKBuildYDTSDKNameWDTXcode\DTXcodeBuild_
MinimumOSVersion^UIDeviceFamilyW16B2657WEnglishVvoiced_
com.apple.voicedS6.0TFMWKU1.0.0T????
^WatchSimulatorS1.0_
"com.apple.compilers.llvm.clang.1_0P^watchsimulatorS4.3V15T162_
watchsimulator4.3T0930U9Q54e
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
<key>com.apple.Contacts.database-allow</key>
<true/>
<key>com.apple.coreaudio.allow-opus-codec</key>
<true/>
<key>com.apple.coreaudio.register-internal-aus</key>
<true/>
<key>com.apple.private.assets.accessible-asset-types</key>
<array>
<string>com.apple.MobileAsset.VoiceServices.CustomVoice</string>
<string>com.apple.MobileAsset.VoiceServices.VoiceResources</string>
<string>com.apple.MobileAsset.VoiceServicesVocalizerVoice</string>
<string>com.apple.MobileAsset.VoiceServices.GryphonVoice</string>
</array>
<key>com.apple.private.assets.change-daemon-config</key>
<true/>
<key>com.apple.private.coreaudio.borrowaudiosession.allow</key>
<true/>
<key>com.apple.private.tcc.allow</key>
<array>
<string>kTCCServiceAddressBook</string>
<string>kTCCServiceMicrophone</string>
<string>kTCCServiceMediaLibrary</string>
</array>
<key>com.apple.siri.client_lite</key>
<true/>
</dict>
</plist>
zPLR
zPLR
zPLR
zPLR
