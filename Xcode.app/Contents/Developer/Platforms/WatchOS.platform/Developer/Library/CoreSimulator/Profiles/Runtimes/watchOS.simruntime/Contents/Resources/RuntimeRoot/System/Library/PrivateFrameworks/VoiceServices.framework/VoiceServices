_bundleIdentifier
_compatibilityVersion
_contentVersion
_masteredVersion
supportsSecureCoding
TB,R
bundleIdentifier
T@"NSString",C,N,V_bundleIdentifier
compatibilityVersion
T@"NSNumber",C,N,V_compatibilityVersion
contentVersion
T@"NSNumber",C,N,V_contentVersion
masteredVersion
T@"NSString",C,N,V_masteredVersion
_utterance
_voiceAssetKey
_voiceResourceAssetKey
_promptCount
_requestCreatedTimestamp
_synthesisBeginTimestamp
_synthesisEndTimestamp
_speechBeginTimestamp
_speechEndTimestamp
_audioStartTimestampDiffs
_synthesisToSpeechTimeGap
_waitForSynthesisToFinishTimeDelay
_audioDuration
_isWarmStart
_isCacheHitFromDisk
_isCacheHitFromMemory
_isSpeechRequest
_canUseServerTTS
_isServerTTS
_isServerTimeout
_isServerTTSRacing
v4@?0
character_count
voice_asset_key
voice_resource_asset_key
is_warm_start
tts_synthesis_latency
tts_total_latency
audio_queue_latency
audio_duration
is_speech_request
synthesis_to_speech_time_gap
is_synthesis_cached
prompt_count
is_server_tts
is_server_timeout
can_use_server_tts
is_server_tts_racing
is_cache_hit_from_disk
is_cache_hit_from_memory
synthesis_to_speech_time
wait_for_synthesis_to_finish_time
audio_start_timestamp_diffs
utterance
T@"NSString",C,V_utterance
voiceAssetKey
T@"NSString",C,V_voiceAssetKey
voiceResourceAssetKey
T@"NSString",C,V_voiceResourceAssetKey
requestCreatedTimestamp
Tq,V_requestCreatedTimestamp
eagerRequestCreatedTimeStampDiffs
Tq,V_eagerRequestCreatedTimeStampDiffs
synthesisBeginTimestamp
Tq,V_synthesisBeginTimestamp
synthesisEndTimestamp
Tq,V_synthesisEndTimestamp
speechBeginTimestamp
Tq,V_speechBeginTimestamp
speechEndTimestamp
Tq,V_speechEndTimestamp
audioStartTimestampDiffs
Tq,V_audioStartTimestampDiffs
audioDuration
Td,V_audioDuration
isWarmStart
TB,V_isWarmStart
isServerTTS
TB,V_isServerTTS
isServerTimeout
TB,V_isServerTimeout
isServerTTSRacing
TB,V_isServerTTSRacing
canUseServerTTS
TB,V_canUseServerTTS
promptCount
Ti,V_promptCount
isSpeechRequest
TB,V_isSpeechRequest
synthesisToSpeechTimeGap
Tq,V_synthesisToSpeechTimeGap
waitForSynthesisToFinishTimeDelay
Tq,V_waitForSynthesisToFinishTimeDelay
isCacheHitFromDisk
TB,V_isCacheHitFromDisk
isCacheHitFromMemory
TB,V_isCacheHitFromMemory
com.apple.MobileAsset.VoiceServicesVocalizerVoice
com.apple.MobileAsset.VoiceServices.CustomVoice
com.apple.MobileAsset.VoiceServices.GryphonVoice
com.apple.MobileAsset.VoiceServices.VoiceResources
Name
Languages
LanguagesCompatibility
Language
Gender
Footprint
Type
TTSResources/PreinstallAssets/
%@:%@:%@:%@:%@:%@
%@.tmp
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VoiceServices_Sim/VoiceServices-481/Framework/VSMobileAssetsManager.m
<Unknown File>
negative size
voiceData
T@"VSVoiceAsset",&,V_voiceData
asset
T@"ASAsset",&,V_asset
builtInVoicePath
T@"NSString",&,V_builtInVoicePath
voicePath
T@"NSString",&,N,V_voicePath
VSMobileAssetManagerCacheQueue
com.apple.voiced.assetQueryQueue
com.apple.voiceservices
preinstall_metadata.plist
_RelativePath
AssetData
Assets
i12@?0@"VSVoiceResourceAsset"4@"VSVoiceResourceAsset"8
(%K BETWEEN %@)
(%@ == %K)
((%@ IN %K) OR (%@ IN %K))
 && 
(%K == %@)
(%@ in %K)
en-US
v8@?0@"NSError"4
VSMobileAssetManager
Cleaning voice assets is disabled in internal setting.
v12@?0@"NSMutableArray"4l8
B12@?0@"ASAsset"4@"NSDictionary"8
%@:%@:%@:%@
Voice asset is not well defined, be more specific
v16@?0d4f12
Operation
WaitingToDownload
DownloadingAsset
EstimatedTimeRemaining
OperationProgress
OperationCompleted
v12@?0@"NSDictionary"4@"NSError"8
v12@?0@"NSArray"4@"NSError"8
(%K != nil)
i12@?0@"VSVoiceAssetSelection"4@"VSVoiceAssetSelection"8
/var/mobile/Library/VoiceServices/voices/%@_%@/AssetData
local_voice
i12@?0@"ASAsset"4@"ASAsset"8
cacheConcurrentQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_cacheConcurrentQueue
assetQueryQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_assetQueryQueue
voiceSelectionCache
T@"NSMutableDictionary",&,N,V_voiceSelectionCache
voiceResourceCache
T@"NSMutableDictionary",&,N,V_voiceResourceCache
AXAccessibilitySiriVoicesInUse
/System/Library/PrivateFrameworks/AccessibilityUtilities.framework/AccessibilityUtilities
_default
VSRecognition
<VSRecognition: %p model=%@>
recognition is already active
recognition reuse attempted
error converting disambiguation context to server
error converting audio input path to server
error converting model identifier
connection failure
recognition request denied
couldn't establish connection
recognition cancelled
connection lost
com.apple.voiceserviceslogging
default
disableNewBackend
enableAudioDump
DisableCaching
DisableAssetCleaning
EnableLocalVoices
EnableHomePodSimulation
ServerTTSTimeout
forceServerTTS
disableServerTimeoutFallback
isInternalBuild
TB,N,V_isInternalBuild
internalDefaults
T@"NSUserDefaults",&,N,V_internalDefaults
internalBuild
TB,R,N,V_internalBuild
TB,N
disableCache
disableAssetCleaning
enableLocalVoices
enableHomePodSimulation
serverTTSTimeout
Tf,N
tts_languages
plist
tts_language_fallbacks
_VSServerConnection
com.apple.voiced
note.server.died
note.recog.prepare
note.recog.start
note.recog.results
note.recog.cancel
note.recog.error
key.recog.results
key.recog.errordesc
key.recog.errorcode
VSErrorDomain
vsplist
yyyy-MM-dd-HH-mm-ss'.vslog'
Library
Logs
CrashReporter
VoiceServicesRecognition
Latest.vslog
HH-mm-ss-
MaxLogCount
i12@?0@"NSURL"4@"NSURL"8
classes
phrases
modelid
handler
) <%@>
VSRecognitionResult
%@:%@
seqtag
known
knownp
ambig
ambigp
VSRecognitionDisambiguationContext
<VSRecognitionDisambiguationContext %p [%@]> 
 will disambiguate with sequence tag %@
 known class values:
constrained ambiguous classes:
  %@ = "%@" (%@)
  %@ = "%@"
  %@ =
     "%@" (%@)
     "%@"
com.apple.voiceservices.kwidxchanged
top-level
class-kws
__model-kws
s5l8942x
s5l8947x
s7002
t8002
HardwarePlatform
DeviceClassNumber
com.apple.voiceservices.logging
VSLogLevel
VSOutputLevel
com.apple.voiceservices.language
lang-id
%@Library/Managed Preferences/mobile/%@.plist
mobile
com.apple.AppSupport.loggingDefaultsChanged
Auto Downloaded Assets
%@-%@
en-GB
zh-HK
zh-TW
RecognitionResources/Express
TTSResources
language_fallbacks.plist
zh-Hans
zh-CN
com.apple.language.changed
range
com.apple.voiceservices.assetInstalled
common
Library/VoiceServices/Assets
FormatVersion
.migrated
NotForSiri
voice_format_version.plist
broker.hdr
broker.hdr.tmp
broker.hdr.asset
Tones
%@%@
.tmp
hash
TI,R
superclass
T#,R
description
T@"NSString",R,C
debugDescription
VSRecognitionSessionKeywordsDidChangeNotification
action already in progress
session is finished or invalid
session is invalid or not finished
session is already speaking
VSSpeechServiceDecoderErrorDomain
v16@?0@"NSData"4I8^B12
Failed to create opus decoder
l16@?0^I4^{AudioBufferList=I[1{AudioBuffer=II^v}]}8^^{AudioStreamPacketDescription}12
decoder gave us %d bytes bytes but we really only expected %d
Could not finish decoding, res %d
recognition action not implemented
VSSpeechLangCharset
could not create recognition instance
recognition already attempted or in progress
voice_configs.plist
vocalizer_resource_order
vocalizer_resources
_voices
legacy
premiumhigh
VoiceServices-Config.plist
voice_speech_rate
voice_speech_pitch
voice_speech_volume
VoiceResource: %@, CV: %@, MV: %@
_languages
_searchPathURL
%@:%@:%@
DisableGryphon
voiceConfig
T@"NSDictionary",C,N,V_voiceConfig
rate
Tf,N,V_rate
pitch
Tf,N,V_pitch
volume
Tf,N,V_volume
vocalizerConfig
T@"NSDictionary",&,N,V_vocalizerConfig
languages
T@"NSArray",C,N,V_languages
resourceList
T@"NSArray",C,N,V_resourceList
resourceMimeTypes
T@"NSDictionary",C,N,V_resourceMimeTypes
searchPathURL
T@"NSURL",C,N,V_searchPathURL
_startTime
_textRange
startTime
Td,N,V_startTime
textRange
T{_NSRange=II},N,V_textRange
model <%@> class <%@>
com.apple.yn
no URL to launch
{AudioStreamBasicDescription=dIIIIIIII}
_audioData
_clientBundleIdentifier
_text
_audioSessionID
_enqueue
%@%@kHz
Opus
PCM%@KHz
sessionId %u, clientId %@, %@ bytes, input format %@, output format %@, requestCreatedTime %@, text '%@'
clientBundleIdentifier
T@"NSString",C,N,V_clientBundleIdentifier
pcmDataSize
TI,N,V_pcmDataSize
stopHandler
T@?,C,N,V_stopHandler
audioSessionID
TI,N,V_audioSessionID
audioData
T@"NSData",R,C,N,V_audioData
decoderStreamDescription
T{AudioStreamBasicDescription=dIIIIIIII},R,N,V_decoderStreamDescription
playerStreamDescription
T{AudioStreamBasicDescription=dIIIIIIII},R,N,V_playerStreamDescription
enqueue
TB,N,V_enqueue
text
T@"NSString",&,N,V_text
TQ,N,V_requestCreatedTimestamp
match
replace
case-sensitive
eat-punct
com.apple.voiceservices.class
title
name
+[VSAssetUpdateListener sharedListener]
-[VSAssetUpdateListener startListening]
-[VSAssetUpdateListener stopListening]
-[VSAssetUpdateListener downloadAssetForLanguage:]
-[VSAssetUpdateListener downloadingAssetLanguage]
-[VSAssetUpdateListener assetStatusForLanguage:]
-[VSAssetUpdateListener assetDownloadStatus:progress:size:]
-[VSAssetUpdateListener removeAssetForLanguage:]
text:'%@', language:%@, type:%@, gender:%@, footprint:%@, rate:%.2f, pitch:%.2f, volume:%.2f, canUseServerTTS:%d, contextInfo:%@
textForAttributes
attributes
_languageCode
_voiceName
_footprint
_useCustomVoice
_voiceType
_gender
_outputPath
_rate
_pitch
_volume
_maintainsInput
_audioSessionIDIsValid
_shouldCache
_disableCompactVoiceFallback
_forceServerTTS
_audioQueueFlags
_resourceListURL
_resourceSearchPathURL
_contextInfo
_pointer
%@%@: %@
v16@?0@4@8^B12
attributedText
T@"NSAttributedString",C,N,V_attributedText
useCustomVoice
TB,N,V_useCustomVoice
voiceName
T@"NSString",C,N,V_voiceName
audioSessionIDIsValid
TB,N,V_audioSessionIDIsValid
maintainsInput
TB,N,V_maintainsInput
audioQueueFlags
TI,N,V_audioQueueFlags
pauseHandler
T@?,C,N,V_pauseHandler
pointer
Ti,N,V_pointer
T@"NSString",C,N,V_text
languageCode
T@"NSString",C,N,V_languageCode
footprint
Tl,N,V_footprint
voiceType
Tl,N,V_voiceType
gender
Tl,N,V_gender
outputPath
T@"NSURL",C,N,V_outputPath
shouldCache
TB,N,V_shouldCache
Td,N,V_rate
Td,N,V_pitch
Td,N,V_volume
contextInfo
T@"NSDictionary",C,N,V_contextInfo
disableCompactVoiceFallback
TB,N,V_disableCompactVoiceFallback
TB,N,V_forceServerTTS
TB,N,V_canUseServerTTS
resourceListURL
T@"NSURL",C,N,V_resourceListURL
resourceSearchPathURL
T@"NSURL",C,N,V_resourceSearchPathURL
%02x
%@ %ld
com.apple.voiceservices.keepalive
com.apple.voiceservices.tts
VoiceServicesErrorDomain
completion
T@?,C,N,V_completion
nil request
input text is not set
audio data is invalid
v8@?0@"VSVoiceResourceAsset"4
%@_%@_legacy.caf
%@_%@.caf
VSSpeechSynthesizer
VSSpeechSynthesizerCallbackThread
language_fallbacks
VSSpeechSynthesizer_%p@%@_%d
nil languageCode
not currently speaking
Missing text of this request
no active speech job
language
T@"NSString",C,N,V_language
delegate
T@"<VSSpeechSynthesizerDelegate>",W,N,V_delegate
voice
T@"NSString",&,N,V_voice
lastTTSRequestDate
defaults
T@"NSUserDefaults",&,N,V_defaults
autoDownloadedVoices
T@"NSArray",&,N
T@"NSDate",&,N
audioType
Ti,N,V_audioType
active
TB,N,V_active
keepAudioSessionActive
TB,N,V_keepAudioSessionActive
com.apple.voiceservices.xpcconnection
Connection invalidated during request
v16@?0@"NSValue"4@"VSSpeechRequest"8^B12
v8@?0@"NSArray"4
-[VSSpeechConnection isSystemSpeaking]_block_invoke
v8@?0B4
-[VSSpeechConnection isSystemSpeakingOnBehalfOfCurrentConnection]_block_invoke
xpcConnection
T@"NSXPCConnection",&,N,V_xpcConnection
delegateWrapper
T@"VSSpeechConnectionDelegateWrapper",&,N,V_delegateWrapper
threadSafeQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_threadSafeQueue
identifier
T@"NSString",&,N,V_identifier
T@"<VSSpeechConnectionDelegate>",W,N,V_delegate
request
T@"VSSpeechRequest",R,N
presynthesizedAudioRequest
T@"VSPresynthesizedAudioRequest",R,N
T@"VSSpeechRequest",&,N,V_request
concurrentSynthesisRequests
T@"NSMutableDictionary",&,N,V_concurrentSynthesisRequests
T@"VSPresynthesizedAudioRequest",&,N,V_presynthesizedAudioRequest
connection
T@"VSSpeechConnection",W,N,V_connection
compact
premium
beta
male
female
vocalizer
custom
gryphon
%@:%@:%@:%@:%@
%@:%@:%@:%@:%@:CV%@:MV%@:Compatibility%@
Type:%@, Name: %@, Languages: %@, Gender: %@, Footprint: %@, Installed: %@, ContentVersion: %@, MasteredVersion: %@, isBuiltIn: %@
_name
_type
_isInstalled
_isBuiltInVoice
MasteredVersion
ContentVersion
T@"NSString",C,N,V_name
type
Tl,N,V_type
isInstalled
TB,N,V_isInstalled
isBuiltInVoice
TB,N,V_isBuiltInVoice
v8@?0@4
_endpoint
endpoint
T@"NSXPCListenerEndpoint",&,N,V_endpoint
queue
T@"NSObject<OS_dispatch_queue>",&,N,V_queue
listener
T@"NSXPCListener",&,N,V_listener
T@?,C,N,V_handler
encodeObject:forKey:
init
class
decodeObjectOfClass:forKey:
supportsSecureCoding
encodeWithCoder:
initWithCoder:
.cxx_destruct
bundleIdentifier
setBundleIdentifier:
compatibilityVersion
setCompatibilityVersion:
contentVersion
setContentVersion:
masteredVersion
setMasteredVersion:
_bundleIdentifier
_compatibilityVersion
_contentVersion
_masteredVersion
dictionaryMetrics
description
encodeInteger:forKey:
encodeInt64:forKey:
encodeDouble:forKey:
encodeBool:forKey:
decodeIntegerForKey:
decodeInt64ForKey:
decodeDoubleForKey:
decodeBoolForKey:
_clockFactor
length
numberWithUnsignedInteger:
numberWithBool:
ttsSynthesisLatency
numberWithDouble:
timeToSpeakLatency
audioQueueLatency
eagerRequestTimeGap
isSynthesisCached
numberWithInteger:
synthesisToSpeechTime
waitForSynthesisToFinishTime
numberWithLongLong:
dictionaryWithObjects:forKeys:count:
synthesisLatency
ttsTotalLatency
utterance
setUtterance:
voiceAssetKey
setVoiceAssetKey:
voiceResourceAssetKey
setVoiceResourceAssetKey:
requestCreatedTimestamp
setRequestCreatedTimestamp:
eagerRequestCreatedTimeStampDiffs
setEagerRequestCreatedTimeStampDiffs:
synthesisBeginTimestamp
setSynthesisBeginTimestamp:
synthesisEndTimestamp
setSynthesisEndTimestamp:
speechBeginTimestamp
setSpeechBeginTimestamp:
speechEndTimestamp
setSpeechEndTimestamp:
audioStartTimestampDiffs
setAudioStartTimestampDiffs:
audioDuration
setAudioDuration:
isWarmStart
setIsWarmStart:
isServerTTS
setIsServerTTS:
isServerTimeout
setIsServerTimeout:
isServerTTSRacing
setIsServerTTSRacing:
canUseServerTTS
setCanUseServerTTS:
promptCount
setPromptCount:
isSpeechRequest
setIsSpeechRequest:
synthesisToSpeechTimeGap
setSynthesisToSpeechTimeGap:
waitForSynthesisToFinishTimeDelay
setWaitForSynthesisToFinishTimeDelay:
isCacheHitFromDisk
setIsCacheHitFromDisk:
isCacheHitFromMemory
setIsCacheHitFromMemory:
_isWarmStart
_isServerTTS
_isServerTimeout
_isServerTTSRacing
_canUseServerTTS
_isSpeechRequest
_isCacheHitFromDisk
_isCacheHitFromMemory
_utterance
_voiceAssetKey
_voiceResourceAssetKey
_promptCount
_requestCreatedTimestamp
_eagerRequestCreatedTimeStampDiffs
_synthesisBeginTimestamp
_synthesisEndTimestamp
_speechBeginTimestamp
_speechEndTimestamp
_audioStartTimestampDiffs
_audioDuration
_synthesisToSpeechTimeGap
_waitForSynthesisToFinishTimeDelay
voiceData
languages
firstObject
type
numberWithLong:
gender
footprint
name
stringWithFormat:
typeStringFromType:
genderStringFromGender:
footprintStringFromFootprint:
asset
localURL
path
stringByAppendingPathComponent:
defaultManager
fileExistsAtPath:
attributes
objectForKeyedSubscript:
integerValue
stringWithUTF8String:
currentHandler
handleFailureInMethod:object:file:lineNumber:description:
state
descriptiveKey
voicePath
size
isInstalled
isDownloading
setVoiceData:
setAsset:
builtInVoicePath
setBuiltInVoicePath:
setVoicePath:
_voiceData
_asset
_builtInVoicePath
_voicePath
alloc
arrayWithObjects:count:
countByEnumeratingWithState:objects:count:
longValue
queryForType:voicename:language:gender:footprint:localOnly:
runQueryAndReturnError:
voiceDataFromAsset:
addObject:
pickCorrectAssetFromLocalAssets:
legacyLocalVocalizerVoiceAssetForLanguage:
bundleWithIdentifier:
bundlePath
preinstallAssetsDirectory
dictionaryWithContentsOfFile:
setIsInstalled:
setIsBuiltInVoice:
genderFromString:
setGender:
setLanguages:
typeFromString:
setType:
setName:
footprintFromString:
setFootprint:
preinstallAssetsMetadata
array
isEqualToString:
voiceAssetFromPreinstallMetadata:
preinstalledVoicesForLanguage:gender:
queryForVoiceResourceAsset:localOnly:
voiceResourceFromAsset:
sortUsingComparator:
lastObject
numberWithUnsignedInt:
count
componentsJoinedByString:
predicateWithFormat:argumentArray:
bundleIdentifierForVoiceType:
initWithAssetType:
setPredicate:
setQueriesLocalAssetInformationOnly:
selectVoiceResourceAssetForLanguage:
defaultVoice
sharedManager
amendVoiceWithDefaultSettings:
downloadVoiceAsset:useBattery:completion:
removeVoiceAsset:completion:
defaultInstance
autoDownloadedVoices
selectVoiceForLang:type:gender:footprint:
activeVoiceAssets
installedAssetsForType:voicename:language:gender:footprint:
assetType
containsObject:
standardInstance
disableAssetCleaning
errorWithDomain:code:userInfo:
inactiveVoiceAssets
purgeAndReturnError:
resetCache
dictionary
setObject:forKeyedSubscript:
_purgeAsset:
cacheConcurrentQueue
removeAllObjects
addObjectsFromArray:
predicateWithBlock:
filterUsingPredicate:
arrayWithCapacity:
installedVoiceResources
voiceSelectionCache
enableLocalVoices
_localVoiceForLanguage:gender:
_builtInVoiceForLanguage:
_nonCacheVoiceSelectionForLanguage:type:gender:footprint:
selectPreinstalledVoiceForLanguage:gender:
voiceResourceCache
_nonCacheVoiceResourcesAssetsForLanguage:
isVoiceAssetWellDefined:
localizedDescription
localizedFailureReason
assetQueryQueue
filteredArrayUsingPredicate:
getLatestAssetFromArray:
isEqual:
_downloadAsset:withOptions:completion:
code
populateVoiceData:fromAsset:
doubleValue
floatValue
_downloadAsset:withOptions:progressHandler:
startQuery:
resumeDownload:
adjustDownloadOptions:completion:
setProgressHandler:
beginDownloadWithOptions:
cancelDownloadAndReturnError:
predicateWithFormat:
setSearchPathURL:
sortedArrayUsingComparator:
numberWithInt:
voiceTypeForBundleIdentifier:
reinstallVoiceData:completion:
cleanUnusedVoiceAssets
cleanOldVoiceResources
downloadVoiceAsset:useBattery:progressUpdateHandler:
cancelDownload:completion:
downloadVoiceResource:useBattery:completion:
removeVoiceResource:completion:
voiceAssetWithName:localOnly:outError:
purgeAsset:
setCacheConcurrentQueue:
setAssetQueryQueue:
setVoiceSelectionCache:
setVoiceResourceCache:
_cacheConcurrentQueue
_assetQueryQueue
_voiceSelectionCache
_voiceResourceCache
initWithSuiteName:
addObserver:forKeyPath:options:context:
defaultCenter
removeObserver:
dealloc
willChangeValueForKey:
didChangeValueForKey:
objectForKey:
boolForKey:
setBool:forKey:
synchronize
floatForKey:
setFloat:forKey:
observeValueForKeyPath:ofObject:change:context:
enableAudioDump
setEnableAudioDump:
disableCache
setDisableCache:
setDisableAssetCleaning:
setEnableLocalVoices:
enableHomePodSimulation
setEnableHomePodSimulation:
serverTTSTimeout
setServerTTSTimeout:
forceServerTTS
setForceServerTTS:
disableServerTimeoutFallback
setDisableServerTimeoutFallback:
disableNewBackend
setDisableNewBackend:
internalBuild
isInternalBuild
setIsInternalBuild:
internalDefaults
setInternalDefaults:
_internalBuild
_isInternalBuild
_internalDefaults
bundleForClass:
pathForResource:ofType:
arrayWithContentsOfFile:
setWithArray:
stringByReplacingOccurrencesOfString:withString:
availableLanguages
rangeOfString:
substringWithRange:
fallbackLanguageForLanguage:
fileURLWithPath:isDirectory:
contentsOfDirectoryAtURL:includingPropertiesForKeys:options:error:
resourceValuesForKeys:error:
fileURLWithPath:
removeItemAtURL:error:
getResourceValue:forKey:error:
compare:
subarrayWithRange:
timeIntervalSinceDate:
directorySize:
removeDirectory:
cleanDirectory:withLRULimit:
cleanDirectory:withDateOlderThan:
legacyPlatforms
hardwarePlatform
isAudioAccessory
isServerTTSPlatform
isWatch
initWithFormat:
initWithContentsOfFile:
removeObjectForKey:
retain
stringByStandardizingPath
initWithContentsOfURL:
filePathURL
attributesOfItemAtPath:error:
autorelease
objectAtIndex:
mutableCopy
removeObjectAtIndex:
replaceObjectAtIndex:withObject:
release
modelIdentifier
recognitionResultWithModelIdentifier:classIdentifiers:values:
elementCount
getElementClassIdentifier:value:atIndex:
bundleWithPath:
load
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retainCount
zone
hash
superclass
debugDescription
actionForRecognitionResult:
actionForRecognitionResults:
instancesRespondToSelector:
initialize
recognitionResultByReplacingValueForClassIdentifier:withValue:
valueOfFirstElementWithClassIdentifier:
createHandler
setRecognitionAction:
recognitionAction
reset
_init
cancel
setDelegate:
setActive:
recognitionSessionDidBeginAction:
recognitionSessionWillBeginAction:
recognitionSession:openURL:
recognitionSession:didCompleteActionWithError:
recognitionSession:didFinishSpeakingFeedbackStringWithError:
_notifyDelegateActionStarted
_continueAfterDeferredStart
perform
_hasDeferredStartCallback
_currentRecognizeAction
_debugDumpPath
setAudioType:
setKeepAudioSessionActive:
initWithModelIdentifier:
_setAction:
_isRecognizing
_isActivelyRecognizing
completionType
_setBluetoothInputAllowed:
invalidate
stopSpeakingAtNextBoundary:error:
cancelMaintainingKeepAlive:
methodSignatureForSelector:
invocationWithMethodSignature:
setSelector:
setTarget:
setArgument:atIndex:
retainArguments
scheduledTimerWithTimeInterval:invocation:repeats:
_setSession:
_setDebugDumpPath:
_setDebugDumpEnabled:
_setPreferredEngine:
_setAudioInputPath:
_setInputLevelUpdateInterval:
_setEngineResetRequired:
postNotificationName:object:
_handledThreadedResults:nextAction:
spokenFeedbackString
spokenFeedbackAttributedString
resultDisplayString
statusDisplayString
_inputLevel
_inputLevelDB
_keywordAtIndex:
_keywordCount
_scrambledKeywordsAndAddToSet:
_nextKeywordUsingCursors:
removeObject:
allObjects
_createKeywordIndex
_createPhaseSortedKeywordsFromArray:
_topLevelKeywords
_keywordIndexChanged
postNotificationName:object:userInfo:
_beginSpeakingAttributedString:
beginSpeakingString:
_beginSpeakingString:attributedString:
_notifyDelegateFinishedSpeakingWithError:
initForInputFeedback
startSpeakingAttributedString:toURL:withLanguageCode:error:
startSpeakingString:withLanguageCode:error:
beginNextAction
isRecognizing
isActivelyRecognizing
isFinished
isValid
hasDeferredAction
isBusy
nextActionWillTerminateSession
nextActionWillRecognize
setSensitiveActionsEnabled:
sensitiveActionsEnabled
setBluetoothInputAllowed:
_actionCompleted:nextAction:error:
_actionStarted:
_notifyDelegateOpenURL:
_recognitionResultHandlingThread
recognitionResultHandlingThread:didHandleResults:nextAction:
displayResultString
displayStatusString
setInputLevelUpdateInterval:
inputLevel
inputLevelDB
setKeywordPhase:
keywordAtIndex:
keywordCount
_keywordsForModelIdentifier:
beginSpeakingFeedbackString
speechSynthesizer:didFinishSpeaking:withError:
setDebugDumpEnabled:
debugDumpPath
setNextRecognitionAudioInputPath:
setNextRecognitionRequiresReset:
setPreferredEngine:
setPerformRecognitionHandlerActions:
_modelIdentifier
_keepAlive
_delegate
_currentAction
_handlingThread
_synthesizer
_languageID
_audioInputPath
_levelInterval
_keywordPhase
_sessionFlags
exchangeObjectAtIndex:withObjectAtIndex:
beginChunkDecoderForStreamDescription:
initWithCapacity:
decodeChunk:outError:
appendData:
enumerateObjectsUsingBlock:
endChunkDecoding
_opusDecoder:
initWithLength:
mutableBytes
bytes
dataWithBytes:length:
sharedInstance
decodeChunks:streamDescription:outError:
_decoder
_asbd
string
_session
setResultDisplayString:
setStatusDisplayString:
setSpokenFeedbackString:
setSpokenFeedbackAttributedString:
completeWithNextAction:error:
_resultString
_statusString
_spokenString
_spokenStringIsAttributed
setObject:forKey:
arrayWithObject:
_disambiguationContext
_reset
setRepeatedSpokenFeedbackString:
repeatedSpokenFeedbackString
sequenceTag
setSequenceTag:
knownValueForClassIdentifier:
setKnownValue:phoneticValue:forClassIdentifier:
knownValuesForClassIdentifier:
setKnownValues:phoneticValues:forClassIdentifier:
ambiguousValuesForClassIdentifier:
setAmbiguousValues:phoneticValues:forClassIdentifier:
_keywords
setKeywords:
_createRecognitionInstanceWithCallbacks:info:
_actionForEmptyResults
_repeatedSpokenFeedbackString
_sequenceTag
_knownValues
_knownPhoneticValues
_ambiguousValues
_ambiguousPhoneticValues
_context
languageMapping
dataWithContentsOfFile:
characterSetWithBitmapRepresentation:
characterSetForLanguage:
characterAtIndex:
characterIsMember:
valueWithRange:
unspeakableRangeOfText:forLanguage:
_setDebugDumpEnabled:dumpPath:
_configureNewRecognitionInstance
_setResults:
_releaseFromPrepare
requiresThreadedProcessing
handleResults:withHandler:
makeObjectsPerformSelector:withObject:
_handleRecognitionPrepared:
_handleRecognitionStarted:
_handleRecognitionCompleted:withResults:error:
_recognition
_results
_recognizeFlags
decodeObjectOfClasses:forKey:
vocalizerConfig
searchPathURL
URLByAppendingPathComponent:
dictionaryWithContentsOfURL:
voiceConfig
rate
pitch
volume
resourceMimeTypes
resourceList
defaultVoiceGender
defaultVoiceType
defaultVoiceFootprint
defaultTypeString
defaultFootprintString
setVoiceConfig:
setRate:
setPitch:
setVolume:
setVocalizerConfig:
setResourceList:
setResourceMimeTypes:
_languages
_searchPathURL
_voiceConfig
_rate
_pitch
_volume
_vocalizerConfig
_resourceList
_resourceMimeTypes
rangeValue
whitespaceAndNewlineCharacterSet
setStartTime:
setTextRange:
textRange
wordTimingInfoFrom:timestamps:
startTime
_startTime
_textRange
stopListening
lock
_spokenLanguageChanged:
addObserver:selector:name:object:
unlock
allValues
beginReportingChanges
makeObjectsPerformSelector:
stopReportingChanges
removeObserver:name:object:
_flush
initWithModelIdentifier:classIdentifier:
_enqueueRequest:
performUpdateForModelIdentifier:classIdentifier:
coalescedRequest:
timerWithTimeInterval:target:selector:userInfo:repeats:
mainRunLoop
addTimer:forMode:
dateWithTimeIntervalSinceNow:
setFireDate:
classIdentifier
sharedListener
sharedListenerIfExists
_initShared
startListening
_lock
_updateRequestQueue
_dataProviders
_flushTimer
_isListening
_modelID
_classID
valueCountForClassWithIdentifier:inModelWithIdentifier:
valueAtIndex:forClassWithIdentifier:inModelWithIdentifier:
getValue:weight:atIndex:forClassWithIdentifier:inModelWithIdentifier:
phoneticValueAtIndex:forClassWithIdentifier:inModelWithIdentifier:
cacheValidityIdentifier
isCacheValidityIdentifierValid:
_setConfirmed:
setConfirmedAction:
confirmedAction
setDeniedAction:
deniedAction
_confirmedAction
_deniedAction
_confirmFlags
setURL:
_url
localizations
pathForResource:ofType:inDirectory:forLocalization:
initFileURLWithPath:
pathForResource:ofType:inDirectory:
initWithSpokenFeedbackString:willTerminate:
_shouldTerminate
encodeValueOfObjCType:at:
encodeInt32:forKey:
initWithAudioData:decoderStreamDescription:playerStreamDescription:
decodeValueOfObjCType:at:
decodeInt32ForKey:
numberWithUnsignedLongLong:
copyWithZone:
initWithAudioData:playerStreamDescription:
audioSessionID
setAudioSessionID:
audioData
decoderStreamDescription
playerStreamDescription
enqueue
setEnqueue:
text
setText:
clientBundleIdentifier
setClientBundleIdentifier:
pcmDataSize
setPcmDataSize:
stopHandler
setStopHandler:
_enqueue
_audioSessionID
_audioData
_text
_clientBundleIdentifier
_pcmDataSize
_stopHandler
_decoderStreamDescription
_playerStreamDescription
initWithCondition:
initWithHandler:results:
_handleRequests
detachNewThreadSelector:toTarget:withObject:
unlockWithCondition:
results
nextAction
lockWhenCondition:
handler
setNextAction:
_notifyRequestHandled:
performSelectorOnMainThread:withObject:waitUntilDone:
_requests
_resultHandlingFlags
_handler
_action
initWithDictionaryRepresentation:
matchedString:forTokenInRange:
replaceCharactersInRange:withString:
initWithContentsOfPath:languageIdentifier:
processedTextFromString:
_rules
_tokenizer
boolValue
_matchPattern
_replacement
_caseSensitive
_eatPunctuation
appendString:withAttributes:
attributedStringWithFormatAndAttributes:
formatSpecifier
formattedArg
setAttributes:range:
processInfo
processName
downloadAssetForLanguage:
downloadingAssetLanguage
assetStatusForLanguage:
assetDownloadStatus:progress:size:
removeAssetForLanguage:
_assetCleanupTimer
contextInfoString
languageCode
contextInfo
isEqualToDictionary:
voiceType
decodePropertyListForKey:
appendString:
appendFormat:
enumerateKeysAndObjectsUsingBlock:
isSimilarTo:
setLanguageCode:
setVoiceType:
outputPath
setOutputPath:
shouldCache
setShouldCache:
setContextInfo:
disableCompactVoiceFallback
setDisableCompactVoiceFallback:
resourceListURL
setResourceListURL:
resourceSearchPathURL
setResourceSearchPathURL:
attributedText
setAttributedText:
useCustomVoice
setUseCustomVoice:
voiceName
setVoiceName:
audioSessionIDIsValid
setAudioSessionIDIsValid:
maintainsInput
setMaintainsInput:
audioQueueFlags
setAudioQueueFlags:
pauseHandler
setPauseHandler:
pointer
setPointer:
_shouldCache
_disableCompactVoiceFallback
_forceServerTTS
_useCustomVoice
_audioSessionIDIsValid
_maintainsInput
_languageCode
_footprint
_voiceType
_gender
_outputPath
_contextInfo
_resourceListURL
_resourceSearchPathURL
_attributedText
_voiceName
_audioQueueFlags
_pauseHandler
_pointer
UTF8String
stringWithCapacity:
stringByAppendingFormat:
md5hash
preinstalledAudioHashForLanguage:gender:
completion
audioPlayerDidFinishPlaying:successfully:
audioPlayerDecodeErrorDidOccur:error:
audioPlayerBeginInterruption:
audioPlayerEndInterruption:withOptions:
audioPlayerEndInterruption:withFlags:
audioPlayerEndInterruption:
setCompletion:
_completion
errorWithReason:
getVoiceResourceForLanguage:reply:
isPlaying
stop
category
setActive:withOptions:error:
setCategory:error:
initWithContentsOfURL:error:
setActive:error:
play
mainBundle
preferredLocalizations
opaqueSessionID
processIdentifier
setIdentifier:
setMaintainPersistentConnection:
setMaintainInactivePersistentConnection:
prewarmIfNeededWithRequest:
speechSynthesizer:didStartSpeakingRequest:
speechSynthesizerDidStartSpeaking:
speechSynthesizer:didFinishSpeakingRequest:successfully:withError:
speechSynthesizer:didFinishSpeakingRequest:successfully:phonemesSpoken:withError:
speechSynthesizer:didFinishSpeaking:phonemesSpoken:withError:
speechSynthesizer:didPauseSpeakingRequest:
speechSynthesizerDidPauseSpeaking:
speechSynthesizer:didContinueSpeakingRequest:
speechSynthesizerDidContinueSpeaking:
speechSynthesizer:willSpeakRangeOfSpeechString:forRequest:
speechSynthesizer:willSpeakRangeOfSpeechString:
speechSynthesizer:didFinishSpeakingRequest:withInstrumentMetrics:
presynthesizedAudioRequest
isSystemSpeaking
stopPresynthesizedAudioRequest
request
stopCurrentSpeechRequestAtMark:
pauseCurrentSpeechRequestAtMark:
_setDelegate:
validateRequest:
startSynthesisRequest:
_stopSpeakingRequest:atNextBoundary:synchronously:error:
_stopSpeakingPresynthesizedAudioRequest:synchronously:error:
startSpeechRequest:
validatePresynthesizedAudioRequest:
connection:presynthesizedAudioRequest:didStopAtEnd:error:
startPresynthesizedAudioRequest:
cachePresynthesizedAudioRequest:
_pauseSpeakingRequest:atNextBoundary:synchronously:error:
isSystemSpeakingOnBehalfOfCurrentConnection
continueCurrentSpeechRequest
speechSynthesizer:withRequest:didReceiveTimingInfo:
speechSynthesizer:didFinishSynthesisRequest:withInstrumentMetrics:error:
speechSynthesizer:didFinishSynthesisRequest:withError:
speechSynthesizer:didStartPresynthesizedAudioRequest:
speechSynthesizer:didStopPresynthesizedAudioRequest:atEnd:error:
speechSynthesizer:didStopPresynthesizedAudioRequestAtEnd:error:
speechSynthesizer:didFinishPresynthesizedAudioRequest:withInstrumentMetrics:error:
setLogToFile:
getLogToFile:
language
_startSpeakingString:orAttributedString:toURL:withLanguageCode:request:error:
pauseSpeakingAtNextBoundary:synchronously:error:
_continueSpeakingRequest:withError:
startSpeakingRequest:
startSynthesizingRequest:
startSpeakingString:toURL:withLanguageCode:error:
stopSpeakingAtNextBoundary:synchronously:error:
availableVoicesForLanguageCode:
availableLanguageCodes
availableFootprintsForVoice:languageCode:
getTTSServerVoicesWithFilter:reply:
beginAudioPowerUpdateWithReply:
endAudioPowerUpdate
cleanUnusedAssets:
getLocalVoiceAssets:
getLocalVoiceResources:
setAutoDownloadedVoiceAssets:
getAutoDownloadedVoiceAssets:
getVoiceInfoForLanguageCode:footprint:gender:type:reply:
playVoicePreviewForLanguageCode:gender:
availableVoices
getAllVoiceAssets:
getVoiceInfoForLanguageCode:footprint:gender:custom:reply:
connection:speechRequestDidStart:
connection:speechRequestDidPause:
connection:speechRequestDidContinue:
connection:speechRequest:didStopAtEnd:phonemesSpoken:error:
connection:speechRequest:willSpeakMark:inRange:
connection:speechRequest:successWithInstrumentMetrics:
connection:speechRequest:didReceiveTimingInfo:
connection:synthesisRequest:didFinishWithInstrumentMetrics:error:
connection:presynthesizedAudioRequestDidStart:
connection:presynthesizedAudioRequest:successWithInstrumentMetrics:error:
startSpeakingPresynthesizedAudioRequest:
stopSpeakingPresynthesizedAudioSynchronously:error:
isSpeaking
speechString
minimumRate
maximumRate
stopSpeakingRequest:atNextBoundary:synchronously:error:
prewarmIfNeeded
startSpeakingString:request:error:
startSpeakingString:toURL:request:error:
startSpeakingString:withLanguageCode:request:error:
stopSpeakingRequest:atNextBoundary:error:
pauseSpeakingRequest:atNextBoundary:error:
pauseSpeakingRequest:atNextBoundary:synchronously:error:
pauseSpeakingAtNextBoundary:error:
continueSpeakingRequest:withError:
useSharedAudioSession:
useSpecificAudioSession:
useAudioQueueFlags:
startSynthesizingString:toFileURL:shouldCache:request:
startSpeakingString:error:
startSpeakingString:toURL:error:
continueSpeakingWithError:
delegate
voice
setVoice:
setLanguage:
_inactiveKeepAlive
_queue
_callbackQueue
_xpcConnection
_identifier
_synthesizerFlags
_voice
_language
dictionaryRepresentation
arrayForKey:
setAutoDownloadedVoices:
setLastTTSRequestDate:
lastTTSRequestDate
defaults
setDefaults:
_defaults
initWithMachServiceName:options:
maintainWithAudioType:keepAudioSessionActive:
interfaceWithProtocol:
setRemoteObjectInterface:
_ensureKeepAliveMaintenance
setInterruptionHandler:
resume
_serverConnection
remoteObjectProxy
_remoteKeepAlive
audioType
active
keepAudioSessionActive
_audioType
_active
_keepAudioSessionActive
setConnection:
updateWithConnectionIdentifier:
pauseSpeechRequestAtMark:
continueSpeechRequest
stopSpeechRequestAtMark:
getVoiceNamesForLanguage:reply:
getFootprintsForVoiceName:languageCode:reply:
getSpeechIsActiveReply:
getSpeechIsActiveForConnectionReply:
getLocalVoicesReply:
getLocalVoiceResourcesReply:
setClasses:forSelector:argumentIndex:ofReply:
_connectionInvalidated
setInvalidationHandler:
speechRequestDidStart
speechRequestDidPause
speechRequestDidContinue
speechRequestMark:didStartForRange:
speechRequestDidStopWithSuccess:phonemesSpoken:error:
speechRequestSuccessWithInstrumentMetrics:
speechRequestDidReceiveTimingInfo:
synthesisRequest:didReceiveTimingInfo:
synthesisRequest:didFinishWithInstrumentMetrics:error:
presynthesizedAudioRequestDidStart
presynthesizedAudioRequestDidStopAtEnd:error:
presynthesizedAudioRequestSuccessWithInstrumentMetrics:error:
setExportedInterface:
delegateWrapper
setExportedObject:
xpcConnection
remoteObjectProxyWithErrorHandler:
concurrentSynthesisRequests
setXpcConnection:
setRequest:
setPresynthesizedAudioRequest:
setConcurrentSynthesisRequests:
_remoteObjectWithErrorHandler:
synchronousRemoteObjectProxyWithErrorHandler:
_remoteObject
identifier
setDelegateWrapper:
threadSafeQueue
setThreadSafeQueue:
_delegateWrapper
_threadSafeQueue
connection
_request
_concurrentSynthesisRequests
_presynthesizedAudioRequest
_connection
lowercaseString
voiceKey
isBuiltInVoice
_isInstalled
_isBuiltInVoice
_name
_type
anonymousListener
setQueue:
setHandler:
setListener:
endpoint
setEndpoint:
_setQueue:
invokeUpdateWithObject:
initWithBlock:
initWithListenerEndpoint:
configuredEndpointWithUpdateHandler:withConnection:
remoteUpdateHanderForEndpoint:
listener:shouldAcceptNewConnection:
queue
listener
_endpoint
_listener
_block
VSAssetBase
NSSecureCoding
NSCoding
VSInstrumentMetrics
VSVoiceAssetSelection
VSMobileAssetsManager
VSSpeechInternalSettings
VSSpeechSynthesizerPreference
VoiceServices
VSUtilities
VSRecognitionResultHandler
NSObject
VSRecognitionResult
VSRecognitionSession
VSRecognitionSessionKeywords
VSOpusDecoder
VSRecognitionAction
VSRecognitionDisambiguateAction
VSSpeechCharacterSet
VSRecognitionRecognizeAction
VSVoiceResourceAsset
VSSpeechWordTimingInfo
VSCacheUpdateListener
VSCacheUpdateRequest
VSRecognitionModelDataProvider
VSRecognitionConfirmAction
VSRecognitionURLAction
VSRecognitionSpeakAction
VSPresynthesizedAudioRequest
NSCopying
VSRecognitionResultHandlingThread
VSRecognitionResultHandlingRequest
VSTextPreProcessor
VSTextPreProcessorRule
VSSpeechAdditions
VSFormatArgument
VSAssetUpdateListener
VSSpeechRequest
Hash
VSAudioPreviewDelegate
AVAudioPlayerDelegate
VSSpeechSynthesizer
VSSpeechConnectionDelegate
VSPreferencesInterface
VSRemoteKeepAlive
VSKeepAlive
VSSpeechXPCServiceProtocol
VSSpeechServiceDelegate
VSSpeechConnection
VSSpeechConnectionDelegateWrapper
VSVoiceAsset
VSGenericUpdate
VSGenericUpdateEndpoint
NSXPCListenerDelegate
VSGenericBlockHolder
B8@0:4
v12@0:4@8
@12@0:4@8
v12@0:4@"NSCoder"8
@12@0:4@"NSCoder"8
v8@0:4
@8@0:4
@"NSString"
@"NSNumber"
d8@0:4
q8@0:4
v16@0:4q8
v16@0:4d8
v12@0:4B8
i8@0:4
v12@0:4i8
I8@0:4
@"VSVoiceAsset"
@"ASAsset"
@32@0:4l8@12@16l20l24B28
@16@0:4@8B12
@28@0:4l8@12@16l20l24
@24@0:4@8l12l16l20
@12@0:4l8
l12@0:4@8
B12@0:4@8
@16@0:4@8l12
v16@0:4@8@?12
v20@0:4@8B12@?16
@20@0:4@8B12^@16
v20@0:4@8@12@?16
v16@0:4@8@12
@"NSObject<OS_dispatch_queue>"
@"NSMutableDictionary"
v24@0:4@8@12@16^v20
f8@0:4
v12@0:4f8
@"NSUserDefaults"
I12@0:4@8
v16@0:4@8I12
#8@0:4
@12@0:4:8
@16@0:4:8@12
@20@0:4:8@12@16
B12@0:4#8
B12@0:4:8
Vv8@0:4
^{_NSZone=}8@0:4
B12@0:4@"Protocol"8
@"NSString"8@0:4
@"VSRecognitionAction"12@0:4@"VSRecognitionResult"8
@"VSRecognitionAction"12@0:4@"NSArray"8
@20@0:4@8@12@16
@16@0:4@8@12
B20@0:4^@8^@12i16
B12@0:4B8
@12@0:4B8
v20@0:4@8@12@16
v12@0:4I8
@12@0:4i8
^{__CFDictionary=}8@0:4
v20@0:4@8B12@16
B12@0:4i8
@"VSKeepAlive"
@"<VSRecognitionSessionDelegate>"
@"VSRecognitionAction"
@"NSArray"
@"VSSpeechSynthesizer"
{?="delegateWillBegin"b1"delegateBegin"b1"delegateOpenURL"b1"delegateFinishedSpeaking"b1"delegateComplete"b1"debugDumpEnabled"b1"preferredEngine"b2"performHandlerActions"b1"allowSensitiveActions"b1"bluetoothAllowed"b1"resetNextAction"b1"isSpeaking"b1"actionBegan"b1"actionBeginning"b1"actionBeginDeferred"b1"invalid"b1"observeKeywordChange"b1}
@12@0:4^{__CFDictionary=}8
^{OpaqueAudioConverter=}48@0:4{AudioStreamBasicDescription=dIIIIIIII}8
@56@0:4@8{AudioStreamBasicDescription=dIIIIIIII}12^@52
@48@0:4{AudioStreamBasicDescription=dIIIIIIII}8
@16@0:4@8^@12
^{OpaqueAudioConverter=}
{AudioStreamBasicDescription="mSampleRate"d"mFormatID"I"mFormatFlags"I"mBytesPerPacket"I"mFramesPerPacket"I"mBytesPerFrame"I"mChannelsPerFrame"I"mBitsPerChannel"I"mReserved"I}
(?="stringValue"@"NSString""attributedStringValue"@"NSAttributedString")
@"VSRecognitionSession"
^{__VSRecognitionDisambiguationContext=}8@0:4
^{__VSRecognition=}16@0:4^{?=^?^?^?}8^v12
B16@0:4d8
B16@0:4B8@12
v12@0:4^{__VSRecognition=}8
v20@0:4^{__VSRecognition=}8^{__CFArray=}12^{__CFError=}16
{?="debugDumpEnabled"b1"preferredEngine"b2"resetEngine"b1"bluetoothAllowed"b1"hasStarted"b1}
l8@0:4
@"NSURL"
@"NSDictionary"
{_NSRange=II}8@0:4
v16@0:4{_NSRange=II}8
{_NSRange="location"I"length"I}
@"NSLock"
@"NSMutableArray"
@"NSTimer"
i16@0:4@8@12
@20@0:4i8@12@16
B28@0:4^@8^i12i16@20@24
i16@0:4@"NSString"8@"NSString"12
@"NSString"20@0:4i8@"NSString"12@"NSString"16
B28@0:4^@8^i12i16@"NSString"20@"NSString"24
@"NSDictionary"8@0:4
B12@0:4@"NSDictionary"8
{?="initializing"b1"confirmed"b1}
@12@0:4^{_NSZone=}8
@52@0:4@8{AudioStreamBasicDescription=dIIIIIIII}12
@92@0:4@8{AudioStreamBasicDescription=dIIIIIIII}12{AudioStreamBasicDescription=dIIIIIIII}52
{AudioStreamBasicDescription=dIIIIIIII}8@0:4
Q8@0:4
v16@0:4Q8
@?8@0:4
v12@0:4@?8
@"NSData"
@"<VSRecognitionResultHandlingThreadDelegate>"
@"NSConditionLock"
{?="running"b1"delegateDidHandleResults"b1"valid"b1}
@"<VSRecognitionResultHandler>"
^{__CFStringTokenizer=}
@16@0:4@8^{?=ii}12
i12@0:4@8
B20@0:4@8^f12^q16
@"PCPersistentTimer"
v12@0:4l8
@"NSAttributedString"
v16@0:4@8B12
v16@0:4@"AVAudioPlayer"8B12
v16@0:4@"AVAudioPlayer"8@"NSError"12
v12@0:4@"AVAudioPlayer"8
v16@0:4@"AVAudioPlayer"8I12
B16@0:4@8l12
v28@0:4@8l12l16B20@?24
v28@0:4@8l12l16l20@?24
v28@0:4@8@12B16@20@24
v28@0:4@8@12l16{_NSRange=II}20
v24@0:4@8@12@16@20
v24@0:4@8@12B16@20
v16@0:4@"VSSpeechConnection"8@"VSSpeechRequest"12
v28@0:4@"VSSpeechConnection"8@"VSSpeechRequest"12B16@"NSString"20@"NSError"24
v28@0:4@"VSSpeechConnection"8@"VSSpeechRequest"12l16{_NSRange=II}20
v20@0:4@"VSSpeechConnection"8@"VSSpeechRequest"12@"VSInstrumentMetrics"16
v20@0:4@"VSSpeechConnection"8@"VSSpeechRequest"12@"NSArray"16
v24@0:4@"VSSpeechConnection"8@"VSSpeechRequest"12@"VSInstrumentMetrics"16@"NSError"20
v16@0:4@"VSSpeechConnection"8@"VSPresynthesizedAudioRequest"12
v24@0:4@"VSSpeechConnection"8@"VSPresynthesizedAudioRequest"12B16@"NSError"20
v24@0:4@"VSSpeechConnection"8@"VSPresynthesizedAudioRequest"12@"VSInstrumentMetrics"16@"NSError"20
B20@0:4@8B12^@16
B24@0:4@8i12B16^@20
B20@0:4i8B12^@16
B16@0:4B8^@12
B16@0:4@8^@12
B24@0:4@8@12@16^@20
B20@0:4@8^@12^@16
B24@0:4@8@12^@16^@20
B20@0:4@8i12^@16
B16@0:4i8^@12
B32@0:4@8@12@16@20^@24^@28
@24@0:4@8@12B16^@20
B20@0:4@8@12^@16
B12@0:4^@8
@"VSSpeechConnection"
{?="delegateStart"b1"delegateFinish"b1"delegateFinishWithPhonemesSpoken"b1"delegatePause"b1"delegateContinue"b1"delegateWillSpeak"b1"delegateStartWithRequest"b1"delegateFinishWithRequest"b1"delegateFinishWithPhonemesSpokenWithRequest"b1"delegateSuccessWithInstrumentMetrics"b1"delegatePauseWithRequest"b1"delegateContinueWithRequest"b1"delegateWillSpeakWithRequest"b1"willUseInput"b1}
@"<VSSpeechSynthesizerDelegate>"
Vv16@0:4i8B12
@"NSXPCConnection"
Vv12@0:4@8
Vv12@0:4l8
Vv16@0:4@8@?12
Vv20@0:4@8@12@?16
Vv12@0:4@?8
Vv28@0:4@8l12l16l20@?24
Vv12@0:4B8
Vv12@0:4@"NSString"8
Vv12@0:4@"VSSpeechRequest"8
Vv12@0:4@"VSPresynthesizedAudioRequest"8
Vv16@0:4@"NSString"8@?<v@?@"NSArray">12
Vv20@0:4@"NSString"8@"NSString"12@?<v@?@"NSArray">16
Vv12@0:4@?<v@?B>8
Vv12@0:4@?<v@?@"AFXPCWrapper">8
Vv12@0:4@?<v@?@"NSError">8
Vv12@0:4@?<v@?@"NSArray"@"NSError">8
Vv12@0:4@"NSArray"8
Vv12@0:4@?<v@?@"NSArray">8
Vv16@0:4@"NSString"8@?<v@?@"VSVoiceResourceAsset">12
Vv28@0:4@"NSString"8l12l16l20@?<v@?@"VSVoiceAsset">24
Vv16@0:4@"VSVoiceAsset"8@?<v@?@"NSArray"@"NSError">12
Vv20@0:4l8{_NSRange=II}12
Vv20@0:4B8@12@16
Vv16@0:4@8@12
Vv20@0:4@8@12@16
Vv16@0:4B8@12
Vv20@0:4B8@"NSString"12@"NSError"16
Vv12@0:4@"VSInstrumentMetrics"8
Vv16@0:4@"VSSpeechRequest"8@"NSArray"12
Vv20@0:4@"VSSpeechRequest"8@"VSInstrumentMetrics"12@"NSError"16
Vv16@0:4B8@"NSError"12
Vv16@0:4@"VSInstrumentMetrics"8@"NSError"12
@12@0:4@?8
@"<VSSpeechConnectionDelegate>"
@"VSSpeechConnectionDelegateWrapper"
@"VSSpeechRequest"
@"VSPresynthesizedAudioRequest"
@16@0:4@?8@12
@?12@0:4@8
B16@0:4@8@12
B16@0:4@"NSXPCListener"8@"NSXPCConnection"12
@"NSXPCListenerEndpoint"
@"NSXPCListener"
@mcpl
@mcpl
@supo
@mcpl
Missing language in voice data:%@
Can't find request language %@ in default languages
reinstall asset: %@
Skip asset that is used by Accessibility, %@
Skip currently in-use asset, %@
Cleaning voice assets is disabled in internal setting. Skip cleaning...
Unable to clean asset: %@, error:%@
Purged asset: %@
#MobileAsset reset cached mobile asset results
Getting cached result for voice selection key: %@
Search local voices for lang: %@, gender: %@
Built in voice is requested.
Search voice asset for lang: %{public}@, type: %@, gender: %@, footprint: %@
Gryphon voice not found, search premium custom voice asset with same gender
Search voices in pre-installed location as fallback
Search custom compact voice assets with same gender
Search available vocalizer voice assets with same gender
Caching voice selection: %{public}@
Fallback to built-in compact voice for lang: %@
Selected %{public}@
Get cached %@
Search VoiceResource for '%@'
Caching %@
%@, %@
#MobileAsset Start querying voice asset for: %@
Enqueued asset query %p for: %p
Running asset query %p for: %@
#MobileAsset Error querying MobileAsset. %@
#MobileAsset Can't download due to unfound asset: %@
Skip downloading the pre-installed voice: %@_%@
Unable to download voice that is not well defined: %@
#MobileAsset #DownloadVoice Start querying voice asset for: %@
#MobileAsset #DownloadVoice Error querying MobileAsset. %@
#MobileAsset #DownloadVoice Network request timed out, make sure AppleWiFiSecure or VPN is connected if you are on internal build.
#MobileAsset #DownloadVoice Can't download due to unfound asset: %@
#MobileAsset #DownloadVoice Asset is installed already: %@
Enqueued download cancellation for: %@
#MobileAsset Start querying resource asset for: %@
#MobileAsset Resume download: %@
#MobileAsset Adjust download: %@
#MobileAsset Start download: %@
#MobileAsset Asset is already installed or is downloading: %@
#MobileAsset purge asset: %@
#MobileAsset cancel downloading asset: %@
#MobileAsset ignore non-local asset: %@
#MobileAsset Can't remove asset %@
#MobileAsset Unable to query legacy voices. error: %@
Couldn't found any built in voice for lang: %@
Failed to convert %ld recognition results
Error getting cache path: %@, error: %@
Unable to get URL: %@, URL resources: %@
Can't remove file '%@', error: %@
Cleaned directory: '%@', LRU limit: %d, latency: %f
compact explicitly specified, look at framework asset first
Now looking for the fallback language: %@
Looking for the resources in %@
Can't find the resources anywhere!
Found the resources here: %@
No TTS resources for asset. Trying fallback language for %@
Using asset fallback language %@
Couldn't get the engine format version for language %@
VoiceEngineFormatVersions hasn't been initialized, voices may not be compatible
Trying to migrate asset because it's not valid: %@
After migrating asset, it's still not valid -- sorry
---> asset's version is %@
---> engine's version is %@
Couldn't get asset's version and/or language
Deleting the asset located here: %@ because the format versions don't match
***ERROR*** There was an error (%d - %s) when trying to symlink %s to %s
Symlinked %s to %s
Successfully appended broker header files
***ERROR*** couldn't append broker header files (%d - %s)
***ERROR*** couldn't move broker header file to final location (%d - %s)
Couldn't initialize the engine voice format versions
Unable to lock temporary asset: %s; presumably peer was first - error: %d
Temporary asset: %s has moved; presumably peer was first - error: %d
Couldn't move the temporary asset: %s to the real asset: %s - error: %d
Moved the temporary asset: %s to the real asset: %s
Couldn't get the contents of the assets directory (error %ld)
Deleting asset at url: %@
Invalid target asbd: %@
Could not create Opus decoder: %{public}d
Only expecting to get 1 packet at a time, not %lu
Enqueuing request: %@
Queue is now:
#Deprecated  %s, called from '%@'
Unable to locate preview sample file for %@
#PrewarmRequest from client:%@, language: %@
Error #SpeechPauseRequest not currently speaking
#SynthesisRequest %p client:%@, %@
Start #SpeechRequest %p from client:%@, %@
#PresynthesizedAudioRequest: %@
Presynthesized audio request failed validation
Cache #PresynthesizedAudioRequest: %@
#SpeechStopRequest client:%@, boundary: %@, synchronously: %@
Error #SpeechStopRequest %@
#SpeechStopPresynthesizedAudioRequest client:%@, synchronously: %@
Error #PresynthesizedAudioStopRequest %@
#SpeechPauseRequest client:%@, boundary: %@, synchronously: %@
#SpeechResumeRequest client:%@
Error #SpeechResumeRequest no active speech job
#AudioPower Begin update
#AudioPower End update
#AutoDownloadRequest #MobileAsset, language: %@, gender: %ld, type: %ld, footprint: %ld, name: %@
%@ is not TTS language, fallback to %@
Closing xpc connection %p
Error updateWithConnectionIdentifier: %@
Can't prewarm %@
Error %@ asking for voices
Error at %s , %@ 
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
