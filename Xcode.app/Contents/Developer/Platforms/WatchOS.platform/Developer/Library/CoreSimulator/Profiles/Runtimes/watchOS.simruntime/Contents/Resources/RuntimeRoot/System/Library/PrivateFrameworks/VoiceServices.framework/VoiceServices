_bundleIdentifier
_compatibilityVersion
_contentVersion
_masteredVersion
supportsSecureCoding
TB,R
bundleIdentifier
T@"NSString",C,N,V_bundleIdentifier
compatibilityVersion
T@"NSNumber",C,N,V_compatibilityVersion
contentVersion
T@"NSNumber",C,N,V_contentVersion
masteredVersion
T@"NSString",C,N,V_masteredVersion
Time-to-speak latency: %.3f, AudioQueueStart latency: %.3f, Synthesis time: %.3f, warm_start:%@, isCacheHitFromDisk:%@, isCacheHitFromMemory:%@, audio_duration:%.3f, eagerRequestTimeGap: %.3f
_utterance
_voiceAssetKey
_requestCreatedTimestamp
_synthesisBeginTimestamp
_synthesisEndTimestamp
_speechBeginTimestamp
_speechEndTimestamp
_audioStartTimestampDiffs
_synthesisToSpeechTimeGap
_waitForSynthesisToFinishTimeDelay
_audioDuration
_isWarmStart
_isCacheHitFromDisk
_isCacheHitFromMemory
_isSpeechRequest
v4@?0
utterance
T@"NSString",C,V_utterance
voiceAssetKey
T@"NSString",C,V_voiceAssetKey
requestCreatedTimestamp
TQ,V_requestCreatedTimestamp
eagerRequestCreatedTimeStampDiffs
TQ,V_eagerRequestCreatedTimeStampDiffs
synthesisBeginTimestamp
TQ,V_synthesisBeginTimestamp
synthesisEndTimestamp
TQ,V_synthesisEndTimestamp
speechBeginTimestamp
TQ,V_speechBeginTimestamp
speechEndTimestamp
TQ,V_speechEndTimestamp
audioStartTimestampDiffs
TQ,V_audioStartTimestampDiffs
audioDuration
Td,V_audioDuration
isWarmStart
TB,V_isWarmStart
isSpeechRequest
TB,V_isSpeechRequest
synthesisToSpeechTimeGap
TQ,V_synthesisToSpeechTimeGap
waitForSynthesisToFinishTimeDelay
TQ,V_waitForSynthesisToFinishTimeDelay
isCacheHitFromDisk
TB,V_isCacheHitFromDisk
isCacheHitFromMemory
TB,V_isCacheHitFromMemory
com.apple.MobileAsset.VoiceServicesVocalizerVoice
com.apple.MobileAsset.VoiceServices.CustomVoice
com.apple.MobileAsset.VoiceServices.GryphonVoice
com.apple.MobileAsset.VoiceServices.VoiceResources
Name
Languages
Language
Gender
Footprint
Type
voice_configs.plist
TTSResources/PreinstallAssets/
%@:%@:%@:%@:%@:%@
%@.tmp
voiceData
T@"VSVoiceAsset",&,V_voiceData
asset
T@"ASAsset",&,V_asset
builtInVoicePath
T@"NSString",&,V_builtInVoicePath
voicePath
T@"NSString",&,N,V_voicePath
VSMobileAssetManagerCacheQueue
com.apple.voiced.assetQueryQueue
com.apple.voiceservices
preinstall_metadata.plist
_RelativePath
AssetData
_CompatibilityVersion
_ContentVersion
_MasterVersion
Assets
i12@?0@"VSVoiceResourceAsset"4@"VSVoiceResourceAsset"8
(%K BETWEEN %@)
(%@ == %K)
(%@ IN %K)
 && 
(%K == %@)
(%@ in %K)
v8@?0@"NSError"4
VSMobileAssetManager
Cleaning voice assets is disabled in internal setting.
v12@?0@"NSMutableArray"4l8
B12@?0@"ASAsset"4@"NSDictionary"8
%@:%@:%@:%@
Voice asset is not well defined, be more specific
v16@?0d4f12
Operation
WaitingToDownload
DownloadingAsset
EstimatedTimeRemaining
OperationProgress
OperationCompleted
v12@?0@"NSDictionary"4@"NSError"8
v12@?0@"NSArray"4@"NSError"8
(%K != nil)
i12@?0@"VSVoiceAssetSelection"4@"VSVoiceAssetSelection"8
/var/mobile/Library/VoiceServices/voices/%@_%@/AssetData
local_voice
i12@?0@"ASAsset"4@"ASAsset"8
cacheConcurrentQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_cacheConcurrentQueue
assetQueryQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_assetQueryQueue
voiceSelectionCache
T@"NSMutableDictionary",&,N,V_voiceSelectionCache
voiceResourceCache
T@"NSMutableDictionary",&,N,V_voiceResourceCache
AXAccessibilitySiriVoicesInUse
/System/Library/PrivateFrameworks/AccessibilityUtilities.framework/AccessibilityUtilities
_default
VSRecognition
<VSRecognition: %p model=%@>
recognition is already active
recognition reuse attempted
error converting disambiguation context to server
error converting audio input path to server
error converting model identifier
connection failure
recognition request denied
couldn't establish connection
recognition cancelled
connection lost
com.apple.voiceserviceslogging
default
InternalBuild
DisableCaching
DisableAssetCleaning
EnableLocalVoices
EnableHomePodSimulation
isInternalBuild
TB,N,V_isInternalBuild
internalDefaults
T@"NSUserDefaults",&,N,V_internalDefaults
internalBuild
TB,R,N,V_internalBuild
disableCache
TB,N
disableAssetCleaning
enableLocalVoices
enableHomePodSimulation
tts_languages
plist
tts_language_fallbacks
en-US
_VSServerConnection
com.apple.voiced
note.server.died
note.recog.prepare
note.recog.start
note.recog.results
note.recog.cancel
note.recog.error
key.recog.results
key.recog.errordesc
key.recog.errorcode
VSErrorDomain
vsplist
yyyy-MM-dd-HH-mm-ss'.vslog'
Library
Logs
CrashReporter
VoiceServicesRecognition
Latest.vslog
HH-mm-ss-
MaxLogCount
classes
phrases
modelid
handler
) <%@>
VSRecognitionResult
%@:%@
seqtag
known
knownp
ambig
ambigp
VSRecognitionDisambiguationContext
<VSRecognitionDisambiguationContext %p [%@]> 
 will disambiguate with sequence tag %@
 known class values:
constrained ambiguous classes:
  %@ = "%@" (%@)
  %@ = "%@"
  %@ =
     "%@" (%@)
     "%@"
com.apple.voiceservices.kwidxchanged
top-level
class-kws
__model-kws
s5l8942x
s5l8947x
s7002
t8002
HardwarePlatform
DeviceClassNumber
com.apple.voiceservices.logging
VSLogLevel
VSOutputLevel
com.apple.voiceservices.language
lang-id
%@Library/Managed Preferences/mobile/%@.plist
mobile
com.apple.AppSupport.loggingDefaultsChanged
Auto Downloaded Assets
Last Asset Remote Query
Last Aggressive Download
Last Asset Paths
%@-%@
en-GB
zh-HK
zh-TW
RecognitionResources/Express
TTSResources
language_fallbacks.plist
zh-Hans
zh-CN
com.apple.language.changed
range
com.apple.voiceservices.assetInstalled
common
Library/VoiceServices/Assets
FormatVersion
.migrated
NotForSiri
voice_format_version.plist
broker.hdr
broker.hdr.tmp
broker.hdr.asset
Tones
%@%@
.tmp
hash
TI,R
superclass
T#,R
description
T@"NSString",R,C
debugDescription
VSRecognitionSessionKeywordsDidChangeNotification
action already in progress
session is finished or invalid
session is invalid or not finished
session is already speaking
VSSpeechServiceDecoderErrorDomain
v16@?0@"NSData"4I8^B12
Failed to create opus decoder
l16@?0^I4^{AudioBufferList=I[1{AudioBuffer=II^v}]}8^^{AudioStreamPacketDescription}12
decoder gave us %d bytes bytes but we really only expected %d
Could not finish decoding, res %d
Default
Compact
Premium
PremiumHigh
Male
Female
recognition action not implemented
VSSpeechLangCharset
could not create recognition instance
recognition already attempted or in progress
vocalizer_resources
_voices
VoiceServices-Config.plist
voice_speech_rate
voice_speech_pitch
voice_speech_volume
VoiceResource: %@, CV: %@, MV: %@
_languages
_searchPathURL
%@:%@:%@
voiceConfig
T@"NSDictionary",C,N,V_voiceConfig
rate
Tf,N,V_rate
pitch
Tf,N,V_pitch
volume
Tf,N,V_volume
vocalizerConfig
T@"NSDictionary",&,N,V_vocalizerConfig
languages
T@"NSArray",C,N,V_languages
resourceList
T@"NSDictionary",C,N,V_resourceList
searchPathURL
T@"NSURL",C,N,V_searchPathURL
_startTime
_textRange
startTime
Td,N,V_startTime
textRange
T{_NSRange=II},N,V_textRange
model <%@> class <%@>
com.apple.yn
no URL to launch
{AudioStreamBasicDescription=dIIIIIIII}
_audioData
_clientBundleIdentifier
_audioSessionID
_enqueue
%@%@kHz
Opus
PCM%@KHz
enqueue %@, sessionId %u, clientId %@, %@ bytes, input format %@, output format %@, requestCreatedTime %@
clientBundleIdentifier
T@"NSString",C,N,V_clientBundleIdentifier
pcmDataSize
TI,N,V_pcmDataSize
stopHandler
T@?,C,N,V_stopHandler
audioSessionID
TI,N,V_audioSessionID
audioData
T@"NSData",R,C,N,V_audioData
decoderStreamDescription
T{AudioStreamBasicDescription=dIIIIIIII},R,N,V_decoderStreamDescription
playerStreamDescription
T{AudioStreamBasicDescription=dIIIIIIII},R,N,V_playerStreamDescription
enqueue
TB,N,V_enqueue
TQ,N,V_requestCreatedTimestamp
match
replace
case-sensitive
eat-punct
com.apple.voiceservices.class
title
name
+[VSAssetUpdateListener sharedListener]
-[VSAssetUpdateListener startListening]
-[VSAssetUpdateListener stopListening]
-[VSAssetUpdateListener downloadAssetForLanguage:]
-[VSAssetUpdateListener downloadingAssetLanguage]
-[VSAssetUpdateListener assetStatusForLanguage:]
-[VSAssetUpdateListener assetDownloadStatus:progress:size:]
-[VSAssetUpdateListener removeAssetForLanguage:]
%@, text: '%@', language:%@, type:%@, gender:%@, footprint:%@, rate:%f, pitch:%f, volume:%f
textForAttributes
attributes
_text
_languageCode
_voiceName
_footprint
_useCustomVoice
_voiceType
_gender
_outputPath
_rate
_pitch
_volume
_maintainsInput
_audioSessionIDIsValid
_shouldCache
_disableCompactVoiceFallback
_audioQueueFlags
_resourceListURL
_resourceSearchPathURL
_contextInfo
_pointer
%@%@: %@
v16@?0@4@8^B12
attributedText
T@"NSAttributedString",C,N,V_attributedText
useCustomVoice
TB,N,V_useCustomVoice
voiceName
T@"NSString",C,N,V_voiceName
audioSessionIDIsValid
TB,N,V_audioSessionIDIsValid
maintainsInput
TB,N,V_maintainsInput
audioQueueFlags
TI,N,V_audioQueueFlags
pauseHandler
T@?,C,N,V_pauseHandler
pointer
Ti,N,V_pointer
text
T@"NSString",C,N,V_text
languageCode
T@"NSString",C,N,V_languageCode
footprint
Tl,N,V_footprint
voiceType
Tl,N,V_voiceType
gender
Tl,N,V_gender
outputPath
T@"NSURL",C,N,V_outputPath
shouldCache
TB,N,V_shouldCache
Td,N,V_rate
Td,N,V_pitch
Td,N,V_volume
contextInfo
T@"NSDictionary",C,N,V_contextInfo
disableCompactVoiceFallback
TB,N,V_disableCompactVoiceFallback
resourceListURL
T@"NSURL",C,N,V_resourceListURL
resourceSearchPathURL
T@"NSURL",C,N,V_resourceSearchPathURL
com.apple.voiceservices.keepalive
com.apple.voiceservices.tts
completion
T@?,C,N,V_completion
nil request
input text is not set
audio data is invalid
v8@?0@"VSVoiceResourceAsset"4
%@_%@_legacy.caf
%@_%@.caf
VSSpeechSynthesizer
VSSpeechSynthesizerCallbackThread
language_fallbacks
VSSpeechSynthesizer_%p@%@_%d
nil languageCode
not currently speaking
no active speech job
language
T@"NSString",C,N,V_language
delegate
T@"<VSSpeechSynthesizerDelegate>",W,N,V_delegate
voice
T@"NSString",&,N,V_voice
audioType
Ti,N,V_audioType
active
TB,N,V_active
keepAudioSessionActive
TB,N,V_keepAudioSessionActive
com.apple.voiceservices.xpcconnection
Connection invalidated during request
v16@?0@"NSValue"4@"VSSpeechRequest"8^B12
v8@?0@"NSArray"4
v8@?0B4
xpcConnection
T@"NSXPCConnection",&,N,V_xpcConnection
delegateWrapper
T@"VSSpeechConnectionDelegateWrapper",&,N,V_delegateWrapper
threadSafeQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_threadSafeQueue
identifier
T@"NSString",&,N,V_identifier
T@"<VSSpeechConnectionDelegate>",W,N,V_delegate
request
T@"VSSpeechRequest",R,N
presynthesizedAudioRequest
T@"VSPresynthesizedAudioRequest",R,N
T@"VSSpeechRequest",&,N,V_request
concurrentSynthesisRequests
T@"NSMutableDictionary",&,N,V_concurrentSynthesisRequests
T@"VSPresynthesizedAudioRequest",&,N,V_presynthesizedAudioRequest
connection
T@"VSSpeechConnection",W,N,V_connection
compact
premium
premiumhigh
beta
male
female
vocalizer
custom
gryphon
%@:%@:%@:%@:%@
Type:%@, Name: %@, Languages: %@, Gender: %@, Footprint: %@, Installed: %@, ContentVersion: %@, MasteredVersion: %@, isBuiltIn: %@
_name
_type
_isInstalled
_isBuiltInVoice
MasteredVersion
ContentVersion
T@"NSString",C,N,V_name
type
Tl,N,V_type
isInstalled
TB,N,V_isInstalled
isBuiltInVoice
TB,N,V_isBuiltInVoice
v8@?0@4
_endpoint
endpoint
T@"NSXPCListenerEndpoint",&,N,V_endpoint
queue
T@"NSObject<OS_dispatch_queue>",&,N,V_queue
listener
T@"NSXPCListener",&,N,V_listener
T@?,C,N,V_handler
encodeObject:forKey:
init
class
decodeObjectOfClass:forKey:
supportsSecureCoding
encodeWithCoder:
initWithCoder:
.cxx_destruct
bundleIdentifier
setBundleIdentifier:
compatibilityVersion
setCompatibilityVersion:
contentVersion
setContentVersion:
masteredVersion
setMasteredVersion:
_bundleIdentifier
_compatibilityVersion
_contentVersion
_masteredVersion
timeToSpeakLatency
audioQueueLatency
ttsSynthesisLatency
isWarmStart
numberWithBool:
isCacheHitFromDisk
isCacheHitFromMemory
audioDuration
eagerRequestTimeGap
stringWithFormat:
encodeInt64:forKey:
encodeDouble:forKey:
encodeBool:forKey:
decodeInt64ForKey:
decodeDoubleForKey:
decodeBoolForKey:
_clockFactor
description
isSynthesisCached
synthesisLatency
ttsTotalLatency
waitForSynthesisToFinishTime
synthesisToSpeechTime
utterance
setUtterance:
voiceAssetKey
setVoiceAssetKey:
requestCreatedTimestamp
setRequestCreatedTimestamp:
eagerRequestCreatedTimeStampDiffs
setEagerRequestCreatedTimeStampDiffs:
synthesisBeginTimestamp
setSynthesisBeginTimestamp:
synthesisEndTimestamp
setSynthesisEndTimestamp:
speechBeginTimestamp
setSpeechBeginTimestamp:
speechEndTimestamp
setSpeechEndTimestamp:
audioStartTimestampDiffs
setAudioStartTimestampDiffs:
setAudioDuration:
setIsWarmStart:
isSpeechRequest
setIsSpeechRequest:
synthesisToSpeechTimeGap
setSynthesisToSpeechTimeGap:
waitForSynthesisToFinishTimeDelay
setWaitForSynthesisToFinishTimeDelay:
setIsCacheHitFromDisk:
setIsCacheHitFromMemory:
_isWarmStart
_isSpeechRequest
_isCacheHitFromDisk
_isCacheHitFromMemory
_utterance
_voiceAssetKey
_requestCreatedTimestamp
_eagerRequestCreatedTimeStampDiffs
_synthesisBeginTimestamp
_synthesisEndTimestamp
_speechBeginTimestamp
_speechEndTimestamp
_audioStartTimestampDiffs
_audioDuration
_synthesisToSpeechTimeGap
_waitForSynthesisToFinishTimeDelay
voiceData
languages
firstObject
type
numberWithLong:
gender
footprint
name
asset
localURL
path
stringByAppendingPathComponent:
defaultManager
fileExistsAtPath:
voicePath
setVoiceData:
setAsset:
builtInVoicePath
setBuiltInVoicePath:
setVoicePath:
_voiceData
_asset
_builtInVoicePath
_voicePath
alloc
arrayWithObjects:count:
countByEnumeratingWithState:objects:count:
longValue
queryForType:voicename:language:gender:footprint:localOnly:
runQueryAndReturnError:
state
voiceDataFromAsset:
addObject:
pickCorrectAssetFromLocalAssets:
legacyLocalVocalizerVoiceAssetForLanguage:
bundleWithIdentifier:
bundlePath
preinstallAssetsDirectory
dictionaryWithContentsOfFile:
objectForKeyedSubscript:
setIsInstalled:
setIsBuiltInVoice:
genderFromString:
setGender:
setLanguages:
typeFromString:
setType:
setName:
footprintFromString:
setFootprint:
preinstallAssetsMetadata
array
isEqualToString:
voiceAssetFromPreinstallMetadata:
preinstalledVoicesForLanguage:gender:
queryForVoiceResourceAsset:localOnly:
voiceResourceFromAsset:
integerValue
sortUsingComparator:
lastObject
numberWithUnsignedInt:
numberWithInteger:
genderStringFromGender:
footprintStringFromFootprint:
count
componentsJoinedByString:
predicateWithFormat:argumentArray:
bundleIdentifierForVoiceType:
initWithAssetType:
setPredicate:
setQueriesLocalAssetInformationOnly:
selectVoiceResourceAssetForLanguage:
defaultVoice
sharedManager
amendVoiceWithDefaultSettings:
downloadVoiceAsset:useBattery:completion:
removeVoiceAsset:completion:
initWithDictionaryRepresentation:
selectVoiceForLang:type:gender:footprint:
activeVoiceAssets
attributes
installedAssetsForType:voicename:language:gender:footprint:
assetType
containsObject:
standardInstance
disableAssetCleaning
dictionaryWithObjects:forKeys:count:
errorWithDomain:code:userInfo:
inactiveVoiceAssets
purgeAndReturnError:
resetCache
dictionary
setObject:forKeyedSubscript:
purgeAsset:
cacheConcurrentQueue
removeAllObjects
addObjectsFromArray:
predicateWithBlock:
filterUsingPredicate:
arrayWithCapacity:
installedVoiceResources
voiceSelectionCache
enableLocalVoices
_localVoiceForLanguage:gender:
_builtInVoiceForLanguage:
typeStringFromType:
_nonCacheVoiceSelectionForLanguage:type:gender:footprint:
selectPreinstalledVoiceForLanguage:gender:
voiceResourceCache
_nonCacheVoiceResourcesAssetsForLanguage:
isVoiceAssetWellDefined:
localizedDescription
localizedFailureReason
assetQueryQueue
filteredArrayUsingPredicate:
getLatestAssetFromArray:
_downloadAsset:withOptions:completion:
doubleValue
floatValue
_downloadAsset:withOptions:progressHandler:
startQuery:
resumeDownload:
adjustDownloadOptions:completion:
setProgressHandler:
beginDownloadWithOptions:
cancelDownloadAndReturnError:
predicateWithFormat:
setSearchPathURL:
URLByAppendingPathComponent:
syncWithConfigFile:
sortedArrayUsingComparator:
numberWithInt:
voiceTypeForBundleIdentifier:
reinstallVoiceData:completion:
cleanUnusedVoiceAssets
cleanOldVoiceResources
downloadVoiceAsset:useBattery:progressUpdateHandler:
cancelDownload:completion:
downloadVoiceResource:useBattery:completion:
removeVoiceResource:completion:
voiceAssetWithName:localOnly:outError:
setCacheConcurrentQueue:
setAssetQueryQueue:
setVoiceSelectionCache:
setVoiceResourceCache:
_cacheConcurrentQueue
_assetQueryQueue
_voiceSelectionCache
_voiceResourceCache
initWithSuiteName:
boolForKey:
setBool:forKey:
synchronize
disableCache
setDisableCache:
setDisableAssetCleaning:
setEnableLocalVoices:
enableHomePodSimulation
setEnableHomePodSimulation:
internalBuild
isInternalBuild
setIsInternalBuild:
internalDefaults
setInternalDefaults:
_internalBuild
_isInternalBuild
_internalDefaults
bundleForClass:
pathForResource:ofType:
arrayWithContentsOfFile:
setWithArray:
stringByReplacingOccurrencesOfString:withString:
availableLanguages
rangeOfString:
substringWithRange:
fallbackLanguageForLanguage:
legacyPlatforms
hardwarePlatform
isAudioAccessory
initWithFormat:
initWithContentsOfFile:
objectForKey:
removeObjectForKey:
contentsOfDirectoryAtURL:includingPropertiesForKeys:options:error:
retain
stringByStandardizingPath
fileURLWithPath:
removeItemAtURL:error:
initWithContentsOfURL:
filePathURL
attributesOfItemAtPath:error:
autorelease
objectAtIndex:
mutableCopy
removeObjectAtIndex:
replaceObjectAtIndex:withObject:
release
modelIdentifier
recognitionResultWithModelIdentifier:classIdentifiers:values:
elementCount
getElementClassIdentifier:value:atIndex:
bundleWithPath:
load
isEqual:
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retainCount
zone
hash
superclass
debugDescription
actionForRecognitionResult:
actionForRecognitionResults:
instancesRespondToSelector:
initialize
recognitionResultByReplacingValueForClassIdentifier:withValue:
valueOfFirstElementWithClassIdentifier:
createHandler
setRecognitionAction:
recognitionAction
reset
_init
cancel
setDelegate:
setActive:
dealloc
recognitionSessionDidBeginAction:
recognitionSessionWillBeginAction:
recognitionSession:openURL:
recognitionSession:didCompleteActionWithError:
recognitionSession:didFinishSpeakingFeedbackStringWithError:
_notifyDelegateActionStarted
_continueAfterDeferredStart
perform
_hasDeferredStartCallback
_currentRecognizeAction
_debugDumpPath
setAudioType:
setKeepAudioSessionActive:
initWithModelIdentifier:
_setAction:
_isRecognizing
_isActivelyRecognizing
completionType
_setBluetoothInputAllowed:
invalidate
stopSpeakingAtNextBoundary:error:
cancelMaintainingKeepAlive:
methodSignatureForSelector:
invocationWithMethodSignature:
setSelector:
setTarget:
setArgument:atIndex:
retainArguments
scheduledTimerWithTimeInterval:invocation:repeats:
_setSession:
_setDebugDumpPath:
_setDebugDumpEnabled:
_setPreferredEngine:
_setAudioInputPath:
_setInputLevelUpdateInterval:
_setEngineResetRequired:
defaultCenter
postNotificationName:object:
_handledThreadedResults:nextAction:
spokenFeedbackString
spokenFeedbackAttributedString
resultDisplayString
statusDisplayString
_inputLevel
_inputLevelDB
_keywordAtIndex:
_keywordCount
_scrambledKeywordsAndAddToSet:
_nextKeywordUsingCursors:
removeObject:
allObjects
_createKeywordIndex
_createPhaseSortedKeywordsFromArray:
_topLevelKeywords
_keywordIndexChanged
postNotificationName:object:userInfo:
_beginSpeakingAttributedString:
beginSpeakingString:
length
_beginSpeakingString:attributedString:
_notifyDelegateFinishedSpeakingWithError:
initForInputFeedback
startSpeakingAttributedString:toURL:withLanguageCode:error:
startSpeakingString:withLanguageCode:error:
beginNextAction
isRecognizing
isActivelyRecognizing
isFinished
isValid
hasDeferredAction
isBusy
nextActionWillTerminateSession
nextActionWillRecognize
setSensitiveActionsEnabled:
sensitiveActionsEnabled
setBluetoothInputAllowed:
_actionCompleted:nextAction:error:
_actionStarted:
_notifyDelegateOpenURL:
_recognitionResultHandlingThread
recognitionResultHandlingThread:didHandleResults:nextAction:
displayResultString
displayStatusString
setInputLevelUpdateInterval:
inputLevel
inputLevelDB
setKeywordPhase:
keywordAtIndex:
keywordCount
_keywordsForModelIdentifier:
beginSpeakingFeedbackString
speechSynthesizer:didFinishSpeaking:withError:
setDebugDumpEnabled:
debugDumpPath
setNextRecognitionAudioInputPath:
setNextRecognitionRequiresReset:
setPreferredEngine:
setPerformRecognitionHandlerActions:
_modelIdentifier
_keepAlive
_delegate
_currentAction
_handlingThread
_synthesizer
_languageID
_audioInputPath
_levelInterval
_keywordPhase
_sessionFlags
exchangeObjectAtIndex:withObjectAtIndex:
beginChunkDecoderForStreamDescription:
initWithCapacity:
decodeChunk:outError:
appendData:
enumerateObjectsUsingBlock:
endChunkDecoding
_opusDecoder:
initWithLength:
mutableBytes
bytes
dataWithBytes:length:
sharedInstance
decodeChunks:streamDescription:outError:
_decoder
_asbd
string
_session
setResultDisplayString:
setStatusDisplayString:
setSpokenFeedbackString:
setSpokenFeedbackAttributedString:
completeWithNextAction:error:
_resultString
_statusString
_spokenString
_spokenStringIsAttributed
setObject:forKey:
arrayWithObject:
_disambiguationContext
_reset
setRepeatedSpokenFeedbackString:
repeatedSpokenFeedbackString
sequenceTag
setSequenceTag:
knownValueForClassIdentifier:
setKnownValue:phoneticValue:forClassIdentifier:
knownValuesForClassIdentifier:
setKnownValues:phoneticValues:forClassIdentifier:
ambiguousValuesForClassIdentifier:
setAmbiguousValues:phoneticValues:forClassIdentifier:
_keywords
setKeywords:
_createRecognitionInstanceWithCallbacks:info:
_actionForEmptyResults
_repeatedSpokenFeedbackString
_sequenceTag
_knownValues
_knownPhoneticValues
_ambiguousValues
_ambiguousPhoneticValues
_context
languageMapping
dataWithContentsOfFile:
characterSetWithBitmapRepresentation:
characterSetForLanguage:
characterAtIndex:
characterIsMember:
valueWithRange:
unspeakableRangeOfText:forLanguage:
_setDebugDumpEnabled:dumpPath:
_configureNewRecognitionInstance
_setResults:
_releaseFromPrepare
subarrayWithRange:
requiresThreadedProcessing
handleResults:withHandler:
makeObjectsPerformSelector:withObject:
_handleRecognitionPrepared:
_handleRecognitionStarted:
_handleRecognitionCompleted:withResults:error:
_recognition
_results
_recognizeFlags
decodeObjectOfClasses:forKey:
dictionaryWithContentsOfURL:
setResourceList:
setVoiceConfig:
vocalizerConfig
searchPathURL
voiceConfig
rate
pitch
volume
defaultTypeString
defaultFootprintString
resourceList
setRate:
setPitch:
setVolume:
setVocalizerConfig:
_languages
_resourceList
_searchPathURL
_voiceConfig
_rate
_pitch
_volume
_vocalizerConfig
rangeValue
startTime
setStartTime:
textRange
setTextRange:
_startTime
_textRange
stopListening
lock
_spokenLanguageChanged:
addObserver:selector:name:object:
unlock
allValues
beginReportingChanges
makeObjectsPerformSelector:
stopReportingChanges
removeObserver:name:object:
_flush
initWithModelIdentifier:classIdentifier:
_enqueueRequest:
performUpdateForModelIdentifier:classIdentifier:
coalescedRequest:
timerWithTimeInterval:target:selector:userInfo:repeats:
mainRunLoop
addTimer:forMode:
dateWithTimeIntervalSinceNow:
setFireDate:
classIdentifier
sharedListener
sharedListenerIfExists
_initShared
startListening
_lock
_updateRequestQueue
_dataProviders
_flushTimer
_isListening
_modelID
_classID
valueCountForClassWithIdentifier:inModelWithIdentifier:
valueAtIndex:forClassWithIdentifier:inModelWithIdentifier:
getValue:weight:atIndex:forClassWithIdentifier:inModelWithIdentifier:
phoneticValueAtIndex:forClassWithIdentifier:inModelWithIdentifier:
cacheValidityIdentifier
isCacheValidityIdentifierValid:
_setConfirmed:
setConfirmedAction:
confirmedAction
setDeniedAction:
deniedAction
_confirmedAction
_deniedAction
_confirmFlags
setURL:
_url
localizations
pathForResource:ofType:inDirectory:forLocalization:
initFileURLWithPath:
pathForResource:ofType:inDirectory:
initWithSpokenFeedbackString:willTerminate:
_shouldTerminate
encodeValueOfObjCType:at:
encodeInt32:forKey:
initWithAudioData:decoderStreamDescription:playerStreamDescription:
decodeValueOfObjCType:at:
decodeInt32ForKey:
numberWithDouble:
numberWithUnsignedInteger:
numberWithUnsignedLongLong:
copyWithZone:
initWithAudioData:playerStreamDescription:
audioSessionID
setAudioSessionID:
audioData
decoderStreamDescription
playerStreamDescription
enqueue
setEnqueue:
clientBundleIdentifier
setClientBundleIdentifier:
pcmDataSize
setPcmDataSize:
stopHandler
setStopHandler:
_enqueue
_audioSessionID
_audioData
_clientBundleIdentifier
_pcmDataSize
_stopHandler
_decoderStreamDescription
_playerStreamDescription
initWithCondition:
initWithHandler:results:
_handleRequests
detachNewThreadSelector:toTarget:withObject:
unlockWithCondition:
results
nextAction
lockWhenCondition:
handler
setNextAction:
_notifyRequestHandled:
performSelectorOnMainThread:withObject:waitUntilDone:
_requests
_resultHandlingFlags
_handler
_action
matchedString:forTokenInRange:
replaceCharactersInRange:withString:
initWithContentsOfPath:languageIdentifier:
processedTextFromString:
_rules
_tokenizer
boolValue
_matchPattern
_replacement
_caseSensitive
_eatPunctuation
appendString:withAttributes:
attributedStringWithFormatAndAttributes:
formatSpecifier
formattedArg
setAttributes:range:
processInfo
processName
downloadAssetForLanguage:
downloadingAssetLanguage
assetStatusForLanguage:
assetDownloadStatus:progress:size:
removeAssetForLanguage:
_assetCleanupTimer
languageCode
text
contextInfo
isEqualToDictionary:
voiceType
encodeInteger:forKey:
decodeIntegerForKey:
decodePropertyListForKey:
appendString:
appendFormat:
enumerateKeysAndObjectsUsingBlock:
isSimilarTo:
contextInfoString
setText:
setLanguageCode:
setVoiceType:
outputPath
setOutputPath:
shouldCache
setShouldCache:
setContextInfo:
disableCompactVoiceFallback
setDisableCompactVoiceFallback:
resourceListURL
setResourceListURL:
resourceSearchPathURL
setResourceSearchPathURL:
attributedText
setAttributedText:
useCustomVoice
setUseCustomVoice:
voiceName
setVoiceName:
audioSessionIDIsValid
setAudioSessionIDIsValid:
maintainsInput
setMaintainsInput:
audioQueueFlags
setAudioQueueFlags:
pauseHandler
setPauseHandler:
pointer
setPointer:
_shouldCache
_disableCompactVoiceFallback
_useCustomVoice
_audioSessionIDIsValid
_maintainsInput
_text
_languageCode
_footprint
_voiceType
_gender
_outputPath
_contextInfo
_resourceListURL
_resourceSearchPathURL
_attributedText
_voiceName
_audioQueueFlags
_pauseHandler
_pointer
completion
audioPlayerDidFinishPlaying:successfully:
audioPlayerDecodeErrorDidOccur:error:
audioPlayerBeginInterruption:
audioPlayerEndInterruption:withOptions:
audioPlayerEndInterruption:withFlags:
audioPlayerEndInterruption:
setCompletion:
_completion
errorWithReason:
getVoiceResourceForLanguage:reply:
isPlaying
stop
category
setActive:withOptions:error:
setCategory:error:
initWithContentsOfURL:error:
setActive:error:
play
mainBundle
preferredLocalizations
opaqueSessionID
processIdentifier
setIdentifier:
setMaintainPersistentConnection:
setMaintainInactivePersistentConnection:
prewarmIfNeededWithRequest:
speechSynthesizer:didStartSpeakingRequest:
speechSynthesizerDidStartSpeaking:
speechSynthesizer:didFinishSpeakingRequest:successfully:withError:
speechSynthesizer:didFinishSpeakingRequest:successfully:phonemesSpoken:withError:
speechSynthesizer:didFinishSpeaking:phonemesSpoken:withError:
speechSynthesizer:didPauseSpeakingRequest:
speechSynthesizerDidPauseSpeaking:
speechSynthesizer:didContinueSpeakingRequest:
speechSynthesizerDidContinueSpeaking:
speechSynthesizer:willSpeakRangeOfSpeechString:forRequest:
speechSynthesizer:willSpeakRangeOfSpeechString:
speechSynthesizer:didFinishSpeakingRequest:withInstrumentMetrics:
presynthesizedAudioRequest
isSystemSpeaking
stopPresynthesizedAudioRequest
request
stopCurrentSpeechRequestAtMark:
pauseCurrentSpeechRequestAtMark:
_setDelegate:
validateRequest:
startSynthesisRequest:
_stopSpeakingRequest:atNextBoundary:synchronously:error:
_stopSpeakingPresynthesizedAudioRequest:synchronously:error:
startSpeechRequest:
connection:speechRequest:didStopAtEnd:phonemesSpoken:error:
validatePresynthesizedAudioRequest:
connection:presynthesizedAudioRequest:didStopAtEnd:error:
startPresynthesizedAudioRequest:
_pauseSpeakingRequest:atNextBoundary:synchronously:error:
isSystemSpeakingOnBehalfOfCurrentConnection
continueCurrentSpeechRequest
speechSynthesizer:withRequest:didReceiveTimingInfo:
speechSynthesizer:didFinishSynthesisRequest:withInstrumentMetrics:error:
speechSynthesizer:didFinishSynthesisRequest:withError:
speechSynthesizer:didStartPresynthesizedAudioRequest:
speechSynthesizer:didStopPresynthesizedAudioRequest:atEnd:error:
speechSynthesizer:didStopPresynthesizedAudioRequestAtEnd:error:
speechSynthesizer:didFinishPresynthesizedAudioRequest:withInstrumentMetrics:error:
setLogToFile:
getLogToFile:
language
_startSpeakingString:orAttributedString:toURL:withLanguageCode:request:error:
pauseSpeakingAtNextBoundary:synchronously:error:
_continueSpeakingRequest:withError:
startSpeakingRequest:
startSynthesizingRequest:
startSpeakingString:toURL:withLanguageCode:error:
stopSpeakingAtNextBoundary:synchronously:error:
availableVoicesForLanguageCode:
availableLanguageCodes
availableFootprintsForVoice:languageCode:
cleanUnusedAssets:
getLocalVoiceAssets:
getLocalVoiceResources:
setAutoDownloadedVoiceAssets:
getAutoDownloadedVoiceAssets:
getVoiceInfoForLanguageCode:footprint:gender:type:reply:
playVoicePreviewForLanguageCode:gender:
availableVoices
getAllVoiceAssets:
getVoiceInfoForLanguageCode:footprint:gender:custom:reply:
connection:speechRequestDidStart:
connection:speechRequestDidPause:
connection:speechRequestDidContinue:
connection:speechRequest:willSpeakMark:inRange:
connection:speechRequest:successWithInstrumentMetrics:
connection:speechRequest:didReceiveTimingInfo:
connection:synthesisRequest:didFinishWithInstrumentMetrics:error:
connection:presynthesizedAudioRequestDidStart:
connection:presynthesizedAudioRequest:successWithInstrumentMetrics:error:
startSpeakingPresynthesizedAudioRequest:
stopSpeakingPresynthesizedAudioSynchronously:error:
isSpeaking
speechString
minimumRate
maximumRate
stopSpeakingRequest:atNextBoundary:synchronously:error:
prewarmIfNeeded
startSpeakingString:request:error:
startSpeakingString:toURL:request:error:
startSpeakingString:withLanguageCode:request:error:
stopSpeakingRequest:atNextBoundary:error:
pauseSpeakingRequest:atNextBoundary:error:
pauseSpeakingRequest:atNextBoundary:synchronously:error:
pauseSpeakingAtNextBoundary:error:
continueSpeakingRequest:withError:
useSharedAudioSession:
useSpecificAudioSession:
useAudioQueueFlags:
startSynthesizingString:toFileURL:shouldCache:request:
startSpeakingString:error:
startSpeakingString:toURL:error:
continueSpeakingWithError:
delegate
voice
setVoice:
setLanguage:
_inactiveKeepAlive
_queue
_callbackQueue
_xpcConnection
_identifier
_synthesizerFlags
_voice
_language
initWithMachServiceName:options:
maintainWithAudioType:keepAudioSessionActive:
interfaceWithProtocol:
setRemoteObjectInterface:
_ensureKeepAliveMaintenance
setInterruptionHandler:
resume
_serverConnection
remoteObjectProxy
_remoteKeepAlive
audioType
active
keepAudioSessionActive
_audioType
_active
_keepAudioSessionActive
setConnection:
updateWithConnectionIdentifier:
pauseSpeechRequestAtMark:
continueSpeechRequest
stopSpeechRequestAtMark:
getVoiceNamesForLanguage:reply:
getFootprintsForVoiceName:languageCode:reply:
getSpeechIsActiveReply:
getSpeechIsActiveForConnectionReply:
getLocalVoicesReply:
getLocalVoiceResourcesReply:
setClasses:forSelector:argumentIndex:ofReply:
_connectionInvalidated
setInvalidationHandler:
speechRequestDidStart
speechRequestDidPause
speechRequestDidContinue
speechRequestMark:didStartForRange:
speechRequestDidStopWithSuccess:phonemesSpoken:error:
speechRequestSuccessWithInstrumentMetrics:
speechRequestDidReceiveTimingInfo:
synthesisRequest:didReceiveTimingInfo:
synthesisRequest:didFinishWithInstrumentMetrics:error:
presynthesizedAudioRequestDidStart
presynthesizedAudioRequestDidStopAtEnd:error:
presynthesizedAudioRequestSuccessWithInstrumentMetrics:error:
setExportedInterface:
delegateWrapper
setExportedObject:
xpcConnection
remoteObjectProxyWithErrorHandler:
concurrentSynthesisRequests
setXpcConnection:
setRequest:
setPresynthesizedAudioRequest:
setConcurrentSynthesisRequests:
_remoteObjectWithErrorHandler:
_remoteObject
identifier
setDelegateWrapper:
threadSafeQueue
setThreadSafeQueue:
_delegateWrapper
_threadSafeQueue
connection
_request
_concurrentSynthesisRequests
_presynthesizedAudioRequest
_connection
lowercaseString
voiceKey
dictionaryRepresentation
isInstalled
isBuiltInVoice
_isInstalled
_isBuiltInVoice
_name
_type
anonymousListener
setQueue:
setHandler:
setListener:
endpoint
setEndpoint:
_setQueue:
invokeUpdateWithObject:
initWithBlock:
initWithListenerEndpoint:
configuredEndpointWithUpdateHandler:withConnection:
remoteUpdateHanderForEndpoint:
listener:shouldAcceptNewConnection:
queue
listener
_endpoint
_listener
_block
VSAssetBase
NSSecureCoding
NSCoding
VSInstrumentMetrics
VSVoiceAssetSelection
VSMobileAssetsManager
VSSpeechInternalSettings
VSSpeechSynthesizerPreference
VSUtilities
VSRecognitionResultHandler
NSObject
VSRecognitionResult
VSRecognitionSession
VSRecognitionSessionKeywords
VSOpusDecoder
VSRecognitionAction
VSRecognitionDisambiguateAction
VSSpeechCharacterSet
VSRecognitionRecognizeAction
VSVoiceResourceAsset
VSSpeechWordTimingInfo
VSCacheUpdateListener
VSCacheUpdateRequest
VSRecognitionModelDataProvider
VSRecognitionConfirmAction
VSRecognitionURLAction
VSRecognitionSpeakAction
VSPresynthesizedAudioRequest
NSCopying
VSRecognitionResultHandlingThread
VSRecognitionResultHandlingRequest
VSTextPreProcessor
VSTextPreProcessorRule
VSSpeechAdditions
VSFormatArgument
VSAssetUpdateListener
VSSpeechRequest
VSAudioPreviewDelegate
AVAudioPlayerDelegate
VSSpeechSynthesizer
VSSpeechConnectionDelegate
VSRemoteKeepAlive
VSKeepAlive
VSSpeechXPCServiceProtocol
VSSpeechServiceDelegate
VSSpeechConnection
VSSpeechConnectionDelegateWrapper
VSVoiceAsset
VSGenericUpdate
VSGenericUpdateEndpoint
NSXPCListenerDelegate
VSGenericBlockHolder
B8@0:4
v12@0:4@8
@12@0:4@8
v12@0:4@"NSCoder"8
@12@0:4@"NSCoder"8
v8@0:4
@8@0:4
@"NSString"
@"NSNumber"
d8@0:4
Q8@0:4
v16@0:4Q8
v16@0:4d8
v12@0:4B8
@"VSVoiceAsset"
@"ASAsset"
@32@0:4l8@12@16l20l24B28
@16@0:4@8B12
@28@0:4l8@12@16l20l24
@24@0:4@8l12l16l20
@12@0:4l8
l12@0:4@8
B12@0:4@8
@16@0:4@8l12
v16@0:4@8@?12
v20@0:4@8B12@?16
@20@0:4@8B12^@16
v20@0:4@8@12@?16
@"NSObject<OS_dispatch_queue>"
@"NSMutableDictionary"
@"NSUserDefaults"
#8@0:4
@12@0:4:8
@16@0:4:8@12
@20@0:4:8@12@16
B12@0:4#8
B12@0:4:8
Vv8@0:4
I8@0:4
^{_NSZone=}8@0:4
B12@0:4@"Protocol"8
@"NSString"8@0:4
@"VSRecognitionAction"12@0:4@"VSRecognitionResult"8
@"VSRecognitionAction"12@0:4@"NSArray"8
@20@0:4@8@12@16
@16@0:4@8@12
i8@0:4
B20@0:4^@8^@12i16
B12@0:4B8
@12@0:4B8
v20@0:4@8@12@16
f8@0:4
v12@0:4I8
@12@0:4i8
^{__CFDictionary=}8@0:4
v20@0:4@8B12@16
B12@0:4i8
@"VSKeepAlive"
@"<VSRecognitionSessionDelegate>"
@"VSRecognitionAction"
@"NSArray"
@"VSSpeechSynthesizer"
{?="delegateWillBegin"b1"delegateBegin"b1"delegateOpenURL"b1"delegateFinishedSpeaking"b1"delegateComplete"b1"debugDumpEnabled"b1"preferredEngine"b2"performHandlerActions"b1"allowSensitiveActions"b1"bluetoothAllowed"b1"resetNextAction"b1"isSpeaking"b1"actionBegan"b1"actionBeginning"b1"actionBeginDeferred"b1"invalid"b1"observeKeywordChange"b1}
@12@0:4^{__CFDictionary=}8
^{OpaqueAudioConverter=}48@0:4{AudioStreamBasicDescription=dIIIIIIII}8
@56@0:4@8{AudioStreamBasicDescription=dIIIIIIII}12^@52
@48@0:4{AudioStreamBasicDescription=dIIIIIIII}8
@16@0:4@8^@12
^{OpaqueAudioConverter=}
{AudioStreamBasicDescription="mSampleRate"d"mFormatID"I"mFormatFlags"I"mBytesPerPacket"I"mFramesPerPacket"I"mBytesPerFrame"I"mChannelsPerFrame"I"mBitsPerChannel"I"mReserved"I}
v16@0:4@8@12
(?="stringValue"@"NSString""attributedStringValue"@"NSAttributedString")
@"VSRecognitionSession"
^{__VSRecognitionDisambiguationContext=}8@0:4
^{__VSRecognition=}16@0:4^{?=^?^?^?}8^v12
B16@0:4d8
B16@0:4B8@12
v12@0:4^{__VSRecognition=}8
v20@0:4^{__VSRecognition=}8^{__CFArray=}12^{__CFError=}16
{?="debugDumpEnabled"b1"preferredEngine"b2"resetEngine"b1"bluetoothAllowed"b1"hasStarted"b1}
v12@0:4f8
@"NSDictionary"
@"NSURL"
{_NSRange=II}8@0:4
v16@0:4{_NSRange=II}8
{_NSRange="location"I"length"I}
@"NSLock"
@"NSMutableArray"
@"NSTimer"
i16@0:4@8@12
@20@0:4i8@12@16
B28@0:4^@8^i12i16@20@24
i16@0:4@"NSString"8@"NSString"12
@"NSString"20@0:4i8@"NSString"12@"NSString"16
B28@0:4^@8^i12i16@"NSString"20@"NSString"24
@"NSDictionary"8@0:4
B12@0:4@"NSDictionary"8
{?="initializing"b1"confirmed"b1}
@12@0:4^{_NSZone=}8
@52@0:4@8{AudioStreamBasicDescription=dIIIIIIII}12
@92@0:4@8{AudioStreamBasicDescription=dIIIIIIII}12{AudioStreamBasicDescription=dIIIIIIII}52
{AudioStreamBasicDescription=dIIIIIIII}8@0:4
@?8@0:4
v12@0:4@?8
@"NSData"
@"<VSRecognitionResultHandlingThreadDelegate>"
@"NSConditionLock"
{?="running"b1"delegateDidHandleResults"b1"valid"b1}
@"<VSRecognitionResultHandler>"
^{__CFStringTokenizer=}
@16@0:4@8^{?=ii}12
i12@0:4@8
B20@0:4@8^f12^q16
@"PCPersistentTimer"
l8@0:4
v12@0:4l8
v12@0:4i8
@"NSAttributedString"
v16@0:4@8B12
v16@0:4@8I12
v16@0:4@"AVAudioPlayer"8B12
v16@0:4@"AVAudioPlayer"8@"NSError"12
v12@0:4@"AVAudioPlayer"8
v16@0:4@"AVAudioPlayer"8I12
B16@0:4@8l12
v28@0:4@8l12l16B20@?24
v28@0:4@8l12l16l20@?24
v28@0:4@8@12B16@20@24
v28@0:4@8@12l16{_NSRange=II}20
v24@0:4@8@12@16@20
v24@0:4@8@12B16@20
v16@0:4@"VSSpeechConnection"8@"VSSpeechRequest"12
v28@0:4@"VSSpeechConnection"8@"VSSpeechRequest"12B16@"NSString"20@"NSError"24
v28@0:4@"VSSpeechConnection"8@"VSSpeechRequest"12l16{_NSRange=II}20
v20@0:4@"VSSpeechConnection"8@"VSSpeechRequest"12@"VSInstrumentMetrics"16
v20@0:4@"VSSpeechConnection"8@"VSSpeechRequest"12@"NSArray"16
v24@0:4@"VSSpeechConnection"8@"VSSpeechRequest"12@"VSInstrumentMetrics"16@"NSError"20
v16@0:4@"VSSpeechConnection"8@"VSPresynthesizedAudioRequest"12
v24@0:4@"VSSpeechConnection"8@"VSPresynthesizedAudioRequest"12B16@"NSError"20
v24@0:4@"VSSpeechConnection"8@"VSPresynthesizedAudioRequest"12@"VSInstrumentMetrics"16@"NSError"20
B20@0:4@8B12^@16
B24@0:4@8i12B16^@20
B20@0:4i8B12^@16
B16@0:4B8^@12
B16@0:4@8^@12
B24@0:4@8@12@16^@20
B20@0:4@8^@12^@16
B24@0:4@8@12^@16^@20
B20@0:4@8i12^@16
B16@0:4i8^@12
B32@0:4@8@12@16@20^@24^@28
@24@0:4@8@12B16^@20
B20@0:4@8@12^@16
B12@0:4^@8
@"VSSpeechConnection"
{?="delegateStart"b1"delegateFinish"b1"delegateFinishWithPhonemesSpoken"b1"delegatePause"b1"delegateContinue"b1"delegateWillSpeak"b1"delegateStartWithRequest"b1"delegateFinishWithRequest"b1"delegateFinishWithPhonemesSpokenWithRequest"b1"delegateSuccessWithInstrumentMetrics"b1"delegatePauseWithRequest"b1"delegateContinueWithRequest"b1"delegateWillSpeakWithRequest"b1"willUseInput"b1}
@"<VSSpeechSynthesizerDelegate>"
Vv16@0:4i8B12
@"NSXPCConnection"
Vv12@0:4@8
Vv12@0:4l8
Vv16@0:4@8@?12
Vv20@0:4@8@12@?16
Vv12@0:4@?8
Vv28@0:4@8l12l16l20@?24
Vv12@0:4B8
Vv12@0:4@"NSString"8
Vv12@0:4@"VSSpeechRequest"8
Vv12@0:4@"VSPresynthesizedAudioRequest"8
Vv16@0:4@"NSString"8@?<v@?@"NSArray">12
Vv20@0:4@"NSString"8@"NSString"12@?<v@?@"NSArray">16
Vv12@0:4@?<v@?B>8
Vv12@0:4@?<v@?@"NSError">8
Vv12@0:4@?<v@?@"NSArray"@"NSError">8
Vv12@0:4@"NSArray"8
Vv12@0:4@?<v@?@"NSArray">8
Vv16@0:4@"NSString"8@?<v@?@"VSVoiceResourceAsset">12
Vv28@0:4@"NSString"8l12l16l20@?<v@?@"VSVoiceAsset">24
Vv20@0:4l8{_NSRange=II}12
Vv20@0:4B8@12@16
Vv16@0:4@8@12
Vv20@0:4@8@12@16
Vv16@0:4B8@12
Vv20@0:4B8@"NSString"12@"NSError"16
Vv12@0:4@"VSInstrumentMetrics"8
Vv16@0:4@"VSSpeechRequest"8@"NSArray"12
Vv20@0:4@"VSSpeechRequest"8@"VSInstrumentMetrics"12@"NSError"16
Vv16@0:4B8@"NSError"12
Vv16@0:4@"VSInstrumentMetrics"8@"NSError"12
@12@0:4@?8
@"<VSSpeechConnectionDelegate>"
@"VSSpeechConnectionDelegateWrapper"
@"VSSpeechRequest"
@"VSPresynthesizedAudioRequest"
@16@0:4@?8@12
@?12@0:4@8
B16@0:4@8@12
B16@0:4@"NSXPCListener"8@"NSXPCConnection"12
@"NSXPCListenerEndpoint"
@"NSXPCListener"
@mcpl
@mcpl
@supo
@mcpl
Missing language in voice data:%@
Can't find request language %@ in default languages
reinstall asset: %@
Skip asset that is used by Accessibility, %@
Skip currently in-use asset, %@
Cleaning voice assets is disabled in internal setting. Skip cleaning...
Unable to clean asset: %@, error:%@
Purged asset: %@
#MobileAsset reset cached mobile asset results
Getting cached result for voice selection key: %@
Search local voices for lang: %@, gender: %@
Built in voice is requested.
Search voice asset for lang: %{public}@, type: %@, gender: %@, footprint: %@
Gryphon voice not found, search premium custom voice asset with same gender
Search voices in pre-installed location as fallback
Search custom compact voice assets with same gender
Search available vocalizer voice assets with same gender
Caching voice selection: %{public}@
Fallback to built-in compact voice for lang: %@
Selected %{public}@
Get cached %@
Search VoiceResource for '%@'
Caching %@
%@, %@
#MobileAsset Start querying MobileAsset for: %@
Enqueued asset query %p for: %p
Running asset query %p for: %@
#MobileAsset Error querying MobileAsset. %@
#MobileAsset Can't download due to unfound asset: %@
Unable to download voice that is not well defined: %@
#MobileAsset Asset is installed already: %@
Enqueued download cancellation for: %@
#MobileAsset Resume download: %@
#MobileAsset Adjust download: %@
#MobileAsset Start download: %@
#MobileAsset Asset is already installed or is downloading: %@
#MobileAsset purge asset: %@
#MobileAsset cancel downloading asset: %@
#MobileAsset ignore non-local asset: %@
#MobileAsset Can't remove asset %@
#MobileAsset Unable to query legacy voices. error: %@
Couldn't found any built in voice for lang: %@
Failed to convert %ld recognition results
compact explicitly specified, look at framework asset first
Now looking for the fallback language: %@
Looking for the resources in %@
Can't find the resources anywhere!
Found the resources here: %@
No TTS resources for asset. Trying fallback language for %@
Using asset fallback language %@
Couldn't get the engine format version for language %@
VoiceEngineFormatVersions hasn't been initialized, voices may not be compatible
Trying to migrate asset because it's not valid: %@
After migrating asset, it's still not valid -- sorry
---> asset's version is %@
---> engine's version is %@
Couldn't get asset's version and/or language
Deleting the asset located here: %@ because the format versions don't match
***ERROR*** There was an error (%d - %s) when trying to symlink %s to %s
Symlinked %s to %s
Successfully appended broker header files
***ERROR*** couldn't append broker header files (%d - %s)
***ERROR*** couldn't move broker header file to final location (%d - %s)
Couldn't initialize the engine voice format versions
Unable to lock temporary asset: %s; presumably peer was first - error: %d
Temporary asset: %s has moved; presumably peer was first - error: %d
Couldn't move the temporary asset: %s to the real asset: %s - error: %d
Moved the temporary asset: %s to the real asset: %s
Couldn't get the contents of the assets directory (error %ld)
Deleting asset at url: %@
Invalid target asbd: %@
Could not create Opus decoder: %{public}d
Only expecting to get 1 packet at a time, not %lu
Enqueuing request: %@
Queue is now:
#Deprecated  %s, called from '%@'
Unable to locate preview sample file for %@
#PrewarmRequest, synthesizer: %@, language: %@
Error #SpeechPauseRequest not currently speaking
#SynthesisRequest %p client:%@, string:%@, toPath:%@, language:%@, type:%@, gender:%@, footprint:%@ contextInfo:%@
#SpeechRequest %p client:%@, string:%@, saveToURL:%@, language:%@, type:%@, gender:%@, footprint:%@ contextInfo:%@
#PresynthesizedAudioRequest: %@
Presynthesized audio request failed validation
#SpeechStopRequest client:%@, boundary: %@, synchronously: %@
Error #SpeechStopRequest %@
#SpeechStopPresynthesizedAudioRequest client:%@, synchronously: %@
Error #PresynthesizedAudioStopRequest %@
#SpeechPauseRequest client:%@, boundary: %@, synchronously: %@
#SpeechResumeRequest client:%@
Error #SpeechResumeRequest no active speech job
#AutoDownloadRequest #MobileAsset, language: %@, gender: %ld, type: %ld, footprint: %ld, name: %@
VSSpeechConnection invalidated %p
Error updateWithConnectionIdentifier: %@
Can't prewarm %@
Error %@ asking for voices
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
