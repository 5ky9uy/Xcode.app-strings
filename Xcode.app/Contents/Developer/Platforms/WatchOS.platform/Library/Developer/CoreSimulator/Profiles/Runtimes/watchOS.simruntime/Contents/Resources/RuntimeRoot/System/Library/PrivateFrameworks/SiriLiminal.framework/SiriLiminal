@(#)PROGRAM:SiriLiminal  PROJECT:CoreSpeech-
com.apple.SiriLiminal
Framework
v8@?0
::: Initializing SiriLiminal logging...
en_US_POSIX
yyyyMMdd-HHmmss
SLLogInitIfNeeded_block_invoke
gitrelno_unavailable
+[SLASRFeatureExtractor extractASRFaturesFrom:]
max:
min:
stddev:
average:
v32@?0@"AFSpeechUtterance"8Q16^B24
+[SLASRFeatureExtractor extractLRNNFaturesFrom:]
+[SLASRFeatureExtractor _getTokenConfidenceForPath:fromPhrases:]
v32@?0@"AFSpeechPhrase"8Q16^B24
+[SLASRFeatureExtractor _getTokenConfidenceForPath:fromPhrases:]_block_invoke
v32@?0@"AFSpeechToken"8Q16^B24
+[SLUtils decodeJsonFromFile:]
SLInvocationType
SLVoiceTriggerEventInfo
SLAudioSourceOption
SLLanguageCode
Missing keys in context
reason
-[SLProgressiveCheckerContext initWithContext:error:]
EAR not supported
-[SLProgressiveCheckerAnalyzer initWithConfig:withDelegate:error:]
com.apple.sl
numAsrRecords
numTokensTopPath
trailingSilenceDuration
theshold
assetVersion
%s ::: SL logging initialized (%s)
%s Received nil recog candidate, nothing to extract
%s Extracted LRNN Score: %f from Model Version: %{public}@
%s Constructing tokens for speech path %{public}@
%s Adding score %{public}ld for token %{public}@
%s ERR: metaData is nil, defaulting to NO for %{public}@
%s ERR: read metafile %{public}@ failed with %{public}@ - defaulting to NO
%s %{public}@
%s Created SLAcousticContext: %{public}@
zPLR
SLASRFeatures
SLLRNNFeatures
SLASRFeatureExtractor
SLUtils
SLProgressiveCheckerContext
SLProgressiveCheckerResult
SLProgressiveCheckerAnalyzer
SLUresMitigatorResult
SLUresMitigatorIpFeats
SLUresMitigator
localeWithLocaleIdentifier:
setLocale:
setDateFormat:
latticePathMaxScores
setLatticePathMaxScores:
latticePathMinScores
setLatticePathMinScores:
latticePathMeanScores
setLatticePathMeanScores:
latticePathVarScores
setLatticePathVarScores:
topLatticePathScores
setTopLatticePathScores:
topLatticePathTokenCount
setTopLatticePathTokenCount:
setSnr:
trailingSilence
setTrailingSilence:
.cxx_destruct
_snr
_trailingSilence
_latticePathMaxScores
_latticePathMinScores
_latticePathMeanScores
_latticePathVarScores
_topLatticePathScores
_topLatticePathTokenCount
T@"NSArray",&,N,V_latticePathMaxScores
T@"NSArray",&,N,V_latticePathMinScores
T@"NSArray",&,N,V_latticePathMeanScores
T@"NSArray",&,N,V_latticePathVarScores
T@"NSArray",&,N,V_topLatticePathScores
TQ,N,V_topLatticePathTokenCount
Tf,N,V_snr
Tf,N,V_trailingSilence
lrnnScore
setLrnnScore:
lrnnProcessed
setLrnnProcessed:
_lrnnProcessed
_lrnnScore
Tf,N,V_lrnnScore
TB,N,V_lrnnProcessed
recognition
utterances
count
initWithCapacity:
phrases
_getTokenConfidenceForPath:fromPhrases:
expressionForConstantValue:
arrayWithObject:
expressionForFunction:arguments:
expressionValueWithObject:context:
addObject:
doubleValue
numberWithDouble:
floatValue
_getLastTokenForPath:fromPhrases:
enumerateObjectsUsingBlock:
audioAnalytics
endTime
silenceStartTime
latticeMitigatorResult
score
threshold
version
interpretationIndices
lastObject
unsignedIntegerValue
interpretations
objectAtIndex:
tokens
firstObject
array
dictionaryRepresentation
objectAtIndexedSubscript:
addObjectsFromArray:
confidenceScore
numberWithInteger:
text
extractASRFaturesFrom:
extractLRNNFaturesFrom:
dataWithContentsOfFile:
JSONObjectWithData:options:error:
decodeJsonFromFile:
init
objectForKeyedSubscript:
stringWithFormat:
dictionaryWithObjects:forKeys:count:
errorWithDomain:code:userInfo:
initWithContext:error:
audioOption
vtei
invocationType
locale
_audioOption
_vtei
_invocationType
_locale
TQ,R,N,V_audioOption
T@"NSDictionary",R,N,V_vtei
TQ,R,N,V_invocationType
T@"NSString",R,N,V_locale
initWithScore:ofType:analyzedSamples:detailedResults:
resultType
analyzedSamples
detailedResult
_score
_resultType
_analyzedSamples
_detailedResult
TQ,R,N,V_resultType
TQ,R,N,V_analyzedSamples
Tf,R,N,V_score
T@"NSArray",R,N,V_detailedResult
initWithConfig:withDelegate:error:
startNewRequestWithContext:
addAudio:
endAudio
initWithScore:decision:decisionLevel:detailedResults:extractedFeats:
didMitigate
decisionLevel
assetVersion
extractedFeats
_didMitigate
_threshold
_decisionLevel
_assetVersion
_extractedFeats
TB,R,N,V_didMitigate
Td,R,N,V_decisionLevel
Tf,R,N,V_threshold
T@"NSString",R,N,V_assetVersion
T@"NSDictionary",R,N,V_detailedResult
T@"NSDictionary",R,N,V_extractedFeats
speechPackage
setSpeechPackage:
inputOrigin
setInputOrigin:
acousticFTMScores
setAcousticFTMScores:
boronScore
setBoronScore:
speakerIDScore
setSpeakerIDScore:
didDetectSpeechActivity
setDidDetectSpeechActivity:
isAirpodsConnected
setIsAirpodsConnected:
timeSinceLastQuery
setTimeSinceLastQuery:
decisionStage
setDecisionStage:
prevStageOutput
setPrevStageOutput:
eosLikelihood
setEosLikelihood:
_didDetectSpeechActivity
_isAirpodsConnected
_speechPackage
_inputOrigin
_acousticFTMScores
_boronScore
_speakerIDScore
_timeSinceLastQuery
_decisionStage
_prevStageOutput
_eosLikelihood
T@"AFSpeechPackage",&,N,V_speechPackage
T@"NSNumber",&,N,V_inputOrigin
T@"NSNumber",&,N,V_acousticFTMScores
T@"NSNumber",&,N,V_boronScore
T@"NSNumber",&,N,V_speakerIDScore
TB,N,V_didDetectSpeechActivity
TB,N,V_isAirpodsConnected
Td,N,V_timeSinceLastQuery
TQ,N,V_decisionStage
T@"NSNumber",&,N,V_prevStageOutput
T@"NSNumber",&,N,V_eosLikelihood
initWithConfig:error:
processResultCandidate:completion:
@16@0:8
v24@0:8@16
Q16@0:8
v24@0:8Q16
f16@0:8
v20@0:8f16
v16@0:8
@"NSArray"
B16@0:8
v20@0:8B16
@24@0:8@16
@32@0:8@16@24
@32@0:8@16^@24
@"NSDictionary"
@"NSString"
@44@0:8f16Q20Q28@36
@40@0:8@16@24^@32
@48@0:8f16B20d24@32@40
d16@0:8
v24@0:8d16
@"AFSpeechPackage"
@"NSNumber"
v32@0:8@16@?24
@(#)PROGRAM:SiriLiminal  PROJECT:CoreSpeech-
com.apple.SiriLiminal
Framework
v8@?0
::: Initializing SiriLiminal logging...
en_US_POSIX
yyyyMMdd-HHmmss
SLLogInitIfNeeded_block_invoke
gitrelno_unavailable
+[SLASRFeatureExtractor extractASRFaturesFrom:]
max:
min:
stddev:
average:
v32@?0@"AFSpeechUtterance"8Q16^B24
+[SLASRFeatureExtractor extractLRNNFaturesFrom:]
+[SLASRFeatureExtractor _getTokenConfidenceForPath:fromPhrases:]
v32@?0@"AFSpeechPhrase"8Q16^B24
+[SLASRFeatureExtractor _getTokenConfidenceForPath:fromPhrases:]_block_invoke
v32@?0@"AFSpeechToken"8Q16^B24
+[SLUtils decodeJsonFromFile:]
SLInvocationType
SLVoiceTriggerEventInfo
SLAudioSourceOption
SLLanguageCode
Missing keys in context
reason
-[SLProgressiveCheckerContext initWithContext:error:]
EAR not supported
-[SLProgressiveCheckerAnalyzer initWithConfig:withDelegate:error:]
com.apple.sl
numAsrRecords
numTokensTopPath
trailingSilenceDuration
theshold
assetVersion
%s ::: SL logging initialized (%s)
%s Received nil recog candidate, nothing to extract
%s Extracted LRNN Score: %f from Model Version: %{public}@
%s Constructing tokens for speech path %{public}@
%s Adding score %{public}ld for token %{public}@
%s ERR: metaData is nil, defaulting to NO for %{public}@
%s ERR: read metafile %{public}@ failed with %{public}@ - defaulting to NO
%s %{public}@
%s Created SLAcousticContext: %{public}@
SLASRFeatures
SLLRNNFeatures
SLASRFeatureExtractor
SLUtils
SLProgressiveCheckerContext
SLProgressiveCheckerResult
SLProgressiveCheckerAnalyzer
SLUresMitigatorResult
SLUresMitigatorIpFeats
SLUresMitigator
localeWithLocaleIdentifier:
setLocale:
setDateFormat:
latticePathMaxScores
setLatticePathMaxScores:
latticePathMinScores
setLatticePathMinScores:
latticePathMeanScores
setLatticePathMeanScores:
latticePathVarScores
setLatticePathVarScores:
topLatticePathScores
setTopLatticePathScores:
topLatticePathTokenCount
setTopLatticePathTokenCount:
setSnr:
trailingSilence
setTrailingSilence:
.cxx_destruct
_snr
_trailingSilence
_latticePathMaxScores
_latticePathMinScores
_latticePathMeanScores
_latticePathVarScores
_topLatticePathScores
_topLatticePathTokenCount
T@"NSArray",&,N,V_latticePathMaxScores
T@"NSArray",&,N,V_latticePathMinScores
T@"NSArray",&,N,V_latticePathMeanScores
T@"NSArray",&,N,V_latticePathVarScores
T@"NSArray",&,N,V_topLatticePathScores
TQ,N,V_topLatticePathTokenCount
Tf,N,V_snr
Tf,N,V_trailingSilence
lrnnScore
setLrnnScore:
lrnnProcessed
setLrnnProcessed:
_lrnnProcessed
_lrnnScore
Tf,N,V_lrnnScore
TB,N,V_lrnnProcessed
recognition
utterances
count
initWithCapacity:
phrases
_getTokenConfidenceForPath:fromPhrases:
expressionForConstantValue:
arrayWithObject:
expressionForFunction:arguments:
expressionValueWithObject:context:
addObject:
doubleValue
numberWithDouble:
floatValue
_getLastTokenForPath:fromPhrases:
enumerateObjectsUsingBlock:
audioAnalytics
endTime
silenceStartTime
latticeMitigatorResult
score
threshold
version
interpretationIndices
lastObject
unsignedIntegerValue
interpretations
objectAtIndex:
tokens
firstObject
array
dictionaryRepresentation
objectAtIndexedSubscript:
addObjectsFromArray:
confidenceScore
numberWithInteger:
text
extractASRFaturesFrom:
extractLRNNFaturesFrom:
dataWithContentsOfFile:
JSONObjectWithData:options:error:
decodeJsonFromFile:
init
objectForKeyedSubscript:
stringWithFormat:
dictionaryWithObjects:forKeys:count:
errorWithDomain:code:userInfo:
initWithContext:error:
audioOption
vtei
invocationType
locale
_audioOption
_vtei
_invocationType
_locale
TQ,R,N,V_audioOption
T@"NSDictionary",R,N,V_vtei
TQ,R,N,V_invocationType
T@"NSString",R,N,V_locale
initWithScore:ofType:analyzedSamples:detailedResults:
resultType
analyzedSamples
detailedResult
_score
_resultType
_analyzedSamples
_detailedResult
TQ,R,N,V_resultType
TQ,R,N,V_analyzedSamples
Tf,R,N,V_score
T@"NSArray",R,N,V_detailedResult
initWithConfig:withDelegate:error:
startNewRequestWithContext:
addAudio:
endAudio
initWithScore:decision:decisionLevel:detailedResults:extractedFeats:
didMitigate
decisionLevel
assetVersion
extractedFeats
_didMitigate
_threshold
_decisionLevel
_assetVersion
_extractedFeats
TB,R,N,V_didMitigate
Td,R,N,V_decisionLevel
Tf,R,N,V_threshold
T@"NSString",R,N,V_assetVersion
T@"NSDictionary",R,N,V_detailedResult
T@"NSDictionary",R,N,V_extractedFeats
speechPackage
setSpeechPackage:
inputOrigin
setInputOrigin:
acousticFTMScores
setAcousticFTMScores:
boronScore
setBoronScore:
speakerIDScore
setSpeakerIDScore:
didDetectSpeechActivity
setDidDetectSpeechActivity:
isAirpodsConnected
setIsAirpodsConnected:
timeSinceLastQuery
setTimeSinceLastQuery:
decisionStage
setDecisionStage:
prevStageOutput
setPrevStageOutput:
eosLikelihood
setEosLikelihood:
_didDetectSpeechActivity
_isAirpodsConnected
_speechPackage
_inputOrigin
_acousticFTMScores
_boronScore
_speakerIDScore
_timeSinceLastQuery
_decisionStage
_prevStageOutput
_eosLikelihood
T@"AFSpeechPackage",&,N,V_speechPackage
T@"NSNumber",&,N,V_inputOrigin
T@"NSNumber",&,N,V_acousticFTMScores
T@"NSNumber",&,N,V_boronScore
T@"NSNumber",&,N,V_speakerIDScore
TB,N,V_didDetectSpeechActivity
TB,N,V_isAirpodsConnected
Td,N,V_timeSinceLastQuery
TQ,N,V_decisionStage
T@"NSNumber",&,N,V_prevStageOutput
T@"NSNumber",&,N,V_eosLikelihood
initWithConfig:error:
processResultCandidate:completion:
@16@0:8
v24@0:8@16
Q16@0:8
v24@0:8Q16
f16@0:8
v20@0:8f16
v16@0:8
@"NSArray"
B16@0:8
v20@0:8B16
@24@0:8@16
@32@0:8@16@24
@32@0:8@16^@24
@"NSDictionary"
@"NSString"
@44@0:8f16Q20Q28@36
@40@0:8@16@24^@32
@48@0:8f16B20d24@32@40
d16@0:8
v24@0:8d16
@"AFSpeechPackage"
@"NSNumber"
v32@0:8@16@?24
