\contact-first
\contact-last
\contact-middle
\contact-nickname
\contact-first-phonetic
\contact-last-phonetic
\contact-middle-phonetic
v24@?0@"CNContact"8^B16
v40@?0@"NSString"8q16@"NSSet"24^B32
-[ESUserData _fetchContactsWithKeepGoing:]
v24@?0@"LSApplicationProxy"8^B16
-[ESUserData _fetchCoreDuetInteractionsWithKeepGoing:completion:]
(outgoingRecipientCount > 0) OR (incomingSenderCount > 0) OR (incomingRecipientCount > 0)
-[ESUserData _fetchCoreDuetInteractionsWithKeepGoing:completion:]_block_invoke
v24@?0@"NSArray"8@"NSError"16
-[ESUserData _fetchCoreDuetSearchEventsWithKeepGoing:completion:]
-[ESUserData _fetchCoreRoutineWithKeepGoing:completion:]_block_invoke
-[ESUserData _fetchDynamicKeyboardLanguageModelWithKeepGoing:]
v28@?0I8d12^B20
-[ESUserData _fetchEventKitWithKeepGoing:]
v24@?0@"EKEvent"8^B16
B8@?0
%s.%@
CoreDuet interactions
v16@?0@?<v@?>8
CoreDuet search events
CoreRoutine
Contacts
Keyboard
v8@?0
language=%@, contactsWords count=%ld, appNames count=%ld, interactionSenderDisplayNames count=%ld, searchEventValues count=%ld, locationOfInterestNames count=%ld, keyboardLMDynamicVocabularyItems count=%ld eventTitles count=%ld eventLocationNames count=%ld, pexNamedEntityNames count=%ld, corrections count=%ld
language=%@, contactsWords=%@, appNames=%@, interactionSenderDisplayNames=%@, searchEventValues=%@, locationOfInterestNames=%@, keyboardLMDynamicVocabularyItems=%@ eventTitles=%@ eventLocationNames=%@, pexNamedEntityNames=%@, corrections=%@
_language
_contactsWords
_appNames
_interactionSenderDisplayNames
_interactionRecords
-[ESUserData initWithCoder:]
senderDisplayName
-[ESUserData initWithCoder:]_block_invoke
v32@?0@"NSString"8@"NSNumber"16^B24
_searchEventValues
_locationOfInterestNames
_spatialLocationOfInterestNames
_keyboardLMDynamicVocabularyItems
_eventTitles
_eventLocationNames
_pexNamedEntityNames
_corrections
contactWords
appNames
interactionSenderDisplayNames
searchEventValues
locationOfInterestNames
spatialLocationOfInterestNames
keyboardLMDynamicVocabularyItems
eventTitles
eventLocationNames
pexNamedEntityNames
corrections
supportsSecureCoding
TB,R
dictionaryRepresentation
T@"NSDictionary",R,N
language
T@"NSString",R,C,N,V_language
contactsWords
T@"NSArray",R,C,N,V_contactsWords
T@"NSArray",R,C,N,V_appNames
T@"NSDictionary",R,C,N,V_interactionSenderDisplayNames
T@"NSDictionary",R,C,N,V_searchEventValues
T@"NSArray",R,C,N,V_locationOfInterestNames
T@"NSArray",R,C,N,V_spatialLocationOfInterestNames
T@"NSArray",R,C,N,V_eventTitles
T@"NSArray",R,C,N,V_eventLocationNames
T@"NSDictionary",R,C,N,V_keyboardLMDynamicVocabularyItems
T@"NSArray",R,C,N,V_pexNamedEntityNames
T@"NSArray",R,C,N,V_corrections
com.apple.embeddedspeech.FetchSerializer
DoFetchWithTimeout
DoFetchWithTimeout_block_invoke_2
DoFetchWithTimeout_block_invoke
DoFetchWithTimeout_block_invoke_3
v32@?0@"NSString"8@"NSString"16^B24
dictationUIInteractionIdentifier
samplingTimestamp
samplingRate
inferenceSpeakerCode
numTrainedFrames
trainingNnetVersion
isSpeakerCodeUsed
-[ESStoreAudioData initWithUUIDString:language:samplingRate:inferenceSpeakerCode:numTrainedFrames:trainingNnetVersion:isSpeakerCodeUsed:]
-[ESStoreAudioData saveAudioToDisk]
-[ESStoreAudioData _cleanupCacheAndReset:]
-[ESStoreAudioData _saveAudioToCache:]
-[ESStoreAudioData _moveAudioToVarMobile:]
Audio file to be moved nil
Sampling Date is nil
Unable to create directory %@
Unable to create directory %@/%@
%@.plist
-[ESStoreAudioData _saveAudioMetadataToFilePath:]
%.0f
%@_%@_%@.pcm
unixTime
samplingDate
success
failed
errorCode
errorDomain
UNDEFINED
description
underlyingErrorCode
underlyingErrorDomain
status
UUIDString
T@"NSString",C,N,V_UUIDString
T@"NSString",C,N,V_language
TQ,N,V_samplingRate
audioPackets
T@"NSMutableData",&,N,V_audioPackets
hasRecognizedAnything
TB,N,V_hasRecognizedAnything
T@"NSString",R,N,V_inferenceSpeakerCode
T@"NSNumber",R,N,V_numTrainedFrames
T@"NSNumber",R,N,V_trainingNnetVersion
TB,R,N,V_isSpeakerCodeUsed
audioMetadata
T@"NSMutableDictionary",&,N,V_audioMetadata
collectedAudioDurationMS
Td,N,V_collectedAudioDurationMS
currentAudioFilePath
T@"NSString",C,N,V_currentAudioFilePath
com.apple.siri.embeddedspeech
com.apple.private.des-service
Rejecting %@, no %@ or %@ entitlement
hash
TQ,R
superclass
T#,R
T@"NSString",R,C
debugDescription
quasarModelPath
type
QuasarDir
PreferOverServer
RequiredCapabilityIdentifier
InstalledLanguages
mini.json
-[MAAsset(ESAdditions) _es_purgeSync]
FormatVersion
Asset: content version: %@, mastered version %@, installed %@, language: %@, path: %@
Language
-[MAAsset(ESAdditions) _es_isInstalled]
-[ESAssetManager _kickCatalogDownload]_block_invoke
v16@?0q8
com.apple.siri.embeddedspeech.ESAssetManager
v12@?0i8
-[ESAssetManager init]
-[ESAssetManager installationStatusForLanguagesIgnoringCache:withError:]
-[ESAssetManager _invalidateInstallationStatusCache]
-[ESAssetManager _queryInstallationStatusForLanguagesWithError:]
%@: %@: AssetId=%@:
-[ESAssetManager installedModelInfoForLanguage:error:]
No models installed yet
-[ESAssetManager _fetchRemoteAssetForLanguage:]_block_invoke_2
-[ESAssetManager _fetchRemoteAssetForLanguage:]_block_invoke
-[ESAssetManager _installedAssetForLanguage:error:]
-[ESAssetManager _installedAssetFromFoundAssets:language:error:]
-[ESAssetManager _installedLocalAssetForLanguage:error:]
+[ESAssetManager _assetQueryForLanguage:]
-[ESAssetManager _startedDownloadingEmbeddedSpeechAsset:error:]
v16@?0@"MAProgressNotification"8
-[ESAssetManager _startedDownloadingEmbeddedSpeechAsset:error:]_block_invoke
v24@?0@"MAAsset"8^B16
-[ESAssetManager purgeInstalledAssetsExceptLanguages:error:]_block_invoke
MAPurgeResult
-[ESAssetManager purgeOutdatedAssets]_block_invoke
%@: ModelInfo=%@: AssetId=%@:
Installed
Installing
Not Installing
Waiting to Install
Not Supported
Unknown
EnumerateInstalledAssets
overrides
keyboardLM
locationOfInterest
spatialLocationOfInterest
interaction
search
calendarEvent
pexNamedEntity
frequency
charsToTrim
charsToSplit
tagName
templateName
tagNameList
minimumWordLength
\NT-contact
\NT-appname
distributedEvaluation
adaptation
lm_interp_weights
version
data
assetPath
PERSONALINFO
numberOfInsertions
Tq,N,V_numberOfInsertions
numberOfDeletions
Tq,N,V_numberOfDeletions
numberOfSubstitutions
Tq,N,V_numberOfSubstitutions
totalCost
Tq,N,V_totalCost
modelType
T@"NSString",C,N
com.apple.siri.ESConnection
-[ESConnection initWithXPCConnection:]_block_invoke
-[ESConnection dealloc]
com.apple.siri.ESConnection.fidesEval
com.apple.siri.embeddedspeech.preheat-keepalive
-[ESConnection _preheatKeepAlive]
-[ESConnection _preheatKeepAlive]_block_invoke
-[ESConnection fetchAssetsForLanguage:completion:]
-[ESConnection fetchUserDataForLanguage:completion:]_block_invoke
v16@?0@"ESUserData"8
-[ESConnection getOfflineDictationStatusIgnoringCache:withCompletion:]
dispatch.voc
lexicon.enh
itn_s.enh
+[ESConnection _speechRecognizerWithLanguage:enableITN:overrides:modelOverrideURL:error:]
Failed to create recognizer from %@
AlreadyLoaded
Preheating
-[ESConnection preheatSpeechRecognitionWithLanguage:modelOverrideURL:]
Success
Failure
-[ESConnection startSpeechRecognitionWithLanguage:interactionIdentifier:task:context:profile:narrowband:detectUtterances:censorSpeech:maximumRecognitionDuration:farField:overrides:modelOverrideURL:secureOfflineOnly:originalAudioFileURL:applicationName:shouldStoreAudioOnDevice:didStartHandler:]
Recognizer is busy
@"NSDictionary"8@?0
-[ESConnection sendSpeechCorrectionInfo:interactionIdentifier:]
-[ESConnection readProfileAndUserDataWithLanguage:allowOverride:completion:]
Not a dictionary: %@
Not an array: %@
orth
prons
freq
v32@?0@"NSString"8@"NSArray"16^B24
-[ESConnection updateSpeechProfileWithLanguage:modelOverridePath:existingProfile:existingAssetPath:completion:]
Could not build empty user profile
-[ESConnection updateSpeechProfileWithLanguage:modelOverridePath:existingProfile:existingAssetPath:completion:]_block_invoke_3
-[ESConnection updateSpeechProfileWithLanguage:modelOverridePath:existingProfile:existingAssetPath:completion:]_block_invoke
Empty user data
User data unchanged
Could not create user profile
UserData
+[ESConnection _parseRequiredParameter:expectedClass:domain:recipe:error:]
Missing %@ for %@
+[ESConnection _runAdaptationRecipeForNamesWithFrequency:tagNames:templateName:charSetToTrim:charSetToSplit:minimumWordLength:nameFrequencies:profile:]
+[ESConnection _runAdaptationRecipeForNamesWithFrequency:tagNames:templateName:charSetToTrim:charSetToSplit:minimumWordLength:nameFrequencies:profile:]_block_invoke_2
v32@?0@"NSString"8Q16^B24
+[ESConnection _runAdaptationRecipeForKeyboardLMWithFrequency:tagName:templateName:charSetToTrim:charSetToSplit:minimumWordLength:userData:profile:]
+[ESConnection _runAdaptationRecipeForLocationOfInterestWithFrequency:tagName:templateName:charSetToTrim:charSetToSplit:minimumWordLength:locationOfInterestNames:profile:]
+[ESConnection _runAdaptionRecipeForCalendarEventsWithFrequency:tagName:templateName:charSetToTrim:charSetToSplit:minimumWordLength:userData:profile:]
+[ESConnection _scheduleCooldownTimer]
+[ESConnection _cancelCooldownTimer]
+[ESConnection _cooldownTimerFired]
+[ESConnection _cachedRecognizerCleanUp]
+[ESConnection purgeOutdatedAssets]_block_invoke
+[ESConnection _sendPendingAnalyticsEvents]
+[ESConnection _adaptRecipe:userData:profile:]_block_invoke
v32@?0@"NSString"8@"NSDictionary"16^B24
recipeType
-[ESConnection readTableFromURL:]
-[ESConnection runRecipeEvaluationDistributedEvaluation:recordData:attachments:completion:]
returnHypothesis
returnOverallWER
returnOverallRTF
returnPerUtteranceWER
returnPerUtteranceRTF
locale
task
sampleRate
wordSenseWhitelist
wav.scp
raw.ref
-[ESConnection runRecipeEvaluationDistributedEvaluation:recordData:attachments:completion:]_block_invoke
token
confidence
transcription
\\\S+$
EditDistance
details
modelVersion
overall-rtf
overall-wer
v24@?0@"NSData"8@"NSString"16
-[ESConnection _userProfileWithLanguage:modelOverridePath:overrides:foundPath:error:]
en_US_napg.json
vocdelta.voc
pg.voc
token_s.enh
mrec.psh
-[ESConnection _deleteTemporaryDirectoryIfExists:]
-[ESConnection resetCacheAndCompileAllAssetsWithCompletion:]
-[ESConnection deleteAllDESRecordsForDictationPersonalizationWithCompletion:]
-[ESConnection speechRecognizer:didRecognizePartialResult:]_block_invoke
Unsupported EAR build?
Unsupported EAR package build?
-[ESConnection speechRecognizer:didFinishRecognitionWithError:]_block_invoke
recognizer-components
audioDurationMs
recognitionDurationMs
-[ESConnection speechRecognizer:didRecognizeRawEagerRecognitionCandidate:]_block_invoke
tokenName
_ESDecompressArchiveWithURL
VoiceTriggerFidesArchive
Failed to specify compression algorithm
Failed to specify format
Failed to open file for reading
Unable to extract file to: %@
Task %@ not available for %@, supported tasks are %@
etiquette.json
ReplacementDictionaryForLanguage
ReplacementDictionaryForLanguage_block_invoke
v32@?0@"NSString"8@16^B24
voicemail_confidence_subtraction.json
PersonalizationRecipeForLanguage
personalization.json
\correction-first
\NT-correction
AddWordsToUserProfile
\app-first
\company-first
\jit
ReadAudioDataFromFileURL
\\\S*$
Insertions
Deletions
Substitutions
ReferenceSize
CONTACTFIRSTNAME
CONTACTMIDDLENAME
CONTACTLASTNAME
APPNAMEFIRSTNAME
COMPANYFIRSTNAME
\interaction-first
\interaction-middle
\interaction-last
INLINEFIRSTNAME
v32@?0@"NSArray"8Q16^B24
init
copy
arrayWithObjects:count:
initWithKeysToFetch:
givenName
length
setValue:forKey:
familyName
middleName
nickname
phoneticGivenName
phoneticFamilyName
phoneticMiddleName
count
addObject:
enumerateContactsWithFetchRequest:error:usingBlock:
countByEnumeratingWithState:objects:count:
personNameComponentsFromString:
dictionaryWithObjects:forKeys:count:
enumerateVocabularyUsingBlock:
localizedNameWithPreferredLocalizations:useShortNameOnly:
allObjects
interactionRecorder
predicateWithFormat:
displayName
statistics
interactionCount
objectForKey:
integerValue
numberWithUnsignedLong:
setObject:forKey:
queryContactsUsingPredicate:sortDescriptors:limit:completionHandler:
searchFeedbackStream
knowledgeStore
date
dateByAddingTimeInterval:
predicateForEventsWithStartOrEndInDateRangeWithFrom:to:
eventQueryWithPredicate:eventStreams:offset:limit:sortDescriptors:
executeQuery:error:
dictionary
value
stringValue
numberWithLong:
currentCalendar
dateByAddingUnit:value:toDate:options:
defaultManager
preferredName
mapItem
name
address
siriCoreSpatialNames
addObjectsFromArray:
fetchLocationsOfInterestVisitedBetweenStartDate:endDate:withHandler:
objectForKeyedSubscript:
doubleValue
numberWithDouble:
setObject:forKeyedSubscript:
valueForKey:
calendarWithIdentifier:
setWeekOfYear:
dateByAddingComponents:toDate:options:
setMonth:
predicateForEventsWithStartDate:endDate:calendars:
title
structuredLocation
location
enumerateEventsMatchingPredicate:usingBlock:
fetchUserDataWithLanguage:keepGoing:completion:
_initWithLanguage:
stringWithFormat:
UTF8String
_fetchCoreDuetInteractionsWithKeepGoing:completion:
_fetchCoreDuetSearchEventsWithKeepGoing:completion:
_fetchCoreRoutineWithKeepGoing:completion:
_fetchContactsWithKeepGoing:
_fetchDynamicKeyboardLanguageModelWithKeepGoing:
hash
description
stringByAppendingFormat:
decodeObjectOfClass:forKey:
setWithArray:
decodeObjectOfClasses:forKey:
decodePropertyListForKey:
enumerateKeysAndObjectsUsingBlock:
encodeObject:forKey:
fetchUserDataWithLanguage:completion:
supportsSecureCoding
encodeWithCoder:
initWithCoder:
_fetchAppsWithKeepGoing:
_fetchEventKitWithKeepGoing:
isEqual:
debugDescription
dictionaryRepresentation
language
contactsWords
appNames
interactionSenderDisplayNames
searchEventValues
locationOfInterestNames
spatialLocationOfInterestNames
eventTitles
eventLocationNames
keyboardLMDynamicVocabularyItems
pexNamedEntityNames
corrections
.cxx_destruct
_language
_contactsWords
_appNames
_interactionSenderDisplayNames
_searchEventValues
_locationOfInterestNames
_spatialLocationOfInterestNames
_eventTitles
_eventLocationNames
_keyboardLMDynamicVocabularyItems
_pexNamedEntityNames
_corrections
thoroughfare
subLocality
locality
country
containsObject:
removeObject:
processInfo
systemUptime
initWithCapacity:
setUUIDString:
setLanguage:
appendData:
hasData
_createAudioFilePath
_saveAudioToCache:
_moveAudioToVarMobile:
_logAFAnalyticsEventWithStatus:error:customReasonForFailure:
_cleanupCacheAndReset:
cleanupCacheAndReset
dealloc
writeToFile:options:error:
pathComponents
lastObject
stringByAppendingPathComponent:
fileExistsAtPath:isDirectory:
moveItemAtPath:toPath:error:
stringByDeletingPathExtension
_saveAudioMetadataToFilePath:
numberWithUnsignedInteger:
numberWithBool:
writeToFile:atomically:
_createCachesDirectoryIfItDoesNotExist
timeIntervalSince1970
firstObject
initWithDictionary:
code
numberWithInteger:
domain
localizedDescription
userInfo
sharedAnalytics
logEventWithType:context:
initWithUUIDString:language:samplingRate:inferenceSpeakerCode:numTrainedFrames:trainingNnetVersion:isSpeakerCodeUsed:
addAudioPacket:
markRecognition
saveAudioToDisk
_trimAudioIfNeeded:
UUIDString
samplingRate
setSamplingRate:
audioPackets
setAudioPackets:
hasRecognizedAnything
setHasRecognizedAnything:
inferenceSpeakerCode
numTrainedFrames
trainingNnetVersion
isSpeakerCodeUsed
audioMetadata
setAudioMetadata:
collectedAudioDurationMS
setCollectedAudioDurationMS:
currentAudioFilePath
setCurrentAudioFilePath:
_hasRecognizedAnything
_isSpeakerCodeUsed
_UUIDString
_samplingRate
_audioPackets
_inferenceSpeakerCode
_numTrainedFrames
_trainingNnetVersion
_audioMetadata
_collectedAudioDurationMS
_currentAudioFilePath
valueForEntitlement:
initWithXPCConnection:
setExportedInterface:
setExportedObject:
setRemoteObjectInterface:
resume
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
superclass
listener:shouldAcceptNewConnection:
purgeOutdatedAssets
enableTransactions
serviceListener
setDelegate:
_es_quasarModelPath
purgeCompiledRecognizerModelsWithConfiguration:
purgeSync
attributes
_es_requiredCapabilityIdentifier
minimumSupportedConfigurationVersion
floatValue
maximumSupportedConfigurationVersion
_es_contentVersion
_es_masteredVersion
_es_isInstalled
_es_language
_es_path
getLocalFileUrl
path
state
refreshState
_es_purgeSync
compare:options:
compare:
boolValue
_es_compareByVersion:
_es_isCompatibleWithThisDevice
_es_description
_es_isDownloading
_es_status
_es_quasarDir
_es_preferOverServer
_es_moreRecentAsset:
timeIntervalSinceReferenceDate
_exponentialBackoffIntervalWithAttempts:
startCatalogDownload:then:
_invalidateInstallationStatusCache
distantPast
_kickCatalogDownload
_queryInstallationStatusForLanguagesWithError:
_assetQueryForLanguage:
queryMetaDataSync
errorWithDomain:code:userInfo:
results
modelTypeStatusStringAndVersionWithAsset:
modelTypeStatusStringWithAsset:
assetId
standardUserDefaults
stringArrayForKey:
mutableCopy
logLocalRecognitionAssetEvictedForLanguage:
componentsJoinedByString:
synchronize
installedModelInfoForLanguage:error:
stringByReplacingOccurrencesOfString:withString:
_installedAssetForLanguage:error:
_fetchRemoteAssetForLanguage:
_installedAssetFromFoundAssets:language:error:
queryMetaData:
_installedLocalAssetForLanguage:error:
arrayByAddingObject:
_startedDownloadingEmbeddedSpeechAsset:error:
initWithType:
returnTypes:
addKeyValuePair:with:
isStalled
totalWritten
totalExpected
expectedTimeRemaining
spaceCheck:
attachProgressCallBack:
startDownload:then:
invalidateInstallationStatusCache
array
allKeys
cancelDownloadSync
sharedInstance
installationStatusForLanguagesIgnoringCache:withError:
installedQuasarModelPathForLanguage:error:
installedAssetSizeWithError:
purgeInstalledAssetsExceptLanguages:error:
_queue
_languageInstallationStatusCache
_assetUpdatedNotificationToken
_lastCatalogDownload
_numFailedCatalogDownloadAttempts
_lastFailedCatalogDownload
_recognizerAssetPathsInUse
_profileAssetPathsInUse
longLongValue
numberWithLongLong:
allocWithZone:
numberOfInsertions
setNumberOfInsertions:
numberOfSubstitutions
setNumberOfSubstitutions:
numberOfDeletions
setNumberOfDeletions:
totalCost
setTotalCost:
copyWithZone:
incrementInsertions
incrementDeletions
incrementSubstitutions
incrementCost
_numberOfInsertions
_numberOfDeletions
_numberOfSubstitutions
_totalCost
setModelType:
modelType
_setQueue:
_UUID
cancelRecognition
invalidate
setInterruptionHandler:
setInvalidationHandler:
remoteObjectProxy
dataWithJSONObject:options:error:
data
_speechRecognizerWithLanguage:enableITN:overrides:modelOverrideURL:error:
initWithConfiguration:overrides:overrideConfigFiles:generalVoc:lexiconEnh:itnEnh:language:
initWithConfiguration:overrides:
setDetectUtterances:
setRecognizeEagerCandidates:
setConcatenateUtterances:
logLocalRecognitionLoadedForLanguage:duration:
_preheatKeepAlive
_clearPendingAnalyticsEvents
_addPendingAnalyticsEvent:
isEqualToString:
_scheduleCooldownTimer
_sendPendingAnalyticsEvents
startRequestActivityWithCompletion:
interruptTraining
modelInfo
setRecognitionReplacements:
setRecognitionConfidenceSubtraction:
setUserProfileData:
setExtraLmList:
setMaximumRecognitionDuration:
setFarField:
runRecognitionWithResultStream:speakerCodeWriter:language:task:samplingRate:
version
speakerCodeInfo
numFrames
nnetVersion
bytes
addAudioSamples:count:
updateAudioDuration:
removeAllObjects
endAudio
_cancelCooldownTimer
correctedText
sharedPreferences
offlineDictationProfileOverridePath
dataWithContentsOfFile:options:error:
dictionaryWithContentsProfilePathForLanguage:errorOut:
_userProfileWithLanguage:modelOverridePath:overrides:foundPath:error:
JSONObjectWithData:options:error:
objectEnumerator
nextObject
initWithOrthography:pronunciations:tagName:frequency:
addWordWithParts:templateName:
dataProfile
readUserProfile:
componentsSeparatedByCharactersInSet:
unsignedIntegerValue
objectAtIndex:
pronunciationsForOrthography:
enumerateObjectsUsingBlock:
dictionaryWithDictionary:
removeObjectForKey:
whitespaceCharacterSet
countForObject:
arrayByAddingObjectsFromArray:
stringByTrimmingCharactersInSet:
_runAdaptationRecipeForKeyboardLMWithFrequency:tagName:templateName:charSetToTrim:charSetToSplit:minimumWordLength:userData:profile:
_runAdaptationRecipeForLocationOfInterestWithFrequency:tagName:templateName:charSetToTrim:charSetToSplit:minimumWordLength:locationOfInterestNames:profile:
_runAdaptationRecipeForNamesWithFrequency:tagNames:templateName:charSetToTrim:charSetToSplit:minimumWordLength:nameFrequencies:profile:
_runAdaptionRecipeForCalendarEventsWithFrequency:tagName:templateName:charSetToTrim:charSetToSplit:minimumWordLength:userData:profile:
_cooldownTimerFired
_cachedRecognizerCleanUp
logEvents:
_parseRequiredParameter:expectedClass:domain:recipe:error:
characterSetWithCharactersInString:
_runAdaptationRecipeForDomain:frequency:tagNames:templateName:charSetToTrim:charSetToSplit:minimumWordLength:userData:profile:
runDefaultAdaptationEvaluation:recordData:attachments:completion:
runRecipeEvaluationDistributedEvaluation:recordData:attachments:completion:
stringWithContentsOfURL:encoding:error:
componentsSeparatedByString:
whitespaceAndNewlineCharacterSet
rangeOfString:
substringToIndex:
substringFromIndex:
objectAtIndexedSubscript:
URLByAppendingPathComponent:
readTableFromURL:
_speechRecognizerWithLanguage:enableITN:error:
_deleteTemporaryDirectoryIfExists:
recognitionResultsWithAudioData:userProfileData:language:task:samplingRate:extraLanguageModel:
preITNTokens
tokenName
confidence
regularExpressionWithPattern:options:error:
firstMatchInString:options:range:
range
substringWithRange:
numberWithFloat:
readProfileAndUserDataWithLanguage:allowOverride:completion:
initWithConfiguration:language:overrides:sdapiOverrides:generalVoc:emptyVoc:pgVoc:lexiconEnh:tokenEnh:paramsetHolder:
removeItemAtURL:error:
compileRecognizerModelsWithConfiguration:
tokens
_delegate
speechServiceDidRecognizeTokens:
raise:format:
recognition
preITNRecognition
audioAnalytics
isFinal
utteranceStart
initWithRecognition:rawRecognition:audioAnalytics:isFinal:utteranceStart:
utterances
interpretationIndices
concatenateUtterances
speechServiceDidRecognizePackage:
recognitionUtterenceStatistics
recognitionStatistics
addEntriesFromDictionary:
speechServiceDidFinishRecognitionWithStatistics:error:
speechServiceDidProcessAudioDuration:
oneBest
speechServiceDidRecognizeRawEagerRecognitionCandidate:
initialize
_adaptRecipe:userData:profile:
speechRecognizer:didRecognizePartialResult:
speechRecognizer:didFinishRecognitionWithError:
speechRecognizer:didRecognizeFinalResults:
speechRecognizer:didRecognizeFinalResults:tokenSausage:nBestChoices:
speechRecognizer:didRecognizeFinalResultPackage:
speechRecognizer:didProcessAudioDuration:
speechRecognizer:didRecognizeRawEagerRecognitionCandidate:
speechRecognizer:didProduceEndpointFeaturesWithWordCount:trailingSilenceDuration:eosLikelihood:pauseCounts:silencePosterior:processedAudioDurationInMilliseconds:
speechRecognizer:didRecognizePartialResultNbest:
resetCacheAndCompileAllAssetsWithCompletion:
preheatSpeechRecognitionWithLanguage:modelOverrideURL:
startSpeechRecognitionWithLanguage:interactionIdentifier:task:context:profile:narrowband:detectUtterances:censorSpeech:maximumRecognitionDuration:farField:overrides:modelOverrideURL:secureOfflineOnly:originalAudioFileURL:applicationName:shouldStoreAudioOnDevice:didStartHandler:
finishAudio
createSpeechProfileWithLanguage:modelOverridePath:JSONData:completion:
updateSpeechProfileWithLanguage:modelOverridePath:existingProfile:existingAssetPath:completion:
getOfflineDictationStatusIgnoringCache:withCompletion:
fetchAssetsForLanguage:completion:
fetchUserDataForLanguage:completion:
runAdaptationRecipeEvaluation:recordData:attachments:completion:
getInstalledAssetSizeWithCompletion:
purgeInstalledAssetsExceptLanguages:completion:
writeDESRecord
sendSpeechCorrectionInfo:interactionIdentifier:
invalidatePersonalizedLM
removePersonalizedLMForFidesOnly:completion:
runEvaluationWithDESRecordDatas:language:recipe:fidesPersonalizedLMPath:fidesPersonalizedLMTrainingAsset:scrubResult:completion:
deleteAllDESRecordsForDictationPersonalizationWithCompletion:
_fidesEvalQueue
_invalidated
_recognizer
_audioBuffer
_connection
_firstAudioPacketTime
_lastAudioPacketTime
_lastRecognizedPackage
_bufferedAudioPackets
_bufferedAudioEnded
_validDomains
_requestCompletion
_storeAudioData
_audioDurationMs
_localMetrics
_recognitionBeginTime
_recognitionEndTime
_speakerCodeWriter
_weakFidesRecognizer
filteredArrayUsingPredicate:
fileURLWithPath:isDirectory:
UUID
createDirectoryAtURL:withIntermediateDirectories:attributes:error:
fileSystemRepresentation
stringWithUTF8String:
tasks
removeAllWords
sanitizedStringWithString:
initWithOrthography:pronunciations:tag:
signalEndOfUserData
assetWithURL:
tracksWithMediaType:
assetReaderWithAsset:error:
assetReaderAudioMixOutputWithAudioTracks:audioSettings:
canAddOutput:
addOutput:
startReading
copyNextSampleBuffer
dataWithBytes:length:
setObject:atIndexedSubscript:
lowercaseString
stringByReplacingMatchesInString:options:range:withTemplate:
setText:
phoneSequence
setPhoneSequence:
start
setStartTime:
silenceStart
setSilenceStartTime:
setEndTime:
setRemoveSpaceBefore:
hasSpaceAfter
setConfidenceScore:
ipaPhoneSequence
setIpaPhoneSequence:
tokenSausage
initWithPhrases:utterances:
orderedSetWithArray:
initWithInterpretationIndices:confidenceScore:
setSource:
setTokens:
indexOfObject:
setInterpretationIndices:
confidenceScore
setInterpretations:
setIsLowConfidence:
interpretations
acousticFeatures
speechRecognitionFeatures
initWithSpeechRecognitionFeatures:acousticFeatures:
acousticFeatureValuePerFrame
frameDuration
initWithAcousticFeatureValue:frameDuration:
%s Found %lu and added %lu contact(s) for offline recognition
%s Could not get contacts for offline recognition: %@
%s Unable to get an instance of _CDInteractionRecorder.
%s Could not fetch CD interactions: %@
%s Unable to get the search feedback stream instance of _DKEventStream.
%s Unable to get an instance of _DKKnowledgeStore.
%s Could not fetch CD search events with %@: %@
%s Got %ld search queries from %ld CD search events with %@
%s Could not CoreRoutine LOIs: %@
%s Got %ld LOI names and %ld spatial LOI names from %ld locations
%s Could not get dynamic vocabulary from Keyboard LM
%s Found %ld non-dynamic token(s) for and %ld dynamic token(s) KeyboardLM for %@
%s Unable to get an instance of EKEventStore.
%s interactionRecords is not NSArray
%s entry in interactionRecords is not NSDictionary
%s _interactionSenderDisplayNames is not NSDictionary
%s key in interactionSenderDisplayNames is not NSString
%s object in interactionSenderDisplayNames is not NSNumber
%s Skipping fetch for  %@ because another fetch is still active
%s Marking fetch available for %@
%s Timed out waiting on %@
%s Fetch completed for %@ in %.2fms
%s Fetch completed too late (%.2fsms) for %@
%s Dictation Sampling: Error while initializing ESStoreAudioData because uuid is invalid.
%s Dictation Sampling: Won't save audio because - has not recognized anything or has no data.
%s Dictation Sampling: Done with cleanup of audioFile=%@ and reset of variables.
%s Dictation Sampling: Failed to save audio to cache dir. Error: %@
%s Dictation Sampling: Successfully saved audio file to cache dir, path=%@
%s Dictation Sampling: audioFileToBeMoved is nil
%s Dictation Sampling: currentSamplingDate is nil
%s Dictation Sampling: Error while creating DictationSampled directory in /var/mobile
%s Dictation Sampling: Error while creating dated DictationSampled directory in %@ with date - %@
%s Dictation Sampling: Error while moving file from cache directory to var/mobile/Library - %@
%s Dictation Sampling: Successfully moved audio file to var/mobile/Library dir, path=%@
%s Dictation Sampling: Error while writing audio metadata dict to plist - %@
%s Purging compiled assets if there are any.
%s Previously installed asset has been removed: %{public}@
%s Installed asset is corrupt! Triggering emergency purge %{public}@
%s Skipping catalog download because it has only been %.0f seconds
%s Skipping catalog download because it has only been %.0f seconds since last failed attempt
%s The MobileAsset catalog download result was %ld
%s The MobileAsset catalog downloaded successfully
%s Failed to register for asset update notifications.
%s Installation status for languages (ignoring cache: %@)
%s Invalidating installation status cache.
%s Language installation status query failed: %@
%s MobileAsset is broken: %ld
%s Found assets: %@
%s Previously installed offline language(s) removed; installed list: [%@] -> [%@]
%s Returning no model path for nil language
%s Remote fetch asset fetch got assets but none have been installed yet: %@
%s Async asset query failed for query=%@, error=%ld
%s Returning no installed asset for nil language
%s Recording newly installed offline language (%@) installed list is now: [%@]
%s Previously installed offline language (%@) removed; installed list is now: [%@]
%s Found %lu asset(s) for %@, with latest being (%@)
%s Starting a download because %p != %p
%s %@
%s MobileAsset is having trouble with queryMetaDataSync: %ld
%s MobileAsset said it succeeded but it didn't for %{public}@: query=%{public}@
%s No assets were found for query: %@
%s Downloading %@
%s Asset Download Progress: %lld of %lld bytes, ~%.2f seconds remaining
%s Asset Download Progress stalled at %lld of %lld bytes
%s Asset is already installed, no need to start download
%s Asset requires %lld bytes, starting download
%s Asset download successful
%s Asset download failed: %ld
%s Not enough space to download asset, size=%{public}lld
%s Asset download is already queued and in progress
%s Unexpected asset state %ld
%s Asset download state=%ld, success=%d, error=%@
%s Ignoring Purging asset: %@, language %@
%s Purging asset: %@, language %@
%s Purging failed: %@
%s Purging outdated assets.
%s Error canceling download of (%@) before fetching newer version: %ld
%s Error purging (%@) before fetching newer version: %ld
%s Purged old asset %@
%s Just ignoring %@
%s MobileAsset is sad: %ld
%s %@ cancelling instance %@
%s %@ deallocating
%s Acquired os_transaction for dictation preheat
%s Released os_transaction for dictation preheat
%s Failing to fetch assets for nil language
%s Could not get offline language for fetch fallback: %{public}@
%s Fell back asset fetch from %{public}@ to %{public}@
%s Failed to fall back asset fetch from %{public}@ to %{public}@, got %{public}@
%s Unable to serialize user profile to JSON data: %{public}@
%s Could not get installed offline language statuses: %{public}@
%s modelRoot: %@
%s Failed to create recognizer from %{public}@
%s EmbeddedSpeechMetric: Created recognizer in %lf sec from %@
%s Skipping preheat for %@; recognizer already loaded
%s Preheated for %@ with CustomModelURL %@
%s Preheated for %@
%s Could not preheat for %@ with CustomModelURL %@: %@
%s Could not preheat for %@: %@
%s Starting
%s Recognizer is busy
%s Cached recognizer for language %@ already loaded
%s Interrupting training for current running recognizer
%s Interrupting training for previously used recognizer
%s _storeAudioData should be nil. Critical Error. Please check.
%s Got speech correction info with text=%@ interactionId=%@
%s Using override profile at %@
%s Could not use override profile at %@: %@
%s Deserialization of existing speech profile failed: %{public}@
%s Mismatch in speech profile language in content (%{public}@) and filename (%{public}@)
%s Profile version on disk (%{public}@) does not match the expected version (%{public}@)
%s Successfully deserialized existing speech profile for %@
%s Creating profile for %@
%s Re-using existing profile data because the asset (%@) is unchanged
%s Ignoring existing profile data because the asset changed (%@ to %@)
%s Cancelling profile update for %@ due to invalidation
%s Got no data from ESUserData
%s Skipping profile update for %@ because user data has not actually changed
%s Created new profile with %ld bytes (was %ld bytes)
%s Recipe for %{public}@ is missing "%{public}@"
%s Recipe for %{public}@ contains parameter %{public}@, expected type %{public}@ but got %{public}@
%s Using name frequencies adaption for names: %@ into slot %@ for template %@
%s Ignoring name part "%@" because it is too short (minimum length is %lu)
%s Using keyboardLMAdaptation adaption for names %@ into slot %@ for template %@
%s Ignoring keyboardDynamicVocabularyItem "%@" because it is too short (minimum length is %lu)
%s Using locationOfInterestNameAdaptationFrequency adaption for names %@ into slot %@ for template %@
%s Ignoring locationOfInterestName "%@" because it is too short (minimum length is %lu)
%s Using eventLocationNameAdaptationFrequency adaption for names %@ into slot %@ for template %@
%s Ignoring calendar event word "%@" because it is too short (minimum length is %lu)
%s Cooldown timer triggered asset purge
%s embeddedspeech process launch triggered asset purge
%s Sending %lu events
%s Recipe has invalid json for "%{public}@"
%s Recipe has invalid tagName for "%{public}@": "%{public}@"
%s Error executing recipe for domain %{public}@
%s Unable to load the contents of file %@: %@
%s Invalid file format
%s Running distributed evaluation for ASR
%s No attachments given, cannot run distributed evaluation
%s Failed to extract test set: %@
%s Cannot initialize recognizer for locale: %@ task: %@
%s Loaded speech profile
%s Unable to load speech profile
%s Test set contains more utterances than allowed, only running %d utterances
%s Unable to load audio file %@
%s Unable to find reference transcriptions for %@
%s Set model root to %@
%s Use currently installed asset.
%s Failed to delete temporary directory: %@
%s Starting to compile language: %@
%s Error when compiling: %@
%s Error when getting status: %@
%s Failed to delete DES Records because dodML is not supported for this device
%s %lu results
%s EmbeddedSpeechMetric: first audio packet to first partial result = %lf secs
%s Audio finish to recognizer finish = %lf sec, connection is %@, error %@
%s _recognitionBeginTime (%@) is greater than _recognitionEndTime (%@)
%s raw eager recognition candidate: %@
%s Could not make temporary attachment directory at %@: %@
%s Failed to specify compression algorithm: %s
%s Failed to specify format: %s
%s Start extracting archive at path: %s
%s Failed to open archive for reading: %s
%s Entry extraction path: %@
%s Unable to extract file to: %@
%s Finished extracting archive to: %@
%s Could not read %@: %@
%s Could not parse %@: %@
%s %@ is wrong type: %@
%s %@ contains bogus key/value pair: %@ => %@
%s Could not locate asset: %@
%s Could not read personalization.json: %@
%s Could not parse personalization.json: %@
%s User Profile: Starting AddWordsToUserProfile
%s VoiceMail asset could not be read: %@
%s Could not create asset reader output
%s Cannot add output
%s Could not get data pointer: %d
ESUserData
NSSecureCoding
NSCoding
SiriCoreAdditions
ESStoreAudioData
ESListenerDelegate
NSXPCListenerDelegate
NSObject
ESAdditions
ESAssetManager
ESAlignmentState
NSCopying
ESConnectionModelInfo
ESConnection
_EARSpeechRecognitionResultStream
AFSpeechService
v32@0:8@16@?24
v40@0:8@16@?24@?32
B16@0:8
v24@0:8@16
@24@0:8@16
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
v24@0:8@?16
v32@0:8@?16@?24
Q16@0:8
B24@0:8@16
@16@0:8
v16@0:8
@"NSString"
@"NSArray"
@"NSDictionary"
@68@0:8@16@24Q32@40@48@56B64
v40@0:8q16@24@32
v24@0:8Q16
v20@0:8B16
d16@0:8
v24@0:8d16
@"NSMutableData"
@"NSNumber"
@"NSMutableDictionary"
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
B32@0:8@16@24
B32@0:8@"NSXPCListener"16@"NSXPCConnection"24
q16@0:8
q24@0:8@16
d24@0:8Q16
@28@0:8B16^@20
@24@0:8^@16
@32@0:8@16^@24
@40@0:8@16@24^@32
B32@0:8@16^@24
@"NSObject<OS_dispatch_queue>"
@24@0:8^{_NSZone=}16
v24@0:8q16
@36@0:8@16B24^@28
@52@0:8@16B24@28@36^@44
@56@0:8@16#24@32@40^@48
B80@0:8d16@24@32@40@48Q56@64@72
B88@0:8@16d24@32@40@48@56Q64@72@80
v40@0:8@16@24@32
v32@0:8@16@24
v48@0:8@16@24@32@40
v32@0:8@16d24
v72@0:8@16q24q32d40@48d56q64
v32@0:8@"_EARSpeechRecognizer"16@"_EARSpeechRecognitionResult"24
v32@0:8@"_EARSpeechRecognizer"16@"NSError"24
v32@0:8@"_EARSpeechRecognizer"16@"NSArray"24
v48@0:8@"_EARSpeechRecognizer"16@"NSArray"24@"NSArray"32@"NSArray"40
v32@0:8@"_EARSpeechRecognizer"16@"_EARSpeechRecognitionResultPackage"24
v32@0:8@"_EARSpeechRecognizer"16d24
v32@0:8@"_EARSpeechRecognizer"16@"_EARSpeechRecognition"24
v72@0:8@"_EARSpeechRecognizer"16q24q32d40@"NSArray"48d56q64
Vv24@0:8@?16
Vv32@0:8@16@24
Vv128@0:8@16@24@32@40@48B56B60B64d68B76@80@88B96@100@108B116@?120
Vv24@0:8@16
Vv48@0:8@16@24@32@?40
Vv56@0:8@16@24@32@40@?48
Vv28@0:8B16@?20
Vv32@0:8@16@?24
Vv36@0:8@16B24@?28
Vv68@0:8@16@24@32@40@48B56@?60
Vv24@0:8@?<v@?@"NSError">16
Vv32@0:8@"NSString"16@"NSURL"24
Vv24@0:8@?<v@?>16
Vv128@0:8@"NSString"16@"NSString"24@"NSString"32@"NSArray"40@"NSData"48B56B60B64d68B76@"NSDictionary"80@"NSURL"88B96@"NSURL"100@"NSString"108B116@?<v@?@"NSString"@"NSString"@"NSError">120
Vv24@0:8@"NSData"16
Vv48@0:8@"NSString"16@"NSString"24@"NSData"32@?<v@?@"NSData"@"NSError">40
Vv56@0:8@"NSString"16@"NSString"24@"NSData"32@"NSString"40@?<v@?@"NSData"@"NSString"@"NSError">48
Vv28@0:8B16@?<v@?@"NSDictionary"@"NSError">20
Vv32@0:8@"NSString"16@?<v@?@"NSString"@"NSError">24
Vv32@0:8@"NSString"16@?<v@?@"NSData">24
Vv48@0:8@"NSDictionary"16@"NSData"24@"NSArray"32@?<v@?@"NSDictionary"@"NSData"@"NSError">40
Vv36@0:8@"NSString"16B24@?<v@?@"NSData"@"NSString">28
Vv24@0:8@?<v@?@"NSNumber"@"NSError">16
Vv32@0:8@"NSSet"16@?<v@?@"NSNumber"@"NSError">24
Vv32@0:8@"AFSpeechCorrectionInfo"16@"NSString"24
Vv28@0:8B16@?<v@?>20
Vv68@0:8@"NSDictionary"16@"NSString"24@"NSDictionary"32@"NSString"40@"NSString"48B56@?<v@?@"NSDictionary"@"NSError">60
v48@0:8@16@24@32@?40
@56@0:8@16@24@32^@40^@48
@"_EARSpeechRecognizer"
@"_EARSpeechRecognitionAudioBuffer"
@"NSXPCConnection"
@"AFSpeechPackage"
@"NSMutableArray"
@"NSSet"
@"ESStoreAudioData"
@"_EARSpeakerCodeWriter"
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
<key>com.apple.CoreRoutine.LocationOfInterest</key>
<true/>
<key>com.apple.coreaudio.allow-amr-decode</key>
<true/>
<key>com.apple.coreduetd.allow</key>
<true/>
<key>com.apple.coreduetd.people</key>
<true/>
<key>com.apple.locationd.effective_bundle</key>
<true/>
<key>com.apple.private.DistributedEvaluation.RecordAccess-com.apple.fides.asr</key>
<true/>
<key>com.apple.private.DistributedEvaluation.RecordAccess-com.apple.siri.speech-dictation-personalization</key>
<true/>
<key>com.apple.private.assets.accessible-asset-types</key>
<array>
<string>com.apple.MobileAsset.EmbeddedSpeech</string>
<string>com.apple.MobileAsset.EmbeddedSpeechWatch</string>
<string>com.apple.MobileAsset.EmbeddedSpeechMac</string>
</array>
<key>com.apple.private.calendar.allow-suggestions</key>
<true/>
<key>com.apple.private.contacts</key>
<true/>
<key>com.apple.private.corerecents</key>
<true/>
<key>com.apple.private.corespotlight.internal</key>
<true/>
<key>com.apple.private.security.storage.SpeechPersonalizedLM</key>
<true/>
<key>com.apple.private.tcc.allow</key>
<array>
<string>kTCCServiceAddressBook</string>
<string>kTCCServiceCalendar</string>
</array>
<key>com.apple.proactive.PersonalizationPortrait.NamedEntity.readOnly</key>
<true/>
<key>com.apple.security.exception.mach-lookup.global-name</key>
<array>
<string>com.apple.suggestd.contacts</string>
</array>
<key>com.apple.security.iokit-user-client-class</key>
<array>
<string>AGXCommandQueue</string>
<string>AGXDevice</string>
<string>AGXDeviceUserClient</string>
<string>AGXSharedUserClient</string>
<string>H11ANEInDirectPathClient</string>
<string>IOAccelContext</string>
<string>IOAccelContext2</string>
<string>IOAccelDevice</string>
<string>IOAccelDevice2</string>
<string>IOAccelSharedUserClient</string>
<string>IOAccelSharedUserClient2</string>
<string>IOAccelSubmitter2</string>
<string>IOSurfaceRootUserClient</string>
</array>
<key>com.apple.security.personal-information.addressbook</key>
<true/>
<key>com.apple.siriknowledged</key>
<true/>
<key>com.apple.spotlight.search</key>
<true/>
</dict>
</plist>
zPLR
zPLR
zPLR
mcpl
