allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
comm_safety_handler
Create
CommSafetyModels/ImageModel
CommSafetyModels/TextModel
v8@?0
General
TextDecoder
CTCTextDecoder
CVNLPLanguageModel
com.apple.cvnlp
%@%@
/System/Library/PrivateFrameworks/CVNLP.framework/lm_vocabulary.plist
/tmp/lm_vocabulary.plist
CVNLPBeamSearch
Could not construct
encoder_opt.espresso.net
image
mean_feats
att_feats
p_att_feats
CVNLPCaptionError
You must override %@ in a subclass
] Avg vocab subset size over 
 samples: 
; numRetries: 
position
] sampleText: 
/dev/urandom
temperature
InputDimension
SequenceLength
ModelURL
ModelData
InputNames
OutputNames
ModelName
ModelVersion
QuantizationParams
QuantizationSchemeName
QuantizationSchemeLinearInt8RangeMin
QuantizationSchemeLinearInt8RangeMax
Unexpected mrlkey: 
from
%@(%@ <%@> at <%@>: <%@>)
CVNLPCommSafetyTextItem requires keyed coding
CVNLPConversationIdentifier
CVNLPDate
CVNLPDirection
CVNLPText
INSendMessageIntent
com.apple.MobileSMS
CVNLPCommSafetyCDTextProvider event query creation failed: %@
CVNLPCommSafetyCDTextProvider event query execution error: %@
chat
urn:biz:
CVNLPCommSafetyCDTextProvider event query execution failed: %@
_DKKnowledgeStore
_DKEventQuery
_DKSystemEventStreams
_DKQuery
_DKSource
_DKIntentMetadataKey
CVNLPCommSafetyCDTextProvider class initialization failed: %p %p %p %p %p %p
CVNLPCommSafetyCDTextProvider class initialization failed: %@
Activation Matrix with %ld timesteps, %ld observations 
 t%ld, <B>:%.2f [%ld], sym=%@:%.2f [%ld]
c_network_get_input_names returned null for encoder
Failed to load encoder network
Encode
EncodePx
Error during scaling.
Error code %zd
q24@?0@"NSString"8@"NSString"16
Could not find item
Could not convert
self ENDSWITH '.net'
self ENDSWITH 'operating_thresholds.json'
class_thresholds
class
index
nsfw_explicit
thresholds
59744aeff8
Scale
Inference
com.apple.CVNLP
Default
v44@?0^{__CFURL=}8i16^{__CFLocale=}20^{__CFString=}28^B36
v56@?0@"NSString"8{_NSRange=QQ}16{_NSRange=QQ}32^B48
v28@?0r*8q16I24
0123456789
<PS>
Missing or incorrect bos or eos or unk token in vocabulary file
Unexpected format in Special Map file
Special token shall not appear in vocabulary file
Missing special token class in vocabulary file
Unknown TokenID: 
Special token 
 not found in vocab!
Unknown Token: 
Input text should not contain BOS token!
OutOfVocabularyError: 
bimap<>: invalid key
[%@: Peak-Delta: %lf, CPU-Time: %lf, Interval: %lf]
maxpeak
peakdelta
recentpeak
current
timeInterval
CVNLPExceptionError
caption_queue
classify_queue
Total
ScalePx
TotalPx
["%@"], modelLogProb=%.8f, logProbTotalNorm=%.8f, logProbBlank=%.8f, logProbNonBlank=%.8f, %lu tokens
["%@"], logProbTotal=%.8f, logProbNormTotal=%.8f, logProbWordLM=%.8f, logProbHistoryLex=%.8f, logProbActiveLex=%.8f, logProbCharacterLM=%.8f, %lu tokens
v24@?0^{_LXCursor=}8^B16
'.-/
com.apple.cvnlp.languagemodeling
d16@?0@"CVNLPTextDecodingPath"8
MRLNeuralNetworkCreate returned nullptr
DictionaryRef_iterator iterator out of range.
decoder_queue
DecodeBlockExecute:%tu
DecodeBlockCopy:%tu
decoder_block%tu_opt.espresso.net
att_feats_placeholder
block_input
block_output
decoder_opt.espresso.net
vanilla_attention
_out
in_word_ids
word_probs
in_word_ids_mask
scale
Failed to load decoder network
self_attention
_k_s_in
_v_s_in
Failed to execute decoder network
CVNLPBeamSearchSize
CVNLPBeamSearchLengthNormalizationFactor
CVNLPBeamSearchOutputVocabSize
CVNLPBeamSearchOutputVocabPath
CVNLPBeamSearchOutputVocabMap
CVNLPBeamSearchOutputVocabFilterList
CVNLPBeamSearchBlacklistRules
CVNLPBeamEndToken
CVNLPBeamSearchIncludeLanguageModel
CVNLPBeamSearchBeamID
CVNLPBeamSearchNextTokenID
CVNLPBeamSearchNextTokenSoftmaxValues
CVNLPBeamSearchNextTokenMetaData
CVNLPBeamTokens
CVNLPBeamScore
vocab.txt
special_map.txt
sentencepiece.model
Unable to find vocab file.
d24@?0d8d16
%@ : %.2f
v32@?0@"NSString"8@"CVNLPCTCTextDecodingPath"16^B24
CVNLPCaption
 %@ 
%@(<%@> from <%@>-<%@> %@)
sensitive
non-sensitive
CVNLPCommSafetyTextClassification requires keyed coding
CVNLPStartDate
CVNLPEndDate
CVNLPResult
%@(%@ %@ > %.2g)
operating_thresholds.json
model_thresholds
threshold
TextClassifier%@.mlmodelc
CVNLPCommSafetyTextAnalyzer item provider error: %@
v32@?0@"NSArray"8@"NSError"16^B24
CVNLPCommSafetyError
triggerTokens
CVNLPCommSafetyImageSensitivity
CVNLPCommSafetyImageSensitivityScore
CVNLPCommSafetyHandlerImageClassificationScores
CVNLPCaptionScaleMethod
CVNLPCaptionScaleMethodCGInterpolationNone
CVNLPCaptionScaleMethodCGInterpolationLow
CVNLPCaptionScaleMethodCGInterpolationMedium
CVNLPCaptionScaleMethodCGInterpolationHigh
CVNLPCaptionScaleMethodvImage
CVNLPCommSafetyUseCPU
CVNLPCommSafetyUseGPU
CVNLPCommSafetyUseANE
CVNLPCommSafetyUseMTLDevice
CVNLPCommSafetyUseTextAnalyzer
CVNLPModelURLKey
CVNLPTokenTypeKey
CVNLPLocaleKey
CVNLPLanguageModelArchitectureKey
CVNLPSamplingBeamSizeKey
CVNLPSamplingMaxLengthKey
CVNLPSamplingMethodKey
CVNLPSamplingNucleusThresholdKey
CVNLPSamplingNumberKey
CVNLPSamplingTopKKey
Missing required key:
model.dat
LSTM
model.espresso.bin
_gpt
Received null token.
Received empty token.
Method
GREEDY
BEAM
TOP_K
NUCLEUS
TopK
Number
NucleusThreshold
MaxLength
Locale
TokenType
Architecture
BeamSize
Unexpected CVNLP key: 
CVNLPLanguageModelWithState
InvalidProbabilityError: expected 
to be in the interval [0, 1].
CVNLPCaptionTrackPerformance
CVNLPCaptionModelPath
CVNLPCaptionLanguage
CVNLPCaptions
CVNLPGeneratedCaption
CVNLPGeneratedCaptionScore
CVNLPGeneratedCaptionConfidenceLow
CVNLPImageClassificationIdentifiers
CVNLPCaptionModelType
CVNLPCaptionModelLSTM
CVNLPCaptionModelTransformer
CVNLPCaptionEnableGenderedCaptions
CVNLPCaptionFilterTokens
v32@?0@"NSString"8d16^B24
Mismatching vocab file and output vocab sizes
vocab_reverse.json
Decode
DecodeBlock
OneStep
q24@?0@"CVNLPDecodingLexicon"8@"CVNLPDecodingLexicon"16
priority == %lu
v24@?0@"CVNLPDecodingLexicon"8^B16
decoder_opt_pro.espresso.net
mean_feats_placeholder
p_att_feats_placeholder
in_word_id
lstm/att_state_feed
lstm/lang_state_feed
word_id
lang_prob
new_att_state
new_lang_state
lstmAttnStateData
lstmLangStateData
system
generic
Unknown error
ENOMEM
boost::filesystem::canonical
boost::filesystem::current_path
boost::filesystem::read_symlink
boost::filesystem::status
precompiled_charsmap is empty.
Normalizer model is not available.
length < 0
norm_to_org and normalized are inconsistent
Trie blob is broken.
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-26/src/util.h
'result' Must be non NULL
Cannot open 
input ifstream is null
Model file is broken
Model is not initialized.
Normalizer is not initialized.
output container is null
Empty piece is not allowed.
consumed index is out-of-range.
original index is out-of-range.
all normalized characters are not consumed.
output proto is null
NBestEncode returns empty result
nbest_size must be 0 < nbest_size <= 512 or nbest_size < 0.
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-26/src/sentencepiece_processor.cc
LOG(
ERROR
Returns default value 
</s>
Unknown extra_option type
reverse
option 
 is not available.
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-26/ProtocolBuffers/src/google/protobuf/arenastring.h
CHECK failed: initial_value != NULL: 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-26/ProtocolBuffers/src/google/protobuf/repeated_field.h
CHECK failed: (index) >= (0): 
CHECK failed: (index) < (current_size_): 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-26/src/model_factory.cc
Unknown model_type: 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-26/src/char_model.cc
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-26/src/unigram_model.cc
best_node
nbest_size >= 1. Returns empty result.
Too big agenda. shrinking
(num_nodes) < (trie_results.size())
model file is already precompiled.
No pieces are loaded.
Cannot build double-array.
No entry is found in the trie.
precompiled_trie is empty.
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-26/third_party/darts_clone/darts.h:776: exception: failed to resize pool: std::bad_alloc
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-26/third_party/darts_clone/darts.h:1214: exception: failed to insert key: negative value
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-26/third_party/darts_clone/darts.h:1216: exception: failed to insert key: zero-length key
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-26/third_party/darts_clone/darts.h:1230: exception: failed to insert key: invalid null character
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-26/third_party/darts_clone/darts.h:1235: exception: failed to insert key: wrong key order
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-26/third_party/darts_clone/darts.h:915: exception: failed to build rank index: std::bad_alloc
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-26/third_party/darts_clone/darts.h:1453: exception: failed to modify unit: too large offset
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-26/third_party/darts_clone/darts.h:1799: exception: failed to build double-array: invalid null character
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-26/third_party/darts_clone/darts.h:1801: exception: failed to build double-array: negative value
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-26/third_party/darts_clone/darts.h:1816: exception: failed to build double-array: wrong key order
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-26/src/sentencepiece_model.pb.cc
CHECK failed: !model_prefix_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
CHECK failed: !input_format_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
CHECK failed: (&from) != (this): 
sentencepiece.TrainerSpec
CHECK failed: !name_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
CHECK failed: !precompiled_charsmap_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
sentencepiece.NormalizerSpec
CHECK failed: !piece_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
sentencepiece.ModelProto.SentencePiece
CHECK failed: !precompiled_trie_.IsDefault( &::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
CHECK failed: trainer_spec_ != NULL: 
CHECK failed: normalizer_spec_ != NULL: 
sentencepiece.ModelProto
CHECK failed: (n) >= (0): 
down_cast
casts.h
f == NULL || dynamic_cast<To>(f) != NULL
CHECK failed: (&other) != (this): 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-26/src/model_interface.cc
User defined symbol is not supported.
 is already defined.
!result.empty()
Cancelled
Unknown
Invalid argument
Deadline exceeded
Not found
Already exists
Permission denied
Unauthenticated
Resource exhausted
Failed precondition
Aborted
Out of range
Unimplemented
Internal
Unavailable
Data loss
Unkown code:
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-26/src/sentencepiece.pb.cc
CHECK failed: !surface_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
sentencepiece.SentencePieceText.SentencePiece
CHECK failed: !text_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
sentencepiece.SentencePieceText
sentencepiece.NBestSentencePieceText
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-26/src/bpe_model.cc
Invalid character length.
(index) >= (0)
(index) < (static_cast<int>(symbols.size()))
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-26/src/model_interface.h
Not implemented.
(cannot determine missing fields for lite message)
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-26/ProtocolBuffers/src/google/protobuf/message_lite.cc
CHECK failed: !coded_out.HadError(): 
parse
Can't 
 message of type "
" because it is missing required fields: 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-26/ProtocolBuffers/src/google/protobuf/wire_format_lite.cc
CHECK failed: (value.size()) <= (kint32max): 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-26/ProtocolBuffers/src/google/protobuf/io/coded_stream.cc
A protocol message was rejected because it was too big (more than 
 bytes).  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
CHECK failed: (buffer_size) >= (0): 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-26/ProtocolBuffers/src/google/protobuf/generated_message_util.cc
Not implemented field number 
 with type 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-26/ProtocolBuffers/src/google/protobuf/stubs/common.cc
This program requires version 
 of the Protocol Buffer runtime library, but the installed version is 
.  Please update your library.  If you compiled the program yourself, make sure that your headers are from the same version of Protocol Buffers as your link-time library.  (Version verification failed in "
This program was compiled against version 
 of the Protocol Buffer runtime library, which is not compatible with the installed version (
).  Contact the program author for an update.  If you compiled the program yourself, make sure that your headers are from the same version of Protocol Buffers as your link-time library.  (Version verification failed in "
%d.%d.%d
INFO
WARNING
FATAL
[libprotobuf %s %s:%d] %s
pthread_mutex_lock: 
pthread_mutex_unlock: 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-26/ProtocolBuffers/src/google/protobuf/io/zero_copy_stream.cc
This ZeroCopyOutputStream doesn't support aliasing. Reaching here usually means a ZeroCopyOutputStream implementation bug.
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-26/ProtocolBuffers/src/google/protobuf/io/zero_copy_stream_impl_lite.cc
CHECK failed: (last_returned_size_) > (0): 
BackUp() can only be called after a successful Next().
CHECK failed: (count) <= (last_returned_size_): 
CHECK failed: (count) >= (0): 
CHECK failed: target_ != NULL: 
Cannot allocate buffer larger than kint32max for 
StringOutputStream.
CHECK failed: (count) <= (target_->size()): 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-26/ProtocolBuffers/src/google/protobuf/extension_set.cc
Non-primitive types can't be packed.
can't reach here.
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-26/ProtocolBuffers/src/google/protobuf/arena.cc
CHECK failed: (min_bytes) <= (std::numeric_limits<size_t>::max() - kHeaderSize): 
N5cvnlp4util6InFileE
N5cvnlp4util4FileE
N5cvnlp4util4PathE
N5boost10filesystem4pathE
N5boost6detail15sp_counted_baseE
N5cvnlp4util9DirectoryE
NSt3__110__function6__funcIZN5cvnlp4util6MatrixIfE3rowEmEUlmmE_NS_9allocatorIS6_EEFmmmEEE
NSt3__110__function6__baseIFmmmEEE
ZN5cvnlp4util6MatrixIfE3rowEmEUlmmE_
<N5cvnlp13GreedySamplerE
N5cvnlp20LanguageModelSamplerE
N5cvnlp11TopKSamplerE
N5cvnlp11BeamSamplerE
N5cvnlp14NucleusSamplerE
7N5cvnlp20OutOfVocabularyErrorE
N5cvnlp19TokenListVocabularyE
N5cvnlp18AbstractVocabularyE
N5cvnlp23SentencePieceVocabularyE
N5boost16exception_detail10clone_implINS0_19error_info_injectorISt12out_of_rangeEEEE
N5boost16exception_detail19error_info_injectorISt12out_of_rangeEE
N5boost9exceptionE
N5boost16exception_detail10clone_baseE
NSt3__113basic_fstreamIcNS_11char_traitsIcEEEE
NSt3__113basic_filebufIcNS_11char_traitsIcEEEE
N5cvnlp18CharacterTokenizerE
N5cvnlp17AbstractTokenizerE
N5cvnlp19WhitespaceTokenizerE
"(9DJPV^djq
"(9DJPV^djq
"(2;CIOV\bj
"(7AMSYcioxN5cvnlp23InvalidProbabilityErrorE
N5boost6system12_GLOBAL__N_121system_error_categoryE
N5boost6system14error_categoryE
N5boost12noncopyable_11noncopyableE
N5boost6system14error_category12std_categoryE
N5boost6system12_GLOBAL__N_122generic_error_categoryE
&4,4/424#4)
N5boost10filesystem16filesystem_errorE
N5boost6system12system_errorE
N5boost6detail17sp_counted_impl_pINS_10filesystem16filesystem_error5m_impEEE
N13sentencepiece10normalizer10NormalizerE
N5Darts15DoubleArrayImplIvvivEE
N13sentencepiece22SentencePieceProcessorE
NSt3__114basic_ifstreamIcNS_11char_traitsIcEEEE
N13sentencepiece4word5ModelE
*-0N13sentencepiece9character5ModelE
$1``
ESKN13sentencepiece7unigram7LatticeE
N13sentencepiece7unigram9ModelBaseE
N13sentencepiece7unigram5ModelE
N5Darts7Details9ExceptionE
!1@O
N13sentencepiece11TrainerSpecE
N13sentencepiece14NormalizerSpecE
N13sentencepiece24ModelProto_SentencePieceE
N13sentencepiece10ModelProtoE
NSt3__112basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEE
N13sentencepiece14ModelInterfaceE
$).38=BGLQV
N13sentencepiece31SentencePieceText_SentencePieceE
N13sentencepiece17SentencePieceTextE
N13sentencepiece22NBestSentencePieceTextE
N6google8protobuf8internal29InternalMetadataWithArenaBaseINSt3__112basic_stringIcNS3_11char_traitsIcEENS3_9allocatorIcEEEENS1_29InternalMetadataWithArenaLiteEE9ContainerE
N13sentencepiece3bpe5ModelE
N6google8protobuf11MessageLiteE
N6google8protobuf8internal12FieldSkipperE
N6google8protobuf8internal29CodedOutputStreamFieldSkipperE
NSt3__119basic_ostringstreamIcNS_11char_traitsIcEENS_9allocatorIcEEEE
NSt3__115basic_stringbufIcNS_11char_traitsIcEENS_9allocatorIcEEEE
N6google8protobuf14FatalExceptionE
N6google8protobuf7ClosureE
N6google8protobuf8internal16FunctionClosure0E
N6google8protobuf2io20ZeroCopyOutputStreamE
N6google8protobuf2io17ArrayOutputStreamE
N6google8protobuf2io18StringOutputStreamE
-BWl
$-6?Pajr{
N6google8protobuf8internal15ExtensionFinderE
N6google8protobuf8internal24GeneratedExtensionFinderE
NSt3__121__basic_string_commonILb1EEE
N6google8protobuf13RepeatedFieldIiEE
N6google8protobuf13RepeatedFieldIxEE
N6google8protobuf13RepeatedFieldIjEE
N6google8protobuf13RepeatedFieldIyEE
N6google8protobuf13RepeatedFieldIfEE
N6google8protobuf13RepeatedFieldIdEE
N6google8protobuf13RepeatedFieldIbEE
N6google8protobuf16RepeatedPtrFieldINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEEE
N6google8protobuf8internal20RepeatedPtrFieldBaseE
N6google8protobuf16RepeatedPtrFieldINS0_11MessageLiteEEE
Expected token=%s to get converted into single TokenID, but got %zu tokenIDs: %s. Returning UNK TokenID as fallback.
[CVNLPTokenIDConverter] Failed to load token id resources: %s
Input buffer and pixel buffer are both nil
Unexpected tokenNormalizedScore issue? got %.8f from tokenScore = %.2f, characterCount = %ld
Received unsupported CFType for locale.
Received unsupported model format. Could be either Montreal or Espresso
Creation options does not contain all required keys.
Unable to determine model locale from options=%@
Locale not supported: %s
Model directory does not exist: %s
Expected output sequence to have dimensions (vocab=%ld, time=%ld), but got (vocab=%ld, time=%ld)
Invalid sampling method: "%s"
softlink:o:path:/System/Library/Frameworks/CoreML.framework/CoreML
softlink:o:path:/System/Library/Frameworks/CoreDuet.framework/CoreDuet
softlink:o:path:/System/Library/Frameworks/CoreML.framework/CoreML
softlink:o:path:/System/Library/Frameworks/CoreDuet.framework/CoreDuet
softlink:o:path:/System/Library/Frameworks/CoreML.framework/CoreML
softlink:o:path:/System/Library/Frameworks/CoreDuet.framework/CoreDuet
CVNLPCommSafetyHandler
CVNLPTextDecodingToken
CVNLPCaptionSensitiveImageParameters
CVNLPInformationStream
CVNLPLanguageResourceBundle
CVNLPCaptionEncoderLSTM
CVNLPCaptionEncoder
CVNLPCommSafetyTextItem
NSCopying
NSSecureCoding
NSCoding
CVNLPCommSafetyTextProvider
CVNLPCommSafetyCDTextProvider
CVNLPActivationMatrix
CVNLPLexiconCursors
CVNLPCaptionEncoderTransformer
CVNLPCaptionPostProcessingHandler
CVNLPCaptionModelBase
BundleHelper
CVNLPTextDecodingConfiguration
CVNLPTextDecodingBeamSearchConfiguration
CVNLPCommSafetyImageAnalyzer
CVNLPTextDecoder
CVNLPCaptionRuntimeParameters
CVNLPTextDecodingResultCandidate
CVNLPTextDecodingResult
CVNLPDecodingLanguageModel
CVNLPTokenIDConverter
CVNLPPerformanceResult
CVNLPPerformance
CVNLPCTCTextDecodingPath
CVNLPCaptionDecoder
CVNLPTextDecodingPath
CVNLPModelBase
CVNLPCaptionDecoderBlock
CVNLPCTCBeamState
CVNLPCaption
CVNLPCommSafetyTextClassification
CVNLPCommSafetyTextAnalyzerModel
CVNLPCommSafetyTextAnalyzer
CVNLPCaptionRuntimeExcludeGenderTrigger
CVNLPVisionRequestHandler
CVNLPCTCTextDecoder
CVNLPTextDecoding
NSObject
CVNLPCaptionRuntimeReplacements
3@!2
CVNLPCaptionDecoderTransformer
CVNLPDecodingLexicon
CVNLPDecodingLexicons
CVNLPCaptionDecoderLSTM
CVNLPTextDecodingContext
initWithOptions:
init
bundleForClass:
objectForKeyedSubscript:
boolValue
perfResults
resourcePath
arrayWithObjects:count:
fileURLWithPathComponents:
options
initWithModelURL:options:
run:block:
clientQueue
imageAnalyzer
classifyImage:
unsignedIntegerValue
generateClassificationScoresForImage:
classifyPixelBuffer:
generateClassificationScoresForPixelBuffer:
textAnalyzer
processText:inConversationWithIdentifier:date:error:
processConversationsWithStartDate:endDate:previousClassifications:progressHandler:completionHandler:
classifyPixelBuffer:startDate:endDate:stagedText:inConversationWithIdentifier:error:
dictionary
results
addEntriesFromDictionary:
performanceResults
copy
classifyPixelBuffer:stagedText:inConversationWithIdentifier:error:
performanceStatistics
.cxx_destruct
_clientQueue
_imageAnalyzer
_textAnalyzer
_options
_perfResults
T@"NSObject<OS_dispatch_queue>",R,V_clientQueue
T@"CVNLPCommSafetyImageAnalyzer",R,V_imageAnalyzer
T@"CVNLPCommSafetyTextAnalyzer",R,V_textAnalyzer
T@"NSDictionary",R,V_options
T@"CVNLPPerformance",R,N,V_perfResults
initWithString:score:alignmentScore:activationRange:terminatingCharacter:
stringWithFormat:
initWithString:score:activationRange:terminatingCharacter:
initWithString:score:activationRange:hasPrecedingSpace:
fullString
string
hasPrecedingSpace
terminatingCharacter
score
alignmentScore
activationRange
_hasPrecedingSpace
_string
_terminatingCharacter
_score
_alignmentScore
_activationRange
T@"NSString",R,C,N,V_string
TB,R,N,V_hasPrecedingSpace
T@"NSString",R,C,N,V_terminatingCharacter
T@"NSNumber",R,C,N,V_score
T@"NSNumber",R,C,N,V_alignmentScore
T{_NSRange=QQ},R,N,V_activationRange
T@"NSString",R,C,N
errorWithDomain:code:userInfo:
defaultManager
fileExistsAtPath:
floatValue
path
bytes
numberWithUnsignedLong:
setObject:forKeyedSubscript:
array
numberWithFloat:
dictionaryWithObjects:forKeys:count:
addObject:
addObjectsFromArray:
initWithVisionIdentifier:minConfidence:commonBlockingTokens:categoryBlockingTokens:categoryBlockingTokensAnnex:
visionIdentifier
minConfidence
blockingTokens
_visionIdentifier
_minConfidence
_blockingTokens
T@"NSString",R,N,V_visionIdentifier
Td,R,N,V_minConfidence
T@"NSArray",R,N,V_blockingTokens
defaultLowerBoundLogProbability
initWithDecodingWeight:lowerBoundLogProbability:
doubleValue
numberWithDouble:
defaultDecodingWeight
initWithDecodingWeight:
decodingWeightValue
lowerBoundLogProbabilityValue
decodingWeight
lowerBoundLogProbability
_decodingWeightValue
_lowerBoundLogProbabilityValue
_decodingWeight
_lowerBoundLogProbability
T@"NSNumber",R,N,V_decodingWeight
T@"NSNumber",R,N,V_lowerBoundLogProbability
packagedLexiconCursorsUsingTextDecodingContext:
packagedLexiconRootCursors
initWithLexicons:characterLanguageModel:wordLanguageModel:
packagedLexiconCursorsUsingContext:
lexicons
characterLanguageModel
wordLanguageModel
_lexicons
_characterLanguageModel
_wordLanguageModel
T@"CVNLPDecodingLexicons",R,N,V_lexicons
T@"CVNLPDecodingLanguageModel",R,N,V_characterLanguageModel
T@"CVNLPDecodingLanguageModel",R,N,V_wordLanguageModel
initWithOptions:runTimeParams:
URLByAppendingPathComponent:
UTF8String
dealloc
_run:meanFeatures:attnFeatures:projectedAttnFeatures:
_copy_data_from_blob:to:
dataWithBytes:length:
data
computeCaptionForImage:outputs:
encoderPlan
encoderCtx
encoderNet
meanFeatsBlob
attFeatsBlob
pAttFeatsBlob
meanFeaturesPresent
exceptionWithName:reason:userInfo:
_blob_size:
computeCaptionForPixelBuffer:outputs:
_fill_blob_data:with:
data_dim
direction
description
conversationIdentifier
date
text
hash
isEqual:
allowsKeyedCoding
encodeObject:forKey:
encodeInteger:forKey:
decodeObjectOfClass:forKey:
decodeIntegerForKey:
initWithConversationIdentifier:date:direction:text:
supportsSecureCoding
copyWithZone:
encodeWithCoder:
initWithCoder:
TB,R
_conversationIdentifier
_date
_text
_direction
T@"NSString",R,C,N,V_conversationIdentifier
T@"NSDate",R,C,N,V_date
Tq,R,N,V_direction
T@"NSString",R,C,N,V_text
defaultTextProvider
setDefaultTextProvider:
T@"CVNLPCommSafetyTextProvider",&
provideTextItemsWithConversationIdentifier:startDate:endDate:progressHandler:
appIntentsStream
arrayWithObjects:
setEventStreams:
startDateSortDescriptorAscending:
setSortDescriptors:
setExecuteConcurrently:
intentClass
predicateForObjectsWithMetadataKey:andStringValue:
intentsSourceID
predicateForEventsWithSourceID:bundleID:groupIDs:
predicateForEventsWithSourceID:bundleID:
distantPast
distantFuture
predicateForEventsWithEndInDateRangeFrom:to:
andPredicateWithSubpredicates:
setPredicate:
knowledgeStoreWithDirectReadOnlyAccess
queryForConversationIdentifier:startDate:endDate:
setLimit:
setOffset:
executeQuery:error:
countByEnumeratingWithState:objects:count:
interaction
intent
content
containsString:
endDate
count
initWithBuffer:domainType:characterObservations:blankIndex:pruningPolicy:
shape
objectAtIndexedSubscript:
integerValue
strides
dataType
initWithMultiArray:domainType:characterObservations:blankIndex:pruningPolicy:
_cachedTimesample
set_cachedTimesample:
_valueForObservationIndex:timestep:
_logProbabilityForRawProbability:
dataPointer
characterIndexForObservationIndex:timestep:
blankIndexForTimestep:
probabilityForObservationIndex:timestep:
logProbabilityForObservationIndex:timestep:
_sortNonBlankCandidatesForTimestep:
_enumerateNonBlankCandidatesInTimestep:block:
_candidateSymbolAtIndex:forTimestep:outputScore:
topCandidateForTimestep:outputLogProbability:outputIndex:
logProbabilityForBlankAtTimestep:
observationCount
appendFormat:
initWithBuffer:indexBuffer:domainType:characterObservations:blankIndex:pruningPolicy:
initWithMultiArray:characterObservations:blankIndex:pruningPolicy:
initWithMultiArray:indexArray:domainType:characterObservations:blankIndex:pruningPolicy:
timestepCount
probabilityForBlankAtTimestep:
enumerateNonBlankCandidatesInTimestep:block:
topCandidateForTimestep:outputLogProbability:
topCandidateForTimestep:outputProbability:outputIndex:
debugDescription
characterObservations
setCharacterObservations:
blankIndex
setBlankIndex:
domainType
_espressoBuffer
set_espressoBuffer:
_indexBuffer
set_indexBuffer:
_doubleScoreMatrix
set_doubleScoreMatrix:
_multiArray
set_multiArray:
_indexArray
set_indexArray:
_timestepCount
set_timestepCount:
_observationCount
set_observationCount:
_timeStride
set_timeStride:
_observationStride
set_observationStride:
_type
set_type:
_pruningPolicy
set_pruningPolicy:
_cachedPriorityQueueTimestep
set_cachedPriorityQueueTimestep:
_isDoubleDataType
set_isDoubleDataType:
_usingIndexes
set_usingIndexes:
_cachedBlankIndexTimestep
_cachedBlankIndex
__isDoubleDataType
__usingIndexes
_characterObservations
_blankIndex
_domainType
__doubleScoreMatrix
__multiArray
__indexArray
__timestepCount
__observationCount
__timeStride
__observationStride
__type
__cachedPriorityQueueTimestep
__cachedTimesample
__cachedBlankIndexTimestep
__cachedBlankIndex
__pruningPolicy
__espressoBuffer
__indexBuffer
T{?=^v^v[4Q][4Q]QQQQQQQQQQi},N,V__espressoBuffer
T{?=^v^v[4Q][4Q]QQQQQQQQQQi},N,V__indexBuffer
T^d,N,V__doubleScoreMatrix
T@"MLMultiArray",&,N,V__multiArray
T@"MLMultiArray",&,N,V__indexArray
Tq,N,V__timestepCount
Tq,N,V__observationCount
Tq,N,V__timeStride
Tq,N,V__observationStride
Tq,N,V__type
T{CVNLPTextDecodingPruningPolicy=qBfI},N,V__pruningPolicy
Tq,V__cachedPriorityQueueTimestep
T^v,V__cachedTimesample
TB,N,V__isDoubleDataType
TB,N,V__usingIndexes
Tq,R,N,V__cachedBlankIndexTimestep
Tq,R,N,V__cachedBlankIndex
T@"NSOrderedSet",&,N,V_characterObservations
Tq,N,V_blankIndex
Tq,R,N,V_domainType
initWithSortedCursors:
enumerateLexiconCursorsSortedByPriorityWithBlock:
.cxx_construct
_sortedCursors
computeCaptionForImageImpl:outputs:
dataWithBytesNoCopy:length:freeWhenDone:
computeCaptionForPixelBufferImpl:outputs:
computeCaptionForVideoPixelBufferImpl:outputs:
computeCaptionForVideoPixelBuffer:outputs:
encoderInputNames
raise:format:
isEqualToString:
characterSetWithCharactersInString:
initWithOptions:runtimeParameters:
postProcessCaptions:visionObservations:
trimSet
runtimeParameters
_trimSet
_runtimeParameters
T@"NSCharacterSet",R,V_trimSet
T@"CVNLPCaptionRuntimeParameters",R,W,V_runtimeParameters
runTimeParams
_runTimeParams
T@"CVNLPCaptionRuntimeParameters",R,N,V_runTimeParams
createBundle
languageCode
defaultWhitespaceCommitActionBehavior
defaultCommitActionBehaviorForLocale:
initWithCommitActionBehavior:
commitActionBlock
setCommitActionBlock:
_commitActionBlock
T@?,N,V_commitActionBlock
_initWithCommitActionBehavior:scoringFunction:beamWidth:pathCount:shouldOptimizeAlignment:
initWithCommitActionBehavior:scoringFunction:beamWidth:pathCount:shouldOptimizeAlignment:
initWithCommitActionBehavior:scoringFunction:beamWidth:pathCount:
initWithCommitActionBehavior:beamWidth:pathCount:shouldOptimizeAlignment:
beamWidth
setBeamWidth:
pathCount
setPathCount:
shouldOptimizeAlignment
setShouldOptimizeAlignment:
scoringFunction
_shouldOptimizeAlignment
_beamWidth
_pathCount
_scoringFunction
TQ,N,V_beamWidth
TQ,N,V_pathCount
TB,N,V_shouldOptimizeAlignment
T@?,R,N,V_scoringFunction
fileURLWithPath:
dataWithContentsOfFile:
JSONObjectWithData:options:error:
initWithContentsOfURL:error:
stringWithUTF8String:
length
rangeOfFirstMatchInString:options:range:
numberWithInteger:
contentsOfDirectoryAtPath:error:
predicateWithFormat:
filteredArrayUsingPredicate:
firstObject
_extractThresholdForNSFWExplicit:
nsfwExplicitThreshold
computeOutputForImage:
_processNetworkOutput:
_computeOutputForPixelBuffer:
acceptedOutputIndices
allKeys
nsfwExplicitIndex
leafProbabilities
_acceptedOutputIndices
_nsfwExplicitThreshold
_nsfwExplicitIndex
T@"NSDictionary",R,V_acceptedOutputIndices
T@"NSNumber",R,V_nsfwExplicitThreshold
TQ,R,V_nsfwExplicitIndex
initWithLanguageResourceBundle:
languageResourceBundle
_languageResourceBundle
T@"CVNLPLanguageResourceBundle",R,N,V_languageResourceBundle
captionModelMinimumConfidence
setCaptionModelMinimumConfidence:
captionModelLengthNormalizationFactor
setCaptionModelLengthNormalizationFactor:
excludeGenderStrategy
setExcludeGenderStrategy:
classifierRevisions
setClassifierRevisions:
sensitiveImageParameters
setSensitiveImageParameters:
replacements
setReplacements:
genderedTokens
setGenderedTokens:
blackListRules
setBlackListRules:
excludeGenderReplacements
setExcludeGenderReplacements:
excludeGenderTriggers
setExcludeGenderTriggers:
genderOption
setGenderOption:
_excludeGenderStrategy
_genderOption
_captionModelMinimumConfidence
_captionModelLengthNormalizationFactor
_classifierRevisions
_sensitiveImageParameters
_replacements
_genderedTokens
_blackListRules
_excludeGenderReplacements
_excludeGenderTriggers
Td,N,V_captionModelMinimumConfidence
Td,N,V_captionModelLengthNormalizationFactor
Ti,N,V_excludeGenderStrategy
T@"NSDictionary",&,N,V_classifierRevisions
T@"NSDictionary",&,N,V_sensitiveImageParameters
T@"NSArray",&,N,V_replacements
T@"NSArray",&,N,V_genderedTokens
T@"NSArray",&,N,V_blackListRules
T@"NSArray",&,N,V_excludeGenderReplacements
T@"NSArray",&,N,V_excludeGenderTriggers
Ti,N,V_genderOption
appendString:
initWithTokens:score:activationScore:
tokens
setScore:
activationScore
setActivationScore:
_tokens
_activationScore
T@"NSArray",R,N,V_tokens
Td,V_score
Td,V_activationScore
candidates
initWithCandidates:
_candidates
T@"NSArray",R,N,V_candidates
_initWithLanguageModel:locale:decodingWeight:lowerBoundLogProbability:type:
initWithLanguageModel:locale:
localeIdentifier
numberWithInt:
_decodingLanguageModelForLocale:modelType:decodingWeight:lowerBoundLogProbability:type:
requiredContextLengthForStringLength:
enumerateSubstringsInRange:options:usingBlock:
stringByAppendingString:
objectAtIndex:
rangeValue
maximumLengthOfBytesUsingEncoding:
getBytes:maxLength:usedLength:encoding:options:range:remainingRange:
initWithBytes:length:encoding:
whitespaceAndNewlineCharacterSet
stringByTrimmingCharactersInSet:
_normalizedLMTokenIDForWord:withTokenID:sourceLanguageModel:outScore:
rangeOfString:options:range:
valueWithRange:
languageModel
lowercaseString
decodingLMLanguageModelForLocale:modelType:decodingWeight:
decodingCVNLPLanguageModelForLocale:modelType:decodingWeight:
initWithLMLanguageModel:locale:decodingWeight:
initWithLMLanguageModel:locale:decodingWeight:lowerBoundLogProbability:
initWithCVNLPLanguageModel:locale:decodingWeight:
initWithCVNLPLanguageModel:locale:decodingWeight:lowerBoundLogProbability:
initWithLanguageModel:
lmSPIType
characterTokenIDsForString:
wordTokenIDsForString:outTokenRanges:
locale
_lmSPIType
_tokenizer
_locale
_languageModel
T@"NSLocale",R,N,V_locale
T^v,R,N,V_languageModel
whitespaceCharacterSet
rangeOfCharacterFromSet:
lowercaseLetterCharacterSet
uppercaseLetterCharacterSet
lengthOfBytesUsingEncoding:
characterAtIndex:
punctuationCharacterSet
dataUsingEncoding:
initWithResource:andTokenType:
enumerateTokenIDsForText:withBlock:
bosTokenID
eosTokenID
unkTokenID
_vocabTokenizer
_bosTokenID
_eosTokenID
_unkTokenID
TI,R,V_bosTokenID
TI,R,V_eosTokenID
TI,R,V_unkTokenID
name
initWithName:
dict
maxpeak
peakdelta
recentpeak
current
cpuTime
cpuInstructions
timeInterval
_name
T@"NSString",R,N,V_name
computePerf
processInfo
processIdentifier
timeIntervalSinceDate:
_computePerf
_results
TB,R,N,V_computePerf
T@"NSMutableDictionary",R,N,V_results
initWithFormat:arguments:
computeCaptionForImageWithInputs:genderOption:
postProcessCaptions:genderOption:error:
code
modelLogProbability
characterCount
substringWithRange:
_currentTokenStringLength
lastTokenBoundaryLogProbability
updateLastTokenWithMaxActivation:totalLogProbability:tokenBoundaryLogProbability:
commitTokenAtTimestep:currentSymbolLogProbability:commitAction:string:stemmingFromPath:
arrayWithCapacity:
scoreForTokenIndex:
arrayWithArray:
normalizedTotalLogProbability
blankLogProbability
nonBlankLogProbability
wordLanguageModelLogProbability
historyLexiconLogProbability
activeWordLexiconLogProbability
characterLanguageModelLogProbability
setLastTokenBoundaryLogProbability:
initWithLanguageResourceBundle:scoringFunction:initialCharacterLMState:characterTokenIDs:wordTokenIDs:optimizingAlignment:hasContext:
setString:
setBlankLogProbability:
setCharacterLanguageModelLogProbability:
setHistoryLexiconLogProbability:
setActiveWordLexiconLogProbability:
setWordLanguageModelLogProbability:
setCharacterCount:
setPseudoSpaceCount:
cursors
setCursors:
_applyWordLanguageModelProbabilityToPath:stemmedFromPath:isCommittingToken:
_updateCharacterLanguageModelLogProbabilityForString:stemmingFromPath:normalizedCodepoint:
_updateLexiconLogProbabilityForString:stemmingFromPath:
_getQueue
_wordLanguageModelLogProbabilityForString:originalWordRanges:originalWordIDs:wordRanges:wordIDs:
letterCharacterSet
mutableCopy
formUnionWithCharacterSet:
invertedSet
rangeOfCharacterFromSet:options:range:
setCharacterLMState:
pseudoSpaceCount
tokenCount
lexiconScore
normalizedActivationLogProbability
tokensWithTimestep:isFinalTimestep:
compare:
merge:logProbCumulator:
childPathWithBlankLogProb:
pathByExtendingWithString:extendedPathString:blankLogProb:nonBlankLogProb:timestep:commitAction:symbolLogProb:
setNonBlankLogProbability:
languageResourceLogProbability
optimizingAlignment
characterLMState
latestExpandedSymbol
_tokenString
_histWordTokenIDs
_beginningCurrentWord
_cumulativeTokenLogProbabilities
_tokenBoundaryLogProbabilities
_tokenStringSegmentationPositions
_tokenMaxActivations
_tokenCommitCharacterLengths
_hasContext
_normalizedTotalLogProbability
_optimizingAlignment
_blankLogProbability
_nonBlankLogProbability
_historyLexiconLogProbability
_activeWordLexiconLogProbability
_languageResourceLogProbability
_cursors
_characterLMState
_latestExpandedSymbol
Td,V_blankLogProbability
Td,V_nonBlankLogProbability
Td,V_historyLexiconLogProbability
Td,V_activeWordLexiconLogProbability
Td,R
Td,R,V_languageResourceLogProbability
TB,R,V_optimizingAlignment
T@"CVNLPLexiconCursors",&,N,V_cursors
T^{CVNLPLanguageModelWithState=},N,V_characterLMState
T@"CVNLPLanguageResourceBundle",R,&,N,V_languageResourceBundle
T@"NSString",R,N,V_latestExpandedSymbol
defaultPathScoringFunctionForLanguageResourceBundle:
defaultPathScoringFunction
initWithCharacterLanguageModelLogProbability:wordLanguageModelLogProbability:lexiconScore:string:
_modelLogProbability
_characterLanguageModelLogProbability
_wordLanguageModelLogProbability
_lexiconScore
_characterCount
_pseudoSpaceCount
_tokenCount
Td,R,N,V_modelLogProbability
Td,R,N,V_characterLanguageModelLogProbability
Td,R,N,V_wordLanguageModelLogProbability
Td,R,N,V_lexiconScore
Tq,R,N,V_characterCount
Tq,R,N,V_pseudoSpaceCount
Tq,R,N,V_tokenCount
T@"NSString",R,N,V_string
_copy_data_from_blob:toPtr:
_copy_data_to_blob:to:
_copy_data_to_blob:toBuffer:
_copy_data_to_blob_repeated:to:
T@"NSDictionary",R,N,V_options
_loadNetwork:modelIndex:
objectForKey:
decoderQueue
_runBlockWithCopyOutputBlock:
blockInput
metricString
decoderPlan
nextBlock
blockOutput
runBlockWithCopyInput:copyOutputBlock:
initWithOptions:modelIndex:runTimeParams:
buildNetworkForSequenceLength:imageFeatures:
copyInputState:
copyOutputState:
runBlockWithCopyInputBlock:copyOutputBlock:
modelIndex
setModelIndex:
setDecoderPlan:
decoderCtx
setDecoderCtx:
decoderNet
setDecoderNet:
attFeatsPlaceholderBlob
setAttFeatsPlaceholderBlob:
scaleInput
setScaleInput:
positionInput
setPositionInput:
maskInput
setMaskInput:
setBlockInput:
setBlockOutput:
stateOutputEspressoBuffers
setStateOutputEspressoBuffers:
stateInputEspressoBuffers
setStateInputEspressoBuffers:
stateInputEspressoBuffersShape
setStateInputEspressoBuffersShape:
setDecoderQueue:
setNextBlock:
setMetricString:
metricCopyString
setMetricCopyString:
decoderInputNames
setDecoderInputNames:
_modelIndex
_decoderPlan
_decoderCtx
_decoderQueue
_nextBlock
_metricString
_metricCopyString
_decoderNet
_stateOutputEspressoBuffers
_stateInputEspressoBuffers
_stateInputEspressoBuffersShape
_decoderInputNames
_attFeatsPlaceholderBlob
_scaleInput
_positionInput
_maskInput
_blockInput
_blockOutput
TQ,N,V_modelIndex
T^v,N,V_decoderPlan
T^v,N,V_decoderCtx
T{?=^vi},N,V_decoderNet
T{?=^v^v[4Q][4Q]QQQQQQQQQQi},N,V_attFeatsPlaceholderBlob
T{?=^v^v[4Q][4Q]QQQQQQQQQQi},N,V_scaleInput
T{?=^v^v[4Q][4Q]QQQQQQQQQQi},N,V_positionInput
T{?=^v^v[4Q][4Q]QQQQQQQQQQi},N,V_maskInput
T{?=^v^v[4Q][4Q]QQQQQQQQQQi},N,V_blockInput
T{?=^v^v[4Q][4Q]QQQQQQQQQQi},N,V_blockOutput
T{map<std::string, std::vector<float>, std::less<std::string>, std::allocator<std::pair<const std::string, std::vector<float>>>>={__tree<std::__value_type<std::string, std::vector<float>>, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<float>>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::vector<float>>>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::vector<float>>, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<float>>, std::less<std::string>, true>>=Q}}},N,V_stateOutputEspressoBuffers
T{map<std::string, std::vector<float>, std::less<std::string>, std::allocator<std::pair<const std::string, std::vector<float>>>>={__tree<std::__value_type<std::string, std::vector<float>>, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<float>>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::vector<float>>>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::vector<float>>, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<float>>, std::less<std::string>, true>>=Q}}},N,V_stateInputEspressoBuffers
T{map<std::string, std::vector<unsigned long>, std::less<std::string>, std::allocator<std::pair<const std::string, std::vector<unsigned long>>>>={__tree<std::__value_type<std::string, std::vector<unsigned long>>, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<unsigned long>>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::vector<unsigned long>>>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::vector<unsigned long>>, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<unsigned long>>, std::less<std::string>, true>>=Q}}},N,V_stateInputEspressoBuffersShape
T@"NSObject<OS_dispatch_queue>",&,N,V_decoderQueue
T@"CVNLPCaptionDecoderBlock",&,N,V_nextBlock
T@"NSString",&,N,V_metricString
T@"NSString",&,N,V_metricCopyString
T{vector<std::string, std::allocator<std::string>>=^v^v{__compressed_pair<std::string *, std::allocator<std::string>>=^v}},N,V_decoderInputNames
enumeratePathsWithBlock:
dictionaryWithDictionary:
enumerateKeysAndObjectsUsingBlock:
keysSortedByValueUsingSelector:
addPath:
removeObjectForKey:
pathForString:
paths
sortedKeys
kBest:discarded:k:shouldUpdateLMState:
mergePathsWithTrailingWhitespaces
mutablePaths
setMutablePaths:
_mutablePaths
T@"NSMutableDictionary",&,N,V_mutablePaths
userInfo
stringWithSpaceAtEnds
startDate
result
initWithConversationIdentifier:startDate:endDate:result:
_startDate
_endDate
_result
T@"NSDate",R,C,N,V_startDate
T@"NSDate",R,C,N,V_endDate
Tq,R,N,V_result
predictedLabelHypothesesForString:maximumCount:
initWithModel:className:threshold:
detectSensitivityForString:
_model
_className
_threshold
dataWithContentsOfURL:
modelWithContentsOfURL:error:
_classifyString:
processText:inConversationWithIdentifier:startDate:endDate:error:
classifyString:
dateByAddingTimeInterval:
lastObject
arrayWithObject:
setObject:forKey:
_classificationForTextItems:conversationIdentifier:
_classificationsForTextItems:previousClassifications:
_models
initWithDictionary:
triggerTokens
_triggerTokens
T@"NSArray",R,V_triggerTokens
pathForResource:ofType:
decodingResultWithConfiguration:withContext:
history
inactiveSubstring
rangeOfComposedCharacterSequenceAtIndex:
subarrayWithRange:
greedyDecodingResultWithConfiguration:
initWithString:
removeLastObject
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
superclass
TQ,R
T#,R
T@"NSString",R,C
decodingResultForKBestPaths:withBeamWidth:
decodingResultForKBestPaths:withBeamWidth:context:
greedyDecodingResult
decodingResultForKBestPaths:withBeamWidth:context:optimizeAlignment:
activationMatrix
setActivationMatrix:
_activationMatrix
T@"CVNLPActivationMatrix",&,N,V_activationMatrix
initWithKey:value:prob:genderOption:
replacementKey
replacementValue
replacementProb
_replacementKey
_replacementValue
_replacementProb
T@"NSString",R,N,V_replacementKey
T@"NSString",R,N,V_replacementValue
Td,R,N,V_replacementProb
T@"NSNumber",R,N,V_genderOption
_loadVocabFile:
_loadNetwork:options:runTimeParams:
_createBeamSearch:runTimeParams:
decoderBlocks
numberWithUnsignedInteger:
computeCaptionForImageWithInputsImpl:genderOption:
maxCaptionLen
startID
decoderBatchSize
vocabSize
endID
vocab
componentsJoinedByString:
numberWithBool:
setStartID:
setEndID:
setDecoderBatchSize:
setMaxCaptionLen:
setVocabSize:
outputVocabSize
setOutputVocabSize:
setVocab:
setDecoderBlocks:
beamSize
setBeamSize:
beamSearch
setBeamSearch:
filterBeamSearch
setFilterBeamSearch:
_startID
_endID
_decoderBatchSize
_maxCaptionLen
_vocabSize
_outputVocabSize
_vocab
_decoderBlocks
_beamSize
_beamSearch
_filterBeamSearch
TQ,N,V_startID
TQ,N,V_endID
TQ,N,V_decoderBatchSize
TQ,N,V_maxCaptionLen
TQ,N,V_vocabSize
TQ,N,V_outputVocabSize
T@"NSDictionary",&,N,V_vocab
T@"NSArray",&,N,V_decoderBlocks
TQ,N,V_beamSize
T^{CVNLPBeamSearch=},N,V_beamSearch
T^{CVNLPBeamSearch=},N,V_filterBeamSearch
initWithLexicon:priority:
_createLexiconForLocale:
initWithLexicon:
decodingLexiconForLocale:
decodingLexiconForLocale:priority:
lexicon
priority
_rootCursor
_lexicon
_priority
__rootCursor
T^{_LXCursor=},R,N,V__rootCursor
Tr^{_LXLexicon=},R,N,V_lexicon
TQ,R,N,V_priority
initWithLexicons:decodingWeight:lowerBoundLogProbability:
allObjects
sortedArrayUsingComparator:
setWithArray:
filteredSetUsingPredicate:
initWithLexicons:decodingWeight:
activeSubstring
enumerateLexiconsSortedByPriorityWithBlock:
initWithLexicons:
lexiconsForPriority:
_sortedLexicons
packBeamID:tokenID:lstmAttnState:lstmLangState:softmax:
extractBeamID:tokenID:lstmAttnState:lstmLangState:fromFollowup:
meanFeatsPlaceholderBlob
pAttFeatsPlaceholderBlob
lstmAttStateFeedBlob
lstmLangStateFeedBlob
inWordIDBlob
wordIDBlob
langProbBlob
newAttStateBlob
newLangStateBlob
initWithHistory:activeRange:
initWithHistory:
activeRange
_history
_activeRange
T@"NSString",R,N,V_history
T{_NSRange=QQ},R,N,V_activeRange
@16@0:8
@24@0:8@16
q24@0:8^{CGImage=}16
@24@0:8^{CGImage=}16
q24@0:8^{__CVBuffer=}16
@24@0:8^{__CVBuffer=}16
@48@0:8@16@24@32^@40
v56@0:8@16@24@32@?40@?48
@48@0:8^{__CVBuffer=}16@24@32^@40
@64@0:8^{__CVBuffer=}16@24@32@40@48^@56
v16@0:8
@"NSObject<OS_dispatch_queue>"
@"CVNLPCommSafetyImageAnalyzer"
@"CVNLPCommSafetyTextAnalyzer"
@"NSDictionary"
@"CVNLPPerformance"
@64@0:8@16@24@32{_NSRange=QQ}40@56
@56@0:8@16@24{_NSRange=QQ}32@48
@52@0:8@16@24{_NSRange=QQ}32B48
B16@0:8
{_NSRange=QQ}16@0:8
@"NSString"
@"NSNumber"
{_NSRange="location"Q"length"Q}
@56@0:8@16d24@32@40@48
d16@0:8
@"NSArray"
@32@0:8@16@24
@40@0:8@16@24@32
@"CVNLPDecodingLexicons"
@"CVNLPDecodingLanguageModel"
v32@0:8^{vImage_Buffer=^vQQQ}16^@24
v48@0:8^{vImage_Buffer=^vQQQ}16^@24^@32^@40
{?="plan"^v"network_index"i}
{?="data"^v"reserved"^v"dim"[4Q]"stride"[4Q]"width"Q"height"Q"channels"Q"batch_number"Q"sequence_length"Q"stride_width"Q"stride_height"Q"stride_channels"Q"stride_batch_number"Q"stride_sequence_length"Q"storage_type"i}
v32@0:8^{__CVBuffer=}16^@24
Q184@0:8{?=^v^v[4Q][4Q]QQQQQQQQQQi}16
v188@0:8{?=^v^v[4Q][4Q]QQQQQQQQQQi}16f184
[4Q]
@24@0:8^{_NSZone=}16
v24@0:8@16
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
@48@0:8@16@24q32@40
Q16@0:8
B24@0:8@16
q16@0:8
@"NSDate"
v48@0:8@16@24@32@?40
@232@0:8{?=^v^v[4Q][4Q]QQQQQQQQQQi}16q184@192q200{CVNLPTextDecodingPruningPolicy=qBfI}208
@400@0:8{?=^v^v[4Q][4Q]QQQQQQQQQQi}16{?=^v^v[4Q][4Q]QQQQQQQQQQi}184q352@360q368{CVNLPTextDecodingPruningPolicy=qBfI}376
@72@0:8@16q24@32q40{CVNLPTextDecodingPruningPolicy=qBfI}48
@64@0:8@16@24q32{CVNLPTextDecodingPruningPolicy=qBfI}40
@80@0:8@16@24q32@40q48{CVNLPTextDecodingPruningPolicy=qBfI}56
d32@0:8q16q24
d24@0:8d16
q24@0:8q16
d24@0:8q16
q32@0:8q16q24
v32@0:8q16@?24
@40@0:8q16q24^d32
v24@0:8q16
@32@0:8q16^d24
@40@0:8q16^d24^q32
{?=^v^v[4Q][4Q]QQQQQQQQQQi}16@0:8
v184@0:8{?=^v^v[4Q][4Q]QQQQQQQQQQi}16
^d16@0:8
v24@0:8^d16
{CVNLPTextDecodingPruningPolicy=qBfI}16@0:8
v40@0:8{CVNLPTextDecodingPruningPolicy=qBfI}16
^v16@0:8
v24@0:8^v16
v20@0:8B16
@"NSOrderedSet"
@"MLMultiArray"
{CVNLPTextDecodingPruningPolicy="strategy"q"shouldSort"B"threshold"f"maxNumberOfCandidates"I}
@24@0:8^v16
v24@0:8@?16
{vector<const _LXCursor *, std::allocator<const _LXCursor *>>="__begin_"^^{_LXCursor}"__end_"^^{_LXCursor}"__end_cap_"{__compressed_pair<const _LXCursor **, std::allocator<const _LXCursor *>>="__value_"^^{_LXCursor}}}
v32@0:8^v16^@24
{vector<std::string, std::allocator<std::string>>="__begin_"^v"__end_"^v"__end_cap_"{__compressed_pair<std::string *, std::allocator<std::string>>="__value_"^v}}
@"NSCharacterSet"
@"CVNLPCaptionRuntimeParameters"
@?24@0:8@16
@?16@0:8
@24@0:8@?16
@52@0:8@?16@?24Q32Q40B48
@48@0:8@?16@?24Q32Q40
@44@0:8@?16Q24Q32B40
v24@0:8Q16
@24@0:8^{vImage_Buffer=^vQQQ}16
@"CVNLPLanguageResourceBundle"
v24@0:8d16
i16@0:8
v20@0:8i16
@40@0:8@16d24d32
@48@0:8@16i24@28@36i44
@36@0:8@16i24@28
I44@0:8@16I24@28^d36
@52@0:8^v16@24@32@40i48
@40@0:8^v16@24@32
@48@0:8^v16@24@32@40
@40@0:8^{CVNLPLanguageModel=}16@24@32
@48@0:8^{CVNLPLanguageModel=}16@24@32@40
@32@0:8^v16@24
{vector<unsigned int, std::allocator<unsigned int>>=^I^I{__compressed_pair<unsigned int *, std::allocator<unsigned int>>=^I}}24@0:8@16
{vector<unsigned int, std::allocator<unsigned int>>=^I^I{__compressed_pair<unsigned int *, std::allocator<unsigned int>>=^I}}32@0:8@16^@24
@"NSLocale"
@28@0:8@16i24
v32@0:8@16@?24
I16@0:8
{unique_ptr<cvnlp::AbstractVocabulary, std::default_delete<cvnlp::AbstractVocabulary>>="__ptr_"{__compressed_pair<cvnlp::AbstractVocabulary *, std::default_delete<cvnlp::AbstractVocabulary>>="__value_"^{AbstractVocabulary}}}
@"NSMutableDictionary"
v36@0:8@16@24B32
@96@0:8@16@?24^{CVNLPLanguageModelWithState=}32{vector<unsigned int, std::allocator<unsigned int>>=^I^I{__compressed_pair<unsigned int *, std::allocator<unsigned int>>=^I}}40{vector<unsigned int, std::allocator<unsigned int>>=^I^I{__compressed_pair<unsigned int *, std::allocator<unsigned int>>=^I}}64B88B92
v24@0:8^{CVNLPLanguageModelWithState=}16
v56@0:8q16d24q32@40@48
@28@0:8q16B24
q24@0:8@16
v40@0:8q16d24d32
@24@0:8d16
@72@0:8@16@24d32d40q48q56d64
v36@0:8@16@24I32
v32@0:8@16@24
f88@0:8@16@24{vector<unsigned int, std::allocator<unsigned int>>=^I^I{__compressed_pair<unsigned int *, std::allocator<unsigned int>>=^I}}32@56{vector<unsigned int, std::allocator<unsigned int>>=^I^I{__compressed_pair<unsigned int *, std::allocator<unsigned int>>=^I}}64
^{CVNLPLanguageModelWithState=}16@0:8
{vector<unsigned int, std::allocator<unsigned int>>="__begin_"^I"__end_"^I"__end_cap_"{__compressed_pair<unsigned int *, std::allocator<unsigned int>>="__value_"^I}}
{vector<double, std::allocator<double>>="__begin_"^d"__end_"^d"__end_cap_"{__compressed_pair<double *, std::allocator<double>>="__value_"^d}}
{vector<unsigned long, std::allocator<unsigned long>>="__begin_"^Q"__end_"^Q"__end_cap_"{__compressed_pair<unsigned long *, std::allocator<unsigned long>>="__value_"^Q}}
@"CVNLPLexiconCursors"
^{CVNLPLanguageModelWithState=}
@48@0:8d16d24d32@40
v192@0:8{?=^v^v[4Q][4Q]QQQQQQQQQQi}16^v184
v192@0:8{?=^v^v[4Q][4Q]QQQQQQQQQQi}16^f184
v192@0:8^f16{?=^v^v[4Q][4Q]QQQQQQQQQQi}24
v192@0:8@16{?=^v^v[4Q][4Q]QQQQQQQQQQi}24
@40@0:8@16Q24@32
B32@0:8@16Q24
v32@0:8Q16@24
v32@0:8@?16@?24
v32@0:8^f16@?24
{?=^vi}16@0:8
v32@0:8{?=^vi}16
{map<std::string, std::vector<float>, std::less<std::string>, std::allocator<std::pair<const std::string, std::vector<float>>>>={__tree<std::__value_type<std::string, std::vector<float>>, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<float>>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::vector<float>>>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::vector<float>>, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<float>>, std::less<std::string>, true>>=Q}}}16@0:8
v40@0:8{map<std::string, std::vector<float>, std::less<std::string>, std::allocator<std::pair<const std::string, std::vector<float>>>>={__tree<std::__value_type<std::string, std::vector<float>>, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<float>>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::vector<float>>>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::vector<float>>, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<float>>, std::less<std::string>, true>>=Q}}}16
{map<std::string, std::vector<unsigned long>, std::less<std::string>, std::allocator<std::pair<const std::string, std::vector<unsigned long>>>>={__tree<std::__value_type<std::string, std::vector<unsigned long>>, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<unsigned long>>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::vector<unsigned long>>>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::vector<unsigned long>>, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<unsigned long>>, std::less<std::string>, true>>=Q}}}16@0:8
v40@0:8{map<std::string, std::vector<unsigned long>, std::less<std::string>, std::allocator<std::pair<const std::string, std::vector<unsigned long>>>>={__tree<std::__value_type<std::string, std::vector<unsigned long>>, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<unsigned long>>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::vector<unsigned long>>>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::vector<unsigned long>>, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<unsigned long>>, std::less<std::string>, true>>=Q}}}16
{vector<std::string, std::allocator<std::string>>=^v^v{__compressed_pair<std::string *, std::allocator<std::string>>=^v}}16@0:8
v40@0:8{vector<std::string, std::allocator<std::string>>=^v^v{__compressed_pair<std::string *, std::allocator<std::string>>=^v}}16
@"CVNLPCaptionDecoderBlock"
{map<std::string, std::vector<float>, std::less<std::string>, std::allocator<std::pair<const std::string, std::vector<float>>>>="__tree_"{__tree<std::__value_type<std::string, std::vector<float>>, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<float>>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::vector<float>>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::vector<float>>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<float>>, std::less<std::string>, true>>="__value_"Q}}}
{map<std::string, std::vector<unsigned long>, std::less<std::string>, std::allocator<std::pair<const std::string, std::vector<unsigned long>>>>="__tree_"{__tree<std::__value_type<std::string, std::vector<unsigned long>>, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<unsigned long>>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::vector<unsigned long>>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::vector<unsigned long>>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::vector<unsigned long>>, std::less<std::string>, true>>="__value_"Q}}}
v44@0:8^@16^@24Q32B40
@48@0:8@16@24@32q40
@40@0:8@16@24d32
@"NLModel"
@56@0:8@16@24@32@40^@48
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
@32@0:8Q16Q24
@40@0:8Q16Q24@32
@"CVNLPTextDecodingResult"32@0:8Q16Q24
@"CVNLPTextDecodingResult"40@0:8Q16Q24@"CVNLPTextDecodingContext"32
@"CVNLPTextDecodingResult"32@0:8@"CVNLPTextDecodingBeamSearchConfiguration"16@"CVNLPTextDecodingContext"24
@"CVNLPTextDecodingResult"16@0:8
@"CVNLPTextDecodingResult"24@0:8@"CVNLPTextDecodingConfiguration"16
@44@0:8Q16Q24@32B40
@"CVNLPActivationMatrix"
@48@0:8@16@24d32@40
v40@0:8@16@24@32
^{CVNLPBeamSearch=}16@0:8
v24@0:8^{CVNLPBeamSearch=}16
^{CVNLPBeamSearch=}
r^{_LXLexicon=}24@0:8@16
@32@0:8@16Q24
@32@0:8^{_LXLexicon=}16Q24
@24@0:8^{_LXLexicon=}16
r^{_LXLexicon=}16@0:8
^{_LXCursor=}16@0:8
r^{_LXLexicon=}
^{_LXCursor=}
@24@0:8Q16
@56@0:8@16@24^{?=^v^v[4Q][4Q]QQQQQQQQQQi}32^{?=^v^v[4Q][4Q]QQQQQQQQQQi}40^{?=^v^v[4Q][4Q]QQQQQQQQQQi}48
v56@0:8^@16^@24^{?=^v^v[4Q][4Q]QQQQQQQQQQi}32^{?=^v^v[4Q][4Q]QQQQQQQQQQi}40@48
@40@0:8@16{_NSRange=QQ}24
