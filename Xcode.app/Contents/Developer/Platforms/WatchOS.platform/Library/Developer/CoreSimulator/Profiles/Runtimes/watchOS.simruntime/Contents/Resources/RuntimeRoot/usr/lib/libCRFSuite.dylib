NSt3__110__function6__funcIPFvPvPN3nlp15_TrieCompletionEPbENS_9allocatorIS8_EES7_EE
NSt3__110__function6__baseIFvPvPN3nlp15_TrieCompletionEPbEEE
PFvPvPN3nlp15_TrieCompletionEPbE
FvPvPN3nlp15_TrieCompletionEPbE
?333333
6Kernel
7QMatrix
6Solver
9Solver_NU
5SVC_Q
11ONE_CLASS_Q
5SVR_Q
NSt3__117bad_function_callE
NSt3__110__function6__funcIPFvPvPN3nlp15_TrieCompletionEbPbENS_9allocatorIS8_EES7_EE
NSt3__110__function6__baseIFvPvPN3nlp15_TrieCompletionEbPbEEE
PFvPvPN3nlp15_TrieCompletionEbPbE
FvPvPN3nlp15_TrieCompletionEbPbE
NSt3__110__function6__baseIFvPvPKhjjfPbEEE
NSt3__110__function6__funcIZN3nlp15BurstTrieSearchEPKNS2_10_BurstTrieEPKhjPvNS_8functionIFvS8_PNS2_15_TrieCompletionEPbEEEiE3$_0NS_9allocatorISF_EEFvS8_S7_jjfSC_EEE
ZN3nlp15BurstTrieSearchEPKNS_10_BurstTrieEPKhjPvNSt3__18functionIFvS5_PNS_15_TrieCompletionEPbEEEiE3$_0
feature.minfreq
The minimum frequency of features.
feature.possible_states
Force to generate possible state features.
feature.possible_transitions
Force to generate possible transition features.
Feature generation
type: CRF1d
feature.minfreq: %f
feature.possible_states: %d
feature.possible_transitions: %d
Number of features: %d
Seconds required: %.3f
Storing the model
Number of active features: %d (%d)
Number of active attributes: %d (%d)
Number of active labels: %d (%d)
Writing labels
Writing attributes
Writing feature references for transitions
Writing feature references for attributes
Warning: attributes will not be stored, because "crfsuite_training_do_not_store_attributes" is specified.
Error: missing attribute dictionary.
Error: missing label dictionary.
To use compact or quantized format, you must store attributes and labels out side of crfsuite model.
Writing label features
crf1de_write_external_attribute_model
/BuildRoot/Library/Caches/com.apple.xbs/Sources/CRFSuite_Sim/CRFSuite-48/crfsuite/lib/crf/src/crf1d_encode.c
feature->type == FT_TRANS
Writing attribute feature counts and offsets.
Writing attribute features.
Number of attributes: %d
Number of labels: %d
Number of active label features: %d
Number of active attribute features: %d
%3d  obj(err) = %f (%6.4f)
  heldout_logl(err) = %f (%6.4f)
operator+
/BuildRoot/Library/Caches/com.apple.xbs/Sources/CRFSuite_Sim/CRFSuite-48/maxent/MaxEnt/mathvec.h
a.Size() == b.Size()
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
operator-
lCRF
crf1dm_initialize_header
/BuildRoot/Library/Caches/com.apple.xbs/Sources/CRFSuite_Sim/CRFSuite-48/crfsuite/lib/crf/src/crf1d_model.c
false
FILEHEADER = {
  magic: %c%c%c%c
  size: %d
  type: %c%c%c%c
  version: %d
  num_features: %d
  num_labels: %d
  num_attrs: %d
  off_features: 0x%X
  off_labels: 0x%X
  off_attrs: 0x%X
  off_labelrefs: 0x%X
  off_attrrefs: 0x%X
LABELS = {
  %5d: %s
ATTRIBUTES = {
TRANSITIONS = {
  (%d) %s --> %s: %f
STATE_FEATURES = {
cmw_write_attribute_feature
fwrite(&feature, 1, sizeof(compact_attribute_feature_t), concrete_writer->fp) == sizeof(compact_attribute_feature_t)
qmw_write_label_features
num_labels <= 255
qmw_write_attribute_feature_counts_and_offsets
feature_counts[i] <= 255
qmw_write_attribute_feature
destination <= 255
fwrite(&feature, 1, sizeof(quantized_attribute_feature_t), concrete_writer->fp) == sizeof(quantized_attribute_feature_t)
crf1dm_initialize_state_scores_compact
model->compact_header
crf1dm_initialize_state_scores_quantized
model->quantized_header
train/
crf1d/
lbfgs
l2sgd
averaged-perceptron
passive-aggressive
arow
Holdout group: %d
ERROR: "crfsuite_training_do_not_store_attributes" flag is not compatible with minimal frequency value that is greater than 1!
Performance by label (#match, #model, #ref) (precision, recall, F1):
[UNKNOWN]
    %s: (%d, %d, %d) (******, ******, ******)
    %s: (%d, %d, %d) (%1.4f, %1.4f, %1.4f)
Macro-average precision, recall, F1: (%f, %f, %f)
Item accuracy: %d / %d (%1.4f)
Instance accuracy: %d / %d (%1.4f)
dictionary
error: L2 regularization is currently not supported in SGD mode.
performing SGD
eta0 = 
 alpha = 
Feature
/BuildRoot/Library/Caches/com.apple.xbs/Sources/CRFSuite_Sim/CRFSuite-48/maxent/MaxEnt/efficient_maxent.h
id >= 0 && id < (int)id2mef.size()
float
string
unknown
Adaptive Regularization of Weights (AROW)
variance: %f
gamma: %f
max_iterations: %d
epsilon: %f
***** Iteration #%d *****
Loss: %f
Feature norm: %f
Seconds required for this iteration: %.3f
Terminated with the stopping criterion
Total seconds required for training: %.3f
variance
The initial variance of every feature weight.
gamma
Tradeoff parameter.
max_iterations
The maximum number of iterations.
epsilon
The stopping criterion (the mean loss).
FunctionGradient
/BuildRoot/Library/Caches/com.apple.xbs/Sources/CRFSuite_Sim/CRFSuite-48/maxent/MaxEnt/efficient_maxent.cpp
(int)_fb.Size() == x.size()
performing OWLQN
performing LBFGS
conditional_probability
prod != 0
max_label >= 0
classify
_num_classes == (int)membp.size()
error: too many types of labels.
error: L1 and L2 regularizers cannot be used simultaneously.
error: no training data.
error: too much heldout data. no training data is available.
warning: _num_class != _label_bag.Size()
L1 regularizer = 
L2 regularizer = 
preparing for estimation...
done
number of samples = 
number of features = 
calculating empirical expectation...
number of active features = 
error: cannot open 
error: could not write out features!
num_classes() == (int)membp.size()
ME_Feature
l >= 0 && l <= MAX_LABEL_TYPES
f >= 0 && f <= 0xffffff
id >= 0 && id < (int)id2str.size()
Averaged perceptron
The stopping criterion (the ratio of incorrect label predictions).
Coefficient for L2 regularization.
The maximum number of iterations (epochs) for SGD optimization.
period
The duration of iterations to test the stopping criterion.
delta
The threshold for the stopping criterion; an optimization process stops when
the improvement of the log likelihood over the last ${period} iterations is no
greater than this threshold.
calibration.eta
The initial value of learning rate (eta) used for calibration.
calibration.rate
The rate of increase/decrease of learning rate for calibration.
calibration.samples
The number of instances used for calibration.
calibration.candidates
The number of candidates of learning rate.
calibration.max_trials
The maximum number of trials of learning rates for calibration.
Stochastic Gradient Descent (SGD)
c2: %f
period: %d
delta: %f
Calibrating the learning rate (eta)
calibration.eta: %f
calibration.rate: %f
calibration.samples: %d
calibration.candidates: %d
calibration.max_trials: %d
Initial loss: %f
Trial #%d (eta = %f): 
%f (worse)
Best learning rate (eta): %f
***** Epoch #%d *****
ERROR: overflow loss
Improvement ratio: %f
Feature L2-norm: %f
Learning rate (eta): %f
Total number of feature updates: %.0f
SGD terminated with the stopping criteria
SGD terminated with the maximum number of iterations
operator+=
b.Size() == _v.size()
L-BFGS optimization
c1: %f
num_memories: %d
stop: %d
linesearch: %s
linesearch.max_iterations: %d
Backtracking
StrongBacktracking
L-BFGS resulted in convergence
L-BFGS terminated with the stopping criteria
L-BFGS terminated with the maximum number of iterations
L-BFGS terminated with error code (%d)
Coefficient for L1 regularization.
The maximum number of iterations for L-BFGS optimization.
num_memories
The number of limited memories for approximating the inverse hessian matrix.
Epsilon for testing the convergence of the objective.
The threshold for the stopping criterion; an L-BFGS iteration stops when the
improvement of the log likelihood over the last ${period} iterations is no
greater than this threshold.
linesearch
MoreThuente
The line search algorithm used in L-BFGS updates:
{   'MoreThuente': More and Thuente's method,
    'Backtracking': Backtracking method with regular Wolfe condition,
    'StrongBacktracking': Backtracking method with strong Wolfe condition
max_linesearch
The maximum number of trials for the line search algorithm.
Error norm: %f
Active features: %d
Line search trials: %d
Line search step: %f
Passive Aggressive
type: %d
c: %f
error_sensitive: %d
averaging: %d
type
The strategy for updating feature weights: {
    0: PA without slack variables,
    1: PA type I,
    2: PA type II
The aggressiveness parameter.
error_sensitive
Consider the number of incorrect labels to the cost function.
averaging
Compute the average of feature weights (similarly to Averaged Perceptron).
crf_paragraph_get_id
/BuildRoot/Library/Caches/com.apple.xbs/Sources/CRFSuite_Sim/CRFSuite-48/crfsuite/compatibility/backward_compatibility.c
index >= 0 && index < paragraph->num_items*paragraph->num_attrs
crf_paragraph_set_id
index >= 0
Warning: using -h 0 may be faster
optimization finished, #iter = %d
warning: class label %d specified in weight is not found
Total nSV = %d
Model doesn't contain information for SVR probability inference
svm_type %s
kernel_type %s
degree %d
gamma %g
coef0 %g
nr_class %d
total_sv %d
label
probA
probB
nr_sv
%.16g 
0:%d 
%d:%.8g 
%80s
unknown svm type.
unknown kernel function.
unknown text in model file: [%s]
unknown svm type
unknown kernel type
gamma < 0
degree of polynomial kernel < 0
cache_size <= 0
eps <= 0
C <= 0
nu <= 0 or nu > 1
p < 0
shrinking != 0 and shrinking != 1
probability != 0 and probability != 1
one-class SVM probability output not supported yet
specified nu is infeasible
Prob. model for test data: target value = predicted value + z,
z: Laplace distribution e^(-|z|/sigma)/(2sigma),sigma= %g
obj = %f, rho = %f
nSV = %d, nBSV = %d
nu = %f
C = %f
epsilon = %f
Line search fails in two-class probability estimates
Reaching maximal iterations in two-class probability estimates
Exceeds max_iter in multiclass_prob
c_svc
nu_svc
one_class
epsilon_svr
nu_svr
linear
polynomial
sigmoid
precomputed
addListNode
/BuildRoot/Library/Caches/com.apple.xbs/Sources/NLPUtils_Sim/NLPUtils-29/Source/BurstTrie.cpp
listcount <= trie->reserved[ContainerSize]
addListNodeRanked
advanceMapCursorTrieList
cursor->prfxlen <= head->restlen
traverseFromMapCursorTrieList
cursor.prfxlen <= head->restlen
serializeLevelsRanked
bitcount == count
serializeLevels
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
