N6marisa9ExceptionE
We love Marisa.
N5rnnlm21LeftContextSetBuilderE
N5rnnlm18QuantizedStateImplE
?N5rnnlm5StateE
N5rnnlm5RNNLME
N5rnnlm9RNNLMImplINS_8CBLASOpsEEE
NSt3__120__shared_ptr_pointerIPN5rnnlm4MmapIcEENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIN5rnnlm4MmapIcEEEE
N5rnnlm9StateImplE
N8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEE
N8gemmlowp4TaskE
N8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEE
N8gemmlowp13DefaultKernelINS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEEEE
N8gemmlowp17DefaultKernelImplILb0ELb1EEE
N8gemmlowp17DefaultKernelImplILb0ELb0EEE
N8gemmlowp15ReferenceKernelINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEEE
N8gemmlowp10KernelBaseE
N8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEEE
N8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEEE
N5rnnlm9RNNLMImplINS_8NaiveOpsEEE
AN5rnnlm14LeftContextSetE
N13sentencepiece10normalizer10NormalizerE
N5Darts15DoubleArrayImplIvvivEE
;N13sentencepiece22SentencePieceProcessorE
NSt3__114basic_ifstreamIcNS_11char_traitsIcEEEE
NSt3__113basic_filebufIcNS_11char_traitsIcEEEE
N13sentencepiece4word5ModelE
N13sentencepiece9character5ModelE
NSt3__118basic_stringstreamIcNS_11char_traitsIcEENS_9allocatorIcEEEE
?N13sentencepiece7unigram7LatticeE
N13sentencepiece7unigram9ModelBaseE
N13sentencepiece7unigram5ModelE
N5Darts7Details9ExceptionE
NSt3__114basic_ofstreamIcNS_11char_traitsIcEEEE
N13sentencepiece11TrainerSpecE
N13sentencepiece14NormalizerSpecE
N13sentencepiece24ModelProto_SentencePieceE
N13sentencepiece10ModelProtoE
NSt3__112basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEE
NSt3__121__basic_string_commonILb1EEE
N13sentencepiece14ModelInterfaceE
N13sentencepiece31SentencePieceText_SentencePieceE
N13sentencepiece17SentencePieceTextE
N13sentencepiece22NBestSentencePieceTextE
N6google8protobuf8internal29InternalMetadataWithArenaBaseINSt3__112basic_stringIcNS3_11char_traitsIcEENS3_9allocatorIcEEEENS1_29InternalMetadataWithArenaLiteEE9ContainerE
N13sentencepiece3bpe5ModelE
N6google8protobuf11MessageLiteE
N6google8protobuf8internal12FieldSkipperE
N6google8protobuf8internal29CodedOutputStreamFieldSkipperE
NSt3__119basic_ostringstreamIcNS_11char_traitsIcEENS_9allocatorIcEEEE
NSt3__115basic_stringbufIcNS_11char_traitsIcEENS_9allocatorIcEEEE
N6google8protobuf14FatalExceptionE
N6google8protobuf7ClosureE
N6google8protobuf8internal16FunctionClosure0E
N6google8protobuf2io20ZeroCopyOutputStreamE
N6google8protobuf2io17ArrayOutputStreamE
N6google8protobuf2io18StringOutputStreamE
_N6google8protobuf8internal15ExtensionFinderE
N6google8protobuf8internal24GeneratedExtensionFinderE
N6google8protobuf13RepeatedFieldIiEE
N6google8protobuf13RepeatedFieldIxEE
N6google8protobuf13RepeatedFieldIjEE
N6google8protobuf13RepeatedFieldIyEE
N6google8protobuf13RepeatedFieldIfEE
N6google8protobuf13RepeatedFieldIdEE
N6google8protobuf13RepeatedFieldIbEE
N6google8protobuf16RepeatedPtrFieldINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEEE
N6google8protobuf8internal20RepeatedPtrFieldBaseE
N6google8protobuf16RepeatedPtrFieldINS0_11MessageLiteEEE
NSt3__110__function6__funcIPFvPvPN3nlp15_TrieCompletionEbPbENS_9allocatorIS8_EES7_EE
NSt3__110__function6__baseIFvPvPN3nlp15_TrieCompletionEbPbEEE
PFvPvPN3nlp15_TrieCompletionEbPbE
FvPvPN3nlp15_TrieCompletionEbPbE
NSt3__110__function6__baseIFvPvPN3nlp15_TrieCompletionEPbEEE
NSt3__110__function6__funcIZN3nlpL12reverseBurstIPNS2_16_RankedTrieLevelEPNS2_15_RankedListNodeEEEvPNS2_10_BurstTrieERKNS_6vectorIT_NS_9allocatorISB_EEEEPKhjEUlPvSI_jjfPbE_NSC_ISL_EEFvSJ_SI_jjfSK_EEE
NSt3__110__function6__baseIFvPvPKhjjfPbEEE
ZN3nlpL12reverseBurstIPNS_16_RankedTrieLevelEPNS_15_RankedListNodeEEEvPNS_10_BurstTrieERKNSt3__16vectorIT_NS7_9allocatorIS9_EEEEPKhjEUlPvSG_jjfPbE_
NSt3__110__function6__funcIZN3nlpL12reverseBurstIPNS2_16_RankedTrieLevelEPNS2_15_RankedListNodeEEEvPNS2_10_BurstTrieERKNS_6vectorIT_NS_9allocatorISB_EEEEPKhjEUlPvSI_jjfPbE0_NSC_ISL_EEFvSJ_SI_jjfSK_EEE
ZN3nlpL12reverseBurstIPNS_16_RankedTrieLevelEPNS_15_RankedListNodeEEEvPNS_10_BurstTrieERKNSt3__16vectorIT_NS7_9allocatorIS9_EEEEPKhjEUlPvSG_jjfPbE0_
NSt3__110__function6__funcIZN3nlpL12reverseBurstIPNS2_10_TrieLevelEPNS2_9_ListNodeEEEvPNS2_10_BurstTrieERKNS_6vectorIT_NS_9allocatorISB_EEEEPKhjEUlPvSI_jjfPbE_NSC_ISL_EEFvSJ_SI_jjfSK_EEE
ZN3nlpL12reverseBurstIPNS_10_TrieLevelEPNS_9_ListNodeEEEvPNS_10_BurstTrieERKNSt3__16vectorIT_NS7_9allocatorIS9_EEEEPKhjEUlPvSG_jjfPbE_
NSt3__110__function6__funcIZN3nlpL12reverseBurstIPNS2_10_TrieLevelEPNS2_9_ListNodeEEEvPNS2_10_BurstTrieERKNS_6vectorIT_NS_9allocatorISB_EEEEPKhjEUlPvSI_jjfPbE0_NSC_ISL_EEFvSJ_SI_jjfSK_EEE
ZN3nlpL12reverseBurstIPNS_10_TrieLevelEPNS_9_ListNodeEEEvPNS_10_BurstTrieERKNSt3__16vectorIT_NS7_9allocatorIS9_EEEEPKhjEUlPvSG_jjfPbE0_
NSt3__110__function6__funcIZN3nlp15BurstTrieSearchEPKNS2_10_BurstTrieEPKhjPvNS_8functionIFvS8_PNS2_15_TrieCompletionEPbEEEiE3$_0NS_9allocatorISF_EEFvS8_S7_jjfSC_EEE
ZN3nlp15BurstTrieSearchEPKNS_10_BurstTrieEPKhjPvNSt3__18functionIFvS5_PNS_15_TrieCompletionEPbEEEiE3$_0
@(#)PROGRAM:mecabra  PROJECT:MeCab-924
@N11InputEngine21AnalyticsEventHandlerE
N11InputEngine30AnalyticsEventHandlerInterfaceE
N5MeCab7ViterbiE
N5MeCab8FreeListI12mecab_path_tEE
N11InputEngine20MecabraCandidateBaseE
9CloneableIN11InputEngine20MecabraCandidateBaseEE
N11InputEngine15CandidateClonerI22ChineseStringCandidateEE
22ChineseStringCandidate
NSt3__120__shared_ptr_pointerIPN11InputEngine13AsyncResourceINS1_13LanguageModelEEENS_14default_deleteIS4_EENS_9allocatorIS4_EEEE
NSt3__114default_deleteIN11InputEngine13AsyncResourceINS1_13LanguageModelEEEEE
NSt3__120__shared_ptr_pointerIPN11InputEngine19LanguageModelLoaderENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN11InputEngine19LanguageModelLoaderEEE
?NSt3__120__shared_ptr_pointerIPN11InputEngine21MecabraResourceLoaderI7LexiconEENS_14default_deleteIS4_EENS_9allocatorIS4_EEEE
NSt3__114default_deleteIN11InputEngine21MecabraResourceLoaderI7LexiconEEEE
N7Seaweed23SingleWordCandidateWordE
N11InputEngine13MecabraStrokeE
N11InputEngine33MecabraTraditionalCantoneseStrokeE
N11InputEngine30MecabraSimplifiedChineseStrokeE
N11InputEngine31MecabraTraditionalChineseStrokeE
NSt3__110__function6__funcIPF18NSComparisonResultP11objc_objectS4_ENS_9allocatorIS6_EES5_EE
NSt3__110__function6__baseIF18NSComparisonResultP11objc_objectS4_EEE
PF18NSComparisonResultP11objc_objectS1_E
F18NSComparisonResultP11objc_objectS1_E
N11InputEngine23JapaneseDynamicLMScorerE
NSt3__110__function6__funcIZNK7Seaweed10CTCLattice8logNBestEmE3$_3NS_9allocatorIS4_EEFvPKNS2_18SyllableHypothesisEPK10__CFStringdEEE
NSt3__110__function6__baseIFvPKN7Seaweed18SyllableHypothesisEPK10__CFStringdEEE
ZNK7Seaweed10CTCLattice8logNBestEmE3$_3
NSt3__117bad_function_callE
N11InputEngine27MecabraCharacterInputEngineE
N11InputEngine37ChinesePhraseLearningCandidateTrackerE
N11InputEngine25CandidateTrackerInterfaceE
N11InputEngine14MecabraCangjieE
NSt3__120__shared_ptr_pointerIPN11InputEngine27MecabraChineseTokenizerBaseENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN11InputEngine27MecabraChineseTokenizerBaseEEE
N5MeCab9ModelImplE
N5MeCab5ModelE
N5MeCab5ParamE
N5MeCab10scoped_ptrINS_6WriterEEE
N11InputEngine23JapaneseLMPredictorBaseE
NSt3__119basic_istringstreamIcNS_11char_traitsIcEENS_9allocatorIcEEEE
N5MeCab10scoped_ptrINSt3__112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEEEE
N5MeCab10MemoryPoolINSt3__112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEENS_4MmapIsEEEE
N5MeCab5MutexE
N5MeCab4MmapIsEE
NSt3__120__shared_ptr_pointerIPN7Seaweed36SeaweedFileMappedImmutableDictionaryENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN7Seaweed36SeaweedFileMappedImmutableDictionaryEEE
N11InputEngine34ChineseAbbreviatedCandidateTrackerE
BNSt3__120__shared_ptr_pointerIPN7Seaweed18CPSearchParametersENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN7Seaweed18CPSearchParametersEEE
N11InputEngine21JapaneseLMRegularizerE
22InspectorAccessContext
N11InputEngine28PinyinTenKeyCandidateTrackerE
N11InputEngine15CandidateClonerI28SyntheticConversionCandidateEE
34ZhuyinSyntheticConversionCandidate
0EN11InputEngine25JapaneseAcceptedCandidateE
25SyncMutableCFSpecificTypeIP14__CFDictionaryE
16SyncMutableCFRef
22IDXBuiltInAccessMethodI17TrieAccessContextE
15IDXAccessMethod
22IDXBuiltInAccessMethodI17HeapAccessContextE
22IDXBuiltInAccessMethodI22InspectorAccessContextE
N11InputEngine15CandidateClonerI18SyntheticCandidateEE
18SyntheticCandidate
22SyntheticCandidateWord
N5MeCab10MemoryPoolINSt3__112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEENS_4MmapIcEEEE
N5MeCab4MmapIcEE
16IDXAccessContext
17HeapAccessContext
17TrieAccessContext
N11InputEngine17MarisaTrieBuilderE
N11InputEngine11TrieBuilderE
333333
?NSt3__110__function6__funcIZN11InputEngine25EnglishCandidateGenerator20addEnglishCandidatesERNS2_12CandidateSetE11UTF16StringbE3$_0NS_9allocatorIS7_EEFvPK10__CFStringSC_dRbEEE
NSt3__110__function6__baseIFvPK10__CFStringS4_dRbEEE
ZN11InputEngine25EnglishCandidateGenerator20addEnglishCandidatesERNS_12CandidateSetE11UTF16StringbE3$_0
N11InputEngine25ABTestingCandidateTrackerE
N5MeCab10DictionaryE
N5MeCab17MutableDictionaryE
14GestureWrapper
N3nlp6CFTypeE
16LayoutKeyWrapper
21ChineseCompletionWord
333333
@N5MeCab13ChunkFreeListIcEE
N5MeCab5IconvE
N11InputEngine24ChineseAdaptationContextE
B0D0F0H0J0
N11InputEngine15CandidateClonerINS_17FacemarkCandidateEEE
N11InputEngine17FacemarkCandidateE
N11InputEngine25DictionaryReadingProviderE
N11InputEngine21TypingBehaviorTrackerE
N5MeCab12StringBufferE
N5MeCab10TaggerImplE
N5MeCab6TaggerE
N5MeCab14NBestGeneratorE
N5MeCab8FreeListINS_14NBestGenerator12QueueElementEEE
N7Seaweed19PhraseCandidateWordE
333333
BN11InputEngine15MecabraJapaneseE
N11InputEngine12CandidateSetE
NSt3__110__function6__funcIPFbRKNS_10unique_ptrIN11InputEngine19ConversionCandidateENS_14default_deleteIS4_EEEES9_ENS_9allocatorISB_EESA_EE
NSt3__110__function6__baseIFbRKNS_10unique_ptrIN11InputEngine19ConversionCandidateENS_14default_deleteIS4_EEEES9_EEE
PFbRKNSt3__110unique_ptrIN11InputEngine19ConversionCandidateENS_14default_deleteIS2_EEEES7_E
FbRKNSt3__110unique_ptrIN11InputEngine19ConversionCandidateENS_14default_deleteIS2_EEEES7_E
NSt3__118codecvt_utf8_utf16IDsLm1114111ELNS_12codecvt_modeE0EEE
14DynamicLexicon
N11InputEngine26MecabraConversionCandidateE
?ffffff
NkQ]N
N11InputEngine28MecabraInputEngineDispatcherINS_15MecabraJapaneseENS_23NoopPredictionComponentEEE
N11InputEngine18MecabraInputEngineE
N11InputEngine28MecabraInputEngineDispatcherIN7Seaweed16ConversionEngineE23ChinesePredictionEngineEE
N11InputEngine28MecabraInputEngineDispatcherINS_30MecabraSimplifiedChineseStrokeE23ChinesePredictionEngineEE
N11InputEngine28MecabraInputEngineDispatcherINS_31MecabraTraditionalChineseStrokeE23ChinesePredictionEngineEE
N11InputEngine28MecabraInputEngineDispatcherINS_33MecabraTraditionalCantoneseStrokeE23ChinesePredictionEngineEE
N11InputEngine28MecabraInputEngineDispatcherINS_14MecabraCangjieE23ChinesePredictionEngineEE
N11InputEngine28MecabraInputEngineDispatcherINS_15MecabraWubixingE23ChinesePredictionEngineEE
N11InputEngine28MecabraInputEngineDispatcherINS_18MecabraHandwritingE23ChinesePredictionEngineEE
N11InputEngine24ChinesePredictionContextE
N11InputEngine22JapaneseRNNLMPredictorE
N11InputEngine25DynamicDictionaryJapaneseE
N11InputEngine17DynamicDictionaryE
NSt3__110__function6__funcIZN11InputEngine24WordCompletionDictionaryC1E15MecabraLanguageE3$_0NS_9allocatorIS5_EEFvvEEE
NSt3__110__function6__baseIFvvEEE
ZN11InputEngine24WordCompletionDictionaryC1E15MecabraLanguageE3$_0
NSt3__110__function6__funcIZN11InputEngine24WordCompletionDictionary40enumerateCompletionsForFixedPhrasePrefixERK11UTF16StringU13block_pointerFvRN7Seaweed17SeaweedDictionary5EntryEmPbEE3$_1NS_9allocatorISE_EEFvvEEE
ZN11InputEngine24WordCompletionDictionary40enumerateCompletionsForFixedPhrasePrefixERK11UTF16StringU13block_pointerFvRN7Seaweed17SeaweedDictionary5EntryEmPbEE3$_1
NSt3__110__function6__funcIZN11InputEngine24WordCompletionDictionary29enumerateCompletionsForPrefixERK11UTF16StringmU13block_pointerFvRN7Seaweed17SeaweedDictionary5EntryEmPbEE3$_2NS_9allocatorISE_EEFvvEEE
ZN11InputEngine24WordCompletionDictionary29enumerateCompletionsForPrefixERK11UTF16StringmU13block_pointerFvRN7Seaweed17SeaweedDictionary5EntryEmPbEE3$_2
NSt3__110__function6__funcIZN11InputEngine18JapaneseComparator32compareCandidatesByTypeAndWeightERKNS_10unique_ptrINS2_19ConversionCandidateENS_14default_deleteIS5_EEEESA_E3$_2NS_9allocatorISB_EEFbNS2_20MecabraCandidateKindESE_EEE
NSt3__110__function6__baseIFbN11InputEngine20MecabraCandidateKindES3_EEE
ZN11InputEngine18JapaneseComparator32compareCandidatesByTypeAndWeightERKNSt3__110unique_ptrINS_19ConversionCandidateENS1_14default_deleteIS3_EEEES8_E3$_2
NSt3__110__function6__funcIZN11InputEngine18JapaneseComparator32compareCandidatesByTypeAndWeightERKNS_10unique_ptrINS2_19ConversionCandidateENS_14default_deleteIS5_EEEESA_E3$_3NS_9allocatorISB_EEFbNS2_20MecabraCandidateKindESE_EEE
ZN11InputEngine18JapaneseComparator32compareCandidatesByTypeAndWeightERKNSt3__110unique_ptrINS_19ConversionCandidateENS1_14default_deleteIS3_EEEES8_E3$_3
NSt3__110__function6__funcIZN11InputEngine18JapaneseComparator32compareCandidatesByTypeAndWeightERKNS_10unique_ptrINS2_19ConversionCandidateENS_14default_deleteIS5_EEEESA_E3$_4NS_9allocatorISB_EEFbNS2_20MecabraCandidateKindESE_EEE
ZN11InputEngine18JapaneseComparator32compareCandidatesByTypeAndWeightERKNSt3__110unique_ptrINS_19ConversionCandidateENS1_14default_deleteIS3_EEEES8_E3$_4
NSt3__110__function6__funcIZN11InputEngine18JapaneseComparator32compareCandidatesByTypeAndWeightERKNS_10unique_ptrINS2_19ConversionCandidateENS_14default_deleteIS5_EEEESA_E3$_0NS_9allocatorISB_EEFbNS2_36ConversionCandidateMatchedLengthTypeESE_EEE
NSt3__110__function6__baseIFbN11InputEngine36ConversionCandidateMatchedLengthTypeES3_EEE
ZN11InputEngine18JapaneseComparator32compareCandidatesByTypeAndWeightERKNSt3__110unique_ptrINS_19ConversionCandidateENS1_14default_deleteIS3_EEEES8_E3$_0
32BTriePositionInterpreterInternal
23BTrieFatBaseInterpreter
27BTrieCompactBaseInterpreter
24BTrieFlatBaseInterpreter
20BTrieNoOpInterpreter
N11InputEngine23MecabraChineseTokenizerE
N11InputEngine27MecabraChineseTokenizerBaseE
N7Seaweed21SyllableLatticeColumnE
NSt3__120__shared_ptr_emplaceIN7Seaweed32SyntheticMixedScriptSyllableNodeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN7Seaweed25AutoCorrectedSyllableNodeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN7Seaweed28SyntheticEnglishSyllableNodeENS_9allocatorIS2_EEEE
17ChineseStringWord
N11InputEngine26MecabraCandidateSetAdaptorE
N11InputEngine34MecabraCandidateSetSkippingAdaptorE
N11InputEngine34MecabraCandidateSetOrderingAdaptorE
21EntryFieldStringValue
15EntryFieldValue
22EntryFieldIntegerValue
NSt3__120__shared_ptr_pointerIP21EntryFieldStringValueNS_14default_deleteIS1_EENS_9allocatorIS1_EEEE
NSt3__114default_deleteI21EntryFieldStringValueEE
NSt3__120__shared_ptr_pointerIP22EntryFieldIntegerValueNS_14default_deleteIS1_EENS_9allocatorIS1_EEEE
NSt3__114default_deleteI22EntryFieldIntegerValueEE
13FileException
NSt3__120__shared_ptr_pointerIP4FileIcENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteI4FileIcEEE
N11InputEngine33JapaneseConversionAccuracyTrackerE
N11InputEngine15CandidateClonerI33CharacterInputConversionCandidateEE
33CharacterInputConversionCandidate
28SyntheticConversionCandidate
N11InputEngine27JapaneseConversionCandidateE
9CloneableIN11InputEngine27JapaneseConversionCandidateEE
N11InputEngine25ConversionAccuracyTrackerE
23SQLiteDatabaseException
N3nlp16BurstTrieAdapterIitEE
N3nlp11MutableTrieIitNS_22BurstTrieAdapterCursorEEE
N3nlp4TrieIitNS_22BurstTrieAdapterCursorEEE
NSt3__110__function6__funcIZNK3nlp16BurstTrieAdapterIitE20enumerateCompletionsEPKcmRKNS_8functionIFvRKiS6_mRbEEEiEUlPvPNS2_15_TrieCompletionEPbE_NS_9allocatorISJ_EEFvSF_SH_SI_EEE
ZNK3nlp16BurstTrieAdapterIitE20enumerateCompletionsEPKcmRKNSt3__18functionIFvRKiS3_mRbEEEiEUlPvPNS_15_TrieCompletionEPbE_
NSt3__110__function6__funcIZNK3nlp16BurstTrieAdapterIitE16enumerateEntriesERKNS2_22BurstTrieAdapterCursorERKNS_8functionIFvRKiPKcmRbEEEiEUlPvPKhjjfPbE_NS_9allocatorISM_EEFvSI_SK_jjfSL_EEE
ZNK3nlp16BurstTrieAdapterIitE16enumerateEntriesERKNS_22BurstTrieAdapterCursorERKNSt3__18functionIFvRKiPKcmRbEEEiEUlPvPKhjjfPbE_
N11InputEngine27MutableAmbiguousTrieAdapterIN3nlp16BurstTrieAdapterIitEEEE
N11InputEngine20AmbiguousTrieAdapterIN3nlp16BurstTrieAdapterIitEEEE
N11InputEngine13AmbiguousTrieIN3nlp16BurstTrieAdapterIitEEEE
NSt3__110__function6__funcIZNK11InputEngine20AmbiguousTrieAdapterIN3nlp16BurstTrieAdapterIitEEE15ambiguousSearchERKNS2_26AmbiguousTrieSearchLatticeItEERKNS_8functionIFvRKNS4_13ScoredPayloadIiEEPKcmmRbEEEbEUlRKNS4_22BurstTrieAdapterCursorEfSI_mmSJ_E_NS_9allocatorISR_EEFvSQ_fSI_mmSJ_EEE
NSt3__110__function6__baseIFvRKN3nlp22BurstTrieAdapterCursorEfPKcmmRbEEE
ZNK11InputEngine20AmbiguousTrieAdapterIN3nlp16BurstTrieAdapterIitEEE15ambiguousSearchERKNS_26AmbiguousTrieSearchLatticeItEERKNSt3__18functionIFvRKNS1_13ScoredPayloadIiEEPKcmmRbEEEbEUlRKNS1_22BurstTrieAdapterCursorEfSG_mmSH_E_
NSt3__110__function6__funcIZNK11InputEngine20AmbiguousTrieAdapterIN3nlp16BurstTrieAdapterIitEEE20enumerateCompletionsERKNS2_26AmbiguousTrieSearchLatticeItEERKNS_8functionIFvRKNS4_13ScoredPayloadIiEEPKcmmRbEEEiEUlRKNS4_22BurstTrieAdapterCursorEfSI_mmSJ_E_NS_9allocatorISR_EEFvSQ_fSI_mmSJ_EEE
NSt3__110__function6__funcIZZNK11InputEngine20AmbiguousTrieAdapterIN3nlp16BurstTrieAdapterIitEEE20enumerateCompletionsERKNS2_26AmbiguousTrieSearchLatticeItEERKNS_8functionIFvRKNS4_13ScoredPayloadIiEEPKcmmRbEEEiENKUlRKNS4_22BurstTrieAdapterCursorEfSI_mmSJ_E_clESQ_fSI_mmSJ_EUlRKiSI_mSJ_E_NS_9allocatorISU_EEFvST_SI_mSJ_EEE
NSt3__110__function6__baseIFvRKiPKcmRbEEE
ZZNK11InputEngine20AmbiguousTrieAdapterIN3nlp16BurstTrieAdapterIitEEE20enumerateCompletionsERKNS_26AmbiguousTrieSearchLatticeItEERKNSt3__18functionIFvRKNS1_13ScoredPayloadIiEEPKcmmRbEEEiENKUlRKNS1_22BurstTrieAdapterCursorEfSG_mmSH_E_clESO_fSG_mmSH_EUlRKiSG_mSH_E_
ZNK11InputEngine20AmbiguousTrieAdapterIN3nlp16BurstTrieAdapterIitEEE20enumerateCompletionsERKNS_26AmbiguousTrieSearchLatticeItEERKNSt3__18functionIFvRKNS1_13ScoredPayloadIiEEPKcmmRbEEEiEUlRKNS1_22BurstTrieAdapterCursorEfSG_mmSH_E_
NSt3__110__function6__funcIZNK22LearningDictionaryTrie28enumerateTrieValueUsingBlockE11UTF16StringjU13block_pointerFviPbEE3$_1NS_9allocatorIS7_EEFvRKN3nlp13ScoredPayloadIiEEPKcmmRbEEE
NSt3__110__function6__baseIFvRKN3nlp13ScoredPayloadIiEEPKcmmRbEEE
ZNK22LearningDictionaryTrie28enumerateTrieValueUsingBlockE11UTF16StringjU13block_pointerFviPbEE3$_1
NSt3__110__function6__funcIZNK22LearningDictionaryTrie28enumerateTrieValueUsingBlockE11UTF16StringjU13block_pointerFviPbEE3$_2NS_9allocatorIS7_EEFvRKiPKcmRbEEE
ZNK22LearningDictionaryTrie28enumerateTrieValueUsingBlockE11UTF16StringjU13block_pointerFviPbEE3$_2
NSt3__110__function6__funcIZNK22LearningDictionaryTrie22enumeratePrefixEntriesERK12TriePositionmiPhU13block_pointerFvjmPbEE3$_3NS_9allocatorISA_EEFvRKiPKcmRbEEE
ZNK22LearningDictionaryTrie22enumeratePrefixEntriesERK12TriePositionmiPhU13block_pointerFvjmPbEE3$_3
N11InputEngine33ChineseShapeBasedCandidateTrackerE
N7Seaweed11ITCandidateE
N7Seaweed10SoftLinkedE
N7Seaweed22TouchTranscoderSessionE
N7Seaweed9ITDecoderE
N7Seaweed15TouchTranscoderE
27CharacterLatticeSessionData
N11InputEngine19JapaneseRNNLMScorerE
333333
?34ChineseCompletionProducerException
NSt3__120__shared_ptr_pointerIP19ReadingMappedStringNS_14default_deleteIS1_EENS_9allocatorIS1_EEEE
NSt3__114default_deleteI19ReadingMappedStringEE
N11InputEngine28ChineseSyllableLengthTrackerE
N7Seaweed11TypeSegmentE
N7Seaweed12InputSegmentE
N7Seaweed11PathSegmentE
N11InputEngine15CandidateClonerIN7Seaweed25InlinePredictionCandidateEEE
N7Seaweed25InlinePredictionCandidateE
NSt3__120__shared_ptr_emplaceIN7Seaweed20InlinePredictionWordENS_9allocatorIS2_EEEE
$@ffffff
?ffffff
?34ChinesePredictionProducerException
<N11InputEngine11GestureBaseE
N11InputEngine9CPGestureE
N11InputEngine18TruncatedCPGestureE
N11InputEngine13TypingGestureE
A0C0E0G0I0
0N11InputEngine15MecabraWubixingE
17InstantLogPrinter
10LogPrinter
18BufferedLogPrinter
N7Seaweed31SeaweedDynamicMutableDictionaryE
.A22SyntheticCandidateBase
N11InputEngine13MecabraEngineE
N11InputEngine30ChineseRevertAdaptationContextE
N11InputEngine20CandidateKindTrackerE
333333
?ffffff
NSt3__110__function6__funcIZNK11InputEngine23EnglishLookupController22enumerateSortedEntriesEPK10__CFStringdttRKNS_8functionIFvS6_S6_dRbEEEbE3$_0NS_9allocatorISD_EEFvPK9_LXCursorS8_EEE
NSt3__110__function6__baseIFvPK9_LXCursorRbEEE
ZNK11InputEngine23EnglishLookupController22enumerateSortedEntriesEPK10__CFStringdttRKNSt3__18functionIFvS3_S3_dRbEEEbE3$_0
NSt3__110__function6__funcIZNK11InputEngine23EnglishLookupController11shouldBlockEPK10__CFStringmE3$_1NS_9allocatorIS7_EEFvPK9_LXCursorRbEEE
ZNK11InputEngine23EnglishLookupController11shouldBlockEPK10__CFStringmE3$_1
NSt3__110__function6__funcIZNK11InputEngine23EnglishLookupController39createLatinWordWithProperCapitalizationEPK10__CFStringS6_bE3$_2NS_9allocatorIS7_EEFvPK9_LXCursorRbEEE
ZNK11InputEngine23EnglishLookupController39createLatinWordWithProperCapitalizationEPK10__CFStringS3_bE3$_2
NSt3__110__function6__funcIZN11InputEngine23EnglishLookupController27updateLayoutKeysWithContextEPKNS2_18MecabraContextImplEE3$_3NS_9allocatorIS7_EEFvRKNS2_9LayoutKeyEEEE
NSt3__110__function6__baseIFvRKN11InputEngine9LayoutKeyEEEE
ZN11InputEngine23EnglishLookupController27updateLayoutKeysWithContextEPKNS_18MecabraContextImplEE3$_3
NSt3__110__function6__funcIZNK11InputEngine23EnglishLookupController28enumerateQuickPathCandidatesEddtRKNS_8functionIFvPK10__CFStringS7_dRbEEEE3$_4NS_9allocatorISD_EES9_EE
ZNK11InputEngine23EnglishLookupController28enumerateQuickPathCandidatesEddtRKNSt3__18functionIFvPK10__CFStringS5_dRbEEEE3$_4
N11InputEngine22ZhuyinCandidateTrackerE
b@N11InputEngine18MecabraContextImplE
N11InputEngine21JapaneseRNNLMRerankerE
N11InputEngine22JapaneseLMRerankerBaseE
N11InputEngine19MecabraCandidateSetE
N11InputEngine26MecabraChineseCandidateSetE
N11InputEngine41MecabraChineseSingleCharacterCandidateSetE
N11InputEngine36MecabraChineseExactMatchCandidateSetE
N11InputEngine27MecabraJapaneseCandidateSetE
N11InputEngine14MecabraLearnerE
NSt3__110__function6__funcIZN11InputEngine14MecabraLearnerC1EPK7__CFURLjE3$_0NS_9allocatorIS7_EEFPK10__CFStringPKNS2_19ConversionCandidateEEEE
NSt3__110__function6__baseIFPK10__CFStringPKN11InputEngine19ConversionCandidateEEEE
ZN11InputEngine14MecabraLearnerC1EPK7__CFURLjE3$_0
NSt3__110__function6__funcIZN11InputEngine14MecabraLearnerC1EPK7__CFURLjE3$_1NS_9allocatorIS7_EEFPK14__CFDictionaryvEEE
NSt3__110__function6__baseIFPK14__CFDictionaryvEEE
ZN11InputEngine14MecabraLearnerC1EPK7__CFURLjE3$_1
N11InputEngine27SeaweedChinesePinyinLearnerE
N11InputEngine21SeaweedChineseLearnerE
N11InputEngine38SeaweedTraditionalChinesePinyinLearnerE
N11InputEngine37SeaweedSimplifiedChinesePinyinLearnerE
N11InputEngine38SeaweedTraditionalChineseZhuyinLearnerE
19ChineseLearningInfo
12LearningInfo
NSt3__110__function6__funcIZN11InputEngine21SeaweedChineseLearnerC1EPK7__CFURLRN7Seaweed17DictionaryManagerERKNS2_15ChineseResourceEE3$_0NS_9allocatorISD_EEF22MecabraInputMethodTypevEEE
NSt3__110__function6__baseIF22MecabraInputMethodTypevEEE
ZN11InputEngine21SeaweedChineseLearnerC1EPK7__CFURLRN7Seaweed17DictionaryManagerERKNS_15ChineseResourceEE3$_0
NSt3__110__function6__funcIZN11InputEngine21SeaweedChineseLearnerC1EPK7__CFURLRN7Seaweed17DictionaryManagerERKNS2_15ChineseResourceEE3$_1NS_9allocatorISD_EEFPK10__CFStringvEEE
NSt3__110__function6__baseIFPK10__CFStringvEEE
ZN11InputEngine21SeaweedChineseLearnerC1EPK7__CFURLRN7Seaweed17DictionaryManagerERKNS_15ChineseResourceEE3$_1
NSt3__110__function6__funcIZN11InputEngine27SeaweedChinesePinyinLearnerC1EPK7__CFURLRN7Seaweed17DictionaryManagerERKNS2_15ChineseResourceEE3$_2NS_9allocatorISD_EEF22MecabraInputMethodTypevEEE
ZN11InputEngine27SeaweedChinesePinyinLearnerC1EPK7__CFURLRN7Seaweed17DictionaryManagerERKNS_15ChineseResourceEE3$_2
N7Seaweed26ReverseDictionaryExceptionE
NSt3__120__shared_ptr_pointerIPN11InputEngine21MecabraResourceLoaderINS1_12CharacterMapEEENS_14default_deleteIS4_EENS_9allocatorIS4_EEEE
NSt3__114default_deleteIN11InputEngine21MecabraResourceLoaderINS1_12CharacterMapEEEEE
N11InputEngine22MecabraJapaneseLearnerE
27MecabraJapaneseLearningInfo
NSt3__110__function6__funcIZN11InputEngine22MecabraJapaneseLearnerC1EPN5MeCab6TaggerERKNS2_25DictionaryReadingProviderEPKNS2_16MecabraTokenizerERKNS2_31MecabraJapaneseCandidateFactoryERKjPK7__CFURLE3$_0NS_9allocatorISL_EEFPK10__CFStringvEEE
ZN11InputEngine22MecabraJapaneseLearnerC1EPN5MeCab6TaggerERKNS_25DictionaryReadingProviderEPKNS_16MecabraTokenizerERKNS_31MecabraJapaneseCandidateFactoryERKjPK7__CFURLE3$_0
N11InputEngine19ConversionCandidateE
default
allocation
conversion
context
correction
learning
languagemodel
live
mobileasset
prediction
pruning
reranking
MecabraSignposts
testing
N11InputEngine15CandidateClonerI20HandwritingCandidateEE
20HandwritingCandidate
@N11InputEngine29MecabraJapaneseNgramPredictorE
  0 
: `k
85*L
W&0CFq
 ? 2t{
,k!%
ab,Ac
^4-*L
Op"I
`'H*@
M!70
V\PI
 HC
k `p
$@R2
8! @
F3$xr0
$"0 
:0p(
<5*L
W&0c
g!Ip"
THhd
CQ d
d:9%
,k1%
cF(Aa
0&dH1
h+]A
H&@8J?
,iud>
&BaY
`"A0
R%!)
:J$4
+AL L+
te  8D
`B*@*
 !:"
I$3@
:! @
% et
>Y%-c@
En Y
F3$xr0
4"0&
CX`0$P
:0p('a
=5*L
W&<c
-H2Y
g!Ip*
>P%0
CQ0d
d:9%
,k1%
0.dH1
h+]C
J&@8J?
)5)P*
,iud>
&BaY
pv5,
W%!)
:J$4
+AL L+
8D1(<
`J*@*@
 R2E
 !:b
I,sB
N7Seaweed23ConversionCandidateWordE
NSt3__120__shared_ptr_emplaceI19ReadingMappedStringNS_9allocatorIS1_EEEE
koyhdnihsnihukufnaemirtbtnoc   =
N11InputEngine15CandidateClonerIN7Seaweed19SingleWordCandidateEEE
N7Seaweed19SingleWordCandidateE
@ffffff
ffffff
333333
ffffff
?ffffff
?N7Seaweed16ConversionEngineE
19PreheatableResource
NSt3__110__function6__funcINS_6__bindIRF18NSComparisonResultP11objc_objectS5_dEJRKNS_12placeholders4__phILi1EEERKNS9_ILi2EEERKdEEENS_9allocatorISI_EEFS3_S5_S5_EEE
NSt3__16__bindIRF18NSComparisonResultP11objc_objectS3_dEJRKNS_12placeholders4__phILi1EEERKNS7_ILi2EEERKdEEE
NSt3__118__weak_result_typeIPF18NSComparisonResultP11objc_objectS3_dEEE
N11InputEngine15CandidateClonerI22ChineseHybridCandidateEE
22ChineseHybridCandidate
N11InputEngine16BurstTrieBuilderE
N11InputEngine31JapaneseStaticLMAccuracyTrackerE
26CharacterLatticeController
N7Seaweed20InlinePredictionWordE
16CharacterLattice
N11InputEngine23EnglishCandidateTrackerE
N7Seaweed26SeaweedImmutableDictionaryE
N7Seaweed17SeaweedDictionaryE
29SingleIndexKeyTokenEnumerator
18KeyTokenEnumerator
31MultipleIndexKeyTokenEnumerator
N7Seaweed13CandidateWordE
@333333
N11InputEngine25MecabraJapaneseLMRerankerE
NSt3__110__function6__funcIZN15MecabraAssetSet19setOptionalAssetURLEPK7__CFURLE3$_0NS_9allocatorIS6_EEFvS5_PK10__CFStringPbEEE
NSt3__110__function6__baseIFvPK7__CFURLPK10__CFStringPbEEE
ZN15MecabraAssetSet19setOptionalAssetURLEPK7__CFURLE3$_0
NSt3__120__shared_ptr_emplaceI15MecabraAssetSetNS_9allocatorIS1_EEEE
N7Seaweed13LatticeSearchE
N11InputEngine30MecabraSimplifiedStrokeLearnerE
N11InputEngine28MecabraCharacterInputLearnerE
N11InputEngine21MecabraSuchengLearnerE
N11InputEngine30MecabraCantoneseSuchengLearnerE
N11InputEngine31MecabraTraditionalStrokeLearnerE
N11InputEngine40MecabraTraditionalCantoneseStrokeLearnerE
N11InputEngine22MecabraWubixingLearnerE
18StrokeLearningInfo
NSt3__110__function6__funcIZN11InputEngine28MecabraCharacterInputLearnerC1EPK7__CFURLU13block_pointerFPK10__CFStringS9_EE3$_0NS_9allocatorISC_EEF22MecabraInputMethodTypevEEE
ZN11InputEngine28MecabraCharacterInputLearnerC1EPK7__CFURLU13block_pointerFPK10__CFStringS6_EE3$_0
NSt3__110__function6__funcIZN11InputEngine28MecabraCharacterInputLearnerC1EPK7__CFURLU13block_pointerFPK10__CFStringS9_EE3$_1NS_9allocatorISC_EEFS9_vEEE
ZN11InputEngine28MecabraCharacterInputLearnerC1EPK7__CFURLU13block_pointerFPK10__CFStringS6_EE3$_1
NSt3__120__shared_ptr_emplaceIN14SharedCFString7WrapperENS_9allocatorIS2_EEEE
?ffffff
N7Seaweed16LookupControllerE
N7Seaweed33MixedScriptSyllableSearchDelegateE
NSt3__110__function6__funcINS_6__bindIMN7Seaweed16LookupControllerEKFbmPKNS3_9WordGroupES7_EJPS4_RKNS_12placeholders4__phILi1EEERKNSC_ILi2EEERKNSC_ILi3EEEEEENS_9allocatorISM_EEFbmS7_S7_EEE
NSt3__110__function6__baseIFbmPKN7Seaweed9WordGroupES5_EEE
NSt3__16__bindIMN7Seaweed16LookupControllerEKFbmPKNS1_9WordGroupES5_EJPS2_RKNS_12placeholders4__phILi1EEERKNSA_ILi2EEERKNSA_ILi3EEEEEE
NSt3__118__weak_result_typeIMN7Seaweed16LookupControllerEKFbmPKNS1_9WordGroupES5_EEE
NSt3__120__shared_ptr_pointerIP29SingleWordCandidateSharedDataNS_14default_deleteIS1_EENS_9allocatorIS1_EEEE
NSt3__114default_deleteI29SingleWordCandidateSharedDataEE
NSt3__110__function6__funcIZNK7Seaweed16LookupController23createSyllableSequencesElE3$_1NS_9allocatorIS4_EEFvPKNS2_18SyllableHypothesisEPK10__CFStringdEEE
ZNK7Seaweed16LookupController23createSyllableSequencesElE3$_1
NSt3__110__function6__funcIZN7Seaweed16LookupController28lookupTenKeyLatinSingleWordsEvE3$_2NS_9allocatorIS4_EEFvPK10__CFStringS9_dRbEEE
ZN7Seaweed16LookupController28lookupTenKeyLatinSingleWordsEvE3$_2
NSt3__110__function6__funcIZN7Seaweed16LookupController31lookupQuickPathLatinSingleWordsEvE3$_3NS_9allocatorIS4_EEFvPK10__CFStringS9_dRbEEE
ZN7Seaweed16LookupController31lookupQuickPathLatinSingleWordsEvE3$_3
NSt3__110__function6__funcIZN7Seaweed16LookupController22lookupLatinSingleWordsEvE3$_4NS_9allocatorIS4_EEFvPK10__CFStringS9_dRbEEE
ZN7Seaweed16LookupController22lookupLatinSingleWordsEvE3$_4
N11InputEngine13LanguageModelE
N5MeCab25MecabraJapaneseDictionaryE
NSt3__110__function6__funcIZN5MeCab25MecabraJapaneseDictionary28enumerateReadingBigramTokensEPKcmbbS5_mjU13block_pointerFvRKNS2_11BigramTokenEfPbEE3$_0NS_9allocatorISC_EEFvRKN3nlp13ScoredPayloadIiEES5_mmRbEEE
ZN5MeCab25MecabraJapaneseDictionary28enumerateReadingBigramTokensEPKcmbbS2_mjU13block_pointerFvRKNS_11BigramTokenEfPbEE3$_0
NSt3__110__function6__funcIZN5MeCab25MecabraJapaneseDictionary6searchEjPKcmPKN11InputEngine19MecabraAnalysisInfoEPK13GeometryModelmP25trie_search_result_type_tmE3$_1NS_9allocatorISF_EEFvRKN3nlp13ScoredPayloadIiEES5_mmRbEEE
ZN5MeCab25MecabraJapaneseDictionary6searchEjPKcmPKN11InputEngine19MecabraAnalysisInfoEPK13GeometryModelmP25trie_search_result_type_tmE3$_1
NSt3__110__function6__funcIZN5MeCab25MecabraJapaneseDictionary6searchEjPKcmPKN11InputEngine19MecabraAnalysisInfoEPK13GeometryModelmP25trie_search_result_type_tmE3$_2NS_9allocatorISF_EEFvRKN3nlp13ScoredPayloadIiEES5_mmRbEEE
ZN5MeCab25MecabraJapaneseDictionary6searchEjPKcmPKN11InputEngine19MecabraAnalysisInfoEPK13GeometryModelmP25trie_search_result_type_tmE3$_2
NSt3__110__function6__funcIZN5MeCab25MecabraJapaneseDictionary6searchEjPKcmPKN11InputEngine19MecabraAnalysisInfoEPK13GeometryModelmP25trie_search_result_type_tmE3$_3NS_9allocatorISF_EEFvRKiS5_mRbEEE
ZN5MeCab25MecabraJapaneseDictionary6searchEjPKcmPKN11InputEngine19MecabraAnalysisInfoEPK13GeometryModelmP25trie_search_result_type_tmE3$_3
N11InputEngine22StaticBurstTrieAdapterIitEE
N3nlp4TrieIitN11InputEngine28StaticBurstTrieAdapterCursorEEE
NSt3__110__function6__funcIZN11InputEngine22StaticBurstTrieAdapterIitEC1ER7btrie_tEUlPS5_E_NS_9allocatorIS8_EEFvS7_EEE
NSt3__110__function6__baseIFvP7btrie_tEEE
ZN11InputEngine22StaticBurstTrieAdapterIitEC1ER7btrie_tEUlPS2_E_
NSt3__110__function6__funcIZNK11InputEngine22StaticBurstTrieAdapterIitE20enumerateCompletionsEPKcmRKNS_8functionIFvRKiS6_mRbEEEiEUlS9_S6_mSA_E_NS_9allocatorISF_EESB_EE
ZNK11InputEngine22StaticBurstTrieAdapterIitE20enumerateCompletionsEPKcmRKNSt3__18functionIFvRKiS3_mRbEEEiEUlS7_S3_mS8_E_
N11InputEngine20AmbiguousTrieAdapterINS_22StaticBurstTrieAdapterIitEEEE
N11InputEngine13AmbiguousTrieINS_22StaticBurstTrieAdapterIitEEEE
NSt3__110__function6__funcIZNK11InputEngine20AmbiguousTrieAdapterINS2_22StaticBurstTrieAdapterIitEEE15ambiguousSearchERKNS2_26AmbiguousTrieSearchLatticeItEERKNS_8functionIFvRKN3nlp13ScoredPayloadIiEEPKcmmRbEEEbEUlRKNS2_28StaticBurstTrieAdapterCursorEfSI_mmSJ_E_NS_9allocatorISR_EEFvSQ_fSI_mmSJ_EEE
NSt3__110__function6__baseIFvRKN11InputEngine28StaticBurstTrieAdapterCursorEfPKcmmRbEEE
ZNK11InputEngine20AmbiguousTrieAdapterINS_22StaticBurstTrieAdapterIitEEE15ambiguousSearchERKNS_26AmbiguousTrieSearchLatticeItEERKNSt3__18functionIFvRKN3nlp13ScoredPayloadIiEEPKcmmRbEEEbEUlRKNS_28StaticBurstTrieAdapterCursorEfSG_mmSH_E_
NSt3__110__function6__funcIZNK11InputEngine20AmbiguousTrieAdapterINS2_22StaticBurstTrieAdapterIitEEE20enumerateCompletionsERKNS2_26AmbiguousTrieSearchLatticeItEERKNS_8functionIFvRKN3nlp13ScoredPayloadIiEEPKcmmRbEEEiEUlRKNS2_28StaticBurstTrieAdapterCursorEfSI_mmSJ_E_NS_9allocatorISR_EEFvSQ_fSI_mmSJ_EEE
NSt3__110__function6__funcIZZNK11InputEngine20AmbiguousTrieAdapterINS2_22StaticBurstTrieAdapterIitEEE20enumerateCompletionsERKNS2_26AmbiguousTrieSearchLatticeItEERKNS_8functionIFvRKN3nlp13ScoredPayloadIiEEPKcmmRbEEEiENKUlRKNS2_28StaticBurstTrieAdapterCursorEfSI_mmSJ_E_clESQ_fSI_mmSJ_EUlRKiSI_mSJ_E_NS_9allocatorISU_EEFvST_SI_mSJ_EEE
ZZNK11InputEngine20AmbiguousTrieAdapterINS_22StaticBurstTrieAdapterIitEEE20enumerateCompletionsERKNS_26AmbiguousTrieSearchLatticeItEERKNSt3__18functionIFvRKN3nlp13ScoredPayloadIiEEPKcmmRbEEEiENKUlRKNS_28StaticBurstTrieAdapterCursorEfSG_mmSH_E_clESO_fSG_mmSH_EUlRKiSG_mSH_E_
ZNK11InputEngine20AmbiguousTrieAdapterINS_22StaticBurstTrieAdapterIitEEE20enumerateCompletionsERKNS_26AmbiguousTrieSearchLatticeItEERKNSt3__18functionIFvRKN3nlp13ScoredPayloadIiEEPKcmmRbEEEiEUlRKNS_28StaticBurstTrieAdapterCursorEfSG_mmSH_E_
NSt3__110__function6__funcIZN11InputEngine22StaticBurstTrieAdapterIitEC1EPcmEUlP7btrie_tE_NS_9allocatorIS8_EEFvS7_EEE
ZN11InputEngine22StaticBurstTrieAdapterIitEC1EPcmEUlP7btrie_tE_
N7Seaweed26SeaweedConversionCandidateE
29SingleWordCandidateSharedData
@19PredictionCandidate
N11InputEngine15CandidateClonerI26ChinesePredictionCandidateEE
26ChinesePredictionCandidate
N11InputEngine15CandidateClonerIN7Seaweed15PhraseCandidateEEE
N7Seaweed15PhraseCandidateE
NSt3__120__shared_ptr_emplaceIN7Seaweed19PhraseCandidateWordENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_pointerIPN7Seaweed19PhraseCandidateWordENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN7Seaweed19PhraseCandidateWordEEE
N11InputEngine19ChineseInputContextE
N7Seaweed8WordCoreE
N7Seaweed29StaticDictionaryEntryWordCoreE
N7Seaweed23DictionaryEntryWordCoreE
N7Seaweed16SentinelWordCoreE
N7Seaweed31LearningDictionaryEntryWordCoreE
N7Seaweed45StaticDictionaryEntryWithModifiedCostWordCoreE
N7Seaweed19MixedScriptWordCoreE
N7Seaweed17SyntheticWordCoreE
adgjmptwN7Seaweed15SyllableLatticeE
N7Seaweed16SyllableNodeBaseE
NSt3__120__shared_ptr_emplaceIN7Seaweed21SyntheticSyllableNodeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN7Seaweed21ShuangpinSyllableNodeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN7Seaweed26IncompleteWithToneSyllableENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN7Seaweed17FuzzySyllableNodeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN7Seaweed12SyllableNodeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_pointerIPN7Seaweed25AutoCorrectedSyllableNodeENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN7Seaweed25AutoCorrectedSyllableNodeEEE
NSt3__120__shared_ptr_emplaceIN7Seaweed18SampleSyllableNodeENS_9allocatorIS2_EEEE
N7Seaweed12SyllableNodeE
N7Seaweed17FuzzySyllableNodeE
N7Seaweed25AutoCorrectedSyllableNodeE
N7Seaweed26IncompleteWithToneSyllableE
N7Seaweed21ShuangpinSyllableNodeE
N7Seaweed21SyntheticSyllableNodeE
N7Seaweed28SyntheticEnglishSyllableNodeE
N7Seaweed18SampleSyllableNodeE
N7Seaweed32SyntheticMixedScriptSyllableNodeE
N11InputEngine21WordAttributeProviderE
N7Seaweed35SimplifiedChineseFeatureInterpreterE
N7Seaweed18FeatureInterpreterE
N7Seaweed36TraditionalChineseFeatureInterpreterE
N7Seaweed38TraditionalCantoneseFeatureInterpreterE
?N11InputEngine15CandidateClonerI26ChineseCompletionCandidateEE
26ChineseCompletionCandidate
37ChineseCompletionFixedPhraseCandidate
NSt3__120__shared_ptr_pointerIPN11InputEngine21MecabraResourceLoaderIN7Seaweed17ReverseDictionaryEEENS_14default_deleteIS5_EENS_9allocatorIS5_EEEE
NSt3__114default_deleteIN11InputEngine21MecabraResourceLoaderIN7Seaweed17ReverseDictionaryEEEEE
N11InputEngine24JapaneseRNNLanguageModelE
N11InputEngine38JapanesePhraseLearningCandidateTrackerE
NSt3__120__shared_ptr_pointerIPN11InputEngine26FacemarkLearningDictionaryENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN11InputEngine26FacemarkLearningDictionaryEEE
N7Seaweed25WordLatticeControllerImplE
N7Seaweed21WordLatticeControllerE
N11InputEngine23PartialCandidateTrackerE
N11InputEngine15CandidateClonerINS_25MecabraProactiveCandidateEEE
N11InputEngine25MecabraProactiveCandidateE
N11InputEngine27JapaneseSpecialtyDictionaryE
N11InputEngine19SpecialtyDictionaryE
21ChinesePredictionWord
N5MeCab13TokenizerImplI12mecab_node_t12mecab_path_tEE
N5MeCab13scoped_stringE
N5MeCab12scoped_arrayIcEE
N5MeCab12CharPropertyE
N5MeCab8FreeListI23mecab_dictionary_info_tEE
?N5MeCab11LatticeImplE
N5MeCab7LatticeE
N5MeCab10scoped_ptrINS_12StringBufferEEE
N5MeCab9AllocatorI12mecab_node_t12mecab_path_tEE
N5MeCab8FreeListI12mecab_node_tEE
N5MeCab10scoped_ptrINS_8FreeListI12mecab_node_tEEEE
N5MeCab10scoped_ptrINS_8FreeListI12mecab_path_tEEEE
N5MeCab10scoped_ptrINS_13ChunkFreeListIcEEEE
N5MeCab10scoped_ptrINS_14NBestGeneratorEEE
N5MeCab12scoped_arrayI25trie_search_result_type_tEE
N5MeCab10scoped_ptrINS_9AllocatorI12mecab_node_t12mecab_path_tEEEE
N5MeCab6WriterE
N11InputEngine7SegmentE
N11InputEngine42MecabraCharacterPhraseInputAnalysisSessionE
N7Seaweed24SeaweedMutableDictionaryE
N7Seaweed36SeaweedFileMappedImmutableDictionaryE
N7Seaweed34SeaweedInMemoryImmutableDictionaryE
N7Seaweed28SeaweedAddressBookDictionaryE
N7Seaweed25SeaweedUserWordDictionaryE
NSt3__120__shared_ptr_pointerIPN11InputEngine13AsyncResourceINS1_14EnglishLexiconEEENS_14default_deleteIS4_EENS_9allocatorIS4_EEEE
NSt3__114default_deleteIN11InputEngine13AsyncResourceINS1_14EnglishLexiconEEEEE
NSt3__110__function6__funcIZN11InputEngine14EnglishLexicon23enumerateMatchedCursorsERKNS_8functionIFvPK9_LXCursorRbEEEbE3$_0NS_9allocatorISD_EEFvRKNS3_11CursorTupleEEEE
NSt3__110__function6__baseIFvRKN11InputEngine14EnglishLexicon11CursorTupleEEEE
ZN11InputEngine14EnglishLexicon23enumerateMatchedCursorsERKNSt3__18functionIFvPK9_LXCursorRbEEEbE3$_0
NSt3__110__function6__funcIZN11InputEngine14EnglishLexicon20enumerateCompletionsEPK10__CFStringRKNS_8functionIFvPK9_LXCursorRbEEEmtdE3$_1NS_9allocatorISG_EEFvRKNS3_11CursorTupleEEEE
ZN11InputEngine14EnglishLexicon20enumerateCompletionsEPK10__CFStringRKNSt3__18functionIFvPK9_LXCursorRbEEEmtdE3$_1
N11InputEngine25MecabraCantoneseTokenizerE
N11InputEngine39MecabraCharacterPhraseInputCandidateSetE
13CharacterNode
N11InputEngine21JapaneseLanguageModelE
32ReadingLookupDictionaryException
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/agent.cc
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/agent.cc:13: MARISA_NULL_ERROR: str == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/agent.cc:21: MARISA_NULL_ERROR: (ptr == NULL) && (length != 0)
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/agent.cc:36: MARISA_STATE_ERROR: state_.get() != NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/agent.cc:38: MARISA_MEMORY_ERROR: state_.get() == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/scoped-ptr.h
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/scoped-ptr.h:19: MARISA_RESET_ERROR: (ptr != NULL) && (ptr == ptr_)
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/io/mapper.cc
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/io/mapper.cc:55: MARISA_NULL_ERROR: filename == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/io/mapper.cc:63: MARISA_NULL_ERROR: (ptr == NULL) && (size != 0)
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/io/mapper.cc:71: MARISA_STATE_ERROR: !is_open()
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/io/mapper.cc:72: MARISA_IO_ERROR: size > avail_
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/io/mapper.cc:99: MARISA_STATE_ERROR: !is_open()
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/io/mapper.cc:100: MARISA_IO_ERROR: size > avail_
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/io/mapper.cc:141: MARISA_IO_ERROR: ::stat(filename, &st) != 0
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/io/mapper.cc:146: MARISA_IO_ERROR: fd_ == -1
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/io/mapper.cc:149: MARISA_IO_ERROR: origin_ == MAP_FAILED
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/io/reader.cc
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/io/reader.cc:27: MARISA_NULL_ERROR: filename == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/io/reader.cc:68: MARISA_STATE_ERROR: !is_open()
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/io/reader.cc:94: MARISA_IO_ERROR: file == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/io/reader.cc:113: MARISA_STATE_ERROR: !is_open()
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/io/reader.cc:129: MARISA_IO_ERROR: size_read <= 0
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/io/reader.cc:134: MARISA_IO_ERROR: ::fread(buf, 1, size, file_) != size
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/io/reader.cc:138: MARISA_IO_ERROR: !stream_->read(static_cast<char *>(buf), size)
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/io/reader.cc:140: MARISA_IO_ERROR: std::ios_base::failure
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/io/writer.cc
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/io/writer.cc:68: MARISA_STATE_ERROR: !is_open()
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/io/writer.cc:113: MARISA_STATE_ERROR: !is_open()
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/io/writer.cc:129: MARISA_IO_ERROR: size_written <= 0
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/io/writer.cc:134: MARISA_IO_ERROR: ::fwrite(data, 1, size, file_) != size
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/io/writer.cc:135: MARISA_IO_ERROR: ::fflush(file_) != 0
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/io/writer.cc:139: MARISA_IO_ERROR: !stream_->write(static_cast<const char *>(data), size)
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/io/writer.cc:141: MARISA_IO_ERROR: std::ios_base::failure
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/louds-trie.cc
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/louds-trie.cc:73: MARISA_BOUND_ERROR: agent.query().id() >= size()
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/louds-trie.cc:451: MARISA_MEMORY_ERROR: next_trie_.get() == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/louds-trie.cc:468: MARISA_MEMORY_ERROR: next_trie_.get() == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/louds-trie.cc:542: MARISA_MEMORY_ERROR: next_trie_.get() == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/louds-trie.cc:568: MARISA_MEMORY_ERROR: next_trie_.get() == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/config.h
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/config.h:59: MARISA_CODE_ERROR: (config_flags & ~MARISA_CONFIG_MASK) != 0
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/config.h:101: MARISA_CODE_ERROR: undefined cache level
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/config.h:121: MARISA_CODE_ERROR: undefined tail mode
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/config.h:141: MARISA_CODE_ERROR: undefined node order
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/header.h
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/header.h:21: MARISA_FORMAT_ERROR: !test_header(ptr)
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/../io/mapper.h
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/../io/mapper.h:28: MARISA_NULL_ERROR: (objs == NULL) && (num_objs != 0)
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/../io/mapper.h:30: MARISA_SIZE_ERROR: num_objs > (MARISA_SIZE_MAX / sizeof(T))
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/header.h:26: MARISA_FORMAT_ERROR: !test_header(buf)
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/../io/reader.h
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/../io/reader.h:31: MARISA_NULL_ERROR: (objs == NULL) && (num_objs != 0)
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/../io/reader.h:33: MARISA_SIZE_ERROR: num_objs > (MARISA_SIZE_MAX / sizeof(T))
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/../io/writer.h
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/../io/writer.h:30: MARISA_NULL_ERROR: (objs == NULL) && (num_objs != 0)
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/../io/writer.h:32: MARISA_SIZE_ERROR: num_objs > (MARISA_SIZE_MAX / sizeof(T))
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/../vector/bit-vector.h
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/../vector/bit-vector.h:52: MARISA_SIZE_ERROR: size_ == MARISA_UINT32_MAX
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/../vector/vector.h
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/../vector/vector.h:100: MARISA_STATE_ERROR: fixed_
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/../vector/bit-vector.h:135: MARISA_FORMAT_ERROR: temp_num_1s > size_
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/../vector/vector.h:202: MARISA_FORMAT_ERROR: (total_size % sizeof(T)) != 0
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/../vector/vector.h:107: MARISA_STATE_ERROR: fixed_
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/../vector/flat-vector.h
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/../vector/flat-vector.h:134: MARISA_FORMAT_ERROR: temp_value_size > 32
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/../vector/bit-vector.h:153: MARISA_FORMAT_ERROR: temp_num_1s > size_
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/../vector/vector.h:213: MARISA_FORMAT_ERROR: (total_size % sizeof(T)) != 0
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/../vector/flat-vector.h:155: MARISA_FORMAT_ERROR: temp_value_size > 32
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/louds-trie.cc:428: MARISA_MEMORY_ERROR: std::bad_alloc
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/../algorithm/../../scoped-ptr.h
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/../algorithm/../../scoped-ptr.h:19: MARISA_RESET_ERROR: (ptr != NULL) && (ptr == ptr_)
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/tail.cc
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/tail.cc:13: MARISA_NULL_ERROR: offsets == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/tail.cc:36: MARISA_CODE_ERROR: undefined tail mode
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/tail.cc:170: MARISA_RANGE_ERROR: current.length() == 0
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/trie/tail.cc:192: MARISA_SIZE_ERROR: buf_.size() > MARISA_UINT32_MAX
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/vector/vector.h
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/grimoire/vector/vector.h:100: MARISA_STATE_ERROR: fixed_
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/keyset.cc
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/keyset.cc:61: MARISA_NULL_ERROR: (ptr == NULL) && (length != 0)
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/keyset.cc:62: MARISA_SIZE_ERROR: length > MARISA_UINT32_MAX
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/keyset.cc:129: MARISA_MEMORY_ERROR: new_blocks.get() == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/keyset.cc:138: MARISA_MEMORY_ERROR: new_block.get() == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/keyset.cc:151: MARISA_MEMORY_ERROR: new_blocks.get() == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/keyset.cc:159: MARISA_MEMORY_ERROR: new_block.get() == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/keyset.cc:169: MARISA_MEMORY_ERROR: new_blocks.get() == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/keyset.cc:177: MARISA_MEMORY_ERROR: new_block.get() == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/trie.cc
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/trie.cc:14: MARISA_MEMORY_ERROR: temp.get() == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/trie.cc:21: MARISA_NULL_ERROR: filename == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/trie.cc:24: MARISA_MEMORY_ERROR: temp.get() == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/trie.cc:33: MARISA_NULL_ERROR: (ptr == NULL) && (size != 0)
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/trie.cc:36: MARISA_MEMORY_ERROR: temp.get() == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/trie.cc:45: MARISA_NULL_ERROR: filename == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/trie.cc:48: MARISA_MEMORY_ERROR: temp.get() == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/trie.cc:233: MARISA_NULL_ERROR: trie == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/trie.cc:200: MARISA_NULL_ERROR: trie == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/trie.cc:204: MARISA_MEMORY_ERROR: temp.get() == NULL
/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-19/lib/marisa/trie.cc:213: MARISA_STATE_ERROR: trie.trie_.get() == NULL
BOS/EOS
innsbruck
posmap-migration.plist
PosList.plist
posmap-univ2current.plist
posmap-current2univ.plist
allocation failure
gemmlowp error: %s
reference(Lhs: %d cells %dx%d %s, Rhs: %d cells %dx%d %s)
WidthMajor
v8@?0
precompiled_charsmap is empty.
Normalizer model is not available.
length < 0
norm_to_org and normalized are inconsistent
Trie blob is broken.
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-19/src/util.h
'result' Must be non NULL
Cannot open 
input ifstream is null
Model file is broken
Model is not initialized.
Normalizer is not initialized.
output container is null
Empty piece is not allowed.
consumed index is out-of-range.
original index is out-of-range.
all normalized characters are not consumed.
output proto is null
NBestEncode returns empty result
nbest_size must be 0 < nbest_size <= 512 or nbest_size < 0.
/dev/urandom
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-19/src/sentencepiece_processor.cc
LOG(
ERROR
Returns default value 
</s>
Unknown extra_option type
reverse
option 
 is not available.
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-19/ProtocolBuffers/src/google/protobuf/arenastring.h
CHECK failed: initial_value != NULL: 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-19/ProtocolBuffers/src/google/protobuf/repeated_field.h
CHECK failed: (index) >= (0): 
CHECK failed: (index) < (current_size_): 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-19/src/model_factory.cc
Unknown model_type: 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-19/src/char_model.cc
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-19/src/unigram_model.cc
best_node
nbest_size >= 1. Returns empty result.
Too big agenda. shrinking
(num_nodes) < (trie_results.size())
No pieces are loaded.
Cannot build double-array.
No entry is found in the trie.
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-19/third_party/darts_clone/darts.h:703: exception: failed to resize pool: std::bad_alloc
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-19/third_party/darts_clone/darts.h:1141: exception: failed to insert key: negative value
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-19/third_party/darts_clone/darts.h:1143: exception: failed to insert key: zero-length key
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-19/third_party/darts_clone/darts.h:1157: exception: failed to insert key: invalid null character
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-19/third_party/darts_clone/darts.h:1162: exception: failed to insert key: wrong key order
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-19/third_party/darts_clone/darts.h:842: exception: failed to build rank index: std::bad_alloc
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-19/third_party/darts_clone/darts.h:1380: exception: failed to modify unit: too large offset
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-19/third_party/darts_clone/darts.h:1726: exception: failed to build double-array: invalid null character
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-19/third_party/darts_clone/darts.h:1728: exception: failed to build double-array: negative value
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-19/third_party/darts_clone/darts.h:1743: exception: failed to build double-array: wrong key order
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-19/src/sentencepiece_model.pb.cc
CHECK failed: !model_prefix_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
CHECK failed: !input_format_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
CHECK failed: (&from) != (this): 
sentencepiece.TrainerSpec
CHECK failed: !name_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
CHECK failed: !precompiled_charsmap_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
sentencepiece.NormalizerSpec
CHECK failed: !piece_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
sentencepiece.ModelProto.SentencePiece
CHECK failed: trainer_spec_ != NULL: 
CHECK failed: normalizer_spec_ != NULL: 
sentencepiece.ModelProto
CHECK failed: (n) >= (0): 
down_cast
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-19/ProtocolBuffers/src/google/protobuf/stubs/casts.h
f == NULL || dynamic_cast<To>(f) != NULL
CHECK failed: (&other) != (this): 
User defined symbol is not supported.
 is already defined.
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-19/src/model_interface.cc
!result.empty()
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-19/src/sentencepiece.pb.cc
CHECK failed: !surface_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
sentencepiece.SentencePieceText.SentencePiece
CHECK failed: !text_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
sentencepiece.SentencePieceText
sentencepiece.NBestSentencePieceText
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-19/src/bpe_model.cc
Invalid character length.
(index) >= (0)
(index) < (static_cast<int>(symbols.size()))
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-19/src/model_interface.h
Not implemented.
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-19/ProtocolBuffers/src/google/protobuf/message_lite.cc
CHECK failed: !coded_out.HadError(): 
parse
Can't 
 message of type "
" because it is missing required fields: 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-19/ProtocolBuffers/src/google/protobuf/wire_format_lite.cc
CHECK failed: (value.size()) <= (kint32max): 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-19/ProtocolBuffers/src/google/protobuf/io/coded_stream.cc
A protocol message was rejected because it was too big (more than 
 bytes).  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
CHECK failed: (buffer_size) >= (0): 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-19/ProtocolBuffers/src/google/protobuf/generated_message_util.cc
Not implemented field number 
 with type 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-19/ProtocolBuffers/src/google/protobuf/stubs/common.cc
This program requires version 
 of the Protocol Buffer runtime library, but the installed version is 
.  Please update your library.  If you compiled the program yourself, make sure that your headers are from the same version of Protocol Buffers as your link-time library.  (Version verification failed in "
This program was compiled against version 
 of the Protocol Buffer runtime library, which is not compatible with the installed version (
).  Contact the program author for an update.  If you compiled the program yourself, make sure that your headers are from the same version of Protocol Buffers as your link-time library.  (Version verification failed in "
%d.%d.%d
INFO
WARNING
FATAL
[libprotobuf %s %s:%d] %s
pthread_mutex_lock: 
pthread_mutex_unlock: 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-19/ProtocolBuffers/src/google/protobuf/io/zero_copy_stream.cc
This ZeroCopyOutputStream doesn't support aliasing. Reaching here usually means a ZeroCopyOutputStream implementation bug.
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-19/ProtocolBuffers/src/google/protobuf/io/zero_copy_stream_impl_lite.cc
CHECK failed: (last_returned_size_) > (0): 
BackUp() can only be called after a successful Next().
CHECK failed: (count) <= (last_returned_size_): 
CHECK failed: (count) >= (0): 
CHECK failed: target_ != NULL: 
Cannot allocate buffer larger than kint32max for 
StringOutputStream.
CHECK failed: (count) <= (target_->size()): 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-19/ProtocolBuffers/src/google/protobuf/extension_set.cc
Non-primitive types can't be packed.
can't reach here.
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-19/ProtocolBuffers/src/google/protobuf/arena.cc
CHECK failed: (min_bytes) <= (std::numeric_limits<size_t>::max() - kHeaderSize): 
addListNode
/Library/Caches/com.apple.xbs/Sources/NLPUtils_Sim/NLPUtils-37/Source/BurstTrie.cpp
listcount <= trie->reserved[ContainerSize]
addListNodeRanked
advanceMapCursorTrieList
cursor->prfxlen <= head->restlen
traverseFromMapCursorTrieList
cursor.prfxlen <= head->restlen
reverseBurst
items.size() < sizeThreshold
levels.size() <= keyLen + 1
burstTrieCreateCursorWithTrieLevelRef
nullptr == trie->mapbase
@"NSDictionary"8@?0
/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-924/src/im/viterbi.cpp
tokenizer_->open(param)
connector_->open(param)
cost-factor
cost_factor_ > 0
cost-factor is empty
/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-924/src/im/viterbisub.h
bestNode
too long sentence.
^{LanguageModel=^^?^vq^{__CFString}{unordered_map<const void *, void (*)(__CFNotificationCenter *, void *, const __CFString *, const void *, const __CFDictionary *), std::__1::hash<const void *>, std::__1::equal_to<const void *>, std::__1::allocator<std::__1::pair<const void *const, void (*)(__CFNotificationCenter *, void *, const __CFString *, const void *, const __CFDictionary *)> > >={__hash_table<std::__1::__hash_value_type<const void *, void (*)(__CFNotificationCenter *, void *, const __CFString *, const void *, const __CFDictionary *)>, std::__1::__unordered_map_hasher<const void *, std::__1::__hash_value_type<const void *, void (*)(__CFNotificationCenter *, void *, const __CFString *, const void *, const __CFDictionary *)>, std::__1::hash<const void *>, true>, std::__1::__unordered_map_equal<const void *, std::__1::__hash_value_type<const void *, void (*)(__CFNotificationCenter *, void *, const __CFString *, const void *, const __CFDictionary *)>, std::__1::equal_to<const void *>, true>, std::__1::allocator<std::__1::__hash_value_type<const void *, void (*)(__CFNotificationCenter *, void *, const __CFString *, const void *, const __CFDictionary *)> > >={unique_ptr<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<const void *, void (*)(__CFNotificationCenter *, void *, const __CFString *, const void *, const __CFDictionary *)>, void *> *> *[], std::__1::__bucket_list_deallocator<std::__1::allocator<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<const void *, void (*)(__CFNotificationCenter *, void *, const __CFString *, const void *, const __CFDictionary *)>, void *> *> *> > >={__compressed_pair<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<const void *, void (*)(__CFNotificationCenter *, void *, const __CFString *, const void *, const __CFDictionary *)>, void *> *> **, std::__1::__bucket_list_deallocator<std::__1::allocator<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<const void *, void (*)(__CFNotificationCenter *, void *, const __CFString *, const void *, const __CFDictionary *)>, void *> *> *> > >=^^{__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<const void *, void (*)(__CFNotificationCenter *, void *, const __CFString *, const void *, const __CFDictionary *)>, void *> *>}{__bucket_list_deallocator<std::__1::allocator<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<const void *, void (*)(__CFNotificationCenter *, void *, const __CFString *, const void *, const __CFDictionary *)>, void *> *> *> >={__compressed_pair<unsigned long, std::__1::allocator<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<const void *, void (*)(__CFNotificationCenter *, void *, const __CFString *, const void *, const __CFDictionary *)>, void *> *> *> >=Q}}}}{__compressed_pair<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<const void *, void (*)(__CFNotificationCenter *, void *, const __CFString *, const void *, const __CFDictionary *)>, void *> *>, std::__1::allocator<std::__1::__hash_node<std::__1::__hash_value_type<const void *, void (*)(__CFNotificationCenter *, void *, const __CFString *, const void *, const __CFDictionary *)>, void *> > >={__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<const void *, void (*)(__CFNotificationCenter *, void *, const __CFString *, const void *, const __CFDictionary *)>, void *> *>=^{__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<const void *, void (*)(__CFNotificationCenter *, void *, const __CFString *, const void *, const __CFDictionary *)>, void *> *>}}}{__compressed_pair<unsigned long, std::__1::__unordered_map_hasher<const void *, std::__1::__hash_value_type<const void *, void (*)(__CFNotificationCenter *, void *, const __CFString *, const void *, const __CFDictionary *)>, std::__1::hash<const void *>, true> >=Q}{__compressed_pair<float, std::__1::__unordered_map_equal<const void *, std::__1::__hash_value_type<const void *, void (*)(__CFNotificationCenter *, void *, const __CFString *, const void *, const __CFDictionary *)>, std::__1::equal_to<const void *>, true> >=f}}}}8@?0
en_US
Montreal-languagemodel
^{LanguageModelLoader=i{CFScopedPtr<const __CFURL *>=^{__CFURL}}{CFScopedPtr<const __CFURL *>=^{__CFURL}}{unique_ptr<InputEngine::LanguageModel, std::__1::default_delete<InputEngine::LanguageModel> >={__compressed_pair<InputEngine::LanguageModel *, std::__1::default_delete<InputEngine::LanguageModel> >=^{LanguageModel}}}{unique_ptr<InputEngine::AsyncResource<InputEngine::LanguageModel>, std::__1::default_delete<InputEngine::AsyncResource<InputEngine::LanguageModel> > >={__compressed_pair<InputEngine::AsyncResource<InputEngine::LanguageModel> *, std::__1::default_delete<InputEngine::AsyncResource<InputEngine::LanguageModel> > >=^{AsyncResource<InputEngine::LanguageModel>}}}}8@?0
^{AsyncResource<InputEngine::LanguageModel>={unique_ptr<InputEngine::LanguageModel, std::__1::default_delete<InputEngine::LanguageModel> >={__compressed_pair<InputEngine::LanguageModel *, std::__1::default_delete<InputEngine::LanguageModel> >=^{LanguageModel}}}^{dispatch_group_s}^{dispatch_queue_s}{once_flag=Q}@?{atomic<InputEngine::AsyncResource<InputEngine::LanguageModel>::State>={__cxx_atomic_impl<InputEngine::AsyncResource<InputEngine::LanguageModel>::State, std::__1::__cxx_atomic_base_impl<InputEngine::AsyncResource<InputEngine::LanguageModel>::State> >=Ai}}{mutex={_opaque_pthread_mutex_t=q[56c]}}{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}{unique_lock<std::__1::mutex>=^{mutex}B}}8@?0
unique_lock::lock: references null mutex
unique_lock::lock: already locked
emoji.dat
no tone change
tone change
Base phrase: %s baseScore=%f candidateWord: %s homophoneForWord: %s homophoneScore=%f
^{MecabraResourceLoader<Lexicon>=i{unique_ptr<Lexicon, std::__1::default_delete<Lexicon> >={__compressed_pair<Lexicon *, std::__1::default_delete<Lexicon> >=^{Lexicon}}}}8@?0
bcdfghjklmprstvwxyz
qwrtpsdfghjklzxcvbnm
v24@?0r^{vector<unsigned short, std::__1::allocator<unsigned short> >=^S^S{__compressed_pair<unsigned short *, std::__1::allocator<unsigned short> >=^S}}8^B16
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
v32@?0@"NSString"8i16B20^B24
v24@?0r^{CharacterNode=^^?^{__CFString}iBB}8^B16
v36@?0r^S8q16i24^B28
^{__CFString=}16@?0^{__CFString=}8
v24@?0S8f12^B16
Filtered by distance: %s, %.4f
Filtered by syllable count: %s, %.4f, syllableCount = %ld, bestSyllableCount = %ld
Filtered by score margin: %s, score = %.4f, bestcore = %.4f
v12@?0I8
v24@?0^{__Candidate=}8^B16
Nbest: 
%s, %.4f
PRAutocorrectionContext
rank
extension
v20@?0^{__CFString=}8C16
v32@?0^{map<std::__1::basic_string<char>, std::__1::shared_ptr<EntryFieldValue>, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, std::__1::shared_ptr<EntryFieldValue> > > >={__tree<std::__1::__value_type<std::__1::basic_string<char>, std::__1::shared_ptr<EntryFieldValue> >, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, std::__1::shared_ptr<EntryFieldValue> >, std::__1::less<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__value_type<std::__1::basic_string<char>, std::__1::shared_ptr<EntryFieldValue> > > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<std::__1::basic_string<char>, std::__1::shared_ptr<EntryFieldValue> >, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, std::__1::shared_ptr<EntryFieldValue> >, std::__1::less<std::__1::basic_string<char> >, true> >=Q}}}8i16i20^B24
lm/Japanese.lm
ja.rnnlm
model.bin
sp.model
Settings.plist
setAdditionalConversionDictionaries
.dic
/zip_code-ja.dat
blocklist.dat
%@*%@
CharacterMap
/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-924/mecabra/CharacterMap.cpp
result.second
v32@?0{?=qq}8^B24
com.apple.mecabra.
Serial
UserInteractive
UserInitiated
Default
Utility
Background
Unspecified
v24@?0r^S8Q16
J_Numeral.dict
Josu.data
Library/Keyboard
Tokenizer
^{MecabraChineseTokenizerBase=^^?}8@?0
theta
current model is not available
atomic model replacement is not supported
Model is not available
input-method-language
set input method language
rcfile
FILE
use FILE as resource file
dicdir
set DIR  as a system dicdir
userdic
use FILE as a user dictionary
learndic
use FILE as a learn dictionary
word-completion-dic
use FILE as a word completion dictionary
lattice-level
lattice information level (default 0)
dictionary-info
show dictionary information and exit
all-morphs
output all morphs(default false)
output-format-type
TYPE
set output format type (wakati,none,...)
partial
partial parsing mode
node-format
%m\t%H\n
use STR as the user-defined node format
unk-format
use STR as the user-defined unk format
bos-format
use STR as the user-defined bos format
eos-format
EOS\n
use STR as the user-defined eos format
unk-feature
use STR as the feature for unknown word
input-buffer-size
set input buffer size (default 8192)
dump-config
dump MeCab parameters
open-mutable-dictionary
open dictioanry with mutable mode (experimental)
allocate-sentence
allocate new memory for input sentence
nbest
output N best results (default 1)
0.75
FLOAT
set temparature parameter theta (default 0.75)
output
set the output file name
version
show the version and exit.
help
show this help and exit.
dicdir
matrix.bin
/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-924/src/im/compressed_connector.cpp
cmmap_->begin()
matrix is NULL
cmmap_->size() >= 2
file size is invalid: 
lsize_ > 0
left size is invalid
rsize_ > 0
num_elements > 0
number of elements is invalid
no such file or directory: 
format error: 
/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-924/src/im/mmap.h
false
unknown open mode: 
(fd = open_create__(filename, flag | O_BINARY, S_IRUSR | S_IWUSR)) >= 0
open failed: 
(fd = open__(filename, flag | O_BINARY)) >= 0
fstat(fd, &st) >= 0
failed to get file size: 
(p = reinterpret_cast<char *> (mmap(0, length, prot, MAP_SHARED, fd, 0))) != MAP_FAILED
mmap() failed: 
^{SeaweedFileMappedImmutableDictionary=^^?I^{BurstTrie}IIIi{shared_ptr<File<char> >=^{File<char>}^{__shared_weak_count}}^{Token}*{vector<BurstTrie, std::__1::allocator<BurstTrie> >=^{BurstTrie}^{BurstTrie}{__compressed_pair<BurstTrie *, std::__1::allocator<BurstTrie> >=^{BurstTrie}}}{vector<unsigned int *, std::__1::allocator<unsigned int *> >=^^I^^I{__compressed_pair<unsigned int **, std::__1::allocator<unsigned int *> >=^^I}}^{FeatureInterpreter}{vector<unsigned int, std::__1::allocator<unsigned int> >=^I^I{__compressed_pair<unsigned int *, std::__1::allocator<unsigned int> >=^I}}{vector<BurstTrie, std::__1::allocator<BurstTrie> >=^{BurstTrie}^{BurstTrie}{__compressed_pair<BurstTrie *, std::__1::allocator<BurstTrie> >=^{BurstTrie}}}{vector<unsigned int *, std::__1::allocator<unsigned int *> >=^^I^^I{__compressed_pair<unsigned int **, std::__1::allocator<unsigned int *> >=^^I}}[256C]}8@?0
v24@?0^{_LXCursor=}8*16
CPSearchParameters
^{CPSearchParameters=fffffffff}8@?0
keyRadii
CTCPathScoreMargin
CTCLMScorerAlpha
CTCFTotalDistanceDeviationRatio
CTCMinDistanceThreshold
CTCFirstCharDistanceThreshold
CTCLastCharDistanceThreshold
CTCShortPathDistance
CTCLongPathDistance
heteronyms.dat
NumberValue.index
openCount
initiallyOpenedCallCount
lastlyClosedCallCount
q24@?0@8@16
%s : %ld
Token count: %ld, UNK count = %ld
RevertLearning
PerformLearning
%s:%s
Contents
zip_code.dat
com.apple.TrieAccessMethod
com.apple.HeapAccessMethod
com.apple.TestAccessMethod-Inspector
IDXDefaultProperty
com.apple.DictionaryServices
plist
Resources
Contents/
Info.plist
IDXDictionaryVersion
IDXDictionaryIndexes
IDXIndexName
IDXIndexPath
IDXIndexAccessMethod
IDXIndexKeyMatchingMethods
IDXIndexDataSizeLength
IDXIndexWritable
IDXIndexSupportDataID
IDXIndexBigEndian
IDXIndexDataFields
IDXExternalDataFields
IDXFixedDataFields
IDXVariableDataFields
IDXDataFieldName
IDXDataSize
IDXDataSizeLength
IDXExactMatch
IDXPrefixMatch
IDXCommonPrefixMatch
IDXWildcardMatch
IDXAllMatch
IDXExactMatchVoicedAmbi
IDXExactMatchSmallAmbi
IDXExactMatchVoicedAndSmallAmbi
IDXPrefixMatchVoicedAmbi
IDXPrefixMatchSmallAmbi
IDXPrefixMatchVoicedAndSmallAmbi
IDXIndex
<%@>
<#invalid index>
<IDXIndexRef %p>{access method = %@, index = %@, open# = %d}
<IDXIndexRef %p>{access method = %@, #invalid index}
HeapDataCompressionType
HeapDataCompressionBlockSize
HeapDataCompressionMaxBlockCount
Failed to add a new data since record count exceeds limit (%lld) defined in the current compaction-type.
Record count exceeds limit (%lld).
TrieIndexCompressionType
TrieAuxiliaryDataOptions
TrieAuxiliaryDataFile
TrieSubIndexPath
%@_aux.data
Packed Homograph
/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-924/mecabra/Dictionary/MarisaTrieBuilder.cpp
m_trie.lookup(m_agent)
cannot find entry in trie.
Adding a single English word candidate
enumerateEntriesWithPrefix
/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-924/src/im/dictionary.cpp
!(option & MECAB_JAPANESE_ROMAJI)
dmmap_->size() >= 100
dictionary file is broken: 
(magic ^ DictionaryMagicID) == dmmap_->size()
ptr == dmmap_->end()
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
com.apple.inMemoryImmutableDictionaryDispatcher.modify
com.apple.inMemoryImmutableDictionaryDispatcher.build
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
GestureWrapper
LayoutKeyWrapper
system
mixed
single_character
category
emoji
supplement
english
asset
asset_mixed
region
Wrong dictionary type string
Cannot load dictionary index property plist.
Cannot find properties for dictionary type 
feature_format
full
skip_syllable_lengths
Unrecognized feature format.
indexes
Cannot find index property array for dictionary type 
is_reversed
type
string
syllable_id
syllable_id based dictionary key must be in reversed direction
Syllable ID indexes must be before string indexes
Unrecognized dictionary key type.
has_sub_index_for_prefix
Analyses
DynamicDictionaries
SessionReset
MecabraAnalysisOption
CurrentAnalysisString
CandidateContext
InputContext
AppContext
GeometryData
GesturesData
Empty Input Context.
Empty App Context.
PosInfo.plist
properNounPosID
numeralPosID
commonNounPosID
sahenNounPosID
placeNamePosID
adjectivePosID
adverbPosID
suffixPosID
verbPosID
personNamePosID
personLastNamePosID
personFirstNamePosID
nounRegionBeginPosID
nounRegionEndPosID
verbRegionBeginPosID
verbRegionEndPosID
auxVerbRegionBeginPosID
auxVerbRegionEndPosID
depVerbRegionBeginPosID
depVerbRegionEndPosID
particleRegionBeginPosID
particleRegionEndPosID
sahenImperativePosID
sahenConjunctivePosID
suffixAdjectiveBasePosID
suffixAdjectiveAttributivePosID
auxSymbolRegionBeginPosID
auxSymbolRegionEndPosID
shouldResetConstraint
phraseFlags
UTF-8
EUC-JP
SHIFT-JIS
UTF-16
UTF-16BE
UTF-16LE
charset 
 is not defined, use EUC-JP
allocator<const T>::allocate(size_t n) 'n' exceeds maximum supported size
bcdfghjklmpqrstvwxyz
v24@?0r^{mecab_node_t=^{mecab_node_t}^{mecab_node_t}^{mecab_node_t}^{mecab_node_t}^{mecab_path_t}^{mecab_path_t}**IIIssSSSSqSCCCC[2c]}8^B16
/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-924/src/param.cpp
pos != std::string::npos
unknown
unrecognized option `
` requres an argument
` dosen't allow an argument
mecab
help
version
MeCab: Yet Another Part-of-Speech and Morphological Analyzer
Copyright(C) 2001-2008 Taku Kudo 
Copyright(C) 2004-2008 Nippon Telegraph and Telephone Corporation
Usage: 
 [options] files
 of 
0.97
, --
/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-924/src/im/tagger.cpp
NULL pointer is given
lattice_level() >= 1
use -l option to obtain N-Best results. e.g., mecab -N10 -l1
sjis
shift-jis
shift_jis
cp932
euc_jp
euc-jp
utf8
utf_8
utf-8
ascii
utf-16be
utf-16le
utf-16
allocate-sentence
partial
all-morphs
marginal
nbest
lattice-level
HOME
.mecabrc
MECABRC
$(rcpath)
dicrc
Seed
Hyoki
Yomi
__??info??__
Keyword_aux.data
@"NSMutableArray"16@?0@"NSString"8
v56@?0@"NSString"8{_NSRange=QQ}16{_NSRange=QQ}32^B48
ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz
1234512344***=
qwertyuiopasdfghjklcvbnmzxxz
qwertyuiopasdfghjklxcvbnm
12345
[LexicalPreferenceLearner] Rewriting candidate from
[LexicalPreferenceLearner] Rewriting candidate to
## Lexical preference applied ##
[PunctuationPreferenceLearner] Rewriting candidate from
[PunctuationPreferenceLearner] Rewriting candidate to
[MJNP::expandPhrasesWithLanguageModel] Adding an LM expansion candidate
## Before finalizing weights ##
## After finalizing weights ##
Previous candidate
Last-bunsetsu
stabilizeCandidates
Adding a bigram learning dictionary candidate
Adding a learned phrase bigram prefix candidate
## Final ##
v32@?0{UTF16String=^SQ}8^B24
[MJ:searchPhrasesByPosContext]
v28@?0{unique_ptr<InputEngine::ConversionCandidate, std::__1::default_delete<InputEngine::ConversionCandidate> >={__compressed_pair<InputEngine::ConversionCandidate *, std::__1::default_delete<InputEngine::ConversionCandidate> >=^{ConversionCandidate}}}8s16^B20
kanakb.dic
null
pos_prediction.dat
word_cache.dat
v24@?0^{__CFString=}8^B16
[reanalysis]
## Before reranking ##
## After reranking ##
assetDictionariesDidChange
-p -d %@ -l1
 -u %@
/Library/Dictionaries
 -g %@
 -i ja
 -i zh-Hans
 -i zh-Hant
Hans
Hant
zh-Hans
zh-Hant
yue-Hant
zh-Hans-Pinyin10
zh-Hans-Pinyin
zh-Hans-Stroke
zh-Hans-Wubixing
zh-Hant-Cangjie
zh-Hant-Pinyin10
zh-Hant-Pinyin
yue-Hant-Pinyin10
yue-Hant-Pinyin
yue-Hant-HWR
yue-Hant-Stroke
yue-Hant-Cangjie
zh-Hant-Stroke
zh-Hant-Zhuyin
ja-Romaji
ja-Kana
zh-Hans-HWR
zh-Hant-HWR
true
IPHONE_SIMULATOR_ROOT
createSystemRootPath
/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-924/mecabra/MecabraMiscUtilities.cpp
simulatorRoot
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
wstring_convert: to_bytes error
Cannot initialize ICU transliterator.
Cannot initialize ICU number formatter.
v28@?0I8d12^B20
0123456789(.
inputMethodType
learningEnabled
dynamicLMEnabled
useSpecialSymbol
syncLearningData
liteMode
systemDictionaryDirectory
learningDictionaryDirectory
additionalDictionaryDirectories
staticLanguageModelBundle
dynamicLanguageModelBundle
wubixingStandard
isEndingWithPunctuation
(left[
] inline[
] App[
%@%@
v36@?0{?=qq}8I24^B28
Rejected: 
[predictPhrasesWithLanguageModel]
[expandPhrasesWithLanguageModel]
wstring_convert: from_bytes error
string_view::substr
build
/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-924/mecabra/DynamicDictionary.cpp
(entriesBufferPos + 1 + keyLength + 1 + 1 + valueLength) <= entriesBufferLength
(entriesBufferPos + 1 + valueLength) <= entriesBufferLength
v28@?0I8Q12^B20
sys.dic
emoji_adornment.plist
emojis
shuffle
Adding an emoji adornment.
v24@?0{UTF16String=^SQ}8
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
.%@.lock
v24@?0^{IDXUserDictionaryEntry=^Sq^Sq^SqI}8^B16
Reading
Surface
Syllables
WordLengths
ReservedString
ReservedInteger
SurfaceSegments
ReadingSegments
PartOfSpeech
Attributes
PinyinReading
ZhuyinReading
PinyinSyllableLengths
ZhuyinSyllableLengths
completion-learning-dictionary-zh-Hans
completion-learning-dictionary-zh-Hant
completion-learning-zh-Hans.dictionary
completion-learning-zh-Hant.dictionary
ReadingMappedString
/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-924/mecabra/ReadingMappedString.cpp
unmappedString
com.apple.languageIntelligenceCJK
languageIdentifier
inputMethodIdentifier
phraseCandidateAccepted
systemDictionaryCandidateAccepted
partialCandidateAccepted
abbreviatedPinyinCandidateAccepted
abbreviatedZhuyinCandidateAccepted
toneZhuyinCandidateAccepted
tonelessZhuyinCandidateAccepted
toneMixedZhuyinCandidateAccepted
extensionCandidateAccepted
userDictionaryConversionCandidateAccepted
learningDictionaryConversionCandidateAccepted
addressBookConversionCandidateAccepted
autocorrectionCandidateAccepted
otaRegionalLexiconCandidateAccepted
otaNonRegionalLexiconCandidateAccepted
emojiCandidateAccepted
fuzzyPinyinCandidateAccepted
englishCandidateAccepted
lstmPredictionCandidateAccepted
ngramPredictionCandidateAccepted
lexiconCompletionPredictionCandidateAccepted
firstConversionCandidateAccepted
secondConversionCandidateAccepted
thirdConversionCandidateAccepted
fourthConversionCandidateAccepted
top10ConversionCandidateAccepted
conversionCandidateAccepted
predictionCandidateAccepted
completionCandidatesAppeared
predictionCandidateListDisplayed
phraseLearningCandidateKeystrokeSavings
candidateWithStaticLMProb
candidateWithTop1StaticLMProb
candidateWithTop4StaticLMProb
candidateWithHybridCost
candidateWithTop1HybridCost
candidateWithTop4HybridCost
fuzzyPinyinEnabled
acceptedCandidateLength
acceptedSyllableLength
acceptedPartialCandidateSyllableLengths
acceptedEnglishCandidateLength
pinyin10KeySyllableSelected
pinyin10KeyFlickInput
acceptedCandidateTypingStyle
TapTyping
ContinuousPath
TapTypingAndContinuousPathMixed
HardwareKeyboard
shapeBasedSingleCharacterCandidateAccepted
shapeBasedWordCandidateAccepted
shapeBasedPinyinConvertedCandidateAccepted
wubi86
wubi98
wubiNewCentury
^{File<char>=*Q{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}iB}8@?0
unknown open mode for file 
could not open file 
failed to get file size for 
mmap failed for 
failed to read from 
Wrong version from 
assetDataFilePaths
assetDataRegionIdentifier
Wubixing
v24@?0r^{bigram_entry_t=ssSSS{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}f}8^B16
Adding a phrase candidate
exact
prefix
v20@?0i8^B12
v32@?0r*8i16i20^B24
%@,%@
v16@?0r^{IDXUserDictionaryEntry=^Sq^Sq^SqI}8
v24@?0^{__CFString=}8^{__CFString=}16
Words
Words_tmp
DROP TABLE Assist
PRAGMA journal_mode = WAL;
:memory:
main
ROLLBACK
BEGIN IMMEDIATE
COMMIT
init
/System/Volumes/Data/SWE/iOS/BuildRoots/BuildRoot938/Applications/Xcode.app/Contents/Developer/Platforms/WatchSimulator.platform/Developer/SDKs/WatchSimulator7.0.Internal.sdk/usr/local/include/nlp/BurstTrieAdapter.h
m_mutable
m_trie
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
addEntry
removeEntry
clear
ambiguousDfsTraverse
/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-924/src/AmbiguousTrieAdapter.hpp
m_trie->isValid(curCursor)
operator()
m_trie->isValid(cursor)
DELETE FROM Words WHERE Identifier = ?
SELECT Identifier FROM Words ORDER BY Seed DESC
SELECT Identifier FROM Words ORDER BY Identifier ASC
SELECT Identifier, 
 FROM Words
SELECT Identifier FROM Words WHERE Identifier = ? 
 AND 
 = ?
INSERT INTO 
 (Seed
) VALUES (?
SELECT Seed
 FROM Words WHERE Identifier = ?
UPDATE Words SET Seed = ? WHERE Identifier = ?
UPDATE Words SET Identifier = ? WHERE Identifier = ?
UPDATE Assist SET LastSeedValue = ? WHERE Identifier = 1
UPDATE Assist SET LastUpdateTime = ? WHERE Identifier = 1
UPDATE Assist SET Version = ? WHERE Identifier = 1
SELECT COUNT(*) FROM Words
CREATE TABLE 
 (Identifier INTEGER PRIMARY KEY, Seed INTEGER
BLOB
INTEGER
CREATE TABLE Assist (Identifier INTEGER PRIMARY KEY, LastSeedValue INTEGER, LastUpdateTime REAL, Version INTEGER DEFAULT 0)
INSERT INTO Assist (LastSeedValue, LastUpdateTime, Version) VALUES (0, 0, 0)
SELECT LastSeedValue FROM Assist WHERE Identifier = 1
SELECT 
SELECT Identifier FROM Words WHERE 
SELECT Identifier, Seed, 
zh-Hans
/System/Library/PrivateFrameworks/InputTranscoder.framework/InputTranscoder
/System/Library/PrivateFrameworks/InputTranscoder.framework/Contents/MacOS/InputTranscoder
kITDecoderLocaleKey
ITDecoderCreate
ITDecoderSetLinguisticContext
ITDecoderClearNeuralNetworkBuffer
ITDecoderEnumerateCandidates
ITCandidateEnumerateTokenIDs
ITCandidateGetScore
ITTouchTranscoderSessionAddEvent
ITTouchTranscoderSessionEnumerateCandidates
kITTouchTranscoderLocaleKey
ITTouchTranscoderCreateWithKeyboardLayout
ITTouchTranscoderUpdateKeyboardLayout
ITTouchTranscoderCreateSession
ITCandidateGetString
v32@?0r^S8q16^B24
Adding a zip code candidate
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
ja_JP
MECABRA_TEST
GGGGGyy/MM/dd
EEEE
MMMM
GGGGGy
 000000000000
analysisString
T@"NSString",C,N,V_analysisString
characterInformation
T@"NSArray",&,N,V_characterInformation
codeLookupInformation
T@"NSArray",&,N,V_codeLookupInformation
TB,N,GisEmoji,V_emoji
language
Ti,N,V_language
dicdir
char.bin
/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-924/src/im/char_property.cpp
fsize == cmmap_->size()
invalid file size: 
v32@?0^{?=^{Token}*}8Q16^B24
/System/Library/PrivateFrameworks/ProofReader.framework
Traditional - Simplified
Simplified - Traditional
abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ
failed to set backup exclusion for item at URL: %s
[[:Hani:]]
zh-Hant
yue-Hant
map::at:  key not found
[ME::addCandidateFromMecabNode] Adding a partial candidate
[ME::addCandidateFromMecabNode] Adding a non-partial candidate
[MJ::makeMecabSingleWordCandidates] Adding a single-word prefix candidate
[MJ::makeMecabSingleWordCandidates] Adding a single-word exact candidate
Adding a partial phrase candidate
B24@?0r^S8q16
taiwan
tibet
/System/Library/PrivateFrameworks/EmojiFoundation.framework/EmojiFoundation
EMFEmojiLocaleData
EMFEmojiPreferencesService
EMFEmojiToken
{type:%d,%c,
%c:%.2f,
%c:%.2f
{type:%d,%d,%.2f,%.2f,%.2f,%.2f,%d,
type:%d;
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
updateBestAnalysis
makeSegmentsExceptLast
best
top segment
best segment
makeLastSegments
createCandidateFromAnalysis
candidate to be added to top
enabled
disabled
Last-bunsetsu candidate #
top candidate
segments except last
last segments
logSegments
shouldChooseTopSegment
isTopSegmentSurfaceUnreliable
makeReliableKanaSegment
isBestSegmentReliable
NULL
makeLastSegmentFromTopSegment
yyyy-MM-dd@HHmm.ssSS
/tmp/GeometryModel
/tmp/GeometryModel/%@-%@.plist
keys
log likelihoods
createStringFromGeometryData
/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-924/mecabra/GeometryModel.cpp
numKeys > 0
%C:%f
{0:0}
flag
^{__CFString=}24@?0^{__CFString=}8^{__CFString=}16
v24@?0^{DynamicDictionaryEntry=^Sq^Sq}8^B16
DEBUG_PRINT_NODES
DEBUG_PRINT_WORD_GROUPS
DEBUG_PRINT_SYLLABLE_LATTICE
DEBUG_PRINT_SAMPLE_LATTICE
DEBUG_PRINT_CONNECTED_NODES
DEBUG_PRINT_HYPOTHESES
DEBUG_PRINT_HYPOTHESIS_SETS
DEBUG_PRINT_SYLLABLE_HYPOTHESIS
DEBUG_HOMOPHONE_PHRASES
DEBUG_NGRAM_SCORE
DEBUG_NGRAM_QUANTIZATION
DEBUG_PINYIN_TEXT_CHECKING
MECABRA_LOG_TIMING
MECABRA_LOG_STATISTICS
DEBUG_PRINT_CHARACTER_LATTICE
LOG_GEOMETRY_MODEL_DATA
DEBUG_PRINT_BEST_BACKTRACE
DEBUG_RERANKING
DEBUG_LEARNING
DEBUG_DYNAMIC_CANDIDATES
DEBUG_ENGINE
DEBUG_PREDICTION
DEBUG_PRINT_ADAPTATION
DEBUG_PRUNING
DEBUG_LIVE_CONVERSION
MECABRA_LOG_DESTINATION
Cannot open specified log file %s.
All logging is turned off.
MECABRA_LOG_BUFFERED
MecabraLogLevel
Log message exceeded the 1024-byte length limit.
[%s] paused at (%lu, %lu), total time elapsed %.8f seconds
[%s] Total time elapsed %.8f seconds
%@ (AS:%@ CAS:%@ DR:%@), %ld, %f
%@ (AS:%@ CAS:%@ DR:%@), %ld
GARBAGE
(%@)
rawCandidate
T^{MecabraCandidateBase=^^?q},R,N
rawConversionCandidate
T^{ConversionCandidate=^^?q},R,N
isConversionCandidate
TB,R,N
isSyntheticCandidate
isExtensionCandidate
isExtensionForCandidateBar
isEmojiCandidate
isPersonName
isLearningDictionaryCandidate
isUserWordCandidate
isPredictionCandidate
isFuzzyMatchCandidate
isAutocorrectedCandidate
isOTAWordlistCandidate
isRegionalCandidate
isBilingualCandidate
isPartialCandidate
isAbbreviated
isWubixingConvertedByPinyin
wubixingType
TQ,R,N
Ti,R,N
wordCount
surface
T@"NSString",R,N
convertedAnalysisString
dictionaryReading
attributes
T@"NSDictionary",R,N
kEmbedded
kJointProbabilityCostFactor
kDiscriminativeCostWeight
kCostFactor
kMatchPenaltyWeight
kMatchPenaltyWeightForSpecialToken
kSingleWordLMScore
kDynamicLMScoreWeight
kSymbolUnkPenalty
kMaxUnkPenalty
kRareUnkPenalty
kConsecutiveUnkPenalty
kSingleUnkCharWordPenalty
kSingleUnkCharWithOkuriganaWordPenalty
kDynamicKatakanaPenalty
kOtherSymbolOrLetterPenalty
kPenaltyForDynamicNumbers
kPenaltyForArabicNumberByReading
kPenaltyForArabicNumberAtEOSByReading
kPenaltyForArabicNumberSingleWordOnHWKeyboard
kPenaltyForWordWithArabicNumber
kPenaltyForUnlikelyNumberUnitCombination
kPenaltyForSymbolConversion
kPenaltyForKanjiNumberWithUnit
kRewardForSingleNumberConversion
kRewardForNumberWithUnit
kRewardForNumberWithParticle
kNumLexicalPreferenceTargetsForSWKeyboard
kNumLexicalPreferenceTargetsForHWKeyboard
kMaxNumExactCandidatesForSWKeyboard
kMaxNumExactCandidatesForHWKeyboard
kMaxNumPrefixCandidates
kSinglePhraseExactMatchCandidatePruningThreshold
kMultiPhraseExactMatchCandidatePruningThreshold
kPrefixMatchCandidatePruningThreshold
[ME::acceptLeftContext] #
[ME::acceptInlineContext] #
[ME:analyzeStringWithContext] Using a truncated context candidate
[ME::acceptCandidate] Accepted
v52@?0^{CandidateSet=^^?{unordered_map<InputEngine::ConversionCandidate *, unsigned long, InputEngine::CandidateSet::CandidateSurfaceHash, InputEngine::CandidateSet::CandidateSurfaceEqual, std::__1::allocator<std::__1::pair<InputEngine::ConversionCandidate *const, unsigned long> > >={__hash_table<std::__1::__hash_value_type<InputEngine::ConversionCandidate *, unsigned long>, std::__1::__unordered_map_hasher<InputEngine::ConversionCandidate *, std::__1::__hash_value_type<InputEngine::ConversionCandidate *, unsigned long>, InputEngine::CandidateSet::CandidateSurfaceHash, true>, std::__1::__unordered_map_equal<InputEngine::ConversionCandidate *, std::__1::__hash_value_type<InputEngine::ConversionCandidate *, unsigned long>, InputEngine::CandidateSet::CandidateSurfaceEqual, true>, std::__1::allocator<std::__1::__hash_value_type<InputEngine::ConversionCandidate *, unsigned long> > >={unique_ptr<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<InputEngine::ConversionCandidate *, unsigned long>, void *> *> *[], std::__1::__bucket_list_deallocator<std::__1::allocator<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<InputEngine::ConversionCandidate *, unsigned long>, void *> *> *> > >={__compressed_pair<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<InputEngine::ConversionCandidate *, unsigned long>, void *> *> **, std::__1::__bucket_list_deallocator<std::__1::allocator<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<InputEngine::ConversionCandidate *, unsigned long>, void *> *> *> > >=^^{__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<InputEngine::ConversionCandidate *, unsigned long>, void *> *>}{__bucket_list_deallocator<std::__1::allocator<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<InputEngine::ConversionCandidate *, unsigned long>, void *> *> *> >={__compressed_pair<unsigned long, std::__1::allocator<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<InputEngine::ConversionCandidate *, unsigned long>, void *> *> *> >=Q}}}}{__compressed_pair<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<InputEngine::ConversionCandidate *, unsigned long>, void *> *>, std::__1::allocator<std::__1::__hash_node<std::__1::__hash_value_type<InputEngine::ConversionCandidate *, unsigned long>, void *> > >={__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<InputEngine::ConversionCandidate *, unsigned long>, void *> *>=^{__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<InputEngine::ConversionCandidate *, unsigned long>, void *> *>}}}{__compressed_pair<unsigned long, std::__1::__unordered_map_hasher<InputEngine::ConversionCandidate *, std::__1::__hash_value_type<InputEngine::ConversionCandidate *, unsigned long>, InputEngine::CandidateSet::CandidateSurfaceHash, true> >=Q}{__compressed_pair<float, std::__1::__unordered_map_equal<InputEngine::ConversionCandidate *, std::__1::__hash_value_type<InputEngine::ConversionCandidate *, unsigned long>, InputEngine::CandidateSet::CandidateSurfaceEqual, true> >=f}}}{vector<std::__1::unique_ptr<InputEngine::ConversionCandidate, std::__1::default_delete<InputEngine::ConversionCandidate> >, std::__1::allocator<std::__1::unique_ptr<InputEngine::ConversionCandidate, std::__1::default_delete<InputEngine::ConversionCandidate> > > >=^{unique_ptr<InputEngine::ConversionCandidate, std::__1::default_delete<InputEngine::ConversionCandidate> >}^{unique_ptr<InputEngine::ConversionCandidate, std::__1::default_delete<InputEngine::ConversionCandidate> >}{__compressed_pair<std::__1::unique_ptr<InputEngine::ConversionCandidate, std::__1::default_delete<InputEngine::ConversionCandidate> > *, std::__1::allocator<std::__1::unique_ptr<InputEngine::ConversionCandidate, std::__1::default_delete<InputEngine::ConversionCandidate> > > >=^{unique_ptr<InputEngine::ConversionCandidate, std::__1::default_delete<InputEngine::ConversionCandidate> >}}}}8r^{UTF16String=^SQ}16r^{UTF16String=^SQ}24r^{UTF16String=^SQ}32i40i44i48
wordListFile
candidates
NSString+CharacterInformationAdditions.mm
Invalid parameter not satisfying: %@
toneNumber >= 1 && toneNumber <= 4
Adding a single dynamic word candidate
v24@?0^{__CFString=}8i16B20
v24@?0^{_LXEntry=}8*16
B24@?0r^{pair<unsigned short, double>=Sd}8r^{pair<unsigned short, double>=Sd}16
%@:(%d)
dictionary ID = %d
Error has occured when process word in %s ... 
Word ID = %d, token offset = %zu
Added %zu words
verify
Incorrect commandline arguments!
langugae
Too few arguments.
Language is not specified.
Language must be "zh-Hans" or "zh-Hant". or "yue-Hant".
Failed to build reverse dictionary %s.
Failed to process %s.
locale
directory
s:i:d:
Locale is required.
Word-ID map is required.
Directory of source dictionaries is required.
Incorrect number of arguments.
Locale can must be zh-Hans or zh-Hant or yue-Hant.
Cannot verify reverse dictionary %s!
Failed to load reverse dictionary %s
Didn't find word ID for %s(%d) in word to ID mapping file.
word to ID mapping file contains different word ID (%d) for %s(%d)
Usage:
%s <command> [args] [DictionaryFileName+] ReverseDictionaryFileName
build:
DictionaryFileName argument is required for build command.
-l|--language: "zh-Hans" or "zh-Hant" or "yue-Hant".
verify:
-s|--locale: Locale.
-i|--id: Word to word ID mapping file.
-d|--directory: Directory containing source dictionaries.
v24@?0Q8^B16
v24@?0@"MecabraCandidate"8^B16
MecabraLearningResetNotification
LearningDictionary
DynamicPhraseLexicon_zh_Hans.db
PhraseLearning_zh_Hans.db
PhraseLearning_zh_Hans.dictionary
StructuralPinyinLearning_zh_Hans.db
StructuralPinyinLearning_zh_Hans.dictionary
DynamicPhraseLexicon_zh_Hant_pinyin.db
PhraseLearning_zh_Hant_pinyin.db
PhraseLearning_zh_Hant_pinyin.dictionary
StructuralPinyinLearning_zh_Hant_pinyin.db
StructuralPinyinLearning_zh_Hant_pinyin.dictionary
DynamicPhraseLexicon_zh_Hant_zhuyin.db
PhraseLearning_zh_Hant_zhuyin.db
PhraseLearning_zh_Hant_zhuyin.dictionary
StructuralZhuyinLearning_zh_Hant_zhuyin.db
StructuralZhuyinLearning_zh_Hant_zhuyin.dictionary
Failed to load character map for language 
 is unsupported language value.
supplement.dic
mixed.dic
 is not a recognized source dictionary name.
Token offset 
 is out of range. The max offset value is 0x1FFFFF.
Failed to open dictionary 
Failed to open dictionary : %s
^{MecabraResourceLoader<InputEngine::CharacterMap>=i{unique_ptr<InputEngine::CharacterMap, std::__1::default_delete<InputEngine::CharacterMap> >={__compressed_pair<InputEngine::CharacterMap *, std::__1::default_delete<InputEngine::CharacterMap> >=^{CharacterMap}}}}8@?0
LexicalLearning_ja_JP.db
NonLexicalLearning_ja_JP.db
FirstSurface
SecondReading
SecondSurface
SecondReadingSegments
SecondSurfaceSegments
SecondPartOfSpeech
Honorific
Lexierra_ja_JP-dynamic-text.dat
LexicalLearning_ja_JP.dat
DynamicPhraseLexicon_ja_JP.db
PhraseLearning_ja_JP.dictionary
PhraseLearning_ja_JP.db
BigramLearning_ja_JP.dictionary
BigramLearning_ja_JP.db
DynamicBigramPhraseLexicon_ja_JP.db
Creating accepted candidate from a synthetic candidate
Creating accepted candidate from a facemark candidate
Creating accepted candidate from a conversion candidate
online
%@/%@ 
%@ (%d) 
LearningDictionaryJapanese
DynamicPersonNameLexicon_ja_JP.db
com.apple.mecabra
Building dictionary: %s
%s usage: <template file> <dictionary data file> <new dictionary path> 
can't read template from file %@
can't create URL for new dictionary %@
CFBundleIdentifier
error building dictionary
Dictionary was built successfully.
reading dictionary data file %@ failed with error %@
bad dictionary data %@
Wrong originalFlag. 
POS:(
LeftPOS1:
LeftPOS2:
RightPOS1:
RightPOS2:
LeftSurface1:
LeftSurface2:
RightSurface1:
RightSurface2:
LeftSurface1
LeftSurface2
RightSurface1
LeftPOS1
LeftPOS2
RightPOS1
Feature
IntValue
StrValue
v48@?0r^I8q16d24q32^B40
[makeCandidateFromExpandedSequence]
[MJNP::expandPhrasesWithLanguageModel] Handling n-gram expansion from
unique_lock::try_lock: references null mutex
unique_lock::try_lock: already locked
LearningSet_zh_Hans.plist
LearningSet_zh_Hant.plist
Revert learning for candidate %s
v16@?0^{__CFString=}8
CP OVS:
CP Dropped:
Best: 
AutoCorrection: 
Phrase without EOS: 
Alternative: 
B16@?0r^{BacktraceWaypoint=^{WordCore}^{BacktraceWaypoint}}8
:/-_+@#
/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-924/mecabra/Dictionary/MecabraJapaneseDictionaryCompiler.cpp
Fails to build unigram reading trie
Fails to build surface trie
token->reading.size()
token reading is empty
token->surface.size()
token surface is empty
iterator == m_tokenIDToUnigramTokenIndexMap.end()
tokenID should be unique.
tokenCount == m_sortedUnigramTokenArray.size()
m_sortedUnigramTokenArray.size is not equal to the token count in m_unigramReadingAndTokensPairList.
homographCount <= 0xff
homographCount is greater than 0xff.
tokenIndex <= 0x00ffffff
tokenIndex is greater than 0x00ffffff.
------------Characters at pos 
 characters --------------- 
------------words at pos 
 cursors --------------- 
/System/Library/LinguisticData/RequiredAssets_zh-Hant.bundle/AssetData/commercial.dic
/System/Library/LinguisticData/RequiredAssets_zh-Hant.bundle/AssetData/computer.dic
/System/Library/LinguisticData/RequiredAssets_zh-Hant.bundle/AssetData/industry.dic
/System/Library/LinguisticData/RequiredAssets_zh-Hant.bundle/AssetData/education.dic
/System/Library/LinguisticData/RequiredAssets_zh-Hant.bundle/AssetData/traffic.dic
/System/Library/LinguisticData/RequiredAssets_zh-Hant.bundle/AssetData/law_poli.dic
/System/Library/LinguisticData/RequiredAssets_zh-Hant.bundle/AssetData/build.dic
/System/Library/LinguisticData/RequiredAssets_zh-Hant.bundle/AssetData/cmedic.dic
/System/Library/LinguisticData/RequiredAssets_zh-Hant.bundle/AssetData/medical.dic
/System/Library/LinguisticData/RequiredAssets_zh-Hant.bundle/AssetData/biology.dic
/System/Library/LinguisticData/RequiredAssets_zh-Hant.bundle/AssetData/military.dic
/System/Library/LinguisticData/RequiredAssets_zh-Hant.bundle/AssetData/phy_chem.dic
/System/Library/LinguisticData/RequiredAssets_zh-Hant.bundle/AssetData/sport.dic
/System/Library/LinguisticData/RequiredAssets_zh-Hant.bundle/AssetData/buddhism.dic
UTF-8
UTF-16LE
/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-924/seaweed/Dictionary/SeaweedChineseDictionaryCompiler.cpp
m_converter.open("UTF-8", "UTF-16LE")
iconv_open() failed (from UTF-8 to UTF-16LE)
index_config
Cannot load dictionary index properties. Error: 
priority
input
pinyin_syllable
zhuyin_syllable
wrong language
columnCount == kOriginalFeatureStartColumn + 1
CSV format error: 
originalFeature.size()
feature empty error: 
featureColumnCount > data.syllableIDIndexCount()
feature format error: 
data.syllableIDIndexCount() <= data.indexCount()
feature format error (syllable ID index count is too big): 
readingColumnCount == data.indexCount()
reading format error: 
!readingString.empty()
readingString error: 
iconv.convert(&readingString)
convert reading error: 
iconv.convert(&convertedReading)
!convertedReading.empty()
empty converted reading error: 
set as input text file
set as output file
set as pinyin syllable data file
set as zhuyin syllable data file
dictionary type(system, supplement, single_character, category, emoji, english, asset (not implemented))
index configuration file
languge: zh-Hans or zh-Hant or yue-Hant
try '--help' for more information.
compile_block_invoke
featureDataOffset < UINT32_MAX
v16@?0r^{RawDictionaryEntry=iii{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}{vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > >=^{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >}^{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >}{__compressed_pair<std::__1::basic_string<char> *, std::__1::allocator<std::__1::basic_string<char> > >=^{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >}}}}8
permission denied: 
(out.tellp() % kAlignmentNumber) == 0
header is not aligned: 
trie data header is not aligned: 
token buffer is not aligned: 
 compiled successfully.
m_data.indexCount() == dictionary->indexCount()
dictionary index count error. 
validate_block_invoke
featureOffset < UINT32_MAX
v24@?0^{?=^{Token}*}8^B16
[ERROR] validation failed on index 
 for line 
v40@?0^{?=^{Token}*}8r*16Q24^B32
keyTokenPairs.size() <= kMaxTrieEntryCount
trie can hold a maximum of 
 entries.
homographCount <= kMaxHomographEntryCount
number of homograph words is greater than 
. string =
 count=
allKeys.size()
no reading error. 
keyTokenOffsetPairs.size() <= kMaxTrieEntryCount
m_data.indexCount() > m_data.syllableIDIndexCount()
trie must hold at least one one non-syllable index
trie data is not aligned: 
token index buffer is not aligned: 
(reading[i] >= 'a' && reading[i] <= 'z') || reading[i] == '*'
not valid pinyin error: 
isZhuyinToneMark(zhuyin[i]) || isValidZhuyin(zhuyin[i])
not valid zhuyin error: 
person
KKK1
syllableLengths[i]
syllable length is zero: 
total == reading.size()
syllable length doesn't match reading: 
syllableID != kInvalidIndex
cannot get syllable ID from syllable trie: 
v44@?0r^{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}8r^{Token=ISSI}16Q24B32^B36
*!@#$%
v20@?0I8^{__CFDictionary=}12
single_character.dic
single_character2.dic
single_character3.dic
facemarks.plist
Chinese.lm
charmap.dat
syllable.dat
emoji_dependency.dat
emoji_conversion.dat
emoji_adornment.dat
emoji_prediction.dat
reverse.dic
Cangjie.dictionary
CangjieCodes.dat
Stroke.dictionary
Wubixing.dictionary
homophones.plist
PinyinToZhuyin.plist
ZhuyinToPinyin.plist
SortedRadicals.plist
WordProperties_CharacterInformation.dictionary
WordProperties_KeyLookup.dictionary
cp_params.plist
rewrite.dat
LanguageModel
RNNLanguageModel
Lexicon
LexiconDelta
AssetData
MobileAssetProperties
IsMainBundle
ContentPath
ContentType
v44@?0^{__CFURL=}8i16^{__CFLocale=}20^{__CFString=}28^B36
getPathsForLMAndLexiconAssets
Mixed
DynamicPhraseLexicon_zh_Hans_Wubixing.db
DynamicPhraseLexicon_zh_Hans_Stroke.db
DynamicPhraseLexicon_zh_Hant_Sucheng.db
DynamicPhraseLexicon_yue_Hant_Sucheng.db
DynamicPhraseLexicon_zh_Hant_Stroke.db
DynamicPhraseLexicon_yue_Hant_Stroke.db
DynamicPhraseLexicon_zh_Hans_Wubixing_v2.db
v24@?0^{LatticeSearchState=^{SyllableNodeBase}QQSSI{vector<std::__1::pair<unsigned char, Seaweed::DictionaryCursorInfo>, std::__1::allocator<std::__1::pair<unsigned char, Seaweed::DictionaryCursorInfo> > >=^{pair<unsigned char, Seaweed::DictionaryCursorInfo>}^{pair<unsigned char, Seaweed::DictionaryCursorInfo>}{__compressed_pair<std::__1::pair<unsigned char, Seaweed::DictionaryCursorInfo> *, std::__1::allocator<std::__1::pair<unsigned char, Seaweed::DictionaryCursorInfo> > >=^{pair<unsigned char, Seaweed::DictionaryCursorInfo>}}}}8Q16
v24@?0r^{WordCore=^^?i^{WordGroupTraits}{vector<unsigned int, std::__1::allocator<unsigned int> >=^I^I{__compressed_pair<unsigned int *, std::__1::allocator<unsigned int> >=^I}}}8^B16
B16@?0Q8
B16@?0r^{SyllableSequence=iQ^S^S^{SyllableInfo}{bitset<10>=Q}Qf}8
v52@?0^{LatticeSearchState=^{SyllableNodeBase}QQSSI{vector<std::__1::pair<unsigned char, Seaweed::DictionaryCursorInfo>, std::__1::allocator<std::__1::pair<unsigned char, Seaweed::DictionaryCursorInfo> > >=^{pair<unsigned char, Seaweed::DictionaryCursorInfo>}^{pair<unsigned char, Seaweed::DictionaryCursorInfo>}{__compressed_pair<std::__1::pair<unsigned char, Seaweed::DictionaryCursorInfo> *, std::__1::allocator<std::__1::pair<unsigned char, Seaweed::DictionaryCursorInfo> > >=^{pair<unsigned char, Seaweed::DictionaryCursorInfo>}}}}8Q16r^{UTF16String=^SQ}24^{?=^{Token}*}32i40^B44
Dropped: 
v24@?0r^{BacktraceWaypoint=^{WordCore}^{BacktraceWaypoint}}8d16
v56@?0Q8{UTF16String=^SQ}16{UTF16String=^SQ}32S48S52
NewWordPenalty
v28@?0r^{BigramToken=sII}8f16^B20
createHybridCandidateWithConversionCandidate
/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-924/mecabra/ChinesePrediction/ChinesePredictionCandidate.mm
v56@?0{?=qq}8r^{vector<unsigned short, std::__1::allocator<unsigned short> >=^S^S{__compressed_pair<unsigned short *, std::__1::allocator<unsigned short> >=^S}}24r^{vector<unsigned short, std::__1::allocator<unsigned short> >=^S^S{__compressed_pair<unsigned short *, std::__1::allocator<unsigned short> >=^S}}32r^{vector<unsigned short, std::__1::allocator<unsigned short> >=^S^S{__compressed_pair<unsigned short *, std::__1::allocator<unsigned short> >=^S}}40r^{vector<bool, std::__1::allocator<bool> >=^QQ{__compressed_pair<unsigned long, std::__1::allocator<unsigned long> >=Q}}48
%@(%d) 
 EOS
<BOS>
<EOS>
(%p)
(%d)
iang
uang
iong
chon
jion
qion
xion
zhon
bang
beng
bian
biao
bing
cang
ceng
chai
chan
chang
chao
chen
cheng
chong
chou
chua
chuai
chuan
chuang
chui
chun
chuo
cong
cuan
dang
deng
dian
diao
ding
dong
duan
fang
feng
gang
geng
gong
guai
guan
guang
hang
heng
hong
huai
huan
huang
jian
jiang
jiao
jing
jiong
juan
kang
keng
kong
kuai
kuan
kuang
lang
leng
lian
liang
liao
ling
long
luan
lvan
mang
meng
mian
miao
ming
nang
neng
nian
niang
niao
ning
nong
nuan
pang
peng
pian
piao
ping
qian
qiang
qiao
qing
qiong
quan
rang
reng
rong
ruan
sang
seng
shai
shan
shang
shao
shei
shen
sheng
shou
shua
shuai
shuan
shuang
shui
shun
shuo
song
suan
tang
teng
tian
tiao
ting
tong
tuan
wang
weng
xian
xiang
xiao
xing
xiong
xuan
yang
ying
yong
yuan
zang
zeng
zhai
zhan
zhang
zhao
zhei
zhen
zheng
zhong
zhou
zhua
zhuai
zhuan
zhuang
zhui
zhun
zhuo
zong
zuan
biang
cuai
cuang
diang
duang
fong
fuai
fuan
fuang
juang
luang
miang
nuang
piang
quang
rian
riang
riao
ring
ruang
shong
suai
suang
tiang
tuang
xuang
yuang
zuai
zuang
v16@?0Q8
v16@?0^{KeyAndProbability=Sf}8
%s: %s
Remove
-------------------- input = 
 ------------------
-------------------- nbests------------------
syllables ending with input char 
 at pos 
complete syllable: 
incomplete syllable: 
Autocorrected Complete syllable: 
prob = 
Previous syllable = 
 rawInputLength = 
Next syllable = 
Autocorrected Incomplete syllable: 
Synthetic syllable: mixed, length = 
Synthetic syllable: 
Start column indexes: 
First syllables: 
First syllable end column indexes: 
zh-Hans-Lati-CN-pinyin
syllablenew.lm
, rawInputLength = 
, separatorCount = 
 next: 
 (fuzzy), original = 
bitset set argument out of range
bitset test argument out of range
Syllable trie file %s is incompatible (version %d, expected version %d)
Syllable trie open failed: %s
^{Hypothesis=[2I]Cd{BacktraceWaypoint=^{WordCore}^{BacktraceWaypoint}}}8@?0
===RESET===
===cummulative stats since last reset===
hypotheses created = %ld
hypothesis sets created = %ld
words created = %ld
word groups created = %ld
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
^{MecabraResourceLoader<Seaweed::ReverseDictionary>=i{unique_ptr<Seaweed::ReverseDictionary, std::__1::default_delete<Seaweed::ReverseDictionary> >={__compressed_pair<Seaweed::ReverseDictionary *, std::__1::default_delete<Seaweed::ReverseDictionary> >=^{ReverseDictionary}}}}8@?0
000 
0000 
xSYMx
xOLTRx
xPERGx
xPROPNx
%@ (%@)
T@"NSString",R,N,V_string
T@"NSString",R,N,V_category
synthetic word group:
type = 
syllable IDs: 
Syllable Lengths:
length = 
, trieValue = 
facemark.dat
^{FacemarkLearningDictionary={basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}{FacemarkLearningDictionaryHeader=IIId}{vector<InputEngine::FacemarkLearningDictionary::FacemarkLearningEntry, std::__1::allocator<InputEngine::FacemarkLearningDictionary::FacemarkLearningEntry> >=^{FacemarkLearningEntry}^{FacemarkLearningEntry}{__compressed_pair<InputEngine::FacemarkLearningDictionary::FacemarkLearningEntry *, std::__1::allocator<InputEngine::FacemarkLearningDictionary::FacemarkLearningEntry> >=^{FacemarkLearningEntry}}}}8@?0
Adding a person name candidate
^{Hypothesis=[2I]Cd{BacktraceWaypoint=^{WordCore}^{BacktraceWaypoint}}}32@?0r^{WordCore=^^?i^{WordGroupTraits}{vector<unsigned int, std::__1::allocator<unsigned int> >=^I^I{__compressed_pair<unsigned int *, std::__1::allocator<unsigned int> >=^I}}}8d16r^{Hypothesis=[2I]Cd{BacktraceWaypoint=^{WordCore}^{BacktraceWaypoint}}}24
adding word group endIndex=%d {
v24@?0r^{WordGroup={WordGroupTraits=^{SyllableSequence}^{__CFString}QIIIi}{vector<Seaweed::LatticeWord *, std::__1::allocator<Seaweed::LatticeWord *> >=^^{LatticeWord}^^{LatticeWord}{__compressed_pair<Seaweed::LatticeWord **, std::__1::allocator<Seaweed::LatticeWord *> >=^^{LatticeWord}}}B}8Q16
^{WordGroup={WordGroupTraits=^{SyllableSequence}^{__CFString}QIIIi}{vector<Seaweed::LatticeWord *, std::__1::allocator<Seaweed::LatticeWord *> >=^^{LatticeWord}^^{LatticeWord}{__compressed_pair<Seaweed::LatticeWord **, std::__1::allocator<Seaweed::LatticeWord *> >=^^{LatticeWord}}}B}8@?0
v24@?0r^{Hypothesis=[2I]Cd{BacktraceWaypoint=^{WordCore}^{BacktraceWaypoint}}}8^B16
NBest: 
 -> 
(%s)
, prob: %f surface: %s
__insert_nodes
/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-924/src/trie_build.cpp
new_children
v40@?0r^{mecab_token_t=sSSSI}8r*16Q24^B32
Dictionary Lookup
Trie Lookup
v24@?0r^{?=SsQI}8^B16
/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-924/src/im/tokenizer.cpp
property_.open(param)
unk.dic
unkdic_->open(create_filename (prefix, UNK_DIC_FILE).c_str(), mode) && setDictionaryID(unkdic_)
sys_mini.dic
succeeded && setDictionaryID(sysdic)
sysdic->type() == 0
not a system dictionary: 
d->open(_dic[i], mode) && setDictionaryID(d)
d->type() == MECAB_USR_DIC
not a user dictionary: 
learndic_->open(learndicpath.c_str(), "r+") && setDictionaryID(learndic_)
n.value != 0
cannot find UNK category: 
bos-feature
*bos_feature_ != '\0'
bos-feature is undefined in dicrc
max-grouping-size
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
v24@?0r*8^B16
/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-924/src/im/lattice_impl.cpp
lsize == lines.size()
features.size() == surfaces.size()
output buffer overflow
node is NULL
nbest size must be 1 <= nbest <= 512
wakati
none
dump
eon-format
/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-924/src/im/writer.cpp
!tmp.empty()
unkown format type [
unknown meta char: 
[iseSCwcnblLh] is required after %p
lr is required after %ph
no path information is available
[icP] is required after %pp
no feature information available
cannot find '['
given index is out of range
cannot find ']'
Adding a phrase learning dictionary candidate
This functionality has not been implemented for mutable dictionary!
Open file %s failed: %s
Dictionary file %s is empty
Dictionary file %s doesn't support the original format
Dictionary file %s has an empty header
Dictionary file %s is incompatible (version %d, expected version %d)
Dictionary file %s has the wrong content
Emoji file %s is empty
/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-924/mecabra/EmojiDictionary.mm
columnCount >= 3
Wrong column count: 
emojiCount > 0 && emojiCount < kMaxFeatureCount
Wrong features: 
currentFeatureOffset < kMaxFeatureOffset
Exceed the feature offset limit: 
ofstream is empty: 
EnglishLexicon_
^{EnglishLexicon={CFScopedPtr<const _LXLexicon *>=^{_LXLexicon}}{SearchState={CFScopedPtr<const __CFString *>=^{__CFString}}Qd{vector<std::__1::set<InputEngine::EnglishLexicon::CursorTuple, std::__1::less<InputEngine::EnglishLexicon::CursorTuple>, std::__1::allocator<InputEngine::EnglishLexicon::CursorTuple> >, std::__1::allocator<std::__1::set<InputEngine::EnglishLexicon::CursorTuple, std::__1::less<InputEngine::EnglishLexicon::CursorTuple>, std::__1::allocator<InputEngine::EnglishLexicon::CursorTuple> > > >=^{set<InputEngine::EnglishLexicon::CursorTuple, std::__1::less<InputEngine::EnglishLexicon::CursorTuple>, std::__1::allocator<InputEngine::EnglishLexicon::CursorTuple> >}^{set<InputEngine::EnglishLexicon::CursorTuple, std::__1::less<InputEngine::EnglishLexicon::CursorTuple>, std::__1::allocator<InputEngine::EnglishLexicon::CursorTuple> >}{__compressed_pair<std::__1::set<InputEngine::EnglishLexicon::CursorTuple, std::__1::less<InputEngine::EnglishLexicon::CursorTuple>, std::__1::allocator<InputEngine::EnglishLexicon::CursorTuple> > *, std::__1::allocator<std::__1::set<InputEngine::EnglishLexicon::CursorTuple, std::__1::less<InputEngine::EnglishLexicon::CursorTuple>, std::__1::allocator<InputEngine::EnglishLexicon::CursorTuple> > > >=^{set<InputEngine::EnglishLexicon::CursorTuple, std::__1::less<InputEngine::EnglishLexicon::CursorTuple>, std::__1::allocator<InputEngine::EnglishLexicon::CursorTuple> >}}}{vector<std::__1::vector<unsigned short, std::__1::allocator<unsigned short> >, std::__1::allocator<std::__1::vector<unsigned short, std::__1::allocator<unsigned short> > > >=^{vector<unsigned short, std::__1::allocator<unsigned short> >}^{vector<unsigned short, std::__1::allocator<unsigned short> >}{__compressed_pair<std::__1::vector<unsigned short, std::__1::allocator<unsigned short> > *, std::__1::allocator<std::__1::vector<unsigned short, std::__1::allocator<unsigned short> > > >=^{vector<unsigned short, std::__1::allocator<unsigned short> >}}}}B}8@?0
EnglishPhraseLexicon_
/System/Library/LinguisticData/RequiredAssets_en.bundle/AssetData/
Phrases-
.dat
Delta-
^{AsyncResource<InputEngine::EnglishLexicon>={unique_ptr<InputEngine::EnglishLexicon, std::__1::default_delete<InputEngine::EnglishLexicon> >={__compressed_pair<InputEngine::EnglishLexicon *, std::__1::default_delete<InputEngine::EnglishLexicon> >=^{EnglishLexicon}}}^{dispatch_group_s}^{dispatch_queue_s}{once_flag=Q}@?{atomic<InputEngine::AsyncResource<InputEngine::EnglishLexicon>::State>={__cxx_atomic_impl<InputEngine::AsyncResource<InputEngine::EnglishLexicon>::State, std::__1::__cxx_atomic_base_impl<InputEngine::AsyncResource<InputEngine::EnglishLexicon>::State> >=Ai}}{mutex={_opaque_pthread_mutex_t=q[56c]}}{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}{unique_lock<std::__1::mutex>=^{mutex}B}}8@?0
v40@?0^{_LXCursor=}8d16Q24*32
/System/Library/PrivateFrameworks/CoreNLP.framework/CoreNLP
/System/Library/PrivateFrameworks/CoreNLP.framework/Contents/MacOS/CoreNLP
NLStringTokenizerCreate
NLStringTokenizerSetString
NLStringTokenizerAdvanceToNextToken
NLStringTokenizerGetCurrentTokenRange
SuppressSensitiveWords
HistorySimulation
DisabledLearningBasedGeneratonBigramPhrase
DisabledLearningBasedGeneratonUnigramPhrase
DisabledLearningBasedGeneratonLexicalPreference
DisabledLearningBasedGeneratonNonLexicalPreference
NoPruning
/System/Library/LinguisticData/RequiredAssets_zh.bundle/AssetData/reading-lookup.dat
Reading lookup index trie error.
Reading lookup version error.
reading %d: 
Cannot open %s
dumpDictionary
/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-924/reading-lookup/BuildReadingLookupDictionary.mm
trie
%d words
reading-list
word-index
r:w:o:d:
ReadingLookupDictionaryBuild
[word length] > 0
[components count] == 4
offset <= 0xFFFFFF
CFBurstTrieAddUTF8String(trie, (UInt8*)utf16String, [word length] * sizeof(unichar), payload)
Cannot create %s
numByteWritten == sizeof(ReadingLookupDictionaryHeader)
numByteWritten == statBuffer.st_size - sizeof(ReadingHeader)
CFBurstTrieSerializeWithFileDescriptor(trie, outputFile, kCFBurstTrieReadOnly | kCFBurstTrieBitmapCompression | kCFBurstTrieSortByKey)
Created reading lookup dictioanry at %s
%s --reading-list PATH --word-index PATH --output PATH
%s --dump PATH
B0j0_0
D0d0
S0S0
S0a0
]0S0
i0S0
j0k0
0_0W0
[b_-
[b_-
*g6qb_-
B}bkb_-
SOb_-
SOb_-
(ub_-
B}bkb_-
SOb_-
*g6qb_-
(ub_-
(ub_-
(ub_-
B}bkb_-
(ub_-
(ub_-
B}bkb_-
(ub_-
SOb_-
]6qb_-
*g6qb_-
(ub_-
(ub_-
S0]0
K0W0
L0k0
U0H0
W0K0
W0M0
Z0d0
`0Q0
`0k0
c0f0
i0S0
j0h0
j0i0
0^0o0
p0K0
{0i0
~0g0
1\D0f0
U0K0D0
_0c0f0
d0d0
f0o0
h0f0
j0L0
p0c0f0
g0o0
k0f0
k0o0
K0D0
K0W0
O0U0
^0D0
n0F0
p0D0
y0D0
*g6qb_-
(ub_-
(ub_-
B}bkb_-
*g6qb_-
D}T~
B0h0
F0a0
S0h0
h0M0
h0S0
j0F0
o0Z0
{0F0
UOK0
,gS_
SOb_-
B}bkb_-
_0a0
Rpe^
Rpe^
zz}v
c0p0
c0s0
c0v0
c0y0
c0|0
s0C0
s0G0
c0s0
c0s0C0
c0s0
c0s0G0
c0s0
c0a0
a0C0
a0G0
c0a0
c0a0C0
c0a0
c0a0G0
c0a0
c0`0
c0b0
c0e0
c0g0
c0i0
g0C0
g0G0
c0g0
c0g0C0
c0g0
c0g0G0
c0g0
i0A0
i0C0
i0E0
i0G0
i0I0
c0i0A0
c0i0C0
c0i0E0
c0i0G0
c0i0I0
b0C0
b0G0
c0b0
c0b0C0
c0b0
c0b0G0
c0b0
c0u0
u0C0
u0G0
u0A0
u0E0
u0I0
c0u0
c0u0C0
c0u0
c0u0G0
c0u0
c0L0
c0N0
c0P0
c0R0
c0T0
P0A0
P0C0
P0E0
P0G0
P0I0
c0P0A0
c0P0C0
c0P0E0
c0P0G0
c0P0I0
N0C0
N0G0
c0N0
c0N0C0
c0N0
c0N0G0
c0N0
c0o0
c0r0
c0x0
c0{0
c0u0A0
c0u0I0
r0C0
r0G0
c0r0
c0r0C0
c0r0
c0r0G0
c0r0
c0X0
X0C0
X0G0
c0X0
c0X0C0
c0X0
c0X0G0
c0X0
c0K0
c0M0
c0O0
c0Q0
c0S0
O0A0
O0C0
O0E0
O0G0
O0I0
c0O0A0
c0O0C0
c0O0E0
c0O0G0
c0O0I0
M0C0
M0G0
c0M0
c0M0C0
c0M0
c0M0G0
c0M0
c0~0
k0C0
k0G0
c0q0
c0t0
c0w0
c0z0
c0}0
t0C0
t0G0
c0t0
c0t0C0
c0t0
c0t0G0
c0t0
c0O0
c0O0
c0O0
c0O0
c0U0
c0W0
c0Y0
c0[0
c0]0
W0G0
c0W0
c0W0
c0W0G0
c0W0
W0C0
c0W0C0
Y0A0
Y0C0
Y0E0
Y0G0
Y0I0
c0Y0A0
c0Y0C0
c0Y0E0
c0Y0G0
c0Y0I0
c0_0
c0d0
c0f0
c0h0
f0C0
f0G0
c0f0
c0f0C0
c0f0
c0f0G0
c0f0
d0A0
d0C0
d0G0
d0I0
c0d0A0
c0d0C0
c0d0G0
c0d0I0
h0A0
h0C0
h0E0
h0G0
h0I0
c0h0A0
c0h0C0
c0h0E0
c0h0G0
c0h0I0
c0F0
F0A0
F0C0
F0G0
F0I0
c0F0A0
c0F0C0
c0F0G0
c0F0I0
D0G0
c0D0G0
c0V0
c0Z0
c0\0
c0^0
N(N?N6N[N
.(N,N6N7N?N@NANZN[N
["\n\
^P_Q_a_s_
_Lb4e5e5llp+r?r\r
uvv;y
o0a0
k0X0
k0X0
0F0o0a0
(ub_
B}bkb_
SOb_
Kb0u4l
^\Sq\
e8\(gkp
zAS'Y-N
N(N?N6N
1OU*
z4lkpKN
](g'Y
SsYP[
NkQ]NAS]
NkQ]NAS]
NkQ]NAS~vCS
NkQ]NAS
NkQ]NAS~vCS
0o0K0k0
0n0x0W0g0
1'1(1)1
1 1!1"1#1$1%1&1
4l!q
^y!q
P[t^
oSt^
HSt^
*gt^
3ut^
bt^
B0Y0
B0W0_0
B0U0c0f0
B0U0d0f0
W0B0U0c0f0
W0B0U0d0f0
0n0B0U0c0f0
0n0B0U0d0f0
0j0B0U0c0f0
0j0B0U0d0f0
T0B0U0c0f0
S0B0U0d0f0
M0n0F0
U0O0X0d0
U0O0W0d0
J0h0h0D0
D0c0U0O0X0d0
D0d0U0O0W0d0
0R0d0
0Q0d0
0D0R0d0
0D0Q0d0
0D0R0d0
0D0Q0d0
0R0d0
0Q0d0
0R0d0
0Q0d0
S0h0W0
0D0m0
0D0m0
U0O0m0
J0h0h0W0
D0c0U0O0m0
D0d0U0O0m0
U0M0J0h0h0W0
j"k"
& & 
g0Y0
~0W0
1'1 1
1'1"1
1'1#1
1'1%1
1'1 1
1'1"1
1'1#1
1'1%1
1'1 1
1'1!1
1'1"1
1'1#1
1'1%1
1'1 1
1'1!1
1'1"1
1'1%1
1(1"1
1(1#1
1(1%1
1'1 1
1'1"1
1'1%1
1(1"1
1(1#1
1(1%1
1'1 1
1'1!1
1'1"1
1'1#1
1'1$1
1'1%1
1(1"1
1(1#1
1(1%1
1 1
1!1
1"1
1$1
1%1
1'1
1'1
1'1
1'1 1
1'1!1
1'1"1
1'1#1
1'1$1
1'1%1
1(1
1(1
1(1"1
1(1#1
1(1%1
1)1
1)1
1)1"1
1(1"1
1(1#1
1(1$1
1(1%1
1(1"1
1(1#1
1(1$1
1(1%1
1(1"1
1(1#1
1(1$1
1(1%1
1'1 1
1'1!1
1'1"1
1'1#1
1'1$1
1'1%1
1)1"1
1)1#1
1)1%1
1'1 1
1'1!1
1'1"1
1'1#1
1'1$1
1'1%1
1)1"1
1)1#1
1)1%1
1'1 1
1'1!1
1'1"1
1'1#1
1'1$1
1'1%1
1)1"1
1)1#1
1)1%1
1(1"1
1(1#1
1(1$1
1(1%1
1(1"1
1(1#1
1(1$1
1(1%1
1(1"1
1(1#1
1(1$1
1(1"1
1(1#1
1(1%1
1(1"1
1(1#1
1(1%1
1(1"1
1(1#1
1(1%1
1(1"1
1(1#1
1(1%1
'1 1
'1!1
'1"1
'1#1
'1$1
'1%1
(1"1
(1#1
(1$1
(1%1
)1"1
)1#1
)1%1
1'1 1
1'1 1
1'1 1
1'1 1
1'1"1
1'1"1
1'1"1
1'1"1
1'1"1
1'1#1
1'1#1
1'1#1
1'1%1
1'1%1
1'1%1
1'1 1
1'1 1
1'1 1
1'1 1
1'1"1
1'1"1
1'1"1
1'1"1
1'1#1
1'1#1
1'1#1
1'1#1
1'1%1
1'1%1
1'1%1
1'1%1
1'1%1
1'1 1
1'1 1
1'1 1
1'1 1
1'1!1
1'1!1
1'1"1
1'1"1
1'1"1
1'1"1
1'1#1
1'1#1
1'1%1
1'1%1
1'1%1
1'1%1
1'1%1
1'1 1
1'1 1
1'1 1
1'1!1
1'1"1
1'1"1
1'1"1
1'1"1
1'1"1
1'1%1
1'1%1
1'1%1
1'1%1
1'1%1
1(1"1
1(1"1
1(1"1
1(1"1
1(1#1
1(1#1
1(1#1
1(1#1
1(1%1
1(1%1
1(1%1
1'1 1
1'1 1
1'1 1
1'1 1
1'1 1
1'1"1
1'1"1
1'1"1
1'1"1
1'1%1
1'1%1
1'1%1
1'1%1
1'1%1
1(1"1
1(1"1
1(1"1
1(1"1
1(1#1
1(1#1
1(1#1
1(1#1
1(1%1
1(1%1
1(1%1
1(1%1
1(1%1
1'1 1
1'1 1
1'1!1
1'1!1
1'1!1
1'1!1
1'1!1
1'1"1
1'1"1
1'1"1
1'1"1
1'1"1
1'1#1
1'1#1
1'1#1
1'1$1
1'1$1
1'1$1
1'1%1
1'1%1
1'1%1
1(1"1
1(1"1
1(1#1
1(1#1
1(1%1
1(1%1
1(1%1
1(1%1
1(1%1
1 1
1 1
1 1
1 1
1 1
1!1
1!1
1!1
1!1
1!1
1"1
1"1
1"1
1$1
1$1
1$1
1$1
1$1
1%1
1%1
1%1
1%1
1%1
1'1
1'1
1'1
1'1
1'1
1'1
1'1
1'1
1'1
1'1
1'1
1'1 1
1'1 1
1'1 1
1'1 1
1'1 1
1'1!1
1'1!1
1'1!1
1'1!1
1'1!1
1'1"1
1'1"1
1'1"1
1'1"1
1'1"1
1'1#1
1'1#1
1'1#1
1'1#1
1'1$1
1'1$1
1'1$1
1'1$1
1'1$1
1'1%1
1'1%1
1'1%1
1'1%1
1'1%1
1(1
1(1
1(1
1(1
1(1
1(1
1(1
1(1
1(1
1(1
1(1"1
1(1"1
1(1"1
1(1"1
1(1#1
1(1#1
1(1#1
1(1#1
1(1%1
1(1%1
1(1%1
1(1%1
1(1%1
1)1
1)1
1)1
1)1
1)1
1)1"1
1)1"1
1(1"1
1(1"1
1(1"1
1(1#1
1(1#1
1(1#1
1(1#1
1(1$1
1(1$1
1(1$1
1(1$1
1(1%1
1(1%1
1(1%1
1(1%1
1(1"1
1(1"1
1(1"1
1(1"1
1(1#1
1(1#1
1(1#1
1(1$1
1(1$1
1(1$1
1(1$1
1(1%1
1(1%1
1(1%1
1(1"1
1(1"1
1(1"1
1(1"1
1(1"1
1(1#1
1(1#1
1(1#1
1(1#1
1(1$1
1(1$1
1(1$1
1(1$1
1(1$1
1(1%1
1(1%1
1(1%1
1(1%1
1(1%1
1'1 1
1'1 1
1'1 1
1'1 1
1'1 1
1'1!1
1'1!1
1'1!1
1'1!1
1'1!1
1'1"1
1'1"1
1'1"1
1'1#1
1'1#1
1'1#1
1'1#1
1'1$1
1'1$1
1'1$1
1'1$1
1'1%1
1'1%1
1'1%1
1'1%1
1)1"1
1)1"1
1)1"1
1)1#1
1)1#1
1)1#1
1)1%1
1)1%1
1)1%1
1'1 1
1'1 1
1'1 1
1'1 1
1'1!1
1'1!1
1'1!1
1'1!1
1'1!1
1'1"1
1'1"1
1'1"1
1'1"1
1'1#1
1'1#1
1'1#1
1'1#1
1'1$1
1'1$1
1'1$1
1'1$1
1'1%1
1'1%1
1'1%1
1'1%1
1'1%1
1)1"1
1)1"1
1)1"1
1)1"1
1)1#1
1)1#1
1)1%1
1)1%1
1)1%1
1'1 1
1'1 1
1'1 1
1'1 1
1'1!1
1'1!1
1'1!1
1'1"1
1'1"1
1'1"1
1'1"1
1'1"1
1'1#1
1'1#1
1'1#1
1'1#1
1'1#1
1'1$1
1'1$1
1'1$1
1'1$1
1'1%1
1'1%1
1'1%1
1'1%1
1'1%1
1)1"1
1)1"1
1)1"1
1)1"1
1)1#1
1)1#1
1)1#1
1)1#1
1)1%1
1)1%1
1)1%1
1)1%1
1(1"1
1(1"1
1(1"1
1(1"1
1(1#1
1(1#1
1(1#1
1(1$1
1(1$1
1(1$1
1(1$1
1(1%1
1(1%1
1(1%1
1(1"1
1(1"1
1(1"1
1(1"1
1(1#1
1(1#1
1(1#1
1(1#1
1(1$1
1(1$1
1(1$1
1(1$1
1(1%1
1(1%1
1(1%1
1(1%1
1(1"1
1(1"1
1(1#1
1(1#1
1(1#1
1(1$1
1(1$1
1(1$1
1(1"1
1(1"1
1(1"1
1(1#1
1(1#1
1(1#1
1(1%1
1(1%1
1(1%1
1(1"1
1(1"1
1(1"1
1(1#1
1(1#1
1(1#1
1(1%1
1(1%1
1(1%1
1(1%1
1(1"1
1(1"1
1(1"1
1(1#1
1(1#1
1(1#1
1(1#1
1(1#1
1(1%1
1(1%1
1(1%1
1(1%1
1(1"1
1(1"1
1(1"1
1(1"1
1(1#1
1(1#1
1(1#1
1(1#1
1(1%1
1(1%1
1(1%1
1(1%1
1(1%1
'1 1
'1 1
'1 1
'1 1
'1 1
'1!1
'1!1
'1!1
'1!1
'1!1
'1"1
'1"1
'1"1
'1"1
'1"1
'1#1
'1#1
'1#1
'1#1
'1#1
'1$1
'1$1
'1$1
'1$1
'1$1
'1%1
'1%1
'1%1
'1%1
'1%1
(1"1
(1"1
(1"1
(1"1
(1#1
(1#1
(1#1
(1#1
(1#1
(1$1
(1$1
(1$1
(1$1
(1$1
(1%1
(1%1
(1%1
(1%1
)1"1
)1"1
)1"1
)1"1
)1#1
)1#1
)1#1
)1#1
)1#1
)1%1
)1%1
)1%1
)1%1
)1%1
NkQ]N
AS~vCS
 " 2 D 
Creating Montreal model with identifier [%s]
getSharedMontrealLanguageModel
[getSharedMontrealLanguageModel] Actually creating Montreal model with identifier [%s]
Load resource with key: [%s]
SingletonResourceManagerLoad
Still waiting for resource [%s] to complete in background.
Async resource load with key: [%s]
AsyncResourceInit
[EmojiPredictor::setDictionary] Loading %@ (%s)
[JADM::setAdditionalConversionDictionaries] #dictionary:%ld
[JADM::setAdditionalConversionDictionaries] - %ld: %@
[JADM::setAdditionalConversionDictionaries] adding dictionary %@
[JADM::setAdditionalConversionDictionaries] setting zip code dictionary path to: %@
[JADM::%s] setting blocklist path to: %@
[JADM::%s] setting language model path to: %@
 Rejected
[TSC::generateReplacements] string:%@ converted:%@ non-geometric:%d, endingIncompleteRomaji: %d
[TaggerImpl::parseNBestInit] length:%lu (prefix:%d)
MecabraJapanese engine init
MecabraJapaneseInit
Open MecabraJapanese engine
MecabraJapaneseOpen
Failed
Mecabra Japanese initialized.
Mecabra Japanese terminated.
Pruning %@ (shortcut like user words)
Pruning %@ (n-gram expansion final)
Pruning %@ (static LM score)
[MJ::makeLastBunsetsuCandidatesFromCurrentLattice]
[MJ::makeMecabMultiWordCandidates] analysisString:%@ (prefix:%d)
[MJ::makeMecabPartialCandidate]
[ME:removeTruncatedContextFromCandidates] Remove an invalid candidate %@ (%@/%@)
[ME:removeTruncatedContextFromCandidates] Converting %@ (%@/%@) to %@ (%@/%@)
[%s] CandidateStabilizer didn't stabilize
[MJ::predict] prediction:%d acceptedCandidate:%p
MecabraPredictionAnalyzeWithContext
[MJ:searchPhrasesByPosContext] Considering POS context (%d, %d) for %@ with additional cost %d
Failed to retrieve system dictionary path.
Failed to retrieve settings file path.
Failed to open Mecabra engine. (System dictionary directory: %@)
Failed to retrieve POS prediction dictionary path.
Load learners for MecabraJapanese
MecabraJapaneseLearnerLoad
Failed to register an immutable dynamic dictionary.
Failed to register a mutable dynamic dictionary.
Load word cache for MecabraJapanese
MecabraJapaneseWordCacheLoad
Failed to retrieve word cache file path.
Failed to retrieve static LM path
No static LM found at %@
Load language models for MecabraJapanese
MecabraJapaneseLanguageModelLoad
Swap RNN language model for MecabraJapanese
MecabraJapaneseRNNLanguageModelSwap
[MJ::createCandidateFromContextString] string:%@|%@ isRightContext:%d allowSynthetic:%d
[MJ::createCandidateFromContextString] 
mergedString:%@
[MJ::createCandidateFromContextString] Reverse-analyzing %@
[MJ::createCandidateFromContextString] Reverse-analysis from %@ failed. Returning a synthetic candidate with an empty analysis string.
[MJ::createCandidateFromContextString] Reverse-analysis from %@ failed. Returning nil.
Pruning %@ (excessive learning candidates)
Pruning %@ (post-processing)
[MJ::assetDictionariesDidChange]
[MJ::%s] swapping RNN language model: %@
[MJ::assetDictionariesDidChange] setting additional dictionary %s
[MecabraCreate]
Input method: %d
Failed for input method: %d
MecabraCreate
[MecabraAnalyzeString] mecabra:%p string:%@
[MecabraAnalyzeStringWithContext] mecabra:%p string:%@ options:0x%lx context:%s
MecabraAnalyzeStringWithContext
[MecabraAnalyzeGesturesWithContext] mecabra:%p gestures:%ld options:0x%lx context:%s
MecabraAnalyzeGesturesWithContext
[MecabraDeclareEndOfSentence] mecabra:%p context:%p
[MecabraAcceptInlineCandidates] mecabra:%p context:%p candidates:%s
[MecabraRevertLearningForCandidate] mecabra:%p context:%p candidate:%@
[MecabraCancelAnalysis] mecabra:%p
[MecabraAcceptCandidate] mecabra:%p candidate.surface:%@ isPartial%d
[MecabraCancelLastAcceptedCandidate] mecabra:%p
[MecabraSetAdditionalConversionDictionaries] mecabra:%p
[MecabraSetAssetDataItemsForType] mecabra:%p type:%ld dataItems:%@
[MecabraSaveLearningDictionaries] mecabra:%p
[MecabraClearLearningDictionaries] mecabra:%p
[MecabraResetLearningDictionaries] learningDictionaryDirectory:%@
[MecabraWaitForLanguageSpecificAsyncDataLoading] language: %u
[MecabraSetAddressBookNamePhoneticPairs] mecabra:%p size:%ld
Address book reset (%ld items).
SetAddressBook
[MecabraSetUserWordKeyPairs] mecabra:%p size:%ld
User word reset (%ld items).
SetUserWord
[MecabraPreheatResources] mecabra:%p
MecabraPreheatResources
[MecabraHandleMemoryPressure] mecabra:%p level:%uld, excessMemoryInBytes:%ld
level: %d, excessMemoryInBytes: %ld
MecabraHandleMemoryPressure
[MecabraRelease] mecabra:%p
[MecabraCreateCandidateFromContextString] mecabra:%p string:[%@] isRightContext:%d
[MecabraGetLengthForContextString] mecabra:%p string:[%@] isRightContext:%d
Reset (%ld) fuzzy pairs.
MecabraSetFuzzyPinyinPairs
[MecabraFlushDynamicData] mecabra:%p
[MecabraPerformMaintenance] mecabra:%p
[MecabraSpecialtyDictionaryCreateWithEntries] entries:%p
[MecabraSpecialtyDictionaryGetData] dictionary:%p
[MecabraSpecialtyDictionaryCreateWithData] dictionaryData:%p
[MecabraAddSpecialtyDictionary] mecabra:%p dictionary:%p
[MecabraRemoveSpecialtyDictionary] mecabra:%p dictionary:%p
[MecabraSpecialtyDictionaryEnumerateEntries] dictionary:%p
[MecabraSpecialtyDictionaryRelease] dictionary:%p
[MecabraAdaptToTokenizedText] mecabra:%p
[MecabraAdaptToTokenizedTextWithEffectiveTime] mecabra:%p
[MecabraAdaptToUntokenizedText] mecabra:%p
[MecabraSetDynamicLanguageModelAppContext] %@ (mecabra:%p)
 subwords %s
%s is not a valid word for prediction
Add to result: %s (%sprob:%f)
Add to open states: %s (%sprob:%f)
Open file %s failed: %s
[Mecabra] Set region lexicon: %@
[Mecabra] Set Non-regional assets: %@
 Replaced
%s (%ld): [%@] (%@/%@), type: %c, length: %s, cost: %d, base-cost: %d, prob: %3.3lf, static prob: %3.3lf penalty: %d autocorrected: %d, rank: %ld, rank(static LM): %d
curSize: %d, rebuildThreshold: %d, newSize: %d
LearningDictionaryRebuild
Corruption of learning dictionary detected. Database has been reset: %@
Data in learning dictionary trie is corrupted.
Failed to create CTC decoder: %@
Failed to create CTC decoder: (null)
Failed to create touch transcoder
[%s] Adjust Static LM Score: %.3f -> %.3f Penalties: (UNK: %.3f, LM: %.3f, Match: %.3f)
[MJ::makeMecabSingleWordCandidates] Searching single-word %s candidates for [%@] with option: 0x%.6X
Partial phrase: %@ (weight: %d)
 rejected
[%s] reset best analysis for short input
[%s] updating best analysis from previous best analysis (segment gap: %zu)
[%s] update best analysis based on truncated candidate
[%s] reset best analysis for unaligned truncated candidate
[%s] updating best analysis from history: %@
[%s] updating best analysis from converted analysis string
[%s] compound noun found, returning best segments
[%s] best-analysis:%d top-analysis:%d threshold:%d
[%s] using %@ segments as reference
[%s] segment[%zu]: from %@ segments
[%s] ignoring top segment
[%s] best analysis(%d) has a much lower weight than  top analysis(%d), using best segment
[%s] endingWithPunctuation:%d
[%s] raw analysis string: %@
[%s] Temporary Roman mode 
[%s] candidate has a punctuation, using best analysis
[%s] there is incomplete romaji and best analysis(weight:%d) can be trusted over top candidate(weight:%d) when truncated input is %s
[%s] %s: %s
[%s] topSegment:%d, bestSegment:%d, threshold:%d
[%s] top candidate: %@ (%d) prefix katakana length: %zu
[%s] last bunsetsu candidates have a hatsu-onbin verb: %@
[%s] top candidate (updated): %@ (%d) prefix katakana length: %zu
[%s] second top candidate: %@ (%d) prefix katakana length: %zu
[%s] Katakana common prefix: %d, threshold: %ld
[%s] top segment is not reliable, but using the common katakana part
[%s] top segment is not reliable
[%s] ignoring best segment since it's a prefix segment
[%s] bestLBCandidate(weight:%d) %@, topLBCandidate(weight:%d) %@, threshold: %d
[%s] using exact top segment
[%s] using the katakana part (len:%zu) of top segment (prefix matched)
[%s] using best segment
[%s] using partial candidate
[%s] expanding the last segment to hiragana string
[MecabraEngine::analyzeString] analysisStr: [%@]
[ME::acceptCandidate] S:%@ isPartial:%d performLearning:%d
Open MecabraEngine with input method: %d
MecabraEngineOpen
[ME::convert] [%@]
Candidates: [Left: %@] [Inline: %@] [Right: %@]
App Context: %@
Text Content Type: %d
Shuangpin Type: %d
Input layout key count: %ld, valid layout key count: %ld
[%s] static LM: %f dynamic LM: %f interpolated: %f
Failed to create analysis string for [%@].
[MecabraLearner::acceptCandidate] %@ isPartial:%d performLearning:%d isOTAWordlist:%d
[MecabraLearner::resetInternalState]
[MecabraLearner::actuallyAcceptCandidate] S:[%@] isPartial:%d performLearning:%d
[MecabraLearner::actuallyAcceptCandidate] adding %@ to partial candidates (total count: %lu)
[MecabraLearner::flushAcceptedCandidate] S:%@ performLearning:%d shouldLearn:%d
[MecabraLearner::registerCandidate] AS:%@ DR:%@ S:%@ isPartial:%d
Begin init for learner type [%d] at [%@]
SeaweedChineseLearner
[MJL::registerToLearningDictionary] Learning phrase %@ (%@)
[MJL::registerToLearningDictionary] Learning dynamic word %@ (%@)
[MJL::combinePartialCandidatesAndRegister] Registering as a phrase sequence: %@ (%@)
[MJL::combinePartialCandidatesAndRegister] Registering as a single phrase: %@ (%@)
[MJL::addBigramEntryIntoLearningDictionary] Registering phrase bigram %@ -> %@ %@
[MJL::addPersonNameEntryIntoLearningDictionary] Registering person name %@ -> %@
[MJL::incrementUsageCount] %@ (%@/%@) type:%@ contextWordCount:%ld
[MJL::incrementUsageCount] %@
[MJL::incrementUsageCount] Registering a dynamic token %@ %@ with ID %u
[MJL::incrementUsageCount] Incrementing usage counts for %@ (probability: %lf -> %lf)
[MJL::registerPhraseSequence] S:%@ AS:%@ DR:%@ phraseSize:%lu skipPhraseCount:%lu NonPhraseLearning:%d lexicalLearning:%d shouldLearnBigram:%d
%s (%ld): [%@] (%@/%@), type: %c, length: %s, cost: %d, base-cost: %d, prob: %3.3lf, autocorrected: %d
[JLPL::loadLexicalRules] Loading %@ (%s)
[registerPunctuationEntry] Registering punctuation preference "%@" to "%@", result:%d
[registerNonLexicalEntry] Registering non-lexical preference %@ = %d, result = %d
[LPL::registerLexicalEntry] Registering lexical rule: %@ => %@ (P0:%hu L2:[%@](%d) L1:[%@](%d) R1:[%@](%d) R2:[%@](%d)), result = %d
[LPL::matchFeature] Comparing ( %s) with ( %s)
[LPL::applyLexicalRules] Rewriting %@ (%@) => %@
[LPL::applyLexicalPreferences] %@ (%@) => %@ (lc:%d rc:%d f-lc:%d f-rc:%d)
[LPL::applyNonLexicalPreferences] %@ (%@) => %@ (lc:%d rc:%d f-lc:%d f-rc:%d)
expandTokenSequence: %@ %@ is blocklisted.
[MJNP::getAndCheckContextSurfaceAndReadingFromCandidate] %@ %@ is an invalid context word.
getAndCheckContextSurfaceAndReadingFromHistory: %@ %@ (attr: %d) is an invalid context word.
Pruning %@ (n-gram expansion)
makeCandidateFromExpandedSequence: matching inputStr:%@ predictedReading:%@ matchResult:%d incompleteLength:%ld
LookupController init with input method [%d].
LookupControllerInit
Pruning %@ (kind:%c) (after reranking)
## Sorted ##
index: %lu, surface: %@, cost: %d, dynamic-score: %lf, static-score: %lf
[%s] contentType:%@ isSupportedAssetType:0x%x
Word history %ld: [%s] [%s] (lc:%d rc:%d)
Search depth is beyond limit. May not return all expected results.
Reload for LMLoader
LanguageModelLoaderReload
[Mecabra] Reset language model
[SentencePiece tokens] input = [%s]: ids = [%s]
batches:
Context: input = [%s]: ids = [%s]
 Added
 REJECTED
[TokenizerImpl::lookup] %s
[TokenizerImpl::lookupOneWord] Input:[%s]
[TI::set_additional_dictionaries] %s has been added with ID %d.
[TokenizerImpl::set_additional_dictionaries] Failed to open %s: %s
[TokenizerImpl::getMinimumCost]
Failed to find data path for locale %s
[MecabraContextCreateMutable]
[MecabraContextRelease] context:%p
[MecabraContextSetShuangpinType] context:%p type:%d
[MecabraContextSetKeyboardLayout] context:%p
Dynamic LM word (%u, %@, %@) loaded.
softlink:o:path:/System/Library/PrivateFrameworks/InputTranscoder.framework/InputTranscoder
softlink:o:path:/System/Library/PrivateFrameworks/CoreNLP.framework/CoreNLP
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
MecabraWordProperties
MecabraCandidate
NSCopying
CharacterInformationAdditions
MecabraFacemarkCandidate
rangeOfCharacterFromSet:options:
dictionaryWithContentsOfURL:
containsObject:
removeAllObjects
length
substringToIndex:
stringByReplacingOccurrencesOfString:withString:
hasSuffix:
stringByAppendingString:
addObject:
initWithCandidate:
countByEnumeratingWithState:objects:count:
count
objectAtIndex:
rangeOfString:
rangeOfCharacterFromSet:
copy
characterAtIndex:
rawConversionCandidate
characterSetWithCharactersInString:
addCharactersInRange:
initWithBytes:length:encoding:
classNamed:
autocorrectionContextOfType:
reset
addInputCharacter:geometryModel:geometryData:
isEmojiCandidate
surface
dictionaryReading
prefixes
replacementString
stringWithCharacters:length:
type
isConversionCandidate
rawCandidate
addObjectsFromArray:
substringFromIndex:
stringWithFormat:
hasPrefix:
rangeOfString:options:range:
stringByReplacingOccurrencesOfString:withString:options:range:
substringWithRange:
isEqualToString:
componentsSeparatedByCharactersInSet:
shortValue
objectForKey:
integerValue
numberWithInteger:
setObject:forKey:
keysSortedByValueUsingComparator:
UTF8String
addEntriesFromDictionary:
stringWithCString:encoding:
dictionaryWithContentsOfFile:
boolValue
description
stringWithUTF8String:
componentsSeparatedByString:
intValue
dictionaryWithObject:forKey:
setValue:forKey:
array
enumerateSubstringsInRange:options:usingBlock:
initWithObjects:forKeys:
objectForKeyedSubscript:
appendString:
initWithPattern:options:error:
matchesInString:options:range:
numberOfRanges
rangeAtIndex:
getCharacters:range:
setDisplayString:
attributes
analysisString
convertedAnalysisString
isPersonName
isExtensionCandidate
isExtensionForCandidateBar
isLearningDictionaryCandidate
isUserWordCandidate
isPredictionCandidate
isFuzzyMatchCandidate
isAutocorrectedCandidate
isOTAWordlistCandidate
isRegionalCandidate
isBilingualCandidate
isPartialCandidate
phraseBoundaryAfterWordAtIndex:
wordCount
wordLengthAtIndex:
wordReadingLengthAtIndex:
wordDictionaryReadingLengthAtIndex:
wordIsFromSystemDictionaryAtIndex:
copySyllableLengthArrayForWordAtIndex:
lcAttrAtIndex:
rcAttrAtIndex:
trieValueAtIndex:
kindAtIndex:
costAtIndex:
lastPrefixValue
weight
kind
matchType
matchedLengthType
lmProbability
baseCost
matchPenalty
copySyllableLengthArrayInAnalysisString
copySyllableLengthArrayInConvertedAnalysisString
copySyllableLengthArrayInDictionaryReading
isWubixingConvertedByPinyin
wubixingType
wordRangeAtIndex:
initWithString:language:
valueForKey:
sortedRadicalList
arrayWithContentsOfFile:
punctuationCharacterSet
mutableCopy
whitespaceAndNewlineCharacterSet
formUnionWithCharacterSet:
symbolCharacterSet
setObject:forKeyedSubscript:
dictionaryWithCapacity:
path
defaultManager
stringByStandardizingPath
removeItemAtPath:error:
localeWithLocaleIdentifier:
calendarWithIdentifier:
setLocale:
setFormatterBehavior:
setTimeStyle:
setYear:
setMonth:
setDay:
dateFromComponents:
date
month
year
dateByAddingComponents:toDate:options:
setCalendar:
setDateFormat:
stringFromDate:
setDateStyle:
component:fromDate:
objectAtIndexedSubscript:
informationDictionaryAtPath:
initWithContentsOfURL:
firstCharacter
characterInformationDictionary
searchResultsForString:dictionary:
codeLookupInformationDictionary
language
componentsByLanguage:
firstObject
pinyinStringFromPinyinWithToneNumber
zhuyinSyllableFromPinyinSyllable
setWithCapacity:
rangeOfComposedCharacterSequenceAtIndex:
stringByStrippingDiacritics
uppercaseString
allObjects
toneFromPinyinSyllableWithNumber
init
dealloc
wubixingCodesForStandard:
codeLookupInformation
separatedInputCodesForString:
strokeStringFromNumberString
characterInformation
radicalInformationForString:
strokeInformationForString:
pinyinInformationForString:
zhuyinInformationForString:
initialsForStrings:
tonesForString:
wubixingCodes
bihuaCodes
cangjieCodes
isIncludedInCurrentLanguage
setAnalysisString:
setCharacterInformation:
setCodeLookupInformation:
isEmoji
setEmoji:
setLanguage:
_analysisString
_characterInformation
_codeLookupInformation
_emoji
_language
isMemberOfClass:
standardUserDefaults
boolForKey:
stringForKey:
removeItemAtURL:error:
fileExistsAtPath:
integerForKey:
bundleWithPath:
initWithObjects:
decimalDigitCharacterSet
rangeOfCharacterFromSet:options:range:
characterSetWithRange:
newlineCharacterSet
whitespaceCharacterSet
invertedSet
_fastCharacterContents
autoupdatingCurrentLocale
stringByTrimmingCharactersInSet:
emojiLocaleDataWithLocaleIdentifier:
emojiTokenWithString:localeData:
sharedServiceWithMachName:
dispatchQueue
preferences
didUseEmoji:
writeEmojiDefaults
supportsSkinToneVariants
lastUsedVariantEmojiForEmoji:
string
resetEmojiDefaults
recentEmojis
isAbbreviated
dictionaryWithObjects:forKeys:count:
allocWithZone:
syllablesInAnalysisString
componentsJoinedByString:
syllablesInConvertedAnalysisString
syllablesInDictionaryReading
unsignedIntegerValue
syllablesInString:syllableLengths:
numberWithUnsignedInt:
syntheticCandidateFromWords:withLexicon:language:
copyWithZone:
isSyntheticCandidate
category
convertedAnalysisStringForFirstSyllable
isEqual:
syllabifiedAnalysisString
syllabifiedConvertedAnalysisString
syllabifiedDictionaryReading
words
wordReadings
wordIDs
setWeight:
_rawCandidate
currentHandler
handleFailureInMethod:object:file:lineNumber:description:
numberWithUnsignedInteger:
initWithObjects:forKeys:count:
insertString:atIndex:
stringByReplacingCharactersInRange:withString:
callStackSymbols
compare:options:range:locale:
stringByApplyingPinyinToneMarkToFirstSyllableWithToneNumber:
lowercaseString
appendFormat:
simplifiedChineseCompare:
traditionalChinesePinyinCompare:
traditionalChineseZhuyinCompare:
initWithLocaleIdentifier:
initWithContentsOfFile:encoding:error:
getCString:maxLength:encoding:
removeObjectAtIndex:
enumerateIndexesUsingBlock:
removeObjectsAtIndexes:
firstIndex
sortUsingComparator:
setObject:atIndexedSubscript:
exchangeObjectAtIndex:withObjectAtIndex:
insertObject:atIndex:
insertObjects:atIndexes:
indexSet
addIndex:
reverseObjectEnumerator
fileURLWithPath:isDirectory:
stringWithContentsOfFile:usedEncoding:error:
arrayWithCapacity:
getLineStart:end:contentsEnd:forRange:
dataUsingEncoding:
arrayWithObjects:count:
numberWithShort:
dictionaryWithObjects:forKeys:
stringWithCapacity:
subarrayWithRange:
initWithArray:
removeObject:
writeToFile:atomically:
isEqualToArray:
indexSetWithIndex:
arrayWithObject:
range
getCharacters:
setValidSequenceCorrectionThreshold:
completions
correction
guesses
removedModifications
addedModifications
modificationType
syllableRange
modificationScore
additionalSyllableRange
initWithString:category:
copyFacemarkCandidatesForLanguage:
candidateWithString:category:
copyFacemarkCandidatesForLocale:
_string
_category
characterIsMember:
stringWithContentsOfFile:encoding:error:
^{__IDXIndex=}24@0:8^{__CFURL=}16
^{__IDXIndex=}16@0:8
@32@0:8@16^{__IDXIndex=}24
@16@0:8
@24@0:8@16
@28@0:8@16i24
v16@0:8
@20@0:8i16
v24@0:8@16
B16@0:8
v20@0:8B16
i16@0:8
v20@0:8i16
@"NSString"
@"NSArray"
@36@0:8@16^{Lexicon=^v^v}24i32
@24@0:8^{_NSZone=}16
^{MecabraCandidateBase=^^?q}16@0:8
Q16@0:8
B24@0:8^{__CFString=}16
S24@0:8Q16
{?=qq}24@0:8q16
q24@0:8q16
B24@0:8Q16
^{__CFArray=}24@0:8Q16
q24@0:8Q16
Q24@0:8Q16
S16@0:8
q16@0:8
d16@0:8
^{__CFArray=}16@0:8
@24@0:8^{MecabraCandidateBase=^^?q}16
^{ConversionCandidate=^^?q}16@0:8
B24@0:8@16
@32@0:8@16@24
v24@0:8Q16
@24@0:8Q16
q24@0:8@16
zh00
sh00
ch00
ing0
ai00
an00
ang0
ao00
ei00
en00
eng0
ia00ian0
iang
iao0
ie00
in00
iu00
ong0
ou00
ua00
uai0
uan0
ue00
un00
ui00
uo00
uang
er00
iong
a000
e000 i000!o000"u000#v000$on00%io00&ion0've00(van0)vn00*
zh00
sh00
ch00
ing0
ai00
an00
ang0
ao00
ei00
en00
eng0
ia00ian0
iang
iao0
ie00
in00
iu00
ong0
ou00
ua00
uai0
uan0
ue00
un00
ui00
uo00
uang
er00
iong
van0
ve00 a000
e000"i000#o000$u000%v000&on00'io00(ion0)
C)\hC\
k1C\
CRx0C
k1C=
^ C=
C)\hC
aC)\hC
^ C\
TCRx0C
HCq=
CC)\hC
ziC=j
<C=j
