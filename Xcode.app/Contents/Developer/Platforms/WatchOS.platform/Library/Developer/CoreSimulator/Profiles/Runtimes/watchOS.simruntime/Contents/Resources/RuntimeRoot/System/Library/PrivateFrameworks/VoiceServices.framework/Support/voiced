mcpl
error setting SRC quality: %d
%s: error %d %s level metering
%s: error converting disambiguation context
%s: allowing recognition start
%s: recognition requested when busy
%s: releasing active client to begin
%s: client requested cancellation of active recognition
%s: client requested cancellation of queued recognition
cancelling recognition
released from holding.. beginning now.
Running with background thread priority
couldn't create instance for client port - cancelling
couldn't open audio input file for reading
%s: sample rate change (now %d Hz); invalidating queue
%s: no valid models could be created
%s: client died - cancelling recognition
couldn't add listener for queue running state (%d)
couldn't create audio queue
setting recognition thread priority to %d
%s: sleeping for %g s
%s: finished starting queue in %g s
couldn't start audio queue for recognition (%d)
%s: starting recognition
%s: starting recognition from file
couldn't get file format description.
Recognition results:
--------------------
%s: error posting client completion notification
%s: error posting client error notification
%s: posted %s to client
caching model <%s> class <%s> ...
no valid cache found; recaching everything.
cache for model <%s> is valid; skipping recache request.
... finished caching model in %g s with error %d <%s> class <%s>
cache for model <%s> is valid; skipping recache.
recache for model <%s> done in %g s
error caching model <%s>
%s: couldn't write keyword index for cache
%s: couldn't create manifest for cache
%s: error setting info dict on temp cache
%s: couldn't move temp cache into place... deleting
%s: couldn't save cache; no base dir exists or couldn't create temp cache
error writing model configuration cache Info.plist:
beginning plugin registry rebuild...
finished.
%s: error examining plugins directory (%ld)
%s: error writing plugin registry cache:
data provider does not implement value method
%s: plugin class does not conform to appropriate protocol
%s: plugin class not found
%s: error loading plugin:
err %d copying manifest
#AudioSession session interrupted
#AudioSession mediaserverd died
#AudioSession : Setting up audio session
#AudioSession error setting HW sample rate: %ld
#AudioSession : category = %d
#AudioSession error %ld setting audio category
#AudioSession error %ld setting bluetooth allowability
#AudioSession : Bluetooth %sabled
#AudioSession active count went negative for input!
#AudioSession active count went negative for output!
#AudioSession active count went negative!
#AudioSession : activity %d --> %s
#AudioSession : Active --> FALSE
#AudioSession : Active --> TRUE
#AudioSession error %ld activating or deactivating session for activity %ld
#AudioSession could not stop queue (%d)
voiced starting up...
Migration failed, %@
Cannot register CacheDelete service.
Receive notification %s
com.apple.MobileAsset.VoiceServices.VoiceResources.ma.new-asset-installed: checking for a voice update
Perform force asset update
xpc_activity state must be RUN, got: %ld
running xpc_activity
Error cleanUnusedAssets in scheduled background task: %@
xpc activity com.apple.voiced, failed to set state to done.
running com.apple.voiced.weekly
xpc activity com.apple.voiced.weekly, failed to set state to done.
XPC connection invalidated, identifier: %{public}@
_VSAudioQueueSetLevelMeteringPropertyValue
enabling
disabling
_default
server_VSRecognitionPrepareOrBegin
server_VSRecognitionBegin
server_VSRecognitionCancel
com.apple.voiceservices.recognition
Error %d at %s:%d
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VoiceServicesDaemons_Sim/VoiceServices-550.14/Daemon/VSRecognitionServer.c
_CreateEngineIfNecessary
_InitializeEngine
_RecognitionClientInvalidationCallback
Error %d at %s:%d (%s)
couldn't start recognition
recording.wav
_BeginRecognition
_SendChoices
VSClientPostNotification
VSLocaleIdentifier
VSVersion
VSPluginVersions
KeywordIndex.plist
%@%@
.vscache
Info.plist
temp.vscache.XXXXX
_SaveEngineToCache
VSEngineIdentifier
temp.vscache.
PluginPath
PluginRegistry.plist
_CreateRegistryAndSaveToCache
modelid-desc
pluginid-vers
pluginpath-moddate
/System/Library/VoiceServices/PlugIns
Library
Caches
VoiceServices
VSRecognitionVersion
VSRecognitionModels
VSRecognitionModelIdentifier
VSRecognitionModelFileName
VSRecognitionModelIsTopLevel
VSRecognitionModelWeight
VSRecognitionModelIsCancelModel
VSRecognitionModelRequiredCapabilities
VSRecognitionModelDataProvider
VSRecognitionResultValidator
VSRecognitionResultHandler
vsplugin
lang
VSRecognitionModelDefinition
.plist
VSPlugin
<VSPlugin %p: %@>
VSRecognitionClasses
VSRecognitionSequences
VSRecognitionKeywords
VSRecognitionClassIdentifier
VSRecognitionClassRequiredCapabilities
VSRecognitionClassElements
VSRecognitionClassElementValues
VSRecognitionClassSequences
VSRecognitionClassType
VSRecognitionClassWeight
VSRecognitionClassContainsKeywords
VSRecognitionClassTypeCommand
VSRecognitionClassTypePersonName
VSRecognitionClassTypeStreetName
VSRecognitionClassTypeCityName
VSRecognitionClassTypeSongTitle
VSRecognitionClassTypeArtistName
VSRecognitionClassTypeAlbumName
VSRecognitionSequenceElements
VSRecognitionSequenceDisambiguationTag
hash
TI,R
superclass
T#,R
description
T@"NSString",R,C
debugDescription
_InstantiatePluginClassWithRecognitionModelKeyedName
_LoadPluginIfNecessary
isvalid
VSRecognitionClassDataProvider
dflt%ld
VSRecognitionModel
VSRecognitionClass
VSRecognitionSequence
<%@>
Manifest.sqlitedb
SELECT model_id, validity FROM Model;
 WHERE model_id = ?;
INSERT OR REPLACE INTO ValueTranslation (model_id, class_id, original_value, translated_value) VALUES (?, ?, ?, ?);
SELECT original_value FROM ValueTranslation WHERE model_id = ? AND class_id = ? AND translated_value = ?;
DELETE FROM ValueTranslation
 model_id = ?
 class_id = ?
 WHERE
 AND
VSRecognitionConfigurationCacheManifest
Model
model_id
validity
last_update
SELECT %s FROM %s WHERE ROWID = ?
UPDATE %s SET %s = ? WHERE ROWID = ?
ValueTranslation
CREATE TABLE Model (ROWID INTEGER PRIMARY KEY AUTOINCREMENT, model_id TEXT, validity TEXT, last_update INTEGER, UNIQUE(model_id));
CREATE INDEX ModelIdIndex on Model(model_id);
CREATE TABLE ValueTranslation (ROWID INTEGER PRIMARY KEY AUTOINCREMENT, model_id TEXT, class_id TEXT, original_value TEXT, translated_value TEXT, UNIQUE(model_id, class_id, original_value));
CREATE INDEX ValueTranslationModelIdClassIdIndex on ValueTranslation(model_id, class_id, translated_value);
v4@?0
VSAudioSessionQueue
ACTIVE
INACTIVE
LatencyFudgeFactor
com.apple.voiceservices.notification.voice-update
com.apple.voiceservices.trigger.asset-force-update
v8@?0@"NSError"4
com.apple.notifyd.matching
v8@?0@"NSObject<OS_xpc_object>"4
com.apple.MobileAsset.VoiceServicesVocalizerVoice.ma.cached-metadata-updated
com.apple.MobileAsset.VoiceServices.GryphonVoice.ma.new-asset-installed
com.apple.MobileAsset.VoiceServicesVocalizerVoice.ma.new-asset-installed
com.apple.MobileAsset.VoiceServices.VoiceResources.ma.new-asset-installed
LastAttemptedDownloadTimeForNewResource
com.apple.voiced
KeepAliveManager
com.apple.voiceservices.keepalive
com.apple.voiced.weekly
connectionCount
TI,N,V_connectionCount
runloopSourceRef
T^{__CFRunLoopSource=},N,V_runloopSourceRef
listener
T@"NSXPCListener",&,N,V_listener
getValue:weight:atIndex:forClassWithIdentifier:inModelWithIdentifier:
phoneticValueAtIndex:forClassWithIdentifier:inModelWithIdentifier:
isEqual:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
description
debugDescription
valueCountForClassWithIdentifier:inModelWithIdentifier:
valueAtIndex:forClassWithIdentifier:inModelWithIdentifier:
cacheValidityIdentifier
isCacheValidityIdentifierValid:
beginReportingChanges
stopReportingChanges
alloc
init
validRecognitionResultFromRecognitionResult:
validRecognitionResultFromRecognitionResult:knownDisambiguationValues:
defaultCenter
_audioSessionInterrupted:
addObserver:selector:name:object:
_mediaServicesWereReset:
removeObserver:
dealloc
userInfo
objectForKey:
integerValue
_setupAudioSession
sharedInstance
setPreferredSampleRate:error:
code
setCategory:error:
categoryOptions
setCategory:withOptions:error:
_setCategoryForActivity:
_nextActivityForActive:activity:serverActivity:
setActive:error:
category
_safeSetupAudioSession
_safeServerGeneration
_safeSetCategoryForActivity:
_safeSetActive:withActivity:
_safeSetBluetoothInputAllowed:
.cxx_destruct
_queue
_audioSessionIsSetUp
_desiredState
_cachedState
_bluetoothAllowed
_activityBag
_serverGeneration
outputLatency
inputLatency
IOBufferDuration
doubleValue
currentRoute
inputs
count
objectAtIndex:
portType
opaqueSessionID
performPostInstallWithCompletion:
sharedService
registerCacheDelete
initWithType:
updateVoicesAndVoiceResources
resume
currentRunLoop
timeIntervalSinceNow
date
sharedManager
resetCache
UTF8String
numberWithDouble:
initWithMachServiceName:
setDelegate:
invalidate
maintainWithAudioType:keepAudioSessionActive:
cancel
interfaceWithProtocol:
setExportedInterface:
setExportedObject:
setInvalidationHandler:
listener:shouldAcceptNewConnection:
_keepAliveListener
_keepAliveManager
addObject:
removeObject:
hasActiveKeepAlives
maintainKeepAlive:
cancelKeepAlive:
_activeKeepAlives
_shouldChangeAudioSession
setManager:
_manager
_isActive
_activity
_keepSessionActive
_transaction
_registryRunLoopSource
scheduleBackgroundTask
isAudioAccessory
localizedDescription
cleanUnusedAssets:
defaultCacheStore
cleanCache
defaultAudioDumpStore
cleanAudioDump
speechRequestDidStart
speechRequestDidPause
speechRequestDidContinue
speechRequestMark:didStartForRange:
speechRequestDidStopWithSuccess:phonemesSpoken:error:
speechRequestSuccessWithInstrumentMetrics:
speechRequestDidReceiveTimingInfo:
synthesisRequest:didReceiveTimingInfo:
synthesisRequest:didFinishWithInstrumentMetrics:error:
presynthesizedAudioRequestDidStart
presynthesizedAudioRequestDidStopAtEnd:error:
presynthesizedAudioRequestSuccessWithInstrumentMetrics:error:
setRemoteObjectInterface:
updateWithConnectionIdentifier:
prewarmIfNeededWithRequest:
queryPhaticCapabilityWithRequest:reply:
startSpeechRequest:
startSynthesisRequest:
pauseSpeechRequestAtMark:
continueSpeechRequest
stopSpeechRequestAtMark:
startPresynthesizedAudioRequest:
cachePresynthesizedAudioRequest:
stopPresynthesizedAudioRequest
getVoiceNamesForLanguage:reply:
getFootprintsForVoiceName:languageCode:reply:
getSpeechIsActiveReply:
getSpeechIsActiveForConnectionReply:
beginAudioPowerUpdateWithReply:
endAudioPowerUpdate
getLocalVoicesReply:
getLocalVoiceResourcesReply:
setAutoDownloadedVoiceAssets:withClientID:
getAutoDownloadedVoiceAssetsWithClientID:reply:
getVoiceResourceForLanguage:reply:
getVoiceInfoForLanguageCode:footprint:gender:type:reply:
setLogToFile:
getLogToFile:
getTTSServerVoicesWithFilter:reply:
forwardStreamObject:
arrayWithObjects:count:
setWithArray:
setClasses:forSelector:argumentIndex:ofReply:
initWithConnection:
connectionIdentifier
isSpeaking
connectionCount
setConnectionCount:
runloopSourceRef
setRunloopSourceRef:
listener
setListener:
_connectionCount
_runloopSourceRef
_listener
VSRecognitionModelDataProvider
NSObject
VSRecognitionResultValidator
VSAudioSession
VSRemoteKeepAlive
VSKeepAliveServer
NSXPCListenerDelegate
VSServerKeepAliveManager
VSKeepAliveClient
VSSpeechServiceDelegate
VSSpeechXPCServiceProtocol
VSSpeechServer
B12@0:4@8
#8@0:4
@8@0:4
@12@0:4:8
@16@0:4:8@12
@20@0:4:8@12@16
B8@0:4
B12@0:4#8
B12@0:4:8
Vv8@0:4
I8@0:4
^{_NSZone=}8@0:4
B12@0:4@"Protocol"8
@"NSString"8@0:4
i16@0:4@8@12
@20@0:4i8@12@16
B28@0:4^@8^i12i16@20@24
v8@0:4
i16@0:4@"NSString"8@"NSString"12
@"NSString"20@0:4i8@"NSString"12@"NSString"16
B28@0:4^@8^i12i16@"NSString"20@"NSString"24
@"NSDictionary"8@0:4
B12@0:4@"NSDictionary"8
@12@0:4@8
@16@0:4@8@12
@"VSRecognitionResult"12@0:4@"VSRecognitionResult"8
@"VSRecognitionResult"16@0:4@"VSRecognitionResult"8@"NSDictionary"12
v12@0:4@8
v12@0:4l8
l20@0:4B8l12l16
i8@0:4
v16@0:4B8l12
v12@0:4B8
@"NSObject<OS_dispatch_queue>"
{?="category"i"activity"l}
^{__CFBag=}
Vv16@0:4i8B12
B16@0:4@8@12
B16@0:4@"NSXPCListener"8@"NSXPCConnection"12
@"NSXPCListener"
@"VSServerKeepAliveManager"
@"NSMutableSet"
@"NSObject<OS_os_transaction>"
^{__CFRunLoopSource=}
Vv20@0:4l8{_NSRange=II}12
Vv20@0:4B8@12@16
Vv12@0:4@8
Vv16@0:4@8@12
Vv20@0:4@8@12@16
Vv16@0:4B8@12
Vv20@0:4B8@"NSString"12@"NSError"16
Vv12@0:4@"VSInstrumentMetrics"8
Vv12@0:4@"NSArray"8
Vv16@0:4@"VSSpeechRequest"8@"NSArray"12
Vv20@0:4@"VSSpeechRequest"8@"VSInstrumentMetrics"12@"NSError"16
Vv16@0:4B8@"NSError"12
Vv16@0:4@"VSInstrumentMetrics"8@"NSError"12
Vv16@0:4@8@?12
Vv12@0:4l8
Vv20@0:4@8@12@?16
Vv12@0:4@?8
Vv28@0:4@8l12l16l20@?24
Vv12@0:4B8
Vv12@0:4@"NSString"8
Vv12@0:4@"VSSpeechRequest"8
Vv16@0:4@"VSSpeechRequest"8@?<v@?B>12
Vv12@0:4@"VSPresynthesizedAudioRequest"8
Vv16@0:4@"NSString"8@?<v@?@"NSArray">12
Vv20@0:4@"NSString"8@"NSString"12@?<v@?@"NSArray">16
Vv12@0:4@?<v@?B>8
Vv12@0:4@?<v@?@"AFXPCWrapper">8
Vv12@0:4@?<v@?@"NSError">8
Vv12@0:4@?<v@?@"NSArray"@"NSError">8
Vv16@0:4@"NSArray"8@"NSString"12
Vv16@0:4@"NSString"8@?<v@?@"VSVoiceResourceAsset">12
Vv28@0:4@"NSString"8l12l16l20@?<v@?@"VSVoiceAsset">24
Vv16@0:4@"VSVoiceAsset"8@?<v@?@"NSArray"@"NSError">12
Vv12@0:4@"SATTSSpeechSynthesisStreaming"8
v12@0:4I8
^{__CFRunLoopSource=}8@0:4
v12@0:4^{__CFRunLoopSource=}8
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
<key>BuildMachineOSBuild</key>
<string>18A391011</string>
<key>CFBundleDevelopmentRegion</key>
<string>English</string>
<key>CFBundleExecutable</key>
<string>voiced</string>
<key>CFBundleIdentifier</key>
<string>com.apple.voiced</string>
<key>CFBundleInfoDictionaryVersion</key>
<string>6.0</string>
<key>CFBundleName</key>
<string>voiced</string>
<key>CFBundlePackageType</key>
<string>FMWK</string>
<key>CFBundleShortVersionString</key>
<string>1.0.0</string>
<key>CFBundleSignature</key>
<string>????</string>
<key>CFBundleSupportedPlatforms</key>
<array>
<string>WatchSimulator</string>
</array>
<key>CFBundleVersion</key>
<string>1.0</string>
<key>DTCompiler</key>
<string>com.apple.compilers.llvm.clang.1_0</string>
<key>DTPlatformBuild</key>
<string>11L374m</string>
<key>DTPlatformName</key>
<string>watchsimulator</string>
<key>DTPlatformVersion</key>
<string>6.0</string>
<key>DTSDKBuild</key>
<string>17R543</string>
<key>DTSDKName</key>
<string>watchsimulator6.0.internal</string>
<key>DTXcode</key>
<string>1100</string>
<key>DTXcodeBuild</key>
<string>11L374m</string>
<key>MinimumOSVersion</key>
<string>6.0</string>
<key>UIDeviceFamily</key>
<array>
<integer>4</integer>
</array>
</dict>
</plist>
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
<key>abs-client</key>
<string>1821501079</string>
<key>com.apple.Contacts.database-allow</key>
<true/>
<key>com.apple.coreaudio.allow-opus-codec</key>
<true/>
<key>com.apple.coreaudio.register-internal-aus</key>
<true/>
<key>com.apple.developer.networking.multipath_extended</key>
<true/>
<key>com.apple.private.assets.accessible-asset-types</key>
<array>
<string>com.apple.MobileAsset.VoiceServices.CustomVoice</string>
<string>com.apple.MobileAsset.VoiceServices.VoiceResources</string>
<string>com.apple.MobileAsset.VoiceServicesVocalizerVoice</string>
<string>com.apple.MobileAsset.VoiceServices.GryphonVoice</string>
</array>
<key>com.apple.private.assets.change-daemon-config</key>
<true/>
<key>com.apple.private.coreaudio.borrowaudiosession.allow</key>
<true/>
<key>com.apple.private.tcc.allow</key>
<array>
<string>kTCCServiceAddressBook</string>
<string>kTCCServiceMicrophone</string>
<string>kTCCServiceMediaLibrary</string>
</array>
<key>com.apple.siri.client_lite</key>
<true/>
</dict>
</plist>
