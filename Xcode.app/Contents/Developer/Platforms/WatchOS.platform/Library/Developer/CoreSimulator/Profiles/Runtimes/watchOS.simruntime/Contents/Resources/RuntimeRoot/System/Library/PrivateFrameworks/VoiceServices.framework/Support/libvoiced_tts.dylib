VoiceServicesErrorDomain
Synthesis is cancelled/interrupted.
v4@?0
@"NSError"8@?0@"VSSpeechSynthesisCallbackResult"4
hash
TI,R
superclass
T#,R
description
T@"NSString",R,C
debugDescription
speakTask
T@"VSSpeechSpeakTask",&,N,V_speakTask
readyForEagerTask
TB,N,V_readyForEagerTask
asbd
T{AudioStreamBasicDescription=dIIIIIIII},N,V_asbd
pcmBufferSize
TI,N,V_pcmBufferSize
floatConverter
T^{OpaqueAudioConverter=},N,V_floatConverter
integerConverter
T^{OpaqueAudioConverter=},N,V_integerConverter
voiceBoostUnit
T^{OpaqueAudioComponentInstance=},N,V_voiceBoostUnit
audioTimeStamp
T{AudioTimeStamp=dQdQ{SMPTETime=ssILLssss}LI},N,V_audioTimeStamp
voiceBoostGainDecibels
Tf,N,V_voiceBoostGainDecibels
%@ %@ %@ %@ %.2f %.2f %.2f %@
Speech is cancelled/interrupted.
request
T@"VSSpeechRequest",&,N,V_request
timingInfos
T@"NSArray",&,N,V_timingInfos
delegate
T@"<VSSpeechServiceDelegate>",W,N,V_delegate
engine
T@"VSSpeechEngine",&,N,V_engine
voiceBooster
T@"VSVoiceBooster",&,N,V_voiceBooster
playbackService
T@"VSAudioPlaybackService",&,N,V_playbackService
voiceSelection
T@"VSVoiceAssetSelection",&,N,V_voiceSelection
voiceResource
T@"VSVoiceResourceAsset",&,N,V_voiceResource
cachingService
T@"VSCachingService",&,N,V_cachingService
instrumentMetrics
T@"VSInstrumentMetrics",&,N,V_instrumentMetrics
speechCache
T@"<VSSpeechCacheItem>",&,N,V_speechCache
phonemes
T@"NSArray",&,N,V_phonemes
audio
T@"VSAudioData",&,N,V_audio
error
T@"NSError",&,N,V_error
taskAuxiliaryQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_taskAuxiliaryQueue
ServerTTSErrorDomain
%@:%@:server
%@:server
Unable to create playback service
EagerTTS
v12@?0@"VSAudioData"4@"NSArray"8
v8@?0@"NSError"4
Server TTS timeout
Task is cancelled.
osprey_round_trip
osprey_streaming
ace_round_trip
ace_inline_streaming
device
unknown
Cancelled
Finished
speaking
synthesizing
voice
(null)
is_eager
is_one_shot
is_time_out
is_device_tts
source_of_tts
shouldSpeak
TB,N,V_shouldSpeak
wordTimingInfo
T@"NSArray",&,N,V_wordTimingInfo
timeoutCondition
T{_opaque_pthread_cond_t=l[24c]},N,V_timeoutCondition
T@"VSSpeechServerTask",&,N,V_speakTask
synthesisCore
T@"VSDeviceTTSCore",&,N,V_synthesisCore
useServerResponse
TB,N,V_useServerResponse
useDeviceSynthesis
TB,N,V_useDeviceSynthesis
speechStartReported
TB,N,V_speechStartReported
isEagerCache
TB,N,V_isEagerCache
disableOsprey
TB,N,V_disableOsprey
racingMutex
T{_opaque_pthread_mutex_t=l[40c]},N,V_racingMutex
serverAudio
T@"VSAudioData",&,N,V_serverAudio
deferredTTSTimingInfo
T@"NSArray",&,N,V_deferredTTSTimingInfo
internalSettings
T@"VSSpeechInternalSettings",&,N,V_internalSettings
ospreyCore
T@"VSOspreyTTSCore",&,N,V_ospreyCore
serverTTSConfig
T@"VSServerTTSConfig",&,N,V_serverTTSConfig
\mrk=emo=whisper\
com.apple.voiced.request.speech
com.apple.voiced.request.presynthesis
com.apple.voiced.request.synthesis
VSAudioPowerUpdateQueue
-[VSSpeechXPCHandler beginAudioPowerUpdateWithReply:]
v8@?0@"AFXPCWrapper"4
-[VSSpeechXPCHandler endAudioPowerUpdate]
-[VSSpeechXPCHandler getVoiceInfoForLanguageCode:footprint:gender:type:reply:]
connectionIdentifier
T@"NSString",&,N,V_connectionIdentifier
audioPowerUpdateQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_audioPowerUpdateQueue
audioPowerUpdater
T@"AFAudioPowerUpdater",&,N,V_audioPowerUpdater
Osprey round-trip TTS timed out
v16@?0@"VSVoiceAsset"4@"VSVoiceResourceAsset"8f12
Osprey streaming TTS timed out
serverTTSClient
T@"VSServerTTSClient",&,N,V_serverTTSClient
serverConfig
T@"VSServerTTSConfig",&,N,V_serverConfig
bufferDurationLimit
Td,N,V_bufferDurationLimit
T@"VSTimeoutCondition",&,N,V_timeoutCondition
T@"VSSpeechRequest",R,N,V_request
T@"<VSOspreyTTSCoreDelegate>",W,N,V_delegate
T@"VSInstrumentMetrics",W,N,V_instrumentMetrics
T@"VSAudioData",R,N,V_audio
T@"VSVoiceAsset",&,N,V_voice
T@"NSString",&,N,V_key
audioData
T@"NSData",&,N,V_audioData
packetCount
Ti,N,V_packetCount
packetDescriptions
T@"NSData",&,N,V_packetDescriptions
magicVersion
Ti,R,N,V_magicVersion
T@"NSArray",R,N,V_timingInfos
/var/mobile/Library/VoiceServices/SpeechCache
TTSResources/PreinstallCache/
VSSpeechCacheErrorDomain
com.apple.voiceservices
-[VSSpeechCache initWithStorePath:]
Cache type name too long
-[VSSpeechCache addCache:]
male
female
%@_%@
dirPath
T@"NSString",&,N,V_dirPath
preinstalledCacheDir
T@"NSString",&,N,V_preinstalledCacheDir
FlatBuffers 1.11.0
language
T@"NSString",R,N
gender
name
version
quality
T@"OPTTSTextToSpeechVoice",R,N
resource
T@"OPTTSTextToSpeechResource",R,N
channel_type
Ti,R,N
app_id
speech_id
session_id
text
audio_type
enable_word_timing_info
TB,R,N
voice_name
context_info
T@"NSArray",R,N
preferred_voice_type
meta_info
T@"OPTTSTextToSpeechRequestMeta",R,N
value
sample_rate
Td,R,N
format_id
TI,R,N
format_flags
bytes_per_packet
frames_per_packet
bytes_per_frame
channels_per_frame
bits_per_channel
reserved
word
sample_idx
offset
length
timestamp
Tf,R,N
error_code
error_str
T@"NSData",R,N
decoder_description
T@"OPTTSAudioDescription",R,N
playback_description
word_timing_info
T@"OPTTSTextToSpeechMeta",R,N
stream_id
streaming_playback_buffer_size_in_seconds
current_pkt_number
total_pkt_number
content_type
contentAsOPTTSStartTextToSpeechStreamingRequest
T@"OPTTSStartTextToSpeechStreamingRequest",R,N
contentAsOPTTSBeginTextToSpeechStreamingResponse
T@"OPTTSBeginTextToSpeechStreamingResponse",R,N
contentAsOPTTSPartialTextToSpeechStreamingResponse
T@"OPTTSPartialTextToSpeechStreamingResponse",R,N
contentAsOPTTSFinalTextToSpeechStreamingResponse
T@"OPTTSFinalTextToSpeechStreamingResponse",R,N
Verifier
/BuildRoot/Applications/Xcode.app/Contents/Developer/Platforms/WatchSimulator.platform/Developer/SDKs/WatchSimulator6.0.Internal.sdk/usr/local/include/flatbuffers/flatbuffers.h
size_ < FLATBUFFERS_MAX_BUFFER_SIZE
NotNested
!nested
!num_field_loc
ensure_space
cur_ >= scratch_ && scratch_ >= buf_
size() < FLATBUFFERS_MAX_BUFFER_SIZE
reallocate_downward
new_size > old_size
ReferTo
off && off <= GetSize()
EndTable
nested
table_object_size < 0x10000
!ReadScalar<voffset_t>(buf_.data() + field_location->id)
data
cur_
scratch_end
scratch_
scratch_data
buf_
EndVector
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
'%c%c%c%c', %.0fhz, %d bits, %d FPP, 
%@:%@
%@:gryphon:%@:%@:%@:%@:null:null
voiced_tts_playback_queue
Error AudioQueueStart
YYYY-MM-dd hh:mm:ss:SSS
-[VSAudioPlaybackService getAveragePower:andPeakPower:]
audioQueue
T^{OpaqueAudioQueue=},N,V_audioQueue
state
Ti,N,V_state
waitForStateChangeMutex
T{_opaque_pthread_mutex_t=l[40c]},N,V_waitForStateChangeMutex
stateChangeCondition
T{_opaque_pthread_cond_t=l[24c]},N,V_stateChangeCondition
enqueuedSampleCount
Td,N,V_enqueuedSampleCount
audioQueueStartDate
T@"NSDate",&,N,V_audioQueueStartDate
audioQueueFutureEndDate
T@"NSDate",&,N,V_audioQueueFutureEndDate
outputRoute
T@"NSString",&,N,V_outputRoute
sessionID
TI,N,V_sessionID
com.apple.voiceservices.notification.voice-update
No voice available
Compact voice is explicitly disabled.
Voice is deleted already.
Can't create VSSpeechEngine
selectedVoice
T@"VSVoiceAssetSelection",&,N,V_selectedVoice
selectedVoiceResource
T@"VSVoiceResourceAsset",&,N,V_selectedVoiceResource
T@"<VSDeviceTTSCoreDelegate>",W,N,V_delegate
CACHE_DELETE_AMOUNT
CACHE_DELETE_VOLUME
com.apple.voiced.CacheDelete
r^{__CFDictionary=}12@?0i4r^{__CFDictionary=}8
refreshTimeoutCondition
T@"NSCondition",&,N,V_refreshTimeoutCondition
shouldStop
TB,N,V_shouldStop
timeoutValue
Td,N,V_timeoutValue
compact
premium
v16@?0d4f12
type
TI,R,N,V_type
https://guzzoni.apple.com
https://seed.siri.apple.com
https://carry.siri.apple.com
deviceID
T@"NSString",&,N,V_deviceID
/var/mobile/Library/Logs/CrashReporter/VoiceServices/
-[VSAudioDump createDirectoryIfNeeded]
yyyy_MM_dd-HHmmss.SSS
TTS-%@.%@
audioDumpPath
T@"NSString",&,N,V_audioDumpPath
ServerTTSTimeout
DeviceWaitTime
ServerTTSPrefer
DisableOsprey
WhitelistedAppId
com.apple.springboard
com.apple.siri
com.apple.CarPlayApp
com.apple.Carousel
com.apple.AssistantServices
com.apple.MapsSupport
knowledgeStore
T@"CKKnowledgeStore",&,N,V_knowledgeStore
timeout
deviceWaitTime
prefer
whitelistedAppId
cache
T@"NSCache",&,N,V_cache
cacheTimer
T@"NSCache",&,N,V_cacheTimer
Unknown inline streaming error %d, %@
Stream TTS network stall
Stream TTS timed out
voice_resource
streamID
T@"NSString",&,N,V_streamID
deviceTTSCore
T@"VSDeviceTTSCore",&,N,V_deviceTTSCore
deviceTTSInstrumentMetrics
T@"VSInstrumentMetrics",&,N,V_deviceTTSInstrumentMetrics
playbackServices
T@"VSAudioPlaybackService",&,N,V_playbackServices
finalAudio
T@"VSAudioData",&,N,V_finalAudio
finalTimingInfo
T@"NSMutableArray",&,N,V_finalTimingInfo
playbackBeginDate
T@"NSDate",&,N,V_playbackBeginDate
task: inprogress %@, request: %@
Can't create VSAudioPlaybackService
Can't decode audio data
T@"VSPresynthesizedAudioRequest",R,N,V_request
T@"NSMutableData",&,N,V_audioData
previousProvider
T@"<AFAudioPowerProviding>",W,N,V_previousProvider
com.apple.voiced.VSNotificationQueue
queuedNotification
T@"NSMutableDictionary",&,N,V_queuedNotification
ongoingNotifications
T@"NSMutableSet",&,N,V_ongoingNotifications
lock
T{_opaque_pthread_mutex_t=l[40c]},N,V_lock
notifyQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_notifyQueue
T@"NSString",C,N
T@"OPTTSTextToSpeechVoice",C,N
T@"OPTTSTextToSpeechResource",C,N
Ti,N
TB,N
T@"NSArray",C,N
T@"OPTTSTextToSpeechRequestMeta",C,N
Td,N
TI,N
Tf,N
T@"NSData",C,N
T@"OPTTSAudioDescription",C,N
T@"OPTTSTextToSpeechMeta",C,N
content
T@"OPTTSStartTextToSpeechStreamingRequest",C,N
T@"OPTTSBeginTextToSpeechStreamingResponse",C,N
T@"OPTTSPartialTextToSpeechStreamingResponse",C,N
T@"OPTTSFinalTextToSpeechStreamingResponse",C,N
finished
Finish
strlen(file_identifier) == kFileIdentifierLength
com.apple.voiced.prewarmQueue
Prewarm textify emoji
gryphon_frontend
VoiceServices/config
cachedEngine
T@"VSSpeechEngine",&,N,V_cachedEngine
loadedResources
T@"VSVoiceResourceAsset",&,N,V_loadedResources
prewarmQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_prewarmQueue
com.apple.voiceservices.request
%@.%@.%@
client
%@.%@
locale
footprint
loggingPrefix
T@"NSString",&,N,V_loggingPrefix
v8@?0@"SABaseCommand"4
v12@?0B4@"NSError"8
-[VSServerTTSClient ospreyStartSynthesisRequest:responseHandler:completion:]_block_invoke
Unable to process audio data.
v12@?0@"OPTTSTextToSpeechResponse"4@"NSError"8
v8@?0@"OPTTSBeginTextToSpeechStreamingResponse"4
v8@?0@"OPTTSPartialTextToSpeechStreamingResponse"4
v8@?0@"OPTTSFinalTextToSpeechStreamingResponse"4
-[VSServerTTSClient aceStartSynthesisRequest:responseHandler:completion:]_block_invoke
Unable to parse audio data
rate
pitch
volume
isEager
com.apple.voiced.cachingQueue
@"AVAudioBuffer"12@?0I4^i8
threadLock
T@"NSLock",&,N,V_threadLock
inMemoryCaches
T@"NSMutableArray",&,N,V_inMemoryCaches
cacheStore
T@"VSSpeechCache",&,N,V_cacheStore
shortTermCache
T@"VSShortTermCache",&,N,V_shortTermCache
cachingQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_cachingQueue
VSVocalizerEngine
T@"NSString",&,N,V_text
stopMark
Tl,N,V_stopMark
callback
T@?,C,N,V_callback
wordTimings
T@"NSMutableArray",&,N,V_wordTimings
samplesProcessed
TI,N,V_samplesProcessed
lastUTF8Offset
TI,N,V_lastUTF8Offset
lastUTF16Offset
TI,N,V_lastUTF16Offset
numOfPromptsTriggered
TI,N,V_numOfPromptsTriggered
path
mimeType
TTSSynthesizer::load_resource
i8@?0i4
TTSSynthesizer::synthesize_text
voicePath
T@"NSString",&,N,V_voicePath
synthesizer
T^{TTSSynthesizer={unique_ptr<TTSSynthesizer::TTSSynthesizerInternal, std::__1::default_delete<TTSSynthesizer::TTSSynthesizerInternal> >={__compressed_pair<TTSSynthesizer::TTSSynthesizerInternal *, std::__1::default_delete<TTSSynthesizer::TTSSynthesizerInternal> >=^{TTSSynthesizerInternal}}}},N,V_synthesizer
currentCallbackResult
T@"VSSpeechSynthesisCallbackResult",&,N,V_currentCallbackResult
T{AudioStreamBasicDescription=dIIIIIIII},R,N,V_asbd
Tf,N,V_rate
Tf,N,V_pitch
Tf,N,V_volume
com.apple.voiced.speakingQueue
eagerTasks
T@"NSMutableArray",&,N,V_eagerTasks
speakTasks
T@"NSMutableArray",&,N,V_speakTasks
currentTask
T@"<VSSpeechTaskProtocol>",&,N,V_currentTask
threadMutex
T{_opaque_pthread_mutex_t=l[40c]},N,V_threadMutex
threadMutexAttr
T{_opaque_pthread_mutexattr_t=l[8c]},N,V_threadMutexAttr
speakingQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_speakingQueue
lastSynthesisRequest
T@"VSSpeechRequest",&,N,V_lastSynthesisRequest
lastSynthesisRequestCreatedTimeStamp
TQ,N,V_lastSynthesisRequestCreatedTimeStamp
audioDataFromFile:error:
AudioFileOpenURL
AudioFileGetProperty kAudioFilePropertyDataFormat
AudioFileGetProperty kAudioFilePropertyAudioDataByteCount
AudioFileGetProperty kAudioFilePropertyAudioDataPacketCount
+[VSAudioData(SAUIAudioData) audioDataWithASBD:rawData:]
filePath
T@"NSString",R,N,V_filePath
fileSize
TL,R,N,V_fileSize
mappedData
T^v,R,N,V_mappedData
Ti,R,N,V_fd
Task %p reported word time info
Device SpeakTask %p: Instrument metric: %@
Task %p started speaking
Device EagerTask %p: Instrument metric: %@
Task %p reported finish, error: %@
Error AudioUnitSetProperty _floatConverter %d
Error AudioUnitSetProperty _integerConverter %d
Error AudioComponentInstanceNew _voiceBoostUnit %d
Error AudioUnitSetProperty _voiceBoostUnit, kAudioUnitProperty_MaximumFramesPerSlice %d
Error AudioUnitSetProperty _voiceBoostUnit, kAudioUnitProperty_StreamFormat, kAudioUnitScope_Input %d
Error AudioUnitSetProperty _voiceBoostUnit, kAudioUnitProperty_StreamFormat, kAudioUnitScope_Output,  %d
Error AudioUnitInitialize _voiceBoostUnit %d
Error AudioUnitSetParameter %d
Error AudioConverterConvertComplexBuffer _floatConverter %d
Error AudioUnitProcess _voiceBoostUnit %d
Error AudioConverterConvertComplexBuffer _integerConverter %d
Using timestamp inside voiced
Starting speech task: %p
Short-term cached synthesis is found for text '%@'
Device task %p: Instrument metric: %@
Using requestCreatedTimestamp inside voiced
Received server TTS response. Use Server TTS.
Received device synthesis previously, ignore server TTS.
Server network error: %@
Device fallback synthesis is disabled.
Start playing device synthsis instead.
Always defer device TTS.
Received server TTS previously, ignore device TTS
Received device synthesis with compact voice. Wait for server response.
Received device synthesis, but wait for server response.
Received device synthesis. Use device synthesis since it's not deferred.
Wait for network response, timeout value: %.3f
Inline server TTS is previously cached.
Eager server TTS is previously cached.
Device TTS wait time: %.2f
Device TTS is cancelled since server TTS is received.
Server task %p: Instrument metric: %@
Error in server task %p, error: %@
Server task %p: %@ %@ utterance: '%@', %{public}@
%@ is not TTS language, fallback to %@
Overwriting volume with internal default: %.3f
Utterance to synthesize for request 0x%0lx: '%@'
Update with connection identifier: %{public}@
Server TTS is disabled in internal settings
Created stream speak task: %p, with request: 0x%0lx
Created server speak task: %p, with request: 0x%0lx
Created speak task: %p, with request: 0x%0lx
Created presynthesized task: %p
Created server synthesis task: %p, with request: 0x%0lx
Created synthesis task: %p, with request: 0x%0lx
client '%@' set auto download voice assets:%@
%s override voice info for server TTS platform, %@
Ignore stream object with nil stream ID: %@
Enqueue stream object %@, streamId: %@
Reading cache %@ error: %@
Error %s, %@
Cache type name too long %@
%@ is not TTS language, falling back to %@
Error in reading audio data from file: %@ error:%@
Error AudioQueueNewOutputWithAudioSession %d
Current audio output route: %@
Unable to set kAudioQueueProperty_ClientUID, errno: %d
VSAudioPlaybackService %p init latency: %.3f
Error AudioQueueDispose %d
mediaserverd reset
Signal AudioQueue running state change
Error AudioQueueStart %d
VSAudioPlaybackService %p success AudioQueueStart
Error AudioQueueAllocateBuffer %d
Error AudioQueueEnqueueBuffer %d
VSAudioPlaybackService %p enqueued audio buffer at sample time: %.2f, size: %ld
Base64 of first 64 bytes data: %@
Error AudioQueueFlush %d
Error AudioQueueStop %d
Error AudioQueuePause %d
VSAudioPlaybackServices %p success AudioQueuePause
Error AudioQueueReset %d
Error AudioQueueAddPropertyListener %d
Error AudioQueueRemovePropertyListener %d
Detected stall of audio queue, based on NSDate. Now: %@, supposed end time: %@, Tolerance: %.2f
Error AudioQueueGetProperty isRunning %d
Unable to enable kAudioQueueProperty_EnableLevelMetering, err: %d
Unable to disable kAudioQueueProperty_EnableLevelMetering, err: %d
Error: %s, errno: %d
VSAudioPlaybackServices %p played audio buffer at sample time: %f, size: %ld
Error AudioQueueFreeBuffer %d
On-disk cached synthesis %@ is found.
In-memory cached synthesis %@ is found.
Reset MobileAsset query cache and retry selecting voice
No voice available
Compact voice is explicitly disabled.
Voice is deleted at path '%@'
#CacheDelete will delete active voice asset: %@
#CacheDelete will delete inactive voice asset: %@
#CacheDelete query purgeable size, urgency: %d / %d, info: %@
#CacheDelete purge, urgency: %d / %d, info: %@
#CacheDelete periodic purge, urgency: %d / %d, info: %@
Voice download is in progress, skip new download. %@
Updating target voice: %@
WatchOS skip downloading non-gryphon voice: %@
Triggered as UserRequest, will start download immediately
Triggered as SystemRequested, found %@ voice
Premium voice found, inactive TTS in last 7 days, delay voice updating: %@
#MobileAsset #DownloadVoice downloading progress: %.2f, voice: %@
#MobileAsset #DownloadVoice finished downloading voice: %@
Updating VoiceResource...
Added short term cache:%@ for key:'%@'
Removed short term cache for key:'%@'
Unknown streaming object: %@
Handle stream begin with streamId: %@, text: %@, decoder: %@
Handle stream chunk with streamId: %@
Reached buffer threshold. Start playing audio.
Handle stream end with streamId: %@, count: %@
Stream TTS network stall.
Error in stream task %p, error: %@
Stream task %p: %@ speaking utterance: '%@', %{public}@
Stream task %p: Instrument metric: %@
Speaking pre-synthesized audio: %@
Can't create VSAudioPlaybackService
Error, %@
Pre-synthesized audio request stopped
Finished speaking pre-synthesized audio: %@
Task is cancelled by user: %@
Prewarming: Invoked with request: '%@'
Unable to prewarm, error: %@
Can't prewarm engine with path '%@'
Engine is previously prewarmed with path '%@'
Prewarm finished. Latency: %.3f
Prewarming: Completed with request: '%@'
Can't create engine with path '%@'
Voice specific resources found.
Specified resource file '%@' does not exist at: '%@'
forceServerTTS is enabled by user default.
forceServerTTS is enabled by speech request.
Server TTS is disabled since '%@' is not in the whitelist
Received AceObject: %@
Voice count for %@_%@: %@
Voice: %@:%@:%@:%@:%@:%@
Error: %@
Sent AceObject: %@
%s, %@
#AFClientLite Request %p received AceObject: %@, %s
Error: %@, %s
Server TTS word timing info size: %d
Server TTS word timing info, offset: %ld, length: %ld, word: %@, sampleIndex: %@, timestamp: %.2f
Synthesis completed, total packet number: %d, %s
#AFClientLite error: %@, %s
#AFClientLite Request %p gets completion call. %s
playbackService is initialized already.
Starting AudioQueue
Error in device task %p, error: %@
Device task %p: %@ %@ utterance: '%@', %{public}@
Cached task %p with hash %@ in memory, caching to disk now.
Caching is disabled. Skipping caching.
Hash %@ is now cached in disk
Error converting audio during caching. %@
Can't add audio cache, error: %@
Preinstalled cached synthesis %@ is found.
Error setPitch 0x%zx
Error setRate 0x%zx
Error setVolume 0x%zx
Engine preheating latency: %.3f
Reloaded memory mapped files
Ignore unspeakable task, type: %@
Start spinNextTask
Dispatch speaking task %p
Starting task %p
%p wait another speaking task %p
%p interrupt task %p
Speak task %p is attached to eager task %p
Dispatch synthesis task %p
Finish spinNextTask
Cancel current task: %p
decoderStreamDescription formatID: %@, sample rate: %@
Unknown server audio format ID: %d
%s, invalid opus data
%s, Unknown format: %d
Invalid chunk size: %d at offset %d, bytes count = %d
Unable to convert OPUS to PCM. %@
Error AudioFileCreateWithURL: '%@', code: %d
Error AudioFileWriteBytes: '%@', code: %d
Error AudioFileClose: '%@', code: %d
Audio save as %@
OPTTSTextToSpeechResponse word timing info, offset: %ld, length: %ld, word: %@, sampleIndex: %d, timestamp: %.2f
Unable to madvise file '%@' MADV_DONTNEED, error: %s
Unable to munmap file '%@', error: %s
Unable to open file '%s', error: %s
Unable to get size of file '%s', error: %s
Unable to mmap '%s', error: %s
fcntl called on file '%@', size: %lu
AN11flatbuffers16DefaultAllocatorE
N11flatbuffers9AllocatorE
?mcpl
NSt3__110__function6__funcIU8__strongU13block_pointerFiN14TTSSynthesizer15CallbackMessageEENS_9allocatorIS6_EES4_EE
NSt3__110__function6__baseIFiN14TTSSynthesizer15CallbackMessageEEEE
U13block_pointerFiN14TTSSynthesizer15CallbackMessageEE
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
VSSpeechSynthesisTask
VSSpeechEagerProtocol
VSSpeechSpeakableProtocol
VSSpeechTaskProtocol
NSObject
VSVoiceBooster
VSSpeechSpeakTask
VSSpeechServerTask
VSDeviceTTSCoreDelegate
VSOspreyTTSCoreDelegate
VSSpeechXPCHandler
VSSpeechXPCServiceProtocol
VSSpeechServiceDelegate
VSOspreyTTSCore
VSSpeechCacheAudio
VSSpeechCacheItem
VSSpeechCache
VSAudioData
NSCopying
OPTTSTextToSpeechVoice
FLTBFBufferVerifier
OPTTSTextToSpeechResource
OPTTSTextToSpeechMeta
OPTTSTextToSpeechRequestMeta
OPTTSTextToSpeechRequest
OPTTSTextToSpeechRequest_ContextInfoEntry
OPTTSAudioDescription
OPTTSWordTimingInfo
OPTTSTextToSpeechResponse
OPTTSStartTextToSpeechStreamingRequest
OPTTSStartTextToSpeechStreamingRequest_ContextInfoEntry
OPTTSBeginTextToSpeechStreamingResponse
OPTTSPartialTextToSpeechStreamingResponse
OPTTSFinalTextToSpeechStreamingResponse
OPTTSTextToSpeechRouterStreamingStreamingRequest
OPTTSTextToSpeechRouterStreamingStreamingResponse
VSAceObjectUtility
VSAudioPlaybackService
AFAudioPowerProviding
VSDeviceTTSCore
VSCacheDeleteService
VSTimeoutCondition
VSDownloadService
OspreyTTSService
SpeechService
VSAudioDump
VSServerTTSConfig
VSShortTermCache
VSSiriInlineTTSStreamTask
VSSpeechPresynthesizedTask
VSSpeechAudioPowerService
VSNotificationQueue
OPTTSMutableTextToSpeechVoice
FLTBFBufferAccessor
OPTTSMutableTextToSpeechResource
OPTTSMutableTextToSpeechMeta
OPTTSMutableTextToSpeechRequestMeta
OPTTSMutableTextToSpeechRequest
OPTTSMutableTextToSpeechRequest_ContextInfoEntry
OPTTSMutableAudioDescription
OPTTSMutableWordTimingInfo
OPTTSMutableTextToSpeechResponse
OPTTSMutableStartTextToSpeechStreamingRequest
OPTTSMutableStartTextToSpeechStreamingRequest_ContextInfoEntry
OPTTSMutableBeginTextToSpeechStreamingResponse
OPTTSMutablePartialTextToSpeechStreamingResponse
OPTTSMutableFinalTextToSpeechStreamingResponse
OPTTSMutableTextToSpeechRouterStreamingStreamingRequest
OPTTSMutableTextToSpeechRouterStreamingStreamingResponse
VSPrewarmService
VSAggdService
VSServerTTSClient
Utilities
VSCachingService
VSSpeechSynthesisCallbackResult
VSSpeechEngine
VSSpeechTaskQueue
SAUIAudioData
VSHelpers
VSMemoryMap
initWithRequest:
speakTask
sharedService
waitUntilPrewarmFinish
fetchVoiceResource
fetchVoiceAsset
init
request
text
languageCode
gender
estimatedTTSWordTimingForText:withLanguage:withGender:
setTimingInfos:
error
cachingService
fetchCacheForTask:
speechCache
synthesize
audio
duration
instrumentMetrics
setAudioDuration:
reportTimingInfo
speakCachedAudio
speechBeginTimestamp
setSpeechEndTimestamp:
setReadyForEagerTask:
isCancelled
dictionaryWithObjects:forKeys:count:
errorWithDomain:code:userInfo:
setError:
reportInstrumentMetrics
defaultService
tallyTask:
defaultAudioDumpStore
dumpAudio:
outputPath
path
writeToFilePath:
shouldCache
enqueueCacheSpeakTask:completion:
reportFinish
logFinish
prepareForSynthesis
audioSessionID
startPlaybackServiceWithAudioSessionID:
data
setSynthesisBeginTimestamp:
engine
utterance
state
mutablePCMData
voiceBooster
processData:
playbackService
enqueue:packetCount:packetDescriptions:
taskAuxiliaryQueue
reportSpeechStart
appendData:
setAudioData:
setSynthesisEndTimestamp:
numOfPromptsTriggered
setPromptCount:
timingInfos
wordTimingInfos
adjustWordTimingInfo
synthesizeText:callback:
waitUntilAudioFinished
delegate
synthesisRequest:didReceiveTimingInfo:
speechRequestDidReceiveTimingInfo:
speechRequestSuccessWithInstrumentMetrics:
setUtterance:
voiceAssetKey
setVoiceAssetKey:
voiceResourceAssetKey
setVoiceResourceAssetKey:
synthesisBeginTimestamp
synthesisEndTimestamp
setSpeechBeginTimestamp:
speechEndTimestamp
audioStartTimestampDiffs
setAudioStartTimestampDiffs:
audioDuration
isWarmStart
setIsWarmStart:
requestCreatedTimestamp
setEagerRequestCreatedTimeStampDiffs:
speechRequestDidStart
speechRequestDidStopWithSuccess:phonemesSpoken:error:
phonemes
componentsJoinedByString:
synthesisRequest:didFinishWithInstrumentMetrics:error:
isEqual:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
description
debugDescription
start
suspend
resume
cancel
md5hash
isSpeaking
audioPowerProvider
readyForEagerTask
setSpeakTask:
main
.cxx_destruct
_readyForEagerTask
_speakTask
uninitialize
dealloc
initialize
voiceBoostGainDecibels
length
pcmBufferSize
asbd
mutableBytes
dataWithLength:
initWithStreamDescription:pcmBufferSize:
setVoiceBoostGainDecibels:
setAsbd:
setPcmBufferSize:
floatConverter
setFloatConverter:
integerConverter
setIntegerConverter:
voiceBoostUnit
setVoiceBoostUnit:
audioTimeStamp
setAudioTimeStamp:
_voiceBoostGainDecibels
_pcmBufferSize
_floatConverter
_integerConverter
_voiceBoostUnit
_asbd
_audioTimeStamp
setRequestCreatedTimestamp:
canUseServerTTS
setCanUseServerTTS:
standardService
voiceSelection
voiceResource
rate
pitch
volume
contextInfo
stringWithFormat:
shortTermCacheForHash:
setIsServerTTS:
setIsCacheHitFromMemory:
setSpeechCache:
synthesizeAndSpeak
setIsSpeechRequest:
stopAtMarker:
stop
pausePlayback
resumePlayback
array
voiceData
type
addObjectsFromArray:
setPhonemes:
setRequest:
setDelegate:
setEngine:
setVoiceBooster:
setPlaybackService:
setVoiceSelection:
setVoiceResource:
setCachingService:
setInstrumentMetrics:
setAudio:
setTaskAuxiliaryQueue:
_request
_timingInfos
_delegate
_engine
_voiceBooster
_playbackService
_voiceSelection
_voiceResource
_cachingService
_instrumentMetrics
_speechCache
_phonemes
_audio
_error
_taskAuxiliaryQueue
standardInstance
defaultConfig
disableOsprey
useDeviceSynthesis
synthesisCore
selectedVoice
footprint
useServerResponse
setUseServerResponse:
ospreyCore
voice
voiceKey
genderStringFromGender:
wordTimingInfo
setWordTimingInfo:
playAudioData:
serverAudio
setServerAudio:
concatenateWithAudio:
localizedDescription
setIsServerTimeout:
internalSettings
disableDeviceRacing
setUseDeviceSynthesis:
deferredTTSTimingInfo
domain
isEqualToString:
serverTTSConfig
deviceWaitTime
selectedVoiceResource
shouldDeferDeviceTTS
setSourceOfTTS:
setDeferredTTSTimingInfo:
shouldSpeak
initWithAudioSessionID:asbd:
outputRoute
setAudioOutputRoute:
audioData
packetCount
packetDescriptions
speechStartReported
setSpeechStartReported:
stringByAppendingString:
serverTTSTimeout
timeout
proceedWithSpeechCache:
eagerTaskHashForRequest:
setIsEagerCache:
proceedWithServerTTS
flushAndStop
tallySynthesisCore:
enqueueShortTermCacheWithHash:audio:timingInfo:completion:
writeAudioIfNeeded:
handleServerResponse:timingInfo:
broadcastTimeoutCondition
aceStartSynthesisRequest:responseHandler:completion:
sharedManager
selectVoiceResourceAssetForLanguage:
defaultVoiceGender
setGender:
serverVoiceNameForGender:
setVoiceName:
startSiriRoundTrip
setIsServerTTSRacing:
isExecuting
waitUntilFinished
waitFor:
waitForSiriServerResponse
fallbackToDeviceSynthesis
pause
isServerTimeout
code
isEagerCache
stringByReplacingOccurrencesOfString:withString:
numberWithBool:
isServerTTS
isSynthesisCached
numberWithInt:
sourceOfTTS
stringOfSourceOfTTS:
handleDeviceSynthesis:timingInfo:
synthesisCore:didReceiveAudio:
synthesisCore:didReceiveWordTimingInfo:
ospreyCore:didReceiveAudio:wordTimingInfo:
ospreyCore:didFinishWithError:
initWithRequest:shouldSpeak:
waitSiriRoundTripToFinish
setShouldSpeak:
timeoutCondition
setTimeoutCondition:
setSynthesisCore:
setDisableOsprey:
racingMutex
setRacingMutex:
setInternalSettings:
setOspreyCore:
setServerTTSConfig:
_shouldSpeak
_useServerResponse
_useDeviceSynthesis
_speechStartReported
_isEagerCache
_disableOsprey
_wordTimingInfo
_synthesisCore
_serverAudio
_deferredTTSTimingInfo
_internalSettings
_ospreyCore
_serverTTSConfig
_timeoutCondition
_racingMutex
invalidate
sharedQueue
currentTask
availableLanguages
containsObject:
fallbackLanguageForLanguage:
setLanguageCode:
performLanguageFallBackIfNeededWithRequest:
vs_insertContextInfo:
vs_substituteAudioWithLocalPath
vs_textifyEmojiWithLanguage:
precomposedStringWithCanonicalMapping
defaultVolume
setVolume:
whisper
pointer
prewarmWithRequest:
voiceType
selectVoiceForLang:type:gender:footprint:
voicePath
UTF8String
preprocessRequestBeforeSynthesis:
defaultInstance
date
setLastTTSRequestDate:
disableServerTTS
sharedInlineStreamKeys
objectForKey:
removeObjectForKey:
initWithRequest:withStreamID:
shouldUseServerTTSForRequest:
setCompletionBlock:
addTask:
identifier
setObject:forKey:
audioDataFromPresynthesisRequest:
cancelCurrentTask
suspendCurrentTask
resumeCurrentTask
sharedServices
audioPowerUpdateQueue
initWithProvider:queue:frequency:delegate:
audioPowerUpdater
createNewXPCWrapperWithCompletion:
beginUpdate
endUpdate
setAudioPowerUpdater:
installedAssetsForType:voicename:language:gender:footprint:
countByEnumeratingWithState:objects:count:
name
addObject:
remoteObjectProxy
speechRequestDidPause
speechRequestDidContinue
speechRequestMark:didStartForRange:
presynthesizedAudioRequestDidStart
presynthesizedAudioRequestSuccessWithInstrumentMetrics:error:
presynthesizedAudioRequestDidStopAtEnd:error:
cleanOldVoiceResources
cleanUnusedVoiceAssets
installedVoiceResources
autoDownloadedVoicesForClientID:
languages
firstObject
setAutoDownloadedVoices:withClientID:
initWithType:
cancelDownloadForAssets:
updateVoicesAndVoiceResources
arrayWithObjects:count:
setLanguages:
boolValue
queryVoices:reply:
streamId
enqueueNotificationName:object:
updateWithConnectionIdentifier:
prewarmIfNeededWithRequest:
queryPhaticCapabilityWithRequest:reply:
startSpeechRequest:
startSynthesisRequest:
pauseSpeechRequestAtMark:
continueSpeechRequest
stopSpeechRequestAtMark:
startPresynthesizedAudioRequest:
cachePresynthesizedAudioRequest:
stopPresynthesizedAudioRequest
getVoiceNamesForLanguage:reply:
getFootprintsForVoiceName:languageCode:reply:
getSpeechIsActiveReply:
getSpeechIsActiveForConnectionReply:
beginAudioPowerUpdateWithReply:
endAudioPowerUpdate
cleanUnusedAssets:
getLocalVoicesReply:
getLocalVoiceResourcesReply:
setAutoDownloadedVoiceAssets:withClientID:
getAutoDownloadedVoiceAssetsWithClientID:reply:
getVoiceResourceForLanguage:reply:
getVoiceInfoForLanguageCode:footprint:gender:type:reply:
setLogToFile:
getLogToFile:
getTTSServerVoicesWithFilter:reply:
forwardStreamObject:
initWithConnection:
connectionIdentifier
setConnectionIdentifier:
setAudioPowerUpdateQueue:
_connection
_connectionIdentifier
_audioPowerUpdateQueue
_audioPowerUpdater
serverConfig
initWithTimeoutValue:
serverTTSClient
ospreyStartSynthesisRequest:responseHandler:completion:
wait
bufferDurationLimit
count
objectAtIndexedSubscript:
refresh
setVoice:
streamBufferDuration
setBufferDurationLimit:
ospreyStartStreamingRequest:dataHandler:metaInfoHandler:completion:
disableOspreyStreaming
performStreamingOspreyTTS
performRoundTripOspreyTTS
setServerTTSClient:
setServerConfig:
_voice
_serverTTSClient
_serverConfig
_bufferDurationLimit
appendBytes:length:
archivedDataWithRootObject:requiringSecureCoding:error:
getBytes:range:
subdataWithRange:
setPacketCount:
setPacketDescriptions:
setWithObjects:
unarchivedObjectOfClasses:fromData:error:
serializedData
initWithKey:data:
initWithKey:audio:wordTimingInfo:
magicVersion
setKey:
_magicVersion
_key
_audioData
_packetCount
_packetDescriptions
bundleWithIdentifier:
bundlePath
stringByAppendingPathComponent:
defaultManager
createDirectoryAtPath:withIntermediateDirectories:attributes:error:
initWithStorePath:
dataUsingEncoding:
dataWithCapacity:
setLength:
dirPath
writeToFile:options:error:
preinstalledAudioHashForLanguage:gender:
preinstalledCacheDir
stringByAppendingPathExtension:
isReadableFileAtPath:
audioDataFromFile:error:
dataWithContentsOfFile:
bytes
stringWithUTF8String:
alloc
preinstalledCacheForText:language:gender:
isAudioAccessory
cleanDirectory:withLRULimit:
directorySize:
removeDirectory:
defaultCacheStore
addCache:
cacheDataForKey:
isPreinstalledCacheAvailableForRequest:
cleanCache
totalCacheSize
deleteCache
setDirPath:
setPreinstalledCacheDir:
_dirPath
_preinstalledCacheDir
allocWithZone:
copy
dataWithData:
copyWithZone:
initWithBytes:length:encoding:
language
version
quality
verify:
initWithFlatbuffData:root:
addObjectToBuffer:
_data
_root
resource
channel_type
app_id
speech_id
session_id
audio_type
enable_word_timing_info
voice_name
context_info
preferred_voice_type
meta_info
value
sample_rate
format_id
format_flags
bytes_per_packet
frames_per_packet
bytes_per_frame
channels_per_frame
bits_per_channel
reserved
word
sample_idx
offset
timestamp
initWithBytes:length:
error_code
error_str
decoder_description
playback_description
word_timing_info
stream_id
streaming_playback_buffer_size_in_seconds
current_pkt_number
total_pkt_number
content_type
contentAsOPTTSStartTextToSpeechStreamingRequest
contentAsOPTTSBeginTextToSpeechStreamingResponse
contentAsOPTTSPartialTextToSpeechStreamingResponse
contentAsOPTTSFinalTextToSpeechStreamingResponse
formatID
intValue
sampleRate
floatValue
bitsPerChannel
framesPerPacket
vsDescription
resourceVersion
contentVersion
sharedInstance
opaqueSessionID
retrieveSessionWithID:
currentRoute
outputs
portType
defaultCenter
handleMediaServerReset
addObserver:selector:name:object:
removeObserver:
dateByAddingTimeInterval:
internalBuild
base64EncodedStringWithOptions:
waitForAudioQueueStop
didEndAccessPower
signalQueueRunningStateChange
isAudioQueueRunning
isAudioQueueStalled
timeIntervalSinceDate:
setDateFormat:
stringFromDate:
durationOfAudioDataLength:withAudioDescription:
bytesOfDuration:withAudioDescription:
willBeginAccessPower
getAveragePower:andPeakPower:
reset
audioQueue
setAudioQueue:
sessionID
setSessionID:
setOutputRoute:
setState:
waitForStateChangeMutex
setWaitForStateChangeMutex:
stateChangeCondition
setStateChangeCondition:
enqueuedSampleCount
setEnqueuedSampleCount:
audioQueueStartDate
setAudioQueueStartDate:
audioQueueFutureEndDate
setAudioQueueFutureEndDate:
_audioQueue
_sessionID
_outputRoute
_state
_audioQueueStartDate
_audioQueueFutureEndDate
_enqueuedSampleCount
_stateChangeCondition
_waitForStateChangeMutex
voiceSelectionWithRequest:error:
getCacheForHash:
reportWordTimingInfo:
reportAudio:
adjustWordTimingInfo:
enqueueCacheWithHash:audio:timingInfo:completion:
inMemoryCacheForHash:
onDiskCacheForHash:
setIsCacheHitFromDisk:
voiceSelection_noRetry_WithRequest:error:
resetCache
disableCompactVoiceFallback
fileExistsAtPath:
cachedEngineForVoice:resources:
prewarmEngineForVoice:resources:
setPitch:
setRate:
gainDecibelWithVolume:
vs_markerStringForContext:
textRange
setTextRange:
setSelectedVoice:
setSelectedVoiceResource:
_selectedVoice
_selectedVoiceResource
objectForKeyedSubscript:
longLongValue
activeVoiceAssets
inactiveVoiceAssets
totalSizeOfAssets:
descriptiveKey
size
purgeableVoiceAssetsWithInfo:urgency:
totalAudioDumpSize
numberWithLongLong:
purgeImpl:urgency:
purgeAsset:
deleteAudioDump
purgeable:urgency:
purge:urgency:
periodic:urgency:
registerCacheDelete
refreshTimeoutCondition
lock
dateWithTimeIntervalSinceNow:
waitUntilDate:
unlock
signal
timeoutValue
_waitForTimeInterval:
shouldStop
setTimeoutValue:
setRefreshTimeoutCondition:
setShouldStop:
_shouldStop
_refreshTimeoutCondition
_timeoutValue
amendVoiceWithDefaultSettings:
inProgressDownloadVoiceKeys
updateVoiceIfNeeded:
updateVoiceResourcesIfNeeded:
isWatch
lastTTSRequestDate
removeObject:
downloadVoiceAsset:useBattery:progressUpdateHandler:
downloadVoiceResource:discretionary:completion:
cancelDownload:completion:
_type
ospreyEndpointURL
isSeedBuild
isInternalBuild
ospreyServiceEndpointURL
roundTripTTS:responseHandler:
streamTTS:beginHandler:chunkHandler:endHandler:completion:
setConfigurationOptionUseCompression:
setConfigurationOptionUseAbsinthe:
deviceID
setDeviceID:
_deviceID
enableAudioDump
audioDumpPath
cleanDirectory:withDateOlderThan:
createDirectoryIfNeeded
pathWithComponents:
cleanAudioDump
setAudioDumpPath:
_audioDumpPath
userDefaultsKnowledgeStore
setKnowledgeStore:
knowledgeStore
valueForKey:
componentsSeparatedByString:
prefer
whitelistedAppId
_knowledgeStore
timeToLiveTimerFired:
timerWithTimeInterval:target:selector:userInfo:repeats:
cache
cacheTimer
mainRunLoop
addTimer:forMode:
userInfo
setObject:forKey:timeToLive:
setCache:
setCacheTimer:
_cache
_cacheTimer
setIsServerStreamTTS:
handleStreamNotification:
startNotificationName:
streamID
removeNotificationName:
object
handleBegin:
handleChunk:
handleEnd:
speechSynthesisVoice
speechSynthesisResource
decoderStreamDescription
streamingPlaybackBufferSize
asbdFromDescription:
finalAudio
setPlaybackServices:
playbackServices
signalNewDataWithError:
populateWithPCMData:
populateWithOpusData:
startPlayback
setPlaybackBeginDate:
playbackBeginDate
numberWithInteger:
errorCode
errorMessage
waitForNewData:
setFinalAudio:
finalTimingInfo
removeAllObjects
deviceTTSInstrumentMetrics
deviceTTSCore
setStreamID:
setDeviceTTSCore:
setDeviceTTSInstrumentMetrics:
setFinalTimingInfo:
_streamID
_deviceTTSCore
_deviceTTSInstrumentMetrics
_playbackServices
_finalAudio
_finalTimingInfo
_playbackBeginDate
_clockFactor
getCurrentAudioPowerProvider
previousProvider
setPreviousProvider:
_previousProvider
ongoingNotifications
notifyQueue
postNotificationName:object:
queuedNotification
setObject:forKeyedSubscript:
setQueuedNotification:
setOngoingNotifications:
setLock:
setNotifyQueue:
_queuedNotification
_ongoingNotifications
_notifyQueue
_lock
dictionary
dataWithBytes:length:
flatbuffData
setLanguage:
setName:
setVersion:
setQuality:
_storage
setResource:
integerValue
initWithInteger:
setChannel_type:
setApp_id:
initWithBool:
setSpeech_id:
setSession_id:
setText:
setAudio_type:
setEnable_word_timing_info:
setVoice_name:
setContext_info:
setPreferred_voice_type:
setMeta_info:
setValue:
doubleValue
initWithDouble:
unsignedIntegerValue
initWithUnsignedInteger:
setSample_rate:
setFormat_id:
setFormat_flags:
setBytes_per_packet:
setFrames_per_packet:
setBytes_per_frame:
setChannels_per_frame:
setBits_per_channel:
setReserved:
initWithFloat:
setWord:
setSample_idx:
setOffset:
setTimestamp:
initWithInt:
setError_code:
setError_str:
setDecoder_description:
setPlayback_description:
setWord_timing_info:
setStream_id:
setStreaming_playback_buffer_size_in_seconds:
setCurrent_pkt_number:
setTotal_pkt_number:
setContent_type:
setContentAsOPTTSStartTextToSpeechStreamingRequest:
setContentAsOPTTSBeginTextToSpeechStreamingResponse:
setContentAsOPTTSPartialTextToSpeechStreamingResponse:
setContentAsOPTTSFinalTextToSpeechStreamingResponse:
cachedEngine
reloadMappedFiles
loadedResources
prewarmQueue
setCachedEngine:
resourceMimeTypes
searchPathURL
initWithVoicePath:resourcePath:
loadEngine:withVoiceResources:
fileURLWithPathComponents:
fileURLWithPath:
setSearchPathURL:
setLoadedResources:
preheat
resourceList
loadResourceAtPath:mimeType:
setPrewarmQueue:
_cachedEngine
_loadedResources
_prewarmQueue
initWithLoggingPrefix:
clientBundleIdentifier
recordCategory:value:
masteredVersion
footprintStringFromFootprint:
loggingPrefix
setLoggingPrefix:
_loggingPrefix
forceServerTTS
fetchSpeechSynthesisVoiceRequest
genderStringFromVSGender:
setFilteredVoiceKey:
voiceKeyList
numberWithUnsignedInteger:
keyString
genderFromString:
setContentVersion:
footprintFromString:
setFootprint:
handleCommand:afterCurrentRequest:commandHandler:completion:
requestFromVSRequest:
audioStreamBasicDescription
audioDataWithASBD:rawData:
vs_wordTimingInfos:withText:
vs_voice
vs_voiceResource
startSpeechSynthesisRequest
setAudioType:
setStreaming:
setEnableAudioInfo:
voiceName
reason
reasonDescription
aceAudioData
audioDataFromSAUIAudioData:
aceAudioInfo
wordTimingInfoList
sampleIndex
setStartTime:
utf16TimingInfoWithUTF8Range:withText:
totalPacketNumber
_fetchVoiceAsset_NoRetry
numberWithDouble:
eagerRequestCreatedTimeStampDiffs
initWithCache:shortTermMemory:
disableCache
threadLock
inMemoryCaches
cachingQueue
cacheWithHash:audio:timingInfo:
initWithStreamDescription:
initFromFormat:toFormat:
initWithPCMFormat:frameCapacity:
setFrameLength:
mutableAudioBufferList
maximumOutputPacketSize
initWithFormat:packetCapacity:maximumPacketSize:
convertToBuffer:error:withInputFromBlock:
audioBufferList
cacheStore
shortTermCache
onDiskCacheForSimilarTask:
setThreadLock:
setInMemoryCaches:
setCacheStore:
setShortTermCache:
setCachingQueue:
_threadLock
_inMemoryCaches
_cacheStore
_shortTermCache
_cachingQueue
processMarkerBuffer
dataWithBytesNoCopy:length:freeWhenDone:
characterAtIndex:
utf8BytesForChar:
utf16OffsetFromUTF8:
initWithCallback:
synthesisCallback:
pcmData
sampleBuffer
markerBuffer
.cxx_construct
stopMark
setStopMark:
callback
setCallback:
wordTimings
setWordTimings:
samplesProcessed
setSamplesProcessed:
lastUTF8Offset
setLastUTF8Offset:
lastUTF16Offset
setLastUTF16Offset:
setNumOfPromptsTriggered:
_samples
_markers
_text
_stopMark
_callback
_wordTimings
_samplesProcessed
_lastUTF8Offset
_lastUTF16Offset
_numOfPromptsTriggered
initializeWithResourcePath:
currentCallbackResult
synthesizer
isUserCancelError:
setVoicePath:
setSynthesizer:
setCurrentCallbackResult:
_voicePath
_rate
_pitch
_volume
_synthesizer
_currentCallbackResult
spinNextTask
removeObjectAtIndex:
isSimilarTo:
setCurrentTask:
setLastSynthesisRequest:
eagerTasks
setEagerTasks:
speakTasks
setSpeakTasks:
threadMutex
setThreadMutex:
threadMutexAttr
setThreadMutexAttr:
speakingQueue
setSpeakingQueue:
lastSynthesisRequest
lastSynthesisRequestCreatedTimeStamp
setLastSynthesisRequestCreatedTimeStamp:
_eagerTasks
_speakTasks
_currentTask
_speakingQueue
_lastSynthesisRequest
_lastSynthesisRequestCreatedTimeStamp
_threadMutexAttr
_threadMutex
formatFlags
unsignedIntValue
bytesPerPacket
bytesPerFrame
channelsPerFrame
audioBuffer
playerStreamDescription
populatePCMDataWithSiriOpusSData:withOpusASBD:
decodeChunks:streamDescription:outError:
beginChunkDecoderForStreamDescription:
decodeChunk:outError:
endChunkDecoding
pcmAudioDataFromOpusAudio:
mmap
initWithFilePath:
madvise
filePath
fileSize
mappedData
_filePath
_fileSize
_mappedData
B12@0:4@8
#8@0:4
@8@0:4
@12@0:4:8
@16@0:4:8@12
@20@0:4:8@12@16
B8@0:4
B12@0:4#8
B12@0:4:8
Vv8@0:4
I8@0:4
^{_NSZone=}8@0:4
B12@0:4@"Protocol"8
@"NSString"8@0:4
v8@0:4
@"VSSpeechRequest"8@0:4
@"VSInstrumentMetrics"8@0:4
@"<AFAudioPowerProviding>"8@0:4
v12@0:4@8
v12@0:4@"<VSSpeechSpeakableProtocol>"8
@12@0:4@8
v12@0:4B8
@"VSSpeechSpeakTask"
@52@0:4{AudioStreamBasicDescription=dIIIIIIII}8I48
v12@0:4f8
f8@0:4
{AudioStreamBasicDescription=dIIIIIIII}8@0:4
v48@0:4{AudioStreamBasicDescription=dIIIIIIII}8
v12@0:4I8
^{OpaqueAudioConverter=}8@0:4
v12@0:4^{OpaqueAudioConverter=}8
^{OpaqueAudioComponentInstance=}8@0:4
v12@0:4^{OpaqueAudioComponentInstance=}8
{AudioTimeStamp=dQdQ{SMPTETime=ssILLssss}LI}8@0:4
v72@0:4{AudioTimeStamp=dQdQ{SMPTETime=ssILLssss}LI}8
^{OpaqueAudioConverter=}
^{OpaqueAudioComponentInstance=}
{AudioStreamBasicDescription="mSampleRate"d"mFormatID"I"mFormatFlags"I"mBytesPerPacket"I"mFramesPerPacket"I"mBytesPerFrame"I"mChannelsPerFrame"I"mBitsPerChannel"I"mReserved"I}
{AudioTimeStamp="mSampleTime"d"mHostTime"Q"mRateScalar"d"mWordClockTime"Q"mSMPTETime"{SMPTETime="mSubframes"s"mSubframeDivisor"s"mCounter"I"mType"L"mFlags"L"mHours"s"mMinutes"s"mSeconds"s"mFrames"s}"mFlags"L"mReserved"I}
@"VSSpeechRequest"
@"NSArray"
@"<VSSpeechServiceDelegate>"
@"VSSpeechEngine"
@"VSVoiceBooster"
@"VSAudioPlaybackService"
@"VSVoiceAssetSelection"
@"VSVoiceResourceAsset"
@"VSCachingService"
@"VSInstrumentMetrics"
@"<VSSpeechCacheItem>"
@"VSAudioData"
@"NSError"
@"NSObject<OS_dispatch_queue>"
v16@0:4@8@12
v16@0:4@"VSDeviceTTSCore"8@"VSAudioData"12
v16@0:4@"VSDeviceTTSCore"8@"NSArray"12
v20@0:4@8@12@16
v20@0:4@"VSOspreyTTSCore"8@"VSAudioData"12@"NSArray"16
v16@0:4@"VSOspreyTTSCore"8@"NSError"12
@16@0:4@8B12
@16@0:4@8@12
i8@0:4
@12@0:4i8
{_opaque_pthread_cond_t=l[24c]}8@0:4
v36@0:4{_opaque_pthread_cond_t=l[24c]}8
{_opaque_pthread_mutex_t=l[40c]}8@0:4
v52@0:4{_opaque_pthread_mutex_t=l[40c]}8
@"VSSpeechServerTask"
@"VSDeviceTTSCore"
@"VSSpeechInternalSettings"
@"VSOspreyTTSCore"
@"VSServerTTSConfig"
{_opaque_pthread_cond_t="__sig"l"__opaque"[24c]}
{_opaque_pthread_mutex_t="__sig"l"__opaque"[40c]}
Vv12@0:4@8
Vv16@0:4@8@?12
Vv12@0:4l8
Vv20@0:4@8@12@?16
Vv12@0:4@?8
Vv16@0:4@8@12
Vv28@0:4@8l12l16l20@?24
Vv12@0:4B8
Vv12@0:4@"NSString"8
Vv12@0:4@"VSSpeechRequest"8
Vv16@0:4@"VSSpeechRequest"8@?<v@?B>12
Vv12@0:4@"VSPresynthesizedAudioRequest"8
Vv16@0:4@"NSString"8@?<v@?@"NSArray">12
Vv20@0:4@"NSString"8@"NSString"12@?<v@?@"NSArray">16
Vv12@0:4@?<v@?B>8
Vv12@0:4@?<v@?@"AFXPCWrapper">8
Vv12@0:4@?<v@?@"NSError">8
Vv12@0:4@?<v@?@"NSArray"@"NSError">8
Vv16@0:4@"NSArray"8@"NSString"12
Vv16@0:4@"NSString"8@?<v@?@"VSVoiceResourceAsset">12
Vv28@0:4@"NSString"8l12l16l20@?<v@?@"VSVoiceAsset">24
Vv16@0:4@"VSVoiceAsset"8@?<v@?@"NSArray"@"NSError">12
Vv12@0:4@"SATTSSpeechSynthesisStreaming"8
Vv20@0:4l8{_NSRange=II}12
Vv20@0:4B8@12@16
Vv20@0:4@8@12@16
Vv16@0:4B8@12
Vv20@0:4B8@"NSString"12@"NSError"16
Vv12@0:4@"VSInstrumentMetrics"8
Vv12@0:4@"NSArray"8
Vv16@0:4@"VSSpeechRequest"8@"NSArray"12
Vv20@0:4@"VSSpeechRequest"8@"VSInstrumentMetrics"12@"NSError"16
Vv16@0:4B8@"NSError"12
Vv16@0:4@"VSInstrumentMetrics"8@"NSError"12
@"NSXPCConnection"
@"NSString"
@"AFAudioPowerUpdater"
d8@0:4
v16@0:4d8
@"<VSOspreyTTSCoreDelegate>"
@"VSVoiceAsset"
@"VSServerTTSClient"
@"VSTimeoutCondition"
@"NSData"8@0:4
@16@0:4@"NSString"8@"NSData"12
@20@0:4@8@12@16
v12@0:4i8
@"NSData"
@20@0:4@8@12l16
@12@0:4^{_NSZone=}8
B12@0:4@"NSData"8
@16@0:4@8r^{TextToSpeechVoice=[1C]}12
{Offset<siri::speech::schema_fb::TextToSpeechVoice>=I}12@0:4^{FlatBufferBuilder={vector_downward=^{Allocator}BIII***}ISBBIBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}8
r^{TextToSpeechVoice=[1C]}
@16@0:4@8r^{TextToSpeechResource=[1C]}12
{Offset<siri::speech::schema_fb::TextToSpeechResource>=I}12@0:4^{FlatBufferBuilder={vector_downward=^{Allocator}BIII***}ISBBIBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}8
r^{TextToSpeechResource=[1C]}
@16@0:4@8r^{TextToSpeechMeta=[1C]}12
{Offset<siri::speech::schema_fb::TextToSpeechMeta>=I}12@0:4^{FlatBufferBuilder={vector_downward=^{Allocator}BIII***}ISBBIBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}8
r^{TextToSpeechMeta=[1C]}
@16@0:4@8r^{TextToSpeechRequestMeta=[1C]}12
{Offset<siri::speech::schema_fb::TextToSpeechRequestMeta>=I}12@0:4^{FlatBufferBuilder={vector_downward=^{Allocator}BIII***}ISBBIBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}8
r^{TextToSpeechRequestMeta=[1C]}
@16@0:4@8r^{TextToSpeechRequest=[1C]}12
{Offset<siri::speech::schema_fb::TextToSpeechRequest>=I}12@0:4^{FlatBufferBuilder={vector_downward=^{Allocator}BIII***}ISBBIBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}8
r^{TextToSpeechRequest=[1C]}
@16@0:4@8r^{ContextInfoEntry=[1C]}12
{Offset<siri::speech::schema_fb::TextToSpeechRequest_::ContextInfoEntry>=I}12@0:4^{FlatBufferBuilder={vector_downward=^{Allocator}BIII***}ISBBIBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}8
r^{ContextInfoEntry=[1C]}
@16@0:4@8r^{AudioDescription=[1C]}12
{Offset<siri::speech::schema_fb::AudioDescription>=I}12@0:4^{FlatBufferBuilder={vector_downward=^{Allocator}BIII***}ISBBIBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}8
r^{AudioDescription=[1C]}
@16@0:4@8r^{WordTimingInfo=[1C]}12
{Offset<siri::speech::schema_fb::WordTimingInfo>=I}12@0:4^{FlatBufferBuilder={vector_downward=^{Allocator}BIII***}ISBBIBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}8
r^{WordTimingInfo=[1C]}
@16@0:4@8r^{TextToSpeechResponse=[1C]}12
{Offset<siri::speech::schema_fb::TextToSpeechResponse>=I}12@0:4^{FlatBufferBuilder={vector_downward=^{Allocator}BIII***}ISBBIBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}8
r^{TextToSpeechResponse=[1C]}
@16@0:4@8r^{StartTextToSpeechStreamingRequest=[1C]}12
{Offset<siri::speech::schema_fb::StartTextToSpeechStreamingRequest>=I}12@0:4^{FlatBufferBuilder={vector_downward=^{Allocator}BIII***}ISBBIBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}8
r^{StartTextToSpeechStreamingRequest=[1C]}
{Offset<siri::speech::schema_fb::StartTextToSpeechStreamingRequest_::ContextInfoEntry>=I}12@0:4^{FlatBufferBuilder={vector_downward=^{Allocator}BIII***}ISBBIBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}8
@16@0:4@8r^{BeginTextToSpeechStreamingResponse=[1C]}12
{Offset<siri::speech::schema_fb::BeginTextToSpeechStreamingResponse>=I}12@0:4^{FlatBufferBuilder={vector_downward=^{Allocator}BIII***}ISBBIBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}8
r^{BeginTextToSpeechStreamingResponse=[1C]}
@16@0:4@8r^{PartialTextToSpeechStreamingResponse=[1C]}12
{Offset<siri::speech::schema_fb::PartialTextToSpeechStreamingResponse>=I}12@0:4^{FlatBufferBuilder={vector_downward=^{Allocator}BIII***}ISBBIBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}8
r^{PartialTextToSpeechStreamingResponse=[1C]}
@16@0:4@8r^{FinalTextToSpeechStreamingResponse=[1C]}12
{Offset<siri::speech::schema_fb::FinalTextToSpeechStreamingResponse>=I}12@0:4^{FlatBufferBuilder={vector_downward=^{Allocator}BIII***}ISBBIBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}8
r^{FinalTextToSpeechStreamingResponse=[1C]}
@16@0:4@8r^{TextToSpeechRouterStreamingStreamingRequest=[1C]}12
{Offset<siri::speech::qss_fb::TextToSpeechRouterStreamingStreamingRequest>=I}12@0:4^{FlatBufferBuilder={vector_downward=^{Allocator}BIII***}ISBBIBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}8
r^{TextToSpeechRouterStreamingStreamingRequest=[1C]}
@16@0:4@8r^{TextToSpeechRouterStreamingStreamingResponse=[1C]}12
{Offset<siri::speech::qss_fb::TextToSpeechRouterStreamingStreamingResponse>=I}12@0:4^{FlatBufferBuilder={vector_downward=^{Allocator}BIII***}ISBBIBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}8
r^{TextToSpeechRouterStreamingStreamingResponse=[1C]}
d52@0:4I8{AudioStreamBasicDescription=dIIIIIIII}12
I56@0:4d8{AudioStreamBasicDescription=dIIIIIIII}16
B16@0:4^f8^f12
@52@0:4I8{AudioStreamBasicDescription=dIIIIIIII}12
@20@0:4@8i12@16
^{OpaqueAudioQueue=}8@0:4
v12@0:4^{OpaqueAudioQueue=}8
^{OpaqueAudioQueue=}
@"NSDate"
@16@0:4@8^@12
@"<VSDeviceTTSCoreDelegate>"
@16@0:4@8i12
q12@0:4@8
@16@0:4d8
B16@0:4d8
@"NSCondition"
@12@0:4I8
v16@0:4@8@?12
v28@0:4@8@?12@?16@?20@?24
f16@0:4d8
@"CKKnowledgeStore"
v24@0:4@8@12d16
@"NSCache"
@"NSMutableArray"
@"VSPresynthesizedAudioRequest"
@"NSMutableData"
@"<AFAudioPowerProviding>"
@"NSMutableDictionary"
@"NSMutableSet"
@12@0:4l8
v20@0:4@8@?12@?16
v24@0:4@8@?12@?16@?20
v24@0:4@8@12@16@?20
@"NSLock"
@"VSSpeechCache"
@"VSShortTermCache"
@12@0:4@?8
i12@0:4i8
^{vector<unsigned char, std::__1::allocator<unsigned char> >=**{__compressed_pair<unsigned char *, std::__1::allocator<unsigned char> >=*}}8@0:4
^{vector<TTSSynthesizer::Marker, std::__1::allocator<TTSSynthesizer::Marker> >=^{Marker}^{Marker}{__compressed_pair<TTSSynthesizer::Marker *, std::__1::allocator<TTSSynthesizer::Marker> >=^{Marker}}}8@0:4
I12@0:4S8
I12@0:4I8
l8@0:4
v12@0:4l8
@?8@0:4
v12@0:4@?8
{vector<unsigned char, std::__1::allocator<unsigned char> >="__begin_"*"__end_"*"__end_cap_"{__compressed_pair<unsigned char *, std::__1::allocator<unsigned char> >="__value_"*}}
{vector<TTSSynthesizer::Marker, std::__1::allocator<TTSSynthesizer::Marker> >="__begin_"^{Marker}"__end_"^{Marker}"__end_cap_"{__compressed_pair<TTSSynthesizer::Marker *, std::__1::allocator<TTSSynthesizer::Marker> >="__value_"^{Marker}}}
@16@0:4@8@?12
^{TTSSynthesizer={unique_ptr<TTSSynthesizer::TTSSynthesizerInternal, std::__1::default_delete<TTSSynthesizer::TTSSynthesizerInternal> >={__compressed_pair<TTSSynthesizer::TTSSynthesizerInternal *, std::__1::default_delete<TTSSynthesizer::TTSSynthesizerInternal> >=^{TTSSynthesizerInternal}}}}8@0:4
v12@0:4^{TTSSynthesizer={unique_ptr<TTSSynthesizer::TTSSynthesizerInternal, std::__1::default_delete<TTSSynthesizer::TTSSynthesizerInternal> >={__compressed_pair<TTSSynthesizer::TTSSynthesizerInternal *, std::__1::default_delete<TTSSynthesizer::TTSSynthesizerInternal> >=^{TTSSynthesizerInternal}}}}8
^{TTSSynthesizer={unique_ptr<TTSSynthesizer::TTSSynthesizerInternal, std::__1::default_delete<TTSSynthesizer::TTSSynthesizerInternal> >={__compressed_pair<TTSSynthesizer::TTSSynthesizerInternal *, std::__1::default_delete<TTSSynthesizer::TTSSynthesizerInternal> >=^{TTSSynthesizerInternal}}}}
@"VSSpeechSynthesisCallbackResult"
{_opaque_pthread_mutexattr_t=l[8c]}8@0:4
v20@0:4{_opaque_pthread_mutexattr_t=l[8c]}8
Q8@0:4
v16@0:4Q8
@"<VSSpeechTaskProtocol>"
{_opaque_pthread_mutexattr_t="__sig"l"__opaque"[8c]}
B52@0:4@8{AudioStreamBasicDescription=dIIIIIIII}12
@52@0:4{AudioStreamBasicDescription=dIIIIIIII}8@48
{AudioStreamBasicDescription=dIIIIIIII}12@0:4@8
L8@0:4
^v8@0:4
