@(#)PROGRAM:SoundAnalysis  PROJECT:SoundAnalysis-1
St12length_error
St11logic_error
St9exception
xfuapraexoba
mron
xfuapargxoba
MbP?St13runtime_error
NSt3__117bad_function_callE
N8DSPGraph9ExceptionE
xfuamlpslppa
.AN5caulk19bad_expected_accessIvEE
xfualmrcxoba
xfuaxtncxoba
cmcp!
mcpl)
mcpl,
xfuadgisxoba
xfuaftmlxoba
timeRange
decibelLevel
type
detectorIdentifier
cannot encode MLModel
cannot copy MLModel
mood
valence
arousal
dominance
confidence
%@ Mood: %.2f Valence: %.2f Arousal: %.2f Dominance: %.2f Confidence: %.2f %@
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
com.apple.SoundAnalysis.EARAudioProcessor
initialize
DSPGraph_EARAudioProcessorBox.mm
in(0).format().mSampleRate == 16000
in(0).format().mChannelsPerFrame == 1
in(0).format().mBytesPerFrame == 2
config
/Library/Caches/com.apple.xbs/Sources/Listen_Sim/Listen-97.2/Framework/Internal/Core/DSPGraph/DSPGraph_EARAudioProcessorBox.mm
inputs must be 16kHz
/System/Volumes/Data/SWE/iOS/BuildRoots/BuildRoot1020/Applications/Xcode.app/Contents/Developer/Platforms/WatchSimulator.platform/Developer/SDKs/WatchSimulator8.0.Internal.sdk/System/Library/PrivateFrameworks/AudioToolboxCore.framework/PrivateHeaders/DSPGraph_Box.h
Box::in inIndex out of range! box %s has %zu inputs but input %u was requested
EARAudioProcessorBox
FormatMatchingNode
SoundAnalysis_FormatMatchingNode.cpp
upstreamFormat.mBlockSize == 1
downstreamFormat.mBlockSize == 1
setUpstreamFormat
formatMatchingGraph
input
channelMapper
output
v8@?0
illegal call to unavailable init selector: %s
-[SNSystemAudioAnalyzerXPCPublisher init]
v16@?0@"NSError"8
could not add request; communication with server failed
v16@?0^{OpaqueAudioQueue=}8
Applause
Babble
Cheering
Laughter
Music
Speech
Distressed Baby
Smoke Alarm
Fire Alarm
Doorbell
Buzzer
Beep
Ding Bell
Dog Bark
Cat Meow
Door Knock
Shouting
SNSoundPrintAEmbeddingModel
com.apple.SoundAnalysis.classifier.v1
com.apple.SoundAnalysis.System
Unknown request of type %@
enumeratedDurations
durationRange
q24@?0@"NSValue"8@"NSValue"16
SNTimeDurationConstraint.m
Unhandled enum case
processBuffer
SoundAnalysis_ProcessingTree.cpp
inputBuffer.mNumFrames == expectedNumberOfFrames
treeGraph
addProcessingContext
!findAnalyzerNodeForContext(processingContext)
setProcessingContexts
format().mBlockSize > 0
removeNodeRecursively
node
removeProcessingContext
requestProcessingNode
MultiRateGraphBox
SingleRateGraphBox
getCurrentInputSampleFromGraphBox
false
convertSampleTimeToRootSampleTime
Couldn't find GraphBox containing graph
Processing tree graph is null
.dot
buildTreeGraphRecursively
downstreamNode->upstreamNode()
formatsAreEquivalent(downstreamNode->upstreamFB(), downstreamNode->upstreamNode()->downstreamFB())
deadEnd
Box::out inIndex out of range! box %s has %zu outputs but input %u was requested
GraphBoxCommon
DSPGraph_GraphBox.h
inGraph
/Library/Caches/com.apple.xbs/Sources/Listen_Sim/Listen-97.2/Framework/Internal/Core/DSPGraph/DSPGraph_GraphBox.h
%s %s graph must have at least one input bus.
%s %s graph must have the same sample rate for all input busses to be used in a GraphBox
%s %s graph must have the same sample rate for all output busses to be used in a GraphBox
innerGraph %p
setParameter
DSPGraph parameters must have global scope and master element.
getParameter
process
isIntegral(numPacketsToWrite)
prepareGraphIOData
mGraphIODataIn.at(0).mNumFrames == inNumFrames
isIntegral(numPacketsOut)
outNumBytes <= mOutBufferList->GetCapacityBytes()
findGraphBoxContainingBox
Tick delta too large
sampleRate
blockSize
magnitudeThreshold
-[SNDetectSignalThresholdRequestImpl resultsFromBox:renderedWithFrameCount:]
SNDetectSignalThresholdRequest.mm
allBussesSignalRanges.size() == 1
allBussesSignalRanges.at(0).size() == 1
detectorEndPosition >= detectorStartPosition
Failed to create DSPGraph
signalDetector
com.apple.SoundAnalysis
SNCorrelateAudioRequest.mm
Invalid parameter not satisfying: %@
overlapFactor >= 0.f
overlapFactor < 1.f
CrossCorrelator
Failed to create graph
Failed to set properties and parameters on graph
(            
graphName "AudioCorrelator"                        
[def procSampleRate %d]            
[def blockSize %d]            
[def numChannels %d]            
[def numBuses %d]                        
in input                        
box CrossCorrelator (aufx xcor appl) [numBuses] [numBuses]            
box dead dead [numBuses] [numBuses]                        
wire input  CrossCorrelator ([procSampleRate] [numChannels] [blockSize])            
wire CrossCorrelator dead ([procSampleRate] [numChannels] [blockSize]))
Text
CopyDataFrom
CABufferList.h
mBufferCapacity == 0 || other.mBuffers[i].mDataByteSize <= mBufferCapacity
com.apple.soundanalysisd
-[SNAnalysisServer init]
com.apple.SoundAnalysis.client
-[SNAnalysisClient init]
@"NSXPCConnection"24@?0@?<v@?>8@"NSObject<OS_dispatch_queue>"16
LogMelSpectrogram
logMelContext
melTransform
com.apple.SNFileSharing
FileSharingVersion
FileTransferRequest
FileTransferComplete
FileTransferDeleteFile
targetPublicKey
targetID
basePath
filePaths
enable_second_pass_recording_in_daemon
daemon_recording_path
recording_directory_maximum_size_bytes
recording_time_to_live_seconds
delete_recordings_without_detection
enable_file_server
file_server_root_directory
built_in_microphone_analysis_channel_number
enable_verbose_logging
SoundAnalysisAnonymousClient
Library
Caches
AudioCaptures
v32@?0@"NSDictionary"8@"NSDictionary"16@"NSError"24
-[SNResourceCoordinatorXPCSubscriber init]
identifier
detected
%@: %@ detected with confidence %f at %@
SNMLModelCacheKey.m
modelClass != nil
modelConfiguration != nil
%@ detected: %@
Type
DSPGraph
AUStrip
PropertyStrip
Path
IncludePaths
Substitutions
Value
SNSoundPrintFeatureExtractorConfiguration.mm
overlapFactor >= 0.0 && overlapFactor < 1.0
VerifyNotTrashingOwnedBuffer
mBufferMemory == NULL
-[SNResultsXPCSubscriber init]
failed to initialize instance of class %@
com.apple.SoundAnalysis.remoteanalyzer
Server connection lost
-[SNSystemAudioAnalyzerRemote init]
@"<SNSystemAudioAnalyzerProtocol>"24@?0@?<v@?>8@"NSObject<OS_dispatch_queue>"16
analyzerProcessingGraph should be non-null
ProcessingContext
SoundAnalysis_ProcessingContext.cpp
requestProcessingGraph->configured()
sharedProcessingGraph->configured()
config-model-epoch-mvn-60.json
floatToFixedConverter
speechEmotionAnalyzer
%f, %d
overlapFactor
windowDuration
classifierIdentifier
Invalid model, userSuppliedInputFeatureNames.count = %lu
Invalid model, input feature must be a multi-array
Invalid model, input feature must be one dimensional (for mono audio), or two dimensional (for multichannel audio).
Invalid model, block size must be 2 or greater
Invalid model, classification models must have 'predictedProbabilitesName' and 'predictedFeaturesKey' properties
-init is not a valid initializer for the class SNClassifySoundRequest
+new is not a valid class method for the class SNClassifySoundRequest
Unknown classifier identifier
Invalid classifier identifier provided: %@
Classifier
context
createGraphWithModel
SNClassifySoundRequest.mm
overlapFactor >= 0.0
overlapFactor < 1.0
Couldn't open audio file %@
com.apple.SoundAnalysis.FileAnalyzer
-[SNAudioFileAnalyzer advanceSamples:withHandler:]
SNAudioFileAnalyzer.mm
self->_audioFile.length > self->_audioFile.framePosition
Couldn't read audio into buffer
v16@?0@"AVAudioPCMBuffer"8
requestType
AUNeuralNetVAD.dspg
AUNeuralNetVAD_SiriEndpointer.propstrip
AUNeuralNetVAD_Siri.austrip
NNVAD
-[SNAnalyzerHost adaptToSystemConfiguration:error:]
SNAnalyzerHost.mm
resultsBox
+[SNAnalyzerHost convertTimeRange:fromBox:usingConverter:]
clientSampleTimeEnd >= clientSampleTimeStart
SoundPrintEmbedding
embeddingExtractor
createGraph
SNSoundPrintFeatureExtractor.mm
configuration.stepSizeFrames > 0 && configuration.stepSizeFrames <= configuration.windowLengthFrames
Do not call %@
-[SNDSPGraphBox init]
SNDSPGraphBox.mm
graph
com.apple.soundanalysis
companion service connection interrupted
v16@?0@"RPCompanionLinkDevice"8
version
v20@?0@"RPCompanionLinkDevice"8I16
expected feature optionality to equal %@
expected shape constraint to have ranged type
expected shape constraint to require %@ dimensions
expected shape constraint dimension %@ to match range: %@
expected shape constraint to enumerated type
expected shape constraint to have shape options %@
expected shape constraint to have unspecified type
expected constraint to have data type %@
expected feature to have multi array type
expected input features to match %@
expected output features to match %@
com.apple.SoundAnalysis.CanHostDaemon
illegal call to unavailable method: %s
-[SNMemoizedMLModel init]
-[SNMemoizedMLModel initWithModelDescription:parameterDictionary:error:]
+[SNMemoizedMLModel new]
@"MLModel"8@?0
SNForwardPassAudioStreamAnalyzer.mm
Audio format must be PCM
v16@?0@"<SNResult>"8
Error creating analyzer
Error configuring analyzer
Error updating tree format
Error configuring analysis tree
Audio format changed mid-stream from %@ to %@. Please configure a new analyzer if the stream format changes.
Error during analysis
Failed to prime analysis
yyyy-MM-dd-HHmmss
%@_%@
yyyy-MM-dd HH:mm:ss
levelMeasurer
dead
v24@?0@"CUFileResponse"8@"NSError"16
+[SNUtils copyAudioBufferList:to:frameCount:bytesPerFrame:]
SNUtils.mm
sourceBufferList->mNumberBuffers > 0
sourceBufferList->mNumberBuffers == destinationBufferList->mNumberBuffers
sourceBufferList->mBuffers[bufferIdx].mNumberChannels > 0
frameCount*bytesPerFrame <= sourceBufferList->mBuffers[bufferIdx].mDataByteSize
frameCount*bytesPerFrame <= destinationBufferList->mBuffers[bufferIdx].mDataByteSize
denylist
MultiArrayInput
MultiArrayOutput
MLModelCreatorDefinedKey
feedback_connections
soundanalysisd
InternalBuild
SELF endswith[c] '.wav'
q24@?0@"NSString"8@"NSString"16
unable to read entitlement
failed to acquire task
v152@?0{?={?=qiIq}{?=qiIq}}8{?={?=qiIq}{?=qiIq}}56{?={?=qiIq}{?=qiIq}}104
Could not create MLMultiarray.
Cannot access data: nil MLMultiarray.
@"AVAudioPCMBuffer"8@?0
B24@?0@"AVAudioPCMBuffer"8^@16
v20@?0I8@"NSError"12
Couldn't read negative duration
prefix did not populate all requested frames
did not process all frames
suffix did not populate all requested frames
B32@?0^v8Q16^@24
B16@?0@"AVAudioPCMBuffer"8
unsupported audio file format; need float32
bad num dimensions; need >0
B24@?0@?<B@?^vQ^@>8^@16
v24@?0@"MLModel"8@"NSError"16
timeout expired while attempting to load model
results
errors
completeCount
copyRecentFramesOfAudioRingBufferToAVAudioBuffer
sourceBufferStartTime <= sourceBufferEndTime
copyRecentFrames
unownedViewOfRecentFrames
numberOfRecentFrames <= sourceBuffer.frameLength
-[SNResourceCoordinatorXPCPublisher init]
v16@?0@"<SNSystemAudioAnalyzerXPCProtocol>"8
-[SNDSPGraph init]
SNDSPGraph.mm
@"SNDSPGraphBox"8@?0
@"NSMutableSet"8@?0
@"NSString"8@?0
addDownstreamNodes
SoundAnalysis_ProcessingNode.cpp
!elementFoundInList(node, mDownstreamNodes)
CA::StreamDescription::IsEquivalent(node->upstreamFB().mFormat, downstreamFB().mFormat)
removeDownstreamNodes
elementFoundInList(node, mDownstreamNodes)
processingBox
mProcessingBox
/Library/Caches/com.apple.xbs/Sources/Listen_Sim/Listen-97.2/Framework/Internal/Core/DSPGraph/DSPGraph_CoreMLBox.mm
only supports 1 bus in 1 bus out
input format must be deinterleaved
output must be single channel
input and output sample rates must match
MLModel input doesn't match CoreMLBox upstream block size
DSPGraph_CoreMLBox.mm
inABL
outABL
inABL->mBuffers[0].mDataByteSize == mInputNumBytes
input data must be Float32
Error: Model input size (
 bytes) doesn't match audio input size (
 bytes)
prediction failed
MLModel output must have only one feature (MLMultiArray)
MLModel output must be an MLMultiArray
Error: Model output size (
unsupported CoreML data type
CoreMLBox
v32@?0@"NSDictionary"8@"NSDictionary"16@?<v@?@"NSDictionary"@"NSDictionary"@"NSError">24
v24@?0@"NSArray"8@"NSError"16
-[SNCopyFilesRequest launchTaskWithQueue:completionHandler:resultsHandler:]_block_invoke
SNCopyFilesRequest.m
error == nil
v24@?0@"RPFileTransferItem"8@?<v@?@"NSError">16
-[SNAudioRecordingQueueScheduler init]
com.apple.SoundAnalysis.AnalysisInProgress
Unexpected MultiArray size %ld
Unexpected error processing model
Must only have one input audio feature
Model needs an input constraint
Must allow %@ shaped vector as input
Must only have one output multiarray feature
Model needs an output constraint
Must allow %@ shaped vector as output
_SNVGGishFrontEndProcessingCustomModel
adjustSingleChannelIODataAhead
SNVGGishFrontEndProcessingCustomModel.mm
data.mBufferList->mBuffers[0].mDataByteSize >= framesToAdjust * sizeof(float)
v24@?0^v8^{GraphIOData=II{AudioTimeStamp=dQdQ{SMPTETime=ssIIIssss}II}^{AudioBufferList}}16
operator()
scratchFloatSpace.size() >= multiArray.count
InvalidFormatException
com.apple.SoundAnalysis.AnalyzerQueue
BuildVersion
buildVersion
listenType
fileName
audioStringDate
confidenceValues
userFeedback
numberOfSamples
timestamp
Name
MinDurationBlocks
ConfidenceThreshold
Failed to parse trigger dictionary, required keys not found
AudioHopSizeSamples
AudioSampleRate
BlocksBetweenTriggers
Commands
Failed to parse dictionary, trigger not found in given model
Failed to parse dictionary
DSPGraph_ContextBox.cpp
/Library/Caches/com.apple.xbs/Sources/Listen_Sim/Listen-97.2/Framework/Internal/Core/DSPGraph/DSPGraph_ContextBox.cpp
validateFormats
Context box can't produce variable output frames.
input and output channel counts don't match
ContextBox has no inputs
mMaxFrames > 1
number of context frames must be greater than block size
isIntegral(mOutputHopSize)
inNumFrames <= mMaxFrames
inNumFrames == mMaxFrames
selfLatencyInTicks
setHistoricalBuffer
historical buffer size must match ring buffer readAvail
RPFTSource
v16@?0@"RPFileTransferProgress"8
%@_%@_bus%ld_%@.caf
%@ startRecordingPort was unsuccessful
SNDSPGraphUtilities
computationalDutyCycle
graphIsDeadEnded
shouldThrowException
Throwing a fake exception to aid in unit testing
com.apple.soundanalysis.SystemAudioAnalyzer
com.apple.soundanalysis.SystemAudioAnalyzer.analysis
v24@?0@"AVAudioBuffer"8@"AVAudioTime"16
Audio stream interrupted
n_mels
fmin
fmax
mel_type
norm
hop_length
win_length
win_offset
n_fft
fft_offset
slaney
none
expected one of choices: %@
expected string
B24@?0@8^@16
expected number
@?<B@?@^@>16@?0@?<v@?I>8
@?<B@?@^@>16@?0@?<v@?f>8
@?<B@?@^@>16@?0@?<v@?i>8
@?<B@?@^@>24@?0@"NSArray"8@?<v@?@"NSString">16
v12@?0I8
v12@?0f8
v16@?0@"NSString"8
v12@?0i8
invalid parameter for key %@
B24@?0@"NSArray"8^@16
expected exactly one feature
B24@?0@"MLFeatureDescription"8^@16
expected all features to be MLMultiArray instances
expected all features to be required
expected constraint: <BATCH>x<NCHAN>x<NSAMPLES> NCHAN is in range [1, 1]
expected constraint: <BATCH>x<NCHAN>x<NMELS>x<NFRAMES> where BATCH is in range [1, IntMax + 1], NCHAN is in range [1, 1], NMELS is given by `n_mels` model parameter
@"NSString"24@?0@"NSArray"8^@16
model input validation failed
model output validation failed
v24@?0@"NSString"8@"NSString"16
v16@?0^v8
B8@?0
@"SNDSPGraph"8@?0
classificationDictionary
-init is not a valid initializer for the class SNClassificationResult
+new is not a valid class method for the class SNClassificationResult
v32@?0@"NSString"8@"NSNumber"16^B24
q24@?0@8@16
%@ %@
-init is not a valid initializer for the class SNClassification
+new is not a valid class method for the class SNClassification
%@ = %f
category
mode
options
%@ %@ %lu
B24@?0@"NSString"8@"NSString"16
feature provider does not provide expected feature names
_SNSoundPrintAFeatureEmbeddingCustomModel
-[_SNSoundPrintFeatureEmbeddingCustomModel initWithModel:modelDescription:]
SNSoundPrintCustomModel.mm
_outerToInnerInputFeatureNameMappings
_outerToInnerOutputFeatureNameMappings
Couldn't load SoundPrintA model
/System/Library/Frameworks/AudioToolbox.framework/libAudioDSP.dylib
RegisterAudioUnits_InternalUnsearchable
SNThresholdBasedSecondPassController.m
secondPassHangoverPeriod >= 0.0
floatFormatWithContext
SNDSPGraphUtils.mm
sampleRate > 0 && blockSize > 0 && contextSize > 0 && channelCount > 0
floatFormat
sampleRate > 0 && blockSize > 0
/Library/Caches/com.apple.xbs/Sources/Listen_Sim/Listen-97.2/Framework/Internal/Core/DSPGraph/DSPGraph_SignalDetectorBox.cpp
inputs must be LPCM
DSPGraph_SignalDetectorBox.cpp
mInputSignalRanges.at(busIdx).at(channelIdx).capacity() >= inNumFrames
SignalDetectorBox
-[SNResultsXPCPublisher init]
failed to initialize instance of class %s
-[SNResultsXPCPublisher initWithSubscriber:]
/Library/Caches/com.apple.xbs/Sources/Listen_Sim/Listen-97.2/Framework/Internal/Core/DSPGraph/DSPGraph_LogMelTransformBox.cpp
input must be single channel
DSPGraph_LogMelTransformBox.cpp
LogMelTransformBox
-[SNSystemAudioAnalyzerXPCSubscriber init]
expected NSXPC to pass a proxy object for argument `observer`
could not add request; unknown error
audioSamples
mlmodelc
classLabel
SNSoundClassifierVersion1Model
(SNSystemAudioAnalyzerXPCPublisher:%@) addRequest:%@ withObserver:%@
(SNSystemAudioAnalyzerXPCPublisher:%@) removeRequest:%@
(SNSystemAudioAnalyzerXPCPublisher:%@) removeAllRequests
(SNSystemAudioAnalyzerXPCPublisher:%@) start
(SNSystemAudioAnalyzerXPCPublisher:%@) stop
(SNSystemAudioAnalyzerXPCPublisher:%@) setAudioConfiguration
Couldn't obtain the built-in mic UID. Skipping setting of the AQ channel assignments
Set audio queue channel assignment %u with result %d
Could register audio units. Returning nil for %@
IncludePaths parse failed
Substitutions parse failed
SNDSPConfiguration parse failed
Applying AUStrip %@ to graph %@ failed
Error applying AUStrip. DSPGraph must be the first item in a DSPConfiguration.
Applying PropertyStrip %@ to graph %@ failed
Error applying PropertyStrip. DSPGraph must be the first item in a DSPConfiguration.
DSPGraphInfo doesn't specify either text or path
AUStripInfo doesn't specify either value or path
PropertyStripInfo doesn't specify either value or path
SNSoundPrintFeatureExtractor models must have one input feature
SNSoundPrintFeatureExtractor model must have an MLMultiArray input feature
SNSoundPrintFeatureExtractor models must have one output feature
SNSoundPrintFeatureExtractor model must have an MLMultiArray output feature
Instantiating SNSystemAudioAnalyzer with In-Process Computation
Instantiating SNSystemAudioAnalyzer in Daemon
(SNSystemAudioAnalyzer:%@) addRequest:%@ withObserver:%@
(SNSystemAudioAnalyzer:%@) addRequestInBackground:%@ withObserver:%@
(SNSystemAudioAnalyzer:%@) removeRequest:%@
(SNSystemAudioAnalyzer:%@) removeAllRequests
(SNSystemAudioAnalyzer:%@) start
(SNSystemAudioAnalyzer:%@) stop
(SNSystemAudioAnalyzerRemote: %@) remote analyzer invalidated: %@
(SNSystemAudioAnalyzerRemote: %@) remote analyzer invalidation attempted; stalling further activity
(SNSystemAudioAnalyzerRemote: %@) finished stalling after analyzer invalidation attempt
(SNSystemAudioAnalyzerRemote:%@) _setAudioConfiguration
(SNSystemAudioAnalyzerRemote:%@) setAudioConfiguration
(SNSystemAudioAnalyzerRemote:%@) addRequest:%@ withObserver:%@
(SNSystemAudioAnalyzerRemote:%@) removeRequest:%@
(SNSystemAudioAnalyzerRemote:%@) removeAllRequests
(SNSystemAudioAnalyzerRemote:%@) start
(SNSystemAudioAnalyzerRemote:%@) stop
EAR framework returned %lu bytes instead of %d float elements
Unknown exception caught!
Caught OSStatus exception %d %4.4s
std::exception caught: %s.
Caught graph exception %d %4.4s %s in %s:%i
Companion service connection invalidated
Could not contact remote SNFileServer to query version (this may not be an issue; not all devices are expected to host SNFileServers); reason: %@
Device found %@
Version check messaged failed with error %@
Version %@
device updated: %@ with changes: %ld
Link failed to activate with error %@
error querying entitlement %@: %@
inadequate entitlements to host daemon
Activated file server with error %@
Created model of class %@ with error %@
for handler %p: result (%@) produced by request %@
for handler %p: termination (%@) received from request %@
Required shared request not found with configuration %@
request failed to adapt to system configuration %@ with error %@
failed to set processing contexts
Caught error: %s
Unknown error
Unknown error while priming
Priming error: %s
Unimplemented
Error analyzing audio buffer
Removing %@, since it doesn't contain any detections
Failed to write results log file with error %@
Started recording graph
Failed to start recording graph
No sample rate metadata provided in model. Defaulting to %d
Feedback connection destination %@ not present in model
Feedback connection source %@ not present in model
Couldn't parse feedback connection. Should be 'source -> destination'
Failed to get files list. Giving up on directory size reduction. Error: %@
Sorting files by date failed; continuing but may have unpredictable results.
No SoundAnalysis file removal needed. Directory size approx: %lld kb.
Deleting these sound files + their associated metadata files: %@
Failed to delete audio file %@. Error: %@
Failed to delete text file %@. Error: %@
Failed to open audio file %@ with error %@
%@ didProduce %@
%@ didFailWith %@
%@ didComplete
AUStrip is nil
PropertyStrip is nil
Model must have MLMultiArray features
CoreMLBox configured to receive %@ elements. CoreMLModel input expects %@ total elements
Error allocating MLMultiArray
Unable to compile model at %@ with error %@
MLModel successfully loaded!
No CoreML model set: %@
MLModel must have at least one feature in and one feature out
MLModel must have only one user defined input. Has %@
MLModel supports block sizes in range %@. CoreMLBox block size is %d.
MLModel input requires %d total elements. CoreMLBox wire block size is %d, with %d channels
Error creating input provider
No CoreML model prepared. Bypassing.
No MLModel, bypassing this process call
CoreML prediction failed with %@
Audio is already running. Model will be loaded next time audio is restarted
Set CoreMLModel URL at path %@
Error creating URL from path: %@
Transfer completed
Fetched local device identity
Fetched server device identity %@
File sharing messaged failed with error %@
Received a file sharing request response %@
Received a file item %@
Queue already running
Failed to create audio queue
Starting audio queue
Stopping audio queue
Completed first pass for request %@ with error %@
Resizing historical ring buffer from %d to %d frames after adding %@
Beginning second pass for request %@
Couldn't begin second pass recording with error %@
Couldn't begin recording, no path set
Completed second pass for request %@ with error %@
Beginning %f seconds of historical data catch-up for request %@
Ended historical data catch-up for request %@
Ending second pass for request %@
Resizing historical ring buffer from %d to %d frames after removing %@
Wrote file %@ at %@ with result %d.
Received version request
Received file transfer request
Progressing %@
Finished transferring files with error %@
Message transmitted!: %@
Skipping transferring of file %@
Requested file path %@
Received file deletion request on server for file path: %@
File deletion request failed on the server: %@
Box %s doesn't exist in graph
(SNSystemAudioAnalyzerLocal:%@) setAudioConfiguration:%@
(SNSystemAudioAnalyzerLocal:%@) addRequest:%@ withObserver:%@
(SNSystemAudioAnalyzerLocal:%@) removeRequest:%@
(SNSystemAudioAnalyzerLocal:%@) removeAllRequests
(SNSystemAudioAnalyzerLocal:%@) start
(SNSystemAudioAnalyzerLocal:%@) stop
Failed to set AVAudioSession with error %@
Failed to activate AVAudioSession with error %@
Audio failed to start. Retrying in %d seconds
Failed to deactivate AVAudioSession with error %@
AVAudioSession interrupted %@
AVAudioSession route change %@
AVAudioSession media services lost %@
AVAudioSession media services reset %@
Graph %@ couldn't be compiled
Graph couldn't be compiled from text
No distance classifier model available on this product
Input feature count doesn't match
Input feature description has > 1 input feature
Input feature isn't an MLMultiArray
Input feature has more than one non-unitary dimension
Additional input feature dimensions must be have size 1
Input feature must contain floating point data
Output feature count doesn't match
Output feature description has > 1 input feature
Output feature has more than one non-unitary dimension
Additional output feature dimensions must be have size 1
Output feature must contain floating point data
Error: Unable to call RegisterAudioUnits_InternalUnsearchable from libAudioDSP.dylib.
Processor not found with configuration %@
(SNSystemAudioAnalyzerXPCSubscriber:%@) addRequest:%@ withObserver:%@
(SNSystemAudioAnalyzerXPCSubscriber:%@) removeRequest:%@
(SNSystemAudioAnalyzerXPCSubscriber:%@) removeAllRequests
(SNSystemAudioAnalyzerXPCSubscriber:%@) start
(SNSystemAudioAnalyzerXPCSubscriber:%@) stop
(SNSystemAudioAnalyzerXPCSubscriber:%@) setAudioConfiguration
Could not load SNSoundPrintAEmbeddingModel.mlmodelc in the bundle resource
Could not load SNSoundClassifierVersion1Model.mlmodelc in the bundle resource
SNLKFSResult
NSCopying
NSSecureCoding
NSCoding
SNTimeRangeProvidingWritable
SNTimeRangeProviding
NSObject
SNDetectorVariant
SNSpeechEmotionResult
SRSampling
SNConfidenceProvidingWritable
SNConfidenceProviding
SNResult
SNFileServerDiscoveryResult
SNResultsObservingXPCProtocol
SNSystemAudioAnalyzerXPCPublisher
SNSystemAudioAnalyzerProtocol
SNAudioQueueConfiguration
SNAudioDataSourceUtilities
SNFileDeletionResult
SNSplitDetectorInfo
SNTaskCreating
SNRequest
SNFileSystem
SNTimeDurationConstraint
SNDetectSignalThresholdRequest
SNAnalyzerCreating
SNDetectSignalThresholdRequestImpl
SNAnalyzing
SNProcessing
SNError
SNCorrelateAudioRequest
SNAudioCorrelator
SNSystemServiceResourceCoordinator
SNResourceCoordinatorProtocol
SNAnalysisServer
NSXPCListenerDelegate
SNAnalysisClient
SNUserDefaults
SNDeleteFilesRequest
SNMLCustomModel
SNMLModel
SNMLLockedModel
SNResourceCoordinatorXPCSubscriber
SNResourceCoordinatorXPCProtocol
SNDetectionResult
SNMLModelCacheKey
SNCustomTwoPassRequest
SNTwoPassRequest
SNSpeechUtteranceResult
SNDSPItemInfo
SNDSPGraphInfo
SNAUStripInfo
SNPropertyStripInfo
SNDSPConfiguration
SNDSPGraphLoader
SNSoundPrintFeatureExtractorConfiguration
SNProcessorCreating
SNDictionaryAdditions
SNResultsXPCSubscriber
SNResultsObserving
SNSystemAudioAnalyzer
SNFileListingResult
SNSystemAudioAnalyzerRemote
SNFileServerInfo
SNEstimateSpeechEmotionRequest
SNSpeechEmotionEstimator
EARSyncPSRAudioProcessorDelegate
SNSystemConfiguration
SNFilterVoiceTriggerResults
SNSoundClassifier
SNClassifySoundRequest
SNAudioFileAnalyzer
SNDetectSpeechUtteranceRequest
SNSpeechUtteranceDetector
SNTimeConversionDictionaryProviding
SNAnalyzerHost
SNSoundPrintFeatureExtractor
SNDSPGraphBox
SNDiscoverFileServerRequest
SNValidateModel
SNDaemon
SNMemoizedMLModel
MLCustomModel
SNLockedMLModelFactory
SNMLModelFactory
SNAnalyzerInfo
SNForwardPassAudioStreamAnalyzer
SNTimeConverting
SNMeasureLKFSRequest
SNAudioLevelMeasurer
SNListFilesRequest
SNUtils
SNResultsCollector
SNResultsPrinter
SNResultsForwarder
SNBooleanCancellable
SNCancellable
SNModelFeatureConnection
SNResourceCoordinatorXPCPublisher
SNDSPGraph
SNVoiceTriggerResult
DSPGMLInputProvider
MLFeatureProvider
DSPGCoreMLInfo
SNFileCopyingResult
SNVoiceTriggerCommandDataPoint
SNVoiceTriggerCommandFilter
SNProcessVoiceTriggerModelOutput
SNCopyFilesRequest
SNTwoPassConfiguration
SNAudioRecordingQueueScheduler
SNAudioRecordingQueue
SNDSPGraphCustomModel
_SNVGGishFrontEndProcessingCustomModel
SNAudioStreamAnalyzer
SNUltronResultsLogger
SNVoiceTriggerCommand
SNDetectVoiceTriggerRequest
SNVoiceTriggerDetector
SNFileServer
SNBoxRecordingInfo
SNDSPGraphUtilities
SNSystemAudioAnalyzerXPCProtocol
SNNullRequest
SNNullDetector
SNSystemAudioAnalyzerLocal
SNLogMelSpectrogramCustomModelUtils
_SNLogMelSpectrogramCustomModel
SNDSPGraphInterpreter
SNClassificationResult
SNClassification
SNDistanceClassifier
SNSignalThresholdResult
SNAudioConfiguration
SNWrapModel
_SNSoundPrintFeatureEmbeddingCustomModel
_SNSoundPrintAFeatureEmbeddingCustomModel
SNAudioUnitRegistration
SNThresholdBasedSecondPassController
SNSecondPassController
SNAudioProcessorCache
SNNullResult
SNAudioCorrelationResult
SNResultsXPCPublisher
NSXPCProxyCreating
SNSystemAudioAnalyzerXPCSubscriber
SNSoundPrintAEmbeddingModelInput
SNSoundPrintAEmbeddingModelOutput
SNSoundPrintAEmbeddingModel
SNSoundClassifierVersion1ModelInput
SNSoundClassifierVersion1ModelOutput
SNSoundClassifierVersion1Model
allocWithZone:
init
timeRange
setTimeRange:
decibelLevel
setDecibelLevel:
isEqualToLKFSResult:
valueWithCMTimeRange:
isEqual:
hash
numberWithFloat:
decodeObjectOfClass:forKey:
decodeDoubleForKey:
CMTimeRangeValue
encodeObject:forKey:
encodeDouble:forKey:
supportsSecureCoding
copyWithZone:
encodeWithCoder:
initWithCoder:
TB,R
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
superclass
description
debugDescription
TQ,R
T#,R
T@"NSString",R,C
T{?={?=qiIq}{?=qiIq}},R,N
T{?={?=qiIq}{?=qiIq}},N
_decibelLevel
_timeRange
Tf,N,V_decibelLevel
T{?={?=qiIq}{?=qiIq}},N,V_timeRange
decodeIntegerForKey:
initWithDetectorIdentifier:
encodeInteger:forKey:
raise:format:
detectorIdentifier
isEqualToDetectorVariant:
type
vggishBasedMLModel
numberWithInteger:
initWithVGGishBasedMLModel:
.cxx_destruct
_type
_vggishBasedMLModel
_detectorIdentifier
Tq,R,V_type
T@"MLModel",R,V_vggishBasedMLModel
T@"NSString",R,V_detectorIdentifier
mood
valence
arousal
dominance
confidence
stringWithFormat:
setMood:
setValence:
setArousal:
setDominance:
setConfidence:
isEqualToSpeechEmotionResult:
numberWithDouble:
unarchivedObjectOfClass:fromData:error:
archivedDataWithRootObject:requiringSecureCoding:error:
initWithBinarySampleRepresentation:
initWithBinarySampleRepresentation:metadata:timestamp:
binarySampleRepresentation
Td,R,N
Td,N
_confidence
_mood
_valence
_arousal
_dominance
Td,V_mood
Td,V_valence
Td,V_arousal
Td,V_dominance
Td,N,V_confidence
dataWithBytes:length:
addAudio:
endAudio
getLatestSuperVector
initWithConfigFile:configRoot:sampleRate:delegate:queue:
resetForNewRequest
setServerInfo:
setState:
initWithServerInfo:state:
serverInfo
state
_serverInfo
_state
T@"SNFileServerInfo",&,N,V_serverInfo
TQ,N,V_state
xpcRequest:didProduceResult:completionHandler:
xpcRequest:didFailWithError:completionHandler:
xpcRequestDidComplete:completionHandler:
interfaceWithProtocol:
setClasses:forSelector:argumentIndex:ofReply:
initWithReceiver:
synchronousRemoteObjectProxyWithErrorHandler:
xpcAddRequest:withObserver:completionHandler:
errorWithCode:underlyingError:message:
xpcRemoveRequest:completionHandler:
xpcRemoveAllRequestsWithCompletionHandler:
xpcStartWithCompletionHandler:
xpcStopWithCompletionHandler:
xpcSetAudioConfiguration:completionHandler:
setAudioConfiguration:
addRequest:withObserver:error:
removeRequest:
removeAllRequests
start
stop
initWithSubscriber:
_subscriber
creationFlags
setCreationFlags:
configureAudioQueue
setConfigureAudioQueue:
_creationFlags
_configureAudioQueue
TI,V_creationFlags
T@?,C,V_configureAudioQueue
enableAlwaysOnAudioRouting:
setChannelAssignment:onQueue:
builtInMicrophoneAnalysisChannelNumberOrDefault:
createDefaultAudioQueueConfigurationUsingChannelNumber:
sharedInstance
availableInputs
countByEnumeratingWithState:objects:count:
portType
isEqualToString:
builtInMicrophoneDeviceUID
createSiriAudioQueueConfigurationUsingChannelNumber:
audioQueueConfiguration
T@"SNAudioQueueConfiguration",R
setFileName:
setError:
initWithFileName:error:
fileName
error
_fileName
_error
T@"NSString",&,N,V_fileName
T@"NSError",&,N,V_error
initWithDetectorHead:featureExtractor:soundIdentifier:
detectorHead
featureExtractor
soundIdentifier
_detectorHead
_featureExtractor
_soundIdentifier
T@"NSString",R,N,V_detectorHead
T@"NSString",R,N,V_featureExtractor
T@"NSString",R,N,V_soundIdentifier
queue
launchTaskWithQueue:completionHandler:resultsHandler:
_removeRequest:error:
taskCompletionMap
valueWithPointer:
setObject:forKeyedSubscript:
objectForKey:
removeObjectForKey:
requests
addRequest:completionHandler:resultsHandler:
setRequests:
setTaskCompletionMap:
setQueue:
_requests
_taskCompletionMap
_queue
T@"NSMutableArray",&,N,V_requests
T@"NSMutableDictionary",&,N,V_taskCompletionMap
T@"NSObject<OS_dispatch_queue>",&,N,V_queue
CMTimeValue
sortedArrayUsingComparator:
isEqualToTimeDurationConstraint:
initWithDurationRange:
initWithEnumeratedDurations:
currentHandler
handleFailureInMethod:object:file:lineNumber:description:
durationRange
enumeratedDurations
isEqualToArray:
decodeCMTimeRangeForKey:
arrayWithObjects:count:
setWithArray:
decodeObjectOfClasses:forKey:
encodeCMTimeRange:forKey:
_enumeratedDurations
_durationRange
T@"NSArray",R,V_enumeratedDurations
T{?={?=qiIq}{?=qiIq}},R,V_durationRange
initWithSampleRate:blockSize:magnitudeThreshold:
sampleRate
setSampleRate:
blockSize
setBlockSize:
magnitudeThreshold
setMagnitudeThreshold:
isEqualToDetectSignalThresholdRequest:
numberWithUnsignedInt:
createAnalyzerWithError:
_detector
_blockSize
_sampleRate
_magnitudeThreshold
Td,N,V_sampleRate
TI,N,V_blockSize
Td,N,V_magnitudeThreshold
array
addObject:
populateClientError:withCode:underlyingError:message:
stringWithUTF8String:
adaptToSystemConfiguration:error:
graph
T{shared_ptr<DSPGraph::Graph>=^{Graph}^{__shared_weak_count}},R,N
resultsFromBox:renderedWithFrameCount:
sharedProcessorConfiguration
resultsBox
primeGraph
T^v,R,N
.cxx_construct
_graph
UTF8String
dictionaryWithObjectsAndKeys:
errorWithDomain:code:userInfo:
registerAudioUnits
initWithAudioFile:overlapFactor:
initWithAudioFile:
overlapFactor
setOverlapFactor:
_referenceAudioFile
_overlapFactor
Td,V_overlapFactor
processingFormat
length
setChannelIndex:
setPeakValue:
setPeakTime:
channelCount
_systemConfiguration
_referenceSampleRate
_channelCount
_framesProcessed
Td,R,V_overlapFactor
dictionaryWithObjects:forKeys:count:
initWithDictionary:resourcePath:
graphWithGraphInfo:
initWithPCMFormat:frameCapacity:
setFramePosition:
readIntoBuffer:error:
streamDescription
audioBufferList
createSystemAudioAnalyzer
setDelegate:
resume
endpoint
initWithListenerEndpoint:
setExportedInterface:
setExportedObject:
launchAsMachServiceWithName:
initWithMachServiceName:
launchWithResourceCoordinator:onXPCListener:
initWithResourceCoordinator:onListener:
launchDefaultServer
listener:shouldAcceptNewConnection:
connectLocally
_listener
_coordinator
initToConnectToMachServiceWithName:queue:
initWithMachServiceName:options:
setInterruptionHandler:
setInvalidationHandler:
newConnectionToMachServiceWithName:lostConnectionHandler:queue:
initWithConnectionGenerator:queue:
_handleLostConnection
setRemoteObjectInterface:
_connectionToServerWithInvalidationHandler:queue:
remoteObjectProxy
_remoteResourceCoordinatorWithInvalidationHandler:queue:
_createRemoteSystemAudioAnalyzerWithInvalidationHandler:queue:
defaultClient
createRemoteSystemAudioAnalyzerWithInvalidationHandler:queue:
_connectionToServerGenerator
_xpcConnectionToServer
_pendingInvalidationHandlers
userDefaults
boolForKey:
stringForKey:
integerForKey:
doubleForKey:
intValue
numberWithInt:
builtInMicrophoneAnalysisChannelNumber
instance
initWithSuiteName:
setUserDefaults:
mainBundle
bundleIdentifier
pathWithComponents:
registerDefaults:
enableSecondPassRecordingInDaemon
daemonRecordingPath
recordingDirectoryMaximumSizeBytes
recordingTimeToLiveSeconds
deleteRecordingsWithoutDetection
enableFileServer
fileServerRootDirectory
enableVerboseLogging
T@"NSString",R
Tq,R
Td,R
T@"NSNumber",R
_userDefaults
T@"NSUserDefaults",&,N,V_userDefaults
setFiles:
setServerBasePath:
setDispatchQueue:
files
serverBasePath
identifier
sendRequestID:request:destinationID:options:responseHandler:
activateWithCompletion:
invalidate
initWithFiles:serverBasePath:serverInfo:
_files
_serverBasePath
T@"NSArray",&,N,V_files
T@"NSString",&,N,V_serverBasePath
predictionFromFeatures:options:error:
modelDescription
T@"MLModelDescription",R
initWithMLCustomModel:modelDescription:
_customModel
_modelDescription
T@"MLModelDescription",R,V_modelDescription
initWithModel:
_model
_lock
xpcCreateSystemAudioAnalyzerWithCompletionHandler:
_receiver
detected
initWithIdentifier:
setDetected:
setDetectorIdentifier:
isEqualToDetectionResult:
numberWithBool:
decodeBoolForKey:
encodeBool:forKey:
_detected
_identifier
TB,N,V_detected
T@"NSString",&,N,V_detectorIdentifier
T@"NSString",R,N,V_identifier
initWithKeys:
isEqualToModelCacheKey:
initWithModelClass:modelConfiguration:
_keys
createSecondPassController
twoPassConfiguration
T@"SNTwoPassConfiguration",R
initWithTwoPassConfiguration:createSecondPassControllerFunction:
_createSecondPassControllerFunction
_twoPassConfiguration
T@"SNTwoPassConfiguration",R,V_twoPassConfiguration
isEqualToSpeechUtteranceResult:
objectForKeyedSubscript:
stringByAppendingPathComponent:
path
text
includePaths
substitutions
setPath:
setText:
setIncludePaths:
setSubstitutions:
_path
_text
_includePaths
_substitutions
T@"NSString",&,N,V_path
T@"NSString",&,N,V_text
T@"NSArray",&,N,V_includePaths
T@"NSDictionary",&,N,V_substitutions
value
containsOnlyAUStrips:
_value
T@"NSString",R,N,V_path
T@"NSDictionary",R,N,V_value
resourcePath
_resourcePath
T@"NSString",R,N,V_resourcePath
initWithArray:resourcePath:
dspItems
setDspItems:
_dspItems
T@"NSArray",&,N,V_dspItems
applyAUStrip:toGraph:
name
applyPropertyStrip:toGraph:
compileText:withSubstitutions:includingPaths:
compileFile:withSubstitutions:includingPaths:
setAUStrip:
dictionaryWithContentsOfFile:
setPropertyStrip:withResourcePath:
graphWithConfiguration:
isEqualToSoundPrintFeatureExtractorConfiguration:
initWithConfiguration:
createProcessorWithError:
initWithModel:overlapFactor:
model
windowLengthFrames
stepSizeFrames
outputFeatureSize
_windowLengthFrames
_stepSizeFrames
_outputFeatureSize
T@"<SNMLModel>",R,V_model
Td,R,V_sampleRate
TI,R,V_windowLengthFrames
TI,R,V_stepSizeFrames
TI,R,V_outputFeatureSize
inputDescriptionsByName
count
allValues
objectAtIndexedSubscript:
multiArrayConstraint
outputDescriptionsByName
null
setObject:forKey:
sn_setSafeObject:forKey:
request:didProduceResult:
request:didFailWithError:
requestDidComplete:
initWithClient:queue:
selectAppropriateImplForThisProcess
initWithImpl:
configureNewAnalyzersToComputeInThisProcess:
initWithAudioConfiguration:
addRequestInBackground:withObserver:
_impl
setFileItems:
initWithFileItems:
fileItems
_fileItems
T@"NSArray",&,N,V_fileItems
dictionary
initWithRemoteAnalyzerGenerator:queue:
_invalidateAnalyzer:
_invalidateActiveAnalyzer
copy
_removeAllRequests
allKeys
connectionLostError
sleepForTimeInterval:
_acquireSystemAudioAnalyzer
removeAllObjects
_setAudioConfiguration:
_addRequest:withObserver:
_removeRequest:
invalidateActiveAnalyzer
_registeredRequests
_analyzer
_generator
_audioConfiguration
setIdentifier:
setIdsDeviceID:
setModel:
setName:
initWithIdentifier:idsDeviceID:model:name:
idsDeviceID
_idsDeviceID
_name
T@"NSString",&,N,V_identifier
T@"NSString",&,N,V_idsDeviceID
T@"NSString",&,N,V_model
T@"NSString",&,N,V_name
isEqualToSpeechEmotionRequest:
bytes
bundleForClass:
psrAudioProcessor:hasSpeakerVector:speakerVectorSize:processedAudioDurationMs:
psrAudioProcessor:finishedWithFinalSpeakerVector:speakerVectorSize:processedAudioDurationMs:
initWithSampleRate:channelCount:
initWithDouble:
initWithUnsignedInt:
setChannelCount:
TI,N,V_channelCount
initWithTimeBetweenTriggers:
removeOverlappingResults:
_timeBetweenTriggers
_lastResult
userSuppliedInputFeatureNames:
firstObject
anyInputMultiArrayShape:
shapeNonUnitaryDimensionCount:
modelBlockSize:
predictedProbabilitiesName
predictedFeatureName
exceptionWithName:reason:userInfo:
feedbackConnections:
denylistFromModelDescription:
modelSampleRate:orDefaultRate:
outputProvider
featureValueForName:
dictionaryValue
filterClassLabelsInDictionary:usingDenylist:
initWithClassificationDictionary:
setClassifierIdentifier:
completeTimingInfoInResult:usingBox:modelBlockSize:
initWithMLModel:overlapFactor:windowDuration:classifierIdentifier:error:
windowDuration
classifierIdentifier
_modelBlockSize
_resultsToDiscardCount
_feedbackConnections
_classLabelsDenylist
_classifierIdentifier
_windowDuration
T{?=qiIq},R,V_windowDuration
T@"NSString",R,V_classifierIdentifier
shapeConstraint
windowDurationConstraintFromMultiArrayShapeConstraint:sampleRate:
lastObject
roundTime:toAllowableTime:
filteredClassLabelsFromModelDescription:
createSoundClassifierVersion1
initWithMLModel:error:
windowDurationConstraint
isEqualToClassifySoundRequest:
valueWithCMTime:
decodeCMTimeForKey:
decodeObjectForKey:
knownClassificationsForClassifierIdentifier:error:
initWithClassifierIdentifier:error:
setWindowDuration:
knownClassifications
_windowDurationConstraint
_knownClassifications
T@"NSString",&,V_classifierIdentifier
T{?=qiIq},V_windowDuration
T@"SNTimeDurationConstraint",R,V_windowDurationConstraint
T@"NSArray",R,C,V_knownClassifications
modelChannelCount:
initForReading:commonFormat:interleaved:error:
initWithFormat:
framePosition
readIntoBuffer:frameCount:error:
sendErrorToAllRequests:
fileFormat
analyzeAudioBuffer:atAudioFramePosition:
frameLength
advanceSamples:withHandler:
completeAnalysis
fullFileTimeRange
analyzeInRange:
analyze
detailedDescription
initWithURL:error:
analyzeWithCompletionHandler:
cancelAnalysis
_audioFile
_streamAnalyzer
_wasCancelled
initWithRequestType:
decisionDelay
requestType
isEqualToDetectSpeechUtteranceRequest:
_requestType
Tq,R,V_requestType
softVAD
hardVAD
TB,R,N
clientResultsFromProcessorResults:
clientSampleTimeFromSampleTime:fromBox:
clientSampleRate
dictionaryWithCapacity:
timeConversionDictionary
T@"NSDictionary",R
addEntriesFromDictionary:
valueForKey:
convertTime:fromBox:usingConverter:
setValue:forKey:
convertTimeRange:fromBox:usingConverter:
initWithAnalyzer:completionHandler:resultsHandler:timeConverter:
handleDSPGraphPostRenderCallbackFromBox:numFrames:
handleAnalyzerCompletion
handleAnalyzerError:
requestDidReturnError:
primeAnalyzerGraph
requestState
setRequestState:
_timeConverter
_resultsHandler
_completionHandler
_requestState
T@,R,N
Tq,N,V_requestState
_configuration
initWithBox:fromGraph:
startRecordingPort:toFile:
stopRecordingPort:
startInjectingPort:toFile:shouldLoop:
stopInjectingPort:
numInputs
numOutputs
getParameterList:numParameterIDs:inScope:
getParameterInfo:forID:inScope:
getParameter:forID:scope:element:
hasParameter:scope:element:
setParameter:forID:scope:element:bufferOffset:
_box
T^v,R,N,V_box
Tq,R,N
T@"NSString",R,N
idsDeviceIdentifier
setLocalDeviceUpdatedHandler:
setDeviceLostHandler:
doubleValue
setDeviceFoundHandler:
setDeviceChangedHandler:
isOptional
sizeRangeForDimension
numberWithUnsignedInteger:
rangeValue
numberWithUnsignedLong:
valueWithRange:
enumeratedShapes
dataType
ensureMultiArrayConstraint:hasDataType:error:
ensureMultiArrayShapeConstraint:hasDimensionSizeRanges:error:
ensureMultiArrayShapeConstraint:hasShapeOptions:error:
ensureMultiArrayIsFreelyShapedByShapeConstraint:error:
ensureFeatureWithDescription:isOptional:error:
ensureMultiArrayIsRequiredByFeatureDescription:error:
ensureMultiArrayConstraint:hasDataType:andDimensionSizeRanges:error:
ensureMultiArrayConstraint:hasDataType:andShapeOptions:error:
ensureMultiArrayIsFreelyShapedWithConstraint:hasDataType:error:
ensureFeatureWithDescription:isOptional:isMultiArrayWithDataType:dimensionSizeRanges:error:
ensureFeatureWithDescription:isOptional:isMultiArrayWithDataType:shapeOptions:error:
ensureFeatureWithDescription:isOptional:isFreelyShapedMultiArrayWithDataType:error:
ensureModelDescription:hasInputFeatureNames:hasOutputFeatureNames:error:
valueForEntitlement:error:
boolValue
isCurrentProcessEntitledToHostDaemon
createFileServer
currentRunLoop
isInternalBuild
initWithRootDirectory:
_fileServer
setInterface:forSelector:argumentIndex:ofReply:
defaultMaxCacheSize
initWithWrappedModel:maxCacheSize:
initWithWrappedModel:
withWrappedModel:maxCacheSize:
withWrappedModel:
initWithModelDescription:parameterDictionary:error:
predictionsFromBatch:options:error:
wrappedModel
_maxCacheSize
_cacheStorage
_cacheAccessRecency
_wrappedModel
T@"<SNMLModel>",R,V_wrappedModel
strongToWeakObjectsMapTable
sharedLockedModelWithKey:orCreateNewModelWithWithFunction:
_vendedModels
initWithConfiguration:error:
createModelOfClass:modelConfiguration:
sharedLockedModelOfClass:memoized:modelConfiguration:
soundPrintAFeatureExtractorModelClass
sharedLockedModelOfClass:modelConfiguration:
soundClassifierVersion1Modelclass
createModelOfClass:
sharedLockedModelOfClass:
splitDetectorInfoForDetectorIdentifier:
createSoundPrintAFeatureExtractorWithModelConfiguration:
sharedLockedSoundPrintAFeatureExtractorWithModelConfiguration:
createSharedLockedSoundClassifierVersion1
defaultDetectorIdentifierForSoundIdentifier:
request
setRequest:
resultsHandler
setResultsHandler:
completionHandler
setCompletionHandler:
analyzerHost
setAnalyzerHost:
sharedProcessor
setSharedProcessor:
configured
setConfigured:
configurationError
setConfigurationError:
_configured
_request
_analyzerHost
_sharedProcessor
_configurationError
T@"<SNAnalyzerCreating>",&,N,V_request
T@?,C,N,V_resultsHandler
T@?,C,N,V_completionHandler
T@"SNAnalyzerHost",&,N,V_analyzerHost
T@"<SNProcessing>",&,N,V_sharedProcessor
TB,N,V_configured
T@"NSError",&,N,V_configurationError
isFormatPCM:
updateProcessingTreeFormat:
stopRecording
dealloc
removeObject:
addRequest:completionHandler:resultsHandler:error:
addResult:
indexOfObjectIdenticalTo:
completionHandlerWithClientCompletionHandler:forRequest:
resultsHandlerWithClientResultsHandler:forRequest:
createAnalyzerInfoForRequest:completionHandler:resultsHandler:error:
configureAnalyzer:withFormat:
arrayByAddingObject:
arrayWithArray:
removeObjectAtIndex:
removeAnalyzerInfoForRequest:
sharedProcessorWithConfiguration:
updateTreeProcessingContexts
handleAnalysisPrimingError
format
configureAnalysisTreeWithFormat:
splitBuffer:intoBuffersWithFrameCount:
handleAnalyzeAudioBufferError
date
setDateFormat:
stringFromDate:
stringByAppendingPathExtension:
initWithDirectoryPath:fileNameWithoutExtension:dateString:soundIdentifier:
initWithDSPGraph:
stopRecordingBoxesInGraph:
directoryPath
fileNameWithoutExtension
audioFileFrameCount:
detectionResults
detectionCountInResults:
defaultManager
removeItemAtPath:error:
writeResultsToFileWithAudioFrameCount:error:
analyzerInfoForRequest:
analyzeAudioBufferList:withAudioFrameCount:atAudioFramePosition:
writeDSPGraphDotFilesToDirectory:
startRecordingToDirectory:requestDescription:error:
_processorCache
_processingContexts
_processingTree
_currentFormat
_analyzerInfos
_resultsLogger
_shouldRebuildProcessingTree
startRecordingFirstBoxInGraph:toDirectory:withFileName:error:
initWithInputSensitivity:
isEqualToMeasureLKFSRequest:
inputSensitivity
_inputSensitivity
Tf,R,N,V_inputSensitivity
setQueryPath:
setServiceType:
setDestinationID:
queryPath
performQuery:
initWithServerInfo:queryPath:
_queryPath
T@"NSString",&,N,V_queryPath
dataPointer
shape
unsignedIntegerValue
featureNames
multiArrayValue
mutableAudioBufferList
setFrameLength:
frameCapacity
metadata
componentsSeparatedByString:
mutableCopy
removeObjectsForKeys:
classLabels
removeObjectsInArray:
integerValue
vggishFrontEndProcessingInputShape
vggishFrontEndProcessingOutputShape
constraintWithShape:dataType:
featureDescriptionWithName:type:optional:constraints:
initWithInputDescriptions:outputDescriptions:predictedFeatureName:predictedProbabilitiesName:metadata:
modelBlockSize:channelCount:
numberOfElements:
parseFeedbackConnectionsString:
destinationFeatureName
containsObject:
sourceFeatureName
userSuppliedFeatureNames:direction:
subtractSet:from:
minusSet:
allObjects
whitespaceAndNewlineCharacterSet
componentsSeparatedByCharactersInSet:
componentsJoinedByString:
initWithSourceFeatureName:destinationFeatureName:
processInfo
processName
stringByReplacingOccurrencesOfString:withString:
stringByAppendingString:
_deleteWAVAndTextFilesInDirectory:createdBeforeDate:withRemainingDirectoryByteSizeLessThan:
contentsOfDirectoryAtPath:error:
predicateWithFormat:
filterUsingPredicate:
fileCreationDate:
compare:
sortUsingComparator:
diskSpaceRemainingBytesContainingDirectory:
unsignedLongLongValue
fileSizeBytes:
subarrayWithRange:
stringByDeletingPathExtension
attributesOfItemAtPath:error:
attributesOfFileSystemForPath:error:
fileURLWithPath:
initForReading:error:
valueForEntitlement:fromTask:error:
convertScaleForTimeRange:toValue:startRoundingMethod:durationRoundingMethod:
standardizeTime:negativeShouldResideInTimescale:
standardizeTimeRange:directionShouldBePositive:
standardizeTimeRange:negativeShouldResideInTimescale:
standardizeTimeRange:directionShouldBePositive:negativeShouldResideInTimescale:
makeInvalidTimeRange
clipTimeRange:toBounds:handler:
getTimeRangeEncompassingEntireAudioFile:
initWithShape:dataType:error:
floatValue
processFrameCount:bufferFactory:populator:handler:completionHandler:
channelLayout
initWithStreamDescription:channelLayout:
initSecondaryReader:format:error:
readFramesFromAudioFile:frameCount:maxFramesPerBuffer:recycleBuffers:handler:error:
readFramesFromAudioFile:frameCount:atSampleRate:maxFramesPerBuffer:recycleBuffers:handler:error:
readPreciseTimeDurationFromAudioFile:timeDuration:maxFramesPerBuffer:recycleBuffers:handler:error:
convertScaleForTimeRange:toValue:preferShrinkingWhenRounding:
readPreciseTimeRangeFromAudioFile:timeRange:maxFramesPerBuffer:recycleBuffers:prefixBufferPopulator:suffixBufferPopulator:handler:error:
flushAudioBuffer:channelIndex:intoSink:error:
commonFormat
numberWithLongLong:
flushBytesFromPreciseTimeRangeInAudioFile:timeRange:maxFramesPerBuffer:recycleBuffers:prefixBufferPopulator:suffixBufferPopulator:intoSink:error:
flushBytesFromStreamSource:toBuffer:ofSizeInBytes:error:
loadContentsOfURL:configuration:completionHandler:
silenceUnfilledFramesInBuffer:
copyAudioBufferList:to:frameCount:bytesPerFrame:
vggishFeatureEmbeddingInputShape
vggishFeatureEmbeddingOutputShape
vggishFrontEndProcessingModelDescription
multiArrayConstraintLastDimensionIsFlexible:
lastDimensionSizeRange:
anyOutputMultiArrayShape:
userSuppliedOutputFeatureNames:
isRunningInDaemon
loggingPrefixForRequest:
deleteWAVAndTextFilesInDirectory:createdBeforeDate:withRemainingDirectoryByteSizeLessThan:
checkTimeRange:isIdenticalToOther:
clipTimeRange:toBounds:
addOffset:toTimeRange:
getTimeRangeEncompassingEntireAudioFileAtURL:error:
toMLMultiArrayConvertFromFloatScalar:error:
toFloatScalarConvertFromMLMultiArray:error:
readApproximateTimeDurationFromAudioFile:timeDuration:roundingMethod:maxFramesPerBuffer:recycleBuffers:handler:error:
readApproximateTimeRangeFromAudioFile:timeRange:preferShrinkingWhenRounding:maxFramesPerBuffer:recycleBuffers:prefixBufferPopulator:suffixBufferPopulator:handler:error:
zeroBufferPopulator
createMultiArrayContainingPreciseTimeRangeOfAudioFile:timeRange:maxFramesPerBuffer:recycleBuffers:prefixBufferPopulator:suffixBufferPopulator:numDimensions:error:
loadModelAtURL:withTimeout:error:
automaticallyNotifiesObserversForKey:
willChangeValueForKey:
didChangeValueForKey:
results
clearResults
errors
clearErrors
clearCompleteCount
completeCount
_results
_errors
_completeCount
T@"NSArray",R,N
Tq,R,N,V_completeCount
initWithCompletionHandler:resultsHandler:
setIsCancelled:
cancel
isCancelled
_isCancelled
TB,V_isCancelled
_sourceFeatureName
_destinationFeatureName
T@"NSString",R,V_sourceFeatureName
T@"NSString",R,V_destinationFeatureName
initWithStreamDescription:
setVariableSliceDuration:forSampleRate:
sliceDurationInSamples
initialized
configure
unconfigure
initialize
uninitialize
reset
getParameter:forID:
hasParameter:
setParameter:forID:
getPropertySize:isWritable:forID:
getProperty:withSize:forID:
setProperty:withSize:forID:
boxWithName:
boxes
numberOfInputs
numberOfOutputs
writeDotFileToPath:
T{shared_ptr<DSPGraph::Graph>=^{Graph}^{__shared_weak_count}},R,N,V_graph
T@"NSString",C,N
T@"NSSet",R,N
setObject:atIndexedSubscript:
shapeFromMultiArrayConstraint:lastDimensionCountIfFlexible:
featureValueWithMultiArray:
initWithFeatureDescription:allInputFeatureNames:elementCountPerChannel:channelCount:
setFeatureValue:forFeatureName:
input
setInput:
_featureDescription
_featureCache
_allInputFeatureNames
_input
T@"MLMultiArray",&,N,V_input
feedbackConnections
setFeedbackConnections:
inputProvider
setInputProvider:
setOutputProvider:
_inputProvider
_outputProvider
T@"<SNMLModel>",&,N,V_model
T@"NSArray",&,N,V_feedbackConnections
T@"DSPGMLInputProvider",&,N,V_inputProvider
T@"<MLFeatureProvider>",&,N,V_outputProvider
modelWithContentsOfURL:error:
filename
setFilename:
fileSize
setFileSize:
itemURL
setItemURL:
initWithFileItem:
_filename
_fileSize
_itemURL
T@"NSString",&,N,V_filename
Tq,N,V_fileSize
T@"NSURL",&,N,V_itemURL
initWithConfidence:timeRange:
Td,R,N,V_confidence
T{?={?=qiIq}{?=qiIq}},R,N,V_timeRange
minDurationBlocks
confidenceThreshold
arrayWithCapacity:
initWithCommand:
processNewTimestep:timeRange:
history
_maxHistoryLength
_confidenceThreshold
_streak
_history
T@"NSString",R,N,V_name
T@"NSMutableArray",R,N,V_history
addObjectsFromArray:
initWithCommands:
processNewResults:timeRange:
commandFilters
_commandFilters
T@"NSArray",R,N,V_commandFilters
setServerFilePaths:
setLocalDestinationPath:
deregisterRequestID:
registerRequestID:options:handler:
getIdentitiesWithCompletion:
edPKData
serverFilePaths
flags
setFlags:
prepareTemplateAndReturnError:
localDestinationPath
fileURLWithPath:isDirectory:
setTemporaryDirectoryURL:
setReceivedItemHandler:
setPeerPublicKey:
setTargetID:
activate
initWithServerInfo:serverBasePath:serverFilePaths:localDestinationPath:
_serverFilePaths
_localDestinationPath
T@"NSArray",&,N,V_serverFilePaths
T@"NSString",&,N,V_localDestinationPath
initWithFirstPassRequest:secondPassRequest:historicalDataAmount:
firstPassRequest
secondPassRequest
historicalDataAmount
_firstPassRequest
_secondPassRequest
_historicalDataAmount
T@"<SNRequest>",R,V_firstPassRequest
T@"<SNRequest>",R,V_secondPassRequest
Td,R,V_historicalDataAmount
floatChannelData
initWithAudioTimeStamp:sampleRate:
initWithBufferHandler:queue:recordFormat:
handleAudioBufferCallbackForQueue:buffer:startTime:numberPacketDescriptions:packetDescriptions:
_bufferHandlerQueue
_bufferHandler
_transaction
_recordFormat
_stop
opaqueSessionID
initWithFormat:audioQueueConfiguration:
startHandlingBuffersOnQueue:audioSession:handler:
_audioQueueConfiguration
_running
_audioQueue
_aqCallbackScheduler
anyObject
initWithDictionary:error:
isAllowedShape:error:
preProcessCallback
initWithModelDescription:expectedInputShape:expectedOutputShape:graph:error:
setPreProcessCallback:
_inputConstraint
_outputConstraint
_scratchFloatSpace
_modelOutput
_preProcessCallback
T@?,C,N,V_preProcessCallback
removeRequestAsync:
_addRequest:completionHandler:resultsHandler:error:
_addTwoPassRequest:completionHandler:resultsHandler:error:
_addSinglePassRequest:completionHandler:resultsHandler:error:
handleBeginSecondPassForRequest:secondPassController:completionHandler:resultsHandler:
setBeginSecondPassHandler:
handleEndSecondPassForRequest:
setEndSecondPassHandler:
firstPassDidProduceResult:
dateByAddingTimeInterval:
valueWithNonretainedObject:
shouldRecordSecondPass
secondPassRecordingPath
deleteWAVAndTextFilesCreatedBeforeLastWeekInDirectory:
secondPassDidProduceResult:
_removeTwoPassRequest:
_removeSinglePassRequest:
_analyzeAudioBuffer:atAudioFramePosition:
string
appendString:
_analyzerQueue
_firstPassAnalyzer
_secondPassAnalyzers
_ringBuffer
_ringBufferWriteBufferList
createUltronResultsDictionaryFromDetectionResults:
createUltronFinalDictionaryWithDetectionResults:dateString:fileNameWithoutExtension:soundIdenfifier:frameCount:
writeDictionaryAsJSON:fileNameWithoutExtension:directoryPath:error:
dataWithJSONObject:options:error:
createDirectoryAtPath:withIntermediateDirectories:attributes:error:
writeToFile:options:error:
_dateString
_wroteResults
_startingTime
_detectionResults
_directoryPath
_fileNameWithoutExtension
T@"NSString",R,V_directoryPath
T@"NSString",R,V_fileNameWithoutExtension
T@"NSArray",R,V_detectionResults
_minDurationBlocks
Tq,R,N,V_minDurationBlocks
Td,R,N,V_confidenceThreshold
initWithModel:request:
isEqualToMeasureDetectVoiceTriggerRequest:
initWithModel:dictionary:error:
hopSizeSamples
setHopSizeSamples:
blocksBetweenTriggers
setBlocksBetweenTriggers:
commands
setCommands:
_hopSizeSamples
_blocksBetweenTriggers
_commands
Td,R,N,V_sampleRate
Tq,N,V_hopSizeSamples
Tq,N,V_blocksBetweenTriggers
T@"NSArray",C,N,V_commands
_modelOutputFilter
_overlapFilter
setLink:
link
setProgressHandler:
rootDirectory
addItem:
finish
server
createDefaultServer
setServer:
setRootDirectory:
_server
_link
_rootDirectory
T@"CUFileServer",&,N,V_server
T@"RPCompanionLinkClient",&,N,V_link
T@"NSString",&,N,V_rootDirectory
setRootDirectoryURL:
pathExtension
boxName
setBoxName:
busIndex
setBusIndex:
_boxName
_busIndex
T@"NSString",&,V_boxName
Tq,V_busIndex
T@"NSString",&,V_fileName
startRecordingWithBoxRecordingInfos:inGraph:toDirectory:error:
startRecordingBoxes:inGraph:toDirectory:error:
startInjectingBoxes:inGraph:error:
stopInjectingBoxesInGraph:
initWithSampleRate:blockSize:computationalDutyCycle:graphIsDeadEnded:shouldThrowException:
computationalDutyCycle
setComputationalDutyCycle:
graphIsDeadEnded
setGraphIsDeadEnded:
shouldThrowException
setShouldThrowException:
isEqualToNullRequest:
_graphIsDeadEnded
_shouldThrowException
_computationalDutyCycle
Td,N,V_computationalDutyCycle
TB,N,V_graphIsDeadEnded
TB,N,V_shouldThrowException
strides
initWithCommonFormat:sampleRate:channels:interleaved:
defaultCenter
handleAVAudioSessionInterruption:
addObserver:selector:name:object:
handleAVAudioSessionRouteChange:
handleAVAudioSessionMediaServicesLost:
handleAVAudioSessionMediaServicesReset:
_addRequest:withObserver:error:
indexOfObject:
startAudio
stopAudio
initAuxiliarySession
category
mode
options
setCategory:mode:options:error:
setActive:error:
sampleTime
handleAudioStreamInterrupted
_dispatchQueue
_analysisQueue
_recordingQueue
_recordingState
_clientStartedAnalysis
_audioSession
makeHandlerForUInt32ParameterWithBlock:
makeHandlerForFloatParameterWithBlock:
makeHandlerForInt32ParameterWithBlock:
makeHandlerForStringParameterWithChoices:block:
defaultLogMelExtractionParameters
overrideLogMelExtractionParameters:withContentsOfParameterDictionary:error:
resetLogMelExtractionParameters:overrideWithParameterDictionary:error:
validateModelDescription:logMelExtractionParameters:withHandler:error:
initWithDataPointer:shape:dataType:strides:deallocator:error:
_inputFeatureName
_outputFeatureName
_logMelExtractionParameters
stringMapFromStringDictionary:
stringVectorFromStringArray:
_interpreter
initWithIdentifier:confidence:
classificationsFromClassificationDictionary:
enumerateKeysAndObjectsUsingBlock:
_init
classificationDictionary
setClassificationDictionary:
isEqualToClassificationResult:
classificationForIdentifier:
classifications
_cachedClassifications
_classificationDictionary
T@"NSDictionary",C,N,V_classificationDictionary
T@"NSString",C,N,V_classifierIdentifier
T@"NSArray",R,C
isEqualToClassification:
T@"NSString",R,C,V_identifier
Td,R,V_confidence
modelURLForCurrentProduct
isEqualToSignalThresholdResult:
isEqualToAudioConfiguration:
setCategory:
setMode:
setOptions:
_category
_mode
_options
T@"NSString",C,N,V_category
T@"NSString",C,N,V_mode
TQ,N,V_options
hasPrefix:
generateFeatureMappingsFromOuterFeatureNames:toInnerFeatureNames:matcher:
generateFeatureMappingsFromOuterFeatureNames:toInnerFeatureNames:
generateInputFeatureMappingsFromOuterDescription:toInnerDescription:
generateOutputFeatureMappingsFromOuterDescription:toInnerDescription:
innerInputFeatureProviderFromOuter:outerToInnerInputFeatureNameMappings:error:
outerOutputFeatureProviderFromInner:outerToInnerOutputFeatureNameMappings:error:
initWithModel:modelDescription:
_outerToInnerInputFeatureNameMappings
_outerToInnerOutputFeatureNameMappings
removeLastObject
validateModelDescription:underlyingModelDescription:error:
_outputShape
beginSecondPassHandler
endSecondPassHandler
T@?,C
initWithSecondPassBeginThreshold:secondPassEndThreshold:secondPassHangoverPeriod:firstPassResultToComparableFunction:secondPassResultToComparableFunction:
_secondPassBeginThreshold
_secondPassEndThreshold
_secondPassHangoverPeriod
_secondPassTriggerTime
_firstResultBelowEndThresholdStartTime
_secondPassIsActive
_firstPassResultToComparableFunction
_secondPassResultToComparableFunction
_beginSecondPassHandler
_endSecondPassHandler
T@?,C,V_beginSecondPassHandler
T@?,C,V_endSecondPassHandler
audioProcessorWithConfiguration:
createAudioProcessorWithConfiguration:
_activeProcessorsCache
isEqualToNullResult:
peakTime
peakValue
channelIndex
_peakValue
_channelIndex
_peakTime
Td,N,V_peakValue
T{?=qiIq},N,V_peakTime
Tq,N,V_channelIndex
T{?={?=qiIq}{?=qiIq}},N,VtimeRange
remoteObjectProxyWithErrorHandler:
_remoteObservers
initWithAudioSamples:
audioSamples
setAudioSamples:
_audioSamples
T@"MLMultiArray",&,N,V_audioSamples
initWith_637:
_637
set_637:
__637
T@"MLMultiArray",&,N,V__637
pathForResource:ofType:
URLOfModelInThisBundle
initWithContentsOfURL:error:
initWithContentsOfURL:configuration:error:
initWithMLModel:
modelWithContentsOfURL:configuration:error:
predictionFromFeatures:error:
initWithFeatureProviderArray:
featuresAtIndex:
loadWithConfiguration:completionHandler:
predictionFromAudioSamples:error:
predictionsFromInputs:options:error:
T@"MLModel",R,N,V_model
featureValueWithDictionary:error:
featureValueWithString:
initWith_646:classLabel:
_646
set_646:
classLabel
setClassLabel:
__646
_classLabel
T@"NSDictionary",&,N,V__646
T@"NSString",&,N,V_classLabel
stringValue
B16@0:8
@24@0:8^{_NSZone=}16
v24@0:8@16
@24@0:8@16
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
B24@0:8@16
#16@0:8
@16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
{?={?=qiIq}{?=qiIq}}16@0:8
v64@0:8{?={?=qiIq}{?=qiIq}}16
f16@0:8
v20@0:8f16
{?="start"{?="value"q"timescale"i"flags"I"epoch"q}"duration"{?="value"q"timescale"i"flags"I"epoch"q}}
q16@0:8
v16@0:8
@"MLModel"
@"NSString"
@40@0:8@16@24d32
@40@0:8@"NSData"16@"NSDictionary"24d32
@"NSData"16@0:8
d16@0:8
v24@0:8d16
@32@0:8@16Q24
v24@0:8Q16
@"SNFileServerInfo"
v40@0:8@16@24@?32
v32@0:8@16@?24
v40@0:8@"<SNRequest>"16@"<SNResult>"24@?<v@?>32
v40@0:8@"<SNRequest>"16@"NSError"24@?<v@?>32
v32@0:8@"<SNRequest>"16@?<v@?>24
B40@0:8@16@24^@32
v24@0:8@"SNAudioConfiguration"16
B40@0:8@"<SNRequest>"16@"<SNResultsObserving>"24^@32
v24@0:8@"<SNRequest>"16
@"<SNSystemAudioAnalyzerXPCProtocol><NSXPCProxyCreating>"
I16@0:8
v20@0:8I16
@?16@0:8
v24@0:8@?16
@20@0:8I16
v24@0:8^{OpaqueAudioQueue=}16
v28@0:8I16^{OpaqueAudioQueue=}20
@32@0:8@16@24
@"NSError"
@40@0:8@16@24@32
@?40@0:8@16@?24@?32
@?<v@?>40@0:8@"NSObject<OS_dispatch_queue>"16@?<v@?@"NSError">24@?<v@?@"<SNResult>">32
v40@0:8@16@?24@?32
v32@0:8@16@24
@"NSMutableArray"
@"NSMutableDictionary"
@"NSObject<OS_dispatch_queue>"
@64@0:8{?={?=qiIq}{?=qiIq}}16
@"NSArray"
@24@0:8^@16
@"<SNAnalyzing>"24@0:8^@16
@"SNDetectSignalThresholdRequestImpl"
B32@0:8@16^@24
{shared_ptr<DSPGraph::Graph>=^{Graph}^{__shared_weak_count}}16@0:8
B32@0:8@"SNSystemConfiguration"16^@24
@28@0:8^v16i24
^v16@0:8
@"NSArray"28@0:8^v16i24
@36@0:8d16I24d28
{shared_ptr<DSPGraph::Graph>="__ptr_"^{Graph}"__cntrl_"^{__shared_weak_count}}
@40@0:8q16@24@32
v48@0:8^@16q24@32@40
@"AVAudioFile"
@32@0:8@16d24
@"SNSystemConfiguration"
@"<SNSystemAudioAnalyzerProtocol>"16@0:8
B32@0:8@16@24
B32@0:8@"NSXPCListener"16@"NSXPCConnection"24
@"NSXPCListener"
@"SNSystemServiceResourceCoordinator"
@40@0:8@16@?24@32
@32@0:8@?16@24
@"NSXPCConnection"
I20@0:8I16
@"NSUserDefaults"
@40@0:8@16@24^@32
@"<MLFeatureProvider>"40@0:8@"<MLFeatureProvider>"16@"MLPredictionOptions"24^@32
@"MLModelDescription"16@0:8
@"<MLCustomModel>"
@"MLModelDescription"
@"<SNMLModel>"
{mutex="__m_"{_opaque_pthread_mutex_t="__sig"q"__opaque"[56c]}}
v24@0:8@?<v@?@"<SNSystemAudioAnalyzerXPCProtocol>">16
@"<SNResourceCoordinatorProtocol>"
v20@0:8B16
@32@0:8#16@24
@"<SNSecondPassController>"16@0:8
@"SNTwoPassConfiguration"16@0:8
@32@0:8@16@?24
@"SNTwoPassConfiguration"
@"NSDictionary"
@"<SNProcessing>"24@0:8^@16
v32@0:8@"<SNRequest>"16@"<SNResult>"24
v32@0:8@"<SNRequest>"16@"NSError"24
@"<SNResultsObserving>"
@"<SNSystemAudioAnalyzerProtocol>"
@"SNAudioConfiguration"
@48@0:8@16@24@32@40
v48@0:8@16@24Q32Q40
v48@0:8@"EARSyncPSRAudioProcessor"16@"NSData"24Q32Q40
@28@0:8d16I24
@40@0:8{?=qiIq}16
{?="value"q"timescale"i"flags"I"epoch"q}
@"SNVoiceTriggerResult"
v36@0:8@16^v24I32
@72@0:8@16d24{?=qiIq}32@56^@64
{?=qiIq}16@0:8
@32@0:8@16^@24
v40@0:8{?=qiIq}16
@"SNTimeDurationConstraint"
I28@0:8I16@?20
@"SNAudioStreamAnalyzer"
@24@0:8q16
@"NSDictionary"16@0:8
{?=qiIq}56@0:8{?=qiIq}16^v40@48
{?={?=qiIq}{?=qiIq}}80@0:8{?={?=qiIq}{?=qiIq}}16^v64@72
@48@0:8@16@?24@?32@40
v28@0:8^v16i24
v24@0:8q16
@"<SNAnalyzing>"
@"<SNTimeConverting>"
@"SNSoundPrintFeatureExtractorConfiguration"
@40@0:8^v16{shared_ptr<DSPGraph::Graph>=^{Graph}^{__shared_weak_count}}24
B32@0:8q16@24
B24@0:8q16
B36@0:8q16@24B32
B36@0:8^I16^q24I32
B32@0:8^{AudioUnitParameterInfo=[52c]^{__CFString}I^{__CFString}IfffI}16I24I28
B36@0:8^f16I24I28I32
B28@0:8I16I20I24
B40@0:8f16I20I24I28q32
B36@0:8@16B24^@28
B40@0:8@16q24^@32
B48@0:8@16q24@32^@40
B52@0:8@16B24q28@36^@44
B44@0:8@16B24q28^@36
B48@0:8@16@24@32^@40
@"SNFileServer"
@40@0:8@"MLModelDescription"16@"NSDictionary"24^@32
@"<MLBatchProvider>"40@0:8@"<MLBatchProvider>"16@"MLPredictionOptions"24^@32
{unordered_map<SoundAnalysis::MD5Hash, id<MLFeatureProvider>, std::hash<SoundAnalysis::MD5Hash>, std::equal_to<SoundAnalysis::MD5Hash>, std::allocator<std::pair<const SoundAnalysis::MD5Hash, id<MLFeatureProvider>>>>="__table_"{__hash_table<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, std::__unordered_map_hasher<SoundAnalysis::MD5Hash, std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, std::hash<SoundAnalysis::MD5Hash>, std::equal_to<SoundAnalysis::MD5Hash>, true>, std::__unordered_map_equal<SoundAnalysis::MD5Hash, std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, std::equal_to<SoundAnalysis::MD5Hash>, std::hash<SoundAnalysis::MD5Hash>, true>, std::allocator<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>>>="__bucket_list_"{unique_ptr<std::__hash_node_base<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *> *> *[], std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *> *> *>>>="__ptr_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *> *> **, std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *> *> *>>>="__value_"^^v"__value_"{__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *> *> *>>="__data_"{__compressed_pair<unsigned long, std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *> *> *>>="__value_"Q}}}}"__p1_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *> *>, std::allocator<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *>>>="__value_"{__hash_node_base<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *> *>="__next_"^v}}"__p2_"{__compressed_pair<unsigned long, std::__unordered_map_hasher<SoundAnalysis::MD5Hash, std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, std::hash<SoundAnalysis::MD5Hash>, std::equal_to<SoundAnalysis::MD5Hash>, true>>="__value_"Q}"__p3_"{__compressed_pair<float, std::__unordered_map_equal<SoundAnalysis::MD5Hash, std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, std::equal_to<SoundAnalysis::MD5Hash>, std::hash<SoundAnalysis::MD5Hash>, true>>="__value_"f}}}
{list<SoundAnalysis::MD5Hash, std::allocator<SoundAnalysis::MD5Hash>>="__end_"{__list_node_base<SoundAnalysis::MD5Hash, void *>="__prev_"^v"__next_"^v}"__size_alloc_"{__compressed_pair<unsigned long, std::allocator<std::__list_node<SoundAnalysis::MD5Hash, void *>>>="__value_"Q}}
@"NSMapTable"
@24@0:8#16
@36@0:8#16B24@28
@"<SNAnalyzerCreating>"
@"SNAnalyzerHost"
@"<SNProcessing>"
q32@0:8q16^v24
@48@0:8@16@?24@?32^@40
@?32@0:8@?16@24
B48@0:8@16@?24@?32^@40
v36@0:8^{AudioBufferList=I[1{AudioBuffer=II^v}]}16I24q28
v32@0:8@16q24
@"SNAudioProcessorCache"
{list<SoundAnalysis::ProcessingContext, std::allocator<SoundAnalysis::ProcessingContext>>="__end_"{__list_node_base<SoundAnalysis::ProcessingContext, void *>="__prev_"^v"__next_"^v}"__size_alloc_"{__compressed_pair<unsigned long, std::allocator<std::__list_node<SoundAnalysis::ProcessingContext, void *>>>="__value_"Q}}
{ProcessingTree="mGraph"{shared_ptr<DSPGraph::Graph>="__ptr_"^{Graph}"__cntrl_"^{__shared_weak_count}}"mProcessingContexts"{list<SoundAnalysis::ProcessingContext, std::allocator<SoundAnalysis::ProcessingContext>>="__end_"{__list_node_base<SoundAnalysis::ProcessingContext, void *>="__prev_"^v"__next_"^v}"__size_alloc_"{__compressed_pair<unsigned long, std::allocator<std::__list_node<SoundAnalysis::ProcessingContext, void *>>>="__value_"Q}}"mFormatMatchingNodes"{list<SoundAnalysis::FormatMatchingNode, std::allocator<SoundAnalysis::FormatMatchingNode>>="__end_"{__list_node_base<SoundAnalysis::FormatMatchingNode, void *>="__prev_"^v"__next_"^v}"__size_alloc_"{__compressed_pair<unsigned long, std::allocator<std::__list_node<SoundAnalysis::FormatMatchingNode, void *>>>="__value_"Q}}"mSharedProcessingNodes"{list<SoundAnalysis::SharedProcessingNode, std::allocator<SoundAnalysis::SharedProcessingNode>>="__end_"{__list_node_base<SoundAnalysis::SharedProcessingNode, void *>="__prev_"^v"__next_"^v}"__size_alloc_"{__compressed_pair<unsigned long, std::allocator<std::__list_node<SoundAnalysis::SharedProcessingNode, void *>>>="__value_"Q}}"mAnalyzerNodes"{list<SoundAnalysis::AnalyzerNode, std::allocator<SoundAnalysis::AnalyzerNode>>="__end_"{__list_node_base<SoundAnalysis::AnalyzerNode, void *>="__prev_"^v"__next_"^v}"__size_alloc_"{__compressed_pair<unsigned long, std::allocator<std::__list_node<SoundAnalysis::AnalyzerNode, void *>>>="__value_"Q}}"mRootNode"{RootNode="_vptr$ProcessingNode"^^?"mUpstreamNode"^{ProcessingNode}"mDownstreamNodes"{list<SoundAnalysis::ProcessingNode *, std::allocator<SoundAnalysis::ProcessingNode *>>="__end_"{__list_node_base<SoundAnalysis::ProcessingNode *, void *>="__prev_"^v"__next_"^v}"__size_alloc_"{__compressed_pair<unsigned long, std::allocator<std::__list_node<SoundAnalysis::ProcessingNode *, void *>>>="__value_"Q}}"mProcessingBox"^{Box}"mUpstreamFormat"{FormatAndBlockSize="mFormat"{AudioStreamBasicDescription="mSampleRate"d"mFormatID"I"mFormatFlags"I"mBytesPerPacket"I"mFramesPerPacket"I"mBytesPerFrame"I"mChannelsPerFrame"I"mBitsPerChannel"I"mReserved"I}"mBlockSize"I}"mDownstreamFormat"{FormatAndBlockSize="mFormat"{AudioStreamBasicDescription="mSampleRate"d"mFormatID"I"mFormatFlags"I"mBytesPerPacket"I"mFramesPerPacket"I"mBytesPerFrame"I"mChannelsPerFrame"I"mBitsPerChannel"I"mReserved"I}"mBlockSize"I}}"mMaxFramesPerSlice"I"mWillInitializeCallback"{function<void (std::shared_ptr<DSPGraph::Graph>, unsigned long)>="__f_"{__value_func<void (std::shared_ptr<DSPGraph::Graph>, unsigned long)>="__buf_"{type="__lx"[24C]}"__f_"^v}}"mCurrentInputSampleTime"q}
@"AVAudioFormat"
@"SNUltronResultsLogger"
@20@0:8f16
@28@0:8@16I24
v40@0:8^{AudioBufferList=I[1{AudioBuffer=II^v}]}16^{AudioBufferList=I[1{AudioBuffer=II^v}]}24I32I36
i24@0:8@16
{?=qiIq}48@0:8{?=qiIq}16@40
I28@0:8@16I24
I24@0:8@16
{_NSRange=QQ}24@0:8@16
@32@0:8@16q24
v40@0:8@16@24q32
q24@0:8@16
@40@0:8@16^{__SecTask=}24^@32
B112@0:8{?={?=qiIq}{?=qiIq}}16{?={?=qiIq}{?=qiIq}}64
{?={?=qiIq}{?=qiIq}}76@0:8{?={?=qiIq}{?=qiIq}}16i64I68I72
{?={?=qiIq}{?=qiIq}}72@0:8{?={?=qiIq}{?=qiIq}}16i64B68
{?={?=qiIq}{?=qiIq}}68@0:8{?={?=qiIq}{?=qiIq}}16B64
{?=qiIq}44@0:8{?=qiIq}16B40
{?={?=qiIq}{?=qiIq}}72@0:8{?={?=qiIq}{?=qiIq}}16B64B68
v120@0:8{?={?=qiIq}{?=qiIq}}16{?={?=qiIq}{?=qiIq}}64@?112
{?={?=qiIq}{?=qiIq}}112@0:8{?={?=qiIq}{?=qiIq}}16{?={?=qiIq}{?=qiIq}}64
{?={?=qiIq}{?=qiIq}}88@0:8{?=qiIq}16{?={?=qiIq}{?=qiIq}}40
{?={?=qiIq}{?=qiIq}}24@0:8@16
{?={?=qiIq}{?=qiIq}}32@0:8@16^@24
v52@0:8I16@?20@?28@?36@?44
I52@0:8@16I24I28B32@?36^@44
I60@0:8@16I24d28I36B40@?44^@52
{?=qiIq}72@0:8@16{?=qiIq}24I48B52@?56^@64
{?=qiIq}76@0:8@16{?=qiIq}24I48I52B56@?60^@68
B112@0:8@16{?={?=qiIq}{?=qiIq}}24I72B76@?80@?88@?96^@104
B116@0:8@16{?={?=qiIq}{?=qiIq}}24B72I76B80@?84@?92@?100^@108
B48@0:8@16Q24@?32^@40
B48@0:8@?16^v24Q32^@40
@112@0:8@16{?={?=qiIq}{?=qiIq}}24I72B76@?80@?88Q96^@104
@40@0:8@16d24^@32
@32@0:8@?16@?24
@"<SNResourceCoordinatorXPCProtocol><NSXPCProxyCreating>"
@32@0:8{shared_ptr<DSPGraph::Graph>=^{Graph}^{__shared_weak_count}}16
B32@0:8q16q24
B28@0:8^f16I24
B20@0:8I16
B24@0:8f16I20
B36@0:8^I16^B24I32
B36@0:8^v16^I24I32
B32@0:8r^v16I24I28
@28@0:8@16i24
@"MLFeatureValue"24@0:8@"NSString"16
@"NSSet"16@0:8
@40@0:8@16@24I32I36
@"MLFeatureDescription"
@"MLMultiArray"
@"DSPGMLInputProvider"
@"<MLFeatureProvider>"
@"NSURL"
@72@0:8d16{?={?=qiIq}{?=qiIq}}24
@72@0:8@16{?={?=qiIq}{?=qiIq}}24
@"<SNRequest>"
@40@0:8@?16@24@32
v52@0:8^{OpaqueAudioQueue=}16^{AudioQueueBuffer=I^vI^vI^{AudioStreamPacketDescription}I}24r^{AudioTimeStamp=dQdQ{SMPTETime=ssIIIssss}II}32I40r^{AudioStreamPacketDescription=qII}44
@"NSObject<OS_os_transaction>"
B40@0:8@16@24@?32
@"SNAudioQueueConfiguration"
^{OpaqueAudioQueue=}
@"SNAudioRecordingQueueScheduler"
@56@0:8@16@24@32{unique_ptr<DSPGraph::Graph, std::default_delete<DSPGraph::Graph>>={__compressed_pair<DSPGraph::Graph *, std::default_delete<DSPGraph::Graph>>=^{Graph}}}40^@48
@"MLMultiArrayConstraint"
{unique_ptr<DSPGraph::Graph, std::default_delete<DSPGraph::Graph>>="__ptr_"{__compressed_pair<DSPGraph::Graph *, std::default_delete<DSPGraph::Graph>>="__value_"^{Graph}}}
{vector<float, std::allocator<float>>="__begin_"^f"__end_"^f"__end_cap_"{__compressed_pair<float *, std::allocator<float>>="__value_"^f}}
@"SNDSPGraphCustomModel"
v48@0:8@16@24@?32@?40
@"SNForwardPassAudioStreamAnalyzer"
{unique_ptr<AT::RingBuffer, std::default_delete<AT::RingBuffer>>="__ptr_"{__compressed_pair<AT::RingBuffer *, std::default_delete<AT::RingBuffer>>="__value_"^{RingBuffer}}}
{unique_ptr<CABufferList, std::default_delete<CABufferList>>="__ptr_"{__compressed_pair<CABufferList *, std::default_delete<CABufferList>>="__value_"^{CABufferList}}}
@56@0:8@16@24@32@40q48
B32@0:8q16^@24
@"SNDetectVoiceTriggerRequest"
@"SNProcessVoiceTriggerModelOutput"
@"SNFilterVoiceTriggerResults"
@"CUFileServer"
@"RPCompanionLinkClient"
v40@0:8@"<SNRequest>"16@"<SNResultsObservingXPCProtocol>"24@?<v@?@"NSError">32
v24@0:8@?<v@?>16
v32@0:8@"SNAudioConfiguration"16@?<v@?>24
@"SNNullDetector"
@44@0:8d16I24d28B36B40
@"SNAudioRecordingQueue"
@"AVAudioSession"
@?32@0:8@16@?24
@?24@0:8@?16
{SNLogMelParameters=fIffiIIIIii}16@0:8
B40@0:8^{SNLogMelParameters=fIffiIIIIii}16@24^@32
B84@0:8@16{SNLogMelParameters=fIffiIIIIii}24@?68^@76
{SNLogMelParameters="sampleRate"f"numMelBands"I"minFrequency"f"maxFrequency"f"melType"i"hopLength"I"windowLength"I"windowOffset"I"fftLength"I"fftOffset"i"normalizationStrategy"i}
{unordered_map<std::string, std::string, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<const std::string, std::string>>>={__hash_table<std::__hash_value_type<std::string, std::string>, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, std::string>, std::hash<std::string>, std::equal_to<std::string>, true>, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, std::string>, std::equal_to<std::string>, std::hash<std::string>, true>, std::allocator<std::__hash_value_type<std::string, std::string>>>={unique_ptr<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *> *> *[], std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *> *> *>>>={__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *> *> **, std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *> *> *>>>=^^v{__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *> *> *>>={__compressed_pair<unsigned long, std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *> *> *>>=Q}}}}{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *> *>, std::allocator<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *>>>={__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *> *>=^v}}{__compressed_pair<unsigned long, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, std::string>, std::hash<std::string>, std::equal_to<std::string>, true>>=Q}{__compressed_pair<float, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, std::string>, std::equal_to<std::string>, std::hash<std::string>, true>>=f}}}24@0:8@16
{vector<std::string, std::allocator<std::string>>=^v^v{__compressed_pair<std::string *, std::allocator<std::string>>=^v}}24@0:8@16
{unique_ptr<DSPGraph::Interpreter, std::default_delete<DSPGraph::Interpreter>>="__ptr_"{__compressed_pair<DSPGraph::Interpreter *, std::default_delete<DSPGraph::Interpreter>>="__value_"^{Interpreter}}}
@40@0:8@16@24@?32
v24@0:8@"<SNResult>"16
@?<v@?>16@0:8
@56@0:8d16d24d32@?40@?48
@"<SNResultsObservingXPCProtocol><NSXPCProxyCreating>"
@24@0:8@?16
@24@0:8@?<v@?@"NSError">16
