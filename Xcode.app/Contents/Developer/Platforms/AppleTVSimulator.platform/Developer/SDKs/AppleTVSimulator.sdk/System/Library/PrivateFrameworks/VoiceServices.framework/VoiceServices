_bundleIdentifier
_compatibilityVersion
_contentVersion
_masteredVersion
supportsSecureCoding
TB,R
bundleIdentifier
T@"NSString",C,N,V_bundleIdentifier
compatibilityVersion
T@"NSNumber",C,N,V_compatibilityVersion
contentVersion
T@"NSNumber",C,N,V_contentVersion
masteredVersion
T@"NSString",C,N,V_masteredVersion
_utterance
_voiceAssetKey
_requestCreatedTimestamp
_speechBeginTimestamp
_speechEndTimestamp
_isWarmStart
utterance
T@"NSString",C,V_utterance
voiceAssetKey
T@"NSString",C,V_voiceAssetKey
requestCreatedTimestamp
TQ,V_requestCreatedTimestamp
speechBeginTimestamp
TQ,V_speechBeginTimestamp
speechEndTimestamp
TQ,V_speechEndTimestamp
isWarmStart
TB,V_isWarmStart
com.apple.MobileAsset.VoiceServicesVocalizerVoice
com.apple.MobileAsset.VoiceServices.CustomVoice
com.apple.MobileAsset.VoiceServices.GryphonVoice
com.apple.MobileAsset.VoiceServices.VoiceResources
Name
Languages
Language
Gender
Footprint
Type
voice_configs.plist
%@:%@:%@:%@:%@
voiceData
T@"VSVoiceAsset",&,V_voiceData
asset
T@"ASAsset",&,V_asset
builtInVoicePath
T@"NSString",&,V_builtInVoicePath
v8@?0
VSMobileAssetManagerCacheQueue
%@:%@:%@:%@
q24@?0@"VSVoiceResourceAsset"8@"VSVoiceResourceAsset"16
(%K BETWEEN %@)
(%@ == %K)
(%@ IN %K)
 && 
(%K == %@)
(%K != nil)
(%@ in %K)
v24@?0@"NSMutableArray"8q16
B24@?0@"ASAsset"8@"NSDictionary"16
B24@?0@"VSVoiceAssetSelection"8@"NSDictionary"16
q24@?0@"VSVoiceAssetSelection"8@"VSVoiceAssetSelection"16
q24@?0@"ASAsset"8@"ASAsset"16
Voice asset is not well defined, be more specific
v24@?0@"NSArray"8@"NSError"16
v20@?0d8f16
Operation
WaitingToDownload
DownloadingAsset
EstimatedTimeRemaining
OperationProgress
OperationCompleted
v24@?0@"NSDictionary"8@"NSError"16
v16@?0@"NSError"8
cacheConcurrentQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_cacheConcurrentQueue
voiceSelectionCache
T@"NSMutableDictionary",&,N,V_voiceSelectionCache
voiceResourceCache
T@"NSMutableDictionary",&,N,V_voiceResourceCache
_default
VSRecognition
<VSRecognition: %p model=%@>
recognition is already active
recognition reuse attempted
error converting disambiguation context to server
error converting audio input path to server
error converting model identifier
connection failure
recognition request denied
couldn't establish connection
recognition cancelled
connection lost
com.apple.voiceserviceslogging
default
tts_languages
plist
tts_language_fallbacks
en-US
com.apple.voiceservices
_VSServerConnection
com.apple.voiced
note.server.died
note.recog.prepare
note.recog.start
note.recog.results
note.recog.cancel
note.recog.error
key.recog.results
key.recog.errordesc
key.recog.errorcode
VSErrorDomain
vsplist
yyyy-MM-dd-HH-mm-ss'.vslog'
Library
Logs
CrashReporter
VoiceServicesRecognition
Latest.vslog
HH-mm-ss-
MaxLogCount
) <%@>
VSRecognitionResult
classes
phrases
modelid
handler
%@:%@
VSRecognitionDisambiguationContext
<VSRecognitionDisambiguationContext %p [%@]> 
 will disambiguate with sequence tag %@
 known class values:
constrained ambiguous classes:
  %@ = "%@" (%@)
  %@ = "%@"
  %@ =
     "%@" (%@)
     "%@"
seqtag
known
knownp
ambig
ambigp
com.apple.voiceservices.kwidxchanged
top-level
class-kws
__model-kws
com.apple.voiceservices.logging
VSLogLevel
VSOutputLevel
com.apple.voiceservices.language
%@Library/Managed Preferences/mobile/%@.plist
mobile
com.apple.AppSupport.loggingDefaultsChanged
lang-id
Auto Downloaded Assets
Last Asset Remote Query
Last Aggressive Download
Last Asset Paths
%@-%@
en-GB
zh-HK
zh-TW
zh-Hans
zh-CN
com.apple.language.changed
RecognitionResources/Express
TTSResources
language_fallbacks.plist
range
com.apple.voiceservices.assetInstalled
common
Library/VoiceServices/Assets
.migrated
voice_format_version.plist
NotForSiri
broker.hdr
broker.hdr.tmp
broker.hdr.asset
Tones
FormatVersion
%@%@
.tmp
hash
TQ,R
superclass
T#,R
description
T@"NSString",R,C
debugDescription
VSRecognitionSessionKeywordsDidChangeNotification
action already in progress
session is finished or invalid
session is invalid or not finished
session is already speaking
Default
Compact
Premium
PremiumHigh
Male
Female
recognition action not implemented
VSSpeechLangCharset
could not create recognition instance
recognition already attempted or in progress
vocalizer_resources
_voices
Voice resource, Languages: %@, ContentVersion: %@, MasteredVersion: %@
_languages
_searchPathURL
s5l8942x
s5l8947x
s5l8950x
s5l8955x
s5l8960x
t7001
s7002
t8002
voiceConfig
T@"NSDictionary",C,N,V_voiceConfig
languages
T@"NSArray",C,N,V_languages
resourceList
T@"NSDictionary",C,N,V_resourceList
searchPathURL
T@"NSURL",C,N,V_searchPathURL
model <%@> class <%@>
com.apple.yn
no URL to launch
match
replace
case-sensitive
eat-punct
com.apple.voiceservices.class
title
name
+[VSAssetUpdateListener sharedListener]
-[VSAssetUpdateListener startListening]
-[VSAssetUpdateListener stopListening]
-[VSAssetUpdateListener downloadAssetForLanguage:]
-[VSAssetUpdateListener downloadingAssetLanguage]
-[VSAssetUpdateListener assetStatusForLanguage:]
-[VSAssetUpdateListener assetDownloadStatus:progress:size:]
-[VSAssetUpdateListener removeAssetForLanguage:]
%@, text: '%@', language:%@, type:%@, gender:%@, footprint:%@, rate:%f, pitch:%f, volume:%f
textForAttributes
attributes
_text
_languageCode
_voiceName
_clientBundleIdentifier
_footprint
_useCustomVoice
_voiceType
_gender
_outputPath
_rate
_pitch
_volume
_maintainsInput
_audioSessionIDIsValid
_audioSessionID
_audioQueueFlags
_resourceListURL
_resourceSearchPathURL
text
T@"NSString",C,N,V_text
attributedText
T@"NSAttributedString",C,N,V_attributedText
languageCode
T@"NSString",C,N,V_languageCode
voiceName
T@"NSString",C,N,V_voiceName
footprint
Tq,N,V_footprint
useCustomVoice
TB,N,V_useCustomVoice
voiceType
Tq,N,V_voiceType
gender
Tq,N,V_gender
outputPath
T@"NSURL",C,N,V_outputPath
rate
Td,N,V_rate
pitch
Td,N,V_pitch
volume
Td,N,V_volume
maintainsInput
TB,N,V_maintainsInput
audioSessionIDIsValid
TB,N,V_audioSessionIDIsValid
audioSessionID
TI,N,V_audioSessionID
audioQueueFlags
TI,N,V_audioQueueFlags
clientBundleIdentifier
T@"NSString",C,N,V_clientBundleIdentifier
resourceListURL
T@"NSURL",C,N,V_resourceListURL
resourceSearchPathURL
T@"NSURL",C,N,V_resourceSearchPathURL
stopHandler
T@?,C,N,V_stopHandler
pauseHandler
T@?,C,N,V_pauseHandler
com.apple.voiceservices.keepalive
com.apple.voiceservices.tts
completion
T@?,C,N,V_completion
%@_%@.caf
v16@?0@"VSVoiceResourceAsset"8
VSSpeechSynthesizer
speech string is empty
not currently speaking
no active speech job
delegate
T@"<VSSpeechSynthesizerDelegate>",W,N,V_delegate
Tf,N,V_rate
Tf,N,V_pitch
Tf,N,V_volume
voice
T@"NSString",&,N,V_voice
audioType
Tq,N,V_audioType
active
TB,N,V_active
keepAudioSessionActive
TB,N,V_keepAudioSessionActive
Connection invalidated during request
v16@?0@"NSArray"8
v12@?0B8
v16@?0@"VSVoiceAsset"8
T@"<VSSpeechConnectionDelegate>",W,N
request
T@"VSSpeechRequest",R,N,V_request
T@"<VSSpeechConnectionDelegate>",W,N,V_delegate
T@"VSSpeechRequest",&,N,V_request
connection
T@"VSSpeechConnection",W,N,V_connection
compact
premium
premiumhigh
male
female
vocalizer
custom
gryphon
Type:%@, Name: %@, Languages: %@, Gender: %@, Footprint: %@, Installed: %@, ContentVersion: %@, MasteredVersion: %@, isBuiltIn: %@
_name
_type
_isInstalled
_isBuiltInVoice
MasteredVersion
ContentVersion
T@"NSString",C,N,V_name
type
Tq,N,V_type
isInstalled
TB,N,V_isInstalled
isBuiltInVoice
TB,N,V_isBuiltInVoice
v16@?0@8
_endpoint
endpoint
T@"NSXPCListenerEndpoint",&,N,V_endpoint
queue
T@"NSObject<OS_dispatch_queue>",&,N,V_queue
listener
T@"NSXPCListener",&,N,V_listener
T@?,C,N,V_handler
gryphront_duration
gryphront_f0
pred_mfcc_b_m_00
mfcc_b_00
pred_mfcc_b_m_01
mfcc_b_01
pred_mfcc_b_m_02
mfcc_b_02
pred_mfcc_b_m_03
mfcc_b_03
pred_mfcc_b_m_04
mfcc_b_04
pred_mfcc_b_m_05
mfcc_b_05
pred_mfcc_b_m_06
mfcc_b_06
pred_mfcc_b_m_07
mfcc_b_07
pred_mfcc_b_m_08
mfcc_b_08
pred_mfcc_b_m_09
mfcc_b_09
pred_mfcc_b_m_10
mfcc_b_10
pred_mfcc_b_m_11
mfcc_b_11
pred_mfcc_b_m_12
mfcc_b_12
pred_mfcc_e_m_00
mfcc_e_00
pred_mfcc_e_m_01
mfcc_e_01
pred_mfcc_e_m_02
mfcc_e_02
pred_mfcc_e_m_03
mfcc_e_03
pred_mfcc_e_m_04
mfcc_e_04
pred_mfcc_e_m_05
mfcc_e_05
pred_mfcc_e_m_06
mfcc_e_06
pred_mfcc_e_m_07
mfcc_e_07
pred_mfcc_e_m_08
mfcc_e_08
pred_mfcc_e_m_09
mfcc_e_09
pred_mfcc_e_m_10
mfcc_e_10
pred_mfcc_e_m_11
mfcc_e_11
pred_mfcc_e_m_12
mfcc_e_12
pred_f0_b_m
pred_f0_m_m
pred_f0_e_m
pred_dur_m
syll
word
senti
sentf
phrsi
phrsf
time
units
first_unit
num_units
word_unit_ranges
feature_labels
features
target_cost
total_cost
presel_cost
concat_cost
concat_f0_cost
unit_number
back_num
viterbi_labels
phone
WARNING: KEY NOT FOUND %s
slice
viterbi
audio_segments
cannot use push_back() with 
null
object
array
string
boolean
discarded
number
cannot use operator[] with 
true
false
%.*E
%.*e
-0.0
<discarded>
Bad pointer in TTSACDecoder, crashing 
Bad pointer in TTSACDecoder will crash on ARM32 as not 4 byte aligned 
Unable to open audio file, exiting 
Unable to stat audio file, exiting 
mmap of Valid audio file failed, exiting 
Number of directory entries is %d
Improper release of MMAP'd audio memory
Extract %7d [+%dms] - %7d [+%dms]
 -> Silence %zu samples
 -> Starting silence %zu samples
 -> Non-silence %zu samples
 -> Ending silence %zu samples
 -> Audio checksum %02x%02x%02x%02x
eyrie
Unterminated string_set in Eyrie file
index
audio_archive
f0_model
dur_model
phone_book
phone_spec
meansd
mdnd
mdnw
mdnn
mdno
mdni
mdnf
tarp
VoiceConfigFlexible: trying to set unknown path %s
VoiceConfigFlexible: trying to set unknown param %s
language
vowels
excluded_features
VoiceConfigFlexible::get_param_int: Unknown parameter: %s requested.
VoiceConfigFlexible::get_param_string: Unknown parameter: %s requested.
VoiceConfigFlexible::get_param_string_vec: Unknown parameter: %s requested.
Unable to open index file/database with file '
Unable to load index file/database with file '
Unable to madvise. error: %s
filename
context
mfcc_b_%02d
UNIT %d either negative or off end of db, selecting neigboring units to edge of db 
add_unit_range [%u:%u[
  exclude [%u:%u[
  adjusted [%u:%u[
Uniphone %s
Right diphone %s
Left diphone %s
Triphone %s
Quinphone %s
mean.
cannot open file
void boost::property_tree::json_parser::read_json(const std::string &, Ptree &, const std::locale &) [Ptree = boost::property_tree::basic_ptree<std::__1::basic_string<char>, std::__1::basic_string<char>, std::__1::less<std::__1::basic_string<char> > >]
/BuildRoot/Applications/Xcode.app/Contents/Developer/Platforms/AppleTVSimulator.platform/Developer/SDKs/AppleTVSimulator10.2.sdk/usr/local/include/boost/property_tree/json_parser.hpp
<unspecified file>
read error
void boost::property_tree::json_parser::read_json_internal(std::basic_istream<typename Ptree::key_type::value_type> &, Ptree &, const std::string &) [Ptree = boost::property_tree::basic_ptree<std::__1::basic_string<char>, std::__1::basic_string<char>, std::__1::less<std::__1::basic_string<char> > >]
/BuildRoot/Applications/Xcode.app/Contents/Developer/Platforms/AppleTVSimulator.platform/Developer/SDKs/AppleTVSimulator10.2.sdk/usr/local/include/boost/property_tree/detail/json_parser_read.hpp
syntax error
expected object or array
expected end of input
expected ',' or '}'
expected ',' or ']'
expected object name
expected ':'
expected value
invalid escape sequence
"\/bfnrt
BOOST_SPIRIT_CLASSIC_NS::parser_error
bitset test argument out of range
bitset set argument out of range
No such node
self_type &boost::property_tree::basic_ptree<std::__1::basic_string<char>, std::__1::basic_string<char>, std::__1::less<std::__1::basic_string<char> > >::get_child(const path_type &) [Key = std::__1::basic_string<char>, Data = std::__1::basic_string<char>, KeyCompare = std::__1::less<std::__1::basic_string<char> >]
/BuildRoot/Applications/Xcode.app/Contents/Developer/Platforms/AppleTVSimulator.platform/Developer/SDKs/AppleTVSimulator10.2.sdk/usr/local/include/boost/property_tree/detail/ptree_implementation.hpp
Unable to mmap audio file, exiting 
FeatureExtractorTarget::create %p
FeatureExtractorTarget::destroy: unknown target for %p
FeatureExtractorTarget::destroy %p
Unclaimed marker
emo=whisper
emo=normal
sil1
duration
stress
syllcount
wordcount
prom
PHON_POS_SYL
SYL_POS
senttype
Unknown phoneme %s (#%d feat_table); replacing with sil
numwords
numsyll
wposition
@ b O r d
aboard
@ b aU t
about
@ b V v
above
{ b s @ n t
absent
@ k O r d I ng
according
@ k O r d I ng l i
accordingly
@ k r A s
across
{ f t @r
after
@ g E n s t
against
@ h E d
ahead
O l b i I t
albeit
@ l O ng
along
@ l O ng s aI d
alongside
O l D o
although
@ m I d
amid
@ m I d s t
amidst
@ m V ng
among
@ m V ng s t
amongst
{ n d
@ n V D @r
another
{ n t aI
anti
E n i
E n i b A 4 i
anybody
E n i w V n
anyone
E n i T I ng
anything
@ r aU n d
around
@ s aI d
aside
@ s t r { 4 l=
astraddle
@ s t r aI d
astride
@ w e
away
b A r
b A r I ng
barring
b i k V z
because
b i f O r
before
b i h aI n d
behind
b @ l o
below
b I n i T
beneath
b I s aI d
beside
b @ s aI d z
besides
b i t w i n
between
b i j A n d
beyond
b o T
both
b V t
b aI
k { n
s @r t n=
certain
s @r k @
circa
k l o s
close
k @ n s @r n I ng
concerning
k A n s @ k w E n t l i
consequently
k @ n s I 4 @ r I ng
considering
k U d
could
d E r
dare
d I s p aI t
despite
d aU n
down
d U r I ng
during
i tS
each
eight
i D @r
either
I n V f
enough
E v r i
every
E v r i b A 4 i
everybody
E v r i w V n
everyone
E v r i T I ng
everything
I k s E p t
except
I k s E p t I ng
excepting
I k s k l u 4 I ng
excluding
f e l I ng
failing
f j u
f j u @r
fewer
f aI v
five
f A l o I ng
following
f O r
four
f r A m
from
g I v @ n
given
h { d
h { v
have
h i p s
heaps
h E n s
hence
h @r
h @r z
hers
h @r s E l f
herself
h I m
h I m s E l f
himself
h I z
h aU E v @r
however
I ng k l u 4 I ng
including
I n s aI d
inside
I n s t E d
instead
I n t U
into
I t s
I t s E l f
itself
l E s
less
l aI k
like
l I 4 l=
little
l o d z
loads
l A t s
lots
m E n i
many
m { s I z
masses
m aI t
might
m aI n
mine
m aI n @ s
minus
m O r
more
m o s t
most
m V tS
much
m V s t
must
m aI
m aI s E l f
myself
n i r
near
n i d
need
n i D @r
neither
n E v @r D @ l E s
nevertheless
n E k s t
next
n aI n
nine
n o b @ 4 i
nobody
n V n
none
n o w V n
no_one
n O r
n V T I ng
nothing
n A t w I T s t { n d I ng
notwithstanding
n V m b @r z
numbers
w V n s
once
w V n
A n t u
onto
A p @ z I t
opposite
V D @r
other
ought
A r z
ours
aU r s E l v z
ourselves
aU t
aU t s aI d
outside
o v @r
over
p A r t
part
p { s t
past
p E n d I ng
pending
p @r
p @r t e n I ng
pertaining
p l E n 4 i
plenty
p l V s
plus
k w A n t @ 4 i z
quantities
r I g A r d I ng
regarding
r I s p E k t I ng
respecting
r aU n d
round
s e v
save
s e v I ng
saving
s E v @ n
seven
s E v r l=
several
S { l
shall
S U d
should
s I m @ l @r
similar
s I n s
since
s I k s
s V m
some
s V m b V 4 i
somebody
s V m w V n
someone
s V m T I ng
something
s V tS
such
t E n
D { n
than
T { ng k s
thanks
D { t
that
D E r
their
D E r z
theirs
D E m
them
D @ m s E l v z
themselves
D E n
then
D E n s
thence
D E r f O r
therefore
D i z
these
they
D I s
this
D o z
those
though
T r i
three
T r u
through
T r u aU t
throughout
thru
D V s
thus
t I l
till
t V n z
tons
t w O r d
toward
t w O r d z
towards
V n d @r
under
V n d @r n i T
underneath
@ n l E s
unless
V n l aI k
unlike
@ n t I l
until
V n t u
unto
@ p A n
upon
j u z d
used
v E r i @ s
various
v @r s @ s
versus
v i @
w A n t I ng
wanting
w A t
what
w A 4 E v @r
whatever
w E n
when
w E n s
whence
w E n E v @r
whenever
w E r
where
w E r { z
whereas
w E r E v @r
wherever
w E D @r
whether
w I tS
which
w I tS E v @r
whichever
w aI l
while
w aI l s t
whilst
h u E v @r
whoever
h u m
whom
h u m E v @r
whomever
h u z
whose
w I l
will
w I D
with
w I D I n
within
w I D aU t
without
w U d
would
j E t
j @r
your
j O r z
yours
j @r s E l f
yourself
j O r s E l v z
yourselves
normal
Unable to open nnet file, exiting
Unable to stat nnet file, exiting
mmap of Valid NNet file failed, exiting
Neural net file is unable to read configuration settings, the mdnf file is not valid
Undefined version of nnet_meta_info file
Dimensions of data entering compute output is incorrect, computing mdn output will fail stopping datadim, in_norms_size_ follow. note that in_norms should be double the datadim: %i %i 
Will crash on ARM32 in neural net need 4 byte alignments 
RIFF
WAVE
fmt 
data
caff
desc
lpcm
.caf
RIFFxxxxWAVEfmt 
dataxxxx
.raw
stateid
feats
Unable to read feat_book_file using Json parser; continuing in backwards compatibility mode.
Unknown feature in spec is specified as input to MDN: %s (ABOUT TO CRASH)
conversion of data to type "
" failed
typename boost::enable_if<detail::is_translator<Translator>, Type>::type boost::property_tree::basic_ptree<std::__1::basic_string<char>, std::__1::basic_string<char>, std::__1::less<std::__1::basic_string<char> > >::get_value(Translator) const [Key = std::__1::basic_string<char>, Data = std::__1::basic_string<char>, KeyCompare = std::__1::less<std::__1::basic_string<char> >, Type = int, Translator = boost::property_tree::stream_translator<char, std::__1::char_traits<char>, std::__1::allocator<char>, int>]
map::at:  key not found
pred_mfcc_b_
pred_mfcc_e_
pred_dmfcc_b_
pred_dmfcc_e_
pred_f0_b_
pred_f0_m_
pred_f0_e_
pred_df0_b_
pred_df0_e_
pred_dur_
Unable to open prompt file, will not run active prompts 
mmap of Valid TAPExtractor file failed, will not run prompts 
Running obsolete version of prompts, skipping prompts instead 
sapx0282-1
sanv0128-0
munmap of Valid TAPExtractor file failed. 
sil2
ERROR, unable to set index for required feature 
Prompt Matching table 
Text:              | 
Character in word: | 
%d  
UTF-8:             | 
Is at start word:  | 
%s  
Is at end word:    | 
Had %u candidates for prompt match, applied sort. 
Matched Canned Prompt: "%s" for text: "%s" affecting unit ranges (initial -> substituted): [%d,%d] -> [%d,%d]. 
Markers provide 0 unit prompt %s.  Prompt has been explicitly disabled for violating a safety condition or contains invalid data. 
play 
AssistantEtiquette
AssistantEtiquette.wav
beep.wav
Attempting prompt match for prompt %s 
First phone is %d, last phone is %d, start index is %d, end_index is %d 
Start index matches are: %c, %c, while the non-blank index is %d 
Backwards sentence and phrase matches are: %c, %c 
Terminal non-blank index is %d 
Start word boundary is %c, start at phrase boundary is %c, start at sentence boundary is %c 
End word boundary is %c, end at phrase boundary is %c, end at sentence boundary is %c 
ERROR: INVALID START BOUNDARY CONDITION FOR TAP using phrase 
ERROR: INVALID END BOUNDARY CONDITION FOR TAP using phrase 
force
veto
Target::run_slicewise run without a marker table
v16@?0Q8
Unit %d is unit number %d and audio unit number %d 
start
Silences are %s
generated
organic
Seg %7u-%-7u %6u@%-8u %s
Final audio %zu samples, checksum %02x%02x%02x%02x
Marker state table does not match actual # of units %zu %zu
.wav
encodeObject:forKey:
init
class
decodeObjectOfClass:forKey:
supportsSecureCoding
encodeWithCoder:
initWithCoder:
.cxx_destruct
bundleIdentifier
setBundleIdentifier:
compatibilityVersion
setCompatibilityVersion:
contentVersion
setContentVersion:
masteredVersion
setMasteredVersion:
_bundleIdentifier
_compatibilityVersion
_contentVersion
_masteredVersion
encodeInt64:forKey:
encodeBool:forKey:
decodeInt64ForKey:
decodeBoolForKey:
utterance
setUtterance:
voiceAssetKey
setVoiceAssetKey:
requestCreatedTimestamp
setRequestCreatedTimestamp:
speechBeginTimestamp
setSpeechBeginTimestamp:
speechEndTimestamp
setSpeechEndTimestamp:
isWarmStart
setIsWarmStart:
_isWarmStart
_utterance
_voiceAssetKey
_requestCreatedTimestamp
_speechBeginTimestamp
_speechEndTimestamp
voiceData
languages
firstObject
type
numberWithLong:
gender
footprint
stringWithFormat:
setVoiceData:
asset
setAsset:
builtInVoicePath
setBuiltInVoicePath:
_voiceData
_asset
_builtInVoicePath
alloc
_reloadAndCacheVoiceAssets
cacheConcurrentQueue
voiceSelectionCache
objectForKeyedSubscript:
arrayWithObjects:count:
countByEnumeratingWithState:objects:count:
longValue
queryForType:voicename:language:gender:footprint:localOnly:
runQueryAndReturnError:
state
voiceDataFromAsset:
addObject:
pickCorrectAssetFromLocalAssets:
setObject:forKey:
legacyLocalVocalizerVoiceAssetForLanguage:
_nonCacheInstalledAssetsForType:voicename:language:gender:footprint:
array
_reloadAndCacheVoiceResourcesAssets
voiceResourceCache
setLanguages:
queryForVoiceResourceAsset:localOnly:
voiceResourceFromAsset:
integerValue
sortUsingComparator:
lastObject
_nonCacheInstalledVoiceResources
count
arrayWithCapacity:
selectVoiceResourceAssetForLanguage:
defaultVoice
_defaultVoiceSettingsForLanguage:
genderFromString:
setGender:
footprintFromString:
setFootprint:
typeFromString:
setType:
numberWithUnsignedInt:
numberWithInteger:
genderStringFromGender:
footprintStringFromFootprint:
componentsJoinedByString:
predicateWithFormat:argumentArray:
bundleIdentifierForVoiceType:
initWithAssetType:
setPredicate:
setQueriesLocalAssetInformationOnly:
predicateWithFormat:
sharedManager
_cachedVoiceResourcesAssetsForLanguage:
attributes
localURL
setSearchPathURL:
URLByAppendingPathComponent:
syncWithConfigFile:
addObjectsFromArray:
predicateWithBlock:
filterUsingPredicate:
isKindOfClass:
name
isEqualToString:
_cachedVoiceAssets
filteredArrayUsingPredicate:
_cachedVoiceResourcesAssets
sortedArrayUsingComparator:
assetType
setIsInstalled:
amendVoiceWithDefaultSettings:
setName:
_builtInVoiceForLanguage:
typeStringFromType:
_cachedVoiceAssetsForLanguage:type:gender:footprint:
setIsBuiltInVoice:
isVoiceAssetWellDefined:
description
dictionaryWithObjects:forKeys:count:
errorWithDomain:code:userInfo:
localizedDescription
localizedFailureReason
numberWithBool:
getLatestAssetFromArray:
_downloadAsset:withOptions:completion:
startQuery:
doubleValue
floatValue
_downloadAsset:withOptions:progressHandler:
_purgeAsset:
resumeDownload:
adjustDownloadOptions:completion:
setProgressHandler:
beginDownloadWithOptions:
purgeAndReturnError:
cancelDownloadAndReturnError:
downloadVoiceAsset:useBattery:completion:
removeVoiceAsset:completion:
initWithDictionaryRepresentation:
selectVoiceForLang:type:gender:footprint:
containsObject:
dictionary
setObject:forKeyedSubscript:
installedAssetsForType:voicename:language:gender:footprint:
installedVoiceResources
voiceTypeForBundleIdentifier:
downloadVoiceAsset:useBattery:progressUpdateHandler:
downloadVoiceResource:useBattery:completion:
removeVoiceResource:completion:
reinstallVoiceData:completion:
cleanUnusedVoiceAssets
cleanOldVoiceResources
setCacheConcurrentQueue:
setVoiceSelectionCache:
setVoiceResourceCache:
_cacheConcurrentQueue
_voiceSelectionCache
_voiceResourceCache
bundleForClass:
pathForResource:ofType:
arrayWithContentsOfFile:
setWithArray:
stringByReplacingOccurrencesOfString:withString:
availableLanguages
dictionaryWithContentsOfFile:
rangeOfString:
substringWithRange:
fallbackLanguageForLanguage:
initWithFormat:
initWithContentsOfFile:
objectForKey:
removeObjectForKey:
defaultManager
contentsOfDirectoryAtURL:includingPropertiesForKeys:options:error:
retain
path
stringByStandardizingPath
fileURLWithPath:
removeItemAtURL:error:
initWithContentsOfURL:
filePathURL
attributesOfItemAtPath:error:
autorelease
objectAtIndex:
mutableCopy
removeObjectAtIndex:
replaceObjectAtIndex:withObject:
release
modelIdentifier
recognitionResultWithModelIdentifier:classIdentifiers:values:
elementCount
getElementClassIdentifier:value:atIndex:
bundleWithPath:
load
actionForRecognitionResult:
actionForRecognitionResults:
isEqual:
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retainCount
zone
hash
superclass
debugDescription
instancesRespondToSelector:
initialize
recognitionResultByReplacingValueForClassIdentifier:withValue:
valueOfFirstElementWithClassIdentifier:
createHandler
setRecognitionAction:
recognitionAction
reset
_init
cancel
setDelegate:
setActive:
dealloc
recognitionSessionDidBeginAction:
recognitionSessionWillBeginAction:
recognitionSession:openURL:
recognitionSession:didCompleteActionWithError:
recognitionSession:didFinishSpeakingFeedbackStringWithError:
_notifyDelegateActionStarted
_continueAfterDeferredStart
perform
_hasDeferredStartCallback
_currentRecognizeAction
_debugDumpPath
setAudioType:
setKeepAudioSessionActive:
initWithModelIdentifier:
_setAction:
_isRecognizing
_isActivelyRecognizing
completionType
_setBluetoothInputAllowed:
invalidate
stopSpeakingAtNextBoundary:error:
cancelMaintainingKeepAlive:
methodSignatureForSelector:
invocationWithMethodSignature:
setSelector:
setTarget:
setArgument:atIndex:
retainArguments
scheduledTimerWithTimeInterval:invocation:repeats:
_setSession:
_setDebugDumpPath:
_setDebugDumpEnabled:
_setPreferredEngine:
_setAudioInputPath:
_setInputLevelUpdateInterval:
_setEngineResetRequired:
defaultCenter
postNotificationName:object:
_handledThreadedResults:nextAction:
spokenFeedbackString
spokenFeedbackAttributedString
resultDisplayString
statusDisplayString
_inputLevel
_inputLevelDB
_keywordAtIndex:
_keywordCount
_scrambledKeywordsAndAddToSet:
removeAllObjects
_nextKeywordUsingCursors:
removeObject:
allObjects
_createKeywordIndex
_createPhaseSortedKeywordsFromArray:
_topLevelKeywords
_keywordIndexChanged
postNotificationName:object:userInfo:
_beginSpeakingAttributedString:
beginSpeakingString:
length
_beginSpeakingString:attributedString:
_notifyDelegateFinishedSpeakingWithError:
initForInputFeedback
startSpeakingAttributedString:toURL:withLanguageCode:error:
startSpeakingString:withLanguageCode:error:
beginNextAction
isRecognizing
isActivelyRecognizing
isFinished
isValid
hasDeferredAction
isBusy
nextActionWillTerminateSession
nextActionWillRecognize
setSensitiveActionsEnabled:
sensitiveActionsEnabled
setBluetoothInputAllowed:
_actionCompleted:nextAction:error:
_actionStarted:
_notifyDelegateOpenURL:
_recognitionResultHandlingThread
recognitionResultHandlingThread:didHandleResults:nextAction:
displayResultString
displayStatusString
setInputLevelUpdateInterval:
inputLevel
inputLevelDB
setKeywordPhase:
keywordAtIndex:
keywordCount
_keywordsForModelIdentifier:
beginSpeakingFeedbackString
speechSynthesizer:didFinishSpeaking:withError:
setDebugDumpEnabled:
debugDumpPath
setNextRecognitionAudioInputPath:
setNextRecognitionRequiresReset:
setPreferredEngine:
setPerformRecognitionHandlerActions:
_modelIdentifier
_keepAlive
_delegate
_currentAction
_handlingThread
_synthesizer
_languageID
_audioInputPath
_levelInterval
_keywordPhase
_sessionFlags
exchangeObjectAtIndex:withObjectAtIndex:
string
_session
setResultDisplayString:
setStatusDisplayString:
setSpokenFeedbackString:
setSpokenFeedbackAttributedString:
completeWithNextAction:error:
_resultString
_statusString
_spokenString
_spokenStringIsAttributed
arrayWithObject:
_disambiguationContext
_reset
setRepeatedSpokenFeedbackString:
repeatedSpokenFeedbackString
sequenceTag
setSequenceTag:
knownValueForClassIdentifier:
setKnownValue:phoneticValue:forClassIdentifier:
knownValuesForClassIdentifier:
setKnownValues:phoneticValues:forClassIdentifier:
ambiguousValuesForClassIdentifier:
setAmbiguousValues:phoneticValues:forClassIdentifier:
_keywords
setKeywords:
_createRecognitionInstanceWithCallbacks:info:
_actionForEmptyResults
_repeatedSpokenFeedbackString
_sequenceTag
_knownValues
_knownPhoneticValues
_ambiguousValues
_ambiguousPhoneticValues
_context
languageMapping
dataWithContentsOfFile:
characterSetWithBitmapRepresentation:
characterSetForLanguage:
characterAtIndex:
characterIsMember:
valueWithRange:
unspeakableRangeOfText:forLanguage:
_setDebugDumpEnabled:dumpPath:
_configureNewRecognitionInstance
_setResults:
_releaseFromPrepare
subarrayWithRange:
requiresThreadedProcessing
handleResults:withHandler:
makeObjectsPerformSelector:withObject:
_handleRecognitionPrepared:
_handleRecognitionStarted:
_handleRecognitionCompleted:withResults:error:
_recognition
_results
_recognizeFlags
decodeObjectOfClasses:forKey:
dictionaryWithContentsOfURL:
setResourceList:
setVoiceConfig:
voiceConfig
legacyPlatforms
defaultTypeString
defaultFootprintString
resourceList
searchPathURL
_languages
_resourceList
_searchPathURL
_voiceConfig
stopListening
lock
_spokenLanguageChanged:
addObserver:selector:name:object:
unlock
allValues
beginReportingChanges
makeObjectsPerformSelector:
stopReportingChanges
removeObserver:name:object:
_flush
initWithModelIdentifier:classIdentifier:
_enqueueRequest:
performUpdateForModelIdentifier:classIdentifier:
coalescedRequest:
timerWithTimeInterval:target:selector:userInfo:repeats:
mainRunLoop
addTimer:forMode:
dateWithTimeIntervalSinceNow:
setFireDate:
classIdentifier
sharedListener
sharedListenerIfExists
_initShared
startListening
_lock
_updateRequestQueue
_dataProviders
_flushTimer
_isListening
_modelID
_classID
valueCountForClassWithIdentifier:inModelWithIdentifier:
valueAtIndex:forClassWithIdentifier:inModelWithIdentifier:
getValue:weight:atIndex:forClassWithIdentifier:inModelWithIdentifier:
phoneticValueAtIndex:forClassWithIdentifier:inModelWithIdentifier:
cacheValidityIdentifier
isCacheValidityIdentifierValid:
_setConfirmed:
setConfirmedAction:
confirmedAction
setDeniedAction:
deniedAction
_confirmedAction
_deniedAction
_confirmFlags
setURL:
_url
localizations
pathForResource:ofType:inDirectory:forLocalization:
initFileURLWithPath:
pathForResource:ofType:inDirectory:
initWithSpokenFeedbackString:willTerminate:
_shouldTerminate
initWithCondition:
initWithHandler:results:
_handleRequests
detachNewThreadSelector:toTarget:withObject:
unlockWithCondition:
results
nextAction
lockWhenCondition:
handler
setNextAction:
_notifyRequestHandled:
performSelectorOnMainThread:withObject:waitUntilDone:
_requests
_resultHandlingFlags
_handler
_action
matchedString:forTokenInRange:
replaceCharactersInRange:withString:
initWithContentsOfPath:languageIdentifier:
processedTextFromString:
_rules
_tokenizer
boolValue
_matchPattern
_replacement
_caseSensitive
_eatPunctuation
appendString:withAttributes:
attributedStringWithFormatAndAttributes:
formatSpecifier
formattedArg
setAttributes:range:
processInfo
processName
downloadAssetForLanguage:
downloadingAssetLanguage
assetStatusForLanguage:
assetDownloadStatus:progress:size:
removeAssetForLanguage:
_assetCleanupTimer
encodeInteger:forKey:
encodeDouble:forKey:
encodeInt32:forKey:
decodeIntegerForKey:
decodeDoubleForKey:
decodeInt32ForKey:
decodePropertyListForKey:
text
setText:
attributedText
setAttributedText:
languageCode
setLanguageCode:
voiceName
setVoiceName:
useCustomVoice
setUseCustomVoice:
voiceType
setVoiceType:
outputPath
setOutputPath:
rate
setRate:
pitch
setPitch:
volume
setVolume:
maintainsInput
setMaintainsInput:
audioSessionIDIsValid
setAudioSessionIDIsValid:
audioSessionID
setAudioSessionID:
audioQueueFlags
setAudioQueueFlags:
clientBundleIdentifier
setClientBundleIdentifier:
resourceListURL
setResourceListURL:
resourceSearchPathURL
setResourceSearchPathURL:
stopHandler
setStopHandler:
pauseHandler
setPauseHandler:
_useCustomVoice
_maintainsInput
_audioSessionIDIsValid
_audioSessionID
_audioQueueFlags
_text
_attributedText
_languageCode
_voiceName
_footprint
_voiceType
_gender
_outputPath
_rate
_pitch
_volume
_clientBundleIdentifier
_resourceListURL
_resourceSearchPathURL
_stopHandler
_pauseHandler
completion
audioPlayerDidFinishPlaying:successfully:
audioPlayerDecodeErrorDidOccur:error:
audioPlayerBeginInterruption:
audioPlayerEndInterruption:withOptions:
audioPlayerEndInterruption:withFlags:
audioPlayerEndInterruption:
setCompletion:
_completion
availableVoicesForLanguageCode:
availableFootprintsForVoice:languageCode:
isSystemSpeaking
getVoiceResourceForLanguage:reply:
fileExistsAtPath:
isPlaying
stop
sharedInstance
category
setActive:withOptions:error:
setCategory:error:
initWithContentsOfURL:error:
setActive:error:
play
mainBundle
_startSpeakingString:orAttributedString:toURL:withLanguageCode:request:error:
language
prewarmIfNeededWithRequest:
_stopSpeakingRequest:atNextBoundary:synchronously:error:
setMaintainPersistentConnection:
setMaintainInactivePersistentConnection:
speechSynthesizer:didStartSpeakingRequest:
speechSynthesizerDidStartSpeaking:
speechSynthesizer:didFinishSpeakingRequest:successfully:withError:
speechSynthesizer:didFinishSpeakingRequest:successfully:phonemesSpoken:withError:
speechSynthesizer:didFinishSpeaking:phonemesSpoken:withError:
speechSynthesizer:didPauseSpeakingRequest:
speechSynthesizerDidPauseSpeaking:
speechSynthesizer:didContinueSpeakingRequest:
speechSynthesizerDidContinueSpeaking:
speechSynthesizer:willSpeakRangeOfSpeechString:forRequest:
speechSynthesizer:willSpeakRangeOfSpeechString:
speechSynthesizer:didFinishSpeakingRequest:withInstrumentMetrics:
opaqueSessionID
startSpeechRequest:
connection:speechRequest:didStopAtEnd:phonemesSpoken:error:
request
stopCurrentSpeechRequestAtMark:
pauseCurrentSpeechRequestAtMark:
continueCurrentSpeechRequest
_setDelegate:
startSpeakingString:toURL:withLanguageCode:error:
stopSpeakingAtNextBoundary:synchronously:error:
pauseSpeakingAtNextBoundary:synchronously:error:
_pauseSpeakingRequest:atNextBoundary:synchronously:error:
_continueSpeakingRequest:withError:
isSystemSpeakingOnBehalfOfCurrentConnection
availableVoices
setLogToFile:
getLogToFile:
availableLanguageCodes
playVoicePreviewForLanguageCode:gender:
connection:speechRequestDidStart:
connection:speechRequestDidPause:
connection:speechRequestDidContinue:
connection:speechRequest:willSpeakMark:inRange:
connection:speechRequest:successWithInstrumentMetrics:
prewarmIfNeeded
startSpeakingString:error:
startSpeakingString:toURL:error:
pauseSpeakingAtNextBoundary:error:
continueSpeakingWithError:
isSpeaking
speechString
minimumRate
maximumRate
voice
setLanguage:
useSharedAudioSession:
useSpecificAudioSession:
useAudioQueueFlags:
startSpeakingString:request:error:
startSpeakingString:toURL:request:error:
startSpeakingString:withLanguageCode:request:error:
stopSpeakingRequest:atNextBoundary:error:
stopSpeakingRequest:atNextBoundary:synchronously:error:
pauseSpeakingRequest:atNextBoundary:error:
pauseSpeakingRequest:atNextBoundary:synchronously:error:
continueSpeakingRequest:withError:
delegate
setVoice:
_inactiveKeepAlive
_language
_useSharedSession
_queue
_speechConnection
_synthesizerFlags
_voice
getLocalVoiceAssets:
getLocalVoiceResources:
setAutoDownloadedVoiceAssets:
getAutoDownloadedVoiceAssets:
getVoiceInfoForLanguageCode:footprint:gender:type:reply:
getAllVoiceAssets:
getVoiceInfoForLanguageCode:footprint:gender:custom:reply:
initWithMachServiceName:options:
maintainWithAudioType:keepAudioSessionActive:
interfaceWithProtocol:
setRemoteObjectInterface:
_ensureKeepAliveMaintenance
setInterruptionHandler:
resume
_serverConnection
remoteObjectProxy
_remoteKeepAlive
audioType
active
keepAudioSessionActive
_audioType
_active
_keepAudioSessionActive
pauseSpeechRequestAtMark:
continueSpeechRequest
stopSpeechRequestAtMark:
getVoiceNamesForLanguage:reply:
getFootprintsForVoiceName:languageCode:reply:
getSpeechIsActiveReply:
getSpeechIsActiveForConnectionReply:
getLocalVoicesReply:
getLocalVoiceResourcesReply:
setClasses:forSelector:argumentIndex:ofReply:
speechRequestDidStart
speechRequestDidPause
speechRequestDidContinue
speechRequestMark:didStartForRange:
speechRequestDidStopWithSuccess:phonemesSpoken:error:
speechRequestSuccessWithInstrumentMetrics:
setExportedInterface:
setExportedObject:
_connectionInvalidated
setInvalidationHandler:
_connection
remoteObjectProxyWithErrorHandler:
_setRequest:
setRequest:
setConnection:
_remoteObjectWithErrorHandler:
addBarrierBlock:
_remoteObject
_delegateWrapper
_request
connection
lowercaseString
voiceKey
dictionaryRepresentation
isInstalled
isBuiltInVoice
_isInstalled
_isBuiltInVoice
_name
_type
anonymousListener
setQueue:
setHandler:
setListener:
endpoint
setEndpoint:
_setQueue:
invokeUpdateWithObject:
initWithBlock:
initWithListenerEndpoint:
configuredEndpointWithUpdateHandler:withConnection:
remoteUpdateHanderForEndpoint:
listener:shouldAcceptNewConnection:
queue
listener
_endpoint
_listener
_block
VSAssetBase
NSSecureCoding
NSCoding
VSInstrumentMetrics
VSVoiceAssetSelection
VSMobileAssetsManager
VSSpeechSynthesizerPreference
VSRecognitionResultHandler
NSObject
VSRecognitionResult
VSRecognitionSession
VSRecognitionSessionKeywords
VSRecognitionAction
VSRecognitionDisambiguateAction
VSSpeechCharacterSet
VSRecognitionRecognizeAction
VSVoiceResourceAsset
VSCacheUpdateListener
VSCacheUpdateRequest
VSRecognitionModelDataProvider
VSRecognitionConfirmAction
VSRecognitionURLAction
VSRecognitionSpeakAction
VSRecognitionResultHandlingThread
VSRecognitionResultHandlingRequest
VSTextPreProcessor
VSTextPreProcessorRule
VSSpeechAdditions
VSFormatArgument
VSAssetUpdateListener
VSSpeechRequest
VSAudioPreviewDelegate
AVAudioPlayerDelegate
VSSpeechSynthesizer
VSSpeechConnectionDelegate
Assets
VSRemoteKeepAlive
VSKeepAlive
VSSpeechService
VSSpeechServiceDelegate
VSSpeechConnection
VSSpeechConnectionDelegateWrapper
VSVoiceAsset
VSGenericUpdate
VSGenericUpdateEndpoint
NSXPCListenerDelegate
VSGenericBlockHolder
B16@0:8
v24@0:8@16
v24@0:8@"NSCoder"16
@24@0:8@16
@24@0:8@"NSCoder"16
v16@0:8
@16@0:8
@"NSString"
@"NSNumber"
Q16@0:8
v24@0:8Q16
v20@0:8B16
@"VSVoiceAsset"
@"ASAsset"
@60@0:8q16@24@32q40q48B56
@28@0:8@16B24
@56@0:8q16@24@32q40q48
@48@0:8@16q24q32q40
B24@0:8@16
@24@0:8q16
q24@0:8@16
v36@0:8@16B24@?28
v32@0:8@16@?24
v40@0:8@16@24@?32
@"NSObject<OS_dispatch_queue>"
@"NSMutableDictionary"
@"VSRecognitionAction"24@0:8@"VSRecognitionResult"16
@"VSRecognitionAction"24@0:8@"NSArray"16
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8@"Protocol"16
B24@0:8:16
Vv16@0:8
^{_NSZone=}16@0:8
@"NSString"16@0:8
@40@0:8@16@24@32
@32@0:8@16@24
q16@0:8
B40@0:8^@16^@24q32
B20@0:8B16
@20@0:8B16
v40@0:8@16@24@32
v24@0:8d16
f16@0:8
^{__CFDictionary=}16@0:8
v36@0:8@16B24@28
B20@0:8i16
@"VSKeepAlive"
@"<VSRecognitionSessionDelegate>"
@"VSRecognitionAction"
@"NSArray"
@"VSSpeechSynthesizer"
{?="delegateWillBegin"b1"delegateBegin"b1"delegateOpenURL"b1"delegateFinishedSpeaking"b1"delegateComplete"b1"debugDumpEnabled"b1"preferredEngine"b2"performHandlerActions"b1"allowSensitiveActions"b1"bluetoothAllowed"b1"resetNextAction"b1"isSpeaking"b1"actionBegan"b1"actionBeginning"b1"actionBeginDeferred"b1"invalid"b1"observeKeywordChange"b1}
@24@0:8^{__CFDictionary=}16
i16@0:8
v32@0:8@16@24
(?="stringValue"@"NSString""attributedStringValue"@"NSAttributedString")
@"VSRecognitionSession"
^{__VSRecognitionDisambiguationContext=}16@0:8
^{__VSRecognition=}32@0:8^{?=^?^?^?}16^v24
B24@0:8d16
B28@0:8B16@20
v24@0:8^{__VSRecognition=}16
v40@0:8^{__VSRecognition=}16^{__CFArray=}24^{__CFError=}32
{?="debugDumpEnabled"b1"preferredEngine"b2"resetEngine"b1"bluetoothAllowed"b1"hasStarted"b1}
@"NSDictionary"
@"NSURL"
@"NSLock"
@"NSMutableArray"
@"NSTimer"
q32@0:8@16@24
q32@0:8@"NSString"16@"NSString"24
@40@0:8q16@24@32
@"NSString"40@0:8q16@"NSString"24@"NSString"32
B56@0:8^@16^q24q32@40@48
B56@0:8^@16^q24q32@"NSString"40@"NSString"48
@"NSDictionary"16@0:8
B24@0:8@"NSDictionary"16
{?="initializing"b1"confirmed"b1}
@"<VSRecognitionResultHandlingThreadDelegate>"
@"NSConditionLock"
{?="running"b1"delegateDidHandleResults"b1"valid"b1}
@"<VSRecognitionResultHandler>"
^{__CFStringTokenizer=}
@32@0:8@16^{?=qq}24
i24@0:8@16
B40@0:8@16^f24^q32
@"PCPersistentTimer"
v24@0:8q16
d16@0:8
I16@0:8
v20@0:8I16
@?16@0:8
v24@0:8@?16
@"NSAttributedString"
v28@0:8@16B24
v28@0:8@"AVAudioPlayer"16B24
v32@0:8@"AVAudioPlayer"16@"NSError"24
v24@0:8@"AVAudioPlayer"16
v32@0:8@16Q24
v32@0:8@"AVAudioPlayer"16Q24
B32@0:8@16q24
v32@0:8@"VSSpeechConnection"16@"VSSpeechRequest"24
v52@0:8@16@24B32@36@44
v52@0:8@"VSSpeechConnection"16@"VSSpeechRequest"24B32@"NSString"36@"NSError"44
v56@0:8@16@24q32{_NSRange=QQ}40
v56@0:8@"VSSpeechConnection"16@"VSSpeechRequest"24q32{_NSRange=QQ}40
v40@0:8@"VSSpeechConnection"16@"VSSpeechRequest"24@"VSInstrumentMetrics"32
B48@0:8@16@24@32^@40
B64@0:8@16@24@32@40^@48^@56
B44@0:8@16q24B32^@36
B32@0:8@16^@24
B40@0:8@16@24^@32
B32@0:8q16^@24
B36@0:8q16B24^@28
B24@0:8^@16
B40@0:8@16^@24^@32
B48@0:8@16@24^@32^@40
B40@0:8@16q24^@32
v20@0:8f16
@"VSSpeechConnection"
{?="delegateStart"b1"delegateFinish"b1"delegateFinishWithPhonemesSpoken"b1"delegatePause"b1"delegateContinue"b1"delegateWillSpeak"b1"delegateStartWithRequest"b1"delegateFinishWithRequest"b1"delegateFinishWithPhonemesSpokenWithRequest"b1"delegateSuccessWithInstrumentMetrics"b1"delegatePauseWithRequest"b1"delegateContinueWithRequest"b1"delegateWillSpeakWithRequest"b1"willUseInput"b1}
@"<VSSpeechSynthesizerDelegate>"
v52@0:8@16q24q32B40@?44
v56@0:8@16q24q32q40@?48
Vv28@0:8q16B24
@"NSXPCConnection"
Vv24@0:8@16
Vv24@0:8@"VSSpeechRequest"16
Vv24@0:8q16
Vv32@0:8@16@?24
Vv32@0:8@"NSString"16@?<v@?@"NSArray">24
Vv40@0:8@16@24@?32
Vv40@0:8@"NSString"16@"NSString"24@?<v@?@"NSArray">32
Vv24@0:8@?16
Vv24@0:8@?<v@?B>16
Vv24@0:8@?<v@?@"NSArray"@"NSError">16
Vv24@0:8@"NSArray"16
Vv24@0:8@?<v@?@"NSArray">16
Vv32@0:8@"NSString"16@?<v@?@"VSVoiceResourceAsset">24
Vv56@0:8@16q24q32q40@?48
Vv56@0:8@"NSString"16q24q32q40@?<v@?@"VSVoiceAsset">48
Vv20@0:8B16
Vv40@0:8q16{_NSRange=QQ}24
Vv36@0:8B16@20@28
Vv36@0:8B16@"NSString"20@"NSError"28
Vv24@0:8@"VSInstrumentMetrics"16
@24@0:8@?16
@"VSSpeechConnectionDelegateWrapper"
@"VSSpeechRequest"
@"<VSSpeechConnectionDelegate>"
@32@0:8@?16@24
@?24@0:8@16
B32@0:8@16@24
B32@0:8@"NSXPCListener"16@"NSXPCConnection"24
@"NSXPCListenerEndpoint"
@"NSXPCListener"
NSt3__114basic_ofstreamIcNS_11char_traitsIcEEEE
NSt3__113basic_filebufIcNS_11char_traitsIcEEEE
NSt3__118basic_stringstreamIcNS_11char_traitsIcEENS_9allocatorIcEEEE
NSt3__115basic_stringbufIcNS_11char_traitsIcEENS_9allocatorIcEEEE
N8nlohmann12_GLOBAL__N_116DecimalSeparatorE
12AudioDecoder
12TTSACDecoder
11VoiceConfig
19VoiceConfigFlexible
16VoiceConfigEyrie
NSt3__120__shared_ptr_pointerIP13NNetExtractorNS_14default_deleteIS1_EENS_9allocatorIS1_EEEE
NSt3__114default_deleteI13NNetExtractorEE
N5boost13property_tree11ptree_errorE
N5boost13property_tree14ptree_bad_pathE
8Database
N5boost16exception_detail10clone_implINS0_19error_info_injectorINS_13property_tree11json_parser17json_parser_errorEEEEE
N5boost16exception_detail19error_info_injectorINS_13property_tree11json_parser17json_parser_errorEEE
N5boost13property_tree11json_parser17json_parser_errorE
N5boost13property_tree17file_parser_errorE
N5boost9exceptionE
N5boost16exception_detail10clone_baseE
N5boost6spirit7classic12parser_errorINSt3__112basic_stringIcNS3_11char_traitsIcEENS3_9allocatorIcEEEENS3_11__wrap_iterIPcEEEE
N5boost6spirit7classic17parser_error_baseE
N5boost6detail17sp_counted_impl_pINS_6spirit7classic4impl26object_with_id_base_supplyImEEEE
N5boost6detail15sp_counted_baseE
N5boost6spirit7classic4impl14grammar_helperINS1_7grammarINS_13property_tree11json_parser12json_grammarINS5_11basic_ptreeINSt3__112basic_stringIcNS9_11char_traitsIcEENS9_9allocatorIcEEEESF_NS9_4lessISF_EEEEEENS1_14parser_contextINS1_5nil_tEEEEESJ_NS1_7scannerINS9_11__wrap_iterIPcEENS1_16scanner_policiesINS1_28skip_parser_iteration_policyINS1_11alternativeINSU_INS1_12space_parserENS1_13confix_parserINS1_6strlitIPKcEENS1_11kleene_starINS1_14anychar_parserEEENSU_INS1_10eol_parserENS1_10end_parserEEENS1_21unary_parser_categoryENS1_10non_nestedENS1_9is_lexemeEEEEENSW_IS10_S13_S10_S17_S18_S19_EEEENS1_16iteration_policyEEENS1_12match_policyENS1_13action_policyEEEEEEE
N5boost6spirit7classic4impl19grammar_helper_baseINS1_7grammarINS_13property_tree11json_parser12json_grammarINS5_11basic_ptreeINSt3__112basic_stringIcNS9_11char_traitsIcEENS9_9allocatorIcEEEESF_NS9_4lessISF_EEEEEENS1_14parser_contextINS1_5nil_tEEEEEEE
N5boost6detail17sp_counted_impl_pINS_6spirit7classic4impl14grammar_helperINS3_7grammarINS_13property_tree11json_parser12json_grammarINS7_11basic_ptreeINSt3__112basic_stringIcNSB_11char_traitsIcEENSB_9allocatorIcEEEESH_NSB_4lessISH_EEEEEENS3_14parser_contextINS3_5nil_tEEEEESL_NS3_7scannerINSB_11__wrap_iterIPcEENS3_16scanner_policiesINS3_28skip_parser_iteration_policyINS3_11alternativeINSW_INS3_12space_parserENS3_13confix_parserINS3_6strlitIPKcEENS3_11kleene_starINS3_14anychar_parserEEENSW_INS3_10eol_parserENS3_10end_parserEEENS3_21unary_parser_categoryENS3_10non_nestedENS3_9is_lexemeEEEEENSY_IS12_S15_S12_S19_S1A_S1B_EEEENS3_16iteration_policyEEENS3_12match_policyENS3_13action_policyEEEEEEEEE
N5boost6spirit7classic4impl15concrete_parserINS1_8sequenceINS1_16assertive_parserINSt3__112basic_stringIcNS6_11char_traitsIcEENS6_9allocatorIcEEEENS1_11alternativeINS1_4ruleINS1_7scannerINS6_11__wrap_iterIPcEENS1_16scanner_policiesINS1_28skip_parser_iteration_policyINSD_INSD_INS1_12space_parserENS1_13confix_parserINS1_6strlitIPKcEENS1_11kleene_starINS1_14anychar_parserEEENSD_INS1_10eol_parserENS1_10end_parserEEENS1_21unary_parser_categoryENS1_10non_nestedENS1_9is_lexemeEEEEENSM_ISQ_ST_SQ_SX_SY_SZ_EEEENS1_16iteration_policyEEENS1_12match_policyENS1_13action_policyEEEEENS1_5nil_tES1A_EES1B_EEEENS5_ISC_SV_EEEES19_S1A_EE
N5boost6spirit7classic4impl15abstract_parserINS1_7scannerINSt3__111__wrap_iterIPcEENS1_16scanner_policiesINS1_28skip_parser_iteration_policyINS1_11alternativeINSB_INS1_12space_parserENS1_13confix_parserINS1_6strlitIPKcEENS1_11kleene_starINS1_14anychar_parserEEENSB_INS1_10eol_parserENS1_10end_parserEEENS1_21unary_parser_categoryENS1_10non_nestedENS1_9is_lexemeEEEEENSD_ISH_SK_SH_SO_SP_SQ_EEEENS1_16iteration_policyEEENS1_12match_policyENS1_13action_policyEEEEENS1_5nil_tEEE
N5boost16exception_detail10clone_implINS0_19error_info_injectorINS_6spirit7classic12parser_errorINSt3__112basic_stringIcNS6_11char_traitsIcEENS6_9allocatorIcEEEENS6_11__wrap_iterIPcEEEEEEEE
N5boost16exception_detail19error_info_injectorINS_6spirit7classic12parser_errorINSt3__112basic_stringIcNS5_11char_traitsIcEENS5_9allocatorIcEEEENS5_11__wrap_iterIPcEEEEEE
N5boost6spirit7classic4impl15concrete_parserINS1_8sequenceINS1_6actionINS1_5chlitIcEENS_13property_tree11json_parser7contextINS8_11basic_ptreeINSt3__112basic_stringIcNSC_11char_traitsIcEENSC_9allocatorIcEEEESI_NSC_4lessISI_EEEEE10a_object_sEEENS1_11alternativeINS5_IS7_NSM_10a_object_eEEENS4_INS1_11list_parserINS1_4ruleINS1_7scannerINSC_11__wrap_iterIPcEENS1_16scanner_policiesINS1_28skip_parser_iteration_policyINSP_INSP_INS1_12space_parserENS1_13confix_parserINS1_6strlitIPKcEENS1_11kleene_starINS1_14anychar_parserEEENSP_INS1_10eol_parserENS1_10end_parserEEENS1_21unary_parser_categoryENS1_10non_nestedENS1_9is_lexemeEEEEENS11_IS15_S18_S15_S1C_S1D_S1E_EEEENS1_16iteration_policyEEENS1_12match_policyENS1_13action_policyEEEEENS1_5nil_tES1P_EES7_NS1_16no_list_endtokenENS1_21plain_parser_categoryEEENS1_16assertive_parserISI_SR_EEEEEEEES1O_S1P_EE
N5boost6spirit7classic4impl15concrete_parserINS1_8sequenceINS4_INS1_16assertive_parserINSt3__112basic_stringIcNS6_11char_traitsIcEENS6_9allocatorIcEEEENS1_6actionINS1_4ruleINS1_7scannerINS6_11__wrap_iterIPcEENS1_16scanner_policiesINS1_28skip_parser_iteration_policyINS1_11alternativeINSL_INS1_12space_parserENS1_13confix_parserINS1_6strlitIPKcEENS1_11kleene_starINS1_14anychar_parserEEENSL_INS1_10eol_parserENS1_10end_parserEEENS1_21unary_parser_categoryENS1_10non_nestedENS1_9is_lexemeEEEEENSN_ISR_SU_SR_SY_SZ_S10_EEEENS1_16iteration_policyEEENS1_12match_policyENS1_13action_policyEEEEENS1_5nil_tES1B_EENS_13property_tree11json_parser7contextINS1D_11basic_ptreeISC_SC_NS6_4lessISC_EEEEE6a_nameEEEEENS5_ISC_NS1_5chlitIcEEEEEENS5_ISC_S1C_EEEES1A_S1B_EE
N5boost6spirit7classic4impl15concrete_parserINS1_16assertive_parserINSt3__112basic_stringIcNS5_11char_traitsIcEENS5_9allocatorIcEEEENS1_4ruleINS1_7scannerINS5_11__wrap_iterIPcEENS1_16scanner_policiesINS1_28skip_parser_iteration_policyINS1_11alternativeINSJ_INS1_12space_parserENS1_13confix_parserINS1_6strlitIPKcEENS1_11kleene_starINS1_14anychar_parserEEENSJ_INS1_10eol_parserENS1_10end_parserEEENS1_21unary_parser_categoryENS1_10non_nestedENS1_9is_lexemeEEEEENSL_ISP_SS_SP_SW_SX_SY_EEEENS1_16iteration_policyEEENS1_12match_policyENS1_13action_policyEEEEENS1_5nil_tES19_EEEES18_S19_EE
N5boost6spirit7classic4impl15concrete_parserINS1_11alternativeINS4_INS4_INS1_6actionINS1_4ruleINS1_7scannerINSt3__111__wrap_iterIPcEENS1_16scanner_policiesINS1_28skip_parser_iteration_policyINS4_INS4_INS1_12space_parserENS1_13confix_parserINS1_6strlitIPKcEENS1_11kleene_starINS1_14anychar_parserEEENS4_INS1_10eol_parserENS1_10end_parserEEENS1_21unary_parser_categoryENS1_10non_nestedENS1_9is_lexemeEEEEENSF_ISJ_SM_SJ_SQ_SR_SS_EEEENS1_16iteration_policyEEENS1_12match_policyENS1_13action_policyEEEEENS1_5nil_tES13_EENS_13property_tree11json_parser7contextINS15_11basic_ptreeINS8_12basic_stringIcNS8_11char_traitsIcEENS8_9allocatorIcEEEES1E_NS8_4lessIS1E_EEEEE12a_string_valEEENS5_INS4_INS4_INS4_IS14_SJ_EESJ_EESJ_EENS1I_13a_literal_valEEEEES14_EES14_EES12_S13_EE
N5boost6spirit7classic4impl15concrete_parserINS1_8sequenceINS4_INS4_INS1_8optionalINS1_5chlitIcEEEENS1_11alternativeIS7_NS4_INS1_5rangeIcEENS1_11kleene_starINS1_12digit_parserEEEEEEEEENS5_INS4_IS7_NS1_8positiveISD_EEEEEEEENS5_INS4_INS4_INS1_5chsetIcEENS5_ISO_EEEESJ_EEEEEENS1_7scannerINSt3__111__wrap_iterIPcEENS1_16scanner_policiesINS1_28skip_parser_iteration_policyINS9_INS9_INS1_12space_parserENS1_13confix_parserINS1_6strlitIPKcEENSC_INS1_14anychar_parserEEENS9_INS1_10eol_parserENS1_10end_parserEEENS1_21unary_parser_categoryENS1_10non_nestedENS1_9is_lexemeEEEEENS12_IS16_S18_S16_S1C_S1D_S1E_EEEENS1_16iteration_policyEEENS1_12match_policyENS1_13action_policyEEEEENS1_5nil_tEEE
N5boost6detail17sp_counted_impl_pINS_6spirit7classic11basic_chsetIcEEEE
N5boost6spirit7classic4impl15concrete_parserINS1_8positiveINS1_10contiguousINS1_13confix_parserINS1_5chlitIcEENS1_11kleene_starINS1_4ruleINS1_7scannerINSt3__111__wrap_iterIPcEENS1_16scanner_policiesINS1_27no_skipper_iteration_policyINS1_28skip_parser_iteration_policyINS1_11alternativeINSJ_INS1_12space_parserENS6_INS1_6strlitIPKcEENS9_INS1_14anychar_parserEEENSJ_INS1_10eol_parserENS1_10end_parserEEENS1_21unary_parser_categoryENS1_10non_nestedENS1_9is_lexemeEEEEENS6_ISO_SQ_SO_SU_SV_SW_EEEENS1_16iteration_policyEEEEENS1_12match_policyENS1_13action_policyEEEEENS1_5nil_tES18_EEEES8_SU_SV_NS1_10non_lexemeEEEEEEENSB_ISF_NSG_IS12_S14_S15_EEEES18_EE
N5boost6spirit7classic4impl15concrete_parserINS1_11alternativeINS1_6actionINS1_10differenceINS6_INS1_14anychar_parserENS1_6strlitIPKcEEEESB_EENS_13property_tree11json_parser7contextINSE_11basic_ptreeINSt3__112basic_stringIcNSI_11char_traitsIcEENSI_9allocatorIcEEEESO_NSI_4lessISO_EEEEE6a_charEEENS1_8sequenceINS1_5chlitIcEENS1_16assertive_parserISO_NS1_4ruleINS1_7scannerINSI_11__wrap_iterIPcEENS1_16scanner_policiesINS1_27no_skipper_iteration_policyINS1_28skip_parser_iteration_policyINS4_INS4_INS1_12space_parserENS1_13confix_parserISB_NS1_11kleene_starIS7_EENS4_INS1_10eol_parserENS1_10end_parserEEENS1_21unary_parser_categoryENS1_10non_nestedENS1_9is_lexemeEEEEENS18_ISB_S1A_SB_S1E_S1F_S1G_EEEENS1_16iteration_policyEEEEENS1_12match_policyENS1_13action_policyEEEEENS1_5nil_tES1S_EEEEEEEES1R_S1S_EE
N5boost6spirit7classic4impl15abstract_parserINS1_7scannerINSt3__111__wrap_iterIPcEENS1_16scanner_policiesINS1_27no_skipper_iteration_policyINS1_28skip_parser_iteration_policyINS1_11alternativeINSC_INS1_12space_parserENS1_13confix_parserINS1_6strlitIPKcEENS1_11kleene_starINS1_14anychar_parserEEENSC_INS1_10eol_parserENS1_10end_parserEEENS1_21unary_parser_categoryENS1_10non_nestedENS1_9is_lexemeEEEEENSE_ISI_SL_SI_SP_SQ_SR_EEEENS1_16iteration_policyEEEEENS1_12match_policyENS1_13action_policyEEEEENS1_5nil_tEEE
N5boost6spirit7classic4impl15concrete_parserINS1_11alternativeINS1_6actionINS1_5chsetIcEENS_13property_tree11json_parser7contextINS8_11basic_ptreeINSt3__112basic_stringIcNSC_11char_traitsIcEENSC_9allocatorIcEEEESI_NSC_4lessISI_EEEEE8a_escapeEEENS1_8sequenceINS1_5chlitIcEENS5_INS1_11uint_parserImLi16ELj4ELi4EEENSM_9a_unicodeEEEEEEENS1_7scannerINSC_11__wrap_iterIPcEENS1_16scanner_policiesINS1_27no_skipper_iteration_policyINS1_28skip_parser_iteration_policyINS4_INS4_INS1_12space_parserENS1_13confix_parserINS1_6strlitIPKcEENS1_11kleene_starINS1_14anychar_parserEEENS4_INS1_10eol_parserENS1_10end_parserEEENS1_21unary_parser_categoryENS1_10non_nestedENS1_9is_lexemeEEEEENS16_IS1A_S1D_S1A_S1H_S1I_S1J_EEEENS1_16iteration_policyEEEEENS1_12match_policyENS1_13action_policyEEEEENS1_5nil_tEEE
N5boost16exception_detail10clone_implINS0_19error_info_injectorINS_13property_tree14ptree_bad_pathEEEEE
N5boost16exception_detail19error_info_injectorINS_13property_tree14ptree_bad_pathEEE
N5boost3any6holderINS_13property_tree11string_pathINSt3__112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEENS2_13id_translatorISA_EEEEEE
N5boost3any11placeholderE
N5boost13property_tree11string_pathINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEENS0_13id_translatorIS8_EEEE
NSt3__120__shared_ptr_emplaceI13NNetExtractorNS_9allocatorIS1_EEEE
NSt3__114basic_ifstreamIcNS_11char_traitsIcEEEE
fact
xxxx
caff
desc
data
N7PCMFile6ReaderE
12PCMProcessor
13PCMReader_WAV
13PCMReader_CAF
N7PCMFile6WriterE
13PCMWriter_WAV
13PCMWriter_CAF
11PCMByteSwapIiE
11PCMByteSwapIsE
14PCMScaleSampleIffE
14PCMScaleSampleIfsE
14PCMScaleSampleIisE
14PCMScaleSampleIfiE
14PCMScaleSampleIifE
14PCMScaleSampleIsfE
14PCMScaleSampleIsiE
12PCMPackInt24ILb1EE
12PCMPackInt24ILb0EE
15PCMExtractInt24IsLb1EE
15PCMExtractInt24IfLb1EE
15PCMExtractInt24IiLb1EE
15PCMExtractInt24IsLb0EE
15PCMExtractInt24IfLb0EE
15PCMExtractInt24IiLb0EE
15PCMDeinterleaveIsE
15PCMDeinterleaveIiE
N5boost13property_tree14ptree_bad_dataE
9Predictor
NSt3__119basic_istringstreamIcNS_11char_traitsIcEENS_9allocatorIcEEEE
N5boost16exception_detail10clone_implINS0_19error_info_injectorINS_13property_tree14ptree_bad_dataEEEEE
N5boost16exception_detail19error_info_injectorINS_13property_tree14ptree_bad_dataEEE
N5boost3any6holderINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEEE
NSt3__112basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEE
NSt3__121__basic_string_commonILb1EEE
12PredictorMDN
0@333333
@333333
!)@{
K;;:a
;R`T;E
;kz<
Uf<{-
s?k?P5
)T<r
3=<kz<
:R`T;S
<Dd0<
NF<E
p?aJo
0!<<
(><Dd0<
g>Wq
{!>[
$'9N"
^:O6
RO;j
Missing language in voice data:%@
Can't find request language %@ in default languages
Built in voice is requested.
Search voice asset for lang: %@, type: %@, gender: %@, footprint: %@
Gryphon voice not found, search custom voice asset with same gender
Search voice asset with same type but undefined gender
Search all available voice assets with same gender
Fallback to built-in voice for lang: %@
Selected %@
Couldn't found any built in voice for lang: %@
%@, %@
Try downloading voice %@
Can't download due to unfound asset: %@
Unable to download voice that is not well defined: %@
Resume download: %@
adjust download: %@
Start download: %@
Asset is already installed or is downloading: %@
Purge asset: %@
Can't remove asset %@
reinstall asset: %@
Unable to clean asset: %@, error:%@
Purged asset: %@
Failed to convert %ld recognition results
compact explicitly specified, look at framework asset first
Now looking for the fallback language: %@
Looking for the resources in %@
Can't find the resources anywhere!
Found the resources here: %@
No TTS resources for asset. Trying fallback language for %@
Using asset fallback language %@
Couldn't get the engine format version for language %@
VoiceEngineFormatVersions hasn't been initialized, voices may not be compatible
Trying to migrate asset because it's not valid: %@
After migrating asset, it's still not valid -- sorry
---> asset's version is %@
---> engine's version is %@
Couldn't get asset's version and/or language
Deleting the asset located here: %@ because the format versions don't match
***ERROR*** There was an error (%d - %s) when trying to symlink %s to %s
Symlinked %s to %s
Successfully appended broker header files
***ERROR*** couldn't append broker header files (%d - %s)
***ERROR*** couldn't move broker header file to final location (%d - %s)
Couldn't initialize the engine voice format versions
Unable to lock temporary asset: %s; presumably peer was first - error: %d
Temporary asset: %s has moved; presumably peer was first - error: %d
Couldn't move the temporary asset: %s to the real asset: %s - error: %d
Moved the temporary asset: %s to the real asset: %s
Couldn't get the contents of the assets directory (error %ld)
Deleting asset at url: %@
Enqueuing request: %@
Queue is now:
#Deprecated  %s, called from '%@'
Unable to locate preview sample file for %@
#SpeechRequest client:%@, string:%@, attrString:%@, saveToURL:%@, language:%@, type:%@, gender:%@, footprint:%@
Can't prewarm %@
Error %@ asking for voices
@mcpl
