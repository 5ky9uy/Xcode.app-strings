N11InputEngine15CandidateClonerI22ChineseStringCandidateEE
9CloneableIN11InputEngine20MecabraCandidateBaseEE
22ChineseStringCandidate
N5MeCab5MutexE
NSt3__119basic_ostringstreamIcNS_11char_traitsIcEENS_9allocatorIcEEEE
NSt3__115basic_stringbufIcNS_11char_traitsIcEENS_9allocatorIcEEEE
NSt3__120__shared_ptr_pointerIPN11InputEngine13LanguageModelENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN11InputEngine13LanguageModelEEE
NSt3__120__shared_ptr_pointerIPN11InputEngine19LanguageModelLoaderENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN11InputEngine19LanguageModelLoaderEEE
N7Seaweed23SingleWordCandidateWordE
N11InputEngine13MecabraStrokeE
N11InputEngine30MecabraSimplifiedChineseStrokeE
N11InputEngine31MecabraTraditionalChineseStrokeE
NSt3__117bad_function_callE
NSt3__110__function6__funcIZN3nlp11CFScopedPtrIPK10__CFStringE5resetES6_EUlPKvE_NS_9allocatorISA_EEFvS9_EEE
NSt3__110__function6__baseIFvPKvEEE
ZN3nlp11CFScopedPtrIPK10__CFStringE5resetES3_EUlPKvE_
N11InputEngine27MecabraCharacterInputEngineE
NSt3__110__function6__funcIZN3nlp11CFScopedPtrIPK10__CFStringE7acquireES6_EUlPKvE_NS_9allocatorISA_EEFvS9_EEE
ZN3nlp11CFScopedPtrIPK10__CFStringE7acquireES3_EUlPKvE_
N11InputEngine14MecabraCangjieE
NSt3__114basic_ifstreamIcNS_11char_traitsIcEEEE
NSt3__113basic_filebufIcNS_11char_traitsIcEEEE
NSt3__120__shared_ptr_pointerIPN11InputEngine12CharacterMapENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN11InputEngine12CharacterMapEEE
NSt3__120__shared_ptr_pointerIPN7Seaweed36SeaweedFileMappedImmutableDictionaryENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN7Seaweed36SeaweedFileMappedImmutableDictionaryEEE
22InspectorAccessContext
N11InputEngine19ConversionCandidateE
N11InputEngine15CandidateClonerI28SyntheticConversionCandidateEE
34ZhuyinSyntheticConversionCandidate
0EN11InputEngine15CandidateClonerINS_34MecabraJapaneseConversionCandidateEEE
N11InputEngine32MecabraJapaneseAcceptedCandidateE
25SyncMutableCFSpecificTypeIP14__CFDictionaryE
16SyncMutableCFRef
22IDXBuiltInAccessMethodI17TrieAccessContextE
15IDXAccessMethod
22IDXBuiltInAccessMethodI17HeapAccessContextE
22IDXBuiltInAccessMethodI22InspectorAccessContextE
N11InputEngine15CandidateClonerI18SyntheticCandidateEE
18SyntheticCandidate
22SyntheticCandidateWord
16IDXAccessContext
17HeapAccessContext
17TrieAccessContext
NSt3__114basic_ofstreamIcNS_11char_traitsIcEEEE
N5MeCab10scoped_ptrINSt3__112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEEEE
N5MeCab10MemoryPoolINSt3__112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEENS_4MmapIcEEEE
N5MeCab4MmapIcEE
N5MeCab10DictionaryE
N5MeCab17MutableDictionaryE
N5MeCab13scoped_stringE
N5MeCab12scoped_arrayIcEE
N5MeCab10scoped_ptrINS_18DictionaryRewriterEEE
N5MeCab10scoped_ptrINS_14POSIDGeneratorEEE
N5MeCab10scoped_ptrINS_9ContextIDEEE
NSt3__112basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEE
NSt3__121__basic_string_commonILb1EEE
21ChineseCompletionWord
N5MeCab5ParamE
N5MeCab12FeatureIndexE
N5MeCab13ChunkFreeListIiEE
N5MeCab13ChunkFreeListIcEE
N5MeCab12CharPropertyE
N)N+N.N@NGNHN
ZNiN
N,4.4
OdO7O>OTOXO
wOxOzO}O
P"Ph4BPFPNPSPWPcPfPjPpP
UR\RlRwR
S$S5S>SBS
gSlSzS
]5^5
SUT$T(Tn5CTbTfTlT
<UAU
5GUJU
5`UaUdU
V0V7V
5=V?V@VGV^V`VmV
EWFWLWMW
hWoWsWtWuW{W
 X'X2X9X
IXLXgX
[Y_Y
uYvY|Y
Z'Z-ZUZeZzZ
[4[-[L[R[h[o[|[
[l7k7
\)\0\
_\c\g\h\i\p\
] ]$]&]1]9]B]
7a]j]
^.^>^I^\8V^a8k^l^m^
_G_c_r_~_
`"`$`
a:ao9AaFa`a|a
b#b)bFbLbQbRbabdb{bmbsb
2c5c;c<cAcDcNc
d%d)d/dZd[d]dsd}d
e2eDeTekeze
f!f*fEfQfNf
[fcf
jfkflfmf{f
LgMgTg]g
tgvg
3h;h>hDhEhIhLhUhWhw;khnhzh|h
;Fiiilirizi
2j3j4j?jFjIjzjNjRjdj
k&</kJkXklkukzk
l5l6l:l
?lMl[lml
m$m&m'mgl/m<m[m^m`mpm
n"n'n
=2n<nHnInKnLnOnQnSnTnWncn
o%o6o<o
RoWoZo`oho
9p:p<pCpGpKp
=Tpepiplpnpvp~p
=/q1qPqJqSq^q
+r4r8r9r,NBrSrWrcr
nrorxr
rf>h>
>9s,s1s3s=sRs
>ksls
nsosqsws
t$t1t9tSt@tCtMtRt]tqt
 u$u*uW?
=u>u@uHuNuPuRuluruquzu}u~u
%v(v<v3v
IvUv
w-w5w
Xw`wjw
rw|w}w
x!x,xGxdxjx
y0y%y;yJyXy[y
Agyry
zcA-z
8zGzLzVzYz\z_z`zgzjzuzxz
={'{*{.{/{1{
AU{y{d{f{i{s{
|&|E|J|Q|W|^|a|i|n|o|p|
=}>}@}G}
BY}Z}j}p}
~ ~'~,~E~s~u~~~
~CC<
%ECE>
& % 
f"g"
"4"B&@&
2 3 
304050;0<0
"*")"
#'"("
"%"&"
"a"R"j"k"
"5"+","b"C"E"H"v"w"
!+!0 o&m&j&  ! 
n&k&l&i&
!4)5)
%=0F
%" !
!'!A
A0B0C0D0E0F0G0H0I0J0K0L0M0N0O0P0Q0R0S0T0U0V0W0X0Y0Z0[0\0]0^0_0`0a0b0c0d0e0f0g0h0i0j0k0l0m0n0o0p0q0r0s0t0u0v0w0x0y0z0{0|0}0~0
0K0M0O0Q0S0
d&`&b&f&a&e&g&c&
"S!T!U!
%,%$%4%<%
%#%3%+%;%K% %/%(%7%?%
%0%%%8%B%Q2R2S2T2U2V2W2X2Y2Z2[2\2]2^2_2
%< G H I 
v'w'x'y'z'{'|'}'~'
$p!q!r!s!t!u!v!w!x!y!z!{!
Q B 
`$a$b$c$d$e$f$g$h$i$j$k$l$m$n$o$p$q$r$s$`!a!b!c!d!e!f!g!h!i!j!I3
3"3M3
363Q3W3
3&3#3+3J3;3
2122292~3}3|3
4(N/N0N
O`OHOIOVO_OjOlO~O
P'P.P@P;PAP
Q5QJQ2
UQWQ
RIRWRaR
aScS}S
T'TMT
TkTtT
U+U5UPU^U
V;VIVvVfV8
oVqVrV
!W/W3W4WpWwW|W
aXdX9
XYA
]YmY
Z#ZgZmZwZ~Z
pOupu
AQpS
U0[q_ f
l)m[t
vNz4
W0XDY
eZl%u
Q.YeY
e*j'k
vharYN
OxSi`)nOz
NUO=O
bYr;u
hwmppLu
d<h8h
\}iM
c {+j
_orR
*h\Q
[r^y^
h>kSkWl"o
8N+T
sLv<w
\^~^
_j0^
uHyc[
UThXjp
'xug
_%`Qe=gBlrl
c nZ
QTS!S
\7_J_/`P`m`
cYeKj
fmi@\
e#k=k4t
]N6P
UzzvP
Q\H\
hp~Qhl
RDQSU-W
WQYb_
_u`vaga
c:dleofBh
nfu=z
}K~k
P kzlTotzP}@
N9P&PeP|Q8RcR
i)j}r
xoxy}w
S{^&_
sC}7
^'_8bEe
OHSIT>T/Z
PIQlQ
W}YT[][
_R`La
fmg!h
i_l*mim/n
vlx?z
KQ;RJT
V@zw
XZZh`
u:}n
[i_Mb
c=hsk
x&xmy
dR(WPgj
QBW*
\OJR
T>d(f
zV{"}/
dce_h
YP[M\
c/e\[
gbk{k
lEsIy
OPQW[
x:y
\hcf
enq>y
R:\Sg|p5rL
[Kb1g
s.zk
yB}M~
NOOEQAS
ncs&~
m]y.~
R SGS
TFU1U
ff-fvf~g
nXn<q&qgq
X"[8^
dagVgDm
rsucz
qT~w
;\8O
_Na/c
u=\N
]i]pe
ncIg
N,p]u/f
b?ete
wMzM|>~
NHQCS`S
]&bGb
g\oNq}q
U8o6qhQ
|LVQX
| }D}
XOY=r
OtPGRsSo`Ic_g,n
cX[k[
dQg\
Y*YplQ
_ `Ka4b
S'Y,{
n'pSSDU
SFOT
9NXS
_e`zf`l
Z@w-N
j&p*s
_5_k_
gnoRr:u:wt
iCO,o
?ipojW
X,[,}*r
NNO\PuPCR
HT$X
xQkX)YU\
T5XWX
e\g!n{v
%x:x
UTXXXWY
b-dqgCh
uwyI{T{R{
|q}0R
myrcw
z4iJ\
pxVo\
XpzcK
~wuWS`i
esNeQ
l>m6t4xFZu
cWeog
hsidq
/OeRZS
Qu`ukQb
zVYX
4O$RJS
g>lNlHr
sTuA~,
=cifju
*SQS&T
`Ibyb
_buF{<
}~v,
thyh
W+YfZ
`vbwe
enfnm6r&{P
R;TtV
NuOuQ@Xc^s^
g&N=
WUcik+u
SFT1XIY
bgc>e
p2x+~
PVRJW
d4ggrfwFz
XL^TY,g
sT*gE
R"Y!q_r
xd!j
2Q(g
$\;b~|
Y:r6
/UQO*Q
m6s7s1uPy
ma}=
qNuSP]
Te\Ng
tYukx
`tAX
m/}^
a#oIq>|
A[V[}[
\#\+\
7b\;
F]G]S]J]m]
N*N1N6N<N?NBNVNXN
OZO0O[O]OWOGOvO
O{OiOpO
P*P%P
O!P)P,P
PCPGP
gUPPPHPZPVPlPxP
Q!Q:Q7Q<Q;Q?Q@QRQLQTQbQ
ziQjQnQ
R'R*R.R3R9RORDRKRLR^RTRjRtRiRsR
S#S/S1S3S8S@SFSES
NISMS
Q^SiSnS
Y{SwS
T=T@T,T-T<T.T6T)T
T_TqTwTpT
T9U@UcULU.U\UEUVUWU8U3U]U
U{U~U
UNVPV
q4V6V2V8VkVdV/VlVjV
W&W7W8WNW;W@WOWiW
XrX!XbXKXpX
kRX=XyX
h%Y,Y-Y2Y8Y>Y
zUYPYNYZYXYbY`YgYlYiY
Z@ZlZIZ5Z6ZbZjZ
Z*[6[>[C[E[@[Q[U[Z[[[e[i[p[s[u[x[
\ \"\(\8\9\A\F\N\S\
P\O\q[l\n\bNv\y\
]L]R]N]K]l]s]v]
^6^7^D^C^@^N^W^T^_^b^d^G^u^v^z^
_]_\_
_)_-_8_A_H_L_N_/_Q_V_W_Y_a_m_s_w_
_!```
`+`&`
`:`Z`A`j`w`_`J`F`M`c`C`d`B`l`k`Y`
aGa>a(a'aJa?a<a,a4a=aBaDasawaXaYaZakataoaeaqa_a]aSaua
b!b*b.b0b2b3bAbNb^bcb[b`bhb|b
bPc>cMc
ckcic
d&d6d
dgdodvdNd*e
e$e#e+e4e5e7e6e8eKuHeVeUeMeXe^e]erexe
esg5f6f4f
fOfDfIfAf^f]fdfgfhf_fbfpf
g&g'g8
.g?g6gAg8g7gFg^g`gYgcgdg
g|gjg
hFh)h@hMh2hNh
h+hYhchwh
h"i&i
h(i*i
i#i!i
hyiwi\ixikiTi~ini9iti=iYi0iai^i]i
jDjjrj6jxjGjbjYjfjHj8j"j
k8k7k
GkCkIkPkYkTk[k_kakxkyk
l$l#l^lUlbljl
l~lhlsl
6m+m=m8m
m5m3m
mmcm
mdmZmymYm
m-nnn.n
nrn_n>n#nkn+nvnMn
nCn:nNn$n
ozoxo
ooo[o
o|oXo
p0p>p2pQpcp
qeqUq
qfqbqLqVqlq
r(r-r,r0r2r;r<r?r@rFrKrXrtr~r
s4s/s)s%s>sNsOs
Wsjshspsxsus{szs
tot%t
s2t:tUt?t_tYtAt\titptctjtvt~t
u&u,u<uDuMuJuIu[uFuZuiudugukumuxuvu
v'v v!v"v$v4v0v;vGvHvFv\vXvavbvhvivjvgvlvpv
rvvvxv|v
w)w$w
w%w&w
w7w8wGwZwhwkw[wew
w~wyw
x&y x*yEx
y,y+y@y`yWy_yZyUySyzy
y1z;z>z7zCzWzIzazbziz
pzyz}z
{5{({6{P{
{L{E{u{e{t{g{p{q{l{n{
{#|'|*|
|7|+|=|L|C|T|O|@|P|X|_|d|V|e|l|u|
}E}K}.}2}?}5}F}s}V}N}r}h}n}O}c}
~#~!~
~"~F~f~;~5~9~C~7~2~:~g~]~V~^~Y~Z~y~j~i~|~{~
^X^^^
_#_4_6_=_@_E_T_X_d_g_}_
`3`5`G`=
a+a0a7a>
"b>bCbVbZbob
c9cCcec|c
d"dydQd`dmd
d"e)eA
f:f"f$f+f0f1f3f
fHfLf
YfZfafefsfwfxf
3gfgGgHg{g
h,h1h[hrhuhD
5iBiWicidihi
;j>jEjPjVj[jkjsj
k,k5kFkVk`kekgkwk
l3lYl\l
ltlvl
m.m1m9m?mXmemE
4nDn\n^n
*o/o3oQoYo^oaobo~o
p(pJp]p^pNpdpup
q q.q0qFqGqQqH
Rq\q`qhq
rUrVr?>
's(s
Psfs|s
&t(t*t+t,t.t/t0tDtFtGtKtWtbtktmt
u/uouyu
v-v5vCvKvdvevmvovqv
w4w6wFwMwNw\w_wbwzw
CxNxOxQxhxnxK
y.y1y4yL
EyFyN
9z]zmzU
{-{;{G{N{`{m{o{r{
| |3|6|dB
Y|m|y|
}#}1}
A}H}S}\}z}
G~R~a~
SD[D`
& % 
f"g"
"4"B&@&
2 3 
"*")"
'"("
"a"R"j"k"
"5"+","
+!0 o&m&j&  ! 
A0B0C0D0E0F0G0H0I0J0K0L0M0N0O0P0Q0R0S0T0U0V0W0X0Y0Z0[0\0]0^0_0`0a0b0c0d0e0f0g0h0i0j0k0l0m0n0o0p0q0r0s0t0u0v0w0x0y0z0{0|0}0~0
%,%$%4%<%
%#%3%+%;%K% %/%(%7%?%
%0%%%8%B%
`$a$b$c$d$e$f$g$h$i$j$k$l$m$n$o$p$q$r$s$`!a!b!c!d!e!f!g!h!i!
3"3M3
363Q3W3
3&3#3+3J3;3
2122292~3}3|3R"a"+"."
"5")"*"
pOupu
AQpS
U0[q_ f
l)m[t
vNz4
W0XDY
eZl%u
Q.YeY
e*j'k
vharYN
OxSi`)nOz
NUO=O
bYr;u
hwmppLu
d<h8h
\}iM
c {+j
_orR
*h\Q
[r^y^
h>kSkWl"o
8N+T
sLv<w
\^~^
_j0^
uHyc[
UThXjp
'xug
_%`Qe
=gBlrl
c nZ
QTS!S
\7_J_/`P`m`
cYeKj
fmi@\
e#k=k4t
]N6P
UzzvP
Q\H\
hp~Qhl
RDQSU-W
WQYb_
_u`vaga
c:dleofBh
nfu=z
}K~k
P kzlTotzP}@
N9P&PeP|Q8RcR
i)j}r
xoxy}w
S{^&_
sC}7
^'_8bEe
OHSIT>T/Z
PIQlQ
W}YT[][
_R`La
fmg!h
i_l*mim/n
vlx?z
KQ;RJT
V@zw
XZZh`
u:}n
[i_Mb
c=hsk
x&xmy
dR(WPgj
QBW*
\OJR
T>d(f
zV{"}/
dce_h
YP[M\
c/e\[
lEsIy
OPQW[
cBf!k
x:y
\hcf
enq>y
R:\Sg|p5rL
[Kb1g
s.zk
yB}M~
NOOEQAS
ncs&~
m]y.~
R SGS
TFU1U
ff-fvf~g
nXn<q&qgq
X"[8^
dagVgDm
rsucz
qT~w
;\8O
_Na/c
u=\N
]i]pe
ncIg
N,p]u/f
b?ete
wMzM|>~
NHQCS`S
]&bGb
g\oNq}q
U8o6qhQ
|LVQX
| }D}
XOY=r
OtPGRsSo`Ic_g,n
cX[k[
dQg\
Y*YplQ
_ `Ka4b
S'Y,{
n'pSSDU
SFOT
9NXS
_e`zf`l
Z@w-N
j&p*s
_5_k_
gnoRr:u:wt
iCO,o
?ipojW
X,[,}*r
NNO\PuPCR
HT$X
xQkX)YU\
T5XWX
e\g!n{v
%x:x
UTXXXWY
b-dqgCh
uwyI{T{R{
|q}0Rc
myrcw
z4iJ\
pxVo\
XpzcK
~wuWS`i
esNeQ
l>m6t4xFZu
cWeog
sidq
/OeRZS
Qu`ukQb
zVYX
4O$RJS
g>lNlHr
sTuA~,
=cifju
*SQS&T
`Ibyb
_buF{<
}~v,
thyh
W+YfZ
`vbwe
enfnm6r&{P
R;TtV
NuOuQ@Xc^s^
g&N=
WUcik+u
SFT1XIY
bgc>e
p2x+~
PVRJW
d4ggrfwFz
XL^TY,g
sT*gE
R"Y!q_r
xd!j
2Q(g
$\;b~|
Y:r6
/UQO*Q
m6s7s1uPy
ma}=
qNuSP]
Te\Ng
tYukx
`tAX
m/}^
a#oIq>|
N*N1N6N<N?NBNVNXN
OZO0O[O]OWOGOvO
O{OiOpO
P*P%P
O!P)P,P
PCPGP
gUPPPHPZPVPlPxP
Q!Q:Q7Q<Q;Q?Q@QRQLQTQbQ
ziQjQnQ
R'R*R.R3R9RORDRKRLR^RTRjRtRiRsR
S#S/S1S3S8S@SFSES
NISMS
Q^SiSnS
Y{SwS
T=T@T,T-T<T.T6T)T
T_TqTwTpT
T9U@UcULU.U\UEUVUWU8U3U]U
U{U~U
UNVPV
q4V6V2V8V
kVdV/VlVjV
W&W7W8WNW;W@WOWiW
XrX!XbXKXpX
kRX=XyX
h%Y,Y-Y2Y8Y>Y
zUYPYNYZYXYbY`YgYlYiY
Z@ZlZIZ5Z6ZbZjZ
Z*[6[>[C[E[@[Q[U[Z[[[e[i[p[s[u[x[
\ \"\(\8\9\A\F\N\S\P\O\q[l\n\bNv\y\
]L]R]N]K]l]s]v]
^6^7^D^C^@^N^W^T^_^b^d^G^u^v^z^
_]_\_
_)_-_8_A_H_L_N_/_Q_V_W_Y_a_m_s_w_
_!```
`+`&`
`:`Z`A`j`w`_`J`F`M`c`C`d`B`l`k`Y`
aGa>a(a'aJa?a<a,a4a=aBaDasawaXaYaZakataoaeaqa_a]aSaua
b!b*b.b0b2b3bAbNb^bcb[b`bhb|b
bPc>cMc
d&d6d
dgdodvdNd*e
e$e#e+e4e5e7e6e8eKuHeVeUeMeXe^e]erexe
esg5f6f4f
fOfDfIfAf^f]fdfgfhf_fbfpf
g&g'g8
.g?g6gAg8g7gFg^g`gYgcgdg
g|gjg
hFh)h@hMh2hNh
h+hYhchwh
h"i&i
h(i*i
i#i!i
hyiwi\ixikiTi~ini9iti=iYi0iai^i]i
jDjjrj6jxjGjbjYjfjHj8j"j
k8k7k
GkCkIkPkYkTk[k_kakxkyk
l$l#l^lUlbljl
l~lhlsl
6m+m=m8m
m5m3m
mmcm
mdmZmymYm
m-nnn.n
nrn_n>n#nkn+nvnMn
nCn:nNn$n
ozoxo
ooo[o
o|oXo
p0p>p2pQpcp
qeqUq
qfqbqLqVqlq
r(r-r,r0r2r;r<r?r@rFrKrXrtr~r
s4s/s)s%s>sNsOs
Wsjshspsxsus{szs
tot%t
s2t:tUt?t_tYtAt\titptctjtvt~t
u&u,u<uDuMuJuIu[uFuZuiudugukumuxuvu
v'v v!v"v$v4v0v;vGvHvFv\vXvavbvhvivjvgvlvpvrvvvxv|v
w)w$w
w%w&w
w7w8wGwZwhwkw[wew
w~wyw
x&y x*yEx
y,y+y@y`yWy_yZyUySyzy
y1z;z>z7zCzWzIzazbziz
pzyz}z
{5{({6{P{z{
{L{E{u{e{t{g{p{q{l{n{
{#|'|*|
|7|+|=|L|C|T|O|@|P|X|_|d|V|e|l|u|
}E}K}.}2}?}5}F}s}V}N}r}h}n}O}c}
~#~!~
~"~F~f~;~5~9~C~7~
2~:~g~]~V~^~Y~Z~y~j~i~|~{~
fE_(N
O9OVO
O@P"P
PFPpPBP
PJQdQ
S$SrS
UYWeW
YSY[Y]YcY
\']S]
B]m]
]!_4_g_
a7a0a
f$fefWfYf
i0jkjFjsj~j
k?l\l
m9n\n'n<n
q\qFqGq
s&t*t)t.tbt
R!xNxdxzx0y
H}\}
}R~G
p!q!r!s!t!u!v!w!x!y!
p!q!r!s!t!u!v!w!x!y!`!a!b!c!d!e!f!g!h!i!
!!!5"
fE_(N
O9OVO
O@P"P
PFPpPBP
S$SrS
UYWeW
YSY[Y]YcY
\']S]
B]m]
]!_4_g_
a7a0a
f$fefWfYf
i0jkjFjsj~j
k?l\l
m9n\n'n<n
q\qFqGq
s&t*t)t.tbt
R!xNxdxzx0y
H}\}
}R~G
N5MeCab15ostream_wrapperE
N5MeCab15istream_wrapperE
NSt3__110__function6__funcIZN3nlp11CFScopedPtrIPK7__CFURLEC1ES6_EUlPKvE_NS_9allocatorISA_EEFvS9_EEE
ZN3nlp11CFScopedPtrIPK7__CFURLEC1ES3_EUlPKvE_
N6marisa9ExceptionE
NSt3__120__shared_ptr_pointerIP19JapaneseDynamicWordNS_14default_deleteIS1_EENS_9allocatorIS1_EEEE
NSt3__114default_deleteI19JapaneseDynamicWordEE
?ffffff
?N5MeCab19DecoderFeatureIndexE
N5MeCab19EncoderFeatureIndexE
N5MeCab5IconvE
z>-C
N5MeCab8FreeListI20mecab_learner_path_tEE
N5MeCab20EncoderLearnerTaggerE
N5MeCab13LearnerTaggerE
N5MeCab5LBFGSE
N5MeCab14learner_threadE
N5MeCab6threadE
N11InputEngine24ChineseAdaptationContextE
I@N5MeCab9ConnectorE
N5MeCab10MemoryPoolINSt3__112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEENS_4MmapIsEEEE
N5MeCab4MmapIsEE
N5MeCab10MemoryPoolINSt3__112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEENS_4MmapIjEEEE
N5MeCab4MmapIjEE
19JapaneseDynamicWord
N5MeCab15WordCoreAdaptorI11DynamicWordEE
4Word
N5MeCab8WordCoreE
21JapaneseWordExtension
N11InputEngine15CandidateClonerINS_17FacemarkCandidateEEE
N11InputEngine17FacemarkCandidateE
N5MeCab12StringBufferE
N5MeCab10TaggerImplE
N5MeCab6TaggerE
N5MeCab6WriterE
N5MeCab14NBestGeneratorE
N5MeCab8FreeListINS_14NBestGenerator12QueueElementEEE
N5MeCab10scoped_ptrINS_14NBestGeneratorEEE
N5MeCab13TokenizerImplI12mecab_node_t12mecab_path_tEE
N5MeCab13TokenizerImplI20mecab_learner_node_t20mecab_learner_path_tEE
N5MeCab8FreeListI12mecab_node_tEE
N5MeCab8FreeListI23mecab_dictionary_info_tEE
N5MeCab12scoped_arrayI25trie_search_result_type_tEE
N)N+N.N@NGNHN
ZNiN
N,4.4
OdO7O>OTOXO
wOxOzO}O
P"Ph4BPFPNPSPWPcPfPjPpP
UR\RlRwR
S$S5S>SBS
gSlSzS
]5^5
SUT$T(Tn5CTbTfTlT
<UAU
5GUJU
5`UaUdU
V0V7V
5=V?V@VGV^V`VmV
EWFWLWMW
hWoWsWtWuW{W
 X'X2X9X
IXLXgX
[Y_Y
uYvY|Y
Z'Z-ZUZeZzZ
[4[-[L[R[h[o[|[
[l7k7
\)\0\
_\c\g\h\i\p\
] ]$]&]1]9]B]
7a]j]
^.^>^I^\8V^a8k^l^m^
_G_c_r_~_
`"`$`
a:ao9AaFa`a|a
b#b)bFbLbQbRbabdb{bmbsb
2c5c;c<cAcDcNc
d%d)d/dZd[d]dsd}d
e2eDeTekeze
f!f*fEfQfNf
[fcf
jfkflfmf{f
LgMgTg]g
tgvg
3h;h>hDhEhIhLhUhWhw;khnhzh|h
;Fiiilirizi
2j3j4j?jFjIjzjNjRjdj
k&</kJkXklkukzk
l5l6l:l
?lMl[lml
m$m&m'mgl/m<m[m^m`mpm
n"n'n
=2n<nHnInKnLnOnQnSnTnWncn
o%o6o<o
RoWoZo`oho
9p:p<pCpGpKp
=Tpepiplpnpvp~p
=/q1qPqJqSq^q
+r4r8r9r,NBrSrWrcr
nrorxr
rf>h>
>9s,s1s3s=sRs
>ksls
nsosqsws
t$t1t9tSt@tCtMtRt]tqt
 u$u*uW?
=u>u@uHuNuPuRuluruquzu}u~u
%v(v<v3v
IvUv
w-w5w
Xw`wjw
rw|w}w
x!x,xGxdxjx
y0y%y;yJyXy[y
Agyry
zcA-z
8zGzLzVzYz\z_z`zgzjzuzxz
={'{*{.{/{1{
AU{y{d{f{i{s{
|&|E|J|Q|W|^|a|i|n|o|p|
=}>}@}G}
BY}Z}j}p}
~ ~'~,~E~s~u~~~
~CC<
%ECE>
& % 
f"g"
"4"B&@&
2 3 
304050;0<0
"*")"
#'"("
"%"&"
"a"R"j"k"
"5"+","b"C"E"H"v"w"
!+!0 o&m&j&  ! 
n&k&l&i&
!4)5)
%=0F
%" !
!'!A
A0B0C0D0E0F0G0H0I0J0K0L0M0N0O0P0Q0R0S0T0U0V0W0X0Y0Z0[0\0]0^0_0`0a0b0c0d0e0f0g0h0i0j0k0l0m0n0o0p0q0r0s0t0u0v0w0x0y0z0{0|0}0~0
0K0M0O0Q0S0
d&`&b&f&a&e&g&c&
"S!T!U!
%,%$%4%<%
%#%3%+%;%K% %/%(%7%?%
%0%%%8%B%Q2R2S2T2U2V2W2X2Y2Z2[2\2]2^2_2
%< G H I 
v'w'x'y'z'{'|'}'~'
$p!q!r!s!t!u!v!w!x!y!z!{!
Q B 
`$a$b$c$d$e$f$g$h$i$j$k$l$m$n$o$p$q$r$s$`!a!b!c!d!e!f!g!h!i!j!I3
3"3M3
363Q3W3
3&3#3+3J3;3
2122292~3}3|3
4(N/N0N
O`OHOIOVO_OjOlO~O
P'P.P@P;PAP
Q5QJQ2
UQWQ
RIRWRaR
aScS}S
T'TMT
TkTtT
U+U5UPU^U
V;VIVvVfV8
oVqVrV
!W/W3W4WpWwW|W
aXdX9
XYA
]YmY
Z#ZgZmZwZ~Z
pOupu
AQpS
U0[q_ f
l)m[t
vNz4
W0XDY
eZl%u
Q.YeY
e*j'k
vharYN
OxSi`)nOz
NUO=O
bYr;u
hwmppLu
d<h8h
\}iM
c {+j
_orR
*h\Q
[r^y^
h>kSkWl"o
8N+T
sLv<w
\^~^
_j0^
uHyc[
UThXjp
'xug
_%`Qe=gBlrl
c nZ
QTS!S
\7_J_/`P`m`
cYeKj
fmi@\
e#k=k4t
]N6P
UzzvP
Q\H\
hp~Qhl
RDQSU-W
WQYb_
_u`vaga
c:dleofBh
nfu=z
}K~k
P kzlTotzP}@
N9P&PeP|Q8RcR
i)j}r
xoxy}w
S{^&_
sC}7
^'_8bEe
OHSIT>T/Z
PIQlQ
W}YT[][
_R`La
fmg!h
i_l*mim/n
vlx?z
KQ;RJT
V@zw
XZZh`
u:}n
[i_Mb
c=hsk
x&xmy
dR(WPgj
QBW*
\OJR
T>d(f
zV{"}/
dce_h
YP[M\
c/e\[
gbk{k
lEsIy
OPQW[
x:y
\hcf
enq>y
R:\Sg|p5rL
[Kb1g
s.zk
yB}M~
NOOEQAS
ncs&~
m]y.~
R SGS
TFU1U
ff-fvf~g
nXn<q&qgq
X"[8^
dagVgDm
rsucz
qT~w
;\8O
_Na/c
u=\N
]i]pe
ncIg
N,p]u/f
b?ete
wMzM|>~
NHQCS`S
]&bGb
g\oNq}q
U8o6qhQ
|LVQX
| }D}
XOY=r
OtPGRsSo`Ic_g,n
cX[k[
dQg\
Y*YplQ
_ `Ka4b
S'Y,{
n'pSSDU
SFOT
9NXS
_e`zf`l
Z@w-N
j&p*s
_5_k_
gnoRr:u:wt
iCO,o
?ipojW
X,[,}*r
NNO\PuPCR
HT$X
xQkX)YU\
T5XWX
e\g!n{v
%x:x
UTXXXWY
b-dqgCh
uwyI{T{R{
|q}0R
myrcw
z4iJ\
pxVo\
XpzcK
~wuWS`i
esNeQ
l>m6t4xFZu
cWeog
hsidq
/OeRZS
Qu`ukQb
zVYX
4O$RJS
g>lNlHr
sTuA~,
=cifju
*SQS&T
`Ibyb
_buF{<
}~v,
thyh
W+YfZ
`vbwe
enfnm6r&{P
R;TtV
NuOuQ@Xc^s^
g&N=
WUcik+u
SFT1XIY
bgc>e
p2x+~
PVRJW
d4ggrfwFz
XL^TY,g
sT*gE
R"Y!q_r
xd!j
2Q(g
$\;b~|
Y:r6
/UQO*Q
m6s7s1uPy
ma}=
qNuSP]
Te\Ng
tYukx
`tAX
m/}^
a#oIq>|
A[V[}[
\#\+\
7b\;
F]G]S]J]m]
N*N1N6N<N?NBNVNXN
OZO0O[O]OWOGOvO
O{OiOpO
P*P%P
O!P)P,P
PCPGP
gUPPPHPZPVPlPxP
Q!Q:Q7Q<Q;Q?Q@QRQLQTQbQ
ziQjQnQ
R'R*R.R3R9RORDRKRLR^RTRjRtRiRsR
S#S/S1S3S8S@SFSES
NISMS
Q^SiSnS
Y{SwS
T=T@T,T-T<T.T6T)T
T_TqTwTpT
T9U@UcULU.U\UEUVUWU8U3U]U
U{U~U
UNVPV
q4V6V2V8VkVdV/VlVjV
W&W7W8WNW;W@WOWiW
XrX!XbXKXpX
kRX=XyX
h%Y,Y-Y2Y8Y>Y
zUYPYNYZYXYbY`YgYlYiY
Z@ZlZIZ5Z6ZbZjZ
Z*[6[>[C[E[@[Q[U[Z[[[e[i[p[s[u[x[
\ \"\(\8\9\A\F\N\S\
P\O\q[l\n\bNv\y\
]L]R]N]K]l]s]v]
^6^7^D^C^@^N^W^T^_^b^d^G^u^v^z^
_]_\_
_)_-_8_A_H_L_N_/_Q_V_W_Y_a_m_s_w_
_!```
`+`&`
`:`Z`A`j`w`_`J`F`M`c`C`d`B`l`k`Y`
aGa>a(a'aJa?a<a,a4a=aBaDasawaXaYaZakataoaeaqa_a]aSaua
b!b*b.b0b2b3bAbNb^bcb[b`bhb|b
bPc>cMc
ckcic
d&d6d
dgdodvdNd*e
e$e#e+e4e5e7e6e8eKuHeVeUeMeXe^e]erexe
esg5f6f4f
fOfDfIfAf^f]fdfgfhf_fbfpf
g&g'g8
.g?g6gAg8g7gFg^g`gYgcgdg
g|gjg
hFh)h@hMh2hNh
h+hYhchwh
h"i&i
h(i*i
i#i!i
hyiwi\ixikiTi~ini9iti=iYi0iai^i]i
jDjjrj6jxjGjbjYjfjHj8j"j
k8k7k
GkCkIkPkYkTk[k_kakxkyk
l$l#l^lUlbljl
l~lhlsl
6m+m=m8m
m5m3m
mmcm
mdmZmymYm
m-nnn.n
nrn_n>n#nkn+nvnMn
nCn:nNn$n
ozoxo
ooo[o
o|oXo
p0p>p2pQpcp
qeqUq
qfqbqLqVqlq
r(r-r,r0r2r;r<r?r@rFrKrXrtr~r
s4s/s)s%s>sNsOs
Wsjshspsxsus{szs
tot%t
s2t:tUt?t_tYtAt\titptctjtvt~t
u&u,u<uDuMuJuIu[uFuZuiudugukumuxuvu
v'v v!v"v$v4v0v;vGvHvFv\vXvavbvhvivjvgvlvpv
rvvvxv|v
w)w$w
w%w&w
w7w8wGwZwhwkw[wew
w~wyw
x&y x*yEx
y,y+y@y`yWy_yZyUySyzy
y1z;z>z7zCzWzIzazbziz
pzyz}z
{5{({6{P{
{L{E{u{e{t{g{p{q{l{n{
{#|'|*|
|7|+|=|L|C|T|O|@|P|X|_|d|V|e|l|u|
}E}K}.}2}?}5}F}s}V}N}r}h}n}O}c}
~#~!~
~"~F~f~;~5~9~C~7~2~:~g~]~V~^~Y~Z~y~j~i~|~{~
^X^^^
_#_4_6_=_@_E_T_X_d_g_}_
`3`5`G`=
a+a0a7a>
"b>bCbVbZbob
c9cCcec|c
d"dydQd`dmd
d"e)eA
f:f"f$f+f0f1f3f
fHfLf
YfZfafefsfwfxf
3gfgGgHg{g
h,h1h[hrhuhD
5iBiWicidihi
;j>jEjPjVj[jkjsj
k,k5kFkVk`kekgkwk
l3lYl\l
ltlvl
m.m1m9m?mXmemE
4nDn\n^n
*o/o3oQoYo^oaobo~o
p(pJp]p^pNpdpup
q q.q0qFqGqQqH
Rq\q`qhq
rUrVr?>
's(s
Psfs|s
&t(t*t+t,t.t/t0tDtFtGtKtWtbtktmt
u/uouyu
v-v5vCvKvdvevmvovqv
w4w6wFwMwNw\w_wbwzw
CxNxOxQxhxnxK
y.y1y4yL
EyFyN
9z]zmzU
{-{;{G{N{`{m{o{r{
| |3|6|dB
Y|m|y|
}#}1}
A}H}S}\}z}
G~R~a~
SD[D`
& % 
f"g"
"4"B&@&
2 3 
"*")"
'"("
"a"R"j"k"
"5"+","
+!0 o&m&j&  ! 
A0B0C0D0E0F0G0H0I0J0K0L0M0N0O0P0Q0R0S0T0U0V0W0X0Y0Z0[0\0]0^0_0`0a0b0c0d0e0f0g0h0i0j0k0l0m0n0o0p0q0r0s0t0u0v0w0x0y0z0{0|0}0~0
%,%$%4%<%
%#%3%+%;%K% %/%(%7%?%
%0%%%8%B%
`$a$b$c$d$e$f$g$h$i$j$k$l$m$n$o$p$q$r$s$`!a!b!c!d!e!f!g!h!i!
3"3M3
363Q3W3
3&3#3+3J3;3
2122292~3}3|3R"a"+"."
"5")"*"
pOupu
AQpS
U0[q_ f
l)m[t
vNz4
W0XDY
eZl%u
Q.YeY
e*j'k
vharYN
OxSi`)nOz
NUO=O
bYr;u
hwmppLu
d<h8h
\}iM
c {+j
_orR
*h\Q
[r^y^
h>kSkWl"o
8N+T
sLv<w
\^~^
_j0^
uHyc[
UThXjp
'xug
_%`Qe
=gBlrl
c nZ
QTS!S
\7_J_/`P`m`
cYeKj
fmi@\
e#k=k4t
]N6P
UzzvP
Q\H\
hp~Qhl
RDQSU-W
WQYb_
_u`vaga
c:dleofBh
nfu=z
}K~k
P kzlTotzP}@
N9P&PeP|Q8RcR
i)j}r
xoxy}w
S{^&_
sC}7
^'_8bEe
OHSIT>T/Z
PIQlQ
W}YT[][
_R`La
fmg!h
i_l*mim/n
vlx?z
KQ;RJT
V@zw
XZZh`
u:}n
[i_Mb
c=hsk
x&xmy
dR(WPgj
QBW*
\OJR
T>d(f
zV{"}/
dce_h
YP[M\
c/e\[
lEsIy
OPQW[
cBf!k
x:y
\hcf
enq>y
R:\Sg|p5rL
[Kb1g
s.zk
yB}M~
NOOEQAS
ncs&~
m]y.~
R SGS
TFU1U
ff-fvf~g
nXn<q&qgq
X"[8^
dagVgDm
rsucz
qT~w
;\8O
_Na/c
u=\N
]i]pe
ncIg
N,p]u/f
b?ete
wMzM|>~
NHQCS`S
]&bGb
g\oNq}q
U8o6qhQ
|LVQX
| }D}
XOY=r
OtPGRsSo`Ic_g,n
cX[k[
dQg\
Y*YplQ
_ `Ka4b
S'Y,{
n'pSSDU
SFOT
9NXS
_e`zf`l
Z@w-N
j&p*s
_5_k_
gnoRr:u:wt
iCO,o
?ipojW
X,[,}*r
NNO\PuPCR
HT$X
xQkX)YU\
T5XWX
e\g!n{v
%x:x
UTXXXWY
b-dqgCh
uwyI{T{R{
|q}0Rc
myrcw
z4iJ\
pxVo\
XpzcK
~wuWS`i
esNeQ
l>m6t4xFZu
cWeog
sidq
/OeRZS
Qu`ukQb
zVYX
4O$RJS
g>lNlHr
sTuA~,
=cifju
*SQS&T
`Ibyb
_buF{<
}~v,
thyh
W+YfZ
`vbwe
enfnm6r&{P
R;TtV
NuOuQ@Xc^s^
g&N=
WUcik+u
SFT1XIY
bgc>e
p2x+~
PVRJW
d4ggrfwFz
XL^TY,g
sT*gE
R"Y!q_r
xd!j
2Q(g
$\;b~|
Y:r6
/UQO*Q
m6s7s1uPy
ma}=
qNuSP]
Te\Ng
tYukx
`tAX
m/}^
a#oIq>|
N*N1N6N<N?NBNVNXN
OZO0O[O]OWOGOvO
O{OiOpO
P*P%P
O!P)P,P
PCPGP
gUPPPHPZPVPlPxP
Q!Q:Q7Q<Q;Q?Q@QRQLQTQbQ
ziQjQnQ
R'R*R.R3R9RORDRKRLR^RTRjRtRiRsR
S#S/S1S3S8S@SFSES
NISMS
Q^SiSnS
Y{SwS
T=T@T,T-T<T.T6T)T
T_TqTwTpT
T9U@UcULU.U\UEUVUWU8U3U]U
U{U~U
UNVPV
q4V6V2V8V
kVdV/VlVjV
W&W7W8WNW;W@WOWiW
XrX!XbXKXpX
kRX=XyX
h%Y,Y-Y2Y8Y>Y
zUYPYNYZYXYbY`YgYlYiY
Z@ZlZIZ5Z6ZbZjZ
Z*[6[>[C[E[@[Q[U[Z[[[e[i[p[s[u[x[
\ \"\(\8\9\A\F\N\S\P\O\q[l\n\bNv\y\
]L]R]N]K]l]s]v]
^6^7^D^C^@^N^W^T^_^b^d^G^u^v^z^
_]_\_
_)_-_8_A_H_L_N_/_Q_V_W_Y_a_m_s_w_
_!```
`+`&`
`:`Z`A`j`w`_`J`F`M`c`C`d`B`l`k`Y`
aGa>a(a'aJa?a<a,a4a=aBaDasawaXaYaZakataoaeaqa_a]aSaua
b!b*b.b0b2b3bAbNb^bcb[b`bhb|b
bPc>cMc
d&d6d
dgdodvdNd*e
e$e#e+e4e5e7e6e8eKuHeVeUeMeXe^e]erexe
esg5f6f4f
fOfDfIfAf^f]fdfgfhf_fbfpf
g&g'g8
.g?g6gAg8g7gFg^g`gYgcgdg
g|gjg
hFh)h@hMh2hNh
h+hYhchwh
h"i&i
h(i*i
i#i!i
hyiwi\ixikiTi~ini9iti=iYi0iai^i]i
jDjjrj6jxjGjbjYjfjHj8j"j
k8k7k
GkCkIkPkYkTk[k_kakxkyk
l$l#l^lUlbljl
l~lhlsl
6m+m=m8m
m5m3m
mmcm
mdmZmymYm
m-nnn.n
nrn_n>n#nkn+nvnMn
nCn:nNn$n
ozoxo
ooo[o
o|oXo
p0p>p2pQpcp
qeqUq
qfqbqLqVqlq
r(r-r,r0r2r;r<r?r@rFrKrXrtr~r
s4s/s)s%s>sNsOs
Wsjshspsxsus{szs
tot%t
s2t:tUt?t_tYtAt\titptctjtvt~t
u&u,u<uDuMuJuIu[uFuZuiudugukumuxuvu
v'v v!v"v$v4v0v;vGvHvFv\vXvavbvhvivjvgvlvpvrvvvxv|v
w)w$w
w%w&w
w7w8wGwZwhwkw[wew
w~wyw
x&y x*yEx
y,y+y@y`yWy_yZyUySyzy
y1z;z>z7zCzWzIzazbziz
pzyz}z
{5{({6{P{z{
{L{E{u{e{t{g{p{q{l{n{
{#|'|*|
|7|+|=|L|C|T|O|@|P|X|_|d|V|e|l|u|
}E}K}.}2}?}5}F}s}V}N}r}h}n}O}c}
~#~!~
~"~F~f~;~5~9~C~7~
2~:~g~]~V~^~Y~Z~y~j~i~|~{~
fE_(N
O9OVO
O@P"P
PFPpPBP
PJQdQ
S$SrS
UYWeW
YSY[Y]YcY
\']S]
B]m]
]!_4_g_
a7a0a
f$fefWfYf
i0jkjFjsj~j
k?l\l
m9n\n'n<n
q\qFqGq
s&t*t)t.tbt
R!xNxdxzx0y
H}\}
}R~G
p!q!r!s!t!u!v!w!x!y!
p!q!r!s!t!u!v!w!x!y!`!a!b!c!d!e!f!g!h!i!
!!!5"
fE_(N
O9OVO
O@P"P
PFPpPBP
S$SrS
UYWeW
YSY[Y]YcY
\']S]
B]m]
]!_4_g_
a7a0a
f$fefWfYf
i0jkjFjsj~j
k?l\l
m9n\n'n<n
q\qFqGq
s&t*t)t.tbt
R!xNxdxzx0y
H}\}
}R~G
N5MeCab34SpecialNodeCreationConcreteContextINS_13TokenizerImplI12mecab_node_t12mecab_path_tEEEE
N5MeCab26SpecialNodeCreationContextE
N5MeCab8FreeListI20mecab_learner_node_tEE
N5MeCab34SpecialNodeCreationConcreteContextINS_13TokenizerImplI20mecab_learner_node_t20mecab_learner_path_tEEEE
N5MeCab7ViterbiE
N5MeCab10scoped_ptrINS_8FreeListI12mecab_path_tEEEE
N5MeCab8FreeListI12mecab_path_tEE
<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd"><plist version="1.0"><dict>
<key>IDXDictionaryIndexes</key>
<array>
<dict>
<key>IDXIndexAccessMethod</key>
<string>com.apple.TrieAccessMethod</string>
<key>IDXIndexBigEndian</key>
<false/>
<key>IDXIndexDataFields</key>
<dict>
<key>IDXFixedDataFields</key>
<array>
<dict>
<key>IDXDataFieldName</key>
<string>Seed</string>
<key>IDXDataSize</key>
<integer>4</integer>
</dict>
</array>
<key>IDXVariableDataFields</key>
<array>
<dict>
<key>IDXDataFieldName</key>
<string>Hyoki</string>
<key>IDXDataSizeLength</key>
<integer>2</integer>
</dict>
<dict>
<key>IDXDataFieldName</key>
<string>Yomi</string>
<key>IDXDataSizeLength</key>
<integer>2</integer>
</dict>
<dict>
<key>IDXDataFieldName</key>
<string>Key</string>
<key>IDXDataSizeLength</key>
<integer>2</integer>
</dict>
</array>
</dict>
<key>IDXIndexKeyMatchingMethods</key>
<array>
<string>IDXExactMatch</string>
<string>IDXExactMatchVoicedAmbi</string>
<string>IDXExactMatchSmallAmbi</string>
<string>IDXExactMatchVoicedAndSmallAmbi</string>
<string>IDXPrefixMatch</string>
<string>IDXPrefixMatchVoicedAmbi</string>
<string>IDXPrefixMatchSmallAmbi</string>
<string>IDXPrefixMatchVoicedAndSmallAmbi</string>
</array>
<key>IDXIndexPath</key>
<string>Keyword.index</string>
<key>IDXIndexWritable</key>
<true/>
<key>IDXIndexDataSizeLength</key>
<integer>2</integer>
</dict>
</array>
<key>IDXDictionaryVersion</key>
<integer>1</integer></dict></plist>
N7Seaweed19PhraseCandidateWordE
333333
N11InputEngine15MecabraJapaneseE
N11InputEngine8ObserverI30MobileAssetNotificationManagerEE
NSt3__118basic_stringstreamIcNS_11char_traitsIcEENS_9allocatorIcEEEE
NSt3__119basic_istringstreamIcNS_11char_traitsIcEENS_9allocatorIcEEEE
NSt3__110__function6__funcIZN3nlp11CFScopedPtrIPK10__CFStringEC1ES6_EUlPKvE_NS_9allocatorISA_EEFvS9_EEE
ZN3nlp11CFScopedPtrIPK10__CFStringEC1ES3_EUlPKvE_
NSt3__110__function6__funcIZN3nlp11CFScopedPtrIPK7__CFURLE5resetES6_EUlPKvE_NS_9allocatorISA_EEFvS9_EEE
ZN3nlp11CFScopedPtrIPK7__CFURLE5resetES3_EUlPKvE_
NSt3__110__function6__funcIZN3nlp11CFScopedPtrIP10__CFStringEC1ES5_EUlPKvE_NS_9allocatorIS9_EEFvS8_EEE
ZN3nlp11CFScopedPtrIP10__CFStringEC1ES2_EUlPKvE_
NSt3__110__function6__funcIZN3nlp11CFScopedPtrIPK9__CFArrayEC1ES6_EUlPKvE_NS_9allocatorISA_EEFvS9_EEE
ZN3nlp11CFScopedPtrIPK9__CFArrayEC1ES3_EUlPKvE_
32MecabSearchContextImplementationI13BridgeBuilderI25JapanesePrefixMatchBridgeES0_I23CommonDynamicWordBridgeES0_I36JapaneseRomajiToKanaConversionBridgeES0_I32CommonCharacterReplacementBridgeEE
18MecabSearchContext
NSt3__120__shared_ptr_pointerIP11DynamicWordNS_14default_deleteIS1_EENS_9allocatorIS1_EEEE
NSt3__114default_deleteI11DynamicWordEE
/System/Library/LinguisticData/RequiredAssets_ja.bundle/AssetData
14DynamicLexicon
N11InputEngine26MecabraConversionCandidateE
N11InputEngine28MecabraInputEngineDispatcherINS_15MecabraJapaneseENS_23NoopPredictionComponentEEE
N11InputEngine18MecabraInputEngineE
N11InputEngine28MecabraInputEngineDispatcherIN7Seaweed16ConversionEngineE23ChinesePredictionEngineEE
N11InputEngine28MecabraInputEngineDispatcherINS_30MecabraSimplifiedChineseStrokeE23ChinesePredictionEngineEE
N11InputEngine28MecabraInputEngineDispatcherINS_31MecabraTraditionalChineseStrokeE23ChinesePredictionEngineEE
N11InputEngine28MecabraInputEngineDispatcherINS_14MecabraCangjieE23ChinesePredictionEngineEE
N11InputEngine28MecabraInputEngineDispatcherINS_15MecabraWubixingE23ChinesePredictionEngineEE
N11InputEngine28MecabraInputEngineDispatcherINS_18MecabraHandwritingE23ChinesePredictionEngineEE
N11InputEngine24ChinesePredictionContextE
N11InputEngine25DynamicDictionaryJapaneseE
N11InputEngine17DynamicDictionaryE
N11InputEngine24DynamicDictionaryChineseE
N11InputEngine20MecabraCandidateBaseE
32BTriePositionInterpreterInternal
23BTrieFatBaseInterpreter
27BTrieCompactBaseInterpreter
24BTrieFlatBaseInterpreter
20BTrieNoOpInterpreter
NSt3__120__shared_ptr_pointerIPN11InputEngine23MecabraChineseTokenizerENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN11InputEngine23MecabraChineseTokenizerEEE
17ChineseStringWord
N11InputEngine26MecabraCandidateSetAdaptorE
N11InputEngine34MecabraCandidateSetSkippingAdaptorE
N11InputEngine34MecabraCandidateSetOrderingAdaptorE
21EntryFieldStringValue
15EntryFieldValue
22EntryFieldIntegerValue
NSt3__120__shared_ptr_pointerIP21EntryFieldStringValueNS_14default_deleteIS1_EENS_9allocatorIS1_EEEE
NSt3__114default_deleteI21EntryFieldStringValueEE
NSt3__120__shared_ptr_pointerIP22EntryFieldIntegerValueNS_14default_deleteIS1_EENS_9allocatorIS1_EEEE
NSt3__114default_deleteI22EntryFieldIntegerValueEE
26AggregateDictionaryTracker
24MecabraStatisticsTracker
22NodeFeatureInterpreter
29ChineseNodeFeatureInterpreter
39SimplifiedChineseNodeFeatureInterpreter
40TraditionalChineseNodeFeatureInterpreter
46TraditionalChinesePinyinNodeFeatureInterpreter
46TraditionalChineseZhuyinNodeFeatureInterpreter
25JapanesePrefixMatchBridge
26EnginePrefixMatchInterface
36JapaneseRomajiToKanaConversionBridge
37EngineRomajiToKanaConversionInterface
13FileException
NSt3__120__shared_ptr_pointerIP4FileIcENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteI4FileIcEEE
23CommonDynamicWordBridge
26EngineDynamicWordInterface
32CommonCharacterReplacementBridge
35EngineCharacterReplacementInterface
N11InputEngine15CandidateClonerI33CharacterInputConversionCandidateEE
33CharacterInputConversionCandidate
28SyntheticConversionCandidate
N11InputEngine34MecabraJapaneseConversionCandidateE
23SQLiteDatabaseException
11DynamicWord
21JapaneseMecabNodeWord
N5MeCab15WordCoreAdaptorI13MecabNodeWordEE
13MecabNodeWord
27CharacterLatticeSessionData
NSt3__110__function6__funcIZN3nlp11CFScopedPtrIPK14__CFDictionaryE7acquireES6_EUlPKvE_NS_9allocatorISA_EEFvS9_EEE
ZN3nlp11CFScopedPtrIPK14__CFDictionaryE7acquireES3_EUlPKvE_
?333333
34ChineseCompletionProducerException
NSt3__120__shared_ptr_pointerIP19ReadingMappedStringNS_14default_deleteIS1_EENS_9allocatorIS1_EEEE
NSt3__114default_deleteI19ReadingMappedStringEE
N11InputEngine15CandidateClonerIN7Seaweed25InlinePredictionCandidateEEE
N7Seaweed25InlinePredictionCandidateE
NSt3__120__shared_ptr_emplaceIN7Seaweed20InlinePredictionWordENS_9allocatorIS2_EEEE
%@ffffff
?ffffff
?34ChinesePredictionProducerException
NSt3__110__function6__funcIZN3nlp11CFScopedPtrIP14__CFDictionaryE5resetES5_EUlPKvE_NS_9allocatorIS9_EEFvS8_EEE
ZN3nlp11CFScopedPtrIP14__CFDictionaryE5resetES2_EUlPKvE_
N11InputEngine15MecabraWubixingE
17InstantLogPrinter
10LogPrinter
18BufferedLogPrinter
N7Seaweed31SeaweedDynamicMutableDictionaryE
@22SyntheticCandidateBase
N11InputEngine13MecabraEngineE
NSt3__110__function6__funcIZN3nlp11CFScopedPtrIPK9__CFArrayE5resetES6_EUlPKvE_NS_9allocatorISA_EEFvS9_EEE
ZN3nlp11CFScopedPtrIPK9__CFArrayE5resetES3_EUlPKvE_
NSt3__120__shared_ptr_pointerIP13MecabNodeWordNS_14default_deleteIS1_EENS_9allocatorIS1_EEEE
NSt3__114default_deleteI13MecabNodeWordEE
N11InputEngine30ChineseRevertAdaptationContextE
NSt3__120__shared_ptr_pointerIP7LexiconNS_14default_deleteIS1_EENS_9allocatorIS1_EEEE
NSt3__114default_deleteI7LexiconEE
N11InputEngine18MecabraContextImplE
NSt3__110__function6__funcIZN3nlp11CFScopedPtrIPK13__CFAllocatorE7acquireES6_EUlPKvE_NS_9allocatorISA_EEFvS9_EEE
ZN3nlp11CFScopedPtrIPK13__CFAllocatorE7acquireES3_EUlPKvE_
?N11InputEngine19MecabraCandidateSetE
N11InputEngine26MecabraChineseCandidateSetE
N11InputEngine41MecabraChineseSingleCharacterCandidateSetE
N11InputEngine36MecabraChineseExactMatchCandidateSetE
N11InputEngine27MecabraJapaneseCandidateSetE
N11InputEngine14MecabraLearnerE
N11InputEngine27SeaweedChinesePinyinLearnerE
N11InputEngine21SeaweedChineseLearnerE
N11InputEngine37SeaweedSimplifiedChinesePinyinLearnerE
N11InputEngine38SeaweedTraditionalChinesePinyinLearnerE
N11InputEngine38SeaweedTraditionalChineseZhuyinLearnerE
19ChineseLearningInfo
12LearningInfo
N7Seaweed26ReverseDictionaryExceptionE
NSt3__120__shared_ptr_pointerIPN7Seaweed17ReverseDictionaryENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN7Seaweed17ReverseDictionaryEEE
N11InputEngine22MecabraJapaneseLearnerE
27MecabraJapaneseLearningInfo
NSt3__110__function6__funcIZN3nlp11CFScopedPtrIP9__CFArrayEC1ES5_EUlPKvE_NS_9allocatorIS9_EEFvS8_EEE
ZN3nlp11CFScopedPtrIP9__CFArrayEC1ES2_EUlPKvE_
com.apple.mecabra
default
allocation
conversion
context
geometry
incremental
learning
languagemodel
live
mobileasset
prediction
pruning
reranking
N11InputEngine15CandidateClonerI20HandwritingCandidateEE
20HandwritingCandidate
  0 
: `k
85*L
W&0CFq
 ? 2t{
,k!%
ab,Ac
^4-*L
Op"I
`'H*@
M!70
V\PI
 HC
k `p
$@R2
8! @
F3$xr0
$"0 
:0p(
<5*L
W&0c
g!Ip"
THhd
CQ d
d:9%
,k1%
cF(Aa
0&dH1
h+]A
H&@8J?
,iud>
&BaY
`"A0
R%!)
:J$4
+AL L+
te  8D
`B*@*
 !:"
I$3@
N7Seaweed23ConversionCandidateWordE
NSt3__120__shared_ptr_emplaceI19ReadingMappedStringNS_9allocatorIS1_EEEE
N11InputEngine15CandidateClonerINS_25MecabraProactiveCandidateEEE
N11InputEngine35MecabraProactiveConversionCandidateE
N11InputEngine15CandidateClonerIN7Seaweed19SingleWordCandidateEEE
N7Seaweed19SingleWordCandidateE
333333
?ffffff
@ffffff
ffffff
ffffff
?333333
N7Seaweed16ConversionEngineE
19PreheatableResource
N11InputEngine8ObserverIN7Seaweed22AssetDictionaryManagerEEE
N11InputEngine15CandidateClonerI22ChineseHybridCandidateEE
22ChineseHybridCandidate
N7Mecabra16BurstTrieBuilderE
N7Mecabra11TrieBuilderE
N7Mecabra17MarisaTrieBuilderE
26CharacterLatticeController
N7Seaweed20InlinePredictionWordE
16CharacterLattice
N7Seaweed26SeaweedImmutableDictionaryE
N7Seaweed17SeaweedDictionaryE
29SingleIndexKeyTokenEnumerator
18KeyTokenEnumerator
31MultipleIndexKeyTokenEnumerator
N7Seaweed13CandidateWordE
@333333
NSt3__120__shared_ptr_emplaceI15MecabraAssetSetNS_9allocatorIS1_EEEE
?ffffff
N7Seaweed13LatticeSearchE
N11InputEngine21MecabraCangjieLearnerE
N11InputEngine28MecabraCharacterInputLearnerE
N11InputEngine30MecabraSimplifiedStrokeLearnerE
N11InputEngine21MecabraSuchengLearnerE
N11InputEngine31MecabraTraditionalStrokeLearnerE
N11InputEngine22MecabraWubixingLearnerE
18StrokeLearningInfo
NSt3__120__shared_ptr_emplaceIN14SharedCFString7WrapperENS_9allocatorIS2_EEEE
?N7Seaweed16LookupControllerE
N7Seaweed33MixedScriptSyllableSearchDelegateE
NSt3__120__shared_ptr_pointerIP29SingleWordCandidateSharedDataNS_14default_deleteIS1_EENS_9allocatorIS1_EEEE
NSt3__114default_deleteI29SingleWordCandidateSharedDataEE
N11InputEngine13LanguageModelE
N5MeCab25MecabraJapaneseDictionaryE
N7Seaweed26SeaweedConversionCandidateE
29SingleWordCandidateSharedData
19PredictionCandidate
N11InputEngine15CandidateClonerI26ChinesePredictionCandidateEE
26ChinesePredictionCandidate
N11InputEngine15CandidateClonerIN7Seaweed15PhraseCandidateEEE
N7Seaweed15PhraseCandidateE
NSt3__120__shared_ptr_emplaceIN7Seaweed19PhraseCandidateWordENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_pointerIPN7Seaweed19PhraseCandidateWordENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN7Seaweed19PhraseCandidateWordEEE
N11InputEngine19ChineseInputContextE
N7Seaweed8WordCoreE
N7Seaweed29StaticDictionaryEntryWordCoreE
N7Seaweed23DictionaryEntryWordCoreE
N7Seaweed16SentinelWordCoreE
N7Seaweed31LearningDictionaryEntryWordCoreE
N7Seaweed45StaticDictionaryEntryWithModifiedCostWordCoreE
N7Seaweed19MixedScriptWordCoreE
N7Seaweed17ProactiveWordCoreE
N7Seaweed17SyntheticWordCoreE
adgjmptw
N7Seaweed21SyllableLatticeColumnE
N7Seaweed15SyllableLatticeE
NSt3__120__shared_ptr_emplaceIN7Seaweed32SyntheticMixedScriptSyllableNodeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN7Seaweed25AutoCorrectedSyllableNodeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN7Seaweed28SyntheticEnglishSyllableNodeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN7Seaweed21SyntheticSyllableNodeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_pointerIPN7Seaweed12SyllableNodeENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN7Seaweed12SyllableNodeEEE
NSt3__120__shared_ptr_emplaceIN7Seaweed21ShuangpinSyllableNodeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN7Seaweed26IncompleteWithToneSyllableENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN7Seaweed17FuzzySyllableNodeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN7Seaweed12SyllableNodeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN7Seaweed27ProactiveEntitySyllableNodeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_pointerIPN7Seaweed25AutoCorrectedSyllableNodeENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN7Seaweed25AutoCorrectedSyllableNodeEEE
N7Seaweed12SyllableNodeE
N7Seaweed16SyllableNodeBaseE
N7Seaweed17FuzzySyllableNodeE
N7Seaweed25AutoCorrectedSyllableNodeE
N7Seaweed26IncompleteWithToneSyllableE
N7Seaweed21ShuangpinSyllableNodeE
N7Seaweed21SyntheticSyllableNodeE
N7Seaweed28SyntheticEnglishSyllableNodeE
N7Seaweed27ProactiveEntitySyllableNodeE
N7Seaweed32SyntheticMixedScriptSyllableNodeE
N7Seaweed35SimplifiedChineseFeatureInterpreterE
N7Seaweed18FeatureInterpreterE
N7Seaweed36TraditionalChineseFeatureInterpreterE
?333333
N11InputEngine15CandidateClonerI26ChineseCompletionCandidateEE
26ChineseCompletionCandidate
37ChineseCompletionFixedPhraseCandidate
NSt3__120__shared_ptr_pointerIPN11InputEngine26FacemarkLearningDictionaryENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN11InputEngine26FacemarkLearningDictionaryEEE
N7Seaweed25WordLatticeControllerImplE
N7Seaweed21WordLatticeControllerE
N11InputEngine25MecabraProactiveCandidateE
N11InputEngine27JapaneseSpecialtyDictionaryE
N11InputEngine19SpecialtyDictionaryE
21ChinesePredictionWord
N11InputEngine7SegmentE
N11InputEngine42MecabraCharacterPhraseInputAnalysisSessionE
N7Seaweed24SeaweedMutableDictionaryE
N7Seaweed36SeaweedFileMappedImmutableDictionaryE
N7Seaweed34SeaweedInMemoryImmutableDictionaryE
N7Seaweed28SeaweedAddressBookDictionaryE
N7Seaweed25SeaweedUserWordDictionaryE
N7Seaweed13ZhiClassifierE
N7Seaweed19CharacterClassifierE
N11InputEngine39MecabraCharacterPhraseInputCandidateSetE
13CharacterNode
N11InputEngine21JapaneseLanguageModelE
32ReadingLookupDictionaryException
v8@?0
Chinese.lm
en-languagemodel
en_US
^{LanguageModel=^^?^vq^{__CFString}}8@?0
^{LanguageModelLoader=i^{__CFURL}^{__CFURL}{unique_ptr<InputEngine::LanguageModel, std::__1::default_delete<InputEngine::LanguageModel> >={__compressed_pair<InputEngine::LanguageModel *, std::__1::default_delete<InputEngine::LanguageModel> >=^{LanguageModel}}}}8@?0
emoji.dat
no tone change
tone change
Base phrase: %s baseScore=%f candidateWord: %s homophoneForWord: %s homophoneScore=%f
bcdfghjklmprstvwxyz
qwrtpsdfghjklzxcvbnm
bcdfghjklmnpqrstvwxz
bcdfghjklmpqrstvwxyz
v24@?0r^{vector<unsigned short, std::__1::allocator<unsigned short> >=^S^S{__compressed_pair<unsigned short *, std::__1::allocator<unsigned short> >=^S}}8^B16
xtsu
UTF-8
UTF-16LE
v32@?0@"NSString"8i16B20^B24
v24@?0r^{CharacterNode=^^?^{__CFString}iBB}8^B16
v36@?0r^S8q16i24^B28
^{__CFString=}16@?0^{__CFString=}8
rank
extension
PRAutocorrectionContext
v20@?0^{__CFString=}8C16
v32@?0^{map<std::__1::basic_string<char>, std::__1::shared_ptr<EntryFieldValue>, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, std::__1::shared_ptr<EntryFieldValue> > > >={__tree<std::__1::__value_type<std::__1::basic_string<char>, std::__1::shared_ptr<EntryFieldValue> >, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, std::__1::shared_ptr<EntryFieldValue> >, std::__1::less<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__value_type<std::__1::basic_string<char>, std::__1::shared_ptr<EntryFieldValue> > > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<std::__1::basic_string<char>, std::__1::shared_ptr<EntryFieldValue> >, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, std::__1::shared_ptr<EntryFieldValue> >, std::__1::less<std::__1::basic_string<char> >, true> >=Q}}}8i16i20^B24
MECABRA_TEST
/zip_code-ja.dat
%@*%@
CharacterMap
^{CharacterMap={map<unsigned short, unsigned short, std::__1::less<unsigned short>, std::__1::allocator<std::__1::pair<const unsigned short, unsigned short> > >={__tree<std::__1::__value_type<unsigned short, unsigned short>, std::__1::__map_value_compare<unsigned short, std::__1::__value_type<unsigned short, unsigned short>, std::__1::less<unsigned short>, true>, std::__1::allocator<std::__1::__value_type<unsigned short, unsigned short> > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<unsigned short, unsigned short>, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<unsigned short, std::__1::__value_type<unsigned short, unsigned short>, std::__1::less<unsigned short>, true> >=Q}}}{map<unsigned short, std::__1::map<std::__1::basic_string<char>, unsigned short, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, unsigned short> > >, std::__1::less<unsigned short>, std::__1::allocator<std::__1::pair<const unsigned short, std::__1::map<std::__1::basic_string<char>, unsigned short, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, unsigned short> > > > > >={__tree<std::__1::__value_type<unsigned short, std::__1::map<std::__1::basic_string<char>, unsigned short, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, unsigned short> > > >, std::__1::__map_value_compare<unsigned short, std::__1::__value_type<unsigned short, std::__1::map<std::__1::basic_string<char>, unsigned short, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, unsigned short> > > >, std::__1::less<unsigned short>, true>, std::__1::allocator<std::__1::__value_type<unsigned short, std::__1::map<std::__1::basic_string<char>, unsigned short, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, unsigned short> > > > > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<unsigned short, std::__1::map<std::__1::basic_string<char>, unsigned short, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, unsigned short> > > >, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<unsigned short, std::__1::__value_type<unsigned short, std::__1::map<std::__1::basic_string<char>, unsigned short, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, unsigned short> > > >, std::__1::less<unsigned short>, true> >=Q}}}}8@?0
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-744.6/mecabra/CharacterMap.cpp
inputStream.is_open()
result.second
v32@?0{?=qq}8^B24
v24@?0r^S8Q16
J_Numeral.dict
Josu.data
^{SeaweedFileMappedImmutableDictionary=^^?CI^{BurstTrie}IIIi{shared_ptr<File<char> >=^{File<char>}^{__shared_weak_count}}^{Token}*{vector<BurstTrie, std::__1::allocator<BurstTrie> >=^{BurstTrie}^{BurstTrie}{__compressed_pair<BurstTrie *, std::__1::allocator<BurstTrie> >=^{BurstTrie}}}{vector<unsigned int *, std::__1::allocator<unsigned int *> >=^^I^^I{__compressed_pair<unsigned int **, std::__1::allocator<unsigned int *> >=^^I}}^{FeatureInterpreter}{vector<unsigned int, std::__1::allocator<unsigned int> >=^I^I{__compressed_pair<unsigned int *, std::__1::allocator<unsigned int> >=^I}}{vector<BurstTrie, std::__1::allocator<BurstTrie> >=^{BurstTrie}^{BurstTrie}{__compressed_pair<BurstTrie *, std::__1::allocator<BurstTrie> >=^{BurstTrie}}}{vector<unsigned int *, std::__1::allocator<unsigned int *> >=^^I^^I{__compressed_pair<unsigned int **, std::__1::allocator<unsigned int *> >=^^I}}[256C]}8@?0
NumberValue.index
openCount
initiallyOpenedCallCount
lastlyClosedCallCount
q24@?0@8@16
%s : %ld
Token count: %ld, UNK count = %ld
RevertLearning
PerformLearning
%s:%s
Contents
%@ [%d] %@
Library/Logs/IndexedSearchLog.txt
zip_code.dat
com.apple.TrieAccessMethod
com.apple.HeapAccessMethod
com.apple.TestAccessMethod-Inspector
IDXDefaultProperty
plist
com.apple.DictionaryServices
Resources
Contents/
Info.plist
IDXDictionaryVersion
IDXDictionaryIndexes
IDXIndexName
IDXIndexPath
IDXIndexAccessMethod
IDXIndexKeyMatchingMethods
IDXIndexDataSizeLength
IDXIndexWritable
IDXIndexSupportDataID
IDXIndexBigEndian
IDXIndexDataFields
IDXExternalDataFields
IDXFixedDataFields
IDXVariableDataFields
IDXDataFieldName
IDXDataSize
IDXDataSizeLength
IDXExactMatch
IDXPrefixMatch
IDXCommonPrefixMatch
IDXWildcardMatch
IDXAllMatch
IDXExactMatchVoicedAmbi
IDXExactMatchSmallAmbi
IDXExactMatchVoicedAndSmallAmbi
IDXPrefixMatchVoicedAmbi
IDXPrefixMatchSmallAmbi
IDXPrefixMatchVoicedAndSmallAmbi
IDXIndex
<%@>
<#invalid index>
<IDXIndexRef %p>{access method = %@, index = %@, open# = %d}
<IDXIndexRef %p>{access method = %@, #invalid index}
HeapDataCompressionType
HeapDataCompressionBlockSize
HeapDataCompressionMaxBlockCount
Failed to add a new data since record count exceeds limit (%lld) defined in the current compaction-type.
Record count exceeds limit (%lld).
TrieIndexCompressionType
TrieAuxiliaryDataOptions
TrieAuxiliaryDataFile
TrieSubIndexPath
%@_aux.data
Packed Homograph
dicdir
char.bin
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-744.6/src/char_property.cpp
fsize == cmmap_->size()
invalid file size: 
DEFAULT 1 0 0
SPACE   0 1 0
0x0020 SPACE
 is not found. minimum setting is used
size >= 2
format error: 
r.low >= 0 && r.low < 0xffff && r.high >= 0 && r.high < 0xffff && r.low <= r.high
range error: low=
 high=
category.find(std::string(col[i])) != category.end()
category [
] is undefined
size >= 4
category.find(key) == category.end()
category 
 is already defined
category.size() < 18
too many categories(>= 18)
DEFAULT
category.find("DEFAULT") != category.end()
category [DEFAULT] is undefined
SPACE
category.find("SPACE") != category.end()
category [SPACE] is undefined
DEFAULT,0,0,0,*
SPACE,0,0,0,*
 is not found. minimum setting is used.
n >= 1
category.find(key) != category.end()
] is undefined in 
unk.find(it->first) != unk.end()
permission denied: 
std::strlen(s) >= 3 && s[0] == '0' && (s[1] == 'x' || s[1] == 'X')
no hex value: 
false
c.size()
category size is empty
it != category->end()
/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-744.6/src/mmap.h
unknown open mode: 
(fd = open_create__(filename, flag | O_BINARY, S_IRUSR | S_IWUSR)) >= 0
open failed: 
(fd = open__(filename, flag | O_BINARY)) >= 0
fstat(fd, &st) >= 0
failed to get file size: 
(p = reinterpret_cast<char *> (mmap(0, length, prot, MAP_SHARED, fd, 0))) != MAP_FAILED
mmap() failed: 
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-744.6/src/context_id.cpp
it != left_.end()
cannot find LEFT-ID  for 
it != right_.end()
cannot find RIGHT-ID  for 
no such file or directory: 
2 == tokenize2(const_cast<char *>(line.c_str()), " \t", std::back_inserter(col), 2)
enumerateEntriesWithPrefix
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-744.6/src/im/dictionary.cpp
!(option & MECAB_JAPANESE_ROMAJI)
dmmap_->size() >= 100
dictionary file is broken: 
(magic ^ DictionaryMagicID) == dmmap_->size()
ptr == dmmap_->end()
bsize <= 0xff
count of homograph words is greater than 255. string =
 count=
bofs
matrix.def
matrix.bin
left-id.def
right-id.def
rewrite.def
pos-id.def
dictionary-charset
charset
wakati
type
node-format
input-method-language
config-charset
!from.empty()
input dictionary charset is empty
!to.empty()
output dictionary charset is empty
iconv.open(from.c_str(), to.c_str())
iconv_open() failed with from=
 to=
config_iconv.open(config_charset.c_str(), from.c_str())
reading 
 ... 
n == 5
index_n == index_count
!word.empty()
empty word error: 
rewrite->rewrite(feature, &ufeature, &lfeature, &rfeature)
rewrite failed: 
cid->left_size() == matrix.left_size() && cid->right_size() == matrix.right_size()
Context ID files(
 or 
 may be broken
no-posid-checking
lid >= 0 && rid >= 0 && matrix.is_valid(lid, rid)
invalid ids are found lid=
 rid=
empty word is found, discard this line
iconv conversion failed. skip this entry
iconv.convert(&word_ary[i])
convert error: 
os.get()
writer.get()
writer->writeNode(&*os, node_format.c_str(), w.c_str(), &node)
conversion error: 
 with 
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-744.6/src/mmap.h
com.apple.inMemoryImmutableDictionaryDispatcher.modify
com.apple.inMemoryImmutableDictionaryDispatcher.build
zh-Hans
zh-Hant
system
mixed
single_character
category
emoji
supplement
english
asset
asset_mixed
Wrong dictionary type string
Cannot load dictionary index property plist.
Cannot find properties for dictionary type 
feature_format
full
skip_syllable_lengths
Unrecognized feature format.
indexes
Cannot find index property array for dictionary type 
is_reversed
string
syllable_id
syllable_id based dictionary key must be in reversed direction
Syllable ID indexes must be before string indexes
Unrecognized dictionary key type.
has_sub_index_for_prefix
OSVersionAndBuildNumber
Analyses
DynamicDictionaries
SessionReset
MecabraAnalysisOption
CurrentAnalysisString
CandidateContext
StringContext
InputContext
AppContext
GeometryData
Empty Input Context.
Empty App Context.
set DIR as dicdir(default "." )
outdir
set DIR as output dir
model
FILE
use FILE as model file
version
show the version and exit
training-algorithm
(crf|hmm)
set training algorithm
default-emission-cost
4000
set default emission cost for HMM
default-transition-cost
set default transition cost for HMM
help
show this help and exit.
MeCab: Yet Another Part-of-Speech and Morphological Analyzer
Copyright(C) 2001-2008 Taku Kudo 
Copyright(C) 2004-2008 Nippon Telegraph and Telephone Corporation
try '--help' for more information.
dicrc
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-744.6/src/dictionary_generator.cpp
param.load(DCONF(DICRC))
sys.dic
dic.open(DCONF(SYS_DIC_FILE), "r")
!charset.empty()
default_transition_cost > 0
default transition cost must be > 0
default_emission_cost > 0
identity-template
property.open(param)
bos-feature
cost-factor
dicdir != outdir
output directory = dictionary directory! Please specify different directory.
!outdir.empty()
output directory is empty
!model.empty()
model file is empty
fi.open(param)
factor > 0
cost factor needs to be positive value
!bos.empty()
bos-feature is empty
dic.size()
no dictionary is found in 
rewrite.open(DCONF(REWRITE_FILE))
unk.def
emitting 
char.def
feature.def
done!
lid > 0
CID is not found for 
rid > 0
c >= 0
unknown property [
escape_csv_element(&w)
invalid character found: 
left.size()
left id size is empty
right.size()
right id size is empty
emitting matrix      
copying 
 to 
mmap.open(src)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-744.6/src/dictionary_rewriter.cpp
n > 0 && (n - 1) < size
 out of range: [
escape_csv_element(&elm)
[unigram rewrite]
[left rewrite]
[right rewrite]
append_to != 0
no sections found
feature.size() < sizeof(buf) - 1
too long feature
n < sizeof(col)
too long CSV entities
n == 2
*p >= '0' && *p <= '9'
not a number: 
std::strlen(feature) < sizeof(buf) - 1
len < sizeof(buf) - 3
too long parameter
too long OR nodes
n >= 2
level
0 -1
set level of evaluations
output
set the output file name
Usage: 
 output answer
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-744.6/src/eval.cpp
*ofs
ifs1
ifs2
!level_str.empty()
level_str is NULL
level.size()
level_str is empty: 
              precision          recall         F
LEVEL ALL: 
LEVEL 
:    
tokenize(buf, "\t", std::back_inserter(col), 2) == 2
format error
m <= n
 out of range 
%4.4f(%d/%d) %4.4f(%d/%d) %4.4f
set the output filename
*ifs
n <= 2
PosList.plist
posmap-univ2current.plist
posmap-current2univ.plist
posmap-migration.plist
innsbruck
properNounPosID
numeralPosID
commonNounPosID
sahenNounPosID
placeNamePosID
adjectivePosID
adverbPosID
suffixPosID
verbPosID
personNamePosID
personLastNamePosID
personFirstNamePosID
nounRegionBeginPosID
nounRegionEndPosID
verbRegionBeginPosID
verbRegionEndPosID
auxVerbRegionBeginPosID
auxVerbRegionEndPosID
particleRegionBeginPosID
particleRegionEndPosID
sahenImperativePosID
sahenConjunctivePosID
suffixAdjectiveBasePosID
suffixAdjectiveAttributivePosID
shouldResetConstraint
phraseFlags
PosInfo.plist
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-744.6/src/feature_index.cpp
**p =='['
getIndex(): unmatched '['
n < max
given index is out of range: 
unmatched '['
U:%u
B:%r/%l
tokenize2(buf, "\t ", std::back_inserter(column), 2) == 2
UNIGRAM
BIGRAM
mmap_.open(modelfile.c_str())
rewrite_.rewrite2(path->lnode->feature, &ufeature1, &lfeature1, &rfeature1)
 cannot rewrite pattern: 
rewrite_.rewrite2(path->rnode->feature, &ufeature2, &lfeature2, &rfeature2)
path->fvector
 fvector is NULL
path->rnode->fvector
fevector is NULL
unkonwn meta char: 
tokenize2(buf, "\t", std::back_inserter(column), 2) == 2
da.build(key.size(), &key[0], 0, 0, 0) == 0
unknown error in building double array: 
EUC-JP
SHIFT-JIS
UTF-16
UTF-16BE
charset 
 is not defined, use EUC-JP
The line search routine mcsrch failed: error code:
cost
FLOAT
set FLOAT for cost C for constraints violatoin
em-hmm
use EM in HMM training (experimental)
freq
set the frequency cut-off (default 1)
default-emission-freq
set the default emission frequency for HMM (default 0.5)
default-transition-freq
set the default transition frequency for HMM (default 0.0)
0.001
set FLOAT for tolerance of termination criterion
thread
number of threads(default 1)
build
build binary model from text model
text-only
output text model only
 corpus model
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-744.6/src/learner.cpp
feature_index.convert(ifile.c_str(), model.c_str())
unknown type: 
param->load(DCONF(DICRC))
eval-size
unk-eval-size
C > 0
cost parameter is out of range: 
eta > 0
] eta is out of range: 
eval_size > 0
eval-size is out of range: 
unk_eval_size > 0
unk-eval-size is out of range: 
freq > 0
freq is out of range: 
thread_num > 0 && thread_num <= 512
# thread is invalid: 
tokenizer.open(*param)
feature_index.open(*param)
reading corpus ...
_x->open(&tokenizer, &path_freelist, &feature_index, eval_size, unk_eval_size)
_x->read(&ifs, &observed)
... 
Number of sentences: 
Number of features:  
eta:                 
freq:                
threads:             
C(sigma^2):          
iter=
 err=
 target=
 diff=
ret > 0
unexpected error in LBFGS routin
Done! writing model file ... 
.txt
feature_index.save(txtfile.c_str())
feature_index.convert(txtfile.c_str(), model.c_str())
size of array is different
routine stops with unexpected error
!bos_feature.empty()
tokenize(line, "\t", std::back_inserter(col), 4) == 4
format error
std::strcmp("B", col[0]) == 0 && std::strcmp("U", col[0]) == 0
rewrite.rewrite(feature, &ufeature, &lfeature, &rfeature)
rewrite failed
format error in rewrite.def: 
rewrite.rewrite(bos_feature, &ufeature, &plfeature, &prfeature)
tokenize(line, "\t", std::back_inserter(col), 2) == 2
freq >= 0.0
 default-emission-freq must be >= 0 
tokenizeCSV(line, std::back_inserter(col), 5) == 5
Done!
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-744.6/src/learner_tagger.cpp
tokenizer_->open(param)
feature_index_->open(param)
_size == 2
!sentence.empty()
empty sentence
adding virtual node: 
feature_index_->buildFeature(path)
open-mutable-dictionary
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-744.6/src/im/connector.cpp
matrix_
matrix is NULL
cmmap_->size() >= 2
file size is invalid: 
static_cast<size_t>(header_size * 2 + (lsize_+1) * 2 + data_num_ * 2) == cmmap_->size()
static_cast<size_t>(lsize_ * rsize_ + 2) == cmmap_->size()
0 0 0
tokenize2(buf, "\t ", column, 2) == 2
tokenize2(buf, "\t ", column, 3) == 3
l < lsize && r < rsize
index values are out of range
tokenize2(buf, "\t ", std::back_inserter(column), 3) == 3
first argment seems invalid
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-744.6/src/param.cpp
pos != std::string::npos
unknown
unrecognized option `
` requres an argument
` dosen't allow an argument
mecab
Usage: 
 [options] files
 of 
0.97
, --
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-744.6/src/tagger.cpp
param_.open(argc, argv, long_options)
param_.open(arg, long_options)
load_dictionary_resource(param)
tokenizer_.open(*param)
connector_->open(*param)
viterbi_.open(*param, &tokenizer_, connector_)
writer_.open(*param)
output-format-type
dump
writer_.write(&ostrs_, str, n)
writer_.write(&os, str, n)
os.str()
output buffer overflow
writer_.writeNode(&ostrs_, static_cast<const char *>(begin_), node)
writer_.writeNode(&os, static_cast<const char *>(begin_), node)
NULL pointer is given
bosNode
(*viterbi_ptr_).lattice_level() >= 1
use -l option to obtain N-Best results. e.g., mecab -N10 -l1
writer_.write(&ostrs_, static_cast<const char *>(begin_), n)
writer_.write(&os, static_cast<const char *>(begin_), n)
nbest
invalid N value
lattice-level
dump-config
dictionary-info
filename:
version:
charset:
type:
size:
left size:
right size:
input-buffer-size
partial
input-buffer overflow. 
The line is splitted. use -b #SIZE option.
set input method language
rcfile
use FILE as resource file
set DIR  as a system dicdir
userdic
use FILE as a user dictionary
learndic
use FILE as a learn dictionary
word-completion-dic
use FILE as a word completion dictionary
lattice information level (default 0)
show dictionary information and exit
all-morphs
output all morphs(default false)
TYPE
set output format type (wakati,none,...)
partial parsing mode
%m\t%H\n
use STR as the user-defined node format
unk-format
use STR as the user-defined unk format
bos-format
use STR as the user-defined bos format
eos-format
EOS\n
use STR as the user-defined eos format
unk-feature
use STR as the feature for unknown word
set input buffer size (default 8192)
dump MeCab parameters
open dictioanry with mutable mode (experimental)
allocate-sentence
allocate new memory for input sentence
output N best results (default 1)
theta
0.75
set temparature parameter theta (default 0.75)
show the version and exit.
Dictionary Lookup
Trie Lookup
BOS/EOS
v24@?0r^{?=SsQ}8^B16
v24@?0r^{?=SsQI}8^B16
could not open dictionary 
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-744.6/src/tokenizer.cpp
property_.open(param)
unk.dic
unkdic_->open(create_filename (prefix, UNK_DIC_FILE).c_str(), mode) && setDictionaryID(unkdic_)
sys_mini.dic
succeeded && setDictionaryID(sysdic)
sysdic->type() == 0
not a system dictionary: 
d->open(_dic[i], mode) && setDictionaryID(d)
d->type() == MECAB_USR_DIC
not a user dictionary: 
learndic_->open(learndicpath.c_str(), "r+") && setDictionaryID(learndic_)
n.value != 0
cannot find UNK category: 
*bos_feature_ != '\0'
bos-feature is undefined in dicrc
max-grouping-size
.dic
v24@?0r*8^B16
sjis
shift-jis
shift_jis
cp932
euc_jp
euc-jp
utf8
utf_8
utf-8
ascii
utf-16be
utf-16le
utf-16
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-744.6/src/utils.cpp
no such directory: 
.csv
%s: %3d%% |%.*s%*s| 
HOME
.mecabrc
MECABRC
$(rcpath)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-744.6/src/viterbi.cpp
cost_factor_ > 0
cost-factor is empty
0xffff != lsize
too long lines
*(uint16_t *)(column[1]) != '\0'
use \t as separator
/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-744.6/src/viterbisub.h
bestNode
too long sentence.
none
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-744.6/src/writer.cpp
!tmp.empty()
unknown format type [
unkonwn meta char 
[iseSCwcnblLh] is required after %p
lr is required after %ph
node->lpath
no path information, use -l option
[icP] is required after %pp
node->feature[0] != '\0'
no feature information available
*++p =='['
cannot find '['
n < psize
given index is out of range
cannot find ']'
Seed
Hyoki
Yomi
__??info??__
Keyword_aux.data
UpdateSpecialKeyData
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-744.6/mecabra/IDXUserDictionary.cpp
dictionary->lastSeedVal
%@_temp
v56@?0@"NSString"8{_NSRange=QQ}16{_NSRange=QQ}32^B48
@"NSMutableArray"16@?0@"NSString"8
ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz
1234512344***=
qwertyuiopasdfghjklcvbnmzxxz
qwertyuiopasdfghjklxcvbnm
12345
v24@?0Q8^B16
v24@?0@"MecabraCandidate"8^B16
q24@?0@"NSNumber"8@"NSNumber"16
[LexicalPreferenceLearner] Rewriting candidate from
[LexicalPreferenceLearner] Rewriting candidate to
## Lexical preference applied ##
## Before finalizing weights ##
## After finalizing weights ##
v32@?0r^S8q16^B24
Adding a single dynamic word candidate
v24@?0^{__CFString=}8i16B20
v24@?0r^{mecab_node_t=^{mecab_node_t}^{mecab_node_t}^{mecab_node_t}^{mecab_node_t}^{mecab_path_t}^{mecab_path_t}**IIIssSSSSqSSCCCfC}8^B16
[Engine] Search single-word %s candidates for %s
prefix
exact
Adding a single-word prefix candidate
Adding a single-word exact candidate
Partial phrase: %s (weight: %d)
Adding a partial phrase candidate
Previous candidate
Last-bunsetsu
v24@?0r^{bigram_entry_t=ssSSS{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}}8^B16
Adding a phrase learning dictionary candidate (success)
Adding a phrase learning dictionary candidate (failure)
Added a single dynamic word candidate
Failed to add a single dynamic word candidates
Adding a bigram learning dictionary candidate
Adding a learned phrase bigram prefix candidate
## Final ##
v32@?0r^S8Q16^B24
v28@?0@"MecabraCandidate"8s16^B20
v24@?0^{__CFString=}8^B16
Creating accepted candidate from a synthetic candidate
Creating accepted candidate from a facemark candidate
Creating accepted candidate from a conversion candidate
## Before reranking ##
## After reranking ##
v44@?0^{__CFURL=}8i16^{__CFLocale=}20^{__CFString=}28^B36
Settings.plist
kanakb.dic
pos_prediction.dat
heteronyms.dat
word_cache.dat
-p -d %@ -l1
 -u %@
/Library/Dictionaries
 -g %@
 -i ja
 -i zh-Hans
 -i zh-Hant
Hans
Hant
zh-Hans-Pinyin10
zh-Hans-Pinyin
zh-Hans-Stroke
zh-Hans-Wubixing
zh-Hant-Cangjie
zh-Hant-Pinyin10
zh-Hant-Pinyin
zh-Hant-Stroke
zh-Hant-Zhuyin
ja-Romaji
ja-Kana
zh-Hans-HWR
zh-Hant-HWR
true
IPHONE_SIMULATOR_ROOT
createSystemRootPath
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-744.6/mecabra/MecabraMiscUtilities.cpp
simulatorRoot
Library/Keyboard
Cannot initialize ICU transliterator.
Cannot initialize ICU number formatter.
v28@?0I8d12^B20
isInputReadingIncompleteForWordAtIndex
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-744.6/mecabra/MecabraConversionCandidate.cpp
index < wordCount()
lastPrefixValue() <= wordCount()
inputMethodType
learningEnabled
dynamicLMEnabled
useSpecialSymbol
syncLearningData
liteMode
systemDictionaryDirectory
learningDictionaryDirectory
additionalDictionaryDirectories
staticLanguageModelBundle
dynamicLanguageModelBundle
isEndingWithPunctuation
MecabraLatticeNumberOfNodes
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-744.6/mecabra/Mecabra.mm
size <= std::numeric_limits<CFIndex>::max()
MecabraLatticeFanoutForNodeAtIndex
MecabraLatticeDestinationNodeForEdgeAtIndexFromSourceNodeAtIndex
destinationNodeIndex <= std::numeric_limits<CFIndex>::max()
%@%@
v36@?0{?=qq}8I24^B28
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-744.6/mecabra/DynamicDictionary.cpp
(entriesBufferPos + 1 + keyLength + 1 + 1 + valueLength) <= entriesBufferLength
(entriesBufferPos + 1 + valueLength) <= entriesBufferLength
v28@?0I8Q12^B20
Tokenizer
^{MecabraChineseTokenizer=^v}8@?0
emoji_adornment.plist
.%@.lock
v24@?0^{IDXUserDictionaryEntry=^Sq^Sq^SqI}8^B16
Reading
Surface
Syllables
Frequency
WordLengths
ReservedString
ReservedInteger
SurfaceSegments
ReadingSegments
PartOfSpeech
DefaultReading
ExtraString1
PinyinReading
ZhuyinReading
PinyinSyllableLengths
ZhuyinSyllableLengths
completion-learning-dictionary-zh-Hans
completion-learning-dictionary-zh-Hant
completion-learning-zh-Hans.dictionary
completion-learning-zh-Hant.dictionary
DictionaryMigrationLock
ReadingMappedString
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-744.6/mecabra/ReadingMappedString.cpp
unmappedString
phrase_candidate_accepted_count
system_dictionary_candidate_accepted_count
partial_candidate_accepted_count
abbreviated_pinyin_candidate_accepted_count
extension_candidate_accepted_count
user_dictionary_conversion_candidate_accepted_count
learning_dictionary_conversion_candidate_accepted_count
address_book_conversion_candidate_accepted_count
autocorrection_candidate_accepted_count
input_string_candidate_accepted_count
first_conversion_candidate_accepted_count
second_conversion_candidate_accepted_count
third_conversion_candidate_accepted_count
fourth_conversion_candidate_accepted_count
conversion_candidate_accepted_count
autocorrection_candidates_appeared_count
first_completion_candidate_accepted_count
second_completion_candidate_accepted_count
third_completion_candidate_accepted_count
fourth_completion_candidate_accepted_count
completion_candidate_accepted_count
completion_candidates_appeared_count
learning_dictionary_completion_candidate_accepted_count
dynamic_dictionary_completion_candidate_accepted_count
fuzzy_pinyin_enabled
input_length
accepted_candidate_length
com.apple.keyboard.%s.%@
AdjacencyListLattice
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-744.6/mecabra/AdjacencyListLattice.cpp
bosNode->stat == MECAB_BOS_NODE
<BOS>
<EOS>
<UNK>
<EXC>
Traditional - Simplified
ASSERTION FAILED: %s
SHOULD NEVER BE REACHED
%s(%d) : %s
%-3d %p %s
%-3d %p
Open file %s failed: %s
^{File<char>=*Q{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}iB}8@?0
unknown open mode for file 
could not open file 
failed to get file size for 
mmap failed for 
failed to read from 
Wrong version from 
.corrupt
v20@?0i8^B12
v32@?0r*8i16i20^B24
%@,%@
v16@?0r^{IDXUserDictionaryEntry=^Sq^Sq^SqI}8
v24@?0^{__CFString=}8^{__CFString=}16
Words
Words_tmp
DROP TABLE 
DROP TABLE Assist
PRAGMA journal_mode = WAL;
:memory:
main
ROLLBACK
BEGIN IMMEDIATE
COMMIT
MECABRA ERROR: trie data for learning dictionary is corrupted!
DELETE FROM Words WHERE Identifier = ?
SELECT Identifier FROM Words ORDER BY Seed DESC
SELECT Identifier FROM Words ORDER BY Identifier ASC
SELECT Identifier, 
 FROM Words
SELECT Identifier FROM Words WHERE Identifier = ? 
 AND 
 = ?
INSERT INTO 
 (Seed
) VALUES (?
SELECT Seed
 FROM Words WHERE Identifier = ?
UPDATE Words SET Seed = ? WHERE Identifier = ?
UPDATE Words SET Identifier = ? WHERE Identifier = ?
UPDATE Assist SET LastSeedValue = ? WHERE Identifier = 1
UPDATE Assist SET LastUpdateTime = ? WHERE Identifier = 1
UPDATE Assist SET Version = ? WHERE Identifier = 1
SELECT name FROM sqlite_master WHERE type='table' AND name='Assist'
SELECT name FROM sqlite_master WHERE type='table' AND name='Words'
SELECT COUNT(*) FROM Words
CREATE TABLE 
 (Identifier INTEGER PRIMARY KEY, Seed INTEGER
BLOB
INTEGER
CREATE TABLE Assist (Identifier INTEGER PRIMARY KEY, LastSeedValue INTEGER, LastUpdateTime REAL, Version INTEGER DEFAULT 0)
INSERT INTO Assist (LastSeedValue, LastUpdateTime, Version) VALUES (0, 0, 0)
SELECT LastSeedValue FROM Assist WHERE Identifier = 1
SELECT LastUpdateTime FROM Assist WHERE Identifier = 1
SELECT Version FROM Assist WHERE Identifier = 1
ALTER TABLE 
 RENAME TO 
SELECT 
SELECT Identifier FROM Words WHERE 
SELECT Identifier, Seed, 
ja_JP
EEEE
MMMM
SortedRadicals.plist
WordProperties_CharacterInformation.dictionary
WordProperties_KeyLookup.dictionary
analysisString
T@"NSString",C,N,V_analysisString
characterInformation
T@"NSArray",&,N,V_characterInformation
codeLookupInformation
T@"NSArray",&,N,V_codeLookupInformation
TB,N,GisEmoji,V_emoji
language
Ti,N,V_language
CREATE TABLE main (id INTEGER PRIMARY KEY AUTOINCREMENT, prefix BLOB, completion BLOB, count INTEGER DEFAULT 1,version INTEGER DEFAULT 0)
PRAGMA journal_mode = WAL
SELECT id, count FROM main WHERE prefix = ?1 AND completion = ?2
INSERT INTO main (prefix, completion) VALUES (?1, ?2)
SELECT completion, count FROM main WHERE prefix = ?
UPDATE main SET count = ?1 WHERE id = ?2
DELETE FROM main WHERE id = ?
DELETE FROM main WHERE prefix = ?1 AND completion = ?2
INSERT INTO main (prefix, completion, count) VALUES (?1, ?2, ?3)
SELECT prefix, completion, count FROM main
Failed to create completion component.
v32@?0^{?=^{Token}*}8Q16^B24
v24@?0^{SeaweedFileMappedImmutableDictionary=^^?CI^{BurstTrie}IIIi{shared_ptr<File<char> >=^{File<char>}^{__shared_weak_count}}^{Token}*{vector<BurstTrie, std::__1::allocator<BurstTrie> >=^{BurstTrie}^{BurstTrie}{__compressed_pair<BurstTrie *, std::__1::allocator<BurstTrie> >=^{BurstTrie}}}{vector<unsigned int *, std::__1::allocator<unsigned int *> >=^^I^^I{__compressed_pair<unsigned int **, std::__1::allocator<unsigned int *> >=^^I}}^{FeatureInterpreter}{vector<unsigned int, std::__1::allocator<unsigned int> >=^I^I{__compressed_pair<unsigned int *, std::__1::allocator<unsigned int> >=^I}}{vector<BurstTrie, std::__1::allocator<BurstTrie> >=^{BurstTrie}^{BurstTrie}{__compressed_pair<BurstTrie *, std::__1::allocator<BurstTrie> >=^{BurstTrie}}}{vector<unsigned int *, std::__1::allocator<unsigned int *> >=^^I^^I{__compressed_pair<unsigned int **, std::__1::allocator<unsigned int *> >=^^I}}[256C]}8^B16
/System/Library/PrivateFrameworks/ProofReader.framework
http
Simplified - Traditional
abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ
failed to set backup exclusion for item at URL: %s
[[:Hani:]]
B24@?0r^S8q16
%p, cost = %f, history = %s
Phrases-en_US
v44@?0I8r*12d20I28I32^B36
%@ %@
taiwan
tibet
best
[makeSegmentsExceptLast] top segment
[makeSegmentsExceptLast] best segment
Adding top candidate
added
replaced
no update
top candidate
Last-bunsetsu candidate #
segments except last
last segments
yyyy-MM-dd@HHmm.ssSS
/tmp/GeometryModel
/tmp/GeometryModel/%@-%@.plist
getLoglikelihoodOfKeys:length:touch_index:totalCount:
keys
log likelihoods
stringFromGeometryData
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-744.6/mecabra/GeometryModel.mm
numKeys > 0
%C:%f
{0:0}
DEBUG_PRINT_NODES
DEBUG_PRINT_WORD_GROUPS
DEBUG_PRINT_SYLLABLE_LATTICE
DEBUG_PRINT_CONNECTED_NODES
DEBUG_PRINT_HYPOTHESES
DEBUG_PRINT_HYPOTHESIS_SETS
DEBUG_HOMOPHONE_PHRASES
DEBUG_NGRAM_SCORE
DEBUG_NGRAM_QUANTIZATION
DEBUG_INCREMENTAL_ANALYSIS
DEBUG_PINYIN_TEXT_CHECKING
MECABRA_LOG_TIMING
MECABRA_LOG_STATISTICS
DEBUG_PRINT_CHARACTER_LATTICE
LOG_GEOMETRY_MODEL_DATA
DEBUG_PRINT_BEST_BACKTRACE
DEBUG_RERANKING
DEBUG_LEARNING
DEBUG_DYNAMIC_CANDIDATES
DEBUG_ENGINE
DEBUG_PREDICTION
DEBUG_PRINT_ADAPTATION
DEBUG_PRUNING
DEBUG_LIVE_CONVERSION
MECABRA_LOG_DESTINATION
Cannot open specified log file %s.
All logging is turned off.
MECABRA_LOG_BUFFERED
MecabraLogLevel
Log message exceeded the 1024-byte length limit.
[%s] started at (%lu, %lu)
[%s] paused at (%lu, %lu), total time elapsed %.8f seconds
[%s] Total time elapsed %.8f seconds
%s: elapsed %fms
SessionViterbi::connect
SessionViterbi::build
SessionViterbi::build (lattice manipulations)
total hypotheses created: %d
total hypothesis sets created: %d
%@ (AS:%@ CAS:%@ DR:%@), %ld, %f
%@ (AS:%@ CAS:%@ DR:%@), %ld
GARBAGE
(%@)
rawCandidate
T^{MecabraCandidateBase=^^?q},R,N
rawConversionCandidate
T^{ConversionCandidate=^^?q},R,N
isConversionCandidate
TB,R,N
isSyntheticCandidate
isExtensionCandidate
isEmojiCandidate
isPersonName
isLearningDictionaryCandidate
isUserWordCandidate
isPredictionCandidate
isFuzzyMatchCandidate
isAutocorrectedCandidate
isOTAWordlistCandidate
Ti,R,N
wordCount
TQ,R,N
surface
T@"NSString",R,N
convertedAnalysisString
dictionaryReading
attributes
T@"NSDictionary",R,N
kEmbedded
kUsePhraseBigramPrediction
kUsePosBasedPrediction
kUsePhrasePrefixDictionary
kUseTransliteration
kUseLanguageModel
kWeightLimitCoefficient
kNgramCandidateCost
kPartialCandidatePenalty
kCostPenaltyForWordSuffixCompletion
kCostThresholdForAmbiguousPos
kCostThresholdForPartialCandidates
kCostThresholdForSinglePhraseCandidates
kCostThresholdForMultiPhraseCandidates
kMaxNumSingleWordExactMatchCandidates
kMaxNumSingleWordPrefixMatchCandidates
kMaxNumSingleWordSuffixCompletionCandidates
kMaxNumMultiwordCandidates
kMaxNumMultiwordCandidateRequests
kMaxNumPartialCandidates
kMaxNumSinglePhrasePartialCandidates
kSingleWordPrefixSearchContextOrder
kLongLearnedPhraseRemoveLength
kMaxNumPhrasePrefixMatchCandidates
kMaxNumPhraseBigramPrefixMatchCandidates
kMaxNumPhraseBigramCandidates
kMaxNumBigramLearnedCandidates
kMaxNumLearnedNgramCandidates
kPhraseBigramContextOrder
kPhrasePrefixSearchContextOrder
kPhrasePrefixSearchMaxSearchKeyLength
kPhrasePrefixSearchMaxReadingLength
kLearnedPhraseBigramMinPrefixSearchKeyLength
kLearnedPhraseBigramMaxPrefixSearchKeyLength
kMaxHomophoneLearnedCandidateCount
kRomajiCapitalizedCandidateRank
kRomajiUpperCaseCandidateRank
kRomajiAsIsCandidateRank
kKatakanaAsIsCandidateRank
kHiraganaAsIsCandidateRank
kProperNounDefaultCost
kPhrasePrefixBaseCost
kPhrasePrefixCostFactor
kPhrasePrefixLengthPenalty
kPhrasePredictionBaseCost
kPhrasePredictionCostFactor
kPhrasePredictionLengthPenalty
kPhraseLearningBaseCost
kPhraseLearningLengthPenalty
kBigramLearningBaseCost
kBigramLearningPrefixBaseCost
kUserDictionaryCandidateBaseCost
kSpecialtyDictionaryEntryCost
kAverageLikelihood
kPrefixMatchCandidateBasePenalty
kPrefixMatchCandidateLengthPenalty
kKanaAmbiguousTokenPenalty
kPhraseEntryNotUsedInConversionCostLimit
kOOVKatakanaWordMinLength
kOOVKatakanaWordMaxLength
kOOVKatakanaWordMaxCost
kOOVKatakanaWordPenaltyCostFactor
Conversion
[ME::acceptLeftContext] #
[ME::acceptInlineContext] #
[ME:analyzeStringWithContext] Using a truncated context candidate
[ME::acceptCandidate] Accepted
v52@?0r^{UTF16String=^SQ}8r^{UTF16String=^SQ}16r^{UTF16String=^SQ}24r^{UTF16String=^SQ}32i40i44i48
^{MecabNodeWord=^^?Ciii{auto_ptr<MeCab::WordCore>=^{WordCore}}B}48@?0r^{mecab_node_t=^{mecab_node_t}^{mecab_node_t}^{mecab_node_t}^{mecab_node_t}^{mecab_path_t}^{mecab_path_t}**IIIssSSSSqSSCCCfC}8^S16Q24r^S32I40B44
wordListFile
candidates
incrementalAnalysisCount
totalAnalysisCount
Adding a partial candidate
Q24@?0^{trie_search_result_type_t=ccfIQ}8Q16
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-744.6/mecabra/CharacterInfo/NSString+CharacterInformationAdditions.mm
<Unknown File>
Invalid parameter not satisfying: %@
toneNumber >= 1 && toneNumber <= 4
zh00
sh00
ch00
ing0
ai00
an00
ang0
ao00
ei00
en00
eng0
ia00ian0
iang
iao0
ie00
in00
iu00
ong0
ou00
ua00
uai0
uan0
ue00
un00
ui00
uo00
uang
er00
iong
a000
e000 i000!o000"u000#v000$on00%io00&ion0've00(ea00)
%K = %@
Delete
Partial Entry
Matching
Set Value
Duplicate entry
Restrict amount
Automatic Delete
Set Values
Uniquing
%@ [%@] 
[%@] 
[CoreData]
MecabraDatabaseUpdatedNotification
MecabraDatabaseChangedNotification
MecabraDatabaseDeletedAllElementsNotification
.bundle
%@_%@
Exception when trying to create new persistent store: %@
Could not create coordinator
B24@?0@"NSURL"8@"NSError"16
journal_mode
DELETE
Error in saving database; %@ %@
localURL
T@"NSURL",&,N,V_localURL
storedElementsForMerge
T@"NSArray",&,N,V_storedElementsForMerge
entityDescription
T@"NSEntityDescription",R,N,V_entityDescription
localStoreURL
T@"NSURL",R,N
localInfoPlistURL
managedObjectModel
T@"NSManagedObjectModel",&,N,V_managedObjectModel
managedObjectContext
T@"NSManagedObjectContext",&,N,V_managedObjectContext
persistentStoreCoordinator
T@"NSPersistentStoreCoordinator",&,N,V_persistentStoreCoordinator
storeURL
T@"NSURL",&,N,V_storeURL
T@"NSString",&,N,V_type
database.db
CoreDataUbiquitySupport
Lexicon
^{Lexicon=^v^v}8@?0
.plist
Dictionaries/Storage.nosync/%@/database.db
Dictionaries
descriptionDictionary
T@"NSMutableDictionary",&,N,V_descriptionDictionary
T@"NSString",R,&,N,V_type
ubiquityContainerIdentifier
/usr/share/mecabra/common/descriptions/
EntityDescriptionURL
EntityModelName
EntityRequiredKeys
EntityUniquingKeys
SortDescriptors
SortDescriptorName
SortDescriptorAscending
com.apple.TextInput
DatabaseSyncs
%@:(%ld)
dictionary ID = %d
Error has occured when process word in %s ... 
Word ID = %d, token offset = %zu
Added %zu words
verify
Incorrect commandline arguments!
langugae
Too few arguments.
Language is not specified.
Language must be "zh-Hans" or "zh-Hant".
Failed to build reverse dictionary %s.
Failed to process %s.
locale
directory
s:i:d:
Locale is required.
Word-ID map is required.
Directory of source dictionaries is required.
Incorrect number of arguments.
Locale can must be zh-Hans or zh-Hant.
Cannot verify reverse dictionary %s!
Failed to load reverse dictionary %s
Didn't find word ID for %s(%d) in word to ID mapping file.
word to ID mapping file contains different word ID (%d) for %s(%d)
Usage:
%s <command> [args] [DictionaryFileName+] ReverseDictionaryFileName
build:
DictionaryFileName argument is required for build command.
-l|--language: "zh-Hans" or "zh-Hant".
verify:
-s|--locale: Locale.
-i|--id: Word to word ID mapping file.
-d|--directory: Directory containing source dictionaries.
com.apple.MobileAsset.LinguisticData.new-asset-installed
com.apple.mecabra.mobileassetnotificationmanager
v12@?0i8
Mecabra: Notification "%s" registration success (token=%d)
Mecabra: Notification "%s" registration FAILURE (status=%u)
Mecabra Mobile Asset changed!
q24@?0@"MecabraCandidate"8@"MecabraCandidate"16
MecabraLearningResetNotification
v32@?0^{__CFDictionary=}8^{map<std::__1::basic_string<char>, std::__1::shared_ptr<EntryFieldValue>, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, std::__1::shared_ptr<EntryFieldValue> > > >={__tree<std::__1::__value_type<std::__1::basic_string<char>, std::__1::shared_ptr<EntryFieldValue> >, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, std::__1::shared_ptr<EntryFieldValue> >, std::__1::less<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__value_type<std::__1::basic_string<char>, std::__1::shared_ptr<EntryFieldValue> > > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<std::__1::basic_string<char>, std::__1::shared_ptr<EntryFieldValue> >, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, std::__1::shared_ptr<EntryFieldValue> >, std::__1::less<std::__1::basic_string<char> >, true> >=Q}}}16^B24
LearningDictionary
DynamicPhraseLexicon_zh_Hans.db
PhraseLearning_zh_Hans.db.bundle
PhraseLearning_zh_Hans.db
PhraseLearning_zh_Hans.dictionary
StructuralPinyinLearning_zh_Hans.db.bundle
StructuralPinyinLearning_zh_Hans.db
StructuralPinyinLearning_zh_Hans.dictionary
DynamicPhraseLexicon_zh_Hant_pinyin.db
PhraseLearning_zh_Hant_pinyin.db.bundle
PhraseLearning_zh_Hant_pinyin.db
PhraseLearning_zh_Hant_pinyin.dictionary
StructuralPinyinLearning_zh_Hant_pinyin.db.bundle
StructuralPinyinLearning_zh_Hant_pinyin.db
StructuralPinyinLearning_zh_Hant_pinyin.dictionary
DynamicPhraseLexicon_zh_Hant_zhuyin.db
PhraseLearning_zh_Hant_zhuyin.db.bundle
PhraseLearning_zh_Hant_zhuyin.db
PhraseLearning_zh_Hant_zhuyin.dictionary
StructuralZhuyinLearning_zh_Hant_zhuyin.db.bundle
StructuralZhuyinLearning_zh_Hant_zhuyin.db
StructuralZhuyinLearning_zh_Hant_zhuyin.dictionary
ReversedDictionary
^{ReverseDictionary={shared_ptr<File<char> >=^{File<char>}^{__shared_weak_count}}{vector<std::__1::shared_ptr<Seaweed::SeaweedFileMappedImmutableDictionary>, std::__1::allocator<std::__1::shared_ptr<Seaweed::SeaweedFileMappedImmutableDictionary> > >=^{shared_ptr<Seaweed::SeaweedFileMappedImmutableDictionary>}^{shared_ptr<Seaweed::SeaweedFileMappedImmutableDictionary>}{__compressed_pair<std::__1::shared_ptr<Seaweed::SeaweedFileMappedImmutableDictionary> *, std::__1::allocator<std::__1::shared_ptr<Seaweed::SeaweedFileMappedImmutableDictionary> > >=^{shared_ptr<Seaweed::SeaweedFileMappedImmutableDictionary>}}}i^{Header}^I{shared_ptr<InputEngine::CharacterMap>=^{CharacterMap}^{__shared_weak_count}}}8@?0
Failed to load character map for language 
 is unsupported language value.
supplement.dic
mixed.dic
english.dic
 is not a recognized source dictionary name.
Token offset 
 is out of range. The max offset value is 0x1FFFFF.
Failed to open dictionary 
Failed to open dictionary : %s
LexicalLearning_ja_JP.db
NonLexicalLearning_ja_JP.db
FirstSurface
SecondReading
SecondSurface
SecondReadingSegments
SecondSurfaceSegments
SecondPartOfSpeech
online
offline
%@/%@ 
%@ (%d) 
Migrating %s %s %u %u (%u,%u,%u..).
Migrating %s => %s %s %u %u (%u,%u,%u..).
Lexierra_ja_JP-dynamic-text.dat
LexicalLearning_ja_JP.dat
DynamicPhraseLexicon_ja_JP.db
PhraseLearning_ja_JP.db.bundle
PhraseLearning_ja_JP.dictionary
PhraseLearning_ja_JP.db
BigramLearning_ja_JP.dictionary
BigramLearning_ja_JP.db
DynamicBigramPhraseLexicon_ja_JP.db
BigramLearning_ja_JP.db.bundle
LearningDictionaryJapanese
JapaneseBigram
Building dictionary: %s
%s usage: <template file> <dictionary data file> <new dictionary path> 
can't read template from file %@
can't create URL for new dictionary %@
error building dictionary
Dictionary was built successfully.
reading dictionary data file %@ failed with error %@
bad dictionary data %@
POS:
LeftPOS1:
LeftPOS2:
RightPOS1:
RightPOS2:
LeftSurface1:
LeftSurface2:
RightSurface1:
RightSurface2:
LeftSurface1
LeftSurface2
RightSurface1
LeftPOS1
LeftPOS2
RightPOS1
Feature
IntValue
StrValue
expandTokenSequence: searching depth:%d reading:%s surface:%s remaining:%s lengthToMatch:%ld
expandTokenSequence: matched depth:%d surface:%@
expandTokenSequence: adding depth:%d surface:%@
expandTokenSequence: %s %s is blacklisted.
v48@?0r^I8q16d24q32^B40
[makeCandidateFromExpandedSequence]
getAndCheckContextSurfaceAndReadingFromCandidate: %s %s is an invalid context word.
getAndCheckContextSurfaceAndReadingFromHistory: %s %s is an invalid context word.
n-gram expansion from
makeCandidateFromExpandedSequence: matching inputStr:%s predictedReading:%s matchResult:%d incompleteLength:%ld
v24@?0^{DynamicDictionaryEntry=^Sq^Sq}8^B16
LearningSet_zh_Hans.plist
LearningSet_zh_Hant.plist
Not allow multiple dictionary to be built at the same time.
sysdic
phrase_bigram
reading_bigram
binary
matrix
set DIR as dicdi (default ".")
set DIR as output dir (default ".")
build user dictionary
build supplement dictionary
build parameters for unknown words
build system dictionary
phrase_bigram file
reading_bigram file
binary dictionary name
build connection matrix
show this help and exit
Revert learning for candidate %s
v16@?0^{__CFString=}8
:/-_+@#
Best backtrace:
 -> 
(%s, %d)
B16@?0r^{BacktraceWaypoint=^{WordCore}^{BacktraceWaypoint}}8
candidateContext
T@"NSMutableArray",&,N,V_candidateContext
rebuildCandidateContextString
TB,N,V_rebuildCandidateContextString
candidateContextString
T@"NSMutableString",&,N,V_candidateContextString
stringBeforeCaret
T@"NSString",&,N,V_stringBeforeCaret
stringContext
T@"NSString",&,N,V_stringContext
candidateContextForAnalysis
T@"NSArray",R,N
stringContextForAnalysis
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-744.6/mecabra/Dictionary/MecabraJapaneseDictionaryCompiler.cpp
m_iconvFromUTF16ToUTF8.convert(str)
error with convertToUTF8 iconv convert!
count == kTokenColumnCount
Wrong format with unigram string: 
 at line 
stringToUInt16(std::string(col[3]), cost)
wrong cost!
count == 6
Wrong format with unigram string
stringToUInt16(std::string(col[4]), cost)
stringToUInt16(std::string(col[2]), rid1)
wrong rid1!
count == 3
wrong format.
m_iconvFromUTF8ToUTF16.convert(&bigramToken->previous)
error with iconv convert!
stringToUInt16(std::string(col[1]), &(bigramToken->prob))
wrong probability value!
bigramToken->prob <= 100
probability value is more than 100!
fields.size() == kTokenColumnCount - 1
Field count 
 is not expected! expected: 
stringToUInt16(fields[1], &lid)
error with stringToUInt16!
stringToUInt16(fields[2], &rid)
stringToUInt16(fields[3], &attribute)
stringToUInt32(fields[4], &tokenID)
m_iconvFromUTF8ToUTF16.convert(&token->reading)
m_iconvFromUTF8ToUTF16.convert(&token->surface)
m_trie.lookup(m_agent)
cannot find entry in trie.
Start to validate dictionary: 
DictionaryValidate done: 
Unigram testing
v24@?0r^{mecab_token_t=sSSSI}8^B16
found == true
cannot found the entry.
count == unigramReadingAndTokensPair.tokens.size()
count doesn't match.
Unigram testing done
Phrase bigram testing.
Reading bigram testing.
v24@?0r^{BigramToken=sII}8^B16
cannout found the bigram entry.
count == firstStringAndTokensPair.tokens.size()
Phrase bigram testing done.
Reading bigram testing done.
token->reading.size()
token reading is empty
token->surface.size()
token surface is empty
iterator == m_tokenIDToUnigramTokenIndexMap.end()
tokenID should be unique.
tokenCount == m_sortedUnigramTokenArray.size()
m_sortedUnigramTokenArray.size is not equal to the token count in m_unigramReadingAndTokensPairList.
token->previous.size()
iterator != m_tokenIDToUnigramTokenIndexMap.end()
wrong mapping from token ID to token index.
convertToKatakana(rawToken.reading, &unigramSurfaceString)
cannot convert to katakana.
homographCount <= 0xff
homographCount is greater than 0xff.
tokenIndex <= 0x00ffffff
tokenIndex is greater than 0x00ffffff.
------------Characters at pos 
 characters --------------- 
------------words at pos 
 cursors --------------- 
/System/Library/LinguisticData/RequiredAssets_zh-Hant.bundle/AssetData/commercial.dic
/System/Library/LinguisticData/RequiredAssets_zh-Hant.bundle/AssetData/computer.dic
/System/Library/LinguisticData/RequiredAssets_zh-Hant.bundle/AssetData/industry.dic
/System/Library/LinguisticData/RequiredAssets_zh-Hant.bundle/AssetData/education.dic
/System/Library/LinguisticData/RequiredAssets_zh-Hant.bundle/AssetData/traffic.dic
/System/Library/LinguisticData/RequiredAssets_zh-Hant.bundle/AssetData/law_poli.dic
/System/Library/LinguisticData/RequiredAssets_zh-Hant.bundle/AssetData/build.dic
/System/Library/LinguisticData/RequiredAssets_zh-Hant.bundle/AssetData/cmedic.dic
/System/Library/LinguisticData/RequiredAssets_zh-Hant.bundle/AssetData/medical.dic
/System/Library/LinguisticData/RequiredAssets_zh-Hant.bundle/AssetData/biology.dic
/System/Library/LinguisticData/RequiredAssets_zh-Hant.bundle/AssetData/military.dic
/System/Library/LinguisticData/RequiredAssets_zh-Hant.bundle/AssetData/phy_chem.dic
/System/Library/LinguisticData/RequiredAssets_zh-Hant.bundle/AssetData/sport.dic
/System/Library/LinguisticData/RequiredAssets_zh-Hant.bundle/AssetData/buddhism.dic
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-744.6/seaweed/Dictionary/SeaweedChineseDictionaryCompiler.cpp
m_converter.open("UTF-8", "UTF-16LE")
iconv_open() failed (from UTF-8 to UTF-16LE)
index_config
Cannot load dictionary index properties. Error: 
priority
input
pinyin_syllable
zhuyin_syllable
wrong language
columnCount == kOriginalFeatureStartColumn + 1
CSV format error: 
originalFeature.size()
feature empty error: 
featureColumnCount > data.syllableIDIndexCount()
feature format error: 
data.syllableIDIndexCount() <= data.indexCount()
feature format error (syllable ID index count is too big): 
readingColumnCount == data.indexCount()
reading format error: 
!readingString.empty()
readingString error: 
iconv.convert(&readingString)
convert reading error: 
iconv.convert(&convertedReading)
!convertedReading.empty()
empty converted reading error: 
set as input text file
set as output file
set as pinyin syllable data file
set as zhuyin syllable data file
dictionary type(system, supplement, single_character, category, emoji, english, asset (not implemented))
index configuration file
languge: zh-Hans or zh-Hant
compile_block_invoke
featureDataOffset < UINT32_MAX
v16@?0r^{RawDictionaryEntry=iii{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}{vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > >=^{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >}^{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >}{__compressed_pair<std::__1::basic_string<char> *, std::__1::allocator<std::__1::basic_string<char> > >=^{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >}}}}8
(out.tellp() % kAlignmentNumber) == 0
header is not aligned: 
trie data header is not aligned: 
token buffer is not aligned: 
 compiled successfully.
m_data.indexCount() == dictionary->indexCount()
dictionary index count error. 
validate_block_invoke
featureOffset < UINT32_MAX
v24@?0^{?=^{Token}*}8^B16
[ERROR] validation failed on index 
 for line 
v40@?0^{?=^{Token}*}8r*16Q24^B32
keyTokenPairs.size() <= kMaxTrieEntryCount
trie can hold a maximum of 
 entries.
homographCount <= kMaxHomographEntryCount
number of homograph words is greater than 
. string =
allKeys.size()
no reading error. 
keyTokenOffsetPairs.size() <= kMaxTrieEntryCount
m_data.indexCount() > m_data.syllableIDIndexCount()
trie must hold at least one one non-syllable index
trie data is not aligned: 
token index buffer is not aligned: 
reading[i] >= 'a' && reading[i] <= 'z'
not valid pinyin error: 
isZhuyinToneMark(zhuyin[i]) || isValidZhuyin(zhuyin[i])
not valid zhuyin error: 
person
KKK1
syllableLengths[i]
syllable length is zero: 
total == reading.size()
syllable length doesn't match reading: 
syllableID != kInvalidIndex
cannot get syllable ID from syllable trie: 
v44@?0r^{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}8r^{Token=ISSI}16Q24B32^B36
*!@#$%
v20@?0I8^{__CFDictionary=}12
single_character.dic
single_character2.dic
single_character3.dic
facemarks.plist
zh-Latn-CN-pinyin
zh-Hans-Latn-CN-pinyin
syllable.lm
charmap.dat
syllable.dat
emoji_conversion.dat
emoji_adornment.dat
wid.dat
reverse.dic
reading-lookup.dat
Cangjie.dictionary
CangjieCodes.dat
Stroke.dictionary
Wubixing.dictionary
homophones.plist
PinyinToZhuyin.plist
ZhuyinToPinyin.plist
rewrite.dat
LanguageModel
Synthetic
Proactive
Root
Mixed
PhraseLearning_zh_Hant_Cangjie.db.bundle
DynamicPhraseLexicon_zh_Hant_Cangjie.db
PhraseLearning_zh_Hans_Stroke.db.bundle
DynamicPhraseLexicon_zh_Hans_Stroke.db
PhraseLearning_zh_Hant_Sucheng.db.bundle
DynamicPhraseLexicon_zh_Hant_Sucheng.db
PhraseLearning_zh_Hant_Stroke.db.bundle
DynamicPhraseLexicon_zh_Hant_Stroke.db
DynamicPhraseLexicon_zh_Hans_Wubixing.db
PhraseLearning_zh_Hans_Wubixing.db.bundle
v24@?0^{LatticeSearchState=^{SyllableNodeBase}QQSSI{vector<std::__1::pair<unsigned char, Seaweed::DictionaryCursorInfo>, std::__1::allocator<std::__1::pair<unsigned char, Seaweed::DictionaryCursorInfo> > >=^{pair<unsigned char, Seaweed::DictionaryCursorInfo>}^{pair<unsigned char, Seaweed::DictionaryCursorInfo>}{__compressed_pair<std::__1::pair<unsigned char, Seaweed::DictionaryCursorInfo> *, std::__1::allocator<std::__1::pair<unsigned char, Seaweed::DictionaryCursorInfo> > >=^{pair<unsigned char, Seaweed::DictionaryCursorInfo>}}}}8Q16
v24@?0r^{WordCore=^^?i^{WordGroupTraits}{vector<unsigned int, std::__1::allocator<unsigned int> >=^I^I{__compressed_pair<unsigned int *, std::__1::allocator<unsigned int> >=^I}}}8^B16
B16@?0Q8
v52@?0^{LatticeSearchState=^{SyllableNodeBase}QQSSI{vector<std::__1::pair<unsigned char, Seaweed::DictionaryCursorInfo>, std::__1::allocator<std::__1::pair<unsigned char, Seaweed::DictionaryCursorInfo> > >=^{pair<unsigned char, Seaweed::DictionaryCursorInfo>}^{pair<unsigned char, Seaweed::DictionaryCursorInfo>}{__compressed_pair<std::__1::pair<unsigned char, Seaweed::DictionaryCursorInfo> *, std::__1::allocator<std::__1::pair<unsigned char, Seaweed::DictionaryCursorInfo> > >=^{pair<unsigned char, Seaweed::DictionaryCursorInfo>}}}}8Q16r^{UTF16String=^SQ}24^{?=^{Token}*}32i40^B44
v56@?0Q8r^S16Q24r^S32Q40S48S52
NewWordPenalty
createHybridCandidateWithConversionCandidate
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-744.6/mecabra/ChinesePrediction/ChinesePredictionCandidate.mm
v48@?0{?=qq}8r^{vector<unsigned short, std::__1::allocator<unsigned short> >=^S^S{__compressed_pair<unsigned short *, std::__1::allocator<unsigned short> >=^S}}24r^{vector<unsigned short, std::__1::allocator<unsigned short> >=^S^S{__compressed_pair<unsigned short *, std::__1::allocator<unsigned short> >=^S}}32r^{vector<unsigned short, std::__1::allocator<unsigned short> >=^S^S{__compressed_pair<unsigned short *, std::__1::allocator<unsigned short> >=^S}}40
%@(%d) 
 EOS
(%d)
iang
uang
iong
chon
jion
qion
xion
zhon
bang
beng
bian
biao
bing
cang
ceng
chai
chan
chang
chao
chen
cheng
chong
chou
chua
chuai
chuan
chuang
chui
chun
chuo
cong
cuan
dang
deng
dian
diao
ding
dong
duan
fang
feng
gang
geng
gong
guai
guan
guang
hang
heng
hong
huai
huan
huang
jian
jiang
jiao
jing
jiong
juan
kang
keng
kong
kuai
kuan
kuang
lang
leng
lian
liang
liao
ling
long
luan
lvan
mang
meng
mian
miao
ming
nang
neng
nian
niang
niao
ning
nong
nuan
pang
peng
pian
piao
ping
qian
qiang
qiao
qing
qiong
quan
rang
reng
rong
ruan
sang
seng
shai
shan
shang
shao
shei
shen
sheng
shou
shua
shuai
shuan
shuang
shui
shun
shuo
song
suan
tang
teng
tian
tiao
ting
tong
tuan
wang
weng
xian
xiang
xiao
xing
xiong
xuan
yang
ying
yong
yuan
zang
zeng
zhai
zhan
zhang
zhao
zhei
zhen
zheng
zhong
zhou
zhua
zhuai
zhuan
zhuang
zhui
zhun
zhuo
zong
zuan
biang
cuai
cuang
diang
duang
fong
fuai
fuan
fuang
juang
luang
miang
nuang
piang
quang
rian
riang
riao
ring
ruang
shong
suai
suang
tiang
tuang
xuang
yuang
zuai
zuang
v16@?0Q8
v16@?0^{?=Sf}8
%s: %s
Remove
-------------------- input = 
 ------------------
syllables ending with input char 
 at pos 
complete syllable: 
incomplete syllable: 
Autocorrected Complete syllable: 
prob = 
Previous syllable = 
 rawInputLength = 
Next syllable = 
Autocorrected Incomplete syllable: 
Synthetic syllable: mixed, length = 
Synthetic syllable: 
Start column indexes: 
First syllables: 
First syllable end column indexes: 
, separatorCount = 
, rawInputLength = 
 (fuzzy), original = 
bitset set argument out of range
bitset test argument out of range
syllableIndex = %d, firstChildNodeIndex = %d, firstChildChar = %c,length = %d, type = %d, completeSyllableCount = %d, completeSyllableStart = %d, childNumber = %d 
Syllable trie file %s is incompatible (version %d, expected version %d)
Syllable trie open failed: %s
seed
Failed to delete legacy learning dictionary: %s
^{Hypothesis=[2I]Cd{BacktraceWaypoint=^{WordCore}^{BacktraceWaypoint}}}8@?0
===RESET===
===cummulative stats since last reset===
hypotheses created = %ld
hypothesis sets created = %ld
words created = %ld
word groups created = %ld
%@ (%@)
T@"NSString",R,N,V_string
T@"NSString",R,N,V_category
synthetic word group:
type = 
syllable IDs: 
Syllable Lengths:
length = 
, trieValue = 
facemark.dat
FacemarkLearning
^{FacemarkLearningDictionary={basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}{FacemarkLearningDictionaryHeader=IIId}{vector<InputEngine::FacemarkLearningDictionary::FacemarkLearningEntry, std::__1::allocator<InputEngine::FacemarkLearningDictionary::FacemarkLearningEntry> >=^{FacemarkLearningEntry}^{FacemarkLearningEntry}{__compressed_pair<InputEngine::FacemarkLearningDictionary::FacemarkLearningEntry *, std::__1::allocator<InputEngine::FacemarkLearningDictionary::FacemarkLearningEntry> >=^{FacemarkLearningEntry}}}}8@?0
^{Hypothesis=[2I]Cd{BacktraceWaypoint=^{WordCore}^{BacktraceWaypoint}}}32@?0r^{WordCore=^^?i^{WordGroupTraits}{vector<unsigned int, std::__1::allocator<unsigned int> >=^I^I{__compressed_pair<unsigned int *, std::__1::allocator<unsigned int> >=^I}}}8d16r^{Hypothesis=[2I]Cd{BacktraceWaypoint=^{WordCore}^{BacktraceWaypoint}}}24
adding word group endIndex=%d {
v24@?0r^{WordGroup={WordGroupTraits=^{SyllableSequence}^{__CFString}QIIIi}{vector<Seaweed::LatticeWord *, std::__1::allocator<Seaweed::LatticeWord *> >=^^{LatticeWord}^^{LatticeWord}{__compressed_pair<Seaweed::LatticeWord **, std::__1::allocator<Seaweed::LatticeWord *> >=^^{LatticeWord}}}B}8Q16
^{WordGroup={WordGroupTraits=^{SyllableSequence}^{__CFString}QIIIi}{vector<Seaweed::LatticeWord *, std::__1::allocator<Seaweed::LatticeWord *> >=^^{LatticeWord}^^{LatticeWord}{__compressed_pair<Seaweed::LatticeWord **, std::__1::allocator<Seaweed::LatticeWord *> >=^^{LatticeWord}}}B}8@?0
v24@?0r^{Hypothesis=[2I]Cd{BacktraceWaypoint=^{WordCore}^{BacktraceWaypoint}}}8^B16
__insert_nodes
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-744.6/src/trie_build.cpp
new_children
wordpooldic
build wordpool dictionary
supplementsysdic
build supplement sys dictionary
charcategory
build character category maps
make charset of binary dictionary ENC (default EUC-JP)
alias of -c
assume charset of input CSVs as ENC (default EUC-JP)
build wakati-gaki only dictionary
posid
assign Part-of-speech id
don't validate pos ID values.
use STR as the user defined node format
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-744.6/src/im/dictionary_compiler.cpp
no dictionaries are specified
v40@?0r^{mecab_token_t=sSSSI}8r*16Q24^B32
This functionality has not been implemented for mutable dictionary!
Dictionary file %s is empty
Dictionary file %s doesn't support the original format
Dictionary file %s has an empty header
Dictionary file %s is incompatible (version %d, expected version %d)
Dictionary file %s has the wrong content
header check failed
Emoji file %s is empty
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-744.6/mecabra/EmojiDictionary.cpp
columnCount >= 3
Wrong column count: 
emojiCount > 0 && emojiCount < kMaxFeatureCount
Wrong features: 
currentFeatureOffset < kMaxFeatureOffset
Exceed the feature offset limit: 
ofstream is empty: 
SuppressSensitiveWords
/System/Library/LinguisticData/RequiredAssets_zh.bundle/AssetData/reading-lookup.dat
Reading lookup index trie error.
Reading lookup version error.
reading %d: 
Cannot open %s
dumpDictionary
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-744.6/reading-lookup/BuildReadingLookupDictionary.mm
trie
%d words
reading-list
word-index
r:w:o:d:
ReadingLookupDictionaryBuild
[word length] > 0
[components count] == 4
offset <= 0xFFFFFF
CFBurstTrieAddUTF8String(trie, (UInt8*)utf16String, [word length] * sizeof(unichar), payload)
Cannot create %s
numByteWritten == sizeof(ReadingLookupDictionaryHeader)
numByteWritten == statBuffer.st_size - sizeof(ReadingHeader)
CFBurstTrieSerializeWithFileDescriptor(trie, outputFile, kCFBurstTrieReadOnly | kCFBurstTrieBitmapCompression | kCFBurstTrieSortByKey)
Created reading lookup dictioanry at %s
%s --reading-list PATH --word-index PATH --output PATH
%s --dump PATH
rangeOfCharacterFromSet:options:
dictionaryWithContentsOfURL:
arrayWithObjects:count:
containsObject:
UTF8String
removeAllObjects
length
substringToIndex:
autorelease
stringByReplacingOccurrencesOfString:withString:
hasSuffix:
stringByAppendingString:
addObject:
alloc
initWithCandidate:
release
countByEnumeratingWithState:objects:count:
count
objectAtIndex:
rangeOfString:
rangeOfCharacterFromSet:
copy
characterAtIndex:
rawConversionCandidate
characterSetWithCharactersInString:
addCharactersInRange:
retain
initWithBytes:length:encoding:
init
classNamed:
autocorrectionContextOfType:
reset
addInputCharacter:geometryModel:geometryData:
prefixes
replacementString
stringWithCharacters:length:
type
surface
isEmojiCandidate
dictionaryReading
isConversionCandidate
rawCandidate
addObjectsFromArray:
substringFromIndex:
stringWithFormat:
hasPrefix:
rangeOfString:options:range:
stringByReplacingOccurrencesOfString:withString:options:range:
substringWithRange:
isEqualToString:
componentsSeparatedByCharactersInSet:
shortValue
objectForKey:
integerValue
numberWithInteger:
setObject:forKey:
keysSortedByValueUsingComparator:
stringWithCString:encoding:
dictionaryWithContentsOfFile:
boolValue
description
stringWithUTF8String:
componentsSeparatedByString:
intValue
dictionaryWithObject:forKey:
setValue:forKey:
array
enumerateSubstringsInRange:options:usingBlock:
initWithObjects:forKeys:
objectForKeyedSubscript:
appendString:
analysisString
indexSet
addIndex:
enumerateIndexesUsingBlock:
dictionary
matchedLengthType
numberWithUnsignedLong:
allKeys
compare:
sortedArrayUsingComparator:
unsignedLongValue
setYear:
setMonth:
setDay:
currentCalendar
dateFromComponents:
date
precomposedStringWithCompatibilityMapping
lowercaseString
uppercaseString
weight
firstObject
sortUsingFunction:context:
initWithCharacters:length:
kind
removeIndex:
initWithPattern:options:error:
matchesInString:options:range:
numberOfRanges
rangeAtIndex:
getCharacters:range:
setDisplayString:
attributes
convertedAnalysisString
isPersonName
isExtensionCandidate
isLearningDictionaryCandidate
isUserWordCandidate
isPredictionCandidate
isFuzzyMatchCandidate
isAutocorrectedCandidate
isOTAWordlistCandidate
phraseBoundaryAfterWordAtIndex:
wordCount
wordLengthAtIndex:
wordReadingLengthAtIndex:
wordDictionaryReadingLengthAtIndex:
wordIsFromSystemDictionaryAtIndex:
copySyllableLengthArrayForWordAtIndex:
lcAttrAtIndex:
rcAttrAtIndex:
trieValueAtIndex:
lastPrefixValue
matchType
copySyllableLengthArrayInAnalysisString
copySyllableLengthArrayInConvertedAnalysisString
copySyllableLengthArrayInDictionaryReading
wordRangeAtIndex:
initWithString:language:
valueForKey:
sortedRadicalList
setStringBeforeCaret:
setStringContext:
adjustCandidateContext
addCandidate:
revertLastCommittedCandidate
stringContextForAnalysis
candidateContextForAnalysis
candidateContextString
arrayWithContentsOfFile:
punctuationCharacterSet
mutableCopy
whitespaceAndNewlineCharacterSet
formUnionWithCharacterSet:
symbolCharacterSet
initWithContentsOfFile:
allValues
objectAtIndexedSubscript:
arrayWithArray:
exchangeObjectAtIndex:withObjectAtIndex:
path
defaultManager
moveItemAtPath:toPath:error:
localeWithLocaleIdentifier:
calendarWithIdentifier:
setLocale:
setFormatterBehavior:
setTimeStyle:
dictionaryWithObjects:forKeys:count:
month
year
arrayWithCapacity:
dateByAddingComponents:toDate:options:
setCalendar:
setDateFormat:
stringFromDate:
setDateStyle:
component:fromDate:
informationDictionaryAtPath:
initWithContentsOfURL:
firstCharacter
characterInformationDictionary
searchResultsForString:dictionary:
codeLookupInformationDictionary
language
componentsByLanguage:
pinyinStringFromPinyinWithToneNumber
zhuyinSyllableFromPinyinSyllable
setWithCapacity:
rangeOfComposedCharacterSequenceAtIndex:
stringByStrippingDiacritics
allObjects
toneFromPinyinSyllableWithNumber
dealloc
codeLookupInformation
separatedInputCodesForString:
strokeStringFromNumberString
numberWithBool:
characterInformation
radicalInformationForString:
strokeInformationForString:
pinyinInformationForString:
zhuyinInformationForString:
initialsForStrings:
tonesForString:
wubixingCodes
bihuaCodes
cangjieCodes
isIncludedInCurrentLanguage
setAnalysisString:
setCharacterInformation:
setCodeLookupInformation:
isEmoji
setEmoji:
setLanguage:
_analysisString
_characterInformation
_codeLookupInformation
_emoji
_language
respondsToSelector:
standardUserDefaults
boolForKey:
stringForKey:
removeItemAtURL:error:
fileExistsAtPath:
integerForKey:
stringByStandardizingPath
bundleWithPath:
initWithObjects:
characterSetWithRange:
newlineCharacterSet
whitespaceCharacterSet
invertedSet
rangeOfCharacterFromSet:options:range:
_fastCharacterContents
autoupdatingCurrentLocale
methodSignatureForSelector:
invocationWithMethodSignature:
setSelector:
setTarget:
setArgument:atIndex:
invoke
getReturnValue:
string
indexSetWithIndexesInRange:
insertObjects:atIndexes:
allocWithZone:
syllablesInAnalysisString
componentsJoinedByString:
syllablesInConvertedAnalysisString
syllablesInDictionaryReading
unsignedIntegerValue
syllablesInString:syllableLengths:
numberWithUnsignedInt:
syntheticCandidateFromWords:withLexicon:language:
copyWithZone:
isSyntheticCandidate
category
convertedAnalysisStringForFirstSyllable
isEqual:
syllabifiedAnalysisString
syllabifiedConvertedAnalysisString
syllabifiedDictionaryReading
words
wordReadings
wordIDs
setWeight:
_rawCandidate
floatValue
unsignedShortValue
currentHandler
handleFailureInMethod:object:file:lineNumber:description:
numberWithUnsignedInteger:
initWithObjects:forKeys:count:
insertString:atIndex:
stringByReplacingCharactersInRange:withString:
callStackSymbols
compare:options:range:locale:
stringByApplyingPinyinToneMarkToFirstSyllableWithToneNumber:
appendFormat:
simplifiedChineseCompare:
traditionalChinesePinyinCompare:
traditionalChineseZhuyinCompare:
initWithLocaleIdentifier:
sharedInstanceForType:
requiredKeys
indexOfObject:
managedObjectContext
searchResultsWithValueDictionary:managedObjectContext:sortDescriptors:
entityDescriptionForContext:
setReturnsObjectsAsFaults:
setEntity:
setSortDescriptors:
class
isKindOfClass:
stringValue
predicateWithFormat:
andPredicateWithSubpredicates:
setPredicate:
executeFetchRequest:error:
dictionaryEntryHasAllRequiredKeys:
entityModelName
insertNewObjectForEntityForName:inManagedObjectContext:
isLogging
dictionaryValueFromManagedObject:
logEntry:operationType:extraInformation:
performBlockAndWait:
deleteAllMatchingEntries:
deleteObject:
localInfoPlistURL
prepareURLForDatabaseFile:
writeToURL:atomically:
entity
attributesByName
null
save
uniqueKeys
sortDescriptors
removeDuplicatesForEntry:uniquingKeys:sortDescriptors:restrictToNumberOfElements:identifierKey:
save:
logMessage:
searchResultsWithValueDictionary:
searchResultsWithValueDictionary:sortDescriptors:
addEntry:
deleteEntry:
deleteAllElements
setValue:forKey:entry:
setDatabaseProperty:forKey:
databasePropertyForKey:
dictionaryValuesFromManagedObjects:
setValuesForEntry:uniquingKeys:
initWithType:URL:
defaultCenter
postNotificationName:object:
removeObserver:
localURL
fileURLWithPathComponents:
databaseName
initWithManagedObjectModel:
addPersistentStoreWithType:configuration:URL:options:error:
databaseSyncs
entityDescriptionURL
URLByDeletingLastPathComponent
createDirectoryAtPath:withIntermediateDirectories:attributes:error:
localStoreURL
ubiquityContainerIdentifier
managedObjectModel
newPersistentStoreWithURL:ubiquityContainerIdentifier:managedObjectModel:
sendRemoteNotification
persistentStoreCoordinator
initWithConcurrencyType:
setPersistentStoreCoordinator:
setMergePolicy:
entityForName:inManagedObjectContext:
enumeratorAtURL:includingPropertiesForKeys:options:errorHandler:
lastPathComponent
removePersistentStore:error:
storedElementsForMerge
setStoredElementsForMerge:
userInfo
resetDatabaseWithType:URL:
shouldSyncDatabase
locallyPresentUbiquitousFiles
stripUbiquitousInformationFromStore:
entriesFromStrippedStoreURL:
coreDataUbiquityFolderURLforStore:
entriesToMerge
clearStoredMergeEntries
entityDescription
setLocalURL:
setManagedObjectModel:
setManagedObjectContext:
storeURL
setStoreURL:
setType:
_entityDescription
_localURL
_localURLLastPartOfName
_managedObjectModel
_managedObjectContext
_persistentStoreCoordinator
_storeURL
_type
_storedElementsForMerge
initWithIdentifier:
descriptionDictionary
fileURLWithPath:
sortDescriptorWithKey:ascending:
URLForUbiquityContainerIdentifier:
ubiquitousURLWithSuffix:
setDefaultDescriptionPath:
defaultDescriptionPath
ubiquityContainerURL
ubiquitousStoreDirectoryURLForIdentifier:
ubiquitousTransactionURLForIdentifier:
forceNoSync
setDescriptionDictionary:
_descriptionDictionary
initWithContentsOfFile:encoding:error:
getCString:maxLength:encoding:
removeObjectAtIndex:
removeObjectsAtIndexes:
firstIndex
sortUsingComparator:
setObject:atIndexedSubscript:
insertObject:atIndex:
reverseObjectEnumerator
removeLastObject
fileURLWithPath:isDirectory:
stringWithContentsOfFile:usedEncoding:error:
getLineStart:end:contentsEnd:forRange:
dataUsingEncoding:
arrayWithObjects:
numberWithShort:
dictionaryWithObjects:forKeys:
stringWithCapacity:
removeObjectsInRange:
subarrayWithRange:
initWithArray:
removeObject:
writeToFile:atomically:
isEqualToArray:
decimalDigitCharacterSet
indexSetWithIndex:
arrayWithObject:
rebuildCandidateContextString
setString:
candidateContext
setRebuildCandidateContextString:
stringBeforeCaret
stringContext
clearContextForAddition
positionInContextWithPartialDocumentStringLength:
lastObject
deleteCharactersInRange:
setCandidateContext:
setCandidateContextString:
_candidateContext
_stringContext
_stringBeforeCaret
_candidateContextString
_rebuildCandidateContextString
containsIndex:
range
getCharacters:
setValidSequenceCorrectionThreshold:
completions
correction
guesses
removedModifications
addedModifications
modificationType
syllableRange
modificationScore
additionalSyllableRange
removeItemAtPath:error:
initWithString:category:
copyFacemarkCandidatesForLanguage:
candidateWithString:category:
copyFacemarkCandidatesForLocale:
_string
_category
characterIsMember:
stringWithContentsOfFile:encoding:error:
stringByTrimmingCharactersInSet:
Loading %@ (%s)
[JapaneseAssetDictionaryManager] set zip code dictionary path to: %@
[Viterbi::clear] clearning node_freelist and path_freelist
[Viterbi::reset_mempool] resetting path_freelist
Mecabra Japanese initialized.
Mecabra Japanese terminated.
Pruning %@ (n-gram expansion final)
[MJ:searchPhrasesByReadingPrefix] %@
[ME::predict] prediction:%d acceptedCandidate:%p
[Prediction] Considering POS context (%d, %d) for %@ with additional cost %d
Failed to retrieve system dictionary path.
Failed to initialize POS manager.
Failed to retrieve settings file path.
Failed to open Mecabra engine.
Failed to retrieve POS prediction dictionary path.
Failed to register an immutable dynamic dictionary.
Failed to register a mutable dynamic dictionary.
Failed to retrieve static LM path.
Failed to retrieve word cache file path.
[MJ::createCandidateFromContextString] string:%@|%@ isRightContext:%d allowSynthetic:%d
[MJ::createCandidateFromContextString] Reverse-analyzing %@
[MJ::createCandidateFromContextString] Reverse-analysis from %@ failed. Returning a synthetic candidate with an empty analysis string.
[MJ::createCandidateFromContextString] Reverse-analysis from %@ failed. Returning NULL.
Pruning %@ (excessive learning candidates)
Pruning %@ (post-processing)
[MecabraCreate]
[MecabraAnalyzeString] mecabra:%p string:%@
[MecabraAnalyzeStringWithGeometryModel] mecabra:%p string:%@
[MecabraAnalyzeStringWithGeometryModelAndContext] mecabra:%p string:%@
[MecabraAnalyzeStringWithContext] mecabra:%p string:%@ options:%lx (L-context:%s I-context:%s)
[MecabraDeclareEndOfSentence] mecabra:%p context:%p
[MecabraAcceptInlineCandidates] mecabra:%p context:%p candidates:%s
[MecabraRevertLearningForCandidate] mecabra:%p context:%p candidate:%@
[MecabraCancelAnalysis] mecabra:%p
[MecabraAcceptCandidate] mecabra:%p candidate.surface:%@ isPartial%d
[MecabraCancelLastAcceptedCandidate] mecabra:%p
[MecabraSetAdditionalConversionDictionaries] mecabra:%p
[MecabraSaveLearningDictionaries] mecabra:%p
[MecabraClearLearningDictionaries] mecabra:%p
[MecabraResetLearningDictionaries] learningDictionaryDirectory:%@
[MecabraSetAddressBookNamePhoneticPairs] mecabra:%p size:%ld
[MecabraSetUserWordKeyPairs] mecabra:%p size:%ld
[MecabraPreheatResources] mecabra:%p
[MecabraHandleMemoryPressure] mecabra:%p excessMemoryInBytes:%ld
[MecabraRelease] mecabra:%p
[MecabraCreateCandidateFromContextString] mecabra:%p string:%@ isRightContext:%d
[MecabraFlushDynamicData] mecabra:%p
[MecabraPerformMaintenance] mecabra:%p
[MecabraSpecialtyDictionaryCreateWithEntries] entries:%p
[MecabraSpecialtyDictionaryGetData] dictionary:%p
[MecabraSpecialtyDictionaryCreateWithData] dictionaryData:%p
[MecabraAddSpecialtyDictionary] mecabra:%p dictionary:%p
[MecabraRemoveSpecialtyDictionary] mecabra:%p dictionary:%p
[MecabraSpecialtyDictionaryEnumerateEntries] dictionary:%p
[MecabraSpecialtyDictionaryRelease] dictionary:%p
[MecabraAdaptToTokenizedText] mecabra:%p
[MecabraAdaptToTokenizedTextWithEffectiveTime] mecabra:%p
[MecabraAdaptToUntokenizedText] mecabra:%p
[MecabraSetDynamicLanguageModelAppContext] %@ (mecabra:%p)
[Mecabra] Set additional dictionary: %@
Corruption of learning dictionary detected. Database has been reset: %s
[updateBestAnalysis] updating best analysis from previous best analysis (segment gap: %zu)
[updateBestAnalysis] updating best analysis from history: %@
[updateBestAnalysis] updating best analysis from converted analysis string
[makeSegmentsExceptLast] compound noun found, returning best segments
[makeSegmentsExceptLast] best-analysis:%d top-analysis:%d threshold:%d
[makeSegmentsExceptLast] using %@ segments as reference
[makeSegmentsExceptLast] segment[%zu]: from %@ segments
[makeLastSegments] ignoring top segment, using best segment or expanded hiragana string
[makeLastSegments] ignoring best segment since it's a prefix segment
[makeLastSegments] top segment is not reliable
[makeLastSegments] top segment is not reliable, but using the common katakana part
[makeLastSegments] using best segment
[makeLastSegments] using the katakana part of top segment (prefix matched)
[makeLastSegments] using best segment since it's a prefix of top segment (prefix matched)
[makeLastSegments] using partial candidate since it's a prefix of top segment (prefix matched)
[makeLastSegments] using top segment (exact matched)
[makeLastSegments] expanding the last segment to hiragana string
endingWithPunctuation:%d
[addCandidateAsTopCandidate]: %@
[stabilizeCandidates] converted analysis string: %@, raw analysis string: %@
%s: %s
[shouldChooseTopSegment] topSegment:%d, bestSegment:%d, threshold:%d
[isTopSegmentSurfaceUnreliable] top candidate: %@ (%ld) prefix katakana length: %zu
[isTopSegmentSurfaceUnreliable] top candidate (updated): %@ (%ld) prefix katakana length: %zu
[isTopSegmentSurfaceUnreliable] second top candidate: %@ (%ld) prefix katakana length: %zu
[isTopSegmentSurfaceUnreliable] Katakana common prefix: %d, threshold: %ld
[ME::acceptCandidate] S:%@ isPartial:%d performLearning:%d
[ME::convert] %@
[ME:removeTruncatedContextFromCandidates] Converting %@ (%@/%@) to %@ (%@/%@)
%s (%ld): %@ (%@/%@), type: %c, length: %s, cost: %d, base-cost: %d, prob: %3.3lf, penalty: %d
   #%lu: %@ %@ (lc:%d rc:%d)
Candidates: [Left: %@] [Inline: %@] [Right: %@]
App Context: %@
%lu: %@ %d
key = %@, value = %ld
[MecabraLearner::acceptCandidate] %@ isPartial:%d performLearning:%d isOTAWordlist:%d
[MecabraLearner::resetInternalState]
[MecabraLearner::actuallyAcceptCandidate] S:%@ isPartial:%d performLearning:%d
[MecabraLearner::actuallyAcceptCandidate] adding %@ to partial candidates (total count: %lu)
[MecabraLearner::flushAcceptedCandidate] S:%@ performLearning:%d shouldLearn:%d
[MecabraLearner::registerCandidate] AS:%@ DR:%@ S:%@ isPartial:%d
[MJL::registerToLearningDictionary] Learning phrase %@ (%@)
[MJL::registerToLearningDictionary] Learning dynamic word %@ (%@)
[MJL::combinePartialCandidatesAndRegister] Registering as a phrase sequence: %@ (%@)
[MJL::combinePartialCandidatesAndRegister] Registering as a single phrase: %@ (%@)
[MJL::addBigramEntryIntoLearningDictionary] Registering phrase bigram %@ -> %@ %@
[MJL::incrementUsageCount] %@ (%@/%@) type:%@ contextWordCount:%ld
[MJL::incrementUsageCount] %@
[MJL::incrementUsageCount] Registering a dynamic token %@ %@ with ID %u
[MJL::incrementUsageCount] Incrementing usage counts for %@ (probability: %lf -> %lf)
[MJL::registerPhraseSequence] S:%@ AS:%@ DR:%@ phraseSize:%lu skipPhraseCount:%lu performLexicalLearning:%d shouldLearnBigram:%d
[registerNonLexicalEntry] Registering non-lexical preference %@ = %d
[LPL::registerLexicalEntry] Registering lexical rule: %@ => %@ (P0:%hu L2:[%@](%d) L1:[%@](%d) R1:[%@](%d) R2:[%@](%d))
[LPL::matchFeature] Comparing ( %s) with ( %s)
[LPL::applyLexicalRules] Rewriting %@ (%@) => %@
[LPL::applyLexicalPreferences] %@ (%@) => %@ (lc:%d rc:%d f-lc:%d f-rc:%d)
Pruning %@ (n-gram expansion)
[Mecabra] Reloading syllable LM
## Sorted ##
index: %lu, surface: %@, cost: %ld, dynamic-score: %lf, static-score: %lf
Pruning %@ (kind:%c) (after reranking)
[Mecabra] Fail to load syllable LM
[Mecabra] Load syllable LM successfully
Word history %ld: %s %s (lc:%d rc:%d)
[Mecabra] Reset language model
[MecabraContextCreateMutable]
[MecabraContextRelease] context:%p
Dynamic LM word (%u, %@, %@) loaded.
N(N?N6N[N
.(N,N6N7N?N@NANZN[N
["\n\
^P_Q_a_s_
_Lb4e5e5llp+r?r\r
uvv;y
B}bkb_
(ub_
Kb0u4l
^\Sq\
e8\(gkp
zAS'Y-N
N(N?N6N
1OU*
z4lkpKN
](g'Y
SsYP[
K0M0O0Q0S0U0W0Y0[0]0_0a0d0f0h0o0r0u0x0{0
o0r0u0x0{0
B0D0F0H0J0
NkQ]NAS]
NkQ]NAS]
NkQ]N
NkQ]NAS
NkQ]NAS~vCS
0o0K0k0
0n0x0W0g0
1'1(1)1
1 1!1"1#1$1%1&1
1'1(1)1
1 1!1"1#1$1%1&1
4l!q
^y!q
P[t^
oSt^
HSt^
*gt^
3ut^
bt^
B0Y0
B0W0_0
B0U0c0f0
B0U0d0f0
W0B0U0c0f0
W0B0U0d0f0
0n0B0U0c0f0
0n0B0U0d0f0
0j0B0U0c0f0
0j0B0U0d0f0
T0B0U0c0f0
S0B0U0d0f0
M0n0F0
U0O0X0d0
U0O0W0d0
J0h0h0D0
D0c0U0O0X0d0
D0d0U0O0W0d0
0R0d0
0Q0d0
0D0R0d0
0D0Q0d0
0D0R0d0
0D0Q0d0
0R0d0
0Q0d0
0R0d0
0Q0d0
S0h0W0
0D0m0
0D0m0
U0O0m0
J0h0h0W0
D0c0U0O0m0
D0d0U0O0m0
U0M0J0h0h0W0
NkQ]NAS~vCS
j"k"
& & 
~0W0
1'1 1
1'1"1
1'1#1
1'1%1
1'1 1
1'1"1
1'1#1
1'1%1
1'1 1
1'1!1
1'1"1
1'1#1
1'1%1
1'1 1
1'1!1
1'1"1
1'1%1
1(1"1
1(1#1
1(1%1
1'1 1
1'1"1
1'1%1
1(1"1
1(1#1
1(1%1
1'1 1
1'1!1
1'1"1
1'1#1
1'1$1
1'1%1
1(1"1
1(1#1
1(1%1
1 1
1!1
1"1
1$1
1%1
1'1
1'1
1'1
1'1 1
1'1!1
1'1"1
1'1#1
1'1$1
1'1%1
1(1
1(1
1(1"1
1(1#1
1(1%1
1)1
1)1
1)1"1
1(1"1
1(1#1
1(1$1
1(1%1
1(1"1
1(1#1
1(1$1
1(1%1
1(1"1
1(1#1
1(1$1
1(1%1
1'1 1
1'1!1
1'1"1
1'1#1
1'1$1
1'1%1
1)1"1
1)1#1
1)1%1
1'1 1
1'1!1
1'1"1
1'1#1
1'1$1
1'1%1
1)1"1
1)1#1
1)1%1
1'1 1
1'1!1
1'1"1
1'1#1
1'1$1
1'1%1
1)1"1
1)1#1
1)1%1
1(1"1
1(1#1
1(1$1
1(1%1
1(1"1
1(1#1
1(1$1
1(1%1
1(1"1
1(1#1
1(1$1
1(1"1
1(1#1
1(1%1
1(1"1
1(1#1
1(1%1
1(1"1
1(1#1
1(1%1
1(1"1
1(1#1
1(1%1
'1 1
'1!1
'1"1
'1#1
'1$1
'1%1
(1"1
(1#1
(1$1
(1%1
)1"1
)1#1
)1%1
1'1 1
1'1 1
1'1 1
1'1 1
1'1"1
1'1"1
1'1"1
1'1"1
1'1"1
1'1#1
1'1#1
1'1#1
1'1%1
1'1%1
1'1%1
1'1 1
1'1 1
1'1 1
1'1 1
1'1"1
1'1"1
1'1"1
1'1"1
1'1#1
1'1#1
1'1#1
1'1#1
1'1%1
1'1%1
1'1%1
1'1%1
1'1%1
1'1 1
1'1 1
1'1 1
1'1 1
1'1!1
1'1!1
1'1"1
1'1"1
1'1"1
1'1"1
1'1#1
1'1#1
1'1%1
1'1%1
1'1%1
1'1%1
1'1%1
1'1 1
1'1 1
1'1 1
1'1!1
1'1"1
1'1"1
1'1"1
1'1"1
1'1"1
1'1%1
1'1%1
1'1%1
1'1%1
1'1%1
1(1"1
1(1"1
1(1"1
1(1"1
1(1#1
1(1#1
1(1#1
1(1#1
1(1%1
1(1%1
1(1%1
1'1 1
1'1 1
1'1 1
1'1 1
1'1 1
1'1"1
1'1"1
1'1"1
1'1"1
1'1%1
1'1%1
1'1%1
1'1%1
1'1%1
1(1"1
1(1"1
1(1"1
1(1"1
1(1#1
1(1#1
1(1#1
1(1#1
1(1%1
1(1%1
1(1%1
1(1%1
1(1%1
1'1 1
1'1 1
1'1!1
1'1!1
1'1!1
1'1!1
1'1!1
1'1"1
1'1"1
1'1"1
1'1"1
1'1"1
1'1#1
1'1#1
1'1#1
1'1$1
1'1$1
1'1$1
1'1%1
1'1%1
1'1%1
1(1"1
1(1"1
1(1#1
1(1#1
1(1%1
1(1%1
1(1%1
1(1%1
1(1%1
1 1
1 1
1 1
1 1
1 1
1!1
1!1
1!1
1!1
1!1
1"1
1"1
1"1
1$1
1$1
1$1
1$1
1$1
1%1
1%1
1%1
1%1
1%1
1'1
1'1
1'1
1'1
1'1
1'1
1'1
1'1
1'1
1'1
1'1
1'1 1
1'1 1
1'1 1
1'1 1
1'1 1
1'1!1
1'1!1
1'1!1
1'1!1
1'1!1
1'1"1
1'1"1
1'1"1
1'1"1
1'1"1
1'1#1
1'1#1
1'1#1
1'1#1
1'1$1
1'1$1
1'1$1
1'1$1
1'1$1
1'1%1
1'1%1
1'1%1
1'1%1
1'1%1
1(1
1(1
1(1
1(1
1(1
1(1
1(1
1(1
1(1
1(1
1(1"1
1(1"1
1(1"1
1(1"1
1(1#1
1(1#1
1(1#1
1(1#1
1(1%1
1(1%1
1(1%1
1(1%1
1(1%1
1)1
1)1
1)1
1)1
1)1
1)1"1
1)1"1
1(1"1
1(1"1
1(1"1
1(1#1
1(1#1
1(1#1
1(1#1
1(1$1
1(1$1
1(1$1
1(1$1
1(1%1
1(1%1
1(1%1
1(1%1
1(1"1
1(1"1
1(1"1
1(1"1
1(1#1
1(1#1
1(1#1
1(1$1
1(1$1
1(1$1
1(1$1
1(1%1
1(1%1
1(1%1
1(1"1
1(1"1
1(1"1
1(1"1
1(1"1
1(1#1
1(1#1
1(1#1
1(1#1
1(1$1
1(1$1
1(1$1
1(1$1
1(1$1
1(1%1
1(1%1
1(1%1
1(1%1
1(1%1
1'1 1
1'1 1
1'1 1
1'1 1
1'1 1
1'1!1
1'1!1
1'1!1
1'1!1
1'1!1
1'1"1
1'1"1
1'1"1
1'1#1
1'1#1
1'1#1
1'1#1
1'1$1
1'1$1
1'1$1
1'1$1
1'1%1
1'1%1
1'1%1
1'1%1
1)1"1
1)1"1
1)1"1
1)1#1
1)1#1
1)1#1
1)1%1
1)1%1
1)1%1
1'1 1
1'1 1
1'1 1
1'1 1
1'1!1
1'1!1
1'1!1
1'1!1
1'1!1
1'1"1
1'1"1
1'1"1
1'1"1
1'1#1
1'1#1
1'1#1
1'1#1
1'1$1
1'1$1
1'1$1
1'1$1
1'1%1
1'1%1
1'1%1
1'1%1
1'1%1
1)1"1
1)1"1
1)1"1
1)1"1
1)1#1
1)1#1
1)1%1
1)1%1
1)1%1
1'1 1
1'1 1
1'1 1
1'1 1
1'1!1
1'1!1
1'1!1
1'1"1
1'1"1
1'1"1
1'1"1
1'1"1
1'1#1
1'1#1
1'1#1
1'1#1
1'1#1
1'1$1
1'1$1
1'1$1
1'1$1
1'1%1
1'1%1
1'1%1
1'1%1
1'1%1
1)1"1
1)1"1
1)1"1
1)1"1
1)1#1
1)1#1
1)1#1
1)1#1
1)1%1
1)1%1
1)1%1
1)1%1
1(1"1
1(1"1
1(1"1
1(1"1
1(1#1
1(1#1
1(1#1
1(1$1
1(1$1
1(1$1
1(1$1
1(1%1
1(1%1
1(1%1
1(1"1
1(1"1
1(1"1
1(1"1
1(1#1
1(1#1
1(1#1
1(1#1
1(1$1
1(1$1
1(1$1
1(1$1
1(1%1
1(1%1
1(1%1
1(1%1
1(1"1
1(1"1
1(1#1
1(1#1
1(1#1
1(1$1
1(1$1
1(1$1
1(1"1
1(1"1
1(1"1
1(1#1
1(1#1
1(1#1
1(1%1
1(1%1
1(1%1
1(1"1
1(1"1
1(1"1
1(1#1
1(1#1
1(1#1
1(1%1
1(1%1
1(1%1
1(1%1
1(1"1
1(1"1
1(1"1
1(1#1
1(1#1
1(1#1
1(1#1
1(1#1
1(1%1
1(1%1
1(1%1
1(1%1
1(1"1
1(1"1
1(1"1
1(1"1
1(1#1
1(1#1
1(1#1
1(1#1
1(1%1
1(1%1
1(1%1
1(1%1
1(1%1
'1 1
'1 1
'1 1
'1 1
'1 1
'1!1
'1!1
'1!1
'1!1
'1!1
'1"1
'1"1
'1"1
'1"1
'1"1
'1#1
'1#1
'1#1
'1#1
'1#1
'1$1
'1$1
'1$1
'1$1
'1$1
'1%1
'1%1
'1%1
'1%1
'1%1
(1"1
(1"1
(1"1
(1"1
(1#1
(1#1
(1#1
(1#1
(1#1
(1$1
(1$1
(1$1
(1$1
(1$1
(1%1
(1%1
(1%1
(1%1
)1"1
)1"1
)1"1
)1"1
)1#1
)1#1
)1#1
)1#1
)1#1
)1%1
)1%1
)1%1
)1%1
)1%1
NkQ]NAS~vCS
B0j0_0
D0d0
S0S0
S0a0
]0S0
i0S0
j0k0
0_0W0
[b_-
[b_-
*g6qb_-
B}bkb_-
SOb_-
SOb_-
(ub_-
B}bkb_-
SOb_-
*g6qb_-
(ub_-
(ub_-
(ub_-
B}bkb_-
(ub_-
(ub_-
B}bkb_-
(ub_-
SOb_-
]6qb_-
*g6qb_-
(ub_-
(ub_-
S0]0
K0W0
L0k0
U0H0
W0K0
W0M0
Z0d0
`0Q0
`0k0
c0f0
i0S0
j0h0
j0i0
0^0o0
p0K0
{0i0
~0g0
1\D0f0
U0K0D0
_0c0f0
d0d0
f0o0
h0f0
j0L0
p0c0f0
g0o0
k0f0
k0o0
K0D0
K0W0
O0U0
^0D0
n0F0
p0D0
y0D0
*g6qb_-
(ub_-
(ub_-
B}bkb_-
*g6qb_-
D}T~
B0h0
F0a0
S0h0
h0M0
h0S0
j0F0
o0Z0
{0F0
UOK0
,gS_
SOb_-
B}bkb_-
_0a0
Rpe^
Rpe^
zz}v
MecabraWordProperties
MecabraCandidate
NSCopying
CharacterInformationAdditions
Access
MecabraCoreDataController
MecabraCoreDataProperties
MecabraAnalysisContextImpl
MecabraFacemarkCandidate
^{__IDXIndex=}24@0:8^{__CFURL=}16
^{__IDXIndex=}16@0:8
@32@0:8@16^{__IDXIndex=}24
@16@0:8
@24@0:8@16
@28@0:8@16i24
v16@0:8
@20@0:8i16
v24@0:8@16
B16@0:8
v20@0:8B16
i16@0:8
v20@0:8i16
@"NSString"
@"NSArray"
@36@0:8@16^{Lexicon=^v^v}24i32
@24@0:8^{_NSZone=}16
^{MecabraCandidateBase=^^?q}16@0:8
B24@0:8^{__CFString=}16
Q16@0:8
S24@0:8Q16
{?=qq}24@0:8q16
q24@0:8q16
B24@0:8Q16
^{__CFArray=}24@0:8Q16
Q24@0:8Q16
S16@0:8
q16@0:8
^{__CFArray=}16@0:8
@24@0:8^{MecabraCandidateBase=^^?q}16
^{ConversionCandidate=^^?q}16@0:8
B24@0:8@16
@32@0:8@16@24
v24@0:8Q16
@24@0:8Q16
q24@0:8@16
@40@0:8@16@24@32
v40@0:8@16@24@32
v32@0:8@16@24
@56@0:8@16@24@32Q40@48
@"NSEntityDescription"
@"NSURL"
@"NSManagedObjectModel"
@"NSManagedObjectContext"
@"NSPersistentStoreCoordinator"
@"NSMutableDictionary"
{?=QQ}24@0:8Q16
@"NSMutableArray"
@"NSMutableString"
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
<key>application-identifier</key>
<string>FAKETEAMID.</string>
<key>com.apple.developer.ubiquity-container-identifiers</key>
<array>
<string>com.apple.TextInput</string>
</array>
</dict>
</plist>
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
###########################################
zh00
sh00
ch00
ing0
ai00
an00
ang0
ao00
ei00
en00
eng0
ia00ian0
iang
iao0
ie00
in00
iu00
ong0
ou00
ua00
uai0
uan0
ue00
un00
ui00
uo00
uang
er00
iong
a000
e000 i000!o000"u000#v000$on00%io00&ion0've00(van0)vn00*
zh00
sh00
ch00
ing0
ai00
an00
ang0
ao00
ei00
en00
eng0
ia00ian0
iang
iao0
ie00
in00
iu00
ong0
ou00
ua00
uai0
uan0
ue00
un00
ui00
uo00
uang
er00
iong
van0
ve00 a000
e000"i000#o000$u000%v000&on00'io00(ion0)
