Name
v8@?0
asset-work-queue
AXCustomPronunciations
ICLOUD: Checking pronunciations
ICLOUD: Got pronunciations: %{private}@, count: %d
Exception decoding data: %@
Reconciled iCloud pronunciations: adding: %{private}@
Did not find a change, not updating updating
CustomPronunciationSubstitutions
NPS: Publishing data to nano domain
ICLOUD[%p]: Waiting 5s to publish
Created an empty length archive, not synching
ICLOUD[%p]: Publishing data to iCloud %{private}@
Custom pronunications settings updated
refresh-voices
It's been too soon since we last updated our available voices. We need to wait longer. %f
Updated TextToSpeech's available voices cache with voices: %@
/BuildRoot/Library/Caches/com.apple.xbs/Sources/AccessibilityFrameworks_Sim/AccessibilityFrameworks-2156.69/Source/SpeechAssetUpdater/AXSpeechAssetUpdaterServer.m
-[AXSpeechAssetUpdaterServer _updateCachedTTSVoiceAssets]_block_invoke_2
We just refreshed voices, why are they missing?
Vocalizer assets example[0]: %{public}@
-[AXSpeechAssetUpdaterServer _handleExtantVoices]
Why is name nil for %@
Victoria macinTalkAsset: %{public}@
VoiceId
Language
local macinTalkAsset: %{public}@
remote macinTalkAsset: %{public}@
en-US
com.apple.speech.synthesis.voice
Retrieved siri assets: %{public}@
Processed Siri assets: %{public}@
Siri voices not supported
Set extant voices: %{public}@
LastSpeechAssetUpdateCheck
Force checking speech assets: %d date: %{public}@
No previous LastSpeechAssetUpdateCheck was found. Setting date earlier: %{public}@.
Not checking voice assets because it's too soon: %{public}@ - only %f seconds 
Checking on assets now
com.apple.private.kernel.jetsam
com.apple.CoreRoutine.preferences
com.apple.TVServices.DisplayManager
com.apple.accessibility.voiceover
options
audioLevel
AXSpeechPronunciationClient
results
v24@?0@"NSDictionary"8@"NSError"16
Fail: %@, %d
Error
error
ASAssetQuery error fetching results %{public}@ %{public}@ %{public}@
(%K == %@)
ASAssetQuery error fetching vocalizer results %{public}@
((%@ IN %K) || %@ = %K) && (%K != %d)
ASAssetQuery error fetching results %{public}@
q24@?0@"ASAsset"8@"ASAsset"16
Asset progress: %{public}@ - %f
Checking assets: %{public}@
no language present for %{public}@, so not trying to update
checking assets[%{public}@] %{public}@
could not parse voice identifier %{public}@
could not find asset for voice identifier %{public}@ but the voice was installed. This is expected if it is a built-in voice.
could not find asset for voice identifier %{public}@
selected voice %{public}@ is already installed.
selected voice %{public}@ is queued for download.
selected voice %{public}@ is already downloading.
download of %{public}@ is stalled!
selected voice %{public}@ is not present. Beginning download.
no space to download voice %{public}@: %{public}@
selected voice %{public}@ was paused. Resuming.
failed to download %{public}@: %{public}@. retrying.
v16@?0@"NSError"8
Adding asset to queue: %{public}@
No macintalk or siri asset installed
Installed asset %{public}@, latest asset: %{public}@
Detected new Asset, downloading: %{public}@
Enough disk space available - start %{public}@
Asset state: %d
Error: %{public}@
No newer asset than %{public}@ - %d [installed asset %{public}@]
Purging old asset: %{public}@
Purged old asset: %{public}@, %{public}@
Trying to update unknown asset (expecting Macintalk, Combined, or Siri): %{public}@
Could not remove file protection from: %{public}@
Updating Installed Asset: %{public}@
Could not purge old asset: %{public}@
hash
TQ,R
superclass
T#,R
description
T@"NSString",R,C
debugDescription
alloc
init
initWithTargetSerialQueue:
_monitoriCloudPronunciations
_icloudDataChanged:
afterDelay:processBlock:
defaultStore
synchronize
dataForKey:
identifier
initForReadingWithData:
setRequiresSecureCoding:
class
arrayWithObjects:count:
setWithArray:
decodeObjectOfClasses:forKey:
count
_iCloudReconcileDataStore:
sharedInstance
customPronunciationSubstitutions
countByEnumeratingWithState:objects:count:
containsObject:
setCustomPronunciationSubstitutions:
_syncToWatch
setWithObject:
synchronizeUserDefaultsDomain:keys:
cancel
copy
archivedDataWithRootObject:
length
setData:forKey:
_saveCustomPronuciationsToExternals
_customPronunicationsSettingsChanged
registerUpdateBlock:forRetrieveSelector:withListener:
defaultCenter
addObserver:selector:name:object:
refreshAllAvailableVoices
allAvailableVoices
setCurrentVoices:
availableVoices
currentVoices
callStackSymbols
_handleExtantVoices
_downloadAssetsForSelectedVoices
attributes
objectForKeyedSubscript:
firstObject
_combinedVocalizerAssets:
boolValue
intValue
isEqualToString:
_languageForAsset:
stringByReplacingOccurrencesOfString:withString:
setIsCombinedVoice:
setNonCombinedVoiceId:
objectForKey:
setIdentifier:
setLanguage:
setName:
setQuality:
setGender:
state
setIsInstalled:
unsignedIntegerValue
setAssetSize:
setCanBeDownloaded:
addObject:
_vocalizerAssets:
supportsAlex
nameForVoiceIdentifier:
hasPrefix:
footprint
canBeDownloaded
supportsSiri
isCombinedFootprint
array
objectAtIndexedSubscript:
replaceObjectAtIndex:withObject:
setExtantVoices:
standardUserDefaults
isKindOfClass:
date
dateByAddingTimeInterval:
setObject:forKey:
timeIntervalSinceReferenceDate
_checkForMacinTalkAssetUpdates
_checkForVocalizerAssetUpdates
_updateCachedTTSVoiceAssets
setWithObjects:
_checkForAssets:
secureUnarchiveData:withExpectedClass:otherAllowedClasses:
_startPronunciationSession:
_cancelPronunciationSession
_stopPronunciationSession
_pronunciationAudioLevel
numberWithFloat:
dictionaryWithObjects:forKeys:count:
_handleFailureForSpeechPronunciation:
averagePower
stopSpeechWithOptions:
cancelSpeech
phonemeSuggestions
clientMessengerWithIdentifier:
backgroundAccessQueue
sendAsynchronousMessage:withIdentifier:targetAccessQueue:completion:
endSession
description
setDelegate:
setTranscriptionMode:
orthography
setOrthography:
initWithActivationEvent:
setIsEyesFree:
setUseAutomaticEndpointing:
language
startDictationWithLanguageCode:options:speechOptions:
initWithAssetType:
setQueriesLocalAssetInformationOnly:
runQueryAndReturnError:
stringWithFormat:
predicateWithFormat:
setPredicate:
sortedArrayUsingComparator:
numberWithBool:
floatValue
_updateAsset:existingAsset:
_alexAssets
_beginDownloadIfNecessaryForAssets:
_vocalizerAssetsForLanguage:
selectedSpeechVoiceIdentifiers
assetForVoiceId:
voiceWithIdentifier:
isInstalled
requiredDiskSpaceIsAvailable:error:
_handleAssetProgress:error:asset:installedAsset:
setProgressHandler:
_mobileAssetDownloadOptions
beginDownloadWithOptions:
resumeDownload:
assetType
alexLocalAssetURL
localURL
isEqual:
_addToDownloadQueue:
progressHandler
purge:
_purgeExistingAsset:inFavorOfAsset:
setAlexLocalAssetURL:
defaultManager
path
setAttributes:ofItemAtPath:error:
purgeAndReturnError:
possibleRequiredEntitlementsForProcessingMessageWithIdentifier:
processMessage:withIdentifier:fromClientWithIdentifier:error:
messageWithIdentifierShouldBeProcessedAsynchronously:
processMessageAsynchronously:withIdentifier:fromClientWithIdentifier:completion:
accessQueueForProcessingMessageWithIdentifier:
messageWithIdentifierRequiresWritingBlock:
processInitializationMessage:
serviceWasFullyInitialized
connectionWillBeInterruptedForClientWithIdentifier:
requiredEntitlementForProcessingMessageWithIdentifier:
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
debugDescription
assistantConnectionRequestWillStart:
assistantConnectionDismissAssistant:
assistantConnectionRequestFinished:
assistantConnection:receivedCommand:completion:
assistantConnection:requestFailedWithError:requestClass:
assistantConnection:openURL:completion:
assistantConnection:openApplicationWithBundleID:URL:completion:
assistantConnection:shouldSpeak:
assistantConnection:didChangeAudioSessionID:
assistantConnectionAudioSessionDidBeginInterruption:
assistantConnectionAudioSessionDidEndInterruption:shouldResume:
assistantConnectionWillStartAcousticIDRequest:
assistantConnectionDidDetectMusic:
assistantConnection:didFinishAcousticIDRequestWithSuccess:
assistantConnection:setUserActivtiyInfoAndMakeCurrent:webpageURL:
assistantConnectionInvalidateCurrentUserActivity:
assistantConnection:wantsToCacheImage:
assistantConnection:extensionRequestWillStartForApplication:
assistantConnection:extensionRequestFinishedForApplication:error:
assistantConnection:startUIRequestWithText:completion:
assistantConnectionSpeechRecordingWillBegin:
assistantConnection:speechRecordingDidBeginOnAVRecordRoute:
assistantConnection:speechRecordingDidChangeAVRecordRoute:
assistantConnectionSpeechRecordingDidDetectStartpoint:
assistantConnection:speechRecordingPerformTwoShotPromptWithType:completion:
assistantConnectionSpeechRecordingDidEnd:
assistantConnectionSpeechRecordingDidCancel:
assistantConnection:speechRecordingDidFail:
assistantConnectionDidChangeAudioRecordingPower:
assistantConnection:speechRecognitionDidFail:
assistantConnection:speechRecognized:
assistantConnection:speechRecognizedPartialResult:
assistantConnection:recognizedAdditionalSpeechInterpretation:refId:
assistantConnection:recognitionUpdateWithPhrases:utterances:refId:
assistantConnection:recognitionWithPhrases:utterances:
assistantConnection:recognitionUpdateWillBeginForTask:
assistantConnection:recognitionUpdateDidFinishWithError:
dictationConnectionSpeechRecordingWillBegin:
dictationConnectionSpeechRecordingDidBegin:
dictationConnectionSpeechRecordingDidEnd:
dictationConnectionSpeechRecordingDidCancel:
dictationConnection:speechRecordingDidFail:
dictationConnection:speechRecognitionDidFail:
dictationConnection:didRecognizePhrases:languageModel:correctionIdentifier:
dictationConnection:didRecognizeTokens:languageModel:
dictationConnection:didProcessAudioDuration:
dictationConnectionSpeechRecognitionDidSucceed:
dictationConnection:didRecognizeTranscriptionObjects:languageModel:
dictationConnnectionDidChangeAvailability:
dictationConnection:didFinishWritingAudioFile:error:
dictationConnection:didReceiveSearchResults:recognizedText:stable:final:
dictationConnection:didRecognizePackage:
_siriAssets
_isVocalizerAsset:
.cxx_destruct
_lastTTSVoiceAssetUpdate
_pronunciationiCloudPusher
_isUpdatingCachedTTSVoices
_dictationConnection
_isRecording
_assetWorkQueue
AXSpeechAssetUpdaterServer
AXUIService
NSObject
AFAssistantUIService
AFSpeechDelegate
AFDictationDelegate
%{public}@
@16@0:8
@24@0:8Q16
@48@0:8@16Q24@32^@40
@"NSDictionary"48@0:8@"NSDictionary"16Q24@"NSString"32^@40
B24@0:8Q16
v48@0:8@16Q24@32@?40
v48@0:8@"NSDictionary"16Q24@"NSString"32@?<v@?@"NSDictionary"@"NSError">40
@"AXAccessQueue"24@0:8Q16
v24@0:8@16
v24@0:8@"NSDictionary"16
v16@0:8
v24@0:8@"NSString"16
@"NSString"24@0:8Q16
@"NSSet"24@0:8Q16
B24@0:8@16
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B16@0:8
B24@0:8#16
B24@0:8@"Protocol"16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
@"NSString"16@0:8
v24@0:8@"AFConnection"16
v40@0:8@16@24@?32
v40@0:8@"AFConnection"16@"AceObject<SAAceCommand>"24@?<v@?@"AceObject<SAAceCommand>">32
v40@0:8@16@24@32
v40@0:8@"AFConnection"16@"NSError"24@"NSString"32
v40@0:8@"AFConnection"16@"NSURL"24@?<v@?B>32
v48@0:8@16@24@32@?40
v48@0:8@"AFConnection"16@"NSString"24@"NSURL"32@?<v@?B>40
v28@0:8@16B24
v28@0:8@"AFConnection"16B24
v28@0:8@16I24
v28@0:8@"AFConnection"16I24
v40@0:8@"AFConnection"16@"NSDictionary"24@"NSURL"32
v32@0:8@16@24
v32@0:8@"AFConnection"16@"INImage"24
v32@0:8@"AFConnection"16@"NSString"24
v40@0:8@"AFConnection"16@"NSString"24@"NSError"32
v40@0:8@"AFConnection"16@"NSString"24@?<v@?B>32
v40@0:8@16q24@?32
v40@0:8@"AFConnection"16q24@?<v@?dd@"NSError">32
v32@0:8@"AFConnection"16@"NSError"24
v32@0:8@"AFConnection"16@"SASSpeechRecognized"24
v32@0:8@"AFConnection"16@"SASSpeechPartialResult"24
v40@0:8@"AFConnection"16@"AFSpeechInterpretation"24@"NSString"32
v48@0:8@16@24@32@40
v48@0:8@"AFConnection"16@"NSArray"24@"NSArray"32@"NSString"40
v40@0:8@"AFConnection"16@"NSArray"24@"NSArray"32
v24@0:8@"AFDictationConnection"16
v32@0:8@"AFDictationConnection"16@"NSError"24
v48@0:8@"AFDictationConnection"16@"NSArray"24@"NSString"32@40
v40@0:8@"AFDictationConnection"16@"NSArray"24@"NSString"32
v32@0:8@16d24
v32@0:8@"AFDictationConnection"16d24
v40@0:8@"AFDictationConnection"16@"NSFileHandle"24@"NSError"32
v48@0:8@16@24@32B40B44
v48@0:8@"AFDictationConnection"16@"NSArray"24@"NSString"32B40B44
v32@0:8@"AFDictationConnection"16@"AFSpeechPackage"24
@24@0:8@16
v20@0:8B16
f16@0:8
@20@0:8B16
@"AXDispatchTimer"
@"AFDictationConnection"
@"NSObject<OS_dispatch_queue>"
