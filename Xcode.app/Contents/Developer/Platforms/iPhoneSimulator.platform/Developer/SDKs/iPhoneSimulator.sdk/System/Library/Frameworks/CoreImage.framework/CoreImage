:D7V
"nN%
AA)Z
>Y1\
?*Ral!
WXp?
>J6h
iQ~V?
iN^d
iN^d
N} y
?9(a
g|_\
&4I,)
|F"4
_Cp\
vj.7
ip[[
'Hlw
?VF#
uoEb
?\='
@ut\
?'/2
h?RD
"nN%
t><K
!sePmp
|zlK
c\qq
0Xr
9x&4
^Cp\
`!sePm
?aobHN
.5B?S
i3NCT
"nN%
|a2U0
%Tpx
"nN%
~NA~
lscz
AA)Z
r?jl@
<e5]O
! _B
?`vO
^Cp\F
@Y32
d:tz
N} y
?Uka
SrNl
-:Yj
tBFe@
@!"5
O7+]3n@
h8en
;a@O
?!=E
"LQ.
OVW
"nN%
0Xr
W zR&
/5B?S
|a2U0*
?EUwv
E|'f
i3NCT
1zn!
"nN%
#gaO;|
[@h=|
2uWv
 |(
?K[\
33S?
L>333?
?ffffff
|?5^
@ffffff
vH7B
W4vC
9Y>)F$
MbP?-C
]r2<
 9^;Q
Dfff?
es-8R
es-8R
MbP?
u@333333
?333333
?333333
MbP?
?w-!
$@M-[
N@\r
++MJ
?|'f
i@r3
 l@a
pw@L7
 |@)?
@gDio
?33333S7
800L80AL
RGBAABGRARGB
AhGRAfGR8Iic80C2f024v024800A80C1
r46l610L61AL6Ric61C2h00Ah00Lh0ALh0C1h0C2yuv2svuyhIic6Iic610Af00Af00LfIicf0C1f0ALf0C284ic
f3ic
r46lfuv2fvuy01icr01cr03w
800L80AL
RGBAABGRARGB 
RGBAABGRARGBAhGRAfGR8Iic80C2f024v024800A80C1ARGBARGBARGBARGBf024f024v024v024r46l610L61AL6Ric61C2h00Ah00Lh0ALh0C1h0C2yuv2svuyhIic6Iic610Af00Af00LfIicf0C1f0ALf0C284icr46lAfGRr46lr46l
f3ic
fuv2fvuy01icr01cr03w
I@333333
?333333
0Xr
?g|_\
Mb@?
$@M-[
N@\r
++MJ
?|'f
i@r3
 l@a
pw@L7
 |@)?
@gDio
?33333S7
?3U0
@333333
@P@ffffff
Ww'&l
333333
?333333
ffffff
ffffff
?333333
:gUU
333333
?333333
?333333
a2U0*
333333
?333333
?333333
?333333
?333333
?333333
?333333
?Zd;
@333333
@UUUUUU
i?yCu
JQ/#
?333333
?~0d>
(knN 
 A)\
$@ffffff
-r0@
|?uS@
(\%p@/
M`@33333[a@
>B`e=
~%<(
?es-8R
@es-8R
333333
?333333
?ffffff
MbP?
eUB
m#39
?eUB
;gM$
?[+5
.z<g
`*h 
Kfie
?cc^G
?cWb
x/k 
7:Ba
:ua;
lErd
m|X5
tZ;z
APPL
mntrRGB XYZ 
acspAPPL
APPLsRGB
-APPL
desc
icprt
"wtpt
rXYZ
gXYZ
bXYZ
rTRC
bTRC
gTRC
desc
sRGB Linear
text
Copyright 2012 Apple Inc.
XYZ 
XYZ 
XYZ 
XYZ 
curv
ffffff
?CUL
?;q9^
?yCu
333333
?es-8R
0123456789&
,:#-.$/+%*=^
@UUUUUU
?UUUUUU
@\^_`|~
!"#$%&'()*+,-./:;<=>?[]{}
?UUUUUU
?UUUUUU
?UUUUUU
:FL@
?59$5r:
?59$5r:
0Xr
?g|_\
ADBE
mntrRGB XYZ 
;acspAPPL
none
-ADBE
cprt
2desc
kwtpt
bkpt
rTRC
gTRC
bTRC
rXYZ
gXYZ
bXYZ
text
Copyright 2000 Adobe Systems Incorporated
desc
Adobe RGB (1998)
XYZ 
XYZ 
curv
XYZ 
XYZ 
XYZ 
yE>-C
ff&?ff&
|a2U0
W[q>
HCF]k
333333
333333
333333
333333
?333333
?333333
333333
333333
init
setSvmParameters:
svmParameters
computeKernelValueWithSupportVector:
scaleVector
predictResult
initWithVersion:
isBurstAction
testAverageCameraTravelDistance
setTestAverageCameraTravelDistance:
testMaxRegistrationErrorIntegral
setTestMaxRegistrationErrorIntegral:
testMaxPeakRegistrationError
setTestMaxPeakRegistrationError:
testMeanPeakRegistrationError
setTestMeanPeakRegistrationError:
testBeginningVsEndAEMatrixVsAverageAdjacentAEMatrix
setTestBeginningVsEndAEMatrixVsAverageAdjacentAEMatrix:
testInOutRatio
setTestInOutRatio:
testMaxInnerDistance
setTestMaxInnerDistance:
testAverageRegistrationErrorSkewness
setTestAverageRegistrationErrorSkewness:
testMinRegionOfInterestSize
setTestMinRegionOfInterestSize:
testMaxRegistrationErrorSkewness
setTestMaxRegistrationErrorSkewness:
hasBeenScaled
testVector
_svmParameters
standardUserDefaults
persistentDomainForName:
objectForKey:
intValue
defaultManager
stringByAppendingPathComponent:
burstId
createDirectoryAtPath:withIntermediateDirectories:attributes:error:
arrayWithCapacity:
retain
defaultVersionString
setVersionString:
isEqualToString:
versionString
setVersion:
alloc
setWithCapacity:
version
dictionaryWithCapacity:
stringWithCString:encoding:
setBurstId:
setForceFaceDetectionEnable:
UTF8String
initWithCGImage:maxDimension:
dictionaryWithDictionary:
setDateFormat:
date
stringFromDate:
release
burstDocumentDirectory
fileExistsAtPath:
count
objectAtIndex:
releaseImage
dealloc
countByEnumeratingWithState:objects:count:
burstImages
isGarbage
registrationErrorIntegral
imageId
timestamp
latestFaceTimestamp
imageProps
numberWithDouble:
setObject:forKey:
image
width
height
addFacesToImageStat:imageSize:
faceStatArray
faceId
numberWithInt:
normalizedFaceRect
numberWithFloat:
hasRollAngle
rollAngle
hasYawAngle
yawAngle
hasLeftEye
leftEyeRect
leftEyeBlinkScore
hasRightEye
rightEyeRect
rightEyeBlinkScore
smileScore
addObject:
findFacesInImage:imageStat:
setTimeFaceDetectionDone:
setTimeBlinkDetectionDone:
timeFaceDetectionDone
timeBlinkDetectionDone
calculateFaceFocusInImage:imageStat:
adjustFaceIdsForImageStat:
dumpFaceInfoArray
computeImageData:faceIDCounts:
focusScore
leftEyeOpen
numberWithBool:
rightEyeOpen
smiling
smallFace
FCRLeftEyeFeaturesOffset
FCRRightEyeFeaturesOffset
FCRSmileFeaturesOffset
FCRBlinkFeaturesSize
FCRSmileFeaturesSize
stringWithFormat:
Ybuffer
bytesPerRow
dataWithBytes:length:
Cbuffer
dictionaryWithObjectsAndKeys:
writeToFile:atomically:
facesRoiRect
AEAverage
AETarget
AEStable
AFStable
orientation
aeMatrix
completionBlock
extractFacesFromMetadata:
initWithImageData:dict:identifier:imageProps:completionBlock:
setTemporalOrder:
doubleValue
setTimeReceived:
processClusters:
setSmiling:
normalizedFocusScore
computeEmotion:
temporalOrder
setEmotionallyRejected:
avgHorzDiffY
blurExtent
setImageScore:
setActionScore:
computeAEMatrixDifference:
canRegister
allocateMeanStdPingPongBuffers::::
assignMeanStdBuffers:
performRegistration:deltaCol:deltaRow:
maxSkewness
setMaxSkewness:
setTx:
setTy:
computeSmoothedGridROI:nextStat:
doLimitedSharpnessAndBlur
hasRegistrationData
countForObject:
removeObject:
collapseSharpnessGrid
setIsGarbage:
flagAsGarbage
roiSize
registrationErrorX
registrationErrorY
computeCameraTravelDistance
computeBeginningVsEndAEMatrixDiffVsAverageAdjacent
computeActionSelectionThreshold
computeScore:
writeGridROI:
actionScore
imageScore
lastObject
stringWithString:
calcFaceScores:
computeAllImageScores
faceRect
performEmotionalRejectionOnCluster:
findBestImage:useActionScores:
emotionallyRejected
selectCoverPhotoFromMultiple:burstSize:
addItemsFromCluster:
removeObjectAtIndex:
setBestImageIdentifiersArray:
forceFaceDetectionEnable
bestImageIdentifiersArray
bestImageIdentifiers
initWithOptions:
addYUVImage:properties:identifier:imageProps:completionBlock:
imageClusterForIdentifier:
isFaceDetectionForced
isPortrait
isAction
clusterArray
setClusterArray:
faceIDCounts
setFaceIDCounts:
allImageIdentifiers
setAllImageIdentifiers:
actionClassifier
setActionClassifier:
statsByImageIdentifier
setStatsByImageIdentifier:
clusterByImageIdentifier
setClusterByImageIdentifier:
burstLogFileName
setBurstLogFileName:
maxNumPendingFrames
setMaxNumPendingFrames:
enableAnalysis
setEnableAnalysis:
dummyAnalysisCount
setDummyAnalysisCount:
enableFaceCore
setEnableFaceCore:
enableDumpYUV
setEnableDumpYUV:
burstCoverSelection
setBurstCoverSelection:
dq_yuvdump
faceAnalysisContext
overrideImage
overrideProps
burstLogFileHandle
curClusterIndexToProcess
_version
_versionString
computeImageDistance:
numHWFaces
setDividerScore:
setLeftImage:
actionClusteringScore
setActionAmount:
dividerScore
setNoiseThreshold:
setHighNoiseThreshold:
leftImage
noiseThreshold
highNoiseThreshold
setTrueLocalMaximum:
compareDividers:
sortedArrayUsingSelector:
compareIndices:
addObjectsFromArray:
removeAllObjects
compareImageOrder:
arrayWithObjects:count:
dictionaryWithObjects:forKeys:count:
extent
CGRectValue
_netExtent
_inputsAreOK
filteredImage:keysAndValues:
dataWithLength:
mutableBytes
length
context
defaultWorkingColorSpace
render:toBitmap:rowBytes:bounds:format:colorSpace:
_outputData:
imageWithBitmapData:bytesPerRow:size:format:colorSpace:
imageWithExtent:processorDescription:argumentDigest:inputFormat:outputFormat:options:roiCallback:processor:
customAttributes
outputData
outputImage
inputImage
setInputImage:
inputExtent
setInputExtent:
inputScale
setInputScale:
inputCount
setInputCount:
_context
baseAddress
region
format
kernelWithString:
floatValue
imageByApplyingGaussianBlurWithSigma:
_CIEdgeWork
applyWithExtent:arguments:
_CIEdgeWorkContrast
inputRadius
_kernelD2
applyWithExtent:roiCallback:arguments:
imageByApplyingFilter:withInputParameters:
autorelease
_isIdentity
downTwo:
upCubic:scale:
_kernelCombine
inputMask
setInputMask:
setInputRadius:
initWithRect:withFaceId:
setFaceId:
setFaceRect:
framesSinceLast
setFramesSinceLast:
computeAverage
initWithScore:
addScore:
computeStandardDeviation
maxScore
setMaxScore:
minScore
setMinScore:
numScores
setNumScores:
sumScores
sumSqScores
setSwFaceId:
setSwCenter:
setSwSize:
setSwLastFrameSeen:
setHwFaceId:
setHwCenter:
setHwSize:
setHwLastFrameSeen:
hwCenter
hwSize
swCenter
swSize
hwFaceId
hwFaceRect
swFaceId
swFaceRect
overlapWithHwRect:
overlapWithSwRect:
swLastFrameSeen
hwLastFrameSeen
dictionary
addEntriesFromDictionary:
faceDetectorWithOptions:
setHwFaceRect:
padRoiRect:paddingX:paddingY:
isSyncedWithImage
setFacesRoiRect:
setNumHWFaces:
setupFaceDetector
calculateFaceCoreROI:imageStat:needFaceCore:
dataWithBytesNoCopy:length:freeWhenDone:
array
setFaceAngle:
faceAngle
setFaceType:
setFace:
setFaceSize:
setExpressionFeatures:
setLeftEye:
setRightEye:
setMouth:
valueWithBytes:objCType:
detectFacesInData:width:height:bytesPerRow:options:error:
arrayByAddingObjectsFromArray:
face
findOverlappingFaceStat:imageStat:
sortedArrayUsingComparator:
subarrayWithRange:
extractDetailsForFaces:inData:width:height:bytesPerRow:options:error:
localizedDescription
expressionFeatures
valueForKey:
boolValue
setNormalizedFaceRect:
setFoundByFaceCore:
setHasLeftEye:
setHasRightEye:
setLeftEyeOpen:
setRightEyeOpen:
setLeftEyeBlinkScore:
setRightEyeBlinkScore:
setSmileScore:
leftEye
setLeftEyeRect:
rightEye
setRightEyeRect:
foundByFaceCore
value:withObjCType:
getValue:
setFocusScore:
setNormalizedFocusScore:
setNormalizedSigma:
removeObjectForKey:
allKeys
arrayWithArray:
class
isKindOfClass:
unsignedLongLongValue
insertObject:atIndex:
addFaceToArray:
setTimestamp:
setHasRollAngle:
setRollAngle:
setHasYawAngle:
setYawAngle:
setIsSyncedWithImage:
setLatestFaceTimestamp:
curConfig
faceIdMapping
renameMapping
faceIdCounter
faceInfoArray
numFramesSinceFullFaceCore
numFramesNoFaces
faceDetector
faceTimestampArray
latestImageTimestamp
lastFaceIndex
normalizedSigma
faceScore
allocWithZone:
initWithFaceStat:
copyWithZone:
setFaceScore:
setFCRLeftEyeFeaturesOffset:
setFCRRightEyeFeaturesOffset:
setFCRSmileFeaturesOffset:
setFCRBlinkFeaturesSize:
setFCRSmileFeaturesSize:
FCRSmileAndBlinkFeatures
setFCRSmileAndBlinkFeatures:
setSmallFace:
_isSyncedWithImage
_hwFaceRect
getSharpnessAndBlurLimits
setAEDelta:
setRegistrationErrorX:
setRegistrationErrorY:
setHasRegistrationData:
setRegistrationErrorIntegral:
setActionClusteringScore:
updateROI:
computeImageColorHistogram:
computeImageSharpnessOnGrid:
computeBlurStatsOnGrid:
computeImageProjections:
getBytes:length:
computeFacialFocusScoreSum
initWithIdentifier:
computeRuleOfThreeDistance
computeSmilePercentage
setAEMatrix:
computeAEMatrix:
compareImageStats:
colorHistogram
setImageId:
setOrientation:
setFaceStatArray:
exclude
setExclude:
setAEStable:
setAEAverage:
setAETarget:
setAFStable:
setAvgHorzDiffY:
setBlurExtent:
timeReceived
setDoLimitedSharpnessAndBlur:
setRoiSize:
AEDelta
fullsizeJpegSize
setFullsizeJpegSize:
numEntries
dissimilarity
projectionMemoryBlock
projectionSignature
sharpnessGrid
gridWidth
gridHeight
gridROI
smoothedROI
_AEDelta
_fullsizeJpegSize
vectorWithX:Y:Z:W:
_CITriangleTile
inputCenter
inputAngle
inputWidth
_CICircle
colorWithRed:green:blue:
inputColor
inputEdgeBlur
vectorWithX:Y:
_CILozengeRefraction
inputPoint0
inputPoint1
inputRefraction
_CITorusRefraction
_internalContext
contextWithOptions:
isEqual:
null
setValue:forKey:
internalCLContextWithOptions:
_initWithInternalRepresentation:
objectForKeyedSubscript:
internalContextWithMTLDevice:options:
internalGLContextWithOptions:
initWithCGContext:options:
initWithEAGLContext:
initWithEAGLContext:options:
internalContextWithEAGLContext:options:
initWithMTLDevice:options:
_gpuContextCheck
_crashed_because_nonaddressable_memory_was_passed_to_render:toBitmap:rowBytes:bounds:format:colorSpace:
_internalRepresentation
lock
unlock
render:toCVPixelBuffer:bounds:colorSpace:
bounds
drawImage:inRect:fromRect:
_isEAGLBackedContext
_isCGBackedContext
createCGImage:fromRect:format:colorSpace:
createCGImage:fromRect:
imageByApplyingTransform:
render:toTexture:target:bounds:colorSpace:
_outputColorSpace
defaultRGBColorSpace
defaultGrayColorSpace
_createCGImage:fromRect:format:colorSpace:deferred:textureLimit:
workingColorSpace
description
regionOfInterestForImage:inRect:
_singletonContext
contextWithCGContext:options:
contextWithEAGLContext:
contextWithEAGLContext:options:
contextWithMTLDevice:
contextWithMTLDevice:options:
abort
invalidate
render:toCVPixelBuffer:
_insertEventMarker:
render:
drawImage:atPoint:fromRect:
render:toTexture:bounds:colorSpace:
render:toMTLTexture:commandBuffer:bounds:colorSpace:
createCGImage:fromRect:format:
createCGImage:fromRect:format:colorSpace:deferred:
createCGLayerWithSize:info:
maximumInputImageSize
maximumOutputImageSize
inputImageMaximumSize
outputImageMaximumSize
workingFormat
reclaimResources
clearCaches
flatten:fromRect:format:colorSpace:
measureRequirementsOf:query::results:
setCTM:
setBounds:
createColorCubeDataForFilters:dimension:
_priv
internalCLContextWithOptions:glContext:
imageByCroppingToRect:
vectorWithCGRect:
_CIPageCurlTransNoEmap
_CIPageCurlTransition
filterWithName:keysAndValues:
inputTargetImage
inputBacksideImage
inputShadingImage
inputTime
emptyImage
_CIPageCurlWithShadowTransition
_CIPageCurlNoShadowTransition
inputShadowSize
inputShadowAmount
inputShadowExtent
inputKeys
hash
copy
setValue:forUndefinedKey:
valueForUndefinedKey:
_crashed_when_dealloc_called_setValue_nil_forKey_probably_because_the_subclass_already_released_it:
finalize
classInfoForClass:
outputKeys
classAttributesForClass:
classDefaultsForClass:
setWithArray:
keyPathsForValuesAffectingValueForKey:
allowsKeyedCoding
raise:format:
initWithFormat:
encodeObject:forKey:
userInfo
setWithObjects:
decodeObjectOfClasses:forKey:
containsValueForKey:
decodeObjectOfClass:forKey:
_copyFilterWithZone:
_propertyArrayFromFilters:inputImageExtent:
_filterArrayFromProperties:inputImageExtent:
ROISelector
respondsToSelector:
methodForSelector:
applyWithExtent:roiCallback:inputImage:arguments:
imageByColorMatchingColorSpaceToWorkingSpace:
apply:arguments:options:
supportsSecureCoding
serializedXMPFromFilters:inputImageExtent:
filterArrayFromSerializedXMP:inputImageExtent:error:
encodeWithCoder:
initWithCoder:
attributes
setDefaults
mutableCopyWithZone:
apply:
name
setName:
isEnabled
setEnabled:
_enabled
classCategoriesForClass:
containsObject:
componentsSeparatedByString:
filterWithName:
hasPrefix:
vectorWithString:
substringWithRange:
_filterClassInCategory:
substringFromIndex:
stringValue
stringRepresentation
rangeOfString:
isSubclassOfClass:
_outputProperties
_initFromProperties:
conformsToProtocol:
_serializedXMPString
filterWithString:
setIdentity
setUserInfo:
setOption:forKey:
_imageMetadataFromFilters:inputImageExtent:
_filterArrayFromImageMetadata:inputImageExtent:
_filterArrayFromProperties:
transformStruct
imageByClampingToExtent
_CIParallelogramTile
inputAcuteAngle
_blur:pass:weightsFactor:
_kernel
setInputAngle:
setInputAmount:
inputAmount
vectorWithX:Y:Z:
setInputCenter:
unsignedIntValue
CGImage
imageWithCGImage:options:
initWithCGImage:options:
fileURLWithPath:
mutableCopy
numberWithUnsignedInt:
_initNaiveWithCGImage:options:
_setOriginalCGImage:
_initWithIOSurface:options:owner:
imageWithCGLayer:options:
initWithCGLayer:options:
initWithBitmapData:bytesPerRow:size:format:options:
initWithBitmapData:bytesPerRow:size:format:colorSpace:
initWithImageProvider:width:height:format:colorSpace:options:
bytes
_initWithBitmapData:bytesPerRow:size:format:options:
initWithBytesNoCopy:length:deallocator:
initWithTexture:size:flipped:colorSpace:
initWithTexture:size:options:
initWithTexture:size:flipped:options:
pixelBuffer
imageWithCVPixelBuffer:options:
initWithCVPixelBuffer:options:
_initWithCVImageBuffer:options:
_setOriginalCVPixelBuffer:
imageWithCVImageBuffer:options:
initWithCVImageBuffer:options:
initWithColor:
cgColor
initWithColorR:G:B:A:
imageTransformForOrientation:
initWithData:options:
initWithCGImageSource:index:options:
imageWithContentsOfURL:options:
initWithContentsOfURL:options:
imageWithContentsOfFile:options:
initWithContentsOfFile:options:
imageWithInternalRepresentation:
imageByClampingToRect:
imageByPremultiplyingAlpha
imageByUnpremultiplyingAlpha
imageByColorMatchingWorkingSpaceToColorSpace:
initWithDictionary:copyItems:
initWithArrayOfImages:selector:
objectAtIndexedSubscript:
shapeWithRect:
stringWithUTF8String:
filterWithName:setDefaults:
initWithCGImage:
nullImage
imageWithCGImage:
imageWithCGLayer:
imageWithBitmapData:bytesPerRow:size:format:options:
imageWithTexture:size:flipped:colorSpace:
imageWithTexture:size:options:
imageWithTexture:size:flipped:options:
imageWithMTLTexture:options:
imageWithCVPixelBuffer:
imageWithCVImageBuffer:
imageWithColor:
noiseImage
noiseImageNearest
noiseImagePadded
imageWithData:
imageWithData:options:
imageWithContentsOfURL:
imageWithContentsOfFile:
imageWithArrayOfImages:selector:
_originalCGImage
initWithCGLayer:
initWithMTLTexture:options:
_originalCVPixelBuffer
initWithCVPixelBuffer:
initWithCVImageBuffer:
imageByApplyingOrientation:
initWithData:
initWithContentsOfURL:
initWithContentsOfFile:
imageByApplyingTransform:highQualityDownsample:
imageByCompositingOverImage:
_imageByPremultiplying
_imageByUnpremultiplying
imageBySettingAlphaOneInExtent:
_imageByApplyingGamma:
_imageByApplyingBlur:
_imageByMatchingWorkingSpaceToColorSpace:
_imageByMatchingColorSpaceToWorkingSpace:
imageByTaggingWithColorSpace:
_imageByRenderingToIntermediate
_imageBySamplingNearest
_imageBySamplingLinear
imageBySettingProperties:
definition
debugDescription
properties
colorSpace
isOpaque
setCacheHint:
cacheHint
writeToTIFF:
printTree
TIFFRepresentation
setValue:forKeyPath:
encodeInt:forKey:
encodeBool:forKey:
decodeIntForKey:
decodeBoolForKey:
modifiedKernelStringForFosl:
_initWithDict:
kernelsWithString:messageLog:
initWithString:
_initWithFirstKernelFromString:withCruftCompatibility:
_outputPixelFormatFromExplicitAttributes:
appendString:
longValue
_isValidOutputPixelFormat:
_outputFormatUsingDictionary:andKernel:
applyWithExtent:roiCallback:arguments:options:
kernelsWithString:
colorMatrixBiasKernel
setROISelector:
parameters
applyWithExtent:arguments:options:
perservesAlpha
setPerservesAlpha:
applyWithExtent:andArguments:
autogenerateROI:args:arguments:extent:
applyWithExtent:roiCallback:inputImage:arguments:options:
_CILenticularHalo
inputHaloRadius
inputHaloWidth
inputHaloOverlap
inputStriationStrength
inputStriationContrast
initWithImageProvider:userInfo:size:format:flipped:colorSpace:
initWithImageProvider:size::format:colorSpace:options:
provideImageData:bytesPerRow:origin::size::userInfo:
_initWithImageProvider:width:height:format:colorSpace:surfaceCache:options:
imageWithImageProvider:userInfo:size:format:flipped:colorSpace:
imageWithImageProvider:size::format:colorSpace:options:
_scale
_CIAlphaNormalize
_CITiltShift
_DistanceColored
inputSaturation
inputUnsharpMaskRadius
inputUnsharpMaskIntensity
initWithFormat:arguments:
stringByAppendingString:
errorWithDomain:code:userInfo:
setInputTransform:
inputTransform
setInputRectangle:
inputRectangle
TIFFRepresentationOfImage:format:colorSpace:options:
writeToURL:options:error:
JPEGRepresentationOfImage:colorSpace:options:
writeTIFFRepresentationOfImage:toURL:format:colorSpace:options:error:
writeJPEGRepresentationOfImage:toURL:colorSpace:options:error:
inputIntensity
setInputIntensity:
initWithExtent:format:options:
initWithExtent:format:
initWithExtent:format:colorSpace:
setImage:
setImage:dirtyRect:
imageAccumulatorWithExtent:format:options:
imageAccumulatorWithExtent:format:
imageAccumulatorWithExtent:format:colorSpace:
clear
commitUpdates:
_state
initWithValues:count:
initWithX:
initWithX:Y:
initWithX:Y:Z:
initWithX:Y:Z:W:
initWithCGPoint:
initWithCGRect:
initWithCGAffineTransform:
valueAtIndex:
stringByAppendingFormat:
isMemberOfClass:
decodeRectForKey:
decodeFloatForKey:
encodeFloat:forKey:
vectorWithValues:count:
vectorWithX:
vectorWithCGPoint:
vectorWithCGAffineTransform:
CGPointValue
CGAffineTransformValue
_count
_values
inputEV
setInputEV:
_CIDisplaceFromImage
inputDisplacementImage
setInputSaturation:
inputBrightness
setInputBrightness:
inputContrast
setInputContrast:
offsetAndCrop
_reduce2X2
_reduce1X4
_reduce4X1
_reduceCrop
inputRVector
setInputRVector:
inputGVector
setInputGVector:
inputBVector
setInputBVector:
inputAVector
setInputAVector:
inputBiasVector
setInputBiasVector:
_kernelNeg
_kernelPos
inputNeutral
setInputNeutral:
inputTargetNeutral
setInputTargetNeutral:
green
blue
alpha
setInputColor:
inputColor0
setInputColor0:
inputColor1
setInputColor1:
initWithAPI:properties:
setDebugLabel:
getMacroContextPrivate
sharegroup
setParameter:to:
currentContext
setCurrentContext:
initWithAPI:
inputPower
setInputPower:
initWithSurface:texture:bounds:context:
surface
_region
_surface
_mtlTexture
metalTexture
metalCommandBuffer
metalCommandBufferRequested
_cmdBuffer
initWithSurface:texture:bounds:context:forCPU:
_forCPU
exceptionWithName:reason:userInfo:
compare:
lengthOfBytesUsingEncoding:
outputFormat
formatForInputAtIndex:
synchronizeInputs
_digestForArgs:
roiForInput:arguments:outputRect:
processWithInputs:arguments:output:error:
applyWithExtent:inputs:arguments:error:
_CINoiseReduction
inputNoiseLevel
inputSharpness
_CIEdgesPrep
_CIFindEdges
_CIConvertRGBtoY
_CIBlur1
_CIBlur2
_CIBlur4
_CISharpenCombineEdges
inputFalloff
inputEdgeScale
arrayWithObjects:
_CIOpTile
initWithImage:
initWithImage:options:
_initWithImage:key0:vargs:
samplerWithImage:
samplerWithImage:keysAndValues:
samplerWithImage:options:
initWithImage:keysAndValues:
opaqueShape
wrapMode
_CIShadedmaterial_0
_CIShadedmaterial
smartToneAdjustmentsForValue:andStatistics:
smartToneAdjustmentsForValue:localLightAutoValue:andStatistics:
smartColorAdjustmentsForValue:andStatistics:
smartToneStatistics
smartColorStatistics
inputUseCube
inputUseCubeColorSpace
_kernelBneg
_kernelBpos
_kernelRH
_kernelH
_kernelC
inputExposure
setInputExposure:
inputShadows
setInputShadows:
inputHighlights
setInputHighlights:
inputBlack
setInputBlack:
inputRawHighlights
setInputRawHighlights:
inputLocalLight
setInputLocalLight:
inputLightMap
setInputLightMap:
setInputUseCube:
setInputUseCubeColorSpace:
_inputLightMap
_cubeImage
_cubeData
_cubeContext
_kernelV_lt1
_kernelV_gt1
_kernelCPos
_kernelCNeg
_kernelCast
inputVibrancy
setInputVibrancy:
inputCast
setInputCast:
initWithBitmap:rowBytes:bounds:format:
initWithBitmap:rowBytes:bounds:format:options:
setBitmap:rowBytes:bounds:format:
contextWithBitmap:rowBytes:bounds:format:
contextWithBitmap:rowBytes:bounds:format:options:
_bcpriv
detectorOfType:context:options:
featuresInImage:options:
drain
_autoRedEyeFilterWithFeatures:imageProperties:context:options:
setFaceBalanceEnabled:
setVibranceEnabled:
setCurvesEnabled:
setShadowsEnabled:
faceBalanceEnabled
setupFaceColorFromImage:usingContext:features:
_scaleImageToMaxDimension:
forImage:usingContext:
setupHistogramsUsing:redIndex:greenIndex:blueIndex:
getAutoRotateFilter:ciImage:rgbRows:inputRect:rotateCropRect:
getAutocropRect:rotateXfrm:inputImageRect:clipRect:
faceBalanceWarmth
faceBalanceStrength
originalFaceColor
vibranceEnabled
vibrance
curvesEnabled
curveCount
curvePointAtIndex:
shadowsEnabled
shadow
autoAdjustmentFiltersWithOptions:
autoAdjustmentFiltersWithImageProperties:options:
hasLeftEyePosition
leftEyePosition
hasRightEyePosition
rightEyePosition
hasMouthPosition
mouthPosition
_dictForFeature:scale:imageHeight:
supportRectangleWithFaceArray:imageSize:
initWithExternalBuffer:subRectangle:fullSize:rowBytes:cameraModel:
autoRepairWithFaceArray:
repairArray
autoAdjustmentFilters
autoRedEyeFilterWithFeatures:imageProperties:options:
autoRedEyeFilterWithFeatures:options:
supportRectangleWithRepair:imageSize:
allValues
inputCameraModel
setInputCameraModel:
inputCorrectionInfo
setInputCorrectionInfo:
executeRepair:
repairExternalBuffer
histogramFromData:
histogramFromFloatData:
histogramFromDoubleData:
values
hist
_CIConvolutionInit_1
_CIConvolutionAdd_1
_CIConvolutionInit_2
_CIConvolutionAdd_2
_CIConvolutionInit_3
_CIConvolutionAdd_3
_CIConvolutionInit_4
_CIConvolutionAdd_4
_CIConvolutionInit_5
_CIConvolutionAdd_5
_CIConvolutionInit_6
_CIConvolutionAdd_6
_CIConvolutionInit_7
_CIConvolutionAdd_7
_CIConvolutionInit_8
_CIConvolutionAdd_8
_CIConvolutionInit_9
_CIConvolutionAdd_9
samplesPerPass
doConvolutionPass:weights:sums:
inputPoints
inputWeights
inputLinearFilterModeEnabled
_CICombine_results
outputImageOriginal
outputImageEnhanced
initWithBounds:andImage:usingContext:
size
centerX
centerY
_CIDroste
inputInsetPoint0
inputInsetPoint1
inputStrands
inputPeriodicity
inputRotation
inputZoom
_kernel_source
_extentForInputExtent:backgroundExtent:
inputBackgroundImage
setInputBackgroundImage:
fromImage:
initFileURLWithPath:
_dumpImage:colorspace:
forImage:downscaleToMax:colorspace:
forImage:downscaleToMax:colorspace:usingContext:
forImage:usingContext:colorspace:
numberWithUnsignedLong:
numberWithShort:
unsignedLongValue
shortValue
fromImageFile:
forImage:downscaleToMax:
withDictionary:
rowAtIndex:
bytesPerPixel
dumpImage:
dumpImageAsDeviceRGB:
dumpImageAsDict:
data
setRGBSumHistogram:
setLuminanceHistogram:
setBorderHistogram:
setSaturationHistogram:
bestWarmthForI:q:percentChange:
setFaceColorFromChromaI:andChromaQ:
analyzeFeatures:usingContext:baseImage:
histogramFromRows:componentOffset:
setupFaceColorFromImage:usingContext:detectorOpts:
_kernel16
curveImageFromPoints:
splineCurveTable:tableSize:gamma:from:
curveImageFromPoints:linear:
setInputPoint0:
setInputPoint1:
setInputPoint2:
setInputPoint3:
setInputPoint4:
inputPoint2
inputPoint3
inputPoint4
_curveImage
filterNamesInCategories:
isSubsetOfSet:
caseInsensitiveCompare:
notificationWithName:object:
defaultQueue
enqueueNotification:postingStyle:coalesceMask:forModes:
classAttributesForName:
localizedStringForKey:value:table:
filterWithName:withInputParameters:
filterNamesInCategory:
registerFilterName:constructor:classAttributes:
localizedNameForFilterName:
localizedNameForCategory:
localizedDescriptionForFilterName:
localizedReferenceDocumentationForFilterName:
compatibilityVersion
filterWithName:compatibilityVersion:
filterWithName:compatibilityVersion:keysAndValues:
allCategories:
URLWithString:
inputClasses
_attributesWithClass:
initWithClass:
indexOfObject:
setObject:atIndexedSubscript:
superclass
bundleForClass:
instanceMethodForSelector:
containsString:
_defaultVersion
_maxVersion
_kernelSnoB_v0
_kernelSHnoB_v0
_kernelSH_v0
_kernelSHnoB_v1
_kernelSH_v1
_kernelSHnoB_v2
_kernelSH_v2
setInputShadowAmount:
setInputHighlightAmount:
inputHighlightAmount
bundleWithPath:
load
classNamed:
initWithDimensions:
setContext:
adjustedImageFromImage:orientation:inverseCTM:
resetOptions
setMinimumCharacterHeight:
setDetectDiacritics:
setReturnSubFeatures:
setMinimizeFalseDetections:
setRecognitionLanguage:
detectFeaturesInBuffer:withRegionOfInterest:error:
subFeatures
text
initWithBounds:topLeft:topRight:bottomLeft:bottomRight:subFeatures:messageString:
initWithContext:options:
featuresInImage:
_width
_height
featureOptions
textDetector
ctmForImageWithBounds:orientation:
boundingBox
corners
_CIRippleTransition
roiForInput:arguments:output:
getNonNormalizedSettings:
createHueArray
hueArrayImage:
inputStrength
setInputStrength:
inputNeutralGamma
setInputNeutralGamma:
inputTone
setInputTone:
inputHue
setInputHue:
inputGrain
setInputGrain:
inputSeed
setInputSeed:
inputScaleFactor
setInputScaleFactor:
smartBlackAndWhiteStatistics
smartBlackAndWhiteAdjustmentsForValue:andStatistics:
setInputOrigI:
setInputOrigQ:
setInputWarmth:
inputOrigI
inputOrigQ
inputWarmth
getBlockSetWithImage:into:width:height:
getDataProviderBytePtrWithImage:into:width:height:
getDataProviderCopyWithImage:into:
initWithDeskView:andFrame:
skinInit
initializeNonDebugVariables
initWithFrameExternalBuffer:
repairWithTag:
upperRepairSizeFraction:
lowerRepairSizeFraction:
upperRepairDistance:
lowerRepairSize:
upperRepairSize:
extractReusableAlignedBitmapsAroundPoint:YR:subYBitmap:subCbCrBitmap:
averageValueFromY:withinSkinMask:butOutsideAlpha:
computeTrimmedBitmaps:newY:newCbCr:IR:newTrimY:newTrimCbCr:returningYR:andCbCrR:
undoRepair:
redEyeRemovalWithPoint:alignPupilShades:matching:force:IOD:tap:
redoRepairWithTag:IOD:
upperRepairDistanceFraction:
insertIntoProminenceVettingHopper:max:outside:confidence:distance:row:column:IOD:
gatherProminencesWithC:MC:altC:altMC:maxwindowsize:repairsize:IR:fr:intoHopper:faceIndex:left:
extractAverageFaceY:contrast:faceIndex:
confidenceWithIOD:repair:andProminenceDifference:
distanceMaskFromPolyToCb:Cr:
prepareLineFunctions
autoRepairExtractAndSearchLeft:right:data:repairSize:autoPupilTonality:faceIndex:
getFloat:d:s:
getInt:d:s:
getBool:d:s:
redEyeRemovalWithData:
supportRectangleWithPoint:imageSize:IOD:
setColorSpace:
initWithCGImage:cameraModel:
createRepairedImage
initWithExternalBuffer:size:rowBytes:
debug
setDebug:
logRepairs
setLogRepairs:
redEyeThresholdKind
setRedEyeThresholdKind:
renderAlpha
setRenderAlpha:
infillBackground
setInfillBackground:
renderSpecularShine
setRenderSpecularShine:
specularSize
setSpecularSize:
specularSoftness
setSpecularSoftness:
pupilShadeAlignment
setPupilShadeAlignment:
autoPupilTonality
setAutoPupilTonality:
forceLoValue
setForceLoValue:
loValue
setLoValue:
standardTemplate
faces
repairs
nRepairs
lastRepairTag
redoLastRepair
executeRepairArray:
setFaceIndex:
setLeft:
ownLF
imageSourceType
blockSet
releaseMe
dataRef
nextRepairTag
lastRepairIOD
iFaceIndex
iLeft
debugRedEye
lastClickYBitmap
lastClickCbCrBitmap
lastClickBitmapMinX
lastClickBitmapMaxX
lastClickBitmapMinY
lastClickBitmapMaxY
lastClickYBitmaps
lastClickCbCrBitmaps
lastClickBitmapRects
lastSearchYBitmap
lastSearchCbCrBitmap
lastSearchBitmapMinX
lastSearchBitmapMaxX
lastSearchBitmapMinY
lastSearchBitmapMaxY
nPolyPoints
polyClosed
polyPoints
polyLines
polyPointConcave
CbCrDistanceTable
nLinears
linearCoefficients
computeDOD:tst:off:mtx:
inputPoint
setInputPoint:
_geomKernel
_colorKernel
inputSize
setInputSize:
setInputRotation:
inputDecay
setInputDecay:
_CICheapBlur
_CILerp
inputPasses
inputSampling
computeDOD:
_kernelGuideMono
_kernelGuideCombine
_kernelJointUpsamp
_kernelJointUpsampRG
_kernelGuideCombine4
inputSmallImage
setInputSmallImage:
inputSpatialSigma
setInputSpatialSigma:
inputLumaSigma
setInputLumaSigma:
filterWithImageURL:options:
filterWithImageData:options:
filterWithCVPixelBuffer:properties:options:
setFaceCoreDetector:
createFaceCoreDataFromCIImage:width:height:
mouth
trackID
trackDuration
initWithBounds:hasLeftEyePosition:leftEyePosition:hasRightEyePosition:rightEyePosition:hasMouthPosition:mouthPosition:hasFaceAngle:faceAngle:hasTrackingID:trackingID:hasTrackingFrameCount:trackingFrameCount:hasSmile:leftEyeClosed:rightEyeClosed:
faceCoreDetector
_tracking
type
hasTrackingID
trackingID
hasTrackingFrameCount
trackingFrameCount
hasFaceAngle
hasSmile
leftEyeClosed
rightEyeClosed
initWithBounds:topLeft:topRight:bottomLeft:bottomRight:
topLeft
topRight
bottomLeft
bottomRight
initWithBounds:topLeft:topRight:bottomLeft:bottomRight:messageString:
messageString
initWithCGColor:
initWithRed:green:blue:alpha:
colorWithRed:green:blue:alpha:
initWithRed:green:blue:alpha:colorSpace:
colorWithRed:green:blue:alpha:colorSpace:
colorWithCGColor:
colorWithRed:green:blue:colorSpace:
colorWithString:
blackColor
whiteColor
grayColor
redColor
greenColor
blueColor
cyanColor
magentaColor
yellowColor
clearColor
initWithRed:green:blue:
initWithRed:green:blue:colorSpace:
numberOfComponents
components
_pad
inputSkyAmount
setInputSkyAmount:
inputGrassAmount
setInputGrassAmount:
stringByReplacingOccurrencesOfString:withString:
hashForString:
betterString:
rawShadow
putShadowsAnalysisInto:
downSampleHistogram:to:storeIn:
printAnalysis
setCurvePercent:
setupFaceColor:redIndex:greenIndex:blueIndex:
setExposureValue:
setShadowsMin:max:zeroExposure:
printHistogram:downsampledTo:
printHistogramsDownsampledTo:
lumHist
rgbSumHist
satHist
borderHist
exposureValue
maxShadow
minShadow
exposureValueAtZeroShadow
curvePercent
faceInputSet
percentFaceChange
initWithFallbackImplementation
initWithVisionKitImplementation
releaseResourcesVisionKit
releaseResourcesFallBack
releaseResources
featuresInImageVisionKit:options:
featuresInImageFallback:options:
pixelTransferSession
interimScaleBuffer
scaleBuffer
CVMLFuncs
_perMeshPtr
_internalBuffer
_CISpotLight
inputLightPosition
inputLightPointsAt
inputConcentration
dataWithData:
_checkInputs
cubeImage
_kernelOpaque
inputCubeDimension
setInputCubeDimension:
inputCubeData
setInputCubeData:
inputColorSpace
setInputColorSpace:
inputRadius0
setInputRadius0:
inputRadius1
setInputRadius1:
_kernelD
inputValue
setInputValue:
inputSoftness
setInputSoftness:
inputDither
setInputDither:
setInputWidth:
setInputSharpness:
_needUnpremuls
_extent
_poskernel
_negkernel
setInputFalloff:
_outputExtent
inputDamping
setInputDamping:
computeDOD:scale:
_pinchDistortionScaleLT1
_pinchDistortionScaleGE1
_CIPointillize
inputRadiusImage
setInputRadiusImage:
_CICMYK_convert
_CIWhite
_CICMYK_cyan
_CICMYK_magenta
_CICMYK_yellow
_CICMYK_black
inputGCR
inputUCR
lumaTable
_tableImage
currentHandler
handleFailureInFunction:file:lineNumber:description:
appendBytes:length:
integerValue
outputCGImage
inputMessage
setInputMessage:
numberWithLong:
setInputMinWidth:
setInputMaxWidth:
setInputMinHeight:
setInputMaxHeight:
setInputDataColumns:
setInputRows:
setInputPreferredAspectRatio:
setInputCompactionMode:
setInputCompactStyle:
setInputCorrectionLevel:
setInputAlwaysSpecifyCompaction:
inputMaxWidth
inputMinHeight
inputMaxHeight
inputDataColumns
inputRows
inputPreferredAspectRatio
inputCompactionMode
inputCompactStyle
inputCorrectionLevel
inputAlwaysSpecifyCompaction
inputMinWidth
setInputLayers:
inputLayers
inputQuietSpace
setInputQuietSpace:
inputBarcodeHeight
setInputBarcodeHeight:
setImageProps:
setCompletionBlock:
computeMergeCost:::
setBurstImages:
_CICrystallize
initReedSolomon
encode:length:bytes:
fillPoly:coefficients:length:
clearPoly:
isZero:
copyPoly:
addOrSubtract:with:
multiply:with:
Degree:
polyCoefficient:degree:
inverse:
multiplyByMonomial:degree:coefficient:
addOrSubtractPoly:with:
Exp:
multiplyPoly:with:
buildGenerator:
divide:by:
createMonomial:coefficient:
coefficients:
_expTable
_logTable
_cachedGeneratorNum
_memoryCapacity
_cachedGenerators
_CISunbeams
inputSunRadius
inputMaxStriationRadius
pathForResource:ofType:
_interpolateGrainKernel
_paddedTileKernel
_grainBlendAndMixKernel
inputISO
setInputISO:
dataWithContentsOfFile:
inputSigmaX
setInputSigmaX:
inputSigmaY
setInputSigmaY:
actionAmount
compareActionAmounts:
trueLocalMaximum
substringToIndex:
componentsJoinedByString:
initWithBytesNoCopy:length:encoding:freeWhenDone:
boolForKey:
volatileDomainForName:
initWithBytesNoCopy:length:freeWhenDone:
_kernel_code
inputLevels
setInputLevels:
_CIEdges
_fadeKernel
setInputTargetImage:
setInputTime:
_CIHexagonalPixellate
inputOpacity
setInputOpacity:
regionOf:destRect:Offset:
setInputWeights:
secondsSinceStart
statsForImageWithIdentifier:
stringByAppendingPathExtension:
dictionaryWithContentsOfFile:
burstImageSet
burstImageSetWithOptions:
coverImageIdentifier
imageClusterCount
imageClusterForIndex:
setLoggingListener:withUserInfo:
computeDOD
_CIBox6
_CIBox4
_CICross4
_CIRectangle
_CILanczosDownBy2
_CILanczosHorizontalUpsample
_CILanczosVerticalUpsample
inputAspectRatio
setInputAspectRatio:
_kernelNoF
_kernelNoB
inputMaskImage
setInputMaskImage:
convertRGBAToYUV420:rgbaBytesPerRow:
setWidth:
setHeight:
setYbuffer:
setCbuffer:
setBytesPerRow:
dataPtr
apply:image:arguments:inoutSpace:
apply:image:arguments:inSpace:
inputWhitePoint
inputVersion
inputRAWDictionary
initWithRect:
_shapeInfinite
initWithStruct:
transformBy:interior:
insetByX:Y:
unionWith:
unionWithRect:
intersectWith:
intersectWithRect:
CGSRegion
inputCompression
setInputCompression:
_kernel_name
_croppedCenterPixelImage
_roiArea
_roiCenter
_singlePixelImage
_roiRect
setInputAcuteAngle:
_CIComicNoiseReduction
_CISobelEdges
_CIColorControls
inputNRNoiseLevel
inputNRSharpness
inputEdgeIntensity
inputThreshold
_CISpotColor
inputCenterColor1
inputReplacementColor1
inputCloseness1
inputContrast1
inputCenterColor2
inputReplacementColor2
inputCloseness2
inputContrast2
inputCenterColor3
inputReplacementColor3
inputCloseness3
inputContrast3
setLength:
localLightStatisticsWithProxy:
localLightStatistics
localLightStatisticsNoProxy
_polyKernel
inputGuideImage
inputLightMapWidth
inputLightMapHeight
initWithLength:
inputGradientImage
setInputGradientImage:
inputBarOffset
setInputBarOffset:
_kernelG
inputShadowRadius
setInputShadowRadius:
inputShadowDensity
setInputShadowDensity:
inputShadowOffset
setInputShadowOffset:
setInputMaxStriationRadius:
setInputStriationStrength:
setInputStriationContrast:
inputFadeThreshold
setInputFadeThreshold:
inputEpsilon
setInputEpsilon:
inputCrossAngle
setInputCrossAngle:
inputCrossScale
setInputCrossScale:
inputCrossWidth
setInputCrossWidth:
inputCrossOpacity
setInputCrossOpacity:
insertString:atIndex:
replaceOccurrencesOfString:withString:options:range:
generateGeneralKernelFromWarpKernel:args:
generateMainFromWarpKernel:args:
makeGridImage:nx:ny:
inputTopLeft
setInputTopLeft:
inputTopRight
setInputTopRight:
inputBottomRight
setInputBottomRight:
inputBottomLeft
setInputBottomLeft:
inputRedCoefficients
setInputRedCoefficients:
inputGreenCoefficients
setInputGreenCoefficients:
inputBlueCoefficients
setInputBlueCoefficients:
inputAlphaCoefficients
setInputAlphaCoefficients:
setWithObject:
initWithImageSource:options:
isFileURL
path
pathExtension
setObject:forKeyedSubscript:
initWithCVPixelBuffer:properties:options:
optionKeys
defaultInputLuminanceNoiseReductionAmount
setInputLuminanceNoiseReductionAmount:
defaultInputColorNoiseReductionAmount
setInputColorNoiseReductionAmount:
defaultInputNoiseReductionContrastAmount
setInputNoiseReductionContrastAmount:
defaultInputNoiseReductionDetailAmount
setInputNoiseReductionDetailAmount:
defaultInputNoiseReductionSharpnessAmount
setInputNoiseReductionSharpnessAmount:
defaultInputEnableVendorLensCorrection
setInputEnableVendorLensCorrection:
setInputIgnoreOrientation:
setInputEnableNoiseTracking:
setInputNoiseReductionAmount:
setInputEnableSharpening:
setInputDraftMode:
setInputBoost:
defaultBoostShadowAmount
setInputBoostShadowAmount:
defaultImageOrientation
setInputImageOrientation:
defaultDecoderVersion
setInputDecoderVersion:
defaultInputBaselineExposureAmount
setInputBaselineExposure:
defaultInputBiasAmount
setInputBias:
defaultInputHueMagMRAmount
setInputHueMagMR:
defaultInputHueMagRYAmount
setInputHueMagRY:
defaultInputHueMagYGAmount
setInputHueMagYG:
defaultInputHueMagGCAmount
setInputHueMagGC:
defaultInputHueMagCBAmount
setInputHueMagCB:
defaultInputHueMagBMAmount
setInputHueMagBM:
setInputDisableGamutMap:
defaultNeutralTemperature
setInputNeutralTemperature:
defaultNeutralTint
setInputNeutralTint:
defaultNeutralChromaticityX
setInputNeutralChromaticityX:
defaultNeutralChromaticityY
setInputNeutralChromaticityY:
arrayByAddingObject:
_inputImageSource
_inputImageAndProperties
_inputImage
_tempImage
_nativeSize
_isRawSource
_calledDealloc
_baseImageProperties
_rawDictionary
_rawReconstructionDefaultsDictionary
_supportedSushiModes
_supportedDecoderVersions
_filters
_typeIdentifierHint
_defaultOrientation
_neutralColour
inputRequestedSushiMode
inputNeutralChromaticityX
inputNeutralChromaticityY
inputNeutralTemperature
inputNeutralTint
inputNeutralLocation
inputBoost
inputDraftMode
inputIgnoreOrientation
inputImageOrientation
inputEnableSharpening
inputEnableNoiseTracking
inputEnableVendorLensCorrection
inputNoiseReductionAmount
inputLuminanceNoiseReductionAmount
inputColorNoiseReductionAmount
inputNoiseReductionSharpnessAmount
inputNoiseReductionContrastAmount
inputNoiseReductionDetailAmount
inputDecoderVersion
inputBoostShadowAmount
inputBias
inputBaselineExposure
inputDisableGamutMap
inputHueMagMR
inputHueMagRY
inputHueMagYG
inputHueMagGC
inputHueMagCB
inputHueMagBM
inputLinearSpaceFilter
rawReconstructionDefaultsDictionary
rawOptions
rawDictionary
whitePointArray
whitePoint
getWhitePointVectorsR:g:b:
sushiMode
invalidateFilters
rawOptionsWithSubsampling:
subsampling
getScaleTransform
initWithObjects:
willChangeValueForKey:
invalidateInputImage
didChangeValueForKey:
valueForKeyPath:
nativeSize
filters
getOrientationTransform
rawMajorVersion
setTempTintAtPoint:
applyMatrix:toCIImage:
automaticallyNotifiesObserversForKey:
isEqualToNumber:
supportedDecoderVersions
RAWFiltersValueForKeyPath:
setInputNeutralLocation:
supportedSushiModes
setInputLinearSpaceFilter:
activeKeys
outputNativeSize
convertNeutralX:y:toTemperature:tint:
convertNeutralTemperature:tint:toX:y:
updateTemperatureAndTint
updateChomaticityXAndY
handleFailureInMethod:object:file:lineNumber:description:
setInputRequestedSushiMode:
_CIResetalpha
inputMinComponents
setInputMinComponents:
inputMaxComponents
setInputMaxComponents:
inputTexture
setInputTexture:
inputCropAmount
inputCenterStretchAmount
inputBreakpoint0
setInputBreakpoint0:
inputBreakpoint1
setInputBreakpoint1:
inputGrowAmount
setInputGrowAmount:
_kernelAlt
inputFlipYTiles
setInputFlipYTiles:
inputHeight
setInputHeight:
inputHighLimit
setInputHighLimit:
inputLowLimit
setInputLowLimit:
_kernelLocalContrast
_kernelWarpS
_kernelWarpT
_kernelMix
inputBottomHeight
setInputBottomHeight:
inputNumberOfFolds
setInputNumberOfFolds:
inputFoldShadowAmount
setInputFoldShadowAmount:
inputOffset
setInputOffset:
inputRange
setInputRange:
inputSpread
setInputSpread:
inputFill
setInputFill:
inputGlowColorInner
setInputGlowColorInner:
inputGlowColorOuter
setInputGlowColorOuter:
inputShadowColorInner
setInputShadowColorInner:
inputShadowColorOuter
setInputShadowColorOuter:
inputShadowBlurInner
setInputShadowBlurInner:
inputShadowBlurOuter
setInputShadowBlurOuter:
inputSoften
setInputSoften:
inputHighlightColor
setInputHighlightColor:
inputShadowColor
setInputShadowColor:
_kernelInvertMask
_kernelMultiplyByMask
setShouldFavorTop:
setShouldFavorBottom:
rectContainingRect:andOtherRect:
replaceObjectAtIndex:withObject:
rectWithSize:andPoint:inPosition:fromOriginalSize:
scaleRect:toFitSize:withAnchorPoint:
determineBestPositionWithinSize:forImportantRect:restrictRect:
scaleRect:byScale:
expandRect:toContainRect:
computeClippingWithinSize:andImportantRect:
getRatioOfSize:
clusterRects:
computeClippingWithinSize:andImportantRects:
computeClippingWithinSize:forImportantRect:andType:restrictRect:
computeClippingWithinSize:forMultipleRects:
shouldFavorTop
shouldFavorBottom
originalImageSize
setOriginalImageSize:
autoRotateFilterFFT:image:inputRect:
calcIntersection:slope1:pt2:slope2:
initWithCapacity:
scaled Average Camera Travel Distance = %f
scaled Max Registration Error Integral = %f
scaled Mean peak registration error / Max peak registration error = %f
scaled Beginning vs. End AEMatrix difference vs. Average of Adjacent AE Matrix Differences = %f
scaled In-out ratio = %f
scaled Max inner distance = %f
scaled Average registration error skewness = %f
Sequence classified as NON-ACTION due to complete lack of local motion (%f, threshold %f)
Non-Linear SVM Action classifier called with:
Average Camera Travel Distance = %f
Max Registration Error Integral = %f
Mean peak registration error / Max peak registration error = %f
Beginning vs. End AEMatrix difference vs. Average of Adjacent AE Matrix Differences = %f
In-out ratio = %f
Max inner distance = %f
Average registration error skewness = %f
PREDICTION: --- %s --- (value = %f)
ACTION
NON-ACTION
testMaxInnerDistance
Tf,VtestMaxInnerDistance
testInOutRatio
Tf,VtestInOutRatio
testMaxPeakRegistrationError
Tf,VtestMaxPeakRegistrationError
testMeanPeakRegistrationError
Tf,VtestMeanPeakRegistrationError
testMinRegionOfInterestSize
Tf,VtestMinRegionOfInterestSize
testMaxRegistrationErrorSkewness
Tf,VtestMaxRegistrationErrorSkewness
testMaxRegistrationErrorIntegral
Tf,VtestMaxRegistrationErrorIntegral
testAverageCameraTravelDistance
Tf,VtestAverageCameraTravelDistance
testAverageRegistrationErrorSkewness
Tf,VtestAverageRegistrationErrorSkewness
testBeginningVsEndAEMatrixVsAverageAdjacentAEMatrix
Tf,VtestBeginningVsEndAEMatrixVsAverageAdjacentAEMatrix
svmParameters
T^{__SVMParameters=[7{__SVMScaleOffset=ff}]ddii^{CIBurstSupportVector}^{CIBurstSupportVector}},V_svmParameters
burst_mode_logging
staccato_mode_logging
burst_max_pending_frames
burst_disable_analysis
burst_force_face_detection
burst_dummy_analysis
burst_disable_facecore
burst_use_fixed_image
burst_fixed_image_filename
burst_dump_yuv
staccato_yuv_dump
burst_use_version
com.apple.camera
/var/mobile/Library/Caches/com.apple.camera
burstSets
com.apple.burstAnalyzer
dd-MM-yyyy'_'HH-mm-ss'_burstLog.txt'
kern.osversion
com.apple.staccato_dump
counter.bin
BurstDoc_AllImageStats
BurstDoc_AllImageIdentifiers
BurstDoc_BestImageIds
BurstDoc_LogFile
Computing action selection threshold
Mean non-zero actions = %f, std dev = %f
ACTION SELECTION THRESHOLD = %f
Examining image, id=%s, timestamp = %.6f, done=%d
Not processing frames, imageStat.timestamp = %.6f, latestFaceTimestamp = %.6f
LeftEyeFeaturesOffset
RightEyeFeaturesOffset
SmileFeaturesOffset
BlinkFeaturesSize
SmileFeaturesSize
burstimage_%06d.yuv
Image_FaceRectROI
Image_Width
Image_Height
Image_AEAverage
Image_AETarget
Image_AEStable
Image_AFStable
Image_Orientation
Image_AEMatrix
Error!  Done adding, but there are still frames left!
Adding image: %s
Image %d:%s has emotional score %d
Image %d:%s has been emotionally rejected.
Skipping projection computation because data isn't present
LOOKING FOR FALSE-POSITIVE FACES...
Analyzing %s...
REMOVING false-positive face with ID = %d
Keeping face with ID = %d
Collapsing %s
*_*_* GARBAGE DETECTOR FOR %s *_*_*
Travel = %f, maxSkewness = %f, avgSkewness = %f, blur = %f, avgBlur = %f, stdBlur = %f
hasFaces = %d
notBlurry = %d
veryBlurry = %d
potentiallyBlurry = %d
poorRegistration = %d
suspectRegistration = %d
******Image %s classified as garbage.
**** Image %s classified as garbage by association.
Image_FacesArray
Score for %s:%d is %f 
with action score %f and center bias %f (isGarbage=%d)
NEW BEST
Cover photo PORTRAIT selection score for %d:%s = %f (unbiased = %f)
Cover photo ACTION selection score for %d:%s = %f
%s:   # faces = %d, avgH = %f
    face id=%d, rect=%.3f,%.3f,%.3f,%.3f, focus=%.3f, faceScore=%.3f, leftEyeOpen=%d, rightEyeOpen=%d
Performing emotional rejection of face images in cluster %d:
Items in next cluster:
Image %s is classified as garbage for portrait mode, no sharp faces.
Checking temporal order: %d vs. %d
Removing %d:%s
All items in one cluster.
clusterArray
T@"NSMutableArray",VclusterArray
temporalOrder
Ti,VtemporalOrder
faceIDCounts
T@"NSCountedSet",VfaceIDCounts
allImageIdentifiers
T@"NSMutableArray",VallImageIdentifiers
statsByImageIdentifier
T@"NSMutableDictionary",VstatsByImageIdentifier
clusterByImageIdentifier
T@"NSMutableDictionary",VclusterByImageIdentifier
burstLogFileName
T@"NSString",VburstLogFileName
actionClassifier
T@"CIBurstActionClassifier",VactionClassifier
maxNumPendingFrames
Ti,VmaxNumPendingFrames
enableAnalysis
TB,VenableAnalysis
dummyAnalysisCount
Ti,VdummyAnalysisCount
enableFaceCore
TB,VenableFaceCore
enableDumpYUV
TB,VenableDumpYUV
burstCoverSelection
T@"NSString",VburstCoverSelection
burstId
T@"NSString",&,N,VburstId
bestImageIdentifiersArray
T@"NSArray",VbestImageIdentifiersArray
versionString
T@"NSString",V_versionString
version
Ti,V_version
Images without faces = %d, threshold = %d, total # = %d
Classified as portrait mode. Affects cover photo selection.
all costs within valid region: 
mean = %f, std = %f
First average cost = %f
Second average cost = %f
--Invalidating two outliers from the start of the burst
--Invalidating one outlier from the start of the burst
Last average cost = %f
Second-to-last average cost = %f
--Invalidating two outliers from the end of the burst
--Invalidating one outlier from the end of the burst
Number of images too few after invalidation at the endpoints. Return one selection.
Result of three-way division: finalCost: %f, inOutRatio: %f
Classified as non-action.
Classified as action.
Between %d and %d: 
motion: %f
Action mean = %f, action std = %f, action threshold = %f
Local statistics for divider %03d
 with score %f:
 noise threshold = %f, high threshold = %f (mean %f, std %f)
Overall mean divider score = %f
clusterDividerArraySize = %d
Locally-maximal divider %d not considered due to being potential noise (%f vs %f,%f)
Locally-maximal divider %d not considered due to lack of any motion: %f
Locally-maximal divider %d not considered due to being potential noise (nearby peak).
local maxima size: %ld
divider %d
Re-running three-way division with minClusterSize = %d, maxClusterSize = %d
Strongest local maxima: %d and %d
Expanding main peak to include divider %d
Adding action-based cluster boundaries.
Cluster %d is too small for action-based cluster boundaries
Action statistics for cluster %d: mean %f std %f threshold %f
Adding ACTION DIVIDER at location %d
***Finding three way division:
firstValidImage = %d, lastValidImage = %d
NEW BEST: largestInnerDistance = %f, bestRatio = %f
Divider1 = %d, Divider2 = %d
RECURSING: (%d->%d) becomes (%d->%d)
Clustering costs: maxInner = %f, inOutRatio = %f
Threshold for dupes: %f
Distance between selections %d and %d: %f, %f
Selection score of %d is %f... isGarbage = %d
Choosing candidate %d from a series of dupes
Throwing away all dupes due to garbage classification
Keeping candidate %d
Tossing out the %s on %d
trash
reject
All images are garbage. Picking the middle selection = %s.
Projections error %d:%s in %s @ %s:%d
FastRegistration_status FastRegistration_computeSignatures(const vImage_Buffer *, _Bool, dispatch_queue_t, FastRegistration_Signatures *)
/Library/Caches/com.apple.xbs/Sources/EmbeddedCoreImage_Sim/EmbeddedCoreImage-449/Framework/api/Burst/Projections/FastRegistration_Core.c
FastRegistration error %d:%s in %s @ %s:%d
FastRegistration_status FastRegistration_register(const FastRegistration_Signatures *, const FastRegistration_Signatures *, float, dispatch_queue_t, float *, float *, float *, float *)
FastRegistration_status FastRegistration_processProjections(float *, vImagePixelCount)
!!! you should not read this !!!
error with the projections computation
vImage error
out of bounds error
memory allocation error
invalid parameter
invalid option
internal error
ProvAssembled %llu
ProvAssembled %p
ProvTile %llu
ProvTile
v48@?0^v8Q16Q24Q32Q40
v48@?0r^v8Q16Q24Q32Q40
v16@?0^{__IOSurface=}8
provider %s %ldx%ld
 tile %zu,%zu
 tile %zu
 nearestsampling
 cache
 tile %zu,%zu<BR/>
 tile %zu<BR/>
<BR/>
alpha_premul
alpha_one
alpha_unpremul
alpha_premul-clear-edges
alpha_unpremul-clear-edges
alpha_unknown
edge_clamp
edge_unknown
shape=hexagon, color="#CCCCFF"
10.5
inputCount
inputScale
CIAreaHistogram requires inputCount >= 1 and <= 256
CIAreaHistogram area width or height is greater than 32768.
CIExposureAdjust
CIAreaHistogram failed to allocate memory.
CIAreaHistogram %d bins
{CGRect={CGPoint=dd}{CGSize=dd}}40@?0{CGRect={CGPoint=dd}{CGSize=dd}}8
v24@?0@"<CIImageProcessorInput>"8@"<CIImageProcessorOutput>"16
inputImage
T@"CIImage",&,N,VinputImage
inputExtent
T@"CIVector",&,N,VinputExtent
T@"NSNumber",&,N,VinputScale
T@"NSNumber",&,N,VinputCount
processHistogram
/Library/Caches/com.apple.xbs/Sources/EmbeddedCoreImage_Sim/EmbeddedCoreImage-449/Framework/filters/CIAreaHistogram.mm
!hist8
hist8
false
kernel vec4 _edgeWork(__sample src, __sample blurred)
  float lum = dot(src.rgb, vec3(0.299, 0.587, 0.114));
  float blum = dot(blurred.rgb, vec3(0.299, 0.587, 0.114));
  return vec4(clamp((lum - blum) * 1000.0, 0.0, 1.0));
kernel vec4 _edgeWorkContrast(__sample src, float contrast)
  return clamp((src - 0.5) * contrast + 0.5, 0.0, 1.0);
10.4
slab_alloc
/Library/Caches/com.apple.xbs/Sources/EmbeddedCoreImage_Sim/EmbeddedCoreImage-449/Framework/util/x-alloc.c
slab->magic == SLAB_MAGIC (bucket_idx)
slab_dealloc
%5s %5s %5s %5s %5s %5s
size
slabs
used
free
full
cache
%5d %5d %5d %5d %5d %5d
%5s %5d %5d %5d %5d %5d
total
x-alloc
%a %b %e %H:%M:%S %Z %Y
** Log started %s **
X_LOG_FILE
stderr
stdout
shape=rect, color="#FFFF99"
setprops
kernel vec4 _betterDown2 (sampler image)
  vec4 U = sample(image, samplerTransform(image, destCoord()*2.0 + vec2(0.0, 1.0))); 
  vec4 D = sample(image, samplerTransform(image, destCoord()*2.0 + vec2(0.0,-1.0))); 
  vec4 R = sample(image, samplerTransform(image, destCoord()*2.0 + vec2( 1.0,0.0))); 
  vec4 L = sample(image, samplerTransform(image, destCoord()*2.0 + vec2(-1.0,0.0))); 
  return (U+D+L+R)*0.25; 
kernel vec4 _maskedVariableBlur (__sample mask, 
    __sample c0, __sample c1, __sample c2, __sample c3, __sample c4, __sample c5, __sample c6, 
    float maxBlur) 
  float k = mask.y; 
  k = clamp(k, 0.0, 1.0); 
  float m = k*maxBlur; 
  m = log2(m*4.0/3.0); 
  m = max(m,0.0); 
  float mLo = floor(m); 
  vec4 cLo = c0; 
  vec4 cHi = c1; 
  cLo =  (mLo > 0.5) ? c1 : cLo; 
  cHi =  (mLo > 0.5) ? c2 : cHi; 
  cLo =  (mLo > 1.5) ? c2 : cLo; 
  cHi =  (mLo > 1.5) ? c3 : cHi; 
  cLo =  (mLo > 2.5) ? c3 : cLo; 
  cHi =  (mLo > 2.5) ? c4 : cHi; 
  cLo =  (mLo > 3.5) ? c4 : cLo; 
  cHi =  (mLo > 3.5) ? c5 : cHi; 
  cLo =  (mLo > 4.5) ? c5 : cLo; 
  cHi =  (mLo > 4.5) ? c6 : cHi; 
  cLo =  (mLo > 5.5) ? c6 : cLo; 
  return mix(cLo,cHi,m-mLo); 
{CGRect={CGPoint=dd}{CGSize=dd}}44@?0i8{CGRect={CGPoint=dd}{CGSize=dd}}12
CISoftCubicUpsample
inputMask
T@"CIImage",&,N,VinputMask
inputRadius
T@"NSNumber",&,N,VinputRadius
faceId
Ti,VfaceId
faceRect
T{CGRect={CGPoint=dd}{CGSize=dd}},VfaceRect
framesSinceLast
Ti,VframesSinceLast
maxScore
Tf,VmaxScore
minScore
Tf,VminScore
numScores
Ti,VnumScores
swFaceId
Ti,VswFaceId
swCenter
T{CGPoint=dd},VswCenter
swSize
T{CGSize=dd},VswSize
swLastFrameSeen
Ti,VswLastFrameSeen
hwFaceId
Ti,VhwFaceId
hwCenter
T{CGPoint=dd},VhwCenter
hwSize
T{CGSize=dd},VhwSize
hwLastFrameSeen
Ti,VhwLastFrameSeen
true
FCRSetupParamLoadModelFiles
    orientation = %d
Number of HW faces = %d - calculating rect
   hwFaceRect: (%.3f,%.3f,%.3f,%.3f), hasLeftEye = %d, hasRightEye = %d
   face %d = (%.3f,%.3f,%.3f,%.3f)
   fcrect  = (%.3f,%.3f,%.3f,%.3f)
   inserting prev face (hw%d,sw=%d) = (%.3f,%.3f,%.3f,%.3f) padding=(%.3f,%.3f)
  needFaceCore = %d
setting faces ROI to (%.3f,%.3f,%.3f,%.3f)
{CGRect={CGPoint=dd}{CGSize=dd}}
q24@?0@"FCRFace"8@"FCRFace"16
Face detection error
extractDetails error: %s
face %d: rect = %.3f,%.3f,%.3f,%.3f, leftOpen=%d,rightOpen=%d
  #faces = %d
calculateFaceFocus:
   adding rect: %.3f,%.3f,%.3f,%.3f
   focusScore = %d, %.3f
AdjustFaceIds: Examining '%s'
faceStat.id = %d
    rename found: %d mapped to %d
    new id: %d mapped to %d
    no id: assigning %d
    map found: %d maps to %d
       entry exists with same id: %d
%d faces so far unmatched:
    face %d
    %d overlaps with %d by %.3f %% : 
    matched!  mapping %d to %d
    not matched
      no match found for id %d - adding face
  prevConfig has %d entries
Found mapping!
   mapping not found for %d, mapping to itself
removing config entry: %d
Timestamp
  face ID = %d, timestamp = %.6f
FaceID
Rect
Width
Height
    inserting at index %d, count=%d
  extractFacesFromMetadata
extractFaceMetadata: invalid properties
AccumulatedFaceMetadata
  accumulatedFaceMetadata = %x
adding %d faces
Regions
regions exist
RegionList
  num regions = %d
    latestFaceTimestamp = %.6f
addFacesToImageStat: timestamp = %.6f, lastFaceIndex=%d
    imageTimestamp > latestFaceTimestamp
RollAngle
YawAngle
LeftEyeX
LeftEyeY
LeftEyeWidth
LeftEyeHeight
LeftEyeBlinkLevel
RightEyeX
RightEyeY
RightEyeWidth
RightEyeHeight
RightEyeBlinkLevel
SmileLevel
      found face id %d, timestamp=%.6f, x=%.3f,y=%.3f,w=%.3f,h=%.3f
    adding face id %d, timestamp %.6f
    face id %d, timestamp %.6f - delta = %.6f, perhaps should use FaceCore
FaceInfoArray:
hwId = %d (lastSeen=%d, ctr=%.3f,%.3f size=%.3f,%.3f), swId = %d (lastSeen=%d, ctr=%.3f,%.3f size=%.3f,%.3f)
timeFaceDetectionDone
Td,VtimeFaceDetectionDone
timeBlinkDetectionDone
Td,VtimeBlinkDetectionDone
forceFaceDetectionEnable
TB,VforceFaceDetectionEnable
latestFaceTimestamp
Td,VlatestFaceTimestamp
leftEyeOpen
TB,VleftEyeOpen
rightEyeOpen
TB,VrightEyeOpen
smiling
TB,Vsmiling
leftEyeBlinkScore
Tf,VleftEyeBlinkScore
rightEyeBlinkScore
Tf,VrightEyeBlinkScore
smileScore
Tf,VsmileScore
hasLeftEye
TB,VhasLeftEye
hasRightEye
TB,VhasRightEye
foundByFaceCore
TB,VfoundByFaceCore
normalizedFaceRect
T{CGRect={CGPoint=dd}{CGSize=dd}},VnormalizedFaceRect
focusScore
Tf,VfocusScore
faceScore
Tf,VfaceScore
leftEyeRect
T{CGRect={CGPoint=dd}{CGSize=dd}},VleftEyeRect
rightEyeRect
T{CGRect={CGPoint=dd}{CGSize=dd}},VrightEyeRect
FCRLeftEyeFeaturesOffset
Ti,VFCRLeftEyeFeaturesOffset
FCRRightEyeFeaturesOffset
Ti,VFCRRightEyeFeaturesOffset
FCRSmileFeaturesOffset
Ti,VFCRSmileFeaturesOffset
FCRBlinkFeaturesSize
Ti,VFCRBlinkFeaturesSize
FCRSmileFeaturesSize
Ti,VFCRSmileFeaturesSize
FCRSmileAndBlinkFeatures
T@"NSMutableArray",VFCRSmileAndBlinkFeatures
hwFaceRect
T{CGRect={CGPoint=dd}{CGSize=dd}},V_hwFaceRect
normalizedFocusScore
Tf,VnormalizedFocusScore
normalizedSigma
Tf,VnormalizedSigma
hasRollAngle
TB,VhasRollAngle
hasYawAngle
TB,VhasYawAngle
rollAngle
Tf,VrollAngle
yawAngle
Tf,VyawAngle
timestamp
Td,Vtimestamp
isSyncedWithImage
TB,V_isSyncedWithImage
smallFace
TB,VsmallFace
Image_ImageROIGridStartX
Image_ImageROIGridStartY
Image_ImageROIGridEndX
Image_ImageROIGridEndY
Original ROI = %d,%d -> %d,%d
Smoothed ROI = %d,%d -> %d,%d
Sharpness ROI for %s updated to (%d,%d)->(%d,%d)
%s REGISTERED AGAINST %s
Registration result: tx = %d, ty = %d
----------REGISTRATION ERROR INTEGRAL 
Row interval: (%d->%d)
Column interval: (%d->%d)
sensedROI = (%d,%d)->(%d,%d)
referenceROI = (%d,%d)->(%d,%d)
Registration rejected due to ROI too large or too small.
Registration in favor of face detection ROI.
Registration rejected due to skewness, which can indicate a bad registration result.
Registration rejected due to insufficient local motion.
----------------------- facecore count = %d, numHWFaces = %d
Limited ROI = (%d,%d)->(%d,%d)
Computing sharpness over grid points (%d,%d)->(%d,%d)
After collapse avgHorzDiffY = %f, blurExtent = %f
Num HW faces = %d, facecore faces = %d
combined normalized focus score for face core detections = %f
Limited sharpness score = %f, with number of faces = %d
Thumbnail selection score computation for %s
Average facial focus score = %f
Initial score (no faces) = %f (isGarbage = %d)
Action selection score = %f
imageId
T@"NSString",VimageId
orientation
Ti,Vorientation
faceStatArray
T@"NSMutableArray",VfaceStatArray
exclude
TB,Vexclude
AEStable
TB,VAEStable
AEAverage
Ti,VAEAverage
AETarget
Ti,VAETarget
AFStable
TB,VAFStable
avgHorzDiffY
Tf,VavgHorzDiffY
blurExtent
Tf,VblurExtent
imageScore
Tf,VimageScore
actionScore
Tf,VactionScore
timeReceived
Td,VtimeReceived
maxSkewness
Tf,VmaxSkewness
registrationErrorX
Tf,VregistrationErrorX
registrationErrorY
Tf,VregistrationErrorY
registrationErrorIntegral
Tf,VregistrationErrorIntegral
actionClusteringScore
Tf,VactionClusteringScore
hasRegistrationData
TB,VhasRegistrationData
facesRoiRect
T{CGRect={CGPoint=dd}{CGSize=dd}},VfacesRoiRect
numHWFaces
Ti,VnumHWFaces
emotionallyRejected
TB,VemotionallyRejected
doLimitedSharpnessAndBlur
TB,VdoLimitedSharpnessAndBlur
Tf,Vtx
Tf,Vty
isGarbage
TB,VisGarbage
roiSize
Tf,VroiSize
AEDelta
Ti,V_AEDelta
fullsizeJpegSize
Ti,V_fullsizeJpegSize
Registration error stats: mean=%f, stdDev=%f, skewness=%f, maxValue=%f
Insufficient peak error for ROI computation %f (threshold %f)
Peak rejection threshold = %f (mean = %f, std = %f)
Starting ROI construction at %d->%d
kernel vec4 _triangleTile (sampler src, vec2 center, vec4 ftrans, vec4 btrans)
  vec2  t = destCoord() - center;
  t = vec2(dot(t, ftrans.xy), dot(t, ftrans.zw));
  t = fract(t);
  t = (t.x > t.y) ? t.yx : t;
  t.y = (t.y > 2.0 - t.x - t.y) ? (2.0 - t.x - t.y) : t.y;
  t.x = (t.x < 1.0 - t.x - t.y) ? (1.0 - t.x - t.y) : t.x;
  t = (t.x > t.y) ? t.yx : t;
  t = vec2(dot(t, btrans.xy), dot(t, btrans.zw));
  t += center;
  return sample(src, samplerTransform(src, t));
kernel vec4 _circle (vec4 parms, __color color)
  float d = parms.z - length (destCoord() - parms.xy);
  return clamp (d * parms.w + .5, 0.0, 1.0) * color;
inputEdgeBlur
inputColor
kernel vec4 _lozengeRefraction(sampler src, vec2 p0, vec2 p1, float radius, vec2 v01, vec2 x01, float indexOfRefraction, float levitation)
  vec2 v0 = destCoord() - p0;
  vec3 c0 = cross(vec3(v0, 0.0), vec3(v01, 0.0));
  vec2 unitvec = (c0.z < 0.0) ? x01 : -x01;
  float dist = abs(c0.z);
  float dist2 = length(v0);
  vec2 unitvec2 = normalize(v0);
  float d0 = dot(v01, v0);
  dist = (d0 < 0.0) ? dist : dist2;
  unitvec = (d0 < 0.0) ? unitvec : unitvec2;
  v0 = destCoord() - p1;
  dist2 = length(v0);
  unitvec2 = normalize(v0);
  d0 = dot(v01, v0);
  dist = (d0 < 0.0) ? dist2 : dist;
  unitvec = (d0 < 0.0) ? unitvec2 : unitvec;
  d0 = dist / radius;
  vec3 surfaceNormal = vec3(unitvec * d0, sqrt(1.0 - d0 * d0));
  float surfaceHeight = surfaceNormal.z * radius + levitation;
  float eta = 1.0 / indexOfRefraction;
  float c1 = surfaceNormal.z;
  float cs2 = 1.0 - eta * eta * (1.0 - c1 * c1);
  vec3 rayDirection = eta * vec3(0.0, 0.0, -1.0);
  c1 = eta * c1 - sqrt(abs(cs2));
  rayDirection += c1 * surfaceNormal;
  float t = - surfaceHeight / rayDirection.z;
  vec2 travel = t * rayDirection.xy;
  travel = max(min(travel, vec2(radius*2.0)), vec2(-radius*2.0));
  vec4 color = sample(src, samplerTransform(src, destCoord() + travel));
  color = (cs2 < 0.0) ? vec4(0.0, 0.0, 0.0, 0.0) : color;
  float alpha = clamp(radius - dist, 0.0, 1.0);
  vec4 unrefracted = sample(src, samplerCoord(src));
  return mix(unrefracted, color, alpha);
inputPoint0
inputPoint1
kernel vec4 _torusRefraction(sampler src, vec2 center, float a, float b, float c, float indexOfRefraction, float levitation)
  vec2 v0 = destCoord() - center;
  float dist = length(v0);
  vec2 unitvec = normalize(v0);
  float fdom = a * dist + b;
  float alpha = clamp((1.0 - abs(fdom)) * c, 0.0, 1.0);
  vec3 surfaceNormal = vec3(unitvec * fdom, sqrt(1.0 - fdom * fdom));
  float surfaceHeight = surfaceNormal.z * c + levitation;
  vec3 rayOrigin = vec3(destCoord(), surfaceHeight);
  float eta = 1.0 / indexOfRefraction;
  float c1 = surfaceNormal.z;
  float cs2 = 1.0 - eta * eta * (1.0 - c1 * c1);
  vec3 rayDirection = eta * vec3(0.0, 0.0, -1.0);
  c1 = eta * c1 - sqrt(abs(cs2));
  rayDirection += c1 * surfaceNormal;
  float t = - surfaceHeight / rayDirection.z;
  vec3 hitPoint = rayOrigin + t * rayDirection;
  if (alpha<0.001) hitPoint.xy = vec2(50.0); 
  vec4 color = sample(src, samplerTransform(src, hitPoint.xy));
  color = (cs2 < 0.0) ? vec4(0.0, 0.0, 0.0, 0.0) : color;
  vec4 unrefracted = sample(src, samplerCoord(src));
  return mix(unrefracted, color, alpha);
output_color_space
working_color_space
working_format
software_renderer
quality
high_quality_downsample
output_premultiplied
kCIContextCacheIntermediates
priority_request_low
disable_software_fallback
color_cube_size
share_context
default_CGImage_format
parametric_color_matching
inline_affine_matrices
kCIContextEnableBlending
kCIContextUseMetalRenderer
kCIContextAllowClampToAlpha
%s unsupported value %@ for key %@
-[CIContext setObject:forKey:]
%s unsupported for key %@
-[CIContext objectForKey:]
[CIContexts initWithEAGLContext:] can only be created with ES 2.0 or 3.0 EAGLContexts.
%s format %s is unsupported%s.
-[CIContext render:toBitmap:rowBytes:bounds:format:colorSpace:]
 in Simulator
%s unsupported colorspace.
%s rowBytes must be a multiple of %ld.
[CIContext render:toCVPixelBuffer:bounds:colorSpace:] format %s is unsupported in Simulator.
[CIContext render:toCVPixelBuffer:bounds:colorSpace:] unsupported format.
[CIContext render:toCVPixelBuffer:bounds:colorSpace:] unsupported plane count.
[CIContext render:toCVPixelBuffer:bounds:colorSpace:] unsupported colorspace.
CI_LOG_CONVERSIONS: Rendered to intermediate 444 buffer in %s because CI can not render directly to %s
-[CIContext render:toCVPixelBuffer:bounds:colorSpace:]
[CIContext render:toCVPixelBuffer:bounds:colorSpace:] could not access buffer.
[CIContext render:toCVPixelBuffer:bounds:colorSpace:] could allocate memory.
[CIContext render:toCVPixelBuffer:bounds:colorSpace:] could not access buffer.
%s cannot render an infinite image into an infinite context.
-[CIContext render:]
%s requires a CIContext created with a GL context or a CG context!
-[CIContext drawImage:inRect:fromRect:]
%s given an infinite rect
%s target must be GL_TEXTURE_2D.
-[CIContext render:toTexture:target:bounds:colorSpace:]
[CIContext render:toTexture:bounds:colorSpace] requires a GL or CL context!
[%@ flatten:fromRect:format:] was called but ignored.
<%@: %p
%@ (%d)
%@ CGContext=%p
%@ GLContext=%p
%@ bounds=[empty]
%@ bounds=[%g %g %g %g]
workingColorSpace
T^{CGColorSpace=},R,N
workingFormat
Ti,R,N
[CIContext createCGImage:fromRect:format:colorSpace:] format %s is unsupported in Simulator.
[CIContext createCGImage:fromRect:format:colorSpace:] unsupported format %s.
[CIContext createCGImage:fromRect:format:colorSpace:] unsupported colorspace.
CIContext workingformat must be kCIFormatBGRA8, kCIFormatRGBA8, kCIFormatRGBAh or nil.
 Ignoring request for %s.
 Ignoring request.
CIContext for CL: do something about disabling software fallback here.
CIContext workingformat must be kCIFormatBGRA8, kCIFormatRGBA8, kCIFormatRGBAh, kCIFormatRGBAf or nil. 
Ignoring request for %s.
Ignoring request.
_internalContext
T^{Context=^^?{Atomic={?=i}}^{CGColorSpace}^{CGColorSpace}iBBBB^{CGContext}fB{CGRect={CGPoint=dd}{CGSize=dd}}{CGAffineTransform=dddddd}iQQiB[1024{TreeCacheElement={Hash=[20C]}Q^{Kernel}}]QddB@@},R
CIContext kCIContextOutputColorSpace must be [NSNull null], or a CGColorSpaceRef with kCGColorSpaceModelRGB or kCGColorSpaceModelMonochrome that supports output.
CIContext kCIContextWorkingColorSpace must be [NSNull null], or a CGColorSpaceRef with kCGColorSpaceModelRGB that supports output.
kernel vec4 _pageCurlTransition(sampler front, sampler back, sampler emap, vec4 cyl, vec2 cyloff, vec4 fbrot, vec2 fboff, vec4 hi, vec2 hioff, float radius, vec4 emapExtent)
  vec2 backPt;
  vec2 d = destCoord();
  vec2 frontPt = backPt = vec2(dot(d,cyl.xy),dot(d,cyl.zw)) + cyloff;
  float f = frontPt.x;
  float asn = sqrt(1.0-pow(frontPt.x,1.5)) - 1.0;
  float v = frontPt.x + asn*asn*0.5625;
  frontPt.x = v;
  backPt.x = (3.141592653589793 - v);
  frontPt = vec2(dot(frontPt,fbrot.xy),dot(frontPt,fbrot.zw)) + fboff;
  backPt  = vec2(dot(backPt,fbrot.xy),dot(backPt,fbrot.zw)) + fboff;
  frontPt = (f <= 0.0) ? d : frontPt;
  vec2 highPt = vec2(dot(d,hi.xy),dot(d,hi.zw)) + hioff;
  backPt = (f <= 0.0) ? highPt : backPt;
  vec4 fs = sample(front, samplerTransform(front, frontPt));
  vec4 bs = sample(back, samplerTransform(back, backPt));
  vec2 n = clamp(f * radius * cyl.xy, -1.0, 1.0);
  vec2 bn0 = ((f < 0.0) ? vec2(0.0) : n);
  bn0 = bn0 * 0.5 + 0.5;
  bn0 = bn0 * emapExtent.zw + emapExtent.xy;
  vec4 es = sample(emap, samplerTransform(emap, bn0));
  es *= bs.a;
  bs = es + (1.0 - es.a) * bs;
  vec4 pix = bs + (1.0 - bs.a) * fs;
  pix *= clamp((1.0 - f) * radius, 0.0, 1.0);
  return pix;
kernel vec4 _pageCurlTransNoEmap(sampler front, sampler back, vec4 cyl, vec2 cyloff, vec4 fbrot, vec2 fboff, vec4 hi, vec2 hioff, float radius)
  vec2 backPt;
  vec2 d = destCoord();
  vec2 frontPt = backPt = vec2(dot(d,cyl.xy),dot(d,cyl.zw)) + cyloff;
  float f = frontPt.x;
  float asn = sqrt(1.0-pow(frontPt.x,1.5)) - 1.0;
  float v = frontPt.x + asn*asn*0.5625;
  frontPt.x = v;
  backPt.x = (3.141592653589793 - v);
  frontPt = vec2(dot(frontPt,fbrot.xy),dot(frontPt,fbrot.zw)) + fboff;
  backPt  = vec2(dot(backPt,fbrot.xy),dot(backPt,fbrot.zw)) + fboff;
  frontPt = (f <= 0.0) ? d : frontPt;
  vec2 highPt = vec2(dot(d,hi.xy),dot(d,hi.zw)) + hioff;
  backPt = (f <= 0.0) ? highPt : backPt;
  vec4 fs = sample(front, samplerTransform(front, frontPt));
  vec4 bs = sample(back, samplerTransform(back, backPt));
  vec4 pix = bs + (1.0 - bs.a) * fs;
  pix *= clamp((1.0 - f) * radius, 0.0, 1.0);
  return pix;
CISourceOverCompositing
kernel vec4 _pageCurlWithShadowTransition (sampler front, sampler back, vec4 cyl, vec2 cyloff, vec4 fbrot, vec2 fboff, vec4 hi, vec2 hioff, float radius, vec4 shadowDims, float shadowSize, float shadowAmount, vec4 sheenBright, vec4 sheenDark)
  float shadowSizeBack = 2.5;
  float pi = 3.141592653589793;
  vec2 frontPt, frontPtAlt, backPt, backPtAlt, highPt;
  vec2 d = destCoord();
  vec2 dcyl = vec2(dot(d,cyl.xy),dot(d,cyl.zw)) + cyloff;
  frontPt = frontPtAlt = dcyl;
  backPt  = backPtAlt  = dcyl;
  float f = frontPt.x;
  float asn = sqrt(1.0-pow(f,1.5)) - 1.0;
  frontPt.x = (f <= 0.0) ? f : ((f >= 1.0) ? 9999.0*f : f + asn*asn*0.5625);
  float ss = f + 0.570796326794897 * smoothstep(0.607,1.3,f);
  asn = sqrt(1.0-pow(f,1.5)) - 1.0;
  frontPtAlt.x = (f <= 0.0) ? f : ((f >= 0.9) ? ss : f + asn*asn*0.5625);
  backPt.x    = pi - frontPt.x;
  backPtAlt.x = pi - frontPtAlt.x;
  frontPt    = vec2(dot(frontPt,fbrot.xy),dot(frontPt,fbrot.zw)) + fboff;
  frontPtAlt = vec2(dot(frontPtAlt,fbrot.xy),dot(frontPtAlt,fbrot.zw)) + fboff;
  backPt     = vec2(dot(backPt,fbrot.xy),dot(backPt,fbrot.zw)) + fboff;
  backPtAlt  = vec2(dot(backPtAlt,fbrot.xy),dot(backPtAlt,fbrot.zw)) + fboff;
  frontPtAlt = mix(frontPtAlt, d, 2.0*shadowSize);
  frontPt = (f < 0.0) ? d : frontPt;
  highPt = vec2(dot(d,hi.xy),dot(d,hi.zw)) + hioff;
  backPt = (f < 0.0) ? highPt : backPt;
  backPtAlt = mix(backPtAlt, highPt, 2.0*shadowSize);
  vec4 fs = sample(front, samplerTransform(front, frontPt));
  fs *= clamp((1.0 - f) * radius, 0.0, 1.0);
  vec4 bs = sample(back, samplerTransform(back, backPt));
  bs *= clamp((1.0 - f) * radius, 0.0, 1.0);
  float sl = (f<0.0) ? 0.0 : f;
  sl = clamp(2.5 * (sl - 0.6), 0.0, 1.0);
  sl = (sl > 0.75) ? (0.4 + 15.0 * (sl - 0.82) * (sl - 0.82)) : (0.35 * sl + 0.375 * sl * sl);
  vec4 shading = mix(sheenBright, sheenDark, sl);
  shading *= bs.a;
  bs = shading + (1.0-shading.a)*bs;
  vec4 one = vec4(1.0);
  vec4 zero = vec4(0.0);
  float light = 0.0;
  float netH, rr;
  netH = mix(2.0, 0.5*shadowSizeBack, smoothstep(0.5,1.0,f));
  netH = mix(2.3, netH, fs.a);
  rr = netH * shadowSize * radius;
  vec4 pp1 = vec4(backPtAlt.xy-shadowDims.xy, shadowDims.zw-backPtAlt.xy)/rr;
  vec4 v4 = 0.5 + 0.64*pp1 - 0.14*pp1*pp1*pp1;
  v4 = compare(pp1+one, zero, v4);
  vec4 ss1 = compare(pp1-one, v4, one);
  float xx = (1.0-f)/(netH * shadowSize);
  float fv = 0.5 + 0.64*xx - 0.14*xx*xx*xx;
  fv = (xx<=-1.0) ? 0.0 : fv;
  fv = (xx>=1.0)  ? 1.0 : fv;
  light = ss1.x * ss1.y * ss1.z * ss1.w * fv;
  light = clamp(light, 0.0, 1.0);
  }  float light2;
  float netH, rr;
  netH = clamp(f*f,0.0,1.5)*0.65;
  netH = (f<0.0) ? 0.0 : netH;
  rr = netH * shadowSize * shadowSizeBack * radius;
  vec4 pp2 = vec4(frontPtAlt.xy-shadowDims.xy, shadowDims.zw-frontPtAlt.xy)/rr;
  vec4 v4 = 0.5 + 0.64*pp2 - 0.14*pp2*pp2*pp2;
  v4 = compare(pp2+one, zero, v4);
  vec4 ss2 = compare(pp2-one, v4, one);
  float xx = (1.0-f)/(shadowSize * shadowSizeBack);
  float fv = 0.5 + 0.64*xx - 0.14*xx*xx*xx;
  fv = (xx<=-1.0) ? 0.0 : fv;
  fv = (xx>=1.0)  ? 1.0 : fv;
  light2 = ss2.x * ss2.y * ss2.z * ss2.w * fv;
  light2 *= 1.0 - fs.a;
  light2 *= clamp(f*1.0, 0.0, 1.0);
  light2 = clamp(light2, 0.0, 1.0);
  if (f<0.0) light2 = 0.0;  }  light = max(light, light2);
  light = min(light, 0.5);
  vec4 shadow = vec4(0.0, 0.0,0.0, light*shadowAmount);
  vec4 pix = fs;
  pix = shadow + (1.0-shadow.a)*pix;
  pix = bs + (1.0-bs.a)*pix;
  return pix;
kernel vec4 _pageCurlNoShadowTransition (sampler front, sampler back, vec4 cyl, vec2 cyloff, vec4 fbrot, vec2 fboff, vec4 hi, vec2 hioff, float radius, vec4 sheenBright, vec4 sheenDark)
  float pi = 3.141592653589793;
  vec2 d = destCoord();
  vec2 dcyl = vec2(dot(d,cyl.xy),dot(d,cyl.zw)) + cyloff;
  vec2 frontPt = dcyl;
  vec2 backPt  = dcyl;
  float f = frontPt.x;
  float asn = sqrt(1.0-pow(f,1.5)) - 1.0;
  frontPt.x = (f <= 0.0) ? f : ((f >= 1.0) ? 9999.0*f : f + asn*asn*0.5625);
  backPt.x  = pi - frontPt.x;
  frontPt = vec2(dot(frontPt,fbrot.xy),dot(frontPt,fbrot.zw)) + fboff;
  backPt  = vec2(dot(backPt,fbrot.xy),dot(backPt,fbrot.zw)) + fboff;
  frontPt = (f < 0.0) ? d : frontPt;
  vec2 highPt = vec2(dot(d,hi.xy),dot(d,hi.zw)) + hioff;
  backPt = (f < 0.0) ? highPt : backPt;
  vec4 fs = sample(front, samplerTransform(front, frontPt));
  fs *= clamp((1.0 - f) * radius, 0.0, 1.0);
  vec4 bs = sample(back, samplerTransform(back, backPt));
  bs *= clamp((1.0 - f) * radius, 0.0, 1.0);
  float sl = (f<0.0) ? 0.0 : f;
  sl = clamp(2.5 * (sl - 0.6), 0.0, 1.0);
  sl = (sl > 0.75) ? (0.4 + 15.0 * (sl - 0.82) * (sl - 0.82)) : (0.35 * sl + 0.375 * sl * sl);
  vec4 shading = mix(sheenBright, sheenDark, sl);
  shading *= bs.a;
  bs = shading + (1.0-shading.a)*bs;
  return bs + (1.0-bs.a)*fs;
10.9
inputShadowSize
inputShadowAmount
inputShadowExtent
outputImage
CIRequiresKeyedArchiver
CoreImage requires keyed archiving.
CICS_%@
CI_%@
[CIImage] encodeWithCoder: CIUserInfo is no longer encoded for sake of security
CIName
CIVersion
CIUserInfo
[CIImage] initWithCoder: CIUserInfo is no longer decoded for sake of security
<%@: 
%@inputVersion=%@ 
%@%@=%@%c
[CIFilter apply:arguments:options] first parameter should be CIKernel.
kCIApplyOptionDefinition is not a CIFilterShape or an NSArray with four elements
kCIApplyOptionExtent is not an NSArray with four elements
regionOf:destRect:userInfo:
regionOf:destRect:
DGCurvesFilter
PXSoftProofingFilter
%s The filter PXSoftProofingFilter has an incorrect ROI method for sampler index 1.  This may fail in the future.
__36-[CIFilter apply:arguments:options:]_block_invoke
PX_CIF_Noise
%s The filter PX_CIF_Noise has an incorrect ROI method for sampler index 1.  This may fail in the future.
__36-[CIFilter apply:arguments:options:]_block_invoke_2
[%@ apply:...] First argument should be CIKernel.
[%@ apply:...] The last key "%@" at index %d is followed by nil. It will be ignored.
[%@ apply:...] Argument at index %d should be a CIImage, CISampler, CIVector, or NSNumber.
supportsSecureCoding
TB,R
T@"CIImage",R,D,N
name
T@"NSString",C,N
enabled
TB,GisEnabled,V_enabled
inputKeys
T@"NSArray",R,N
outputKeys
attributes
T@"NSDictionary",R,N
input%@
%@,%@=%@
%@,%@="%s"
%@,%@=nil
Filter %@ cannot be serialized because %@ value is a %@.  Only NSString, NSNumber and CIVector is supported at this time.
CIAffineTransform
CICrop
+[CIFilter(Private) _propertyArrayFromFilters:inputImageExtent:]
/Library/Caches/com.apple.xbs/Sources/EmbeddedCoreImage_Sim/EmbeddedCoreImage-449/Framework/api/CIFilter.mm
affineFilter != nil || cropFilter != nil
inputRectangle
warning - affine+crop region falls outside of image area, results may be wrong
http://ns.adobe.com/camera-raw-settings/1.0/
CropAngle
CropTop
CropBottom
CropLeft
CropRight
HasCrop
AlreadyApplied
http://ns.apple.com/adjustment-settings/1.0/
Filters
CIRedEyeCorrections
CIFaceBalance
CIVibrance
CIToneCurve
CIHighlightShadowAdjust
_filterArrayFromProperties: now returns nil.  Use _filterArrayFromProperties:inputImageExtent: instead
CIAttributeFilterName
CIAttributeFilterDisplayName
CIAttributeDescription
CIAttributeFilterAvailable_Mac
CIAttributeFilterAvailable_iOS
CIAttributeReferenceDocumentation
CIAttributeFilterCategories
CIAttributeClass
CIAttributeType
CIAttributeMin
CIAttributeMax
CIAttributeSliderMin
CIAttributeSliderMax
CIAttributeDefault
CIAttributeIdentity
CIAttributeName
CIAttributeDisplayName
CIUIParameterSet
CIUISetBasic
CIUISetIntermediate
CIUISetAdvanced
CIUISetDevelopment
CIAttributeTypeTime
CIAttributeTypeScalar
CIAttributeTypeDistance
CIAttributeTypeAngle
CIAttributeTypeBoolean
CIAttributeTypeInteger
CIAttributeTypeCount
CIAttributeTypePosition
CIAttributeTypeOffset
CIAttributeTypePosition3
CIAttributeTypeRectangle
CIAttributeTypeColor
CIAttributeTypeOpaqueColor
CIAttributeTypeImage
CIAttributeTypeGradient
CIAttributeTypeTransform
inputBackgroundImage
inputTime
inputTransform
inputAspectRatio
inputCenter
inputAngle
inputRefraction
inputWidth
inputSharpness
inputIntensity
inputEV
inputSaturation
inputBrightness
inputContrast
inputGradientImage
inputBias
inputWeights
inputMaskImage
inputShadingImage
inputTargetImage
__inputVersion
CICategoryDistortionEffect
CICategoryGeometryAdjustment
CICategoryCompositeOperation
CICategoryLightingEffect
CICategoryHalftoneEffect
CICategoryColorAdjustment
CICategoryColorEffect
CICategoryTransition
CICategoryTileEffect
CICategoryGenerator
CICategoryGradient
CICategoryStylize
CICategorySharpen
CICategoryBlur
CICategoryVideo
CICategoryStillImage
CICategoryInterlaced
CICategoryNonSquarePixels
CICategoryHighDynamicRange
CICategoryApplePrivate
CICategoryReduction
CICategoryBuiltIn
CICategoryFilterGenerator
CICategoryXMPSerializable
extent
definition
user_info
color_space
cs_deviceGray
cs_deviceRGB
cs_deviceCMYK
{CGAffineTransform=dddddd}
kernel vec4 _parallelogramTile (sampler src, vec2 center, vec2 ftransx, vec2 ftransy, vec2 btransx, vec2 btransy)
  vec2 t2;
  vec2 t1 = destCoord() - center;
  t2.x = dot(t1, ftransx);
  t2.y = dot(t1, ftransy);
  t2 = fract(t2);
  t2 = min(t2, vec2(1.0) - t2);
  t2 = t2 + t2;
  t1.x = dot(t2, btransx);
  t1.y = dot(t2, btransy);
  return sample(src, samplerTransform(src, t1 + center));
inputAcuteAngle
kernel vec4 _motionBlur (sampler src, vec4 parms)
  vec2 delta = parms.xy;
  vec2 delt2 = delta * 2.0;
  vec2 p0 = samplerTransform (src, destCoord() - delt2);
  vec2 p1 = samplerTransform (src, destCoord() - delta);
  vec2 p3 = samplerTransform (src, destCoord() + delta);
  vec2 p4 = samplerTransform (src, destCoord() + delt2);
  vec4 s0 = sample (src, p0);
  vec4 s1 = sample (src, p1);
  vec4 s2 = sample (src, samplerCoord(src));
  vec4 s3 = sample (src, p3);
  vec4 s4 = sample (src, p4);
  vec2 w = parms.zw;
  return w.x * s2 + w.y * (s3 + s1 + (w.y * (s4 + s0)));
T@"NSNumber",&,N,VinputAngle
inputAmount
kernel vec4 _zoomBlur (sampler src, vec2 center, vec4 parms, vec4 w0, float w1)
  vec2 v = destCoord() - center;
  vec4 s0 = sample (src, samplerCoord (src));
  vec4 s1 = sample (src, samplerTransform (src, v * parms.x + center));
  vec4 s2 = sample (src, samplerTransform (src, v * parms.y + center));
  vec4 s3 = sample (src, samplerTransform (src, v * parms.z + center));
  vec4 s4 = sample (src, samplerTransform (src, v * parms.w + center));
  return s4*w0.x + s3*w0.y + s2*w0.z + s1*w0.w + s0*w1;
T@"CIVector",&,N,VinputCenter
T@"NSNumber",&,N,VinputAmount
CIImageFlipped
CIImagePremultiplied
opaque
CIImageColorSpace
CIImageEdgesAreClear
CIImageProperties
CIImageClampToEdge
CIImageNearestSampling
CIImageEdgeRepeat
kCIImageAlphaOne
kCIImageCacheHint
kCIImageCacheImmediately
kCIImageYCCMatrix
kCIImageTextureTarget
kCIImageTextureFormat
ignorePixelFormatFor601Fixup
[CIImage initWithIOSurface:options:] failed because surface format was %.4s.
[CIImage initWithIOSurface:options:] failed because surface format was %ld.
[CIImage initWithIOSurface:options:] kCIImageSurfaceFormat option value is not compatable with actual format of surface..
CIImage kCIImageEdgeRepeat not supported.
/tmp
%s/%s_%u.%s
tiff
public.tiff
wrote input CG image %p to file %@
Unable to write CG image %p to file %@
[CIImage initWithCGImage:options] failed because the CGImage is nil
CIImage
CI_LOG_CONVERSIONS: Rendered to intermediate ABGR8 CGImage in %s because CI can not directly support a %s CGImage.
-[CIImage initWithCGImage:options:]
[CIImage initWithCGImage:options] failed because the CGImage format is not supported and we failed to create a CGBitmapContext
v56@?0^v8Q16Q24Q32Q40Q48
[CIImage initWithBitmapData:] failed because the format '%s' is not supported.
[CIImage initWithBitmapData:] failed because the format is not supported.
[CIImage initWithBitmapData:] failed because data length was less than height times bytesPerRow.
v24@?0^v8Q16
[CIImage initWithCVPixelBuffer:optiopns:] failed because it is not a CVPixelBuffer.
v64@?0^v8Q16Q24Q32Q40Q48Q56
[CIImage initWithCVPixelBuffer:options:] failed because the buffer is nil.
[CIImage initWithCVPixelBuffer:options:] failed because the buffer is not a CVPixelBufferRef.
[CIImage initWithCVPixelBuffer:options:] failed because its pixel format %.4s is not supported.
[CIImage initWithCVPixelBuffer:options:] failed because its pixel format %ld is not supported.
[CIImage initWithCVImageBuffer:options:] failed because the buffer is nil.
[CIImage initWithCVImageBuffer:options]failed because the type of buffer is not yet supported.
CIGaussianBlur
ColorSpace must be an RGB CGColorSpaceRef that supports output.
ColorSpace must be an RGB CGColorSpaceRef
ColorSpace must be an RGB CGColorSpaceRef.
%s properties is not a NSDictionary.
-[CIImage imageBySettingProperties:]
%s object at index %d of array is not a CIImage.
-[CIImage initWithArrayOfImages:selector:]
<CIImage: %p extent [infinite]>
<CIImage: %p extent [empty]>
<CIImage: %p extent [%g %g %g %g]>
<CIImage: %p extent [infinite]>
<CIImage: %p extent [empty]>
<CIImage: %p extent [%g %g %g %g]>
CoreImage doesn't support old-style archiving
CIImageEncoder
CoreImage doesn't support archiving infinite images.
<CIImage: %p> printTree:
%s not supported for keypath %@
-[CIImage setValue:forKeyPath:]
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N
properties
T@"NSDictionary",R
T@"CIFilterShape",R
T@"NSURL",R
colorSpace
T^{CGColorSpace=},R
pixelBuffer
T^{__CVBuffer=},R,N
CGImage
T^{CGImage=},R,N
CIImageSurfaceFormat
shape=rounded, color="#CCCCFF"
shape=rect, color="#FFCCCC"
tagcolorspace 
tagcolorspace<BR/>
CICGImageData
CICGImageWidth
CICGImageHeight
CICGImageBPC
CICGImageBPP
CICGImageBPR
CICGImageAlphaInfo
CICGImageInterp
CICGImageRI
CIKernelMessageType
CIKernelMessageTypeNote
CIKernelMessageTypeRemark
CIKernelMessageTypeWarning
CIKernelMessageTypeError
CIKernelMessageTypeFatal
CIKernelMessageFilename
CIKernelMessageLineNumber
kCIKernelMessageOffset
kCIKernelMessageDescription
kCIKernelMessageTypeSyntaxError
kCIKernelMessageTypeInternalError
kCIKernelMessageTypeFunctionName
kCIKernelOutputFormat
<%@: %s>
vec4  compare (vec4 x, vec4 y, vec4 z)    { return mix(y, z, step(0.0,x)); }
vec3  compare (vec3 x, vec3 y, vec3 z)    { return mix(y, z, step(0.0,x)); }
vec2  compare (vec2 x, vec2 y, vec2 z)    { return mix(y, z, step(0.0,x)); }
float compare (float x, float y, float z) { return x < 0.0 ? y : z; }
vec4  cos_ (vec4 x)  { return cos(x); }
vec3  cos_ (vec3 x)  { return cos(x); }
vec2  cos_ (vec2 x)  { return cos(x); }
float cos_ (float x) { return cos(x); }
vec4  sin_ (vec4 x)  { return sin(x); }
vec3  sin_ (vec3 x)  { return sin(x); }
vec2  sin_ (vec2 x)  { return sin(x); }
float sin_ (float x) { return sin(x); }
vec4  tan_ (vec4 x)  { return tan(x); }
vec3  tan_ (vec3 x)  { return tan(x); }
vec2  tan_ (vec2 x)  { return tan(x); }
float tan_ (float x) { return tan(x); }
vec2 cossin (float x)
    return vec2(cos(x), sin(x));
vec2 cossin_ (float x)
    return vec2(cos_(x), sin_(x));
vec2 sincos (float x)
    return vec2(sin(x), cos(x));
vec2 sincos_ (float x)
    return vec2(sin_(x), cos_(x));
vec4 premultiply (vec4 s)
    return vec4(s.rgb*s.a, s.a);
vec4 unpremultiply (vec4 s)
    return vec4(s.rgb/max(s.a,0.00001), s.a);
vec3 srgb_to_linear (vec3 s)
    return sign(s)*mix(abs(s)*0.077399380804954, pow(abs(s)*0.947867298578199 + 0.052132701421801, vec3(2.4)), step(0.04045, abs(s)));
vec4 srgb_to_linear (vec4 s)
    s = unpremultiply(s);
    s.rgb = sign(s.rgb)*mix(abs(s.rgb)*0.077399380804954, pow(abs(s.rgb)*0.947867298578199 + 0.052132701421801, vec3(2.4)), step(0.04045, abs(s.rgb)));
    return premultiply(s);
vec3 linear_to_srgb (vec3 s)
    return sign(s)*mix(abs(s)*12.92, pow(abs(s), vec3(0.4166667)) * 1.055 - 0.055, step(0.0031308, abs(s)));
vec4 linear_to_srgb (vec4 s)
    s = unpremultiply(s);
    s.rgb = sign(s.rgb)*mix(abs(s.rgb)*12.92, pow(abs(s.rgb), vec3(0.4166667)) * 1.055 - 0.055, step(0.0031308, abs(s.rgb)));
    return premultiply(s);
#ifndef _sampleImage
#define _sampleImage(s, p) linear_to_srgb(srgb_to_linear(vec4(0.0)))
#endif
#ifndef _samplerTransform
#define _samplerTransform(s, p) p
#endif
#ifndef _samplerExtent
#define _samplerExtent(s) vec4(0.0)
#endif
#ifndef sampler
#define sampler int
#endif
vec2 destCoord ()
    return _dc;
vec4 sampleImage (sampler src, vec2 point)
    return _sampleImage(src, point);
vec4 sampleImage (sampler2D src, vec2 point)
    return _sampleImage(src, point);
vec2 samplerTransform (sampler src, vec2 point)
    return _samplerTransform(src, point);
vec2 samplerTransform (sampler2D src, vec2 point)
    return _samplerTransform(src, point);
#define samplerCoord(src) samplerTransform(src, destCoord())
vec4 samplerExtent (sampler src)
    return _samplerExtent(src);
vec4 samplerExtent (sampler2D src)
    return _samplerExtent(src);
#define samplerOrigin(src) samplerExtent(src).xy
#define samplerSize(src) samplerExtent(src).zw
vec4 sampleImage (vec4 src, vec2 point) { return src; }
vec2 samplerTransform (vec4 src, vec2 point) { return point; }
void writeImage (vec4 color, vec2 point) {}
void writeImagePlane (vec4 color, vec2 point) {}
void writePixel (int r, int g, int b, int a, vec2 point) {}
vec2 writeCoord () { return vec2(0.0); }
#define new _new
#define delete _delete
#define and _and
#define not _not
#define or _or
#define xor _xor
#define sample(s, p) sampleImage(s, p)
[%@ initWithString:] failed due to error parsing kernel source.
[%@ initWithString:] failed because no valid kernels were in the string.
[%@ initWithString:] failed because '%s', the first kernel in the string, does not conform to supported calling convensions.
[CIWarpKernel initWithString:] failed because '%s', the first kernel in the string, does not conform to the calling convensions of a CIWarpKernel.
[CIColorKernel initWithString:] failed because '%s', the first kernel in the string, does not conform to the calling convensions of a CIColorKernel.
[CIKernel initWithString:] failed because '%s', the first kernel in the string, does not conform to supported calling convensions.
[%@ initWithString:] failed because '%s', the first kernel in the string, has an unsupported type for the parameter '%s'.
[CIKernel kernelsWithString:] passed an empty or nil string.
[%@ kernelsWithString:] kernel '%s' failed because it does not conform to supported calling convensions.
[%@ kernelsWithString:] kernel '%s' failed because it has an unsupported type for the parameter '%s'.
outputFormat
%@ is not an acceptable output format name; will use working space format.
Unable to find a pixel format for %@; likely not the correct name.
%s, kCIKernelOutputFormat value (%s) is not supported.
-[CIKernel _isValidOutputPixelFormat:]
Use one of these formats instead: 
kCIFormat
Warning: specifying output format as kernel attribute to be %s and apply as %s; using former.
CI internal error, argument count mismatch for kernel '%s', expected %d but saw %d.
CI internal error, no image argument in kernel parameters
_arg%d
CISampler
NSNumber
CIVector
CIVectorSize
CIColor
T@"NSString",R
Note: CIColorKernel applyWithExtent:roiCallback:arguments:options: ignores callback and is not recomended.  Use applyWithExtent:arguments:options: instead.
Note: CIColorKernel applyWithExtent:roiCallback:arguments: ignores callback and is not recomended.  Use applyWithExtent:arguments: instead.
perservesAlpha
TB,N
CIWarpKernel applyWithExtent:roiCallback:arguments:options: is not supported.  Use applyWithExtent:roiCallback:inputImage:arguments:options: instead.
CIWarpKernel applyWithExtent:roiCallback:arguments: is not supported.  Use applyWithExtent:roiCallback:inputImage:arguments: instead.
{%g,%g %g x %g}
provided rect for kernel %s is %@ but should be at least %@
[CIKernelPool] 
note: 
remark: 
WARNING: 
ERROR: 
FATAL ERROR: 
kernel_name
kernel_gl_source
kernel_argument_types
kernel_argument_names
kernel_attributes
kernel_explicit_attributes
CI internal error, type mismatch for kernel '%s' parameter %d. Expected CIImage or CISampler. Got %@.
CI internal error, type mismatch for kernel '%s' parameter %d. Expected CIImage. Got %@.
CI internal error, type mismatch for kernel '%s' parameter %d. Expected a leaf CIImage.
CI internal error, type mismatch for kernel '%s' parameter %d. Expected NSNumber or a CIVector of count 1. Got CIVector of count %ld.
CI internal error, type mismatch for kernel '%s' parameter %d. Expected NSNumber or a CIVector of count 1. Got %@.
CI internal error, type mismatch for kernel '%s' parameter %d. Expected CIVector of count 2 or more. Got CIVector of count %ld.
CI internal error, type mismatch for kernel '%s' parameter %d. Expected CIVector of count 2 or more. Got %@.
CI internal error, type mismatch for kernel '%s' parameter %d. Expected CIVector of count 3 or more. Got CIVector of count %ld.
CI internal error, type mismatch for kernel '%s' parameter %d. Expected CIVector of count 3 or more. Got %@.
CI internal error, type mismatch for kernel '%s' parameter %d. Expected CIVector of count 3 or 4. Got CIVector of count %ld.
CI internal error, type mismatch for kernel '%s' parameter %d. Expected CIVector of count 3 or 4. Got %@.
CI internal error, type mismatch for kernel '%s' parameter %d. Expected CIColor or CIVector. Got %@.
CI internal error, type mismatch for kernel '%s' parameter %d.
Unexpected float input
kernel vec4 _lenticularHalo(sampler noise, vec2 center, vec2 sourcecenter, float noiseRadius, float haloThicknessRecip, float a, float b, vec3 rgbdist, __color color)
  vec2 v = destCoord() - center;
  vec3 rgbfunc = clamp((length(v) - rgbdist) * haloThicknessRecip, 0.0, 1.0);
  rgbfunc = 2.0 * min(rgbfunc, 1.0 - rgbfunc);
  rgbfunc = (3.0 - 2.0 * rgbfunc) * rgbfunc * rgbfunc;
  vec2 noiseloc = normalize(v) * noiseRadius + sourcecenter;
  vec4 npix = sample(noise, samplerTransform(noise, noiseloc));
  vec3 color3 = (npix.r * a + b) * rgbfunc * color.rgb;
  return vec4(color3, max(max(color3.r, color3.g), color3.b));
inputHaloRadius
inputHaloWidth
inputHaloOverlap
inputStriationStrength
inputStriationContrast
CILenticularHaloGenerator only has one input
AffineImage
ApplyImage
ClampToAlphaImage
ColorMatchImage
ColorMatrixImage
CropImage
ClampImage
FillImage
GammaImage
SRGBImage
NoopImage
PremultiplyImage
ProcessorImage
PromiseImage
ProviderImage
SampleModeImage
SetPropsImage
SurfaceImage
SwitchImage
SwizzleImage
TagColorSpaceImage
TextueImage
AffineNode
ApplyNode
CGNode
ClampToAlphaNode
ColorMatrixNode
CropNode
DivNode
ClampNode
GammaNode
CurveNode
FillNode
NoopNode
PremultiplyNode
ProcessorNode
PromiseNode
ProviderNode
SRGBNode
SampleModeNode
SurfaceNode
SwizzleNode
TextureNode
ProgramNode
Bitmap
Vector
Color
TextureSampler
ColorKernel
WarpKernel
GeneralKernel
ComputeKernel
MainProgram
MetalDAG
CLContext
GLContext
MetalContext
SurfaceCacheEntry
Unknown enum %d
Unknown
<CI::Object %s %p>
Type %s : %d
[infinite]
[null]
[empty]
[%g %g %g %g]
.png
.jpg
B32@?0^{GraphObject=^^?{Atomic={?=i}}}8^{GraphObject=^^?{Atomic={?=i}}}16i24i28
%.*sNULL
%.*s
<%ld>
 <%ld>
%s/%d_%s.dot
 failed to write.
digraph CI {
edge [dir=back]
n0x0 [label="%s" style=filled shape=rect, color="#CCFFFF"];
%s/%d_%s_%u.png
n%p [
style=filled, %s, 
label=
<<TABLE border="0" cellborder="0">
<TR><TD>
<IMG SRC="%s"/>
</TD></TR>
<IMG SRC="%s/%d_intermediate_%d_0.png"/>
<TR><TD balign="left">
</TABLE>>];
n%p -> n%p;
write_image_for_graphviz_queue
waiting for graphviz output to complete...
IOSurface %p %s %ldx%ld
IOSurface %p<BR/>
%s %ldx%ld<BR/>
CI_LOG_CONVERSIONS: Converting input surface %p to a new surface with required rowbytes alignment (of %d bytes).
 rois=
 extent=
 opaque
{%d}<BR/>
<BR/>rois=
<BR/>extent=
<BR/>opaque
<BR/>digest=%llX
crop 
singular matrix cannot be inverted
shape=rect, color="#FF9999"
crop
colorkernel
warpkernel
kernel
computekernel
mainprogram
metaldag
unknownkernel
=nil
colorkernel%s
warpkernel%s
kernel%s
computekernel%s
metaldag%s
unknownkernel%s
%s%s
shape=rect color="#FFCCCC"
shape=rect color="#FF9999"
shape=rect, color="#CCFFCC"
shape=component, color="#CCCCCC"
<CI::%s %p, %s>
tile_size
kCIImageProviderContentDigest
provideImageData:bytesPerRow:origin::size::userInfo:
%s provider does not implement provideImageData:bytesPerRow:origin::size::userInfo:.
-[CIImage(CIImageProvider) initWithImageProvider:size::format:colorSpace:options:]
provideImageTexture:bounds:userInfo:
CIImageProvider <%s %p> %zux%zu at %zu,%zu
%s format is not supported.
-[CIImage(CIImageProvider) _initWithImageProvider:width:height:format:colorSpace:surfaceCache:options:]
%s format %s is not supported.
%s kCIImageProviderTileSize value is not a NSNumber, NSArray, CIVector, or NSNull.
%s kCIImageProviderContentDigest value is not NSData of at least 32 bytes.
shape=rect, color="#CCCCCC"
samplemode %s
point
nearest
linear
unknown
affine 
affine<BR/>
%g  %g  %g<BR/>
[%g %g %g %g %g %g]
 outputFormat=%s
colorkernel<BR/>
warpkernel<BR/>
kernel<BR/>
computekernel<BR/>
unknownkernel<BR/>
%s<BR/>
outputFormat=%s<BR/>
CGImageRef %p %s %ldx%ld 
CGImageRef %p<BR/>
nearestsampling 
cache 
processor %s
:%llX
processor<BR/>%s
shape=hexagon, color="#999999"
kernel vec4 _softCubicUpsample (sampler src, vec4 scale) 
  vec2 d = scale.xy * destCoord() - 0.5; 
  vec2 c = floor(d); 
  vec2 x = (c - d + 1.0); 
  vec2 X = (d - c); 
  vec2 w1 = (-1.0/3.0)*x*x*x + 0.5*x*x + 0.5*x + 1.0/6.0; 
  vec2 w2 = 1.0 - w1; 
  vec2 o1 = -0.2*x*x + c + 0.5; 
  vec2 o2 =  0.2*X*X + c + 1.5; 
  vec4 r; 
  r  = w1.x * w1.y * sample(src, samplerTransform(src, vec2(o1.x,o1.y))); 
  r += w2.x * w1.y * sample(src, samplerTransform(src, vec2(o2.x,o1.y))); 
  r += w1.x * w2.y * sample(src, samplerTransform(src, vec2(o1.x,o2.y))); 
  r += w2.x * w2.y * sample(src, samplerTransform(src, vec2(o2.x,o2.y))); 
  return r; 
IOSurface %p %s
 roi=
<BR/>roi=
com.apple.coreimage.regionOfInterestForImage
renderbuffer
texture
none
UNKNOWN
fbo = %d, attachment type = %s, id = %d
 level = %d, internal format = 0x%x, width = %d, height = %d
 internal format = 0x%x, width = %d, height = %d
%llX(%04x,%04x,%04x)
Cannot handle a (%lu x %lu) sized texture with the given GLES context!
CIEAGLContextTexImageIOSurface failed for %s!
GLTextureManager::attach_IOSurface unsupported format %s!
GL_APPLE_client_storage
GL_APPLE_texture_ycbcr_basic_formats
GL_APPLE_texture_ycbcr_extended_formats
GL_EXT_color_buffer_half_float
GL_EXT_shader_texture_lod
GL_OES_texture_half_float
GL_OES_texture_float
GL_EXT_sRGB
GL_APPLE_texture_xr
finish_render
link_shaders
Program exceeds GLES%d uniform limits.
position
texcoord
quad
GLContext::set_surface_destination unsupported format %s!
Destination buffer size too large (%lu x %lu); cannot be larger than %d x %d.
Using low GPU priority for background rendering.
readback_bitmap
Unhandled type: %d
compile_kernel
compile_shader
CI_SUBDIVIDE_QUADS
CI_LIMIT_GL_RENDER
opengles2
opengles3
opengles?
CI_PRINT_TIME %s = %.6f seconds
metal
v16@?0r^{__IOSurface=}8
sync_render_completion
render
B12@?0i8
CI::RenderCompletionQueue
/%s/%d_intermediate_%d_%zu.png
Dumped intermediate to: %s
kernel vec4 _tiltShift(sampler image,sampler blurM,sampler blurL,vec2 p0,vec2 p1,vec2 sizes)
  vec2 pt       = samplerCoord(image);
  vec4 col0     = sample(image, pt);
  vec4 colMed   = sample(blurM, samplerCoord(blurM));
  vec4 colLarge = sample(blurL, samplerCoord(blurL));
  float denom = (p1.x-p0.x)*(p1.x-p0.x) + (p1.y-p0.y)*(p1.y-p0.y);
  float s =  ((p0.y-pt.y)*(p1.x-p0.x)-(p0.x-pt.x)*(p1.y-p0.y) ) / denom;
  float dist = abs(s)*sqrt(denom) / sizes.y;
  dist *= 2.0;
  float w0 = smoothstep(0.0, 1.0,  1.0 - 2.0*dist);
  float wL = smoothstep(0.0, 1.0, -1.0 + 2.0*dist);
  float wM = 1.0 - (w0 + wL);
  return w0*col0 + wM*colMed + wL*colLarge;
kernel vec4 _distanceColored(sampler image,vec2 p0,vec2 p1)
  vec2 pt = samplerCoord(image);
  float denom = (p1.x-p0.x)*(p1.x-p0.x) + (p1.y-p0.y)*(p1.y-p0.y);
  float s =  ((p0.y-pt.y)*(p1.x-p0.x)-(p0.x-pt.x)*(p1.y-p0.y) ) / denom;
  float dist = abs(s)*sqrt(denom) / samplerSize(image).y;
  dist *= 2.0;
  float val = dist;
  return vec4(val,val,val,1.0);
kernel vec4 _alphaNormalize(__sample image)
  vec4 col = image;
  col.rgb /= col.a;
  col.a = 1.0;
  return col;
CIColorControls
CIUnsharpMask
CIDiscBlur
10.6
inputUnsharpMaskRadius
inputUnsharpMaskIntensity
The message is too long for a Code128 barcode.
The message contains non-7bit ascii characters.
Could not allocate memory for image.
v24@?0i8B12r*16
com.apple.code128
StartC
StartA
StartB
Code C
Code B
Code A
Check
Stop
image
image_chroma
float
vec2
vec3
vec4
mat3
mat4
table
sampler_index
sampler_transform
sampler_transform_and_extent
sampler_transform_row0
sampler_transform_row1
vertex_transform
vertex_transform_row0
vertex_transform_row1
set_roi_selector queue
fill 
clear
shape=oval, color="#CCCCFF"
[CIAffineTransform inputTransfom] is not a valid object.
AffineA
AffineB
AffineC
AffineD
AffineX
AffineY
T@"NSValue",&,N,VinputTransform
CropX
CropY
CropW
CropH
T@"CIVector",&,N,VinputRectangle
CI_PRINT_TIME new bitmap (%ldx%ld) = %.3f seconds
affine
%s requires an image with a finite non-empty extent.
-[CIContext(ImageRepresentation) TIFFRepresentationOfImage:format:colorSpace:options:]
-[CIContext(ImageRepresentation) JPEGRepresentationOfImage:colorSpace:options:]
-[CIContext(ImageRepresentation) writeTIFFRepresentationOfImage:toURL:format:colorSpace:options:error:]
-[CIContext(ImageRepresentation) writeJPEGRepresentationOfImage:toURL:colorSpace:options:error:]
CGImageRef %p %s %ldx%ld
CGImageRef %d
Could not create IOSurface in ioSurfaceFromCGImage failed
kCGImageBlockTileRequest
Failed to access image block data.
LA16
RG16
RGB8
RGB16
RGBh
RGBf
BGRA8
RGBA8
ARGB8
ABGR8
BGRX8
RGBX8
XRGB8
XBGR8
YCC420f
YCC420v
YCC444f601
YCC444f709
YCC444v601
YCC444v709
YCC420f601
YCC420f709
YCC420v601
YCC420v709
RGBA16
ARGB16
RGBA16-Unorm
RGBAh
RGBAf
ARGBf
A2BGR10
A2RGB10
RGB10A2-WideGamut
RGBA14
RGBA14v0
CbYCrY8
CbYCrY8f
YCbYCr8
YCbYCr8f
CbYCrY_RGB8
YCbYCr_RGB8
unknown-format
need a %s swizzler so that %s can be read as %s
kSwizzleBGRAtoRRGG1
kPixelFormatRG16
kPixelFormatBGRA8
kSwizzleBGRAtoLLAA
kPixelFormatLA16
kSwizzleGBAR
kPixelFormatARGB8
kPixelFormatRGBA8
kSwizzleAGBR
kPixelFormatABGR8
kSwizzleGBA1
kPixelFormatXRGB8
kSwizzleAGB1
kPixelFormatXBGR8
kSwizzleRGB14
kPixelFormatRGBA14
kPixelFormatRGBA16
kSwizzleRGB14v0
kPixelFormatRGBA14v0
need a swizzler so that %s can be read.
kSwizzleToA16asRG8
kPixelFormatA16
kPixelFormatRG8
kSwizzleToRGB14
kSwizzleToRGB14v0
need a swizzler so that %s can be written.
swizzle_identity
swizzle_bgra
swizzle_abgr
swizzle_argb
swizzle_gbra
swizzle_grab
swizzle_gbar
swizzle_rgb1
swizzle_bgr1
swizzle_arg1
swizzle_gra1
swizzle_1bgr
swizzle_1rgb
swizzle_aaaa
swizzle_rrrr
swizzle_000r
swizzle_rrr1
swizzle_r001
swizzle_a001
swizzle_rg01
swizzle_ra01
swizzle_aaa1
swizzle_rrrg
swizzle_rg_to_rr1
swizzle_rg_to_ll1
swizzle_rg_to_a
swizzle_rg_to_i
swizzle_rg_to_cbycry
swizzle_rg_to_ycbycr
swizzle_la_to_rr1
swizzle_la_to_ll1
swizzle_la_to_a
swizzle_la_to_i
swizzle_rgba_to_rrgg1
swizzle_rgba_to_llaa
swizzle_to_r16_as_rg8
swizzle_to_l16_as_rg8
swizzle_to_rg16_as_rgba8
swizzle_to_rg16_as_bgra8
swizzle_to_la16_as_rgba8
swizzle_to_la16_as_bgra8
swizzle_to_YCbYCr_as_rg8
swizzle_to_CbYCrY_as_rg8
swizzle_to_rgb_as_r
swizzle_to_a2bgr10_as_rgba8
swizzle_to_a2rgb10_as_rgba8
swizzle_to_rgb10_wide_as_rgba8
swizzle_to_420
swizzle_ycc_to_rgb
swizzle_to_laaa
swizzle_rgb10_wide
swizzle_bgr10_wide
swizzle_to_rgb10_wide
swizzle_to_bgr10_wide
swizzle_rgba16_normalize
swizzle_to_rg_as_rgba
swizzle_to_la_as_rgba
unknown-swizzle
kernel vec4 _sepia (__sample s, float amount)
  vec4  color = vec4(1.0, 0.99, 0.92, 1.0);
  vec4  c0 = vec4(0.895663e-3, -0.1104567e-2, -0.60827e-3, 0.32774281e-1);
  vec4  c1 = vec4(3.1166719, 0.79263718, 0.32196859e-1, 1.4118470);
  vec4  c2 = vec4(-50.933413, 0.46548312, 1.0275550, -.90690876);
  vec4  c3 = vec4(708.79386, -0.39031064, -0.58540133e-1, 0.66210230);
  vec4  c4 = vec4(-3605.9836, 0.13231560, 0.0, -0.19916155);
  float l  = dot(s.rgb, vec3(.2125, .7154, .0721));
  float la = l / max(0.0001, s.a);
  vec4  t  = c0*s.a + (c1 + (c2 + (c3 + c4*la)*la)*la)*l;
        t.r = (l < 0.085*s.a)  ?  t.r  :  t.a;
  vec3  r = (l*l-l < 0.0)  ?  t.rgb  :  vec3(l,l,l);
  return mix(s,vec4(r, s.a)*color, amount);
T@"NSNumber",&,N,VinputIntensity
10.7
abortable
[CIImageAccumulator initWithExtent:format:] failed because the extent is empty.
[CIImageAccumulator initWithExtent:format:] failed because the format '%s' is not supported.
[CIImageAccumulator initWithExtent:format:] failed because the format is not supported.
CIImageImageAccumulator
[CIImageAccumulator initWithExtent:format:] failed.
<CIImageAccumulator: %p extent [%g %g %g %g] format %s>
T{CGRect={CGPoint=dd}{CGSize=dd}},R
format
Ti,R
kernel vec4 _clearer() { return vec4(0.0); }
[%g]
[%g %g]
[%g %g %g]
[%g %g %g %g
CICount
CI_%zu
count
TQ,R
Td,R
CGPointValue
T{CGPoint=dd},R
CGRectValue
CGAffineTransformValue
T{CGAffineTransform=dddddd},R
stringRepresentation
_values
T^d,R
CIColorMatrix
inputRVector
inputGVector
inputBVector
inputAVector
inputBiasVector
T@"NSNumber",&,N,VinputEV
render_to_display
render_to_texture
render:toIOSurface: failed because format was %.4s.
render:toIOSurface: failed because format was %ld.
render_to_surface
get_bitmap
v48@?0^{Node=^^?{Atomic={?=i}}I{SerialRectArray=ii^{CGRect}}Q{Hash=[20C]}{Hash=[20C]}B}8{CGRect={CGPoint=dd}{CGSize=dd}}16
Failed to render %llu pixels 
Failed to render %llu of %llu pixels 
because a CIKernel's ROI function did not allow tiling.
CI_PRINT_TIME %s (%s%s context %d frame %lu) (%llux%llu) = %.3f seconds%s
 (aborted)
create_cgimage
Could not access surface.
CI_PRINT_TIME %s (%s%s context %d frame %lu) (%llux%llu) = %.3f seconds
initial graph\n%s\n(%s%s context %d frame %lu)\nformat=%s roi=[%g %g %g %g]
 lowp
initial_graph_%d_%lu
initial graph graphviz %s (%s%s context %d frame %lu) format=%s roi=
initial graph %s (%s%s context %d frame %lu) format=%s roi=
v32@?0^{GraphObject=^^?{Atomic={?=i}}}8^{GraphObject=^^?{Atomic={?=i}}}16i24i28
optimized graph\n%s\n(%s%s context %d frame %lu)\nformat=%s roi=[%g %g %g %g]
optimized_graph_%d_%lu
optimized graph graphviz %s (%s%s context %d frame %lu) format=%s roi=
optimized graph %s (%s%s context %d frame %lu) format=%s roi=
timing graph\n%s\n(%s%s context %d frame %lu tile %lu)\nformat=%s roi=[%g %g %g %g]
timing_graph_%d_%lu_%lu
timing graph graphviz %s (%s%s context %d frame %lu tile %lu) format=%s roi=
timing graph %s (%s%s context %d frame %lu tile %lu) format=%s roi=
destination %dx%d too big
input %d too big
intermediate %d too big
memory requirement of %d too big
tile graph roi\n%s\n(%s%s context %d frame %lu tile %lu)\nformat=%s roi=[%g %g %g %g]
tile_graph_%d_%lu_%lu
tile graph graphviz %s (%s%s context %d frame %lu tile %lu) format=%s roi=
tile graph %s (%s%s context %d frame %lu tile %lu) format=%s roi=
programs graph\n%s\n(%s%s context %d frame %lu tile %lu)\nformat=%s roi=[%g %g %g %g]
programs_graph_%d_%lu_%lu
programs graph graphviz %s (%s%s context %d frame %lu tile %lu) format=%s roi=
programs graph %s (%s%s context %d frame %lu tile %lu) format=%s roi=
Cannot create a CGImageProvider for %s
kCGImageProviderPrefersBandedDecoding
kCGImageProviderPreferedBandHeight
failed mprotect
fill
kernel vec4 _displaceFromImage (sampler src, sampler image, float k)
  vec2 dc = destCoord(); 
  float E = sample(image, samplerTransform(image,dc+vec2(1.0,0.0))).r; 
  float S = sample(image, samplerTransform(image,dc+vec2(0.0,-1.0))).r; 
  float C = sample(image, samplerTransform(image,dc)).r; 
  return sample(src, samplerTransform(src, dc + k * vec2(E-C, S-C)));
T@"NSNumber",&,N,VinputSaturation
T@"NSNumber",&,N,VinputBrightness
T@"NSNumber",&,N,VinputContrast
<CI::Vector %p>[]
<CI::Vector %p>[%g]
<CI::Vector %p>[%g %g]
<CI::Vector %p>[%g %g %g]
<CI::Vector %p>[%g %g %g %g]
<CI::Vector %p>[%d values]
%c%g
CIColumnAverage
kernel vec4 _reduceCrop (sampler image)
  vec4 p = sample(image, samplerTransform(image, vec2(0.5, 0.5)));
  vec2 d = abs(destCoord() - 0.5);
  return max(d.x, d.y) < 0.5  ?  p  :  vec4(0.0);
kernel vec4 _areaMax4(sampler image, vec2 bound)
  vec2  d  = 2.0*destCoord();
  vec4 p0 = sample(image, samplerTransform(image, d + vec2(-0.5,-0.5)));
  vec4 p1 = sample(image, samplerTransform(image, d + vec2(+0.5,-0.5)));
  vec4 p2 = sample(image, samplerTransform(image, d + vec2(-0.5,+0.5)));
  vec4 p3 = sample(image, samplerTransform(image, d + vec2(+0.5,+0.5)));
  p0 = (d.x+0.5 < bound.x)  ?  max(p0, p1)  :  p0;
  p2 = (d.x+0.5 < bound.x)  ?  max(p2, p3)  :  p2;
  p0 = (d.y+0.5 < bound.y)  ?  max(p0, p2)  :  p0;
  return p0;
kernel vec4 _horizMax4(sampler image, float bound)
  vec2 d  = vec2(4.0,1.0)*destCoord();
  vec4 p0 = sample(image, samplerTransform(image, d + vec2(-1.5, 0.0)));
  vec4 p1 = sample(image, samplerTransform(image, d + vec2(-0.5, 0.0)));
  vec4 p2 = sample(image, samplerTransform(image, d + vec2(+0.5, 0.0)));
  vec4 p3 = sample(image, samplerTransform(image, d + vec2(+1.5, 0.0)));
  p0 = (d.x-0.5 < bound)  ?  max(p0, p1)  :  p0;
  p0 = (d.x+0.5 < bound)  ?  max(p0, p2)  :  p0;
  p0 = (d.x+1.5 < bound)  ?  max(p0, p3)  :  p3;
  return p0;
kernel vec4 _vertMax4(sampler image, float bound)
  vec2 d  = vec2(1.0,4.0)*destCoord();
  vec4 p0 = sample(image, samplerTransform(image, d + vec2( 0.0,-1.5)));
  vec4 p1 = sample(image, samplerTransform(image, d + vec2( 0.0,-0.5)));
  vec4 p2 = sample(image, samplerTransform(image, d + vec2( 0.0,+0.5)));
  vec4 p3 = sample(image, samplerTransform(image, d + vec2( 0.0,+1.5)));
  p0 = (d.y-0.5 < bound)  ?  max(p0, p1)  :  p0;
  p0 = (d.y+0.5 < bound)  ?  max(p0, p2)  :  p0;
  p0 = (d.y+1.5 < bound)  ?  max(p0, p3)  :  p0;
  return p0;
kernel vec4 _areaMin4(sampler image, vec2 bound)
  vec2 d  = 2.0*destCoord();
  vec4 p0 = sample(image, samplerTransform(image, d + vec2(-0.5,-0.5)));
  vec4 p1 = sample(image, samplerTransform(image, d + vec2(+0.5,-0.5)));
  vec4 p2 = sample(image, samplerTransform(image, d + vec2(-0.5,+0.5)));
  vec4 p3 = sample(image, samplerTransform(image, d + vec2(+0.5,+0.5)));
  p0 = (d.x+0.5 < bound.x)  ?  min(p0, p1)  :  p0;
  p2 = (d.x+0.5 < bound.x)  ?  min(p2, p3)  :  p2;
  p0 = (d.y+0.5 < bound.y)  ?  min(p0, p2)  :  p0;
  return p0;
kernel vec4 _horizMin4(sampler image, float bound)
  vec2 d  = vec2(4.0,1.0)*destCoord();
  vec4 p0 = sample(image, samplerTransform(image, d + vec2(-1.5, 0.0)));
  vec4 p1 = sample(image, samplerTransform(image, d + vec2(-0.5, 0.0)));
  vec4 p2 = sample(image, samplerTransform(image, d + vec2(+0.5, 0.0)));
  vec4 p3 = sample(image, samplerTransform(image, d + vec2(+1.5, 0.0)));
  p0 = (d.x-0.5 < bound)  ?  min(p0, p1)  :  p0;
  p0 = (d.x+0.5 < bound)  ?  min(p0, p2)  :  p0;
  p0 = (d.x+1.5 < bound)  ?  min(p0, p3)  :  p0;
  return p0;
kernel vec4 _vertMin4(sampler image, float bound)
  vec2 d  = vec2(1.0,4.0)*destCoord();
  vec4 p0 = sample(image, samplerTransform(image, d + vec2( 0.0,-1.5)));
  vec4 p1 = sample(image, samplerTransform(image, d + vec2( 0.0,-0.5)));
  vec4 p2 = sample(image, samplerTransform(image, d + vec2( 0.0,+0.5)));
  vec4 p3 = sample(image, samplerTransform(image, d + vec2( 0.0,+1.5)));
  p0 = (d.y-0.5 < bound)  ?  min(p0, p1)  :  p0;
  p0 = (d.y+0.5 < bound)  ?  min(p0, p2)  :  p0;
  p0 = (d.y+1.5 < bound)  ?  min(p0, p3)  :  p0;
  return p0;
kernel vec4 _areaMaxAlphaS4(sampler image, vec2 bound)
  vec2 d  = 2.0*destCoord();
  vec4 p0 = sample(image, samplerTransform(image, d + vec2(-0.5,-0.5)));
  vec4 p1 = sample(image, samplerTransform(image, d + vec2(+0.5,-0.5)));
  vec4 p2 = sample(image, samplerTransform(image, d + vec2(-0.5,+0.5)));
  vec4 p3 = sample(image, samplerTransform(image, d + vec2(+0.5,+0.5)));
  p0 = (d.x+0.5 < bound.x)  ?  (p0.a>=p1.a ? p0 : p1)  :  p0;
  p2 = (d.x+0.5 < bound.x)  ?  (p2.a>=p3.a ? p2 : p3)  :  p2;
  p0 = (d.y+0.5 < bound.y)  ?  (p0.a>=p2.a ? p0 : p2)  :  p0;
  return p0;
kernel vec4 _areaMaxAlphaH4(sampler image, float bound)
  vec2 d  = vec2(4.0,1.0)*destCoord();
  vec4 p0 = sample(image, samplerTransform(image, d + vec2(-1.5, 0.0)));
  vec4 p1 = sample(image, samplerTransform(image, d + vec2(-0.5, 0.0)));
  vec4 p2 = sample(image, samplerTransform(image, d + vec2(+0.5, 0.0)));
  vec4 p3 = sample(image, samplerTransform(image, d + vec2(+1.5, 0.0)));
  p0 = (d.x-0.5 < bound)  ?  (p0.a>=p1.a ? p0 : p1)  :  p0;
  p0 = (d.x+0.5 < bound)  ?  (p0.a>=p2.a ? p0 : p2)  :  p0;
  p0 = (d.x+1.5 < bound)  ?  (p0.a>=p3.a ? p0 : p3)  :  p0;
  return p0;
kernel vec4 _areaMaxAlphaV4(sampler image, float bound)
  vec2 d  = vec2(1.0,4.0)*destCoord();
  vec4 p0 = sample(image, samplerTransform(image, d + vec2( 0.0,-1.5)));
  vec4 p1 = sample(image, samplerTransform(image, d + vec2( 0.0,-0.5)));
  vec4 p2 = sample(image, samplerTransform(image, d + vec2( 0.0,+0.5)));
  vec4 p3 = sample(image, samplerTransform(image, d + vec2( 0.0,+1.5)));
  p0 = (d.y-0.5 < bound)  ?  (p0.a>=p1.a ? p0 : p1)  :  p0;
  p0 = (d.y+0.5 < bound)  ?  (p0.a>=p2.a ? p0 : p2)  :  p0;
  p0 = (d.y+1.5 < bound)  ?  (p0.a>=p3.a ? p0 : p3)  :  p0;
  return p0;
kernel vec4 _areaMinAlphaS4(sampler image, vec2 bound)
  vec2 d  = 2.0*destCoord();
  vec4 p0 = sample(image, samplerTransform(image, d + vec2(-0.5,-0.5)));
  vec4 p1 = sample(image, samplerTransform(image, d + vec2(+0.5,-0.5)));
  vec4 p2 = sample(image, samplerTransform(image, d + vec2(-0.5,+0.5)));
  vec4 p3 = sample(image, samplerTransform(image, d + vec2(+0.5,+0.5)));
  p0 = (d.x+0.5 < bound.x)  ?  (p0.a<=p1.a ? p0 : p1)  :  p0;
  p2 = (d.x+0.5 < bound.x)  ?  (p2.a<=p3.a ? p2 : p3)  :  p2;
  p0 = (d.y+0.5 < bound.y)  ?  (p0.a<=p2.a ? p0 : p2)  :  p0;
  return p0;
kernel vec4 _areaMinAlphaH4(sampler image, float bound)
  vec2 d  = vec2(4.0,1.0)*destCoord();
  vec4 p0 = sample(image, samplerTransform(image, d + vec2(-1.5, 0.0)));
  vec4 p1 = sample(image, samplerTransform(image, d + vec2(-0.5, 0.0)));
  vec4 p2 = sample(image, samplerTransform(image, d + vec2(+0.5, 0.0)));
  vec4 p3 = sample(image, samplerTransform(image, d + vec2(+1.5, 0.0)));
  p0 = (d.x-0.5 < bound)  ?  (p0.a<=p1.a ? p0 : p1)  :  p0;
  p0 = (d.x+0.5 < bound)  ?  (p0.a<=p2.a ? p0 : p2)  :  p0;
  p0 = (d.x+1.5 < bound)  ?  (p0.a<=p3.a ? p0 : p3)  :  p0;
  return p0;
kernel vec4 _areaMinAlphaV4(sampler image, float bound)
  vec2 d  = vec2(1.0,4.0)*destCoord();
  vec4 p0 = sample(image, samplerTransform(image, d + vec2( 0.0,-1.5)));
  vec4 p1 = sample(image, samplerTransform(image, d + vec2( 0.0,-0.5)));
  vec4 p2 = sample(image, samplerTransform(image, d + vec2( 0.0,+0.5)));
  vec4 p3 = sample(image, samplerTransform(image, d + vec2( 0.0,+1.5)));
  p0 = (d.y-0.5 < bound)  ?  (p0.a<=p1.a ? p0 : p1)  :  p0;
  p0 = (d.y+0.5 < bound)  ?  (p0.a<=p2.a ? p0 : p2)  :  p0;
  p0 = (d.y+1.5 < bound)  ?  (p2.a<=p3.a ? p0 : p3)  :  p0;
  return p0;
kernel vec4 _areaAvg8(sampler image)
  vec2 d = 8.0*destCoord();
  vec4 p = sample(image, samplerTransform(image, d + vec2(-3.0,-3.0))) 
         + sample(image, samplerTransform(image, d + vec2(-1.0,-3.0))) 
         + sample(image, samplerTransform(image, d + vec2( 1.0,-3.0))) 
         + sample(image, samplerTransform(image, d + vec2( 3.0,-3.0))) 
         + sample(image, samplerTransform(image, d + vec2(-3.0,-1.0))) 
         + sample(image, samplerTransform(image, d + vec2(-1.0,-1.0))) 
         + sample(image, samplerTransform(image, d + vec2( 1.0,-1.0))) 
         + sample(image, samplerTransform(image, d + vec2( 3.0,-1.0))) 
         + sample(image, samplerTransform(image, d + vec2(-3.0, 1.0))) 
         + sample(image, samplerTransform(image, d + vec2(-1.0, 1.0))) 
         + sample(image, samplerTransform(image, d + vec2( 1.0, 1.0))) 
         + sample(image, samplerTransform(image, d + vec2( 3.0, 1.0))) 
         + sample(image, samplerTransform(image, d + vec2(-3.0, 3.0))) 
         + sample(image, samplerTransform(image, d + vec2(-1.0, 3.0))) 
         + sample(image, samplerTransform(image, d + vec2( 1.0, 3.0))) 
         + sample(image, samplerTransform(image, d + vec2( 3.0, 3.0)));
  return 0.0625*p;
kernel vec4 _areaAvg4(sampler image)
  vec2 d = 4.0*destCoord();
  vec4 p = sample(image, samplerTransform(image, d + vec2(-1.0,-1.0))) 
         + sample(image, samplerTransform(image, d + vec2(+1.0,-1.0))) 
         + sample(image, samplerTransform(image, d + vec2(-1.0,+1.0))) 
         + sample(image, samplerTransform(image, d + vec2(+1.0,+1.0)));
  return 0.25*p;
kernel vec4 _areaAvg2(sampler image)
  vec2 d  = 2.0*destCoord();
  return sample(image, samplerTransform(image, d));
kernel vec4 _vertAvg16(sampler image)
  vec2 d = vec2(1.0, 16.0) * destCoord();
  vec4 p = sample(image, samplerTransform(image, d + vec2(0.0,-7.0))) 
         + sample(image, samplerTransform(image, d + vec2(0.0,-5.0))) 
         + sample(image, samplerTransform(image, d + vec2(0.0,-3.0))) 
         + sample(image, samplerTransform(image, d + vec2(0.0,-1.0))) 
         + sample(image, samplerTransform(image, d + vec2(0.0,+1.0))) 
         + sample(image, samplerTransform(image, d + vec2(0.0,+3.0))) 
         + sample(image, samplerTransform(image, d + vec2(0.0,+5.0))) 
         + sample(image, samplerTransform(image, d + vec2(0.0,+7.0)));
  return p * 0.125;
kernel vec4 _vertAvg8(sampler image)
  vec2 d = vec2(1.0, 8.0) * destCoord();
  vec4 p = sample(image, samplerTransform(image, d + vec2(0.0,-3.0))) 
         + sample(image, samplerTransform(image, d + vec2(0.0,-1.0))) 
         + sample(image, samplerTransform(image, d + vec2(0.0,+1.0))) 
         + sample(image, samplerTransform(image, d + vec2(0.0,+3.0)));
  return p * 0.25;
kernel vec4 _vertAvg4(sampler image)
  vec2 d = vec2(1.0, 4.0) * destCoord();
  vec4 p = sample(image, samplerTransform(image, d + vec2(0.0,-1.0))) 
         + sample(image, samplerTransform(image, d + vec2(0.0,+1.0)));
  return p * 0.5;
kernel vec4 _vertAvg2(sampler image)
  vec2 d = vec2(1.0,2.0)*destCoord();
  return sample(image, samplerTransform(image, d));
kernel vec4 _horizAvg16(sampler image)
  vec2 d = vec2(16.0, 1.0) * destCoord();
  vec4 p = sample(image, samplerTransform(image, d + vec2(-7.0, 0.0))) 
         + sample(image, samplerTransform(image, d + vec2(-5.0, 0.0))) 
         + sample(image, samplerTransform(image, d + vec2(-3.0, 0.0))) 
         + sample(image, samplerTransform(image, d + vec2(-1.0, 0.0))) 
         + sample(image, samplerTransform(image, d + vec2(+1.0, 0.0))) 
         + sample(image, samplerTransform(image, d + vec2(+3.0, 0.0))) 
         + sample(image, samplerTransform(image, d + vec2(+5.0, 0.0))) 
         + sample(image, samplerTransform(image, d + vec2(+7.0, 0.0)));
  return p * 0.125;
kernel vec4 _horizAvg8(sampler image)
  vec2 d = vec2(8.0, 1.0) * destCoord();
  vec4 p = sample(image, samplerTransform(image, d + vec2(-3.0, 0.0))) 
         + sample(image, samplerTransform(image, d + vec2(-1.0, 0.0))) 
         + sample(image, samplerTransform(image, d + vec2(+1.0, 0.0))) 
         + sample(image, samplerTransform(image, d + vec2(+3.0, 0.0)));
  return p * 0.25;
kernel vec4 _horizAvg4(sampler image)
  vec2 d = vec2(4.0, 1.0) * destCoord();
  vec4 p = sample(image, samplerTransform(image, d + vec2(-1.0, 0.0))) 
         + sample(image, samplerTransform(image, d + vec2(+1.0, 0.0)));
  return p * 0.5;
kernel vec4 _horizAvg2(sampler image)
  vec2 d = vec2(2.0,1.0)*destCoord();
  return sample(image, samplerTransform(image, d));
// Copyright 2015 Apple Inc.
attribute highp vec4 position;
attribute highp vec4 texcoord;
varying highp vec2 p0;
uniform highp mat3 vertexTransform;
void main()
  gl_Position = position;
  p0 = (vec3(texcoord.xy,1.0) * vertexTransform).xy;
construct_fragment_shader
#define _ci_swizzle(s) (%s)
#define _srgb_to_linear(s) srgb_to_linear(s, _dc)
static constant float4 _ci_constants = (float4)(1.0,0.0,1.0/257.0,256.0/257.0);
#define sampleImage(s, ss, p, dc) %s(%s(read_imagef(s, ss, p))%s)
_ci_swizzle
_srgb_to_linear
#define samplerTransform(s, ss, p, dc) (float2)(dot((float4)(p,1.0,0.0),s##_transform0),dot((float4)(p,1.0,0.0),s##_transform1))
#define samplerExtent(s, ss, dc) s##_transform2
#define _srgb_to_linear(s) srgb_to_linear(s)
const lowp vec4 _ci_constants = vec4(1.0,0.0,1.0/257.0,256.0/257.0);
#define sampleImage(s,p) %s(%s(texture2D(_image[s],p))%s)
#define samplerTransform(s,p) ((vec3(p, 1.0) * _transform[s]).xy)
#define samplerExtent(s) _extent[s]
uniform lowp sampler2D _image[%d];
uniform highp mat3 _transform[%d];
uniform highp vec4 _extent[%d];
static constant metal::float4 _ci_constants = metal::float4(1.0,0.0,1.0/257.0,256.0/257.0);
#define sampleImage(s, ss, p, dc) %s(%s(s.sample(ss,p))%s)
#define samplerTransform(s, ss, p, dc) float2(dot(float3(p,1.0),s##_transform[0].xyz),dot(float3(p,1.0),s##_transform[1].xyz))
#define samplerExtent(s, ss, dc) (s##_transform[3])
#define writeImage(c, p, _dc) (write_imagef(_outputTexture, (int2)p, c))
#define writeImagePlane(c, p, _dc) (write_imagef(_outputTexturePlane, (int2)p, c))
#define writePixel(r, g, b, a, p, _dc) (write_imagei(_outputTexture, (int2)p, (int4)(r,g,b,a)))
#define writeCoord(_dc) (float2)_writeLoc
#define writeImage(c, p, _dc) (_outputTexture.write(c, static_cast<uint2>(p)))
#define writeImagePlane(c, p, _dc) (_outputTexturePlane.write(c, static_cast<uint2>(p)))
#define writePixel(r, g, b, a, p, _dc) (_outputTexture.write(int4(r,g,b,a), static_cast<uint2>(p)))
#define writeCoord(_dc) static_cast<float2>(_gid)
sampleImage(
_STUB_
samplerTransform(
samplerExtent(
write_imagef
gl_FragColor
outputTexture.write
writeImage
writeImagePlane
writePixel
writeCoord
write_only image2d_t _outputTexture, write_only image2d_t _outputTexturePlane, int2 _writeLoc
texture2d<float, access::write> _outputTexture, texture2d<float, access::write> _outputTexturePlane, uint2 _gid
write_only image2d_t out
texture2d<float, access::write> outputTexture
out, out1, _writeLoc
outputTexture, outputTexture1, gid
EntryPoint
%s, 
%s1,
.bgra
.abgr
.argb
.gbra
.grab
.gbar
.aaaa
.rrrr
.rrrg
.rgba * _ci_constants.xxxy + _ci_constants.yyyx
.bgra * _ci_constants.xxxy + _ci_constants.yyyx
.argb * _ci_constants.xxxy + _ci_constants.yyyx
.grab * _ci_constants.xxxy + _ci_constants.yyyx
.abgr * _ci_constants.yxxx + _ci_constants.xyyy
.argb * _ci_constants.yxxx + _ci_constants.xyyy
.rrrr * _ci_constants.yyyx
.rrrr * _ci_constants.xxxy + _ci_constants.yyyx
.rrrr * _ci_constants.xyyy + _ci_constants.yyyx
.rggg * _ci_constants.xxyy + _ci_constants.yyyx
.aaaa * _ci_constants.xyyy + _ci_constants.yyyx
.raaa * _ci_constants.xxyy + _ci_constants.yyyx
.aaaa * _ci_constants.xxxy + _ci_constants.yyyx
dot(s.rg, _ci_constants.zw) * _ci_constants.xyyy + _ci_constants.yyyx
dot(s.rg, _ci_constants.zw) * _ci_constants.xxxy + _ci_constants.yyyx
dot(s.rg, _ci_constants.zw) * _ci_constants.yyyx
dot(s.rg, _ci_constants.zw) * _ci_constants.xxxx
dot(s.ra, _ci_constants.zw) * _ci_constants.xyyy + _ci_constants.yyyx
dot(s.ra, _ci_constants.zw) * _ci_constants.xxxy + _ci_constants.yyyx
dot(s.ra, _ci_constants.zw) * _ci_constants.yyyx
dot(s.ra, _ci_constants.zw) * _ci_constants.xxxx
dot(s.rg, _ci_constants.zw) * _ci_constants.xyyy + dot(s.ba, _ci_constants.zw) * _ci_constants.yxyy + _ci_constants.yyyx
dot(s.rg, _ci_constants.zw) * _ci_constants.xxxy + dot(s.ba, _ci_constants.zw) * _ci_constants.yyyx
T@"CIVector",&,N,VinputRVector
T@"CIVector",&,N,VinputGVector
T@"CIVector",&,N,VinputBVector
T@"CIVector",&,N,VinputAVector
T@"CIVector",&,N,VinputBiasVector
kernel vec4 _vibrance_neg(__sample pixel0, float vibrance)
  vec4 pixel = clamp(pixel0, 0.0001, 0.9999);
  vec4 pdelta = pixel0 - pixel;
  float gray = (pixel.r + pixel.g + pixel.b) * 0.33333;
  float gi   = 1.0 / gray;
  float gii  = 1.0 / (1.0 - gray);
  vec3 rgbsat = max((pixel.rgb - gray) * gii, (gray - pixel.rgb) * gi);
  float sat = max(max(rgbsat.r, rgbsat.g), rgbsat.b);
  float skin = min(pixel.r - pixel.g, pixel.g * 2.0 - pixel.b) * 4.0 * (1.0 - rgbsat.r) * gi;
  skin = 0.15 + clamp(skin, 0.0, 1.0) * 0.7;
  float boost = ((sat * (sat - 1.0) + 1.0) * vibrance) * (1.0-skin);
  pixel = clamp(pixel + (pixel - gray) * boost, 0.0, 1.0);
  pixel.a = pixel0.a;
  pixel.rgb += pdelta.rgb;
  return pixel;
kernel vec4 _vibrance_pos(__sample pixel0, vec4 vvec)
  vec4 pixel = clamp(pixel0, 0.0001, 0.9999);
  vec4 pdelta = pixel0 - pixel;
  float gray = (pixel.r + pixel.g + pixel.b) * 0.33333;
  float gi   = 1.0 / gray;
  float gii  = 1.0 / (1.0 - gray);
  vec3 rgbsat = max((pixel.rgb - gray) * gii, (gray - pixel.rgb) * gi);
  float sat = max(max(rgbsat.r, rgbsat.g), rgbsat.b);
  float skin = min(pixel.r - pixel.g, pixel.g * 2.0 - pixel.b) * 4.0 * (1.0 - rgbsat.r) * gi;
  skin = 0.15 + clamp(skin, 0.0, 1.0) * 0.7;
  float boost = dot(vvec, vec4(1.0, sat, sat*sat, sat*sat*sat)) * (1.0 - skin);
  pixel = clamp(pixel + (pixel - gray) * boost, 0.0, 1.0);
  pixel.a = pixel0.a;
  pixel.rgb += pdelta.rgb;
  return pixel;
Vibrance
inputNeutral
inputTargetNeutral
T@"CIVector",&,D,N
T@"CIVector",&,N,VinputTargetNeutral
kernel vec4 _whitepointadjust (__sample img, __color color) { return img * color; }
T@"CIColor",&,N,VinputColor
kernel vec4 _falseColor (__sample img, __color c0, __color c1)
  return img.a * mix (c0, c1, dot(img.rgb, vec3(.2125, .7154, .0721)));
inputColor0
inputColor1
T@"CIColor",&,N,VinputColor0
T@"CIColor",&,N,VinputColor1
CI Internal Context
Could not set current contest to %p.
inputPower
T@"NSNumber",&,N,VinputPower
kCIImageProcessorSynchronizeInputs
%s surface is nil.
-[CIImageProcessorInOut initWithSurface:texture:bounds:context:]
%s context is nil.
%@: cannot return a CVPixelBuffer on this platform.
<%@: %p %s extent [infinite]>
<%@: %p %s extent [empty]>
<%@: %p %s extent [%g %g %g %g]>
region
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,V_region
surface
T^{__IOSurface=},R,N
bytesPerRow
TQ,R,N
baseAddress
T^v,R,N
metalTexture
T@"<MTLTexture>",R,N
metalCommandBuffer
T@"<MTLCommandBuffer>",R,N
%s Input buffer may not contain valid data for CPU access if kCIImageProcessorSynchronizeInputs option is set to NO!
-[CIImageProcessorInput baseAddress]
Tr^v,R,N
%s processor block must be provided.
-[CIImage(CIImageProcessor) imageWithExtent:processorDescription:argumentDigest:inputFormat:outputFormat:options:roiCallback:processor:]
%s inputFormat must be 0, R8, BGRA8, RGBAh, RGBAf.
%s outputFormat must be 0, R8, BGRA8, RGBAh, RGBAf.
Image Processor
v96@?0^^{__IOSurface}8^{Texture=(?=I^v)I}16^{CGRect={CGPoint=dd}{CGSize=dd}}24^{__IOSurface=}32{Texture=(?=I^v)I}40{CGRect={CGPoint=dd}{CGSize=dd}}56^{Context=^^?{Atomic={?=i}}^{CGColorSpace}^{CGColorSpace}iBBBB^{CGContext}fB{CGRect={CGPoint=dd}{CGSize=dd}}{CGAffineTransform=dddddd}iQQiB[1024{TreeCacheElement={Hash=[20C]}Q^{Kernel}}]QddB@@}88
%s must be overridden in %@ class
+[CIImageProcessorKernel processWithInputs:arguments:output:error:]
Don't know how to compute digest for an object of type %@ in the processor node %@
processWithInputs:arguments:output:error:
+[CIImageProcessorKernel applyWithExtent:inputs:arguments:error:]
CIImageProcessorKernel
CINonLocalizedDescriptionKey
outputFormat must be 0, R8, BGRA8, RGBAh, RGBAf.
argument value for key %@ must be NSNumber, NSData, NSString, CIVector or CIColor.
inputFormat for image %d must be 0, R8, BGRA8, RGBAh, RGBAf.
synchronizeInputs
v16@?0^v8
kernel vec4 _noiseReduction(sampler src, vec2 offset, vec3 weight, vec3 intensity)
  vec2 c  = destCoord();
  vec4 cn = sample(src, samplerTransform(src, c));
  vec4 t0 = sample(src, samplerTransform(src, c + vec2(0.0,-offset.x)));
  vec4 t1 = sample(src, samplerTransform(src, c + vec2(0.0, offset.x)));
  vec4 t2 = sample(src, samplerTransform(src, c + vec2(-offset.x,0.0)));
  vec4 t3 = sample(src, samplerTransform(src, c + vec2( offset.x,0.0)));
  vec4 t4 = sample(src, samplerTransform(src, c + vec2( offset.y, offset.y)));
  vec4 t5 = sample(src, samplerTransform(src, c + vec2( offset.y,-offset.y)));
  vec4 t6 = sample(src, samplerTransform(src, c + vec2(-offset.y,-offset.y)));
  vec4 t7 = sample(src, samplerTransform(src, c + vec2(-offset.y, offset.y)));
  t0      = (t0+t1+t2+t3)*weight.x + (t4+t5+t6+t7)*weight.y + cn*weight.z;
  vec4 d  = abs(t0 - cn);
  float s = intensity.x + intensity.y * (d.r + d.g + d.b);
  s     = clamp(s, intensity.z, 1.0);
  return mix(cn, t0, s);
inputNoiseLevel
kernel vec4 _convertRGBtoY (__sample c)
  c = vec4(c.rgb/max(c.a,0.00001), c.a);
  float Y = sqrt(max(dot(c.rgb, vec3(0.299,0.587,0.114)), 0.0));
  c.rgb = vec3(Y);
  return c;
kernel vec4 _blur1(sampler src) 
  vec2 p = destCoord(); 
  vec4 pixB  = sample(src, samplerTransform(src, p + vec2(-1.0, 1.0)));
  vec4 pixA  = sample(src, samplerTransform(src, p + vec2( 0.0, 1.0)));
       pixB += sample(src, samplerTransform(src, p + vec2( 1.0, 1.0)));
       pixA += sample(src, samplerTransform(src, p + vec2(-1.0, 0.0)));
  vec4 pix   = sample(src, samplerTransform(src, p));
       pixA += sample(src, samplerTransform(src, p + vec2( 1.0, 0.0)));
       pixB += sample(src, samplerTransform(src, p + vec2(-1.0,-1.0)));
       pixA += sample(src, samplerTransform(src, p + vec2( 0.0,-1.0)));
       pixB += sample(src, samplerTransform(src, p + vec2( 1.0,-1.0)));
  pix.g = pix.r * 0.25  +  pixA.r * 0.125  +  pixB.r * 0.0625;
  return pix;
kernel vec4 _blur2(sampler src) 
  vec2 p = destCoord(); 
  vec4 pixB  = sample(src, samplerTransform(src, p + vec2(-2.0, 2.0)));
  vec4 pixA  = sample(src, samplerTransform(src, p + vec2( 0.0, 2.0)));
       pixB += sample(src, samplerTransform(src, p + vec2( 2.0, 2.0)));
       pixA += sample(src, samplerTransform(src, p + vec2(-2.0, 0.0)));
  vec4 pix   = sample(src, samplerTransform(src, p));
       pixA += sample(src, samplerTransform(src, p + vec2( 2.0, 0.0)));
       pixB += sample(src, samplerTransform(src, p + vec2(-2.0,-2.0)));
       pixA += sample(src, samplerTransform(src, p + vec2( 0.0,-2.0)));
       pixB += sample(src, samplerTransform(src, p + vec2( 2.0,-2.0)));
  pix.b = pix.g * 0.25  +  pixA.g * 0.125  +  pixB.g * 0.0625;
  return pix;
kernel vec4 _blur4(sampler src) 
  vec2 p = destCoord(); 
  vec4 pixB  = sample(src, samplerTransform(src, p + vec2(-4.0, 4.0)));
  vec4 pixA  = sample(src, samplerTransform(src, p + vec2( 0.0, 4.0)));
       pixB += sample(src, samplerTransform(src, p + vec2( 4.0, 4.0)));
       pixA += sample(src, samplerTransform(src, p + vec2(-4.0, 0.0)));
  vec4 pix   = sample(src, samplerTransform(src, p));
       pixA += sample(src, samplerTransform(src, p + vec2( 4.0, 0.0)));
       pixB += sample(src, samplerTransform(src, p + vec2(-4.0,-4.0)));
       pixA += sample(src, samplerTransform(src, p + vec2( 0.0,-4.0)));
       pixB += sample(src, samplerTransform(src, p + vec2( 4.0,-4.0)));
  pix.a = pix.b * 0.25  +  pixA.b * 0.125  + pixB.b * 0.0625;
  return pix;
kernel vec4 _edgesPrep(__sample s)
  s = vec4(s.rgb/max(s.a,0.00001), s.a);
  s.rgb = sqrt(max(s.rgb, vec3(0.0)));
  return s;
kernel vec4 _findEdges(sampler src, float scale)
  vec2 p = destCoord();
  vec4 rA = sample(src, samplerTransform(src, p)) - 
            sample(src, samplerTransform(src, p + vec2(1.0, 1.0)));  
  vec4 rB = sample(src, samplerTransform(src, p + vec2(0.0, 1.0))) - 
            sample(src, samplerTransform(src, p + vec2(1.0, 0.0)));  
  vec4 r = (rA*rA + rB*rB) * scale;
  float R = min(max(max(r.r, r.g), r.b),1.0);
  return vec4(vec3(R), 1.0);
kernel vec4 _sharpenCombineEdges(__sample orig, __sample blurs, vec3 sharps, __sample edges)
  vec4 so = vec4(orig.rgb/max(orig.a,0.00001), orig.a); 
  float Y = blurs.r + dot(blurs.r - blurs.gba, sharps); 
  so.rgb = vec3(Y*Y) +
           so.r * vec3( 0.701428, -0.299276, -0.297756) + 
           so.g * vec3(-0.5881610, 0.4133170, -0.5857185) + 
           so.b * vec3(-0.113745, -0.113905, 0.884027); 
  float alpha = edges.x;
  so = vec4(so.rgb*so.a, so.a);
  return mix(orig, so, alpha);
inputFalloff
inputEdgeScale
kernel vec4 _opTile (sampler src, vec2 center, vec2 params, vec4 trans)
  vec2  t3;
  vec2 t1 = destCoord() - center;
  vec2 t2 = floor (t1 * params.x) * params.y;
  t1 = t1 - t2;
  t3.x = dot (t2, trans.xy);
  t3.y = dot (t2, trans.zw);
  t1 = t3 + t1 + center;
  return sample (src, samplerTransform (src, t1));
builtin_sqr
builtin_pow4
builtin_sqrt
builtin_gamma
sqrt
pow4
gamma %g
gamma
CI::TextureManager
TextureManager::TextureManager() failed to create empty surface
TextureManager::remove_lru() did not find an info struct!
%p numSurfaceHits: %zu, numMisses: %zu
Unneccesary release of intermediate for image
clamp
clamp 
affine_matrix
wrap_mode
filter_mode
black
CISampler value for key '%s' is nil. Skipping.
CISampler value for key '%s' must be a NSObject or a CGColorSpaceRef. Skipping.
CISampler option key must be a NSString. Skipping.
CISampler ignoring kCISamplerBlurFormat because it is not supported.
CISampler ignoring kCISamplerWrapPeriodic because it is not supported.
CISampler ignoring kCISamplerAffineMatrix value because it is not a valid object '%@'.
CISampler ignoring kCISamplerColorSpace value because it is not an RGB CGColorSpaceRef that supports output.
<CISampler: %p extent [infinite]>
<CISampler: %p extent [empty]>
<CISampler: %p extent [%g %g %g %g]>
<CISampler: %p>
blur
blur_format
periodic
color_matrix
bias
 %s=(%g %g %g %g)
color_matrix<BR/>
%s=(%g %g %g %g)<BR/>
kernel vec4 _shadedmaterial(sampler heightfield, sampler envmap, float surfaceScale, vec2 envscaling)
  vec2 d       = destCoord();
  vec4 sup     = sample(heightfield, samplerTransform(heightfield, d+vec2( 0.0,+1.0)));
  vec4 sdown   = sample(heightfield, samplerTransform(heightfield, d+vec2( 0.0,-1.0)));
  vec4 sleft   = sample(heightfield, samplerTransform(heightfield, d+vec2(-1.0, 0.0)));
  vec4 sright  = sample(heightfield, samplerTransform(heightfield, d+vec2(+1.0, 0.0)));
  vec4 scenter = sample(heightfield, samplerCoord(heightfield));
  vec3 normal  = normalize(vec3(sleft.r - sright.r, sdown.r - sup.r, surfaceScale));
  vec2 eloc = (normal.xy * 0.495 + 0.5) * envscaling;
  vec4 pix = sample(envmap, samplerTransform(envmap, eloc));
  return pix * scenter.a;
kernel vec4 _shadedmaterial_0(sampler heightfield, sampler envmap, vec2 envscaling)
  vec4 scenter = sample(heightfield, samplerCoord(heightfield));
  vec3 normal  = vec3(0.0, 0.0, 1.0);
  vec2 eloc = (normal.xy * 0.495 + 0.5) * envscaling;
  vec4 pix = sample(envmap, samplerTransform(envmap, eloc));
  return pix * scenter.a;
Warning smartToneStatistics will soon need [receiver properties] be non-nil so flash-fired state can be determined.
tonalRange
highKey
autoValue
blackPoint
whitePoint
satPercentile75
satPercentile98
satPercentileG98
satAutoValue
inputExposure
inputShadows
inputHighlights
inputBlack
inputLocalLight
inputRawHighlights
inputVibrancy
inputCast
inputUseCube
inputUseCubeColorSpace
kernel vec4 _smarttone_brightness_neg (__sample c, float gamma)
  vec3 neg = min(c.rgb, 0.0); 
  c.rgb = max(c.rgb, 0.0); 
  vec3 pix = pow(c.rgb, vec3(gamma)); 
  float lum = dot(c.rgb, vec3(0.39, .5, .11)); 
  vec3 pix2 = lum>0.0 ? c.rgb*pow(lum, gamma)/lum : vec3(0.0); 
  pix = mix(pix, pix2, 0.8) + neg; 
  return vec4(pix, c.a); 
kernel vec4 _smarttone_brightness_pos (__sample c, float gamma)
  vec3 neg = min(c.rgb, 0.0); 
  vec3 pos = max(c.rgb, 1.0)-1.0; 
  c.rgb = clamp(c.rgb, 0.0, 1.0); 
  vec3 m = 1.0-c.rgb; 
  float a = 0.6; 
  vec4 result = c; 
  result.rgb = 1.0 - (pow(m, vec3(gamma))+a*( ((gamma-1.0)*m*(1.0-m*m))/(gamma*gamma))); 
  c.rgb = pow(c.rgb, vec3(1.0-((min(gamma, 2.95)-1.0)/2.6))); 
  result.rgb = mix(c.rgb, result.rgb, .85); 
  result.rgb = result.rgb+neg+pos; 
  return result; 
kernel vec4 _smarttone_contrast (__sample im, float midAmt) 
  vec3 neg = min(im.rgb, 0.0); 
  vec3 pos = max(im.rgb, 1.0)-1.0; 
  im.rgb = clamp(im.rgb, 0.0, 1.0); 
  float y = dot(im.rgb, vec3(0.3333)); 
  y = sqrt(y); 
  float sat = (im.r-y)*(im.r-y)+(im.g-y)*(im.g-y)+(im.b-y)*(im.b-y); 
  y = y*(1.0-y); 
  im.rgb = sqrt(im.rgb); 
  float a = midAmt*y; 
  float b = -0.5*a; 
  vec3 pix = im.r * vec3(0.299*a) + 
             im.g * vec3(0.587*a) + 
             im.b * vec3(0.114*a) + 
             im.rgb + vec3(b); 
  im.rgb = mix(im.rgb, vec3(0.5), -y*midAmt); 
  im.rgb = mix(im.rgb, pix, 0.8+sat); 
  im.rgb = max(im.rgb, 0.0); 
  im.rgb *= im.rgb; 
  im.rgb = im.rgb + neg + pos; 
  return im; 
kernel vec4 _smarttone_highlightcontrast (__sample pix, float highAmt, float sat)
  float lum = clamp(dot(pix.rgb, vec3(.3333)),0.0,1.0); 
  vec3 high = pow(max(pix.rgb, 0.0), vec3(3.0 - 2.0*highAmt))  +  min(pix.rgb, 0.0); 
  float pivot = 0.8; 
  vec3 pix1 = (high - pivot)*(4.0 - 3.0*highAmt) + pivot; 
  float h = highAmt*highAmt*highAmt*highAmt; 
  float a = (4.0 - 3.0*h); 
  vec3 pix2 = (lum-pivot)*a+pivot + high.rgb -lum; 
  high = mix(pix2, pix1, sat); 
  pix.rgb = mix(pix.rgb, high, lum*lum); 
  return pix; 
kernel vec4 rawHighlights(__sample pix, float gain) 
    vec3 high = gain*pix.rgb; 
    float lum = clamp(dot(pix.rgb, vec3(.3333)), 0.0, 1.0); 
    vec3 neg = min(high, 0.0); 
    high.rgb = mix(max(pix.rgb, 0.0), high.rgb, lum*lum) + neg; 
    return vec4(high, pix.a); 
CIColorCubeWithColorSpace
inputCubeData
inputColorSpace
inputCubeDimension
inputHighlightAmount
T@"NSNumber",&,N,VinputExposure
T@"NSNumber",&,N,VinputShadows
T@"NSNumber",&,N,VinputHighlights
T@"NSNumber",&,N,VinputBlack
T@"NSNumber",&,N,VinputRawHighlights
T@"NSNumber",&,N,VinputLocalLight
inputLightMap
T@"NSData",&,N,V_inputLightMap
T@"NSNumber",&,N,VinputUseCube
T@,&,N,VinputUseCubeColorSpace
kernel vec4 _smartcolor_contrast (__sample im, float amt)
  vec3 diff = im.rgb-dot(im.rgb, vec3(.0, .3, .5)); 
  float dist = distance(diff, vec3(0.0)); 
  dist = smoothstep(0.0, 1.0, dist); 
  float strength = 5.0*dist*amt; 
  vec3 pos = max(im.rgb, 1.0)-1.0 + min(im.rgb, 0.0); 
  im.rgb = clamp(im.rgb, 0.0, 1.0); 
  strength *= (im.b-im.g); 
  strength = max(strength, -0.35); 
  vec4 result; 
  result.rgb = im.rgb/(strength + 1.0 - (im.rgb*strength)) + pos; 
  result.a = im.a; 
  return result; 
kernel vec4 _smartcolor_contrast_darken (__sample im, float amt)
  vec3 diff = im.rgb-dot(im.rgb, vec3(.0, .3, .5)); 
  float dist = distance(diff, vec3(0.0)); 
  dist = smoothstep(0.0, 1.0, dist); 
  float strength = 5.0*dist*amt; 
  vec3 pos = max(im.rgb, 1.0)-1.0 + min(im.rgb, 0.0); 
  im.rgb = clamp(im.rgb, 0.0, 1.0); 
  strength *= (im.b-im.g); 
  float gray = 1.0-min(dot(im.rgb, vec3(0.5, 0.7, -0.20)), 1.0); 
  vec4 result; 
  result.rgb = strength < 0.0 ? pow(im.rgb, vec3(1.0-strength*gray)) : im.rgb/(strength+1.0-(im.rgb*strength)); 
  result.rgb += pos;  result.a = im.a; 
  return result; 
kernel vec4 _smartcolor_vibrancy_gt1 (__sample im, float amt) 
  float gray = dot(clamp(im.rgb, 0.0, 1.0), vec3(.3, .5, .2)); 
  float y = dot(clamp(im.rgb, 0.0, 1.0), vec3(.4, .2, .1)); 
  float damp = 1.0-4.0*y*(1.0-y); 
  float s = 1.0/(im.r+im.g+im.b); 
  float r = im.r*s; 
  float b = im.b*s; 
  float d = 1.0-.8*smoothstep(0.2, 0.4, r-b); 
  damp *= d; 
  damp = amt > 2.5 ? min(damp+(amt-2.5)/5.0, 1.0) : damp; 
  float sat = min(amt, 3.0); 
  vec4 result; 
  result.rgb = (im.rgb - gray)*sat + gray; 
  result.rgb = mix(im.rgb, result.rgb, damp); 
  result.a = im.a; 
  return result; 
kernel vec4 _smartcolor_vibrancy_lt1 (__sample im, float amt) 
  float gray = dot(im.rgb, vec3(0.333333)); 
  im.rgb = mix(vec3(gray), im.rgb, amt); 
  return im; 
kernel vec4 _smartcolor_cast (__sample im, float lum, float grayI, float grayQ, float strength) 
  vec4 pix = clamp(im, 0.0, 1.0);
  pix.rgb = pow(pix.rgb, vec3(.25));
  pix.rgb = pix.r * vec3(0.299,  0.595716,  0.211456) + 
            pix.g * vec3(0.587, -0.274453, -0.522591) + 
            pix.b * vec3(0.114, -0.321263,  0.311135); 
  vec2 grayOffset = vec2(grayI, grayQ) ; 
  vec3 result = pix.rgb; 
  float newStrength = 1.0 + (strength-1.0)*(1.0-pix.r) ; 
  result.gb = pix.gb + newStrength*grayOffset ; 
  float damp = max(min(1.0, pix.r/(lum+0.00001)),0.0) ; 
  result.rgb = mix(pix.rgb, result.rgb, damp) ; 
  pix.rgb = result.r * vec3(1.0) + 
            result.g * vec3(0.956296, -0.272122, -1.10699) + 
            result.b * vec3(0.621024, -0.647381, 1.70461); 
  pix.rgb = clamp(pix.rgb, 0.0, 1.0); 
  pix.rgb *= pix.rgb*pix.rgb*pix.rgb; 
  pix.rgb += min(im.rgb, 0.0) + max(im.rgb,1.0) -1.0; 
  return pix; 
T@"NSNumber",&,N,VinputVibrancy
T@"NSNumber",&,N,VinputCast
CIBitmapContext bounds is too large
CIBitmapContext format %s is unsupported%s.
CIBitmapContext rowBytes must be a multiple of %ld.
CIBitmapContext output colorspace can't be used with pixel format %s. Using default output colorspace instead.
<CI::%s %p>[%@  %llx]
render_processor
shape=component, color="#FFFF99"
noop
builtin_colormatrix_rrra
builtin_colormatrixdiag
builtin_colormatrixdiag4
builtin_colormatrix3x1
builtin_colormatrix3x3
builtin_colormatrix3x4
builtin_colormatrix
color_matrix_rrra
color_matrix_diag [%g, %g, %g]
color_matrix_diag4 [%g, %g, %g, %g]
color_matrix_3x1 [%g, %g, %g]
color_matrix_3x3 (
r=[%g %g %g],
g=[%g %g %g],
b=[%g %g %g])
color_matrix_3x4 (
bias=[%g %g %g])
color_matrix (
r=[%g %g %g %g],
g=[%g %g %g %g],
b=[%g %g %g %g],
a=[%g %g %g %g],
bias=[%g %g %g %g])
color_matrix_diag
color_matrix_diag4
color_matrix_3x1
color_matrix_3x3
color_matrix_3x4
color_matrix_diag%s[%g, %g, %g]
color_matrix_diag4%s[%g, %g, %g, %g]
color_matrix_3x1%s[%g, %g, %g]
color_matrix_3x3%s
r=[%g %g %g]%s
g=[%g %g %g]%s
b=[%g %g %g]
color_matrix_3x4%s
b=[%g %g %g]%s
bias=[%g %g %g]
color_matrix%s
r=[%g %g %g %g]%s
g=[%g %g %g %g]%s
b=[%g %g %g %g]%s
a=[%g %g %g %g]%s
bias=[%g %g %g %g]
colormatrix
kCIImageAutoAdjustEnhance
kCIImageAutoAdjustRedEye
kCIImageAutoAdjustFeatures
kCIImageAutoAdjustCrop
kCIImageAutoAdjustLevel
CIDetectorBetterEyeLocs
   adding crop rect: x=%.3f,y=%.3f,w=%.3f,h=%.3f
inputOrigI
inputOrigQ
inputStrength
inputWarmth
inputPoint2
inputPoint3
inputPoint4
iPhone
iPad
DUMP_AUTO_ENHANCE_ARRAY
filters = %@
leftEyeX
leftEyeY
rightEyeX
rightEyeY
mouthCenterX
mouthCenterY
leftEyePosition
leftEye
rightEyePosition
rightEye
leftEyeTouchSize
leftEyeSize
rightEyeTouchSize
rightEyeSize
mouthPosition
mouthCenter
inputCameraModel
inputCorrectionInfo
kIOSurfaceWidth
kIOSurfaceHeight
kIOSurfaceBytesPerRow
kIOSurfaceBytesPerElement
kIOSurfaceElementWidth
kIOSurfaceElementHeight
kIOSurfaceOffset
kIOSurfaceClientAddress
kIOSurfaceAllocSize
kIOSurfacePlaneInfo
kIOSurfacePlaneWidth
kIOSurfacePlaneHeight
kIOSurfacePlaneBytesPerRow
kIOSurfacePlaneBytesPerElement
kIOSurfacePlaneElementWidth
kIOSurfacePlaneElementHeight
kIOSurfacePlaneOffset
kIOSurfacePlaneSize
kIOSurfacePlaneBase
kIOSurfacePixelFormat
kIOSurfaceCacheMode
kIOSurfaceYCbCrMatrix
kIOSurfaceYCbCrMatrix_ITU_R_709_2_String
kIOSurfaceYCbCrMatrix_ITU_R_601_4_String
kIOSurfaceYCbCrMatrix_SMPTE_240M_1995_String
kIOSurfaceGammaLevel
kIOSurfaceColorPrimaries
kIOSurfaceTransferFunction
DCI_P3
P3_D65
profileType
description
gammaR
gammaG
gammaB
phosphorRx
phosphorRy
phosphorGx
phosphorGy
phosphorBx
phosphorBy
whitePointx
whitePointy
copyright
displayRGB
HDTV
Composite NTSC
Composite PAL
HDTV Interim Color Implementation
Digital Cinema P3
D65 P3
QuickTime 'nclc' Video (%d,%d,%d)
Copyright 2007 Apple Inc.
rTRC
gTRC
bTRC
IOSurface
<IOSurface %p refcnt=%d>
com.apple.surface.isolationqueue
CI_TRASH_SURFACES_ON_SETVOLATILE
providerGetBytesAtPositionCallback_HtoF_surface
/Library/Caches/com.apple.xbs/Sources/EmbeddedCoreImage_Sim/EmbeddedCoreImage-449/Framework/misc/Surface.c
info
buffer
providerGetBytesAtPositionCallback_2C08_surface
providerGetBytesAtPositionCallback_YCbYCr_surface
providerGetBytesAtPositionCallback_CbYCrY_surface
providerGetBytesAtPositionCallback_YCbYCrFull_surface
providerGetBytesAtPositionCallback_CbYCrYFull_surface
providerGetBytesAtPositionCallback_2C0h_surface
providerGetBytesAtPositionCallback_2C0f_surface
providerGetBytesAtPositionCallback_1C08_surface
providerGetBytesAtPositionCallback_A008_surface
providerGetBytesAtPositionCallback_1C0f_surface
providerGetBytesAtPositionCallback_1C0h_surface
providerGetBytePointerCallback
providerReleaseBytePointerCallback
undefined
CILinearToSRGBToneCurve
CIRedEyeCorrections %lu
CISRGBToneCurveToLinear
T@"NSString",C,N,VinputCameraModel
T@"NSDictionary",C,N,VinputCorrectionInfo
CIRedEyeCorrection
x = %.5f, y = %.5f, width = %.5f, height = %.5f, alpha = 0.0244, density = 0.86, strength = 0.0757, redBias = 0.253, pupilSize = 0.50, pupilDarkenAmount = 0.75
pointX
pointY
%@ %@ %@
%@ %@ %@ %@
pupilShadeLow
pupilShadeMedium
pupilShadeHigh
pupilShadeAverage
interocularDistance
%@ %@
snappedX
snappedY
bitmaskX
bitmaskY
bitmaskThreshold
cornealReflectionX
cornealReflectionY
cornealReflectionThreshold
existingPupilLow
existingPupilMedium
existingPupilHigh
existingPupilAverage
averageSkinLuminance
searchRectangleMinimumY
searchRectangleMaximumY
searchRectangleMinimumX
searchRectangleMaximumX
repairRectangleMinimumY
repairRectangleMaximumY
repairRectangleMinimumX
repairRectangleMaximumX
forceCase
pupilShadeAlignment
finalEyeCase
RedEyeInfo
RedEyeW
fullImageWidth
RedEyeH
fullImageHeight
RedEyeISV
imageSpecialValue
RedEyeOrt
imageOrientation
RedEyeSNR
imageSignalToNoiseRatio
http://ns.apple.com/adjustment-settings/1.0/sType/redeye
RedEyeCorrections
RedEyeModel
http://ns.apple.com/adjustment-settings/1.0/sType/red-eye
T@"NSArray",C,N,VinputCorrectionInfo
vImageConvert_Planar16FtoPlanar8 error %zi in CIRedEyeCorrection
Unknown input pixel format in CIRedEyeCorrection %i
vImageConvert_Planar8toPlanar16F error %zi in CIRedEyeCorrection
Unknown output pixel format in CIRedEyeCorrection %i
kernel vec4 _convolutionInit_1(sampler src, vec2 offset1, float weight1)
  vec2 coord = destCoord();
  vec4 pix1 = sample(src, samplerTransform(src, coord + offset1));
  return pix1 * weight1;
kernel vec4 _convolutionAdd_1(sampler src, sampler sums, vec2 offset1, float weight1)
  vec4 sum = sample(sums, samplerCoord(sums));
  vec2 coord = destCoord();
  vec4 pix1 = sample(src, samplerTransform(src, coord + offset1));
  return sum + pix1 * weight1;
kernel vec4 _convolutionInit_2(sampler src, vec2 offset1, vec2 offset2, vec2 weight1)
  vec2 coord = destCoord();
  vec4 pix1 = sample(src, samplerTransform(src, coord + offset1));
  vec4 pix2 = sample(src, samplerTransform(src, coord + offset2));
  return pix1 * weight1.x + pix2 * weight1.y;
kernel vec4 _convolutionAdd_2(sampler src, sampler sums, vec2 offset1, vec2 offset2, vec2 weight1)
  vec4 sum = sample(sums, samplerCoord(sums));
  vec2 coord = destCoord();
  vec4 pix1 = sample(src, samplerTransform(src, coord + offset1));
  vec4 pix2 = sample(src, samplerTransform(src, coord + offset2));
  return sum + pix1 * weight1.x + pix2 * weight1.y;
kernel vec4 _convolutionInit_3(sampler src, vec2 offset1, vec2 offset2, vec2 offset3, vec3 weight1)
  vec2 coord = destCoord();
  vec4 pix1 = sample(src, samplerTransform(src, coord + offset1));
  vec4 pix2 = sample(src, samplerTransform(src, coord + offset2));
  vec4 pix3 = sample(src, samplerTransform(src, coord + offset3));
  return pix1 * weight1.x + pix2 * weight1.y + pix3 * weight1.z;
kernel vec4 _convolutionAdd_3(sampler src, sampler sums, vec2 offset1, vec2 offset2, vec2 offset3, vec3 weight1)
  vec4 sum = sample(sums, samplerCoord(sums));
  vec2 coord = destCoord();
  vec4 pix1 = sample(src, samplerTransform(src, coord + offset1));
  vec4 pix2 = sample(src, samplerTransform(src, coord + offset2));
  vec4 pix3 = sample(src, samplerTransform(src, coord + offset3));
  return sum + pix1 * weight1.x + pix2 * weight1.y + pix3 * weight1.z;
kernel vec4 _convolutionInit_4(sampler src, vec4 offset12, vec4 offset34, vec4 weight1)
  vec2 coord = destCoord();
  vec4 pix1 = sample(src, samplerTransform(src, coord + offset12.xy));
  vec4 pix2 = sample(src, samplerTransform(src, coord + offset12.zw));
  vec4 pix3 = sample(src, samplerTransform(src, coord + offset34.xy));
  vec4 pix4 = sample(src, samplerTransform(src, coord + offset34.zw));
  return pix1 * weight1.x + pix2 * weight1.y + pix3 * weight1.z + pix4 * weight1.w;
kernel vec4 _convolutionAdd_4(sampler src, sampler sums, vec4 offset12, vec4 offset34, vec4 weight1)
  vec4 sum = sample(sums, samplerCoord(sums));
  vec2 coord = destCoord();
  vec4 pix1 = sample(src, samplerTransform(src, coord + offset12.xy));
  vec4 pix2 = sample(src, samplerTransform(src, coord + offset12.zw));
  vec4 pix3 = sample(src, samplerTransform(src, coord + offset34.xy));
  vec4 pix4 = sample(src, samplerTransform(src, coord + offset34.zw));
  return sum + pix1 * weight1.x + pix2 * weight1.y + pix3 * weight1.z + pix4 * weight1.w;
kernel vec4 _convolutionInit_5(sampler src, vec4 offset12, vec4 offset34, vec2 offset5, vec4 weight1, float weight2)
  vec2 coord = destCoord();
  vec4 pix1 = sample(src, samplerTransform(src, coord + offset12.xy));
  vec4 pix2 = sample(src, samplerTransform(src, coord + offset12.zw));
  vec4 pix3 = sample(src, samplerTransform(src, coord + offset34.xy));
  vec4 pix4 = sample(src, samplerTransform(src, coord + offset34.zw));
  vec4 pix5 = sample(src, samplerTransform(src, coord + offset5));
  return pix1 * weight1.x + pix2 * weight1.y + pix3 * weight1.z + pix4 * weight1.w + pix5 * weight2;
kernel vec4 _convolutionAdd_5(sampler src, sampler sums, vec4 offset12, vec4 offset34, vec2 offset5, vec4 weight1, float weight2)
  vec4 sum = sample(sums, samplerCoord(sums));
  vec2 coord = destCoord();
  vec4 pix1 = sample(src, samplerTransform(src, coord + offset12.xy));
  vec4 pix2 = sample(src, samplerTransform(src, coord + offset12.zw));
  vec4 pix3 = sample(src, samplerTransform(src, coord + offset34.xy));
  vec4 pix4 = sample(src, samplerTransform(src, coord + offset34.zw));
  vec4 pix5 = sample(src, samplerTransform(src, coord + offset5));
  return sum + pix1 * weight1.x + pix2 * weight1.y + pix3 * weight1.z + pix4 * weight1.w + pix5 * weight2;
kernel vec4 _convolutionInit_6(sampler src, vec4 offset12, vec4 offset34, vec4 offset56, vec4 weight1, vec2 weight2)
  vec2 coord = destCoord();
  vec4 pix1 = sample(src, samplerTransform(src, coord + offset12.xy));
  vec4 pix2 = sample(src, samplerTransform(src, coord + offset12.zw));
  vec4 pix3 = sample(src, samplerTransform(src, coord + offset34.xy));
  vec4 pix4 = sample(src, samplerTransform(src, coord + offset34.zw));
  vec4 pix5 = sample(src, samplerTransform(src, coord + offset56.xy));
  vec4 pix6 = sample(src, samplerTransform(src, coord + offset56.zw));
  return pix1 * weight1.x + pix2 * weight1.y + pix3 * weight1.z + pix4 * weight1.w + pix5 * weight2.x + pix6 * weight2.y;
kernel vec4 _convolutionAdd_6(sampler src, sampler sums, vec4 offset12, vec4 offset34, vec4 offset56, vec4 weight1, vec2 weight2)
  vec4 sum = sample(sums, samplerCoord(sums));
  vec2 coord = destCoord();
  vec4 pix1 = sample(src, samplerTransform(src, coord + offset12.xy));
  vec4 pix2 = sample(src, samplerTransform(src, coord + offset12.zw));
  vec4 pix3 = sample(src, samplerTransform(src, coord + offset34.xy));
  vec4 pix4 = sample(src, samplerTransform(src, coord + offset34.zw));
  vec4 pix5 = sample(src, samplerTransform(src, coord + offset56.xy));
  vec4 pix6 = sample(src, samplerTransform(src, coord + offset56.zw));
  return sum + pix1 * weight1.x + pix2 * weight1.y + pix3 * weight1.z + pix4 * weight1.w + pix5 * weight2.x + pix6 * weight2.y;
kernel vec4 _convolutionInit_7(sampler src, vec4 offset12, vec4 offset34, vec4 offset56, vec2 offset7, vec4 weight1, vec3 weight2)
  vec2 coord = destCoord();
  vec4 pix1 = sample(src, samplerTransform(src, coord + offset12.xy));
  vec4 pix2 = sample(src, samplerTransform(src, coord + offset12.zw));
  vec4 pix3 = sample(src, samplerTransform(src, coord + offset34.xy));
  vec4 pix4 = sample(src, samplerTransform(src, coord + offset34.zw));
  vec4 pix5 = sample(src, samplerTransform(src, coord + offset56.xy));
  vec4 pix6 = sample(src, samplerTransform(src, coord + offset56.zw));
  vec4 pix7 = sample(src, samplerTransform(src, coord + offset7));
  return pix1 * weight1.x + pix2 * weight1.y + pix3 * weight1.z + pix4 * weight1.w + pix5 * weight2.x + pix6 * weight2.y + pix7 * weight2.z;
kernel vec4 _convolutionAdd_7(sampler src, sampler sums, vec4 offset12, vec4 offset34, vec4 offset56, vec2 offset7, vec4 weight1, vec3 weight2)
  vec4 sum = sample(sums, samplerCoord(sums));
  vec2 coord = destCoord();
  vec4 pix1 = sample(src, samplerTransform(src, coord + offset12.xy));
  vec4 pix2 = sample(src, samplerTransform(src, coord + offset12.zw));
  vec4 pix3 = sample(src, samplerTransform(src, coord + offset34.xy));
  vec4 pix4 = sample(src, samplerTransform(src, coord + offset34.zw));
  vec4 pix5 = sample(src, samplerTransform(src, coord + offset56.xy));
  vec4 pix6 = sample(src, samplerTransform(src, coord + offset56.zw));
  vec4 pix7 = sample(src, samplerTransform(src, coord + offset7));
  return sum + pix1 * weight1.x + pix2 * weight1.y + pix3 * weight1.z + pix4 * weight1.w + pix5 * weight2.x + pix6 * weight2.y + pix7 * weight2.z;
kernel vec4 _convolutionInit_8(sampler src, vec4 offset12, vec4 offset34, vec4 offset56, vec4 offset78, vec4 weight1, vec4 weight2)
  vec2 coord = destCoord();
  vec4 pix1 = sample(src, samplerTransform(src, coord + offset12.xy));
  vec4 pix2 = sample(src, samplerTransform(src, coord + offset12.zw));
  vec4 pix3 = sample(src, samplerTransform(src, coord + offset34.xy));
  vec4 pix4 = sample(src, samplerTransform(src, coord + offset34.zw));
  vec4 pix5 = sample(src, samplerTransform(src, coord + offset56.xy));
  vec4 pix6 = sample(src, samplerTransform(src, coord + offset56.zw));
  vec4 pix7 = sample(src, samplerTransform(src, coord + offset78.xy));
  vec4 pix8 = sample(src, samplerTransform(src, coord + offset78.zw));
  return pix1 * weight1.x + pix2 * weight1.y + pix3 * weight1.z + pix4 * weight1.w + pix5 * weight2.x + pix6 * weight2.y + pix7 * weight2.z + pix8 * weight2.w;
kernel vec4 _convolutionAdd_8(sampler src, sampler sums, vec4 offset12, vec4 offset34, vec4 offset56, vec4 offset78, vec4 weight1, vec4 weight2)
  vec4 sum = sample(sums, samplerCoord(sums));
  vec2 coord = destCoord();
  vec4 pix1 = sample(src, samplerTransform(src, coord + offset12.xy));
  vec4 pix2 = sample(src, samplerTransform(src, coord + offset12.zw));
  vec4 pix3 = sample(src, samplerTransform(src, coord + offset34.xy));
  vec4 pix4 = sample(src, samplerTransform(src, coord + offset34.zw));
  vec4 pix5 = sample(src, samplerTransform(src, coord + offset56.xy));
  vec4 pix6 = sample(src, samplerTransform(src, coord + offset56.zw));
  vec4 pix7 = sample(src, samplerTransform(src, coord + offset78.xy));
  vec4 pix8 = sample(src, samplerTransform(src, coord + offset78.zw));
  return sum + pix1 * weight1.x + pix2 * weight1.y + pix3 * weight1.z + pix4 * weight1.w + pix5 * weight2.x + pix6 * weight2.y + pix7 * weight2.z + pix8 * weight2.w;
kernel vec4 _convolutionInit_9(sampler src, vec4 offset12, vec4 offset34, vec4 offset56, vec4 offset78, vec2 offset9, vec4 weight1, vec4 weight2, float weight3)
  vec2 coord = destCoord();
  vec4 pix1 = sample(src, samplerTransform(src, coord + offset12.xy));
  vec4 pix2 = sample(src, samplerTransform(src, coord + offset12.zw));
  vec4 pix3 = sample(src, samplerTransform(src, coord + offset34.xy));
  vec4 pix4 = sample(src, samplerTransform(src, coord + offset34.zw));
  vec4 pix5 = sample(src, samplerTransform(src, coord + offset56.xy));
  vec4 pix6 = sample(src, samplerTransform(src, coord + offset56.zw));
  vec4 pix7 = sample(src, samplerTransform(src, coord + offset78.xy));
  vec4 pix8 = sample(src, samplerTransform(src, coord + offset78.zw));
  vec4 pix9 = sample(src, samplerTransform(src, coord + offset9));
  return pix1 * weight1.x + pix2 * weight1.y + pix3 * weight1.z + pix4 * weight1.w + pix5 * weight2.x + pix6 * weight2.y + pix7 * weight2.z + pix8 * weight2.w + pix9 * weight3;
kernel vec4 _convolutionAdd_9(sampler src, sampler sums, vec4 offset12, vec4 offset34, vec4 offset56, vec4 offset78, vec2 offset9, vec4 weight1, vec4 weight2, float weight3)
  vec4 sum = sample(sums, samplerCoord(sums));
  vec2 coord = destCoord();
  vec4 pix1 = sample(src, samplerTransform(src, coord + offset12.xy));
  vec4 pix2 = sample(src, samplerTransform(src, coord + offset12.zw));
  vec4 pix3 = sample(src, samplerTransform(src, coord + offset34.xy));
  vec4 pix4 = sample(src, samplerTransform(src, coord + offset34.zw));
  vec4 pix5 = sample(src, samplerTransform(src, coord + offset56.xy));
  vec4 pix6 = sample(src, samplerTransform(src, coord + offset56.zw));
  vec4 pix7 = sample(src, samplerTransform(src, coord + offset78.xy));
  vec4 pix8 = sample(src, samplerTransform(src, coord + offset78.zw));
  vec4 pix9 = sample(src, samplerTransform(src, coord + offset9));
  return sum + pix1 * weight1.x + pix2 * weight1.y + pix3 * weight1.z + pix4 * weight1.w + pix5 * weight2.x + pix6 * weight2.y + pix7 * weight2.z + pix8 * weight2.w + pix9 * weight3;
kernel vec4 _combine_results(__sample box, __sample conv, float box_scale, float inv_scale)
  return (box_scale * box * inv_scale) + conv;
CIConvolution
inputLinearFilterModeEnabled
inputPoints
CIBoxBlur
size = %d, center = %d, %d, I = %g, Q = %g
Ti,R,Vsize
centerX
Ti,R,VcenterX
centerY
Ti,R,VcenterY
Td,R,VI
Td,R,VQ
kernel vec2 _droste(vec2 center, vec2 r, float logScale, vec2 rotzoom, vec2 innerSizeHalved)
  vec2 c = destCoord() - center;
  float theta = atan(c.y, c.x) + rotzoom.x;
  vec2 polar = vec2(0.5 * log(dot(c,c)), theta);
  vec2 rotated = vec2( polar.x * r.x - polar.y * r.y, dot(polar, r.yx));
  vec2 coord = exp(rotated.x) * cossin(rotated.y);
  coord *= rotzoom.y;
  float d0 = max(abs(coord.x)/innerSizeHalved.x,
                 abs(coord.y)/innerSizeHalved.y);
  float myMod; { 
    float a = log(d0); 
    float b = logScale; 
    myMod = a - b*floor(a/b); 
  } 
  float d1 = exp(myMod);
  coord *= ( d1 / d0 );
  return coord + center;
inputInsetPoint0
inputInsetPoint1
inputPeriodicity
inputStrands
inputRotation
inputZoom
com.apple.coreimage.compositeKernelIsolation
T@"CIImage",&,N,VinputBackgroundImage
kernel vec4 _sourceOver(__sample src, __sample dst) { return src + dst*(1.0 - src.a); }
kernel vec4 _sourceIn(__sample src, __sample dst) { return src*dst.a; }
kernel vec4 _sourceOut(__sample src, __sample dst) { return src*(1.0-dst.a); }
kernel vec4 _sourceAtop(__sample src, __sample dst) { return src * dst.a + dst * (1.0 - src.a); }
kernel vec4 _addition(__sample src, __sample dst) { return src + dst; }
kernel vec4 _multiply(__sample src, __sample dst) { return src * dst; }
kernel vec4 _minimum(__sample src, __sample dst) { return min(src, dst); }
kernel vec4 _maximum(__sample src, __sample dst) { return max(src, dst); }
kernel vec4 _plusDarker(__sample src, __sample dst)
  vec4 R = src + dst;
  R.rgb = R.a - R.rgb;
  R = clamp(R, 0.0, 1.0);
  R.rgb = R.a - R.rgb;
  return R;
kernel vec4 _plusLighter(__sample src, __sample dst) { return src + dst; }
bytes
width
height
green
blue
alpha
bounds
faceBalanceEnabled
TB,VfaceBalanceEnabled
vibranceEnabled
TB,VvibranceEnabled
curvesEnabled
TB,VcurvesEnabled
shadowsEnabled
TB,VshadowsEnabled
kernel vec4 _curve16 (__sample s, sampler2D curveImage, vec2 normalizer)
  s.rgb = normalizer.x * s.rgb + normalizer.y;
  vec2 v = texture2D(curveImage, vec2(s.r , 0.5)).rg;
  s.r = 0.9961089494 * v.r + 0.0038910506 * v.g;
  v = texture2D(curveImage, vec2(s.g, 0.5)).rg;
  s.g = 0.9961089494 * v.r + 0.0038910506 * v.g;
  v = texture2D(curveImage, vec2(s.b, 0.5)).rg;
  s.b = 0.9961089494 * v.r + 0.0038910506 * v.g;
  return s;
%d, %d
Curve0x
Curve0y
Curve1x
Curve1y
Curve2x
Curve2y
Curve3x
Curve3y
Curve4x
Curve4y
ToneCurve
ToneCurveName
Custom
T@"CIVector",C,N,VinputPoint0
T@"CIVector",C,N,VinputPoint1
T@"CIVector",C,N,VinputPoint2
T@"CIVector",C,N,VinputPoint3
T@"CIVector",C,N,VinputPoint4
CIFilterAddedNotification
CIConstructorKey
CIAccordionFoldTransition
CIAdditionCompositing
CIAffineClamp
CIAffineTile
CIAreaAverage
CIAreaHistogram
CIAreaMaximum
CIAreaMaximumAlpha
CIAreaMinimum
CIAreaMinimumAlpha
CIRowAverage
CIAztecCodeGenerator
CIBarsSwipeTransition
CIBlendWithMask
CIBlendWithAlphaMask
CIBloom
CIBumpDistortion
CIBumpDistortionLinear
CICheatBlur
CICheapBlur
CICheapMorphology
CICheckerboardGenerator
CICircleGenerator
CICircleSplashDistortion
CICircularScreen
CICircularWrap
CIClamp
CICMYKHalftone
CICode128BarcodeGenerator
CIColorBalance
CIColorBlendMode
CIColorBurnBlendMode
CIColorClamp
CIColorCrossPolynomial
CIColorCube
CIColorDodgeBlendMode
CIColorInvert
CIColorMap
CIColorMonochrome
CIColorPolynomial
CIColorPosterize
CIComicEffect
CIConstantColorGenerator
CIConvolution3X3
CIConvolution5X5
CIConvolution7X7
CIConvolution9Horizontal
CIConvolution9Vertical
CICopyMachineTransition
CICrystallize
CIDarkenBlendMode
CIDepthOfField
CIDifferenceBlendMode
CIDisintegrateWithMaskTransition
CIDisplacementDistortion
CIDissolveTransition
CIDivideBlendMode
CIDotScreen
CIDroste
CIEdges
CIEdgePreserveUpsampleFilter
CIEdgeWork
CIEightfoldReflectedTile
CIExclusionBlendMode
CIFalseColor
CIFlashTransition
CIFourfoldReflectedTile
CIFourfoldRotatedTile
CIFourfoldTranslatedTile
CIGammaAdjust
CIGaussianBlurXY
CIGaussianGradient
CIGlideReflectedTile
CIGloom
CIGlassDistortion
CIGlassLozenge
CIHardLightBlendMode
CIHardMixBlendMode
CIHatchedScreen
CIHeightFieldFromMask
CIHexagonalPixellate
CIHistogramDisplayFilter
CIHoleDistortion
CIHueAdjust
CIHueBlendMode
CIHueSaturationValueGradient
CIIntegralImage
CIKaleidoscope
CILanczosScaleTransform
CILenticularHaloGenerator
CILightTunnel
CILightenBlendMode
CILinearLightBlendMode
CILineScreen
CILinearBurnBlendMode
CILinearDodgeBlendMode
CILinearGradient
CILineOverlay
CILuminosityBlendMode
CIMaskToAlpha
CIMaximumComponent
CIMaximumCompositing
CIMedianFilter
CIMinimumComponent
CIMinimumCompositing
CIMirror
CIModTransition
CIMorphologyGradient
CIMorphologyLaplacian
CIMotionBlur
CIMultiplyBlendMode
CIMultiplyCompositing
CINinePartStretched
CINinePartTiled
CINoiseReduction
CIOpacity
CIOpTile
CIOverlayBlendMode
CIPDF417BarcodeGenerator
CIPageCurlTransition
CIPageCurlWithShadowTransition
CIParallelogramTile
CIPerspectiveTile
CIPerspectiveTransform
CIPerspectiveTransformWithExtent
CIPerspectiveCorrection
CIPhotoEffectNoir
CIPhotoEffectChrome
CIPhotoEffectFade
CIPhotoEffectInstant
CIPhotoEffectMono
CIPhotoEffectProcess
CIPhotoEffectTonal
CIPhotoEffectTransfer
CIPinLightBlendMode
CIPinchDistortion
CIPixellate
CIPointillize
CIPremultiply
CIProSharpenEdges
CIPseudoMedian
CIQRCodeGenerator
CIRadialGradient
CIRandomGenerator
CIRectangleGenerator
CIRippleTransition
CISaturationBlendMode
CIScreenBlendMode
CISepiaTone
CIShadedMaterial
CISharpenLuminance
CISimpleTile
CISixfoldReflectedTile
CISixfoldRotatedTile
CISkyAndGrassAdjust
CISmartColorFilter
CISmartToneFilter
CISmoothLinearGradient
CISpotColor
CISpotLight
CISoftLightBlendMode
CISourceAtopCompositing
CISourceInCompositing
CISourceOutCompositing
CIStarShineGenerator
CIStraightenFilter
CIStretch
CIStretchCrop
CIStripesGenerator
CISubtractBlendMode
CISunbeamsGenerator
CISwipeTransition
CITemperatureAndTint
CIThermal
CITorusLensDistortion
CITriangleKaleidoscope
CITriangleTile
CITwelvefoldReflectedTile
CITwirlDistortion
CIUnpremultiply
CIVariableBoxBlur
CIVignette
CIVignetteEffect
CIVividLightBlendMode
CIVortexDistortion
CIWhitePointAdjust
CIWrapMirror
CIXRay
CIZoomBlur
CUIScaleClampFilter
CUIOuterBevelEmbossFilter
CUIOuterGlowOrShadowFilter
CUIInnerBevelEmbossFilter
CUIInnerGlowOrShadowFilter
CUIShapeEffectBlur1
CIPlusDarkerCompositing
CIPlusLighterCompositing
CIMaskedVariableBlur
CISmartBlackAndWhite
CIPhotoGrain
CIPassThroughColorFilter
CIPassThroughWarpFilter
CIPassThroughGeneralFilter
CIPassThroughGeneralAltFilter
CIPassThroughIntermediateFilter
[CIFilter registerFilterName:constructor:classAttributes:] needs a name parameter.
[CIFilter registerFilterName:constructor:classAttributes:] registration of '%@' should provide a contructor object or class.
[CIFilter registerFilterName:constructor:classAttributes:] registration of '%@' should not provide a contructor class that is just [CIFilter class].
filterWithName:
[CIFilter registerFilterName:constructor:classAttributes:] registration of '%@' needs a constructor object or class that implements filterWithName:
[CIFilter registerFilterName:constructor:classAttributes:] registration of '%@' needs a constructor object or class that overrides filterWithName:
Categories
Descriptions
%s [constructor filterWithName:%@] returned nil.
+[CIFilter(CIFilterRegistryPrivate) filterWithName:setDefaults:]
%s [constructor filterWithName:%@] returned an object of class %@.
__64+[CIFilter(CIFilterRegistryPrivate) filterWithName:setDefaults:]_block_invoke.560
http://developer.apple.com/library/ios/documentation/GraphicsImaging/Reference/CoreImageFilterReference/index.html#//apple_ref/doc/filter/ci/%@
Keys
<none>
%@.%@
input
output
<%@: inputKeys=%@ inputClasses=%@ outputKeys=%@>
com.apple.coreimage.CIFilterRegistryIsolation
customAttributes
%@ -customAttributes is not supported on iOS. Implement +customAttributes instead.
iIsSlLqQBfdcC
NSObject
kernel vec4 _highlightsAndShadows2(__sample pix, __sample blur, vec4 params)
  float rgbFactor = dot(vec3(1.0, 0.8, 1.1), max(pix.rgb, 0.0)) / max( 0.001, pix.r + pix.g + pix.b); 
  float shadAmt = params.x * pow(min(rgbFactor, 1.0), 1.0-params.x); 
  vec3 shadExp = mix(pow(vec3(2.0), (-shadAmt - blur.rgb)), vec3(1.0), params.z); 
  float blurLum2 = max(0.0, max(max(blur.r, blur.g), blur.b)); 
  float blurLum = sqrt(blurLum2); 
  float kGain = 0.5 + 0.5*smoothstep(0.5, 1.0, params.x); 
  float newGain = shadAmt; 
  vec3 neg = min(pix.rgb, 0.0); 
  vec3 shad = (1.0+newGain)*pow(max(pix.rgb, 0.0)*kGain, shadExp)*2.0; 
  vec3 ycc = pix.r * vec3(0.299, 0.596, 0.212) + 
             pix.g * vec3(0.587, -0.2755, -0.523) + 
             pix.b * vec3(0.114, -0.321, 0.311); 
  float Y = pow(max(ycc.r, 0.0)*kGain, shadExp.r)*2.0; 
  vec3 shad2 = Y * vec3(1.00048, 0.999864, 0.999446) + 
           ycc.g * vec3(0.955558, -0.271545, -1.10803) + 
           ycc.b * vec3(0.619549, -0.646786, 1.70542); 
  shad = mix(shad, shad2, 0.35); 
  shad = mix(pix.rgb, shad, (smoothstep(0.0, 0.1+shadAmt, sqrt(blurLum)))); 
  shad = mix(shad, pix.rgb, blurLum); 
  vec3 high = sign(pix.rgb)*pow(abs(pix.rgb)*params.w, vec3((2.0 - params.y))); 
  Y = dot(high, vec3(0.299, 0.587, 0.114)); 
  float effectAmount = max(max(-2.6*Y*Y - 2.6*Y + 0.98, -6.25*Y*Y - 6.25*Y + 0.5965), 1.0); 
  float kHighMix = 1.0 + (1.0-min(1.0, params.y+0.3))*0.4; 
  vec3 mid = mix(vec3(0.25), high, kHighMix); 
  float highBoost = min(effectAmount, 30.0*blurLum2) * (1.0-params.y); 
  high = mix(high, mid, highBoost); 
  high = mix(pix.rgb, high, smoothstep(0.2, 0.8, blurLum)); 
  high = mix(pix.rgb, high, blurLum2); 
  vec4 result; 
  result.rgb = mix(shad, high, min(blurLum, 1.0)); 
  Y = dot(result.rgb, vec3(0.299, 0.587, 0.114)); 
  effectAmount = max(max(-2.6*Y*Y - 2.6*Y + 0.98, -6.25*Y*Y - 6.25*Y + 0.5965), 1.0); 
  float midAmt = abs(shadAmt)*0.1*(1.0-params.z); 
  mid = mix(vec3(0.5), result.rgb, 1.0 + midAmt); 
  result.rgb = mix(result.rgb, mid, min(effectAmount, 30.0*blurLum2)); 
  result.rgb = max(result.rgb, 0.0)+neg; 
  result.a = pix.a; 
  return result; 
kernel vec4 _highlightsAndShadows_noblur2(__sample pix, vec4 params)
  vec4 blur = pix; 
  float rgbFactor = dot(vec3(1.0, 0.8, 1.1), max(pix.rgb, 0.0)) / max( 0.001, pix.r + pix.g + pix.b); 
  float shadAmt = params.x * pow(min(rgbFactor, 1.0), 1.0-params.x); 
  vec3 shadExp = mix(pow(vec3(2.0), (-shadAmt - blur.rgb)), vec3(1.0), params.z); 
  float blurLum2 = max(0.0, max(max(blur.r, blur.g), blur.b)); 
  float blurLum = sqrt(blurLum2); 
  float kGain = 0.5 + 0.5*smoothstep(0.5, 1.0, params.x); 
  float newGain = shadAmt; 
  vec3 neg = min(pix.rgb, 0.0); 
  vec3 shad = (1.0+newGain)*pow(max(pix.rgb, 0.0)*kGain, shadExp)*2.0; 
  vec3 ycc = pix.r * vec3(0.299, 0.596, 0.212) + 
             pix.g * vec3(0.587, -0.2755, -0.523) + 
             pix.b * vec3(0.114, -0.321, 0.311); 
  float Y = sign(ycc.r)*pow(abs(ycc.r)*kGain, shadExp.r)*2.0; 
  vec3 shad2 = Y * vec3(1.00048, 0.999864, 0.999446) + 
           ycc.g * vec3(0.955558, -0.271545, -1.10803) + 
           ycc.b * vec3(0.619549, -0.646786, 1.70542); 
  shad = mix(shad, shad2, 0.35); 
  shad = mix(pix.rgb, shad, (smoothstep(0.0, 0.1+shadAmt, sqrt(blurLum)))); 
  shad = mix(shad, pix.rgb, blurLum); 
  vec3 high = sign(pix.rgb)*pow(abs(pix.rgb)*params.w, vec3((2.0 - params.y))); 
  Y = dot(high, vec3(0.299, 0.587, 0.114)); 
  float effectAmount = max(max(-2.6*Y*Y - 2.6*Y + 0.98, -6.25*Y*Y - 6.25*Y + 0.5965), 1.0); 
  float kHighMix = 1.0 + (1.0-min(1.0, params.y+0.3))*0.4; 
  vec3 mid = mix(vec3(0.25), high, kHighMix); 
  float highBoost = min(effectAmount, 30.0*blurLum2) * (1.0-params.y); 
  high = mix(high, mid, highBoost); 
  high = mix(pix.rgb, high, smoothstep(0.2, 0.8, blurLum)); 
  high = mix(pix.rgb, high, blurLum2); 
  vec4 result; 
  result.rgb = mix(shad, high, min(blurLum, 1.0)); 
  Y = dot(result.rgb, vec3(0.299, 0.587, 0.114)); 
  effectAmount = max(max(-2.6*Y*Y - 2.6*Y + 0.98, -6.25*Y*Y - 6.25*Y + 0.5965), 1.0); 
  float midAmt = abs(shadAmt)*0.1*(1.0-params.z); 
  mid = mix(vec3(0.5), result.rgb, 1.0 + midAmt); 
  result.rgb = mix(result.rgb, mid, min(effectAmount, 30.0*blurLum2)); 
  result.rgb = max(result.rgb, 0.0)+neg; 
  result.a = pix.a; 
  return result; 
kernel vec4 _highlightsAndShadows1(__sample pix, __sample blur, vec4 params)
  float rgbFactor = dot(vec3(1.0, 0.8, 1.1), max(pix.rgb, 0.0)) / max( 0.001, pix.r + pix.g + pix.b); 
  float shadAmt = params.x * pow(min(rgbFactor, 1.0), 1.0-params.x); 
  vec3 shadExp = mix(pow(vec3(2.0), (-shadAmt - blur.rgb)), vec3(1.0), params.z); 
  float blurLum2 = max(0.0, max(max(blur.r, blur.g), blur.b)); 
  float blurLum = sqrt(blurLum2); 
  float kGain = 0.5 + 0.5*smoothstep(0.5, 1.0, params.x); 
  vec3 shad = sign(pix.rgb)*pow(abs(pix.rgb)*kGain, shadExp)*2.0; 
  vec3 ycc = pix.r * vec3(0.299, 0.596, 0.212) + 
             pix.g * vec3(0.587, -0.2755, -0.523) + 
             pix.b * vec3(0.114, -0.321, 0.311); 
  float Y = sign(ycc.r)*pow(abs(ycc.r)*kGain, shadExp.r)*2.0; 
  vec3 shad2 = Y * vec3(1.00048, 0.999864, 0.999446) + 
           ycc.g * vec3(0.955558, -0.271545, -1.10803) + 
           ycc.b * vec3(0.619549, -0.646786, 1.70542); 
  shad = mix(shad, shad2, 0.35); 
  shad = mix(pix.rgb, shad, sqrt(smoothstep(0.0, 0.1+shadAmt, sqrt(blurLum)))); 
  shad = mix(shad, pix.rgb, blurLum); 
  vec3 high = sign(pix.rgb)*pow(abs(pix.rgb)*params.w, vec3((2.0 - params.y))); 
  Y = dot(high, vec3(0.299, 0.587, 0.114)); 
  float effectAmount = max(max(-2.6*Y*Y - 2.6*Y + 0.98, -6.25*Y*Y - 6.25*Y + 0.5965), 1.0); 
  float kHighMix = 1.0 + (1.0-min(1.0, params.y+0.3))*0.4; 
  vec3 mid = mix(vec3(0.25), high, kHighMix); 
  float highBoost = min(effectAmount, 30.0*blurLum2) * (1.0-params.y); 
  high = mix(high, mid, highBoost); 
  high = mix(pix.rgb, high, smoothstep(0.2, 0.8, blurLum)); 
  high = mix(pix.rgb, high, blurLum2); 
  vec4 result; 
  result.rgb = mix(shad, high, min(blurLum, 1.0)); 
  Y = dot(result.rgb, vec3(0.299, 0.587, 0.114)); 
  effectAmount = max(max(-2.6*Y*Y - 2.6*Y + 0.98, -6.25*Y*Y - 6.25*Y + 0.5965), 1.0); 
  float midAmt = abs(shadAmt)*0.1*(1.0-params.z); 
  mid = mix(vec3(0.5), result.rgb, 1.0 + midAmt); 
  result.rgb = mix(result.rgb, mid, min(effectAmount, 30.0*blurLum2)); 
  result.a = pix.a; 
  return result; 
kernel vec4 _highlightsAndShadows_noblur1(__sample pix, vec4 params)
  vec4 blur = pix; 
  float rgbFactor = dot(vec3(1.0, 0.8, 1.1), max(pix.rgb, 0.0)) / max( 0.001, pix.r + pix.g + pix.b); 
  float shadAmt = params.x * pow(min(rgbFactor, 1.0), 1.0-params.x); 
  vec3 shadExp = mix(pow(vec3(2.0), (-shadAmt - blur.rgb)), vec3(1.0), params.z); 
  float blurLum2 = max(0.0, max(max(blur.r, blur.g), blur.b)); 
  float blurLum = sqrt(blurLum2); 
  float kGain = 0.5 + 0.5*smoothstep(0.5, 1.0, params.x); 
  vec3 shad = sign(pix.rgb)*pow(abs(pix.rgb)*kGain, shadExp)*2.0; 
  vec3 ycc = pix.r * vec3(0.299, 0.596, 0.212) + 
             pix.g * vec3(0.587, -0.2755, -0.523) + 
             pix.b * vec3(0.114, -0.321, 0.311); 
  float Y = sign(ycc.r)*pow(abs(ycc.r)*kGain, shadExp.r)*2.0; 
  vec3 shad2 = Y * vec3(1.00048, 0.999864, 0.999446) + 
           ycc.g * vec3(0.955558, -0.271545, -1.10803) + 
           ycc.b * vec3(0.619549, -0.646786, 1.70542); 
  shad = mix(shad, shad2, 0.35); 
  shad = mix(pix.rgb, shad, sqrt(smoothstep(0.0, 0.1+shadAmt, sqrt(blurLum)))); 
  shad = mix(shad, pix.rgb, blurLum); 
  vec3 high = sign(pix.rgb)*pow(abs(pix.rgb)*params.w, vec3((2.0 - params.y))); 
  Y = dot(high, vec3(0.299, 0.587, 0.114)); 
  float effectAmount = max(max(-2.6*Y*Y - 2.6*Y + 0.98, -6.25*Y*Y - 6.25*Y + 0.5965), 1.0); 
  float kHighMix = 1.0 + (1.0-min(1.0, params.y+0.3))*0.4; 
  vec3 mid = mix(vec3(0.25), high, kHighMix); 
  float highBoost = min(effectAmount, 30.0*blurLum2) * (1.0-params.y); 
  high = mix(high, mid, highBoost); 
  high = mix(pix.rgb, high, smoothstep(0.2, 0.8, blurLum)); 
  high = mix(pix.rgb, high, blurLum2); 
  vec4 result; 
  result.rgb = mix(shad, high, min(blurLum, 1.0)); 
  Y = dot(result.rgb, vec3(0.299, 0.587, 0.114)); 
  effectAmount = max(max(-2.6*Y*Y - 2.6*Y + 0.98, -6.25*Y*Y - 6.25*Y + 0.5965), 1.0); 
  float midAmt = abs(shadAmt)*0.1*(1.0-params.z); 
  mid = mix(vec3(0.5), result.rgb, 1.0 + midAmt); 
  result.rgb = mix(result.rgb, mid, min(effectAmount, 30.0*blurLum2)); 
  result.a = pix.a; 
  return result; 
kernel vec4 _highlightsAndShadows0(__sample pix, __sample blur, vec4 params)
  float rgbFactor = dot(vec3(1.0, 0.8, 1.1), max(pix.rgb, 0.0)) / max(0.001, pix.r + pix.g + pix.b); 
  rgbFactor = clamp(rgbFactor, 0.0, 1.0); 
  float shadAmt = params.x * pow(rgbFactor, max(0.0,(1.0-params.x))); 
  vec3 clamped = clamp(pix.rgb, 0.00001, 0.99999); 
  float gray = (clamped.r + clamped.g + clamped.b) * 0.33333; 
  float gi   = 1.0 / gray;
  float gii  = 1.0 / (1.0 - gray);
  float rgbsat = max((clamped.r - gray) * gii, (gray - clamped.r) * gi); 
  float skin = min(1.0, max(0.0, min(clamped.r - clamped.g, clamped.g * 2.0 - clamped.b)) * 4.0 * (1.0 - rgbsat) * gi); 
  skin = 0.15 + skin * 0.7; 
  vec3 rgbExp = pow(vec3(2.0), (-shadAmt - blur.rgb)); 
  float uniformExp = min(rgbExp.r, min(rgbExp.g, rgbExp.b)); 
  vec3 shadExp = mix(rgbExp, vec3(uniformExp), skin); 
  float nopMix = params.z; 
  shadExp = mix(shadExp, vec3(1.0, 1.0, 1.0), nopMix); 
  vec3 shad = sign(pix.rgb)*pow(abs(pix.rgb)*0.5, shadExp)*2.0; 
  float maxChan = max(0.0, max(max(blur.r, blur.g), blur.b)); 
  float blurLum = sqrt(maxChan); 
  float origPercent = sqrt( smoothstep(0.0, 0.1 + 0.5*shadAmt*shadAmt, blurLum) ); 
  origPercent *= (1.0-origPercent); 
  shad = mix(shad, pix.rgb, origPercent); 
  vec3 high = sign(pix.rgb)*pow(abs(pix.rgb)*params.w, vec3((2.0 - params.y))); 
  origPercent = 1.0 - smoothstep(0.2, 0.8, blurLum); 
  high = mix(high, pix.rgb, origPercent); 
  vec4 result; 
  result.rgb = mix(shad, high, blurLum); 
  float Y = dot(result.rgb, vec3(0.299, 0.587, 0.114)); 
  float effectAmount = max(max(-2.6*Y*Y - 2.6*Y + 0.98, -6.25*Y*Y - 6.25*Y + 0.5965), 1.0); 
  vec3 mid = mix(vec3(0.5), result.rgb, 1.0 + abs(shadAmt)*0.05); 
  result.rgb = mix(result.rgb, mid.rgb, min(effectAmount, 30.0*blurLum*blurLum)); 
  result.a = pix.a; 
  return result;
kernel vec4 _highlightsAndShadows_noblur0(__sample pix, vec4 params)
  vec4 blur = pix; 
  float rgbFactor = dot(vec3(1.0, 0.8, 1.1), max(pix.rgb, 0.0)) / max(0.001, pix.r + pix.g + pix.b); 
  rgbFactor = clamp(rgbFactor, 0.0, 1.0); 
  float shadAmt = params.x * pow(rgbFactor, max(0.0,(1.0-params.x))); 
  vec3 clamped = clamp(pix.rgb, 0.00001, 0.99999); 
  float gray = (clamped.r + clamped.g + clamped.b) * 0.33333; 
  float gi   = 1.0 / gray;
  float gii  = 1.0 / (1.0 - gray);
  float rgbsat = max((clamped.r - gray) * gii, (gray - clamped.r) * gi); 
  float skin = min(1.0, max(0.0, min(clamped.r - clamped.g, clamped.g * 2.0 - clamped.b)) * 4.0 * (1.0 - rgbsat) * gi); 
  skin = 0.15 + skin * 0.7; 
  vec3 rgbExp = pow(vec3(2.0), (-shadAmt - blur.rgb)); 
  float uniformExp = min(rgbExp.r, min(rgbExp.g, rgbExp.b)); 
  vec3 shadExp = mix(rgbExp, vec3(uniformExp), skin); 
  float nopMix = params.z; 
  shadExp = mix(shadExp, vec3(1.0, 1.0, 1.0), nopMix); 
  vec3 shad = sign(pix.rgb)*pow(abs(pix.rgb)*0.5, shadExp)*2.0; 
  float maxChan = max(0.0, max(max(blur.r, blur.g), blur.b)); 
  float blurLum = sqrt(maxChan); 
  float origPercent = sqrt( smoothstep(0.0, 0.1 + 0.5*shadAmt*shadAmt, blurLum) ); 
  origPercent *= (1.0-origPercent); 
  shad = mix(shad, pix.rgb, origPercent); 
  vec3 high = sign(pix.rgb)*pow(abs(pix.rgb)*params.w, vec3((2.0 - params.y))); 
  origPercent = 1.0 - smoothstep(0.2, 0.8, blurLum); 
  high = mix(high, pix.rgb, origPercent); 
  vec4 result; 
  result.rgb = mix(shad, high, blurLum); 
  float Y = dot(result.rgb, vec3(0.299, 0.587, 0.114)); 
  float effectAmount = max(max(-2.6*Y*Y - 2.6*Y + 0.98, -6.25*Y*Y - 6.25*Y + 0.5965), 1.0); 
  vec3 mid = mix(vec3(0.5), result.rgb, 1.0 + abs(shadAmt)*0.05); 
  result.rgb = mix(result.rgb, mid.rgb, min(effectAmount, 30.0*blurLum*blurLum)); 
  result.a = pix.a; 
  return result;
kernel vec4 shadows_noblur(__sample pix, vec4 params)
  vec4 blur = pix; 
  float rgbFactor = dot(vec3(1.0, 0.8, 1.1), max(pix.rgb, 0.0)) / max(0.001, pix.r + pix.g + pix.b); 
  rgbFactor = clamp(rgbFactor, 0.0, 1.0); 
  float shadAmt = params.x * pow(rgbFactor, max(0.0,(1.0-params.x))); 
  vec3 clamped = clamp(pix.rgb, 0.00001, 0.99999); 
  float gray = (clamped.r + clamped.g + clamped.b) * 0.33333; 
  float gi   = 1.0 / gray;
  float gii  = 1.0 / (1.0 - gray);
  float rgbsat = max((clamped.r - gray) * gii, (gray - clamped.r) * gi); 
  float skin = min(1.0, max(0.0, min(clamped.r - clamped.g, clamped.g * 2.0 - clamped.b)) * 4.0 * (1.0 - rgbsat) * gi); 
  skin = 0.15 + skin * 0.7; 
  vec3 rgbExp = pow(vec3(2.0), (-shadAmt - blur.rgb)); 
  float uniformExp = min(rgbExp.r, min(rgbExp.g, rgbExp.b)); 
  vec3 shadExp = mix(rgbExp, vec3(uniformExp), skin); 
  float nopMix = params.z; 
  shadExp = mix(shadExp, vec3(1.0, 1.0, 1.0), nopMix); 
  vec3 shad = sign(pix.rgb)*pow(abs(pix.rgb)*0.5, shadExp)*2.0; 
  float maxChan = max(0.0, max(max(blur.r, blur.g), blur.b)); 
  float blurLum = sqrt(maxChan); 
  float origPercent = sqrt( smoothstep(0.0, 0.1 + 0.5*shadAmt*shadAmt, blurLum) ); 
  origPercent *= (1.0-origPercent); 
  shad = mix(shad, pix.rgb, origPercent); 
  vec4 result; 
  result.rgb = mix(shad, pix.rgb, blurLum); 
  float Y = dot(result.rgb, vec3(0.299, 0.587, 0.114)); 
  float effectAmount = max(max(-2.6*Y*Y - 2.6*Y + 0.98, -6.25*Y*Y - 6.25*Y + 0.5965), 1.0); 
  vec3 mid = mix(vec3(0.5), result.rgb, 1.0 + abs(shadAmt)*0.05); 
  result.rgb = mix(result.rgb, mid.rgb, min(effectAmount, 30.0*blurLum*blurLum)); 
  result.a = pix.a; 
  return result;
Shadows
Highlights
FillLight
T@"NSNumber",&,N,VinputShadowAmount
T@"NSNumber",&,N,VinputHighlightAmount
/System/Library/PrivateFrameworks/Futhark.framework
%s%@
SIMULATOR_ROOT
FKTextDetector
FKTextDetector not loaded
Unknown CIDetectorMinFeatureSize specified. Ignoring.
Text detection failed with error: %@
context
T@"CIContext",&,N,Vcontext
ASCII
%@;%@
kernel vec4 _rippleTransition (sampler src1, sampler src2, sampler emap, vec2 center, vec4 parms, vec2 emapscaling)
  vec2 dest = destCoord();
  vec2 delta = dest - center;
  float delta_length = length(delta);
  vec2 unit = delta / delta_length;
  float scaled = (delta_length - parms.x) * parms.y;
  vec4 normalized_radius = vec4(scaled * parms.z) + vec4(-0.0, -1.0, -2.0, -3.0);
  vec4 smoothed = smoothstep(0.0, 1.0, clamp(normalized_radius.xyzy, 0.0, 1.0));
  vec4 cubic = smoothed * vec4(1.0, -2.0, 1.0, 1.0) + vec4(0.0, 1.0, -1.0, 0.0);
  smoothed = compare(vec4(normalized_radius.x), vec4(0.0), vec4(cubic.x));
  smoothed = compare(vec4(normalized_radius.y), smoothed, vec4(cubic.y));
  smoothed = compare(vec4(normalized_radius.z), smoothed, vec4(cubic.z));
  normalized_radius = compare(vec4(normalized_radius.w), vec4(smoothed), vec4(0.0));
  vec2 displacement = normalized_radius.xy * unit;
  vec2 location = displacement * parms.w + dest;
  vec2 emap_location = (displacement * 0.5 + 0.5) * emapscaling;
  vec4 pix1 = sample(src1, samplerTransform(src1, location));
  vec4 pix2 = sample(src2, samplerTransform(src2, location));
  vec4 emap_pix = sample(emap, samplerTransform(emap, emap_location));
  vec4 tmp = mix(pix2, pix1, cubic.w);
  emap_pix *= tmp.a;
  tmp = tmp * (1.0 - emap_pix.a) + emap_pix;
  return tmp;
10.12
integral_image_manual
/Library/Caches/com.apple.xbs/Sources/EmbeddedCoreImage_Sim/EmbeddedCoreImage-449/Framework/filters/CIIntegralImage.mm
input.format == kCIFormatRGBAf || input.format == kCIFormatRGBAh || input.format == kCIFormatBGRA8 || input.format == kCIFormatRGBA8
output.format == kCIFormatRGBAf || output.format == kCIFormatRGBAh
input.region.size.width == output.region.size.width
input.region.size.height == output.region.size.height
compute_integral_image
don't know how to create builtin kernel for type %d
_ci_affine
vec2 _ci_affine(vec4 vx, vec4 vy)
  vec4 d = vec4(destCoord(), 1.0, 0.0);
  return vec2(dot(d,vx),dot(d,vy));
_ci_crop
vec4 _ci_crop(vec4 p, vec4 rect)
  highp vec4 x = destCoord().xxyy * vec4(1.0, -1.0, 1.0, -1.0) + rect;
  x = clamp(min(x, x.yzwx), 0.0, 1.0);
  return (x.x * x.z) * p;
rect
_ci_clamp
vec2 _ci_clamp(vec4 r) { return min(max(destCoord(), r.xy), r.zw); }
_ci_srgb_to_lin
vec4 _ci_srgb_to_lin(vec4 s)
  vec4 abss = abs(s);  s.rgb = sign(s.rgb)*mix(abss.rgb*0.077399380804954, pow(abss.rgb*0.947867298578199 + 0.052132701421801, vec3(2.4)), step(0.04045, abss.rgb));
  return s;
_ci_lin_to_srgb
vec4 _ci_lin_to_srgb(vec4 s)
  vec4 abss = abs(s);  s.rgb = sign(s.rgb)*mix(abss.rgb*12.92, pow(abss.rgb, vec3(0.4166667)) * 1.055 - 0.055, step(0.0031308, abss.rgb));
  return s;
_ci_premul
vec4 _ci_premul(vec4 s) { return vec4(s.rgb*s.a, s.a); }
_ci_unpremul
vec4 _ci_unpremul(vec4 s) { return vec4(s.rgb/max(s.a,0.00001), s.a); }
_ci_clamp_to_alpha
vec4 _ci_clamp_to_alpha(vec4 s) { return clamp(s, 0.0, s.a); }
_ci_nearest
vec2 _ci_nearest() { return (floor((destCoord())) + 0.5); }
_ci_pass_thru
vec4 _ci_pass_thru (vec4 s) { return s; }
_ci_fill
vec4 _ci_fill(vec4 c) {return c;}
_ci_gamma
vec4 _ci_gamma(vec4 s, float power)
  s.rgb = pow(max(vec3(0.0), s.rgb), vec3(power));
  return s;
power
_ci_sqr
vec4 _ci_sqr(vec4 s)
  s.rgb = max(vec3(0.0), s.rgb);
  s.rgb *= s.rgb;
  return s;
_ci_pow4
vec4 _ci_pow4(vec4 s)
  s.rgb = max(vec3(0.0), s.rgb);
  s.rgb = s.rgb * s.rgb * s.rgb * s.rgb;
  return s;
_ci_sqrt
vec4 _ci_sqrt(vec4 s)
  s.rgb = sqrt(max(vec3(0.0), s.rgb));
  return s;
_ci_curv
vec4 _ci_curv(vec4 s, vec4 p0, vec3 p1)
  float power = p0.x; 
  float a = p0.y, b = p0.z, c = p0.w; 
  float d = p1.x, e = p1.y, f = p1.z; 
  vec3 hi = pow(max(vec3(0.0), s.rgb * a + b), vec3(power)) + e; 
  vec3 lo = s.rgb * c + f; 
  s.rgb = mix(lo, hi, step(d, s.rgb));
  return s;}
_ci_colormatrix_canonical
vec4 _ci_colormatrix_canonical (vec4 s, vec4 r0, vec4 r1, vec4 r2) 
  s.rgb /= max(s.a, 0.00001);
  s.rgb = vec3(dot(s,r0), dot(s,r1), dot(s,r2)); 
  s.rgb *= s.a;
  return s;
_ci_colormatrix
vec4 _ci_colormatrix (vec4 s, vec4 c0, vec4 c1, vec4 c2, vec4 c3, vec4 bias) 
  s.rgb /= max(s.a, 0.00001);
  s = s.r*c0 + s.g*c1 + s.b*c2 + s.a*c3 + bias;
  s.rgb *= s.a;
  return s;
_ci_colormatrix3x4
vec4 _ci_colormatrix3x4 (vec4 s, vec4 c0, vec4 c1, vec4 c2) 
{ s.rgb = s.r*c0.rgb + s.g*c1.rgb + s.b*c2.rgb + s.a*vec3(c0.a,c1.a,c2.a); return s; }
_ci_colormatrix3x3
vec4 _ci_colormatrix3x3 (vec4 s, vec3 col0, vec3 col1, vec3 col2)
  s.rgb = s.r*col0 + s.g*col1 + s.b*col2;
  return s;
col0
col1
col2
_ci_colormatrix3x1
vec4 _ci_colormatrix3x1 (vec4 s, vec3 v) { return vec4(vec3(dot(s.rgb, v)), s.a); }
_ci_colormatrix_rrra
vec4 _ci_colormatrix_rrra(vec4 s) { return s.rrra; }
_ci_colormatrixdiag
vec4 _ci_colormatrixdiag (vec4 s, vec3 diag) 
  s.rgb *= diag;
  return s;
diag
_ci_colormatrixdiag4
vec4 _ci_colormatrixdiag4 (vec4 s, vec4 diag) 
  return s * diag;
_ci_divx
vec4 _ci_divx (vec4 a, vec4 b, float d) { return (destCoord().x < d) ? a : b; }
_ci_divy
vec4 _ci_divy (vec4 a, vec4 b, float d) { return (destCoord().y < d) ? a : b; }
_ci_aaaa
vec4 _ci_aaaa (vec4 s) { return s.aaaa; }
_ci_rrrr
vec4 _ci_rrrr (vec4 s) { return s.rrrr; }
_ci_000r
vec4 _ci_000r (vec4 s) { return vec4(0.,0.,0.,s.r); }
_ci_rrr1
vec4 _ci_rrr1 (vec4 s) { return vec4(s.rrr,1.); }
_ci_r001
vec4 _ci_r001 (vec4 s) { return vec4(s.r,0.,0.,1.); }
_ci_rg01
vec4 _ci_rg01 (vec4 s) { return vec4(s.rg,0.,1.); }
_ci_a001
vec4 _ci_a001 (vec4 s) { return vec4(s.a,0.,0.,1.); }
_ci_aaa1
vec4 _ci_aaa1 (vec4 s) { return vec4(s.www,1.); }
_ci_rrrg
vec4 _ci_rrrg (vec4 s) { return s.rrrg; }
_ci_bgra
vec4 _ci_bgra (vec4 s) { return s.bgra; }
_ci_abgr
vec4 _ci_abgr (vec4 s) { return s.abgr; }
_ci_gbra
vec4 _ci_gbra (vec4 s) { return s.gbra; }
_ci_grab
vec4 _ci_grab (vec4 s) { return s.grab; }
_ci_gbar
vec4 _ci_gbar (vec4 s) { return s.gbar; }
_ci_argb
vec4 _ci_argb (vec4 s) { return s.argb; }
_ci_gra1
vec4 _ci_gra1 (vec4 s) { s = s.grab; s.a = 1.0; return s; }
_ci_arg1
vec4 _ci_arg1 (vec4 s) { s = s.argb; s.a = 1.0; return s; }
_ci_rgb1
vec4 _ci_rgb1 (vec4 s) { return vec4(s.rgb, 1.0); }
_ci_bgr1
vec4 _ci_bgr1 (vec4 s) { return vec4(s.bgr, 1.0); }
_ci_1rgb
vec4 _ci_1rgb (vec4 s) { return vec4(1.0, s.rgb); }
_ci_1bgr
vec4 _ci_1bgr (vec4 s) { return vec4(1.0, s.bgr); }
_ci_rg_to_rr1
vec4 _ci_rg_to_rr1(vec4 s) { return vec4((s.g*256.0+s.r)/257.0, 0.0, 0.0, 1.0); }
_ci_rg_to_ll1
vec4 _ci_rg_to_ll1(vec4 s) { return vec4(vec3((s.g*256.0+s.r)/257.0), 1.0); }
_ci_rg_to_a
vec4 _ci_rg_to_a(vec4 s) { return vec4(0.0, 0.0, 0.0, (s.g*256.0+s.r)/257.0); }
_ci_rg_to_i
vec4 _ci_rg_to_i(vec4 s) { return vec4((s.g*256.0+s.r)/257.0); }
_ci_la_to_rr1
vec4 _ci_la_to_rr1(vec4 s) { return vec4((s.a*256.0+s.r)/257.0, 0.0, 0.0, 1.0); }
_ci_la_to_ll1
vec4 _ci_la_to_ll1(vec4 s) { return vec4(vec3((s.a*256.0+s.r)/257.0), 1.0); }
_ci_la_to_a
vec4 _ci_la_to_a(vec4 s) { return vec4(0.0, 0.0, 0.0, (s.a*256.0+s.r)/257.0); }
_ci_la_to_i
vec4 _ci_la_to_i(vec4 s) { return vec4((s.a*256.0+s.r)/257.0); }
_ci_rgba_to_rrgg1
vec4 _ci_rgba_to_rrgg1(vec4 s) { return vec4((s.g*256.0+s.r)/257.0, (s.a*256.0+s.b)/257.0, 0.0, 1.0); }
_ci_rgba_to_llaa
vec4 _ci_rgba_to_llaa(vec4 s) { return vec4(vec3((s.g*256.0+s.r)/257.0), (s.a*256.0+s.b)/257.0); }
_ci_to_r16_as_rg8
vec4 _ci_to_r16_as_rg8(vec4 s) 
  float r = s.r*65535.0; 
  float rL = mod(r,256.0); 
  float rH = (r-rL)/256.0; 
  return vec4(rL,rH,0.0,1.0)/255.0; 
_ci_to_l16_as_rg8
vec4 _ci_to_l16_as_rg8(vec4 s) 
  const vec4 gray = vec4(0.299, 0.587, 0.114, 0.0); 
  float l = dot(s,gray)*65535.0; 
  float lL = mod(l,256.0); 
  float lH = (l-lL)/256.0; 
  return vec4(lL,lH,0.0,1.0)/255.0; 
_ci_to_rg16_as_rgba8
vec4 _ci_to_rg16_as_rgba8(vec4 s) 
  float r = s.r*65535.0; 
  float rL = mod(r,256.0); 
  float rH = (r-rL)/256.0; 
  float g = s.g*65535.0; 
  float gL = mod(g,256.0); 
  float gH = (g-gL)/256.0; 
  return vec4(rL,rH,gL,gH)/255.0; 
_ci_to_rg16_as_bgra8
vec4 _ci_to_rg16_as_bgra8(vec4 s) 
  float r = s.r*65535.0; 
  float rL = mod(r,256.0); 
  float rH = (r-rL)/256.0; 
  float g = s.g*65535.0; 
  float gL = mod(g,256.0); 
  float gH = (g-gL)/256.0; 
  return vec4(gL,rH,rL,gH)/255.0; 
_ci_to_la16_as_rgba8
vec4 _ci_to_la16_as_rgba8(vec4 s) 
  const vec4 gray = vec4(0.299, 0.587, 0.114, 0.0); 
  float l = dot(s,gray)*65535.0; 
  float lL = mod(l,256.0); 
  float lH = (l-lL)/256.0; 
  float a = s.a*65535.0; 
  float aL = mod(a,256.0); 
  float aH = (a-aL)/256.0; 
  return vec4(lL,lH,aL,aH)/255.0; 
_ci_to_la16_as_bgra8
vec4 _ci_to_la16_as_bgra8(vec4 s) 
  const vec4 gray = vec4(0.299, 0.587, 0.114, 0.0); 
  float l = dot(s,gray)*65535.0; 
  float lL = mod(l,256.0); 
  float lH = (l-lL)/256.0; 
  float a = s.a*65535.0; 
  float aL = mod(a,256.0); 
  float aH = (a-aL)/256.0; 
  return vec4(aL,lH,lL,aH)/255.0; 
_ci_rg_to_cbycry
vec4 _ci_rg_to_cbycry(sampler s) 
  vec4 c = sample(s,samplerCoord(s)); 
  float col = step(0.5, fract(destCoord().x * 0.5)); 
  float cOther = sample(s,samplerCoord(s) + vec2(1.0-2.0*col,0.0)).r; 
  vec4 r0 = vec4(c.g, c.r, cOther, 1.0); 
  vec4 r1 = vec4(c.g, cOther, c.r, 1.0); 
  return mix(r0,r1,col); 
_ci_rg_to_ycbycr
vec4 _ci_rg_to_ycbycr(sampler s) 
  vec4 c = sample(s,samplerCoord(s)); 
  float col = step(0.5, fract(destCoord().x * 0.5)); 
  float cOther = sample(s,samplerCoord(s) + vec2(1.0-2.0*col,0.0)).g; 
  vec4 r0 = vec4(c.r, c.g, cOther, 1.0); 
  vec4 r1 = vec4(c.r, cOther, c.g, 1.0); 
  return mix(r0,r1,col); 
_ci_to_YCbYCr_as_rg8
vec4 _ci_to_YCbYCr_as_rg8(vec4 s) 
  vec2 YCb = s.rg, YCr = s.rb; 
  float m = step(0.5, fract(destCoord().x * 0.5)); 
  return vec4(mix(YCb,YCr,m),0.0,1.0); 
_ci_to_CbYCrY_as_rg8
vec4 _ci_to_CbYCrY_as_rg8(vec4 s) 
  vec2 CbY = s.gr, CrY = s.br; 
  float m = step(0.5, fract(destCoord().x * 0.5)); 
  return vec4(mix(CbY,CrY,m),0.0,1.0); 
_ci_to_rgb_as_r
vec4 _ci_to_rgb_as_r (vec4 s)
  vec2 rCoord = writeCoord() * vec2(3,1);
  writeImage(s.rrrr, rCoord);
  vec2 gCoord = rCoord + vec2(1,0);
  writeImage(s.gggg, gCoord);
  vec2 bCoord = rCoord + vec2(2,0);
  writeImage(s.bbbb, bCoord);
  return s; 
_ci_to_a2bgr10_as_rgba8
vec4 _ci_to_a2bgr10_as_rgba8 (vec4 s)
  vec4 denorm = clamp(s,0.0,1.0) * vec4(vec3(1023.0), 3.0) + 0.5;
  int pixel  = int(denorm.r);
      pixel |= int(denorm.g) << 10;
      pixel |= int(denorm.b) << 20;
      pixel |= int(denorm.a) << 30;
  writePixel((pixel) & 0xFF, (pixel >> 8) & 0xFF, (pixel >> 16) & 0xFF, (pixel >> 24) & 0xFF, writeCoord());
  return s; 
_ci_to_a2rgb10_as_rgba8
vec4 _ci_to_a2rgb10_as_rgba8 (vec4 s)
  vec4 denorm = clamp(s,0.0,1.0) * vec4(vec3(1023.0), 3.0) + 0.5;
  int pixel  = int(denorm.b);
      pixel |= int(denorm.g) << 10;
      pixel |= int(denorm.r) << 20;
      pixel |= int(denorm.a) << 30;
  writePixel((pixel) & 0xFF, (pixel >> 8) & 0xFF, (pixel >> 16) & 0xFF, (pixel >> 24) & 0xFF, writeCoord());
  return s; 
_ci_to_rgb10wide_as_rgba8
vec4 _ci_to_rgb10wide_as_rgba8 (vec4 s)
  s = vec4(linear_to_srgb(s.rgb) * (511.0/1023.0) + (384.0/1023.0), 1.0);
  vec4 denorm = clamp(s,0.0,1.0) * vec4(vec3(1023.0), 3.0) + 0.5;
  int pixel  = int(denorm.b);
      pixel |= int(denorm.g) << 10;
      pixel |= int(denorm.r) << 20;
      pixel |= int(denorm.a) << 30;
  writePixel((pixel) & 0xFF, (pixel >> 8) & 0xFF, (pixel >> 16) & 0xFF, (pixel >> 24) & 0xFF, writeCoord());
  return s; 
_ci_to_420
vec4 _ci_to_420(vec4 s00, vec4 s10, vec4 s01, vec4 s11)
  vec2 pc = writeCoord();
  vec2 py = pc * vec2(2,2);
  writeImage(s00.rrrr, py);
  writeImage(s10.rrrr, py + vec2(1,0));
  writeImage(s01.rrrr, py + vec2(0,1));
  writeImage(s11.rrrr, py + vec2(1,1));
  vec4 cc = (s00 + s10 + s01 + s11) * 0.25;
  writeImagePlane(vec4(cc.gb,0.0,0.0), pc);
  return s00; 
_ci_rgb10wide
vec4 _ci_rgb10wide(vec4 s) { return vec4(srgb_to_linear((s.rgb - 384.0/1023.0) * (1023.0/511.0)), 1.0); }
_ci_bgr10wide
vec4 _ci_bgr10wide(vec4 s) { return vec4(srgb_to_linear((s.bgr - 384.0/1023.0) * (1023.0/511.0)), 1.0); }
_ci_to_rgb10wide
vec4 _ci_to_rgb10wide(vec4 s) { return vec4(linear_to_srgb(s.rgb) * (511.0/1023.0) + (384.0/1023.0), 1.0); }
_ci_to_bgr10wide
vec4 _ci_to_bgr10wide(vec4 s) { return vec4(linear_to_srgb(s.bgr) * (511.0/1023.0) + (384.0/1023.0), 1.0); }
_ci_rgba16_normalize
vec4 _ci_rgba16_normalize(vec4 s) { return s / 65535.0; }
_ci_ra01
vec4 _ci_ra01(vec4 s) { return vec4(s.ra, 0.0, 1.0); }
_ci_ycc_to_rgb
vec4 _ci_ycc_to_rgb(vec4 s) { return s.zxyw; }
_ci_swizzle_LA
vec4 _ci_swizzle_LA(vec4 s) 
  const vec4 g = vec4(0.299, 0.587, 0.114, 0.0); 
  return vec4(dot(s,g), s.a, 0., s.a); 
_ci_swizzle_to_laaa
vec4 _ci_swizzle_to_laaa(vec4 s) 
  const vec4 g = vec4(0.299, 0.587, 0.114, 0.0); 
  return vec4(dot(s,g), s.aaa); 
_ci_combine_gray
vec4 _ci_combine_gray(vec4 s0, vec4 s1, vec4 s2, vec4 s3) 
  vec4 g = vec4(0.299, 0.587, 0.114, 0.0); 
  return vec4(dot(s0,g), dot(s1,g), dot(s2,g), dot(s3,g)); 
_ci_combine_r
vec4 _ci_combine_r(vec4 s0, vec4 s1, vec4 s2, vec4 s3) { return vec4(s0.r, s1.r, s2.r, s3.r); }
_ci_combine_rg
vec4 _ci_combine_rg(vec4 s0, vec4 s1) { return vec4(s0.rg, s1.rg); }
_ci_combine_la
vec4 _ci_combine_la(vec4 s0, vec4 s1) 
  vec4 g = vec4(0.299, 0.587, 0.114, 0.0); 
  return vec4(dot(s0,g), s0.a, dot(s1,g), s1.a);
True
False
TRUE
inputNeutralGamma
inputTone
inputHue
inputGrain
inputSeed
inputScaleFactor
kernel vec4 _smartBlackAndWhite(__sample image, sampler2D hueImage, vec4 rgbWeights, vec4 normalizer)
    float scaleFactor = rgbWeights.w;
    float neutralGamma = normalizer.z;
    float phototone = normalizer.w;
    image = clamp(image, 0.0, 1.0);
    vec3 lms;
    lms.x = dot(image.rgb, vec3(0.3139902162, 0.6395129383, 0.0464975462));
    lms.y = dot(image.rgb, vec3(0.155372406, 0.7578944616, 0.0867014186));
    lms.z = dot(image.rgb, vec3(0.017752387, 0.109442094, 0.8725692246));
    lms = pow(lms, vec3(0.43));
    float i = dot(lms, vec3(0.4,0.4,0.2));
    float p = dot(lms, vec3(4.4550,-4.8510,0.3960));
    float t = dot(lms, vec3(0.8056,0.3572,-1.1628));
    float chroma = sqrt(p*p+t*t);
    float hue = 0.5 + (atan(t, p) / 6.28318530718); 
    vec2 huePt = vec2(hue * normalizer.x + normalizer.y, 0.5); 
    float exponent = scaleFactor * texture2D(hueImage, huePt).a; 
    float cd = 0.06 + 0.53*abs(i-0.5); 
    float lumDamp = smoothstep(0.0, 1.0, 25.0*i); 
    float x = smoothstep(0.0, 1.0, chroma/cd); 
    exponent = x*(1.0-i)*lumDamp*(exponent - 1.0) + 1.0; 
    float bw = dot(image.rgb, rgbWeights.rgb); 
    bw = pow(bw, exponent); 
    x = 1.0 - smoothstep(0.0, 1.0, chroma * 10.0); 
    float lumAdjust = bw*(1.0 - bw)*x*(neutralGamma - 1.0) + 1.0;
    lumAdjust = 5.0 - 4.0 * lumAdjust;
    bw = pow(bw, lumAdjust);
    float result = 1.8031*bw*bw*bw - 2.1972*bw*bw + 1.3823*bw;
    bw = mix(bw, result, -phototone);
    return vec4(bw,bw,bw,image.a);
inputISO
T@"NSNumber",C,N,VinputStrength
T@"NSNumber",C,N,VinputNeutralGamma
T@"NSNumber",C,N,VinputTone
T@"NSNumber",C,N,VinputHue
T@"NSNumber",C,N,VinputGrain
T@"NSNumber",C,N,VinputSeed
T@"NSNumber",C,N,VinputScaleFactor
There is no need to call smartBlackAndWhiteStatistics.
Just use [CIFilter filterWithName:@"CISmartBlackAndWhite"] instead.
There is no need to call smartBlackAndWhiteAdjustmentsForValue:andStatistics:.
kernel vec4 facebalance (__sample pix, vec2 delta)
  pix.rgb = pix.r * vec3(0.299,  0.595716,  0.211456) + 
            pix.g * vec3(0.587, -0.274453, -0.522591) + 
            pix.b * vec3(0.114, -0.321263,  0.311135);
  float chroma2 = min(1.0, 4.0*(pix.g*pix.g + pix.b*pix.b));
  pix.gb += delta * pow(chroma2,0.2) * (1.0-chroma2*chroma2);
  pix.rgb = pix.r * vec3(1.0) + 
            pix.g * vec3(0.956296, -0.272122, -1.10699) + 
            pix.b * vec3(0.621024, -0.647381, 1.70461); 
  return pix;
FaceBalanceOrigI
FaceBalanceOrigQ
FaceBalanceStrength
FaceBalanceWarmth
IncrementalTemperature
IncrementalTint
HasSettings
T@"NSNumber",&,N,VinputOrigI
T@"NSNumber",&,N,VinputOrigQ
T@"NSNumber",&,N,VinputStrength
T@"NSNumber",&,N,VinputWarmth
%3d 
leak testing is off
copySliceOfBitmapToBitmap: bytes per sample or samples per pixel differs!
copyBitmapToSliceOfBitmap: bytes per sample or samples per pixel differs!
bitmapToBitmapDifferenceBitmapRect: source pixel configuration illegal
initBitmask:b
initBitmask:b->body
setUpBitmask:b->body
initBitmask: bitmap record can not be allocated
initBitmask: bitmap body can not be allocated
termBitmask: bitmap was null
setBitInBitmask: coordinate out of range
bitmaskAndBitmask: bitmasks have different shapes
bitmaskOrBitmask: bitmasks have different shapes
bitmaskAndNotBitmask: bitmasks have different shapes
bitmaskMinus: bitmasks have different shapes
bitmaskBoundingBitmapRectWithSeedPoint: seed point outside bitmask
ConvertYCbCrtoREDEYEFORMAT: rowSamples is too small for CbCr bitmap
ConvertYCbCrtoREDEYEFORMAT: rowSamples is too small for Y bitmap
ConvertYCbCrtoREDEYEFORMAT: heights do not match
ConvertYCbCrtoREDEYEFORMAT: widths do not match
ConvertRedChannel2toY: rowSamples is too small for ARGB bitmap
ConvertRedChannel2toY: rowSamples is too small for CbCr bitmap
ConvertRedChannel2toY: rowSamples is too small for Y bitmap
ConvertRedChannel2toY: heights do not match
ConvertRedChannel2toY: widths do not match
ConvertRedChannel5toY: rowSamples is too small for ARGB bitmap
ConvertRedChannel5toY: rowSamples is too small for CbCr bitmap
ConvertRedChannel5toY: rowSamples is too small for Y bitmap
ConvertRedChannel5toY: heights do not match
ConvertRedChannel5toY: widths do not match
extractAlpha:alphaMap
extractAlpha:savedscans
computePupilAlphaMap:allPoints
computePupilAlphaMap:alphaMap
blurBitmapHorizontal:scan
blurBitmapVertical:scan
infill area boundary path
specular bitmask outside path
infill arcs surround arcs
specular bitmask path outside arc bodies
specular bitmask path outside arcs
arcCorrelation: improper crossing pairing at f1 %.2f
%d crossings:
  [%2d] f2 %.2f pix %.2f 
arcInfill: improper crossing pairing at f1 %.2f
extractFirstGradientMaximumFrom:scanline
computeOutlineByTracingSnake:snakeBodies
computeOutlineByTracingSnake:points
winning snake = connection of snakes %d and %d
computeBitmask: connected pieces search failed
computeBitmask: seedFill failed
computeBitmask: centroid closest bit search failed
computeBitmask: can not allocate bitmask bm2
computeBitmask: can not allocate bitmask bm
recomputeBitmask: seedFill failed
recomputeBitmask: can not allocate bitmask bm2
recomputeBitmask: can not allocate bitmask bm
closestConnectedComponent: seedFill failed
closestConnectedComponent: centroid closest bit search failed
closestConnectedComponent: can not allocate bitmask bm3
closestConnectedComponent: can not allocate bitmask bm2
closestConnectedComponent: can not allocate bitmask bm
cornealReflectionBitmask: can not allocate bitmask bm2 intended for spread
determineOutsidePath: nowhere to go
determineOutsidePath: border pixel expected
determineOutsidePath: overflow
determineOutsidePath: unable to allocate path body
determineOutsidePath: isolated point
determineOutsidePath: no bits set
determineOutsidePath: unable to allocate path
determineArcsAtAngleForOutsidePath: too many arc bodies
determineArcsAtAngleForOutsidePath: too many arcs
determineArcsAtAngleForOutsidePath: unable to allocate arc bodies
determineArcsAtAngleForOutsidePath: unable to allocate arcs
arcCorrelation: no crossings at f1
arcCorrelation: odd number of crossings
arcCorrelation: too many crossings
arcInfill: no crossings at f1
arcInfill: odd number of crossings
arcInfill: too many crossings
infillChannelWithBitmask: can not allocate bitmask bm2
error - impossible connect arrangement
incorrect number of points
examineAlpha: bitmaps don't match
examineAlpha: bitmaps are the wrong number of samples per pixel
examineBitmask: bitmaps don't match
examineBitmask: bitmaps are the wrong number of samples per pixel
allocSpanStack:s
allocSpanStack:s->firstChunk
pushSpan:s->stackHeadChunk->next
allocSpanStack: span stack could not be allocated
spanSearch: empty span
freeSpanStack: span stack is null
seedFill: can not pop span stack
seedFill: can not push span onto stack
seedFill: can not allocate span stack
frame
initWithExternalBuffer:size:rowBytes:f
initWithExternalBuffer:subRectange:fullSize:rowBytes:f
redEyeRemovalWithPoint:recognitionChannels[0]
redEyeRemovalWithPoint:recognitionChannels[1]
redEyeRemovalWithPoint:recognitionChannels[i]
redEyeRemovalWithData:recognitionChannel
surface=%p(%.3u)
 fmt=%.4s
 fmt=%ld
 x=%+.4lld y=%+.4lld w=%.4zu h=%.4zu ctx=%u img=%u vol=%d
 id='%s'
 id=nil
 size=%ld%s
 empty
 use=%ld
SurfaceCacheEntry 
GetSurfaceFromCacheAndFill was passed contextIndex=%d and imageIndex=%d.  Ignoring imageIndex.
GetValidSurfaceFromCache was passed contextIndex=%d and imageIndex=%d.  Ignoring imageIndex.
GetSurfaceFromCache was passed contextIndex=%d and imageIndex=%d.  Ignoring imageIndex.
RemoveSurfaceFromCache error %p is not known to cache
CISurfaceCacheQueue
v16@?0^{SurfaceCacheEntry=^^?{Atomic={?=i}}^{__IOSurface}{IPoint=qq}II^{__CFString}Q^{dispatch_queue_s}@?qi}8
SurfaceCache:
  count: %ld
  size: %ld%s
  non-volatile: %ld%s
  volatile: %ld%s
  capacity: %ld%s
  cumulativeStats:
    peakCount=%ld peakSize=%ld%s peakNVSize=%ld%s totalAlloced=%ld%s totalFilled=%ld%s timeFilling=%gs
    hits=%ld (%lu%%)  purgedHits=%ld (%lu%%)  recycledMisses=%ld (%lu%%)  misses=%ld (%lu%%)
useCountDecrement
/Library/Caches/com.apple.xbs/Sources/EmbeddedCoreImage_Sim/EmbeddedCoreImage-449/Framework/internal/surface-cache.cpp
_useCount > 0
inputPoint
kernel vec2 _mirror (vec2 center, vec3 tst, vec4 off, vec4 mtx)
  float test = dot(tst.xy, destCoord()) + tst.z;
  vec2 p = destCoord() - center;
  p = (test < 0.0) ? p + off.xy : vec2(dot(p, mtx.xy), dot(p, mtx.zw)) + off.zw;
  return p + center;
T@"CIVector",&,N,VinputPoint
10.10
inputSize
inputDecay
kernel vec4 _triangleKaleidoscopeColor (__sample c, vec2 center, vec4 ftrans, float decay)
  vec2 p = destCoord() - center;
  p = vec2(dot(p, ftrans.xy), dot(p, ftrans.zw));
  highp vec3 z = vec3(1.0 + p.x - p.y, 2.0 - p.x - 2.0 * p.y, 2.0 - 2.0 * p.x - p.y);
  z = abs(floor(z));
  float K = pow(decay, dot(z, vec3(1.0)));
  c.rgb *= K;
  return c;
kernel vec2 _triangleKaleidoscopeGeom (vec2 center, vec4 ftrans, vec4 btrans)
  vec2 p = destCoord() - center;
  p = vec2(dot(p, ftrans.xy), dot(p, ftrans.zw));
  p = fract(p);
  p = (p.x > p.y) ? p.yx : p;
  p.y = (p.y > 2.0 - p.x - p.y) ? (2.0 - p.x - p.y) : p.y;
  p.x = (p.x < 1.0 - p.x - p.y) ? (1.0 - p.x - p.y) : p.x;
  p = (p.x > p.y) ? p.yx : p;
  p = vec2(dot(p, btrans.xy), dot(p, btrans.zw));
  p += center;
  return p;
T@"NSNumber",&,N,VinputSize
T@"NSNumber",&,N,VinputRotation
T@"NSNumber",&,N,VinputDecay
kernel vec4 _cheapBlur(sampler src, vec2 parms)
  vec2 dc = destCoord();
  vec2 offA = parms * vec2(-1.0,  4.0);
  vec2 offB = parms * vec2( 4.0,  1.0);
  vec4 sul = sample(src, samplerTransform(src, dc + offA));
  vec4 sur = sample(src, samplerTransform(src, dc + offB));
  vec4 sdl = sample(src, samplerTransform(src, dc - offB));
  vec4 sdr = sample(src, samplerTransform(src, dc - offA));
  vec4 sc  = sample(src, samplerCoord (src));
  return 0.181818181818182 * sc + 0.204545454545455 * (sur + sul + sdr + sdl);
kernel vec4 _lerp(__sample src0, __sample src1, float factor) { return mix(src1, src0, factor); }
inputPasses
inputSampling
kernel vec2 _stretch (vec2 center, vec3 param)
  vec2 g = vec2(1.0) - clamp(abs(destCoord() - center) * param.x, 0.0, 1.0);
  g = (g * -2.0 + vec2(3.0)) * g * g;
  g *= param.y * sin((destCoord() - center.yy) * param.z);
  return destCoord() - g;
T@"CIVector",&,N,VinputSize
kernel vec2 _lighttunnel (vec4 param)
  vec2 p = destCoord() - param.xy;
  float rlen = param.z * inversesqrt(dot(p,p));
  float angle = log(rlen) * param.w;
  vec2 cs = vec2(cos(angle), sin(angle));
  p = vec2(dot(p, cs), dot(p, vec2(-cs.y, cs.x)));
  p = p * rlen + param.xy;
  p = mix(destCoord(), p, step(rlen, 1.0));
  return p;
%.12g
curve gamma=%g a=%g b=%g c=%g d=%g e=%g f=%g
curve%sgamma=%g%sa=%g b=%g c=%g d=%g e=%g f=%g
curve
inputSpatialSigma
inputLumaSigma
kernel vec4 _jointBilateral (sampler small, sampler guide, vec4 parms) 
  vec2 dc = destCoord(); 
  vec2 smallCenter = samplerCoord(small); 
  vec2 guideCenter = samplerCoord(guide); 
  vec2 smallDelta = samplerTransform(small, dc+vec2(1.0)) - smallCenter; 
  vec2 guideDelta = samplerTransform(guide, dc+vec2(1.0)) - guideCenter; 
  vec4 I0 = sample(small, smallCenter); 
  float IE0 = sample(guide, guideCenter).r; 
  vec4 sumFGI = vec4(0.0); 
  float sumFG = 0.0; 
  float x,y; 
  float w=2.0; 
  for (x=-w;x<=w;x++) 
  { 
    for (y=-w;y<=w;y++) 
    { 
      vec2 xy = vec2(x,y) * parms.zw; 
      float G = exp(-(x*x+y*y)*parms.y); 
      vec4  I  = sample(small, smallCenter + xy*smallDelta); 
      float IE = sample(guide, guideCenter + xy*guideDelta).g; 
      float F = exp(-((IE - IE0)*(IE - IE0))*parms.x); 
      sumFG += F*G; 
      sumFGI += F*G*I; 
    } 
  } 
  return sumFG<0.001 ? I0 : sumFGI/sumFG; 
kernel vec4 _jointBilateralRG (sampler combo, vec4 parms) 
  vec2 dc = destCoord(); 
  vec2 comboCenter = samplerCoord(combo); 
  vec2 comboDelta = samplerTransform(combo, dc+vec2(1.0)) - comboCenter; 
  vec4  c = sample(combo, comboCenter); 
  vec2  I0 = c.zw; 
  float IE0 = c.r; 
  vec2 sumFGI = vec2(0.0); 
  float sumFG = 0.0; 
  float x,y; 
  float w=2.0; 
  for (x=-w;x<=w;x++) 
  { 
    for (y=-w;y<=w;y++) 
    { 
      vec2 xy = vec2(x,y) * parms.zw; 
      float G = exp(-(x*x+y*y)*parms.y); 
      vec4  c = sample(combo, comboCenter + xy*comboDelta); 
      vec2  I  = c.zw; 
      float IE = c.g; 
      float F = exp(-((IE - IE0)*(IE - IE0))*parms.x); 
      sumFG += F*G; 
      sumFGI += F*G*I; 
    } 
  } 
  return vec4(sumFG<0.001 ? I0 : sumFGI/sumFG, 0.0, 1.0); 
kernel vec4 _guideCombine (__sample g, __sample gb) __attribute__((outputFormat(kCIFormatRGh))) 
  return vec4(g.r, gb.r, 0.0, 1.0); 
kernel vec4 _guideCombine4 (__sample guide, __sample guideblurred, __sample map) 
  return vec4(guide.r, guideblurred.r, map.rg); 
kernel vec4 _guideMono (__sample g) __attribute__((outputFormat(kCIFormatRh))) 
  return vec4(clamp(dot(g.rgb, vec3(0.3333)),0.0,1.0), 0.0, 0.0, 1.0); 
inputSigmaX
inputSigmaY
inputSmallImage
T@"CIImage",&,N,VinputSmallImage
T@"NSNumber",&,N,VinputSpatialSigma
T@"NSNumber",&,N,VinputLumaSigma
inputEnableNoiseTracking
inputNoiseReductionAmount
inputEnableSharpening
inputEnableVendorLensCorrection
inputDisableGamutMap
inputLuminanceNoiseReductionAmount
inputColorNoiseReductionAmount
inputNoiseReductionSharpnessAmount
inputNoiseReductionContrastAmount
inputNoiseReductionDetailAmount
inputBaselineExposure
inputBoost
inputBoostShadowAmount
inputNeutralChromaticityX
inputNeutralChromaticityY
inputNeutralTemperature
inputNeutralTint
inputNeutralLocation
inputDraftMode
inputIgnoreOrientation
inputImageOrientation
inputLinearSpaceFilter
inputDecoderVersion
supportedDecoderVersions
outputNativeSize
activeKeys
[CIDetector detectorOfType:context:options:] failed because type %@ is unkonw.
CIDetectorTypeFace
CIDetectorTypeRectangle
CIDetectorTypeQRCode
CIDetectorTypeText
CIDetectorAccuracy
CIDetectorAccuracyLow
CIDetectorAccuracyHigh
CIDetectorMinFeatureSize
CIDetectorMaxFeatureCount
CIDetectorTracking
CIDetectorNumberOfAngles
CIDetectorImageOrientation
CIDetectorEyeBlink
CIDetectorSmile
CIDetectorFocalLength
CIDetectorAspectRatio
CIDetectorDetectDiacritics
CIDetectorReturnSubFeatures
CITextDetectorMinimizeFalseDetections
CIDetectorExtraCharacters
CIDetectorLanguage
CIDetectorLanguageNone
CIDetectorLanguageASCII
CIDetectorLanguageEnglish
CIDetectorLanguageDanish
CIDetectorLanguageDutch
CIDetectorLanguageFrench
CIDetectorLanguageGerman
CIDetectorLanguageIcelandic
CIDetectorLanguageItalian
CIDetectorLanguageNorwegian
CIDetectorLanguagePortuguese
CIDetectorLanguageSpanish
CIDetectorLanguageSwedish
Unknown CIDetectorTracking specified. Ignoring.
Unknown CIDetectorNumberOfAngles specified. Ignoring.
Face detection finding face error: %@
Face detection finding facial expression error: %@
faceCoreDetector
T@"FCRFaceDetector",&,VfaceCoreDetector
type
T@"NSString",R,&
Face
Rectangle
QRCode
Text
T{CGRect={CGPoint=dd}{CGSize=dd}},R,Vbounds
hasLeftEyePosition
TB,R,VhasLeftEyePosition
T{CGPoint=dd},R,VleftEyePosition
hasRightEyePosition
TB,R,VhasRightEyePosition
T{CGPoint=dd},R,VrightEyePosition
hasMouthPosition
TB,R,VhasMouthPosition
T{CGPoint=dd},R,VmouthPosition
hasTrackingID
TB,R,VhasTrackingID
trackingID
Ti,R,VtrackingID
hasTrackingFrameCount
TB,R,VhasTrackingFrameCount
trackingFrameCount
Ti,R,VtrackingFrameCount
hasFaceAngle
TB,R,VhasFaceAngle
faceAngle
Tf,R,VfaceAngle
hasSmile
TB,R,VhasSmile
leftEyeClosed
TB,R,VleftEyeClosed
rightEyeClosed
TB,R,VrightEyeClosed
topLeft
T{CGPoint=dd},R,VtopLeft
topRight
T{CGPoint=dd},R,VtopRight
bottomLeft
T{CGPoint=dd},R,VbottomLeft
bottomRight
T{CGPoint=dd},R,VbottomRight
messageString
T@"NSString",R,VmessageString
subFeatures
T@"NSArray",R,VsubFeatures
%s colorSpace must be kCGColorSpaceModelRGB.
-[CIColor initWithRed:green:blue:alpha:colorSpace:]
%g %g %g %g
(%g %g %g %g)
numberOfComponents
components
Tr^d,R
inputSkyAmount
inputGrassAmount
kernel vec4 _grassAndSkyAdjust (__sample im, vec2 params) 
  float enhanceGrass = params.x; 
  float enhanceSky = params.y; 
  vec3 ipt, ipt2; 
  float range; 
  { 
    vec3 lms = im.r * vec3(0.3347, 0.1747, 0.0187) + 
               im.g * vec3(0.5984, 0.7151, 0.1018) + 
               im.b * vec3(0.0671, 0.1106, 0.8794); 
    lms = sign(lms)*pow(abs(lms), vec3(0.43)); 
    ipt = lms.r * vec3(0.4,  4.455,  0.8056) + 
          lms.g * vec3(0.4, -4.851,  0.3572) + 
          lms.b * vec3(0.2,  0.396,-1.1628); 
  } 
  float hue = atan((sqrt(ipt.b*ipt.b+ipt.g*ipt.g)-ipt.g)/ipt.b)/3.1416+0.5; 
  range = hue - 0.88; 
  float maskGrass = exp((-1.0*range*range)/(2.0*.088*.088)); 
  range = 1.0 - smoothstep(0.4, 0.5, ipt.r); 
  maskGrass *= range; 
  vec2 idealGrass = vec2(-0.03, 0.1); 
  vec2 toIdeal = idealGrass - ipt.gb; 
  float dist = sqrt(toIdeal.r*toIdeal.r+toIdeal.g*toIdeal.g); 
  float chroma2 = 4.0*(ipt.g*ipt.g + ipt.b*ipt.b); 
  float str = enhanceGrass*pow(chroma2, .2); 
  str = str*min(1.0, 1.0-chroma2*chroma2); 
  str = min(str, 1.5); 
  float scale = min(1.0, 0.1/(dist+0.05)); 
  ipt2.gb = ipt.gb + str*toIdeal*scale; 
  ipt2.gb *= enhanceGrass; 
  ipt2.r = ipt.r; 
  ipt = mix(ipt, ipt2.rgb, maskGrass); 
  float maskSky = smoothstep(0.2, 0.5, ipt.r); 
  range = ipt.g + .04; 
  maskSky *= exp((-1.0*range*range)/(2.0*0.15*0.15)); 
  range = ipt.b + 0.1; 
  maskSky *= exp((-1.0*range*range)/(2.0*0.2*0.2)); 
  { 
    vec3 lms = ipt.r * vec3(1.0000, 1.0000, 1.0000) + 
               ipt.g * vec3(0.0976,-0.1139, 0.0326) + 
               ipt.b * vec3(0.2052, 0.1332,-0.6769); 
    lms = sign(lms)*pow(abs(lms), vec3(1.0/.43)); 
    im.rgb = lms.r * vec3( 5.3089, -1.3026,  0.0381) + 
             lms.g * vec3(-4.4648,  2.5193, -0.1968) + 
             lms.b * vec3( 0.1564, -0.2175,  1.1590); 
  } 
  im.rgb = max(im.rgb, 0.0); 
  float gain = max(1.0, 1.0 + enhanceSky); 
  float gamma = 1.0 + abs(enhanceSky); 
  vec4 result = pow(gain*im, vec4(gamma)); 
  float gray = (result.r + result.b + result.g)/3.0; 
  result.rgb += (result.rgb-gray) * abs(enhanceSky) * 0.5; 
  result = mix(im, result, maskSky); 
  result.a = im.a; 
  return result;
T@"NSNumber",&,N,VinputSkyAmount
T@"NSNumber",&,N,VinputGrassAmount
CI_ENABLE_DIV_NODES
CI_TILE_ROI
CI_MAX_TEXTURE_SIZE
CI_IOSURFACE_WRAPPING
CI_IOSURFACE_INTERMEDIATES
CI_PRINT_TIME
CI_PRINT_TREE
CI_PRINT_TREE options flags:
%3d  initial graph %s
(set)
%3d  optimized graph %s
%3d  tile graph %s
%3d  programs graph %s
%3d  timing graph %s
 graphviz %s
graphviz
 dump-inputs %s
dump-inputs
 dump-intermediates %s
dump-intermediates
 skip-cpu %s
skip-cpu
 skip-gpu %s
skip-gpu
 skip-small %s
skip-small
 frame-<number> %s
frame-
CI_PRINT_FOSL
CI_EMIT_KERNEL_DIAGNOSTICS
CI_PRINT_PROGRAM
CI_USE_SW
CI_NO_CM
CI_FORCE_IS_BACKGROUND
CI_FORCE_GPU_PRIORITY
CI_ENABLE_RENDER_DAG
CI_INPUT_CACHE_SIZE
CI_ENABLE_KERNEL_CACHE
CI_INTERMEDIATE_CACHE_SIZE
CI_INTERMEDIATE_SRGB_TEXTURES
CI_RECYCLE_OPENGL_TEXTURES
CI_RECYCLE_METAL_TEXTURES
CI_WORKING_FORMAT
CI_DUMP_TEXTURES
CI_ENABLE_METAL_GPU
CI_ENABLE_CL_CPU
CI_ENABLE_CL_GPU
CI_AUTOTEST_ROI
CI_DISABLE_MERGING
CI_DISABLE_MERGING_PRE_GENERAL
CI_DISABLE_MERGING_POST_GENERAL
CI_LOG_TEXTURE_CACHE
CI_NO_RENDER
CI_LOG_CONVERSIONS
CI_LOG_SURFACE_CACHE
CI_LOG_IMAGE_PROVIDER
CI_NAME_SURFACES
CI_SURFACE_CACHE_CAPACITY
CI_ENABLE_FAST_POW
CI_TEMP_DIR
/tmp/
CI_KDEBUG
CI_ADD_NOOPS_AT_BRANCHES
CI_DISABLE_CRUFT_COMPATABILITY
CI_DISABLE_CRUFT_OVERRIDE
CI_FORCE_INSERT_NOOPS
CI_MAX_CL_COMPLEXITY
CI_DEBUG_CONTEXT_COLOR
CI_DISABLE_WORKAROUND
CI_GRAPH_ALLOW_REORDER
CI_GRAPH_FORCE_CROP
CI_FLIP_IMAGE_PROCESSOR
CI_FORCE_GLES_VERSION
CI_DISABLE_VISION_KIT
&amp;
&lt;
&gt;
&quot;
&apos;
 94 42182154  3198255235 94254236138180 80 32238196106200163
231135151  7244167137102 45 85205108187254 85 31125176101125
210159109 92 99  0111 42232183107 75 83 73 33168 13158104 52
 21 79 25207203 12204  9 16  0 62169 72 50 15164121 22 12 90
135126204  9215 16198163 19138 52 28252162 65199105 9821615
110155171173177217230 12135125 99179192 62  5100 27100247229
158 76 12 19 74 59179 69199170224162116160 36243192238102116
227190 38186 46106  3151139 74180110126140101135 38175114 52
 45 22116246144186171156230 18224154112100 95178129 78 52 67
154 79203178105 68227227 46106 31216231181 41 16111 49120 67
  8228 62134  5248 95233220104181 33112 30245  1 49236 63237
252226233 24195165144 12195245 33239 61140 56 66242 86209 37
195 93 42 53191  4198 41165172182107162183 15163222242 96 46
 43 78166 61115228209209199 78 64193117220101158144234 11205
%.5f
%.6f
originalFaceColor
T{?=dd},R,VoriginalFaceColor
lumHist
T@"CIEnhancementHistogram",R,VlumHist
rgbSumHist
T@"CIEnhancementHistogram",R,VrgbSumHist
satHist
T@"CIEnhancementHistogram",R,VsatHist
borderHist
T@"CIEnhancementHistogram",R,VborderHist
Failed to load VisionKit dynamic library, using fallback implementation.
Failed to create VTPixelTransferSession %d
Failed to create CVPixelBuffer %d
Invalid CIDetectorMinFeatureSize specified. Ignoring.
Invalid optionMaxCount specified. Ignoring.
Invalid CIDetectorMaxFeatureCount specified. Ignoring.
Unknown CIDetectorAspectRatio specified. Ignoring.
%spremultiply
kernel vec4 _spotLight (__sample src, vec3 lightpos, vec3 lightpointsat, vec4 lightcolor, vec2 parms)
  vec4 t0 = vec4(0.0);
  t0.xy = destCoord();
  vec4 r0;
  r0.xyz = lightpos - t0.xyz;
  r0.w = 0.0;
  r0 = normalize(r0);
  float k0 = dot(r0.xyz, lightpointsat);
  k0 = clamp(k0, 0.0, 1.0);
  k0 = pow(k0, parms.x); 
  vec4 r3 = k0 * lightcolor;
  r0 = r0.z * r3;
  vec4 dest = r0 * src;
  return dest;
inputConcentration
inputLightPosition
inputLightPointsAt
builtin_premultiply
builtin_unpremultiply
Invalid premultiply power %d.
premultiply
unpremultiply
nopremultiply
badpremultiply
premul
unpremul
kernel vec4 _colorcube (__sample im, sampler2D cube, vec4 dims)
  im.rgb = clamp(im.rgb, 0.0001, 0.9999);
  im.rgb *= dims.x;
  float flr = floor(im.b);
  vec2 xy = (0.5 + im.rg) * dims.zw;
  xy.y += flr * dims.z; 
  vec4 sLo = texture2D(cube, xy);
  xy.y += dims.z; 
  vec4 sHi = texture2D(cube, xy);
  return mix(sLo, sHi, im.b - flr) * im.a;
kernel vec4 _colorcubeopaque (__sample im, sampler2D cube, vec4 dims)
  im.rgb = clamp(im.rgb, 0.0001, 0.9999);
  im.rgb *= dims.x;
  float flr = floor(im.b);
  vec2 xy = (0.5 + im.rg) * dims.zw;
  xy.y += flr * dims.z; 
  vec3 sLo = texture2D(cube, xy).rgb;
  xy.y += dims.z; 
  vec3 sHi = texture2D(cube, xy).rgb;
  im.rgb = mix(sLo, sHi, im.b - flr);
  return im;
CIColorCube inputCubeDimension must be from 2 through %d.
CIColorCube inputCubeData must be of type NSData.
CIColorCube inputCubeData is not of the expected length.
T@"NSNumber",&,N,VinputCubeDimension
T@"NSData",C,N,VinputCubeData
CIColorCubeWithColorSpace inputColorSpace must be an RGB CGColorSpaceRef
T@,&,N,VinputColorSpace
kernel vec4 _radialGradient (vec4 params, __color c0, __color c1)
  highp float t = distance(destCoord(),params.xy) * params.z + params.w;
  return mix(c0, c1, clamp(t, 0.0, 1.0));
inputRadius0
inputRadius1
T@"NSNumber",&,N,VinputRadius0
T@"NSNumber",&,N,VinputRadius1
kernel vec4 _linearGradient (vec2 p0, vec2 p1, __color c0, __color c1, float d1Inv)
  highp float t = dot(p1 - p0, destCoord() - p0) * d1Inv;
  return mix(c0, c1, clamp(t, 0.0, 1.0));
T@"CIVector",&,N,VinputPoint0
T@"CIVector",&,N,VinputPoint1
kernel vec4 _smoothLinearGradient (vec2 p0, vec2 p1, __color c0, __color c1, float d1Inv)
  highp float t = dot(p1 - p0, destCoord() - p0) * d1Inv;
  return mix(c0, c1, smoothstep(0.0, 1.0, t));
kernel vec4 _gaussianGradient (vec3 params, __color c0, __color c1)
  highp float d = min(distance(destCoord(), params.xy) * params.z, 1.0);
  d = (d * -2.0 + 3.0) * d * d;
  return mix(c0, c1, d);
kernel vec4 _hsvwheel (vec4 params) 
  float value = params.x; 
  float radius = params.y; 
  float invradius = params.z; 
  float smoothness = params.w; 
  vec2 p = destCoord() - vec2(radius); 
  float len = length(p); 
  float H = atan(p.y,p.x) * 3.0 / 3.1415926; 
  float S = clamp(len / radius, 0.0, 1.0); 
  vec4 c = vec4(H, H-2.0, H+2.0, 0.0); 
  c = clamp(abs(3.0-abs(c))-1.0, 0.0, 1.0); 
  c = mix(c, smoothstep(0.0,1.0,c), smoothness); 
  c = mix(vec4(1.0), c, S); 
  c.a = 1.0; 
  c.rgb *= value; 
  return c * clamp(radius - len, 0.0, 1.0); 
float noise(float seed, vec2 dc) 
  float x = (13.0*dc.x + 1111.0)/(17.0 + seed); 
  float y = (11.0*dc.y + 7777.0)/(19.0 - seed); 
  float m = 37.0; 
  float n = x; 
  n = mod(y*n + y, m); 
  n = mod(y*n + x, m); 
  n = mod(x*n, m); 
  n = mod(x*n, m); 
  return n/m; 
kernel vec4 _hsvwheeldithered (vec4 params, float dither) 
  float value = params.x; 
  float radius = params.y; 
  float invradius = params.z; 
  float smoothness = params.w; 
  vec2 p = destCoord() - vec2(radius); 
  float len = length(p); 
  float H = atan(p.y,p.x) * 3.0 / 3.1415926; 
  float S = clamp(len / radius, 0.0, 1.0); 
  vec4 c = vec4(H, H-2.0, H+2.0, 0.0); 
  c = clamp(abs(3.0-abs(c))-1.0, 0.0, 1.0); 
  c = mix(c, smoothstep(0.0,1.0,c), smoothness); 
  c = mix(vec4(1.0), c, S); 
  c.a = 1.0; 
  c.rgb *= value; 
  c.rgb += (noise(0.0, floor(destCoord())) - 0.5)*dither; 
  return c * clamp(radius - len, 0.0, 1.0); 
+[CIHueSaturationValueGradient customAttributes]
/Library/Caches/com.apple.xbs/Sources/EmbeddedCoreImage_Sim/EmbeddedCoreImage-449/Framework/filters/CIGradient.mm
inputValue
inputSoftness
inputDither
T@"NSNumber",&,N,VinputValue
T@"NSNumber",&,N,VinputSoftness
T@"NSNumber",&,N,VinputDither
kernel vec4 _checker (vec2 center, __color c0, __color c1, vec3 parms)
  vec2 d0 = destCoord() - center;
  d0 = fract(d0 * parms.x);
  d0 = min (1.0 - d0, d0);
  d0 = clamp (d0 * parms.y + parms.z, 0.0, 1.0);
  d0 = (d0 * -2.0 + 3.0) * d0 * d0;
  float d1 = 2.0 * min (d0.x, d0.y) + 1.0 - (d0.x + d0.y);
  return mix(c1, c0, d1);
T@"NSNumber",&,N,VinputWidth
T@"NSNumber",&,N,VinputSharpness
kernel vec4 _colorMonochrome (__sample img, __color color, float intensity)
  float c1 = dot(img.rgb, vec3(0.2125, 0.7154, 0.0721));
  vec4 low = 2.0 * c1 * color;
  vec4 high = 1.0 - 2.0 * ((1.0 - c1) * (vec4(1.0) - color));
  vec4 lt = vec4(lessThan(vec4(c1 - 0.5), vec4(0.0)));
  vec4 pix = mix(img, mix(high, low, lt), intensity);
  img.rgb = pix.rgb;
  return img;
kernel vec4 _stripes (vec2 center, __color c0, __color c1, vec3 params)
  float d0;
  d0 = (destCoord() - center).x;
  d0 = fract(d0 * params.x - .25);
  d0 = min (1.0 - d0, d0);
  d0 = clamp (d0 * params.y + params.z, 0.0, 1.0);
  float d1 = (d0 * -2.0 + 3.0) * d0 * d0;
  return mix(c1, c0, d1);
kernel vec4 _colorBurnBlendMode (__sample uCf, __sample uCb)
  vec4 Ct = clamp(1.0 - (1.0 - uCb) / max(uCf, vec4(0.0000001)), 0.0, 1.0);
  vec4 Cb = vec4(uCb.rgb * uCb.a, uCb.a);
  Ct = mix(uCf, Ct, uCb.a);
  Ct.a = 1.0;
  return mix(Cb, Ct, uCf.a);
kernel vec4 _colorDodgeBlendMode (__sample uCf, __sample uCb)
  vec4 Ct = clamp(uCb / max(1.0 - uCf, vec4(0.0000001)), 0.0, 1.0);
  vec4 Cb = vec4(uCb.rgb * uCb.a, uCb.a);
  Ct = mix(uCf, Ct, uCb.a);
  Ct.a = 1.0;
  return mix(Cb, Ct, uCf.a);
kernel vec4 _linearBurnBlendMode (__sample uCf, __sample uCb)
  vec4 Ct = clamp(uCb - (1.0 - uCf*uCf.a), 0.0, 1.0);
  vec4 Cb = vec4(uCb.rgb * uCb.a, uCb.a);
  Ct = mix(uCf, Ct, uCb.a);
  Ct.a = 1.0;
  return mix(Cb, Ct, uCf.a);
kernel vec4 _linearDodgeBlendMode (__sample uCf, __sample uCb)
  vec4 Ct = clamp(uCf*uCf.a + uCb, 0.0, 1.0);
  vec4 Cb = vec4(uCb.rgb * uCb.a, uCb.a);
  Ct = mix(uCf, Ct, uCb.a);
  Ct.a = 1.0;
  return mix(Cb, Ct, uCf.a);
kernel vec4 _darkenBlendMode (__sample uCf, __sample uCb)
  vec4 Ct = clamp(min(uCb, uCf), 0.0, 1.0);
  vec4 Cb = vec4(uCb.rgb * uCb.a, uCb.a);
  Ct = mix(uCf, Ct, uCb.a);
  Ct.a = 1.0;
  return mix(Cb, Ct, uCf.a);
kernel vec4 _differenceBlendMode (__sample uCf, __sample uCb)
  vec4 Ct = clamp(abs(uCf - uCb), 0.0, 1.0);
  vec4 Cb = vec4(uCb.rgb * uCb.a, uCb.a);
  Ct = mix(uCf, Ct, uCb.a);
  Ct.a = 1.0;
  return mix(Cb, Ct, uCf.a);
kernel vec4 _divideBlendMode (__sample uCf, __sample uCb)
  vec4 Ct = clamp(uCb / max(uCf,vec4(0.0000001)), 0.0, 1.0);
  vec4 Cb = vec4(uCb.rgb * uCb.a, uCb.a);
  Ct = mix(uCf, Ct, uCb.a);
  Ct.a = 1.0;
  return mix(Cb, Ct, uCf.a);
kernel vec4 _subtractBlendMode (__sample uCf, __sample uCb)
  vec4 Ct = clamp(uCb - uCf, 0.0, 1.0);
  vec4 Cb = vec4(uCb.rgb * uCb.a, uCb.a);
  Ct = mix(uCf, Ct, uCb.a);
  Ct.a = 1.0;
  return mix(Cb, Ct, uCf.a);
kernel vec4 _exclusionBlendMode (__sample uCf, __sample uCb)
  vec4 Ct = clamp(uCf + uCb - 2.0 * uCb * uCf, 0.0, 1.0);
  vec4 Cb = vec4(uCb.rgb * uCb.a, uCb.a);
  Ct = mix(uCf, Ct, uCb.a);
  Ct.a = 1.0;
  return mix(Cb, Ct, uCf.a);
kernel vec4 _hardLightBlendMode (__sample uCf, __sample uCb)
  vec4 lt = vec4(lessThan(uCf - 0.5, vec4(0.0f)));
  vec4 Ct = clamp(mix(1.0 - 2.0 * (1.0 - uCf) * (1.0 - uCb), 2.0 * uCf * uCb, lt), 0.0, 1.0);
  vec4 Cb = vec4(uCb.rgb * uCb.a, uCb.a);
  Ct = mix(uCf, Ct, uCb.a);
  Ct.a = 1.0;
  return mix(Cb, Ct, uCf.a);
kernel vec4 _hardMixBlendMode (__sample uCf, __sample uCb)
  vec4 Ct = clamp(floor(1.9999999 - (1.0 - uCb) / uCf), 0.0, 1.0);
  vec4 Cb = vec4(uCb.rgb * uCb.a, uCb.a);
  Ct = mix(uCf, Ct, uCb.a);
  Ct.a = 1.0;
  return mix(Cb, Ct, uCf.a);
kernel vec4 _lightenBlendMode (__sample uCf, __sample uCb)
  vec4 Ct = clamp(max(uCb, uCf), 0.0, 1.0);
  vec4 Cb = vec4(uCb.rgb * uCb.a, uCb.a);
  Ct = mix(uCf, Ct, uCb.a);
  Ct.a = 1.0;
  return mix(Cb, Ct, uCf.a);
kernel vec4 _linearLightBlendMode (__sample uCf, __sample uCb)
  vec4 Ct = clamp(uCb - (1.0 - (2.0 * uCf)), 0.0, 1.0);
  vec4 Cb = vec4(uCb.rgb * uCb.a, uCb.a);
  Ct = mix(uCf, Ct, uCb.a);
  Ct.a = 1.0;
  return mix(Cb, Ct, uCf.a);
kernel vec4 _multiplyBlendMode (__sample uCf, __sample uCb)
  vec4 Ct = clamp(uCf * uCb, 0.0, 1.0);
  vec4 Cb = vec4(uCb.rgb * uCb.a, uCb.a);
  Ct = mix(uCf, Ct, uCb.a);
  Ct.a = 1.0;
  return mix(Cb, Ct, uCf.a);
kernel vec4 _pinLightBlendMode (__sample uCf, __sample uCb)
  vec4 Ct = clamp(compare(uCf - 0.5, min(uCb, uCf * 2.0), max(uCb, uCf * 2.0 - 1.0)), 0.0, 1.0);
  vec4 Cb = vec4(uCb.rgb * uCb.a, uCb.a);
  Ct = mix(uCf, Ct, uCb.a);
  Ct.a = 1.0;
  return mix(Cb, Ct, uCf.a);
kernel vec4 _screenBlendMode (__sample uCf, __sample uCb)
  vec4 Ct = clamp(uCf + clamp(1.0 - uCf, 0.0, 1.0) * uCb, 0.0, 1.0);
  vec4 Cb = vec4(uCb.rgb * uCb.a, uCb.a);
  Ct = mix(uCf, Ct, uCb.a);
  Ct.a = 1.0;
  return mix(Cb, Ct, uCf.a);
kernel vec4 _softLightBlendMode (__sample uCf, __sample uCb)
  vec4 D = compare(uCb-0.25, ((16.0*uCb-12.0)*uCb+4.0)*uCb, sqrt(uCb));
  vec4 Ct = clamp(uCb + (2.0*uCf-1.0) * compare(uCf - 0.5, uCb*(1.0-uCb), D-uCb), 0.0, 1.0);
  vec4 Cb = vec4(uCb.rgb * uCb.a, uCb.a);
  Ct = mix(uCf, Ct, uCb.a);
  Ct.a = 1.0;
  return mix(Cb, Ct, uCf.a);
kernel vec4 _vividLightBlendMode (__sample uCf, __sample uCb)
  vec4 epsilon = vec4(0.0000001);
  vec4 r3 = 1.0 - ((0.5 - 0.5 * uCb) / max(uCf, epsilon));
  vec4 r2 = (0.5 * uCb) / max(1.0 - uCf, epsilon);
  vec4 Ct = clamp(compare(uCf - 0.5, r3, r2), 0.0, 1.0);
  vec4 Cb = vec4(uCb.rgb * uCb.a, uCb.a);
  Ct = mix(uCf, Ct, uCb.a);
  Ct.a = 1.0;
  return mix(Cb, Ct, uCf.a);
kernel vec4 _hueBlendMode (__sample uCf, __sample uCb) 
  vec4 uCfSort = (uCf.r > uCf.g) ? uCf : uCf.grba;
  uCfSort = (uCfSort.g > uCfSort.b) ? uCfSort : uCfSort.rbga;
  uCfSort = (uCfSort.r > uCfSort.g) ? uCfSort : uCfSort.grba;
  vec4 uCbSort = (uCb.r > uCb.g) ? uCb : uCb.grba;
  uCbSort = (uCbSort.g > uCbSort.b) ? uCbSort : uCbSort.rbga;
  uCbSort = (uCbSort.r > uCbSort.g) ? uCbSort : uCbSort.grba;
  vec4 Ct = (uCfSort.b+0.00001 > uCfSort.r) ? uCbSort.rbba : (uCf - uCfSort.b) * (uCbSort.r - uCbSort.b) / (uCfSort.r - uCfSort.b) + uCbSort.b;
  Ct.a = uCb.a;
  vec4 Cb = vec4(uCb.rgb * uCb.a, uCb.a);
  Ct = mix(uCf, Ct, uCb.a);
  Ct.a = 1.0;
  return mix(Cb, Ct, uCf.a);
kernel vec4 _saturationBlendMode (__sample uCf, __sample uCb)
  vec4 uCfSort = (uCf.r > uCf.g) ? uCf : uCf.grba;
  uCfSort = (uCfSort.g > uCfSort.b) ? uCfSort : uCfSort.rbga;
  uCfSort = (uCfSort.r > uCfSort.g) ? uCfSort : uCfSort.grba;
  float fL = (uCfSort.r + uCfSort.b) * 0.5;
  float cmax = uCfSort.r;
  float cmin = uCfSort.b;
  vec4 uCbSort = (uCb.r > uCb.g) ? uCb : uCb.grba;
  uCbSort = (uCbSort.g > uCbSort.b) ? uCbSort : uCbSort.rbga;
  uCbSort = (uCbSort.r > uCbSort.g) ? uCbSort : uCbSort.grba;
  float bL = (uCbSort.r + uCbSort.b) * 0.5;
  float d = cmax - cmin;
  float dv = (fL < 0.5) ? (cmax + cmin) : (2.0 - (cmax + cmin));
  float s = d / max(dv, 0.000001);
  float mmax = (bL <= 0.5) ? (bL + bL*s) : (bL + s - bL*s);
  float mmin = bL * 2.0 - mmax;
  vec4 Ct = (uCbSort.b+0.00001 > uCbSort.r) ? vec4(mmax,mmin,mmin,1.0) : (uCb - uCbSort.b) * (mmax - mmin) / (uCbSort.r - uCbSort.b) + mmin;
  Ct.a = uCb.a;
  vec4 Cb = vec4(uCb.rgb * uCb.a, uCb.a);
  Ct = mix(uCf, Ct, uCb.a);
  Ct.a = 1.0;
  return mix(Cb, Ct, uCf.a);
kernel vec4 _colorBlendMode (__sample uCf, __sample uCb)
  vec4 uCfSort = (uCf.r > uCf.g) ? uCf : uCf.grba;
  uCfSort = (uCfSort.g > uCfSort.b) ? uCfSort : uCfSort.rbga;
  uCfSort = (uCfSort.r > uCfSort.g) ? uCfSort : uCfSort.grba;
  float fL = (uCfSort.r + uCfSort.b) * 0.5;
  float cmax = uCfSort.r;
  float cmin = uCfSort.b;
  vec4 uCbSort = (uCb.r > uCb.g) ? uCb : uCb.grba;
  uCbSort = (uCbSort.g > uCbSort.b) ? uCbSort : uCbSort.rbga;
  uCbSort = (uCbSort.r > uCbSort.g) ? uCbSort : uCbSort.grba;
  float bL = (uCbSort.r + uCbSort.b) * 0.5;
  float d = cmax - cmin;
  float dv = (fL < 0.5) ? (cmax + cmin) : (2.0 - (cmax + cmin));
  float s = d / max(dv, 0.000001);
  float mmax = (bL <= 0.5) ? (bL + bL*s) : (bL + s - bL*s);
  float mmin = bL * 2.0 - mmax;
  vec4 Ct = (uCf - uCfSort.b) * (mmax - mmin) / (uCfSort.r - uCfSort.b) + mmin;
  Ct = (mmin+0.00001 > mmax) ? vec4(mmin) : Ct;
  Ct.a = uCb.a;
  vec4 Cb = vec4(uCb.rgb * uCb.a, uCb.a);
  Ct = mix(uCf, Ct, uCb.a);
  Ct.a = 1.0;
  return mix(Cb, Ct, uCf.a);
kernel vec2 _twirl(vec4 param)
  vec2 d = destCoord() - param.xy;
  float r = min(length(d) * param.z, 1.0);
  float _1mr = 1.0 - r;
  float ss = (_1mr * -2.0 + 3.0) * _1mr * _1mr;
  float angle = param.w * ss;
  vec2 cs = vec2(cos(angle), sin(angle));
  vec2 p = vec2(dot(d, cs), dot(d, vec2(-cs.y, cs.x)));
  return (r >= 1.0) ? destCoord() : p + param.xy;
function not implemented
out of boundaries
<CI::Color %p>[%g %g %g %g]
[%g %g %g %g 
kernel vec4 vignette (__sample s, vec4 params)
  vec2 point = destCoord() - params.xy;
  float len2 = dot(point, point);
  float v = pow(max(1.0 - len2 * params.w, 0.0), params.z);
  s.rgb *= v;
  return s;
kernel vec4 _vignetteeffect (__sample s, vec2 center, vec4 params) 
  vec2 point = (destCoord() - center) * params.x; 
  float dist = sqrt(dot(point,point)); 
  float x = clamp((dist-params.y)*params.z,0.0,1.0); 
  x = x*x*x*((6.0*x - 15.0)*x + 10.0); 
  float v = 1.0 - x*params.w; 
  v = ((( -0.120638501063760*v + 0.543878646118680)*v + 0.538772615443760)*v + 0.037600999734998)*v; 
  s.rgb *= v; 
  return s; 
kernel vec4 _vignetteeffectneg (__sample s, vec2 center, vec4 params) 
  vec2 point = (destCoord() - center) * params.x; 
  float dist = sqrt(dot(point,point)); 
  float x = clamp((dist-params.y)*params.z,0.0,1.0); 
  x = x*x*x*((6.0*x - 15.0)*x + 10.0); 
  float v = 16.0*x*params.w + 1.0; 
  s.rgb *= v; 
  return s; 
T@"NSNumber",&,N,VinputFalloff
kernel vec2 _kaleida (vec4 parms, vec4 rota, vec4 rotb)
  vec2 ctr = parms.xy;
  float TwoPiDivCount = parms.z;
  float CountDivTwoPi = parms.w;
  vec2 v = destCoord() - ctr;
  v = vec2(dot(v, rota.xy), dot(v, rota.zw));
  const float pi = 3.141592653589793;
  const float halfpi = 1.570796326794897;
  v.y = abs(v.y);
  float a = atan(v.y,v.x);
  a = - TwoPiDivCount * floor(a*CountDivTwoPi+0.5);
  float x = (a>halfpi) ? pi-a : a;
  x = (x<-halfpi) ? -pi-x : x;
  float sn = x - (x*x*x/6.0) + (x*x*x*x*x/120.0) - (x*x*x*x*x*x*x/5040.0) + (x*x*x*x*x*x*x*x*x/362880.0);
  x = abs(a);
  float k = (x>halfpi) ? -1.0 : 1.0;
  x = (x>halfpi) ? pi-x : x;
  x = x*x;
  x = (((0.000024801587302*x - 0.001388888888889)*x + 0.041666666666667)*x - 0.5)*x + 1.0;
  float cs = x*k;
  v = vec2(v.x*cs - v.y*sn, v.x*sn + v.y*cs);
  v.y = abs(v.y);
  v = vec2(dot(v, rotb.xy),dot(v, rotb.zw));
  return v + ctr;
devicegray
devicergb
calRGB(
wp=d50 
wp=%.3f,%.3f,%.3f 
bp=%.3f,%.3f,%.3f 
gamma=1 
gamma=%.3f 
gamma=%.3f,%.3f,%.3f 
mtx=%.3f,%.3f,%.3f,%.3f,%.3f,%.3f,%.3f,%.3f,%.3f)
calGray(
gamma=1)
gamma=%.3f)
DeviceCMYK Colorspace %p
Lab Colorspace %p
Indexed Colorspace %p
DeviceN Colorspace %p
Pattern Colorspace %p
PlatformSets Colorspace %p
srgb-to-linear
linear-to-srgb
srgb-noop
builtin_linear_to_srgb
builtin_srgb_to_linear
Invalid srgb direction %d.
linear_to_srgb
srgb_to_linear
srgb_noop
srgb_invalid
lintosrgb
srgbtolin
samplemode
inputDamping
kernel vec4 _colorbalance (__sample pix, __color clr, vec4 params)
  pix.rgb = pix.r * vec3(0.299,  0.595716,  0.211456) + 
            pix.g * vec3(0.587, -0.274453, -0.522591) + 
            pix.b * vec3(0.114, -0.321263,  0.311135);
  clr.rgb /= max(clr.a, 0.00001);
  clr.rgb = pow(max(clr.rgb, 0.0), vec3(0.25)); 
  clr.rgb = clr.r * vec3(0.299,  0.595716,  0.211456) + 
            clr.g * vec3(0.587, -0.274453, -0.522591) + 
            clr.b * vec3(0.114, -0.321263,  0.311135);
  pix.gb += params.z * (params.xy - clr.gb) * pow(pix.r, params.w); 
  pix.rgb = pix.r * vec3(1.0) + 
            pix.g * vec3(0.956296, -0.272122, -1.10699) + 
            pix.b * vec3(0.621024, -0.647381, 1.70461); 
  return pix;
T@"NSNumber",&,N,VinputDamping
kernel vec2 _pinchDistortionScaleLT1(vec2 c, vec4 param)
  vec2 p = destCoord() - c;
  float r = length(p) * param.y + .000001;
  p = p * inversesqrt(r) + c;
  return mix(destCoord(), p, param.z);
kernel vec2 _pinchDistortionScaleGE1(vec2 c, vec4 param)
  vec2 p = destCoord() - c;
  float r = length(p) * param.y + .000001;
  vec2 pRGT = pow(r, param.w) * p + c;
  p = p * inversesqrt(r) + c;
  p = mix(destCoord(), p, param.z);
  return (r <= 1.0) ? p : pRGT;
Invalid scale %g in CIPinchDistortion, must be less than 2
map_point_inv
/Library/Caches/com.apple.xbs/Sources/EmbeddedCoreImage_Sim/EmbeddedCoreImage-449/Framework/filters/PhotoBooth/CIPinchDistortion.m
scale < 2.0
[%u] pixel count = %ld, rate = %g ns/pixel, time = %g
%lu renders Pixels processed by %s = %llu (%g%% of total), time = %g (%g%% of total time), overall rate = %g ns/pixel
%lu kernels, %u renders, # pixels processed = %llu, total run time = %g, overall rate for all kernels = %g ns/pixel
Showing top %d kernel processing rates now: 
%g ns/pixel 
<?xml version="1.0"?> <?mso-application progid="Excel.Sheet"?> <Workbook xmlns="urn:schemas-microsoft-com:office:spreadsheet" xmlns:o="urn:schemas-microsoft-com:office:office" xmlns:x="urn:schemas-microsoft-com:office:excel" xmlns:ss="urn:schemas-microsoft-com:office:spreadsheet" xmlns:html="http://www.w3.org/TR/REC-html40"> <DocumentProperties xmlns="urn:schemas-microsoft-com:office:office"> <Author>Alexandre Naaman</Author> <LastAuthor>Self</LastAuthor> <Created>2015-07-23T23:04:04Z</Created> <Company>Apple, Inc.</Company> <Version>11.8036</Version> </DocumentProperties> <ExcelWorkbook xmlns="urn:schemas-microsoft-com:office:excel"> <WindowHeight>6795</WindowHeight> <WindowWidth>8460</WindowWidth> <WindowTopX>120</WindowTopX> <WindowTopY>15</WindowTopY> <ProtectStructure>False</ProtectStructure> <ProtectWindows>False</ProtectWindows> </ExcelWorkbook> <Styles> <Style ss:ID="Default" ss:Name="Normal"> <Alignment ss:Vertical="Bottom" /> <Borders /> <Font /> <Interior /> <NumberFormat /> <Protection /> </Style> <Style ss:ID="s62"> <Font x:Family="Swiss" ss:Bold="1" /> </Style> <Style ss:ID="s63"> <Font x:Family="Swiss"/> <NumberFormat ss:Format="#,##0"/> </Style> <Style ss:ID="s64"> <Font x:Family="Swiss" ss:Bold="1"/> <NumberFormat ss:Format="#,##0"/> </Style> </Styles> <Worksheet ss:Name="Sheet1">
</Table> <WorksheetOptions xmlns="urn:schemas-microsoft-com:office:excel"> <Print> <ValidPrinterInfo /> <HorizontalResolution>600</HorizontalResolution> <VerticalResolution>600</VerticalResolution> </Print> <Selected /> <Panes> <Pane> <Number>3</Number> <ActiveRow>5</ActiveRow> <ActiveCol>1</ActiveCol> </Pane> </Panes> <Table> </Table> <ProtectObjects>False</ProtectObjects> <ProtectScenarios>False</ProtectScenarios> </WorksheetOptions> </Worksheet> </Workbook>
CI_PRINT_TIME(%s) %zux%zu = %g (%g ns/pixel)
 total time so far = %g, pixelsProcessed = %llu cummulative rate = %g ns/pixel
colormatch
workingspace
-to-
colormatch<BR/>
Matching a color failed: from 
 to 
Core Image could not support source colorspace: 
B96@?0{CGColorConversionIteratorData=Iqqqqqq^^{CGColorTRCData}^^{CGColorMatrixData}^^{CGColorNxMLUTData}}8^{__CFDictionary=}88
B112@?0{CGColorConversionIteratorData=Iqqqqqq^^{CGColorTRCData}^^{CGColorMatrixData}^^{CGColorNxMLUTData}}8q88q96^q104
B104@?0{CGColorConversionIteratorData=Iqqqqqq^^{CGColorTRCData}^^{CGColorMatrixData}^^{CGColorNxMLUTData}}8q88q96
failed to create a converter from 
cmlut %llu
cm%zux%zulut %llu
kernel vec4 _cmlut (__sample im, sampler2D lut, vec2 dim)
  im.rgb = clamp(im.rgb, 0.0, 1.0); 
  im.rgb = im.rgb * dim.x + dim.y; 
  im.r = texture2D(lut, vec2(im.r, 0.5)).r; 
  im.g = texture2D(lut, vec2(im.g, 0.5)).r; 
  im.b = texture2D(lut, vec2(im.b, 0.5)).r; 
  return im;
cube
_cmlut
kernel vec4 _cmcubeopaque (__sample im, sampler2D cube, vec4 dims)
  im.rgb = clamp(im.rgb, 0.0001, 0.9999);
  im.rgb *= dims.x;
  float flr = floor(im.b);
  vec2 xy = (0.5 + im.rg) * dims.zw;
  xy.y += flr * dims.z; 
  vec3 sLo = texture2D(cube, xy).rgb;
  xy.y += dims.z; 
  vec3 sHi = texture2D(cube, xy).rgb;
  im.rgb = mix(sLo, sHi, im.b - flr);
  return im;
dims
_cmcubeopaque
kernel vec4 _cm1x3lut (__sample im, sampler2D lut, vec2 dim)
  im.rgb = clamp(im.rgb, 0.0, 1.0); 
  im.rgb = im.rgb * dim.x + dim.y; 
  im.rgb = texture2D(lut, vec2(im.r, 0.5)).rgb; 
  return im;
_cm1x3lut
Core Image could not support destination colorspace: 
vec4 _pointillizeStep( sampler src, vec4 background, sampler noise, vec2 cellSize, vec2 noiseOffset, vec2 cellOffset)
  float o; 
  float tSize = 256.0; 
  float _randomFactor = 0.65; 
  float _radiusFactor = 0.71; 
  float _colorRandom = 0.1; 
  vec2 dc = destCoord();
  vec2 noiseLoc = floor(dc*cellSize.y + .5) + noiseOffset; 
  vec4 np = sample(noise, samplerTransform(noise, mod(noiseLoc, tSize))); 
  vec2 cellLoc = (floor(dc*cellSize.y - 0.5) + 0.5) * cellSize.x + 0.5 + cellOffset; 
  cellLoc += (np.xy - 0.5) * cellSize.x * _randomFactor; 
  o = distance(dc, cellLoc); 
  o = clamp((1.0 - o * cellSize.y / _radiusFactor) * 3.0, 0.0, 1.0); 
  o = (3.0 - 2.0 * o) * o * o; 
  vec4 p1 = sample(src, samplerTransform(src, cellLoc)); 
  p1.rgb += vec3(np.b - 0.5) * _colorRandom * p1.a; 
  return mix(background, p1, o); 
kernel vec4 _pointillize(sampler src, sampler noise, vec4 parms)
  vec4 background = sample(src, samplerCoord(src)).aaaa;
  background = _pointillizeStep(src, background, noise, parms.zw, parms.xy + vec2(0.5,0.5),   vec2(parms.z,parms.z)); 
  background = _pointillizeStep(src, background, noise, parms.zw, parms.xy + vec2(-0.5,0.5),  vec2(0,parms.z)); 
  background = _pointillizeStep(src, background, noise, parms.zw, parms.xy + vec2(0.5,-0.5),  vec2(parms.z,0)); 
  background = _pointillizeStep(src, background, noise, parms.zw, parms.xy + vec2(-0.5,-0.5), vec2(0,0)); 
  return background;
Projections_status Projections_computeShiftBruteForce(const float *, int, const Projections_meanStdTable *, const float *, int, const Projections_meanStdTable *, int, float, float *, float *, float *, float *)
/Library/Caches/com.apple.xbs/Sources/EmbeddedCoreImage_Sim/EmbeddedCoreImage-449/Framework/api/Burst/Projections/Projections_Optimizer.c
Projections_status Projections_computeShiftDescent(const float *, int, const Projections_meanStdTable *, const float *, int, const Projections_meanStdTable *, int, float *, float *)
Projections_status Projections_computeCost(int, float, float, const float *, int, const Projections_meanStdTable *, const float *, int, const Projections_meanStdTable *, int, float *)
hw.optional.sse
hw.optional.sse2
hw.optional.sse3
clamptoalpha
clamp_to_alpha
vec2 clampToRect(vec2 point,vec4 rect) {
  return clamp(point,rect.xy,rect.xy + rect.zw);
vec4 sampleBilinear(sampler image,vec2 p) {
    vec2 xy0 = p - vec2(0.5);
    vec2  p0 = floor(xy0);
    vec2  p1 = p0 + vec2(1.0);
    vec2 amount = p1 - xy0;
    vec4 ll = sample(image, samplerTransform(image, p0 + vec2(0.5)));
    vec4 ur = sample(image, samplerTransform(image, p1 + vec2(0.5)));
    vec4 lr = sample(image, samplerTransform(image, vec2(p1.x, p0.y) + vec2(0.5)));
    vec4 ul = sample(image, samplerTransform(image, vec2(p0.x, p1.y) + vec2(0.5)));
    vec4 bottom = mix(lr, ll, amount.x);
    vec4 top = mix(ur, ul, amount.x);
    return mix(top, bottom, amount.y);
kernel vec4 variableBoxBlur(sampler integralImage,sampler radiusImage,float scale,vec4 e) {
  vec4 v = unpremultiply(sample(radiusImage, samplerCoord(radiusImage)));
  float radius = scale * dot(v.rgb,vec3(0.2126, 0.7152, 0.0722));
 radius = max(radius, 0.5);
  vec2 c = destCoord();
  vec2 lowerLeft = clampToRect(c + vec2(-radius-1.0, -radius), e);
  vec2 upperRight = clampToRect(c + vec2(radius, radius+1.0), e);
  vec4 ul = sampleBilinear(integralImage, vec2(lowerLeft.x, upperRight.y));
  vec4 ur = sampleBilinear(integralImage, upperRight);
  vec4 ll = sampleBilinear(integralImage, lowerLeft);
  vec4 lr = sampleBilinear(integralImage, vec2(upperRight.x, lowerLeft.y));
  vec4 rc = ul + lr - ur - ll;
  vec2 diagonal = upperRight - lowerLeft;
  float usedArea = abs(diagonal.x * diagonal.y);
  float originalArea = (2.0*radius+1.0) * (2.0*radius+1.0);
 rc /= rc.a;
 rc.a = 1.0;
  return premultiply(rc);
inputRadiusImage
T@"CIImage",&,N,VinputRadiusImage
kernel vec4 _white(__sample src)
  return vec4(src.a);
kernel vec4 _cmyk_convert(__sample src, vec2 ucrgcr)
  vec4 pix = src;
  vec3 v = 1.0 - pix.rgb;
  float f = min(min(v.r,v.g),v.b) * ucrgcr.y;
  float sblack = f * f;
  float removed = sblack * ucrgcr.x;
  pix.rgb = v - vec3(removed);
  pix.a = sblack;
  return pix;
kernel vec4 _cmyk_cyan(__sample sofar, __sample cmyksrc, vec2 center, vec4 mtx, float con)
  vec2 pt = destCoord() - center;
  pt = vec2(dot(pt, mtx.xy),dot(pt, mtx.zw));
  pt = fract(pt + center) * 6.2831853;
  float g = (sin(pt.x) + sin(pt.y)) * 0.25 * (0.995 - 1.0 / con) + 0.5;
  float f = clamp((cmyksrc.r - g) * con + 0.5, 0.0, 1.0);
  vec4 ink = mix(vec4(1.0), vec4(0.0,1.0,1.0,1.0), f);
  return clamp(ink * sofar, 0.0, 1.0);
kernel vec4 _cmyk_magenta(__sample sofar, __sample cmyksrc, vec2 center, vec4 mtx, float con)
  vec2 pt = destCoord() - center;
  pt = vec2(dot(pt, mtx.xy),dot(pt, mtx.zw));
  pt = fract(pt + center) * 6.2831853;
  float g = (sin(pt.x) + sin(pt.y)) * 0.25 * (0.995 - 1.0 / con) + 0.5;
  float f = clamp((cmyksrc.g - g) * con + 0.5, 0.0, 1.0);
  vec4 ink = mix(vec4(1.0), vec4(1.0,0.0,1.0,1.0), f);
  return clamp(ink * sofar, 0.0, 1.0);
kernel vec4 _cmyk_yellow(__sample sofar, __sample cmyksrc, vec2 center, vec4 mtx, float con)
  vec2 pt = destCoord() - center;
  pt = vec2(dot(pt, mtx.xy),dot(pt, mtx.zw));
  pt = fract(pt + center) * 6.2831853;
  float g = (sin(pt.x) + sin(pt.y)) * 0.25 * (0.995 - 1.0 / con) + 0.5;
  float f = clamp((cmyksrc.b - g) * con + 0.5, 0.0, 1.0);
  vec4 ink = mix(vec4(1.0), vec4(1.0,1.0,0.0,1.0), f);
  return clamp(ink * sofar, 0.0, 1.0);
kernel vec4 _cmyk_black(__sample sofar, __sample cmyksrc, vec2 center, vec4 mtx, float con)
  vec2 pt = destCoord() - center;
  pt = vec2(dot(pt, mtx.xy),dot(pt, mtx.zw));
  pt = fract(pt + center) * 6.2831853;
  float g = (sin(pt.x) + sin(pt.y)) * 0.25 * (0.995 - 1.0 / con) + 0.5;
  float f = clamp((cmyksrc.a - g) * con + 0.5, 0.0, 1.0);
  vec4 ink = mix(vec4(1.0), vec4(0.0,0.0,0.0,1.0), f);
  return clamp(ink * sofar, 0.0, 1.0);
inputGCR
inputUCR
 <%04x:%04x:%04x:%04x:%04x>
kernel vec2 _wrapMirror (vec2 dim) { return mix(dim - abs(dim-destCoord()), abs(destCoord()), vec2(lessThan(destCoord(), 0.5 * dim))); }
kernel vec4 _lumaMap (__sample pixel, sampler2D table,vec2 normalizer)
  float luma = dot(pixel, vec4(0.299, 0.587, 0.114, 0.0));
  vec4 result = texture2D(table, vec2(normalizer.x * luma + normalizer.y, 0.5));
  result.a = pixel.a;
  return result;
10.11
PDF417OptionCompactionMode
PDF417OptionUseCompactStyle
PDF417OptionErrorCorrectionLevel
PDF417OptionAlwaysSpecifyCompaction
PDF417OptionDataColumns
PDF417OptionRows
PDF417OptionMinWidth
PDF417OptionMaxWidth
PDF417OptionMinHeight
PDF417OptionMaxHeight
PDF417OptionPreferredAspectRatio
CGImageRef PDF417CreateBarcodeImage(NSData *, NSDictionary *, NSError **)
<Unknown Function>
/Library/Caches/com.apple.xbs/Sources/EmbeddedCoreImage_Sim/EmbeddedCoreImage-449/Framework/filters/Barcodes/PDF417.m
<Unknown File>
Invalid parameter not satisfying: %@
message != nil
The message must contain at least one character.
Message is longer than is supportable by barcode format.
Unable to create barcode. 
com.apple.pdf417
;<>@[\]_`~!
-.$/"|*()?{}'
Specified %@, %ld, is less than the minimum, %ld.
Specified %@, %ld, is greater than the maximum, %ld.
__EmitCodeWordsWithTextCompactionMode_block_invoke
cannot flush an odd number of half code words
v16@?0c8i12
Message cannot be encoded with PDF417CompactionModeText because it contains character '%d'
Message cannot be encoded with PDF417CompactionModeNumeric because it contains character '%d'
It is not possible to encode a message this long with the recommended level of error correction
NSInteger ErrorCorrectionCodeWordCountForLevel(NSInteger)
Error correction level must be between 0 and 8!
Unable to fit message into space available!
inputMessage
T@"NSData",C,N,VinputMessage
inputOptions
CIPDF417BarcodeGenerator filter requires NSData for inputMessage
CIPDF417BarcodeGenerator could not generate an image
inputMinWidth
T@"NSNumber",C,N,VinputMinWidth
inputMaxWidth
T@"NSNumber",C,N,VinputMaxWidth
inputMinHeight
T@"NSNumber",C,N,VinputMinHeight
inputMaxHeight
T@"NSNumber",C,N,VinputMaxHeight
inputDataColumns
T@"NSNumber",C,N,VinputDataColumns
inputRows
T@"NSNumber",C,N,VinputRows
inputPreferredAspectRatio
T@"NSNumber",C,N,VinputPreferredAspectRatio
inputCompactionMode
T@"NSNumber",C,N,VinputCompactionMode
inputCompactStyle
T@"NSNumber",C,N,VinputCompactStyle
inputCorrectionLevel
T@"NSNumber",C,N,VinputCorrectionLevel
inputAlwaysSpecifyCompaction
T@"NSNumber",C,N,VinputAlwaysSpecifyCompaction
QRCodeOptionErrorCorrectionLevel
CIQRCodeGenerator filter requires NSData for inputMessage
CIQRCodeGenerator filter requires L, M, Q, or H for inputCorrectionLevel
T@"NSString",C,N,VinputCorrectionLevel
AztecOptionErrorCorrectionPercentage
AztecOptionLayers
AztecOptionUseCompactStyle
CIAztecCodeGenerator filter requires NSData for inputMessage
CIAztecCodeGenerator filter requires nil or a number between 5 and 95 for inputCorrectionLevel
CIAztecCodeGenerator filter requires nil or a number between 1 and 32 for inputLayers
CIAztecCodeGenerator filter requires nil or @YES or @NO for inputCompactStyle
CIAztecCodeGenerator could not generate an image
inputLayers
T@"NSNumber",C,N,VinputLayers
CICode128BarcodeGenerator filter requires NSData for inputMessage
CICode128BarcodeGenerator could not generate an image
inputQuietSpace
T@"NSNumber",C,N,VinputQuietSpace
inputBarcodeHeight
T@"NSNumber",C,N,VinputBarcodeHeight
ThumbnailCluster - adding %s
[CIBurstThumbnailCluster initWithImageData] : metadata parsing error
[CIBurstThumbnailCluster initWithImageData] : no error
burstImages
T@"NSMutableArray",VburstImages
imageProps
T@"NSMutableDictionary",VimageProps
T@"CIBurstYUVImage",Vimage
completionBlock
T@?,VcompletionBlock
kernel vec4 _crystallize(sampler src, sampler noise, vec2 cellSize, vec2 offset)
  float tSize = 256.;
  vec4 u1, u2, u3, u4;
  vec2 t0 = destCoord();
  vec2 cellCorner = (floor(t0 * cellSize.y - 0.5) + 0.5) * cellSize.x + 0.5;
  vec2 t1 = cellCorner * cellSize.y + offset;
  t1 = t1 + vec2(-.5,-.5);
  vec2 t2 = t1 + vec2(1.0, 0.0);
  vec2 t3 = t1 + vec2(0.0, 1.0);
  vec2 t4 = t1 + vec2(1.0, 1.0);
  vec4 c1 = sample(noise, samplerTransform(noise, mod(t1, tSize)));
  vec4 c2 = sample(noise, samplerTransform(noise, mod(t2, tSize)));
  vec4 c3 = sample(noise, samplerTransform(noise, mod(t3, tSize)));
  vec4 c4 = sample(noise, samplerTransform(noise, mod(t4, tSize)));
  u1.xy = cellCorner;
  u2.xy = u1.xy + vec2(cellSize.x, 0.0);
  u3.xy = u1.xy + vec2(0.0, cellSize.x);
  u4.xy = u1.xy + vec2(cellSize.x, cellSize.x);
  float cellSize3 = cellSize.x * 0.65;
  u1.xy += (c1.rg - 0.5) * cellSize3;
  u2.xy += (c2.rg - 0.5) * cellSize3;
  u3.xy += (c3.rg - 0.5) * cellSize3;
  u4.xy += (c4.rg - 0.5) * cellSize3;
  vec2 d0 = t0 - u1.xy;
  u1.z = dot(d0,d0);
  d0 = t0 - u2.xy;
  u2.z = dot(d0,d0);
  d0 = t0 - u3.xy;
  u3.z = dot(d0,d0);
  d0 = t0 - u4.xy;
  u4.z = dot(d0,d0);
  vec4 desc = vec4(u1.z - u2.z);
  vec4 v1 = compare(desc, u1, u2);
  vec4 v2 = compare(desc, u2, u1);
  desc = vec4(u3.z - u4.z);
  vec4 v3 = compare(desc, u3, u4);
  vec4 v4 = compare(desc, u4, u3);
  desc = vec4(v1.z - v3.z);
  u1 = compare(desc, v1, v3);
  u2 = compare(desc, v3, v1);
  desc = vec4(v2.z - v4.z);
  u3 = compare(desc, v2, v4);
  desc = vec4(u2.z - u3.z);
  u2 = compare(desc, u2, u3);
  float alpha = clamp((sqrt(u2.z) - sqrt(u1.z)) * 0.5 + 0.5, 0.0, 1.0);
  vec4 p1 = sample(src, samplerTransform(src, u1.xy));
  vec4 p2 = sample(src, samplerTransform(src, u2.xy));
  return mix(p2, p1, alpha);
kernel vec4 _passThroughColor (__sample s) { return s; }
kernel vec2 _passThroughWarp () { return destCoord(); }
kernel vec4 _passThroughGeneral (sampler s)
{ return sample(s, samplerCoord(s)); }
kernel vec4 _passThroughGeneralAlt (sampler s, float v)
{ return sample(s, samplerCoord(s)+v); }
Error: bitAt parameter index out of range
Error: bitAppendBit bad bit
Error: bitAppendBits num bits must be between 0 and 32
Error: bitXor bitVector sizes don't match
Error: byteArrayAt ByteArray is NULL
Error: byteArraySetIndex ByteArray is NULL
Error: byteArraySetSource ByteArray is NULL
Error: byteMatrixInitWithSizes ByteMatrix is NULL
Error: createQRCodeWithHint invalid QR code
Shift_JIS
Error: initQRCode cannot find proper rs block info (input data too big?)
Error: data bits cannot fit in the QR Code
Error: terminateBits number of bits is not a multiple of 8
Error: terminateBits bits size does not equal capacity
Error: getNumDataBytesAndNumECBytesForBlockID block ID too large
Error: getNumDataBytesAndNumECBytesForBlockID EC bytes mismatch
Error: getNumDataBytesAndNumECBytesForBlockID total bytes mismatch
Error: interleaveWithECBytes number of bits and data bytes does not match
Error: interleaveWithECBytes memory allocation failed
Error: interleaveWithECBytes data bytes does not match offset
Error: interleaveWithECBytes interleaving error
Error: appendLengthInfo %d is bigger than %d
Error: appendBytes invalid mode
Error: appendAlphanumericBytes appendAlphanumericBytes
Error: invalid byte sequence
ISO-8859-1
BYTE
Cp437
ISO8859_1
ISO-8859_1
ISO8859_2
ISO8859_3
ISO8859_4
ISO8859_5
ISO8859_6
ISO8859_7
ISO8859_8
ISO8859_9
ISO8859_10
ISO8859_11
ISO8859_13
ISO8859_14
ISO8859_15
ISO8859_16
SJIS
KANJI
ALPHANUMERIC
NUMERIC
Error: embedPositionDetectionPattern the matrix element should be empty
Error: embedHorizontalSeparationPattern the matrix element should be empty
Error: the matrix element should be empty
Error: embedDarkDotAtLeftBottomCorner matrix element wrong value
Error: embedTimingPatternsMatrix matrix element invalid value
Error: makeTypeInfoBitsErrorCorrectionLevel should not happen but we got: %d
Error: number should not be negative!
Error: makeVersionInfoBitsVersion should not happen but we got: %d
Error: embedDataBits not all bits consumed: %i / %i
Error: invalid mask pattern: %d
Error: getCharacterCountBits character count doesn't apply to this mode
Error: inverse argument error
Error: createMonomial arugment error
Error: fillPoly argument error
Error: polyCoefficient argument error
Error: multiplyByMonomial arugment error
Error: divide by 0
Error: encode no error correction bytes
Error: encode no data bytes provided
kernel vec4 _sunbeams(sampler noise, vec4 centers, vec4 params, __color color)
  float sunRadius2 = params.x; 
  float striationFactor = params.y; 
  float a = params.z; 
  float b = params.w; 
  vec2  v = destCoord() - centers.xy; 
  float len = length(v);
  float len2 = dot(v,v);
  vec2  noiseCtr = centers.zw; 
  vec2  noiseLoc = normalize(v) * 50.0 + noiseCtr; 
  vec4  npix = sample(noise, samplerTransform(noise, noiseLoc)); 
  float noiseAmount = npix.r * a + b;
  float f2 = sunRadius2 / (len2+0.0001);
  vec4  pix = f2 * color + noiseAmount; 
  return pix * clamp(1.0 - len * striationFactor, 0.0, 1.0); 
inputSunRadius
inputMaxStriationRadius
Error: versionForNumber version number is not between 0 and 40
kernel vec4 _blendGrains(__sample isoImages, float log10iso)
  vec4 c = isoImages; 
  float mix10_50    = mix(c.r, c.g, log10iso*1.43067655809 
                                           - 1.43067655809); 
  float mix50_400   = mix(c.g, c.b, log10iso*1.10730936496 
                                           - 1.88128539659); 
  float mix400_3200 = mix(c.b, c.a, log10iso*1.10730936496 
                                           - 2.88128539659); 
  float v = compare(log10iso - 1.69897000434,                     mix10_50,                     compare(log10iso - 2.60205999133,                             mix50_400,                             mix400_3200)); 
  return vec4(v,v,v,1.0);
kernel vec4 _grainBlendAndMix(__sample greyImage, __sample grainImage, float contrast, float mixAmount)
  float luminance = greyImage.r; 
  float gamma = 4.01 - 2.0*luminance;
  float grey = pow(luminance, 1.0/gamma);
  float grain = grainImage.r - 0.5;
  float mult = contrast * grain;
  float photo = grey + max(grey, 0.5) * mult * (1.0-luminance);
  photo = sign(photo) * pow(abs(photo), gamma);
  vec4 pix1 = vec4(photo,photo,photo,greyImage.a);
  return mix(greyImage, pix1, mixAmount);
kernel vec2 _paddedTile2(vec4 k) { return fract(destCoord() * k.zw) * k.xy + vec2(1.0); }
noiseImage
T@"NSNumber",C,N,VinputISO
T@"NSNumber",C,N,VinputAmount
GLTexture %d
MTLTexture %p
 %dx%d
com.apple.coreimage.photoEffectsIsolation
%@.%d
scube
GLTexture %d<BR/>
MTLTexture %p<BR/>
Cannot render image (with an input %s texture) using a %s context.
Metal
T@"NSNumber",&,N,VinputSigmaX
T@"NSNumber",&,N,VinputSigmaY
kernel vec4 _gaussianReduce4(sampler src, vec4 scale)
  vec2 d = destCoord() * scale.xy;
  vec4 q  = sample(src, samplerTransform(src, d));
  vec4 s  = q*0.249105655;
  vec2 o = vec2(1.95019665)*scale.zw;
  q  = sample(src, samplerTransform(src, d-o)) + sample(src, samplerTransform(src, d+o));
  s += q*0.204995265;
  o  = vec2(3.90137021)*scale.zw;
  q  = sample(src, samplerTransform(src, d-o)) + sample(src, samplerTransform(src, d+o));
  s += q*0.11422973;
  o  = vec2(5.85840079)*scale.zw;
  q  = sample(src, samplerTransform(src, d-o)) + sample(src, samplerTransform(src, d+o));
  s += q*0.0433552031;
  o  = vec2(7.86886245)*scale.zw;
  q  = sample(src, samplerTransform(src, d-o)) + sample(src, samplerTransform(src, d+o));
  s += q*0.0128669748;
  return s;
kernel vec4 _gaussianReduce2(sampler src, vec4 scale)
  vec2 d = destCoord() * scale.xy;
  vec2 o1 = vec2(1.84623909)*scale.zw;
  vec2 o2 = vec2(3.74518052)*scale.zw;
  vec4 q1  = sample(src, samplerTransform(src, d - o2));
  vec4 q2  = sample(src, samplerTransform(src, d - o1));
  vec4 q3  = sample(src, samplerTransform(src, d));
  q2 += sample(src, samplerTransform(src, d + o1));
  q1 += sample(src, samplerTransform(src, d + o2));
  return 0.432290834*q3 + 0.24061645*q2 + 0.0432381327*q1;
kernel vec4 _gaussianBlur19(sampler src, vec4 offset01, vec4 offset23, vec4 offset4, vec4 weight, vec4 weight2)
  vec2 d   = destCoord();
  vec4 q0  = sample(src, samplerTransform(src, d - offset4.xy));
  vec4 q1  = sample(src, samplerTransform(src, d - offset23.zw));
  vec4 q2  = sample(src, samplerTransform(src, d - offset23.xy));
  vec4 q3  = sample(src, samplerTransform(src, d - offset01.zw));
  vec4 q4  = sample(src, samplerTransform(src, d - offset01.xy));
  vec4 q5  = sample(src, samplerTransform(src, d + offset01.xy));
  vec4 q6  = sample(src, samplerTransform(src, d + offset01.zw));
  vec4 q7  = sample(src, samplerTransform(src, d + offset23.xy));
  vec4 q8  = sample(src, samplerTransform(src, d + offset23.zw));
  vec4 q9  = sample(src, samplerTransform(src, d + offset4.xy));
  return weight.x*(q4+q5) + weight.y*(q3+q6) + weight.z*(q2+q7) + weight.w*(q1+q8) + weight2.x*(q0+q9);
kernel vec4 _gaussianBlur15(sampler src, vec4 offset01, vec4 offset23, vec4 weight)
  vec2 d   = destCoord();
  vec4 q0  = sample(src, samplerTransform(src, d - offset23.zw));
  vec4 q1  = sample(src, samplerTransform(src, d - offset23.xy));
  vec4 q2  = sample(src, samplerTransform(src, d - offset01.zw));
  vec4 q3  = sample(src, samplerTransform(src, d - offset01.xy));
  vec4 q4  = sample(src, samplerTransform(src, d + offset01.xy));
  vec4 q5  = sample(src, samplerTransform(src, d + offset01.zw));
  vec4 q6  = sample(src, samplerTransform(src, d + offset23.xy));
  vec4 q7  = sample(src, samplerTransform(src, d + offset23.zw));
  return weight.x*(q3+q4) + weight.y*(q2+q5) + weight.z*(q1+q6) + weight.w*(q0+q7);
kernel vec4 _gaussianBlur11(sampler src, vec4 offset01, vec4 offset2, vec4 weight)
  vec2 d   = destCoord();
  vec4 q1  = sample(src, samplerTransform(src, d - offset2.xy));
  vec4 q2  = sample(src, samplerTransform(src, d - offset01.zw));
  vec4 q3  = sample(src, samplerTransform(src, d - offset01.xy));
  vec4 q4  = sample(src, samplerTransform(src, d + offset01.xy));
  vec4 q5  = sample(src, samplerTransform(src, d + offset01.zw));
  vec4 q6  = sample(src, samplerTransform(src, d + offset2.xy));
  return weight.x*(q3+q4) + weight.y*(q2+q5) + weight.z*(q1+q6);
kernel vec4 _gaussianBlur7(sampler src, vec4 offset01, vec4 weight)
  vec2 d   = destCoord();
  vec4 q2  = sample(src, samplerTransform(src, d - offset01.zw));
  vec4 q3  = sample(src, samplerTransform(src, d - offset01.xy));
  vec4 q4  = sample(src, samplerTransform(src, d + offset01.xy));
  vec4 q5  = sample(src, samplerTransform(src, d + offset01.zw));
  return weight.x*(q3+q4) + weight.y*(q2+q5);
kernel vec4 _gaussianBlur3(sampler src, vec4 offset0)
  vec2 d = destCoord();
  return (sample(src, samplerTransform(src, d - offset0.xy)) + sample(src, samplerTransform(src, d + offset0.xy))) * 0.5;
kernel vec4 _unsharpmask (__sample s, __sample b, float k) { s.rgb += (s.rgb - b.rgb * (s.a/max(b.a, 0.0001))) * k; return s; }
dividerScore
Tf,VdividerScore
trueLocalMaximum
Ti,VtrueLocalMaximum
leftImage
Ti,VleftImage
actionAmount
Tf,VactionAmount
noiseThreshold
Tf,VnoiseThreshold
highNoiseThreshold
Tf,VhighNoiseThreshold
fftGrayMag
/Library/Caches/com.apple.xbs/Sources/EmbeddedCoreImage_Sim/EmbeddedCoreImage-449/Framework/api/Detectors/CCRect/fftAngleHistogram.c
fftSize > 0
fft2DMagShift
nOver2 > 0
noop_affine
noop_forced
noop_contextlimits
noop_multiuse
noop_samplemode
noop_disablemerging
%-15s %@
CGImageRef AztecCreateBarcodeImage(NSData *, NSDictionary *, NSError **)
/Library/Caches/com.apple.xbs/Sources/EmbeddedCoreImage_Sim/EmbeddedCoreImage-449/Framework/filters/Barcodes/Aztec.m
msgData != nil
The message is too long for an Aztec barcode.
Head
%@ '%c'
NumStates (bad value?)
<unknown state>
Latch %@->%@
Shift %@->%@
<null two char punc val>
P 'CR' 'LF'
P '.' ' '
P ',' ' '
P ':' ' '
<unknown two char punc>
len %d
com.apple.aztec
len:%ld seq:
CreateSeqEntryPool
initialCapacity > 0
AztecDebugSequence
%@=%@
The message doesn't fit into the specified number of layers, %d.
The message is too large for an Aztec barcode.
Specified %@, %d, is less than the minimum, %d.
Specified %@, %d, is greater than the maximum, %d.
The message does not fit into the space allocated in the barcode.
i16@?0i8i12
i12@?0i8
v16@?0i8i12
v20@?0i8i12B16
kernel vec2 _paddedTile(vec4 k) { return fract(destCoord() * k.zw) * k.xy + vec2(1.0); }
com.apple.coreimage.halftoneKernelIsolation
kernel vec4 _dotscreen (__sample s, vec3 params, vec4 mtx)
  vec2 pt = destCoord() - params.xy;
  pt = vec2(dot(pt, mtx.xy), dot(pt, mtx.zw));
  pt = fract(pt + params.xy) * 6.2831853;
  float g = (sin(pt.x) + sin(pt.y)) * 0.25 * (0.995 - 1.0 / params.z) + 0.5;
  float l = dot(s.rgb, vec3(0.2125, 0.7154, 0.0721));
  s.rgb = vec3(clamp((l - g) * params.z + 0.5, 0.0, 1.0) * s.a);
  return s;
kernel vec4 _hatchedscreen (__sample s, vec3 params, vec4 mtx)
  vec2 pt = destCoord() - params.xy;
  pt = vec2(dot(pt, mtx.xy), dot(pt, mtx.zw));
  pt = fract(pt.xy + params.xy);
  pt = min(vec2(1.0) - pt, pt) * 2.0;
  float g = min(pt.x, pt.y * .5 + .5);
  float l = dot(s.xyz, vec3(.2125, .7154, .0721));
  s.rgb = vec3(clamp((l - g) * params.z + 0.5, 0.0, 1.0) * s.a);
  return s;
kernel vec4 _linescreen (__sample s, vec3 params, vec4 mtx)
  vec2 pt = destCoord() - params.xy;
  pt = vec2(dot(pt, mtx.xy), dot(pt, mtx.zw));
  pt = fract(pt.xy + params.xy);
  float g = min(1.0 - pt.x, pt.x) * 2.0;
  float l = dot(s.xyz, vec3(.2125, .7154, .0721));
  s.rgb = vec3(clamp((l - g) * params.z + 0.5, 0.0, 1.0) * s.a);
  return s;
kernel vec4 _circularscreen (__sample s, vec4 params)
  float d = length(destCoord() - params.xy);
  d = fract(d * params.z);
  d = min(1.0 - d, d);
  d = dot(s.rgb, vec3(.2125, .7154, .0721)) - d * 2.0;
  d = clamp(d * params.w + .5, 0.0, 1.0);
  s.rgb = vec3(d) * s.a;
  return s;
kernel vec4 _bloom (__sample s, __sample b, float k) { return mix(s, max(s,b), k); }
kernel vec4 _gloom (__sample s, __sample b, float k) { return mix(s, min(s,b), k); }
inputLevels
kernel vec4 _colorPosterize (__sample src, vec2 factors)
  src.rgb = floor(src.rgb * factors.x + 0.5) * factors.y;
  return src;
T@"NSNumber",&,N,VinputLevels
kernel vec4 _edges(sampler src, float scale)
  vec2 dc = destCoord();
  vec4 r0 = sample (src, samplerTransform(src, dc + vec2(0.0,-1.0)));
  vec4 r3 = sample (src, samplerTransform(src, dc + vec2(1.0,-1.0)));
  vec4 r2 = sample (src, samplerTransform(src, dc + vec2(1.0, 0.0)));
  vec4 r1 = sample (src, samplerCoord(src));
  r3 = r1 - r3;
  r2 = r0 - r2;
  r2 = (r3 * r3 + r2 * r2) * scale;
  return vec4(r2.rgb, r1.a);
kernel vec4 _disolve (__sample src0, __sample src1, float factor) { return mix(src1, src0, factor); }
kernel vec4 _fadeDissolve (__sample src, float factor) { return src*factor; }
T@"CIImage",&,N,VinputTargetImage
T@"NSNumber",&,N,VinputTime
kernel vec4 maskToAlpha (__sample src) { return src.yyyy; }
kernel vec2 _pixellate (vec2 c, vec2 params) { return (floor((destCoord() - c) * params.x) + 0.5) * params.y + c; }
kernel vec4 _hexagonalPixellate(sampler src, vec2 center, vec2 skew_to_unit, vec2 unit_to_skew, float sqrt3inv)
  vec2 t0 = destCoord() - center;
  vec2 t0_skewed = t0;
  t0_skewed.x -= t0_skewed.y * sqrt3inv;
  vec2 t0_unit = t0_skewed * skew_to_unit;
  vec2 t0_slot = floor(t0_unit);
  vec2 t0_offset = t0_unit - t0_slot;
  vec2 t0_base = t0_slot * unit_to_skew;
  vec2 p0 = t0_base;
  vec2 p1 = t0_base;
  p1.y = p1.y + unit_to_skew.y;
  vec2 p2 = t0_base;
  p2.x = p2.x + unit_to_skew.x;
  vec2 p3 = t0_base + unit_to_skew;
  p0 = compare(vec2(t0_offset.x + t0_offset.y - 1.0), p0, p3);
  p0.x += p0.y * sqrt3inv;
  p1.x += p1.y * sqrt3inv;
  p2.x += p2.y * sqrt3inv;
  vec2 d0 = t0 - p0;
  d0 = d0 * d0;
  float d1 = d0.x + d0.y;
  vec3 s0 = vec3(p0, d1 * inversesqrt(d1));
  d0 = t0 - p1;
  d0 = d0 * d0;
  d1 = d0.x + d0.y;
  vec3 s1 = vec3(p1, d1 * inversesqrt(d1));
  d0 = t0 - p2;
  d0 = d0 * d0;
  d1 = d0.x + d0.y;
  vec3 s2 = vec3(p2, d1 * inversesqrt(d1));
  vec3 desc = vec3(s0.z - s1.z);
  vec3 s3 = compare(desc, s0, s1);
  vec3 s4 = compare(desc, s1, s0);
  desc = vec3(s3.z - s4.z);
  vec3 s5 = compare(desc, s3, s2);
  vec3 s6 = compare(desc, s2, s3);
  desc = vec3(s4.z - s6.z);
  vec3 s7 = compare(desc, s4, s6);
  vec4 c0 = sample(src, samplerTransform(src, s5.xy + center));
  vec4 c1 = sample(src, samplerTransform(src, s7.xy + center));
  return mix(c0, c1, clamp((s5.z - s7.z) * 0.5 + 0.5, 0.0, 1.0));
kernel vec4 _sharpenLuminance(__sample ip, __sample bl, float s)
  vec3 luminance = vec3(0.299, 0.587, 0.114);
  vec3 invLuminance = vec3(1.0, -0.5093696763, -0.1942078365);
  float intensity = 1.0 + s;
  vec3  s0,s1;
  s0.x  = dot(luminance, bl.rgb);
  s0.yz = bl.rb - s0.x;
  s1.x  = dot(luminance, ip.rgb);
  s1.yz = ip.rb - s1.x;
  s0    = mix(s0,s1, intensity);
  ip.g  = dot(invLuminance, s0);
  ip.rb = s0.yz + s0.x;
  return ip;
inputOpacity
kernel vec4 _swipeTransition(__sample src0, __sample src1, __color color, vec4 parms)
  float k1 = clamp(dot(vec4(destCoord(), 1.0, 0.0), parms), 0.0, 1.0);
  float k0 = min(1.0-k1, k1) * 2.0 * parms.w;
  return mix(mix(src1, src0, k1), color, k0);
T@"NSNumber",&,N,VinputOpacity
T@"NSNumber",&,N,VinputWeights
kernel vec4 _max3x3 (sampler s, vec4 d)
    vec2 p = destCoord ();
    vec4 c =   sample(s, samplerTransform(s, p - d.yy));
    c = max(c, sample(s, samplerTransform(s, p - d.wx)));
    c = max(c, sample(s, samplerTransform(s, p + d.yz)));
    c = max(c, sample(s, samplerTransform(s, p - d.xw)));
    c = max(c, sample(s, samplerTransform(s, p       )));
    c = max(c, sample(s, samplerTransform(s, p + d.xw)));
    c = max(c, sample(s, samplerTransform(s, p - d.yz)));
    c = max(c, sample(s, samplerTransform(s, p + d.wx)));
    c = max(c, sample(s, samplerTransform(s, p + d.yy)));
    return c;
kernel vec4 _min3x3 (sampler s, vec4 d)
    vec2 p = destCoord ();
    vec4 c =   sample(s, samplerTransform(s, p - d.yy));
    c = min(c, sample(s, samplerTransform(s, p - d.wx)));
    c = min(c, sample(s, samplerTransform(s, p + d.yz)));
    c = min(c, sample(s, samplerTransform(s, p - d.xw)));
    c = min(c, sample(s, samplerTransform(s, p       )));
    c = min(c, sample(s, samplerTransform(s, p + d.xw)));
    c = min(c, sample(s, samplerTransform(s, p - d.yz)));
    c = min(c, sample(s, samplerTransform(s, p + d.wx)));
    c = min(c, sample(s, samplerTransform(s, p + d.yy)));
    return c;
kernel vec4 _gradient (__sample sMax, __sample sMin)
  return vec4( (sMax.rgb - sMin.rgb) * .5, sMax.a);
kernel vec4 _laplacian (__sample s, __sample sMax, __sample sMin)
  return vec4( (sMax.rgb + sMin.rgb - 2.0 * s.rgb) * .5, s.a);
kernel vec4 _average (__sample s0, __sample s1, float w)
  return mix(s0, s1, w);
Unable to load liblowLevelDetectors.dylib from %s
CCRectLowLevel
initializePerMesh
createPerMeshForFFTSIZE
horizonDetectionFFT
/System/Library/PrivateFrameworks/CVML.framework/liblowLevelDetectors.dylib
2.006 -   May 13, 2015
1.021 - Aug 1, 2013
BurstSet_AlgorithmVersion
Image_ISPFacesArray
Image_ImageScore
Image_Timestamp
Image_YUVData
ImageYUVWidth
ImageYUVHeight
ImageYData
ImageUVData
ImageYUVBytesPerRow
Image_TimeReceived
Image_TimeQueued
Image_TimeConverted
Image_TimeStartedAnalysis
Image_TimeStartedFaceDetection
Image_TimeDoneFaceDetection
Image_TimeDoneFaceBlinkDetection
Image_TimeDoneFaceFocusScore
Image_TimeDoneAnalysis
ImageFace_ID
ImageFaceX
ImageFaceY
ImageFaceW
ImageFaceH
ImageFaceFocusScore
ImageFaceLeftEyeOpen
ImageFaceRightEyeOpen
ImageFaceSmiling
ImageFaceLeftEyePosX
ImageFaceLeftEyePosY
ImageFaceRightEyePosX
ImageFaceRightEyePosY
ImageFaceTimestamp
ImageFaceRollAngle
ImageFaceYawAngle
ImageFaceLeftEyeBlinkScore
ImageFaceRightEyeBlinkScore
ImageFaceSmileScore
ImageFaceSmallFace
ImageSet_Version
ImageSetVersion_Default
ImageSetVersion_Latest
BurstSet_TimeDoneCapturing
BurstSet_TimeDone
BurstSet_Setting_MaxNumPendingFrames
BurstSet_Setting_DisableAnalysis
BurstSet_Setting_DisableFaceCore
BurstSet_Setting_DummyAnalysisCount
BurstSet_Setting_ForceFaceDetection
BurstSet_Setting_EnableDumpYUV
BurstSet_IsAction
BurstSet_IsPortrait
BurstSet_CoverImage
BURST ANALYSIS VERSION = %s (%s)
   initWithBurstImageSet - Error: stats not found
fosl_filter_kernelpool_createPool
fosl_filter_kernelpool_hasError
fosl_filter_kernelpool_addLibrary
fosl_filter_kernelpool_addString
fosl_filter_kernelpool_destroyPool
fosl_filter_kernelpool_getNumKernels
fosl_filter_kernelpool_lookupKernel
fosl_filter_kernelpool_getKernelByIdx
fosl_filter_kernelpool_getNumDiagnostics
fosl_filter_kernelpool_getDiagnosticByIdx
fosl_filter_kernelpool_getKernelKind
fosl_filter_kernelpool_getKernelName
fosl_filter_kernelpool_getPrintedKernel
fosl_filter_kernelpool_getKernelDimensionality
fosl_filter_kernelpool_isPositionInvariant
fosl_filter_kernelpool_preservesAlpha
fosl_filter_kernelpool_getNumKernelParameters
fosl_filter_kernelpool_getParamName
fosl_filter_kernelpool_getParamType
fosl_filter_kernelpool_getNumKernelAttributes
fosl_filter_kernelpool_getAttributeKeyword
fosl_filter_kernelpool_getAttributeParameters
fosl_filter_kernelpool_hasAttributeParameters
fosl_filter_createGraph
fosl_filter_assignRoot
fosl_filter_destroyGraph
fosl_filter_createKernel
fosl_filter_addLibraryFunction
fosl_filter_addChild
fosl_filter_createImage
fosl_filter_createUniform
fosl_filter_createConstant
fosl_filter_createTransformMatrix
fosl_filter_createSampleTransform
fosl_filter_createUsePosition
fosl_filter_createPositionUpdate
fosl_filter_createCoordinateTransform
fosl_filter_setPositionUpdatePosition
fosl_filter_setPositionUpdateContinuation
fosl_filter_parseNodesInGraph
fosl_filter_synthesizeMainInGraph
fosl_filter_synthesizeMainInGraphOfType
fosl_filter_synthesizeMainInGraphOfTypeWithOptions
fosl_filter_dumpGraph
fosl_filter_printGraph
fosl_filter_getStringForGraph
fosl_filter_getStringForGraphWithOptions
fosl_filter_createReadPixel
/usr/lib/libFosl_dynamic.dylib
IPHONE_SIMULATOR_ROOT
Core Image Fosl wrapper: Unable to determine iPhone simulator root SDK path.
Unable to open Fosl library at path %s
foslFunctions
kernel vec2 holeDistortion (vec2 center, float radius2)
  vec2 delta = destCoord() - center;
  float dist2 = dot(delta,delta);
  return (dist2 <= radius2) ? center : (destCoord() - delta * radius2 / dist2);
kernel vec4 holeAntialias(__sample src, vec2 center, float radius)
  return src * clamp(length(destCoord() - center) - radius, 0.0, 1.0);
kernel vec4 _box4(sampler src)
  vec2 d   = destCoord() * 4.0;
  vec4 q0  = sample(src, samplerTransform(src, d + vec2(-1.0, -1.0)));
  vec4 q1  = sample(src, samplerTransform(src, d + vec2(-1.0, +1.0)));
  vec4 q2  = sample(src, samplerTransform(src, d + vec2(+1.0, -1.0)));
  vec4 q3  = sample(src, samplerTransform(src, d + vec2(+1.0, +1.0)));
  return 0.25*(q0+q1+q2+q3);
kernel vec4 _box6(sampler src)
  vec2 d   = destCoord() * 6.0;
  vec4 q0  = sample(src, samplerTransform(src, d + vec2(-2.0, -2.0)));
  vec4 q1  = sample(src, samplerTransform(src, d + vec2( 0.0, -2.0)));
  vec4 q2  = sample(src, samplerTransform(src, d + vec2(+2.0, -2.0)));
  vec4 q3  = sample(src, samplerTransform(src, d + vec2(-2.0,  0.0)));
  vec4 q4  = sample(src, samplerTransform(src, d + vec2( 0.0,  0.0)));
  vec4 q5  = sample(src, samplerTransform(src, d + vec2(+2.0,  0.0)));
  vec4 q6  = sample(src, samplerTransform(src, d + vec2(-2.0, +2.0)));
  vec4 q7  = sample(src, samplerTransform(src, d + vec2( 0.0, +2.0)));
  vec4 q8  = sample(src, samplerTransform(src, d + vec2(+2.0, +2.0)));
  return (1.0/9.0)*(q0+q1+q2+q3+q4+q5+q6+q7+q8);
kernel vec4 _cross4(sampler src, float weight)
  vec2 d   = destCoord();
  vec4 q0  = sample(src, samplerTransform(src, d));
  vec4 q1  = sample(src, samplerTransform(src, d - vec2(+0.5, +1.5)));
  vec4 q2  = sample(src, samplerTransform(src, d + vec2(+0.5, +1.5)));
  vec4 q3  = sample(src, samplerTransform(src, d - vec2(+1.5, -0.5)));
  vec4 q4  = sample(src, samplerTransform(src, d + vec2(+1.5, -0.5)));
  q1  = 0.23*(q1+q2+q3+q4) + 0.08*q0;
  return mix(q0,q1, weight);
kernel vec4 minimumComponent (__sample s) { return vec4(vec3(min(min(s.r,s.g),s.b)), s.a); }
kernel vec4 maximumComponent (__sample s) { return vec4(vec3(max(max(s.r,s.g),s.b)), s.a); }
kernel vec4 _rectangle (vec4 parms1, vec4 parms2, __color color)
  vec4 d0 = destCoord().xxyy;
  d0 = d0 * parms1 + parms2;
  d0 = clamp(max(d0, d0.yxwz), 0.0, 1.0);
  d0 = 1.0 - smoothstep(0.0, 1.0, d0); 
  return d0.x * d0.z * color; 
kernel vec2 _vortexDistortion(vec2 center, vec2 params)
  vec2 d = destCoord() - center;
  float len = length(d);
  float r = len * params.x - 1.0;
  float a = r * r * params.y / len;
  vec2 sc = vec2(cos(a), sin(a));
  vec2 p = vec2(dot(d, sc), dot(d, vec2(-sc.y, sc.x)));
  return (r >= 0.0) ? destCoord() : p+center;
kernel vec4 _lanczosDownBy2(sampler src, vec4 scale)
  vec2 d   = destCoord() * scale.xy;
  vec2 o0  = scale.zw * 0.732871;
  vec2 o1  = scale.zw * 2.83784;
  vec2 o2  = scale.zw * 4.6968;
  vec4 q0  = sample(src, samplerTransform(src, d - o2));
  vec4 q1  = sample(src, samplerTransform(src, d - o1));
  vec4 q2  = sample(src, samplerTransform(src, d - o0));
  vec4 q3  = sample(src, samplerTransform(src, d + o0));
  vec4 q4  = sample(src, samplerTransform(src, d + o1));
  vec4 q5  = sample(src, samplerTransform(src, d + o2));
  return (0.581891)*(q2+q3) + (-0.100636)*(q1+q4) + (0.0187453)*(q0+q5);
kernel vec4 _lanczosHorizontalUpsample(sampler src, float scale)
  vec4 w;
  vec2 c = destCoord();
  c.x = scale*c.x - 0.5;
  vec2 d = c;
  c.x = floor(c.x);
  float x = (c.x - d.x + 1.0);
  w.z = x*x*(x*(x*(x*-0.41086841 + 0.78286595) + 1.04059357) - 2.41189213) + 1.0;
  w.x = x*x*(x*(x*(x*-0.29216512 + 1.02524562) - 0.52422910) - 0.20885140);
  x = 1.0-x;
  w.y = x*x*(x*(x*(x*-0.41086841 + 0.78286595) + 1.04059357) - 2.41189213) + 1.0;
  w.w = 1.0 - w.x - w.y - w.z;
  vec4 p0  = sample(src, samplerTransform(src, c + vec2(-0.5,0.0)));
  vec4 p1  = sample(src, samplerTransform(src, c + vec2(+0.5,0.0)));
  vec4 p2  = sample(src, samplerTransform(src, c + vec2(+1.5,0.0)));
  vec4 p3  = sample(src, samplerTransform(src, c + vec2(+2.5,0.0)));
  return w.x*p0 + w.y*p1 + w.z*p2 + w.w*p3;
kernel vec4 _lanczosVerticalUpsample(sampler src, float scale)
  vec4    w;
  vec2 c   = destCoord();
  c.y = scale*c.y - 0.5;
  vec2 d   = c;
  c.y = floor(c.y);
  float x = (c.y - d.y + 1.0);
  w.z = x*x*(x*(x*(x*-0.41086841 + 0.78286595) + 1.04059357) - 2.41189213) + 1.0;
  w.x = x*x*(x*(x*(x*-0.29216512 + 1.02524562) - 0.52422910) - 0.20885140);
  x = 1.0-x;
  w.y = x*x*(x*(x*(x*-0.41086841 + 0.78286595) + 1.04059357) - 2.41189213) + 1.0;
  w.w = 1.0 - w.x - w.y - w.z;
  vec4 p0  = sample(src, samplerTransform(src, c + vec2(0.0,-0.5)));
  vec4 p1  = sample(src, samplerTransform(src, c + vec2(0.0,+0.5)));
  vec4 p2  = sample(src, samplerTransform(src, c + vec2(0.0,+1.5)));
  vec4 p3  = sample(src, samplerTransform(src, c + vec2(0.0,+2.5)));
  return w.y*p1 + w.z*p2 + w.x*p0 + w.w*p3;
T@"NSNumber",&,N,VinputAspectRatio
kernel vec4 _blendWithMask (__sample f, __sample b, __sample m) { return mix(b,f,m.g); }
kernel vec4 _blendWithMaskNoB (__sample f, __sample m) { return f * m.g; }
kernel vec4 _blendWithMaskNoF (__sample b, __sample m) { return b * (1.0 - m.g); }
T@"CIImage",&,N,VinputMaskImage
kernel vec4 _blendWithAlphaMask (__sample f, __sample b, __sample m) { return mix(b,f,m.a); }
kernel vec4 _blendWithAlphaMaskNoB (__sample f, __sample m) { return f * m.a; }
kernel vec4 _blendWithAlphaMaskNoF (__sample b, __sample m) { return b * (1.0 - m.a); }
initWithCGImage: %dx%d
Ti,Vwidth
Ti,Vheight
Ti,VbytesPerRow
Ybuffer
T*,VYbuffer
Cbuffer
T*,VCbuffer
Kernel %@ should be of class CIColorKernel
mc00
mc01
mc02
mc10
mc11
mc12
mc20
mc21
mc22
bknd
btpnt
btwid
blamt
bamt
otrcS0
otrcS1
otrcS2
otrcS3
otrcS4
otrcY1
otrcY2
otrcY3
kernel vec4 convertUsingColorMatrix(sampler src, vec4 rv, vec4 gv, vec4 bv) {
  vec4 pix, color;
  pix = sample(src, samplerCoord(src));
  color = pix.r * rv + pix.g * gv + pix.b * bv;
  color.a = pix.a;
  return color;
CIRAWGamutMapping: key %@ was not found in the RAW dictionary
kernel vec4 localBoost(sampler src, vec4 breaks, vec4 coeffs1, vec4 coeffs2, vec4 coeffs3, vec4 coeffs4, float scaleAboveOne) {
  float x;
  vec4 color, powers, interval1, interval2, interval3, interval4, answer;
  color = sample(src, samplerCoord(src));
  x = color.r;
  powers.rgb = vec3(x);
  powers.rg = powers.rg * vec2(x);
  powers.r = powers.r * x;
  powers.a = 1.0;
  interval1.r = dot(powers, coeffs1);
  interval2.r = dot(powers, coeffs2);
  interval3.r = dot(powers, coeffs3);
  interval4.r = dot(powers, coeffs4);
  answer.r = (x - 1.0) * scaleAboveOne + 1.0;
  x = color.g;
  powers.rgb = vec3(x);
  powers.rg = powers.rg * vec2(x);
  powers.r = powers.r * x;
  powers.a = 1.0;
  interval1.g = dot(powers, coeffs1);
  interval2.g = dot(powers, coeffs2);
  interval3.g = dot(powers, coeffs3);
  interval4.g = dot(powers, coeffs4);
  answer.g = (x - 1.0) * scaleAboveOne + 1.0;
  x = color.b;
  powers.rgb = vec3(x);
  powers.rg = powers.rg * vec2(x);
  powers.r = powers.r * x;
  powers.a = 1.0;
  interval1.b = dot(powers, coeffs1);
  interval2.b = dot(powers, coeffs2);
  interval3.b = dot(powers, coeffs3);
  interval4.b = dot(powers, coeffs4);
  answer.b = (x - 1.0) * scaleAboveOne + 1.0;
  answer = compare(color - breaks.w, interval4, answer);
  answer = compare(color - breaks.z, interval3, answer);
  answer = compare(color - breaks.y, interval2, answer);
  answer = compare(color - breaks.x, interval1, answer);
  answer = compare(color, vec4(0.0), answer);
  answer.a = color.a;
  return answer;
kernel vec4 boostRGB(sampler src, vec4 breaks, vec4 coeffs1, vec4 coeffs2, vec4 coeffs3, vec4 coeffs4, float scaleAboveOne) {
  float x;
  vec4 color, powers, interval1, interval2, interval3, interval4, answer;
  color = sample(src, samplerCoord(src));
  x = color.r;
  powers.rgb = vec3(x);
  powers.rg = powers.rg * vec2(x);
  powers.r = powers.r * x;
  powers.a = 1.0;
  interval1.r = dot(powers, coeffs1);
  interval2.r = dot(powers, coeffs2);
  interval3.r = dot(powers, coeffs3);
  interval4.r = dot(powers, coeffs4);
  answer.r = (x - 1.0) * scaleAboveOne + 1.0;
  x = color.g;
  powers.rgb = vec3(x);
  powers.rg = powers.rg * vec2(x);
  powers.r = powers.r * x;
  powers.a = 1.0;
  interval1.g = dot(powers, coeffs1);
  interval2.g = dot(powers, coeffs2);
  interval3.g = dot(powers, coeffs3);
  interval4.g = dot(powers, coeffs4);
  answer.g = (x - 1.0) * scaleAboveOne + 1.0;
  x = color.b;
  powers.rgb = vec3(x);
  powers.rg = powers.rg * vec2(x);
  powers.r = powers.r * x;
  powers.a = 1.0;
  interval1.b = dot(powers, coeffs1);
  interval2.b = dot(powers, coeffs2);
  interval3.b = dot(powers, coeffs3);
  interval4.b = dot(powers, coeffs4);
  answer.b = (x - 1.0) * scaleAboveOne + 1.0;
  answer = compare(color - breaks.w, interval4, answer);
  answer = compare(color - breaks.z, interval3, answer);
  answer = compare(color - breaks.y, interval2, answer);
  answer = compare(color - breaks.x, interval1, answer);
  answer = compare(color, vec4(0.0), answer);
  answer = compare(answer, vec4(0.0), answer);
  answer.a = color.a;
  return answer;
kernel vec4 boostRGBLNoGamma(sampler src, vec4 breaks, vec4 coeffs1, vec4 coeffs2, vec4 coeffs3, vec4 coeffs4, float scaleAboveOne) {
   float x, luminance;
   vec4 color, powers, interval1, interval2, interval3, interval4, answer, xcolor;
   color = sample(src, samplerCoord(src));
   x = color.r;
   powers.rgb = vec3(x);
   powers.rg = powers.rg * vec2(x);
   powers.r = powers.r * x;
   powers.a = 1.0;
   interval1.r = dot(powers, coeffs1);
   interval2.r = dot(powers, coeffs2);
   interval3.r = dot(powers, coeffs3);
   interval4.r = dot(powers, coeffs4);
   x = color.g;
   powers.rgb = vec3(x);
   powers.rg = powers.rg * vec2(x);
   powers.r = powers.r * x;
   powers.a = 1.0;
   interval1.g = dot(powers, coeffs1);
   interval2.g = dot(powers, coeffs2);
   interval3.g = dot(powers, coeffs3);
   interval4.g = dot(powers, coeffs4);
   x = color.b;
   powers.rgb = vec3(x);
   powers.rg = powers.rg * vec2(x);
   powers.r = powers.r * x;
   powers.a = 1.0;
   interval1.b = dot(powers, coeffs1);
   interval2.b = dot(powers, coeffs2);
   interval3.b = dot(powers, coeffs3);
   interval4.b = dot(powers, coeffs4);
   luminance = dot(color.rgb, vec3(0.299, 0.587, 0.114));
   x = luminance;
   powers.rgb = vec3(x);
   powers.rg = powers.rg * vec2(x);
   powers.r = powers.r * x;
   powers.a = 1.0;
   interval1.a = dot(powers, coeffs1);
   interval2.a = dot(powers, coeffs2);
   interval3.a = dot(powers, coeffs3);
   interval4.a = dot(powers, coeffs4);
   xcolor = color;
   xcolor.a = luminance;
   answer = xcolor*scaleAboveOne + vec4(1.0-scaleAboveOne);
   answer = compare(xcolor - breaks.w, interval4, answer);
   answer = compare(xcolor - breaks.z, interval3, answer);
   answer = compare(xcolor - breaks.y, interval2, answer);
   answer = compare(xcolor - breaks.x, interval1, answer);
   return answer;
kernel vec4 boostHybrid(sampler src, sampler rgblboostnogamma, float transitionBreakpoint, float transitionWidth, float luminanceAmount) {
  float luminance, factor, interpolant;
  vec4 color, xcolor, answer;
  color = sample(src, samplerCoord(src));
  luminance = dot(color.rgb, vec3(0.299, 0.587, 0.114));
  answer = sample(rgblboostnogamma, samplerCoord(rgblboostnogamma));
  xcolor = color;
  xcolor.a = luminance;
  answer = compare(xcolor, vec4(0.0), answer);
  answer = max(answer, vec4(0.0));
  factor = answer.a / max(luminance, 0.000001);
  color.rgb = color.rgb * vec3(factor);
  color.rgb = max(color.rgb, vec3(0.0));
  interpolant = clamp((luminance - (transitionBreakpoint - transitionWidth * 0.5)) / transitionWidth, 0.0, 1.0);
  interpolant = 1.0 - ((3.0 - 2.0 * interpolant) * interpolant * interpolant);
  interpolant = interpolant * luminanceAmount;
  color.rgb = mix(answer.rgb, color.rgb, interpolant);
  return color;
<CIFilterShape: %p extent [infinite]>
<CIFilterShape: %p extent [empty]>
<CIFilterShape: %p extent [%g %g %g %g]>
kernel vec2 _tile(vec2 origin, vec4 scaling) {return fract((destCoord() - origin) * scaling.zw) * scaling.xy + origin;}
kernel vec2 _lowq_affine(vec2 center, vec2 xvec, vec2 yvec)
  vec2 p = destCoord(); 
  return center + vec2(dot(p, xvec), dot(p, yvec)); 
[CIAffineTile inputTransfom] is not a valid object.
[CIAffineClamp inputTransfom] is not a valid object.
kernel vec2 circleSplash(vec2 center, float radius)
  vec2 r0;
  float r1, r2;
  r0 = destCoord() - center;
  r1 = dot (r0, r0);
  r2 = inversesqrt (r1);
  r1 = r1 * r2;
  r0 = r0 * r2;
  r1 = min(r1, radius);
  r0 = r0 * r1 + center;
  return r0;
inputCompression
kernel vec4 modTransition (__sample src0, __sample src1, vec2 center, vec4 parms, vec4 xform, vec4 botparms, vec4 topparms)
  vec2 offset = destCoord() - center, vv;
  float r = offset.x * parms.z;
  float a = botparms.z / (r * botparms.x + botparms.y) + botparms.w;
  float b = topparms.z / (r * topparms.x + topparms.y) + topparms.w;
  float v = (r<0.5) ? a : b;
  vv = vec2(v * parms.w, offset.y);
  vv = vec2(dot(vv, xform.xy), dot(vv, xform.zw));
  vv = fract(vv + center);
  vv = 2.0 * min(vv, vec2(1.0) - vv);
  float len = clamp(length(vv)* parms.x + parms.y, 0.0, 1.0);
  return mix(src1, src0, len);
T@"NSNumber",&,N,VinputCompression
projectionRows_planar8UtoF
projectionCols_planar8UtoF
Projections_status Projections_projectionRowsCols_planar8UtoF(const uint8_t *, int, int, size_t, float *, float *)
/Library/Caches/com.apple.xbs/Sources/EmbeddedCoreImage_Sim/EmbeddedCoreImage-449/Framework/api/Burst/Projections/Projections_Core.c
Projections_status Projections_computeProjectionDerivative(const float *, int, float *)
kernel vec4 _copyMachineTransition (__sample src0, __sample src1, vec3 parms2, vec4 multiplier, vec4 color, vec3 parms)
  vec4 v = vec4(destCoord(), parms.x, 1.0);
  float k = clamp(dot(v, multiplier), 0.0, 1.0);
  float j = clamp(min(k * parms2.x + parms2.y, k * parms2.z), 0.0, 1.0) * parms.y;
  k = max(k, parms.z);
  return j * color + mix(src0, src1, k);
com.apple.coreimage.tileKernelIsolation
T@"NSNumber",&,N,VinputAcuteAngle
_fourfoldRotatedTile
kernel vec2 _fourfoldRotatedTile(vec2 center, vec4 ftrans, vec4 btrans)
  vec2 t1, t2, t3, t4, t5, ci;
  t1 = destCoord() - center;
  t2.x = dot(t1, ftrans.xy);
  t2.y = dot(t1, ftrans.zw);
  ci = fract(floor(t2) * 0.5) * 2.0;
  t2 = fract(t2);
  t4 = 1.0 - t2;
  t3 = vec2(t4.y, t2.x);
  t5 = vec2(t2.y, t4.x);
  t2 = mix(t2, t5, ci.x);
  t3 = mix(t3, t4, ci.x);
  t2 = mix(t2, t3, ci.y);
  t1.x = dot(t2, btrans.xy);
  t1.y = dot(t2, btrans.zw);
  return t1 + center;
_sixfoldRotatedTile
kernel vec2 _sixfoldRotatedTile(vec2 center, vec4 ftrans, vec4 btrans)
  vec2 t1, t2;
  t1 = destCoord() - center;
  t2.x = dot(t1, ftrans.xy);
  t2.y = dot(t1, ftrans.zw);
  t2 = fract(t2);
  t1.x = 1.0 - t2.y;
  t1.y = t2.x + t2.y - 1.0;
  t2 = (t1.y < 0.0) ? t2 : t1;
  t1.x = t2.y;
  t1.y = 1.0 - t2.x - t2.y;
  t2 = (1.0 - 2.0 * t2.x - t2.y < 0.0) ? t1 : t2;
  t1.x = 1.0 - t2.x - t2.y;
  t1.y = t2.x;
  t2 = (1.0 - 2.0 * t2.y - t2.x < 0.0) ? t1 : t2;
  t1.x = t2.y;
  t1.y = 1.0 - t2.x - t2.y;
  t2 = (1.0 - 2.0 * t2.x - t2.y < 0.0) ? t1 : t2;
  t1.x = dot(t2, btrans.xy);
  t1.y = dot(t2, btrans.zw);
  return t1 + center;
_twelvefoldReflectedTile
kernel vec2 _twelvefoldReflectedTile(vec2 center, vec4 ftrans, vec4 btrans)
  vec2 t1, t2;
  float d0, d1;
  t1 = destCoord() - center;
  t2.x = dot(t1.xy, ftrans.xy);
  t2.y = dot(t1.xy, ftrans.zw);
  t2 = fract(t2).xy;
  d0 = t2.x - t2.y;
  vec2 lt = vec2(lessThan(vec2(d0), vec2(0.0)));
  t2 = mix(t2.yx, t2.xy, lt);
  d0 = 1.0 - t2.x - t2.y;
  t1 = 1.0 - t2.yx;
  lt = vec2(lessThan(vec2(d0), vec2(0.0)));
  t2 = mix(t2, t1, lt);
  d1 = 1.0 - 2.0 * t2.x - t2.y;
  d0 = 1.0 - t2.x - t2.y;
  t2.x = (d1 < 0.0) ? d0 : t2.x;
  d1 = 0.5 - 0.5 * t2.x - t2.y;
  d0 = 1.0 - t2.x - t2.y;
  t2.y = (d1 < 0.0) ? d0 : t2.y;
  t1.x = dot(t2.xy, btrans.xy);
  t1.y = dot(t2.xy, btrans.zw);
  return t1 + center;
_fourfoldTranslatedTile
kernel vec2 _fourfoldTranslatedTile(vec2 center, vec4 ftrans, vec4 btrans)
  vec2 t1, t2;
  t1 = destCoord() - center;
  t2.x = dot(t1, ftrans.xy);
  t2.y = dot(t1, ftrans.zw);
  t2 = fract(t2);
  t1.x = dot(t2, btrans.xy);
  t1.y = dot(t2, btrans.zw);
  return t1 + center;
_glideReflectedTile
kernel vec2 _glideReflectedTile(vec2 center, vec4 ftrans, vec4 btrans)
  vec2 t1, t2, t3, t4, t5, ci;
  t1 = destCoord() - center;
  t2.x = dot(t1, ftrans.xy);
  t2.y = dot(t1, ftrans.zw);
  ci = fract(floor(t2) * 0.5) * 2.0;
  t2 = fract(t2);
  t3 = vec2(t2.x, t2.y + 1.0);
  t4 = vec2(1.0 - t2.x, t2.y);
  t5 = vec2(t4.x, t4.y + 1.0);
  t2 = mix(t2, t5, ci.x);
  t3 = mix(t3, t4, ci.x);
  t2 = mix(t2, t3, ci.y);
  t1.x = dot(t2, btrans.xy);
  t1.y = dot(t2, btrans.zw);
  return t1 + center;
_eightfoldReflectedTile
kernel vec2 _eightfoldReflectedTile(vec2 center, vec4 ftrans, vec4 btrans)
  vec2 t1, t2;
  float d0;
  t1 = destCoord() - center;
  t2.x = dot(t1, ftrans.xy);
  t2.y = dot(t1, ftrans.zw);
  t2 = fract(t2);
  t2 = min(t2, 1.0 - t2);
  d0 = t2.y - t2.x;
  vec2 lt = vec2(lessThan(vec2(d0), vec2(0.0)));
  t2 = mix(t2.yx, t2.xy, lt);
  t1.x = dot(t2, btrans.xy);
  t1.y = dot(t2, btrans.zw);
  return t1 + center;
_fourfoldReflectedTile
kernel vec2 _fourfoldReflectedTile(vec2 center, vec4 ftrans, vec4 btrans)
  vec2 t1, t2;
  t1 = destCoord() - center;
  t2.x = dot(t1, ftrans.xy);
  t2.y = dot(t1, ftrans.zw);
  t2 = fract(t2);
  t2 = min (t2, 1.0 - t2);
  t2 = t2 + t2;
  t1.x = dot(t2, btrans.xy);
  t1.y = dot(t2, btrans.zw);
  return t1 + center;
_sixfoldReflectedTile
kernel vec2 _sixfoldReflectedTile(vec2 center, vec4 ftrans, vec4 btrans)
  vec2 t1, t2;
  float d0, d1, d2;
  t1 = destCoord() - center;
  t2.x = dot(t1, ftrans.xy);
  t2.y = dot(t1, ftrans.zw);
  t2 = fract(t2);
  d0 = t2.x - t2.y; 
  vec2 lt = vec2(lessThan(vec2(d0), vec2(0.0)));
  t2 = mix(t2.yx, t2.xy, lt);
  d2 = t2.x + t2.y;
  d0 = 2.0 - d2;
  d1 = d0 - t2.y;
  t2.y = (d1 < 0.0) ? d0 : t2.y;
  d0 = 1.0 - d2;
  d1 = d0 * -1.0 + t2.x;
  t2.x = (d1 < 0.0) ? d0 : t2.x;
  d0 = t2.x - t2.y;
  lt = vec2(lessThan(vec2(d0), vec2(0.0)));
  t2 = mix(t2.yx, t2.xy, lt);
  t1.x = dot(t2, btrans.xy);
  t1.y = dot(t2, btrans.zw);
  return t1 + center;
kernel vec4 _sobelEdges(sampler src, float scale)
  vec2 coord = destCoord();
  vec2 sc = samplerTransform(src, coord);
  vec2 dx = samplerTransform(src, coord + vec2(1.0, 0.0)) - sc;
  vec2 dy = samplerTransform(src, coord + vec2(0.0, 1.0)) - sc;
  vec2 d = dx + dy;
  vec4 pix3 = sample(src, sc + d);
  vec4 pix7 = sample(src, sc - d);
  d = dx - dy;
  vec4 pix9 = sample(src, sc + d);
  vec4 pix1 = sample(src, sc - d);
  vec4 pix2 = sample(src, sc + dy);
  vec4 pix8 = sample(src, sc - dy);
  vec4 pix6 = sample(src, sc + dx);
  vec4 pix4 = sample(src, sc - dx);
  vec4 pix5 = sample(src, sc);
  vec4 gx = (pix3 + 2.0*pix6 + pix9) - (pix1 + 2.0*pix4 + pix7);
  vec4 gy = (pix1 + 2.0*pix2 + pix3) - (pix7 + 2.0*pix8 + pix9);
  vec4 g2 = gx*gx + gy*gy;
  pix5 = vec4(pix5.rgb/max(pix5.a,0.00001), pix5.a);
  pix5.rgb = sqrt(g2).rgb * scale;
  return vec4(pix5.rgb*pix5.a, pix5.a);
kernel vec4 _noiseComicReduction(sampler src, vec2 offset, vec3 weight, vec3 intensity)
  vec2 c = destCoord();
  vec4 cn = sample(src, samplerTransform(src, c));
  vec4 t0 = sample(src, samplerTransform(src, c + vec2(0.0, -offset.x)));
  vec4 t1 = sample(src, samplerTransform(src, c + vec2(0.0, offset.x)));
  vec4 t2 = sample(src, samplerTransform(src, c + vec2(-offset.x, 0.0)));
  vec4 t3 = sample(src, samplerTransform(src, c + vec2(offset.x, 0.0)));
  vec4 t4 = sample(src, samplerTransform(src, c + vec2(offset.y, offset.y)));
  vec4 t5 = sample(src, samplerTransform(src, c + vec2(offset.y, -offset.y)));
  vec4 t6 = sample(src, samplerTransform(src, c + vec2(-offset.y, -offset.y)));
  vec4 t7 = sample(src, samplerTransform(src, c + vec2(-offset.y, offset.y)));
  t0 = (t0 + t1 + t2 + t3) * weight.x + (t4 + t5 + t6 + t7) * weight.y + cn * weight.z;
  vec4 d = abs(t0 - cn);
  float s = intensity.x + intensity.y * (d.r + d.g + d.b);
  s = clamp(s, intensity.z, 1.0);
  return mix(cn, t0, s);
kernel vec4 _colorControls(__sample src, float threshold, float contrast)
  vec4 pix = vec4(src.rgb/max(src.a,0.00001), src.a);
  float f = clamp((dot(pix.rgb, vec3(0.2125, 0.7154, 0.0721)) - threshold) * contrast + 0.5, 0.0, 1.0);
  return vec4(0.0, 0.0, 0.0, f);
inputNRSharpness
inputNRNoiseLevel
inputEdgeIntensity
inputThreshold
kernel vec4 _spotColor(__sample src, 
  __color cclr1, __color rclr1, 
  __color cclr2, __color rclr2, 
  __color cclr3, __color rclr3, 
  vec4 closeness, vec4 contrast)
  vec4 pix = vec4(src.rgb/max(src.a,0.00001), src.a);
  float dist = length(pix.rgb - cclr1.rgb);
  float alpha = clamp((closeness.x - dist) * contrast.x + 0.5, 0.0, 1.0);
  vec4 result1 = rclr1 * alpha;
  dist = length(pix.rgb - cclr2.rgb);
  alpha = clamp((closeness.y - dist) * contrast.y + 0.5, 0.0, 1.0);
  vec4 result2 = rclr2 * alpha;
  dist = length(pix.rgb - cclr3.rgb);
  alpha = clamp((closeness.z - dist) * contrast.z + 0.5, 0.0, 1.0);
  vec4 result3 = rclr3 * alpha;
  pix = result1 + (1.0 - result1.a) * vec4(1.0);
  pix = result2 + (1.0 - result2.a) * pix;
  return result3 + (1.0 - result3.a) * pix;
inputCloseness1
inputContrast1
inputCenterColor1
inputReplacementColor1
inputCloseness2
inputContrast2
inputCenterColor2
inputReplacementColor2
inputCloseness3
inputContrast3
inputCenterColor3
inputReplacementColor3
B36@?0^{Node=^^?{Atomic={?=i}}I{SerialRectArray=ii^{CGRect}}Q{Hash=[20C]}{Hash=[20C]}B}8^{Node=^^?{Atomic={?=i}}I{SerialRectArray=ii^{CGRect}}Q{Hash=[20C]}{Hash=[20C]}B}16i24i28i32
v32@?0^{Node=^^?{Atomic={?=i}}I{SerialRectArray=ii^{CGRect}}Q{Hash=[20C]}{Hash=[20C]}B}8^{Node=^^?{Atomic={?=i}}I{SerialRectArray=ii^{CGRect}}Q{Hash=[20C]}{Hash=[20C]}B}16i24i28
program 
 format=%s%s
 time=%g
program
<BR/>%.*s
<CI::%s %p>
vertexTransform0
vertexTransform1
vertexTransform2
vertexTransform3
vertexTransform
programs <%llu> (%s context %p) = 
vertex = 
fragment = 
[argument types]
[argument names]
[argument objects]
r*12@?0i8
mData[%i] = %s
mData[%i] = %p <%s> 
kernel vec4 _boxBlur3(sampler i, vec2 dir)
  vec2 dc = destCoord(); 
  vec4 c; 
  c  = sample(i, samplerTransform(i,dc - dir)); 
  c += sample(i, samplerTransform(i,dc + 0.5*dir)) * 2.0; 
  return c / 3.0; 
kernel vec4 _boxBlur5(sampler i, vec2 dir)
  vec2 dc = destCoord(); 
  vec4 c; 
  c  = sample(i, samplerTransform(i,dc - 1.5*dir)) * 0.4; 
  c += sample(i, samplerTransform(i,dc)) * 0.2; 
  c += sample(i, samplerTransform(i,dc + 1.5*dir)) * 0.4; 
  return c; 
kernel vec4 _boxBlur7(sampler i, vec2 dir)
  vec2 dc = destCoord(); 
  vec4 c; 
  c  = sample(i, samplerTransform(i,dc - 2.5*dir)); 
  c += sample(i, samplerTransform(i,dc - dir)) * 0.5; 
  c += sample(i, samplerTransform(i,dc + 0.5*dir)); 
  c += sample(i, samplerTransform(i,dc + 2.5*dir)); 
  return c / 3.5; 
kernel vec4 _boxBlur9(sampler i, vec2 dir)
  vec2 dc = destCoord(); 
  vec4 c; 
  c  = sample(i, samplerTransform(i,dc - 3.5*dir)); 
  c += sample(i, samplerTransform(i,dc - 1.5*dir)); 
  c += sample(i, samplerTransform(i,dc)) * 0.5; 
  c += sample(i, samplerTransform(i,dc + 1.5*dir)); 
  c += sample(i, samplerTransform(i,dc + 3.5*dir)); 
  return c / 4.5; 
kernel vec4 _boxBlur11(sampler i, vec2 dir)
  vec2 dc = destCoord(); 
  vec4 c; 
  c  = sample(i, samplerTransform(i,dc - 4.5*dir)); 
  c += sample(i, samplerTransform(i,dc - 2.5*dir)); 
  c += sample(i, samplerTransform(i,dc - dir)) * 0.5; 
  c += sample(i, samplerTransform(i,dc + 0.5*dir)); 
  c += sample(i, samplerTransform(i,dc + 2.5*dir)); 
  c += sample(i, samplerTransform(i,dc + 4.5*dir)); 
  return c / 5.5; 
kernel vec4 _boxBlur13(sampler i, vec2 dir)
  vec2 dc = destCoord(); 
  vec4 c; 
  c  = sample(i, samplerTransform(i,dc - 5.5*dir)); 
  c += sample(i, samplerTransform(i,dc - 3.5*dir)); 
  c += sample(i, samplerTransform(i,dc - 1.5*dir)); 
  c += sample(i, samplerTransform(i,dc)) * 0.5; 
  c += sample(i, samplerTransform(i,dc + 1.5*dir)); 
  c += sample(i, samplerTransform(i,dc + 3.5*dir)); 
  c += sample(i, samplerTransform(i,dc + 5.5*dir)); 
  return c / 6.5; 
kernel vec4 _boxCombine7 (sampler blur, vec2 off)
  vec2 dc = destCoord(); 
  vec4 c = sample(blur, samplerTransform(blur, dc - 3.0*off)) 
         + sample(blur, samplerTransform(blur, dc - 2.0*off)) 
         + sample(blur, samplerTransform(blur, dc - off)) 
         + sample(blur, samplerTransform(blur, dc)) 
         + sample(blur, samplerTransform(blur, dc + off)) 
         + sample(blur, samplerTransform(blur, dc + 2.0*off)) 
         + sample(blur, samplerTransform(blur, dc + 3.0*off)); 
  return c / 7.0; 
kernel vec4 _boxCombine5 (sampler blur, vec2 off)
  vec2 dc = destCoord(); 
  vec4 c = sample(blur, samplerTransform(blur, dc - 2.0*off)) 
         + sample(blur, samplerTransform(blur, dc - off)) 
         + sample(blur, samplerTransform(blur, dc)) 
         + sample(blur, samplerTransform(blur, dc + off)) 
         + sample(blur, samplerTransform(blur, dc + 2.0*off)); 
  return c * 0.2; 
kernel vec4 _boxCombine3 (sampler blur, vec2 off)
  vec2 dc = destCoord(); 
  vec4 c = sample(blur, samplerTransform(blur, dc)) 
         + sample(blur, samplerTransform(blur, dc - off)) 
         + sample(blur, samplerTransform(blur, dc + off)); 
  return c / 3.0; 
kernel vec4 _boxCombine2 (sampler img, sampler blur, vec4 parms)
  vec2 off = parms.xy; 
  float kc = parms.w; 
  float kb = parms.z; 
  vec2 dc = destCoord(); 
  return kc * sample(img,  samplerTransform(img,  dc)) 
       + kb * sample(blur, samplerTransform(blur, dc - off)) 
       + kb * sample(blur, samplerTransform(blur, dc + off)); 
lightMap
lightMapWidth
lightMapHeight
lightMapAvg
localAutoValue
proxyLightMap
proxyLightMapWidth
proxyLightMapHeight
inputLightMapWidth
inputLightMapHeight
kernel vec4 _polyKernel(__sample im, __sample adj, float str) 
  adj.r = 3.4*adj.r-1.2; 
  vec3 neg = min(im.rgb, 0.0); 
  vec3 pos = max(im.rgb, 1.0)-1.0; 
  im.rgb = clamp(im.rgb, 0.0, 1.0); 
  vec4 orig = im; 
  float y = sqrt(dot(im.rgb, vec3(.33333))); 
  float s = mix(0.0, adj.r, str); 
  vec3 gain = s > 0.0 ? vec3(1.5*s) : vec3(1.75*s, 1.75*s, 1.55*s); 
  im.rgb = im.rgb*im.rgb*gain + im.rgb*(1.0-gain); 
  im.rgb = (clamp(im.rgb, 0.0, 1.0)); 
  float midAmt = min(str, .5); 
  y = y*(1.0-y); 
  im.rgb = sqrt(im.rgb); 
  float pivot = max(adj.g, 0.5); 
  float a = midAmt*y; 
  float b = -pivot*a; 
  vec3 pix = im.r * vec3(0.299*a) + 
             im.g * vec3(0.587*a) + 
             im.b * vec3(0.114*a) + 
             im.rgb + vec3(b); 
  im.rgb = mix(im.rgb, vec3(pivot), -y*midAmt); 
  im.rgb = mix(im.rgb, pix, 0.8); 
  im.rgb = max(im.rgb, 0.0); 
  im.rgb *= im.rgb; 
  im.rgb = clamp(im.rgb, 0.0,1.0)+pos+neg; 
  return im; 
-[CILocalLightFilter outputImage]
/Library/Caches/com.apple.xbs/Sources/EmbeddedCoreImage_Sim/EmbeddedCoreImage-449/Framework/filters/CILocalLight.mm
CGRectEqualToRect([guideImage extent], [inputImage extent])
inputImage != nil
guideImage != nil
inputLocalLight != nil
___ZL20_scaledLightMapImageP6NSDataP8NSNumberS2_P7CIImage_block_invoke
x == 0
y == 0
width == lmWidth
height == lmHeight
CIEdgePreserveUpsampleRGFilter
kernel vec4 _colorMap (sampler src, sampler map, float scale)
  vec4 s = unpremultiply(sample(src, samplerCoord(src))); 
  float n = clamp(dot(s.rgb, vec3(0.2125, 0.7154, 0.0721)), 0.0, 1.0);
  return s.a * sample(map, samplerTransform(map, vec2(n*scale + 0.5, 0.5)));
%s requires the inputGradientImage to be finite
-[CIColorMap outputImage]
T@"CIImage",&,N,VinputGradientImage
kernel vec4 _median3x3(sampler src) 
  vec2  d; 
  vec4  p1,p2,p3,p4,p5,p6,p7,p8,p9; 
  vec4  e1, e2, e3, e4, e5, e6, e7, e8, e9, e10; 
  vec4  e11, e12, e13, e14, e15, e16, e17, e18, e19, e20; 
  vec4  e21, e22, e23, e24, e25, e26, e27, e28, e29; 
  d  = destCoord(); 
  p1 = sample(src, samplerTransform(src, d + vec2(+1.0, 0.0))); 
  p2 = sample(src, samplerTransform(src, d + vec2(+1.0,+1.0))); 
  p3 = sample(src, samplerTransform(src, d + vec2( 0.0,+1.0))); 
  p4 = sample(src, samplerTransform(src, d + vec2(-1.0,+1.0))); 
  p5 = sample(src, samplerTransform(src, d + vec2(-1.0, 0.0))); 
  p6 = sample(src, samplerTransform(src, d + vec2(-1.0,-1.0))); 
  p7 = sample(src, samplerTransform(src, d + vec2( 0.0,-1.0))); 
  p8 = sample(src, samplerTransform(src, d + vec2(+1.0,-1.0))); 
  p9 = sample(src, samplerTransform(src, d)); 
  e1  = min(p2 , p3 );    e2  = max(p2 , p3 ); 
  e3  = min(p5 , p6 );    e4  = max(p5 , p6 ); 
  e5  = min(p8 , p9 );    e6  = max(p8 , p9 ); 
  e7  = min(p1 , e1 );    e8  = max(p1 , e1 ); 
  e9  = min(p4 , e3 );    e10 = max(p4 , e3 ); 
  e11 = min(p7 , e5 );    e12 = max(p7 , e5 ); 
  e13 = min(e8 , e2 );    e14 = max(e8 , e2 ); 
  e15 = min(e10, e4 );    e16 = max(e10, e4 ); 
  e17 = min(e12, e6 );    e18 = max(e12, e6 ); 
  e19 = max(e7 , e9 ); 
  e20 = min(e16, e18); 
  e21 = max(e19, e11); 
  e22 = min(e14, e20); 
  e23 = min(e15, e17);    e24 = max(e15, e17); 
  e25 = max(e13, e23); 
  e26 = min(e24, e25); 
  e27 = min(e26, e22);    e28 = max(e26, e22); 
  e29 = max(e21, e27); 
  return min(e29, e28); 
inputBarOffset
kernel vec2 _barsSwipe (vec3 ptoy, vec2 dir, float progress)
  float y = dot(ptoy.xy,destCoord()) + ptoy.z;
  y = abs(floor(y));
  y = max(progress - y, 0.0);
  return destCoord() + y*y*dir;
T@"NSNumber",&,N,VinputBarOffset
inputShadowRadius
inputShadowDensity
inputShadowOffset
kernel vec4 _disintegrateWithMask (__sample t0, __sample t1, 
   __sample m0, __sample m1, __sample m2, __sample m3, 
   vec4 param)
  float shadowRadiusInv = param.y; 
  float shadowDensity = param.z; 
  float time = param.w; 
  float ramp = 1.0 / (max(abs(m1.r-m0.r), abs(m2.r-m0.r)) + 0.001);
  float shadow = (time - m3.r) * shadowRadiusInv * ramp + time;
  shadow = clamp(shadow, 0.0, 1.0);
  shadow = shadowDensity*(shadow-1.0) + 1.0;
  t0.rgb = t0.rgb * (param.x*time + 1.0);
  t1.rgb = t1.rgb * (param.x*time + 1.0 - param.x) * shadow;
  float s = clamp((time - m0.r) * ramp + time, 0.0, 1.0);
  return mix(t0, t1, s);
kernel vec4 _disintegrateWithMaskG (sampler s0, sampler s1, sampler m, vec2 offset, vec4 param)
  float shadowRadiusInv = param.y; 
  float shadowDensity = param.z; 
  float time = param.w; 
  vec4 t0 = sample(s0, samplerCoord(s0)); 
  vec4 t1 = sample(s1, samplerCoord(s1)); 
  vec2 d  = destCoord(); 
  vec4 m0 = sample(m, samplerTransform(m, d)); 
  vec4 m1 = sample(m, samplerTransform(m, d + vec2(1.0, 0.0))); 
  vec4 m2 = sample(m, samplerTransform(m, d + vec2(0.0, 1.0))); 
  vec4 m3 = sample(m, samplerTransform(m, d - offset)); 
  float ramp = 1.0 / (max(abs(m1.r-m0.r), abs(m2.r-m0.r)) + 0.001);
  float shadow = (time - m3.r) * shadowRadiusInv * ramp + time;
  shadow = clamp(shadow, 0.0, 1.0);
  shadow = shadowDensity*(shadow-1.0) + 1.0;
  t0.rgb = t0.rgb * (param.x*time + 1.0);
  t1.rgb = t1.rgb * (param.x*time + 1.0 - param.x) * shadow;
  float s = clamp((time - m0.r) * ramp + time, 0.0, 1.0);
  return mix(t0, t1, s);
T@"NSNumber",&,N,VinputShadowRadius
T@"NSNumber",&,N,VinputShadowDensity
T@"CIVector",&,N,VinputShadowOffset
inputFadeThreshold
kernel vec4 flashColor (__sample r1, __sample r0, vec2 center, __color color, __sample noise, vec4 parms, vec2 parms2)
  vec2 delta = destCoord() - center;
  float len = length(delta);
  float len2 = dot(delta,delta);
  float mask = clamp(1.0 - len * parms.z, 0.0, 1.0);
  float n = clamp(noise.x, 0.0, noise.a);
  n = n * parms2.x + parms2.y;
  vec4 flash = color * parms.y / len2 + n;
  vec4 r2 = clamp(flash * mask, 0.0, 1.0);
  r1 = clamp(r1 + r2, 0.0, 1.0);
  return mix(r1, r0, parms.w);
kernel vec2 flashGeom (vec2 center)
  vec2 delta = destCoord() - center;
  float len = length(delta);
  return (delta * 100.0 / len) + vec2(128.0);
T@"NSNumber",&,N,VinputMaxStriationRadius
T@"NSNumber",&,N,VinputStriationStrength
T@"NSNumber",&,N,VinputStriationContrast
T@"NSNumber",&,N,VinputFadeThreshold
inputCrossScale
inputCrossAngle
inputCrossOpacity
inputCrossWidth
inputEpsilon
kernel vec4 _starshine(vec2 center, vec4 xyvec, vec4 parms, float widthrecip, __color color)
  vec2 offset = destCoord() - center;
  vec2 loc = vec2(dot(offset, xyvec.xy), dot(offset, xyvec.zw));
  float l = length(offset);
  float rlen = parms.x / l;
  loc = max(abs(loc) * widthrecip + parms.w, vec2(0.0000001));
  loc = abs(parms.x / loc);
  loc = loc * loc * loc;
  float f = loc.x * loc.y * parms.z;
  float g = clamp(1.0 - l * parms.y, 0.0, 1.0);
  return min(rlen * rlen * color + g * g * f, vec4(1.0));
T@"NSNumber",&,N,VinputCrossScale
T@"NSNumber",&,N,VinputCrossAngle
T@"NSNumber",&,N,VinputCrossOpacity
T@"NSNumber",&,N,VinputCrossWidth
T@"NSNumber",&,N,VinputEpsilon
,vec2 samplePoint
destCoord()
samplePoint
sampler
color
__table
kernel vec4 autoROI_%s(__sample s,vec4 e,
%s v%d%s
  vec2 pt = ( 
v%d%s
,s.xy) - e.xy) / e.zw; return pt.xyxy; }
kernel vec4 autoROI_%s(sampler s,vec4 e,
  vec2 pt = 
 return ((samplerTransform(s, pt).xyxy)- e.xyxy) / e.zwzw; }
inputBottomLeft
inputBottomRight
inputTopRight
inputTopLeft
kernel vec2 _perspectiveTransform(vec3 A1, vec3 A2, vec3 A3, vec2 origin)
  vec3 h = vec3(destCoord(), 1.0);
  vec2 p = vec2(dot(h, A1), dot(h, A2));
  float w = 1.0 / max(dot(h, A3), 0.000001);
  return p * w + origin;
T@"CIVector",&,N,VinputTopLeft
T@"CIVector",&,N,VinputTopRight
T@"CIVector",&,N,VinputBottomRight
T@"CIVector",&,N,VinputBottomLeft
kernel vec4 _perspectiveMask(__sample p, vec3 A3) { return p * ((dot(vec3(destCoord(), 1.0), A3)<0.000001) ? 0.0 : 1.0); }
kernel vec2 _perspectiveCorrection(vec3 A1, vec3 A2, vec3 A3, vec4 rect)
  vec3 h = vec3(destCoord()/rect.zw, 1.0);
  vec2 p = vec2(dot(h, A1)*rect.z, dot(h, A2)*rect.w);
  float w = 1.0 / max(dot(h, A3), 0.000001);
  return p * w + rect.xy;
public.jpeg
public.png
com.microsoft.bmp
Error: couldn't open file
convertLToRGBA8888: src must be L format!
createImage - invalid format
convertRGBA8888ToYUV420: src must be RGBA8888 format!
convertYUV420ToRGBA8888: src must be YUV420 format!
 calculateOverlapRMS: unspecfied pixel format
  calculateOverlapRMS: not supporting Logical yet
  calculateOverlapRMS: not supporting Gray yet
  calculateOverlapRMS: not supporting L yet
  calculateOverlapRMS: not supporting ARGB8888 yet
  calculateOverlapRMS: not supporting RGBA8888 yet
  calculateOverlapRMS: rectangles don't match
  calculateOverlapRMS: image formats don't match
kernel vec2 _bumpDistortion(vec4 parms)
  float d0 = clamp(distance(destCoord(), parms.zw) * -parms.x + 1.0, 0.0, 1.0);
  d0 = ((d0 * -2.0 + 3.0) * d0 * d0) * parms.y + 1.0;
  return (destCoord() - parms.zw) * d0 + parms.zw;
kernel vec2 _bumpDistortionLinear(vec4 edgeFunc, vec4 vec)
  float eFunc = dot(vec4(destCoord(), 1.0, 0.0), edgeFunc);
  float r0 = clamp(1.0 - abs(eFunc), 0.0, 1.0);
  r0 = ((r0 * -2.0 + 3.0) * r0 * r0) * vec.z + 1.0;
  return destCoord() + (eFunc * (r0 - 1.0) * vec.xy);
kernel vec4 _colorPolynomial (__sample c, vec4 cf0, vec4 cf1, vec4 cf2, vec4 cf3) { return cf0 + c * (cf1 + c * (cf2 + c * cf3)); }
inputRedCoefficients
inputGreenCoefficients
inputBlueCoefficients
inputAlphaCoefficients
T@"CIVector",&,N,VinputRedCoefficients
T@"CIVector",&,N,VinputGreenCoefficients
T@"CIVector",&,N,VinputBlueCoefficients
T@"CIVector",&,N,VinputAlphaCoefficients
kernel vec4 _colorCrossPolynomial (__sample c, vec3 pr, vec3 pg, vec3 pb, 
                                    vec3 prr, vec3 pgg, vec3 pbb, 
                                    vec3 prg, vec3 pgb, vec3 pbr, vec3 p1) 
  c.rgb =   c.r * pr   +        c.g * pg   +        c.b * pb   +  
      c.r * c.r * prr  +  c.g * c.g * pgg  +  c.b * c.b * pbb  +  
      c.r * c.g * prg  +  c.g * c.b * pgb  +  c.b * c.r * pbr  +  p1;
  return c; 
shape=diamond, color="#FFFFCC"
switch
NSString
CIFilter
inputHueMagMR
inputHueMagRY
inputHueMagYG
inputHueMagGC
inputHueMagCB
inputHueMagBM
RCCreateCIImageFromBufferAndProperties
raw-image
kCGImageSourceShouldUseRawDataForFulleSize
kCGImageSourceSupportedSushiLevels
{Raw}
filters
RAWDemosaicFilter
RAWGamutMap
RAWReduceNoise
inputLNRAmount
inputCNRAmount
inputSharpenAmount
inputContrastAmount
inputDetailAmount
RAWRadialLensCorrection
inputLDCExecuteFlags
RAWConvert
RAWAdjustTempTint
inputWhitePoint
RAWAdjustExposureAndBias
RAWHueMagnet
RAWAdjustColorTRC
inputBoostAmount
RAWAdjustColors
RAWTemperatureAdjust
RAWLinearSpacePlaceholder
kCGImageSourceNoiseReductionAmount
kCGImageSourceLuminanceNoiseReductionAmount
kCGImageSourceColorNoiseReductionAmount
kCGImageSourceNoiseReductionSharpnessAmount
kCGImageSourceNoiseReductionContrastAmount
kCGImageSourceNoiseReductionDetailAmount
kCGImageSourceDisableVendorLensDistortionCorrection
kCGImageSourceNeutral
PixelWidth
PixelHeight
{Raw}.filters
inputCropRect
{Exif}.PixelXDimension
{Exif}.PixelYDimension
RAWCropFilter
rawDictionary
T@"NSDictionary",R,&
rawReconstructionDefaultsDictionary
sushiMode
T@"NSNumber",R,&
rawMajorVersion
T@"NSArray",R,&
subsampling
nativeSize
T{CGSize=dd},R
-[CIRAWFilterImpl(CustomAccessors) inputImage]
/Library/Caches/com.apple.xbs/Sources/EmbeddedCoreImage_Sim/EmbeddedCoreImage-449/Framework/filters/Raw/CIRAWFilterImpl.m
_inputImage != nil
CIRAWFilter %s: The file does not support version %@. The version %@ will be used instead.
-[CIRAWFilterImpl(CustomAccessors) setInputDecoderVersion:]
kCGImageSourceVendorLensCorrectionFeatures
RAWAdjustExposureAndBias.inputBias
RAWAdjustExposureAndBias.inputBaselineExposure
RAWHueMagnet.inputHueMagMR
RAWHueMagnet.inputHueMagRY
RAWHueMagnet.inputHueMagYG
RAWHueMagnet.inputHueMagGC
RAWHueMagnet.inputHueMagCB
RAWHueMagnet.inputHueMagBM
bsamt
(rVector != nil) && (gVector != nil) && (bVector != nil)
kernel vec4 _resetalpha(__sample src, __sample mask)
  src.a = mask.a;
  return src;
kernel vec4 _colorClamp (__sample c, vec4 lo, vec4 hi) { return clamp(c,lo,hi); }
inputMinComponents
inputMaxComponents
T@"CIVector",&,N,VinputMinComponents
T@"CIVector",&,N,VinputMaxComponents
inputTexture
kernel vec4 _glassDistort (sampler tex0, sampler tex1, 
              vec2 scale_plus_unit, vec2 off0, vec2 off1, 
              vec2 off2, vec2 unit_to_glass, float height_factor) 
    vec2 dc = destCoord(); 
    vec2 dcscaled = dc * scale_plus_unit; 
    vec2 t0g = fract(dcscaled + off0) * unit_to_glass + vec2(.5); 
    vec2 t1g = fract(dcscaled + off1) * unit_to_glass + vec2(.5); 
    vec2 t2g = fract(dcscaled + off2) * unit_to_glass + vec2(.5); 
    float tcen = sample(tex1, samplerTransform(tex1, t0g)).r; 
    float tdx  = sample(tex1, samplerTransform(tex1, t1g)).r; 
    float tdy  = sample(tex1, samplerTransform(tex1, t2g)).r; 
    vec2 p = dc + vec2(tdx-tcen, tdy-tcen) * height_factor; 
    return sample(tex0, samplerTransform(tex0, p)); 
T@"CIImage",&,N,VinputTexture
kernel vec2 _stretchcrop (vec2 sizeIn, vec2 center, vec4 p)
  vec2 a = p.xy, b = p.zw; 
  vec2 c = destCoord(); 
  c = (c-center)/sizeIn;
  c = c / (a + b*abs(c));
  c = (c + 0.5)*sizeIn;
  return c;
inputCropAmount
inputCenterStretchAmount
kernel vec2 _ninePartStretched (vec2 bpmin, vec2 growth, vec2 slope)
  vec2 dc = destCoord();
  vec2 c1 = slope * (dc - bpmin) + bpmin;
  vec2 c2 = dc - growth;
  return max(min(dc,c1),c2);
inputBreakpoint0
inputBreakpoint1
inputGrowAmount
T@"CIVector",&,N,VinputBreakpoint0
T@"CIVector",&,N,VinputBreakpoint1
T@"CIVector",&,N,VinputGrowAmount
kernel vec2 _ninePartTiledAlt (vec4 bp01, vec2 growth, vec2 shift)
  vec2 dc = destCoord();
  vec2 bp0 = bp01.xy;
  vec2 bp1 = bp01.zw;
  vec2 myMod; { 
    vec2 a = dc - shift; 
    vec2 b = bp1-bp0; 
    myMod = a - b*floor(a/b); 
  } 
  vec2 c1 = bp0 + myMod;
  vec2 p = compare(dc - bp0, dc, c1); 
  p = compare(dc - (bp1+growth), p, dc - growth); 
  return p;
inputFlipYTiles
T@"NSNumber",&,N,VinputFlipYTiles
10.?
inputHeight
inputLowLimit
inputHighLimit
kernel vec4 _histogram_display (sampler image, float height, vec2 hilo) 
    vec2  d = destCoord(); 
    vec2  histcoord = vec2(floor(d.x)+0.5, 0.5); 
    vec4  v = sample(image, samplerTransform(image, histcoord)); 
    v = step(vec4(d.y), height*v); 
    float vi = v.r*4.0 + v.g*2.0 + v.b; 
    vec4 p = vec4(.25,.25,.25,1.0); 
    p = (vi==4.0) ? vec4(.50,.05,.05,1.0) : p; 
    p = (vi==6.0) ? vec4(.20,.40,.05,1.0) : p; 
    p = (vi==2.0) ? vec4(.05,.50,.05,1.0) : p; 
    p = (vi==3.0) ? vec4(.05,.20,.40,1.0) : p; 
    p = (vi==1.0) ? vec4(.05,.05,.50,1.0) : p; 
    p = (vi==5.0) ? vec4(.20,.05,.40,1.0) : p; 
    p = (vi==7.0) ? vec4(.05,.10,.30,1.0) : p; 
    p.rgb = (d.x<hilo.x+0.5)  ? p.rgb*vec3(0.4)             : p.rgb; 
    p.rgb = (d.x>=hilo.y+0.5) ? p.rgb*vec3(0.6) + vec3(0.4) : p.rgb; 
    return p; 
T@"NSNumber",&,N,VinputHeight
T@"NSNumber",&,N,VinputHighLimit
T@"NSNumber",&,N,VinputLowLimit
%llX(%04X)
CI_LOG_CONVERSIONS: Converted input image to %s surface, from which to create a Metal texture.
Cannot handle a (%lu x %lu) sized texture with the given context!
MetalTextureForCGImage %p <%d>
MetalTextureForIOSurface %p <%d>
ci_kernels
kCIImageProcessorSupportsMPS
compute_quad
CI_PRINT_TIME [GPU] render_root_node = %.6f seconds
CI_PRINT_TIME [GPU] render_intermediate_node = %.6f seconds
CI_PRINT_TIME %s (%s) = %.6f seconds
kernel vec4 _localContrast(__sample im, __sample shc, float amt)
  float midAmt = amt;
  vec3 neg = min(im.rgb, 0.0);
  vec3 pos = max(im.rgb, 1.0)-1.0;
  im.rgb = clamp(im.rgb, 0.0, 1.0);
  float y = dot(im.rgb, vec3(0.3333));
  y = sqrt(y);
  y = y*(1.0-y);
  im.rgb = sqrt(im.rgb);
  float pivot = sqrt(shc.g);
  float a = midAmt*y;
  float b = -pivot*a;
  vec3 pix = im.r * vec3(0.299*a) +
             im.g * vec3(0.587*a) +
             im.b * vec3(0.114*a) +
             im.rgb + vec3(b);
  im.rgb = mix(im.rgb, vec3(pivot), -y*midAmt);
  im.rgb = mix(im.rgb, pix, 0.8);
  im.rgb = max(im.rgb, 0.0);
  im.rgb *= im.rgb;
  im.rgb = im.rgb + neg + pos;
  return im;
inputBottomHeight
inputNumberOfFolds
inputFoldShadowAmount
kernel vec2 _accordianWarpS (vec3 foldParms, vec4 dims)
    float numFoldsX2 = foldParms.x;
    float foldScaleH = foldParms.y;
    float bottomHeight = dims.x;
    float gap = dims.y;
    vec2 dc = destCoord();
    float x = dc.x;
    float y = dc.y;
    float gapLoc = clamp((y - bottomHeight) / gap, 0.0, 1.0);
    float gapLocSaw = 1.0 - abs(mod((numFoldsX2*gapLoc), 2.0) - 1.0);
    float hScale = 1.0 + foldScaleH*gapLocSaw;
    vec2 pS;
    pS.y = min( y, max( y-gap, bottomHeight));
    pS.x = x * hScale;
    return pS;
kernel vec2 _accordianWarpT (vec3 foldParms, vec4 dims)
    float numFoldsX2 = foldParms.x;
    float foldScaleH = foldParms.y;
    float bottomHeight = dims.x;
    float gap = dims.y;
    vec2 dc = destCoord();
    float x = dc.x;
    float y = dc.y;
    float gapLoc = clamp((y - bottomHeight) / gap, 0.0, 1.0);
    float gapLocSaw = 1.0 - abs(mod((numFoldsX2*gapLoc), 2.0) - 1.0);
    float hScale = 1.0 + foldScaleH*gapLocSaw;
    vec2 pT;
    pT.y = max( y, min ( (y-bottomHeight)*dims.z + bottomHeight, y+dims.w ));
    pT.x = x * hScale;
    return pT;
kernel vec4 _accordionMix (
    __sample cS, __sample cT,
    vec3 foldParms, float time, vec4 dims)
    float numFoldsX2 = foldParms.x;
    float foldShadeAmt = foldParms.z;
    float bottomHeight = dims.x;
    float gap = dims.y;
    vec2 dc = destCoord();
    float y = dc.y;
    float gapLoc = clamp((y - bottomHeight) / gap, 0.0, 1.0);
    float shadeAmt = 1.0 - foldShadeAmt*mod((numFoldsX2*gapLoc), 1.0);
    vec4 result = mix(cS, cT, time);
    result.rgb *= shadeAmt;
    return result;
kernel vec4 _accordionFoldTransition (
    sampler shortImage, sampler tallImage,
    vec3 foldParms, float time, vec4 dims)
    float numFoldsX2 = foldParms.x;
    float foldScaleH = foldParms.y;
    float foldShadeAmt = foldParms.z;
    float bottomHeight = dims.x;
    float gap = dims.y;
    vec2 dc = destCoord();
    float x = dc.x;
    float y = dc.y;
    float gapLoc = clamp((y - bottomHeight) / gap, 0.0, 1.0);
    float gapLocSaw = 1.0 - abs(mod((numFoldsX2*gapLoc), 2.0) - 1.0);
    float shadeAmt = 1.0 - foldShadeAmt*mod((numFoldsX2*gapLoc), 1.0);
    float hScale = 1.0 + foldScaleH*gapLocSaw;
    vec2 pS;
    pS.y = min( y, max( y-gap, bottomHeight));
    pS.x = x * hScale;
    vec4 cS = sample(shortImage, samplerTransform(shortImage, pS));
    vec2 pT;
    pT.y = max( y, min ( (y-bottomHeight)*dims.z + bottomHeight, y+dims.w ));
    pT.x = x * hScale;
    vec4 cT = sample(tallImage, samplerTransform(tallImage, pT));
    vec4 result = mix(cS, cT, time);
    result.rgb *= shadeAmt;
    return result;
T@"NSNumber",&,N,VinputBottomHeight
T@"NSNumber",&,N,VinputNumberOfFolds
T@"NSNumber",&,N,VinputFoldShadowAmount
kernel %s
kernel<BR/>%s
CodeProperties
SymbolDescriptionArray
ErrorCorrectionLevel
CodeLocation
BarcodeRawData
BarcodeType
BarcodeString
Unknown CIDetectorAccuracy specified. Ignoring.
-[CIBarcodeDetector featuresInImage:options:]
/Library/Caches/com.apple.xbs/Sources/EmbeddedCoreImage_Sim/EmbeddedCoreImage-449/Framework/api/Detectors/CIBarcodeDetector.mm
NULL != symbologies
/System/Library/PrivateFrameworks/Quagga.framework
ACBSConfigCreate
ACBSConfigFree
ACBSConfigSetMaxQRModuleSamples
ACBSCreateFrameInfoBySearchingForBarcodesInCVPixelBuffer
ACBSConfigSetSymbologiesEnabled
ACBSCreateSymbolDescriptorFromBasicDescriptorWithDefaultPayloadEncoding
v8@?0
Quagga.framework is not linked.
Invalid div direction.
divx
divy
div%c %d
<CI::%s %p [%s]>
CIConvolutionWeights
CIConvolution3X3 expects inputWeights to be a length-9 CIVector
T@"CIVector",&,N,VinputWeights
T@"NSNumber",&,N,VinputBias
CIConvolution5X5 expects inputWeights to be a length-25 CIVector
CIConvolution7X7 expects inputWeights to be a length-49 CIVector
kernel vec4 _conv3x3sym (sampler image, vec4 parms)
  vec2 dc = destCoord(); 
  vec2 dA = parms.xy; 
  vec2 dB = vec2(-dA.y, dA.x); 
  vec4 sum = sample(image, samplerTransform(image, dc + dB)) 
           + sample(image, samplerTransform(image, dc + dA)) 
           + sample(image, samplerTransform(image, dc - dA)) 
           + sample(image, samplerTransform(image, dc - dB));
  return sum * parms.z + parms.w;
kernel vec4 _conv3x3 (sampler image, vec4 w0, vec4 w1, vec4 w2)
  vec2 dc = destCoord();
  vec4 sum = w2.yyyy;
  vec2 delta = w2.zw;
  sum += sample(image, samplerTransform(image, dc + vec2(-delta.x, -delta.y))) * w0.x;
  sum += sample(image, samplerTransform(image, dc + vec2(     0.0, -delta.y))) * w0.y;
  sum += sample(image, samplerTransform(image, dc + vec2( delta.x, -delta.y))) * w0.z;
  sum += sample(image, samplerTransform(image, dc + vec2(-delta.x,      0.0))) * w0.w;
  sum += sample(image, samplerTransform(image, dc                           )) * w1.x;
  sum += sample(image, samplerTransform(image, dc + vec2( delta.x,      0.0))) * w1.y;
  sum += sample(image, samplerTransform(image, dc + vec2(-delta.x,  delta.y))) * w1.z;
  sum += sample(image, samplerTransform(image, dc + vec2(     0.0,  delta.y))) * w1.w;
  sum += sample(image, samplerTransform(image, dc + vec2( delta.x,  delta.y))) * w2.x;
  return sum;
kernel vec4 _convolution5x5 (sampler image, vec4 w0, vec4 w1, vec4 w2, vec4 w3, vec4 w4, vec4 w5, vec4 w6)
  vec2 dc = destCoord();
  vec4 sum = w6.yyyy;
  vec2 delta = w6.zw;
  vec2 delt2 = 2.0 * delta;
  sum += sample(image, samplerTransform(image, dc + vec2(-delt2.x, -delt2.y))) * w0.x;
  sum += sample(image, samplerTransform(image, dc + vec2(-delta.x, -delt2.y))) * w0.y;
  sum += sample(image, samplerTransform(image, dc + vec2(     0.0, -delt2.y))) * w0.z;
  sum += sample(image, samplerTransform(image, dc + vec2( delta.x, -delt2.y))) * w0.w;
  sum += sample(image, samplerTransform(image, dc + vec2( delt2.x, -delt2.y))) * w1.x;
  sum += sample(image, samplerTransform(image, dc + vec2(-delt2.x, -delta.y))) * w1.y;
  sum += sample(image, samplerTransform(image, dc + vec2(-delta.x, -delta.y))) * w1.z;
  sum += sample(image, samplerTransform(image, dc + vec2(     0.0, -delta.y))) * w1.w;
  sum += sample(image, samplerTransform(image, dc + vec2( delta.x, -delta.y))) * w2.x;
  sum += sample(image, samplerTransform(image, dc + vec2( delt2.x, -delta.y))) * w2.y;
  sum += sample(image, samplerTransform(image, dc + vec2(-delt2.x,      0.0))) * w2.z;
  sum += sample(image, samplerTransform(image, dc + vec2(-delta.x,      0.0))) * w2.w;
  sum += sample(image, samplerTransform(image, dc                           )) * w3.x;
  sum += sample(image, samplerTransform(image, dc + vec2( delta.x,      0.0))) * w3.y;
  sum += sample(image, samplerTransform(image, dc + vec2( delt2.x,      0.0))) * w3.z;
  sum += sample(image, samplerTransform(image, dc + vec2(-delt2.x,  delta.y))) * w3.w;
  sum += sample(image, samplerTransform(image, dc + vec2(-delta.x,  delta.y))) * w4.x;
  sum += sample(image, samplerTransform(image, dc + vec2(     0.0,  delta.y))) * w4.y;
  sum += sample(image, samplerTransform(image, dc + vec2( delta.x,  delta.y))) * w4.z;
  sum += sample(image, samplerTransform(image, dc + vec2( delt2.x,  delta.y))) * w4.w;
  sum += sample(image, samplerTransform(image, dc + vec2(-delt2.x,  delt2.y))) * w5.x;
  sum += sample(image, samplerTransform(image, dc + vec2(-delta.x,  delt2.y))) * w5.y;
  sum += sample(image, samplerTransform(image, dc + vec2(     0.0,  delt2.y))) * w5.z;
  sum += sample(image, samplerTransform(image, dc + vec2( delta.x,  delt2.y))) * w5.w;
  sum += sample(image, samplerTransform(image, dc + vec2( delt2.x,  delt2.y))) * w6.x;
  return sum;
kernel vec4 _convolution7x7 (sampler image, vec4 w0, vec4 w1, vec4 w2, vec4 w3, vec4 w4, vec4 w5, vec4 w6, vec4 w7, vec4 w8, vec4 w9, vec4 w10, vec4 w11, vec4 w12)
  vec2 dc = destCoord();
  vec4 sum = w12.yyyy;
  vec2 delta = w12.zw;
  vec2 delt2 = 2.0 * delta;
  vec2 delt3 = 3.0 * delta;
  sum += sample(image, samplerTransform(image, dc + vec2(-delt3.x, -delt3.y))) * w0.x;
  sum += sample(image, samplerTransform(image, dc + vec2(-delt2.x, -delt3.y))) * w0.y;
  sum += sample(image, samplerTransform(image, dc + vec2(-delta.x, -delt3.y))) * w0.z;
  sum += sample(image, samplerTransform(image, dc + vec2(     0.0, -delt3.y))) * w0.w;
  sum += sample(image, samplerTransform(image, dc + vec2( delta.x, -delt3.y))) * w1.x;
  sum += sample(image, samplerTransform(image, dc + vec2( delt2.x, -delt3.y))) * w1.y;
  sum += sample(image, samplerTransform(image, dc + vec2( delt3.x, -delt3.y))) * w1.z;
  sum += sample(image, samplerTransform(image, dc + vec2(-delt3.x, -delt2.y))) * w1.w;
  sum += sample(image, samplerTransform(image, dc + vec2(-delt2.x, -delt2.y))) * w2.x;
  sum += sample(image, samplerTransform(image, dc + vec2(-delta.x, -delt2.y))) * w2.y;
  sum += sample(image, samplerTransform(image, dc + vec2(     0.0, -delt2.y))) * w2.z;
  sum += sample(image, samplerTransform(image, dc + vec2( delta.x, -delt2.y))) * w2.w;
  sum += sample(image, samplerTransform(image, dc + vec2( delt2.x, -delt2.y))) * w3.x;
  sum += sample(image, samplerTransform(image, dc + vec2( delt3.x, -delt2.y))) * w3.y;
  sum += sample(image, samplerTransform(image, dc + vec2(-delt3.x, -delta.y))) * w3.z;
  sum += sample(image, samplerTransform(image, dc + vec2(-delt2.x, -delta.y))) * w3.w;
  sum += sample(image, samplerTransform(image, dc + vec2(-delta.x, -delta.y))) * w4.x;
  sum += sample(image, samplerTransform(image, dc + vec2(     0.0, -delta.y))) * w4.y;
  sum += sample(image, samplerTransform(image, dc + vec2( delta.x, -delta.y))) * w4.z;
  sum += sample(image, samplerTransform(image, dc + vec2( delt2.x, -delta.y))) * w4.w;
  sum += sample(image, samplerTransform(image, dc + vec2( delt3.x, -delta.y))) * w5.x;
  sum += sample(image, samplerTransform(image, dc + vec2(-delt3.x,      0.0))) * w5.y;
  sum += sample(image, samplerTransform(image, dc + vec2(-delt2.x,      0.0))) * w5.z;
  sum += sample(image, samplerTransform(image, dc + vec2(-delta.x,      0.0))) * w5.w;
  sum += sample(image, samplerTransform(image, dc                           )) * w6.x;
  sum += sample(image, samplerTransform(image, dc + vec2( delta.x,      0.0))) * w6.y;
  sum += sample(image, samplerTransform(image, dc + vec2( delt2.x,      0.0))) * w6.z;
  sum += sample(image, samplerTransform(image, dc + vec2( delt3.x,      0.0))) * w6.w;
  sum += sample(image, samplerTransform(image, dc + vec2(-delt3.x,  delta.y))) * w7.x;
  sum += sample(image, samplerTransform(image, dc + vec2(-delt2.x,  delta.y))) * w7.y;
  sum += sample(image, samplerTransform(image, dc + vec2(-delta.x,  delta.y))) * w7.z;
  sum += sample(image, samplerTransform(image, dc + vec2(     0.0,  delta.y))) * w7.w;
  sum += sample(image, samplerTransform(image, dc + vec2( delta.x,  delta.y))) * w8.x;
  sum += sample(image, samplerTransform(image, dc + vec2( delt2.x,  delta.y))) * w8.y;
  sum += sample(image, samplerTransform(image, dc + vec2( delt3.x,  delta.y))) * w8.z;
  sum += sample(image, samplerTransform(image, dc + vec2(-delt3.x,  delt2.y))) * w8.w;
  sum += sample(image, samplerTransform(image, dc + vec2(-delt2.x,  delt2.y))) * w9.x;
  sum += sample(image, samplerTransform(image, dc + vec2(-delta.x,  delt2.y))) * w9.y;
  sum += sample(image, samplerTransform(image, dc + vec2(     0.0,  delt2.y))) * w9.z;
  sum += sample(image, samplerTransform(image, dc + vec2( delta.x,  delt2.y))) * w9.w;
  sum += sample(image, samplerTransform(image, dc + vec2( delt2.x,  delt2.y))) * w10.x;
  sum += sample(image, samplerTransform(image, dc + vec2( delt3.x,  delt2.y))) * w10.y;
  sum += sample(image, samplerTransform(image, dc + vec2(-delt3.x,  delt3.y))) * w10.z;
  sum += sample(image, samplerTransform(image, dc + vec2(-delt2.x,  delt3.y))) * w10.w;
  sum += sample(image, samplerTransform(image, dc + vec2(-delta.x,  delt3.y))) * w11.x;
  sum += sample(image, samplerTransform(image, dc + vec2(     0.0,  delt3.y))) * w11.y;
  sum += sample(image, samplerTransform(image, dc + vec2( delta.x,  delt3.y))) * w11.z;
  sum += sample(image, samplerTransform(image, dc + vec2( delt2.x,  delt3.y))) * w11.w;
  sum += sample(image, samplerTransform(image, dc + vec2( delt3.x,  delt3.y))) * w12.x;
  return sum;
kernel vec4 _convolution9 (sampler image, vec4 w0, vec4 w1, vec4 w2)
  vec2 dc = destCoord();
  vec4 sum = w2.yyyy;
  vec2 delta = w2.zw;
  sum += sample(image, samplerTransform(image, dc - delta*4.0)) * w0.x;
  sum += sample(image, samplerTransform(image, dc - delta*3.0)) * w0.y;
  sum += sample(image, samplerTransform(image, dc - delta*2.0)) * w0.z;
  sum += sample(image, samplerTransform(image, dc - delta    )) * w0.w;
  sum += sample(image, samplerTransform(image, dc            )) * w1.x;
  sum += sample(image, samplerTransform(image, dc + delta    )) * w1.y;
  sum += sample(image, samplerTransform(image, dc + delta*2.0)) * w1.z;
  sum += sample(image, samplerTransform(image, dc + delta*3.0)) * w1.w;
  sum += sample(image, samplerTransform(image, dc + delta*4.0)) * w2.x;
  return sum;
kernel vec4 _convolution7 (sampler image, vec4 w0, vec4 w1, vec4 w2)
  vec2 dc = destCoord();
  vec4 sum = w2.yyyy;
  vec2 delta = w2.zw;
  sum += sample(image, samplerTransform(image, dc - delta*3.0)) * w0.y;
  sum += sample(image, samplerTransform(image, dc - delta*2.0)) * w0.z;
  sum += sample(image, samplerTransform(image, dc - delta    )) * w0.w;
  sum += sample(image, samplerTransform(image, dc            )) * w1.x;
  sum += sample(image, samplerTransform(image, dc + delta    )) * w1.y;
  sum += sample(image, samplerTransform(image, dc + delta*2.0)) * w1.z;
  sum += sample(image, samplerTransform(image, dc + delta*3.0)) * w1.w;
  return sum;
kernel vec4 _convolution5 (sampler image, vec4 w0, vec4 w1)
  vec2 dc = destCoord();
  vec4 sum = w1.yyyy;
  vec2 delta = w1.zw;
  sum += sample(image, samplerTransform(image, dc - delta*2.0)) * w0.x;
  sum += sample(image, samplerTransform(image, dc - delta    )) * w0.y;
  sum += sample(image, samplerTransform(image, dc            )) * w0.z;
  sum += sample(image, samplerTransform(image, dc + delta    )) * w0.w;
  sum += sample(image, samplerTransform(image, dc + delta*2.0)) * w1.x;
  return sum;
kernel vec4 _convolution3 (sampler image, vec4 w0, vec4 w1)
  vec2 dc = destCoord();
  vec4 sum = w1.yyyy;
  vec2 delta = w1.zw;
  sum += sample(image, samplerTransform(image, dc - delta    )) * w0.y;
  sum += sample(image, samplerTransform(image, dc            )) * w0.z;
  sum += sample(image, samplerTransform(image, dc + delta    )) * w0.w;
  return sum;
kernel vec4 _scaleClamp(__sample p, float scale)
  return clamp(p * scale, 0.0, 1.0);
kernel vec4 _innerGorS (__sample b, __color color, float range)
  return clamp((1.0 - b.a) / range, 0.0, 1.0) * color;
inputOffset
inputRange
T@"CIVector",&,N,VinputOffset
T@"NSNumber",&,N,VinputRange
kernel vec4 _outerGorS (__sample b, __color color, float range)
  return clamp(b.a / range, 0.0, 1.0) * color;
inputSpread
T@"NSNumber",&,N,VinputSpread
inputGlowColorInner
inputGlowOuterOuter
inputShadowColorInner
inputShadowOuterOuter
inputShadowBlurInner
inputShadowBlurOuter
kernel vec4 _shapeEffectBlur_1 (__sample p0, __sample p1, __sample b0, __sample b1, __sample f0, 
                         __color gcI, __color gcO, __color scI, __color scO, vec2 sparms) 
  gcI *= clamp( (1.0 - b0.a) * 2.0, 0.0, 1.0); 
  gcO *= clamp( b0.a * 2.0, 0.0, 1.0); 
  scI *= mix( (1.0 - p1.a), (1.0 - b1.a), sparms.x ); 
  scO *= mix( p1.a, b1.a, sparms.y ); 
  vec4 I,O; 
  I = (gcI +  f0*(1.0 - gcI.a)); 
  I = (scI +   I*(1.0 - scI.a)) * (p0.a); 
  O = (gcO + scO*(1.0 - gcO.a)) * (1.0 - p0.a); 
  return I + O*(1.0 - I.a); 
inputFill
T@"CIImage",&,N,VinputFill
T@"CIColor",&,N,VinputGlowColorInner
inputGlowColorOuter
T@"CIColor",&,N,VinputGlowColorOuter
T@"CIColor",&,N,VinputShadowColorInner
inputShadowColorOuter
T@"CIColor",&,N,VinputShadowColorOuter
T@"NSNumber",&,N,VinputShadowBlurInner
T@"NSNumber",&,N,VinputShadowBlurOuter
inputSoften
inputHighlightColor
inputShadowColor
kernel vec4 _outerBevelEmboss (sampler image, vec2 ss) 
  vec2 st = destCoord(); 
  float a = 0.0, mm_a, pm_a, mp_a, pp_a;
  mm_a = sample(image, samplerTransform(image, st + ss.yy)).a; 
  pm_a = sample(image, samplerTransform(image, st + ss.xy)).a; 
  mp_a = sample(image, samplerTransform(image, st + ss.yx)).a; 
  pp_a = sample(image, samplerTransform(image, st + ss.xx)).a; 
  a = mm_a + pm_a - 1.3*(mp_a+pp_a); 
  a = clamp( a*0.5 + 0.5, 0.0, 1.0); 
  return vec4(a); 
kernel vec4 _outerBevelEmbossC (__sample v, __color hc, __color sc) 
  float a = v.a * 2.0 - 1.0; 
  vec4 result = hc*clamp(a, 0.0, 1.0) + sc*clamp(-a, 0.0, 1.0); 
  return result; 
T@"NSNumber",&,N,VinputSoften
T@"CIColor",&,N,VinputHighlightColor
T@"CIColor",&,N,VinputShadowColor
kernel vec4 _invertedMask (__sample c) { return vec4(0.0, 0.0, 0.0, 1.0 - c.a); } 
kernel vec4 _multiplyByMask (__sample c, __sample m) { return c*m.a;} 
CI_DEBUG_AUTOCROP
scaleRect:inner=(%.3f,%.3f,%.3f,%.3f), size=(%.3f,%.3f), anchor=(%.3f,%.3f)
ERROR <AutoCropper>: Point should be within rect
AspectRatioCutoff
MinimumCroppedArea
ProximityToCenter
Face area is %f, Total is %f
Large Face!
ERROR <AutoCropper>: unrecognized aspect ratio
No Crop. Reduces area too much
Clipping to original aspect ratio
Clipping to aspect ratio 4:3
Clipping to aspect ratio 3:2
Clipping to aspect ratio 16:9
Clipping to square
Clipping to aspect ratio 5:3
Clipping to aspect ratio 5:4
MinCropPercentage
com.apple.mobileslideshow
determineBestPositionWithinSize:size=%.3f,%.3f, center=%.3f,%.3f, minPercentage=%.3f, restrict=%.3f,%.3f,%.3f,%.3f
originalArea = %.2f
pos = %d, rect=(%.2f,%.2f,%.2f,%.2f), area=%.2f
    topleft=%.2f
    topcenter=%.2f
    topright=%.2f
    bottomleft=%.2f
    bottomcenter=%.2f
    bottomright=%.2f
    leftcenter=%.2f
    rightcenter=%.2f
    center=%.2f
Best is %d
Want bottom
shouldFavorBottom
TB,N,VshouldFavorBottom
shouldFavorTop
TB,N,VshouldFavorTop
originalImageSize
T{CGSize=dd},N,VoriginalImageSize
ProviderImageSurfaceCacheQueue
provider %s
 %ldx%ld<BR/>
tile=%zux%zu<BR/>
Render failed because a pixel format %s is not supported.
image%d_0
u%d_0
transform%d
vec4 _srgb_to_linear (vec4 s) { return srgb_to_linear(s); }
_image[%d]
_transform[%d]
_extent[%d]
Invalid DAG node type
vec4 _linear_to_srgb (vec4 s) { return linear_to_srgb(s); }
vec4 _read_pixel(sampler2D image, vec2 c, vec4 m0, vec4 m1) {
     float x = dot(vec4(c,1.0,0.0), m0);
     float y = dot(vec4(c,1.0,0.0), m1);
     return texture2D(image, vec2(x,y)); }
vec4 _read_pixel(sampler2D image, vec2 c, mat3 m){ return texture2D(image, (vec3(c, 1.0) * m).xy);}
vec4 _read_pixel_420(sampler2D Y, sampler2D cc, vec2 c, vec2 f, vec4 m0, vec4 m1){
     float x = dot(vec4(c,1.0,0.0), m0);
     float y = dot(vec4(c,1.0,0.0), m1);
     return vec4(texture2D(Y, vec2(x,y)).a, texture2D(cc, 0.5*vec2(x,y)).rg, 1.0);}
vec4 _read_pixel_420(sampler2D Y, sampler2D cc, vec2 c, vec2 f, mat3 m){
     highp vec3 p = vec3(c, 1.0) * m;
     return vec4(texture2D(Y, p.xy).a, texture2D(cc, f*p.xy).rg, 1.0);}
tweakViaRegex
 ## 
(float|vec2|vec3|vec4)[[:s:]]+([a-zA-Z_0-9]+)[[:s:]]*\((.*)\)[[:s:]]*{
.*(sampler|int).*
[[:s:]]+
[[:s:]]*
_ci_tweaked_(
[[:s:]]*([a-zA-Z_0-9]*)[[:s:]]+([a-zA-Z_0-9]*)
sampler2D 
, vec4 
_transform0
_transform1
_transform2
, mat4 
_transform
#define 
Mapping beyond limit of 2
doCanny
/Library/Caches/com.apple.xbs/Sources/EmbeddedCoreImage_Sim/EmbeddedCoreImage-449/Framework/filters/AutoEnhance/Horizon/fft/CannyEdge.c
rows > 0
cols > 0
doCannyRGB
  CI:follow_edges - stack increase failed
follow_edges
kernel vec2 _circularWrap(vec2 center, float b, float c, float d, float minAngle)
  vec2 p;
  vec2 t0 = destCoord() - center;
  float d0 = dot(t0, t0);
  float d1 = inversesqrt(d0);
  float r = d0 * d1; 
  vec2 u = t0 * d1; 
  vec2 x_ = abs(u);
  vec2 t = 0.00119152193164364 + (1.149637430629571 + (-0.6987144230270900 + 0.9002138006758336 * x_) * x_) * x_;
  vec2 thetas = compare(u, -t, t);
  thetas.x = (u.y < 0.0) ? (thetas.x - 1.5707963) : (1.5707963 - thetas.x);
  thetas.y = (u.x < 0.0) ? (3.1415927 - thetas.y) : thetas.y;
  vec2 abss = abs(u); 
  float theta = (abss.x < abss.y) ? thetas.x : thetas.y;
  theta = fract((theta - minAngle) * 0.15915494) * 6.2831853;
  p.x = theta * c + d; 
  p.y = r + b; 
  return p;
autoRotateFilterFFT: props exist
Orientation = %d
  Found makerNotes
    Found vector: %.3f,%.3f,%.3f
acc = (%.5f, %.5f, %.5f)
accelTilt = %.3f deg, accelPitch = %.3f deg, accMagnitudeDev %.3f
accelPitch = %.3f deg, accelMagnitudeDev = %.3f
MaxAccelPitch
MaxPixelTilt
MinPixelTilt
MaxAccelMagDev
MaxAccelFFTDiff
MaxPitch = %.3f, MaxPixelTilt = %.3f, MinPixelTilt = %.3f, MaxAccelMagDev = %.3f, MaxAccelFFTDifff = %.3f
FFT detected angle = %.3f deg
Crop: Based on %d features
  feature%d has left eye at (%.3f,%.3f), right eye at (%.3f,%.3f)
  clip overall %% = %.3f
    too much clipping - reverting back to rotated crop only
    too little clipping - reverting back
CIBurstActionClassifier
CIBurstImageSetInternal
CIAreaHistogram
CIEdgeWork
CIMaskedVariableBlur
CIBurstFaceConfigEntry
CIBurstFaceScoreEntry
CIBurstFaceInfo
CIBurstImageFaceAnalysisContext
CIBurstFaceStat
NSCopying
CIBurstImageStat
CITriangleTile
CICircleGenerator
CIGlassLozenge
CITorusLensDistortion
CIContext
Internal
CIPageCurlTransition
CIPageCurlWithShadowTransition
CIFilter
NSSecureCoding
NSCoding
_CIFilterProperties
Private
CIParallelogramTile
CILinearBlur
CIMotionBlur
CIZoomBlur
CIImage
CIKernel
CIColorKernel
CIWarpKernel
CILenticularHaloGenerator
CIImageProvider
CISoftCubicUpsample
CIDepthOfField
NSError
CIAffineTransform
CICrop
ImageRepresentation
CISepiaTone
CIStraightenFilter
CIImageAccumulator
CIVector
CIExposureAdjust
CIDisplacementDistortion
CIColorControls
CIHueAdjust
CIReductionFilter
CIAreaAverage
CIColumnAverage
CIRowAverage
CIAreaMaximum
CIAreaMinimum
CIAreaMaximumAlpha
CIAreaMinimumAlpha
CIColorMatrix
CIColorInvert
CIVibrance
CITemperatureAndTint
CIWhitePointAdjust
CIFalseColor
CIGammaAdjust
CIImageProcessorInOut
CIImageProcessorOutput
CIImageProcessorInput
CIImageProcessor
CIImageProcessorKernel
CINoiseReduction
CIProSharpenEdges
CIOpTile
CISampler
CIShadedMaterial
PrivateSmartToneAndColor
CISmartToneFilter
CISmartColorFilter
CIBitmapContext
AutoAdjust
CIRedEyeCorrection
CIRedEyeCorrections
CIEnhancementHistogram
CIConvolution
CIDiscBlur
CIAutoEnhanceFace
CIDroste
_CICompositeFilter
CISourceOverCompositing
CISourceInCompositing
CISourceOutCompositing
CISourceAtopCompositing
CIAdditionCompositing
CIMultiplyCompositing
CIMinimumCompositing
CIMaximumCompositing
CIPlusDarkerCompositing
CIPlusLighterCompositing
CIImageRowReader
ImageRowReading
CIEnhancementCalculator
CIToneCurve
CIFilterRegistry
CIFilterRegistryPrivate
CIFilterClassAttributes
CIFilterClassCategories
CIFilterClassDefaults
CIFilterClassInfo
CIHighlightShadowAdjust
CITextDetector
CIRippleTransition
CIIntegralImageKernelProcessor
CIIntegralImage
CISmartBlackAndWhite
PrivateSmartBlackAndWhite
CIFaceBalance
CIRedEyeRepair
CIMirror
CITriangleKaleidoscope
CICheapBlur
CIStretch
CILightTunnel
CIEdgePreserveUpsampleFilter
CIEdgePreserveUpsampleRGFilter
CIRAWFilter
CIDetector
CIFaceCoreDetector
CIFeature
CIFaceFeature
CIRectangleFeature
CIQRCodeFeature
CITextFeature
CIColor
CISkyAndGrassAdjust
CIConstantColorGenerator
CruftCompatability
CIEnhancementCalculation
CIRectangleDetector
CIPremultiply
CIUnpremultiply
CISpotLight
CIColorCube
CIColorCubeWithColorSpace
CIRadialGradient
CILinearGradient
CISmoothLinearGradient
CIGaussianGradient
CIHueSaturationValueGradient
CICheckerboardGenerator
CIColorMonochrome
CIStripesGenerator
CIBlendModeFilter
CIColorBurnBlendMode
CIColorDodgeBlendMode
CILinearBurnBlendMode
CILinearDodgeBlendMode
CIDarkenBlendMode
CIDifferenceBlendMode
CIDivideBlendMode
CISubtractBlendMode
CIExclusionBlendMode
CIHardLightBlendMode
CIHardMixBlendMode
CILightenBlendMode
CILinearLightBlendMode
CIMultiplyBlendMode
CIOverlayBlendMode
CIPinLightBlendMode
CIScreenBlendMode
CISoftLightBlendMode
CIVividLightBlendMode
CIHueBlendMode
CISaturationBlendMode
CIColorBlendMode
CILuminosityBlendMode
CITwirlDistortion
CIVignette
CIVignetteEffect
CIKaleidoscope
CIColorBalance
CIPinchDistortion
CIPointillize
CIVariableBoxBlur
CICMYKHalftone
CIWrapMirror
CILumaMap
CIXRay
CIThermal
CICodeGenerator
CIPDF417BarcodeGenerator
CIQRCodeGenerator
CIAztecCodeGenerator
CICode128BarcodeGenerator
CIBurstThumbnailCluster
CICrystallize
CIPassThroughFilter
CIPassThroughColorFilter
CIPassThroughWarpFilter
CIPassThroughGeneralFilter
CIPassThroughGeneralAltFilter
CIPassThroughIntermediateFilter
CIReedSolomon
CISunbeamsGenerator
CIPhotoGrain
CIPhotoEffect
CIPhotoEffectNoir
CIPhotoEffectChrome
CIPhotoEffectFade
CIPhotoEffectInstant
CIPhotoEffectMono
CIPhotoEffectProcess
CIPhotoEffectTonal
CIPhotoEffectTransfer
CIGaussianBlur
CIGaussianBlurXY
CIUnsharpMask
CIBurstClusterDivider
CIRandomGenerator
_CIScreenFilter
CIDotScreen
CIHatchedScreen
CILineScreen
CICircularScreen
CISRGBToneCurveToLinear
CILinearToSRGBToneCurve
CIBloom
CIGloom
CIColorPosterize
CIEdges
CIDissolveTransition
CIMaskToAlpha
CIPixellate
CIHexagonalPixellate
CISharpenLuminance
CISwipeTransition
CICheapMorphology
CIMorphologyGradient
CIMorphologyLaplacian
CIPseudoMedian
CIBurstImageSet
CIHoleDistortion
CICheatBlur
CIMinimumComponent
CIMaximumComponent
CIRectangleGenerator
CIVortexDistortion
CILanczosScaleTransform
CIBlendWithMask
CIBlendWithAlphaMask
CIBurstYUVImage
Apply
CIRAWTemperatureAdjust
CIRAWGamutMapping
CIFilterShape
CIFilterShapePrivate
CISimpleTile
CIAffineTile
CIClamp
CIAffineClamp
CICircleSplashDistortion
CIModTransition
CICopyMachineTransition
CITileFilter
CITile2Filter
CIFourfoldRotatedTile
CISixfoldRotatedTile
CITwelvefoldReflectedTile
CIFourfoldTranslatedTile
CIGlideReflectedTile
CIEightfoldReflectedTile
CIFourfoldReflectedTile
CISixfoldReflectedTile
CILineOverlay
CISpotColor
CIComicEffect
CIBoxBlur
PrivateLocalLight
CILocalLightFilter
CIColorMap
CIMedianFilter
CIBarsSwipeTransition
CIDisintegrateWithMaskTransition
CIFlashTransition
CIStarShineGenerator
AutoROI
CIPerspectiveTransformWithExtent
CIPerspectiveTransform
CIPerspectiveTile
CIPerspectiveCorrection
CIBumpDistortion
CIBumpDistortionLinear
CIColorPolynomial
CIColorCrossPolynomial
CIRAWFilterImpl
CustomAccessors
WhiteBalance
CIHeightFieldFromMask
CIColorClamp
CIGlassDistortion
CIStretchCrop
CINinePartStretched
CINinePartTiled
CIHistogramDisplayFilter
CILocalContrast
CIAccordionFoldTransition
CIBarcodeDetector
CIConvolution3X3
CIConvolution5X5
CIConvolution7X7
CIConvolution9Horizontal
CIConvolution9Vertical
CUIScaleClampFilter
CUIInnerGlowOrShadowFilter
CUIOuterGlowOrShadowFilter
CUIShapeEffectBlur1
CUIOuterBevelEmbossFilter
CUIInnerBevelEmbossFilter
AutoCropper
CIOpacity
CICircularWrap
AutoAdjustCrop
@16@0:8
@20@0:8i16
v16@0:8
d24@0:8r^{CIBurstSupportVector=d[7d]}16
f16@0:8
B16@0:8
v20@0:8f16
^{__SVMParameters=[7{__SVMScaleOffset=ff}]ddii^{CIBurstSupportVector}^{CIBurstSupportVector}}16@0:8
v24@0:8^{__SVMParameters=[7{__SVMScaleOffset=ff}]ddii^{CIBurstSupportVector}^{CIBurstSupportVector}}16
[7d]
^{__SVMParameters=[7{__SVMScaleOffset=ff}]ddii^{CIBurstSupportVector}^{CIBurstSupportVector}}
@24@0:8@16
v20@0:8B16
v56@0:8@16@24@32@40@?48
i24@0:8@16
v24@0:8@16
@28@0:8@16B24
v28@0:8@16i24
i16@0:8
v20@0:8i16
@"NSObject<OS_dispatch_queue>"
@"NSObject<OS_dispatch_semaphore>"
@"NSMutableArray"
@"NSString"
@"CIBurstImageFaceAnalysisContext"
@"CIBurstYUVImage"
@"NSDictionary"
@"NSCountedSet"
@"NSMutableDictionary"
^{__sFILE=*iiss{__sbuf=*i}i^v^?^?^?^?{__sbuf=*i}^{__sFILEX}i[3C][1C]{__sbuf=*i}iq}
@"CIBurstActionClassifier"
{IRect={IPoint=qq}{ISize=QQ}}16@0:8
@20@0:8B16
@"CIImage"
@"CIVector"
@"NSNumber"
@"CIContext"
@28@0:8@16f24
@52@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16i48
{CGRect={CGPoint=dd}{CGSize=dd}}16@0:8
v48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
{CGRect="origin"{CGPoint="x"d"y"d}"size"{CGSize="width"d"height"d}}
@20@0:8f16
f48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
{CGPoint=dd}16@0:8
v32@0:8{CGPoint=dd}16
{CGSize=dd}16@0:8
v32@0:8{CGSize=dd}16
{CGPoint="x"d"y"d}
{CGSize="width"d"height"d}
{CGRect={CGPoint=dd}{CGSize=dd}}56@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16f48f52
{CGRect={CGPoint=dd}{CGSize=dd}}40@0:8@16@24^B32
@56@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48
i32@0:8@16@24
v32@0:8@16@24
v40@0:8@16{CGSize=dd}24
d16@0:8
v24@0:8d16
@"FCRFaceDetector"
@24@0:8^{_NSZone=}16
v48@0:8^^f16^^f24^^f32^^f40
v24@0:8^f16
{GridROI_t=iiii}16@0:8
f32@0:8@16@24
v32@0:8{GridROI_t=iiii}16
v40@0:8@16^f24^f32
f24@0:8@16
^S16@0:8
f20@0:8f16
q24@0:8@16
^f16@0:8
[1024f]
[256S]
{FastRegistration_Signatures="piRow"^f"nPiRow"Q"piRowTable"{Projections_meanStdTable="sumTable"^f"sumSqTable"^f}"piCol"^f"nPiCol"Q"piColTable"{Projections_meanStdTable="sumTable"^f"sumSqTable"^f}}
^{SharpnessGridElement_t=CCf}
{GridROI_t="startX"i"startY"i"endX"i"endY"i}
@"CIColor"
@32@0:8^{CGContext=}16@24
@32@0:8@16@24
i84@0:8@16^v24q32{CGRect={CGPoint=dd}{CGSize=dd}}40i72^{CGColorSpace=}76
^{CGColorSpace=}16@0:8
v84@0:8@16^v24q32{CGRect={CGPoint=dd}{CGSize=dd}}40i72^{CGColorSpace=}76
v32@0:8@16^{__CVBuffer=}24
v72@0:8@16^{__CVBuffer=}24{CGRect={CGPoint=dd}{CGSize=dd}}32^{CGColorSpace=}64
v24@0:8r*16
v72@0:8@16{CGPoint=dd}24{CGRect={CGPoint=dd}{CGSize=dd}}40
v88@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24{CGRect={CGPoint=dd}{CGSize=dd}}56
v68@0:8@16I24{CGRect={CGPoint=dd}{CGSize=dd}}28^{CGColorSpace=}60
v72@0:8@16I24I28{CGRect={CGPoint=dd}{CGSize=dd}}32^{CGColorSpace=}64
v80@0:8@16@24@32{CGRect={CGPoint=dd}{CGSize=dd}}40^{CGColorSpace=}72
^{CGImage=}56@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24
^{CGImage=}60@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24i56
^{CGImage=}68@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24i56^{CGColorSpace=}60
^{CGImage=}72@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24i56^{CGColorSpace=}60B68
^{CGLayer=}40@0:8{CGSize=dd}16^{__CFDictionary=}32
Q16@0:8
@68@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24i56^{CGColorSpace=}60
B44@0:8@16i24^@28^{CGRect={CGPoint=dd}{CGSize=dd}}36
v64@0:8{CGAffineTransform=dddddd}16
{CGAffineTransform=dddddd}16@0:8
@28@0:8@16i24
^{CGImage=}80@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24i56^{CGColorSpace=}60B68Q72
^{Context=^^?{Atomic={?=i}}^{CGColorSpace}^{CGColorSpace}iBBBB^{CGContext}fB{CGRect={CGPoint=dd}{CGSize=dd}}{CGAffineTransform=dddddd}iQQiB[1024{TreeCacheElement={Hash=[20C]}Q^{Kernel}}]QddB@@}16@0:8
@24@0:8^v16
^{Context=^^?{Atomic={?=i}}^{CGColorSpace}^{CGColorSpace}iBBBB^{CGContext}fB{CGRect={CGPoint=dd}{CGSize=dd}}{CGAffineTransform=dddddd}iQQiB[1024{TreeCacheElement={Hash=[20C]}Q^{Kernel}}]QddB@@}24@0:8@16
^{Context=^^?{Atomic={?=i}}^{CGColorSpace}^{CGColorSpace}iBBBB^{CGContext}fB{CGRect={CGPoint=dd}{CGSize=dd}}{CGAffineTransform=dddddd}iQQiB[1024{TreeCacheElement={Hash=[20C]}Q^{Kernel}}]QddB@@}32@0:8@16@24
^{Context=^^?{Atomic={?=i}}^{CGColorSpace}^{CGColorSpace}iBBBB^{CGContext}fB{CGRect={CGPoint=dd}{CGSize=dd}}{CGAffineTransform=dddddd}iQQiB[1024{TreeCacheElement={Hash=[20C]}Q^{Kernel}}]QddB@@}32@0:8@16^v24
@56@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24
@64@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24^@56
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
@40@0:8@16@24@32
[8^v]
@"NSArray"16@0:8
@"CIFilter"24@0:8@"NSArray"16
B24@0:8@16
^{CGImageMetadata=}56@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24
@56@0:8^{CGImageMetadata=}16{CGRect={CGPoint=dd}{CGSize=dd}}24
@32@0:8@16i24f28
@24@0:8^{CGImage=}16
@32@0:8^{CGImage=}16@24
@24@0:8^{CGLayer=}16
@32@0:8^{CGLayer=}16@24
@60@0:8@16Q24{CGSize=dd}32i48@52
@60@0:8@16Q24{CGSize=dd}32i48^{CGColorSpace=}52
@48@0:8I16{CGSize=dd}20B36^{CGColorSpace=}40
@44@0:8I16{CGSize=dd}20@36
@48@0:8I16{CGSize=dd}20B36@40
@24@0:8^{__CVBuffer=}16
@32@0:8^{__CVBuffer=}16@24
@32@0:8@16@?24
@40@0:8^{__IOSurface=}16@24^v32
v24@0:8^{CGImage=}16
^{CGImage=}16@0:8
@40@0:8^{CGImageSource=}16Q24@32
v24@0:8^{__CVBuffer=}16
^{__CVBuffer=}16@0:8
@48@0:8d16d24d32d40
{CGAffineTransform=dddddd}20@0:8i16
@64@0:8{CGAffineTransform=dddddd}16
@68@0:8{CGAffineTransform=dddddd}16B64
@48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
@24@0:8d16
@24@0:8^{CGColorSpace=}16
^v16@0:8
{CGRect={CGPoint=dd}{CGSize=dd}}56@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24
B20@0:8i16
i32@0:8@16^{Kernel=^^?{Atomic={?=i}}**B^{SerialIntArray}^{SerialStringArray}^{__CFString}BBBi}24
@72@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@?48@56@64
@64@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@?48@56
v24@0:8:16
:16@0:8
@64@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48@56
@80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@?48@56@64@72
@64@0:8@16@24{CGSize=dd}32i48B52^{CGColorSpace=}56
@60@0:8@16Q24Q32i40^{CGColorSpace=}44@52
@60@0:8@?16Q24Q32i40^{CGColorSpace=}44@52
@64@0:8@?16Q24Q32i40^{CGColorSpace=}44B52@56
{vec2=ff}16@0:8
@"NSValue"
@44@0:8@16i24^{CGColorSpace=}28@36
@40@0:8@16^{CGColorSpace=}24@32
B60@0:8@16@24i32^{CGColorSpace=}36@44^@52
B56@0:8@16@24^{CGColorSpace=}32@40^@48
@60@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16i48@52
@60@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16i48^{CGColorSpace=}52
v56@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24
@32@0:8r^d16Q24
@32@0:8d16d24
@40@0:8d16d24d32
@32@0:8{CGPoint=dd}16
d24@0:8Q16
(?="vec"[4d]"ptr"^d)
^d16@0:8
@80@0:8^{__IOSurface=}16{Texture=(?=I^v)I}24{CGRect={CGPoint=dd}{CGSize=dd}}40^{Context=^^?{Atomic={?=i}}^{CGColorSpace}^{CGColorSpace}iBBBB^{CGContext}fB{CGRect={CGPoint=dd}{CGSize=dd}}{CGAffineTransform=dddddd}iQQiB[1024{TreeCacheElement={Hash=[20C]}Q^{Kernel}}]QddB@@}72
^{__IOSurface=}16@0:8
^{__IOSurface=}
^{Context=^^?{Atomic={?=i}}^{CGColorSpace}^{CGColorSpace}iBBBB^{CGContext}fB{CGRect={CGPoint=dd}{CGSize=dd}}{CGAffineTransform=dddddd}iQQiB[1024{TreeCacheElement={Hash=[20C]}Q^{Kernel}}]QddB@@}
@"<MTLTexture>"
@"<MTLTexture>"16@0:8
@"<MTLCommandBuffer>"16@0:8
@"<MTLCommandBuffer>"
r^v16@0:8
@84@0:8^{__IOSurface=}16{Texture=(?=I^v)I}24{CGRect={CGPoint=dd}{CGSize=dd}}40^{Context=^^?{Atomic={?=i}}^{CGColorSpace}^{CGColorSpace}iBBBB^{CGContext}fB{CGRect={CGPoint=dd}{CGSize=dd}}{CGAffineTransform=dddddd}iQQiB[1024{TreeCacheElement={Hash=[20C]}Q^{Kernel}}]QddB@@}72B80
@96@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48Q56i64i68@72@?80@?88
B48@0:8@16@24@32^@40
{CGRect={CGPoint=dd}{CGSize=dd}}60@0:8i16@20{CGRect={CGPoint=dd}{CGSize=dd}}28
i20@0:8i16
Q24@0:8@16
@72@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48@56^@64
@40@0:8@16@24[1{__va_list_tag=II^v^v}]32
@32@0:8d16@24
@40@0:8d16d24@32
@"NSData"
@68@0:8^v16q24{CGRect={CGPoint=dd}{CGSize=dd}}32i64
@76@0:8^v16q24{CGRect={CGPoint=dd}{CGSize=dd}}32i64@68
B68@0:8^v16q24{CGRect={CGPoint=dd}{CGSize=dd}}32i64
^{CIBitmapContextPrivate=^vq{CGRect={CGPoint=dd}{CGSize=dd}}i}
@20@0:8I16
@36@0:8@16d24f32
@48@0:8@16@24@32@40
@"NSArray"
@24@0:8r^d16
@24@0:8r^f16
r^d16@0:8
[256d]
{CGRect={CGPoint=dd}{CGSize=dd}}80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48
@28@0:8@16I24
@36@0:8@16I24^{CGColorSpace=}28
@44@0:8@16I24^{CGColorSpace=}28@36
@40@0:8@16@24^{CGColorSpace=}32
r*20@0:8I16
I16@0:8
v32@0:8@16^{CGColorSpace=}24
s16@0:8
^{CGColorSpace=}
v36@0:8@16i24i28i32
v40@0:8@16@24@32
@28@0:8r^{CGPoint=dd}16B24
@24@0:8r^{CGPoint=dd}16
v44@0:8^d16i24d28r^{CGPoint=dd}36
@36@0:8@16i24@28
@24@0:8#16
@"FKTextDetector"
{CGAffineTransform=dddddd}52@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16i48
@36@0:8@16i24^{CGAffineTransform=dddddd}28
v24@0:8^{?=Bffff[3f]}16
@24@0:8^f16
{CGRect={CGPoint=dd}{CGSize=dd}}52@0:8{CGPoint=dd}16{CGSize=dd}32f48
{CGRect={CGPoint=dd}{CGSize=dd}}40@0:8@16{CGSize=dd}24
B48@0:8^{CGImage=}16^{?=*iiiiiiif}24Q32Q40
B32@0:8^{CGImage=}16^{?=*iiiiiiif}24
v24@0:8^{CGColorSpace=}16
@32@0:8@16^{?=[256c][32c]{?=*iiiiiiif}ii{?=iiii}^{CGColorSpace}IiiBf}24
@24@0:8^{?=[256c][32c]{?=*iiiiiiif}ii{?=iiii}^{CGColorSpace}IiiBf}16
@48@0:8*16{CGSize=dd}24Q40
@88@0:8*16{CGRect={CGPoint=dd}{CGSize=dd}}24{CGSize=dd}56Q72@80
{?=iiii}16@0:8
^{?=i{CGPoint=dd}iiii{?=*iiiiiiif}{?=iiii}{?=iiii}B{?=iiii}iBf{?=iiiiiiiiiiB{?=iiii}{?=iiii}iiif{?=ifBifff}{?=iiii}}{?={CGPoint=dd}ifffi{?=iiii}fBiiiiffff}}16@0:8
i40@0:8^{?=*iiiiiiif}16^{?=*iiiiiiif}24^{?=*iiiiiiif}32
B88@0:8^{?=*iiiiiiif}16^{?=*iiiiiiif}24^{?=*iiiiiiif}32{?=iiii}40^{?=*iiiiiiif}56^{?=*iiiiiiif}64^{?=iiii}72^{?=iiii}80
B56@0:8^{?=*iiiiiiif}16{?=iiii}24^{?=*iiiiiiif}40^{?=*iiiiiiif}48
i64@0:8{CGPoint=dd}16B32{?=iiii}36i52f56B60
^{?=i{CGPoint=dd}iiii{?=*iiiiiiif}{?=iiii}{?=iiii}B{?=iiii}iBf{?=iiiiiiiiiiB{?=iiii}{?=iiii}iiif{?=ifBifff}{?=iiii}}{?={CGPoint=dd}ifffi{?=iiii}fBiiiiffff}}20@0:8i16
i24@0:8i16f20
f36@0:8^{?=Biiffiiiiffiifiiiiiifiiii}16^f24i32
f28@0:8f16i20i24
v52@0:8^{?=i[4{?=fiifffiif}]}16i24i28f32f36i40i44f48
B96@0:8^{?=*iiiiiiif}16^{?=*iiiiiiif}24^{?=*iiiiiiif}32^{?=*iiiiiiif}40i48i52{?=iiii}56^{?=Biiffiiiiffiifiiiiiifiiii}72^{?=i[4{?=fiifffiif}]}80i88B92
v68@0:8{?=iiii}16{?=iiii}32^{?=Biiffiiiiffiifiiiiiifiiii}48f56B60i64
i24@0:8i16i20
i152@0:8{?=iiiiiiiiiiB{?=iiii}{?=iiii}iiif{?=ifBifff}{?=iiii}}16
B40@0:8^f16@24@32
B40@0:8^i16@24@32
B40@0:8^B16@24@32
^{?=[256c][32c]{?=*iiiiiiif}ii{?=iiii}^{CGColorSpace}IiiBf}
^{CGImageBlockSet=}
^{__CFData=}
[32{?="tag"i"pt2"{CGPoint="x"d"y"d}"eyeCase"i"forceCase"i"npixels"i"bignpixels"i"fullNew"{?="baseAddress"*"width"i"height"i"rowSamples"i"rowBytes"i"size"i"samplesPerPixel"i"bytesPerSample"i"resolution"f}"YR"{?="minrow"i"maxrow"i"mincol"i"maxcol"i}"psTemplate"{?="lo"i"med"i"hi"i"average"i}"pupilShadeAlignment"B"matchingTemplate"{?="lo"i"med"i"hi"i"average"i}"faceIndex"i"left"B"IOD"f"data"{?="origHitX"i"origHitY"i"snapHitX"i"snapHitY"i"bitmaskSeedX"i"bitmaskSeedY"i"bitmaskThreshold"i"cornealReflectionSeedX"i"cornealReflectionSeedY"i"cornealReflectionThreshold"i"align"B"mTemplate"{?="lo"i"med"i"hi"i"average"i}"existingTemplate"{?="lo"i"med"i"hi"i"average"i}"averageSkinMapY"i"characterizeCase"i"finalEyeCase"i"IOD"f"O"{?="orientation"i"SNR"f"N90"B"redBitmaskArea"i"imageCenterX"f"imageCenterY"f"halfDiagonalSize"f}"CR"{?="minrow"i"maxrow"i"mincol"i"maxcol"i}}"BI"{?="centroid"{CGPoint="x"d"y"d}"area"i"ovalness"f"contrast"f"mincontrast"f"nborder"i"IR"{?="minrow"i"maxrow"i"mincol"i"maxcol"i}"aspectRatio"f"touchingEdge"B"localmax"i"localmaxrow"i"localmaxcol"i"localfloor"i"rgmean"f"rgstd"f"ymean"f"ystd"f}}]
{?="lo"i"med"i"hi"i"average"i}
{?="baseAddress"*"width"i"height"i"rowSamples"i"rowBytes"i"size"i"samplesPerPixel"i"bytesPerSample"i"resolution"f}
[3{?="baseAddress"*"width"i"height"i"rowSamples"i"rowBytes"i"size"i"samplesPerPixel"i"bytesPerSample"i"resolution"f}]
[3{?="minrow"i"maxrow"i"mincol"i"maxcol"i}]
[20{CGPoint="x"d"y"d}]
[20{?="a"f"b"f"c"f}]
[20B]
[65536C]
[8[3i]]
{Rectangle=dddd}68@0:8{vec2=ff}16{vec3=fff}24{vec4=ffff}36{vec4=ffff}52
{CGRect={CGPoint=dd}{CGSize=dd}}32@0:8{vec4=ffff}16
@40@0:8^{__CVBuffer=}16@24@32
@40@0:8@16^Q24^Q32
@144@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16B48{CGPoint=dd}52B68{CGPoint=dd}72B88{CGPoint=dd}92B108f112B116i120B124i128B132B136B140
@112@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGPoint=dd}48{CGPoint=dd}64{CGPoint=dd}80{CGPoint=dd}96
@120@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGPoint=dd}48{CGPoint=dd}64{CGPoint=dd}80{CGPoint=dd}96@112
@128@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGPoint=dd}48{CGPoint=dd}64{CGPoint=dd}80{CGPoint=dd}96@112@120
@24@0:8^{CGColor=}16
@56@0:8d16d24d32d40^{CGColorSpace=}48
@48@0:8d16d24d32^{CGColorSpace=}40
^{CGColor=}16@0:8
[3^v]
d40@0:8d16d24^d32
v32@0:8d16d24
v40@0:8d16d24d32
{?=dd}16@0:8
{CGPoint=dd}24@0:8Q16
i24@0:8^d16
v36@0:8@16I24^d28
v28@0:8@16I24
v20@0:8I16
{?="i"d"q"d}
@"CIEnhancementHistogram"
^{OpaqueVTPixelTransferSession=}
^{__CVBuffer=}
^{?=^?^?^?^?}
{CGRect={CGPoint=dd}{CGSize=dd}}24@0:8f16f20
r*16@0:8
@56@0:8@16@24@32@40@?48
f36@0:8@16^i24i32
@?16@0:8
v24@0:8@?16
^{?=^ii}24@0:8i16i20
i32@0:8{?=^ii}16
^i32@0:8{?=^ii}16
B32@0:8{?=^ii}16
B36@0:8^{?=^ii}16^i24i32
v24@0:8^{?=^ii}16
i28@0:8^{?=^ii}16i24
^{?=^ii}24@0:8^{?=^ii}16
^{?=^ii}32@0:8^{?=^ii}16^{?=^ii}24
^{?=^ii}32@0:8^{?=^ii}16i24i28
^{?=^ii}20@0:8i16
B32@0:8^i16i24i28
[256i]
^{?=^ii}
{CGRect={CGPoint=dd}{CGSize=dd}}60@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24f56
@24@0:8Q16
v32@0:8^v16^v24
@"CIBurstImageSetInternal"
v28@0:8*16i24
@28@0:8^{CGImage=}16i24
*16@0:8
v24@0:8*16
@48@0:8@16@24@32^{CGColorSpace=}40
@24@0:8^{filterShape={CGRect={CGPoint=dd}{CGSize=dd}}}16
@24@0:8i16i20
^{CGSRegionObject=}16@0:8
@32@0:8^{WarpKernel=^^?{Atomic={?=i}}**B^{SerialIntArray}^{SerialStringArray}^{__CFString}BBBi}16^{SerialObjectPtrArray=iii^^v}24
@56@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16i48i52
{CGRect={CGPoint=dd}{CGSize=dd}}72@0:8^{WarpKernel=^^?{Atomic={?=i}}**B^{SerialIntArray}^{SerialStringArray}^{__CFString}BBBi}16^{SerialObjectPtrArray=iii^^v}24@32{CGRect={CGPoint=dd}{CGSize=dd}}40
^{CGImageSource=}
@"NSObject"
@"CIFilter"
@32@0:8^{CGImageSource=}16@24
@32@0:8r^d16@24
v40@0:8^@16^@24^@32
v48@0:8@16@24^@32^@40
{CGRect={CGPoint=dd}{CGSize=dd}}56@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16d48
{CGRect={CGPoint=dd}{CGSize=dd}}64@0:8{CGSize=dd}16{CGRect={CGPoint=dd}{CGSize=dd}}32
i32@0:8{CGSize=dd}16
{CGRect={CGPoint=dd}{CGSize=dd}}80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGSize=dd}48{CGPoint=dd}64
{CGRect={CGPoint=dd}{CGSize=dd}}68@0:8{CGSize=dd}16{CGPoint=dd}32i48{CGSize=dd}52
{CGRect={CGPoint=dd}{CGSize=dd}}40@0:8{CGSize=dd}16@32
i96@0:8{CGSize=dd}16{CGRect={CGPoint=dd}{CGSize=dd}}32{CGRect={CGPoint=dd}{CGSize=dd}}64
{CGRect={CGPoint=dd}{CGSize=dd}}100@0:8{CGSize=dd}16{CGRect={CGPoint=dd}{CGSize=dd}}32i64{CGRect={CGPoint=dd}{CGSize=dd}}68
{CGPoint=dd}80@0:8{CGPoint=dd}16{CGPoint=dd}32{CGPoint=dd}48{CGPoint=dd}64
@80@0:8@16@24@32{CGRect={CGPoint=dd}{CGSize=dd}}40^{CGRect={CGPoint=dd}{CGSize=dd}}72
@64@0:8@16^{CGImage=}24{CGRect={CGPoint=dd}{CGSize=dd}}32
v112@0:8@16{CGAffineTransform=dddddd}24{CGRect={CGPoint=dd}{CGSize=dd}}72^{CGRect={CGPoint=dd}{CGSize=dd}}104
a8A 
?P$
?9EGr
